{"title": [], "abstractContent": [{"text": "We design and release BONIE, the first open numerical relation extractor, for extracting Open IE tuples where one of the arguments is a number or a quantity-unit phrase.", "labels": [], "entities": [{"text": "BONIE", "start_pos": 22, "end_pos": 27, "type": "METRIC", "confidence": 0.9891899824142456}, {"text": "numerical relation extractor", "start_pos": 44, "end_pos": 72, "type": "TASK", "confidence": 0.6318349838256836}, {"text": "extracting Open IE tuples", "start_pos": 78, "end_pos": 103, "type": "TASK", "confidence": 0.7272881865501404}]}, {"text": "BONIE uses bootstrapping to learn the specific dependency patterns that express numerical relations in a sentence.", "labels": [], "entities": [{"text": "BONIE", "start_pos": 0, "end_pos": 5, "type": "DATASET", "confidence": 0.7306945323944092}]}, {"text": "BONIE's novelty lies in task-specific cus-tomizations, such as inferring implicit relations , which are clear due to context such as units (for e.g., 'square kilometers' suggests area, even if the word 'area' is missing in the sentence).", "labels": [], "entities": [{"text": "BONIE", "start_pos": 0, "end_pos": 5, "type": "METRIC", "confidence": 0.9344136714935303}]}, {"text": "BONIE obtains 1.5x yield and 15 point precision gain on numerical facts over a state-of-the-art Open IE system.", "labels": [], "entities": [{"text": "BONIE", "start_pos": 0, "end_pos": 5, "type": "METRIC", "confidence": 0.8750325441360474}, {"text": "yield", "start_pos": 19, "end_pos": 24, "type": "METRIC", "confidence": 0.9622906446456909}, {"text": "precision gain", "start_pos": 38, "end_pos": 52, "type": "METRIC", "confidence": 0.9550024569034576}]}], "introductionContent": [{"text": "Open Information Extraction (Open IE) systems extract relational tuples from text, without requiring a pre-specified vocabulary (, by constructing the relation phrases and arguments from within the sentences themselves.", "labels": [], "entities": [{"text": "Open Information Extraction (Open IE)", "start_pos": 0, "end_pos": 37, "type": "TASK", "confidence": 0.7773582254137311}]}, {"text": "Early works on Open IE such as REVERB ) extract verbmediated relations via a handful of human-defined patterns.", "labels": [], "entities": []}, {"text": "OLLIE improves recall by learning dependency patterns, using bootstrapping over RE-VERB extractions).", "labels": [], "entities": [{"text": "OLLIE", "start_pos": 0, "end_pos": 5, "type": "METRIC", "confidence": 0.8394873738288879}, {"text": "recall", "start_pos": 15, "end_pos": 21, "type": "METRIC", "confidence": 0.9945566654205322}, {"text": "RE-VERB", "start_pos": 80, "end_pos": 87, "type": "METRIC", "confidence": 0.8648245334625244}]}, {"text": "Open IE 4.2, a state-of-the-art open information extractor, is based on a combination of SRLIE, a verbmediated extractor over SRL frames ), and RELNOUN 2.0, which performs special linguistic processing for extraction from complex noun phrases ( In this work, we present and release 2 the first system for open numerical extraction, which we name BONIE for Bootstrapping-based Open Numerical Information Extractor.", "labels": [], "entities": [{"text": "open information extractor", "start_pos": 32, "end_pos": 58, "type": "TASK", "confidence": 0.7148660818735758}, {"text": "SRLIE", "start_pos": 89, "end_pos": 94, "type": "DATASET", "confidence": 0.7295228242874146}, {"text": "RELNOUN", "start_pos": 144, "end_pos": 151, "type": "METRIC", "confidence": 0.9821674823760986}, {"text": "open numerical extraction", "start_pos": 305, "end_pos": 330, "type": "TASK", "confidence": 0.6904231806596121}, {"text": "BONIE", "start_pos": 346, "end_pos": 351, "type": "METRIC", "confidence": 0.9606835246086121}, {"text": "Bootstrapping-based Open Numerical Information Extractor", "start_pos": 356, "end_pos": 412, "type": "TASK", "confidence": 0.4902326464653015}]}, {"text": "It is important to note that existing Open IE systems, like Open IE 4.2, may also extract numerical facts.", "labels": [], "entities": []}, {"text": "However, they are oblivious to the presence of numbers in arguments.", "labels": [], "entities": []}, {"text": "Therefore, they may miss important extractions and may not always output the best numerical facts.", "labels": [], "entities": []}, {"text": "compares extractions generated by Open IE 4.2 and BONIE on some of the sample sentences.", "labels": [], "entities": [{"text": "BONIE", "start_pos": 50, "end_pos": 55, "type": "METRIC", "confidence": 0.8516470193862915}]}, {"text": "At a high level BONIE follows OLLIE's design of identifying seed facts, constructing training data by bootstrapping sentences that may mention a seed fact, pattern learning and ranking.", "labels": [], "entities": [{"text": "BONIE", "start_pos": 16, "end_pos": 21, "type": "METRIC", "confidence": 0.9761600494384766}, {"text": "OLLIE", "start_pos": 30, "end_pos": 35, "type": "METRIC", "confidence": 0.6424500346183777}]}, {"text": "note that bootstrapping for numerical IE is challenging; it can lead to high noise and missed recall, since numbers can easily match out of context, and numbers may not match due to approximations.", "labels": [], "entities": [{"text": "IE", "start_pos": 38, "end_pos": 40, "type": "TASK", "confidence": 0.7825149297714233}, {"text": "recall", "start_pos": 94, "end_pos": 100, "type": "METRIC", "confidence": 0.900643527507782}]}, {"text": "In response, similar to most previous works (e.g., LUCHS () BONIE matches a number if it is within a percentage threshold.", "labels": [], "entities": [{"text": "LUCHS", "start_pos": 51, "end_pos": 56, "type": "METRIC", "confidence": 0.7771815061569214}, {"text": "BONIE", "start_pos": 60, "end_pos": 65, "type": "METRIC", "confidence": 0.8575748205184937}]}, {"text": "Additionally, BONIE uses a quantity extractor, which provides the units mentioned in the sentence -BONIE bootstraps a sentence only when the units match.", "labels": [], "entities": [{"text": "BONIE", "start_pos": 14, "end_pos": 19, "type": "DATASET", "confidence": 0.8499060869216919}]}, {"text": "When compared to OLLIE, BONIE contributes several numerical IE specific customizations.", "labels": [], "entities": [{"text": "OLLIE", "start_pos": 17, "end_pos": 22, "type": "METRIC", "confidence": 0.8302346467971802}, {"text": "BONIE", "start_pos": 24, "end_pos": 29, "type": "METRIC", "confidence": 0.9955873489379883}, {"text": "IE", "start_pos": 60, "end_pos": 62, "type": "TASK", "confidence": 0.8975260853767395}]}, {"text": "Since no open facts are available for this task, we first manually define a set of high-precision seed patterns, which are run over a large corpus to generate seed facts.", "labels": [], "entities": []}, {"text": "(2) Not all seeds are fit for bootstrapping -many don't even have an entity as first argument.", "labels": [], "entities": []}, {"text": "We develop heuristics to identify an informative subset from these.", "labels": [], "entities": []}, {"text": "After bootstrapping and pattern learning, we find that we are missing important tuples.", "labels": [], "entities": [{"text": "pattern learning", "start_pos": 24, "end_pos": 40, "type": "TASK", "confidence": 0.8960287570953369}]}, {"text": "E.g., sentence #3 in above has no explicit relation word -the relation \"has length of\" is implicit via the adjective 'long'.", "labels": [], "entities": []}, {"text": "And, sentence #5 expresses the relation 'area' via the units.", "labels": [], "entities": []}, {"text": "(3) BONIE identifies implicit relations using additional processing of units and adjectives.", "labels": [], "entities": [{"text": "BONIE", "start_pos": 4, "end_pos": 9, "type": "METRIC", "confidence": 0.9431608319282532}]}, {"text": "(4) Finally, BONIE can tag a quantity as count and prepends \"number of\" in the relation phrase (sentence #2).", "labels": [], "entities": [{"text": "BONIE", "start_pos": 13, "end_pos": 18, "type": "METRIC", "confidence": 0.9886018633842468}]}], "datasetContent": [{"text": "We build BONIE over data from ClueWeb12, 4 filtered so as to keep only the sentences that contain numbers.", "labels": [], "entities": [{"text": "BONIE", "start_pos": 9, "end_pos": 14, "type": "METRIC", "confidence": 0.9758270978927612}]}, {"text": "We further remove those where quantity represents a date, time, or duration, and where the quantity is accompanied by document words like 'Section', ', or '.", "labels": [], "entities": []}, {"text": "We use the dependency parser from ClearNLP 5 . We generate about 21,000 seed facts from roughly 20 million numerical sentences.", "labels": [], "entities": [{"text": "ClearNLP 5", "start_pos": 34, "end_pos": 44, "type": "DATASET", "confidence": 0.937740832567215}]}, {"text": "These are matched against 7 million numerical sentences obtaining about 18,500 (sentence, fact) pairs.", "labels": [], "entities": []}, {"text": "We tried different values of \u03b4 (the matching threshold) and found results to not be sensitive as long as \u03b4 varies in the range of 2% to 5%.", "labels": [], "entities": []}, {"text": "So we set \u03b4=2% during the final evaluation.", "labels": [], "entities": [{"text": "\u03b4", "start_pos": 10, "end_pos": 11, "type": "METRIC", "confidence": 0.9609823226928711}]}, {"text": "The distance threshold between the quantity and unit mentioned in Section 2.3 is set to 3 and is based on our general understanding of parse trees.", "labels": [], "entities": []}, {"text": "BONIE learns around 7,000 new patterns.", "labels": [], "entities": [{"text": "BONIE", "start_pos": 0, "end_pos": 5, "type": "METRIC", "confidence": 0.9098842740058899}]}, {"text": "Since pattern frequency is a good indicator of pattern quality (, we rank the patterns on the basis of frequency and take the top 1,000 patterns for further analysis.", "labels": [], "entities": []}, {"text": "We find that almost all patterns beyond the top 1,000 are learned only once or twice on our training set.", "labels": [], "entities": []}, {"text": "Our decision to ignore all patterns beyond the top 1,000 is so that we have a support of at least three for each pattern.", "labels": [], "entities": []}, {"text": "We sample a random testset of 2,000 numerical sentences from ClueWeb12 (not used in training).", "labels": [], "entities": [{"text": "ClueWeb12", "start_pos": 61, "end_pos": 70, "type": "DATASET", "confidence": 0.9317445755004883}]}, {"text": "Two annotators with NLP experience annotate each extraction for correctness.", "labels": [], "entities": []}, {"text": "We obtain an inter-annotator agreement of 97%, and report the results on the subset where both annotators agree.", "labels": [], "entities": []}, {"text": "Since there are no open numerical extractors available, we compare BONIE against an Open IE system and another closed numerical IE system.", "labels": [], "entities": [{"text": "BONIE", "start_pos": 67, "end_pos": 72, "type": "METRIC", "confidence": 0.9639943838119507}]}, {"text": "We also perform additional ablation study to evaluate the value of each component.", "labels": [], "entities": [{"text": "ablation", "start_pos": 27, "end_pos": 35, "type": "METRIC", "confidence": 0.9571484327316284}]}, {"text": "Just the seed patterns themselves have a significantly higher precision but much smaller yield.", "labels": [], "entities": [{"text": "precision", "start_pos": 62, "end_pos": 71, "type": "METRIC", "confidence": 0.9991208910942078}]}, {"text": "This is expected, since the seeds must be highly precise for bootstrapping.", "labels": [], "entities": []}, {"text": "If Yago matching and other seed filtering heuristics are turned off, the precision of the system goes down drastically due to a very noisy bootstrapped set.", "labels": [], "entities": [{"text": "Yago matching", "start_pos": 3, "end_pos": 16, "type": "TASK", "confidence": 0.7201623618602753}, {"text": "precision", "start_pos": 73, "end_pos": 82, "type": "METRIC", "confidence": 0.9996892213821411}]}, {"text": "If the post-processing of relation phrase construction is turned off, there is a 5 point precision loss and about 7% yield reduction due to some incorrect extracted tuples, which are corrected by post-processing.", "labels": [], "entities": [{"text": "relation phrase construction", "start_pos": 26, "end_pos": 54, "type": "TASK", "confidence": 0.7452186544736227}, {"text": "precision", "start_pos": 89, "end_pos": 98, "type": "METRIC", "confidence": 0.9898257851600647}]}, {"text": "Finally, Wordnet-based expansion has marginal increase in yield and slight precision loss.", "labels": [], "entities": [{"text": "yield", "start_pos": 58, "end_pos": 63, "type": "METRIC", "confidence": 0.9917128086090088}, {"text": "precision", "start_pos": 75, "end_pos": 84, "type": "METRIC", "confidence": 0.9987666606903076}]}, {"text": "Open IE 4.2 associates a confidence value with each extraction -ranking against which generates a precision-yield curve.", "labels": [], "entities": [{"text": "Open IE 4.2", "start_pos": 0, "end_pos": 11, "type": "DATASET", "confidence": 0.7117067178090414}, {"text": "precision-yield", "start_pos": 98, "end_pos": 113, "type": "METRIC", "confidence": 0.9943619966506958}]}, {"text": "For BONIE, we rank the patterns in such away that the seed patterns are at the top, followed by the learned patterns.", "labels": [], "entities": [{"text": "BONIE", "start_pos": 4, "end_pos": 9, "type": "METRIC", "confidence": 0.8740212917327881}]}, {"text": "The learned patterns are ordered based on their frequencies.", "labels": [], "entities": []}, {"text": "reports the curves for both the systems and we find that BONIE has a larger area under the curve as compared to Open IE 4.2.", "labels": [], "entities": [{"text": "BONIE", "start_pos": 57, "end_pos": 62, "type": "METRIC", "confidence": 0.8600379228591919}, {"text": "Open IE 4.2", "start_pos": 112, "end_pos": 123, "type": "DATASET", "confidence": 0.8234311739603678}]}, {"text": "Estimating recall in Open IE is difficult since it requires annotators to exhaustively tag all open extractions in a sentence.", "labels": [], "entities": [{"text": "recall", "start_pos": 11, "end_pos": 17, "type": "METRIC", "confidence": 0.8553886413574219}, {"text": "Open IE", "start_pos": 21, "end_pos": 28, "type": "TASK", "confidence": 0.4968612790107727}]}, {"text": "To get an estimate, an author manually tagged 100 sentences with all numerical extractions.", "labels": [], "entities": []}, {"text": "We find that BONIE's recall is about 48%.", "labels": [], "entities": [{"text": "BONIE", "start_pos": 13, "end_pos": 18, "type": "METRIC", "confidence": 0.9975554347038269}, {"text": "recall", "start_pos": 21, "end_pos": 27, "type": "METRIC", "confidence": 0.9009968042373657}]}, {"text": "Two-thirds of missed recall is because of missing conjuncts.", "labels": [], "entities": [{"text": "recall", "start_pos": 21, "end_pos": 27, "type": "METRIC", "confidence": 0.9534428715705872}]}, {"text": "E.g., it misses the tuple relating retirement age with 68 years in \"The retirement age for men is 65 years and 68 years for women.\"", "labels": [], "entities": []}, {"text": "Other missed recall is due to complexity of sentences or inaccuracy of parsers.", "labels": [], "entities": [{"text": "recall", "start_pos": 13, "end_pos": 19, "type": "METRIC", "confidence": 0.96038419008255}]}], "tableCaptions": [{"text": " Table 2: Precision and Yield (#correct numerical extrac-", "labels": [], "entities": [{"text": "Precision", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9168511033058167}]}]}