{"title": [], "abstractContent": [{"text": "Existing Knowledge Base Population methods extract relations from a closed relational schema with limited coverage, leading to sparse KBs.", "labels": [], "entities": []}, {"text": "We propose Pocket Knowledge Base Population (PKBP), the task of dynamically constructing a KB of entities related to a query and finding the best characterization of relationships between entities.", "labels": [], "entities": []}, {"text": "We describe novel Open Information Extraction methods which leverage the PKB to find informative trigger words.", "labels": [], "entities": [{"text": "Open Information Extraction", "start_pos": 18, "end_pos": 45, "type": "TASK", "confidence": 0.618185818195343}, {"text": "PKB", "start_pos": 73, "end_pos": 76, "type": "DATASET", "confidence": 0.8385183215141296}]}, {"text": "We evaluate using existing KBP shared-task data as well as new annotations collected for this work.", "labels": [], "entities": [{"text": "KBP shared-task data", "start_pos": 27, "end_pos": 47, "type": "DATASET", "confidence": 0.7290133039156595}]}, {"text": "Our methods produce high quality KBs from just text with many more entities and relationships than existing KBP systems.", "labels": [], "entities": []}], "introductionContent": [{"text": "Much of human knowledge is contained in text in books, encyclopedias, the internet, and written communications.", "labels": [], "entities": []}, {"text": "Building knowledge bases to store, search, and reason over this information is an important problem in natural language understanding.", "labels": [], "entities": [{"text": "natural language understanding", "start_pos": 103, "end_pos": 133, "type": "TASK", "confidence": 0.6618166367212931}]}, {"text": "A lot of work in knowledge base population (KBP) has focused on the NIST Text Analysis Conference track of the same name, and specifically the slot filling task.", "labels": [], "entities": [{"text": "NIST Text Analysis Conference track", "start_pos": 68, "end_pos": 103, "type": "DATASET", "confidence": 0.7581022500991821}, {"text": "slot filling task", "start_pos": 143, "end_pos": 160, "type": "TASK", "confidence": 0.8657823006312052}]}, {"text": "Slot Filling (SF) defines a relational schema similar to Wikipedia infoboxes.", "labels": [], "entities": [{"text": "Slot Filling (SF)", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.8635592579841613}]}, {"text": "SF KBP systems extract facts from text corresponding to an entity called the query.", "labels": [], "entities": []}, {"text": "This work addresses two issues concerning SF KBP.", "labels": [], "entities": [{"text": "SF KBP", "start_pos": 42, "end_pos": 48, "type": "DATASET", "confidence": 0.748092919588089}]}, {"text": "First, the SF schema has strict semantics for the relations which can be extracted, and thus no SF relation can be extracted for most related entities, leading to sparse KBs.", "labels": [], "entities": []}, {"text": "Second, because SF has a small static schema, most research has focused on batch processing fora single schema, limiting downstream usefulness.", "labels": [], "entities": [{"text": "SF", "start_pos": 16, "end_pos": 18, "type": "TASK", "confidence": 0.9333702325820923}]}, {"text": "This means KBs built by slot filling have limited applicability in some real world settings of interest.", "labels": [], "entities": [{"text": "slot filling", "start_pos": 24, "end_pos": 36, "type": "TASK", "confidence": 0.9228133261203766}]}, {"text": "We address these issues by proposing Pocket Knowledge Base Population.", "labels": [], "entities": [{"text": "Pocket Knowledge Base Population", "start_pos": 37, "end_pos": 69, "type": "DATASET", "confidence": 0.886512503027916}]}, {"text": "Pocket KBs (PKBs) are dense entity-centric KBs dynamically constructed fora query.", "labels": [], "entities": []}, {"text": "In both SF and pocket KBP, a query is an entity of interest and a document mentioning that entity.", "labels": [], "entities": []}, {"text": "However, in PKB the primary goal is to populate the KB with nodes for all entities related to the query, irrespective of any prior beliefs about relations.", "labels": [], "entities": []}, {"text": "PKB edges store representations of mentions referring to the entities connected by that edge, and thus may better serve downstream tasks which don't perfectly align to a particular schema.", "labels": [], "entities": []}, {"text": "We describe a PKBP system which builds KBs from text corpora.", "labels": [], "entities": []}, {"text": "This includes unsupervised methods for finding related entities and mentions of them and the query with accuracies of 89.5 and 93.1 respectively when evaluated on SF queries.", "labels": [], "entities": []}, {"text": "We also propose novel entity-centric Open IE () methods for characterizing the relationship between entities which perform twice as well as a syntactically-informed baseline.", "labels": [], "entities": []}, {"text": "Our contributions also include a comparison between pocket and SF KBs constructed on SF queries, showing our KBs are multiple times larger while remaining high quality.", "labels": [], "entities": []}, {"text": "We make our system publicly available.", "labels": [], "entities": []}], "datasetContent": [{"text": "We use the TAC SF13 query entities to evaluate our methods; 50 person and 50 organization entities are used as queries to construct 100 PKBs.", "labels": [], "entities": [{"text": "TAC SF13 query entities", "start_pos": 11, "end_pos": 34, "type": "DATASET", "confidence": 0.8908120095729828}]}, {"text": "70 of the 100 query entities were NIL (26/60 PER and 44/50 ORG), meaning that they do not appear in the TAC KB, though our methods aren't in principle sensitive to this because they create entities on the fly.", "labels": [], "entities": [{"text": "NIL", "start_pos": 34, "end_pos": 37, "type": "METRIC", "confidence": 0.9450625777244568}, {"text": "PER", "start_pos": 45, "end_pos": 48, "type": "METRIC", "confidence": 0.9918253421783447}, {"text": "ORG", "start_pos": 59, "end_pos": 62, "type": "METRIC", "confidence": 0.9816793203353882}, {"text": "TAC KB", "start_pos": 104, "end_pos": 110, "type": "DATASET", "confidence": 0.6843831539154053}]}, {"text": "We use annotated versions of Gigaword 5 and English Wikipedia to construct our PKBs.", "labels": [], "entities": [{"text": "English Wikipedia", "start_pos": 44, "end_pos": 61, "type": "DATASET", "confidence": 0.8170900642871857}]}, {"text": "We use Amazon Mechanical Turk workers as annotators.", "labels": [], "entities": [{"text": "Amazon Mechanical Turk workers", "start_pos": 7, "end_pos": 37, "type": "DATASET", "confidence": 0.9432066828012466}]}, {"text": "We generated our PKBs with \u03c4 = 15, \u03c1 = 0.5, \u03b1 t = 40, \u03b1 c = 20, and \u03b1 a = 10.", "labels": [], "entities": []}, {"text": "These constants were tuned by hand and are not sensitive to small changes.", "labels": [], "entities": []}, {"text": "We take a subset of the PKB which covers the 15 most related entities and the one-best trigger for each.", "labels": [], "entities": [{"text": "PKB", "start_pos": 24, "end_pos": 27, "type": "DATASET", "confidence": 0.8796821236610413}]}, {"text": "We call these \"explanations\" where each is a sentence with three labels: a) a mention of the query m q , b) a mention of the a related entity m r , and c) a trigger word t.", "labels": [], "entities": []}, {"text": "Entity Linking and Relatedness For each explanation, we ask: COREF: Does the query mention refer to the same entity as m q ? RELATED: Is the query entity meaningfully related to the referent of m r ? These annotations are not done by the same annotators to avoid confirmation bias.", "labels": [], "entities": [{"text": "Entity Linking", "start_pos": 0, "end_pos": 14, "type": "TASK", "confidence": 0.720878466963768}, {"text": "COREF", "start_pos": 61, "end_pos": 66, "type": "METRIC", "confidence": 0.9927780032157898}, {"text": "RELATED", "start_pos": 125, "end_pos": 132, "type": "METRIC", "confidence": 0.9978577494621277}]}, {"text": "Worried annotators might be lulled into thinking all COREF instances were true, we made the task ternary by adding an intruder entity (randomly drawn from SF13 queries).", "labels": [], "entities": []}, {"text": "Annotators were shown m q and could choose coreference with the query, the intruder, or neither.", "labels": [], "entities": []}, {"text": "We drop annotations from annotators who chose an intruder 6 because we know these to be incorrect, and compute accuracy as proportion of the remaining annotations which chose the query.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 111, "end_pos": 119, "type": "METRIC", "confidence": 0.999129593372345}]}, {"text": "RELATED was posed as a binary task of whether m r is more related to the query or the intruder (without highlighting m q ).", "labels": [], "entities": [{"text": "RELATED", "start_pos": 0, "end_pos": 7, "type": "METRIC", "confidence": 0.8909991979598999}]}, {"text": "In positive cases, the annotator should observe that sentence shown contains a mention of the query entity and explains why they are related.", "labels": [], "entities": []}, {"text": "Our system retrieves coreferent and related mentions with high accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 63, "end_pos": 71, "type": "METRIC", "confidence": 0.9963471293449402}]}, {"text": "For coreference, mistakes usually happen when there is significant lexical overlap but some distinguishing feature that proves too subtle for our system to doubt the match, like Midwest High Speed Rail Association vs U.S. High Speed Rail Association or [English] Nationwide Building Society vs Irish Nationwide Building Society.", "labels": [], "entities": [{"text": "coreference", "start_pos": 4, "end_pos": 15, "type": "TASK", "confidence": 0.9555315971374512}, {"text": "Midwest High Speed Rail Association vs U.S. High Speed Rail Association", "start_pos": 178, "end_pos": 249, "type": "DATASET", "confidence": 0.8303894075480375}, {"text": "Nationwide Building Society vs Irish Nationwide Building Society", "start_pos": 263, "end_pos": 327, "type": "DATASET", "confidence": 0.8235848620533943}]}, {"text": "For relatedness, the biggest source of errors are news organizations listed as related entities because it is common to see sentences like \"Mohammed Sobeih, Moussa's deputy, told The Associated Press on Monday that...\".", "labels": [], "entities": []}, {"text": "Future work might address this problem by using normalized measures of statistical relatedness like PMI rather than raw co-occurrence counts.", "labels": [], "entities": []}, {"text": "Trigger Words To evaluate the informativeness of chosen triggers, we present annotators with m q , The order of the intruder and the query were randomized.", "labels": [], "entities": []}, {"text": "6 This affected 6.1% of COREF annotations.", "labels": [], "entities": []}, {"text": "m r , and two potential trigger words highlighted.", "labels": [], "entities": []}, {"text": "One trigger is chosen according to \u00a73.3 and the other is an NN * |VB * |JJ * |RB * word in the projection of the dependency node dominating both entities.", "labels": [], "entities": []}, {"text": "The annotator may choose either trigger as a good characterization of the situation involving m q and m r , or label neither as sufficient.", "labels": [], "entities": []}, {"text": "Note that this baseline is strong: it shares the entity linking ( \u00a73.2), trigger sentence selection ( \u00a73.3), and dependency parse tree as our system.", "labels": [], "entities": [{"text": "trigger sentence selection", "start_pos": 73, "end_pos": 99, "type": "TASK", "confidence": 0.5595316191514333}, {"text": "dependency parse", "start_pos": 113, "end_pos": 129, "type": "TASK", "confidence": 0.6818916350603104}]}, {"text": "We report the results in.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: PKB entity accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 21, "end_pos": 29, "type": "METRIC", "confidence": 0.9687503576278687}]}, {"text": " Table 2: Related entity trigger identification.", "labels": [], "entities": [{"text": "Related entity trigger identification", "start_pos": 10, "end_pos": 47, "type": "TASK", "confidence": 0.8006972819566727}]}]}