{"title": [{"text": "Creating Training Corpora for NLG Micro-Planning", "labels": [], "entities": []}], "abstractContent": [{"text": "In this paper, we present a novel framework for semi-automatically creating linguistically challenging micro-planning data-to-text corpora from existing Knowledge Bases.", "labels": [], "entities": []}, {"text": "Because our method pairs data of varying size and shape with texts ranging from simple clauses to short texts, a dataset created using this framework provides a challenging benchmark for microplanning.", "labels": [], "entities": []}, {"text": "Another feature of this framework is that it can be applied to any large scale knowledge base and can therefore be used to train and learn KB verbalisers.", "labels": [], "entities": []}, {"text": "We apply our framework to DBpedia data and compare the resulting dataset with Wen et al.", "labels": [], "entities": [{"text": "DBpedia data", "start_pos": 26, "end_pos": 38, "type": "DATASET", "confidence": 0.8767749667167664}]}, {"text": "We show that while Wen et al.'s dataset is more than twice larger than ours, it is less diverse both in terms of input and in terms of text.", "labels": [], "entities": [{"text": "Wen et al.'s dataset", "start_pos": 19, "end_pos": 39, "type": "DATASET", "confidence": 0.6648682951927185}]}, {"text": "We thus propose our corpus generation framework as a novel method for creating challenging data sets from which NLG models can be learned which are capable of handling the complex interactions occurring during in micro-planning between lexicalisation, aggregation, surface reali-sation, referring expression generation and sentence segmentation.", "labels": [], "entities": [{"text": "referring expression generation", "start_pos": 287, "end_pos": 318, "type": "TASK", "confidence": 0.7494506438573202}, {"text": "sentence segmentation", "start_pos": 323, "end_pos": 344, "type": "TASK", "confidence": 0.7089689373970032}]}, {"text": "To encourage researchers to take up this challenge, we recently made available a dataset created using this framework in the context of the WEBNLG shared task.", "labels": [], "entities": [{"text": "WEBNLG shared task", "start_pos": 140, "end_pos": 158, "type": "DATASET", "confidence": 0.7628231048583984}]}], "introductionContent": [{"text": "To train Natural Language Generation (NLG) systems, various input-text corpora have been developed which associate (numerical, formal, linguistic) input with text.", "labels": [], "entities": [{"text": "Natural Language Generation (NLG)", "start_pos": 9, "end_pos": 42, "type": "TASK", "confidence": 0.8286407788594564}]}, {"text": "As discussed in detail in Section 2, these corpora can be classified into three main types namely, (i) domain specific corpora, (ii) benchmarks constructed from \"Expert\" Linguistic Annotations and (iii) crowdsourced benchmarks.", "labels": [], "entities": []}, {"text": "In this paper, we focus on how to create datato-text corpora which can support the learning of micro-planners i.e., data-to-text generation systems that can handle the complex interactions occurring between lexicalisation (mapping data to words), aggregation (exploiting linguistic constructs such as ellipsis and coordination to avoid repetition), surface realisation (using the appropriate syntactic constructs to build sentences), sentence segmentation and referring expression generation.", "labels": [], "entities": [{"text": "surface realisation", "start_pos": 349, "end_pos": 368, "type": "TASK", "confidence": 0.6993218511343002}, {"text": "sentence segmentation", "start_pos": 434, "end_pos": 455, "type": "TASK", "confidence": 0.7676936089992523}, {"text": "referring expression generation", "start_pos": 460, "end_pos": 491, "type": "TASK", "confidence": 0.7868051131566366}]}, {"text": "We start by reviewing the main existing types of NLG benchmarks and we argue fora crowdsourcing approach in which (i) data units are automatically built from an existing Knowledge Base (KB) and (ii) text is crowdsourced from the data (Section 2).", "labels": [], "entities": []}, {"text": "We then propose a generic framework for semi-automatically creating training corpora for NLG (Section 3) from existing knowledge bases.", "labels": [], "entities": []}, {"text": "In Section 4, we apply this framework to DBpedia data and we compare the resulting dataset with the dataset of using various metrics to evaluate the linguistic and computational adequacy of both datasets.", "labels": [], "entities": [{"text": "DBpedia data", "start_pos": 41, "end_pos": 53, "type": "DATASET", "confidence": 0.8718101680278778}]}, {"text": "By applying these metrics, we show that while Wen et al.'s dataset is more than twice larger than ours, it is less diverse both in terms of input and in terms of text.", "labels": [], "entities": [{"text": "Wen et al.'s dataset", "start_pos": 46, "end_pos": 66, "type": "DATASET", "confidence": 0.6891027589639028}]}, {"text": "We also com-pare the performance of a sequence-to-sequence model ( on both datasets to estimate the complexity of the learning task induced by each dataset.", "labels": [], "entities": []}, {"text": "We show that the performance of this neural model is much lower on the new data set than on the existing ones.", "labels": [], "entities": []}, {"text": "We thus propose our corpus generation framework as a novel method for creating challenging data sets from which NLG models can be learned which are capable of generating complex texts from KB data.", "labels": [], "entities": [{"text": "corpus generation", "start_pos": 20, "end_pos": 37, "type": "TASK", "confidence": 0.7229504585266113}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Data statistics from content selec- tion (A:Astronaut, B:Building, M:Monument,  U:University, W:Written work, S:Sports team).", "labels": [], "entities": []}, {"text": " Table 2: Text statistics from crowdsourcing for triple sets of varying sizes (min/max/avg).", "labels": [], "entities": []}, {"text": " Table 3: Comparing WEBNLG and RNNLG  datasets. Attributes are properties in RDF triples  or slots in dialog acts.", "labels": [], "entities": [{"text": "WEBNLG", "start_pos": 20, "end_pos": 26, "type": "DATASET", "confidence": 0.8216396570205688}, {"text": "RNNLG  datasets", "start_pos": 31, "end_pos": 46, "type": "DATASET", "confidence": 0.8908952474594116}]}, {"text": " Table 4: Text statistics from WEBNLG and  RNNLG.", "labels": [], "entities": [{"text": "WEBNLG", "start_pos": 31, "end_pos": 37, "type": "DATASET", "confidence": 0.9461928606033325}, {"text": "RNNLG", "start_pos": 43, "end_pos": 48, "type": "DATASET", "confidence": 0.9331836700439453}]}, {"text": " Table 5: Vocabulary sizes of input, output (number  of tokens). Perplexity and BLEU scores.", "labels": [], "entities": [{"text": "BLEU scores", "start_pos": 80, "end_pos": 91, "type": "METRIC", "confidence": 0.9680456221103668}]}]}