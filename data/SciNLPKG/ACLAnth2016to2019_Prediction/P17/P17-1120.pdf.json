{"title": [{"text": "Chat Detection in an Intelligent Assistant: Combining Task-oriented and Non-task-oriented Spoken Dialogue Systems", "labels": [], "entities": [{"text": "Chat Detection", "start_pos": 0, "end_pos": 14, "type": "TASK", "confidence": 0.7598719298839569}]}], "abstractContent": [{"text": "Recently emerged intelligent assistants on smartphones and home electronics (e.g., Siri and Alexa) can be seen as novel hybrids of domain-specific task-oriented spoken dialogue systems and open-domain non-task-oriented ones.", "labels": [], "entities": []}, {"text": "To realize such hybrid dialogue systems, this paper investigates determining whether or not a user is going to have a chat with the system.", "labels": [], "entities": []}, {"text": "To address the lack of benchmark datasets for this task, we construct anew dataset consisting of 15, 160 utterances collected from the real log data of a commercial intelligent assistant (and will release the dataset to facilitate future research activity).", "labels": [], "entities": []}, {"text": "In addition, we investigate using tweets and Web search queries for handling open-domain user utterances, which characterize the task of chat detection.", "labels": [], "entities": [{"text": "chat detection", "start_pos": 137, "end_pos": 151, "type": "TASK", "confidence": 0.7408844977617264}]}, {"text": "Experiments demonstrated that, while simple supervised methods are effective , the use of the tweets and search queries further improves the F 1-score from 86.21 to 87.53.", "labels": [], "entities": [{"text": "F 1-score", "start_pos": 141, "end_pos": 150, "type": "METRIC", "confidence": 0.9890032708644867}]}], "introductionContent": [], "datasetContent": [{"text": "In this section we explain how we constructed the new benchmark dataset for chat detection.", "labels": [], "entities": [{"text": "chat detection", "start_pos": 76, "end_pos": 90, "type": "TASK", "confidence": 0.8215507566928864}]}, {"text": "We then analyze the data to provide insights into the actual user behavior.", "labels": [], "entities": []}, {"text": "We empirically evaluate the proposed methods on the chat detection dataset.", "labels": [], "entities": [{"text": "chat detection", "start_pos": 52, "end_pos": 66, "type": "TASK", "confidence": 0.7610593140125275}]}, {"text": "We performed 10-fold cross validation on the chat detection dataset to train and evaluate the proposed classifiers.", "labels": [], "entities": []}, {"text": "In each fold, we used 80%, 10%, and 10% of the data for the training, development, and evaluation, respectively.", "labels": [], "entities": []}, {"text": "We used word2vec 10 to learn 300 dimensional word embeddings.", "labels": [], "entities": []}, {"text": "They were used to induce the additional 300 features for SVM.", "labels": [], "entities": []}, {"text": "They were also used as the pre-trained word embeddings for CNN.", "labels": [], "entities": []}, {"text": "We used the faster-rnn toolkit to train the GRU language models.", "labels": [], "entities": []}, {"text": "The size of the embedding and hidden layer was set to 256.", "labels": [], "entities": []}, {"text": "Noise contrastive estimation () was used to train the soft-max function and the number of noise samples was set to 50.", "labels": [], "entities": [{"text": "Noise contrastive estimation", "start_pos": 0, "end_pos": 28, "type": "TASK", "confidence": 0.734013835589091}]}, {"text": "Maximum entropy 4-gram models were also trained to yield a combined model.", "labels": [], "entities": []}, {"text": "The language models were trained on 100 millions tweets collected between Apr. and July 2016 and 100 million Web search queries issued between Mar. and Jun. 2016. The tweets were sampled from those received replies to collect only conversational tweets ().", "labels": [], "entities": []}, {"text": "The same Web search queries were used to derive the binary feature.", "labels": [], "entities": []}, {"text": "Although it is difficult to release those data, we plan to make the feature values available together with the benchmark dataset.", "labels": [], "entities": []}, {"text": "We used liblinear 12 to train L 2 -regularized L 2 -loss SVM.", "labels": [], "entities": []}, {"text": "The hyperparameter c was tuned   over {2 \u221210 , 2 \u22129 , . .", "labels": [], "entities": []}, {"text": "The CNN was implemented with chainer.", "labels": [], "entities": [{"text": "CNN", "start_pos": 4, "end_pos": 7, "type": "DATASET", "confidence": 0.38747039437294006}, {"text": "chainer", "start_pos": 29, "end_pos": 36, "type": "METRIC", "confidence": 0.9625425338745117}]}, {"text": "13 We tuned the number of feature maps over {100, 150}, and filter region sizes over {{2}, {3}, {1, 2}, {2, 3}, {3, 4}, {1, 2, 3}, {2, 3, 4}}.", "labels": [], "entities": []}, {"text": "The mini-batch size was set to 32.", "labels": [], "entities": []}, {"text": "The dropout rate was set to 0.5.", "labels": [], "entities": []}, {"text": "We used Adam (\u03b1 = 0.001, \u03b21 = 0.9, \u03b22 = 0.999, and \u03f5 = 10 \u22128 ) to perform stochastic gradient descent (.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Example utterances and the numbers of votes. NONCHAT utterances are further divided into  information seeking (top) and device control (bottom) to facilitate readers' understanding.", "labels": [], "entities": [{"text": "NONCHAT utterances", "start_pos": 55, "end_pos": 73, "type": "TASK", "confidence": 0.6955894231796265}, {"text": "information seeking", "start_pos": 100, "end_pos": 119, "type": "TASK", "confidence": 0.6991320699453354}]}, {"text": " Table 2: Distribution of the numbers of votes.", "labels": [], "entities": [{"text": "Distribution", "start_pos": 10, "end_pos": 22, "type": "TASK", "confidence": 0.9784553647041321}]}, {"text": " Table 4: Chat detection results.", "labels": [], "entities": [{"text": "Chat detection", "start_pos": 10, "end_pos": 24, "type": "TASK", "confidence": 0.9351528584957123}]}, {"text": " Table 5: Examples of the language model scores. The first two columns represent the scores provided  by the GRU language models trained on the tweets and Web search queries, respectively. The third and  fourth columns represent the label and utterance.", "labels": [], "entities": []}, {"text": " Table 6: Effect of the three features derived from  the tweets and Web search queries.", "labels": [], "entities": []}, {"text": " Table 8: Chat detection results across the numbers  of votes that the majority label obtained.", "labels": [], "entities": [{"text": "Chat detection", "start_pos": 10, "end_pos": 24, "type": "TASK", "confidence": 0.9441574513912201}]}]}