{"title": [{"text": "Linguistically Regularized LSTM for Sentiment Classification", "labels": [], "entities": [{"text": "Sentiment Classification", "start_pos": 36, "end_pos": 60, "type": "TASK", "confidence": 0.9758069515228271}]}], "abstractContent": [{"text": "This paper deals with sentence-level sentiment classification.", "labels": [], "entities": [{"text": "sentence-level sentiment classification", "start_pos": 22, "end_pos": 61, "type": "TASK", "confidence": 0.7993482649326324}]}, {"text": "Though a variety of neural network models have been proposed recently, however, previous models either depend on expensive phrase-level annotation, most of which has remarkably degraded performance when trained with only sentence-level annotation; or do not fully employ linguistic resources (e.g., sentiment lexicons, negation words, intensity words).", "labels": [], "entities": []}, {"text": "In this paper, we propose simple models trained with sentence-level annotation , but also attempt to model the linguistic role of sentiment lexicons, negation words, and intensity words.", "labels": [], "entities": []}, {"text": "Results show that our models are able to capture the linguistic role of sentiment words, negation words, and intensity words in sentiment expression.", "labels": [], "entities": [{"text": "sentiment expression", "start_pos": 128, "end_pos": 148, "type": "TASK", "confidence": 0.8921769261360168}]}], "introductionContent": [{"text": "Sentiment classification aims to classify text to sentiment classes such as positive or negative, or more fine-grained classes such as very positive, positive, neutral, etc.", "labels": [], "entities": [{"text": "Sentiment classification", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.9428709745407104}]}, {"text": "There has been a variety of approaches for this purpose such as lexicon-based classification), and early machine learning based methods (, and recently neural network models such as convolutional neural network (CNN), recursive autoencoders, Long ShortTerm Memory (LSTM), and many more.", "labels": [], "entities": [{"text": "lexicon-based classification", "start_pos": 64, "end_pos": 92, "type": "TASK", "confidence": 0.7475932240486145}]}, {"text": "* Corresponding Author: Minlie Huang In spite of the great success of these neural models, there are some defects in previous studies.", "labels": [], "entities": []}, {"text": "First, tree-structured models such as recursive autoencoders and Tree-LSTM (, depend on parsing tree structures and expensive phrase-level annotation, whose performance drops substantially when only trained with sentence-level annotation.", "labels": [], "entities": []}, {"text": "Second, linguistic knowledge such as sentiment lexicon, negation words or negators (e.g., not, never), and intensity words or intensifiers (e.g., very, absolutely), has not been fully employed in neural models.", "labels": [], "entities": [{"text": "sentiment lexicon", "start_pos": 37, "end_pos": 54, "type": "TASK", "confidence": 0.8692958950996399}]}, {"text": "The goal of this research is to developing simple sequence models but also attempts to fully employing linguistic resources to benefit sentiment classification.", "labels": [], "entities": [{"text": "sentiment classification", "start_pos": 135, "end_pos": 159, "type": "TASK", "confidence": 0.946791023015976}]}, {"text": "Firstly, we attempts to develop simple models that do not depend on parsing trees and do not require phrase-level annotation which is too expensive in real-world applications.", "labels": [], "entities": []}, {"text": "Secondly, in order to obtain competitive performance, simple models can benefit from linguistic resources.", "labels": [], "entities": []}, {"text": "Three types of resources will be addressed in this paper: sentiment lexicon, negation words, and intensity words.", "labels": [], "entities": []}, {"text": "Sentiment lexicon offers the prior polarity of a word which can be useful in determining the sentiment polarity of longer texts such as phrases and sentences.", "labels": [], "entities": []}, {"text": "Negators are typical sentiment shifters (), which constantly change the polarity of sentiment expression.", "labels": [], "entities": [{"text": "sentiment shifters", "start_pos": 21, "end_pos": 39, "type": "TASK", "confidence": 0.8475933074951172}]}, {"text": "Intensifiers change the valence degree of the modified text, which is important for fine-grained sentiment classification.", "labels": [], "entities": [{"text": "fine-grained sentiment classification", "start_pos": 84, "end_pos": 121, "type": "TASK", "confidence": 0.7204797565937042}]}, {"text": "In order to model the linguistic role of sentiment, negation, and intensity words, our central idea is to regularize the difference between the predicted sentiment distribution of the current position 1 , and that of the previous or next positions, in a sequence model.", "labels": [], "entities": []}, {"text": "For instance, if the cur-rent position is a negator not, the negator should change the sentiment distribution of the next position accordingly.", "labels": [], "entities": []}, {"text": "To summarize, our contributions lie in two folds: \u2022 We discover that modeling the linguistic role of sentiment, negation, and intensity words can enhance sentence-level sentiment classification.", "labels": [], "entities": [{"text": "sentence-level sentiment classification", "start_pos": 154, "end_pos": 193, "type": "TASK", "confidence": 0.7098514636357626}]}, {"text": "We address the issue by imposing linguistic-inspired regularizers on sequence LSTM models.", "labels": [], "entities": []}, {"text": "\u2022 Unlike previous models that depend on parsing structures and expensive phrase-level annotation, our models are simple and efficient, but the performance is on a par with the stateof-the-art.", "labels": [], "entities": []}, {"text": "The rest of the paper is organized as follows: In the following section, we survey related work.", "labels": [], "entities": []}, {"text": "In Section 3, we briefly introduce the background of LSTM and bidirectional LSTM, and then describe in detail the lingistic regularizers for sentiment/negation/intensity words in Section 4.", "labels": [], "entities": []}, {"text": "Experiments are presented in Section 5, and Conclusion follows in Section 6.", "labels": [], "entities": [{"text": "Conclusion", "start_pos": 44, "end_pos": 54, "type": "METRIC", "confidence": 0.9316266775131226}]}], "datasetContent": [{"text": "Two datasets are used for evaluating the proposed models: Movie Review (MR)) where each sentence is annotated with two classes as negative, positive and Stanford Sentiment Treebank (SST)) with five classes { very negative, negative, neutral, positive, very positive}.", "labels": [], "entities": [{"text": "Stanford Sentiment Treebank (SST))", "start_pos": 153, "end_pos": 187, "type": "DATASET", "confidence": 0.8771697183450063}]}, {"text": "Note that SST has provided phrase-level annotation on all inner nodes, but we only use the sentence-level annotation since one of our goals is to avoid expensive phrase-level annotation.", "labels": [], "entities": []}, {"text": "The sentiment lexicon contains two parts.", "labels": [], "entities": []}, {"text": "The first part comes from MPQA (), which contains 5, 153 sentiment words, each with polarity rating.", "labels": [], "entities": [{"text": "MPQA", "start_pos": 26, "end_pos": 30, "type": "DATASET", "confidence": 0.9203565120697021}]}, {"text": "The second part consists of the leaf nodes of the SST dataset (i.e., all sentiment words) and there are 6, 886 polar words except neural ones.", "labels": [], "entities": [{"text": "SST dataset", "start_pos": 50, "end_pos": 61, "type": "DATASET", "confidence": 0.9007423222064972}]}, {"text": "We combine the two parts and ignore those words that have conflicting sentiment labels, and produce a lexicon of 9, 750 words with 4 sentiment labels.", "labels": [], "entities": []}, {"text": "For negation and intensity words, we collect them manually since the number is small, some of which can be seen in: The data statistics.", "labels": [], "entities": [{"text": "negation and intensity words", "start_pos": 4, "end_pos": 32, "type": "TASK", "confidence": 0.775635614991188}]}, {"text": "In order to let others reproduce our results, we present all the details of our models.", "labels": [], "entities": []}, {"text": "We adopt Glove vectors () as the initial setting of word embeddings V . The shifting vector for each sentiment class (s c ), and the transformation matrices for negation and intensity (T m ) are initialized with a prior value.", "labels": [], "entities": []}, {"text": "The other parameters for hidden layers (W ( * ) , U ( * ) , S) are initialized with U nif orm(0, 1/sqrt(d)), where dis the dimension of hidden representation, and we set d=300.", "labels": [], "entities": []}, {"text": "We adopt adaGrad to train the models, and the learning rate is 0.1.", "labels": [], "entities": [{"text": "learning", "start_pos": 46, "end_pos": 54, "type": "METRIC", "confidence": 0.9761776328086853}]}, {"text": "It's worth noting that, we adopt stochastic gradient descent to update the word embeddings (V ), with a learning rate of 0.2 but without momentum.", "labels": [], "entities": []}, {"text": "The optimal setting for \u03b1 and \u03b2 is 0.5 and 0.0001 respectively.", "labels": [], "entities": []}, {"text": "During training, we adopt the dropout operation before the softmax layer, with a probability of 0.5.", "labels": [], "entities": []}, {"text": "Mini-batch is taken to train the models, each batch containing 25 samples.", "labels": [], "entities": []}, {"text": "After training with 3,000 mini-batch (about 9 epochs on MR and 10 epochs on SST), we choose the results of the model that performs best on the validation dataset as the final performance.", "labels": [], "entities": [{"text": "MR", "start_pos": 56, "end_pos": 58, "type": "DATASET", "confidence": 0.6885995864868164}]}, {"text": "Negation word no, nothing, never, neither, not, seldom, scarcely, etc.", "labels": [], "entities": []}, {"text": "Intensity word terribly, greatly, absolutely, too, very, completely, etc.: Examples of negation and intensity words.", "labels": [], "entities": [{"text": "negation and intensity words", "start_pos": 87, "end_pos": 115, "type": "TASK", "confidence": 0.7303672432899475}]}], "tableCaptions": [{"text": " Table 1: The data statistics.", "labels": [], "entities": []}, {"text": " Table 3: The accuracy on MR and SST. Phrase- level means the models use phrase-level annota- tion for training. And Sent.-level means the mod- els only use sentence-level annotation. Results  marked with * are re-printed from the references,  while those with # are obtained either by our own  implementation or with the same codes shared by  the original authors.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 14, "end_pos": 22, "type": "METRIC", "confidence": 0.9996681213378906}, {"text": "SST", "start_pos": 33, "end_pos": 36, "type": "TASK", "confidence": 0.818702757358551}]}, {"text": " Table 4: The accuracy for LR-Bi-LSTM and LR- LSTM with regularizer ablation. NSR, SR, NR and  IR denotes Non-sentiment Regularizer, Sentiment  Regularizer, Negation Regularizer, and Intensity  Regularizer respectively.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 14, "end_pos": 22, "type": "METRIC", "confidence": 0.9996820688247681}, {"text": "IR", "start_pos": 95, "end_pos": 97, "type": "METRIC", "confidence": 0.9558125138282776}]}, {"text": " Table 5: The accuracy on the negation sub-dataset  (Neg. Sub.) that only contains negators, and in- tensity sub-dataset (Int. Sub.) that only contains  intensifiers.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 14, "end_pos": 22, "type": "METRIC", "confidence": 0.999672532081604}]}]}