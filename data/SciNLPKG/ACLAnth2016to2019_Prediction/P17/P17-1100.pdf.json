{"title": [{"text": "Supervised Learning of Automatic Pyramid for Optimization-Based Multi-Document Summarization", "labels": [], "entities": [{"text": "Optimization-Based Multi-Document Summarization", "start_pos": 45, "end_pos": 92, "type": "TASK", "confidence": 0.5906105637550354}]}], "abstractContent": [{"text": "We present anew supervised framework that learns to estimate automatic Pyramid scores and uses them for optimization-based extractive multi-document summa-rization.", "labels": [], "entities": []}, {"text": "For learning automatic Pyramid scores, we developed a method for automatic training data generation which is based on a genetic algorithm using automatic Pyramid as the fitness function.", "labels": [], "entities": [{"text": "automatic training data generation", "start_pos": 65, "end_pos": 99, "type": "TASK", "confidence": 0.6528855040669441}]}, {"text": "Our experimental evaluation shows that our new framework significantly outperforms strong baselines regarding automatic Pyramid , and that there is much room for improvement in comparison with the upper-bound for automatic Pyramid.", "labels": [], "entities": []}], "introductionContent": [{"text": "We consider extractive text summarization, the task of condensing a textual source, e.g., a set of source documents in multi-document summarization (MDS), into a short summary text.", "labels": [], "entities": [{"text": "extractive text summarization", "start_pos": 12, "end_pos": 41, "type": "TASK", "confidence": 0.6160911917686462}, {"text": "multi-document summarization (MDS)", "start_pos": 119, "end_pos": 153, "type": "TASK", "confidence": 0.7741755962371826}]}, {"text": "The quality of an automatic system summary is traditionally evaluated by comparing it against one or more reference summaries written by humans.", "labels": [], "entities": []}, {"text": "This comparison is performed by means of an evaluation metric measuring indicators of summary quality and combining them into an aggregated score.", "labels": [], "entities": []}, {"text": "Many state-of-the-art summarization systems cast extractive summarization as an optimization problem and maximize an objective function in order to create good, i.e., high-scoring summaries.", "labels": [], "entities": [{"text": "summarization", "start_pos": 22, "end_pos": 35, "type": "TASK", "confidence": 0.9685672521591187}]}, {"text": "To this end, optimization-based systems commonly use an objective function which encodes exactly those quality indicators which are measured by the particular evaluation metric being used.", "labels": [], "entities": []}, {"text": "Some systems even employ an approximation of the evaluation metric as objective function.", "labels": [], "entities": []}, {"text": "Consider as an example the ROUGE metric which has become a de-facto standard for summary evaluation.", "labels": [], "entities": [{"text": "ROUGE", "start_pos": 27, "end_pos": 32, "type": "METRIC", "confidence": 0.9434930682182312}, {"text": "summary evaluation", "start_pos": 81, "end_pos": 99, "type": "TASK", "confidence": 0.863491028547287}]}, {"text": "ROUGE computes the n-gram overlap between a system summary and a pool of reference summaries.", "labels": [], "entities": [{"text": "ROUGE", "start_pos": 0, "end_pos": 5, "type": "METRIC", "confidence": 0.6491419076919556}]}, {"text": "There are several previous approaches which have used an approximation of ROUGE as the optimization objective (e.g.,;).", "labels": [], "entities": [{"text": "ROUGE", "start_pos": 74, "end_pos": 79, "type": "METRIC", "confidence": 0.9503528475761414}]}, {"text": "However, ROUGE has been widely criticized for being too simplistic and not suitable for capturing important quality aspects we are interested in.", "labels": [], "entities": []}, {"text": "In particular, ROUGE does not capture sentences which are semantically equivalent but expressed with different words (.", "labels": [], "entities": []}, {"text": "Ideally, we would like to evaluate our summaries based on human judgments.", "labels": [], "entities": []}, {"text": "A well-known example of such a human evaluation method is the so-called Pyramid method (: it evaluates the particular quality aspect of content selection and is based on a manual comparison of Summary Content Units (SCUs) in reference summaries against SCUs in system summaries.", "labels": [], "entities": []}, {"text": "While the resulting Pyramid score is much more meaningful and informative than ROUGE, it is very expensive to obtain, and -worse -not reproducible.", "labels": [], "entities": [{"text": "ROUGE", "start_pos": 79, "end_pos": 84, "type": "METRIC", "confidence": 0.9844740629196167}]}, {"text": "These issues have been addressed by a line of research aimed at automating the Pyramid evaluation (.", "labels": [], "entities": [{"text": "Pyramid evaluation", "start_pos": 79, "end_pos": 97, "type": "TASK", "confidence": 0.6518439650535583}]}, {"text": "Recently, developed a freely available off-the-shelf system for automatic Pyramid scoring called PEAK, which uses open Information Extraction (open IE) propositions as SCUs and relies on proposition comparison.", "labels": [], "entities": [{"text": "Pyramid scoring", "start_pos": 74, "end_pos": 89, "type": "TASK", "confidence": 0.8441596925258636}, {"text": "PEAK", "start_pos": 97, "end_pos": 101, "type": "METRIC", "confidence": 0.9613268375396729}]}, {"text": "Automatic Pyramid (AP) scores are reproducible, and unlike ROUGE, they are based on semantically motivated content units (SCUs) rather than word n-grams.", "labels": [], "entities": []}, {"text": "Moreover, they correlate better with human judgments than ROUGE (.", "labels": [], "entities": [{"text": "ROUGE", "start_pos": 58, "end_pos": 63, "type": "METRIC", "confidence": 0.9900509715080261}]}, {"text": "Given these recent advances in the automatic evaluation of summaries regarding content selection, we believe that research in optimizationbased summarization should move away from ROUGE towards AP as a more meaningful evaluation metric to approximate and to optimize.", "labels": [], "entities": [{"text": "summaries regarding content selection", "start_pos": 59, "end_pos": 96, "type": "TASK", "confidence": 0.6719337403774261}, {"text": "optimizationbased summarization", "start_pos": 126, "end_pos": 157, "type": "TASK", "confidence": 0.43937861919403076}, {"text": "ROUGE", "start_pos": 180, "end_pos": 185, "type": "METRIC", "confidence": 0.9274356365203857}, {"text": "AP", "start_pos": 194, "end_pos": 196, "type": "METRIC", "confidence": 0.9368475675582886}]}, {"text": "In our work, we are the first to explore this new direction and to systematically investigate the use of AP in optimization-based extractive summarization.", "labels": [], "entities": [{"text": "optimization-based extractive summarization", "start_pos": 111, "end_pos": 154, "type": "TASK", "confidence": 0.44505921999613446}]}, {"text": "We make the following contributions: \u2022 We compute an upper-bound for AP with a Genetic Algorithm (GA), and compare it to the ROUGE upper-bound.", "labels": [], "entities": [{"text": "ROUGE", "start_pos": 125, "end_pos": 130, "type": "METRIC", "confidence": 0.8348855972290039}]}, {"text": "\u2022 We develop anew extractive MDS system specifically optimizing for an approximation of AP.", "labels": [], "entities": [{"text": "AP", "start_pos": 88, "end_pos": 90, "type": "METRIC", "confidence": 0.9227102398872375}]}, {"text": "Our system uses a supervised learning setup to learn an approximation of AP from automatically generated training data.", "labels": [], "entities": []}, {"text": "We constrain the learned approximation of AP to be linear so that we can extract summaries efficiently via Integer Linear Programming (ILP).", "labels": [], "entities": []}, {"text": "Our experimental evaluation shows that our approach significantly outperforms strong baselines on the AP metric.", "labels": [], "entities": [{"text": "AP metric", "start_pos": 102, "end_pos": 111, "type": "DATASET", "confidence": 0.6470955908298492}]}, {"text": "The code both for the new upper-bound and for our ILP is available at github.com/UKPLab/ acl2017-optimize_pyramid.", "labels": [], "entities": [{"text": "UKPLab", "start_pos": 81, "end_pos": 87, "type": "DATASET", "confidence": 0.9687339067459106}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Upper bound comparison between  ROUGE and Automatic Pyramid (AP).", "labels": [], "entities": [{"text": "ROUGE", "start_pos": 42, "end_pos": 47, "type": "METRIC", "confidence": 0.9462819695472717}, {"text": "Automatic Pyramid (AP)", "start_pos": 52, "end_pos": 74, "type": "TASK", "confidence": 0.43440760374069215}]}, {"text": " Table 2: End-to-end evaluation of our approach on  TAC-2009.", "labels": [], "entities": [{"text": "TAC-2009", "start_pos": 52, "end_pos": 60, "type": "DATASET", "confidence": 0.7694252729415894}]}, {"text": " Table 3: Performance of the supervised learn- ing of \u03c0 on TAC-2009 in a leave-one-out cross- validation.", "labels": [], "entities": [{"text": "TAC-2009", "start_pos": 59, "end_pos": 67, "type": "DATASET", "confidence": 0.9325770735740662}]}, {"text": " Table 4: Correlation between ROUGE-1 and  ROUGE-2 with AP on the automatically generated  training data for TAC-2009.", "labels": [], "entities": [{"text": "ROUGE-1", "start_pos": 30, "end_pos": 37, "type": "METRIC", "confidence": 0.8249481320381165}, {"text": "AP", "start_pos": 56, "end_pos": 58, "type": "METRIC", "confidence": 0.9976842403411865}, {"text": "TAC-2009", "start_pos": 109, "end_pos": 117, "type": "DATASET", "confidence": 0.6887961626052856}]}]}