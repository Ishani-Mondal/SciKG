{"title": [{"text": "Accent Adaptation for the Air Traffic Control Domain", "labels": [], "entities": [{"text": "Accent Adaptation", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.928808867931366}, {"text": "Air Traffic Control", "start_pos": 26, "end_pos": 45, "type": "TASK", "confidence": 0.7464118202527364}]}], "abstractContent": [{"text": "Automated speech recognition (ASR) plays a significant role in training and simulation systems for air traffic controllers.", "labels": [], "entities": [{"text": "Automated speech recognition (ASR)", "start_pos": 0, "end_pos": 34, "type": "TASK", "confidence": 0.8477466801802317}]}, {"text": "However, because English is the default language used in air traffic control (ATC), ASR systems often encounter difficulty with speakers' non-native accents, for which there is a paucity of data.", "labels": [], "entities": [{"text": "air traffic control (ATC)", "start_pos": 57, "end_pos": 82, "type": "TASK", "confidence": 0.8011414706707001}, {"text": "ASR", "start_pos": 84, "end_pos": 87, "type": "TASK", "confidence": 0.988444447517395}]}, {"text": "This paper examines the effects of accent adaptation on the recognition of non-native En-glish speech in the ATC domain.", "labels": [], "entities": [{"text": "accent adaptation", "start_pos": 35, "end_pos": 52, "type": "TASK", "confidence": 0.6723148822784424}]}, {"text": "Accent adaptation has been demonstrated to bean effective way to model under-resourced speech, and can be applied to a variety of models.", "labels": [], "entities": [{"text": "Accent adaptation", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.768785685300827}]}, {"text": "We use Subspace Gaus-sian Mixture Models (SGMMs) with the Kaldi Speech Recognition Toolkit to adapt acoustic models from American English to German-accented English, and compare it against other adaptation methods.", "labels": [], "entities": []}, {"text": "Our results provide additional evidence that SGMMs can bean efficient and effective way to approach this problem, particularly with smaller amounts of accented training data.", "labels": [], "entities": []}], "introductionContent": [{"text": "As the field of speech recognition has developed, ASR systems have grown increasingly useful for the ATC domain.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 16, "end_pos": 34, "type": "TASK", "confidence": 0.8114139139652252}, {"text": "ASR", "start_pos": 50, "end_pos": 53, "type": "TASK", "confidence": 0.9921230673789978}, {"text": "ATC domain", "start_pos": 101, "end_pos": 111, "type": "TASK", "confidence": 0.6268557608127594}]}, {"text": "The majority of air traffic communication is verbal, meaning ASR has the potential to bean invaluable tool not just in assisting air traffic controllers in their daily operations, but also for training purposes and workload analysis (.", "labels": [], "entities": [{"text": "air traffic communication", "start_pos": 16, "end_pos": 41, "type": "TASK", "confidence": 0.6521159410476685}, {"text": "ASR", "start_pos": 61, "end_pos": 64, "type": "TASK", "confidence": 0.9649628400802612}]}, {"text": "Due to a constrained grammar and vocabulary, ATC ASR systems have relatively low word error rates (WER) when compared to other domains, such as broadcast news.", "labels": [], "entities": [{"text": "ATC ASR", "start_pos": 45, "end_pos": 52, "type": "TASK", "confidence": 0.8153757452964783}, {"text": "word error rates (WER)", "start_pos": 81, "end_pos": 103, "type": "METRIC", "confidence": 0.9017980595429739}]}, {"text": "These systems can also be limited at run-time by location (e.g. place names, runway designations), further constraining these parameters and increasing accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 152, "end_pos": 160, "type": "METRIC", "confidence": 0.9982314705848694}]}, {"text": "Despite the effectiveness of existing systems, air traffic control has little tolerance for mistakes in day-to-day operations.", "labels": [], "entities": [{"text": "air traffic control", "start_pos": 47, "end_pos": 66, "type": "TASK", "confidence": 0.6414463122685751}]}, {"text": "Furthermore, these systems generally perform worse in real-world conditions, where they have to contend with confounding factors such as noise and speaker accents.", "labels": [], "entities": []}, {"text": "In this paper, we attempt to ameliorate the issue of speaker accents by examining the usefulness of accent adaptation in the ATC domain.", "labels": [], "entities": [{"text": "accent adaptation", "start_pos": 100, "end_pos": 117, "type": "TASK", "confidence": 0.721945121884346}]}, {"text": "We compare the relatively new innovation of SGMMs () against older adaptation techniques, such as maximum a posteriori (MAP) estimation, as well as pooling, a type of multicondition training.", "labels": [], "entities": [{"text": "SGMMs", "start_pos": 44, "end_pos": 49, "type": "TASK", "confidence": 0.927025556564331}, {"text": "maximum a posteriori (MAP) estimation", "start_pos": 98, "end_pos": 135, "type": "METRIC", "confidence": 0.7808618715831211}]}, {"text": "We perform experiments using out-of-domain American English data from the HUB4 Broadcast News Corpus (, as well as German-accented English data taken from the AT-COSIM corpus) and provided by UFA, Inc., a company specializing in ATC training and simulation.", "labels": [], "entities": [{"text": "HUB4 Broadcast News Corpus", "start_pos": 74, "end_pos": 100, "type": "DATASET", "confidence": 0.9531915038824081}, {"text": "AT-COSIM corpus", "start_pos": 159, "end_pos": 174, "type": "DATASET", "confidence": 0.8881880342960358}, {"text": "ATC training", "start_pos": 229, "end_pos": 241, "type": "TASK", "confidence": 0.880862295627594}]}, {"text": "The paper is organized as follows: in Section 2, we describe previous accent adaptation techniques as well as the structure of SGMMs and how they can be adapted on new data.", "labels": [], "entities": [{"text": "accent adaptation", "start_pos": 70, "end_pos": 87, "type": "TASK", "confidence": 0.6943447589874268}]}, {"text": "In Section 3, we outline our experiments and show how accent adaptation with SGMMs outperforms other methods when using smaller amounts of data.", "labels": [], "entities": [{"text": "accent adaptation", "start_pos": 54, "end_pos": 71, "type": "TASK", "confidence": 0.8447562158107758}]}, {"text": "Section 4 concludes the paper and presents paths for future study.", "labels": [], "entities": []}], "datasetContent": [{"text": "All experiments were performed using the Kaldi Speech Recognition Toolkit (Povey et al., 2011b).", "labels": [], "entities": [{"text": "Kaldi Speech Recognition", "start_pos": 41, "end_pos": 65, "type": "TASK", "confidence": 0.5337476134300232}]}, {"text": "The baseline acoustic model was a regular HMM-GMM and was trained with the usual 39 MFCC features, including delta and acceleration features.", "labels": [], "entities": [{"text": "delta", "start_pos": 109, "end_pos": 114, "type": "METRIC", "confidence": 0.9506286978721619}]}, {"text": "Experiments were conducted both with and without pooling the adaptation data with the US English data, since pooling data prior to adaptation has been shown to give better results for both MAP and SGMM maximum likelihood adaptation, as well as for other adaptation techniques).", "labels": [], "entities": [{"text": "US English data", "start_pos": 86, "end_pos": 101, "type": "DATASET", "confidence": 0.6463635762532552}, {"text": "SGMM maximum likelihood adaptation", "start_pos": 197, "end_pos": 231, "type": "TASK", "confidence": 0.5594497993588448}]}, {"text": "We conducted two experiments, each with a different amount of adaptation data.", "labels": [], "entities": []}, {"text": "The first experiment included only a 6.5-hour subset of the total adaptation data, which was created by randomly selecting speakers from both the ATCOSIM corpus and the UFA data.", "labels": [], "entities": [{"text": "ATCOSIM corpus", "start_pos": 146, "end_pos": 160, "type": "DATASET", "confidence": 0.8893904387950897}, {"text": "UFA data", "start_pos": 169, "end_pos": 177, "type": "DATASET", "confidence": 0.8476294577121735}]}, {"text": "The second included all 26 hours of adaptation data.", "labels": [], "entities": [{"text": "adaptation", "start_pos": 36, "end_pos": 46, "type": "TASK", "confidence": 0.9596813321113586}]}, {"text": "HMM-GMM models were adapted using MAP estimation and SGMMs were adapted using the method outlined above.", "labels": [], "entities": [{"text": "MAP estimation", "start_pos": 34, "end_pos": 48, "type": "TASK", "confidence": 0.4239640086889267}]}, {"text": "For each amount of adaptation data, we trained several different models, testing all combinations of the following variables: \u2022 Whether the model was trained solely on the native-accented data, trained solely on the adaptation data, trained on the combined data but not adapted, trained of the native data and then adapted, or trained on the combined data and then adapted.", "labels": [], "entities": []}, {"text": "\u2022 Whether an HMM-GMM or SGMM was used (as well as the corresponding adaptation method).", "labels": [], "entities": []}, {"text": "\u2022 Whether the model was trained with speakerdependent fMLLR transforms.", "labels": [], "entities": []}, {"text": "With 6.5 hours of German accented data, both the MAP-adapted and SGMM-adapted pooled systems saw modest reductions in word error rate, as can be seen in.", "labels": [], "entities": [{"text": "MAP-adapted", "start_pos": 49, "end_pos": 60, "type": "DATASET", "confidence": 0.805046021938324}, {"text": "word error rate", "start_pos": 118, "end_pos": 133, "type": "METRIC", "confidence": 0.6124159793059031}]}, {"text": "MAP adaptation provided a 6.3% relative improvement over the corresponding accented-only model 1 , though WER was reduced by only 2.8% when fMLLR was implemented.", "labels": [], "entities": [{"text": "WER", "start_pos": 106, "end_pos": 109, "type": "METRIC", "confidence": 0.9986648559570312}, {"text": "fMLLR", "start_pos": 140, "end_pos": 145, "type": "DATASET", "confidence": 0.8513820767402649}]}, {"text": "Pooled SGMMs were more versatile and amenable to adaptation, with a relative reduction in WER of 10.6%, and a relative improvement of 6.1% when using fMLLR.", "labels": [], "entities": [{"text": "WER", "start_pos": 90, "end_pos": 93, "type": "METRIC", "confidence": 0.999459445476532}, {"text": "fMLLR", "start_pos": 150, "end_pos": 155, "type": "DATASET", "confidence": 0.8230741024017334}]}, {"text": "Changes in sentence error rate (SER) between models correlated with the changes in WER, reaching a minimum of 22.38% with the adapted SGMM-fMLLR system, a relative reduction of just over 5%.", "labels": [], "entities": [{"text": "sentence error rate (SER)", "start_pos": 11, "end_pos": 36, "type": "METRIC", "confidence": 0.8155235896507899}, {"text": "WER", "start_pos": 83, "end_pos": 86, "type": "METRIC", "confidence": 0.44424739480018616}]}, {"text": "Including the full 26 hours of non-native speech in the training and adaptation data generally resulted in higher error rates in the adapted systems than the corresponding accented-only models, as seen in.", "labels": [], "entities": [{"text": "error", "start_pos": 114, "end_pos": 119, "type": "METRIC", "confidence": 0.9605942964553833}]}, {"text": "This decrease in performance approached 10% for the HMM-GMM systems.", "labels": [], "entities": []}, {"text": "Though the SGMM-fMLLR adapted system experienced a relative reduction in performance of about 4%, the performance of the non-fMLLR SGMM increased by about the same amount.", "labels": [], "entities": []}, {"text": "Changes in SER again correlated with the changes in WER, with the adapted speaker independent SGMM possessing a slight edge (about 1%) over its accented-only counterpart.", "labels": [], "entities": [{"text": "SER", "start_pos": 11, "end_pos": 14, "type": "METRIC", "confidence": 0.9228293299674988}, {"text": "WER", "start_pos": 52, "end_pos": 55, "type": "METRIC", "confidence": 0.8832640647888184}]}, {"text": "It is not clear from this experiment why the speaker independent SGMM system was the only one to undergo an increase in performance when adapted with the full dataset.", "labels": [], "entities": []}, {"text": "A possible explanation is that, with enough data, the speaker adaptive techniques were simply more robust than the accent-adaptation method.", "labels": [], "entities": []}, {"text": "Unsurprisingly, the unadapted native-accented systems had the worst performance out of all of the models, with word error rates that were more than double than that of next best corresponding system.", "labels": [], "entities": [{"text": "word error rates", "start_pos": 111, "end_pos": 127, "type": "METRIC", "confidence": 0.7547227740287781}]}, {"text": "The unadapted pooled models and the adapted native models were usually the second-and thirdworst performing groups of models, though their ranking depended on the amount of adaptation data used.", "labels": [], "entities": []}, {"text": "The pooled models generally gave better results when more adaptation data was provided, while the adapted native models had an advantage with less adaptation data.", "labels": [], "entities": []}, {"text": "Interestingly, fMLLR had relatively little effect when used with the adapted native SGMMs, regardless of the amount of adaptation data used.", "labels": [], "entities": [{"text": "fMLLR", "start_pos": 15, "end_pos": 20, "type": "METRIC", "confidence": 0.4473804533481598}]}, {"text": "WER was reduced by only about 1 to 2% compared to the models' non-fMLLR counterparts.", "labels": [], "entities": [{"text": "WER", "start_pos": 0, "end_pos": 3, "type": "METRIC", "confidence": 0.988051176071167}]}, {"text": "This stands in contrast with the gains that virtually every other model saw with the introduction of fMLLR.", "labels": [], "entities": [{"text": "fMLLR", "start_pos": 101, "end_pos": 106, "type": "DATASET", "confidence": 0.9423485994338989}]}, {"text": "It is not clear why this was the case, though it might relate to some overlap between the SGMM adaptation method and fMLLR.", "labels": [], "entities": [{"text": "SGMM adaptation", "start_pos": 90, "end_pos": 105, "type": "TASK", "confidence": 0.8793370425701141}, {"text": "fMLLR", "start_pos": 117, "end_pos": 122, "type": "DATASET", "confidence": 0.908318281173706}]}, {"text": "While it is possible that training the pooled model with in-domain English speech could increase performance, it seems unlikely that it would be superior to either the accented-only model or the adapted pooled model.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Error rates of different models trained with 6.5 hours of adaptation data.", "labels": [], "entities": [{"text": "Error", "start_pos": 10, "end_pos": 15, "type": "METRIC", "confidence": 0.9770686030387878}]}, {"text": " Table 2: Error rates of different models trained with 26 hours of adaptation data.", "labels": [], "entities": [{"text": "Error", "start_pos": 10, "end_pos": 15, "type": "METRIC", "confidence": 0.9846216440200806}]}]}