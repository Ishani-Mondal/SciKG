{"title": [{"text": "Domain Attention with an Ensemble of Experts", "labels": [], "entities": [{"text": "Domain Attention", "start_pos": 0, "end_pos": 16, "type": "TASK", "confidence": 0.8278846740722656}]}], "abstractContent": [{"text": "An important problem in domain adaptation is to quickly generalize to anew domain with limited supervision given K existing domains.", "labels": [], "entities": [{"text": "domain adaptation", "start_pos": 24, "end_pos": 41, "type": "TASK", "confidence": 0.7775006294250488}]}, {"text": "One approach is to retrain a global model across all K + 1 domains using standard techniques, for instance Daum\u00e9 III (2009).", "labels": [], "entities": [{"text": "Daum\u00e9 III (2009)", "start_pos": 107, "end_pos": 123, "type": "DATASET", "confidence": 0.9101664662361145}]}, {"text": "However, it is desirable to adapt without having to re-estimate a global model from scratch each time anew domain with potentially new intents and slots is added.", "labels": [], "entities": []}, {"text": "We describe a solution based on attending an ensemble of domain experts.", "labels": [], "entities": []}, {"text": "We assume K domain-specific intent and slot models trained on respective domains.", "labels": [], "entities": []}, {"text": "When given domain K + 1, our model uses a weighted combination of the K domain experts' feedback along with its own opinion to make predictions on the new domain.", "labels": [], "entities": []}, {"text": "In experiments, the model significantly outperforms base-lines that do not use domain adaptation and also performs better than the full retraining approach.", "labels": [], "entities": []}], "introductionContent": [{"text": "An important problem in domain adaptation is to quickly generalize to anew domain with limited supervision given K existing domains.", "labels": [], "entities": [{"text": "domain adaptation", "start_pos": 24, "end_pos": 41, "type": "TASK", "confidence": 0.7775006294250488}]}, {"text": "In spoken language understanding, new domains of interest for categorizing user utterances are added on a regular basis . For instance, we may A scenario frequently arising in practice is having a request for creating anew virtual domain targeting a specific application.", "labels": [], "entities": [{"text": "spoken language understanding", "start_pos": 3, "end_pos": 32, "type": "TASK", "confidence": 0.7352630694707235}]}, {"text": "One typical use case is that of building natural language capability through intent and slot modeling (without actually building a domain classifier) targeting a specific application.", "labels": [], "entities": []}, {"text": "add ORDERPIZZA domain and desire a domainspecific intent and semantic slot tagger with a limited amount of training data.", "labels": [], "entities": [{"text": "ORDERPIZZA", "start_pos": 4, "end_pos": 14, "type": "METRIC", "confidence": 0.992598295211792}]}, {"text": "Training only on the target domain fails to utilize the existing resources in other domains that are relevant (e.g., labeled data for PLACES domain with place name, location as the slot types), but naively training on the union of all domains does notwork well since different domains can have widely varying distributions.", "labels": [], "entities": []}, {"text": "Domain adaptation offers a balance between these extremes by using all data but simultaneously distinguishing domain types.", "labels": [], "entities": [{"text": "Domain adaptation", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.8156600296497345}]}, {"text": "A common approach for adapting to anew domain is to retrain a global model across all K + 1 domains using well-known techniques, for example the feature augmentation method of which trains a single model that has one domaininvariant component along with K + 1 domainspecific components each of which is specialized in a particular domain.", "labels": [], "entities": []}, {"text": "While such a global model is effective, it requires re-estimating a model from scratch on all K + 1 domains each time anew domain is added.", "labels": [], "entities": []}, {"text": "This is burdensome particularly in our scenario in which new domains can arise frequently.", "labels": [], "entities": []}, {"text": "In this paper, we present an alternative solution based on attending an ensemble of domain experts.", "labels": [], "entities": []}, {"text": "We assume that we have already trained K domain-specific models on respective domains.", "labels": [], "entities": []}, {"text": "Given anew domain K +1 with a small amount of training data, we train a model on that data alone but queries the K experts as part of the training procedure.", "labels": [], "entities": []}, {"text": "We compute an attention weight for each of these experts and use their combined feedback along with the model's own opinion to make predictions.", "labels": [], "entities": []}, {"text": "This way, the model is able to selectively capitalize on relevant domains much like in standard domain adaptation but without explicitly re-training on all domains together.", "labels": [], "entities": []}, {"text": "In experiments, we show clear gains in a domain adaptation scenario across 7 test domains, yielding average error reductions of 44.97% for intent classification and 32.30% for slot tagging compared to baselines that do not use domain adaptation.", "labels": [], "entities": [{"text": "domain adaptation", "start_pos": 41, "end_pos": 58, "type": "TASK", "confidence": 0.7050890326499939}, {"text": "error reductions", "start_pos": 108, "end_pos": 124, "type": "METRIC", "confidence": 0.977411538362503}, {"text": "intent classification", "start_pos": 139, "end_pos": 160, "type": "TASK", "confidence": 0.764676958322525}, {"text": "slot tagging", "start_pos": 176, "end_pos": 188, "type": "TASK", "confidence": 0.692446380853653}]}, {"text": "Moreover we have higher accuracy than the full re-training approach of, a neural analog of Daum\u00e9 III (2009).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 24, "end_pos": 32, "type": "METRIC", "confidence": 0.9994588494300842}]}], "datasetContent": [{"text": "In this section, we describe the set of experiments conducted to evaluate the performance of our model.", "labels": [], "entities": []}, {"text": "In order to fully assess the contribution of our approach, we also consider several baselines and variants besides our primary expert model.: The overlapping percentage of intent types and slot types with experts or source domains.", "labels": [], "entities": []}, {"text": "\u2022 Multiple source domains: In most previous works, only a pair of domains (source vs. target) have been considered, although they can be easily generalized to K > 2.", "labels": [], "entities": []}, {"text": "Here, we experiment with K = 25 domains shown in.", "labels": [], "entities": []}, {"text": "\u2022 Variant output: Ina typical setting for domain adaptation, the label space is invariant across all domains.", "labels": [], "entities": [{"text": "domain adaptation", "start_pos": 42, "end_pos": 59, "type": "TASK", "confidence": 0.7308982759714127}]}, {"text": "Here, the label space can be different in different domains, which is a more challenging setting.", "labels": [], "entities": []}, {"text": "See for details of this setting.", "labels": [], "entities": []}, {"text": "For this DA scenario, we test whether our approach can effectively make a system to quickly generalize to anew domain with limited supervision given K existing domain experts shown in 3 . In summary, our approach is tested with 7 Microsoft Cortana personal assistant domains across 2 tasks of intent classification and slot tagging.", "labels": [], "entities": [{"text": "DA", "start_pos": 9, "end_pos": 11, "type": "TASK", "confidence": 0.9615975618362427}, {"text": "intent classification", "start_pos": 293, "end_pos": 314, "type": "TASK", "confidence": 0.7513111531734467}, {"text": "slot tagging", "start_pos": 319, "end_pos": 331, "type": "TASK", "confidence": 0.7920268177986145}]}, {"text": "Below shows more detail of our baselines and variants used in our experiments.", "labels": [], "entities": []}, {"text": "Baselines: All models below use same underlying architecture described in Section 3.1 \u2022 TARGET: a model trained on a targeted domain without DA techniques.", "labels": [], "entities": [{"text": "TARGET", "start_pos": 88, "end_pos": 94, "type": "METRIC", "confidence": 0.9887181520462036}]}, {"text": "\u2022 UNION: a model trained on the union of a targeted domain and 25 domain experts.", "labels": [], "entities": [{"text": "UNION", "start_pos": 2, "end_pos": 7, "type": "METRIC", "confidence": 0.5808699727058411}]}, {"text": "\u2022 DA: a neural domain adaptation method of which trains domain specific K LSTMs with a generic LSTM on all domain training data.", "labels": [], "entities": []}, {"text": "Domain Experts (DE) variants: All models below are based on attending on an ensemble of 25 domain experts (DE) described in Section 4.1, where a specific set of intent and slots models are trained for each domain.", "labels": [], "entities": []}, {"text": "We have two feedback from domain experts: (1) feature representation from LSTM, and (2) label embedding from feedfoward described in Section 4.1 and Section 4.2, respectively.", "labels": [], "entities": []}, {"text": "\u2022 DE B : DE without domain attention mechanism.", "labels": [], "entities": [{"text": "DE B", "start_pos": 2, "end_pos": 6, "type": "METRIC", "confidence": 0.8891132473945618}, {"text": "DE", "start_pos": 9, "end_pos": 11, "type": "METRIC", "confidence": 0.8415041565895081}]}, {"text": "It uses the unweighted combination of first feedback from experts like bag-of-word model.", "labels": [], "entities": []}, {"text": "\u2022 DE 1 : DE with domain attention with the weighted combination of the first feedbacks from experts.", "labels": [], "entities": [{"text": "DE", "start_pos": 2, "end_pos": 4, "type": "METRIC", "confidence": 0.9830470681190491}, {"text": "DE", "start_pos": 9, "end_pos": 11, "type": "METRIC", "confidence": 0.9548420310020447}]}, {"text": "\u2022 DE 2 : DE 1 with additional weighted combination of second feedbacks.", "labels": [], "entities": [{"text": "DE", "start_pos": 2, "end_pos": 4, "type": "METRIC", "confidence": 0.9471621513366699}, {"text": "DE", "start_pos": 9, "end_pos": 11, "type": "METRIC", "confidence": 0.9428262710571289}]}, {"text": "\u2022 DE S2 : DE 2 with selected attention mechanism, described in Section 4.2.", "labels": [], "entities": []}, {"text": "In our experiments, all the models were implemented using Dynet ( and were trained using Stochastic Gradient Descent (SGD) with Adam ()-an adaptive learning rate algorithm.", "labels": [], "entities": []}, {"text": "We used the initial learning rate of 4 \u00d7 10 \u22124 and left all the other hyper parameters as suggested in.", "labels": [], "entities": []}, {"text": "Each SGD update was computed without a minibatch with Intel MKL (Math Kernel Library) . We used the dropout regularization) with the keep probability of 0.4 at each LSTM layer.", "labels": [], "entities": [{"text": "keep probability", "start_pos": 133, "end_pos": 149, "type": "METRIC", "confidence": 0.9770604074001312}]}, {"text": "To encode user utterances, we used bidirectional LSTMs (BiLSTMs) at the character level and the word level, along with 25 dimensional character embedding and 100 dimensional word embedding.", "labels": [], "entities": []}, {"text": "The dimension of both the input and output of the character LSTMs were 25, and the dimensions of the input and output of the word LSTMs were 150 5 and 100, respectively.", "labels": [], "entities": []}, {"text": "The dimension of the input and output of the final feedforward network for intent, and slot were 200 and the number of their corresponding task.", "labels": [], "entities": [{"text": "slot", "start_pos": 87, "end_pos": 91, "type": "METRIC", "confidence": 0.9893500208854675}]}, {"text": "Its activation was rectified linear unit (ReLU).", "labels": [], "entities": [{"text": "rectified linear unit (ReLU)", "start_pos": 19, "end_pos": 47, "type": "METRIC", "confidence": 0.9220329423745474}]}, {"text": "To initialize word embedding, we used word embedding trained from ().", "labels": [], "entities": []}, {"text": "In the following sections, we report intent classification results inaccuracy percentage and slot results in F1-score.", "labels": [], "entities": [{"text": "intent classification", "start_pos": 37, "end_pos": 58, "type": "TASK", "confidence": 0.6858783662319183}, {"text": "slot", "start_pos": 93, "end_pos": 97, "type": "METRIC", "confidence": 0.9960221648216248}, {"text": "F1-score", "start_pos": 109, "end_pos": 117, "type": "METRIC", "confidence": 0.998412013053894}]}, {"text": "To compute slot F1-score, we used the standard CoNLL evaluation script", "labels": [], "entities": [{"text": "F1-score", "start_pos": 16, "end_pos": 24, "type": "METRIC", "confidence": 0.9925686717033386}, {"text": "CoNLL evaluation", "start_pos": 47, "end_pos": 63, "type": "DATASET", "confidence": 0.8261058628559113}]}], "tableCaptions": [{"text": " Table 1: The number of intent types (|I|), the num- ber of slot types (|S|), and a short description of  the test domains.", "labels": [], "entities": []}, {"text": " Table 2: The overlapping percentage of intent  types and slot types with experts or source do- mains.", "labels": [], "entities": []}, {"text": " Table 4: Intent classification accuracy (%) and slot tagging F1-score (%) of our baselines and variants of  DE. The numbers in boldface indicate the best performing methods.", "labels": [], "entities": [{"text": "Intent", "start_pos": 10, "end_pos": 16, "type": "METRIC", "confidence": 0.9937148690223694}, {"text": "accuracy", "start_pos": 32, "end_pos": 40, "type": "METRIC", "confidence": 0.8131603598594666}, {"text": "slot tagging", "start_pos": 49, "end_pos": 61, "type": "TASK", "confidence": 0.6882806718349457}, {"text": "F1-score", "start_pos": 62, "end_pos": 70, "type": "METRIC", "confidence": 0.9287301301956177}]}, {"text": " Table 5: Intent classification accuracy with an or- acle expert in the expert pool.", "labels": [], "entities": [{"text": "Intent classification", "start_pos": 10, "end_pos": 31, "type": "TASK", "confidence": 0.7457745671272278}, {"text": "accuracy", "start_pos": 32, "end_pos": 40, "type": "METRIC", "confidence": 0.9433987140655518}]}, {"text": " Table 6: Accuracies of DE S2 using different num- ber of experts.", "labels": [], "entities": [{"text": "Accuracies", "start_pos": 10, "end_pos": 20, "type": "METRIC", "confidence": 0.9806120991706848}]}]}