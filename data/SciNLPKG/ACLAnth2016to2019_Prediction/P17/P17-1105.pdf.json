{"title": [{"text": "Abstract Syntax Networks for Code Generation and Semantic Parsing", "labels": [], "entities": [{"text": "Code Generation", "start_pos": 29, "end_pos": 44, "type": "TASK", "confidence": 0.7556461989879608}, {"text": "Semantic Parsing", "start_pos": 49, "end_pos": 65, "type": "TASK", "confidence": 0.7101974636316299}]}], "abstractContent": [{"text": "Tasks like code generation and semantic parsing require mapping unstructured (or partially structured) inputs to well-formed, executable outputs.", "labels": [], "entities": [{"text": "code generation", "start_pos": 11, "end_pos": 26, "type": "TASK", "confidence": 0.7488555312156677}, {"text": "semantic parsing", "start_pos": 31, "end_pos": 47, "type": "TASK", "confidence": 0.7181219458580017}]}, {"text": "We introduce abstract syntax networks, a modeling framework for these problems.", "labels": [], "entities": []}, {"text": "The outputs are represented as abstract syntax trees (ASTs) and constructed by a decoder with a dynamically-determined modular structure paralleling the structure of the output tree.", "labels": [], "entities": []}, {"text": "On the benchmark HEARTHSTONE dataset for code generation, our model obtains 79.2 BLEU and 22.7% exact match accuracy, compared to previous state-of-the-art values of 67.1 and 6.1%.", "labels": [], "entities": [{"text": "HEARTHSTONE dataset", "start_pos": 17, "end_pos": 36, "type": "DATASET", "confidence": 0.8875229954719543}, {"text": "code generation", "start_pos": 41, "end_pos": 56, "type": "TASK", "confidence": 0.7182254046201706}, {"text": "BLEU", "start_pos": 81, "end_pos": 85, "type": "METRIC", "confidence": 0.9972347617149353}, {"text": "exact match", "start_pos": 96, "end_pos": 107, "type": "METRIC", "confidence": 0.8489313423633575}, {"text": "accuracy", "start_pos": 108, "end_pos": 116, "type": "METRIC", "confidence": 0.6535124182701111}]}, {"text": "Furthermore , we perform competitively on the ATIS, JOBS, and GEO semantic parsing datasets with no task-specific engineering.", "labels": [], "entities": [{"text": "ATIS", "start_pos": 46, "end_pos": 50, "type": "DATASET", "confidence": 0.8839262127876282}, {"text": "JOBS", "start_pos": 52, "end_pos": 56, "type": "DATASET", "confidence": 0.7055435180664062}, {"text": "GEO semantic parsing datasets", "start_pos": 62, "end_pos": 91, "type": "DATASET", "confidence": 0.86841881275177}]}], "introductionContent": [{"text": "Tasks like semantic parsing and code generation are challenging in part because they are structured (the output must be well-formed) but not synchronous (the output structure diverges from the input structure).", "labels": [], "entities": [{"text": "semantic parsing", "start_pos": 11, "end_pos": 27, "type": "TASK", "confidence": 0.734185591340065}, {"text": "code generation", "start_pos": 32, "end_pos": 47, "type": "TASK", "confidence": 0.7176070213317871}]}, {"text": "Sequence-to-sequence models have proven effective for both tasks, using encoder-decoder frameworks to exploit the sequential structure on both the input and output side.", "labels": [], "entities": []}, {"text": "Yet these approaches do not account for much richer structural constraints on outputs-including well-formedness, well-typedness, and executability.", "labels": [], "entities": []}, {"text": "The wellformedness case is of particular interest, since it can readily be enforced by representing outputs as abstract syntax trees (ASTs) (), an approach that can be seen as a much lighter weight * Equal contribution.", "labels": [], "entities": []}, {"text": "show me the fare from ci0 to ci1 lambda $0 e ( exists $1 ( and ( from $1 ci0 ) ( to $1 ci1 ) ( = ( fare $1 ) $0 ) ) ) Figure 2: Example of a query and its logical form from the ATIS dataset.", "labels": [], "entities": [{"text": "ATIS dataset", "start_pos": 177, "end_pos": 189, "type": "DATASET", "confidence": 0.9878392815589905}]}, {"text": "The ci0 and ci1 tokens are entity abstractions introduced in preprocessing).", "labels": [], "entities": []}, {"text": "version of CCG-based semantic parsing.", "labels": [], "entities": [{"text": "CCG-based semantic parsing", "start_pos": 11, "end_pos": 37, "type": "TASK", "confidence": 0.6270927588144938}]}, {"text": "In this work, we introduce abstract syntax networks (ASNs), an extension of the standard encoder-decoder framework utilizing a modular decoder whose submodels are composed to natively generate ASTs in a top-down manner.", "labels": [], "entities": []}, {"text": "The decoding process for any given input follows a dy-namically chosen mutual recursion between the modules, where the structure of the tree being produced mirrors the call graph of the recursion.", "labels": [], "entities": []}, {"text": "We implement this process using a decoder model built of many submodels, each associated with a specific construct in the AST grammar and invoked when that construct is needed in the output tree.", "labels": [], "entities": [{"text": "AST grammar", "start_pos": 122, "end_pos": 133, "type": "TASK", "confidence": 0.7630142271518707}]}, {"text": "As is common with neural approaches to structured prediction, our decoder proceeds greedily and accesses not only a fixed encoding but also an attention-based representation of the input (.", "labels": [], "entities": [{"text": "structured prediction", "start_pos": 39, "end_pos": 60, "type": "TASK", "confidence": 0.7281894683837891}]}, {"text": "Our model significantly outperforms previous architectures for code generation and obtains competitive or state-of-the-art results on a suite of semantic parsing benchmarks.", "labels": [], "entities": [{"text": "code generation", "start_pos": 63, "end_pos": 78, "type": "TASK", "confidence": 0.7964329719543457}, {"text": "semantic parsing", "start_pos": 145, "end_pos": 161, "type": "TASK", "confidence": 0.7387171685695648}]}, {"text": "On the HEARTH-STONE dataset for code generation, we achieve a token BLEU score of 79.2 and an exact match accuracy of 22.7%, greatly improving over the previous best results of 67.1 BLEU and 6.1% exact match (.", "labels": [], "entities": [{"text": "HEARTH-STONE dataset", "start_pos": 7, "end_pos": 27, "type": "DATASET", "confidence": 0.8219911456108093}, {"text": "code generation", "start_pos": 32, "end_pos": 47, "type": "TASK", "confidence": 0.7075468301773071}, {"text": "BLEU score", "start_pos": 68, "end_pos": 78, "type": "METRIC", "confidence": 0.9746678173542023}, {"text": "exact match", "start_pos": 94, "end_pos": 105, "type": "METRIC", "confidence": 0.9459065198898315}, {"text": "accuracy", "start_pos": 106, "end_pos": 114, "type": "METRIC", "confidence": 0.5365803241729736}, {"text": "BLEU", "start_pos": 182, "end_pos": 186, "type": "METRIC", "confidence": 0.9958617091178894}, {"text": "exact match", "start_pos": 196, "end_pos": 207, "type": "METRIC", "confidence": 0.9463215470314026}]}, {"text": "The flexibility of ASNs makes them readily applicable to other tasks with minimal adaptation.", "labels": [], "entities": []}, {"text": "We illustrate this point with a suite of semantic parsing experiments.", "labels": [], "entities": [{"text": "semantic parsing", "start_pos": 41, "end_pos": 57, "type": "TASK", "confidence": 0.7663756012916565}]}, {"text": "On the JOBS dataset, we improve on previous state-of-the-art, achieving 92.9% exact match accuracy as compared to the previous record of 90.7%.", "labels": [], "entities": [{"text": "JOBS dataset", "start_pos": 7, "end_pos": 19, "type": "DATASET", "confidence": 0.9831303060054779}, {"text": "exact match", "start_pos": 78, "end_pos": 89, "type": "METRIC", "confidence": 0.8050190508365631}, {"text": "accuracy", "start_pos": 90, "end_pos": 98, "type": "METRIC", "confidence": 0.8006767630577087}]}, {"text": "Likewise, we perform competitively on the ATIS and GEO datasets, matching or exceeding the exact match reported by, though not quite reaching the records held by the best previous semantic parsing approaches ().", "labels": [], "entities": [{"text": "ATIS", "start_pos": 42, "end_pos": 46, "type": "DATASET", "confidence": 0.8279874324798584}, {"text": "GEO datasets", "start_pos": 51, "end_pos": 63, "type": "DATASET", "confidence": 0.8699009418487549}, {"text": "semantic parsing", "start_pos": 180, "end_pos": 196, "type": "TASK", "confidence": 0.7237594574689865}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Accuracies for the semantic parsing tasks. ASN denotes our abstract syntax network framework.  SUPATT refers to the supervised attention mentioned in Section 3.4.", "labels": [], "entities": [{"text": "Accuracies", "start_pos": 10, "end_pos": 20, "type": "METRIC", "confidence": 0.9569478631019592}, {"text": "semantic parsing tasks", "start_pos": 29, "end_pos": 51, "type": "TASK", "confidence": 0.8033164143562317}]}, {"text": " Table 2: Results for the HEARTHSTONE task. SU- PATT refers to the system with supervised atten- tion mentioned in Section 3.4. LPN refers to the  system of Ling et al. (2016). Our nearest neigh- bor baseline NEAREST follows that of Ling et al.  (2016), though it performs somewhat better; its  nonzero exact match number stems from spurious  repetition in the data.", "labels": [], "entities": [{"text": "SU- PATT", "start_pos": 44, "end_pos": 52, "type": "METRIC", "confidence": 0.6437499026457468}, {"text": "NEAREST", "start_pos": 209, "end_pos": 216, "type": "METRIC", "confidence": 0.4932968020439148}, {"text": "exact match number", "start_pos": 303, "end_pos": 321, "type": "METRIC", "confidence": 0.8869332472483317}]}]}