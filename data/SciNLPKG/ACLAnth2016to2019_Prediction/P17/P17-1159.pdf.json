{"title": [{"text": "Universal Dependencies Parsing for Colloquial Singaporean English", "labels": [], "entities": []}], "abstractContent": [{"text": "Singlish can be interesting to the ACL community both linguistically as a major creole based on English, and compu-tationally for information extraction and sentiment analysis of regional social media.", "labels": [], "entities": [{"text": "information extraction", "start_pos": 130, "end_pos": 152, "type": "TASK", "confidence": 0.8217193186283112}, {"text": "sentiment analysis of regional social media", "start_pos": 157, "end_pos": 200, "type": "TASK", "confidence": 0.8396339118480682}]}, {"text": "We investigate dependency parsing of Singlish by constructing a dependency treebank under the Universal Dependencies scheme, and then training a neural network model by integrating En-glish syntactic knowledge into a state-of-the-art parser trained on the Singlish tree-bank.", "labels": [], "entities": [{"text": "dependency parsing of Singlish", "start_pos": 15, "end_pos": 45, "type": "TASK", "confidence": 0.8370533883571625}]}, {"text": "Results show that English knowledge can lead to 25% relative error reduction , resulting in a parser of 84.47% accuracies.", "labels": [], "entities": [{"text": "relative error reduction", "start_pos": 52, "end_pos": 76, "type": "METRIC", "confidence": 0.7497601310412089}, {"text": "accuracies", "start_pos": 111, "end_pos": 121, "type": "METRIC", "confidence": 0.969736635684967}]}, {"text": "To the best of our knowledge, we are the first to use neural stacking to improve cross-lingual dependency parsing on low-resource languages.", "labels": [], "entities": [{"text": "neural stacking", "start_pos": 54, "end_pos": 69, "type": "TASK", "confidence": 0.7533737123012543}, {"text": "cross-lingual dependency parsing", "start_pos": 81, "end_pos": 113, "type": "TASK", "confidence": 0.7016559839248657}]}, {"text": "We make both our annotation and parser available for further research.", "labels": [], "entities": []}], "introductionContent": [{"text": "Languages evolve temporally and geographically, both in vocabulary as well as in syntactic structures.", "labels": [], "entities": []}, {"text": "When major languages such as English or French are adopted in another culture as the primary language, they often mix with existing languages or dialects in that culture and evolve into a stable language called a creole.", "labels": [], "entities": []}, {"text": "Examples of creoles include the French-based Haitian Creole, and Colloquial Singaporean English (Singlish), an English-based creole.", "labels": [], "entities": []}, {"text": "While the majority of the natural language processing (NLP) research attention has been focused on the major languages, little work has been done on adapting the components to creoles.", "labels": [], "entities": [{"text": "natural language processing (NLP)", "start_pos": 26, "end_pos": 59, "type": "TASK", "confidence": 0.7725786566734314}]}, {"text": "One notable body of work originated from the featured translation task of the EMNLP 2011 Workshop on Statistical Machine Translation (WMT11) to translate Haitian Creole SMS messages sent during the 2010 Haitian earthquake.", "labels": [], "entities": [{"text": "translation task of the EMNLP 2011 Workshop on Statistical Machine Translation (WMT11)", "start_pos": 54, "end_pos": 140, "type": "TASK", "confidence": 0.7311089677470071}, {"text": "translate Haitian Creole SMS messages sent during the 2010 Haitian earthquake", "start_pos": 144, "end_pos": 221, "type": "TASK", "confidence": 0.7768416187979958}]}, {"text": "This work highlights the importance of NLP tools on creoles in crisis situations for emergency relief).", "labels": [], "entities": [{"text": "emergency relief", "start_pos": 85, "end_pos": 101, "type": "TASK", "confidence": 0.8126123249530792}]}, {"text": "Singlish is one of the major languages in Singapore, with borrowed vocabulary and grammars 1 from a number of languages including Malay, Tamil, and Chinese dialects such as Hokkien, Cantonese and Teochew (, and it has been increasingly used in written forms on web media.", "labels": [], "entities": []}, {"text": "Fluent English speakers unfamiliar with Singlish would find the creole hard to comprehend.", "labels": [], "entities": []}, {"text": "Correspondingly, fundamental English NLP components such as POS taggers and dependency parsers perform poorly on such Singlish texts as shown in and 4.", "labels": [], "entities": [{"text": "POS taggers", "start_pos": 60, "end_pos": 71, "type": "TASK", "confidence": 0.6409140080213547}]}, {"text": "For example, adapted the sentiment analysis engine to the Singlish vocabulary, but failed to adapt the parser.", "labels": [], "entities": [{"text": "sentiment analysis engine", "start_pos": 25, "end_pos": 50, "type": "TASK", "confidence": 0.9295679330825806}]}, {"text": "Since dependency parsers are important for tasks such as information extraction and discourse parsing (, this hinders the development of such downstream applications for Singlish in written forms and thus makes it crucial to build a dependency parser that can perform well natively on Singlish.", "labels": [], "entities": [{"text": "dependency parsers", "start_pos": 6, "end_pos": 24, "type": "TASK", "confidence": 0.7409081161022186}, {"text": "information extraction", "start_pos": 57, "end_pos": 79, "type": "TASK", "confidence": 0.800410658121109}, {"text": "discourse parsing", "start_pos": 84, "end_pos": 101, "type": "TASK", "confidence": 0.7109149992465973}]}, {"text": "To address this issue, we start with investigating the linguistic characteristics of Singlish and specifically the causes of difficulties for understanding Singlish with English syntax.", "labels": [], "entities": []}, {"text": "We found that, despite the obvious attribute of inheriting a large portion of basic vocabularies and grammars from English, Singlish not only imports terms from regional languages and dialects, its lexical  semantics and syntax also deviate significantly from English ().", "labels": [], "entities": []}, {"text": "We categorize the challenges and formalize their interpretation using Universal Dependencies (, which extends to the creation of a Singlish dependency treebank with 1,200 sentences.", "labels": [], "entities": []}, {"text": "Based on the intricate relationship between Singlish and English, we build a Singlish parser by leveraging knowledge of English syntax as a basis.", "labels": [], "entities": []}, {"text": "This overall approach is illustrated in.", "labels": [], "entities": []}, {"text": "In particular, we train a basic Singlish parser with the best off-the-shelf neural dependency parsing model using biaffine attention, and improve it with knowledge transfer by adopting neural stacking ( to integrate the English syntax.", "labels": [], "entities": [{"text": "Singlish parser", "start_pos": 32, "end_pos": 47, "type": "TASK", "confidence": 0.6173611283302307}, {"text": "neural dependency parsing", "start_pos": 76, "end_pos": 101, "type": "TASK", "confidence": 0.7687607407569885}]}, {"text": "Since POS tags are important features for dependency parsing, we train a POS tagger for Singlish following the same idea by integrating English POS knowledge using neural stacking.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 42, "end_pos": 60, "type": "TASK", "confidence": 0.8302200436592102}]}, {"text": "Results show that English syntax knowledge brings 51.50% and 25.01% relative error reduction on POS tagging and dependency parsing respectively, resulting in a Singlish dependency parser with 84.47% unlabeled attachment score (UAS) and 77.76% labeled attachment score (LAS).", "labels": [], "entities": [{"text": "relative error reduction", "start_pos": 68, "end_pos": 92, "type": "METRIC", "confidence": 0.7644690076510111}, {"text": "POS tagging", "start_pos": 96, "end_pos": 107, "type": "TASK", "confidence": 0.8020052313804626}, {"text": "dependency parsing", "start_pos": 112, "end_pos": 130, "type": "TASK", "confidence": 0.7507831454277039}, {"text": "Singlish dependency parser", "start_pos": 160, "end_pos": 186, "type": "TASK", "confidence": 0.5403715570767721}, {"text": "unlabeled attachment score (UAS)", "start_pos": 199, "end_pos": 231, "type": "METRIC", "confidence": 0.8214903275171915}, {"text": "labeled attachment score (LAS)", "start_pos": 243, "end_pos": 273, "type": "METRIC", "confidence": 0.9326829314231873}]}, {"text": "We make our Singlish dependency treebank, the source code for training a dependency parser and the trained model for the parser with the best performance freely available online 2 .", "labels": [], "entities": [{"text": "Singlish dependency treebank", "start_pos": 12, "end_pos": 40, "type": "DATASET", "confidence": 0.7381115953127543}]}], "datasetContent": [{"text": "We train an English parser on UD-Eng with the default model settings in, and the main difference is caused by us not using fine-grained POS tags.", "labels": [], "entities": []}, {"text": "We apply the same settings fora baseline Singlish parser.", "labels": [], "entities": []}, {"text": "We attempt to choose a better configuration of the number of bi-LSTM layers and the hidden dimension based on the development set performance, but the default settings turnout to perform the best.", "labels": [], "entities": []}, {"text": "Thus we stick to all default hyper-parameters in Dozat and Manning (2017) for training the Singlish parsers.", "labels": [], "entities": []}, {"text": "We experimented with different word embeddings, as with the raw text sources summarized in and further described in section 6.2.", "labels": [], "entities": []}, {"text": "When using the neural stacking model, we fix the model configuration for the base English parser model and choose the size of the hidden vector and the number of bi-LSTM layers stacked on top based on the performance on the development set.", "labels": [], "entities": [{"text": "neural stacking", "start_pos": 15, "end_pos": 30, "type": "TASK", "confidence": 0.7617296278476715}]}, {"text": "It turns out that a 1-layer bi-LSTM with 900 hidden dimension performs the best, where the bigger hidden layer accommodates the elongated input vector to the stacked bi-LSTM and the fewer number of recurrent layers avoids over-fitting on the small Singlish dependency treebank, given the deep bi-LSTM English parser network at the bottom.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Division of training, development, and  test sets for Singlish Treebank", "labels": [], "entities": [{"text": "Singlish Treebank", "start_pos": 64, "end_pos": 81, "type": "DATASET", "confidence": 0.8169550597667694}]}, {"text": " Table 2: POS tagging accuracies", "labels": [], "entities": [{"text": "POS tagging accuracies", "start_pos": 10, "end_pos": 32, "type": "TASK", "confidence": 0.6371731956799825}]}, {"text": " Table 3: Comparison of the scale of sources for  training word embeddings", "labels": [], "entities": []}, {"text": " Table 4: Dependency parser performances", "labels": [], "entities": [{"text": "Dependency parser", "start_pos": 10, "end_pos": 27, "type": "TASK", "confidence": 0.7516924738883972}]}, {"text": " Table 5: Dependency parser performances by the  5-cross-fold validation", "labels": [], "entities": [{"text": "Dependency parser", "start_pos": 10, "end_pos": 27, "type": "TASK", "confidence": 0.8464180827140808}]}]}