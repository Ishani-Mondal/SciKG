{"title": [{"text": "Bandit Structured Prediction for Neural Sequence-to-Sequence Learning", "labels": [], "entities": [{"text": "Neural Sequence-to-Sequence Learning", "start_pos": 33, "end_pos": 69, "type": "TASK", "confidence": 0.7361960013707479}]}], "abstractContent": [{"text": "Bandit structured prediction describes a stochastic optimization framework where learning is performed from partial feedback.", "labels": [], "entities": [{"text": "Bandit structured prediction", "start_pos": 0, "end_pos": 28, "type": "TASK", "confidence": 0.7087780634562174}]}, {"text": "This feedback is received in the form of a task loss evaluation to a predicted output structure, without having access to gold standard structures.", "labels": [], "entities": []}, {"text": "We advance this framework by lifting linear bandit learning to neural sequence-to-sequence learning problems using attention-based recurrent neural networks.", "labels": [], "entities": []}, {"text": "Furthermore, we show how to incorporate control variates into our learning algorithms for variance reduction and improved generalization.", "labels": [], "entities": [{"text": "variance reduction", "start_pos": 90, "end_pos": 108, "type": "TASK", "confidence": 0.828946590423584}]}, {"text": "We present an evaluation on a neural machine translation task that shows improvements of up to 5.89 BLEU points for domain adaptation from simulated bandit feedback.", "labels": [], "entities": [{"text": "neural machine translation task", "start_pos": 30, "end_pos": 61, "type": "TASK", "confidence": 0.774105429649353}, {"text": "BLEU", "start_pos": 100, "end_pos": 104, "type": "METRIC", "confidence": 0.9992631077766418}, {"text": "domain adaptation", "start_pos": 116, "end_pos": 133, "type": "TASK", "confidence": 0.7014937996864319}]}], "introductionContent": [{"text": "Many NLP tasks involve learning to predict a structured output such as a sequence, a tree or a graph.", "labels": [], "entities": []}, {"text": "Sequence-to-sequence learning with neural networks has recently become a popular approach that allows tackling structured prediction as a mapping problem between variable-length sequences, e.g., from foreign language sentences into target-language sentences ), or from natural language input sentences into linearized versions of syntactic ( or semantic parses.", "labels": [], "entities": [{"text": "Sequence-to-sequence learning", "start_pos": 0, "end_pos": 29, "type": "TASK", "confidence": 0.8652185797691345}, {"text": "structured prediction", "start_pos": 111, "end_pos": 132, "type": "TASK", "confidence": 0.7131202220916748}]}, {"text": "A known bottleneck in structured prediction is the requirement of large amounts of gold-standard structures for supervised learning of model parameters, especially for data-hungry neural network models.", "labels": [], "entities": [{"text": "structured prediction", "start_pos": 22, "end_pos": 43, "type": "TASK", "confidence": 0.8067605793476105}]}, {"text": "presented a framework for stochastic structured prediction under bandit feedback that alleviates the need for labeled output structures in learning: Following an online learning protocol, on each iteration the learner receives an input, predicts an output structure, and receives partial feedback inform of a task loss evaluation of the predicted structure.", "labels": [], "entities": [{"text": "stochastic structured prediction", "start_pos": 26, "end_pos": 58, "type": "TASK", "confidence": 0.6580546200275421}]}, {"text": "They \"banditize\" several objective functions for linear structured predictions, and evaluate the resulting algorithms with simulated bandit feedback on various NLP tasks.", "labels": [], "entities": []}, {"text": "We show how to lift linear structured prediction under bandit feedback to non-linear models for sequence-to-sequence learning with attentionbased recurrent neural networks (.", "labels": [], "entities": [{"text": "linear structured prediction", "start_pos": 20, "end_pos": 48, "type": "TASK", "confidence": 0.7179005742073059}]}, {"text": "Our framework is applicable to sequenceto-sequence learning from various types of weak feedback.", "labels": [], "entities": []}, {"text": "For example, extracting learning signals from the execution of structured outputs against databases has been established in the communities of semantic parsing and grounded language learning since more than a decade).", "labels": [], "entities": [{"text": "extracting learning signals from the execution of structured outputs against databases", "start_pos": 13, "end_pos": 99, "type": "TASK", "confidence": 0.789550857110457}, {"text": "semantic parsing", "start_pos": 143, "end_pos": 159, "type": "TASK", "confidence": 0.7275236397981644}]}, {"text": "Our work can build the basis for neural semantic parsing from weak feedback.", "labels": [], "entities": [{"text": "neural semantic parsing", "start_pos": 33, "end_pos": 56, "type": "TASK", "confidence": 0.6817190051078796}]}, {"text": "In this paper, we focus on the application of machine translation via neural sequence-to-sequence learning.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 46, "end_pos": 65, "type": "TASK", "confidence": 0.7775120437145233}]}, {"text": "The standard procedure of training neural machine translation (NMT) models is to compare their output to human-generated translations and to infer model updates from this comparison.", "labels": [], "entities": [{"text": "training neural machine translation (NMT)", "start_pos": 26, "end_pos": 67, "type": "TASK", "confidence": 0.7748336025646755}]}, {"text": "However, the creation of reference translations or post-edits requires professional expertise of users.", "labels": [], "entities": []}, {"text": "Our framework allows NMT models to learn from feedback that is weaker than human references or post-edits.", "labels": [], "entities": []}, {"text": "One could imagine a scenario of personalized machine translation where translations have to be adapted to the user's specific purpose and domain.", "labels": [], "entities": [{"text": "personalized machine translation", "start_pos": 32, "end_pos": 64, "type": "TASK", "confidence": 0.6185517211755117}]}, {"text": "The feedback required by our methods can be provided by laymen users or can even be implicit, e.g., inferred from user interactions with the translated content on a web page.", "labels": [], "entities": []}, {"text": "Starting from the work of, we lift their objectives to neural sequence-to-sequence learning.", "labels": [], "entities": []}, {"text": "We evaluate the resulting algorithms on the task of French-toEnglish translation domain adaptation where a seed model trained on Europarl data is adapted to the NewsCommentary and the TED talks domain with simulated weak feedback.", "labels": [], "entities": [{"text": "French-toEnglish translation domain adaptation", "start_pos": 52, "end_pos": 98, "type": "TASK", "confidence": 0.6716329827904701}, {"text": "Europarl data", "start_pos": 129, "end_pos": 142, "type": "DATASET", "confidence": 0.992368757724762}, {"text": "NewsCommentary", "start_pos": 161, "end_pos": 175, "type": "DATASET", "confidence": 0.9814074635505676}, {"text": "TED talks domain", "start_pos": 184, "end_pos": 200, "type": "DATASET", "confidence": 0.8236733476320902}]}, {"text": "By learning from this feedback, we find 4.08 BLEU points improvements on NewsCommentary, and 5.89 BLEU points improvement on TED.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 45, "end_pos": 49, "type": "METRIC", "confidence": 0.999609649181366}, {"text": "NewsCommentary", "start_pos": 73, "end_pos": 87, "type": "DATASET", "confidence": 0.9722046852111816}, {"text": "BLEU", "start_pos": 98, "end_pos": 102, "type": "METRIC", "confidence": 0.9994266033172607}, {"text": "TED", "start_pos": 125, "end_pos": 128, "type": "DATASET", "confidence": 0.8662155270576477}]}, {"text": "Furthermore, we show how control variates can be integrated in our algorithms, yielding faster learning and improved generalization in our experiments.", "labels": [], "entities": []}], "datasetContent": [{"text": "In the following, we present an experimental evaluation of the learning objectives presented above on machine translation domain adaptation.", "labels": [], "entities": [{"text": "machine translation domain adaptation", "start_pos": 102, "end_pos": 139, "type": "TASK", "confidence": 0.8374247699975967}]}, {"text": "We compare how the presented neural bandit learning objectives perform in comparison to linear models, then discuss the handling of unknown words and eventually investigate the impact of techniques for variance reduction.", "labels": [], "entities": [{"text": "variance reduction", "start_pos": 202, "end_pos": 220, "type": "TASK", "confidence": 0.7669463455677032}]}], "tableCaptions": [{"text": " Table 1: Number of parallel sentences for train- ing, validation and test sets for French-to-English  domain adaptation.", "labels": [], "entities": [{"text": "train- ing", "start_pos": 43, "end_pos": 53, "type": "TASK", "confidence": 0.6367949148019155}, {"text": "French-to-English  domain adaptation", "start_pos": 84, "end_pos": 120, "type": "TASK", "confidence": 0.548174649477005}]}, {"text": " Table 2: Out-of-domain NMT baseline results  (BLEU) on in-and out-of-domain test sets trained  only on EP data.", "labels": [], "entities": [{"text": "Out-of-domain NMT baseline results  (BLEU)", "start_pos": 10, "end_pos": 52, "type": "METRIC", "confidence": 0.566556202513831}]}, {"text": " Table 3: In-domain NMT baselines results  (BLEU) on in-and out-of-domain test sets. The  EP\u2192NC is first trained on EP, then fine-tuned on  NC. The EP\u2192TED is first trained on EP, then fine- tuned on TED.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 44, "end_pos": 48, "type": "METRIC", "confidence": 0.9871212840080261}]}, {"text": " Table 4: Bandit NMT results (BLEU) on EP, NC and TED test sets. UNK* models involve UNK  replacement only during testing, UNK** include UNK replacement already during training. For PR,  either binary (bin) or continuous feedback (cont) was used. Control variates: average reward baseline  (BL) and score function (SF). Results are averaged over two independent runs and standard deviation is  given in subscripts. Improvements over respective out-of-domain models are given in the Diff.-columns.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 30, "end_pos": 34, "type": "METRIC", "confidence": 0.9741232991218567}, {"text": "EP, NC and TED test sets", "start_pos": 39, "end_pos": 63, "type": "DATASET", "confidence": 0.6614136270114354}, {"text": "average reward baseline  (BL)", "start_pos": 265, "end_pos": 294, "type": "METRIC", "confidence": 0.8371302088101705}, {"text": "score function (SF)", "start_pos": 299, "end_pos": 318, "type": "METRIC", "confidence": 0.8670154094696045}]}]}