{"title": [{"text": "Semi-Supervised QA with Generative Domain-Adaptive Nets", "labels": [], "entities": []}], "abstractContent": [{"text": "We study the problem of semi-supervised question answering-utilizing unlabeled text to boost the performance of question answering models.", "labels": [], "entities": [{"text": "question answering-utilizing unlabeled text", "start_pos": 40, "end_pos": 83, "type": "TASK", "confidence": 0.8039179518818855}, {"text": "question answering", "start_pos": 112, "end_pos": 130, "type": "TASK", "confidence": 0.7342703342437744}]}, {"text": "We propose a novel training framework, the Generative Domain-Adaptive Nets.", "labels": [], "entities": []}, {"text": "In this framework, we train a generative model to generate questions based on the unlabeled text, and combine model-generated questions with human-generated questions for training question answering models.", "labels": [], "entities": [{"text": "question answering", "start_pos": 180, "end_pos": 198, "type": "TASK", "confidence": 0.7241978049278259}]}, {"text": "We develop novel domain adaptation algorithms, based on reinforcement learning, to alleviate the discrepancy between the model-generated data distribution and the human-generated data distribution.", "labels": [], "entities": [{"text": "domain adaptation", "start_pos": 17, "end_pos": 34, "type": "TASK", "confidence": 0.7302795350551605}]}, {"text": "Experiments show that our proposed framework obtains substantial improvement from unlabeled text.", "labels": [], "entities": []}], "introductionContent": [{"text": "Recently, various neural network models were proposed and successfully applied to the tasks of questions answering (QA) and/or reading comprehension (.", "labels": [], "entities": [{"text": "questions answering (QA)", "start_pos": 95, "end_pos": 119, "type": "TASK", "confidence": 0.7842784464359284}]}, {"text": "While achieving stateof-the-art performance, these models rely on a large amount of labeled data.", "labels": [], "entities": []}, {"text": "However, it is extremely difficult to collect large-scale question answering datasets.", "labels": [], "entities": [{"text": "question answering", "start_pos": 58, "end_pos": 76, "type": "TASK", "confidence": 0.7495932281017303}]}, {"text": "Historically, many of the question answering datasets have only thousands of question answering pairs, such as WebQuestions (), MCTest (), WikiQA (, and TREC-QA).", "labels": [], "entities": [{"text": "question answering", "start_pos": 26, "end_pos": 44, "type": "TASK", "confidence": 0.817083477973938}, {"text": "MCTest", "start_pos": 128, "end_pos": 134, "type": "DATASET", "confidence": 0.8661807179450989}]}, {"text": "Although larger question answering datasets with hundreds of thousands of question-answer pairs have been collected, including), MSMARCO (, and NewsQA (), the data collection process is expensive and time-consuming in practice.", "labels": [], "entities": [{"text": "question answering", "start_pos": 16, "end_pos": 34, "type": "TASK", "confidence": 0.7434205710887909}, {"text": "MSMARCO", "start_pos": 129, "end_pos": 136, "type": "DATASET", "confidence": 0.9060971140861511}, {"text": "NewsQA", "start_pos": 144, "end_pos": 150, "type": "DATASET", "confidence": 0.9765316247940063}]}, {"text": "This hinders real-world applications for domain-specific question answering.", "labels": [], "entities": [{"text": "question answering", "start_pos": 57, "end_pos": 75, "type": "TASK", "confidence": 0.7474913001060486}]}, {"text": "Compared to obtaining labeled question answer pairs, it is trivial to obtain unlabeled text data.", "labels": [], "entities": []}, {"text": "In this work, we study the following problem of semi-supervised question answering: is it possible to leverage unlabeled text to boost the performance of question answering models, especially when only a small amount of labeled data is available?", "labels": [], "entities": [{"text": "question answering", "start_pos": 64, "end_pos": 82, "type": "TASK", "confidence": 0.7547528743743896}, {"text": "question answering", "start_pos": 154, "end_pos": 172, "type": "TASK", "confidence": 0.7764411866664886}]}, {"text": "The problem is challenging because conventional manifold-based semi-supervised learning algorithms () cannot be straightforwardly applied.", "labels": [], "entities": []}, {"text": "Moreover, since the main foci of most question answering tasks are extraction rather than generation, it is also not sensible to use unlabeled text to improve language modeling as in machine translation (.", "labels": [], "entities": [{"text": "question answering tasks", "start_pos": 38, "end_pos": 62, "type": "TASK", "confidence": 0.8259511788686117}, {"text": "machine translation", "start_pos": 183, "end_pos": 202, "type": "TASK", "confidence": 0.7296812236309052}]}, {"text": "To better leverage the unlabeled text, we propose a novel neural framework called Generative Domain-Adaptive Nets (GDANs).", "labels": [], "entities": []}, {"text": "The starting point of our framework is to use linguistic tags to extract possible answer chunks in the unlabeled text, and then train a generative model to generate questions given the answer chunks and their contexts.", "labels": [], "entities": []}, {"text": "The model-generated questionanswer pairs and the human-generated questionanswer pairs can then be combined to train a question answering model, referred to as a discriminative model in the following text.", "labels": [], "entities": [{"text": "question answering", "start_pos": 118, "end_pos": 136, "type": "TASK", "confidence": 0.6919521391391754}]}, {"text": "However, there is discrepancy between the model-generated data distribution and the human-generated data distribution, which leads to suboptimal discriminative models.", "labels": [], "entities": []}, {"text": "To address this issue, we further propose two domain adaptation techniques that treat the model-generated data distribution as a different domain.", "labels": [], "entities": [{"text": "domain adaptation", "start_pos": 46, "end_pos": 63, "type": "TASK", "confidence": 0.7519837319850922}]}, {"text": "First, we use an additional domain tag to indicate whether a question-answer pair is modelgenerated or human-generated.", "labels": [], "entities": []}, {"text": "We condition the discriminative model on the domain tags so that the discriminative model can learn to factor out domain-specific and domain-invariant representations.", "labels": [], "entities": []}, {"text": "Second, we employ a reinforcement learning algorithm to fine-tune the generative model to minimize the loss of the discriminative model in an adversarial way.", "labels": [], "entities": []}, {"text": "In addition, we present a simple and effective baseline method for semi-supervised question answering.", "labels": [], "entities": [{"text": "question answering", "start_pos": 83, "end_pos": 101, "type": "TASK", "confidence": 0.6927736103534698}]}, {"text": "Although the baseline method performs worse than our GDAN approach, it is extremely easy to implement and can still lead to substantial improvement when only limited labeled data is available.", "labels": [], "entities": []}, {"text": "We experiment on the SQuAD dataset) with various labeling rates and various amounts of unlabeled data.", "labels": [], "entities": [{"text": "SQuAD dataset", "start_pos": 21, "end_pos": 34, "type": "DATASET", "confidence": 0.8498935997486115}]}, {"text": "Experimental results show that our GDAN framework consistently improves over both the supervised learning setting and the baseline methods, including adversarial domain adaptation () and dual learning ( . More specifically, the GDAN model improves the F1 score by 9.87 points in F1 over the supervised learning setting when 8K labeled question-answer pairs are used.", "labels": [], "entities": [{"text": "F1 score", "start_pos": 252, "end_pos": 260, "type": "METRIC", "confidence": 0.9866226613521576}, {"text": "F1", "start_pos": 279, "end_pos": 281, "type": "METRIC", "confidence": 0.9979745745658875}]}, {"text": "First, different from most of the previous neural network studies on question answering, we study a critical but challenging problem, semi-supervised question answering.", "labels": [], "entities": [{"text": "question answering", "start_pos": 69, "end_pos": 87, "type": "TASK", "confidence": 0.8751456439495087}, {"text": "question answering", "start_pos": 150, "end_pos": 168, "type": "TASK", "confidence": 0.7094049155712128}]}, {"text": "Second, we propose the Generative Domain-Adaptive Nets that employ domain adaptation techniques on generative models with reinforcement learning algorithms.", "labels": [], "entities": []}, {"text": "Third, we introduce a simple and effective baseline method.", "labels": [], "entities": []}, {"text": "Fourth, we empirically show that our framework leads to substantial improvements.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 2: Performance with various labeling rates, unlabeled data sizes |U |, and methods. \"Dev\" denotes the development", "labels": [], "entities": []}]}