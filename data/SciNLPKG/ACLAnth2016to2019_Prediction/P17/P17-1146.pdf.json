{"title": [{"text": "Neural Modeling of Multi-Predicate Interactions for Japanese Predicate Argument Structure Analysis", "labels": [], "entities": [{"text": "Neural Modeling of Multi-Predicate Interactions", "start_pos": 0, "end_pos": 47, "type": "TASK", "confidence": 0.8182615041732788}, {"text": "Japanese Predicate Argument Structure Analysis", "start_pos": 52, "end_pos": 98, "type": "TASK", "confidence": 0.6120463609695435}]}], "abstractContent": [{"text": "The performance of Japanese predicate argument structure (PAS) analysis has improved in recent years thanks to the joint modeling of interactions between multiple predicates.", "labels": [], "entities": [{"text": "Japanese predicate argument structure (PAS) analysis", "start_pos": 19, "end_pos": 71, "type": "TASK", "confidence": 0.7594165988266468}]}, {"text": "However, this approach relies heavily on syntactic information predicted by parsers, and suffers from error propagation.", "labels": [], "entities": []}, {"text": "To remedy this problem, we introduce a model that uses grid-type recurrent neural networks.", "labels": [], "entities": []}, {"text": "The proposed model automatically induces features sensitive to multi-predicate interactions from the word sequence information of a sentence.", "labels": [], "entities": []}, {"text": "Experiments on the NAIST Text Corpus demonstrate that without syntactic information, our model outperforms previous syntax-dependent models.", "labels": [], "entities": [{"text": "NAIST Text Corpus", "start_pos": 19, "end_pos": 36, "type": "DATASET", "confidence": 0.9771409829457601}]}], "introductionContent": [{"text": "Predicate argument structure (PAS) analysis is a basic semantic analysis task, in which systems are required to identify the semantic units of a sentence, such as who did what to whom.", "labels": [], "entities": [{"text": "Predicate argument structure (PAS) analysis", "start_pos": 0, "end_pos": 43, "type": "TASK", "confidence": 0.822365015745163}, {"text": "semantic analysis task", "start_pos": 55, "end_pos": 77, "type": "TASK", "confidence": 0.7681870957215627}]}, {"text": "In prodrop languages such as Japanese, Chinese and Italian, arguments are often omitted in text, and such argument omission is regarded as one of the most problematic issues facing PAS analysis (.", "labels": [], "entities": [{"text": "PAS analysis", "start_pos": 181, "end_pos": 193, "type": "TASK", "confidence": 0.9599241316318512}]}, {"text": "In response to the argument omission problem, in Japanese PAS analysis, a joint model of the interactions between multiple predicates has been gaining popularity and achieved the state-ofthe-art results (.", "labels": [], "entities": [{"text": "PAS analysis", "start_pos": 58, "end_pos": 70, "type": "TASK", "confidence": 0.895075112581253}]}, {"text": "This approach is based on the linguistic intuition that the predicates in a sentence are semantically related to each other, and capturing this relation can be useful for PAS analysis.", "labels": [], "entities": [{"text": "PAS analysis", "start_pos": 171, "end_pos": 183, "type": "TASK", "confidence": 0.9797495901584625}]}, {"text": "In the exam-: Example of Japanese PAS.", "labels": [], "entities": [{"text": "Japanese", "start_pos": 25, "end_pos": 33, "type": "DATASET", "confidence": 0.5076828598976135}, {"text": "PAS", "start_pos": 34, "end_pos": 37, "type": "METRIC", "confidence": 0.7910739779472351}]}, {"text": "The upper edges denote dependency relations, and the lower edges denote case arguments.", "labels": [], "entities": []}, {"text": "\"NOM\" and \"ACC\" denote the nominative and accusative arguments, respectively.", "labels": [], "entities": [{"text": "ACC", "start_pos": 11, "end_pos": 14, "type": "METRIC", "confidence": 0.9360260963439941}]}, {"text": "\"\u03d5 i \" is a zero pronoun, referring to the antecedent \" i (man i )\".", "labels": [], "entities": []}, {"text": "ple sentence in, the word \" i (man i )\" is the accusative argument of the predicate \" (arrested)\" and is shared by the other predicate \" (escaped)\" as its nominative argument.", "labels": [], "entities": []}, {"text": "Considering the semantic relation between \" (arrested)\" and \" (escaped)\", we intuitively know that the person arrested by someone is likely to be the escaper.", "labels": [], "entities": []}, {"text": "That is, information about one predicate-argument relation could help to identify another predicate-argument relation.", "labels": [], "entities": []}, {"text": "However, to model such multi-predicate interactions, the joint approach in the previous studies relies heavily on syntactic information, such as part-of-speech (POS) tags and dependency relations predicted by POS taggers and syntactic parsers.", "labels": [], "entities": []}, {"text": "Consequently, it suffers from error propagation caused by pipeline processing.", "labels": [], "entities": []}, {"text": "To remedy this problem, we propose a neural model which automatically induces features sensitive to multi-predicate interactions exclusively from the word sequence information of a sentence.", "labels": [], "entities": []}, {"text": "The proposed model takes as input all predicates and their argument candidates in a sentence at a time, and captures the interactions using gridtype recurrent neural networks (Grid-RNN) without syntactic information.", "labels": [], "entities": []}, {"text": "In this paper, we first introduce a basic model that uses RNNs.", "labels": [], "entities": []}, {"text": "This model independently estimates the arguments of each predicate without considering multi-predicate interactions (Sec. 3).", "labels": [], "entities": []}, {"text": "Then, extending this model, we propose a neural model that uses.", "labels": [], "entities": []}, {"text": "Performing experiments on the NAIST Text Corpus (, we demonstrate that even without syntactic information, our neural models outperform previous syntax-dependent models ().", "labels": [], "entities": [{"text": "NAIST Text Corpus", "start_pos": 30, "end_pos": 47, "type": "DATASET", "confidence": 0.9769839445749918}]}, {"text": "In particular, the neural model using Grid-RNNs achieved the best result.", "labels": [], "entities": []}, {"text": "This suggests that the proposed grid-type neural architecture effectively captures multi-predicate interactions and contributes to performance improvements.", "labels": [], "entities": []}], "datasetContent": [{"text": "We used the NAIST Text Corpus 1.5, which consists of 40,000 sentences from Japanese newspapers (.", "labels": [], "entities": [{"text": "NAIST Text Corpus 1.5", "start_pos": 12, "end_pos": 33, "type": "DATASET", "confidence": 0.9713066071271896}]}, {"text": "For the experiments, we adopted standard data splits: Train: Articles: Jan 1-11, Editorials: Jan-Aug Dev: Articles: Jan 12-13, Editorials: Sept Test: Articles: Jan 14-17, Editorials: Oct-Dec We used the word boundaries annotated in the NAIST Text Corpus and the target predicates that have at least one argument in the same sentence.", "labels": [], "entities": [{"text": "NAIST Text Corpus", "start_pos": 236, "end_pos": 253, "type": "DATASET", "confidence": 0.9824504454930624}]}, {"text": "We did not use any external resources.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: F-measures in the test set. Single- Seq is the single-sequence model, and Multi-Seq  is the multi-sequence model. Imamura+ 09 is  the model in Imamura et al. (2009) reimplemented  by Ouchi et al. (2015), and Ouchi+ 15 is the  ALL-Cases Joint Model in Ouchi et al. (2015).  The mark  \u2020 denotes the significantly better results  with the significance level p < 0.05, comparing", "labels": [], "entities": [{"text": "significance level p", "start_pos": 346, "end_pos": 366, "type": "METRIC", "confidence": 0.9416125814119974}]}, {"text": " Table 2: Performance comparison for different  numbers of layers on the development set in F- measures. L is the number of the RNN or Grid lay- ers. +res. or \u2212res. indicates whether the model  has residual connections (+) or not (\u2212).", "labels": [], "entities": [{"text": "Grid lay- ers", "start_pos": 135, "end_pos": 148, "type": "METRIC", "confidence": 0.6963790059089661}]}, {"text": " Table 3: Performance comparison for different  numbers (M ) of predicates in a sentence on the  test set in F-measures.", "labels": [], "entities": []}, {"text": " Table 4: Performance comparison for different case roles on the test set in F-measures. NOM, ACC or  DAT is the nominal, accusative or dative case, respectively. The asterisk (*) indicates that the model uses  external resources.", "labels": [], "entities": [{"text": "NOM", "start_pos": 89, "end_pos": 92, "type": "METRIC", "confidence": 0.7702526450157166}, {"text": "ACC", "start_pos": 94, "end_pos": 97, "type": "METRIC", "confidence": 0.8395566940307617}, {"text": "DAT", "start_pos": 102, "end_pos": 105, "type": "METRIC", "confidence": 0.8492898344993591}]}]}