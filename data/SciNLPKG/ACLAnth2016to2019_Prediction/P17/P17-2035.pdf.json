{"title": [{"text": "Neural Architecture for Temporal Relation Extraction: A Bi-LSTM Approach for Detecting Narrative Containers", "labels": [], "entities": [{"text": "Temporal Relation Extraction", "start_pos": 24, "end_pos": 52, "type": "TASK", "confidence": 0.849566121896108}, {"text": "Detecting Narrative Containers", "start_pos": 77, "end_pos": 107, "type": "TASK", "confidence": 0.7739189863204956}]}], "abstractContent": [{"text": "We present a neural architecture for containment relation identification between medical events and/or temporal expressions.", "labels": [], "entities": [{"text": "containment relation identification between medical events and/or temporal expressions", "start_pos": 37, "end_pos": 123, "type": "TASK", "confidence": 0.8644472035494718}]}, {"text": "We experiment on a corpus of de-identified clinical notes in English from the Mayo Clinic, namely the THYME corpus.", "labels": [], "entities": [{"text": "THYME corpus", "start_pos": 102, "end_pos": 114, "type": "DATASET", "confidence": 0.8857993483543396}]}, {"text": "Our model achieves an F-measure of 0.613 and outperforms the best result reported on this corpus to date.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 22, "end_pos": 31, "type": "METRIC", "confidence": 0.9995037317276001}]}], "introductionContent": [{"text": "Temporal information extraction from clinical health records allows fora fine-grained analysis of patient health history.", "labels": [], "entities": [{"text": "Temporal information extraction from clinical health", "start_pos": 0, "end_pos": 52, "type": "TASK", "confidence": 0.8574334482351939}]}, {"text": "Providing medical staff with patient timelines could lead to improved diagnostic and care.", "labels": [], "entities": [{"text": "diagnostic", "start_pos": 70, "end_pos": 80, "type": "METRIC", "confidence": 0.8205349445343018}]}, {"text": "Important temporal information (such as when a patient started a treatment, or when they started experiencing side effects from a treatment) can be found only within the narrative portion of records and needs the development of new Natural Language Processing methods in order to be accessed.", "labels": [], "entities": []}, {"text": "In this paper, we present a neural architecture for narrative container identification between medical events (EVENT) and/or temporal expressions (TIMEX3).", "labels": [], "entities": [{"text": "narrative container identification between medical events", "start_pos": 52, "end_pos": 109, "type": "TASK", "confidence": 0.7856235454479853}, {"text": "EVENT", "start_pos": 111, "end_pos": 116, "type": "METRIC", "confidence": 0.6123274564743042}, {"text": "TIMEX3", "start_pos": 147, "end_pos": 153, "type": "METRIC", "confidence": 0.7772271037101746}]}, {"text": "We experiment on the THYME corpus), a corpus of deidentified clinical notes in English from the Mayo Clinic.", "labels": [], "entities": [{"text": "THYME corpus", "start_pos": 21, "end_pos": 33, "type": "DATASET", "confidence": 0.8019612431526184}]}, {"text": "We use the Gold Standard annotations for EVENT and TIMEX3 entities and we focus on containment relation extraction where the objective is to identify temporal relations between pairs of entities formalized as narrative container relations.", "labels": [], "entities": [{"text": "containment relation extraction", "start_pos": 83, "end_pos": 114, "type": "TASK", "confidence": 0.930228590965271}]}], "datasetContent": [{"text": "We experimented with three configurations.", "labels": [], "entities": []}, {"text": "In the first one, we used only word embeddings and character embeddings.", "labels": [], "entities": []}, {"text": "In the second one, we added the feature embeddings related to the Gold Standard (GS) attributes.", "labels": [], "entities": [{"text": "Gold Standard (GS) attributes", "start_pos": 66, "end_pos": 95, "type": "DATASET", "confidence": 0.8365416626135508}]}, {"text": "Finally, in a third experiment, we added the feature embeddings related to cTAKES.", "labels": [], "entities": [{"text": "cTAKES", "start_pos": 75, "end_pos": 81, "type": "DATASET", "confidence": 0.9148735404014587}]}, {"text": "For each experiment, we report precision (P), recall (R) and F1-measure (F1) computed with the official evaluation script 2 provided during the Clinical TempEval challenges.", "labels": [], "entities": [{"text": "precision (P)", "start_pos": 31, "end_pos": 44, "type": "METRIC", "confidence": 0.946140244603157}, {"text": "recall (R)", "start_pos": 46, "end_pos": 56, "type": "METRIC", "confidence": 0.9522956013679504}, {"text": "F1-measure (F1)", "start_pos": 61, "end_pos": 76, "type": "METRIC", "confidence": 0.9357380121946335}]}, {"text": "Results of the experiments are presented in.", "labels": [], "entities": []}, {"text": "For comparison, we report the baseline provided as reference during the Clinical TempEval shared tasks,: Experimentation results.", "labels": [], "entities": [{"text": "Clinical TempEval shared tasks", "start_pos": 72, "end_pos": 102, "type": "TASK", "confidence": 0.5311166346073151}]}, {"text": "We report precision (P), recall (R) and F1-measure (F1) for each configuration of our model, for the best system of the Clinical TempEval 2016 challenge ( and for the best result obtained so far on the corpus (.", "labels": [], "entities": [{"text": "precision (P)", "start_pos": 10, "end_pos": 23, "type": "METRIC", "confidence": 0.935723140835762}, {"text": "recall (R)", "start_pos": 25, "end_pos": 35, "type": "METRIC", "confidence": 0.9480362236499786}, {"text": "F1-measure (F1)", "start_pos": 40, "end_pos": 55, "type": "METRIC", "confidence": 0.8975422233343124}, {"text": "Clinical TempEval 2016 challenge", "start_pos": 120, "end_pos": 152, "type": "DATASET", "confidence": 0.6950289160013199}]}, {"text": "All three of our models perform better in terms of F1-measure than and.", "labels": [], "entities": [{"text": "F1-measure", "start_pos": 51, "end_pos": 61, "type": "METRIC", "confidence": 0.9992307424545288}]}, {"text": "Our two best models also outperform, who report an F-measure of .608 using a structured perceptron.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 51, "end_pos": 60, "type": "METRIC", "confidence": 0.9991899132728577}]}, {"text": "Interestingly, their model did not distinguish between intra-and inter-sentence relations, but instead considered that related entities had to occur within a window of 30 tokens.", "labels": [], "entities": []}, {"text": "We see that the addition of attribute embeddings slightly improves the overall performance of our system (+0.008).", "labels": [], "entities": []}, {"text": "Adding the embeddings of GS features contributes to the major part of this improvement but tends to increase the imbalance between recall and precision.", "labels": [], "entities": [{"text": "recall", "start_pos": 131, "end_pos": 137, "type": "METRIC", "confidence": 0.9989293217658997}, {"text": "precision", "start_pos": 142, "end_pos": 151, "type": "METRIC", "confidence": 0.9809331893920898}]}, {"text": "On the contrary, while the attribute embeddings related to cTAKES seem to have little impact on the overall performance, they tend to restore more balanced precision and recall.", "labels": [], "entities": [{"text": "precision", "start_pos": 156, "end_pos": 165, "type": "METRIC", "confidence": 0.9977394342422485}, {"text": "recall", "start_pos": 170, "end_pos": 176, "type": "METRIC", "confidence": 0.997702419757843}]}, {"text": "The results for respectively intra-and intersentence relations are presented in.", "labels": [], "entities": []}, {"text": "Similarly to our global results, the intra-sentence classifier benefits from the addition of feature embeddings with a small increase for GS features and only a very little improvement for cTAKES features.", "labels": [], "entities": []}, {"text": "The inter-sentence classifier exhibits the same trend: GS features do improve the performance.", "labels": [], "entities": []}, {"text": "However, adding cTAKES features degrades it slightly (-0.013).", "labels": [], "entities": []}, {"text": "The closest work compared to ours is clearly as it also heavily relies on neural models for extracting temporal containment relations between medical events.", "labels": [], "entities": [{"text": "extracting temporal containment relations between medical events", "start_pos": 92, "end_pos": 156, "type": "TASK", "confidence": 0.856459881578173}]}, {"text": "tested both CNN and LSTM models and found CNN superior to LSTM.", "labels": [], "entities": [{"text": "CNN", "start_pos": 12, "end_pos": 15, "type": "DATASET", "confidence": 0.9356828331947327}, {"text": "CNN", "start_pos": 42, "end_pos": 45, "type": "DATASET", "confidence": 0.8942877054214478}]}, {"text": "However, this work addressed intra-sentence relations only.", "labels": [], "entities": []}, {"text": "Moreover, its LSTM model was not a Bi-LSTM model as ours and it did not include characterbased or attribute embeddings.", "labels": [], "entities": []}, {"text": "Finally, it distinguished EVENT-TIMEX3 and EVENT-EVENT relations while we have only one model for the two types of relations.", "labels": [], "entities": [{"text": "EVENT-TIMEX3", "start_pos": 26, "end_pos": 38, "type": "METRIC", "confidence": 0.9407613277435303}]}], "tableCaptions": [{"text": " Table 1: Descriptive statistics about the train and  test parts of the THYME corpus.", "labels": [], "entities": [{"text": "THYME corpus", "start_pos": 72, "end_pos": 84, "type": "DATASET", "confidence": 0.9243341982364655}]}, {"text": " Table 3: Results obtained by the intra-sentence and inter-sentence classifiers for each model of this paper.", "labels": [], "entities": []}, {"text": " Table 4: Experimentation results. We report preci- sion (P), recall (R) and F1-measure (F1) for each  configuration of our model, for the best system of  the Clinical TempEval 2016 challenge (", "labels": [], "entities": [{"text": "preci- sion (P)", "start_pos": 45, "end_pos": 60, "type": "METRIC", "confidence": 0.9576539595921835}, {"text": "recall (R)", "start_pos": 62, "end_pos": 72, "type": "METRIC", "confidence": 0.9516507685184479}, {"text": "F1-measure (F1)", "start_pos": 77, "end_pos": 92, "type": "METRIC", "confidence": 0.9492570757865906}, {"text": "Clinical TempEval 2016 challenge", "start_pos": 159, "end_pos": 191, "type": "DATASET", "confidence": 0.6114231795072556}]}]}