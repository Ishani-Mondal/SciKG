{"title": [], "abstractContent": [{"text": "We present the first attempt at using sequence to sequence neural networks to model text simplification (TS).", "labels": [], "entities": [{"text": "text simplification (TS)", "start_pos": 84, "end_pos": 108, "type": "TASK", "confidence": 0.8377212643623352}]}, {"text": "Unlike the previously proposed automated TS systems , our neural text simplification (NTS) systems are able to simultaneously perform lexical simplification and content reduction.", "labels": [], "entities": [{"text": "TS", "start_pos": 41, "end_pos": 43, "type": "TASK", "confidence": 0.9506925940513611}, {"text": "content reduction", "start_pos": 161, "end_pos": 178, "type": "TASK", "confidence": 0.746568351984024}]}, {"text": "An extensive human evaluation of the output has shown that NTS systems achieve almost perfect grammaticality and meaning preservation of output sentences and higher level of simplification than the state-of-the-art automated TS systems.", "labels": [], "entities": []}], "introductionContent": [{"text": "Neural sequence to sequence models have been successfully used in many applications, from speech and signal processing to text processing or dialogue systems (.", "labels": [], "entities": []}, {"text": "Neural machine translation () is a particular type of sequence to sequence model that recently attracted a lot of attention from industry () and academia, especially due to the capability to obtain state-of-the-art results for various translation tasks (.", "labels": [], "entities": [{"text": "Neural machine translation", "start_pos": 0, "end_pos": 26, "type": "TASK", "confidence": 0.7593035697937012}]}, {"text": "Unlike classical statistical machine translation (SMT) systems, neural networks are being trained end-to-end, without the need to have external decoders, language models or phrase tables.", "labels": [], "entities": [{"text": "statistical machine translation (SMT)", "start_pos": 17, "end_pos": 54, "type": "TASK", "confidence": 0.8046348790327708}]}, {"text": "The architectures are relatively simpler and more flexible, making possible the use of character models or even training multilingual systems in one go (.", "labels": [], "entities": []}, {"text": "Automated text simplification (ATS) systems are meant to transform original texts into differ- * * Both authors have contributed equally to this work ent (simpler) variants which would be understood by wider audiences and more successfully processed by various NLP tools.", "labels": [], "entities": [{"text": "Automated text simplification (ATS)", "start_pos": 0, "end_pos": 35, "type": "TASK", "confidence": 0.7553907434145609}]}, {"text": "In the last several years, great attention has been given to addressing ATS as a monolingual machine translation problem translating from 'original' to 'simple' sentences.", "labels": [], "entities": [{"text": "ATS", "start_pos": 72, "end_pos": 75, "type": "TASK", "confidence": 0.9692944884300232}, {"text": "machine translation problem translating from 'original' to 'simple' sentences", "start_pos": 93, "end_pos": 170, "type": "TASK", "confidence": 0.8282177219024072}]}, {"text": "So far, attempts were made at standard phrase-based SMT (PBSMT) models, PBSMT models with added phrasal deletion rules) or reranking of the n-best outputs according to their dissimilarity to the output (), tree-based translation models (, and syntax-based MT with specially designed tuning function ( . Recently, lexical simplification (LS) was addressed by unsupervised approaches leveraging word-embeddings, with reported good success.", "labels": [], "entities": [{"text": "SMT (PBSMT)", "start_pos": 52, "end_pos": 63, "type": "TASK", "confidence": 0.7623544335365295}, {"text": "MT", "start_pos": 256, "end_pos": 258, "type": "TASK", "confidence": 0.904484212398529}, {"text": "lexical simplification (LS)", "start_pos": 313, "end_pos": 340, "type": "TASK", "confidence": 0.7610331535339355}]}, {"text": "To the best of our knowledge, our work is the first to address the applicability of neural sequence to sequence models for ATS.", "labels": [], "entities": [{"text": "ATS", "start_pos": 123, "end_pos": 126, "type": "TASK", "confidence": 0.9445804357528687}]}, {"text": "We make use of the recent advances in neural machine translation (NMT) and adapt the existing architectures for our specific task.", "labels": [], "entities": [{"text": "neural machine translation (NMT)", "start_pos": 38, "end_pos": 70, "type": "TASK", "confidence": 0.8437406023343405}]}, {"text": "We also perform an extensive human evaluation to directly compare our systems with the current state-of-the-art (supervised) MT-based and unsupervised lexical simplification systems.", "labels": [], "entities": []}], "datasetContent": [{"text": "To train our models, we use the publicly available dataset provided by based on manual and automatic alignments between standard English Wikipedia and Simple English Wikipedia (EW-SEW).", "labels": [], "entities": [{"text": "Simple English Wikipedia (EW-SEW)", "start_pos": 151, "end_pos": 184, "type": "DATASET", "confidence": 0.7975684901078542}]}, {"text": "We discard the uncategorized matches, and use only good matches and partial matches which were above the 0.45 threshold (), totaling to 280K aligned sentences (around 150K full matches and 130K partial matches).", "labels": [], "entities": []}, {"text": "It is one of the largest freely available resources for text simplification, and unlike the previously used EW-SEW corpus 2, which only contains full matches (167K pairs), the newer dataset also contains partial matches.", "labels": [], "entities": [{"text": "text simplification", "start_pos": 56, "end_pos": 75, "type": "TASK", "confidence": 0.8105096817016602}, {"text": "EW-SEW corpus 2", "start_pos": 108, "end_pos": 123, "type": "DATASET", "confidence": 0.9449576735496521}]}, {"text": "Therefore, it is not only larger, but it also allows for learning sentence shortening (dropping irrelevant parts) transformations (see We use the Stanford NER system () to get an approximate number of locations, persons, organizations and miscellaneous entities in the corpus.", "labels": [], "entities": [{"text": "sentence shortening (dropping irrelevant parts) transformations", "start_pos": 66, "end_pos": 129, "type": "TASK", "confidence": 0.6912517994642258}, {"text": "Stanford NER system", "start_pos": 146, "end_pos": 165, "type": "DATASET", "confidence": 0.8478292425473531}]}, {"text": "A brief analysis of the vocabulary is rendered in.", "labels": [], "entities": []}, {"text": "The dataset we use contains an abundant amount of named entities and consequently a large amount of low frequency words, but the majority of entities are not part of the model's 50,000 words vocabulary due to their small frequency.", "labels": [], "entities": []}, {"text": "These words are replaced with 'UNK' symbols during training.", "labels": [], "entities": []}, {"text": "At prediction time, we replace the unknown words with the highest probability score from the attention layer.", "labels": [], "entities": []}, {"text": "We believe it is important to ensure that the models learn good word representations, either during the model training or through word2vec, in order to accurately create alignments between source and target sentences.", "labels": [], "entities": []}, {"text": "Given that in TS there is not only one best simplification, and that the quality of simplifications in Simple English Wikipedia has been disputed before, for tuning and testing we use the dataset previously released by , which contains 2000 sentences for tuning and 359 for testing, each with eight simplification variants obtained by eight Amazon Mechanical Turkers.", "labels": [], "entities": [{"text": "Simple English Wikipedia", "start_pos": 103, "end_pos": 127, "type": "DATASET", "confidence": 0.7678680022557577}]}, {"text": "The tune subset is also used as reference corpus in combination with BLEU and SARI to select the best beam size and hypothesis for prediction reranking.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 69, "end_pos": 73, "type": "METRIC", "confidence": 0.9923372864723206}, {"text": "SARI", "start_pos": 78, "end_pos": 82, "type": "METRIC", "confidence": 0.9269177913665771}, {"text": "prediction reranking", "start_pos": 131, "end_pos": 151, "type": "TASK", "confidence": 0.8967146575450897}]}, {"text": "For the first 70 original sentences of the Xu et al.'s (2016) test set we perform three types of human evaluation to assess the output of our best systems and three ATS systems of different architectures: (1) the PBSMT system with reranking of n-best outputs (, which represent the best PBSMT approach to ATS, trained and tuned over the same datasets as our systems; (2) the state-of-the-art SBMT system ( ) with modified tuning function (using SARI) and using PPDB paraphrase database (); 5 and (3) one of the state-of-theart unsupervised lexical simplification (LS) systems that leverages word-embeddings (Glava\u0161 and.", "labels": [], "entities": [{"text": "Xu et al.'s (2016) test set", "start_pos": 43, "end_pos": 70, "type": "DATASET", "confidence": 0.772345894575119}]}, {"text": "We evaluate the output of all systems using three types of human evaluation.", "labels": [], "entities": []}, {"text": "Correctness and Number of Changes.", "labels": [], "entities": [{"text": "Correctness", "start_pos": 0, "end_pos": 11, "type": "METRIC", "confidence": 0.9724091291427612}, {"text": "Number", "start_pos": 16, "end_pos": 22, "type": "METRIC", "confidence": 0.9630903005599976}]}, {"text": "First, we count the total number of changes made by each system (Total), counting the change of a whole phrase (e.g. \"become defunct\" \u2192 \"was dissolved\") as one change.", "labels": [], "entities": []}, {"text": "Those changes that preserve the original meaning and grammaticality of the sentence (assessed by two native English speakers) and, at the same time, make the sentence easier to understand (assessed by two non-native fluent English speakers) are marked as Correct.", "labels": [], "entities": [{"text": "Correct", "start_pos": 255, "end_pos": 262, "type": "METRIC", "confidence": 0.9951815009117126}]}, {"text": "In the case of content reduction, we instructed the annotators to count the deletion of each array of consecutive words as one change and consider the meaning unchanged if the main information of the sentence was retained and unchanged.", "labels": [], "entities": [{"text": "content reduction", "start_pos": 15, "end_pos": 32, "type": "TASK", "confidence": 0.7391928732395172}]}, {"text": "The sentences for which the two annotators did not agree were given to a third annotator to obtain the majority vote.", "labels": [], "entities": []}, {"text": "Second, three native English speakers rate the grammaticality (G) and meaning preservation (M) of each (whole) sentence with at least one change on a 1-5 Likert scale (1 -very bad; 5 -very good).", "labels": [], "entities": [{"text": "grammaticality (G) and meaning preservation (M)", "start_pos": 47, "end_pos": 94, "type": "METRIC", "confidence": 0.7184989303350449}]}, {"text": "The obtained inter-annotator agreement (quadratic Cohens kappa) was 0.78 for G and 0.63 for M.", "labels": [], "entities": [{"text": "quadratic Cohens kappa)", "start_pos": 40, "end_pos": 63, "type": "METRIC", "confidence": 0.6998590677976608}]}, {"text": "Third, the three nonnative fluent English speakers were shown original (reference) sentences and target (output) sentences, one pair at the time, and asked whether the target sentence is: +2 -much simpler; +1 -somewhat simpler; 0 -equally difficult; -1 -somewhat more difficult; -2 -much more difficult, than the reference sentence.", "labels": [], "entities": []}, {"text": "The obtained inter-annotator agreement (quadratic Cohens kappa) was 0.66.", "labels": [], "entities": [{"text": "quadratic Cohens kappa)", "start_pos": 40, "end_pos": 63, "type": "METRIC", "confidence": 0.7685012370347977}]}, {"text": "While the correctness of changes takes into account the influence of each individual change on grammaticality, meaning and simplicity of a sentence, the Scores (G and M) and Rank (S) take into account the mutual influence of all changes within a sentence.", "labels": [], "entities": [{"text": "simplicity", "start_pos": 123, "end_pos": 133, "type": "METRIC", "confidence": 0.9980352520942688}, {"text": "Rank (S)", "start_pos": 174, "end_pos": 182, "type": "METRIC", "confidence": 0.9021580815315247}]}], "tableCaptions": [{"text": " Table 1: The number of tokens and entities in the  corpus.", "labels": [], "entities": []}, {"text": " Table 2: Human evaluation results (the highest scores by each evaluation criterion are shown in bold).", "labels": [], "entities": []}]}