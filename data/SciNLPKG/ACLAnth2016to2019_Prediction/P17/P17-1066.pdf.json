{"title": [{"text": "Detect Rumors in Microblog Posts Using Propagation Structure via Kernel Learning", "labels": [], "entities": [{"text": "Detect Rumors in Microblog Posts", "start_pos": 0, "end_pos": 32, "type": "TASK", "confidence": 0.635347044467926}]}], "abstractContent": [{"text": "How fake news goes viral via social me-dia?", "labels": [], "entities": []}, {"text": "How does its propagation pattern differ from real stories?", "labels": [], "entities": []}, {"text": "In this paper, we attempt to address the problem of identifying rumors, i.e., fake information, out of microblog posts based on their propagation structure.", "labels": [], "entities": []}, {"text": "We firstly model mi-croblog posts diffusion with propagation trees, which provide valuable clues on how an original message is transmitted and developed overtime.", "labels": [], "entities": [{"text": "mi-croblog posts diffusion", "start_pos": 17, "end_pos": 43, "type": "TASK", "confidence": 0.6295579870541891}]}, {"text": "We then propose a kernel-based method called Propagation Tree Kernel, which captures high-order patterns differentiating different types of rumors by evaluating the similarities between their propagation tree structures.", "labels": [], "entities": [{"text": "Propagation Tree Kernel", "start_pos": 45, "end_pos": 68, "type": "TASK", "confidence": 0.5946057637532552}]}, {"text": "Experimental results on two real-world datasets demonstrate that the proposed kernel-based approach can detect rumors more quickly and accurately than state-of-the-art rumor detection models.", "labels": [], "entities": []}], "introductionContent": [{"text": "On November 9th, 2016, Eric Tucker, a grassroots user who had just about 40 followers on Twitter, tweeted his unverified observations about paid protesters being bused to attend anti-Trump demonstration in Austin, Texas.", "labels": [], "entities": []}, {"text": "The tweet, which was proved false later, was shared over 16 thousand times on Twitter and 350 thousand times on Facebook within a couple of days, fueling a nation-wide conspiracy theory . The diffusion of the story is illustrated as which gives the key spreading points of the story along the timeline.", "labels": [], "entities": []}, {"text": "We can see that after the initial post, the tweet was shared or promoted by some influential online communities and users (including Trump himself), resulting in its widespread.", "labels": [], "entities": []}, {"text": "A widely accepted definition of rumor is \"unverified and instrumentally relevant information statements in circulation\".", "labels": [], "entities": []}, {"text": "This unverified information may eventually turnout to be true, or partly or entirely false.", "labels": [], "entities": []}, {"text": "In today's ever-connected world, rumors can arise and spread at lightening speed thanks to social media platforms, which could not only be wrong, but be misleading and dangerous to the public society.", "labels": [], "entities": []}, {"text": "Therefore, it is crucial to track and debunk such rumors in timely manner.", "labels": [], "entities": []}, {"text": "Journalists and fact-checking websites such as snopes.com have made efforts to track and detect rumors.", "labels": [], "entities": []}, {"text": "However, such endeavor is manual, thus prone to poor coverage and low speed.", "labels": [], "entities": [{"text": "coverage", "start_pos": 53, "end_pos": 61, "type": "METRIC", "confidence": 0.9830498099327087}, {"text": "speed", "start_pos": 70, "end_pos": 75, "type": "METRIC", "confidence": 0.9771536588668823}]}, {"text": "Feature-based methods) achieved certain success by employing large feature sets crafted from message contents, user profiles and holistic statistics of diffusion patterns (e.g., number of retweets, propagation time, etc.).", "labels": [], "entities": []}, {"text": "But such an approach was over simplified as they ignored the dynamics of rumor propagation.", "labels": [], "entities": [{"text": "rumor propagation", "start_pos": 73, "end_pos": 90, "type": "TASK", "confidence": 0.874626636505127}]}, {"text": "Existing studies considering propagation characteristics mainly focused on the temporal features ( rather than the structure of propagation.", "labels": [], "entities": []}, {"text": "So, can the propagation structure make any difference for differentiating rumors from nonrumors?", "labels": [], "entities": [{"text": "differentiating rumors", "start_pos": 58, "end_pos": 80, "type": "TASK", "confidence": 0.821412980556488}]}, {"text": "Recent studies showed that rumor spreaders are persons who want to get attention and popularity.", "labels": [], "entities": [{"text": "rumor spreaders", "start_pos": 27, "end_pos": 42, "type": "TASK", "confidence": 0.7203959971666336}]}, {"text": "However, popular users who get more attention on Twitter (e.g., with more followers) are actually less likely to spread rumor in a sense that the high audience size might hinder a user from participating in propagating unverified information (.", "labels": [], "entities": []}, {"text": "Intuitively, for \"successful\" rumors being propagated as widely as popular real news, initial spreaders (typically lack of popularity) must attract certain amount of broadcasting power, e.g., attention of influential users or communities that have a lot of audiences joining in promoting the propagation.", "labels": [], "entities": []}, {"text": "We refer to this as a constrained mode propagation, relative to the open mode propagation of normal messages that everyone is open to share.", "labels": [], "entities": []}, {"text": "Such different modes of propagation may imply some distinct propagation structures between rumors and nonrumors and even among different types of rumors.", "labels": [], "entities": []}, {"text": "Due to the complex nature of information diffusion, explicitly defining discriminant features based on propagation structure is difficult and biased.", "labels": [], "entities": [{"text": "information diffusion", "start_pos": 29, "end_pos": 50, "type": "TASK", "confidence": 0.830508291721344}]}, {"text": "exemplifies the propagation structures of two Twitter posts, a rumor and a nonrumor, initiated by two users shown as the root nodes (in green color).", "labels": [], "entities": []}, {"text": "The information flows here illustrate that the rumorous tweet is first posted by a low-impact user, then some popular users joining in who boost the spreading, but the non-rumorous tweet is initially posted by a popular user and directly spread by many general users; contentbased signal like various users' stance ( and edge-based signal such as relative influence ( can also suggest the different nature of source tweets.", "labels": [], "entities": []}, {"text": "Many of such implicit distinctions throughout message propagation are hard to handcraft specifically using flat summary of statistics as previous work did.", "labels": [], "entities": [{"text": "message propagation", "start_pos": 46, "end_pos": 65, "type": "TASK", "confidence": 0.8593971431255341}]}, {"text": "In addition, unlike representation learning for plain text, learning for representation of structures such as networks is not well studied in general.", "labels": [], "entities": [{"text": "representation learning", "start_pos": 20, "end_pos": 43, "type": "TASK", "confidence": 0.9185228943824768}]}, {"text": "Therefore, traditional and latest text-based models (Castillo To capture high-order propagation patterns for rumor detection, we firstly represent the propagation of each source tweet with a propagation tree which is formed by harvesting user's interactions to one another triggered by the source tweet.", "labels": [], "entities": [{"text": "rumor detection", "start_pos": 109, "end_pos": 124, "type": "TASK", "confidence": 0.8433775305747986}]}, {"text": "Then, we propose a kernel-based data-driven method called Propagation Tree Kernel (PTK) to generate relevant features (i.e., subtrees) automatically for estimating the similarity between two propagation trees.", "labels": [], "entities": []}, {"text": "Unlike traditional tree kernel) for modeling syntactic structure based on parse tree, our propagation tree consists of nodes corresponding to microblog posts, each represented as a continuous vector, and edges representing the direction of propagation and providing the context to individual posts.", "labels": [], "entities": []}, {"text": "The basic idea is to find and capture the salient substructures in the propagation trees indicative of rumors.", "labels": [], "entities": []}, {"text": "We also extend PTK into a context-enriched PTK (cPTK) to enhance the model by considering different propagation paths from source tweet to the roots of subtrees, which capture the context of transmission.", "labels": [], "entities": []}, {"text": "Extensive experiments on two real-world Twitter datasets show that the proposed methods outperform state-of-the-art rumor detection models with large margin.", "labels": [], "entities": [{"text": "rumor detection", "start_pos": 116, "end_pos": 131, "type": "TASK", "confidence": 0.7722486853599548}]}, {"text": "Moreover, most existing approaches regard rumor detection as a binary classification problem, which predicts a candidate hypothesis as rumor or not.", "labels": [], "entities": [{"text": "rumor detection", "start_pos": 42, "end_pos": 57, "type": "TASK", "confidence": 0.8944493234157562}]}, {"text": "Since a rumor often begins as unverified and later turns out to be confirmed as true or false, or remains unverified (, here we consider a set of more practical, finer-grained classes: false rumor, true rumor, unverified rumor, and non-rumor, which becomes an even more challenging problem.", "labels": [], "entities": []}], "datasetContent": [{"text": "We compare our kernel-based method against the following baselines: SVM-TS: A linear SVM classification model that uses time-series to model the variation of a set of hand-crafted features (.", "labels": [], "entities": [{"text": "SVM classification", "start_pos": 85, "end_pos": 103, "type": "TASK", "confidence": 0.8537729978561401}]}, {"text": "DTR: A Decision-Tree-based Ranking method to identify trending rumors (, which searches for enquiry phrases and clusters disputed factual claims, and ranked the clustered results based on statistical features.", "labels": [], "entities": [{"text": "DTR", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.688744306564331}]}, {"text": "DTC and SVM-RBF: The Twitter information credibility model using Decision Tree Classifier) and the SVM-based model with RBF kernel, respectively, both using hand-crafted features based on the overall statistics of the posts.", "labels": [], "entities": [{"text": "DTC", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.9375572800636292}]}, {"text": "RFC: The Random Forest Classifier proposed by using three parameters to fit the temporal properties and an extensive set of hand-crafted features related to the user, linguistic and structure characteristics.", "labels": [], "entities": []}, {"text": "GRU: The RNN-based rumor detection model proposed by with gated recurrent unit for representation learning of high-level features from relevant posts overtime.", "labels": [], "entities": [{"text": "GRU", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.7962890863418579}, {"text": "RNN-based rumor detection", "start_pos": 9, "end_pos": 34, "type": "TASK", "confidence": 0.8341781894365946}, {"text": "representation learning of high-level features from relevant posts", "start_pos": 83, "end_pos": 149, "type": "TASK", "confidence": 0.8327982872724533}]}, {"text": "BOW: A naive baseline we worked by representing the text in each tree using bag-of-words and building the rumor classifier with linear SVM.", "labels": [], "entities": [{"text": "BOW", "start_pos": 0, "end_pos": 3, "type": "METRIC", "confidence": 0.9761810898780823}]}, {"text": "Our models: PTK and cPTK are our full PTK and cPTK models, respectively; PTK-and cPTKare the setting of only using content while ignoring user properties.", "labels": [], "entities": []}, {"text": "We implemented DTC and RFC with Weka 5 , SVM models with LibSVM and GRU with Theano . We held out 10% of the trees in each dataset for model tuning, and for the rest of the trees, we performed 3-fold cross-validation.", "labels": [], "entities": [{"text": "GRU", "start_pos": 68, "end_pos": 71, "type": "METRIC", "confidence": 0.9019089937210083}, {"text": "Theano", "start_pos": 77, "end_pos": 83, "type": "DATASET", "confidence": 0.9414589405059814}, {"text": "model tuning", "start_pos": 135, "end_pos": 147, "type": "TASK", "confidence": 0.7067491412162781}]}, {"text": "We used accuracy, F 1 measure as evaluation metrics.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 8, "end_pos": 16, "type": "METRIC", "confidence": 0.9995582699775696}, {"text": "F 1 measure", "start_pos": 18, "end_pos": 29, "type": "METRIC", "confidence": 0.963665227095286}]}, {"text": "shows that our proposed methods outperform all the baselines on both datasets.", "labels": [], "entities": []}, {"text": "Among all baselines, GRU performs the best, which learns the low-dimensional representation of responsive tweets by capturing the textual and temporal information.", "labels": [], "entities": [{"text": "GRU", "start_pos": 21, "end_pos": 24, "type": "METRIC", "confidence": 0.5491054058074951}]}, {"text": "This indicates the effectiveness of complex signals indicative of rumors beyond cue words or phrases (e.g., \"what?\", \"really?\", \"not sure\", etc.).", "labels": [], "entities": []}, {"text": "This also justifies the good performance of BOW even though it only uses uni-grams for representation.", "labels": [], "entities": [{"text": "BOW", "start_pos": 44, "end_pos": 47, "type": "DATASET", "confidence": 0.7721133232116699}]}, {"text": "Although DTR uses a set of regular expressions, we found only 19.59% and 22.21% tweets in our datasets containing these expressions.", "labels": [], "entities": [{"text": "DTR", "start_pos": 9, "end_pos": 12, "type": "DATASET", "confidence": 0.8931653499603271}]}, {"text": "That is why the results of DTR are not satisfactory.", "labels": [], "entities": [{"text": "DTR", "start_pos": 27, "end_pos": 30, "type": "TASK", "confidence": 0.7247010469436646}]}, {"text": "SVM-TS and RFC are comparable because both of them utilize an extensive set of features especially focusing on temporal traits.", "labels": [], "entities": [{"text": "SVM-TS", "start_pos": 0, "end_pos": 6, "type": "DATASET", "confidence": 0.8470898270606995}, {"text": "RFC", "start_pos": 11, "end_pos": 14, "type": "DATASET", "confidence": 0.6995032429695129}]}, {"text": "But none of the models can directly incorporate structured propagation patterns for deep similarity compar-  ison between propagation trees.", "labels": [], "entities": []}, {"text": "SVM-RBF, although using a non-linear kernel, is based on traditional hand-crafted features instead of the structural kernel like ours.", "labels": [], "entities": [{"text": "SVM-RBF", "start_pos": 0, "end_pos": 7, "type": "DATASET", "confidence": 0.8906568884849548}]}, {"text": "So, they performed obviously worse than our approach.", "labels": [], "entities": []}, {"text": "Representation learning methods like GRU cannot easily utilize complex structural information for learning important features from our networked data.", "labels": [], "entities": []}, {"text": "In contrast, our models can capture complex propagation patterns from structured data rich of linguistic, user and temporal signals.", "labels": [], "entities": []}, {"text": "Therefore, the superiority of our models is clear: PTK-which only uses text is already better than GRU, demonstrating the importance of propagation structures.", "labels": [], "entities": []}, {"text": "PTK that combines text and user yields better results on both datasets, implying that both properties are complementary and PTK integrating flat and structured information is obviously more effective.", "labels": [], "entities": [{"text": "PTK", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.6203282475471497}]}, {"text": "It is also observed that cPTK outperforms PTK except for non-rumor class.", "labels": [], "entities": [{"text": "PTK", "start_pos": 42, "end_pos": 45, "type": "DATASET", "confidence": 0.7265439629554749}]}, {"text": "This suggests the context-sensitive modeling based on PTK is effective for different types of rumors, but for non- The example subtree of a rumor captured by the algorithm at early stage of propagation rumors, it seems that considering context of propagation path is not always helpful.", "labels": [], "entities": [{"text": "PTK", "start_pos": 54, "end_pos": 57, "type": "DATASET", "confidence": 0.8185876607894897}]}, {"text": "This might be due to the generally weak signals originated from node properties on the paths during non-rumor's diffusion since user distribution patterns in nonrumors do not seem as obvious as in rumors.", "labels": [], "entities": []}, {"text": "This is not an issue in cPTK-since user information is not considered at all.", "labels": [], "entities": []}, {"text": "Over all classes, cPTK achieves the highest accuracies on both datasets.", "labels": [], "entities": [{"text": "accuracies", "start_pos": 44, "end_pos": 54, "type": "METRIC", "confidence": 0.9960682392120361}]}, {"text": "Furthermore, we observe that all the baseline methods perform much better on non-rumors than on rumors.", "labels": [], "entities": []}, {"text": "This is because the features of existing methods were defined fora binary (rumor vs. non-rumor) classification problem.", "labels": [], "entities": []}, {"text": "So, they do not perform well for finer-grained classes.", "labels": [], "entities": []}, {"text": "Our approach can differentiate various classes much better by deep, detailed comparison of different patterns based on propagation structure.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Statistics of the datasets", "labels": [], "entities": []}, {"text": " Table 2: Rumor detection results (NR: Non- Rumor; FR: False Rumor; TR: True Rumor; UR:  Unverified Rumor)", "labels": [], "entities": [{"text": "Rumor detection", "start_pos": 10, "end_pos": 25, "type": "TASK", "confidence": 0.8528633117675781}, {"text": "FR: False Rumor", "start_pos": 51, "end_pos": 66, "type": "METRIC", "confidence": 0.8038669526576996}]}]}