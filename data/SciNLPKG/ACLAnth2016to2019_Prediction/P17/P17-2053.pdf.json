{"title": [{"text": "Group Sparse CNNs for Question Classification with Answer Sets", "labels": [], "entities": [{"text": "Question Classification", "start_pos": 22, "end_pos": 45, "type": "TASK", "confidence": 0.7413023710250854}]}], "abstractContent": [{"text": "Question classification is an important task with wide applications.", "labels": [], "entities": [{"text": "Question classification", "start_pos": 0, "end_pos": 23, "type": "TASK", "confidence": 0.869212418794632}]}, {"text": "However, traditional techniques treat questions as general sentences, ignoring the corresponding answer data.", "labels": [], "entities": []}, {"text": "In order to consider answer information into question modeling, we first introduce novel group sparse autoen-coders which refine question representation by utilizing group information in the answer set.", "labels": [], "entities": [{"text": "question modeling", "start_pos": 45, "end_pos": 62, "type": "TASK", "confidence": 0.7439248263835907}, {"text": "question representation", "start_pos": 129, "end_pos": 152, "type": "TASK", "confidence": 0.7171616107225418}]}, {"text": "We then propose novel group sparse CNNs which naturally learn question representation with respect to their answers by implanting group sparse au-toencoders into traditional CNNs.", "labels": [], "entities": []}, {"text": "The proposed model significantly outperform strong baselines on four datasets.", "labels": [], "entities": []}], "introductionContent": [{"text": "Question classification has applications in many domains ranging from question answering to dialog systems, and has been increasingly popular in recent years.", "labels": [], "entities": [{"text": "Question classification", "start_pos": 0, "end_pos": 23, "type": "TASK", "confidence": 0.8679093420505524}, {"text": "question answering", "start_pos": 70, "end_pos": 88, "type": "TASK", "confidence": 0.8520466685295105}]}, {"text": "Several recent efforts) treat questions as general sentences and employ Convolutional Neural Networks (CNNs) to achieve remarkably strong performance in the TREC question classification task.", "labels": [], "entities": [{"text": "TREC question classification task", "start_pos": 157, "end_pos": 190, "type": "TASK", "confidence": 0.9106154441833496}]}, {"text": "We argue, however, that those general sentence modeling frameworks neglect two unique properties of question classification.", "labels": [], "entities": [{"text": "question classification", "start_pos": 100, "end_pos": 123, "type": "TASK", "confidence": 0.7351845800876617}]}, {"text": "First, different from the flat and coarse categories inmost sentence classification tasks (i.e. sentimental classification), question classes often have a hierarchical structure such as those from the New York State DMV FAQ 1 (see).", "labels": [], "entities": [{"text": "sentence classification tasks", "start_pos": 60, "end_pos": 89, "type": "TASK", "confidence": 0.8123306234677633}, {"text": "sentimental classification", "start_pos": 96, "end_pos": 122, "type": "TASK", "confidence": 0.8496007919311523}, {"text": "DMV FAQ 1", "start_pos": 216, "end_pos": 225, "type": "DATASET", "confidence": 0.6353266835212708}]}, {"text": "Another unique aspect of question classification is the well prepared answers for each question or question category.", "labels": [], "entities": [{"text": "question classification", "start_pos": 25, "end_pos": 48, "type": "TASK", "confidence": 0.822268545627594}]}, {"text": "These answer Crawled from http://nysdmv.custhelp.com/app/home.", "labels": [], "entities": []}, {"text": "This data and our code will beat http://github.com/cosmmb.", "labels": [], "entities": []}, {"text": "sets generally cover a larger vocabulary (than the questions themselves) and provide richer information for each class.", "labels": [], "entities": []}, {"text": "We believe there is a great potential to enhance question representation with extra information from corresponding answer sets.", "labels": [], "entities": [{"text": "question representation", "start_pos": 49, "end_pos": 72, "type": "TASK", "confidence": 0.7681383192539215}]}, {"text": "To exploit the hierarchical and overlapping structures in question categories and extra information from answer sets, we consider dictionary learning which is a common approach for representing samples from many correlated groups with external information.", "labels": [], "entities": []}, {"text": "This learning procedure first builds a dictionary with a series of grouped bases.", "labels": [], "entities": []}, {"text": "These bases can be initialized randomly or from external data (from the answer set in our case) and optimized during training through Sparse Group Lasso (SGL) (.", "labels": [], "entities": []}, {"text": "To apply dictionary learning to CNN, we first develop a neural version of SGL, Group Sparse Autoencoders (GSAs), which to the best of our knowledge, is the first full neural model with group sparse constraints.", "labels": [], "entities": []}, {"text": "The encoding matrix of GSA (like the dictionary in SGL) is grouped into different categories.", "labels": [], "entities": []}, {"text": "The bases in different groups can be either initialized randomly or by the sentences in corresponding answer categories.", "labels": [], "entities": []}, {"text": "Each question sentence will be reconstructed by a few bases within a few groups.", "labels": [], "entities": []}, {"text": "GSA can use either linear or nonlinear encoding or decoding while SGL is restricted to be linear.", "labels": [], "entities": [{"text": "GSA", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.7702473998069763}]}, {"text": "Eventually, to model questions with sparsity, we further propose novel Group Sparse Convolutional Neural Networks (GSCNNs) by implanting the GSA onto CNNs, essentially enforcing group sparsity between the convolutional and classification layers.", "labels": [], "entities": []}, {"text": "This framework is a jointly trained neural model to learn question representation with group sparse constraints from both question and answer sets.", "labels": [], "entities": [{"text": "question representation", "start_pos": 58, "end_pos": 81, "type": "TASK", "confidence": 0.7701075673103333}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Summary of datasets. C t and C s are  the numbers of top-level and sub-categories, resp.  N data , N test , N ans are the sizes of data set, test  set, and answer set, resp. Multilabel means each  question can belong to multiple categories.", "labels": [], "entities": []}]}