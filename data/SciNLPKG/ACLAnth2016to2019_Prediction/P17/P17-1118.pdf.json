{"title": [{"text": "Enriching Complex Networks with Word Embeddings for Detecting Mild Cognitive Impairment from Speech Transcripts", "labels": [], "entities": [{"text": "Detecting Mild Cognitive Impairment from Speech Transcripts", "start_pos": 52, "end_pos": 111, "type": "TASK", "confidence": 0.873187073639461}]}], "abstractContent": [{"text": "Mild Cognitive Impairment (MCI) is a mental disorder difficult to diagnose.", "labels": [], "entities": [{"text": "Mild Cognitive Impairment (MCI)", "start_pos": 0, "end_pos": 31, "type": "TASK", "confidence": 0.786068876584371}]}, {"text": "Linguistic features, mainly from parsers, have been used to detect MCI, but this is not suitable for large-scale assessments.", "labels": [], "entities": [{"text": "detect MCI", "start_pos": 60, "end_pos": 70, "type": "TASK", "confidence": 0.5559445321559906}]}, {"text": "MCI disfluencies produce non-grammatical speech that requires manual or high precision automatic correction of transcripts.", "labels": [], "entities": []}, {"text": "In this paper, we mod-eled transcripts into complex networks and enriched them with word embedding (CNE) to better represent short texts produced in neuropsychological assessments.", "labels": [], "entities": []}, {"text": "The network measurements were applied with well-known classifiers to automatically identify MCI in transcripts, in a binary classification task.", "labels": [], "entities": []}, {"text": "A comparison was made with the performance of traditional approaches using Bag of Words (BoW) and linguistic features for three datasets: DementiaBank in English, and Cinderella and Arizona-Battery in Por-tuguese.", "labels": [], "entities": []}, {"text": "Overall, CNE provided higher accuracy than using only complex networks , while Support Vector Machine was superior to other classifiers.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 29, "end_pos": 37, "type": "METRIC", "confidence": 0.9981574416160583}]}, {"text": "CNE provided the highest accuracies for Dementia-Bank and Cinderella, but BoW was more efficient for the Arizona-Battery dataset probably owing to its short narratives.", "labels": [], "entities": [{"text": "CNE", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.9454141855239868}, {"text": "accuracies", "start_pos": 25, "end_pos": 35, "type": "METRIC", "confidence": 0.985508382320404}, {"text": "Cinderella", "start_pos": 58, "end_pos": 68, "type": "DATASET", "confidence": 0.9107668399810791}, {"text": "BoW", "start_pos": 74, "end_pos": 77, "type": "DATASET", "confidence": 0.8276345133781433}, {"text": "Arizona-Battery dataset", "start_pos": 105, "end_pos": 128, "type": "DATASET", "confidence": 0.9186401963233948}]}, {"text": "The approach using linguistic features yielded higher accuracy if the transcriptions of the Cinderella dataset were manually revised.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 54, "end_pos": 62, "type": "METRIC", "confidence": 0.9990158081054688}, {"text": "Cinderella dataset", "start_pos": 92, "end_pos": 110, "type": "DATASET", "confidence": 0.8316451907157898}]}, {"text": "Taken together, the results indicate that complex networks enriched with embedding is promising for detecting MCI in large-scale assessments.", "labels": [], "entities": [{"text": "detecting MCI", "start_pos": 100, "end_pos": 113, "type": "TASK", "confidence": 0.7449616193771362}]}], "introductionContent": [{"text": "Mild Cognitive Impairment (MCI) can affect one or multiple cognitive domains (e.g. memory, language, visuospatial skills and executive functions), and may represent a pre-clinical stage of Alzheimer's disease (AD).", "labels": [], "entities": [{"text": "Mild Cognitive Impairment (MCI)", "start_pos": 0, "end_pos": 31, "type": "TASK", "confidence": 0.7512143502632777}, {"text": "Alzheimer's disease (AD)", "start_pos": 189, "end_pos": 213, "type": "TASK", "confidence": 0.664488265911738}]}, {"text": "The impairment that affects memory, referred to as amnestic MCI, is the most frequent, with the highest conversion rate for AD, at 15% per year versus 1 to 2% for the general population.", "labels": [], "entities": [{"text": "memory", "start_pos": 28, "end_pos": 34, "type": "METRIC", "confidence": 0.9749430418014526}, {"text": "conversion", "start_pos": 104, "end_pos": 114, "type": "METRIC", "confidence": 0.9864193797111511}, {"text": "AD", "start_pos": 124, "end_pos": 126, "type": "METRIC", "confidence": 0.9467974901199341}]}, {"text": "Since dementias are chronic and progressive diseases, their early diagnosis ensures a greater chance of success to engage patients in non-pharmacological treatment strategies such as cognitive training, physical activity and socialization (.", "labels": [], "entities": []}, {"text": "Language is one of the most efficient information sources to assess cognitive functions.", "labels": [], "entities": []}, {"text": "Changes in language usage are frequent in patients with dementia and are normally first recognized by the patients themselves or their family members.", "labels": [], "entities": []}, {"text": "Therefore, the automatic analysis of discourse production is promising in diagnosing MCI at early stages, which may address potentially reversible factors.", "labels": [], "entities": []}, {"text": "Proposals to detect language-related impairment in dementias include machine learning (, magnetic resonance imaging (, and data screening tests added to demographic information (.", "labels": [], "entities": []}, {"text": "Discourse production (mainly narratives) is attractive because it allows the analysis of linguistic microstructures, including phonetic-phonological, morphosyntactic and semantic-lexical components, as well as semantic-pragmatic macrostructures.", "labels": [], "entities": [{"text": "Discourse production", "start_pos": 0, "end_pos": 20, "type": "TASK", "confidence": 0.7994412183761597}]}, {"text": "Automated discourse analysis based on Natural Language Processing (NLP) resources and tools to diagnose dementias via machine learning methods has been used for English language () and for Brazilian Portuguese.", "labels": [], "entities": []}, {"text": "A variety of features are required for this analysis, including Part-of-Speech (PoS), syntactic complexity, lexical diversity and acoustic features.", "labels": [], "entities": []}, {"text": "Producing robust tools to extract these features is extremely difficult because speech transcripts used in neuropsychological evaluations contain disfluencies (repetitions, revisions, paraphasias) and patient's comments about the task being evaluated.", "labels": [], "entities": []}, {"text": "Another problem in using linguistic knowledge is the high dependence on manually created resources, such as hand-crafted linguistic rules and/or annotated corpora.", "labels": [], "entities": []}, {"text": "Even when traditional statistical techniques (Bag of Words or ngrams) are applied, problems still appear in dealing with disfluencies, because mispronounced words will not be counted together.", "labels": [], "entities": []}, {"text": "Indeed, other types of disfluencies (repetition, amendments, patient's comments about the task) will be counted, thus increasing the vocabulary.", "labels": [], "entities": [{"text": "repetition", "start_pos": 37, "end_pos": 47, "type": "METRIC", "confidence": 0.9812989830970764}]}, {"text": "An approach applied successfully to several areas of NLP (, which may suffer less from the problems mentioned above, relies on the use of complex networks and graph theory.", "labels": [], "entities": []}, {"text": "The word adjacency network model has provided good results in text classification (de and related tasks, namely author detection, identification of literary movements (), authenticity verification ( and word sense discrimination (.", "labels": [], "entities": [{"text": "text classification", "start_pos": 62, "end_pos": 81, "type": "TASK", "confidence": 0.7525934875011444}, {"text": "author detection", "start_pos": 112, "end_pos": 128, "type": "TASK", "confidence": 0.804163932800293}, {"text": "identification of literary movements", "start_pos": 130, "end_pos": 166, "type": "TASK", "confidence": 0.8698288947343826}, {"text": "authenticity verification", "start_pos": 171, "end_pos": 196, "type": "TASK", "confidence": 0.7235486507415771}, {"text": "word sense discrimination", "start_pos": 203, "end_pos": 228, "type": "TASK", "confidence": 0.7041111588478088}]}, {"text": "In this paper, we show that speech transcripts (narratives or descriptions) can be modeled into complex networks that are enriched with word embedding in order to better represent short texts produced in these assessments.", "labels": [], "entities": []}, {"text": "When applied to a machine learning classifier, the complex network features were able to distinguish between control participants and mild cognitive impairment participants.", "labels": [], "entities": []}, {"text": "Discrimination of the two classes could be improved by combining complex networks with linguistic and traditional statistical features.", "labels": [], "entities": []}, {"text": "With regard to the task of detecting MCI from transcripts, this paper is, to the best of our knowledge, the first to: a) show that classifiers using features extracted from transcripts modeled into complex networks enriched with word embedding present higher accuracy than using only complex networks for 3 datasets; and b) show that for languages that do not have competitive dependency and constituency parsers to exploit syntactic features, e.g. Brazilian Portuguese, complex networks enriched with word embedding constitute a source to extract new, language independent features from transcripts.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 259, "end_pos": 267, "type": "METRIC", "confidence": 0.9970734119415283}]}], "datasetContent": [{"text": "The datasets 2 used in our study consisted of: (i) manually segmented and transcribed samples from the DementiaBank and Cinderella story and (ii) transcribed samples of Arizona Battery for Communication Disorders of Dementia (ABCD) automatically segmented into sentences, since we are working towards a fully automated system to detect MCI in transcripts and would like to evaluate a dataset which was automatically processed.", "labels": [], "entities": []}, {"text": "The DementiaBank dataset is composed of short English descriptions, while the Cinderella dataset contains longer Brazilian Portuguese narratives.", "labels": [], "entities": [{"text": "DementiaBank dataset", "start_pos": 4, "end_pos": 24, "type": "DATASET", "confidence": 0.8901222050189972}, {"text": "Cinderella dataset", "start_pos": 78, "end_pos": 96, "type": "DATASET", "confidence": 0.9730519652366638}]}, {"text": "ABCD dataset is composed of very short narratives, also in Portuguese.", "labels": [], "entities": [{"text": "ABCD dataset", "start_pos": 0, "end_pos": 12, "type": "DATASET", "confidence": 0.9283383190631866}]}, {"text": "Below, we describe 2 All datasets are made available in the same representations used in this work, upon request to the authors.", "labels": [], "entities": []}, {"text": "in further detail the datasets, participants, and the task in which they were used.", "labels": [], "entities": []}, {"text": "The clinical dataset used for the English language was created during a longitudinal study conducted by the University of Pittsburgh School of Medicine on Alzheimer's and related dementia, funded by the National Institute of Aging.", "labels": [], "entities": []}, {"text": "To be eligible for inclusion in the study, all participants were required to be above 44 years of age, have at least 7 years of education, no history of nervous system disorders nor be taking neuroleptic medication, have an initial Mini-Mental State Exam (MMSE) score of 10 or greater, and be able to give informed consent.", "labels": [], "entities": [{"text": "Mini-Mental State Exam (MMSE) score", "start_pos": 232, "end_pos": 267, "type": "METRIC", "confidence": 0.7021159657410213}]}, {"text": "The dataset contains transcripts of verbal interviews with AD and related Dementia patients, including those with MCI (for further details see).", "labels": [], "entities": []}, {"text": "We used 43 transcriptions with MCI in addition to another 43 transcriptions sampled from 242 healthy elderly people to be used as the control group.", "labels": [], "entities": []}, {"text": "For this dataset, interviews were conducted in English and narrative speech was elicited using the Cookie Theft picture () from in Section A.1).", "labels": [], "entities": [{"text": "Cookie Theft picture", "start_pos": 99, "end_pos": 119, "type": "DATASET", "confidence": 0.8317765990893046}]}, {"text": "During the interview, patients were given the picture and were told to discuss everything they could see happening in the picture.", "labels": [], "entities": []}, {"text": "The patients' verbal utterances were recorded and then transcribed into the CHAT (Codes for the Human Analysis of Transcripts) transcription format.", "labels": [], "entities": []}, {"text": "We extracted the word-level transcript patient sentences from the CHAT files and discarded the annotations, as our goal was to create a fully automated system that does not require the input of a human annotator.", "labels": [], "entities": [{"text": "CHAT files", "start_pos": 66, "end_pos": 76, "type": "DATASET", "confidence": 0.8263078927993774}]}, {"text": "We automatically removed filled pauses such as uh, um , er , and ah (e.g. uh it seems to be summer out), short false starts (e.g. just t the ones ), and repetition (e.g. mother's finished certain of the the dishes ), as in ().", "labels": [], "entities": [{"text": "repetition", "start_pos": 153, "end_pos": 163, "type": "METRIC", "confidence": 0.9708970785140991}]}, {"text": "The control group had an average of 9.58 sentences per narrative, with each sentence having an average of 9.18 words; while the MCI group had an average of 10.97 sentences per narrative, with 10.33 words per sentence in average.", "labels": [], "entities": [{"text": "MCI group", "start_pos": 128, "end_pos": 137, "type": "DATASET", "confidence": 0.8952282667160034}]}, {"text": "The dataset examined in this study included 20 subjects with MCI and 20 normal elderly control subjects, as diagnosed at the Medical School of the University of S\u00e3o Paulo (FMUSP).", "labels": [], "entities": []}, {"text": "shows the demographic information of the two diagnostic groups, which were also used in  The criteria used to diagnose MCI came from.", "labels": [], "entities": [{"text": "diagnose MCI", "start_pos": 110, "end_pos": 122, "type": "TASK", "confidence": 0.7456712424755096}]}, {"text": "Diagnostics were carried out by a multidisciplinary team consisting of psychiatrists, geriatricians, neurologists, neuropsychologists, speech pathologists, and occupational therapists, by a criterion of consensus.", "labels": [], "entities": []}, {"text": "Inclusion criteria for the control group were elderlies with no cognitive deficits and preservation of functional capacity in everyday life.", "labels": [], "entities": []}, {"text": "The exclusion criteria for the normal group were: poorly controlled clinical diseases, sensitive deficits that were not being compensated for and interfered with the performance in tests, and other neurological or psychiatric diagnoses associated with dementia or cognitive deficits and use of medications in doses that affected cognition.", "labels": [], "entities": []}, {"text": "Speech narrative samples were elicited by having participants tell the Cinderella story; participants were given as much time as they needed to examine a picture book illustrating the story in Section A).", "labels": [], "entities": []}, {"text": "When each participant had finished looking at the pictures, the examiner asked the subject to tell the story in their own words, as in.", "labels": [], "entities": []}, {"text": "The time was recorded, but there was no limit imposed to the narrative length.", "labels": [], "entities": []}, {"text": "If the participant had difficulty initiating or continuing speech, or took along pause, an evaluator would use the stimulus question \"What happens next ?\", seeking to encourage the participant to continue his/her narrative.", "labels": [], "entities": []}, {"text": "When the subject was unable to proceed with the narrative, the examiner asked if he/she had finished the story and had something to add.", "labels": [], "entities": []}, {"text": "Each speech sample was recorded and then manually transcribed at the word level following the NURC/SP N.", "labels": [], "entities": [{"text": "NURC/SP N", "start_pos": 94, "end_pos": 103, "type": "DATASET", "confidence": 0.7537735402584076}]}, {"text": "338 EF and 331 D2 transcription norms 3 . Other tests were applied after the narrative, in the following sequence: phonemic verbal fluency test, action verbal fluency, Camel and Cactus test), and Boston Naming test), in order to diagnose the groups.", "labels": [], "entities": [{"text": "EF", "start_pos": 4, "end_pos": 6, "type": "METRIC", "confidence": 0.9378072619438171}, {"text": "Boston Naming test", "start_pos": 196, "end_pos": 214, "type": "DATASET", "confidence": 0.6708010137081146}]}, {"text": "Since our ultimate goal is to create a fully automated system that does not require the input of a human annotator, we manually segmented sentences to simulate a high-quality ASR transcript with sentence segmentation, and we automatically removed the disfluencies following the same guidelines of TalkBank project.", "labels": [], "entities": [{"text": "sentence segmentation", "start_pos": 195, "end_pos": 216, "type": "TASK", "confidence": 0.708385780453682}, {"text": "TalkBank project", "start_pos": 297, "end_pos": 313, "type": "DATASET", "confidence": 0.9332996904850006}]}, {"text": "However, other disfluencies (revisions, elaboration, paraphasias and comments about the task) were kept.", "labels": [], "entities": []}, {"text": "The control group had an average of 30.80 sentences per narrative, and each sentence averaged 12.17 words.", "labels": [], "entities": []}, {"text": "As for the MCI group, it had an average of 29.90 sentences per narrative, and each sentence averaged 13.03 words.", "labels": [], "entities": [{"text": "MCI group", "start_pos": 11, "end_pos": 20, "type": "DATASET", "confidence": 0.8179872035980225}]}, {"text": "We also evaluated a different version of the dataset used in, where narratives were manually annotated and revised to improve parsing results.", "labels": [], "entities": [{"text": "parsing", "start_pos": 126, "end_pos": 133, "type": "TASK", "confidence": 0.9653556942939758}]}, {"text": "The revision process was the following: (i) in the original transcript, segments with hesitations or repetitions of more than one word or segment of a single word were annotated to become a feature and then removed from the narrative to allow the extraction of features from parsing; (ii) empty emissions, which were comments unrelated to the topic of narration or confirmations, such as \"n\u00e9\" (alright), were also annotated and removed; (iii) prolongations of vowels, short pauses and long pauses were also annotated and removed; and (iv) omitted subjects in sentences were inserted.", "labels": [], "entities": []}, {"text": "In this revised dataset, the control group had an average of 45.10 sentences per narrative, and each sentence averaged 8.17 words.", "labels": [], "entities": []}, {"text": "The MCI group had an average of 31.40 sentences per narrative, with each sentence averaging 10.91 words.", "labels": [], "entities": [{"text": "MCI group", "start_pos": 4, "end_pos": 13, "type": "DATASET", "confidence": 0.9029463529586792}]}, {"text": "The subtest of immediate/delayed recall of narratives of the ABCD battery was administered to 23 participants with a diagnosis of MCI and 20 normal elderly control participants, as diagnosed at the Medical School of the University of S\u00e3o Paulo (FMUSP).", "labels": [], "entities": [{"text": "recall", "start_pos": 33, "end_pos": 39, "type": "METRIC", "confidence": 0.9031051993370056}]}, {"text": "MCI subjects produced 46 narratives while the control group produced 39 ones.", "labels": [], "entities": []}, {"text": "In order to carryout experiments with a balanced corpus, as with the previous two datasets, we excluded seven transcriptions from the MCI group.", "labels": [], "entities": [{"text": "MCI group", "start_pos": 134, "end_pos": 143, "type": "DATASET", "confidence": 0.9074705541133881}]}, {"text": "We used the automatic sentence segmentation method referred to as DeepBond () in the transcripts.", "labels": [], "entities": [{"text": "sentence segmentation", "start_pos": 22, "end_pos": 43, "type": "TASK", "confidence": 0.7300289571285248}]}, {"text": "The control group had an average of 5.23 sentences per narrative, with 11 words per sentence on average, and the MCI group had an average of 4.95 sentences per narrative, with an average of 12.04 words per sentence.", "labels": [], "entities": [{"text": "MCI group", "start_pos": 113, "end_pos": 122, "type": "DATASET", "confidence": 0.8553617298603058}]}, {"text": "Interviews were conducted in Portuguese and the subject listened to the examiner read a short narrative.", "labels": [], "entities": []}, {"text": "The subject then retold the narrative to the examiner twice: once immediately upon hearing it and again after a 30-minute delay (  All experiments were conducted using the Scikitlearn, with classifiers evaluated on the basis of classification accuracy i.e. the total proportion of narratives which were correctly classified.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 243, "end_pos": 251, "type": "METRIC", "confidence": 0.8000722527503967}]}, {"text": "The evaluation was performed using 5-fold cross-validation instead of the well-accepted 10-fold cross-validation because the datasets in our study were small and the test set would have shrunk, leading to less precise measurements of accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 234, "end_pos": 242, "type": "METRIC", "confidence": 0.9977344274520874}]}, {"text": "The threshold parameter was optimized with the best values being 0.7 in the Cookie Theft dataset and 0.4 in both the Cinderella and ABCD datasets.", "labels": [], "entities": [{"text": "Cookie Theft dataset", "start_pos": 76, "end_pos": 96, "type": "DATASET", "confidence": 0.8680568734804789}, {"text": "ABCD datasets", "start_pos": 132, "end_pos": 145, "type": "DATASET", "confidence": 0.8514764904975891}]}, {"text": "We used the model proposed by with default parameters (100 dimensional embeddings, context window equal to 5 and 5 epochs) to generate word embedding.", "labels": [], "entities": []}, {"text": "We trained the models in Portuguese and English Wikipedia dumps from October and November 2016 respectively.", "labels": [], "entities": []}, {"text": "The accuracy in classification is given in.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 4, "end_pos": 12, "type": "METRIC", "confidence": 0.9997486472129822}, {"text": "classification", "start_pos": 16, "end_pos": 30, "type": "TASK", "confidence": 0.9317054152488708}]}, {"text": "CN, CNE, LM, and BoW denote, respectively, complex networks, complex network enriched with embedding, linguistic metrics and Bag of Words, and CNE-LM, CNE-BoW, LMBoW and CNE-LM-BoW refer to combinations of the feature spaces (multiview learning), using the majority vote.", "labels": [], "entities": []}, {"text": "Cells with the \"-\" sign mean that it was not possible to apply majority voting because there were two classifiers.", "labels": [], "entities": []}, {"text": "The last line represents the use of an ensemble of machine learning algorithms, in which the combination used was the majority voting in both ensemble and multiview learning.", "labels": [], "entities": []}, {"text": "In general, CNE outperforms the approach using only complex networks (CN), while SVM (Linear or RBF kernel) provides higher accuracy than other machine learning algorithms.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 124, "end_pos": 132, "type": "METRIC", "confidence": 0.9963163137435913}]}, {"text": "The results for the three datasets show that characterizing transcriptions into complex networks is competitive with other traditional methods, such as the use of linguistic metrics.", "labels": [], "entities": [{"text": "characterizing transcriptions", "start_pos": 45, "end_pos": 74, "type": "TASK", "confidence": 0.8927622735500336}]}, {"text": "In fact, among the three types of features, using enriched networks (CNE) provided the highest accuracies in two datasets (Cookie Theft and original Cinderella).", "labels": [], "entities": [{"text": "accuracies", "start_pos": 95, "end_pos": 105, "type": "METRIC", "confidence": 0.9665883183479309}]}, {"text": "For the ABCD dataset, which contains short narratives, the small length of the transcriptions may have had an effect, since BoW features led to the highest accuracy.", "labels": [], "entities": [{"text": "ABCD dataset", "start_pos": 8, "end_pos": 20, "type": "DATASET", "confidence": 0.9632148742675781}, {"text": "accuracy", "start_pos": 156, "end_pos": 164, "type": "METRIC", "confidence": 0.9961801767349243}]}, {"text": "In the case of the revised Cinderella dataset, segmented into sentences and capitalized as reported in, shows that the manual revision was an important factor, since the highest accuracies were obtained with the approach based on linguistic metrics (LM).", "labels": [], "entities": [{"text": "Cinderella dataset", "start_pos": 27, "end_pos": 45, "type": "DATASET", "confidence": 0.6774863749742508}, {"text": "accuracies", "start_pos": 178, "end_pos": 188, "type": "METRIC", "confidence": 0.9591687917709351}]}, {"text": "However, this process of manually removing disfluencies demands time; therefore it is not practical for large-scale assessments.", "labels": [], "entities": []}, {"text": "Ensemble and multi-view learning were helpful for the Cookie Theft dataset, in which multi-view learning achieved the highest accuracy (65% of accuracy for narrative texts, a 3% of improvement compared to the best individual classifier).", "labels": [], "entities": [{"text": "Cookie Theft dataset", "start_pos": 54, "end_pos": 74, "type": "DATASET", "confidence": 0.7672217885653178}, {"text": "accuracy", "start_pos": 126, "end_pos": 134, "type": "METRIC", "confidence": 0.9980911612510681}, {"text": "accuracy", "start_pos": 143, "end_pos": 151, "type": "METRIC", "confidence": 0.9971727132797241}]}, {"text": "However, neither multi-view or ensemble learning enhanced accuracy in the Cinderella dataset, where SVM-RBF with CNE space achieved the highest accuracy (65%).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 58, "end_pos": 66, "type": "METRIC", "confidence": 0.9991040825843811}, {"text": "Cinderella dataset", "start_pos": 74, "end_pos": 92, "type": "DATASET", "confidence": 0.8870235681533813}, {"text": "accuracy", "start_pos": 144, "end_pos": 152, "type": "METRIC", "confidence": 0.9971325397491455}]}, {"text": "For the ABCD dataset, multiview CNE-LM-BoW with SVM-RBF and KNN classifiers improved the accuracy to 4% and 2%, respectively.", "labels": [], "entities": [{"text": "ABCD dataset", "start_pos": 8, "end_pos": 20, "type": "DATASET", "confidence": 0.9121699929237366}, {"text": "accuracy", "start_pos": 89, "end_pos": 97, "type": "METRIC", "confidence": 0.9995542168617249}]}, {"text": "Somewhat surprising were the results of SVM with linear kernel in BoW feature space (75% of accuracy).", "labels": [], "entities": [{"text": "BoW", "start_pos": 66, "end_pos": 69, "type": "DATASET", "confidence": 0.8965570330619812}, {"text": "accuracy", "start_pos": 92, "end_pos": 100, "type": "METRIC", "confidence": 0.9992208480834961}]}], "tableCaptions": [{"text": " Table 1 shows the demographic informa- tion for the two diagnostic groups.", "labels": [], "entities": []}, {"text": " Table 2: Demographic information of participants  in the Cinderella dataset.", "labels": [], "entities": [{"text": "Cinderella dataset", "start_pos": 58, "end_pos": 76, "type": "DATASET", "confidence": 0.9228087067604065}]}, {"text": " Table 3: Demographic information of participants  in the ABCD dataset.", "labels": [], "entities": [{"text": "ABCD dataset", "start_pos": 58, "end_pos": 70, "type": "DATASET", "confidence": 0.9502183198928833}]}, {"text": " Table 4: Classification accuracy achieved on Cookie Theft dataset.", "labels": [], "entities": [{"text": "Classification", "start_pos": 10, "end_pos": 24, "type": "TASK", "confidence": 0.8464659452438354}, {"text": "accuracy", "start_pos": 25, "end_pos": 33, "type": "METRIC", "confidence": 0.9811958074569702}, {"text": "Cookie Theft dataset", "start_pos": 46, "end_pos": 66, "type": "DATASET", "confidence": 0.8764820297559103}]}, {"text": " Table 6: Classification accuracy achieved on ABCD dataset.", "labels": [], "entities": [{"text": "Classification", "start_pos": 10, "end_pos": 24, "type": "TASK", "confidence": 0.9176544547080994}, {"text": "accuracy", "start_pos": 25, "end_pos": 33, "type": "METRIC", "confidence": 0.9727129340171814}, {"text": "ABCD dataset", "start_pos": 46, "end_pos": 58, "type": "DATASET", "confidence": 0.9737430512905121}]}, {"text": " Table 7: Classification accuracy achieved on Cin- derella dataset manually processed to revise non- grammatical sentences.", "labels": [], "entities": [{"text": "Classification", "start_pos": 10, "end_pos": 24, "type": "TASK", "confidence": 0.880585789680481}, {"text": "accuracy", "start_pos": 25, "end_pos": 33, "type": "METRIC", "confidence": 0.9783782362937927}, {"text": "Cin- derella dataset", "start_pos": 46, "end_pos": 66, "type": "DATASET", "confidence": 0.6220921725034714}]}]}