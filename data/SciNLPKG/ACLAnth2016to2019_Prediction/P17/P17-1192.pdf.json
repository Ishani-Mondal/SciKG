{"title": [{"text": "Identifying 1950s American Jazz Musicians: Fine-Grained IsA Extraction via Modifier Composition", "labels": [], "entities": [{"text": "Identifying 1950s American Jazz Musicians", "start_pos": 0, "end_pos": 41, "type": "TASK", "confidence": 0.8335480690002441}, {"text": "IsA Extraction", "start_pos": 56, "end_pos": 70, "type": "TASK", "confidence": 0.9171279966831207}]}], "abstractContent": [{"text": "We present a method for populating fine-grained classes (e.g., \"1950s Amer-ican jazz musicians\") with instances (e.g., Charles Mingus).", "labels": [], "entities": [{"text": "Amer-ican jazz musicians", "start_pos": 70, "end_pos": 94, "type": "DATASET", "confidence": 0.8607466419537863}]}, {"text": "While state-of-the-art methods tend to treat class labels as single lexical units, the proposed method considers each of the individual modifiers in the class label relative to the head.", "labels": [], "entities": []}, {"text": "An evaluation on the task of reconstructing Wikipedia category pages demonstrates a >10 point increase in AUC, over a strong baseline relying on widely-used Hearst patterns.", "labels": [], "entities": [{"text": "reconstructing Wikipedia category pages", "start_pos": 29, "end_pos": 68, "type": "TASK", "confidence": 0.5965578407049179}, {"text": "AUC", "start_pos": 106, "end_pos": 109, "type": "METRIC", "confidence": 0.9987402558326721}]}], "introductionContent": [{"text": "The majority of approaches () for extracting IsA relations from text rely on lexical patterns as the primary signal of whether an instance belongs to a class.", "labels": [], "entities": [{"text": "extracting IsA relations from text", "start_pos": 34, "end_pos": 68, "type": "TASK", "confidence": 0.8401487588882446}]}, {"text": "For example, observing a pattern like \"X such as Y\" is a strong indication that Y (e.g., \"Charles Mingus\") is an instance of class X (e.g., \"musician\").", "labels": [], "entities": []}, {"text": "Methods based on these \"Hearst patterns\" assume that class labels can be treated as atomic lexicalized units.", "labels": [], "entities": []}, {"text": "This assumption has several significant weakness.", "labels": [], "entities": []}, {"text": "First, in order to recognize an instance of a class, these patternbased methods require that the entire class label be observed verbatim in text.", "labels": [], "entities": []}, {"text": "The requirement is reasonable for class labels containing a single word, but in practice, there are many possible fine-grained classes: not only \"musicians\" but also \"1950s American jazz musicians\".", "labels": [], "entities": []}, {"text": "The probability that a given label will appear in its entirety within one of the expected patterns is very low, even in large * Contributed during an internship at Google.", "labels": [], "entities": []}, {"text": "Second, when class labels are treated as though they cannot be decomposed, every class label must be modeled independently, even those containing overlapping words (\"American jazz musician\", \"French jazz musician\").", "labels": [], "entities": []}, {"text": "As a result, the number of meaning representations to be learned is exponential in the length of the class label, and quickly becomes intractable.", "labels": [], "entities": []}, {"text": "Thus, compositional models of taxonomic relations are necessary for better language understanding.", "labels": [], "entities": [{"text": "language understanding", "start_pos": 75, "end_pos": 97, "type": "TASK", "confidence": 0.7137845158576965}]}, {"text": "We introduce a compositional approach for reasoning about fine-grained class labels.", "labels": [], "entities": []}, {"text": "Our approach is based on the notion from formal semantics, in which modifiers (\"1950s\") correspond to properties that differentiate instances of a subclass (\"1950s musicians\") from instances of the superclass (\"musicians\").", "labels": [], "entities": []}, {"text": "Our method consists of two stages: interpreting each modifier relative to the head (\"musicians active during 1950s\"), and using the interpretations to identify instances of the class from text ().", "labels": [], "entities": []}, {"text": "Our main contributions are: 1) a compositional method for IsA extraction, which in-volves a novel application of noun-phrase paraphrasing methods to the task of semantic taxonomy induction and 2) the operationalization of a formal semantics framework to address two aspects of semantics that are often kept separate in NLP: assigning intrinsic \"meaning\" to a phrase, and reasoning about that phrase in a truth-theoretic context.", "labels": [], "entities": [{"text": "IsA extraction", "start_pos": 58, "end_pos": 72, "type": "TASK", "confidence": 0.9646629393100739}, {"text": "semantic taxonomy induction", "start_pos": 161, "end_pos": 188, "type": "TASK", "confidence": 0.655047744512558}]}], "datasetContent": [{"text": "We evaluate our models on their ability to return correct instances for arbitrary class labels.", "labels": [], "entities": []}, {"text": "As a source of evaluation data, we use Wikipedia category pages (e.g., http://en.wikipedia.org/wiki/Category: Pakistani film actresses).", "labels": [], "entities": []}, {"text": "These are pages in which the title is the name of the category (\"pakistani film actresses\") and the body is a manually curated list of links to other pages that fall under the category.", "labels": [], "entities": []}, {"text": "We measure the precision and recall of each method for discovering the instances listed on these pages given the page title (henceforth \"class label\").", "labels": [], "entities": [{"text": "precision", "start_pos": 15, "end_pos": 24, "type": "METRIC", "confidence": 0.9995623230934143}, {"text": "recall", "start_pos": 29, "end_pos": 35, "type": "METRIC", "confidence": 0.9991872906684875}]}, {"text": "We collect the titles of all Wikipedia category pages, removing those in which the last word is capitalized or which contain fewer than three words.", "labels": [], "entities": []}, {"text": "These heuristics are intended to retain compositional titles in which the head is a single common noun.", "labels": [], "entities": []}, {"text": "We also remove 6 Also tried minimum, but mean gave better results.", "labels": [], "entities": []}, {"text": "Feature templates in supplementary material.", "labels": [], "entities": []}, {"text": "Evaluation Set: Examples of Class Labels UniformSet: 2008 california wildfires \u00b7 australian army chaplains \u00b7 australian boy bands \u00b7 canadian military nurses \u00b7 canberra urban places \u00b7 cellular automaton rules \u00b7 chinese rice dishes \u00b7 coldplay concert tours \u00b7 daniel libeskind designs \u00b7 economic stimulus programs \u00b7 german film critics \u00b7 invasive amphibian species \u00b7 latin political phrases \u00b7 log flume rides \u00b7 malayalam short stories \u00b7 pakistani film actresses \u00b7 puerto rican sculptors \u00b7 string theory books WeightedSet: ancient greek physicists \u00b7 art deco sculptors \u00b7 audio engineering schools \u00b7 ballet training methods \u00b7 bally pinball machines \u00b7 british rhythmic gymnasts \u00b7 calgary flames owners \u00b7 canadian rock climbers \u00b7 canon l-series lenses \u00b7 emi classics artists \u00b7 free password managers \u00b7 georgetown university publications \u00b7 grapefruit league venues \u00b7 liz claiborne subsidiaries \u00b7 miss usa 2000 delegates \u00b7 new zealand illustrators \u00b7 russian art critics: Examples of class labels from evaluation sets.", "labels": [], "entities": []}, {"text": "any titles that contain links to sub-categories.", "labels": [], "entities": []}, {"text": "This is to favor fine-grained classes (\"pakistani film actresses\") over coarse-grained ones (\"film actresses\").", "labels": [], "entities": []}, {"text": "We perform heuristic modifier chunking in order to group together multiword modifiers (e.g., \"puerto rican\"); for details, see supplementary material.", "labels": [], "entities": []}, {"text": "From the resulting list of class labels, we draw two samples of 100 labels each, enforcing that no H appear as the head of more than three class labels per sample.", "labels": [], "entities": []}, {"text": "The first sample is chosen uniformly at random (denoted UniformSet).", "labels": [], "entities": []}, {"text": "The second (WeightedSet) is weighted so that the probability of drawing M 1 . .", "labels": [], "entities": []}, {"text": "Mk H is proportional to the total number of class labels in which H appears as the head.", "labels": [], "entities": [{"text": "Mk H", "start_pos": 0, "end_pos": 4, "type": "METRIC", "confidence": 0.9303472638130188}]}, {"text": "These different evaluation sets 8 are intended to evaluate performance on the head versus the tail of class label distribution, since information retrieval methods often perform differently on different parts of the distribution.", "labels": [], "entities": []}, {"text": "On average, there are 17 instances per category in UniformSet and 19 in WeightedSet.", "labels": [], "entities": []}, {"text": "gives examples of class labels.", "labels": [], "entities": []}, {"text": "We implement two baselines using our IsA repository (O as defined in Section 4.1).", "labels": [], "entities": [{"text": "IsA repository", "start_pos": 37, "end_pos": 51, "type": "DATASET", "confidence": 0.704124242067337}]}, {"text": "Our simplest baseline ignores modifiers altogether, and simply assumes that any instance of H is an instance of M H, regardless of M . In this case the confidence value fore, M H is equivalent to that fore, H. We refer to this baseline simply as Baseline.", "labels": [], "entities": []}, {"text": "Our second, stronger baseline uses the IsA repository directly to identify instances of the finegrained class C = M 1 . .", "labels": [], "entities": []}, {"text": "Mk H. That is, we consider e to bean instance of the class if e, C \u2208 O, meaning the entire class label appeared in a source sentence matching some Hearst pattern.", "labels": [], "entities": []}, {"text": "We refer to this baseline as Hearst.", "labels": [], "entities": [{"text": "Hearst", "start_pos": 29, "end_pos": 35, "type": "DATASET", "confidence": 0.801404595375061}]}, {"text": "The weight used to rank the candidate instances is the confidence value assigned by the Hearst pattern extraction (Section 4.2).", "labels": [], "entities": [{"text": "Hearst pattern extraction", "start_pos": 88, "end_pos": 113, "type": "TASK", "confidence": 0.5784360269705454}]}, {"text": "As a baseline compositional model, we augment the Hearst baseline via set intersection.", "labels": [], "entities": [{"text": "Hearst baseline", "start_pos": 50, "end_pos": 65, "type": "DATASET", "confidence": 0.8121359050273895}]}, {"text": "Specifically, fora class C = M 1 . .", "labels": [], "entities": []}, {"text": "Mk H, if each of the M i H appears in O independently, we take the instances of C to be the intersection of the instances of each of the M i H.", "labels": [], "entities": []}, {"text": "We assign the weight of an instance e to be the sum of the weights associated with each independent modifier.", "labels": [], "entities": []}, {"text": "We refer to this method as Hearst\u2229.", "labels": [], "entities": []}, {"text": "It is roughly equivalent to).", "labels": [], "entities": []}, {"text": "We contrast it with our proposed model, which recognizes instances of a fine-grained class by 1) assigning a meaning to each modifier in the form of a property profile and 2) checking whether a candidate instance exhibits these properties.", "labels": [], "entities": []}, {"text": "We refer to the versions of our method as Mods H and Mods I , as described in Section 5.", "labels": [], "entities": []}, {"text": "When relevant, we use \"raw\" to refer to the version in which instances are ranked using raw weights and \"RR\" to refer to the version in which instances are ranked using logistic regression (Section 5).", "labels": [], "entities": [{"text": "RR", "start_pos": 105, "end_pos": 107, "type": "METRIC", "confidence": 0.9822477698326111}]}, {"text": "We also try using the proposed methods to extend rather than replace the Hearst baseline.", "labels": [], "entities": [{"text": "Hearst baseline", "start_pos": 73, "end_pos": 88, "type": "DATASET", "confidence": 0.8684355318546295}]}, {"text": "We combine predictions by merging the ranked lists produced by each system: i.e. the score of an instance is the inverse of the sum of its ranks in each of the input lists.", "labels": [], "entities": []}, {"text": "If an instance does not appear at all in an input list, its rank in that list is set to a large constant value.", "labels": [], "entities": []}, {"text": "We refer to these combination systems as Hearst+Mods H and Hearst+Mods I .", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 4: Instances extracted for several fine-grained classes from Wikipedia. Lists shown are  from Mods I . Instances in italics were also returned by Hearst\u2229. Strikethrough denotes incorrect.", "labels": [], "entities": [{"text": "Strikethrough", "start_pos": 162, "end_pos": 175, "type": "METRIC", "confidence": 0.9518309235572815}]}, {"text": " Table 5: Coverage and precision for populat- ing Wikipedia category pages with instances.", "labels": [], "entities": [{"text": "precision", "start_pos": 23, "end_pos": 32, "type": "METRIC", "confidence": 0.9993332028388977}]}, {"text": " Table 6: P@10 before vs. after re-annotation;  Wikipedia underestimates true precision.", "labels": [], "entities": [{"text": "P", "start_pos": 10, "end_pos": 11, "type": "METRIC", "confidence": 0.9836576581001282}, {"text": "Wikipedia", "start_pos": 48, "end_pos": 57, "type": "DATASET", "confidence": 0.9289358258247375}, {"text": "precision", "start_pos": 78, "end_pos": 87, "type": "METRIC", "confidence": 0.8643836975097656}]}, {"text": " Table 7: Recall of instances on Wikipedia cat- egory pages, measured against the full set of  instances from all pages in sample. AUC cap- tures tradeoff between true and false positives.", "labels": [], "entities": [{"text": "Recall", "start_pos": 10, "end_pos": 16, "type": "METRIC", "confidence": 0.9529119729995728}, {"text": "AUC cap- tures", "start_pos": 131, "end_pos": 145, "type": "METRIC", "confidence": 0.9564000219106674}]}]}