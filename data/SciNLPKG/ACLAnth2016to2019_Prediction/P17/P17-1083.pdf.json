{"title": [{"text": "Tandem Anchoring: a Multiword Anchor Approach for Interactive Topic Modeling", "labels": [], "entities": [{"text": "Tandem Anchoring", "start_pos": 0, "end_pos": 16, "type": "TASK", "confidence": 0.8334652781486511}, {"text": "Interactive Topic Modeling", "start_pos": 50, "end_pos": 76, "type": "TASK", "confidence": 0.6252948343753815}]}], "abstractContent": [{"text": "Interactive topic models are powerful tools for understanding large collections of text.", "labels": [], "entities": [{"text": "understanding large collections of text", "start_pos": 48, "end_pos": 87, "type": "TASK", "confidence": 0.7437624454498291}]}, {"text": "However, existing sampling-based interactive topic modeling approaches scale poorly to large data sets.", "labels": [], "entities": [{"text": "sampling-based interactive topic modeling", "start_pos": 18, "end_pos": 59, "type": "TASK", "confidence": 0.6373446360230446}]}, {"text": "Anchor methods , which use a single word to uniquely identify a topic, offer the speed needed for interactive work but lack both a mechanism to inject prior knowledge and lack the intuitive semantics needed for user-facing applications.", "labels": [], "entities": []}, {"text": "We propose combinations of words as anchors, going beyond existing single word anchor algorithms-an approach we call \"Tandem Anchors\".", "labels": [], "entities": []}, {"text": "We begin with a synthetic investigation of this approach then apply the approach to interactive topic modeling in a user study and compare it to interactive and non-interactive approaches.", "labels": [], "entities": [{"text": "interactive topic modeling", "start_pos": 84, "end_pos": 110, "type": "TASK", "confidence": 0.7267570296923319}]}, {"text": "Tandem anchors are faster and more intuitive than existing interactive approaches.", "labels": [], "entities": [{"text": "Tandem anchors", "start_pos": 0, "end_pos": 14, "type": "TASK", "confidence": 0.8326618671417236}]}, {"text": "Topic models distill large collections of text into topics, giving a high-level summary of the thematic structure of the data without manual annotation.", "labels": [], "entities": []}, {"text": "In addition to facilitating discovery of topical trends (Gardner et al., 2010), topic modeling is used fora wide variety of problems including document classification (Rubin et al., 2012), information retrieval (Wei and Croft, 2006), author identification (Rosen-Zvi et al., 2004), and sentiment analysis (Titov and McDonald, 2008).", "labels": [], "entities": [{"text": "topic modeling", "start_pos": 80, "end_pos": 94, "type": "TASK", "confidence": 0.8019230365753174}, {"text": "document classification", "start_pos": 143, "end_pos": 166, "type": "TASK", "confidence": 0.7603879272937775}, {"text": "information retrieval", "start_pos": 189, "end_pos": 210, "type": "TASK", "confidence": 0.8126553595066071}, {"text": "author identification", "start_pos": 234, "end_pos": 255, "type": "TASK", "confidence": 0.8578803837299347}, {"text": "sentiment analysis", "start_pos": 286, "end_pos": 304, "type": "TASK", "confidence": 0.9588896036148071}]}, {"text": "However , the most compelling use of topic models is to help users understand large datasets (Chuang et al., 2012).", "labels": [], "entities": []}, {"text": "Interactive topic modeling (Hu et al., 2014) allows non-experts to refine automatically generated topics, making topic models less of a \"take it or leave it\" proposition.", "labels": [], "entities": [{"text": "Interactive topic modeling", "start_pos": 0, "end_pos": 26, "type": "TASK", "confidence": 0.583064079284668}]}, {"text": "Including humans input during training improves the quality of the model and allows users to guide topics in a specific way, custom tailoring the model fora specific downstream task or analysis.", "labels": [], "entities": []}, {"text": "The downside is that interactive topic model-ing is slow-algorithms typically scale with the size of the corpus-and requires non-intuitive information from the user in the form of must-link and cannot-link constraints (Andrzejewski et al., 2009).", "labels": [], "entities": []}, {"text": "We address these shortcomings of interactive topic modeling by using an interactive version of the anchor words algorithm for topic models.", "labels": [], "entities": [{"text": "topic modeling", "start_pos": 45, "end_pos": 59, "type": "TASK", "confidence": 0.710040420293808}]}, {"text": "The anchor algorithm (Arora et al., 2013) is an alternative topic modeling algorithm which scales with the number of unique word types in the data rather than the number of documents or tokens (Section 1).", "labels": [], "entities": []}, {"text": "This makes the anchor algorithm fast enough for interactive use, even in web-scale document collections.", "labels": [], "entities": []}, {"text": "A drawback of the anchor method is that anchor words-words that have high probability of being in a single topic-are not intuitive.", "labels": [], "entities": []}, {"text": "We extend the anchor algorithm to use multiple anchor words in tandem (Section 2).", "labels": [], "entities": []}, {"text": "Tandem anchors not only improve interactive refinement, but also make the underlying anchor-based method more intuitive.", "labels": [], "entities": [{"text": "Tandem anchors", "start_pos": 0, "end_pos": 14, "type": "TASK", "confidence": 0.657414585351944}]}, {"text": "For interactive topic modeling, tandem anchors produce higher quality topics than single word anchors (Section 3).", "labels": [], "entities": [{"text": "interactive topic modeling", "start_pos": 4, "end_pos": 30, "type": "TASK", "confidence": 0.6330770154794058}]}, {"text": "Tandem anchors provide a framework for fast interactive topic model-ing: users improve and refine an existing model through multiword anchors (Section 4).", "labels": [], "entities": []}, {"text": "Compared to existing methods such as Interactive Topic Models (Hu et al., 2014), our method is much faster.", "labels": [], "entities": []}], "introductionContent": [], "datasetContent": [{"text": "We use the well-known 20 Newsgroups dataset (20NEWS) used in previous interactive topic modeling work: 18,846 Usenet postings from 20 different newgroups in the early 1990s.", "labels": [], "entities": [{"text": "20 Newsgroups dataset (20NEWS)", "start_pos": 22, "end_pos": 52, "type": "DATASET", "confidence": 0.8040115982294083}]}, {"text": "We remove the newsgroup headers from each message, which contain the newsgroup names, but otherwise left messages intact with any footers or quotes.", "labels": [], "entities": []}, {"text": "We then remove stopwords and words which appear in fewer than 100 documents or more than 1,500 documents.", "labels": [], "entities": []}, {"text": "To seed the tandem anchors, we use the titles of newsgroups.", "labels": [], "entities": []}, {"text": "To build each multiword anchor facet, we split the title on word boundaries and expand any abbreviations or acronyms.", "labels": [], "entities": []}, {"text": "For example, the newsgroup title 'comp.os.mswindows.misc' becomes {\"computer\", \"operating\", \"system\", \"microsoft\", \"windows\", \"miscellaneous\"}.", "labels": [], "entities": []}, {"text": "We do not fully specify the topic; the title gives some intuition, but the topic modeling algorithm must still recover the complete topic-word distributions.", "labels": [], "entities": []}, {"text": "This is akin to knowing the names of the categories used but nothing else.", "labels": [], "entities": []}, {"text": "Critically, the topic modeling algorithm has no knowledge of document-label relationships.", "labels": [], "entities": [{"text": "topic modeling", "start_pos": 16, "end_pos": 30, "type": "TASK", "confidence": 0.8205813765525818}]}, {"text": "Our first evaluation is a classification task to predict documents' newsgroup membership.", "labels": [], "entities": []}, {"text": "Thus, we do not aim for state-of-the-art accuracy, 2 but the experiment shows title-based tandem anchors yield topics closer to the underlying classes than Gram-Schmidt anchors.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 41, "end_pos": 49, "type": "METRIC", "confidence": 0.9982182383537292}]}, {"text": "After randomly splitting the data into test and training sets we learn topics from the test data using both the title-based tandem anchors and the Gram-Schmidt single word anchors.", "labels": [], "entities": []}, {"text": "For multiword anchors, we use each of the combiner functions from Section 2.2.", "labels": [], "entities": [{"text": "multiword anchors", "start_pos": 4, "end_pos": 21, "type": "TASK", "confidence": 0.7880419790744781}]}, {"text": "The anchor algorithm only gives the topic-word distributions and not word-level topic assignments, so we infer token-level topic assignments using LDA Latent Dirichlet Allocation () with fixed topics discovered by the anchor method.", "labels": [], "entities": []}, {"text": "We use our own implementation of Gibbs sampling with fixed topics and asymmetric documenttopic Dirichlet prior with concentration \u03b1 = .01.", "labels": [], "entities": []}, {"text": "Since the topics are fixed, this inference is very fast and can be parallelized on a per-document basis.", "labels": [], "entities": []}, {"text": "We then train a hinge-loss linear classifier on the newsgroup labels using Vowpal Wabbit with topic-word pairs as features.", "labels": [], "entities": [{"text": "Vowpal Wabbit", "start_pos": 75, "end_pos": 88, "type": "DATASET", "confidence": 0.9382306933403015}]}, {"text": "Finally, we infer topic assignments in the test data and evaluate the classification using those topic-word features.", "labels": [], "entities": []}, {"text": "For both training and test, we exclude words outside the LDA vocabulary.", "labels": [], "entities": [{"text": "LDA vocabulary", "start_pos": 57, "end_pos": 71, "type": "DATASET", "confidence": 0.7550771236419678}]}, {"text": "The topics created from multiword anchor facets are more accurate than Gram-Schmidt topics).", "labels": [], "entities": []}, {"text": "This is true regardless of the combiner function.", "labels": [], "entities": [{"text": "combiner", "start_pos": 31, "end_pos": 39, "type": "METRIC", "confidence": 0.9729903340339661}]}, {"text": "However, harmonic mean is more accurate than the other functions.", "labels": [], "entities": []}, {"text": "Since 20NEWS has twenty classes, accuracy alone does not capture confusion between closely related newsgroups.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 33, "end_pos": 41, "type": "METRIC", "confidence": 0.9992924928665161}]}, {"text": "For example, accuracy penalizes a classifier just as much for labeling a document from 'rec.sport.baseball' with 'rec.sport.hockey' as with 'alt.atheism' despite the similarity between sports newsgroups.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 13, "end_pos": 21, "type": "METRIC", "confidence": 0.9971565008163452}]}, {"text": "Consequently, after building a confusion matrix between the predicted and true classes, external clustering metrics reveal confusion between classes.", "labels": [], "entities": []}, {"text": "The first clustering metric is the adjusted Rand index, which is akin to accuracy for clustering, as it gives the percentage of correct pairing decisions from a reference clustering.", "labels": [], "entities": [{"text": "Rand index", "start_pos": 44, "end_pos": 54, "type": "METRIC", "confidence": 0.9035997986793518}, {"text": "accuracy", "start_pos": 73, "end_pos": 81, "type": "METRIC", "confidence": 0.999116837978363}]}, {"text": "Adjusted Rand index (ARI) also accounts for chance groupings of documents.", "labels": [], "entities": [{"text": "Adjusted Rand index (ARI)", "start_pos": 0, "end_pos": 25, "type": "METRIC", "confidence": 0.9080717861652374}]}, {"text": "Next we use F-measure, which also considers pairwise groups, balancing the contribution of false negatives, but without the true negatives.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 12, "end_pos": 21, "type": "METRIC", "confidence": 0.9419801235198975}]}, {"text": "Finally, we use variation of information (VI).", "labels": [], "entities": []}, {"text": "This metric measures the amount of information lost by switching from the gold standard labels to the predicted labels (Meil\u02d8 a, 2003).", "labels": [], "entities": []}, {"text": "Since we are measuring the amount of information lost, lower variation of information is better.", "labels": [], "entities": [{"text": "variation", "start_pos": 61, "end_pos": 70, "type": "METRIC", "confidence": 0.9661465287208557}]}, {"text": "Based on these clustering metrics, tandem anchors can yield superior topics to those created using single word anchors.", "labels": [], "entities": []}, {"text": "As with accuracy, this is true regardless of which combination function we use.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 8, "end_pos": 16, "type": "METRIC", "confidence": 0.9993923902511597}]}, {"text": "Furthermore, harmonic mean produces the least confusion between classes.", "labels": [], "entities": []}, {"text": "The final evaluation is topic coherence by, which measures whether the topics make sense, and correlates with human judgments of topic quality.", "labels": [], "entities": []}, {"text": "Given V , the set of then most probable words of a topic, coherence is where D(v 1 , v 2 ) is the co-document frequency of Figure 1: Using metadata can improve anchor-based topic models.", "labels": [], "entities": []}, {"text": "For all metrics, the unsupervised Gram-Schmidt anchors do worse than creating anchors based on Newsgroup titles (for all metrics except VI, higher is better).", "labels": [], "entities": []}, {"text": "For coherence, Gram-Schmidt does better than two functions for combining anchor words, but not the element-wise minor harmonic mean.", "labels": [], "entities": []}, {"text": "word types v 1 and v 2 , and D(v 2 ) is the document frequency of word type v 2 . A smoothing parameter prevents zero logarithms.", "labels": [], "entities": [{"text": "D(v 2 )", "start_pos": 29, "end_pos": 36, "type": "METRIC", "confidence": 0.9137964725494385}]}, {"text": "Although title-based anchor facets produce better classification features, topics from Gram-Schmidt anchors have better coherence than title-based anchors with the vector average or the or-operator.", "labels": [], "entities": []}, {"text": "However, when using the harmonic mean combiner, title-based anchors produce the most human interpretable topics.", "labels": [], "entities": []}, {"text": "Harmonic mean beats other combiner functions because it is robust to ambiguous or irrelevant term cooccurrences an anchor facet.", "labels": [], "entities": []}, {"text": "Both the vector average and the or-operator are swayed by large outliers, making them sensitive to ambiguous terms in an anchor facet.", "labels": [], "entities": []}, {"text": "Element-wise min also has this robustness, but harmonic mean is also able to better characterize anchor facets as it has more centralizing tendency than the min.", "labels": [], "entities": []}], "tableCaptions": []}