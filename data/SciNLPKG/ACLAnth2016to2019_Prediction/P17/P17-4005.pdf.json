{"title": [{"text": "ESTEEM: A Novel Framework for Qualitatively Evaluating and Visualizing Spatiotemporal Embeddings in Social Media", "labels": [], "entities": [{"text": "ESTEEM", "start_pos": 0, "end_pos": 6, "type": "DATASET", "confidence": 0.7987295389175415}, {"text": "Qualitatively Evaluating and Visualizing Spatiotemporal Embeddings in Social Media", "start_pos": 30, "end_pos": 112, "type": "TASK", "confidence": 0.7597463197178311}]}], "abstractContent": [{"text": "Analyzing and visualizing large amounts of social media communications and contrasting short-term conversation changes overtime and geolocations is extremely important for commercial and government applications.", "labels": [], "entities": []}, {"text": "Earlier approaches for large-scale text stream summarization used dynamic topic models and trending words.", "labels": [], "entities": [{"text": "text stream summarization", "start_pos": 35, "end_pos": 60, "type": "TASK", "confidence": 0.598868856827418}]}, {"text": "Instead, we rely on text embeddings-low-dimensional word representations in a continuous vector space where similar words are embedded nearby each other.", "labels": [], "entities": []}, {"text": "This paper presents ESTEEM, 1 a novel tool for visualizing and evaluating spa-tiotemporal embeddings learned from streaming social media texts.", "labels": [], "entities": []}, {"text": "Our tool allows users to monitor and analyze query words and their closest neighbors with an interactive interface.", "labels": [], "entities": []}, {"text": "We used state-of-the-art techniques to learn embeddings and developed a visualization to represent dynamically changing relations between words in social media overtime and other dimensions.", "labels": [], "entities": []}, {"text": "This is the first interactive visualization of streaming text representations learned from social media texts that also allows users to contrast differences across multiple dimensions of the data.", "labels": [], "entities": []}], "introductionContent": [], "datasetContent": [{"text": "There are two principle ways one can evaluate embeddings: (a) intrinsically and (b) extrinsically.", "labels": [], "entities": []}, {"text": "(a) Intrinsic evaluations directly test syntactic or semantic relationships between the words, and rely on existing NLP resources e.g., WordNet and subjective human judgements e.g., crowdsourcing.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 136, "end_pos": 143, "type": "DATASET", "confidence": 0.9539064764976501}]}, {"text": "(b) Extrinsic methods evaluate word vectors by measuring their performance when used for downstream NLP tasks e.g., dependency parsing, named entity recognition ().", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 116, "end_pos": 134, "type": "TASK", "confidence": 0.844426840543747}, {"text": "named entity recognition", "start_pos": 136, "end_pos": 160, "type": "TASK", "confidence": 0.6086092193921407}]}, {"text": "Recent work suggests that intrinsic and extrinsic measures correlate poorly with one another ().", "labels": [], "entities": []}, {"text": "In many cases we want an embedding not just to capture relationships within the data, but also to do so in away which can be usefully applied.", "labels": [], "entities": []}, {"text": "In these cases, both intrinsic and extrinsic evaluation must betaken into account.", "labels": [], "entities": []}, {"text": "We collected a large sample of tweets (with geolocations and language IDs assigned to each tweet) from 240 countries in 66 languages from Twitter.", "labels": [], "entities": []}, {"text": "Data collection lasted two weeks, beginning on March 15th, 2016 and ending March 29th, 2016.", "labels": [], "entities": [{"text": "Data collection", "start_pos": 0, "end_pos": 15, "type": "TASK", "confidence": 0.6497482359409332}]}, {"text": "We chose this 15 day period because it includes the attacks on Brussels on March 22 (a widelydiscussed event) as well as one whole week before and after the attacks.", "labels": [], "entities": [{"text": "Brussels on March 22", "start_pos": 63, "end_pos": 83, "type": "DATASET", "confidence": 0.9382007867097855}]}, {"text": "We used 140 million tweets in English to learn daily spatiotemporal embeddings overtime and across 10 European countries.", "labels": [], "entities": []}, {"text": "We manually constructed a list of trusted news accounts that tweet in English and checked whether they are verified on Twitter.", "labels": [], "entities": []}, {"text": "The example verified accounts include @cnn,@bbcnews, @foxnews.", "labels": [], "entities": []}, {"text": "We found the list of accounts that spread suspicious news -propaganda, clickbait, hoaxes and satire, 8 e.g., @TheOnion, @ActivistPost,@DRUDGE_REPORT.", "labels": [], "entities": [{"text": "TheOnion", "start_pos": 110, "end_pos": 118, "type": "DATASET", "confidence": 0.9485484957695007}]}, {"text": "We collected retweets generated in 2016 by any user that mentions one of these accounts and assigned the corresponding label propagated from suspicious or trusted news sources.", "labels": [], "entities": []}, {"text": "In total, we collected 9.6 million verified news posts and 8.4 million suspicious news tweets.", "labels": [], "entities": []}, {"text": "We used 18 million tweets to learn monthly embeddings overtime and across suspicious and verified news account types.", "labels": [], "entities": []}], "tableCaptions": []}