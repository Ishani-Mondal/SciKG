{"title": [{"text": "Time Expression Analysis and Recognition Using Syntactic Token Types and General Heuristic Rules", "labels": [], "entities": [{"text": "Time Expression Analysis", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.8514520327250162}]}], "abstractContent": [{"text": "Extracting time expressions from free text is a fundamental task for many applications.", "labels": [], "entities": [{"text": "Extracting time expressions from free text", "start_pos": 0, "end_pos": 42, "type": "TASK", "confidence": 0.8833969334761301}]}, {"text": "We analyze time expressions from four different datasets and find that only a small group of words are used to express time information and that the words in time expressions demonstrate similar syntactic behaviour.", "labels": [], "entities": []}, {"text": "Based on the findings, we propose a type-based approach named SynTime 1 for time expression recognition.", "labels": [], "entities": [{"text": "time expression recognition", "start_pos": 76, "end_pos": 103, "type": "TASK", "confidence": 0.6865497827529907}]}, {"text": "Specifically, we define three main syntactic token types, namely time token, mod-ifier, and numeral, to group time-related token regular expressions.", "labels": [], "entities": []}, {"text": "On the types we design general heuristic rules to recognize time expressions.", "labels": [], "entities": []}, {"text": "In recognition, SynTime first identifies time tokens from raw text, then searches their surroundings for modifiers and numerals to form time segments, and finally merges the time segments to time expressions.", "labels": [], "entities": []}, {"text": "As a lightweight rule-based tagger, SynTime runs in real time, and can be easily expanded by simply adding keywords for the text from different domains and different text types.", "labels": [], "entities": []}, {"text": "Experiments on benchmark datasets and tweets data show that SynTime out-performs state-of-the-art methods.", "labels": [], "entities": []}], "introductionContent": [{"text": "Time expression plays an important role in information retrieval and many applications in natural language processing).", "labels": [], "entities": [{"text": "Time expression", "start_pos": 0, "end_pos": 15, "type": "TASK", "confidence": 0.6431299299001694}, {"text": "information retrieval", "start_pos": 43, "end_pos": 64, "type": "TASK", "confidence": 0.8199204802513123}]}, {"text": "Recognizing time expressions from free text has attracted considerable attention since last decade We analyze time expressions in four datasets: TimeBank (), Gigaword), WikiWars, and Tweets.", "labels": [], "entities": [{"text": "Recognizing time expressions from free text", "start_pos": 0, "end_pos": 43, "type": "TASK", "confidence": 0.8358169396718343}]}, {"text": "From the analysis we make four findings about time expressions.", "labels": [], "entities": []}, {"text": "First, most time expressions are very short, with 80% of time expressions containing no more than three tokens.", "labels": [], "entities": []}, {"text": "Second, at least 91.8% of time expressions contain at least onetime token.", "labels": [], "entities": []}, {"text": "Third, the vocabulary used to express time information is very small, with a small group of keywords.", "labels": [], "entities": []}, {"text": "Finally, words in time expressions demonstrate similar syntactic behaviour.", "labels": [], "entities": []}, {"text": "All the findings relate to the principle of least effort.", "labels": [], "entities": []}, {"text": "That is, people tend to act under the least effort in order to minimize the cost of energy at both individual level and collective level to language usage.", "labels": [], "entities": []}, {"text": "Time expression is part of language and acts as an interface of communication.", "labels": [], "entities": []}, {"text": "Short expressions, occurrence, small vocabulary, and similar syntactic behaviour all reduce the cost of energy required to communicate.", "labels": [], "entities": []}, {"text": "According to the findings we propose a typebased approach named SynTime ('Syn' stands for syntactic) to recognize time expressions.", "labels": [], "entities": []}, {"text": "Specifically, we define three main token types, namely time token, modifier, and numeral, to group timerelated token regular expressions.", "labels": [], "entities": []}, {"text": "Time tokens are the words that explicitly express time information, such as time units (e.g., 'year').", "labels": [], "entities": []}, {"text": "Modifiers modify time tokens; they appear before or after time tokens, e.g., 'several' and 'ago' in 'several years ago.'", "labels": [], "entities": []}, {"text": "Numerals are ordinals and numbers.", "labels": [], "entities": []}, {"text": "From free text SynTime first identifies time tokens, then recognizes modifiers and numerals.", "labels": [], "entities": []}, {"text": "Naturally, SynTime is a rule-based tagger.", "labels": [], "entities": []}, {"text": "The key difference between SynTime and other rulebased taggers lies in the way of defining token types and the way of designing rules.", "labels": [], "entities": []}, {"text": "The definition of token type in SynTime is inspired by part-of-speech in which \"linguists group some words of language into classes (sets) which show similar syntactic behaviour.\")", "labels": [], "entities": []}, {"text": "SynTime defines token types for tokens according to their syntactic behaviour.", "labels": [], "entities": []}, {"text": "Other rulebased taggers define types for tokens based on their semantic meaning.", "labels": [], "entities": []}, {"text": "For example, SUTime defines 5 semantic modifier types, such as frequency modifiers; 2 while SynTime defines 5 syntactic modifier types, such as modifiers that appear before time tokens.", "labels": [], "entities": []}, {"text": "(See Section 4.1 for details.)", "labels": [], "entities": []}, {"text": "Accordingly, other rule-based taggers design deterministic rules based on their meanings of tokens themselves.", "labels": [], "entities": []}, {"text": "SynTime instead designs general rules on the token types rather than on the tokens themselves.", "labels": [], "entities": []}, {"text": "For example, our general rules do notwork on tokens 'February' nor '1989' but on their token types 'MONTH' and 'YEAR.'", "labels": [], "entities": [{"text": "1989", "start_pos": 68, "end_pos": 72, "type": "DATASET", "confidence": 0.7249675393104553}, {"text": "MONTH", "start_pos": 100, "end_pos": 105, "type": "METRIC", "confidence": 0.9550473690032959}, {"text": "YEAR", "start_pos": 112, "end_pos": 116, "type": "METRIC", "confidence": 0.9156185984611511}]}, {"text": "That is why we call SynTime a type-based approach.", "labels": [], "entities": []}, {"text": "More importantly, other rule-based taggers design rules in a fixed method, including fixed length and fixed position.", "labels": [], "entities": []}, {"text": "In contrast, SynTime designs general rules in a heuristic way, based on the idea of boundary expansion.", "labels": [], "entities": []}, {"text": "The general heuristic rules are quite light-weight that it makes SynTime much more flexible and expansible, and leads SynTime to run in real time.", "labels": [], "entities": []}, {"text": "The heuristic rules are designed on token types and are independent of specific tokens, SynTime therefore is independent of specific domains, specific text types, and even specific languages that consist of specific tokens.", "labels": [], "entities": []}, {"text": "In this paper, we test SynTime on specific domains and specific text types in English.", "labels": [], "entities": []}, {"text": "(The test for other languages needs only to construct a collection of token regular expressions in the target language under our defined token types.)", "labels": [], "entities": []}, {"text": "Specifically, we evaluate SynTime against three state-of-the-art methods (i.e., HeidelTime, SUTime, and UWTime) on three datasets: TimeBank, WikiWars, and Tweets.  datasets.", "labels": [], "entities": [{"text": "TimeBank", "start_pos": 131, "end_pos": 139, "type": "DATASET", "confidence": 0.9622292518615723}]}, {"text": "More importantly, SynTime achieves the best recalls on all three datasets and exceptionally good results on Tweets dataset.", "labels": [], "entities": [{"text": "recalls", "start_pos": 44, "end_pos": 51, "type": "METRIC", "confidence": 0.9972223043441772}, {"text": "Tweets dataset", "start_pos": 108, "end_pos": 122, "type": "DATASET", "confidence": 0.9562376141548157}]}, {"text": "To sum up, we make the following contributions.", "labels": [], "entities": []}, {"text": "\u2022 We analyze time expressions from four datasets and make four findings.", "labels": [], "entities": []}, {"text": "The findings provide evidence in terms of time expression for the principle of least effort.", "labels": [], "entities": []}, {"text": "\u2022 We propose a time tagger named SynTime to recognize time expressions using syntactic token types and general heuristic rules.", "labels": [], "entities": []}, {"text": "SynTime is independent of specific tokens, and therefore independent of specific domains, specific text types, and specific languages.", "labels": [], "entities": []}, {"text": "\u2022 We conduct experiments on three datasets, and the results demonstrate the effectiveness of SynTime against state-of-the-art baselines.", "labels": [], "entities": []}], "datasetContent": [{"text": "We evaluate SynTime against three state-of-theart baselines (i.e., HeidelTime, SUTime, and UWTime) on three datasets (i.e., TimeBank, WikiWars, and Tweets).", "labels": [], "entities": [{"text": "TimeBank", "start_pos": 124, "end_pos": 132, "type": "DATASET", "confidence": 0.9337752461433411}]}, {"text": "WikiWars is a specific domain dataset about war; TimeBank and WikiWars are the datasets informal text while Tweets dataset is in informal text.", "labels": [], "entities": [{"text": "WikiWars", "start_pos": 0, "end_pos": 8, "type": "DATASET", "confidence": 0.9160543084144592}, {"text": "TimeBank", "start_pos": 49, "end_pos": 57, "type": "DATASET", "confidence": 0.9735937118530273}, {"text": "WikiWars", "start_pos": 62, "end_pos": 70, "type": "DATASET", "confidence": 0.9266397953033447}, {"text": "Tweets dataset", "start_pos": 108, "end_pos": 122, "type": "DATASET", "confidence": 0.8324248492717743}]}, {"text": "For SynTime we report the results of its two versions: SynTime-I and SynTime-E.", "labels": [], "entities": []}, {"text": "SynTime-I is the initial version, and SynTime-E is the expanded version of SynTime-I.", "labels": [], "entities": [{"text": "SynTime-I", "start_pos": 0, "end_pos": 9, "type": "DATASET", "confidence": 0.9004729390144348}]}, {"text": "We use three datasets of which TimeBank and WikiWars are benchmark datasets whose details are shown in Section 3.1; Tweets is our manually labeled dataset that are collected from Twitter.", "labels": [], "entities": [{"text": "TimeBank", "start_pos": 31, "end_pos": 39, "type": "DATASET", "confidence": 0.9414032697677612}]}, {"text": "For Tweets dataset, we randomly sample 4000 tweets and use SUTime to tag them.", "labels": [], "entities": [{"text": "Tweets dataset", "start_pos": 4, "end_pos": 18, "type": "DATASET", "confidence": 0.8050829470157623}]}, {"text": "942 tweets of which each contains at least onetime expression.", "labels": [], "entities": []}, {"text": "From the remaining 3,058 tweets, we randomly sample 500 and manually annotate them, and find that only 15 tweets contain time expressions.", "labels": [], "entities": []}, {"text": "We therefore roughly consider that SUTime misses about 3% time expressions in tweets.", "labels": [], "entities": []}, {"text": "Two annotators then manually annotate the 942 tweets with discussion to final agreement according to the standards of TimeML and TimeBank.", "labels": [], "entities": [{"text": "TimeML", "start_pos": 118, "end_pos": 124, "type": "DATASET", "confidence": 0.9477750062942505}, {"text": "TimeBank", "start_pos": 129, "end_pos": 137, "type": "DATASET", "confidence": 0.9499951004981995}]}, {"text": "We finally get 1,127 manually labeled time expressions.", "labels": [], "entities": []}, {"text": "For the 942 tweets, we randomly sample 200 tweets as test set, and the rest 742 as training set, because a baseline UWTime requires training.", "labels": [], "entities": [{"text": "UWTime", "start_pos": 116, "end_pos": 122, "type": "DATASET", "confidence": 0.9072934985160828}]}, {"text": "We compare SynTime with methods:,, and UW- Evaluation Metrics.", "labels": [], "entities": []}, {"text": "We follow TempEval-3 and use their evaluation toolkit 10 to report P recision, Recall, and F 1 in terms of strict match and relaxed match (UzZaman et al., 2013).", "labels": [], "entities": [{"text": "P recision", "start_pos": 67, "end_pos": 77, "type": "METRIC", "confidence": 0.7004770040512085}, {"text": "Recall", "start_pos": 79, "end_pos": 85, "type": "METRIC", "confidence": 0.9903268218040466}, {"text": "F 1", "start_pos": 91, "end_pos": 94, "type": "METRIC", "confidence": 0.9922218322753906}, {"text": "relaxed match", "start_pos": 124, "end_pos": 137, "type": "METRIC", "confidence": 0.9341764152050018}]}, {"text": "Among the 18 measures, SynTime-I and SynTime-E achieve 12 best results and 13 second best results.", "labels": [], "entities": [{"text": "SynTime-I", "start_pos": 23, "end_pos": 32, "type": "DATASET", "confidence": 0.7195340991020203}]}, {"text": "Except the strict match on WikiWars dataset, both SynTime-I and SynTime-E achieve F 1 above 91%.", "labels": [], "entities": [{"text": "WikiWars dataset", "start_pos": 27, "end_pos": 43, "type": "DATASET", "confidence": 0.9346230328083038}, {"text": "F 1", "start_pos": 82, "end_pos": 85, "type": "METRIC", "confidence": 0.9930376410484314}]}, {"text": "For the relaxed match on all three datasets, SynTime-I and SynTime-E achieve recalls above 92%.", "labels": [], "entities": [{"text": "recalls", "start_pos": 77, "end_pos": 84, "type": "METRIC", "confidence": 0.9982820749282837}]}, {"text": "The high recalls are consistent with our finding that at least 91.81% of time expressions contain time token(s).", "labels": [], "entities": [{"text": "recalls", "start_pos": 9, "end_pos": 16, "type": "METRIC", "confidence": 0.9969040751457214}]}, {"text": "(See.) the size of time keywords is small, (only 60 distinct time tokens; see.) and even in tweets people tend to use formal words.", "labels": [], "entities": []}, {"text": "(See Section 4.3 for our finding from Twitter word clusters.)", "labels": [], "entities": []}, {"text": "For precision, SynTime achieves comparable results in strict match and performs slightly poorer in relaxed match.", "labels": [], "entities": [{"text": "precision", "start_pos": 4, "end_pos": 13, "type": "METRIC", "confidence": 0.9977422952651978}]}], "tableCaptions": [{"text": " Table 1: Statistics of the datasets (A tweet here is  a document.)  Dataset  #Docs #Words #TIMEX  TimeBank  183  61,418  1,243  Gigaword  2,452 666,309  12,739  WikiWars  22 119,468  2,671  Tweets  942  18,199  1,127", "labels": [], "entities": [{"text": "TIMEX  TimeBank  183  61,418  1,243  Gigaword  2,452 666,309  12,739  WikiWars  22 119,468  2,671  Tweets  942  18,199  1,127", "start_pos": 92, "end_pos": 217, "type": "DATASET", "confidence": 0.8286936072742238}]}, {"text": " Table 2: The percentage of time expressions that  contain at least one time token, and the average  length of time expressions  Dataset  Percent Average Length  TimeBank  94.61  2.00  Gigaword  96.44  1.70  WikiWars  91.81  2.38  Tweets  96.01  1.51", "labels": [], "entities": [{"text": "Dataset  Percent Average Length  TimeBank  94.61", "start_pos": 129, "end_pos": 177, "type": "METRIC", "confidence": 0.6955824395020803}]}, {"text": " Table 3: Number of distinct words and number of  distinct time tokens in time expressions  Dataset  #Words #Time Tokens  TimeBank  130  64  Gigaword  214  80  WikiWars  224  74  Tweets  107  64", "labels": [], "entities": []}, {"text": " Table 4: Overall performance. The best results are in bold face and the second best are underlined. Some  results are borrowed from their original papers and the papers are indicated by the references.", "labels": [], "entities": []}, {"text": " Table 5: Number of time tokens and modifiers for  expansion  Dataset  #Time Tokens #Modifiers  TimeBank  3  5  WikiWars  16  21  Tweets  3  2", "labels": [], "entities": []}]}