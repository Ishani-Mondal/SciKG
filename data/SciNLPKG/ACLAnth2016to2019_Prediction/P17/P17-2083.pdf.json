{"title": [{"text": "A Generative Attentional Neural Network Model for Dialogue Act Classification", "labels": [], "entities": [{"text": "Dialogue Act Classification", "start_pos": 50, "end_pos": 77, "type": "TASK", "confidence": 0.8828927874565125}]}], "abstractContent": [{"text": "We propose a novel generative neural network architecture for Dialogue Act classification.", "labels": [], "entities": [{"text": "Dialogue Act classification", "start_pos": 62, "end_pos": 89, "type": "TASK", "confidence": 0.7596254547437032}]}, {"text": "Building upon the Recurrent Neural Network framework, our model incorporates anew attentional technique and a label-to-label connection for sequence learning, akin to Hidden Markov Models.", "labels": [], "entities": []}, {"text": "Our experiments show that both of these innovations enable our model to out-perform strong baselines for dialogue-act classification on the MapTask and Switchboard corpora.", "labels": [], "entities": [{"text": "dialogue-act classification", "start_pos": 105, "end_pos": 132, "type": "TASK", "confidence": 0.7492319345474243}]}, {"text": "In addition, we analyse empirically the effectiveness of each of these innovations.", "labels": [], "entities": []}], "introductionContent": [{"text": "Dialogue Act (DA) classification is a sequenceto-sequence learning task where a sequence of utterances is mapped into a sequence of DAs.", "labels": [], "entities": [{"text": "Dialogue Act (DA) classification", "start_pos": 0, "end_pos": 32, "type": "TASK", "confidence": 0.5968384196360906}]}, {"text": "Some works in DA classification treat each utterance as an independent instance (, which leads to ignoring important long-range dependencies in the dialogue history.", "labels": [], "entities": [{"text": "DA classification", "start_pos": 14, "end_pos": 31, "type": "TASK", "confidence": 0.9763266742229462}]}, {"text": "Other works have captured inter-utterance relationships using models such as Hidden Markov Models (HMMs) () or Recurrent Neural Networks (RNNs), where RNNs have been particularly successful.", "labels": [], "entities": []}, {"text": "In this paper, we present a generative model of utterances and dialogue acts which conditions on the relevant part of the dialogue history.", "labels": [], "entities": []}, {"text": "To this effect, we use the attention mechanism ( ) developed originally for sequence-tosequence models, which has proven effective in Machine Translation ( and DA classification).", "labels": [], "entities": [{"text": "Machine Translation", "start_pos": 134, "end_pos": 153, "type": "TASK", "confidence": 0.864640474319458}, {"text": "DA classification", "start_pos": 160, "end_pos": 177, "type": "TASK", "confidence": 0.8379082083702087}]}, {"text": "The intuition is that different parts of an input sequence have different levels of importance with respect to the objective, and this mechanism enables the selection of the important parts.", "labels": [], "entities": []}, {"text": "However, the traditional attention mechanism suffers from the attention-bias problem (, where the attention mechanism tends to favor the inputs at the end of a sequence.", "labels": [], "entities": []}, {"text": "To address this problem, we propose a gated attention mechanism, where the attention signal is represented as agate over the input vector.", "labels": [], "entities": []}, {"text": "In addition, when generating a dialogue act, we capture its direct dependence on the previous dialogue act -a reasonable source of information, which, surprisingly, has not been explored in the RNN literature for DA classification.", "labels": [], "entities": [{"text": "RNN literature", "start_pos": 194, "end_pos": 208, "type": "DATASET", "confidence": 0.7428661584854126}, {"text": "DA classification", "start_pos": 213, "end_pos": 230, "type": "TASK", "confidence": 0.97977614402771}]}, {"text": "Our experiments show that our model significantly outperforms variants that do not have our innovations, i.e., the gated attention mechanism and direct label-to-label dependency.", "labels": [], "entities": []}], "datasetContent": [{"text": "We conduct our experiments on the MapTask and Switchboard corpora.", "labels": [], "entities": []}, {"text": "The MapTask Dialog Act corpus ( consists of 128 conversations and more than 27000 utterances in an instruction-giving scenario.", "labels": [], "entities": [{"text": "MapTask Dialog Act corpus", "start_pos": 4, "end_pos": 29, "type": "DATASET", "confidence": 0.8726249933242798}]}, {"text": "There are 13 DA types in this corpus.", "labels": [], "entities": []}, {"text": "For the experiments, the available data is split into three parts, train/test/validation with 103, 13 and 12 conversations respectively.", "labels": [], "entities": []}, {"text": "The Switchboard Dialog Act corpus () consists of 1155 transcribed telephone conversations with around 205000 utterances.", "labels": [], "entities": [{"text": "Switchboard Dialog Act corpus", "start_pos": 4, "end_pos": 33, "type": "DATASET", "confidence": 0.7771981656551361}]}, {"text": "In contrast with the MapTask conversations, which are task-oriented, the Switchboard corpus consists mostly of general topic conversations.", "labels": [], "entities": [{"text": "Switchboard corpus", "start_pos": 73, "end_pos": 91, "type": "DATASET", "confidence": 0.764116108417511}]}, {"text": "The Switchboard tag set has 42 DAs.", "labels": [], "entities": [{"text": "Switchboard tag set", "start_pos": 4, "end_pos": 23, "type": "DATASET", "confidence": 0.8421658873558044}]}, {"text": "1 without gate bias gate all HMM HMM HMM no attn.", "labels": [], "entities": []}, {"text": "60.97% 64.60% 63.55% traditional 61.72% 64.73% 65.19% gated attn.", "labels": [], "entities": []}, {"text": "62.21% 65.94% 65.94%: Comparison of our model variants on the MapTask corpus.", "labels": [], "entities": [{"text": "MapTask corpus", "start_pos": 62, "end_pos": 76, "type": "DATASET", "confidence": 0.9264462292194366}]}, {"text": "On MapTask, to the best of our knowledge, there is no standard data split, thus, we make the comparison against our implementation of strong baselines such as HMM-trigram) and instance-based random forest classifier (1/2/3-gram features).", "labels": [], "entities": []}, {"text": "results for this corpus are obtained by running their publicly available code with the same hyper parameters as those used by our models.", "labels": [], "entities": []}, {"text": "We also report the results of.", "labels": [], "entities": []}, {"text": "However, the experimental setup of these two works differs from ours, hence their results are not directly comparable to ours.", "labels": [], "entities": []}, {"text": "On Switchboard, we compare our results with strong baselines using the experimental setup from and Our Model Configurations.", "labels": [], "entities": []}, {"text": "We experiment with several variants of our model to explore the effectiveness of our two improvements: the HMM-like connection and the gated attention mechanism.", "labels": [], "entities": []}, {"text": "For the HMM connection, we consider three choices: gating all parameters (Equation 3), gating only the bias, and no connection.", "labels": [], "entities": [{"text": "Equation", "start_pos": 74, "end_pos": 82, "type": "METRIC", "confidence": 0.9553519487380981}]}, {"text": "For the attention, we consider three choices: our new gated attention mechanism, the traditional attention, and no attention.", "labels": [], "entities": []}, {"text": "Thus, in total, we explore nine model variants.", "labels": [], "entities": []}, {"text": "All the model variants are implemented with the CNN package and trained with Adagrad (Duchi et al., 2011) using dropout ().", "labels": [], "entities": [{"text": "CNN package", "start_pos": 48, "end_pos": 59, "type": "DATASET", "confidence": 0.9122471809387207}, {"text": "Adagrad", "start_pos": 77, "end_pos": 84, "type": "DATASET", "confidence": 0.6914190649986267}]}, {"text": "They share the same word-embedding size (128) and hidden vector size (64).", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Results on MapTask data.", "labels": [], "entities": [{"text": "MapTask data", "start_pos": 21, "end_pos": 33, "type": "DATASET", "confidence": 0.9276294410228729}]}, {"text": " Table 3: Results on Switchboard data.", "labels": [], "entities": [{"text": "Switchboard data", "start_pos": 21, "end_pos": 37, "type": "DATASET", "confidence": 0.8406625092029572}]}]}