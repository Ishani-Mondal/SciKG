{"title": [{"text": "Multi-Task Learning of Keyphrase Boundary Classification", "labels": [], "entities": [{"text": "Keyphrase Boundary Classification", "start_pos": 23, "end_pos": 56, "type": "TASK", "confidence": 0.7592433194319407}]}], "abstractContent": [{"text": "Keyphrase boundary classification (KBC) is the task of detecting keyphrases in scientific articles and labelling them with respect to predefined types.", "labels": [], "entities": [{"text": "Keyphrase boundary classification (KBC)", "start_pos": 0, "end_pos": 39, "type": "TASK", "confidence": 0.8391367693742117}]}, {"text": "Although important in practice, this task is so far un-derexplored, partly due to the lack of labelled data.", "labels": [], "entities": []}, {"text": "To overcome this, we explore several auxiliary tasks, including semantic super-sense tagging and identification of multi-word expressions, and cast the task as a multi-task learning problem with deep recurrent neural networks.", "labels": [], "entities": [{"text": "semantic super-sense tagging", "start_pos": 64, "end_pos": 92, "type": "TASK", "confidence": 0.6120954155921936}, {"text": "identification of multi-word expressions", "start_pos": 97, "end_pos": 137, "type": "TASK", "confidence": 0.8334655463695526}]}, {"text": "Our multi-task models perform significantly better than previous state of the art approaches on two scientific KBC datasets, particularly for long keyphrases.", "labels": [], "entities": [{"text": "KBC datasets", "start_pos": 111, "end_pos": 123, "type": "DATASET", "confidence": 0.8191592395305634}]}], "introductionContent": [{"text": "The scientific keyphrase boundary classification (KBC) task consists of a) determining keyphrase boundaries, and b) labelling keyphrases with their types according to a predefined schema.", "labels": [], "entities": [{"text": "scientific keyphrase boundary classification (KBC)", "start_pos": 4, "end_pos": 54, "type": "TASK", "confidence": 0.7390507970537458}]}, {"text": "KBC is motivated by the need to efficiently search scientific literature, which can be summarised by their keyphrases.", "labels": [], "entities": [{"text": "KBC", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.8221958875656128}]}, {"text": "Several companies are working on keyphrase-based recommender systems for scientific literature or search interfaces where scientific articles decorate graphs, in which nodes are keyphrases.", "labels": [], "entities": []}, {"text": "Such keyphrases must be dynamically retrieved from the articles, because important scientific concepts emerge on a daily basis, and the most recent concepts are typically the ones of interest to scientists.", "labels": [], "entities": []}, {"text": "KBC is not a common task in NLP, and there are only few small annotated datasets for inducing supervised KBC models, made available recently ? Both authors contributed equally.", "labels": [], "entities": []}, {"text": "Typical KBC approaches therefore rely on hand-crafted gazetteers or reduce the task to extracting a list of keyphrases for each document) instead of identifying mentions of keyphrases in sentences.", "labels": [], "entities": []}, {"text": "For related more common NLP tasks such as named entity recognition and identification of multi-word expressions, neural sequence labelling methods have been shown to be useful (.", "labels": [], "entities": [{"text": "named entity recognition", "start_pos": 42, "end_pos": 66, "type": "TASK", "confidence": 0.6404595772425333}]}, {"text": "In order to overcome the small data problem, we study using more widely available data for tasks related to KBC and exploit their synergies in a deep multi-task learning setup.", "labels": [], "entities": []}, {"text": "Multi-task learning has become popular within natural language processing and machine learning over the last few years; in particular, hard parameter sharing of hidden layers in deep learning models.", "labels": [], "entities": [{"text": "Multi-task learning", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.806549608707428}]}, {"text": "This approach to multi-task learning has three advantages: a) It significantly reduces Rademacher complexity, i.e., the risk of over-fitting, b) it is spaceefficient, reducing the number of parameters, and c) it is easy to implement.", "labels": [], "entities": [{"text": "Rademacher complexity", "start_pos": 87, "end_pos": 108, "type": "METRIC", "confidence": 0.7193095982074738}]}, {"text": "This paper shows how hard parameter sharing can be used to improve gazetteer-free keyphrase boundary classification models, by exploiting different syntactically and semantically annotated corpora, as well as more readily available data such as hyperlinks.", "labels": [], "entities": [{"text": "gazetteer-free keyphrase boundary classification", "start_pos": 67, "end_pos": 115, "type": "TASK", "confidence": 0.6865530908107758}]}, {"text": "Contributions We study the so far widely underexplored, though in practice important task of scientific keyphrase boundary classification, for which only a small amount of training data is available.", "labels": [], "entities": [{"text": "keyphrase boundary classification", "start_pos": 104, "end_pos": 137, "type": "TASK", "confidence": 0.6923169990380605}]}, {"text": "We overcome this by identifying good auxiliary tasks and cast it as a multi-task learning problem.", "labels": [], "entities": []}, {"text": "We evaluate our models across two new, manually annotated corpora of scientific articles and outperform single-task approaches by up to 9.64% F1, mostly due to better performance for long keyphrases.", "labels": [], "entities": [{"text": "F1", "start_pos": 142, "end_pos": 144, "type": "METRIC", "confidence": 0.9994255304336548}]}], "datasetContent": [{"text": "Experimental Setup We perform experiments for both keyphrase boundary identification (unlabelled), and keyphrase boundary identification and classification (labelled).", "labels": [], "entities": [{"text": "keyphrase boundary identification", "start_pos": 51, "end_pos": 84, "type": "TASK", "confidence": 0.6875601609547933}, {"text": "keyphrase boundary identification and classification", "start_pos": 103, "end_pos": 155, "type": "TASK", "confidence": 0.6842134356498718}]}, {"text": "Metrics measured are token-level precision, recall and F1, which are micro-average results across keyphrase types.", "labels": [], "entities": [{"text": "precision", "start_pos": 33, "end_pos": 42, "type": "METRIC", "confidence": 0.9669432640075684}, {"text": "recall", "start_pos": 44, "end_pos": 50, "type": "METRIC", "confidence": 0.9996057152748108}, {"text": "F1", "start_pos": 55, "end_pos": 57, "type": "METRIC", "confidence": 0.9995054006576538}]}, {"text": "Types are defined by the two datasets studied.", "labels": [], "entities": []}, {"text": "Auxiliary tasks We experiment with five auxiliary tasks: (1) syntactic chunking using annotations extracted from the English Penn Treebank, following; (2) frame target annotations from FrameNet 1.5 (corresponding to the target identification and classification tasks in); (3) hyperlink prediction using the dataset from, (4) identification of multi-word expressions using the Streusle corpus (; and (5) semantic super-sense tagging using the Semcor dataset, following.", "labels": [], "entities": [{"text": "English Penn Treebank", "start_pos": 117, "end_pos": 138, "type": "DATASET", "confidence": 0.7694198489189148}, {"text": "hyperlink prediction", "start_pos": 276, "end_pos": 296, "type": "TASK", "confidence": 0.8618405759334564}, {"text": "Streusle corpus", "start_pos": 376, "end_pos": 391, "type": "DATASET", "confidence": 0.9412680268287659}, {"text": "semantic super-sense tagging", "start_pos": 403, "end_pos": 431, "type": "TASK", "confidence": 0.6563075681527456}, {"text": "Semcor dataset", "start_pos": 442, "end_pos": 456, "type": "DATASET", "confidence": 0.9471760094165802}]}, {"text": "We train our models on the main task with one auxiliary task at a time.", "labels": [], "entities": []}, {"text": "Note that the datasets for the auxiliary tasks are not annotated with keyphrase boundary identification or classification labels.", "labels": [], "entities": []}, {"text": "Datasets We evaluate on the SemEval 2017 Task 10 dataset () and the the ACL RD-TEC 2.0 dataset (QasemiZadeh and.", "labels": [], "entities": [{"text": "SemEval 2017 Task 10 dataset", "start_pos": 28, "end_pos": 56, "type": "DATASET", "confidence": 0.7514898300170898}, {"text": "ACL RD-TEC 2.0 dataset", "start_pos": 72, "end_pos": 94, "type": "DATASET", "confidence": 0.8486721217632294}]}, {"text": "The SemEval 2017 dataset is annotated with three keyphrase types, the ACL RD-TEC dataset with seven.", "labels": [], "entities": [{"text": "SemEval 2017 dataset", "start_pos": 4, "end_pos": 24, "type": "DATASET", "confidence": 0.787577748298645}, {"text": "ACL RD-TEC dataset", "start_pos": 70, "end_pos": 88, "type": "DATASET", "confidence": 0.7972883979479471}]}, {"text": "For the former, we test on the development portion of the dataset, as the test set is not released yet.", "labels": [], "entities": []}, {"text": "We randomly split ACL RD-TEC into a training and test set, reserv- Models Our single-and multi-task networks are three-layer, bi-directional LSTMs (Graves and) with pre-trained SENNA embeddings.", "labels": [], "entities": []}, {"text": "1 For the multi-task networks, we follow the training procedure outlined in Section 3.", "labels": [], "entities": []}, {"text": "The dimensionality of the embeddings is 50, and we follow S\u00f8gaard and Goldberg (2016) in using the same dimensionality for the hidden layers.", "labels": [], "entities": []}, {"text": "We add a dropout of 0.1 to the input and train these architectures with momentum SGD with initial learning rate of 0.001 and momentum of 0.9 for 10 epochs.", "labels": [], "entities": []}, {"text": "We use the implementations released by the authors and re-train models on our data.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Characteristics of SemEval 2017 Task 10 and ACL-RD-TEC corpora, statistics of training sets", "labels": [], "entities": [{"text": "SemEval 2017 Task 10", "start_pos": 29, "end_pos": 49, "type": "TASK", "confidence": 0.8005244731903076}, {"text": "ACL-RD-TEC corpora", "start_pos": 54, "end_pos": 72, "type": "DATASET", "confidence": 0.8725307881832123}]}, {"text": " Table 2: Results for keyphrase boundary classification on the SemEval 2017 Task 10 corpus", "labels": [], "entities": [{"text": "keyphrase boundary classification", "start_pos": 22, "end_pos": 55, "type": "TASK", "confidence": 0.8167584935824076}, {"text": "SemEval 2017 Task 10", "start_pos": 63, "end_pos": 83, "type": "DATASET", "confidence": 0.7557460218667984}]}, {"text": " Table 3: Results for keyphrase boundary classification on the ACL RD-TEC corpus", "labels": [], "entities": [{"text": "keyphrase boundary classification", "start_pos": 22, "end_pos": 55, "type": "TASK", "confidence": 0.8335694869359335}, {"text": "ACL RD-TEC", "start_pos": 63, "end_pos": 73, "type": "DATASET", "confidence": 0.9146931767463684}]}]}