{"title": [{"text": "Model Transfer for Tagging Low-resource Languages using a Bilingual Dictionary", "labels": [], "entities": [{"text": "Model Transfer", "start_pos": 0, "end_pos": 14, "type": "TASK", "confidence": 0.7002068907022476}, {"text": "Tagging Low-resource Languages", "start_pos": 19, "end_pos": 49, "type": "TASK", "confidence": 0.8892432848612467}]}], "abstractContent": [{"text": "Cross-lingual model transfer is a compelling and popular method for predicting annotations in a low-resource language, whereby parallel corpora provide abridge to a high-resource language and its associated annotated corpora.", "labels": [], "entities": [{"text": "Cross-lingual model transfer", "start_pos": 0, "end_pos": 28, "type": "TASK", "confidence": 0.6276034812132517}]}, {"text": "However, parallel data is not readily available for many languages , limiting the applicability of these approaches.", "labels": [], "entities": []}, {"text": "We address these drawbacks in our framework which takes advantage of cross-lingual word embeddings trained solely on a high coverage bilingual dictionary.", "labels": [], "entities": []}, {"text": "We propose a novel neural network model for joint training from both sources of data based on cross-lingual word em-beddings, and show substantial empirical improvements over baseline techniques.", "labels": [], "entities": []}, {"text": "We also propose several active learning heuristics, which result in improvements over competitive benchmark methods.", "labels": [], "entities": []}], "introductionContent": [{"text": "Part-of-speech (POS) tagging is an important first step inmost natural language processing (NLP) applications.", "labels": [], "entities": [{"text": "Part-of-speech (POS) tagging", "start_pos": 0, "end_pos": 28, "type": "TASK", "confidence": 0.5763983607292176}]}, {"text": "Typically this is modelled using sequence labelling methods to predict the conditional probability of taggings given word sequences, using linear graphical models (), or neural network models, such as recurrent neural networks (RNN) ().", "labels": [], "entities": []}, {"text": "These supervised learning algorithms rely on large labelled corpora; this is particularly true for state-of-the-art neural network models.", "labels": [], "entities": []}, {"text": "Due to the expense of annotating sufficient data, such techniques are not well suited to applications in low-resource languages.", "labels": [], "entities": []}, {"text": "Prior work on low-resource NLP has primarily focused on exploiting parallel corpora to project information between a high-and low-resource language.", "labels": [], "entities": []}, {"text": "For example, POS tags can be projected via word alignments, and the projected POS is then used to train a model in the lowresource language (.", "labels": [], "entities": [{"text": "word alignments", "start_pos": 43, "end_pos": 58, "type": "TASK", "confidence": 0.6948442608118057}]}, {"text": "These methods overall have limited effectiveness due to errors in the alignment and fundamental differences between the languages.", "labels": [], "entities": []}, {"text": "They also assume a large parallel corpus, which may not be available for many low-resource languages.", "labels": [], "entities": []}, {"text": "To address these limitations, we propose anew technique for low resource tagging, with more modest resource requirements: 1) a bilingual dictionary; 2) monolingual corpora in the high and low resource languages; and 3) a small annotated corpus of around 1, 000 tokens in the low-resource language.", "labels": [], "entities": [{"text": "low resource tagging", "start_pos": 60, "end_pos": 80, "type": "TASK", "confidence": 0.6288126309712728}]}, {"text": "The first two resources are used as a form of distant supervision through learning crosslingual word embeddings over the monolingual corpora and bilingual dictionary.", "labels": [], "entities": []}, {"text": "Additionally, our model jointly incorporates the language-dependent information from the small set of gold annotations.", "labels": [], "entities": []}, {"text": "Our approach combines these two sources of supervision using multi-task learning, such that the kinds of errors that occur in cross-lingual transfer can be accounted for, and corrected automatically.", "labels": [], "entities": []}, {"text": "We empirically demonstrate the validity of our observation by using distant supervision to improve POS tagging performance with little supervision.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 99, "end_pos": 110, "type": "TASK", "confidence": 0.8718976378440857}]}, {"text": "Experimental results show the effectiveness of our approach across several low-resource languages, including both simulated and true lowresource settings.", "labels": [], "entities": []}, {"text": "Furthermore, given the clear superiority of training with manual annotations, we compare several active learning heuristics.", "labels": [], "entities": []}, {"text": "Active learning using uncertainty sampling with a word-  type bias leads to substantial gains over benchmark methods such as token or sentence level uncertainty sampling.", "labels": [], "entities": []}], "datasetContent": [{"text": "We evaluate the effectiveness of the proposed model for several different languages, including both simulated low-resource and true low-resource settings.", "labels": [], "entities": []}, {"text": "The first evaluation set uses the CoNLL-X datasets of European languages), comprising Danish (da), Dutch (nl), German (de), Greek (el), Italian (it), Portuguese (pt), Spanish (es) and Swedish (sv).", "labels": [], "entities": [{"text": "CoNLL-X datasets", "start_pos": 34, "end_pos": 50, "type": "DATASET", "confidence": 0.9502244591712952}]}, {"text": "We use the standard corpus splits.", "labels": [], "entities": []}, {"text": "The first 20 sentences of training set are used for training as the tiny labelled (gold) data and the last 20 sentences are used for development (early stopping).", "labels": [], "entities": []}, {"text": "We report accuracy on the held-out test set.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9994811415672302}]}, {"text": "The second evaluation set includes two highly challenging languages, Turkish (tk) and Malagasy (mg), both having high morphological complexity and the latter has truly scant resources.", "labels": [], "entities": []}, {"text": "Turkish data was drawn from CoNLL 2003 2 and Malagasy data was collected from , in both cases using the same training configuration as above.", "labels": [], "entities": [{"text": "CoNLL 2003 2", "start_pos": 28, "end_pos": 40, "type": "DATASET", "confidence": 0.9371437033017477}]}, {"text": "In all cases English is used as the source 'high resource' language, on which we train a tagger using the Penn Treebank, and we evaluate on each of the remaining languages as an independent target.", "labels": [], "entities": [{"text": "Penn Treebank", "start_pos": 106, "end_pos": 119, "type": "DATASET", "confidence": 0.9962078928947449}]}, {"text": "For cross-lingual word embeddings, we evaluate two techniques from: CCA-based word embeddings and clusterbased word embeddings.", "labels": [], "entities": []}, {"text": "Both types of word embedding techniques are based on bilingual dictionaries.", "labels": [], "entities": []}, {"text": "The dictionaries were formed by translating the 20k most common words in the En-glish monolingual corpus with Google Translate.", "labels": [], "entities": []}, {"text": "The monolingual corpora were constructed from a combination of text from the Leipzig Corpora Collection and Europarl.", "labels": [], "entities": [{"text": "Leipzig Corpora Collection", "start_pos": 77, "end_pos": 103, "type": "DATASET", "confidence": 0.9487064878145853}, {"text": "Europarl", "start_pos": 108, "end_pos": 116, "type": "DATASET", "confidence": 0.946476399898529}]}, {"text": "We trained the languageuniversal POS tagger based on the cross-lingual word embeddings with the universal POS tagset , and then applied to the target language using the embedding lookup table for the corresponding language embeddings.", "labels": [], "entities": [{"text": "POS tagger", "start_pos": 33, "end_pos": 43, "type": "TASK", "confidence": 0.595834955573082}]}, {"text": "We implement our learning procedure with the DyNet toolkit (.", "labels": [], "entities": []}, {"text": "The BiLSTM layer uses 128 hidden units, and 32 hidden units for the transformation step.", "labels": [], "entities": []}, {"text": "We used SGD with momentum to train models, with early stopping based on development performance.", "labels": [], "entities": []}, {"text": "For benchmarks, we compare the proposed model against various state-of-the-art supervised learning methods, namely: a BILSTM tagger, BILSTM-CRF tagger (, and a state-of-the-art semi-supervised POS tagging algorithm, MINITAGGER, which is also focusing on minimising the amount of labelled data.", "labels": [], "entities": [{"text": "BILSTM", "start_pos": 118, "end_pos": 124, "type": "METRIC", "confidence": 0.8514679670333862}, {"text": "BILSTM-CRF", "start_pos": 133, "end_pos": 143, "type": "METRIC", "confidence": 0.8700894117355347}]}, {"text": "Note these methods do not use cross-lingual supervision.", "labels": [], "entities": []}, {"text": "For a more direct comparison, we include BILSTM-DEBIAS, applied using our proposed cross-lingual supervision based on dictionaries, instead of parallel corpora; accordingly the key difference is their linear transformation for the distant data, versus our non-linear transformation to the gold data.", "labels": [], "entities": [{"text": "BILSTM-DEBIAS", "start_pos": 41, "end_pos": 54, "type": "METRIC", "confidence": 0.9943777918815613}]}, {"text": "Results reports the tagging accuracy, showing that our models consistently outperform the baseline techniques.", "labels": [], "entities": [{"text": "tagging", "start_pos": 20, "end_pos": 27, "type": "TASK", "confidence": 0.9425014853477478}, {"text": "accuracy", "start_pos": 28, "end_pos": 36, "type": "METRIC", "confidence": 0.9663007855415344}]}, {"text": "The poor performance of the supervised methods suggests they are overfitting the small training set, however this is much less of a problem for our approach (labelled Joint).", "labels": [], "entities": []}, {"text": "Note that distant supervision alone gives reasonable performance (labelled DISTANT) however the joint modelling of the ground truth and distant data yields significant improvements in almost all cases.", "labels": [], "entities": [{"text": "DISTANT", "start_pos": 75, "end_pos": 82, "type": "METRIC", "confidence": 0.9614748954772949}]}, {"text": "BILSTM-DEBIAS performs worse than our proposed method, indicating that a linear transformation is insufficient for modelling distant supervision.", "labels": [], "entities": [{"text": "BILSTM-DEBIAS", "start_pos": 0, "end_pos": 13, "type": "METRIC", "confidence": 0.9611302018165588}]}, {"text": "The accuracies are higher overall for the European cf. Turkic languages, presumably because these languages are Although the use of a translation system conveys a dependence on parallel text, high quality word embeddings can be learned directly from bilingual dictionaries such as Panlex (: POS tagging accuracy on over the ten target languages, showing first approaches using only the gold data; next methods using only distant cross-lingual supervision, and lastly joint multi-task learning.", "labels": [], "entities": [{"text": "accuracies", "start_pos": 4, "end_pos": 14, "type": "METRIC", "confidence": 0.9972476363182068}, {"text": "Panlex", "start_pos": 281, "end_pos": 287, "type": "DATASET", "confidence": 0.9627244472503662}, {"text": "accuracy", "start_pos": 303, "end_pos": 311, "type": "METRIC", "confidence": 0.9333354234695435}]}, {"text": "English is used as the source language and columns correspond to a specific target language.", "labels": [], "entities": []}, {"text": "closer to English, have higher quality dictionaries and inmost cases are morphologically simpler.", "labels": [], "entities": []}, {"text": "Finally, note the difference between CCA and Cluster methods for learning word embeddings which arise from the differing quality of distant supervision between the languages.", "labels": [], "entities": []}, {"text": "compares various active learning heuristics (see \u00a73) based on different taggers, either a supervised BILSTM (labelled Trad) or our multi-task model which also includes crosslingual supervision (JOINT).", "labels": [], "entities": [{"text": "BILSTM", "start_pos": 101, "end_pos": 107, "type": "METRIC", "confidence": 0.9928517937660217}]}, {"text": "Traditional uncertainty-based sampling strategies (TOKEN(Trad) and SENT(Trad)) do notwork well because models based on limited supervision do not provide accurate uncertainty information, and moreover, annotating at the type rather than token level provides a significantly stronger supervision signal.", "labels": [], "entities": [{"text": "TOKEN", "start_pos": 51, "end_pos": 56, "type": "METRIC", "confidence": 0.8232234120368958}, {"text": "SENT(Trad))", "start_pos": 67, "end_pos": 78, "type": "METRIC", "confidence": 0.8927387297153473}]}, {"text": "The difference is apparent from the decent performance of Random sampling over word types.", "labels": [], "entities": [{"text": "Random sampling", "start_pos": 58, "end_pos": 73, "type": "TASK", "confidence": 0.8079740405082703}]}, {"text": "Overall, SUMTYPE(Joint) outperforms the other heuristics consistently, underlining the importance of cross-lingual distant super-vision, as well as combining the benefits of uncertainty sampling, type selection and a frequency bias.", "labels": [], "entities": [{"text": "type selection", "start_pos": 196, "end_pos": 210, "type": "TASK", "confidence": 0.8392534554004669}]}, {"text": "Comparing the amount of annotation required between the best traditional active learning method SUMTYPE(Trad) and our best method SUMTYPE(Joint), we achieve the same performance with an order of magnitude less annotated data (100 vs. 1, 000 labelled words).", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: POS tagging accuracy on over the ten target languages, showing first approaches using only the  gold data; next methods using only distant cross-lingual supervision, and lastly joint multi-task learning.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 10, "end_pos": 21, "type": "TASK", "confidence": 0.8208862841129303}, {"text": "accuracy", "start_pos": 22, "end_pos": 30, "type": "METRIC", "confidence": 0.9722769260406494}]}]}