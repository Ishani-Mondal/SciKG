{"title": [{"text": "Learning Discourse-level Diversity for Neural Dialog Models using Conditional Variational Autoencoders", "labels": [], "entities": [{"text": "Learning Discourse-level Diversity", "start_pos": 0, "end_pos": 34, "type": "TASK", "confidence": 0.6035153468449911}, {"text": "Neural Dialog Models", "start_pos": 39, "end_pos": 59, "type": "TASK", "confidence": 0.7901320060094198}]}], "abstractContent": [{"text": "While recent neural encoder-decoder models have shown great promise in mod-eling open-domain conversations, they often generate dull and generic responses.", "labels": [], "entities": []}, {"text": "Unlike past work that has focused on diversifying the output of the decoder at word-level to alleviate this problem, we present a novel framework based on conditional variational autoencoders that captures the discourse-level diversity in the encoder.", "labels": [], "entities": []}, {"text": "Our model uses latent variables to learn a distribution over potential conversational intents and generates diverse responses using only greedy de-coders.", "labels": [], "entities": []}, {"text": "We have further developed a novel variant that is integrated with linguistic prior knowledge for better performance.", "labels": [], "entities": []}, {"text": "Finally, the training procedure is improved by introducing a bag-of-word loss.", "labels": [], "entities": []}, {"text": "Our proposed models have been validated to generate significantly more diverse responses than baseline approaches and exhibit competence in discourse-level decision-making.", "labels": [], "entities": []}], "introductionContent": [{"text": "The dialog manager is one of the key components of dialog systems, which is responsible for modeling the decision-making process.", "labels": [], "entities": []}, {"text": "Specifically, it typically takes anew utterance and the dialog context as input, and generates discourse-level decisions (.", "labels": [], "entities": []}, {"text": "Advanced dialog managers usually have a list of potential actions that enable them to have diverse behavior during a conversation, e.g. different strategies to recover from non-understanding (.", "labels": [], "entities": []}, {"text": "However, the conventional approach of designing a dialog manager does not scale well to open-domain conversation models because of the vast quantity of possible decisions.", "labels": [], "entities": []}, {"text": "Thus, there has been a growing interest in applying encoder-decoder models) for modeling open-domain conversation).", "labels": [], "entities": []}, {"text": "The basic approach treats a conversation as a transduction task, in which the dialog history is the source sequence and the next response is the target sequence.", "labels": [], "entities": []}, {"text": "The model is then trained end-to-end on large conversation corpora using the maximum-likelihood estimation (MLE) objective without the need for manual crafting.", "labels": [], "entities": [{"text": "maximum-likelihood estimation (MLE) objective", "start_pos": 77, "end_pos": 122, "type": "METRIC", "confidence": 0.7450784494479498}]}, {"text": "However recent research has found that encoder-decoder models tend to generate generic and dull responses (e.g., I don't know), rather than meaningful and specific answers ().", "labels": [], "entities": []}, {"text": "There have been many attempts to explain and solve this limitation, and they can be broadly divided into two categories (see Section 2 for details): (1) the first category argues that the dialog history is only one of the factors that decide the next response.", "labels": [], "entities": []}, {"text": "Other features should be extracted and provided to the models as conditionals in order to generate more specific responses (; (2) the second category aims to improve the encoder-decoder model itself, including decoding with beam search and its variations, encouraging responses that have long-term payoff (), etc.", "labels": [], "entities": []}, {"text": "Building upon the past work in dialog managers and encoder-decoder models, the key idea of this paper is to model dialogs as a one-to-many problem at the discourse level.", "labels": [], "entities": []}, {"text": "Previous studies indicate that there are many factors in open-domain dialogs that decide the next response, and it is nontrivial to extract all of them.", "labels": [], "entities": []}, {"text": "Intuitively, given a similar dialog history (and other observed inputs), there may exist many valid responses (at the discourse-level), each corresponding to a certain configuration of the latent variables that are not presented in the input.", "labels": [], "entities": []}, {"text": "To uncover the potential responses, we strive to model a probabilistic distribution over the distributed utterance embeddings of the potential responses using a latent variable).", "labels": [], "entities": []}, {"text": "This allows us to generate diverse responses by drawing samples from the learned distribution and reconstruct their words via a decoder neural network.", "labels": [], "entities": []}, {"text": "Specifically, our contributions are three-fold: 1.", "labels": [], "entities": []}, {"text": "We present a novel neural dialog model adapted from conditional variational autoencoders (CVAE) (, which introduces a latent variable that can capture discourse-level variations as described above 2.", "labels": [], "entities": []}, {"text": "We propose Knowledge-Guided CVAE (kgC-VAE), which enables easy integration of expert knowledge and results in performance improvement and model interpretability.", "labels": [], "entities": []}, {"text": "3. We develop a training method in addressing the difficulty of optimizing CVAE for natural language generation (.", "labels": [], "entities": [{"text": "natural language generation", "start_pos": 84, "end_pos": 111, "type": "TASK", "confidence": 0.6753404140472412}]}, {"text": "We evaluate our models on human-human conversation data and yield promising results in: (a) generating appropriate and discourse-level diverse responses, and (b) showing that the proposed training method is more effective than the previous techniques.", "labels": [], "entities": []}], "datasetContent": [{"text": "We chose the Switchboard (SW) 1 Release 2 Corpus) to evaluate the proposed models.", "labels": [], "entities": [{"text": "Switchboard (SW) 1 Release 2 Corpus", "start_pos": 13, "end_pos": 48, "type": "DATASET", "confidence": 0.5998190678656101}]}, {"text": "SW has 2400 two-sided telephone conversations with manually transcribed speech and alignment.", "labels": [], "entities": [{"text": "SW", "start_pos": 0, "end_pos": 2, "type": "DATASET", "confidence": 0.8369103670120239}]}, {"text": "In the beginning of the call, a computer operator gave the callers recorded prompts that define the desired topic of discussion.", "labels": [], "entities": []}, {"text": "There are 70 available topics.", "labels": [], "entities": []}, {"text": "We randomly split the data into 2316/60/62 dialogs for train/validate/test.", "labels": [], "entities": []}, {"text": "The pre-processing includes (1) tokenize using the NLTK tokenizer (; (2) remove non-verbal symbols and repeated words due to false starts; (3) keep the top 10K frequent word types as the vocabulary.", "labels": [], "entities": []}, {"text": "The final data have 207, 833/5, 225/5, 481 (c, x) pairs for train/validate/test.", "labels": [], "entities": []}, {"text": "Furthermore, a subset of SW was manually labeled with dialog acts ().", "labels": [], "entities": []}, {"text": "We extracted dialog act labels based on the dialog act recognizer proposed in ().", "labels": [], "entities": [{"text": "dialog act recognizer", "start_pos": 44, "end_pos": 65, "type": "TASK", "confidence": 0.6461107929547628}]}, {"text": "The features include the uni-gram and bi-gram of the utterance, and the contextual features of the last 3 utterances.", "labels": [], "entities": []}, {"text": "We trained a Support Vector Machine (SVM)) with linear kernel on the subset of SW with human annotations.", "labels": [], "entities": []}, {"text": "There are 42 types of dialog acts and the SVM achieved 77.3% accuracy on held-out data.", "labels": [], "entities": [{"text": "SVM", "start_pos": 42, "end_pos": 45, "type": "TASK", "confidence": 0.6079055070877075}, {"text": "accuracy", "start_pos": 61, "end_pos": 69, "type": "METRIC", "confidence": 0.9995846152305603}]}, {"text": "Then the rest of SW data are labelled with dialog acts using the trained SVM dialog act recognizer.", "labels": [], "entities": [{"text": "SVM dialog act recognizer", "start_pos": 73, "end_pos": 98, "type": "TASK", "confidence": 0.5975652486085892}]}, {"text": "We compared three neural dialog models: a strong baseline model, CVAE, and kgCVAE.", "labels": [], "entities": []}, {"text": "The baseline model is an encoder-decoder neural dialog model without latent variables similar to).", "labels": [], "entities": []}, {"text": "The baseline model's encoder uses the same context encoder to encode the dialog history and the meta features as shown in.", "labels": [], "entities": []}, {"text": "The encoded context c is directly fed into the decoder networks as the initial state.", "labels": [], "entities": []}, {"text": "The hyperparameters of the baseline are the same as the ones reported in Section 4.2 and the baseline is trained to minimize the standard cross entropy loss of the decoder RNN model without any auxiliary loss.", "labels": [], "entities": []}, {"text": "Also, to compare the diversity introduced by the stochasticity in the proposed latent variable versus the softmax of RNN at each decoding step, we generate N responses from the baseline by sam-pling from the softmax.", "labels": [], "entities": []}, {"text": "For CVAE/kgCVAE, we sample N times from the latent z and only use greedy decoders so that the randomness comes entirely from the latent variable z.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Performance of each model on automatic  measures. The highest score in each row is in  bold. Note that our BLEU scores are normalized  to", "labels": [], "entities": [{"text": "BLEU", "start_pos": 117, "end_pos": 121, "type": "METRIC", "confidence": 0.9984660148620605}]}, {"text": " Table 3: The reconstruction perplexity and KL  terms on Penn Treebank test set.", "labels": [], "entities": [{"text": "KL", "start_pos": 44, "end_pos": 46, "type": "METRIC", "confidence": 0.9099012613296509}, {"text": "Penn Treebank test set", "start_pos": 57, "end_pos": 79, "type": "DATASET", "confidence": 0.996354341506958}]}]}