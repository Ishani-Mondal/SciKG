{"title": [{"text": "EUROSENSE: Automatic Harvesting of Multilingual Sense Annotations from Parallel Text", "labels": [], "entities": [{"text": "EUROSENSE", "start_pos": 0, "end_pos": 9, "type": "DATASET", "confidence": 0.9132985472679138}, {"text": "Automatic Harvesting of Multilingual Sense Annotations from Parallel Text", "start_pos": 11, "end_pos": 84, "type": "TASK", "confidence": 0.8310384054978689}]}], "abstractContent": [{"text": "Parallel corpora are widely used in a variety of Natural Language Processing tasks, from Machine Translation to cross-lingual Word Sense Disambiguation, where parallel sentences can be exploited to automatically generate high-quality sense annotations on a large scale.", "labels": [], "entities": [{"text": "Machine Translation", "start_pos": 89, "end_pos": 108, "type": "TASK", "confidence": 0.8256402015686035}, {"text": "cross-lingual Word Sense Disambiguation", "start_pos": 112, "end_pos": 151, "type": "TASK", "confidence": 0.6178038641810417}]}, {"text": "In this paper we present EUROSENSE, a multilingual sense-annotated resource based on the joint disambiguation of the Europarl parallel corpus, with almost 123 million sense annotations for over 155 thousand distinct concepts and entities from a language-independent unified sense inventory.", "labels": [], "entities": [{"text": "Europarl parallel corpus", "start_pos": 117, "end_pos": 141, "type": "DATASET", "confidence": 0.9638312657674154}]}, {"text": "We evaluate the quality of our sense annotations intrinsically and extrinsically, showing their effectiveness as training data for Word Sense Disambiguation.", "labels": [], "entities": [{"text": "Word Sense Disambiguation", "start_pos": 131, "end_pos": 156, "type": "TASK", "confidence": 0.634599765141805}]}], "introductionContent": [{"text": "One of the long-standing challenges in Natural Language Processing (NLP) lies in automatically identifying the meaning of words in context.", "labels": [], "entities": [{"text": "Natural Language Processing (NLP)", "start_pos": 39, "end_pos": 72, "type": "TASK", "confidence": 0.7330824434757233}, {"text": "automatically identifying the meaning of words in context", "start_pos": 81, "end_pos": 138, "type": "TASK", "confidence": 0.7690120115876198}]}, {"text": "Various lines of research have been geared towards achieving this goal, most notably Word Sense Disambiguation and Entity Linking (.", "labels": [], "entities": [{"text": "Word Sense Disambiguation", "start_pos": 85, "end_pos": 110, "type": "TASK", "confidence": 0.6071037153402964}, {"text": "Entity Linking", "start_pos": 115, "end_pos": 129, "type": "TASK", "confidence": 0.7386951148509979}]}, {"text": "In both tasks, supervised approaches ( tend to obtain the best performances over standard benchmarks but, from a practical standpoint, they lose ground to knowledge-based approaches, which scale better in terms of scope and number of languages.", "labels": [], "entities": []}, {"text": "In fact, the development of supervised disambiguation systems depends crucially on the availability of reliable sense-annotated corpora, which are indispensable in order to provide solid training and testing grounds).", "labels": [], "entities": []}, {"text": "However, hand-labeled sense annotations are notoriously difficult to obtain on a large scale, and manually curated corpora) have a limited size.", "labels": [], "entities": []}, {"text": "Given that scaling the manual annotation process becomes practically unfeasible when both lexicographic and encyclopedic knowledge is addressed (), recent years have witnessed efforts to produce larger sense-annotated corpora automatically (.", "labels": [], "entities": []}, {"text": "Even though these automatic approaches produce noisier corpora, it has been shown that training on them leads to better supervised and semi-supervised models, as well as to effective embedded representations for senses.", "labels": [], "entities": []}, {"text": "A convenient way of generating sense annotations is to exploit parallel corpora and word alignments: indeed, parallel corpora exist in many flavours ( and are widely used across the NLP community fora variety of different tasks.", "labels": [], "entities": [{"text": "word alignments", "start_pos": 84, "end_pos": 99, "type": "TASK", "confidence": 0.6861726641654968}]}, {"text": "In this paper we focus on Europarl ( , one of the most popular multilingual corpora, originally designed to provide aligned parallel text for Machine Translation (MT) systems.", "labels": [], "entities": [{"text": "Europarl", "start_pos": 26, "end_pos": 34, "type": "DATASET", "confidence": 0.9618201851844788}, {"text": "Machine Translation (MT)", "start_pos": 142, "end_pos": 166, "type": "TASK", "confidence": 0.8595374822616577}]}, {"text": "Extracted from the proceedings of the European Parliament, the latest release of the Europarl corpus comprises parallel text for 21 European languages, with more than 743 million tokens overall.", "labels": [], "entities": [{"text": "Europarl corpus", "start_pos": 85, "end_pos": 100, "type": "DATASET", "confidence": 0.980651468038559}]}, {"text": "Apart from its prominent role in MT as a training set, the Europarl corpus has been used for cross-lingual WSD (, including, more recently, preposition sense disambiguation, and widely exploited to develop cross-lingual word embeddings () as well as multi-sense embeddings (.", "labels": [], "entities": [{"text": "MT", "start_pos": 33, "end_pos": 35, "type": "TASK", "confidence": 0.9884220957756042}, {"text": "Europarl corpus", "start_pos": 59, "end_pos": 74, "type": "DATASET", "confidence": 0.9841033816337585}, {"text": "preposition sense disambiguation", "start_pos": 140, "end_pos": 172, "type": "TASK", "confidence": 0.6463354627291361}]}, {"text": "In this paper, our aim is to augment Europarl with sense-level information for multiple languages, thereby constructing a large-scale senseannotated multilingual corpus which has the potential to boost both WSD and MT research.", "labels": [], "entities": [{"text": "Europarl", "start_pos": 37, "end_pos": 45, "type": "DATASET", "confidence": 0.9330431222915649}, {"text": "WSD", "start_pos": 207, "end_pos": 210, "type": "TASK", "confidence": 0.9581661820411682}, {"text": "MT", "start_pos": 215, "end_pos": 217, "type": "TASK", "confidence": 0.9041759371757507}]}, {"text": "We follow an approach that has already proved effective in a definitional setting (CamachoCollados et al., 2016a): unlike previous crosslingual approaches, we do not rely on word alignments against a pivot language, but instead leverage all languages at the same time in a joint disambiguation procedure that is subsequently refined using distributional similarity.", "labels": [], "entities": []}, {"text": "We draw on the wide-coverage multilingual encyclopedic dictionary of BabelNet (Navigli and Ponzetto, 2012) 2 , which enables us to seamlessly cover lexicographic and encyclopedic knowledge in multiple languages within a unified sense inventory.", "labels": [], "entities": []}, {"text": "As a result of our disambiguation pipeline we obtain and make available to the community EU-ROSENSE, a multilingual sense-annotated corpus with almost 123 million sense annotations of more than 155 thousand distinct concepts and named entities drawn from the multilingual sense inventory of BabelNet, and covering all the 21 languages of the Europarl corpus.", "labels": [], "entities": [{"text": "EU-ROSENSE", "start_pos": 89, "end_pos": 99, "type": "DATASET", "confidence": 0.9139918684959412}, {"text": "Europarl corpus", "start_pos": 342, "end_pos": 357, "type": "DATASET", "confidence": 0.9888550937175751}]}, {"text": "As such EUROSENSE constitutes, to our knowledge, the largest corpus of its kind.", "labels": [], "entities": [{"text": "EUROSENSE", "start_pos": 8, "end_pos": 17, "type": "DATASET", "confidence": 0.9457544088363647}]}], "datasetContent": [{"text": "We assessed the quality of EUROSENSE's sense annotations both intrinsically, by means of a manual evaluation on four samples of randomly extracted sentences in different languages (Section 5.1), as well as extrinsically, by augmenting the training set of a state-of-the-art supervised WSD system ( and showing that it leads to consistent performance improvements over two standard WSD benchmarks (Section 5.2).", "labels": [], "entities": []}, {"text": "In order to assess annotation quality directly, we carried out a manual evaluation on 4 different languages (English, French, German and Spanish) with 2 human judges per language.", "labels": [], "entities": []}, {"text": "We sampled 50 random sentences across the subset of sentences in EUROSENSE featuring a translation in all 4 languages, totaling 200 sentences overall.", "labels": [], "entities": [{"text": "EUROSENSE", "start_pos": 65, "end_pos": 74, "type": "DATASET", "confidence": 0.9617063999176025}]}, {"text": "For each sentence, we evaluated all sense annotations both before and after the refinement stage, along with the sense annotations obtained by a baseline that disambiguates each sentence in isolation with Babelfy.", "labels": [], "entities": []}, {"text": "Overall, we manually verified a total of 5818 sense annotations across the three configurations.", "labels": [], "entities": []}, {"text": "In every language the two judges agreed in more than 85% of the cases, with an inter-annotator agreement in terms of Cohen's kappa above 60% in all evaluations (67.7% on average).", "labels": [], "entities": []}, {"text": "Results, reported in, show that joint multilingual disambiguation improves consistently over the baseline.", "labels": [], "entities": []}, {"text": "The similarity-based refinement boosts precision even further, at the expense of a reduced coverage (whereas both Babelfy and the baseline attempt an answer for every disambiguation target).", "labels": [], "entities": [{"text": "precision", "start_pos": 39, "end_pos": 48, "type": "METRIC", "confidence": 0.9994258880615234}, {"text": "coverage", "start_pos": 91, "end_pos": 99, "type": "METRIC", "confidence": 0.9848926067352295}]}, {"text": "Over the 4 languages, sense annotations appear to be most reliable for German, which is consistent with its lower lexical ambiguity on the corpus (cf. Section 4).", "labels": [], "entities": []}, {"text": "We additionally carried out an extrinsic evaluation of EUROSENSE by using its refined sense an-, IMS trained on our augmented training set consistently outperforms all baseline models, showing the reliability of EUROSENSE as training corpus, even against sense annotations obtained semiautomatically (Taghipour and Ng, 2015a).", "labels": [], "entities": [{"text": "EUROSENSE", "start_pos": 55, "end_pos": 64, "type": "DATASET", "confidence": 0.9572141170501709}, {"text": "IMS", "start_pos": 97, "end_pos": 100, "type": "METRIC", "confidence": 0.9715325236320496}]}], "tableCaptions": [{"text": " Table 1: General statistics on EUROSENSE before (full) and after refinement (refined) for all the 21  languages. Language-specific figures are also reported for the 4 languages of the intrinsic evaluation.", "labels": [], "entities": [{"text": "EUROSENSE", "start_pos": 32, "end_pos": 41, "type": "DATASET", "confidence": 0.8634637594223022}]}, {"text": " Table 2: Precision (Prec.) and coverage (Cov.) of EUROSENSE, manually evaluated on a random sample  in 4 languages. Precision is averaged between the two judges, and coverage is computed assuming each  content word in the sense inventory to be a valid disambiguation target.", "labels": [], "entities": [{"text": "Precision (Prec.)", "start_pos": 10, "end_pos": 27, "type": "METRIC", "confidence": 0.9083893895149231}, {"text": "coverage (Cov.)", "start_pos": 32, "end_pos": 47, "type": "METRIC", "confidence": 0.9648455828428268}, {"text": "EUROSENSE", "start_pos": 51, "end_pos": 60, "type": "DATASET", "confidence": 0.9200380444526672}, {"text": "Precision", "start_pos": 117, "end_pos": 126, "type": "METRIC", "confidence": 0.9733209013938904}, {"text": "coverage", "start_pos": 167, "end_pos": 175, "type": "METRIC", "confidence": 0.9842155575752258}]}, {"text": " Table 3: F-Score on all-words WSD.", "labels": [], "entities": [{"text": "F-Score", "start_pos": 10, "end_pos": 17, "type": "METRIC", "confidence": 0.9983215928077698}, {"text": "WSD", "start_pos": 31, "end_pos": 34, "type": "METRIC", "confidence": 0.44402122497558594}]}]}