{"title": [{"text": "Naturalizing a Programming Language via Interactive Learning", "labels": [], "entities": []}], "abstractContent": [{"text": "Our goal is to create a convenient natural language interface for performing well-specified but complex actions such as analyzing data, manipulating text, and querying databases.", "labels": [], "entities": []}, {"text": "However, existing natural language interfaces for such tasks are quite primitive compared to the power one wields with a programming language.", "labels": [], "entities": []}, {"text": "To bridge this gap, we start with a core programming language and allow users to \"naturalize\" the core language incremen-tally by defining alternative, more natural syntax and increasingly complex concepts in terms of compositions of simpler ones.", "labels": [], "entities": []}, {"text": "Ina voxel world, we show that a community of users can simultaneously teach a common system a diverse language and use it to build hundreds of complex voxel structures.", "labels": [], "entities": []}, {"text": "Over the course of three days, these users went from using only the core language to using the naturalized language in 85.9% of the last 10K utterances.", "labels": [], "entities": []}], "introductionContent": [{"text": "In tasks such as analyzing and plotting data, querying databases (, manipulating text (, or controlling the Internet of) and robots), people need computers to perform well-specified but complex actions.", "labels": [], "entities": [{"text": "analyzing and plotting data", "start_pos": 17, "end_pos": 44, "type": "TASK", "confidence": 0.6719168871641159}]}, {"text": "To accomplish this, one route is to use a programming language, but this is inaccessible to most and can be tedious even for experts because the syntax is uncompromising and all statements have to be precise.", "labels": [], "entities": []}, {"text": "Another route is to convert natural language into a formal lanCubes: initial -select left 6 -select front 8 -black 10x10x10 frame -black 10x10x10 frame -move front 10 -red cube size 6 -move bot 2 -blue cube size 6 -green cube size 4 -(some steps are omitted) Monsters, Inc: initial -move forward -add green monster -go down 8 -go right and front -add brown floor -add girl -go back and down -add door -add black column 30 -go up 9 -finish door -(some steps for moving are omitted) Deer: initial -bird's eye view -deer head; up; left 2; back 2; { left antler }; right 2; {right antler} -down 4; front 2; left 3; deer body; down 6; {deer leg front}; back 7; {deer leg back}; left 4; {deer leg back}; front 7; {deer leg front} -(some steps omitted): Some examples of users building structures using a naturalized language in Voxelurn: http://www.voxelurn.com guage, which has been the subject of work in semantic parsing.", "labels": [], "entities": [{"text": "semantic parsing", "start_pos": 901, "end_pos": 917, "type": "TASK", "confidence": 0.7401947975158691}]}, {"text": "However, the capability of semantic parsers is still quite primitive compared to the power one wields with a programming language.", "labels": [], "entities": []}, {"text": "This gap is increasingly limiting the potential of both text and voice interfaces as they become more ubiquitous and desirable.", "labels": [], "entities": []}, {"text": "In this paper, we propose bridging this gap with an interactive language learning process which we call naturalization.", "labels": [], "entities": []}, {"text": "Before any learning, we seed a system with a core programming language that is always available to the user.", "labels": [], "entities": []}, {"text": "As users instruct the system to perform actions, they augment the language by defining new utterances -e.g., the user can explicitly tell the computer that 'X' means 'Y'.", "labels": [], "entities": []}, {"text": "Through this process, users gradually and interactively teach the system to understand the language that they want to use, rather than the core language that they are forced to use initially.", "labels": [], "entities": []}, {"text": "While the first users have to learn the core language, later users can make use of everything that is already taught.", "labels": [], "entities": []}, {"text": "This process accommodates both users' preferences and the computer action space, where the final language is both interpretable by the computer and easier to produce by human users.", "labels": [], "entities": []}, {"text": "Compared to interactive language learning with weak denotational supervision (, definitions are critical for learning complex actions ().", "labels": [], "entities": []}, {"text": "Definitions equate a novel utterance to a sequence of utterances that the system already understands.", "labels": [], "entities": []}, {"text": "For example, 'go left 6 and go front' might be defined as 'repeat 6 [go left]; go front', which eventually can be traced back to the expression 'repeat 6 [select left of this]; select front of this' in the core language.", "labels": [], "entities": []}, {"text": "Unlike function definitions in programming languages, the user writes concrete values rather than explicitly declaring arguments.", "labels": [], "entities": []}, {"text": "The system automatically extracts arguments and learns to produce the correct generalizations.", "labels": [], "entities": []}, {"text": "For this, we propose a grammar induction algorithm tailored to the learning from definitions setting.", "labels": [], "entities": [{"text": "grammar induction", "start_pos": 23, "end_pos": 40, "type": "TASK", "confidence": 0.7052696943283081}]}, {"text": "Compared to standard machine learning, say from demonstrations, definitions provide a much more powerful learning signal: the system is told directly that 'a 3 by 4 red square' is '3 red columns of height 4', and does not have to infer how to generalize from observing many structures of different sizes.", "labels": [], "entities": []}, {"text": "We implemented a system called Voxelurn, which is a command language interface fora voxel world initially equipped with a programming language supporting conditionals, loops, and variable scoping etc.", "labels": [], "entities": [{"text": "Voxelurn", "start_pos": 31, "end_pos": 39, "type": "DATASET", "confidence": 0.911323606967926}]}, {"text": "We recruited 70 users from Amazon Mechanical Turk to build 230 voxel structures using our system.", "labels": [], "entities": []}, {"text": "All users teach the system at once, and what is learned from one user can be used by another user.", "labels": [], "entities": []}, {"text": "Thus a community of users evolves the language to becomes more efficient overtime, in a distributed way, through interaction.", "labels": [], "entities": []}, {"text": "We show that the user community defined many new utterances-short forms, alternative syntax, and also complex concepts such as 'add green monster, add yellow plate 3 x 3'.", "labels": [], "entities": []}, {"text": "As the system learns, users increasingly prefer to use the naturalized language over the core language: 85.9% of the last 10K accepted utterances are in the naturalized language.", "labels": [], "entities": []}], "datasetContent": [{"text": "Our ultimate goal is to create a community of users who can build interesting structures in Voxelurn while naturalizing the core language.", "labels": [], "entities": [{"text": "Voxelurn", "start_pos": 92, "end_pos": 100, "type": "DATASET", "confidence": 0.9387568235397339}]}, {"text": "We created this community using Amazon Mechanical Turk (AMT) in two stages.", "labels": [], "entities": [{"text": "Amazon Mechanical Turk (AMT)", "start_pos": 32, "end_pos": 60, "type": "DATASET", "confidence": 0.8703921238581339}]}, {"text": "First, we had qualifier tasks, in which an AMT worker was instructed to replicate a fixed target exactly), ensuring that the initial users are familiar with at least some of the core language, which is the starting point of the naturalization process.", "labels": [], "entities": []}, {"text": "Next, we allowed the workers who qualified to enter the second freebuilding task, in which they were asked to build any structure they wanted in 30 minutes.", "labels": [], "entities": []}, {"text": "This process was designed to give users freedom while ensuring quality.", "labels": [], "entities": []}, {"text": "The analogy of this scheme in areal system is that early users (or a small portion of expert users) have to make some learning investment, so the system can learn and become easier for other users.", "labels": [], "entities": []}, {"text": "70 workers passed the qualifier task, and 42 workers participated in the final freebuilding experiment.", "labels": [], "entities": []}, {"text": "There were over 103,000 queries consisting of 5,388 distinct token types.", "labels": [], "entities": []}, {"text": "Of these, 64,075 utterances were tried and 36,589 were accepted (so an action was performed).", "labels": [], "entities": []}, {"text": "There were 2,495 definitions combining over 15,000 body utterances with 6.5 body utterances per head on average (96 max).", "labels": [], "entities": []}, {"text": "From these definitions, 2,817 grammar rules were induced, compared to less than 100 core rules.", "labels": [], "entities": []}, {"text": "Over all queries, there were 8.73 parses per utterance on average (starting from 1 for core).", "labels": [], "entities": []}, {"text": "The answer is yes according to, which plots the cummulative percentage of utterances that are core, induced, or unparsable.", "labels": [], "entities": []}, {"text": "To rule out that more induced utterances are getting rejected, we consider only accepted utterances in the middle of, which plots the percentage of induced rules among accepted utterances for the entire community, as well as for the 5 heaviest users.", "labels": [], "entities": []}, {"text": "Since unparsable utterances cannot be accepted, accepted core (which is not shown) is the complement of accepted induced.", "labels": [], "entities": []}, {"text": "At the conclusion of the experiment, 72.9% of all accepted utterances are induced-this becomes 85.9% if we only consider the final 10,000 accepted utterances.", "labels": [], "entities": []}, {"text": "Three modes of naturalization are outlined in.", "labels": [], "entities": []}, {"text": "For very common operations, like moving the selection, people found 'select left' too verbose and shorterned this to l, left, >, sell.", "labels": [], "entities": []}, {"text": "One user preferred 'go down and right' instead of 'select bot; select right' in core and defined it as 'go down; go right'.", "labels": [], "entities": []}, {"text": "Definitions for high-level concepts tend to be whole objects that are not parameterized (e.g., 'dancer').", "labels": [], "entities": []}, {"text": "The bottom plot of suggests that users are defining and using higher level concepts, since programs become longer relative to utterances overtime.", "labels": [], "entities": []}, {"text": "As a result of the automatic but implicit grammar induction, some concepts do not generalize correctly.", "labels": [], "entities": []}, {"text": "In definition head '3 tall 9 wide white tower centered here', arguments do not match the body; for 'black 10x10x10 frame', we failed to tokenize.", "labels": [], "entities": []}, {"text": "Short forms left, l, mov left, go left, <, sel left br, black, blu, brn, orangeright, left3 add row brn left 5 := add row brown left 5 Alternative syntax go down and right := go down; go right select orange := select has color orange add red top 4 times := repeat 4 [add red top] l white := go left and add white mov up 2 := repeat 2 [select up] go up 3 := go up 2; go up Higher level add red plate 6 x 7, green cube size 4, add green monster, black 10x10x10 frame, flower petals, deer leg back, music box, dancer Learned parameters.", "labels": [], "entities": []}, {"text": "Training using L1 regularization, we obtained 1713 features with nonzero parameters.", "labels": [], "entities": []}, {"text": "One user defined many concepts consisting of a single short token, and the Social.Author feature for that user has the most negative weight overall.", "labels": [], "entities": []}, {"text": "With user compatibility (Social.Friends), some pairs have large positive weights and others large negative weights.", "labels": [], "entities": []}, {"text": "The 'isolate' scoping choice (which allows easier hierarchical building) received the most positive weights, both overall and for many users.", "labels": [], "entities": []}, {"text": "The 2 highest scoring induced rules correspond to 'add row red right 5' and 'select left 2'.", "labels": [], "entities": []}, {"text": "Having complex structures show that the actions in Voxelurn are expressive and that hierarchical definitions are useful.", "labels": [], "entities": [{"text": "Voxelurn", "start_pos": 51, "end_pos": 59, "type": "DATASET", "confidence": 0.9190770387649536}]}, {"text": "To incentivize this behavior, we created a leaderboard which ranked structures based on recency and upvotes (like Hacker News).", "labels": [], "entities": [{"text": "Hacker News)", "start_pos": 114, "end_pos": 126, "type": "DATASET", "confidence": 0.8779574036598206}]}, {"text": "Over the course of 3 days, we picked three prize categories to be released daily.", "labels": [], "entities": []}, {"text": "The prize categories for each day were bridge, house, animal; tower, monster, flower; ship, dancer, and castle.", "labels": [], "entities": []}, {"text": "To incentivize more definitions, we also track citations.", "labels": [], "entities": []}, {"text": "When a rule is used in an accepted utterance by another user, the rule (and its author) receives a citation.", "labels": [], "entities": []}, {"text": "We pay bonuses to top users according to their h-index.", "labels": [], "entities": []}, {"text": "Most cited definitions are also displayed on the leaderboard.", "labels": [], "entities": []}, {"text": "Our qualitative results should be robust to the incentives scheme, because the users do not overfit to the incentives-e.g., around 20% of the structures are not in the prize categories and users define complex concepts that are rarely cited.", "labels": [], "entities": []}], "tableCaptions": []}