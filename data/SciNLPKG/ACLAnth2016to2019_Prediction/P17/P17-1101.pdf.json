{"title": [{"text": "Selective Encoding for Abstractive Sentence Summarization", "labels": [], "entities": [{"text": "Summarization", "start_pos": 44, "end_pos": 57, "type": "TASK", "confidence": 0.7468586564064026}]}], "abstractContent": [{"text": "We propose a selective encoding model to extend the sequence-to-sequence framework for abstractive sentence summariza-tion.", "labels": [], "entities": []}, {"text": "It consists of a sentence encoder, a selective gate network, and an attention equipped decoder.", "labels": [], "entities": []}, {"text": "The sentence en-coder and decoder are built with recurrent neural networks.", "labels": [], "entities": []}, {"text": "The selective gate network constructs a second level sentence representation by controlling the information flow from encoder to decoder.", "labels": [], "entities": []}, {"text": "The second level representation is tailored for sentence summarization task, which leads to better performance.", "labels": [], "entities": [{"text": "sentence summarization task", "start_pos": 48, "end_pos": 75, "type": "TASK", "confidence": 0.8062723278999329}]}, {"text": "We evaluate our model on the English Gigaword, DUC 2004 and MSR abstractive sentence summarization datasets.", "labels": [], "entities": [{"text": "DUC 2004", "start_pos": 47, "end_pos": 55, "type": "DATASET", "confidence": 0.9000612497329712}, {"text": "MSR abstractive sentence summarization", "start_pos": 60, "end_pos": 98, "type": "TASK", "confidence": 0.6364389359951019}]}, {"text": "The experimental results show that the proposed selective encoding model outperforms the state-of-the-art baseline models.", "labels": [], "entities": []}], "introductionContent": [{"text": "Sentence summarization aims to shorten a given sentence and produce a brief summary of it.", "labels": [], "entities": [{"text": "Sentence summarization", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.9494856595993042}]}, {"text": "This is different from document level summarization task since it is hard to apply existing techniques in extractive methods, such as extracting sentence level features and ranking sentences.", "labels": [], "entities": [{"text": "document level summarization", "start_pos": 23, "end_pos": 51, "type": "TASK", "confidence": 0.5990788737932841}]}, {"text": "Early works propose using rule-based methods (, syntactic tree pruning methods), statistical machine translation techniques () and soon for this task.", "labels": [], "entities": [{"text": "statistical machine translation", "start_pos": 81, "end_pos": 112, "type": "TASK", "confidence": 0.7222241560618082}]}, {"text": "We focus on abstractive sentence summarization task in this paper.", "labels": [], "entities": [{"text": "abstractive sentence summarization", "start_pos": 12, "end_pos": 46, "type": "TASK", "confidence": 0.6539020339647929}]}, {"text": "Recently, neural network models have been applied in this task.", "labels": [], "entities": []}, {"text": "use autoconstructed sentence-headline pairs to train a neu- * Contribution during internship at Microsoft Research.", "labels": [], "entities": []}, {"text": "They use a Convolutional Neural Network (CNN) encoder and feed-forward neural network language model decoder for this task.", "labels": [], "entities": []}, {"text": "extend their work by replacing the decoder with Recurrent Neural Network (RNN).", "labels": [], "entities": []}, {"text": "follow this line and change the encoder to RNN to make it a full RNN based sequence-tosequence model ).", "labels": [], "entities": []}, {"text": "the sri lankan government on wednesday announced the closure of government schools with immediate effect as a military campaign against tamil separatists escalated in the north of the country . sri lanka closes schools as war escalates: An abstractive sentence summarization system may produce the output summary by distilling the salient information from the highlight to generate a fluent sentence.", "labels": [], "entities": [{"text": "abstractive sentence summarization", "start_pos": 240, "end_pos": 274, "type": "TASK", "confidence": 0.6332960526148478}]}, {"text": "We model the distilling process with selective encoding.", "labels": [], "entities": []}, {"text": "All the above works fall into the encodingdecoding paradigm, which first encodes the input sentence to an abstract representation and then decodes the intended output sentence based on the encoded information.", "labels": [], "entities": []}, {"text": "As an extension of the encoding-decoding framework, attentionbased approach () has been broadly used: the encoder produces a list of vectors for all tokens in the input, and the decoder uses an attention mechanism to dynamically extract encoded information and align with the output tokens.", "labels": [], "entities": []}, {"text": "This approach achieves huge success in tasks like machine translation, where alignment between all parts of the input and output are required.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 50, "end_pos": 69, "type": "TASK", "confidence": 0.8421144485473633}]}, {"text": "However, in abstractive sentence summarization, there is no explicit alignment relationship between the input sentence and the summary ex-cept for the extracted common words.", "labels": [], "entities": [{"text": "abstractive sentence summarization", "start_pos": 12, "end_pos": 46, "type": "TASK", "confidence": 0.6054930686950684}]}, {"text": "The challenge here is not to infer the alignment, but to select the highlights while filtering out secondary information in the input.", "labels": [], "entities": []}, {"text": "A desired work-flow for abstractive sentence summarization is encoding, selection, and decoding.", "labels": [], "entities": [{"text": "abstractive sentence summarization", "start_pos": 24, "end_pos": 58, "type": "TASK", "confidence": 0.5780869424343109}]}, {"text": "After selecting the important information from an encoded sentence, the decoder produces the output summary using the selected information.", "labels": [], "entities": []}, {"text": "For example, in given the input sentence, the summarization system first selects the important information, and then rephrases or paraphrases to produce a well-organized summary.", "labels": [], "entities": [{"text": "summarization", "start_pos": 46, "end_pos": 59, "type": "TASK", "confidence": 0.9625353217124939}]}, {"text": "Although this is implicitly modeled in the encoding-decoding framework, we argue that abstractive sentence summarization shall benefit from explicitly modeling this selection process.", "labels": [], "entities": [{"text": "abstractive sentence summarization", "start_pos": 86, "end_pos": 120, "type": "TASK", "confidence": 0.6021700104077657}]}, {"text": "In this paper we propose Selective Encoding for Abstractive Sentence Summarization (SEASS).", "labels": [], "entities": [{"text": "Sentence Summarization (SEASS)", "start_pos": 60, "end_pos": 90, "type": "TASK", "confidence": 0.8000530242919922}]}, {"text": "We treat the sentence summarization as a threephase task: encoding, selection, and decoding.", "labels": [], "entities": [{"text": "sentence summarization", "start_pos": 13, "end_pos": 35, "type": "TASK", "confidence": 0.5851994156837463}]}, {"text": "It consists of a sentence encoder, a selective gate network, and a summary decoder.", "labels": [], "entities": []}, {"text": "First, the sentence encoder reads the input words through an RNN unit to construct the first level sentence representation.", "labels": [], "entities": []}, {"text": "Then the selective gate network selects the encoded information to construct the second level sentence representation.", "labels": [], "entities": []}, {"text": "The selective mechanism controls the information flow from encoder to decoder by applying agate network according to the sentence information, which helps improve encoding effectiveness and release the burden of the decoder.", "labels": [], "entities": []}, {"text": "Finally, the attention-equipped decoder generates the summary using the second level sentence representation.", "labels": [], "entities": []}, {"text": "We conduct experiments on English Gigaword, DUC 2004 and Microsoft Research Abstractive Text Compression test sets.", "labels": [], "entities": [{"text": "DUC 2004", "start_pos": 44, "end_pos": 52, "type": "DATASET", "confidence": 0.9375264048576355}, {"text": "Microsoft Research Abstractive Text Compression test sets", "start_pos": 57, "end_pos": 114, "type": "DATASET", "confidence": 0.8966208951813834}]}, {"text": "Our SEASS model achieves 17.54 ROUGE-2 F1, 9.56 ROUGE-2 recall and 10.63 ROUGE-2 F1 on these test sets respectively, which improves performance compared to the state-of-the-art methods.", "labels": [], "entities": [{"text": "SEASS", "start_pos": 4, "end_pos": 9, "type": "METRIC", "confidence": 0.741185188293457}, {"text": "ROUGE-2 F1", "start_pos": 31, "end_pos": 41, "type": "METRIC", "confidence": 0.7875129282474518}, {"text": "ROUGE-2", "start_pos": 48, "end_pos": 55, "type": "METRIC", "confidence": 0.9776512980461121}, {"text": "recall", "start_pos": 56, "end_pos": 62, "type": "METRIC", "confidence": 0.8613149523735046}, {"text": "ROUGE-2 F1", "start_pos": 73, "end_pos": 83, "type": "METRIC", "confidence": 0.8037946224212646}]}], "datasetContent": [{"text": "In this section we introduce the dataset we use, the evaluation metric, the implementation details, the baselines we compare to, and the performance of our system.", "labels": [], "entities": []}, {"text": "Training Set For our training set, we use a parallel corpus which is constructed from the Anno- English Gigaword Test Set We randomly sample 8000 pairs from the extracted development set as our development set since it is relatively large.", "labels": [], "entities": [{"text": "Anno- English Gigaword Test Set", "start_pos": 90, "end_pos": 121, "type": "DATASET", "confidence": 0.6164005398750305}]}, {"text": "For the test set, we use the same randomly heldout test set of 2000 sentence-summary pairs as.", "labels": [], "entities": []}, {"text": "We also find that except for the empty titles, this test set has some invalid lines like the input sentence containing only one word.", "labels": [], "entities": []}, {"text": "Therefore, we further sample 2000 pairs as our internal test set and release it for future works .  We employ ROUGE  gram) and ROUGE-L (LCS) as the evaluation metrics in the reported experimental results.", "labels": [], "entities": [{"text": "ROUGE  gram", "start_pos": 110, "end_pos": 121, "type": "METRIC", "confidence": 0.9762657284736633}, {"text": "ROUGE-L (LCS)", "start_pos": 127, "end_pos": 140, "type": "METRIC", "confidence": 0.9605540037155151}]}], "tableCaptions": [{"text": " Table 2: Data statistics for the English Giga- word, DUC 2004 and MSR-ATC datasets. #(x)  denotes the number of x, e.g., #(ref) is the num- ber of reference summaries of an input sentence.  AvgInputLen is the average input sentence length  and AvgSummLen is the average summary length.   \u2020DUC 2004 and MSR-ATC datasets are for test  purpose only.", "labels": [], "entities": [{"text": "English Giga- word", "start_pos": 34, "end_pos": 52, "type": "DATASET", "confidence": 0.8559727817773819}, {"text": "DUC 2004", "start_pos": 54, "end_pos": 62, "type": "DATASET", "confidence": 0.8927447497844696}, {"text": "MSR-ATC datasets", "start_pos": 67, "end_pos": 83, "type": "DATASET", "confidence": 0.8912274539470673}, {"text": "AvgSummLen", "start_pos": 245, "end_pos": 255, "type": "METRIC", "confidence": 0.9299325346946716}, {"text": "DUC 2004", "start_pos": 290, "end_pos": 298, "type": "DATASET", "confidence": 0.9569158256053925}, {"text": "MSR-ATC datasets", "start_pos": 303, "end_pos": 319, "type": "DATASET", "confidence": 0.8943763375282288}]}, {"text": " Table 3: Full length ROUGE F1 evaluation results  on the English Gigaword test set used by Rush  et al. (2015). RG in the Table denotes ROUGE.  Results with  \u2021 mark are taken from the correspond- ing papers. The superscript -indicates that our  SEASS model with beam search performs signif- icantly better than it as given by the 95% confi- dence interval in the official ROUGE script.", "labels": [], "entities": [{"text": "F1", "start_pos": 28, "end_pos": 30, "type": "METRIC", "confidence": 0.5182801485061646}, {"text": "English Gigaword test set", "start_pos": 58, "end_pos": 83, "type": "DATASET", "confidence": 0.8169436454772949}, {"text": "RG", "start_pos": 113, "end_pos": 115, "type": "METRIC", "confidence": 0.954503059387207}, {"text": "ROUGE", "start_pos": 137, "end_pos": 142, "type": "METRIC", "confidence": 0.9328205585479736}]}, {"text": " Table 4: Full length ROUGE F1 evaluation on our  internal English Gigaword test data. The super- script -indicates that our SEASS model performs  significantly better than it as given by the 95%  confidence interval in the official ROUGE script.", "labels": [], "entities": [{"text": "F1", "start_pos": 28, "end_pos": 30, "type": "METRIC", "confidence": 0.5408461689949036}, {"text": "English Gigaword test data", "start_pos": 59, "end_pos": 85, "type": "DATASET", "confidence": 0.8058216571807861}, {"text": "SEASS", "start_pos": 125, "end_pos": 130, "type": "METRIC", "confidence": 0.6577998995780945}]}, {"text": " Table 5: ROUGE recall evaluation results on DUC  2004 test set. All these models are tested using  beam search. Results with  \u2021 mark are taken from  the corresponding papers. The superscript -in- dicates that our SEASS model performs signifi- cantly better than it as given by the 95% confi- dence interval in the official ROUGE script.", "labels": [], "entities": [{"text": "recall", "start_pos": 16, "end_pos": 22, "type": "METRIC", "confidence": 0.9077399969100952}, {"text": "DUC  2004 test set", "start_pos": 45, "end_pos": 63, "type": "DATASET", "confidence": 0.9872118085622787}]}, {"text": " Table 6: Full length ROUGE F1 evaluation on  MSR-ATC test set. Beam search are used in both  the baselines and our method. The superscript -", "labels": [], "entities": [{"text": "ROUGE", "start_pos": 22, "end_pos": 27, "type": "METRIC", "confidence": 0.9791117906570435}, {"text": "F1", "start_pos": 28, "end_pos": 30, "type": "METRIC", "confidence": 0.6200326681137085}, {"text": "MSR-ATC test set", "start_pos": 46, "end_pos": 62, "type": "DATASET", "confidence": 0.9607449372609457}]}]}