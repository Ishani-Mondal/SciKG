{"title": [{"text": "Adversarial Adaptation of Synthetic or Stale Data", "labels": [], "entities": [{"text": "Adversarial Adaptation", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.8421224653720856}]}], "abstractContent": [{"text": "Two types of data shift common in practice are 1.", "labels": [], "entities": []}, {"text": "transferring from synthetic data to live user data (a deployment shift), and 2.", "labels": [], "entities": []}, {"text": "transferring from stale data to current data (a temporal shift).", "labels": [], "entities": []}, {"text": "Both cause a distribution mismatch between training and evaluation, leading to a model that overfits the flawed training data and performs poorly on the test data.", "labels": [], "entities": []}, {"text": "We propose a solution to this mismatch problem by framing it as domain adaptation, treating the flawed training dataset as a source domain and the evaluation dataset as a target domain.", "labels": [], "entities": [{"text": "domain adaptation", "start_pos": 64, "end_pos": 81, "type": "TASK", "confidence": 0.7653506696224213}]}, {"text": "To this end, we use and build on several recent advances in neural domain adaptation such as adversarial training () and domain separation network (, proposing anew effective adversarial training scheme.", "labels": [], "entities": [{"text": "domain separation network", "start_pos": 121, "end_pos": 146, "type": "TASK", "confidence": 0.7830282549063364}]}, {"text": "In both supervised and unsupervised adaptation scenarios, our approach yields clear improvement over strong baselines.", "labels": [], "entities": []}, {"text": "We are interested in addressing two types of data shift common in SLU applications.", "labels": [], "entities": []}, {"text": "The first data shift problem happens when we transfer from synthetic data to live user data (a deployment shift).", "labels": [], "entities": []}, {"text": "This is also known as the \"cold-start\" problem; a model cannot be trained on the real usage data prior to deployment simply because it does not exist.", "labels": [], "entities": []}, {"text": "A common practice is to generate a large quantity of synthetic training data that mimics the expected user behavior.", "labels": [], "entities": []}, {"text": "Such synthetic data is crafted using domain-specific knowledge and can be time-consuming.", "labels": [], "entities": []}, {"text": "It is also flawed in that it typically does not match the live user data generated by actual users; the real queries submitted to these systems are different from what the model designers expect to see.", "labels": [], "entities": []}], "introductionContent": [{"text": "The second data shift problem happens when we transfer from stale data to current data (a temporal shift).", "labels": [], "entities": []}, {"text": "In our use case, we have one set of training data from 2013 and wish to handle data from.", "labels": [], "entities": []}, {"text": "This is problematic since the content of the user queries changes overtime (e.g., new restaurant or movie names maybe added).", "labels": [], "entities": []}, {"text": "Consequently, the model performance degrades overtime.", "labels": [], "entities": [{"text": "overtime", "start_pos": 45, "end_pos": 53, "type": "METRIC", "confidence": 0.9643227458000183}]}, {"text": "Both shifts cause a distribution mismatch between training and evaluation, leading to a model that overfits the flawed training data and performs poorly on the test data.", "labels": [], "entities": []}, {"text": "We propose a solution to this mismatch problem by framing it as domain adaptation, treating the flawed training dataset as a source domain and the evaluation dataset as a target domain.", "labels": [], "entities": [{"text": "domain adaptation", "start_pos": 64, "end_pos": 81, "type": "TASK", "confidence": 0.7653506696224213}]}, {"text": "To this end, we use and build on several recent advances in neural domain adaptation such as adversarial training ( and domain separation network (, proposing anew adversarial training scheme based on randomized predictions.", "labels": [], "entities": [{"text": "neural domain adaptation", "start_pos": 60, "end_pos": 84, "type": "TASK", "confidence": 0.8066574732462565}, {"text": "domain separation network", "start_pos": 120, "end_pos": 145, "type": "TASK", "confidence": 0.7377532025178274}]}, {"text": "We consider both supervised and unsupervised adaptation scenarios (i.e., absence/presence of labeled data in the target domain).", "labels": [], "entities": []}, {"text": "We find that unsupervised DA can greatly improve performance without requiring additional annotation.", "labels": [], "entities": [{"text": "DA", "start_pos": 26, "end_pos": 28, "type": "TASK", "confidence": 0.9129350781440735}]}, {"text": "Super-vised DA with a small amount of labeled data gives further improvement on top of unsupervised DA.", "labels": [], "entities": [{"text": "DA", "start_pos": 12, "end_pos": 14, "type": "TASK", "confidence": 0.8998007774353027}]}, {"text": "In experiments, we show clear gains in both deployment and temporal shifts across 5 test domains, yielding average error reductions of 74.04% and 41.46% for intent classification and 70.33% and 32.0% for slot tagging compared to baselines without adaptation.", "labels": [], "entities": [{"text": "error", "start_pos": 115, "end_pos": 120, "type": "METRIC", "confidence": 0.9757757782936096}, {"text": "intent classification", "start_pos": 157, "end_pos": 178, "type": "TASK", "confidence": 0.7445655465126038}, {"text": "slot tagging", "start_pos": 204, "end_pos": 216, "type": "TASK", "confidence": 0.7715778648853302}]}], "datasetContent": [{"text": "In this section, we conducted a series of experiments to evaluate the proposed techniques on datasets obtained from real usage.", "labels": [], "entities": []}, {"text": "We consider 2 possible domain adaptation (DA) scenarios: (1) adaptation of an engineered dataset to a live user dataset and (2) adaptation of an old dataset to anew dataset.", "labels": [], "entities": [{"text": "domain adaptation (DA)", "start_pos": 23, "end_pos": 45, "type": "TASK", "confidence": 0.8478380560874939}]}, {"text": "For the first DA scenario, we test whether our approach can effectively make a system adapt from experimental, engineered data to real-world, live data.", "labels": [], "entities": [{"text": "DA", "start_pos": 14, "end_pos": 16, "type": "TASK", "confidence": 0.9858908653259277}]}, {"text": "We use synthetic data which domain experts manually create based on a given domain schema 2 before the system goes live as the engineered data.", "labels": [], "entities": []}, {"text": "We use transcribed dataset from users' speech input as the live user data.", "labels": [], "entities": []}, {"text": "For the second scenario, we test whether our approach can effectively make a system adapt overtime.", "labels": [], "entities": []}, {"text": "A large number of users will quickly generate a large amount of data, and the usage pattern could also change.", "labels": [], "entities": []}, {"text": "We use annotation data over 1 month in 2013 (more precisely August of 2013) as our old dataset, and use the whole data between 2014 and 2016 as our new dataset regardless of whether the datatype is engineered or live user.", "labels": [], "entities": []}, {"text": "As we describe in the earlier sections, we consider both supervised and unsupervised DA.", "labels": [], "entities": [{"text": "DA", "start_pos": 85, "end_pos": 87, "type": "TASK", "confidence": 0.858763575553894}]}, {"text": "We apply our DA approach with labeled data in the target domain for the supervised setting and with unlabeled data for the unsupervised one.", "labels": [], "entities": []}, {"text": "We give details of the baselines and variants of our approach below.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: The number of intents, the number of  slots and a short description of the test domains.", "labels": [], "entities": []}, {"text": " Table 2: Data statistics for unsupervised domain adaptation; In the first row, the columns are adaptation  of engineered dataset to live user dataset, and and adaptation of old dataset to new dataset. In the second  row, columns are domain, size of labeled training, unlabeled training, development and test sets. *  denotes unlabeled data", "labels": [], "entities": []}, {"text": " Table 3: Intent classification accuracy (%) and slot tagging F1-score (%) for the unsupervised domain  adaptation. The results that perform in each domain are in bold font.", "labels": [], "entities": [{"text": "Intent", "start_pos": 10, "end_pos": 16, "type": "METRIC", "confidence": 0.9974862337112427}, {"text": "accuracy", "start_pos": 32, "end_pos": 40, "type": "METRIC", "confidence": 0.77554851770401}, {"text": "slot tagging", "start_pos": 49, "end_pos": 61, "type": "TASK", "confidence": 0.735422670841217}, {"text": "F1-score", "start_pos": 62, "end_pos": 70, "type": "METRIC", "confidence": 0.9304724931716919}]}, {"text": " Table 4: Data statistics for supervised domain adaptation", "labels": [], "entities": [{"text": "supervised domain adaptation", "start_pos": 30, "end_pos": 58, "type": "TASK", "confidence": 0.6824546058972677}]}, {"text": " Table 5: Intent classification accuracy (%) and slot tagging F1-score (%) for the supervised domain  adaptation.", "labels": [], "entities": [{"text": "Intent", "start_pos": 10, "end_pos": 16, "type": "METRIC", "confidence": 0.9693208336830139}, {"text": "accuracy", "start_pos": 32, "end_pos": 40, "type": "METRIC", "confidence": 0.7842763662338257}, {"text": "slot tagging", "start_pos": 49, "end_pos": 61, "type": "TASK", "confidence": 0.7018421143293381}, {"text": "F1-score", "start_pos": 62, "end_pos": 70, "type": "METRIC", "confidence": 0.9346405267715454}, {"text": "supervised domain  adaptation", "start_pos": 83, "end_pos": 112, "type": "TASK", "confidence": 0.7034058173497518}]}, {"text": " Table 6: Intent classification accuracy (%) and slot  tagging F1-score (%) for the unsupervised domain  adaptation with two different adversarial classifi- cation losses -our claimed random domain pre- dictions (RAND) and adversarial loss (ADVR) of  Ganin et al. (2016) as explained in 3.2.3.", "labels": [], "entities": [{"text": "Intent", "start_pos": 10, "end_pos": 16, "type": "METRIC", "confidence": 0.9639968276023865}, {"text": "accuracy", "start_pos": 32, "end_pos": 40, "type": "METRIC", "confidence": 0.7217332124710083}, {"text": "slot  tagging", "start_pos": 49, "end_pos": 62, "type": "TASK", "confidence": 0.8081733286380768}, {"text": "F1-score", "start_pos": 63, "end_pos": 71, "type": "METRIC", "confidence": 0.9134878516197205}, {"text": "random domain pre- dictions (RAND) and adversarial loss (ADVR)", "start_pos": 184, "end_pos": 246, "type": "METRIC", "confidence": 0.7254545199019569}]}, {"text": " Table 7: Proxy A-distance of resulting models: (1)  engineered and live user dataset and (2) old and  new dataset.", "labels": [], "entities": [{"text": "A-distance", "start_pos": 16, "end_pos": 26, "type": "METRIC", "confidence": 0.6571835875511169}]}, {"text": " Table 8: Distance between different datasets: (1)  engineered and live user dataset and (2) old and  new dataset.", "labels": [], "entities": []}]}