{"title": [{"text": "Improved Word Representation Learning with Sememes", "labels": [], "entities": [{"text": "Improved Word Representation Learning", "start_pos": 0, "end_pos": 37, "type": "TASK", "confidence": 0.899862214922905}]}], "abstractContent": [{"text": "Sememes are minimum semantic units of word meanings, and the meaning of each word sense is typically composed by several sememes.", "labels": [], "entities": []}, {"text": "Since sememes are not explicit for each word, people manually annotate word sememes and form linguistic common-sense knowledge bases.", "labels": [], "entities": []}, {"text": "In this paper, we present that, word sememe information can improve word representation learning (WRL), which maps words into a low-dimensional semantic space and serves as a fundamental step for many NLP tasks.", "labels": [], "entities": [{"text": "word representation learning (WRL)", "start_pos": 68, "end_pos": 102, "type": "TASK", "confidence": 0.7787055820226669}]}, {"text": "The key idea is to utilize word sememes to capture exact meanings of a word within specific contexts accurately.", "labels": [], "entities": []}, {"text": "More specifically, we follow the framework of Skip-gram and present three sememe-encoded models to learn representations of sememes, senses and words , where we apply the attention scheme to detect word senses in various contexts.", "labels": [], "entities": []}, {"text": "We conduct experiments on two tasks including word similarity and word analogy, and our models significantly outperform baselines.", "labels": [], "entities": [{"text": "word similarity", "start_pos": 46, "end_pos": 61, "type": "TASK", "confidence": 0.7499790787696838}, {"text": "word analogy", "start_pos": 66, "end_pos": 78, "type": "TASK", "confidence": 0.7871016561985016}]}, {"text": "The results indicate that WRL can benefit from sememes via the attention scheme, and also confirm our models being capable of correctly modeling sememe information.", "labels": [], "entities": [{"text": "WRL", "start_pos": 26, "end_pos": 29, "type": "METRIC", "confidence": 0.47369933128356934}]}], "introductionContent": [{"text": "Sememes are defined as minimum semantic units of word meanings, and there exists a limited close set of sememes to compose the semantic meanings of an open set of concepts (i.e. word sense).", "labels": [], "entities": []}, {"text": "However, sememes are not explicit * indicates equal contribution \u2020 Corresponding author: Z.", "labels": [], "entities": []}, {"text": "Liu (liuzy@tsinghua.edu.cn) for each word.", "labels": [], "entities": []}, {"text": "Hence, people manually annotate word sememes and build linguistic common-sense knowledge bases.", "labels": [], "entities": []}, {"text": "HowNet () is one of such knowledge bases, which annotates each concept in Chinese with one or more relevant sememes.", "labels": [], "entities": [{"text": "HowNet", "start_pos": 0, "end_pos": 6, "type": "DATASET", "confidence": 0.9295894503593445}]}, {"text": "Different from WordNet, the philosophy of HowNet emphasizes the significance of part and attribute represented by sememes.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 15, "end_pos": 22, "type": "DATASET", "confidence": 0.9370507001876831}, {"text": "HowNet", "start_pos": 42, "end_pos": 48, "type": "DATASET", "confidence": 0.9004680514335632}]}, {"text": "HowNet has been widely utilized in word similarity computation () and sentiment analysis (), and in section 3.2 we will give a detailed introduction to sememes, senses and words in HowNet.", "labels": [], "entities": [{"text": "HowNet", "start_pos": 0, "end_pos": 6, "type": "DATASET", "confidence": 0.9229625463485718}, {"text": "word similarity computation", "start_pos": 35, "end_pos": 62, "type": "TASK", "confidence": 0.7840762933095297}, {"text": "sentiment analysis", "start_pos": 70, "end_pos": 88, "type": "TASK", "confidence": 0.9600757658481598}, {"text": "HowNet", "start_pos": 181, "end_pos": 187, "type": "DATASET", "confidence": 0.9267423748970032}]}, {"text": "In this paper, we aim to incorporate word sememes into word representation learning (WRL) and learn improved word embeddings in a lowdimensional semantic space.", "labels": [], "entities": [{"text": "word representation learning (WRL)", "start_pos": 55, "end_pos": 89, "type": "TASK", "confidence": 0.8263473709424337}]}, {"text": "WRL is a fundamental and critical step in many NLP tasks such as language modeling () and neural machine translation.", "labels": [], "entities": [{"text": "language modeling", "start_pos": 65, "end_pos": 82, "type": "TASK", "confidence": 0.7730673551559448}, {"text": "neural machine translation", "start_pos": 90, "end_pos": 116, "type": "TASK", "confidence": 0.6204587618509928}]}, {"text": "There have been a lot of researches for learning word representations, among which word2vec () achieves a nice balance between effectiveness and efficiency.", "labels": [], "entities": []}, {"text": "In word2vec, each word corresponds to one single embedding, ignoring the polysemy of most words.", "labels": [], "entities": []}, {"text": "To address this issue, () introduces a multiprototype model for WRL, conducting unsupervised word sense induction and embeddings according to context clusters.", "labels": [], "entities": [{"text": "WRL", "start_pos": 64, "end_pos": 67, "type": "TASK", "confidence": 0.8612593412399292}, {"text": "word sense induction", "start_pos": 93, "end_pos": 113, "type": "TASK", "confidence": 0.6323127845923106}]}, {"text": "( ) further utilizes the synset information in WordNet to instruct word sense representation learning.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 47, "end_pos": 54, "type": "DATASET", "confidence": 0.9482319355010986}, {"text": "word sense representation learning", "start_pos": 67, "end_pos": 101, "type": "TASK", "confidence": 0.7891745418310165}]}, {"text": "From these previous studies, we conclude that word sense disambiguation are critical for WR-L, and we believe that the sememe annotation of word senses in HowNet can provide necessary semantic regularization for the both tasks.", "labels": [], "entities": [{"text": "word sense disambiguation", "start_pos": 46, "end_pos": 71, "type": "TASK", "confidence": 0.6853441794713339}, {"text": "HowNet", "start_pos": 155, "end_pos": 161, "type": "DATASET", "confidence": 0.9379441738128662}]}, {"text": "To explore its feasibility, we propose a novel Sememe-Encoded Word Representation Learning (SE-WRL) model, which detects word senses and learns representations simultaneously.", "labels": [], "entities": [{"text": "Sememe-Encoded Word Representation Learning (SE-WRL)", "start_pos": 47, "end_pos": 99, "type": "TASK", "confidence": 0.6987428792885372}]}, {"text": "More specifically, this framework regards each word sense as a combination of its sememes, and iteratively performs word sense disambiguation according to their contexts and learn representations of sememes, senses and words by extending Skip-gram in word2vec (.", "labels": [], "entities": [{"text": "word sense disambiguation", "start_pos": 116, "end_pos": 141, "type": "TASK", "confidence": 0.623976598183314}]}, {"text": "In this framework, an attention-based method is proposed to select appropriate word senses according to contexts automatically.", "labels": [], "entities": []}, {"text": "To take full advantages of sememes, we propose three different learning and attention strategies for SE-WRL.", "labels": [], "entities": []}, {"text": "In experiments, we evaluate our framework on two tasks including word similarity and word analogy, and further conduct case studies on sememe, sense and word representations.", "labels": [], "entities": [{"text": "word similarity", "start_pos": 65, "end_pos": 80, "type": "TASK", "confidence": 0.7076487690210342}, {"text": "word analogy", "start_pos": 85, "end_pos": 97, "type": "TASK", "confidence": 0.7621658742427826}]}, {"text": "The evaluation results show that our models outperform other baselines significantly, especially on word analogy.", "labels": [], "entities": [{"text": "word analogy", "start_pos": 100, "end_pos": 112, "type": "TASK", "confidence": 0.8018704652786255}]}, {"text": "This indicates that our models can build better knowledge representations with the help of sememe information, and also implies the potential of our models on word sense disambiguation.", "labels": [], "entities": [{"text": "word sense disambiguation", "start_pos": 159, "end_pos": 184, "type": "TASK", "confidence": 0.6815193295478821}]}, {"text": "The key contributions of this work are concluded as follows: (1) To the best of our knowledge, this is the first work to utilize sememes in HowNet to improve word representation learning.", "labels": [], "entities": [{"text": "HowNet", "start_pos": 140, "end_pos": 146, "type": "DATASET", "confidence": 0.9051649570465088}, {"text": "word representation learning", "start_pos": 158, "end_pos": 186, "type": "TASK", "confidence": 0.8479959567387899}]}, {"text": "(2) We successfully apply the attention scheme to detect word senses and learn representations according to contexts with the favor of the sememe annotation in HowNet.", "labels": [], "entities": [{"text": "HowNet", "start_pos": 160, "end_pos": 166, "type": "DATASET", "confidence": 0.9733894467353821}]}, {"text": "(3) We conduct extensive experiments and verify the effectiveness of incorporating word sememes for improved WRL.", "labels": [], "entities": [{"text": "WRL", "start_pos": 109, "end_pos": 112, "type": "TASK", "confidence": 0.8227030634880066}]}], "datasetContent": [{"text": "In this section, we evaluate the effectiveness of our SE-WRL 1 models on two tasks including word similarity and word analogy, which are two classical evaluation tasks mainly focusing on evaluating the quality of learned word representations.", "labels": [], "entities": [{"text": "word analogy", "start_pos": 113, "end_pos": 125, "type": "TASK", "confidence": 0.7908356189727783}]}, {"text": "We also explore the potential of our models in word sense disambiguation with case study, showing the power of our attention-based models.", "labels": [], "entities": [{"text": "word sense disambiguation", "start_pos": 47, "end_pos": 72, "type": "TASK", "confidence": 0.7292315363883972}]}, {"text": "We use the web pages in Sogou-T 2 as the text corpus to learn WRL models.", "labels": [], "entities": []}, {"text": "Sogou-T is provided by a Chinese commercial search engine, which contains 2.7 billion words in total.", "labels": [], "entities": [{"text": "Sogou-T", "start_pos": 0, "end_pos": 7, "type": "DATASET", "confidence": 0.8984456062316895}]}, {"text": "We also utilize the sememe annotation in HowNet.", "labels": [], "entities": [{"text": "HowNet", "start_pos": 41, "end_pos": 47, "type": "DATASET", "confidence": 0.980109453201294}]}, {"text": "The number of distinct sememes used in this paper is 1, 889.", "labels": [], "entities": []}, {"text": "The average senses for each word are about 2.4, while the average sememes for each sense are about 1.6.", "labels": [], "entities": []}, {"text": "Throughout the Sogou-T corpus, we find that 42.2% of words have multiple senses.", "labels": [], "entities": [{"text": "Sogou-T corpus", "start_pos": 15, "end_pos": 29, "type": "DATASET", "confidence": 0.8603174090385437}]}, {"text": "This indicates the significance of WSD.", "labels": [], "entities": [{"text": "significance", "start_pos": 19, "end_pos": 31, "type": "METRIC", "confidence": 0.9899829030036926}, {"text": "WSD", "start_pos": 35, "end_pos": 38, "type": "TASK", "confidence": 0.6685298681259155}]}, {"text": "For evaluation, we choose wordsim-240 and wordsim-297 3 to evaluate the performance of word similarity computation.", "labels": [], "entities": [{"text": "word similarity computation", "start_pos": 87, "end_pos": 114, "type": "TASK", "confidence": 0.7322550614674886}]}, {"text": "The two datasets both contain frequently-used Chinese word pairs with similarity scores annotated manually.", "labels": [], "entities": []}, {"text": "We choose the Chinese Word Analogy dataset proposed by to evaluate the performance of word analogy inference, that is, w(\"king\") \u2212 w(\"man\") w(\"queen\") \u2212 w(\"woman\").", "labels": [], "entities": [{"text": "Chinese Word Analogy dataset", "start_pos": 14, "end_pos": 42, "type": "DATASET", "confidence": 0.6793357282876968}, {"text": "word analogy inference", "start_pos": 86, "end_pos": 108, "type": "TASK", "confidence": 0.8004575371742249}]}, {"text": "We evaluate three SE-WRL models including S-SA, SAC and SAT on all tasks.", "labels": [], "entities": [{"text": "SAC", "start_pos": 48, "end_pos": 51, "type": "METRIC", "confidence": 0.7973799109458923}, {"text": "SAT", "start_pos": 56, "end_pos": 59, "type": "METRIC", "confidence": 0.9926342368125916}]}, {"text": "As for baselines, we consider three conventional WRL models including Skip-gram, CBOW and GloVe.", "labels": [], "entities": [{"text": "Skip-gram", "start_pos": 70, "end_pos": 79, "type": "DATASET", "confidence": 0.9287022352218628}]}, {"text": "For Skipgram and CBOW, we directly use the code released by).", "labels": [], "entities": [{"text": "Skipgram", "start_pos": 4, "end_pos": 12, "type": "DATASET", "confidence": 0.9570670127868652}, {"text": "CBOW", "start_pos": 17, "end_pos": 21, "type": "DATASET", "confidence": 0.8941560387611389}]}, {"text": "GloVe is proposed by), which seeks the advantages of the WRL models based on statistics and those based on prediction.", "labels": [], "entities": [{"text": "GloVe", "start_pos": 0, "end_pos": 5, "type": "METRIC", "confidence": 0.6598401069641113}]}, {"text": "Moreover, we propose another model, Maximum Selection over Target Model (MST), for further comparison inspired by . It represents the current word embeddings with only the most probable sense according to the contexts, instead of viewing a word as a particular distribution overall its senses similar to that of SAT.", "labels": [], "entities": []}, {"text": "For a fair comparison, we train these models with the same experimental settings and with their best parameters.", "labels": [], "entities": []}, {"text": "As for the parameter settings, we set the context window size K = 8 as the upper bound, and during training, the window size is dynamically selected ranging from 1 to 8 randomly.", "labels": [], "entities": []}, {"text": "We set the dimensions of word, sense and sememe embeddings to be the same 200.", "labels": [], "entities": []}, {"text": "For learning rate \u03b1, its initial value is 0.025 and will descend through iterations.", "labels": [], "entities": []}, {"text": "We set the number of negative samples to be 25.", "labels": [], "entities": []}, {"text": "We also set a lower bound of word frequency as 50, and in the training set, those words less frequent than this bound will be filtered out.", "labels": [], "entities": []}, {"text": "For SAT, we set K = 2.", "labels": [], "entities": [{"text": "SAT", "start_pos": 4, "end_pos": 7, "type": "TASK", "confidence": 0.7345148324966431}]}, {"text": "The dataset proposed by) consists of 1, 124 analogies, which contains three analogy types: (1) capitals of countries (Capital), 677 groups; (2) states/provinces of cities (City), 175 groups; (3) family words (Relationship), 272 groups.", "labels": [], "entities": []}, {"text": "Given an analogy group of words (w 1 , w 2 , w 3 , w 4 ), WRL models usually get w 2 \u2212w 1 +w 3 equal tow 4 . Hence for word analogy inference, we suppose w 4 is missing, and WRL models will rank all candidate words according to their scores as follows: and select the top-ranked word as the answer.", "labels": [], "entities": [{"text": "word analogy inference", "start_pos": 119, "end_pos": 141, "type": "TASK", "confidence": 0.8521845539410909}]}, {"text": "For word analogy inference, we consider two evaluation metrics: (1) Accuracy.", "labels": [], "entities": [{"text": "word analogy inference", "start_pos": 4, "end_pos": 26, "type": "TASK", "confidence": 0.8327592213948568}, {"text": "Accuracy", "start_pos": 68, "end_pos": 76, "type": "METRIC", "confidence": 0.9990242719650269}]}, {"text": "For each analogy group, a WRL model selects the top-ranked word w = arg max w R(w), which is judged as positive if w = w 4 . The percentage of positive samples is regarded as the accuracy score for this WRL model.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 179, "end_pos": 187, "type": "METRIC", "confidence": 0.999438464641571}]}, {"text": "For each analogy group, a WRL model will assign a rank for the gold standard word w 4 according to the scores computed by Eq.", "labels": [], "entities": []}, {"text": "We use the mean rank of all gold standard words as the evaluation metric.", "labels": [], "entities": []}, {"text": "shows the evaluation results of these models for word analogy inference.", "labels": [], "entities": [{"text": "word analogy inference", "start_pos": 49, "end_pos": 71, "type": "TASK", "confidence": 0.8547386328379313}]}, {"text": "From the table, we can observe that:  (1) The SAT model performs best among all models, and the superiority is more significant than that on word similarity computation.", "labels": [], "entities": [{"text": "word similarity computation", "start_pos": 141, "end_pos": 168, "type": "TASK", "confidence": 0.7481327851613363}]}, {"text": "This indicates that SAT will enhance the modeling of implicit relations between word embeddings in the semantic space.", "labels": [], "entities": []}, {"text": "The reason is that sememes annotated to word senses have encoded these word relations.", "labels": [], "entities": []}, {"text": "For example, capital and Cuba are two sememes of the word \"Havana\", which provide explicit semantic relations between the words \"Cuba\" and \"Havana\".", "labels": [], "entities": []}, {"text": "(2) The SAT model does well on both classes of Capital and City, because some words in these classes have low frequencies, while their sememes occur so many times that sememe embeddings can be learned sufficiently.", "labels": [], "entities": [{"text": "SAT", "start_pos": 8, "end_pos": 11, "type": "METRIC", "confidence": 0.9356327056884766}]}, {"text": "With these sememe embeddings, these low-frequent words can be learned more efficiently by SAT.", "labels": [], "entities": []}, {"text": "(3) It seems that CBOW works better than SAT on Relationship class.", "labels": [], "entities": [{"text": "CBOW", "start_pos": 18, "end_pos": 22, "type": "METRIC", "confidence": 0.6462405323982239}, {"text": "SAT", "start_pos": 41, "end_pos": 44, "type": "METRIC", "confidence": 0.9307178854942322}]}, {"text": "Whereas for the mean rank, CBOW gets the worst results, which indicates the performance of CBOW is unstable.", "labels": [], "entities": [{"text": "CBOW", "start_pos": 27, "end_pos": 31, "type": "DATASET", "confidence": 0.6143209338188171}, {"text": "CBOW", "start_pos": 91, "end_pos": 95, "type": "DATASET", "confidence": 0.8528730869293213}]}, {"text": "On the contrary, although the accuracy of SAT is a bit lower than that of CBOW, SAT seldom gives an outrageous prediction.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 30, "end_pos": 38, "type": "METRIC", "confidence": 0.9997268319129944}, {"text": "SAT", "start_pos": 42, "end_pos": 45, "type": "METRIC", "confidence": 0.9430190324783325}, {"text": "SAT", "start_pos": 80, "end_pos": 83, "type": "METRIC", "confidence": 0.9811806678771973}]}, {"text": "In most wrong cas-Word: \u00b0J(\"Apple brand/apple\") sense1: Apple brand (computer, PatternValue, able, bring, SpeBrand) sense2: duct (fruit)  es, SAT predicts the word \"grandfather\" instead of \"grandmother\", which is not completely nonsense, because in HowNet the words \"grandmother\", \"grandfather\", \"grandma\" and some other similar words share four common sememes while only one sememe of them are different.", "labels": [], "entities": [{"text": "SAT", "start_pos": 142, "end_pos": 145, "type": "METRIC", "confidence": 0.9312352538108826}, {"text": "HowNet", "start_pos": 249, "end_pos": 255, "type": "DATASET", "confidence": 0.9410654902458191}]}, {"text": "These similar sememes make the attention process less discriminative with each other.", "labels": [], "entities": []}, {"text": "But for the wrong cases of CBOW, we find that many mistakes are about words with low frequencies, such as \"stepdaughter\" which occurs merely for 358 times.", "labels": [], "entities": []}, {"text": "Considering sememes may relieve this problem.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Evaluation results of word similarity  computation.", "labels": [], "entities": [{"text": "word similarity  computation", "start_pos": 32, "end_pos": 60, "type": "TASK", "confidence": 0.8042484323183695}]}, {"text": " Table 2: Evaluation results of word analogy inference.", "labels": [], "entities": [{"text": "word analogy inference", "start_pos": 32, "end_pos": 54, "type": "TASK", "confidence": 0.8272947867711385}]}, {"text": " Table 4: Sememe weight for computing attention.", "labels": [], "entities": []}]}