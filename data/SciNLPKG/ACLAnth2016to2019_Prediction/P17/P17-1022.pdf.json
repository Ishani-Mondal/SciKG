{"title": [], "abstractContent": [{"text": "Several approaches have recently been proposed for learning decentralized deep mul-tiagent policies that coordinate via a dif-ferentiable communication channel.", "labels": [], "entities": []}, {"text": "While these policies are effective for many tasks, interpretation of their induced communication strategies has remained a challenge.", "labels": [], "entities": []}, {"text": "Here we propose to interpret agents' messages by translating them.", "labels": [], "entities": []}, {"text": "Unlike in typical machine translation problems, we have no parallel data to learn from.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 18, "end_pos": 37, "type": "TASK", "confidence": 0.7179884165525436}]}, {"text": "Instead we develop a translation model based on the insight that agent messages and natural language strings mean the same thing if they induce the same belief about the world in a listener.", "labels": [], "entities": []}, {"text": "We present theoretical guarantees and empirical evidence that our approach preserves both the semantics and pragmat-ics of messages by ensuring that players communicating through a translation layer do not suffer a substantial loss in reward relative to players with a common language.", "labels": [], "entities": []}], "introductionContent": [{"text": "Several recent papers have described approaches for learning deep communicating policies (DCPs): decentralized representations of behavior that enable multiple agents to communicate via a differentiable channel that can be formulated as a recurrent neural network.", "labels": [], "entities": [{"text": "learning deep communicating policies (DCPs)", "start_pos": 52, "end_pos": 95, "type": "TASK", "confidence": 0.7237608432769775}]}, {"text": "DCPs have been shown to solve a variety of coordination problems, including reference games (), logic puzzles (, and simple control (.", "labels": [], "entities": []}, {"text": "Appealingly, the agents' communication protocol can be learned via direct Figure 1: Example interaction between a pair of agents in a deep communicating policy.", "labels": [], "entities": []}, {"text": "Both cars are attempting to cross the intersection, but cannot see each other.", "labels": [], "entities": []}, {"text": "By exchanging message vectors z (t) , the agents are able to coordinate and avoid a collision.", "labels": [], "entities": []}, {"text": "This paper presents an approach for understanding the contents of these message vectors by translating them into natural language.", "labels": [], "entities": []}, {"text": "backpropagation through the communication channel, avoiding many of the challenging inference problems associated with learning in classical decentralized decision processes ().", "labels": [], "entities": []}, {"text": "But analysis of the strategies induced by DCPs has remained a challenge.", "labels": [], "entities": []}, {"text": "As an example, depicts a driving game in which two cars, which are unable to see each other, must both cross an intersection without colliding.", "labels": [], "entities": []}, {"text": "In order to ensure success, it is clear that the cars must communicate with each other.", "labels": [], "entities": []}, {"text": "But a number of successful communication strategies are possible-for example, they might report their exact (x, y) coordinates at every timestep, or they might simply announce whenever they are entering and leaving the intersection.", "labels": [], "entities": []}, {"text": "If these messages were communicated in natural language, it would be straightforward to determine which strategy was being employed.", "labels": [], "entities": []}, {"text": "However, DCP agents instead communicate with an automatically induced protocol of unstructured, real-valued recurrent state vectors-an artificial language we might call \"neuralese,\" which superficially bears little resemblance to natural language, and thus frustrates attempts at direct interpretation.", "labels": [], "entities": []}, {"text": "We propose to understand neuralese messages by translating them.", "labels": [], "entities": []}, {"text": "In this work, we present a simple technique for inducing a dictionary that maps between neuralese message vectors and short natural language strings, given only examples of DCP agents interacting with other agents, and humans interacting with other humans.", "labels": [], "entities": []}, {"text": "Natural language already provides a rich set of tools for describing beliefs, observations, and plans-our thesis is that these tools provide a useful complement to the visualization and ablation techniques used in previous work on understanding complex models.", "labels": [], "entities": []}, {"text": "While structurally quite similar to the task of machine translation between pairs of human languages, interpretation of neuralese poses a number of novel challenges.", "labels": [], "entities": [{"text": "machine translation between pairs of human languages", "start_pos": 48, "end_pos": 100, "type": "TASK", "confidence": 0.869927636214665}]}, {"text": "First, there is no natural source of parallel data: there are no bilingual \"speakers\" of both neuralese and natural language.", "labels": [], "entities": []}, {"text": "Second, there may not be a direct correspondence between the strategy employed by humans and DCP agents: even if it were constrained to communicate using natural language, an automated agent might choose to produce a different message from humans in a given state.", "labels": [], "entities": []}, {"text": "We tackle both of these challenges by appealing to the grounding of messages in gameplay.", "labels": [], "entities": []}, {"text": "Our approach is based on one of the core insights in natural language semantics: messages (whether in neuralese or natural language) have similar meanings when they induce similar beliefs about the state of the world.", "labels": [], "entities": []}, {"text": "Based on this intuition, we introduce a translation criterion that matches neuralese messages with natural language strings by minimizing statistical distance in a common representation space of distributions over speaker states.", "labels": [], "entities": []}, {"text": "We explore several related questions: \u2022 What makes a good translation, and under what conditions is translation possible at all?", "labels": [], "entities": []}, {"text": "(Section 4) \u2022 How can we build a model to translate between neuralese and natural language?", "labels": [], "entities": []}, {"text": "(Section 5) \u2022 What kinds of theoretical guarantees can we provide about the behavior of agents communicating via this translation model?", "labels": [], "entities": []}, {"text": "(Section 6) Our translation model and analysis are general, and in fact apply equally to human-computer and Figure 2: Overview of our approach-best-scoring translations generated fora reference game involving images of birds.", "labels": [], "entities": [{"text": "translation", "start_pos": 16, "end_pos": 27, "type": "TASK", "confidence": 0.9620210528373718}]}, {"text": "The speaking agent's goal is to send a message that uniquely identifies the bird on the left.", "labels": [], "entities": []}, {"text": "From these translations it can be seen that the learned model appears to discriminate based on coarse attributes like size and color.", "labels": [], "entities": []}, {"text": "human-human translation problems grounded in gameplay.", "labels": [], "entities": []}, {"text": "In this paper, we focus our experiments specifically on the problem of interpreting communication in deep policies, and apply our approach to the driving game in and two reference games of the kind shown in.", "labels": [], "entities": [{"text": "interpreting communication in deep policies", "start_pos": 71, "end_pos": 114, "type": "TASK", "confidence": 0.8858594059944153}]}, {"text": "We find that this approach outperforms a more conventional machine translation criterion both when attempting to interoperate with neuralese speakers and when predicting their state.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 59, "end_pos": 78, "type": "TASK", "confidence": 0.7338419258594513}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Evaluation results for reference games. (a) The colors  task. (b) The birds task. Whether the model human is in a  listener or speaker role, translation based on belief matching  outperforms both random and machine translation baselines.", "labels": [], "entities": []}, {"text": " Table 2: Belief evaluation results for the driving game. Driving  states are challenging to identify based on messages alone (as  evidenced by the comparatively low scores obtained by single- language pairs) . Translation based on belief achieves the best  overall performance in both directions.", "labels": [], "entities": []}, {"text": " Table 3: Behavior evaluation results for the driving game.", "labels": [], "entities": []}]}