{"title": [{"text": "MalwareTextDB: A Database for Annotated Malware Articles", "labels": [], "entities": []}], "abstractContent": [{"text": "Cybersecurity risks and malware threats are becoming increasingly dangerous and common.", "labels": [], "entities": []}, {"text": "Despite the severity of the problem , there has been few NLP efforts fo-cused on tackling cybersecurity.", "labels": [], "entities": []}, {"text": "In this paper, we discuss the construction of anew database for annotated malware texts.", "labels": [], "entities": []}, {"text": "An annotation framework is introduced based around the MAEC vocabulary for defining malware characteristics, along with a database consisting of 39 annotated APT reports with a total of 6,819 sentences.", "labels": [], "entities": [{"text": "MAEC vocabulary", "start_pos": 55, "end_pos": 70, "type": "DATASET", "confidence": 0.8622552454471588}]}, {"text": "We also use the database to construct models that can potentially help cybersecurity researchers in their data collection and analytics efforts.", "labels": [], "entities": []}], "introductionContent": [{"text": "In 2010, the malware known as Stuxnet physically damaged centrifuges in Iranian nuclear facilities).", "labels": [], "entities": []}, {"text": "More recently in 2016, a botnet known as Mirai used infected Internet of Things (IoT) devices to conduct large-scale Distributed Denial of Service (DDoS) attacks and disabled Internet access for millions of users in the US West Coast (US-CERT, 2016).", "labels": [], "entities": []}, {"text": "These are only two cases in along list ranging from ransomeware on personal laptops () to taking over control of moving cars).", "labels": [], "entities": []}, {"text": "Attacks such as these are likely to become increasingly frequent and dangerous as more devices and facilities become connected and digitized.", "labels": [], "entities": []}, {"text": "Recently, cybersecurity defense has also been recognized as one of the \"problem areas likely to be important both for advancing AI and for its long-run impact on society\").", "labels": [], "entities": [{"text": "cybersecurity defense", "start_pos": 10, "end_pos": 31, "type": "TASK", "confidence": 0.7762898802757263}]}, {"text": "In particular, we feel that natural language processing (NLP) has the potential for substantial contribution in cybersecurity and that this is a critical research area given the urgency and risks involved.", "labels": [], "entities": [{"text": "natural language processing (NLP)", "start_pos": 28, "end_pos": 61, "type": "TASK", "confidence": 0.793735533952713}]}, {"text": "There exists a large repository of malwarerelated texts online, such as detailed malware reports by various cybersecurity agencies such as Symantec ( and Cylance and in various blog posts.", "labels": [], "entities": []}, {"text": "Cybersecurity researchers often consume such texts in the process of data collection.", "labels": [], "entities": []}, {"text": "However, the sheer volume and diversity of these texts make it difficult for researchers to quickly obtain useful information.", "labels": [], "entities": []}, {"text": "A potential application of NLP can be to quickly highlight critical information from these texts, such as the specific actions taken by a certain malware.", "labels": [], "entities": []}, {"text": "This can help researchers quickly understand the capabilities of a specific malware and search in other texts for malware with similar capabilities.", "labels": [], "entities": []}, {"text": "An immediate problem preventing application of NLP techniques to malware texts is that such texts are mostly unannotated.", "labels": [], "entities": []}, {"text": "This severely limits their use in supervised learning techniques.", "labels": [], "entities": []}, {"text": "In light of that, we introduce a database of annotated malware reports for facilitating future NLP work in cybersecurity.", "labels": [], "entities": []}, {"text": "To the best of our knowledge, this is the first database consisting of annotated malware reports.", "labels": [], "entities": []}, {"text": "It is intended for public release, where we hope to inspire contributions from other research groups and individuals.", "labels": [], "entities": []}, {"text": "The main contributions of this paper are: \u2022 We initiate a framework for annotating malware reports and annotate 39 Advanced Persistent Threat (APT) reports (containing 6,819 sentences) with attribute labels from the Malware Attribute Enumeration and Characterization (MAEC) vocabulary ().", "labels": [], "entities": []}, {"text": "\u2022 We propose the following tasks, construct models for tackling them, and discuss the challenges: \u2022 Classify if a sentence is useful for inferring malware actions and capabilities, \u2022 Predict token, relation and attribute labels fora given malware-related text, as defined by the earlier framework, and \u2022 Predict a malware's signatures based only on text describing the malware.", "labels": [], "entities": []}], "datasetContent": [{"text": "Since the focus of this paper is on the introduction of anew framework and database for annotating malware-related texts, we only use simple algorithms for building the models and leave more complex models for future work.", "labels": [], "entities": []}, {"text": "For the following experiments, we use linear support vector machine (SVM) and multinomial Naive Bayes (NB) implementations in the scikitlearn library).", "labels": [], "entities": []}, {"text": "The regularization parameter in SVM and smoothing parame-  ter in NB were tuned (with the values 10 \u22123 to 10 3 in logarithmic increments) by taking the value that gave the best performance in development set.", "labels": [], "entities": [{"text": "NB", "start_pos": 66, "end_pos": 68, "type": "DATASET", "confidence": 0.916202187538147}]}, {"text": "For experiments where Conditional Random Field (CRF) () is used, we utilized the CRF++ implementation ().", "labels": [], "entities": []}, {"text": "For scoring the predictions, unless otherwise stated, we use the metrics module in scikit-learn for SVM and NB, as well as the CoNLL2000 conlleval Perl script for CRF . Also, unless otherwise mentioned, we make use of all 39 annotated documents in the database.", "labels": [], "entities": []}, {"text": "The experiments are conducted with a 60%/20%/20% training/development/test split, resulting in 23, 8 and 8 documents in the respective datasets.", "labels": [], "entities": []}, {"text": "Each experiment is conducted 5 times with a different random allocation of the dataset splits and we report averaged scores 2 . Since we focus on building a database, we weigh recall and precision as equally important in the following experiments and hence focus on the F 1 score metric.", "labels": [], "entities": [{"text": "recall", "start_pos": 176, "end_pos": 182, "type": "METRIC", "confidence": 0.9990642666816711}, {"text": "precision", "start_pos": 187, "end_pos": 196, "type": "METRIC", "confidence": 0.998516857624054}, {"text": "F 1 score metric", "start_pos": 270, "end_pos": 286, "type": "METRIC", "confidence": 0.9748624116182327}]}, {"text": "The relative importance of recall against precision will ultimately depend on the downstream tasks.", "labels": [], "entities": [{"text": "recall", "start_pos": 27, "end_pos": 33, "type": "METRIC", "confidence": 0.9976629018783569}, {"text": "precision", "start_pos": 42, "end_pos": 51, "type": "METRIC", "confidence": 0.9978348612785339}]}], "tableCaptions": [{"text": " Table 2: Task 1 scores: classifying relevant sen- tences.", "labels": [], "entities": []}, {"text": " Table 3: Task 2 scores: predicting token labels.", "labels": [], "entities": [{"text": "predicting token labels", "start_pos": 25, "end_pos": 48, "type": "TASK", "confidence": 0.9127306143442789}]}, {"text": " Table 4: Task 2 relaxed/token-level scores.", "labels": [], "entities": []}, {"text": " Table 5: Task 3 scores: predicting relation labels.", "labels": [], "entities": [{"text": "predicting relation labels", "start_pos": 25, "end_pos": 51, "type": "TASK", "confidence": 0.9116500417391459}]}, {"text": " Table 6: Task 4 scores: predicting attribute labels.", "labels": [], "entities": [{"text": "predicting attribute labels", "start_pos": 25, "end_pos": 52, "type": "TASK", "confidence": 0.9149313569068909}]}, {"text": " Table 7: Task 5 scores: predicting malware sig- natures using text and annotations.", "labels": [], "entities": [{"text": "predicting malware sig- natures", "start_pos": 25, "end_pos": 56, "type": "TASK", "confidence": 0.8339625358581543}]}]}