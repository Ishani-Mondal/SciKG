{"title": [], "abstractContent": [{"text": "Domain adaptation is an important technology to handle domain dependence problem in sentiment analysis field.", "labels": [], "entities": [{"text": "Domain adaptation", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.8005289435386658}, {"text": "sentiment analysis", "start_pos": 84, "end_pos": 102, "type": "TASK", "confidence": 0.9452468156814575}]}, {"text": "Existing methods usually rely on sentiment classi-fiers trained in source domains.", "labels": [], "entities": []}, {"text": "However , their performance may heavily decline if the distributions of sentiment features in source and target domains have significant difference.", "labels": [], "entities": []}, {"text": "In this paper, we propose an active sentiment domain adaptation approach to handle this problem.", "labels": [], "entities": [{"text": "sentiment domain adaptation", "start_pos": 36, "end_pos": 63, "type": "TASK", "confidence": 0.6641002098719279}]}, {"text": "Instead of the source domain sentiment classifiers, our approach adapts the general-purpose sentiment lexicons to target domain with the help of a small number of labeled samples which are selected and annotated in an active learning mode, as well as the domain-specific sentiment similarities among words mined from unlabeled samples of target domain.", "labels": [], "entities": []}, {"text": "A unified model is proposed to fuse different types of sentiment information and train sentiment clas-sifier for target domain.", "labels": [], "entities": []}, {"text": "Extensive experiments on benchmark datasets show that our approach can train accurate sentiment classifier with less labeled samples.", "labels": [], "entities": [{"text": "sentiment classifier", "start_pos": 86, "end_pos": 106, "type": "TASK", "confidence": 0.8911343216896057}]}], "introductionContent": [{"text": "Sentiment classification is widely known as a domain-dependent problem.", "labels": [], "entities": [{"text": "Sentiment classification", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.9611703753471375}]}, {"text": "This is because different domains usually have many different sentiment expressions.", "labels": [], "entities": []}, {"text": "For example, \"lengthy\" and \"boring\" are popularly used in Book domain to express negative sentiment.", "labels": [], "entities": [{"text": "Book domain", "start_pos": 58, "end_pos": 69, "type": "DATASET", "confidence": 0.9273143410682678}]}, {"text": "However, they are rare in Kitchen appliance domain.", "labels": [], "entities": []}, {"text": "Moreover, the same word or phrase may convey * Corresponding author.", "labels": [], "entities": []}, {"text": "different sentiments in different domains.", "labels": [], "entities": []}, {"text": "For instance, \"unpredictable\" is frequently used to express positive sentiment in Movie domain (e.g., \"The plot of this movie is fun and unpredictable\").", "labels": [], "entities": []}, {"text": "However, it tends to be used as a negative word in Kitchen appliance domain (e.g., \"Even holding heat is unpredictable. It is just terrible!\").", "labels": [], "entities": []}, {"text": "Thus, every domain has many domain-specific sentiment expressions, which cannot be captured by other domains.", "labels": [], "entities": []}, {"text": "The performance of directly applying a general sentiment classifier or a sentiment classifier trained in other domains to target domain is usually suboptimal.", "labels": [], "entities": []}, {"text": "Since there area large number of domains in user-generated content, it is impractical to manually annotate enough samples for each domain to train an accurate domain-specific sentiment classifier.", "labels": [], "entities": [{"text": "domain-specific sentiment classifier", "start_pos": 159, "end_pos": 195, "type": "TASK", "confidence": 0.6412333647410074}]}, {"text": "Thus, sentiment domain adaptation, which transfers the sentiment classifier trained in a source domain with sufficient labeled data to a target domain with no or scarce labeled data, has been widely studied).", "labels": [], "entities": [{"text": "sentiment domain adaptation", "start_pos": 6, "end_pos": 33, "type": "TASK", "confidence": 0.8970863024393717}]}, {"text": "Existing sentiment domain adaptation methods are mainly based on transfer learning techniques.", "labels": [], "entities": [{"text": "sentiment domain adaptation", "start_pos": 9, "end_pos": 36, "type": "TASK", "confidence": 0.8094430764516195}]}, {"text": "Many of them try to learn anew feature representation to augment or replace the original feature space in order to reduce the gap of sentiment feature distributions between source and target domains).", "labels": [], "entities": []}, {"text": "For example, proposed to learn a latent representation for domain-specific words from both source and target domains by using pivot features as bridge.", "labels": [], "entities": []}, {"text": "The advantage of these methods is that no labeled data in target domain is needed.", "labels": [], "entities": []}, {"text": "However, when the distributions of sentiment features in source and target domains have significant difference, the performance of domain adaptation will heavily decline ( ).", "labels": [], "entities": []}, {"text": "In some cases, the performance of adaptation is even lower than that without adaptation, which is usually known as negative transfer . In this paper, we propose an active sentiment domain adaptation approach to handle this problem by incorporating both general sentiment information and a small number of actively selected labeled samples from target domain.", "labels": [], "entities": []}, {"text": "More specifically, in our approach the general sentiment information extracted from sentiment lexicons is adapted to target domain using domain-specific sentiment similarities among words.", "labels": [], "entities": []}, {"text": "The general sentiment information is regarded as a \"background\" domain to transfer.", "labels": [], "entities": []}, {"text": "The word similarities are extracted from unlabeled samples of target domain using both syntactic rules and co-occurrence patterns.", "labels": [], "entities": []}, {"text": "Then we actively select and annotate a small number of informative samples from target domain in an active learning manner.", "labels": [], "entities": []}, {"text": "These labeled samples are incorporated into our approach to improve the performance of sentiment domain adaptation.", "labels": [], "entities": [{"text": "sentiment domain adaptation", "start_pos": 87, "end_pos": 114, "type": "TASK", "confidence": 0.8388661543528239}]}, {"text": "A unified model is proposed to incorporate different types of sentiment information to train sentiment classifier for target domain.", "labels": [], "entities": [{"text": "sentiment classifier", "start_pos": 93, "end_pos": 113, "type": "TASK", "confidence": 0.7556849718093872}]}, {"text": "Extensive experiments were conducted on benchmark datasets.", "labels": [], "entities": []}, {"text": "The experimental results show that our approach can train accurate sentiment classifiers and reduce the manual annotation effort.", "labels": [], "entities": [{"text": "sentiment classifiers", "start_pos": 67, "end_pos": 88, "type": "TASK", "confidence": 0.8646778762340546}]}], "datasetContent": [{"text": "The dataset used in our experiments is the Amazon product review dataset 1 collected by, which is widely used in sentiment analysis and domain adaptation research ().", "labels": [], "entities": [{"text": "Amazon product review dataset 1 collected", "start_pos": 43, "end_pos": 84, "type": "DATASET", "confidence": 0.9254214366277059}, {"text": "sentiment analysis", "start_pos": 113, "end_pos": 131, "type": "TASK", "confidence": 0.9663479328155518}, {"text": "domain adaptation research", "start_pos": 136, "end_pos": 162, "type": "TASK", "confidence": 0.7850261529286703}]}, {"text": "This dataset contains product reviews in four domains, i.e., Book, DVD, Electronics, and Kitchen appliances.", "labels": [], "entities": [{"text": "Book", "start_pos": 61, "end_pos": 65, "type": "DATASET", "confidence": 0.9386627078056335}]}, {"text": "In each domain, 1,000 positive and 1,000 negative reviews as well as a large number of unlabeled samples are included.", "labels": [], "entities": []}, {"text": "The detailed statistics of this dataset are summarized in  Following many previous works), unigrams and bigrams were used to build feature vectors in our experiments.", "labels": [], "entities": []}, {"text": "We randomly split the labeled samples in each domain into two parts with equal size.", "labels": [], "entities": []}, {"text": "The first part was used as test data, and the second part was used as the pool of \"unlabeled\" samples to perform active learning.", "labels": [], "entities": []}, {"text": "The general sentiment information was extracted from Bing Liu's sentiment lexicon 2 (), which is one of the state-of-the-art general-purpose sentiment lexicons.", "labels": [], "entities": [{"text": "Bing Liu's sentiment lexicon 2", "start_pos": 53, "end_pos": 83, "type": "DATASET", "confidence": 0.6798557837804159}]}, {"text": "The domain-specific sentiment similarities among words were extracted from the large-scale unlabeled samples.", "labels": [], "entities": []}, {"text": "The total number of samples actively selected by our approach to annotate was set to 100.", "labels": [], "entities": []}, {"text": "The values of \u03b1, \u03b2, and \u03bb were set to 0.1, 1, and 1 respectively.", "labels": [], "entities": []}, {"text": "We repeated each experiment 10 times independently and the average results were reported.", "labels": [], "entities": []}, {"text": "In this section we conducted experiments to evaluate the performance of our approach by comparing it with several baseline methods.", "labels": [], "entities": []}, {"text": "The methods to be compared include: 1) MPQA and BingLiu, using two state-of-the-art sentiment lexicons, i.e., MPQA) and Bing Liu's lexicon () for sentiment classification following the suggestions in (); 2) SVM, LS, and LR, three popular supervised sentiment classification methods, i.e., support vector machine (), least squares (   According to, the performance of directly applying sentiment lexicons to target domain is suboptimal.", "labels": [], "entities": [{"text": "BingLiu", "start_pos": 48, "end_pos": 55, "type": "DATASET", "confidence": 0.8848493695259094}, {"text": "sentiment classification", "start_pos": 146, "end_pos": 170, "type": "TASK", "confidence": 0.8745697736740112}]}, {"text": "This is because there are many domain-specific sentiment expressions that are not covered by these general-purpose sentiment lexicons (.", "labels": [], "entities": []}, {"text": "In addition, the performance of supervised sentiment classification methods such as SVM, LS, and LR is also limited, because the labeled samples for training are extremely scarce.", "labels": [], "entities": [{"text": "sentiment classification", "start_pos": 43, "end_pos": 67, "type": "TASK", "confidence": 0.8367474675178528}]}, {"text": "The active learning methods such as ZIAL () and LIAL (Settles, 2010) perform relatively better, because they can actively select informative samples to annotate and learn.", "labels": [], "entities": [{"text": "LIAL", "start_pos": 48, "end_pos": 52, "type": "METRIC", "confidence": 0.9840402007102966}]}, {"text": "Our approach can outperform both of them.", "labels": [], "entities": []}, {"text": "This is because besides the labeled samples, our approach also adapts the general sentiment information in sentiment lexicons to target domain and incorporates it into the learning of target domain sentiment classifier.", "labels": [], "entities": []}, {"text": "Our approach also performs better than state-of-the-art domain adaptation methods such as SCL () and SFA ( . It implies that a small number of actively selected labeled samples from target domain are beneficial for sentiment domain adaptation.", "labels": [], "entities": [{"text": "sentiment domain adaptation", "start_pos": 215, "end_pos": 242, "type": "TASK", "confidence": 0.8017112016677856}]}, {"text": "ILP) tries to adapt a sentiment lexicon to target domain, which is similar with our approach.", "labels": [], "entities": [{"text": "ILP", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.7988360524177551}]}, {"text": "ILP relies on labeled samples to extract the relations among words and relations between words and sentiment expressions.", "labels": [], "entities": []}, {"text": "However, labeled samples in target domain are usually limited and the sentiment information in many unlabeled samples is not exploited in ILP.", "labels": [], "entities": []}, {"text": "Thus, our approach can outperform it.", "labels": [], "entities": []}, {"text": "Similar with our approach, AODA) and ALCD (  also apply active learning to domain adaptation.", "labels": [], "entities": [{"text": "AODA", "start_pos": 27, "end_pos": 31, "type": "METRIC", "confidence": 0.7952193021774292}, {"text": "ALCD", "start_pos": 37, "end_pos": 41, "type": "METRIC", "confidence": 0.8311524391174316}]}, {"text": "The major difference is that in our approach the general sentiment information extracted from sentiment lexicons is adapted to target domain, while in AODA and ALCD the sentiment classifier trained in source domains is transferred.", "labels": [], "entities": [{"text": "AODA", "start_pos": 151, "end_pos": 155, "type": "METRIC", "confidence": 0.5646605491638184}, {"text": "ALCD", "start_pos": 160, "end_pos": 164, "type": "DATASET", "confidence": 0.7306990623474121}]}, {"text": "The superior performance of our approach implies that the general sentiment information has better generalization ability than the sentiment classifier trained in a specific source domain, and is more suitable for sentiment domain adaptation.", "labels": [], "entities": [{"text": "sentiment domain adaptation", "start_pos": 214, "end_pos": 241, "type": "TASK", "confidence": 0.8029019037882487}]}, {"text": "We further conducted several experiments to validate the advantage of our approach in training accurate sentiment classifier for target domain with only a few labeled samples.", "labels": [], "entities": [{"text": "sentiment classifier", "start_pos": 104, "end_pos": 124, "type": "TASK", "confidence": 0.8324486613273621}]}, {"text": "We varied the annotation budget, i.e., the number of labeled samples, from 100 to 1,000.", "labels": [], "entities": []}, {"text": "The learning curve of our ASDA approach in Book domain is shown in.", "labels": [], "entities": [{"text": "ASDA", "start_pos": 26, "end_pos": 30, "type": "TASK", "confidence": 0.9514651894569397}, {"text": "Book domain", "start_pos": 43, "end_pos": 54, "type": "DATASET", "confidence": 0.9690236449241638}]}, {"text": "We also included a purely supervised sentiment classification method, i.e., SVM, in as a baseline for comparison.", "labels": [], "entities": [{"text": "sentiment classification", "start_pos": 37, "end_pos": 61, "type": "TASK", "confidence": 0.8859104216098785}]}, {"text": "shows that our ASDA approach can consistently outperform SVM when the same number of labeled samples are used.", "labels": [], "entities": [{"text": "SVM", "start_pos": 57, "end_pos": 60, "type": "TASK", "confidence": 0.8981762528419495}]}, {"text": "The performance advantage of our approach is more significant when labeled samples are scarce.", "labels": [], "entities": []}, {"text": "For example, the performance of our approach with only 200 labeled samples is similar to SVM with more than 800 labeled samples.", "labels": [], "entities": []}, {"text": "Thus, the experimental results validate that by adapting the general sentiment information to target domain and selecting the most informative samples to annotate and learn, our approach can effectively reduce the manual annotation effort, and can train accurate sentiment classifier for target domain with much less labeled samples.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: The statistics of the Amazon dataset.", "labels": [], "entities": [{"text": "Amazon dataset", "start_pos": 32, "end_pos": 46, "type": "DATASET", "confidence": 0.9783994257450104}]}, {"text": " Table 2: Sentiment classification performance of  different methods in different domains. Acc and  Fscore represent accuracy and macro-averaged  Fscore respectively.", "labels": [], "entities": [{"text": "Sentiment classification", "start_pos": 10, "end_pos": 34, "type": "TASK", "confidence": 0.9344150722026825}, {"text": "Acc", "start_pos": 91, "end_pos": 94, "type": "METRIC", "confidence": 0.9962694644927979}, {"text": "Fscore", "start_pos": 100, "end_pos": 106, "type": "METRIC", "confidence": 0.9901690483093262}, {"text": "accuracy", "start_pos": 117, "end_pos": 125, "type": "METRIC", "confidence": 0.999233603477478}, {"text": "Fscore", "start_pos": 146, "end_pos": 152, "type": "METRIC", "confidence": 0.9459146857261658}]}]}