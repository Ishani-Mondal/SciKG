{"title": [{"text": "An Unsupervised Neural Attention Model for Aspect Extraction", "labels": [], "entities": [{"text": "Aspect Extraction", "start_pos": 43, "end_pos": 60, "type": "TASK", "confidence": 0.8100663423538208}]}], "abstractContent": [{"text": "Aspect extraction is an important and challenging task in aspect-based sentiment analysis.", "labels": [], "entities": [{"text": "Aspect extraction", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.9724441468715668}, {"text": "aspect-based sentiment analysis", "start_pos": 58, "end_pos": 89, "type": "TASK", "confidence": 0.6613459487756094}]}, {"text": "Existing works tend to apply variants of topic models on this task.", "labels": [], "entities": []}, {"text": "While fairly successful, these methods usually do not produce highly coherent aspects.", "labels": [], "entities": []}, {"text": "In this paper, we present a novel neural approach with the aim of discovering coherent aspects.", "labels": [], "entities": []}, {"text": "The model improves coherence by exploiting the distribution of word co-occurrences through the use of neural word embeddings.", "labels": [], "entities": []}, {"text": "Unlike topic models which typically assume independently generated words, word embedding models encourage words that appear in similar contexts to be located close to each other in the embedding space.", "labels": [], "entities": []}, {"text": "In addition, we use an attention mechanism to de-emphasize irrelevant words during training, further improving the coherence of aspects.", "labels": [], "entities": []}, {"text": "Experimental results on real-life datasets demonstrate that our approach discovers more meaningful and coherent aspects, and substantially outper-forms baseline methods on several evaluation tasks.", "labels": [], "entities": []}], "introductionContent": [{"text": "Aspect extraction is one of the key tasks in sentiment analysis.", "labels": [], "entities": [{"text": "Aspect extraction", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.9578160643577576}, {"text": "sentiment analysis", "start_pos": 45, "end_pos": 63, "type": "TASK", "confidence": 0.9649060964584351}]}, {"text": "It aims to extract entity aspects on which opinions have been expressed (.", "labels": [], "entities": []}, {"text": "For example, in the sentence \"The beef was tender and melted in my mouth\", the aspect term is \"beef\".", "labels": [], "entities": []}, {"text": "Two sub-tasks are performed in aspect extraction: (1) extracting all aspect terms (e.g., \"beef\") from a review corpus, (2) clustering aspect terms with similar meaning into categories where each category represents a single aspect (e.g., cluster \"beef\", \"pork\", \"pasta\", and \"tomato\" into one aspect food).", "labels": [], "entities": [{"text": "aspect extraction", "start_pos": 31, "end_pos": 48, "type": "TASK", "confidence": 0.7741798758506775}]}, {"text": "Previous works for aspect extraction can be categorized into three approaches: rule-based, supervised, and unsupervised.", "labels": [], "entities": [{"text": "aspect extraction", "start_pos": 19, "end_pos": 36, "type": "TASK", "confidence": 0.8395358026027679}]}, {"text": "Rule-based methods usually do not group extracted aspect terms into categories.", "labels": [], "entities": []}, {"text": "Supervised learning requires data annotation and suffers from domain adaptation problems.", "labels": [], "entities": []}, {"text": "Unsupervised methods are adopted to avoid reliance on labeled data needed for supervised learning.", "labels": [], "entities": []}, {"text": "In recent years, Latent Dirichlet Allocation (LDA) () and its variants) have become the dominant unsupervised approach for aspect extraction.", "labels": [], "entities": [{"text": "Latent Dirichlet Allocation (LDA", "start_pos": 17, "end_pos": 49, "type": "METRIC", "confidence": 0.8908918142318726}, {"text": "aspect extraction", "start_pos": 123, "end_pos": 140, "type": "TASK", "confidence": 0.8780426681041718}]}, {"text": "LDA models the corpus as a mixture of topics (aspects), and topics as distributions over word types.", "labels": [], "entities": []}, {"text": "While the mixture of aspects discovered by LDA-based models may describe a corpus fairly well, we find that the individual aspects inferred are of poor quality -aspects often consist of unrelated or loosely-related concepts.", "labels": [], "entities": []}, {"text": "This may substantially reduce users' confidence in using such automated systems.", "labels": [], "entities": []}, {"text": "There could be two primary reasons for the poor quality.", "labels": [], "entities": []}, {"text": "Conventional LDA models do not directly encode word co-occurrence statistics which are the primary source of information to preserve topic coherence).", "labels": [], "entities": []}, {"text": "They implicitly capture such patterns by modeling word generation from the document level, assuming that each word is generated independently.", "labels": [], "entities": []}, {"text": "Furthermore, LDA-based models need to estimate a distribution of topics for each document.", "labels": [], "entities": []}, {"text": "Review documents tend to be short, thus making the estimation of topic distributions more difficult.", "labels": [], "entities": []}, {"text": "In this work, we present a novel neural approach to tackle the weaknesses of LDA-based methods.", "labels": [], "entities": []}, {"text": "We start with neural word embeddings that al-ready map words that usually co-occur within the same context to nearby points in the embedding space (.", "labels": [], "entities": []}, {"text": "We then filter the word embeddings within a sentence using an attention mechanism ( and use the filtered words to construct aspect embeddings.", "labels": [], "entities": []}, {"text": "The training process for aspect embeddings is analogous to autoencoders, where we use dimension reduction to extract the common factors among embedded sentences and reconstruct each sentence through a linear combination of aspect embeddings.", "labels": [], "entities": []}, {"text": "The attention mechanism deemphasizes words that are not part of any aspect, allowing the model to focus on aspect words.", "labels": [], "entities": []}, {"text": "We call our proposed model Attention-based Aspect Extraction (ABAE).", "labels": [], "entities": [{"text": "Attention-based Aspect Extraction (ABAE", "start_pos": 27, "end_pos": 66, "type": "TASK", "confidence": 0.632919454574585}]}, {"text": "In contrast to LDA-based models, our proposed method explicitly encodes word-occurrence statistics into word embeddings, uses dimension reduction to extract the most important aspects in the review corpus, and uses an attention mechanism to remove irrelevant words to further improve coherence of the aspects.", "labels": [], "entities": []}, {"text": "We have conducted extensive experiments on large review data sets.", "labels": [], "entities": []}, {"text": "The results show that ABAE is effective in discovering meaningful and coherent aspects.", "labels": [], "entities": [{"text": "ABAE", "start_pos": 22, "end_pos": 26, "type": "METRIC", "confidence": 0.8164668083190918}]}, {"text": "It substantially outperforms baseline methods on multiple evaluation tasks.", "labels": [], "entities": []}, {"text": "In addition, ABAE is intuitive and structurally simple.", "labels": [], "entities": [{"text": "ABAE", "start_pos": 13, "end_pos": 17, "type": "METRIC", "confidence": 0.814657986164093}]}, {"text": "It can also easily scale to a large amount of training data.", "labels": [], "entities": []}, {"text": "Therefore, it is a promising alternative to LDA-based methods proposed previously.", "labels": [], "entities": []}], "datasetContent": [{"text": "We evaluate our method on two real-word datasets.", "labels": [], "entities": []}, {"text": "The detailed statistics of the datasets are summarized in.", "labels": [], "entities": []}, {"text": "(1) Citysearch corpus: This is a restaurant review corpus widely used by previous works (, which contains over 50,000 restaurant reviews from Citysearch New York.", "labels": [], "entities": [{"text": "Citysearch corpus", "start_pos": 4, "end_pos": 21, "type": "DATASET", "confidence": 0.865500271320343}]}, {"text": "also provided a subset of 3,400 sentences from the corpus with manually labeled aspects.", "labels": [], "entities": []}, {"text": "These annotated sentences are used for evaluation of aspect identification.", "labels": [], "entities": [{"text": "aspect identification", "start_pos": 53, "end_pos": 74, "type": "TASK", "confidence": 0.9414314925670624}]}, {"text": "There are six manually defined aspect labels: Food, Staff, Ambience, Price, Anecdotes, and Miscellaneous.", "labels": [], "entities": [{"text": "Anecdotes", "start_pos": 76, "end_pos": 85, "type": "METRIC", "confidence": 0.964451014995575}]}, {"text": "(2) BeerAdvocate: This is a beer review corpus introduced in), containing over 1.5 million reviews.", "labels": [], "entities": [{"text": "BeerAdvocate", "start_pos": 4, "end_pos": 16, "type": "DATASET", "confidence": 0.9208862781524658}]}, {"text": "A subset of 1,000 reviews, corresponding to 9,245 sentences, are annotated with five aspect labels: Feel, Look, Smell, Taste, and Overall.", "labels": [], "entities": []}, {"text": "Review corpora are preprocessed by removing punctuation symbols, stop words, and words appearing less than 10 times.", "labels": [], "entities": []}, {"text": "For LocLDA, we use the open-source implementation GibbsLDA++ and for BTM, we use the implementation released by (Yan et al., 2013) 2 . We tune the hyperparameters of all topic model baselines on a held-out set with grid search using the topic coherence metric to be introduced later in Eq 10: for LocLDA, the Dirichlet priors \u03b1 = 0.05 and \u03b2 = 0.1; for SAS and BTM, \u03b1 = 50/K and \u03b2 = 0.1.", "labels": [], "entities": []}, {"text": "We run 1,000 iterations of Gibbs sampling for all topic models.", "labels": [], "entities": []}, {"text": "For the ABAE model, we initialize the word embedding matrix E with word vectors trained by word2vec with negative sampling on each dataset, setting the embedding size to 200, window size to 10, and negative sample size to 5.", "labels": [], "entities": []}, {"text": "The parameters we use for training word embeddings are standard with no specific tuning to our data.", "labels": [], "entities": []}, {"text": "We also initialize the aspect embedding matrix T with the centroids of clusters resulting from running k-means on word embeddings.", "labels": [], "entities": []}, {"text": "Other parameters are initialized randomly.", "labels": [], "entities": []}, {"text": "During the training process, we fix the word embedding matrix E and optimize other parameters using Adam () with learning rate 0.001 for 15 epochs and batch size of 50.", "labels": [], "entities": []}, {"text": "We set the number of negative samples per input sample m to 20, and the orthogonality penalty weight \u03bb to 1 by tuning the hyperparameters on a held-out set with grid search.", "labels": [], "entities": [{"text": "orthogonality penalty weight \u03bb", "start_pos": 72, "end_pos": 102, "type": "METRIC", "confidence": 0.6875458806753159}]}, {"text": "The results reported for all models are the average over 10 runs.", "labels": [], "entities": []}, {"text": "Following, we set the number of aspects for the restaurant corpus to 14.", "labels": [], "entities": []}, {"text": "We experimented with different number of aspects from 10 to 20 for the beer corpus.", "labels": [], "entities": [{"text": "beer corpus", "start_pos": 71, "end_pos": 82, "type": "DATASET", "confidence": 0.9426847696304321}]}, {"text": "The results showed no major difference, so we also set it to 14.", "labels": [], "entities": []}, {"text": "As in previous work, we manually mapped each inferred aspect to one of the gold-standard aspects according to its top ranked representative words.", "labels": [], "entities": []}, {"text": "In ABAE, representative words of an aspect can be found by looking at its nearest words in the embedding space using cosine as the similarity metric.", "labels": [], "entities": []}, {"text": "We describe the evaluation tasks and report the experimental results in this section.", "labels": [], "entities": []}, {"text": "We evaluate ABAE on two criteria: \u2022 Is it able to find meaningful and semantically coherent aspects?", "labels": [], "entities": [{"text": "ABAE", "start_pos": 12, "end_pos": 16, "type": "TASK", "confidence": 0.5334513783454895}]}, {"text": "\u2022 Is it able to improve aspect identification performance on real-world review datasets?", "labels": [], "entities": [{"text": "aspect identification", "start_pos": 24, "end_pos": 45, "type": "TASK", "confidence": 0.9456975162029266}]}, {"text": "standard labels, the inferred aspects are more finegrained.", "labels": [], "entities": []}, {"text": "For example, it can distinguish main dishes from desserts, and drinks from food.", "labels": [], "entities": []}, {"text": "As we want to discover a set of aspects that the human user finds agreeable, it is also necessary to carryout user evaluation directly.", "labels": [], "entities": []}, {"text": "Following the experimental setting in), we recruited three human judges.", "labels": [], "entities": []}, {"text": "Each aspect is labeled as coherent if the majority of judges assess that most of its top 50 terms coherently represent a product aspect.", "labels": [], "entities": []}, {"text": "The numbers of coherent aspects discovered by each model are shown in.", "labels": [], "entities": []}, {"text": "ABAE discovers the most number of coherent aspects compared with other models.", "labels": [], "entities": [{"text": "ABAE", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.39680832624435425}]}, {"text": "For a coherent aspect, each of its top terms is labeled as correct if and only if the majority of judges assess that it reflects the related aspect.", "labels": [], "entities": []}, {"text": "We adopt precision@n (or p@n) to evaluate the results, which was also used in).", "labels": [], "entities": [{"text": "precision", "start_pos": 9, "end_pos": 18, "type": "METRIC", "confidence": 0.9977216124534607}]}, {"text": "shows the average p@n results overall coherent aspects for each domain.", "labels": [], "entities": []}, {"text": "We can see that the user evaluation results correlate well with the coherence scores shown in, where ABAE substantially outperforms all other models for all ranked buckets, especially for large values of n.", "labels": [], "entities": [{"text": "ABAE", "start_pos": 101, "end_pos": 105, "type": "METRIC", "confidence": 0.9713354110717773}]}], "tableCaptions": [{"text": " Table 3: Number of coherent aspects. K (number  of aspects) = 14 for all models.", "labels": [], "entities": [{"text": "K (number  of aspects)", "start_pos": 38, "end_pos": 60, "type": "METRIC", "confidence": 0.9152783453464508}]}, {"text": " Table 3.  ABAE discovers the most number of coherent as- pects compared with other models.  For a coherent aspect, each of its top terms is  labeled as correct if and only if the majority of  judges assess that it reflects the related aspect. We  adopt precision@n (or p@n) to evaluate the re- sults, which was also used in", "labels": [], "entities": [{"text": "ABAE", "start_pos": 11, "end_pos": 15, "type": "METRIC", "confidence": 0.6675223708152771}, {"text": "precision", "start_pos": 254, "end_pos": 263, "type": "METRIC", "confidence": 0.9964706897735596}]}, {"text": " Table 1. The evalua- tion criterion is to judge how well the predictions  match the true labels, measured by precision, re- call, and F 1 scores. The results 4 are shown in", "labels": [], "entities": [{"text": "precision", "start_pos": 110, "end_pos": 119, "type": "METRIC", "confidence": 0.9992916584014893}, {"text": "re- call", "start_pos": 121, "end_pos": 129, "type": "METRIC", "confidence": 0.9214676022529602}, {"text": "F 1 scores", "start_pos": 135, "end_pos": 145, "type": "METRIC", "confidence": 0.9861418406168619}]}, {"text": " Table 5: Aspect identification results on the beer  domain.", "labels": [], "entities": [{"text": "Aspect identification", "start_pos": 10, "end_pos": 31, "type": "TASK", "confidence": 0.8038099110126495}, {"text": "beer  domain", "start_pos": 47, "end_pos": 59, "type": "DATASET", "confidence": 0.9331047534942627}]}, {"text": " Table 6: Comparison between ABAE and ABAE \u2212  on aspect identification on the restaurant domain.", "labels": [], "entities": [{"text": "ABAE", "start_pos": 29, "end_pos": 33, "type": "METRIC", "confidence": 0.9947237968444824}, {"text": "ABAE", "start_pos": 38, "end_pos": 42, "type": "METRIC", "confidence": 0.9627925157546997}, {"text": "aspect identification", "start_pos": 49, "end_pos": 70, "type": "TASK", "confidence": 0.7932401895523071}]}]}