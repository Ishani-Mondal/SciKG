{"title": [], "abstractContent": [{"text": "In this paper we study the problem of answering cloze-style questions over documents.", "labels": [], "entities": [{"text": "answering cloze-style questions over documents", "start_pos": 38, "end_pos": 84, "type": "TASK", "confidence": 0.8565764427185059}]}, {"text": "Our model, the Gated-Attention (GA) Reader 1 , integrates a multi-hop architecture with a novel attention mechanism , which is based on multiplicative interactions between the query embedding and the intermediate states of a recurrent neural network document reader.", "labels": [], "entities": []}, {"text": "This enables the reader to build query-specific representations of tokens in the document for accurate answer selection.", "labels": [], "entities": [{"text": "answer selection", "start_pos": 103, "end_pos": 119, "type": "TASK", "confidence": 0.7571938335895538}]}, {"text": "The GA Reader obtains state-of-the-art results on three benchmarks for this task-the CNN & Daily Mail news stories and the Who Did What dataset.", "labels": [], "entities": [{"text": "GA Reader", "start_pos": 4, "end_pos": 13, "type": "DATASET", "confidence": 0.9440040588378906}, {"text": "CNN & Daily Mail news stories", "start_pos": 85, "end_pos": 114, "type": "DATASET", "confidence": 0.9145220915476481}, {"text": "Who Did What dataset", "start_pos": 123, "end_pos": 143, "type": "DATASET", "confidence": 0.7743064910173416}]}, {"text": "The effectiveness of multi-plicative interaction is demonstrated by an ablation study, and by comparing to alternative compositional operators for implementing the gated-attention.", "labels": [], "entities": []}], "introductionContent": [{"text": "A recent trend to measure progress towards machine reading is to test a system's ability to answer questions about a document it has to comprehend.", "labels": [], "entities": [{"text": "machine reading", "start_pos": 43, "end_pos": 58, "type": "TASK", "confidence": 0.7664192318916321}]}, {"text": "Towards this end, several large-scale datasets of cloze-style questions over a context document have been introduced recently, which allow the training of supervised machine learning systems (.", "labels": [], "entities": []}, {"text": "Such datasets can be easily constructed automatically and the unambiguous nature of their queries provides an objective benchmark to measure a system's performance at text comprehension.", "labels": [], "entities": []}, {"text": "Deep learning models have been shown to outperform traditional shallow approaches on text comprehension tasks ().", "labels": [], "entities": []}, {"text": "The success of many recent models can be attributed primarily to two factors: (1) Multi-hop architectures (), allow a model to scan the document and the question iteratively for multiple passes.", "labels": [], "entities": []}, {"text": "(2) Attention mechanisms,) borrowed from the machine translation literature (), allow the model to focus on appropriate subparts of the context document.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 45, "end_pos": 64, "type": "TASK", "confidence": 0.7213814854621887}]}, {"text": "Intuitively, the multi-hop architecture allows the reader to incrementally refine token representations, and the attention mechanism re-weights different parts in the document according to their relevance to the query.", "labels": [], "entities": []}, {"text": "The effectiveness of multi-hop reasoning and attentions have been explored orthogonally so far in the literature.", "labels": [], "entities": []}, {"text": "In this paper, we focus on combining both in a complementary manner, by designing a novel attention mechanism which gates the evolving token representations across hops.", "labels": [], "entities": []}, {"text": "More specifically, unlike existing models where the query attention is applied either token-wise () or sentence-wise () to allow weighted aggregation, the Gated-Attention (GA) module proposed in this work allows the query to directly interact with each dimension of the token embeddings at the semantic-level, and is applied layer-wise as information filters during the multi-hop representation learning process.", "labels": [], "entities": []}, {"text": "Such a fine-grained attention enables our model to learn conditional token representations w.r.t. the given question, leading to accurate answer selections.", "labels": [], "entities": []}, {"text": "We show in our experiments that the proposed GA reader, despite its relative simplicity, consis-tently improves over a variety of strong baselines on three benchmark datasets . Our key contribution, the GA module, provides a significant improvement for large datasets.", "labels": [], "entities": []}, {"text": "Qualitatively, visualization of the attentions at intermediate layers of the GA reader shows that in each layer the GA reader attends to distinct salient aspects of the query which help in determining the answer.", "labels": [], "entities": []}], "datasetContent": [{"text": "We evaluate the GA reader on five large-scale datasets recently proposed in the literature.", "labels": [], "entities": [{"text": "GA", "start_pos": 16, "end_pos": 18, "type": "TASK", "confidence": 0.9241848587989807}]}, {"text": "The first two, CNN and Daily Mail news stories 2 consist of articles from the popular CNN and Daily Mail websites (.", "labels": [], "entities": [{"text": "CNN and Daily Mail news stories", "start_pos": 15, "end_pos": 46, "type": "DATASET", "confidence": 0.8481671909491221}]}, {"text": "A query over each article is formed by removing an entity from the short summary which follows the article.", "labels": [], "entities": []}, {"text": "Further, entities within each article were anonymized to make the task purely a comprehension one.", "labels": [], "entities": []}, {"text": "N-gram statistics, for instance, computed over the entire corpus are no longer useful in such an anonymized corpus.", "labels": [], "entities": []}, {"text": "The next two datasets are formed from two different subsets of the Children's Book Test (CBT).", "labels": [], "entities": [{"text": "Children's Book Test (CBT)", "start_pos": 67, "end_pos": 93, "type": "DATASET", "confidence": 0.8497677360262189}]}, {"text": "Documents consist of 20 contiguous sentences from the body of a popular children's book, and queries are formed by deleting a token from the 21 st sentence.", "labels": [], "entities": []}, {"text": "We only focus on subsets where the deleted token is either a common noun (CN) or named entity (NE) since simple language models already give human-level performance on the other types (cf.).", "labels": [], "entities": []}, {"text": "The final dataset is Who Did What 4 (WDW) (, constructed from the LDC English Gigaword newswire corpus.", "labels": [], "entities": [{"text": "Who Did What 4 (WDW)", "start_pos": 21, "end_pos": 41, "type": "DATASET", "confidence": 0.6351083048752376}, {"text": "LDC English Gigaword newswire corpus", "start_pos": 66, "end_pos": 102, "type": "DATASET", "confidence": 0.952164626121521}]}, {"text": "First, article pairs which appeared around the same time and with overlapping entities are chosen, and then one article forms the document and a cloze query is constructed from the other.", "labels": [], "entities": []}, {"text": "Missing tokens are always person named entities.", "labels": [], "entities": []}, {"text": "Questions which are easily answered by simple baselines are filtered out, to make the task more challenging.", "labels": [], "entities": []}, {"text": "There are two versions of the training set-a small but focused \"Strict\" version and a large but noisy \"Relaxed\" version.", "labels": [], "entities": []}, {"text": "We report results on both settings which share the same validation and test sets.", "labels": [], "entities": []}, {"text": "Statistics of all the datasets used in our experiments are summarized in the Appendix).", "labels": [], "entities": [{"text": "Appendix", "start_pos": 77, "end_pos": 85, "type": "METRIC", "confidence": 0.9495730400085449}]}, {"text": "show a comparison of the performance of GA Reader with previously published results on WDW and CNN, Daily Mail, CBT datasets respectively.", "labels": [], "entities": [{"text": "GA Reader", "start_pos": 40, "end_pos": 49, "type": "DATASET", "confidence": 0.8792725205421448}, {"text": "WDW", "start_pos": 87, "end_pos": 90, "type": "DATASET", "confidence": 0.9848732948303223}, {"text": "CNN", "start_pos": 95, "end_pos": 98, "type": "DATASET", "confidence": 0.5871443152427673}, {"text": "Daily Mail", "start_pos": 100, "end_pos": 110, "type": "DATASET", "confidence": 0.866062581539154}, {"text": "CBT datasets", "start_pos": 112, "end_pos": 124, "type": "DATASET", "confidence": 0.9226064085960388}]}, {"text": "The numbers reported for GA Reader are for single best models, though we compare to both ensembles and single models from prior work.", "labels": [], "entities": [{"text": "GA Reader", "start_pos": 25, "end_pos": 34, "type": "DATASET", "confidence": 0.8581573367118835}]}, {"text": "GA Reader--refers to an earlier version of the model, unpublished but described in a preprint, with the following differences-(1) it does not utilize token-specific attentions within the GA module, as described in equation, it does not use a character composition model, (3) it is initialized with word embeddings pretrained on the corpus itself rather than GloVe.", "labels": [], "entities": [{"text": "GA Reader", "start_pos": 0, "end_pos": 9, "type": "DATASET", "confidence": 0.7496943771839142}]}, {"text": "A detailed analysis of these differences is studied in the next section.", "labels": [], "entities": []}, {"text": "Here we present 4 variants of the latest GA Reader, using combinations of whether the qe-comm feature is used (+feature) or not, and whether the word lookup table L(w) is updated during training or fixed to its initial value.", "labels": [], "entities": [{"text": "GA Reader", "start_pos": 41, "end_pos": 50, "type": "DATASET", "confidence": 0.7616593539714813}]}, {"text": "Other hyperparameters are listed in Appendix A.", "labels": [], "entities": [{"text": "Appendix", "start_pos": 36, "end_pos": 44, "type": "METRIC", "confidence": 0.7553674578666687}]}], "tableCaptions": [{"text": " Table 1: Validation/Test accuracy (%) on WDW dataset for both \"Strict\"", "labels": [], "entities": [{"text": "Test", "start_pos": 21, "end_pos": 25, "type": "METRIC", "confidence": 0.9031015038490295}, {"text": "accuracy", "start_pos": 26, "end_pos": 34, "type": "METRIC", "confidence": 0.8133718371391296}, {"text": "WDW dataset", "start_pos": 42, "end_pos": 53, "type": "DATASET", "confidence": 0.9779313802719116}]}, {"text": " Table 2: Top: Performance of different gating", "labels": [], "entities": [{"text": "gating", "start_pos": 40, "end_pos": 46, "type": "TASK", "confidence": 0.5880526304244995}]}, {"text": " Table 3: Validation/Test accuracy (%) on CNN, Daily Mail and CBT. Results marked with \" \u2020\" are cf previously published", "labels": [], "entities": [{"text": "accuracy", "start_pos": 26, "end_pos": 34, "type": "METRIC", "confidence": 0.7420365214347839}, {"text": "CNN", "start_pos": 42, "end_pos": 45, "type": "DATASET", "confidence": 0.966887891292572}, {"text": "Daily Mail", "start_pos": 47, "end_pos": 57, "type": "DATASET", "confidence": 0.9274513721466064}, {"text": "CBT", "start_pos": 62, "end_pos": 65, "type": "DATASET", "confidence": 0.5545580983161926}]}, {"text": " Table 4: Ablation study on WDW dataset, without using", "labels": [], "entities": [{"text": "Ablation", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9451570510864258}, {"text": "WDW dataset", "start_pos": 28, "end_pos": 39, "type": "DATASET", "confidence": 0.9500605165958405}]}]}