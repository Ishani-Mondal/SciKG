{"title": [{"text": "Diversity driven attention model for query-based abstractive summarization", "labels": [], "entities": [{"text": "summarization", "start_pos": 61, "end_pos": 74, "type": "TASK", "confidence": 0.8439598083496094}]}], "abstractContent": [{"text": "ive summarization aims to generate a shorter version of the document covering all the salient points in a compact and coherent fashion.", "labels": [], "entities": []}, {"text": "On the other hand, query-based summarization highlights those points that are relevant in the context of a given query.", "labels": [], "entities": []}, {"text": "The encode-attend-decode paradigm has achieved notable success in machine translation, extractive summarization, dialog systems , etc.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 66, "end_pos": 85, "type": "TASK", "confidence": 0.8325657546520233}, {"text": "extractive summarization", "start_pos": 87, "end_pos": 111, "type": "TASK", "confidence": 0.7831191718578339}]}, {"text": "But it suffers from the drawback of generation of repeated phrases.", "labels": [], "entities": []}, {"text": "In this work we propose a model for the query-based summarization task based on the encode-attend-decode paradigm with two key additions (i) a query attention model (in addition to document attention model) which learns to focus on different portions of the query at different time steps (instead of using a static representation for the query) and (ii) anew diversity based attention model which aims to alleviate the problem of repeating phrases in the summary.", "labels": [], "entities": [{"text": "summarization task", "start_pos": 52, "end_pos": 70, "type": "TASK", "confidence": 0.8383567631244659}]}, {"text": "In order to enable the testing of this model we introduce anew query-based summarization dataset building on debatepedia.", "labels": [], "entities": []}, {"text": "Our experiments show that with these two additions the proposed model clearly out-performs vanilla encode-attend-decode models with again of 28% (absolute) in ROUGE-L scores.", "labels": [], "entities": [{"text": "ROUGE-L", "start_pos": 159, "end_pos": 166, "type": "METRIC", "confidence": 0.976437509059906}]}], "introductionContent": [{"text": "Over the past few years neural models based on the encode-attend-decode () paradigm have shown great success in various natural language generation (NLG) tasks such as machine translation (), abstractive summarization,) dialog (, etc.", "labels": [], "entities": [{"text": "natural language generation (NLG)", "start_pos": 120, "end_pos": 153, "type": "TASK", "confidence": 0.8052547673384348}, {"text": "machine translation", "start_pos": 168, "end_pos": 187, "type": "TASK", "confidence": 0.7829243242740631}, {"text": "abstractive summarization", "start_pos": 192, "end_pos": 217, "type": "TASK", "confidence": 0.622467964887619}]}, {"text": "One such NLG problem which has not received enough attention in the past is query based abstractive text summarization where the aim is to generate the summary of a document in the context of a query.", "labels": [], "entities": [{"text": "query based abstractive text summarization", "start_pos": 76, "end_pos": 118, "type": "TASK", "confidence": 0.5931518733501434}]}, {"text": "In general, abstractive summarization, aims to coverall the salient points of a document in a compact and coherent fashion.", "labels": [], "entities": [{"text": "abstractive summarization", "start_pos": 12, "end_pos": 37, "type": "TASK", "confidence": 0.49762968719005585}]}, {"text": "On the other hand, query focused summarization highlights those points that are relevant in the context of the query.", "labels": [], "entities": [{"text": "query focused summarization", "start_pos": 19, "end_pos": 46, "type": "TASK", "confidence": 0.6439857482910156}]}, {"text": "Thus given a document on \"the super bowl\", the query \"How was the half-time show?\", would result in a summary that would not cover the actual game itself.", "labels": [], "entities": []}, {"text": "Note that there has been some work on query based extractive summarization in the past where the aim is to simply extract the most salient sentence(s) from a document and treat these as a summary.", "labels": [], "entities": [{"text": "query based extractive summarization", "start_pos": 38, "end_pos": 74, "type": "TASK", "confidence": 0.6541188880801201}]}, {"text": "There is no natural language generation involved.", "labels": [], "entities": [{"text": "natural language generation", "start_pos": 12, "end_pos": 39, "type": "TASK", "confidence": 0.7829595804214478}]}, {"text": "Since, we were interested in abstractive (as opposed to extractive) summarization we created anew dataset based on debatepedia.", "labels": [], "entities": []}, {"text": "This dataset contains triplets of the form (query, document, summary).", "labels": [], "entities": []}, {"text": "Further, each summary is abstractive and not extractive in the sense that the summary does not necessarily comprise of a sentence which is simply copied from the original document.", "labels": [], "entities": []}, {"text": "Using this dataset as a testbed, we focus on a recurring problem in models based on the encode-attend-decode paradigm.", "labels": [], "entities": []}, {"text": "Specifically, it is observed that the summaries produced by such models contain repeated phrases.", "labels": [], "entities": []}, {"text": "shows a few such examples of summaries gener-Document Snippet: The \"natural death\" alternative to euthanasia is not keeping someone alive via life support until they die on life support.", "labels": [], "entities": []}, {"text": "That would, indeed, be unnatural.", "labels": [], "entities": []}, {"text": "The natural alternative is, instead, to allow them to die off of life support.", "labels": [], "entities": []}, {"text": "Query: Is euthanasia better than withdrawing life support (non-treatment)?", "labels": [], "entities": []}, {"text": "Ground Truth Summary: The alternative to euthanasia is a natural death without life support.", "labels": [], "entities": [{"text": "Ground Truth Summary", "start_pos": 0, "end_pos": 20, "type": "TASK", "confidence": 0.635242780049642}]}, {"text": "Predicted Summary: the large to euthanasia is a natural death life life use Document Snippet: Legalizing same-sex marriage would also be a recognition of basic American principles, and would represent the culmination of our nation's commitment to equal rights.", "labels": [], "entities": [{"text": "Predicted", "start_pos": 0, "end_pos": 9, "type": "METRIC", "confidence": 0.9834919571876526}]}, {"text": "It is, some have said, the last major civil-rights milestone yet to be surpassed in our two-century struggle to attain the goals we set for this nation at its formation.", "labels": [], "entities": []}, {"text": "Query: Is gay marriage a civil right?", "labels": [], "entities": []}, {"text": "Ground Truth Summary: Gay marriage is a fundamental equal right.", "labels": [], "entities": []}, {"text": "Predicted Summary: gay marriage is a appropriate right right: Examples showing repeated words in the output of encoder-decoder models ated by such a model when trained on this new dataset.", "labels": [], "entities": []}, {"text": "This problem has also been reported by) in the context of summarization and by) in the context of machine translation.", "labels": [], "entities": [{"text": "summarization", "start_pos": 58, "end_pos": 71, "type": "TASK", "confidence": 0.983611524105072}, {"text": "machine translation", "start_pos": 98, "end_pos": 117, "type": "TASK", "confidence": 0.8066449761390686}]}, {"text": "We first provide an intuitive explanation for this problem and then propose a solution for alleviating it.", "labels": [], "entities": []}, {"text": "A typical encode-attend-decode model first computes a vectorial representation for the document and the query and then produces a contextual summary one word at a time.", "labels": [], "entities": []}, {"text": "Each word is produced by feeding anew context vector to the decoder at each time step by attending to different parts of the document and query.", "labels": [], "entities": []}, {"text": "If the decoder produces the same word or phrase repeatedly then it could mean that the context vectors fed to the decoder at these time steps are very similar.", "labels": [], "entities": []}, {"text": "We propose a model which explicitly prevents this by ensuring that successive context vectors are orthogonal to each other.", "labels": [], "entities": []}, {"text": "Specifically, we subtract out any component that the current context vector has in the direction of the previous context vector.", "labels": [], "entities": []}, {"text": "Notice that, we do not require the current context vector to be orthogonal to all previous context vectors but just its immediate predecessor.", "labels": [], "entities": []}, {"text": "This enables the model to attend to words repeatedly if required later in the process.", "labels": [], "entities": []}, {"text": "To account for the complete history (or all previous context vectors) we also propose an extension of this idea where we pass the sequence of context vectors through a LSTM and ensure that the current state produced by the LSTM is orthogonal to the history.", "labels": [], "entities": []}, {"text": "At each time step, the state of the LSTM is then fed to the decoder to produce one word in the summary.", "labels": [], "entities": []}, {"text": "Our contributions can be summarized as follows: (i) We propose anew dataset for query based abstractive summarization and evaluate encode-attend-decode models on this dataset (ii) We study the problem of repeating phrases in NLG in the context of this dataset and propose two solutions for countering this problem.", "labels": [], "entities": [{"text": "query based abstractive summarization", "start_pos": 80, "end_pos": 117, "type": "TASK", "confidence": 0.5420425459742546}]}, {"text": "We show that our method outperforms a vanilla encoder-decoder model with again of 28% (absolute) in ROUGE-L score (iii) We also demonstrate that our method clearly outperforms a recent state of the art method proposed for handling the problem of repeating phrases with again of 7% (absolute) in ROUGE-L scores (iv) We do a qualitative analysis of the results and show that our model indeed produces outputs with fewer repetitions.", "labels": [], "entities": []}], "datasetContent": [{"text": "As mentioned earlier, there are no existing datasets for query based abstractive summarization.", "labels": [], "entities": [{"text": "query based abstractive summarization", "start_pos": 57, "end_pos": 94, "type": "TASK", "confidence": 0.5879778414964676}]}, {"text": "We create such a dataset from Debatepedia an encyclopedia of pro and con arguments and quotes on critical debate topics.", "labels": [], "entities": []}, {"text": "There are 663 debates in the corpus (we have considered only those debates which have at least one query with one document).", "labels": [], "entities": []}, {"text": "These 663 debates belong to 53 overlapping categories such as Politics, Law, Crime, Environment, Health, Morality, Religion, etc.", "labels": [], "entities": []}, {"text": "A given topic can belong to more than one category.", "labels": [], "entities": []}, {"text": "For example, the topic \"Eye for an Eye philosophy\" belongs to both \"Law\" as well as \"Morality\".", "labels": [], "entities": []}, {"text": "The average number of queries per debate is 5 and the average number of documents per query is 4.", "labels": [], "entities": []}, {"text": "Please refer to the dataset url for more details about number of debates per category.", "labels": [], "entities": []}, {"text": "For example, shows the queries associated with the topic \"Algae Biofuel\".", "labels": [], "entities": []}, {"text": "It also lists the set of documents and an abstractive summary associated with each query.", "labels": [], "entities": []}, {"text": "As is obvious from the example, the summary is an abstractive summary and not extracted directly from the document.", "labels": [], "entities": []}, {"text": "We crawled 12695 such {query, document, summary} triples from debatepedia (these were all the triples that were available).", "labels": [], "entities": []}, {"text": "reports the average length of the query, summary and documents in this dataset.", "labels": [], "entities": []}, {"text": "We used 10 fold cross validation for all our experiments.", "labels": [], "entities": []}, {"text": "Each fold uses 80% of the documents for training, 10% for validation and 10% for testing.", "labels": [], "entities": []}, {"text": "We evaluate our models on the dataset described in section 3.", "labels": [], "entities": []}, {"text": "Note that there are no prior baselines on query based abstractive summarization so we could only compare with different variations of the encoder decoder models as described above.", "labels": [], "entities": [{"text": "query based abstractive summarization", "start_pos": 42, "end_pos": 79, "type": "TASK", "confidence": 0.5808071941137314}]}, {"text": "Further, we compare our diversity based attention models with existing models for diversity by suitably adapting them to this problem as described earlier.", "labels": [], "entities": []}, {"text": "Specifically, we compare the performance of the following models: \u2022 Vanilla e-a-d: This is the vanilla encoderattention-decoder model adapted to the problem of abstractive summarization.", "labels": [], "entities": []}, {"text": "It contains the following components (i) document encoder (ii) document attention model (iii) decoder.", "labels": [], "entities": []}, {"text": "It does not contain an encoder or attention model for the query.", "labels": [], "entities": []}, {"text": "This helps us understand the importance of the query.", "labels": [], "entities": []}, {"text": "\u2022 Query enc : This model contains the query encoder in addition to the three components used in the vanilla model above.", "labels": [], "entities": []}, {"text": "It does not contain any attention model for the query.", "labels": [], "entities": []}, {"text": "\u2022 Query att : This model contains the query attention model in addition to all the components in Query enc . \u2022 D 1 : The diversity attention model as described in Section 4.1.", "labels": [], "entities": []}, {"text": "\u2022 D 2 : The LSTM based diversity attention model as described in Section 4.1.", "labels": [], "entities": [{"text": "LSTM based diversity attention", "start_pos": 12, "end_pos": 42, "type": "TASK", "confidence": 0.8264975249767303}]}, {"text": "\u2022 SD 1 : The soft diversity attention model as described in Section 4.1 \u2022 SD 2 : The soft LSTM based diversity attention model as described in Section 4.1 \u2022 B 1 : Diversity cell in Figure3 is replaced by the basic LSTM cell (i.e. c diverse t = ct instead of using Equation.", "labels": [], "entities": [{"text": "Equation", "start_pos": 264, "end_pos": 272, "type": "METRIC", "confidence": 0.9518625736236572}]}, {"text": "This helps us understand whether simply using an LSTM to track the history of context vectors (without imposing a diversity constraint) is sufficient.", "labels": [], "entities": []}, {"text": "\u2022 M 1 : The baseline model which operates on the context vector as described in Section 5.", "labels": [], "entities": []}, {"text": "\u2022 M 2 : The baseline model which operates on the attention weights in addition to the context vector as described in Section 5.", "labels": [], "entities": []}, {"text": "We used 80% of the data for training, 10% for validation and 10% for testing.", "labels": [], "entities": []}, {"text": "We create 10 such folds and report the average Rouge-1, Rouge-2, Rouge-L scores across the 10 folds.", "labels": [], "entities": []}, {"text": "The hyperparameters (batch size and GRU cell sizes) of all the models are tuned on the validation set.", "labels": [], "entities": [{"text": "GRU cell sizes", "start_pos": 36, "end_pos": 50, "type": "METRIC", "confidence": 0.9274922609329224}]}, {"text": "We tried the following batch sizes : 32, 64 and the following GRU cell sizes 200, 300, 400.", "labels": [], "entities": []}, {"text": "We used Adam () as the optimization algorithm with the initial learning rate set to 0.0004, \u03b2 1 = 0.9, \u03b2 2 = 0.999.", "labels": [], "entities": []}, {"text": "We used pre-trained publicly available Glove word embeddings 2 and fine-tuned them during training.", "labels": [], "entities": []}, {"text": "The same word embeddings are used for the query words and the document words.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2:  Average length of docu- ments/queries/summaries in the dataset", "labels": [], "entities": [{"text": "Average length", "start_pos": 11, "end_pos": 25, "type": "METRIC", "confidence": 0.8907831907272339}]}, {"text": " Table 4: Summaries generated by different models. In general, we observed that the baseline models  which do not use a diversity based attention model tend to produce more repetitions. Notice that the last  example shows that our model is not very aggressive in dealing with the history and is able to produce  valid repetitions (treated ... treated) when needed", "labels": [], "entities": []}, {"text": " Table 5: Average number of sentences with repeat- ing words across 10 folds", "labels": [], "entities": []}]}