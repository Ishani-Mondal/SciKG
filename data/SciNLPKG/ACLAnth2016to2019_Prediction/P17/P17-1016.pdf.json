{"title": [{"text": "Automatically Generating Rhythmic Verse with Neural Networks", "labels": [], "entities": [{"text": "Automatically Generating Rhythmic Verse", "start_pos": 0, "end_pos": 39, "type": "TASK", "confidence": 0.5959117114543915}]}], "abstractContent": [{"text": "We propose two novel methodologies for the automatic generation of rhythmic poetry in a variety of forms.", "labels": [], "entities": [{"text": "automatic generation of rhythmic poetry", "start_pos": 43, "end_pos": 82, "type": "TASK", "confidence": 0.7853445053100586}]}, {"text": "The first approach uses a neural language model trained on a phonetic encoding to learn an implicit representation of both the form and content of English poetry.", "labels": [], "entities": []}, {"text": "This model can effectively learn common poetic devices such as rhyme, rhythm and alliteration.", "labels": [], "entities": []}, {"text": "The second approach considers poetry generation as a constraint satisfaction problem where a generative neural language model is tasked with learning a representation of content, and a discrimi-native weighted finite state machine constrains it on the basis of form.", "labels": [], "entities": [{"text": "poetry generation", "start_pos": 30, "end_pos": 47, "type": "TASK", "confidence": 0.7729776203632355}]}, {"text": "By manipulating the constraints of the latter model, we can generate coherent poetry with arbitrary forms and themes.", "labels": [], "entities": []}, {"text": "A large-scale ex-trinsic evaluation demonstrated that participants consider machine-generated poems to be written by humans 54% of the time.", "labels": [], "entities": []}, {"text": "In addition, participants rated a machine-generated poem to be the most human-like amongst all evaluated.", "labels": [], "entities": []}], "introductionContent": [{"text": "Poetry is an advanced form of linguistic communication, in which a message is conveyed that satisfies both aesthetic and semantic constraints.", "labels": [], "entities": []}, {"text": "As poetry is one of the most expressive forms of language, the automatic creation of texts recognisable as poetry is difficult.", "labels": [], "entities": []}, {"text": "In addition to requiring an understanding of many aspects of language including phonetic patterns such as rhyme, rhythm and alliteration, poetry composition also requires a deep understanding of the meaning of language.", "labels": [], "entities": [{"text": "poetry composition", "start_pos": 138, "end_pos": 156, "type": "TASK", "confidence": 0.7242905497550964}]}, {"text": "Poetry generation can be divided into two subtasks, namely the problem of content, which is concerned with a poem's semantics, and the problem of form, which is concerned with the aesthetic rules that a poem follows.", "labels": [], "entities": [{"text": "Poetry generation", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.7220227271318436}]}, {"text": "These rules may describe aspects of the literary devices used, and are usually highly prescriptive.", "labels": [], "entities": []}, {"text": "Examples of different forms of poetry are limericks, ballads and sonnets.", "labels": [], "entities": []}, {"text": "Limericks, for example, are characterised by their strict rhyme scheme (AABBA), their rhythm (two unstressed syllables followed by one stressed syllable) and their shorter third and fourth lines.", "labels": [], "entities": [{"text": "Limericks", "start_pos": 0, "end_pos": 9, "type": "DATASET", "confidence": 0.910337507724762}, {"text": "rhyme", "start_pos": 58, "end_pos": 63, "type": "METRIC", "confidence": 0.941132128238678}, {"text": "AABBA", "start_pos": 72, "end_pos": 77, "type": "METRIC", "confidence": 0.9335511922836304}]}, {"text": "Creating such poetry requires not only an understanding of the language itself, but also of how it sounds when spoken aloud.", "labels": [], "entities": []}, {"text": "Statistical text generation usually requires the construction of a generative language model that explicitly learns the probability of any given word given previous context.", "labels": [], "entities": [{"text": "Statistical text generation", "start_pos": 0, "end_pos": 27, "type": "TASK", "confidence": 0.6695642669995626}]}, {"text": "Neural language models () have garnered signficant research interest for their ability to learn complex syntactic and semantic representations of natural language.", "labels": [], "entities": []}, {"text": "Poetry generation is an interesting application, since performing this task automatically requires the creation of models that not only focus on what is being written (content), but also on how it is being written (form).", "labels": [], "entities": [{"text": "Poetry generation", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.8022692799568176}]}, {"text": "We experiment with two novel methodologies for solving this task.", "labels": [], "entities": []}, {"text": "The first involves training a model to learn an implicit representation of content and form through the use of a phonological encoding.", "labels": [], "entities": []}, {"text": "The second involves training a generative language model to represent content, which is then constrained by a discriminative pronunciation model, representing form.", "labels": [], "entities": []}, {"text": "This second model is of particular interest because poetry with arbitrary rhyme, rhythm, repetition and themes can be generated by tuning the pronunciation model.", "labels": [], "entities": []}], "datasetContent": [{"text": "In order to examine how effective our methodologies for generating poetry are, we evaluate the proposed models in two ways.", "labels": [], "entities": []}, {"text": "First, we perform an intrinsic evaluation where we examine the quality of the models and the generated poetry.", "labels": [], "entities": []}, {"text": "Second, we perform an extrinsic evaluation where we evaluate the generated output using human annotators, and compare it to human-generated poetry.", "labels": [], "entities": []}, {"text": "To evaluate the ability of both models to generate formulaic poetry that adheres to rhythmic rules, we compared sets of fifty sampled lines from each model.", "labels": [], "entities": []}, {"text": "The first set was sampled from the phonetic-level model trained on Iambic poetry.", "labels": [], "entities": []}, {"text": "The second set was sampled from the characterlevel model, constrained to Iambic form.", "labels": [], "entities": []}, {"text": "For com-: Error when transliterating text into phonemes and reconstructing back into text.", "labels": [], "entities": [{"text": "Error", "start_pos": 10, "end_pos": 15, "type": "METRIC", "confidence": 0.9874672293663025}]}, {"text": "parison, and to act as a baseline, we also sampled from the unconstrained character model.", "labels": [], "entities": []}, {"text": "We created gold-standard syllabic classifications by recording each line spoken-aloud, and marking each syllable as either stressed or unstressed.", "labels": [], "entities": [{"text": "syllabic classifications", "start_pos": 25, "end_pos": 49, "type": "TASK", "confidence": 0.6764566451311111}]}, {"text": "We then compared these observations to loose Iambic Pentameter (containing all four variants), to determine how many syllabic misclassifications existed on each line.", "labels": [], "entities": []}, {"text": "This was done by speaking each line aloud, and noting where the speaker put stresses.", "labels": [], "entities": []}, {"text": "As shows, the constrained character level model generated the most formulaic poetry.", "labels": [], "entities": []}, {"text": "Results from this model show that 70% of lines had zero mistakes, with frequency obeying an inverse power-law relationship with the number of errors.", "labels": [], "entities": []}, {"text": "We can see that the phonetic model performed similarly, but produced more subtle mistakes than the constrained character model: many of the errors were single mistakes in an otherwise correct line of poetry.", "labels": [], "entities": []}, {"text": "In order to investigate this further, we examined to what extent these errors are due to transliteration (i.e., the phonetic encoding and orthographic decoding steps).", "labels": [], "entities": []}, {"text": "shows the reconstruction accuracy per word and per line when transliterating either Wikipedia or Sonnets to phonemes using the CMU pronunciation dictionary and subsequently reconstructing English text using the ngram model . Word accuracy reflects the frequency of perfect reconstruction, whereas per line tri-gram similarity) reflects the overall reconstruction.", "labels": [], "entities": [{"text": "CMU pronunciation dictionary", "start_pos": 127, "end_pos": 155, "type": "DATASET", "confidence": 0.8829109271367391}, {"text": "accuracy", "start_pos": 230, "end_pos": 238, "type": "METRIC", "confidence": 0.5248802900314331}]}, {"text": "Coverage captures the percentage of in-vocabulary items.", "labels": [], "entities": []}, {"text": "The relatively low per-word accuracy achieved on the Wikipedia corpus is likely due to the high frequency of out-ofvocabulary words.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 28, "end_pos": 36, "type": "METRIC", "confidence": 0.9747324585914612}, {"text": "Wikipedia corpus", "start_pos": 53, "end_pos": 69, "type": "DATASET", "confidence": 0.9499839544296265}]}, {"text": "The results show that a significant number of errors in the phonetic-level model are likely to be caused by transliteration mistakes.", "labels": [], "entities": []}, {"text": "We conducted an indistinguishability study with a selection of automatically generated poetry and human poetry.", "labels": [], "entities": []}, {"text": "As extrinsic evaluations are expensive and the phonetic model was unlikely to do well (as illustrated in: the model generates good Iambic form, but not very good English), we only evaluate on the constrained characterlevel model.", "labels": [], "entities": []}, {"text": "Poetry was generated with a variety of themes and poetic devices (see supplementary material).", "labels": [], "entities": []}, {"text": "The aim of the study was to determine whether participants could distinguish between human and machine-generated poetry, and if so to what extent.", "labels": [], "entities": []}, {"text": "A set of 70 participants (of whom 61 were English native speakers) were each shown a selection of randomly chosen poetry segments, and were invited to classify them as either human or generated.", "labels": [], "entities": []}, {"text": "Participants were recruited from friends and people within poetry communities within the University of Cambridge, with an age range of 17 to 80, and a mean age of 29.", "labels": [], "entities": []}, {"text": "Our participants were not financially incentivised, perceiving the evaluation as an intellectual challenge.", "labels": [], "entities": []}, {"text": "In addition to the classification task, each participant was also invited to rate each poem on a 1-5 scale with respect to three criteria, namely readability, form and evocation (how much emotion did a poem elicit).", "labels": [], "entities": []}, {"text": "We naively consider the overall quality of a poem to be the mean of these three measures.", "labels": [], "entities": []}, {"text": "We used a custom web-based environment, built specifically for this evaluation , which is illustrated in.", "labels": [], "entities": []}, {"text": "Based on human judgments, we can determine whether the models presented in this work can produce poetry of a similar quality to humans.", "labels": [], "entities": []}, {"text": "To select appropriate human poetry that could be meaningfully compared with the machinegenerated poetry, we performed a comprehension test on all poems used in the evaluation, using the Dale-Chall readability formula.", "labels": [], "entities": []}, {"text": "This formula represents readability as a function of the complexity of the input words.", "labels": [], "entities": []}, {"text": "We selected nine machine-generated poems with a high readability score.", "labels": [], "entities": []}, {"text": "The generated poems produced an average score of 7.11, indicating that readers over 15 years of age should easily be able to comprehend them.", "labels": [], "entities": []}, {"text": "For our human poems, we focused explicitly on poetry where greater consideration is placed on (a) The crow crooked on more beautiful and free, He journeyed off into the quarter sea.", "labels": [], "entities": []}, {"text": "his radiant ribs girdled empty and veryleast beautiful as dignified to see.", "labels": [], "entities": []}, {"text": "(c) Man with the broken blood blue glass and gold.", "labels": [], "entities": []}, {"text": "Cheap chatter chants to be a lover do.", "labels": [], "entities": []}, {"text": "(e) The son still streams and strength and spirit.", "labels": [], "entities": []}, {"text": "The ridden souls of which the fills of.", "labels": [], "entities": []}, {"text": "(b) Is that people like things (are the way we to figure it out) and I thought of you reading and then is your show or you know we will finish along will you play.", "labels": [], "entities": []}, {"text": "prosodic elements like rhythm and rhyme than semantic content (known as \"nonsense verse\").", "labels": [], "entities": []}, {"text": "We randomly selected 30 poems belonging to that category from the website poetrysoup.com, of which eight were selected for the final comparison based on their comparable readability score.", "labels": [], "entities": []}, {"text": "The selected poems were segmented into passages of between four and six lines, to match the length of the generated poetry segments.", "labels": [], "entities": []}, {"text": "An example of such a segment is shown in.", "labels": [], "entities": []}, {"text": "The human poems had an average score of 7.52, requiring a similar level of English aptitude to the generated texts.", "labels": [], "entities": []}, {"text": "The performance of each human poem, alongside the aggregated scores of the generated poems, is illustrated in.", "labels": [], "entities": []}, {"text": "For the human poems, our group of participants guessed correctly that they were human 51.4% of the time.", "labels": [], "entities": []}, {"text": "For the generated poems, our participants guessed correctly 46.2% of the time that they were machine generated.", "labels": [], "entities": []}, {"text": "To determine whether our results were statistically significant, we performed a Chi 2 test.", "labels": [], "entities": []}, {"text": "This resulted in a p-value of 0.718.", "labels": [], "entities": []}, {"text": "This indicates that our participants were unable to tell the difference between human and generated poetry in any significant way.", "labels": [], "entities": []}, {"text": "Although our participants generally considered the human poems to be of marginally higher quality than our generated poetry, they were unable to effectively distinguish between them.", "labels": [], "entities": []}, {"text": "Interestingly, our results seem to suggest that our participants consider the generated poems to be more 'human-like' than those actually written by humans.", "labels": [], "entities": []}, {"text": "In addition, the poem with the highest overall quality rating is a machine generated one.", "labels": [], "entities": []}, {"text": "This shows that our approach was effective at generating high-quality rhythmic verse.", "labels": [], "entities": []}, {"text": "It should be noted that the poems that were most 'human-like' and most aesthetic respectively were generated by the neural character model.", "labels": [], "entities": []}, {"text": "Generally the set of poetry produced by the neural character model was slightly less readable and emotive than the human poetry, but had above average form.", "labels": [], "entities": []}, {"text": "All generated poems included in this evaluation can be found in the supplementary material, and our code is made available online: Proportion of people classifying each poem as 'human', as well as the relative qualitative scores of each poem as deviations from the mean.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2:  Error when transliterating text into  phonemes and reconstructing back into text.", "labels": [], "entities": [{"text": "Error", "start_pos": 11, "end_pos": 16, "type": "METRIC", "confidence": 0.9945159554481506}]}, {"text": " Table 3: Proportion of people classifying each poem as 'human', as well as the relative qualitative scores  of each poem as deviations from the mean.", "labels": [], "entities": []}]}