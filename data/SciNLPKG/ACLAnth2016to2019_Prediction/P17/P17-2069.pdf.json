{"title": [{"text": "Improving Semantic Composition with Offset Inference", "labels": [], "entities": [{"text": "Improving Semantic Composition", "start_pos": 0, "end_pos": 30, "type": "TASK", "confidence": 0.8895552555720011}]}], "abstractContent": [{"text": "Count-based distributional semantic models suffer from sparsity due to unobserved but plausible co-occurrences in any text collection.", "labels": [], "entities": []}, {"text": "This problem is amplified for models like Anchored Packed Trees (APTs), that take the grammatical type of a co-occurrence into account.", "labels": [], "entities": []}, {"text": "We therefore introduce a novel form of distributional inference that exploits the rich type structure in APTs and infers missing data by the same mechanism that is used for semantic composition.", "labels": [], "entities": []}], "introductionContent": [{"text": "Anchored Packed Trees (APTs) is a recently proposed approach to distributional semantics that takes distributional composition to be a process of lexeme contextualisation . A lexeme's meaning, characterised as knowledge concerning co-occurrences involving that lexeme, is represented with a higher-order dependencytyped structure (the APT) where paths associated with higher-order dependencies connect vertices associated with weighted lexeme multisets.", "labels": [], "entities": []}, {"text": "The central innovation in the compositional theory is that the APT's type structure enables the precise alignment of the semantic representation of each of the lexemes being composed.", "labels": [], "entities": []}, {"text": "Like other countbased distributional spaces, however, it is prone to considerable data sparsity, caused by not observing all plausible co-occurrences in the given data.", "labels": [], "entities": []}, {"text": "Recently,  introduced a simple unsupervised algorithm to infer missing cooccurrence information by leveraging the distributional neighbourhood and ease the sparsity effect in count-based models.", "labels": [], "entities": []}, {"text": "In this paper, we generalise distributional inference (DI) in APTs and show how precisely the same mechanism that was introduced to support distributional composition, namely \"offsetting\" APT representations, gives rise to a novel form of distributional inference, allowing us to infer co-occurrences from neighbours of these representations.", "labels": [], "entities": [{"text": "distributional inference (DI)", "start_pos": 29, "end_pos": 58, "type": "TASK", "confidence": 0.6696211576461792}, {"text": "APTs", "start_pos": 62, "end_pos": 66, "type": "TASK", "confidence": 0.9352864027023315}]}, {"text": "For example, by transforming a representation of white to a representation of \"things that can be white\", inference of unobserved, but plausible, co-occurrences can be based on finding near neighbours (which will be nouns) of the \"things that can be white\" structure.", "labels": [], "entities": []}, {"text": "This furthermore exposes an interesting connection between distributional inference and distributional composition.", "labels": [], "entities": []}, {"text": "Our method is unsupervised and maintains the intrinsic interpretability of APTs 1 .", "labels": [], "entities": []}], "datasetContent": [{"text": "For our experiments we re-implemented the standard DI method of  fora direct comparison.", "labels": [], "entities": []}, {"text": "We built an order 2 APT space on the basis of the concatenation of ukWaC, Wackypedia and the BNC (, pre-parsed with the Malt parser ().", "labels": [], "entities": [{"text": "ukWaC", "start_pos": 67, "end_pos": 72, "type": "DATASET", "confidence": 0.9582260847091675}, {"text": "BNC", "start_pos": 93, "end_pos": 96, "type": "DATASET", "confidence": 0.9053884744644165}]}, {"text": "We PPMI transformed the raw co-occurrence counts prior to composition, using a negative SPPMI shift of log 5 (Levy and Goldberg, 2014b).", "labels": [], "entities": []}, {"text": "We also experimented with composing normalised counts and applying the PPMI transformation after composition as done by, however found composing PPMI scores to work better for this task.", "labels": [], "entities": []}, {"text": "We evaluate our offset inference algorithm on two popular short phrase composition benchmarks by and, henceforth ML08 and ML10 respectively.", "labels": [], "entities": [{"text": "ML08", "start_pos": 113, "end_pos": 117, "type": "DATASET", "confidence": 0.7695258855819702}, {"text": "ML10", "start_pos": 122, "end_pos": 126, "type": "DATASET", "confidence": 0.7933574914932251}]}, {"text": "The ML08 dataset consists of 120 distinct verb-object (VO) pairs and the ML10 dataset contains 108 adjective-noun (AN), 108 noun-noun (NN) and 108 verb-object pairs.", "labels": [], "entities": [{"text": "ML08 dataset", "start_pos": 4, "end_pos": 16, "type": "DATASET", "confidence": 0.9833626747131348}, {"text": "ML10 dataset", "start_pos": 73, "end_pos": 85, "type": "DATASET", "confidence": 0.9662540256977081}]}, {"text": "The goal is to compare a model's similarity estimates to human provided judgements.", "labels": [], "entities": []}, {"text": "For both tasks, each phrase pair has been rated by multiple human annotators on a scale between 1 and 7, where 7 indicates maximum similarity.", "labels": [], "entities": []}, {"text": "Comparison with human judgements is achieved by calculating Spearman's \u03c1 between the model's similarity estimates and the scores of each human annotator individually.", "labels": [], "entities": [{"text": "Spearman's \u03c1", "start_pos": 60, "end_pos": 72, "type": "METRIC", "confidence": 0.7573441664377848}]}, {"text": "We performed composition by intersection and tuned the number of neighbours by a grid search over {0, 10, 30, 50, 100, 500, 1000} on the ML10 development set, selecting 10 neighbours for NNs, 100 for ANs and 50 for VOs for both DI algorithms.", "labels": [], "entities": [{"text": "ML10 development set", "start_pos": 137, "end_pos": 157, "type": "DATASET", "confidence": 0.9618004163106283}]}, {"text": "We calculate statistical significance using the method of. shows the effect of the number of neighbours for AN, NN and VO phrases, using offset inference, on the ML10 development set.", "labels": [], "entities": [{"text": "ML10 development set", "start_pos": 162, "end_pos": 182, "type": "DATASET", "confidence": 0.8915432095527649}]}, {"text": "Interestingly, NN compounds exhibit an early saturation effect, while VOs and ANs require more neighbours for optimal performance.", "labels": [], "entities": []}, {"text": "One explanation for the observed behaviour is that up to some threshold, the neighbours being added contribute actually missing co-occurrence events, whereas past that threshold distributional inference degrades to just generic smoothing that is simply compensating for sparsity, but overwhelming the representations with non-plausible co-occurrence information.", "labels": [], "entities": []}, {"text": "A similar effect has also been observed by in an exemplarbased model.", "labels": [], "entities": []}, {"text": "shows that both forms of distributional inference significantly outperform a baseline without DI.", "labels": [], "entities": [{"text": "DI", "start_pos": 94, "end_pos": 96, "type": "METRIC", "confidence": 0.8800442218780518}]}, {"text": "On average, offset inference outperforms the method of  by a statistically significant margin on both datasets.: Comparison of DI algorithms.", "labels": [], "entities": [{"text": "offset inference", "start_pos": 12, "end_pos": 28, "type": "TASK", "confidence": 0.9561404585838318}]}, {"text": "\u2021 denotes statistical significance at p < 0.01 in comparison to the method without DI, * denotes statistical significance at p < 0.01 in comparison to standard DI and \u2020 denotes statistical significance at p < 0.05 in comparison to standard DI.", "labels": [], "entities": []}, {"text": "shows that offset inference substantially outperforms comparable sparse models by  on ML08, achieving anew state-ofthe-art, and matches the performance of the stateof-the-art neural network model of on ML10, while being fully interpretable.", "labels": [], "entities": [{"text": "ML08", "start_pos": 86, "end_pos": 90, "type": "DATASET", "confidence": 0.9527795910835266}, {"text": "ML10", "start_pos": 202, "end_pos": 206, "type": "DATASET", "confidence": 0.9367451667785645}]}], "tableCaptions": [{"text": " Table 3: Comparison of DI algorithms.  \u2021 denotes statistical  significance at p < 0.01 in comparison to the method without  DI, * denotes statistical significance at p < 0.01 in compar- ison to standard DI and  \u2020 denotes statistical significance at  p < 0.05 in comparison to standard DI.", "labels": [], "entities": []}, {"text": " Table 4: Comparison with existing methods.", "labels": [], "entities": []}]}