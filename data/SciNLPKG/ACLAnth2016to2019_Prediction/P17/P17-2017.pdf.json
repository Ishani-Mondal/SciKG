{"title": [{"text": "Understanding Task Design Trade-offs in Crowdsourced Paraphrase Collection", "labels": [], "entities": [{"text": "Paraphrase Collection", "start_pos": 53, "end_pos": 74, "type": "TASK", "confidence": 0.6106880456209183}]}], "abstractContent": [{"text": "Linguistically diverse datasets are critical for training and evaluating robust machine learning systems, but data collection is a costly process that often requires experts.", "labels": [], "entities": [{"text": "data collection", "start_pos": 110, "end_pos": 125, "type": "TASK", "confidence": 0.7980075180530548}]}, {"text": "Crowdsourcing the process of paraphrase generation is an effective means of expanding natural language datasets, but there has been limited analysis of the trade-offs that arise when designing tasks.", "labels": [], "entities": [{"text": "paraphrase generation", "start_pos": 29, "end_pos": 50, "type": "TASK", "confidence": 0.8624430596828461}]}, {"text": "In this paper, we present the first systematic study of the key factors in crowdsourc-ing paraphrase collection.", "labels": [], "entities": [{"text": "crowdsourc-ing paraphrase collection", "start_pos": 75, "end_pos": 111, "type": "TASK", "confidence": 0.7469116449356079}]}, {"text": "We consider variations in instructions, incentives, data domains, and workflows.", "labels": [], "entities": []}, {"text": "We manually analyzed paraphrases for correctness, gram-maticality, and linguistic diversity.", "labels": [], "entities": []}, {"text": "Our observations provide new insight into the trade-offs between accuracy and diversity in crowd responses that arise as a result of task design, providing guidance for future paraphrase generation procedures.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 65, "end_pos": 73, "type": "METRIC", "confidence": 0.998383641242981}, {"text": "paraphrase generation", "start_pos": 176, "end_pos": 197, "type": "TASK", "confidence": 0.9171826243400574}]}], "introductionContent": [{"text": "Paraphrases are useful fora range of tasks, including machine translation evaluation), semantic parsing (, and question answering.", "labels": [], "entities": [{"text": "machine translation evaluation", "start_pos": 54, "end_pos": 84, "type": "TASK", "confidence": 0.8519290089607239}, {"text": "semantic parsing", "start_pos": 87, "end_pos": 103, "type": "TASK", "confidence": 0.7986396253108978}, {"text": "question answering", "start_pos": 111, "end_pos": 129, "type": "TASK", "confidence": 0.884835809469223}]}, {"text": "Crowdsourcing has been widely used as a scalable and cost-effective means of generating paraphrases (, but there has been limited analysis of the factors influencing diversity and correctness of the paraphrases workers write.", "labels": [], "entities": []}, {"text": "In this paper, we perform a systematic investigation of design decisions for crowdsourcing paraphrases, including the first exploration of worker incentives for paraphrasing.", "labels": [], "entities": []}, {"text": "For worker incentives, we either provide a bonus payment when a paraphrase is novel (encouraging diversity) or when it matches a paraphrase from another worker (encouraging agreement/correctness).", "labels": [], "entities": []}, {"text": "We also varied the type of example paraphrases shown to workers, the number of paraphrases requested from each worker per sentence, the subject domain of the data, whether to show answers to questions, and whether the prompt sentence is the same for multiple workers or varies, with alternative prompts drawn from the output of other workers.", "labels": [], "entities": []}, {"text": "Effective paraphrasing has two desired properties: correctness and diversity.", "labels": [], "entities": [{"text": "Effective paraphrasing", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.6659031808376312}, {"text": "correctness", "start_pos": 51, "end_pos": 62, "type": "METRIC", "confidence": 0.9766472578048706}]}, {"text": "To measure correctness, we hand-labeled all paraphrases with semantic equivalence and grammaticality scores.", "labels": [], "entities": []}, {"text": "For diversity, we measure the fraction of paraphrases that are distinct, as well as Paraphrase In N-gram Changes (PINC), a measure of n-gram variation.", "labels": [], "entities": [{"text": "Paraphrase In N-gram Changes (PINC)", "start_pos": 84, "end_pos": 119, "type": "METRIC", "confidence": 0.8914861764226641}]}, {"text": "We have released all 2,600 paraphrases along with accuracy annotations.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 50, "end_pos": 58, "type": "METRIC", "confidence": 0.9985901713371277}]}, {"text": "Our analysis shows that the most important factor is how workers are primed fora task, with the choice of examples and the prompt sentence affecting diversity and correctness significantly.", "labels": [], "entities": []}], "datasetContent": [{"text": "We conducted a series of experiments to investigate factors in crowdsourced paraphrase creation.", "labels": [], "entities": [{"text": "crowdsourced paraphrase creation", "start_pos": 63, "end_pos": 95, "type": "TASK", "confidence": 0.6640252073605856}]}, {"text": "To do so in a controlled manner, we studied a single variation per condition.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Variation across conditions for a range of  metrics (defined in  \u00a7 3.4). Bold indicates a statisti- cally significant difference compared to the base- line at the 0.05 level, and a  \u2020 indicates significance  at the 0.01 level, both after applying the Holm- Bonferroni method across each row", "labels": [], "entities": [{"text": "Variation", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9000797271728516}, {"text": "statisti- cally significant difference", "start_pos": 100, "end_pos": 138, "type": "METRIC", "confidence": 0.8316795587539673}]}]}