{"title": [{"text": "Olelo: A Question Answering Application for Biomedicine", "labels": [], "entities": [{"text": "Question Answering Application", "start_pos": 9, "end_pos": 39, "type": "TASK", "confidence": 0.856994112332662}]}], "abstractContent": [{"text": "Despite the importance of the biomedi-cal domain, there are few reliable applications to support researchers and physicians for retrieving particular facts that fit their needs.", "labels": [], "entities": []}, {"text": "Users typically rely on search engines that only support keyword-and filter-based searches.", "labels": [], "entities": []}, {"text": "We present Olelo, a question answering system for biomedicine.", "labels": [], "entities": [{"text": "Olelo", "start_pos": 11, "end_pos": 16, "type": "DATASET", "confidence": 0.7161470055580139}, {"text": "question answering", "start_pos": 20, "end_pos": 38, "type": "TASK", "confidence": 0.7448027431964874}]}, {"text": "Olelo is built on top of an in-memory database, integrates domain resources , such as document collections and terminologies, and uses various natural language processing components.", "labels": [], "entities": [{"text": "Olelo", "start_pos": 0, "end_pos": 5, "type": "DATASET", "confidence": 0.8876779675483704}]}, {"text": "Olelo is fast, intuitive and easy to use.", "labels": [], "entities": [{"text": "Olelo", "start_pos": 0, "end_pos": 5, "type": "DATASET", "confidence": 0.7459707856178284}]}, {"text": "We evaluated the systems on two use cases: answering questions related to a particular gene and on the BioASQ benchmark.", "labels": [], "entities": [{"text": "BioASQ benchmark", "start_pos": 103, "end_pos": 119, "type": "DATASET", "confidence": 0.7347011268138885}]}, {"text": "Olelo is available at: http://hpi.de/ plattner/olelo.", "labels": [], "entities": [{"text": "Olelo", "start_pos": 0, "end_pos": 5, "type": "DATASET", "confidence": 0.9051104784011841}]}], "introductionContent": [{"text": "Biomedical researchers and physicians regularly query the scientific literature for particular facts, e.g., a syndrome caused by mutations on a particular gene or treatments fora certain disease.", "labels": [], "entities": []}, {"text": "For this purposes, users usually rely on the PubMed search engine 1 , which indexes millions of publications available in the Medline database.", "labels": [], "entities": [{"text": "PubMed search engine 1", "start_pos": 45, "end_pos": 67, "type": "DATASET", "confidence": 0.9344312399625778}, {"text": "Medline database", "start_pos": 126, "end_pos": 142, "type": "DATASET", "confidence": 0.981651782989502}]}, {"text": "Similar to classical information retrieval (IR) systems, input to PubMed is usually in the form of keywords, and alternatively MeSH concepts, and output is usually a list of documents.", "labels": [], "entities": [{"text": "information retrieval (IR)", "start_pos": 21, "end_pos": 47, "type": "TASK", "confidence": 0.850111472606659}]}, {"text": "For instance, when searching for diseases which could be caused by mutations on the CFTR gene, the user would simply write the gene name in PubMed's input field.", "labels": [], "entities": [{"text": "CFTR gene", "start_pos": 84, "end_pos": 93, "type": "DATASET", "confidence": 0.9427633285522461}, {"text": "PubMed's input field", "start_pos": 140, "end_pos": 160, "type": "DATASET", "confidence": 0.8627309799194336}]}, {"text": "For this example, he would 1 http://www.ncbi.nlm.nih.gov/pubmed be presented with a list of 9227 potentially relevant publications (as of.", "labels": [], "entities": []}, {"text": "There are plenty of other Web applications for searching and navigating through the scientific biomedical literature, as surveyed in.", "labels": [], "entities": []}, {"text": "However, most of these systems rely on simple natural language processing (NLP) techniques, such as tokenization and named-entity recognition (NER).", "labels": [], "entities": [{"text": "named-entity recognition (NER)", "start_pos": 117, "end_pos": 147, "type": "TASK", "confidence": 0.8334257006645203}]}, {"text": "Their functionalities are restricted to ranking documents with the support of domain terminologies, enriching publications with concepts and clustering similar documents.", "labels": [], "entities": []}, {"text": "Question answering (QA) can support biomedical professionals by allowing input in the form of natural questions and by providing exact answers and customized short summaries in return (.", "labels": [], "entities": [{"text": "Question answering (QA)", "start_pos": 0, "end_pos": 23, "type": "TASK", "confidence": 0.9324788331985474}]}, {"text": "We are aware of three of such systems for biomedicine (cf. Section 2), however, current solutions still fail to fulfill the needs of users: (i) In most of them, no question understanding is carried out on the questions.", "labels": [], "entities": []}, {"text": "(ii) Those that do make use of more complex NLP techniques (e.g., HONQA) cannot output answers in real time.", "labels": [], "entities": []}, {"text": "(iii) The output is usually in the form of a list of documents, instead of short answers.", "labels": [], "entities": []}, {"text": "(iv) They provide no innovative or NLP-based means to further explore the scientific literature.", "labels": [], "entities": []}, {"text": "We present Olelo, a QA system for the biomedical domain.", "labels": [], "entities": [{"text": "Olelo", "start_pos": 11, "end_pos": 16, "type": "DATASET", "confidence": 0.8192076683044434}]}, {"text": "It indexes biomedical abstracts and full texts, relies on a fast in-memory database (IMDB) for storage and document indexing and implements various NLP procedures, such as domain-specific NER, question type detection, answer type detection and answer extraction.", "labels": [], "entities": [{"text": "question type detection", "start_pos": 193, "end_pos": 216, "type": "TASK", "confidence": 0.7869552771250407}, {"text": "answer type detection", "start_pos": 218, "end_pos": 239, "type": "TASK", "confidence": 0.7943520545959473}, {"text": "answer extraction", "start_pos": 244, "end_pos": 261, "type": "TASK", "confidence": 0.8217487931251526}]}, {"text": "We evaluated the methods behind Olelo in the scope of the BioASQ challenge (, the most comprehensive shared task on biomedical QA.", "labels": [], "entities": []}, {"text": "We participated in the last three challenges and obtained top results for snippets retrieval and ideal answers (customized summaries) in the last two editions", "labels": [], "entities": [{"text": "snippets retrieval", "start_pos": 74, "end_pos": 92, "type": "TASK", "confidence": 0.6831543743610382}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Statistics on documents, sentences and  named entities (as of February/2017).", "labels": [], "entities": []}]}