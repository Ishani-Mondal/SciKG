{"title": [{"text": "The State of the Art in Semantic Representation", "labels": [], "entities": [{"text": "Semantic Representation", "start_pos": 24, "end_pos": 47, "type": "TASK", "confidence": 0.6839921325445175}]}], "abstractContent": [{"text": "Semantic representation is receiving growing attention in NLP in the past few years, and many proposals for semantic schemes (e.g., AMR, UCCA, GMB, UDS) have been put forth.", "labels": [], "entities": [{"text": "Semantic representation", "start_pos": 0, "end_pos": 23, "type": "TASK", "confidence": 0.8307044208049774}]}, {"text": "Yet, little has been done to assess the achievements and the shortcomings of these new contenders, compare them with syntactic schemes, and clarify the general goals of research on semantic representation.", "labels": [], "entities": [{"text": "semantic representation", "start_pos": 181, "end_pos": 204, "type": "TASK", "confidence": 0.7602603435516357}]}, {"text": "We address these gaps by critically surveying the state of the art in the field.", "labels": [], "entities": []}], "introductionContent": [{"text": "Schemes for Semantic Representation of Text (SRT) aim to reflect the meaning of sentences and texts in a transparent way.", "labels": [], "entities": [{"text": "Semantic Representation of Text (SRT)", "start_pos": 12, "end_pos": 49, "type": "TASK", "confidence": 0.882256805896759}]}, {"text": "There has recently been an influx of proposals for semantic representations and corpora, e.g. GMB (), AMR (, UCCA (Abend and Rappoport, 2013b) and Universal Decompositional Semantics (UDS;.", "labels": [], "entities": [{"text": "GMB", "start_pos": 94, "end_pos": 97, "type": "DATASET", "confidence": 0.8715360760688782}, {"text": "UCCA (Abend and Rappoport, 2013b)", "start_pos": 109, "end_pos": 142, "type": "DATASET", "confidence": 0.8821249678730965}]}, {"text": "Nevertheless, no detailed assessment of the relative merits of the different schemes has been carried out, nor their comparison to previous sentential analysis schemes, notably syntactic ones.", "labels": [], "entities": []}, {"text": "An understanding of the achievements and gaps of semantic analysis in NLP is crucial to its future prospects.", "labels": [], "entities": [{"text": "semantic analysis", "start_pos": 49, "end_pos": 66, "type": "TASK", "confidence": 0.8545270562171936}]}, {"text": "In this paper we begin to chart the various proposals for semantic schemes according to the content they support.", "labels": [], "entities": []}, {"text": "As not many semantic queries on texts can at present be answered with near human-like reliability without using manual symbolic annotation, we will mostly focus on schemes that represent semantic distinctions explicitly.", "labels": [], "entities": []}, {"text": "We begin by discussing the goals of SRT in Section 2.", "labels": [], "entities": [{"text": "SRT", "start_pos": 36, "end_pos": 39, "type": "TASK", "confidence": 0.9722007513046265}]}, {"text": "Section 3 surveys major represented meaning components, including predicate-argument relations, discourse relations and logical structure.", "labels": [], "entities": []}, {"text": "Section 4 details the various concrete proposals for SRT schemes and annotated resources, while Sections 5 and 6 discuss criteria for their evaluation and their relation to syntax, respectively.", "labels": [], "entities": [{"text": "SRT", "start_pos": 53, "end_pos": 56, "type": "TASK", "confidence": 0.9923257827758789}]}, {"text": "We find that despite the major differences in terms of formalism and interface with syntax, in terms of their content there is a great deal of convergence of SRT schemes.", "labels": [], "entities": [{"text": "SRT", "start_pos": 158, "end_pos": 161, "type": "TASK", "confidence": 0.9754374623298645}]}, {"text": "Principal differences between schemes are mostly related to their ability to abstract away from formal and syntactic variation, namely to assign similar structures to different constructions that have a similar meaning, and to assign different structures to constructions that have different meanings, despite their surface similarity.", "labels": [], "entities": []}, {"text": "Other important differences are in the level of training they require from their annotators (e.g., expert annotators vs. crowd-sourcing) and in their cross-linguistic generality.", "labels": [], "entities": []}, {"text": "We discuss the complementary strengths of different schemes, and suggest paths for future integration.", "labels": [], "entities": []}], "datasetContent": [{"text": "Human evaluation is the ultimate criterion for validating an SRT scheme given our definition of semantics as meaning as it is understood by a language speaker.", "labels": [], "entities": [{"text": "SRT", "start_pos": 61, "end_pos": 64, "type": "TASK", "confidence": 0.9890710115432739}]}, {"text": "Determining how well an SRT scheme corresponds to human interpretation of a text is ideally carried out by asking annotators to make some semantic prediction or annotation according to pre-specified guidelines, and to compare this to the information extracted from the SRT.", "labels": [], "entities": [{"text": "SRT", "start_pos": 24, "end_pos": 27, "type": "TASK", "confidence": 0.9802077412605286}]}, {"text": "Question Answering SRL (QASRL;) is an SRL scheme which solicits nonexperts to answer mostly wh-questions, converting their output to an SRL annotation. and use crowdsourcing to elicit semantic role features, such as whether the argument was volitional in the described event, in order to evaluate proposals for semantic role sets.", "labels": [], "entities": [{"text": "Question Answering SRL (QASRL", "start_pos": 0, "end_pos": 29, "type": "TASK", "confidence": 0.7896065652370453}, {"text": "SRL", "start_pos": 38, "end_pos": 41, "type": "TASK", "confidence": 0.9760528206825256}]}, {"text": "Another evaluation approach is task-based evaluation.", "labels": [], "entities": []}, {"text": "Many semantic representations in NLP are defined with an application in mind, making this type of evaluation natural.", "labels": [], "entities": []}, {"text": "For instance, a major motivation for AMR is its applicability to machine translation, making MT a natural (albeit hitherto unexplored) testbed for AMR evaluation.", "labels": [], "entities": [{"text": "AMR", "start_pos": 37, "end_pos": 40, "type": "TASK", "confidence": 0.9815896153450012}, {"text": "machine translation", "start_pos": 65, "end_pos": 84, "type": "TASK", "confidence": 0.7663169801235199}, {"text": "MT", "start_pos": 93, "end_pos": 95, "type": "TASK", "confidence": 0.9020170569419861}, {"text": "AMR evaluation", "start_pos": 147, "end_pos": 161, "type": "TASK", "confidence": 0.9450855851173401}]}, {"text": "Another example is using question answering to evaluate semantic parsing into knowledge-base queries.", "labels": [], "entities": [{"text": "question answering", "start_pos": 25, "end_pos": 43, "type": "TASK", "confidence": 0.7885144054889679}, {"text": "evaluate semantic parsing into knowledge-base queries", "start_pos": 47, "end_pos": 100, "type": "TASK", "confidence": 0.7469808806975683}]}, {"text": "Another common criterion for evaluating a semantic scheme is invariance, where semantic analysis should be similar across paraphrases or translation pairs (.", "labels": [], "entities": []}, {"text": "For instance, most SRL schemes abstract away from the syntactic divergence between the sentences (1) \"He gave a present to John\" and (2) \"It was John who was given a present\" (although a complete analysis would reflect the difference of focus between them).", "labels": [], "entities": [{"text": "SRL", "start_pos": 19, "end_pos": 22, "type": "TASK", "confidence": 0.9849796891212463}]}, {"text": "Importantly, these evaluation criteria also apply in cases where the representation is automatically induced, rather than manually defined.", "labels": [], "entities": []}, {"text": "For instance, vector space representations are generally evaluated either through task-based evaluation, or in terms of semantic features computed from them, whose validity is established by human annotators (e.g.,.", "labels": [], "entities": []}, {"text": "Finally, where semantic schemes are induced through manual annotation (and not through automated procedures), a common criterion for determining whether the guidelines are sufficiently clear, and whether the categories are well-defined is to measure agreement between annotators, by assigning them the same texts and measuring the similarity of the resulting structures.", "labels": [], "entities": []}, {"text": "Measures include the SMATCH measure for AMR, and the PARSEVAL F-score ( adapted for DAGs for UCCA.", "labels": [], "entities": [{"text": "SMATCH measure", "start_pos": 21, "end_pos": 35, "type": "METRIC", "confidence": 0.9673691093921661}, {"text": "AMR", "start_pos": 40, "end_pos": 43, "type": "TASK", "confidence": 0.944891631603241}, {"text": "PARSEVAL", "start_pos": 53, "end_pos": 61, "type": "METRIC", "confidence": 0.9226499795913696}, {"text": "F-score", "start_pos": 62, "end_pos": 69, "type": "METRIC", "confidence": 0.6198670864105225}]}, {"text": "SRT schemes diverge in the background and training they require from their annotators.", "labels": [], "entities": [{"text": "SRT", "start_pos": 0, "end_pos": 3, "type": "TASK", "confidence": 0.9709680080413818}]}, {"text": "Some schemes require extensive training (e.g., AMR), while others can be (at least partially) collected by crowdsourcing (e.g., UDS).", "labels": [], "entities": []}, {"text": "Other examples include FrameNet, which requires expert annotators for creating new frames, but employs less trained in-house annotators for applying existing frames to texts; QASRL, which employs non-expert annotators remotely; and UCCA, which uses inhouse non-experts, demonstrating no advantage to expert over non-expert annotators after an initial training period.", "labels": [], "entities": [{"text": "QASRL", "start_pos": 175, "end_pos": 180, "type": "DATASET", "confidence": 0.8287712335586548}, {"text": "UCCA", "start_pos": 232, "end_pos": 236, "type": "DATASET", "confidence": 0.8833427429199219}]}, {"text": "Another approach is taken by GMB, which uses online collaboration where expert collaborators participate in manually correcting automatically created representations.", "labels": [], "entities": [{"text": "GMB", "start_pos": 29, "end_pos": 32, "type": "DATASET", "confidence": 0.9416805505752563}]}, {"text": "They further employ gamification strategies for collecting some aspects of the annotation.", "labels": [], "entities": []}, {"text": "One of the great promises of semantic analysis (over more surface forms of analysis) is its cross-linguistic potential.", "labels": [], "entities": [{"text": "semantic analysis", "start_pos": 29, "end_pos": 46, "type": "TASK", "confidence": 0.891688197851181}]}, {"text": "However, while the theoretical and applicative importance of universality in semantics has long been recognized, the nature of universal semantics remains unknown.", "labels": [], "entities": []}, {"text": "Recently, projects such as BabelNet (), UBY (Gurevych et al., 2012) and Open Multilingual Wordnet 4 , constructed huge multi-lingual semantic nets, by linking resources such as Wikipedia and WordNet and processing them using modern NLP.", "labels": [], "entities": [{"text": "UBY", "start_pos": 40, "end_pos": 43, "type": "DATASET", "confidence": 0.8611727356910706}]}, {"text": "However, such projects currently focus on lexical semantic and encyclopedic information rather than on text semantics.", "labels": [], "entities": []}, {"text": "Symbolic SRT schemes such as SRL schemes and AMR have also been studied for their crosslinguistic applicability), indicating partial portability across languages.", "labels": [], "entities": [{"text": "SRT", "start_pos": 9, "end_pos": 12, "type": "TASK", "confidence": 0.9468785524368286}]}, {"text": "Translated versions of PropBank and FrameNet have been constructed for multiple languages (e.g.,.", "labels": [], "entities": [{"text": "PropBank", "start_pos": 23, "end_pos": 31, "type": "DATASET", "confidence": 0.9378495812416077}]}, {"text": "How-ever, as both PropBank and FrameNet are lexicalized schemes, and as lexicons diverge wildly across languages, these schemes require considerable adaptation when ported across languages (.", "labels": [], "entities": [{"text": "PropBank", "start_pos": 18, "end_pos": 26, "type": "DATASET", "confidence": 0.9220547676086426}]}, {"text": "Ongoing research tackles the generalization of VerbNet's unlexicalized roles to a universally applicable set (e.g.,.", "labels": [], "entities": []}, {"text": "Few SRT schemes place cross-linguistically applicability as one of their main criteria, examples include UCCA, and the), both of which draw on typological theory.", "labels": [], "entities": [{"text": "SRT", "start_pos": 4, "end_pos": 7, "type": "TASK", "confidence": 0.9860870242118835}, {"text": "UCCA", "start_pos": 105, "end_pos": 109, "type": "DATASET", "confidence": 0.9258923530578613}]}, {"text": "Vector space models, which embed words and sentences in a vector space, have also been applied to induce a shared cross-linguistic space.", "labels": [], "entities": []}, {"text": "However, further evaluation is required in order to determine what aspects of meaning these representations reflect reliably.", "labels": [], "entities": []}], "tableCaptions": []}