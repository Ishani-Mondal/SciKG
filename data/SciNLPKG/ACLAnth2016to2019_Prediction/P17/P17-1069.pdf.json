{"title": [{"text": "Leveraging Behavioral and Social Information for Weakly Supervised Collective Classification of Political Discourse on Twitter", "labels": [], "entities": [{"text": "Supervised Collective Classification of Political Discourse", "start_pos": 56, "end_pos": 115, "type": "TASK", "confidence": 0.7246961245934168}]}], "abstractContent": [{"text": "Framing is apolitical strategy in which politicians carefully word their statements in order to control public perception of issues.", "labels": [], "entities": [{"text": "Framing", "start_pos": 0, "end_pos": 7, "type": "TASK", "confidence": 0.8970817923545837}]}, {"text": "Previous works exploring political framing typically analyze frame usage in longer texts, such as congressional speeches.", "labels": [], "entities": []}, {"text": "We present a collection of weakly supervised models which harness collective classification to predict the frames used in political discourse on the microblogging platform, Twitter.", "labels": [], "entities": []}, {"text": "Our global probabilistic models show that by combining both lexical features of tweets and network-based behavioral features of Twitter, we are able to increase the average , unsupervised F 1 score by 21.52 points over a lexical baseline alone.", "labels": [], "entities": [{"text": "F 1 score", "start_pos": 188, "end_pos": 197, "type": "METRIC", "confidence": 0.9755216836929321}]}], "introductionContent": [{"text": "The importance of understanding political discourse on social media platforms is becoming increasingly clear.", "labels": [], "entities": []}, {"text": "In recent U.S. presidential elections, Twitter was widely used by all candidates to promote their agenda, interact with supporters, and attack their opponents.", "labels": [], "entities": []}, {"text": "Social interactions on such platforms allow politicians to quickly react to current events and gauge interest in and support for their actions.", "labels": [], "entities": []}, {"text": "These dynamic settings emphasize the importance of constructing automated tools for analyzing this content.", "labels": [], "entities": []}, {"text": "However, these same dynamics make constructing such tools difficult, as the language used to discuss new events and political agendas continuously changes.", "labels": [], "entities": []}, {"text": "Consequently, the rich social interactions on Twitter can be leveraged to help support such analysis by providing alternatives to direct supervision.", "labels": [], "entities": []}, {"text": "In this paper we focus on political framing, a very nuanced political discourse analysis task, on a variety of issues frequently discussed on Twitter.", "labels": [], "entities": [{"text": "political framing", "start_pos": 26, "end_pos": 43, "type": "TASK", "confidence": 0.7429524064064026}]}, {"text": "Framing) is employed by politicians to bias the discussion towards their stance by emphasizing specific aspects of the issue.", "labels": [], "entities": [{"text": "Framing)", "start_pos": 0, "end_pos": 8, "type": "TASK", "confidence": 0.8144932687282562}]}, {"text": "For example, the debate around increasing the minimum wage can be framed as a quality of life issue or as an economic issue.", "labels": [], "entities": []}, {"text": "While the first frame supports increasing minimum wage because it improves workers' lives, the second frame, by conversely emphasizing the costs involved, opposes the increase.", "labels": [], "entities": []}, {"text": "Using framing to analyze political discourse has gathered significant interest over the last few years ( as away to automatically analyze political discourse in congressional speeches and political news articles.", "labels": [], "entities": []}, {"text": "Different from previous works which focus on these longer texts or single issues, our dataset includes tweets authored by all members of the U.S. Congress from both parties, dealing with several policy issues (e.g., immigration, ACA, etc.).", "labels": [], "entities": [{"text": "immigration, ACA", "start_pos": 216, "end_pos": 232, "type": "TASK", "confidence": 0.6174789865811666}]}, {"text": "These tweets were annotated by adapting the annotation guidelines developed by for Twitter.", "labels": [], "entities": []}, {"text": "Twitter issue framing is a challenging multilabel prediction task.", "labels": [], "entities": [{"text": "Twitter issue framing", "start_pos": 0, "end_pos": 21, "type": "TASK", "confidence": 0.5949481924374899}, {"text": "multilabel prediction task", "start_pos": 39, "end_pos": 65, "type": "TASK", "confidence": 0.8037496010462443}]}, {"text": "Each tweet can be labeled as using one or more frames, out of 17 possibilities, while only providing 140 characters as input to the classifier.", "labels": [], "entities": []}, {"text": "The main contribution of this work is to evaluate whether the social and behavioral information available on Twitter is sufficient for constructing a reliable classifier for this task.", "labels": [], "entities": []}, {"text": "We approach this framing prediction task using a weakly supervised collective classification approach which leverages the dependencies between tweet frame predictions based on the interactions between their authors.", "labels": [], "entities": [{"text": "framing prediction task", "start_pos": 17, "end_pos": 40, "type": "TASK", "confidence": 0.9472387830416361}]}, {"text": "These dependencies are modeled by connecting Twitter users who have social connections or behavioral similarities.", "labels": [], "entities": []}, {"text": "Social connections are di-rected dependencies that represent the followers of each user as well as retweeting behavior (i.e., user A retweets user B's content).", "labels": [], "entities": []}, {"text": "Interestingly, such social connections capture the flow of influence within political parties; however, the number of connections that cross party lines is extremely low.", "labels": [], "entities": []}, {"text": "Instead, we rely on capturing behavioral similarity between users to provide this information.", "labels": [], "entities": []}, {"text": "For example, users whose Twitter activity peaks at similar times tend to discuss issues in similar ways, providing indicators of their frame usage for those issues.", "labels": [], "entities": []}, {"text": "In addition to using social and behavioral information, our approach also incorporates each politician's party affiliation and the frequent phrases (e.g., bigrams and trigrams) used by politicians on Twitter.", "labels": [], "entities": []}, {"text": "These lexical, social, and behavioral features are extracted from tweets via weakly supervised models and then declaratively compiled into a graphical model using Probabilistic Soft Logic (PSL), a recently introduced probabilistic modeling framework.", "labels": [], "entities": []}, {"text": "As described in Section 4, PSL specifies high level rules over a relational representation of these features.", "labels": [], "entities": [{"text": "PSL", "start_pos": 27, "end_pos": 30, "type": "TASK", "confidence": 0.955092191696167}]}, {"text": "These rules are then compiled into a graphical model called a hingeloss Markov random field (), which is used to make the frame prediction.", "labels": [], "entities": [{"text": "frame prediction", "start_pos": 122, "end_pos": 138, "type": "TASK", "confidence": 0.7249107956886292}]}, {"text": "Instead of direct supervision we take a bootstrapping approach by providing a small seed set of keywords adapted from, for each frame.", "labels": [], "entities": []}, {"text": "Our experiments show that modeling social and behavioral connections improves F 1 prediction scores in both supervised and unsupervised settings, with double the increase in the latter.", "labels": [], "entities": [{"text": "F 1 prediction scores", "start_pos": 78, "end_pos": 99, "type": "METRIC", "confidence": 0.8911411613225937}]}, {"text": "We apply our unsupervised model to our entire dataset of tweets to analyze framing patterns overtime by both party and individual politicians.", "labels": [], "entities": []}, {"text": "Our analysis provides insight into the usage of framing for identification of aisle-crossing politicians, i.e., those politicians who vote against their party.", "labels": [], "entities": []}], "datasetContent": [{"text": "Evaluation Metrics: Since each tweet can have more than one frame, our prediction task is a multilabel classification task.", "labels": [], "entities": []}, {"text": "The precision of a multilabel model is the ratio of how many predicted labels are correct: The recall of this model is the ratio of how many of the actual labels were predicted: We conducted experiments with different hour and day limits and found that using a time frame of one hour results in the best accuracy while limiting noise.", "labels": [], "entities": [{"text": "precision", "start_pos": 4, "end_pos": 13, "type": "METRIC", "confidence": 0.9983729124069214}, {"text": "recall", "start_pos": 95, "end_pos": 101, "type": "METRIC", "confidence": 0.9996517896652222}, {"text": "accuracy", "start_pos": 304, "end_pos": 312, "type": "METRIC", "confidence": 0.9985382556915283}]}, {"text": "In both formulas, T is the number of tweets, Y t is the true label for tweet t, x t is a tweet example, and h(x t ) are the predicted labels for that tweet.", "labels": [], "entities": []}, {"text": "The F 1 score is computed as the harmonic mean of the precision and recall.", "labels": [], "entities": [{"text": "F 1 score", "start_pos": 4, "end_pos": 13, "type": "METRIC", "confidence": 0.9780731995900472}, {"text": "precision", "start_pos": 54, "end_pos": 63, "type": "METRIC", "confidence": 0.9996727705001831}, {"text": "recall", "start_pos": 68, "end_pos": 74, "type": "METRIC", "confidence": 0.9985533356666565}]}, {"text": "Additionally, in, and 6 the reported average is the micro-weighted average F 1 scores overall frames.", "labels": [], "entities": []}, {"text": "Experimental Settings: We provide an analysis of our PSL models under both supervised and unsupervised settings.", "labels": [], "entities": []}, {"text": "In the PSL supervised experiments, we used five-fold cross validation with randomly chosen splits.", "labels": [], "entities": []}, {"text": "Previous works typically use an SVM, with bagof-words features, which is not used in a multilabel prediction, i.e., each frame is predicted individually.", "labels": [], "entities": []}, {"text": "The results of this approach on our dataset are shown in column 2 of.", "labels": [], "entities": []}, {"text": "In this scenario, the SVM tends to prefer the majority class, which results in many incorrect labels.", "labels": [], "entities": []}, {"text": "Column 3 shows the results of using an SVM with bag-of-words features to perform multilabel classification.", "labels": [], "entities": [{"text": "multilabel classification", "start_pos": 81, "end_pos": 106, "type": "TASK", "confidence": 0.7444056570529938}]}, {"text": "This approach decreases the F 1 score fora majority of frames.", "labels": [], "entities": [{"text": "F 1 score", "start_pos": 28, "end_pos": 37, "type": "METRIC", "confidence": 0.9924633304278055}]}, {"text": "Both SVMs also result in F 1 scores of 0 for some frames, further lowering the overall performance.", "labels": [], "entities": [{"text": "F 1 scores", "start_pos": 25, "end_pos": 35, "type": "METRIC", "confidence": 0.9926145076751709}]}, {"text": "Finally, columns 4 and 5 show the results of using our worst and best PSL models, respectively.", "labels": [], "entities": []}, {"text": "PSL Model 1, which uses our adapted unigram features instead of the bag-of-words features for multilabel classification, serves as our baseline to improve upon.", "labels": [], "entities": [{"text": "PSL Model 1", "start_pos": 0, "end_pos": 11, "type": "DATASET", "confidence": 0.9296085437138876}, {"text": "multilabel classification", "start_pos": 94, "end_pos": 119, "type": "TASK", "confidence": 0.6728212088346481}]}, {"text": "Additionally, Model 6 of the supervised, collective network setting represents the best results we can achieve.", "labels": [], "entities": []}, {"text": "We also explore the results of our PSL models in an unsupervised setting because the highly dynamic nature of political discourse on Twitter makes it unrealistic to expect annotated data to generalize to future discussions.", "labels": [], "entities": []}, {"text": "The only source of supervision comes from the initial unigrams lists and party information as described in Section 4.", "labels": [], "entities": []}, {"text": "The labeled tweets are used for evaluation only.", "labels": [], "entities": []}, {"text": "As seen in  Analysis of Supervised Experiments: shows the results of our supervised experiments.", "labels": [], "entities": []}, {"text": "Here we can see that by adding Twitter behavior (beginning with Model 4), our behaviorbased models achieve the best F 1 scores across all frames.", "labels": [], "entities": [{"text": "F 1 scores", "start_pos": 116, "end_pos": 126, "type": "METRIC", "confidence": 0.979878564675649}]}, {"text": "Model 4 achieves the highest results on two frames, suggesting retweeting and network follower information do not help improve the prediction score for these frames.", "labels": [], "entities": []}, {"text": "Similarly, Model 5 achieves the highest prediction for 5 of the frames, suggesting network follower information cannot further improve the score for these frames.", "labels": [], "entities": [{"text": "prediction", "start_pos": 40, "end_pos": 50, "type": "METRIC", "confidence": 0.9640059471130371}]}, {"text": "Overall, the Twitter behavior based models are able to outperform language based models alone, including the best performing language model (Model 3) which combines unigrams, bigrams, and trigrams together to collectively infer the correct frames.", "labels": [], "entities": []}, {"text": "Analysis of Unsupervised Experiments: In the unsupervised setting, Model 6, the combination of language and Twitter behavior features achieves the best results on 16 of the 17 issues, as shown in.", "labels": [], "entities": []}, {"text": "There area few interesting aspects of the unsupervised setting which differ from the supervised setting.", "labels": [], "entities": []}, {"text": "Six of the frame predictions do worse in Model 2, which is double that of the supervised version.", "labels": [], "entities": []}, {"text": "This is likely due to the presence of overlapping bigrams across frames and issues, e.g., \"women's healthcare\" could appear in both Frames 4 and 8 and the issues of ACA and abortion.", "labels": [], "entities": [{"text": "Frames", "start_pos": 132, "end_pos": 138, "type": "DATASET", "confidence": 0.9124997854232788}, {"text": "ACA", "start_pos": 165, "end_pos": 168, "type": "TASK", "confidence": 0.9399927258491516}]}, {"text": "However, all six are able to improve with the addition of trigrams (Model 3), whereas only 1 of 3 frames improves in the supervised setting.", "labels": [], "entities": []}, {"text": "This suggests that bigrams may not be as useful as trigrams in an unsupervised setting.", "labels": [], "entities": []}, {"text": "Finally, in Model 5, which adds retweet behaviors, we notice that 5 of the frames decrease in F 1 score and 11 of the frames have the same score as the previous model.", "labels": [], "entities": [{"text": "F 1 score", "start_pos": 94, "end_pos": 103, "type": "METRIC", "confidence": 0.9912034670511881}]}, {"text": "These results suggest that retweet behaviors are not as useful as the follower network relationships in an unsupervised setting.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Statistics of Collected Tweets. REP stands for Republican and DEM for Democrats.", "labels": [], "entities": [{"text": "REP", "start_pos": 42, "end_pos": 45, "type": "METRIC", "confidence": 0.9909915924072266}, {"text": "DEM", "start_pos": 72, "end_pos": 75, "type": "METRIC", "confidence": 0.8706055879592896}]}, {"text": " Table 4: Baseline and Skyline Micro-weighted  Average F 1 Scores. SVM INDIV. is the SVM  trained to predict one frame. SVM MULTI. is the  multiclass SVM. PSL M1 is the adapted unigram  PSL Model 1. PSL M6 is the collective network.", "labels": [], "entities": [{"text": "Micro-weighted  Average F 1 Scores", "start_pos": 31, "end_pos": 65, "type": "METRIC", "confidence": 0.8311848402023315}, {"text": "INDIV.", "start_pos": 71, "end_pos": 77, "type": "METRIC", "confidence": 0.8783436417579651}]}, {"text": " Table 5: F 1 Scores of Supervised PSL Models. The highest prediction per frame is marked in bold.", "labels": [], "entities": [{"text": "F 1 Scores", "start_pos": 10, "end_pos": 20, "type": "METRIC", "confidence": 0.9441144863764445}]}, {"text": " Table 6: F 1 Scores of Unsupervised PSL Models. The highest prediction per frame is marked in bold.", "labels": [], "entities": [{"text": "F 1 Scores", "start_pos": 10, "end_pos": 20, "type": "METRIC", "confidence": 0.9614621798197428}]}]}