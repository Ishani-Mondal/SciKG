{"title": [{"text": "Estimating Code-Switching on Twitter with a Novel Generalized Word-Level Language Detection Technique", "labels": [], "entities": []}], "abstractContent": [{"text": "Word-level language detection is necessary for analyzing code-switched text, where multiple languages could be mixed within a sentence.", "labels": [], "entities": [{"text": "Word-level language detection", "start_pos": 0, "end_pos": 29, "type": "TASK", "confidence": 0.6093580623467764}]}, {"text": "Existing models are restricted to code-switching between two specific languages and fail in real-world scenarios as text input rarely has a priori information on the languages used.", "labels": [], "entities": []}, {"text": "We present a novel unsupervised word-level language detection technique for code-switched text for an arbitrarily large number of languages, which does not require any manually annotated training data.", "labels": [], "entities": [{"text": "word-level language detection", "start_pos": 32, "end_pos": 61, "type": "TASK", "confidence": 0.5935874780019125}]}, {"text": "Our experiments with tweets in seven languages show a 74% relative error reduction in word-level labeling with respect to competitive baselines.", "labels": [], "entities": []}, {"text": "We then use this system to conduct a large-scale quantitative analysis of code-switching patterns on Twitter, both global as well as region-specific, with 58M tweets.", "labels": [], "entities": []}], "introductionContent": [{"text": "In stable multilingual societies, communication often features fluid alteration between two or more languages -a phenomenon known as code-switching 1.", "labels": [], "entities": []}, {"text": "It has been studied extensively in linguistics, primarily as a speech phenomenon.", "labels": [], "entities": []}, {"text": "However, the growing popularity of computer mediated * * This work was done when the authors were affiliated with Microsoft Research.communication, particularly social media, has resulted in language data in the text form which exhibits code-switching, among other speechlike characteristics.", "labels": [], "entities": []}, {"text": "With the large amount of online content generated by multilingual users around the globe, it becomes necessary to design techniques to analyze mixed language, which can help not only in developing end-user applications, but also in conducting fundamental sociolinguistic studies.", "labels": [], "entities": []}, {"text": "Language detection (LD) is a prerequisite to several NLP techniques.", "labels": [], "entities": [{"text": "Language detection (LD)", "start_pos": 0, "end_pos": 23, "type": "TASK", "confidence": 0.7956384956836701}]}, {"text": "Most state-of-the-art LD systems detect a single language for an entire document or sentence.", "labels": [], "entities": []}, {"text": "Such methods often fail to detect code-switching, which can occur within a sentence.", "labels": [], "entities": []}, {"text": "In recent times, there has been some effort to build word-level LD for code-switching between a specific pair of languages.", "labels": [], "entities": []}, {"text": "However, usually user-generated text (e.g., on social media) has no prior information of the languages being used.", "labels": [], "entities": []}, {"text": "Further, as several previous social-media based studies on multilingualism have pointed out, lack of general wordlevel LD has been a bottleneck in studying codeswitching patterns in multilingual societies.", "labels": [], "entities": []}, {"text": "This paper proposes a novel technique for wordlevel LD that generalizes to an arbitrarily large set of languages.", "labels": [], "entities": [{"text": "wordlevel LD", "start_pos": 42, "end_pos": 54, "type": "TASK", "confidence": 0.6724786162376404}]}, {"text": "The method does not require a priori information on the specific languages (potentially more than two) being mixed in an input text as long as the languages are from a fixed (arbitrarily large) set.", "labels": [], "entities": []}, {"text": "Training is done without any manually annotated data, while achieving accuracies comparable to language-restricted systems trained with large amounts of labeled data.", "labels": [], "entities": []}, {"text": "With a wordlevel LD accuracy of 96.3% on seven languages, this technique enabled us to analyze patterns of code-switching on Twitter, which is the second key contribution of this paper.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 20, "end_pos": 28, "type": "METRIC", "confidence": 0.6563394069671631}]}, {"text": "To the best of our knowledge, this is the first quantitative study of its kind, particularly at such a large-scale.", "labels": [], "entities": []}], "datasetContent": [{"text": "The data for both training and testing comes primarily from Twitter because of its public API, and studies have shown the presence of codeswitching in social media.", "labels": [], "entities": []}, {"text": "Our experiments use monolingual and codeswitched tweets in seven languages -Dutch (nl), English (en), French (fr), German (de), Portuguese (pt), Spanish (es) and Turkish (tr).", "labels": [], "entities": []}, {"text": "These form the set L.", "labels": [], "entities": []}, {"text": "The choice of languages is motivated by several factors.", "labels": [], "entities": []}, {"text": "First, LD is non-trivial as all these languages use the Latin script.", "labels": [], "entities": []}, {"text": "Second, a large volume of tweets are generated in these languages.", "labels": [], "entities": []}, {"text": "Third, there is annotated code-switched data available in nl-tr and en-es, which can be used for validation and testing.", "labels": [], "entities": [{"text": "validation", "start_pos": 97, "end_pos": 107, "type": "TASK", "confidence": 0.9641962647438049}]}, {"text": "Lastly, we know that certain pairs of these languages are code-switched often.", "labels": [], "entities": []}, {"text": "We compare GWLD with three existing systems: LINGUINI (Prager, 1999), LANGID (Lui and Baldwin, 2012), and POLYGLOT ().", "labels": [], "entities": [{"text": "LINGUINI", "start_pos": 45, "end_pos": 53, "type": "METRIC", "confidence": 0.9921131134033203}, {"text": "LANGID", "start_pos": 70, "end_pos": 76, "type": "METRIC", "confidence": 0.9865648746490479}, {"text": "POLYGLOT", "start_pos": 106, "end_pos": 114, "type": "METRIC", "confidence": 0.9190916419029236}]}, {"text": "None of these perform word-level LD, however, LANGID and POLYGLOT return a list of languages with confidence scores for the input.", "labels": [], "entities": [{"text": "word-level LD", "start_pos": 22, "end_pos": 35, "type": "TASK", "confidence": 0.48259975016117096}, {"text": "LANGID", "start_pos": 46, "end_pos": 52, "type": "METRIC", "confidence": 0.9861353635787964}, {"text": "POLYGLOT", "start_pos": 57, "end_pos": 65, "type": "METRIC", "confidence": 0.9874310493469238}]}, {"text": "Since codeswitching with more than two languages is absent in our dataset, we consider up to two language labels.", "labels": [], "entities": []}, {"text": "We define the tweet to be monolingual if the difference between the confidence values for the top two languages is greater than a parameter \u03b4.", "labels": [], "entities": []}, {"text": "Otherwise, it is assumed to be code-switched with the top two languages.", "labels": [], "entities": []}, {"text": "\u03b4 is tuned independently for the two LD systems on the validation set by maximizing the metric L 1 L 2 Accuracy (Sec. 6.2).", "labels": [], "entities": [{"text": "metric L 1 L 2 Accuracy", "start_pos": 88, "end_pos": 111, "type": "METRIC", "confidence": 0.6565148631731669}]}, {"text": "Inspired by, we also compare with dictionary-based word-level LD baselines.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Performance of LD Systems on Test Set", "labels": [], "entities": []}, {"text": " Table 3: Statistics for Pairwise (col. 2 and 3) and  GWLD Systems", "labels": [], "entities": [{"text": "GWLD", "start_pos": 54, "end_pos": 58, "type": "DATASET", "confidence": 0.9565420746803284}]}]}