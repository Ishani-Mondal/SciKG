{"title": [{"text": "Visualizing and Understanding Neural Machine Translation", "labels": [], "entities": [{"text": "Neural Machine Translation", "start_pos": 30, "end_pos": 56, "type": "TASK", "confidence": 0.6512151459852854}]}], "abstractContent": [{"text": "While neural machine translation (NMT) has made remarkable progress in recent years, it is hard to interpret its internal workings due to the continuous representations and non-linearity of neural networks.", "labels": [], "entities": [{"text": "neural machine translation (NMT)", "start_pos": 6, "end_pos": 38, "type": "TASK", "confidence": 0.8255045115947723}]}, {"text": "In this work, we propose to use layer-wise relevance propagation (LRP) to compute the contribution of each contextual word to arbitrary hidden states in the attention-based encoder-decoder framework.", "labels": [], "entities": [{"text": "layer-wise relevance propagation", "start_pos": 32, "end_pos": 64, "type": "TASK", "confidence": 0.6560325225194296}]}, {"text": "We show that visu-alization with LRP helps to interpret the internal workings of NMT and analyze translation errors.", "labels": [], "entities": []}], "introductionContent": [{"text": "End-to-end neural machine translation (NMT), which leverages neural networks to directly map between natural languages, has gained increasing popularity recently.", "labels": [], "entities": [{"text": "End-to-end neural machine translation (NMT)", "start_pos": 0, "end_pos": 43, "type": "TASK", "confidence": 0.7537546966757093}]}, {"text": "NMT proves to outperform conventional statistical machine translation (SMT) significantly across a variety of language pairs and becomes the new de facto method in practical MT systems ( ).", "labels": [], "entities": [{"text": "NMT", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.6878769993782043}, {"text": "statistical machine translation (SMT)", "start_pos": 38, "end_pos": 75, "type": "TASK", "confidence": 0.7793317983547846}, {"text": "MT", "start_pos": 174, "end_pos": 176, "type": "TASK", "confidence": 0.9871218800544739}]}, {"text": "However, there still remains a severe challenge: it is hard to interpret the internal workings of NMT.", "labels": [], "entities": []}, {"text": "In SMT (, the translation process can be denoted as a derivation that comprises a sequence of translation rules (e.g., phrase pairs and synchronous CFG rules).", "labels": [], "entities": [{"text": "SMT", "start_pos": 3, "end_pos": 6, "type": "TASK", "confidence": 0.9893223643302917}]}, {"text": "Defined on language structures with varying granularities, these translation rules are interpretable from a linguistic perspective.", "labels": [], "entities": []}, {"text": "In contrast, NMT takes an end-to-end approach: all internal information is represented as real-valued vectors or * Corresponding author. matrices.", "labels": [], "entities": []}, {"text": "It is challenging to associate hidden states in neural networks with interpretable language structures.", "labels": [], "entities": []}, {"text": "As a result, the lack of interpretability makes it very difficult to understand translation process and debug NMT systems.", "labels": [], "entities": [{"text": "translation process", "start_pos": 80, "end_pos": 99, "type": "TASK", "confidence": 0.8900821506977081}]}, {"text": "Therefore, it is important to develop new methods for visualizing and understanding NMT.", "labels": [], "entities": []}, {"text": "Existing work on visualizing and interpreting neural models has been extensively investigated in computer vision (.", "labels": [], "entities": [{"text": "interpreting neural models", "start_pos": 33, "end_pos": 59, "type": "TASK", "confidence": 0.863713006178538}]}, {"text": "Although visualizing and interpreting neural models for natural language processing has started to attract attention recently (, to the best of our knowledge, there is no existing work on visualizing NMT models.", "labels": [], "entities": [{"text": "interpreting neural models for natural language processing", "start_pos": 25, "end_pos": 83, "type": "TASK", "confidence": 0.686141984803336}]}, {"text": "Note that the attention mechanism () is restricted to demonstrate the connection between words in source and target languages and unable to offer more insights in interpreting how target words are generated (see Section 4.5).", "labels": [], "entities": []}, {"text": "In this work, we propose to use layer-wise relevance propagation (LRP) () to visualize and interpret neural machine translation.", "labels": [], "entities": [{"text": "layer-wise relevance propagation", "start_pos": 32, "end_pos": 64, "type": "TASK", "confidence": 0.6362928052743276}, {"text": "interpret neural machine translation", "start_pos": 91, "end_pos": 127, "type": "TASK", "confidence": 0.799652561545372}]}, {"text": "Originally designed to compute the contributions of single pixels to predictions for image classifiers, LRP back-propagates relevance recursively from the output layer to the input layer.", "labels": [], "entities": []}, {"text": "In contrast to visualization methods relying on derivatives, a major advantage of LRP is that it does not require neural activations to be differentiable or smooth (.", "labels": [], "entities": []}, {"text": "We adapt LRP to the attention-based encoder-decoder framework () to calculate relevance that measures the association degree between two arbitrary neurons in neural networks.", "labels": [], "entities": []}, {"text": "Case studies on Chinese-English translation show that visualization helps to interpret the internal workings of NMT and analyze translation errors.", "labels": [], "entities": [{"text": "Chinese-English translation", "start_pos": 16, "end_pos": 43, "type": "TASK", "confidence": 0.6649605184793472}]}], "datasetContent": [], "tableCaptions": []}