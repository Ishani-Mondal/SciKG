{"title": [{"text": "Methodical Evaluation of Arabic Word Embeddings", "labels": [], "entities": []}], "abstractContent": [{"text": "Many unsupervised learning techniques have been proposed to obtain meaningful representations of words from text.", "labels": [], "entities": []}, {"text": "In this study, we evaluate these various techniques when used to generate Arabic word embeddings.", "labels": [], "entities": []}, {"text": "We first build a benchmark for the Arabic language that can be utilized to perform intrinsic evaluation of different word embeddings.", "labels": [], "entities": []}, {"text": "We then perform additional extrinsic evaluations of the embed-dings based on two NLP tasks.", "labels": [], "entities": []}], "introductionContent": [{"text": "Distributed word representations, commonly referred to as word embeddings, represent words as vectors in a low-dimensional space.", "labels": [], "entities": []}, {"text": "The goal of this deep representation of words is to capture syntactic and semantic relationships between words.", "labels": [], "entities": []}, {"text": "These word embeddings have been proven to be very useful in various NLP applications, particularly those employing deep learning.", "labels": [], "entities": []}, {"text": "Word embeddings are typically learned using unsupervised learning techniques on large text corpora.", "labels": [], "entities": []}, {"text": "Many techniques have been proposed to learn such embeddings (.", "labels": [], "entities": []}, {"text": "While most of the work has focused on English word embeddings, few attempts have been carried out to learn word embeddings for other languages, mostly using the above mentioned techniques.", "labels": [], "entities": []}, {"text": "In this paper, we focus on Arabic word embeddings.", "labels": [], "entities": []}, {"text": "Particularly, we provide a thorough evaluation of the quality of four Arabic word embeddings that have been generated by previous work).", "labels": [], "entities": []}, {"text": "We use both intrinsic and extrinsic evaluation methods to evaluate the different embeddings.", "labels": [], "entities": []}, {"text": "For the intrinsic evaluation, we build a benchmark consisting of over 115,000 word analogy questions for the Arabic language.", "labels": [], "entities": []}, {"text": "Unlike previous attempts to evaluate Arabic embeddings, which relied on translating existing English benchmarks, our benchmark is the first specifically built for the Arabic language and is publicly available for future work in this area . Translating an English benchmark is not the best strategy to evaluate Arabic embeddings for the following reasons.", "labels": [], "entities": []}, {"text": "First, the currently available English benchmarks are specifically designed for the English language and some of the questions there are not applicable to Arabic.", "labels": [], "entities": []}, {"text": "Second, Arabic has more relations compared to English and these should be included in the benchmark as well.", "labels": [], "entities": []}, {"text": "Third, translating an English benchmark is subject to errors since it is usually carried out in an automatic fashion.", "labels": [], "entities": [{"text": "translating an English benchmark", "start_pos": 7, "end_pos": 39, "type": "TASK", "confidence": 0.8433268368244171}]}, {"text": "In addition to the new benchmark, we also extend the basic analogy reasoning task by taking into consideration more than two word pairs when evaluating a relation, and by considering the top-5 words rather than only the top-1 word when answering an analogy question.", "labels": [], "entities": [{"text": "analogy reasoning", "start_pos": 59, "end_pos": 76, "type": "TASK", "confidence": 0.9356340765953064}]}, {"text": "Finally, we perform an extrinsic evaluation of the different embeddings using two different NLP tasks, namely Document Classification and Named Entity Recognition.", "labels": [], "entities": [{"text": "Document Classification", "start_pos": 110, "end_pos": 133, "type": "TASK", "confidence": 0.8679595589637756}, {"text": "Named Entity Recognition", "start_pos": 138, "end_pos": 162, "type": "TASK", "confidence": 0.6193968256314596}]}], "datasetContent": [{"text": "To the best of our knowledge, these are the only available word embeddings that have been constructed for the Arabic language.", "labels": [], "entities": []}, {"text": "As we mentioned in the previous section, we use our word analogy benchmark to evaluate the embeddings using four different criteria, namely using top-1 and top-5 words when representing relations using two versus 11 word pairs.", "labels": [], "entities": []}, {"text": "Tables 2 displays the accuracy of each embedding technique for the four evaluation criteria.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 22, "end_pos": 30, "type": "METRIC", "confidence": 0.999462902545929}]}, {"text": "Note that we consider a question to be answered wrongly if at least one of the words in the question are not present in the word embeddings.", "labels": [], "entities": []}, {"text": "That is, we take into consideration the coverage of the embeddings as well ().", "labels": [], "entities": []}, {"text": "As can be seen in, the CBOW model consistently outperforms all other compared models for all four evaluation criteria.", "labels": [], "entities": []}, {"text": "The performance of Polyglot is particularly low since the embeddings were trained on a much smaller corpus (Arabic portion of Wikipedia), and thus both its coverage and the quality of the embeddings are much lower.", "labels": [], "entities": [{"text": "Polyglot", "start_pos": 19, "end_pos": 27, "type": "DATASET", "confidence": 0.9600894451141357}, {"text": "coverage", "start_pos": 156, "end_pos": 164, "type": "METRIC", "confidence": 0.9781745672225952}]}, {"text": "As can also be seen from the table, the accuracies of all the methods are boosted when: F-measure for two NLP tasks representing a relation using 11 pairs rather just two pairs.", "labels": [], "entities": [{"text": "accuracies", "start_pos": 40, "end_pos": 50, "type": "METRIC", "confidence": 0.9644096493721008}, {"text": "F-measure", "start_pos": 88, "end_pos": 97, "type": "METRIC", "confidence": 0.9962875843048096}]}, {"text": "This validates that it is indeed more appropriate to use more than two pairs to represent relations in word analogy tasks.", "labels": [], "entities": [{"text": "word analogy tasks", "start_pos": 103, "end_pos": 121, "type": "TASK", "confidence": 0.8109136422475179}]}, {"text": "When considering the top-5 matches, the accuracies of the embeddings are boosted drastically, which indeed shows that relying on just the top-1 word to assess the quality of embeddings might be unduly harsh, particularly in the case of Arabic.", "labels": [], "entities": [{"text": "accuracies", "start_pos": 40, "end_pos": 50, "type": "METRIC", "confidence": 0.9882301092147827}]}, {"text": "We perform extrinsic evaluation of the four word embeddings using two NLP tasks, namely: Arabic Document Classification and Arabic Named Entity Recognition (NER).", "labels": [], "entities": [{"text": "Arabic Document Classification", "start_pos": 89, "end_pos": 119, "type": "TASK", "confidence": 0.5889128943284353}, {"text": "Arabic Named Entity Recognition (NER)", "start_pos": 124, "end_pos": 161, "type": "TASK", "confidence": 0.7115479111671448}]}, {"text": "In the Document Classification task, the goal is to classify Arabic Wikipedia articles into four different classes (person (PER), organization (ORG), location (LOC), or miscellaneous (MISC)).", "labels": [], "entities": [{"text": "Document Classification task", "start_pos": 7, "end_pos": 35, "type": "TASK", "confidence": 0.9048247933387756}, {"text": "organization (ORG)", "start_pos": 130, "end_pos": 148, "type": "METRIC", "confidence": 0.7113624215126038}]}, {"text": "To do this, we relied on a neural network with a Long Short-Term Memory (LSTM) layer), which is fed from the word embeddings.", "labels": [], "entities": [{"text": "Long Short-Term Memory (LSTM) layer", "start_pos": 49, "end_pos": 84, "type": "METRIC", "confidence": 0.8201460540294647}]}, {"text": "The LSTM layer is followed by two fullyconnected layers, which in turn are followed by a softmax layer that predicts class-assignment probabilities.", "labels": [], "entities": []}, {"text": "The model was trained for 150 epochs on 8,000 articles, validated on 1,000 articles, and tested on another 1,000 articles.", "labels": [], "entities": []}, {"text": "In the NER task, the goal is to label each word in a given sequence using one of the following labels: PER, LOC, ORG, and MISC, which represent different Named Entity classes.", "labels": [], "entities": [{"text": "NER task", "start_pos": 7, "end_pos": 15, "type": "TASK", "confidence": 0.9304066002368927}, {"text": "PER", "start_pos": 103, "end_pos": 106, "type": "METRIC", "confidence": 0.9836784601211548}, {"text": "LOC", "start_pos": 108, "end_pos": 111, "type": "METRIC", "confidence": 0.7666789293289185}, {"text": "ORG", "start_pos": 113, "end_pos": 116, "type": "METRIC", "confidence": 0.8995862007141113}, {"text": "MISC", "start_pos": 122, "end_pos": 126, "type": "METRIC", "confidence": 0.9489665627479553}]}, {"text": "The same architecture as in the Document Classification task was used for this task as well.", "labels": [], "entities": [{"text": "Document Classification task", "start_pos": 32, "end_pos": 60, "type": "TASK", "confidence": 0.9045815666516622}]}, {"text": "The model was trained for 150 epochs on 3,852 sentences and tested on 963 sentence using Columbia's University Arabic Named Entity Recognition Corpus.", "labels": [], "entities": [{"text": "Columbia's University Arabic Named Entity Recognition Corpus", "start_pos": 89, "end_pos": 149, "type": "DATASET", "confidence": 0.682174876332283}]}, {"text": "We used an LSTM neural network for both tasks since they flexibly make use of contextual data and thus are com-monly used in NLP tasks such as Document Classification and NER.", "labels": [], "entities": [{"text": "Document Classification", "start_pos": 143, "end_pos": 166, "type": "TASK", "confidence": 0.8803716897964478}]}, {"text": "As can be seen in, the first three methods CBOW, Skip-gram and GloVe seem to perform relatively well for both the Document Classification task as well as the NER task with very comparable performance in terms of F-measure.", "labels": [], "entities": [{"text": "GloVe", "start_pos": 63, "end_pos": 68, "type": "METRIC", "confidence": 0.9400997757911682}, {"text": "Document Classification task", "start_pos": 114, "end_pos": 142, "type": "TASK", "confidence": 0.8789002696673075}, {"text": "NER task", "start_pos": 158, "end_pos": 166, "type": "TASK", "confidence": 0.8590241968631744}, {"text": "F-measure", "start_pos": 212, "end_pos": 221, "type": "METRIC", "confidence": 0.9658581018447876}]}, {"text": "They also clearly outperform Polyglot when it comes to both tasks as well.", "labels": [], "entities": [{"text": "Polyglot", "start_pos": 29, "end_pos": 37, "type": "DATASET", "confidence": 0.9051077961921692}]}], "tableCaptions": [{"text": " Table 1: Summary of the Arabic Word Analogy Benchmark", "labels": [], "entities": [{"text": "Summary of the Arabic Word Analogy Benchmark", "start_pos": 10, "end_pos": 54, "type": "TASK", "confidence": 0.6086634227207729}]}, {"text": " Table 2: Intrinsic evaluation of the word embeddings using different criteria", "labels": [], "entities": []}, {"text": " Table 3: F-measure for two NLP tasks", "labels": [], "entities": [{"text": "F-measure", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9942533373832703}]}]}