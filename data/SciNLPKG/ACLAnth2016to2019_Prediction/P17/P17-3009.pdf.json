{"title": [{"text": "Text-based Speaker Identification on Multiparty Dialogues Using Multi-document Convolutional Neural Networks", "labels": [], "entities": [{"text": "Text-based Speaker Identification", "start_pos": 0, "end_pos": 33, "type": "TASK", "confidence": 0.556478480497996}]}], "abstractContent": [{"text": "We propose a convolutional neural network model for text-based speaker identification on multiparty dialogues extracted from the TV show, Friends.", "labels": [], "entities": [{"text": "text-based speaker identification", "start_pos": 52, "end_pos": 85, "type": "TASK", "confidence": 0.6313694715499878}]}, {"text": "While most previous works on this task rely heavily on acoustic features, our approach attempts to identify speakers in dialogues using their speech patterns as captured by transcriptions to the TV show.", "labels": [], "entities": []}, {"text": "It has been shown that different individual speakers exhibit distinct idiolec-tal styles.", "labels": [], "entities": []}, {"text": "Several convolutional neural network models are developed to discriminate between differing speech patterns.", "labels": [], "entities": []}, {"text": "Our results confirm the promise of text-based approaches , with the best performing model showing an accuracy improvement of over 6% upon the baseline CNN model.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 101, "end_pos": 109, "type": "METRIC", "confidence": 0.9992770552635193}]}], "introductionContent": [{"text": "Speakers verbalize their thoughts in different ways through dialogues.", "labels": [], "entities": []}, {"text": "The differences in their expressions, be they striking or subtle, can serve as clues to the speakers' identities when they are withheld.", "labels": [], "entities": []}, {"text": "This paper investigates the possibility of identifying speakers in anonymous multiparty dialogues.", "labels": [], "entities": []}, {"text": "Impressive advancements have been achieved in the field of speech recognition prior to this paper ().", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 59, "end_pos": 77, "type": "TASK", "confidence": 0.8547084033489227}]}, {"text": "Research on dialogue systems has also involved considerable efforts on speaker identification, as it constitutes an important step in building a more natural and human-like system.", "labels": [], "entities": [{"text": "speaker identification", "start_pos": 71, "end_pos": 93, "type": "TASK", "confidence": 0.8243125379085541}]}, {"text": "Research in this area, however, has mostly been focused on acoustic features, which are absent in many situations (e.g., online chats, discussion forums, text messages).", "labels": [], "entities": []}, {"text": "In addition, it is commonly acknowledged that natural language texts themselves reflect the personalities of speakers, in addition to their semantic content (.", "labels": [], "entities": []}, {"text": "Various experiments have demonstrated significant differences in the linguistic patterns generated by different participants, suggesting the possibility to perform speaker identification with text-based data.", "labels": [], "entities": [{"text": "speaker identification", "start_pos": 164, "end_pos": 186, "type": "TASK", "confidence": 0.7558238804340363}]}, {"text": "An increasing number of large unstructured dialogue datasets are becoming available, although they comprise only the dialogue transcripts without speaker labels.", "labels": [], "entities": []}, {"text": "This paper attempts to identify the six main characters in the dialogues occurring in the first 8 seasons of the TV show, Friends.", "labels": [], "entities": []}, {"text": "The minor characters in the show are to be identified collectively as Other.", "labels": [], "entities": []}, {"text": "For each episode, we first withhold the identity of the speaker to each utterance in its transcript, and have prediction models label the speakers.", "labels": [], "entities": []}, {"text": "The accuracy and the F1 score of the labeling against the gold labels are used to measure the model performance.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 4, "end_pos": 12, "type": "METRIC", "confidence": 0.9996635913848877}, {"text": "F1 score", "start_pos": 21, "end_pos": 29, "type": "METRIC", "confidence": 0.9869208931922913}]}, {"text": "Our best model using multi-document convolutional neural network shows an accuracy of 31.06% and a macro average F1 score of 29.72, exhibiting promising performance on the text-based speaker identification task.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 74, "end_pos": 82, "type": "METRIC", "confidence": 0.9995458722114563}, {"text": "F1 score", "start_pos": 113, "end_pos": 121, "type": "METRIC", "confidence": 0.9579100608825684}, {"text": "text-based speaker identification task", "start_pos": 172, "end_pos": 210, "type": "TASK", "confidence": 0.7093231752514839}]}, {"text": "We believe that the application of text-based speaker identification is extensive since data collected from online chatting and social media contains no acoustic information.", "labels": [], "entities": [{"text": "speaker identification", "start_pos": 46, "end_pos": 68, "type": "TASK", "confidence": 0.6956905424594879}]}, {"text": "Building accurate speaker identification models will enable the prediction of speaker labels in such datasets.", "labels": [], "entities": [{"text": "speaker identification", "start_pos": 18, "end_pos": 40, "type": "TASK", "confidence": 0.834794670343399}]}], "datasetContent": [{"text": "In the KNN experiment, the transcript to season 8 of Friends is used as evaluation data, and the first 7 seasons as training data.", "labels": [], "entities": [{"text": "KNN experiment", "start_pos": 7, "end_pos": 21, "type": "DATASET", "confidence": 0.8757396936416626}]}, {"text": "In the rest of the experiments, season 8 is used as evaluation data, and season 7 is used as the development set.", "labels": [], "entities": []}, {"text": "The first 6 seasons are used as the training dataset.", "labels": [], "entities": []}, {"text": "In each experiment, the F1 scores for the speakers, the average F1 score for major speakers, the average F1 score for all speakers, and the accuracy are reported in In, the highest accuracy achieved by the KNN approach on the paper's film dialogue dataset was 30.39% , which is comparable to the best result of this paper.", "labels": [], "entities": [{"text": "F1", "start_pos": 24, "end_pos": 26, "type": "METRIC", "confidence": 0.9993188381195068}, {"text": "F1 score", "start_pos": 64, "end_pos": 72, "type": "METRIC", "confidence": 0.9788030683994293}, {"text": "F1 score", "start_pos": 105, "end_pos": 113, "type": "METRIC", "confidence": 0.9856261909008026}, {"text": "accuracy", "start_pos": 140, "end_pos": 148, "type": "METRIC", "confidence": 0.9996885061264038}, {"text": "accuracy", "start_pos": 181, "end_pos": 189, "type": "METRIC", "confidence": 0.997395396232605}, {"text": "film dialogue dataset", "start_pos": 234, "end_pos": 255, "type": "DATASET", "confidence": 0.6355815231800079}]}, {"text": "In contrast, the KNN approach did not perform well on the Friends dataset.", "labels": [], "entities": [{"text": "Friends dataset", "start_pos": 58, "end_pos": 73, "type": "DATASET", "confidence": 0.9864932000637054}]}, {"text": "Upon further examination of the KNN model's prediction process, we observe that the cosine similarities between any given utterance and its 15 nearest neighbors are consistently above 98%.", "labels": [], "entities": []}, {"text": "The speaker labels are not linearly separable due to the low dimensionality of the feature space.", "labels": [], "entities": []}, {"text": "The basic CNN model is able to outperform the baseline by almost 9% because the highly differing n-grams frequencies in the dataset enabled the model to distinguish between speakers.", "labels": [], "entities": []}, {"text": "It is also worth noting that when the surrounding utterances 52 Individual F1 Score: Model performance where the prediction labels are restricted to speakers present in each scene. are taken into account, identification accuracy increases significantly from that achieved by the simple CNN.", "labels": [], "entities": [{"text": "F1 Score", "start_pos": 75, "end_pos": 83, "type": "METRIC", "confidence": 0.9430243968963623}, {"text": "accuracy", "start_pos": 220, "end_pos": 228, "type": "METRIC", "confidence": 0.9728691577911377}]}, {"text": "With more contextual information, the model is able to identify speakers with higher accuracy, as individual speakers react differently in comparable situations.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 85, "end_pos": 93, "type": "METRIC", "confidence": 0.9983617663383484}]}, {"text": "The experiment on the utterance concatenation dataset yields a relatively high identification accuracy, corroborating our theory that the prediction model can better capture different speech patterns on longer documents.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 94, "end_pos": 102, "type": "METRIC", "confidence": 0.9341962933540344}]}, {"text": "When prediction labels are restricted to the speakers present in a scene, accuracy boosts of 10% and 12% are achieved on the two datasets, respectively.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 74, "end_pos": 82, "type": "METRIC", "confidence": 0.9992603659629822}]}, {"text": "shows the confusion matrix produced by the multi-document CNN, i.e., the best performing model.", "labels": [], "entities": []}, {"text": "The speakers for whom the model produces higher accuracies (Ross and Other) are also confused by the model more often than other speakers.", "labels": [], "entities": [{"text": "accuracies", "start_pos": 48, "end_pos": 58, "type": "METRIC", "confidence": 0.9836404919624329}]}, {"text": "The cause can be accounted for by the model's overzealousness in assigning these two labels to utterances due to their relatively large percentages in the training data.", "labels": [], "entities": []}, {"text": "In addition, Monica and Chandler are often confused with each other.", "labels": [], "entities": []}, {"text": "Due to their romantic relationship, it is possible that there is a convergence between their idiolectal styles.", "labels": [], "entities": []}, {"text": "On the other hand, the confusion rates between Phoebe and Rachel, and between Phoebe and Joey are both fairly low.", "labels": [], "entities": [{"text": "confusion rates", "start_pos": 23, "end_pos": 38, "type": "METRIC", "confidence": 0.9871823191642761}]}, {"text": "Such results confirm the observation that the frequency of interactions between speaker pairs correlates with the rate of confusion.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Dataset distribution by speakers. M: Monica, P: Phoebe, R 1 : Rachel, R 2 : Ross, J: Joey, C:  Chandler, O: Other. Non-main speakers (all the others), are collectively grouped as the Other speaker.", "labels": [], "entities": []}, {"text": " Table 3: Model performance. MF1: Average of F1 scores for major speakers, F1: Average of F1 scores  for all speakers, ACC: Accuracy", "labels": [], "entities": [{"text": "MF1", "start_pos": 29, "end_pos": 32, "type": "METRIC", "confidence": 0.8460600972175598}, {"text": "F1 scores", "start_pos": 45, "end_pos": 54, "type": "METRIC", "confidence": 0.9116448760032654}, {"text": "F1", "start_pos": 75, "end_pos": 77, "type": "METRIC", "confidence": 0.9984318614006042}, {"text": "Average of F1 scores", "start_pos": 79, "end_pos": 99, "type": "METRIC", "confidence": 0.7749217301607132}, {"text": "ACC", "start_pos": 119, "end_pos": 122, "type": "METRIC", "confidence": 0.9877322912216187}, {"text": "Accuracy", "start_pos": 124, "end_pos": 132, "type": "METRIC", "confidence": 0.9768312573432922}]}, {"text": " Table 4: Model performance where the prediction labels are restricted to speakers present in each scene.", "labels": [], "entities": []}, {"text": " Table 5: Confusion Matrix between speakers. S: true speaker, P: predicted speaker.", "labels": [], "entities": []}]}