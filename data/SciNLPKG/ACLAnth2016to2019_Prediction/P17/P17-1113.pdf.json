{"title": [{"text": "Joint Extraction of Entities and Relations Based on a Novel Tagging Scheme", "labels": [], "entities": []}], "abstractContent": [{"text": "Joint extraction of entities and relations is an important task in information extraction.", "labels": [], "entities": [{"text": "Joint extraction of entities and relations", "start_pos": 0, "end_pos": 42, "type": "TASK", "confidence": 0.8788373867670695}, {"text": "information extraction", "start_pos": 67, "end_pos": 89, "type": "TASK", "confidence": 0.9058493375778198}]}, {"text": "To tackle this problem, we firstly propose a novel tagging scheme that can convert the joint extraction task to a tagging problem.", "labels": [], "entities": [{"text": "joint extraction task", "start_pos": 87, "end_pos": 108, "type": "TASK", "confidence": 0.7881936033566793}]}, {"text": "Then, based on our tagging scheme, we study different end-to-end models to extract entities and their relations directly, without identifying entities and relations separately.", "labels": [], "entities": []}, {"text": "We conduct experiments on a public dataset produced by distant supervision method and the experimental results show that the tagging based methods are better than most of the existing pipelined and joint learning methods.", "labels": [], "entities": []}, {"text": "What's more, the end-to-end model proposed in this paper, achieves the best results on the public dataset.", "labels": [], "entities": []}], "introductionContent": [{"text": "Joint extraction of entities and relations is to detect entity mentions and recognize their semantic relations simultaneously from unstructured text, as shows.", "labels": [], "entities": []}, {"text": "Different from open information extraction (Open IE) () whose relation words are extracted from the given sentence, in this task, relation words are extracted from a predefined relation set which may not appear in the given sentence.", "labels": [], "entities": [{"text": "open information extraction (Open IE)", "start_pos": 15, "end_pos": 52, "type": "TASK", "confidence": 0.8001837730407715}]}, {"text": "It is an important issue in knowledge extraction and automatic construction of knowledge base.", "labels": [], "entities": [{"text": "knowledge extraction", "start_pos": 28, "end_pos": 48, "type": "TASK", "confidence": 0.8312273919582367}]}, {"text": "Traditional methods handle this task in a pipelined manner, i.e., extracting the entities () first and then recognizing their relations.", "labels": [], "entities": []}, {"text": "This separated framework makes the task easy to deal with, and each component can be more flexible.", "labels": [], "entities": []}, {"text": "But it neglects the relevance between these two sub-tasks and each subtask is an independent model.", "labels": [], "entities": []}, {"text": "The results of entity recognition may affect the performance of relation classification and lead to erroneous delivery ().", "labels": [], "entities": [{"text": "entity recognition", "start_pos": 15, "end_pos": 33, "type": "TASK", "confidence": 0.7490733861923218}, {"text": "relation classification", "start_pos": 64, "end_pos": 87, "type": "TASK", "confidence": 0.8543014526367188}]}, {"text": "Different from the pipelined methods, joint learning framework is to extract entities together with relations using a single model.", "labels": [], "entities": []}, {"text": "It can effectively integrate the information of entities and relations, and it has been shown to achieve better results in this task.", "labels": [], "entities": []}, {"text": "However, most existing joint methods are feature-based structured systems (.", "labels": [], "entities": []}, {"text": "They need complicated feature engineering and heavily rely on the other NLP toolkits, which might also lead to error propagation.", "labels": [], "entities": [{"text": "error propagation", "start_pos": 111, "end_pos": 128, "type": "TASK", "confidence": 0.6581071764230728}]}, {"text": "In order to reduce the manual work in feature extraction, recently,) presents a neural networkbased method for the end-to-end entities and relations extraction.", "labels": [], "entities": [{"text": "feature extraction", "start_pos": 38, "end_pos": 56, "type": "TASK", "confidence": 0.7356200963258743}, {"text": "relations extraction", "start_pos": 139, "end_pos": 159, "type": "TASK", "confidence": 0.7525618672370911}]}, {"text": "Although the joint models can represent both entities and relations with shared parameters in a single model, they also extract the entities and relations separately and produce redundant information.", "labels": [], "entities": []}, {"text": "For instance, the sentence in contains three entities: \"United States\", \"Trump\" and \"Apple Inc\".", "labels": [], "entities": []}, {"text": "But only \"United States\" and \"Trump\" hold a fix relation \"CountryPresident\".", "labels": [], "entities": []}, {"text": "Entity \"Apple Inc\" has no obvious relationship with the other entities in this sen-tence.", "labels": [], "entities": []}, {"text": "Hence, the extracted result from this sentence is {United States e1 , Country-President r , Trump e2 }, which called triplet here.", "labels": [], "entities": []}, {"text": "In this paper, we focus on the extraction of triplets that are composed of two entities and one relation between these two entities.", "labels": [], "entities": []}, {"text": "Therefore, we can model the triplets directly, rather than extracting the entities and relations separately.", "labels": [], "entities": []}, {"text": "Based on the motivations, we propose a tagging scheme accompanied with the end-to-end model to settle this problem.", "labels": [], "entities": []}, {"text": "We design a kind of novel tags which contain the information of entities and the relationships they hold.", "labels": [], "entities": []}, {"text": "Based on this tagging scheme, the joint extraction of entities and relations can be transformed into a tagging problem.", "labels": [], "entities": []}, {"text": "In this way, we can also easily use neural networks to model the task without complicated feature engineering.", "labels": [], "entities": []}, {"text": "Recently, end-to-end models based on LSTM have been successfully applied to various tagging tasks: Named Entity Recognition (, CCG Supertagging (, Chunking ( et al.", "labels": [], "entities": [{"text": "Named Entity Recognition", "start_pos": 99, "end_pos": 123, "type": "TASK", "confidence": 0.6158984303474426}]}, {"text": "LSTM is capable of learning long-term dependencies, which is beneficial to sequence modeling tasks.", "labels": [], "entities": [{"text": "sequence modeling tasks", "start_pos": 75, "end_pos": 98, "type": "TASK", "confidence": 0.8080887198448181}]}, {"text": "Therefore, based on our tagging scheme, we investigate different kinds of LSTM-based end-to-end models to jointly extract the entities and relations.", "labels": [], "entities": []}, {"text": "We also modify the decoding method by adding a biased loss to make it more suitable for our special tags.", "labels": [], "entities": []}, {"text": "The method we proposed is a supervised learning algorithm.", "labels": [], "entities": []}, {"text": "In reality, however, the process of manually labeling a training set with a large number of entity and relation is too expensive and error-prone.", "labels": [], "entities": []}, {"text": "Therefore, we conduct experiments on a public dataset 1 which is produced by distant supervision method) to validate our approach.", "labels": [], "entities": []}, {"text": "The experimental results show that our tagging scheme is effective in this task.", "labels": [], "entities": [{"text": "tagging", "start_pos": 39, "end_pos": 46, "type": "TASK", "confidence": 0.9661911725997925}]}, {"text": "In addition, our end-to-end model can achieve the best results on the public dataset.", "labels": [], "entities": []}, {"text": "The major contributions of this paper are: (1) A novel tagging scheme is proposed to jointly extract entities and relations, which can easily transform the extraction problem into a tagging task.", "labels": [], "entities": []}, {"text": "(2) Based on our tagging scheme, we study different kinds of end-to-end models to settle the problem.", "labels": [], "entities": []}, {"text": "The tagging-based methods are better than most of the existing pipelined and joint learning methods.", "labels": [], "entities": []}, {"text": "(3) Furthermore, we also develop an end-to-1 https://github.com/shanzhenren/CoType end model with biased loss function to suit for the novel tags.", "labels": [], "entities": []}, {"text": "It can enhance the association between related entities.", "labels": [], "entities": []}], "datasetContent": [{"text": "We report the results of different methods as shown in.", "labels": [], "entities": []}, {"text": "It can be seen that our method, LSTM-LSTM-Bias, outperforms all other methods in F1 score and achieves a 3% improvement in F 1 over the best method CoType (.", "labels": [], "entities": [{"text": "F1 score", "start_pos": 81, "end_pos": 89, "type": "METRIC", "confidence": 0.9803642928600311}, {"text": "F 1", "start_pos": 123, "end_pos": 126, "type": "METRIC", "confidence": 0.992659330368042}]}, {"text": "It shows the effectiveness of our proposed method.", "labels": [], "entities": []}, {"text": "Furthermore, from, we also can see that the jointly extracting methods are better than pipelined methods, and the tagging methods are better than most of the jointly extracting methods.", "labels": [], "entities": []}, {"text": "It also validates the validity of our tagging scheme for the task of jointly extracting entities and relations.", "labels": [], "entities": []}, {"text": "When compared with the traditional methods, the precisions of the end-to-end models are significantly improved.", "labels": [], "entities": [{"text": "precisions", "start_pos": 48, "end_pos": 58, "type": "METRIC", "confidence": 0.9990127086639404}]}, {"text": "But only LSTM-LSTM-Bias can be better to balance the precision and recall.", "labels": [], "entities": [{"text": "precision", "start_pos": 53, "end_pos": 62, "type": "METRIC", "confidence": 0.9997058510780334}, {"text": "recall", "start_pos": 67, "end_pos": 73, "type": "METRIC", "confidence": 0.9986982345581055}]}, {"text": "The reason maybe that these end-to-end models all use a Bi-LSTM encoding input sentence and different neural networks to decode the results.", "labels": [], "entities": []}, {"text": "The methods based on neural networks can well fit the data.", "labels": [], "entities": []}, {"text": "Therefore, they can learn the common features of the training set well and may lead to the lower expansibility.", "labels": [], "entities": []}, {"text": "We also find that the LSTM-LSTM: The predicted results of triplet's elements based on our tagging scheme.", "labels": [], "entities": []}, {"text": "model is better than LSTM-CRF model based on our tagging scheme.", "labels": [], "entities": []}, {"text": "Because, LSTM is capable of learning long-term dependencies and CRF) is good at capturing the joint probability of the entire sequence of labels.", "labels": [], "entities": []}, {"text": "The related tags may have along distance from each other.", "labels": [], "entities": []}, {"text": "Hence, LSTM decoding manner is a little better than CRF.", "labels": [], "entities": []}, {"text": "LSTM-LSTM-Bias adds a bias weight to enhance the effect of entity tags and weaken the effect of invalid tag.", "labels": [], "entities": []}, {"text": "Therefore, in this tagging scheme, our method can be better than the common LSTM-decoding methods.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: The predicted results of different methods on extracting both entities and their relations. The  first part (from row", "labels": [], "entities": []}, {"text": " Table 2: The predicted results of triplet's elements based on our tagging scheme.", "labels": [], "entities": []}, {"text": " Table 3: Output from different models. Standard S i represents the gold standard of sentence i. The  blue part is the correct result, and the red one is the wrong one. E1CF in case '3' is short for  E1 Company\u2212F ounder .", "labels": [], "entities": [{"text": "E1CF", "start_pos": 169, "end_pos": 173, "type": "DATASET", "confidence": 0.8660470843315125}, {"text": "E1 Company\u2212F ounder", "start_pos": 200, "end_pos": 219, "type": "DATASET", "confidence": 0.8544927716255188}]}]}