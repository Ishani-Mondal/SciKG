{"title": [{"text": "Adversarial Multi-task Learning for Text Classification", "labels": [], "entities": [{"text": "Text Classification", "start_pos": 36, "end_pos": 55, "type": "TASK", "confidence": 0.8128423392772675}]}], "abstractContent": [{"text": "Neural network models have shown their promising opportunities for multi-task learning, which focus on learning the shared layers to extract the common and task-invariant features.", "labels": [], "entities": []}, {"text": "However, inmost existing approaches, the extracted shared features are prone to be contaminated by task-specific features or the noise brought by other tasks.", "labels": [], "entities": []}, {"text": "In this paper, we propose an adversarial multi-task learning framework , alleviating the shared and private latent feature spaces from interfering with each other.", "labels": [], "entities": []}, {"text": "We conduct extensive experiments on 16 different text classification tasks, which demonstrates the benefits of our approach.", "labels": [], "entities": [{"text": "text classification tasks", "start_pos": 49, "end_pos": 74, "type": "TASK", "confidence": 0.8415435353914896}]}, {"text": "Besides, we show that the shared knowledge learned by our proposed model can be regarded as off-the-shelf knowledge and easily transferred to new tasks.", "labels": [], "entities": []}, {"text": "The datasets of all 16 tasks are publicly available at http://nlp.fudan.", "labels": [], "entities": []}], "introductionContent": [{"text": "Multi-task learning is an effective approach to improve the performance of a single task with the help of other related tasks.", "labels": [], "entities": [{"text": "Multi-task learning", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.7866361439228058}]}, {"text": "Recently, neuralbased models for multi-task learning have become very popular, ranging from computer vision () to natural language processing), since they provide a convenient way of combining information from multiple tasks.", "labels": [], "entities": []}, {"text": "However, most existing work on multi-task learning ( attempts to divide the features of different tasks into private and shared spaces, merely based on whether parameters of Figure 1: Two sharing schemes for task A and task B.", "labels": [], "entities": []}, {"text": "The overlap between two black circles denotes shared space.", "labels": [], "entities": []}, {"text": "The blue triangles and boxes represent the task-specific features while the red circles denote the features which can be shared.", "labels": [], "entities": []}, {"text": "some components should be shared.", "labels": [], "entities": []}, {"text": "As shown in-(a), the general shared-private model introduces two feature spaces for any task: one is used to store task-dependent features, the other is used to capture shared features.", "labels": [], "entities": []}, {"text": "The major limitation of this framework is that the shared feature space could contain some unnecessary taskspecific features, while some sharable features could also be mixed in private space, suffering from feature redundancy.", "labels": [], "entities": []}, {"text": "Taking the following two sentences as examples, which are extracted from two different sentiment classification tasks: Movie reviews and Baby products reviews.", "labels": [], "entities": [{"text": "sentiment classification", "start_pos": 87, "end_pos": 111, "type": "TASK", "confidence": 0.7548060417175293}]}, {"text": "The infantile cart is simple and easy to use.", "labels": [], "entities": []}, {"text": "This kind of humour is infantile and boring.", "labels": [], "entities": []}, {"text": "The word \"infantile\" indicates negative sentiment in Movie task while it is neutral in Baby task.", "labels": [], "entities": []}, {"text": "However, the general shared-private model could place the task-specific word \"infantile\" in a shared space, leaving potential hazards for other tasks.", "labels": [], "entities": []}, {"text": "Additionally, the capacity of shared space could also be wasted by some unnecessary features.", "labels": [], "entities": []}, {"text": "To address this problem, in this paper we propose an adversarial multi-task framework, in which the shared and private feature spaces are in-1 herently disjoint by introducing orthogonality constraints.", "labels": [], "entities": []}, {"text": "Specifically, we design a generic sharedprivate learning framework to model the text sequence.", "labels": [], "entities": []}, {"text": "To prevent the shared and private latent feature spaces from interfering with each other, we introduce two strategies: adversarial training and orthogonality constraints.", "labels": [], "entities": []}, {"text": "The adversarial training is used to ensure that the shared feature space simply contains common and task-invariant information, while the orthogonality constraint is used to eliminate redundant features from the private and shared spaces.", "labels": [], "entities": []}, {"text": "The contributions of this paper can be summarized as follows.", "labels": [], "entities": []}, {"text": "1. Proposed model divides the task-specific and shared space in a more precise way, rather than roughly sharing parameters.", "labels": [], "entities": []}, {"text": "2. We extend the original binary adversarial training to multi-class, which not only enables multiple tasks to be jointly trained, but allows us to utilize unlabeled data.", "labels": [], "entities": []}, {"text": "3. We can condense the shared knowledge among multiple tasks into an off-the-shelf neural layer, which can be easily transferred to new tasks.", "labels": [], "entities": []}], "datasetContent": [{"text": "To make an extensive evaluation, we collect 16 different datasets from several popular review corpora.", "labels": [], "entities": []}, {"text": "The first 14 datasets are product reviews, which contain Amazon product reviews from different domains, such as Books, DVDs, Electronics, ect.", "labels": [], "entities": [{"text": "Books", "start_pos": 112, "end_pos": 117, "type": "DATASET", "confidence": 0.95372074842453}]}, {"text": "The goal is to classify a product review as either positive or negative.", "labels": [], "entities": []}, {"text": "These datasets are collected based on the raw data 1 provided by . Specifically, we extract the sentences and corresponding labels from the unprocessed original data 2 . The only preprocessing operation of these sentences is tokenized using the Stanford tokenizer 3 . The remaining two datasets are about movie reviews.", "labels": [], "entities": []}, {"text": "The IMDB dataset consists of movie reviews with binary classes).", "labels": [], "entities": [{"text": "IMDB dataset", "start_pos": 4, "end_pos": 16, "type": "DATASET", "confidence": 0.9599072635173798}]}, {"text": "One key aspect of this dataset is that each movie review has several sentences.", "labels": [], "entities": []}, {"text": "The MR dataset also consists of movie reviews from rotten tomato website with two classes 5 (Pang and).", "labels": [], "entities": [{"text": "MR", "start_pos": 4, "end_pos": 6, "type": "METRIC", "confidence": 0.9731412529945374}]}, {"text": "All the datasets in each task are partitioned randomly into training set, development set and testing set with the proportion of 70%, 20% and 10% respectively.", "labels": [], "entities": []}, {"text": "The detailed statistics about all the datasets are listed in.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Statistics of the 16 datasets. The columns  2-5 denote the number of samples in training, de- velopment, test and unlabeled sets. The last two  columns represent the average length and vocabu- lary size of corresponding dataset.", "labels": [], "entities": [{"text": "vocabu- lary size", "start_pos": 195, "end_pos": 212, "type": "METRIC", "confidence": 0.8864878267049789}]}, {"text": " Table 2: Error rates of our models on 16 datasets against typical baselines. The numbers in brackets  represent the improvements relative to the average performance (Avg.) of three single task baselines.", "labels": [], "entities": [{"text": "Error", "start_pos": 10, "end_pos": 15, "type": "METRIC", "confidence": 0.9811861515045166}, {"text": "Avg.", "start_pos": 167, "end_pos": 171, "type": "METRIC", "confidence": 0.9691126346588135}]}, {"text": " Table 3: Error rates of our models on 16 datasets against vanilla multi-task learning. \u03c6 (Books) means  that we transfer the knowledge of the other 15 tasks to the target task Books.", "labels": [], "entities": [{"text": "Error", "start_pos": 10, "end_pos": 15, "type": "METRIC", "confidence": 0.9845603704452515}, {"text": "\u03c6", "start_pos": 88, "end_pos": 89, "type": "METRIC", "confidence": 0.9888638257980347}]}]}