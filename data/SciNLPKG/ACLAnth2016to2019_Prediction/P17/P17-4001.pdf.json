{"title": [{"text": "Annotating tense, mood and voice for", "labels": [], "entities": []}], "abstractContent": [{"text": "We present the first open-source tool for annotating morphosyntactic tense, mood and voice for English, French and Ger-man verbal complexes.", "labels": [], "entities": []}, {"text": "The annotation is based on a set of language-specific rules, which are applied on dependency trees and leverage information about lemmas, morphological properties and POS-tags of the verbs.", "labels": [], "entities": []}, {"text": "Our tool has an average accuracy of about 76%.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 24, "end_pos": 32, "type": "METRIC", "confidence": 0.9988986253738403}]}, {"text": "The tense, mood and voice features are useful both as features in computational modeling and for corpus-linguistic research.", "labels": [], "entities": []}], "introductionContent": [{"text": "Natural language employs, among other devices such as temporal adverbials, tense and aspect to locate situations in time and to describe their temporal structure.", "labels": [], "entities": []}, {"text": "The tool presented here addresses the automatic annotation of morphosyntactic tense, i.e., the tense-aspect combinations, expressed in the morphology and syntax of verbal complexes (VC).", "labels": [], "entities": []}, {"text": "VCs are sequences of verbal tokens within a verbal phrase.", "labels": [], "entities": []}, {"text": "We address German, French and English, in which the morphology and syntax also includes information on mood and voice.", "labels": [], "entities": []}, {"text": "Morphosyntactic tenses do not always correspond to semantic tense.", "labels": [], "entities": []}, {"text": "For example, the morphosyntactic tense of the English sentence \"He is leaving at noon.\" is present progressive, while the semantic tense is future.", "labels": [], "entities": []}, {"text": "In the remainder of this paper, we use the term tense to refer to the morphological tense and aspect information encoded infinite verbal complexes.", "labels": [], "entities": []}, {"text": "Corpus-linguistic research, as well as automatic modeling of mono-and cross-lingual use of tense, mood and voice will strongly profit from a reliable automatic method for identifying these clausal features.", "labels": [], "entities": []}, {"text": "They may, for instance, be used to classify texts with respect to the epoch or region in which they have been produced, or for assigning texts to a specific author.", "labels": [], "entities": []}, {"text": "Moreover, in crosslingual research, tense, mood, and voice have been used to model the translation of tense between different language pairs).", "labels": [], "entities": [{"text": "translation of tense", "start_pos": 87, "end_pos": 107, "type": "TASK", "confidence": 0.8817389806111654}]}, {"text": "Identifying the morphosyntactic tense is also a necessary prerequisite for identifying the semantic tense in synthetic languages such as English, French or German.", "labels": [], "entities": []}, {"text": "The extracted tense-mood-voice (TMV) features may also be useful for training models in computational linguistics, e.g., for modeling of temporal relations.", "labels": [], "entities": []}, {"text": "As illustrated by the examples in, relevant information for determining TMV is given by syntactic dependencies and partially by partof-speech (POS) tags output by analyzers such as Mate.", "labels": [], "entities": [{"text": "TMV", "start_pos": 72, "end_pos": 75, "type": "TASK", "confidence": 0.6921148896217346}]}, {"text": "However, the parser's output is not sufficient for determining TMV features; morphological features and lexical information needs to betaken into account as well.", "labels": [], "entities": []}, {"text": "Learning TMV features from an annotated corpus would bean alternative; however, to the best of our knowledge, no such large-scale corpora exist.", "labels": [], "entities": []}, {"text": "A sentence may contain more than one VC, and the tokens belonging to a VC are not always contiguous in the sentence (see VCs A and B in the English sentence in).", "labels": [], "entities": []}, {"text": "Ina first step, our tool identifies the tokens that belong to a VC by analysing their POS tags as well as the syntactic dependency parse of the sentence.", "labels": [], "entities": []}, {"text": "Next, TMV values are assigned according to language specific hand-crafted sets of rules, which have been developed based on extensive data analysis.", "labels": [], "entities": []}, {"text": "(2) Extraction of verbal complexes based on dependencies; (3) Assignment of TMV features based on POS sequences, morphological features and lexical rules: A will be examined formation about the VCs into a TSV file which can easily be used for further processing.", "labels": [], "entities": []}, {"text": "To the best of our knowledge, our system represents the first open-source 2 system which implements a reliable set of derivation rules for annotating tense, mood and voice for English, French and German.", "labels": [], "entities": []}, {"text": "Furthermore, the online demo 3 version of the tool allows for fast text processing without installing the tool.", "labels": [], "entities": [{"text": "text processing", "start_pos": 67, "end_pos": 82, "type": "TASK", "confidence": 0.7332549095153809}]}], "datasetContent": [{"text": "We manually evaluate annotations for 157 German VCs, 151 English Vcs and 137 French VCs extracted from a set of randomly chosen sentences from Europarl (.", "labels": [], "entities": [{"text": "Europarl", "start_pos": 143, "end_pos": 151, "type": "DATASET", "confidence": 0.9785131216049194}]}, {"text": "The results are shown in  For French, the overall acurracy is 75%, while the accuracy of German and English annotations is 76%.", "labels": [], "entities": [{"text": "acurracy", "start_pos": 50, "end_pos": 58, "type": "METRIC", "confidence": 0.9991697072982788}, {"text": "accuracy", "start_pos": 77, "end_pos": 85, "type": "METRIC", "confidence": 0.9996427297592163}]}, {"text": "Based on the manually annotated sample, we estimate that 23/59/85% (for EN/DE/FR) of the erroneous annotations are due to parsing errors.", "labels": [], "entities": [{"text": "EN/DE/FR)", "start_pos": 72, "end_pos": 81, "type": "METRIC", "confidence": 0.543318564693133}]}, {"text": "For instance, in the case of English, the VC extraction process sometimes adds gerunds to the VC and interprets them as a present participle.", "labels": [], "entities": [{"text": "VC extraction", "start_pos": 42, "end_pos": 55, "type": "TASK", "confidence": 0.8219814300537109}]}, {"text": "Similarly, for French, a past participle is added, which erroneously causes the voice assignment to be passive.", "labels": [], "entities": []}, {"text": "Contrary to German and English, French has higher mood accuracy, since mood is largely encoded unambiguously in the verb morphology.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 55, "end_pos": 63, "type": "METRIC", "confidence": 0.947073221206665}]}, {"text": "For German, false or missing morphological annotation of the finite verbs causes some errors, and there are cases not covered by our rules for identifying stative passive.", "labels": [], "entities": []}, {"text": "Our rule sets have been developed based on extensive data analysis.", "labels": [], "entities": []}, {"text": "This evaluation presents a sent verb main num id has climbed climbed yes presPerf indicative active no no 2 4,5 has crossed crossed yes presPerf indicative active no no 2 13,14 can 't increase increase yes present indicative active yes no: TSV output of the annotation tool for two English sentences: \"Since then, the index has climbed above 10,000.", "labels": [], "entities": []}, {"text": "Now that gold has crossed the magic $1,000 barrier, why can't it increase ten-fold, too?\" snapshot of the tool's performance.", "labels": [], "entities": []}, {"text": "The findings of this analysis will lead to improvement of the rules' precision in future development iterations.", "labels": [], "entities": [{"text": "precision", "start_pos": 69, "end_pos": 78, "type": "METRIC", "confidence": 0.9985252022743225}]}], "tableCaptions": [{"text": " Table 5: Accuracy of TMV features according to  manual evaluation.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9952383041381836}]}]}