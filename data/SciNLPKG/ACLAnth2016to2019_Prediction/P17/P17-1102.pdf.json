{"title": [{"text": "PositionRank: An Unsupervised Approach to Keyphrase Extraction from Scholarly Documents", "labels": [], "entities": [{"text": "Keyphrase Extraction from Scholarly Documents", "start_pos": 42, "end_pos": 87, "type": "TASK", "confidence": 0.8149882912635803}]}], "abstractContent": [{"text": "The large and growing amounts of online scholarly data present both challenges and opportunities to enhance knowledge discovery.", "labels": [], "entities": [{"text": "knowledge discovery", "start_pos": 108, "end_pos": 127, "type": "TASK", "confidence": 0.7139742970466614}]}, {"text": "One such challenge is to automatically extract a small set of keyphrases from a document that can accurately describe the document's content and can facilitate fast information processing.", "labels": [], "entities": []}, {"text": "In this paper, we propose PositionRank, an unsupervised model for keyphrase extraction from scholarly documents that incorporates information from all positions of a word's occurrences into a biased PageR-ank.", "labels": [], "entities": [{"text": "keyphrase extraction from scholarly documents", "start_pos": 66, "end_pos": 111, "type": "TASK", "confidence": 0.8562406063079834}]}, {"text": "Our model obtains remarkable improvements in performance over PageR-ank models that do not take into account word positions as well as over strong base-lines for this task.", "labels": [], "entities": []}, {"text": "Specifically, on several datasets of research papers, PositionRank achieves improvements as high as 29.09%.", "labels": [], "entities": []}], "introductionContent": [{"text": "The current Scholarly Web contains many millions of scientific documents.", "labels": [], "entities": []}, {"text": "For example, Google Scholar is estimated to have more than 100 million documents.", "labels": [], "entities": [{"text": "Google Scholar", "start_pos": 13, "end_pos": 27, "type": "DATASET", "confidence": 0.8661533296108246}]}, {"text": "On one hand, these rapidly-growing scholarly document collections offer benefits for knowledge discovery, and on the other hand, finding useful information has become very challenging.", "labels": [], "entities": [{"text": "knowledge discovery", "start_pos": 85, "end_pos": 104, "type": "TASK", "confidence": 0.7991340458393097}]}, {"text": "Keyphrases associated with a document typically provide a high-level topic description of the document and can allow for efficient information processing.", "labels": [], "entities": []}, {"text": "In addition, keyphrases are shown to be rich sources of information in many natural language processing and information retrieval tasks such as scientific paper summarization, classification, recommendation, clustering, and search ().", "labels": [], "entities": [{"text": "scientific paper summarization", "start_pos": 144, "end_pos": 174, "type": "TASK", "confidence": 0.5768313705921173}]}, {"text": "Due to their importance, many approaches to keyphrase extraction have been proposed in the literature along two lines of research: supervised and unsupervised).", "labels": [], "entities": [{"text": "keyphrase extraction", "start_pos": 44, "end_pos": 64, "type": "TASK", "confidence": 0.8610235154628754}]}, {"text": "In the supervised line of research, keyphrase extraction is formulated as a binary classification problem, where candidate phrases are classified as either positive (i.e., keyphrases) or negative (i.e., non-keyphrases).", "labels": [], "entities": [{"text": "keyphrase extraction", "start_pos": 36, "end_pos": 56, "type": "TASK", "confidence": 0.8777228593826294}]}, {"text": "Various feature sets and classification algorithms yield different extraction systems.", "labels": [], "entities": []}, {"text": "For example, Frank et al.", "labels": [], "entities": []}, {"text": "(1999) developed a system that extracts two features for each candidate phrase, i.e., the tf-idf of the phrase and its distance from the beginning of the target document, and uses them as input to Na\u00a8\u0131veNa\u00a8\u0131ve Bayes classifiers.", "labels": [], "entities": []}, {"text": "Although supervised approaches typically perform better than unsupervised approaches, the requirement for large human-annotated corpora for each field of study has led to significant attention towards the design of unsupervised approaches.", "labels": [], "entities": []}, {"text": "In the unsupervised line of research, keyphrase extraction is formulated as a ranking problem with graph-based ranking techniques being considered state-of-the-art ().", "labels": [], "entities": [{"text": "keyphrase extraction", "start_pos": 38, "end_pos": 58, "type": "TASK", "confidence": 0.9210532605648041}]}, {"text": "These graph-based techniques construct a word graph from each target document, such that nodes correspond to words and edges correspond to word association patterns.", "labels": [], "entities": []}, {"text": "Nodes are then ranked using graph centrality measures such as PageRank ( or HITS (, and the top ranked phrases are returned as keyphrases.", "labels": [], "entities": []}, {"text": "Since their introduction, many graph-based extensions have been proposed, which aim at modeling various types of information.", "labels": [], "entities": []}, {"text": "For example, proposed a model that incorporates a local neighborhood of the target document corresponding to its textually-similar documents, computed using the cosine similarity between the tf-idf vectors of documents.", "labels": [], "entities": []}, {"text": "assumed a mixture of topics over documents and proposed to use topic models to decompose these topics in order to select keyphrases from all major topics.", "labels": [], "entities": []}, {"text": "Keyphrases are then ranked by aggregating the topic-specific scores obtained from several topicbiased PageRanks.", "labels": [], "entities": []}, {"text": "We posit that other information can be leveraged that has the potential to improve unsupervised keyphrase extraction.", "labels": [], "entities": [{"text": "keyphrase extraction", "start_pos": 96, "end_pos": 116, "type": "TASK", "confidence": 0.7757447957992554}]}, {"text": "For example, in a scholarly domain, keyphrases generally occur on positions very close to the beginning of a document and occur frequently.", "labels": [], "entities": []}, {"text": "shows an anecdotal example illustrating this behavior using the 2010 best paper award winner in the World Wide Web conference.", "labels": [], "entities": [{"text": "World Wide Web conference", "start_pos": 100, "end_pos": 125, "type": "DATASET", "confidence": 0.6739019602537155}]}, {"text": "The author input keyphrases are marked with red bold in the figure.", "labels": [], "entities": []}, {"text": "Notice in this example the high frequency of the keyphrase \"Markov chain\" that occurs very early in the document (even from its title).", "labels": [], "entities": []}, {"text": "Hence, can we design an effective unsupervised approach to keyphrase extraction by jointly exploiting words' position information and their frequency in documents?", "labels": [], "entities": [{"text": "keyphrase extraction", "start_pos": 59, "end_pos": 79, "type": "TASK", "confidence": 0.8132826089859009}]}, {"text": "We specifically address this question using research papers as a case study.", "labels": [], "entities": []}, {"text": "The result of this extraction task will aid indexing of documents in digital libraries, and hence, will lead to improved organization, search, retrieval, and recommendation of scientific documents.", "labels": [], "entities": [{"text": "indexing of documents", "start_pos": 44, "end_pos": 65, "type": "TASK", "confidence": 0.8851408759752909}]}, {"text": "The importance of keyphrase extraction from research papers is also emphasized by the SemEval Shared Tasks on this topic from 2017.", "labels": [], "entities": [{"text": "keyphrase extraction from research papers", "start_pos": 18, "end_pos": 59, "type": "TASK", "confidence": 0.8518161535263061}]}, {"text": "Our contributions are as follows: \u2022 We propose an unsupervised graph-based model, called PositionRank, that incorporates information from all positions of a word's occurrences into a biased PageRank to score keywords that are later used to score and rank keyphrases in research papers.", "labels": [], "entities": []}, {"text": "\u2022 We show that PositionRank that aggregates information from all positions of a word's occurrences performs better than a model that uses only the first position of a word.", "labels": [], "entities": []}, {"text": "\u2022 We experimentally evaluate PositionRank on three datasets of research papers and show statistically significant improvements over PageRank-based models that do not take into account word positions, as well as over strong baselines for keyphrase extraction.", "labels": [], "entities": [{"text": "keyphrase extraction", "start_pos": 237, "end_pos": 257, "type": "TASK", "confidence": 0.7297060042619705}]}, {"text": "The rest of the paper is organized as follows.", "labels": [], "entities": []}, {"text": "We summarize related work in the next section.", "labels": [], "entities": []}, {"text": "PositionRank is described in Section 3.", "labels": [], "entities": []}, {"text": "We then present the datasets of research papers, and our experiments and results in Section 4.", "labels": [], "entities": []}, {"text": "Finally, we conclude the paper in Section 5.", "labels": [], "entities": []}], "datasetContent": [{"text": "In order to evaluate the performance of PositionRank, we carried out experiments on three datasets.", "labels": [], "entities": []}, {"text": "The first and second datasets were made available by.", "labels": [], "entities": []}, {"text": "These datasets are compiled from the CiteSeerX digital library ( and consist of research papers from various disciplines.", "labels": [], "entities": [{"text": "CiteSeerX digital library", "start_pos": 37, "end_pos": 62, "type": "DATASET", "confidence": 0.9264159202575684}]}, {"text": "In experiments, we use the title and abstract of each paper to extract keyphrases.", "labels": [], "entities": []}, {"text": "The author-input keyphrases are used as gold-standard for evaluation.", "labels": [], "entities": []}, {"text": "All three datasets are summarized in, which shows the number of papers in each dataset, the total number of keyphrases (Kp), the average number of keyphrases per document (AvgKp), and a brief insight into the length and number of available keyphrases.", "labels": [], "entities": [{"text": "total number of keyphrases (Kp)", "start_pos": 92, "end_pos": 123, "type": "METRIC", "confidence": 0.6151128028120313}, {"text": "AvgKp)", "start_pos": 172, "end_pos": 178, "type": "METRIC", "confidence": 0.9220252335071564}]}, {"text": "We use mean reciprocal rank (MRR) curves to illustrate our experimental findings.", "labels": [], "entities": [{"text": "mean reciprocal rank (MRR)", "start_pos": 7, "end_pos": 33, "type": "METRIC", "confidence": 0.8816012342770895}]}, {"text": "MRR gives the averaged ranking of the first correct prediction and is defined as: where Dis the collection of documents and rd is the rank at which the first correct keyphrase of document d was found.", "labels": [], "entities": [{"text": "MRR", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.9057698249816895}]}, {"text": "We also summarize the results in terms of Precision, Recall, and F1-score in a table to contrast PositionRank with previous models since these metrics are widely used in previous works).", "labels": [], "entities": [{"text": "Precision", "start_pos": 42, "end_pos": 51, "type": "METRIC", "confidence": 0.9991139769554138}, {"text": "Recall", "start_pos": 53, "end_pos": 59, "type": "METRIC", "confidence": 0.9910160303115845}, {"text": "F1-score", "start_pos": 65, "end_pos": 73, "type": "METRIC", "confidence": 0.9993372559547424}]}, {"text": "To compute \"performance@k\" (such as MRR@k), we examine the top-k predictions (with k ranging from 1 to 10).", "labels": [], "entities": [{"text": "MRR", "start_pos": 36, "end_pos": 39, "type": "METRIC", "confidence": 0.7887396216392517}]}, {"text": "We use average k to refer to the average number of keyphrases fora particular dataset as listed in.", "labels": [], "entities": []}, {"text": "For example, average k = 5 for the WWW dataset.", "labels": [], "entities": [{"text": "WWW dataset", "start_pos": 35, "end_pos": 46, "type": "DATASET", "confidence": 0.9851844906806946}]}, {"text": "For comparison purposes, we used Porter Stemmer to reduce both predicted and gold keyphrases to abase form.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: A summary of our datasets.", "labels": [], "entities": []}, {"text": " Table 2: PositionRank against baselines in terms of Precision, Recall and F1-score. Best results are  shown in bold blue.", "labels": [], "entities": [{"text": "Precision", "start_pos": 53, "end_pos": 62, "type": "METRIC", "confidence": 0.9994934797286987}, {"text": "Recall", "start_pos": 64, "end_pos": 70, "type": "METRIC", "confidence": 0.9960007071495056}, {"text": "F1-score", "start_pos": 75, "end_pos": 83, "type": "METRIC", "confidence": 0.9992477893829346}]}]}