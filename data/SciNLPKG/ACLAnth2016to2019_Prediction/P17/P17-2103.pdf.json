{"title": [{"text": "Recognizing Counterfactual Thinking in Social Media Texts", "labels": [], "entities": [{"text": "Recognizing Counterfactual Thinking in Social Media Texts", "start_pos": 0, "end_pos": 57, "type": "TASK", "confidence": 0.8787595629692078}]}], "abstractContent": [{"text": "Counterfactual statements, describing events that did not occur and their con-sequents, have been studied in areas including problem-solving, affect management , and behavior regulation.", "labels": [], "entities": [{"text": "affect management", "start_pos": 142, "end_pos": 159, "type": "TASK", "confidence": 0.7371622323989868}, {"text": "behavior regulation", "start_pos": 166, "end_pos": 185, "type": "TASK", "confidence": 0.7128712832927704}]}, {"text": "People with more counterfactual thinking tend to perceive life events as more personally meaningful.", "labels": [], "entities": []}, {"text": "Nevertheless, counterfactuals have not been studied in computational linguistics.", "labels": [], "entities": []}, {"text": "We create a counterfactual tweet dataset and explore approaches for detecting counterfactuals using rule-based and supervised statistical approaches.", "labels": [], "entities": []}, {"text": "A combined rule-based and statistical approach yielded the best results (F1 = 0.77) outperforming either approach used alone.", "labels": [], "entities": [{"text": "F1", "start_pos": 73, "end_pos": 75, "type": "METRIC", "confidence": 0.9995810389518738}]}], "introductionContent": [{"text": "Counterfactuals describe events that did not occur, and what would have happened (or not happened), had the event occurred (e.g., \"If I hadn't broken my arm, I never would have met her.\").", "labels": [], "entities": []}, {"text": "More precisely, counterfactual conditionals have the form \"If it had been the case that A (or not A), it would have been the case that B (or not B).\"", "labels": [], "entities": []}, {"text": "Counterfactuals have been studied in many different domains.", "labels": [], "entities": []}, {"text": "Logicians and philosophers focus on literally logical relations between the antecedent and consequent of counterfactual forms and the outcomes.", "labels": [], "entities": []}, {"text": "In contrast, political scientists usually conduct counterfactual thought experiments for hypothetical tests on historical events, policies, or other aspects of a society and assess them.", "labels": [], "entities": []}, {"text": "Counterfactual thoughts are defined, especially in psychology, as mental representations of alternatives to past events, actions, or states.", "labels": [], "entities": []}, {"text": "Their use has been explored for correlations with many different demographics (age, gender) and psychological variables (depression, religiosity) ().", "labels": [], "entities": []}, {"text": "Counterfactual thinking has been linked to perceiving life events as more meaningful, fated, and even as influenced by the divine (, as well as with problemsolving, because imagining alternate outcomes can easily bring to mind the steps needed for improvement.", "labels": [], "entities": [{"text": "Counterfactual thinking", "start_pos": 0, "end_pos": 23, "type": "TASK", "confidence": 0.8684641420841217}]}, {"text": "It has also been shown to be associated with affect management, particularly when imagining realities that are worse than what actually happened Despite the extensive research on counterfactual thinking, counterfactual language forms have not been studied in computational linguistics.", "labels": [], "entities": [{"text": "affect management", "start_pos": 45, "end_pos": 62, "type": "TASK", "confidence": 0.7221865206956863}]}, {"text": "Language-based models to recognize counterfactual thinking in social media would potentially allow for psychological analysis on users based on their everyday language, avoiding the high expense of capturing counterfactual thinking at a large scale using traditional psychological assessments.", "labels": [], "entities": []}, {"text": "Therefore, in this paper, we build a languagebased model to recognize counterfactual forms in social media texts of Twitter and Facebook.", "labels": [], "entities": []}, {"text": "There are many challenges for this task.", "labels": [], "entities": []}, {"text": "First, counterfactual statements have a low base rate; we found only 2% of status updates on Facebook and 1% of tweets contain counterfactual statements.", "labels": [], "entities": [{"text": "base rate", "start_pos": 44, "end_pos": 53, "type": "METRIC", "confidence": 0.9842121601104736}]}, {"text": "Secondly, counterfactual statements can take on many forms in natural language.", "labels": [], "entities": []}, {"text": "For example, they mayor may not use explicit if-or then-clauses (e.g, consider \"If I had not met him then I would be better off\" versus \"I wish I had not met him\").", "labels": [], "entities": []}, {"text": "The low base rate and high variability of natural language counterfactuals in social media texts make them difficult to recognize using simple linguistic or statistical features.", "labels": [], "entities": [{"text": "base rate", "start_pos": 8, "end_pos": 17, "type": "METRIC", "confidence": 0.9851329624652863}]}, {"text": "We address these challenges by using a combined rule-based and statistical approach.", "labels": [], "entities": []}, {"text": "Key to our success is defining seven sub-types of counterfactuals, allowing better coverage of rarer sub-types.", "labels": [], "entities": []}], "datasetContent": [{"text": "As discussed, counterfactuals are not easily identified by rules or specific words.", "labels": [], "entities": []}, {"text": "Given their low base rate and multiplicity of forms, traditional machine learning approaches trained on a random tweet sample tend to label all tweets as the most frequent class (non-counterfactual).", "labels": [], "entities": []}, {"text": "Use of a counterfactual-enriched training set increases the performance, but still gives a low F1 on the imbalanced test set.", "labels": [], "entities": [{"text": "F1", "start_pos": 95, "end_pos": 97, "type": "METRIC", "confidence": 0.999114453792572}]}, {"text": "Thus, in order to make the classifier robust to the imbalanced dataset, we designed a rule-based model with counterfactual forms, which resulted in significantly higher F1 than statistical model.", "labels": [], "entities": [{"text": "F1", "start_pos": 169, "end_pos": 171, "type": "METRIC", "confidence": 0.9994994401931763}]}, {"text": "Moreover, the rule-based model captures positive samples of all possible forms which might not exist in the training set.", "labels": [], "entities": []}, {"text": "A combined approach gives the best result.", "labels": [], "entities": []}, {"text": "As shows, our whole pipeline ('CF Parser' in) obtained the best overall performance with the combination of both approaches.", "labels": [], "entities": [{"text": "CF Parser", "start_pos": 31, "end_pos": 40, "type": "DATASET", "confidence": 0.7505195140838623}]}, {"text": "For Wish Verb form prediction gets a big performance boost from the statistical model because of highly frequent false positives which have counterfactual-like forms such as birthday wishes or new year's day wishes.", "labels": [], "entities": [{"text": "Wish Verb form prediction", "start_pos": 4, "end_pos": 29, "type": "TASK", "confidence": 0.61855099350214}]}, {"text": "Among samples classified as Wish Verb form the counterfactual prediction F1 increased from 0.82 to 0.90 after the final prediction by the statistical model.", "labels": [], "entities": [{"text": "F1", "start_pos": 73, "end_pos": 75, "type": "METRIC", "confidence": 0.9106593728065491}]}, {"text": "Finally, we conducted an ablation test to analyze how each process of the pipeline affects the overall performance of the classifier.", "labels": [], "entities": []}, {"text": "The argument detection was less effective (F1 0.01 drop) than we expected due to the relatively simple and concise structure of tweets in general (Args in).", "labels": [], "entities": [{"text": "argument detection", "start_pos": 4, "end_pos": 22, "type": "TASK", "confidence": 0.8358266353607178}, {"text": "F1 0.01 drop", "start_pos": 43, "end_pos": 55, "type": "METRIC", "confidence": 0.9715865651766459}, {"text": "Args", "start_pos": 147, "end_pos": 151, "type": "METRIC", "confidence": 0.9928659200668335}]}, {"text": "Using only n-grams as features for the statistical model without PTB-style Tweet POS tags gives a relatively large drop (0.02) from F1.", "labels": [], "entities": [{"text": "PTB-style Tweet POS tags", "start_pos": 65, "end_pos": 89, "type": "DATASET", "confidence": 0.825552687048912}, {"text": "F1", "start_pos": 132, "end_pos": 134, "type": "METRIC", "confidence": 0.9993127584457397}]}, {"text": "From the grammatical perspective, n-grams are less informative than POS tags for counterfactuals especially considering that there are so many variations of each word token in social media (e.g., 'clda', 'coulda', and 'couldve' for 'could have').", "labels": [], "entities": []}, {"text": "We examined how the statistical model affected the final performance of each counterfactual form.", "labels": [], "entities": []}, {"text": "The model we used for filtering out frequent false positives (e.g., birthday wishes) of Wish Verb form caused 0.03 F1 drop when it is removed.", "labels": [], "entities": [{"text": "F1 drop", "start_pos": 115, "end_pos": 122, "type": "METRIC", "confidence": 0.9791210293769836}]}, {"text": "Also, the models trained with twoargument-relation forms (Conjunctive Normal / Converse, Modal Normal, and Verb Inversion) caused 0.04 F1 drop when they are removed from the pipeline, since the classifier cannot use subtle relations between arguments for its counterfactual prediction.", "labels": [], "entities": [{"text": "F1", "start_pos": 135, "end_pos": 137, "type": "METRIC", "confidence": 0.9975916147232056}]}], "tableCaptions": [{"text": " Table 1: Data Collection. 'CF' is counterfactual  and 'Non-CF' is non-counterfactual", "labels": [], "entities": [{"text": "Data Collection", "start_pos": 10, "end_pos": 25, "type": "TASK", "confidence": 0.6767609119415283}]}, {"text": " Table 3: Performance of Classifiers", "labels": [], "entities": []}, {"text": " Table 4: Ablation Test for Each Process", "labels": [], "entities": [{"text": "Ablation Test", "start_pos": 10, "end_pos": 23, "type": "METRIC", "confidence": 0.966252475976944}]}]}