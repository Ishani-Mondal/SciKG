{"title": [{"text": "Deep Multitask Learning for Semantic Dependency Parsing", "labels": [], "entities": [{"text": "Parsing", "start_pos": 48, "end_pos": 55, "type": "TASK", "confidence": 0.7633630633354187}]}], "abstractContent": [{"text": "We present a deep neural architecture that parses sentences into three semantic dependency graph formalisms.", "labels": [], "entities": []}, {"text": "By using efficient , nearly arc-factored inference and a bidirectional-LSTM composed with a multi-layer perceptron, our base system is able to significantly improve the state of the art for semantic dependency parsing, without using hand-engineered features or syntax.", "labels": [], "entities": [{"text": "semantic dependency parsing", "start_pos": 190, "end_pos": 217, "type": "TASK", "confidence": 0.7219389875729879}]}, {"text": "We then explore two multitask learning approaches-one that shares parameters across formalisms, and one that uses higher-order structures to predict the graphs jointly.", "labels": [], "entities": []}, {"text": "We find that both approaches improve performance across formalisms on average, achieving anew state of the art.", "labels": [], "entities": []}, {"text": "Our code is open-source and available at https://github.com/ Noahs-ARK/NeurboParser.", "labels": [], "entities": []}], "introductionContent": [{"text": "Labeled directed graphs area natural and flexible representation for semantics.", "labels": [], "entities": []}, {"text": "Their generality over trees, for instance, allows them to represent relational semantics while handling phenomena like coreference and coordination.", "labels": [], "entities": []}, {"text": "Even syntactic formalisms are moving toward graphs ().", "labels": [], "entities": []}, {"text": "However, full semantic graphs can be expensive to annotate, and efforts are fragmented across competing semantic theories, leading to a limited number of annotations in anyone formalism.", "labels": [], "entities": []}, {"text": "This makes learning to parse more difficult, especially for powerful but data-hungry machine learning techniques like neural networks.", "labels": [], "entities": []}, {"text": "In this work, we hypothesize that the overlap among theories and their corresponding represenLast week , shareholders took their money and ran .  tations can be exploited using multitask learning, allowing us to learn from more data.", "labels": [], "entities": []}, {"text": "We use the 2015 SemEval shared task on Broad-Coverage Semantic Dependency Parsing (SDP; as our testbed.", "labels": [], "entities": [{"text": "SemEval shared task on Broad-Coverage Semantic Dependency Parsing (SDP;", "start_pos": 16, "end_pos": 87, "type": "TASK", "confidence": 0.7143059237436815}]}, {"text": "The shared task provides an English-language corpus with parallel annotations for three semantic graph representations, described in \u00a72.", "labels": [], "entities": []}, {"text": "Though the shared task was designed in part to encourage comparison between the formalisms, we are the first to treat SDP as a multitask learning problem.", "labels": [], "entities": []}, {"text": "As a strong baseline, we introduce anew system that parses each formalism separately ( \u00a73).", "labels": [], "entities": []}, {"text": "It uses a bidirectional-LSTM composed with a multi-layer perceptron to score arcs and predicates, and has efficient, nearly arc-factored inference.", "labels": [], "entities": []}, {"text": "Experiments show it significantly improves on state-of-the-art methods ( \u00a73.4).", "labels": [], "entities": []}, {"text": "We then present two multitask extensions ( \u00a74.2: Graph statistics for in-domain (WSJ, \"id\") and out-of-domain (Brown corpus, \"ood\") data.", "labels": [], "entities": []}, {"text": "Numbers taken from. and \u00a74.3), with a parameterization and factorization that implicitly models the relationship between multiple formalisms.", "labels": [], "entities": []}, {"text": "Experiments show that both techniques improve over our basic model, with an additional (but smaller) improvement when they are combined ( \u00a74.5).", "labels": [], "entities": []}, {"text": "Our analysis shows that the improvement in unlabeled F 1 is greater for the two formalisms that are more structurally similar, and suggests directions for future work.", "labels": [], "entities": [{"text": "F 1", "start_pos": 53, "end_pos": 56, "type": "METRIC", "confidence": 0.9675041437149048}]}, {"text": "Finally, we survey related work ( \u00a75), and summarize our contributions and findings ( \u00a76).", "labels": [], "entities": []}], "datasetContent": [{"text": "We compare four multitask variants to the basic model, as well as the two baseline systems introduced in \u00a73.4.", "labels": [], "entities": []}, {"text": "\u2022 SHARED1 is a first-order model.", "labels": [], "entities": [{"text": "SHARED1", "start_pos": 2, "end_pos": 9, "type": "METRIC", "confidence": 0.6690371632575989}]}, {"text": "It uses a single shared BiLSTM encoder, and keeps the inference separate for each task.", "labels": [], "entities": []}, {"text": "\u2022 FREDA1 is a first-order model based on \"frustratingly easy\" parameter sharing.", "labels": [], "entities": [{"text": "FREDA1", "start_pos": 2, "end_pos": 8, "type": "METRIC", "confidence": 0.7061752080917358}]}, {"text": "It uses a shared encoder as well as task-specific ones.", "labels": [], "entities": []}, {"text": "The inference is kept separate for each task.", "labels": [], "entities": []}, {"text": "\u2022 SHARED3 is a third-order model.", "labels": [], "entities": [{"text": "SHARED3", "start_pos": 2, "end_pos": 9, "type": "METRIC", "confidence": 0.6129621863365173}]}, {"text": "It follows SHARED1 and uses a single shared BiLSTM encoder, but additionally employs cross-task structures and inference.", "labels": [], "entities": [{"text": "SHARED1", "start_pos": 11, "end_pos": 18, "type": "DATASET", "confidence": 0.7984367609024048}]}, {"text": "\u2022 FREDA3 is also a third-order model.", "labels": [], "entities": [{"text": "FREDA3", "start_pos": 2, "end_pos": 8, "type": "METRIC", "confidence": 0.569087564945221}]}, {"text": "It combines FREDA1 and SHARED3 by using both \"frustratingly easy\" parameter sharing and cross-task structures and inference.", "labels": [], "entities": [{"text": "FREDA1", "start_pos": 12, "end_pos": 18, "type": "METRIC", "confidence": 0.923095166683197}, {"text": "SHARED3", "start_pos": 23, "end_pos": 30, "type": "DATASET", "confidence": 0.47027093172073364}]}, {"text": "In addition, we also examine the effects of syntax by comparing our models to the state-of-the-art open track system (.", "labels": [], "entities": []}, {"text": "compares our models to the best published results (labeled F 1 score) on SemEval 2015 Task 18 in-domain test set.", "labels": [], "entities": [{"text": "F 1 score", "start_pos": 59, "end_pos": 68, "type": "METRIC", "confidence": 0.9582975705464681}, {"text": "SemEval 2015 Task 18 in-domain test set", "start_pos": 73, "end_pos": 112, "type": "DATASET", "confidence": 0.7499824251447406}]}, {"text": "Our basic model improves overall closed track entries in all formalisms.", "labels": [], "entities": []}, {"text": "It is even with the best open track system for DM and PSD, but improves on PAS and on average, without making use of any syntax.", "labels": [], "entities": [{"text": "PAS", "start_pos": 75, "end_pos": 78, "type": "METRIC", "confidence": 0.9270580410957336}]}, {"text": "Three of our four multitask variants further improve over our basic model; SHARED1's differences are statistically insignificant.", "labels": [], "entities": [{"text": "SHARED1", "start_pos": 75, "end_pos": 82, "type": "TASK", "confidence": 0.40198224782943726}]}, {"text": "Our best models (SHARED3, FREDA3) outperform the previous state-of-the-art closed track system by 1.7% absolute F 1 , and the best open track system by 0.9%, without the use of syntax.", "labels": [], "entities": [{"text": "SHARED3", "start_pos": 17, "end_pos": 24, "type": "METRIC", "confidence": 0.8351492881774902}, {"text": "FREDA3", "start_pos": 26, "end_pos": 32, "type": "METRIC", "confidence": 0.9340275526046753}, {"text": "F 1", "start_pos": 112, "end_pos": 115, "type": "METRIC", "confidence": 0.9878548681735992}]}, {"text": "We observe similar trends on the out-of-domain test set), with the exception that, on PSD, our best-performing model's improvement over the open-track system of Almeida and Martins (2015) is not statistically significant.", "labels": [], "entities": [{"text": "PSD", "start_pos": 86, "end_pos": 89, "type": "DATASET", "confidence": 0.7360750436782837}]}, {"text": "The extent to which we might benefit from syntactic information remains unclear.", "labels": [], "entities": []}, {"text": "With automatically generated syntactic parses, manage to obtain more than 1% absolute improvements over their closed track en-10 was the winner of the gold track, which overall saw higher performance than the closed and open tracks.", "labels": [], "entities": []}, {"text": "Since gold-standard syntactic analyses are not available inmost realistic scenarios, we do not include it in this comparison., the strongest baseline system.", "labels": [], "entities": []}, {"text": "try, which is consistent with the extensive evaluation by , but we leave the incorporation of syntactic trees to future work.", "labels": [], "entities": []}, {"text": "Syntactic parsing could be treated as yet another output task, as explored in and in the transition-based frameworks of and.", "labels": [], "entities": [{"text": "Syntactic parsing", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.8570245802402496}]}, {"text": "We hypothesized that the overlap between formalisms would enable multitask learning to be effective; in this section we investigate in more detail how structural overlap affected performance.", "labels": [], "entities": []}, {"text": "By looking at undirected overlap between unlabeled arcs, we discover that modeling only arcs in the same direction may have been a design mistake.", "labels": [], "entities": []}, {"text": "DM and PAS are more structurally similar to each other than either is to PSD.", "labels": [], "entities": [{"text": "DM", "start_pos": 0, "end_pos": 2, "type": "DATASET", "confidence": 0.7389054894447327}]}, {"text": "malisms in unlabeled F 1 score (each formalism's gold-standard unlabeled graph is used as a prediction of each other formalism's gold-standard unlabeled graph).", "labels": [], "entities": [{"text": "F 1 score", "start_pos": 21, "end_pos": 30, "type": "METRIC", "confidence": 0.8999196688334147}]}, {"text": "All three formalisms have more than 50% overlap when ignoring arcs' directions, but considering direction, PSD is clearly different; PSD reverses the direction about half of the time it shares an edge with another formalism.", "labels": [], "entities": [{"text": "PSD", "start_pos": 107, "end_pos": 110, "type": "TASK", "confidence": 0.928670346736908}]}, {"text": "A concrete example can be found in, where DM and PAS both have an arc from \"Last\" to \"week,\" while PSD has an arc from \"week\" to \"Last.\"", "labels": [], "entities": []}, {"text": "We can compare FREDA3 to FREDA1 to isolate the effect of modeling higher-order structures.", "labels": [], "entities": [{"text": "FREDA3", "start_pos": 15, "end_pos": 21, "type": "METRIC", "confidence": 0.6135016083717346}, {"text": "FREDA1", "start_pos": 25, "end_pos": 31, "type": "METRIC", "confidence": 0.6475475430488586}]}, {"text": "Table 6 shows performance on the development data in both unlabeled and labeled F 1 . We can see that FREDA3's unlabeled performance improves on DM and PAS, but degrades on PSD.", "labels": [], "entities": [{"text": "FREDA3", "start_pos": 102, "end_pos": 108, "type": "METRIC", "confidence": 0.9223508834838867}, {"text": "PAS", "start_pos": 152, "end_pos": 155, "type": "METRIC", "confidence": 0.924345076084137}]}, {"text": "This supports our hypothesis, and suggests that in future work, a more careful selection of structures to model might lead to further improvements.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Graph statistics for in-domain (WSJ,  \"id\") and out-of-domain (Brown corpus, \"ood\")  data. Numbers taken from", "labels": [], "entities": []}, {"text": " Table 2: Labeled parsing performance (F 1 score)  on both in-domain (id) and out-of-domain (ood)  test data. The last column shows the micro- average over the three tasks. Bold font indicates  best performance without syntax. Underlines indi- cate statistical significance with Bonferroni (1936)  correction compared to the best baseline system. 4", "labels": [], "entities": [{"text": "F 1 score)", "start_pos": 39, "end_pos": 49, "type": "METRIC", "confidence": 0.9697748869657516}, {"text": "micro- average", "start_pos": 136, "end_pos": 150, "type": "METRIC", "confidence": 0.9526383479436239}, {"text": "indi- cate statistical significance", "start_pos": 238, "end_pos": 273, "type": "METRIC", "confidence": 0.7317180037498474}, {"text": "correction", "start_pos": 298, "end_pos": 308, "type": "METRIC", "confidence": 0.9419910311698914}]}, {"text": " Table 3: Hyperparameters used in the experi- ments.", "labels": [], "entities": []}, {"text": " Table 4: The last columns show the micro-average  over the three tasks.  \u2020 denotes the use of syntac- tic parses. Bold font indicates best performance  among all systems, and underlines indicate statis- tical significance with Bonferroni correction com- pared to", "labels": [], "entities": []}, {"text": " Table 5: Pairwise structural similarities between  the three formalisms in unlabeled F 1 score. Scores  from Oepen et al. (2015).", "labels": [], "entities": [{"text": "F 1 score", "start_pos": 86, "end_pos": 95, "type": "METRIC", "confidence": 0.9356435537338257}]}, {"text": " Table 6: Unlabeled (UF ) and labeled (LF ) pars- ing performance of FREDA1 and FREDA3 on the  development set of SemEval 2015 Task 18.", "labels": [], "entities": [{"text": "Unlabeled (UF ) and labeled (LF ) pars-", "start_pos": 10, "end_pos": 49, "type": "METRIC", "confidence": 0.7671064165505496}, {"text": "FREDA1", "start_pos": 69, "end_pos": 75, "type": "DATASET", "confidence": 0.7746617197990417}, {"text": "FREDA3", "start_pos": 80, "end_pos": 86, "type": "DATASET", "confidence": 0.8804901838302612}, {"text": "SemEval 2015 Task 18", "start_pos": 114, "end_pos": 134, "type": "TASK", "confidence": 0.7766217738389969}]}]}