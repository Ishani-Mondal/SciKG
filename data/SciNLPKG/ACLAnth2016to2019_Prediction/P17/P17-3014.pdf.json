{"title": [{"text": "Domain Specific Automatic Question Generation from Text", "labels": [], "entities": [{"text": "Question Generation", "start_pos": 26, "end_pos": 45, "type": "TASK", "confidence": 0.6796159893274307}]}], "abstractContent": [{"text": "The goal of my doctoral thesis is to automatically generate interrogative sentences from descriptive sentences of Turkish biology text.", "labels": [], "entities": [{"text": "Turkish biology text", "start_pos": 114, "end_pos": 134, "type": "DATASET", "confidence": 0.6427944699923197}]}, {"text": "We employ syntactic and semantic approaches to parse descriptive sentences.", "labels": [], "entities": [{"text": "parse descriptive sentences", "start_pos": 47, "end_pos": 74, "type": "TASK", "confidence": 0.8204940557479858}]}, {"text": "Syntactic and semantic approaches utilize syntactic (constituent or dependency) parsing and semantic role labeling systems respectively.", "labels": [], "entities": [{"text": "syntactic (constituent or dependency) parsing", "start_pos": 42, "end_pos": 87, "type": "TASK", "confidence": 0.6590033684458051}]}, {"text": "After parsing step, question statements whose answers are embedded in the descriptive sentences are going to be formulated by using some predefined rules and templates.", "labels": [], "entities": []}, {"text": "Syntactic parsing is done using an open source dependency parser called MaltParser (Nivre et al. 2007).", "labels": [], "entities": [{"text": "Syntactic parsing", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.7303284108638763}]}, {"text": "Whereas to accomplish semantic parsing, we will construct a biological proposition bank (BioPropBank) and a corpus annotated with semantic roles.", "labels": [], "entities": [{"text": "semantic parsing", "start_pos": 22, "end_pos": 38, "type": "TASK", "confidence": 0.7409098148345947}]}, {"text": "Then we will employ supervised methods to automatic label the semantic roles of a sentence.", "labels": [], "entities": []}], "introductionContent": [{"text": "\"Cognition is the mental action or process of acquiring knowledge and understanding through thought, experience, and the senses.\"", "labels": [], "entities": []}, {"text": "Thought is triggered by asking questions and attempt to find answer of questions cause knowledge acquisition.", "labels": [], "entities": [{"text": "knowledge acquisition", "start_pos": 87, "end_pos": 108, "type": "TASK", "confidence": 0.7120825797319412}]}, {"text": "Researches indicate that questioning is a powerful teaching technique.", "labels": [], "entities": []}, {"text": "Lecturers benefit from questions for students' knowledge evaluation, student's stimulation to thinking on their own and encourage students to self-learning.", "labels": [], "entities": []}, {"text": "Also, students can review and memorize information previously learned by questioning themselves.", "labels": [], "entities": []}, {"text": "Generating questions manually need much time and effort for lecturers.", "labels": [], "entities": []}, {"text": "Moreover, student face considerable problems exercising and memorizing lessons.", "labels": [], "entities": []}, {"text": "To address these challenges, Automatic question generation (AQG) systems can provide sample questions to alleviate lecturer's effort and help students in self-learning.", "labels": [], "entities": [{"text": "Automatic question generation (AQG)", "start_pos": 29, "end_pos": 64, "type": "TASK", "confidence": 0.7222326596577963}]}, {"text": "Our motivation in generating questions automatically is to facilitate lecturer effort and help students to practice on course materials more efficiently.", "labels": [], "entities": []}, {"text": "Our goal in my thesis is building a system for question generation from Turkish biological text.", "labels": [], "entities": [{"text": "question generation from Turkish biological text", "start_pos": 47, "end_pos": 95, "type": "TASK", "confidence": 0.805607944726944}]}, {"text": "We take biology text as input of our system and generate questions which will rank based on questions quality.", "labels": [], "entities": []}, {"text": "AQG is one of the challenging problems in natural language processing especially when semantic analysis is needed to generate comprehensive questions like how and why.", "labels": [], "entities": [{"text": "natural language processing", "start_pos": 42, "end_pos": 69, "type": "TASK", "confidence": 0.6634702881177267}]}, {"text": "To the best of our knowledge, AQG approaches in Turkish have been proposed by and.", "labels": [], "entities": []}, {"text": "Both of these studies just have used syntactic approach without any semantic analysis for generating questions.", "labels": [], "entities": []}, {"text": "However, generating questions from biological text, which contain complex process, cannot rely on syntactic approach merely.", "labels": [], "entities": []}, {"text": "Relation between entities in a biological process make it difficult to analyze in syntactic level.", "labels": [], "entities": []}, {"text": "Understanding these process needs some level of semantic analysis.", "labels": [], "entities": [{"text": "semantic analysis", "start_pos": 48, "end_pos": 65, "type": "TASK", "confidence": 0.7735265493392944}]}, {"text": "In my proposal, we plan to generate comprehensive questions like how and why in addition to when, where, who and whom.", "labels": [], "entities": []}, {"text": "Therefore, we need syntactic and semantic analysis of descriptive sentences.", "labels": [], "entities": []}, {"text": "Syntactic analysis of a sentence determines the structure of phrases of a text and converts it into a more structured representation, the parse tree.", "labels": [], "entities": []}, {"text": "Characterizing \"who\" did \"what\" to \"whom,\" \"where,\" \"when,\" \"how\" and \"why\" is semantic analysis of a sentence.", "labels": [], "entities": []}, {"text": "Semantic role labeling (SRL) is a task of automatically identifying semantic relations between predicate and its related arguments in the sentence.", "labels": [], "entities": [{"text": "Semantic role labeling (SRL)", "start_pos": 0, "end_pos": 28, "type": "TASK", "confidence": 0.8543665508429209}]}, {"text": "Assigning pre-defined set of semantic roles such as Agent, Patient and Manner to arguments is defined as predicateargument structure (PAS) identification problem.", "labels": [], "entities": [{"text": "predicateargument structure (PAS) identification", "start_pos": 105, "end_pos": 153, "type": "TASK", "confidence": 0.6222392320632935}]}, {"text": "Lexical resources like PropBank () and FrameNet () are needed to label semantic role of arguments.", "labels": [], "entities": [{"text": "PropBank", "start_pos": 23, "end_pos": 31, "type": "DATASET", "confidence": 0.9017269611358643}]}, {"text": "The Turkish lexical semantic resource (TLSR) were built by Isguder.", "labels": [], "entities": [{"text": "Turkish lexical semantic resource (TLSR", "start_pos": 4, "end_pos": 43, "type": "TASK", "confidence": 0.5351819892724355}]}, {"text": "TLSR is in general domain and does not cover biological field.", "labels": [], "entities": [{"text": "TLSR", "start_pos": 0, "end_pos": 4, "type": "TASK", "confidence": 0.5387080907821655}]}, {"text": "Moreover, size of TLSR is small compared to PropBank in other languages.", "labels": [], "entities": []}, {"text": "At present the number of annotated verb frame and sense are 759 and 1262 respectively.", "labels": [], "entities": []}, {"text": "Domain sensitivity of SRL systems have been emphasized by many researchers).", "labels": [], "entities": [{"text": "SRL", "start_pos": 22, "end_pos": 25, "type": "TASK", "confidence": 0.9781266450881958}]}, {"text": "showed that the performance of SRL systems dropped dramatically by almost 10% when domain of testing data is different from training data.", "labels": [], "entities": [{"text": "SRL", "start_pos": 31, "end_pos": 34, "type": "TASK", "confidence": 0.981141209602356}]}, {"text": "indicated the accuracy enhancement of SRL systems with the existence of in-domain annotations of data.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 14, "end_pos": 22, "type": "METRIC", "confidence": 0.9991350769996643}, {"text": "SRL", "start_pos": 38, "end_pos": 41, "type": "TASK", "confidence": 0.9687750935554504}]}, {"text": "Therefore, to automatically generating questions from biological text using semantic parsing, we first need to build an SRL system in the biological domain.", "labels": [], "entities": [{"text": "semantic parsing", "start_pos": 76, "end_pos": 92, "type": "TASK", "confidence": 0.7404780089855194}, {"text": "SRL", "start_pos": 120, "end_pos": 123, "type": "TASK", "confidence": 0.9652507305145264}]}, {"text": "To this end we will construct a lexical resource for the biology domain along with a corpus annotated with semantic roles in semi-automatic manner.", "labels": [], "entities": []}, {"text": "Furthermore, there is not automatic SRL system in Turkish yet.", "labels": [], "entities": [{"text": "SRL", "start_pos": 36, "end_pos": 39, "type": "TASK", "confidence": 0.9411577582359314}]}, {"text": "So, we plan to design a supervised SRL system too.", "labels": [], "entities": [{"text": "SRL", "start_pos": 35, "end_pos": 38, "type": "TASK", "confidence": 0.966757595539093}]}, {"text": "In AQG step, we parse descriptive sentence using syntactic and semantic parser.", "labels": [], "entities": []}, {"text": "Automatic SRL system which will construct in the first phase of my thesis, will employ to parse descriptive sentence semantically.", "labels": [], "entities": [{"text": "SRL", "start_pos": 10, "end_pos": 13, "type": "TASK", "confidence": 0.9196130037307739}, {"text": "parse descriptive sentence semantically", "start_pos": 90, "end_pos": 129, "type": "TASK", "confidence": 0.8001779019832611}]}, {"text": "Syntactic parsing of descriptive sentence will do by an open source dependency parser called MaltParser ().", "labels": [], "entities": []}, {"text": "Semantic role labels and syntactic tags will use to identify content to generate relevant question (i.e. if semantic role label is \"Arg0\" then the question type will be \"who\").", "labels": [], "entities": [{"text": "Arg0", "start_pos": 132, "end_pos": 136, "type": "METRIC", "confidence": 0.941440224647522}]}, {"text": "In the question formation step, some predefined rules and template will utilize.", "labels": [], "entities": [{"text": "question formation", "start_pos": 7, "end_pos": 25, "type": "TASK", "confidence": 0.7964513301849365}]}, {"text": "The quality of the generated questions will measure based on its syntactic and semantic correctness and its relevancy to the given sentence.", "labels": [], "entities": []}], "datasetContent": [{"text": "To evaluate the SRL system, precision, recall, F1 and accuracy will be calculated.", "labels": [], "entities": [{"text": "SRL", "start_pos": 16, "end_pos": 19, "type": "TASK", "confidence": 0.7660447955131531}, {"text": "precision", "start_pos": 28, "end_pos": 37, "type": "METRIC", "confidence": 0.9998146891593933}, {"text": "recall", "start_pos": 39, "end_pos": 45, "type": "METRIC", "confidence": 0.9997518658638}, {"text": "F1", "start_pos": 47, "end_pos": 49, "type": "METRIC", "confidence": 0.9997667670249939}, {"text": "accuracy", "start_pos": 54, "end_pos": 62, "type": "METRIC", "confidence": 0.9998354911804199}]}, {"text": "The following components are evaluated for the quality of the whole system: \uf0b7 Argument identification performance \uf0b7 Argument classification performance when arguments are known \uf0b7 Performance of system when training data is in news domain and test data is in biology domain and vice versa.", "labels": [], "entities": [{"text": "\uf0b7", "start_pos": 76, "end_pos": 77, "type": "METRIC", "confidence": 0.9903324246406555}, {"text": "Argument identification", "start_pos": 78, "end_pos": 101, "type": "METRIC", "confidence": 0.8400508463382721}, {"text": "\uf0b7", "start_pos": 114, "end_pos": 115, "type": "METRIC", "confidence": 0.9833872318267822}, {"text": "Argument classification", "start_pos": 116, "end_pos": 139, "type": "METRIC", "confidence": 0.806361585855484}]}, {"text": "\uf0b7 Performance of self-training method in news and biology domain Rus at al.", "labels": [], "entities": [{"text": "news and biology domain Rus at al", "start_pos": 41, "end_pos": 74, "type": "DATASET", "confidence": 0.6968860839094434}]}, {"text": "(2010) evaluated generated questions with the parameters, relevance, question type, syntactic correctness and fluency, ambiguity and variety.", "labels": [], "entities": []}, {"text": "All parameters are among 1 and 4 which 1 is the best and 4 is the worst score.", "labels": [], "entities": []}, {"text": "In my thesis we will evaluate generated questions by these parameters and the parameters that will define.", "labels": [], "entities": []}, {"text": "'questions importance in education' can be one of these parameters.", "labels": [], "entities": []}, {"text": "We will ask three experts to evaluate generated questions manually.", "labels": [], "entities": []}], "tableCaptions": []}