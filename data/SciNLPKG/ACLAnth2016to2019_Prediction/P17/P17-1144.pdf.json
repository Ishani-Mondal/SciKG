{"title": [{"text": "A Corpus of Annotated Revisions for Studying Argumentative Writing", "labels": [], "entities": [{"text": "Studying Argumentative Writing", "start_pos": 36, "end_pos": 66, "type": "TASK", "confidence": 0.6162452598412832}]}], "abstractContent": [{"text": "This paper presents ArgRewrite, a corpus of between-draft revisions of argumentative essays.", "labels": [], "entities": [{"text": "ArgRewrite", "start_pos": 20, "end_pos": 30, "type": "METRIC", "confidence": 0.6373031735420227}]}, {"text": "Drafts are manually aligned at the sentence level, and the writer's purpose for each revision is annotated with categories analogous to those used in argument mining and discourse analysis.", "labels": [], "entities": [{"text": "argument mining", "start_pos": 150, "end_pos": 165, "type": "TASK", "confidence": 0.7382092326879501}, {"text": "discourse analysis", "start_pos": 170, "end_pos": 188, "type": "TASK", "confidence": 0.6942237913608551}]}, {"text": "The corpus should enable advanced research in writing comparison and revision analysis, as demonstrated via our own studies of student revision behavior and of automatic revision purpose prediction.", "labels": [], "entities": [{"text": "writing comparison", "start_pos": 46, "end_pos": 64, "type": "TASK", "confidence": 0.8546770811080933}, {"text": "revision analysis", "start_pos": 69, "end_pos": 86, "type": "TASK", "confidence": 0.9505340158939362}, {"text": "automatic revision purpose prediction", "start_pos": 160, "end_pos": 197, "type": "TASK", "confidence": 0.6217544823884964}]}], "introductionContent": [{"text": "Most writing-related natural language processing (NLP) research focuses on the analysis of single drafts.", "labels": [], "entities": [{"text": "writing-related natural language processing (NLP)", "start_pos": 5, "end_pos": 54, "type": "TASK", "confidence": 0.746244877576828}]}, {"text": "Examples include document-level quality assessment (, discourse-level analysis and mining, and fine-grained error detection (.", "labels": [], "entities": [{"text": "document-level quality assessment", "start_pos": 17, "end_pos": 50, "type": "TASK", "confidence": 0.6507287621498108}, {"text": "discourse-level analysis and mining", "start_pos": 54, "end_pos": 89, "type": "TASK", "confidence": 0.7273533418774605}, {"text": "fine-grained error detection", "start_pos": 95, "end_pos": 123, "type": "TASK", "confidence": 0.5653140743573507}]}, {"text": "Less studied is the analysis of changes between drafts -a comparison of revisions and the properties of the differences.", "labels": [], "entities": []}, {"text": "Research on this topic can support applications involing revision analysis (, paraphrase (Malakasiotis and Androutsopoulos, 2011) and correction detection.", "labels": [], "entities": [{"text": "revision analysis", "start_pos": 57, "end_pos": 74, "type": "TASK", "confidence": 0.9888021945953369}, {"text": "correction detection", "start_pos": 134, "end_pos": 154, "type": "TASK", "confidence": 0.9773614406585693}]}, {"text": "Although there are some corpora resources for NLP research on writing comparisons, most tend to be between individual sentences/phrases for tasks such as paraphrase comparison) or grammar error correction ().", "labels": [], "entities": [{"text": "paraphrase comparison", "start_pos": 154, "end_pos": 175, "type": "TASK", "confidence": 0.8476601541042328}, {"text": "grammar error correction", "start_pos": 180, "end_pos": 204, "type": "TASK", "confidence": 0.5751966834068298}]}, {"text": "In terms of revision analysis, the most relevant work analyzes Wikipedia revisions; however, the domain of Wikipedia is so specialized that the properties of Wikipedia revisions do not correspond well with other kinds of texts.", "labels": [], "entities": [{"text": "revision analysis", "start_pos": 12, "end_pos": 29, "type": "TASK", "confidence": 0.9575279653072357}]}, {"text": "This work presents the ArgRewrite corpus 1 to facilitate revision analysis research for argumentative essays.", "labels": [], "entities": [{"text": "ArgRewrite corpus 1", "start_pos": 23, "end_pos": 42, "type": "DATASET", "confidence": 0.7848657667636871}, {"text": "revision analysis", "start_pos": 57, "end_pos": 74, "type": "TASK", "confidence": 0.9681858420372009}]}, {"text": "The corpus consists of a collection of three drafts of essays written by university students and employees; the drafts are manually aligned at the sentence level, then the purpose of each revision is manually coded using a revision schema closely related to argument mining/discourse analysis.", "labels": [], "entities": [{"text": "argument mining/discourse analysis", "start_pos": 258, "end_pos": 292, "type": "TASK", "confidence": 0.7719181954860688}]}, {"text": "Within the domain of argumentative essays, the corpus will be useful for supporting research in argumentative revision analysis and the application of argument mining techniques.", "labels": [], "entities": [{"text": "argumentative revision analysis", "start_pos": 96, "end_pos": 127, "type": "TASK", "confidence": 0.8297134637832642}, {"text": "argument mining", "start_pos": 151, "end_pos": 166, "type": "TASK", "confidence": 0.7422402501106262}]}, {"text": "The corpus may also be useful for research on paraphrase comparisons, grammar error correction, and computational stylistics (.", "labels": [], "entities": [{"text": "paraphrase comparisons", "start_pos": 46, "end_pos": 68, "type": "TASK", "confidence": 0.8711092472076416}, {"text": "grammar error correction", "start_pos": 70, "end_pos": 94, "type": "TASK", "confidence": 0.5769723753134409}]}, {"text": "In this paper, we present two example uses of our corpus: 1) rewriting behavior data analysis, and 2) automatic revision purpose classification.", "labels": [], "entities": [{"text": "automatic revision purpose classification", "start_pos": 102, "end_pos": 143, "type": "TASK", "confidence": 0.7189021855592728}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 3: Descriptive statistics of the ArgRewrite  Corpus, including average number of words, sen- tences and paragraphs per essay draft.", "labels": [], "entities": [{"text": "ArgRewrite  Corpus", "start_pos": 40, "end_pos": 58, "type": "DATASET", "confidence": 0.8902153074741364}]}, {"text": " Table 4: Number of revisions, by participant  groups (language, interface), coarse-grain pur- poses, and revision drafts (Rev12 is between  Draft1-Draft2; Rev23 is between Draft2-Draft3).", "labels": [], "entities": []}, {"text": " Table 5: Number of revisions, by fine-grain revision purposes and edit types (add, delete, modify).", "labels": [], "entities": []}, {"text": " Table 6: Illustration of features used in the revision classification study.", "labels": [], "entities": [{"text": "revision classification", "start_pos": 47, "end_pos": 70, "type": "TASK", "confidence": 0.9838503003120422}]}, {"text": " Table 7: Average unweighted F-score for each binary classification task. The first 6 rows show the  average value of 10-fold cross-validation.  *  indicates significantly better than unigram baseline (p <  .05). The last 2 rows show the F-value for training on L2/Native data and testing on Native data. Bold  indicates larger than the number in the other row.", "labels": [], "entities": [{"text": "F-score", "start_pos": 29, "end_pos": 36, "type": "METRIC", "confidence": 0.9589862823486328}, {"text": "F-value", "start_pos": 238, "end_pos": 245, "type": "METRIC", "confidence": 0.9912099838256836}]}]}