{"title": [{"text": "Lifelong Learning CRF for Supervised Aspect Extraction", "labels": [], "entities": [{"text": "Lifelong Learning CRF", "start_pos": 0, "end_pos": 21, "type": "TASK", "confidence": 0.43795861800511676}, {"text": "Supervised Aspect Extraction", "start_pos": 26, "end_pos": 54, "type": "TASK", "confidence": 0.6990416248639425}]}], "abstractContent": [{"text": "This paper makes a focused contribution to supervised aspect extraction.", "labels": [], "entities": [{"text": "supervised aspect extraction", "start_pos": 43, "end_pos": 71, "type": "TASK", "confidence": 0.6405636767546335}]}, {"text": "It shows that if the system has performed aspect extraction from many past domains and retained their results as knowledge, Conditional Random Fields (CRF) can leverage this knowledge in a lifelong learning manner to extract in anew domain markedly better than the traditional CRF without using this prior knowledge.", "labels": [], "entities": [{"text": "aspect extraction", "start_pos": 42, "end_pos": 59, "type": "TASK", "confidence": 0.7359161674976349}]}, {"text": "The key innovation is that even after CRF training, the model can still improve its extraction with experiences in its applications.", "labels": [], "entities": [{"text": "CRF", "start_pos": 38, "end_pos": 41, "type": "TASK", "confidence": 0.9501158595085144}]}], "introductionContent": [{"text": "Aspect extraction is a key task of opinion mining (.", "labels": [], "entities": [{"text": "Aspect extraction", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.9397178292274475}, {"text": "opinion mining", "start_pos": 35, "end_pos": 49, "type": "TASK", "confidence": 0.8496421873569489}]}, {"text": "It extracts opinion targets from opinion text.", "labels": [], "entities": []}, {"text": "For example, from the sentence \"The screen is great\", it aims to extract \"screen\", which is a product feature, also called an aspect.", "labels": [], "entities": []}, {"text": "Aspect extraction is commonly done using a supervised or an unsupervised approach.", "labels": [], "entities": [{"text": "Aspect extraction", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.9621522426605225}]}, {"text": "The unsupervised approach includes methods such as frequent pattern mining (), syntactic rules-based extraction (;), topic modeling (, word alignment (, label propagation (, and others (.", "labels": [], "entities": [{"text": "frequent pattern mining", "start_pos": 51, "end_pos": 74, "type": "TASK", "confidence": 0.5965883930524191}, {"text": "syntactic rules-based extraction", "start_pos": 79, "end_pos": 111, "type": "TASK", "confidence": 0.6857718427975973}, {"text": "topic modeling", "start_pos": 117, "end_pos": 131, "type": "TASK", "confidence": 0.8508313000202179}, {"text": "word alignment", "start_pos": 135, "end_pos": 149, "type": "TASK", "confidence": 0.799243688583374}, {"text": "label propagation", "start_pos": 153, "end_pos": 170, "type": "TASK", "confidence": 0.74812912940979}]}, {"text": "This paper focuses on the supervised approach () using Conditional Random Fields (CRF) ().", "labels": [], "entities": []}, {"text": "It shows that the results of CRF can be significantly improved by leveraging some prior knowledge automatically mined from the extraction results of previous domains, including domains without labeled data.", "labels": [], "entities": []}, {"text": "The improvement is possible because although every product (domain) is different, there is a fair amount of aspects sharing across domains ).", "labels": [], "entities": []}, {"text": "For example, every review domain has the aspect price and reviews of many products have the aspect battery life or screen.", "labels": [], "entities": [{"text": "aspect", "start_pos": 41, "end_pos": 47, "type": "METRIC", "confidence": 0.9504198431968689}]}, {"text": "Those shared aspects may not appear in the training data but appear in unlabeled data and the test data.", "labels": [], "entities": []}, {"text": "We can exploit such sharing to help CRF perform much better.", "labels": [], "entities": []}, {"text": "Due to leveraging the knowledge gained from the past to help the new domain extraction, we are using the idea of lifelong machine learning (LML), which is a continuous learning paradigm that retains the knowledge learned in the past and uses it to help future learning and problem solving with possible adaptations.", "labels": [], "entities": [{"text": "domain extraction", "start_pos": 69, "end_pos": 86, "type": "TASK", "confidence": 0.8537417948246002}, {"text": "problem solving", "start_pos": 273, "end_pos": 288, "type": "TASK", "confidence": 0.7474424242973328}]}, {"text": "The setting of the proposed approach L-CRF (Lifelong CRF) is as follows: A CRF model M has been trained with a labeled training review dataset.", "labels": [], "entities": []}, {"text": "At a particular point in time, M has extracted aspects from data inn previous domains D 1 , . .", "labels": [], "entities": []}, {"text": ", D n (which are unlabeled) and the extracted sets of aspects are A 1 , . .", "labels": [], "entities": []}, {"text": ", A n . Now, the system is faced with anew domain data D n+1 . M can leverage some reliable prior knowledge in A 1 , . .", "labels": [], "entities": []}, {"text": ", A n to make a better extraction from D n+1 than without leveraging this prior knowledge.", "labels": [], "entities": []}, {"text": "The key innovation of L-CRF is that even after supervised training, the model can still improve its extraction in testing or its applications with experiences.", "labels": [], "entities": []}, {"text": "Note that L-CRF is different from semisupervised learning () as then previous (unlabeled) domain data used in extraction are not used or not available during model training.", "labels": [], "entities": []}, {"text": "There are prior LML works for aspect extraction ( ), but they were all unsupervised methods.", "labels": [], "entities": [{"text": "aspect extraction", "start_pos": 30, "end_pos": 47, "type": "TASK", "confidence": 0.863579511642456}]}, {"text": "Supervised LML methods exist), but they are for classification rather than for sequence learning or labeling like CRF.", "labels": [], "entities": []}, {"text": "A semi-supervised LML method is used in NELL (), but it is heuristic patternbased.", "labels": [], "entities": []}, {"text": "It doesn't use sequence learning and is not for aspect extraction.", "labels": [], "entities": [{"text": "aspect extraction", "start_pos": 48, "end_pos": 65, "type": "TASK", "confidence": 0.8502193987369537}]}, {"text": "LML is related to transfer learning and multi-task learning), but they are also quite different (see ) for details).", "labels": [], "entities": []}, {"text": "To the best of our knowledge, this is the first paper that uses LML to help a supervised extraction method to markedly improve its results.", "labels": [], "entities": []}], "datasetContent": [{"text": "We now evaluate the proposed L-CRF method and compare with baselines.", "labels": [], "entities": []}, {"text": "We use two types of data for our experiments.", "labels": [], "entities": []}, {"text": "The first type consists of seven annotated benchmark review datasets from 7 domains (types of products).", "labels": [], "entities": []}, {"text": "Since they are annotated, they are used in training and testing.", "labels": [], "entities": []}, {"text": "The first 4 datasets are from (), which actually has 5 datasets from 4 domains.", "labels": [], "entities": []}, {"text": "Since we are mainly interested in results at the domain level, we did not use one of the domain-repeated datasets.", "labels": [], "entities": []}, {"text": "The last 3 datasets of three domains (products) are from ( ).", "labels": [], "entities": []}, {"text": "These datasets are used to makeup our CRF training data D t and test data D n+1 . The annotation details are given in.", "labels": [], "entities": [{"text": "CRF training data D t", "start_pos": 38, "end_pos": 59, "type": "DATASET", "confidence": 0.8402311325073242}]}, {"text": "The second type has 50 unlabeled review datasets from 50 domains or types of products . Each dataset has 1000 reviews.", "labels": [], "entities": []}, {"text": "They are used as the past domain data, i.e., D 1 , . .", "labels": [], "entities": [{"text": "D 1", "start_pos": 45, "end_pos": 48, "type": "METRIC", "confidence": 0.9563547670841217}]}, {"text": ", D n (n = 50).", "labels": [], "entities": []}, {"text": "Since they are not labeled, they cannot be used for training or testing.", "labels": [], "entities": []}, {"text": "To compare the systems using the same training and test data, for each dataset we use 200 sentences for training and 200 sentences for testing to avoid bias towards any dataset or domain because we will combine multiple domain datasets for CRF training.", "labels": [], "entities": []}, {"text": "We conducted both cross-domain and in-domain tests.", "labels": [], "entities": []}, {"text": "Our problem setting is crossdomain.", "labels": [], "entities": []}, {"text": "In-domain is used for completeness.", "labels": [], "entities": []}, {"text": "In both cases, we assume that extraction has been done for the 50 domains.", "labels": [], "entities": []}, {"text": "Cross-domain experiments: We combine 6 labeled domain datasets for training (1200 sentences) and test on the 7th domain (not used in training).", "labels": [], "entities": []}, {"text": "This gives us 7 cross-domain results.", "labels": [], "entities": []}, {"text": "This set of tests is particularly interesting as it is desirable to have the trained model used in crossdomain situations to save manual labeling effort.", "labels": [], "entities": []}, {"text": "In-domain experiments: We train and test on the same 6 domains (1200 sentences for training and 1200 sentences for testing).", "labels": [], "entities": []}, {"text": "This also gives us 7 in-domain results.", "labels": [], "entities": []}, {"text": "Evaluating Measures: We use the popular precision P, recall R, and F 1 -score.", "labels": [], "entities": [{"text": "Evaluating Measures", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.6576128453016281}, {"text": "precision P", "start_pos": 40, "end_pos": 51, "type": "METRIC", "confidence": 0.9187137186527252}, {"text": "recall R", "start_pos": 53, "end_pos": 61, "type": "METRIC", "confidence": 0.9574078023433685}, {"text": "F 1 -score", "start_pos": 67, "end_pos": 77, "type": "METRIC", "confidence": 0.9739176481962204}]}], "tableCaptions": [{"text": " Table 1: Dependency relations parsed from \"The battery of this camera is great\"", "labels": [], "entities": []}, {"text": " Table 2: Annotation details of the datasets", "labels": [], "entities": []}, {"text": " Table 3: Aspect extraction results in precision, recall and F 1 score: Cross-Domain and In-Domain (\u2212X  means all except domain X)", "labels": [], "entities": [{"text": "Aspect extraction", "start_pos": 10, "end_pos": 27, "type": "TASK", "confidence": 0.8340683579444885}, {"text": "precision", "start_pos": 39, "end_pos": 48, "type": "METRIC", "confidence": 0.9997251629829407}, {"text": "recall", "start_pos": 50, "end_pos": 56, "type": "METRIC", "confidence": 0.9997333884239197}, {"text": "F 1 score", "start_pos": 61, "end_pos": 70, "type": "METRIC", "confidence": 0.9634502331415812}]}]}