{"title": [{"text": "Parser Adaptation for Social Media by Integrating Normalization", "labels": [], "entities": [{"text": "Parser Adaptation", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.7740713059902191}, {"text": "Normalization", "start_pos": 50, "end_pos": 63, "type": "TASK", "confidence": 0.48260438442230225}]}], "abstractContent": [{"text": "This work explores normalization for parser adaptation.", "labels": [], "entities": [{"text": "parser adaptation", "start_pos": 37, "end_pos": 54, "type": "TASK", "confidence": 0.889230489730835}]}, {"text": "Traditionally, normal-ization is used as separate pre-processing step.", "labels": [], "entities": []}, {"text": "We show that integrating the nor-malization model into the parsing algorithm is beneficial.", "labels": [], "entities": [{"text": "parsing", "start_pos": 59, "end_pos": 66, "type": "TASK", "confidence": 0.9715772867202759}]}, {"text": "This way, multiple nor-malization candidates can be leveraged, which improves parsing performance on social media.", "labels": [], "entities": [{"text": "parsing", "start_pos": 78, "end_pos": 85, "type": "TASK", "confidence": 0.966140627861023}]}, {"text": "We test this hypothesis by modifying the Berkeley parser; out-of-the-box it achieves an F1 score of 66.52.", "labels": [], "entities": [{"text": "F1 score", "start_pos": 88, "end_pos": 96, "type": "METRIC", "confidence": 0.9877153933048248}]}, {"text": "Our integrated approach reaches a significant improvement with an F1 score of 67.36, while using the best normalization sequence results in an F1 score of only 66.94.", "labels": [], "entities": [{"text": "F1 score", "start_pos": 66, "end_pos": 74, "type": "METRIC", "confidence": 0.9866623282432556}, {"text": "F1 score", "start_pos": 143, "end_pos": 151, "type": "METRIC", "confidence": 0.9864383637905121}]}], "introductionContent": [{"text": "The non-canonical language use on social media introduces many difficulties for existing NLP models.", "labels": [], "entities": []}, {"text": "For some NLP tasks, there has already been an effort to annotate enough data to train models, e.g. named entity recognition ( , sentiment analysis () and paraphrase detection ( ).", "labels": [], "entities": [{"text": "named entity recognition", "start_pos": 99, "end_pos": 123, "type": "TASK", "confidence": 0.6069030364354452}, {"text": "sentiment analysis", "start_pos": 128, "end_pos": 146, "type": "TASK", "confidence": 0.8983118832111359}, {"text": "paraphrase detection", "start_pos": 154, "end_pos": 174, "type": "TASK", "confidence": 0.8912225961685181}]}, {"text": "For parsing social media texts, such a resource is not available yet, although there are some small treebanks that can be used for development/testing purposes.", "labels": [], "entities": [{"text": "parsing social media texts", "start_pos": 4, "end_pos": 30, "type": "TASK", "confidence": 0.9095652103424072}]}, {"text": "To the best of our knowledge, the only treebank big enough to train a supervised parser for user generated content is the English Web Treebank (.", "labels": [], "entities": [{"text": "English Web Treebank", "start_pos": 122, "end_pos": 142, "type": "DATASET", "confidence": 0.9222644964853922}]}, {"text": "This treebank consists of constituency trees from five different web domains, not including the domain of social media.", "labels": [], "entities": []}, {"text": "The magnitude of domain adaptation problems for the social media domain becomes clear when training the Berkeley parser on newswire text, and comparing its in-domain performance with performance on the Twitter domain.", "labels": [], "entities": [{"text": "domain adaptation", "start_pos": 17, "end_pos": 34, "type": "TASK", "confidence": 0.747959315776825}]}, {"text": "The Berkeley parser achieves an F1 score above 90 on newswire text).", "labels": [], "entities": [{"text": "F1 score", "start_pos": 32, "end_pos": 40, "type": "METRIC", "confidence": 0.9871690571308136}]}, {"text": "An empirical experiment that we carried out on a Twitter treebank shows that the F1 score drops below 70 for this domain.", "labels": [], "entities": [{"text": "Twitter treebank", "start_pos": 49, "end_pos": 65, "type": "DATASET", "confidence": 0.8637803792953491}, {"text": "F1 score", "start_pos": 81, "end_pos": 89, "type": "METRIC", "confidence": 0.9912027716636658}]}, {"text": "Annotating anew training treebank for this domain would not only bean expensive solution, the ever-changing nature of social media makes this approach less effective overtime.", "labels": [], "entities": []}, {"text": "We propose an approach in which we integrate normalization into the parsing model.", "labels": [], "entities": []}, {"text": "The normalization model provides the parser with different normalization candidates for each word in the input sentence.", "labels": [], "entities": []}, {"text": "Existing algorithms can then be used to find the optimal parse tree over this lattice (.", "labels": [], "entities": []}, {"text": "A possible normalization lattice for the sentence 'this is nice' is shown in.", "labels": [], "entities": []}, {"text": "In this example output, the probability of 'as' is higher than the probability of 'is', whereas the most fluent word sequence would be 'this is nice'.", "labels": [], "entities": []}, {"text": "The parser can disambiguate this word graph because it has access to the syntactic context: 'is' is usually tagged as VBZ, while 'as' is mostly tagged as IN.", "labels": [], "entities": [{"text": "VBZ", "start_pos": 118, "end_pos": 121, "type": "DATASET", "confidence": 0.7633113265037537}]}, {"text": "This example shows the main motivation for using an integrated approach; the extra information from the normalization can be useful for parsing.", "labels": [], "entities": [{"text": "parsing", "start_pos": 136, "end_pos": 143, "type": "TASK", "confidence": 0.9817682504653931}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Some basic statistics for our training and  development corpora. % of unknown words (Unk)  calculated against the Aspell dictionary ignoring  capitalization. * Only the development part.", "labels": [], "entities": [{"text": "Aspell dictionary", "start_pos": 124, "end_pos": 141, "type": "DATASET", "confidence": 0.9246275126934052}]}, {"text": " Table 2: F1 scores on the development data using  different weights, comparing only using the best  candidate versus using 6 candidates.", "labels": [], "entities": [{"text": "F1", "start_pos": 10, "end_pos": 12, "type": "METRIC", "confidence": 0.9995429515838623}]}, {"text": " Table 3: F1 scores of our proposed models and  previous work on the test set, trained on the EWT  and WSJ. * Statistical significant against Berkeley- parser at P < 0.01 and at P < 0.05 against the  best normalization sequence using a paired t-test.", "labels": [], "entities": [{"text": "F1", "start_pos": 10, "end_pos": 12, "type": "METRIC", "confidence": 0.9995725750923157}, {"text": "EWT", "start_pos": 94, "end_pos": 97, "type": "DATASET", "confidence": 0.9798556566238403}, {"text": "WSJ", "start_pos": 103, "end_pos": 106, "type": "DATASET", "confidence": 0.8763445019721985}]}]}