{"title": [{"text": "A Deep Network with Visual Text Composition Behavior", "labels": [], "entities": []}], "abstractContent": [{"text": "While natural languages are composi-tional, how state-of-the-art neural models achieve compositionality is still unclear.", "labels": [], "entities": []}, {"text": "We propose a deep network, which not only achieves competitive accuracy for text classification, but also exhibits com-positional behavior.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 63, "end_pos": 71, "type": "METRIC", "confidence": 0.9839591383934021}, {"text": "text classification", "start_pos": 76, "end_pos": 95, "type": "TASK", "confidence": 0.8441446721553802}]}, {"text": "That is, while creating hierarchical representations of apiece of text, such as a sentence, the lower layers of the network distribute their layer-specific attention weights to individual words.", "labels": [], "entities": []}, {"text": "In contrast, the higher layers compose meaningful phrases and clauses, whose lengths increase as the networks get deeper until fully composing the sentence.", "labels": [], "entities": []}], "introductionContent": [{"text": "Deep neural networks leverage task-specific architectures to develop hierarchical representations of the input, where higher level representations are derived from lower level features (.", "labels": [], "entities": []}, {"text": "Such hierarchical representations have visually demonstrated compositionality in image processing, i.e., pixels combine to form shapes and then contours).", "labels": [], "entities": []}, {"text": "Natural languages are also compositional, i.e., words combine to form phrases and then sentences.", "labels": [], "entities": []}, {"text": "Yet unlike in vision, how deep neural models in NLP, which mainly operate on distributed word embeddings, achieve compositionality, is still unclear (.", "labels": [], "entities": []}, {"text": "We propose an Attention Gated Transformation (AGT) network, where each layer's feature generation is gated by a layer-specific attention mechanism ().", "labels": [], "entities": [{"text": "Attention Gated Transformation (AGT)", "start_pos": 14, "end_pos": 50, "type": "TASK", "confidence": 0.8080143133799235}]}, {"text": "Specifically, through distributing its attention to the original given text, each layer of the networks tends to incrementally retrieve new words and phrases from the original text.", "labels": [], "entities": []}, {"text": "The new knowledge is then combined with the previous layer's features to create the current layer's representation, thus resulting in composing longer or new phrases and clauses while creating higher layers' representations of the text.", "labels": [], "entities": []}, {"text": "Experiments on the Stanford Sentiment Treebank () dataset show that the AGT method not only achieves very competitive accuracy, but also exhibits compositional behavior via its layer-specific attention.", "labels": [], "entities": [{"text": "Stanford Sentiment Treebank () dataset", "start_pos": 19, "end_pos": 57, "type": "DATASET", "confidence": 0.8915892839431763}, {"text": "accuracy", "start_pos": 118, "end_pos": 126, "type": "METRIC", "confidence": 0.9836376905441284}]}, {"text": "We empirically show that, given apiece of text, e.g., a sentence, the lower layers of the networks select individual words, e.g, negative and conjunction words not and though, while the higher layers aim at composing meaningful phrases and clauses such as negation phrase not so much, where the phrase length increases as the networks get deeper until fully composing the whole sentence.", "labels": [], "entities": []}, {"text": "Interestingly, after composing the sentence, the compositions of different sentence phrases compete to become the dominating features of the end task.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Test-set accuracies obtained; results ex- cept the AGT are drawn from (Lei et al., 2015).", "labels": [], "entities": [{"text": "AGT", "start_pos": 61, "end_pos": 64, "type": "METRIC", "confidence": 0.410800039768219}]}]}