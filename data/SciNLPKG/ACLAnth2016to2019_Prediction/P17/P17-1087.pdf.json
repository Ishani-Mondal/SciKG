{"title": [{"text": "Semantic Word Clusters Using Signed Spectral Clustering", "labels": [], "entities": []}], "abstractContent": [{"text": "Vector space representations of words capture many aspects of word similarity, but such methods tend to produce vector spaces in which antonyms (as well as synonyms) are close to each other.", "labels": [], "entities": []}, {"text": "For spectral clustering using such word embed-dings, words are points in a vector space where synonyms are linked with positive weights, while antonyms are linked with negative weights.", "labels": [], "entities": [{"text": "spectral clustering", "start_pos": 4, "end_pos": 23, "type": "TASK", "confidence": 0.7960378229618073}]}, {"text": "We present anew signed spectral normalized graph cut algorithm , signed clustering, that overlays existing thesauri upon distributionally derived vector representations of words, so that antonym relationships between word pairs are represented by negative weights.", "labels": [], "entities": []}, {"text": "Our signed clustering algorithm produces clusters of words that simultaneously capture distributional and synonym relations.", "labels": [], "entities": []}, {"text": "By using randomized spectral decomposition (Halko et al., 2011) and sparse matrices , our method is both fast and scalable.", "labels": [], "entities": []}, {"text": "We validate our clusters using datasets containing human judgments of word pair similarities and show the benefit of using our word clusters for sentiment prediction.", "labels": [], "entities": [{"text": "sentiment prediction", "start_pos": 145, "end_pos": 165, "type": "TASK", "confidence": 0.9653353989124298}]}], "introductionContent": [{"text": "In distributional vector representations, opposite relations are not fully captured.", "labels": [], "entities": []}, {"text": "Take, for example, words such as \"great\" and \"awful\" that can appear with similar frequency in the same sentence structure: \"John had a great meeting\" and \"John had an awful day.\"", "labels": [], "entities": []}, {"text": "Word embeddings, which are successful in a wide array of NLP tasks, fail to capture this antonymy because they follow the distributional hypothesis that similar words are used in similar contexts, thus assigning small cosine or euclidean distances between the vector representations of \"great\" and \"awful\".", "labels": [], "entities": []}, {"text": "While vector space models () such as word2vec (), Global vectors (GloVe) (), or Eigenwords () capture relatedness, they do not adequately encode synonymy and semantic similarity.", "labels": [], "entities": []}, {"text": "Our goal is to create clusters of synonyms or semantically equivalent words and linguistically motivated unified constructs.", "labels": [], "entities": []}, {"text": "Signed graphs, which are graphs with negative edge weights, were first introduced by.", "labels": [], "entities": []}, {"text": "However, signed graph clustering for multiclass normalized cuts (K-clusters) has been largely unexplored until recently.", "labels": [], "entities": [{"text": "signed graph clustering", "start_pos": 9, "end_pos": 32, "type": "TASK", "confidence": 0.6364282468954722}]}, {"text": "We present a novel theory and method that extends multiclass normalized cuts (K-cluster) of to signed graphs ( and the work of to K-clustering.", "labels": [], "entities": []}, {"text": "This extension allows the incorporation of knowledge base information, positive and negatively weighted links (see figure 2.1).", "labels": [], "entities": []}, {"text": "Negative edges serve as repellent or opposite relationships between nodes.", "labels": [], "entities": []}, {"text": "Our signed spectral normalized graph cut algorithm (henceforth, signed clustering) builds negative edge relations into graph embeddings using similarity structure in vector spaces.", "labels": [], "entities": []}, {"text": "It takes as input an initial set of vectors and edge relations, and hence is easy to combine with any word embedding method.", "labels": [], "entities": []}, {"text": "This paper formally improves on the discrete optimization problem of.", "labels": [], "entities": []}, {"text": "Signed clustering gives better clusters than spectral clustering) of word embeddings, and it has better coverage and is more robust than thesaurus look-up.", "labels": [], "entities": [{"text": "Signed clustering", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.7906850874423981}]}, {"text": "This is because the-sauri erroneously give equal weight to rare senses of a word -for example, \"rich\" as a rarely used synonym of \"absurd\".", "labels": [], "entities": []}, {"text": "Also, the overlap between thesauri is small, due to their manual creation.", "labels": [], "entities": []}, {"text": "found 17.8397% overlap between synonym sets from Roget's Thesaurus and WordNet 1.5.", "labels": [], "entities": []}, {"text": "We find similarly small overlap between all three thesauri tested.", "labels": [], "entities": [{"text": "overlap", "start_pos": 24, "end_pos": 31, "type": "METRIC", "confidence": 0.9734786748886108}]}, {"text": "We evaluate our clusters using SimLex-999 () and SimVerb-3500 () as aground truth for our cluster evaluation.", "labels": [], "entities": [{"text": "SimVerb-3500", "start_pos": 49, "end_pos": 61, "type": "DATASET", "confidence": 0.901147186756134}]}, {"text": "Finally, we test our method on the sentiment analysis task.", "labels": [], "entities": [{"text": "sentiment analysis task", "start_pos": 35, "end_pos": 58, "type": "TASK", "confidence": 0.9591174721717834}]}, {"text": "Overall, signed spectral clustering can augment methods using signed information and has broad application for many fields.", "labels": [], "entities": [{"text": "signed spectral clustering", "start_pos": 9, "end_pos": 35, "type": "TASK", "confidence": 0.7245683471361796}]}, {"text": "Our main contributions are: the novel extension of signed clustering to the multiclass (K-cluster), and the application of this method to create semantic word clusters that are agnostic to vector space representations and thesauri.", "labels": [], "entities": []}], "datasetContent": [{"text": "We evaluated the clusters using both intrinsic and extrinsic methods.", "labels": [], "entities": []}, {"text": "For intrinsic evaluation, we used thesaurus information for two novel metrics: 1) the number of negative edges (NNE) within the clusters, which in our semantic clusters is the number of antonyms in the same cluster, and 2) the number of disconnected components (NDC) in the synonym graph, so the number of groups of words that are not connected by a synonym relation in the thesaurus.", "labels": [], "entities": []}, {"text": "The NDC thus has the disadvantage that it is a function of the thesaurus coverage.", "labels": [], "entities": [{"text": "NDC", "start_pos": 4, "end_pos": 7, "type": "DATASET", "confidence": 0.746465265750885}]}, {"text": "Our third intrinsic measure uses a gold standard designed to measure how well we capture word similarity: Semantically similar words should be in the same cluster and semantically dissimilar words should not.", "labels": [], "entities": []}, {"text": "For extrinsic evaluation, as descibed below, we measure how much our clusters help to identify text polarity.", "labels": [], "entities": [{"text": "identify text polarity", "start_pos": 86, "end_pos": 108, "type": "TASK", "confidence": 0.6570667922496796}]}, {"text": "We also compare multiple word embeddings and thesauri to demonstrate the stability of our method.", "labels": [], "entities": []}, {"text": "In order to evaluate our signed graph clustering method, we first focused on intrinsic measures of cluster quality in synthetic data.", "labels": [], "entities": [{"text": "signed graph clustering", "start_pos": 25, "end_pos": 48, "type": "TASK", "confidence": 0.6626908183097839}]}, {"text": "To do so, we created random signed graphs with the same proportion of positive and negative edges as in our real dataset.", "labels": [], "entities": []}, {"text": "demonstrates that the number of negative edges within a cluster is minimized using our clustering algorithm on simulated data.", "labels": [], "entities": []}, {"text": "As the number of clusters becomes large, the number of disconnected components, which includes clusters of size one, consistently increases.", "labels": [], "entities": []}, {"text": "Determining the optimal cluster size and similarity parameters requires making a trade off between NDC and NNE.", "labels": [], "entities": []}, {"text": "For example, in figure 2 the optimal cluster size is 20.", "labels": [], "entities": []}, {"text": "One can see that as the number of clusters increases NNE goes to zero, but the number of disconnected components becomes the number of vertices.", "labels": [], "entities": [{"text": "NNE", "start_pos": 53, "end_pos": 56, "type": "METRIC", "confidence": 0.9096542596817017}]}, {"text": "In the extreme case all clusters contain one vertex.", "labels": [], "entities": []}, {"text": "K-means, also shown in, does not optimize NNE.", "labels": [], "entities": []}, {"text": "We now turn to quantitative measures of word similarity and synonym cluster quality.", "labels": [], "entities": []}, {"text": "Ina perfect setting, all word pairs rated highly similar by human annotators would be in the same cluster, and all words which were rated dissimilar would be in different clusters.", "labels": [], "entities": []}, {"text": "Since our clustering algorithm produced sets of words, we used this evaluation instead of the more commonly reported correlations we show the results of the evaluation with SimLex-999.", "labels": [], "entities": [{"text": "SimLex-999", "start_pos": 173, "end_pos": 183, "type": "DATASET", "confidence": 0.9116155505180359}]}, {"text": "Combining thesaurus lookup and word2vec+CombThes clusters, labeled as Lookup + SC(W2V), yielded an accuracy of 0.96 (5 errors).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 99, "end_pos": 107, "type": "METRIC", "confidence": 0.9989435076713562}]}, {"text": "Note that clusters using word2vec with normalized cuts does not improve accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 72, "end_pos": 80, "type": "METRIC", "confidence": 0.9972038269042969}]}, {"text": "The MSW thesaurus has much lower coverage, but 100 % accuracy, which is why when  combined with the signed clustering the performance is 0.95 we state the proportion of clusters containing dissimilar words as a sanity check for cluster size.", "labels": [], "entities": [{"text": "MSW thesaurus", "start_pos": 4, "end_pos": 17, "type": "DATASET", "confidence": 0.9329632818698883}, {"text": "coverage", "start_pos": 33, "end_pos": 41, "type": "METRIC", "confidence": 0.9645739197731018}, {"text": "accuracy", "start_pos": 53, "end_pos": 61, "type": "METRIC", "confidence": 0.9994840621948242}]}, {"text": "(See supplemental material for full cluster size optimization information.)", "labels": [], "entities": [{"text": "cluster size optimization", "start_pos": 36, "end_pos": 61, "type": "TASK", "confidence": 0.6702402035395304}]}, {"text": "Another important result is that the verb accuracy yielded the largest accuracy gains, consistent with the results of. clearly shows that the overall performance of all methods is lower for verb similarity.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 42, "end_pos": 50, "type": "METRIC", "confidence": 0.9699975848197937}, {"text": "accuracy", "start_pos": 71, "end_pos": 79, "type": "METRIC", "confidence": 0.998836100101471}]}, {"text": "However, the improvement using both signed clustering as well as thesaurus look is also larger.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Clustering evaluation of K-means, nor- malized cuts, and signed normalized cuts with 750  clusters. Ratio of clusters with containing one or  more antonym pair and ratio of clusters with dis- connected components.", "labels": [], "entities": []}, {"text": " Table 3: Clustering evaluation using SimLex-999  with 120 word pairs having similarity score over  8. SC stands for our signed clustering and NC is  standard normalized cuts. SC(W2V) are the word  clusters from signed clustering using word2vec  and the combined thesauri. Err is the proportion  of dissimilar words (with score < 2) present in the  same cluster.", "labels": [], "entities": [{"text": "Err", "start_pos": 273, "end_pos": 276, "type": "METRIC", "confidence": 0.9966275095939636}]}, {"text": " Table 4: Clustering evaluation using SimVerb- 3500 with 317 word pairs having similarity score  over 8. SC stands for our signed clustering and  NC is standard normalized cuts. SC(W2V) are  the word clusters from signed clustering using  word2vec and the combined thesauri.", "labels": [], "entities": []}, {"text": " Table 5: Sentiment analysis accuracy for binary  predictions of signed clustering algorithm (SC)  versus other models. SC(W2V) are the signed  clusters using word2vec word representations.", "labels": [], "entities": [{"text": "Sentiment analysis", "start_pos": 10, "end_pos": 28, "type": "TASK", "confidence": 0.8900468647480011}, {"text": "accuracy", "start_pos": 29, "end_pos": 37, "type": "METRIC", "confidence": 0.9652689695358276}]}]}