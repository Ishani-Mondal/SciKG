{"title": [{"text": "Feature-Rich Networks for Knowledge Base Completion", "labels": [], "entities": [{"text": "Knowledge Base Completion", "start_pos": 26, "end_pos": 51, "type": "TASK", "confidence": 0.555770993232727}]}], "abstractContent": [{"text": "We propose jointly modelling Knowledge Bases and aligned text with Feature-Rich Networks.", "labels": [], "entities": []}, {"text": "Our models perform Knowledge Base Completion by learning to represent and compose diverse feature types from partially aligned and noisy resources.", "labels": [], "entities": [{"text": "Knowledge Base Completion", "start_pos": 19, "end_pos": 44, "type": "TASK", "confidence": 0.5730312665303549}]}, {"text": "We perform experiments on Freebase utilizing additional entity type information and syntactic textual relations.", "labels": [], "entities": [{"text": "Freebase", "start_pos": 26, "end_pos": 34, "type": "DATASET", "confidence": 0.9591928720474243}]}, {"text": "Our evaluation suggests that the proposed models can better incorporate side information than previously proposed combinations of bilinear models with convolutional neu-ral networks, showing large improvements when scoring the plausibility of unob-served facts with associated textual mentions .", "labels": [], "entities": []}], "introductionContent": [{"text": "Knowledge Bases (KB) are an important resource for many applications such as question answering (), relation extraction () and named entity recognition (.", "labels": [], "entities": [{"text": "question answering", "start_pos": 77, "end_pos": 95, "type": "TASK", "confidence": 0.8710298240184784}, {"text": "relation extraction", "start_pos": 100, "end_pos": 119, "type": "TASK", "confidence": 0.8822862803936005}, {"text": "named entity recognition", "start_pos": 127, "end_pos": 151, "type": "TASK", "confidence": 0.6350245674451193}]}, {"text": "While large collaborative KBs like Freebase ( and DBpedia () contain facts about million of entities, they are mostly incomplete and contain errors.", "labels": [], "entities": [{"text": "Freebase", "start_pos": 35, "end_pos": 43, "type": "DATASET", "confidence": 0.9591442942619324}, {"text": "DBpedia", "start_pos": 50, "end_pos": 57, "type": "DATASET", "confidence": 0.9234601855278015}]}, {"text": "A large amount of research has been dedicated to automatically extend knowledge bases, a task called Entity Linking or Knowledge Base Completion (KBC).", "labels": [], "entities": [{"text": "Entity Linking or Knowledge Base Completion (KBC)", "start_pos": 101, "end_pos": 150, "type": "TASK", "confidence": 0.6614753173457252}]}, {"text": "Proposed approaches to KBC either reason about the internal structure of the KB, or utilize external data sources that indicate relations between the entities in the KB.", "labels": [], "entities": []}, {"text": "Avery successful approach to KBC is latent feature models).", "labels": [], "entities": []}, {"text": "Such models embed the symbols of the KB into a low dimensional space and assign a score to unseen triples as a function of the latent feature representations.", "labels": [], "entities": []}, {"text": "Most approaches define a scoring function as a linear or bilinear operator.", "labels": [], "entities": []}, {"text": "Latent feature models have shown good performance when considering the internal structure of KBs and are scalable to very large datasets.", "labels": [], "entities": []}, {"text": "Utilizing textual data or other external resources for KBC is a challenging task but has the potential of constantly updating KBs as new information becomes available.", "labels": [], "entities": []}, {"text": "Aline of work uses the KB as a means to obtain distant supervision to train relation extraction systems that classify textual mentions into one of the KBs relations (.", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 76, "end_pos": 95, "type": "TASK", "confidence": 0.7329160273075104}]}, {"text": "State-of-the-art approaches for KBC with external textual data are obtained by latent feature models that jointly embed the KB symbols and text relations into the same space (.", "labels": [], "entities": []}, {"text": "The benefit of such models over relation extraction systems is that they can combine both the internal structure of the KB and textual information to reason about the plausibility of unobserved facts.", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 32, "end_pos": 51, "type": "TASK", "confidence": 0.7791516184806824}]}, {"text": "A commonly used approach for augmenting a KBC given an aligned text corpus is by adopting a Universal Schema (, where extracted textual relations between entities are directly added to the knowledge graph and treated the same as KB relations.", "labels": [], "entities": []}, {"text": "This allows application of any latent variable model defined over triples to jointly embed the KB and text relations to the same space.", "labels": [], "entities": []}, {"text": "An extension to the Universal Schema approach was proposed by, where representations of text relations are formed compositionally by Convolutional Neural Networks (CNNs) and then composed with entity vectors by a bilinear model to score a fact.", "labels": [], "entities": []}, {"text": "However, these models show only moderate improvement when incorporating tex-  A limitation of the Universal Schema approach for joint embedding of KBs and text is that information about the correspondence between KB and text relations is only implicitly available through their co-occurrence with entities.", "labels": [], "entities": []}, {"text": "Text relations can often be noisy and pairs of entities can cooccur in the same sentence without sharing a semantic relation.", "labels": [], "entities": []}, {"text": "In addition, there is usually a mismatch in the relations found in the KB and those expressed in text.", "labels": [], "entities": []}, {"text": "The model has to learn the alignment between KB and text relations without explicit evidence of co-occurrence between the two, and then propagate that information through the entity embeddings in order to score unseen KB triples.", "labels": [], "entities": []}, {"text": "We propose a different approach to combine KB and textual evidence, where the textual relations are not part of the same graph but are treated as side evidence.", "labels": [], "entities": []}, {"text": "In our setting, a fact does not necessarily consist of a (sbj, rel, obj) triple, but as an n-tuple where extra elements are formed by extracting additional information from the KB and aligned side resources such as text.", "labels": [], "entities": []}, {"text": "We score the probability of the tuple being true by learning latent representations for each element of the tuple, and then learning a composition and scoring function parameterized by a Multilayer Perceptron (MLP).", "labels": [], "entities": []}, {"text": "We choose MLPs as they area generic method to model interactions between latent features without having to specify the form of a composition operator for tuples of different arity.", "labels": [], "entities": []}, {"text": "When scoring the plausibility of unseen facts, all the side evidence associated with that fact becomes explicit through the n-tuple.", "labels": [], "entities": []}, {"text": "We evaluate the ability of the proposed FeatureRich Networks (FRN) for KBC on the challenging FB15k-237 (.", "labels": [], "entities": [{"text": "FB15k-237", "start_pos": 94, "end_pos": 103, "type": "DATASET", "confidence": 0.9767128825187683}]}, {"text": "We compare the performance of bilinear models to an MLP when facts are represented as simple triples, and the contribution of two additional types of aligned information: entity types and textual relation mentions from aside corpus.", "labels": [], "entities": []}, {"text": "We also evaluate the contribution of initializing feature representations from external models.", "labels": [], "entities": []}, {"text": "Evaluation suggests that while MLPs and bilinear models perform similarly when treating facts as triples of KB symbols, the proposed approach can better utilize additional textual data than a combination of CNNs with bilinear models, showing large improvements in predicting unseen facts when they have linked relation mentions in text.", "labels": [], "entities": []}], "datasetContent": [{"text": "The FB15k237 dataset consists of about 15k entities and 237 relations derived from the FB15k dataset (.", "labels": [], "entities": [{"text": "FB15k237 dataset", "start_pos": 4, "end_pos": 20, "type": "DATASET", "confidence": 0.9906738102436066}, {"text": "FB15k dataset", "start_pos": 87, "end_pos": 100, "type": "DATASET", "confidence": 0.993614137172699}]}, {"text": "This sub-set of relations does not contain redundant relations that can be easily inferred, resulting in a more challenging task compared to the original FB15k dataset.", "labels": [], "entities": [{"text": "FB15k dataset", "start_pos": 154, "end_pos": 167, "type": "DATASET", "confidence": 0.991465836763382}]}, {"text": "There are 310,116 triples in the dataset split into 272,115/17,535/20,466 for training/validation/testing.", "labels": [], "entities": []}, {"text": "In addition to the KB, the dataset includes dependency paths of approximately 2.7 million relation instances of linked entity mentions extracted from the ClueWeb corpus (.", "labels": [], "entities": [{"text": "ClueWeb corpus", "start_pos": 154, "end_pos": 168, "type": "DATASET", "confidence": 0.9365059435367584}]}, {"text": "Evaluation follows the procedure of (.", "labels": [], "entities": []}, {"text": "Given a positive fact in the test set, the subject entity and relation are fixed and models have to rank all facts formed by the object entities appearing in the training set.", "labels": [], "entities": []}, {"text": "The reported metrics are mean reciprocal rank (MRR) and hits@10.", "labels": [], "entities": [{"text": "mean reciprocal rank (MRR)", "start_pos": 25, "end_pos": 51, "type": "METRIC", "confidence": 0.9512903392314911}]}, {"text": "Hits@10 is the fraction of positive facts ranked in the top 10 positions.", "labels": [], "entities": []}, {"text": "Positive facts in the training, validation and test set are removed before ranking.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Evaluation results on the FB15k-237 dataset. Results for F,E,DistMult and their CNN versions  are reported from (Toutanova et al., 2015). With/Without Mentions indicates KB facts with/without  aligned textual relations for their entity pair.", "labels": [], "entities": [{"text": "FB15k-237 dataset", "start_pos": 36, "end_pos": 53, "type": "DATASET", "confidence": 0.9918105602264404}]}]}