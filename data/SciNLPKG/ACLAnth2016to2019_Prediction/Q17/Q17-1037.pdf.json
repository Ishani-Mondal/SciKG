{"title": [{"text": "Anchored Correlation Explanation: Topic Modeling with Minimal Domain Knowledge", "labels": [], "entities": [{"text": "Anchored Correlation Explanation", "start_pos": 0, "end_pos": 32, "type": "TASK", "confidence": 0.5832021633783976}, {"text": "Topic Modeling", "start_pos": 34, "end_pos": 48, "type": "TASK", "confidence": 0.8611778914928436}]}], "abstractContent": [{"text": "While generative models such as Latent Dirichlet Allocation (LDA) have proven fruitful in topic modeling, they often require detailed assumptions and careful specification of hyperparameters.", "labels": [], "entities": [{"text": "Latent Dirichlet Allocation (LDA)", "start_pos": 32, "end_pos": 65, "type": "TASK", "confidence": 0.6024181644121805}]}, {"text": "Such model complexity issues only compound when trying to generalize generative models to incorporate human input.", "labels": [], "entities": [{"text": "generalize generative", "start_pos": 58, "end_pos": 79, "type": "TASK", "confidence": 0.6411251723766327}]}, {"text": "We introduce Correlation Explanation (CorEx), an alternative approach to topic mod-eling that does not assume an underlying gen-erative model, and instead learns maximally informative topics through an information-theoretic framework.", "labels": [], "entities": []}, {"text": "This framework naturally generalizes to hierarchical and semi-supervised extensions with no additional mod-eling assumptions.", "labels": [], "entities": []}, {"text": "In particular, word-level domain knowledge can be flexibly incorporated within CorEx through anchor words, allowing topic separability and representation to be promoted with minimal human intervention.", "labels": [], "entities": []}, {"text": "Across a variety of datasets, metrics, and experiments, we demonstrate that CorEx produces topics that are comparable in quality to those produced by unsupervised and semi-supervised variants of LDA.", "labels": [], "entities": []}], "introductionContent": [{"text": "The majority of topic modeling approaches utilize probabilistic generative models, models which specify mechanisms for how documents are written in order to infer latent topics.", "labels": [], "entities": [{"text": "topic modeling", "start_pos": 16, "end_pos": 30, "type": "TASK", "confidence": 0.7673710286617279}]}, {"text": "These mechanisms maybe explicitly stated, as in Latent Dirichlet Allocation (LDA) (, or implicitly stated, as with matrix factorization techniques).", "labels": [], "entities": [{"text": "Latent Dirichlet Allocation (LDA)", "start_pos": 48, "end_pos": 81, "type": "TASK", "confidence": 0.582376167178154}]}, {"text": "The core generative mechanisms of LDA, in particular, have inspired numerous generalizations that account for additional information, such as the authorship), document labels, or hierarchical structure ( ).", "labels": [], "entities": []}, {"text": "However, these generalizations come at the cost of increasingly elaborate and unwieldy generative assumptions.", "labels": [], "entities": []}, {"text": "While these assumptions allow topic inference to be tractable in the face of additional metadata, they progressively constrain topics to a narrower view of what a topic can be.", "labels": [], "entities": [{"text": "topic inference", "start_pos": 30, "end_pos": 45, "type": "TASK", "confidence": 0.734068363904953}]}, {"text": "Such assumptions are undesirable in contexts where one wishes to minimize model complexity and learn topics without preexisting notions of how those topics originated.", "labels": [], "entities": []}, {"text": "For these reasons, we propose topic modeling byway of Correlation Explanation, an information-theoretic approach to learning latent topics over documents.", "labels": [], "entities": []}, {"text": "Unlike LDA, CorEx does not assume a particular data generating model, and instead searches for topics that are \"maximally informative\" about a set of documents.", "labels": [], "entities": []}, {"text": "By learning informative topics rather than generated topics, we avoid specifying the structure and nature of topics ahead of time.", "labels": [], "entities": []}, {"text": "In addition, the lightweight framework underlying CorEx is versatile and naturally extends to hierarchical and semi-supervised variants with no additional modeling assumptions.", "labels": [], "entities": []}, {"text": "More specifically, we may flexibly incorporate word-level domain knowledge within the CorEx topic model.", "labels": [], "entities": []}, {"text": "Topic models are often susceptible to portraying only dominant themes of documents.", "labels": [], "entities": []}, {"text": "Injecting a topic model, such as CorEx, with domain knowledge can help guide it towards otherwise underrepresented topics that are of importance to the user.", "labels": [], "entities": [{"text": "CorEx", "start_pos": 33, "end_pos": 38, "type": "DATASET", "confidence": 0.9019373655319214}]}, {"text": "By incorporating relevant domain words, we might encourage our topic model to recognize a rare disease that would otherwise be missed in clinical health notes, focus more attention to topics from news articles that can guide relief workers in distributing aid more effectively, or disambiguate aspects of a complex social issue.", "labels": [], "entities": []}, {"text": "Our contributions are as follows: first, we frame CorEx as a topic model and derive an efficient alteration to the CorEx algorithm to exploit sparse data, such as word counts in documents, for dramatic speedups.", "labels": [], "entities": []}, {"text": "Second, we show how domain knowledge can be naturally integrated into CorEx through \"anchor words\" and the information bottleneck.", "labels": [], "entities": []}, {"text": "Third, we demonstrate that CorEx and anchored CorEx produce topics of comparable quality to unsupervised and semi-supervised variants of LDA over several datasets and metrics.", "labels": [], "entities": []}, {"text": "Finally, we carefully detail several anchoring strategies that highlight the versatility of anchored CorEx on a variety of tasks.", "labels": [], "entities": []}], "datasetContent": [{"text": "We perform experiments comparing the running time of CorEx before and after implementing the improvements which exploit sparsity.", "labels": [], "entities": []}, {"text": "We also compare with Scikit-Learn's simple batch implementation of LDA using the variational Bayes algorithm.", "labels": [], "entities": []}, {"text": "Experiments were performed on a four core, Intel i5 chip running at 4 GHz with 32 GB RAM.", "labels": [], "entities": []}, {"text": "We show run time when varying the data size in terms of the number of word types and the number of documents.", "labels": [], "entities": []}, {"text": "We used 50 topics for all runs and set the number of iterations for each run to 10 iterations for LDA and 50 iterations for CorEx.", "labels": [], "entities": [{"text": "CorEx", "start_pos": 124, "end_pos": 129, "type": "DATASET", "confidence": 0.923490047454834}]}, {"text": "We see that CorEx exploiting sparsity is orders of magnitude faster than the naive version and is generally comparable to LDA as the number of documents scales.", "labels": [], "entities": [{"text": "CorEx exploiting sparsity", "start_pos": 12, "end_pos": 37, "type": "TASK", "confidence": 0.65675617257754}]}, {"text": "The slope on the log-log plot suggests a linear dependence of running time on the dataset size, as expected.", "labels": [], "entities": []}, {"text": "CorEx does not explicitly attempt to learn a generative model and, thus, traditional measures such as perplexity are not appropriate for model comparison against LDA.", "labels": [], "entities": [{"text": "CorEx", "start_pos": 0, "end_pos": 5, "type": "DATASET", "confidence": 0.9013534188270569}]}, {"text": "Furthermore, it is well-known that perplexity and held-out log-likelihood do not necessarily correlate with human evaluation of semantic topic quality ().", "labels": [], "entities": []}, {"text": "Therefore, we measure the semantic topic quality using Mimno et al.'s (2011) UMass automatic topic coherence score, which correlates with human judgments.", "labels": [], "entities": []}, {"text": "We also evaluate the models in terms of multiclass logistic regression document classification, where the feature set of each document is its topic distribution.", "labels": [], "entities": [{"text": "multiclass logistic regression document classification", "start_pos": 40, "end_pos": 94, "type": "TASK", "confidence": 0.598166424036026}]}, {"text": "We perform all document classification tasks using a 60/40 trainingtest split.", "labels": [], "entities": [{"text": "document classification tasks", "start_pos": 15, "end_pos": 44, "type": "TASK", "confidence": 0.8051173686981201}]}, {"text": "Finally, we measure how well each topic model does at clustering documents.", "labels": [], "entities": [{"text": "clustering documents", "start_pos": 54, "end_pos": 74, "type": "TASK", "confidence": 0.8908117115497589}]}, {"text": "We obtain a clustering by assigning each document to the topic that occurs with the highest probability.", "labels": [], "entities": []}, {"text": "We then measure the quality within clusters (homogeneity) and across clusters (adjusted mutual information).", "labels": [], "entities": []}, {"text": "The highest possible value for both measures is one.", "labels": [], "entities": []}, {"text": "We do not report clustering metrics on the clinical health notes because the documents are multi-label and, in that case, the metrics are not well-defined.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Examples of topics learned by the CorEx topic  model. Words are ranked according to mutual informa- tion with the topic, and topics are ranked according to the  amount of total correlation they explain. Topic models  were run with 50 topics on the Reliefweb and 20 News- groups datasets, and 30 topics on the clinical health notes.", "labels": [], "entities": [{"text": "Reliefweb and 20 News- groups datasets", "start_pos": 258, "end_pos": 296, "type": "DATASET", "confidence": 0.8470017824854169}]}]}