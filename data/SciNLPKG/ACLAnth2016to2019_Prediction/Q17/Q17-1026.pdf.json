{"title": [{"text": "Fully Character-Level Neural Machine Translation without Explicit Segmentation", "labels": [], "entities": [{"text": "Neural Machine Translation", "start_pos": 22, "end_pos": 48, "type": "TASK", "confidence": 0.6518787940343221}]}], "abstractContent": [{"text": "Most existing machine translation systems operate at the level of words, relying on explicit segmentation to extract tokens.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 14, "end_pos": 33, "type": "TASK", "confidence": 0.7069289684295654}]}, {"text": "We introduce a neural machine translation (NMT) model that maps a source character sequence to a target character sequence without any seg-mentation.", "labels": [], "entities": [{"text": "neural machine translation (NMT)", "start_pos": 15, "end_pos": 47, "type": "TASK", "confidence": 0.848841259876887}]}, {"text": "We employ a character-level con-volutional network with max-pooling at the encoder to reduce the length of source representation , allowing the model to be trained at a speed comparable to subword-level models while capturing local regularities.", "labels": [], "entities": []}, {"text": "Our character-to-character model outperforms a recently proposed baseline with a subword-level encoder on WMT'15 DE-EN and CS-EN, and gives comparable performance on FI-EN and RU-EN.", "labels": [], "entities": [{"text": "WMT'15 DE-EN", "start_pos": 106, "end_pos": 118, "type": "DATASET", "confidence": 0.8687706589698792}, {"text": "FI-EN", "start_pos": 166, "end_pos": 171, "type": "DATASET", "confidence": 0.802878737449646}]}, {"text": "We then demonstrate that it is possible to share a single character-level encoder across multiple languages by training a model on a many-to-one translation task.", "labels": [], "entities": []}, {"text": "In this multilingual setting, the character-level encoder significantly outper-forms the subword-level encoder on all the language pairs.", "labels": [], "entities": []}, {"text": "We observe that on CS-EN, FI-EN and RU-EN, the quality of the multilingual character-level translation even surpasses the models specifically trained on that language pair alone, both in terms of the BLEU score and human judgment.", "labels": [], "entities": [{"text": "FI-EN", "start_pos": 26, "end_pos": 31, "type": "METRIC", "confidence": 0.8006728887557983}, {"text": "BLEU score", "start_pos": 200, "end_pos": 210, "type": "METRIC", "confidence": 0.9812605381011963}]}], "introductionContent": [{"text": "Nearly all previous work in machine translation has been at the level of words.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 28, "end_pos": 47, "type": "TASK", "confidence": 0.7808671593666077}]}, {"text": "Aside from our intu- * The majority of this work was completed while the author was visiting New York University.", "labels": [], "entities": []}, {"text": "itive understanding of word as a basic unit of meaning, one reason behind this is that sequences are significantly longer when represented in characters, compounding the problem of data sparsity and modeling long-range dependencies.", "labels": [], "entities": []}, {"text": "This has driven NMT research to be almost exclusively word-level ().", "labels": [], "entities": [{"text": "NMT", "start_pos": 16, "end_pos": 19, "type": "TASK", "confidence": 0.9409310221672058}]}, {"text": "Despite their remarkable success, word-level NMT models suffer from several major weaknesses.", "labels": [], "entities": []}, {"text": "For one, they are unable to model rare, out-ofvocabulary words, making them limited in translating languages with rich morphology such as Czech, Finnish and Turkish.", "labels": [], "entities": []}, {"text": "If one uses a large vocabulary to combat this (, the complexity of training and decoding grows linearly with respect to the target vocabulary size, leading to a vicious cycle.", "labels": [], "entities": []}, {"text": "To address this, we present a fully character-level NMT model that maps a character sequence in a source language to a character sequence in a target language.", "labels": [], "entities": []}, {"text": "We show that our model outperforms a baseline with a subword-level encoder on DE-EN and CS-EN, and achieves a comparable result on FI-EN and RU-EN.", "labels": [], "entities": [{"text": "FI-EN", "start_pos": 131, "end_pos": 136, "type": "METRIC", "confidence": 0.6855812072753906}]}, {"text": "A purely character-level NMT model with a basic encoder was proposed as a baseline by, but training it was prohibitively slow.", "labels": [], "entities": []}, {"text": "We were able to train our model at a reasonable speed by drastically reducing the length of source sentence representation using a stack of convolutional, pooling and highway layers.", "labels": [], "entities": []}, {"text": "One advantage of character-level models is that they are better suited for multilingual translation than their word-level counterparts which require a separate word vocabulary for each language.", "labels": [], "entities": []}, {"text": "We verify this by training a single model to translate four languages (German, Czech, Finnish and Russian) to English.", "labels": [], "entities": []}, {"text": "Our multilingual character-level model outperforms the subword-level baseline by a considerable margin in all four language pairs, strongly indicating that a character-level model is more flexible in assigning its capacity to different language pairs.", "labels": [], "entities": []}, {"text": "Furthermore, we observe that our multilingual character-level translation even exceeds the quality of bilingual translation in three out of four language pairs, both in BLEU score metric and human evaluation.", "labels": [], "entities": [{"text": "BLEU score metric", "start_pos": 169, "end_pos": 186, "type": "METRIC", "confidence": 0.972905158996582}]}, {"text": "This demonstrates excellent parameter efficiency of character-level translation in a multilingual setting.", "labels": [], "entities": [{"text": "character-level translation", "start_pos": 52, "end_pos": 79, "type": "TASK", "confidence": 0.757064551115036}]}, {"text": "We also showcase our model's ability to handle intra-sentence codeswitching while performing language identification on the fly.", "labels": [], "entities": [{"text": "language identification", "start_pos": 93, "end_pos": 116, "type": "TASK", "confidence": 0.708636000752449}]}, {"text": "The contributions of this work are twofold: we empirically show that (1) we can train character-tocharacter NMT model without any explicit segmentation; and (2) we can share a single character-level encoder across multiple languages to build a multilingual translation system without increasing the model size.", "labels": [], "entities": []}], "datasetContent": [{"text": "We use all available parallel data on the four language pairs from WMT'15: DE-EN, CS-EN, FI-EN and RU-EN.", "labels": [], "entities": [{"text": "WMT'15", "start_pos": 67, "end_pos": 73, "type": "DATASET", "confidence": 0.9260830283164978}, {"text": "FI-EN", "start_pos": 89, "end_pos": 94, "type": "METRIC", "confidence": 0.8990350365638733}]}, {"text": "For the bpe2char baselines, we only use sentence pairs where the source is no longer than 50 subword symbols.", "labels": [], "entities": []}, {"text": "For our char2char models, we only use pairs where the source sentence is no longer than 450 characters.", "labels": [], "entities": []}, {"text": "For all the language pairs apart from FI-EN, we use newstest-2013 as a development set and newstest-2014 and newstest-2015 as test sets.", "labels": [], "entities": [{"text": "FI-EN", "start_pos": 38, "end_pos": 43, "type": "DATASET", "confidence": 0.9274030327796936}]}, {"text": "For FI-EN, we use newsdev-2015 and newstest-2015 as development and test sets, respectively.", "labels": [], "entities": [{"text": "FI-EN", "start_pos": 4, "end_pos": 9, "type": "DATASET", "confidence": 0.8843801021575928}]}, {"text": "We tokenize 2 each corpus using the script from Moses.", "labels": [], "entities": []}, {"text": "When training bilingual bpe2char models, we extract 20,000 BPE operations from each of the source and target corpus using a script from.", "labels": [], "entities": []}, {"text": "This gives a source BPE vocabulary of size 20k\u221224k for each language.", "labels": [], "entities": []}, {"text": "In this section, we first establish our main hypotheses for introducing character-level and multilingual models, and investigate whether our observations support or disagree with our hypotheses.", "labels": [], "entities": []}, {"text": "From our empirical results, we want to verify: (1) if fully character-level translation outperforms subwordlevel translation, (2) in which setting and to what extent is multilingual translation beneficial and (3) if multilingual, character-level translation achieves superior performance to other models.", "labels": [], "entities": []}, {"text": "We outline our results with respect to each hypothesis below.", "labels": [], "entities": []}, {"text": "(1) Character-level vs. subword-level Ina bilingual setting, the char2char model outperforms both subword-level baselines on DE-EN (a-c)) and CS-EN (f-h)).", "labels": [], "entities": []}, {"text": "On the other two language pairs, it exceeds the bpe2bpe model and achieves a similar performance with the bpe2char baseline (k-m) and (p-r)).", "labels": [], "entities": []}, {"text": "We conclude that the proposed character-level model is comparable to or better than both subword-level baselines.", "labels": [], "entities": []}, {"text": "Meanwhile, in a multilingual setting, the character-level encoder significantly surpasses the subword-level encoder consistently in all the language pairs (d-e), (i-j), (n-o) and (s-t)).", "labels": [], "entities": []}, {"text": "From this, we conclude that translating at the level of characters allows the model to discover shared constructs between languages more effectively.", "labels": [], "entities": []}, {"text": "This also demonstrates that the character-level model is more flexible in assigning model capacity to different language pairs.", "labels": [], "entities": []}, {"text": "(2) Multilingual vs. bilingual At the level of characters, we note that multilingual translation is indeed strongly beneficial.", "labels": [], "entities": [{"text": "multilingual translation", "start_pos": 72, "end_pos": 96, "type": "TASK", "confidence": 0.70476034283638}]}, {"text": "On the test sets, the multilingual character-level model outperforms the singlepair character-level model by 2.64 BLEU in FI-EN (m, o)) and 0.78 BLEU in CS-EN (Table 5 (h, j)), while achieving comparable results on DE-EN and RU-EN.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 114, "end_pos": 118, "type": "METRIC", "confidence": 0.9948063492774963}, {"text": "FI-EN", "start_pos": 122, "end_pos": 127, "type": "METRIC", "confidence": 0.8790159225463867}, {"text": "BLEU", "start_pos": 145, "end_pos": 149, "type": "METRIC", "confidence": 0.9943968057632446}, {"text": "DE-EN", "start_pos": 215, "end_pos": 220, "type": "DATASET", "confidence": 0.8770347833633423}]}, {"text": "At the level of subwords, on the other hand, we do not observe the same degree of performance benefit.", "labels": [], "entities": []}, {"text": "The multilingual bpe2char model requires much more updates to reach the performance of the bilingual bpe2char model (see).", "labels": [], "entities": []}, {"text": "This: Human evaluation results for adequacy and fluency.", "labels": [], "entities": []}, {"text": "We present both the averaged raw scores (Raw) and the averaged standardized scores (Stnd.).", "labels": [], "entities": []}, {"text": "Standardized adequacy is used to rank the systems and standardized fluency is used to break ties.", "labels": [], "entities": []}, {"text": "A positive standardized score should be interpreted as the number of standard deviations above this particular worker's mean score that this system scored on average.", "labels": [], "entities": [{"text": "standardized score", "start_pos": 11, "end_pos": 29, "type": "METRIC", "confidence": 0.9086461067199707}]}, {"text": "For each language pair, we boldface the best performing model with statistical significance.", "labels": [], "entities": []}, {"text": "When there is a tie, we boldface both systems.", "labels": [], "entities": []}, {"text": "suggests that learning useful subword segmentation across languages is difficult.", "labels": [], "entities": [{"text": "subword segmentation across languages", "start_pos": 30, "end_pos": 67, "type": "TASK", "confidence": 0.8235560655593872}]}, {"text": "(3) Multilingual char2char vs. others The multilingual char2char model is the best performer in CS-EN, FI-EN and RU-EN (j, o, t)), and is the runner-up in DE-EN (e)).", "labels": [], "entities": [{"text": "FI-EN", "start_pos": 103, "end_pos": 108, "type": "METRIC", "confidence": 0.8462771773338318}]}, {"text": "The fact that the multilingual char2char model outperforms the single-pair models goes to show the parameter efficiency of character-level translation: instead of training N separate models for N language pairs, it is possible to get a better performance with a single multilingual character-level model.", "labels": [], "entities": [{"text": "character-level translation", "start_pos": 123, "end_pos": 150, "type": "TASK", "confidence": 0.7065617740154266}]}, {"text": "It is well known that automatic evaluation metrics such as BLEU encourage reference-like translations and do not fully capture true translation quality).", "labels": [], "entities": [{"text": "BLEU", "start_pos": 59, "end_pos": 63, "type": "METRIC", "confidence": 0.9945940375328064}]}, {"text": "Therefore, we also carryout a recently proposed evaluation from where we have human assessors rate both (1) adequacy; and (2) fluency of each system translation on a scale from 0 to 100 via Amazon Mechanical Turk.", "labels": [], "entities": [{"text": "Amazon Mechanical Turk", "start_pos": 190, "end_pos": 212, "type": "DATASET", "confidence": 0.9379934072494507}]}, {"text": "Adequacy is the degree to which assessors agree that the system translation expresses the meaning of the reference translation.", "labels": [], "entities": []}, {"text": "Fluency is evaluated using system translation alone without any reference translation.", "labels": [], "entities": [{"text": "Fluency", "start_pos": 0, "end_pos": 7, "type": "METRIC", "confidence": 0.8799676895141602}, {"text": "system translation", "start_pos": 27, "end_pos": 45, "type": "TASK", "confidence": 0.6892290860414505}]}, {"text": "Approximately 1K Turkers assessed a single test set (3K sentences in newstest-2014) for each system and language pair.", "labels": [], "entities": [{"text": "newstest-2014", "start_pos": 69, "end_pos": 82, "type": "DATASET", "confidence": 0.956313967704773}]}, {"text": "Each Turker conducted a minimum of 100 assessments for quality control, and the set of scores generated by each Turker was standardized to remove any bias in the individual's scoring strategy.", "labels": [], "entities": []}, {"text": "We consider three models (bilingual bpe2char, bilingual char2char and multilingual char2char) for the human evaluation.", "labels": [], "entities": []}, {"text": "We leave out the multilingual bpe2char model to minimize the number of similar systems to improve the interpretability of the evaluation overall.", "labels": [], "entities": []}, {"text": "For DE-EN, we observe that the multilingual char2char and bilingual char2char models are tied with respect to both adequacy and fluency (Table 6 (b-c)).", "labels": [], "entities": []}, {"text": "For CS-EN, the multilingual char2char and bilingual bpe2char models are tied for adequacy.", "labels": [], "entities": []}, {"text": "However, the multilingual char2char model yields significantly better fluency).", "labels": [], "entities": []}, {"text": "For FI-EN and RU-EN, the multilingual char2char model is tied with the bilingual char2char model with respect to adequacy, but significantly outperforms all other models in fluency (g-i, j-l)).", "labels": [], "entities": [{"text": "FI-EN", "start_pos": 4, "end_pos": 9, "type": "DATASET", "confidence": 0.7084450125694275}]}, {"text": "Overall, the improvement in translation quality yielded by the multilingual character-level model mainly comes from fluency.", "labels": [], "entities": [{"text": "translation", "start_pos": 28, "end_pos": 39, "type": "TASK", "confidence": 0.9705412983894348}]}, {"text": "We conjecture that because the English decoder of the multilingual model is tuned in on all the training sentence pairs, it Why are we to be friends ? char2char Why should we not be friends ? (b) Rare words", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Bilingual model architectures. The char2char  model uses 200 filters of width 1, 200 filters of width 2,  \u00b7 \u00b7 \u00b7 and 300 filters of width 8.", "labels": [], "entities": []}, {"text": " Table 2: Multilingual model architectures.", "labels": [], "entities": []}, {"text": " Table 3: The minibatch size of each language (second  row) is proportionate to the number of sentence pairs in  each corpus (first row).", "labels": [], "entities": []}, {"text": " Table 5: BLEU scores of five different models on four language pairs. For each test or development set, the best  performing model is shown in bold. ( * ) results are taken from (Firat et al., 2016a).", "labels": [], "entities": [{"text": "BLEU", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9934784173965454}]}, {"text": " Table 6: Human evaluation results for adequacy and fluency. We present both the averaged raw scores (Raw) and the  averaged standardized scores (Stnd.). Standardized adequacy is used to rank the systems and standardized fluency is  used to break ties. A positive standardized score should be interpreted as the number of standard deviations above  this particular worker's mean score that this system scored on average. For each language pair, we boldface the best  performing model with statistical significance. When there is a tie, we boldface both systems.", "labels": [], "entities": []}, {"text": " Table 9: Speed comparison. The second column shows  the time taken to execute 1,000 training updates. The  model makes each update after having seen one mini- batch.", "labels": [], "entities": []}]}