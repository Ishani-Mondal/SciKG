{"title": [{"text": "Shift-Reduce Constituent Parsing with Neural Lookahead Features", "labels": [], "entities": [{"text": "Shift-Reduce Constituent Parsing", "start_pos": 0, "end_pos": 32, "type": "TASK", "confidence": 0.8568019866943359}]}], "abstractContent": [{"text": "Transition-based models can be fast and accurate for constituent parsing.", "labels": [], "entities": [{"text": "constituent parsing", "start_pos": 53, "end_pos": 72, "type": "TASK", "confidence": 0.6962503790855408}]}, {"text": "Compared with chart-based models, they leverage richer features by extracting history information from a parser stack, which consists of a sequence of non-local constituents.", "labels": [], "entities": []}, {"text": "On the other hand, during incremental parsing, constituent information on the right hand side of the current word is not utilized, which is a relative weakness of shift-reduce parsing.", "labels": [], "entities": []}, {"text": "To address this limitation, we leverage a fast neural model to extract lookahead features.", "labels": [], "entities": []}, {"text": "In particular, we build a bidirectional LSTM model, which leverages full sentence information to predict the hierarchy of constituents that each word starts and ends.", "labels": [], "entities": []}, {"text": "The results are then passed to a strong transition-based constituent parser as lookahead features.", "labels": [], "entities": []}, {"text": "The resulting parser gives 1.3% absolute improvement in WSJ and 2.3% in CTB compared to the baseline, giving the highest reported accuracies for fully-supervised parsing.", "labels": [], "entities": [{"text": "WSJ", "start_pos": 56, "end_pos": 59, "type": "METRIC", "confidence": 0.9222093224525452}, {"text": "CTB", "start_pos": 72, "end_pos": 75, "type": "METRIC", "confidence": 0.9928880333900452}, {"text": "accuracies", "start_pos": 130, "end_pos": 140, "type": "METRIC", "confidence": 0.9886930584907532}]}], "introductionContent": [{"text": "Transition-based constituent parsers are fast and accurate, performing incremental parsing using a sequence of state transitions in linear time.", "labels": [], "entities": [{"text": "Transition-based constituent parsers", "start_pos": 0, "end_pos": 36, "type": "TASK", "confidence": 0.5820338428020477}]}, {"text": "Pioneering models rely on a classifier to make local decisions, searching greedily for local transitions to build a parse tree).", "labels": [], "entities": []}, {"text": "use abeam search framework, which preserves linear time complexity of greedy search, while alleviating the disadvantage of error propagation.", "labels": [], "entities": []}, {"text": "The model gives state-of-the-art accuracies at a speed of 89 sentences per second on the standard WSJ benchmark.", "labels": [], "entities": [{"text": "WSJ benchmark", "start_pos": 98, "end_pos": 111, "type": "DATASET", "confidence": 0.9314437806606293}]}, {"text": "exploit rich features by extracting history information from a parser stack, which consists of a sequence of non-local constituents.", "labels": [], "entities": []}, {"text": "However, due to the incremental nature of shiftreduce parsing, the right-hand side constituents of the current word cannot be used to guide the action at each step.", "labels": [], "entities": [{"text": "shiftreduce parsing", "start_pos": 42, "end_pos": 61, "type": "TASK", "confidence": 0.6511930823326111}]}, {"text": "Such lookahead features) correspond to the outside scores in chart parsing, which has been effective for obtaining improved accuracies.", "labels": [], "entities": [{"text": "chart parsing", "start_pos": 61, "end_pos": 74, "type": "TASK", "confidence": 0.7202176749706268}]}, {"text": "To leverage such information for improving shiftreduce parsing, we propose a novel neural model to predict the constituent hierarchy related to each word before parsing.", "labels": [], "entities": [{"text": "shiftreduce parsing", "start_pos": 43, "end_pos": 62, "type": "TASK", "confidence": 0.6401412039995193}]}, {"text": "Our idea is inspired by the work of and, which shows that shallow syntactic information gathered over the word sequence can be utilized for pruning chart parsers, improving chart parsing speed without sacrificing accuracies.", "labels": [], "entities": [{"text": "pruning chart parsers", "start_pos": 140, "end_pos": 161, "type": "TASK", "confidence": 0.7224392493565878}, {"text": "chart parsing", "start_pos": 173, "end_pos": 186, "type": "TASK", "confidence": 0.6656010150909424}]}, {"text": "For example, predict constituent boundary information on words as a preprocessing step, and use such information to prune the chart.", "labels": [], "entities": []}, {"text": "Since such information is much lighterweight compared to full parsing, it can be predicted relatively accurately using sequence labellers.", "labels": [], "entities": []}, {"text": "Different from, we collect lookahead constituent information for shift-reduce parsing, rather than pruning information for chart parsing.", "labels": [], "entities": [{"text": "shift-reduce parsing", "start_pos": 65, "end_pos": 85, "type": "TASK", "confidence": 0.5210854262113571}, {"text": "chart parsing", "start_pos": 123, "end_pos": 136, "type": "TASK", "confidence": 0.7200422286987305}]}, {"text": "Our main concern is improving the accuracy rather than improving the speed.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 34, "end_pos": 42, "type": "METRIC", "confidence": 0.9995410442352295}, {"text": "speed", "start_pos": 69, "end_pos": 74, "type": "METRIC", "confidence": 0.9980252981185913}]}, {"text": "Accordingly, our model should predict the constituent hierarchy for each word rather than simple boundary information.", "labels": [], "entities": []}, {"text": "For example, in(a), the constituent hierarchy that the word \"The\" starts is \"S \u2192 NP\", and the constituent hierarchy that the word \"table\" ends is \"S \u2192 VP \u2192 NP \u2192 PP \u2192 NP\".", "labels": [], "entities": []}, {"text": "For each word, we predict both the constituent hierarchy it starts and the constituent hierarchy it ends, using them as lookahead features.", "labels": [], "entities": []}, {"text": "First, it is significantly more difficult compared to simple sequence labelling, since two sequences of constituent hierarchies must be predicted for each word in the input sequence.", "labels": [], "entities": []}, {"text": "Second, for high accuracies, global features from the full sentence are necessary since constituent hierarchies contain rich structural information.", "labels": [], "entities": []}, {"text": "Third, to retain high speed for shift-reduce parsing, lookahead feature prediction must be executed efficiently.", "labels": [], "entities": [{"text": "lookahead feature prediction", "start_pos": 54, "end_pos": 82, "type": "TASK", "confidence": 0.5954926311969757}]}, {"text": "It is highly difficult to build such a model using manual discrete features and structured search.", "labels": [], "entities": []}, {"text": "Fortunately, sequential recurrent neural networks (RNNs) are remarkably effective models to encode the full input sentence.", "labels": [], "entities": []}, {"text": "We leverage RNNs for building our constituent hierarchy predictor.", "labels": [], "entities": []}, {"text": "In particular, an LSTM) is used to learn global features automatically from the input words.", "labels": [], "entities": []}, {"text": "For each word, a second LSTM is then used to generate the constituent hierarchies greedily using features from the hidden layer of the first LSTM, in the same way a neural language model decoder generates output sentences for machine translation ().", "labels": [], "entities": [{"text": "machine translation", "start_pos": 226, "end_pos": 245, "type": "TASK", "confidence": 0.7629496157169342}]}, {"text": "The resulting model solves all three challenges raised above.", "labels": [], "entities": []}, {"text": "For fullysupervised learning, we learn word embeddings as part of the model parameters.", "labels": [], "entities": []}, {"text": "In the standard WSJ () and CTB 5.1 tests (), our parser gives 1.3 F 1 and 2.3 F 1 improvement, respectively, over the Induction Rules: Figure 2: Deduction system for the baseline shiftreduce parsing process.", "labels": [], "entities": [{"text": "WSJ", "start_pos": 16, "end_pos": 19, "type": "DATASET", "confidence": 0.7569524049758911}, {"text": "CTB 5.1 tests", "start_pos": 27, "end_pos": 40, "type": "DATASET", "confidence": 0.900648852189382}, {"text": "F 1", "start_pos": 66, "end_pos": 69, "type": "METRIC", "confidence": 0.9859575033187866}, {"text": "F 1", "start_pos": 78, "end_pos": 81, "type": "METRIC", "confidence": 0.856059193611145}, {"text": "shiftreduce parsing process", "start_pos": 179, "end_pos": 206, "type": "TASK", "confidence": 0.6677196423212687}]}, {"text": "baseline of, resulting in a accuracy of 91.7 F 1 for English and 85.5 F 1 for Chinese, which are the best for fully-supervised models in the literature.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 28, "end_pos": 36, "type": "METRIC", "confidence": 0.9996479749679565}, {"text": "F 1", "start_pos": 45, "end_pos": 48, "type": "METRIC", "confidence": 0.9710002839565277}, {"text": "F 1", "start_pos": 70, "end_pos": 73, "type": "METRIC", "confidence": 0.9601351022720337}]}, {"text": "We release our code, based on ZPar (, at https://github.com/SUTDNLP/LookAheadConparser.", "labels": [], "entities": []}], "datasetContent": [{"text": "Our English data are taken from the Wall Street Journal (WSJ) sections of the Penn Treebank ().", "labels": [], "entities": [{"text": "Wall Street Journal (WSJ) sections of the Penn Treebank", "start_pos": 36, "end_pos": 91, "type": "DATASET", "confidence": 0.9449050751599398}]}, {"text": "We use sections 2-21 for training, section 24 for system development, and section 23 for final performance evaluation.", "labels": [], "entities": [{"text": "system development", "start_pos": 50, "end_pos": 68, "type": "TASK", "confidence": 0.8113877773284912}]}, {"text": "Our Chinese data are taken from the version 5.1 of the Penn Chinese Treebank (CTB) (: Performance of the constituent hierarchy predictor and the corresponding parser on the WSJ dev dataset.", "labels": [], "entities": [{"text": "Penn Chinese Treebank (CTB)", "start_pos": 55, "end_pos": 82, "type": "DATASET", "confidence": 0.9737700323263804}, {"text": "WSJ dev dataset", "start_pos": 173, "end_pos": 188, "type": "DATASET", "confidence": 0.9260388215382894}]}, {"text": "n-layer denotes an LSTM model with n hidden layers.", "labels": [], "entities": []}, {"text": "data, we adopt ZPar 2 for POS tagging, and use tenfold jackknifing to assign POS tags automatically to the training data.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 26, "end_pos": 37, "type": "TASK", "confidence": 0.859245240688324}]}, {"text": "In addition, we use ten-fold jackknifing to assign constituent hierarchies automatically to the training data for training the parser using the constituent hierarchy predictor.", "labels": [], "entities": []}, {"text": "We use F 1 score to evaluate constituent hierarchy prediction.", "labels": [], "entities": [{"text": "F 1 score", "start_pos": 7, "end_pos": 16, "type": "METRIC", "confidence": 0.9808862805366516}, {"text": "constituent hierarchy prediction", "start_pos": 29, "end_pos": 61, "type": "TASK", "confidence": 0.6771393616994222}]}, {"text": "For example, if the prediction is \"S \u2192 S \u2192 VP \u2192 NP\" and the gold is \"S \u2192 NP \u2192 NP\", the evaluation process matches the two hierarchies bottom-up.", "labels": [], "entities": []}, {"text": "The precision is 2/4 = 0.5, the recall is 2/3 = 0.66 and the F 1 score is 0.57.", "labels": [], "entities": [{"text": "precision", "start_pos": 4, "end_pos": 13, "type": "METRIC", "confidence": 0.9997424483299255}, {"text": "recall", "start_pos": 32, "end_pos": 38, "type": "METRIC", "confidence": 0.999832034111023}, {"text": "F 1 score", "start_pos": 61, "end_pos": 70, "type": "METRIC", "confidence": 0.9888394673665365}]}, {"text": "A label is counted as correct if and only if it occurs at the correct position.", "labels": [], "entities": []}, {"text": "We use EVALB to evaluate parsing performance, including labelled precision (LP ), labelled recall (LR), and bracketing F 1 .", "labels": [], "entities": [{"text": "parsing", "start_pos": 25, "end_pos": 32, "type": "TASK", "confidence": 0.9736502170562744}, {"text": "labelled precision (LP )", "start_pos": 56, "end_pos": 80, "type": "METRIC", "confidence": 0.8405893325805665}, {"text": "recall (LR)", "start_pos": 91, "end_pos": 102, "type": "METRIC", "confidence": 0.92900650203228}, {"text": "bracketing F 1", "start_pos": 108, "end_pos": 122, "type": "METRIC", "confidence": 0.726330985625585}]}], "tableCaptions": [{"text": " Table 4: Performance of the constituent hierarchy  predictor and the corresponding parser on the WSJ  dev dataset. n-layer denotes an LSTM model with n  hidden layers.", "labels": [], "entities": [{"text": "WSJ  dev dataset", "start_pos": 98, "end_pos": 114, "type": "DATASET", "confidence": 0.9214442571004232}]}, {"text": " Table 5: Performance of the constituent hierarchy  predictor and the corresponding parser on the WSJ  dev dataset. all denotes the proposed model with- out ablation. wins denotes input windows. chars  denotes character-based attention.", "labels": [], "entities": [{"text": "WSJ  dev dataset", "start_pos": 98, "end_pos": 114, "type": "DATASET", "confidence": 0.9387868046760559}]}, {"text": " Table 6: Comparison of related work on the WSJ  test set. * denotes neural parsing;  \u2020 denotes methods  using a shift-reduce framework.", "labels": [], "entities": [{"text": "WSJ  test set", "start_pos": 44, "end_pos": 57, "type": "DATASET", "confidence": 0.9442145228385925}, {"text": "neural parsing", "start_pos": 69, "end_pos": 83, "type": "TASK", "confidence": 0.7321871221065521}]}, {"text": " Table 7: Comparison of related work on the CTB5.1  test set. * denotes neural parsing;  \u2020 denotes methods  using a shift-reduce framework;  \u2021 denotes joint POS  tagging and parsing.", "labels": [], "entities": [{"text": "CTB5.1  test set", "start_pos": 44, "end_pos": 60, "type": "DATASET", "confidence": 0.9781359632809957}, {"text": "neural parsing", "start_pos": 72, "end_pos": 86, "type": "TASK", "confidence": 0.7417733073234558}, {"text": "POS  tagging", "start_pos": 157, "end_pos": 169, "type": "TASK", "confidence": 0.800464391708374}]}, {"text": " Table 8: Comparison of running times on the test  set, where the time for loading models is excluded.  The running times of related parsers are taken from  Zhu et al. (2013).", "labels": [], "entities": []}, {"text": " Table 9: Comparison between the parsers with lookahead features on different phrases types, with the  corresponding constituent hierarchy predictor performances.", "labels": [], "entities": []}]}