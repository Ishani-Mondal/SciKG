{"title": [{"text": "Aspect-augmented Adversarial Networks for Domain Adaptation", "labels": [], "entities": [{"text": "Domain Adaptation", "start_pos": 42, "end_pos": 59, "type": "TASK", "confidence": 0.7431251406669617}]}], "abstractContent": [{"text": "We introduce a neural method for transfer learning between two (source and target) classification tasks or aspects over the same domain.", "labels": [], "entities": [{"text": "transfer learning between two (source and target) classification tasks", "start_pos": 33, "end_pos": 103, "type": "TASK", "confidence": 0.7687809250571511}]}, {"text": "Rather than training on target labels , we use a few keywords pertaining to source and target aspects indicating sentence relevance instead of document class labels.", "labels": [], "entities": []}, {"text": "Documents are encoded by learning to embed and softly select relevant sentences in an aspect-dependent manner.", "labels": [], "entities": []}, {"text": "A shared classi-fier is trained on the source encoded documents and labels, and applied to target encoded documents.", "labels": [], "entities": []}, {"text": "We ensure transfer through aspect-adversarial training so that encoded documents are, as sets, aspect-invariant.", "labels": [], "entities": []}, {"text": "Experimental results demonstrate that our approach outperforms different baselines and model variants on two datasets, yielding an improvement of 27% on a pathology dataset and 5% on a review dataset.", "labels": [], "entities": []}], "introductionContent": [{"text": "Many NLP problems are naturally multitask classification problems.", "labels": [], "entities": [{"text": "multitask classification", "start_pos": 32, "end_pos": 56, "type": "TASK", "confidence": 0.6862088441848755}]}, {"text": "For instance, values extracted for different fields from the same document are often dependent as they share the same context.", "labels": [], "entities": []}, {"text": "Existing systems rely on this dependence (transfer across fields) to improve accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 77, "end_pos": 85, "type": "METRIC", "confidence": 0.996708869934082}]}, {"text": "In this paper, we consider aversion of this problem where there is a clear dependence between two tasks but annotations are available only for the source task.", "labels": [], "entities": []}, {"text": "For example, Figure 1: A snippet of abreast pathology report with diagnosis results for two types of disease (aspects): carcinoma (IDC) and lymph invasion (LVI).", "labels": [], "entities": []}, {"text": "Note how the same phrase indicating positive results (e.g. identified) is applicable to both aspects.", "labels": [], "entities": []}, {"text": "A transfer model learns to map other key phrases (e.g. Grade 3) to such shared indicators.", "labels": [], "entities": []}, {"text": "the target goal maybe to classify pathology reports (shown in) for the presence of lymph invasion but training data are available only for carcinoma in the same reports.", "labels": [], "entities": []}, {"text": "We call this problem aspect transfer as the objective is to learn to classify examples differently, focusing on different aspects, without access to target aspect labels.", "labels": [], "entities": [{"text": "aspect transfer", "start_pos": 21, "end_pos": 36, "type": "TASK", "confidence": 0.7122507393360138}]}, {"text": "Clearly, such transfer learning is possible only with auxiliary information relating the tasks together.", "labels": [], "entities": [{"text": "transfer learning", "start_pos": 14, "end_pos": 31, "type": "TASK", "confidence": 0.9424221217632294}]}, {"text": "The key challenge is to articulate and incorporate commonalities across the tasks.", "labels": [], "entities": []}, {"text": "For instance, in classifying reviews of different products, sentiment words (referred to as pivots) can be shared across the products.", "labels": [], "entities": []}, {"text": "This commonality enables one to align feature spaces across multiple products, enabling useful transfer (?).", "labels": [], "entities": []}, {"text": "Similar properties hold in other contexts and beyond sentiment analysis.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 53, "end_pos": 71, "type": "TASK", "confidence": 0.9444364905357361}]}, {"text": "shows that certain words and phrases like \"identified\", which indicates the presence of a histological property, are applicable to both carcinoma and lymph invasion.", "labels": [], "entities": []}, {"text": "Our method learns and relies on such shared indicators, and utilizes them for effective transfer.", "labels": [], "entities": []}, {"text": "The unique feature of our transfer problem is that both the source and the target classifiers operate over the same domain, i.e., the same examples.", "labels": [], "entities": []}, {"text": "In this setting, traditional transfer methods will always predict the same label for both aspects and thus leading to failure.", "labels": [], "entities": []}, {"text": "Instead of supplying the target classifier with direct training labels, our approach builds on a secondary relationship between the tasks using aspect-relevance annotations of sentences.", "labels": [], "entities": []}, {"text": "These relevance annotations indicate a possibility that the answer could be found in a sentence, not what the answer is.", "labels": [], "entities": []}, {"text": "One can often write simple keyword rules that identify sentence relevance to a particular aspect through representative terms, e.g., specific hormonal markers in the context of pathology reports.", "labels": [], "entities": []}, {"text": "Annotations of this kind can be readily provided by domain experts, or extracted from medical literature such as codex rules in pathology (.", "labels": [], "entities": []}, {"text": "We assume a small number of relevance annotations (rules) pertaining to both source and target aspects as a form of weak supervision.", "labels": [], "entities": []}, {"text": "We use this sentence-level aspect relevance to learn how to encode the examples (e.g., pathology reports) from the point of view of the desired aspect.", "labels": [], "entities": []}, {"text": "In our approach, we construct different aspect-dependent encodings of the same document by softly selecting sentences relevant to the aspect of interest.", "labels": [], "entities": []}, {"text": "The key to effective transfer is how these encodings are aligned.", "labels": [], "entities": []}, {"text": "This encoding mechanism brings the problem closer to the realm of standard domain adaptation, where the derived aspect-specific representations are considered as different domains.", "labels": [], "entities": []}, {"text": "Given these representations, our method learns a label classifier shared between the two domains.", "labels": [], "entities": []}, {"text": "To ensure that it can be adjusted only based on the source class labels, and that it also reasonably applies to the target encodings, we must align the two sets of encoded examples.", "labels": [], "entities": []}, {"text": "Learning this alignment is pos-sible because, as discussed above, some keywords are directly transferable and can serve as anchors for constructing this invariant space.", "labels": [], "entities": []}, {"text": "To learn this invariant representation, we introduce an adversarial domain classifier analogous to the recent successful use of adversarial training in computer vision (.", "labels": [], "entities": []}, {"text": "The role of the domain classifier (adversary) is to learn to distinguish between the two types of encodings.", "labels": [], "entities": []}, {"text": "During training we update the encoder with an adversarial objective to cause the classifier to fail.", "labels": [], "entities": []}, {"text": "The encoder therefore learns to eliminate aspect-specific information so that encodings look invariant (as sets) to the classifier, thus establishing aspect-invariance encodings and enabling transfer.", "labels": [], "entities": []}, {"text": "All three components in our approach, 1) aspect-driven encoding, 2) classification of source labels, and 3) domain adversary, are trained jointly (concurrently) to complement and balance each other.", "labels": [], "entities": [{"text": "aspect-driven encoding", "start_pos": 41, "end_pos": 63, "type": "TASK", "confidence": 0.6675824970006943}, {"text": "classification of source labels", "start_pos": 68, "end_pos": 99, "type": "TASK", "confidence": 0.8704635351896286}]}, {"text": "Adversarial training of domain and label classifiers can be challenging to stabilize.", "labels": [], "entities": []}, {"text": "In our setting, sentences are encoded with a convolutional model.", "labels": [], "entities": []}, {"text": "Feedback from adversarial training can bean unstable guide for how the sentences should be encoded.", "labels": [], "entities": []}, {"text": "To address this issue, we incorporate an additional word-level auto-encoder reconstruction loss to ground the convolutional processing of sentences.", "labels": [], "entities": [{"text": "word-level auto-encoder reconstruction", "start_pos": 52, "end_pos": 90, "type": "TASK", "confidence": 0.5636174182097117}]}, {"text": "We empirically demonstrate that this additional objective yields richer and more diversified feature representations, improving transfer.", "labels": [], "entities": []}, {"text": "We evaluate our approach on pathology reports (aspect transfer) as well as on a more standard review dataset (domain adaptation).", "labels": [], "entities": [{"text": "aspect transfer)", "start_pos": 47, "end_pos": 63, "type": "TASK", "confidence": 0.7923231820265452}, {"text": "domain adaptation)", "start_pos": 110, "end_pos": 128, "type": "TASK", "confidence": 0.7908388177553812}]}, {"text": "On the pathology dataset, we explore cross-aspect transfer across different types of breast disease.", "labels": [], "entities": [{"text": "cross-aspect transfer", "start_pos": 37, "end_pos": 58, "type": "TASK", "confidence": 0.6898577362298965}]}, {"text": "Specifically, we test on six adaptation tasks, consistently outperforming all other baselines.", "labels": [], "entities": []}, {"text": "Overall, our full model achieves 27% and 20.2% absolute improvement arising from aspect-driven encoding and adversarial training respectively.", "labels": [], "entities": [{"text": "aspect-driven encoding", "start_pos": 81, "end_pos": 103, "type": "TASK", "confidence": 0.6153670251369476}]}, {"text": "Moreover, our unsupervised adaptation method is only 5.7% behind the accuracy of a supervised target model.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 69, "end_pos": 77, "type": "METRIC", "confidence": 0.9992623925209045}]}, {"text": "On the review dataset, we test adaptations from hotel to restaurant reviews.", "labels": [], "entities": []}, {"text": "Our model outperforms the marginalized denoising autoencoder () by 5%.", "labels": [], "entities": []}, {"text": "Finally, we examine and illustrate the impact of individual components on the resulting performance.", "labels": [], "entities": []}], "datasetContent": [{"text": "Pathology dataset This dataset contains 96.6k breast pathology reports collected from three hospitals (.", "labels": [], "entities": [{"text": "Pathology dataset", "start_pos": 0, "end_pos": 17, "type": "DATASET", "confidence": 0.6891365945339203}]}, {"text": "A portion of this dataset is manually annotated with 20 categorical values, representing various aspects of breast disease.", "labels": [], "entities": []}, {"text": "In our experiments, we focus on four aspects related to carcinomas and atypias: Ductal Carcinoma InSitu (DCIS), Lobular Carcinoma In-Situ (LCIS), Invasive Ductal Carcinoma (IDC) and Atypical Lobular Hyperplasia (ALH).", "labels": [], "entities": []}, {"text": "Each aspect is annotated using binary labels.", "labels": [], "entities": []}, {"text": "We use 500 held out reports as our test set and use the rest of the labeled data as our training set: 23.8k reports for DCIS, 10.7k for LCIS, 22.9k for IDC, and 9.2k for ALH.", "labels": [], "entities": [{"text": "DCIS", "start_pos": 120, "end_pos": 124, "type": "DATASET", "confidence": 0.9727434515953064}, {"text": "IDC", "start_pos": 152, "end_pos": 155, "type": "DATASET", "confidence": 0.8010009527206421}, {"text": "ALH", "start_pos": 170, "end_pos": 173, "type": "DATASET", "confidence": 0.6364278197288513}]}, {"text": "summarizes statistics of the dataset.", "labels": [], "entities": []}, {"text": "We explore the adaptation problem from one aspect to another.", "labels": [], "entities": []}, {"text": "For example, we want to train a model on annotations of DCIS and apply it on LCIS.", "labels": [], "entities": [{"text": "DCIS", "start_pos": 56, "end_pos": 60, "type": "DATASET", "confidence": 0.9501878619194031}, {"text": "LCIS", "start_pos": 77, "end_pos": 81, "type": "DATASET", "confidence": 0.9066775441169739}]}, {"text": "For each aspect, we use up to three common names as a source of supervision for learning the relevance scorer, as illustrated in.", "labels": [], "entities": []}, {"text": "Note that the provided list is by no means exhaustive.", "labels": [], "entities": []}, {"text": "In fact provide example of 60 different verbalizations of LCIS, not counting negations.", "labels": [], "entities": []}, {"text": "Our second experiment is based on a domain transfer of sentiment classification.", "labels": [], "entities": [{"text": "domain transfer of sentiment classification", "start_pos": 36, "end_pos": 79, "type": "TASK", "confidence": 0.759891951084137}]}, {"text": "For the source domain, we use the hotel review dataset introduced in previous work (, and for the target domain, we use the restaurant review dataset from Yelp.", "labels": [], "entities": [{"text": "hotel review dataset", "start_pos": 34, "end_pos": 54, "type": "DATASET", "confidence": 0.6151074965794882}, {"text": "restaurant review dataset from Yelp", "start_pos": 124, "end_pos": 159, "type": "DATASET", "confidence": 0.7154655635356904}]}, {"text": "Both datasets have ratings on a scale of 1 to 5 stars.", "labels": [], "entities": []}, {"text": "Following previous work, we label reviews with ratings > 3 as positive and those with ratings < 3 as negative, discarding the rest.", "labels": [], "entities": []}, {"text": "The hotel dataset includes a total of around 200k reviews collected from TripAdvisor, so we split 100k as labeled and the other 100k as unlabeled data.", "labels": [], "entities": [{"text": "TripAdvisor", "start_pos": 73, "end_pos": 84, "type": "DATASET", "confidence": 0.9365705847740173}]}, {"text": "We randomly select 200k restaurant reviews as the unlabeled data in the target domain.", "labels": [], "entities": []}, {"text": "Our test set consists of 2k reviews.", "labels": [], "entities": []}, {"text": "summarizes the statistics of the review dataset.", "labels": [], "entities": [{"text": "review dataset", "start_pos": 33, "end_pos": 47, "type": "DATASET", "confidence": 0.7381283938884735}]}, {"text": "The hotel reviews naturally have ratings for six aspects, including value, room quality, checkin service, room service, cleanliness and location.", "labels": [], "entities": []}, {"text": "We use the first five aspects because the sixth aspect location has positive labels for over 95% of the reviews and thus the trained model will suffer from the lack of negative examples.", "labels": [], "entities": []}, {"text": "The restaurant reviews, however, only have single ratings for an overall impression.", "labels": [], "entities": []}, {"text": "Therefore, we explore the task of adaptation from each of the five hotel aspects to the restaurant domain.", "labels": [], "entities": []}, {"text": "The hotel reviews dataset also provides a total of 280 keywords for different aspects that are generated by the bootstrapping method used in.", "labels": [], "entities": [{"text": "hotel reviews dataset", "start_pos": 4, "end_pos": 25, "type": "DATASET", "confidence": 0.7073314785957336}]}, {"text": "We use those keywords as supervision for learning the relevance scorer.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 4: Pathology: Classification accuracy (%) of different approaches on the pathology reports dataset,  including the results of twelve adaptation scenarios from four different aspects (IDC, ALH, DCIS and LCIS)  in breast cancer pathology reports. \"mSDA\" indicates the marginalized denoising autoencoder in (", "labels": [], "entities": [{"text": "accuracy", "start_pos": 36, "end_pos": 44, "type": "METRIC", "confidence": 0.8922041654586792}]}, {"text": " Table 5: Review: Classification accuracy (%) of different approaches on the reviews dataset. Columns have  the same meaning as in", "labels": [], "entities": [{"text": "accuracy", "start_pos": 33, "end_pos": 41, "type": "METRIC", "confidence": 0.8004009127616882}, {"text": "reviews dataset", "start_pos": 77, "end_pos": 92, "type": "DATASET", "confidence": 0.7691268920898438}]}, {"text": " Table 4. Boldface numbers indicate the best accuracy for each testing scenario.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 45, "end_pos": 53, "type": "METRIC", "confidence": 0.9993337988853455}]}, {"text": " Table 6: Impact of adding the reconstruction com- ponent in the model, measured by the average ac- curacy on each dataset. +REC. and -REC. denote  the presence and absence of the reconstruction loss,  respectively.", "labels": [], "entities": [{"text": "ac- curacy", "start_pos": 96, "end_pos": 106, "type": "METRIC", "confidence": 0.929844876130422}, {"text": "REC.", "start_pos": 125, "end_pos": 129, "type": "METRIC", "confidence": 0.9889378547668457}, {"text": "REC", "start_pos": 135, "end_pos": 138, "type": "METRIC", "confidence": 0.8902007341384888}]}, {"text": " Table 7: The effect of regularization of the transfor- mation layer \u03bb t on the performance.", "labels": [], "entities": []}]}