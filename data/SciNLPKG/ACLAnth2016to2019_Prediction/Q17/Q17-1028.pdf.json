{"title": [{"text": "Learning Distributed Representations of Texts and Entities from Knowledge Base", "labels": [], "entities": [{"text": "Learning Distributed Representations of Texts and Entities from Knowledge Base", "start_pos": 0, "end_pos": 78, "type": "TASK", "confidence": 0.8394416332244873}]}], "abstractContent": [{"text": "We describe a neural network model that jointly learns distributed representations of texts and knowledge base (KB) entities.", "labels": [], "entities": []}, {"text": "Given a text in the KB, we train our proposed model to predict entities that are relevant to the text.", "labels": [], "entities": []}, {"text": "Our model is designed to be generic with the ability to address various NLP tasks with ease.", "labels": [], "entities": []}, {"text": "We train the model using a large corpus of texts and their entity annotations extracted from Wikipedia.", "labels": [], "entities": []}, {"text": "We evaluated the model on three important NLP tasks (i.e., sentence textual similarity, entity linking, and fac-toid question answering) involving both unsu-pervised and supervised settings.", "labels": [], "entities": [{"text": "sentence textual similarity", "start_pos": 59, "end_pos": 86, "type": "TASK", "confidence": 0.6165536046028137}, {"text": "entity linking", "start_pos": 88, "end_pos": 102, "type": "TASK", "confidence": 0.7653856575489044}, {"text": "fac-toid question answering", "start_pos": 108, "end_pos": 135, "type": "TASK", "confidence": 0.6180166999499003}]}, {"text": "As a result, we achieved state-of-the-art results on all three of these tasks.", "labels": [], "entities": []}, {"text": "Our code and trained models are publicly available for further academic research.", "labels": [], "entities": []}], "introductionContent": [{"text": "Methods capable of learning distributed representations of arbitrary-length texts (i.e., fixed-length continuous vectors that encode the semantics of texts), such as sentences and paragraphs, have recently attracted considerable attention (.", "labels": [], "entities": []}, {"text": "These methods aim to learn generic representations that are useful across domains similar to word embedding methods such as Word2vec () and GloVe (.", "labels": [], "entities": [{"text": "Word2vec", "start_pos": 124, "end_pos": 132, "type": "DATASET", "confidence": 0.9339415431022644}]}, {"text": "Another interesting approach is learning distributed representations of entities in a knowledge https://github.com/studio-ousia/ntee base (KB) such as Wikipedia and Freebase.", "labels": [], "entities": []}, {"text": "These methods encode information of entities in the KB into a continuous vector space.", "labels": [], "entities": []}, {"text": "They are shown to be effective for various KB-related tasks such as entity search (, entity linking (, and link prediction (.", "labels": [], "entities": [{"text": "entity search", "start_pos": 68, "end_pos": 81, "type": "TASK", "confidence": 0.7964771091938019}, {"text": "entity linking", "start_pos": 85, "end_pos": 99, "type": "TASK", "confidence": 0.7906458973884583}, {"text": "link prediction", "start_pos": 107, "end_pos": 122, "type": "TASK", "confidence": 0.7211835086345673}]}, {"text": "In this paper, we describe a novel method to bridge these two different approaches.", "labels": [], "entities": []}, {"text": "In particular, we propose Neural Text-Entity Encoder (NTEE), a neural network model to jointly learn distributed representations of texts (i.e., sentences and paragraphs) and KB entities.", "labels": [], "entities": []}, {"text": "For every text in the KB, our model aims to predict its relevant entities, and places the text and the relevant entities close to each other in a continuous vector space.", "labels": [], "entities": []}, {"text": "We use humanedited entity annotations obtained from Wikipedia (see) as supervised data of relevant entities to the texts containing these annotations.", "labels": [], "entities": []}, {"text": "Note that, KB entities have been conventionally used to model semantics of texts.", "labels": [], "entities": []}, {"text": "A representative example is Explicit Semantic Analysis (ESA) (, which represents the semantics of a text using a sparse vector space, where each dimension corresponds to the relevance score of the text to each entity.", "labels": [], "entities": [{"text": "Explicit Semantic Analysis (ESA)", "start_pos": 28, "end_pos": 60, "type": "TASK", "confidence": 0.7514242231845856}]}, {"text": "Essentially, ESA shows that text can be accurately represented using a small set of its relevant entities.", "labels": [], "entities": [{"text": "ESA", "start_pos": 13, "end_pos": 16, "type": "DATASET", "confidence": 0.7383976578712463}]}, {"text": "Based on Entity annotations in Wikipedia can be viewed as supervised data of relevant entities because Wikipedia instructs its contributors to create annotations only where they are relevant in its manual: https://en.wikipedia.org/ wiki/Wikipedia:Manual_of_Style this fact, we hypothesize that we can use the annotations of relevant entities as the supervised data of learning text representations.", "labels": [], "entities": []}, {"text": "Furthermore, we also consider that placing texts and entities into the same vector space enables us to easily compute the similarity between texts and entities, which can be beneficial for various KB-related tasks.", "labels": [], "entities": []}, {"text": "In order to test this hypothesis, we conduct three experiments involving both the unsupervised and the supervised tasks.", "labels": [], "entities": []}, {"text": "First, we use standard semantic textual similarity datasets to evaluate the quality of the learned text representations of our method in an unsupervised fashion.", "labels": [], "entities": []}, {"text": "As a result, our method clearly outperformed the state-of-the-art methods.", "labels": [], "entities": []}, {"text": "Furthermore, to test the effectiveness of our method to perform KB-related tasks, we address the following two important problems in the supervised setting: entity linking (EL) and factoid question answering (QA).", "labels": [], "entities": [{"text": "entity linking (EL)", "start_pos": 157, "end_pos": 176, "type": "TASK", "confidence": 0.7484054923057556}, {"text": "factoid question answering (QA)", "start_pos": 181, "end_pos": 212, "type": "TASK", "confidence": 0.7706391414006551}]}, {"text": "In both tasks, we adopt a simple multi-layer perceptron (MLP) classifier with the learned representations as features.", "labels": [], "entities": []}, {"text": "We tested our method using two standard datasets (i.e., for the EL task and a popular factoid QA dataset based on the quiz bowl quiz game for the factoid QA task.", "labels": [], "entities": [{"text": "factoid QA task", "start_pos": 146, "end_pos": 161, "type": "TASK", "confidence": 0.6032472650210062}]}, {"text": "As a result, our method outperformed recent state-of-the-art methods on both the EL and the factoid QA tasks.", "labels": [], "entities": []}, {"text": "Additionally, there have also been proposed methods that map words and entities into the same continuous vector space (.", "labels": [], "entities": []}, {"text": "Our work differs from these works because we aim to map texts (i.e., sentences and paragraphs) and entities into the same vector space.", "labels": [], "entities": []}, {"text": "Our contributions are summarized as follows: \u2022 We propose a neural network model that jointly learns vector representations of texts and KB entities.", "labels": [], "entities": []}, {"text": "We train the model using a large amount of entity annotations extracted directly from Wikipedia.", "labels": [], "entities": []}, {"text": "\u2022 We demonstrate that our proposed representations are surprisingly effective for various NLP tasks.", "labels": [], "entities": []}, {"text": "In particular, we apply the proposed model to three different NLP tasks, namely semantic textual similarity, entity linking, and factoid question answering, and achieve stateof-the-art results on all three tasks.", "labels": [], "entities": [{"text": "entity linking", "start_pos": 109, "end_pos": 123, "type": "TASK", "confidence": 0.7786677479743958}, {"text": "factoid question answering", "start_pos": 129, "end_pos": 155, "type": "TASK", "confidence": 0.7517900665601095}]}, {"text": "The Lord of the Rings is an epic high-fantasy novel written by English author J.", "labels": [], "entities": []}, {"text": "Entity Annotations: The Lord of the Rings, Epic (genre), High fantasy, J. R. R. Tolkien: An example of a sentence with entity annotations.", "labels": [], "entities": []}, {"text": "\u2022 We release our code and trained models to the community at https://github.com/ studio-ousia/ntee to facilitate further academic research.", "labels": [], "entities": []}], "datasetContent": [{"text": "In order to evaluate our model presented in the previous section, we conduct experiments on three important NLP tasks using the representations learned by our model.", "labels": [], "entities": []}, {"text": "First, we conduct an experiment on a semantic textual similarity task in order to evaluate the quality of the learned text representations.", "labels": [], "entities": []}, {"text": "Next, we conduct experiments on two important NLP problems (i.e., EL and factoid QA) in order to test the effectiveness of our proposed representations as features for downstream NLP tasks.", "labels": [], "entities": []}, {"text": "Finally, we further qualitatively analyze the learned representations.", "labels": [], "entities": []}, {"text": "Note that we separately describe how we address each task using our representations in the subsection of each experiment.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 3: Hyper-parameters used for EL and QA tasks.", "labels": [], "entities": [{"text": "EL and QA tasks", "start_pos": 36, "end_pos": 51, "type": "TASK", "confidence": 0.5552824139595032}]}, {"text": " Table 4: Accuracies of the proposed method and the  state-of-the-art methods.", "labels": [], "entities": [{"text": "Accuracies", "start_pos": 10, "end_pos": 20, "type": "METRIC", "confidence": 0.9956145286560059}]}, {"text": " Table 5: Accuracies of the proposed method and the  state-of-the-art methods for the factoid QA task.", "labels": [], "entities": [{"text": "Accuracies", "start_pos": 10, "end_pos": 20, "type": "METRIC", "confidence": 0.9913902282714844}, {"text": "factoid QA task", "start_pos": 86, "end_pos": 101, "type": "TASK", "confidence": 0.7988842527071635}]}, {"text": " Table 6. Interestingly, our model is some- what more specific than the skip-gram model. For  example, there is only one word she whose cosine  similarity to the word her is more than 0.5 in our  model, whereas all the corresponding similar words  in the skip-gram model (i.e., she, his, herself, him,  and mother) satisfy that condition. We observe a  similar trend for the similar words of dry. Further- more, all the words similar to tennis are strictly re-", "labels": [], "entities": []}]}