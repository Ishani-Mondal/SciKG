{"title": [], "abstractContent": [{"text": "This paper focuses on unsupervised modeling of morphological families, collectively comprising a forest over the language vocabulary.", "labels": [], "entities": []}, {"text": "This formulation enables us to capture edge-wise properties reflecting single-step morphological derivations, along with global distribu-tional properties of the entire forest.", "labels": [], "entities": []}, {"text": "These global properties constrain the size of the affix set and encourage formation of tight morphological families.", "labels": [], "entities": []}, {"text": "The resulting objective is solved using Integer Linear Programming (ILP) paired with contrastive estimation.", "labels": [], "entities": []}, {"text": "We train the model by alternating between optimizing the local log-linear model and the global ILP objective.", "labels": [], "entities": []}, {"text": "We evaluate our system on three tasks: root detection, clustering of morphological families, and segmentation.", "labels": [], "entities": [{"text": "root detection", "start_pos": 39, "end_pos": 53, "type": "TASK", "confidence": 0.8550465404987335}, {"text": "clustering of morphological families", "start_pos": 55, "end_pos": 91, "type": "TASK", "confidence": 0.8364288061857224}]}, {"text": "Our experiments demonstrate that our model yields consistent gains in all three tasks compared with the best published results.", "labels": [], "entities": []}], "introductionContent": [{"text": "The morphological study of a language inherently draws upon the existence of families of related words.", "labels": [], "entities": []}, {"text": "All words within a family can be derived from a common root via a series of transformations, whether inflectional or derivational.", "labels": [], "entities": []}, {"text": "depicts one such family, originating from the word faith.", "labels": [], "entities": []}, {"text": "This representation can benefit a range of applications, including segmentation, root detection and clustering of morphological families.", "labels": [], "entities": [{"text": "root detection", "start_pos": 81, "end_pos": 95, "type": "TASK", "confidence": 0.8075450360774994}]}, {"text": "Using graph terminology, a full morphological assignment of the words in a language can be represented as a forest.", "labels": [], "entities": []}, {"text": "Valid forests of morphological families exhibit a number of well-known regularities.", "labels": [], "entities": []}, {"text": "At the global level, the number of roots is limited, and only constitute a small fraction of the vocabulary.", "labels": [], "entities": []}, {"text": "A similar constraint applies to the number of possible affixes, shared across families.", "labels": [], "entities": []}, {"text": "At the local edge level, we prefer derivations that follow regular orthographic patterns and preserve semantic relatedness.", "labels": [], "entities": []}, {"text": "We hypothesize that enforcing these constraints as part of the forest induction pro-cess will allow us to accurately learn morphological structures in an unsupervised fashion.", "labels": [], "entities": []}, {"text": "To test this hypothesis, we define an objective over the entire forest representation.", "labels": [], "entities": []}, {"text": "The proposed objective is designed to maximize the likelihood of local derivations, while constraining the overall number of affixes and encouraging tighter morphological families.", "labels": [], "entities": []}, {"text": "We optimize this objective using Integer Linear Programming (ILP), which is commonly employed to handle global constraints.", "labels": [], "entities": []}, {"text": "While in prior work, ILP has often been employed in supervised settings, we explore its effectiveness in unsupervised learning.", "labels": [], "entities": []}, {"text": "We induce a forest by alternating between learning local edge probabilities using a log-linear model, and enforcing global constraints with the ILP-based decoder.", "labels": [], "entities": []}, {"text": "With each iteration, the model progresses towards more consistent forests.", "labels": [], "entities": []}, {"text": "We evaluate our model on three tasks: root detection, clustering of morphologically related families, and segmentation.", "labels": [], "entities": [{"text": "root detection", "start_pos": 38, "end_pos": 52, "type": "TASK", "confidence": 0.8645135164260864}, {"text": "clustering of morphologically related families", "start_pos": 54, "end_pos": 100, "type": "TASK", "confidence": 0.8119468927383423}]}, {"text": "The last task has been extensively studied in recent literature, providing us with the opportunity to compare the model with multiple unsupervised techniques.", "labels": [], "entities": []}, {"text": "On benchmark datasets representing four languages, our model outperforms the baselines, yielding new state-of-the-art results.", "labels": [], "entities": []}, {"text": "For instance, we improve segmentation performance on Turkish by 4.4% and on English by 3.7%, relative to the best published results (.", "labels": [], "entities": [{"text": "segmentation", "start_pos": 25, "end_pos": 37, "type": "TASK", "confidence": 0.9671543836593628}]}, {"text": "Similarly, our model exhibits superior performance on the other two tasks.", "labels": [], "entities": []}, {"text": "We also provide analysis of the model behavior which reveals that most of the gain comes from enforcing global constraints on the number of unique affixes.", "labels": [], "entities": []}], "datasetContent": [{"text": "We evaluate our model on three tasks: segmentation, morphological family clustering, and root detection.", "labels": [], "entities": [{"text": "segmentation", "start_pos": 38, "end_pos": 50, "type": "TASK", "confidence": 0.9635502696037292}, {"text": "morphological family clustering", "start_pos": 52, "end_pos": 83, "type": "TASK", "confidence": 0.5822475155194601}, {"text": "root detection", "start_pos": 89, "end_pos": 103, "type": "TASK", "confidence": 0.7673347592353821}]}, {"text": "While the first task has been extensively studied in the prior literature, we consider two additional tasks to assess the flexibility of the derived representation.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Data statistics: MC-10 = MorphoChal- lenge 2010 , MC:05-10 = aggregated from Mor- phoChallenge 2005-2010, BOUN = BOUN cor- pus (Sak et al., 2008), Gigaword = Arabic Gigaword  corpus (Parker et al., 2011), ATB = Arabic Tree- bank (Maamouri et al., 2003). Duplicates in Arabic  test set are filtered. Dsolve is the dataset released  by W\u00fcrzner and Jurish (2015), and for training Ger- man vectors, we use the pre-processed Wikipedia  dump from (Al-Rfou et al., 2013).", "labels": [], "entities": [{"text": "BOUN", "start_pos": 116, "end_pos": 120, "type": "METRIC", "confidence": 0.9980066418647766}, {"text": "BOUN", "start_pos": 123, "end_pos": 127, "type": "METRIC", "confidence": 0.935934841632843}]}, {"text": " Table 2: Data statistics for the family clustering task  (CELEX). We only evaluate on English and Ger- man, since these are the languages MorphoChal- lenge has segmentations for.", "labels": [], "entities": [{"text": "family clustering task", "start_pos": 34, "end_pos": 56, "type": "TASK", "confidence": 0.746321032444636}]}, {"text": " Table 2.  We remove words without stems from CELEX. 8", "labels": [], "entities": [{"text": "CELEX", "start_pos": 46, "end_pos": 51, "type": "DATASET", "confidence": 0.935725748538971}]}, {"text": " Table 3: Data statistics for root detection task. Du- plicate words are removed.", "labels": [], "entities": [{"text": "root detection", "start_pos": 30, "end_pos": 44, "type": "TASK", "confidence": 0.7929524779319763}]}, {"text": " Table 5: Some English words that our model seg- ments correctly which the unsupervised base model  (NBJ'15) fails at.", "labels": [], "entities": [{"text": "NBJ'15", "start_pos": 101, "end_pos": 107, "type": "DATASET", "confidence": 0.9643967151641846}]}, {"text": " Table 6: Results for morphological family cluster- ing. P = precision, R = recall.", "labels": [], "entities": [{"text": "morphological family cluster- ing", "start_pos": 22, "end_pos": 55, "type": "TASK", "confidence": 0.8381401419639587}, {"text": "P", "start_pos": 57, "end_pos": 58, "type": "METRIC", "confidence": 0.9924465417861938}, {"text": "precision", "start_pos": 61, "end_pos": 70, "type": "METRIC", "confidence": 0.9645642638206482}, {"text": "R", "start_pos": 72, "end_pos": 73, "type": "METRIC", "confidence": 0.9869930744171143}, {"text": "recall", "start_pos": 76, "end_pos": 82, "type": "METRIC", "confidence": 0.9239263534545898}]}, {"text": " Table 7: Results for root detection. Numbers for  Morfette and Chipmunk are reported by", "labels": [], "entities": [{"text": "root detection", "start_pos": 22, "end_pos": 36, "type": "TASK", "confidence": 0.8083098828792572}]}]}