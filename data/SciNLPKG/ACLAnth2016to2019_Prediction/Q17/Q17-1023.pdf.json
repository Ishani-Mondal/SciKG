{"title": [{"text": "Colors in Context: A Pragmatic Neural Model for Grounded Language Understanding", "labels": [], "entities": []}], "abstractContent": [{"text": "We present a model of pragmatic referring expression interpretation in a grounded communication task (identifying colors from descriptions) that draws upon predictions from two recurrent neural network classifiers, a speaker and a listener, unified by a recur-sive pragmatic reasoning framework.", "labels": [], "entities": [{"text": "referring expression interpretation", "start_pos": 32, "end_pos": 67, "type": "TASK", "confidence": 0.652697761853536}]}, {"text": "Experiments show that this combined pragmatic model interprets color descriptions more accurately than the classifiers from which it is built, and that much of this improvement results from combining the speaker and listener perspectives.", "labels": [], "entities": []}, {"text": "We observe that pragmatic reasoning helps primarily in the hardest cases: when the model must distinguish very similar colors, or when few utterances adequately express the target color.", "labels": [], "entities": []}, {"text": "Our findings make use of a newly-collected corpus of human utterances in color reference games, which exhibit a variety of pragmatic behaviors.", "labels": [], "entities": []}, {"text": "We also show that the embedded speaker model reproduces many of these pragmatic behaviors.", "labels": [], "entities": []}], "introductionContent": [{"text": "In using language, we are sensitive to context and our interlocutors' expectations, both when choosing our utterances (as speakers) and when interpreting the utterances we hear (as listeners).", "labels": [], "entities": []}, {"text": "Visual referring tasks exercise this complex process of grounding, in the environment and in our mental models of each other, and thus provide a valuable test-bed for computational models of production and comprehension.", "labels": [], "entities": [{"text": "Visual referring tasks", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.804745634396871}]}, {"text": "task-oriented dialogue corpus we introduce in this paper.", "labels": [], "entities": []}, {"text": "In these dialogues, the speaker is trying to identify their (privately assigned) target color for the listener.", "labels": [], "entities": []}, {"text": "In context 1, the comparative darker implicitly refers to both the target (boxed) and one of the other colors.", "labels": [], "entities": []}, {"text": "In contexts 2 and 3, the target color is the same, but the distractors led the speaker to choose different basic color terms.", "labels": [], "entities": []}, {"text": "In context 4, blue is a pragmatic choice even though two colors are shades of blue, because the interlocutors assume about each other that they find the target color a more prototypical representative of blue and would prefer other descriptions (teal, cyan) for the middle color.", "labels": [], "entities": []}, {"text": "The fact that blue appears in three of these four cases highlights the flexibility and context dependence of color descriptions.", "labels": [], "entities": []}, {"text": "In this paper, we present a scalable, learned model of pragmatic language understanding.", "labels": [], "entities": [{"text": "pragmatic language understanding", "start_pos": 55, "end_pos": 87, "type": "TASK", "confidence": 0.6442073980967203}]}, {"text": "The model is built around aversion of the Rational Speech Acts (RSA) model, in which agents reason recur-sively about each other's expectations and intentions to communicate more effectively than literal semantic agents could.", "labels": [], "entities": [{"text": "Rational Speech Acts (RSA)", "start_pos": 42, "end_pos": 68, "type": "TASK", "confidence": 0.7053013642628988}]}, {"text": "In most work on RSA, the literal semantic agents use fixed message sets and stipulated grammars, which is a barrier to experiments in linguistically complex domains.", "labels": [], "entities": [{"text": "RSA", "start_pos": 16, "end_pos": 19, "type": "TASK", "confidence": 0.9760092496871948}]}, {"text": "In our formulation, the literal semantic agents are recurrent neural networks (RNNs) that produce and interpret color descriptions in context.", "labels": [], "entities": []}, {"text": "These models are learned from data and scale easily to large datasets containing diverse utterances.", "labels": [], "entities": []}, {"text": "The RSA recursion is then defined in terms of these base agents: the pragmatic speaker produces utterances based on a literal RNN listener, and the pragmatic listener interprets utterances based on the pragmatic speaker's behavior.", "labels": [], "entities": [{"text": "RSA recursion", "start_pos": 4, "end_pos": 17, "type": "TASK", "confidence": 0.9555079638957977}]}, {"text": "We focus on accuracy in a listener task (i.e., at language understanding).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 12, "end_pos": 20, "type": "METRIC", "confidence": 0.9989094734191895}, {"text": "language understanding", "start_pos": 50, "end_pos": 72, "type": "TASK", "confidence": 0.709419384598732}]}, {"text": "However, our most successful model integrates speaker and listener perspectives, combining predictions made by a system trained to understand color descriptions and one trained to produce them.", "labels": [], "entities": []}, {"text": "We evaluate this model with anew, psycholinguistically motivated corpus of real-time, dyadic reference games in which the referents are patches of color.", "labels": [], "entities": []}, {"text": "Our task is fundamentally the same as that of, but the corpus we release is larger by several orders of magnitude, consisting of 948 complete games with 53,365 utterances produced by human participants paired into dyads on the web.", "labels": [], "entities": []}, {"text": "The linguistic behavior of the players exhibits many of the intricacies of language in general, including not just the context dependence and cognitive complexity discussed above, but also compositionality, vagueness, and ambiguity.", "labels": [], "entities": []}, {"text": "While many previous data sets feature descriptions of individual colors, situating colors in a communicative context elicits greater variety in language use, including negations, comparatives, superlatives, metaphor, and shared associations.", "labels": [], "entities": []}, {"text": "Experiments on the data in our corpus show that this combined pragmatic model improves accuracy in interpreting human-produced descriptions over the basic RNN listener alone.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 87, "end_pos": 95, "type": "METRIC", "confidence": 0.9987093210220337}, {"text": "interpreting human-produced descriptions", "start_pos": 99, "end_pos": 139, "type": "TASK", "confidence": 0.8738283316294352}]}, {"text": "We find that the largest improvement over the single RNN comes from blending it with an RNN trained to perform the speaker task, despite the fact that a model based only on this speaker RNN performs poorly on its own.", "labels": [], "entities": []}, {"text": "Pragmatic reasoning on top of the listener RNN alone also yields improvements, which moreover come primarily in the hardest cases: 1) contexts with colors that are very similar, thus requiring the interpretation of descriptions that convey fine distinctions; and 2) target colors that most referring expressions fail to identify, whether due to alack of adequate descriptive terms or a consistent bias against the color in the RNN listener.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 2: Corpus statistics and statistics of samples from artificial speakers (rates per utterance). S 0 : RNN speaker; S 1 :  pragmatic speaker derived from RNN listener (see Section 4.3). The human and artificial speakers show many of the  same correlations between language use and context type.", "labels": [], "entities": []}, {"text": " Table 3: Accuracy and perplexity of the base and prag- matic listeners and various blends (weighted averages,  denoted A \u00b7 B). Top: dev set; bottom: test set.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9980389475822449}]}]}