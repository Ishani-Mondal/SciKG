{"title": [{"text": "Evaluating Low-Level Speech Features Against Human Perceptual Data", "labels": [], "entities": [{"text": "Evaluating Low-Level Speech Features", "start_pos": 0, "end_pos": 36, "type": "TASK", "confidence": 0.797729566693306}]}], "abstractContent": [{"text": "We introduce a method for measuring the correspondence between low-level speech features and human perception, using a cognitive model of speech perception implemented directly on speech recordings.", "labels": [], "entities": []}, {"text": "We evaluate two speaker normalization techniques using this method and find that in both cases, speech features that are normalized across speakers predict human data better than unnormalized speech features , consistent with previous research.", "labels": [], "entities": []}, {"text": "Results further reveal differences across normal-ization methods in how well each predicts human data.", "labels": [], "entities": []}, {"text": "This work provides anew framework for evaluating low-level representations of speech on their match to human perception, and lays the groundwork for creating more ecologically valid models of speech perception.", "labels": [], "entities": []}], "introductionContent": [{"text": "Understanding the features that listeners extract from the speech signal is a critical part of understanding phonetic learning and perception.", "labels": [], "entities": []}, {"text": "Different feature spaces imply different statistical distributions of speech sounds in listeners' input (), and these statistical distributions of speech sounds influence speech perception in both adults and infants).", "labels": [], "entities": []}, {"text": "The performance of automatic speech recognition (ASR) systems is also affected by the way in which these systems represent the speech signal.", "labels": [], "entities": [{"text": "automatic speech recognition (ASR)", "start_pos": 19, "end_pos": 53, "type": "TASK", "confidence": 0.8125197490056356}]}, {"text": "For example, changing the signal processing methods that are used to extract features from the speech waveform and applying speaker normalization techniques to these features () can improve the performance of a recognizer.", "labels": [], "entities": []}, {"text": "Recently there has been considerable interest in representation learning, in which new features that are created through exposure to data from the language to be recognized, or through exposure to other languages, lead to better system performance (.", "labels": [], "entities": [{"text": "representation learning", "start_pos": 49, "end_pos": 72, "type": "TASK", "confidence": 0.9503618776798248}]}, {"text": "It is potentially useful to know how closely the feature representations in ASR resemble those of human listeners, particularly for low-resource settings, where systems rely heavily on these features to guide generalization across speakers and dialects.", "labels": [], "entities": [{"text": "ASR", "start_pos": 76, "end_pos": 79, "type": "TASK", "confidence": 0.9754088521003723}]}, {"text": "In this paper we introduce a method for measuring the correspondence between low-level speech feature representations and human speech perception.", "labels": [], "entities": []}, {"text": "This allows us to compare different feature spaces in terms of how well the locations of sounds in the space can predict listeners' perception of acoustic similarity.", "labels": [], "entities": []}, {"text": "Our method has potential relevance both in ASR, for understanding how well the feature representations in ASR systems capture the similarity structure that guides human perception, and in cognitive science, for evaluating hypotheses regarding the feature spaces that human listeners use.", "labels": [], "entities": [{"text": "ASR", "start_pos": 43, "end_pos": 46, "type": "TASK", "confidence": 0.9950256943702698}]}, {"text": "We evaluate the ability of a feature space to capture listeners' same-different responses in AX discrimination tasks, in which listeners hear two sounds and decide whether they are acoustically identical.", "labels": [], "entities": [{"text": "AX discrimination tasks", "start_pos": 93, "end_pos": 116, "type": "TASK", "confidence": 0.8304144144058228}]}, {"text": "Rather than assuming that listeners' ability to discriminate Figure 1: Acoustic characteristics of vowels produced in hVd contexts by men, women, and children from, plotted as raw formant frequencies (left) and z-scored formant frequencies (right).", "labels": [], "entities": []}, {"text": "These feature spaces yield different distributions of sounds in acoustic space.", "labels": [], "entities": []}, {"text": "If listeners' perception is biased toward peaks in these distributions, the feature spaces make different predictions for listeners' behavior in perceptual discrimination tasks.", "labels": [], "entities": []}, {"text": "sounds is directly related to those sounds' distance in a feature space, we instead adopt a cognitive model of speech perception which predicts that listeners' perception of sounds is biased toward peaks in the distribution of sounds in their input.", "labels": [], "entities": []}, {"text": "This leads listeners to perceive some sounds as closer together in the feature space than they actually are, and others as farther apart ().", "labels": [], "entities": []}, {"text": "The model has previously been shown to accurately predict listeners' same-different discrimination judgments when listening to pairs of sounds.", "labels": [], "entities": []}, {"text": "Our innovation in this work is to estimate the distribution of sounds in the input from a corpus, using different feature spaces.", "labels": [], "entities": []}, {"text": "Under the model, listeners are expected to bias their perception toward peaks in the distribution of sounds in the corpus.", "labels": [], "entities": []}, {"text": "Those peaks occur in different locations for different feature spaces.", "labels": [], "entities": []}, {"text": "Thus, different feature representations yield different predictions about listeners' discrimination.", "labels": [], "entities": []}, {"text": "Features that yield a better match with listeners' discrimination are assumed to more closely reflect the way in which listeners generalize their previous experience when perceiving speech.", "labels": [], "entities": []}, {"text": "In addition to providing away to evaluate feature representations, adapting a cognitive model to operate directly over speech recordings lays the groundwork for building more ecologically valid models of speech perception, by enabling cognitive scientists to make use of the same rich corpus data that is often used by researchers in ASR.", "labels": [], "entities": [{"text": "ASR", "start_pos": 334, "end_pos": 337, "type": "TASK", "confidence": 0.9504748582839966}]}, {"text": "These speech corpora will allow models to be trained and tested on data that more faithfully simulate the speech environment that listeners encounter, rather than on artificially simplified data.", "labels": [], "entities": []}, {"text": "As an initial case study, we use the perceptual model to evaluate features derived from two speaker normalization algorithms, which aim to reduce variability in the speech signal stemming from physical characteristics of the vocal tract.", "labels": [], "entities": []}, {"text": "We compare these normalized features to a baseline set of unnormalized features.", "labels": [], "entities": []}, {"text": "Speaker normalization has previously been found to improve phonetic categorization, increase a phonetic categorization model's match with human behavior, and improve the performance of speech recognizers (.", "labels": [], "entities": [{"text": "Speaker normalization", "start_pos": 0, "end_pos": 21, "type": "TASK", "confidence": 0.7320864498615265}, {"text": "speech recognizers", "start_pos": 185, "end_pos": 203, "type": "TASK", "confidence": 0.7043306231498718}]}, {"text": "However, the degree to which specific normalization techniques from ASR match human perception is not yet known.", "labels": [], "entities": [{"text": "ASR", "start_pos": 68, "end_pos": 71, "type": "TASK", "confidence": 0.9913990497589111}]}, {"text": "Experiments in this paper replicate the general benefit of speaker normalization using our perceptual model, while also providing new data on the degree to which different normalization algorithms from ASR capture information that is similar to what humans use in perceptual tasks.", "labels": [], "entities": [{"text": "speaker normalization", "start_pos": 59, "end_pos": 80, "type": "TASK", "confidence": 0.7564516067504883}, {"text": "ASR capture information", "start_pos": 202, "end_pos": 225, "type": "TASK", "confidence": 0.8757996161778768}]}, {"text": "The paper is organized as follows.", "labels": [], "entities": []}, {"text": "We begin by characterizing the speech features tested in this paper.", "labels": [], "entities": []}, {"text": "The following section describes the method we use for evaluating these features against human discrimination data.", "labels": [], "entities": []}, {"text": "Experiments are presented testing how well each representation predicts human data.", "labels": [], "entities": []}, {"text": "We compare our method to previous work, and conclude by discussing implications and future directions.", "labels": [], "entities": []}], "datasetContent": [{"text": "Experiments implemented the perceptual model with normalized and unnormalized representations, comparing model predictions to human discrimination data.", "labels": [], "entities": []}, {"text": "To the extent that different representations of speech yield different distributions of sounds in a corpus, they should make different predictions about the biases that listeners will exhibit in a speech perception experiment.", "labels": [], "entities": []}, {"text": "Representations that yield more accurate predictions can be assumed to correspond to a similarity space more similar to the dimensions that human listeners use in speech perception.", "labels": [], "entities": [{"text": "speech perception", "start_pos": 163, "end_pos": 180, "type": "TASK", "confidence": 0.7015076130628586}]}], "tableCaptions": [{"text": " Table 1: Effect of normalization on symmetrized K-L  divergence.", "labels": [], "entities": [{"text": "symmetrized K-L  divergence", "start_pos": 37, "end_pos": 64, "type": "TASK", "confidence": 0.5273849864800771}]}]}