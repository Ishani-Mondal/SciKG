{"title": [{"text": "Cross-Sentence N -ary Relation Extraction with Graph LSTMs", "labels": [], "entities": [{"text": "Cross-Sentence N -ary Relation Extraction", "start_pos": 0, "end_pos": 41, "type": "TASK", "confidence": 0.5545458495616913}]}], "abstractContent": [{"text": "Past work in relation extraction has focused on binary relations in single sentences.", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 13, "end_pos": 32, "type": "TASK", "confidence": 0.9493757784366608}]}, {"text": "Recent NLP inroads in high-value domains have sparked interest in the more general setting of extracting n-ary relations that span multiple sentences.", "labels": [], "entities": []}, {"text": "In this paper, we explore a general relation extraction framework based on graph long short-term memory networks (graph LSTMs) that can be easily extended to cross-sentence n-ary relation extraction.", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 36, "end_pos": 55, "type": "TASK", "confidence": 0.802212119102478}, {"text": "cross-sentence n-ary relation extraction", "start_pos": 158, "end_pos": 198, "type": "TASK", "confidence": 0.6093728691339493}]}, {"text": "The graph formulation provides a unified way of exploring different LSTM approaches and incorporating various intra-sentential and inter-sentential dependencies, such as sequential, syntactic, and discourse relations.", "labels": [], "entities": []}, {"text": "A robust contextual representation is learned for the entities , which serves as input to the relation clas-sifier.", "labels": [], "entities": []}, {"text": "This simplifies handling of relations with arbitrary arity, and enables multi-task learning with related relations.", "labels": [], "entities": []}, {"text": "We evaluate this framework in two important precision medicine settings , demonstrating its effectiveness with both conventional supervised learning and distant supervision.", "labels": [], "entities": []}, {"text": "Cross-sentence extraction produced larger knowledge bases. and multi-task learning significantly improved extraction accuracy.", "labels": [], "entities": [{"text": "Cross-sentence extraction", "start_pos": 0, "end_pos": 25, "type": "TASK", "confidence": 0.7600123882293701}, {"text": "accuracy", "start_pos": 117, "end_pos": 125, "type": "METRIC", "confidence": 0.9837610125541687}]}, {"text": "A thorough analysis of various LSTM approaches yielded useful insight the impact of linguistic analysis on extraction accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 118, "end_pos": 126, "type": "METRIC", "confidence": 0.9294877052307129}]}], "introductionContent": [{"text": "Relation extraction has made great strides in newswire and Web domains.", "labels": [], "entities": [{"text": "Relation extraction", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.9712187051773071}]}, {"text": "Recently, there has * This research was conducted when the authors were at Microsoft Research.", "labels": [], "entities": [{"text": "Microsoft Research", "start_pos": 75, "end_pos": 93, "type": "DATASET", "confidence": 0.9093100726604462}]}, {"text": "been increasing interest in applying relation extraction to high-value domains such as biomedicine.", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 37, "end_pos": 56, "type": "TASK", "confidence": 0.8926149308681488}]}, {"text": "The advent of $1000 human genome 1 heralds the dawn of precision medicine, but progress in personalized cancer treatment has been hindered by the arduous task of interpreting genomic data using prior knowledge.", "labels": [], "entities": []}, {"text": "For example, given a tumor sequence, a molecular tumor board needs to determine which genes and mutations are important, and what drugs are available to treat them.", "labels": [], "entities": []}, {"text": "Already the research literature has a wealth of relevant knowledge, and it is growing at an astonishing rate.", "labels": [], "entities": []}, {"text": "PubMed 2 , the online repository of biomedical articles, adds two new papers per minute, or one million each year.", "labels": [], "entities": [{"text": "PubMed 2", "start_pos": 0, "end_pos": 8, "type": "DATASET", "confidence": 0.9173530638217926}]}, {"text": "It is thus imperative to advance relation extraction for machine reading.", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 33, "end_pos": 52, "type": "TASK", "confidence": 0.8214551210403442}, {"text": "machine reading", "start_pos": 57, "end_pos": 72, "type": "TASK", "confidence": 0.8144377768039703}]}, {"text": "In the vast literature on relation extraction, past work focused primarily on binary relations in single sentences, limiting the available information.", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 26, "end_pos": 45, "type": "TASK", "confidence": 0.9327085912227631}]}, {"text": "Consider the following example: \"The deletion mutation on exon-19 of EGFR gene was present in 16 patients, while the L858E point mutation on exon-21 was noted in 10.", "labels": [], "entities": [{"text": "EGFR gene", "start_pos": 69, "end_pos": 78, "type": "DATASET", "confidence": 0.9486851096153259}]}, {"text": "All patients were treated with gefitinib and showed a partial response.\".", "labels": [], "entities": []}, {"text": "Collectively, the two sentences convey the fact that there is a ternary interaction between the three entities in bold, which is not expressed in either sentence alone.", "labels": [], "entities": []}, {"text": "Namely, tumors with L858E mutation in EGFR gene can be treated with gefitinib.", "labels": [], "entities": []}, {"text": "Extracting such knowledge clearly requires moving beyond binary relations and single sentences.", "labels": [], "entities": [{"text": "Extracting", "start_pos": 0, "end_pos": 10, "type": "TASK", "confidence": 0.9674662947654724}]}, {"text": "N -ary relations and cross-sentence extraction have received relatively little attention in the past.", "labels": [], "entities": [{"text": "cross-sentence extraction", "start_pos": 21, "end_pos": 46, "type": "TASK", "confidence": 0.8550885319709778}]}, {"text": "Prior  work on n-ary relation extraction focused on single sentences) or entity-centric attributes that can be extracted largely independently.", "labels": [], "entities": [{"text": "n-ary relation extraction", "start_pos": 15, "end_pos": 40, "type": "TASK", "confidence": 0.6894835035006205}]}, {"text": "Prior work on cross-sentence extraction often used coreference to gain access to arguments in a different sentence), without truly modeling inter-sentential relational patterns.", "labels": [], "entities": [{"text": "cross-sentence extraction", "start_pos": 14, "end_pos": 39, "type": "TASK", "confidence": 0.8418988585472107}]}, {"text": "(See Section 7 fora more detailed discussion.)", "labels": [], "entities": []}, {"text": "A notable exception is, which applied distant supervision to general cross-sentence relation extraction, but was limited to binary relations.", "labels": [], "entities": [{"text": "cross-sentence relation extraction", "start_pos": 69, "end_pos": 103, "type": "TASK", "confidence": 0.6706916093826294}]}, {"text": "In this paper, we explore a general framework for cross-sentence n-ary relation extraction, based on graph long short-term memory networks (graph LSTMs).", "labels": [], "entities": [{"text": "cross-sentence n-ary relation extraction", "start_pos": 50, "end_pos": 90, "type": "TASK", "confidence": 0.6618223115801811}]}, {"text": "By adopting the graph formulation, our framework subsumes prior approaches based on chain or tree LSTMs, and can incorporate a rich set of linguistic analyses to aid relation extraction.", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 166, "end_pos": 185, "type": "TASK", "confidence": 0.8393786549568176}]}, {"text": "Relation classification takes as input the entity representations learned from the entire text, and can be easily extended for arbitrary relation arity n.", "labels": [], "entities": [{"text": "Relation classification", "start_pos": 0, "end_pos": 23, "type": "TASK", "confidence": 0.8737791478633881}]}, {"text": "This approach also facilitates joint learning with kindred relations where the supervision signal is more abundant.", "labels": [], "entities": []}, {"text": "We conducted extensive experiments on two important domains in precision medicine.", "labels": [], "entities": []}, {"text": "In both distant supervision and supervised learning settings, graph LSTMs that encode rich linguistic knowledge outperformed other neural network variants, as well as a well-engineered feature-based classifier.", "labels": [], "entities": []}, {"text": "Multitask learning with sub-relations led to further improvement.", "labels": [], "entities": []}, {"text": "Syntactic analysis conferred a significant benefit to the performance of graph LSTMs, especially when syntax accuracy was high.", "labels": [], "entities": [{"text": "Syntactic analysis", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.7072369605302811}, {"text": "accuracy", "start_pos": 109, "end_pos": 117, "type": "METRIC", "confidence": 0.9670918583869934}]}, {"text": "In the molecular tumor board domain, PubMedscale extraction using distant supervision from a small set of known interactions produced orders of magnitude more knowledge, and cross-sentence extraction tripled the yield compared to single-sentence extraction.", "labels": [], "entities": [{"text": "PubMedscale extraction", "start_pos": 37, "end_pos": 59, "type": "TASK", "confidence": 0.7599228918552399}, {"text": "cross-sentence extraction", "start_pos": 174, "end_pos": 199, "type": "TASK", "confidence": 0.7578364312648773}]}, {"text": "Manual evaluation verified that the accuracy is high despite the lack of annotated examples.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 36, "end_pos": 44, "type": "METRIC", "confidence": 0.9996981620788574}]}, {"text": "2 Cross-sentence n-ary relation extraction Let e 1 , \u00b7 \u00b7 \u00b7 , em be entity mentions in text T . Relation extraction can be formulated as a classification problem of determining whether a relation R holds fore 1 , \u00b7 \u00b7 \u00b7 , em in T . For example, given a cancer patient with mutation v in gene g, a molecular tumor board seeks to find if this type of cancer would respond to drug d.", "labels": [], "entities": [{"text": "Cross-sentence n-ary relation extraction", "start_pos": 2, "end_pos": 42, "type": "TASK", "confidence": 0.5839782506227493}, {"text": "Relation extraction", "start_pos": 95, "end_pos": 114, "type": "TASK", "confidence": 0.9606088399887085}]}, {"text": "Literature with such knowledge has been growing rapidly; we can help the tumor board by checking if the Respond relation holds for the triple.", "labels": [], "entities": [{"text": "Respond relation", "start_pos": 104, "end_pos": 120, "type": "METRIC", "confidence": 0.9550235569477081}]}, {"text": "Traditional relation extraction methods focus on binary relations where all entities occur in the same sentence (i.e., m = 2 and T is a sentence), and cannot handle the aforementioned ternary relations.", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 12, "end_pos": 31, "type": "TASK", "confidence": 0.7941604852676392}]}, {"text": "Moreover, as we focus on more complex relations and n increases, it becomes increasingly rare that the related entities will be contained entirely in a single sentence.", "labels": [], "entities": []}, {"text": "In this paper, we generalize extraction to cross-sentence, n-ary relations, where m > 2 and T can contain multiple sentences.", "labels": [], "entities": []}, {"text": "As will be shown in our experiments section, n-ary relations are crucial for high-value domains such as biomedicine, and expanding beyond the sentence boundary enables the extraction of more knowledge.", "labels": [], "entities": []}, {"text": "In the standard binary-relation setting, the dominant approaches are generally defined in terms of the shortest dependency path between the two entities in question, either by deriving rich features from the path or by modeling it using deep neural networks.", "labels": [], "entities": []}, {"text": "Generalizing this paradigm to the n-ary setting is challenging, as there are n 2 paths.", "labels": [], "entities": []}, {"text": "One apparent solution is inspired by Davidsonian semantics: first, identify a single trigger phrase that signifies the whole relation, then reduce the n-ary relation ton binary relations between the trigger and an argument.", "labels": [], "entities": []}, {"text": "It is often hard to specify a single trigger, as the relation is manifested by several words, often not contiguous.", "labels": [], "entities": []}, {"text": "Moreover, it is expensive and time-consuming to annotate training examples, especially if triggers are required, as is evident in prior annotation efforts such as GENIA ().", "labels": [], "entities": [{"text": "GENIA", "start_pos": 163, "end_pos": 168, "type": "DATASET", "confidence": 0.874742865562439}]}, {"text": "The realistic and widely adopted paradigm is to leverage indirect supervision, such as distant supervision, where triggers are not available.", "labels": [], "entities": []}, {"text": "Additionally, lexical and syntactic patterns signifying the relation will be sparse.", "labels": [], "entities": []}, {"text": "To handle such sparsity, traditional feature-based approaches require extensive engineering and large data.", "labels": [], "entities": []}, {"text": "Unfortunately, this challenge becomes much more severe in crosssentence extraction when the text spans multiple sentences.", "labels": [], "entities": [{"text": "crosssentence extraction", "start_pos": 58, "end_pos": 82, "type": "TASK", "confidence": 0.8882445096969604}]}, {"text": "To overcome these challenges, we explore a general relation extraction framework based on graph LSTMs.", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 51, "end_pos": 70, "type": "TASK", "confidence": 0.8153217732906342}]}, {"text": "By learning a continuous representation for words and entities, LSTMs can handle sparsity effectively without requiring intense feature engineering.", "labels": [], "entities": []}, {"text": "The graph formulation subsumes prior LSTM approaches based on chains or trees, and can incorporate rich linguistic analyses.", "labels": [], "entities": []}, {"text": "This approach also opens up opportunities for joint learning with related relations.", "labels": [], "entities": []}, {"text": "For example, the Response relation over d, g, v also implies a binary sub-relation over drug d and mutation v, with the gene underspecified.", "labels": [], "entities": [{"text": "Response", "start_pos": 17, "end_pos": 25, "type": "METRIC", "confidence": 0.9000971913337708}]}, {"text": "Even with distant supervision, the supervision signal for n-ary relations will likely be sparser than their binary sub-relations.", "labels": [], "entities": []}, {"text": "Our approach makes it very easy to use multi-task learning over both the n-ary relations and their sub-relations.", "labels": [], "entities": []}], "datasetContent": [{"text": "We obtained biomedical literature from PubMed Central , consisting of approximately one million fulltext articles as of 2015.", "labels": [], "entities": [{"text": "biomedical literature from PubMed Central", "start_pos": 12, "end_pos": 53, "type": "DATASET", "confidence": 0.6277683794498443}]}, {"text": "Note that only a fraction of papers contain knowledge about drug-gene-mutation interactions.", "labels": [], "entities": []}, {"text": "Extracting such knowledge from the vast body of biomedical papers is exactly the challenge.", "labels": [], "entities": [{"text": "Extracting", "start_pos": 0, "end_pos": 10, "type": "TASK", "confidence": 0.9601213335990906}]}, {"text": "As we will see in later subsections, distant supervision enables us to generate a sizable training set from a small number of manually curated facts, and the learned model was able to extract orders of magnitude more facts.", "labels": [], "entities": []}, {"text": "In future work, we will explore incorporating more known facts for distant supervision and extracting from more full-text articles.", "labels": [], "entities": []}, {"text": "We conducted tokenization, part-of-speech tagging, and syntactic parsing using SPLAT, and obtained Stanford dependencies (de) using Stanford CoreNLP).", "labels": [], "entities": [{"text": "part-of-speech tagging", "start_pos": 27, "end_pos": 49, "type": "TASK", "confidence": 0.7021674364805222}, {"text": "syntactic parsing", "start_pos": 55, "end_pos": 72, "type": "TASK", "confidence": 0.7259369641542435}, {"text": "Stanford CoreNLP", "start_pos": 132, "end_pos": 148, "type": "DATASET", "confidence": 0.8945074379444122}]}, {"text": "We used the entity taggers from Literome () to identify drug, gene and mutation mentions.", "labels": [], "entities": []}, {"text": "We used the Gene Drug Knowledge Database (GDKD) () and the Clinical Interpretations of Variants In Cancer (CIVIC) knowledge base 6 for distant supervision.", "labels": [], "entities": [{"text": "Gene Drug Knowledge Database (GDKD)", "start_pos": 12, "end_pos": 47, "type": "DATASET", "confidence": 0.75253769329616}, {"text": "Clinical Interpretations of Variants In Cancer (CIVIC) knowledge base 6", "start_pos": 59, "end_pos": 130, "type": "DATASET", "confidence": 0.6857322653134664}]}, {"text": "The knowledge bases distinguish fine-grained interaction types, which we do not use in this paper.", "labels": [], "entities": []}, {"text": "To compare the various models in our proposed framework, we conducted five-fold cross-validation, treating the positive and negative examples from distant supervision as gold annotation.", "labels": [], "entities": []}, {"text": "To avoid traintest contamination, all examples from a document were assigned to the same fold.", "labels": [], "entities": []}, {"text": "Since our datasets are balanced by construction, we simply report average test accuracy on held-out folds.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 79, "end_pos": 87, "type": "METRIC", "confidence": 0.9602547883987427}]}, {"text": "Obviously, the    results could be noisy (e.g., entity triples not known to have an interaction might actually have one), but this evaluation is automatic and can quickly evaluate the impact of various design choices.", "labels": [], "entities": []}, {"text": "We evaluated two variants of graph LSTMs: \"Graph LSTM-FULL\" with full parametrization and \"Graph LSTM-EMBED\" with edge-type embedding.", "labels": [], "entities": []}, {"text": "We compared graph LSTMs with three strong baseline systems: a well-engineered feature-based classifier, a convolutional neural network (CNN) (, and a bi-directional LSTM (BiLSTM).", "labels": [], "entities": []}, {"text": "Following , we used input attention for the CNN and a input window size of 5.", "labels": [], "entities": [{"text": "CNN", "start_pos": 44, "end_pos": 47, "type": "DATASET", "confidence": 0.8661512136459351}]}, {"text": "We extended it to ternary relations by deriving features for each entity pair (with added annotation to signify the two entity types), and pooling the features from all pairs.", "labels": [], "entities": []}, {"text": "For binary relation extraction, prior syntax-aware approaches are directly applicable.", "labels": [], "entities": [{"text": "binary relation extraction", "start_pos": 4, "end_pos": 30, "type": "TASK", "confidence": 0.7050219575564066}]}, {"text": "So we also compared with a state-of-the-art tree LSTM system) and a BiLSTM on the shortest dependency path between the two entities (BiLSTM-Shortest-Path) (.", "labels": [], "entities": []}, {"text": "shows the results for cross-sentence, ternary relation extraction.", "labels": [], "entities": [{"text": "ternary relation extraction", "start_pos": 38, "end_pos": 65, "type": "TASK", "confidence": 0.5975197553634644}]}, {"text": "All neural-network based models outperformed the feature-based classifier, illustrating their advantage in handling sparse linguistic patterns without requiring intense feature engineering.", "labels": [], "entities": []}, {"text": "All LSTMs significantly outperformed CNN in the cross-sentence setting, verifying the importance in capturing long-distance dependencies.", "labels": [], "entities": []}, {"text": "The two variants of graph LSTMs perform on par with each other, though Graph LSTM-FULL has a small advantage, suggesting that further exploration of parametrization schemes could be beneficial.", "labels": [], "entities": []}, {"text": "In particular, the edge-type embedding might improve by pretraining on unlabeled text with syntactic parses.", "labels": [], "entities": []}, {"text": "Both graph variants significantly outperformed BiLSTMs (p < 0.05 by McNemar's chi-square test), though the difference is small.", "labels": [], "entities": []}, {"text": "In, the best system incorporated syntactic dependencies and outperformed the linear-chain variant (Base) by a large margin.", "labels": [], "entities": []}, {"text": "So why didn't graph LSTMs make an equally substantial gain by modeling syntactic dependencies?", "labels": [], "entities": []}, {"text": "One reason is that linear-chain LSTMs can already captured some of the long-distance dependencies available in syntactic parses.", "labels": [], "entities": []}, {"text": "BiLSTMs substantially outperformed the feature-based classifier, even without explicit modeling of syntactic dependencies.", "labels": [], "entities": []}, {"text": "The gain cannot be entirely attributed to word embedding as LSTMs also outperformed CNNs.", "labels": [], "entities": []}, {"text": "Another reason is that syntactic parsing is less accurate in the biomedical domain.", "labels": [], "entities": [{"text": "syntactic parsing", "start_pos": 23, "end_pos": 40, "type": "TASK", "confidence": 0.8102794587612152}]}, {"text": "Parse errors confuse the graph LSM learner, limiting the potential for gain.", "labels": [], "entities": [{"text": "Parse", "start_pos": 0, "end_pos": 5, "type": "METRIC", "confidence": 0.9555723071098328}]}, {"text": "In Section 6, we show supporting evidence in a domain when gold parses are available.", "labels": [], "entities": []}, {"text": "We also reported accuracy on instances within single sentences, which exhibited a broadly similar set of trends.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 17, "end_pos": 25, "type": "METRIC", "confidence": 0.9993977546691895}]}, {"text": "Note that single-sentence and crosssentence accuracies are not directly comparable, as the test sets are different (one subsumes the other).", "labels": [], "entities": []}, {"text": "We conducted the same experiments on the binary sub-relation between drug-mutation pairs.", "labels": [], "entities": []}, {"text": "Graph LSTM 80.7 76.7 +Multi-task 82.0 78.5: Multi-task learning improved accuracy for both BiLSTMs and Graph LSTMs.", "labels": [], "entities": [{"text": "Graph LSTM 80.7 76.7", "start_pos": 0, "end_pos": 20, "type": "DATASET", "confidence": 0.8635244369506836}, {"text": "accuracy", "start_pos": 73, "end_pos": 81, "type": "METRIC", "confidence": 0.9991175532341003}]}, {"text": "shows the results, which are similar to the ternary case: Graph LSTM-FULL consistently performed the best for both single sentence and cross-sentence instances.", "labels": [], "entities": []}, {"text": "BiLSTMs on the shortest path substantially underperformed BiLSTMs or graph LSTMs, losing between 4-5 absolute points inaccuracy, which could be attributed to the lower parsing quality in the biomedical domain.", "labels": [], "entities": []}, {"text": "Interestingly, the state-of-the-art tree LSTMs (Miwa and Bansal, 2016) also underperformed graph LSTMs, even though they encoded essentially the same linguistic structures (word adjacency and syntactic dependency).", "labels": [], "entities": []}, {"text": "We attributed the gain to the fact that Miwa and Bansal (2016) used separate LSTMs for the linear chain and the dependency tree, whereas graph LSTMs learned a single representation for both.", "labels": [], "entities": []}, {"text": "To evaluate whether joint learning with subrelations can help, we conducted multi-task learning using Graph LSTM-FULL to jointly train extractors for both the ternary interaction and the drug-mutation, drug-gene sub-relations.", "labels": [], "entities": []}, {"text": "Multi-task learning resulted in a significant gain for both the ternary interaction and the drug-mutation interaction.", "labels": [], "entities": []}, {"text": "Interestingly, the advantage of graph LSTMs over BiLSTMs is reduced with multi-task learning, suggesting that with more supervision signal, even linear-chain LSTMs can learn to capture long-range dependencies that are were made evident by parse features in graph LSTMs.", "labels": [], "entities": []}, {"text": "Note that there are many more instances for drug-gene interaction than others, so we only sampled a subset of comparable size.", "labels": [], "entities": []}, {"text": "Therefore, we do not evaluate the performance gain for drug-gene interaction, as in practice, one would simply learn from all available data, and the sub-sampled results are not competitive.", "labels": [], "entities": []}, {"text": "We included coreference and discourse relations in our document graph.", "labels": [], "entities": []}, {"text": "However, we didn't observe any significant gains, similar to the observation in Single-Sent.", "labels": [], "entities": []}, {"text": "Cross-Sent.: Numbers of unique drug-gene-mutation interactions extracted from PubMed Central articles, compared to that from manually curated KBs used in distant supervision.", "labels": [], "entities": [{"text": "PubMed Central articles", "start_pos": 78, "end_pos": 101, "type": "DATASET", "confidence": 0.9733381668726603}]}, {"text": "Quirk and Poon (2017).", "labels": [], "entities": [{"text": "Quirk and Poon (2017)", "start_pos": 0, "end_pos": 21, "type": "DATASET", "confidence": 0.8826493720213572}]}, {"text": "We leave further exploration to future work.", "labels": [], "entities": []}, {"text": "Our automatic evaluations are useful for comparing competing approaches, but may not reflect the true classifier precision as the labels are noisy.", "labels": [], "entities": [{"text": "precision", "start_pos": 113, "end_pos": 122, "type": "METRIC", "confidence": 0.8175845742225647}]}, {"text": "Therefore, we randomly sampled extracted relation instances and asked three researchers knowledgeable in precision medicine to evaluate their correctness.", "labels": [], "entities": []}, {"text": "For each instance, the annotators were presented with the provenance: sentences with the drug, gene, and mutation highlighted.", "labels": [], "entities": []}, {"text": "The annotators determined in Drug Gene Mut.", "labels": [], "entities": [{"text": "Drug Gene Mut.", "start_pos": 29, "end_pos": 43, "type": "DATASET", "confidence": 0.7823094427585602}]}], "tableCaptions": [{"text": " Table 1: Average test accuracy in five-fold cross- validation for drug-gene-mutation ternary interac- tions. Feature-Based used the best performing model  in (Quirk and Poon, 2017) with features derived from  shortest paths between all entity pairs.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 23, "end_pos": 31, "type": "METRIC", "confidence": 0.9880943894386292}]}, {"text": " Table 2: Average test accuracy in five-fold cross- validation for drug-mutation binary relations, with  an extra baseline using a BiLSTM on the shortest  dependency path (Xu et al., 2015b; Miwa and Bansal,  2016).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 23, "end_pos": 31, "type": "METRIC", "confidence": 0.9828709363937378}, {"text": "BiLSTM", "start_pos": 131, "end_pos": 137, "type": "METRIC", "confidence": 0.9786240458488464}]}, {"text": " Table 3: Multi-task learning improved accuracy for  both BiLSTMs and Graph LSTMs.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 39, "end_pos": 47, "type": "METRIC", "confidence": 0.9994057416915894}]}, {"text": " Table 4: Numbers of unique drug-gene-mutation in- teractions extracted from PubMed Central articles,  compared to that from manually curated KBs used in  distant supervision. p signifies output probability.", "labels": [], "entities": [{"text": "PubMed Central articles", "start_pos": 77, "end_pos": 100, "type": "DATASET", "confidence": 0.9792103171348572}]}, {"text": " Table 5: Numbers of unique drugs, genes and muta- tions in extraction from PubMed Central articles, in  comparison with that in the manually curated Gene  Drug Knowledge Database (GDKD) and Clinical In- terpretations of Variants In Cancer (CIVIC) used for  distant supervision. p signifies output probability.", "labels": [], "entities": [{"text": "PubMed Central articles", "start_pos": 76, "end_pos": 99, "type": "DATASET", "confidence": 0.9652938445409139}]}, {"text": " Table 7: GENIA test results on the binary relation  of gene regulation. Graph LSTM (GOLD) used gold  syntactic parses in the document graph.", "labels": [], "entities": [{"text": "Graph LSTM (GOLD", "start_pos": 73, "end_pos": 89, "type": "DATASET", "confidence": 0.5256790518760681}]}]}