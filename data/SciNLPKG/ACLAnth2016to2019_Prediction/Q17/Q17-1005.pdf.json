{"title": [{"text": "A Polynomial-Time Dynamic Programming Algorithm for Phrase-Based Decoding with a Fixed Distortion Limit", "labels": [], "entities": []}], "abstractContent": [{"text": "Decoding of phrase-based translation models in the general case is known to be NP-complete, by a reduction from the traveling salesman problem (Knight, 1999).", "labels": [], "entities": [{"text": "phrase-based translation", "start_pos": 12, "end_pos": 36, "type": "TASK", "confidence": 0.5927998274564743}]}, {"text": "In practice, phrase-based systems often impose a hard distortion limit that limits the movement of phrases during translation.", "labels": [], "entities": []}, {"text": "However, the impact on complexity after imposing such a constraint is not well studied.", "labels": [], "entities": []}, {"text": "In this paper, we describe a dynamic programming algorithm for phrase-based decoding with a fixed distortion limit.", "labels": [], "entities": []}, {"text": "The runtime of the algorithm is O(nd!lh d+1) where n is the sentence length, dis the distortion limit, l is abound on the number of phrases starting at any position in the sentence, and h is related to the maximum number of target language translations for any source word.", "labels": [], "entities": [{"text": "O", "start_pos": 32, "end_pos": 33, "type": "METRIC", "confidence": 0.9724830985069275}]}, {"text": "The algorithm makes use of a novel representation that gives anew perspective on decoding of phrase-based models.", "labels": [], "entities": []}], "introductionContent": [{"text": "Phrase-based translation models () are widely used in statistical machine translation.", "labels": [], "entities": [{"text": "Phrase-based translation", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.7752575576305389}, {"text": "statistical machine translation", "start_pos": 54, "end_pos": 85, "type": "TASK", "confidence": 0.6781901021798452}]}, {"text": "The decoding problem for phrase-based translation models is known to be difficult: the results from imply that in the general case decoding of phrase-based translation models is NP-complete.", "labels": [], "entities": []}, {"text": "The complexity of phrase-based decoding comes from reordering of phrases.", "labels": [], "entities": []}, {"text": "In practice, however, various constraints on reordering are often imposed in phrase-based translation systems.", "labels": [], "entities": [{"text": "phrase-based translation", "start_pos": 77, "end_pos": 101, "type": "TASK", "confidence": 0.6890219449996948}]}, {"text": "A common constraint is a \"distortion limit\", which places a hard constraint on how far phrases can move.", "labels": [], "entities": [{"text": "distortion limit", "start_pos": 26, "end_pos": 42, "type": "METRIC", "confidence": 0.9352164268493652}]}, {"text": "The complexity of decoding with such a distortion limit is an open question: the NP-hardness result from Knight * On leave from Columbia University.", "labels": [], "entities": []}, {"text": "(1999) applies to a phrase-based model with no distortion limit.", "labels": [], "entities": []}, {"text": "This paper describes an algorithm for phrasebased decoding with a fixed distortion limit whose runtime is linear in the length of the sentence, and fora fixed distortion limit is polynomial in other factors.", "labels": [], "entities": [{"text": "phrasebased decoding", "start_pos": 38, "end_pos": 58, "type": "TASK", "confidence": 0.8203816711902618}]}, {"text": "More specifically, fora hard distortion limit d, and sentence length n, the runtime is O(nd!lh d+1 ), where l is abound on the number of phrases starting at any point in the sentence, and h is related to the maximum number of translations for any word in the source language sentence.", "labels": [], "entities": [{"text": "O", "start_pos": 87, "end_pos": 88, "type": "METRIC", "confidence": 0.9831796884536743}]}, {"text": "The algorithm builds on the insight that decoding with a hard distortion limit is related to the bandwidth-limited traveling salesman problem (BTSP) (.", "labels": [], "entities": []}, {"text": "The algorithm is easily amenable to beam search.", "labels": [], "entities": [{"text": "beam search", "start_pos": 36, "end_pos": 47, "type": "TASK", "confidence": 0.9384733438491821}]}, {"text": "It is quite different from previous methods for decoding of phrase-based models, potentially opening up a very different way of thinking about decoding algorithms for phrasebased models, or more generally for models in statistical NLP that involve reordering.", "labels": [], "entities": []}, {"text": "proves that decoding of word-to-word translation models is NP-complete, assuming that there is no hard limit on distortion, through a reduction from the traveling salesman problem.", "labels": [], "entities": [{"text": "decoding of word-to-word translation", "start_pos": 12, "end_pos": 48, "type": "TASK", "confidence": 0.6351380571722984}]}, {"text": "Phrasebased models are more general than word-to-word models, hence this result implies that phrase-based decoding with unlimited distortion is NP-complete.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": []}