{"title": [{"text": "Visually Grounded and Textual Semantic Models Differentially Decode Brain Activity Associated with Concrete and Abstract Nouns", "labels": [], "entities": []}], "abstractContent": [{"text": "Important advances have recently been made using computational semantic models to decode brain activity patterns associated with concepts; however, this work has almost exclusively focused on concrete nouns.", "labels": [], "entities": []}, {"text": "How well these models extend to decoding abstract nouns is largely unknown.", "labels": [], "entities": []}, {"text": "We address this question by applying state-of-the-art computational models to decode functional Magnetic Resonance Imaging (fMRI) activity patterns, elicited by participants reading and imagining a diverse set of both concrete and abstract nouns.", "labels": [], "entities": [{"text": "Magnetic Resonance Imaging (fMRI) activity patterns", "start_pos": 96, "end_pos": 147, "type": "TASK", "confidence": 0.7680024206638336}]}, {"text": "One of the models we use is linguistic, exploiting the recent word2vec skipgram approach trained on Wikipedia.", "labels": [], "entities": []}, {"text": "The second is visually grounded, using deep convolutional neural networks trained on Google Images.", "labels": [], "entities": []}, {"text": "Dual coding theory considers concrete concepts to be encoded in the brain both linguistically and visually, and abstract concepts only linguistically.", "labels": [], "entities": [{"text": "Dual coding theory", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.8922862609227499}]}, {"text": "Splitting the fMRI data according to human concreteness ratings, we indeed observe that both models significantly decode the most concrete nouns; however, accuracy is significantly greater using the text-based models for the most abstract nouns.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 155, "end_pos": 163, "type": "METRIC", "confidence": 0.9994220733642578}]}, {"text": "More generally this confirms that current computational models are sufficiently advanced to assist in investigating the representational structure of abstract concepts in the brain.", "labels": [], "entities": []}], "introductionContent": [{"text": "Since the work of, there has been increasing interest in using computational semantic models to interpret neural activity patterns scanned as participants engage in conceptual tasks.", "labels": [], "entities": []}, {"text": "This research has almost exclusively focused on brain activity elicited as participants comprehend concrete nouns as experimental stimuli.", "labels": [], "entities": []}, {"text": "Different modelling approaches -predominantly distributional semantic models () and semantic models based on human behavioural estimation of conceptual features () -have elucidated how different brain regions contribute to semantic representation of concrete nouns; however, how these results extend to non-concrete nouns is unknown.", "labels": [], "entities": [{"text": "semantic representation of concrete nouns", "start_pos": 223, "end_pos": 264, "type": "TASK", "confidence": 0.7865052103996277}]}, {"text": "In computational modelling there has been increasing importance attributed to grounding semantic models in sensory modalities, e.g.,,.", "labels": [], "entities": []}, {"text": "demonstrated that multi-modal models formed by combining text-based distributional information with behaviourally generated conceptual properties (as a surrogate for perceptual experience) provide a better proxy for human-like intelligence.", "labels": [], "entities": []}, {"text": "However, both the text-based and behaviourallybased components of their model were ultimately derived from linguistic information.", "labels": [], "entities": []}, {"text": "Since then, in analyses of brain data, have applied multi-modal models incorporating features that are truly grounded in natural image statistics to further support this claim.", "labels": [], "entities": []}, {"text": "In addition, have demonstrated that visually grounded models describe brain activity associated with internally induced visual features of objects as the ob-jects names are read and comprehended.", "labels": [], "entities": []}, {"text": "Having both image-and text-based models of semantic representation, and neural activity patterns associated with concrete and abstract nouns, enables a natural test of Dual coding theory.", "labels": [], "entities": [{"text": "semantic representation", "start_pos": 43, "end_pos": 66, "type": "TASK", "confidence": 0.715787261724472}, {"text": "Dual coding theory", "start_pos": 168, "end_pos": 186, "type": "TASK", "confidence": 0.9201765855153402}]}, {"text": "Dual coding posits that concrete concepts are represented in the brain in terms of a visual and linguistic code, whereas abstract concepts are only represented by a linguistic code.", "labels": [], "entities": [{"text": "Dual coding", "start_pos": 0, "end_pos": 11, "type": "TASK", "confidence": 0.7826859056949615}]}, {"text": "Whereas previous work has demonstrated that image-and text-based semantic models contribute to explaining neural activity patterns associated with concrete nouns, it remains unclear whether either text-or image-based semantic models can decode neural activity patterns associated with abstract words.", "labels": [], "entities": []}, {"text": "We extend previous work by applying image-and text-based computational semantic models to decode an fMRI data set spanning a diverse set of nouns of varying concreteness.", "labels": [], "entities": [{"text": "fMRI data set", "start_pos": 100, "end_pos": 113, "type": "DATASET", "confidence": 0.8465774854024252}]}, {"text": "The 70-word stimuli for the fMRI experiment (listed in) are semantically structured according to taxonomic categories and domains embedded in WordNet) and its extensions.", "labels": [], "entities": [{"text": "fMRI experiment", "start_pos": 28, "end_pos": 43, "type": "DATASET", "confidence": 0.8871908485889435}]}, {"text": "Participants read the noun and were instructed to imagine a situation that they personally associate with the noun.", "labels": [], "entities": []}, {"text": "In this sense, the data solicited was targetting deep thought patterns (deeper than might be anticipated for rapid semantic processing required in conversations and many real time interactions with the world).", "labels": [], "entities": []}, {"text": "In the analysis we split the fMRI data set into the most concrete and most abstract words based on behavioural concreteness ratings.", "labels": [], "entities": [{"text": "fMRI data set", "start_pos": 29, "end_pos": 42, "type": "DATASET", "confidence": 0.96605517466863}]}, {"text": "Our key contribution is in demonstrating a decoding advantage for text-based semantic models over the image-based models when decoding the more abstract nouns.", "labels": [], "entities": []}, {"text": "In line with the previous results of and, both visual and textual models decode the more concrete nouns.", "labels": [], "entities": []}, {"text": "The image-and text-based computational models we use have recently been developed using neural networks ().", "labels": [], "entities": []}, {"text": "The image-based model is built using a deep convolutional neural network approach, similar in nature to those recently used to study neural representations of visual stimuli (see, although note this is the first application to study word elicited neural activation known to the authors).", "labels": [], "entities": []}, {"text": "For decoding we use a recently introduced algorithm ) that abstracts the decoding task to representational similarity space, and achieve decoding accuracies on par with those conventionally achieved through discriminating concrete nouns (and higher if we combine data to exploit grouplevel regularities).", "labels": [], "entities": []}, {"text": "Because the fMRI experiments were performed in Italian on native Italians, and because approximately comparable text corpora in content were available in English and Italian (English and Italian Wikipedia), we were able to compare how well English and Italian text-based semantic models can decode neural activity patterns.", "labels": [], "entities": []}, {"text": "Whilst Italian Wikipedia could reasonably be expected to be advantaged by supporting culturally appropriate nuances of semantic structure, it is disadvantaged by being considerably smaller than English Wikipedia.", "labels": [], "entities": []}, {"text": "Taking inspiration from previous work exploiting cross-lingual resources ( we combined Italian and English text-based models in our decoding analyses in an attempt to leverage the benefits of both.", "labels": [], "entities": []}, {"text": "Although combined language and English models tended to yield marginally better decoding accuracies, there were no significant differences between the different language models.", "labels": [], "entities": []}, {"text": "Whilst we expect semantic structure on a grand scale to broadly straddle language boundaries for most concrete and abstract concepts (albeit with cultural specificities), this is proof of principle that cross linguistic commonalities are reflected in neural activity patterns measurable with current technology.", "labels": [], "entities": []}], "datasetContent": [{"text": "Participants Nine right-handed native Italian speakers aged between 19 and 38 years (3 women) were recruited to take part in the study.", "labels": [], "entities": []}, {"text": "Two were scanned after to match the number of participants analysed by.", "labels": [], "entities": []}, {"text": "Scanning had previously been halted at 7 instead of the planned 9 participants fora period due to equipment failure.", "labels": [], "entities": []}, {"text": "All had normal or correctedto-normal vision.", "labels": [], "entities": []}, {"text": "The 70 stimulus words were presented as written words, in 5 runs (all runs were collected in one participant visit), with the order of presentations randomised across runs.", "labels": [], "entities": []}, {"text": "In each run, a randomly selected word was presented every 10 seconds, and remained onscreen for 3 seconds.", "labels": [], "entities": []}, {"text": "On reading a stimulus word, participants thought of a situation that they individually associated with the noun.", "labels": [], "entities": []}, {"text": "This process is similar to previous concrete noun tasks, e.g.,, where participants were instructed to think of the properties of the noun.", "labels": [], "entities": []}, {"text": "However, as people encounter difficulties eliciting properties of non-concrete concepts, compared to thinking of situations in which concepts played a role), the experimental paradigm was adapted to imagining situations.", "labels": [], "entities": []}, {"text": "fMRI acquisition and preprocessing recorded fMRI images on a 4T Bruker MedSpec MRI scanner.", "labels": [], "entities": [{"text": "fMRI acquisition", "start_pos": 0, "end_pos": 16, "type": "TASK", "confidence": 0.8321850299835205}, {"text": "Bruker MedSpec MRI scanner", "start_pos": 64, "end_pos": 90, "type": "DATASET", "confidence": 0.7509260848164558}]}, {"text": "They used an Echo Planar Imaging (EPI) pulse sequence with a 1000 msec repetition time, an echo time of 33 msec, and a 26 \u2022 flip angle.", "labels": [], "entities": [{"text": "repetition", "start_pos": 71, "end_pos": 81, "type": "METRIC", "confidence": 0.9392703771591187}, {"text": "echo time", "start_pos": 91, "end_pos": 100, "type": "METRIC", "confidence": 0.9694486856460571}]}, {"text": "A 64\u00d764 acquisition matrix was used, and 17 slices were imaged with a between-slice gap of 1 mm.", "labels": [], "entities": []}, {"text": "Voxels had dimensions of 3mm\u00d73mm\u00d75mm.", "labels": [], "entities": []}, {"text": "fMRI data were corrected for head motion, unwarped, and spatially normalized to the Montreal Neurological Institute and Hospital (MNI) template.", "labels": [], "entities": [{"text": "Montreal Neurological Institute and Hospital (MNI) template", "start_pos": 84, "end_pos": 143, "type": "DATASET", "confidence": 0.9391710493299696}]}, {"text": "Only voxels estimated to be grey matter were included in the subsequent analysis.", "labels": [], "entities": []}, {"text": "For each participant, for each scanning run (where a run is a complete presentation of 70 words), voxel activity was corrected by removing linear trend and transformed to z scores (within each run).", "labels": [], "entities": []}, {"text": "Each stimulus word was represented as a single volume by taking the voxel-wise mean of the 4 sec of data offset by 4 sec from the stimulus onset (to account for hemodynamic response).", "labels": [], "entities": []}, {"text": "Voxel selection The 500 most stable grey matter voxels per participant were selected for analysis.", "labels": [], "entities": []}, {"text": "This was undertaken within the leave-2-wordout decoding procedure detailed later in Section 4 using the same method as: Pearson's correlation of each voxel's activity between matched word lists in all scanning run pairs (10 unique run pairs giving 10 correlation coefficients of 68/70 words, where the other 2 words were test words to be decoded) was computed.", "labels": [], "entities": [{"text": "Pearson's correlation", "start_pos": 120, "end_pos": 141, "type": "METRIC", "confidence": 0.8699811100959778}]}, {"text": "The mean coefficient was used as stability measure.", "labels": [], "entities": [{"text": "mean coefficient", "start_pos": 4, "end_pos": 20, "type": "METRIC", "confidence": 0.9741148054599762}]}, {"text": "Voxels associated with the 500 largest stability measures were selected.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2. p=.05 lines were empirically estimated  as described in Section 4 and apply to decoding an individual's fMRI data (not multiple individuals).", "labels": [], "entities": []}]}