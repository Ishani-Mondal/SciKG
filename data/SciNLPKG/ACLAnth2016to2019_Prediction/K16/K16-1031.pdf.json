{"title": [{"text": "Semi-supervised Convolutional Networks for Translation Adaptation with Tiny Amount of In-domain Data", "labels": [], "entities": [{"text": "Translation Adaptation", "start_pos": 43, "end_pos": 65, "type": "TASK", "confidence": 0.974928468465805}]}], "abstractContent": [{"text": "In this paper, we propose a method which uses semi-supervised convolutional neu-ral networks (CNNs) to select in-domain training data for statistical machine translation.", "labels": [], "entities": [{"text": "statistical machine translation", "start_pos": 138, "end_pos": 169, "type": "TASK", "confidence": 0.71331986784935}]}, {"text": "This approach is particularly effective when only tiny amounts of in-domain data are available.", "labels": [], "entities": []}, {"text": "The in-domain data and randomly sampled general-domain data are used to train a data selection model with semi-supervised CNN, then this model computes domain relevance scores for all the sentences in the general-domain data set.", "labels": [], "entities": []}, {"text": "The sentence pairs with top scores are selected to train the system.", "labels": [], "entities": []}, {"text": "We carryout experiments on 4 language directions with three test domains.", "labels": [], "entities": []}, {"text": "Compared with strong baseline systems trained with large amount of data, this method can improve the performance up to 3.1 BLEU.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 123, "end_pos": 127, "type": "METRIC", "confidence": 0.9986135959625244}]}, {"text": "Its performances are significant better than three state-of-the-art language model based data selection methods.", "labels": [], "entities": []}, {"text": "We also show that the in-domain data used to train the selection model could be as few as 100 sentences, which makes fine-grained topic-dependent translation adaptation possible.", "labels": [], "entities": [{"text": "topic-dependent translation adaptation", "start_pos": 130, "end_pos": 168, "type": "TASK", "confidence": 0.665589819351832}]}], "introductionContent": [{"text": "Statistical machine translation (SMT) systems are trained on bilingual parallel and monolingual data.", "labels": [], "entities": [{"text": "Statistical machine translation (SMT)", "start_pos": 0, "end_pos": 37, "type": "TASK", "confidence": 0.8209045132001241}]}, {"text": "The training corpora typically come from different sources, and vary across topics, genres, dialects, authors' written styles, etc., which are usually referred as \"general domain\" training data.", "labels": [], "entities": []}, {"text": "Here the word \"domain\" is often used to indicate some combination of all above and other possible hidden factors . At run time, the content to be translated may come from a different domain.", "labels": [], "entities": []}, {"text": "Due to the mismatch in \"domains\", it is possible to achieve better performance by adapting the SMT system to the test domain (in-domain).", "labels": [], "entities": [{"text": "SMT", "start_pos": 95, "end_pos": 98, "type": "TASK", "confidence": 0.9873678088188171}]}, {"text": "However, manually creating training data to match the test domain is not a preferred solution, because 1) sometimes the test domain is not known when training the model, and it could change from sentence to sentence; 2) even if the test domain is pre-determined, the resources required and slow turnaround in data collection process will still delay the system development process.", "labels": [], "entities": []}, {"text": "Therefore, training data selection is widely used for domain adaptation in statistical machine translation (.", "labels": [], "entities": [{"text": "domain adaptation", "start_pos": 54, "end_pos": 71, "type": "TASK", "confidence": 0.7452885508537292}, {"text": "statistical machine translation", "start_pos": 75, "end_pos": 106, "type": "TASK", "confidence": 0.6460733314355215}]}, {"text": "Data selection techniques select monolingual or bilingual data that are similar to the indomain seed data based on some criteria, which are incorporated into the training data.", "labels": [], "entities": []}, {"text": "The most successful data selection approaches) train n-gram language models on in-domain text to select similar sentences from the large general-domain corpora according to the cross entropy.", "labels": [], "entities": []}, {"text": "Furthermore, ( obtained some gains by extending these approaches from n-gram models to recurrent neural network language models (.", "labels": [], "entities": []}, {"text": "To train the in-domain language model, a reasonable size in-domain data set, which typically includes several thousands of sentences, is required.", "labels": [], "entities": []}, {"text": "In, the sizes of the in-domain data sets are 30K and over 100K sentences respectively.", "labels": [], "entities": []}, {"text": "However, we do not always have access to large or even medium amounts of in-domain data.", "labels": [], "entities": []}, {"text": "With the growth of social media, new domains have emerged which need machine translation but which have very limited in-domain data, maybe just a few hundred sentence pairs.", "labels": [], "entities": []}, {"text": "What's more, if one wishes to build a large scale topic-specific MT system with hundreds of topics, it is prohibitively expensive to collect tens of thousands of in-domain sentences for each topic.", "labels": [], "entities": [{"text": "MT", "start_pos": 65, "end_pos": 67, "type": "TASK", "confidence": 0.9090859889984131}]}, {"text": "In this paper, we try to address this challenge, i.e., domain adaptation with very limited amounts of in-domain data.", "labels": [], "entities": [{"text": "domain adaptation", "start_pos": 55, "end_pos": 72, "type": "TASK", "confidence": 0.8189107775688171}]}, {"text": "Inspired by the success of convolutional neural networks applied to image and text classification (, we propose to use CNN to classify training sentence pairs as in-domain or outof-domain sentences.", "labels": [], "entities": [{"text": "image and text classification", "start_pos": 68, "end_pos": 97, "type": "TASK", "confidence": 0.6781351640820503}]}, {"text": "To overcome the problem of limited in-domain data, we propose to augment the original model with semi-supervised convolutional neural networks for domain classification.", "labels": [], "entities": [{"text": "domain classification", "start_pos": 147, "end_pos": 168, "type": "TASK", "confidence": 0.7237594723701477}]}, {"text": "Convolutional neural networks () are feed-forward neural networks that exploit the internal structure of data through convolution layers; each computation unit processes a small region of the input data.", "labels": [], "entities": []}, {"text": "CNN has been very successful on image classification.", "labels": [], "entities": [{"text": "CNN", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.9423277378082275}, {"text": "image classification", "start_pos": 32, "end_pos": 52, "type": "TASK", "confidence": 0.8800390660762787}]}, {"text": "When applying it to text input, the convolution layers process small regions of a document, i.e., a sequence of sentences or words.", "labels": [], "entities": []}, {"text": "CNN has been gaining attention, and is now used in many text classification tasks ().", "labels": [], "entities": [{"text": "CNN", "start_pos": 0, "end_pos": 3, "type": "TASK", "confidence": 0.646769642829895}, {"text": "text classification tasks", "start_pos": 56, "end_pos": 81, "type": "TASK", "confidence": 0.8695724209149679}]}, {"text": "In many of these studies, the first layer of the network converts words to word embeddings using table lookup.", "labels": [], "entities": []}, {"text": "The word embeddings are either trained as part of CNN training, or pre-trained (thus fixed during model training time) on an additional unlabled corpus.", "labels": [], "entities": []}, {"text": "The later is termed semi-supervised CNN.", "labels": [], "entities": [{"text": "semi-supervised CNN", "start_pos": 20, "end_pos": 39, "type": "TASK", "confidence": 0.5748619735240936}]}, {"text": "Given tiny amounts of indomain data, the information learned in these pretrained word embeddings is very helpful.", "labels": [], "entities": []}, {"text": "We use a small amount of in-domain data, such as the development set, as the positive sample and randomly select the same number of sentences from the general-domain training data as the negative sample to form the training sample for training the CNN classification model.", "labels": [], "entities": [{"text": "CNN classification", "start_pos": 248, "end_pos": 266, "type": "TASK", "confidence": 0.7369454801082611}]}, {"text": "This is atypical supervised learning setting.", "labels": [], "entities": []}, {"text": "To compensate the limit of in-domain data size, we use word2vec ( to learn the word embedding from a large amount of general-domain data.", "labels": [], "entities": []}, {"text": "Together with the labeled data, these word embeddings are fed to the convolution layer as additional input to train the final classification model.", "labels": [], "entities": []}, {"text": "This is a semi-supervised framework.", "labels": [], "entities": []}, {"text": "The learned models are then used to classify each sentence in the general-domain training data based on their domain relevance score.", "labels": [], "entities": []}, {"text": "The top N sentence pairs are selected to train the SMT system.", "labels": [], "entities": [{"text": "SMT", "start_pos": 51, "end_pos": 54, "type": "TASK", "confidence": 0.994835376739502}]}, {"text": "We carryout experiments on 4 different language directions with 9-15M sentence pairs in each direction.", "labels": [], "entities": []}, {"text": "The test domains include short message (sms), tweets, and Facebook posts.", "labels": [], "entities": []}, {"text": "The experimental results show that our method is able to select a small amount of training data that is used to create a system which outperforms baseline systems trained with all the general-domain data.", "labels": [], "entities": []}, {"text": "For example, we obtain over 3.1 BLEU improvement on the Chinese-to-English sms task with around 3% of the whole training data.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 32, "end_pos": 36, "type": "METRIC", "confidence": 0.9995012283325195}]}, {"text": "Experiments also show that we can reduce the size of the in-domain sample to around 100 sentences and still obtain a 2.1 BLEU improvement.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 121, "end_pos": 125, "type": "METRIC", "confidence": 0.9995651841163635}]}], "datasetContent": [{"text": "Our goal is to adapt the MT system when only a tiny amount of in-domain data is available.", "labels": [], "entities": [{"text": "MT", "start_pos": 25, "end_pos": 27, "type": "TASK", "confidence": 0.9686459898948669}]}, {"text": "So in our experiments, we did not consider any domain information about the training data, such as the source of each corpus.", "labels": [], "entities": []}, {"text": "What we have is a small development set (dev) and one or more test sets (test) which are in the same domain.", "labels": [], "entities": []}, {"text": "We experiment with two CNN-based data selection strategies: We employ the dev set as in-domain data.", "labels": [], "entities": [{"text": "CNN-based data selection", "start_pos": 23, "end_pos": 47, "type": "TASK", "confidence": 0.6721271077791849}]}, {"text": "All the supervised CNN models are trained with the in-domain dev data as positive examples and an equal number of randomly selected generaldomain sentences as negative examples.", "labels": [], "entities": []}, {"text": "All the meta-parameters of the CNN are tuned on heldout data; we generate both bow-regions and seqregions and input them to the CNN.", "labels": [], "entities": []}, {"text": "We set the region size to 5 and stride size to 1.", "labels": [], "entities": [{"text": "stride size", "start_pos": 32, "end_pos": 43, "type": "METRIC", "confidence": 0.9527937173843384}]}, {"text": "The nonlinear function we chose is \"ReLU\", the number of weight vectors or neurons is 500.", "labels": [], "entities": [{"text": "ReLU", "start_pos": 36, "end_pos": 40, "type": "METRIC", "confidence": 0.9709545969963074}]}, {"text": "The pooling method is component-wise maximum (max pooling).", "labels": [], "entities": []}, {"text": "We use the online available CNN toolkit conT ext.", "labels": [], "entities": [{"text": "CNN toolkit conT ext", "start_pos": 28, "end_pos": 48, "type": "DATASET", "confidence": 0.8513991981744766}]}, {"text": "To train the general domain word embedding, we used word2vec.", "labels": [], "entities": []}, {"text": "The size of the vector was set to 300.", "labels": [], "entities": []}, {"text": "We also generate wordembedding-based bow-regions and seq-regions as additional input to the: Summary of the data.", "labels": [], "entities": [{"text": "Summary", "start_pos": 93, "end_pos": 100, "type": "METRIC", "confidence": 0.9748114347457886}]}, {"text": "\"sms\" means \"short message\".", "labels": [], "entities": []}, {"text": "\"facebook\" means \"Facebook post\".", "labels": [], "entities": []}, {"text": "Data is given as the number of sentence pairs, \"M\" represents \"million\".", "labels": [], "entities": []}, {"text": "The tasks \"zh2en\" and \"en2zh\" use the same training data.", "labels": [], "entities": []}, {"text": "We compared with four baselines for each task.", "labels": [], "entities": []}, {"text": "The first baseline SMT system is trained using all general-domain data.", "labels": [], "entities": [{"text": "SMT", "start_pos": 19, "end_pos": 22, "type": "TASK", "confidence": 0.9889011383056641}]}, {"text": "The other three systems are trained with data selected with different LM-based data selection methods as same as in (.", "labels": [], "entities": []}, {"text": "The four baselines are: 1.", "labels": [], "entities": []}, {"text": "alldata: All general-domain data.", "labels": [], "entities": []}, {"text": "All systems are trained with a standard phrasebased SMT system with standard settings, i.e., GIZA++ alignment, phrase table Kneser-Ney smoothing, hierarchical reordering models, target side 4-gram language model, \"gigaword\" 5-gram language model for systems with English as the target language, etc.", "labels": [], "entities": [{"text": "SMT", "start_pos": 52, "end_pos": 55, "type": "TASK", "confidence": 0.8177618980407715}, {"text": "phrase table Kneser-Ney smoothing", "start_pos": 111, "end_pos": 144, "type": "TASK", "confidence": 0.585710883140564}]}, {"text": "We evaluated the system using BLEU () score on the test set.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 30, "end_pos": 34, "type": "METRIC", "confidence": 0.9992573857307434}]}, {"text": "Following), we use the bootstrap resampling test to do significance testing.", "labels": [], "entities": []}, {"text": "summarizes the results and numbers of the selected sentences for each task.", "labels": [], "entities": []}, {"text": "First, we can see that all the data selection methods improved the performance over the baseline \"alldata\" with much less training data (only around 2.5% to 10% of the whole training data).", "labels": [], "entities": []}, {"text": "Consistent with (, the three LM based data selection all got improvements, where \"rnnlm\" obtained better performance than the \"ngram\" on average.", "labels": [], "entities": []}, {"text": "It is not clear that combining the two language model methods (\"comblm\") yields further improvement.", "labels": [], "entities": []}, {"text": "While the one-hot CNN method \"ohcnn\" obtained similar improvement as the three LM-based methods on average.", "labels": [], "entities": []}, {"text": "The semi-supervised CNN (sscnn) achieved the best performance for all the tasks: its improvements over the \"alldata\" baseline are 3.1, 1.4, 0.7 and 1.4 BLEU score respectively.", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 152, "end_pos": 162, "type": "METRIC", "confidence": 0.9774893224239349}]}, {"text": "It beats \"ohcnn\" by about 0.5 BLEU point on average.", "labels": [], "entities": [{"text": "ohcnn", "start_pos": 10, "end_pos": 15, "type": "METRIC", "confidence": 0.8747794032096863}, {"text": "BLEU", "start_pos": 30, "end_pos": 34, "type": "METRIC", "confidence": 0.999392032623291}]}, {"text": "There are two results worth noticing.", "labels": [], "entities": []}, {"text": "First, task 1 (zh2en sms task) obtained very high BLEU improvement through data selection.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 50, "end_pos": 54, "type": "METRIC", "confidence": 0.9996474981307983}]}, {"text": "This is because in this task, there is a 120K in-domain subset within the general-domain data.", "labels": [], "entities": []}, {"text": "If we train a system on this in-domain data set, we get 25.7 BLEU on the test set.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 61, "end_pos": 65, "type": "METRIC", "confidence": 0.9993183612823486}]}, {"text": "The LM-based methods did not beat this \"in-domain data only (indata)\" baseline, while the semi-supervised CNN method performed significantly better than this baseline at p < 0.05 level.", "labels": [], "entities": []}, {"text": "In the top 300K selected sentence pairs, LM-based methods can select around 90K out of 120K in-domain sentence pairs, while both \"ohcnn\" and \"sscnn\" can select around 105K indomain sentence pairs.", "labels": [], "entities": []}, {"text": "This demonstrates the effectiveness of the proposed approach.", "labels": [], "entities": []}, {"text": "Second, for the other three tasks, there is no in-domain data component in the general-domain data (that we know of).", "labels": [], "entities": []}, {"text": "Even in this case, we achieved up to 1.4 BLEU improvement, which also demonstrates the effectiveness of our method: it can select highly suitable in-domain sentences, even when the indomain data is very limited.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 41, "end_pos": 45, "type": "METRIC", "confidence": 0.9986461997032166}]}, {"text": "In: Summary of the results.", "labels": [], "entities": [{"text": "Summary", "start_pos": 4, "end_pos": 11, "type": "TASK", "confidence": 0.5092185735702515}]}, {"text": "Data size is given as number of sentence pairs.", "labels": [], "entities": []}, {"text": "The number of selected in-domain sentences is determined by the performance on held-out data.", "labels": [], "entities": []}, {"text": "\"M\" represents million, \"K\" represents thousand.", "labels": [], "entities": []}, {"text": "*/** means result is significantly better than the \"alldata\" baseline at p < 0.05 or p < 0.01 level, respectively.", "labels": [], "entities": []}, {"text": "+/++ means result is significantly better than the best LM-based method at p < 0.05 or p < 0.01 level, respectively. data.", "labels": [], "entities": []}, {"text": "Fixing the number of MT training sentence pairs to 300K that will be selected by the CNN, we reduce the CNN training data from 6,000 down to 100 sentence pairs in steps.", "labels": [], "entities": [{"text": "MT training sentence", "start_pos": 21, "end_pos": 41, "type": "TASK", "confidence": 0.8671239813168844}, {"text": "CNN", "start_pos": 85, "end_pos": 88, "type": "DATASET", "confidence": 0.9531506299972534}, {"text": "CNN training data", "start_pos": 104, "end_pos": 121, "type": "DATASET", "confidence": 0.7278137803077698}]}, {"text": "The performance of the resulting MT systems for all five data selection methods is shown in.", "labels": [], "entities": [{"text": "MT", "start_pos": 33, "end_pos": 35, "type": "TASK", "confidence": 0.9826629161834717}]}, {"text": "From, we can see that all the data selection methods obtained improvement compared to the \"alldata\" baseline.", "labels": [], "entities": []}, {"text": "When the in-domain training sample is more than 1600 sentence pairs, all the data selection methods obtain reasonable and comparable improvement, while \"sscnn\" is better than the best LM-based method by 0.3-0.5 BLEU.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 211, "end_pos": 215, "type": "METRIC", "confidence": 0.998206615447998}]}, {"text": "However, when the in-domain training sample is less than 800 sentence pairs, the difference between the \"sscnn\" and other methods gets bigger, and CNN-based methods get more stable results than the LM-based methods get.", "labels": [], "entities": []}, {"text": "For instance, when the in-domain set increases from 400 to 800, the LM-based methods did not get an improvement; \"ngram\" and \"comblm\" even got a small loss on BLEU score.", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 159, "end_pos": 169, "type": "METRIC", "confidence": 0.9781119525432587}]}, {"text": "When the in-domain sample is reduced to 100 sentence pairs, the LM-based methods only get a small improvement over the baseline, while the \"ohcnn\" got a 1.2 BLEU score improvement over the baseline and \"sscnn\" got a 2.1 BLEU improvement over the baseline.", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 157, "end_pos": 167, "type": "METRIC", "confidence": 0.9746430516242981}, {"text": "BLEU", "start_pos": 220, "end_pos": 224, "type": "METRIC", "confidence": 0.995771586894989}]}, {"text": "Thus, even if we have no domain knowledge about the training data, when we have only 100 sentences in the test domain, the semi-supervised CNN classifier can still select a good in-domain subset and achieve good performance.", "labels": [], "entities": []}, {"text": "We obtained 2.1 BLEU improvement even when we randomly select only 100 in-domain sentence pairs to train the classification model.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 16, "end_pos": 20, "type": "METRIC", "confidence": 0.9990794658660889}]}, {"text": "Is this just because we luckily sampled a good part of the in-domain data?", "labels": [], "entities": []}, {"text": "We repeated the \"100 in-domain sentence pairs experiment\" three times for our most effective method -\"sscnn\" -by sampling three different in-domain sets from the whole 6,016-sentence dev set.", "labels": [], "entities": []}, {"text": "The average BLEU score we got is 25.03, and the standard deviation is 0.12.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 12, "end_pos": 16, "type": "METRIC", "confidence": 0.999327540397644}]}, {"text": "This means that our algorithm is quite stable even when the in-domain set is very small.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Summary of the data. \"sms\" means \"short message\". \"facebook\" means \"Facebook post\". Data  is given as the number of sentence pairs, \"M\" represents \"million\". The tasks \"zh2en\" and \"en2zh\" use  the same training data.", "labels": [], "entities": []}, {"text": " Table 2: Summary of the results. Data size is given as number of sentence pairs. The number of selected  in-domain sentences is determined by the performance on held-out data. \"M\" represents million, \"K\"  represents thousand. */** means result is significantly better than the \"alldata\" baseline at p < 0.05 or  p < 0.01 level, respectively. +/++ means result is significantly better than the best LM-based method at  p < 0.05 or p < 0.01 level, respectively.", "labels": [], "entities": []}]}