{"title": [{"text": "DA-IICT Submission for PDTB-styled Discourse Parser", "labels": [], "entities": [{"text": "PDTB-styled Discourse Parser", "start_pos": 23, "end_pos": 51, "type": "TASK", "confidence": 0.6588735779126486}]}], "abstractContent": [{"text": "The CONLL 2016 Shared task focusses on building a Shallow Discourse Parsing system , which is given apiece of newswire text as input and it returns all discourse relations in that text in the form of discourse connectives, its two arguments and the relation sense.", "labels": [], "entities": [{"text": "CONLL 2016 Shared task", "start_pos": 4, "end_pos": 26, "type": "DATASET", "confidence": 0.8947906047105789}]}, {"text": "We have built a parser for the same.", "labels": [], "entities": []}, {"text": "We follow a pipeline architecture to build the system.", "labels": [], "entities": []}, {"text": "We employ machine learning methods to train our classifiers for each component in the pipeline.", "labels": [], "entities": []}, {"text": "The system achieves an overall F1 score of 0.1065 when tested on blind dataset provided by the task organisers.", "labels": [], "entities": [{"text": "F1 score", "start_pos": 31, "end_pos": 39, "type": "METRIC", "confidence": 0.9922381341457367}]}, {"text": "On the same dataset, for explicit relations, F1 score of 0.2067 is achieved, while for non explicit relations, an F1 score of 0.0112 is achieved.", "labels": [], "entities": [{"text": "F1 score", "start_pos": 45, "end_pos": 53, "type": "METRIC", "confidence": 0.9898116886615753}, {"text": "F1 score", "start_pos": 114, "end_pos": 122, "type": "METRIC", "confidence": 0.9872688353061676}]}], "introductionContent": [{"text": "Discourse Parsing is the process of assigning a discourse structure to the input provided in the form of natural language.", "labels": [], "entities": [{"text": "Discourse Parsing", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.7323275804519653}]}, {"text": "The term \"Shallow\" signifies that the annotation of one discourse relation is independent of all other discourse relations, thus leaving room fora high level analysis that may attempt to connect them.", "labels": [], "entities": []}, {"text": "For the purpose of training and testing the system, we used PDTB (Penn Discourse Tree Bank), which is a discourse-level annotation on top of PTB (Penn Tree Bank).", "labels": [], "entities": [{"text": "Penn Discourse Tree Bank)", "start_pos": 66, "end_pos": 91, "type": "DATASET", "confidence": 0.9113683938980103}, {"text": "PTB (Penn Tree Bank)", "start_pos": 141, "end_pos": 161, "type": "DATASET", "confidence": 0.8483608961105347}]}, {"text": "The corpus provides annotation for all discourse relations present in the documents.", "labels": [], "entities": []}, {"text": "A discourse relation is composed of discourse connectives, its two arguments and the relation sense.", "labels": [], "entities": []}, {"text": "PDTB provides a list of 100 discourse connectives, which may indicate the presence of a relation.", "labels": [], "entities": [{"text": "PDTB", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.9280774593353271}]}, {"text": "A discourse connective can fall in any of 3 categories: Coordinating Conjunctions (e.g.: and, but, etc.), Subordinating Conjunctions (e.g.: if, because, etc.) or Discourse Adverbial (e.g.: however, also, etc.).", "labels": [], "entities": []}, {"text": "There are four kinds of relations, namely 1.", "labels": [], "entities": []}], "datasetContent": [{"text": "A relation is seen correct iff: \u2022 The discourse connective is correctly detected (for explicit relations) \u2022 Sense of relation is correctly predicted.", "labels": [], "entities": [{"text": "Sense", "start_pos": 108, "end_pos": 113, "type": "METRIC", "confidence": 0.994475781917572}]}, {"text": "\u2022 Text spans of two arguments as well as their labels (Arg1 and Arg2) are correctly predicted.", "labels": [], "entities": [{"text": "Arg1", "start_pos": 55, "end_pos": 59, "type": "METRIC", "confidence": 0.9811304211616516}, {"text": "Arg2", "start_pos": 64, "end_pos": 68, "type": "METRIC", "confidence": 0.911392331123352}]}, {"text": "Partial matches are not identified as correct.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Features for Connective Classifier", "labels": [], "entities": []}, {"text": " Table 2: Features for Argument Position Classifier", "labels": [], "entities": [{"text": "Argument Position Classifier", "start_pos": 23, "end_pos": 51, "type": "TASK", "confidence": 0.754871149857839}]}, {"text": " Table 3: Features for Kong's approach in SS case", "labels": [], "entities": []}, {"text": " Table 4: Features for Classifying clauses in PS case", "labels": [], "entities": [{"text": "Classifying clauses", "start_pos": 23, "end_pos": 42, "type": "TASK", "confidence": 0.9013520777225494}]}, {"text": " Table 5: Features for Explicit Sense Classifier", "labels": [], "entities": [{"text": "Explicit Sense Classifier", "start_pos": 23, "end_pos": 48, "type": "TASK", "confidence": 0.5900733371575674}]}, {"text": " Table 6: Features for Non Explicit Classifier", "labels": [], "entities": []}]}