{"title": [{"text": "Two End-to-end Shallow Discourse Parsers for English and Chinese in CoNLL-2016 Shared Task", "labels": [], "entities": [{"text": "CoNLL-2016 Shared Task", "start_pos": 68, "end_pos": 90, "type": "DATASET", "confidence": 0.7930522958437601}]}], "abstractContent": [{"text": "This paper describes our two discourse parsers (i.e., English discourse parser and Chinese discourse parser) for submission to CoNLL-2016 shared task on Shallow Discourse Parsing.", "labels": [], "entities": [{"text": "English discourse parser", "start_pos": 54, "end_pos": 78, "type": "TASK", "confidence": 0.5714477996031443}, {"text": "Shallow Discourse Parsing", "start_pos": 153, "end_pos": 178, "type": "TASK", "confidence": 0.6688395440578461}]}, {"text": "For English discourse parser, we build two separate argument extractors for single sentence (SS) case, and adopt a convolu-tional neural network for Non-Explicit sense classification based on (Wang and Lan, 2015b)'s work.", "labels": [], "entities": [{"text": "English discourse parser", "start_pos": 4, "end_pos": 28, "type": "TASK", "confidence": 0.5828609267870585}, {"text": "Non-Explicit sense classification", "start_pos": 149, "end_pos": 182, "type": "TASK", "confidence": 0.6182897388935089}]}, {"text": "As for Chinese discourse parser, we build a pipeline system following the annotation procedure of Chinese Discourse Treebank in (Zhou and Xue, 2015).", "labels": [], "entities": [{"text": "Chinese discourse parser", "start_pos": 7, "end_pos": 31, "type": "TASK", "confidence": 0.5948134164015452}, {"text": "Chinese Discourse Treebank", "start_pos": 98, "end_pos": 124, "type": "DATASET", "confidence": 0.870110015074412}]}, {"text": "Our English discourse parser achieves better performance than the best system of CoNLL-2015 and the Chinese discourse parser achieves encouraging results.", "labels": [], "entities": [{"text": "English discourse parser", "start_pos": 4, "end_pos": 28, "type": "TASK", "confidence": 0.5252643624941508}, {"text": "CoNLL-2015", "start_pos": 81, "end_pos": 91, "type": "DATASET", "confidence": 0.937810480594635}, {"text": "Chinese discourse parser", "start_pos": 100, "end_pos": 124, "type": "TASK", "confidence": 0.6932673652966818}]}, {"text": "Our two parsers both rank second on the blind datasets.", "labels": [], "entities": []}], "introductionContent": [{"text": "A discourse relation between two segments of textual units expresses how they are logically connected to one another (cause or contrast), which is considered a crucial step for the ability to properly interpret or produce discourse.", "labels": [], "entities": []}, {"text": "It can be of great benefit to many downstream natural language processing (NLP) applications and has attracted lots of research.", "labels": [], "entities": []}, {"text": "Following the first edition in CoNLL-2015 ( ,) is the 2nd edition of the CoNLL Shared Task on Shallow Discourse Parsing, which contains following tasks: discourse parsing task and supplementary task (sense classification using gold standard argument pairs) in English and Chinese.", "labels": [], "entities": [{"text": "CoNLL-2015", "start_pos": 31, "end_pos": 41, "type": "DATASET", "confidence": 0.9248456358909607}, {"text": "CoNLL Shared Task on Shallow Discourse Parsing", "start_pos": 73, "end_pos": 119, "type": "TASK", "confidence": 0.6744974255561829}, {"text": "discourse parsing task", "start_pos": 153, "end_pos": 175, "type": "TASK", "confidence": 0.8047661781311035}, {"text": "sense classification", "start_pos": 200, "end_pos": 220, "type": "TASK", "confidence": 0.7089273184537888}]}, {"text": "To build an English parser, we follow ()'s work except for several modifications described later in section 2.", "labels": [], "entities": []}, {"text": "In consideration of distinct linguistic and syntactic difference between English and Chinese, for Chinese parser, we design anew pipeline system which simulates the annotation procedure of Chinese Discourse Treebank in (.", "labels": [], "entities": [{"text": "Chinese Discourse Treebank", "start_pos": 189, "end_pos": 215, "type": "DATASET", "confidence": 0.793930729230245}]}, {"text": "And for both English and Chinese sense classification (i.e., supplementary task), we just regard them as parts of the whole parser.", "labels": [], "entities": [{"text": "English and Chinese sense classification", "start_pos": 13, "end_pos": 53, "type": "TASK", "confidence": 0.6440579771995545}]}], "datasetContent": [{"text": "All classifiers in the two parsers are trained using logistic regression with the default parameters (i.e., c=1) implemented in LIBLIN-EAR toolkit 1 . We adopt the same Explicit Sense Classifier and Non-Explicit Sense Classifier used in the discourse parser for both English and Chinese supplementary tasks which are sense classification using gold standard argument pairs.", "labels": [], "entities": [{"text": "sense classification", "start_pos": 317, "end_pos": 337, "type": "TASK", "confidence": 0.7379385828971863}]}, {"text": "From, compared with the best system in on blind dataset, our system achieves better performances on Explicit arguments extraction and Non-Explicit arguments extraction and beat them on the overall performance.", "labels": [], "entities": [{"text": "Explicit arguments extraction", "start_pos": 100, "end_pos": 129, "type": "TASK", "confidence": 0.6146570841471354}, {"text": "Non-Explicit arguments extraction", "start_pos": 134, "end_pos": 167, "type": "TASK", "confidence": 0.7038999597231547}]}, {"text": "From table 4, we see that the performance of Explicit sense classification is better on dev and blind test set, which is slight lower on the test set than the performance of (.", "labels": [], "entities": [{"text": "Explicit sense classification", "start_pos": 45, "end_pos": 74, "type": "TASK", "confidence": 0.6084425151348114}]}, {"text": "As for the Non-Explicit sense classification in supplementary task, we achieve much better performance than () on dev and test set when using CNN instead of handcrafted features.", "labels": [], "entities": []}, {"text": "However, our CNN model achieve a worse performance on blind test set, the possible reason might be that the blind test set has a different sense distribution compared with dev and test sets.", "labels": [], "entities": []}, {"text": "Note that the dev and test set are both from PDTB dataset, whereas the blind test set is annotated from English Wikinews 2 . For Chinese discourse parser, from table 3, we seethe performance of the Explicit connective identification on Chinese is much lower than that in English and reduced a lot from dev to test and blind test, the possible reason might be that there are lots of connectives come in pairs and much more unseen connectives in the Chinese test than in English which makes it hard to detect and classify them from the texts.", "labels": [], "entities": [{"text": "PDTB dataset", "start_pos": 45, "end_pos": 57, "type": "DATASET", "confidence": 0.9881905913352966}, {"text": "Explicit connective identification", "start_pos": 198, "end_pos": 232, "type": "TASK", "confidence": 0.7090175847212473}]}, {"text": "From, the performance of Non-Explicit sense classification in Chinese is much higher than in English, due to the high performance of the baseline system (labelling the sense of all the Non-Explicit relations as \"Conjunction\" can achieve the 64.61% accuracy on train set).", "labels": [], "entities": [{"text": "Non-Explicit sense classification", "start_pos": 25, "end_pos": 58, "type": "TASK", "confidence": 0.61948029200236}, {"text": "accuracy", "start_pos": 248, "end_pos": 256, "type": "METRIC", "confidence": 0.9989511966705322}]}, {"text": "Due to the variety distri-: Results of the supplementary tasks on both English and Chinese discourses, which are sense classification using gold standard argument pairs.", "labels": [], "entities": [{"text": "sense classification", "start_pos": 113, "end_pos": 133, "type": "TASK", "confidence": 0.7769531905651093}]}, {"text": "The corresponding performance of (Wang and Lan, 2015b)'s system is shown within parentheses.", "labels": [], "entities": []}, {"text": "bution of the arguments, the arguments extraction is more challenging than other components, and achieve low performance on test set.", "labels": [], "entities": [{"text": "arguments extraction", "start_pos": 29, "end_pos": 49, "type": "TASK", "confidence": 0.7582686543464661}]}], "tableCaptions": [{"text": " Table 3: Results of our English and Chinese discourse parsers on dev, test and blind test datasets", "labels": [], "entities": [{"text": "English and Chinese discourse parsers", "start_pos": 25, "end_pos": 62, "type": "TASK", "confidence": 0.6217514276504517}]}, {"text": " Table 4: Results of the supplementary tasks on both English and Chinese discourses, which  are sense classification using gold standard argument pairs. The corresponding performance of  (Wang and Lan, 2015b)'s system is shown within parentheses.", "labels": [], "entities": [{"text": "sense classification", "start_pos": 96, "end_pos": 116, "type": "TASK", "confidence": 0.8123489022254944}]}]}