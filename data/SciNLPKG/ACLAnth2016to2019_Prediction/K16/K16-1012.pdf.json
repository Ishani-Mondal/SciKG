{"title": [{"text": "Redefining part-of-speech classes with distributional semantic models", "labels": [], "entities": []}], "abstractContent": [{"text": "This paper studies how word embeddings trained on the British National Corpus interact with part of speech boundaries.", "labels": [], "entities": [{"text": "British National Corpus", "start_pos": 54, "end_pos": 77, "type": "DATASET", "confidence": 0.9624765515327454}]}, {"text": "Our work targets the Universal PoS tag set, which is currently actively being used for annotation of a range of languages.", "labels": [], "entities": [{"text": "Universal PoS tag set", "start_pos": 21, "end_pos": 42, "type": "DATASET", "confidence": 0.7888427674770355}]}, {"text": "We experiment with training classifiers for predicting PoS tags for words based on their embeddings.", "labels": [], "entities": [{"text": "predicting PoS tags", "start_pos": 44, "end_pos": 63, "type": "TASK", "confidence": 0.8149882952372233}]}, {"text": "The results show that the information about PoS affiliation contained in the distributional vectors allows us to discover groups of words with distribu-tional patterns that differ from other words of the same part of speech.", "labels": [], "entities": [{"text": "PoS affiliation", "start_pos": 44, "end_pos": 59, "type": "TASK", "confidence": 0.8192473649978638}]}, {"text": "This data often reveals hidden inconsistencies of the annotation processor guidelines.", "labels": [], "entities": []}, {"text": "At the same time, it supports the notion of 'soft' or 'graded' part of speech affiliations.", "labels": [], "entities": []}, {"text": "Finally, we show that information about PoS is distributed among dozens of vector components, not limited to only one or two features.", "labels": [], "entities": []}], "introductionContent": [{"text": "Parts of speech (PoS) are useful abstractions, but still abstractions.", "labels": [], "entities": []}, {"text": "Boundaries between them in natural languages are flexible.", "labels": [], "entities": []}, {"text": "Sometimes, large open classes of words are situated on the verge between several parts of speech: for example, participles in English are in many respects both verbs and adjectives.", "labels": [], "entities": []}, {"text": "In other cases, closed word classes 'intersect', e.g., it is often difficult to tell a determiner from a possessive pronoun.", "labels": [], "entities": []}, {"text": "As puts it, 'Grammatical categories exist along a continuum which does not exhibit sharp boundaries between the categories'.", "labels": [], "entities": []}, {"text": "When annotating natural language texts for parts of speech, the choice of a PoS tag in many ways depends on the human annotators themselves, but also on the quality of linguistic conventions behind the division into different word classes.", "labels": [], "entities": []}, {"text": "That is why there have been several attempts to refine the definitions of parts of speech and to make them more empirically grounded, based on corpora of real texts: see, among others, the seminal work of.", "labels": [], "entities": []}, {"text": "The aim of such attempts is to identify clusters of words occurring naturally and corresponding to what we usually call 'parts of speech'.", "labels": [], "entities": []}, {"text": "One of the main distance metrics that can be used in detecting such clusters is a distance between distributional features of words (their contexts in a reference training corpus).", "labels": [], "entities": []}, {"text": "In this paper, we test this approach using predictive models developed in the field of distributional semantics.", "labels": [], "entities": []}, {"text": "Recent achievements in training distributional models of language using machine learning allow for robust representations of natural language semantics created in a completely unsupervised way, using only large corpora of raw text.", "labels": [], "entities": []}, {"text": "Relations between dense word vectors (embeddings) in the resulting vector space are as a rule used for semantic purposes.", "labels": [], "entities": []}, {"text": "But can they be employed to discover something new about grammar and syntax, particularly parts of speech?", "labels": [], "entities": []}, {"text": "Do learned embeddings help here?", "labels": [], "entities": []}, {"text": "Below we show that such models do contain a lot of interesting data related to PoS classes.", "labels": [], "entities": []}, {"text": "The rest of the paper is organized as follows.", "labels": [], "entities": []}, {"text": "In Section 2 we briefly cover the previous work on the subject of parts of speech and distributional models.", "labels": [], "entities": []}, {"text": "Section 3 describes data processing and the training of a PoS predictor based on word embeddings.", "labels": [], "entities": [{"text": "data processing", "start_pos": 20, "end_pos": 35, "type": "TASK", "confidence": 0.7011964321136475}, {"text": "PoS predictor", "start_pos": 58, "end_pos": 71, "type": "TASK", "confidence": 0.8694191873073578}]}, {"text": "In Section 4 errors of this predictor are analyzed and insights gained from them described.", "labels": [], "entities": []}, {"text": "Section 5 introduces an attempt to build a fullfledged PoS tagger within the same approach.", "labels": [], "entities": [{"text": "PoS tagger", "start_pos": 55, "end_pos": 65, "type": "TASK", "confidence": 0.7697312831878662}]}, {"text": "It also analyzes the correspondence between partic-115 ular word embedding components and PoS affiliation, before we conclude in Section 6.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1. Distributional similarity between parts of  speech (fragment)", "labels": [], "entities": [{"text": "Distributional similarity between parts of  speech", "start_pos": 10, "end_pos": 60, "type": "TASK", "confidence": 0.6503241658210754}]}, {"text": " Table 3. Coverage of misclassifications with dis- tributional predictor, i.e., ratio of errors over all  word types of a given PoS. The absolute type  count is given by #.", "labels": [], "entities": [{"text": "dis- tributional predictor", "start_pos": 46, "end_pos": 72, "type": "METRIC", "confidence": 0.6271544098854065}]}, {"text": " Table 5. Coverage of misclassifications (from all  word types of this PoS) with the Stanford tagger.", "labels": [], "entities": [{"text": "Stanford tagger", "start_pos": 85, "end_pos": 100, "type": "DATASET", "confidence": 0.9348432123661041}]}]}