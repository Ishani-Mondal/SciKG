{"title": [{"text": "The CLaC Discourse Parser at CoNLL-2016", "labels": [], "entities": [{"text": "CLaC Discourse Parser at", "start_pos": 4, "end_pos": 28, "type": "DATASET", "confidence": 0.7964148074388504}, {"text": "CoNLL-2016", "start_pos": 29, "end_pos": 39, "type": "DATASET", "confidence": 0.7326081991195679}]}], "abstractContent": [{"text": "This paper describes our submission (CLaC) to the CoNLL-2016 shared task on shallow discourse parsing.", "labels": [], "entities": [{"text": "shallow discourse parsing", "start_pos": 76, "end_pos": 101, "type": "TASK", "confidence": 0.5652069449424744}]}, {"text": "We used two complementary approaches for the task.", "labels": [], "entities": []}, {"text": "A standard machine learning approach for the parsing of explicit relations, and a deep learning approach for non-explicit relations.", "labels": [], "entities": [{"text": "parsing of explicit relations", "start_pos": 45, "end_pos": 74, "type": "TASK", "confidence": 0.8626796454191208}]}, {"text": "Overall, our parser achieves an F 1-score of 0.2106 on the identification of discourse relations (0.3110 for explicit relations and 0.1219 for non-explicit relations) on the blind CoNLL-2016 test set.", "labels": [], "entities": [{"text": "F 1-score", "start_pos": 32, "end_pos": 41, "type": "METRIC", "confidence": 0.9925912320613861}, {"text": "CoNLL-2016 test set", "start_pos": 180, "end_pos": 199, "type": "DATASET", "confidence": 0.9546106060345968}]}], "introductionContent": [{"text": "Shallow discourse parsing is defined as the identification of two discourse units, or discourse arguments, and labeling their relation.", "labels": [], "entities": [{"text": "Shallow discourse parsing", "start_pos": 0, "end_pos": 25, "type": "TASK", "confidence": 0.6816383103529612}]}, {"text": "Although the topic of shallow discourse parsing has received much interest in the past few years (e.g. (), the performance of the state-of-the-art discourse parsers is not yet adequate to be used in other downstream Natural Language Processing applications.", "labels": [], "entities": [{"text": "shallow discourse parsing", "start_pos": 22, "end_pos": 47, "type": "TASK", "confidence": 0.6460419495900472}]}, {"text": "For example, the best parser submitted at achieved an F 1 score of 0.2400 on the blind test dataset.", "labels": [], "entities": [{"text": "F 1 score", "start_pos": 54, "end_pos": 63, "type": "METRIC", "confidence": 0.9930901726086935}]}, {"text": "For the CoNLL 2016 task of shallow discourse parsing, four types of discourse relations have to be annotated in texts (more details of the task can be found in (): 1.", "labels": [], "entities": [{"text": "CoNLL 2016", "start_pos": 8, "end_pos": 18, "type": "DATASET", "confidence": 0.8165494501590729}, {"text": "shallow discourse parsing", "start_pos": 27, "end_pos": 52, "type": "TASK", "confidence": 0.5418555239836375}]}, {"text": "Explicit Discourse Relations: explicit discourse relations are explicitly signalled within the text through discourse connectives such as because, however, since, etc.", "labels": [], "entities": []}, {"text": "* Both authors contributed equally 2.", "labels": [], "entities": []}, {"text": "Implicit Discourse Relations: implicit discourse relations are inferred by the reader and no discourse connective is used within the text to convey the relation.", "labels": [], "entities": []}, {"text": "As a reader, implicit discourse relations can be inferred by inserting a discourse connective (called an implicit discourse connective) in the text that best expresses the inferred relation.", "labels": [], "entities": []}, {"text": "3. AltLex Discourse Relations: Similarly to implicit discourse relations, AltLex are not signalled through the presence of discourse connectives in the text.", "labels": [], "entities": []}, {"text": "However, the relation is alternatively lexicalized by some nonconnective expression, hence inserting an implicit discourse connective to express the inferred relation would lead to a redundancy.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: F 1 -score of the CLaC Discourse Parser and the best parser of 2015 with Different Datasets.", "labels": [], "entities": [{"text": "F 1 -score", "start_pos": 10, "end_pos": 20, "type": "METRIC", "confidence": 0.9677828997373581}, {"text": "CLaC Discourse Parser", "start_pos": 28, "end_pos": 49, "type": "DATASET", "confidence": 0.9246639013290405}]}, {"text": " Table 2: Results of the CLaC Discourse parser for  the identification of discourse arguments with the  blind test dataset (exact match).", "labels": [], "entities": [{"text": "CLaC Discourse parser", "start_pos": 25, "end_pos": 46, "type": "TASK", "confidence": 0.791982630888621}]}, {"text": " Table 3: Results of the CLaC Discourse parser for  the identification of discourse argument with the  blind test dataset (partial match).", "labels": [], "entities": [{"text": "CLaC Discourse parser", "start_pos": 25, "end_pos": 46, "type": "DATASET", "confidence": 0.8565876682599386}]}]}