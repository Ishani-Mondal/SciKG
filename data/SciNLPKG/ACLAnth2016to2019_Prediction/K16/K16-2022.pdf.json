{"title": [{"text": "Discourse Relation Sense Classification Systems for CoNLL-2016 Shared Task", "labels": [], "entities": [{"text": "Discourse Relation Sense Classification", "start_pos": 0, "end_pos": 39, "type": "TASK", "confidence": 0.800103947520256}, {"text": "CoNLL-2016 Shared Task", "start_pos": 52, "end_pos": 74, "type": "DATASET", "confidence": 0.6881802479426066}]}], "abstractContent": [{"text": "This paper reports the submitted discourse relation classification systems of the language information processing group of Beijing Institute of Technology (BIT) to the CoNLL-2016 shared task.", "labels": [], "entities": [{"text": "discourse relation classification", "start_pos": 33, "end_pos": 66, "type": "TASK", "confidence": 0.6984051465988159}, {"text": "Beijing Institute of Technology (BIT)", "start_pos": 123, "end_pos": 160, "type": "DATASET", "confidence": 0.8107448390551976}]}, {"text": "In this work, discriminative methods were employed according to the different characteristics of English and Chinese discourse structures.", "labels": [], "entities": []}, {"text": "Additionally, distributed representations were introduced to catch the deep semantic relations.", "labels": [], "entities": []}, {"text": "Experiments shows their effectiveness on both English and Chinese tasks.", "labels": [], "entities": []}], "introductionContent": [{"text": "In natural language processing (NLP), discourse parsing is the process of understanding the internal structure of a text and identifying the discourse relations in between its text unites ().", "labels": [], "entities": [{"text": "natural language processing (NLP)", "start_pos": 3, "end_pos": 36, "type": "TASK", "confidence": 0.8102769653002421}, {"text": "discourse parsing", "start_pos": 38, "end_pos": 55, "type": "TASK", "confidence": 0.7290322780609131}]}, {"text": "It is a recognized challenging task since deep semantic understanding and discourse wide global information even world knowledge are essential to achieve well acceptable solutions.", "labels": [], "entities": []}, {"text": "According to alternative discourse structure theoretical frameworks, RST-DT Corpus ( provides the possibility of data-driven modeling for complete tree structure while PDTB () offers a framework to predicting shallow discourse structures statistically in a \"predicate-argument\" style.", "labels": [], "entities": [{"text": "RST-DT Corpus", "start_pos": 69, "end_pos": 82, "type": "DATASET", "confidence": 0.6861788630485535}]}, {"text": "Compared with RST-DT, PDTB is larger, so it draws more attentions in these years to support discourse parsing model verification.", "labels": [], "entities": [{"text": "discourse parsing model verification", "start_pos": 92, "end_pos": 128, "type": "TASK", "confidence": 0.8470624089241028}]}, {"text": "In this situation, CoNLL launched Shallow Discourse Parsing Shared Task in the year 2015 and called for PDTB-styled individual discourse relations that are presented in a free text under an end-to-end paradigm (.", "labels": [], "entities": [{"text": "Shallow Discourse Parsing Shared Task", "start_pos": 34, "end_pos": 71, "type": "TASK", "confidence": 0.6725194334983826}]}, {"text": "According to the annotation framework of PDTB, relations held between arguments can be either 1 http://www.cs.brandeis.edu/~clp/conll15st/ explicit or non-explicit.", "labels": [], "entities": []}, {"text": "Non-explicit relations are further divided into implicit, EntRel and AltLex ones.", "labels": [], "entities": []}, {"text": "In CoNLL-2015 Shared Task, the PDTB senses were regularized into more reasonable 15 categories to facilitate machine learning (.", "labels": [], "entities": []}, {"text": "Participants were required to run their systems on a web-based evaluation platform and the systems should (1) locate the explicit discourse connectives (e.g., \"because\", \"however\") in the text, (2) identify the spans of text that serve as the two arguments for each discourse connective, and (3) predict the sense of the discourse relations (e.g., \"Cause\", \"Condition\", \"Contrast\").", "labels": [], "entities": []}, {"text": "This is the 2nd edition of the CoNLL Shared Task on Shallow Discourse Parsing this year.", "labels": [], "entities": [{"text": "CoNLL Shared Task on Shallow Discourse Parsing", "start_pos": 31, "end_pos": 77, "type": "TASK", "confidence": 0.5384285577705928}]}, {"text": "Besides the English PDTB-styled end-to-end paradigm, PDTB-styled Chinese end-to-end parsing is also involved (.", "labels": [], "entities": [{"text": "PDTB-styled Chinese end-to-end parsing", "start_pos": 53, "end_pos": 91, "type": "TASK", "confidence": 0.548480823636055}]}, {"text": "It is attributed to the annotation of discourse structures in Chinese texts, a PDTB-styled Chinese discourse Treebank (CDTB) (.", "labels": [], "entities": [{"text": "PDTB-styled Chinese discourse Treebank (CDTB)", "start_pos": 79, "end_pos": 124, "type": "DATASET", "confidence": 0.7723636967795235}]}, {"text": "Based on the adapted PDTB annotation scheme, discourse structures in CDTB own the same \"predicate-argument\" pattern and similar sense hierarchy.", "labels": [], "entities": []}, {"text": "The same as English discourse parsing, the CDTB sense in CoNLL-2016 Shared Task is also transferred.", "labels": [], "entities": [{"text": "English discourse parsing", "start_pos": 12, "end_pos": 37, "type": "TASK", "confidence": 0.5620298087596893}]}, {"text": "8 categories for explicit and non-explicit relations are refactored: \"Causation\", \"Conditional\", \"Conjunction\", \"Contrast\", \"Expansion\", \"Purpose\", \"Temporal\" and \"Progression\".", "labels": [], "entities": []}, {"text": "In addition to the Chinese discourse parsing, CoNLL-2016 Shared Task also allows participants to do the supplementary task which is sense classification using gold standard argument pairs both in English and Chinese.", "labels": [], "entities": [{"text": "Chinese discourse parsing", "start_pos": 19, "end_pos": 44, "type": "TASK", "confidence": 0.5826160113016764}, {"text": "sense classification", "start_pos": 132, "end_pos": 152, "type": "TASK", "confidence": 0.8824456334114075}]}, {"text": "It is proved that implicit sense discrimination is the most difficult subtask in discourse parsing, not only as an individual task but also as a key component in pipeline end-to-end system.", "labels": [], "entities": [{"text": "implicit sense discrimination", "start_pos": 18, "end_pos": 47, "type": "TASK", "confidence": 0.5944236318270365}, {"text": "discourse parsing", "start_pos": 81, "end_pos": 98, "type": "TASK", "confidence": 0.7109882980585098}]}, {"text": "Implicit discourse relation is also the most attended issue at the beginning of the release of PDTB (.", "labels": [], "entities": [{"text": "Implicit discourse relation", "start_pos": 0, "end_pos": 27, "type": "TASK", "confidence": 0.75167848666509}, {"text": "PDTB", "start_pos": 95, "end_pos": 99, "type": "DATASET", "confidence": 0.908852219581604}]}, {"text": "Due to the lack of effective structural semantic representation model, discourse relation sense disambiguation, which is a deep semantic analysis problem, is always conducted by modeling large scale shallow linguistic features.", "labels": [], "entities": [{"text": "discourse relation sense disambiguation", "start_pos": 71, "end_pos": 110, "type": "TASK", "confidence": 0.6399165093898773}]}, {"text": "We can see that the named efficient features such as lexical and syntactic features (word co-occurrences, function words, phrase or dependency parses), partial shallow semantic features (co-reference patterns, semantic attribute of words, e.g., polarity) and a few dynamic features are adopted in existing works (.", "labels": [], "entities": []}, {"text": "In response to the data scarcity problem, semi-supervised and unsupervised methods are explored for implicit relations inference in recent years.", "labels": [], "entities": [{"text": "implicit relations inference", "start_pos": 100, "end_pos": 128, "type": "TASK", "confidence": 0.6376754542191824}]}, {"text": "Experiments demonstrate that these kinds of methods can acquire more stable statistical distribution via large scale unlabeled corpus hence achieve higher classification accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 170, "end_pos": 178, "type": "METRIC", "confidence": 0.8540552258491516}]}, {"text": "In this Shared Task, we focus on the supplementary task and submit both the English and Chinese discourse relation sense classification systems.", "labels": [], "entities": [{"text": "English and Chinese discourse relation sense classification", "start_pos": 76, "end_pos": 135, "type": "TASK", "confidence": 0.569924533367157}]}, {"text": "According to the different characteristics of English and Chinese discourse structures, we examine rule-based and statistical discriminative classification approaches, conventional and distributed semantic representation models, as well as the expressiveness of extra resources.", "labels": [], "entities": [{"text": "statistical discriminative classification", "start_pos": 114, "end_pos": 155, "type": "TASK", "confidence": 0.7394415338834127}]}, {"text": "The organization of this work is as follows.", "labels": [], "entities": []}, {"text": "Section 2 presents our explicit relation classifiers.", "labels": [], "entities": []}, {"text": "Section 3 gives the description of the non-explicit relation classification models in our system.", "labels": [], "entities": [{"text": "relation classification", "start_pos": 52, "end_pos": 75, "type": "TASK", "confidence": 0.7323860228061676}]}, {"text": "Section 4 reports the preliminary experimental results on the training and development dataset, and the final results on two test datasets.", "labels": [], "entities": []}, {"text": "Conclusions are provided in Section 5.", "labels": [], "entities": []}], "datasetContent": [{"text": "The same as the CoNLL-2015's task, participants are required to deploy their systems on the provided platform instead of submitting the output.", "labels": [], "entities": []}, {"text": "The organizer also offers potentially useful linguistic resources for the closed track.", "labels": [], "entities": []}, {"text": "In this section, the experimental results are presented and the experimental analyses are induced.", "labels": [], "entities": []}, {"text": "All the systems are evaluated on TIRA evaluation platform).", "labels": [], "entities": [{"text": "TIRA evaluation platform", "start_pos": 33, "end_pos": 57, "type": "DATASET", "confidence": 0.793205996354421}]}, {"text": "presents the English connective sense classification results conducted by SVM classifier.", "labels": [], "entities": [{"text": "English connective sense classification", "start_pos": 13, "end_pos": 52, "type": "TASK", "confidence": 0.5589838847517967}]}, {"text": "All the SVM classifiers utilized in our experiments were implemented by the LibSVM 6 .  Unfortunately, we submitted a wrong edition of our system during the competition for technical reasons and the official outputs produced by this edition are also listed in (System submitted).", "labels": [], "entities": [{"text": "LibSVM 6", "start_pos": 76, "end_pos": 84, "type": "DATASET", "confidence": 0.9585573375225067}]}, {"text": "Sense classification results for Chinese connectives are displayed in Implicit relation sense classification results for Chinese.", "labels": [], "entities": [{"text": "Sense classification", "start_pos": 0, "end_pos": 20, "type": "TASK", "confidence": 0.7028149515390396}, {"text": "Implicit relation sense classification", "start_pos": 70, "end_pos": 108, "type": "TASK", "confidence": 0.6071784347295761}]}, {"text": "The system submitted is in italic.", "labels": [], "entities": []}, {"text": "son, we also conducted atypical SVM classifier in which two features are applied: the connective itself and its POS tag.", "labels": [], "entities": [{"text": "SVM classifier", "start_pos": 32, "end_pos": 46, "type": "TASK", "confidence": 0.8504610061645508}]}, {"text": "Since the Chinese training data is much smaller and there are too many low-frequency connectives involved, only the connectives which appear more than 10 times are considered in the experiment.", "labels": [], "entities": []}, {"text": "Because of the serious imbalance and small quantity of training samples, the SVM classifier gets a poor classification precisions.", "labels": [], "entities": [{"text": "SVM classifier", "start_pos": 77, "end_pos": 91, "type": "TASK", "confidence": 0.7916110157966614}, {"text": "precisions", "start_pos": 119, "end_pos": 129, "type": "METRIC", "confidence": 0.8846621513366699}]}, {"text": "Whereas, the rule-based approach performs soundly and achieves acceptable results.", "labels": [], "entities": []}, {"text": "It is simple, crude but practically effective in Chinese explicit relation classification.", "labels": [], "entities": [{"text": "Chinese explicit relation classification", "start_pos": 49, "end_pos": 89, "type": "TASK", "confidence": 0.601363904774189}]}, {"text": "The implicit relation sense classification results for English and Chinese are listed in respectively.", "labels": [], "entities": [{"text": "relation sense classification", "start_pos": 13, "end_pos": 42, "type": "TASK", "confidence": 0.6478946010271708}]}, {"text": "As we can see, although the overall performance of English system is not good enough, the results of Simple Embedding and Huffman Tree-based Prediction are always better than the One-Hot paradigm.", "labels": [], "entities": []}, {"text": "The Huffman Tree Prediction outperforms the Simple Embedding slightly mainly because the training samples from CNA are seriously imbalance.", "labels": [], "entities": [{"text": "Huffman Tree Prediction", "start_pos": 4, "end_pos": 27, "type": "DATASET", "confidence": 0.8209723432858785}]}, {"text": "A finer sifted corpus will be introduced in the future work to improve this work.", "labels": [], "entities": []}, {"text": "In Chinese experiments, the Simple Embedding with Word Pairs Fuzzy Matching gains significant improvement compared with the One-Hot paradigm, which means that the sparseness of word pairs is alleviated effectively.", "labels": [], "entities": [{"text": "Word Pairs Fuzzy Matching", "start_pos": 50, "end_pos": 75, "type": "TASK", "confidence": 0.6330438330769539}]}], "tableCaptions": [{"text": " Table 1: Distributions of the connectives and relation  senses in the training set from PDTB", "labels": [], "entities": [{"text": "PDTB", "start_pos": 89, "end_pos": 93, "type": "DATASET", "confidence": 0.8754842281341553}]}, {"text": " Table 2: Distributions of the connectives and relation  senses in the training set from CDTB", "labels": [], "entities": [{"text": "CDTB", "start_pos": 89, "end_pos": 93, "type": "DATASET", "confidence": 0.8630638122558594}]}, {"text": " Table 6: Explicit connective sense classification results for English. The system submitted is in italic.", "labels": [], "entities": [{"text": "Explicit connective sense classification", "start_pos": 10, "end_pos": 50, "type": "TASK", "confidence": 0.6062872409820557}]}, {"text": " Table 7: Explicit connective sense classification results for Chinese. The system submitted is in italic.", "labels": [], "entities": [{"text": "Explicit connective sense classification", "start_pos": 10, "end_pos": 50, "type": "TASK", "confidence": 0.6121563091874123}]}, {"text": " Table 8: Implicit relation sense classification results for English. The system submitted is in italic.", "labels": [], "entities": [{"text": "Implicit relation sense classification", "start_pos": 10, "end_pos": 48, "type": "TASK", "confidence": 0.6865811198949814}]}, {"text": " Table 9 Implicit relation sense classification results for Chinese. The system submitted is in italic.", "labels": [], "entities": [{"text": "relation sense classification", "start_pos": 18, "end_pos": 47, "type": "TASK", "confidence": 0.7436066269874573}]}]}