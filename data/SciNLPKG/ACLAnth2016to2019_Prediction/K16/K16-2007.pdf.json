{"title": [{"text": "Robust Non-Explicit Neural Discourse Parser in English and Chinese", "labels": [], "entities": [{"text": "Robust Non-Explicit Neural Discourse Parser", "start_pos": 0, "end_pos": 43, "type": "TASK", "confidence": 0.6529580116271972}]}], "abstractContent": [{"text": "Neural discourse models proposed so far are very sophisticated and tuned specifically to certain label sets.", "labels": [], "entities": []}, {"text": "These are effective, but unwieldy to deploy or re-purpose for different label sets or languages.", "labels": [], "entities": []}, {"text": "Here, we propose a robust neu-ral classifier for non-explicit discourse relations for both English and Chinese in CoNLL 2016 Shared Task datasets.", "labels": [], "entities": [{"text": "CoNLL 2016 Shared Task datasets", "start_pos": 114, "end_pos": 145, "type": "DATASET", "confidence": 0.9626689553260803}]}, {"text": "Our model only requires word vectors and simple feed-forward training procedure, which we have previously shown to work better than some of the more sophisticated neural architecture such as long-short term memory model.", "labels": [], "entities": []}, {"text": "Our Chinese model out-performs feature-based model and performs competitively against other teams.", "labels": [], "entities": []}, {"text": "Our model obtains the state-of-the-art results on the English blind test set, which is used as the main criteria in this competition .", "labels": [], "entities": [{"text": "English blind test set", "start_pos": 54, "end_pos": 76, "type": "DATASET", "confidence": 0.9063590914011002}]}], "introductionContent": [{"text": "In the context of CoNLL 2016 Shared Task, we participate partially in the English and Chinese supplementary evaluation, which is discourse relation sense classification ( ).", "labels": [], "entities": [{"text": "CoNLL 2016 Shared Task", "start_pos": 18, "end_pos": 40, "type": "DATASET", "confidence": 0.8284169733524323}, {"text": "discourse relation sense classification", "start_pos": 129, "end_pos": 168, "type": "TASK", "confidence": 0.6600874960422516}]}, {"text": "We focus on identifying the sense of non-explicit discourse relations in both English and Chinese.", "labels": [], "entities": []}, {"text": "Previous studies including the results from CoNLL 2015 Shared Task have shown that classifying the senses of implicit discourse relations is the most difficult part of the task of discourse parsing).", "labels": [], "entities": [{"text": "CoNLL 2015 Shared Task", "start_pos": 44, "end_pos": 66, "type": "DATASET", "confidence": 0.8484794497489929}, {"text": "classifying the senses of implicit discourse relations", "start_pos": 83, "end_pos": 137, "type": "TASK", "confidence": 0.8083926609584263}, {"text": "discourse parsing", "start_pos": 180, "end_pos": 197, "type": "TASK", "confidence": 0.7241422235965729}]}, {"text": "Therefore, we focus exclusively on this particular challenging subtask.", "labels": [], "entities": []}, {"text": "We want our system to be robust such that the system can be easily trained to handle different la- * Work performed while being a student at Brandeis bel sets and different languages.", "labels": [], "entities": [{"text": "Brandeis bel sets", "start_pos": 141, "end_pos": 158, "type": "DATASET", "confidence": 0.8576486309369405}]}, {"text": "Neural network is attractive in this regard as we do not need handcrafted linguistic resources, which are not readily available in all languages.", "labels": [], "entities": []}, {"text": "The past neural network models for this task focus on top-level senses or require parses, redundant surface features, or extensive semantic lexicon).", "labels": [], "entities": []}, {"text": "The results from these systems are not likely to extend to languages that do not have as much linguistic resources as English.", "labels": [], "entities": []}, {"text": "Therefore, we come up with a neural network model that requires no parses and specific model tuning.", "labels": [], "entities": []}, {"text": "The only extra ingredient is word vectors, which are easily obtained through large amount of unannotated data.", "labels": [], "entities": []}, {"text": "Our past studies have indicated that feedforward neural networks outperform more complicated models such as long-short term memory models and perform comparably with systems with traditional surface features in this task . But we want to test our results further.", "labels": [], "entities": []}, {"text": "We wonder whether our best feedforward architecture can be adopted to deal with a totally different language and a different label set put forth specifically for this shared task.", "labels": [], "entities": []}, {"text": "We also want to know whether our model is robust against the slightly out-of-domain blind datasets.", "labels": [], "entities": []}, {"text": "The performance numbers from the experiments alone hardly provide us with insight into implicit discourse relations.", "labels": [], "entities": []}, {"text": "We compare and contrast the two approaches in more detail to learn what we gain and lose by using each approach.", "labels": [], "entities": []}, {"text": "The fundamental difference between our approach and the baseline is that our approach does not use surface features or semantic lexicons.", "labels": [], "entities": []}, {"text": "We want to know the advantage one gains from shifting the paradigm from discrete surface features to continuous features.", "labels": [], "entities": []}, {"text": "Are the errors made by two types of systems complementary?", "labels": [], "entities": []}, {"text": "Our system is ranked the first on the English dataset and the third on the Chinese dataset.", "labels": [], "entities": [{"text": "English dataset", "start_pos": 38, "end_pos": 53, "type": "DATASET", "confidence": 0.9466736614704132}, {"text": "Chinese dataset", "start_pos": 75, "end_pos": 90, "type": "DATASET", "confidence": 0.9535266160964966}]}, {"text": "The accuracy on the English blind test set is 0.3767, and the accuracy on the Chinese blind test set is 0.6338.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 4, "end_pos": 12, "type": "METRIC", "confidence": 0.9996953010559082}, {"text": "English blind test set", "start_pos": 20, "end_pos": 42, "type": "DATASET", "confidence": 0.9193763583898544}, {"text": "accuracy", "start_pos": 62, "end_pos": 70, "type": "METRIC", "confidence": 0.9994822144508362}, {"text": "Chinese blind test set", "start_pos": 78, "end_pos": 100, "type": "DATASET", "confidence": 0.8976391851902008}]}, {"text": "The performance on the test sets even exceeds the one on the development sets, which suggest the robustness of our model.", "labels": [], "entities": []}], "datasetContent": [{"text": "Word vectors English word vectors are taken from 300-dimensional Skip-gram word vectors trained on Google News data, provided by the shared task organizers (.", "labels": [], "entities": [{"text": "Google News data", "start_pos": 99, "end_pos": 115, "type": "DATASET", "confidence": 0.7615846196810404}]}, {"text": "We trained our own 250-dimensional Chinese word vectors on Gigaword corpus, which is the same corpus used by the 300-dimensional Chinese word vectors provided by the shared task organizers ().", "labels": [], "entities": [{"text": "Gigaword corpus", "start_pos": 59, "end_pos": 74, "type": "DATASET", "confidence": 0.9754089415073395}]}, {"text": "We found the 250-dimensional version to work better despite fewer parameters.", "labels": [], "entities": []}, {"text": "Training Weight initialization is uniform random, following the formula recommended by.", "labels": [], "entities": [{"text": "Training Weight initialization", "start_pos": 0, "end_pos": 30, "type": "TASK", "confidence": 0.48464136322339374}]}, {"text": "Word vectors are fixed during training.", "labels": [], "entities": []}, {"text": "The cost function is the standard cross-entropy loss function, and we use Adagrad as the optimization algorithm of choice.", "labels": [], "entities": [{"text": "Adagrad", "start_pos": 74, "end_pos": 81, "type": "DATASET", "confidence": 0.9140800833702087}]}, {"text": "We monitor the accuracy on the development set to determine convergence.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 15, "end_pos": 23, "type": "METRIC", "confidence": 0.9996507167816162}, {"text": "convergence", "start_pos": 60, "end_pos": 71, "type": "METRIC", "confidence": 0.5404455661773682}]}, {"text": "Implementation All of the models are implemented in Theano ().", "labels": [], "entities": [{"text": "Implementation", "start_pos": 0, "end_pos": 14, "type": "METRIC", "confidence": 0.8572560548782349}, {"text": "Theano", "start_pos": 52, "end_pos": 58, "type": "DATASET", "confidence": 0.9587801098823547}]}, {"text": "The gradient computation is done with symbolic differentiation, a functionality provided by Theano.", "labels": [], "entities": [{"text": "Theano", "start_pos": 92, "end_pos": 98, "type": "DATASET", "confidence": 0.9646772742271423}]}, {"text": "The models are trained on CPUs on Intel Xeon X5690 3.47GHz, using only a single core per model.", "labels": [], "entities": []}, {"text": "The models converge in minutes.", "labels": [], "entities": []}, {"text": "The implementation, the training script, and the trained model are already made available . Baseline The winning system from last year's task serves as a strong baseline for English.", "labels": [], "entities": []}, {"text": "We choose this system because it represents one of the strongest systems that utilizes exclusively surface features and extensive semantic lexicon (.", "labels": [], "entities": []}, {"text": "This approach uses a MaxEnt model loaded with millions of features.", "labels": [], "entities": []}, {"text": "We use Brown cluster pair features as the baseline for Chinese as there is no previous system for Chinese.", "labels": [], "entities": []}, {"text": "We use 3,200 clusters to create features and perform feature selection on the development set based on the information gain criteria).", "labels": [], "entities": []}, {"text": "We end up with 10,000 features total.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: F 1 scores for English non-explicit discourse relation. The bold-faced numbers highlight the  senses where the classification of our model and the baseline model might be complementary.", "labels": [], "entities": [{"text": "F 1", "start_pos": 10, "end_pos": 13, "type": "METRIC", "confidence": 0.9792531728744507}]}, {"text": " Table 2: F 1 scores for Chinese non-explicit discourse relation.", "labels": [], "entities": [{"text": "F 1", "start_pos": 10, "end_pos": 13, "type": "METRIC", "confidence": 0.988248199224472}]}]}