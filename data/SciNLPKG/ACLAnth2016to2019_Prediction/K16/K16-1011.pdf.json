{"title": [{"text": "A Data-driven Investigation of Corrective Feedback on Subject Omission Errors in First Language Acquisition", "labels": [], "entities": [{"text": "Subject Omission Errors in First Language Acquisition", "start_pos": 54, "end_pos": 107, "type": "TASK", "confidence": 0.6949168784277779}]}], "abstractContent": [{"text": "We investigate implicit corrections in the form of contrastive discourse in child-adult interaction, which have been argued to contribute to language learning.", "labels": [], "entities": []}, {"text": "In contrast to previous work in psycholinguis-tics, we adopt a data-driven methodology , using comparably large amounts of data and leveraging computational methods.", "labels": [], "entities": []}, {"text": "We conduct a corpus study on the use of parental corrective feedback and show that its presence in child directed speech is associated with a reduction of child subject omission errors in English.", "labels": [], "entities": []}], "introductionContent": [{"text": "It is widely agreed that children learn how to use language through interaction with their caregivers and peers.", "labels": [], "entities": []}, {"text": "There is, however, a long-standing discussion concerning the exact nature of the learning mechanism enabling this.", "labels": [], "entities": []}, {"text": "For example, while there is no doubt that children are exposed to positive input (i.e., grammatically correct utterances in context), it is an open question whether they also receive negative input-evidence about the inadequacy of their erroneous utterances.", "labels": [], "entities": []}, {"text": "What seems clear is that explicit disapprovals are very rarely used to correct grammatical mistakes, as already shown by.", "labels": [], "entities": []}, {"text": "However, certain contrastive constructions may provide negative input in an implicit way.", "labels": [], "entities": []}, {"text": "For instance, in the following exchange between 2-year-old Lara and her father, from the corpus by, the father picks up the child's erroneous utterance in the following turn and presents a form with the appropriate preposition: (1) CHI: I climb up daddy . DAD: you did climb over daddy . The contrast between the two forms is particularly noticeable and could potentially lead the child to recognise and correct their own error.", "labels": [], "entities": [{"text": "DAD", "start_pos": 256, "end_pos": 259, "type": "METRIC", "confidence": 0.9893965125083923}]}, {"text": "It has thus been argued that this type of construction presents children with negative evidence and, unlike explicit corrections, it does so in the course of conversation, without disrupting the dialogue flow.", "labels": [], "entities": []}, {"text": "Researchers have used different terms to refer to this phenomenon, including recast, reformulation, embedded correction, and corrective input.", "labels": [], "entities": []}, {"text": "In this paper, we adopt the term corrective feedback (CF), which we will define precisely in Section 3, and analyse its effect on first language learning-in particular on retreating from subject omission errors in English.", "labels": [], "entities": [{"text": "corrective feedback (CF)", "start_pos": 33, "end_pos": 57, "type": "TASK", "confidence": 0.6433696866035461}]}, {"text": "In contrast to previous work in psycholinguistics, we investigate these questions in a data-driven manner, using comparably large amounts of data from the CHILDES Database and developing computational methods to support linguistically motivated studies.", "labels": [], "entities": [{"text": "CHILDES Database", "start_pos": 155, "end_pos": 171, "type": "DATASET", "confidence": 0.9121013283729553}]}, {"text": "More concretely, we make the following contributions: \u2022 We present a taxonomy of child error types that can receive CF and an annotation scheme for coding instances of CF.", "labels": [], "entities": []}, {"text": "\u2022 We report the results of a corpus study showing that subject omission errors makeup the largest proportion of errors met with CF.", "labels": [], "entities": []}, {"text": "\u2022 We develop classifiers to automatically detect subject omission errors and CF on those errors, training on the manually annotated data.", "labels": [], "entities": [{"text": "CF", "start_pos": 77, "end_pos": 79, "type": "METRIC", "confidence": 0.9981410503387451}]}, {"text": "\u2022 Using automatically processed data, we investigate the impact of CF on learning subject inclusion in English with a series of linear regression models, showing that CF has predictive power over a variety of control factors.", "labels": [], "entities": [{"text": "learning subject inclusion", "start_pos": 73, "end_pos": 99, "type": "TASK", "confidence": 0.6335990130901337}]}, {"text": "Our results indicate that the effects of CF are most noticeable after a period of about 9 months.", "labels": [], "entities": [{"text": "CF", "start_pos": 41, "end_pos": 43, "type": "METRIC", "confidence": 0.9204891324043274}]}], "datasetContent": [{"text": "Our dataset consists of a selection of files from the English language section of the CHILDES Database) including all transcripts of conversations between adults and unimpaired, naturally developing children that contain a minimum of 50 utterances by the child and 100 utterances in total, and where the mean length of utterance (MLU; in words) of the child is at least 2.", "labels": [], "entities": [{"text": "CHILDES Database", "start_pos": 86, "end_pos": 102, "type": "DATASET", "confidence": 0.944670557975769}, {"text": "mean length of utterance (MLU; in words)", "start_pos": 304, "end_pos": 344, "type": "METRIC", "confidence": 0.7928494870662689}]}, {"text": "This ensures that the child is already at a stage where grammatical constructions are starting to be used.", "labels": [], "entities": []}, {"text": "Finally, since we are conducting a longitudinal study, in order to make sure there is enough data per child we consider only transcripts of children for which there is data over at least one year, with a file density of at least 5 transcripts per year and a minimum of 10 transcripts overall per child.", "labels": [], "entities": []}, {"text": "The resulting dataset contains a total number of 1,683 transcripts from 25 different children, with 1,598,838 utterances overall.", "labels": [], "entities": []}, {"text": "The average child age at the time of the first transcribed conversation lays around 2 years, with very little variation.", "labels": [], "entities": []}, {"text": "The mean difference between the child's age in the first and the last gathered transcript varies considerably ances, while we use them to characterise the type of error in a child utterance.", "labels": [], "entities": []}, {"text": "We deviate from Saxton et al.: Overview of our dataset containing longitudinal data from 25 different children.", "labels": [], "entities": []}, {"text": "more across children, but overall also lies around 2 years.", "labels": [], "entities": []}, {"text": "Most of the transcripts in the dataset already include part-of-speech tagging, morphological analysis, and dependency parsing.", "labels": [], "entities": [{"text": "part-of-speech tagging", "start_pos": 55, "end_pos": 77, "type": "TASK", "confidence": 0.7485585510730743}, {"text": "dependency parsing", "start_pos": 107, "end_pos": 125, "type": "TASK", "confidence": 0.823091596364975}]}, {"text": "We used the CLAN toolbox) and the MEGRASP dependency parser () to add POS tags and to morphologically and syntactically parse the transcripts where this information was not available.", "labels": [], "entities": [{"text": "MEGRASP dependency parser", "start_pos": 34, "end_pos": 59, "type": "TASK", "confidence": 0.6289408504962921}]}, {"text": "We also automatically coded each adult response to a child utterance with information on overlap using the CHIP programme), also part of the CLAN toolbox.", "labels": [], "entities": [{"text": "CHIP programme", "start_pos": 107, "end_pos": 121, "type": "DATASET", "confidence": 0.8456107378005981}, {"text": "CLAN toolbox", "start_pos": 141, "end_pos": 153, "type": "DATASET", "confidence": 0.8892173767089844}]}, {"text": "CHIP provides information on added ($ADD), deleted ($DEL), and exactly matching ($EXA) morphemes in the source and response utterances, as well as the proportion of morphemes in the response utterance which match exactly morphemes in the source ($REP).", "labels": [], "entities": [{"text": "REP)", "start_pos": 247, "end_pos": 251, "type": "METRIC", "confidence": 0.9673036336898804}]}, {"text": "shows a sample child-adult exchange with all the layers of information computed during the preprocessing stage.", "labels": [], "entities": []}, {"text": "5 Selection of candidate CF utterance pairs.", "labels": [], "entities": []}, {"text": "In order to investigate the effect of CF on language learning, we need to quantify the CF exchanges present in the corpus.", "labels": [], "entities": []}, {"text": "That is, we need to find mechanisms for automatically detecting these.", "labels": [], "entities": []}, {"text": "We use the overlap information to extract candidate instances of CF.", "labels": [], "entities": []}, {"text": "In line with constraints (C2) and (C3) in our definition, we consider candidate instances all child-adult utterance pairs with a percentage of repetition 0 < $REP < 1, where the overlap is not exclusively due to stopwords.", "labels": [], "entities": [{"text": "REP", "start_pos": 159, "end_pos": 162, "type": "METRIC", "confidence": 0.8181496858596802}]}, {"text": "We also require that the child's utterance contains a minimum of two distinct words so that there is scope fora grammatical anomaly (C1).", "labels": [], "entities": []}, {"text": "An overview of the dataset in shown in.", "labels": [], "entities": []}, {"text": "CHI: I climb up daddy .  Our experiments are designed as follows: We estimate the amount of SOEs at a particular period of time (defined in terms of child age in months) as the proportion of child utterances that contain a SOE.", "labels": [], "entities": []}, {"text": "We compute the amount of SOEs at two different time periods, t 0 and a later time t 1 . We then calculate the relative error reduction (rer) as the proportion of SOEs at t 0 that has been overcome at t 1 : Our aim is to investigate the relationship between relative error reduction (rer) of SOEs at t 1 and the presence of corrective feedback on SOEs at t 0 . The latter is calculated as the number of instances of CF on SOE at t 0 divided by the total number of child SOEs at t 0 . We consider all possible instantiations oft 0 and t 1 per child in the corpus, with a minimum time distance of one month between the two.", "labels": [], "entities": [{"text": "relative error reduction (rer)", "start_pos": 110, "end_pos": 140, "type": "METRIC", "confidence": 0.8936181664466858}, {"text": "relative error reduction (rer)", "start_pos": 257, "end_pos": 287, "type": "METRIC", "confidence": 0.7605923016866049}]}, {"text": "This allows us to investigate at what age CF seems more effective (different t 0 values) and how much time is needed for its effect to be noticeable on learning (distance between t 0 and t 1 ).", "labels": [], "entities": []}, {"text": "We construct several linear regression models, where rer(t 0 , t 1 ) is always the dependent variable we are interested in predicting and CF at t 0 is the independent variable whose predictive power we are investigating, while controlling for several other factors characterising child directed speech and children's own speech.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Overview of our dataset containing lon- gitudinal data from 25 different children.", "labels": [], "entities": []}, {"text": " Table 2: Types of errors in exchanges coded as CF.", "labels": [], "entities": []}, {"text": " Table 3: Beta coefficients for linear regression  model; *** p<0.001, ** p<0.01. Overall variance  in rer captured by the model (adjusted R 2 ): 0.53.", "labels": [], "entities": []}]}