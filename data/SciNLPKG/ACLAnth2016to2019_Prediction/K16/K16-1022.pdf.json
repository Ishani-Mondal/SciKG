{"title": [{"text": "Cross-Lingual Named Entity Recognition via Wikification", "labels": [], "entities": [{"text": "Cross-Lingual Named Entity Recognition", "start_pos": 0, "end_pos": 38, "type": "TASK", "confidence": 0.6767429038882256}, {"text": "Wikification", "start_pos": 43, "end_pos": 55, "type": "DATASET", "confidence": 0.7259265184402466}]}], "abstractContent": [{"text": "Named Entity Recognition (NER) models for language L are typically trained using annotated data in that language.", "labels": [], "entities": [{"text": "Named Entity Recognition (NER)", "start_pos": 0, "end_pos": 30, "type": "TASK", "confidence": 0.7584079553683599}]}, {"text": "We study cross-lingual NER, where a model for NER in L is trained on another , source, language (or multiple source languages).", "labels": [], "entities": []}, {"text": "We introduce a language independent method for NER, building on cross-lingual wikification, a technique that grounds words and phrases in non-English text into English Wikipedia entries.", "labels": [], "entities": [{"text": "NER", "start_pos": 47, "end_pos": 50, "type": "TASK", "confidence": 0.9621812701225281}]}, {"text": "Thus, mentions in any language can be described using a set of categories and FreeBase types, yielding, as we show, strong language-independent features.", "labels": [], "entities": []}, {"text": "With this insight, we propose an NER model that can be applied to all languages in Wikipedia.", "labels": [], "entities": []}, {"text": "When trained on English, our model outperforms comparable approaches on the standard CoNLL datasets (Spanish, German, and Dutch) and also performs very well on low-resource languages (e.g., Turkish, Taga-log, Yoruba, Bengali, and Tamil) that have significantly smaller Wikipedia.", "labels": [], "entities": [{"text": "CoNLL datasets", "start_pos": 85, "end_pos": 99, "type": "DATASET", "confidence": 0.918938934803009}]}, {"text": "Moreover , our method allows us to train on multiple source languages, typically improving NER results on the target languages.", "labels": [], "entities": []}, {"text": "Finally, we show that our language-independent features can be used also to enhance monolingual NER systems, yielding improved results for all 9 languages.", "labels": [], "entities": []}], "introductionContent": [{"text": "Named Entity Recognition (NER) is the task of identifying and typing phrases that contain the names of persons, organizations, locations, and soon.", "labels": [], "entities": [{"text": "Named Entity Recognition (NER) is the task of identifying and typing phrases that contain the names of persons, organizations, locations, and soon", "start_pos": 0, "end_pos": 146, "type": "Description", "confidence": 0.6686919055603169}]}, {"text": "It is an information extraction task that is important for understanding large bodies of text and is considered an essential pre-processing stage in Natural Language Processing (NLP) and Information Retrieval systems.", "labels": [], "entities": [{"text": "information extraction task", "start_pos": 9, "end_pos": 36, "type": "TASK", "confidence": 0.8474889794985453}, {"text": "understanding large bodies of text", "start_pos": 59, "end_pos": 93, "type": "TASK", "confidence": 0.7890472412109375}, {"text": "Information Retrieval", "start_pos": 187, "end_pos": 208, "type": "TASK", "confidence": 0.7982858121395111}]}, {"text": "NER is successful for languages which have a large amount of annotated data, but for languages with little to no annotated data, this task becomes very challenging.", "labels": [], "entities": []}, {"text": "There are two common approaches to address the lack of training data problem.", "labels": [], "entities": []}, {"text": "The first approach is to automatically generate annotated training data in the target language from Wikipedia articles or from parallel corpora.", "labels": [], "entities": []}, {"text": "The performance of this method depends on the quality of the generated data and how well the language-specific features are explored.", "labels": [], "entities": []}, {"text": "The second approach is to train a model on another language which has abundant training data, and then apply the model directly on test documents in the target language.", "labels": [], "entities": []}, {"text": "This direct transfer technique relies on developing language-independent features.", "labels": [], "entities": []}, {"text": "Note that these two approaches are orthogonal and can be used together.", "labels": [], "entities": []}, {"text": "In this paper, we focus on the second, direct transfer setting.", "labels": [], "entities": []}, {"text": "We propose a cross-lingual NER model which is trained on annotated documents in one or multiple source languages, and can be applied to all languages in Wikipedia.", "labels": [], "entities": []}, {"text": "The model depends on a cross-lingual wikifier, which only requires multilingual Wikipedia, no sentencealigned or word-aligned parallel text is needed.", "labels": [], "entities": []}, {"text": "The key contribution of this paper is the development of a method that makes use of crosslingual wikification and entity linking) to generate language-independent features for NER, and showing how useful this can be for training NER models with no annotation in the target language.", "labels": [], "entities": []}, {"text": "Given a mention (sub-string) from a document written in a foreign language, the goal of cross-lingual wikification is to find the cor- Figure 1: An example of a German sentence.", "labels": [], "entities": []}, {"text": "We ground each word to the English Wikipedia using a cross-lingual wikifier.", "labels": [], "entities": [{"text": "English Wikipedia", "start_pos": 27, "end_pos": 44, "type": "DATASET", "confidence": 0.9060083031654358}]}, {"text": "A word is not linked if it is a stop word or the wikifier returns NIL.", "labels": [], "entities": []}, {"text": "We can see that the FreeBase types are strong signals to NER even with imperfect disambiguation.", "labels": [], "entities": []}, {"text": "responding title in the English Wikipedia.", "labels": [], "entities": [{"text": "English Wikipedia", "start_pos": 24, "end_pos": 41, "type": "DATASET", "confidence": 0.9439152479171753}]}, {"text": "Traditionally, wikification has been considered a downstream task of NER.", "labels": [], "entities": [{"text": "NER", "start_pos": 69, "end_pos": 72, "type": "TASK", "confidence": 0.782833993434906}]}, {"text": "That is, a named entity recognizer is first applied to identify mentions of interest, and then a wikifier is used to ground the extracted mentions to Wikipedia entries.", "labels": [], "entities": []}, {"text": "In contrast to this traditional pipeline, we show that the ability to ground and disambiguate words is very useful to NER.", "labels": [], "entities": [{"text": "NER", "start_pos": 118, "end_pos": 121, "type": "TASK", "confidence": 0.9379453659057617}]}, {"text": "By grounding every n-gram to the English Wikipedia, we obtain useful clues to NER, regardless of the target language.", "labels": [], "entities": [{"text": "NER", "start_pos": 78, "end_pos": 81, "type": "TASK", "confidence": 0.8184495568275452}]}, {"text": "shows an example of a German sentence.", "labels": [], "entities": []}, {"text": "We use a cross-lingual wikifier to ground each word to the English Wikipedia.", "labels": [], "entities": []}, {"text": "We can see that even though the disambiguation is not perfect, the FreeBase types still provide valuable information.", "labels": [], "entities": []}, {"text": "That is, although \"Albrecht Lehmann\" is not an entry in Wikipedia, the wikifier still links \"Albrecht\" and \"Lehmann\" to people.", "labels": [], "entities": []}, {"text": "Since words in any language are grounded to the English Wikipedia, the corresponding Wikipedia categories and Freebase types can be used as language-independent features.", "labels": [], "entities": []}, {"text": "The proposed model significantly outperforms comparable direct transfer methods on the Spanish, Dutch, and German CoNLL data.", "labels": [], "entities": [{"text": "CoNLL data", "start_pos": 114, "end_pos": 124, "type": "DATASET", "confidence": 0.9244340062141418}]}, {"text": "We also evaluate the model on five low-resource languages: Turkish, Tagalog, Yoruba, Bengali, and Tamil.", "labels": [], "entities": []}, {"text": "Due to small sizes of Wikipedia, the overall performance is not as good as the CoNLL experiments.", "labels": [], "entities": []}, {"text": "Nevertheless, the wikifier features still give significant improvements, and the proposed direct transfer model outperforms the state of the art, which assumes parallel text and some interaction with a native speaker of the target language.", "labels": [], "entities": []}, {"text": "In addition, we show that the proposed languageindependent features not only perform well on the direct transfer scenario, but also improve monolingual models, which are trained on the target language.", "labels": [], "entities": []}, {"text": "Another advantage of the proposed direct transfer model is that we can train on documents from multiple languages together, and further improve the results.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section, we conduct experiments to validate and analyze the proposed NER model.", "labels": [], "entities": [{"text": "NER", "start_pos": 77, "end_pos": 80, "type": "TASK", "confidence": 0.9518365859985352}]}, {"text": "First, we show that adding wikifier features improves results on monolingual NER.", "labels": [], "entities": []}, {"text": "Second, we show that wikifier features are strong signals indirect transfer of a trained NER model across languages.", "labels": [], "entities": []}, {"text": "Finally, we explore the importance of Wikipedia size to the quality of wikifier features and study the use of multiple source languages.", "labels": [], "entities": []}, {"text": "We use data from CoNLL2002/2003 shared tasks).", "labels": [], "entities": [{"text": "CoNLL2002/2003 shared tasks", "start_pos": 17, "end_pos": 44, "type": "DATASET", "confidence": 0.9128287434577942}]}, {"text": "The 4 languages represented are English, German, Spanish, and Dutch, each annotated using the IOB1 labeling scheme, which we convert to the BIO labeling scheme.", "labels": [], "entities": [{"text": "BIO labeling scheme", "start_pos": 140, "end_pos": 159, "type": "DATASET", "confidence": 0.7213151852289835}]}, {"text": "All training is on the train set, and testing is on the test set.", "labels": [], "entities": []}, {"text": "The evaluation metric for all experiments is phrase level F1, as explained in).", "labels": [], "entities": [{"text": "phrase level F1", "start_pos": 45, "end_pos": 60, "type": "METRIC", "confidence": 0.7664983073870341}]}, {"text": "In order to experiment on a broader range of languages, we also use data from the REFLEX () and LORELEI projects.", "labels": [], "entities": [{"text": "REFLEX", "start_pos": 82, "end_pos": 88, "type": "METRIC", "confidence": 0.7058664560317993}, {"text": "LORELEI", "start_pos": 96, "end_pos": 103, "type": "METRIC", "confidence": 0.8919225931167603}]}, {"text": "From LORELEI, we use Turkish, 2 From REFLEX, we use Bengali, Tagalog, Tamil, and Yoruba.", "labels": [], "entities": [{"text": "LORELEI", "start_pos": 5, "end_pos": 12, "type": "METRIC", "confidence": 0.9451968669891357}, {"text": "REFLEX", "start_pos": 37, "end_pos": 43, "type": "METRIC", "confidence": 0.9052311778068542}]}, {"text": "3 While Turkish, Tagalog, and Yoruba each has a few non-Latin characters, Bengali and Tamil are with an entirely non-Latin script.", "labels": [], "entities": []}, {"text": "This is a major reason for inclusion in our experiments.", "labels": [], "entities": []}, {"text": "We use the same set of test documents as used in.", "labels": [], "entities": []}, {"text": "All other documents in the REFLEX and LORELEI packages are used as the training documents in our monolingual experiments.", "labels": [], "entities": [{"text": "REFLEX", "start_pos": 27, "end_pos": 33, "type": "METRIC", "confidence": 0.9681122899055481}, {"text": "LORELEI", "start_pos": 38, "end_pos": 45, "type": "METRIC", "confidence": 0.9495272636413574}]}, {"text": "We refer to these five languages collectively as low-resource languages.", "labels": [], "entities": []}, {"text": "Besides PER, LOC, and ORG, some lowresource languages contain TIME tags and TTL tags, which represented titles in text, such as Secretary, President, or Minister.", "labels": [], "entities": [{"text": "PER", "start_pos": 8, "end_pos": 11, "type": "METRIC", "confidence": 0.7538728713989258}, {"text": "ORG", "start_pos": 22, "end_pos": 25, "type": "METRIC", "confidence": 0.8905163407325745}]}, {"text": "Since such words are not tagged in the CoNLL training data, we opted to simply remove these tags.", "labels": [], "entities": [{"text": "CoNLL training data", "start_pos": 39, "end_pos": 58, "type": "DATASET", "confidence": 0.931405504544576}]}, {"text": "On the other hand, there is no MISC tag in the low-resource languages.", "labels": [], "entities": [{"text": "MISC", "start_pos": 31, "end_pos": 35, "type": "TASK", "confidence": 0.8153908848762512}]}, {"text": "Instead, many MISC-tagged entities in the CoNLL datasets have LOC tags in the RE-FLEX and LORELEI packages, e.g., Italian and 2 LDC2014E115 3 LDC2015E13,LDC2015E90,LDC2015E83,LDC2015E91 Chinese.", "labels": [], "entities": [{"text": "CoNLL datasets", "start_pos": 42, "end_pos": 56, "type": "DATASET", "confidence": 0.9650575220584869}, {"text": "RE-FLEX", "start_pos": 78, "end_pos": 85, "type": "METRIC", "confidence": 0.9651686549186707}, {"text": "LORELEI", "start_pos": 90, "end_pos": 97, "type": "METRIC", "confidence": 0.9024897813796997}]}, {"text": "We modify a MISC-tagged word to LOC tag if it is grounded to an entity with location as a FreeBase type, and remove all the other MISC tags in the training data.", "labels": [], "entities": []}, {"text": "This process of changing MISC tags is only done when we train on CoNLL documents and test on low-resource languages.", "labels": [], "entities": [{"text": "MISC tags", "start_pos": 25, "end_pos": 34, "type": "TASK", "confidence": 0.8142313361167908}, {"text": "CoNLL documents", "start_pos": 65, "end_pos": 80, "type": "DATASET", "confidence": 0.909075915813446}]}, {"text": "The only requirement to build the cross-lingual wikifier model is a multilingual Wikipedia dump, and it can be trivially applied to all languages in Wikipedia.", "labels": [], "entities": []}, {"text": "The top section of lists Wikipedia sizes in terms of articles, 4 the number of titles linked to English titles, and the number of training and test mentions for each language.", "labels": [], "entities": []}, {"text": "Besides the English gazetteers used in Ratinov and Roth (2009), we collect gazetteers for each language using Wikipedia titles.", "labels": [], "entities": []}, {"text": "A Wikipedia title is included in the list for person names if it contains FreeBase type person.", "labels": [], "entities": []}, {"text": "Similarly, we also create a location list and an organization list for each language.", "labels": [], "entities": []}, {"text": "The total number of names in the gazetteers of each language is listed in.", "labels": [], "entities": []}, {"text": "We begin by showing that wikifier features help when we train and test on the same language.", "labels": [], "entities": []}, {"text": "The middle section of shows these results.", "labels": [], "entities": []}, {"text": "In the 'Wikifier only' row, we use only wikifier features and previous tags features.", "labels": [], "entities": []}, {"text": "This is intended to show the predictive power of wikifier features alone.", "labels": [], "entities": []}, {"text": "Without using any lexical features, it gets good scores on the languages that have a large Wikipedia.", "labels": [], "entities": []}, {"text": "These numbers represent the quality of the cross-lingual wikifier in that language, which in turn is correlated with the size of Wikipedia and size of the intersection with English Wikipedia.", "labels": [], "entities": []}, {"text": "The next row, 'Base features', shows that lexical features are always better than wikifier features only.", "labels": [], "entities": []}, {"text": "This agrees with the common wisdom that lexical features are important for NER.", "labels": [], "entities": [{"text": "NER", "start_pos": 75, "end_pos": 78, "type": "TASK", "confidence": 0.9867525100708008}]}, {"text": "Adding gazetteers to the base features improves by more than 3 points for higher-resource languages.", "labels": [], "entities": []}, {"text": "This is because the low-resource languages have much smaller gazetteers which have lower coverage than other languages' gazetteers.", "labels": [], "entities": []}, {"text": "Finally, the '+Wikifier' row shows that our proposed features are valuable even in combination with strong features.", "labels": [], "entities": []}, {"text": "It improves upon base features and gazetteer features for all 9 languages.", "labels": [], "entities": []}, {"text": "These numbers maybe less than state of the art because the features we use are designed for English, and may not capture lexical subtleties in every language.", "labels": [], "entities": []}, {"text": "Nevertheless, they show that wikifier features have a non-trivial signal that has not been captured by other features.", "labels": [], "entities": []}, {"text": "We evaluate our direct transfer experiments by training on English and testing on the target language.", "labels": [], "entities": []}, {"text": "The results from these experiments are shown in the bottom section of.", "labels": [], "entities": []}, {"text": "The 'Wikifier only' row shows that the wikifier features alone preserve a signal across languages.", "labels": [], "entities": []}, {"text": "Interestingly, for both Bengali and Tamil, this is the strongest signal, and gets the highest score.", "labels": [], "entities": []}, {"text": "If the lexical features are included when we train the English model, the learning algorithm will give them too much emphasis, thus decreasing the importance of the wikifier features.", "labels": [], "entities": []}, {"text": "Since Bengali and Tamil use non-Latin scripts, no lexical feature in English will fire attest time.", "labels": [], "entities": []}, {"text": "Thus, approaches that include base features perform poorly.", "labels": [], "entities": []}, {"text": "The results of 'Base features' can be viewed as a sort of language similarity to English, which, in this case, is related to lexical overlap and similarity between the scripts.", "labels": [], "entities": []}, {"text": "Comparing to monolingual experiments, we can see that the lexical features become weak in the cross-lingual setting.", "labels": [], "entities": []}, {"text": "The gazetteer features are again shown to be very useful for almost all languages except Bengali and Tamil due to the reason explained in the monolingual experiment and to the inclusion of lexical features.", "labels": [], "entities": []}, {"text": "For all other languages, the gain from adding gazetteers is even larger than it is in the monolingual setting.", "labels": [], "entities": []}, {"text": "For nearly every language, wikifier features help dramatically, which indicates that they are very good delexicalized features.", "labels": [], "entities": []}, {"text": "Wikifier features add more than 10 points on Dutch, German, and Turkish.", "labels": [], "entities": []}, {"text": "The trend in suggests the following strategy when we want to extract named entities in anew foreign language: It is better to include all features if the foreign language uses Latin script, since the names are likely to be mentioned similarly to the English names.", "labels": [], "entities": []}, {"text": "Otherwise, using wikifier features only could be the best setting.", "labels": [], "entities": []}, {"text": "also directly transfer an English NER model using the same setting as ours: train on the CoNLL English training set and predict on the test set of other three languages.", "labels": [], "entities": [{"text": "CoNLL English training set", "start_pos": 89, "end_pos": 115, "type": "DATASET", "confidence": 0.9368460327386856}]}, {"text": "We compare our baseline transfer model (Base Features) to the row denoted by \"T\u00e4ckstr\u00f6m baseline\".", "labels": [], "entities": []}, {"text": "Even though we do not use gold POS tags, we see that our results are comparable.", "labels": [], "entities": []}, {"text": "The second T\u00e4ckstr\u00f6m row uses parallel text to induce multilingual word clustering.", "labels": [], "entities": [{"text": "multilingual word clustering", "start_pos": 54, "end_pos": 82, "type": "TASK", "confidence": 0.6387776434421539}]}, {"text": "While this approach is orthogonal to ours, and could be used in tandem to get even better scores, we compare against it for lack of a more closely aligned scenario.", "labels": [], "entities": []}, {"text": "We see that for each language, our approach significantly outperforms their approach.", "labels": [], "entities": []}, {"text": "We note that our numbers are comparable to those reported for WIKI-2 in Nothman et al. for the CoNLL languages (with the exception of German, where their result is higher).", "labels": [], "entities": [{"text": "WIKI-2", "start_pos": 62, "end_pos": 68, "type": "DATASET", "confidence": 0.8860803842544556}, {"text": "CoNLL languages", "start_pos": 95, "end_pos": 110, "type": "DATASET", "confidence": 0.9051530361175537}]}, {"text": "However, they require language-specific heuristics to generate silver-standard training data from Wikipedia articles.", "labels": [], "entities": []}, {"text": "What they gain for single languages, they likely lose in generalization to other languages.", "labels": [], "entities": []}, {"text": "This approach is orthogonal to ours; we, too, can use their silver-standard data in training.", "labels": [], "entities": []}, {"text": "For the low-resource languages, we compare our direct transfer model with the expectation learning model proposed in.", "labels": [], "entities": []}, {"text": "This model is not a direct transfer model, but it does not use any training data in the target languages either.", "labels": [], "entities": []}, {"text": "Instead, for each target language, it generates patterns from parallel documents between English and the target language, a large monolingual corpus in the target language, and one-hour interaction with a native speaker of the target language.", "labels": [], "entities": []}, {"text": "Note that they also use a crosslingual wikifier, but only for refining the entity types.", "labels": [], "entities": []}, {"text": "On the other hand, in our model, the features from the wikifier are used both in detecting entity mention boundaries and entity types.", "labels": [], "entities": []}, {"text": "We can see that our approach performs better than their model on all five languages even though we assume much fewer resources.", "labels": [], "entities": []}, {"text": "The difference is most significant on Turkish, Tagalog, and Bengali.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Data sizes, monolingual experiments, and direct transfer experiments. Wiki size is the  number of articles in Wikipedia. For monolingual experiments, we train the proposed model on the  training data of the target languages. 'Wikifier only' uses the previous tags features also. For direct  transfer experiments, all models are trained on CoNLL English training set. The rows marked T\u00e4ckstr\u00f6m  come from (T\u00e4ckstr\u00f6m et al., 2012), and are the baseline and clustering result. The plus signs (+) signify  cumulative addition. EN: English, NL: Dutch, DE: German, ES: Spanish, TR: Turkish, TL: Tagalog,  YO: Yoruba, BN: Bengali, TA: Tamil.", "labels": [], "entities": [{"text": "CoNLL English training set", "start_pos": 349, "end_pos": 375, "type": "DATASET", "confidence": 0.9194491654634476}]}, {"text": " Table 3: The F1 scores of using only wikifier fea- tures with removing the support from FreeBase  and varying the number of titles linked to the  English Wikipedia. 'W.\u2212FB query' removes the  component of querying FreeBase by the target lan- guage title from 'Wikifier only'. '\u2212X% inter.' in- dicates removing X% of the interlanguage links  with English titles. The column #inter. shows the  number of titles that intersect with English.", "labels": [], "entities": [{"text": "F1", "start_pos": 14, "end_pos": 16, "type": "METRIC", "confidence": 0.9995294809341431}]}, {"text": " Table 4: The F1 scores of the proposed direct  transfer model on three low-resource languages  using training data in multiple languages. The  row \"ALL\u2212Test Lang\" trains the model on all  languages except the test language, Bengali, and  Tamil. Bengali and Tamil are excluded since we  use all features in this experiment.", "labels": [], "entities": [{"text": "F1", "start_pos": 14, "end_pos": 16, "type": "METRIC", "confidence": 0.9992260932922363}]}, {"text": " Table 5: The domain adaptation experiments. The  source domain (English) training examples are  used to improve the monolingual baseline model  (Target) which is only trained on the target domain  (Spanish, Dutch, Turkish, and Tagalog) training  data. The numbers are the phrase-level F1 scores.", "labels": [], "entities": [{"text": "domain adaptation", "start_pos": 14, "end_pos": 31, "type": "TASK", "confidence": 0.7474833428859711}, {"text": "F1", "start_pos": 286, "end_pos": 288, "type": "METRIC", "confidence": 0.9419806599617004}]}]}