{"title": [{"text": "Beyond Centrality and Structural Features: Learning Information Importance for Text Summarization", "labels": [], "entities": [{"text": "Learning Information Importance", "start_pos": 43, "end_pos": 74, "type": "TASK", "confidence": 0.6382619639237722}, {"text": "Text Summarization", "start_pos": 79, "end_pos": 97, "type": "TASK", "confidence": 0.726276695728302}]}], "abstractContent": [{"text": "Most automatic text summarization systems proposed to date rely on centrality and structural features as indicators for information importance.", "labels": [], "entities": [{"text": "text summarization", "start_pos": 15, "end_pos": 33, "type": "TASK", "confidence": 0.6414559334516525}]}, {"text": "In this paper, we argue that these features cannot reliably detect important information in heterogeneous document collections.", "labels": [], "entities": []}, {"text": "Instead, we propose CPSum, a summarizer that learns the importance of information objects from a background source.", "labels": [], "entities": []}, {"text": "Our hypothesis is tested on a multi-document corpus where we remove centrality and structural features.", "labels": [], "entities": []}, {"text": "CPSum proves to be able to perform well in this challenging scenario whereas reference systems fail.", "labels": [], "entities": [{"text": "CPSum", "start_pos": 0, "end_pos": 5, "type": "DATASET", "confidence": 0.9151940941810608}]}], "introductionContent": [{"text": "The goal of text summarization is to take an information source, extract content from it, and present the most important content to the user (.", "labels": [], "entities": [{"text": "text summarization", "start_pos": 12, "end_pos": 30, "type": "TASK", "confidence": 0.7135829776525497}]}, {"text": "Identifying important information in source documents is therefore a major goal in summarization.", "labels": [], "entities": [{"text": "Identifying important information in source documents", "start_pos": 0, "end_pos": 53, "type": "TASK", "confidence": 0.8603470921516418}, {"text": "summarization", "start_pos": 83, "end_pos": 96, "type": "TASK", "confidence": 0.9856089949607849}]}, {"text": "Most methods to date rely on structural features such as sentence position, number of upper-case words, or title words, and a wide range of measures of sentence centrality as signals for what is important in source documents.", "labels": [], "entities": []}, {"text": "In particular in news articles, such as those used for the DUC2002 single-document summarization and the DUC2004 multi-document summarization tasks, 1 it is quite common that the most important information is repeated most frequently.", "labels": [], "entities": [{"text": "DUC2002 single-document summarization", "start_pos": 59, "end_pos": 96, "type": "TASK", "confidence": 0.764893631140391}, {"text": "DUC2004 multi-document summarization tasks", "start_pos": 105, "end_pos": 147, "type": "TASK", "confidence": 0.7915312200784683}]}, {"text": "Indeed, showed that information which appears frequently in the input documents is likely to appear in a human-generated summary.", "labels": [], "entities": []}, {"text": "Similar conclusions can be drawn for single-document news corpora, where, for example, important information is likely to be found at the beginning of the document (for impatient readers), and repeated and expanded later in the article.", "labels": [], "entities": []}, {"text": "Even though most research in text summarization to date focused on newswire documents, this special kind of text genre is not the only one to be considered for summarization.", "labels": [], "entities": [{"text": "text summarization", "start_pos": 29, "end_pos": 47, "type": "TASK", "confidence": 0.6982743740081787}, {"text": "summarization", "start_pos": 160, "end_pos": 173, "type": "TASK", "confidence": 0.9909061193466187}]}, {"text": "Recently, about 400 journalists organized by the International Consortium of Investigative Journalists (ICIJ) 2 spent more than a year to analyze 11.5 million documents in the Panama Papers repository, which consists of emails, PDFs, and other text documents not belonging to the newswire genre.", "labels": [], "entities": [{"text": "International Consortium of Investigative Journalists (ICIJ)", "start_pos": 49, "end_pos": 109, "type": "TASK", "confidence": 0.5972265675663948}, {"text": "Panama Papers repository", "start_pos": 176, "end_pos": 200, "type": "DATASET", "confidence": 0.9523979624112447}]}, {"text": "In such a heterogeneous collection of raw and unprocessed source documents we cannot assume that frequency information correlates with importance, and therefore cannot rely on (in)frequency as (un)importance signal.", "labels": [], "entities": []}, {"text": "Nevertheless, journalists are able to cope with such situations because they bring along their background knowledge about the world, which allows them to estimate what information is important and what is not.", "labels": [], "entities": []}, {"text": "We therefore propose to incorporate world knowledge to handle more challenging summarization scenarios where centrality cannot be used as a signal for importance.", "labels": [], "entities": [{"text": "summarization", "start_pos": 79, "end_pos": 92, "type": "TASK", "confidence": 0.9824333190917969}]}, {"text": "Our assumption is that summarization systems which are aware of the importance of information without analyzing the structure of the source documents are able to summarize heterogeneous documents properly.", "labels": [], "entities": [{"text": "summarization", "start_pos": 23, "end_pos": 36, "type": "TASK", "confidence": 0.9886159300804138}, {"text": "summarize heterogeneous documents", "start_pos": 162, "end_pos": 195, "type": "TASK", "confidence": 0.8885523676872253}]}, {"text": "The key question of the paper is whether a knowledge-based summarization system is still able to detect important information even when structural and centrality-based features cannot be used as signals for importance.", "labels": [], "entities": []}, {"text": "We first review well-known summarization sys- tems for single-and multi-document summarization in Section 2.", "labels": [], "entities": [{"text": "single-and multi-document summarization", "start_pos": 55, "end_pos": 94, "type": "TASK", "confidence": 0.5100060701370239}]}, {"text": "Particular emphasis is put on the methodologies used to identify important information and avoid redundancy since this is the main innovation of our knowledge-based system described in Section 3.", "labels": [], "entities": []}, {"text": "CPSum learns about importance by analyzing an independent background corpus of document-summary pairs and applies this knowledge in the summarization task.", "labels": [], "entities": [{"text": "summarization task", "start_pos": 136, "end_pos": 154, "type": "TASK", "confidence": 0.8882100880146027}]}, {"text": "A major difference to previous systems is that we do not use similarity measures to compute centrality, neither for detecting importance nor for avoiding redundancy.", "labels": [], "entities": []}, {"text": "In order to verify our assumptions, we compare our approach on a commonly used evaluation corpus, both in its original version and in various version in which we remove redundancy and sentence order.", "labels": [], "entities": []}, {"text": "We describe the corpus modification in Section 4.", "labels": [], "entities": [{"text": "corpus modification", "start_pos": 16, "end_pos": 35, "type": "TASK", "confidence": 0.7214668840169907}]}, {"text": "Expectedly, our experiments described in Section 5 and 6 show a substantial performance decrease for all tested reference systems, whereas the performance of CPSum remains essentially unchanged.", "labels": [], "entities": []}, {"text": "The conclusions we draw from this study are summarized in Section 7.", "labels": [], "entities": []}], "datasetContent": [{"text": "The fundamental hypothesis of centrality-based summarization systems is that frequency within the source documents implies importance of information.", "labels": [], "entities": [{"text": "centrality-based summarization", "start_pos": 30, "end_pos": 60, "type": "TASK", "confidence": 0.6554266214370728}]}, {"text": "All information which is frequent in the source documents is considered to be important and therefore extracted for the summary.", "labels": [], "entities": []}, {"text": "While this maybe a suitable assumption for some document collections (such as newswire documents), we do not believe that it is suitable for the task of summarizing heterogeneous document collections.", "labels": [], "entities": [{"text": "summarizing heterogeneous document collections", "start_pos": 153, "end_pos": 199, "type": "TASK", "confidence": 0.9047359377145767}]}, {"text": "Since most of the work in summarization has been done for newswire data, there is alack of evaluation data where structural and centrality signals do not provide a strong indicator for importance.", "labels": [], "entities": [{"text": "summarization", "start_pos": 26, "end_pos": 39, "type": "TASK", "confidence": 0.9899290204048157}]}, {"text": "We therefore modify the DUC2004 multi-document summarization corpus by shuffling and oversampling to remove the commonly used indicators for importance.", "labels": [], "entities": [{"text": "DUC2004 multi-document summarization corpus", "start_pos": 24, "end_pos": 67, "type": "DATASET", "confidence": 0.7819029241800308}]}, {"text": "By doing so, we intend to demonstrate that centrality-based document summarization algorithms breakdown, whereas PLSum will maintain its performance.", "labels": [], "entities": [{"text": "centrality-based document summarization", "start_pos": 43, "end_pos": 82, "type": "TASK", "confidence": 0.7477792104085287}]}, {"text": "Shuffling: In order to remove order-dependency, we randomly shuffle the sentences to hide the very strong sentence position signal, which is commonly used to detect importance in news documents.", "labels": [], "entities": []}, {"text": "Oversampling: With oversampling we aim for hiding the important information in the corpus by increasing the frequency of unimportant information.", "labels": [], "entities": []}, {"text": "In particular, we iteratively search fora sentenc\u00ea s with\u02c6s with\u02c6with\u02c6s = arg min where sim is a similarity measure for two sentences, and add\u02c6sadd\u02c6add\u02c6s to a random document in topic D.", "labels": [], "entities": []}, {"text": "Since we duplicate the sentences we make sure that we do not introduce new, important information to the corpus which is not reflected in the summary.", "labels": [], "entities": []}, {"text": "For the similarity measure we use in our experiments, where cos is a cosine similarity implemented in the DKPro Similarity framework: Average similarities of the sentences contained in the test corpora.", "labels": [], "entities": []}, {"text": "combination lead to reasonably good results on the English subtask of the SemEval2014 Semantic Textual Similarity dataset.", "labels": [], "entities": [{"text": "SemEval2014 Semantic Textual Similarity dataset", "start_pos": 74, "end_pos": 121, "type": "DATASET", "confidence": 0.767588472366333}]}, {"text": "With this methodology, we create four new corpora with 100%, 200%, 500%, and 1000% of the size of DUC2004.", "labels": [], "entities": [{"text": "DUC2004", "start_pos": 98, "end_pos": 105, "type": "DATASET", "confidence": 0.9754664897918701}]}, {"text": "The bigger the corpora is, the more unimportant information has been added to it.", "labels": [], "entities": []}, {"text": "In the 100% corpus sentences are only shuffled without duplicating sentences.", "labels": [], "entities": []}, {"text": "With increasing size we hide the originally frequent information better and make it therefore harder to detect important information.", "labels": [], "entities": []}, {"text": "An analysis of the result of the oversampling is displayed in.", "labels": [], "entities": []}, {"text": "The average similarity decreases which means that we hide dense regions by adding sentences to less dense regions.", "labels": [], "entities": [{"text": "similarity", "start_pos": 12, "end_pos": 22, "type": "METRIC", "confidence": 0.9755343198776245}]}, {"text": "Since the DUC data provides manually written reference summaries, we can compare these gold standard summaries to the newly generated summaries of the automatic summarization systems.", "labels": [], "entities": [{"text": "DUC data", "start_pos": 10, "end_pos": 18, "type": "DATASET", "confidence": 0.9720218181610107}]}, {"text": "We provide in the evaluation ROUGE-1 (R1) and ROUGE-2 (R2) based recall scores according to who showed that R2 provides the best agreement with manual evaluations when using stemming and without removing stopwords.", "labels": [], "entities": [{"text": "ROUGE-1", "start_pos": 29, "end_pos": 36, "type": "METRIC", "confidence": 0.9765027761459351}, {"text": "ROUGE-2 (R2) based", "start_pos": 46, "end_pos": 64, "type": "METRIC", "confidence": 0.9353896498680114}, {"text": "recall", "start_pos": 65, "end_pos": 71, "type": "METRIC", "confidence": 0.6543402671813965}]}, {"text": "As showed that there is no clear winner between R1 and R2, we provide R1 as well, which is well suited to identify the better summary in a pair of summaries.", "labels": [], "entities": []}, {"text": "Furthermore, all automatically generated summaries are truncated at a length of 100 words by the ROUGE system.", "labels": [], "entities": [{"text": "ROUGE", "start_pos": 97, "end_pos": 102, "type": "METRIC", "confidence": 0.7495771050453186}]}, {"text": "Summarized, we use ROUGE-1.5.5 with parameters -a -m -n 2 -x -c 95 -r 1000 -f A -p 0.5 -t 0 -l 100 -d.", "labels": [], "entities": [{"text": "ROUGE-1.5.5", "start_pos": 19, "end_pos": 30, "type": "METRIC", "confidence": 0.9455721378326416}]}], "tableCaptions": [{"text": " Table 1: Average similarities of the sentences con- tained in the test corpora.", "labels": [], "entities": [{"text": "similarities", "start_pos": 18, "end_pos": 30, "type": "METRIC", "confidence": 0.7887167930603027}]}, {"text": " Table 2: ROUGE-1 and ROUGE-2 scores on the original and the modified DUC 2004 corpora.", "labels": [], "entities": [{"text": "ROUGE-1", "start_pos": 10, "end_pos": 17, "type": "METRIC", "confidence": 0.9948666095733643}, {"text": "ROUGE-2", "start_pos": 22, "end_pos": 29, "type": "METRIC", "confidence": 0.9958212375640869}, {"text": "DUC 2004 corpora", "start_pos": 70, "end_pos": 86, "type": "DATASET", "confidence": 0.972695012887319}]}]}