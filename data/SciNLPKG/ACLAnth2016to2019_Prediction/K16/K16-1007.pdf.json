{"title": [{"text": "Learning to Jointly Predict Ellipsis and Comparison Structures", "labels": [], "entities": [{"text": "Learning to Jointly Predict Ellipsis and Comparison Structures", "start_pos": 0, "end_pos": 62, "type": "TASK", "confidence": 0.6831550262868404}]}], "abstractContent": [{"text": "Domain-independent meaning representation of text has received a renewed interest in the NLP community.", "labels": [], "entities": [{"text": "Domain-independent meaning representation of text", "start_pos": 0, "end_pos": 49, "type": "TASK", "confidence": 0.7421661496162415}]}, {"text": "Comparison plays a crucial role in shaping objective and subjective opinion and measurement in natural language, and is often expressed in complex constructions including ellipsis.", "labels": [], "entities": []}, {"text": "In this paper, we introduce a novel framework for jointly capturing the semantic structure of comparison and ellipsis constructions.", "labels": [], "entities": []}, {"text": "Our framework models ellipsis and comparison as interconnected predicate-argument structures, which enables automatic ellipsis resolution.", "labels": [], "entities": [{"text": "ellipsis resolution", "start_pos": 118, "end_pos": 137, "type": "TASK", "confidence": 0.747742772102356}]}, {"text": "We show that a structured prediction model trained on our dataset of 2,800 gold annotated review sentences yields promising results.", "labels": [], "entities": []}, {"text": "Together with this paper we release the dataset and an annotation tool which enables two-stage expert annotation on top of tree structures.", "labels": [], "entities": []}], "introductionContent": [{"text": "Representing the underlying meaning of text has been a long-standing topic of interest in computational linguistics.", "labels": [], "entities": [{"text": "Representing the underlying meaning of text", "start_pos": 0, "end_pos": 43, "type": "TASK", "confidence": 0.899692972501119}]}, {"text": "Recently there has been a renewed interest in representation of meaning for various tasks such as semantic parsing, where the task is to map a natural language sentence into its corresponding formal meaning representation ().", "labels": [], "entities": [{"text": "semantic parsing", "start_pos": 98, "end_pos": 114, "type": "TASK", "confidence": 0.7337832599878311}]}, {"text": "Open-domain and broad-coverage semantic representation of text () is crucial for many language understanding tasks such as reading comprehension tests and question answering.", "labels": [], "entities": [{"text": "broad-coverage semantic representation of text", "start_pos": 16, "end_pos": 62, "type": "TASK", "confidence": 0.7508601188659668}, {"text": "language understanding", "start_pos": 86, "end_pos": 108, "type": "TASK", "confidence": 0.7330854535102844}, {"text": "question answering", "start_pos": 155, "end_pos": 173, "type": "TASK", "confidence": 0.863025426864624}]}, {"text": "With the rise of continuous-space models there is even more interest in capturing deeper generic semantics of text as opposed to surface word representations.", "labels": [], "entities": []}, {"text": "One of the most common ways for expressing evaluative sentiment towards different entities is using comparison.", "labels": [], "entities": []}, {"text": "A simple natural language example of comparison is Their pizza is the best.", "labels": [], "entities": []}, {"text": "Capturing the underlying meaning of comparison structures, as opposed to their surface wording, is required for accurate evaluation of qualities and quantities.", "labels": [], "entities": []}, {"text": "For instance, given a more complex comparison example, The pizza was great, but it was not as awesome as the sandwich, the state-ofthe-art sentiment analysis system) assigns an overall 'neutral' sentiment value, which clearly lacks deeper understanding of the comparison happening in the sentence.", "labels": [], "entities": []}, {"text": "Consider the generic meaning representation depicted in in according to frame semantic parsing 1 () for the following sentence: (1) My Mazda drove faster than his Hyundai.", "labels": [], "entities": [{"text": "frame semantic parsing", "start_pos": 72, "end_pos": 94, "type": "TASK", "confidence": 0.6506582597891489}]}, {"text": "It is evident that this meaning representation does not fully capture how the semantics of the adjective fast relates to the driving event, and what it actually means fora car to drive faster than another car.", "labels": [], "entities": []}, {"text": "More importantly, there is an ellipsis in this sentence, the resolution of which results incomplete understood reading of My Mazda drove faster than his Hyundai drove fast , which is in noway captured in  tures which can capture the mentioned phenomena can enable the development of computational semantic models which are suitable for various reasoning tasks.", "labels": [], "entities": []}, {"text": "In this paper we introduce a joint theoretical model for comprehensive semantic representation of the structure of comparison and ellipsis in natural language.", "labels": [], "entities": []}, {"text": "We jointly model comparison and ellipsis as inter-connected predicateargument structures, which enables automatic ellipsis resolution.", "labels": [], "entities": [{"text": "ellipsis resolution", "start_pos": 114, "end_pos": 133, "type": "TASK", "confidence": 0.7289795875549316}]}, {"text": "The main contributions of this paper can be summarized as follows: (1) introducing a novel framework for jointly representing the semantics of comparison and ellipsis on top of syntactic trees, (2) releasing a dataset of 2,800 expert annotated user review comparison instances , which significantly increases the size of the available resources on comparison structures in the community, (3) presenting anew structured prediction model for automatic extraction of semantic structures of comparison text together with ellipsis resolution, (4) releasing an interactive tool for tree-based human annotation of corpora, which can be helpful for many other annotation tasks in NLP.", "labels": [], "entities": []}, {"text": "To our knowledge, this paper presents the first comprehensive computational framework of its kind for ellipsis and comparison constructions.", "labels": [], "entities": [{"text": "comparison constructions", "start_pos": 115, "end_pos": 139, "type": "TASK", "confidence": 0.8692516386508942}]}, {"text": "Our semantic model can be incorporated as apart of any broad-coverage semantic parser ( for augmenting their meaning representation.", "labels": [], "entities": []}], "datasetContent": [{"text": "We divide our dataset into train and train-dev (70%), and test (30%) sets.", "labels": [], "entities": []}, {"text": "For evaluation of a given system prediction against the reference gold annotation, for each constituency node in the reference, we give the system a point in two ways:  (1) Exact: the label assigned to the node by the system exactly matches the gold label; (2) Head: the reference label matches the label of the headword of the node in system's prediction.", "labels": [], "entities": [{"text": "Exact", "start_pos": 173, "end_pos": 178, "type": "METRIC", "confidence": 0.945458173751831}, {"text": "Head", "start_pos": 261, "end_pos": 265, "type": "METRIC", "confidence": 0.9924182891845703}]}, {"text": "We report on Precision (P), Recall (R) and F1 score.", "labels": [], "entities": [{"text": "Precision (P)", "start_pos": 13, "end_pos": 26, "type": "METRIC", "confidence": 0.9624800980091095}, {"text": "Recall (R)", "start_pos": 28, "end_pos": 38, "type": "METRIC", "confidence": 0.970291331410408}, {"text": "F1 score", "start_pos": 43, "end_pos": 51, "type": "METRIC", "confidence": 0.9712807834148407}]}, {"text": "We test three models: our comprehensive ILP model (detailed in Section 5), our model without the ILP constraints, and a rule-based baseline.", "labels": [], "entities": []}, {"text": "The baseline encodes the same linguistically motivated ILP constraints via rules.", "labels": [], "entities": []}, {"text": "It further uses a few pattern extraction functions for pinpointing comparison morphemes which detect comparison and ellipsis predicates.", "labels": [], "entities": []}, {"text": "More details about the baseline can be found in the supplementary material.", "labels": [], "entities": [{"text": "baseline", "start_pos": 23, "end_pos": 31, "type": "METRIC", "confidence": 0.9808082580566406}]}, {"text": "The results on predicate prediction is shown in.", "labels": [], "entities": [{"text": "predicate prediction", "start_pos": 15, "end_pos": 35, "type": "TASK", "confidence": 0.9189538359642029}]}, {"text": "Given that our ILP constraints only encode argument structures, in this Table we only compare the baseline with our full ILP model.", "labels": [], "entities": []}, {"text": "As the results show, overall, the scores are high for predicting the predicates, with ellipsis predicates being the most challenging.", "labels": [], "entities": [{"text": "predicting the predicates", "start_pos": 54, "end_pos": 79, "type": "TASK", "confidence": 0.8670222957928976}]}, {"text": "The baseline has a near perfect prediction on Assetive and Superlative types, which shows that the linguistic patterns can capture these types well.", "labels": [], "entities": []}, {"text": "Our model performs the poorest on Equatives.", "labels": [], "entities": []}, {"text": "If we look at the specific cases it misses, it is often regarding the morpheme 'as', which takes part in many various linguistics constructions, many of which are not comparatives.", "labels": [], "entities": []}, {"text": "For example, for the test sentence We will let them manage our other investment properties as well as us getting older., our system wrongly classifies 'as' as an equative: Results of argument prediction on test set.", "labels": [], "entities": [{"text": "argument prediction", "start_pos": 183, "end_pos": 202, "type": "TASK", "confidence": 0.7430546879768372}]}, {"text": "The average for the models only takes into account non-zero results.", "labels": [], "entities": []}, {"text": "predicate, which is clearly an ambiguous and challenging test sentence.", "labels": [], "entities": [{"text": "predicate", "start_pos": 0, "end_pos": 9, "type": "METRIC", "confidence": 0.862945020198822}]}, {"text": "Analysis shows that the errors are often due to inaccuracies in automatically generated parse trees, e.g., challenging long sentences (average length > 12 tokens) with informal language which are generally hard to parse.", "labels": [], "entities": []}, {"text": "The task of predicting arguments is a more demanding task.", "labels": [], "entities": [{"text": "predicting arguments", "start_pos": 12, "end_pos": 32, "type": "TASK", "confidence": 0.9232939183712006}]}, {"text": "As you can see in, the baseline model often fails at predicting the arguments.", "labels": [], "entities": []}, {"text": "Our comprehensive ILP model consistently outperforms the No Constraints model, showing the effectiveness of our linguistically motivated ILP constraints.", "labels": [], "entities": []}, {"text": "Our ILP model performs the best on Scale and Domain argument types, which is partly due to the frequency of these types in our dataset.", "labels": [], "entities": []}, {"text": "We are planning on annotating more data to improve the argument prediction in future.", "labels": [], "entities": [{"text": "argument prediction", "start_pos": 55, "end_pos": 74, "type": "TASK", "confidence": 0.8049051463603973}]}], "tableCaptions": [{"text": " Table 2: The percentage of each argument type.", "labels": [], "entities": []}, {"text": " Table 3: Predicate prediction results on test set.  Each cell contains scores according to Exact/Head  measurement.", "labels": [], "entities": [{"text": "Predicate", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9302189946174622}, {"text": "Exact/Head  measurement", "start_pos": 92, "end_pos": 115, "type": "METRIC", "confidence": 0.7709003835916519}]}, {"text": " Table 4: Results of argument prediction on test set. The average for the models only takes into account  non-zero results.", "labels": [], "entities": [{"text": "argument prediction", "start_pos": 21, "end_pos": 40, "type": "TASK", "confidence": 0.7485457956790924}]}]}