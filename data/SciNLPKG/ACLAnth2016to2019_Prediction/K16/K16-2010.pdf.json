{"title": [{"text": "Shallow Discourse Parsing Using Convolutional Neural Network", "labels": [], "entities": []}], "abstractContent": [{"text": "This paper describes a discourse parsing system for our participation in the CoNLL 2016 Shared Task.", "labels": [], "entities": [{"text": "discourse parsing", "start_pos": 23, "end_pos": 40, "type": "TASK", "confidence": 0.6987749934196472}, {"text": "CoNLL 2016 Shared Task", "start_pos": 77, "end_pos": 99, "type": "DATASET", "confidence": 0.8305571973323822}]}, {"text": "We focus on the supplementary task: Sense Classification, especially the Non-Explicit one which is the bottleneck of discourse parsing system.", "labels": [], "entities": [{"text": "Sense Classification", "start_pos": 36, "end_pos": 56, "type": "TASK", "confidence": 0.6982276737689972}, {"text": "discourse parsing", "start_pos": 117, "end_pos": 134, "type": "TASK", "confidence": 0.711744487285614}]}, {"text": "To improve Non-Explicit sense classification , we propose a Convolutional Neural Network (CNN) model to determine the senses for both English and Chinese tasks.", "labels": [], "entities": [{"text": "Non-Explicit sense classification", "start_pos": 11, "end_pos": 44, "type": "TASK", "confidence": 0.6187261839707693}]}, {"text": "We also explore a traditional linear model with novel dependency features for Explicit sense classification.", "labels": [], "entities": [{"text": "Explicit sense classification", "start_pos": 78, "end_pos": 107, "type": "TASK", "confidence": 0.813169260819753}]}, {"text": "Compared with the best system in CoNLL-2015, our system achieves competitive performances.", "labels": [], "entities": [{"text": "CoNLL-2015", "start_pos": 33, "end_pos": 43, "type": "DATASET", "confidence": 0.9023678302764893}]}, {"text": "Moreover, as shown in the results, our system has higher F1 score on Non-Explicit sense classification.", "labels": [], "entities": [{"text": "F1 score", "start_pos": 57, "end_pos": 65, "type": "METRIC", "confidence": 0.9789165556430817}, {"text": "Non-Explicit sense classification", "start_pos": 69, "end_pos": 102, "type": "TASK", "confidence": 0.6097578903039297}]}], "introductionContent": [{"text": "This paper presents the Shanghai Jiao Tong University discourse parsing system for the) on Shallow Discourse Parsing and the supplementary tasks of sense classification for English and Chinese.", "labels": [], "entities": [{"text": "Shanghai Jiao Tong University discourse parsing", "start_pos": 24, "end_pos": 71, "type": "TASK", "confidence": 0.8787504335244497}, {"text": "Shallow Discourse Parsing", "start_pos": 91, "end_pos": 116, "type": "TASK", "confidence": 0.5942042072614034}, {"text": "sense classification", "start_pos": 148, "end_pos": 168, "type": "TASK", "confidence": 0.7447957396507263}]}, {"text": "As shown by the results of the same task in CoNLL 2015 (, sense classification has been found more difficult than other subtasks, especially determining Non-Explicit senses which is the bottleneck of the end-to-end discourse parsing system.", "labels": [], "entities": [{"text": "CoNLL 2015", "start_pos": 44, "end_pos": 54, "type": "DATASET", "confidence": 0.9093025624752045}, {"text": "sense classification", "start_pos": 58, "end_pos": 78, "type": "TASK", "confidence": 0.7539305984973907}, {"text": "discourse parsing", "start_pos": 215, "end_pos": 232, "type": "TASK", "confidence": 0.7284754514694214}]}, {"text": "Without the discourse connectives which provide strong indications, the NonExplicit relations between adjacent sentences are difficult to figure out.", "labels": [], "entities": []}, {"text": "Therefore, our primary work is to improve sense classification components, especially on Non-Explicit relations.", "labels": [], "entities": [{"text": "sense classification", "start_pos": 42, "end_pos": 62, "type": "TASK", "confidence": 0.7831750214099884}]}, {"text": "For other components such as connectives detection and arguments extraction, we just follow the top ranked system () in CoNLL-2015, which is as the baseline system in this paper.", "labels": [], "entities": [{"text": "connectives detection", "start_pos": 29, "end_pos": 50, "type": "TASK", "confidence": 0.8870511651039124}, {"text": "arguments extraction", "start_pos": 55, "end_pos": 75, "type": "TASK", "confidence": 0.7490904629230499}, {"text": "CoNLL-2015", "start_pos": 120, "end_pos": 130, "type": "DATASET", "confidence": 0.9236245155334473}]}, {"text": "In CoNLL-2015, various approaches were explored to conquer the sense classification problem, which is a straightforward multi-category classification task (;.", "labels": [], "entities": [{"text": "CoNLL-2015", "start_pos": 3, "end_pos": 13, "type": "DATASET", "confidence": 0.8990682363510132}, {"text": "sense classification problem", "start_pos": 63, "end_pos": 91, "type": "TASK", "confidence": 0.8075945178667704}, {"text": "multi-category classification task", "start_pos": 120, "end_pos": 154, "type": "TASK", "confidence": 0.794319748878479}]}, {"text": "Typical data-driven machine learning methods, like Maximum Entropy and Support Vector Machine, were adopted.", "labels": [], "entities": []}, {"text": "Some of them selected lexical and syntactic features over the arguments, including linguistically motivated word groupings such as Levin verb classes and polarity tags.", "labels": [], "entities": []}, {"text": "Brown cluster features, surface features and entity semantics were also effective to enhance sense classification.", "labels": [], "entities": [{"text": "sense classification", "start_pos": 93, "end_pos": 113, "type": "TASK", "confidence": 0.72784124314785}]}, {"text": "Additionally, paragraph embeddings were also used to determine the senses (.", "labels": [], "entities": []}, {"text": "In other previous work of implicit sense classification, used word-pair features for predicting missing connectives, attempted to insert discourse connectives between arguments with the use of a language model, applied various feature selection methods.", "labels": [], "entities": [{"text": "implicit sense classification", "start_pos": 26, "end_pos": 55, "type": "TASK", "confidence": 0.8087445298830668}]}, {"text": "Although traditional methods have performed well on semantic tasks through feature engineering (, they still suffer from data sparsity problems.", "labels": [], "entities": []}, {"text": "Recently, Neural Network (NN) methods have shown competitive or even better performance than traditional linear models with hand-crafted sparse features for some Nature Language Process (NLP) tasks (, such as sentence modeling ().", "labels": [], "entities": [{"text": "sentence modeling", "start_pos": 209, "end_pos": 226, "type": "TASK", "confidence": 0.7545777261257172}]}, {"text": "In Non-Explicit sense classification, due to the absence of discourse connectives, the task is exactly to classify a sentence pair, where CNN could be utilized.", "labels": [], "entities": [{"text": "Non-Explicit sense classification", "start_pos": 3, "end_pos": 36, "type": "TASK", "confidence": 0.673646092414856}]}, {"text": "For Explicit sense classification which has strong discourse relation information provided by the connectives, we will use traditional linear methods with novel dependency features.", "labels": [], "entities": [{"text": "Explicit sense classification", "start_pos": 4, "end_pos": 33, "type": "TASK", "confidence": 0.8158291180928549}]}, {"text": "The rest of the paper is organized as follows: Section 2 briefly describes our system, Section 3 introduces the CNN model for modeling sentence pairs, Section 4 discusses our main works including Explicit sense classification and Non-Explicit sense classification, Section 5 shows our experiments on sense classification and Section 6 reports our results on the final official evaluation.", "labels": [], "entities": [{"text": "Explicit sense classification", "start_pos": 196, "end_pos": 225, "type": "TASK", "confidence": 0.5814558565616608}, {"text": "Non-Explicit sense classification", "start_pos": 230, "end_pos": 263, "type": "TASK", "confidence": 0.6747501393159231}, {"text": "sense classification", "start_pos": 300, "end_pos": 320, "type": "TASK", "confidence": 0.7852098941802979}]}, {"text": "Section 7 concludes this paper.", "labels": [], "entities": []}], "datasetContent": [{"text": "Our system is trained on the PDTB 2.0 corpus.", "labels": [], "entities": [{"text": "PDTB 2.0 corpus", "start_pos": 29, "end_pos": 44, "type": "DATASET", "confidence": 0.9364442825317383}]}, {"text": "Sections 02-21 are used as training set, and Section 22 as the development set.", "labels": [], "entities": []}, {"text": "There are two tests: Results of the Shallow Discourse Parsing task on English Blind test set.", "labels": [], "entities": [{"text": "Shallow Discourse Parsing task", "start_pos": 36, "end_pos": 66, "type": "TASK", "confidence": 0.7251672297716141}, {"text": "English Blind test set", "start_pos": 70, "end_pos": 92, "type": "DATASET", "confidence": 0.9866990447044373}]}, {"text": "sets for the shared task: Section 23 of the PDTB, and a blind test prepared especially for this task.", "labels": [], "entities": [{"text": "Section 23 of the PDTB", "start_pos": 26, "end_pos": 48, "type": "DATASET", "confidence": 0.7077176809310913}]}, {"text": "We participate in the closed track, so only two resources (Brown Clusters and MPQA Subjectivity Lexicon) are used.", "labels": [], "entities": [{"text": "Brown Clusters", "start_pos": 59, "end_pos": 73, "type": "DATASET", "confidence": 0.9612088799476624}, {"text": "MPQA Subjectivity Lexicon", "start_pos": 78, "end_pos": 103, "type": "DATASET", "confidence": 0.8409717281659445}]}, {"text": "test platform of CoNLL-2016 still adopts still the TIRA evaluation platform).", "labels": [], "entities": [{"text": "CoNLL-2016", "start_pos": 17, "end_pos": 27, "type": "DATASET", "confidence": 0.8941515684127808}, {"text": "TIRA", "start_pos": 51, "end_pos": 55, "type": "METRIC", "confidence": 0.6397660374641418}]}, {"text": "Non-Explicit relations contains three types: Implicit, EntRel and AltLex.", "labels": [], "entities": []}, {"text": "Originally EntRel is not treated as discourse relation in Penn Discourse TreeBank (PDTB) (, but this category has been included in this task and we also count it as one sense.", "labels": [], "entities": [{"text": "Penn Discourse TreeBank (PDTB)", "start_pos": 58, "end_pos": 88, "type": "DATASET", "confidence": 0.9500866929690043}]}, {"text": "Some instances are annotated with two senses, so the predicted sense fora relation must match one of the two senses if there is more than one sense.", "labels": [], "entities": []}, {"text": "We compare with the best system in the competition of CoNLL 2015 (, which is regarded as the baseline.", "labels": [], "entities": [{"text": "CoNLL 2015", "start_pos": 54, "end_pos": 64, "type": "DATASET", "confidence": 0.9371151328086853}]}, {"text": "reports our results of the Explicit sense classifier on both English and Chinese development sets.", "labels": [], "entities": [{"text": "Explicit sense classifier", "start_pos": 27, "end_pos": 52, "type": "TASK", "confidence": 0.4911412099997203}]}, {"text": "Compared with the baseline, our methods obtain progress and the overall F1 score of Explicit Sense classification increases by 1.97% for English task.", "labels": [], "entities": [{"text": "F1 score", "start_pos": 72, "end_pos": 80, "type": "METRIC", "confidence": 0.9890028834342957}, {"text": "Explicit Sense classification", "start_pos": 84, "end_pos": 113, "type": "TASK", "confidence": 0.5952368776003519}]}], "tableCaptions": [{"text": " Table 1: Explicit Sense Classification on English  and Chinese development sets without error prop- agation.", "labels": [], "entities": []}, {"text": " Table 2: Non-Explicit Sense Classification on En- glish and Chinese development sets without error  propagation.", "labels": [], "entities": []}, {"text": " Table 3: F 1 scores (%) with different CNN filter  sizes for Non-Explicit on original arguments on  development set.", "labels": [], "entities": [{"text": "F 1 scores", "start_pos": 10, "end_pos": 20, "type": "METRIC", "confidence": 0.9758819937705994}]}, {"text": " Table 4: F 1 scores (%) with different CNN filter  sizes for Explicit on refined arguments on devel- opment set.", "labels": [], "entities": [{"text": "F 1", "start_pos": 10, "end_pos": 13, "type": "METRIC", "confidence": 0.9848757684230804}]}, {"text": " Table 5: Results of the Shallow Discourse Parsing task on English WSJ test set.", "labels": [], "entities": [{"text": "Shallow Discourse Parsing task", "start_pos": 25, "end_pos": 55, "type": "TASK", "confidence": 0.7521795183420181}, {"text": "English WSJ test set", "start_pos": 59, "end_pos": 79, "type": "DATASET", "confidence": 0.9331327080726624}]}, {"text": " Table 6: Results of the Shallow Discourse Parsing task on English Blind test set.", "labels": [], "entities": [{"text": "Shallow Discourse Parsing task", "start_pos": 25, "end_pos": 55, "type": "TASK", "confidence": 0.7406501471996307}, {"text": "English Blind test set", "start_pos": 59, "end_pos": 81, "type": "DATASET", "confidence": 0.9901118278503418}]}, {"text": " Table 7: Results of the supplementary task on English and Chinese.", "labels": [], "entities": []}]}