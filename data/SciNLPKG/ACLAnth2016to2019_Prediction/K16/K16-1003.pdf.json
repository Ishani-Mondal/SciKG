{"title": [{"text": "Identifying Temporality of Word Senses Based on Minimum Cuts", "labels": [], "entities": [{"text": "Identifying Temporality of Word Senses", "start_pos": 0, "end_pos": 38, "type": "TASK", "confidence": 0.8862526178359985}]}], "abstractContent": [{"text": "The ability to capture time information is essential to many natural language processing and information retrieval applications.", "labels": [], "entities": [{"text": "information retrieval", "start_pos": 93, "end_pos": 114, "type": "TASK", "confidence": 0.678313136100769}]}, {"text": "Therefore, a lexical resource associating word senses to their temporal orientation might be crucial for the computational tasks aiming at the interpretation of language of time in texts.", "labels": [], "entities": [{"text": "interpretation of language of time in texts", "start_pos": 143, "end_pos": 186, "type": "TASK", "confidence": 0.7965521556990487}]}, {"text": "In this paper, we propose a semi-supervised minimum cuts strategy that makes use of WordNet glosses and semantic relations to supplement WordNet entries with temporal information.", "labels": [], "entities": []}, {"text": "Intrinsic and extrinsic evaluations show that our approach outperforms prior semi-supervised non-graph classifiers.", "labels": [], "entities": []}], "introductionContent": [{"text": "Recognizing temporal information can significantly improve the functionality of information retrieval () and natural language processing () applications.", "labels": [], "entities": [{"text": "information retrieval", "start_pos": 80, "end_pos": 101, "type": "TASK", "confidence": 0.7464000284671783}]}, {"text": "Most text applications have been relying on rule-based time taggers such as HeidelTime or SUTime () to identify and normalize time mentions in texts.", "labels": [], "entities": [{"text": "HeidelTime", "start_pos": 76, "end_pos": 86, "type": "DATASET", "confidence": 0.9234044551849365}]}, {"text": "Although interesting levels of performance have been seen), their coverage is limited to the finite number of rules they implement.", "labels": [], "entities": [{"text": "coverage", "start_pos": 66, "end_pos": 74, "type": "METRIC", "confidence": 0.8623364567756653}]}, {"text": "Let's take the following sentence: \"Apple's iPhone is currently one of the most popular smartphone\".", "labels": [], "entities": []}, {"text": "When labeled by SUTime or HeidelTime 2 , the adverb currently is correctly tagged with the PRESENT_REF value.", "labels": [], "entities": [{"text": "PRESENT_REF value", "start_pos": 91, "end_pos": 108, "type": "METRIC", "confidence": 0.6999341398477554}]}, {"text": "However, if we change the sentence to \"Apple's iPhone is one of the most popular smartphones at the present day\", no temporal mention is found, although one may expect that within this context currently and present day share some equivalent temporal dimension.", "labels": [], "entities": []}, {"text": "Such systems would certainly benefit from the existence of a temporal resource enumerating a large set of possible time variants.", "labels": [], "entities": []}, {"text": "In parallel, new trends have emerged in the context of human temporal orientation (.", "labels": [], "entities": [{"text": "human temporal orientation", "start_pos": 55, "end_pos": 81, "type": "TASK", "confidence": 0.6365527808666229}]}, {"text": "The underlying idea is to understand how past, present, and future emphasis in text may affect people's finances, health, and happiness.", "labels": [], "entities": []}, {"text": "For that purpose, temporal classifiers are built to detect the overall temporal dimension of a given sentence.", "labels": [], "entities": []}, {"text": "For instance, the following Facebook post \"can't wait to get a pint tonight\" would be tagged as FUTURE.", "labels": [], "entities": [{"text": "FUTURE", "start_pos": 96, "end_pos": 102, "type": "METRIC", "confidence": 0.8626968264579773}]}, {"text": "Successful features include timexes, specific temporal (past, present, future) words from a commercial dictionary, but also ngrams, thus indicating that temporality maybe embodied by multi-word terms, whose temporal orientation is unknown.", "labels": [], "entities": []}, {"text": "As a consequence, discovering the temporal orientation of words is a challenging issue that may benefit many text applications.", "labels": [], "entities": [{"text": "discovering the temporal orientation of words", "start_pos": 18, "end_pos": 63, "type": "TASK", "confidence": 0.7745837271213531}]}, {"text": "Whereas most prior studies have focused on temporal expressions and events, there has been alack of work looking at the temporal orientation of word senses.", "labels": [], "entities": []}, {"text": "In this paper, we focus on automatically timetagging word senses in WordNet as past, present, future, or atemporal based on their glosses and relational semantic structures in the line of  and.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 68, "end_pos": 75, "type": "DATASET", "confidence": 0.9405720829963684}]}, {"text": "In particular, we propose a semi-supervised graph-based strategy that relies on the max-flow min-cut theorem (, that finds successive minimum cuts in a connected graph to time-tag each synset as one of the four 22 dimensions.", "labels": [], "entities": []}, {"text": "Compared to previous work based on propagation strategies (, the exploration of WordNet's graph structure with minimum cuts allows us to independently model both temporal connotation and semantic denotation.", "labels": [], "entities": []}, {"text": "In order to evaluate our proposal, both intrinsic (inter-annotator agreement and temporal sense classification) and extrinsic (temporal sentence classification and temporal relation annotation) evaluations have been performed.", "labels": [], "entities": [{"text": "temporal sense classification", "start_pos": 81, "end_pos": 110, "type": "TASK", "confidence": 0.7275609771410624}, {"text": "temporal sentence classification", "start_pos": 127, "end_pos": 159, "type": "TASK", "confidence": 0.7090981801350912}]}, {"text": "In both cases, the proposed methodology outperformed state-of-the-art approaches., an extension of WordNet, where each synset is augmented with its temporal connotation (past, present, future, or atemporal).", "labels": [], "entities": [{"text": "WordNet", "start_pos": 99, "end_pos": 106, "type": "DATASET", "confidence": 0.9204978942871094}]}, {"text": "It mainly relies on the quantitative analysis of the glosses associated to synsets, and on the use of the resulting vector space model representations for semisupervised synset classification.", "labels": [], "entities": [{"text": "synset classification", "start_pos": 170, "end_pos": 191, "type": "TASK", "confidence": 0.7421815395355225}]}, {"text": "In particular, temporal classifiers are learned over manually labeled synsets (seed list), and new learning synsets are chosen based on their specific semantic relation (e.g. hyponymy) with synsets from the seed list.", "labels": [], "entities": []}, {"text": "Their class is given by the synset they have been propagated from.", "labels": [], "entities": []}, {"text": "This process is iterated until cross-validation accuracy drops.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 48, "end_pos": 56, "type": "METRIC", "confidence": 0.9927349090576172}]}, {"text": "The final classifier is used to time-tag all WordNet synsets.", "labels": [], "entities": [{"text": "WordNet synsets", "start_pos": 45, "end_pos": 60, "type": "DATASET", "confidence": 0.9232094883918762}]}], "datasetContent": [{"text": "We used a list that consists of 632 temporal synsets and an equal number of atemporal synsets provided by  as labeled data for our experiments.", "labels": [], "entities": []}, {"text": "Temporal synsets are distributed as follows: 210 synsets marked as past, 291 as present, and 131 as future.", "labels": [], "entities": []}, {"text": "As the labeled dataset is small, we created an annotation task using the CrowdFlower platform 8 in order to produce a testset.", "labels": [], "entities": [{"text": "CrowdFlower platform 8", "start_pos": 73, "end_pos": 95, "type": "DATASET", "confidence": 0.9121189514795939}]}, {"text": "For the annotation task, 398 synsets equally distributed over nouns, verbs, adjectives, and adverbs along with their lemmas and glosses were randomly selected from WordNet 9 as representative of the whole WordNet.", "labels": [], "entities": [{"text": "WordNet 9", "start_pos": 164, "end_pos": 173, "type": "DATASET", "confidence": 0.9273239374160767}, {"text": "WordNet", "start_pos": 205, "end_pos": 212, "type": "DATASET", "confidence": 0.9810406565666199}]}, {"text": "Note that this number is a statistically significant representative sample of all WordNet synsets calculated as defined in.", "labels": [], "entities": []}, {"text": "The annotators were expected to answer two questions fora given synset (lemmas and gloss were also provided).", "labels": [], "entities": []}, {"text": "While the first question is related to the decision as to whether a synset is temporal or atemporal, the motivation behind the second question is to collect a more fine-grained (past, present, future) gold-standard.", "labels": [], "entities": []}, {"text": "The reliability of the annotators was evaluated on 60 control synsets from the labeled dataset, and 10 ambiguous synsets associated to more than one temporal dimension.", "labels": [], "entities": []}, {"text": "Similary to, raters who scored at least 70% accuracy on average on both sets were considered to be reliable.", "labels": [], "entities": [{"text": "raters", "start_pos": 13, "end_pos": 19, "type": "METRIC", "confidence": 0.951614260673523}, {"text": "accuracy", "start_pos": 44, "end_pos": 52, "type": "METRIC", "confidence": 0.9993682503700256}]}, {"text": "Finally, each synset was annotated by at least 10 reliable raters.", "labels": [], "entities": []}, {"text": "To have a concrete idea about the agreement between annotators, we calculated the majority class for each synset in our dataset.", "labels": [], "entities": []}, {"text": "A synset belongs to a majority class k if the most frequent annotation for the synset was selected by at least k annotators.", "labels": [], "entities": []}, {"text": "As a consequence, a large percentage of synsets belonging to high majority classes are symptomatic of good inter-annotator agreement.", "labels": [], "entities": []}, {"text": "Similarly to, we consider all annotations with a majority class greater than 5 as reliable.", "labels": [], "entities": []}, {"text": "In this case, for the temporal vs. atemporal annotation scheme, 84.83% of the synsets were annotated identically by the majority of annotators, while for past, present, and future, 72.36% of the annotations fell into this case.", "labels": [], "entities": []}, {"text": "As such, we can be confident that the annotation process was successful and the dataset is reliable.", "labels": [], "entities": []}, {"text": "Different intrinsic and extrinsic evaluations have been proposed in prior studies.", "labels": [], "entities": []}, {"text": "We compare our work to the same tasks as proposed by  and, and introduce an extra experiment on temporal relation annotation.", "labels": [], "entities": [{"text": "temporal relation annotation", "start_pos": 96, "end_pos": 124, "type": "TASK", "confidence": 0.5976201395193735}]}], "tableCaptions": [{"text": " Table 1: SVM results for individual scores.", "labels": [], "entities": []}, {"text": " Table 2: Association scores with DiffWt Method.", "labels": [], "entities": [{"text": "Association", "start_pos": 10, "end_pos": 21, "type": "METRIC", "confidence": 0.9502800703048706}]}, {"text": " Table 3: Percentage of synsets in each majority class.", "labels": [], "entities": []}, {"text": " Table 5: Accuracy for temporal vs. atemporal and past, present, future classifications using different  methods measured over test data. Results are broken down by precision (p), recall (r), and f1-measure  (f1) scores.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9914865493774414}, {"text": "precision (p)", "start_pos": 165, "end_pos": 178, "type": "METRIC", "confidence": 0.9476950019598007}, {"text": "recall (r)", "start_pos": 180, "end_pos": 190, "type": "METRIC", "confidence": 0.9500225782394409}, {"text": "f1-measure  (f1) scores", "start_pos": 196, "end_pos": 219, "type": "METRIC", "confidence": 0.8739620327949524}]}, {"text": " Table 6: Accuracy results with different sizes of  labeled data for temporal vs. atemporal classifica- tion.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9970209002494812}]}, {"text": " Table 7: Results for temporal sentence and tweet classification performed on 10-fold cross validation  with SVM with Weka default parameters.", "labels": [], "entities": [{"text": "temporal sentence and tweet classification", "start_pos": 22, "end_pos": 64, "type": "TASK", "confidence": 0.5500199854373932}]}, {"text": " Table 8: Temporal relation classification results.", "labels": [], "entities": [{"text": "Temporal relation classification", "start_pos": 10, "end_pos": 42, "type": "TASK", "confidence": 0.9619239966074625}]}, {"text": " Table 9: Feature ablation analysis. The most fre- quent class baseline (mfc).", "labels": [], "entities": [{"text": "Feature ablation analysis", "start_pos": 10, "end_pos": 35, "type": "TASK", "confidence": 0.6159497002760569}]}, {"text": " Table 9. Results clearly show the im- portance of the features based on the temporal lex- icon, being the second best-performing feature set.  As a consequence, we may conclude that improve- ments in temporal analysis may be obtained by the  correct use of some temporal lexical resource.", "labels": [], "entities": []}]}