{"title": [{"text": "An End-to-End Chinese Discourse Parser with Adaptation to Explicit and Non-explicit Relation Recognition", "labels": [], "entities": [{"text": "Explicit and Non-explicit Relation Recognition", "start_pos": 58, "end_pos": 104, "type": "TASK", "confidence": 0.7081855177879334}]}], "abstractContent": [{"text": "This paper describes our end-to-end discourse parser in the CoNLL-2016 Shared Task on Chinese Shallow Discourse Parsing.", "labels": [], "entities": [{"text": "CoNLL-2016 Shared Task on Chinese Shallow Discourse Parsing", "start_pos": 60, "end_pos": 119, "type": "TASK", "confidence": 0.7776752561330795}]}, {"text": "To adapt to the characteristics of Chi-nese, we implement a uniform framework for both explicit and non-explicit relation parsing.", "labels": [], "entities": [{"text": "relation parsing", "start_pos": 113, "end_pos": 129, "type": "TASK", "confidence": 0.7256706655025482}]}, {"text": "In this framework, we are the first to utilize a seed-expansion approach for the argument extraction subtask.", "labels": [], "entities": [{"text": "argument extraction subtask", "start_pos": 81, "end_pos": 108, "type": "TASK", "confidence": 0.7784162958463033}]}, {"text": "In the official evaluation, our system achieves an F1 score of 26.90% in overall performance on the blind test set.", "labels": [], "entities": [{"text": "F1 score", "start_pos": 51, "end_pos": 59, "type": "METRIC", "confidence": 0.9893614947795868}]}], "introductionContent": [{"text": "Discourse parser analyzes the relations underlying text units to uncover abstractive structure information, which has a wide usage in different tasks in natural language processing, such as text summarization, question answering, information extraction and machine translation.", "labels": [], "entities": [{"text": "Discourse parser", "start_pos": 0, "end_pos": 16, "type": "TASK", "confidence": 0.7016347348690033}, {"text": "text summarization", "start_pos": 190, "end_pos": 208, "type": "TASK", "confidence": 0.721189558506012}, {"text": "question answering", "start_pos": 210, "end_pos": 228, "type": "TASK", "confidence": 0.8912051022052765}, {"text": "information extraction", "start_pos": 230, "end_pos": 252, "type": "TASK", "confidence": 0.8274650573730469}, {"text": "machine translation", "start_pos": 257, "end_pos": 276, "type": "TASK", "confidence": 0.7935985922813416}]}, {"text": "Since the release of the Penn Discourse TreeBank (PDTB) (, discourse parsing has drawn more and more attention.", "labels": [], "entities": [{"text": "Penn Discourse TreeBank (PDTB)", "start_pos": 25, "end_pos": 55, "type": "DATASET", "confidence": 0.9462493658065796}, {"text": "discourse parsing", "start_pos": 59, "end_pos": 76, "type": "TASK", "confidence": 0.7373422384262085}]}, {"text": "The PDTB-style parser puts emphasis on shallow discourse parsing, which annotates apiece of text with a set of discourse relations.", "labels": [], "entities": [{"text": "shallow discourse parsing", "start_pos": 39, "end_pos": 64, "type": "TASK", "confidence": 0.7054892579714457}]}, {"text": "The relations are divided into two types, explicit or non-explicit, depending on whether connectives exist or not.", "labels": [], "entities": []}, {"text": "A complete discourse relation contains two discourse units called Argument1 (Arg1) and Argument2 (Arg2).", "labels": [], "entities": [{"text": "Argument2 (Arg2)", "start_pos": 87, "end_pos": 103, "type": "METRIC", "confidence": 0.8676082044839859}]}, {"text": "An end-to-end parser usually consists of some components, such as discourse connective identification, argument extraction, explicit sense classification and implicit sense classification.", "labels": [], "entities": [{"text": "discourse connective identification", "start_pos": 66, "end_pos": 101, "type": "TASK", "confidence": 0.6558326184749603}, {"text": "argument extraction", "start_pos": 103, "end_pos": 122, "type": "TASK", "confidence": 0.7371366620063782}, {"text": "explicit sense classification", "start_pos": 124, "end_pos": 153, "type": "TASK", "confidence": 0.6500646869341532}, {"text": "implicit sense classification", "start_pos": 158, "end_pos": 187, "type": "TASK", "confidence": 0.6231510837872823}]}, {"text": "Pitler and used syntactic features to disambiguate explicit discourse connectives.", "labels": [], "entities": []}, {"text": "For argument extraction, used a tree subtraction algorithm to extract arguments and proposed a constituent-based approach to solve it.", "labels": [], "entities": [{"text": "argument extraction", "start_pos": 4, "end_pos": 23, "type": "TASK", "confidence": 0.8142493069171906}]}, {"text": "Recent researches mainly focus on the implicit sense classification.", "labels": [], "entities": [{"text": "implicit sense classification", "start_pos": 38, "end_pos": 67, "type": "TASK", "confidence": 0.6038928230603536}]}, {"text": "In this subtask, and explored rich features such as word-pairs, dependency rules, production rules and Brown cluster pairs.", "labels": [], "entities": []}, {"text": "Some studies () paid attention to the data expansion.", "labels": [], "entities": []}, {"text": "Neural network approaches ( were also applied to improve the classification performance.", "labels": [], "entities": []}, {"text": "implemented a full endto-end PDTB parser and built a more refined system in the In contrast to English, there are limited studies on Chinese discourse parsing (.", "labels": [], "entities": [{"text": "PDTB parser", "start_pos": 29, "end_pos": 40, "type": "TASK", "confidence": 0.5624825060367584}, {"text": "Chinese discourse parsing", "start_pos": 133, "end_pos": 158, "type": "TASK", "confidence": 0.5852293074131012}]}, {"text": "One of the main reasons is the shortage of Chinese discourse corpus.", "labels": [], "entities": []}, {"text": "annotated a PDTBstyle Chinese Discourse TreeBank (CDTB), which is the data for Chinese shallow discourse parsing.", "labels": [], "entities": [{"text": "PDTBstyle Chinese Discourse TreeBank (CDTB)", "start_pos": 12, "end_pos": 55, "type": "DATASET", "confidence": 0.772712379693985}, {"text": "Chinese shallow discourse parsing", "start_pos": 79, "end_pos": 112, "type": "TASK", "confidence": 0.6602278724312782}]}, {"text": "In this paper, we describe our approaches to implement the Chinese shallow discourse parser which is participated in the.", "labels": [], "entities": [{"text": "Chinese shallow discourse parser", "start_pos": 59, "end_pos": 91, "type": "TASK", "confidence": 0.5932323709130287}]}, {"text": "In view of some typical characteristics in CDTB (Section 2), we adopt and extend the state-of-the-art English parser in.", "labels": [], "entities": []}, {"text": "A unified framework for both explicit and non-explicit parsing is built and a seed-expansion approach is utilized for argument extraction.", "labels": [], "entities": [{"text": "argument extraction", "start_pos": 118, "end_pos": 137, "type": "TASK", "confidence": 0.7727189064025879}]}, {"text": "Some useful features are selected to train classifiers (Section 3).", "labels": [], "entities": []}, {"text": "Our system achieves 40.89% and 26.90% in F1-measure on the test and blind data set respectively (Section 4).", "labels": [], "entities": [{"text": "F1-measure", "start_pos": 41, "end_pos": 51, "type": "METRIC", "confidence": 0.9995556473731995}, {"text": "blind data set", "start_pos": 68, "end_pos": 82, "type": "DATASET", "confidence": 0.7881331841150919}]}, {"text": "We make the following main contributions in this work: \u2022 We implement a complete end-to-end PDTBstyle discourse parser for Chinese.", "labels": [], "entities": [{"text": "PDTBstyle discourse parser", "start_pos": 92, "end_pos": 118, "type": "TASK", "confidence": 0.6577142675717672}]}, {"text": "\u2022 We design a uniform framework to recog-27 nize both explicit and non-explicit relations together.", "labels": [], "entities": []}, {"text": "\u2022 We utilize an effective seed-expansion approach to determine the exact span boundaries in the argument extraction subtask.", "labels": [], "entities": []}], "datasetContent": [{"text": "Our end-to-end parser consists of 4 subtasks and 17 classifiers, trained on the corpora provided in the CoNLL-2016 Shared Task.", "labels": [], "entities": [{"text": "CoNLL-2016 Shared Task", "start_pos": 104, "end_pos": 126, "type": "DATASET", "confidence": 0.8085111975669861}]}, {"text": "All of the models are trained using the maximum entropy algorithm implemented in MALLET toolkit 3 . The system was evaluated on the TIRA evaluation platform) on 3 data sets offered by CoNLL-2016: development set, test set and blind test set.", "labels": [], "entities": [{"text": "TIRA evaluation platform", "start_pos": 132, "end_pos": 156, "type": "DATASET", "confidence": 0.7841117183367411}, {"text": "CoNLL-2016", "start_pos": 184, "end_pos": 194, "type": "DATASET", "confidence": 0.9138051867485046}]}, {"text": "reported the official results of our parser.: The official subtasks and overall F1-measures of the parser on the development, test and blind test sets for explicit, non-explicit and all relations.", "labels": [], "entities": [{"text": "F1-measures", "start_pos": 80, "end_pos": 91, "type": "METRIC", "confidence": 0.9975484013557434}]}], "tableCaptions": [{"text": " Table 1: The official subtasks and overall F1- measures of the parser on the development, test  and blind test sets for explicit, non-explicit and all  relations.", "labels": [], "entities": [{"text": "F1- measures", "start_pos": 44, "end_pos": 56, "type": "METRIC", "confidence": 0.9826720754305521}]}]}