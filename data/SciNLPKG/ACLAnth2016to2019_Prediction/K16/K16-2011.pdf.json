{"title": [{"text": "SoNLP-DP System for ConLL-2016 Chinese Shallow Discourse Parsing", "labels": [], "entities": [{"text": "ConLL-2016 Chinese Shallow Discourse Parsing", "start_pos": 20, "end_pos": 64, "type": "TASK", "confidence": 0.6744963109493256}]}], "abstractContent": [{"text": "This paper describes our submission to the CoNLL-2016 shared task (Xue et al., 2016) on end-to-end Chinese shallow discourse parsing.", "labels": [], "entities": [{"text": "Chinese shallow discourse parsing", "start_pos": 99, "end_pos": 132, "type": "TASK", "confidence": 0.5468398630619049}]}, {"text": "We decompose the end-to-end process into four steps.", "labels": [], "entities": []}, {"text": "Firstly, we define a syntactically heuristic algorithm to identify elementary discourse units (EDUs) and further to recognize valid EDU pairs.", "labels": [], "entities": []}, {"text": "Secondly, we recognize explicit discourse connectives.", "labels": [], "entities": []}, {"text": "Thirdly, we link each explicit connective to valid EDU pairs to obtain explicit discourse relations.", "labels": [], "entities": []}, {"text": "For those valid EDU pairs not linked to any explicit connective, they become non-explicit discourse relations.", "labels": [], "entities": []}, {"text": "1 Finally, we assign each discourse relation , either explicit or non-explicit with a discourse sense.", "labels": [], "entities": []}, {"text": "Our system is evaluated on the closed track of the CoNLL-2016 shared task and achieves 35.54% and 23.46% in F1-measure on the official test set and blind test set, respectively.", "labels": [], "entities": [{"text": "CoNLL-2016 shared task", "start_pos": 51, "end_pos": 73, "type": "DATASET", "confidence": 0.7853477597236633}, {"text": "F1-measure", "start_pos": 108, "end_pos": 118, "type": "METRIC", "confidence": 0.9991291165351868}]}], "introductionContent": [{"text": "Shallow discourse parsing maps apiece of text into a set of discourse relations, each of which is composed of a discourse connective, two arguments, and the sense of the discourse connective.", "labels": [], "entities": [{"text": "Shallow discourse parsing", "start_pos": 0, "end_pos": 25, "type": "TASK", "confidence": 0.6543645163377126}]}, {"text": "Shallow discourse parsing has been drawing more and more attention in recent years due to its importance in deep NLP applications, such as coherence modeling (), event extraction (, and statistical machine translation (.", "labels": [], "entities": [{"text": "Shallow discourse parsing", "start_pos": 0, "end_pos": 25, "type": "TASK", "confidence": 0.739425520102183}, {"text": "coherence modeling", "start_pos": 139, "end_pos": 157, "type": "TASK", "confidence": 0.7003316730260849}, {"text": "event extraction", "start_pos": 162, "end_pos": 178, "type": "TASK", "confidence": 0.7868832349777222}, {"text": "statistical machine translation", "start_pos": 186, "end_pos": 217, "type": "TASK", "confidence": 0.7470007141431173}]}, {"text": "During the past few years, English shallow discourse parsing has dominated the research on dis-course parsing, thanks to the availability of Penn Discourse TreeBank (PDTB) (.", "labels": [], "entities": [{"text": "English shallow discourse parsing", "start_pos": 27, "end_pos": 60, "type": "TASK", "confidence": 0.5676817819476128}, {"text": "dis-course parsing", "start_pos": 91, "end_pos": 109, "type": "TASK", "confidence": 0.8902248740196228}, {"text": "Penn Discourse TreeBank (PDTB)", "start_pos": 141, "end_pos": 171, "type": "DATASET", "confidence": 0.9433151582876841}]}, {"text": "As a representative, decompose the end-to-end PDTB-styled discourse parser into a few components, including a connective classifier, an argument labeler, an explicit sense classifier, and a non-explicit sense classifier.", "labels": [], "entities": []}, {"text": "The popularity of English shallow discourse parsing is further fueled by the CoNLL-2015 shared task (.", "labels": [], "entities": [{"text": "English shallow discourse parsing", "start_pos": 18, "end_pos": 51, "type": "TASK", "confidence": 0.5778962522745132}, {"text": "CoNLL-2015 shared task", "start_pos": 77, "end_pos": 99, "type": "DATASET", "confidence": 0.7869426210721334}]}, {"text": "Meanwhile research on Chinese discourse parsing is also carried out smoothly ().", "labels": [], "entities": [{"text": "Chinese discourse parsing", "start_pos": 22, "end_pos": 47, "type": "TASK", "confidence": 0.6351090371608734}]}, {"text": "As a complement to PDTB annotated on English TreeBank, Chinese Discourse TreeBank (CDTB) ( annotates shallow discourse relations on Chinese TreeBank by using similar framework of PDTB.", "labels": [], "entities": [{"text": "English TreeBank", "start_pos": 37, "end_pos": 53, "type": "DATASET", "confidence": 0.9528067409992218}, {"text": "Chinese Discourse TreeBank (CDTB)", "start_pos": 55, "end_pos": 88, "type": "DATASET", "confidence": 0.8551024397214254}, {"text": "Chinese TreeBank", "start_pos": 132, "end_pos": 148, "type": "DATASET", "confidence": 0.7856170833110809}]}, {"text": "However, the two languages have many different properties.", "labels": [], "entities": []}, {"text": "For example, the non-explicit discourse relations in the training data of CoNLL-2016 shared task dataset account for 54.75% in English while they account for 78.27% in Chinese, indicating the difficulties in Chinese shallow discourse parsing.", "labels": [], "entities": [{"text": "CoNLL-2016 shared task dataset", "start_pos": 74, "end_pos": 104, "type": "DATASET", "confidence": 0.8565021902322769}, {"text": "Chinese shallow discourse parsing", "start_pos": 208, "end_pos": 241, "type": "TASK", "confidence": 0.6175269186496735}]}, {"text": "Second, the two arguments of a Chinese non-explicit discourse relation are more apt to locate in the same sentence.", "labels": [], "entities": []}, {"text": "This is verified by the statistics that 56.57% of Chinese nonexplicit discourse relations are within one sentence while only 2.55% of English non-explicit discourse relations are.", "labels": [], "entities": []}, {"text": "In particular, the English non-explicit discourse relations are usually composed of two consecutive sentences.", "labels": [], "entities": []}, {"text": "This paper describes our submission to the CoNLL-2016 shared task on end-to-end Chinese shallow discourse parsing.", "labels": [], "entities": [{"text": "CoNLL-2016 shared task on end-to-end Chinese shallow discourse parsing", "start_pos": 43, "end_pos": 113, "type": "TASK", "confidence": 0.5548640986283621}]}, {"text": "A participant system needs to (1) identify all explicit discourse connectives in the text (e.g., continuous connectives \" \", \" \", discontinuous one \" ...", "labels": [], "entities": []}, {"text": "\"), (2) identify the spans of text that function as the two arguments (i.e., Arg1 and Arg2) for each discourse connective, and (3) predict the sense of the discourse relations (e.g., Cause, Condition, Contrast).", "labels": [], "entities": [{"text": "Arg1", "start_pos": 77, "end_pos": 81, "type": "METRIC", "confidence": 0.9741199612617493}, {"text": "Arg2", "start_pos": 86, "end_pos": 90, "type": "METRIC", "confidence": 0.87637859582901}]}, {"text": "Due to the differences between Chinese and English, our approach to Chinese discourse parsing is very different from the one to English discourse parsing ().", "labels": [], "entities": [{"text": "Chinese discourse parsing", "start_pos": 68, "end_pos": 93, "type": "TASK", "confidence": 0.60735684633255}, {"text": "English discourse parsing", "start_pos": 128, "end_pos": 153, "type": "TASK", "confidence": 0.6658778389294943}]}, {"text": "For example, construct non-explicit discourse relations in English by looking for two consecutive sentences that are not connected to any explicit connective.", "labels": [], "entities": []}, {"text": "However, it fails to discover non-explicit discourse relations in which the two arguments locate in one sentence.", "labels": [], "entities": []}, {"text": "Alternatively, we decompose the whole process of our Chinese discourse parser into four steps.", "labels": [], "entities": [{"text": "Chinese discourse parser", "start_pos": 53, "end_pos": 77, "type": "TASK", "confidence": 0.5674888888994852}]}, {"text": "Firstly, we define a syntactically heuristic algorithm to identify elementary discourse units (EDUs) and further to recognize valid EDU pairs.", "labels": [], "entities": []}, {"text": "Secondly, we recognize explicit discourse connectives.", "labels": [], "entities": []}, {"text": "Thirdly, we link each explicit connective to valid EDU pairs to obtain explicit discourse relations.", "labels": [], "entities": []}, {"text": "For those valid EDU pairs not linked to any explicit connective, they become non-explicit discourse relations.", "labels": [], "entities": []}, {"text": "Finally, we assign each discourse relation, either explicit or non-explicit with a discourse sense.", "labels": [], "entities": []}, {"text": "Our system is evaluated on the closed track of the CoNLL-2016 shared task and achieves 35.54% and 23.46% in F1-measure on the official test set and blind test set, respectively.", "labels": [], "entities": [{"text": "CoNLL-2016 shared task", "start_pos": 51, "end_pos": 73, "type": "DATASET", "confidence": 0.7853471636772156}, {"text": "F1-measure", "start_pos": 108, "end_pos": 118, "type": "METRIC", "confidence": 0.9991291165351868}]}, {"text": "The rest of this paper is organized as follows.", "labels": [], "entities": []}, {"text": "Section 2 describes the details of our Chinese shallow discourse parser.", "labels": [], "entities": [{"text": "Chinese shallow discourse parser", "start_pos": 39, "end_pos": 71, "type": "TASK", "confidence": 0.5084181427955627}]}, {"text": "In Section 3, we present our experimental results, followed by the conclusion in Section 4.", "labels": [], "entities": []}], "datasetContent": [{"text": "We evaluate our system on the Chinese dataset provided in the close track of the CoNLL-2016 Shared Task.", "labels": [], "entities": [{"text": "Chinese dataset", "start_pos": 30, "end_pos": 45, "type": "DATASET", "confidence": 0.8872489035129547}, {"text": "CoNLL-2016 Shared Task", "start_pos": 81, "end_pos": 103, "type": "DATASET", "confidence": 0.8253416816393534}]}, {"text": "All our kernel-based classifiers (e.g., valid EDU pair recognizer, connective recognizer, and linker connecting connectives with EDU pairs) and flat feature-based classifiers (e.g., sense classifiers for either explicit discourse relations or non-explicit discourse relations) are trained using SVMLight toolkit for tree kernel.", "labels": [], "entities": []}, {"text": "4 shows our official performance on the development, test and blind test sets, respectively.", "labels": [], "entities": []}, {"text": "From the table, we observe: \u2022 For argument recognition, the performance of Arg2 is much better than that of Arg1 on the development and test datasets.", "labels": [], "entities": [{"text": "argument recognition", "start_pos": 34, "end_pos": 54, "type": "TASK", "confidence": 0.9280871152877808}, {"text": "Arg2", "start_pos": 75, "end_pos": 79, "type": "METRIC", "confidence": 0.8759992122650146}]}, {"text": "This is similar to the performance trend in English.", "labels": [], "entities": []}, {"text": "However, the performance gap between Arg1 and Arg2 recognition is very small on the blind test dataset.: Official results (%) of our parser on development, test and blind test sets.", "labels": [], "entities": [{"text": "Arg1", "start_pos": 37, "end_pos": 41, "type": "METRIC", "confidence": 0.9459444284439087}, {"text": "Arg2 recognition", "start_pos": 46, "end_pos": 62, "type": "TASK", "confidence": 0.7488848268985748}]}, {"text": "Group Explicit indicates the performance with respect to explicit discourse relations; group Non-Explicit indicates the performance with respect to non-explicit discourse relations, and group all indicates the performance with respect to all discourse relations, including both explicit and non-explicit ones.", "labels": [], "entities": []}, {"text": "\u2022 With respect to explicit discourse relations, the sense classification works almost perfectly on development data (e.g., almost no performance gap from Arg1 & Arg2 to Overall.", "labels": [], "entities": [{"text": "sense classification", "start_pos": 52, "end_pos": 72, "type": "TASK", "confidence": 0.7503509521484375}, {"text": "Arg1", "start_pos": 154, "end_pos": 158, "type": "METRIC", "confidence": 0.9466874599456787}, {"text": "Arg2", "start_pos": 161, "end_pos": 165, "type": "METRIC", "confidence": 0.8334798812866211}]}, {"text": "It also works well on the test and blind test sets.", "labels": [], "entities": []}, {"text": "\u2022 With respect to non-explicit discourse relations, the sense classification works much worse than that of explicit sense classification.", "labels": [], "entities": [{"text": "sense classification", "start_pos": 56, "end_pos": 76, "type": "TASK", "confidence": 0.7337945103645325}]}, {"text": "The performance gap caused by non-explicit sense classification reaches 14% 18%.", "labels": [], "entities": [{"text": "sense classification", "start_pos": 43, "end_pos": 63, "type": "TASK", "confidence": 0.6735311448574066}]}, {"text": "\u2022 The overall performance on all discourse relations is dominated by non-explicit ones.", "labels": [], "entities": []}, {"text": "This is because larger size of non-explicit discourse relations.", "labels": [], "entities": []}, {"text": "For example, the size of non-explicit discourse relations is 3.6 times of that of explicit ones in training data.", "labels": [], "entities": []}, {"text": "\u2022 Our system achieves similar results on development set and test set.", "labels": [], "entities": []}, {"text": "However, the performance on blind test decreases sharply, probably due to the differences in genres and the bad quality of parse trees.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Official results (%) of our parser on development, test and blind test sets. Group Explicit  indicates the performance with respect to explicit discourse relations; group Non-Explicit indicates the  performance with respect to non-explicit discourse relations, and group all indicates the performance  with respect to all discourse relations, including both explicit and non-explicit ones.", "labels": [], "entities": []}]}