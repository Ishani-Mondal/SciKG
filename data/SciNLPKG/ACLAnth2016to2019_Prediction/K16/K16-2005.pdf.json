{"title": [{"text": "Do We Really Need All Those Rich Linguistic Features? A Neural Network-Based Approach to Implicit Sense Labeling", "labels": [], "entities": [{"text": "Implicit Sense Labeling", "start_pos": 89, "end_pos": 112, "type": "TASK", "confidence": 0.7966788013776144}]}], "abstractContent": [{"text": "We describe our contribution to the CoNLL 2016 Shared Task on shallow discourse parsing.", "labels": [], "entities": [{"text": "CoNLL 2016 Shared Task", "start_pos": 36, "end_pos": 58, "type": "DATASET", "confidence": 0.6939928233623505}, {"text": "shallow discourse parsing", "start_pos": 62, "end_pos": 87, "type": "TASK", "confidence": 0.5501244366168976}]}, {"text": "1 Our system extends the two best parsers from previous year's competition by integration of a novel implicit sense labeling component.", "labels": [], "entities": []}, {"text": "It is grounded on a highly generic, language-independent feedforward neural network architecture incorporating weighted word embeddings for argument spans which obviates the need for (traditional) hand-crafted features.", "labels": [], "entities": []}, {"text": "Despite its simplicity, our system overall outperforms all results from 2015 on 5 out of 6 evaluation sets for English and achieves an absolute improvement in F 1-score of 3.2% on the PDTB test section for non-explicit sense classification.", "labels": [], "entities": [{"text": "F 1-score", "start_pos": 159, "end_pos": 168, "type": "METRIC", "confidence": 0.9942198097705841}, {"text": "PDTB test section", "start_pos": 184, "end_pos": 201, "type": "DATASET", "confidence": 0.9697178403536478}, {"text": "non-explicit sense classification", "start_pos": 206, "end_pos": 239, "type": "TASK", "confidence": 0.6159818371136984}]}], "introductionContent": [{"text": "Text comprehension is an essential part of Natural Language Understanding and requires capabilities beyond capturing the lexical semantics of individual words or phrases.", "labels": [], "entities": [{"text": "Text comprehension", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.7891544103622437}, {"text": "Natural Language Understanding", "start_pos": 43, "end_pos": 73, "type": "TASK", "confidence": 0.6464258035024008}]}, {"text": "In order to understand how meaning is established, altered and transferred across words and sentences, a model is needed to account for contextual information as a semantically coherent representation of the logical discourse structure of a text.", "labels": [], "entities": []}, {"text": "Different formalisms and frameworks have been proposed to realize this assumption (.", "labels": [], "entities": []}, {"text": "Ina more applied NLP context, shallow discourse parsing (SDP) aims at automatically de-tecting relevant discourse units and to label the relations that hold between them.", "labels": [], "entities": [{"text": "shallow discourse parsing (SDP)", "start_pos": 30, "end_pos": 61, "type": "TASK", "confidence": 0.8318931857744852}]}, {"text": "Unlike deep discourse parsing, astringent logical formalization or the establishment of a global data structure, for instance, a tree, is not required.", "labels": [], "entities": [{"text": "deep discourse parsing", "start_pos": 7, "end_pos": 29, "type": "TASK", "confidence": 0.6804002126057943}]}, {"text": "With the release of the Penn Discourse Treebank (, PDTB) and the Chinese Discourse Treebank (, annotated training data for SDP has become available and, as a consequence, the field has considerably attracted researchers from the NLP and IR community.", "labels": [], "entities": [{"text": "Penn Discourse Treebank (, PDTB)", "start_pos": 24, "end_pos": 56, "type": "DATASET", "confidence": 0.9594577465738569}, {"text": "Chinese Discourse Treebank", "start_pos": 65, "end_pos": 91, "type": "DATASET", "confidence": 0.9609048167864481}]}, {"text": "Informally, the PDTB annotation scheme describes a discourse unit as a syntactically motivated character span in the text, augmented with relations pointing from the second argument (Arg2, prototypically, a discourse unit associated with an explicit discourse marker) to its antecedent, i.e., the discourse unit Arg1.", "labels": [], "entities": []}, {"text": "Relations are labeled with a relation type (its sense) and the associated discourse marker (either as found in the text or as inferred by the annotator).", "labels": [], "entities": []}, {"text": "PDTB distinguishes explicit and implicit relations depending on whether such a connector or cue phrase (e.g., because) is present, or not.", "labels": [], "entities": []}, {"text": "As an illustrative example without such a marker, consider the following two adjacent sentences from the PDTB: Arg1: The real culprits are computer makers such as IBM that have jumped the gun to unveil 486-based products.", "labels": [], "entities": [{"text": "PDTB", "start_pos": 105, "end_pos": 109, "type": "DATASET", "confidence": 0.9402101039886475}, {"text": "Arg1", "start_pos": 111, "end_pos": 115, "type": "METRIC", "confidence": 0.9973796606063843}]}, {"text": "Arg2: The reason this is getting so much visibility is that some started shipping and announced early availability.", "labels": [], "entities": [{"text": "Arg2", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.6786205768585205}]}, {"text": "In this implicit relation, Arg1 and Arg2 are directly related.", "labels": [], "entities": [{"text": "Arg1", "start_pos": 27, "end_pos": 31, "type": "METRIC", "confidence": 0.9854625463485718}, {"text": "Arg2", "start_pos": 36, "end_pos": 40, "type": "METRIC", "confidence": 0.9606790542602539}]}, {"text": "The discourse relation type is Expansion.Restatement-one out of roughly twenty finegrained tags marking the sense relation between any given argument pair in the PDTB.", "labels": [], "entities": [{"text": "PDTB", "start_pos": 162, "end_pos": 166, "type": "DATASET", "confidence": 0.9137780666351318}]}, {"text": "Our Contribution: We participate in the CoNLL 2016 Shared Task on SDP () and propose a novel, neural network-based approach for implicit sense labeling.", "labels": [], "entities": [{"text": "CoNLL 2016 Shared Task on SDP", "start_pos": 40, "end_pos": 69, "type": "TASK", "confidence": 0.7652590672175089}, {"text": "implicit sense labeling", "start_pos": 128, "end_pos": 151, "type": "TASK", "confidence": 0.6394568284352621}]}, {"text": "Its system architecture is modular, highly generic and mostly language-independent, by leveraging the full power of pre-trained word embeddings for the SDP sense classification task.", "labels": [], "entities": [{"text": "SDP sense classification task", "start_pos": 152, "end_pos": 181, "type": "TASK", "confidence": 0.9139949679374695}]}, {"text": "Our parser performs well on both English and Chinese data and is highly competitive with the state-of-the-art, though does not require manual feature engineering as employed inmost prior works on implicit SDP, but rather relies extensively on features learned from data.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: English full task F 1 -scores.", "labels": [], "entities": [{"text": "English full task F 1 -scores", "start_pos": 10, "end_pos": 39, "type": "METRIC", "confidence": 0.6949419890131269}]}, {"text": " Table 2: English sense-only task F 1 -scores.", "labels": [], "entities": [{"text": "English sense-only task F 1 -scores", "start_pos": 10, "end_pos": 45, "type": "METRIC", "confidence": 0.6985179824488503}]}, {"text": " Table 3: Chinese full task F 1 -scores.", "labels": [], "entities": [{"text": "Chinese full task F 1 -scores", "start_pos": 10, "end_pos": 39, "type": "METRIC", "confidence": 0.7161507180758885}]}, {"text": " Table 4: Chinese sense-only task F 1 -scores.", "labels": [], "entities": [{"text": "Chinese sense-only task F 1 -scores", "start_pos": 10, "end_pos": 45, "type": "METRIC", "confidence": 0.6399459881441933}]}]}