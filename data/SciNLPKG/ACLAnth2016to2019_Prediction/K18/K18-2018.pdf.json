{"title": [{"text": "Towards JointUD: Part-of-speech Tagging and Lemmatization using Recurrent Neural Networks", "labels": [], "entities": [{"text": "Part-of-speech Tagging", "start_pos": 17, "end_pos": 39, "type": "TASK", "confidence": 0.7084006071090698}]}], "abstractContent": [{"text": "This paper describes our submission to CoNLL 2018 UD Shared Task.", "labels": [], "entities": [{"text": "CoNLL 2018 UD Shared Task", "start_pos": 39, "end_pos": 64, "type": "DATASET", "confidence": 0.7843201637268067}]}, {"text": "We have extended an LSTM-based neural network designed for sequence tagging to additionally generate character-level sequences.", "labels": [], "entities": [{"text": "sequence tagging", "start_pos": 59, "end_pos": 75, "type": "TASK", "confidence": 0.7174887508153915}]}, {"text": "The network was jointly trained to produce lemmas, part-of-speech tags and morphological features.", "labels": [], "entities": []}, {"text": "Sentence seg-mentation, tokenization and dependency parsing were handled by UDPipe 1.2 base-line.", "labels": [], "entities": [{"text": "tokenization", "start_pos": 24, "end_pos": 36, "type": "TASK", "confidence": 0.9701593518257141}, {"text": "dependency parsing", "start_pos": 41, "end_pos": 59, "type": "TASK", "confidence": 0.8127602934837341}, {"text": "UDPipe 1.2 base-line", "start_pos": 76, "end_pos": 96, "type": "DATASET", "confidence": 0.8855870167414347}]}, {"text": "The results demonstrate the viability of the proposed multitask architecture, although its performance still remains far from state-of-the-art.", "labels": [], "entities": []}], "introductionContent": [{"text": "The Universal Dependencies project () aims to collect consistently annotated treebanks for many languages.", "labels": [], "entities": []}, {"text": "Its current version (2.2) (  includes publicly available treebanks for 71 languages in CoNLL-U format.", "labels": [], "entities": []}, {"text": "The treebanks contain lemmas, part-ofspeech tags, morphological features and dependency relations for every word.", "labels": [], "entities": []}, {"text": "Neural networks have been successfully applied to most of these tasks and produced state-of-theart results for part-of-speech tagging and dependency parsing.", "labels": [], "entities": [{"text": "part-of-speech tagging", "start_pos": 111, "end_pos": 133, "type": "TASK", "confidence": 0.7868411839008331}, {"text": "dependency parsing", "start_pos": 138, "end_pos": 156, "type": "TASK", "confidence": 0.8418885171413422}]}, {"text": "Part-of-speech tagging is usually defined as a sequence tagging problem and is solved with recurrent or convolutional neural networks using word-level softmax outputs or conditional random fields (.", "labels": [], "entities": [{"text": "Part-of-speech tagging", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.7786721587181091}, {"text": "sequence tagging", "start_pos": 47, "end_pos": 63, "type": "TASK", "confidence": 0.7710918188095093}]}, {"text": "have studied these architectures in depth and demonstrated the effect of network hyperparameters and even random seeds on the performance of the networks.", "labels": [], "entities": []}, {"text": "Neural networks have been applied to dependency parsing since 2014).", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 37, "end_pos": 55, "type": "TASK", "confidence": 0.8759565949440002}]}, {"text": "The state-of-the-art in dependency parsing is a network with deep biaffine attention module, which won CoNLL 2017 UD Shared.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 24, "end_pos": 42, "type": "TASK", "confidence": 0.8539093732833862}, {"text": "CoNLL 2017 UD Shared", "start_pos": 103, "end_pos": 123, "type": "DATASET", "confidence": 0.8235701322555542}]}, {"text": "used a neural network to jointly learn POS tagging and dependency parsing.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 39, "end_pos": 50, "type": "TASK", "confidence": 0.7996715009212494}, {"text": "dependency parsing", "start_pos": 55, "end_pos": 73, "type": "TASK", "confidence": 0.8148554861545563}]}, {"text": "To the best of our knowledge, lemma generation and POS tagging have never been trained jointly using a single multitask architecture.", "labels": [], "entities": [{"text": "lemma generation", "start_pos": 30, "end_pos": 46, "type": "TASK", "confidence": 0.8565510511398315}, {"text": "POS tagging", "start_pos": 51, "end_pos": 62, "type": "TASK", "confidence": 0.8362504541873932}]}, {"text": "This paper describes our submission to CoNLL 2018 UD Shared Task.", "labels": [], "entities": [{"text": "CoNLL 2018 UD Shared Task", "start_pos": 39, "end_pos": 64, "type": "DATASET", "confidence": 0.7843201637268067}]}, {"text": "We have designed a neural network that jointly learns to predict part-ofspeech tags, morphological features and lemmas for the given sequence of words.", "labels": [], "entities": []}, {"text": "This is the first step towards JointUD, a multitask neural network that will learn to output all labels included in UD treebanks given a tokenized text.", "labels": [], "entities": []}, {"text": "Our system used UDPipe 1.2 () for sentence segmentation, tokenization and dependency parsing.", "labels": [], "entities": [{"text": "sentence segmentation", "start_pos": 34, "end_pos": 55, "type": "TASK", "confidence": 0.7503654956817627}, {"text": "tokenization", "start_pos": 57, "end_pos": 69, "type": "TASK", "confidence": 0.9676533341407776}, {"text": "dependency parsing", "start_pos": 74, "end_pos": 92, "type": "TASK", "confidence": 0.7816874384880066}]}, {"text": "Our main contribution is the extension of a sequence tagging network by to support character-level sequence outputs for lemma generation.", "labels": [], "entities": [{"text": "sequence tagging", "start_pos": 44, "end_pos": 60, "type": "TASK", "confidence": 0.7181205302476883}, {"text": "lemma generation", "start_pos": 120, "end_pos": 136, "type": "TASK", "confidence": 0.7839612066745758}]}, {"text": "The proposed architecture was validated on nine UD v2.2 treebanks.", "labels": [], "entities": [{"text": "UD v2.2 treebanks", "start_pos": 48, "end_pos": 65, "type": "DATASET", "confidence": 0.86907031138738}]}, {"text": "The results are generally not better than the UDPipe baseline, but we did not extensively tune the network to squeeze most out of it.", "labels": [], "entities": [{"text": "UDPipe baseline", "start_pos": 46, "end_pos": 61, "type": "DATASET", "confidence": 0.857522189617157}]}, {"text": "Hyperparameter search and improved network design are left for the future work.", "labels": [], "entities": []}], "datasetContent": [{"text": "We have implemented the architecture defined in the previous section using Keras framework.", "labels": [], "entities": [{"text": "Keras framework", "start_pos": 75, "end_pos": 90, "type": "DATASET", "confidence": 0.9181604385375977}]}, {"text": "Our implementation is based on the codebase for ( . The new part of the architecture (lemma generation) is quite slow.", "labels": [], "entities": [{"text": "lemma generation", "start_pos": 86, "end_pos": 102, "type": "TASK", "confidence": 0.7494341731071472}]}, {"text": "The overall training speed is decreased by more than three times when it is enabled.", "labels": [], "entities": []}, {"text": "We have left speed improvements for future work.", "labels": [], "entities": [{"text": "speed", "start_pos": 13, "end_pos": 18, "type": "METRIC", "confidence": 0.9834824800491333}]}, {"text": "To train the model we used RMSProp optimizer with early stopping.", "labels": [], "entities": []}, {"text": "The initial learning rate was 0.001, and it was decreased to 0.0005 since the seventh epoch.", "labels": [], "entities": [{"text": "learning rate", "start_pos": 12, "end_pos": 25, "type": "METRIC", "confidence": 0.9401842951774597}]}, {"text": "The training was stopped when the loss function was not improved on the development set for five consecutive epochs.", "labels": [], "entities": []}, {"text": "Due to time constraints, we have trained our neural architecture on just nine treebanks.", "labels": [], "entities": []}, {"text": "These include three English and two French treebanks.", "labels": [], "entities": [{"text": "French treebanks", "start_pos": 36, "end_pos": 52, "type": "DATASET", "confidence": 0.7190203368663788}]}, {"text": "Our system was evaluated on Ubuntu virtual machines in TIRA platform) and on our local machines using the test sets available on UD GitHub repository ().", "labels": [], "entities": [{"text": "UD GitHub repository", "start_pos": 129, "end_pos": 149, "type": "DATASET", "confidence": 0.9041249950726827}]}, {"text": "The version we ran on TIRA had a bug in the preprocessing pipeline and was doubling newline symbols in the input text.", "labels": [], "entities": [{"text": "TIRA", "start_pos": 22, "end_pos": 26, "type": "DATASET", "confidence": 0.9251728653907776}]}, {"text": "Raw texts in UD v2.2 occasionally contain newline symbols inside the sentences.", "labels": [], "entities": []}, {"text": "These symbols were duplicated due to the bug, and the sentence segmentation part of UDPipe treated them as two different sentences.", "labels": [], "entities": [{"text": "sentence segmentation", "start_pos": 54, "end_pos": 75, "type": "TASK", "confidence": 0.7292163372039795}, {"text": "UDPipe", "start_pos": 84, "end_pos": 90, "type": "DATASET", "confidence": 0.8479679822921753}]}, {"text": "The evaluation scripts used in CoNLL 2018 UD Shared Task obviously penalized these errors.", "labels": [], "entities": [{"text": "CoNLL 2018 UD Shared Task", "start_pos": 31, "end_pos": 56, "type": "DATASET", "confidence": 0.7743674755096436}]}, {"text": "After the deadline of the Shared Task, we ran the same models (without retraining) on the test sets on our local machines without newline symbols.", "labels": [], "entities": []}, {"text": "Additionally, we locally trained models for two more non-Indo-European treebanks: Arabic PADT and Korean GSD.", "labels": [], "entities": []}, {"text": "shows the main metrics of CoNLL 2018 UD Shared Task on the nine treebanks that we used for training our models.", "labels": [], "entities": [{"text": "CoNLL 2018 UD Shared Task", "start_pos": 26, "end_pos": 51, "type": "DATASET", "confidence": 0.8244668364524841}]}, {"text": "For each of the metrics we report five scores, two scores on our local machine (our model and UDPipe 1.2), and three scores from the official leaderboard 4 (our model, UDPipe baseline, the best score for that particular treebank).", "labels": [], "entities": []}, {"text": "LAS metric evaluates sentence segmentation, tokenization and dependency parsing, so the numbers for our models should be identical to UDPipe 1.2.", "labels": [], "entities": [{"text": "sentence segmentation", "start_pos": 21, "end_pos": 42, "type": "TASK", "confidence": 0.750936359167099}, {"text": "tokenization", "start_pos": 44, "end_pos": 56, "type": "TASK", "confidence": 0.9636788964271545}, {"text": "dependency parsing", "start_pos": 61, "end_pos": 79, "type": "TASK", "confidence": 0.7036461532115936}]}, {"text": "MLAS metric additionally takes into account POS tags and morphological features, but not the lemmas.", "labels": [], "entities": [{"text": "MLAS", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.6845502853393555}]}, {"text": "BLEX metric evaluates dependency parsing and lemmatization.", "labels": [], "entities": [{"text": "BLEX", "start_pos": 0, "end_pos": 4, "type": "METRIC", "confidence": 0.9080930948257446}, {"text": "dependency parsing", "start_pos": 22, "end_pos": 40, "type": "TASK", "confidence": 0.6599363386631012}]}, {"text": "The full description of these metrics are available in () and in CoNLL 2018 UD Shared Task website . compares the same models using another set of metrics that measure the performance of POS tagging, morphological feature extraction and lemmatization.", "labels": [], "entities": [{"text": "CoNLL 2018 UD Shared Task website", "start_pos": 65, "end_pos": 98, "type": "DATASET", "confidence": 0.9315639038880666}, {"text": "POS tagging", "start_pos": 187, "end_pos": 198, "type": "TASK", "confidence": 0.8393561840057373}, {"text": "morphological feature extraction", "start_pos": 200, "end_pos": 232, "type": "TASK", "confidence": 0.6267992556095123}]}], "tableCaptions": [{"text": " Table 3: Performance of our model compared to UDPipe 1.2 baseline and the winner models of CoNLL  2018 UD Shared Task.", "labels": [], "entities": [{"text": "UDPipe 1.2 baseline", "start_pos": 47, "end_pos": 66, "type": "DATASET", "confidence": 0.8402219216028849}, {"text": "CoNLL  2018 UD Shared Task", "start_pos": 92, "end_pos": 118, "type": "DATASET", "confidence": 0.8141527295112609}]}, {"text": " Table 4: Additional metrics describing the performance of our model, UDPipe 1.2 baseline, and the  winner models of CoNLL 2018 UD Shared Task.", "labels": [], "entities": [{"text": "UDPipe 1.2 baseline", "start_pos": 70, "end_pos": 89, "type": "DATASET", "confidence": 0.6742689808209738}, {"text": "CoNLL 2018 UD Shared Task", "start_pos": 117, "end_pos": 142, "type": "DATASET", "confidence": 0.8069529294967651}]}]}