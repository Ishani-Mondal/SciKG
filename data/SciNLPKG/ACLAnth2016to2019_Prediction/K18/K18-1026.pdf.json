{"title": [{"text": "Using sparse semantic embeddings learned from multimodal text and image data to model human conceptual knowledge", "labels": [], "entities": []}], "abstractContent": [{"text": "Distributional models provide a convenient way to model semantics using dense embedding spaces derived from unsupervised learning algorithms.", "labels": [], "entities": []}, {"text": "However, the dimensions of dense embedding spaces are not designed to resemble human semantic knowledge.", "labels": [], "entities": []}, {"text": "Moreover , embeddings are often built from a single source of information (typically text data), even though neurocognitive research suggests that semantics is deeply linked to both language and perception.", "labels": [], "entities": []}, {"text": "In this paper, we combine multimodal information from both text and image-based representations derived from state-of-the-art distributional models to produce sparse, interpretable vectors using Joint Non-Negative Sparse Embedding.", "labels": [], "entities": []}, {"text": "Through in-depth analyses comparing these sparse models to human-derived behavioural and neuroimag-ing data, we demonstrate their ability to predict interpretable linguistic descriptions of human ground-truth semantic knowledge.", "labels": [], "entities": [{"text": "predict interpretable linguistic descriptions of human ground-truth semantic knowledge", "start_pos": 141, "end_pos": 227, "type": "TASK", "confidence": 0.6269107229179807}]}], "introductionContent": [{"text": "Distributional Semantic Models (DSMs) are used to represent semantic information about concepts in a high-dimensional vector space, where each concept is represented as a point in the space such that concepts with more similar meanings are closer together.", "labels": [], "entities": [{"text": "Distributional Semantic Models (DSMs)", "start_pos": 0, "end_pos": 37, "type": "TASK", "confidence": 0.6499922921260198}]}, {"text": "Unsupervised learning algorithms are regularly employed to produce these models, where learning depends on statistical regularities in the distribution of words, exploiting a theory in linguistics called the distributional hypothesis.", "labels": [], "entities": []}, {"text": "Recent developments in deep learning have resulted in weakly-supervised prediction-based methods, where, for example, a neural network is trained to predict words from surrounding contexts, and the network parameters are interpreted as vectors of the distributional model (.", "labels": [], "entities": []}, {"text": "Like their counterparts in machine vision, neural network algorithms for DSMs automate feature extraction from highly complex data without prior feature selection (.", "labels": [], "entities": [{"text": "DSMs automate feature extraction", "start_pos": 73, "end_pos": 105, "type": "TASK", "confidence": 0.7145763710141182}]}, {"text": "Such deep learning techniques have led to state-of-the-art performance in many domains, though this is often at the expense of the interpretability and cognitive plausibility of the learned features (.", "labels": [], "entities": []}, {"text": "Furthermore, these compact, dense embeddings are structurally dissimilar to the way in which humans conceptualise the meanings of words ().", "labels": [], "entities": []}, {"text": "One way of drawing interpretability from highly latent data is by transforming it into a sparse representation.", "labels": [], "entities": []}, {"text": "Moreover, the design of distributional models has been for the most part unimodal, typically relying on text corpora, even though studies in psychology have shown that human semantic processing is deeply linked with visual perception.", "labels": [], "entities": []}, {"text": "In cognitive neuroscience, research demonstrates that representations of high-level concepts corresponding to the meanings of nouns and visual objects are widely distributed and overlapping across the cortex (, which has opened up research into exploiting machine learning for neurosemantic prediction tasks using distributed semantic models (.", "labels": [], "entities": []}, {"text": "Such research has helped with both the construction and evaluation of semantic distributional embeddings in computer science.", "labels": [], "entities": []}, {"text": "In this paper, we utilise a matrix factorisation algorithm known as Non-Negative Sparse Embedding (NNSE) (, and an extension known as Joint Non-Negative Sparse Embedding (JNNSE) () to produce joint sparse multimodal distributions from text and image data.", "labels": [], "entities": []}, {"text": "Furthermore, we show that this joint multimodal semantic embedding approach offers a more faithful and parsimonious description of se-mantics as exhibited inhuman cognitive knowledge and neurocognitive processing, when compared with dense embeddings learned from the same data.", "labels": [], "entities": []}], "datasetContent": [{"text": "The aim of our experiments is to compare the quality of the dense and sparse unimodal and multimodal embedding models, with a focus on their ability to explain human-derived semantic data.", "labels": [], "entities": []}, {"text": "We use several qualitatively different analyses of how well the models explain human-derived measures of semantic representation and processing.", "labels": [], "entities": [{"text": "semantic representation and processing", "start_pos": 105, "end_pos": 143, "type": "TASK", "confidence": 0.8065392822027206}]}, {"text": "In the results that follow, we first demonstrate that sparse multimodal models are competitive with larger dense embedding models on standard semantic similarity evaluation benchmarks.", "labels": [], "entities": []}, {"text": "We then investigate whether the underlying representations of the sparse, multimodal models are more easily interpreted in terms of human semantic property knowledge about familiar concepts, by evaluating the models' ability to predict predicates describing property knowledge found inhuman property norm data.", "labels": [], "entities": []}, {"text": "Finally, we evaluate the models' ability to predict human brain activation data.", "labels": [], "entities": []}, {"text": "For our final set of analysis, we tested how closely each of the eight dense and eight sparse models relate to neurocognitive processing in the human brain.", "labels": [], "entities": []}, {"text": "We used BrainBench (, an evaluation benchmark for semantic models that allows us to evaluate each model's ability to predict patterns of activation in neuroimaging data.", "labels": [], "entities": []}, {"text": "The BrainBench dataset includes brain activation data recorded using two complementary neuroimaging modalities: fMRI (which measures cerebral blood oxygenation and which has relatively good spatial resolution but poor temporal resolution) and MEG (which measures aggregate magnetic field changes induced by neural activity and which has good temporal resolution but poorer spatial resolution).", "labels": [], "entities": [{"text": "BrainBench dataset", "start_pos": 4, "end_pos": 22, "type": "DATASET", "confidence": 0.8511576950550079}, {"text": "MEG", "start_pos": 243, "end_pos": 246, "type": "METRIC", "confidence": 0.8919064998626709}]}, {"text": "The neuroimaging data in both modalities are taken from nine participants that viewed pictures of 60 different concepts.", "labels": [], "entities": []}, {"text": "The first step is to transform the embedding matrices and the brain activation data into a format that more readily facilitates comparison of these two very different kinds of data.", "labels": [], "entities": []}, {"text": "For each distributional model, we calculated the pairwise correlation between concepts to produce the 60 \u00d7 60  similarity matrix M where each element M i,j in the matrix is the correlation between the embedding vectors of the distributional model for the ith and j-th concepts.", "labels": [], "entities": []}, {"text": "In Brainbench, the brain data is already preprocessed and transformed into such a representation for both the fMRI and MEG neuroimaging modalities, giving a 60 \u00d7 60 similarity matrix for each participant for both modalities.", "labels": [], "entities": [{"text": "Brainbench", "start_pos": 3, "end_pos": 13, "type": "DATASET", "confidence": 0.9159640073776245}]}, {"text": "The next step for BrainBench evaluation is to perform a \"2 vs. 2\" test between each distributional model and the brain data.", "labels": [], "entities": []}, {"text": "Let MD and MB be the similarity matrices associated with a distributional semantic model and a participant's brain data respectively.", "labels": [], "entities": [{"text": "MD", "start_pos": 4, "end_pos": 6, "type": "METRIC", "confidence": 0.9372156858444214}, {"text": "MB", "start_pos": 11, "end_pos": 13, "type": "METRIC", "confidence": 0.8792455196380615}]}, {"text": "Let r be the Pearson correlation function, then a 2 vs. 2 testis a positive case for any two pairs of concepts w 1 and w 2 if where MD (w 1 ) and MD (w 2 ) denote the rows of values corresponding to the concepts w 1 and w 2 respectively, omitting the columns that correspond to the correlation between w 1 and w 2 . This 2 vs. 2 testis performed on all pairs of the 60 concepts, to obtain the proportion of positive cases for the pair MD and MB . The distributional models are evaluated against all brainbased representations and averaged by imaging modality.", "labels": [], "entities": []}, {"text": "The results for both sparse and dense models are displayed in.", "labels": [], "entities": []}, {"text": "For the fMRI data, the model with the highest average 2 vs. 2 test score is the sparse multimodal GloVe+CNN-Max embedding, whilst on the MEG data the highest scoring model is a tie between the dense multimodal GloVe+CNN-Max embedding and the dense multimodal GloVe+CNN-Mean embedding.", "labels": [], "entities": [{"text": "fMRI data", "start_pos": 8, "end_pos": 17, "type": "DATASET", "confidence": 0.9362009167671204}, {"text": "MEG data", "start_pos": 137, "end_pos": 145, "type": "DATASET", "confidence": 0.9612703621387482}]}, {"text": "The results demonstrate that semantic distributional models that encode a range of different information are better at making statistically significant predictions on brain data.", "labels": [], "entities": []}, {"text": "In general, the multimodal models do better than the unimodal text and image models at fitting the brain data.", "labels": [], "entities": []}, {"text": "Finally, we computed the direct correlation be- For a given distributional model, we average all Spearman correlation values across the nine participants for each imaging modality; the results are presented in.", "labels": [], "entities": []}, {"text": "The results show that sparse models give the closest representation to both fMRI and MEG data, with the multimodal sparse word2vec+CNN-Mean model best fitting the fMRI data, and the sparse GloVe model best fitting the MEG data.", "labels": [], "entities": [{"text": "fMRI data", "start_pos": 163, "end_pos": 172, "type": "DATASET", "confidence": 0.9402632713317871}, {"text": "MEG data", "start_pos": 218, "end_pos": 226, "type": "DATASET", "confidence": 0.86571404337883}]}, {"text": "These results indicate that semantic model sparsity is an important property reflected in neurocognitive semantic representations.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: List of all dense (D) and sparse (S) models  used in this paper, and the number of dimensions  (#) in each model.", "labels": [], "entities": []}, {"text": " Table 2: Average cross-validation F1 \u00d7100 scores for each model. The blue highlighting indicates the  model that scores the highest on each property class.", "labels": [], "entities": [{"text": "F1 \u00d7100 scores", "start_pos": 35, "end_pos": 49, "type": "METRIC", "confidence": 0.9396347105503082}]}, {"text": " Table 3: Results of all sparse (S) and dense (D) models on 2 vs. 2 tests against the fMRI and MEG  neuroimaging data, averaged over participants.", "labels": [], "entities": [{"text": "MEG  neuroimaging data", "start_pos": 95, "end_pos": 117, "type": "DATASET", "confidence": 0.696199913819631}]}, {"text": " Table 4: Average RSA results (Spearman's \u03c1) for all sparse (S) and dense (D) models.", "labels": [], "entities": [{"text": "RSA", "start_pos": 18, "end_pos": 21, "type": "TASK", "confidence": 0.6230255365371704}, {"text": "Spearman's \u03c1)", "start_pos": 31, "end_pos": 44, "type": "METRIC", "confidence": 0.6683613732457161}]}]}