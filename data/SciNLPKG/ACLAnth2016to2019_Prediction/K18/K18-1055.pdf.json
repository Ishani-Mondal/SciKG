{"title": [{"text": "From Random to Supervised: A Novel Dropout Mechanism Integrated with Global Information", "labels": [], "entities": []}], "abstractContent": [{"text": "Dropout is used to avoid overfitting by randomly dropping units from the neural networks during training.", "labels": [], "entities": []}, {"text": "Inspired by dropout, this paper presents GI-Dropout, a novel dropout method integrating with global information to improve neural networks for text classification.", "labels": [], "entities": [{"text": "text classification", "start_pos": 143, "end_pos": 162, "type": "TASK", "confidence": 0.8194178640842438}]}, {"text": "Unlike the traditional dropout method in which the units are dropped randomly according to the same probability, we aim to use explicit instructions based on global information of the dataset to guide the training process.", "labels": [], "entities": []}, {"text": "With GI-Dropout, the model is supposed to pay more attention to inapparent features or patterns.", "labels": [], "entities": []}, {"text": "Experiments demonstrate the effectiveness of the dropout with global information on seven text classification tasks, including sentiment analysis and topic classification .", "labels": [], "entities": [{"text": "text classification", "start_pos": 90, "end_pos": 109, "type": "TASK", "confidence": 0.7214068621397018}, {"text": "sentiment analysis", "start_pos": 127, "end_pos": 145, "type": "TASK", "confidence": 0.9579675197601318}, {"text": "topic classification", "start_pos": 150, "end_pos": 170, "type": "TASK", "confidence": 0.8307135999202728}]}], "introductionContent": [{"text": "Recently, neural networks have achieved remarkable results in natural language processing (NLP).", "labels": [], "entities": [{"text": "natural language processing (NLP)", "start_pos": 62, "end_pos": 95, "type": "TASK", "confidence": 0.8040455679098765}]}, {"text": "Convolutional Neural Network (CNN) and Recurrent Neural Network (RNN) are two popular types of neural network architectures and both of them are widely applied to various NLP tasks.", "labels": [], "entities": []}, {"text": "CNN is known for its strong ability in extracting position-invariant features and RNN is highlighted in modeling sequences (.", "labels": [], "entities": [{"text": "CNN", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.7864770889282227}, {"text": "RNN", "start_pos": 82, "end_pos": 85, "type": "METRIC", "confidence": 0.8089383244514465}]}, {"text": "In sentence classification tasks, models based on CNN or RNN aim to represent sentences as appropriate embeddings, which are supposed to encode semantic features for the classification.", "labels": [], "entities": [{"text": "sentence classification tasks", "start_pos": 3, "end_pos": 32, "type": "TASK", "confidence": 0.8129149675369263}]}, {"text": "However, with the consideration of computational complexity and spatial limitation, neural networks are often trained via mini-batch in which global information is gathered implicitly rather \u2020 Hengru Xu and Shen Li contributed equally to this work.", "labels": [], "entities": []}, {"text": "\u2021 Corresponding author. than explicitly.", "labels": [], "entities": []}, {"text": "To facilitate the learning process, extract global semantic features from the training dataset, and encode them into CNN filters with a novel initialization mechanism.", "labels": [], "entities": []}, {"text": "This approach gains significant improvements in sentiment analysis and topic classification tasks.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 48, "end_pos": 66, "type": "TASK", "confidence": 0.972038596868515}, {"text": "topic classification tasks", "start_pos": 71, "end_pos": 97, "type": "TASK", "confidence": 0.8816569050153097}]}, {"text": "Unlike most of machine learning methods, the advantage of neural networks is extracting features with less need of feature engineering.", "labels": [], "entities": []}, {"text": "In general, the stronger ability of a model to learn features automatically, the better performance it will achieve.", "labels": [], "entities": []}, {"text": "However, during the training process, neural networks tend to focus on some distinctive words or phrases but ignore other noteworthy patterns, which may result in overfitting, especially in a small dataset.", "labels": [], "entities": []}, {"text": "To avoid this problem, dropout is proposed ().", "labels": [], "entities": []}, {"text": "The key idea of dropout is to randomly drop units from the neural network during training and use a smaller weight of these units in the test.", "labels": [], "entities": []}, {"text": "Inspired by the above works, we propose a novel dropout method guided by global information (GI-Dropout).", "labels": [], "entities": []}, {"text": "In our method, we force the model to pay more attention to features that are inapparent or with low frequency by dropping words that are prominent and easy to learn.", "labels": [], "entities": []}, {"text": "Unlike the traditional dropout method where neurons are dropped randomly with the same probability, we encode global information into dropout.", "labels": [], "entities": []}, {"text": "Specifically, we drop words based on their importance which are calculated from training data via a novel Na\u00a8\u0131veNa\u00a8\u0131ve Bayes (NB) weighting technique.", "labels": [], "entities": []}, {"text": "With this dropout method, neural networks tend to extract not only the obvious features but also the unobvious features which are also helpful for the classification.", "labels": [], "entities": []}, {"text": "By integrating our method into a classic CNN model for text classification) and a novel self-attentive RNN (, we observe significant improvements in various benchmarks.", "labels": [], "entities": [{"text": "text classification", "start_pos": 55, "end_pos": 74, "type": "TASK", "confidence": 0.8136025071144104}]}, {"text": "The advantages of our approach are as follows: 1.", "labels": [], "entities": []}, {"text": "Global information is directly obtained from the training data without any external resources; 2.", "labels": [], "entities": []}, {"text": "GI-Dropout is simple but effective, and could be easily applied to other DNN models; 3.", "labels": [], "entities": [{"text": "GI-Dropout", "start_pos": 0, "end_pos": 10, "type": "DATASET", "confidence": 0.6795240640640259}]}, {"text": "The computation brought by our method is relatively small, resulting in little additional training cost.", "labels": [], "entities": []}], "datasetContent": [{"text": "CNN-non-static proposed by Kim (2014) is considered as a very strong baseline in sentence classification.", "labels": [], "entities": [{"text": "sentence classification", "start_pos": 81, "end_pos": 104, "type": "TASK", "confidence": 0.7365726232528687}]}, {"text": "Self-attentive RNN proposed by also achieves outstanding performance in many sentence classification tasks.", "labels": [], "entities": [{"text": "sentence classification tasks", "start_pos": 77, "end_pos": 106, "type": "TASK", "confidence": 0.8029830555121104}]}, {"text": "We adopt these two models to evaluate GI-dropout.", "labels": [], "entities": []}, {"text": "Following, we evaluate the performance of the proposed approach on various datasets.", "labels": [], "entities": []}, {"text": "We use the same seven datasets with, including both sentiment analysis and topic classification tasks: MR: Movie reviews sentiment datasets 2 . SST-1: Stanford Sentiment Treebank with 5 sentiment labels . The data consists of phrases-level and sentence-level instances.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 52, "end_pos": 70, "type": "TASK", "confidence": 0.8685106635093689}, {"text": "topic classification", "start_pos": 75, "end_pos": 95, "type": "TASK", "confidence": 0.6771587282419205}, {"text": "Movie reviews sentiment datasets", "start_pos": 107, "end_pos": 139, "type": "DATASET", "confidence": 0.59330103546381}, {"text": "Stanford Sentiment Treebank", "start_pos": 151, "end_pos": 178, "type": "DATASET", "confidence": 0.8558818697929382}]}, {"text": "To keep same with, we train the model on both phrases and sentences but only test on sentences.", "labels": [], "entities": []}, {"text": "SST-2: SST-1 data with binary labels.", "labels": [], "entities": []}, {"text": "Subj: Subjective or objective classification dataset (Pang and  MPQA: Opinion polarity detection dataset ().", "labels": [], "entities": [{"text": "Subjective or objective classification", "start_pos": 6, "end_pos": 44, "type": "TASK", "confidence": 0.5971807911992073}, {"text": "Pang and  MPQA", "start_pos": 54, "end_pos": 68, "type": "DATASET", "confidence": 0.7320982416470846}, {"text": "Opinion polarity detection", "start_pos": 70, "end_pos": 96, "type": "TASK", "confidence": 0.6579010784626007}]}, {"text": "The statistics of the datasets can be seen in Table 1.", "labels": [], "entities": []}, {"text": "We apply our method to two baseline models.", "labels": [], "entities": []}, {"text": "For fair comparison, we use the same hyperparameters settings with two baselines for training and testing.", "labels": [], "entities": []}, {"text": "For datasets that do not have test sets, we split them for cross-validation with fixed random seeds.", "labels": [], "entities": []}, {"text": "We train all the models using early stopping and set timedelay to 10.", "labels": [], "entities": [{"text": "timedelay", "start_pos": 53, "end_pos": 62, "type": "METRIC", "confidence": 0.9890322089195251}]}], "tableCaptions": [{"text": " Table 1: Datasets summary. c: Number of target  classes. l: Average sentence length. N: Dataset  size. V: Vocabulary size. Test: Test set size (CV  means there is no standard train/test split and thus  10-fold CV is used).", "labels": [], "entities": []}, {"text": " Table 5: \u03b2 and accuracy in SST-1.", "labels": [], "entities": [{"text": "\u03b2", "start_pos": 10, "end_pos": 11, "type": "METRIC", "confidence": 0.9864411950111389}, {"text": "accuracy", "start_pos": 16, "end_pos": 24, "type": "METRIC", "confidence": 0.9997093081474304}, {"text": "SST-1", "start_pos": 28, "end_pos": 33, "type": "TASK", "confidence": 0.9391975402832031}]}, {"text": " Table 6: Accuracy decline when removing top-k  apparent words in SST-2.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9988271594047546}, {"text": "SST-2", "start_pos": 66, "end_pos": 71, "type": "TASK", "confidence": 0.8469265699386597}]}]}