{"title": [{"text": "Turku Neural Parser Pipeline: An End-to-End System for the CoNLL 2018 Shared Task", "labels": [], "entities": [{"text": "Turku Neural Parser Pipeline", "start_pos": 0, "end_pos": 28, "type": "TASK", "confidence": 0.7284706383943558}, {"text": "CoNLL 2018 Shared Task", "start_pos": 59, "end_pos": 81, "type": "DATASET", "confidence": 0.9029454588890076}]}], "abstractContent": [{"text": "In this paper we describe the TurkuNLP entry at the CoNLL 2018 Shared Task on Multilingual Parsing from Raw Text to Universal Dependencies.", "labels": [], "entities": [{"text": "CoNLL 2018 Shared Task", "start_pos": 52, "end_pos": 74, "type": "DATASET", "confidence": 0.8384261131286621}, {"text": "Multilingual Parsing from Raw Text", "start_pos": 78, "end_pos": 112, "type": "TASK", "confidence": 0.6748192131519317}]}, {"text": "Compared to the last year, this year the shared task includes two new main metrics to measure the morphological tagging and lemmatization accuracies in addition to syntactic trees.", "labels": [], "entities": [{"text": "morphological tagging", "start_pos": 98, "end_pos": 119, "type": "TASK", "confidence": 0.624171793460846}]}, {"text": "Basing our motivation into these new met-rics, we developed an end-to-end parsing pipeline especially focusing on developing a novel and state-of-the-art component for lemmatization.", "labels": [], "entities": []}, {"text": "Our system reached the highest aggregate ranking on three main metrics out of 26 teams by achieving 1st place on metric involving lemmatization, and 2nd on both morphological tagging and parsing.", "labels": [], "entities": [{"text": "morphological tagging", "start_pos": 161, "end_pos": 182, "type": "TASK", "confidence": 0.6221241056919098}]}], "introductionContent": [{"text": "The 2017 and 2018 CoNLL UD Shared tasks aim at an evaluation of end-to-end parsing systems on a large set of treebanks and languages.) focused primarily on the evaluation of the syntactic trees produced by the participating systems, whereas the 2018 task (Zeman et al., 2018) adds further two metrics which also measure the accuracy of morphological tagging and lemmatization.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 324, "end_pos": 332, "type": "METRIC", "confidence": 0.9979841709136963}]}, {"text": "In this paper, we present the TurkuNLP system submission to the CoNLL 2018 UD Shared Task.", "labels": [], "entities": [{"text": "TurkuNLP system submission", "start_pos": 30, "end_pos": 56, "type": "DATASET", "confidence": 0.8562520146369934}, {"text": "CoNLL 2018 UD Shared Task", "start_pos": 64, "end_pos": 89, "type": "DATASET", "confidence": 0.8301664352416992}]}, {"text": "The system is an end-toend parsing pipeline, with components for segmentation, morphological tagging, parsing, and lemmatization.", "labels": [], "entities": [{"text": "morphological tagging", "start_pos": 79, "end_pos": 100, "type": "TASK", "confidence": 0.5782106518745422}, {"text": "parsing", "start_pos": 102, "end_pos": 109, "type": "TASK", "confidence": 0.964415431022644}]}, {"text": "The tagger and parser are based on the 2017 winning system by, while the lemmatizer is a novel approach utilizing the OpenNMT neural machine translation system for sequence-to-sequence learning.", "labels": [], "entities": [{"text": "OpenNMT neural machine translation", "start_pos": 118, "end_pos": 152, "type": "TASK", "confidence": 0.7560687810182571}]}, {"text": "Our pipeline ranked first on the evaluation metric related to lemmatization, and second on the metrics related to tagging and parsing.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: The number of unique UPOS+morphlogical feature combinations needed to cover 80%, 90%,  95% and 100% of the running words in each treebank.", "labels": [], "entities": []}, {"text": " Table 2: LAS, UPOS and XPOS scores for seven parsers trained with and without tagger predicting the  additional morphological information. m after the score name stands for including the morphological  information during training, i.e. the official result for our system. Note that when evaluating XPOS, the  morphological information is already extracted from that field so the evaluation only includes prediction  of original XPOS-tags, not morphological features.", "labels": [], "entities": [{"text": "LAS", "start_pos": 10, "end_pos": 13, "type": "METRIC", "confidence": 0.9741696715354919}]}]}