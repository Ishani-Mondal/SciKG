{"title": [{"text": "Embedded-State Latent Conditional Random Fields for Sequence Labeling", "labels": [], "entities": [{"text": "Sequence Labeling", "start_pos": 52, "end_pos": 69, "type": "TASK", "confidence": 0.9337356984615326}]}], "abstractContent": [{"text": "Complex textual information extraction tasks are often posed as sequence labeling or shallow parsing, where fields are extracted using local labels made consistent through proba-bilistic inference in a graphical model with constrained transitions.", "labels": [], "entities": [{"text": "textual information extraction", "start_pos": 8, "end_pos": 38, "type": "TASK", "confidence": 0.6737286448478699}]}, {"text": "Recently, it has become common to locally parametrize these models using rich features extracted by recurrent neural networks (such as LSTM), while enforcing consistent outputs through a simple linear-chain model, representing Marko-vian dependencies between successive labels.", "labels": [], "entities": []}, {"text": "However, the simple graphical model structure belies the often complex non-local constraints between output labels.", "labels": [], "entities": []}, {"text": "For example, many fields, such as a first name, can only occur a fixed number of times, or in the presence of other fields.", "labels": [], "entities": []}, {"text": "While RNNs have provided increasingly powerful context-aware local features for sequence tagging, they have yet to be integrated with a global graphical model of similar expressivity in the output distribution.", "labels": [], "entities": [{"text": "sequence tagging", "start_pos": 80, "end_pos": 96, "type": "TASK", "confidence": 0.7037779837846756}]}, {"text": "Our model goes beyond the linear chain CRF to incorporate multiple hidden states per output label, but parametrizes their transitions parsimoniously with low-rank log-potential scoring matrices, effectively learning an embedding space for hidden states.", "labels": [], "entities": []}, {"text": "This augmented latent space of inference variables complements the rich feature representation of the RNN, and allows exact global inference obeying complex, learned non-local output constraints.", "labels": [], "entities": []}, {"text": "We experiment with several datasets and show that the model outperforms baseline CRF+RNN models when global output constraints are necessary at inference-time, and explore the interpretable latent structure.", "labels": [], "entities": []}], "introductionContent": [{"text": "As with many other prediction tasks involving complex structured outputs, such as image segmentation (, machine translation (, and speech recognition (, deep neural networks (DNNs) for sequence labeling and shallow parsing have become standard tools for for information extraction).", "labels": [], "entities": [{"text": "image segmentation", "start_pos": 82, "end_pos": 100, "type": "TASK", "confidence": 0.7694392204284668}, {"text": "machine translation", "start_pos": 104, "end_pos": 123, "type": "TASK", "confidence": 0.8087530136108398}, {"text": "speech recognition", "start_pos": 131, "end_pos": 149, "type": "TASK", "confidence": 0.7137720584869385}, {"text": "shallow parsing", "start_pos": 207, "end_pos": 222, "type": "TASK", "confidence": 0.6756817698478699}, {"text": "information extraction", "start_pos": 258, "end_pos": 280, "type": "TASK", "confidence": 0.8025090992450714}]}, {"text": "In the language of structured prediction, DNNs process the input sequence to produce a rich local parametrization for the output prediction model.", "labels": [], "entities": [{"text": "structured prediction", "start_pos": 19, "end_pos": 40, "type": "TASK", "confidence": 0.7456441521644592}]}, {"text": "However, output variables obey a variety of hard and soft constraints -for example, in sequence tagging tasks such as named entity recognition, I-PER cannot follow B-ORG.", "labels": [], "entities": [{"text": "sequence tagging tasks", "start_pos": 87, "end_pos": 109, "type": "TASK", "confidence": 0.7479788263638815}, {"text": "named entity recognition", "start_pos": 118, "end_pos": 142, "type": "TASK", "confidence": 0.5583828290303549}]}, {"text": "Interestingly, even with such powerful local featurization, the DNN model does not automatically capture a mode of the output distribution through local decisions alone, and can violate these constraints.", "labels": [], "entities": []}, {"text": "Successful applications of DNNs to sequence tagging gain from incorporating a simple linear chain probabilistic graphical model to enforce consistent output predictions, and more generally the addition of a graphical model to enforce output label consistency is common practice for other tasks such as image segmentation.", "labels": [], "entities": [{"text": "sequence tagging", "start_pos": 35, "end_pos": 51, "type": "TASK", "confidence": 0.7538085281848907}, {"text": "image segmentation", "start_pos": 302, "end_pos": 320, "type": "TASK", "confidence": 0.7704276144504547}]}, {"text": "Previous work in DNN-featurized sequence tagging with graphical models for information extraction has limited its output structure modeling to these simple local Markovian dependencies.", "labels": [], "entities": [{"text": "DNN-featurized sequence tagging", "start_pos": 17, "end_pos": 48, "type": "TASK", "confidence": 0.7304425040880839}, {"text": "information extraction", "start_pos": 75, "end_pos": 97, "type": "TASK", "confidence": 0.8114937841892242}]}, {"text": "In this work, we explore the addition of latent variables to the prediction model, and through a parsimonious factorized parameter structure, perform representation learning of hidden state embeddings in the graphical model, complementary to the standard practice of representation learning in the local potentials of the segmentation model.", "labels": [], "entities": [{"text": "representation learning", "start_pos": 267, "end_pos": 290, "type": "TASK", "confidence": 0.8321304619312286}]}, {"text": "By factorizing the log-potentials of the hidden state transition matrices, we are able to learn large numbers of hidden states without overfitting, while the latent dynamics add the capability to learn global constraints on the overall prediction, without sacrificing efficient exact inference.", "labels": [], "entities": []}, {"text": "While soft and hard global constraints have a rich history in sequence tagging (, they have been underexplored in the context of neural-network based feature extraction models.", "labels": [], "entities": [{"text": "sequence tagging", "start_pos": 62, "end_pos": 78, "type": "TASK", "confidence": 0.6550464034080505}]}, {"text": "In response, we present a latent-variable CRF model with a novel mechanism for learning latent constraints without overfitting, using low-rank embeddings of large-cardinality latent variables.", "labels": [], "entities": []}, {"text": "For example, these non-local constraints appear in fine-grained nested field extraction, which requires hierarchical consistency between the subtags of an entity.", "labels": [], "entities": [{"text": "fine-grained nested field extraction", "start_pos": 51, "end_pos": 87, "type": "TASK", "confidence": 0.6969402879476547}]}, {"text": "Further, information extraction and slot filling tasks often require domain specific constraints -for example, we must avoid extracting the same field multiple times.", "labels": [], "entities": [{"text": "information extraction", "start_pos": 9, "end_pos": 31, "type": "TASK", "confidence": 0.8669398128986359}, {"text": "slot filling", "start_pos": 36, "end_pos": 48, "type": "TASK", "confidence": 0.8694101572036743}]}, {"text": "A good combination of input featurization and output modeling is needed to capture these structural dependencies.", "labels": [], "entities": []}, {"text": "In this work we present a method for sequence labeling in which representation learning is applied not only to inputs, but also to output space, in the form of a lightly parameterized transition function between a large number of latent states.", "labels": [], "entities": [{"text": "sequence labeling", "start_pos": 37, "end_pos": 54, "type": "TASK", "confidence": 0.6421584039926529}]}, {"text": "We introduce a hidden state variable and learn the model dynamics in the hidden state space rather than the label state space.", "labels": [], "entities": []}, {"text": "This relaxes the Markov assumption between output labels and allows the model to learn global constraints.", "labels": [], "entities": []}, {"text": "To avoid the quadratic blowup in parameters with the size of the latent state space, we factorize the transition logpotentials into a low-rank matrix, avoiding overfitting by effectively learning parsimonious embedded representations of the latent states.", "labels": [], "entities": []}, {"text": "While the low rank log-potential matrix does not improve test-time inference speed, we can perform exact Viterbi inference to compute the labeling sequence.", "labels": [], "entities": []}, {"text": "shows an example where our model finds the correct labeling sequence while a standard DNN+CRF model fails, by obeying a global constraint learned from the training data.", "labels": [], "entities": []}, {"text": "We examine the performance of the EmbeddedState Latent CRF on two datasets: citation extraction on the UMass Citations dataset and medical record field extraction on the CLEF dataset.", "labels": [], "entities": [{"text": "citation extraction", "start_pos": 76, "end_pos": 95, "type": "TASK", "confidence": 0.8527216613292694}, {"text": "UMass Citations dataset", "start_pos": 103, "end_pos": 126, "type": "DATASET", "confidence": 0.974313219388326}, {"text": "medical record field extraction", "start_pos": 131, "end_pos": 162, "type": "TASK", "confidence": 0.5402157157659531}, {"text": "CLEF dataset", "start_pos": 170, "end_pos": 182, "type": "DATASET", "confidence": 0.9758285582065582}]}, {"text": "We observe improved performance in both tasks, whose outputs obey complex structural dependencies that are notable to be captured by RNN featurization.", "labels": [], "entities": []}, {"text": "Our biggest improvement comes in the medical domain, where the small training set gives our parsimonious approach to output representation learning an extra advantage.", "labels": [], "entities": [{"text": "output representation learning", "start_pos": 117, "end_pos": 147, "type": "TASK", "confidence": 0.7182803750038147}]}], "datasetContent": [{"text": "We experiment on two datasets with a rich output label space, the UMass Citations dataset) and the CLEF eHealth dataset ().", "labels": [], "entities": [{"text": "UMass Citations dataset", "start_pos": 66, "end_pos": 89, "type": "DATASET", "confidence": 0.9598947763442993}, {"text": "CLEF eHealth dataset", "start_pos": 99, "end_pos": 119, "type": "DATASET", "confidence": 0.9290796717007955}]}, {"text": "Both of the datasets have a hierarchical label space, enforced by hard transition constraints, making this a form of shallow parsing), with additional soft constraints in the label space due to the interdependent nature of the fields being extracted.", "labels": [], "entities": []}, {"text": "We report field-level F1 scores as computed using the conlleval.pl script.", "labels": [], "entities": [{"text": "F1 scores", "start_pos": 22, "end_pos": 31, "type": "METRIC", "confidence": 0.9397716820240021}]}, {"text": "Since the train/validation/test splits were clearly defined for the UMass Citation dataset, we trained the models on the training split, tuned the hyperparameters on the validation split and report the scores on the test dataset.", "labels": [], "entities": [{"text": "UMass Citation dataset", "start_pos": 68, "end_pos": 90, "type": "DATASET", "confidence": 0.9767665266990662}]}, {"text": "However, as there were only 101 documents in the CLEF eHealth dataset, we report the Leave-One-Out (LOO) cross-validation F1 scores for this dataset i.e., we trained 101 models each with a different held-out document, merged the respective test outputs, and computed the F1 score on this merged output.", "labels": [], "entities": [{"text": "CLEF eHealth dataset", "start_pos": 49, "end_pos": 69, "type": "DATASET", "confidence": 0.9692192276318868}, {"text": "Leave-One-Out (LOO) cross-validation F1 scores", "start_pos": 85, "end_pos": 131, "type": "METRIC", "confidence": 0.8633670125688825}, {"text": "F1 score", "start_pos": 271, "end_pos": 279, "type": "METRIC", "confidence": 0.9812692105770111}]}, {"text": "shows that overall performance on the UMass Citation dataset using the embedded-state latent CRF (95.18) is marginally better than the baseline BiLSTM+CRF model (95.07).", "labels": [], "entities": [{"text": "UMass Citation dataset", "start_pos": 38, "end_pos": 60, "type": "DATASET", "confidence": 0.9599190155665079}, {"text": "embedded-state latent CRF", "start_pos": 71, "end_pos": 96, "type": "METRIC", "confidence": 0.5844220320383707}]}, {"text": "However, examining the entities with the largest F1 score improvement in, we see that they are mostly within the VENUE section, which has longrange constraints with other sections, giving evidence of the model's ability to learn constraints from the citation dataset.", "labels": [], "entities": [{"text": "F1 score improvement", "start_pos": 49, "end_pos": 69, "type": "METRIC", "confidence": 0.9806008736292521}, {"text": "VENUE section", "start_pos": 113, "end_pos": 126, "type": "DATASET", "confidence": 0.7481889724731445}]}, {"text": "due to the global constraint that those entities always co-occur.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Entity-level F1 scores of the embedded- state latent CRF and BiLSTM+CRF baseline.", "labels": [], "entities": [{"text": "F1", "start_pos": 23, "end_pos": 25, "type": "METRIC", "confidence": 0.8735904097557068}, {"text": "BiLSTM+CRF baseline", "start_pos": 71, "end_pos": 90, "type": "DATASET", "confidence": 0.6933582574129105}]}, {"text": " Table 2: Top 5 entities in terms of F1 improve- ment on the UMass Citation Dataset. The col- umn S shows the support for a given entity in the  test dataset. Key for contracted entity names: V:", "labels": [], "entities": [{"text": "F1 improve- ment", "start_pos": 37, "end_pos": 53, "type": "METRIC", "confidence": 0.967660441994667}, {"text": "UMass Citation Dataset", "start_pos": 61, "end_pos": 83, "type": "DATASET", "confidence": 0.9832245310147604}]}, {"text": " Table 3: Top 5 entities in terms of F1 im- provement on the CLEF eHealth dataset.  Key for contracted entity names:", "labels": [], "entities": [{"text": "F1 im- provement", "start_pos": 37, "end_pos": 53, "type": "METRIC", "confidence": 0.9426878988742828}, {"text": "CLEF eHealth dataset", "start_pos": 61, "end_pos": 81, "type": "DATASET", "confidence": 0.973523219426473}]}, {"text": " Table 4: Comparison of F1 scores obtained by  varying the factor size parameter, and setting the  other model and neural network parameters from  the model with the best cross validation.", "labels": [], "entities": [{"text": "F1 scores", "start_pos": 24, "end_pos": 33, "type": "METRIC", "confidence": 0.9728636741638184}]}]}