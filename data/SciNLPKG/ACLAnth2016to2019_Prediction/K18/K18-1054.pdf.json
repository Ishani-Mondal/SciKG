{"title": [{"text": "Neural Maximum Subgraph Parsing for Cross-Domain Semantic Dependency Analysis", "labels": [], "entities": [{"text": "Neural Maximum Subgraph Parsing", "start_pos": 0, "end_pos": 31, "type": "TASK", "confidence": 0.7131323963403702}, {"text": "Cross-Domain Semantic Dependency Analysis", "start_pos": 36, "end_pos": 77, "type": "TASK", "confidence": 0.5864374041557312}]}], "abstractContent": [{"text": "We present experiments for cross-domain semantic dependency analysis with a neural Maximum Subgraph parser.", "labels": [], "entities": [{"text": "cross-domain semantic dependency analysis", "start_pos": 27, "end_pos": 68, "type": "TASK", "confidence": 0.71702491492033}]}, {"text": "Our parser targets 1-endpoint-crossing, pagenumber-2 graphs which area good fit to semantic dependency graphs, and utilizes an efficient dynamic programming algorithm for decoding.", "labels": [], "entities": []}, {"text": "For dis-ambiguation, the parser associates words with BiLSTM vectors and utilizes these vectors to assign scores to candidate dependencies.", "labels": [], "entities": []}, {"text": "We conduct experiments on the data sets from Se-mEval 2015 as well as Chinese CCGBank.", "labels": [], "entities": [{"text": "Chinese CCGBank", "start_pos": 70, "end_pos": 85, "type": "DATASET", "confidence": 0.8321323990821838}]}, {"text": "Our parser achieves very competitive results for both English and Chinese.", "labels": [], "entities": []}, {"text": "To improve the parsing performance on cross-domain texts, we propose a data-oriented method to explore the linguistic generality encoded in En-glish Resource Grammar, which is a precision-oriented, hand-crafted HPSG grammar, in an implicit way.", "labels": [], "entities": []}, {"text": "Experiments demonstrate the effectiveness of our data-oriented method across a wide range of conditions.", "labels": [], "entities": []}], "introductionContent": [{"text": "Semantic Dependency Parsing (SDP) is defined as the task of recovering sentence-internal bilexical semantic dependency structures, which encode predicate-argument relationships for all content words.", "labels": [], "entities": [{"text": "Semantic Dependency Parsing (SDP)", "start_pos": 0, "end_pos": 33, "type": "TASK", "confidence": 0.8394177407026291}]}, {"text": "Such sentence-level semantic analysis of text is concerned with the characterization of events and is therefore important to understand the essential meaning of a natural language sentence.", "labels": [], "entities": [{"text": "sentence-level semantic analysis of text", "start_pos": 5, "end_pos": 45, "type": "TASK", "confidence": 0.784827709197998}]}, {"text": "With the advent of many supporting resources, SDP has become a well-defined task with a substantial body of work and comparative evaluation.", "labels": [], "entities": [{"text": "SDP", "start_pos": 46, "end_pos": 49, "type": "TASK", "confidence": 0.9863921403884888}]}, {"text": "(. Two SDP shared tasks have been run as part of the 2014 and 2015 International Workshops on Semantic Evaluation (SemEval).", "labels": [], "entities": [{"text": "International Workshops on Semantic Evaluation (SemEval)", "start_pos": 67, "end_pos": 123, "type": "TASK", "confidence": 0.506223239004612}]}, {"text": "There are two key dimensions of the data-driven dependency parsing approach: decoding and disambiguation.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 48, "end_pos": 66, "type": "TASK", "confidence": 0.6538435965776443}]}, {"text": "Existing decoding approaches to syntactic or semantic analysis into bilexical dependencies can be categorized into two dominant types: transition-based () and graph-based, i.e., Maximum Subgraph () approaches.", "labels": [], "entities": [{"text": "syntactic or semantic analysis", "start_pos": 32, "end_pos": 62, "type": "TASK", "confidence": 0.6163391247391701}]}, {"text": "For disambiguation, while early work on dependency parsing focused on global linear models, e.g., structured perceptron), recent work shows that deep learning techniques, e.g., LSTM, is able to significantly advance the state-of-the-art of the parsing accuracy.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 40, "end_pos": 58, "type": "TASK", "confidence": 0.8041575253009796}, {"text": "parsing", "start_pos": 244, "end_pos": 251, "type": "TASK", "confidence": 0.9683203101158142}, {"text": "accuracy", "start_pos": 252, "end_pos": 260, "type": "METRIC", "confidence": 0.569378137588501}]}, {"text": "From the above two perspectives, i.e., the decoding and disambiguation frameworks, we find that what is still underexploited is neural Maximum Subgraph parsing for highly constrained graph classes, e.g., noncrossing graphs.", "labels": [], "entities": [{"text": "neural Maximum Subgraph parsing", "start_pos": 128, "end_pos": 159, "type": "TASK", "confidence": 0.6590903103351593}]}, {"text": "In this paper, we fill this gap in the literature by developing a neural Maximum Subgraph parser.", "labels": [], "entities": []}, {"text": "Previous work showed that the 1-endpointcrossing, pagenumber-2 (1EC/P2) graphs are an appropriate graph class for modeling semantic dependency structures.", "labels": [], "entities": []}, {"text": "In this paper, we build a parser that targets 1EC/P2 graphs.", "labels": [], "entities": []}, {"text": "Based on an efficient first-order Maximum Subgraph decoder, we implement a data-driven parser that scores arcs based on stacked bidirectional-LSTM (BiLSTM) together with a multi-layer perceptron.", "labels": [], "entities": []}, {"text": "Using the benchmark data sets from the, our parser gives very competitive results for English semantic parsing.", "labels": [], "entities": [{"text": "English semantic parsing", "start_pos": 86, "end_pos": 110, "type": "TASK", "confidence": 0.707473357518514}]}, {"text": "To test the ability for crosslingual parsing, we also conduct experiments on the Chinese CCGBank ( and Enju HPSGBank () data.", "labels": [], "entities": [{"text": "crosslingual parsing", "start_pos": 24, "end_pos": 44, "type": "TASK", "confidence": 0.7572903633117676}, {"text": "Chinese CCGBank", "start_pos": 81, "end_pos": 96, "type": "DATASET", "confidence": 0.9040414094924927}, {"text": "Enju HPSGBank () data", "start_pos": 103, "end_pos": 124, "type": "DATASET", "confidence": 0.8781256824731827}]}, {"text": "Our parser plays equally well for Chinese, resulting in an error reduction of 23.5% and 9.4% over the best published result reported in and.", "labels": [], "entities": [{"text": "error reduction", "start_pos": 59, "end_pos": 74, "type": "METRIC", "confidence": 0.9863225519657135}]}, {"text": "Most studies on semantic parsing focused on the in-domain setting, meaning that both training and testing data are drawn from the same domain.", "labels": [], "entities": [{"text": "semantic parsing", "start_pos": 16, "end_pos": 32, "type": "TASK", "confidence": 0.8456320464611053}]}, {"text": "Even a data-driven parsing system achieves a high in-domain accuracy, it usually performs rather poorly on the out-of-domain data.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 60, "end_pos": 68, "type": "METRIC", "confidence": 0.9889473915100098}]}, {"text": "How to build robust semantic dependency parsers that can learn across domains remains an under-addressed problem.", "labels": [], "entities": []}, {"text": "To improve the cross-domain parsing performance, we propose a data-oriented model to explore the linguistic generality encoded in a hand-crafted, domainindependent, linguistically-precise English grammar, namely English Resource Grammar).", "labels": [], "entities": [{"text": "cross-domain parsing", "start_pos": 15, "end_pos": 35, "type": "TASK", "confidence": 0.7133115828037262}]}, {"text": "In particular, we introduce a cost-sensitive training model to learn crossdomain semantic information implicitly encoded in WikiWoods (, i.e., a corpus that collects the wikipedia 1 texts as well as their automatic syntactico-semantic annotations produced by ERG.", "labels": [], "entities": []}, {"text": "Evaluation demonstrates the usefulness of the imperfect annotations automatically created by ERG.", "labels": [], "entities": []}, {"text": "Our parser is available at https://github.", "labels": [], "entities": []}, {"text": "com/draplater/msg-parser.", "labels": [], "entities": []}], "datasetContent": [{"text": "Since around 2001, the ERG has been accompanied by syntactico-semantic annotations, where for each sentence an annotator has selected the intended analysis among all alternatives licensed by the grammar.", "labels": [], "entities": []}, {"text": "This derived resource, namly Redwoods 6 (, is a collection of hand-annotated corpora and consists of data sets from several distinct domains.", "labels": [], "entities": [{"text": "namly Redwoods 6", "start_pos": 23, "end_pos": 39, "type": "DATASET", "confidence": 0.9653715292612711}]}, {"text": "Redwoods also includes (re)treebanking results of the first 22 sections of the venerable Wall Street Journal (WSJ) text and the section of Brown Corpus in the Penn Treebank.", "labels": [], "entities": [{"text": "Wall Street Journal (WSJ) text", "start_pos": 89, "end_pos": 119, "type": "DATASET", "confidence": 0.9463860477719989}, {"text": "Brown Corpus in the Penn Treebank", "start_pos": 139, "end_pos": 172, "type": "DATASET", "confidence": 0.9251644611358643}]}, {"text": "The WSJ part is also known as Deep-Bank ( , which provides automatically created annotations for the texts from wikipedia.", "labels": [], "entities": [{"text": "WSJ", "start_pos": 4, "end_pos": 7, "type": "DATASET", "confidence": 0.8535307049751282}]}, {"text": "The annotations are disambiguated using the MaxEnt model trained using redwoods without DeepBank.", "labels": [], "entities": [{"text": "MaxEnt", "start_pos": 44, "end_pos": 50, "type": "DATASET", "confidence": 0.8982235193252563}, {"text": "DeepBank", "start_pos": 88, "end_pos": 96, "type": "DATASET", "confidence": 0.9629537463188171}]}, {"text": "We use a small portion of Wikiwoods, which contains 857,329 sentences in total.", "labels": [], "entities": [{"text": "Wikiwoods", "start_pos": 26, "end_pos": 35, "type": "DATASET", "confidence": 0.9210271239280701}]}, {"text": "To evaluate the (positive) impact of ERG on out-of-domain parsing, we conduct experiments on the DM data.", "labels": [], "entities": [{"text": "DM data", "start_pos": 97, "end_pos": 104, "type": "DATASET", "confidence": 0.7972423434257507}]}, {"text": "The first group of experiments are designed to be comparable with the results obtained by various participant systems of SemEval 2015.", "labels": [], "entities": []}, {"text": "The detailed data set-up is as follows: \u2022 Test Data.", "labels": [], "entities": [{"text": "Test Data", "start_pos": 42, "end_pos": 51, "type": "DATASET", "confidence": 0.8020243942737579}]}, {"text": "We use the Brown corpus section which is provided by SemEval 2015.", "labels": [], "entities": [{"text": "Brown corpus section", "start_pos": 11, "end_pos": 31, "type": "DATASET", "confidence": 0.968035360177358}]}, {"text": "We use three data sets for training: (1) DeepBank, (2) RedWoods and (3) a small portion of WikiWoods reparsed using the MaxEnt model trained on DeepBank.", "labels": [], "entities": [{"text": "DeepBank", "start_pos": 41, "end_pos": 49, "type": "DATASET", "confidence": 0.9515835046768188}]}, {"text": "We denote this reparsed WikiWoods as WikiWoods-ACE, since the HPSG analysis is provided by the ACE parser.", "labels": [], "entities": []}, {"text": "To extract the semantic dependency graph, we use the pydelphin tool 8 . For the second group of experiments, we use the section wsj21 from the DeepBank as test data, which is the official in-domain test of the SemEval 2015.", "labels": [], "entities": []}, {"text": "The training data includes the \"RedWoods minus DeepBank\" annotations (RedwoodsWOD for short) as well as the official WikiWoods annotations.", "labels": [], "entities": []}, {"text": "Note that the MaxEnt model used to obtain the official WikiWoods annotations are compatible with RedwoodswWOD.", "labels": [], "entities": [{"text": "RedwoodswWOD", "start_pos": 97, "end_pos": 109, "type": "DATASET", "confidence": 0.9663255214691162}]}, {"text": "Due to the diversity of the RedwoodsWOD and DeepBank sentences, this set-up can also be viewed as an outof-domain evaluation.: Labeled F1 on the DM test sets.", "labels": [], "entities": [{"text": "F1", "start_pos": 135, "end_pos": 137, "type": "METRIC", "confidence": 0.9887228012084961}, {"text": "DM test sets", "start_pos": 145, "end_pos": 157, "type": "DATASET", "confidence": 0.8841173450152079}]}, {"text": "\"S\" denotes single model, while \"E\" denotes ensemble model with 3 sub-models.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Labeled F1 on the test data from SemEval 2015.", "labels": [], "entities": [{"text": "F1", "start_pos": 18, "end_pos": 20, "type": "METRIC", "confidence": 0.9594883322715759}, {"text": "test data from SemEval 2015", "start_pos": 28, "end_pos": 55, "type": "DATASET", "confidence": 0.7681426763534546}]}, {"text": " Table 2: Hyper-parameter setting of our model.", "labels": [], "entities": []}, {"text": " Table 4: Labeled F1 on the test set of SemEval 2015 for", "labels": [], "entities": [{"text": "F1", "start_pos": 18, "end_pos": 20, "type": "METRIC", "confidence": 0.9887533187866211}, {"text": "test set of SemEval 2015", "start_pos": 28, "end_pos": 52, "type": "DATASET", "confidence": 0.7457141399383544}]}, {"text": " Table 5: Labeled F1 on the test set of Chinese CCGBank.", "labels": [], "entities": [{"text": "F1", "start_pos": 18, "end_pos": 20, "type": "METRIC", "confidence": 0.9940504431724548}, {"text": "Chinese CCGBank", "start_pos": 40, "end_pos": 55, "type": "DATASET", "confidence": 0.8998944759368896}]}]}