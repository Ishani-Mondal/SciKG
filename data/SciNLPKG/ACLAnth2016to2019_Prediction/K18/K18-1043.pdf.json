{"title": [{"text": "DIMSIM: An Accurate Chinese Phonetic Similarity Algorithm based on Learned High Dimensional Encoding", "labels": [], "entities": [{"text": "Chinese Phonetic Similarity Algorithm", "start_pos": 20, "end_pos": 57, "type": "TASK", "confidence": 0.6594386845827103}]}], "abstractContent": [{"text": "Phonetic similarity algorithms identify words and phrases with similar pronunciation which are used in many natural language processing tasks.", "labels": [], "entities": []}, {"text": "However, existing approaches are designed mainly for Indo-European languages and fail to capture the unique properties of Chinese pronunciation.", "labels": [], "entities": []}, {"text": "In this paper, we propose a high dimensional encoded phonetic similarity algorithm for Chinese, DIMSIM.", "labels": [], "entities": []}, {"text": "The encodings are learned from annotated data to separately map initial and final phonemes into n-dimensional coordinates.", "labels": [], "entities": []}, {"text": "Pinyin pho-netic similarities are then calculated by aggre-gating the similarities of initial, final and tone.", "labels": [], "entities": []}, {"text": "DIMSIM demonstrates a 7.5X improvement on mean reciprocal rank over the state-of-the-art phonetic similarity approaches.", "labels": [], "entities": [{"text": "DIMSIM", "start_pos": 0, "end_pos": 6, "type": "DATASET", "confidence": 0.87322598695755}, {"text": "mean reciprocal rank", "start_pos": 42, "end_pos": 62, "type": "METRIC", "confidence": 0.8558931946754456}]}], "introductionContent": [{"text": "Performing the mental gymnastics of transforming 'I'm hear' to 'I'm here,' or, 'I can't so buttons' to 'I can't sew buttons,' is familiar to anyone who has encountered autocorrected text messages, punny social media posts, or just friends with bad grammar.", "labels": [], "entities": []}, {"text": "Although at first glance it may seem that phonetic similarity can only be quantified for audible words, this problem is often present in purely textual spaces, such as social media posts or text messages.", "labels": [], "entities": []}, {"text": "Incorrect homophones and synophones, whether used in error or in jest, pose challenges fora wide range of NLP tasks, such as named entity identification, text normalization and spelling correction;).", "labels": [], "entities": [{"text": "named entity identification", "start_pos": 125, "end_pos": 152, "type": "TASK", "confidence": 0.629574199517568}, {"text": "text normalization", "start_pos": 154, "end_pos": 172, "type": "TASK", "confidence": 0.790568619966507}, {"text": "spelling correction", "start_pos": 177, "end_pos": 196, "type": "TASK", "confidence": 0.8398467600345612}]}, {"text": "These tasks must therefore successfully transform incorrect words or phrases ('hear','so') to their phonetically similar correct counterparts ('here','sew'), which in turn requires a robust representation of phonetic similarity between word pairs.", "labels": [], "entities": []}, {"text": "A reli-   able approach for generating phonetically similar words is equally crucial for Chinese text).", "labels": [], "entities": []}, {"text": "Unfortunately, most existing phonetic similarity algorithms such as and Double Metaphone (DM) are motivated by English and designed for Indo-European languages.", "labels": [], "entities": []}, {"text": "Words are encoded to approximate phonetic presentations by ignoring vowels (except foremost ones), which is appropriate where phonetic transcription consists of a sequence of phonemes, such as for English.", "labels": [], "entities": []}, {"text": "In contrast, the speech sound of a Chinese character is represented by a single syllable in Pinyin consisting of two or three parts: an initial (optional), a final or compound finals, and tone 1 (Table 1).", "labels": [], "entities": []}, {"text": "As a result, phonetic similarity approaches designed for Indo-European languages often fall short when applied to Chinese text.", "labels": [], "entities": []}, {"text": "Note that we use Pinyin as the phonetic representation because it is a widely accepted Romanization system of Chinese syllables, used to teach pronunciation of standard Chinese.", "labels": [], "entities": []}, {"text": "shows two sentences from Chinese microblogs, containing informal words derived from phonetic transcription.", "labels": [], "entities": []}, {"text": "The DM and Soundex encodings for S:S,FN:FN X000,F500 \u559cxi2\u6b22huan1 S:S,HN:HN X000,H500 \u6cc4xie4\u6124fen4 S:S,FN:FN X000,F500 zh ch sh z c s near-homonyms of \u559c\u6b22 from are shown in.", "labels": [], "entities": []}, {"text": "Since both DM and Soundex ignore vowels and tones, words with dissimilar pronunciations are incorrectly assigned to the same encoding (e.g. \u7a00 \u996d and \u6cc4 \u6124), while true nearhomonyms are encoded much further apart (e.g. \u7a00\u996d and \u559c\u6b22).", "labels": [], "entities": []}, {"text": "On the other hand, additional candidates with similar phonetic distances such as \u5fc3xin1\u70e6fan2\uff0c\u897fxi1\u65b9fang1 for \u7a00\u996d should be generated, for consumption by downstream applications such as text normalization.", "labels": [], "entities": [{"text": "text normalization", "start_pos": 182, "end_pos": 200, "type": "TASK", "confidence": 0.7968094348907471}]}, {"text": "The example highlights the importance of considering all Pinyin components and their characteristics when calculating Chinese phonetic similarity ().", "labels": [], "entities": []}, {"text": "One recent work manually assigns a single numerical number to encode and derive phonetic similarity.", "labels": [], "entities": []}, {"text": "However, this single-encoding approach is inaccurate since the phonetic distances between Pinyins are not captured well in a one dimensional space.", "labels": [], "entities": []}, {"text": "illustrates the similarities between a subset of initials.", "labels": [], "entities": []}, {"text": "Initial groups \"z, c\", \"zh, ch\", \"z, zh\" and \"zh, ch\" are all similar, which cannot be captured using a one dimensional representation (e.g., an encoding of \"zh=0,z=1,c=2,ch=3\" fails to identify the \"zh, ch\" pair as similar.)", "labels": [], "entities": []}, {"text": "ALINE is another illustration of the challenge of manually assigning numerical values in order to accurately represent the complex relative phonetic similarity relationships across various languages.", "labels": [], "entities": []}, {"text": "Therefore, given the perceptual nature of the problem of phonetic similarity, it is critical to learn the distances based on as much empirical data as possible, rather than using a manually encoded metric.", "labels": [], "entities": []}, {"text": "This paper presents DIMSIM, a learned ndimensional phonetic encoding for Chinese along with a phonetic similarity algorithm, which uses the encoding to generate and rank phonetically similar words.", "labels": [], "entities": []}, {"text": "To address the complexity of relative phonetic similarities in Pinyin components, we propose a supervised learning approach to learn n dimensional encodings for finals and initials where n can be easily extended from one to two or higher dimensions.", "labels": [], "entities": []}, {"text": "The learning model derives accurate encodings by jointly considering Pinyin linguistic characteristics, such as place of articulation and pronunciation methods, as well as high quality annotated training data sets.", "labels": [], "entities": []}, {"text": "We compare DIMSIM to Double Metaphone(DM), Minimum edit distance(MED) and ALINE demonstrating that DIMSIM outperforms these algorithms by 7.5X on mean reciprocal rank, 1.4X on precision and 1.5X on recall on a real-world dataset.", "labels": [], "entities": [{"text": "Minimum edit distance(MED)", "start_pos": 43, "end_pos": 69, "type": "METRIC", "confidence": 0.9174670378367106}, {"text": "ALINE", "start_pos": 74, "end_pos": 79, "type": "METRIC", "confidence": 0.997978150844574}, {"text": "precision", "start_pos": 176, "end_pos": 185, "type": "METRIC", "confidence": 0.998008668422699}, {"text": "recall", "start_pos": 198, "end_pos": 204, "type": "METRIC", "confidence": 0.9991740584373474}]}], "datasetContent": [{"text": "We collect 350 words from social media, and annotate each with 1-3 phonetically similar words.", "labels": [], "entities": []}, {"text": "We use a communitymaintained free dictionary to map characters to Pinyins.", "labels": [], "entities": []}, {"text": "We compare DIMSIM with Double Metaphone (DM)), ALINE and Minimum edit distance (MED)) in terms of precision (P), recall (R), and average Mean Reciprocal Rank (MRR)).", "labels": [], "entities": [{"text": "ALINE", "start_pos": 47, "end_pos": 52, "type": "METRIC", "confidence": 0.9971848130226135}, {"text": "Minimum edit distance (MED))", "start_pos": 57, "end_pos": 85, "type": "METRIC", "confidence": 0.9392196039358774}, {"text": "precision (P)", "start_pos": 98, "end_pos": 111, "type": "METRIC", "confidence": 0.9642994850873947}, {"text": "recall (R)", "start_pos": 113, "end_pos": 123, "type": "METRIC", "confidence": 0.963859349489212}, {"text": "average Mean Reciprocal Rank (MRR))", "start_pos": 129, "end_pos": 164, "type": "METRIC", "confidence": 0.923071529184069}]}, {"text": "We calculate recall automatically using the the full test set of word pairs.", "labels": [], "entities": [{"text": "recall", "start_pos": 13, "end_pos": 19, "type": "METRIC", "confidence": 0.9986697435379028}]}, {"text": "Since downstream applications will only consider a limited number of candidates in practice, we evaluate precision via a manual annotation task on the top-ranked candidates generated by each approach.", "labels": [], "entities": [{"text": "precision", "start_pos": 105, "end_pos": 114, "type": "METRIC", "confidence": 0.9993013143539429}]}, {"text": "DM considers word spelling, pronunciation and other miscellaneous characteristics to encode the word into a primary and a secondary code.", "labels": [], "entities": [{"text": "DM", "start_pos": 0, "end_pos": 2, "type": "DATASET", "confidence": 0.5936854481697083}, {"text": "word spelling", "start_pos": 13, "end_pos": 26, "type": "TASK", "confidence": 0.6840748339891434}]}, {"text": "DM as one of the baselines is known to perform poorly at ranking the candidates) since only two codes are used.", "labels": [], "entities": [{"text": "DM", "start_pos": 0, "end_pos": 2, "type": "METRIC", "confidence": 0.40304872393608093}]}, {"text": "We therefore use our method (Equation 1) to rank the DM-generated candidates, to create a second baseline, DM-rank.", "labels": [], "entities": []}, {"text": "The third baseline, ALINE, measures phonetic similarity based on manually coded multi-valued articulatory features weighted by their relative importance with respect to feature salience (again, manually determined).", "labels": [], "entities": [{"text": "ALINE", "start_pos": 20, "end_pos": 25, "type": "METRIC", "confidence": 0.9835757613182068}]}, {"text": "MED, the last baseline, computes similarity as the minimum-weight series of edit operations that transforms one sound component into another.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 4: Table of Pinyin initials (colors denote clusters).", "labels": [], "entities": []}, {"text": " Table 4: Variations of \u03b8,\u03c4 .", "labels": [], "entities": []}, {"text": " Table 4: F11, F22, F33, F44, but the near- identical performance of these variations demon- strates DIMSIM's robustness to the particular scor- ing and penalty functions used. Note that not using  a penalty function impacts MRR significantly.", "labels": [], "entities": [{"text": "F11", "start_pos": 10, "end_pos": 13, "type": "METRIC", "confidence": 0.9954400062561035}, {"text": "MRR", "start_pos": 225, "end_pos": 228, "type": "TASK", "confidence": 0.7911725044250488}]}]}