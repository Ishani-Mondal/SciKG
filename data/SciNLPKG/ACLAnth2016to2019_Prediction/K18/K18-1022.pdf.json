{"title": [{"text": "Simple Unsupervised Keyphrase Extraction using Sentence Embeddings", "labels": [], "entities": [{"text": "Keyphrase Extraction", "start_pos": 20, "end_pos": 40, "type": "TASK", "confidence": 0.6256324052810669}]}], "abstractContent": [{"text": "Keyphrase extraction is the task of automatically selecting a small set of phrases that best describe a given free text document.", "labels": [], "entities": [{"text": "Keyphrase extraction", "start_pos": 0, "end_pos": 20, "type": "TASK", "confidence": 0.7902204096317291}]}, {"text": "Supervised keyphrase extraction requires large amounts of labeled training data and generalizes very poorly outside the domain of the training data.", "labels": [], "entities": [{"text": "keyphrase extraction", "start_pos": 11, "end_pos": 31, "type": "TASK", "confidence": 0.882786214351654}]}, {"text": "At the same time, unsuper-vised systems have poor accuracy, and often do not generalize well, as they require the input document to belong to a larger corpus also given as input.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 50, "end_pos": 58, "type": "METRIC", "confidence": 0.9987927675247192}]}, {"text": "Addressing these drawbacks, in this paper, we tackle keyphrase extraction from single documents with EmbedRank: a novel unsupervised method, that leverages sentence embeddings.", "labels": [], "entities": [{"text": "keyphrase extraction from single documents", "start_pos": 53, "end_pos": 95, "type": "TASK", "confidence": 0.8640304684638977}]}, {"text": "EmbedRank achieves higher F-scores than graph-based state of the art systems on standard datasets and is suitable for real-time processing of large amounts of Web data.", "labels": [], "entities": [{"text": "F-scores", "start_pos": 26, "end_pos": 34, "type": "METRIC", "confidence": 0.9963990449905396}]}, {"text": "With EmbedRank, we also explicitly increase coverage and diversity among the selected keyphrases by introducing an embedding-based maximal marginal relevance (MMR) for new phrases.", "labels": [], "entities": [{"text": "coverage", "start_pos": 44, "end_pos": 52, "type": "METRIC", "confidence": 0.9636185765266418}, {"text": "embedding-based maximal marginal relevance (MMR)", "start_pos": 115, "end_pos": 163, "type": "METRIC", "confidence": 0.7435453363827297}]}, {"text": "A user study including over 200 votes showed that, although reducing the phrases' semantic overlap leads to no gains in F-score, our high diversity selection is preferred by humans.", "labels": [], "entities": [{"text": "F-score", "start_pos": 120, "end_pos": 127, "type": "METRIC", "confidence": 0.9985382556915283}]}], "introductionContent": [{"text": "Document keywords and keyphrases enable faster and more accurate search in large text collections, serve as condensed document summaries, and are used for various other applications, such as categorization of documents.", "labels": [], "entities": [{"text": "categorization of documents", "start_pos": 191, "end_pos": 218, "type": "TASK", "confidence": 0.8440098762512207}]}, {"text": "In particular, keyphrase extraction is a crucial component when gleaning real-time insights from large amounts of Web and social media data.", "labels": [], "entities": [{"text": "keyphrase extraction", "start_pos": 15, "end_pos": 35, "type": "TASK", "confidence": 0.8846713602542877}]}, {"text": "In this case, the extraction must be fast and the keyphrases must be disjoint.", "labels": [], "entities": []}, {"text": "Most existing systems are slow and plagued by overgeneration, i.e. extracting redundant keyphrases.", "labels": [], "entities": []}, {"text": "Here, we address both these problems with anew unsupervised algorithm.", "labels": [], "entities": []}, {"text": "Unsupervised keyphrase extraction has a series of advantages over supervised methods.", "labels": [], "entities": [{"text": "keyphrase extraction", "start_pos": 13, "end_pos": 33, "type": "TASK", "confidence": 0.8412347137928009}]}, {"text": "Supervised keyphrase extraction always requires the existence of a (large) annotated corpus of both documents and their manually selected keyphrases to train on -a very strong requirement inmost cases.", "labels": [], "entities": [{"text": "keyphrase extraction", "start_pos": 11, "end_pos": 31, "type": "TASK", "confidence": 0.7422734797000885}]}, {"text": "Supervised methods also perform poorly outside of the domain represented by the training corpus -a big issue, considering that the domain of new documents may not be known at all.", "labels": [], "entities": []}, {"text": "Unsupervised keyphrase extraction addresses such informationconstrained situations in one of two ways: (a) by relying on in-corpus statistical information (e.g., the inverse document frequency of the words), and the current document; (b) by only using information extracted from the current document.", "labels": [], "entities": [{"text": "keyphrase extraction", "start_pos": 13, "end_pos": 33, "type": "TASK", "confidence": 0.765640527009964}]}, {"text": "We propose EmbedRank -an unsupervised method to automatically extract keyphrases from a document, that is both simple and only requires the current document itself, rather than an entire corpus that this document maybe linked to.", "labels": [], "entities": []}, {"text": "Our method relies on notable new developments in text representation learning (, where documents or word sequences of arbitrary length are embedded into the same continuous vector space.", "labels": [], "entities": [{"text": "text representation learning", "start_pos": 49, "end_pos": 77, "type": "TASK", "confidence": 0.807680626710256}]}, {"text": "This opens the way to computing semantic relatedness among text fragments by using the induced similarity measures in that feature space.", "labels": [], "entities": [{"text": "computing semantic relatedness among text fragments", "start_pos": 22, "end_pos": 73, "type": "TASK", "confidence": 0.7201714615027109}]}, {"text": "Using these semantic text representations, we guarantee the two most challenging properties of keyphrases: informativeness obtained by the distance between the embedding of a candidate phrase and that of the full document; diversity expressed by the distances among candidate phrases themselves.", "labels": [], "entities": []}, {"text": "Ina traditional F-score evaluation, EmbedRank clearly outperforms the current state of the art (i.e. complex graph-based methods (; Rui Wang, Wei Liu, 2015)) on two out of three common datasets for keyphrase extraction.", "labels": [], "entities": [{"text": "keyphrase extraction", "start_pos": 198, "end_pos": 218, "type": "TASK", "confidence": 0.8626165390014648}]}, {"text": "We also evaluated the impact of ensuring diversity by conducting a user study, since this aspect cannot be captured by the F-score evaluation.", "labels": [], "entities": [{"text": "F-score", "start_pos": 123, "end_pos": 130, "type": "METRIC", "confidence": 0.9820924997329712}]}, {"text": "The study showed that users highly prefer keyphrases with the diversity property.", "labels": [], "entities": []}, {"text": "Finally, to the best of our knowledge, we are the first to present an unsupervised method based on phrase and document embeddings for keyphrase extraction, as opposed to standard individual word embeddings.", "labels": [], "entities": [{"text": "keyphrase extraction", "start_pos": 134, "end_pos": 154, "type": "TASK", "confidence": 0.7758292555809021}]}, {"text": "The paper is organized as follows.", "labels": [], "entities": []}, {"text": "Related work on keyphrase extraction and sentence embeddings is presented in Section 2.", "labels": [], "entities": [{"text": "keyphrase extraction", "start_pos": 16, "end_pos": 36, "type": "TASK", "confidence": 0.8515980541706085}]}, {"text": "In Section 3 we present how our method works.", "labels": [], "entities": []}, {"text": "An enhancement of the method allowing us to gain a control over the redundancy of the extracted keyphrases is then described in Section 4.", "labels": [], "entities": []}, {"text": "Section 5 contains the different experiments that we performed and Section 6 outlines the importance of Embedrank in realworld examples.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section we show that EmbedRank outperforms the graph-based state-of-the-art schemes on the most common datasets, when using traditional F-score evaluation.", "labels": [], "entities": []}, {"text": "In addition, we report on the results of a sizable user study showing that, although EmbedRank++ achieves slightly lower Fscores than EmbedRank, users prefer the semantically diverse keyphrases it returns to those computed by the other method.", "labels": [], "entities": [{"text": "Fscores", "start_pos": 121, "end_pos": 128, "type": "METRIC", "confidence": 0.9993628859519958}]}, {"text": "describes three common datasets for keyphrase extraction.", "labels": [], "entities": [{"text": "keyphrase extraction", "start_pos": 36, "end_pos": 56, "type": "TASK", "confidence": 0.8728393614292145}]}, {"text": "The Inspec dataset consists of 2 000 short documents from scientific journal abstracts.", "labels": [], "entities": [{"text": "Inspec dataset", "start_pos": 4, "end_pos": 18, "type": "DATASET", "confidence": 0.9326516389846802}]}, {"text": "To compare with previous work, we evaluated our methods on the test dataset (500 documents).", "labels": [], "entities": []}, {"text": "consists of 308 medium length newspaper articles from TREC-9.", "labels": [], "entities": [{"text": "TREC-9", "start_pos": 54, "end_pos": 60, "type": "DATASET", "confidence": 0.8439293503761292}]}, {"text": "The documents originate from several newspapers and are organized in 30 topics.", "labels": [], "entities": []}, {"text": "For keyphrase extraction, we used exclusively the text contained in the first <TEXT> tags of the original documents (we do not use titles and other metadata).", "labels": [], "entities": [{"text": "keyphrase extraction", "start_pos": 4, "end_pos": 24, "type": "TASK", "confidence": 0.8951742947101593}]}, {"text": "NUS ( consists of 211 long documents (full scientific conference papers), of between 4 and 12 pages.", "labels": [], "entities": [{"text": "NUS (", "start_pos": 0, "end_pos": 5, "type": "DATASET", "confidence": 0.9598183333873749}]}, {"text": "Each document has several sets of keyphrases: one created by the authors and, potentially, several others created by annotators.", "labels": [], "entities": []}, {"text": "Following, we evaluate on the union of all sets of assigned keyphrases (author and annotator(s)).", "labels": [], "entities": []}, {"text": "The dataset is very similar to the SemEval dataset which is also often used for keyphrase extraction.", "labels": [], "entities": [{"text": "SemEval dataset", "start_pos": 35, "end_pos": 50, "type": "DATASET", "confidence": 0.7622429430484772}, {"text": "keyphrase extraction", "start_pos": 80, "end_pos": 100, "type": "TASK", "confidence": 0.8237281739711761}]}, {"text": "Since our results on SemEval are very similar to NUS, we omit them due to space constraints.", "labels": [], "entities": [{"text": "NUS", "start_pos": 49, "end_pos": 52, "type": "DATASET", "confidence": 0.9048356413841248}]}, {"text": "As shown in, not all assigned keyphrases are present in the documents (missing kp in doc).", "labels": [], "entities": []}, {"text": "It is thus impossible to achieve a recall of 100%.", "labels": [], "entities": [{"text": "recall", "start_pos": 35, "end_pos": 41, "type": "METRIC", "confidence": 0.9996286630630493}]}, {"text": "We show in the next subsection that our method beats the state of the art on short scientific documents and clearly outperforms it on medium length news articles.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: The three datasets we use. Columns are: number of documents; average number of tokens  per document; average number of unique candidates per document; total number of unique keyphrases;  average number of unique keyphrases per document; percentage of keyphrases not present in the docu- ments; percentage of keyphrases not present in the candidates; percentage of keyphrases present in the  document, but not in the candidates. These statistics were computed after stemming the candidates, the  keyphrases and the document.", "labels": [], "entities": []}]}