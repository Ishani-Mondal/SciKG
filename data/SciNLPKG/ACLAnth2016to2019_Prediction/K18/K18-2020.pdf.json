{"title": [{"text": "UDPipe 2.0 Prototype at CoNLL 2018 UD Shared Task", "labels": [], "entities": [{"text": "UDPipe 2.0 Prototype at CoNLL 2018 UD Shared Task", "start_pos": 0, "end_pos": 49, "type": "DATASET", "confidence": 0.8157931301328871}]}], "abstractContent": [{"text": "UDPipe is a trainable pipeline which performs sentence segmentation, tokeniza-tion, POS tagging, lemmatization and dependency parsing (Straka et al., 2016).", "labels": [], "entities": [{"text": "UDPipe", "start_pos": 0, "end_pos": 6, "type": "DATASET", "confidence": 0.8756203651428223}, {"text": "sentence segmentation", "start_pos": 46, "end_pos": 67, "type": "TASK", "confidence": 0.7498278021812439}, {"text": "POS tagging", "start_pos": 84, "end_pos": 95, "type": "TASK", "confidence": 0.8546899855136871}, {"text": "dependency parsing", "start_pos": 115, "end_pos": 133, "type": "TASK", "confidence": 0.8108668327331543}]}, {"text": "We present a prototype for UDPipe 2.0 and evaluate it in the CoNLL 2018 UD Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies, which employs three metrics for submission ranking.", "labels": [], "entities": [{"text": "CoNLL 2018 UD Shared Task", "start_pos": 61, "end_pos": 86, "type": "DATASET", "confidence": 0.8775386214256287}, {"text": "Multilingual Parsing from Raw Text", "start_pos": 88, "end_pos": 122, "type": "TASK", "confidence": 0.7050399959087372}]}, {"text": "Out of 26 participants, the prototype placed first in the MLAS ranking, third in the LAS ranking and third in the BLEX ranking.", "labels": [], "entities": [{"text": "MLAS ranking", "start_pos": 58, "end_pos": 70, "type": "DATASET", "confidence": 0.7497102320194244}, {"text": "LAS", "start_pos": 85, "end_pos": 88, "type": "METRIC", "confidence": 0.7486988306045532}, {"text": "BLEX", "start_pos": 114, "end_pos": 118, "type": "METRIC", "confidence": 0.9196569919586182}]}, {"text": "In extrinsic parser evaluation EPE 2018, the system ranked first in the overall score.", "labels": [], "entities": [{"text": "extrinsic parser evaluation EPE", "start_pos": 3, "end_pos": 34, "type": "TASK", "confidence": 0.7728429734706879}]}, {"text": "The prototype utilizes an artificial neu-ral network with a single joint model for POS tagging, lemmatization and dependency parsing, and is trained only using the CoNLL-U training data and pretrained word embeddings, contrary to both systems surpassing the prototype in the LAS and BLEX ranking in the shared task.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 83, "end_pos": 94, "type": "TASK", "confidence": 0.8168534934520721}, {"text": "dependency parsing", "start_pos": 114, "end_pos": 132, "type": "TASK", "confidence": 0.7793113887310028}, {"text": "CoNLL-U training data", "start_pos": 164, "end_pos": 185, "type": "DATASET", "confidence": 0.8650038441022238}, {"text": "LAS", "start_pos": 275, "end_pos": 278, "type": "METRIC", "confidence": 0.8045529127120972}, {"text": "BLEX", "start_pos": 283, "end_pos": 287, "type": "METRIC", "confidence": 0.9733366966247559}]}, {"text": "The open-source code of the prototype is available at http://github.com/ CoNLL-UD-2018/UDPipe-Future.", "labels": [], "entities": []}, {"text": "After the shared task, we slightly refined the model architecture, resulting in better performance both in the intrinsic evaluation (corresponding to first, second and second rank in MLAS, LAS and BLEX shared task metrics) and the extrinsic evaluation.", "labels": [], "entities": [{"text": "MLAS", "start_pos": 183, "end_pos": 187, "type": "DATASET", "confidence": 0.7514610886573792}, {"text": "BLEX", "start_pos": 197, "end_pos": 201, "type": "METRIC", "confidence": 0.9258610010147095}]}, {"text": "The improved models will be available shortly in UDPipe at", "labels": [], "entities": []}], "introductionContent": [{"text": "The Universal Dependencies project () seeks to develop cross-linguistically consistent treebank annotation of morphology and syntax for many languages.", "labels": [], "entities": []}, {"text": "The latest version of UD 2.2 ( ) consists of 122 dependency treebanks in 71 languages.", "labels": [], "entities": []}, {"text": "As such, the UD project represents an excellent data source for developing multi-lingual NLP tools which perform sentence segmentation, tokenization, POS tagging, lemmatization and dependency tree parsing.", "labels": [], "entities": [{"text": "sentence segmentation", "start_pos": 113, "end_pos": 134, "type": "TASK", "confidence": 0.7432883679866791}, {"text": "tokenization", "start_pos": 136, "end_pos": 148, "type": "TASK", "confidence": 0.9575374126434326}, {"text": "POS tagging", "start_pos": 150, "end_pos": 161, "type": "TASK", "confidence": 0.8594542443752289}, {"text": "dependency tree parsing", "start_pos": 181, "end_pos": 204, "type": "TASK", "confidence": 0.7187524835268656}]}, {"text": "The goal of the CoNLL 2018 Shared Tasks: Multilingual Parsing from Raw Text to Universal Dependencies (CoNLL 2018 UD Shared Task) is to stimulate research in multi-lingual dependency parsers which process raw text only.", "labels": [], "entities": [{"text": "Multilingual Parsing from Raw Text to Universal Dependencies (CoNLL 2018 UD Shared Task)", "start_pos": 41, "end_pos": 129, "type": "TASK", "confidence": 0.7553175707658132}]}, {"text": "The overview of the task and the results are presented in.", "labels": [], "entities": []}, {"text": "The current shared task is a reiteration of previous year's CoNLL 2017 UD Shared Task (.", "labels": [], "entities": [{"text": "CoNLL 2017 UD Shared Task", "start_pos": 60, "end_pos": 85, "type": "DATASET", "confidence": 0.8549857020378113}]}, {"text": "This paper describes our contribution to CoNLL 2018 UD Shared Task, a prototype of UDPipe 2.0.", "labels": [], "entities": [{"text": "CoNLL 2018 UD Shared Task", "start_pos": 41, "end_pos": 66, "type": "DATASET", "confidence": 0.7207780122756958}]}, {"text": "UDPipe ( is an open-source tool which automatically generates sentence segmentation, tokenization, POS tagging, lemmatization and dependency trees, using UD treebanks as training data.", "labels": [], "entities": [{"text": "UDPipe", "start_pos": 0, "end_pos": 6, "type": "DATASET", "confidence": 0.9250566363334656}, {"text": "sentence segmentation", "start_pos": 62, "end_pos": 83, "type": "TASK", "confidence": 0.7331187874078751}, {"text": "POS tagging", "start_pos": 99, "end_pos": 110, "type": "TASK", "confidence": 0.7773343920707703}]}, {"text": "The current version UDPipe 1.2 () is used as a baseline in CoNLL 2018 UD Shared Task.", "labels": [], "entities": [{"text": "CoNLL 2018 UD Shared Task", "start_pos": 59, "end_pos": 84, "type": "DATASET", "confidence": 0.8673931360244751}]}, {"text": "UDPipe 1.2 achieves low running times and moderately sized models, however, its performance is behind the current state-of-the-art, placing 13th, 17th and 18th in the three metrics (MLAS, LAS and BLEX, respectively).", "labels": [], "entities": [{"text": "UDPipe 1.2", "start_pos": 0, "end_pos": 10, "type": "DATASET", "confidence": 0.8882712423801422}, {"text": "MLAS", "start_pos": 182, "end_pos": 186, "type": "DATASET", "confidence": 0.7810569405555725}, {"text": "LAS", "start_pos": 188, "end_pos": 191, "type": "METRIC", "confidence": 0.9774826169013977}, {"text": "BLEX", "start_pos": 196, "end_pos": 200, "type": "METRIC", "confidence": 0.9944822788238525}]}, {"text": "As a participation system in the shared task, we therefore propose a prototype for UDPipe 2.0, with the goal of reaching state-of-theart performance.", "labels": [], "entities": []}], "datasetContent": [{"text": "The official CoNLL 2018 UD Shared Task results are presented in.", "labels": [], "entities": [{"text": "CoNLL 2018 UD Shared Task results", "start_pos": 13, "end_pos": 46, "type": "DATASET", "confidence": 0.8596777021884918}]}, {"text": "In addition to F1 scores, we also include rank of our submission (out of the 26 participant systems).", "labels": [], "entities": [{"text": "F1", "start_pos": 15, "end_pos": 17, "type": "METRIC", "confidence": 0.9996366500854492}]}, {"text": "In the three official metrics (LAS, MLAS and BLEX) our system reached third, first and third average performance.", "labels": [], "entities": [{"text": "LAS", "start_pos": 31, "end_pos": 34, "type": "METRIC", "confidence": 0.9394323825836182}, {"text": "MLAS", "start_pos": 36, "end_pos": 40, "type": "DATASET", "confidence": 0.6219696402549744}, {"text": "BLEX", "start_pos": 45, "end_pos": 49, "type": "METRIC", "confidence": 0.9971413016319275}]}, {"text": "Additionally, our system achieved best average performance in XPOS and AllTags metrics.", "labels": [], "entities": [{"text": "XPOS", "start_pos": 62, "end_pos": 66, "type": "DATASET", "confidence": 0.844063937664032}, {"text": "AllTags", "start_pos": 71, "end_pos": 78, "type": "DATASET", "confidence": 0.745743989944458}]}, {"text": "Furthermore, the lemmatization F1 score was the second best.", "labels": [], "entities": [{"text": "F1 score", "start_pos": 31, "end_pos": 39, "type": "METRIC", "confidence": 0.9570351839065552}]}, {"text": "Interestingly, although our system achieves highest average score in MLAS (which is a combination of dependency parsing and morphological features), it reaches only third best average LAS and fourth best average UFeats.", "labels": [], "entities": [{"text": "MLAS", "start_pos": 69, "end_pos": 73, "type": "DATASET", "confidence": 0.4964871406555176}, {"text": "dependency parsing", "start_pos": 101, "end_pos": 119, "type": "TASK", "confidence": 0.6924404054880142}]}, {"text": "Furthermore, the TurkuNLP participation system surpasses our system in both LAS and UFeats.", "labels": [], "entities": [{"text": "LAS", "start_pos": 76, "end_pos": 79, "type": "METRIC", "confidence": 0.6811392307281494}, {"text": "UFeats", "start_pos": 84, "end_pos": 90, "type": "DATASET", "confidence": 0.9257521629333496}]}, {"text": "We hypothesise that the high performance of our system in MLAS metric is caused by the fact that the tagger and parser models are joined, thus producing consistent annotations.", "labels": [], "entities": [{"text": "MLAS metric", "start_pos": 58, "end_pos": 69, "type": "DATASET", "confidence": 0.867616593837738}]}, {"text": "Finally, we note that the segmentation improvements outlined in Section 4.1 resulted in third average F1 score of our system.: Statistics of the model sizes.", "labels": [], "entities": [{"text": "segmentation", "start_pos": 26, "end_pos": 38, "type": "TASK", "confidence": 0.9726553559303284}, {"text": "F1 score", "start_pos": 102, "end_pos": 110, "type": "METRIC", "confidence": 0.9852667152881622}]}, {"text": "The results of our system are displayed in Table 2.", "labels": [], "entities": []}, {"text": "Even though our system ranked only 3 rd , 3 rd , and 7 thin the downstream task F1 scores, it was the best system in the overall score (and average of the three F1 scores).", "labels": [], "entities": [{"text": "F1", "start_pos": 80, "end_pos": 82, "type": "METRIC", "confidence": 0.9594389796257019}, {"text": "F1", "start_pos": 161, "end_pos": 163, "type": "METRIC", "confidence": 0.9825448393821716}]}, {"text": "All ablation experiment results in this section are performed using test sets of 61 so called \"big treebanks\", which are treebanks with provided development data, disregarding small treebanks and test treebanks without training data.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Statistics of number of lemma generation  rules for 73 treebank training sets of the CoNLL  2018 UD Shared Task.", "labels": [], "entities": [{"text": "CoNLL  2018 UD Shared Task", "start_pos": 95, "end_pos": 121, "type": "DATASET", "confidence": 0.843204653263092}]}, {"text": " Table 2: UDPipe 2.0 prototype results in EPE  2018. For each metric we present F1 score per- centage and also rank.", "labels": [], "entities": [{"text": "EPE", "start_pos": 42, "end_pos": 45, "type": "DATASET", "confidence": 0.8809604644775391}, {"text": "F1 score per- centage", "start_pos": 80, "end_pos": 101, "type": "METRIC", "confidence": 0.9449580550193787}]}, {"text": " Table 3: Statistics of the model sizes.", "labels": [], "entities": []}, {"text": " Table 4: Official CoNLL 2018 UD Shared Task results of the UDPipe 2.0 prototype. For each metric we  present F1 score percentage and also rank (out of the 26 participant systems).", "labels": [], "entities": [{"text": "Official CoNLL 2018 UD Shared Task", "start_pos": 10, "end_pos": 44, "type": "DATASET", "confidence": 0.753221129377683}, {"text": "F1 score percentage", "start_pos": 110, "end_pos": 129, "type": "METRIC", "confidence": 0.9779162804285685}]}, {"text": " Table 5: Average score of different variants of our system.", "labels": [], "entities": [{"text": "Average score", "start_pos": 10, "end_pos": 23, "type": "METRIC", "confidence": 0.9659247696399689}]}, {"text": " Table 6: Average runtime performance of our sys- tem.", "labels": [], "entities": []}]}