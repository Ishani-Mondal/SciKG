{"title": [{"text": "From Strings to Other Things: Linking the Neighborhood and Transposition effects in Word Reading", "labels": [], "entities": [{"text": "Word Reading", "start_pos": 84, "end_pos": 96, "type": "TASK", "confidence": 0.6808192878961563}]}], "abstractContent": [{"text": "We investigate the relation between the transposition and deletion effects in word reading , i.e., the finding that readers can successfully read \"SLAT\" as \"SALT\", or \"WRK\" as \"WORK\", and the neighborhood effect.", "labels": [], "entities": [{"text": "word reading", "start_pos": 78, "end_pos": 90, "type": "TASK", "confidence": 0.7347402572631836}, {"text": "SLAT", "start_pos": 147, "end_pos": 151, "type": "METRIC", "confidence": 0.8406711220741272}, {"text": "SALT", "start_pos": 157, "end_pos": 161, "type": "METRIC", "confidence": 0.7443148493766785}]}, {"text": "In particular, we investigate whether lexical orthographic neighborhoods take into account transposition and deletion in determining neighbors.", "labels": [], "entities": []}, {"text": "If this is the case, it is more likely that the neighborhood effect takes place early during processing, and does not solely rely on similarity of internal representations.", "labels": [], "entities": []}, {"text": "We introduce anew neighborhood measure, rd20, which can be used to quantify neighborhood effects over arbitrary feature spaces.", "labels": [], "entities": []}, {"text": "We calculate the rd20 overlarge sets of words in three languages using various feature sets and show that feature sets that do not allow for transposition or deletion explain more variance in Reaction Time (RT) measurements.", "labels": [], "entities": [{"text": "Reaction Time (RT)", "start_pos": 192, "end_pos": 210, "type": "TASK", "confidence": 0.6359202265739441}]}, {"text": "We also show that the rd20 can be calculated using the hidden state representations of an Multi-Layer Perceptron, and show that these explain less variance than the raw features.", "labels": [], "entities": []}, {"text": "We conclude that the neighborhood effect is unlikely to have a perceptual basis, but is more likely to be the result of items co-activating after recognition.", "labels": [], "entities": []}, {"text": "All code is available at: www.github.com/clips/conll2018", "labels": [], "entities": []}], "introductionContent": [{"text": "Despite their many disagreements and differences, a common thread among many models of word reading is that they attempt to explain differences in reading speeds by assuming that similarity between words modulate reading speed.", "labels": [], "entities": [{"text": "word reading", "start_pos": 87, "end_pos": 99, "type": "TASK", "confidence": 0.7432319223880768}]}, {"text": "There is good reason for this assumption; many experiments have shown that responses on trials are modulated by a word's similarity to other words, be it semantic (), orthographic (Andrews, 1997; Perea and Pollat- The left model is the early model, in which the neighborhood effect arises before perceptual uncertainty is resolved; this causes transposition and substitution neighbors to count as neighbors.", "labels": [], "entities": []}, {"text": "In the late model, the neighborhood effect only arises after perceptual uncertainty is resolved, and transposition and substitution neighbors do not count towards the neighborhood.", "labels": [], "entities": []}, {"text": "sek, 1998), or phonological similarity).", "labels": [], "entities": []}, {"text": "In psycholinguistic research on word reading, this has led to the common practice of including a measure of orthographic neighborhood similarity as a control variable, as these neighborhood measures explain variance in word reading even when controlling for frequency and length.", "labels": [], "entities": [{"text": "word reading", "start_pos": 32, "end_pos": 44, "type": "TASK", "confidence": 0.777591198682785}]}, {"text": "Orthographic neighborhood measures are usually operationalized using edit distance metrics, such as the Levenshtein distance.", "labels": [], "entities": []}, {"text": "The most well-known measure of neighborhood size is, which is the number of types within a substitution distance of 1.", "labels": [], "entities": []}, {"text": "show that N is nearly always 0 for longer words, as long words tend are less frequent, and present an alternative to N , called old20, which is the mean Levenshtein distance to the 20 closest neighbors.", "labels": [], "entities": [{"text": "old20", "start_pos": 128, "end_pos": 133, "type": "DATASET", "confidence": 0.5523742437362671}]}, {"text": "old20 corre-lates well with reaction time (RT) measures on two experiments, and explains more variance than N after accounting for length and frequency, and is therefore considered superior to N , and often used as a de facto replacement for N ().", "labels": [], "entities": [{"text": "reaction time (RT)", "start_pos": 28, "end_pos": 46, "type": "METRIC", "confidence": 0.809394121170044}]}, {"text": "Despite its ubiquity as a control variable, the cause for the neighborhood effect is unknown or disputed.", "labels": [], "entities": []}, {"text": "One aspect, which we explore in the current work, is that it is currently unknown whether the neighborhood effect is early or late.", "labels": [], "entities": []}, {"text": "If the neighborhood effect is early, it is caused by the visual stimulus co-activating multiple representations.", "labels": [], "entities": []}, {"text": "If it is late, the effect is caused by an already activated representation coactivating similar representations.", "labels": [], "entities": []}, {"text": "Of particular interest regarding this question is the finding that skilled readers are remarkably proficient in reading words that contain transposed letters, e.g. \"SLAT\" versus \"SALT\", or words from which letters are deleted, e.g. \"WRK\" and \"WORK\" (.", "labels": [], "entities": [{"text": "SLAT", "start_pos": 165, "end_pos": 169, "type": "METRIC", "confidence": 0.846054196357727}, {"text": "SALT", "start_pos": 179, "end_pos": 183, "type": "METRIC", "confidence": 0.939989447593689}, {"text": "WORK", "start_pos": 243, "end_pos": 247, "type": "METRIC", "confidence": 0.7769753932952881}]}, {"text": "In this work, we refer to these two effects in tandem as flexible letter encoding.", "labels": [], "entities": [{"text": "letter encoding", "start_pos": 66, "end_pos": 81, "type": "TASK", "confidence": 0.7049772888422012}]}, {"text": "Examples of models that try to explain flexible letter encoding include the open bigram family of models), the SOLAR model), the overlap model (, and, most recently, the spatial coding model.", "labels": [], "entities": [{"text": "letter encoding", "start_pos": 48, "end_pos": 63, "type": "TASK", "confidence": 0.6754998564720154}]}, {"text": "Taking into consideration both the neighborhood effect and flexible letter encoding, we define the following research question: are the neighborhoods also defined using flexible letter encoding?", "labels": [], "entities": []}, {"text": "That is, if we know that readers activate \"SALT\" upon reading \"SLAT\", does this also imply that the lexical neighborhood of \"THREE\" includes \"THERE\"?", "labels": [], "entities": [{"text": "SALT", "start_pos": 43, "end_pos": 47, "type": "METRIC", "confidence": 0.9772359728813171}, {"text": "SLAT", "start_pos": 63, "end_pos": 67, "type": "METRIC", "confidence": 0.6038023829460144}, {"text": "THREE", "start_pos": 125, "end_pos": 130, "type": "METRIC", "confidence": 0.8233270645141602}, {"text": "THERE", "start_pos": 142, "end_pos": 147, "type": "METRIC", "confidence": 0.9849392175674438}]}, {"text": "To answer this question, we calculate the neighborhood density using a variety of feature sets, including features that do not allow for flexible letter encoding, and those that do.", "labels": [], "entities": [{"text": "letter encoding", "start_pos": 146, "end_pos": 161, "type": "TASK", "confidence": 0.7409208118915558}]}, {"text": "If lexical neighborhoods calculated using flexible letter encodings account for less variance in word reading times than neighborhoods based on slot-based features, we can surmise that it is more likely that the neighborhood effect is late in origin.", "labels": [], "entities": []}, {"text": "This follows from the fact that flexible letter encodings are most likely to bean intermediate encoding step towards a concrete internal representation.", "labels": [], "entities": []}, {"text": "Hence, if neighborhoods with flexible letter encodings explain less variance, flexible letter encoding most likely does not play a role in the neighborhood effect.", "labels": [], "entities": []}, {"text": "This, in turn implies that the neighborhood effect is likely a late effect, and is caused by concrete representations co-activating similar representations.", "labels": [], "entities": []}, {"text": "These two positions are contrasted in.", "labels": [], "entities": []}], "datasetContent": [{"text": "Using the materials defined in Section 3, we carryout comparative experiments of old20, N , and the rd20 of the four feature sets described above.", "labels": [], "entities": [{"text": "old20", "start_pos": 81, "end_pos": 86, "type": "DATASET", "confidence": 0.9066454172134399}]}, {"text": "shows the word length versus the mean distance for each of the measures for all three languages.", "labels": [], "entities": []}, {"text": "The figure shows that old20 and the measures based on slot-based encodings correlate strongly with length, while flexible encodings do not correlate with length.", "labels": [], "entities": [{"text": "old20", "start_pos": 22, "end_pos": 27, "type": "DATASET", "confidence": 0.914298951625824}, {"text": "length", "start_pos": 99, "end_pos": 105, "type": "METRIC", "confidence": 0.9843206405639648}]}, {"text": "We observe the same  pattern of performance for all three languages.", "labels": [], "entities": []}, {"text": "As a similar pattern of performance was observed in, we consider this to bean empirical validation of our datasets.", "labels": [], "entities": []}, {"text": "shows the Spearman correlations between the different predictor variables (length, frequency), and the various measures for all languages.", "labels": [], "entities": []}, {"text": "As the figure indicates, the pattern of correlations is consistent across all surveyed languages, and only differs in magnitude, not direction.", "labels": [], "entities": []}, {"text": "Additionally, because the results corre-  spond with those from, this provides additional evidence for old20 and our datasets.", "labels": [], "entities": [{"text": "old20", "start_pos": 103, "end_pos": 108, "type": "DATASET", "confidence": 0.9732035994529724}]}, {"text": "Given that old20 is considered to be a good neighborhood measure, and the various rd20 measures show the same type of effects, i.e., effects in the same direction, this indirectly validates rd20 as a good measure.", "labels": [], "entities": [{"text": "old20", "start_pos": 11, "end_pos": 16, "type": "DATASET", "confidence": 0.9623385667800903}]}, {"text": "As an aside, while we seethe same direction of effects as in, we do see that the magnitude of the correlations between the scores and RT are lower for all corpora, which was reported to be .612 for the English Lexicon Project stimuli used in.", "labels": [], "entities": [{"text": "RT", "start_pos": 134, "end_pos": 136, "type": "METRIC", "confidence": 0.9561326503753662}, {"text": "English Lexicon Project stimuli", "start_pos": 202, "end_pos": 233, "type": "DATASET", "confidence": 0.8570348471403122}]}, {"text": "In the previous experiment, we showed that rd20 can be used to assess the neighborhood of featurized words.", "labels": [], "entities": []}, {"text": "Calculating the rd20 over the raw features, however, assumes that our internal representations are exemplars instead of learned abstract representations, such as those found in a neural network.", "labels": [], "entities": []}, {"text": "To assess whether rd20 can also be used with hidden state representations, we performed an additional experiment using a Multi-Layer Perceptron (MLP).", "labels": [], "entities": []}, {"text": "For each feature set, we trained an MLP to predict the identity of the word based on the input features, which is similar to experiments conducted by.", "labels": [], "entities": []}, {"text": "Each MLP had one hidden layer with 500 hidden units and a Sigmoid activation function, while the output layer had a softmax activation function, and a dimensionality of the vocabulary size.", "labels": [], "entities": []}, {"text": "We used cross-entropy as a loss function, and optimized using Adam (.", "labels": [], "entities": []}, {"text": "Our training regime was as follows: we shuffled before each epoch, and then presented all featurized words to the MLP.", "labels": [], "entities": [{"text": "MLP", "start_pos": 114, "end_pos": 117, "type": "DATASET", "confidence": 0.8238010406494141}]}, {"text": "As in the previous experiment, we used the whole corpus for each language during training.", "labels": [], "entities": []}, {"text": "We trained each model until convergence, where we defined convergence as there being no change in the loss for 20 epochs in a row.", "labels": [], "entities": [{"text": "convergence", "start_pos": 58, "end_pos": 69, "type": "METRIC", "confidence": 0.9964602589607239}]}, {"text": "After convergence, we calculated the accuracy score for each of the models in each language.", "labels": [], "entities": [{"text": "accuracy score", "start_pos": 37, "end_pos": 51, "type": "METRIC", "confidence": 0.9801501631736755}]}, {"text": "Each of the models achieved an accuracy of .95 or higher, showing that each model has correctly learned to predict nearly every word.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 31, "end_pos": 39, "type": "METRIC", "confidence": 0.999421238899231}]}, {"text": "We then presented the words for which we had RTs (i.e. the words which were both in the SUBTLEX database and in the Lexicon Project for each language) to the network again, and stored the hidden unit activations in response to the input.", "labels": [], "entities": [{"text": "SUBTLEX database", "start_pos": 88, "end_pos": 104, "type": "DATASET", "confidence": 0.7798404395580292}]}, {"text": "Following the neural network literature (e.g.), we assume these internal representations are the representations learned during the task of attempting to predict the word identity.", "labels": [], "entities": []}, {"text": "We then calculated rd20 for each representation, and used these as input to the same analyses as the previous experiment.", "labels": [], "entities": []}, {"text": "Comparing the MLP results in to the results from, we see that the MLP has a normalizing effect; as far as these statistics are concerned, the differences between the different feature sets have become smaller.", "labels": [], "entities": []}, {"text": "The most prominent change is that all rd20 measures now correlate with length, whereas before only the rd20 based on slot-based values correlated with length.", "labels": [], "entities": [{"text": "length", "start_pos": 71, "end_pos": 77, "type": "METRIC", "confidence": 0.9909628033638}]}, {"text": "Similarly, the rd20 based on the one hot features did not correlate with the rd20 based on the bigram and wickelgraphs in experiment 1, but does correlate in the present experiment.", "labels": [], "entities": []}, {"text": "We also conducted regression analyses, using the distances between the hidden layer representations as a predictor, as in experiment 1.", "labels": [], "entities": []}, {"text": "shows the results of these regression analyses.", "labels": [], "entities": []}, {"text": "These analyses confirm that the MLP has a normalizing effect; whereas the effect of frequency and length differed in magnitude and sign between feature sets in Experiment 1, nearly all feature sets see a positive effect of length and a negative effect of frequency.", "labels": [], "entities": []}, {"text": "The regression analysis shows that the R 2 adj was generally lower for the representations in the MLP, with the wickelgraphs especially suffering in comparison to Experiment 1.", "labels": [], "entities": [{"text": "MLP", "start_pos": 98, "end_pos": 101, "type": "DATASET", "confidence": 0.6723222732543945}]}], "tableCaptions": [{"text": " Table 1: The number of words left over in the  SUBTLEX and Lexicon projects after filtering. Note  that we removed any words from the Lexicon project  which were not in the SUBTLEX database, so that the  words from the lexicon project are an exact subset of  those in the SUBTLEX database.", "labels": [], "entities": [{"text": "SUBTLEX database", "start_pos": 273, "end_pos": 289, "type": "DATASET", "confidence": 0.8507645130157471}]}, {"text": " Table 2: The coefficients, explained variance, and change in explained variance of the regression analyses. The  rd20 measure using one hot features explains the most variance across all languages, although the difference is not  significant for English.", "labels": [], "entities": []}, {"text": " Table 3: The coefficients, adjusted explained variance, and change in adjusted explained variance of the regression  analyses on the hidden state representations learned by an MLP.", "labels": [], "entities": []}]}