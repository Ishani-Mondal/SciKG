{"title": [], "abstractContent": [{"text": "Learning attention functions requires large volumes of data, but many NLP tasks simulate human behavior, and in this paper, we show that human attention really does provide a good inductive bias on many attention functions in NLP.", "labels": [], "entities": []}, {"text": "Specifically, we use estimated human attention derived from eye-tracking corpora to regularize attention functions in recurrent neural networks.", "labels": [], "entities": []}, {"text": "We show substantial improvements across a range of tasks, including sentiment analysis, grammatical error detection, and detection of abusive language.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 68, "end_pos": 86, "type": "TASK", "confidence": 0.9757904708385468}, {"text": "grammatical error detection", "start_pos": 88, "end_pos": 115, "type": "TASK", "confidence": 0.5768550833066305}, {"text": "detection of abusive language", "start_pos": 121, "end_pos": 150, "type": "TASK", "confidence": 0.8187691420316696}]}], "introductionContent": [{"text": "When humans read a text, they do not attend to all its words.", "labels": [], "entities": []}, {"text": "For example, humans are likely to omit many function words and other words that are predictable in context and focus on less predictable content words.", "labels": [], "entities": []}, {"text": "Moreover, when they fixate on a word, the duration of that fixation depends on a number of linguistic factors.", "labels": [], "entities": []}, {"text": "Since learning good attention functions for recurrent neural networks requires large volumes of data (, and errors in attention are known to propagate to classification decisions (, we explore the idea of using human attention, as estimated from eye-tracking corpora, as an inductive bias on such attention functions.", "labels": [], "entities": []}, {"text": "Penalizing attention functions for departing from human attention may enable us to learn better attention functions when data is limited.", "labels": [], "entities": []}, {"text": "Eye-trackers provide millisecond-accurate records on where humans look when they are reading, and they are becoming cheaper and more easily available by the day.", "labels": [], "entities": []}, {"text": "In this paper, we use publicly available eye-tracking corpora, i.e., texts augmented with eye-tracking measures such as fixation duration times, and large eye-tracking corpora have appeared increasingly over the past years.", "labels": [], "entities": []}, {"text": "Some studies suggest that the relevance of text can be inferred from the gaze pattern of the reader () -even on word-level ().", "labels": [], "entities": []}, {"text": "Contributions We present a recurrent neural architecture with attention for sequence classification tasks.", "labels": [], "entities": [{"text": "sequence classification tasks", "start_pos": 76, "end_pos": 105, "type": "TASK", "confidence": 0.8212650616963705}]}, {"text": "The architecture jointly learns its parameters and an attention function, but can alternate between supervision signals from labeled sequences (with no explicit supervision of the attention function) and from attention trajectories.", "labels": [], "entities": []}, {"text": "This enables us to use per-word fixation durations from eye-tracking corpora to regularize attention functions for sequence classification tasks.", "labels": [], "entities": [{"text": "sequence classification tasks", "start_pos": 115, "end_pos": 144, "type": "TASK", "confidence": 0.8273170789082845}]}, {"text": "We show such regularization leads to significant improvements across a range of tasks, including sentiment analysis, detection of abusive language, and grammatical error detection.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 97, "end_pos": 115, "type": "TASK", "confidence": 0.9770171344280243}, {"text": "detection of abusive language", "start_pos": 117, "end_pos": 146, "type": "TASK", "confidence": 0.8665108978748322}, {"text": "grammatical error detection", "start_pos": 152, "end_pos": 179, "type": "TASK", "confidence": 0.6155393222967783}]}, {"text": "Our implementation is made available at https://github.com/coastalcph/ Sequence_classification_with_ human_attention.", "labels": [], "entities": []}], "datasetContent": [{"text": "Hyperparameters Basic hyper-parameters such as number of hidden layers, layer size, and activation functions were following the settings of.", "labels": [], "entities": []}, {"text": "The dimensionality of our word embedding layer was set to size 300, and we use publicly available pre-trained Glove word embeddings () that we finetune during training.", "labels": [], "entities": []}, {"text": "The dimensionality of the character embedding layer was set to 100.", "labels": [], "entities": []}, {"text": "The recurrent layers in the character-level component have dimensionality 100; the word-level recurrent layers dimensionality 300.", "labels": [], "entities": []}, {"text": "The dimensionality of our feed-forward layer, leading to reduced combined representations hi , is 200, and the attention layer has dimensionality 100.", "labels": [], "entities": []}, {"text": "Three hyper-parameters, however, we tune for each architecture and for each task, by measuring sentence-level F 1 -scores on the development sets.", "labels": [], "entities": [{"text": "sentence-level F 1 -scores", "start_pos": 95, "end_pos": 121, "type": "METRIC", "confidence": 0.790576982498169}]}, {"text": "These are: (a) learning rate, (b) \u03bb in Equation (12), i.e., controlling the relative importance of the attention regularization, and (c) the probability of sampling data from the eye-tracking corpus during training.", "labels": [], "entities": [{"text": "learning rate", "start_pos": 15, "end_pos": 28, "type": "METRIC", "confidence": 0.9458329677581787}, {"text": "Equation", "start_pos": 39, "end_pos": 47, "type": "METRIC", "confidence": 0.9796715378761292}]}, {"text": "For all tasks and all conditions (baseline, frequency-informed baseline, and our human attention model), we perform a grid search over learning rates .25 .5 1., decreasing ] -where decreasing means that the probability of sampling from the eye-tracking corpus initially is 0.5, but drops linearly for each epoch ( 1 E+1 ; see 2.1.", "labels": [], "entities": []}, {"text": "We apply the models with the best average F 1 scores over three random seeds on the validation data, to our test sets.", "labels": [], "entities": [{"text": "F 1 scores", "start_pos": 42, "end_pos": 52, "type": "METRIC", "confidence": 0.959723432858785}]}, {"text": "Initialization Our models are randomly initialized.", "labels": [], "entities": [{"text": "Initialization", "start_pos": 0, "end_pos": 14, "type": "TASK", "confidence": 0.9657915830612183}]}, {"text": "This leads to some variance in performance across different runs.", "labels": [], "entities": []}, {"text": "We therefore report averages over 10 runs in our experiments below.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Sentence classification results. P(recision), R(ecall) and F 1 . Averages over 10 random seeds. The best  average F 1 score per task is shown in bold.", "labels": [], "entities": [{"text": "Sentence classification", "start_pos": 10, "end_pos": 33, "type": "TASK", "confidence": 0.9380892813205719}, {"text": "F 1", "start_pos": 69, "end_pos": 72, "type": "METRIC", "confidence": 0.9829917252063751}, {"text": "F 1 score", "start_pos": 124, "end_pos": 133, "type": "METRIC", "confidence": 0.8517649372418722}]}]}