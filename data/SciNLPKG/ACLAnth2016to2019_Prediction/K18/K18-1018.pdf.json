{"title": [], "abstractContent": [{"text": "Aspect-level sentiment analysis aims to identify the sentiment of a specific target in its context.", "labels": [], "entities": [{"text": "Aspect-level sentiment analysis", "start_pos": 0, "end_pos": 31, "type": "TASK", "confidence": 0.9037422935167948}]}, {"text": "Previous works have proved that the interactions between aspects and the contexts are important.", "labels": [], "entities": []}, {"text": "On this basis, we also propose a succinct hierarchical attention based mechanism to fuse the information of targets and the contextual words.", "labels": [], "entities": []}, {"text": "In addition, most existing methods ignore the position information of the aspect when encoding the sentence.", "labels": [], "entities": []}, {"text": "In this paper, we argue that the position-aware representations are beneficial to this task.", "labels": [], "entities": []}, {"text": "Therefore, we propose a hierarchical attention based position-aware network (HAPN), which introduces position embeddings to learn the position-aware representations of sentences and further generate the target-specific representations of contextual words.", "labels": [], "entities": []}, {"text": "The experimental results on SemEval 2014 dataset show that our approach outperforms the state-of-the-art methods.", "labels": [], "entities": [{"text": "SemEval 2014 dataset", "start_pos": 28, "end_pos": 48, "type": "DATASET", "confidence": 0.7600923577944437}]}], "introductionContent": [{"text": "Aspect-level sentiment analysis is a fine-grained task in sentiment analysis, which aims to identify the sentiment polarity (i.e., negative, neutral, or positive) of a specific opinion target expressed in a comment/review by a reviewer.", "labels": [], "entities": [{"text": "Aspect-level sentiment analysis", "start_pos": 0, "end_pos": 31, "type": "TASK", "confidence": 0.850985606511434}, {"text": "sentiment analysis", "start_pos": 58, "end_pos": 76, "type": "TASK", "confidence": 0.9320250451564789}]}, {"text": "For example, given a sentence \"The price is reasonable although the service is poor\", the sentiment polarity for aspects \"price\" and \"service\" are positive and negative respectively.", "labels": [], "entities": []}, {"text": "Traditional methods for aspect-level sentiment analysis mainly focus on designing a set of features (such as bag-of-words, sentiment lexicons, and linguistic features) to train a classifier for sentiment classification (.", "labels": [], "entities": [{"text": "aspect-level sentiment analysis", "start_pos": 24, "end_pos": 55, "type": "TASK", "confidence": 0.6961643199125925}, {"text": "sentiment classification", "start_pos": 194, "end_pos": 218, "type": "TASK", "confidence": 0.8702607452869415}]}, {"text": "However, such kind of feature engineering work often relies on human ingenuity, which is a timeconsuming process and lacks generalization.", "labels": [], "entities": []}, {"text": "In recent years, more and more neural network based models have been proposed and obtained the stateof-the-art results (.", "labels": [], "entities": []}, {"text": "As previous research) reveals that 40% of sentiment classification errors are caused by not considering targets in sentiment classification, recent works tend to focus on fusing the information of the targets and the contexts. and both concatenated the aspect embeddings and embeddings of each word as inputs to a LSTM based model so as to introduce the information of the target into the model.", "labels": [], "entities": [{"text": "sentiment classification", "start_pos": 42, "end_pos": 66, "type": "TASK", "confidence": 0.891972690820694}, {"text": "sentiment classification", "start_pos": 115, "end_pos": 139, "type": "TASK", "confidence": 0.8655083775520325}]}, {"text": "adopted circular convolution and circular correlation to model the similarity between aspect and contextual words. and both employed a bidirectional attention operation to achieve the representations of targets and contextual words determined by each other.", "labels": [], "entities": []}, {"text": "introduced an attention-over-attention based network to model the aspects and contexts in a joint way and explicitly capture the interaction between aspects and the context.", "labels": [], "entities": []}, {"text": "As described above, the existing studies show that the interactions between aspects and the context are important to the aspect-level sentiment analysis.", "labels": [], "entities": [{"text": "aspect-level sentiment analysis", "start_pos": 121, "end_pos": 152, "type": "TASK", "confidence": 0.7668107350667318}]}, {"text": "Leveraging this idea, we also propose a succinct hierarchical attention based mechanism to fuse the information of targets and the contextual words, which aims to generate the target-specific representations of each word.", "labels": [], "entities": []}, {"text": "In addition, most of the above methods ignore the position information of the aspect when", "labels": [], "entities": []}], "datasetContent": [{"text": "We conduct experiments on SemEval 2014 Task 4 to validate the effectiveness of our model, as shown in.", "labels": [], "entities": [{"text": "SemEval 2014 Task 4", "start_pos": 26, "end_pos": 45, "type": "DATASET", "confidence": 0.7371238619089127}]}, {"text": "The SemEval 2014 dataset contains reviews of restaurant and laptop domains, which are widely used in previous works.", "labels": [], "entities": [{"text": "SemEval 2014 dataset", "start_pos": 4, "end_pos": 24, "type": "DATASET", "confidence": 0.7508238951365153}]}, {"text": "The evaluation metric is classification accuracy.", "labels": [], "entities": [{"text": "classification", "start_pos": 25, "end_pos": 39, "type": "TASK", "confidence": 0.9555028676986694}, {"text": "accuracy", "start_pos": 40, "end_pos": 48, "type": "METRIC", "confidence": 0.8770167231559753}]}, {"text": "We use 300-dimension word vectors pre-trained by) (whose vocabulary size is 1.9M) for our experiments, as previous works did (.", "labels": [], "entities": []}, {"text": "All out-of-vocabulary words are initialized as zero vectors, and all biases are set to zero.", "labels": [], "entities": []}, {"text": "The dimensions of hidden states and fused embeddings are set to 300.", "labels": [], "entities": []}, {"text": "The dimension of position embeddings is set to 50.", "labels": [], "entities": []}, {"text": "Keras is used for implementing our neural network model.", "labels": [], "entities": []}, {"text": "In model training, we set the learning rate to 0.001, the batch size to 64, and dropout rate to 0.5.", "labels": [], "entities": [{"text": "learning rate", "start_pos": 30, "end_pos": 43, "type": "METRIC", "confidence": 0.9531401693820953}, {"text": "dropout rate", "start_pos": 80, "end_pos": 92, "type": "METRIC", "confidence": 0.900521993637085}]}, {"text": "The paired t-test is used for the significance testing.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1. The SemEval 2014 dataset  contains reviews of restaurant and laptop domains,  which are widely used in previous works. The  evaluation metric is classification accuracy.", "labels": [], "entities": [{"text": "SemEval 2014 dataset", "start_pos": 14, "end_pos": 34, "type": "DATASET", "confidence": 0.7505641976992289}, {"text": "accuracy", "start_pos": 170, "end_pos": 178, "type": "METRIC", "confidence": 0.9533082246780396}]}, {"text": " Table 2 shows the performance comparison of our  method with the state-of-the-art methods on the  same test dataset. From the table, we make the  following observations:  (1) As shown in the table, we can clearly  observe that the Majority method is the worst,  which means the majority sentiment polarity  occupies 65.0% and 53.45% of all samples on the  Restaurant and Laptop corpus respectively. In  addition to MemNet, all the other models are RNN  based models and better than the Majority method.  This indicates that RNN based models can obtain  better representations of sentence automatically", "labels": [], "entities": [{"text": "MemNet", "start_pos": 416, "end_pos": 422, "type": "DATASET", "confidence": 0.89430171251297}]}, {"text": " Table 2: Comparison with baselines on SemEval  2014 dataset. The results with * are retrieved from  MemNet paper.", "labels": [], "entities": [{"text": "SemEval  2014 dataset", "start_pos": 39, "end_pos": 60, "type": "DATASET", "confidence": 0.894484261671702}, {"text": "MemNet paper", "start_pos": 101, "end_pos": 113, "type": "DATASET", "confidence": 0.9678405225276947}]}, {"text": " Table 3: The performance of models with different  strategies to introduce position information.", "labels": [], "entities": []}, {"text": " Table 4: The performance of models with or  without fusion operation.", "labels": [], "entities": []}, {"text": " Table 5: The performance of models with or  without Source2aspect attention.", "labels": [], "entities": []}]}