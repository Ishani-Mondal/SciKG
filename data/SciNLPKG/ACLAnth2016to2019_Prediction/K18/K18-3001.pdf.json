{"title": [{"text": "The CoNLL-SIGMORPHON 2018 Shared Task: Universal Morphological Reinflection", "labels": [], "entities": [{"text": "CoNLL-SIGMORPHON", "start_pos": 4, "end_pos": 20, "type": "DATASET", "confidence": 0.7579106092453003}, {"text": "Universal Morphological Reinflection", "start_pos": 39, "end_pos": 75, "type": "TASK", "confidence": 0.5294513901074728}]}], "abstractContent": [{"text": "The CoNLL-SIGMORPHON 2018 shared task on supervised learning of morphological generation featured data sets from 103 typo-logically diverse languages.", "labels": [], "entities": []}, {"text": "Apart from extending the number of languages involved in earlier supervised tasks of generating inflected forms, this year the shared task also featured anew second task which asked participants to inflect words in sentential context, similar to a cloze task.", "labels": [], "entities": []}, {"text": "This second task featured seven languages.", "labels": [], "entities": []}, {"text": "Task 1 received 27 submissions and task 2 received 6 submissions.", "labels": [], "entities": []}, {"text": "Both tasks featured a low, medium, and high data condition.", "labels": [], "entities": []}, {"text": "Nearly all submissions featured a neu-ral component and built on highly-ranked systems from the earlier 2017 shared task.", "labels": [], "entities": []}, {"text": "In the inflection task (task 1), 41 of the 52 languages present in last year's inflection task showed improvement by the best systems in the low-resource setting.", "labels": [], "entities": []}, {"text": "The cloze task (task 2) proved to be difficult, and few submissions managed to consistently improve upon both a simple neural baseline system and a lemma-repeating baseline.", "labels": [], "entities": []}], "introductionContent": [{"text": "Some of a word's syntactic and semantic properties are expressed on the word form through a process termed morphological inflection.", "labels": [], "entities": []}, {"text": "For example, each English count noun has both singular and plural forms (robot/robots, process/processes), known as the inflected forms of the noun.", "labels": [], "entities": []}, {"text": "Some languages display little inflection, while others possess a proliferation of forms.", "labels": [], "entities": []}, {"text": "A Polish verb can have nearly 100 inflected forms and an Archi verb has thousands.", "labels": [], "entities": []}, {"text": "Natural language processing systems must be able to analyze and generate these inflected forms.", "labels": [], "entities": []}, {"text": "Fortunately, inflected forms tend to be systematically related to one another.", "labels": [], "entities": []}, {"text": "This is why English  example maps a lemma and inflection to an inflected form, The inflection is a bundle of morphosyntactic features.", "labels": [], "entities": []}, {"text": "Note that inflected forms (and lemmata) can encompass multiple words.", "labels": [], "entities": []}, {"text": "In the test data, the last column (the inflected form) must be predicted by the system.", "labels": [], "entities": []}, {"text": "speakers can usually predict the singular form from the plural and vice versa, even for words they have never seen before: given a novel noun wug, an English speaker knows that the plural is wugs.", "labels": [], "entities": []}, {"text": "We conducted a competition on generating inflected forms.", "labels": [], "entities": []}, {"text": "This \"shared task\" consisted of two separate scenarios.", "labels": [], "entities": []}, {"text": "In Task 1, participating systems must inflect word forms based on labeled examples.", "labels": [], "entities": []}, {"text": "In English, an example of inflection is the conversion of a citation form 1 run to its present participle, running.", "labels": [], "entities": []}, {"text": "The system is provided with the source form and the morphosyntactic description (MSD) of the target form, and must generate the actual target form.", "labels": [], "entities": []}, {"text": "Task 2 is a harder version of Task 1, where the system must infer the appropriate MSD from a sentential context.", "labels": [], "entities": []}, {"text": "This is essentially a cloze task, asking participants to provide the correct form of a lemma in context.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 2: Total number of lemmata and forms available for sampling, and number of distinct lemmata and forms present in each", "labels": [], "entities": []}, {"text": " Table 3: Total number of lemmata and forms available for sampling, and number of distinct lemmata and forms present in each", "labels": [], "entities": []}, {"text": " Table 4: Token counts of the training, development and test", "labels": [], "entities": []}, {"text": " Table 5: Counts of target lemmata to be inflected in the de-", "labels": [], "entities": [{"text": "Counts", "start_pos": 10, "end_pos": 16, "type": "METRIC", "confidence": 0.98470139503479}]}, {"text": " Table 8: Task 1 results: Per-form accuracy (in percentage", "labels": [], "entities": [{"text": "accuracy", "start_pos": 35, "end_pos": 43, "type": "METRIC", "confidence": 0.9758130311965942}]}, {"text": " Table 11: Overall accuracies (in %-points) for Tracks 1 and 2 in Task 2 for different training data settings. Results are", "labels": [], "entities": [{"text": "accuracies", "start_pos": 19, "end_pos": 29, "type": "METRIC", "confidence": 0.9389755129814148}]}, {"text": " Table 13: Task 1 High Condition Part 1.", "labels": [], "entities": []}, {"text": " Table 14: Task 1 High Condition Part 2.", "labels": [], "entities": []}, {"text": " Table 15: Task 1 Medium Condition Part 1.", "labels": [], "entities": []}, {"text": " Table 16: Task 1 Medium Condition Part 2.", "labels": [], "entities": []}, {"text": " Table 17: Task 1 Low Condition Part 1.", "labels": [], "entities": []}, {"text": " Table 18: Task 1 Low Condition Part 2.", "labels": [], "entities": []}, {"text": " Table 19: Task 1 Low Condition Part 3.", "labels": [], "entities": []}]}