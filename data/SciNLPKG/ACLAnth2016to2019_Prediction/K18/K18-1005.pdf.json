{"title": [{"text": "A Unified Neural Network Model for Geolocating Twitter Users", "labels": [], "entities": []}], "abstractContent": [{"text": "Locations of social media users are important to many applications such as rapid disaster response, targeted advertisement, and news recommendation.", "labels": [], "entities": [{"text": "rapid disaster response", "start_pos": 75, "end_pos": 98, "type": "TASK", "confidence": 0.615015427271525}, {"text": "news recommendation", "start_pos": 128, "end_pos": 147, "type": "TASK", "confidence": 0.7255778759717941}]}, {"text": "However, many users do not share their exact geographical coordinates due to reasons such as privacy concerns.", "labels": [], "entities": []}, {"text": "The lack of explicit location information has motivated a growing body of research in recent years looking at different automatic ways of determining the user's primary location.", "labels": [], "entities": []}, {"text": "In this paper, we propose a unified user geoloca-tion method which relies on a fusion of neural networks.", "labels": [], "entities": []}, {"text": "Our joint model incorporates different types of available information including tweet text, user network, and metadata to predict users' locations.", "labels": [], "entities": []}, {"text": "Moreover, we utilize a bidirectional LSTM network augmented with an attention mechanism to identify the most location indicative words in textual content of tweets.", "labels": [], "entities": []}, {"text": "The experiments demonstrate that our approach achieves state-of-the-art performance over two Twitter benchmark geolo-cation datasets.", "labels": [], "entities": []}, {"text": "We also conduct an abla-tion study to evaluate the contribution of each type of information in user geolocation performance .", "labels": [], "entities": []}], "introductionContent": [{"text": "Knowing physical locations involved in social media data helps us to understand what is happening in real life, to bridge the online and offline worlds, and to develop applications for supporting real-life demands.", "labels": [], "entities": []}, {"text": "For example, we can monitor public health of residents (, recommend local events () or attractive places () to tourists, identify locations of emergency () or even disasters (, and summarize regional topics.", "labels": [], "entities": []}, {"text": "Even though platforms such as Twitter allow users to geolocate their posts to reveal their locations either manually or with the help of GPS, it is reported that less than 1% of Twitter data has geo-coordinates provided.", "labels": [], "entities": []}, {"text": "Moreover, location information on Twitter is far from being complete and accurate.", "labels": [], "entities": []}, {"text": "For instance, self-declared home information in many user profiles is inaccurate or even invalid).", "labels": [], "entities": []}, {"text": "The lack of explicit location information in the majority of tweets has motivated a growing body of research in recent years looking at different automatic ways of determining the user's primary location (i.e.,user geolocation) and/or -as a proxy for the former -the location from which tweets have been posted (.", "labels": [], "entities": []}, {"text": "Geolocation methods usually train a model on a small set of users whose locations are known (e.g., through GPS-based geotagging), and predict locations of other users using the resulting model.", "labels": [], "entities": []}, {"text": "These models broadly fall into three categories: text-based (, networkbased, and hybrid methods that combine text, user network, and metadata information () with the aim of achieving stateof-the-art performance.", "labels": [], "entities": []}, {"text": "In this paper, we present a neural network-based system that we developed for user geolocation in Twitter.", "labels": [], "entities": []}, {"text": "Our model combines different sources of information including tweet text, metadata, and user network.", "labels": [], "entities": []}, {"text": "We employ a neural network model to generate a dense vector representation for each field and then use the concatenation of these representations as the feature for classification.", "labels": [], "entities": []}, {"text": "Our main contributions can be summarized as follows: 1.", "labels": [], "entities": []}, {"text": "We propose a unified user geolocation method that relies on a fusion of neural networks, incorporating different types of avail-able information: tweet message, users' social relationships, and metadata fields embedded in tweets and profiles.", "labels": [], "entities": []}, {"text": "2. For modeling the tweet text (and textual metadata fields), we use bidirectional Long Short-Term Memory (LSTM) networks augmented with a context-aware attention mechanism (, which helps to identify the most location indicative words.", "labels": [], "entities": []}, {"text": "3. Through the empirical studies on two standard Twitter datasets, we demonstrate that the proposed method outperforms other state-ofthe-art approaches in addressing the problem of user geolocation.", "labels": [], "entities": [{"text": "Twitter datasets", "start_pos": 49, "end_pos": 65, "type": "DATASET", "confidence": 0.7111074328422546}]}, {"text": "4. We train an individual model for each information field, and analyze the contribution of each component in the geolocation process.", "labels": [], "entities": []}, {"text": "The rest of the paper is organized as follows.", "labels": [], "entities": []}, {"text": "We review the related work in Section 2.", "labels": [], "entities": []}, {"text": "Utilized data is described in Section 3.", "labels": [], "entities": []}, {"text": "Section 4 explains the proposed approach.", "labels": [], "entities": []}, {"text": "The experimental results are given in Section 5, and finally, we conclude the paper and outline possible future work in Section 6.", "labels": [], "entities": []}], "datasetContent": [{"text": "In the text sub-network, words are input to the model as n-dimensional word embeddings.", "labels": [], "entities": []}, {"text": "We pre-trained word embeddings using word2vec) over tweet text of the full training data.", "labels": [], "entities": []}, {"text": "The model was trained using the Skip-gram architecture and negative sampling (k = 5) for five iterations, with a context window of 5 and subsampling factor of 0.001.", "labels": [], "entities": []}, {"text": "It is noteworthy that to be part of the vocabulary, words should occur at least five times in the corpus.", "labels": [], "entities": []}, {"text": "We chose word embeddings of size 200/300 for TWIT-TERUS/WNUT datasets because smaller embeddings experimentally showed to capture not as much detail and resulted in a lower accuracy.", "labels": [], "entities": [{"text": "TWIT-TERUS/WNUT datasets", "start_pos": 45, "end_pos": 69, "type": "DATASET", "confidence": 0.6949282735586166}, {"text": "accuracy", "start_pos": 173, "end_pos": 181, "type": "METRIC", "confidence": 0.9974027276039124}]}, {"text": "Larger word embeddings, on the other hand, made the model too complex to train.", "labels": [], "entities": []}, {"text": "In the preprocessing step, we used replacement tokens for URLs, mentions and numbers.", "labels": [], "entities": []}, {"text": "However, we did not replace hashtags as doing so experimentally demonstrated to decrease the accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 93, "end_pos": 101, "type": "METRIC", "confidence": 0.9988998174667358}]}, {"text": "The layers and the embeddings in our subnetworks have parameters like embedding dimension, LSTM unit size, and attention context vector size.", "labels": [], "entities": [{"text": "LSTM unit size", "start_pos": 91, "end_pos": 105, "type": "METRIC", "confidence": 0.8861349821090698}]}, {"text": "We chose optimal values for these parameters in terms of accuracy with a grid search using the development sets of TwitterUS and WNUT.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 57, "end_pos": 65, "type": "METRIC", "confidence": 0.9994243383407593}, {"text": "TwitterUS", "start_pos": 115, "end_pos": 124, "type": "DATASET", "confidence": 0.9805850386619568}, {"text": "WNUT", "start_pos": 129, "end_pos": 133, "type": "DATASET", "confidence": 0.8932303786277771}]}, {"text": "The selected parameters values are reported in Table 1.", "labels": [], "entities": []}, {"text": "It should be noted that the main reason for selecting smaller values for the TWITTERUS dataset is its larger size (in terms of tweet number) comparing to the WNUT dataset.", "labels": [], "entities": [{"text": "TWITTERUS dataset", "start_pos": 77, "end_pos": 94, "type": "DATASET", "confidence": 0.8926867544651031}, {"text": "WNUT dataset", "start_pos": 158, "end_pos": 170, "type": "DATASET", "confidence": 0.9736018776893616}]}, {"text": "We set the hyper-parameters of our final model as follows: batch size = 256, learning rate = 0.001, epochs = 5.", "labels": [], "entities": [{"text": "learning rate", "start_pos": 77, "end_pos": 90, "type": "METRIC", "confidence": 0.9293654561042786}]}, {"text": "The dropout rate between layers is set to 0.2.", "labels": [], "entities": []}, {"text": "We evaluate our approach in the following three commonly used metrics for user geolocation: \u2022 Acc@161: The percentage of predicted locations which are within a 161km (100 mile) radius of the actual location (.", "labels": [], "entities": [{"text": "Acc@161", "start_pos": 94, "end_pos": 101, "type": "METRIC", "confidence": 0.9497818350791931}]}, {"text": "This metric is a proxy for accuracy within a metro area.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 27, "end_pos": 35, "type": "METRIC", "confidence": 0.9989997744560242}]}, {"text": "\u2022 Mean error: The mean value of error distances in predicted locations ().", "labels": [], "entities": [{"text": "Mean error", "start_pos": 2, "end_pos": 12, "type": "METRIC", "confidence": 0.9881049394607544}]}, {"text": "\u2022 Median error: The median value of error distances in predictions ().", "labels": [], "entities": []}, {"text": "Note that higher numbers are better for Acc@161 but lower numbers are better for mean and median errors.", "labels": [], "entities": [{"text": "Acc@161", "start_pos": 40, "end_pos": 47, "type": "METRIC", "confidence": 0.9669273495674133}, {"text": "mean and median errors", "start_pos": 81, "end_pos": 103, "type": "METRIC", "confidence": 0.7728806138038635}]}, {"text": "presents the performance of user geolocation methods over TWITTERUS and WNUT 2 datasets.", "labels": [], "entities": [{"text": "WNUT 2 datasets", "start_pos": 72, "end_pos": 87, "type": "DATASET", "confidence": 0.8631694316864014}]}], "tableCaptions": [{"text": " Table 1: Parameter settings of the proposed models.", "labels": [], "entities": [{"text": "Parameter", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9432649612426758}]}, {"text": " Table 3: Performance breakdown for each compo- nent over WNUT dataset", "labels": [], "entities": [{"text": "WNUT dataset", "start_pos": 58, "end_pos": 70, "type": "DATASET", "confidence": 0.9190544188022614}]}]}