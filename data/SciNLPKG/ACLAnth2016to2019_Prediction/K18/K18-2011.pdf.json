{"title": [{"text": "82 Treebanks, 34 Models: Universal Dependency Parsing with Multi-Treebank Models", "labels": [], "entities": []}], "abstractContent": [{"text": "We present the Uppsala system for the CoNLL 2018 Shared Task on universal dependency parsing.", "labels": [], "entities": [{"text": "Uppsala", "start_pos": 15, "end_pos": 22, "type": "DATASET", "confidence": 0.9741412401199341}, {"text": "CoNLL 2018 Shared Task", "start_pos": 38, "end_pos": 60, "type": "DATASET", "confidence": 0.7710349559783936}, {"text": "universal dependency parsing", "start_pos": 64, "end_pos": 92, "type": "TASK", "confidence": 0.5524737238883972}]}, {"text": "Our system is a pipeline consisting of three components: the first performs joint word and sentence segmentation; the second predicts part-of-speech tags and morphological features; the third predicts dependency trees from words and tags.", "labels": [], "entities": [{"text": "word and sentence segmentation", "start_pos": 82, "end_pos": 112, "type": "TASK", "confidence": 0.7098620533943176}]}, {"text": "Instead of training a single parsing model for each treebank, we trained models with multiple treebanks for one language or closely related languages, greatly reducing the number of models.", "labels": [], "entities": []}, {"text": "On the official test run, we ranked 7th of 27 teams for the LAS and MLAS metrics.", "labels": [], "entities": [{"text": "LAS", "start_pos": 60, "end_pos": 63, "type": "METRIC", "confidence": 0.7489281296730042}]}, {"text": "Our system obtained the best scores overall for word segmentation, universal POS tagging, and morphological features.", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 48, "end_pos": 65, "type": "TASK", "confidence": 0.7798984944820404}, {"text": "POS tagging", "start_pos": 77, "end_pos": 88, "type": "TASK", "confidence": 0.8389557898044586}]}], "introductionContent": [{"text": "The CoNLL 2018 Shared Task on Multilingual Parsing from Raw Text to Universal Dependencies () requires participants to build systems that take as input raw text, without any linguistic annotation, and output full labelled dependency trees for 82 test treebanks covering 46 different languages.", "labels": [], "entities": [{"text": "Multilingual Parsing from Raw Text to Universal Dependencies", "start_pos": 30, "end_pos": 90, "type": "TASK", "confidence": 0.6868271268904209}]}, {"text": "Besides the labeled attachment score (LAS) used to evaluate systems in the 2017 edition of the Shared Task (, this year's task introduces two new metrics: morphology-aware labeled attachment score (MLAS) and bi-lexical dependency score (BLEX).", "labels": [], "entities": [{"text": "labeled attachment score (LAS)", "start_pos": 12, "end_pos": 42, "type": "METRIC", "confidence": 0.7722466737031937}, {"text": "morphology-aware labeled attachment score (MLAS)", "start_pos": 155, "end_pos": 203, "type": "METRIC", "confidence": 0.7314161275114331}, {"text": "bi-lexical dependency score (BLEX)", "start_pos": 208, "end_pos": 242, "type": "METRIC", "confidence": 0.7697616418202718}]}, {"text": "The Uppsala system focuses exclusively on LAS and MLAS, and consists of a three-step pipeline.", "labels": [], "entities": [{"text": "Uppsala", "start_pos": 4, "end_pos": 11, "type": "DATASET", "confidence": 0.9728025794029236}, {"text": "MLAS", "start_pos": 50, "end_pos": 54, "type": "DATASET", "confidence": 0.5102720856666565}]}, {"text": "The first step is a model for joint sentence and word segmentation which uses the BiRNN-CRF framework of to predict sentence and word boundaries in the raw input and simultaneously marks multiword tokens that need non-segmental analysis.", "labels": [], "entities": [{"text": "joint sentence and word segmentation", "start_pos": 30, "end_pos": 66, "type": "TASK", "confidence": 0.6560914874076843}]}, {"text": "The second component is a part-of-speech (POS) tagger based on, which employs a sentence-based character model and also predicts morphological features.", "labels": [], "entities": [{"text": "part-of-speech (POS) tagger", "start_pos": 26, "end_pos": 53, "type": "TASK", "confidence": 0.6436135470867157}]}, {"text": "The final stage is a greedy transitionbased dependency parser that takes segmented words and their predicted POS tags as input and produces full dependency trees.", "labels": [], "entities": []}, {"text": "While the segmenter and tagger models are trained on a single treebank, the parser uses multi-treebank learning to boost performance and reduce the number of models.", "labels": [], "entities": []}, {"text": "After evaluation on the official test sets , which was run on the TIRA server (), the Uppsala system ranked 7th of 27 systems with respect to LAS, with a macro-average F1 of 72.37, and 7th of 27 systems with respect to MLAS, with a macro-average F1 of 59.20.", "labels": [], "entities": [{"text": "TIRA server", "start_pos": 66, "end_pos": 77, "type": "DATASET", "confidence": 0.9421586096286774}, {"text": "Uppsala system", "start_pos": 86, "end_pos": 100, "type": "DATASET", "confidence": 0.9749938547611237}, {"text": "F1", "start_pos": 168, "end_pos": 170, "type": "METRIC", "confidence": 0.8739979863166809}, {"text": "MLAS", "start_pos": 219, "end_pos": 223, "type": "DATASET", "confidence": 0.5656126737594604}, {"text": "F1", "start_pos": 246, "end_pos": 248, "type": "METRIC", "confidence": 0.7908695936203003}]}, {"text": "It also reached the highest average score for word segmentation, universal POS (UPOS) tagging (90.91), and morphological features (87.59).", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 46, "end_pos": 63, "type": "TASK", "confidence": 0.7703778445720673}, {"text": "universal POS (UPOS) tagging", "start_pos": 65, "end_pos": 93, "type": "TASK", "confidence": 0.5094338804483414}]}, {"text": "Corrigendum: After the test phase was over, we discovered that we had used a non-permitted resource when developing the UPOS tagger for Thai PUD (see Section 4).", "labels": [], "entities": [{"text": "Thai PUD", "start_pos": 136, "end_pos": 144, "type": "DATASET", "confidence": 0.8418405950069427}]}, {"text": "Setting our LAS, MLAS and UPOS scores to 0.00 for Thai PUD gives the corrected scores: LAS 72.31, MLAS 59.17, UPOS 90.50.", "labels": [], "entities": [{"text": "LAS", "start_pos": 12, "end_pos": 15, "type": "METRIC", "confidence": 0.95549076795578}, {"text": "Thai PUD", "start_pos": 50, "end_pos": 58, "type": "DATASET", "confidence": 0.8898947238922119}, {"text": "LAS 72.31", "start_pos": 87, "end_pos": 96, "type": "METRIC", "confidence": 0.9456649124622345}]}, {"text": "This does not affect the ranking for any of the three scores, as confirmed by the shared task organizers.", "labels": [], "entities": []}], "datasetContent": [{"text": "In addition to the official shared task evaluation, we also participated in the 2018 edition of the Extrinsic Parser Evaluation Initiative (EPE), where parsers developed for the CoNLL 2018 shared task were evaluated with respect to their contribution to three downstream systems: biological event extraction, fine-grained opinion analysis, and negation resolution.", "labels": [], "entities": [{"text": "biological event extraction", "start_pos": 280, "end_pos": 307, "type": "TASK", "confidence": 0.737227996190389}, {"text": "fine-grained opinion analysis", "start_pos": 309, "end_pos": 338, "type": "TASK", "confidence": 0.5492793222268423}, {"text": "negation resolution", "start_pos": 344, "end_pos": 363, "type": "TASK", "confidence": 0.9868941307067871}]}, {"text": "The downstream systems are available for English only, and we participated with our English model trained on English EWT, English LinES and English GUM, using English EWT as the proxy.", "labels": [], "entities": [{"text": "LinES", "start_pos": 130, "end_pos": 135, "type": "METRIC", "confidence": 0.4246055781841278}, {"text": "GUM", "start_pos": 148, "end_pos": 151, "type": "METRIC", "confidence": 0.7190772294998169}]}, {"text": "In the extrinsic evaluation, the Uppsala system ranked second for event extraction, first for opinion analysis, and 16th (out of 16 systems) for negation resolution.", "labels": [], "entities": [{"text": "extrinsic evaluation", "start_pos": 7, "end_pos": 27, "type": "TASK", "confidence": 0.9265742599964142}, {"text": "Uppsala", "start_pos": 33, "end_pos": 40, "type": "DATASET", "confidence": 0.9623215794563293}, {"text": "event extraction", "start_pos": 66, "end_pos": 82, "type": "TASK", "confidence": 0.8083964586257935}, {"text": "opinion analysis", "start_pos": 94, "end_pos": 110, "type": "TASK", "confidence": 0.7952893972396851}, {"text": "negation resolution", "start_pos": 145, "end_pos": 164, "type": "TASK", "confidence": 0.9899422526359558}]}, {"text": "Our results for the first two tasks are better than expected, given that our system ranks in the middle with respect to intrinsic evaluation on English (9th for LAS, 6th for UPOS).", "labels": [], "entities": [{"text": "LAS", "start_pos": 161, "end_pos": 164, "type": "METRIC", "confidence": 0.8895365595817566}]}, {"text": "By contrast, our performance is very low on the negation resolution task, which we suspect is due to the fact that our system only predicts universal part-of-speech tags (UPOS) and not the language specific PTB tags (XPOS), since the three systems that only predict UPOS are all ranked at the bottom of the list.", "labels": [], "entities": [{"text": "negation resolution task", "start_pos": 48, "end_pos": 72, "type": "TASK", "confidence": 0.9465949138005575}]}], "tableCaptions": [{"text": " Table 1: Hyper-parameter values for parsing.", "labels": [], "entities": [{"text": "parsing", "start_pos": 37, "end_pos": 44, "type": "TASK", "confidence": 0.9751885533332825}]}, {"text": " Table 2: Results for LAS (+ mono-treebank baseline), MLAS, sentence and word segmentation, UPOS  tagging and morphological features (UFEATS). Treebanks sharing a parsing model grouped together;  substitute and proxy treebanks for segmentation, tagging, parsing far right (SPECIAL models detailed in  the text). Confidence intervals for coloring: | < \u00b5\u2212\u03c3 < | < \u00b5\u2212SE < \u00b5 < \u00b5+SE < | < \u00b5+\u03c3 < | .", "labels": [], "entities": [{"text": "sentence and word segmentation", "start_pos": 60, "end_pos": 90, "type": "TASK", "confidence": 0.6605756506323814}, {"text": "UPOS  tagging", "start_pos": 92, "end_pos": 105, "type": "TASK", "confidence": 0.6831593811511993}]}]}