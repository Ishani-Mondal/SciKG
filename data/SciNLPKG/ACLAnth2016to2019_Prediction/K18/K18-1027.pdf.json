{"title": [{"text": "Similarity dependent Chinese Restaurant Process for Cognate Identification in Multilingual Wordlists", "labels": [], "entities": [{"text": "Cognate Identification", "start_pos": 52, "end_pos": 74, "type": "TASK", "confidence": 0.7270728647708893}]}], "abstractContent": [{"text": "We present and evaluate two similarity dependent Chinese Restaurant Process (sd-CRP) algorithms at the task of automated cognate detection.", "labels": [], "entities": [{"text": "automated cognate detection", "start_pos": 111, "end_pos": 138, "type": "TASK", "confidence": 0.7018448909123739}]}, {"text": "The sd-CRP clustering algorithms do not require any predefined threshold for detecting cognate sets in a multilingual word list.", "labels": [], "entities": [{"text": "sd-CRP clustering", "start_pos": 4, "end_pos": 21, "type": "TASK", "confidence": 0.8316127359867096}]}, {"text": "We evaluate the performance of the algorithms on six language families (more than 750 languages) and find that both the sd-CRP variants performs as well as InfoMap and better than UPGMA at the task of inferring cognate clusters.", "labels": [], "entities": []}, {"text": "The algorithms presented in this paper are family agnostic and can be applied to any linguistically under-studied language family.", "labels": [], "entities": []}], "introductionContent": [{"text": "Cognates are related words across languages that have descended from a common ancestral language.", "labels": [], "entities": []}, {"text": "Identification of cognates is an important step in historical linguistics while establishing genetic relations between languages that are hypothesized to have descended from a single language that existed in the past.", "labels": [], "entities": [{"text": "Identification of cognates", "start_pos": 0, "end_pos": 26, "type": "TASK", "confidence": 0.9033721288045248}, {"text": "historical linguistics", "start_pos": 51, "end_pos": 73, "type": "TASK", "confidence": 0.7535971701145172}]}, {"text": "For instance, English hound and German Hund \"dog\" are cognates that go back to the Proto-Germanic stage.", "labels": [], "entities": []}, {"text": "Cognate identification requires great amount of scholarly effort and is available for some language families such as Indo-European, Dravidian, Austronesian, and Uralic which have along tradition of comparative linguistic research that involves decades (Dravidian family) to centuries (Indo-European family) of scholarly effort.", "labels": [], "entities": [{"text": "Cognate identification", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.9009140729904175}]}, {"text": "Automatic detection of cognates with high accuracy is very much desired for reducing the effort required in analyzing understudied language families of the world.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 42, "end_pos": 50, "type": "METRIC", "confidence": 0.9894875288009644}]}, {"text": "Typically, expert annotated cognate sets are employed to infer phylogenetic trees showing language relationships that can be used to test hypotheses about temporal and spatial evolution of language families, linguistic reconstruction of ancestral states on a tree , or lexical reconstruction ().", "labels": [], "entities": [{"text": "linguistic reconstruction of ancestral states", "start_pos": 208, "end_pos": 253, "type": "TASK", "confidence": 0.7851081132888794}, {"text": "lexical reconstruction", "start_pos": 269, "end_pos": 291, "type": "TASK", "confidence": 0.7325572669506073}]}, {"text": "showed that cognates inferred from automated methods of cognate detection can be used to infer high quality phylogenetic trees.", "labels": [], "entities": [{"text": "cognate detection", "start_pos": 56, "end_pos": 73, "type": "TASK", "confidence": 0.7966771423816681}]}, {"text": "The authors noted that there is a need for more research towards developing highly accurate cognate identification methods that can be applied to the data of not so well-studied language families which will be of assistance to historical linguists to automate parts if not the whole of the comparative method.", "labels": [], "entities": []}, {"text": "The last decades have seen a large amount of computational effort towards automatizing the process of cognate identification since the work of and.", "labels": [], "entities": [{"text": "cognate identification", "start_pos": 102, "end_pos": 124, "type": "TASK", "confidence": 0.71315036714077}]}, {"text": "The computational effort involved devising new sequence alignment algorithms), novel sound transition matrices which are linguistically guided or data-driven, and machine learning approaches () to identify cognates within multilingual word lists (see; belonging to different language families and dictionaries).", "labels": [], "entities": [{"text": "sequence alignment", "start_pos": 47, "end_pos": 65, "type": "TASK", "confidence": 0.7260693162679672}]}, {"text": "Most of the above cognate identification methods involve a workflow consisting of computation of distances between all the word pairs that have the same meaning using a machine learning algorithm or a sequence alignment algorithm; and, then clustering the pairwise distance matrix using a clustering algorithm such as InfoMap ( or UPGMA (Unweighted Pair Group Method with Arithmetic Mean;.", "labels": [], "entities": []}, {"text": "Both InfoMap and UPGMA require a predefined threshold that is either set heuristically or through tuned to obtain to obtain optimal perfor-Language ALL AND . .", "labels": [], "entities": [{"text": "UPGMA", "start_pos": 17, "end_pos": 22, "type": "DATASET", "confidence": 0.8216390609741211}]}, {"text": "On the other hand, a non-parametric clustering method such as Chinese Restaurant Process (CRP; Gershman and Blei 2012) can form clusters directly from the data without the need for tuning the threshold.", "labels": [], "entities": [{"text": "Chinese Restaurant Process (CRP; Gershman and Blei 2012", "start_pos": 62, "end_pos": 117, "type": "DATASET", "confidence": 0.859469187259674}]}, {"text": "CRP has found application in different NLP tasks such as morphological segmentation (), language modeling), machine translation (, part-of-speech induction (, and language decipherment.", "labels": [], "entities": [{"text": "morphological segmentation", "start_pos": 57, "end_pos": 83, "type": "TASK", "confidence": 0.7678959965705872}, {"text": "language modeling", "start_pos": 88, "end_pos": 105, "type": "TASK", "confidence": 0.7819481790065765}, {"text": "machine translation", "start_pos": 108, "end_pos": 127, "type": "TASK", "confidence": 0.8475439548492432}, {"text": "part-of-speech induction", "start_pos": 131, "end_pos": 155, "type": "TASK", "confidence": 0.7188562452793121}, {"text": "language decipherment", "start_pos": 163, "end_pos": 184, "type": "TASK", "confidence": 0.7452245950698853}]}], "datasetContent": [{"text": "In this section, we describe the datasets and cluster evaluation metrics.", "labels": [], "entities": []}, {"text": "Training dataset and compiled cognacy annotated multilingual word lists for subsets of families from various scholarly sources such as comparative handbooks and historical linguistics' articles.", "labels": [], "entities": []}, {"text": "The detailed references to all the datasets are given in.", "labels": [], "entities": []}, {"text": "Below, we provide the number of languages/number of meanings in each language group in parantheses.", "labels": [], "entities": []}, {"text": "\u2022  We use B-cubed F-score) and Adjusted Rand Index ( to evaluate the quality of the inferred clusters.", "labels": [], "entities": [{"text": "B-cubed F-score", "start_pos": 10, "end_pos": 25, "type": "METRIC", "confidence": 0.7882939279079437}, {"text": "Adjusted Rand Index", "start_pos": 31, "end_pos": 50, "type": "METRIC", "confidence": 0.8491819500923157}]}, {"text": "B-cubed F-scores are defined for each individual item (word) as follows.", "labels": [], "entities": [{"text": "B-cubed", "start_pos": 0, "end_pos": 7, "type": "METRIC", "confidence": 0.9263697862625122}, {"text": "F-scores", "start_pos": 8, "end_pos": 16, "type": "METRIC", "confidence": 0.5393527150154114}]}, {"text": "The precision for an item is defined as the ratio between the number of cognates in its cluster to the total number of items in its cluster.", "labels": [], "entities": [{"text": "precision", "start_pos": 4, "end_pos": 13, "type": "METRIC", "confidence": 0.9990432858467102}]}, {"text": "The recall for an item is defined as the ratio between the number of cognates in its cluster to the total number of expert labeled cognates.", "labels": [], "entities": [{"text": "recall", "start_pos": 4, "end_pos": 10, "type": "METRIC", "confidence": 0.9986300468444824}]}, {"text": "Finally, the B-cubed F-score fora meaning is computed as the harmonic mean of the items' average precision and recall.", "labels": [], "entities": [{"text": "B-cubed F-score", "start_pos": 13, "end_pos": 28, "type": "METRIC", "confidence": 0.78780397772789}, {"text": "precision", "start_pos": 97, "end_pos": 106, "type": "METRIC", "confidence": 0.9974347949028015}, {"text": "recall", "start_pos": 111, "end_pos": 117, "type": "METRIC", "confidence": 0.9952375888824463}]}, {"text": "The B-cubed F-score for the whole dataset is computed as the average of the B-cubed F-scores across all the meanings.", "labels": [], "entities": [{"text": "B-cubed F-score", "start_pos": 4, "end_pos": 19, "type": "METRIC", "confidence": 0.8080695271492004}]}, {"text": "Adjusted Rand Index (ARI) is a chance corrected version of rand index.", "labels": [], "entities": [{"text": "Adjusted Rand Index (ARI)", "start_pos": 0, "end_pos": 25, "type": "METRIC", "confidence": 0.8875621755917867}]}, {"text": "The ARI scores are in the range of \u22121 to +1.", "labels": [], "entities": [{"text": "ARI", "start_pos": 4, "end_pos": 7, "type": "METRIC", "confidence": 0.9575294256210327}]}, {"text": "A score of 0 indicates that the obtained clusters are randomly labelled whereas a score +1 indicates perfect match between the two clusters.", "labels": [], "entities": []}, {"text": "The ARI score is zero whenever the gold standard groups all the words belonging to the same meaning slot (e.g. words for meaning name are cognate across the daughter Indo-European languages) as one cluster, whereas the B-cubed F-score is not zero in such a case.", "labels": [], "entities": [{"text": "ARI score", "start_pos": 4, "end_pos": 13, "type": "METRIC", "confidence": 0.9821836948394775}, {"text": "F-score", "start_pos": 227, "end_pos": 234, "type": "METRIC", "confidence": 0.5313939452171326}]}], "tableCaptions": [{"text": " Table 1: Excerpt of the Indo-European word list  (from our dataset) in ASJP code for five languages  belonging to Germanic (English, German, and  Swedish) and Romance (Spanish and French) sub- families. Cognates are indicated with the same su- perscript.", "labels": [], "entities": []}, {"text": " Table 2: The second, third, and fourth columns show the", "labels": [], "entities": []}, {"text": " Table 4: Results of feature ablation experiments on  Austronesian and Austro-Asiatic datasets.", "labels": [], "entities": [{"text": "Austronesian and Austro-Asiatic datasets", "start_pos": 54, "end_pos": 94, "type": "DATASET", "confidence": 0.5951558351516724}]}, {"text": " Table 6: The mean and standard deviation of the F-scores", "labels": [], "entities": [{"text": "F-scores", "start_pos": 49, "end_pos": 57, "type": "METRIC", "confidence": 0.9335567951202393}]}]}