{"title": [{"text": "Churn Intent Detection in Multilingual Chatbot Conversations and Social Media", "labels": [], "entities": [{"text": "Churn Intent Detection", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.8315693140029907}]}], "abstractContent": [{"text": "We propose anew method to detect when users express the intent to leave a service, also known as churn.", "labels": [], "entities": []}, {"text": "While previous work focuses solely on social media, we show that this intent can be detected in chatbot conversations.", "labels": [], "entities": []}, {"text": "As companies increasingly rely on chatbots, they need an overview of potentially churny users.", "labels": [], "entities": []}, {"text": "To this end, we crowdsource and publish a dataset of churn intent expressions in chatbot interactions in German and English.", "labels": [], "entities": []}, {"text": "We show that classifiers trained on social media data can detect the same intent in the context of chat-bots.", "labels": [], "entities": []}, {"text": "We introduce a classification architecture that outperforms existing work on churn intent detection in social media.", "labels": [], "entities": [{"text": "churn intent detection in social media", "start_pos": 77, "end_pos": 115, "type": "TASK", "confidence": 0.7990089257558187}]}, {"text": "Moreover, we show that, using bilingual word embeddings, a system trained on combined English and German data outperforms monolingual approaches.", "labels": [], "entities": []}, {"text": "As the only existing dataset is in English, we crowdsource and publish a novel dataset of German tweets.", "labels": [], "entities": []}, {"text": "We thus underline the universal aspect of the problem, as examples of churn intent in English help us identify churn in German tweets and chatbot conversations.", "labels": [], "entities": []}], "introductionContent": [{"text": "Identifying customers who intend to terminate their relation with a company is commonly known as churn detection.", "labels": [], "entities": [{"text": "Identifying customers who intend to terminate their relation with a company", "start_pos": 0, "end_pos": 75, "type": "TASK", "confidence": 0.7778051983226429}, {"text": "churn detection", "start_pos": 97, "end_pos": 112, "type": "TASK", "confidence": 0.9058184027671814}]}, {"text": "This is very important for companies if we consider that attracting new customers is a time and cost-intensive task.", "labels": [], "entities": []}, {"text": "Therefore, it is often preferable for companies to focus on the existing customers in order to prevent losing them instead of trying to acquire new ones.", "labels": [], "entities": []}, {"text": "Traditionally, churn detection is based on tracking the user behavior and correlating it with the decision to churn.", "labels": [], "entities": [{"text": "churn detection", "start_pos": 15, "end_pos": 30, "type": "TASK", "confidence": 0.9512863159179688}]}, {"text": "The analysis of the user behavior typically includes metadata such as the subscription information, network usage or customer transactions ().", "labels": [], "entities": []}], "datasetContent": [{"text": "In this work, we use pairs of datasets from two different languages (English and German) with the certainty that churn detection is a universal problem and therefore does not depend on the language.", "labels": [], "entities": [{"text": "churn detection", "start_pos": 113, "end_pos": 128, "type": "TASK", "confidence": 0.8689343631267548}]}, {"text": "Each pair is composed of a Twitter and a chatbot conversations dataset denoted as Lang T  The dataset is introduced by Hadi Amiri and is composed of English tweets that show mentions of Verizon, AT&T, and T-Mobile (telecommunication brands).", "labels": [], "entities": []}, {"text": "Each tweet is associated with a source brand (name of the company that is targeted by the tweet) and a label (1 or 0 whether the content is churny or not).", "labels": [], "entities": []}, {"text": "tabulates the exact distribution of the data as a function of the source brand where churn is the number of churny tweets associated to the brand and non churn the number of non-churny ones.", "labels": [], "entities": []}, {"text": "Overall, the dataset contains 4339 2 labeled tweets and is highly imbalanced regarding the distribution of churny/nonchurny tweets.", "labels": [], "entities": []}, {"text": "Since there is no existing dataset for churn detection except for English, we create a novel German dataset.", "labels": [], "entities": [{"text": "churn detection", "start_pos": 39, "end_pos": 54, "type": "TASK", "confidence": 0.8715395927429199}, {"text": "German dataset", "start_pos": 93, "end_pos": 107, "type": "DATASET", "confidence": 0.8708072900772095}]}, {"text": "As a first step, we crawl all mentions on Twitter of multiple telecommunication brands that are active in German-speaking countries fora period of six months.", "labels": [], "entities": []}, {"text": "The result is a large Twitter dataset, DE T F U LL , containing more than 160000 tweets.", "labels": [], "entities": [{"text": "Twitter dataset", "start_pos": 22, "end_pos": 37, "type": "DATASET", "confidence": 0.7462665438652039}, {"text": "DE T F U LL", "start_pos": 39, "end_pos": 50, "type": "METRIC", "confidence": 0.8967611908912658}]}, {"text": "However, labeling such a large corpus The created datasets are publicly available at https: //github.com/swisscom/churn-intent-DE 2 We only keep those with annotation confidence above 0.7 as in: Non-exhaustive list of word filters used to detect potential churny tweets in German. is extremely time intensive and would result in a waste of resources since the density of churny tweets is extremely low.", "labels": [], "entities": []}, {"text": "A solution to reduce the size of DE T F U LL is to apply filters composed of predefined keywords to isolate potential churny tweets and generate a sub-dataset of candidates, DE T F ILT ER , as depicted in.", "labels": [], "entities": [{"text": "DE T F U LL", "start_pos": 33, "end_pos": 44, "type": "DATASET", "confidence": 0.4760752201080322}, {"text": "DE T F ILT ER", "start_pos": 174, "end_pos": 187, "type": "METRIC", "confidence": 0.557508397102356}]}, {"text": "Those keywords are manually selected and are assumed to be linked with or carry churny content.", "labels": [], "entities": []}, {"text": "A nonexhaustive list of used keywords is displayed in.", "labels": [], "entities": []}, {"text": "The resulting subset, DE T F ILT ER , is given to annotation through a platform specifically created for this purpose.", "labels": [], "entities": [{"text": "DE T F ILT ER", "start_pos": 22, "end_pos": 35, "type": "METRIC", "confidence": 0.7866740107536316}]}, {"text": "All tweets are annotated by at least two annotators.", "labels": [], "entities": []}, {"text": "We keep in our dataset only the entries where both annotators agree on the label.", "labels": [], "entities": []}, {"text": "We train the first version of our model with the newly labeled subset and then apply it to our initial dataset DE  The final result is German Twitter dataset as The complete distribution of the labels of DE T is displayed in for comparison purposes with EN T . Here, three main companies emerged from our dataset, namely O2, Vodafone and Telekom (all other brands are grouped in the table as Others).", "labels": [], "entities": [{"text": "German Twitter dataset", "start_pos": 135, "end_pos": 157, "type": "DATASET", "confidence": 0.9361027479171753}, {"text": "O2", "start_pos": 321, "end_pos": 323, "type": "DATASET", "confidence": 0.9250773787498474}]}, {"text": "It is interesting to note that the size and distribution of the labels of the German dataset is comparable to the English one which allows fair performance comparison across languages.", "labels": [], "entities": [{"text": "German dataset", "start_pos": 78, "end_pos": 92, "type": "DATASET", "confidence": 0.9338112473487854}]}, {"text": "For textual churn detection, we design and report on the performance of three experiments: \u2022 Training on EN T and testing on EN T using English monolingual embeddings.", "labels": [], "entities": [{"text": "textual churn detection", "start_pos": 4, "end_pos": 27, "type": "TASK", "confidence": 0.6633507013320923}]}, {"text": "\u2022 Training on DE T and testing on DE T using German monolingual embeddings.", "labels": [], "entities": []}, {"text": "\u2022 Training on (EN+DE) T and testing on EN T and DE T using multilingual embeddings.", "labels": [], "entities": []}, {"text": "For all experiments, a consistent model with the same hyper-parameters is used to ensure a fair comparison.", "labels": [], "entities": []}, {"text": "We employ 256 filters with a kernel size of 2 for the convolutional layer.", "labels": [], "entities": []}, {"text": "In addition, we set the number of GRU units to 128 and apply a dropout with a rate of 0.3.", "labels": [], "entities": []}, {"text": "Finally, we use the Adam optimizer with its default parameters.", "labels": [], "entities": []}, {"text": "To allow a fair comparison, 10-fold cross validation is used as in.", "labels": [], "entities": []}, {"text": "This ensures that the results are less affected by the train/test split and all models are trained until convergence for each fold.", "labels": [], "entities": []}, {"text": "In the end, the mean and standard deviation of macro precision, recall and F1-score are computed over the maximum of each fold.", "labels": [], "entities": [{"text": "precision", "start_pos": 53, "end_pos": 62, "type": "METRIC", "confidence": 0.8827210068702698}, {"text": "recall", "start_pos": 64, "end_pos": 70, "type": "METRIC", "confidence": 0.999656081199646}, {"text": "F1-score", "start_pos": 75, "end_pos": 83, "type": "METRIC", "confidence": 0.9993994235992432}]}, {"text": "We execute all experiments 20 times, test them under statistical dependence and reject with a threshold of \u03b1 = 5%.", "labels": [], "entities": []}, {"text": "For chatbot conversations, we directly evaluate the best model trained on datasets from social media on chatbot conversation data.", "labels": [], "entities": []}, {"text": "We report the performance for the following three experiments in Section 5.3: \u2022 Best model trained on EN T and tested on EN C using English embeddings.", "labels": [], "entities": [{"text": "EN T", "start_pos": 102, "end_pos": 106, "type": "DATASET", "confidence": 0.8873896896839142}]}, {"text": "\u2022 Best model trained on DE T and tested on DEC using German embeddings.", "labels": [], "entities": [{"text": "DE T", "start_pos": 24, "end_pos": 28, "type": "DATASET", "confidence": 0.9265999495983124}, {"text": "DEC", "start_pos": 43, "end_pos": 46, "type": "DATASET", "confidence": 0.9822598099708557}]}, {"text": "\u2022 Best model trained on (EN+DE) T and tested on EN C and DEC using multilingual embeddings.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Distribution of English tweets along the dif- ferent brands.", "labels": [], "entities": [{"text": "Distribution of English tweets", "start_pos": 10, "end_pos": 40, "type": "TASK", "confidence": 0.8429100066423416}]}, {"text": " Table 2: Non-exhaustive list of word filters used to  detect potential churny tweets in German.", "labels": [], "entities": []}, {"text": " Table 4: Distribution of labels in chatbot conversations  for both languages (EN/DE).", "labels": [], "entities": []}, {"text": " Table 5: Performance comparison of our model on English against the current state-of-the-art", "labels": [], "entities": []}, {"text": " Table 6: Results on chatbot conversations. EN and DE are scores for language dependent models using mono- lingual embeddings. EN+DE are for system trained on both languages at the same time using multilingual word  embeddings. We distinguish Twitter from chatbot dataset using respectively the indices T and C.", "labels": [], "entities": [{"text": "DE", "start_pos": 51, "end_pos": 53, "type": "METRIC", "confidence": 0.9598715305328369}]}]}