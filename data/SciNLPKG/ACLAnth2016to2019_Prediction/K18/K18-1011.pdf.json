{"title": [{"text": "Comparing Attention-based Convolutional and Recurrent Neural Networks: Success and Limitations in Machine Reading Comprehension", "labels": [], "entities": [{"text": "Machine Reading Comprehension", "start_pos": 98, "end_pos": 127, "type": "TASK", "confidence": 0.7622732917467753}]}], "abstractContent": [{"text": "We propose a machine reading comprehension model based on the compare-aggregate framework with two-staged attention that achieves state-of-the-art results on the MovieQA question answering dataset.", "labels": [], "entities": [{"text": "MovieQA question answering dataset", "start_pos": 162, "end_pos": 196, "type": "DATASET", "confidence": 0.8763410747051239}]}, {"text": "To investigate the limitations of our model as well as the behavioral difference between convolutional and recurrent neural networks, we generate adversarial examples to confuse the model and compare to human performance.", "labels": [], "entities": []}, {"text": "Furthermore, we assess the generalizability of our model by analyzing its differences to human inference, drawing upon insights from cognitive science.", "labels": [], "entities": []}], "introductionContent": [{"text": "Current state-of-the-art deep learning (DL) models outperform other techniques in many tasks including computer vision (, speech recognition (  and more recently natural language processing (NLP)).", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 122, "end_pos": 140, "type": "TASK", "confidence": 0.7625725567340851}, {"text": "natural language processing (NLP))", "start_pos": 162, "end_pos": 196, "type": "TASK", "confidence": 0.7586399018764496}]}, {"text": "Neural-based NLP systems often use word embeddings) which are then fed into a convolutional neural network (CNN) () or a recurrent neural network (RNN)) for further classification.", "labels": [], "entities": []}, {"text": "These approaches proved to be successful for many NLP tasks ().", "labels": [], "entities": []}, {"text": "Along with the success of DL in a wide range of applications, adversarial examples (  -that aim to confuse the system -have gained popularity in a wide range of research communities such as computer vision and NLP, since they can reveal the limitations in the generalizability of the models.", "labels": [], "entities": []}, {"text": "As opposed to adversarial examples in computer vision, which are computed on continuous data and can thus easily be imperceptible if desired, adversarial attacks in NLP entail the necessity to perform discrete and perceptible changes to the data.", "labels": [], "entities": []}, {"text": "Thus, attack methods for computer vision such as the Fast Gradient Sign Method (FGSM) ( ) cannot be directly applied to NLP.", "labels": [], "entities": [{"text": "Fast Gradient Sign Method (FGSM)", "start_pos": 53, "end_pos": 85, "type": "METRIC", "confidence": 0.6264926450593131}]}, {"text": "Machine comprehension has recently received increased interest in the NLP community.", "labels": [], "entities": [{"text": "Machine comprehension", "start_pos": 0, "end_pos": 21, "type": "TASK", "confidence": 0.827020138502121}]}, {"text": "Neural network models perform reasonably well on many data sets with different question answering setups, e.g. multiple choice or answer generation (.", "labels": [], "entities": [{"text": "answer generation", "start_pos": 130, "end_pos": 147, "type": "TASK", "confidence": 0.7336650788784027}]}, {"text": "Among others, proposed the compare-aggregate framework, which uses an attention mechanism ( to compare the question and candidate answers, and a CNN to aggregate information.", "labels": [], "entities": []}, {"text": "However, there is still an ongoing debate whether CNNs or RNNs are more suitable to NLP, and the behavioral differences between them are still under research.", "labels": [], "entities": []}, {"text": "Many papers reported remarkable gains when combining these two models in ensembles), since they process information in different ways and thus are complimentary to each other.", "labels": [], "entities": []}, {"text": "Despite the seemingly high accuracies of many models on machine comprehension tasks, argued that many questions in such datasets are easily solvable by superficial cues.", "labels": [], "entities": []}, {"text": "They showed with adversarial examples that most models can be easily tricked by modifications on the data which do not confuse humans.", "labels": [], "entities": []}, {"text": "Similarly, performed controlled experiments on the robustness of several Natural Language Inference models by altering hypernym, hyponym, and antonym relations in the data.", "labels": [], "entities": []}, {"text": "Both studies revealed a major weakness of the models: They largely rely on pattern matching instead of human decision-making processes as required in the tasks, including heuristics) and elimination by aspects.", "labels": [], "entities": []}, {"text": "In this paper, we implement two machine comprehension models based on the compareaggregate framework with a hierarchical attention structure using CNNs and RNNs.", "labels": [], "entities": []}, {"text": "First we show that we achieve state-of-the-art results on the MovieQA multiple choice question answering dataset ( outperforming other systems by a large margin.", "labels": [], "entities": [{"text": "MovieQA multiple choice question answering dataset", "start_pos": 62, "end_pos": 112, "type": "DATASET", "confidence": 0.8456927041212717}]}, {"text": "1 Second, we investigate the different behavior of the two systems applying adversarial attacks in a systematic way.", "labels": [], "entities": []}, {"text": "To our best knowledge, this is the first work exploring the difference between CNNs and RNNs by such an approach.", "labels": [], "entities": []}, {"text": "Third, we present a detailed comparison between human and machine reading comprehension, giving insights when and why our systems fail.", "labels": [], "entities": []}, {"text": "Therefore, these insights are important for future research towards enhancing machine comprehension systems loosely inspired by human processing.", "labels": [], "entities": []}, {"text": "All code necessary to reproduce our experimental results is made available.", "labels": [], "entities": []}], "datasetContent": [{"text": "The hyperparameters for our models are provided in \u00a7A.1 in the appendix.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: MovieQA accuracies for previously published  results and our proposed single models (best out of 11)  and ensembles (nine best out of 11).", "labels": [], "entities": [{"text": "MovieQA", "start_pos": 10, "end_pos": 17, "type": "DATASET", "confidence": 0.7410582900047302}, {"text": "accuracies", "start_pos": 18, "end_pos": 28, "type": "METRIC", "confidence": 0.7569799423217773}]}, {"text": " Table 2: Percentage of questions in which the plot sen- tences containing the clues for the answer are ranked  highest according to the model's sentence attention dis- tribution (relative to its selected answer) on the valida- tion set (averaged results of nine models).", "labels": [], "entities": [{"text": "sentence attention dis- tribution", "start_pos": 145, "end_pos": 178, "type": "METRIC", "confidence": 0.7742377281188965}]}, {"text": " Table 3: Adversarial accuracies on the validation set  under the word-level black-box attack based on manual  lexical substitutions in questions.", "labels": [], "entities": []}, {"text": " Table 4: Adversarial accuracies on 200 random vali- dation questions under the sentence-level black-box at- tacks (averaged results of nine models).", "labels": [], "entities": []}, {"text": " Table 5: AddQA attack results when testing models on  adversarial examples optimized to fool another model  (averaged results of nine models).", "labels": [], "entities": []}]}