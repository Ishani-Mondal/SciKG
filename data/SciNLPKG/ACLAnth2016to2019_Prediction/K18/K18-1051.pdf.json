{"title": [{"text": "Modelling Salient Features as Directions in Fine-Tuned Semantic Spaces", "labels": [], "entities": []}], "abstractContent": [{"text": "In this paper we consider semantic spaces consisting of objects from some particular domain (e.g. IMDB movie reviews).", "labels": [], "entities": []}, {"text": "Various authors have observed that such semantic spaces often model salient features (e.g. how scary a movie is) as directions.", "labels": [], "entities": []}, {"text": "These feature directions allow us to rank objects according to how much they have the corresponding feature , and can thus play an important role in interpretable classifiers, recommendation systems , or entity-oriented search engines, among others.", "labels": [], "entities": []}, {"text": "Methods for learning semantic spaces, however, are mostly aimed at modelling similarity.", "labels": [], "entities": []}, {"text": "In this paper, we argue that there is an inherent trade-off between capturing similarity and faithfully modelling features as directions.", "labels": [], "entities": []}, {"text": "Following this observation, we propose a simple method to fine-tune existing semantic spaces, with the aim of improving the quality of their feature directions.", "labels": [], "entities": []}, {"text": "Crucially, our method is fully unsupervised, requiring only a bag-of-words representation of the objects as input.", "labels": [], "entities": []}], "introductionContent": [{"text": "Vector space representations, or 'embeddings', play a crucial role in various areas of natural language processing.", "labels": [], "entities": [{"text": "natural language processing", "start_pos": 87, "end_pos": 114, "type": "TASK", "confidence": 0.6385977466901144}]}, {"text": "For instance, word embeddings () are routinely used as representations of word meaning, while knowledge graph embeddings () are used to find plausible missing information in structured knowledge bases, or to exploit such knowledge bases in neural network architectures.", "labels": [], "entities": []}, {"text": "In this paper we focus on domainspecific semantic spaces, i.e. vector space representations of the objects of a single domain, as opposed to the more heterogeneous setting of e.g. word embeddings.", "labels": [], "entities": []}, {"text": "Such domain-specific semantic spaces are used, for instance, to represent items in recommender systems (, to represent entities in semantic search engines (, or to represent examples in classification tasks.", "labels": [], "entities": []}, {"text": "In many semantic spaces it is possible to find directions that correspond to salient features from the considered domain.", "labels": [], "entities": []}, {"text": "For instance, found that features of countries, such as their GDP, fertility rate or even level of CO 2 emissions, can be predicted from word embeddings using a linear regression model.", "labels": [], "entities": []}, {"text": "Similarly, in) directions in word embeddings were found that correspond to adjectival scales (e.g. bad < okay < good < excellent) while found directions indicating lexical features such as the frequency of occurrence and polarity of words.", "labels": [], "entities": []}, {"text": "Finally, found directions corresponding to properties such as 'Scary', 'Romantic' or 'Hilarious' in a semantic space of movies.", "labels": [], "entities": []}, {"text": "In our work, we focus on improving the representation of these feature directions in domainspecific semantic spaces.", "labels": [], "entities": []}, {"text": "Such feature directions are useful in a wide variety of applications.", "labels": [], "entities": []}, {"text": "The most immediate example is perhaps that they allow fora natural way to implement critique-based recommendation systems, where users can specify how their desired result should relate to a given set of suggestions ().", "labels": [], "entities": []}, {"text": "For instance, propose a movie recommendation system in which the user can specify that they want to see suggestions for movies that are \"similar to this one, but scarier\".", "labels": [], "entities": []}, {"text": "If the property of being scary is adequately modelled as a direction in a semantic space of movies, such critiques can be addressed in a straightforward way.", "labels": [], "entities": []}, {"text": "Similarly, in () a system was developed that can find \"shoes like these but shinier\", based on a semantic space representation that was derived from visual features.", "labels": [], "entities": []}, {"text": "Semantic search systems can use such directions to interpret queries involving gradual and possibly ill-defined features, such as \"popular holiday destinations in Europe\" (.", "labels": [], "entities": []}, {"text": "While features such as popularity are typically not encoded in traditional knowledge bases, they can often be represented as semantic space directions.", "labels": [], "entities": []}, {"text": "As another application, feature directions can also be used in interpretable classifiers.", "labels": [], "entities": []}, {"text": "For example, learned rule based classifiers from rankings induced by the feature directions.", "labels": [], "entities": []}, {"text": "Along similar lines, in this paper we will use shallow decision trees to evaluate the quality of our feature directions.", "labels": [], "entities": []}, {"text": "In the aforementioned applications, feature directions are typically emerging from vector space representations that have been learned with a similarity-centred objective, i.e. the main consideration when learning these representations is that similar objects should be represented as similar vectors.", "labels": [], "entities": []}, {"text": "An important observation is that such spaces may not actually be optimal for modelling feature directions.", "labels": [], "entities": []}, {"text": "To illustrate why this can be the case, shows a toy example in which basic geometric shapes are embedded in a twodimensional space.", "labels": [], "entities": []}, {"text": "Within this space, we can identify directions which encode how light an object is and how closely its shape resembles a square.", "labels": [], "entities": []}, {"text": "While most of the shapes embedded in this space are grey-scale circles and squares, one of the shapes embedded in this space is a red triangle, which is a clear outlier.", "labels": [], "entities": []}, {"text": "If this space is learned with a similarity-centred objective, the representation of the triangle will be far from all the other shapes.", "labels": [], "entities": []}, {"text": "However, this means that outliers like this will often take up extreme positions in the rankings induced by the feature directions, and may thus lead us to incorrectly assume that they have certain features.", "labels": [], "entities": []}, {"text": "In this example, the triangle would incorrectly be considered as the shape which most exhibits the features \"light\" and \"square\".", "labels": [], "entities": []}, {"text": "In contrast, if we had learned the representation with the knowledge that it should model these two features rather than similarity, this triangle would have ended up closer to the bottom-left corner.", "labels": [], "entities": []}, {"text": "Unfortunately, we usually have no a priori knowledge of which are the most salient features.", "labels": [], "entities": []}, {"text": "In this paper, we therefore suggest the following fully unsupervised strategy.", "labels": [], "entities": []}, {"text": "First, we learn a semantic space from bag-of-words representations of the considered objects, using a standard similarity-centric method.", "labels": [], "entities": []}, {"text": "Using the method from, we subsequently determine the most salient features in the considered domain, and their corresponding directions.", "labels": [], "entities": []}, {"text": "Finally, we fine-tune the semantic space and the associated feature directions, modelling the considered features in a more faithful way.", "labels": [], "entities": []}, {"text": "This last step is the main contribution of this paper.", "labels": [], "entities": []}, {"text": "All code and hyperparameters are available online 1 .", "labels": [], "entities": []}], "datasetContent": [{"text": "To evaluate our method, we consider the problem of learning interpretable classifiers.", "labels": [], "entities": []}, {"text": "In particular, we learn decision trees which are limited to depth 1 and 3, which use the rankings induced by the feature directions as input.", "labels": [], "entities": []}, {"text": "This allows us to simultaneously assess to what extent the method can identify the right features and whether these features are modelled well using the learned directions.", "labels": [], "entities": []}, {"text": "Note that depth 1 trees are only a single direction and a cut-off, so to perform well, the method needs to identify a highly relevant feature to the considered category.", "labels": [], "entities": []}, {"text": "Depth 3 decision trees are able to model categories that can be characterized using at most three feature directions.", "labels": [], "entities": []}, {"text": "We evaluate our method on four datasets.", "labels": [], "entities": []}, {"text": "First, we used the movies and place-types datasets from, which are available in preprocessed form . The former describes 15000 movies, using a BoW representation that was obtained by combining reviews from several sources.", "labels": [], "entities": []}, {"text": "However, 1022 duplicate movies were found in the data, which we removed.", "labels": [], "entities": []}, {"text": "The associated classification tasks are to predict the movie genres according to IMDB (23 classes), predicting IMDB plot keywords such as 'suicide', 'beach' or 'crying' (100 classes) and predicting age rating certificates such as 'UK-15' 'UK-18' or 'USA-R' (6 classes).", "labels": [], "entities": [{"text": "IMDB", "start_pos": 81, "end_pos": 85, "type": "DATASET", "confidence": 0.729363203048706}, {"text": "predicting IMDB plot keywords such as 'suicide'", "start_pos": 100, "end_pos": 147, "type": "TASK", "confidence": 0.6114382280243768}, {"text": "UK-15", "start_pos": 231, "end_pos": 236, "type": "DATASET", "confidence": 0.9603070020675659}, {"text": "UK-18", "start_pos": 239, "end_pos": 244, "type": "DATASET", "confidence": 0.5328764915466309}, {"text": "USA-R", "start_pos": 250, "end_pos": 255, "type": "DATASET", "confidence": 0.7868750095367432}]}, {"text": "All tasks are evaluated as binary classification tasks.", "labels": [], "entities": []}, {"text": "We randomly split the datasets into 2/3 for training and 1/3 for testing.", "labels": [], "entities": []}, {"text": "The place-types dataset was obtained by associating each place-type with the bag of tags that have been used to describe places of that type on Flickr.", "labels": [], "entities": [{"text": "Flickr", "start_pos": 144, "end_pos": 150, "type": "DATASET", "confidence": 0.981487512588501}]}, {"text": "It contains BoW represenations for 1383 different place-types.", "labels": [], "entities": [{"text": "BoW represenations", "start_pos": 12, "end_pos": 30, "type": "DATASET", "confidence": 0.8936021327972412}]}, {"text": "The classification problems for this dataset involve predicting whether a place-type belongs to a given category in three different taxonomies: Geonames (7 classes), Foursquare (9 classes) and OpenCYC (20 classes).", "labels": [], "entities": [{"text": "Foursquare", "start_pos": 166, "end_pos": 176, "type": "METRIC", "confidence": 0.4827137291431427}, {"text": "OpenCYC", "start_pos": 193, "end_pos": 200, "type": "DATASET", "confidence": 0.9073691964149475}]}, {"text": "Since many of these categories are very small, for this dataset we have used 5-fold cross validation.", "labels": [], "entities": []}, {"text": "The remaining two datasets are standard datasets for document classification: 20 newsgroups and the IMDB sentiment dataset.", "labels": [], "entities": [{"text": "document classification", "start_pos": 53, "end_pos": 76, "type": "TASK", "confidence": 0.7085079103708267}, {"text": "IMDB sentiment dataset", "start_pos": 100, "end_pos": 122, "type": "DATASET", "confidence": 0.9222777485847473}]}, {"text": "For the 20 newsgroups dataset, the standard 4 split was used where 11314 of the 18446 documents are used for training.", "labels": [], "entities": []}, {"text": "Headers, footers and quote metadata were removed using scikit-learn . The associated classification problem is to predict which newsgroup a given post was submitted to (20 classes).", "labels": [], "entities": []}, {"text": "The IMDB sentiment dataset contains a total of 50000 documents, and it is split into 25000 documents for training and 25000 for testing.", "labels": [], "entities": [{"text": "IMDB sentiment dataset", "start_pos": 4, "end_pos": 26, "type": "DATASET", "confidence": 0.9064390261967977}]}, {"text": "For the newsgroups and sentiment datasets, we used stopwords from the NLTK python package).", "labels": [], "entities": [{"text": "NLTK python package", "start_pos": 70, "end_pos": 89, "type": "DATASET", "confidence": 0.8468723694483439}]}, {"text": "For these datasets, we used all (lowercased) tokens and retained numbers, rather than only using nouns and adjectives.", "labels": [], "entities": []}, {"text": "The associated classification problem is to predict the sentiment of the review (positive or negative).", "labels": [], "entities": []}, {"text": "We will consider semantic spaces that have been learned using a number of different methods.", "labels": [], "entities": []}, {"text": "First, following, we use Multi-Dimensional Scaling (MDS) to learn semantic spaces from the angular differences between the PPMI weighted   BoW vectors.", "labels": [], "entities": [{"text": "PPMI weighted   BoW vectors", "start_pos": 123, "end_pos": 150, "type": "DATASET", "confidence": 0.5998297110199928}]}, {"text": "We also consider PCA, which directly uses the PPMI weighted BoW vectors as input, and which avoids the quadratic complexity of the MDS method.", "labels": [], "entities": [{"text": "PPMI weighted BoW vectors", "start_pos": 46, "end_pos": 71, "type": "DATASET", "confidence": 0.5978396981954575}]}, {"text": "As our third method, we consider Doc2vec, which is inspired by the Skipgram model ().", "labels": [], "entities": [{"text": "Doc2vec", "start_pos": 33, "end_pos": 40, "type": "DATASET", "confidence": 0.9018572568893433}]}, {"text": "Finally, we also learn semantic spaces by averaging word vectors, using a pre-trained GloVe word embeddings trained on the Wikipedia 2014 + Gigaword 5 corpus . While simply averaging word vectors may seem naive, this was found to be a competitive approach for unsupervised representations in several applications ().", "labels": [], "entities": [{"text": "Wikipedia 2014 + Gigaword 5 corpus", "start_pos": 123, "end_pos": 157, "type": "DATASET", "confidence": 0.8120867063601812}]}, {"text": "We consider two variants, In the first variant (denoted by AWV), we simply average the vector representations of the words that appear at least twice in the BoW representation, or at least 15 times in the case of the movies dataset.", "labels": [], "entities": [{"text": "AWV", "start_pos": 59, "end_pos": 62, "type": "METRIC", "confidence": 0.9727307558059692}, {"text": "movies dataset", "start_pos": 217, "end_pos": 231, "type": "DATASET", "confidence": 0.8929626643657684}]}, {"text": "The second variant (denoted by AWVw) uses the same words, but weights the vectors by PPMI score.", "labels": [], "entities": [{"text": "AWVw", "start_pos": 31, "end_pos": 35, "type": "METRIC", "confidence": 0.9572234153747559}]}, {"text": "As a comparison method, we also include results for LDA.", "labels": [], "entities": []}, {"text": "As candidate words for learning the initial directions, we only consider sufficiently frequent words.", "labels": [], "entities": []}, {"text": "The thresholds we used are 100 for the movies dataset, 50 for the place-types, 30 for 20 newsgroups, and 50 for the IMDB sentiment dataset.", "labels": [], "entities": [{"text": "movies dataset", "start_pos": 39, "end_pos": 53, "type": "DATASET", "confidence": 0.8321837782859802}, {"text": "IMDB sentiment dataset", "start_pos": 116, "end_pos": 138, "type": "DATASET", "confidence": 0.9061018228530884}]}, {"text": "We used the logistic regression implementation from scikit-learn to find the directions.", "labels": [], "entities": []}, {"text": "We deal with class imbalance by weighting the positive instances higher.", "labels": [], "entities": []}, {"text": "For hyperparameter tuning, we take 20% of the data from the training split as development data.", "labels": [], "entities": [{"text": "hyperparameter tuning", "start_pos": 4, "end_pos": 25, "type": "TASK", "confidence": 0.8622379899024963}]}, {"text": "We choose the hyperparameter values that maximize the F1 score on this development data.", "labels": [], "entities": [{"text": "F1 score", "start_pos": 54, "end_pos": 62, "type": "METRIC", "confidence": 0.9877299070358276}]}, {"text": "As candidate values for the number of dimensions of the vector spaces we used {50, 100, 200}.", "labels": [], "entities": []}, {"text": "The number of directions to be used as input to the clustering algorithm was chosen from {500, 1000, 2000}.", "labels": [], "entities": []}, {"text": "The number of clusters was chosen from {k, 2k}, with k the chosen number of dimensions.", "labels": [], "entities": []}, {"text": "For the hidden layer of the neural network, we fixed the number of dimensions as equal to the number of clusters.", "labels": [], "entities": []}, {"text": "As the scoring metric for the dimensions, we considered accuracy, Kappa and NDCG.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 56, "end_pos": 64, "type": "METRIC", "confidence": 0.9997227787971497}, {"text": "Kappa", "start_pos": 66, "end_pos": 71, "type": "METRIC", "confidence": 0.9777595400810242}, {"text": "NDCG", "start_pos": 76, "end_pos": 80, "type": "DATASET", "confidence": 0.722115695476532}]}, {"text": "In all experiments, we used 300 epochs, a minibatch size of 200, and the tanh activation function for the hidden layer of the neural network.", "labels": [], "entities": []}, {"text": "We train the network using AdaGrad (, with default values, and the model was implemented in the Keras library.", "labels": [], "entities": []}, {"text": "As the performance of LDA can be sensitive to the number of topics and other parameters, we tuned the number of topics from {50, 100, 200, 400}, the topic word prior from {0.1, 0.01, 0.001} and the document topic prior {0.1, 0.01, 0.001}.", "labels": [], "entities": []}, {"text": "To learn the decision trees, we use the scikitlearn implementation of CART, which allows us to limit the depth of the trees.", "labels": [], "entities": []}, {"text": "To mitigate the effects of class imbalance, the less frequent class was given a higher weight during training.", "labels": [], "entities": []}, {"text": "shows the results for the 20 newsgroups dataset, where we use FT to indicate the results with fine-tuning . We can see that the fine-tuning method consistently improves the performance of the depth-1 and depth-3 trees, often in a very substantial way.", "labels": [], "entities": [{"text": "newsgroups dataset", "start_pos": 29, "end_pos": 47, "type": "DATASET", "confidence": 0.6724199205636978}, {"text": "FT", "start_pos": 62, "end_pos": 64, "type": "METRIC", "confidence": 0.9746013283729553}]}, {"text": "After fine-tuning, the results are also consistently better than those of LDA.", "labels": [], "entities": []}, {"text": "For the unbounded trees (DN), the differences are small and fine-tuning sometimes even makes the results worse.", "labels": [], "entities": []}, {"text": "This can be explained by the fact that the fine-tuning method specializes the space towards the selected features, which means that some of the structure of the initial space will be distorted.", "labels": [], "entities": []}, {"text": "Unbounded decision trees are far less sensitive to the quality of the directions, and can even perform reasonably on random directions.", "labels": [], "entities": []}, {"text": "Interestingly, depth-1 trees achieved the best overall performance, with depth-3 trees and especially unbounded trees overfitting.", "labels": [], "entities": []}, {"text": "Since MDS and AWV perform best, we have only considered these two representations (along with LDA) for the remaining datasets, except for the IMDB Sentiment dataset, which is too large for using MDS.", "labels": [], "entities": [{"text": "AWV", "start_pos": 14, "end_pos": 17, "type": "METRIC", "confidence": 0.6676828861236572}, {"text": "IMDB Sentiment dataset", "start_pos": 142, "end_pos": 164, "type": "DATASET", "confidence": 0.9251311222712199}]}], "tableCaptions": [{"text": " Table 3: Results for 20 Newsgroups.", "labels": [], "entities": []}, {"text": " Table 4: The results for Movie Reviews and Place-Types on depth-1, depth-3 and unbounded trees.", "labels": [], "entities": []}, {"text": " Table 5: Results for IMDB Sentiment.", "labels": [], "entities": [{"text": "IMDB Sentiment", "start_pos": 22, "end_pos": 36, "type": "TASK", "confidence": 0.7644913792610168}]}]}