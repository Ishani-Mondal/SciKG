{"title": [{"text": "Universal Dependency Parsing with a General Transition-Based DAG Parser", "labels": [], "entities": [{"text": "Universal Dependency Parsing", "start_pos": 0, "end_pos": 28, "type": "TASK", "confidence": 0.5010883510112762}]}], "abstractContent": [{"text": "This paper presents our experiments with applying TUPA to the CoNLL 2018 UD shared task.", "labels": [], "entities": [{"text": "CoNLL 2018 UD shared task", "start_pos": 62, "end_pos": 87, "type": "DATASET", "confidence": 0.8736901760101319}]}, {"text": "TUPA is a general neu-ral transition-based DAG parser, which we use to present the first experiments on recovering enhanced dependencies as part of the general parsing task.", "labels": [], "entities": [{"text": "TUPA", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.745437502861023}]}, {"text": "TUPA was designed for parsing UCCA, a cross-linguistic semantic annotation scheme, exhibiting reentrancy, discontinuity and non-terminal nodes.", "labels": [], "entities": [{"text": "TUPA", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.8288217782974243}, {"text": "parsing UCCA", "start_pos": 22, "end_pos": 34, "type": "TASK", "confidence": 0.8577832281589508}]}, {"text": "By converting UD trees and graphs to a UCCA-like DAG format , we train TUPA almost without modification on the UD parsing task.", "labels": [], "entities": [{"text": "UD parsing task", "start_pos": 111, "end_pos": 126, "type": "TASK", "confidence": 0.8728304505348206}]}, {"text": "The generic nature of our approach lends itself naturally to multitask learning.", "labels": [], "entities": []}, {"text": "Our code is available at https://github.", "labels": [], "entities": []}, {"text": "com/CoNLL-UD-2018/HUJI.", "labels": [], "entities": [{"text": "CoNLL-UD-2018/HUJI", "start_pos": 4, "end_pos": 22, "type": "DATASET", "confidence": 0.8446137309074402}]}], "introductionContent": [{"text": "In this paper, we present the HUJI submission to the CoNLL 2018 shared task on Universal Dependency parsing.", "labels": [], "entities": [{"text": "HUJI submission", "start_pos": 30, "end_pos": 45, "type": "DATASET", "confidence": 0.8316311836242676}, {"text": "CoNLL 2018 shared task", "start_pos": 53, "end_pos": 75, "type": "DATASET", "confidence": 0.7785075008869171}, {"text": "Universal Dependency parsing", "start_pos": 79, "end_pos": 107, "type": "TASK", "confidence": 0.661068856716156}]}, {"text": "We focus only on parsing, using the baseline system, UDPipe 1.2 ( for tokenization, sentence splitting, part-of-speech tagging and morphological tagging.", "labels": [], "entities": [{"text": "sentence splitting", "start_pos": 84, "end_pos": 102, "type": "TASK", "confidence": 0.7346306443214417}, {"text": "part-of-speech tagging", "start_pos": 104, "end_pos": 126, "type": "TASK", "confidence": 0.6957263201475143}]}, {"text": "Our system is based on TUPA (, see \u00a73), a transition-based UCCA parser.", "labels": [], "entities": [{"text": "TUPA", "start_pos": 23, "end_pos": 27, "type": "DATASET", "confidence": 0.5840454697608948}]}, {"text": "UCCA (Universal Conceptual Cognitive Annotation;) is a cross-linguistic semantic annotation scheme, representing events, participants, attributes and relations in a directed acyclic graph (DAG) structure.", "labels": [], "entities": [{"text": "UCCA", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.8776326775550842}]}, {"text": "UCCA allows reentrancy to support argument sharing, discontinuity (corresponding to non-projectivity in dependency formalisms) and non-terminal nodes (as opposed to dependencies, which are bi-lexical).", "labels": [], "entities": [{"text": "UCCA", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.889518141746521}]}, {"text": "To parse Universal Dependencies () using TUPA, we employ a bidirectional conversion protocol to represent UD trees and graphs in a UCCA-like unified DAG format ( \u00a72).", "labels": [], "entities": []}, {"text": "Our method treats enhanced dependencies 1 as part of the dependency graph, providing the first approach, to our knowledge, for supervised learning of enhanced UD parsing.", "labels": [], "entities": [{"text": "UD parsing", "start_pos": 159, "end_pos": 169, "type": "TASK", "confidence": 0.8629448711872101}]}, {"text": "Due to the scarcity of enhanced dependencies in UD treebanks, previous approaches ( have attempted to recover them using languagespecific rules.", "labels": [], "entities": []}, {"text": "Our approach attempts to learn them from data: while only a few UD treebanks contain any enhanced dependencies, similar structures are an integral part of UCCA and its annotated corpora (realized as reentrancy by remote edges; see \u00a72), and TUPA supports them as a standard feature.", "labels": [], "entities": [{"text": "TUPA", "start_pos": 240, "end_pos": 244, "type": "DATASET", "confidence": 0.8435859680175781}]}, {"text": "As their annotation in UD is not yet widespread and standardized, enhanced dependencies are not included in the evaluation metrics for UD parsing, and so TUPA's ability to parse them is not reflected in the official shared task scores.", "labels": [], "entities": [{"text": "UD parsing", "start_pos": 135, "end_pos": 145, "type": "TASK", "confidence": 0.9504351019859314}]}, {"text": "However, we believe these enhancements, representing case information, elided predicates, and shared arguments due to conjunction, control, raising and relative clauses, provide richer information to downstream semantic applications, making UD better suited for text understanding.", "labels": [], "entities": [{"text": "text understanding", "start_pos": 262, "end_pos": 280, "type": "TASK", "confidence": 0.822672426700592}]}, {"text": "We propose an evaluation metric specific to enhanced dependencies, enhanced LAS ( \u00a75.1), and use it to evaluate our method.", "labels": [], "entities": []}, {"text": "Figure 1: (a) Example UCCA annotation for the sentence \"We were made to feel very welcome.\", containing a control verb, made.", "labels": [], "entities": []}, {"text": "The dashed A edge is a remote edge.", "labels": [], "entities": [{"text": "A edge", "start_pos": 11, "end_pos": 17, "type": "METRIC", "confidence": 0.871292382478714}]}, {"text": "(b) Bilexical graph annotating the same sentence in UD (reviews-077034-0002 from UD_English-EWT).", "labels": [], "entities": [{"text": "UD", "start_pos": 52, "end_pos": 54, "type": "DATASET", "confidence": 0.888495922088623}]}, {"text": "Enhanced dependencies appear below the sentence.", "labels": [], "entities": []}, {"text": "(c) The same UD graph, after conversion to the unified DAG format.", "labels": [], "entities": []}, {"text": "Intermediate non-terminals and head edges are introduced, to get a UCCA-like structure.", "labels": [], "entities": []}], "datasetContent": [{"text": "For test treebanks without corresponding training data, but with training data in the same language, during testing we use the model trained on the largest training treebank in the same language.", "labels": [], "entities": []}, {"text": "Since the official evaluation ignores enhanced dependencies, we evaluate them separately using a modified version of the shared task evaluation script . We calculate the enhanced LAS, identical to the standard LAS except that the set of dependencies in both gold and predicted graphs are the enhanced dependencies instead of the basic dependencies: ignoring null nodes and any enhanced dependency sharing ahead with a basic one, we align the words in the gold graph and the system's graph as in the standard LAS, and define lists the enhanced LAS precision, recall and F1 score on the test treebanks with any enhanced dependencies, as well as the percentage of enhanced dependencies in each test treebank, calculated as 100 \u00b7 #enhanced #enhanced+#words . Just as remote edges in UCCA parsing are more challenging than primary edges, parsing enhanced dependencies is a harder task than standard UD parsing, as the scores demonstrate.", "labels": [], "entities": [{"text": "precision", "start_pos": 547, "end_pos": 556, "type": "METRIC", "confidence": 0.9612151384353638}, {"text": "recall", "start_pos": 558, "end_pos": 564, "type": "METRIC", "confidence": 0.9943276047706604}, {"text": "F1", "start_pos": 569, "end_pos": 571, "type": "METRIC", "confidence": 0.9953334927558899}, {"text": "UCCA parsing", "start_pos": 779, "end_pos": 791, "type": "TASK", "confidence": 0.6099814176559448}, {"text": "UD parsing", "start_pos": 894, "end_pos": 904, "type": "TASK", "confidence": 0.8088698983192444}]}, {"text": "However, TUPA learns them successfully, getting as much as 56.55 enhanced LAS-F1 (on the Polish LFG test set).", "labels": [], "entities": [{"text": "TUPA", "start_pos": 9, "end_pos": 13, "type": "DATASET", "confidence": 0.7308177947998047}, {"text": "LAS-F1", "start_pos": 74, "end_pos": 80, "type": "METRIC", "confidence": 0.9522016644477844}, {"text": "Polish LFG test set", "start_pos": 89, "end_pos": 108, "type": "DATASET", "confidence": 0.9321257472038269}]}, {"text": "The TUPA transition classifier for some of the languages uses named entity features calculated    by spaCy.", "labels": [], "entities": []}, {"text": "8 For German, Spanish, Portuguese, French, Italian, Dutch and Russian, the spaCy named entity recognizer was trained on Wikipedia (.", "labels": [], "entities": []}, {"text": "However, the English model was trained on OntoNotes 9 , which is in fact not among the additional resources allowed by the shared task organizers.", "labels": [], "entities": [{"text": "OntoNotes 9", "start_pos": 42, "end_pos": 53, "type": "DATASET", "confidence": 0.8372562825679779}]}, {"text": "To get a fair evaluation and to quantify the contribution of the NER features, we re-trained TUPA on the English EWT (en_ewt) training set with the same hyperparameters as in our submitted model, just without these features.", "labels": [], "entities": [{"text": "TUPA", "start_pos": 93, "end_pos": 97, "type": "DATASET", "confidence": 0.8367560505867004}, {"text": "English EWT (en_ewt) training set", "start_pos": 105, "end_pos": 138, "type": "DATASET", "confidence": 0.659041467640135}]}, {"text": "As shows, removing the NER features (\u2212NER) only slightly hurts the performance, by 0.28 LAS-F1 points on the test treebank, and 0.63 on the development treebank.", "labels": [], "entities": [{"text": "LAS-F1", "start_pos": 88, "end_pos": 94, "type": "METRIC", "confidence": 0.9978986978530884}]}, {"text": "As further ablation experiments, we tried removing POS features, pre-trained word embeddings, and remote edges (the latter enabling TUPA to parse enhanced dependencies).", "labels": [], "entities": []}, {"text": "Removing the POS features does hurt performance to a larger degree, by 2.87 LAS-F1 points on the test set, while removing the pre-trained word embeddings even slightly improves the performance.", "labels": [], "entities": [{"text": "LAS-F1", "start_pos": 76, "end_pos": 82, "type": "METRIC", "confidence": 0.9977364540100098}]}, {"text": "Removing remote edges and transitions from TUPA causes a very small decrease in LAS-F1, and of course enhanced dependencies can then no longer be produced at all.", "labels": [], "entities": [{"text": "LAS-F1", "start_pos": 80, "end_pos": 86, "type": "METRIC", "confidence": 0.7196794748306274}]}, {"text": "8 https://spacy.io/api/annotation 9 https://catalog.ldc.upenn.edu/ LDC2013T19", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Transition classifier features.  si: stack node i from the top. bi: buffer node i.  xl, xr (xL, xR): x's leftmost and rightmost children (par- ents). w: head terminal text. m: lemma. u: coarse (universal)  POS tag. t: fine-grained POS tag. h: node's height. e: la- bel of its first incoming edge. p: any separator punctuation  between s0 and s1. q: count of any separator punctuation  between s0 and s1. x: numeric value of gap type (Maier and  Lichte", "labels": [], "entities": []}, {"text": " Table 3: Aggregated test LAS-F1 scores for our system  (TUPA) and the baseline system (UDPipe 1.2).", "labels": [], "entities": [{"text": "Aggregated test LAS-F1 scores", "start_pos": 10, "end_pos": 39, "type": "METRIC", "confidence": 0.7989533096551895}, {"text": "UDPipe 1.2)", "start_pos": 88, "end_pos": 99, "type": "DATASET", "confidence": 0.8820797204971313}]}, {"text": " Table 4: TUPA's enhanced LAS precision, recall and F1 per  test treebank with any enhanced dependencies, and percent- age of enhanced dependencies in test treebank.", "labels": [], "entities": [{"text": "TUPA", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.5706415176391602}, {"text": "LAS", "start_pos": 26, "end_pos": 29, "type": "METRIC", "confidence": 0.8498684763908386}, {"text": "precision", "start_pos": 30, "end_pos": 39, "type": "METRIC", "confidence": 0.8429385423660278}, {"text": "recall", "start_pos": 41, "end_pos": 47, "type": "METRIC", "confidence": 0.9997631907463074}, {"text": "F1", "start_pos": 52, "end_pos": 54, "type": "METRIC", "confidence": 0.9989111423492432}, {"text": "percent- age", "start_pos": 110, "end_pos": 122, "type": "METRIC", "confidence": 0.7443405588467916}]}, {"text": " Table 5: Ablation LAS-F1 and Enhanced LAS-F1 on the En- glish EWT development and test set. NER: named entity  features. POS: part-of-speech tag features (both universal  and fine-grained). Embed.: external pre-trained word em- beddings (fastText). Remote: remote edges and transitions in  TUPA.", "labels": [], "entities": [{"text": "Ablation", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9895530939102173}, {"text": "En- glish EWT development and test set", "start_pos": 53, "end_pos": 91, "type": "DATASET", "confidence": 0.6792777329683304}]}]}