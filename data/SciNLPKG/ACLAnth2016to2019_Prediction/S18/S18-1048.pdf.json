{"title": [{"text": "SSN MLRG1 at SemEval-2018 Task 1: Emotion and Sentiment Intensity Detection Using Rule Based Feature Selection", "labels": [], "entities": [{"text": "Emotion and Sentiment Intensity Detection", "start_pos": 34, "end_pos": 75, "type": "TASK", "confidence": 0.8133073806762695}]}], "abstractContent": [{"text": "The system developed by the SSN MLRG1 team for Semeval-2018 task 1 on affect in tweets uses rule based feature selection and one-hot encoding to generate the input feature vector.", "labels": [], "entities": [{"text": "SSN MLRG1", "start_pos": 28, "end_pos": 37, "type": "TASK", "confidence": 0.6474448442459106}, {"text": "Semeval-2018 task 1", "start_pos": 47, "end_pos": 66, "type": "TASK", "confidence": 0.5376524329185486}]}, {"text": "Multilayer Perceptron was used to build the model for emotion intensity ordinal classification, sentiment analysis ordinal classification and emotion classfication subtasks.", "labels": [], "entities": [{"text": "emotion intensity ordinal classification", "start_pos": 54, "end_pos": 94, "type": "TASK", "confidence": 0.587738923728466}, {"text": "sentiment analysis ordinal classification", "start_pos": 96, "end_pos": 137, "type": "TASK", "confidence": 0.8684532642364502}, {"text": "emotion classfication subtasks", "start_pos": 142, "end_pos": 172, "type": "TASK", "confidence": 0.7716613312562307}]}, {"text": "Support Vector Regression was used to build the model for emotion intensity regression and sentiment intensity regression subtasks.", "labels": [], "entities": [{"text": "emotion intensity regression", "start_pos": 58, "end_pos": 86, "type": "TASK", "confidence": 0.6073050399621328}]}], "introductionContent": [{"text": "Twitter is a huge microblogging service with more than 500 million tweets per day from different locations of the world and in different languages (.", "labels": [], "entities": []}, {"text": "Tweets are often used to convey ones emotions, opinions towards products, and stance over issues.", "labels": [], "entities": []}, {"text": "Automatically detecting emotion intensities in tweets has several applications, including commerce), crisis management (, tracking brand and product perception, tracking support for issues and policies, and tracking public health and well-being ().", "labels": [], "entities": [{"text": "Automatically detecting emotion intensities in tweets", "start_pos": 0, "end_pos": 53, "type": "TASK", "confidence": 0.7735781768957773}, {"text": "crisis management", "start_pos": 101, "end_pos": 118, "type": "TASK", "confidence": 0.7563201189041138}, {"text": "tracking brand and product perception", "start_pos": 122, "end_pos": 159, "type": "TASK", "confidence": 0.6261711239814758}]}, {"text": "The task is challenging because of the informal writing style, the semantic diversity of content as well as the \"unconventional\" grammar.", "labels": [], "entities": []}, {"text": "These challenges in building a classification model and regression model can be handled by using proper approaches to feature generation and machine learning.", "labels": [], "entities": [{"text": "feature generation", "start_pos": 118, "end_pos": 136, "type": "TASK", "confidence": 0.758129745721817}]}, {"text": "There are several machine learning techniques that can be used for sentiment intensity prediction or emotion intensity prediction.", "labels": [], "entities": [{"text": "sentiment intensity prediction", "start_pos": 67, "end_pos": 97, "type": "TASK", "confidence": 0.9253992239634196}, {"text": "emotion intensity prediction", "start_pos": 101, "end_pos": 129, "type": "TASK", "confidence": 0.776430477698644}]}, {"text": "Some of the approaches inlclude Artificial Neural Network (ANN) (  function (in the input layer the activation function is not applied).", "labels": [], "entities": []}, {"text": "The output layer has as many nuerons as the number of class labels in the problem.", "labels": [], "entities": []}, {"text": "Each connection has a weight assigned to it.", "labels": [], "entities": []}, {"text": "Output of each neuron is calculated by applying the activation function on the weighted sum of the inputs.", "labels": [], "entities": [{"text": "Output", "start_pos": 0, "end_pos": 6, "type": "METRIC", "confidence": 0.9835684895515442}]}, {"text": "Linear, sigmoid, tanh, elu, softplus, softmax and relu are some of the commonly used activation functions.", "labels": [], "entities": []}, {"text": "The supervised learning problem of the MLP can be solved with the backpropagation algorithm.", "labels": [], "entities": [{"text": "MLP", "start_pos": 39, "end_pos": 42, "type": "TASK", "confidence": 0.5886643528938293}]}, {"text": "The algorithm consists of two steps.", "labels": [], "entities": []}, {"text": "In the forward pass, the predicted outputs are calculated for the given inputs . In the backward pass, partial derivatives of the cost function with respect to the weight parameters are propagated back through the network.", "labels": [], "entities": []}, {"text": "The chain rule of differentiation gives very similar computational rules for the backward pass as the ones for the forward pass.", "labels": [], "entities": []}, {"text": "The network weights can then be adapted using any gradient-based optimisation algorithm.", "labels": [], "entities": []}, {"text": "MLP was used in implementing for the following subtasks: 1.", "labels": [], "entities": [{"text": "MLP", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.8137555718421936}]}, {"text": "EI-oc (an emotion intensity ordinal classification task): Given a tweet and an emotion E, classify the tweet into one of four ordinal intensity classes of E that best represents the mental state of the tweeter.", "labels": [], "entities": [{"text": "emotion intensity ordinal classification task", "start_pos": 10, "end_pos": 55, "type": "TASK", "confidence": 0.6837813377380371}]}, {"text": "2. V-oc (a sentiment analysis, ordinal classification task): Given a tweet, classify it into one of seven ordinal classes, corresponding to various levels of positive and negative sentiment intensity, that best represents the mental state of the tweeter.", "labels": [], "entities": [{"text": "sentiment analysis, ordinal classification task", "start_pos": 11, "end_pos": 58, "type": "TASK", "confidence": 0.7911150008440018}]}, {"text": "3. E-c (an emotion classification task): Given a tweet, classify it as neutral or no emotion or as one, or more, of eleven given emotions that best represent the mental state of the tweeter.", "labels": [], "entities": [{"text": "emotion classification task", "start_pos": 11, "end_pos": 38, "type": "TASK", "confidence": 0.808351993560791}]}], "datasetContent": [{"text": "We evaluated the system only for English language.", "labels": [], "entities": []}, {"text": "The results obtained using MLP and SVR for the subtasks are tabulated in to.", "labels": [], "entities": [{"text": "MLP", "start_pos": 27, "end_pos": 30, "type": "METRIC", "confidence": 0.7610710859298706}, {"text": "SVR", "start_pos": 35, "end_pos": 38, "type": "METRIC", "confidence": 0.6254830360412598}]}, {"text": "From which shows the Pearson scores obtained for SVR, we can infer that SVR predicts joy better compared to anger, fear and sadness.", "labels": [], "entities": [{"text": "Pearson", "start_pos": 21, "end_pos": 28, "type": "METRIC", "confidence": 0.9735312461853027}]}, {"text": "Similarly, from which shows the Pearson scores obtained for MLP, we observe that MLP model predicts joy better compared to anger, fear and sadness.", "labels": [], "entities": [{"text": "Pearson", "start_pos": 32, "end_pos": 39, "type": "METRIC", "confidence": 0.9603649377822876}]}, {"text": "The Pearson score for valence intensity regression and sentiment intensity ordinal classification are given in    Pearson (all instances) Pearson (gold in 0.5-1) 0.582 0.424: Pearson score for V-reg (valence intensity regression) using SVR.", "labels": [], "entities": [{"text": "Pearson", "start_pos": 4, "end_pos": 11, "type": "METRIC", "confidence": 0.992715060710907}, {"text": "valence intensity regression", "start_pos": 22, "end_pos": 50, "type": "TASK", "confidence": 0.5979347825050354}, {"text": "sentiment intensity ordinal classification", "start_pos": 55, "end_pos": 97, "type": "TASK", "confidence": 0.6801605373620987}, {"text": "Pearson", "start_pos": 114, "end_pos": 121, "type": "METRIC", "confidence": 0.9231638312339783}, {"text": "Pearson (gold in 0.5-1) 0.582 0.424", "start_pos": 138, "end_pos": 173, "type": "METRIC", "confidence": 0.908562071621418}, {"text": "Pearson", "start_pos": 175, "end_pos": 182, "type": "METRIC", "confidence": 0.9776445627212524}]}, {"text": "Pearson (all classes) Pearson (some-emotion) 0.427 0.479: Pearson score for V-oc (Sentiment intensity ordinal classification) using MLP.", "labels": [], "entities": [{"text": "Pearson", "start_pos": 0, "end_pos": 7, "type": "METRIC", "confidence": 0.8621839284896851}, {"text": "Pearson (some-emotion) 0.427 0.479", "start_pos": 22, "end_pos": 56, "type": "METRIC", "confidence": 0.7538488805294037}, {"text": "Pearson score", "start_pos": 58, "end_pos": 71, "type": "METRIC", "confidence": 0.97547647356987}, {"text": "MLP", "start_pos": 132, "end_pos": 135, "type": "DATASET", "confidence": 0.7065572738647461}]}, {"text": "The Pearson scorer is calculated using the Equation 1.", "labels": [], "entities": [{"text": "Pearson scorer", "start_pos": 4, "end_pos": 18, "type": "METRIC", "confidence": 0.9645051658153534}, {"text": "Equation", "start_pos": 43, "end_pos": 51, "type": "METRIC", "confidence": 0.9961318969726562}]}, {"text": "Accuracy Micro-avg F1 Macro-avg F1 0.468 0.595 0.476 where Y is actual output and y is predicted output.", "labels": [], "entities": [{"text": "Accuracy Micro-avg F1 Macro-avg F1 0.468 0.595 0.476", "start_pos": 0, "end_pos": 52, "type": "METRIC", "confidence": 0.8587498962879181}]}, {"text": "The accuracy, micro-averaged F score and macro-avearged F score for emotion classification are given in.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 4, "end_pos": 12, "type": "METRIC", "confidence": 0.9997614026069641}, {"text": "F score", "start_pos": 29, "end_pos": 36, "type": "METRIC", "confidence": 0.9049196243286133}, {"text": "F score", "start_pos": 56, "end_pos": 63, "type": "METRIC", "confidence": 0.8993772864341736}, {"text": "emotion classification", "start_pos": 68, "end_pos": 90, "type": "TASK", "confidence": 0.8031538724899292}]}, {"text": "The metrics are defined from Equations 2 to 5.", "labels": [], "entities": []}, {"text": "where G t is the set of the gold labels for tweet t, Pt is the set of the predicted labels for tweet t, and T is the set of tweets.", "labels": [], "entities": [{"text": "Pt", "start_pos": 53, "end_pos": 55, "type": "METRIC", "confidence": 0.9540732502937317}]}, {"text": "where micro-P is micro-averaged precision and micro-R is micro-averaged recall where P e is precision, Re is recall and E is the given set of eleven emotions.", "labels": [], "entities": [{"text": "precision", "start_pos": 32, "end_pos": 41, "type": "METRIC", "confidence": 0.8971313834190369}, {"text": "recall", "start_pos": 72, "end_pos": 78, "type": "METRIC", "confidence": 0.870373547077179}, {"text": "precision", "start_pos": 92, "end_pos": 101, "type": "METRIC", "confidence": 0.9993228912353516}, {"text": "recall", "start_pos": 109, "end_pos": 115, "type": "METRIC", "confidence": 0.9221054315567017}]}], "tableCaptions": [{"text": " Table 2: Pearson score for EI-reg (emotion intensity  regression) using SVR.", "labels": [], "entities": [{"text": "Pearson score", "start_pos": 10, "end_pos": 23, "type": "METRIC", "confidence": 0.975035548210144}, {"text": "EI-reg", "start_pos": 28, "end_pos": 34, "type": "METRIC", "confidence": 0.8807547092437744}]}, {"text": " Table 3: Pearson score for EI-oc (emotion intensity or- dinal classification) using MLP.", "labels": [], "entities": [{"text": "Pearson score", "start_pos": 10, "end_pos": 23, "type": "METRIC", "confidence": 0.9742172658443451}, {"text": "EI-oc", "start_pos": 28, "end_pos": 33, "type": "METRIC", "confidence": 0.8844932913780212}, {"text": "MLP", "start_pos": 85, "end_pos": 88, "type": "DATASET", "confidence": 0.5370457768440247}]}]}