{"title": [{"text": "NEUROSENT-PDI at SemEval-2018 Task 7: Discovering Textual Relations With a Neural Network Model", "labels": [], "entities": []}], "abstractContent": [{"text": "Discovering semantic relations within textual documents is a timely topic worthy of investigation.", "labels": [], "entities": [{"text": "Discovering semantic relations within textual documents", "start_pos": 0, "end_pos": 55, "type": "TASK", "confidence": 0.8961106638113657}]}, {"text": "Natural language processing strategies are generally used for linking chunks of text in order to extract information that can be exploited by semantic search engines for performing complex queries.", "labels": [], "entities": []}, {"text": "The scientific domain is an interesting area where these techniques can be applied.", "labels": [], "entities": []}, {"text": "In this paper, we describe a system based on neural networks applied to the SemEval 2018 Task 7.", "labels": [], "entities": [{"text": "SemEval 2018 Task 7", "start_pos": 76, "end_pos": 95, "type": "TASK", "confidence": 0.7525571137666702}]}, {"text": "The system relies on the use of word embeddings for composing the vectorial representation of text chunks.", "labels": [], "entities": []}, {"text": "Such representations are used for feeding a neural network aims to learn the structure of paths connecting chunks associated with a specific relation.", "labels": [], "entities": []}, {"text": "Preliminary results demonstrated the suitability of the proposed approach encouraging the investigation of this research direction.", "labels": [], "entities": []}], "introductionContent": [{"text": "One of the emerging trends of natural language technologies is their application to scientific literature.", "labels": [], "entities": []}, {"text": "There is a constant increase in the production of scientific papers and experts are faced with an explosion of information that makes it difficult to have an overview of the state of the art in a given domain.", "labels": [], "entities": []}, {"text": "Recent works from the semantic web, scientometry, and natural language processing (NLP) communities aimed to improve the access to scientific literature, in particular to answer queries that are currently beyond the capabilities of standard search engines.", "labels": [], "entities": []}, {"text": "Examples of such queries include finding all papers that address a given problem in a specific way, or to discover the roots of a certain idea.", "labels": [], "entities": []}, {"text": "The NLP tasks that underlie intelligent processing of scientific documents are those of information extraction: identifying concepts and recognizing the semantic relation that holds between them.", "labels": [], "entities": [{"text": "information extraction", "start_pos": 88, "end_pos": 110, "type": "TASK", "confidence": 0.7303000837564468}]}, {"text": "Information extraction from corpora including relation extraction and classification normally involves a complicated multiple-step process.", "labels": [], "entities": [{"text": "Information extraction from corpora", "start_pos": 0, "end_pos": 35, "type": "TASK", "confidence": 0.8426447510719299}, {"text": "relation extraction", "start_pos": 46, "end_pos": 65, "type": "TASK", "confidence": 0.8164491057395935}]}, {"text": "In this paper, we present a neural network strategy for addressing the challenge of extracting informative entities from scientific papers and inferring their semantic relation among a set of six alternatives.", "labels": [], "entities": []}, {"text": "This challenge is part of the.", "labels": [], "entities": []}, {"text": "One of the pillar of the proposed approach is that the word embeddings used for representing the text within the neural network have been generated from a corpus containing only scientific papers instead of a general purpose one, like news repositories or Wikipedia.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Results obtained on the training set by Neu- roSent and by the four baselines for the Task#1.", "labels": [], "entities": [{"text": "Neu- roSent", "start_pos": 50, "end_pos": 61, "type": "DATASET", "confidence": 0.8927136063575745}]}, {"text": " Table 2: Results obtained on the training set by Neu- roSent and by the four baselines for the Task#2.", "labels": [], "entities": [{"text": "Neu- roSent", "start_pos": 50, "end_pos": 61, "type": "DATASET", "confidence": 0.8925840457280477}]}, {"text": " Table 3: Results obtained on the test set by NeuroSent  and by the best system of Task#1.", "labels": [], "entities": []}, {"text": " Table 4: Results obtained on the test set by NeuroSent  and by the best systems of Task#2.", "labels": [], "entities": []}]}