{"title": [{"text": "NIHRIO at SemEval-2018 Task 3: A Simple and Accurate Neural Network Model for Irony Detection in Twitter", "labels": [], "entities": [{"text": "Irony Detection", "start_pos": 78, "end_pos": 93, "type": "TASK", "confidence": 0.6828868538141251}]}], "abstractContent": [{"text": "This paper describes our NIHRIO system for SemEval-2018 Task 3 \"Irony detection in En-glish tweets.\"", "labels": [], "entities": [{"text": "SemEval-2018 Task 3", "start_pos": 43, "end_pos": 62, "type": "TASK", "confidence": 0.8231445749600729}, {"text": "Irony detection", "start_pos": 64, "end_pos": 79, "type": "TASK", "confidence": 0.8469292223453522}]}, {"text": "We propose to use a simple neu-ral network architecture of Multilayer Percep-tron with various types of input features including: lexical, syntactic, semantic and polarity features.", "labels": [], "entities": []}, {"text": "Our system achieves very high performance in both subtasks of binary and multi-class irony detection in tweets.", "labels": [], "entities": [{"text": "multi-class irony detection", "start_pos": 73, "end_pos": 100, "type": "TASK", "confidence": 0.678736021121343}]}, {"text": "In particular , we rank third using the accuracy metric and fifth using the F 1 metric.", "labels": [], "entities": [{"text": "accuracy metric", "start_pos": 40, "end_pos": 55, "type": "METRIC", "confidence": 0.9766171872615814}, {"text": "F 1 metric", "start_pos": 76, "end_pos": 86, "type": "METRIC", "confidence": 0.9558388988176981}]}, {"text": "Our code is available at: https://github.com/ NIHRIO/IronyDetectionInTwitter.", "labels": [], "entities": []}], "introductionContent": [{"text": "Mining Twitter data has increasingly been attracting much research attention in many NLP applications such as in sentiment analysis and stock market prediction.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 113, "end_pos": 131, "type": "TASK", "confidence": 0.9549484252929688}, {"text": "stock market prediction", "start_pos": 136, "end_pos": 159, "type": "TASK", "confidence": 0.6913448770840963}]}, {"text": "Recently, and have shown that Twitter data includes a high volume of \"ironic\" tweets.", "labels": [], "entities": []}, {"text": "For example, a user can use positive words in a Twitter message to her intended negative meaning (e.g., \"It is awesome to go to bed at 3 am #not\").", "labels": [], "entities": []}, {"text": "This especially results in a research challenge to assign correct sentiment labels for ironic tweets.", "labels": [], "entities": []}, {"text": "To handle that problem, much attention has been focused on automatic irony detection in Twitter (.", "labels": [], "entities": [{"text": "automatic irony detection", "start_pos": 59, "end_pos": 84, "type": "TASK", "confidence": 0.6408465305964152}]}, {"text": "In this paper, we propose a neural network model for irony detection in tweets.", "labels": [], "entities": [{"text": "irony detection", "start_pos": 53, "end_pos": 68, "type": "TASK", "confidence": 0.8625865578651428}]}, {"text": "Our model obtains the fifth best performances in both binary and multi-class irony detection subtasks in terms of F 1 score (Van Hee et al., 2018).", "labels": [], "entities": [{"text": "multi-class irony detection subtasks", "start_pos": 65, "end_pos": 101, "type": "TASK", "confidence": 0.689123198390007}, {"text": "F 1 score", "start_pos": 114, "end_pos": 123, "type": "METRIC", "confidence": 0.9800458550453186}]}, {"text": "Details of the two subtasks can be found in the task description paper.", "labels": [], "entities": []}, {"text": "We briefly describe the subtasks as follows: Subtask 1 (A): Ironic vs non-ironic This first subtask is a binary classification problem, in which we predict whether or not a tweet is ironic.", "labels": [], "entities": []}, {"text": "For example, \"I just love when you test my patience!!", "labels": [], "entities": []}, {"text": "#not\" is ironic, but \"Had no sleep and have got school now #not happy\" is non-ironic.", "labels": [], "entities": []}], "datasetContent": [{"text": "The dataset consists of 4,618 tweets (2,222 ironic + 2,396 non-ironic) that are manually labelled by three students.", "labels": [], "entities": []}, {"text": "Some pre-processing steps were applied to the dataset, such as the emoji icons in a tweet are replaced by a describing text using the Python emoji package.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Basic statistics of the provided dataset.", "labels": [], "entities": []}, {"text": " Table 4: The optimal hyperparameter settings for sub- tasks 1 (A) and 2 (B).", "labels": [], "entities": []}, {"text": " Table 5: The performance (in %) of our model on the  test set for subtask 1 (binary classification). The sub- scripts denote our official ranking.", "labels": [], "entities": []}, {"text": " Table 6: The performance (in %) of our model on the  test set for subtask 2 (multi-class classification).", "labels": [], "entities": []}, {"text": " Table 7: The performance (in %) of our model on the  test set for each class label in subtask 2.", "labels": [], "entities": []}]}