{"title": [{"text": "uOttawa at SemEval-2018 Task 1: Self-Attentive Hybrid GRU-Based Network", "labels": [], "entities": []}], "abstractContent": [{"text": "We propose a novel attentive hybrid GRU-based network (SAHGN), which we used at SemEval-2018 Task 1: Affect in Tweets.", "labels": [], "entities": [{"text": "SemEval-2018 Task 1", "start_pos": 80, "end_pos": 99, "type": "TASK", "confidence": 0.6027858058611552}]}, {"text": "Our network has two main characteristics, 1) has the ability to internally optimize its feature representation using attention mechanisms, and 2) provides a hybrid representation using a character-level Convo-lutional Neural Network (CNN), as well as a self-attentive word-level encoder.", "labels": [], "entities": []}, {"text": "The key advantage of our model is its ability to signify the relevant and important information that enables self-optimization.", "labels": [], "entities": []}, {"text": "Results are reported on the valence intensity regression task.", "labels": [], "entities": [{"text": "valence intensity regression task", "start_pos": 28, "end_pos": 61, "type": "TASK", "confidence": 0.738615408539772}]}], "introductionContent": [{"text": "Affect analysis is one of the main topics of natural language processing (NLP).", "labels": [], "entities": [{"text": "Affect analysis", "start_pos": 0, "end_pos": 15, "type": "TASK", "confidence": 0.7221733629703522}, {"text": "natural language processing (NLP)", "start_pos": 45, "end_pos": 78, "type": "TASK", "confidence": 0.7972282667954763}]}, {"text": "It involves many sub-tasks such as sentiment and valence analyses expressed in text.", "labels": [], "entities": [{"text": "sentiment and valence analyses expressed in text", "start_pos": 35, "end_pos": 83, "type": "TASK", "confidence": 0.8099156447819301}]}, {"text": "We focus on the task of determining valence intensity.", "labels": [], "entities": []}, {"text": "Hand-crafted features and/or sentiment lexicons are commonly used for affect analysis) with classifiers such as random forest and support vector machines (SVM).", "labels": [], "entities": [{"text": "affect analysis", "start_pos": 70, "end_pos": 85, "type": "TASK", "confidence": 0.732772633433342}]}, {"text": "Affect in tweets (AIT) is a challenging task as it requires handling an informal writing style, which typically has many grammar mistakes, slangs, and misspellings.", "labels": [], "entities": [{"text": "Affect in tweets (AIT)", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.7336725642283758}]}, {"text": "In this paper, we present a self-attentive hybrid GRU-based network (SAHGN) that competed at.", "labels": [], "entities": []}, {"text": "Our contributions can be summarized as below.", "labels": [], "entities": []}, {"text": "\u2022 The implementation of asocial media text processor: A library to help process social media text such as short-forms, emoticons, emojis, misspellings, hash tags, and slangs, as well as tokenization, word normalization, and sentence encoding.", "labels": [], "entities": [{"text": "word normalization", "start_pos": 200, "end_pos": 218, "type": "TASK", "confidence": 0.7742542326450348}, {"text": "sentence encoding", "start_pos": 224, "end_pos": 241, "type": "TASK", "confidence": 0.7659103274345398}]}, {"text": "\u2022 The implementation of a self-attentive deep learning system: This system can predict valence and intensity with limited corpora and vocabulary, and yet can have acceptable performance.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 2: Results of valence intensity regression (Eng- lish).", "labels": [], "entities": []}]}