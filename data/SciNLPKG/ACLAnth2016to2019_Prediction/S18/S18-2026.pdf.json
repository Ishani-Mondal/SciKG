{"title": [{"text": "Agree or Disagree: Predicting Judgments on Nuanced Assertions", "labels": [], "entities": [{"text": "Agree or Disagree: Predicting Judgments on Nuanced Assertions", "start_pos": 0, "end_pos": 61, "type": "TASK", "confidence": 0.7382440368334452}]}], "abstractContent": [{"text": "Being able to predict whether people agree or disagree with an assertion (i.e. an explicit, self-contained statement) has several applications ranging from predicting how many people will like or dislike asocial media post to classifying posts based on whether they are in accordance with a particular point of view.", "labels": [], "entities": [{"text": "predict whether people agree or disagree with an assertion (i.e. an explicit, self-contained statement)", "start_pos": 14, "end_pos": 117, "type": "TASK", "confidence": 0.5809387950336232}]}, {"text": "We formalize this as two NLP tasks: predicting judgments of (i) individuals and (ii) groups based on the text of the assertion and previous judgments.", "labels": [], "entities": [{"text": "predicting judgments", "start_pos": 36, "end_pos": 56, "type": "TASK", "confidence": 0.9131366312503815}]}, {"text": "We evaluate a wide range of approaches on a crowdsourced data set containing over 100,000 judgments on over 2,000 assertions.", "labels": [], "entities": []}, {"text": "We find that predicting individual judgments is a hard task with our best results only slightly exceeding a majority baseline.", "labels": [], "entities": [{"text": "predicting individual judgments", "start_pos": 13, "end_pos": 44, "type": "TASK", "confidence": 0.9052133162816366}]}, {"text": "Judgments of groups, however, can be more reliably predicted using a Siamese neural network , which outperforms all other approaches by a wide margin.", "labels": [], "entities": []}], "introductionContent": [{"text": "One of the most basic reactions when reading a sentence is to agree or disagree with it.", "labels": [], "entities": []}, {"text": "Mechanisms that allow us to express agreement (e.g. thumb-up, like, up-vote, \u2665) or disagreement (e.g. thumb-down, dislike, down-vote) towards posts of other users can be found in almost all social networking sites.", "labels": [], "entities": []}, {"text": "The judgments associated with posts that discuss controversial political or social issues, such as legalization of drug, immigration policy, or gun rights, area rich source of information for those interested in the opinions of individuals or groups.", "labels": [], "entities": []}, {"text": "For instance, public opinion regarding an issue is often illustrated by the number of retweets, likes, or upvotes that a politician or influential person receives.", "labels": [], "entities": []}, {"text": "Hence, especially for controversial issues, being able to predict how people judge posts has several applications: people at large could automatically anticipate if politicians, companies or other decision makers would agree or disagree with anew perspective on a problem or how they would evaluate anew possible solution.", "labels": [], "entities": []}, {"text": "The method can also be used by journalists to more accurately analyze the homogeneity of opinions or to detect filter bubbles in social media.", "labels": [], "entities": []}, {"text": "Decision makers themselves would be able to evaluate in advance how citizens, customers, or employees react to a press announcement, anew regulation, or tweet.", "labels": [], "entities": []}, {"text": "Social media users could be enabled to search, sort or filter posts based on whether they are in accordance with or contrary to their personal worldview.", "labels": [], "entities": []}, {"text": "Such predictions could also be used to augment chat applications by indicating to a user if her recipients will agree or disagree with a message to be sent, enabling to choose a more or less confrontational discussion style.", "labels": [], "entities": []}, {"text": "In this paper, we describe how the outlined use cases can be framed as two inference tasks: predicting individual judgments and predicting judgments of whole groups.", "labels": [], "entities": [{"text": "predicting individual judgments", "start_pos": 92, "end_pos": 123, "type": "TASK", "confidence": 0.8676205078760783}, {"text": "predicting judgments of whole groups", "start_pos": 128, "end_pos": 164, "type": "TASK", "confidence": 0.8441234350204467}]}, {"text": "As a first step, we restrict ourselves to judgments on textual utterances that are explicit, relevant, and that do not contain multiple positions.", "labels": [], "entities": []}, {"text": "We will refer to such utterances as assertions.", "labels": [], "entities": []}, {"text": "For solving the tasks, we define the degree to which two assertions are judged similar as judgment similarity.", "labels": [], "entities": []}, {"text": "This similarity allows us to predict a judgment based on other judgments that have been made on similar, known assertions.", "labels": [], "entities": []}, {"text": "Across both tasks, we compare this strategy against several baselines and reference approaches on a newly crowdsourced data set containing over 100 000 judgments on assertions.", "labels": [], "entities": []}, {"text": "We find that, for predicting individual judgments, our best results only slightly exceed a majority baseline, but that judgments of groups can be more reliably pre- dicted using a Siamese neural network, which outperforms all other approaches by a wide margin.", "labels": [], "entities": [{"text": "predicting individual judgments", "start_pos": 18, "end_pos": 49, "type": "TASK", "confidence": 0.8415566682815552}]}], "datasetContent": [{"text": "As baselines for this task, we utilize wellestablished semantic text similarity (STS) methods that calculate overlap between the surface forms of assertions.", "labels": [], "entities": [{"text": "semantic text similarity (STS)", "start_pos": 55, "end_pos": 85, "type": "TASK", "confidence": 0.5928402642409006}]}, {"text": "We use the following methods as implemented by DKPro Similarity (B\u00e4r et al., 2013) 3 : (i) unigram overlap expressed by the Jaccard coefficient (), (ii) greedy string tiling, (iii) longest common sub string.", "labels": [], "entities": []}, {"text": "Additionally, we use averaged word embeddings (.", "labels": [], "entities": []}, {"text": "Beyond the baselines, we apply two machine learning approaches: a conventional SVM-based classifier and a neural network.", "labels": [], "entities": []}, {"text": "The SVM classifier is implemented using LibSVM (Chang and Lin, 2011) as provided by DKProTC).", "labels": [], "entities": [{"text": "DKProTC", "start_pos": 84, "end_pos": 91, "type": "DATASET", "confidence": 0.9538099765777588}]}, {"text": "We use a combination of various ngram features, sentiment features (derived from the system by ), embedding features (averaged embeddings by) and negation features.", "labels": [], "entities": []}, {"text": "We used a linear kernel with C=100 and the nu-SVR regression model.", "labels": [], "entities": []}, {"text": "Iterative experiments showed that this configuration gave the most stable results across the issues.", "labels": [], "entities": []}, {"text": "For the neural approach, we adapt Siamese neural networks (SNN), which consist of two identical branches or sub-networks that try to extract useful representations of the assertions and a final layer that merges these branches.", "labels": [], "entities": []}, {"text": "SNNs have been successfully used to predict text similarity and match pairs of sentences (e.g. a tweet to reply) ().", "labels": [], "entities": []}, {"text": "In our SNN, a branch consists of a layer that translates the assertions into sequences of word embeddings, which is followed by a convolution layer with a filter size of two, max pooling overtime layer, and a dense layer.", "labels": [], "entities": []}, {"text": "To merge the branches, we calculate the cosine similarity of the extracted vector representations.", "labels": [], "entities": []}, {"text": "The SNN was implemented using the deep learning framework deepTC () in conjunction with Keras and Tensorflow (.", "labels": [], "entities": []}, {"text": "In order to ensure full reproducibility of our results, the source code for both approaches is publicly available.", "labels": [], "entities": []}, {"text": "We evaluate all approaches using 10-fold cross validation and calculate Pearson correlation between the prediction and the gold similarity.", "labels": [], "entities": [{"text": "Pearson correlation", "start_pos": 72, "end_pos": 91, "type": "METRIC", "confidence": 0.9805727899074554}, {"text": "gold similarity", "start_pos": 123, "end_pos": 138, "type": "METRIC", "confidence": 0.9190240502357483}]}, {"text": "shows the correlation of all approaches averaged overall sixteen issues.", "labels": [], "entities": []}, {"text": "8 Overall, the STS baselines result in very low correlation coefficients between .02 and .07, while the trained models obtain coefficients around .6.", "labels": [], "entities": [{"text": "STS baselines", "start_pos": 15, "end_pos": 28, "type": "METRIC", "confidence": 0.7470810413360596}, {"text": "correlation", "start_pos": 48, "end_pos": 59, "type": "METRIC", "confidence": 0.965033769607544}]}, {"text": "This shows that the systems can learn useful representations that capture judgment similarity and that this representation is indeed different from semantic similarity.", "labels": [], "entities": []}, {"text": "Since both models are purely lexical and still yield reliable performance, we suspect that the relationship between a pair of assertions and their judgment similarity also has a lexical nature.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Issues and number of crowdsourced assertions  and judgments.", "labels": [], "entities": []}, {"text": " Table 2: Pearson correlation (averaged over all issues)  of text-based approaches for approximating similarity  of assertion judgments. 5", "labels": [], "entities": [{"text": "Pearson correlation", "start_pos": 10, "end_pos": 29, "type": "METRIC", "confidence": 0.93021160364151}, {"text": "approximating similarity  of assertion judgments", "start_pos": 87, "end_pos": 135, "type": "TASK", "confidence": 0.7629045784473419}]}, {"text": " Table 3: Correlation coefficients of the similarity pre- diction by the SVM and the SNN, obtained in 10 fold  cross-validation.", "labels": [], "entities": [{"text": "Correlation", "start_pos": 10, "end_pos": 21, "type": "METRIC", "confidence": 0.9559969305992126}]}, {"text": " Table 4: Accuracy of different approaches for predict- ing judgments of individuals.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9701228737831116}, {"text": "predict- ing judgments", "start_pos": 47, "end_pos": 69, "type": "TASK", "confidence": 0.9411141872406006}]}, {"text": " Table 5: Correlation coefficients for approaches on pre- dicting judgments of groups.", "labels": [], "entities": []}]}