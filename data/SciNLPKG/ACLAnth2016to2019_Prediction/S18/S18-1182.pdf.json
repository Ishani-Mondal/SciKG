{"title": [{"text": "SNU IDS at SemEval-2018 Task 12: Sentence Encoder with Contextualized Vectors for Argument Reasoning Comprehension", "labels": [], "entities": [{"text": "Sentence Encoder", "start_pos": 33, "end_pos": 49, "type": "TASK", "confidence": 0.9465435445308685}, {"text": "Argument Reasoning Comprehension", "start_pos": 82, "end_pos": 114, "type": "TASK", "confidence": 0.6860856215159098}]}], "abstractContent": [{"text": "We present a novel neural architecture for the Argument Reasoning Comprehension task of SemEval 2018.", "labels": [], "entities": [{"text": "Argument Reasoning Comprehension task", "start_pos": 47, "end_pos": 84, "type": "TASK", "confidence": 0.856953352689743}]}, {"text": "It is a simple neural network consisting of three parts, collectively judging whether the logic built on a set of given sentences (a claim, reason, and warrant) is plausible or not.", "labels": [], "entities": []}, {"text": "The model utilizes contextual-ized word vectors pre-trained on large machine translation (MT) datasets as a form of transfer learning, which can help to mitigate the lack of training data.", "labels": [], "entities": [{"text": "contextual-ized word vectors pre-trained on large machine translation (MT)", "start_pos": 19, "end_pos": 93, "type": "TASK", "confidence": 0.7499758709560741}, {"text": "transfer learning", "start_pos": 116, "end_pos": 133, "type": "TASK", "confidence": 0.8774306774139404}]}, {"text": "Quantitative analysis shows that simply leveraging LSTMs trained on MT datasets outperforms several baselines and non-transferred models, achieving accuracies of about 70% on the development set and about 60% on the test set.", "labels": [], "entities": [{"text": "MT datasets", "start_pos": 68, "end_pos": 79, "type": "DATASET", "confidence": 0.8436931073665619}, {"text": "accuracies", "start_pos": 148, "end_pos": 158, "type": "METRIC", "confidence": 0.9921759963035583}]}], "introductionContent": [{"text": "The Argument Reasoning Comprehension Task () is a newly released task that tackles the core of reasoning in natural language argumentation, highlighting the importance of implicit warrants.", "labels": [], "entities": []}, {"text": "Even though the task could be regarded as simple binary classification, it is quite challenging in several perspectives.", "labels": [], "entities": [{"text": "binary classification", "start_pos": 49, "end_pos": 70, "type": "TASK", "confidence": 0.7270942628383636}]}, {"text": "First, the task requires human-level reasoning to judge whether a claim supported by a reason and a warrant is logically correct.", "labels": [], "entities": []}, {"text": "Second, common knowledge, which is not present in the input sentences themselves, is often required to solve the problem.", "labels": [], "entities": []}, {"text": "Third, even though each instance of the data is helpful, the number of training data is relatively small to train prevailing complex neural models such as convolutional neural networks) and recurrent neural networks) with (or without) attention mechanisms (.", "labels": [], "entities": []}, {"text": "In this paper, we propose anew architecture named SECOVARC 1 (Sentence Encoder with COnextualized Vectors for Argument Reasoning Comprehension) to deal with the complicated task.", "labels": [], "entities": [{"text": "SECOVARC 1", "start_pos": 50, "end_pos": 60, "type": "METRIC", "confidence": 0.8498470485210419}, {"text": "Argument Reasoning Comprehension)", "start_pos": 110, "end_pos": 143, "type": "TASK", "confidence": 0.7416917830705643}]}, {"text": "The main idea behind our model is that transfer learning can be a remedy to resolve the difficulties we face.", "labels": [], "entities": [{"text": "transfer learning", "start_pos": 39, "end_pos": 56, "type": "TASK", "confidence": 0.9255277514457703}]}, {"text": "With experimental results and analysis, we show that the simple neural model enhanced by transferred knowledge can be competitive, compared to complex models trained on the given data only.", "labels": [], "entities": []}], "datasetContent": [{"text": "The reported results show that SECOVARC-last (w/ heuristics) outperforms all the baselines on the development set, with a mean accuracy of 70.6%.", "labels": [], "entities": [{"text": "SECOVARC-last", "start_pos": 31, "end_pos": 44, "type": "METRIC", "confidence": 0.7332493662834167}, {"text": "accuracy", "start_pos": 127, "end_pos": 135, "type": "METRIC", "confidence": 0.981481671333313}]}, {"text": "However, it is SECOVARC-max (w/ heuristics) that performs best on the test set, with a mean accuracy of 59.2%.", "labels": [], "entities": [{"text": "SECOVARC-max", "start_pos": 15, "end_pos": 27, "type": "DATASET", "confidence": 0.5163742899894714}, {"text": "accuracy", "start_pos": 92, "end_pos": 100, "type": "METRIC", "confidence": 0.8645209670066833}]}, {"text": "We submitted an instance obtained from SECOVARC-last (w/ heuristics) and achieved the official result of 56.5% on the leaderboard.: Experiment on the possibility of transfer learning in case of the argument reasoning comprehension task.", "labels": [], "entities": [{"text": "SECOVARC-last", "start_pos": 39, "end_pos": 52, "type": "DATASET", "confidence": 0.8876739740371704}, {"text": "transfer learning", "start_pos": 165, "end_pos": 182, "type": "TASK", "confidence": 0.8777452111244202}, {"text": "argument reasoning comprehension task", "start_pos": 198, "end_pos": 235, "type": "TASK", "confidence": 0.7979319915175438}]}, {"text": "Note that the heuristic methods are employed for all models.", "labels": [], "entities": []}, {"text": "layer, except for the test accuracy of SECOVARClast.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 27, "end_pos": 35, "type": "METRIC", "confidence": 0.9901171326637268}, {"text": "SECOVARClast", "start_pos": 39, "end_pos": 51, "type": "DATASET", "confidence": 0.7028348445892334}]}], "tableCaptions": [{"text": " Table 1: Comparison of baselines and variants of our  model on the development set and the test set.", "labels": [], "entities": []}, {"text": " Table 2: Experiment on the possibility of transfer learn- ing in case of the argument reasoning comprehension  task. Note that the heuristic methods are employed for  all models.", "labels": [], "entities": [{"text": "transfer learn- ing", "start_pos": 43, "end_pos": 62, "type": "TASK", "confidence": 0.7491579800844193}, {"text": "argument reasoning comprehension  task", "start_pos": 78, "end_pos": 116, "type": "TASK", "confidence": 0.8020639643073082}]}]}