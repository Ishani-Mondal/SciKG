{"title": [{"text": "CitiusNLP at SemEval-2018 Task 10: The Use of Transparent Distributional Models and Salient Contexts to Discriminate Word Attributes", "labels": [], "entities": [{"text": "SemEval-2018 Task 10", "start_pos": 13, "end_pos": 33, "type": "TASK", "confidence": 0.8104902108510336}, {"text": "Discriminate Word Attributes", "start_pos": 104, "end_pos": 132, "type": "TASK", "confidence": 0.6496313810348511}]}], "abstractContent": [{"text": "This article describes the unsupervised strategy submitted by the CitiusNLP team to Se-mEval 2018 Task 10, a task which consists of predicting whether a word is a discrimina-tive attribute between two other words.", "labels": [], "entities": [{"text": "predicting whether a word is a discrimina-tive attribute", "start_pos": 132, "end_pos": 188, "type": "TASK", "confidence": 0.7312253341078758}]}, {"text": "The proposed strategy relies on the correspondence between discriminative attributes and relevant contexts of a word.", "labels": [], "entities": []}, {"text": "More precisely, the method uses transparent distributional models to extract salient contexts of words which are identified as discriminative attributes.", "labels": [], "entities": []}, {"text": "The system performance reaches about 70% accuracy when it is applied on the development dataset, but its accuracy goes down (63%) on the official test dataset.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 41, "end_pos": 49, "type": "METRIC", "confidence": 0.9992806315422058}, {"text": "accuracy", "start_pos": 105, "end_pos": 113, "type": "METRIC", "confidence": 0.9996059536933899}, {"text": "official test dataset", "start_pos": 137, "end_pos": 158, "type": "DATASET", "confidence": 0.7803049286206564}]}], "introductionContent": [{"text": "The goal of is to predict whether a word is a discriminative attribute between two other words.", "labels": [], "entities": []}, {"text": "The key idea underlying this task is to capture semantic attributes of words in order to discriminate their senses.", "labels": [], "entities": []}, {"text": "Distributional semantics is based on the assumption that two words have similar senses if they tend to appear with the same contextual words.", "labels": [], "entities": [{"text": "Distributional semantics", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.7749441564083099}]}, {"text": "As contextual words actually refer to the semantic attributes of a given word, I will focus on identifying the most salient word contexts.", "labels": [], "entities": []}, {"text": "So, my method to identify discriminative attributes relies on the identification of salient contexts, since they represent the main semantic attributes of a word.", "labels": [], "entities": []}, {"text": "For this purpose, in this paper we will make use of distributional models built with transparent and lexico-syntactic contexts.", "labels": [], "entities": []}, {"text": "To capture discriminative attributes, I will rank the most relevant contexts of a word by using lexical association measures between a given word and their contexts.", "labels": [], "entities": []}, {"text": "My method is unsupervised and only requires pretrained distributional models.", "labels": [], "entities": []}, {"text": "This paper is organized as follows.", "labels": [], "entities": []}, {"text": "The method is described in Section 2.", "labels": [], "entities": []}, {"text": "Experiments, results, and a discussion on them are presented in Section 3.", "labels": [], "entities": []}, {"text": "Finally, conclusions are addressed in Section 4.", "labels": [], "entities": []}], "datasetContent": [{"text": "To find the best configuration of the proposed system, I carried out several experiments on the train and validation datasets (20,510 examples).", "labels": [], "entities": []}, {"text": "As the system is unsupervised, I am not required to separate training from validation.", "labels": [], "entities": []}, {"text": "First, I searched for the best lexical association by comparing loglikelihood and positive pointwise mutual information (ppmi), by using models with 400 and 500 salient contexts.", "labels": [], "entities": []}, {"text": "As loglikelihood performed slightly better than ppmi, I chose the former measure to carryout the next experiments.", "labels": [], "entities": []}, {"text": "Second, I searched for the best number of salient contexts.", "labels": [], "entities": []}, {"text": "For this purpose, several evaluations were made with models from 10 to 2000 salient contexts.", "labels": [], "entities": []}, {"text": "shows that the peak is quickly reached with 500 contexts (more than 0.67 accuracy), while performance is getting down slowly as more contexts are added.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 73, "end_pos": 81, "type": "METRIC", "confidence": 0.9982189536094666}]}, {"text": "I therefore decided to use models with 500 salient contexts per word for the next experiments.", "labels": [], "entities": []}, {"text": "Next, I merged the Wikipedia-based model with other models generated from two different corpora: British National Corpus (BNC), and a sample with 500 million words from Reddit corpus.", "labels": [], "entities": [{"text": "British National Corpus (BNC)", "start_pos": 97, "end_pos": 126, "type": "DATASET", "confidence": 0.966437578201294}, {"text": "Reddit corpus", "start_pos": 169, "end_pos": 182, "type": "DATASET", "confidence": 0.8368187248706818}]}, {"text": "5 Results are shown in.", "labels": [], "entities": []}, {"text": "As expected, accuracy is improved as the model grows.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 13, "end_pos": 21, "type": "METRIC", "confidence": 0.99959796667099}]}, {"text": "Given these preliminary experiments, I submitted the two best configurations to the test evaluation (2,340 examples): syst. meas.", "labels": [], "entities": []}, {"text": "saliency corpora run1 loglike 500 ctxs wiki+bnc run2 loglike 500 ctxs wiki+bnc+reddit In my preliminary experiment, I also used the word embeddings described in the previous subsection to capture discriminative attributes.", "labels": [], "entities": []}, {"text": "As mentioned above, a word is considered to bean attribute of a target word if their similarity is higher than a specific threshold, otherwise it is not a discriminative attribute.", "labels": [], "entities": []}, {"text": "Several similarity scores were set to determine whether a word is an attribute or not.", "labels": [], "entities": []}, {"text": "shows that the best similarity threshold is around 0.3 (cosine value).", "labels": [], "entities": [{"text": "similarity threshold", "start_pos": 20, "end_pos": 40, "type": "METRIC", "confidence": 0.9708449840545654}]}, {"text": "Accuracy drops dramatically with higher threshold values.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 0, "end_pos": 8, "type": "METRIC", "confidence": 0.9962575435638428}]}, {"text": "The best accuracy reached by this strategy is about 20 points below the best models based on salient contexts.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 9, "end_pos": 17, "type": "METRIC", "confidence": 0.9992048144340515}]}, {"text": "Therefore, for this particular task, transparent models consistently outperform word embeddings.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Accuracy obtained with three corpus- based models: just Wikipedia, Wikipedia and BNC,  Wikipedia, BNC and Reddit. The experiments were  carried out with the development dataset: training and  validation. All models were built by filtering 500 con- texts per word. The last column shows the size of the  filtered word-context pairs.", "labels": [], "entities": [{"text": "Wikipedia", "start_pos": 97, "end_pos": 106, "type": "DATASET", "confidence": 0.9511414170265198}, {"text": "BNC", "start_pos": 108, "end_pos": 111, "type": "DATASET", "confidence": 0.7965806722640991}]}]}