{"title": [{"text": "ELiRF-UPV at SemEval-2018 Task 10: Capturing Discriminative Attributes with Knowledge Graphs and Wikipedia", "labels": [], "entities": [{"text": "Capturing Discriminative Attributes", "start_pos": 35, "end_pos": 70, "type": "TASK", "confidence": 0.8912748297055563}]}], "abstractContent": [{"text": "This paper describes the participation of ELiRF-UPV team at task 10, Capturing Dis-criminative Attributes, of SemEval-2018.", "labels": [], "entities": [{"text": "Capturing Dis-criminative Attributes", "start_pos": 69, "end_pos": 105, "type": "TASK", "confidence": 0.8967419266700745}]}, {"text": "Our best approach consists of using ConceptNet, Wikipedia and NumberBatch embeddings in order to stablish relationships between concepts and attributes.", "labels": [], "entities": []}, {"text": "Furthermore, this system achieves competitive results in the official evaluation.", "labels": [], "entities": []}], "introductionContent": [{"text": "Capturing Discriminative Attributes, task 10 of SemEval-2018 (, proposes working on semantic difference detection . The goal of the task is to predict whether a word is a discriminative attribute between two other words.", "labels": [], "entities": [{"text": "Capturing Discriminative Attributes", "start_pos": 0, "end_pos": 35, "type": "TASK", "confidence": 0.7839996019999186}, {"text": "semantic difference detection", "start_pos": 84, "end_pos": 113, "type": "TASK", "confidence": 0.7888616323471069}]}, {"text": "This problem is known as semantic difference detection, which is a binary classification task: given a triple (apple, banana, red), it consists in determining whether it exemplifies a semantic difference.", "labels": [], "entities": [{"text": "semantic difference detection", "start_pos": 25, "end_pos": 54, "type": "TASK", "confidence": 0.8406360348065695}]}, {"text": "Regarding semantic difference, it is a ternary relation between two concepts, for instance, (apple, banana) and a discriminative feature (red) that characterizes the first concept but not the other.", "labels": [], "entities": [{"text": "semantic difference", "start_pos": 10, "end_pos": 29, "type": "TASK", "confidence": 0.7342672646045685}]}, {"text": "As task 10 is related to the semantic relations among different words, knowledge graphs seems the most appropriate resources to be used.", "labels": [], "entities": []}, {"text": "An interesting knowledge resource that we used for this task is ConceptNet.", "labels": [], "entities": []}, {"text": "In particular, ConceptNet () is a knowledge graph that connects words and phrases of natural language using labeled edges.", "labels": [], "entities": []}, {"text": "It was designed to represent some general knowledge involved in natural language and could be used in combination with other resources.", "labels": [], "entities": []}, {"text": "The combination of ConceptNet with distributed representations such as Word2Vec ( and GloVe, is known as NumberBatch embeddings.", "labels": [], "entities": [{"text": "Word2Vec", "start_pos": 71, "end_pos": 79, "type": "DATASET", "confidence": 0.9662454724311829}]}, {"text": "Regarding the relations specified in ConceptNet, there area total of 36 relations such as IsA (A banana is a dessert), UsedFor (A net is used for catching fish), or FormOf (\"Leaves\" is a form of the word \"leaf\"), intended to represent a relationship independently of the language or the source of the terms it connects.", "labels": [], "entities": []}, {"text": "In this work, we propose five knowledge based systems and one additional machine learning system based on Siamese networks.", "labels": [], "entities": []}, {"text": "We used ConceptNet in order to determine if each input concept and the input attribute are related through a relation edge or path.", "labels": [], "entities": []}, {"text": "When there is a relationship between the first concept and the attribute and there is no relationship between the second concept and the attribute, then the answer is 1, otherwise, the answer is 0.", "labels": [], "entities": []}, {"text": "However, there are cases in which ConceptNet does not provide enough information to take a decision.", "labels": [], "entities": []}, {"text": "In those cases, we have implemented a system that seeks the information in Wikipedia articles by using distances between NumberBatch embeddings.", "labels": [], "entities": []}], "datasetContent": [{"text": "In order to validate the correctness of the proposed approaches and also to select the one with the best performance for the competition, we carried out an evaluation of the approaches using the development set provided by the organizers.", "labels": [], "entities": []}, {"text": "The results obtained are shown in.", "labels": [], "entities": []}, {"text": "As can be seen in, the knowledge-based systems which use knowledge resources obtain among 1.31 and 11.13 points of macro F 1 more than the Siamese network which uses only NumberBatch embeddings.", "labels": [], "entities": [{"text": "macro F 1", "start_pos": 115, "end_pos": 124, "type": "METRIC", "confidence": 0.6507432361443838}]}, {"text": "The approaches that use only ConceptNet (d ) achieved as good results as those based on Wikipedia (d W e and d W t ).", "labels": [], "entities": []}, {"text": "Note that the coverage of d CN and d CN 2 is very low, 48.71% ford CN and 56.61% ford CN 2 . In cases where there are no links in ConceptNet -more than fifty percent of the time ford CN -it is decided that the attribute is not discriminant.", "labels": [], "entities": []}, {"text": "Moreover, the more knowledge incorporated into the system, the better results are obtained.", "labels": [], "entities": []}, {"text": "We achieved the best results using the combination of ConceptNet graph and Wikipedia articles (d CN 2 +W t ), achieving 68.20 macro F 1 . Regarding the evaluation with the test set, we used d CN 2 +W t as decision function for the SemEval competition.", "labels": [], "entities": [{"text": "F 1", "start_pos": 132, "end_pos": 135, "type": "METRIC", "confidence": 0.8569488525390625}]}, {"text": "Our system achieved competitive results (69.00 macro F 1 , 6 points of macro F 1 below the best system that obtains 75.00 macro F 1 ).", "labels": [], "entities": [{"text": "macro F 1", "start_pos": 47, "end_pos": 56, "type": "METRIC", "confidence": 0.6880393028259277}]}, {"text": "Our proposal was ranked in 5 th place out of a total of 26 participating teams.", "labels": [], "entities": []}, {"text": "Several results from the official evaluation are shown in.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Results on the development set.", "labels": [], "entities": []}, {"text": " Table 3: Error analysis in samples with attributes re- lated to colors.", "labels": [], "entities": [{"text": "Error analysis", "start_pos": 10, "end_pos": 24, "type": "TASK", "confidence": 0.8086574077606201}]}]}