{"title": [{"text": "ECNU at SemEval-2018 Task 1: Emotion Intensity Prediction Using Effective Features and Machine Learning Models", "labels": [], "entities": [{"text": "ECNU", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.877366840839386}, {"text": "Emotion Intensity Prediction", "start_pos": 29, "end_pos": 57, "type": "TASK", "confidence": 0.9080693125724792}]}], "abstractContent": [{"text": "In this paper we describe our systems submitted to Semeval 2018 Task 1 \"Affect in Tweet\" (Mohammad et al., 2018).", "labels": [], "entities": []}, {"text": "We participated in all subtasks of English tweets, including emotion intensity classification and quantification, valence intensity classification and quantifica-tion.", "labels": [], "entities": [{"text": "emotion intensity classification", "start_pos": 61, "end_pos": 93, "type": "TASK", "confidence": 0.5917822122573853}, {"text": "valence intensity classification", "start_pos": 114, "end_pos": 146, "type": "TASK", "confidence": 0.720451553662618}]}, {"text": "In our systems, we extracted four types of features, including linguistic, sentiment lexicon, emotion lexicon and domain-specific features, then fed them to different regressors, finally combined the models to create an ensemble for the better performance.", "labels": [], "entities": []}, {"text": "Officially released results showed that our system can be further extended.", "labels": [], "entities": []}], "introductionContent": [{"text": "The Semeval 2018 Task 1 aims to automatically determine the intensity of emotions of the tweeters from their tweets, including five subtasks.", "labels": [], "entities": []}, {"text": "That is, given a tweet and one of the four emotions (anger, fear, joy, sadness), the subtask 1 and 2 are to determine the intensity and classify the tweet into one of the four ordinal classes of intensity of the emotion respectively.", "labels": [], "entities": []}, {"text": "Similarly, the subtask 3 and 4 determine the intensity and classify the tweet into one of seven ordinal classes of intensity of valance.", "labels": [], "entities": []}, {"text": "Subtask 5 is a multi-label emotion classification task which classifies the tweets as neutral or no emotion or as one, or more, of eleven given emotions (anger, anticipation, disgust, fear, joy, love, optimism, pessimism, sadness, surprise, trust) that best represent the mental state of the tweeter.", "labels": [], "entities": [{"text": "multi-label emotion classification task", "start_pos": 15, "end_pos": 54, "type": "TASK", "confidence": 0.7167052626609802}]}, {"text": "For each task, training and test datasets are divided into English, Arabic, and Spanish tweets.", "labels": [], "entities": []}, {"text": "We participated in all subtasks of English tweets.", "labels": [], "entities": []}, {"text": "Traditional sentiment classification is a coarsegrained task in sentiment analysis which focuses on sentiment polarity classification of the whole sentence (i.e., positive, negative, neutral, mixed).", "labels": [], "entities": [{"text": "sentiment classification", "start_pos": 12, "end_pos": 36, "type": "TASK", "confidence": 0.8249694406986237}, {"text": "sentiment analysis", "start_pos": 64, "end_pos": 82, "type": "TASK", "confidence": 0.9301413595676422}, {"text": "sentiment polarity classification", "start_pos": 100, "end_pos": 133, "type": "TASK", "confidence": 0.6484061678250631}]}, {"text": "Semeval 2018 Task 1 subtask 5 takes basic human emotion proposed by Ekman (Ekman, 1999) into consideration, including Anger, Anticipation, Disgust, Fear, Joy, Sadness, Surprise, and Trust.", "labels": [], "entities": [{"text": "Ekman (Ekman, 1999)", "start_pos": 68, "end_pos": 87, "type": "DATASET", "confidence": 0.8103505869706472}]}, {"text": "The difference between these subtasks lies in the emotion granularity and classification or quantification, so in our work, the similar method is adopted for five subtasks.", "labels": [], "entities": [{"text": "classification or quantification", "start_pos": 74, "end_pos": 106, "type": "TASK", "confidence": 0.7155240873495737}]}, {"text": "We extracted a rich set of elaborately designed features.", "labels": [], "entities": []}, {"text": "In addition to linguistic features, sentiment lexicon features and emotion lexicon features, we also extracted some domain specific features.", "labels": [], "entities": []}, {"text": "Also, we conducted a series of experiments on different machine learning algorithms and ensemble methods to obtain the better performing for each subtask.", "labels": [], "entities": []}, {"text": "For subask 5, we adopted multiple binary classification and constructed a model for each emotion.", "labels": [], "entities": []}], "datasetContent": [{"text": "The statistics of the English datasets provided by Semeval 2018 Task 1 are shown in and 2.", "labels": [], "entities": [{"text": "English datasets provided by Semeval 2018 Task 1", "start_pos": 22, "end_pos": 70, "type": "DATASET", "confidence": 0.7954738587141037}]}, {"text": "How the English data created is described in  To evaluate the performance of different systems, the official evaluation measure Pearson Correlation Coefficient with the Gold ratings/labels is adopted for the first four subtasks.", "labels": [], "entities": [{"text": "Pearson Correlation Coefficient", "start_pos": 128, "end_pos": 159, "type": "METRIC", "confidence": 0.9066011309623718}]}, {"text": "The correlation scores across all four emotions will be averaged (macro-average) to determine the final system performance.", "labels": [], "entities": []}, {"text": "As for the last subtask, systems are evaluated by calculating multi-label accuracy namely Jaccard index, the formula are follow: where G t is the set of the gold labels for tweet t, Pt is the set of the predicted labels for tweet t, and T is the set of tweets.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 74, "end_pos": 82, "type": "METRIC", "confidence": 0.955978512763977}]}, {"text": "Firstly, we performed a series of experiments in order to explore the effectiveness of each feature type.: Performance of our system, top-ranked system and baseline on test set for subtask 1, 2.", "labels": [], "entities": []}, {"text": "SVM and unigrams are adopted in baseline.", "labels": [], "entities": [{"text": "SVM", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.825270414352417}]}, {"text": "The numbers in the brackets are the official rankings.: Performance of our system, top-ranked system and baseline on test set for subtask 3, 4, 5.", "labels": [], "entities": []}, {"text": "SVM and unigrams are adopted in baseline.", "labels": [], "entities": [{"text": "SVM", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.825270414352417}]}, {"text": "The numbers in the brackets are the official rankings.", "labels": [], "entities": []}, {"text": "different features on development set with Support Vector Regression algorithm for subtask 1.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: The statistics of data sets for subtask 1 and 2.", "labels": [], "entities": []}, {"text": " Table 2: The statistics of data sets for subtask 3, 4, 5.", "labels": [], "entities": []}, {"text": " Table 3: Performance of different features on development set for subtask 1. \".+\" means to add current features to  the previous feature set. The numbers in the brackets are the performance increments compared with the previous  results.", "labels": [], "entities": []}, {"text": " Table 4: Performance of different learning algorithm on development set for subtask 1.", "labels": [], "entities": []}, {"text": " Table 5: Performance of our system, top-ranked system and baseline on test set for subtask 1, 2. SVM and unigrams  are adopted in baseline. The numbers in the brackets are the official rankings.", "labels": [], "entities": []}, {"text": " Table 6: Performance of our system, top-ranked system  and baseline on test set for subtask 3, 4, 5. SVM and  unigrams are adopted in baseline. The numbers in the  brackets are the official rankings.", "labels": [], "entities": []}]}