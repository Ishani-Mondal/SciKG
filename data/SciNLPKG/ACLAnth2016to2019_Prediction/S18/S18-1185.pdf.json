{"title": [{"text": "NLITrans at SemEval-2018 Task 12: Transfer of Semantic Knowledge for Argument Comprehension", "labels": [], "entities": [{"text": "NLITrans", "start_pos": 0, "end_pos": 8, "type": "DATASET", "confidence": 0.8079580068588257}, {"text": "SemEval-2018 Task 12", "start_pos": 12, "end_pos": 32, "type": "TASK", "confidence": 0.5570682287216187}]}], "abstractContent": [{"text": "The Argument Reasoning Comprehension Task requires significant language understanding and complex reasoning over world knowledge.", "labels": [], "entities": [{"text": "Argument Reasoning Comprehension Task", "start_pos": 4, "end_pos": 41, "type": "TASK", "confidence": 0.813312217593193}]}, {"text": "We focus on transfer of a sentence encoder to bootstrap more complicated models given the small size of the dataset.", "labels": [], "entities": []}, {"text": "Our best model uses a pre-trained BiLSTM to encode input sentences, learns task-specific features for the argument and warrants, then performs independent argument-warrant matching.", "labels": [], "entities": []}, {"text": "This model achieves mean test set accuracy of 64.43%.", "labels": [], "entities": [{"text": "mean test set", "start_pos": 20, "end_pos": 33, "type": "METRIC", "confidence": 0.9136119286219279}, {"text": "accuracy", "start_pos": 34, "end_pos": 42, "type": "METRIC", "confidence": 0.6006786823272705}]}, {"text": "Encoder transfer yields a significant gain to our best model over random initialization.", "labels": [], "entities": [{"text": "Encoder transfer", "start_pos": 0, "end_pos": 16, "type": "TASK", "confidence": 0.7508739829063416}]}, {"text": "Independent warrant matching effectively doubles the size of the dataset and provides additional regularization.", "labels": [], "entities": [{"text": "Independent warrant matching", "start_pos": 0, "end_pos": 28, "type": "TASK", "confidence": 0.6404242813587189}]}, {"text": "We demonstrate that regularization comes from ignoring statistical correlations between warrant features and position.", "labels": [], "entities": [{"text": "regularization", "start_pos": 20, "end_pos": 34, "type": "TASK", "confidence": 0.9759681224822998}]}, {"text": "We also report an experiment with our best model that only matches warrants to reasons, ignoring claims.", "labels": [], "entities": []}, {"text": "Relatively low performance degradation suggests that our model is not necessarily learning the intended task.", "labels": [], "entities": []}], "introductionContent": [{"text": "The Argument Reasoning Comprehension Task (ARCT) () addresses a significant open problem in argumentation mining: connecting reasons and claims via inferential licenses, called warrants.", "labels": [], "entities": [{"text": "Argument Reasoning Comprehension Task (ARCT)", "start_pos": 4, "end_pos": 48, "type": "TASK", "confidence": 0.7045616805553436}, {"text": "argumentation mining", "start_pos": 92, "end_pos": 112, "type": "TASK", "confidence": 0.7803144454956055}]}, {"text": "Warrants area form of shared world knowledge and are mostly implicit in argumentation.", "labels": [], "entities": []}, {"text": "This makes it difficult for machine learning algorithms to discover arguments, as they must acquire and use this knowledge to identify argument components and their relations.", "labels": [], "entities": []}, {"text": "ARCT isolates the reasoning step by not requiring warrants to be discovered.", "labels": [], "entities": [{"text": "ARCT isolates", "start_pos": 0, "end_pos": 13, "type": "TASK", "confidence": 0.8443052768707275}]}, {"text": "A correct warrant W and an incorrect alternative A are given, and the correct one must be predicted given the corresponding claim C and reason R.", "labels": [], "entities": []}, {"text": "However, this does not eliminate the need for other forms of world knowledge.", "labels": [], "entities": []}, {"text": "Consider the following example from the test set:", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Transfer results for our COMP model with different encoder sizes. Learning rates and dropout are tuned  to specific encoder sizes. All other hyperparameters are the same. Results are the mean test set accuracy of 200  runs from different random seeds. \"Difference\" shows the percentage change of transfer relative to random.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 211, "end_pos": 219, "type": "METRIC", "confidence": 0.8134788870811462}, {"text": "Difference", "start_pos": 263, "end_pos": 273, "type": "METRIC", "confidence": 0.9442660212516785}]}, {"text": " Table 2: Comparison of independent (COMP) and cor- related (CORR) models on full, half, and unbalanced  (Unbal.) datasets. COMP has 6,541,057 parameters  and CORR has 6,543,106.", "labels": [], "entities": []}]}