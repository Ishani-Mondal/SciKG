{"title": [{"text": "Binarizer at SemEval-2018 Task 3: Parsing dependency and deep learning for irony detection", "labels": [], "entities": [{"text": "irony detection", "start_pos": 75, "end_pos": 90, "type": "TASK", "confidence": 0.9698311984539032}]}], "abstractContent": [{"text": "In this paper, we describe the system submitted for the SemEval 2018 Task 3 (Irony detection in English tweets) Subtask A by the team Binarizer.", "labels": [], "entities": [{"text": "SemEval 2018 Task 3", "start_pos": 56, "end_pos": 75, "type": "TASK", "confidence": 0.8121792525053024}]}, {"text": "Irony detection is a key task for many natural language processing works.", "labels": [], "entities": [{"text": "Irony detection", "start_pos": 0, "end_pos": 15, "type": "TASK", "confidence": 0.8002771437168121}]}, {"text": "Our method treats ironical tweets to consist of smaller parts containing different emotions.", "labels": [], "entities": []}, {"text": "We breakdown tweets into separate phrases using a dependency parser.", "labels": [], "entities": []}, {"text": "We then embed those phrases using an LSTM-based neural network model which is pre-trained to predict emoticons for tweets.", "labels": [], "entities": []}, {"text": "Finally, we train a fully-connected network to achieve classification.", "labels": [], "entities": [{"text": "classification", "start_pos": 55, "end_pos": 69, "type": "TASK", "confidence": 0.9699521660804749}]}], "introductionContent": [{"text": "The micro-blogging site Twitter has created an abundance of data about opinions and sentiments regarding almost every aspect of daily life.", "labels": [], "entities": []}, {"text": "A deeper study of the public opinion can be obtained by applying natural language processing techniques on this data.", "labels": [], "entities": []}, {"text": "However, the performance of these NLP models is detrimentally affected by irony (.", "labels": [], "entities": []}, {"text": "As per the Oxford English Dictionary, irony is the expression of one's meaning by using language that normally signifies the opposite, typically for humorous or emphatic effect.", "labels": [], "entities": [{"text": "Oxford English Dictionary", "start_pos": 11, "end_pos": 36, "type": "DATASET", "confidence": 0.9261055787404379}]}, {"text": "This deviation between what is said and what is intended makes irony hard to detect.", "labels": [], "entities": []}, {"text": "Being a platform where users are free to communicate and express themselves colloquially, Twitter generates considerable data injected with irony.", "labels": [], "entities": []}, {"text": "Studying this would provide us with a better sentiment analysis of these tweets.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 45, "end_pos": 63, "type": "TASK", "confidence": 0.9164972901344299}]}, {"text": "Prior work on irony detection includes the use of unigrams and emoticons).", "labels": [], "entities": [{"text": "irony detection", "start_pos": 14, "end_pos": 29, "type": "TASK", "confidence": 0.964012861251831}]}, {"text": "describe an unsupervised pattern mining approach where the sentiment of the hashtag in the tweet is proposed to be a key indicator of sarcasm.", "labels": [], "entities": [{"text": "pattern mining", "start_pos": 25, "end_pos": 39, "type": "TASK", "confidence": 0.7803235352039337}]}, {"text": "If the sentiment of the tweet does not match the sentiment of the hashtag, it is predicted to be sarcastic.", "labels": [], "entities": []}, {"text": "illustrates a semi-supervised approach where rule-based classifiers are used to look for negative situation phrases and positive verbs in a sentence.", "labels": [], "entities": []}, {"text": "build pattern-based features that detect the presence of discriminative patterns as extracted from a large sarcasm-labelled corpus.", "labels": [], "entities": []}, {"text": "N-gram-based approaches have also been used () with sentiment features.", "labels": [], "entities": []}, {"text": "use similarity between word embeddings as feature and use convolutional neural networks to extract sentiment, emotion and personality features for sarcasm detection.", "labels": [], "entities": [{"text": "sarcasm detection", "start_pos": 147, "end_pos": 164, "type": "TASK", "confidence": 0.9104760587215424}]}, {"text": "SemEval-2018 Task 3 (the 12th workshop on semantic evaluation) specifies two subtasks in relation to irony detection in English tweets.", "labels": [], "entities": [{"text": "semantic evaluation", "start_pos": 42, "end_pos": 61, "type": "TASK", "confidence": 0.7085225135087967}, {"text": "irony detection in English tweets", "start_pos": 101, "end_pos": 134, "type": "TASK", "confidence": 0.8086665272712708}]}, {"text": "In subtask A the goal was to train a binary classifier that detects whether a given tweet is ironic or not.", "labels": [], "entities": []}, {"text": "Subtask B was a multi-class classification problem where four labels were specified to describe the nature of irony (verbal irony by means of a polarity contrast, situational irony, other verbal irony, and non-ironic).", "labels": [], "entities": []}, {"text": "The goal was to assign one of the four labels to each tweet.", "labels": [], "entities": []}, {"text": "We propose anew method which considers ironical tweets to be collections of smaller parts containing different emotions.", "labels": [], "entities": []}, {"text": "We breakdown tweets into these collections using a dependency parser and embed them using DeepMoji) which is pre-trained to predict emoticons for tweets.", "labels": [], "entities": []}, {"text": "Finally we train a classifier to detect irony.", "labels": [], "entities": [{"text": "detect irony", "start_pos": 33, "end_pos": 45, "type": "TASK", "confidence": 0.5060541182756424}]}, {"text": "The paper is organized as follows: We discuss our methods in section 2.", "labels": [], "entities": []}, {"text": "Section 3 contains the details about the experiments and the training data.", "labels": [], "entities": []}, {"text": "In Section 4 we discuss the results and Section 5 concludes the paper with closing remarks.", "labels": [], "entities": []}], "datasetContent": [{"text": "For subtask A, we were provided with a dataset consisting of tweets along with a binary class (0 or 1) which indicates whether this tweet is ironic or not (0 for non-ironic tweets and 1 for ironic tweets).", "labels": [], "entities": []}, {"text": "The data was collected from Twitter API by querying tweets using the hashtags #irony, #sarcasm and #not, with subsequent manual an- notation to remove noise.", "labels": [], "entities": []}, {"text": "3,833 tweets for training and 784 tweets for testing were provided.", "labels": [], "entities": []}, {"text": "The evaluation was done by using accuracy, precision, recall and F1 score.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 33, "end_pos": 41, "type": "METRIC", "confidence": 0.9998059868812561}, {"text": "precision", "start_pos": 43, "end_pos": 52, "type": "METRIC", "confidence": 0.9996800422668457}, {"text": "recall", "start_pos": 54, "end_pos": 60, "type": "METRIC", "confidence": 0.9997567534446716}, {"text": "F1 score", "start_pos": 65, "end_pos": 73, "type": "METRIC", "confidence": 0.9835650026798248}]}], "tableCaptions": []}