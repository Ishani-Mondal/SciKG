{"title": [{"text": "UWB at SemEval-2018 Task 1: Emotion Intensity Detection in Tweets", "labels": [], "entities": [{"text": "UWB", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.8773817420005798}, {"text": "Emotion Intensity Detection in Tweets", "start_pos": 28, "end_pos": 65, "type": "TASK", "confidence": 0.8586404204368592}]}], "abstractContent": [{"text": "This paper describes our system created for the SemEval-2018 Task 1: Affect in Tweets (AIT-2018).", "labels": [], "entities": [{"text": "SemEval-2018 Task 1", "start_pos": 48, "end_pos": 67, "type": "TASK", "confidence": 0.8155121405919393}]}, {"text": "We participated in both the regression and the ordinal classification subtasks for emotion intensity detection in English, Arabic, and Spanish.", "labels": [], "entities": [{"text": "emotion intensity detection", "start_pos": 83, "end_pos": 110, "type": "TASK", "confidence": 0.6677724421024323}]}, {"text": "For the regression subtask we use the Affecti-veTweets system with added features using various word embeddings, lexicons, and LDA.", "labels": [], "entities": []}, {"text": "For the ordinal classification we additionally use our Brainy system with features using parse tree, POS tags, and morphological features.", "labels": [], "entities": []}, {"text": "The most beneficial features apart from word and character n-grams include word em-beddings, POS count and morphological features .", "labels": [], "entities": [{"text": "POS count", "start_pos": 93, "end_pos": 102, "type": "METRIC", "confidence": 0.7247830331325531}]}], "introductionContent": [{"text": "The task of Detecting Emotion Intensity assigns the intensity to a tweet with given emotion.", "labels": [], "entities": [{"text": "Detecting Emotion Intensity", "start_pos": 12, "end_pos": 39, "type": "TASK", "confidence": 0.9136394262313843}]}, {"text": "The emotions include anger, fear, joy, and sadness.", "labels": [], "entities": []}, {"text": "The intensity is either on a scale of zero to one for the regression subtask, or one of four classes (0:no, 1: low, 2: moderate, 3: high) for the classification subtask.", "labels": [], "entities": []}, {"text": "The task was prepared in three languages: English, Arabic, and Spanish.", "labels": [], "entities": []}, {"text": "For each language there are four training and test sets of data -one for each emotion.", "labels": [], "entities": []}, {"text": "The data creation is described in  and detailed description of the task is in ( . We participated in the emotion intensity regression task (EI-reg) and in the emotion intensity ordinal classification task (EI-oc) in English, Arabic and Spanish.", "labels": [], "entities": [{"text": "emotion intensity regression task (EI-reg)", "start_pos": 105, "end_pos": 147, "type": "METRIC", "confidence": 0.6704603816781726}, {"text": "emotion intensity ordinal classification task (EI-oc)", "start_pos": 159, "end_pos": 212, "type": "TASK", "confidence": 0.689293596893549}]}], "datasetContent": [{"text": "All presented experiments are evaluated on the test data for the given task.", "labels": [], "entities": []}, {"text": "We performed ablation experiments to see which features are the most beneficial (see, 8, and 10).", "labels": [], "entities": []}, {"text": "Numbers represent the performance change when the given feature is removed . Word embeddings features have a great impact on system performance, so we compared several word embeddings for every language, 3, and 4).", "labels": [], "entities": []}, {"text": "For English was best WE-ue word embeddings, but for submission we used WE-b word embeddings, because it worked better on dev data.", "labels": [], "entities": []}, {"text": "In Spanish tweets the WE-us word embeddings outperformed the WE-ft word embeddings in regression and WE-us was better for classification in anger and on average of all emotions.", "labels": [], "entities": []}, {"text": "For classification in Arabic was var-CBOW best on every emotion except anger and for regression var-SG worked best on average and on fear.", "labels": [], "entities": []}, {"text": "We also experimented with only LDA features to find out how the numbers of topics in LDA model affect the performance (see.", "labels": [], "entities": []}, {"text": "We star- The lowest number denotes the most beneficial feature ted with models containing 5 topics and continued up to 1000 (step was non-equidistantly increased).", "labels": [], "entities": []}, {"text": "Our experiments suggest that the best setting is around 200-300 topics.", "labels": [], "entities": []}, {"text": "We selected the number of topics based on the performance on the development data.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Arabic embeddings experiments results", "labels": [], "entities": []}, {"text": " Table 3: Spanish embeddings experiments results", "labels": [], "entities": []}, {"text": " Table 4: English embeddings experiments results", "labels": [], "entities": []}, {"text": " Table 6: Pearson correlation for the emotion intensity ordinal classification task", "labels": [], "entities": [{"text": "Pearson correlation", "start_pos": 10, "end_pos": 29, "type": "METRIC", "confidence": 0.935857743024826}, {"text": "emotion intensity ordinal classification", "start_pos": 38, "end_pos": 78, "type": "TASK", "confidence": 0.6596420854330063}]}, {"text": " Table 7: Cohen's kappa for the emotion intensity ordinal classification task", "labels": [], "entities": [{"text": "emotion intensity ordinal classification", "start_pos": 32, "end_pos": 72, "type": "TASK", "confidence": 0.696040540933609}]}, {"text": " Table 8: AffectiveTweets feature ablation study", "labels": [], "entities": []}, {"text": " Table 9: Brainy feature ablation study", "labels": [], "entities": []}]}