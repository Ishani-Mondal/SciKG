{"title": [{"text": "HCCL at SemEval-2018 Task 8: An End-to-End System for Sequence Labeling from Cybersecurity Reports", "labels": [], "entities": [{"text": "Sequence Labeling from Cybersecurity Reports", "start_pos": 54, "end_pos": 98, "type": "TASK", "confidence": 0.8519565105438233}]}], "abstractContent": [{"text": "This paper describes HCCL team systems that participated in SemEval 2018 Task 8: Se-cureNLP (Semantic Extraction from cyberse-curity reports using NLP).", "labels": [], "entities": [{"text": "SemEval 2018 Task 8", "start_pos": 60, "end_pos": 79, "type": "TASK", "confidence": 0.9101663380861282}]}, {"text": "To solve the problem , our team applied a neural network architecture that benefits from both word and character level representaions automatically, by using combination of Bi-directional LSTM, CNN and CRF (Ma and Hovy, 2016).", "labels": [], "entities": []}, {"text": "Our system is truly end-to-end, requiring no feature engineering or data preprocessing, and we ranked 4th in the subtask 1, 7th in the subtask 2 and 3rd in the SubTask2-relaxed.", "labels": [], "entities": []}], "introductionContent": [{"text": "Recently, cybersecurity defense has also been recognized as one of the problem areas likely to be important both for advancing AI and for its longrun impact on society.", "labels": [], "entities": [{"text": "cybersecurity defense", "start_pos": 10, "end_pos": 31, "type": "TASK", "confidence": 0.7600063383579254}]}, {"text": "In particular, natural language processing (NLP) has the potential for substantial contribution in cybersecurity and that this is a critical research area given the urgency and risks involved (. In), there are four subtask: 1.", "labels": [], "entities": [{"text": "natural language processing (NLP)", "start_pos": 15, "end_pos": 48, "type": "TASK", "confidence": 0.8058243890603384}]}, {"text": "SubTask1: Classify if a sentence is useful for inferring malware actions and capabilities 2.", "labels": [], "entities": []}, {"text": "SubTask2: predict the token labels in the sentences.", "labels": [], "entities": []}, {"text": "The output needs to be in BIO format.", "labels": [], "entities": []}, {"text": "There are 3 types of token labels: \"Action\", \"Entity\", and \"Modifier\".", "labels": [], "entities": []}, {"text": "3. SubTask3: predict the relations between the token labels 4.", "labels": [], "entities": []}, {"text": "SubTask4: predict the attributes for each entity token In this evaluation, our team submitted the results of Subtask 1 and Subtask 2.", "labels": [], "entities": []}, {"text": "To tackle this problem, we treat subtask 2 as a sequence labeling problem.", "labels": [], "entities": [{"text": "sequence labeling", "start_pos": 48, "end_pos": 65, "type": "TASK", "confidence": 0.5969637036323547}]}, {"text": "Most traditional high performance sequence labeling models are linear statistical models, including Hidden Markov Models (HMM) and Conditional Random Fields (CRF) (, which rely heavily on hand-crafted features and taskspecific resources.", "labels": [], "entities": []}, {"text": "Recently, many neural network based methods have been successfully applied to sequence labeling task: Named Entity Recognition.", "labels": [], "entities": [{"text": "sequence labeling task", "start_pos": 78, "end_pos": 100, "type": "TASK", "confidence": 0.7779377897580465}, {"text": "Named Entity Recognition", "start_pos": 102, "end_pos": 126, "type": "TASK", "confidence": 0.6528193950653076}]}, {"text": "In this paper, we present an end-to-end System (combined CNN, LSTM and CRF) for sequence labeling that uses no complicated handcrafted features or domain knowledge.", "labels": [], "entities": [{"text": "sequence labeling", "start_pos": 80, "end_pos": 97, "type": "TASK", "confidence": 0.7648150622844696}]}, {"text": "LSTM is capable of learning long-term dependencies, which is beneficial to sequence modeling tasks.", "labels": [], "entities": [{"text": "sequence modeling tasks", "start_pos": 75, "end_pos": 98, "type": "TASK", "confidence": 0.8080887198448181}]}, {"text": "And character level CNN can get characterlevel representation.", "labels": [], "entities": []}, {"text": "For sequence labeling (or general structured prediction) tasks, it is beneficial to consider the correlations between labels in neighborhoods and jointly decode the best chain of labels fora given input sentence.", "labels": [], "entities": [{"text": "sequence labeling (or general structured prediction) tasks", "start_pos": 4, "end_pos": 62, "type": "TASK", "confidence": 0.6804350912570953}]}, {"text": "So we model label sequence jointly using a conditional random field (CRF), instead of decoding each label independently.", "labels": [], "entities": []}, {"text": "Therefore, the system we proposed is based on CNN, Bi-directional LSTM and CRF.", "labels": [], "entities": [{"text": "CNN", "start_pos": 46, "end_pos": 49, "type": "DATASET", "confidence": 0.884269654750824}]}, {"text": "And in the SubTask2-relaxed our group ranked third.", "labels": [], "entities": []}, {"text": "As for SubTask1, we proposed a ruled based method that if any token in the sentence is labled \"Action\", \"Entity\", or \"Modifier\", the sentence would be considered relevant.", "labels": [], "entities": []}, {"text": "Our team ranked 4th in the subtask 1.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Results on subtask1 and subtask2.", "labels": [], "entities": []}]}