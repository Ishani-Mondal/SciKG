{"title": [{"text": "AttnConvnet at SemEval-2018 Task 1: Attention-based Convolutional Neural Networks for Multi-label Emotion Classification", "labels": [], "entities": [{"text": "Multi-label Emotion Classification", "start_pos": 86, "end_pos": 120, "type": "TASK", "confidence": 0.6708478430906931}]}], "abstractContent": [{"text": "In this paper, we propose an attention-based classifier that predicts multiple emotions of a given sentence.", "labels": [], "entities": []}, {"text": "Our model imitates human's two-step procedure of sentence understanding and it can effectively represent and classify sentences.", "labels": [], "entities": [{"text": "sentence understanding", "start_pos": 49, "end_pos": 71, "type": "TASK", "confidence": 0.7593393921852112}]}, {"text": "With emoji-to-meaning preprocess-ing and extra lexicon utilization, we further improve the model performance.", "labels": [], "entities": []}, {"text": "We train and evaluate our model with data provided by SemEval-2018 task 1-5, each sentence of which has several labels among 11 given emotions.", "labels": [], "entities": []}, {"text": "Our model achieves 5th/1st rank in En-glish/Spanish respectively.", "labels": [], "entities": []}], "introductionContent": [{"text": "Since the revolution in deep neural networks, especially with the help of Long short-term memory, it has been easy for machines to imitate human's linguistic activities, such as sentence classification, language model(, machine translation(.", "labels": [], "entities": [{"text": "sentence classification", "start_pos": 178, "end_pos": 201, "type": "TASK", "confidence": 0.7528801262378693}, {"text": "machine translation", "start_pos": 220, "end_pos": 239, "type": "TASK", "confidence": 0.7268767207860947}]}, {"text": "Emotion classification is a subpart of sentence classification that predicts the emotion of the given sentence by understanding the meaning of it.", "labels": [], "entities": [{"text": "Emotion classification", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.7945672869682312}, {"text": "sentence classification", "start_pos": 39, "end_pos": 62, "type": "TASK", "confidence": 0.7665030658245087}]}, {"text": "Multi-label emotion classification requires more powerful ability to comprehend the sentence in variety of aspects.", "labels": [], "entities": [{"text": "Multi-label emotion classification", "start_pos": 0, "end_pos": 34, "type": "TASK", "confidence": 0.8047288060188293}]}, {"text": "For example, given a sentence 'For real?", "labels": [], "entities": []}, {"text": "Look what I got for my birthday present!!', it is easy for human to figure out that the sentence not only expressing 'joy' but also 'surprise'.", "labels": [], "entities": []}, {"text": "However, machines may require more task-specific structure to solve the same problem.", "labels": [], "entities": []}, {"text": "Attention mechanisms are one of the most spotlighted trends in deep learning and recently made their way into NLP.", "labels": [], "entities": []}, {"text": "Applied to systems with neural networks, it functions as visual attention mechanisms found in humans) and the most effective region of features will be highlighted overtime, making the system better exploit the features related to the training objective.", "labels": [], "entities": []}, {"text": "() is one of the most significant footprints of attention mechanism in NLP and they applied attention mechanisms to machine translation for the first time.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 116, "end_pos": 135, "type": "TASK", "confidence": 0.7832733690738678}]}, {"text": "The model generates target word under the influence of related source words.", "labels": [], "entities": []}, {"text": "Furthermore, proposed a brand new architecture for neural machine translation.", "labels": [], "entities": [{"text": "neural machine translation", "start_pos": 51, "end_pos": 77, "type": "TASK", "confidence": 0.6620730261007944}]}, {"text": "The model utilizes attention mechanisms not only as the submodule but also as the main structure, improving time complexity and performance.", "labels": [], "entities": []}, {"text": "Inspired by, we come up with attention-based multi-label sentence classifier that can effectively represent and classify sentences.", "labels": [], "entities": []}, {"text": "Our system is composed of a selfattention module and multiple CNNs enabling it to imitate human's two-step procedure of analyzing sentences: comprehend and classify.", "labels": [], "entities": []}, {"text": "Furthermore, our emoji-to-meaning preprocessing and extra lexicon utilization improve model performance on given dataset.", "labels": [], "entities": []}, {"text": "We evaluated our system on the dataset of (, where it ranked 5th/1st rank in English/Spanish respectively.", "labels": [], "entities": []}], "datasetContent": [{"text": "We conduct several experiments to prove the effectiveness of our model, each to verify the benefit from: (1) tweets specific preprocessing (2) selfattention representation (3) emotional lexicon utilization.", "labels": [], "entities": []}, {"text": "Experimental results are mainly compared with English data.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 3: Experimental results with extra resources and  an ensemble result", "labels": [], "entities": []}]}