{"title": [{"text": "YNU-HPCC at SemEval-2018 Task 2: Multi-ensemble Bi-GRU Model with Attention Mechanism for Multilingual Emoji Prediction", "labels": [], "entities": [{"text": "YNU-HPCC", "start_pos": 0, "end_pos": 8, "type": "DATASET", "confidence": 0.7921072840690613}, {"text": "Multilingual Emoji Prediction", "start_pos": 90, "end_pos": 119, "type": "TASK", "confidence": 0.5955694317817688}]}], "abstractContent": [{"text": "This paper describes our approach to SemEval-2018 Task 2, which aims to predict the most likely associated emoji, given a tweet in English or Spanish.", "labels": [], "entities": [{"text": "SemEval-2018 Task 2", "start_pos": 37, "end_pos": 56, "type": "TASK", "confidence": 0.8789095878601074}]}, {"text": "We normalized text-based tweets during preprocessing, following which we utilized a bi-directional gated recurrent unit with an attention mechanism to build our base model.", "labels": [], "entities": []}, {"text": "Multi-models with or without class weights were trained for the ensemble methods.", "labels": [], "entities": []}, {"text": "We boosted models without class weights, and only strong boost classifiers were identified.", "labels": [], "entities": []}, {"text": "In our system, not only was a boosting method used, but we also took advantage of the voting ensemble method to enhance our final system result.", "labels": [], "entities": []}, {"text": "Our method demonstrated an obvious improvement of approximately 3% of the macro F1 score in English and 2% in Spanish.", "labels": [], "entities": [{"text": "F1 score", "start_pos": 80, "end_pos": 88, "type": "METRIC", "confidence": 0.9328041672706604}]}], "introductionContent": [{"text": "As a novel means of enhancing the visual effect and meaning of short text messages, emojis are almost indispensable to each social platform, such as Facebook, Twitter, and Instagram.", "labels": [], "entities": []}, {"text": "These graphic facial expressions and other object symbols enrich the emotion the user wishes to express in a text-based message.", "labels": [], "entities": []}, {"text": "Although they are significant as part of social messages, emojis have scarcely attracted attention from a natural language processing (NLP) standpoint.", "labels": [], "entities": []}, {"text": "Notable exceptions include studies focused on emoji semantics and usages (.", "labels": [], "entities": []}, {"text": "However, the interplay between textbased messages and emojis remains virtually unexplored.", "labels": [], "entities": []}, {"text": "The aim of SemEval-2018 task 2 () is to fill this gap by providing all participants with a large set of textbased tweets and their related emojis, which were extracted from original tweet messages, in order to determine the connection between text words and emojis.", "labels": [], "entities": [{"text": "SemEval-2018 task 2", "start_pos": 11, "end_pos": 30, "type": "TASK", "confidence": 0.8515284856160482}]}, {"text": "In recent years, an increasing amount of research work has been conducted on the sentiment analysis of tweets.", "labels": [], "entities": [{"text": "sentiment analysis of tweets", "start_pos": 81, "end_pos": 109, "type": "TASK", "confidence": 0.9196898639202118}]}, {"text": "Emojis have always played an important role in the sentiment polarity of tweets.", "labels": [], "entities": []}, {"text": "proposed a sentiment map of the 751 most frequently used emojis, by computing the sentiment emoji from the sentiment of tweets in which they occurred, and they determined a significant difference in the sentiment distribution of tweets with and without emojis.", "labels": [], "entities": []}, {"text": "As opposed to sentiment polarity prediction of tweets, we further investigated potential tweet emojis in this task, evoked by the text part.", "labels": [], "entities": [{"text": "sentiment polarity prediction", "start_pos": 14, "end_pos": 43, "type": "TASK", "confidence": 0.7301567196846008}]}, {"text": "Neural networks involving attention mechanisms have been studied extensively in the image processing and NLP fields, and have demonstrated remarkable results, particularly convolutional neural networks (CNNs)) and long short-term memories (LSTMs)).", "labels": [], "entities": []}, {"text": "Cliche (2017) assembled several CNNs and LSTMs and achieved first ranking in all of five English subtasks.", "labels": [], "entities": []}, {"text": "proposed a feed-forward network model with attention, which selects the most important element from each time step using learnable weights, depending on the target.", "labels": [], "entities": []}, {"text": "As a variant of LSTM, the gated recurrent units (GRUs) ( ) use gating units directly in order to modulate the data flow inside the unit, rather than consisting of separate memory cells.", "labels": [], "entities": []}, {"text": "For this task, we firstly utilized bi-directional GRUs and the attention mechanism to train the base model, following which we boosted the base model with different sample weights.", "labels": [], "entities": []}, {"text": "In order to achieve optimum performance, soft and hard voting ensemble methods were also used in our system.", "labels": [], "entities": []}, {"text": "The remainder of paper is structured as follows.", "labels": [], "entities": []}, {"text": "Section 2 provides an overview of task 2.", "labels": [], "entities": []}, {"text": "In section 3, we describe the architecture of our base model, particularly the attention mechanism, as well as the multi-ensemble methods used in our submission.", "labels": [], "entities": []}, {"text": "Section 4 describes our experiment, which consists of system parameters, evaluation metrics, and experimental results for the two subtasks.", "labels": [], "entities": []}, {"text": "Finally, in section 5, we list several possible improvement points, and in section 6, we outline our main conclusions.", "labels": [], "entities": []}], "datasetContent": [{"text": "The organizers provided a huge amount of training data, including 500K tweets in English and 100K tweets in Spanish . We crawled almost the entire set of tweets with Twitter APIs 2 , as parts of the training tweets were no longer available.", "labels": [], "entities": []}, {"text": "provides a detailed distribution of the datasets for subtasks 1 and 2.", "labels": [], "entities": []}, {"text": "Furthermore, all of the used emoji labels extracted from the tweets are the 20 or 19 most frequently used emojis in the languages themselves.", "labels": [], "entities": []}, {"text": "Data samples for these classes are gradually decreasing; thus, datasets of the two The crawler and extractor for this task can be downloaded from https://github.com/fvancesco/Semeval2018-Task2-Emoji-Detection/tree/master/dataset 2 https://apps.twitter.com/ subtasks are both imbalanced.", "labels": [], "entities": []}, {"text": "In subtask 1, the greatest majority class includes 106352 (21.7%) samples, nearly ten times that of the lowest minority class , which includes only 12190 (2.5%) samples.", "labels": [], "entities": []}, {"text": "For subtask 2, similar to subtask 1, the greatest majority class includes 19640 (19.9%) samples, while the lowest minority class includes 2525 (2.6%) samples.", "labels": [], "entities": []}, {"text": "Pre-trained Twitter embeddings for English and Spanish were offered in the task.", "labels": [], "entities": []}, {"text": "We validated these by using another pre-trained embedding from GloVe 3 (, and the English embedding offered in the task presented approximately the same performance in our test.", "labels": [], "entities": [{"text": "GloVe 3", "start_pos": 63, "end_pos": 70, "type": "DATASET", "confidence": 0.9349378645420074}]}, {"text": "For evaluation purposes, the official results were based on the macro F1 score for the two tasks.", "labels": [], "entities": [{"text": "F1 score", "start_pos": 70, "end_pos": 78, "type": "METRIC", "confidence": 0.8752675354480743}]}, {"text": "The F1 score was calculated as follows: where F i is the F1 score of the i-th class, and \u03c0 i and \u03c1 i denote the precision and recall of the i-th class, respectively.", "labels": [], "entities": [{"text": "F1 score", "start_pos": 4, "end_pos": 12, "type": "METRIC", "confidence": 0.9833050072193146}, {"text": "F1 score", "start_pos": 57, "end_pos": 65, "type": "METRIC", "confidence": 0.9863872826099396}, {"text": "precision", "start_pos": 112, "end_pos": 121, "type": "METRIC", "confidence": 0.9995321035385132}, {"text": "recall", "start_pos": 126, "end_pos": 132, "type": "METRIC", "confidence": 0.9982568621635437}]}, {"text": "The macro average provides an equal weight to all the classes, regardless of how many samples belong to it.", "labels": [], "entities": []}, {"text": "The micro average provides equal weights to all the samples, thereby favoring the performance of the majority classes.", "labels": [], "entities": []}, {"text": "The macro F1 as well as micro F1 score were utilized to evaluate the performance of every model in our system.", "labels": [], "entities": [{"text": "F1", "start_pos": 10, "end_pos": 12, "type": "METRIC", "confidence": 0.8062437176704407}, {"text": "micro F1 score", "start_pos": 24, "end_pos": 38, "type": "METRIC", "confidence": 0.7713135083516439}]}], "tableCaptions": [{"text": " Table 1: Datasets of Task2.", "labels": [], "entities": []}, {"text": " Table 2: Results of each model and voting ensem- ble in Spanish.", "labels": [], "entities": [{"text": "ensem- ble", "start_pos": 43, "end_pos": 53, "type": "METRIC", "confidence": 0.8166331052780151}]}, {"text": " Table 3: Macro F1 of each emoji label in Spanish.", "labels": [], "entities": [{"text": "F1", "start_pos": 16, "end_pos": 18, "type": "METRIC", "confidence": 0.5381643176078796}]}, {"text": " Table 4: Results of each model and voting ensem- ble in English.", "labels": [], "entities": [{"text": "ensem- ble", "start_pos": 43, "end_pos": 53, "type": "METRIC", "confidence": 0.8486101627349854}]}, {"text": " Table  5.  All above-mentioned results were obtained  following the competition, and we changed the  learning rate from 0.01 to 0.001 for increased  boost classifiers. The competition submission  only used two boost classifiers for ensemble in  Spanish and one was utilized in English. We  ranked 16th among 48 teams in the English task  and 13th among 21 teams in the Spanish task", "labels": [], "entities": []}]}