{"title": [{"text": "NEUROSENT-PDI at SemEval-2018 Task 3: Understanding Irony in Social Networks Through a Multi-Domain Sentiment Model", "labels": [], "entities": [{"text": "NEUROSENT-PDI", "start_pos": 0, "end_pos": 13, "type": "METRIC", "confidence": 0.5962045192718506}]}], "abstractContent": [{"text": "This paper describes the NeuroSent system that participated in SemEval 2018 Task 3.", "labels": [], "entities": [{"text": "SemEval 2018 Task 3", "start_pos": 63, "end_pos": 82, "type": "TASK", "confidence": 0.8541145771741867}]}, {"text": "Our system takes a supervised approach that builds on neural networks and word embeddings.", "labels": [], "entities": []}, {"text": "Word embeddings were built by starting from a repository of user generated reviews.", "labels": [], "entities": []}, {"text": "Thus, they are specific for sentiment analysis tasks.", "labels": [], "entities": [{"text": "sentiment analysis tasks", "start_pos": 28, "end_pos": 52, "type": "TASK", "confidence": 0.9626254836718241}]}, {"text": "Then, tweets are converted in the corresponding vector representation and given as input to the neural network with the aim of learning the different semantics contained in each emotion taken into account by the SemEval task.", "labels": [], "entities": [{"text": "SemEval task", "start_pos": 212, "end_pos": 224, "type": "TASK", "confidence": 0.8742705285549164}]}, {"text": "The output layer has been adapted based on the characteristics of each subtask.", "labels": [], "entities": []}, {"text": "Preliminary results obtained on the provided training set are encouraging for pursuing the investigation into this direction.", "labels": [], "entities": []}], "introductionContent": [{"text": "Sentiment Analysis is a natural language processing (NLP) task () which aims at classifying documents according to the opinion expressed about a given subject.", "labels": [], "entities": [{"text": "Sentiment Analysis", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.8997684121131897}, {"text": "natural language processing (NLP) task", "start_pos": 24, "end_pos": 62, "type": "TASK", "confidence": 0.7212264708110264}]}, {"text": "Many works available in the literature address the sentiment analysis problem without distinguishing specific information context of documents when sentiment models are built.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 51, "end_pos": 69, "type": "TASK", "confidence": 0.96462082862854}]}, {"text": "The necessity of investigating this problem from a multi-domain perspective is led by the different influence that a term might have in different contexts.", "labels": [], "entities": []}, {"text": "The idea of adapting terms polarity to different domains emerged only in the last decade.", "labels": [], "entities": []}, {"text": "Multi-domain sentiment analysis approaches discussed in the literature focus on building models for transferring information between pairs of domains.", "labels": [], "entities": [{"text": "Multi-domain sentiment analysis", "start_pos": 0, "end_pos": 31, "type": "TASK", "confidence": 0.8128983775774637}]}, {"text": "While on the one hand such approaches allow to propagate specific domain information to others, their drawback is the necessity of building new transfer models every time anew domain has to be analyzed.", "labels": [], "entities": []}, {"text": "Thus, such approaches do not have a great generalization capability of analyzing texts, because transfer models are limited to the N domains used for building the models.", "labels": [], "entities": []}, {"text": "The problem of detecting irony in text can be considered from a multi-domain perspective.", "labels": [], "entities": [{"text": "detecting irony in text", "start_pos": 15, "end_pos": 38, "type": "TASK", "confidence": 0.8971092998981476}]}, {"text": "The development of the social web has stimulated creative and figurative language use like irony.", "labels": [], "entities": []}, {"text": "This frequent use of irony on social media has important implications for natural language processing tasks, which struggle to maintain high performance when applied to ironic text (.", "labels": [], "entities": []}, {"text": "Although different definitions of irony co-exist, it is often identified as a trope or figurative language use whose actual meaning differs from what is literally enunciated.", "labels": [], "entities": []}, {"text": "As such, modeling irony has a large potential for applications in various research areas, including text mining, author profiling, detecting online harassment, and perhaps one of the most popular applications at present, sentiment analysis.", "labels": [], "entities": [{"text": "text mining", "start_pos": 100, "end_pos": 111, "type": "TASK", "confidence": 0.8453996479511261}, {"text": "author profiling", "start_pos": 113, "end_pos": 129, "type": "TASK", "confidence": 0.7433205544948578}, {"text": "detecting online harassment", "start_pos": 131, "end_pos": 158, "type": "TASK", "confidence": 0.8206260800361633}, {"text": "sentiment analysis", "start_pos": 221, "end_pos": 239, "type": "TASK", "confidence": 0.9595467448234558}]}, {"text": "As described by, recent approaches to irony can roughly be classified into rule-based and machine learning-based methods.", "labels": [], "entities": []}, {"text": "While rule-based approaches mostly rely upon lexical information and require no training, machine learning invariably makes use of training data and exploits different types of information sources, including bags of words, syntactic patterns, sentiment information or semantic relatedness.", "labels": [], "entities": []}, {"text": "Recently, deep learning techniques gain increasing popularity for this task as they allow to integrate semantic relatedness by making use of, for instance, word embeddings.", "labels": [], "entities": []}, {"text": "In this paper, we discuss how the NeuroSent tool has been applied in).", "labels": [], "entities": []}, {"text": "The tool leverages on the 512 following pillars: (i) the use of word embeddings for representing each word contained in raw sentences; (ii) the word embeddings are generated from an opinion-based corpus instead of a general purpose one (like news or Wikipedia); (iii) the design of a deep learning technique exploiting the generated word embeddings for training the sentiment model; and (iv) the use of multiple output layers for combining domain overlap scores with domain-specific polarity predictions.", "labels": [], "entities": []}, {"text": "The last point enables the exploitation of linguistic overlaps between domains, which can be considered one of the pivotal assets of our approach.", "labels": [], "entities": []}, {"text": "This way, the overall polarity of a document is computed by aggregating, for each domain, the domain-specific polarity value multiplied by a belonging degree representing the overlap between the embedded representation of the whole document and the domain itself.", "labels": [], "entities": []}], "datasetContent": [{"text": "The validation procedure leverages on a fivefold cross evaluation setting in order to validate the robustness of the proposed solution.", "labels": [], "entities": []}, {"text": "The approach has been compared with four baselines: Support Vector Machine (SVM) (Chang and Lin, 2011), Naive Bayes (NB) and Maximum Entropy (ME), and Convolutional Neural Network (.", "labels": [], "entities": []}, {"text": "In, we provide average Pearson correlation obtained on the five folds in which the training set has been split.", "labels": [], "entities": [{"text": "Pearson correlation", "start_pos": 23, "end_pos": 42, "type": "METRIC", "confidence": 0.9265365302562714}]}, {"text": "The obtained results demonstrated the suitability of NeuroSent with respect to the adopted baselines.", "labels": [], "entities": []}, {"text": "We may also observed how solutions based on neural networks obtained a significant improvement with respect to the others for both tasks.", "labels": [], "entities": []}, {"text": "We performed a detailed error analysis concerning the performance of NeuroSent.", "labels": [], "entities": []}, {"text": "In general, we observed how our strategy tends to provide false negative predictions.", "labels": [], "entities": []}, {"text": "An in depth analysis of some incorrect predictions highlighted that the embedded representations of some positive opinion words are very close to the space region of negative opinion words.", "labels": [], "entities": []}, {"text": "Even if we may state that the confidence about positive predictions is very high, this scenario leads to have a predominant negative classification for borderline instances.", "labels": [], "entities": []}, {"text": "On the one hand, a possible action for improving the effectiveness our strategy is to increase the granularity of the embeddings (i.e. augmenting the size of the embedding vectors) in order to increase the distance between the positive and negative polarities space regions.", "labels": [], "entities": []}, {"text": "On the other hand, by increasing the size of embedding vectors, the computational time for building, or updating, the model and for evaluating a single instance increases as well.", "labels": [], "entities": []}, {"text": "Part of the future work, will be the analysis of more efficient neural network architectures able to manage augmented embedding vectors without negatively affecting the efficiency of the platform.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Results obtained on the training set by Neu- roSent and by the four baselines.", "labels": [], "entities": [{"text": "Neu- roSent", "start_pos": 50, "end_pos": 61, "type": "DATASET", "confidence": 0.9083646337191263}]}]}