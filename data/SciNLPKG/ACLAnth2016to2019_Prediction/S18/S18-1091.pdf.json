{"title": [{"text": "Random Decision Syntax Trees at SemEval-2018 Task 3: LSTMs and Sentiment Scores for Irony Detection", "labels": [], "entities": [{"text": "Irony Detection", "start_pos": 84, "end_pos": 99, "type": "TASK", "confidence": 0.6915138214826584}]}], "abstractContent": [{"text": "We propose a Long Short Term Memory Neu-ral Network model for irony detection in tweets in this paper.", "labels": [], "entities": [{"text": "irony detection", "start_pos": 62, "end_pos": 77, "type": "TASK", "confidence": 0.9000152945518494}]}, {"text": "Our model is trained using word embeddings and emoji embeddings.", "labels": [], "entities": []}, {"text": "We show that adding sentiment scores to our model improves the F1 score of our baseline LSTM by approximately .012, and therefore show that high-level features can be used to improve word embeddings in certain Natural Language Processing applications.", "labels": [], "entities": [{"text": "F1 score", "start_pos": 63, "end_pos": 71, "type": "METRIC", "confidence": 0.9892269372940063}]}, {"text": "Our model ranks 24/43 for binary classification and 5/31 for multiclass classification.", "labels": [], "entities": [{"text": "multiclass classification", "start_pos": 61, "end_pos": 86, "type": "TASK", "confidence": 0.6686015427112579}]}, {"text": "We make our model easily accessible to the research community 1 .", "labels": [], "entities": []}], "introductionContent": [{"text": "Recently, irony detection has become an increasingly important problem with new applications appearing everyday.", "labels": [], "entities": [{"text": "irony detection", "start_pos": 10, "end_pos": 25, "type": "TASK", "confidence": 0.9770972728729248}]}, {"text": "In discourse analysis, it is extremely important to understand if a politician is making an ironic or a literal response, or understanding can be completely lost.", "labels": [], "entities": [{"text": "discourse analysis", "start_pos": 3, "end_pos": 21, "type": "TASK", "confidence": 0.7306917309761047}]}, {"text": "In chatbots, if a chatbot misinterprets an unhappy sarcastic comment from a customer, the customer could become even more frustrated.", "labels": [], "entities": []}, {"text": "In sentiment analysis, if irony is not taken into account, the actual sentiment could be the opposite of the prediction.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 3, "end_pos": 21, "type": "TASK", "confidence": 0.93317711353302}]}, {"text": "The aim of irony detection is generally a binary classfication problem: Is the piece of text ironic or literal?", "labels": [], "entities": [{"text": "irony detection", "start_pos": 11, "end_pos": 26, "type": "TASK", "confidence": 0.9523568749427795}]}, {"text": "In SemEval2018 Task 3 (Van Hee et al., 2018), there are two subtasks.", "labels": [], "entities": [{"text": "SemEval2018 Task 3 (Van Hee et al., 2018)", "start_pos": 3, "end_pos": 44, "type": "TASK", "confidence": 0.7186352989890359}]}, {"text": "First, subtask A, is our standard binary classification problem.", "labels": [], "entities": []}, {"text": "We are provided with a corpus of tweets annotated with 0 or 1's to specify if a tweet is ironic or literal.", "labels": [], "entities": []}, {"text": "Second, in subtask B, we are tasked with a more challenging problem.", "labels": [], "entities": []}, {"text": "In subtask B, participants must determine which type of irony a particular tweet contains.", "labels": [], "entities": []}, {"text": "Is it verbal irony based on polarity, another type of verbal irony, situational irony or not ironic at all?", "labels": [], "entities": []}, {"text": "Recently, research has shown that neural approaches are particularly effective in sarcasm detection ( and similar problems such as sentiment analysis.", "labels": [], "entities": [{"text": "sarcasm detection", "start_pos": 82, "end_pos": 99, "type": "TASK", "confidence": 0.9550396800041199}, {"text": "sentiment analysis", "start_pos": 131, "end_pos": 149, "type": "TASK", "confidence": 0.9535156786441803}]}, {"text": "In this paper, we present neural network model designed to tackle the challenge of irony detection.", "labels": [], "entities": [{"text": "irony detection", "start_pos": 83, "end_pos": 98, "type": "TASK", "confidence": 0.9314347505569458}]}, {"text": "In subsection 2.1, we give a brief overview of the entire model.", "labels": [], "entities": []}, {"text": "In subsection 2.2 and 2.3, we describe our neural architecture and approach.", "labels": [], "entities": []}, {"text": "In subsection 2.5 and 2.6, we describe the embeddings and sentiment scores that are used as the input to our neural network.", "labels": [], "entities": []}, {"text": "In section 3, we describe our results, and give quantitative evidence of the effectiveness of our features.", "labels": [], "entities": []}, {"text": "In section 4 we conclude, and in section 5, we describe ways that our approach could be improved.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 2: Accuracy and F1 scores of various models  tested on a 75%-25% split of the training data.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9991042017936707}, {"text": "F1", "start_pos": 23, "end_pos": 25, "type": "METRIC", "confidence": 0.9993219375610352}]}]}