{"title": [{"text": "YNU-HPCC at SemEval-2018 Task 1: BiLSTM with Attention Based Sentiment Analysis for Affect in Tweets", "labels": [], "entities": []}], "abstractContent": [{"text": "This paper describes the system we built as the YNU-HPCC team in the SemEval-2018 competition.", "labels": [], "entities": [{"text": "YNU-HPCC team", "start_pos": 48, "end_pos": 61, "type": "DATASET", "confidence": 0.8768947124481201}, {"text": "SemEval-2018 competition", "start_pos": 69, "end_pos": 93, "type": "TASK", "confidence": 0.5496541857719421}]}, {"text": "As participants of Task 1, named Affect in Tweets, we implemented the sentiment system for all five subtasks in English and Spanish.", "labels": [], "entities": []}, {"text": "All subtasks involved predicting emotion or sentiment intensity (regression and ordinal classification) and determining emotions (multi-label classification).", "labels": [], "entities": [{"text": "predicting emotion or sentiment intensity", "start_pos": 22, "end_pos": 63, "type": "TASK", "confidence": 0.8144385337829589}]}, {"text": "Our system mainly applied the bidirectional long-short term memory (BiLSTM) model with an attention mechanism.", "labels": [], "entities": []}, {"text": "We used BiLSTM in order to extract word information from both directions.", "labels": [], "entities": []}, {"text": "The attention mechanism was used to find the contribution of each word to improving the scores.", "labels": [], "entities": []}, {"text": "Furthermore, based on the BiLSTM with an attention mechanism, a few deep-learning algorithms were employed for different subtasks.", "labels": [], "entities": []}, {"text": "For regression and ordinal classification tasks, we used domain adaptation and ensemble learning methods to leverage the base model, while a single base model was used for the multi-label task.", "labels": [], "entities": [{"text": "domain adaptation", "start_pos": 57, "end_pos": 74, "type": "TASK", "confidence": 0.7093369513750076}]}, {"text": "Our system achieved very competitive results on the official leaderboard.", "labels": [], "entities": []}], "introductionContent": [{"text": "Sentiment analysis is an area of natural language processing (NLP), which aims to systematically identify and study affective state, and to quantify subjective sentiment expressed in texts.", "labels": [], "entities": [{"text": "Sentiment analysis", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.9125919044017792}, {"text": "natural language processing (NLP)", "start_pos": 33, "end_pos": 66, "type": "TASK", "confidence": 0.8161676327387491}]}, {"text": "Tweets in Twitter always constitute a challenging task among NLP problems because of the colorful writing styles used.", "labels": [], "entities": []}, {"text": "In previous work on sentiment analysis tasks, researchers usually used a variety of hand-crafted features and sentiment lexicons to generate the solution system by combining traditional methods such as naive Bayes, support vector machines (SVMs) (, and decision trees.", "labels": [], "entities": [{"text": "sentiment analysis tasks", "start_pos": 20, "end_pos": 44, "type": "TASK", "confidence": 0.9357636570930481}]}, {"text": "Recently, many ensemble learning models based on these traditional methods () have attracted the interest of researcher and have shown good results.", "labels": [], "entities": []}, {"text": "These approaches require long-term studies to gather information from massive or unstructured datasets, and often result in redundant or missing features.", "labels": [], "entities": []}, {"text": "In contrast, the novel deep learning method) has immediately and shown exceptionally good results in NLP.", "labels": [], "entities": []}, {"text": "In this paper, we primarily present a deep learning system for the SemEval-2018 shared Task 1: Affect in Tweets.", "labels": [], "entities": [{"text": "SemEval-2018 shared Task 1: Affect in Tweets", "start_pos": 67, "end_pos": 111, "type": "TASK", "confidence": 0.6167132928967476}]}, {"text": "We employ the bidirectional long short-term memory with an attention mechanism (BiLSTM AT T ) as abase model.", "labels": [], "entities": [{"text": "BiLSTM AT T )", "start_pos": 80, "end_pos": 93, "type": "METRIC", "confidence": 0.9387794435024261}]}, {"text": "For the regression and ordinal classification tasks, we used fine-tuning methods on the base model, combined with multi-tasking and AdaBoost algorithm.", "labels": [], "entities": [{"text": "ordinal classification", "start_pos": 23, "end_pos": 45, "type": "TASK", "confidence": 0.7257112860679626}]}, {"text": "We use a simple BiLSTM with an attention mechanism for the multi-label task.", "labels": [], "entities": []}, {"text": "Our contributions are as follows: \u2022 We propose abase model combining the BiL-STM with an attention mechanism for the sentiment analysis problem.", "labels": [], "entities": [{"text": "sentiment analysis problem", "start_pos": 117, "end_pos": 143, "type": "TASK", "confidence": 0.9465133349100748}]}, {"text": "\u2022 Using the base model, a domain adaptation method of fine-tuning combined with multitasking is used for associated tasks.", "labels": [], "entities": []}, {"text": "\u2022 An ensemble learning method using the AdaBoost algorithm implemented on the base model is of great use for performing the task with unevenly distributed data.", "labels": [], "entities": []}, {"text": "The remainder of this paper is organized as follows.", "labels": [], "entities": []}, {"text": "In Section 2, we describe an overview of our system.", "labels": [], "entities": []}, {"text": "The details of the model are presented in Section 3.", "labels": [], "entities": []}, {"text": "Finally, comparative results of the experiments are discussed, and a conclusion is drawn in Sections 4 and 5, respectively.", "labels": [], "entities": []}], "datasetContent": [{"text": "The datasets we used were all provided by the competition, with no other external corpus.", "labels": [], "entities": []}, {"text": "Except for subtasks EI-reg and EI-oc, which had four sub-datasets, subtasks had only one dataset each for English and Spanish.", "labels": [], "entities": []}, {"text": "We thank Mohammad and) for contributions to the data.", "labels": [], "entities": []}, {"text": "For regression and ordinal tasks (including task EI-reg, EI-oc, V-reg, and Voc), the official competition metric was the value (p) of the Pearson Correction Coefficient.", "labels": [], "entities": []}, {"text": "Moreover, tasks EI-oc and V-oc have a second metric, the quadratic weighted kappa (k).", "labels": [], "entities": []}, {"text": "For the multilabel task (task E-c), apart from the official competition metric (multi-label accuracy, a), a microaveraged F-score (f 1 micro ) and a macro-averaged F-score (f 1 macro ) were also calculated for our submissions.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 92, "end_pos": 100, "type": "METRIC", "confidence": 0.6620530486106873}, {"text": "F-score", "start_pos": 122, "end_pos": 129, "type": "METRIC", "confidence": 0.6635277271270752}, {"text": "F-score", "start_pos": 164, "end_pos": 171, "type": "METRIC", "confidence": 0.917989194393158}]}, {"text": "On the competition leaderboard, our system placed 22/48 (9/24) for English (Spanish) in task EI-reg, 12/39 (8/16) in task EI-oc, 27/38 (7/14) in task V-reg, 14/31 (6/14) in task V-oc and 7/35 (6/14) in task E-c.", "labels": [], "entities": []}, {"text": "We trained our models on the training set and evaluated the prediction with the golden scores of the development set.", "labels": [], "entities": []}, {"text": "In order to illustrate the good performance of our methods, we compare the results with baseline models of CNN, LSTM, CNN-LSTM () and a regular BiLSTM.", "labels": [], "entities": [{"text": "CNN", "start_pos": 107, "end_pos": 110, "type": "DATASET", "confidence": 0.8974082469940186}, {"text": "CNN-LSTM", "start_pos": 118, "end_pos": 126, "type": "DATASET", "confidence": 0.9090084433555603}]}, {"text": "From the results shown in, we can see that our approach achieved a significant result.", "labels": [], "entities": []}, {"text": "A regular L-STM tends to ignore future contextual information while processing sequences in a time series.", "labels": [], "entities": []}, {"text": "The BiLSTM is able to use both past and future contexts by processing the text from both directions.", "labels": [], "entities": [{"text": "BiLSTM", "start_pos": 4, "end_pos": 10, "type": "DATASET", "confidence": 0.8566029071807861}]}, {"text": "Not all words make the same contribution to sentiment analysis in the text.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 44, "end_pos": 62, "type": "TASK", "confidence": 0.9590166211128235}]}, {"text": "The attention mechanism is able to shuffle the word annotation weights according to their importance to the meaning of sentence.", "labels": [], "entities": []}, {"text": "We can see that the attention based BiLST-M obtained higher scores than the BiLSTM without the attention mechanism.", "labels": [], "entities": []}, {"text": "Moreover, the SIM and the EIM showed their best performance on subtasks V-reg and EI-reg, respectively.", "labels": [], "entities": [{"text": "EIM", "start_pos": 26, "end_pos": 29, "type": "DATASET", "confidence": 0.8754703402519226}]}, {"text": "SIM employed the AdaBoost algorithm so as to integrate 30 the models of BiLSTM AT T . The SIM was able to adapt to the training error rate of each learner, so that the whole system was improved effectively.", "labels": [], "entities": [{"text": "SIM", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.9168305397033691}, {"text": "BiLSTM AT T", "start_pos": 72, "end_pos": 83, "type": "DATASET", "confidence": 0.7733936309814453}]}, {"text": "The EIM fine-tuned the parameters for the multitask approach, which made full use of associated sub-datasets of the task EI-reg.", "labels": [], "entities": []}, {"text": "Before training the target dataset, the special parameter initialization gave the target model additional knowledge from the other source datasets.", "labels": [], "entities": []}, {"text": "In addition, for the same training tweets that were used in task EI-reg (or V-reg) and EI-oc (or V-oc), we defined the thresh-old for translating from real-value score to ordinal classes by referring to the training labels across the training dataset.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Comparable results of experiments for subtask EI-reg and V-reg.", "labels": [], "entities": []}]}