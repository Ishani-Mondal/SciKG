{"title": [{"text": "KNU CI System at SemEval-2018 Task4: Character Identification by Solving Sequence-Labeling Problem", "labels": [], "entities": [{"text": "KNU CI System at SemEval-2018 Task4", "start_pos": 0, "end_pos": 35, "type": "DATASET", "confidence": 0.6666091084480286}, {"text": "Character Identification", "start_pos": 37, "end_pos": 61, "type": "TASK", "confidence": 0.8129919171333313}]}], "abstractContent": [{"text": "Character identification is an entity-linking task that finds words referring to the same person among the nouns mentioned in a conversation and turns them into one entity.", "labels": [], "entities": [{"text": "Character identification", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.833155483007431}]}, {"text": "In this paper, we define a sequence-labeling problem to solve character identification, and propose an attention-based recurrent neural network (RNN) encoder-decoder model.", "labels": [], "entities": [{"text": "character identification", "start_pos": 62, "end_pos": 86, "type": "TASK", "confidence": 0.9048668742179871}]}, {"text": "The input document for character identification on multiparty dialogues consists of several conversations, which increase the length of the input sequence.", "labels": [], "entities": [{"text": "character identification", "start_pos": 23, "end_pos": 47, "type": "TASK", "confidence": 0.8591256737709045}]}, {"text": "The RNN encoder-decoder model suffers from poor performance when the length of the input sequence is long.", "labels": [], "entities": []}, {"text": "To solve this problem, we propose applying position encoding and the self-matching network to the RNN en-coder-decoder model.", "labels": [], "entities": [{"text": "position encoding", "start_pos": 43, "end_pos": 60, "type": "TASK", "confidence": 0.74934121966362}]}, {"text": "Our experimental results demonstrate that of the four models proposed, Model 2 showed an F1 score of 86.00% and a label accuracy of 85.10% at the scene-level.", "labels": [], "entities": [{"text": "F1 score", "start_pos": 89, "end_pos": 97, "type": "METRIC", "confidence": 0.9884648323059082}, {"text": "accuracy", "start_pos": 120, "end_pos": 128, "type": "METRIC", "confidence": 0.6861457824707031}]}], "introductionContent": [{"text": "In this paper, we define character identification (CI)) as a sequence-labeling problem and use a recurrent neural network (RNN) encoder-decoder (Enc-Dec) model () based on the attention mechanism () to solve it.", "labels": [], "entities": [{"text": "character identification (CI))", "start_pos": 25, "end_pos": 55, "type": "TASK", "confidence": 0.849218237400055}]}, {"text": "An Enc-Dec is an extension of the RNN model; it generates an encoding vector using an RNN in the encoder when an input sequence is given and performs decoding using the encoding vector.", "labels": [], "entities": []}, {"text": "The attention mechanism calculates the alignment score for the two sequences and performs the input sequence and weighted sum so that they can focus more on the position that affects the output result.", "labels": [], "entities": [{"text": "alignment score", "start_pos": 39, "end_pos": 54, "type": "METRIC", "confidence": 0.9338982999324799}]}, {"text": "The self-matching network () is used to calculate an attention weight for itself and a context vector by using a weighted sum, after which the weights of similar words in the RNN sequence can be applied to aid in coreference resolution.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 213, "end_pos": 235, "type": "TASK", "confidence": 0.9687777161598206}]}, {"text": "Position encoding (PE) () is a method of applying weights differently, according to the positions of words appearing in a sequence.", "labels": [], "entities": [{"text": "Position encoding (PE)", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.6786440670490265}]}, {"text": "Training and prediction are performed by multiplying a weight vector by a vector of positions to be identified in a given input sequence.", "labels": [], "entities": [{"text": "prediction", "start_pos": 13, "end_pos": 23, "type": "TASK", "confidence": 0.9505362510681152}]}, {"text": "In an Enc-Dec model, along input sequence results in performance degradation due to loss of information in the front portion of the input sequence when encoding is performed.", "labels": [], "entities": []}, {"text": "In this paper, we propose four models that apply PE, attention mechanism, and self-matching network to Enc-Dec models to solve the problem of performance degradation due to long input sequences.", "labels": [], "entities": [{"text": "PE", "start_pos": 49, "end_pos": 51, "type": "METRIC", "confidence": 0.9101090431213379}]}, {"text": "To summarize, the main contributions of this paper are as follows: 1.", "labels": [], "entities": []}, {"text": "In this paper, we define CI task as sequencelabeling problem, and perform training and prediction in end-to-end model.", "labels": [], "entities": []}, {"text": "2. We propose four models using Enc-Dec based on attention mechanism and achieve high performance.", "labels": [], "entities": []}, {"text": "state by encoding the input sequence, and the decoder generates an output sequence that maximizes P(\u00ed \u00b5\u00ed\u00b1\u00a6|\u00ed \u00b5\u00ed\u00b1\u00a5) using the hidden state of the decoder, which was generated until this time step, with the encoder hidden state.", "labels": [], "entities": []}, {"text": "The attention mechanism is a method of determining which part of the target class should be focused using the hidden state of the decoder and the hidden state of the encoder when performing decoding.", "labels": [], "entities": []}], "datasetContent": [{"text": "We evaluate the entity linking performance of the models using label accuracy and macro-F1 (, and the coreference resolution performance using CoNLL F1.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 69, "end_pos": 77, "type": "METRIC", "confidence": 0.7328872084617615}]}, {"text": "The word representation used in this paper is a data-set provided by LDC, which is learned by a neural network language model (, and is set to 50 dimensions.", "labels": [], "entities": []}, {"text": "The experiments were performed with cross validation.", "labels": [], "entities": []}, {"text": "The hyper parameters used in the experiment are as follows.", "labels": [], "entities": []}, {"text": "We used tanh for the encoder and decoder, and ReLU for the attention layer.", "labels": [], "entities": [{"text": "ReLU", "start_pos": 46, "end_pos": 50, "type": "METRIC", "confidence": 0.9825201630592346}]}, {"text": "The hidden layers had 150 dimension, and the dropout of all layers was set to 0.3.", "labels": [], "entities": [{"text": "dimension", "start_pos": 26, "end_pos": 35, "type": "METRIC", "confidence": 0.9672520756721497}]}, {"text": "The learning was done using RMSprop () and the learning rate was reduced by 50% for every 5 epochs without performance improvement starting at 0.1.", "labels": [], "entities": [{"text": "learning rate", "start_pos": 47, "end_pos": 60, "type": "METRIC", "confidence": 0.9857375025749207}]}, {"text": "The decoder attention functions of the models used in the experiments are all based on hard attention, and are compared with soft attention in. shows a comparison between the CI performances of the models on the trial set.", "labels": [], "entities": []}, {"text": "M 2' is a model in which PE proposed by is applied, and M 4' is a model in which soft attention is applied to M 4.", "labels": [], "entities": [{"text": "PE", "start_pos": 25, "end_pos": 27, "type": "METRIC", "confidence": 0.8170776963233948}]}, {"text": "At the episode-level, M 3 showed the best Main F1 performance (86.30%) and M 1 showed the best All F1 performance (23.33%).", "labels": [], "entities": [{"text": "Main F1 performance (86.30%)", "start_pos": 42, "end_pos": 70, "type": "METRIC", "confidence": 0.7727822164694468}, {"text": "All F1 performance", "start_pos": 95, "end_pos": 113, "type": "METRIC", "confidence": 0.8134622375170389}]}, {"text": "At the scene-level, M 4 showed the highest Main F1 performance (87.41%), and M 4 showed the highest All F1 performance (23.92%).", "labels": [], "entities": [{"text": "Main F1 performance", "start_pos": 43, "end_pos": 62, "type": "METRIC", "confidence": 0.841316302617391}, {"text": "All F1 performance", "start_pos": 100, "end_pos": 118, "type": "METRIC", "confidence": 0.8302757143974304}]}, {"text": "In the case of M 2 and M 2', we can see that the proposed PE method resulted in a better overall performance.", "labels": [], "entities": []}, {"text": "At the episode-level, M 4' showed a better Main F1 performance (1.83%) than M 4, whereas M 4 showed a better All F1 performance (by 2.67%).", "labels": [], "entities": [{"text": "Main F1 performance", "start_pos": 43, "end_pos": 62, "type": "METRIC", "confidence": 0.6903277238210043}, {"text": "All F1 performance", "start_pos": 109, "end_pos": 127, "type": "METRIC", "confidence": 0.7707985242207845}]}, {"text": "At the scene-level, M 4 showed a better Main F1 performance (by 1.18%) than M 4', whereas M 4'  showed a better All F1 performance (by 1.86%).", "labels": [], "entities": [{"text": "Main", "start_pos": 40, "end_pos": 44, "type": "DATASET", "confidence": 0.5621300935745239}, {"text": "F1", "start_pos": 45, "end_pos": 47, "type": "METRIC", "confidence": 0.5217799544334412}, {"text": "All F1 performance", "start_pos": 112, "end_pos": 130, "type": "METRIC", "confidence": 0.7017904917399088}]}, {"text": "Thus, it can be seen that the use of hard attention results in a better performance.", "labels": [], "entities": []}, {"text": "presents the experimental results of the test set (episode-and scene-level) for the method proposed in this paper, and the performance comparison with other competing models, namely AMORE UPF (Amore), Kampfpudding (Kamp.), and zuma.", "labels": [], "entities": [{"text": "AMORE UPF", "start_pos": 182, "end_pos": 191, "type": "METRIC", "confidence": 0.7619129121303558}]}, {"text": "In the Main + Other character evaluations at episode-level, M 2 showed the best performance among all models (F1 of 85.01%, Acc of 84.36%), whereas in the All character evaluations, M 3 showed the best F1 performance (17.02%) and M 2 showed the best Acc performance (68.42%).", "labels": [], "entities": [{"text": "F1", "start_pos": 110, "end_pos": 112, "type": "METRIC", "confidence": 0.9996381998062134}, {"text": "Acc", "start_pos": 124, "end_pos": 127, "type": "METRIC", "confidence": 0.9985938668251038}, {"text": "F1", "start_pos": 202, "end_pos": 204, "type": "METRIC", "confidence": 0.9986382126808167}, {"text": "Acc", "start_pos": 250, "end_pos": 253, "type": "METRIC", "confidence": 0.9990928173065186}]}, {"text": "At the scene-level, M 2 showed the best performance in both the Main + Other and the All character evaluation.", "labels": [], "entities": []}, {"text": "The proposed method showed a lower overall performance in the All character evaluation compared with other competing models, but showed a higher performance in the Main + Other character evaluations.", "labels": [], "entities": []}, {"text": "The reason for the lower performance in the All character evaluation is that the number of data points is smaller than that of the main characters.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Entity-linking results on the trial set (in %).  Main and All in column mean main and other char- acters, and all characters.", "labels": [], "entities": [{"text": "Main", "start_pos": 59, "end_pos": 63, "type": "METRIC", "confidence": 0.9889786839485168}]}, {"text": " Table 2: Entity-linking results on the evaluation set (in %). The F1 score is reported for each character. E/S:  episode/scene level. F1 is macro-average F1 score. Acc is character label accuracy.", "labels": [], "entities": [{"text": "F1 score", "start_pos": 67, "end_pos": 75, "type": "METRIC", "confidence": 0.985101580619812}, {"text": "E/S", "start_pos": 108, "end_pos": 111, "type": "METRIC", "confidence": 0.9232412775357565}, {"text": "F1", "start_pos": 135, "end_pos": 137, "type": "METRIC", "confidence": 0.9982499480247498}, {"text": "F1 score", "start_pos": 155, "end_pos": 163, "type": "METRIC", "confidence": 0.9442790150642395}, {"text": "Acc", "start_pos": 165, "end_pos": 168, "type": "METRIC", "confidence": 0.9980735778808594}, {"text": "accuracy", "start_pos": 188, "end_pos": 196, "type": "METRIC", "confidence": 0.9739475250244141}]}]}