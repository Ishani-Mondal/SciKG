{"title": [{"text": "LDR at SemEval-2018 Task 3: A Low Dimensional Text Representation for Irony Detection", "labels": [], "entities": [{"text": "Irony Detection", "start_pos": 70, "end_pos": 85, "type": "TASK", "confidence": 0.7086976319551468}]}], "abstractContent": [{"text": "In this paper we describe our participation in the SemEval-2018 task 3 Shared Task on Irony Detection.", "labels": [], "entities": [{"text": "SemEval-2018 task 3 Shared Task on Irony Detection", "start_pos": 51, "end_pos": 101, "type": "TASK", "confidence": 0.7195231653749943}]}, {"text": "We have approached the task with our low dimensionality representation method (LDR), which exploits low dimensional features extracted from text on the basis of the occurrence probability of the words depending on each class.", "labels": [], "entities": []}, {"text": "Our intuition is that words in ironic texts have different probability of occurrence than in non-ironic ones.", "labels": [], "entities": []}, {"text": "Our approach obtained acceptable results in both subtasks A and B.", "labels": [], "entities": []}, {"text": "We have performed an error analysis that shows the difference on correct and incorrect classified tweets.", "labels": [], "entities": []}], "introductionContent": [{"text": "With the existence of online social networks, a huge amount of information rapidly pervades, which attracting the attention of researchers to investigate the linguistic phenomenon that appears.", "labels": [], "entities": []}, {"text": "One of these complex phenomenon is irony, where the speaker uses words that mean the opposite of the literal meaning and what others really think, especially in order to be funny . Moreover, irony can be considered as a strategy intended to criticise or to praise.", "labels": [], "entities": []}, {"text": "The detection of irony recently is quite a hot research topic due to its importance for efficient sentiment analysis (.", "labels": [], "entities": [{"text": "detection of irony", "start_pos": 4, "end_pos": 22, "type": "TASK", "confidence": 0.9316094319025675}, {"text": "sentiment analysis", "start_pos": 98, "end_pos": 116, "type": "TASK", "confidence": 0.8798128068447113}]}, {"text": "Also, another figurative language device noticed recently is sarcasm, where the writer intend to offend someone rather than creating a humor situation.", "labels": [], "entities": []}, {"text": "In many research works, irony and sarcasm are often viewed as the same language device, or they considered irony as an umbrella term that covers also sarcasm (.", "labels": [], "entities": []}, {"text": "Several approaches have been proposed to detect irony, where most of them have turned the problem into a binary classification task using a set of features.", "labels": [], "entities": [{"text": "detect irony", "start_pos": 41, "end_pos": 53, "type": "TASK", "confidence": 0.8780811429023743}]}, {"text": "( proposed one of the first works on irony detection.", "labels": [], "entities": [{"text": "irony detection", "start_pos": 37, "end_pos": 52, "type": "TASK", "confidence": 0.9544003903865814}]}, {"text": "They worked on the identification of a set of patterns to identify ironic sentences.", "labels": [], "entities": [{"text": "identify ironic sentences", "start_pos": 58, "end_pos": 83, "type": "TASK", "confidence": 0.5004004140694936}]}, {"text": "The adopted features were the use of punctuation marks and emoticons.", "labels": [], "entities": []}, {"text": "( proposed a model that employed four types of conceptual features: signatures, unexpectedness, style and emotional scenarios.", "labels": [], "entities": []}, {"text": "() proposed a model using lexical features, such as frequency of rare and common terms, synonyms, adjectives, emoticons, punctuation marks, positive and negative terms.", "labels": [], "entities": []}, {"text": "Their results showed that the most important features are structure, frequency and synonyms for detecting irony in multiple datasets.", "labels": [], "entities": [{"text": "frequency", "start_pos": 69, "end_pos": 78, "type": "METRIC", "confidence": 0.9534614086151123}, {"text": "detecting irony", "start_pos": 96, "end_pos": 111, "type": "TASK", "confidence": 0.8257709443569183}]}, {"text": "() presented a model to detect irony using a vector composed of six main groups of features: surface features (such as punctuation marks), sentiment (positive and negative words), sentiment shifter (positive and negative words in the scope of an intensifier), shifter (presence a negation word or reporting speech verbs), opposition (sentiment opposition or contrast between a subjective and an objective proposition) and internal contextual (the presence of personal pronouns).", "labels": [], "entities": []}, {"text": "() also studied the effect of multiple features to distinguish ironic and non-ironic tweets messages.", "labels": [], "entities": []}, {"text": "The adopted features include quantifiers of sentence complexity, morphosyntactic and semantic ambiguity, polarity, unexpectedness, emotional activation, imagery, and pleasantness of words.", "labels": [], "entities": []}, {"text": "() presented away to approach verbal irony classification by exploits contextual features, specifically by combining noun phrases and sentiment extracted from comments using a dataset of comments collected from reddit site which is social news aggregation.", "labels": [], "entities": [{"text": "verbal irony classification", "start_pos": 30, "end_pos": 57, "type": "TASK", "confidence": 0.7994142174720764}]}, {"text": "Most of these features did well in detecting ironic sentences, wherein general they relied on different types of high level features that use lexical resources, sentiment analysis methods or common terms occurrence.", "labels": [], "entities": [{"text": "detecting ironic sentences", "start_pos": 35, "end_pos": 61, "type": "TASK", "confidence": 0.918563723564148}, {"text": "sentiment analysis", "start_pos": 161, "end_pos": 179, "type": "TASK", "confidence": 0.8708068430423737}]}, {"text": "Based on these previous works, we investigate the using of low dimensional features extracted from a given text.", "labels": [], "entities": []}, {"text": "LDR uses terms weights to represent the probability that each Twitter message belongs to a specific class (e.g. ironic vs. non-ironic).", "labels": [], "entities": [{"text": "LDR", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.8437461853027344}]}, {"text": "Our intuition is that words usage in ironic texts has different probability of occurrence than in non-ironic ones, and LDR is good at capturing these differences.", "labels": [], "entities": [{"text": "words usage in ironic texts", "start_pos": 22, "end_pos": 49, "type": "TASK", "confidence": 0.7583683788776397}]}, {"text": "LDR does not need external resources, hand-crafted features, and drastically reduces the dimensionality of the representation.", "labels": [], "entities": []}, {"text": "This allows the method to deal with big data problems.", "labels": [], "entities": []}, {"text": "In this paper, we present the participation of LDR in the SemEval-2018 task 3 on Irony Detection (Van Hee et al., 2018).", "labels": [], "entities": [{"text": "SemEval-2018 task 3", "start_pos": 58, "end_pos": 77, "type": "TASK", "confidence": 0.6398746371269226}, {"text": "Irony Detection", "start_pos": 81, "end_pos": 96, "type": "TASK", "confidence": 0.6962707489728928}]}, {"text": "The rest of the paper is structured as follows.", "labels": [], "entities": []}, {"text": "In Section 2, the LDR method is presented.", "labels": [], "entities": []}, {"text": "In Section 3, we discuss the results we have achieved in both tasks and further analyse the error in Section 4.", "labels": [], "entities": []}, {"text": "For example, to know whether the terms usage changes depending on ironic and non-ironic tweets.", "labels": [], "entities": []}, {"text": "Finally, we draw some conclusions in Section 5 together with future work proposals.", "labels": [], "entities": []}], "datasetContent": [{"text": "During the experiments, LDR was tested using different classifiers.", "labels": [], "entities": []}, {"text": "In the following sections we will illustrate the experiments that we carried out.", "labels": [], "entities": []}, {"text": "For the evaluation, we used both accuracy and macro-average F-score.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 33, "end_pos": 41, "type": "METRIC", "confidence": 0.9997782111167908}, {"text": "F-score", "start_pos": 60, "end_pos": 67, "type": "METRIC", "confidence": 0.9491840600967407}]}, {"text": "Moreover, the error anal-  ysis we did allowed us to further understand the behavior of LDR in irony detection.", "labels": [], "entities": [{"text": "irony detection", "start_pos": 95, "end_pos": 110, "type": "TASK", "confidence": 0.9413780868053436}]}], "tableCaptions": [{"text": " Table 2: Number of positive and negative tweets in  the used datasets -Task A.", "labels": [], "entities": []}, {"text": " Table 3: LDR classification results of Task A and  B using Accuracy and Macro average F-score.", "labels": [], "entities": [{"text": "LDR classification", "start_pos": 10, "end_pos": 28, "type": "TASK", "confidence": 0.7648731172084808}, {"text": "Accuracy", "start_pos": 60, "end_pos": 68, "type": "METRIC", "confidence": 0.9982484579086304}, {"text": "F-score", "start_pos": 87, "end_pos": 94, "type": "METRIC", "confidence": 0.5948365330696106}]}]}