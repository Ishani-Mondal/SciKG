{"title": [{"text": "EmojiIt at SemEval-2018 Task 2: An Effective Attention-Based Recurrent Neural Network Model for Emoji Prediction with Characters Gated Words", "labels": [], "entities": [{"text": "Emoji Prediction", "start_pos": 96, "end_pos": 112, "type": "TASK", "confidence": 0.7388008832931519}]}], "abstractContent": [{"text": "This paper presents our single model to Sub-task 1 of SemEval 2018 Task 2: Emoji Prediction in English.", "labels": [], "entities": [{"text": "SemEval 2018 Task 2", "start_pos": 54, "end_pos": 73, "type": "TASK", "confidence": 0.8455963432788849}, {"text": "Emoji Prediction", "start_pos": 75, "end_pos": 91, "type": "TASK", "confidence": 0.8021313846111298}]}, {"text": "In order to predict the emo-ji that maybe contained in a tweet, the basic model we use is an attention-based recurrent neural network which has achieved satisfactory performs in Natural Language processing.", "labels": [], "entities": []}, {"text": "Considering the text comes from social media, it contains many discrepant abbreviations and online terms, we also combine word-level and character-level word vector embedding to better handling the words not appear in the vocabulary.", "labels": [], "entities": []}, {"text": "Our single model 1 achieved 29.50% Macro F-score in test data and ranks 9 th among 48 teams.", "labels": [], "entities": [{"text": "F-score", "start_pos": 41, "end_pos": 48, "type": "METRIC", "confidence": 0.8906140923500061}]}], "introductionContent": [{"text": "SemEval-2018 shared task 2 () provides a platform for us to explore the relationship between text and emoji in Twitter.", "labels": [], "entities": []}, {"text": "The participants are expected to predict, given a tweet in English or Spanish, its most likely associated emoji.", "labels": [], "entities": []}, {"text": "As the number of frequently-used emojis up to 20, this is also a multi-category classification task.", "labels": [], "entities": [{"text": "multi-category classification task", "start_pos": 65, "end_pos": 99, "type": "TASK", "confidence": 0.7677417794863383}]}, {"text": "Overall, both the prediction of emoji and the multi-category classification have undoubtedly increased the difficulty of task 2.", "labels": [], "entities": [{"text": "difficulty", "start_pos": 107, "end_pos": 117, "type": "METRIC", "confidence": 0.9782756567001343}]}, {"text": "Before choosing a suitable model, we first analyze the data characteristics in detail.", "labels": [], "entities": []}, {"text": "For each emoji, we count the total number of all tweets words under this emoji and enumerate the top 10 meaningful words with the highest frequency.", "labels": [], "entities": []}, {"text": "And we can explore the following observations from the statistics: \u2022 In almost all emojis, the first three words that appear frequently include \"@user\" suggesting that Twitter is a highly interactive social networking site (all the person names unified as \"users\" during the data preprocessing).", "labels": [], "entities": []}, {"text": "Such a tweet should include an unwritten but important context information.", "labels": [], "entities": []}, {"text": "\u2022 Because people do not always have the same understanding of emojis, some words can evoke more than one emoji.", "labels": [], "entities": []}, {"text": "The greater the repetition of high-frequency words among different emojis, the harder it is to distinguish among these tweets.", "labels": [], "entities": []}, {"text": "\u2022 There are also some easily recognizable words.", "labels": [], "entities": []}, {"text": "They are just common words under a certain emoji, almost do not appear under others, such as \"lit\" and \"fire\" under ; \"photo\" under ; \"usa\", \"america\" and \"vote\" under ; \"beach\" and \"summer\" under . \u2022 When glancing over the data, we find that tweets have the following characteristics: a) Non-standard language, some discrepant shorthand or Internet jargon causes the model to get confused about the word; b) Misspelled words, although the human can easily realize the correct words, but if the model takes word-level as the processing unit, it cannot process them correctly.", "labels": [], "entities": []}, {"text": "All of these can affect the ability of text representation seriously.", "labels": [], "entities": [{"text": "text representation", "start_pos": 39, "end_pos": 58, "type": "TASK", "confidence": 0.8362000584602356}]}, {"text": "Taking all of these factors into consideration, we explore solutions form three perspectives: \u2022 The second observation indicates that traditional statistical-based model may not achieve good performance, so we decide to adopt a neural network.", "labels": [], "entities": []}, {"text": "\u2022 Considering that the importance of each word is different in one tweet although text is very short no more than 140 words, we introduce an attention mechanism to extract the key words in tweets.", "labels": [], "entities": []}, {"text": "\u2022 As the last observation can generate some tokens do not appear in the vocabulary (OOV), we utilizes both word-level and characterlevel word vector embedding.", "labels": [], "entities": []}, {"text": "Ina word, our single model is an attentionbased neural network with word-level and character-level sentence embedding.", "labels": [], "entities": []}], "datasetContent": [{"text": "SemEval-2018 provided 500k tweets in English and 100k in Spanish for task 2, while our model is only for English.", "labels": [], "entities": []}, {"text": "Dateset is split into trial, training and test sets.", "labels": [], "entities": []}, {"text": "However, it was unable to download all the training set because some tweets were deleted or not available due to modified authorization status, and we finally collected 471, 455 training tweets.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Experimental results on test data and result of rank 1 system", "labels": [], "entities": []}, {"text": " Table 2: Precision, Recall, F-measure and percentage  of occurrences in the test set of each emoji.", "labels": [], "entities": [{"text": "Precision", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9995288848876953}, {"text": "Recall", "start_pos": 21, "end_pos": 27, "type": "METRIC", "confidence": 0.9985567927360535}, {"text": "F-measure", "start_pos": 29, "end_pos": 38, "type": "METRIC", "confidence": 0.9987066984176636}]}]}