{"title": [{"text": "UG18 at SemEval-2018 Task 1: Generating Additional Training Data for Predicting Emotion Intensity in Spanish", "labels": [], "entities": [{"text": "UG18", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.8285069465637207}, {"text": "Predicting Emotion Intensity", "start_pos": 69, "end_pos": 97, "type": "TASK", "confidence": 0.8854330579439799}]}], "abstractContent": [{"text": "The present study describes our submission to SemEval 2018 Task 1: Affect in Tweets.", "labels": [], "entities": [{"text": "SemEval 2018 Task 1", "start_pos": 46, "end_pos": 65, "type": "TASK", "confidence": 0.8544797897338867}]}, {"text": "Our Spanish-only approach aimed to demonstrate that it is beneficial to automatically generate additional training data by (i) translating training data from other languages and (ii) applying a semi-supervised learning method.", "labels": [], "entities": []}, {"text": "We find strong support for both approaches, with those models outperforming our regular models in all subtasks.", "labels": [], "entities": []}, {"text": "However, creating a stepwise ensemble of different models as opposed to simply averaging did not result in an increase in performance.", "labels": [], "entities": []}, {"text": "We placed second (EI-Reg), second (EI-Oc), fourth (V-Reg) and fifth (V-Oc) in the four Spanish subtasks we participated in.", "labels": [], "entities": []}], "introductionContent": [{"text": "Understanding the emotions expressed in a text or message is of high relevance nowadays.", "labels": [], "entities": []}, {"text": "Companies are interested in this to get an understanding of the sentiment of their current customers regarding their products and the sentiment of their potential customers to attract new ones.", "labels": [], "entities": []}, {"text": "Moreover, changes in a product or a company may also affect the sentiment of a customer.", "labels": [], "entities": []}, {"text": "However, the intensity of an emotion is crucial in determining the urgency and importance of that sentiment.", "labels": [], "entities": []}, {"text": "If someone is only slightly happy about a product, is a customer willing to buy it again?", "labels": [], "entities": []}, {"text": "Conversely, if someone is very angry about customer service, his or her complaint might be given priority over somewhat milder complaints.", "labels": [], "entities": []}, {"text": "present four tasks 1 in which systems have to automatically determine the intensity of emotions (EI) or the intensity of the sentiment (Valence) of tweets in the languages English, Arabic, and Spanish.", "labels": [], "entities": [{"text": "intensity of emotions (EI)", "start_pos": 74, "end_pos": 100, "type": "METRIC", "confidence": 0.6747229794661204}, {"text": "Valence)", "start_pos": 136, "end_pos": 144, "type": "METRIC", "confidence": 0.9029754102230072}]}, {"text": "The goal is to either predict a continuous regression (reg) value or We did not participate in subtask 5 (E-c).", "labels": [], "entities": []}, {"text": "to do ordinal classification (oc) based on a number of predefined categories.", "labels": [], "entities": [{"text": "ordinal classification (oc)", "start_pos": 6, "end_pos": 33, "type": "TASK", "confidence": 0.7307569742202759}]}, {"text": "The EI tasks have separate training sets for four different emotions: anger, fear, joy and sadness.", "labels": [], "entities": []}, {"text": "Due to the large number of subtasks and the fact that this language does not have many resources readily available, we only focus on the Spanish subtasks.", "labels": [], "entities": []}, {"text": "Our work makes the following contributions: \u2022 We show that automatically translating English lexicons and English training data boosts performance; \u2022 We show that employing semi-supervised learning is beneficial; \u2022 We show that the stepwise creation of an ensemble model is not necessarily better method than simply averaging predictions.", "labels": [], "entities": []}, {"text": "Our submissions ranked second (EI-Reg), second (EI-Oc), fourth (V-Reg) and fifth (V-Oc), demonstrating that the proposed method is accurate in automatically determining the intensity of emotions and sentiment of Spanish tweets.", "labels": [], "entities": []}, {"text": "This paper will first focus on the datasets, the data generation procedure, and the techniques and tools used.", "labels": [], "entities": [{"text": "data generation", "start_pos": 49, "end_pos": 64, "type": "TASK", "confidence": 0.7377654314041138}]}, {"text": "Then we present the results in detail, after which we perform a small error analysis on the largest mistakes our model made.", "labels": [], "entities": []}, {"text": "We conclude with some possible ideas for future work.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 2: Parameter settings for the algorithms used. For feed-forward, we show the number of nodes per layer.  The Dense column for LSTM shows whether a dense layer was added after the LSTM layers (with half the number  of nodes as is shown in the Nodes column). The feed-forward networks always use a dropout of 0.001 after the  first layer.", "labels": [], "entities": []}, {"text": " Table 3: Statistics and parameter settings of the semi-supervised learning experiments.", "labels": [], "entities": []}, {"text": " Table 4: Models included in our final ensemble.", "labels": [], "entities": []}, {"text": " Table 5: Scores for each individual model per subtask. Best individual score per subtask is bolded.", "labels": [], "entities": []}, {"text": " Table 6: Results on the dev and test set for averaging  and stepwise ensembling the individual models. The  last column shows our official results.", "labels": [], "entities": []}, {"text": " Table 7: Error analysis for the EI-Reg-anger subtask, with English translations.", "labels": [], "entities": []}]}