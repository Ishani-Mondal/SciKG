{"title": [{"text": "SeerNet at SemEval-2018 Task 1: Domain Adaptation for Affect in Tweets", "labels": [], "entities": []}], "abstractContent": [{"text": "The paper describes the best performing system for the SemEval-2018 Affect in Tweets (English) sub-tasks.", "labels": [], "entities": [{"text": "SemEval-2018 Affect in Tweets (English) sub-tasks", "start_pos": 55, "end_pos": 104, "type": "TASK", "confidence": 0.849351741373539}]}, {"text": "The system focuses on the ordinal classification and regression sub-tasks for valence and emotion.", "labels": [], "entities": [{"text": "ordinal classification", "start_pos": 26, "end_pos": 48, "type": "TASK", "confidence": 0.7324012517929077}]}, {"text": "For ordinal classification valence is classified into 7 different classes ranging from-3 to 3 whereas emotion is classified into 4 different classes 0 to 3 separately for each emotion namely anger, fear, joy and sadness.", "labels": [], "entities": []}, {"text": "The regression sub-tasks estimate the intensity of valence and each emotion.", "labels": [], "entities": []}, {"text": "The system performs domain adaptation of 4 different models and creates an ensemble to give the final prediction.", "labels": [], "entities": []}, {"text": "The proposed system achieved 1 st position out of 75 teams which participated in the fore-mentioned sub-tasks.", "labels": [], "entities": []}, {"text": "We outperform the baseline model by margins ranging from 49.2% to 76.4%, thus, pushing the state-of-the-art significantly.", "labels": [], "entities": []}], "introductionContent": [{"text": "Twitter is one of the most popular micro-blogging platforms that has attracted over 300M daily users 1 with over 500M 2 tweets sent everyday.", "labels": [], "entities": []}, {"text": "Tweet data has attracted NLP researchers because of the ease of access to large data-source of people expressing themselves online.", "labels": [], "entities": []}, {"text": "Tweets are micro-texts comprising of emoticons, hashtags as well as location data, making them feature rich for performing various kinds of analysis.", "labels": [], "entities": []}, {"text": "Tweets provide an interesting challenge as users tend to write grammatically incorrect and use informal and slang words.", "labels": [], "entities": []}, {"text": "In domain of natural language processing, emotion recognition is the task of associating words, phrases or documents with emotions from predefined using psychological models.", "labels": [], "entities": [{"text": "emotion recognition", "start_pos": 42, "end_pos": 61, "type": "TASK", "confidence": 0.7432532757520676}]}, {"text": "The classification of emotions has mainly been researched from two fundamental viewpoints. and proposed that emotions are discrete with each emotion being a distinct entity.", "labels": [], "entities": [{"text": "classification of emotions", "start_pos": 4, "end_pos": 30, "type": "TASK", "confidence": 0.8700024485588074}]}, {"text": "On the contrary, and propose that emotions can be categorized into dimensional groupings.", "labels": [], "entities": []}, {"text": "Affect in Tweets () -shared task in SemEval-2018 focuses on extracting affect from tweets confirming to both variants of the emotion models, extracting valence (dimensional) and emotion (discrete).", "labels": [], "entities": []}, {"text": "Previous version of the task) focused on estimating the emotion intensity in tweets.", "labels": [], "entities": []}, {"text": "We participated in 4 sub-tasks of Affect in Tweets, all dealing with English tweets.", "labels": [], "entities": []}, {"text": "The sub-tasks were: EI-oc: Ordinal classification of emotion intensity of 4 different emotions (anger, joy, sadness, fear), EI-reg: to determine the intensity of emotions (anger, joy, sadness, fear) into a real-valued scale of 0-1, V-oc: Ordinal classification of valence into one of 7 ordinal classes, V-reg: determine the intensity of valence on the scale of 0-1.", "labels": [], "entities": [{"text": "EI-oc", "start_pos": 20, "end_pos": 25, "type": "METRIC", "confidence": 0.90461665391922}, {"text": "EI-reg", "start_pos": 124, "end_pos": 130, "type": "METRIC", "confidence": 0.9079104065895081}]}, {"text": "Prior work in extracting Valence, Arousal, Dominance (VAD) from text primarily relied on using and extending lexicons).", "labels": [], "entities": [{"text": "extracting Valence, Arousal, Dominance (VAD) from text", "start_pos": 14, "end_pos": 68, "type": "TASK", "confidence": 0.719237660819834}]}, {"text": "Recent advancements in deep learning have been applied in detecting sentiments from tweets (), (,.", "labels": [], "entities": [{"text": "detecting sentiments from tweets", "start_pos": 58, "end_pos": 90, "type": "TASK", "confidence": 0.8465448766946793}]}, {"text": "In this work, we use various state-of-the-art machine learning models and perform domain adaptation (Pan and Yang, 2010) from their source task to the target task.", "labels": [], "entities": [{"text": "domain adaptation", "start_pos": 82, "end_pos": 99, "type": "TASK", "confidence": 0.7271634042263031}]}, {"text": "We use multi-view ensemble learning technique ( to produce the optimal feature-set partitioning for the classifier.", "labels": [], "entities": []}, {"text": "Finally, results from multiple such classifiers are stacked together to create an ensemble.", "labels": [], "entities": []}, {"text": "In this paper, we describe our approach and experiments to solve this problem.", "labels": [], "entities": []}, {"text": "The rest of the paper is laid out as follows: Section 2 describes the system architecture, Section 3 reports results and inference from different experiments.", "labels": [], "entities": []}, {"text": "Finally we conclude in Section 4 along with a discussion about future work.", "labels": [], "entities": []}, {"text": "2 System Description 2.1 Pipeline details the System Architecture.", "labels": [], "entities": []}, {"text": "We now describe how all the different modules are tied together.", "labels": [], "entities": []}, {"text": "The input raw tweet is pre-processed as described in Section 2.2.", "labels": [], "entities": []}, {"text": "The processed tweet is passed through all the feature extractors described in Section 2.3.", "labels": [], "entities": []}, {"text": "At the end of this step, we extract 5 different feature vectors corresponding to each tweet.", "labels": [], "entities": []}, {"text": "Each feature vector is passed through the model zoo where classifiers with different hyper parameters are tuned.", "labels": [], "entities": []}, {"text": "The models are described in Section 2.4.", "labels": [], "entities": []}, {"text": "For each vector, the results of top-2 performing models (based on cross-validation) are retained.", "labels": [], "entities": []}, {"text": "At the end of this step, we've 10 different results corresponding to each tweet.", "labels": [], "entities": []}, {"text": "All these results are ensembled together via stacking as described in Section 2.4.3.", "labels": [], "entities": []}, {"text": "Finally, the output from the ensembler is the output returned by the system.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Primary metrics across various sub-tasks.", "labels": [], "entities": []}, {"text": " Table 4: Pearson Correlation for V-reg task. Best re- sults are highlighted in bold.", "labels": [], "entities": [{"text": "Pearson Correlation", "start_pos": 10, "end_pos": 29, "type": "METRIC", "confidence": 0.7767587006092072}]}, {"text": " Table 5: Pearson Correlation for V-oc task. Best re- sults are highlighted in bold.", "labels": [], "entities": [{"text": "Pearson Correlation", "start_pos": 10, "end_pos": 29, "type": "METRIC", "confidence": 0.7780599892139435}]}, {"text": " Table 6: Macro-Averaged Pearson Correlation for EI- reg task. Best results are highlighted in bold.", "labels": [], "entities": [{"text": "Pearson Correlation", "start_pos": 25, "end_pos": 44, "type": "METRIC", "confidence": 0.9132872223854065}]}, {"text": " Table 7: Macro-Averaged Pearson Correlation for EI- oc task. Best results are highlighted in bold.", "labels": [], "entities": [{"text": "Pearson Correlation", "start_pos": 25, "end_pos": 44, "type": "METRIC", "confidence": 0.9179789423942566}]}]}