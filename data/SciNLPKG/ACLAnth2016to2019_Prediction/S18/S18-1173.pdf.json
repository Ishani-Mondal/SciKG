{"title": [{"text": "YNU AI1799 at SemEval-2018 Task 11: Machine Comprehension using Commonsense Knowledge of Different model ensemble", "labels": [], "entities": [{"text": "YNU AI1799", "start_pos": 0, "end_pos": 10, "type": "DATASET", "confidence": 0.8146439492702484}, {"text": "SemEval-2018 Task 11", "start_pos": 14, "end_pos": 34, "type": "TASK", "confidence": 0.550502081712087}]}], "abstractContent": [{"text": "In this paper, we describe a machine reading comprehension system that participated in SemEval-2018 Task 11: Machine Comprehension using commonsense knowledge.", "labels": [], "entities": [{"text": "SemEval-2018 Task 11", "start_pos": 87, "end_pos": 107, "type": "TASK", "confidence": 0.8549180626869202}]}, {"text": "In this work, we train a series of neural network models such as multi-LSTM, BiLSTM, multi-BiLSTM-CNN and attention-based BiLSTM, etc.", "labels": [], "entities": []}, {"text": "On top of some sub models, there are two kinds of word embedding: (a) general word embedding generated from unsupervised neu-ral language model; and (b) position embedding generated from general word embedding.", "labels": [], "entities": []}, {"text": "Finally, we make a hard vote on the predictions of these models and achieve relatively good result.", "labels": [], "entities": []}, {"text": "The proposed approach achieves 8th place in Task 11 with the accuracy of 0.7213.", "labels": [], "entities": [{"text": "8th place", "start_pos": 31, "end_pos": 40, "type": "METRIC", "confidence": 0.9454255700111389}, {"text": "accuracy", "start_pos": 61, "end_pos": 69, "type": "METRIC", "confidence": 0.9996957778930664}]}], "introductionContent": [{"text": "Machine Comprehension using Commonsense Knowledge is a well-researched problem in NLP.", "labels": [], "entities": [{"text": "Machine Comprehension", "start_pos": 0, "end_pos": 21, "type": "TASK", "confidence": 0.815278947353363}]}, {"text": "In order to simplify the task of the process, we turn this task into text classification work and use a deep learning neural network to fulfill it.", "labels": [], "entities": [{"text": "text classification", "start_pos": 69, "end_pos": 88, "type": "TASK", "confidence": 0.8219230473041534}]}, {"text": "The method of deep learning models used in text analysis has achieved numerous notable advances in recently years (e.g.,, and).", "labels": [], "entities": [{"text": "text analysis", "start_pos": 43, "end_pos": 56, "type": "TASK", "confidence": 0.8736496269702911}]}, {"text": "However, inmost previous works, the tasks are to apply a single model to a particular data set task.", "labels": [], "entities": []}, {"text": "The single model is a vertical stack of multiple hidden layers, which is not good for text analysis and processing.", "labels": [], "entities": [{"text": "text analysis", "start_pos": 86, "end_pos": 99, "type": "TASK", "confidence": 0.8437843918800354}]}, {"text": "The first drawback is the need to consume more hardware resources, followed by over-fitting and loss of feature information.", "labels": [], "entities": []}, {"text": "So the task here is to apply different structure sub models to the same train-set.", "labels": [], "entities": []}, {"text": "We train many classic sub models with one layer on top of word embedding, like LSTM, CNN, Attention,Attention+BiLSTM, multi-BiLSTM+CNN and some other models which are slightly different from the above models with different activation functions and different layers inside the model.", "labels": [], "entities": []}, {"text": "In each single model, we use a flag to determine which embedding tool is used or not.", "labels": [], "entities": []}, {"text": "Most of the deep learning involve word vectors represented by neural language models) , (Yih et al., 2011) and ().", "labels": [], "entities": []}, {"text": "Using the learned word vectors for classification task will naturally increase the effect.", "labels": [], "entities": [{"text": "classification task", "start_pos": 35, "end_pos": 54, "type": "TASK", "confidence": 0.88623046875}]}, {"text": "Word vectors are expressed as a hidden-layer word vector of the specified dimension (1-of-V, here V is the vocabulary size), the training methods can be found here 1 . In our system, we introduce different word vectors: 100 billion words of Google News, Glove vectors of 100 dimensions and word vectors self-trained on the basis of official task data.", "labels": [], "entities": []}, {"text": "Finally, a hard vote(the majority voting from result document) is made on the results of those different models.", "labels": [], "entities": []}, {"text": "Many tasks often suffer from insufficient training data.", "labels": [], "entities": []}, {"text": "In this work, we parse external data from CodaLab introduction data, including DeScript(?) data, RKP() data and OMCS) data to trained embedding.", "labels": [], "entities": []}], "datasetContent": [{"text": "In order to optimize our network, we use () optimizer on training model.", "labels": [], "entities": []}, {"text": "All our experiments have been developed using an open source software library of Tensorflow with CUDA enabled, and run on a computer with Intel Core(TM) i3 CPU 760 @2.8GHz, 8GB of RAM and GeForce GTX960 GPU.", "labels": [], "entities": []}, {"text": "Due to the lack of hardware capacity, we do not run the entire system in onetime.", "labels": [], "entities": []}, {"text": "Instead, we run single model each time with different word embeddings.", "labels": [], "entities": []}, {"text": "When we use the word embedding of Google News 300d on some sub models, the system gives memory exhausted, and we switch to a smaller glove 27B 100d to run successfully.", "labels": [], "entities": [{"text": "Google News 300d", "start_pos": 34, "end_pos": 50, "type": "DATASET", "confidence": 0.8810987075169882}, {"text": "memory", "start_pos": 88, "end_pos": 94, "type": "METRIC", "confidence": 0.9683511257171631}]}, {"text": "Table 2 shows our results for various models.", "labels": [], "entities": []}, {"text": "As it can be seen from the table, ensemble results from the more different models get better results when other conditions are similar.", "labels": [], "entities": []}, {"text": "Here we ensemble these models: RNN, GRU, BiLSTM, multiBiLSTM+CNN and Attention+BiLSTM, based on their high accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 107, "end_pos": 115, "type": "METRIC", "confidence": 0.9978596568107605}]}, {"text": "The dropout probability is 0.6 in each model, and the initial learning rate is 0.01.", "labels": [], "entities": [{"text": "initial learning rate", "start_pos": 54, "end_pos": 75, "type": "METRIC", "confidence": 0.7644307613372803}]}], "tableCaptions": [{"text": " Table 2: Result for various models on task data set.", "labels": [], "entities": []}]}