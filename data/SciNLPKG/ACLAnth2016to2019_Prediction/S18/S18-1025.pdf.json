{"title": [{"text": "DL Team at SemEval-2018 Task 1: Tweet Affect Detection using Sentiment Lexicons and Embeddings", "labels": [], "entities": [{"text": "Tweet Affect Detection", "start_pos": 32, "end_pos": 54, "type": "TASK", "confidence": 0.8979237079620361}]}], "abstractContent": [{"text": "The paper describes our approach for SemEval-2018 Task 1: Affect Detection in Tweets.", "labels": [], "entities": [{"text": "SemEval-2018 Task 1", "start_pos": 37, "end_pos": 56, "type": "TASK", "confidence": 0.9010864098866781}, {"text": "Affect Detection in Tweets", "start_pos": 58, "end_pos": 84, "type": "TASK", "confidence": 0.7521810159087181}]}, {"text": "We perform experiments with manually compelled sentiment lexicons and word embeddings.", "labels": [], "entities": []}, {"text": "We test their performance on twitter affect detection task to determine which features produce the most informative representation of a sentence.", "labels": [], "entities": [{"text": "twitter affect detection task", "start_pos": 29, "end_pos": 58, "type": "TASK", "confidence": 0.6684512794017792}]}, {"text": "We demonstrate that general-purpose word embeddings produces more informative sentence representation than lexicon features.", "labels": [], "entities": [{"text": "informative sentence representation", "start_pos": 66, "end_pos": 101, "type": "TASK", "confidence": 0.6794000466664633}]}, {"text": "However, combining lexicon features with embeddings yields higher performance than embeddings alone.", "labels": [], "entities": []}], "introductionContent": [{"text": "The paper describes our approach for SemEval-2018 Task 1: Affect Detection in Tweets.", "labels": [], "entities": [{"text": "SemEval-2018 Task 1", "start_pos": 37, "end_pos": 56, "type": "TASK", "confidence": 0.9010864496231079}, {"text": "Affect Detection in Tweets", "start_pos": 58, "end_pos": 84, "type": "TASK", "confidence": 0.7521810159087181}]}, {"text": "The research question we address in this paper is what are the best features for tweet affect detection.", "labels": [], "entities": [{"text": "tweet affect detection", "start_pos": 81, "end_pos": 103, "type": "TASK", "confidence": 0.8413917819658915}]}, {"text": "Our solution uses two types of features: lexicon features obtained from manually compiled emotion lexicons, and word embeddings built unsupervisedly from large corpora.", "labels": [], "entities": []}, {"text": "We use well established lexicons, namely DepecheMood and Vader Sentiment, and most popular Word embeddings, namely GloVe and Google News.", "labels": [], "entities": []}, {"text": "We systematically compare all features on two subtasks and demonstrate that even though lexicon features produce unsatisfactory results in isolation, they significantly improve an algorithm performance when combined with more general embeddings.", "labels": [], "entities": []}, {"text": "In addition, we demonstrate that special treatment of Twitter hash-tags also improves the algorithm performance.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Training, development and test set split for  three subtasks", "labels": [], "entities": []}, {"text": " Table 2: Experimental results for on development set for two subtasks. Pearson correlation. Gradient Boosting  Regressor is used for the EI-reg subtask. Gradient Boosting Regressor (Boost) and Random Forest (RF) is used  for V-reg. # means that hash-tags are used separately as additional features.", "labels": [], "entities": [{"text": "Pearson correlation", "start_pos": 72, "end_pos": 91, "type": "METRIC", "confidence": 0.919139176607132}]}, {"text": " Table 3: Data coverage for various feature sets, percent of word usages. Legend: # -coverage of hash tags, - coverage of all other words.", "labels": [], "entities": []}, {"text": " Table 4: Feature sets and their dimensionality.", "labels": [], "entities": []}, {"text": " Table 5: Official results for EI-reg (emotion intensity  regression) and V-reg (valence intensity regression).  Scores are given in the format X / Y , where X is our  result, and Y is the best official result on the task. Pear- son correlation.", "labels": [], "entities": [{"text": "EI-reg", "start_pos": 31, "end_pos": 37, "type": "METRIC", "confidence": 0.8490188717842102}, {"text": "Pear- son correlation", "start_pos": 223, "end_pos": 244, "type": "METRIC", "confidence": 0.9112445414066315}]}]}