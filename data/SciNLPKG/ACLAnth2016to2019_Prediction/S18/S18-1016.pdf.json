{"title": [{"text": "LT3 at SemEval-2018 Task 1: A classifier chain to detect emotions in tweets", "labels": [], "entities": []}], "abstractContent": [{"text": "This paper presents an emotion classification system for English tweets, submitted for the SemEval shared task on Affect in Tweets, sub-task 5: Detecting Emotions.", "labels": [], "entities": [{"text": "emotion classification", "start_pos": 23, "end_pos": 45, "type": "TASK", "confidence": 0.7556767463684082}]}, {"text": "The system combines lexicon, n-gram, style, syntactic and semantic features.", "labels": [], "entities": []}, {"text": "For this multi-class multi-label problem, we created a classifier chain.", "labels": [], "entities": []}, {"text": "This is an ensemble of eleven binary classi-fiers, one for each possible emotion category, where each model gets the predictions of the preceding models as additional features.", "labels": [], "entities": []}, {"text": "The predicted labels are combined to get a multi-label representation of the predictions.", "labels": [], "entities": []}, {"text": "Our system was ranked eleventh among thirty five participating teams, with a Jaccard accuracy of 52.0% and macro-and micro-average F1-scores of 49.3% and 64.0%, respectively.", "labels": [], "entities": [{"text": "Jaccard", "start_pos": 77, "end_pos": 84, "type": "METRIC", "confidence": 0.9615297913551331}, {"text": "accuracy", "start_pos": 85, "end_pos": 93, "type": "METRIC", "confidence": 0.7837310433387756}, {"text": "F1-scores", "start_pos": 131, "end_pos": 140, "type": "METRIC", "confidence": 0.877362072467804}]}], "introductionContent": [{"text": "Most research in the domain of sentiment analysis focuses on the automatic prediction of polarity or valence in text, but also the detection of emotions has attracted growing interest in the last couple of years ( . Although emotion detection is a rather new research focus in NLP, the study of emotions has along history in fields like psychology and neuroimaging.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 31, "end_pos": 49, "type": "TASK", "confidence": 0.8798820972442627}, {"text": "automatic prediction of polarity or valence in text", "start_pos": 65, "end_pos": 116, "type": "TASK", "confidence": 0.7680112645030022}, {"text": "emotion detection", "start_pos": 225, "end_pos": 242, "type": "TASK", "confidence": 0.7534622550010681}]}, {"text": "Many different frameworks exist, but the specific emotion approach, in which emotions are classified as specific discrete categories, predominates.", "labels": [], "entities": []}, {"text": "Ina lot of those approaches, some emotions are considered more basic than others, with Ekman's theory of six basic emotions (joy, sadness, anger, fear, disgust, and surprise) as the most well-known.", "labels": [], "entities": []}, {"text": "Another popular theory is Plutchik's wheel of emotions, in which joy, sadness, anger, fear, disgust, surprise, trust, and anticipation are considered most basic.", "labels": [], "entities": [{"text": "anticipation", "start_pos": 122, "end_pos": 134, "type": "METRIC", "confidence": 0.9730181097984314}]}, {"text": "Emotion analysis in NLP makes use of the frameworks developed by psychologists, mostly by employing categorical models of (basic) emotions.", "labels": [], "entities": [{"text": "Emotion analysis", "start_pos": 0, "end_pos": 16, "type": "TASK", "confidence": 0.9261420369148254}]}, {"text": "In traditional emotion classification tasks, a 'document' or sentence is classified under one or more emotion classes (or classified as neutral/no class when no emotions are present).", "labels": [], "entities": [{"text": "emotion classification tasks", "start_pos": 15, "end_pos": 43, "type": "TASK", "confidence": 0.808393120765686}]}, {"text": "Such emotion classification systems have been developed and tested on different kinds of data, including fairy tales (), newspaper headlines (, chat messages (e.g., and tweets (e.g. Mohammad, 2012;).", "labels": [], "entities": [{"text": "emotion classification", "start_pos": 5, "end_pos": 27, "type": "TASK", "confidence": 0.7352332770824432}]}, {"text": "The big advantage of using tweet datasets is the relative ease with which twitter data can be collected and the possibility of using hashtags as emotion labels (distant supervision approach).", "labels": [], "entities": []}, {"text": "For this paper, we used the data that was collected for the SemEval shared task on Affect in Tweets ( , a collection of tweets annotated for eleven emotions: anger, anticipation, disgust, fear, joy, love, optimism, pessimism, sadness, surprise, and trust . We participated in Subtask 5: Detecting Emotions (English emotion classification).", "labels": [], "entities": [{"text": "English emotion classification)", "start_pos": 307, "end_pos": 338, "type": "TASK", "confidence": 0.6918888539075851}]}, {"text": "The remainder of this paper is structured as follows: in Section 2 we describe how we first analyzed the data in order to get more insight in the task.", "labels": [], "entities": []}, {"text": "Section 3 discusses how the data was preprocessed and which information sources were extracted.", "labels": [], "entities": []}, {"text": "Next, in Section 4 the actual experimental setup and results are discussed and we end this paper with a conclusion in Section 5.", "labels": [], "entities": []}], "datasetContent": [{"text": "We trained different models on the training set and tested them on the development set, using scikitlearn   periments, we used an SVM classifier with linear kernel (LinearSVC) and used the lexicon features from the Weka Affective Tweets package.", "labels": [], "entities": [{"text": "Weka Affective Tweets package", "start_pos": 215, "end_pos": 244, "type": "DATASET", "confidence": 0.7880906760692596}]}, {"text": "The results for each binary classifier are shown in (second column).", "labels": [], "entities": []}, {"text": "Combining the predictions of these eleven binary classifiers resulted in a jaccard accuracy of 42.7%.", "labels": [], "entities": [{"text": "jaccard", "start_pos": 75, "end_pos": 82, "type": "METRIC", "confidence": 0.941779613494873}, {"text": "accuracy", "start_pos": 83, "end_pos": 91, "type": "METRIC", "confidence": 0.8360164165496826}]}, {"text": "Before optimizing the separate classifiers, we took a more detailed look at the lexicon features and the clusters to assess whether it is beneficial to use only apart of the lexicons (e.g. only the emotion lexicons) or whether it is better to use all lexicons (even polarity lexicons).", "labels": [], "entities": []}, {"text": "We found that the combination of all lexicons (including the valence-arousal-dominance lexicon of) gave the highest performance.", "labels": [], "entities": []}, {"text": "As regards the clusters, we tried all cluster types on each emotion category and picked the cluster that gave the highest performance on that particular category.", "labels": [], "entities": []}, {"text": "For every emotion category, we tested different classifiers on different combinations of features.", "labels": [], "entities": []}, {"text": "The classifiers we used, were SVM, SGD (linear SVM with stochastic gradient descent learning), Logistic Regression, and Random Forest.", "labels": [], "entities": []}, {"text": "shows the F1-scores (in bold) on the positive class for the best performing classifiers and feature combinations, which are significantly higher than the baseline results.", "labels": [], "entities": [{"text": "F1-scores", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9988030195236206}]}, {"text": "We joined the predictions of these optimized binary classifiers, and achieved a jaccard accuracy of 47.7%.", "labels": [], "entities": [{"text": "jaccard", "start_pos": 80, "end_pos": 87, "type": "METRIC", "confidence": 0.8399554491043091}, {"text": "accuracy", "start_pos": 88, "end_pos": 96, "type": "METRIC", "confidence": 0.7969216704368591}]}], "tableCaptions": [{"text": " Table 1: Phi coefficients for moderate or high negative  (left) and positive (right) correlations between emotion  pairs.", "labels": [], "entities": [{"text": "Phi", "start_pos": 10, "end_pos": 13, "type": "METRIC", "confidence": 0.9586246609687805}]}, {"text": " Table 2: IAA (Kappa) per emotion class based on 500  re-annotated instances.", "labels": [], "entities": [{"text": "IAA (Kappa)", "start_pos": 10, "end_pos": 21, "type": "METRIC", "confidence": 0.7565985172986984}]}, {"text": " Table 6: Jaccard accuracy, micro averaged F1-score  and macro averaged F1-score of the optimized model  on the development and held-out test set.", "labels": [], "entities": [{"text": "Jaccard", "start_pos": 10, "end_pos": 17, "type": "METRIC", "confidence": 0.769446611404419}, {"text": "accuracy", "start_pos": 18, "end_pos": 26, "type": "METRIC", "confidence": 0.8960275650024414}, {"text": "micro averaged", "start_pos": 28, "end_pos": 42, "type": "METRIC", "confidence": 0.9089002907276154}, {"text": "F1-score", "start_pos": 43, "end_pos": 51, "type": "METRIC", "confidence": 0.5505736470222473}, {"text": "F1-score", "start_pos": 72, "end_pos": 80, "type": "METRIC", "confidence": 0.7489187121391296}]}, {"text": " Table 7: Confusion matrices for the results on the held  out test set. P = predicted labels; G = gold labels.", "labels": [], "entities": []}]}