{"title": [{"text": "EPUTION at SemEval-2018 Task 2: Emoji Prediction with User Adaption", "labels": [], "entities": [{"text": "Emoji Prediction", "start_pos": 32, "end_pos": 48, "type": "TASK", "confidence": 0.7687707245349884}]}], "abstractContent": [{"text": "This paper describes our approach, called EPUTION, for the open trial of the SemEval-2018 Task 2, Multilingual Emoji Prediction.", "labels": [], "entities": [{"text": "EPUTION", "start_pos": 42, "end_pos": 49, "type": "METRIC", "confidence": 0.6310876607894897}, {"text": "SemEval-2018 Task 2", "start_pos": 77, "end_pos": 96, "type": "TASK", "confidence": 0.7789708971977234}, {"text": "Multilingual Emoji Prediction", "start_pos": 98, "end_pos": 127, "type": "TASK", "confidence": 0.5918515423933665}]}, {"text": "The task relates to using social media-more precisely, Twitter-with its aim to predict the most likely associated emoji of a tweet.", "labels": [], "entities": []}, {"text": "Our solution for this text classification problem explores the idea of transfer learning for adapting the classifier based on users' tweet-ing history.", "labels": [], "entities": [{"text": "text classification", "start_pos": 22, "end_pos": 41, "type": "TASK", "confidence": 0.7674170732498169}]}, {"text": "Our experiments show that our user-adaption method improves classification results by more than 6 percent on the macro-averaged F1.", "labels": [], "entities": [{"text": "classification", "start_pos": 60, "end_pos": 74, "type": "TASK", "confidence": 0.931071400642395}]}, {"text": "Thus, our paper provides evidence for the rationality of enriching the original corpus longitudinally with user behaviors and transferring the lessons learned from corresponding users to specific instances.", "labels": [], "entities": []}], "introductionContent": [{"text": "Twitter sentiment analysis is an essential problem for companies and organizations to computationally measure customers' perceptions which attracts attention from fields of both social media analytics and natural language processing.", "labels": [], "entities": [{"text": "Twitter sentiment analysis", "start_pos": 0, "end_pos": 26, "type": "TASK", "confidence": 0.7075468202431997}]}, {"text": "A Twitter message, called a tweet, is generally composed of text, emojis, links, and mentioned users, known as tweeters.", "labels": [], "entities": []}, {"text": "An emoji is a small picture or symbol of a standardized set to represent a feeling or another concept, contributing to the sentiment of its sender (.", "labels": [], "entities": []}, {"text": "Consequently, techniques for emoji classification are relevant and can be used to transfer information to subsequent tasks of sentiment, emotion, and sarcasm analysis (.", "labels": [], "entities": [{"text": "emoji classification", "start_pos": 29, "end_pos": 49, "type": "TASK", "confidence": 0.8966385126113892}, {"text": "sentiment, emotion, and sarcasm analysis", "start_pos": 126, "end_pos": 166, "type": "TASK", "confidence": 0.7586634968008313}]}, {"text": "The SemEval-2018 Task 2 challenges its participants to perform multilingual emoji prediction in English and Spanish.", "labels": [], "entities": [{"text": "emoji prediction", "start_pos": 76, "end_pos": 92, "type": "TASK", "confidence": 0.7537532448768616}]}, {"text": "The top-20 most frequent emojis of each language are annotated as tweets' class labels.", "labels": [], "entities": []}, {"text": "To encourage systems with better performance on less frequent emojis, the macroaveraged F 1 score (Macro-F)) is used as the official evaluation measure.", "labels": [], "entities": [{"text": "F 1 score (Macro-F))", "start_pos": 88, "end_pos": 108, "type": "METRIC", "confidence": 0.8979864219824473}]}, {"text": "Emoji prediction is widely formalized as a text classification problem in which the state-of-theart systems fail to perform satisfactory (.", "labels": [], "entities": [{"text": "Emoji prediction", "start_pos": 0, "end_pos": 16, "type": "TASK", "confidence": 0.8724509179592133}, {"text": "text classification", "start_pos": 43, "end_pos": 62, "type": "TASK", "confidence": 0.759862631559372}]}, {"text": "Because individual users enjoy diverse preferences in their emoji usage, it is hard to train a generalized classifier to tackle emoji prediction.", "labels": [], "entities": [{"text": "emoji prediction", "start_pos": 128, "end_pos": 144, "type": "TASK", "confidence": 0.8673937320709229}]}, {"text": "As demonstrated in, with two examples of simple tweets with various annotations from the training set, even with exactly the same tweet texts, different tweeters have various choices of emojis, such as i) a user can select one of the emojis express the same emotion and ii) a user can have different attitudes towards the same objects or topics.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section, we will describe our supplementary data collection process, model, and test settings.", "labels": [], "entities": []}, {"text": "With additional retrospective data from the users, our model achieves more than 6 percent better Macro-F than FastText.", "labels": [], "entities": []}, {"text": "Consequently, it outperforms leading results from this competition.", "labels": [], "entities": []}, {"text": "Both DA and IUA achieve higher performance on the retrieved part of test set, Test-R, and thus improve the Macro-F on the full test set, Test-F. This demonstrates the effectiveness of introducing the users' retrospective tweets.", "labels": [], "entities": [{"text": "IUA", "start_pos": 12, "end_pos": 15, "type": "METRIC", "confidence": 0.7674775719642639}]}, {"text": "IUA out performs DA, with a margin of more than 8 percent on Test-R, indicating the necessity of training individual user adaptive models for the emoji prediction task.", "labels": [], "entities": [{"text": "IUA", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.9223816394805908}, {"text": "DA", "start_pos": 17, "end_pos": 19, "type": "METRIC", "confidence": 0.9022791385650635}, {"text": "emoji prediction task", "start_pos": 146, "end_pos": 167, "type": "TASK", "confidence": 0.887344757715861}]}, {"text": "Compared with the best results in the task, on Test-F, -namely, 35.99 percent for cagri and 35.36 percent for cbaziotis () -IUA achieves better results, even without an intensive feature engineering process.", "labels": [], "entities": [{"text": "IUA", "start_pos": 124, "end_pos": 127, "type": "DATASET", "confidence": 0.6899588108062744}]}], "tableCaptions": [{"text": " Table 2: Macro-F [%] for the models on the test sets", "labels": [], "entities": []}]}