{"title": [{"text": "EMA at SemEval-2018 Task 1: Emotion Mining for Arabic", "labels": [], "entities": [{"text": "Emotion Mining", "start_pos": 28, "end_pos": 42, "type": "TASK", "confidence": 0.8003729581832886}]}], "abstractContent": [{"text": "While significant progress has been achieved for Opinion Mining in Arabic (OMA), very limited efforts have been put towards the task of Emotion mining in Arabic.", "labels": [], "entities": [{"text": "Opinion Mining in Arabic (OMA)", "start_pos": 49, "end_pos": 79, "type": "TASK", "confidence": 0.8272076121398381}, {"text": "Emotion mining in Arabic", "start_pos": 136, "end_pos": 160, "type": "TASK", "confidence": 0.9373549222946167}]}, {"text": "In fact, businesses are interested in learning a fine-grained representation of how users are feeling towards their products or services.", "labels": [], "entities": []}, {"text": "In this work, we describe the methods used by the team Emotion Mining in Arabic (EMA), as part of the SemEval-2018 Task 1 for Affect Mining for Arabic tweets.", "labels": [], "entities": [{"text": "Emotion Mining in Arabic (EMA)", "start_pos": 55, "end_pos": 85, "type": "TASK", "confidence": 0.7387440460068839}, {"text": "Affect Mining for Arabic tweets", "start_pos": 126, "end_pos": 157, "type": "TASK", "confidence": 0.7436767220497131}]}, {"text": "EMA participated in all 5 subtasks.", "labels": [], "entities": [{"text": "EMA", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.9654264450073242}]}, {"text": "For the five tasks, several prepro-cessing steps were evaluated and eventually the best system included diacritics removal, elongation adjustment, replacement of emojis by the corresponding Arabic word, character normalization and light stemming.", "labels": [], "entities": [{"text": "diacritics removal", "start_pos": 104, "end_pos": 122, "type": "TASK", "confidence": 0.6609509736299515}, {"text": "character normalization", "start_pos": 203, "end_pos": 226, "type": "TASK", "confidence": 0.7885793447494507}, {"text": "light stemming", "start_pos": 231, "end_pos": 245, "type": "TASK", "confidence": 0.7257857918739319}]}, {"text": "Moreover, several features were evaluated along with different classification and regression techniques.", "labels": [], "entities": []}, {"text": "For the 5 subtasks, word embeddings feature turned out to perform best along with Ensemble technique.", "labels": [], "entities": []}, {"text": "EMA achieved the 1 st place in subtask 5, and 3 rd place in subtasks 1 and 3.", "labels": [], "entities": [{"text": "EMA", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.9593223333358765}]}], "introductionContent": [{"text": "Emotion recognition has captured the interest of researchers for many years.", "labels": [], "entities": [{"text": "Emotion recognition", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.9571913778781891}]}, {"text": "Different models have been used to detect people's emotions such as human computer interaction (HCI) ( and their facial expressions (.", "labels": [], "entities": []}, {"text": "Recently, with Web 2.0, the size of textual data charged with opinions and emotions on the web has tremendously increased.", "labels": [], "entities": []}, {"text": "Thus, researchers have been looking at automatically performing sentiment and emotion analysis from textual data.", "labels": [], "entities": [{"text": "sentiment and emotion analysis", "start_pos": 64, "end_pos": 94, "type": "TASK", "confidence": 0.8990263938903809}]}, {"text": "In fact, learning emotions of users is critical for different applications such as shaping marketing strategies (, providing customers with better personalized recommendations for advertisements and products, improving recommendation of typical recommender systems (, tracking emotions of users towards politicians, movies, music, products, etc, (, or accurately predicting stock market prices).", "labels": [], "entities": []}, {"text": "Some efforts have already been placed in developing emotion classification models from text (.", "labels": [], "entities": [{"text": "emotion classification", "start_pos": 52, "end_pos": 74, "type": "TASK", "confidence": 0.7245278805494308}]}, {"text": "Since sentiment lexicons helped in improving the accuracy of sentiment classification models (), several researchers are working on developing emotion lexicons for different languages such as English, French, Chinese).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 49, "end_pos": 57, "type": "METRIC", "confidence": 0.9970067143440247}, {"text": "sentiment classification", "start_pos": 61, "end_pos": 85, "type": "TASK", "confidence": 0.7994347214698792}]}, {"text": "There were also couple of attempts for developing Arabic emotion lexicons).", "labels": [], "entities": []}, {"text": "Building on our previous work on opinion mining which involved development of sentiment lexicons (ArSenL (), opinion mining models () and applications (, and building on our analysis and characterization for Twitter Data (,c), we participate in: Affect in Arabic Tweets.", "labels": [], "entities": [{"text": "opinion mining", "start_pos": 33, "end_pos": 47, "type": "TASK", "confidence": 0.8054181039333344}, {"text": "ArSenL", "start_pos": 98, "end_pos": 104, "type": "METRIC", "confidence": 0.9758589863777161}, {"text": "opinion mining", "start_pos": 109, "end_pos": 123, "type": "TASK", "confidence": 0.7054612636566162}]}, {"text": "In fact, analyzing sentiment and emotions from dialectal Arabic such as text data from Twitter is of great importance given the tremendous increase of Arabic speaking users on Twitter.", "labels": [], "entities": []}, {"text": "In this paper, we describe our approaches to: Affect in Arabic Tweets, along with the achieved results for each of the subtasks where we employed preprocessing steps, features and classification models based on our prior work on sentiment analysis.", "labels": [], "entities": [{"text": "Affect in Arabic Tweets", "start_pos": 46, "end_pos": 69, "type": "TASK", "confidence": 0.6689608693122864}, {"text": "sentiment analysis", "start_pos": 229, "end_pos": 247, "type": "TASK", "confidence": 0.9037146866321564}]}, {"text": "In section 2, we present a brief overview of related work to emotion classification for English and Arabic.", "labels": [], "entities": [{"text": "emotion classification", "start_pos": 61, "end_pos": 83, "type": "TASK", "confidence": 0.7301590293645859}]}, {"text": "In section 3, we describe the five subtasks that are part of Affect in Tweet task.", "labels": [], "entities": []}, {"text": "In section 4, we present our proposed approach and finally, we conclude in section 5.", "labels": [], "entities": []}], "datasetContent": [{"text": "For each of the 5 tasks, 3 sets of datasets were released, each set corresponding to a language (English, Arabic and Spanish).", "labels": [], "entities": []}, {"text": "For each language, 3 datasets were released (training, development and test).", "labels": [], "entities": []}, {"text": "For subtasks 1 and 2 Arabic, each emotion of the four emotions had a training set of around 800 tweets on average and a development set of around 200 tweets.", "labels": [], "entities": []}, {"text": "Subtasks 3 and 4 Arabic had a dataset consisting of 932 tweets for training and 138 tweets for development.", "labels": [], "entities": []}, {"text": "For subtask 5 Arabic, 2278 tweets were used for training and 585 tweets for development.", "labels": [], "entities": []}, {"text": "All experiments were conducted using Python with scikit-learn and Keras libraries.", "labels": [], "entities": []}, {"text": "A grid search mechanism was utilized to optimize the hyperparameters of the different learning models used and whose performances are reported in below tables: alpha parameter for Ridge, penalty C, kernel and gamma for Support Vectors, and, number trees, maximum tree depth and number of features per tree for Random Forests.", "labels": [], "entities": []}, {"text": "Rows 2 to 5 in tables 1 and 2 show the results (Pearson Score) of the different regression techniques used for subtasks 1 and 3 respectively on the corresponding development sets for each of the four emotions (Joy, Sadness, Poor and Anger).", "labels": [], "entities": [{"text": "Pearson Score)", "start_pos": 48, "end_pos": 62, "type": "METRIC", "confidence": 0.9745665192604065}]}, {"text": "Average performance is also reported in the last column.", "labels": [], "entities": []}, {"text": "The last two rows in show the result on the test set of our Ensemble model on average and per each emotion and the performance of the best team for subtask1 respectively.", "labels": [], "entities": []}, {"text": "The last two rows in show the performance of Ridge Regression on the test set and the performance of the best team respectively.", "labels": [], "entities": [{"text": "Ridge Regression", "start_pos": 45, "end_pos": 61, "type": "TASK", "confidence": 0.5495096743106842}]}, {"text": "In both subtasks, EMA ranked 3 rd among participants.", "labels": [], "entities": [{"text": "EMA", "start_pos": 18, "end_pos": 21, "type": "DATASET", "confidence": 0.7465522289276123}]}, {"text": "By examining the results of the different participants in subtask 1, we can observe that the proposed systems perform best for the Joy emotion.", "labels": [], "entities": []}, {"text": "show the hyperparameters for each technique employed.", "labels": [], "entities": []}, {"text": "For Random Forest, the number of estimators was set to 1000.", "labels": [], "entities": []}, {"text": "In, we show the results of subtasks 2 and 4 respectively.", "labels": [], "entities": []}, {"text": "SVC was the best performing model on the development set in subtask 2 and Ensemble methods performed best in subtask 4.", "labels": [], "entities": [{"text": "SVC", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.9584224820137024}]}, {"text": "The last column in table 5 shows the performance of SVC on the test set on average and per each of the four emotions.", "labels": [], "entities": [{"text": "SVC", "start_pos": 52, "end_pos": 55, "type": "TASK", "confidence": 0.7848747372627258}]}, {"text": "The last row in table 6 represents the Pearson score achieved by the Ensemble of RC and SVC on the test set.", "labels": [], "entities": [{"text": "Pearson score", "start_pos": 39, "end_pos": 52, "type": "METRIC", "confidence": 0.9877485930919647}]}, {"text": "EMA was ranked 8 th and 5 thin subtasks 2 and 4 respectively.", "labels": [], "entities": [{"text": "EMA", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.953980028629303}]}, {"text": "show the best hyperparameters of the classification models used.", "labels": [], "entities": []}, {"text": "Finally, shows the results of subtask 5 on the development and the test sets where fora given tweet, the tweet is classified either as neutral  or as one or more of 11 emotions (anger, anticipation, disgust, fear, joy, love, optimism, pessimism, sadness, surprise, trust).", "labels": [], "entities": []}, {"text": "Linear SVC performed best among all classifiers.", "labels": [], "entities": []}, {"text": "EMA ranked 1 st in subtask 5.", "labels": [], "entities": [{"text": "EMA", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.9593790769577026}]}], "tableCaptions": [{"text": " Table 1: Subtask 1 Pearson Correlation Results on Dev  and Test Sets. RR = Ridge Regression; SVR = Support  Vector Regressor; RF = Random Forest.", "labels": [], "entities": [{"text": "RR", "start_pos": 71, "end_pos": 73, "type": "METRIC", "confidence": 0.9901968240737915}, {"text": "Ridge Regression", "start_pos": 76, "end_pos": 92, "type": "METRIC", "confidence": 0.8384622037410736}, {"text": "SVR", "start_pos": 94, "end_pos": 97, "type": "METRIC", "confidence": 0.9643308520317078}, {"text": "RF", "start_pos": 127, "end_pos": 129, "type": "METRIC", "confidence": 0.9161317348480225}]}, {"text": " Table 2: Subtask 3 Pearson Correlation Results on Dev  and Test Sets. RR = Ridge Regression; SVR = Support  Vector Regressor; RF = Random Forest.", "labels": [], "entities": [{"text": "RR", "start_pos": 71, "end_pos": 73, "type": "METRIC", "confidence": 0.9894730448722839}, {"text": "Ridge Regression", "start_pos": 76, "end_pos": 92, "type": "METRIC", "confidence": 0.8338919878005981}, {"text": "SVR", "start_pos": 94, "end_pos": 97, "type": "METRIC", "confidence": 0.9593340754508972}, {"text": "RF", "start_pos": 127, "end_pos": 129, "type": "METRIC", "confidence": 0.9105431437492371}]}, {"text": " Table 3: Subtask 1 Regression Models' Hyperparam- eters.", "labels": [], "entities": []}, {"text": " Table 4: Subtask 3 Regression Models' Hyperparam- eters.", "labels": [], "entities": []}, {"text": " Table 5: Subtask 2 Pearson Correlation Results on  Dev and Test Sets. RC = Ridge Classification; SVC =  Support Vector Classifier; Ens = Ensemble.", "labels": [], "entities": [{"text": "Pearson", "start_pos": 20, "end_pos": 27, "type": "METRIC", "confidence": 0.934276282787323}]}, {"text": " Table 6: Subtask 4 Pearson Correlation Results on  Dev and Test Sets. RC = Ridge Classification; SVC =  Support Vector Classifier.", "labels": [], "entities": [{"text": "Pearson", "start_pos": 20, "end_pos": 27, "type": "METRIC", "confidence": 0.9576337337493896}]}, {"text": " Table 7: Subtask 2 Classification Models' Hyperpa- rameters.", "labels": [], "entities": []}, {"text": " Table 8: Subtask 4 Classification Models' Hyperpa- rameters.", "labels": [], "entities": []}, {"text": " Table 9: Subtask 5 Accuracy Results on Dev and Test  Sets. RC = Ridge Classification; SVC = Support Vector  Classifier; RF = Random Forest.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 20, "end_pos": 28, "type": "METRIC", "confidence": 0.9926799535751343}]}, {"text": " Table 10: Subtask 5 Classification Models' Hyperpa- rameters.", "labels": [], "entities": []}]}