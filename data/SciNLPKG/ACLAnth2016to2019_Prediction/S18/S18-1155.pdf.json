{"title": [{"text": "GHH at SemEval-2018 Task 10: Discovering Discriminative Attributes in Distributional Semantics", "labels": [], "entities": [{"text": "Discovering Discriminative Attributes", "start_pos": 29, "end_pos": 66, "type": "TASK", "confidence": 0.8342060446739197}]}], "abstractContent": [{"text": "This paper describes our system submission to the SemEval 2018 Task 10 on Capturing Discriminative Attributes.", "labels": [], "entities": [{"text": "SemEval 2018 Task 10 on Capturing Discriminative Attributes", "start_pos": 50, "end_pos": 109, "type": "TASK", "confidence": 0.7877932786941528}]}, {"text": "Given two concepts and an attribute, the task is to determine whether the attribute is semantically related to one concept and not the other.", "labels": [], "entities": []}, {"text": "In this work we assume that discriminative attributes can be detected by discovering the association (or lack of association) between a pair of words.", "labels": [], "entities": []}, {"text": "The hypothesis we test in this contribution is whether the semantic difference between two pairs of concepts can be treated in terms of measuring the distance between words in a vector space, or can simply be obtained as a by-product of word co-occurrence counts.", "labels": [], "entities": []}], "introductionContent": [{"text": "Equipped with their cognitive skills, encyclopedic knowledge and linguistic competence, humans generally can identify the lexical association or semantic relation between two words or concepts with relative ease.", "labels": [], "entities": [{"text": "identify the lexical association or semantic relation between two words or concepts", "start_pos": 109, "end_pos": 192, "type": "TASK", "confidence": 0.7787581483523051}]}, {"text": "However, building a computational model for identifying fine-grained semantic relations (such as synonymy, antonymy, hyponymy, or hypernymy, meronymy, holonymy, metonymy, containment or causality) or even detecting binary relatedness has proven to be a challenging task.", "labels": [], "entities": []}, {"text": "Efforts to model semantic representation computationally are generally classified into statistical and knowledge-driven semantics.", "labels": [], "entities": []}, {"text": "This classification depends on whether the assumption is that human knowledge is encapsulated in language manifestation or that explicit manual encoding of this knowledge is needed.", "labels": [], "entities": []}, {"text": "The statistical approach to the encoding of semantic relations is referred to as \"distributional semantics\" or \"distributed word representations\", and its theoretical appeal stems from the fact that it gives practical application to the Firthian dictum \"You shall know a word by the company it keeps\" which has become commonsense wisdom in lexical semantics.", "labels": [], "entities": []}, {"text": "Features of the statistical model are extracted from unstructured data, such as words embeddings, n-gram counts, or directly from raw data.", "labels": [], "entities": []}, {"text": "The basic idea with word embeddings is to formulate semantic relations in arithmetic fashion by creating a vector space in which words with similar contextual embeddings have closer vectors distance ().", "labels": [], "entities": []}, {"text": "The public availability of word embedding training programs such as word2vec () and GloVe () allowed researchers to create models with different parameters and dimensionality sizes for different purposes including capturing semantic relations (.", "labels": [], "entities": []}, {"text": "The Google n-gram corpus) is a collection of English word n-grams and their observed counts generated from 1 trillion words of texts from web pages.", "labels": [], "entities": [{"text": "Google n-gram corpus)", "start_pos": 4, "end_pos": 25, "type": "DATASET", "confidence": 0.7564166560769081}]}, {"text": "This corpus has been used in many different applications including estimating word-relatedness (), comparison of semantic similarity (Joubarne and Inkpen, 2011), information retrieval, lexical disambiguation (, improving general purpose NLP classifiers ( , and improving parsing performance . Knowledge-driven approaches to the detection of semantic relations rely on manually constructed lexical and encyclopedic resources, such as ConceptNet (, ImageNet (Russakovsky et al., 2015), WordNet), Wiktionary, Open Mind Common Sense () and DBpedia (.", "labels": [], "entities": [{"text": "comparison of semantic similarity", "start_pos": 99, "end_pos": 132, "type": "TASK", "confidence": 0.8506765514612198}, {"text": "information retrieval", "start_pos": 162, "end_pos": 183, "type": "TASK", "confidence": 0.8196254968643188}, {"text": "lexical disambiguation", "start_pos": 185, "end_pos": 207, "type": "TASK", "confidence": 0.7248006463050842}, {"text": "WordNet", "start_pos": 484, "end_pos": 491, "type": "DATASET", "confidence": 0.933872640132904}]}, {"text": "In this work we follow a statistical based approach and show the strengths and weakness of the distributional semantics of the word vectors and ngram frequency counts in capturing the different types of discriminative attributes.", "labels": [], "entities": [{"text": "ngram frequency counts", "start_pos": 144, "end_pos": 166, "type": "METRIC", "confidence": 0.8665484189987183}]}], "datasetContent": [{"text": "We test our system on various combination of the features mentioned in subsection 3.1.", "labels": [], "entities": []}, {"text": "We assume  the baseline is 50% as this is what a random system would generate given that the validation set has an almost equal number of True's and False's. shows the system results on the dev set, with the last row showing results on the test set using our best model, \"all features\".", "labels": [], "entities": [{"text": "False's.", "start_pos": 149, "end_pos": 157, "type": "METRIC", "confidence": 0.9704603552818298}]}, {"text": "Surprisingly, using the cosine distance between pairs of words gives a low score (56.17%) which is slightly above the baseline, indicating the ineffectiveness of cosine distances in capturing this kind of relationships.", "labels": [], "entities": []}, {"text": "Word counts alone were the most impactful of all the features.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Sizes of the shared task datasets.", "labels": [], "entities": []}, {"text": " Table 3: System results with different feature combinations.", "labels": [], "entities": []}, {"text": " Table 4: Discriminative classes sorted by system per- formance.", "labels": [], "entities": []}]}