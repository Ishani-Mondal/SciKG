{"title": [{"text": "TeamDL at SemEval-2018 Task 8: Cybersecurity Text Analysis using Convolutional Neural Network and Conditional Random Fields", "labels": [], "entities": [{"text": "SemEval-2018 Task 8", "start_pos": 10, "end_pos": 29, "type": "TASK", "confidence": 0.4930245677630107}, {"text": "Cybersecurity Text Analysis", "start_pos": 31, "end_pos": 58, "type": "TASK", "confidence": 0.7664578755696615}]}], "abstractContent": [{"text": "In this paper we present our participation to SemEval-2018 Task 8 subtasks 1 & 2 respectively.", "labels": [], "entities": [{"text": "SemEval-2018 Task 8 subtasks", "start_pos": 46, "end_pos": 74, "type": "TASK", "confidence": 0.6667587906122208}]}, {"text": "We developed Convolution Neural Network system for malware sentence classification (subtask 1) and Conditional Random Fields system for malware token label prediction (subtask 2).", "labels": [], "entities": [{"text": "malware sentence classification", "start_pos": 51, "end_pos": 82, "type": "TASK", "confidence": 0.6332088311513265}, {"text": "token label prediction", "start_pos": 144, "end_pos": 166, "type": "TASK", "confidence": 0.6053435901800791}]}, {"text": "We experimented with couple of word embedding strategies, feature sets and achieved competitive performance across the two subtasks.", "labels": [], "entities": []}, {"text": "Code is made available at https://bitbucket.org/ vishnumani2009/securenlp", "labels": [], "entities": []}], "introductionContent": [{"text": "Cybersecurity risks and malware threats are becoming common and increasingly dangerous requiring analysis of large repositories of malware related information in realtime to understand its capabilities and mount an effective defense.", "labels": [], "entities": []}, {"text": "The sheer volume of data and its potential applications alone have increased traction in recent times among NLP researchers.", "labels": [], "entities": []}, {"text": "In this line, SemEval 2018 Task-8 offers 4 subtasks addressing text classification and token, relation and attribute label prediction in cybersecurity domain using MalwareTextDB (.", "labels": [], "entities": [{"text": "text classification", "start_pos": 63, "end_pos": 82, "type": "TASK", "confidence": 0.7161460220813751}, {"text": "relation and attribute label prediction", "start_pos": 94, "end_pos": 133, "type": "TASK", "confidence": 0.5880871891975403}]}, {"text": "While subtask 1 focuses on predicting sentences relevance to malware , subtasks 2, 3 and 4 focus on predicting token, relation and attribute labels for malware text from subtask 1.", "labels": [], "entities": [{"text": "predicting sentences relevance", "start_pos": 27, "end_pos": 57, "type": "TASK", "confidence": 0.8869393666585287}]}, {"text": "More details about the each of the subtasks can be found in.", "labels": [], "entities": []}, {"text": "Concerning subtask 1, which was inherently formulated as a text classification problem very few works are done till date in cybersecurity domain (.", "labels": [], "entities": [{"text": "text classification", "start_pos": 59, "end_pos": 78, "type": "TASK", "confidence": 0.7424007654190063}]}, {"text": "However, in general domain the problem of text classification is well addressed with extensive usage * Work performed during weekend part time assistantship at CAMMS of deep learning approaches (, Support vector machines, logistic regression ( and Tree based approaches ().", "labels": [], "entities": [{"text": "text classification", "start_pos": 42, "end_pos": 61, "type": "TASK", "confidence": 0.7979014217853546}, {"text": "CAMMS", "start_pos": 160, "end_pos": 165, "type": "DATASET", "confidence": 0.8897933959960938}]}, {"text": "On the other hand, subtask 2 was formulated as sequence tagging problem which is addressed till date by CRF (, deep learning approaches ( and SVM.", "labels": [], "entities": [{"text": "sequence tagging", "start_pos": 47, "end_pos": 63, "type": "TASK", "confidence": 0.765178382396698}]}, {"text": "In this paper, we describe our system that addresses subtasks 1 and 2 involving malware sentence classification and malware token label prediction.", "labels": [], "entities": [{"text": "malware sentence classification", "start_pos": 80, "end_pos": 111, "type": "TASK", "confidence": 0.6347466011842092}, {"text": "malware token label prediction", "start_pos": 116, "end_pos": 146, "type": "TASK", "confidence": 0.5739460811018944}]}, {"text": "We designed these systems by adapting various insights from previous works on text classification and sequence tagging.", "labels": [], "entities": [{"text": "text classification", "start_pos": 78, "end_pos": 97, "type": "TASK", "confidence": 0.7898489534854889}, {"text": "sequence tagging", "start_pos": 102, "end_pos": 118, "type": "TASK", "confidence": 0.6841816157102585}]}, {"text": "We submitted a Convolutional Neural Network(CNN) based system based system for subtask 1 and Conditional Random Field (CRF) based system for subtask 2.", "labels": [], "entities": []}, {"text": "The rest of the paper is organized as follows.", "labels": [], "entities": []}, {"text": "In section section 2, we discuss datasets and preprocessing.", "labels": [], "entities": []}, {"text": "In section 3, we describe the algorithms and features used in the process of model development.", "labels": [], "entities": [{"text": "model development", "start_pos": 77, "end_pos": 94, "type": "TASK", "confidence": 0.705156534910202}]}, {"text": "In section 4, we describe our results and some of our findings.", "labels": [], "entities": []}, {"text": "Finally in section 5, we conclude with summary and possible implications on future work.", "labels": [], "entities": []}], "datasetContent": [{"text": "The MalwareTextDB corpus used for this work consists of APT reports describing malware reported information taken from APTnotes 1 . We designed an end-to-end pipeline consisting on three module which process input text across multiple stages.", "labels": [], "entities": [{"text": "MalwareTextDB corpus", "start_pos": 4, "end_pos": 24, "type": "DATASET", "confidence": 0.7958294451236725}]}, {"text": "In stage 1, the input sentence is fed to a preprocessing module which pre-processes the  text for stage 2 where the sentence are subject to classification and finally stage 3 sequence tags the tokens of the input sentence.", "labels": [], "entities": []}, {"text": "We used following preprocessing steps in stage 1. 1. All the words are lower-cased.", "labels": [], "entities": []}, {"text": "2. All the words that can be grouped under common category were replaced by a category placeholder as shown in table 1.", "labels": [], "entities": []}, {"text": "In this section, we present results for each of the developed systems.", "labels": [], "entities": []}, {"text": "The original dataset was split into train17, test-17 3 released at the start of competition and dev-18, test-18 released during the competition pre-evaluation period for tuning of parameters and final evaluation respectively . We submitted CNN system for subtask 1 and CRF system for subtask 2.", "labels": [], "entities": []}, {"text": "show the results of subtasks 1 and 2 respectively across the datasets.", "labels": [], "entities": []}, {"text": "Our systems achieve F-score of 0.5 for subtask 1 and 0.25, 0.36 for subtask 2 overstrict, relaxed runs of subtask 2.", "labels": [], "entities": [{"text": "F-score", "start_pos": 20, "end_pos": 27, "type": "METRIC", "confidence": 0.9996142387390137}]}], "tableCaptions": [{"text": " Table 3: Results of subtask 1 on native Embeddings", "labels": [], "entities": []}, {"text": " Table 4: Results of subtask 1 on task specific embed- dings", "labels": [], "entities": []}, {"text": " Table 5: Results of subtask 2 on Conditional Random  fields", "labels": [], "entities": []}]}