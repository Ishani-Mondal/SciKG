{"title": [{"text": "Coarse Lexical Frame Acquisition at the Syntax-Semantics Interface Using a Latent-Variable PCFG Model", "labels": [], "entities": [{"text": "Coarse Lexical Frame Acquisition", "start_pos": 0, "end_pos": 32, "type": "TASK", "confidence": 0.638729028403759}]}], "abstractContent": [{"text": "We present a method for unsupervised lexical frame acquisition at the syntax-semantics interface.", "labels": [], "entities": [{"text": "unsupervised lexical frame acquisition", "start_pos": 24, "end_pos": 62, "type": "TASK", "confidence": 0.7519063949584961}]}, {"text": "Given a set of input strings derived from dependency parses, our method generates a set of clusters that resemble lexical frame structures.", "labels": [], "entities": []}, {"text": "Our work is motivated not only by its practical applications (e.g., to build, or expand the coverage of lexical frame databases), but also to gain linguistic insight into frame structures with respect to lexical distributions in relation to grammatical structures.", "labels": [], "entities": []}, {"text": "We model our task using a hierarchical Bayesian network and employ tools and methods from latent variable probabilistic context free grammars (L-PCFGs) for statistical inference and parameter fitting, for which we propose anew split and merge procedure.", "labels": [], "entities": [{"text": "statistical inference", "start_pos": 156, "end_pos": 177, "type": "TASK", "confidence": 0.8513631522655487}, {"text": "parameter fitting", "start_pos": 182, "end_pos": 199, "type": "TASK", "confidence": 0.7396833598613739}]}, {"text": "We show that our model outperforms several base-lines on a portion of the Wall Street Journal sentences that we have newly annotated for evaluation purposes.", "labels": [], "entities": [{"text": "Wall Street Journal sentences", "start_pos": 74, "end_pos": 103, "type": "DATASET", "confidence": 0.9726157784461975}]}], "introductionContent": [{"text": "We propose a method for building coarse lexical frames automatically from dependency parsed sentences; i.e., without using any explicit semantic information as training data.", "labels": [], "entities": []}, {"text": "The task involves grouping verbs that evoke the same frame (i.e., are considered to be the head of this frame) and further clustering their syntactic arguments into latent semantic roles.", "labels": [], "entities": []}, {"text": "Hence, our target structures stand between FrameNet () and PropBank () frames.", "labels": [], "entities": [{"text": "PropBank", "start_pos": 59, "end_pos": 67, "type": "DATASET", "confidence": 0.8932108283042908}]}, {"text": "Similar to FrameNet and in contrast to PropBank, we assume a many-to-many relationship between verb types and frame types.", "labels": [], "entities": []}, {"text": "But similar to PropBank, we aim to cluster syntactic arguments into general semantic roles instead of frame-specific slot * Both authors contributed equally to this types in FrameNet.", "labels": [], "entities": []}, {"text": "This allows us to generalize across frames concerning semantic roles.", "labels": [], "entities": []}, {"text": "As part of this, we study possible ways to automatically generate more abstract lexical-semantic representations from lexicalized dependency structures.", "labels": [], "entities": []}, {"text": "In our task, grouping verb tokens into frames requires not only distinguishing between different senses of verbs, but also identifying a range of lexical relationships (e.g., synonymy, opposite verbs, troponymy, etc.) among them.", "labels": [], "entities": [{"text": "grouping verb tokens into frames", "start_pos": 13, "end_pos": 45, "type": "TASK", "confidence": 0.846277391910553}]}, {"text": "Hence (as), our problem definition differs from most work on unsupervised fine-grained frame induction using verb sense disambiguation (e.g.,.", "labels": [], "entities": [{"text": "verb sense disambiguation", "start_pos": 109, "end_pos": 134, "type": "TASK", "confidence": 0.6596409877141317}]}, {"text": "Similarly, forming role clusters yields generalization from several alternate linkings between semantic roles and their syntactic realization.", "labels": [], "entities": []}, {"text": "Given, for instance, an occurrence of the verb pack and its syntactic arguments, not only do we aim to distinguish different senses of the verb pack (e.g., as used to evoke the FILLING frame, or the PLACING frame), but also to group these instances of 'pack' with other verbs that evoke the same frame (e.g., to group instances of pack that evoke the frame PLACING with instances of verbs load, pile, place, and soon when used to evoke the same PLACING frame).", "labels": [], "entities": [{"text": "FILLING", "start_pos": 177, "end_pos": 184, "type": "METRIC", "confidence": 0.9739219546318054}]}, {"text": "The motivation for this work is twofold.", "labels": [], "entities": []}, {"text": "On the one hand, the frame induction techniques we propose can be useful in the context of applications such as text summarization, question answering (, and soon, for languages where we lack a frame-annotated resource for supervised frame induction, or to expand the coverage of already existing resources.", "labels": [], "entities": [{"text": "frame induction", "start_pos": 21, "end_pos": 36, "type": "TASK", "confidence": 0.7979254126548767}, {"text": "text summarization", "start_pos": 112, "end_pos": 130, "type": "TASK", "confidence": 0.7650315463542938}, {"text": "question answering", "start_pos": 132, "end_pos": 150, "type": "TASK", "confidence": 0.8998894989490509}, {"text": "frame induction", "start_pos": 234, "end_pos": 249, "type": "TASK", "confidence": 0.7351607531309128}]}, {"text": "On the other hand, we are interested in theoretical linguistic insights into frame structure.", "labels": [], "entities": []}, {"text": "In this sense, our work is a step towards an empirical investigation of frames and semantic roles including hierarchical relations between them.", "labels": [], "entities": []}, {"text": "We cast the frame induction task as unsupervised learning using an L-PCFG.", "labels": [], "entities": []}, {"text": "As input, our model takes syntactic dependency trees and extracts input strings corresponding to instances of frame expressions, which are subsequently grouped into latent semantic frames and roles using an L-PCFG.", "labels": [], "entities": []}, {"text": "We use the insideoutside (i.e., Expectation-Maximization) algorithm and a split-merge procedure () for dynamically adapting the number of frames and roles to the data, for which we employ new heuristics.", "labels": [], "entities": []}, {"text": "As implied, one advantage of the L-PCFGs framework is that we can adapt and reuse statistical inference techniques used for learning PCFGs in syntactic parsing application (e.g., split-merge).", "labels": [], "entities": []}, {"text": "Our experiment shows that the method outperforms a number of baselines, including frame grouping by lexical heads and one based on agglomerative clustering.", "labels": [], "entities": [{"text": "frame grouping", "start_pos": 82, "end_pos": 96, "type": "TASK", "confidence": 0.672964483499527}]}, {"text": "The main contributions of this paper are a) using L-PCFGs for coarse lexical frame acquisition; b) anew split-merge routine adapted for this task; and, c) anew dataset for evaluating the induced lexical frame-role groupings.", "labels": [], "entities": [{"text": "coarse lexical frame acquisition", "start_pos": 62, "end_pos": 94, "type": "TASK", "confidence": 0.5824876204133034}]}, {"text": "In the remainder of the paper, \u00a7 2 describes our statistical model and its formalization to an L-PCFG.", "labels": [], "entities": []}, {"text": "\u00a7 3 describes procedures used for statistical inference.", "labels": [], "entities": [{"text": "statistical inference", "start_pos": 34, "end_pos": 55, "type": "TASK", "confidence": 0.8720090091228485}]}, {"text": "\u00a7 4 describes our evaluation dataset and reports results from experiments.", "labels": [], "entities": []}, {"text": "\u00a7 5 discusses related work followed by a conclusion in \u00a7 6.", "labels": [], "entities": []}], "datasetContent": [{"text": "We derive our data for evaluation from the PTB's WSJ sections parsed (using) to the enhanced UD format.", "labels": [], "entities": [{"text": "PTB's WSJ sections parsed", "start_pos": 43, "end_pos": 68, "type": "DATASET", "confidence": 0.9141828656196594}]}, {"text": "We augment these sentences with semantic role annotations obtained from Prague Semantic Dependencies (PSD) () from the SDP resource.", "labels": [], "entities": []}, {"text": "Using EngVallex () and SemLink, we semi-automatically annotate verbs with FrameNet frames ().", "labels": [], "entities": []}, {"text": "We choose 1k random sentences and manually verify the semi-automatic mappings to eventually build our evaluation dataset of approximately 5k instances (all).", "labels": [], "entities": []}, {"text": "From this data, we use a random subset of 200 instances (dev) during the development and for parameter tuning (see  For these gold instances, we extract input strings from their UD parses according \u00a7 2.", "labels": [], "entities": [{"text": "parameter tuning", "start_pos": 93, "end_pos": 109, "type": "TASK", "confidence": 0.6914302855730057}]}, {"text": "Since we discard verbs without syntactic arguments, use automatic parses, and do not distinguish arguments from adjuncts, the input strings do not exactly match the gold data argument structures.", "labels": [], "entities": []}, {"text": "We report results only for the portion of the gold data that appears in the extracted input strings.", "labels": [], "entities": []}, {"text": "reports the statistics for the induced input strings and their agreement with the gold data (in terms of precision and recall).", "labels": [], "entities": [{"text": "precision", "start_pos": 105, "end_pos": 114, "type": "METRIC", "confidence": 0.999464213848114}, {"text": "recall", "start_pos": 119, "end_pos": 125, "type": "METRIC", "confidence": 0.9987443685531616}]}, {"text": "Input strings are hard to cluster in the sense that a) all the frames are lexicalized by at least two different verb lemmas, b) many verbs lexicalizes at least two different types of frames, c) verb lemmas that lexicalize a frame have long-tailed distributions, i.e., a large proportion of instances of a frame are realized at surface structure by one: Input strings extracted from the UD parses: GR, AIG, RF , R A , and PA denote, respectively, the number of distinct grammatical relations, syntactic arguments that area semantic role in the gold data, recall for frame and arguments, and precision for arguments.", "labels": [], "entities": [{"text": "PA", "start_pos": 421, "end_pos": 423, "type": "METRIC", "confidence": 0.9509609341621399}, {"text": "recall", "start_pos": 554, "end_pos": 560, "type": "METRIC", "confidence": 0.9978429079055786}, {"text": "precision", "start_pos": 590, "end_pos": 599, "type": "METRIC", "confidence": 0.9989639520645142}]}, {"text": "The remaining symbols are the same as lemma while in the remaining instances the frame is evoked by different lemmas, and d) last but not least, the frame types themselves have long-tailed distribution.", "labels": [], "entities": []}, {"text": "shows examples of frames and verb lemmas that lexicalize them; in the table, the most frequent lemma for each frame type is italicized.", "labels": [], "entities": []}, {"text": "We evaluate our method's performance on a) clustering input strings to frame types, and b) clustering syntactic arguments to semantic role types.", "labels": [], "entities": [{"text": "clustering syntactic arguments to semantic role types", "start_pos": 91, "end_pos": 144, "type": "TASK", "confidence": 0.7574503166334969}]}, {"text": "To this end, we report the harmonic mean of BCubed precision and recall (BCF) (, and purity (PU), inverse purity (IPU) and their harmonic mean (FPU) () as figures of merit.", "labels": [], "entities": [{"text": "precision", "start_pos": 51, "end_pos": 60, "type": "METRIC", "confidence": 0.7044845819473267}, {"text": "recall (BCF)", "start_pos": 65, "end_pos": 77, "type": "METRIC", "confidence": 0.9569063782691956}, {"text": "purity (PU)", "start_pos": 85, "end_pos": 96, "type": "METRIC", "confidence": 0.9612857699394226}, {"text": "inverse purity (IPU)", "start_pos": 98, "end_pos": 118, "type": "METRIC", "confidence": 0.9418918251991272}, {"text": "harmonic mean (FPU)", "start_pos": 129, "end_pos": 148, "type": "METRIC", "confidence": 0.6951838374137879}]}, {"text": "These measures reflect a notion of similarity between the distribution of instances in the obtained clusters and the gold/evaluation data based on certain criteria and alone may lack sufficient information fora fair understanding of the system's performance.", "labels": [], "entities": []}, {"text": "While PU and IPU are easy to interpret (by establishing an analogy between them and precision and recall in classification tasks), they maybe deceiving under certain conditions (as explained by, under the notions of homogeneity, completeness, ragbag, and 'size vs. quantity' constraints).", "labels": [], "entities": [{"text": "precision", "start_pos": 84, "end_pos": 93, "type": "METRIC", "confidence": 0.9986286163330078}, {"text": "recall", "start_pos": 98, "end_pos": 104, "type": "METRIC", "confidence": 0.9580000638961792}]}, {"text": "Reporting BCF alongside FPU ensures that these pitfalls are not overlooked when our system's output are compared quantitatively with the baselines.", "labels": [], "entities": [{"text": "FPU", "start_pos": 24, "end_pos": 27, "type": "METRIC", "confidence": 0.5006458163261414}]}], "tableCaptions": [{"text": " Table 1: Gold Data: FT, FI, V, AT, and AI denote  the number of frame types, instances, distinct verb  heads, argument types, and argument instances", "labels": [], "entities": [{"text": "FT", "start_pos": 21, "end_pos": 23, "type": "METRIC", "confidence": 0.6281917691230774}, {"text": "FI", "start_pos": 25, "end_pos": 27, "type": "METRIC", "confidence": 0.7045139670372009}, {"text": "AT", "start_pos": 32, "end_pos": 34, "type": "METRIC", "confidence": 0.9709380865097046}, {"text": "AI", "start_pos": 40, "end_pos": 42, "type": "METRIC", "confidence": 0.9901060461997986}]}, {"text": " Table 2: Input strings extracted from the UD  parses: GR, AIG, R F , R A , and P A denote, respec- tively, the number of distinct grammatical rela- tions, syntactic arguments that are a semantic role  in the gold data, recall for frame and arguments,  and precision for arguments. The remaining sym- bols are the same as", "labels": [], "entities": [{"text": "recall", "start_pos": 220, "end_pos": 226, "type": "METRIC", "confidence": 0.9982783794403076}, {"text": "precision", "start_pos": 257, "end_pos": 266, "type": "METRIC", "confidence": 0.9992291927337646}]}, {"text": " Table 3: Examples of frames in our evaluation set and verbs that evoke them; #T and #V denote the total  number of instances for the frame and the number of distinct verb lemmas that evoke them, respectively.", "labels": [], "entities": []}, {"text": " Table 4: Results for head groupings: #C de- notes the number of induced clusters by each  method/baseline; the last two rows reports the av- erage and the standard deviation for the obtained  results using the L-PCFG model.The remaining  abbreviations are introduced in  \u00a7 4.2 and 4.3.", "labels": [], "entities": [{"text": "av- erage", "start_pos": 138, "end_pos": 147, "type": "METRIC", "confidence": 0.893119235833486}]}, {"text": " Table 5: Results on clustering of syntactic argu- ments to semantic roles.", "labels": [], "entities": []}]}