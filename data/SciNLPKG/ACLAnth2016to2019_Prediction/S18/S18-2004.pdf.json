{"title": [], "abstractContent": [{"text": "Measuring the salience of a word is an essential step in numerous NLP tasks.", "labels": [], "entities": []}, {"text": "Heuristic approaches such as tfidf have been used so far to estimate the salience of words.", "labels": [], "entities": []}, {"text": "We propose Neural Word Salience (NWS) scores, unlike heuristics, are learnt from a corpus.", "labels": [], "entities": [{"text": "Neural Word Salience (NWS)", "start_pos": 11, "end_pos": 37, "type": "TASK", "confidence": 0.7111537257830302}]}, {"text": "Specifically , we learn word salience scores such that, using pre-trained word embeddings as the input , can accurately predict the words that appear in a sentence, given the words that appear in the sentences preceding or succeeding that sentence.", "labels": [], "entities": []}, {"text": "Experimental results on sentence similarity prediction show that the learnt word salience scores perform comparably or better than some of the state-of-the-art approaches for representing sentences on benchmark datasets for sentence similarity, while using only a fraction of the training and prediction times required by prior methods.", "labels": [], "entities": [{"text": "sentence similarity prediction", "start_pos": 24, "end_pos": 54, "type": "TASK", "confidence": 0.8119314114252726}, {"text": "sentence similarity", "start_pos": 224, "end_pos": 243, "type": "TASK", "confidence": 0.7386345565319061}]}, {"text": "Moreover , our NWS scores positively correlate with psycholinguistic measures such as concrete-ness, and imageability implying a close connection to the salience as perceived by humans .", "labels": [], "entities": []}], "introductionContent": [{"text": "Humans can easily recognise the words that contribute to the meaning of a sentence (i.e. content words) from words that serve only a grammatical functionality (i.e. functional words).", "labels": [], "entities": []}, {"text": "For example, functional words such as the, an, a etc.", "labels": [], "entities": []}, {"text": "have limited contributions towards the overall meaning of a document and are often filtered out as stop words in information retrieval systems).", "labels": [], "entities": []}, {"text": "We define the salience q(w) of a word win a given text T as the semantic contribution made by w towards the overall meaning of T . If we can accurately compute the salience of words, then we can develop better representations of texts that can be used in downstream NLP tasks such as similarity measurement or text (e.g. sentiment, entailment) classification.", "labels": [], "entities": [{"text": "similarity measurement", "start_pos": 284, "end_pos": 306, "type": "TASK", "confidence": 0.6770699769258499}, {"text": "text (e.g. sentiment, entailment) classification", "start_pos": 310, "end_pos": 358, "type": "TASK", "confidence": 0.69703159481287}]}, {"text": "As described later in section 2, existing methods for detecting word salience can be classified into two groups: (a) lexicon-based filtering methods such as stop word lists, or (b) word frequency-based heuristics such as the popular term-frequency inverse document frequency (tfidf) measure and its variants.", "labels": [], "entities": [{"text": "detecting word salience", "start_pos": 54, "end_pos": 77, "type": "TASK", "confidence": 0.722989430030187}]}, {"text": "Unfortunately, two main drawbacks can be identified in common to both stop words lists and frequencybased salience scores.", "labels": [], "entities": []}, {"text": "First, such methods do not take into account the semantics associated with individual words when determining their salience.", "labels": [], "entities": []}, {"text": "For example, consider the following two adjacent sentences extracted from a newspaper article related to the visit of the Japanese Prime Minister, Shinzo Abe, to the White House in Washington, to meet the US President Donald Trump.", "labels": [], "entities": []}], "datasetContent": [{"text": "We use the Toronto books corpus 4 as our training dataset.", "labels": [], "entities": [{"text": "Toronto books corpus 4", "start_pos": 11, "end_pos": 33, "type": "DATASET", "confidence": 0.9860647171735764}]}, {"text": "This corpus contains 81 million sentences from 11,038 books, and has been used as a training dataset in several prior work on sentence embedding learning.", "labels": [], "entities": []}, {"text": "Note that only 7,807 books in this corpus are unique.", "labels": [], "entities": []}, {"text": "Specifically, for 2,098 books there exist one duplicate, for 733 there are two and for 95 books there are more than two duplicates.", "labels": [], "entities": []}, {"text": "However, following the training protocol used in prior work (), we do not remove those duplicates from the corpus, and use the entire collection of books for training.", "labels": [], "entities": []}, {"text": "We convert all sentences to lowercase and tokenise using the Python NLTK 5 punctuation tokeniser.", "labels": [], "entities": [{"text": "Python NLTK 5 punctuation tokeniser", "start_pos": 61, "end_pos": 96, "type": "DATASET", "confidence": 0.7556502938270568}]}, {"text": "No further pre-processing is conduced beyond tokenisation.", "labels": [], "entities": [{"text": "tokenisation", "start_pos": 45, "end_pos": 57, "type": "TASK", "confidence": 0.9716193675994873}]}, {"text": "The proposed method is implemented using TensorFlow and executed on a NVIDIA Tesla K40c 2880 GPU.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Performance on STS benchmarks.", "labels": [], "entities": [{"text": "STS benchmarks", "start_pos": 25, "end_pos": 39, "type": "DATASET", "confidence": 0.7137146294116974}]}, {"text": " Table 2: Effect of word embeddings.", "labels": [], "entities": []}, {"text": " Table 3: Pearson correlation coefficients against Psycholin-", "labels": [], "entities": [{"text": "Pearson correlation", "start_pos": 10, "end_pos": 29, "type": "METRIC", "confidence": 0.8056595623493195}]}]}