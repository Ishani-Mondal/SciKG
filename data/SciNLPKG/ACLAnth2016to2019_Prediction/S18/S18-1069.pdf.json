{"title": [{"text": "NTUA-SLP at SemEval-2018 Task 2: Predicting Emojis using RNNs with Context-aware Attention", "labels": [], "entities": [{"text": "NTUA-SLP", "start_pos": 0, "end_pos": 8, "type": "DATASET", "confidence": 0.8740257620811462}, {"text": "Predicting Emojis", "start_pos": 33, "end_pos": 50, "type": "TASK", "confidence": 0.8525353968143463}]}], "abstractContent": [{"text": "In this paper we present a deep-learning model that competed at SemEval-2018 Task 2 \"Mul-tilingual Emoji Prediction\".", "labels": [], "entities": [{"text": "SemEval-2018 Task 2", "start_pos": 64, "end_pos": 83, "type": "TASK", "confidence": 0.6401787996292114}, {"text": "Mul-tilingual Emoji Prediction", "start_pos": 85, "end_pos": 115, "type": "TASK", "confidence": 0.5135921239852905}]}, {"text": "We participated in subtask A, in which we are called to predict the most likely associated emoji in En-glish tweets.", "labels": [], "entities": [{"text": "A", "start_pos": 27, "end_pos": 28, "type": "METRIC", "confidence": 0.8729734420776367}]}, {"text": "The proposed architecture relies on a Long Short-Term Memory network, augmented with an attention mechanism, that conditions the weight of each word, on a \"con-text vector\" which is taken as the aggregation of a tweet's meaning.", "labels": [], "entities": []}, {"text": "Moreover, we initialize the embedding layer of our model, with word2vec word embeddings, pretrained on a dataset of 550 million English tweets.", "labels": [], "entities": []}, {"text": "Finally, our model does not rely on hand-crafted features or lexicons and is trained end-to-end with back-propagation.", "labels": [], "entities": []}, {"text": "We ranked 2 nd out of 48 teams.", "labels": [], "entities": []}], "introductionContent": [{"text": "Emojis play an important role in textual communication, as they function as a substitute for nonverbal cues, that are taken for granted in face-toface communication, thus allowing users to convey emotions by means other than words.", "labels": [], "entities": []}, {"text": "Despite their large appeal in text, they haven't received much attention until recently.", "labels": [], "entities": []}, {"text": "Former works, mostly consider their semantics () and only recently their role in social media was explored (.", "labels": [], "entities": []}, {"text": "In SemEval-2018 Task 2: \"Multilingual Emoji Prediction\" (, given a tweet, we are asked to predict its most likely associated emoji.", "labels": [], "entities": [{"text": "Multilingual Emoji Prediction", "start_pos": 25, "end_pos": 54, "type": "TASK", "confidence": 0.6250114738941193}]}, {"text": "thanks for always making me feel like family ! love you guys ! \u2026", "labels": [], "entities": []}], "datasetContent": [{"text": "In order to deal with class imbalances, we apply class weights to the loss function of our models, penalizing more the misclassification of underrepresented classes.", "labels": [], "entities": []}, {"text": "We weight each class by its inverse frequency in the training set.", "labels": [], "entities": []}, {"text": "Training We use Adam algorithm) for optimizing our networks, with minibatches of size 32 and we clip the norm of the gradients ( at 1, as an extra safety measure against exploding gradients.", "labels": [], "entities": []}, {"text": "For developing our models we used PyTorch ( and Scikit-learn ().", "labels": [], "entities": [{"text": "PyTorch", "start_pos": 34, "end_pos": 41, "type": "METRIC", "confidence": 0.6966186761856079}]}, {"text": "In order to find good hyperparameter values in a relative short time (compared to grid or random search), we adopt the Bayesian optimization () approach, performing a time-efficient search in the space of all hyper-parameter values.", "labels": [], "entities": []}, {"text": "The size of the embedding layer is 300, and the LSTM layers 300 (600 for BiLSTM).", "labels": [], "entities": []}, {"text": "We add Gaussian noise with \u03c3 = 0.05 and dropout of 0.1 at the embedding layer and dropout of 0.3 at the LSTM layer.", "labels": [], "entities": [{"text": "Gaussian noise", "start_pos": 7, "end_pos": 21, "type": "METRIC", "confidence": 0.9433874189853668}]}, {"text": "The dataset for Task 2 was introduced in , where the authors propose a character level model with pretrained word vectors that achieves an F1 score of 34%.", "labels": [], "entities": [{"text": "F1 score", "start_pos": 139, "end_pos": 147, "type": "METRIC", "confidence": 0.9860062003135681}]}, {"text": "Our ranking as shown in was 2/49, with an F1 score of 35.361%, which was the official evaluation metric, while team TueOslo achieved the first position with an F1 score of 35.991%.", "labels": [], "entities": [{"text": "F1 score", "start_pos": 42, "end_pos": 50, "type": "METRIC", "confidence": 0.9866547286510468}, {"text": "F1 score", "start_pos": 160, "end_pos": 168, "type": "METRIC", "confidence": 0.9836601614952087}]}, {"text": "It should be noted that only the first 2 teams managed to surpass the baseline model presented in ).", "labels": [], "entities": []}, {"text": "In we compare the proposed ContextAttention LSTM (CA-LSTM) model against 2 baselines: (1) a Bag-of-Words (BOW) model with TF-IDF weighting and (2) a Neural Bag-of-Words (N-BOW) model, where we retrieve the word2vec representations of the words in a tweet and compute the tweet representation as the centroid of the constituent word2vec representations.", "labels": [], "entities": []}, {"text": "Both BOW and N-BOW features are then fed to a linear SVM classifier, with tuned C = 0.6.", "labels": [], "entities": [{"text": "BOW", "start_pos": 5, "end_pos": 8, "type": "METRIC", "confidence": 0.9775027632713318}]}, {"text": "The CA-LSTM results in are computed by averaging the results of 10 runs to account for model variability.", "labels": [], "entities": []}, {"text": "shows that BOW model outperforms N-BOW by a large margin, which may indicate that there exist words, which are very correlated with specific classes and their occurrence can determine the classification result.", "labels": [], "entities": [{"text": "BOW", "start_pos": 11, "end_pos": 14, "type": "METRIC", "confidence": 0.9288478493690491}]}, {"text": "Finally, we observe that CA-LSTM significantly outperforms both baselines.", "labels": [], "entities": []}, {"text": "Furthermore, we observe that heart or face emojis, which are more ambiguous, are easily confusable with each other.", "labels": [], "entities": []}, {"text": "However, as expected this in not the case for emojis like the US flag or the Christmas tree, as they are tied with specific expressions.", "labels": [], "entities": []}, {"text": "The attention mechanism not only improves the performance of the model, but also makes it interpretable.", "labels": [], "entities": []}, {"text": "By using the attention scores assigned to each word annotation, we can investigate the behavior of the model.", "labels": [], "entities": []}, {"text": "shows how the attention mechanism focuses on each word in order to estimate the most suitable emoji label.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Official Results for Subtask A", "labels": [], "entities": [{"text": "Subtask", "start_pos": 31, "end_pos": 38, "type": "TASK", "confidence": 0.9569103121757507}]}, {"text": " Table 3: Comparison against baselines", "labels": [], "entities": []}]}