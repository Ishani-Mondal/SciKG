{"title": [{"text": "ALB at SemEval-2018 Task 10: A System for Capturing Discriminative Attributes", "labels": [], "entities": [{"text": "SemEval-2018 Task 10", "start_pos": 7, "end_pos": 27, "type": "TASK", "confidence": 0.7102353572845459}, {"text": "Capturing Discriminative Attributes", "start_pos": 42, "end_pos": 77, "type": "TASK", "confidence": 0.885260542233785}]}], "abstractContent": [{"text": "Semantic difference detection attempts to capture whether a word is a discriminative attribute between two other words.", "labels": [], "entities": [{"text": "Semantic difference detection", "start_pos": 0, "end_pos": 29, "type": "TASK", "confidence": 0.8321860829989115}]}, {"text": "For example , the discriminative feature red characterizes the first word from the (apple, banana) pair, but not the second.", "labels": [], "entities": []}, {"text": "Modeling semantic difference is essential for language understanding systems, as it provides useful information for identifying particular aspects of word senses.", "labels": [], "entities": [{"text": "Modeling semantic difference", "start_pos": 0, "end_pos": 28, "type": "TASK", "confidence": 0.8657180070877075}, {"text": "language understanding", "start_pos": 46, "end_pos": 68, "type": "TASK", "confidence": 0.6976303160190582}]}, {"text": "This paper describes our system implementation (the ALB system of the NLP@Unibuc team) for the 10th task of the Semaval 2018 workshop, \"Capturing Discriminative Attributes\".", "labels": [], "entities": [{"text": "NLP@Unibuc team", "start_pos": 70, "end_pos": 85, "type": "DATASET", "confidence": 0.792213648557663}, {"text": "Capturing Discriminative Attributes", "start_pos": 136, "end_pos": 171, "type": "TASK", "confidence": 0.8874568939208984}]}, {"text": "We propose a method for semantic difference detection that uses an SVM classifier with features based on co-occurrence counts and shallow semantic parsing, achieving 0.63 F1 score in the competition .", "labels": [], "entities": [{"text": "semantic difference detection", "start_pos": 24, "end_pos": 53, "type": "TASK", "confidence": 0.8669610619544983}, {"text": "semantic parsing", "start_pos": 138, "end_pos": 154, "type": "TASK", "confidence": 0.7506617605686188}, {"text": "F1 score", "start_pos": 171, "end_pos": 179, "type": "METRIC", "confidence": 0.9830493628978729}]}], "introductionContent": [], "datasetContent": [{"text": "The input data (training, validation and testing) is translated into an intermediary configuration as described below.", "labels": [], "entities": []}, {"text": "Each word triplet from the input data is split into two word pairs: (w 1 , w 3 ) and (w 2 , w 3 ).", "labels": [], "entities": []}, {"text": "The initial part of our model extracts features for each pair, and in the last steps, where the performance is computed, a cross-reference is done with the original input database.", "labels": [], "entities": []}, {"text": "We use the English Wikipedia as an external data source for feature extraction.", "labels": [], "entities": [{"text": "English Wikipedia", "start_pos": 11, "end_pos": 28, "type": "DATASET", "confidence": 0.9039681255817413}, {"text": "feature extraction", "start_pos": 60, "end_pos": 78, "type": "TASK", "confidence": 0.7202282100915909}]}, {"text": "We convert the raw Wikipedia database to plain text and concatenate the sentences of all the articles in a large text corpus.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Examples of word pairs and feature values.", "labels": [], "entities": []}]}