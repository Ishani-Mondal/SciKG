{"title": [{"text": "UWB at SemEval-2018 Task 3: Irony detection in English tweets", "labels": [], "entities": [{"text": "UWB", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.8177863359451294}, {"text": "Irony detection", "start_pos": 28, "end_pos": 43, "type": "TASK", "confidence": 0.8485656976699829}]}], "abstractContent": [{"text": "This paper describes our system created for the SemEval-2018 Task 3: Irony detection in En-glish tweets.", "labels": [], "entities": [{"text": "SemEval-2018 Task 3", "start_pos": 48, "end_pos": 67, "type": "TASK", "confidence": 0.8390046755472819}, {"text": "Irony detection", "start_pos": 69, "end_pos": 84, "type": "TASK", "confidence": 0.8476133644580841}]}, {"text": "Our strongly constrained system uses only the provided training data without any additional external resources.", "labels": [], "entities": []}, {"text": "Our system is based on Maximum Entropy classifier and various features using parse tree, POS tags, and morphological features.", "labels": [], "entities": []}, {"text": "Even without additional lexicons and word embeddings we achieved fourth place in Subtask A and seventh in Subtask B in terms of accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 128, "end_pos": 136, "type": "METRIC", "confidence": 0.9977540373802185}]}], "introductionContent": [{"text": "Frequent use of creative and figurative language on social media has important implications for natural language processing tasks such as sentiment analysis.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 138, "end_pos": 156, "type": "TASK", "confidence": 0.9591680467128754}]}, {"text": "The semantics of a sentence with creative or figurative language can be quite different from the same sentence with literal meaning and misinterpreting figurative language such as irony represents a significant challenge in sentiment analysis.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 224, "end_pos": 242, "type": "TASK", "confidence": 0.9265990555286407}]}, {"text": "explored the effect of figurative language on sentiment analysis and confirmed that figurative language affects sentiment analysis.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 46, "end_pos": 64, "type": "TASK", "confidence": 0.9597513377666473}, {"text": "sentiment analysis", "start_pos": 112, "end_pos": 130, "type": "TASK", "confidence": 0.9476089477539062}]}, {"text": "The issue of automatic irony and/or sarcasm 1 detection has been addressed mostly in English, however there has been some research in other languages as well (e.g. Dutch (), Italian (), Brazilian Portuguese (, and).", "labels": [], "entities": [{"text": "automatic irony and/or sarcasm 1 detection", "start_pos": 13, "end_pos": 55, "type": "TASK", "confidence": 0.7096746191382408}]}], "datasetContent": [{"text": "Our results in Subtask A are in and our results in Subtask B are in.", "labels": [], "entities": []}, {"text": "The official evaluation metric was F1-score.", "labels": [], "entities": [{"text": "F1-score", "start_pos": 35, "end_pos": 43, "type": "METRIC", "confidence": 0.9987888932228088}]}, {"text": "The system settings and features were selected based on our pre-  evaluation experiments using 10-fold cross validation on the training data for the team description UWB submitted.", "labels": [], "entities": [{"text": "UWB", "start_pos": 166, "end_pos": 169, "type": "DATASET", "confidence": 0.9130335450172424}]}, {"text": "The team description UWB best represents the best settings according to the experiments on test data.", "labels": [], "entities": [{"text": "UWB", "start_pos": 21, "end_pos": 24, "type": "DATASET", "confidence": 0.8383873701095581}]}, {"text": "We performed ablation experiments to see which features are the most beneficial (see and).", "labels": [], "entities": []}, {"text": "Numbers represent the performance change when the given feature is removed.", "labels": [], "entities": []}, {"text": "We can see that many features in the submitted settings for both subtasks are not beneficial for the results, thus we remove them in the best settings for the given subtask.", "labels": [], "entities": []}, {"text": "The best features apart from character n-grams include POS-B, FW, and BoM for both subtasks.", "labels": [], "entities": [{"text": "POS-B", "start_pos": 55, "end_pos": 60, "type": "METRIC", "confidence": 0.7227339744567871}, {"text": "FW", "start_pos": 62, "end_pos": 64, "type": "METRIC", "confidence": 0.823948323726654}, {"text": "BoM", "start_pos": 70, "end_pos": 73, "type": "METRIC", "confidence": 0.84615558385849}]}, {"text": "In subtask A R-Bow, TF-IDF, and unigrams were also beneficial.", "labels": [], "entities": []}, {"text": "In subtask B word shape n-grams were also helpful.", "labels": [], "entities": []}, {"text": "Detailed statistical analysis into the datasets and feature presence in the data would be needed in order to infer further insides.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 3: CodaLab results for Subtask A.", "labels": [], "entities": []}, {"text": " Table 4: CodaLab results for Subtask B.", "labels": [], "entities": [{"text": "Subtask B", "start_pos": 30, "end_pos": 39, "type": "TASK", "confidence": 0.9004862308502197}]}, {"text": " Table 5: Feature ablation study for Subtask A.", "labels": [], "entities": [{"text": "Subtask A", "start_pos": 37, "end_pos": 46, "type": "TASK", "confidence": 0.8271467685699463}]}, {"text": " Table 6: Feature ablation study for Subtask B.", "labels": [], "entities": [{"text": "Subtask B", "start_pos": 37, "end_pos": 46, "type": "TASK", "confidence": 0.9158796072006226}]}]}