{"title": [{"text": "RIDDL at SemEval-2018 Task 1: Rage Intensity Detection with Deep Learning", "labels": [], "entities": [{"text": "Rage Intensity Detection", "start_pos": 30, "end_pos": 54, "type": "TASK", "confidence": 0.9104547500610352}]}], "abstractContent": [{"text": "We present our methods and results for affect analysis in Twitter developed as apart of SemEval-2018 Task 1, where the sub-tasks involve predicting the intensity of emotion, the intensity of sentiment, and valence for tweets.", "labels": [], "entities": [{"text": "affect analysis", "start_pos": 39, "end_pos": 54, "type": "TASK", "confidence": 0.7594861686229706}]}, {"text": "For modeling, though we use a traditional LSTM network, we combine our model with several state-of-the-art techniques to improve its performance in a low-resource setting.", "labels": [], "entities": []}, {"text": "For example, we use an encoder-decoder network to initialize the LSTM weights.", "labels": [], "entities": []}, {"text": "Without any task specific optimization we achieve competitive results (macro-average Pearson correlation coefficient 0.696) in the El-reg task.", "labels": [], "entities": [{"text": "macro-average Pearson correlation coefficient 0.696", "start_pos": 71, "end_pos": 122, "type": "METRIC", "confidence": 0.7987819671630859}]}, {"text": "In this paper, we describe our development strategy in detail along with an exposition of our results.", "labels": [], "entities": []}], "introductionContent": [{"text": "Sentiment analysis is a technique to classify documents based on the polarity of opinion expressed by the author of the document ().", "labels": [], "entities": [{"text": "Sentiment analysis", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.9413349032402039}]}, {"text": "Traditionally this involved extracting coarse sentiment (positive, negative, or neutral) from documents such as news articles, product or movie reviews ().", "labels": [], "entities": [{"text": "extracting coarse sentiment (positive, negative, or neutral) from documents such as news articles, product or movie reviews", "start_pos": 28, "end_pos": 151, "type": "TASK", "confidence": 0.6877755387262865}]}, {"text": "In order to get a fine grained view of the opinion, sentiment analysis was applied at the sentence and phrase level ().", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 52, "end_pos": 70, "type": "TASK", "confidence": 0.9549967050552368}]}, {"text": "With the advent of social media, Twitter in particular, sentiment towards a wide range of topics could be extracted at a much larger scale than before.", "labels": [], "entities": []}, {"text": "This however came with its own set of problems, viz., alack of proper grammatical structure, prevalence of slang, acronyms, and misspellings (.", "labels": [], "entities": []}, {"text": "SemEval tasks have provided a curated testing environment for analysis on Twitter data with tasks to quantify sentiment on two-point, threepoint, and five-point scales (.", "labels": [], "entities": []}, {"text": "While a finer gradation in polarity of the text could be inferred by introducing more nuanced categories, it faces the problem of needing to collect more labeled data as the number of classes increase.", "labels": [], "entities": []}, {"text": "Therefore, this approach requires that the intensity of the sentiment expressed be measured on a continuous scale rather than through discrete categories.", "labels": [], "entities": []}, {"text": "SemEval 2018 Task 1 takes a novel step in this direction by introducing tasks for predicting intensity of emotion, or sentiment expressed ( . We participated in SemEval-2018 Task-1 (ElReg, V-reg, V-oc) and our contributions through this paper are as follows: \u2022 We present an LSTM network combined with known state-of-the-art techniques to improve performance on low-resource setting tasks.", "labels": [], "entities": [{"text": "SemEval 2018 Task 1", "start_pos": 0, "end_pos": 19, "type": "DATASET", "confidence": 0.8338835388422012}]}, {"text": "\u2022 The proposed model requires no task specific hyper-parameter tuning.", "labels": [], "entities": []}, {"text": "\u2022 We perform error analysis of our model to obtain a better understanding of strengths and weaknesses of a deep learning-based approach for these tasks and propose improvements.", "labels": [], "entities": []}], "datasetContent": [{"text": "For each subtask, the organizers provide training and development datasets for model training and hyperparameter selection.", "labels": [], "entities": [{"text": "hyperparameter selection", "start_pos": 98, "end_pos": 122, "type": "TASK", "confidence": 0.7312935292720795}]}, {"text": "The details on how much data and how it was labeled can be found here . We concatenate the training and development datasets and sample 10% of this combined dataset, to use as validation data.", "labels": [], "entities": []}, {"text": "Our model training involves an unsupervised phase and a supervised phase, which is described in detail in Section 2.3.", "labels": [], "entities": []}, {"text": "For the unsupervised learning phase, we use the concatenated training data from all the tasks, and for the supervised learning phase, we use the task specific training data.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Hyperparameters used for network training.", "labels": [], "entities": [{"text": "network training", "start_pos": 35, "end_pos": 51, "type": "TASK", "confidence": 0.7522285878658295}]}, {"text": " Table 2: Pearson correlation on emotion intensity re- gression task (EI-reg) in English for each emotion us- ing Strategy 1.", "labels": [], "entities": [{"text": "Pearson correlation", "start_pos": 10, "end_pos": 29, "type": "METRIC", "confidence": 0.9048902094364166}, {"text": "emotion intensity re- gression task (EI-reg)", "start_pos": 33, "end_pos": 77, "type": "METRIC", "confidence": 0.7914041843679216}]}, {"text": " Table 3: Macro average of Pearson correlation on emo- tion intensity regression task (EI-reg) in English using  Strategy 1.", "labels": [], "entities": [{"text": "Pearson correlation", "start_pos": 27, "end_pos": 46, "type": "METRIC", "confidence": 0.9258682727813721}, {"text": "emo- tion intensity regression task (EI-reg)", "start_pos": 50, "end_pos": 94, "type": "METRIC", "confidence": 0.6380632420380911}]}, {"text": " Table 4: Pearson correlation on valence intensity re- gression task (V-reg) in English using Strategy 1.", "labels": [], "entities": [{"text": "Pearson correlation", "start_pos": 10, "end_pos": 29, "type": "METRIC", "confidence": 0.8569425046443939}, {"text": "valence intensity re- gression task (V-reg)", "start_pos": 33, "end_pos": 76, "type": "METRIC", "confidence": 0.8497652014096578}]}, {"text": " Table 5: Pearson correlation on valence ordinal classi- fication task (V-oc) in English using Strategy 1.", "labels": [], "entities": [{"text": "Pearson correlation", "start_pos": 10, "end_pos": 29, "type": "METRIC", "confidence": 0.8498902022838593}]}, {"text": " Table 6: Pearson correlation (average and standard de- viation of 5 runs) on emotion intensity regression task  (EI-reg) in English using Strategy 2.", "labels": [], "entities": [{"text": "Pearson correlation", "start_pos": 10, "end_pos": 29, "type": "METRIC", "confidence": 0.9225873351097107}]}]}