{"title": [{"text": "NEUROSENT-PDI at SemEval-2018 Task 1: Leveraging a Multi-Domain Sentiment Model for Inferring Polarity in Micro-blog Text", "labels": [], "entities": [{"text": "NEUROSENT-PDI", "start_pos": 0, "end_pos": 13, "type": "METRIC", "confidence": 0.6194851994514465}]}], "abstractContent": [{"text": "This paper describes the NeuroSent system that participated in SemEval 2018 Task 1.", "labels": [], "entities": [{"text": "SemEval 2018 Task 1", "start_pos": 63, "end_pos": 82, "type": "TASK", "confidence": 0.8650260418653488}]}, {"text": "Our system takes a supervised approach that builds on neural networks and word embeddings.", "labels": [], "entities": []}, {"text": "Word embeddings were built by starting from a repository of user generated reviews.", "labels": [], "entities": []}, {"text": "Thus, they are specific for sentiment analysis tasks.", "labels": [], "entities": [{"text": "sentiment analysis tasks", "start_pos": 28, "end_pos": 52, "type": "TASK", "confidence": 0.9626254836718241}]}, {"text": "Then, tweets are converted in the corresponding vector representation and given as input to the neural network with the aim of learning the different semantics contained in each emotion taken into account by the SemEval task.", "labels": [], "entities": [{"text": "SemEval task", "start_pos": 212, "end_pos": 224, "type": "TASK", "confidence": 0.8742705285549164}]}, {"text": "The output layer has been adapted based on the characteristics of each subtask.", "labels": [], "entities": []}, {"text": "Preliminary results obtained on the provided training set are encouraging for pursuing the investigation into this direction.", "labels": [], "entities": []}], "introductionContent": [{"text": "Sentiment Analysis is a natural language processing (NLP) task () which aims at classifying documents according to the opinion expressed about a given subject.", "labels": [], "entities": [{"text": "Sentiment Analysis", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.8997684121131897}, {"text": "natural language processing (NLP) task", "start_pos": 24, "end_pos": 62, "type": "TASK", "confidence": 0.7212264708110264}]}, {"text": "Many works available in the literature address the sentiment analysis problem without distinguishing domain specific information of documents when sentiment models are built.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 51, "end_pos": 69, "type": "TASK", "confidence": 0.9662262797355652}]}, {"text": "The necessity of investigating this problem from a multi-domain perspective is led by the different influence that a term might have in different contexts.", "labels": [], "entities": []}, {"text": "The idea of adapting terms polarity to different domains emerged only in the last decade.", "labels": [], "entities": []}, {"text": "Multi-domain sentiment analysis approaches discussed in the literature focus on building models for transferring information between pairs of domains.", "labels": [], "entities": [{"text": "Multi-domain sentiment analysis", "start_pos": 0, "end_pos": 31, "type": "TASK", "confidence": 0.8128983775774637}]}, {"text": "While on the one hand such approaches allow to propagate specific domain information to others, their drawback is the necessity of building new transfer models every time anew domain has to be analyzed.", "labels": [], "entities": []}, {"text": "Thus, such approaches do not have a great generalization capability of analyzing texts, because transfer models are limited to the N domains used for building the models.", "labels": [], "entities": []}, {"text": "The NeuroSent tool applied in) leverages on the following pillars: (i) the use of word embeddings for representing each word contained in raw sentences; (ii) the word embeddings are generated from an opinion-based corpus instead of a general purpose one (like news or Wikipedia); (iii) the design of a deep learning technique exploiting the generated word embeddings for training the sentiment model; and (iv) the use of multiple output layers for combining domain overlap scores with domain-specific polarity predictions.", "labels": [], "entities": []}, {"text": "The last point enables the exploitation of linguistic overlaps between domains, which can be considered one of the pivotal assets of our approach.", "labels": [], "entities": []}, {"text": "This way, the overall polarity of a document is computed by aggregating, for each domain, the domain-specific polarity value multiplied by a belonging degree representing the overlap between the embedded representation of the whole document and the domain itself.", "labels": [], "entities": []}, {"text": "Within the SemEval 2018 Task 1 challenge, we consider with the term domain one of the emotions that have been considered into the provided datasets.", "labels": [], "entities": [{"text": "SemEval 2018 Task 1 challenge", "start_pos": 11, "end_pos": 40, "type": "TASK", "confidence": 0.8644073843955994}]}], "datasetContent": [{"text": "The NeuroSent approach have been preliminarily evaluated by adopting the Dranziera protocol (.", "labels": [], "entities": [{"text": "Dranziera protocol", "start_pos": 73, "end_pos": 91, "type": "DATASET", "confidence": 0.8600037693977356}]}, {"text": "The validation procedure leverages on a fivefold cross evaluation setting in order to validate the robustness of the proposed solution.", "labels": [], "entities": []}, {"text": "The approach has been compared with four baselines: Support Vector Machine (SVM) (Chang and Lin, 2011), Naive Bayes (NB) and Maximum Entropy (ME), and Convolutional Neural Network (.", "labels": [], "entities": []}, {"text": "In, we provide for subtasks two, four, and five the average Pearson correlation obtained on the five folds in which the training set has been split.", "labels": [], "entities": [{"text": "Pearson correlation", "start_pos": 60, "end_pos": 79, "type": "METRIC", "confidence": 0.9463815689086914}]}, {"text": "While, for subtasks one and three, we provide the average mean square error.", "labels": [], "entities": [{"text": "mean square error", "start_pos": 58, "end_pos": 75, "type": "METRIC", "confidence": 0.8208046555519104}]}, {"text": "The obtained results demonstrated the suitability of NeuroSent with respect to the adopted baselines.", "labels": [], "entities": []}, {"text": "We may also observed how solutions based on neural networks obtained a significant improvement with respect to the others for the Tasks #1.2 and #1.4.", "labels": [], "entities": []}, {"text": "Then, for Tasks #1.2, #1.4, and #1.5, we performed a detailed error analysis concerning the performance of NeuroSent.", "labels": [], "entities": []}, {"text": "In general, we observed how our strategy tends to provide false negative predictions.", "labels": [], "entities": []}, {"text": "An in depth analysis of some incorrect predictions highlighted that the embedded representations of some positive opinion words are very close to the space region of negative opinion words.", "labels": [], "entities": []}, {"text": "Even if we may state that the confidence about positive predictions is very high, this scenario leads to have a predominant negative classification for borderline instances.", "labels": [], "entities": []}, {"text": "On the one hand, a possible action for improving the effectiveness our strategy is to increase the granularity of the embeddings (i.e. augmenting the size of the embedding vectors) in order to increase the distance between the positive and negative polarities space regions.", "labels": [], "entities": []}, {"text": "On the other hand, by increasing the size of embedding vectors, the computational time for building, or updating, the model and for evaluating a single instance increases as well.", "labels": [], "entities": []}, {"text": "Part of the future work, will be the analysis of more efficient neural network architectures able to manage augmented embedding vectors without negatively affecting the efficiency of the platform.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Results obtained on the training set by NeuroSent and by the four baselines.", "labels": [], "entities": []}]}