{"title": [{"text": "CENNLP at SemEval-2018 Task 1: Constrained Vector Space Model in Affects in Tweets", "labels": [], "entities": [{"text": "CENNLP", "start_pos": 0, "end_pos": 6, "type": "DATASET", "confidence": 0.9380720257759094}]}], "abstractContent": [{"text": "This paper discusses on task 1, \"Affect in Tweets\" sharedtask, conducted in SemEval-2018.", "labels": [], "entities": []}, {"text": "This task comprises of various sub-tasks, which required participants to analyse over different emotions and sentiments based on the provided tweet data and also measure the intensity of these emotions for subsequent subtasks.", "labels": [], "entities": []}, {"text": "Our approach is to come up with a model for all the subtasks on count based representation and use machine learning techniques for regression and classification related tasks.", "labels": [], "entities": []}, {"text": "In this work, we use bag of words technique for supervised text classification and regression.", "labels": [], "entities": [{"text": "text classification", "start_pos": 59, "end_pos": 78, "type": "TASK", "confidence": 0.688401848077774}]}, {"text": "Further, fine tuning on various parameters for the bag of word, representation model we acquired better scores over various other baseline models (Vinayan et al.) participated in the sharedtask.", "labels": [], "entities": []}], "introductionContent": [{"text": "A huge portion of analysis in natural language processing try to find better understand and process various kinds of info in text.", "labels": [], "entities": []}, {"text": "Day by day the development of social websites, blogging and the consummation of technologies gives vast amount text data on the internet, which opened a space to study peoples feeling, reviews, and emotion from their own written languages, called sentimental analysis.", "labels": [], "entities": [{"text": "sentimental analysis", "start_pos": 247, "end_pos": 267, "type": "TASK", "confidence": 0.8823243081569672}]}, {"text": "Sentimental analysis has so many attractions and has done so many research ( ) in this area.", "labels": [], "entities": [{"text": "Sentimental analysis", "start_pos": 0, "end_pos": 20, "type": "TASK", "confidence": 0.9894322156906128}]}, {"text": "Sentiment analysis remains a sequence of techniques, approaches, and tools about sensing and mining subjective info (such as opinion and attitudes) from language ().", "labels": [], "entities": [{"text": "Sentiment analysis", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.9442868232727051}, {"text": "sensing and mining subjective info (such as opinion and attitudes) from language", "start_pos": 81, "end_pos": 161, "type": "TASK", "confidence": 0.7424130120447704}]}, {"text": "Traditional approaches () are finding out the polarity of the positive, negative, neutral classification problem.", "labels": [], "entities": []}, {"text": "Recent research in sentimental analysis ) are done on the data-driven algorithm viewpoint.", "labels": [], "entities": [{"text": "sentimental analysis", "start_pos": 19, "end_pos": 39, "type": "TASK", "confidence": 0.9682654440402985}]}, {"text": "But at the same time combination of good linguistic awareness data can increase the performance and insights about the task.", "labels": [], "entities": []}, {"text": "We used machine learning techniques to build the model.", "labels": [], "entities": []}, {"text": "Linear regression, random forest methods are used respectively for prediction and classification tasks.", "labels": [], "entities": [{"text": "prediction and classification", "start_pos": 67, "end_pos": 96, "type": "TASK", "confidence": 0.5984927217165629}]}, {"text": "A mathematical system or an algorithm need some form of numeric representation to work with.", "labels": [], "entities": []}, {"text": "The naive way of representing a word in vector form is one hot representation but it is a very ineffective way for representing a large corpus.", "labels": [], "entities": []}, {"text": "Ina more effective way, we need some semantic similarities ( ) to nearby points, thus creating the representation bring beneficial info about the word actual meaning, called word embedding models that are categorized based on count and predictive word embedding models.", "labels": [], "entities": []}, {"text": "Both embedding models at least someway share sematic meaning.", "labels": [], "entities": []}, {"text": "We used here count based word embedding methods for inputting the word.", "labels": [], "entities": []}, {"text": "In more specific, Feature representation is done based on the term-document matrix (TDM) and term frequency-inverse frequency (TFIDF) matrix.", "labels": [], "entities": [{"text": "Feature representation", "start_pos": 18, "end_pos": 40, "type": "TASK", "confidence": 0.8534428775310516}, {"text": "term frequency-inverse frequency (TFIDF) matrix", "start_pos": 93, "end_pos": 140, "type": "METRIC", "confidence": 0.8741780349186489}]}, {"text": "The optimum value of n-gram range, depth of classifier, mindf are obtained by hyper parameter tuning.", "labels": [], "entities": [{"text": "mindf", "start_pos": 56, "end_pos": 61, "type": "METRIC", "confidence": 0.9327632784843445}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: El-reg vocabulary size with variation of pa- rameters.", "labels": [], "entities": []}, {"text": " Table 2: V-reg vocabulary size with variation of param- eters.", "labels": [], "entities": []}, {"text": " Table 3: EI-reg cross validation results.", "labels": [], "entities": [{"text": "EI-reg cross validation", "start_pos": 10, "end_pos": 33, "type": "TASK", "confidence": 0.48138612508773804}]}, {"text": " Table 4: EI-oc cross validation results.", "labels": [], "entities": [{"text": "EI-oc cross validation", "start_pos": 10, "end_pos": 32, "type": "TASK", "confidence": 0.5408047735691071}]}, {"text": " Table 5: V-reg cross validation results.", "labels": [], "entities": [{"text": "V-reg cross validation", "start_pos": 10, "end_pos": 32, "type": "TASK", "confidence": 0.4792029360930125}]}, {"text": " Table 6: V-oc cross validation results.", "labels": [], "entities": [{"text": "V-oc cross validation", "start_pos": 10, "end_pos": 31, "type": "TASK", "confidence": 0.5383761326471964}]}, {"text": " Table 7: E-c cross validation results.", "labels": [], "entities": []}]}