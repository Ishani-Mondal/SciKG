{"title": [{"text": "ECNU at SemEval-2018 Task 3: Exploration on Irony Detection from Tweets via Machine Learning and Deep Learning Methods", "labels": [], "entities": [{"text": "ECNU at SemEval-2018 Task 3", "start_pos": 0, "end_pos": 27, "type": "DATASET", "confidence": 0.8524358868598938}, {"text": "Irony Detection from Tweets", "start_pos": 44, "end_pos": 71, "type": "TASK", "confidence": 0.7641250044107437}]}], "abstractContent": [{"text": "The paper describes our submissions to task 3 in SemEval 2018.", "labels": [], "entities": [{"text": "SemEval 2018", "start_pos": 49, "end_pos": 61, "type": "TASK", "confidence": 0.7909205257892609}]}, {"text": "There are two subtasks: Subtask A is a binary classification task to determine whether a tweet is ironic, and Subtask B is a fine-grained classification task including four classes.", "labels": [], "entities": []}, {"text": "To address them, we explored supervised machine learning method alone and in combination with neural networks.", "labels": [], "entities": []}], "introductionContent": [{"text": "Irony, also known as sarcasm, refers to the use of words and sentences, whose intended meanings contrary to their literal meanings.", "labels": [], "entities": []}, {"text": "Modeling irony has a large potential for applications in various research areas, so SemEval2018-Task3 (Hee et al.) aims to classify irony into different classes.", "labels": [], "entities": [{"text": "Modeling irony", "start_pos": 0, "end_pos": 14, "type": "TASK", "confidence": 0.8597053289413452}]}, {"text": "In subtask A, when given a tweet, the classifier should predict whether the tweet is ironic or non-ironic, and in subtask B, the ironic class is further divided into another three categories, i.e., irony by Polarity contrast, by Situational and Other verbal irony.", "labels": [], "entities": []}, {"text": "Polarity contrast irony represents the tweets containing an expression whose polarity (positive, negative) is inverted between the literal and the intended meaning.", "labels": [], "entities": []}, {"text": "Situational irony stands for the ones which don't contain explicit polarity contrast.", "labels": [], "entities": [{"text": "Situational irony", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.7573841512203217}]}, {"text": "However, the events or results described in them are contrary to the desired or expected common knowledge.", "labels": [], "entities": []}, {"text": "Other verbal irony tweets also don't contain any explicit polarity contrast, but they can't be classified into the Situational irony.", "labels": [], "entities": []}, {"text": "Finally, non-ironic contains instances which are clearly not ironic, or lack adequate context to be sure that they are ironic.", "labels": [], "entities": []}, {"text": "In the remaining of the paper, section 2 describes our system in details.", "labels": [], "entities": []}, {"text": "Section 3 reports datasets, experiments and results discussions.", "labels": [], "entities": []}, {"text": "Finally, Section 4 concludes our work.", "labels": [], "entities": []}], "datasetContent": [{"text": "The statistics of the datasets provided by SemEval 2018 task 3 are shown in.: Statistics of datasets in train and test data.", "labels": [], "entities": [{"text": "SemEval 2018 task 3", "start_pos": 43, "end_pos": 62, "type": "TASK", "confidence": 0.592239536345005}]}, {"text": "Label 0 stands for non-ironic, label 1 in subtask A is ironic, label 1, 2, 3 in subtask B is respectively polarity contrast irony, situational irony and other verbal irony.", "labels": [], "entities": []}, {"text": "The official evaluation criterion is as follow: \u2022 For subtask A, only F 1 -score of Ironic class is used.", "labels": [], "entities": [{"text": "F 1 -score", "start_pos": 70, "end_pos": 80, "type": "METRIC", "confidence": 0.9808178246021271}]}, {"text": "F = F pos \u2022 For subtask B, macro-averaged F 1 -score calculated among all four classes is used.", "labels": [], "entities": [{"text": "F", "start_pos": 0, "end_pos": 1, "type": "METRIC", "confidence": 0.9733341932296753}, {"text": "macro-averaged F 1 -score", "start_pos": 27, "end_pos": 52, "type": "METRIC", "confidence": 0.8198495864868164}]}], "tableCaptions": [{"text": " Table 3: The results of hill climbing.", "labels": [], "entities": []}, {"text": " Table 4: Performance of three best learning algorithms.", "labels": [], "entities": []}, {"text": " Table 5: Performance of partial neural networks on  subtask A on train and dev datasets.", "labels": [], "entities": []}, {"text": " Table 6: The f 1 -scores of each label in subtask B.", "labels": [], "entities": [{"text": "f 1 -scores", "start_pos": 14, "end_pos": 25, "type": "METRIC", "confidence": 0.8116904050111771}]}, {"text": " Table 7: The performances of using 4 binary  classifications", "labels": [], "entities": []}, {"text": " Table 10: Performance of ensemble on machine  learning and neural networks on subtask A and test  datasets.", "labels": [], "entities": []}, {"text": " Table 11: Performance of pure neural networks. The  numbers in parentheses represent positions in the  official ranking if the result is submitted.", "labels": [], "entities": []}]}