{"title": [{"text": "YNU-HPCC at SemEval-2018 Task 3: Ensemble Neural Network Models for Irony Detection on Twitter", "labels": [], "entities": [{"text": "Irony Detection", "start_pos": 68, "end_pos": 83, "type": "TASK", "confidence": 0.6791636496782303}]}], "abstractContent": [{"text": "This paper describes our proposed to participate in the first year of the irony detection in English tweets competition.", "labels": [], "entities": [{"text": "irony detection in English tweets competition", "start_pos": 74, "end_pos": 119, "type": "TASK", "confidence": 0.8896361490090688}]}, {"text": "Previous works have demonstrated that long short-term memory models have achieved remarkable performance in natural language processing; moreover , combining multiple classifications from various individual classifiers is generally more powerful than a single classification.", "labels": [], "entities": []}, {"text": "In order to obtain more precise irony detection classification , our system trains several individual neural network classifiers and combines their results according to the ensemble-learning algorithm .", "labels": [], "entities": [{"text": "irony detection classification", "start_pos": 32, "end_pos": 62, "type": "TASK", "confidence": 0.9142783284187317}]}], "introductionContent": [{"text": "In most sentiment analysis tasks, recognition of the precise emotional polarity of a sentence forms the basis for further work.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 8, "end_pos": 26, "type": "TASK", "confidence": 0.9647483229637146}, {"text": "recognition of the precise emotional polarity of a sentence", "start_pos": 34, "end_pos": 93, "type": "TASK", "confidence": 0.6459142830636766}]}, {"text": "However, much of the corpus we used for analysis and training contains numerous sarcasm and irony features that will have a negative impact on the results of our analysis and training.", "labels": [], "entities": []}, {"text": "For example, although the tweets provided by Twitter constitute a valuable and widely applicable corpus for many natural language processing tasks, Twitter users express their feelings and opinions on social networks with frequent irony.", "labels": [], "entities": []}, {"text": "Therefore, such tweets may contain converse sentiments information compared their literal meaning.", "labels": [], "entities": []}, {"text": "For example, @someuser Yeah keeping cricket clean, that's what he wants #Sarcasm: ignoring the hashtag, this tweet would be positive, which would miss lead an analysis system that uses these types of tweets as input.", "labels": [], "entities": []}, {"text": "Thus, it makes sense to discriminate whether a text is ironic, particularly for social network texts such as tweets.", "labels": [], "entities": []}, {"text": "Further applications including tweet sentiment analysis, will benefit from automatic irony detection.", "labels": [], "entities": [{"text": "tweet sentiment analysis", "start_pos": 31, "end_pos": 55, "type": "TASK", "confidence": 0.841996987660726}, {"text": "irony detection", "start_pos": 85, "end_pos": 100, "type": "TASK", "confidence": 0.7712115943431854}]}, {"text": "The SemEval-2018 Twitter competition promotes research in this area, and is divided into two subtasks that involve binary and four-class classification.", "labels": [], "entities": []}, {"text": "Subtask A is a two-class (or binary) classification task whereby the system must predict whether or not a tweet is ironic.", "labels": [], "entities": []}, {"text": "The subtask B is a multiclass classification task where the system has to predict one out of four labels describing i) verbal irony realized through a polarity contrast, ii) verbal irony without such a polarity contrast (i.e., other verbal irony), iii) descriptions of situational irony, and iv) non-irony (Cynthia Van Hee and Hoste, 2018).", "labels": [], "entities": []}, {"text": "For a more detailed description, please see.", "labels": [], "entities": []}, {"text": "In recent years, deep learning techniques have significantly outperformed traditional methods in several natural language processing (NLP) tasks.", "labels": [], "entities": []}, {"text": "In such task, several deep learning architecture-based methods have achieved outstanding performance in irony and sarcasm detection in social media.", "labels": [], "entities": [{"text": "irony and sarcasm detection in social media", "start_pos": 104, "end_pos": 147, "type": "TASK", "confidence": 0.7380403407982418}]}, {"text": "presented a novel convolutional network-based method for learning user embeddings from their previous posts and used the user embeddings with lexical signals to recognize sarcasm.", "labels": [], "entities": []}, {"text": "proposed a combined convolutional neural network (CNN) model and long short-term memory (LSTM) method followed by a deep neural network (DNN), which also achieved an improvement compared to traditional machine learning approaches such as support vector machines (SVM).In this paper, we propose an ensemble of multiple deep learning models with a voting classifier in order to enhance the performance of individual neural network models for to detecting the ironic tweets.", "labels": [], "entities": []}, {"text": "We trained six individual classifiers, including LSTMs, bi-directional LSTMs, gated recurrent units (GRUs), bi-directional GRUs, attention-based BiLSTMs and attention-based Bi-GRU.", "labels": [], "entities": []}, {"text": "Thereafter, we use a voting mechanism to combine the results from the six classifiers in order to produce the final prediction label.", "labels": [], "entities": []}, {"text": "The remainder of this paper is organized as follows.", "labels": [], "entities": []}, {"text": "In section 2, we describe the overall structure of our system and the LSTM-based models, as well as the selected individual classifiers.", "labels": [], "entities": []}, {"text": "In section 3, we present the experimental results of our system, and conclusions are drawn in section 4.", "labels": [], "entities": []}], "datasetContent": [{"text": "The training dataset is constructed from 3834 English tweets collected by the organizers by means of searching Twitter for the hashtags #irony, #sar-casm, and #not.", "labels": [], "entities": []}, {"text": "The training dataset for task A consists of tweets with a binary value score (0 or 1)  indicating whether the tweet is ironic.", "labels": [], "entities": []}, {"text": "The training data for subtask B includes tweets with a numeric value corresponding to one of the subcategories, namely ironic by clash, other irony, situational irony and non-ironic.", "labels": [], "entities": []}, {"text": "For subtasks A and B, the content of the tweet is exactly the same apart from the labels.", "labels": [], "entities": []}, {"text": "The organizers also provided aversion with no emoticons or hashtags and one with emoticons or hashtags.", "labels": [], "entities": []}, {"text": "According to people's tweeting habits, emoticons and hashtags are important tools for expressing emotions, thus, we used tweets with these features for training.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Cross-validation results for subtask A.", "labels": [], "entities": []}, {"text": " Table 2: Cross-validation results for subtask B.", "labels": [], "entities": []}, {"text": " Table 3: Evaluation for Subtask A and B.", "labels": [], "entities": []}, {"text": " Table 3. Due to our negligence, we  submitted a wrong result of Subtask B. After the", "labels": [], "entities": []}]}