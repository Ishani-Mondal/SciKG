{"title": [{"text": "ETH-DS3Lab at SemEval-2018 Task 7: Effectively Combining Recurrent and Convolutional Neural Networks for Relation Classification and Extraction", "labels": [], "entities": [{"text": "ETH-DS3Lab", "start_pos": 0, "end_pos": 10, "type": "DATASET", "confidence": 0.9385232329368591}, {"text": "Relation Classification", "start_pos": 105, "end_pos": 128, "type": "TASK", "confidence": 0.9614622592926025}, {"text": "Extraction", "start_pos": 133, "end_pos": 143, "type": "TASK", "confidence": 0.7350142002105713}]}], "abstractContent": [{"text": "Reliably detecting relevant relations between entities in unstructured text is a valuable resource for knowledge extraction, which is why it has awaken significant interest in the field of Natural Language Processing.", "labels": [], "entities": [{"text": "detecting relevant relations between entities in unstructured text", "start_pos": 9, "end_pos": 75, "type": "TASK", "confidence": 0.7554422467947006}, {"text": "knowledge extraction", "start_pos": 103, "end_pos": 123, "type": "TASK", "confidence": 0.7624943256378174}]}, {"text": "In this paper, we present a system for relation classification and extraction based on an ensemble of con-volutional and recurrent neural networks that ranked first in 3 out of the 4 subtasks at Se-mEval 2018 Task 7.", "labels": [], "entities": [{"text": "relation classification and extraction", "start_pos": 39, "end_pos": 77, "type": "TASK", "confidence": 0.8099201545119286}]}, {"text": "We provide detailed explanations and grounds for the design choices behind the most relevant features and analyze their importance.", "labels": [], "entities": []}], "introductionContent": [], "datasetContent": [], "tableCaptions": [{"text": " Table 2: Final parameter values and their explored ranges", "labels": [], "entities": []}, {"text": " Table 3: Precision (P), recall (R) and F 1 -score (F1) in  % on the test set by Subtask", "labels": [], "entities": [{"text": "Precision (P)", "start_pos": 10, "end_pos": 23, "type": "METRIC", "confidence": 0.9373249858617783}, {"text": "recall (R)", "start_pos": 25, "end_pos": 35, "type": "METRIC", "confidence": 0.9495480060577393}, {"text": "F 1 -score (F1)", "start_pos": 40, "end_pos": 55, "type": "METRIC", "confidence": 0.9577984639576503}]}, {"text": " Table 4: Detailed results (Precision (P), recall (R) and  F 1 -score (F1)) in % for each relation type on the test set  for Subtask 1.1", "labels": [], "entities": [{"text": "Precision (P)", "start_pos": 28, "end_pos": 41, "type": "METRIC", "confidence": 0.9288539886474609}, {"text": "recall (R)", "start_pos": 43, "end_pos": 53, "type": "METRIC", "confidence": 0.933131143450737}, {"text": "F 1 -score (F1))", "start_pos": 59, "end_pos": 75, "type": "METRIC", "confidence": 0.9578805480684552}, {"text": "Subtask 1.1", "start_pos": 125, "end_pos": 136, "type": "TASK", "confidence": 0.8540474474430084}]}]}