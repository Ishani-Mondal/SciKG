{"title": [{"text": "ABDN at SemEval-2018 Task 10: Recognising Discriminative Attributes using Context Embeddings and WordNet", "labels": [], "entities": [{"text": "ABDN", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.5075578093528748}, {"text": "Recognising Discriminative Attributes", "start_pos": 30, "end_pos": 67, "type": "TASK", "confidence": 0.9039097825686137}, {"text": "WordNet", "start_pos": 97, "end_pos": 104, "type": "DATASET", "confidence": 0.7011473774909973}]}], "abstractContent": [{"text": "This paper describes the system that we submitted for SemEval-2018 task 10: capturing discriminative attributes.", "labels": [], "entities": [{"text": "SemEval-2018 task 10", "start_pos": 54, "end_pos": 74, "type": "TASK", "confidence": 0.8886062701543173}]}, {"text": "Our system is built upon a simple idea of measuring the attribute word's similarity with each of the two semantically similar words, based on an extended word embedding method and WordNet.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 180, "end_pos": 187, "type": "DATASET", "confidence": 0.9619259238243103}]}, {"text": "Instead of computing the similarities between the attribute and semantically similar words by using standard word embeddings, we propose a novel method that combines word and context embeddings which can better measure similarities.", "labels": [], "entities": []}, {"text": "Our model is simple and effective, which achieves an average F1 score of 0.62 on the test set.", "labels": [], "entities": [{"text": "F1 score", "start_pos": 61, "end_pos": 69, "type": "METRIC", "confidence": 0.9886505007743835}]}], "introductionContent": [{"text": "Capturing discriminative attributes is a novel task, which is very different from classical semantic tasks that model similarities in semantics.", "labels": [], "entities": [{"text": "Capturing discriminative attributes", "start_pos": 0, "end_pos": 35, "type": "TASK", "confidence": 0.8919138113657633}]}, {"text": "The task aims to recognise semantic differences between words.", "labels": [], "entities": []}, {"text": "Traditional semantic similarity evaluation tasks were designed for evaluating the quality of word representations based on the fact that words with similar semantics will be close to each other in vector space.", "labels": [], "entities": [{"text": "semantic similarity evaluation", "start_pos": 12, "end_pos": 42, "type": "TASK", "confidence": 0.7333295543988546}]}, {"text": "Recent state-of-the-art distributed semantic models ( inspired by the success of word2vec () gave good performance in these similarity measure tasks.", "labels": [], "entities": []}, {"text": "Nevertheless, how to capture discriminative attributes between semantically similar words is still a challenge for traditional word embedding methods, because these methods are designed to capture similar semantics.", "labels": [], "entities": []}, {"text": "We have two observations for the nature of the task and the provided data: (1) only limited data is available for model training; (2) the inputs of the model are merely isolated words themselves, which lack context information for applying complex models.", "labels": [], "entities": []}, {"text": "Therefore, we propose a novel framework that differentiates two semantically similar words with the attribute word by using their word and context embeddings.", "labels": [], "entities": []}, {"text": "We experimented with both Continuous Bag of Words (CBOW) and Skip-gram, demonstrating that using the combination of word and context embeddings outperforms using word embeddings alone.", "labels": [], "entities": []}, {"text": "The contribution of this work can be summarised as follows.", "labels": [], "entities": []}, {"text": "We examine word and context embeddings in CBOW and Skip-gram, showing that using both word and context embeddings can better measure the co-occurrence of two words in sentences than simply using word embeddings.", "labels": [], "entities": [{"text": "CBOW", "start_pos": 42, "end_pos": 46, "type": "DATASET", "confidence": 0.8976700305938721}]}, {"text": "Hence our similarity measure can recognise the discriminative attributes of two semantically similar words more accurately.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 2: Experimental results by using word and context embeddings (Feature 1-3).", "labels": [], "entities": []}, {"text": " Table 4: Final results by using CBOW word and context embeddings, and WordNet features (Feature 1-5).", "labels": [], "entities": [{"text": "WordNet", "start_pos": 71, "end_pos": 78, "type": "DATASET", "confidence": 0.9217468500137329}]}]}