{"title": [], "abstractContent": [{"text": "Sentiment analysis plays an important role in E-commerce.", "labels": [], "entities": [{"text": "Sentiment analysis", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.9314024448394775}]}, {"text": "Identifying ironic and sarcastic content in text plays a vital role in inferring the actual intention of the user, and is necessary to increase the accuracy of sentiment analysis.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 148, "end_pos": 156, "type": "METRIC", "confidence": 0.9984096884727478}, {"text": "sentiment analysis", "start_pos": 160, "end_pos": 178, "type": "TASK", "confidence": 0.8639401197433472}]}, {"text": "This paper describes the work on identifying the irony level in twitter texts.", "labels": [], "entities": [{"text": "identifying the irony level in twitter texts", "start_pos": 33, "end_pos": 77, "type": "TASK", "confidence": 0.7749144775526864}]}, {"text": "The system developed by the SSN MLRG1 team in SemEval-2018 for task 3 (irony detection) uses rule based approach for feature selection and MultiLayer Perceptron (MLP) technique to build the model for multiclass irony classification subtask, which classifies the given text into one of the four class labels.", "labels": [], "entities": [{"text": "SSN MLRG1", "start_pos": 28, "end_pos": 37, "type": "TASK", "confidence": 0.7148881256580353}, {"text": "irony detection)", "start_pos": 71, "end_pos": 87, "type": "TASK", "confidence": 0.8890374501546224}, {"text": "multiclass irony classification subtask", "start_pos": 200, "end_pos": 239, "type": "TASK", "confidence": 0.7026438266038895}]}], "introductionContent": [{"text": "Humans have the natural ability to identify the sentiment or the irony intended in a review or comment.", "labels": [], "entities": [{"text": "identify the sentiment or the irony intended in a review or comment", "start_pos": 35, "end_pos": 102, "type": "TASK", "confidence": 0.6709125985701879}]}, {"text": "However, identifying the intention of the user is a difficult task for the machine.", "labels": [], "entities": []}, {"text": "Detecting irony present in a text is critical to sentiment analysis since it will inverse the polarity of the sentiment inferred (.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 49, "end_pos": 67, "type": "TASK", "confidence": 0.9143569767475128}]}, {"text": "Choice of shops, books, movies, hotels and various other services and products is influenced by comments and reviews in social media to a large extent.", "labels": [], "entities": []}, {"text": "Huge amount of data is available in the Internet about the choices people make and their reviews about it.", "labels": [], "entities": []}, {"text": "Irony in texts affects the polarity of the sentiment inferred from them.", "labels": [], "entities": []}, {"text": "Since it gives the text a meaning that is just the opposite to what is actually said, it is called as a polarity reverser.", "labels": [], "entities": []}, {"text": "Irony is studied in various disciplines such as linguistics, philosophy and psychology.", "labels": [], "entities": []}, {"text": "Due to the frequent use of irony in social media, its detection has gained importance in natural language processing, which faces difficulty in achieving a high performance).", "labels": [], "entities": [{"text": "natural language processing", "start_pos": 89, "end_pos": 116, "type": "TASK", "confidence": 0.6643307209014893}]}, {"text": "The potential applications of irony detection include text mining, author profiling, detecting online harassment and sentiment analysis (Van Hee et al., June 2018).", "labels": [], "entities": [{"text": "irony detection", "start_pos": 30, "end_pos": 45, "type": "TASK", "confidence": 0.9032250046730042}, {"text": "text mining", "start_pos": 54, "end_pos": 65, "type": "TASK", "confidence": 0.8348717391490936}, {"text": "author profiling", "start_pos": 67, "end_pos": 83, "type": "TASK", "confidence": 0.7601943612098694}, {"text": "detecting online harassment", "start_pos": 85, "end_pos": 112, "type": "TASK", "confidence": 0.8678564230600992}, {"text": "sentiment analysis", "start_pos": 117, "end_pos": 135, "type": "TASK", "confidence": 0.8932563662528992}]}, {"text": "SSN MLRG1 team has already worked in sentiment analysis tasks conducted in SemEval 2017.", "labels": [], "entities": [{"text": "SSN MLRG1", "start_pos": 0, "end_pos": 9, "type": "DATASET", "confidence": 0.8400969207286835}, {"text": "sentiment analysis tasks", "start_pos": 37, "end_pos": 61, "type": "TASK", "confidence": 0.936163067817688}]}, {"text": "We can identify three types irony namely verbal irony, situational irony and dramatic irony.", "labels": [], "entities": [{"text": "situational irony", "start_pos": 55, "end_pos": 72, "type": "TASK", "confidence": 0.6953560411930084}]}, {"text": "Subtask B in task 3 is a multiclass classification task for classifying a given tweet to one of these four classes: 1.", "labels": [], "entities": [{"text": "multiclass classification task", "start_pos": 25, "end_pos": 55, "type": "TASK", "confidence": 0.7696868777275085}]}, {"text": "verbal irony realized through a polarity contrast, 2.", "labels": [], "entities": [{"text": "verbal irony", "start_pos": 0, "end_pos": 12, "type": "TASK", "confidence": 0.6623413413763046}]}, {"text": "verbal irony without such a polarity contrast, 3.", "labels": [], "entities": [{"text": "verbal irony", "start_pos": 0, "end_pos": 12, "type": "TASK", "confidence": 0.6737245619297028}]}, {"text": "situational irony, and 4. non-irony.", "labels": [], "entities": [{"text": "situational irony", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.7543303668498993}]}], "datasetContent": [{"text": "The dataset consists of 4792 English tweets that are collected between 01/12/2014 and 04/01/2015 from 2676 unique users.", "labels": [], "entities": []}, {"text": "The entire corpus is split into training (80%) and test (20%) sets.", "labels": [], "entities": []}, {"text": "The tweets are manually labeled using a fine grained annotation scheme for irony.", "labels": [], "entities": []}, {"text": "The training dataset is further divided into training set and development test set for system building.", "labels": [], "entities": [{"text": "system building", "start_pos": 87, "end_pos": 102, "type": "TASK", "confidence": 0.8031299412250519}]}, {"text": "The performance of the system is measured using accuracy, precision, recall and F1-score, using formulas shown in Equations 1 to 4.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 48, "end_pos": 56, "type": "METRIC", "confidence": 0.9997405409812927}, {"text": "precision", "start_pos": 58, "end_pos": 67, "type": "METRIC", "confidence": 0.9996640682220459}, {"text": "recall", "start_pos": 69, "end_pos": 75, "type": "METRIC", "confidence": 0.9997555613517761}, {"text": "F1-score", "start_pos": 80, "end_pos": 88, "type": "METRIC", "confidence": 0.9995982050895691}]}, {"text": "where TP denotes True Positive, TN denotes True Negative, FP denotes False Positive, FN denotes False Negative and N denotes total number of tweets.", "labels": [], "entities": [{"text": "TP", "start_pos": 6, "end_pos": 8, "type": "METRIC", "confidence": 0.9474559426307678}, {"text": "FP", "start_pos": 58, "end_pos": 60, "type": "METRIC", "confidence": 0.9673644304275513}, {"text": "False", "start_pos": 69, "end_pos": 74, "type": "METRIC", "confidence": 0.676762044429779}, {"text": "FN", "start_pos": 85, "end_pos": 87, "type": "METRIC", "confidence": 0.97608882188797}, {"text": "False", "start_pos": 96, "end_pos": 101, "type": "METRIC", "confidence": 0.7719165682792664}]}, {"text": "The optimization of the model was performed using different gradient descent algorithms such as SGD, adam, adaGrad, RMSProp and nadam.", "labels": [], "entities": []}, {"text": "Adam and nadam are the widely used optimizers.", "labels": [], "entities": []}, {"text": "Adam (Adaptive Moment Estimation) computes the adaptive learning rates using momentum and RMSProp.", "labels": [], "entities": []}, {"text": "Momentum points the model in the best direction, while RMSProp adapts how far the model goes in that direction on parameter basis.", "labels": [], "entities": []}, {"text": "Nadam combines Nesterov momentum with Adam which is superior to momentum..", "labels": [], "entities": []}, {"text": "We split the training set into training set (80%) and development test set (20%).", "labels": [], "entities": []}, {"text": "The different optimization algorithms were used with the model and nadam optimizer produced better results compared to other algorithms for the development test set.", "labels": [], "entities": []}, {"text": "There are 32 submissions for this particular task.", "labels": [], "entities": []}, {"text": "The model has achieved the following values for the various measures as listed in  From the result, it appears as if the basic text features selected by rule based approach is not enough to detect the irony level in the given text.", "labels": [], "entities": []}, {"text": "Additional features like emoticons and hashtags can be added to the feature set to enhance the performance.", "labels": [], "entities": []}], "tableCaptions": []}