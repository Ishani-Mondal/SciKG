{"title": [{"text": "NTU NLP Lab System at SemEval-2018 Task 10: Verifying Semantic Differences by Integrating Distributional Information and Expert Knowledge", "labels": [], "entities": [{"text": "NTU NLP Lab System", "start_pos": 0, "end_pos": 18, "type": "DATASET", "confidence": 0.9630348831415176}, {"text": "SemEval-2018 Task 10", "start_pos": 22, "end_pos": 42, "type": "TASK", "confidence": 0.5773670971393585}, {"text": "Verifying Semantic Differences", "start_pos": 44, "end_pos": 74, "type": "TASK", "confidence": 0.7232063412666321}]}], "abstractContent": [{"text": "This paper presents the NTU NLP Lab system for the SemEval-2018 Capturing Discrimina-tive Attributes task.", "labels": [], "entities": [{"text": "NTU NLP Lab", "start_pos": 24, "end_pos": 35, "type": "DATASET", "confidence": 0.8728474974632263}, {"text": "SemEval-2018 Capturing Discrimina-tive Attributes task", "start_pos": 51, "end_pos": 105, "type": "TASK", "confidence": 0.8999384999275207}]}, {"text": "Word embeddings, point-wise mutual information (PMI), ConceptNet edges and shortest path lengths are utilized as input features to build binary classifiers to tell whether an attribute is discriminative fora pair of concepts.", "labels": [], "entities": []}, {"text": "Our neural network model reaches about 73% F1 score on the test set and ranks the 3rd in the task.", "labels": [], "entities": [{"text": "F1 score", "start_pos": 43, "end_pos": 51, "type": "METRIC", "confidence": 0.9878492057323456}]}, {"text": "Though the attributes to deal within this task are all visual, our models are not provided with any image data.", "labels": [], "entities": []}, {"text": "The results indicate that visual information can be derived from textual data.", "labels": [], "entities": []}], "introductionContent": [{"text": "Modern semantic models are good at capturing semantic similarity and relatedness.", "labels": [], "entities": []}, {"text": "The widely-used distributional word representations, or word embeddings, have achieved promising performance on various semantic tasks.", "labels": [], "entities": []}, {"text": "The word pair similarities calculated with these models are to some extent consistent with human judgments, and many downstream applications such as sentiment analysis and machine translation have benefited from word embeddings' ability to aggregate the information of lexical items with similar meaning but different surface forms.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 149, "end_pos": 167, "type": "TASK", "confidence": 0.9723515808582306}, {"text": "machine translation", "start_pos": 172, "end_pos": 191, "type": "TASK", "confidence": 0.7819440364837646}]}, {"text": "However, the ability to distinguish one concept from another similar concept is also core to linguistic competence.", "labels": [], "entities": []}, {"text": "Our knowledge about what is a \"subway\", for example, may contain \"it is a kind of train that runs underground\".", "labels": [], "entities": []}, {"text": "Also, discriminating things is an important mechanism for teaching and learning.", "labels": [], "entities": []}, {"text": "For example, if we would like to explain how a \"plate\" is different from a \"bowl\", we may use expressions like \"a plate is flatter\" or \"a bowl is deeper\".", "labels": [], "entities": []}, {"text": "All these examples show that one form of semantic difference is a discriminative attribute which applies to one of the two concepts being compared but does not apply to the other.", "labels": [], "entities": []}, {"text": "In the SemEval-2018 Capturing Discriminative Attributes task (, participants need to put forward semantic models that are aware of semantic differences.", "labels": [], "entities": [{"text": "SemEval-2018 Capturing Discriminative Attributes task", "start_pos": 7, "end_pos": 60, "type": "TASK", "confidence": 0.8671219825744629}]}, {"text": "A data instance consists of a triple and a label.", "labels": [], "entities": []}, {"text": "In this paper, we denote a triple with < w 1 , w 2 , a >, in which w 1 and w 2 are the two words (concepts) to be compared, and a is an attribute.", "labels": [], "entities": []}, {"text": "The label is either positive (1) or negative (0).", "labels": [], "entities": []}, {"text": "Ina positive example, a is an attribute of w 1 but not an attribute of w 2 . For negative examples, there are two cases: 1) both w 1 and w 2 have attribute a ; 2) neither w 1 nor w 2 has attribute a.", "labels": [], "entities": []}, {"text": "In this task, a is limited to visual ones such as color and shape.", "labels": [], "entities": []}, {"text": "The evaluation metric is the macro-averaged F1 score of the positive and the negative classes.", "labels": [], "entities": [{"text": "F1 score", "start_pos": 44, "end_pos": 52, "type": "METRIC", "confidence": 0.9634017050266266}]}, {"text": "Visual attribute learning has been investigated by past researchers.", "labels": [], "entities": [{"text": "Visual attribute learning", "start_pos": 0, "end_pos": 25, "type": "TASK", "confidence": 0.6546067098776499}]}, {"text": "build a dataset of concept-level attribute annotations based on images in ImageNet ().", "labels": [], "entities": []}, {"text": "For each attribute, they train a classifier to predict its presence or absence in the input image.", "labels": [], "entities": []}, {"text": "propose a model that does not learn visual attributes explicitly, but learns discriminativeness.", "labels": [], "entities": []}, {"text": "Their model predicts whether an attribute can be used to discriminate a referent from a context.", "labels": [], "entities": []}, {"text": "Both the referent and the context are represented by visual instances sampled from ImageNet.", "labels": [], "entities": [{"text": "ImageNet", "start_pos": 83, "end_pos": 91, "type": "DATASET", "confidence": 0.9563094973564148}]}, {"text": "This setting is similar to that of this SemEval task.", "labels": [], "entities": [{"text": "SemEval task", "start_pos": 40, "end_pos": 52, "type": "TASK", "confidence": 0.9278813302516937}]}, {"text": "However, one critical difference is that in this task, the set of attributes is open.", "labels": [], "entities": []}, {"text": "The dataset is partitioned so that all the attributes in the test set are unseen in the training set, which makes this task more challenging.", "labels": [], "entities": []}, {"text": "The use of word embeddings for detecting semantic properties is studied by.", "labels": [], "entities": []}, {"text": "They focus on a fixed set of properties and train a binary classifier for each property.", "labels": [], "entities": []}, {"text": "Their results indicate that word embeddings capture taxonomic properties (e.g. \"an animal\") better than attributive properties (e.g. \"is fast\"), possibly because attributive signal is weak in text.", "labels": [], "entities": []}, {"text": "In this task, most visual attributes are attributive properties.", "labels": [], "entities": []}, {"text": "The signal of \"visual\" attributes can be even weaker in text since they are not mainly communicated through language inhuman cognition.", "labels": [], "entities": []}, {"text": "The word \"red\" in \"I bought a red apple\" sounds more like a linguistic redundancy than that in \"I bought a red jacket\" does, since \"red\" is atypical attribute of apples.", "labels": [], "entities": []}, {"text": "However, these visual attributes may impose constraints on valid expressions.", "labels": [], "entities": []}, {"text": "For instance, we can say \"the bananas turned yellow\", but it would be extremely difficult to find some context where \"the bananas turned red\" makes sense.", "labels": [], "entities": []}, {"text": "Therefore, visual attributes can be signaled in some implicit and indirect ways.", "labels": [], "entities": []}, {"text": "By utilizing several computational approaches, we reveal to what extent visual attributes can be acquired from text.", "labels": [], "entities": []}, {"text": "This paper aims at capturing semantic difference by incorporating information from both corpus statistics and expert-constructed knowledge bases.", "labels": [], "entities": [{"text": "capturing semantic difference", "start_pos": 19, "end_pos": 48, "type": "TASK", "confidence": 0.6692514022191366}]}, {"text": "We build a rule-based system and a learning-based system for the binary classification problem, i.e., to tell whether an attribute is discriminative for two concepts.", "labels": [], "entities": []}, {"text": "The learningbased system achieved F1 score of 0.7294, which is the third best in the official evaluation period of SemEval-2018 Task 10.", "labels": [], "entities": [{"text": "F1 score", "start_pos": 34, "end_pos": 42, "type": "METRIC", "confidence": 0.9884012937545776}, {"text": "SemEval-2018 Task 10", "start_pos": 115, "end_pos": 135, "type": "TASK", "confidence": 0.5371313293774923}]}, {"text": "Our approach is purely based on textual data, without access to image instances, which indicates that it is possible to figure out substantial visual information from text.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Training and validation scores of MLP model  with embeddings of different subsets of the triple.", "labels": [], "entities": []}, {"text": " Table 4. However, there is only slight macro-", "labels": [], "entities": []}, {"text": " Table 2: Performance of the sim 1 > sim 2 rule with  different embeddings on the validation set.", "labels": [], "entities": []}, {"text": " Table 3: Confusion matrix of the sim 1 > sim 2 rule  with Numberbatch embeddings on the validation set.", "labels": [], "entities": []}, {"text": " Table 4: Performance of MLP models with different  combinations of word vector similarity differences.", "labels": [], "entities": []}, {"text": " Table 5: Performance of the P M I 1 > P M I 2 rule  with different context windows on the validation set.", "labels": [], "entities": []}, {"text": " Table 6: Confusion matrix of the P M I 1 > P M I 2  rule with context window size 20 on the validation set.", "labels": [], "entities": []}, {"text": " Table 7:  Confusion matrix of the sim 1 >  sim 2 & P M I 1 > P M I 2 rule on the validation set.", "labels": [], "entities": []}, {"text": " Table 8: Performance of MLP models with combina- tions of word vector similarity differences and sign of  PMI differences.", "labels": [], "entities": []}, {"text": " Table 9: Performance of the w 1 \u2192 a & w 2 a  rule with the ConceptNet graph and its extension on  the validation set.", "labels": [], "entities": []}, {"text": " Table 10: Performance of MLP models with Concept- Net edge features on the validation set.", "labels": [], "entities": []}, {"text": " Table 11: Performance of the dis(w 1 , a) < dis(w 2 , a)  rule with the ConceptNet graph and its extension on the  validation set.", "labels": [], "entities": []}, {"text": " Table 12:  Confusion matrix of the dis(w 1 , a) <  dis(w 2 , a) rule (reverse edges considered) on the vali- dation set.", "labels": [], "entities": []}, {"text": " Table 13: Performance of MLP models with one-hot  representation of ConceptNet shortest path lengths on  the validation set.", "labels": [], "entities": []}, {"text": " Table 14: Evaluation results of the two submitted systems.", "labels": [], "entities": []}]}