{"title": [{"text": "YNU Deep at SemEval-2018 Task 11: An Ensemble of Attention-based BiLSTM Models for Machine Comprehension", "labels": [], "entities": [{"text": "YNU Deep at SemEval-2018 Task 11", "start_pos": 0, "end_pos": 32, "type": "DATASET", "confidence": 0.8286252419153849}]}], "abstractContent": [{"text": "This paper reports our submission to task 11 (Machine Comprehension using Common-sense Knowledge) in SemEval 2018.", "labels": [], "entities": [{"text": "Machine Comprehension using Common-sense Knowledge)", "start_pos": 46, "end_pos": 97, "type": "TASK", "confidence": 0.6665003349383672}]}, {"text": "We firstly use GloVe to learn the distributed representations automatically from the instance, question and answer triples.", "labels": [], "entities": [{"text": "GloVe", "start_pos": 15, "end_pos": 20, "type": "DATASET", "confidence": 0.7806181311607361}]}, {"text": "Then an attention-based Bidirectional LSTM (BiLSTM) model is used to encode the triples.", "labels": [], "entities": []}, {"text": "We also perform a simple ensemble method to improve the effectiveness of our model.", "labels": [], "entities": []}, {"text": "The system we developed obtains an encouraging result on this task.", "labels": [], "entities": []}, {"text": "It achieves the accuracy 0.7472 on the test set.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 16, "end_pos": 24, "type": "METRIC", "confidence": 0.9995811581611633}]}, {"text": "We rank 5th according to the official ranking.", "labels": [], "entities": []}], "introductionContent": [{"text": "Machine comprehension of text is one of the ultimate goals of natural language processing.", "labels": [], "entities": [{"text": "Machine comprehension of text", "start_pos": 0, "end_pos": 29, "type": "TASK", "confidence": 0.793775662779808}, {"text": "natural language processing", "start_pos": 62, "end_pos": 89, "type": "TASK", "confidence": 0.6783720354239146}]}, {"text": "The machine comprehension problem can be formulated as follows: Given an instance i, a question q and an answer candidate pool {a 1 , a 2 , . .", "labels": [], "entities": []}, {"text": "., a s }, the aim is to search for the best answer candidate a k , where 1 \u2264 k \u2264 s.", "labels": [], "entities": []}, {"text": "The major challenge of this task is that the words in the answer do not necessarily appear in the instance.", "labels": [], "entities": []}, {"text": "In recent years, deep learning models are widely used in the field of NLP, such as semantic analysis, machine translation () and text summarization (.", "labels": [], "entities": [{"text": "semantic analysis", "start_pos": 83, "end_pos": 100, "type": "TASK", "confidence": 0.8953857719898224}, {"text": "machine translation", "start_pos": 102, "end_pos": 121, "type": "TASK", "confidence": 0.795491486787796}, {"text": "text summarization", "start_pos": 129, "end_pos": 147, "type": "TASK", "confidence": 0.7694899439811707}]}, {"text": "() also introduced the attention mechanism into NLP task for the first time.", "labels": [], "entities": []}, {"text": "This attention-based model yielded stateof-the-art performance on the machine translation task.", "labels": [], "entities": [{"text": "machine translation task", "start_pos": 70, "end_pos": 94, "type": "TASK", "confidence": 0.845158855120341}]}, {"text": "() built a supervised reading comprehension data set, the CNN/Daily Mail data sets 1 . They also presented Attentive Reader for machine comprehension, which allows a model to focus on the aspects of an instance that 1 http://www.github.com/deepmind/rc-data/ can help to answer a question, and also allows us to visualize its inference process (.", "labels": [], "entities": [{"text": "CNN/Daily Mail data sets", "start_pos": 58, "end_pos": 82, "type": "DATASET", "confidence": 0.9438422719637553}]}, {"text": "The key point of the attention-based models is the design of attention function.", "labels": [], "entities": []}, {"text": "Compared to Attentive Reader, Attention Sum Reader () used the dot products instead of a tanh layer to compute the attention between question and contextual embeddings.", "labels": [], "entities": [{"text": "Attention Sum Reader", "start_pos": 30, "end_pos": 50, "type": "TASK", "confidence": 0.6812372008959452}]}, {"text": "Stanford Attention Reader () took a bilinear term as the attention function and obtained stateof-the-art results on the CNN/Daily Mail data sets.", "labels": [], "entities": [{"text": "Stanford Attention Reader", "start_pos": 0, "end_pos": 25, "type": "DATASET", "confidence": 0.8211499055226644}, {"text": "CNN/Daily Mail data sets", "start_pos": 120, "end_pos": 144, "type": "DATASET", "confidence": 0.9545202950636545}]}, {"text": "The reasoning process was implemented in some models for machine comprehension.", "labels": [], "entities": []}, {"text": "Memory Networks () was the first model to propose reasoning process, which had important influence on other follow-up models.", "labels": [], "entities": []}, {"text": "Compared to the traditional attention model, Memory Networks additionally uses a function t that constantly updates the representation of the instance and the question so as to realize the reasoning process.", "labels": [], "entities": []}, {"text": "( proposed an attention-based multi-hop recurrent neural network which achieved good performance on the machine listening comprehension test of TOEFL.", "labels": [], "entities": [{"text": "TOEFL", "start_pos": 144, "end_pos": 149, "type": "DATASET", "confidence": 0.819551408290863}]}, {"text": "Other reasoning models ( shared the same idea as previous models, i.e., the representations of the instance and the question embedding were updated through continuous conversion of attention.", "labels": [], "entities": []}, {"text": "Some more complex models ( were proposed based on SQuAD data set (.", "labels": [], "entities": [{"text": "SQuAD data set", "start_pos": 50, "end_pos": 64, "type": "DATASET", "confidence": 0.8959906895955404}]}, {"text": "Their performances have been very close to or even exceeded the human performance on this dataset.", "labels": [], "entities": []}, {"text": "In this paper, we introduce a simple ensemble method on multiple identical attention-based BiL-STM models, only changing the dropout parameters in each model.", "labels": [], "entities": []}, {"text": "We use each model to generate a soft prediction, and sum each result, then take the sum as the final prediction result.", "labels": [], "entities": []}, {"text": "Experiments show that the ensemble model is about 2% higher than the single model in terms of accuracy on both development and test sets.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 94, "end_pos": 102, "type": "METRIC", "confidence": 0.9995290040969849}]}, {"text": "Besides, we also made our code available online 2 .", "labels": [], "entities": []}], "datasetContent": [{"text": "We run each model 10 times, taking the average results as the final experimental results to enhance reliability.", "labels": [], "entities": []}, {"text": "In all single models, the dropout parameter is taken as 0.3, and the ensemble model is trained through 5 BiLSTM models.", "labels": [], "entities": []}, {"text": "Their dropout parameters are changed from 0.2 to 0.6, respectively, and then the results of the 5 models are summed as the final prediction.", "labels": [], "entities": []}, {"text": "We set epoch = 6, batch size = 512 and LSTM Units = 64.", "labels": [], "entities": [{"text": "epoch", "start_pos": 7, "end_pos": 12, "type": "METRIC", "confidence": 0.9567570090293884}]}, {"text": "Optimization is carried out using Adaptive Moment Estimation (Adam).", "labels": [], "entities": [{"text": "Adaptive Moment Estimation (Adam)", "start_pos": 34, "end_pos": 67, "type": "METRIC", "confidence": 0.7287773291269938}]}, {"text": "We compare two word embedding tools, Word2Vec and GloVe, and the experimental results show that GloVe almost always outperforms Word2Vec on this task.", "labels": [], "entities": [{"text": "Word2Vec", "start_pos": 37, "end_pos": 45, "type": "DATASET", "confidence": 0.9618566632270813}]}, {"text": "Although the vocabularies in GloVe are less than those in Word2Vec, GloVe contains more abbreviations, which are especially useful after tokenizing the instance, question and answer triples, and greatly reduce the number of unknown words in word embedding, making the context semantics better learned by the model.", "labels": [], "entities": []}, {"text": "We make random assignments on unknown words, ranging from -0.25 to 0.25.", "labels": [], "entities": []}, {"text": "We can see GloVe performs better, but its loading time is much longer than that of Word2Vec.", "labels": [], "entities": [{"text": "Word2Vec", "start_pos": 83, "end_pos": 91, "type": "DATASET", "confidence": 0.959966778755188}]}, {"text": "As seen in, we compare two network architectures, LSTM and BiLSTM.", "labels": [], "entities": []}, {"text": "The results show that the BiLSTM model performs better than the LSTM model on this task.", "labels": [], "entities": [{"text": "BiLSTM", "start_pos": 26, "end_pos": 32, "type": "METRIC", "confidence": 0.8218147158622742}]}, {"text": "Based on Glove word embedding and BiLSTM architecture, we train 5 single models for ensemble.", "labels": [], "entities": []}, {"text": "The only difference between them is the difference in dropout parameters, which increases from 0.2 to 0.6.", "labels": [], "entities": []}, {"text": "In our experiments, we train the  single model with the dropout in order of 0.3, 0.5, 0.4, 0.2, 0.6, then the first ensemble is the result of adding the first two models with the dropout of 0.3, 0.5 as the predictive result, the result of the second ensemble is based on the first ensemble plus the single model with dropout of 0.4, and soon.", "labels": [], "entities": []}, {"text": "We perform a total of 4 ensemble experiments, the results show that the accuracy of each ensemble model improved on both datasets.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 72, "end_pos": 80, "type": "METRIC", "confidence": 0.9996005892753601}]}, {"text": "The final ensemble model has an accuracy rate of 0.7699 on the development set and 0.7472 on the test set.", "labels": [], "entities": [{"text": "accuracy rate", "start_pos": 32, "end_pos": 45, "type": "METRIC", "confidence": 0.9912532866001129}]}, {"text": "However, we find that our model was slightly more accurate on the test set without the ensemble of the model with a dropout of 0.6, but the overall effect is not obvious.", "labels": [], "entities": []}, {"text": "Ensemble makes our model perform well on this task, ranking 5th out of 11 submissions.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Comparison between Word2Vec and GloVe  tools on BiLSTM models. Ukw is the number of un- known words. Time is the loading time of two tools.", "labels": [], "entities": [{"text": "Word2Vec", "start_pos": 29, "end_pos": 37, "type": "DATASET", "confidence": 0.9377738237380981}, {"text": "Ukw", "start_pos": 73, "end_pos": 76, "type": "METRIC", "confidence": 0.9945902824401855}, {"text": "Time", "start_pos": 111, "end_pos": 115, "type": "METRIC", "confidence": 0.983343780040741}]}, {"text": " Table 3: Comparison between LSTM and BiLSTM.  BiLSTM performs better than LSTM on both datasets.", "labels": [], "entities": []}, {"text": " Table 4: Results on single and ensemble models. All  models adopt GloVe + Attention-based BiLSTM archi- tecture. The dropout layer is behind the BiLSTM layer.", "labels": [], "entities": []}]}