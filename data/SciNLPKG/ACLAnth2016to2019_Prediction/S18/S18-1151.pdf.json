{"title": [{"text": "ADAPT at SemEval-2018 Task 9: Skip-Gram Word Embeddings for Unsupervised Hypernym Discovery in Specialised Corpora", "labels": [], "entities": [{"text": "ADAPT", "start_pos": 0, "end_pos": 5, "type": "METRIC", "confidence": 0.4420642554759979}, {"text": "Unsupervised Hypernym Discovery", "start_pos": 60, "end_pos": 91, "type": "TASK", "confidence": 0.6923395395278931}]}], "abstractContent": [{"text": "This paper describes a simple but competitive unsupervised system for hypernym discovery.", "labels": [], "entities": [{"text": "hypernym discovery", "start_pos": 70, "end_pos": 88, "type": "TASK", "confidence": 0.9082481563091278}]}, {"text": "The system uses skip-gram word embeddings with negative sampling, trained on specialised corpora.", "labels": [], "entities": []}, {"text": "Candidate hypernyms for an input word are predicted based on cosine similarity scores.", "labels": [], "entities": []}, {"text": "Two sets of word embedding models were trained separately on two specialised corpora: a medical corpus and a music industry corpus.", "labels": [], "entities": []}, {"text": "Our system scored highest in the medical domain among the competing unsu-pervised systems but performed poorly on the music industry domain.", "labels": [], "entities": []}, {"text": "Our approach does not depend on any external data other than raw specialised corpora.", "labels": [], "entities": []}], "introductionContent": [{"text": "The SemEval-2018 shared task on Hypernymy Discovery sought to study approaches for identifying words that hold a hypernymic relation.", "labels": [], "entities": [{"text": "Hypernymy Discovery", "start_pos": 32, "end_pos": 51, "type": "TASK", "confidence": 0.7131944447755814}]}, {"text": "Two words have a hypernymic relation if one of the words belongs to a taxonomical class that is more general than that of the other word.", "labels": [], "entities": []}, {"text": "For example, the word vehicle belongs to a more general taxonomical class than car does, as car is a type of vehicle.", "labels": [], "entities": []}, {"text": "Hypernymy can be seen as an is-a relationship.", "labels": [], "entities": []}, {"text": "Hypernymy has been studied from different angles in the natural language processing literature as it is related to the human cognitive ability of generalisation.", "labels": [], "entities": []}, {"text": "This shared task differs from recent taxonomy evaluation tasks () by concentrating on Hypernym Discovery: the task of predicting (discovering) n hypernym candidates fora given input word, within the vocabulary of a specific domain.", "labels": [], "entities": [{"text": "Hypernym Discovery", "start_pos": 86, "end_pos": 104, "type": "TASK", "confidence": 0.764973908662796}, {"text": "predicting (discovering) n hypernym candidates fora given input word", "start_pos": 118, "end_pos": 186, "type": "TASK", "confidence": 0.7645234032110735}]}, {"text": "This shared task provided a general language domain vocabulary and two specialised domain vocabularies in English: medical and music industry.", "labels": [], "entities": []}, {"text": "For each vocabulary, a reference corpus was also supplied.", "labels": [], "entities": []}, {"text": "In addition to these English vocabularies, general language domain vocabularies for Spanish and Italian were also provided.", "labels": [], "entities": []}, {"text": "The ADAPT team focused on the two specialised domain English subtasks by developing an unsupervised system that builds word embeddings from the supplied reference corpora for these domains.", "labels": [], "entities": [{"text": "ADAPT", "start_pos": 4, "end_pos": 9, "type": "DATASET", "confidence": 0.8590277433395386}]}, {"text": "Word embeddings trained on large corpora have been shown to capture semantic relations between words, including hypernym-hyponym relations.", "labels": [], "entities": []}, {"text": "The word embeddings built and used by the system presented here exploit this property.", "labels": [], "entities": []}, {"text": "Although these word embeddings do not distinguish one semantic relation from another, we expect that true hypernyms will constitute a significant proportion of the predicted candidate hypernyms.", "labels": [], "entities": []}, {"text": "Indeed, we show that for the medical domain subtask, our system beats the other unsupervised systems, although it still ranks behind the supervised systems.", "labels": [], "entities": []}, {"text": "Even though unsupervised systems tend to rank behind supervised systems in NLP tasks in general, our motivation to focus on an unsupervised approach is derived from the fact that they do not require explicit hand-annotated data, and from the expectation that they are able to generalise more easily to unseen hypernym-hyponym pairs.", "labels": [], "entities": []}, {"text": "The rest of this system description paper is organised as follows: Section 2 briefly surveys the relevant literature and explains the reasons for choosing to use a particular flavour of word embeddings.", "labels": [], "entities": []}, {"text": "Section 3 describes the components of the system and its settings.", "labels": [], "entities": []}, {"text": "Section 4 summarises the results and offers some insights behind the numbers.", "labels": [], "entities": []}, {"text": "Section 5 concludes and proposes avenues for future work.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Automatic evaluation results for the submitted system (SGNS) and a Hypervec variant (HV).", "labels": [], "entities": []}]}