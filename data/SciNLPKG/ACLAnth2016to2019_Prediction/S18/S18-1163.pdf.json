{"title": [{"text": "BomJi at SemEval-2018 Task 10: Combining Vector-, Pattern-and Graph-based Information to Identify Discriminative Attributes", "labels": [], "entities": [{"text": "BomJi", "start_pos": 0, "end_pos": 5, "type": "DATASET", "confidence": 0.8987075090408325}]}], "abstractContent": [{"text": "This paper describes BomJi, a supervised system for capturing discriminative attributes in word pairs (e.g. yellow as discriminative for banana over watermelon).", "labels": [], "entities": []}, {"text": "The system relies on an XGB classifier trained on carefully engineered graph-, pattern-and word embedding-based features.", "labels": [], "entities": []}, {"text": "It participated in the SemEval-2018 Task 10 on Capturing Discriminative Attributes , achieving an F1 score of 0.73 and ranking 2nd out of 26 participant systems.", "labels": [], "entities": [{"text": "SemEval-2018 Task 10", "start_pos": 23, "end_pos": 43, "type": "TASK", "confidence": 0.7743500669797262}, {"text": "Capturing Discriminative Attributes", "start_pos": 47, "end_pos": 82, "type": "TASK", "confidence": 0.8168129722277323}, {"text": "F1 score", "start_pos": 98, "end_pos": 106, "type": "METRIC", "confidence": 0.9859353005886078}]}], "introductionContent": [{"text": "The recent introduction of popular software packages for training neural word embeddings () has led to an increase of the number of studies dedicated to lexical similarity and to remarkable performance improvements on related tasks ().", "labels": [], "entities": []}, {"text": "However, the validity of similarity estimation as the only benchmark for semantic representations has been questioned, for several reasons.", "labels": [], "entities": [{"text": "similarity estimation", "start_pos": 25, "end_pos": 46, "type": "TASK", "confidence": 0.697230651974678}]}, {"text": "One for all, most evaluation datasets provide human-elicited similarity scores, with the consequences that the ratings are subjective and the performance of some automated systems is already above the upper bound of the inter-annotator agreement (.", "labels": [], "entities": []}, {"text": "Originally proposed as an alternative benchmark for Distributional Semantic Models (DSMs), the Discriminative Attributes task focuses instead on the extraction of semantic differences between lexical meanings (: given two words and an attribute (i.e., a discrete semantic feature), a system has to predict whether the attribute describes a difference between the corresponding concepts or not (e.g. wing is an attribute of plane, but not of helicopter).", "labels": [], "entities": [{"text": "Distributional Semantic Models (DSMs)", "start_pos": 52, "end_pos": 89, "type": "TASK", "confidence": 0.6505982925494512}]}, {"text": "Since even related words may differ for some non-shared attributes (e.g. hypernyms and hyponyms), the ability of automatically recognize discriminative features would bean extremely useful addition for the creation of ontologies and other types of lexical resources and would make machine decisions interpretable, enabling human validation ( ).", "labels": [], "entities": []}, {"text": "Moreover, one can think to applications to many other NLP domains, such as machine translation and dialogue systems (.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 75, "end_pos": 94, "type": "TASK", "confidence": 0.8304890990257263}]}, {"text": "In the present contribution, we describe the BomJi classification system, which we used for the identification of discriminative features between concept pairs.", "labels": [], "entities": [{"text": "BomJi classification", "start_pos": 45, "end_pos": 65, "type": "TASK", "confidence": 0.661417081952095}, {"text": "identification of discriminative features between concept pairs", "start_pos": 96, "end_pos": 159, "type": "TASK", "confidence": 0.8124116318566459}]}, {"text": "According to the official evaluation results provided by the organizers 1 , our system ranked second out of 26 participants.", "labels": [], "entities": []}, {"text": "Our score, F 1 = 0.73 lags slightly behind the best score of 0.75.", "labels": [], "entities": [{"text": "F 1", "start_pos": 11, "end_pos": 14, "type": "METRIC", "confidence": 0.9919557273387909}]}, {"text": "After the evaluation period, we run further experiments including all investigated features and found that the system can achieve up to 0.75 F1 score.", "labels": [], "entities": [{"text": "F1 score", "start_pos": 141, "end_pos": 149, "type": "METRIC", "confidence": 0.9820917546749115}]}], "datasetContent": [{"text": "The task of capturing discriminative attributes between words can be described as a binary classification task, in which the system has to assign a positive label if the feature is discriminative for the first concept over the second one, and a negative label otherwise.", "labels": [], "entities": []}, {"text": "In the test data, the first two words correspond to the concepts being compared (they are called, respectively, the pivot and the comparison term) and the third word is the feature, which could describe a discriminative attribute or not (some examples are shown in).", "labels": [], "entities": []}, {"text": "In the paper, we will refer  to the elements of the triples as w1, and feat.", "labels": [], "entities": []}, {"text": "A training and validation set have been provided for system development (figures in).", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Examples of triples from the training dataset.", "labels": [], "entities": []}, {"text": " Table 2: Number of examples, distinctive features and  Positive-Negative split for each dataset.", "labels": [], "entities": []}, {"text": " Table 3: Results both in absolute (F1) and in incremental terms (F1++: in brackets the features used to obtain the  score) on the test set, organized by training set. In bold, we report the best results. In bold-italics, we report the  submitted systems.", "labels": [], "entities": [{"text": "F1", "start_pos": 36, "end_pos": 38, "type": "METRIC", "confidence": 0.9910426139831543}, {"text": "F1", "start_pos": 66, "end_pos": 68, "type": "METRIC", "confidence": 0.9936152696609497}]}]}