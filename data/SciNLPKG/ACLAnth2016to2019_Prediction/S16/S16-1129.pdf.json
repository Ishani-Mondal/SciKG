{"title": [{"text": "Building a Feature-Rich System for Community Question Answering", "labels": [], "entities": [{"text": "Community Question Answering", "start_pos": 35, "end_pos": 63, "type": "TASK", "confidence": 0.6327218512694041}]}], "abstractContent": [{"text": "We present the system we built for participating in SemEval-2016 Task 3 on Community Question Answering.", "labels": [], "entities": [{"text": "SemEval-2016 Task 3 on Community Question Answering", "start_pos": 52, "end_pos": 103, "type": "TASK", "confidence": 0.7021160168307168}]}, {"text": "We achieved the best results on subtask C, and strong results on subtasks A and B, by combining a rich set of various types of features: semantic, lexical, metadata, and user-related.", "labels": [], "entities": []}, {"text": "The most important group turned out to be the metadata for the question and for the comment, semantic vectors trained on QatarLiving data and similarities between the question and the comment for subtasks A and C, and between the original and the related question for Subtask B.", "labels": [], "entities": [{"text": "QatarLiving data", "start_pos": 121, "end_pos": 137, "type": "DATASET", "confidence": 0.9583311676979065}]}], "introductionContent": [{"text": "SemEval-2016 Task 3 on Community Question Answering 1 ) aims to solve a reallife application problem.", "labels": [], "entities": [{"text": "SemEval-2016 Task 3 on Community Question Answering", "start_pos": 0, "end_pos": 51, "type": "TASK", "confidence": 0.6652788519859314}]}, {"text": "The main subtask C (Question-External Comment Similarity) asks to find an answer in the forum that will be appropriate as a response to a newly posted question.", "labels": [], "entities": [{"text": "Question-External Comment Similarity)", "start_pos": 20, "end_pos": 57, "type": "TASK", "confidence": 0.6680220067501068}]}, {"text": "This is achieved by retrieving similar questions and ranking their answers with respect to the new question.", "labels": [], "entities": []}, {"text": "Two additional supporting subtasks are defined: Subtask A (Question-Comment Similarity): Given a question from a question-comment thread, rank the comments within the thread based on their relevance with respect to the question.", "labels": [], "entities": [{"text": "Question-Comment Similarity)", "start_pos": 59, "end_pos": 87, "type": "TASK", "confidence": 0.7036069929599762}]}, {"text": "Subtask B (Question-Question Similarity): Given anew question, re-rank the similar questions retrieved by a search engine with respect to that question.", "labels": [], "entities": [{"text": "Question-Question Similarity)", "start_pos": 11, "end_pos": 40, "type": "TASK", "confidence": 0.760586162408193}]}, {"text": "1 http://alt.qcri.org/semeval2016/task3/", "labels": [], "entities": []}], "datasetContent": [{"text": "We grouped our features in several groups and we ran experiments by excluding some of them in order to identify the most important types of features.", "labels": [], "entities": []}, {"text": "In particular, we used the LibSVM fselect script for feature selection.", "labels": [], "entities": [{"text": "LibSVM fselect script", "start_pos": 27, "end_pos": 48, "type": "DATASET", "confidence": 0.8834573825200399}, {"text": "feature selection", "start_pos": 53, "end_pos": 70, "type": "TASK", "confidence": 0.73050457239151}]}, {"text": "We achieved the best results by combining the features with the semantic vectors of the question and of the comment trained on QatarLiving data.", "labels": [], "entities": [{"text": "QatarLiving data", "start_pos": 127, "end_pos": 143, "type": "DATASET", "confidence": 0.9816985428333282}]}, {"text": "In, we present the results for Semeval-2016 Task 3, Subtask A using all features, as well as when excluding individual feature groups.", "labels": [], "entities": [{"text": "Semeval-2016 Task 3", "start_pos": 31, "end_pos": 50, "type": "TASK", "confidence": 0.7749225894610087}]}, {"text": "Our primary submission includes the top-rated features and semantic vectors.", "labels": [], "entities": []}, {"text": "We selected our primary submission as it achieved higher score on Dev than Contrastive1 and Contrastive2.", "labels": [], "entities": [{"text": "Dev", "start_pos": 66, "end_pos": 69, "type": "DATASET", "confidence": 0.8676586747169495}]}, {"text": "Compared to Contrastive-1, our Primary has some additional features: number of user comments in the thread, cosine between the comment text with question subject and category, more locations and organizations.", "labels": [], "entities": []}, {"text": "Our Contrastive-1 submission included the top-rated features and semantic vectors, and our Contrastive-2 submission included the same features as our Primary submission, but used Dev-2016 as additional training set.", "labels": [], "entities": []}, {"text": "In, we show the results for Semeval-2016 Task 3, Subtask C using all features, as well as when excluding individual feature groups.", "labels": [], "entities": [{"text": "Semeval-2016 Task 3", "start_pos": 28, "end_pos": 47, "type": "TASK", "confidence": 0.8025667468706766}]}, {"text": "Our Primary submission includes all features excluding user statistics and troll features.", "labels": [], "entities": []}, {"text": "Our Contrastive-1 submission includes all features, including PMI, while Contrastive-2 includes all features, excluding PMI.", "labels": [], "entities": []}, {"text": "have shown that the most important feature groups are the metadata characteristics, the distance measures between the question and the comment, and the semantic vectors.", "labels": [], "entities": []}, {"text": "Other features that fselect scored highly are the credibility score, text readability measures and the number of tokens of some parts of speech in the comment text (namely, number of adjectives and nouns).", "labels": [], "entities": []}, {"text": "The least useful features are statistics about the forum users and characteristics of the question: question length and number of tokens of different parts of speech in the question text.", "labels": [], "entities": []}, {"text": "In all above reported results, we used vectors for which we achieved the best results on the development dataset.", "labels": [], "entities": []}, {"text": "In, we present the results from experiments with semantic vectors.", "labels": [], "entities": []}, {"text": "We experimented with pre-trained vectors from Google News and we also trained vectors with word2vec on the unannotated Qatar Living forum data.", "labels": [], "entities": [{"text": "Qatar Living forum data", "start_pos": 119, "end_pos": 142, "type": "DATASET", "confidence": 0.9765959680080414}]}, {"text": "When training vectors on Qatar Living data, we experimented with different vector sizes and minimum word frequencies.", "labels": [], "entities": [{"text": "Qatar Living data", "start_pos": 25, "end_pos": 42, "type": "DATASET", "confidence": 0.9575032790501913}]}, {"text": "We also added the following entities as words: numbers, images, URLs, smileys (referred to in the table as \"special symbols\").", "labels": [], "entities": []}, {"text": "We achieved best results with vectors from QatarLiving, vector size 100, and minimum word frequency of 5.", "labels": [], "entities": [{"text": "QatarLiving", "start_pos": 43, "end_pos": 54, "type": "DATASET", "confidence": 0.9576897025108337}, {"text": "minimum word frequency", "start_pos": 77, "end_pos": 99, "type": "METRIC", "confidence": 0.835435132185618}]}, {"text": "Including special symbols as words also improved the results.", "labels": [], "entities": []}, {"text": "We experimented with calculating the centroids of the question and of the comment using specific parts of speech only; however, ultimately we found that using all words from all parts of speech worked best.", "labels": [], "entities": []}, {"text": "For Subtask B, we used a similar approach as for Subtask A: we passed to the classifier the semantic vectors of the original and of the related question, some metadata and distance features.", "labels": [], "entities": []}, {"text": "However, we could not experiment much with this subtask, and thus our results are not as strong, as shows.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Subtask A: Experiments with all features and excluding some feature groups.", "labels": [], "entities": []}, {"text": " Table 2: Subtask C. Experiments with all features and excluding some feature groups.", "labels": [], "entities": []}, {"text": " Table 3: Subtask B. Experiments with the different feature sets for the related and the original question.", "labels": [], "entities": []}, {"text": " Table 4: Selection of semantic vectors. Experiments with dif-", "labels": [], "entities": []}]}