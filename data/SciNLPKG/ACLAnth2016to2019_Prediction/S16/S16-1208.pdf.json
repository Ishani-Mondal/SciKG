{"title": [{"text": "TALN at SemEval-2016 Task 14: Semantic Taxonomy Enrichment Via Sense-Based Embeddings", "labels": [], "entities": [{"text": "Semantic Taxonomy Enrichment", "start_pos": 30, "end_pos": 58, "type": "TASK", "confidence": 0.6360214253266653}]}], "abstractContent": [{"text": "This paper describes the participation of the TALN team in SemEval-2016 Task 14: Semantic Taxonomy Enrichment.", "labels": [], "entities": [{"text": "SemEval-2016 Task 14", "start_pos": 59, "end_pos": 79, "type": "TASK", "confidence": 0.8481563329696655}, {"text": "Semantic Taxonomy Enrichment", "start_pos": 81, "end_pos": 109, "type": "TASK", "confidence": 0.7342813611030579}]}, {"text": "The purpose of the task is to find the best point of attachment in WordNet fora set of Out of Vocabulary (OOV) terms.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 67, "end_pos": 74, "type": "DATASET", "confidence": 0.9322378635406494}]}, {"text": "These may come, to name a few, from domain specific glossaries, slang or typical jargon from Internet forums and cha-trooms.", "labels": [], "entities": []}, {"text": "Our contribution takes as input an OOV term, its part of speech and its associated definition, and generates a set of WordNet synset candidates derived from modelling the term's definition as a sense embedding representation.", "labels": [], "entities": []}, {"text": "We leverage a BabelNet-based vector space representation, which allows us to map the algorithm's prediction to WordNet.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 111, "end_pos": 118, "type": "DATASET", "confidence": 0.9664857387542725}]}, {"text": "Our approach is designed to be generic and fitting to any domain, without exploiting, for instance, HTML markup in source web pages.", "labels": [], "entities": []}, {"text": "Our system performs above the median of all submitted systems, and rivals in performance a powerful baseline based on extracting the first word of the definition with the same part-of-speech as the OOV term.", "labels": [], "entities": []}], "introductionContent": [{"text": "Semantic knowledge, expressed in terms of concepts and relations holding among them, is an essential enabling component of NLP applications.", "labels": [], "entities": []}, {"text": "One of the best known semantic repository is WordNet (), a manually created semantic network with a coverage of over 200k English senses and 155k word forms.", "labels": [], "entities": []}, {"text": "However, as knowledge domains advance and expand, novel terms beyond the coverage of WordNet are coined on a regular basis.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 85, "end_pos": 92, "type": "DATASET", "confidence": 0.9500333070755005}]}, {"text": "Thus, the need for automatic approaches which are able to gather information from unstructured online sources and structure them is in high demand.", "labels": [], "entities": []}, {"text": "In this context, WordNet has become the reference semantic network in previous attempts to formalize novel knowledge.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 17, "end_pos": 24, "type": "DATASET", "confidence": 0.9327404499053955}]}, {"text": "The SemEval-2016 Task 14: Semantic Taxonomy Enrichment aims at providing an experimental ground on the task of, given an Out-of-Vocabulary (OOV) term, and an associated definition and part of speech, find the best point of attachment in WordNet (its most similar synset).", "labels": [], "entities": [{"text": "Semantic Taxonomy Enrichment", "start_pos": 26, "end_pos": 54, "type": "TASK", "confidence": 0.63229967157046}, {"text": "WordNet", "start_pos": 237, "end_pos": 244, "type": "DATASET", "confidence": 0.9615801572799683}]}, {"text": "This is a challenging problem because an OOV term maybe defined without any explicit mention to its closest WordNet synset.", "labels": [], "entities": [{"text": "WordNet synset", "start_pos": 108, "end_pos": 122, "type": "DATASET", "confidence": 0.9404316246509552}]}, {"text": "For instance, for the OOV term (from training data) \"lectionary\", the associated definition is \"The book that contains all the readings from the Scriptures for use in the celebration of the liturgy\", and the best point of attachment is sacred text#n#01.", "labels": [], "entities": []}, {"text": "However, if one was to simply obtain the first headword of the definition and retrieve its first sense, the result would be book#n#01, with a score of 0.125/1 according to the official evaluation metric (see Section 4).", "labels": [], "entities": []}, {"text": "In this paper we describe our approach to such task.", "labels": [], "entities": []}, {"text": "We base our method on the intuition that unseen terminology maybe understood in terms of how terms are defined.", "labels": [], "entities": []}, {"text": "Hence, we propose an algorithm which, for each definition, performs partof-speech tagging and parsing, generates a set of noun and verb phrases, and then takes advantage of a vector space representation of word and phrase senses for modelling the definition.", "labels": [], "entities": [{"text": "partof-speech tagging and parsing", "start_pos": 68, "end_pos": 101, "type": "TASK", "confidence": 0.7059928625822067}]}, {"text": "Our algorithm produces several WordNet attachment candidates as the modelling takes place, e.g. by obtaining the definition's centroid and mapping it to WordNet, or by parsing the OOV term and searching fora mapping between its head and WordNet.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 153, "end_pos": 160, "type": "DATASET", "confidence": 0.9595698118209839}, {"text": "WordNet", "start_pos": 237, "end_pos": 244, "type": "DATASET", "confidence": 0.9714758992195129}]}, {"text": "For this task, we submitted the three runs of our system with the highest scores on the training data.", "labels": [], "entities": []}, {"text": "Moreover, the task organizers provided two baselines: One which selected a random WordNet synset, and one which extracted the first word in the definition with the same part-of-speech, and assigned it its first sense in WordNet (BaselineFirst).", "labels": [], "entities": [{"text": "WordNet", "start_pos": 220, "end_pos": 227, "type": "DATASET", "confidence": 0.9597941040992737}]}, {"text": "The experimental results suggest that the baseline was a very strong competitor, ranking way above the median of the participating systems.", "labels": [], "entities": []}, {"text": "Our best run was 3 points below the baseline and 5 points above the median according to a metric designed to compute the distance between two nodes in a hierarchical cluster (see Section 4).", "labels": [], "entities": []}, {"text": "The rest of this paper is structured as follows: After presenting an overview of related work (Section 2), we describe in detail the methodology followed for our submission (Section 3), then we provide evaluation results as compared with baseline systems and the participants' median score, along with a discussion of a few interesting cases.", "labels": [], "entities": []}, {"text": "Finally, we outline directions of future work in a novel and exciting task, which opens a very interesting research problem to be tackled in the future.", "labels": [], "entities": []}], "datasetContent": [{"text": "Evaluation is performed over several criteria.", "labels": [], "entities": []}, {"text": "First, the distance between the selected point of attachment and the gold standard is computed via the Wu & Palmer similarity (W&P) (.", "labels": [], "entities": [{"text": "Palmer similarity (W&P)", "start_pos": 108, "end_pos": 131, "type": "METRIC", "confidence": 0.8256502066339765}]}, {"text": "Second, a Recall measure (R), aimed at allowing systems to not provide an answer in doubtful cases, where the chances of an incorrect attachment would be high.", "labels": [], "entities": [{"text": "Recall measure (R)", "start_pos": 10, "end_pos": 28, "type": "METRIC", "confidence": 0.9647047996520997}]}, {"text": "It is simply computed as the percentage of items answered by the system.", "labels": [], "entities": []}, {"text": "Finally, a score on lemma match (LM) is provided, in order to cover cases where the system identifies a correct lemma but selects the wrong sense of the lemma.", "labels": [], "entities": [{"text": "score on lemma match (LM)", "start_pos": 11, "end_pos": 36, "type": "METRIC", "confidence": 0.7860260350363595}]}], "tableCaptions": [{"text": " Table 1: Evaluation summary for our submission", "labels": [], "entities": [{"text": "submission", "start_pos": 37, "end_pos": 47, "type": "TASK", "confidence": 0.7287695407867432}]}]}