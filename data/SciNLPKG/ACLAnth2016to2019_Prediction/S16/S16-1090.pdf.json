{"title": [{"text": "HHU at SemEval-2016 Task 1: Multiple Approaches to Measuring Semantic Textual Similarity", "labels": [], "entities": []}], "abstractContent": [{"text": "This paper describes our participation in the SemEval-2016 Task 1: Semantic Textual Similarity (STS).", "labels": [], "entities": [{"text": "SemEval-2016 Task 1: Semantic Textual Similarity (STS)", "start_pos": 46, "end_pos": 100, "type": "TASK", "confidence": 0.759413343667984}]}, {"text": "We developed three methods for the English subtask (STS Core).", "labels": [], "entities": [{"text": "STS Core)", "start_pos": 52, "end_pos": 61, "type": "DATASET", "confidence": 0.9628614783287048}]}, {"text": "The first method is unsupervised and uses WordNet and word2vec to measure a token-based overlap.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 42, "end_pos": 49, "type": "DATASET", "confidence": 0.9625903367996216}]}, {"text": "In our second approach, we train a neural network on two features.", "labels": [], "entities": []}, {"text": "The third method uses word2vec and LDA with regression splines.", "labels": [], "entities": []}], "introductionContent": [{"text": "Measuring semantic textual similarity (STS) is the task of determining the similarity between two different text passages.", "labels": [], "entities": [{"text": "Measuring semantic textual similarity (STS)", "start_pos": 0, "end_pos": 43, "type": "TASK", "confidence": 0.7092835094247546}]}, {"text": "The task is important for various natural language processing tasks like topic detection or automated text summarization because languages are versatile and authors can express similar content or even the same content with different words.", "labels": [], "entities": [{"text": "topic detection", "start_pos": 73, "end_pos": 88, "type": "TASK", "confidence": 0.9169487655162811}, {"text": "text summarization", "start_pos": 102, "end_pos": 120, "type": "TASK", "confidence": 0.698183074593544}]}, {"text": "Predicting semantic textual similarity has been a recurring task in SemEval challenges).", "labels": [], "entities": [{"text": "Predicting semantic textual similarity", "start_pos": 0, "end_pos": 38, "type": "TASK", "confidence": 0.7642365545034409}, {"text": "SemEval challenges", "start_pos": 68, "end_pos": 86, "type": "TASK", "confidence": 0.906542956829071}]}, {"text": "As in previous years, the purpose of the STS task is the development of systems that automatically predict the semantic similarity of two sentences in the continuous interval where 0 represents a complete dissimilarity and 5 denotes a complete semantic equivalence between the sentences (.", "labels": [], "entities": []}, {"text": "The organizers provide sentence pairs whose semantic similarities have to be predicted by the contestants.", "labels": [], "entities": []}, {"text": "The quality of a system is determined by calculating the Pearson correlation between the predicted values and a human gold standard that has been created by crowdsourcing.", "labels": [], "entities": [{"text": "Pearson correlation", "start_pos": 57, "end_pos": 76, "type": "METRIC", "confidence": 0.9738328754901886}]}, {"text": "The data from previous STS tasks can be used for training supervised methods.", "labels": [], "entities": []}, {"text": "The test data consists of text content from different sources.", "labels": [], "entities": []}, {"text": "In this year's shared task, the systems are tested on five different categories with different topics and varying textual characteristics like text length or spelling errors: answer-answer, plagiarism, postediting, headlines, and question-question The remainder of the paper is structured as follows: Section 2 discusses related approaches to automatically determining semantic textual similarity.", "labels": [], "entities": [{"text": "determining semantic textual similarity", "start_pos": 357, "end_pos": 396, "type": "TASK", "confidence": 0.6294899955391884}]}, {"text": "Section 3 describes our three methods in detail.", "labels": [], "entities": []}, {"text": "We discuss their results in section 4.", "labels": [], "entities": []}, {"text": "Finally, we conclude in chapter 5 and outline future work.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: An example for creating the two-dimensional feature", "labels": [], "entities": []}, {"text": " Table 2: Examples for the results of the Overlap method with the corresponding gold standards", "labels": [], "entities": []}, {"text": " Table 3: Pearson correlation of the 2016 test data", "labels": [], "entities": [{"text": "Pearson correlation", "start_pos": 10, "end_pos": 29, "type": "METRIC", "confidence": 0.7729598879814148}, {"text": "2016 test data", "start_pos": 37, "end_pos": 51, "type": "DATASET", "confidence": 0.6880580186843872}]}, {"text": " Table 4: Pearson correlation of the 2015 test data", "labels": [], "entities": [{"text": "Pearson correlation", "start_pos": 10, "end_pos": 29, "type": "METRIC", "confidence": 0.7740359306335449}, {"text": "2015 test data", "start_pos": 37, "end_pos": 51, "type": "DATASET", "confidence": 0.6985977093378702}]}]}