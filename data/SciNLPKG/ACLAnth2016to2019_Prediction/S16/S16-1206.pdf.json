{"title": [{"text": "TAXI at SemEval-2016 Task 13: a Taxonomy Induction Method based on Lexico-Syntactic Patterns, Substrings and Focused Crawling", "labels": [], "entities": [{"text": "TAXI", "start_pos": 0, "end_pos": 4, "type": "METRIC", "confidence": 0.8220128417015076}, {"text": "Taxonomy Induction", "start_pos": 32, "end_pos": 50, "type": "TASK", "confidence": 0.8906238973140717}]}], "abstractContent": [{"text": "We present a system for taxonomy construction that reached the first place in all sub-tasks of the SemEval 2016 challenge on Tax-onomy Extraction Evaluation.", "labels": [], "entities": [{"text": "taxonomy construction", "start_pos": 24, "end_pos": 45, "type": "TASK", "confidence": 0.8766396939754486}, {"text": "SemEval 2016 challenge on Tax-onomy Extraction Evaluation", "start_pos": 99, "end_pos": 156, "type": "TASK", "confidence": 0.8007332256862095}]}, {"text": "Our simple yet effective approach harvests hypernyms with substring inclusion and Hearst-style lexico-syntactic patterns from domain-specific texts obtained via language model based focused crawling.", "labels": [], "entities": []}, {"text": "Extracted taxonomies are evaluated on English, Dutch, French and Italian for three domains each (Food, Environment and Science).", "labels": [], "entities": []}, {"text": "Evaluations against a gold standard and by human judgment show that our method out-performs more complex and knowledge-rich approaches on most domains and languages.", "labels": [], "entities": []}, {"text": "Furthermore, to adapt the method to anew domain or language, only a small amount of manual labour is needed.", "labels": [], "entities": []}], "introductionContent": [{"text": "In this paper, we describe TAXI -a taxonomy induction method first presented at the SemEval 2016 challenge on Taxonomy Extraction Evaluation.", "labels": [], "entities": [{"text": "TAXI", "start_pos": 27, "end_pos": 31, "type": "METRIC", "confidence": 0.9472398161888123}, {"text": "SemEval 2016 challenge on Taxonomy Extraction Evaluation", "start_pos": 84, "end_pos": 140, "type": "TASK", "confidence": 0.8178584916251046}]}, {"text": "We consider taxonomy induction as a process that should -as much as possiblebe driven solely on the basis of raw text processing.", "labels": [], "entities": [{"text": "taxonomy induction", "start_pos": 12, "end_pos": 30, "type": "TASK", "confidence": 0.9290062189102173}]}, {"text": "While some labeled examples might be utilized to tune the extraction and induction process, we avoid relying on structured lexical resources such as WordNet or BabelNet (.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 149, "end_pos": 156, "type": "DATASET", "confidence": 0.9528746604919434}]}, {"text": "We rather envision a situation where a taxonomy shall be induced in anew domain or anew language for which such resources do not exist.", "labels": [], "entities": []}, {"text": "In this paper, we demonstrate our methodology based on hyponym extraction from substrings and general-domain and domain-specific corpora for four languages and three domains.", "labels": [], "entities": []}], "datasetContent": [{"text": "To assess quality of the taxonomies several complementary measures were used.", "labels": [], "entities": []}, {"text": "The first type of measurements are structural measures, such as the number of connected components (c.c.), the number of intermediate nodes (i.i.), i.e. the number of nodes without degree equal to zero, and the presence of cycles.", "labels": [], "entities": []}, {"text": "Second, system outputs were compared against the corresponding domain gold standards and performances are evaluated in terms of Fscore.", "labels": [], "entities": [{"text": "Fscore", "start_pos": 128, "end_pos": 134, "type": "METRIC", "confidence": 0.9967424273490906}]}, {"text": "Here precision and recall are based on the number of edges in common with the gold standard taxonomy over the number of system edges and over the number of gold standard edges respectively.", "labels": [], "entities": [{"text": "precision", "start_pos": 5, "end_pos": 14, "type": "METRIC", "confidence": 0.9994408488273621}, {"text": "recall", "start_pos": 19, "end_pos": 25, "type": "METRIC", "confidence": 0.9994350075721741}]}, {"text": "To better compare against gold standard taxonomies the task included the evaluation of a cumulative measure (, namely Cumulative Fowlkes & Mallows Measure (F&M), where the similarity between the system and the reference taxonomies are measured as the combination of the hierarchical cluster similarities.", "labels": [], "entities": [{"text": "Fowlkes & Mallows Measure (F&M)", "start_pos": 129, "end_pos": 160, "type": "METRIC", "confidence": 0.6462324195437961}]}, {"text": "Finally, the organizers performed manual quality assessment to estimate the precision of the hypernyms.", "labels": [], "entities": [{"text": "precision", "start_pos": 76, "end_pos": 85, "type": "METRIC", "confidence": 0.9990710020065308}]}, {"text": "To compute this measure, annotators labeled a sample of 100 hypernym relations as corrector wrong.", "labels": [], "entities": []}, {"text": "The taxonomy extraction was evaluated on four languages, namely English, Dutch, French and Italian, and three different domains (Food, Science and Environment).", "labels": [], "entities": [{"text": "taxonomy extraction", "start_pos": 4, "end_pos": 23, "type": "TASK", "confidence": 0.9164535701274872}]}, {"text": "A detailed description of the evaluation settings and metrics can be found in ().", "labels": [], "entities": []}, {"text": "presents a summary of evaluation of our method on the SemEval 2016 Task 13 dataset.", "labels": [], "entities": [{"text": "SemEval 2016 Task 13 dataset", "start_pos": 54, "end_pos": 82, "type": "DATASET", "confidence": 0.7624239325523376}]}, {"text": "Overall 5 systems participated in the challenge: JUNLP, TAXI, NUIG-UNLP, USAAR and QASITT.", "labels": [], "entities": [{"text": "JUNLP", "start_pos": 49, "end_pos": 54, "type": "DATASET", "confidence": 0.694952666759491}, {"text": "TAXI", "start_pos": 56, "end_pos": 60, "type": "METRIC", "confidence": 0.7606787085533142}, {"text": "NUIG-UNLP", "start_pos": 62, "end_pos": 71, "type": "DATASET", "confidence": 0.7325195074081421}, {"text": "USAAR", "start_pos": 73, "end_pos": 78, "type": "DATASET", "confidence": 0.8117386698722839}, {"text": "QASITT", "start_pos": 83, "end_pos": 89, "type": "DATASET", "confidence": 0.7808067202568054}]}, {"text": "We represent the respective best scores across our four competitors in the BestComp column.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Wikipedia, 59G and CommonCrawl 1 .", "labels": [], "entities": [{"text": "Wikipedia", "start_pos": 10, "end_pos": 19, "type": "DATASET", "confidence": 0.9807170033454895}, {"text": "59G", "start_pos": 21, "end_pos": 24, "type": "DATASET", "confidence": 0.8637435436248779}, {"text": "CommonCrawl 1", "start_pos": 29, "end_pos": 42, "type": "DATASET", "confidence": 0.9251157343387604}]}, {"text": " Table 1: Corpora sizes used in our system in GB, where  \u2021is the", "labels": [], "entities": [{"text": "GB", "start_pos": 46, "end_pos": 48, "type": "DATASET", "confidence": 0.7160091996192932}]}, {"text": " Table 2: Number of hypernyms in millions of relations. Sys-", "labels": [], "entities": []}, {"text": " Table 3: Overall scores obtained by averaging the results over domains (Environment, Science, Food) and languages (NL, FR, IT)", "labels": [], "entities": []}]}