{"title": [{"text": "NileTMRG at SemEval-2016 Task 5: Deep Convolutional Neural Networks for Aspect Category and Sentiment Extraction", "labels": [], "entities": [{"text": "NileTMRG", "start_pos": 0, "end_pos": 8, "type": "DATASET", "confidence": 0.836413562297821}, {"text": "Sentiment Extraction", "start_pos": 92, "end_pos": 112, "type": "TASK", "confidence": 0.7187187075614929}]}], "abstractContent": [{"text": "This paper describes our participation in the SemEval-2016 task 5, Aspect Based Sentiment Analysis (ABSA).", "labels": [], "entities": [{"text": "SemEval-2016 task 5", "start_pos": 46, "end_pos": 65, "type": "TASK", "confidence": 0.8776756127675375}, {"text": "Aspect Based Sentiment Analysis (ABSA)", "start_pos": 67, "end_pos": 105, "type": "TASK", "confidence": 0.745744743517467}]}, {"text": "We participated in two slots in the sentence level ABSA (Subtask 1) namely: aspect category extraction (Slot 1) and sentiment polarity extraction (Slot 3) in Eng-lish Restaurants and Laptops reviews.", "labels": [], "entities": [{"text": "sentence level ABSA", "start_pos": 36, "end_pos": 55, "type": "TASK", "confidence": 0.42309726277987164}, {"text": "aspect category extraction", "start_pos": 76, "end_pos": 102, "type": "TASK", "confidence": 0.5882241030534109}, {"text": "sentiment polarity extraction", "start_pos": 116, "end_pos": 145, "type": "TASK", "confidence": 0.7145364979902903}, {"text": "Eng-lish Restaurants and Laptops reviews", "start_pos": 158, "end_pos": 198, "type": "DATASET", "confidence": 0.7861397862434387}]}, {"text": "For Slot 1, we applied different models for each domain.", "labels": [], "entities": [{"text": "Slot 1", "start_pos": 4, "end_pos": 10, "type": "TASK", "confidence": 0.8994331061840057}]}, {"text": "In the restaurants domain, we used an ensemble classifier for each aspect which is a combination of a Convolutional Neural Network (CNN) classifier initialized with pre-trained word vectors, and a Support Vector Machine (SVM) classifier based on the bag of words model.", "labels": [], "entities": []}, {"text": "For the Laptops domain, we used only one CNN classifier that predicts the aspects based on a probability threshold.", "labels": [], "entities": []}, {"text": "For Slot 3, we incorporated domain and aspect knowledge in one ensemble CNN classifier initialized with fine-tuned word vectors and used it in both domains.", "labels": [], "entities": [{"text": "Slot 3", "start_pos": 4, "end_pos": 10, "type": "TASK", "confidence": 0.8668997287750244}]}, {"text": "In the Restaurants domain, our system achieved the 2 nd and the 3 rd places in Slot 1 and Slot 3 respectively.", "labels": [], "entities": [{"text": "Slot 1", "start_pos": 79, "end_pos": 85, "type": "DATASET", "confidence": 0.8453161418437958}]}, {"text": "However, we ranked the 8 thin Slot 1 and the 5 thin Slot 3 in the Laptops domain.", "labels": [], "entities": [{"text": "Laptops domain", "start_pos": 66, "end_pos": 80, "type": "DATASET", "confidence": 0.9416717886924744}]}, {"text": "Our extended experiments show our system could have ranked 2 nd in the Laptops domain in Slot 1 and Slot 3, had we followed the same approach we followed in the Restaurants domain in slot 1 and trained each domain separately in Slot 3.", "labels": [], "entities": []}], "introductionContent": [{"text": "Due to the increasing numbers of user generated reviews written everyday within e-commerce websites, a great interest has been shown in the sentiment analysis research community to build intelligent systems that can accurately tackle the task of sentiment analysis in these reviews.", "labels": [], "entities": [{"text": "sentiment analysis research", "start_pos": 140, "end_pos": 167, "type": "TASK", "confidence": 0.9109183748563131}, {"text": "sentiment analysis", "start_pos": 246, "end_pos": 264, "type": "TASK", "confidence": 0.8526135683059692}]}, {"text": "In this context, the SemEval-2016 ABSA, task 5 1 , Subtask 1 addresses a number of research problems related to this topic, including building systems that are able to extract aspect categories (Slot 1) and determine the sentiment polarity towards each aspect in each sentence (Slot-3) which were the two slots in which we participated.", "labels": [], "entities": [{"text": "SemEval-2016 ABSA", "start_pos": 21, "end_pos": 38, "type": "TASK", "confidence": 0.6012018322944641}]}, {"text": "The best results for Slot 1 in, were achieved by the NLANGP team (.", "labels": [], "entities": [{"text": "Slot 1", "start_pos": 21, "end_pos": 27, "type": "TASK", "confidence": 0.5253251791000366}, {"text": "NLANGP", "start_pos": 53, "end_pos": 59, "type": "DATASET", "confidence": 0.8965235948562622}]}, {"text": "The team tackled the problem by modeling it as a multi-class classification problem with binary classifiers for each aspect.", "labels": [], "entities": []}, {"text": "They used a neural network with one hidden layer and features based on word n-grams, brown and k-means word clusters from Amazon and Yelp datasets and parsing features.", "labels": [], "entities": [{"text": "Yelp datasets", "start_pos": 133, "end_pos": 146, "type": "DATASET", "confidence": 0.8307393491268158}]}, {"text": "For Slot 3, the best results were achieved by the Sentiue team who used a Maximum Entropy classifier with domain and aspect features and features based on word n-grams, lemmas, negation terms, exclamation and question marks, sentiment lexicons, and POS tags.", "labels": [], "entities": []}, {"text": "This year, when addressing Slot 1, we participated with a system that can extract aspects in English reviews in the two domains that the task provided test sets for, namely: restaurants (REST) and laptops (LAPT).", "labels": [], "entities": [{"text": "Slot 1", "start_pos": 27, "end_pos": 33, "type": "DATASET", "confidence": 0.6072320640087128}]}, {"text": "For the restaurants domain we treated the problem as a multi-class classification problem using an ensemble binary classifier for each aspect which is a combination of a Support Vector Machine (SVM) classifier and a Convolutional Neural Network (CNN).", "labels": [], "entities": []}, {"text": "While the SVM classifier features were based on a Bag of words model, the CNN classifier was initialized with pre-trained word vectors based on the architecture proposed by.", "labels": [], "entities": []}, {"text": "For the Laptops domain, we used one CNN classifier that outputs probability scores for each aspect, then a threshold was applied so that only outputs with scores higher than that threshold were predicted as aspects.", "labels": [], "entities": []}, {"text": "For Slot 3, we incorporated domain and aspect information in one ensemble classifier consisting of three CNNs trained using the whole training data provided in both domains and initialized with word vectors that were fine-tuned using training examples collected in a semi supervised way by the same CNN architecture as in an earlier phase.", "labels": [], "entities": [{"text": "Slot 3", "start_pos": 4, "end_pos": 10, "type": "TASK", "confidence": 0.8838461339473724}]}, {"text": "The rest of this paper is organized as follows: section 2, describes the system architecture and settings, while section 3, presents and discusses our system performance and evaluation.", "labels": [], "entities": []}, {"text": "Finally, section 4 concludes the paper and presents some ideas for potential future work.", "labels": [], "entities": []}], "datasetContent": [{"text": "In addition to the official submissions, we ran some additional experiments that were evaluated using the official scripts provided by the task organizers.", "labels": [], "entities": []}, {"text": "For Slot 1, given that the RAEM model achieved a good result in the restaurants domain, we decided to train this model on the laptops data.", "labels": [], "entities": []}, {"text": "The resulting model achieved an F-score of 51.42 which would have put the system in 2 nd place.", "labels": [], "entities": [{"text": "F-score", "start_pos": 32, "end_pos": 39, "type": "METRIC", "confidence": 0.9996378421783447}]}, {"text": "We also experimented using the RAEM model without using the SVM classifier and reported that in which shows that it contributed to enhancing the recall especially in the laptops domain.", "labels": [], "entities": [{"text": "recall", "start_pos": 145, "end_pos": 151, "type": "METRIC", "confidence": 0.999422550201416}]}, {"text": "However, the RAEM system on its own, seems to perform relatively well even without the help of the SVM.", "labels": [], "entities": [{"text": "RAEM", "start_pos": 13, "end_pos": 17, "type": "TASK", "confidence": 0.5683550834655762}, {"text": "SVM", "start_pos": 99, "end_pos": 102, "type": "DATASET", "confidence": 0.8912925124168396}]}, {"text": "For Slot 3, we conducted two other experiments in which we used the fine-tuned word vectors to initialize two different ensemble classifiers like the one which was described in the SEM.", "labels": [], "entities": [{"text": "Slot 3", "start_pos": 4, "end_pos": 10, "type": "TASK", "confidence": 0.8520882725715637}]}, {"text": "However, here we separated the data so that we there is one classifier per domain.", "labels": [], "entities": []}, {"text": "This provided better results in the laptops domain which would have ranked as the 2 nd best performer, but decreased the accuracy slightly in the restaurants domain as shown in as Domain Specific SEM.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 121, "end_pos": 129, "type": "METRIC", "confidence": 0.9993372559547424}]}], "tableCaptions": [{"text": " Table 1: Fine-tuning data distribution.", "labels": [], "entities": []}, {"text": " Table 3: Results for Slot 1 in terms of precision, re- call, and F-Score.", "labels": [], "entities": [{"text": "Slot 1", "start_pos": 22, "end_pos": 28, "type": "TASK", "confidence": 0.964060366153717}, {"text": "precision", "start_pos": 41, "end_pos": 50, "type": "METRIC", "confidence": 0.9997112154960632}, {"text": "re- call", "start_pos": 52, "end_pos": 60, "type": "METRIC", "confidence": 0.9260478218396505}, {"text": "F-Score", "start_pos": 66, "end_pos": 73, "type": "METRIC", "confidence": 0.9989770650863647}]}, {"text": " Table 4: Results for Slot 3 in terms of positive, nega- tive, neutral F-Score and accuracy.", "labels": [], "entities": [{"text": "Slot 3", "start_pos": 22, "end_pos": 28, "type": "TASK", "confidence": 0.9355799555778503}, {"text": "F-Score", "start_pos": 71, "end_pos": 78, "type": "METRIC", "confidence": 0.965910017490387}, {"text": "accuracy", "start_pos": 83, "end_pos": 91, "type": "METRIC", "confidence": 0.9996768236160278}]}]}