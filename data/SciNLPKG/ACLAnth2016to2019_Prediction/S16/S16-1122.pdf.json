{"title": [{"text": "IISCNLP at SemEval-2016 Task 2: Interpretable STS with ILP based Multiple Chunk Aligner", "labels": [], "entities": []}], "abstractContent": [{"text": "Interpretable semantic textual similarity (iSTS) task adds a crucial explanatory layer to pairwise sentence similarity.", "labels": [], "entities": [{"text": "Interpretable semantic textual similarity (iSTS)", "start_pos": 0, "end_pos": 48, "type": "TASK", "confidence": 0.750021253313337}, {"text": "pairwise sentence similarity", "start_pos": 90, "end_pos": 118, "type": "TASK", "confidence": 0.6477009852727255}]}, {"text": "We address various components of this task: chunk level semantic alignment along with assignment of similarity type and score for aligned chunks with a novel system presented in this paper.", "labels": [], "entities": [{"text": "chunk level semantic alignment", "start_pos": 44, "end_pos": 74, "type": "TASK", "confidence": 0.790863037109375}]}, {"text": "We propose an algorithm, iMATCH, for the alignment of multiple non-contiguous chunks based on Integer Linear Programming (ILP).", "labels": [], "entities": []}, {"text": "Similarity type and score assignment for pairs of chunks is done using a supervised multiclass classification technique based on Random Forrest Classifier.", "labels": [], "entities": [{"text": "multiclass classification", "start_pos": 84, "end_pos": 109, "type": "TASK", "confidence": 0.709537923336029}]}, {"text": "Results show that our algorithm iMATCH has low execution time and outperforms most other participating systems in terms of alignment score.", "labels": [], "entities": []}, {"text": "Of the three datasets, we are top ranked for answer-students dataset in terms of overall score and have top alignment score for headlines dataset in the gold chunks track.", "labels": [], "entities": [{"text": "alignment score", "start_pos": 108, "end_pos": 123, "type": "METRIC", "confidence": 0.9661842286586761}, {"text": "headlines dataset", "start_pos": 128, "end_pos": 145, "type": "DATASET", "confidence": 0.7750055193901062}]}], "introductionContent": [], "datasetContent": [{"text": "In this section, we present our results, in both the gold standard and the system chunks tracks.", "labels": [], "entities": []}, {"text": "We submitted 3 runs for each track.", "labels": [], "entities": []}, {"text": "In gold chunks track,        Results of our system compared to the best performing systems in each track are listed in Tables 2-9.", "labels": [], "entities": []}, {"text": "In both gold and system chunks track, run2 performs best owing to more data during training.", "labels": [], "entities": []}, {"text": "Our system performed well for the answerstudents dataset owing to our edit-distance feature that enables handling noisy data without any preprocessing for spelling correction.", "labels": [], "entities": [{"text": "answerstudents dataset", "start_pos": 34, "end_pos": 56, "type": "DATASET", "confidence": 0.8020186126232147}, {"text": "spelling correction", "start_pos": 155, "end_pos": 174, "type": "TASK", "confidence": 0.8349787890911102}]}, {"text": "Our alignment score is best or close to the best in the gold chunks track, thus validating that our novel and simple approach based on ILP can be used for high quality monolingual multiple alignment at the chunk level.", "labels": [], "entities": [{"text": "alignment score", "start_pos": 4, "end_pos": 19, "type": "METRIC", "confidence": 0.88945671916008}]}, {"text": "Our system took only 5.2 minutes fora single threaded execution on a Xeon 2420, 6 core system for the headlines dataset.", "labels": [], "entities": [{"text": "Xeon 2420", "start_pos": 69, "end_pos": 78, "type": "DATASET", "confidence": 0.9326068460941315}, {"text": "headlines dataset", "start_pos": 102, "end_pos": 119, "type": "DATASET", "confidence": 0.8663552701473236}]}, {"text": "Therefore, our technique is fast to execute.", "labels": [], "entities": []}, {"text": "We observe that the quality of chunking has a huge impact on alignment and thereby the final score.", "labels": [], "entities": [{"text": "alignment", "start_pos": 61, "end_pos": 70, "type": "TASK", "confidence": 0.4898713529109955}, {"text": "final score", "start_pos": 87, "end_pos": 98, "type": "METRIC", "confidence": 0.9038586616516113}]}, {"text": "We are actively exploring other chunking strategies that could improve results.", "labels": [], "entities": []}, {"text": "Code for our alignment module is available at https://github.com/lavanyats/ iMATCH.git", "labels": [], "entities": [{"text": "alignment", "start_pos": 13, "end_pos": 22, "type": "TASK", "confidence": 0.9759238362312317}]}], "tableCaptions": [{"text": " Table 2: Gold Chunks Images", "labels": [], "entities": [{"text": "Gold Chunks", "start_pos": 10, "end_pos": 21, "type": "DATASET", "confidence": 0.945899099111557}]}, {"text": " Table 3: Gold Chunks headlines", "labels": [], "entities": [{"text": "Gold Chunks", "start_pos": 10, "end_pos": 21, "type": "DATASET", "confidence": 0.9650146961212158}]}, {"text": " Table 4: Gold Chunks Answer Students", "labels": [], "entities": []}, {"text": " Table 5: Gold Chunks Overall", "labels": [], "entities": [{"text": "Gold Chunks", "start_pos": 10, "end_pos": 21, "type": "DATASET", "confidence": 0.9430743455886841}]}, {"text": " Table 6: System Chunks Images", "labels": [], "entities": []}, {"text": " Table 7: System Chunks Headlines", "labels": [], "entities": [{"text": "System Chunks Headlines", "start_pos": 10, "end_pos": 33, "type": "DATASET", "confidence": 0.8615603446960449}]}, {"text": " Table 8: System Chunks Answer Students", "labels": [], "entities": []}, {"text": " Table 9: System Chunks Overall", "labels": [], "entities": []}]}