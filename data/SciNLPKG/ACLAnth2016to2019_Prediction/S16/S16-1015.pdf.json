{"title": [{"text": "UDLAP at SemEval-2016 Task 4: Sentiment Quantification Using a Graph Based Representation", "labels": [], "entities": [{"text": "Sentiment Quantification", "start_pos": 30, "end_pos": 54, "type": "TASK", "confidence": 0.9667687118053436}]}], "abstractContent": [{"text": "We present an approach for tackling the tweet quantification problem in SemEval 2016.", "labels": [], "entities": [{"text": "tweet quantification problem", "start_pos": 40, "end_pos": 68, "type": "TASK", "confidence": 0.7729319135348002}]}, {"text": "The approach is based on the creation of a co-occurrence graph per sentiment from the training dataset and a graph per topic from the test dataset with the aim of comparing each topic graph against the sentiment graphs and evaluate the similarity between them.", "labels": [], "entities": []}, {"text": "A heuristic is applied on those similarities to calculate the percentage of positive and negative texts.", "labels": [], "entities": []}, {"text": "The overall result obtained for the test dataset according to the proposed task score (KL divergence) is 0.261, showing that the graph based representation and heuristic could be away of quantifying the percentage of tweets that are positive and negative in a given set of texts about a topic.", "labels": [], "entities": [{"text": "KL divergence)", "start_pos": 87, "end_pos": 101, "type": "METRIC", "confidence": 0.9402199983596802}]}], "introductionContent": [{"text": "In the past decade, new forms of communication, such as microblogging and text messaging have emerged and become ubiquitous.", "labels": [], "entities": []}, {"text": "There is no limit to the range of information conveyed by tweets and texts.", "labels": [], "entities": []}, {"text": "These short messages are extensively used to share opinions and sentiments that people have about their topics of interest.", "labels": [], "entities": []}, {"text": "Working with these informal text genres presents challenges for Natural Language Processing (NLP) beyond those encountered when working with more traditional text genres.", "labels": [], "entities": [{"text": "Natural Language Processing (NLP)", "start_pos": 64, "end_pos": 97, "type": "TASK", "confidence": 0.6792792975902557}]}, {"text": "Typically, this kind of texts are short and the language used is very informal.", "labels": [], "entities": []}, {"text": "We can find creative spelling and punctuation, slang, new words, URLs, and genre-specific terminology and abbreviations that make their manipulation more challenging.", "labels": [], "entities": []}, {"text": "Representing that kind of text for automatically mining and understanding the opinions and sentiments that people communicate inside them has very recently become an attractive research topic.", "labels": [], "entities": [{"text": "automatically mining and understanding the opinions and sentiments that people communicate", "start_pos": 35, "end_pos": 125, "type": "TASK", "confidence": 0.7471834123134613}]}, {"text": "In this sense, the experiments reported in this paper were carried out in the framework of the SemEval 2016 1 (Semantic Evaluation) which has created a series of tasks for sentiment analysis on Twitter ().", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 172, "end_pos": 190, "type": "TASK", "confidence": 0.9406655132770538}]}, {"text": "Among the proposed tasks we chose Task 4, subtask D which was named tweet quantification according to a two-point scale and was defined as follows: \"Given a set of tweets known to be about a given topic, estimate the distribution of the tweets across the Positive and Negative classes\".", "labels": [], "entities": [{"text": "tweet quantification", "start_pos": 68, "end_pos": 88, "type": "TASK", "confidence": 0.7436269521713257}]}, {"text": "In order to solve this task we created an algorithm that builds up graphs to compare each topic against all possible sentiments for obtaining the polarity percentage of each one.", "labels": [], "entities": []}, {"text": "The steps involved in our sentiment quantification process are then discussed in detail.", "labels": [], "entities": [{"text": "sentiment quantification process", "start_pos": 26, "end_pos": 58, "type": "TASK", "confidence": 0.877943237622579}]}, {"text": "The rest of the paper is structured as follows: in Section 2 we present some related work found in the literature with respect to the quantification of sentiments in text documents.", "labels": [], "entities": [{"text": "quantification of sentiments in text documents", "start_pos": 134, "end_pos": 180, "type": "TASK", "confidence": 0.8446528017520905}]}, {"text": "In Sections 3 to 5 the algorithm and the graph representation used to detect the percentage of texts for each sentiment are explained.", "labels": [], "entities": []}, {"text": "In Section 6, the experimental results are presented and discussed.", "labels": [], "entities": []}, {"text": "Finally, in Section 7 the conclusions as well as further work are described.", "labels": [], "entities": []}], "datasetContent": [{"text": "The results obtained with the proposed approach are discussed in this section.", "labels": [], "entities": []}, {"text": "First, we describe the dataset used in the experiments and, thereafter, the results obtained.", "labels": [], "entities": []}, {"text": "The document collection used in the experiments is a subset of the SemEval 2016 task 4 corpus (), which includes, several text documents in English on different topics and genres.", "labels": [], "entities": [{"text": "SemEval 2016 task 4 corpus", "start_pos": 67, "end_pos": 93, "type": "DATASET", "confidence": 0.6895959138870239}]}, {"text": "The dataset is divided in two groups: \u2022 Training documents: It contains a set of topics each one with a set of known documents.", "labels": [], "entities": []}, {"text": "For each document a label that indicates the polarity of the text (positive or negative) is assigned.", "labels": [], "entities": []}, {"text": "\u2022 Test documents: It contains a set of topics 3 each one with a set of known documents.", "labels": [], "entities": []}, {"text": "In this case there is no label that indicates the polarity of the text.", "labels": [], "entities": []}, {"text": "These documents are used to test our algorithm taking into account the writing style samples of the training documents.", "labels": [], "entities": []}, {"text": "In, main dataset features are shown, including the number of documents per topic for the training and test dataset.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: SemEval task 4 subtask D dataset features.", "labels": [], "entities": [{"text": "SemEval", "start_pos": 10, "end_pos": 17, "type": "TASK", "confidence": 0.947208046913147}]}, {"text": " Table 2: Evaluation of the proposed algorithm using  the test dataset.", "labels": [], "entities": []}]}