{"title": [{"text": "UTA DLNLP at SemEval-2016 Task 1: Semantic Textual Similarity: A Unified Framework for Semantic Processing and Evaluation", "labels": [], "entities": [{"text": "UTA DLNLP", "start_pos": 0, "end_pos": 9, "type": "DATASET", "confidence": 0.8255268335342407}, {"text": "Semantic Textual Similarity", "start_pos": 34, "end_pos": 61, "type": "TASK", "confidence": 0.7530850768089294}, {"text": "Semantic Processing and Evaluation", "start_pos": 87, "end_pos": 121, "type": "TASK", "confidence": 0.6872278973460197}]}], "abstractContent": [{"text": "In this paper, we propose a deep neural network based natural language processing system for semantic textual similarity prediction.", "labels": [], "entities": [{"text": "semantic textual similarity prediction", "start_pos": 93, "end_pos": 131, "type": "TASK", "confidence": 0.7185950875282288}]}, {"text": "We leverage multi-layer bidirectional LSTM to learn sentence representation.", "labels": [], "entities": [{"text": "sentence representation", "start_pos": 52, "end_pos": 75, "type": "TASK", "confidence": 0.7224345803260803}]}, {"text": "After that, we construct matching features followed by Highway Multilayer Perceptron to make predictions.", "labels": [], "entities": []}, {"text": "Experimental results demonstrate that this approach can't get better results on standard evaluation datasets.", "labels": [], "entities": []}], "introductionContent": [{"text": "Traditional approaches) for semantic textual similarity prediction usually build the supervised model using a variety of hand crafted features.", "labels": [], "entities": [{"text": "semantic textual similarity prediction", "start_pos": 28, "end_pos": 66, "type": "TASK", "confidence": 0.7102594450116158}]}, {"text": "Hundreds of features generated at different linguistic levels are exploited to boost classification.", "labels": [], "entities": []}, {"text": "With the success of deep learning in many machine learning related applications, there has been much interest in applying deep neural network based techniques to further improve the prediction tasks in natural language processing (NLP).", "labels": [], "entities": [{"text": "natural language processing (NLP)", "start_pos": 202, "end_pos": 235, "type": "TASK", "confidence": 0.6584775646527609}]}, {"text": "A key component of deep neural network is word embeddings which serves as a lookup table to get word representations.", "labels": [], "entities": []}, {"text": "From low-level NLP tasks such as language modeling, POS tagging, name entity recognition, and semantic role labeling, to high- * To whom all correspondence should be addressed.", "labels": [], "entities": [{"text": "language modeling", "start_pos": 33, "end_pos": 50, "type": "TASK", "confidence": 0.7336436063051224}, {"text": "POS tagging", "start_pos": 52, "end_pos": 63, "type": "TASK", "confidence": 0.8489950597286224}, {"text": "name entity recognition", "start_pos": 65, "end_pos": 88, "type": "TASK", "confidence": 0.7454906702041626}, {"text": "semantic role labeling", "start_pos": 94, "end_pos": 116, "type": "TASK", "confidence": 0.6582207679748535}]}, {"text": "This work was partially supported by NSF-IIS 1117965, NSF-IIS 1302675, NSF-IIS 1344152, NSF-DBI 1356628, NIH R01 AG049371.", "labels": [], "entities": [{"text": "NSF-IIS 1117965", "start_pos": 37, "end_pos": 52, "type": "DATASET", "confidence": 0.9299644529819489}, {"text": "NSF-IIS 1302675", "start_pos": 54, "end_pos": 69, "type": "DATASET", "confidence": 0.9413898587226868}, {"text": "NSF-IIS 1344152", "start_pos": 71, "end_pos": 86, "type": "DATASET", "confidence": 0.9204720854759216}, {"text": "NSF-DBI 1356628", "start_pos": 88, "end_pos": 103, "type": "DATASET", "confidence": 0.9283453524112701}, {"text": "NIH R01 AG049371", "start_pos": 105, "end_pos": 121, "type": "METRIC", "confidence": 0.5961825847625732}]}, {"text": "level tasks such as machine translation, information retrieval and semantic analysis.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 20, "end_pos": 39, "type": "TASK", "confidence": 0.8247884213924408}, {"text": "information retrieval", "start_pos": 41, "end_pos": 62, "type": "TASK", "confidence": 0.8161612153053284}, {"text": "semantic analysis", "start_pos": 67, "end_pos": 84, "type": "TASK", "confidence": 0.8320092856884003}]}, {"text": "Deep word representation learning has demonstrated its importance for these tasks.", "labels": [], "entities": [{"text": "Deep word representation learning", "start_pos": 0, "end_pos": 33, "type": "TASK", "confidence": 0.6899518892168999}]}, {"text": "All the tasks get performance improvement via further learning either word level representations or sentence level representations.", "labels": [], "entities": []}, {"text": "In this work, we focus on deep neural network based semantic textual similarity prediction.", "labels": [], "entities": [{"text": "deep neural network based semantic textual similarity prediction", "start_pos": 26, "end_pos": 90, "type": "TASK", "confidence": 0.6011366918683052}]}, {"text": "We use multi-layer bidirectional LSTM (Long Short Term Memory) () to learn sentence representations.", "labels": [], "entities": []}, {"text": "After that, we construct matching features followed by Highway Multilayer Perceptron to learn high-level hidden matching feature representations.", "labels": [], "entities": []}, {"text": "Below, we will briefly introduce Multi-Layer Bidirectional LSTM.", "labels": [], "entities": []}], "datasetContent": [{"text": "We use all previous dataset to train our LSTM classifier.", "labels": [], "entities": [{"text": "LSTM classifier", "start_pos": 41, "end_pos": 56, "type": "TASK", "confidence": 0.5615087151527405}]}, {"text": "The total number of training examples is 12912, and the number of dev examples is 680.", "labels": [], "entities": []}, {"text": "Note that we didn't use cross validation to find the best model.", "labels": [], "entities": []}, {"text": "shows the Pearson correlation results of STS task.", "labels": [], "entities": [{"text": "Pearson correlation", "start_pos": 10, "end_pos": 29, "type": "METRIC", "confidence": 0.9149632453918457}, {"text": "STS", "start_pos": 41, "end_pos": 44, "type": "METRIC", "confidence": 0.6053963303565979}]}], "tableCaptions": []}