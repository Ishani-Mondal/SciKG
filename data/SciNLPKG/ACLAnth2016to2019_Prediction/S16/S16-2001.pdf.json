{"title": [{"text": "Quantificational features in distributional word representations", "labels": [], "entities": [{"text": "distributional word representations", "start_pos": 29, "end_pos": 64, "type": "TASK", "confidence": 0.619642565647761}]}], "abstractContent": [{"text": "Do distributional word representations encode the linguistic regularities that theories of meaning argue they should encode?", "labels": [], "entities": []}, {"text": "We address this question in the case of the logical properties (monotonicity, force) of quantificational words such as everything (in the object domain) and always (in the time domain).", "labels": [], "entities": []}, {"text": "Using the vector offset approach to solving word analogies, we find that the skip-gram model of distributional semantics behaves in away that is remarkably consistent with encoding these features in some domains, with accuracy approaching 100%, especially with medium-sized context windows.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 218, "end_pos": 226, "type": "METRIC", "confidence": 0.9989903569221497}]}, {"text": "Accuracy in others domains was less impressive.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 0, "end_pos": 8, "type": "METRIC", "confidence": 0.9753119945526123}]}, {"text": "We compare the performance of the model to the behavior of human participants, and find that humans performed well even where the models struggled.", "labels": [], "entities": []}], "introductionContent": [{"text": "Vector-space models of lexical semantics (VSMs) represent words as points in a high-dimensional space.", "labels": [], "entities": []}, {"text": "Similar words are represented by points that are close together in the space.", "labels": [], "entities": []}, {"text": "VSMs are typically trained on a corpus in an unsupervised way; the goal is for words that occur in similar contexts to be assigned similar representations.", "labels": [], "entities": [{"text": "VSMs", "start_pos": 0, "end_pos": 4, "type": "TASK", "confidence": 0.7490212917327881}]}, {"text": "The context of a word in a corpus is often defined as the set of words that occur in a small window around the word of interest (.", "labels": [], "entities": []}, {"text": "VSM representations have been shown to be useful in improving the performance of NLP systems) as well as in predicting cognitive measures such as similarity judgments and semantic priming (.", "labels": [], "entities": []}, {"text": "While there is evidence that VSM representations encode useful information about the meaning of open-class words such as dog or table, less is known about the extent to which they capture abstract linguistic properties, in particular the aspects of word meaning that are crucial in logical reasoning.", "labels": [], "entities": []}, {"text": "Some have conjectured that those properties are unlikely to be encoded in VSMs (), but evidence that VSMs encode features such as syntactic category or verb tense suggests that this pessimism is premature ().", "labels": [], "entities": []}, {"text": "The goal of this paper is to evaluate to what extent logical features are encoded in VSMs.", "labels": [], "entities": []}, {"text": "We undertake a detailed analysis of words with quantificational features, such as everybody or nowhere.", "labels": [], "entities": []}, {"text": "To assess whether a particular linguistic feature is encoded in a vector space, we adopt the vector offset approach to the analogy task).", "labels": [], "entities": []}, {"text": "In the analogy task, a system is requested to fill in the blank in a sentence: man is to woman as king is to . The system is expected to infer the relation between the first two words-man and woman-and find a word that stands in the same relation to king.", "labels": [], "entities": []}, {"text": "When this task is solved using the offset method, there is no explicit set of relations that the system is trained to identify.", "labels": [], "entities": []}, {"text": "We simply subtract the vector for man from the vector for woman and add it to king.", "labels": [], "entities": [{"text": "king", "start_pos": 78, "end_pos": 82, "type": "METRIC", "confidence": 0.9880068302154541}]}, {"text": "If the offset woman \u2212 man represents an abstract gender feature, adding that offset to king should lead us to queen).", "labels": [], "entities": []}, {"text": "In the rest of this paper, we describe the set of analogy problems that we used to evaluate the VSMs' representation of quantificational features, and explore how accuracy is affected by the con-1 king queen man woman?", "labels": [], "entities": [{"text": "accuracy", "start_pos": 163, "end_pos": 171, "type": "METRIC", "confidence": 0.9973161816596985}]}, {"text": "woman?: Using the vector offset method to solve the analogy task ().", "labels": [], "entities": []}, {"text": "text windows used to construct the VSM.", "labels": [], "entities": [{"text": "VSM", "start_pos": 35, "end_pos": 38, "type": "DATASET", "confidence": 0.6512754559516907}]}, {"text": "We then report two experiments that examine the robustness of the results.", "labels": [], "entities": []}, {"text": "First, we determine whether the level of performance that we expect from the VSMs is reasonable, by testing how well humans solve the same analogy problems.", "labels": [], "entities": []}, {"text": "Second, we investigate how the quality of the representations is affected by the size of the training corpus.", "labels": [], "entities": []}, {"text": "A large and constantly expanding range of VSM architectures have been proposed in the literature (.", "labels": [], "entities": [{"text": "VSM", "start_pos": 42, "end_pos": 45, "type": "TASK", "confidence": 0.9332335591316223}]}, {"text": "Instead of exploring the full range of architectures, the present study will focus on the skip-gram model, implemented in word2vec (.", "labels": [], "entities": []}, {"text": "This model has been argued to perform either better than or on a par with competing architectures, depending on the task and on hyperparameter settings (.", "labels": [], "entities": []}, {"text": "Particularly pertinent to our purposes, find that the skip-gram model tends to recover formal linguistic features more accurately than traditional distributional models.", "labels": [], "entities": []}], "datasetContent": [{"text": "In what follows, we use the following notation (: The offset model is typically understood as in: the analogy task is solved by finding x = a * \u2212 a + b.", "labels": [], "entities": []}, {"text": "In practice, since the space is continuous, x is unlikely to precisely identify a word in the vocabulary.", "labels": [], "entities": []}, {"text": "The guess is then taken to be the word x * that is nearest to x: where cos denotes the cosine similarity between the vectors.", "labels": [], "entities": []}, {"text": "This point has a significant effect on the results of the offset method, as we will see below.", "labels": [], "entities": [{"text": "offset", "start_pos": 58, "end_pos": 64, "type": "TASK", "confidence": 0.9385821223258972}]}, {"text": "Following and, we normalize a, a * and b prior to entering them into Equation 1.", "labels": [], "entities": []}, {"text": "Trivial responses: x * as defined above is almost always trivial: in our experiments the nearest neighbor of x was either a * (11% of the time) orb (88.9% of the time).", "labels": [], "entities": []}, {"text": "Only in a single analogy out of the 2160 we tested was it not one of those two options.", "labels": [], "entities": []}, {"text": "Following, then, our guess x * will be the nearest neighbor of x that is not a, a * orb.", "labels": [], "entities": []}, {"text": "Baseline: The fact that the nearest neighbor of a * \u2212 a + b tends to be b itself suggests that a * \u2212 a is typically small in comparison to the distance between band any of its neighbors.", "labels": [], "entities": []}, {"text": "Even if b is excluded as a guess, then, one might be concerned that the analogy target b * is closer to b than any of its neighbors.", "labels": [], "entities": []}, {"text": "If that is the case, our success on the analogy task would not be informative: our results would stay largely the same if a * \u2212 a were replaced by a random vector of the same magnitude.", "labels": [], "entities": []}, {"text": "To address this concern, we add a baseline that solves the analogy task by simply returning the nearest neighbor of b, ignoring a and a * altogether.", "labels": [], "entities": []}, {"text": "Multiplication: point out that the word x * that is closest to a * \u2212 a + bin terms of cosine similarity is the one that maximizes the following expression: (2) They report that replacing addition with multiplication improves accuracy on the analogy task: We experiment with both methods.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 225, "end_pos": 233, "type": "METRIC", "confidence": 0.9989078044891357}]}, {"text": "Synonyms: Previous studies required an exact match between the guess and the analogy target selected by the experimenter.", "labels": [], "entities": []}, {"text": "This requirement may underestimate the extent to which the space encodes linguistic features, since the bundle of semantic features expressed by the intended target can often be expressed by one or more other words.", "labels": [], "entities": []}, {"text": "This is the case for everyone and everybody, prohibit and forbid or can't and cannot.", "labels": [], "entities": []}, {"text": "As such, we considered synonyms of b * to be exact matches.", "labels": [], "entities": []}, {"text": "Likewise, we considered synonyms of a, a * and b to be trivial responses and excluded them from consideration as guesses.", "labels": [], "entities": []}, {"text": "This treatment of synonyms is reasonable when the goal is to probe the VSM's semantic representations (as it often is), but maybe inappropriate for other purposes.", "labels": [], "entities": [{"text": "VSM's semantic representations", "start_pos": 71, "end_pos": 101, "type": "TASK", "confidence": 0.5267106965184212}]}, {"text": "If, for example, the analogy task is used as a method for generating inflected forms, prohibiting would not bean appropriate guess for like : liking :: forbid : . Partial success metrics: We did not restrict the guesses to words with quantificational features: all of the words in the vocabulary, including words like penguin and melancholy, were potential guesses.", "labels": [], "entities": []}, {"text": "In addition to counting exact matches (x * = b * ), then, we keep track of the proportion of cases in which x * was a quantificational word in one of the six relevant domains.", "labels": [], "entities": []}, {"text": "Within the cases in which x * was a quantificational word, we separately counted how often x * had the expected domain, the expected polarity and the expected force.", "labels": [], "entities": []}, {"text": "To be able to detect such partial matches, we manually added some words to our vocabulary that were not included in the set in.", "labels": [], "entities": []}, {"text": "These included items starting with any, such as anywhere or anybody, as well as additional temporal adverbs (seldom, often).", "labels": [], "entities": []}, {"text": "Finally, we record the rank of b * among the 100 nearest neighbors of x, where a rank of 1 indicates an exact match.", "labels": [], "entities": []}, {"text": "It was often the case that b * was not among the 100 nearest neighbors of x; we therefore record how often b * was ranked at all.", "labels": [], "entities": []}, {"text": "For each ordered pair of domains (6 \u00d7 5 = 30 pairs in total), we constructed all possible analogies where a and a * were drawn from one domain (the source domain) and band b * from the other (the target domain).", "labels": [], "entities": []}, {"text": "Since there are three words per domain, we had six possible analogies per domain pair, fora total of 180 analogies.", "labels": [], "entities": []}, {"text": "Each set of four words was used to construct multiple analogies.", "labels": [], "entities": []}, {"text": "Those analogies are in general not equivalent.", "labels": [], "entities": []}, {"text": "For example, the words everybody, nobody, everywhere and nowhere makeup the following analogies: everybody : nobody :: everywhere : (10) nobody : everybody :: nowhere : (11) everywhere : nowhere :: everybody : (12) nowhere : everywhere :: nobody : The neighborhoods of everywhere and nobody may well differ in density.", "labels": [], "entities": []}, {"text": "Since the density of the neighborhood of b affects the results of the offset method, the result is not invariant to a permutation of the words in an analogy.", "labels": [], "entities": []}, {"text": "It is, however, invariant to replacing a within-domain analogy with an across-domain one.", "labels": [], "entities": []}, {"text": "The following analogy is equivalent to (9): (13) everybody : everywhere :: nobody : This analogy would be solved by finding the nearest neighbor of everywhere \u2212 everybody + nobody, which is, of course, the same as the nearest neighbor of nobody \u2212 everybody + everywhere used to solve (9).", "labels": [], "entities": []}, {"text": "We do not include such analogies.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Results on all hyperparameter set- tings, evaluated using three methods: B(aseline),  O(ffset) and M(ultiplication).", "labels": [], "entities": []}]}