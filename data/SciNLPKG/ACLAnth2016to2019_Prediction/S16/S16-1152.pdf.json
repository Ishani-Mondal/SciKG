{"title": [], "abstractContent": [{"text": "The complex word identification task refers to the process of identifying difficult words in a sentence from the perspective of readers belonging to a specific target audience.", "labels": [], "entities": [{"text": "word identification task", "start_pos": 12, "end_pos": 36, "type": "TASK", "confidence": 0.7619146009286245}]}, {"text": "This task has immense importance in the field of lexical simplification.", "labels": [], "entities": [{"text": "lexical simplification", "start_pos": 49, "end_pos": 71, "type": "TASK", "confidence": 0.7908168733119965}]}, {"text": "Lexical simplification helps in improving the readability of texts consisting of challenging words.", "labels": [], "entities": [{"text": "Lexical simplification", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.8866569399833679}]}, {"text": "As a participant of the SemEval-2016: Task 11 shared task, we developed two systems using various lexical and semantic features to identify complex words, one using Na\u00a8\u0131veNa\u00a8\u0131ve Bayes and another based on Random Forest Classifiers.", "labels": [], "entities": [{"text": "SemEval-2016: Task 11 shared task", "start_pos": 24, "end_pos": 57, "type": "TASK", "confidence": 0.847091555595398}]}, {"text": "The Na\u00a8\u0131veNa\u00a8\u0131ve Bayes classifier based system achieves the maximum G-score of 76.7% after incorporating rule based post-processing techniques.", "labels": [], "entities": [{"text": "G-score", "start_pos": 68, "end_pos": 75, "type": "METRIC", "confidence": 0.9939823746681213}]}], "introductionContent": [{"text": "Extensive research has been performed in the field of lexical simplification (.", "labels": [], "entities": [{"text": "lexical simplification", "start_pos": 54, "end_pos": 76, "type": "TASK", "confidence": 0.7803815603256226}]}, {"text": "Lexical simplification refers to identifying complex words and replacing them with lexically simple substitutes ().", "labels": [], "entities": [{"text": "Lexical simplification", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.8964777886867523}]}, {"text": "The English lexical simplification task 1 was organized in the year 2012, in which the complex words were provided by the organizers.", "labels": [], "entities": [{"text": "English lexical simplification task", "start_pos": 4, "end_pos": 39, "type": "TASK", "confidence": 0.775762215256691}]}, {"text": "The complex word (CW) identification is the first step towards the lexical simplification task.", "labels": [], "entities": [{"text": "complex word (CW) identification", "start_pos": 4, "end_pos": 36, "type": "TASK", "confidence": 0.6638698875904083}, {"text": "lexical simplification", "start_pos": 67, "end_pos": 89, "type": "TASK", "confidence": 0.6771653294563293}]}, {"text": "Understanding words which are not frequently used in any language is very difficult for non-native speakers.", "labels": [], "entities": []}, {"text": "It maybe challenging fora reader to interpret a particular word because it might be absent in his vocabulary.", "labels": [], "entities": []}, {"text": "Also it may so happen that he knows the 1 https://www.cs.york.ac.uk/semeval-2012/task1.html word but cannot comprehend it as he fails to capture the context it is used in.", "labels": [], "entities": []}, {"text": "Generally, it is observed that the frequent use of complex words decreases the readability of the document.", "labels": [], "entities": []}, {"text": "Thus, the complex word identification (CWI) task aims to classify those challenging words in a sentence with respect to a particular target audience.", "labels": [], "entities": [{"text": "complex word identification (CWI)", "start_pos": 10, "end_pos": 43, "type": "TASK", "confidence": 0.7909903774658839}]}, {"text": "For example, in the following sentence, the words in italics are complex words.", "labels": [], "entities": []}, {"text": "These words are related to biology and are rarely used in our daily life.", "labels": [], "entities": []}, {"text": "e.g. \"The first amniotes, such as Casineria, resembled small lizards and evolved from amphibian reptiliomorphs about 340 million years ago.\"", "labels": [], "entities": []}, {"text": "Some research has been performed in CWI task in comparison to the lexical simplification.", "labels": [], "entities": []}, {"text": "The important features which have been used previously in the CWI task are frequency thresholding and lexical matching etc..", "labels": [], "entities": [{"text": "CWI task", "start_pos": 62, "end_pos": 70, "type": "TASK", "confidence": 0.8892685174942017}, {"text": "lexical matching", "start_pos": 102, "end_pos": 118, "type": "TASK", "confidence": 0.7297920286655426}]}, {"text": "Some motivations of the CWI task are to understand the defining characteristics of the words which are challenging for non-native speakers to interpret.", "labels": [], "entities": []}, {"text": "Another is assessing an individual's vocabulary limitations from the group he is apart of.", "labels": [], "entities": []}, {"text": "We have participated in the SemEval 2016-Task 11: Complex Word Identification 2.", "labels": [], "entities": [{"text": "SemEval 2016-Task 11: Complex Word Identification", "start_pos": 28, "end_pos": 77, "type": "TASK", "confidence": 0.7050388625689915}]}, {"text": "The main goal of this task is to identify the complex words from English sentences.", "labels": [], "entities": []}, {"text": "We identified highly correlated features and performed the classification using Na\u00a8\u0131veNa\u00a8\u0131ve Bayes and Random Forest classifiers.", "labels": [], "entities": [{"text": "Na\u00a8\u0131veNa\u00a8\u0131ve Bayes", "start_pos": 80, "end_pos": 98, "type": "METRIC", "confidence": 0.6430901984373728}]}, {"text": "After the classification, we used post-processing techniques with deterministic features to improve the F-Score of our system.", "labels": [], "entities": [{"text": "F-Score", "start_pos": 104, "end_pos": 111, "type": "METRIC", "confidence": 0.9965680837631226}]}], "datasetContent": [{"text": "Participants were provided with training and test datasets by the organizers of CWI task.", "labels": [], "entities": []}, {"text": "A subset of words of a sentence are tagged as complex or noncomplex.", "labels": [], "entities": []}, {"text": "The training and test datasets comprise of 2,237 and 88,221 instances respectively.", "labels": [], "entities": []}, {"text": "The numbers of complex and noncomplex words are 706 and 1531 for the training dataset, whereas the number of complex and noncomplex words are 4,131 and 84,090 in the test dataset.", "labels": [], "entities": [{"text": "training dataset", "start_pos": 69, "end_pos": 85, "type": "DATASET", "confidence": 0.6555867940187454}]}, {"text": "The training dataset was collected through a survey, in which 400 annotators were presented with 200 sentences.", "labels": [], "entities": []}, {"text": "They were asked to select the words which they did not understand in terms of the meaning.", "labels": [], "entities": []}, {"text": "Each of the words in the training dataset have been annotated by 20 distinct annotators.", "labels": [], "entities": []}, {"text": "Even if one of the 20 annotators judged the word to be complex it has been tagged as complex.", "labels": [], "entities": []}, {"text": "The test set has annotations made over 9,000 sentences by only one annotator (Paetzold and Specia, 2016).", "labels": [], "entities": []}, {"text": "The performance of the systems was calculated using Accuracy, Precision, Recall, F-Score, and GScore (.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 52, "end_pos": 60, "type": "METRIC", "confidence": 0.999322772026062}, {"text": "Precision", "start_pos": 62, "end_pos": 71, "type": "METRIC", "confidence": 0.9970676302909851}, {"text": "Recall", "start_pos": 73, "end_pos": 79, "type": "METRIC", "confidence": 0.9961611032485962}, {"text": "F-Score", "start_pos": 81, "end_pos": 88, "type": "METRIC", "confidence": 0.9974614381790161}, {"text": "GScore", "start_pos": 94, "end_pos": 100, "type": "METRIC", "confidence": 0.9903501272201538}]}, {"text": "The accuracy is calculated as: Accuracy = (correctly classified instances) / (total instances).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 4, "end_pos": 12, "type": "METRIC", "confidence": 0.9994617104530334}, {"text": "Accuracy", "start_pos": 31, "end_pos": 39, "type": "METRIC", "confidence": 0.9995453953742981}]}, {"text": "The G-Score metric has been used to rank the systems.", "labels": [], "entities": [{"text": "G-Score", "start_pos": 4, "end_pos": 11, "type": "METRIC", "confidence": 0.9774512648582458}]}, {"text": "The G-score is the harmonic mean of Accuracy and Recall (Paetzold and Specia, 2016).", "labels": [], "entities": [{"text": "G-score", "start_pos": 4, "end_pos": 11, "type": "METRIC", "confidence": 0.9838104248046875}, {"text": "Accuracy", "start_pos": 36, "end_pos": 44, "type": "METRIC", "confidence": 0.9990440011024475}, {"text": "Recall", "start_pos": 49, "end_pos": 55, "type": "METRIC", "confidence": 0.9697397947311401}]}], "tableCaptions": [{"text": " Table 1: POS tagging statistics", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 10, "end_pos": 21, "type": "TASK", "confidence": 0.759013831615448}]}, {"text": " Table 2: System performance (NB: Na\u00a8\u0131veNa\u00a8\u0131ve Bayes, RF: Random", "labels": [], "entities": [{"text": "NB: Na\u00a8\u0131veNa\u00a8\u0131ve Bayes", "start_pos": 30, "end_pos": 52, "type": "METRIC", "confidence": 0.5194208808243275}]}, {"text": " Table 3: Confusion Matrix for systems", "labels": [], "entities": []}]}