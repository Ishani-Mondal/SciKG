{"title": [{"text": "UWB at SemEval-2016 Task 7: Novel Method for Automatic Sentiment Intensity Determination", "labels": [], "entities": [{"text": "UWB", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.7903762459754944}, {"text": "Sentiment Intensity Determination", "start_pos": 55, "end_pos": 88, "type": "TASK", "confidence": 0.8688059647878011}]}], "abstractContent": [{"text": "We present a novel method for determining sentiment intensity.", "labels": [], "entities": [{"text": "determining sentiment intensity", "start_pos": 30, "end_pos": 61, "type": "TASK", "confidence": 0.7271304726600647}]}, {"text": "The main goal is to assign a phrase a score from 0 to 1 which indicates the strength of its association with positive sentiment.", "labels": [], "entities": []}, {"text": "The proposed model uses a rich set of features with Gaussian processes regression model that computes the final score.", "labels": [], "entities": []}, {"text": "The system was evaluated on the data from 7th task of SemEval 2016.", "labels": [], "entities": []}, {"text": "Our regression model trained on the development data reached Kendall rank correlation of 0.659 on general English phrases and 0.414 on En-glish Twitter test data.", "labels": [], "entities": [{"text": "Kendall rank correlation", "start_pos": 61, "end_pos": 85, "type": "METRIC", "confidence": 0.9745740493138632}, {"text": "En-glish Twitter test data", "start_pos": 135, "end_pos": 161, "type": "DATASET", "confidence": 0.7977439165115356}]}], "introductionContent": [{"text": "A great part of today's communication takes place on the Internet.", "labels": [], "entities": []}, {"text": "Many companies make their business on the Web, it is possible to read newspapers through this media, etc.", "labels": [], "entities": []}, {"text": "All these topics are tightly connected with forums, reviews and comments where users express their opinions and feelings.", "labels": [], "entities": []}, {"text": "This great amount of short messages is a very rich source of information.", "labels": [], "entities": []}, {"text": "For example companies can survey how people appreciate their goods or services.", "labels": [], "entities": []}, {"text": "Social media such as Twitter or Facebook can also provide large amount of data for opinion and sentiment analysis.", "labels": [], "entities": [{"text": "opinion and sentiment analysis", "start_pos": 83, "end_pos": 113, "type": "TASK", "confidence": 0.6375675424933434}]}, {"text": "Sentiment analysis can be seen as apart of opinion mining that gives the affective part of an opinion ().", "labels": [], "entities": [{"text": "Sentiment analysis", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.9522237181663513}, {"text": "opinion mining", "start_pos": 43, "end_pos": 57, "type": "TASK", "confidence": 0.7197603583335876}]}, {"text": "The short texts are usually assigned either positive or negative sentiment (i.e. sentiment polarity).", "labels": [], "entities": []}, {"text": "It can be done for example by text categorization techniques.", "labels": [], "entities": []}, {"text": "The minimum cuts are used for this task in ().", "labels": [], "entities": []}, {"text": "Another sentiment analysis approach based on Latent Dirichlet Allocation (LDA) is proposed in ().", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 8, "end_pos": 26, "type": "TASK", "confidence": 0.9508278369903564}, {"text": "Latent Dirichlet Allocation (LDA", "start_pos": 45, "end_pos": 77, "type": "METRIC", "confidence": 0.8747082471847534}]}, {"text": "Many researchers evaluate their approaches on movie or product reviews.", "labels": [], "entities": []}, {"text": "Lately, with the boom of social networks, there are also applications that analyze sentiment on Twitter ().", "labels": [], "entities": []}, {"text": "An important progress was made thanks to the SemEval workshop () in a sentiment analysis task.", "labels": [], "entities": [{"text": "sentiment analysis task", "start_pos": 70, "end_pos": 93, "type": "TASK", "confidence": 0.9602679212888082}]}, {"text": "The task of determining sentiment intensity was introduced as apart of SemEval 2015 task 10.", "labels": [], "entities": [{"text": "determining sentiment intensity", "start_pos": 12, "end_pos": 43, "type": "TASK", "confidence": 0.6995082596937815}, {"text": "SemEval 2015 task", "start_pos": 71, "end_pos": 88, "type": "TASK", "confidence": 0.6444044907887777}]}, {"text": "The goal of this task is to associate a word (or a short phrase) with a score that indicates its sentiment level.", "labels": [], "entities": []}, {"text": "A score of 1 means that the phrase is fully positive whereas 0 is assigned to negative ones.", "labels": [], "entities": []}, {"text": "This approach allows much more fine-grained sentiment evaluation.", "labels": [], "entities": [{"text": "sentiment evaluation", "start_pos": 44, "end_pos": 64, "type": "TASK", "confidence": 0.8758101463317871}]}, {"text": "This year, sentiment intensity determination is the objective of the task 7 () and aims at three separate datasets: General English phrases, English Twitter and Arabic Twitter.", "labels": [], "entities": [{"text": "sentiment intensity determination", "start_pos": 11, "end_pos": 44, "type": "TASK", "confidence": 0.9068915049235026}]}, {"text": "An interesting method that uses no linguistic resources and is based on word embeddings was proposed in ().", "labels": [], "entities": []}, {"text": "The system reached Kendall rank correlation of 0.625 on the SemEval 2015 test data.", "labels": [], "entities": [{"text": "Kendall rank correlation", "start_pos": 19, "end_pos": 43, "type": "METRIC", "confidence": 0.9637885888417562}, {"text": "SemEval 2015 test data", "start_pos": 60, "end_pos": 82, "type": "DATASET", "confidence": 0.8651228845119476}]}, {"text": "Another successful system ( used sentiment lexicons and a regression model to determine the sentiment intensity.", "labels": [], "entities": []}, {"text": "The proposed system computes a rich set of features which are further used to train a regression model that computes the final sentiment intensity score.", "labels": [], "entities": []}, {"text": "Four different types of features are proposed: \u2022 lexicon based features; \u2022 word2vec embeddings ( based features; \u2022 classifier based features; \u2022 other features.", "labels": [], "entities": []}, {"text": "The paper is organized as follows.", "labels": [], "entities": []}, {"text": "Section 2 describes the proposed system.", "labels": [], "entities": []}, {"text": "Section 3 summarizes the experiments conducted with individual features and presents further the final results on the test data.", "labels": [], "entities": []}, {"text": "Section 4 then concludes the paper and lists some perspectives for the future research.", "labels": [], "entities": []}], "datasetContent": [{"text": "First, the development data containing 200 annotated words and phrases were provided for each subtask.", "labels": [], "entities": []}, {"text": "The general English test dataset contains 2,799 words and phrases and the English Twitter dataset contains 1,069 phrases.", "labels": [], "entities": [{"text": "English test dataset", "start_pos": 12, "end_pos": 32, "type": "DATASET", "confidence": 0.819615642229716}, {"text": "English Twitter dataset", "start_pos": 74, "end_pos": 97, "type": "DATASET", "confidence": 0.8484046260515848}]}, {"text": "All of the presented experiments are done on the general English test dataset.", "labels": [], "entities": [{"text": "general English test dataset", "start_pos": 49, "end_pos": 77, "type": "DATASET", "confidence": 0.6754970699548721}]}, {"text": "The testing gold data were not provided.", "labels": [], "entities": []}, {"text": "Therefore, we have tuned our system on the development data as briefly presented below.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Numbers of words in the JRC sentiment lexicon", "labels": [], "entities": [{"text": "JRC sentiment lexicon", "start_pos": 34, "end_pos": 55, "type": "DATASET", "confidence": 0.6813918352127075}]}, {"text": " Table 2: Performance of the individual features on general En-", "labels": [], "entities": [{"text": "general En-", "start_pos": 52, "end_pos": 63, "type": "DATASET", "confidence": 0.7442042032877604}]}, {"text": " Table 3: Results of the regression model with the different fea-", "labels": [], "entities": []}, {"text": " Table 4: Comparison of the top three teams competing in Se-", "labels": [], "entities": [{"text": "Se-", "start_pos": 57, "end_pos": 60, "type": "TASK", "confidence": 0.9048442542552948}]}, {"text": " Table 5: Comparison of the top three teams competing in Se-", "labels": [], "entities": [{"text": "Se-", "start_pos": 57, "end_pos": 60, "type": "TASK", "confidence": 0.9101195633411407}]}]}