{"title": [{"text": "UoB-UK at SemEval-2016 Task 1: A Flexible and Extendable System for Semantic Text Similarity using Types, Surprise and Phrase Linking", "labels": [], "entities": [{"text": "UoB-UK at SemEval-2016 Task 1", "start_pos": 0, "end_pos": 29, "type": "DATASET", "confidence": 0.9008594155311584}, {"text": "Semantic Text Similarity", "start_pos": 68, "end_pos": 92, "type": "TASK", "confidence": 0.6202947100003561}, {"text": "Phrase Linking", "start_pos": 119, "end_pos": 133, "type": "TASK", "confidence": 0.7022078931331635}]}], "abstractContent": [{"text": "We present in this paper a system for measuring Semantic Text Similarity (STS) in English.", "labels": [], "entities": [{"text": "Semantic Text Similarity (STS)", "start_pos": 48, "end_pos": 78, "type": "TASK", "confidence": 0.717674603064855}]}, {"text": "We introduce three novel techniques: the use of Types, methods of linking phrases, and the use of a Surprise Factor to generate 8,370 similarity measures, which we then combine using Support Vector and Kernel Ridge Regression.", "labels": [], "entities": []}, {"text": "Our system out performs the State of the Art in SemEval 2015, and our best performing run achieved a score of .7094 on the 2016 test set as a whole, and over 0.8 on the majority of the datasets.", "labels": [], "entities": []}, {"text": "Additionally, the use of Surprise , Types and phrase linking is not limited to STS and can be used across various Natural Language Processing tasks, while our method of combining scores provides a flexible way of combining variously generated Similarity Scores.", "labels": [], "entities": [{"text": "phrase linking", "start_pos": 46, "end_pos": 60, "type": "TASK", "confidence": 0.6701423823833466}]}], "introductionContent": [], "datasetContent": [], "tableCaptions": [{"text": " Table 2: Performance on the 2016 STS Test Set", "labels": [], "entities": [{"text": "STS Test Set", "start_pos": 34, "end_pos": 46, "type": "DATASET", "confidence": 0.8773348728815714}]}, {"text": " Table 2.  Our system's poor performance on the ans-ans and  ques-ques datasets can be attributed to our choice of  training data, which, although well suited for previ- ous years, was not well suited for these datasets.  However, our system produces State of the Art re- sults on the 2015 Test Sets. A breakdown of each of  the run's performance against the 2015 STS data set  is provided in", "labels": [], "entities": [{"text": "2015 Test Sets", "start_pos": 285, "end_pos": 299, "type": "DATASET", "confidence": 0.7392773628234863}, {"text": "STS data set", "start_pos": 364, "end_pos": 376, "type": "DATASET", "confidence": 0.9417992035547892}]}, {"text": " Table 3. We note that the results we  have reported for previous State of Art for individ- ual data sources are not the results from just the win- ning system but the State of Art across all Systems  for that data source. Our system also achieves com- parable results (0.7793) to that presented by Sul- tan et al. (2015) (0.779) on the 2014 STS dataset.  The weighted mean reported by us does not include  definitions as we decided to consider them indepen- dently.", "labels": [], "entities": [{"text": "STS dataset", "start_pos": 342, "end_pos": 353, "type": "DATASET", "confidence": 0.8279431164264679}]}, {"text": " Table 3: Performance on the 2015 STS Test Set.", "labels": [], "entities": [{"text": "2015 STS Test Set", "start_pos": 29, "end_pos": 46, "type": "DATASET", "confidence": 0.8640770763158798}]}, {"text": " Table 4: Performance on the 2014 STS Test Set.", "labels": [], "entities": [{"text": "2014 STS Test Set", "start_pos": 29, "end_pos": 46, "type": "DATASET", "confidence": 0.9027146846055984}]}]}