{"title": [{"text": "WOLVESAAR at SemEval-2016 Task 1: Replicating the Success of Monolingual Word Alignment and Neural Embeddings for Semantic Textual Similarity", "labels": [], "entities": [{"text": "Monolingual Word Alignment", "start_pos": 61, "end_pos": 87, "type": "TASK", "confidence": 0.6328916450341543}, {"text": "Semantic Textual Similarity", "start_pos": 114, "end_pos": 141, "type": "TASK", "confidence": 0.6170274913311005}]}], "abstractContent": [{"text": "This paper describes the WOLVESAAR systems that participated in the English Semantic Textual Similarity (STS) task in SemEval-2016.", "labels": [], "entities": [{"text": "English Semantic Textual Similarity (STS) task in SemEval-2016", "start_pos": 68, "end_pos": 130, "type": "TASK", "confidence": 0.7316472053527832}]}, {"text": "We replicated the top systems from the last two editions of the STS task and extended the model using GloVe word embed-dings and dense vector space LSTM based sentence representations.", "labels": [], "entities": []}, {"text": "We compared the difference in performance of the replicated system and the extended variants.", "labels": [], "entities": []}, {"text": "Our variants to the replicated system show improved correlation scores and all of our submissions outperform the median scores from all participating systems.", "labels": [], "entities": [{"text": "correlation", "start_pos": 52, "end_pos": 63, "type": "METRIC", "confidence": 0.993953287601471}]}], "introductionContent": [{"text": "Semantic Textual Similarity (STS) is the task of assigning areal number score to quantify the semantic likeness of two text snippets.", "labels": [], "entities": [{"text": "Semantic Textual Similarity (STS)", "start_pos": 0, "end_pos": 33, "type": "TASK", "confidence": 0.8000717212756475}]}, {"text": "Similarity measures play a crucial role in various areas of text processing and translation technologies ranging from improving information retrieval rankings () and text summarization to machine translation evaluation and enhancing matches in translation memory and terminologies.", "labels": [], "entities": [{"text": "text summarization", "start_pos": 166, "end_pos": 184, "type": "TASK", "confidence": 0.6966200172901154}, {"text": "machine translation evaluation", "start_pos": 188, "end_pos": 218, "type": "TASK", "confidence": 0.8644370635350546}]}, {"text": "The annual SemEval STS task () provides a platform where systems are evaluated on the same data and evaluation criteria.", "labels": [], "entities": [{"text": "SemEval STS task", "start_pos": 11, "end_pos": 27, "type": "TASK", "confidence": 0.9330181280771891}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Pearson Correlation Results for English STS Task at SemEval-2016", "labels": [], "entities": [{"text": "English STS Task", "start_pos": 42, "end_pos": 58, "type": "TASK", "confidence": 0.7366971572240194}, {"text": "SemEval-2016", "start_pos": 62, "end_pos": 74, "type": "TASK", "confidence": 0.3862524628639221}]}]}