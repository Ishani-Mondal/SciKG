{"title": [{"text": "Training a Naive Bayes Classifier using Features of an Unsupervised System", "labels": [], "entities": [{"text": "Naive Bayes Classifier", "start_pos": 11, "end_pos": 33, "type": "TASK", "confidence": 0.8456403414408366}]}], "abstractContent": [{"text": "This paper presents the approach of the GTI Research Group to SemEval-2016 task 4 on Sentiment Analysis in Twitter, or more specifically , subtasks A (Message Polarity Classification), B (Tweet classification according to a two-point scale) and D (Tweet quantification according to a two-point scale).", "labels": [], "entities": [{"text": "GTI Research", "start_pos": 40, "end_pos": 52, "type": "DATASET", "confidence": 0.8344278931617737}, {"text": "Sentiment Analysis", "start_pos": 85, "end_pos": 103, "type": "TASK", "confidence": 0.8636442422866821}]}, {"text": "We followed a supervised approach based on the extraction of features by a dependency parsing-based approach using a sentiment lexicon and Natural Language Processing techniques.", "labels": [], "entities": [{"text": "dependency parsing-based", "start_pos": 75, "end_pos": 99, "type": "TASK", "confidence": 0.7099797874689102}]}], "introductionContent": [{"text": "In recent years, research on the field of Sentiment Analysis (SA) has increased considerably, due to the growth of user content generated in social networks, blogs and other platforms on the Internet.", "labels": [], "entities": [{"text": "Sentiment Analysis (SA)", "start_pos": 42, "end_pos": 65, "type": "TASK", "confidence": 0.867535138130188}]}, {"text": "These are considered valuable information for companies, which seek to know or even predict the acceptance of their products, to design their marketing campaigns more efficiently.", "labels": [], "entities": []}, {"text": "One of these sources of information is Twitter, where users can write about any topic, using colloquial and compact language.", "labels": [], "entities": []}, {"text": "As a consecuence, SA in Twitter is specially challenging, as opinions are expressed in one or two short sentences.", "labels": [], "entities": []}, {"text": "Many approaches have been proposed for SA, and can be roughly divided into two categories.", "labels": [], "entities": [{"text": "SA", "start_pos": 39, "end_pos": 41, "type": "TASK", "confidence": 0.9923439621925354}]}, {"text": "The first one tries to capture and model linguistic knowledge through the use of dictionaries) containing words that are tagged with their semantic orientation.", "labels": [], "entities": []}, {"text": "These methods detect the words present in a text using different strategies involving lexics, syntax or semantics ().", "labels": [], "entities": []}, {"text": "The other one is machine learning-based, which is currently the most predominant approach including supervised learning and deep learning.", "labels": [], "entities": []}, {"text": "They widely use classifiers including Support Vector Machines (SVM), Maximum Entropy Models (MAXENT), and Naive Bayes classifiers.", "labels": [], "entities": []}, {"text": "Most of the time, they are built from features of a \"bag of words\" representation.", "labels": [], "entities": []}, {"text": "Our group has participated in SemEval-2016 task 4 on Sentiment Analysis in Twitter, subtasks A (Message Polarity Classification), B (Tweet classification according to a two-point scale) and D (Tweet quantification according to a two-point scale).", "labels": [], "entities": [{"text": "Sentiment Analysis", "start_pos": 53, "end_pos": 71, "type": "TASK", "confidence": 0.9032048583030701}, {"text": "Tweet quantification", "start_pos": 193, "end_pos": 213, "type": "TASK", "confidence": 0.7442922592163086}]}, {"text": "The remainder of this article is structured as follows: Section 2 presents in detail the system proposed for the performance of these subtasks, and Section 3 shows the results obtained and discusses them.", "labels": [], "entities": []}, {"text": "Finally, Section 4 summarizes the main findings and conclusions.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section, the conducted experiments for subtasks A, B and Dare described.", "labels": [], "entities": []}, {"text": "The experiments were carried out using the datasets provided by SemEval-2016 task organizers.", "labels": [], "entities": []}, {"text": "These datasets are composed of texts extracted from Twitter, and in the case of the subtasks B and D, with a given topic.", "labels": [], "entities": []}, {"text": "In subtask A, the number of tweets is and the performance of the system is measured by means of the F-score.", "labels": [], "entities": [{"text": "F-score", "start_pos": 100, "end_pos": 107, "type": "METRIC", "confidence": 0.9945112466812134}]}, {"text": "In subtask B, the number of tweets is 10551 and the performance of the system is measured by means of the macroaveraged recall.", "labels": [], "entities": [{"text": "recall", "start_pos": 120, "end_pos": 126, "type": "METRIC", "confidence": 0.8063054084777832}]}, {"text": "Finally, in subtask D, as in subtask B, the number of tweets is 10551 (same dataset) but this time, the performance of the system is measured by means of the normalized cross-entropy, better known as.", "labels": [], "entities": []}, {"text": "In this last case, there is a minor modification in the formula, with a smoothed version of the originals p(c j ) and\u02c6p and\u02c6 and\u02c6p(c j ), and a smoothing factor . All of these measurements are described in. presents the overall scores for subtasks A, B and D, in their respective test sets: F-measure, recall and KLD, respectively.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 291, "end_pos": 300, "type": "METRIC", "confidence": 0.9872523546218872}, {"text": "recall", "start_pos": 302, "end_pos": 308, "type": "METRIC", "confidence": 0.9990668892860413}, {"text": "KLD", "start_pos": 313, "end_pos": 316, "type": "METRIC", "confidence": 0.9737919569015503}]}, {"text": "The third column shows the unsupervised approach results (UAR) and the fourth shows the supervised approach results (SAR) obtained this year.", "labels": [], "entities": [{"text": "unsupervised approach results (UAR)", "start_pos": 27, "end_pos": 62, "type": "METRIC", "confidence": 0.6648372213045756}, {"text": "supervised approach results (SAR)", "start_pos": 88, "end_pos": 121, "type": "METRIC", "confidence": 0.6447130391995112}]}, {"text": "After performing several experiments on the training, development and development-test datasets provided by organizers, the neutral sentiment intervals were set to [-0.5, 0.5] for subtask A and [-0.05, 0.05] for subtask B (subtask D depends on subtask B).", "labels": [], "entities": []}, {"text": "More specifically, in subtask A, our supervised approach was tested with SemEval-2014 development-test, SemEval-2015 development-test and 2016 development-test datasets provided; in subtask B, it was tested with 2016 development-test dataset; and for subtask D, the 2016 developmenttest dataset results in subtask B were taken into account.", "labels": [], "entities": []}, {"text": "In development time, the improvement of our supervised system was between 1 and 3 % compared to our unsupervised system for subtasks A and B, and for subtask D a difference of -0.02 KLD.", "labels": [], "entities": []}, {"text": "In order to assess the improvement of our supervised system regarding our unsupervised system, a comparison is performed in the test sets of this year, as it can be seen in.", "labels": [], "entities": []}, {"text": "With these results, we can say that the new approach, inmost cases, improves the unsupervised system, between 0.19 and 1.73 % for subtask A and B (except in Twitter Sarcasm 2014), and a difference of -0.012 in subtask D.", "labels": [], "entities": [{"text": "Twitter Sarcasm 2014", "start_pos": 157, "end_pos": 177, "type": "DATASET", "confidence": 0.878432035446167}]}], "tableCaptions": [{"text": " Table 2: Results of the approach for subtasks A, B and D. Tw", "labels": [], "entities": []}, {"text": " Table 3: Positions of the approach for subtasks A, B and D.", "labels": [], "entities": []}]}