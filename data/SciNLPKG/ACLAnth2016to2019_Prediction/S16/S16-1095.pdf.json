{"title": [{"text": "SAARSHEFF at SemEval-2016 Task 1: Semantic Textual Similarity with Machine Translation Evaluation Metrics and (eXtreme) Boosted Tree Ensembles", "labels": [], "entities": [{"text": "SAARSHEFF", "start_pos": 0, "end_pos": 9, "type": "METRIC", "confidence": 0.8886937499046326}, {"text": "Machine Translation Evaluation", "start_pos": 67, "end_pos": 97, "type": "TASK", "confidence": 0.739818145831426}]}], "abstractContent": [{"text": "This paper describes the SAARSHEFF systems that participated in the English Semantic Textual Similarity (STS) task in SemEval-2016.", "labels": [], "entities": [{"text": "English Semantic Textual Similarity (STS) task in SemEval-2016", "start_pos": 68, "end_pos": 130, "type": "TASK", "confidence": 0.7352594405412674}]}, {"text": "We extend the work on using machine translation (MT) metrics in the STS task by automatically annotating the STS datasets with a variety of MT scores for each pair of text snippets in the STS datasets.", "labels": [], "entities": [{"text": "machine translation (MT)", "start_pos": 28, "end_pos": 52, "type": "TASK", "confidence": 0.8447484254837037}]}, {"text": "We trained our systems using boosted tree ensembles and achieved competitive results that outperforms he median Pearson correlation scores from all participating systems.", "labels": [], "entities": [{"text": "Pearson correlation scores", "start_pos": 112, "end_pos": 138, "type": "METRIC", "confidence": 0.9030105868975321}]}], "introductionContent": [{"text": "Semantic Textual Similarity (STS) is the task of measuring the degree to which two texts have the same meaning ().", "labels": [], "entities": [{"text": "Semantic Textual Similarity (STS)", "start_pos": 0, "end_pos": 33, "type": "TASK", "confidence": 0.8064672301212946}]}, {"text": "For instance, given the two texts, \"the man is slicing the tape from the box.\" and \"a man is cutting open a box.\", an STS system predicts areal number similarity score on a scale of 0 (no relation) to 5 (semantic equivalence).", "labels": [], "entities": [{"text": "areal number similarity score", "start_pos": 138, "end_pos": 167, "type": "METRIC", "confidence": 0.6878874376416206}]}, {"text": "This paper presents a collaborative submission between Saarland University and University of Sheffield to the STS English shared task at SemEval-2016.", "labels": [], "entities": [{"text": "STS English shared task at SemEval-2016", "start_pos": 110, "end_pos": 149, "type": "DATASET", "confidence": 0.5477305948734283}]}, {"text": "We have submitted three supervised models that predict the similarity scores for the STS task using Machine Translation (MT) evaluation metrics as regression features.", "labels": [], "entities": [{"text": "STS task", "start_pos": 85, "end_pos": 93, "type": "TASK", "confidence": 0.9087583720684052}, {"text": "Machine Translation (MT) evaluation", "start_pos": 100, "end_pos": 135, "type": "TASK", "confidence": 0.8397018909454346}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Pearson Correlation Results for English STS Task at SemEval-2016", "labels": [], "entities": [{"text": "English STS Task", "start_pos": 42, "end_pos": 58, "type": "TASK", "confidence": 0.7366971572240194}, {"text": "SemEval-2016", "start_pos": 62, "end_pos": 74, "type": "TASK", "confidence": 0.3862524628639221}]}]}