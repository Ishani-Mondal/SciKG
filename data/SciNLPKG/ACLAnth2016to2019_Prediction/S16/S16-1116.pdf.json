{"title": [{"text": "SERGIOJIMENEZ at SemEval-2016 Task 1: Effectively Combining Paraphrase Database, String Matching, WordNet and Word Embedding for Semantic Textual Similarity", "labels": [], "entities": [{"text": "SERGIOJIMENEZ", "start_pos": 0, "end_pos": 13, "type": "METRIC", "confidence": 0.9658856987953186}, {"text": "String Matching", "start_pos": 81, "end_pos": 96, "type": "TASK", "confidence": 0.7297987341880798}, {"text": "Semantic Textual Similarity", "start_pos": 129, "end_pos": 156, "type": "TASK", "confidence": 0.5931874414285024}]}], "abstractContent": [{"text": "In this paper, a system for semantic tex-tual similarity, which participated in Task-1 in SemEval 2016 (monolingual and cross-lingual sub-tasks) is described.", "labels": [], "entities": [{"text": "semantic tex-tual similarity", "start_pos": 28, "end_pos": 56, "type": "TASK", "confidence": 0.6118626395861307}]}, {"text": "The system contains a preprocessing step that simplifies text using PPDB 2.0 and detects negations.", "labels": [], "entities": []}, {"text": "Also, six lexical similarity functions were constructed using string matching, word embedding and synonyms-antonyms relations in WordNet.", "labels": [], "entities": [{"text": "string matching", "start_pos": 62, "end_pos": 77, "type": "TASK", "confidence": 0.7666627168655396}, {"text": "WordNet", "start_pos": 129, "end_pos": 136, "type": "DATASET", "confidence": 0.9552592039108276}]}, {"text": "These lexical similarity functions are projected to sentence level using anew method called Polarized Soft Cardinality that supports negative similarities between words to model opposites.", "labels": [], "entities": []}, {"text": "We also introduce a novel L 2-norm \"cardinality\" for vector space representations.", "labels": [], "entities": []}, {"text": "The system extracts a set of 660 features from each pair of text snippets using the proposed cardinality measures.", "labels": [], "entities": []}, {"text": "From this set, a subset of 12 features was selected in a supervised manner.", "labels": [], "entities": []}, {"text": "These features are combined by SVR and, alternatively, by using the arithmetic mean to produce similarity predictions.", "labels": [], "entities": []}, {"text": "Our team ranked second in the cross-lingual sub-task and got close to the best official results in the monolingual sub-task.", "labels": [], "entities": []}], "introductionContent": [{"text": "Semantic Textual Similarity (STS) is a fundamental task in the field of natural language processing that has been addressed in SemEval competitions uninterruptedly since 2012 (.", "labels": [], "entities": [{"text": "Semantic Textual Similarity (STS)", "start_pos": 0, "end_pos": 33, "type": "TASK", "confidence": 0.8286109368006388}, {"text": "natural language processing", "start_pos": 72, "end_pos": 99, "type": "TASK", "confidence": 0.6660391887029012}]}, {"text": "The task is to compare two text fragments and produce a similarity score that is assessed according to human judgment.", "labels": [], "entities": [{"text": "similarity score", "start_pos": 56, "end_pos": 72, "type": "METRIC", "confidence": 0.9466369152069092}]}, {"text": "This year (), anew cross-lingual sub-task in English and Spanish is proposed in addition to the traditional monolingual English task.", "labels": [], "entities": []}, {"text": "In SemEval 2015, the most popular approach among the best systems was the use of words alignments between sentences combining resources such as WordNet, neural word embedding (Mikolov,) and the Paraphrase Database ().", "labels": [], "entities": [{"text": "words alignments between sentences", "start_pos": 81, "end_pos": 115, "type": "TASK", "confidence": 0.8045654818415642}, {"text": "WordNet", "start_pos": 144, "end_pos": 151, "type": "DATASET", "confidence": 0.9595392942428589}]}, {"text": "This paper describes our system submission to STS 2016 that uses a cardinality-based approach (instead of word alignments) for combining the resources mentioned above.", "labels": [], "entities": []}, {"text": "Several teams have used soft cardinality successfully in previous STS competitions from 2012 to 2014 ().", "labels": [], "entities": []}, {"text": "For the proposed system, we extended the model of soft cardinality to allow the use of negative values in the lexical similarity component to model opposites due to antonymy and negation.", "labels": [], "entities": []}, {"text": "shows the overall architecture of the proposed system.", "labels": [], "entities": []}, {"text": "Yellow labels in the upper left corner of each process component (blue squares) indicate the sections of this document where the module is discussed.", "labels": [], "entities": []}, {"text": "In this figure, the processing pipeline is represented vertically in three stages: preprocessing, feature extraction and model learning.", "labels": [], "entities": [{"text": "feature extraction", "start_pos": 98, "end_pos": 116, "type": "TASK", "confidence": 0.7842464447021484}]}, {"text": "Red parallelograms represent the inputs and outputs of each process, from the pair of snippets of text for evaluation, through different intermediate representations (bag-of-words, vectors, etc.) and end on the predictions of similarity scores.", "labels": [], "entities": []}, {"text": "The left side contains the used external resources linked to the process that makes use of each one.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 3: Results of our 2016 systems using data from previ-", "labels": [], "entities": [{"text": "previ", "start_pos": 54, "end_pos": 59, "type": "DATASET", "confidence": 0.9532538056373596}]}, {"text": " Table 4: Results of our 2016 systems being compared against", "labels": [], "entities": []}, {"text": " Table 5: Official results for our participating systems in the", "labels": [], "entities": []}, {"text": " Table 6: Official results for our participating systems in the", "labels": [], "entities": []}]}