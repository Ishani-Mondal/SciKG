{"title": [{"text": "Melbourne at SemEval 2016 Task 11: Classifying Type-level Word Complexity using Random Forests with Corpus and Word List Features", "labels": [], "entities": [{"text": "SemEval 2016 Task 11", "start_pos": 13, "end_pos": 33, "type": "TASK", "confidence": 0.5173367634415627}, {"text": "Classifying Type-level Word Complexity", "start_pos": 35, "end_pos": 73, "type": "TASK", "confidence": 0.7338027060031891}]}], "abstractContent": [{"text": "SemEval 2016 task 11 involved determining whether words in a sentence were complex or simple fora cohort of people with English as a second language.", "labels": [], "entities": [{"text": "SemEval 2016 task 11", "start_pos": 0, "end_pos": 20, "type": "TASK", "confidence": 0.6656180322170258}]}, {"text": "Training data consisted of 200 annotated sentences, representing the combined judgements of 20 human annota-tors, such that if any annotator of the group labelled a word as complex, then it was considered to be complex.", "labels": [], "entities": []}, {"text": "Testing was based on single annotator judgements.", "labels": [], "entities": []}, {"text": "Our system used a random forest classifier with a variety of features , the most important of which were term frequency statistics garnered from four large corpora, and style lexicons built on two large corpora.", "labels": [], "entities": []}, {"text": "Minor features in the final system include the presence or absence of words in various readability word lists; many other features we tried were not successful.", "labels": [], "entities": []}, {"text": "Our ranking amongst submitted systems did not reflect the strength of our system, due to submitting afar from optimal weighting between complex and simple, but we show that when a more appropriate weighting is used, our system ranks amongst the best submitted systems.", "labels": [], "entities": []}], "introductionContent": [{"text": "Most work related to readability measurement ( focuses on text-level assessment, but it is clear that being able to determine the difficulty of individual words is important to both that task as well as related ones such as lexical text simplification.", "labels": [], "entities": [{"text": "readability measurement", "start_pos": 21, "end_pos": 44, "type": "TASK", "confidence": 0.7200062274932861}, {"text": "lexical text simplification", "start_pos": 224, "end_pos": 251, "type": "TASK", "confidence": 0.6664097209771475}]}, {"text": "Although some words can be considered conceptually difficult -that is, a level of intellectual sophistication is required to grasp its meaning -for language learners, it is more common for words to be considered difficult (or complex) simply because a reader has had little or no exposure to them.", "labels": [], "entities": []}, {"text": "This exposure may depend on many different external factors related to the person's background, some of which may generalize across other similar readers, while others maybe entirely idiosyncratic to the reader in question.", "labels": [], "entities": []}, {"text": "For example, those who study academic English, or operate in an academic environment, have a different vocabulary exposure to those who specialize in hospitality English.", "labels": [], "entities": []}, {"text": "Therefore, there is value in not only trying to predict some prior difficulty of a word, but also trying to generalize across readers in a similar cohort.", "labels": [], "entities": []}, {"text": "Task 11 of the 2016 SemEval competition (Complex Word Identification) is aimed at addressing this challenge.", "labels": [], "entities": [{"text": "SemEval competition (Complex Word Identification)", "start_pos": 20, "end_pos": 69, "type": "TASK", "confidence": 0.7088914683886937}]}, {"text": "This paper describes our system for the task.", "labels": [], "entities": []}, {"text": "We commenced with previous work in word readability scoring) and stylistic lexicon creation).", "labels": [], "entities": [{"text": "word readability scoring", "start_pos": 35, "end_pos": 59, "type": "TASK", "confidence": 0.7386355598767599}, {"text": "stylistic lexicon creation", "start_pos": 65, "end_pos": 91, "type": "TASK", "confidence": 0.7529623111089071}]}, {"text": "For features, we drew on a diverse set of corpus-based and human-derived metrics, and built a random forest-based classifier.", "labels": [], "entities": []}, {"text": "While a mistake related to the proper distribution of complex versus simple words prevented us from scoring amongst the top teams in either of the evaluations metrics used in this task, we show that by appropriate class weighting with the same classifier and features, we can obtain results on either metric that are competitive or better than the best teams.", "labels": [], "entities": []}], "datasetContent": [{"text": "The evaluation for this task includes 3 basic metrics (precision, recall, and accuracy) and two combined metrics based on them (F-score and G-score).", "labels": [], "entities": [{"text": "precision", "start_pos": 55, "end_pos": 64, "type": "METRIC", "confidence": 0.999220609664917}, {"text": "recall", "start_pos": 66, "end_pos": 72, "type": "METRIC", "confidence": 0.9937174320220947}, {"text": "accuracy", "start_pos": 78, "end_pos": 86, "type": "METRIC", "confidence": 0.9987928867340088}, {"text": "F-score", "start_pos": 128, "end_pos": 135, "type": "METRIC", "confidence": 0.9955506324768066}, {"text": "G-score", "start_pos": 140, "end_pos": 147, "type": "METRIC", "confidence": 0.9759901762008667}]}, {"text": "For precision and recall, the positive class is COM-PLEX, and this is the basis for calculating F-score.", "labels": [], "entities": [{"text": "precision", "start_pos": 4, "end_pos": 13, "type": "METRIC", "confidence": 0.999421238899231}, {"text": "recall", "start_pos": 18, "end_pos": 24, "type": "METRIC", "confidence": 0.9990928173065186}, {"text": "COM-PLEX", "start_pos": 48, "end_pos": 56, "type": "METRIC", "confidence": 0.9240245223045349}, {"text": "F-score", "start_pos": 96, "end_pos": 103, "type": "METRIC", "confidence": 0.9948575496673584}]}, {"text": "G-score, the primary evaluation metric for this competition, is the harmonic mean of precision and accuracy, putting extra emphasis on recall for the COM-PLEX class beyond that which is built into the accuracy score.", "labels": [], "entities": [{"text": "G-score", "start_pos": 0, "end_pos": 7, "type": "METRIC", "confidence": 0.9610664248466492}, {"text": "precision", "start_pos": 85, "end_pos": 94, "type": "METRIC", "confidence": 0.9987216591835022}, {"text": "accuracy", "start_pos": 99, "end_pos": 107, "type": "METRIC", "confidence": 0.9986521601676941}, {"text": "recall", "start_pos": 135, "end_pos": 141, "type": "METRIC", "confidence": 0.9992321729660034}, {"text": "accuracy", "start_pos": 201, "end_pos": 209, "type": "METRIC", "confidence": 0.9986721277236938}]}, {"text": "Relevant to this task, the effect of G-score is opposite to the class imbalance problem mentioned earlier: when training on a set where the positive class is over-represented, the resulting classifier will do better on G-score than F-score because it will tend to overestimate the instances of the positive class, improving recall.", "labels": [], "entities": [{"text": "G-score", "start_pos": 37, "end_pos": 44, "type": "METRIC", "confidence": 0.9680398106575012}, {"text": "recall", "start_pos": 324, "end_pos": 330, "type": "METRIC", "confidence": 0.9973945617675781}]}, {"text": "shows the performance of our system for the various metrics across different weightings of the COMPLEX class.", "labels": [], "entities": [{"text": "COMPLEX class", "start_pos": 95, "end_pos": 108, "type": "DATASET", "confidence": 0.8920807838439941}]}, {"text": "With regard to G-score and F-score, our best submitted system is far from optimal, since we overestimated the effect of G-score, and underestimated the influence of the class imbalance between the training and test sets; we incorrectly put too much weight on the COMPLEX class, which resulted in a G-score of 0.701 (12th ranked) for the 1.5 weighting of COMPLEX, and 0.647 (19th ranked) for the 3.0 weighting of COMPLEX.", "labels": [], "entities": [{"text": "G-score", "start_pos": 15, "end_pos": 22, "type": "METRIC", "confidence": 0.9008569717407227}, {"text": "F-score", "start_pos": 27, "end_pos": 34, "type": "METRIC", "confidence": 0.992723286151886}, {"text": "COMPLEX", "start_pos": 354, "end_pos": 361, "type": "DATASET", "confidence": 0.9272207617759705}, {"text": "COMPLEX", "start_pos": 412, "end_pos": 419, "type": "DATASET", "confidence": 0.962847888469696}]}, {"text": "However, across all possible weightings, our best G-score (0.773), which is our system without any weighting at all, is tied with the second best G-score in the competition (the best score was 0.774).", "labels": [], "entities": [{"text": "G-score", "start_pos": 50, "end_pos": 57, "type": "METRIC", "confidence": 0.9928703904151917}]}, {"text": "If we put more weight on simple words, we reach the maximum F-score of 0.355 when the ratio is (roughly) 3 to 1 in favor of simple words; this F-score is better than any other reported F-score (the best F-score of a submitted system is 0.353), though we note that teams might have been more focused on optimizing G-score, since it was the primary metric.", "labels": [], "entities": [{"text": "F-score", "start_pos": 60, "end_pos": 67, "type": "METRIC", "confidence": 0.9981246590614319}, {"text": "F-score", "start_pos": 143, "end_pos": 150, "type": "METRIC", "confidence": 0.9927126169204712}, {"text": "F-score", "start_pos": 203, "end_pos": 210, "type": "METRIC", "confidence": 0.9574626684188843}]}, {"text": "Accuracy is maximized simply by minimizing the number of COMPLEX guesses, and in fact guessing only SIM-PLE will net an accuracy of 0.953, which is impossible for our system to beat.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 0, "end_pos": 8, "type": "METRIC", "confidence": 0.9932812452316284}, {"text": "accuracy", "start_pos": 120, "end_pos": 128, "type": "METRIC", "confidence": 0.9991769194602966}]}, {"text": "lation study using the best system with regard to each the two combined metrics (no weighting for G-score, 1/3 weighting for F-score); results were erratic for less than optimal values.", "labels": [], "entities": [{"text": "G-score", "start_pos": 98, "end_pos": 105, "type": "METRIC", "confidence": 0.9775322675704956}, {"text": "F-score", "start_pos": 125, "end_pos": 132, "type": "METRIC", "confidence": 0.9970601201057434}]}, {"text": "Term frequency information is clearly the most important source of information for deciding complexity, but we also see improvements due to the stylistic lexicons built using co-occurrence information, and the minor features.", "labels": [], "entities": []}, {"text": "The effects are not consistent with respect to degree across the two metrics, likely because different feature sets result in substantially different class distributions, which in turn have very different effects on G-score and F-score.", "labels": [], "entities": [{"text": "G-score", "start_pos": 216, "end_pos": 223, "type": "METRIC", "confidence": 0.9692437648773193}, {"text": "F-score", "start_pos": 228, "end_pos": 235, "type": "METRIC", "confidence": 0.9891242980957031}]}], "tableCaptions": [{"text": " Table 1 shows the results of a small feature ab-", "labels": [], "entities": []}]}