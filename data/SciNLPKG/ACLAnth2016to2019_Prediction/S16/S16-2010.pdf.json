{"title": [{"text": "Improving Zero-Shot-Learning for German Particle Verbs by using Training-Space Restrictions and Local Scaling", "labels": [], "entities": []}], "abstractContent": [{"text": "Recent models in distributional semantics consider derivational patterns (e.g., use \u2192 use + f ul) as the result of a compositional process, where base term and affix are combined.", "labels": [], "entities": []}, {"text": "We exploit such models for German particle verbs (PVs), and focus on the task of learning a mapping function between base verbs and particle verbs.", "labels": [], "entities": []}, {"text": "Our models apply particle-verb motivated training-space restrictions relying on nearest neighbors, as well as recent advances from zero-shot-learning.", "labels": [], "entities": []}, {"text": "The models improve the mapping between base terms and derived terms fora new PV derivation dataset, and also across existing derivation datasets for German and English.", "labels": [], "entities": [{"text": "PV derivation dataset", "start_pos": 77, "end_pos": 98, "type": "DATASET", "confidence": 0.7144824465115865}]}], "introductionContent": [{"text": "were the first to apply distributional semantic models (DSMs) to the task of deriving the meaning of morphologically complex words from their parts.", "labels": [], "entities": [{"text": "deriving the meaning of morphologically complex words from their parts", "start_pos": 77, "end_pos": 147, "type": "TASK", "confidence": 0.7838342845439911}]}, {"text": "They relied on high-dimensional vector representations to model the derived term (e.g., useful) as a result of a compositional process that combines the meanings of the base term (e.g., to use) and the affix (e.g., ful).", "labels": [], "entities": []}, {"text": "For evaluation, they compared the predicted vector of the complex word with the original, corpus-based vector.", "labels": [], "entities": []}, {"text": "More recently, put the task of modeling derivation into the perspective of zero-shot-learning: instead of using cosine similarities they predicted the derived term by learning a mapping function between the base term and the derived term.", "labels": [], "entities": []}, {"text": "Once the predicted vector was computed, a nearest neighbor search was applied to validate if the prediction corresponded to the derived term.", "labels": [], "entities": []}, {"text": "In zero-shotlearning the task is to predict novel values, i.e., values that were never seen in training.", "labels": [], "entities": []}, {"text": "More formally, zero-shot-learning trains a classifier f : X \u2192 Y that predicts novel values for Y (.", "labels": [], "entities": []}, {"text": "It is often applied across vector spaces, such as different domains.", "labels": [], "entities": []}, {"text": "The experiments by were performed over six derivational patterns for German (cf. Table 1), including particle verbs (PVs) with two different particle prefixes (an and durch), which were particularly difficult to predict.", "labels": [], "entities": []}, {"text": "PVs such as anfangen (to start) are compositions of abase verb (BV) such as fangen (to catch) and a verb particle such as an.", "labels": [], "entities": []}, {"text": "Predicting PV meaning is challenging because German PVs are highly productive, and the particles are notoriously ambiguous).", "labels": [], "entities": []}, {"text": "Furthermore, the particles often trigger meaning shifts when they combine with base verbs, so the resulting PVs represent frequent cases of non-literal meaning.", "labels": [], "entities": []}, {"text": "In this paper, we focus on predicting the meanings of German PV derivations.", "labels": [], "entities": []}, {"text": "Our models provide two contributions to the research field of predicting derivations: (i) We suggest a novel idea of restricting the available training data, which has a positive impact on the mapping quality.", "labels": [], "entities": [{"text": "predicting derivations", "start_pos": 62, "end_pos": 84, "type": "TASK", "confidence": 0.931311845779419}]}, {"text": "(ii) We integrate a correction method for popular nearest neighbors into our models, so-called hubs, to improve the prediction quality.: New German PV derivation dataset.", "labels": [], "entities": [{"text": "German PV derivation dataset", "start_pos": 141, "end_pos": 169, "type": "DATASET", "confidence": 0.7795483469963074}]}], "datasetContent": [{"text": "As in, we treat every derivation type as a specific learning problem: we take a set of word pairs with a particular derivation pattern (e.g., \"-in\", B\u00e4cker::B\u00e4ckerin), and divide this set into training and test pairs by performing 10-fold cross-validation.", "labels": [], "entities": []}, {"text": "For the test pairs, we predict the vectors of the derived terms (e.g., The search space includes all corpus words across parts-of-speech, except for the base term.", "labels": [], "entities": []}, {"text": "The performance is measured in terms of recall-out-of-5, counting how often the correct derived term is found among the five nearest neighbors of the predicted vector.", "labels": [], "entities": [{"text": "recall-out-of-5", "start_pos": 40, "end_pos": 55, "type": "METRIC", "confidence": 0.9991127848625183}]}, {"text": "We created anew collection of German particle verb derivations 1 relying on the same resource as, the semiautomatic derivational lexicon for German DErivBase ().", "labels": [], "entities": []}, {"text": "From DErivBase, we induced all pairs of base verbs and particle verbs across seven different particles.", "labels": [], "entities": [{"text": "DErivBase", "start_pos": 5, "end_pos": 14, "type": "DATASET", "confidence": 0.869868814945221}]}, {"text": "Nonexisting verbs were manually filtered out.", "labels": [], "entities": []}, {"text": "In total, our collection contains 1 410 BV-PV combinations across seven particles, cf..", "labels": [], "entities": []}, {"text": "In addition, we apply our models to two existing collections for derivational patterns, the German dataset from, comprising six derivational patterns with 80 in-stances each (cf., and the English dataset from, comprising 18 derivational patterns (3 prefixes and 15 suffixes) and 7 449 instances (cf.", "labels": [], "entities": [{"text": "German dataset", "start_pos": 92, "end_pos": 106, "type": "DATASET", "confidence": 0.8788753151893616}, {"text": "English dataset", "start_pos": 188, "end_pos": 203, "type": "DATASET", "confidence": 0.8684187531471252}]}], "tableCaptions": [{"text": " Table 4: Macro-averaged recall-out-of-5 across methods, with and without local scaling N I 15 .", "labels": [], "entities": [{"text": "recall-out-of-5", "start_pos": 25, "end_pos": 40, "type": "METRIC", "confidence": 0.9826709628105164}]}]}