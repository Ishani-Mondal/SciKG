{"title": [{"text": "CNRC at SemEval-2016 Task 1: Experiments in Crosslingual Semantic Textual Similarity", "labels": [], "entities": [{"text": "Crosslingual Semantic Textual Similarity", "start_pos": 44, "end_pos": 84, "type": "TASK", "confidence": 0.5562007799744606}]}], "abstractContent": [{"text": "We describe the systems entered by the National Research Council Canada in the SemEval-2016 Task1: Crosslingual Semantic Textual Similarity.", "labels": [], "entities": [{"text": "National Research Council Canada", "start_pos": 39, "end_pos": 71, "type": "DATASET", "confidence": 0.9027348905801773}, {"text": "SemEval-2016 Task1: Crosslingual Semantic Textual Similarity", "start_pos": 79, "end_pos": 139, "type": "TASK", "confidence": 0.609572274344308}]}, {"text": "We tried two approaches: One computes a true crosslingual similarity based on features extracted from lexical semantics and shallow semantic structures of the source and target fragments, combined using a linear model.", "labels": [], "entities": []}, {"text": "The other approach relies on Statistical Machine Translation, followed by a monolingual semantic similarity, relying again on syntactic and semantic features.", "labels": [], "entities": [{"text": "Statistical Machine Translation", "start_pos": 29, "end_pos": 60, "type": "TASK", "confidence": 0.7477736473083496}]}, {"text": "We report our experiments using trial data, as well as official final results on the evaluation data.", "labels": [], "entities": []}], "introductionContent": [{"text": "The SemEval-2016 Semantic Textual Similarity (STS) evaluation (task1) introduced a crosslingual track.", "labels": [], "entities": [{"text": "SemEval-2016 Semantic Textual Similarity (STS)", "start_pos": 4, "end_pos": 50, "type": "TASK", "confidence": 0.8073824644088745}]}, {"text": "Given a Spanish-English bilingual fragment pair, the goal is to compute the degree of equivalence between them.", "labels": [], "entities": []}, {"text": "This offers additional challenges compared to the \"STS Core\" track, where both fragments are in the same language.", "labels": [], "entities": [{"text": "STS Core\" track", "start_pos": 51, "end_pos": 66, "type": "DATASET", "confidence": 0.8971585184335709}]}, {"text": "The crosslingual track requires potentially to detect which fragment is in which language, perform further language processing accordingly, and estimate lexical and semantic similarities across languages.", "labels": [], "entities": []}, {"text": "In our work, we investigated two approaches.", "labels": [], "entities": []}, {"text": "In the first approach, we try to build a true crosslingual similarity based on a number of features computed from both fragments.", "labels": [], "entities": []}, {"text": "One of these features projects Spanish words into an English embedding space in order to compute similarities in that space.", "labels": [], "entities": []}, {"text": "Other features compute various kinds of syntactic and semantic overlap between the fragments.", "labels": [], "entities": []}, {"text": "These features are combined in a linear model estimated on the trial data, and combined with an isotonic regression (de) layer in order to account for non-linearity in the scores.", "labels": [], "entities": []}, {"text": "The second approach uses a Statistical Machine Translation system to map Spanish fragments to English, then relies on a monolingual semantic similarity between the translated fragment and the English fragment.", "labels": [], "entities": [{"text": "Statistical Machine Translation", "start_pos": 27, "end_pos": 58, "type": "TASK", "confidence": 0.6802682479222616}]}, {"text": "Various monolingual similarity features, using embeddings, syntactic and semantic information, are computed and combined again using a linear model followed by an isotonic regression layer.", "labels": [], "entities": []}, {"text": "In the next section, we describe the two approaches and their components: SMT system, crosslingual and monolingual feature extraction, and the output layer fitting the features to the semantic similarity scores.", "labels": [], "entities": [{"text": "SMT", "start_pos": 74, "end_pos": 77, "type": "TASK", "confidence": 0.9936931133270264}, {"text": "crosslingual and monolingual feature extraction", "start_pos": 86, "end_pos": 133, "type": "TASK", "confidence": 0.6747123181819916}]}, {"text": "We then describe the corpora used to fit the features to the output similarity score, and make various modeling choices (Section 3).", "labels": [], "entities": []}, {"text": "We present our experimental results on the trial and test data in Section 4.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 2: Estimated results on the trial data (  *  estimates from", "labels": [], "entities": [{"text": "Estimated", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9856908917427063}]}, {"text": " Table 3: Official evaluation results for our three runs.", "labels": [], "entities": []}]}