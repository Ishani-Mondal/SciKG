{"title": [{"text": "HMC at SemEval-2016 Task 11: Identifying Complex Words Using Depth-limited Decision Trees", "labels": [], "entities": [{"text": "SemEval-2016 Task 11", "start_pos": 7, "end_pos": 27, "type": "TASK", "confidence": 0.559507687886556}, {"text": "Identifying Complex Words", "start_pos": 29, "end_pos": 54, "type": "TASK", "confidence": 0.8842848738034567}]}], "abstractContent": [{"text": "We present two systems created for SemEval-2016s Task 11: Complex Word Identification.", "labels": [], "entities": [{"text": "SemEval-2016s Task 11", "start_pos": 35, "end_pos": 56, "type": "TASK", "confidence": 0.8749897281328837}, {"text": "Complex Word Identification", "start_pos": 58, "end_pos": 85, "type": "TASK", "confidence": 0.6352902551492056}]}, {"text": "Our two systems, a regression tree and decision tree, were trained with a word's uni-gram and lemma word counts, average age-of-acquisition, and a measure of concreteness.", "labels": [], "entities": []}, {"text": "The systems ranked 5th and 6th, respectively, on the test set by G-score (the harmonic mean between accuracy and recall).", "labels": [], "entities": [{"text": "G-score", "start_pos": 65, "end_pos": 72, "type": "METRIC", "confidence": 0.9969128370285034}, {"text": "accuracy", "start_pos": 100, "end_pos": 108, "type": "METRIC", "confidence": 0.9797952175140381}, {"text": "recall", "start_pos": 113, "end_pos": 119, "type": "METRIC", "confidence": 0.9532716870307922}]}, {"text": "With the regression tree's predictions earning a G-score of 0.766, and the decision tree's earning 0.765, the two systems scored within 1 percent of the score of the best-performing system in the task.", "labels": [], "entities": [{"text": "G-score", "start_pos": 49, "end_pos": 56, "type": "METRIC", "confidence": 0.9821410179138184}]}], "introductionContent": [{"text": "Text simplification is the process of reducing the complexity of a text while preserving the original meaning.", "labels": [], "entities": [{"text": "Text simplification", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.8134267628192902}]}, {"text": "Text simplification may include syntactic or pragmatic aspects, but much of the work that has been done has focused on lexical simplifications.", "labels": [], "entities": [{"text": "Text simplification", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.762994110584259}]}, {"text": "In lexical simplification, difficult words or phrases are replaced to make a text more accessible.", "labels": [], "entities": [{"text": "lexical simplification", "start_pos": 3, "end_pos": 25, "type": "TASK", "confidence": 0.7062028050422668}]}, {"text": "This kind of simplification can benefit several reader populations, including secondlanguage learners.", "labels": [], "entities": []}, {"text": "One important first step in lexical simplification is complex word identification.", "labels": [], "entities": [{"text": "lexical simplification", "start_pos": 28, "end_pos": 50, "type": "TASK", "confidence": 0.8527265787124634}, {"text": "complex word identification", "start_pos": 54, "end_pos": 81, "type": "TASK", "confidence": 0.5939637621243795}]}, {"text": "This step predicts which words in a text will be difficult fora reader so that they can then be targeted for simplification.", "labels": [], "entities": []}, {"text": "The International Workshop on Semantic Evaluation for 2016 hosted Task 11: Complex Word Identification (CWI), which asked participants to identify words that would be challenging for non-native English speakers).", "labels": [], "entities": [{"text": "Complex Word Identification (CWI)", "start_pos": 75, "end_pos": 108, "type": "TASK", "confidence": 0.7545695304870605}]}, {"text": "Task participants were given 2,237 training examples.", "labels": [], "entities": []}, {"text": "Each example contained a word, the sentence containing the word, and the word's index in the sentence.", "labels": [], "entities": []}, {"text": "In addition, each word was labeled as complex or not complex (or simple) by 20 human annotators, and each word was given a binary label of complex if at least one annotator thought the word was hard to read.", "labels": [], "entities": []}, {"text": "The individual labels of the 20 annotators were also made available to participants.", "labels": [], "entities": []}, {"text": "Submissions were evaluated on a test set of 88,221 words.", "labels": [], "entities": []}, {"text": "Test set items had the same format as the training set, except that they were only annotated by one person, so the labels indicated whether that annotator alone labeled it complex.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 2: Summary of system performance on the CWI test set", "labels": [], "entities": [{"text": "CWI test set", "start_pos": 47, "end_pos": 59, "type": "DATASET", "confidence": 0.9598496754964193}]}]}