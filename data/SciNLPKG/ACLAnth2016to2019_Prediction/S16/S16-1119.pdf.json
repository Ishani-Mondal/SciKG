{"title": [{"text": "iUBC at SemEval-2016 Task 2: RNNs and LSTMs for interpretable STS", "labels": [], "entities": [{"text": "iUBC at SemEval-2016 Task", "start_pos": 0, "end_pos": 25, "type": "DATASET", "confidence": 0.8548623323440552}, {"text": "interpretable STS", "start_pos": 48, "end_pos": 65, "type": "TASK", "confidence": 0.9709106087684631}]}], "abstractContent": [{"text": "This paper describes iUBC, a neural network based approach that achieves competitive results on the interpretable STS task (iSTS 2016).", "labels": [], "entities": [{"text": "iSTS 2016)", "start_pos": 124, "end_pos": 134, "type": "DATASET", "confidence": 0.928796648979187}]}, {"text": "Actually, it achieves top performance in one of the three datasets.", "labels": [], "entities": []}, {"text": "iUBC makes use of a jointly trained classifier and regressor, and both models work on top of a recurrent neural network.", "labels": [], "entities": [{"text": "iUBC", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.9424263834953308}]}, {"text": "Through the paper we provide detailed description of the approach, as well as the results obtained in iSTS 2015 test, iSTS 2016 training and iSTS 2016 test.", "labels": [], "entities": [{"text": "iSTS 2015 test", "start_pos": 102, "end_pos": 116, "type": "DATASET", "confidence": 0.907484233379364}, {"text": "iSTS 2016 training", "start_pos": 118, "end_pos": 136, "type": "DATASET", "confidence": 0.8576094110806783}, {"text": "iSTS 2016 test", "start_pos": 141, "end_pos": 155, "type": "DATASET", "confidence": 0.8979425430297852}]}], "introductionContent": [{"text": "Semantic Textual Similarity (STS) aims to catch the degree of equivalence between a pair of text nuggets.", "labels": [], "entities": [{"text": "Semantic Textual Similarity (STS)", "start_pos": 0, "end_pos": 33, "type": "TASK", "confidence": 0.816401461760203}]}, {"text": "Interpretable STS (iSTS) is beyond STS in that it adds fine-grained information when evaluating the equivalence between text snippets.", "labels": [], "entities": [{"text": "Interpretable STS (iSTS)", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.7688307821750641}]}, {"text": "This explanatory layer is achieved by aligning text segments pertaining to one sentence with the segments pertaining to the second sentence, and, for each alignment, indicating a relation label and a similarity score.", "labels": [], "entities": []}, {"text": "In sum, alignments consist of a similarity score and a relation label that are defined as follows.", "labels": [], "entities": [{"text": "similarity score", "start_pos": 32, "end_pos": 48, "type": "METRIC", "confidence": 0.9306411743164062}]}, {"text": "On the one hand, the relation label has to be chosen from a set of categorical values (equivalence, opposition, specialization, similarity and other kind of relation).", "labels": [], "entities": []}, {"text": "On the other hand, the similarity score has to be areal number bounded by.", "labels": [], "entities": [{"text": "similarity score", "start_pos": 23, "end_pos": 39, "type": "METRIC", "confidence": 0.9772487878799438}]}, {"text": "Apart from this, there is an extra label to handle not aligned text segments.", "labels": [], "entities": []}, {"text": "The present paper describes iUBC and its participation in the International Workshop on Semantic Evaluation (SemEval-2016) task 2: Interpretable Semantic Textual Similarity.", "labels": [], "entities": [{"text": "International Workshop on Semantic Evaluation (SemEval-2016) task", "start_pos": 62, "end_pos": 127, "type": "TASK", "confidence": 0.5925114618407356}]}, {"text": "To check the task in full detail please refer to.", "labels": [], "entities": []}, {"text": "Note that some of the authors participated in the organization of the task.", "labels": [], "entities": []}, {"text": "Organizers prevented developers from access to the test dataset, and only allowed to access the same data as the rest of participants.", "labels": [], "entities": []}, {"text": "The paper is organized as follows.", "labels": [], "entities": []}, {"text": "Section 2 describes iUBC's components, section 3 describes development performance and run configurations, section 4 shows the results obtained in the iSTS 2016 task, and, finally, section 5 mentions the conclusions and future work directions.", "labels": [], "entities": [{"text": "iSTS 2016 task", "start_pos": 151, "end_pos": 165, "type": "DATASET", "confidence": 0.790306568145752}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 2: iSTS 2015 test results in Headlines and Images on", "labels": [], "entities": [{"text": "iSTS 2015 test", "start_pos": 10, "end_pos": 24, "type": "DATASET", "confidence": 0.8897717992464701}]}, {"text": " Table 2. Comparing our  runs to the published results, we think they perform  competitively. According to the F evaluation met- ric, in both datasets we obtain equal or higher re- sults than the maximum score among participants,", "labels": [], "entities": [{"text": "F evaluation met- ric", "start_pos": 111, "end_pos": 132, "type": "METRIC", "confidence": 0.8987043380737305}, {"text": "re- sults", "start_pos": 177, "end_pos": 186, "type": "METRIC", "confidence": 0.968527615070343}]}, {"text": " Table 3: iSTS 2016 test results in Headlines, Images and", "labels": [], "entities": [{"text": "iSTS 2016 test", "start_pos": 10, "end_pos": 24, "type": "DATASET", "confidence": 0.8780513008435568}]}]}