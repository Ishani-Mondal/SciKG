{"title": [{"text": "UTHealth at SemEval-2016 Task 12: an End-to-End System for Temporal Information Extraction from Clinical Notes", "labels": [], "entities": [{"text": "UTHealth at SemEval-2016 Task 12", "start_pos": 0, "end_pos": 32, "type": "DATASET", "confidence": 0.7998592615127563}, {"text": "Temporal Information Extraction from Clinical", "start_pos": 59, "end_pos": 104, "type": "TASK", "confidence": 0.7953343510627746}]}], "abstractContent": [{"text": "The 2016 Clinical TempEval challenge addresses temporal information extraction from clinical notes.", "labels": [], "entities": [{"text": "Clinical TempEval challenge", "start_pos": 9, "end_pos": 36, "type": "TASK", "confidence": 0.6237934132417043}, {"text": "temporal information extraction from clinical notes", "start_pos": 47, "end_pos": 98, "type": "TASK", "confidence": 0.7972820202509562}]}, {"text": "The challenge is composed of six sub-tasks, each of which is to identify: (1) event mention spans, (2) time expression spans, (3) event attributes, (4) time attributes, (5) events' temporal relations to the document creation times (DocTimeRel), and (6) narrative container relations among events and times.", "labels": [], "entities": []}, {"text": "In this article, we present an end-to-end system that addresses all six sub-tasks.", "labels": [], "entities": []}, {"text": "Our system achieved the best performance for all six sub-tasks when plain texts were given as input.", "labels": [], "entities": []}, {"text": "It also performed best for narrative container relation identification when gold standard event/time annotations were given.", "labels": [], "entities": [{"text": "narrative container relation identification", "start_pos": 27, "end_pos": 70, "type": "TASK", "confidence": 0.8050007224082947}]}], "introductionContent": [{"text": "Temporality is crucial in understanding the course of clinical events from a patient's electronic health records.", "labels": [], "entities": [{"text": "understanding the course of clinical events", "start_pos": 26, "end_pos": 69, "type": "TASK", "confidence": 0.7471102078755697}]}, {"text": "Since a large part of the information on temporality resides in narrative clinical notes, automatic extraction of temporal information from clinical notes using natural language processing (NLP) techniques has received much attention.", "labels": [], "entities": [{"text": "automatic extraction of temporal information from clinical notes", "start_pos": 90, "end_pos": 154, "type": "TASK", "confidence": 0.8093495517969131}]}, {"text": "Over the years, research community challenges on clinical temporal information extraction have been organized; i.e., the 2012 Informatics for Integrating Biology and the Bedside (i2b2) challenge, the 2013/2014 CLEF/ShARe challenge (, and the 2015 Clinical TempEval challenge ( ).", "labels": [], "entities": [{"text": "clinical temporal information extraction", "start_pos": 49, "end_pos": 89, "type": "TASK", "confidence": 0.6611815169453621}, {"text": "CLEF/ShARe challenge", "start_pos": 210, "end_pos": 230, "type": "DATASET", "confidence": 0.7235613763332367}]}, {"text": "These challenges provide annotated corpora on temporal entities and relations, which facilitate comparisons of multiple systems and expediate the development of clinical temporal information extraction methodologies.", "labels": [], "entities": [{"text": "clinical temporal information extraction", "start_pos": 161, "end_pos": 201, "type": "TASK", "confidence": 0.6170794293284416}]}, {"text": "The 2016 Clinical TempEval challenge is the most recent community challenge that addresses temporal information extraction from clinical notes.", "labels": [], "entities": [{"text": "Clinical TempEval challenge", "start_pos": 9, "end_pos": 36, "type": "TASK", "confidence": 0.6030632555484772}, {"text": "temporal information extraction from clinical notes", "start_pos": 91, "end_pos": 142, "type": "TASK", "confidence": 0.7987468341986338}]}, {"text": "Following the 2015 Clinical TempEval challenge, the 2016 challenge consists of six sub-tasks, each of which is to identify: (1) spans of event mentions, (2) spans of time expressions, (3) attributes of events, (4) attribute of times, (5) events' temporal relations to the document creation times (DocTimeRel), and (6) narrative container relations among events and times (TLINK:Contains).", "labels": [], "entities": []}, {"text": "440 annotated clinical notes from Mayo Clinic, or the THYME corpus), were provided as the training data set, and 153 plain text clinical notes were provided as the test set.", "labels": [], "entities": [{"text": "THYME corpus", "start_pos": 54, "end_pos": 66, "type": "DATASET", "confidence": 0.9267414212226868}]}, {"text": "The participating systems were evaluated through two phases.", "labels": [], "entities": []}, {"text": "In phase 1, the systems were evaluated on their results for all six sub-tasks given plain texts as inputs.", "labels": [], "entities": []}, {"text": "In phase 2, system predictions on DocTimeRel and TLINK:Contains were evaluated given the gold-standard event annotations (EVENT) and time annotations (TIMEX3).", "labels": [], "entities": [{"text": "DocTimeRel", "start_pos": 34, "end_pos": 44, "type": "DATASET", "confidence": 0.9603597521781921}, {"text": "gold-standard event annotations (EVENT)", "start_pos": 89, "end_pos": 128, "type": "METRIC", "confidence": 0.7290665606657664}, {"text": "time annotations (TIMEX3)", "start_pos": 133, "end_pos": 158, "type": "METRIC", "confidence": 0.9005711317062378}]}, {"text": "In this article, we describe a comprehensive system that addresses all six sub-tasks.", "labels": [], "entities": []}, {"text": "We designed the system by adapting state-of-the-art techniques from previous work on named entity recognition () and temporal relation identification () in the medical domain.", "labels": [], "entities": [{"text": "named entity recognition", "start_pos": 85, "end_pos": 109, "type": "TASK", "confidence": 0.6145726044972738}, {"text": "temporal relation identification", "start_pos": 117, "end_pos": 149, "type": "TASK", "confidence": 0.6179406841595968}]}, {"text": "Our end-to-end system achieved top performance for all six sub-tasks in the phase 1 and the TLINK:Contains identification task in the phase 2 stages of the challenge.", "labels": [], "entities": [{"text": "TLINK", "start_pos": 92, "end_pos": 97, "type": "METRIC", "confidence": 0.9505232572555542}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Test set results on EVENT span (ES) and TIMEX3", "labels": [], "entities": [{"text": "EVENT span (ES)", "start_pos": 30, "end_pos": 45, "type": "METRIC", "confidence": 0.9203442454338073}, {"text": "TIMEX3", "start_pos": 50, "end_pos": 56, "type": "METRIC", "confidence": 0.8729713559150696}]}, {"text": " Table 2: Test set results on EVENT attribute (EA) and TIMEX3", "labels": [], "entities": [{"text": "EVENT attribute (EA)", "start_pos": 30, "end_pos": 50, "type": "METRIC", "confidence": 0.8973895072937011}, {"text": "TIMEX3", "start_pos": 55, "end_pos": 61, "type": "METRIC", "confidence": 0.8660318851470947}]}, {"text": " Table 3: Test set results on DocTimeRel (DR) and", "labels": [], "entities": [{"text": "DocTimeRel (DR)", "start_pos": 30, "end_pos": 45, "type": "DATASET", "confidence": 0.9302509874105453}]}]}