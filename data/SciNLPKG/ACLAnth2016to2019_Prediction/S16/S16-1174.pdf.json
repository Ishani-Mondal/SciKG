{"title": [{"text": "IIT-TUDA at SemEval-2016 Task 5: Beyond Sentiment Lexicon: Combining Domain Dependency and Distributional Semantics Features for Aspect Based Sentiment Analysis", "labels": [], "entities": [{"text": "IIT-TUDA", "start_pos": 0, "end_pos": 8, "type": "DATASET", "confidence": 0.7915691137313843}, {"text": "Aspect Based Sentiment Analysis", "start_pos": 129, "end_pos": 160, "type": "TASK", "confidence": 0.7043988108634949}]}], "abstractContent": [{"text": "This paper reports the IIT-TUDA participation in the SemEval 2016 shared Task 5 of Aspect Based Sentiment Analysis (ABSA) for sub-task 1.", "labels": [], "entities": [{"text": "SemEval 2016 shared Task 5 of Aspect Based Sentiment Analysis (ABSA)", "start_pos": 53, "end_pos": 121, "type": "TASK", "confidence": 0.75043729864634}]}, {"text": "We describe our system incorporating domain dependency graph features, dis-tributional thesaurus and unsupervised lexical induction using an unlabeled external corpus for aspect based sentiment analysis.", "labels": [], "entities": [{"text": "aspect based sentiment analysis", "start_pos": 171, "end_pos": 202, "type": "TASK", "confidence": 0.6711956113576889}]}, {"text": "Overall, we submitted 29 runs, covering 7 languages and 4 different domains.", "labels": [], "entities": []}, {"text": "Our system is placed first in sentiment polarity classification for the English laptop domain, Spanish and Turkish restaurant reviews, and opinion target expression for Dutch and French in restaurant domain , and scores in medium ranks for aspect category identification and opinion target extraction .", "labels": [], "entities": [{"text": "sentiment polarity classification", "start_pos": 30, "end_pos": 63, "type": "TASK", "confidence": 0.757932702700297}, {"text": "aspect category identification", "start_pos": 240, "end_pos": 270, "type": "TASK", "confidence": 0.6240935822327932}, {"text": "opinion target extraction", "start_pos": 275, "end_pos": 300, "type": "TASK", "confidence": 0.6988101800282797}]}], "introductionContent": [{"text": "The advent of web technologies has made an unprecedented opportunity for online users to share and explain their views and opinions.", "labels": [], "entities": []}, {"text": "The corelation between the views expressed by the users and the market strategies by the organizations strikes the importance of analyzing such reviews.", "labels": [], "entities": []}, {"text": "But, valuable as they are, user-generated review texts are unstructured and very noisy.", "labels": [], "entities": []}, {"text": "Major research studies adopted Natural Language Processing (NLP) and text mining techniques to better understand and process various types of information in user-generated reviews.", "labels": [], "entities": []}, {"text": "Such efforts have come to be known as opinion mining, sentiment analysis or review mining (.", "labels": [], "entities": [{"text": "opinion mining", "start_pos": 38, "end_pos": 52, "type": "TASK", "confidence": 0.854893296957016}, {"text": "sentiment analysis or review mining", "start_pos": 54, "end_pos": 89, "type": "TASK", "confidence": 0.742045545578003}]}, {"text": "Aspect level analysis performs a finer-grained sentiment analysis by addressing three subproblems: extracting aspects from the review text, identifying the entity that is referred to by the aspect, and finally classifying the opinion polarity towards the aspect (.", "labels": [], "entities": [{"text": "Aspect level analysis", "start_pos": 0, "end_pos": 21, "type": "TASK", "confidence": 0.8923144936561584}]}, {"text": "For example, a review of the \"entity\" laptop is likely to discuss distinct \"aspects\" like size, processing unit, and memory, and a single product can trigger a positive \"opinion\" about one feature, and a negative \"opinion\" about another.", "labels": [], "entities": []}, {"text": "In an attempt to support the efforts on Aspect Based Sentiment Analysis (ABSA), the SemEval 2016 shared Task 5 ABSA ( offers the opportunity to experiment and evaluate on benchmark datasets (reviews) across various domains and languages through three subtasks.", "labels": [], "entities": [{"text": "Aspect Based Sentiment Analysis (ABSA)", "start_pos": 40, "end_pos": 78, "type": "TASK", "confidence": 0.7596868276596069}, {"text": "SemEval 2016 shared Task 5 ABSA", "start_pos": 84, "end_pos": 115, "type": "TASK", "confidence": 0.649681160847346}]}, {"text": "Subtask 1 covers the three sub-problems mentioned above, namely: aspect category identification (Slot 1), opinion target expression (OTE) (Slot 2) and sentiment polarity classification (Slot 3).", "labels": [], "entities": [{"text": "aspect category identification", "start_pos": 65, "end_pos": 95, "type": "TASK", "confidence": 0.6510703365008036}, {"text": "sentiment polarity classification", "start_pos": 151, "end_pos": 184, "type": "TASK", "confidence": 0.8629276355107626}]}, {"text": "We participated in Slot 1 and Slot 3 for English, Spanish, Dutch, French, Turkish, Russian and Arabic language for all available domains except telecoms.", "labels": [], "entities": []}, {"text": "We also conducted experiments for Slot 2 for English, Spanish, Dutch and French.", "labels": [], "entities": [{"text": "Slot 2", "start_pos": 34, "end_pos": 40, "type": "TASK", "confidence": 0.5704866647720337}]}, {"text": "Overall, we submitted 29 runs, covering 7 languages and 4 different domains.", "labels": [], "entities": []}], "datasetContent": [{"text": "For feature selection and hyperparameter tuning, we perform five-fold cross-validation on the training set.", "labels": [], "entities": [{"text": "feature selection", "start_pos": 4, "end_pos": 21, "type": "TASK", "confidence": 0.7584878504276276}, {"text": "hyperparameter tuning", "start_pos": 26, "end_pos": 47, "type": "TASK", "confidence": 0.7070907056331635}]}, {"text": "For Slot 1 and Slot 3, we use supervised classification using Support Vector Machine (SVM) . Based on cross-validation results, we set the probability threshold of 0.185, 0.13 and 0.145 for restaurants, laptops and phones, respectively, for predicting aspect categories in the review.", "labels": [], "entities": []}, {"text": "All E#A pairs having predicted probability greater than the threshold are enlisted as aspect categories.", "labels": [], "entities": []}, {"text": "For Slot 2, we use CRFSuite 15 with default parameters.", "labels": [], "entities": []}, {"text": "CRF-   Suite is a fast implementation of Conditional Random Field (CRFs) for segmenting and labelling sequential data.", "labels": [], "entities": [{"text": "CRF-   Suite", "start_pos": 0, "end_pos": 12, "type": "DATASET", "confidence": 0.8701293269793192}, {"text": "segmenting and labelling sequential data", "start_pos": 77, "end_pos": 117, "type": "TASK", "confidence": 0.6966561138629913}]}, {"text": "Teams were allowed to submit their systems in two modes: constrained and unconstrained modes.", "labels": [], "entities": []}, {"text": "In constrained mode, the participants are allowed to use only the resources and dataset provided by the organizers whereas in unconstrained submission, participants can use any external resource.", "labels": [], "entities": []}, {"text": "For Slot 2 and Slot 3, we only sent unconstrained submission, while for Slot 1 we sent constrained as well as unconstrained submissions except for Russian restaurants.", "labels": [], "entities": []}, {"text": "Our system achieves the best results in sentiment polarity classification for reviews about English laptops, Spanish restaurants and Turkish restaurants.", "labels": [], "entities": [{"text": "sentiment polarity classification", "start_pos": 40, "end_pos": 73, "type": "TASK", "confidence": 0.8189042607943217}]}, {"text": "We score second for English restaurants.", "labels": [], "entities": []}, {"text": "We also produce the maximum F1-score value for opinion target expression for French and Dutch restaurants.", "labels": [], "entities": [{"text": "F1-score", "start_pos": 28, "end_pos": 36, "type": "METRIC", "confidence": 0.99932861328125}]}, {"text": "Our evaluation results across all domains and languages are given in.", "labels": [], "entities": []}, {"text": "The results show that our system performs comparably well for sentiment polarity classification and opinion target expression.", "labels": [], "entities": [{"text": "sentiment polarity classification", "start_pos": 62, "end_pos": 95, "type": "TASK", "confidence": 0.900477925936381}, {"text": "opinion target expression", "start_pos": 100, "end_pos": 125, "type": "TASK", "confidence": 0.6333765983581543}]}, {"text": "A feature ablation experiment given in shows the effectiveness of induced lexicon for Slot 3 task.", "labels": [], "entities": [{"text": "Slot 3 task", "start_pos": 86, "end_pos": 97, "type": "TASK", "confidence": 0.6749527454376221}]}, {"text": "We get a significant improvement on adding information from the induced lexicons in each language.", "labels": [], "entities": []}, {"text": "This holds especially for languages other than English, where existing sentiment lexicons are less comprehensive.", "labels": [], "entities": []}, {"text": "We also note that entity-attribute pairs also help in resolving conflicting sentiments (for example: cheap food (positive) to cheap service (negative)).", "labels": [], "entities": []}, {"text": "We score in medium ranks for Slot 1 task.", "labels": [], "entities": [{"text": "Slot 1 task", "start_pos": 29, "end_pos": 40, "type": "TASK", "confidence": 0.7951594591140747}]}, {"text": "which may not have been captured explicitly by the external features.", "labels": [], "entities": []}, {"text": "For the Slot 2 task, we have found some inconsistencies in our extraction pipeline, unfortunately were notable to correct them in time for the submission.", "labels": [], "entities": [{"text": "Slot 2 task", "start_pos": 8, "end_pos": 19, "type": "TASK", "confidence": 0.8633478879928589}]}, {"text": "After the evaluation period, we revised our feature representation to ensure that it matches the correct input format for CRF.", "labels": [], "entities": []}, {"text": "We also added two new features including unsupervised PoS tags as the feature for all the languages and SentiWordNet score for English language.", "labels": [], "entities": []}, {"text": "For the current token, we use PoS tag, distributional thesaurus, lexical expansion score, unsupervised PoS tag, SentiWordNet score of context tokens [-2, -1, 0, 1, 2], prefix (upto 3-character), suffix (upto 3-character) and chunk information of context tokens.", "labels": [], "entities": []}, {"text": "The updated results of after modification are shown in.", "labels": [], "entities": []}, {"text": "If we had incorporated these changes earlier, we would have scored third for English and first for the other three languages.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Expansion statistics for induced lexicons. Common entries denote the number of words which are present both in the seed", "labels": [], "entities": []}, {"text": " Table 3: Evaluation result for Subtask 1. Mode of submission (C-constrained, U-unconstrained) and rank is given in the parenthesis.", "labels": [], "entities": [{"text": "Mode", "start_pos": 43, "end_pos": 47, "type": "METRIC", "confidence": 0.9868655800819397}]}, {"text": " Table 4: Feature Ablation Experiment for Sentiment Polarity Classification", "labels": [], "entities": [{"text": "Ablation", "start_pos": 18, "end_pos": 26, "type": "METRIC", "confidence": 0.8230104446411133}, {"text": "Sentiment Polarity Classification", "start_pos": 42, "end_pos": 75, "type": "TASK", "confidence": 0.9565237760543823}]}, {"text": " Table 5: Result on Slot 2 task after modification", "labels": [], "entities": [{"text": "Slot 2 task", "start_pos": 20, "end_pos": 31, "type": "TASK", "confidence": 0.7214647531509399}]}]}