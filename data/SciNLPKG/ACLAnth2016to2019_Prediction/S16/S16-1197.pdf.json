{"title": [{"text": "UTA DLNLP at SemEval-2016 Task 12: Deep Learning Based Natural Language Processing System for Clinical Information Identification from Clinical Notes and Pathology Reports", "labels": [], "entities": [{"text": "UTA DLNLP", "start_pos": 0, "end_pos": 9, "type": "DATASET", "confidence": 0.8108907341957092}, {"text": "SemEval-2016 Task 12", "start_pos": 13, "end_pos": 33, "type": "TASK", "confidence": 0.5505107839902242}, {"text": "Clinical Information Identification from Clinical Notes and Pathology", "start_pos": 94, "end_pos": 163, "type": "TASK", "confidence": 0.7549040019512177}]}], "abstractContent": [{"text": "We propose a deep neural network based natural language processing system for clinical information (such as time information, event spans, and their attributes) extraction from raw clinical notes and pathology reports.", "labels": [], "entities": [{"text": "time information, event spans, and their attributes) extraction from raw clinical notes and pathology reports", "start_pos": 108, "end_pos": 217, "type": "TASK", "confidence": 0.5936479883061515}]}, {"text": "Our approach uses the context words and their part-of-speech tags and shape information as features.", "labels": [], "entities": []}, {"text": "We utilize the temporal (1D) convolu-tion neural network to learn the hidden feature representations.", "labels": [], "entities": []}, {"text": "In prediction step, we use the Multilayer Perceptron (MLP) to predict event spans.", "labels": [], "entities": [{"text": "prediction", "start_pos": 3, "end_pos": 13, "type": "TASK", "confidence": 0.9680258631706238}]}, {"text": "The empirical evaluation demonstrates that our approach significantly outper-forms baseline methods.", "labels": [], "entities": []}], "introductionContent": [{"text": "In past several years, there has been much interest in applying neural network based deep learning techniques to solve many natural language processing (NLP) tasks.", "labels": [], "entities": []}, {"text": "From low-level tasks such as language modeling, POS tagging, named entity recognition, and semantic role labeling, to high-level tasks such as machine translation, information retrieval, semantic analysis () and sentence relation modeling tasks such as paraphrase identification and question answering.", "labels": [], "entities": [{"text": "language modeling", "start_pos": 29, "end_pos": 46, "type": "TASK", "confidence": 0.7266811579465866}, {"text": "POS tagging", "start_pos": 48, "end_pos": 59, "type": "TASK", "confidence": 0.8365879952907562}, {"text": "named entity recognition", "start_pos": 61, "end_pos": 85, "type": "TASK", "confidence": 0.6364656786123911}, {"text": "semantic role labeling", "start_pos": 91, "end_pos": 113, "type": "TASK", "confidence": 0.6658994654814402}, {"text": "machine translation", "start_pos": 143, "end_pos": 162, "type": "TASK", "confidence": 0.774766743183136}, {"text": "information retrieval", "start_pos": 164, "end_pos": 185, "type": "TASK", "confidence": 0.7627077400684357}, {"text": "semantic analysis", "start_pos": 187, "end_pos": 204, "type": "TASK", "confidence": 0.7145625352859497}, {"text": "sentence relation modeling", "start_pos": 212, "end_pos": 238, "type": "TASK", "confidence": 0.7261232733726501}, {"text": "paraphrase identification", "start_pos": 253, "end_pos": 278, "type": "TASK", "confidence": 0.8845482766628265}, {"text": "question answering", "start_pos": 283, "end_pos": 301, "type": "TASK", "confidence": 0.8336833715438843}]}, {"text": "Deep representation learning has demonstrated its importance for * To whom all correspondence should be addressed.", "labels": [], "entities": [{"text": "Deep representation learning", "start_pos": 0, "end_pos": 28, "type": "TASK", "confidence": 0.6796395480632782}]}, {"text": "This work was partially supported by NSF-IIS 1117965, NSF-IIS 1302675, NSF-IIS 1344152, NSF-DBI 1356628, NIH R01 AG049371.", "labels": [], "entities": [{"text": "NSF-IIS 1117965", "start_pos": 37, "end_pos": 52, "type": "DATASET", "confidence": 0.9299643635749817}, {"text": "NSF-IIS 1302675", "start_pos": 54, "end_pos": 69, "type": "DATASET", "confidence": 0.941389799118042}, {"text": "NSF-IIS 1344152", "start_pos": 71, "end_pos": 86, "type": "DATASET", "confidence": 0.9204720854759216}, {"text": "NSF-DBI 1356628", "start_pos": 88, "end_pos": 103, "type": "DATASET", "confidence": 0.9283453226089478}, {"text": "NIH R01 AG049371", "start_pos": 105, "end_pos": 121, "type": "METRIC", "confidence": 0.5961824158827463}]}, {"text": "All the tasks get performance improvement via learning either word level representations or sentence level representations.", "labels": [], "entities": []}, {"text": "In this work, we introduce the deep representation learning technologies to the electronic medical record research.", "labels": [], "entities": []}, {"text": "Specifically, we focus on clinical information extraction, using clinical notes and pathology reports from the Mayo Clinic.", "labels": [], "entities": [{"text": "clinical information extraction", "start_pos": 26, "end_pos": 57, "type": "TASK", "confidence": 0.6833759148915609}]}, {"text": "Our system is designed to identify event expressions consisting of the following components: \u2022 The spans (character offsets) of the expression in the raw text \u2022 Contextual Modality: ACTUAL, HYPOTHET-ICAL, HEDGED or GENERIC \u2022 Degree: MOST, LITTLE or N/A \u2022 Polarity: POS or NEG \u2022 Type: ASPECTUAL, EVIDENTIAL or N/A The input of our system consists of raw clinical notes or pathology reports.", "labels": [], "entities": [{"text": "ACTUAL", "start_pos": 182, "end_pos": 188, "type": "METRIC", "confidence": 0.6794546246528625}, {"text": "HYPOTHET-ICAL", "start_pos": 190, "end_pos": 203, "type": "METRIC", "confidence": 0.8720362186431885}]}, {"text": "The following is an example: April 23, 2014: The patient did not have any postoperative bleeding so we will resume chemotherapy with a larger bolus on Friday even if there is slight nausea.", "labels": [], "entities": []}, {"text": "The output annotations over the text capture the key information such as event mentions and attributes.", "labels": [], "entities": []}, {"text": "illustrates the output of clinical information extraction in details.", "labels": [], "entities": [{"text": "clinical information extraction", "start_pos": 26, "end_pos": 57, "type": "TASK", "confidence": 0.660893589258194}]}, {"text": "To solve this task, the major challenge is how to precisely identify the spans (character offsets) of To address this challenge, we propose a deep neural networks based method, especially convolution neural network), to learn hidden feature representations directly from raw clinical notes.", "labels": [], "entities": []}, {"text": "More specifically, one method first extracts a window of surrounding words for the candidate word.", "labels": [], "entities": []}, {"text": "Then, we attach each word with their part-of-speech tag and shape information as extra features.", "labels": [], "entities": []}, {"text": "After that, our system deploys a temporal convolution neural network to learn hidden feature representations.", "labels": [], "entities": []}, {"text": "Finally, our system uses Multilayer Perceptron (MLP) to predict event spans.", "labels": [], "entities": []}, {"text": "Note that we use the same model to predict event attributes.", "labels": [], "entities": []}, {"text": "1 Apache cTAKES is a natural language processing system for extraction of information from electronic medical record clinical free-text", "labels": [], "entities": []}], "datasetContent": [{"text": "The major advantage of our system is that we only leverage NLTK 2 tokenization and a POS tagger to preprocess our training dataset.", "labels": [], "entities": []}, {"text": "When implementing our neural network based clinical information extraction system, we found it is not easy to construct high quality training data due to the noisy format of clinical notes.", "labels": [], "entities": [{"text": "clinical information extraction", "start_pos": 43, "end_pos": 74, "type": "TASK", "confidence": 0.6501418948173523}]}, {"text": "Choosing the proper tokenizer is quite important for span identification.", "labels": [], "entities": [{"text": "span identification", "start_pos": 53, "end_pos": 72, "type": "TASK", "confidence": 0.9654927253723145}]}, {"text": "After conducting experiments, we found that \"RegexpTokenizer\" can match our needs.", "labels": [], "entities": []}, {"text": "This tokenizer can generate spans for each token via sophisticated regular expression such as: We then use \"PerceptronTagger\" as our part-ofspeech tagger due to its fast tagging speed.", "labels": [], "entities": []}, {"text": "Note that when extracting context words, please make sure you deploy the same tokenization module instead of just splitting strings by space.", "labels": [], "entities": []}, {"text": "We use the Clinical TempEval corpus 3 as the evaluation dataset.", "labels": [], "entities": [{"text": "Clinical TempEval corpus 3", "start_pos": 11, "end_pos": 37, "type": "DATASET", "confidence": 0.8356143981218338}]}, {"text": "This corpus was based on a set of  600 clinical notes and pathology reports from cancer patients at the Mayo Clinic.", "labels": [], "entities": []}, {"text": "These notes were manually de-identified by the Mayo Clinic to replace names, locations, etc. with generic placeholders, but time expression were not altered.", "labels": [], "entities": []}, {"text": "The notes were then manually annotated with times, events, and temporal relations in clinical notes.", "labels": [], "entities": []}, {"text": "These annotations include time expression types, event attributes, and an increased focus on temporal relations.", "labels": [], "entities": []}, {"text": "The event, time, and temporal relation annotations were distributed separately from the text using the Anafora standoff format.", "labels": [], "entities": [{"text": "Anafora standoff format", "start_pos": 103, "end_pos": 126, "type": "DATASET", "confidence": 0.896993080774943}]}, {"text": "shows the number of documents, event expressions in the training, development and testing portions of the 2016 THYME data.", "labels": [], "entities": [{"text": "THYME data", "start_pos": 111, "end_pos": 121, "type": "DATASET", "confidence": 0.8436791896820068}]}, {"text": "All of the tasks were evaluated using the standard metrics of precision (P), recall (R), and F 1 : where S is the set of items predicted by the system and H is the set of items manually annotated by the humans.", "labels": [], "entities": [{"text": "precision (P)", "start_pos": 62, "end_pos": 75, "type": "METRIC", "confidence": 0.9368533343076706}, {"text": "recall (R)", "start_pos": 77, "end_pos": 87, "type": "METRIC", "confidence": 0.9629389047622681}, {"text": "F 1", "start_pos": 93, "end_pos": 96, "type": "METRIC", "confidence": 0.9942699670791626}]}, {"text": "Applying these metrics of the tasks only requires a definition of what is considered an \"item\" for each task.", "labels": [], "entities": []}, {"text": "For evaluating the spans of event expressions, items were tuples of character offsets.", "labels": [], "entities": []}, {"text": "Thus, system only received credit for identifying events with exactly the same character offsets as the manually annotated ones.", "labels": [], "entities": []}, {"text": "For evaluating the attributes of event expression types, items were tuples of (begin, end, value) where begin and end are character offsets and value is the value that was given to the relevant attribute.", "labels": [], "entities": []}, {"text": "Thus, systems only received credit for an event attribute if they both found an event with correct character offsets and then assigned the correct value for that attribute (Bethard et al., 2015).", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Number of documents, event expressions in the train-", "labels": [], "entities": []}, {"text": " Table 4: Phase 2: DocTimeRel", "labels": [], "entities": [{"text": "DocTimeRel", "start_pos": 19, "end_pos": 29, "type": "DATASET", "confidence": 0.7989693880081177}]}]}