{"title": [{"text": "CAMR at SemEval-2016 Task 8: An Extended Transition-based AMR Parser", "labels": [], "entities": [{"text": "SemEval-2016 Task 8", "start_pos": 8, "end_pos": 27, "type": "TASK", "confidence": 0.7217081189155579}]}], "abstractContent": [{"text": "This paper describes CAMR, the transition-based parser that we use in the SemEval-2016 Meaning Representation Parsing task.", "labels": [], "entities": [{"text": "SemEval-2016 Meaning Representation Parsing task", "start_pos": 74, "end_pos": 122, "type": "TASK", "confidence": 0.8754788398742676}]}, {"text": "The main contribution of this paper is a description of the additional sources of information that we use as features in the parsing model to further boost its performance.", "labels": [], "entities": [{"text": "parsing", "start_pos": 125, "end_pos": 132, "type": "TASK", "confidence": 0.9655529260635376}]}, {"text": "We start with our existing AMR parser and experiment with three sets of new features: 1) rich named entities , 2) a verbalization list, 3) semantic role labels.", "labels": [], "entities": [{"text": "AMR parser", "start_pos": 27, "end_pos": 37, "type": "TASK", "confidence": 0.6258628666400909}]}, {"text": "We also use the RPI Wikifier to wikify the concepts in the AMR graph.", "labels": [], "entities": [{"text": "RPI Wikifier", "start_pos": 16, "end_pos": 28, "type": "DATASET", "confidence": 0.8148430287837982}, {"text": "AMR graph", "start_pos": 59, "end_pos": 68, "type": "DATASET", "confidence": 0.8039169609546661}]}, {"text": "Our parser achieves a Smatch F-score of 62% on the official blind test set.", "labels": [], "entities": [{"text": "Smatch", "start_pos": 22, "end_pos": 28, "type": "METRIC", "confidence": 0.9355059266090393}, {"text": "F-score", "start_pos": 29, "end_pos": 36, "type": "METRIC", "confidence": 0.7604084014892578}, {"text": "official blind test set", "start_pos": 51, "end_pos": 74, "type": "DATASET", "confidence": 0.736703097820282}]}], "introductionContent": [{"text": "AMR parsing is the task of taking a sentence as input and producing as output an Abstract Meaning Representation (AMR) that is a rooted, directed, edge-labeled and leaf-labeled graph that is used to represent the meaning of a sentence.", "labels": [], "entities": [{"text": "AMR parsing", "start_pos": 0, "end_pos": 11, "type": "TASK", "confidence": 0.8512890636920929}, {"text": "Abstract Meaning Representation (AMR)", "start_pos": 81, "end_pos": 118, "type": "TASK", "confidence": 0.6627016216516495}]}, {"text": "AMR parsing has drawn an increasing amount of attention recently.", "labels": [], "entities": [{"text": "AMR parsing", "start_pos": 0, "end_pos": 11, "type": "TASK", "confidence": 0.9060219824314117}]}, {"text": "The first published AMR parser, JAMR), performs AMR parsing in two stages: concept identification and relation identification.", "labels": [], "entities": [{"text": "AMR parser", "start_pos": 20, "end_pos": 30, "type": "TASK", "confidence": 0.8623749613761902}, {"text": "JAMR", "start_pos": 32, "end_pos": 36, "type": "DATASET", "confidence": 0.8880825042724609}, {"text": "AMR parsing", "start_pos": 48, "end_pos": 59, "type": "TASK", "confidence": 0.9339590072631836}, {"text": "concept identification", "start_pos": 75, "end_pos": 97, "type": "TASK", "confidence": 0.7282349169254303}, {"text": "relation identification", "start_pos": 102, "end_pos": 125, "type": "TASK", "confidence": 0.8214824795722961}]}, {"text": "treat concept identification as a sequence labeling task and utilize a semi-Markov model to map spans of words in a sentence to concept graph fragments.", "labels": [], "entities": [{"text": "concept identification", "start_pos": 6, "end_pos": 28, "type": "TASK", "confidence": 0.797607034444809}]}, {"text": "For relation identification, they adopt graph-based techniques similar to those used in dependency parsing).", "labels": [], "entities": [{"text": "relation identification", "start_pos": 4, "end_pos": 27, "type": "TASK", "confidence": 0.973732978105545}, {"text": "dependency parsing", "start_pos": 88, "end_pos": 106, "type": "TASK", "confidence": 0.7832279205322266}]}, {"text": "Instead of finding maximum spanning trees (MST) over words, they propose an algorithm that finds the maximum spanning connected subgraph (MSCG) over concept fragments identified in the first stage.", "labels": [], "entities": []}, {"text": "describes a transition-based parser that also involves two stages.", "labels": [], "entities": []}, {"text": "In the first step, an input sentence is parsed into a dependency tree with a dependency parser.", "labels": [], "entities": []}, {"text": "In the second step, it transforms the dependency tree into an AMR graph by performing a series of actions.", "labels": [], "entities": []}, {"text": "Note that the dependency parser used in the first step can be any off-the-shelf dependency parser and does not have to trained on the same data set as used in the second step.", "labels": [], "entities": []}, {"text": "There are also approaches which utilize grammar induction to parse the AMR.", "labels": [], "entities": [{"text": "parse the AMR", "start_pos": 61, "end_pos": 74, "type": "TASK", "confidence": 0.6114001274108887}]}, {"text": "presents a model that first use Combinatory Categorial Grammar (CCG) to construct the lambdacalculus representations of the sentence, then further resolve non-compositional dependencies using a factor graph. and formalize parsing AMR as a machine translation problem by learning string-graph/string-tree rules from the annotated data.", "labels": [], "entities": [{"text": "parsing AMR", "start_pos": 222, "end_pos": 233, "type": "TASK", "confidence": 0.891730934381485}, {"text": "machine translation", "start_pos": 239, "end_pos": 258, "type": "TASK", "confidence": 0.7001127302646637}]}, {"text": "Although the field of AMR parsing is growing and several systems () have substantially advanced the state of the art, the overall performance of existing AMR parsers is far less accurate than syntactic parsers.", "labels": [], "entities": [{"text": "AMR parsing", "start_pos": 22, "end_pos": 33, "type": "TASK", "confidence": 0.9560982584953308}, {"text": "AMR parsers", "start_pos": 154, "end_pos": 165, "type": "TASK", "confidence": 0.7663584351539612}]}, {"text": "This makes it difficult to use in downstream NLP tasks.", "labels": [], "entities": []}, {"text": "In this paper, we aim to boost the AMR parsing performance by introducing additional features.", "labels": [], "entities": [{"text": "AMR parsing", "start_pos": 35, "end_pos": 46, "type": "TASK", "confidence": 0.8916724622249603}]}, {"text": "We mainly experiment with three sets of features derived from: 1) rich named entities, 2) a verbalization list provided by ISI, and 3) semantic role labels produced by an automatic SRL system.", "labels": [], "entities": [{"text": "SRL", "start_pos": 181, "end_pos": 184, "type": "TASK", "confidence": 0.9552591443061829}]}, {"text": "The rest of the paper is organized as follows.", "labels": [], "entities": []}, {"text": "In Section 2 we briefly describe CAMR, and in Section 3 we describe our extensions for the SemEval shared task.", "labels": [], "entities": [{"text": "SemEval shared task", "start_pos": 91, "end_pos": 110, "type": "TASK", "confidence": 0.7825241684913635}]}, {"text": "In Section 4 we describe the different AMR releases available with some salient characteristics.", "labels": [], "entities": []}, {"text": "We report experimental results in Section 5 and conclude the paper in Section 6.", "labels": [], "entities": []}], "datasetContent": [{"text": "We use the official release dataset and standard train/dev/test split of SemEval Task 8 for experiments.", "labels": [], "entities": [{"text": "SemEval Task 8", "start_pos": 73, "end_pos": 87, "type": "TASK", "confidence": 0.6256268421808878}]}, {"text": "All the sentences are preprocessed using Stanford CoreNLP () to get tokenization, lemma, named entity tag, POS tag.", "labels": [], "entities": [{"text": "Stanford CoreNLP", "start_pos": 41, "end_pos": 57, "type": "DATASET", "confidence": 0.9371743202209473}]}, {"text": "And we use the aligner that comes with JAMR) to align the sentence with its AMR graph.", "labels": [], "entities": [{"text": "JAMR", "start_pos": 39, "end_pos": 43, "type": "DATASET", "confidence": 0.6213839650154114}]}, {"text": "We then parse the tokenized sentences using Charniak parser)(Its phrase structure output is converted to dependency structure using a slightly modified version of the Stanford CoreNLP converter).", "labels": [], "entities": []}, {"text": "Rich named entity tags are generated using Stanford named entity tagger.", "labels": [], "entities": [{"text": "Stanford named entity tagger", "start_pos": 43, "end_pos": 71, "type": "TASK", "confidence": 0.6214193254709244}]}, {"text": "The semantic role labels are generated using ASSERT-a semantic role labeler (), including a frameset disambiguator trained using a word sense disambiguation system-IMS (.", "labels": [], "entities": [{"text": "ASSERT-a semantic role labeler", "start_pos": 45, "end_pos": 75, "type": "TASK", "confidence": 0.60378847271204}]}, {"text": "All these components viz., the Charniak parser, Stanford named entity tagger, ASSERT, and IMS word sense disambiguator were retrained on the OntoNotes v5.0 training data 2 . We use the version of CAMR described in () (without the feature extensions) as the baseline.", "labels": [], "entities": [{"text": "Stanford named entity tagger", "start_pos": 48, "end_pos": 76, "type": "TASK", "confidence": 0.4743696004152298}, {"text": "ASSERT", "start_pos": 78, "end_pos": 84, "type": "METRIC", "confidence": 0.7914360761642456}, {"text": "IMS word sense disambiguator", "start_pos": 90, "end_pos": 118, "type": "TASK", "confidence": 0.5142903849482536}, {"text": "OntoNotes v5.0 training data 2", "start_pos": 141, "end_pos": 171, "type": "DATASET", "confidence": 0.8782651424407959}]}, {"text": "We evaluate our parser with Smatch v2.0.) on all the experiments.", "labels": [], "entities": []}, {"text": "It should be noted that all the rows in except for the last one get implicitly penalized by the scorer for lack of wikification information.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: AMR parsing performance on the official SemEval development set (LDC2015E86).VERB: ISI  verbalization list. BROWN: Brown cluster features.RNE: Rich (OntoNotes) named entities.SRL: semantic  role labeling features. WIKI: Addition of wikification of named entities in AMR.", "labels": [], "entities": [{"text": "AMR parsing", "start_pos": 10, "end_pos": 21, "type": "TASK", "confidence": 0.8941367566585541}, {"text": "SemEval development set (LDC2015E86).", "start_pos": 50, "end_pos": 87, "type": "DATASET", "confidence": 0.8324895103772482}, {"text": "VERB", "start_pos": 87, "end_pos": 91, "type": "METRIC", "confidence": 0.6688955426216125}, {"text": "BROWN", "start_pos": 118, "end_pos": 123, "type": "METRIC", "confidence": 0.9952514171600342}, {"text": "semantic  role labeling", "start_pos": 190, "end_pos": 213, "type": "TASK", "confidence": 0.6297351320584615}]}, {"text": " Table 3: AMR parsing performance on full SemEval  Test Set and the Blind Test Set", "labels": [], "entities": [{"text": "AMR parsing", "start_pos": 10, "end_pos": 21, "type": "TASK", "confidence": 0.8171540796756744}, {"text": "SemEval  Test Set", "start_pos": 42, "end_pos": 59, "type": "DATASET", "confidence": 0.8202494382858276}, {"text": "Blind Test Set", "start_pos": 68, "end_pos": 82, "type": "DATASET", "confidence": 0.8329137166341146}]}]}