{"title": [{"text": "SemanticZ at SemEval-2016 Task 3: Ranking Relevant Answers in Community Question Answering Using Semantic Similarity Based on Fine-tuned Word Embeddings", "labels": [], "entities": [{"text": "Ranking Relevant Answers in Community Question Answering", "start_pos": 34, "end_pos": 90, "type": "TASK", "confidence": 0.5998132015977587}]}], "abstractContent": [{"text": "We describe our system for finding good answers in a community forum, as defined in SemEval-2016, Task 3 on Community Question Answering.", "labels": [], "entities": [{"text": "Community Question Answering", "start_pos": 108, "end_pos": 136, "type": "TASK", "confidence": 0.5662149687608083}]}, {"text": "Our approach relies on several semantic similarity features based on fine-tuned word embeddings and topics similarities.", "labels": [], "entities": []}, {"text": "In the main Subtask C, our primary submission was ranked third, with a MAP of 51.68 and accuracy of 69.94.", "labels": [], "entities": [{"text": "MAP", "start_pos": 71, "end_pos": 74, "type": "METRIC", "confidence": 0.9996354579925537}, {"text": "accuracy", "start_pos": 88, "end_pos": 96, "type": "METRIC", "confidence": 0.9998040795326233}]}, {"text": "In Subtask A, our primary submission was also third, with MAP of 77.58 and accuracy of 73.39.", "labels": [], "entities": [{"text": "MAP", "start_pos": 58, "end_pos": 61, "type": "METRIC", "confidence": 0.9997455477714539}, {"text": "accuracy", "start_pos": 75, "end_pos": 83, "type": "METRIC", "confidence": 0.9997920393943787}]}], "introductionContent": [{"text": "Posting questions that have already been asked and answered in a community forum is annoying to users as it usually ends up with them being referred to a previously asked question.", "labels": [], "entities": [{"text": "Posting questions that have already been asked and answered in a community forum", "start_pos": 0, "end_pos": 80, "type": "TASK", "confidence": 0.7213349525745099}]}, {"text": "The SemEval-2016 Task 3 on Community Question Answering 1 ( ) aims to solve this real-life problem.", "labels": [], "entities": [{"text": "SemEval-2016 Task 3 on Community Question Answering 1", "start_pos": 4, "end_pos": 57, "type": "TASK", "confidence": 0.6900182105600834}]}, {"text": "The main subtask (Subtask C) asks to find an answer that already exists in the forum and will be appropriate as a response to a newly-posted question.", "labels": [], "entities": []}, {"text": "There is also a secondary, Subtask A, which focuses on QuestionComment Similarity and asks to rank the comments within a question-comment thread based on their relevance with respect to the thread's question.", "labels": [], "entities": [{"text": "QuestionComment Similarity", "start_pos": 55, "end_pos": 81, "type": "TASK", "confidence": 0.722247987985611}]}, {"text": "Here, we examine the performance of using different word embeddings obtained with the Word2Vec tool (), which we use to build vectors for the questions and the answers.", "labels": [], "entities": [{"text": "Word2Vec", "start_pos": 86, "end_pos": 94, "type": "DATASET", "confidence": 0.9304502010345459}]}, {"text": "We train classifiers using features derived from these embeddings to solve subtasks A and C.", "labels": [], "entities": []}, {"text": "1 http://alt.qcri.org/semeval2016/task3/ Our contribution is in producing good word embeddings based on empirical evaluation of different configurations working in the Community Question Answering domain; as they perform well, we make them freely available to the research community.", "labels": [], "entities": [{"text": "Community Question Answering domain", "start_pos": 168, "end_pos": 203, "type": "TASK", "confidence": 0.6691267415881157}]}], "datasetContent": [{"text": "As explained above, we rely mainly on semantic features extracted from Word2Vec word embeddings.", "labels": [], "entities": []}, {"text": "Thus, we ran several experiments looking for the best embeddings for the task.", "labels": [], "entities": []}, {"text": "shows experiments with Word2Vec models trained on the unannotated datasets described above.", "labels": [], "entities": [{"text": "Word2Vec", "start_pos": 23, "end_pos": 31, "type": "DATASET", "confidence": 0.9359601140022278}]}, {"text": "The Google News Word2Vec model comes pretrained with vector size of 300, window 10, minimum word frequency of 10 and skip-gram 1.", "labels": [], "entities": [{"text": "Google News Word2Vec model", "start_pos": 4, "end_pos": 30, "type": "DATASET", "confidence": 0.8793591409921646}, {"text": "minimum word frequency", "start_pos": 84, "end_pos": 106, "type": "METRIC", "confidence": 0.741737554470698}]}, {"text": "We started with training our three Word2Vec models using the same parameters.", "labels": [], "entities": [{"text": "Word2Vec", "start_pos": 35, "end_pos": 43, "type": "DATASET", "confidence": 0.9299123287200928}]}, {"text": "shows results using raw word vectors as features, together with an extra feature for question body to comment cosine similarity.", "labels": [], "entities": []}, {"text": "We can see that training on Qatar Living Forum data performs best followed by using Qatar Living Forum+Ext, Google News, and Doha News.", "labels": [], "entities": [{"text": "Qatar Living Forum data", "start_pos": 28, "end_pos": 51, "type": "DATASET", "confidence": 0.9610563367605209}, {"text": "Qatar Living Forum+Ext", "start_pos": 84, "end_pos": 106, "type": "DATASET", "confidence": 0.9686848163604737}, {"text": "Google News", "start_pos": 108, "end_pos": 119, "type": "DATASET", "confidence": 0.9079954028129578}, {"text": "Doha News", "start_pos": 125, "end_pos": 134, "type": "DATASET", "confidence": 0.979478269815445}]}, {"text": "This is not surprising as the first two datasets are in-domain, while the latter two cover more topics (as they are news) and more formal language.", "labels": [], "entities": []}, {"text": "Overall, Doha News contains topics that largely overlap with the topics discussed in the Qatar Living forum; yet, it uses more formal language and contains very little conversational word types (mostly in quotations and interviews); moreover, being smaller in size, it covers much less vocabulary.", "labels": [], "entities": [{"text": "Doha News", "start_pos": 9, "end_pos": 18, "type": "DATASET", "confidence": 0.9364908635616302}, {"text": "Qatar Living forum", "start_pos": 89, "end_pos": 107, "type": "DATASET", "confidence": 0.9499747157096863}]}, {"text": "Based on these preliminary experiments on Dev2016, we concluded that the domain-specific word vectors trained on Qatar Living Forum were the best for this task, and we used them further in our experiments.", "labels": [], "entities": [{"text": "Dev2016", "start_pos": 42, "end_pos": 49, "type": "DATASET", "confidence": 0.9414821863174438}, {"text": "Qatar Living Forum", "start_pos": 113, "end_pos": 131, "type": "DATASET", "confidence": 0.9820096095403036}]}], "tableCaptions": [{"text": " Table 2: Semantic vectors trained on different unanno-", "labels": [], "entities": []}, {"text": " Table 3: Semantic vectors of different vector sizes, trained", "labels": [], "entities": []}, {"text": " Table 4: Exploring Word2Vec training parameters on Qatar", "labels": [], "entities": []}, {"text": " Table 5: Subtask A. Using all features without some feature", "labels": [], "entities": []}, {"text": " Table 6: Subtask C. Using all features without some feature", "labels": [], "entities": []}]}