{"title": [{"text": "CICBUAPnlp at SemEval-2016 Task 4-A: Discovering Twitter Polarity using Enhanced Embeddings", "labels": [], "entities": [{"text": "Discovering Twitter Polarity", "start_pos": 37, "end_pos": 65, "type": "TASK", "confidence": 0.832953155040741}]}], "abstractContent": [{"text": "This paper presents our approach for SemEval 2016 task 4: Sentiment Analysis in Twitter.", "labels": [], "entities": [{"text": "SemEval 2016 task 4", "start_pos": 37, "end_pos": 56, "type": "TASK", "confidence": 0.8972393721342087}, {"text": "Sentiment Analysis", "start_pos": 58, "end_pos": 76, "type": "TASK", "confidence": 0.9194623529911041}]}, {"text": "We participated in Subtask A: Message Polarity Classification.", "labels": [], "entities": [{"text": "Message Polarity Classification", "start_pos": 30, "end_pos": 61, "type": "TASK", "confidence": 0.7367079059282938}]}, {"text": "The aim is to classify Twit-ter messages into positive, neutral, and negative polarity.", "labels": [], "entities": []}, {"text": "We used a lexical resource for pre-processing of social media data and train a neural network model for feature representation.", "labels": [], "entities": [{"text": "feature representation", "start_pos": 104, "end_pos": 126, "type": "TASK", "confidence": 0.7181153297424316}]}, {"text": "Our resource includes dictionaries of slang words, contractions, abbreviations, and emoticons commonly used in social media.", "labels": [], "entities": []}, {"text": "For the classification process, we pass the features obtained in an unsupervised manner into an SVM classifier.", "labels": [], "entities": []}], "introductionContent": [{"text": "In this paper, we describe our approach for the SemEval 2016 task 4 \"Sentiment Analysis in Twitter\" subtask A (, where the goal is to classify a tweet message as either positive, neutral, or negative.", "labels": [], "entities": [{"text": "SemEval 2016 task 4 \"Sentiment Analysis in Twitter\" subtask A", "start_pos": 48, "end_pos": 109, "type": "TASK", "confidence": 0.8016934742530187}]}, {"text": "The main goal of our approach is to improve the feature representation obtained by a well-known neural network method-Doc2vec (, using dictionaries of abbreviations, contractions, slang words, and emoticons.", "labels": [], "entities": []}, {"text": "Approaches based on neural networks for unsupervised feature representation (or embeddings) often do not perform data cleaning, considering that the network itself would solve the related problems.", "labels": [], "entities": [{"text": "data cleaning", "start_pos": 113, "end_pos": 126, "type": "TASK", "confidence": 0.7560542821884155}]}, {"text": "These approaches treat special characters such as ,.!?# and user mentions as a regular word ().", "labels": [], "entities": []}, {"text": "Still, in some works which use embeddings a basic data cleaning process (i.e., stopwords removal, URL filtering, and removal of rare terms) improves the feature representation and, consequently, the performance of the classification task).", "labels": [], "entities": [{"text": "stopwords removal", "start_pos": 79, "end_pos": 96, "type": "TASK", "confidence": 0.7402752041816711}, {"text": "URL filtering", "start_pos": 98, "end_pos": 111, "type": "TASK", "confidence": 0.7473304271697998}]}, {"text": "The problem with the content of social media messages is that they usually have a lot of nonstandard language expressions ().", "labels": [], "entities": []}, {"text": "Due to the short nature of the messages, most of the users use a large vocabulary of slang words, abbreviations, and emoticons ().", "labels": [], "entities": []}, {"text": "Slang words are not considered as apart of the standard vocabulary of a language, and they are mostly used in informal messages, while abbreviations are shortened forms of a word or name that are used in order to replace the full forms.", "labels": [], "entities": []}, {"text": "Emoticons usually convey the current feeling of the message writer.", "labels": [], "entities": []}, {"text": "For this task we propose a preprocessing phase using the dictionaries that we previously built for the task of Authorship Atribution ().", "labels": [], "entities": [{"text": "Authorship Atribution", "start_pos": 111, "end_pos": 132, "type": "TASK", "confidence": 0.7401280701160431}]}, {"text": "These dictionaries are useful for preprocessing and cleaning messages obtained from several social networks, such as Facebook, Google+, Instagram, etc.", "labels": [], "entities": []}, {"text": "The rest of the paper is structured as follows.", "labels": [], "entities": []}, {"text": "Section 2 describes related work.", "labels": [], "entities": []}, {"text": "Section 3 introduces the social media lexical resource used for this work.", "labels": [], "entities": []}, {"text": "Section 4 presents our proposed approach.", "labels": [], "entities": []}, {"text": "Section 5 presents the evaluation of the task using the neural network based feature representation.", "labels": [], "entities": []}, {"text": "Finally, Section 6 draws the conclusions from our experiments and points out the possible directions of future work.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 2: Obtained results for 2016 Test and Progress", "labels": [], "entities": [{"text": "Obtained", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9962443113327026}, {"text": "2016 Test and Progress", "start_pos": 31, "end_pos": 53, "type": "DATASET", "confidence": 0.7287685871124268}]}]}