{"title": [{"text": "Pomona at SemEval-2016 Task 11: Predicting Word Complexity Based on Corpus Frequency", "labels": [], "entities": [{"text": "SemEval-2016 Task 11", "start_pos": 10, "end_pos": 30, "type": "TASK", "confidence": 0.8333727320035299}, {"text": "Predicting Word Complexity", "start_pos": 32, "end_pos": 58, "type": "TASK", "confidence": 0.9041741291681925}]}], "abstractContent": [{"text": "We introduce a word frequency-based classi-fier for the SemEval 2016 complex word identification task (#11).", "labels": [], "entities": [{"text": "SemEval 2016 complex word identification task", "start_pos": 56, "end_pos": 101, "type": "TASK", "confidence": 0.8461064199606577}]}, {"text": "Words with lower frequency are predicted as complex based on a threshold optimized for G-score.", "labels": [], "entities": [{"text": "G-score", "start_pos": 87, "end_pos": 94, "type": "METRIC", "confidence": 0.9929647445678711}]}, {"text": "We examine three different corpora for calculating frequencies and find English Wikipedia to perform best (ranked 13th on the SemEval task), followed by the Google Web Corpus and lastly Simple English Wikipedia.", "labels": [], "entities": [{"text": "Google Web Corpus", "start_pos": 157, "end_pos": 174, "type": "DATASET", "confidence": 0.939558744430542}, {"text": "Simple English Wikipedia", "start_pos": 186, "end_pos": 210, "type": "DATASET", "confidence": 0.7695909937222799}]}, {"text": "Bagging is also shown to slightly improve the performance of the classifier.", "labels": [], "entities": []}, {"text": "Overall, we find word frequency to be a strong predictor of complexity.", "labels": [], "entities": []}, {"text": "On the SemEval \"test\" set, a frequency classifier that uses the optimal frequency threshold performs on-par with the best submitted system and a system trained using only 500 labeled examples split from the test set achieves results that are only slightly below the best submitted system .", "labels": [], "entities": [{"text": "SemEval \"test\" set", "start_pos": 7, "end_pos": 25, "type": "DATASET", "confidence": 0.6319608211517334}]}], "introductionContent": [{"text": "Text simplification aims to transform text into more accessible versions while retaining the original meaning.", "labels": [], "entities": [{"text": "Text simplification", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.7857534289360046}]}, {"text": "A frequent subproblem of the general simplification problem is complex word identification: identify words in a text that are difficult to understand for the reader.", "labels": [], "entities": [{"text": "complex word identification", "start_pos": 63, "end_pos": 90, "type": "TASK", "confidence": 0.6396094063917795}]}, {"text": "Complex word identification is critical in lexical simplification algorithms where the simplification process is done a word at a time; frequently, simplification is broken into two steps, first identifying the complex words that need simplifying and, second, determining substitutions for these words.", "labels": [], "entities": [{"text": "Complex word identification", "start_pos": 0, "end_pos": 27, "type": "TASK", "confidence": 0.6871223350365957}]}, {"text": "Even for simplification systems that make sentence-level transformations) complex word identification can be used as an additional feature function in the model and as a development tool to help measure progress.", "labels": [], "entities": [{"text": "word identification", "start_pos": 82, "end_pos": 101, "type": "TASK", "confidence": 0.7851938009262085}]}, {"text": "Additionally, in some domains such as health and medicine, accuracy is critical and semiautomated simplification tools are common (.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 59, "end_pos": 67, "type": "METRIC", "confidence": 0.9981404542922974}]}, {"text": "In these domains, complex word identification is useful to help guide the simplification process by both identifying which words need to be simplified and filtering/ranking possible candidate substitutions ( . In this paper, we explore the use of word frequency as a predictor of the complexity of that word.", "labels": [], "entities": [{"text": "word identification", "start_pos": 26, "end_pos": 45, "type": "TASK", "confidence": 0.7426657974720001}]}, {"text": "Corpus studies have shown that simpler texts contain more frequent words than more complicated texts).", "labels": [], "entities": []}, {"text": "User studies have also shown a correlation between word frequency and whether users know the definition of a word ( . In semi-automated text simplification approaches, replacing less frequent words with higher frequency synonyms has been shown to produce text that people view as simpler and is easier to understand ( ).", "labels": [], "entities": []}], "datasetContent": [{"text": "We submitted two systems to the SemEval Complex Word Identification challenge (Task 11), which used the same parameter settings and only differed in where the corpus frequencies were collected, English Wikipedia (NormalBag) and the Google Web Corpus (GoogleBag).", "labels": [], "entities": [{"text": "SemEval Complex Word Identification challenge", "start_pos": 32, "end_pos": 77, "type": "TASK", "confidence": 0.9004609823226929}, {"text": "English Wikipedia (NormalBag)", "start_pos": 194, "end_pos": 223, "type": "DATASET", "confidence": 0.9018957734107971}, {"text": "Google Web Corpus (GoogleBag)", "start_pos": 232, "end_pos": 261, "type": "DATASET", "confidence": 0.8939260045687357}]}, {"text": "Both systems used b = 10 rounds of bagging, which was shown experimentally to have the best scoring value, using repeated rounds of 10-fold validation.", "labels": [], "entities": [{"text": "scoring", "start_pos": 92, "end_pos": 99, "type": "METRIC", "confidence": 0.9778232574462891}]}, {"text": "We also discuss results here fora system which used Simple English Wikipedia word frequencies, though we did not submit it to the challenge (for consistency, we denote it SimpleBag).", "labels": [], "entities": [{"text": "Simple English Wikipedia word frequencies", "start_pos": 52, "end_pos": 93, "type": "DATASET", "confidence": 0.7804627895355225}, {"text": "SimpleBag", "start_pos": 171, "end_pos": 180, "type": "DATASET", "confidence": 0.9404458999633789}]}, {"text": "The task consisted of a training data set (N = 2,237), which was available during development, and a test data set (N = 88,221) on which the competition was scored and the labels were only released after the competition (.", "labels": [], "entities": []}, {"text": "We use both data sets hereto analyze the performance of the classifiers.", "labels": [], "entities": []}, {"text": "shows the results for the classifiers trained using bagging with word frequencies calculated from the three different corpora.", "labels": [], "entities": []}, {"text": "English Wikipedia performed the best, followed by Google Web Corpus and finally Simple English Wikipedia.", "labels": [], "entities": [{"text": "English Wikipedia", "start_pos": 0, "end_pos": 17, "type": "DATASET", "confidence": 0.9463373422622681}, {"text": "Google Web Corpus", "start_pos": 50, "end_pos": 67, "type": "DATASET", "confidence": 0.8814891775449117}, {"text": "Simple English Wikipedia", "start_pos": 80, "end_pos": 104, "type": "DATASET", "confidence": 0.7852868437767029}]}, {"text": "The top two entries were entered into the SemEval competition and ranked 13th and 16th respectively out of 51 systems (42 team submitted systems and 9 baseline systems).", "labels": [], "entities": [{"text": "SemEval competition", "start_pos": 42, "end_pos": 61, "type": "TASK", "confidence": 0.8818128108978271}]}, {"text": "We hypothesize that English Wikipedia represents a good compromise between size/coverage and corpus quality; even though NormalBag had slightly lower recall than the other two, it was able to achieve that recall with a significantly higher accuracy.", "labels": [], "entities": [{"text": "NormalBag", "start_pos": 121, "end_pos": 130, "type": "DATASET", "confidence": 0.9343823194503784}, {"text": "recall", "start_pos": 150, "end_pos": 156, "type": "METRIC", "confidence": 0.9976891279220581}, {"text": "recall", "start_pos": 205, "end_pos": 211, "type": "METRIC", "confidence": 0.996681272983551}, {"text": "accuracy", "start_pos": 240, "end_pos": 248, "type": "METRIC", "confidence": 0.9954110980033875}]}], "tableCaptions": [{"text": " Table 1: Results for the bagged systems (b = 10) with word frequencies calculated on the three different corpora. Results are", "labels": [], "entities": []}]}