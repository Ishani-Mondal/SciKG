{"title": [{"text": "IHS-RD-Belarus at SemEval-2016 Task 9: Transition-based Chinese Semantic Dependency Parsing with Online Reordering and Bootstrapping", "labels": [], "entities": [{"text": "IHS-RD-Belarus", "start_pos": 0, "end_pos": 14, "type": "DATASET", "confidence": 0.8631954193115234}, {"text": "Transition-based Chinese Semantic Dependency Parsing", "start_pos": 39, "end_pos": 91, "type": "TASK", "confidence": 0.5519870221614838}]}], "abstractContent": [{"text": "This paper is a description of our system developed for SemEval-2016 Task 9: Chinese Semantic Dependency Parsing.", "labels": [], "entities": [{"text": "SemEval-2016 Task 9", "start_pos": 56, "end_pos": 75, "type": "TASK", "confidence": 0.8892039259274801}, {"text": "Chinese Semantic Dependency Parsing", "start_pos": 77, "end_pos": 112, "type": "TASK", "confidence": 0.5648391991853714}]}, {"text": "We have built a transition-based dependency parser with on-line reordering, which is not limited to a tree structure and can produce 99.7% of the necessary dependencies while maintaining linear algorithm complexity.", "labels": [], "entities": []}, {"text": "To improve parsing quality we used additional techniques such as pre-and post-processing of the dependency graph, bootstrapping and a rich feature set with additional semantic features.", "labels": [], "entities": [{"text": "parsing", "start_pos": 11, "end_pos": 18, "type": "TASK", "confidence": 0.9632980823516846}]}], "introductionContent": [{"text": "Dependency parsing is one of the core tasks in natural language processing, as it provides useful information for other NLP tasks.", "labels": [], "entities": [{"text": "Dependency parsing", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.8672453761100769}, {"text": "natural language processing", "start_pos": 47, "end_pos": 74, "type": "TASK", "confidence": 0.6450948317845663}]}, {"text": "Traditional syntactic parsing usually represents a sentence as a treeshape structure and this restriction is essential for most of efficient algorithms developed in the past years.", "labels": [], "entities": [{"text": "syntactic parsing", "start_pos": 12, "end_pos": 29, "type": "TASK", "confidence": 0.7036802768707275}]}, {"text": "Semantic dependency parsing, on the other hand, deals with acyclic graphs, where words may have multiple incoming dependencies.", "labels": [], "entities": [{"text": "Semantic dependency parsing", "start_pos": 0, "end_pos": 27, "type": "TASK", "confidence": 0.7170747319857279}]}, {"text": "It significantly complicates the task and requires development of the new algorithms or special adoption of the old ones.", "labels": [], "entities": []}, {"text": "There are two main approaches to dependency parsing ().", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 33, "end_pos": 51, "type": "TASK", "confidence": 0.8695554137229919}]}, {"text": "The first one is a graph-based approach, for example, spanning tree algorithms (, where the goal is to find the highest scoring tree from a complete graph of dependencies between words in the sentence.", "labels": [], "entities": []}, {"text": "The second approach is transition-based, which, instead of searching for global optimum, greedily finds local optimum with a chain of actions that lead to a parsing tree.", "labels": [], "entities": []}, {"text": "The main advantage of the transition-based parsers is that they are in general faster than graph-based ones because of the linear complexity of the algorithm.", "labels": [], "entities": []}, {"text": "As we move from syntactic parsing to semantic parsing, and instead of projective trees have to deal with acyclic graphs, exact inference becomes NPhard, so some strong independence assumptions or heuristics are needed.", "labels": [], "entities": [{"text": "syntactic parsing", "start_pos": 16, "end_pos": 33, "type": "TASK", "confidence": 0.7650900185108185}, {"text": "semantic parsing", "start_pos": 37, "end_pos": 53, "type": "TASK", "confidence": 0.7314527630805969}]}, {"text": "A lot of modifications have been proposed for transition-based parsers to support non-projective structures.", "labels": [], "entities": []}, {"text": "proposed a pseudo-projective parsing technique which consists in modifying the input into a projective dependency tree with extended labels, performing the projective parsing and then applying an approximate back transformation.", "labels": [], "entities": []}, {"text": "Attardi (2006) introduced additional actions that add dependencies between the roots of non-adjacent subtrees.", "labels": [], "entities": []}, {"text": "Both techniques maintain linear algorithm complexity at the expense of incomplete coverage of all possible dependency trees.", "labels": [], "entities": []}, {"text": "Complete coverage of all non-projective trees is achieved by Nivre (2009) with a technique called on-line reordering but it increases the worst-case complexity from linear to quadratic.", "labels": [], "entities": []}], "datasetContent": [{"text": "In order to evaluate the influence of the methods described above on parsing quality, we have built five different systems and tested them on the development set.", "labels": [], "entities": [{"text": "parsing", "start_pos": 69, "end_pos": 76, "type": "TASK", "confidence": 0.9828960299491882}]}, {"text": "The labeled and unlabeled results for 2 types of corpus (\"sdpv2\" and \"text\") are presented in tables from 1 to 4.", "labels": [], "entities": []}, {"text": "LP, LR and LF are labeled precision, recall and F1-score for predicted dependencies (parent-child-dependency label triples).", "labels": [], "entities": [{"text": "precision", "start_pos": 26, "end_pos": 35, "type": "METRIC", "confidence": 0.9968715310096741}, {"text": "recall", "start_pos": 37, "end_pos": 43, "type": "METRIC", "confidence": 0.9980060458183289}, {"text": "F1-score", "start_pos": 48, "end_pos": 56, "type": "METRIC", "confidence": 0.9985195994377136}]}, {"text": "NLF is F1-score for non-local dependencies.", "labels": [], "entities": [{"text": "NLF", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.7930756211280823}, {"text": "F1-score", "start_pos": 7, "end_pos": 15, "type": "METRIC", "confidence": 0.9990180730819702}]}, {"text": "UP, UR, UF and NUF are unlabeled counterparts.", "labels": [], "entities": [{"text": "UP", "start_pos": 0, "end_pos": 2, "type": "DATASET", "confidence": 0.8902608752250671}, {"text": "UR", "start_pos": 4, "end_pos": 6, "type": "DATASET", "confidence": 0.6608151197433472}, {"text": "NUF", "start_pos": 15, "end_pos": 18, "type": "DATASET", "confidence": 0.891315221786499}]}, {"text": "The base system is built with the algorithm described in 2.1.", "labels": [], "entities": []}, {"text": "BS is bootstrapping (2.2), SemSemantic Features (2.3) and PP is pre-and postprocessing (2.4).", "labels": [], "entities": [{"text": "BS", "start_pos": 0, "end_pos": 2, "type": "DATASET", "confidence": 0.7234492897987366}]}, {"text": "Pre-and post-processing procedures proved to be the most useful, especially on the \"sdpv2\" corpus.", "labels": [], "entities": [{"text": "sdpv2\" corpus", "start_pos": 84, "end_pos": 97, "type": "DATASET", "confidence": 0.6368440588315328}]}, {"text": "Bootstrapping improves recall, but harms precision and non-local dependencies.", "labels": [], "entities": [{"text": "recall", "start_pos": 23, "end_pos": 29, "type": "METRIC", "confidence": 0.9989355206489563}, {"text": "precision", "start_pos": 41, "end_pos": 50, "type": "METRIC", "confidence": 0.9992400407791138}]}, {"text": "Semantic Features, on the other hand, help to extract non-local dependencies.", "labels": [], "entities": []}, {"text": "The PP_BS_SEM system, with all features included, performed better than all other on the \"text\" corpus and has comparable results on the \"sdpv2\" corpus.", "labels": [], "entities": [{"text": "PP_BS_SEM", "start_pos": 4, "end_pos": 13, "type": "TASK", "confidence": 0.6091971874237061}]}, {"text": "That is why the output of this system was submitted to.", "labels": [], "entities": []}, {"text": "The results of our system, compared to other submissions, are represented in tables 5-8.", "labels": [], "entities": []}, {"text": "Our submitted system has shown the highest precision, recall and F1-score values for all dependencies, but did not perform well on nonlocal labeled dependencies, which maybe an effect of bootstrapping or shortcomings of the selected model in general.", "labels": [], "entities": [{"text": "precision", "start_pos": 43, "end_pos": 52, "type": "METRIC", "confidence": 0.9994416832923889}, {"text": "recall", "start_pos": 54, "end_pos": 60, "type": "METRIC", "confidence": 0.9993245601654053}, {"text": "F1-score", "start_pos": 65, "end_pos": 73, "type": "METRIC", "confidence": 0.9981505274772644}]}], "tableCaptions": [{"text": " Table 1: evaluation on sdpv2 (labeled)", "labels": [], "entities": []}, {"text": " Table 2: evaluation on sdpv2 (unlabeled)", "labels": [], "entities": []}, {"text": " Table 3: evaluation on text (labeled)", "labels": [], "entities": []}, {"text": " Table 4: evaluation on text (unlabeled)", "labels": [], "entities": []}, {"text": " Table 5: SemEval results on sdpv2 (labeled)", "labels": [], "entities": [{"text": "SemEval", "start_pos": 10, "end_pos": 17, "type": "TASK", "confidence": 0.9715968370437622}]}, {"text": " Table 6: SemEval results on sdpv2 (unlabeled)", "labels": [], "entities": [{"text": "SemEval", "start_pos": 10, "end_pos": 17, "type": "TASK", "confidence": 0.9626359343528748}]}, {"text": " Table 7: SemEval results on text (labeled)", "labels": [], "entities": [{"text": "SemEval", "start_pos": 10, "end_pos": 17, "type": "TASK", "confidence": 0.9814022183418274}]}, {"text": " Table 8: SemEval results on text (unlabeled)", "labels": [], "entities": [{"text": "SemEval", "start_pos": 10, "end_pos": 17, "type": "TASK", "confidence": 0.9736644625663757}]}]}