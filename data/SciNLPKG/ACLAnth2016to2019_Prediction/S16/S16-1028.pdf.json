{"title": [{"text": "SentiSys at SemEval-2016 Task 4: Feature-Based System for Sentiment Analysis in Twitter", "labels": [], "entities": [{"text": "Sentiment Analysis", "start_pos": 58, "end_pos": 76, "type": "TASK", "confidence": 0.8981124758720398}]}], "abstractContent": [{"text": "This paper describes our sentiment analysis system which has been built for Sentiment Analysis in Twitter Task of SemEval-2016.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 25, "end_pos": 43, "type": "TASK", "confidence": 0.8990986347198486}, {"text": "Sentiment Analysis", "start_pos": 76, "end_pos": 94, "type": "TASK", "confidence": 0.9671152532100677}, {"text": "Twitter Task of SemEval-2016", "start_pos": 98, "end_pos": 126, "type": "DATASET", "confidence": 0.5976512134075165}]}, {"text": "We have used a Logistic Regression classifier with different groups of features.", "labels": [], "entities": [{"text": "Logistic Regression classifier", "start_pos": 15, "end_pos": 45, "type": "TASK", "confidence": 0.7352708578109741}]}, {"text": "This system is an improvement to our previous system Lsislif in Semeval-2015 after removing some features and adding new features extracted from anew automatic constructed sentiment lexicon.", "labels": [], "entities": [{"text": "Lsislif in Semeval-2015", "start_pos": 53, "end_pos": 76, "type": "DATASET", "confidence": 0.6795116265614828}]}], "introductionContent": [{"text": "Sentiment analysis in Twitter is different from document level sentiment analysis.", "labels": [], "entities": [{"text": "Sentiment analysis", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.9395963549613953}, {"text": "document level sentiment analysis", "start_pos": 48, "end_pos": 81, "type": "TASK", "confidence": 0.6989083290100098}]}, {"text": "Normally, in document level, each document is classified as positive or negative, the document is long enough to obtain a good representation using only the existing words (bag-of-words).", "labels": [], "entities": []}, {"text": "For example, in movie reviews we can get f-score of 85% using bag-of-words representation with SVM classifier while in Twitter it is about 60% according to our experiments in previous SemEval workshops.", "labels": [], "entities": [{"text": "f-score", "start_pos": 41, "end_pos": 48, "type": "METRIC", "confidence": 0.9967345595359802}]}, {"text": "This lower performance in Twitter domain is not surprising if we know the limitations of such task when applied to Twitter: \u2022 The size of a tweet is limited to 140 characters which leads to sparseness where the tweets do not provide enough word co-occurrence.", "labels": [], "entities": []}, {"text": "\u2022 The informal language and non-standard expressions.", "labels": [], "entities": []}, {"text": "\u2022 The numerous spelling errors.", "labels": [], "entities": [{"text": "spelling errors", "start_pos": 15, "end_pos": 30, "type": "METRIC", "confidence": 0.8135809600353241}]}, {"text": "For dealing with the previous limitations, we have decided to extend the bag-of-words representation.", "labels": [], "entities": []}, {"text": "Therefore, many group of features have been extracted.", "labels": [], "entities": []}, {"text": "Uni-gram, bi-gram and 3-grams of words features to capture the text of tweet and the context.", "labels": [], "entities": []}, {"text": "Negation features to handle the negated context.", "labels": [], "entities": []}, {"text": "Sentiment lexicons features can help the classification because it contains positive and negative words which can add a useful information about the polarity of a tweet, they also contain a lot of terms which may not appear in the training data which can be very useful.", "labels": [], "entities": []}, {"text": "Semantic features as Brown clusters can also give a rich representation which can be useful for reducing the sparsity.", "labels": [], "entities": []}, {"text": "For evaluating our system, we have participated in SemEval-2016 competition for sentiment analysis in Twitter (message polarity subtask A).", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 80, "end_pos": 98, "type": "TASK", "confidence": 0.9212520718574524}]}, {"text": "Our system has been ranked six over 34, this system is derived from our previous system LsisLif which has been ranked third in.", "labels": [], "entities": []}, {"text": "The rest of this chapter is organized as follows.", "labels": [], "entities": []}, {"text": "Section 2 presents the problem formulation.", "labels": [], "entities": [{"text": "problem formulation", "start_pos": 23, "end_pos": 42, "type": "TASK", "confidence": 0.6833317875862122}]}, {"text": "Section 3 gives an overview of our proposed approach.", "labels": [], "entities": []}, {"text": "The features we extracted for training the classifier are presented in Section 4.", "labels": [], "entities": []}, {"text": "Our experiments are described in Section 5.", "labels": [], "entities": []}, {"text": "The related work is presented in Section 6.", "labels": [], "entities": []}, {"text": "The conclusion and future work are presented in Section 7.", "labels": [], "entities": []}, {"text": "possible features F = f 1 , f 2 , .., f m that can appear int i . The features can be single words, bigrams, ngrams, stemmed words or other syntactic or semantic features.", "labels": [], "entities": []}, {"text": "If a feature f i exists in a tweet t j , the tweet can be represented as a vector of weighted features t j = (w 1 , w 2 , .., w m ) where w i is the weight of the feature f i in the tweet t j . w i can represent the presence or absence of the feature or the frequency or any other function of the feature frequency in the tweet.", "labels": [], "entities": []}, {"text": "Let us have three classes C = c 1 , c 2 , c 3 where c 1 represents the negative class, c 2 the neutral class and c 3 the positive class.", "labels": [], "entities": []}, {"text": "Our task is to assign each tweet t j to a class c i .", "labels": [], "entities": []}], "datasetContent": [{"text": "Twitter datasets have been provided by SemEval organizers since 2013 for message polarity classification subtask of sentiment analysis in Twitter ().", "labels": [], "entities": [{"text": "Twitter datasets", "start_pos": 0, "end_pos": 16, "type": "DATASET", "confidence": 0.814859002828598}, {"text": "message polarity classification subtask of sentiment analysis", "start_pos": 73, "end_pos": 134, "type": "TASK", "confidence": 0.7706138236182076}]}, {"text": "The participants have been provided with training tweets annotated positive, negative or neutral.", "labels": [], "entities": []}, {"text": "In addition to a script for downloading the tweets.", "labels": [], "entities": []}, {"text": "After executing the given script, we got the whole training dataset which consists of 9684 tweets.", "labels": [], "entities": []}, {"text": "The organizers have also provided a development set containing 1654 tweets for tuning a machine learner.", "labels": [], "entities": []}, {"text": "shows the distribution of each label in each dataset.", "labels": [], "entities": []}, {"text": "We trained the L1-regularized logistic regression classifier implemented in LIBLINEAR), we had also tested L2 regularization technique but it gives less performance than L1.", "labels": [], "entities": []}, {"text": "The classifier is trained on the training dataset using the features in the previous section with the three polarities (positive, negative, and neutral) as labels.", "labels": [], "entities": []}, {"text": "A weighting schema is adapted for each class, we use the weighting option \u2212w i which enables a use of different cost parameter C for different classes.", "labels": [], "entities": []}, {"text": "Since the training data is unbalanced, this weighting schema adjusts the probability of each label.", "labels": [], "entities": []}, {"text": "Thus, we tuned the classifier in adjusting the cost parameter C of logistic regression, weight w pos of positive class and weight w neg of negative class.", "labels": [], "entities": []}, {"text": "We used the development set for tuning the three parameters, all combinations of C in range [0. 3, w pos =7.6, w neg =5.2 have given the best F1-score for the development set and therefore it was selected for our experiments on test set 2016.", "labels": [], "entities": [{"text": "F1-score", "start_pos": 142, "end_pos": 150, "type": "METRIC", "confidence": 0.9987905621528625}]}], "tableCaptions": [{"text": " Table 3: Sentiment labels distribution in the training, testing", "labels": [], "entities": [{"text": "Sentiment labels distribution", "start_pos": 10, "end_pos": 39, "type": "TASK", "confidence": 0.8883055647214254}]}]}