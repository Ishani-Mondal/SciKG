{"title": [{"text": "DeepStance at SemEval-2016 Task 6: Detecting Stance in Tweets Using Character and Word-Level CNNs", "labels": [], "entities": [{"text": "Detecting Stance in Tweets", "start_pos": 35, "end_pos": 61, "type": "TASK", "confidence": 0.8833895623683929}]}], "abstractContent": [{"text": "This paper describes our approach for the Detecting Stance in Tweets task (SemEval-2016 Task 6).", "labels": [], "entities": [{"text": "Detecting Stance in Tweets task", "start_pos": 42, "end_pos": 73, "type": "TASK", "confidence": 0.9331893563270569}, {"text": "SemEval-2016 Task 6)", "start_pos": 75, "end_pos": 95, "type": "DATASET", "confidence": 0.7568336725234985}]}, {"text": "We utilized recent advances in short text categorization using deep learning to create word-level and character-level models.", "labels": [], "entities": []}, {"text": "The choice between word-level and character-level models in each particular case was informed through validation performance.", "labels": [], "entities": []}, {"text": "Our final system is a combination of classifiers using word-level or character-level models.", "labels": [], "entities": []}, {"text": "We also employed novel data augmentation techniques to expand and diversify our training dataset, thus making our system more robust.", "labels": [], "entities": []}, {"text": "Our system achieved a macro-average precision , recall and F1-scores of 0.67, 0.61 and 0.635 respectively.", "labels": [], "entities": [{"text": "precision", "start_pos": 36, "end_pos": 45, "type": "METRIC", "confidence": 0.9672294855117798}, {"text": "recall", "start_pos": 48, "end_pos": 54, "type": "METRIC", "confidence": 0.9996346235275269}, {"text": "F1-scores", "start_pos": 59, "end_pos": 68, "type": "METRIC", "confidence": 0.9996023774147034}]}], "introductionContent": [{"text": "Stance detection is the task of automatically determining whether the authors of a text are against or in favour of a given target.", "labels": [], "entities": [{"text": "Stance detection", "start_pos": 0, "end_pos": 16, "type": "TASK", "confidence": 0.9395020008087158}]}, {"text": "For instance, take the following sentence: \"It has been such a cold April, so much for global warming.\"", "labels": [], "entities": [{"text": "global warming", "start_pos": 87, "end_pos": 101, "type": "TASK", "confidence": 0.7395729124546051}]}, {"text": "This sentence's author is most likely against the concept of global warming (i.e., does not believe in it).", "labels": [], "entities": []}, {"text": "The work presented here is specifically targeted towards detecting stance in tweets.", "labels": [], "entities": [{"text": "detecting stance in tweets", "start_pos": 57, "end_pos": 83, "type": "TASK", "confidence": 0.8215634673833847}]}, {"text": "The noisy and idiosyncratic nature of tweets make this a particularly hard task.", "labels": [], "entities": []}, {"text": "Automatic identification of stance in tweets has practical applications fora range of domains.", "labels": [], "entities": [{"text": "Automatic identification of stance in tweets", "start_pos": 0, "end_pos": 44, "type": "TASK", "confidence": 0.7648589362700781}]}, {"text": "For instance, it can be used as a sensor to measure the attitude of Twitter users on various issues, such as: political issues, candidates, brand names, TV shows, etc.", "labels": [], "entities": []}, {"text": "There has been extensive research done on modelling and automatic detection of stance in political arenas (e.g., debates) () and on online forums.", "labels": [], "entities": [{"text": "automatic detection of stance in political arenas (e.g., debates)", "start_pos": 56, "end_pos": 121, "type": "TASK", "confidence": 0.7749327371517817}]}, {"text": "However, as we alluded to earlier, the peculiar nature of tweets make techniques that have been developed for other platforms unsuitable.", "labels": [], "entities": []}, {"text": "The field closest to this work is the field of Twitter sentiment classification, where the task is to detect the sentiment of a given tweet, usually as positive, negative, or neutral.", "labels": [], "entities": [{"text": "Twitter sentiment classification", "start_pos": 47, "end_pos": 79, "type": "TASK", "confidence": 0.712022602558136}]}, {"text": "Nonetheless, it is important to note that there are substantial differences between sentiment classification and stance detection.", "labels": [], "entities": [{"text": "sentiment classification", "start_pos": 84, "end_pos": 108, "type": "TASK", "confidence": 0.9655179381370544}, {"text": "stance detection", "start_pos": 113, "end_pos": 129, "type": "TASK", "confidence": 0.9133489727973938}]}, {"text": "Sentiment classifiers determine the polarity of a given tweet, without considering any targets (see for an example of a Twitter sentiment classifier).", "labels": [], "entities": [{"text": "Sentiment classifiers", "start_pos": 0, "end_pos": 21, "type": "TASK", "confidence": 0.8539674580097198}]}, {"text": "For instance, consider the tweet: \"I love Donald Trump\", this tweet has a positive sentiment, and the author of the tweet has a positive stance towards Donald Trump, but it can also be inferred that the author is most likely against or at best neutral towards Bernie Sanders.", "labels": [], "entities": []}, {"text": "In this paper, we present a system for automatic detection of stance in Tweets.", "labels": [], "entities": [{"text": "automatic detection of stance in Tweets", "start_pos": 39, "end_pos": 78, "type": "TASK", "confidence": 0.7605801423390707}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Samples of representative hashtags", "labels": [], "entities": []}, {"text": " Table 2: Number of collected tweets per target and stance", "labels": [], "entities": []}, {"text": " Table 3: Baseline performance (Naive Bayes classifiers, test", "labels": [], "entities": []}, {"text": " Table 4: Performance of Word-Level Classifiers for Climate Change, Hillary Clinton and Feminist Movement.", "labels": [], "entities": []}, {"text": " Table 5: Results on test data, with rank out of the 19 teams.", "labels": [], "entities": []}]}