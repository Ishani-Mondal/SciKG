{"title": [{"text": "AKTSKI at SemEval-2016 Task 5: Aspect Based Sentiment Analysis for Consumer Reviews", "labels": [], "entities": [{"text": "AKTSKI", "start_pos": 0, "end_pos": 6, "type": "DATASET", "confidence": 0.5938743948936462}, {"text": "Aspect Based Sentiment Analysis", "start_pos": 31, "end_pos": 62, "type": "TASK", "confidence": 0.7657951563596725}]}], "abstractContent": [{"text": "This paper describes the polarity classification system designed for participation in SemEval-2016 Task 5-ABSA.", "labels": [], "entities": [{"text": "polarity classification", "start_pos": 25, "end_pos": 48, "type": "TASK", "confidence": 0.7700627744197845}, {"text": "SemEval-2016 Task 5-ABSA", "start_pos": 86, "end_pos": 110, "type": "TASK", "confidence": 0.8283331394195557}]}, {"text": "The aim is to determine the sentiment polarity expressed towards certain aspect within a consumer review.", "labels": [], "entities": []}, {"text": "Our system is based on supervised learning using Support Vector Machine (SVM).", "labels": [], "entities": []}, {"text": "We use standard features for basic classification model.", "labels": [], "entities": []}, {"text": "On top this, we include rules to check precedent polarity sequence.", "labels": [], "entities": []}], "introductionContent": [{"text": "In the consumer-focused markets today, understanding opinions expressed on the online platforms or review portals is of key essence for the businesses.", "labels": [], "entities": []}, {"text": "Statistical or Machine learning methods and Natural Language Processing are now being widely applied to extract important information or patterns from the opinion data.", "labels": [], "entities": []}, {"text": "A review statement may have a mix of sentiments towards different aspects.", "labels": [], "entities": []}, {"text": "For e.g., consider the food and ambiance at xyz hotel were extraordinary, as expected.", "labels": [], "entities": []}, {"text": "However, the waiters seemed rude.", "labels": [], "entities": []}, {"text": "Here, the main entity of review is a 'hotel'.", "labels": [], "entities": []}, {"text": "Henceforth, we will refer to such main entity as global item.", "labels": [], "entities": []}, {"text": "However, there is no definite overall sentiment expressed towards the global item.", "labels": [], "entities": []}, {"text": "Different sentiments are expressed towards food and ambiance aspects (extraordinary: positive) and towards the aspect of service (waiters, rude: negative).", "labels": [], "entities": []}, {"text": "Thus, it is important to approach sentiment detection as an aspect-based problem.", "labels": [], "entities": [{"text": "sentiment detection", "start_pos": 34, "end_pos": 53, "type": "TASK", "confidence": 0.975890040397644}]}, {"text": "The SemEval-2016 Task 5 -Aspect Based Sentiment Analysis (ABSA) focuses on this problem.", "labels": [], "entities": [{"text": "SemEval-2016 Task 5 -Aspect Based Sentiment Analysis (ABSA)", "start_pos": 4, "end_pos": 63, "type": "TASK", "confidence": 0.760505811734633}]}, {"text": "This task is a continuation from SemEval-2015 ABSA task (.", "labels": [], "entities": [{"text": "SemEval-2015 ABSA task", "start_pos": 33, "end_pos": 55, "type": "TASK", "confidence": 0.7161749402681986}]}, {"text": "The task was organized across different domains and languages.", "labels": [], "entities": []}, {"text": "We participated in Restaurant domain in English language.", "labels": [], "entities": [{"text": "Restaurant domain", "start_pos": 19, "end_pos": 36, "type": "TASK", "confidence": 0.5173462778329849}]}, {"text": "The focus of our system is polarity detection and not aspect extraction.", "labels": [], "entities": [{"text": "polarity detection", "start_pos": 27, "end_pos": 45, "type": "TASK", "confidence": 0.7598215341567993}, {"text": "aspect extraction", "start_pos": 54, "end_pos": 71, "type": "TASK", "confidence": 0.6833332031965256}]}, {"text": "Thus, we use dataset in which aspects are already known.", "labels": [], "entities": []}, {"text": "To develop our system, we have used standard features for basic model and also rules to check effect of precedent-polarity sequence pattern on polarity to be predicted.", "labels": [], "entities": []}, {"text": "We focus on experimenting with sequence pattern.", "labels": [], "entities": []}, {"text": "The system is described in Section 3.", "labels": [], "entities": []}, {"text": "Pre-processing is described in Sub-section 3.1.", "labels": [], "entities": []}, {"text": "selected features are discussed in Sub-section 3.2 and sequence pattern discussed in Sub-section 3.3.", "labels": [], "entities": [{"text": "sequence", "start_pos": 55, "end_pos": 63, "type": "METRIC", "confidence": 0.9343667030334473}]}, {"text": "In section 4, we discuss the analysis and evaluation results for our system.", "labels": [], "entities": []}], "datasetContent": [{"text": "Following observations are made on the provided training dataset: 1.", "labels": [], "entities": []}, {"text": "In majority of the cases, the sentences under the same rID exhibit similar sentiment.", "labels": [], "entities": []}, {"text": "In other words, polarity values {p 1 , p 2 , ..., p N }, under same rID, are equal.", "labels": [], "entities": []}, {"text": "Henceforth, we will refer to this as Flow.", "labels": [], "entities": []}, {"text": "2. There are sentences where the polarity values change, i.e., pi is not equal top i\u22121 , under same rID.", "labels": [], "entities": []}, {"text": "Henceforth, we will refer to this as Trans (transition).", "labels": [], "entities": []}, {"text": "Trans instances maybe identified by explicit contrast terms present around tar.", "labels": [], "entities": []}, {"text": "The common contrast terms found in the dataset are: 'but', 'however', 'though', 'tho', 'although', 'yet', 'except' For instance, The decor is right tho...but they REALLY need to clean that vent in the ceiling...its quite un-appetizing, and kills your effort to make this place look sleek and modern target=\"place\" polarity=\"negative\"; target=\"decor\" polarity=\"positive\"; target=\"vent\" polarity=\"negative\" However, this does not imply that a contrast term is always present when Trans happens.", "labels": [], "entities": [{"text": "REALLY", "start_pos": 163, "end_pos": 169, "type": "METRIC", "confidence": 0.990658164024353}]}, {"text": "Exploiting the 'Flow or Trans' patterns can help address ambiguity.", "labels": [], "entities": []}, {"text": "This is the main reason for including sequence pattern.", "labels": [], "entities": []}, {"text": "Consider following sentence: The manager came to the table and said we can do what we want, so we paid for what we did enjoy, the drinks and appetizers.", "labels": [], "entities": []}, {"text": "For a classifier, the sentiment expressed towards 'manager' maybe ambiguous.", "labels": [], "entities": []}, {"text": "Our basic model classifies this as neutral, while the true polarity is negative.", "labels": [], "entities": []}, {"text": "However, if we take previous sentence in consideration -The level of rudeness was preposterous -the state of mind of the reviewer becomes more clear.", "labels": [], "entities": []}, {"text": "Based on this observation, we hypothesize that, under same review (rID), precedent polarity outcome affects current polarity outcome, either by Flow or Trans, given certain conditions.", "labels": [], "entities": []}, {"text": "() propose a context-based model for sentiment analysis of tweets, on similar lines.", "labels": [], "entities": [{"text": "sentiment analysis of tweets", "start_pos": 37, "end_pos": 65, "type": "TASK", "confidence": 0.9321380108594894}]}, {"text": "They use sequence of tweets to build Conversational context, hashtags to build Topical context and also use Markovian approach.", "labels": [], "entities": []}, {"text": "We describe our methods to account for Flow or Trans here.", "labels": [], "entities": []}, {"text": "Method1: We use new set of features instead of basic feature-set discussed in sub-section 3.2.", "labels": [], "entities": []}, {"text": "First, we generate the features representing conditions for Flow or Trans.", "labels": [], "entities": []}, {"text": "We use two conditions for our model -contrast keywords and sentiment keywords -present in a SubSent.", "labels": [], "entities": []}, {"text": "The training dataset is divided into 3 sub-sets according to polarity labels.", "labels": [], "entities": []}, {"text": "Then, we search for sentiment terms belonging to one of the lexicon corpora, sentiment terms with negation terms (bi-grams and tri-grams) and terms belonging to our neutral word list.", "labels": [], "entities": []}, {"text": "A new dictionary Dis created with these terms.", "labels": [], "entities": []}, {"text": "Moreover, TF-IDF based selection is performed on the 3 sub-sets (or documents).", "labels": [], "entities": [{"text": "TF-IDF based selection", "start_pos": 10, "end_pos": 32, "type": "TASK", "confidence": 0.7725660602251688}]}, {"text": "Separate sentiment classes have been used hereto let the classifier learn how strongly a SubSent is inclined towards any particular sentiment type.", "labels": [], "entities": []}, {"text": "The classifier should learn that if such inclination is strong, then ambiguity is low.", "labels": [], "entities": [{"text": "ambiguity", "start_pos": 69, "end_pos": 78, "type": "METRIC", "confidence": 0.9645966291427612}]}, {"text": "So, effect of previous SubSent should also below.", "labels": [], "entities": []}, {"text": "New input feature-set corresponding to SubSent i is X(i) = {X i , X i\u22121 , X i\u22122 }, plus, selective features from sub-section 3.2.", "labels": [], "entities": []}, {"text": "For initial two SubSent(s) under a rID, X i\u22122 or both X i\u22121 and X i\u22122 are empty.", "labels": [], "entities": []}, {"text": "We do not use n-gram and neutral word features because terms are now selected from D.", "labels": [], "entities": []}, {"text": "Punctuation is ignored since its effect is minimal.", "labels": [], "entities": [{"text": "Punctuation", "start_pos": 0, "end_pos": 11, "type": "METRIC", "confidence": 0.9632750749588013}]}, {"text": "cat specific keywords are included because they are extracted using different document-types.", "labels": [], "entities": []}, {"text": "Lexicon scores are also included to capture sentiment strength.", "labels": [], "entities": []}, {"text": "The same SVM-RBF classifier is then trained with X to predict polarities.", "labels": [], "entities": []}, {"text": "For test data, same dictionary Dis used to generate new features.", "labels": [], "entities": []}, {"text": "Method2: This method is along the lines of auto-regression 5 . However, polarity sequence is not a strict time-series.", "labels": [], "entities": []}, {"text": "Hence, we devise our mathematical model with necessary considerations.", "labels": [], "entities": []}, {"text": "A first set of predicted polarities P 1 = {p 11 , p 12 , ..., p 1k } are obtained using SVM-RBF with all of the basic features from sub-section 3.2.", "labels": [], "entities": [{"text": "SVM-RBF", "start_pos": 88, "end_pos": 95, "type": "DATASET", "confidence": 0.9099974036216736}]}, {"text": "Polarities are mapped as {positive, negative, neutral} \u2192 {1,-1,0}.", "labels": [], "entities": []}, {"text": "The aim is to obtain final predictions, P 2 = {p 21 , p 22 , ..., p 2k }.", "labels": [], "entities": []}, {"text": "Feature-set X i = {posD i , negD i , neutD i , cont i } for SubSent i of test data is obtained using D.", "labels": [], "entities": []}, {"text": "However, we do not predict using these features.", "labels": [], "entities": []}, {"text": "The Flow or Trans effect is directly calculated using P 1 values.", "labels": [], "entities": [{"text": "Flow or Trans effect", "start_pos": 4, "end_pos": 24, "type": "METRIC", "confidence": 0.7669605314731598}]}, {"text": "For each SubSent i , we define following values: s pi : positive vote.", "labels": [], "entities": []}, {"text": "This is initialized by 0, then incremented by +1 for first term found in posD i and by +0.5 for every next term in posD i , s n i : negative vote.", "labels": [], "entities": []}, {"text": "This is initialized by 0, then incremented by -1 for first term found in negD i and by -0.5 for every next term in negD i , so i : neutral vote.", "labels": [], "entities": []}, {"text": "This is initialized by 0.4 (s o imin ), then incremented by (1-s oi )/4 for every term found in neutD i , keeping the value below 1.", "labels": [], "entities": []}, {"text": "c i : contrast vote.", "labels": [], "entities": [{"text": "contrast", "start_pos": 6, "end_pos": 14, "type": "METRIC", "confidence": 0.9449184536933899}]}, {"text": "This is initialized by +1; assigned c i = 2, if cont i is not empty, w i : aggregate voting weight.", "labels": [], "entities": []}, {"text": "This is calculated as, Since, a SubSent must express some sentiment, we assume a basic neutral characteristic in each SubSent.", "labels": [], "entities": []}, {"text": "Hence, so imin is added.", "labels": [], "entities": []}, {"text": "We define a function g(w,p) = |w|(p + ||p|-1|).", "labels": [], "entities": []}, {"text": "Then, using these parameters we calculate a weighted effect, \u02c6 p(i), for polarity as, The increment and assignment values have been chosen after experimenting with different values.", "labels": [], "entities": []}, {"text": "Also, for our model, l = i-2 works best.", "labels": [], "entities": []}, {"text": "Effect value E i captures the effect of precedent polarities.", "labels": [], "entities": []}, {"text": "The effect of a polarity value p 1,i\u22122 should be amplified with respect top 1,i\u22121 if p 1,i\u22121 came by contrast and reduced if p 1,i\u22122 itself came by contrast.", "labels": [], "entities": []}, {"text": "Hence, p 1,i\u22122 is multiplied with c i\u22121 /c i\u22122 . Finally, the average effect E i(avg) should be reduced if current SubSent i has explicit contrast terms.", "labels": [], "entities": []}, {"text": "Hence, the division by 2c i . Then, if\u02c6pif\u02c6 if\u02c6p(i)<0, p 2i = -1; if\u02c6pif\u02c6 if\u02c6p(i)>1, p 2i = 1; otherwise, p 2i = 0.", "labels": [], "entities": []}, {"text": "These equations are tuned based on observations made on training data.", "labels": [], "entities": []}, {"text": "More generic and robust equations need to be formed.", "labels": [], "entities": []}, {"text": "The result of evaluation is provided in.", "labels": [], "entities": []}, {"text": "There were 676 sentences in the evaluation (test) data and 859 instances of aspect values (tar, cat, f, t).", "labels": [], "entities": []}, {"text": "The polarity values had to be predicted.", "labels": [], "entities": []}, {"text": "The system predictions were evaluated against gold labels by the organizers.", "labels": [], "entities": []}, {"text": "There were total 30 submissions in polarity detection task for Restaurant domain and English language.", "labels": [], "entities": [{"text": "polarity detection", "start_pos": 35, "end_pos": 53, "type": "TASK", "confidence": 0.7433973550796509}]}, {"text": "This included multiple submissions from single teams as well.", "labels": [], "entities": []}, {"text": "Relative performance of our system was poor.", "labels": [], "entities": []}, {"text": "This maybe attributed to less effort invested on improving classifier model (using ensembles, or otherwise) or on using more robust features.", "labels": [], "entities": []}, {"text": "We also suspect that {posD, negD, neutD, cont} features maybe biased towards training data as the keyword dictionary D was generated on the full training dataset before evaluation.", "labels": [], "entities": []}, {"text": "Moreover, Method2 is tuned using training data and expected to perform weaker on unseen datasets.", "labels": [], "entities": []}, {"text": "We did further evaluation of our system after release of gold-labeled test data.", "labels": [], "entities": []}, {"text": "This was aimed at checking the effect of using sequence pattern.", "labels": [], "entities": []}, {"text": "The results are provided in.", "labels": [], "entities": []}, {"text": "The accuracy obtained against gold labels without using sequence pattern was 0.668.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 4, "end_pos": 12, "type": "METRIC", "confidence": 0.9996899366378784}]}, {"text": "By using Method1, the accuracy increased to 0.702.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 22, "end_pos": 30, "type": "METRIC", "confidence": 0.9997926354408264}]}, {"text": "With Method2, the accuracy obtained was 0.717.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 18, "end_pos": 26, "type": "METRIC", "confidence": 0.999799907207489}]}, {"text": "Also, the method has obvious caveats as mentioned above.", "labels": [], "entities": []}, {"text": "So, the usage of sequence pattern needs to be improved by more research.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Model performance on training dataset.", "labels": [], "entities": []}, {"text": " Table 2: Evaluation results. Ratio is no. of correct predic-", "labels": [], "entities": [{"text": "Ratio", "start_pos": 30, "end_pos": 35, "type": "METRIC", "confidence": 0.9901238083839417}]}, {"text": " Table 3: Comparative performance. System1: without se-", "labels": [], "entities": []}]}