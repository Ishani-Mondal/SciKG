{"title": [{"text": "I2RNTU at SemEval-2016 Task 4: Classifier Fusion for Polarity Classification in Twitter", "labels": [], "entities": [{"text": "Polarity Classification", "start_pos": 53, "end_pos": 76, "type": "TASK", "confidence": 0.6996124088764191}]}], "abstractContent": [{"text": "In this work, we apply classifier fusion to tweet polarity identification problem.", "labels": [], "entities": [{"text": "classifier fusion", "start_pos": 23, "end_pos": 40, "type": "TASK", "confidence": 0.8357223570346832}, {"text": "tweet polarity identification", "start_pos": 44, "end_pos": 73, "type": "TASK", "confidence": 0.8541576067606608}]}, {"text": "The task is to predict whether the emotion hidden in a tweet is positive, neutral, or negative.", "labels": [], "entities": []}, {"text": "An asymmetric SIMPLS (ASIMPLS) based clas-sifier, which was proved to be able to identify the minority class well in imbalanced classification problems, is implemented.", "labels": [], "entities": []}, {"text": "Word embedding is also employed as anew feature.", "labels": [], "entities": []}, {"text": "For each word, we obtain three word embedding vectors on positive, neutral, and negative tweet sets respectively.", "labels": [], "entities": []}, {"text": "These vectors are used as features in the ASIMPLS classifier.", "labels": [], "entities": []}, {"text": "Another three state-of-the-art systems are implemented also, and these four systems are fused together to further boost the performance.", "labels": [], "entities": []}, {"text": "The fusion system achieved 59.63% accuracy on the 2016 test set of SemEval2016 Task 4, Subtask A.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 34, "end_pos": 42, "type": "METRIC", "confidence": 0.9995104074478149}, {"text": "SemEval2016 Task 4", "start_pos": 67, "end_pos": 85, "type": "TASK", "confidence": 0.6243168413639069}]}], "introductionContent": [{"text": "The I2RNTU system works on the Subtask A: Message Polarity Classification in Twitter of SemEval-2016 Task 4: the Sentiment Analysis in Twitter (.", "labels": [], "entities": [{"text": "Message Polarity Classification", "start_pos": 42, "end_pos": 73, "type": "TASK", "confidence": 0.638218363126119}, {"text": "Sentiment Analysis", "start_pos": 113, "end_pos": 131, "type": "TASK", "confidence": 0.8954699635505676}]}, {"text": "The task is to predict whether a tweet is of positive, neutral, or negative sentiment.", "labels": [], "entities": []}, {"text": "This task can be formulated as a multiclass classification problem, i.e., to classify a tweet into one of the three classes.", "labels": [], "entities": [{"text": "multiclass classification", "start_pos": 33, "end_pos": 58, "type": "TASK", "confidence": 0.7098941057920456}]}, {"text": "We use the one-vs-rest strategy to solve the three-class classification problem.", "labels": [], "entities": [{"text": "three-class classification", "start_pos": 45, "end_pos": 71, "type": "TASK", "confidence": 0.7014875113964081}]}, {"text": "Given a tweet, a classifier generates three confidence scores about the tweet belonging to the three classes respectively.", "labels": [], "entities": []}, {"text": "The predicted label is chosen based on the highest confidence score.", "labels": [], "entities": []}, {"text": "Four classifiers are implemented in our work, and classifier fusion is used to improve the system performance.", "labels": [], "entities": []}, {"text": "Classifier fusion has been proved to be very powerful in classification problems.", "labels": [], "entities": [{"text": "Classifier fusion", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.9175545871257782}, {"text": "classification", "start_pos": 57, "end_pos": 71, "type": "TASK", "confidence": 0.9677020907402039}]}, {"text": "In SemEval-2015, a system named Webis won the first place in the message polarity classification subtask, which is subtask B of SemEval-2015 task 10 \"Sentiment Analysis in Twitter\").", "labels": [], "entities": [{"text": "message polarity classification", "start_pos": 65, "end_pos": 96, "type": "TASK", "confidence": 0.7995927929878235}, {"text": "Sentiment Analysis in Twitter", "start_pos": 150, "end_pos": 179, "type": "TASK", "confidence": 0.8259553909301758}]}, {"text": "The authors reproduced four state-of-the-art twitter polarity prediction algorithms.", "labels": [], "entities": [{"text": "twitter polarity prediction", "start_pos": 45, "end_pos": 72, "type": "TASK", "confidence": 0.7345829506715139}]}, {"text": "Each algorithm generates three confidence scores fora tweet.", "labels": [], "entities": []}, {"text": "The fusion system averages the scores generated by the four classifiers, and then predicts a label according to the highest average score.", "labels": [], "entities": []}, {"text": "In the Speaker State Challenge of INTER-SPEECH 2011, the method of fusing Asymmetric SIMPLS (ASIMPLS) and Support Vector Machines (SVMs) won the sleepiness sub-challenge).", "labels": [], "entities": [{"text": "Speaker State Challenge of INTER-SPEECH 2011", "start_pos": 7, "end_pos": 51, "type": "TASK", "confidence": 0.5865819255510966}]}, {"text": "The asymmetric SIMPLS based classifier is shown to be able to generate a higher prediction accuracy for the class with small number of instances in the imbalanced classification problem, while SVMs are strong at predicting the class with majority number of instances.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 91, "end_pos": 99, "type": "METRIC", "confidence": 0.9188105463981628}]}, {"text": "The fusion of these two types of methods could achieve a balance between favouring the majority class and the minority class.", "labels": [], "entities": []}, {"text": "In the Music Information Retrieval Evaluation eXchange, the method of fusing SIMPLS and SuperFlux won the 3rd place on Audio Onset Detection subtask ().", "labels": [], "entities": [{"text": "Music Information Retrieval Evaluation", "start_pos": 7, "end_pos": 45, "type": "TASK", "confidence": 0.6473599001765251}, {"text": "Audio Onset Detection", "start_pos": 119, "end_pos": 140, "type": "TASK", "confidence": 0.5314115385214487}]}, {"text": "In the Emotion Recognition in the Wild Challenge (EmotiW2014), which aims to automatically classify the emotions acted by human subjects in video clips under real-world environment, the fusion of kernel SVM, logistic regression, and partial least squares (PLS) with different Riemannian ker-nels won the first place of the competition (.", "labels": [], "entities": [{"text": "Emotion Recognition in the Wild Challenge (EmotiW2014)", "start_pos": 7, "end_pos": 61, "type": "TASK", "confidence": 0.8592416048049927}]}, {"text": "In this paper, we will take advantage of the classifier fusion again.", "labels": [], "entities": []}, {"text": "We introduce the asymmetric SIMPLS based classifier to the tweet polarity classification problem, and combine it with other three of state-of-the-art classifiers.", "labels": [], "entities": [{"text": "tweet polarity classification", "start_pos": 59, "end_pos": 88, "type": "TASK", "confidence": 0.7774982353051504}]}, {"text": "The fusion method is same with.", "labels": [], "entities": []}, {"text": "The most popular features used in the tweet polarity classification problem are derived from sentiment lexicons (.", "labels": [], "entities": [{"text": "tweet polarity classification problem", "start_pos": 38, "end_pos": 75, "type": "TASK", "confidence": 0.8879190534353256}]}, {"text": "Word embedding represents a word using a low dimensional vector which contains the syntactic and semantic meaning of the word.", "labels": [], "entities": []}, {"text": "If we can enhance the sentiment information hidden in the vector, it maybe a good feature for the task.", "labels": [], "entities": []}, {"text": "Word embedding has been used in tweet sentiment analysis in.", "labels": [], "entities": [{"text": "tweet sentiment analysis", "start_pos": 32, "end_pos": 56, "type": "TASK", "confidence": 0.8853804071744283}]}, {"text": "The authors used the vectors with dimensionality of 300 trained by word2vec, which is publicly available on-line 1 . However, the vectors are trained using Google News.", "labels": [], "entities": [{"text": "word2vec", "start_pos": 67, "end_pos": 75, "type": "DATASET", "confidence": 0.9456394910812378}]}, {"text": "No emotional info was considered during the training.", "labels": [], "entities": []}, {"text": "Also, the news articles are written informal language.", "labels": [], "entities": []}, {"text": "Many words appearing frequently in tweets such as 'goood' may not be included in the data set.", "labels": [], "entities": []}, {"text": "In this paper, we train the word embedding on downloaded tweet data sets.", "labels": [], "entities": []}, {"text": "Furthermore, we separate the tweet data set into three subsets named positive, neutral, and negative subsets respectively.", "labels": [], "entities": []}, {"text": "For each word, three vectors are obtained.", "labels": [], "entities": []}, {"text": "These vectors are used as features for the ASIMPLS classifier.", "labels": [], "entities": [{"text": "ASIMPLS classifier", "start_pos": 43, "end_pos": 61, "type": "TASK", "confidence": 0.6359623372554779}]}, {"text": "The papers of task description of SemEval () maybe the best material of understanding the related work of sentiment analysis in twitter.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 106, "end_pos": 124, "type": "TASK", "confidence": 0.9398930370807648}]}, {"text": "The classifiers used include SVM, maximum entropy, Conditional Random Fields (CRFs), deep neural networks, and linear regression etc.", "labels": [], "entities": []}, {"text": "The most popular features are derived from sentiment lexicons.", "labels": [], "entities": []}, {"text": "Bag-of-words, hashtags, and punctuations etc. are also used widely.", "labels": [], "entities": []}, {"text": "We will introduce the asymmetric SIMPLS classifier and the proposed word embedding feature in Section 2.", "labels": [], "entities": []}, {"text": "The three state-of-the-art systems and the fusion method are described in Section 3.", "labels": [], "entities": []}, {"text": "The experimental results are shown in Section 4.", "labels": [], "entities": []}, {"text": "We conclude For the bianry classification problems, K = 1.", "labels": [], "entities": [{"text": "bianry classification", "start_pos": 20, "end_pos": 41, "type": "TASK", "confidence": 0.7449302673339844}]}, {"text": "The solution is to extract the orthogonal factors of X and Y sequentially, and where In the SIMPLS algorithm, a constrain is added that the scores ti are orthogonal to each other, i.e., tb ta = 0 fora > b.", "labels": [], "entities": []}, {"text": "Also ta is normalized by ta = ta / ta * ta . Then we have T T = I where as: For anew feature matrix X * , the new projected matrix where The prediction can be written in another format: Algorithm 1 Training procedure of SIMPLS Input: Feature set X, Label y, and Number of components A Variables:Projection matrix R, score vectors T and U, loading P and , and vi into R, T, P, Q, U, and V, respectively.", "labels": [], "entities": []}, {"text": "The newt * is calculated by Algorithm 2.", "labels": [], "entities": []}, {"text": "For the classification problems, we need to predict the label of a sampl\u00ea It can be observed that the label Y is a function of the score vectors t * . If\u02c6YIf\u02c6 If\u02c6Y and t were on a plane, the boundary would be a line passes the original point (0, 0).", "labels": [], "entities": []}, {"text": "Suppose the original point is the center of the whole data set, which can be achieved by subtracting the mean of the data.", "labels": [], "entities": []}, {"text": "When the number of instances of a class is much less than the other one, the original point will be faraway from the center of the minority class, while near the center of the majority class.", "labels": [], "entities": []}, {"text": "Hence, the line will pass cross the majority class.", "labels": [], "entities": []}, {"text": "That is the reason that PLS based classifiers can detect the minority class well.", "labels": [], "entities": []}, {"text": "However, the accuracy of majority class will decrease because the line cuts the majority class into two parts.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 13, "end_pos": 21, "type": "METRIC", "confidence": 0.9996028542518616}]}, {"text": "The Asymmetric PLS classifier tries to move the line towards to the center of the minority class to make the boundary in the middle of the two classes ().", "labels": [], "entities": [{"text": "PLS classifier", "start_pos": 15, "end_pos": 29, "type": "TASK", "confidence": 0.6152999997138977}]}, {"text": "The distance moved is calculated on the first dimension of T.", "labels": [], "entities": []}, {"text": "The center points and the radii of positive and negative classes are estimated as in.", "labels": [], "entities": []}, {"text": "Let the minority class be the positive class, and index postive denotes the index of positive items in Y.", "labels": [], "entities": [{"text": "index postive", "start_pos": 50, "end_pos": 63, "type": "METRIC", "confidence": 0.9361889660358429}]}, {"text": "We use t p = t 1 [index postive].", "labels": [], "entities": []}, {"text": "Similarly, tn = t 1 [index negative].", "labels": [], "entities": []}, {"text": "The center points and the radii of the two classes are estimated by Then the distance should be moved is We move the line on the plane oft", "labels": [], "entities": []}], "datasetContent": [{"text": "Our training set is composed by the training and development set of SemEval-2013 as well as the training set of SemEval-2016.", "labels": [], "entities": [{"text": "SemEval-2013", "start_pos": 68, "end_pos": 80, "type": "DATASET", "confidence": 0.9036465883255005}, {"text": "SemEval-2016", "start_pos": 112, "end_pos": 124, "type": "DATASET", "confidence": 0.8455180525779724}]}, {"text": "The testing set includes the development-test set of 2013 and 2014, as well as the development and development-test sets of 2016.", "labels": [], "entities": []}, {"text": "The numbers of tweets in all data sets are shown in.", "labels": [], "entities": []}, {"text": "We remove the tweets that only have @somebody or hyper-links.", "labels": [], "entities": []}, {"text": "Hence, we have a total of 16682 tweets for training and 9146 tweets for testing after preprocessing.", "labels": [], "entities": []}, {"text": "In both training and testing sets, there are much less number of negative tweets comparing to positive and neutral tweets.", "labels": [], "entities": []}, {"text": "ASIMPLS may help improve the accuracy of negative tweets.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 29, "end_pos": 37, "type": "METRIC", "confidence": 0.9960837364196777}]}, {"text": "The experimental results are shown in Table 2.", "labels": [], "entities": []}, {"text": "We list all the results of individual systems and the fusion results.", "labels": [], "entities": []}, {"text": "In the table, the \"Score\" is the value obtained using the evaluation method of SemEval2016 Task 4 (.", "labels": [], "entities": [{"text": "Score", "start_pos": 19, "end_pos": 24, "type": "METRIC", "confidence": 0.9450632333755493}, {"text": "SemEval2016 Task 4", "start_pos": 79, "end_pos": 97, "type": "TASK", "confidence": 0.5724414587020874}]}, {"text": "\"Positive\" means the accuracy of positive samples in the testing, i.e. P ositive = number of correct positive samples number of all positive samples . Similarly, \"Negative\" and \"Neutral\" denote the accuracies of negative as well as neutral samples respectively.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 21, "end_pos": 29, "type": "METRIC", "confidence": 0.9993076324462891}, {"text": "P ositive", "start_pos": 71, "end_pos": 80, "type": "METRIC", "confidence": 0.7600543200969696}]}, {"text": "\"All Accuracy\" means number of all correct samples number of all testing samples . The results demonstrated that classifier fusion is able to generate better scores than individual classifiers.", "labels": [], "entities": [{"text": "All Accuracy\"", "start_pos": 1, "end_pos": 14, "type": "METRIC", "confidence": 0.8770263393719991}]}, {"text": "Fusing all systems obtained the best score 63.78.", "labels": [], "entities": []}, {"text": "It is marginally higher than the score of fusing the first three systems 63.72.", "labels": [], "entities": []}, {"text": "The score of the PLS system is worse than the other three systems.", "labels": [], "entities": [{"text": "PLS", "start_pos": 17, "end_pos": 20, "type": "TASK", "confidence": 0.7241491079330444}]}, {"text": "The reason maybe that the dimension of the features (more than 200 thousands) is even bigger than the number of training samples (about 16 thousands).", "labels": [], "entities": []}, {"text": "The ASIMPLS classifier is not good at handling this type of data even we have used 5 subsystems to alleviate the influence of high dimensional features.", "labels": [], "entities": [{"text": "ASIMPLS classifier", "start_pos": 4, "end_pos": 22, "type": "TASK", "confidence": 0.5473112761974335}]}, {"text": "Nonetheless, it obtained the highest accuracy of negative samples and the second-best accuracy of neutral samples.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 37, "end_pos": 45, "type": "METRIC", "confidence": 0.9993267059326172}, {"text": "accuracy", "start_pos": 86, "end_pos": 94, "type": "METRIC", "confidence": 0.9988956451416016}]}, {"text": "The positive accuracy is much worse than the other three classifiers.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 13, "end_pos": 21, "type": "METRIC", "confidence": 0.9251561164855957}]}, {"text": "It indicates that the bias should be further adjusted in the future.", "labels": [], "entities": [{"text": "bias", "start_pos": 22, "end_pos": 26, "type": "METRIC", "confidence": 0.9856899380683899}]}, {"text": "The results of our submission are shown in.", "labels": [], "entities": []}, {"text": "We obtained a score of 59.63 on the 2016 Tweet submission.", "labels": [], "entities": [{"text": "2016 Tweet submission", "start_pos": 36, "end_pos": 57, "type": "DATASET", "confidence": 0.6928574045499166}]}], "tableCaptions": [{"text": " Table 1: Training and testing sets.", "labels": [], "entities": []}]}