{"title": [{"text": "UW-CSE at SemEval-2016 Task 10: Detecting Multiword Expressions and Supersenses using Double-Chained Conditional Random Fields", "labels": [], "entities": [{"text": "UW-CSE", "start_pos": 0, "end_pos": 6, "type": "DATASET", "confidence": 0.9361230731010437}, {"text": "Detecting Multiword Expressions", "start_pos": 32, "end_pos": 63, "type": "TASK", "confidence": 0.8674140373865763}]}], "abstractContent": [{"text": "We describe our entry to SemEval 2016 Task 10: Detecting Minimal Semantic Units and their Meanings.", "labels": [], "entities": [{"text": "SemEval 2016 Task 10", "start_pos": 25, "end_pos": 45, "type": "TASK", "confidence": 0.8859542012214661}, {"text": "Detecting Minimal Semantic Units", "start_pos": 47, "end_pos": 79, "type": "TASK", "confidence": 0.8793506175279617}]}, {"text": "Our approach uses a discrim-inative first-order sequence model similar to Schneider and Smith (2015).", "labels": [], "entities": []}, {"text": "The chief novelty in our approach is a factorization of the labels into multiword expression and supersense labels, and restricting first-order dependencies within these two parts.", "labels": [], "entities": []}, {"text": "Our submitted models achieved first place in the closed competition (CRF) and second place in the open competition (2-CRF).", "labels": [], "entities": []}], "introductionContent": [{"text": "argued that the problems of segmenting apiece of text into minimal semantic units, and of labeling those units with semantic classes (e.g., supersenses), are intimately connected.", "labels": [], "entities": []}, {"text": "We propose to use a double-chained conditional random field (which we refer to as \"2-CRF,\" an example of a factorial CRF; \u00a73.4) for joint multiword expression identification and supersense tagging.", "labels": [], "entities": [{"text": "multiword expression identification", "start_pos": 138, "end_pos": 173, "type": "TASK", "confidence": 0.59177565574646}, {"text": "supersense tagging", "start_pos": 178, "end_pos": 196, "type": "TASK", "confidence": 0.7910736799240112}]}, {"text": "Like other CRFs, 2-CRF is a feature-rich probabilistic model that can represent probabilistic dependencies between features and labels and between the labels of the consecutive words.", "labels": [], "entities": []}, {"text": "The 2-CRF models local dependencies between MWE and supersense sequences with two parallel chains of labels, restricting direct interaction between the two to local, single-word positions.", "labels": [], "entities": []}, {"text": "Label constraints on tag bigrams ensure a globally consistent tagging.", "labels": [], "entities": []}, {"text": "Our experiments show that 2-CRF outperforms a zero-order baseline, the structured perceptron used by, and a conventional CRF ( \u00a74).", "labels": [], "entities": []}, {"text": "For SemEval 2016 Task 10: Detecting Minimal Semantic Units and their Meanings, we submitted a CRF for the closed condition and a 2-CRF (incompletely trained) for the open condition, achieving first and second place, respectively.", "labels": [], "entities": [{"text": "SemEval 2016 Task 10", "start_pos": 4, "end_pos": 24, "type": "TASK", "confidence": 0.8186636418104172}, {"text": "Detecting Minimal Semantic Units and their Meanings", "start_pos": 26, "end_pos": 77, "type": "TASK", "confidence": 0.8802465541022164}]}], "datasetContent": [{"text": "We compare the performance of the following four models that use exactly the same input features \u00a73.1: \u2022 Multinomial logistic regression (MLR) as described in \u00a73.2 (a zero-order model) \u2022 Structured perceptron as used by with the same set of features (first-order, similar to our CRF) \u2022 CRF as described in \u00a73.3 \u2022 Double-chained CRF as described in \u00a73.4 We used the AMALGrAM 9 code base for feature extraction (.", "labels": [], "entities": [{"text": "AMALGrAM 9 code base", "start_pos": 365, "end_pos": 385, "type": "DATASET", "confidence": 0.8743269741535187}, {"text": "feature extraction", "start_pos": 390, "end_pos": 408, "type": "TASK", "confidence": 0.696132704615593}]}, {"text": "For hyperparameter tuning, we holdout 30% randomly selected training samples of the DiMSUM dataset as validation data.", "labels": [], "entities": [{"text": "hyperparameter tuning", "start_pos": 4, "end_pos": 25, "type": "TASK", "confidence": 0.8525364398956299}, {"text": "DiMSUM dataset", "start_pos": 84, "end_pos": 98, "type": "DATASET", "confidence": 0.9053999185562134}]}, {"text": "Using preliminary experiments on validation data, we set the number of L-BFGS iterations for multinomial logistic regression, CRF, and 2-CRF as 100, 120, and 120, respectively.", "labels": [], "entities": []}, {"text": "We set the number of iterations of averaged perceptron algorithm for structured percetpron as 10.", "labels": [], "entities": []}, {"text": "We also impose a percept cutoff of 3 on the minimum number of occurrences fora zero-order percept to be considered in the models.", "labels": [], "entities": []}, {"text": "We use validation data to tune \u03b1 1 and \u03b1 2 (where applicable) hyperparameters.", "labels": [], "entities": []}, {"text": "After tuning the parameters, we use the whole DiMSUM training dataset to train the models.", "labels": [], "entities": [{"text": "DiMSUM training dataset", "start_pos": 46, "end_pos": 69, "type": "DATASET", "confidence": 0.7644580801328024}]}, {"text": "show the results for the closed and open conditions.", "labels": [], "entities": []}, {"text": "The selected hyperparameters \u03b1 1 and \u03b1 2 are shown for each model.", "labels": [], "entities": []}, {"text": "In each table, we An open source efficient cython implementation of our method will be made publicly available at: https:// github.com/mjhosseini/2-CRF-MWE.", "labels": [], "entities": []}, {"text": "show the results on our held-out validation data and on the DiMSUM test datasets.", "labels": [], "entities": [{"text": "DiMSUM test datasets", "start_pos": 60, "end_pos": 80, "type": "DATASET", "confidence": 0.9325273831685384}]}, {"text": "The official submitted systems are marked with * in the tables.", "labels": [], "entities": []}, {"text": "For the closed condition, the 2-CRF had not completed training, so our entry was the CRF; it achieved first place.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Closed condition: Results on validation (left) and DiMSUM data (right) for multinomial logistic regression  (MLR), structured perceptron (SP), CRF, and 2-CRF models. The hyperparameters and F 1 scores for identifying  MWEs, supersenses, and their combination are reported. The best result in each column is bolded. The results that  are significant over SP (p-value < 0.05) are italicized. The system denoted by  *  is our official submission for the  supervised closed condition.", "labels": [], "entities": [{"text": "F 1 scores", "start_pos": 200, "end_pos": 210, "type": "METRIC", "confidence": 0.9684871037801107}]}]}