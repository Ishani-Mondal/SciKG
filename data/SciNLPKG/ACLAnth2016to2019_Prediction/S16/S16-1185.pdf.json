{"title": [{"text": "CU-NLP at SemEval-2016 Task 8: AMR Parsing using LSTM-based Recurrent Neural Networks", "labels": [], "entities": [{"text": "SemEval-2016 Task 8", "start_pos": 10, "end_pos": 29, "type": "TASK", "confidence": 0.5906179348627726}, {"text": "AMR Parsing", "start_pos": 31, "end_pos": 42, "type": "TASK", "confidence": 0.8938818573951721}]}], "abstractContent": [{"text": "We describe the system used in our participation in the AMR Parsing task for SemEval-2016.", "labels": [], "entities": [{"text": "AMR Parsing task for SemEval-2016", "start_pos": 56, "end_pos": 89, "type": "TASK", "confidence": 0.6463792562484741}]}, {"text": "Our parser does not rely on a syntactic pre-parse, or heavily engineered features, and uses five recurrent neural networks as the key architectural components for estimating AMR graph structure.", "labels": [], "entities": [{"text": "estimating AMR graph structure", "start_pos": 163, "end_pos": 193, "type": "TASK", "confidence": 0.7298865467309952}]}], "introductionContent": [{"text": "Abstract Meaning Representation, or AMR () is a graph-based representation of the meaning of sentences which incorporates linguistic phenomena such as semantic roles, coreference, negation, and more.", "labels": [], "entities": [{"text": "Abstract Meaning Representation", "start_pos": 0, "end_pos": 31, "type": "TASK", "confidence": 0.7245218853155772}]}, {"text": "The process of creating AMR's for sentences is called AMR Parsing.", "labels": [], "entities": [{"text": "AMR Parsing", "start_pos": 54, "end_pos": 65, "type": "TASK", "confidence": 0.7015170753002167}]}, {"text": "We used an early version of the system described in this paper to generate our submission to the Semeval-2016 Meaning Representation Parsing Task.", "labels": [], "entities": [{"text": "Semeval-2016 Meaning Representation Parsing Task", "start_pos": 97, "end_pos": 145, "type": "TASK", "confidence": 0.8108035981655121}]}, {"text": "The details of our system will be explained using this example sentence: France plans further nuclear cooperation with numerous countries . A graphical depiction is shown in.", "labels": [], "entities": []}, {"text": "The system extracts features from the sentence which are processed by a form of recurrent neural network called BDLSTM to create a set of AMR concepts.", "labels": [], "entities": []}, {"text": "Features from these concepts are processed by a pair of BDLSTM networks to compute relation probabilities.", "labels": [], "entities": []}, {"text": "All concepts are then connected using an iterative, greedy algorithm to compute the set of relations in the AMR.", "labels": [], "entities": [{"text": "AMR", "start_pos": 108, "end_pos": 111, "type": "DATASET", "confidence": 0.8805237412452698}]}, {"text": "Another two 1 http://amr.isi.edu/language.html 2 http://alt.qcri.org/semeval2016/task8/# BDLSTM networks compute attribute and name categories to complete the estimation of AMR element probabilities.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: L0 Network Example Output", "labels": [], "entities": []}, {"text": " Table 2: Smatch F1 results for Test and Eval Datasets", "labels": [], "entities": [{"text": "Smatch F1", "start_pos": 10, "end_pos": 19, "type": "TASK", "confidence": 0.6362822949886322}, {"text": "Eval Datasets", "start_pos": 41, "end_pos": 54, "type": "DATASET", "confidence": 0.7793219983577728}]}]}