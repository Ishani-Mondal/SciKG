{"title": [{"text": "Amrita CEN at SemEval-2016 Task 1: Semantic Relation from Word Embeddings in Higher Dimension", "labels": [], "entities": [{"text": "Amrita CEN", "start_pos": 0, "end_pos": 10, "type": "DATASET", "confidence": 0.5902632772922516}, {"text": "Semantic Relation from Word Embeddings in Higher Dimension", "start_pos": 35, "end_pos": 93, "type": "TASK", "confidence": 0.7983253225684166}]}], "abstractContent": [{"text": "Semantic Textual Similarity measures similarity between pair of texts, even though the similar context is projected using different words.", "labels": [], "entities": [{"text": "Semantic Textual Similarity", "start_pos": 0, "end_pos": 27, "type": "TASK", "confidence": 0.7639205654462179}]}, {"text": "This work attempted to incorporate the context space of the sentence from that sentence alone.", "labels": [], "entities": []}, {"text": "It proposes combination of Word2Vec and Non-Negative Matrix Factorization to represent the sentence as context embedding vector in context space.", "labels": [], "entities": []}, {"text": "Distance and correlation values between context embedding vector pairs used as a features for Support Vector Regression to built the domain independent similarity measuring model.", "labels": [], "entities": [{"text": "Distance", "start_pos": 0, "end_pos": 8, "type": "METRIC", "confidence": 0.9241708517074585}, {"text": "Support Vector Regression", "start_pos": 94, "end_pos": 119, "type": "TASK", "confidence": 0.6464520593484243}, {"text": "domain independent similarity measuring", "start_pos": 133, "end_pos": 172, "type": "TASK", "confidence": 0.5781892314553261}]}, {"text": "The proposed model yielding performance 0.41 in terms of correlation .", "labels": [], "entities": [{"text": "correlation", "start_pos": 57, "end_pos": 68, "type": "METRIC", "confidence": 0.9789460301399231}]}], "introductionContent": [{"text": "Semantic Textual Similarity (STS) assess the degree to which two snippets of text mean the same thing ().", "labels": [], "entities": [{"text": "Semantic Textual Similarity (STS", "start_pos": 0, "end_pos": 32, "type": "TASK", "confidence": 0.7260041236877441}]}, {"text": "The modules developed for successful STS systems have abroad range of potential applications including: Discourse Analysis, Information Retrieval, Machine Reading, Machine Translation, Question Answering, Text Summarization and Plagiarism Detection.", "labels": [], "entities": [{"text": "Discourse Analysis", "start_pos": 104, "end_pos": 122, "type": "TASK", "confidence": 0.8739906251430511}, {"text": "Information Retrieval", "start_pos": 124, "end_pos": 145, "type": "TASK", "confidence": 0.8428643643856049}, {"text": "Machine Reading", "start_pos": 147, "end_pos": 162, "type": "TASK", "confidence": 0.868172824382782}, {"text": "Machine Translation", "start_pos": 164, "end_pos": 183, "type": "TASK", "confidence": 0.8735872507095337}, {"text": "Question Answering", "start_pos": 185, "end_pos": 203, "type": "TASK", "confidence": 0.856334775686264}, {"text": "Text Summarization", "start_pos": 205, "end_pos": 223, "type": "TASK", "confidence": 0.8277045786380768}, {"text": "Plagiarism Detection", "start_pos": 228, "end_pos": 248, "type": "TASK", "confidence": 0.7103818506002426}]}, {"text": "Degree of dependence between sentences vary even-though there exist similar words present in them (Example 1) whereas the dependence remains unchanged when the context is being projected with different words (Example 2).", "labels": [], "entities": []}, {"text": "For instance, S1 : Boy chases the cat.", "labels": [], "entities": []}, {"text": "S2 : Cat chases the boy.", "labels": [], "entities": []}, {"text": "Example 1 S1 : The rat jumps inside the tub.", "labels": [], "entities": []}, {"text": "S2 : Mouse dives into the vessel.", "labels": [], "entities": []}, {"text": "Example 2 From the above example, representing sentence as context dependent vector in a context space is more informative than the traditional frequency based representation methods.", "labels": [], "entities": []}, {"text": "Thus by considering this, the proposed approach measures the similarity between the sentences as prescribed in STS task, which is given in the.", "labels": [], "entities": []}, {"text": "From the it is clear that simple frequency based representation will fail to achieve the objective.", "labels": [], "entities": []}, {"text": "Our approach proposes measuring similarity based on contextual information provided by the other words in the sentences instead of measuring similarity using just the words.", "labels": [], "entities": []}, {"text": "Words tends to have different meaning with respect to their appearance with context.", "labels": [], "entities": []}, {"text": "In this proposed approach, sentence embedding will be found from word embedding in which words are represented as word embedding vectors with respect to context they occurs.", "labels": [], "entities": []}, {"text": "Thereafter the similarity measure is done by finding correlation of the features in the sentence embedding.", "labels": [], "entities": [{"text": "similarity measure", "start_pos": 15, "end_pos": 33, "type": "METRIC", "confidence": 0.9420655071735382}]}, {"text": "Remaining paper details about the related works done on STS in section 2, detailed mathematical explanation is given in section 3 and statistics about the data-set, experiment and observations are explained in section 4.", "labels": [], "entities": [{"text": "STS", "start_pos": 56, "end_pos": 59, "type": "TASK", "confidence": 0.9071045517921448}]}], "datasetContent": [{"text": "The Model diagram of the conducted experiment is given in.", "labels": [], "entities": []}, {"text": "Statistics about the data-set are given in.", "labels": [], "entities": []}, {"text": "Given data-set includes wide varieties of sentences in varying length and representation.", "labels": [], "entities": []}, {"text": "This work is focused on building a unified model irrespective of domain.", "labels": [], "entities": []}, {"text": "The training corpus for similarity measure involves shuffled sentence pairs from all the domains (i.e. single model for measuring similarity for Plagiarism, Answer-Answer, Post-editing, Headlines and Question-Question corpus).", "labels": [], "entities": []}, {"text": "To build the word embedding model, we use a snapshot of the articles in the English Wikipedia (articles) has been utilized.", "labels": [], "entities": []}, {"text": "After removing XML tags, special characters and unwanted spaces the corpus (size:12 GB) is fed to the Continuous Bag of Words (CBOW) model for processing.", "labels": [], "entities": []}, {"text": "Window size, minimum occurrence and vector dimension are assigned as 5, 4, 400 respectively to create word embedding model (size:2.6 GB) using the Gensim package.", "labels": [], "entities": [{"text": "Gensim package", "start_pos": 147, "end_pos": 161, "type": "DATASET", "confidence": 0.847775787115097}]}, {"text": "The sentence pairs were fed to the word embedding model to represent the words in a sentence as vector of dimension 400.", "labels": [], "entities": []}, {"text": "Word vectors in a sentence are concatenated to form a matrix (Context Matrix).", "labels": [], "entities": []}, {"text": "Before concatenation the vectors are normalized (unity-based normalization) between 0 and 1, which forms dense positive vectors that are appropriate for further factorization.", "labels": [], "entities": []}, {"text": "This is given by, By equating the reduction rank to be one (r=1) the  Once the context embedding pairs are found, they are fed to the feature function to measure the distance and correlation between them.", "labels": [], "entities": []}, {"text": "These are used as attributes to train the SVR.", "labels": [], "entities": [{"text": "SVR", "start_pos": 42, "end_pos": 45, "type": "DATASET", "confidence": 0.9149100184440613}]}, {"text": "SVR has been trained using Python Scikit-learn 8 . Radial Basis Function (RBF) kernel used for the non-linearity learning.", "labels": [], "entities": [{"text": "SVR", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.7949185967445374}, {"text": "Radial Basis Function (RBF)", "start_pos": 51, "end_pos": 78, "type": "METRIC", "confidence": 0.7138850092887878}]}, {"text": "The typical C = 1.0 and gamma = 1/length(training set) parameters are used in SVR.", "labels": [], "entities": [{"text": "gamma = 1/length", "start_pos": 24, "end_pos": 40, "type": "METRIC", "confidence": 0.8790877103805542}]}, {"text": "While training, the performance of the system is measured by 10-cross validation.", "labels": [], "entities": []}, {"text": "Correlation coefficient between gold-standard and predicted vector are computed to validate the significance of the system.", "labels": [], "entities": []}, {"text": "The average correlation value obtained out of 10-cross validation during the training phase is 0.4178.", "labels": [], "entities": [{"text": "correlation", "start_pos": 12, "end_pos": 23, "type": "METRIC", "confidence": 0.9786967039108276}]}, {"text": "Our final system was trained on entire training corpus (9183 pairs) and then submitted to the STS shared task for evaluation.", "labels": [], "entities": []}, {"text": "The official evaluation results are reported in.", "labels": [], "entities": []}, {"text": "Our model performed poorly on the Question-Question data, but performed better on all the others.", "labels": [], "entities": [{"text": "Question-Question data", "start_pos": 34, "end_pos": 56, "type": "DATASET", "confidence": 0.7485708892345428}]}, {"text": "The model did best on the Plagiarism and Post-editing pairs.", "labels": [], "entities": []}, {"text": "The average score of the system is 0.4090, which is almost equal to the training accuracy (0.4178).", "labels": [], "entities": [{"text": "training", "start_pos": 72, "end_pos": 80, "type": "METRIC", "confidence": 0.9339638948440552}, {"text": "accuracy", "start_pos": 81, "end_pos": 89, "type": "METRIC", "confidence": 0.7217966318130493}]}], "tableCaptions": [{"text": " Table 1: STS Score Level for Similarity", "labels": [], "entities": [{"text": "STS Score Level", "start_pos": 10, "end_pos": 25, "type": "METRIC", "confidence": 0.9585832953453064}, {"text": "Similarity", "start_pos": 30, "end_pos": 40, "type": "TASK", "confidence": 0.9058501124382019}]}, {"text": " Table 3: Data-set Statistics and System Performance in terms of correlation", "labels": [], "entities": []}]}