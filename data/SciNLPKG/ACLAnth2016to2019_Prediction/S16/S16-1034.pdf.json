{"title": [{"text": "IIP at SemEval-2016 Task 4: Prioritizing Classes in Ensemble Classification for Sentiment Analysis of Tweets", "labels": [], "entities": [{"text": "Sentiment Analysis of Tweets", "start_pos": 80, "end_pos": 108, "type": "TASK", "confidence": 0.929784283041954}]}], "abstractContent": [{"text": "This paper describes the submission of team IIP in SemEval-2016 Task 4 Subtask A. The presented system is a novel weighted sum ensemble approach for sentiment analysis of short informal texts.", "labels": [], "entities": [{"text": "SemEval-2016 Task 4 Subtask", "start_pos": 51, "end_pos": 78, "type": "TASK", "confidence": 0.752964973449707}, {"text": "sentiment analysis of short informal texts", "start_pos": 149, "end_pos": 191, "type": "TASK", "confidence": 0.9336174031098684}]}, {"text": "The ensemble combines member classifiers that output classification confidence metrics.", "labels": [], "entities": []}, {"text": "For the ensemble classification decision the members are combined by weights.", "labels": [], "entities": [{"text": "ensemble classification", "start_pos": 8, "end_pos": 31, "type": "TASK", "confidence": 0.7922832071781158}]}, {"text": "In the presented approach the weights are derived to prioritize specific classes in multi-class classification.", "labels": [], "entities": [{"text": "multi-class classification", "start_pos": 84, "end_pos": 110, "type": "TASK", "confidence": 0.6726634204387665}]}, {"text": "The presented results confirm that this improves results for the prioritized classes.", "labels": [], "entities": []}, {"text": "The official task submission achieved a macro-averaged negative positive F1 of 57.4%.", "labels": [], "entities": [{"text": "macro-averaged negative positive F1", "start_pos": 40, "end_pos": 75, "type": "METRIC", "confidence": 0.7401903718709946}]}, {"text": "Post submission changes resulted in a F1 score of 60.2%.", "labels": [], "entities": [{"text": "F1 score", "start_pos": 38, "end_pos": 46, "type": "METRIC", "confidence": 0.9864634275436401}]}, {"text": "The evaluation also shows that the system out-performs other ensemble methods.", "labels": [], "entities": []}], "introductionContent": [{"text": "The SemEval workshops offer the opportunity to compete across a variety of natural language processing tasks.", "labels": [], "entities": []}, {"text": "The SemEval-2016 Task 4 Subtask A targets message polarity classification of tweets ().", "labels": [], "entities": [{"text": "SemEval-2016 Task 4 Subtask", "start_pos": 4, "end_pos": 31, "type": "TASK", "confidence": 0.714014083147049}, {"text": "message polarity classification", "start_pos": 42, "end_pos": 73, "type": "TASK", "confidence": 0.7828647394975027}]}, {"text": "The polarity can be negative, neutral or positive while the submissions are ranked omitting performance on the neutral class.", "labels": [], "entities": []}, {"text": "In practical use cases some classes of a multiclassification problem might be deemed more important than others.", "labels": [], "entities": []}, {"text": "For example some work looks explicitly at negative sentiment.", "labels": [], "entities": []}, {"text": "Combining diverse methods has shown success in sentiment analysis.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 47, "end_pos": 65, "type": "TASK", "confidence": 0.9763809740543365}]}, {"text": "The combination of machine learners and opinion lexicons has resulted in some of the best submissions in previous SemEval competitions ().", "labels": [], "entities": [{"text": "SemEval competitions", "start_pos": 114, "end_pos": 134, "type": "TASK", "confidence": 0.8996410667896271}]}, {"text": "Along the line of combining different methods, ensemble approaches have also shown top results in previous runs of this task.", "labels": [], "entities": []}, {"text": "Both ensembles of a small number of sophisticated systems) as well as large numbers of simpler approaches have been evaluated.", "labels": [], "entities": []}, {"text": "Ensemble classification with regard to combining different machine learners and feature spaces has previously been evaluated extensively for document level sentiment classification).", "labels": [], "entities": [{"text": "Ensemble classification", "start_pos": 0, "end_pos": 23, "type": "TASK", "confidence": 0.7978824079036713}, {"text": "document level sentiment classification", "start_pos": 141, "end_pos": 180, "type": "TASK", "confidence": 0.7284207046031952}]}, {"text": "In that context, weighted sum ensemble methods have shown the best performance.", "labels": [], "entities": []}, {"text": "This paper describes a weighted sum ensemble that prioritizes some classes in multi-class classification.", "labels": [], "entities": [{"text": "multi-class classification", "start_pos": 78, "end_pos": 104, "type": "TASK", "confidence": 0.6776546537876129}]}, {"text": "Results compare the system against two baselines.", "labels": [], "entities": []}, {"text": "One baseline is the equivalent approach without prioritizing classes, while the other is an unweighted combination of ensemble members.", "labels": [], "entities": []}, {"text": "Naive Bayes and logistic regression classifiers are explored as members across a variety of feature spaces.", "labels": [], "entities": []}, {"text": "These classifiers are know to perform differently ().", "labels": [], "entities": []}, {"text": "The presented results show: 1.", "labels": [], "entities": []}, {"text": "The presented approach successfully prioritizes classes in a multi-class classification problem.", "labels": [], "entities": []}, {"text": "2. The ensemble method outperforms individual members and the baseline ensembles.", "labels": [], "entities": []}, {"text": "The system description will start by a brief outline of the evaluation data.", "labels": [], "entities": []}, {"text": "Then the ensemble members are described before the ensemble method is detailed.", "labels": [], "entities": []}, {"text": "Finally, the results on all SemEval test sets allow an assessment of the approach and future work.", "labels": [], "entities": [{"text": "SemEval test sets", "start_pos": 28, "end_pos": 45, "type": "DATASET", "confidence": 0.833936333656311}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: SemEval data subsets as well as the full 2016 training", "labels": [], "entities": [{"text": "SemEval", "start_pos": 10, "end_pos": 17, "type": "TASK", "confidence": 0.9529411196708679}]}, {"text": " Table 2: Macro-averaged positive negative F1 [%] for all test data sets across three ensemble methods and three member sets. Set", "labels": [], "entities": [{"text": "Macro-averaged positive negative F1", "start_pos": 10, "end_pos": 45, "type": "METRIC", "confidence": 0.6518690958619118}]}]}