{"title": [{"text": "CU-GWU Perspective at SemEval-2016 Task 6: Ideological Stance Detection in Informal Text", "labels": [], "entities": [{"text": "CU-GWU", "start_pos": 0, "end_pos": 6, "type": "DATASET", "confidence": 0.8789255619049072}, {"text": "Ideological Stance Detection", "start_pos": 43, "end_pos": 71, "type": "TASK", "confidence": 0.9442739884058634}]}], "abstractContent": [{"text": "We present a supervised system that uses lexical , sentiment, semantic dictionaries and latent and frame semantic features to identify the stance of a tweeter towards an ideological target.", "labels": [], "entities": []}, {"text": "We evaluate the performance of the proposed system on subtask A in SemEval-2016 Task 6: \"Detecting Stance in Tweets\".", "labels": [], "entities": [{"text": "Detecting Stance in Tweets", "start_pos": 89, "end_pos": 115, "type": "TASK", "confidence": 0.9083816111087799}]}, {"text": "The system yields an average F \u03b2=1 score of 63.6% on the task's test set and has been ranked the 6 th by the task organizers out of 19 judged systems.", "labels": [], "entities": [{"text": "F \u03b2=1 score", "start_pos": 29, "end_pos": 40, "type": "METRIC", "confidence": 0.9801576972007752}]}], "introductionContent": [], "datasetContent": [{"text": "For tuning, we split the training data for each target into two subsets: 90% training and 10% development.", "labels": [], "entities": [{"text": "tuning", "start_pos": 4, "end_pos": 10, "type": "TASK", "confidence": 0.9653571248054504}]}, {"text": "We evaluate different configurations of the proposed features on the development set and apply the ones that yield best tuning results to the held-out test set.", "labels": [], "entities": []}, {"text": "Specifically we experiment with the following configurations: (1) Lexical Features (n-grams), (2) WTMF, (3) Sentiment, (4) Frames, (5) LIWC, (6) All Semantic features, (7) All features.", "labels": [], "entities": []}, {"text": "We compare the proposed approach against a majority baseline which assigns all tweets to the most frequent class in the data (\"Against\").", "labels": [], "entities": []}, {"text": "shows the results on the development set.", "labels": [], "entities": []}, {"text": "Ngrams outperform using any of the semantic features separately which is quite expected given how well n-grams generally perform on text classification tasks.", "labels": [], "entities": [{"text": "text classification tasks", "start_pos": 132, "end_pos": 157, "type": "TASK", "confidence": 0.8172669212023417}]}, {"text": "Moreover WTMF outperforms all other semantic features except on \"Climate Change\" dataset.", "labels": [], "entities": [{"text": "WTMF", "start_pos": 9, "end_pos": 13, "type": "DATASET", "confidence": 0.4827226400375366}, {"text": "Climate Change\" dataset", "start_pos": 65, "end_pos": 88, "type": "DATASET", "confidence": 0.6262017264962196}]}, {"text": "Overall we find \"Climate Change\" to show different trends and a much lower performance than those of the other four targets.", "labels": [], "entities": []}, {"text": "We believe that this is at-tributed to the small size of this set and to its very skewed distribution.", "labels": [], "entities": []}, {"text": "Only 3.8% of its tweets belong to \"against\" class which is the most frequent class in the whole dataset.", "labels": [], "entities": []}, {"text": "Combining all semantic features yields better results than using any of them separately for three out of the five targets \"Abortion\", \"Climate Change\" and \"Feminist Movement\" while for the other two targets using WTMF only outperforms using the full set of semantic features.", "labels": [], "entities": [{"text": "WTMF", "start_pos": 213, "end_pos": 217, "type": "DATASET", "confidence": 0.88801509141922}]}, {"text": "For the same two targets -\"Atheism\" and \"Hillary Clinton\"-using only n-grams outperforms combing n-grams with all-semantic features.", "labels": [], "entities": []}, {"text": "Overall, combining lexical and semantic features yields the best results on the majority of tweets.", "labels": [], "entities": []}, {"text": "Accordingly we used this setup in our official task submission.", "labels": [], "entities": []}, {"text": "We apply the top four development-set configurations -\"n-grams\", \"WTMF\", \"all semantic\" and \"all features\"-to the test set.", "labels": [], "entities": []}, {"text": "shows the held-out test results.", "labels": [], "entities": []}, {"text": "While using the combination of lexical and all-semantic features yields best overall performance, using only the semantics features achieves close to best results.", "labels": [], "entities": []}, {"text": "Additionally, using only WTMF yields best performance on two targets -\"Atheism\" and \"Climate Change\".", "labels": [], "entities": [{"text": "WTMF", "start_pos": 25, "end_pos": 29, "type": "DATASET", "confidence": 0.7464978098869324}]}, {"text": "We also find that while the best configuration for each target varies across the development and test sets, the best overall configuration for the majority of tweets remains the same.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Number of tweets per class in the training and test data.", "labels": [], "entities": []}, {"text": " Table 2: Coverage of the used LIWC categories on the training and test sets of each target/domain", "labels": [], "entities": []}, {"text": " Table 3: Development Set Results (measured in average F \u03b2=1 score of \"Favor\" and \"Against\" classes)", "labels": [], "entities": [{"text": "F \u03b2", "start_pos": 55, "end_pos": 58, "type": "METRIC", "confidence": 0.9649099111557007}, {"text": "Favor", "start_pos": 71, "end_pos": 76, "type": "METRIC", "confidence": 0.9602159857749939}]}, {"text": " Table 4: Held-Out Test Set Results (measured in average F \u03b2=1 score of \"Favor\" and \"Against\" classes)", "labels": [], "entities": [{"text": "F \u03b2", "start_pos": 57, "end_pos": 60, "type": "METRIC", "confidence": 0.9748924970626831}, {"text": "Favor", "start_pos": 73, "end_pos": 78, "type": "METRIC", "confidence": 0.970658004283905}]}]}