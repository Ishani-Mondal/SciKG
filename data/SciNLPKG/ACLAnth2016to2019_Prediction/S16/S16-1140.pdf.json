{"title": [{"text": "Rule-Based MWE Identification and Predominant-Supersense Tagging", "labels": [], "entities": [{"text": "MWE Identification", "start_pos": 11, "end_pos": 29, "type": "TASK", "confidence": 0.7175526022911072}, {"text": "Predominant-Supersense Tagging", "start_pos": 34, "end_pos": 64, "type": "TASK", "confidence": 0.7443030178546906}]}], "abstractContent": [{"text": "This paper presents our approach towards the SemEval-2016 Task 10-Detecting Minimal Semantic Units and their Meanings.", "labels": [], "entities": [{"text": "SemEval-2016 Task 10-Detecting Minimal Semantic Units and their Meanings", "start_pos": 45, "end_pos": 117, "type": "TASK", "confidence": 0.8802915215492249}]}, {"text": "Systems are expected to provide a representation of lexical semantics by (1) segmenting tokens into words and multiword units and (2) providing a supersense tag for segments that function as nouns or verbs.", "labels": [], "entities": []}, {"text": "Our pipeline rule-based system uses no external resources and was implemented using the mwetoolkit.", "labels": [], "entities": []}, {"text": "First, we extract and filter known MWEs from the training corpus.", "labels": [], "entities": []}, {"text": "Second, we group input tokens of the test corpus based on this lexicon, with special treatment for non-contiguous expressions.", "labels": [], "entities": []}, {"text": "Third, we use an MWE-aware predominant-sense heuristic for supersense tagging.", "labels": [], "entities": [{"text": "supersense tagging", "start_pos": 59, "end_pos": 77, "type": "TASK", "confidence": 0.7756321728229523}]}, {"text": "We obtain an F-score of 51.48% for MWE identification and 49.98% for supersense tagging.", "labels": [], "entities": [{"text": "F-score", "start_pos": 13, "end_pos": 20, "type": "METRIC", "confidence": 0.9995007514953613}, {"text": "MWE identification", "start_pos": 35, "end_pos": 53, "type": "TASK", "confidence": 0.9605942964553833}, {"text": "supersense tagging", "start_pos": 69, "end_pos": 87, "type": "TASK", "confidence": 0.6396022439002991}]}], "introductionContent": [{"text": "Accurate segmentation and semantic disambiguation of minimal text units is a major challenge in the general pipeline of NLP applications.", "labels": [], "entities": [{"text": "semantic disambiguation of minimal text units", "start_pos": 26, "end_pos": 71, "type": "TASK", "confidence": 0.7932020624478658}]}, {"text": "A machine translation system, for example, needs to decide what is the intended meaning fora given word or phrase in its context, so that it may translate it into an equivalent meaning in the target language.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 2, "end_pos": 21, "type": "TASK", "confidence": 0.7207107245922089}]}, {"text": "While determining the meaning of single words is a difficult task on its own, the problem is compounded by the pervasiveness of Multiword Expressions (MWEs).", "labels": [], "entities": [{"text": "determining the meaning of single words", "start_pos": 6, "end_pos": 45, "type": "TASK", "confidence": 0.783390998840332}]}, {"text": "MWEs are semantic units that span over multiple lexemes in the text (e.g. dry run, lookup, fall flat).", "labels": [], "entities": []}, {"text": "Their meaning cannot be inferred by applying regular composition rules on the meanings of their component words.", "labels": [], "entities": []}, {"text": "The task of semantic tagging is thus deeply intertwined with the identification of multiword expressions.", "labels": [], "entities": [{"text": "semantic tagging", "start_pos": 12, "end_pos": 28, "type": "TASK", "confidence": 0.7337116301059723}]}, {"text": "This paper presents our solution to the DiMSUM shared task (, where the evaluated systems are expected to perform both semantic tagging and multiword identification.", "labels": [], "entities": [{"text": "DiMSUM shared task", "start_pos": 40, "end_pos": 58, "type": "TASK", "confidence": 0.802116592725118}, {"text": "semantic tagging", "start_pos": 119, "end_pos": 135, "type": "TASK", "confidence": 0.6893844604492188}, {"text": "multiword identification", "start_pos": 140, "end_pos": 164, "type": "TASK", "confidence": 0.7773856520652771}]}, {"text": "Our pipeline system first detects and groups MWEs and then assigns supersense tags, as two consecutive steps.", "labels": [], "entities": []}, {"text": "For MWE identification, we use a task-specific instantiation of the mwetoolkit, handling both contiguous and non-contiguous MWEs with some degree of customization (.", "labels": [], "entities": [{"text": "MWE identification", "start_pos": 4, "end_pos": 22, "type": "TASK", "confidence": 0.9814884960651398}]}, {"text": "Additionally, MWE type-level candidates are extracted without losing track of their tokenlevel occurrences, to guarantee that all the MWE occurrences learned from the training data are projected onto the test corpus.", "labels": [], "entities": [{"text": "MWE type-level", "start_pos": 14, "end_pos": 28, "type": "TASK", "confidence": 0.85346719622612}]}, {"text": "For semantic tagging we adopted a predominant-sense heuristic.", "labels": [], "entities": [{"text": "semantic tagging", "start_pos": 4, "end_pos": 20, "type": "TASK", "confidence": 0.8547775447368622}]}, {"text": "In the remainder of this paper, we present related work ( \u00a7 2), then we present and discuss the results of the MWE identification subsystem ( \u00a7 3) and of the supersense tagging subsystem ( \u00a7 4).", "labels": [], "entities": [{"text": "MWE identification", "start_pos": 111, "end_pos": 129, "type": "TASK", "confidence": 0.9003536105155945}, {"text": "supersense tagging", "start_pos": 158, "end_pos": 176, "type": "TASK", "confidence": 0.6959883272647858}]}, {"text": "We then conclude and share ideas for future improvements ( \u00a7 5).", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Precision and coverage per MWE annotation. Cover-", "labels": [], "entities": [{"text": "Precision", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9963222742080688}, {"text": "coverage", "start_pos": 24, "end_pos": 32, "type": "METRIC", "confidence": 0.9973989725112915}, {"text": "Cover", "start_pos": 53, "end_pos": 58, "type": "METRIC", "confidence": 0.9614154100418091}]}, {"text": " Table 2: MWE identification results on test set per POS-tag.", "labels": [], "entities": [{"text": "MWE identification", "start_pos": 10, "end_pos": 28, "type": "TASK", "confidence": 0.9539099335670471}]}, {"text": " Table 3: Confusion matrix for noun supersense tagging. Skipped segments are those absent in training data.", "labels": [], "entities": [{"text": "noun supersense tagging", "start_pos": 31, "end_pos": 54, "type": "TASK", "confidence": 0.8356284896532694}]}, {"text": " Table 4: Confusion matrix for verb supersense tagging. Skipped segments are those absent in training data.", "labels": [], "entities": [{"text": "verb supersense tagging", "start_pos": 31, "end_pos": 54, "type": "TASK", "confidence": 0.7630522350470225}]}]}