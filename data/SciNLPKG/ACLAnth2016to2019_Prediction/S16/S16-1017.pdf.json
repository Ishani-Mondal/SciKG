{"title": [{"text": "Aicyber at SemEval-2016 Task 4: i-vector based sentence representation", "labels": [], "entities": []}], "abstractContent": [{"text": "This paper introduces aicyber's systems for SemEval 2016 , Task 4A.", "labels": [], "entities": [{"text": "SemEval 2016", "start_pos": 44, "end_pos": 56, "type": "TASK", "confidence": 0.8346104025840759}]}, {"text": "The first system is build on vector space model (VSM), the second system is build on anew framework to estimate sentence vector, it is inspired by the i-vector in speaker verification domain.", "labels": [], "entities": []}, {"text": "Both systems are evaluated on SemEval 2016 (Task4A) as well as IMDB dataset.", "labels": [], "entities": [{"text": "SemEval 2016 (Task4A)", "start_pos": 30, "end_pos": 51, "type": "DATASET", "confidence": 0.7988209903240204}, {"text": "IMDB dataset", "start_pos": 63, "end_pos": 75, "type": "DATASET", "confidence": 0.9771724045276642}]}, {"text": "Evaluation results show that the i-vector based sentence vector is an alternative approach to present sentence.", "labels": [], "entities": []}], "introductionContent": [{"text": "The SemEval 2016 Task 4 is sentiment analysis in tweets.", "labels": [], "entities": [{"text": "SemEval 2016 Task", "start_pos": 4, "end_pos": 21, "type": "TASK", "confidence": 0.8332342108090719}, {"text": "sentiment analysis", "start_pos": 27, "end_pos": 45, "type": "TASK", "confidence": 0.9392737746238708}]}, {"text": "The subtask, task A focused on classifying tweets into three classes: positive, negative or neutral sentiment.", "labels": [], "entities": []}, {"text": "This paper will first presents the submitted system used by team aicyber.", "labels": [], "entities": []}, {"text": "Then anew framework of estimating sentence vector will be introduced and evaluated.", "labels": [], "entities": []}], "datasetContent": [{"text": "Training of i-vector system is in a completely unsupervised manner, it includes training of word2vec and training of i-vector extractor.", "labels": [], "entities": []}, {"text": "Evaluation is done on IMDB similar to) and SemEval 2016 Task4A.", "labels": [], "entities": [{"text": "IMDB", "start_pos": 22, "end_pos": 26, "type": "DATASET", "confidence": 0.9055787920951843}, {"text": "SemEval 2016 Task4A", "start_pos": 43, "end_pos": 62, "type": "DATASET", "confidence": 0.6991808513800303}]}, {"text": "The i-vector framework is first evaluated on the IMDB dataset then on the SemEval 2016 dataset.", "labels": [], "entities": [{"text": "IMDB dataset", "start_pos": 49, "end_pos": 61, "type": "DATASET", "confidence": 0.987439900636673}, {"text": "SemEval 2016 dataset", "start_pos": 74, "end_pos": 94, "type": "DATASET", "confidence": 0.851302961508433}]}, {"text": "Evaluation metric is accuracy measured on IMDB database.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 21, "end_pos": 29, "type": "METRIC", "confidence": 0.9995230436325073}, {"text": "IMDB database", "start_pos": 42, "end_pos": 55, "type": "DATASET", "confidence": 0.9609952867031097}]}, {"text": "shows the performance of different systems.", "labels": [], "entities": []}, {"text": "The current state-of-the-art system is an ensemble of RNN language model, sentence vectors and NB SVM, achieved 92.57%) testing accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 128, "end_pos": 136, "type": "METRIC", "confidence": 0.9900779724121094}]}, {"text": "Sentence vector system is one of sub-system used in ensemble and achieved 88.73% accuracy alone.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 81, "end_pos": 89, "type": "METRIC", "confidence": 0.9992238283157349}]}, {"text": "Aicyber's system is the same system mentioned in Section 2, a VSM approach, it obtained 88.38%.", "labels": [], "entities": [{"text": "Aicyber", "start_pos": 0, "end_pos": 7, "type": "DATASET", "confidence": 0.8260812163352966}, {"text": "VSM", "start_pos": 62, "end_pos": 65, "type": "TASK", "confidence": 0.7002752423286438}]}, {"text": "To make a fair comparison same type of classifier, LDA is used to train and classify i-vector system, a 87.52% accuracy is reported.", "labels": [], "entities": [{"text": "LDA", "start_pos": 51, "end_pos": 54, "type": "METRIC", "confidence": 0.7626861929893494}, {"text": "accuracy", "start_pos": 111, "end_pos": 119, "type": "METRIC", "confidence": 0.9981073141098022}]}, {"text": "Concatenation of i-vector and vector from VSM a 89.94% accuracy can be achieved.", "labels": [], "entities": [{"text": "VSM", "start_pos": 42, "end_pos": 45, "type": "DATASET", "confidence": 0.8373035788536072}, {"text": "accuracy", "start_pos": 55, "end_pos": 63, "type": "METRIC", "confidence": 0.9994934797286987}]}, {"text": "Evaluation metric for SemEval 2016 task is Macro-F1 introduced in Equation 1.", "labels": [], "entities": [{"text": "SemEval 2016 task", "start_pos": 22, "end_pos": 39, "type": "TASK", "confidence": 0.82144828637441}]}, {"text": "During evaluation period we validate the performance on development and develop-test dataset.", "labels": [], "entities": []}, {"text": "Results as shown in indicate i-vector system is worse than our baseline system.", "labels": [], "entities": []}, {"text": "So we only submitted the baseline system.", "labels": [], "entities": []}], "tableCaptions": []}