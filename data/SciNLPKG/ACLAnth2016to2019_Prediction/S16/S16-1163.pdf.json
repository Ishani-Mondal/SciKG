{"title": [{"text": "AI-KU at SemEval-2016 Task 11: Word Embeddings and Substring Features for Complex Word Identification", "labels": [], "entities": [{"text": "Complex Word Identification", "start_pos": 74, "end_pos": 101, "type": "TASK", "confidence": 0.6388150652249655}]}], "abstractContent": [{"text": "We investigate the usage of word embeddings, namely Glove and SCODE, along with sub-string features on Complex Word Identification task.", "labels": [], "entities": [{"text": "Complex Word Identification task", "start_pos": 103, "end_pos": 135, "type": "TASK", "confidence": 0.6072050482034683}]}, {"text": "We introduce two systems: the first system utilizes the word embeddings of the target word and its substrings as features while the other considers the context information by using the embeddings of the surrounding words as well.", "labels": [], "entities": []}, {"text": "Although the proposed representations perform below the average with nonlinear models, we show that word embeddings with substring features is an effective representation choice when employed with linear classifiers.", "labels": [], "entities": []}], "introductionContent": [{"text": "Complex Word Identification (CWI) is the task of determining which words in a given sentence should be simplified.", "labels": [], "entities": [{"text": "Complex Word Identification (CWI)", "start_pos": 0, "end_pos": 33, "type": "TASK", "confidence": 0.7614279041687647}]}, {"text": "CWI is often considered as the first step in Lexical Simplification (LS) where the goal is to identify and replace complex words with simpler substitutes.", "labels": [], "entities": [{"text": "Lexical Simplification (LS)", "start_pos": 45, "end_pos": 72, "type": "TASK", "confidence": 0.9149557232856751}]}, {"text": "Although CWI is considered as a vital component of Lexical Simplification pipeline, there is not a lot of work done for identifying word complexity in the context of Lexical Simplification.", "labels": [], "entities": [{"text": "Lexical Simplification pipeline", "start_pos": 51, "end_pos": 82, "type": "TASK", "confidence": 0.8101231257120768}, {"text": "Lexical Simplification", "start_pos": 166, "end_pos": 188, "type": "TASK", "confidence": 0.8482499420642853}]}, {"text": "describes an LS model in which they employ a Complex Word identifier implicitly.", "labels": [], "entities": []}, {"text": "However, their results show that the method is notable to capture complex words very accurately.", "labels": [], "entities": []}, {"text": "Paetzold and Specia (2016) organizes the Complex Word Identification task of SemEval 2016 with the goal of attracting systems that are able to detect complex words in given a sentence.", "labels": [], "entities": [{"text": "Complex Word Identification task of SemEval 2016", "start_pos": 41, "end_pos": 89, "type": "TASK", "confidence": 0.6851134257657188}]}, {"text": "This work investigates the usage of word embeddings along with substrings as features to build a Complex Word Identifier.", "labels": [], "entities": []}, {"text": "Word embeddings are unsupervised word representations which map each word to a dense, real valued, low dimensional vector.", "labels": [], "entities": []}, {"text": "These vectors are able to capture semantic and syntactic similarities between words and proven useful as features in a variety of applications, such as, document classification), named entity recognition (, and parsing).", "labels": [], "entities": [{"text": "document classification", "start_pos": 153, "end_pos": 176, "type": "TASK", "confidence": 0.7925343215465546}, {"text": "named entity recognition", "start_pos": 179, "end_pos": 203, "type": "TASK", "confidence": 0.6614857614040375}, {"text": "parsing", "start_pos": 211, "end_pos": 218, "type": "TASK", "confidence": 0.9624383449554443}]}, {"text": "GloVe () is an unsupervised learning algorithm for obtaining vector representations for words which is essentially a logbilinear model with a weighted least-squares objective.", "labels": [], "entities": []}, {"text": "shows that the word embeddings produced by the model achieves state-of-the-art performance in Word Analogy task.", "labels": [], "entities": [{"text": "Word Analogy task", "start_pos": 94, "end_pos": 111, "type": "TASK", "confidence": 0.7415374418099722}]}, {"text": "Moreover, they also illustrate that Glove embeddings outperform embeddings induced by other methods on several word similarity tasks.", "labels": [], "entities": [{"text": "word similarity tasks", "start_pos": 111, "end_pos": 132, "type": "TASK", "confidence": 0.7701944013436636}]}, {"text": "Another work ( represents the context of a word by its probable substitutes.", "labels": [], "entities": []}, {"text": "Words with their probable substitutes are fed to a cooccurrence modeling framework (SCODE).", "labels": [], "entities": []}, {"text": "Words co-occurring in similar context are closely embedded on a sphere.", "labels": [], "entities": []}, {"text": "These word embeddings are effective at modeling syntactic features and they achieve state-of-the-art results in inducing part-of-speech.", "labels": [], "entities": []}, {"text": "We conducted several experiments to examine the usage of word embeddings.", "labels": [], "entities": []}, {"text": "First, we investigated whether pretrained word embeddings improve random embedding baseline.", "labels": [], "entities": []}, {"text": "Second, we tried concate-nations of word embeddings with different types and dimensions.", "labels": [], "entities": []}, {"text": "Next, we examined context-aware representations of target words by incorporating embeddings of neighbouring words.", "labels": [], "entities": []}, {"text": "After the release of test set annotations, we scrutinize how a linear model benefits from increasing the size of the training set.", "labels": [], "entities": []}, {"text": "This paper is organized as follows: Section 2 details the proposed dataset and evaluation metric, Section 3 analyzes the utilization of word embeddings for CWI, Section 4 presents results and discusses the performance of our work and Section 5 concludes the paper.", "labels": [], "entities": []}], "datasetContent": [{"text": "Complex Word Identification task of) prepares a dataset with 200 sentences for training and 9000 for testing.", "labels": [], "entities": []}, {"text": "The training set is composed of 5,362 tokens with 2,237 instances annotated, and the test set is composed of 217,902 tokens with 88,221 instances annotated.", "labels": [], "entities": []}, {"text": "Dataset properties are summarized in 9,200 sentences were annotated through a survey, in which 400 volunteers were presented with several sentences and asked to judge whether or not they could understand the meaning of each word in a given sentence.", "labels": [], "entities": []}, {"text": "A set of 200 sentences is separated for training and split into 20 subsets of 10 sentences, and each subset was annotated by a total of 20 volunteers.", "labels": [], "entities": []}, {"text": "In the training set, a word is considered as complex if at least one of the 20 annotators judged them so.", "labels": [], "entities": []}, {"text": "To compose the test set, remaining 9,000 sentences were split into 300 subsets of 30 sentences, each of which was annotated by a single volunteer.", "labels": [], "entities": []}, {"text": "Notably, training set is extremely small compared to test set.", "labels": [], "entities": []}, {"text": "As a result of this, 92% of test set vocabulary is unknown to training set.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Random Embedding Baseline, Comparison of Glove", "labels": [], "entities": []}, {"text": " Table 3. Experiments yield the best  results when we use 50 dimensional embeddings of  both methods. We show that concatenating embed- dings yields better results.", "labels": [], "entities": []}, {"text": " Table 4: Context-Aware Representations. S and G denotes", "labels": [], "entities": [{"text": "Context-Aware Representations", "start_pos": 10, "end_pos": 39, "type": "TASK", "confidence": 0.8118405640125275}]}, {"text": " Table 5: Best performed hyperparameters and 5-fold cross val-", "labels": [], "entities": []}, {"text": " Table 6: Final system results on test set along with baselines", "labels": [], "entities": []}]}