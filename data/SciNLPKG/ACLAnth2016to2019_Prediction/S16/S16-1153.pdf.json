{"title": [{"text": "MAZA at SemEval-2016 Task 11: Detecting Lexical Complexity Using a Decision Stump Meta-Classifier", "labels": [], "entities": [{"text": "Detecting Lexical Complexity", "start_pos": 30, "end_pos": 58, "type": "TASK", "confidence": 0.8955101569493612}]}], "abstractContent": [{"text": "This paper describes team MAZA entries for the 2016 SemEval Task 11: Complex Word Identification (CWI).", "labels": [], "entities": [{"text": "SemEval Task 11: Complex Word Identification (CWI)", "start_pos": 52, "end_pos": 102, "type": "TASK", "confidence": 0.7903783917427063}]}, {"text": "The task is a binary classification task in which systems are trained to predict whether a word in a sentence is considered to be complex or not.", "labels": [], "entities": [{"text": "binary classification task", "start_pos": 14, "end_pos": 40, "type": "TASK", "confidence": 0.7978489995002747}]}, {"text": "We developed our two systems for this task based on classi-fier stacking using decision stumps and decision trees.", "labels": [], "entities": [{"text": "classi-fier stacking", "start_pos": 52, "end_pos": 72, "type": "TASK", "confidence": 0.646168053150177}]}, {"text": "Our best system, using contextual features, frequency information, and word and sentence length, achieved 91.2% accuracy and 30.8% F-Score.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 112, "end_pos": 120, "type": "METRIC", "confidence": 0.997825562953949}, {"text": "F-Score", "start_pos": 131, "end_pos": 138, "type": "METRIC", "confidence": 0.9986028075218201}]}, {"text": "The system ranked 4 th among the 38 entries in the CWI task in terms of F-Score.", "labels": [], "entities": [{"text": "F-Score", "start_pos": 72, "end_pos": 79, "type": "METRIC", "confidence": 0.9962418079376221}]}], "introductionContent": [{"text": "Lexical simplification is a popular task in natural language processing and it was the topic of a successful SemEval task in 2012 (.", "labels": [], "entities": [{"text": "Lexical simplification", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.9161926805973053}, {"text": "natural language processing", "start_pos": 44, "end_pos": 71, "type": "TASK", "confidence": 0.6733200152715048}, {"text": "SemEval task", "start_pos": 109, "end_pos": 121, "type": "TASK", "confidence": 0.8855273723602295}]}, {"text": "It consists of applying computational methods to substitute words or short phrases for simpler ones to improve text readability and comprehension aimed at a given target population (e.g. children, language learners, people with reading impairment, etc.).", "labels": [], "entities": []}, {"text": "Lexical simplification is considered to be the sub-task of text simplification that deals with the lexicon while other sub-tasks address, for example, complex syntactic structures.", "labels": [], "entities": [{"text": "Lexical simplification", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.8717392683029175}, {"text": "text simplification", "start_pos": 59, "end_pos": 78, "type": "TASK", "confidence": 0.7185636311769485}]}, {"text": "To perform lexical simplification efficiently, computational methods should be first applied to identify which words in a text pose more difficulty to readers and they therefore good candidates for substitution.", "labels": [], "entities": [{"text": "lexical simplification", "start_pos": 11, "end_pos": 33, "type": "TASK", "confidence": 0.677555501461029}]}, {"text": "This task is called complex word identification (CWI) and it is the topic of the 2016 SemEval Task 11 with the same name.", "labels": [], "entities": [{"text": "complex word identification (CWI)", "start_pos": 20, "end_pos": 53, "type": "TASK", "confidence": 0.7729841570059458}, {"text": "SemEval Task 11", "start_pos": 86, "end_pos": 101, "type": "TASK", "confidence": 0.8626101414362589}]}, {"text": "The CWI shared task is modeled as a binary text classification task.", "labels": [], "entities": [{"text": "binary text classification task", "start_pos": 36, "end_pos": 67, "type": "TASK", "confidence": 0.7646636515855789}]}, {"text": "Participants are provided with training data containing sentences and a label for each word in them containing a value of either 1 (for complex words) or 0 (for simple words).", "labels": [], "entities": []}, {"text": "The label was attributed according to the judgment of human annotators that were required to indicate which words in the sentences could not be easily understood.", "labels": [], "entities": []}, {"text": "Below, an example can be found of a sentence from the training set.", "labels": [], "entities": []}, {"text": "Complex words are marked in bold.", "labels": [], "entities": []}, {"text": "(1) The name 'kangaroo mouse' refers to the species' extraordinary jumping ability, as well as its habit of bipedal locomotion.", "labels": [], "entities": [{"text": "kangaroo mouse'", "start_pos": 14, "end_pos": 29, "type": "TASK", "confidence": 0.7993191281954447}]}, {"text": "In the example presented above, the CWI systems should label extraordinary, bipedal and locomotion as complex words.", "labels": [], "entities": []}, {"text": "1 To accomplish this task, the MAZA team applied a decision stump meta-classifier and a wide set of features that we will describe here.", "labels": [], "entities": []}], "datasetContent": [{"text": "We employed a meta-classifier for our entry, also referred to as classifier stacking.", "labels": [], "entities": [{"text": "classifier stacking", "start_pos": 65, "end_pos": 84, "type": "TASK", "confidence": 0.7156367003917694}]}, {"text": "A meta-classifier architecture is generally composed of an ensemble of base classifiers that each make predictions for all of the input data.", "labels": [], "entities": []}, {"text": "Their individual predictions, along with the gold labels are used to train a second-level meta-classifier that learns to predict the final decision for an input, given the decisions of the individual classifiers.", "labels": [], "entities": []}, {"text": "This setup is illustrated in.", "labels": [], "entities": []}, {"text": "This meta-classifier attempts to learn from the collective knowledge represented by the ensemble of local classifiers.", "labels": [], "entities": []}, {"text": "The first step in such a setup is to create the set of base classifiers that form the first layer of the architecture.", "labels": [], "entities": []}, {"text": "We describe this process below.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: The top 20 systems submitted to the shared task, ranked by their F-score.", "labels": [], "entities": [{"text": "F-score", "start_pos": 75, "end_pos": 82, "type": "METRIC", "confidence": 0.9959638118743896}]}]}