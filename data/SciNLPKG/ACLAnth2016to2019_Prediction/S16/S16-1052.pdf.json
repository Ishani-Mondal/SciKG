{"title": [{"text": "MayAnd at SemEval-2016 Task 5: Syntactic and word2vec-based Approach to Aspect-based Polarity Detection in Russian", "labels": [], "entities": [{"text": "Aspect-based Polarity Detection", "start_pos": 72, "end_pos": 103, "type": "TASK", "confidence": 0.6074259479840597}]}], "abstractContent": [{"text": "This paper describes aspect-based polarity detection system for Russian, used in aspect-based sentiment analysis task (ABSA) of SemEval-2016 (Task 5, subtask 1, slot 3).", "labels": [], "entities": [{"text": "aspect-based polarity detection", "start_pos": 21, "end_pos": 52, "type": "TASK", "confidence": 0.7105149229367574}, {"text": "aspect-based sentiment analysis task (ABSA)", "start_pos": 81, "end_pos": 124, "type": "TASK", "confidence": 0.7509740718773433}]}, {"text": "The system consists of two independent classifiers: for opinion target expressions and for implicit opinion target mentions.", "labels": [], "entities": []}, {"text": "We introduce a set of standard unigram features together with more sophisticated ones: based on sentence syntactic structure and based on lemmas vector representation.", "labels": [], "entities": []}, {"text": "Being applied to Russian restaurant reviews, our system achieved best quality among four participants.", "labels": [], "entities": []}], "introductionContent": [{"text": "Aspect-based sentiment analysis task (ABSA) drew much attention with the growth of Internet retail sites and facilities for customers to make a free text product review.", "labels": [], "entities": [{"text": "Aspect-based sentiment analysis task (ABSA)", "start_pos": 0, "end_pos": 43, "type": "TASK", "confidence": 0.8056897350719997}]}, {"text": "ABSA systems allow businesses to track reputation of their products even more granularly than before: per aspect.", "labels": [], "entities": []}, {"text": "At the same time, customers can be provided with per-aspect sentiment summaries of reviews about concurrent products to simplify their choice.", "labels": [], "entities": []}, {"text": "SemEval-2016 Task 5 (ABSA) organizers (Pontiki et al., 2016) proposed two subtasks: Sentencelevel ABSA and Text-level ABSA.", "labels": [], "entities": [{"text": "SemEval-2016 Task 5 (ABSA)", "start_pos": 0, "end_pos": 26, "type": "DATASET", "confidence": 0.6398834387461344}, {"text": "Sentencelevel ABSA", "start_pos": 84, "end_pos": 102, "type": "TASK", "confidence": 0.4141393303871155}, {"text": "Text-level ABSA", "start_pos": 107, "end_pos": 122, "type": "TASK", "confidence": 0.4895000606775284}]}, {"text": "First subtask was split to three slots: Aspect Category Detection, Opinion Target Expression, Sentiment Polarity.", "labels": [], "entities": [{"text": "Aspect Category Detection", "start_pos": 40, "end_pos": 65, "type": "TASK", "confidence": 0.6032116512457529}]}, {"text": "Training data for the task were available for various languages (English, Russian, etc.) and domains (restaurants, laptops, etc.).", "labels": [], "entities": []}, {"text": "Slot 3 can be described as follows: given a set of reviews labeled with OTEs (opinion target expressions: start-end-entity-attribute quadruples) determine a polarity label for each OTE: positive, negative, neutral (mildly positive or mildly negative sentiment).", "labels": [], "entities": []}, {"text": "Additionally polarity labels should be computed for entity-attribute pairs assigned to reviews sentences.", "labels": [], "entities": []}, {"text": "This paper describes our team participation in slot 3 evaluation for Russian language Restaurant domain.", "labels": [], "entities": [{"text": "Russian language Restaurant domain", "start_pos": 69, "end_pos": 103, "type": "TASK", "confidence": 0.5617048144340515}]}, {"text": "The rest of the article is structured as follows: section 2 mentions some recent approaches to aspect-based polarity detection task, section 3 contains our system description, section 4 provides our system evaluation results.", "labels": [], "entities": [{"text": "aspect-based polarity detection task", "start_pos": 95, "end_pos": 131, "type": "TASK", "confidence": 0.7029652893543243}]}], "datasetContent": [{"text": "The official results are presented in.", "labels": [], "entities": []}, {"text": "Our system (MayAnd) official result differs from result presented in due to regrettable inadvertence with training dataset.", "labels": [], "entities": [{"text": "MayAnd", "start_pos": 12, "end_pos": 18, "type": "DATASET", "confidence": 0.7169671058654785}, {"text": "training dataset", "start_pos": 106, "end_pos": 122, "type": "DATASET", "confidence": 0.6707412302494049}]}, {"text": "Our system was trained on ini-tially published data instead of revised dataset that had been published later.", "labels": [], "entities": []}, {"text": "reflects actual quality of our system (trained on the latest published dataset).", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: 8-fold cross-validation with different word2vec training settings", "labels": [], "entities": []}, {"text": " Table 2: Features impact evaluation. Accuracy score of the", "labels": [], "entities": [{"text": "Accuracy score", "start_pos": 38, "end_pos": 52, "type": "METRIC", "confidence": 0.9768208861351013}]}, {"text": " Table 3: Evaluation official results", "labels": [], "entities": []}]}