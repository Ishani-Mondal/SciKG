{"title": [{"text": "Brundlefly at SemEval-2016 Task 12: Recurrent Neural Networks vs. Joint Inference for Clinical Temporal Information Extraction", "labels": [], "entities": [{"text": "Clinical Temporal Information Extraction", "start_pos": 86, "end_pos": 126, "type": "TASK", "confidence": 0.6081456914544106}]}], "abstractContent": [{"text": "We submitted two systems to the SemEval-2016 Task 12: Clinical TempEval challenge, participating in Phase 1, where we identified text spans of time and event expressions in clinical notes and Phase 2, where we predicted a relation between an event and its parent document creation time.", "labels": [], "entities": [{"text": "SemEval-2016 Task 12", "start_pos": 32, "end_pos": 52, "type": "TASK", "confidence": 0.8761809666951498}]}, {"text": "For temporal entity extraction, we find that a joint inference-based approach using struc-tured prediction outperforms a vanilla recurrent neural network that incorporates word embeddings trained on a variety of large clinical document sets.", "labels": [], "entities": [{"text": "temporal entity extraction", "start_pos": 4, "end_pos": 30, "type": "TASK", "confidence": 0.6966308355331421}]}, {"text": "For document creation time relations, we find that a combination of date canonicalization and distant supervision rules for predicting relations on both events and time expressions improves classification, though gains are limited, likely due to the small scale of training data.", "labels": [], "entities": [{"text": "document creation time relations", "start_pos": 4, "end_pos": 36, "type": "TASK", "confidence": 0.6607913225889206}, {"text": "classification", "start_pos": 190, "end_pos": 204, "type": "TASK", "confidence": 0.9457830786705017}]}], "introductionContent": [{"text": "This work discusses two information extraction systems for identifying temporal information in clinical text, submitted to).", "labels": [], "entities": [{"text": "information extraction", "start_pos": 24, "end_pos": 46, "type": "TASK", "confidence": 0.7429382801055908}]}, {"text": "We participated in tasks from both phases: (1) identifying text spans of time and event mentions; and (2) predicting relations between clinical events and document creation time.", "labels": [], "entities": [{"text": "predicting relations between clinical events", "start_pos": 106, "end_pos": 150, "type": "TASK", "confidence": 0.856077241897583}]}, {"text": "Temporal information extraction is the task of constructing a timeline or ordering of all events in a given document.", "labels": [], "entities": [{"text": "Temporal information extraction", "start_pos": 0, "end_pos": 31, "type": "TASK", "confidence": 0.9244949022928873}]}, {"text": "In the clinical domain, this is a key requirement for medical reasoning systems as well as longitudinal research into the progression of disease.", "labels": [], "entities": []}, {"text": "While timestamps and the structured nature of the electronic medical record (EMR) directly capture some aspects of time, a large amount of information on the progression of disease is found in the unstructured text component of the EMR where temporal structure is less obvious.", "labels": [], "entities": []}, {"text": "We examine a deep-learning approach to sequence labeling using a vanilla recurrent neural network (RNN) with word embeddings, as well as a joint inference, structured prediction approach using Stanford's knowledge base construction framework DeepDive.", "labels": [], "entities": [{"text": "sequence labeling", "start_pos": 39, "end_pos": 56, "type": "TASK", "confidence": 0.7212203741073608}]}, {"text": "Our DeepDive application outperformed the RNN and scored similarly to 2015's best-in-class extraction systems, even though it only used a small set of context window and dictionary features.", "labels": [], "entities": [{"text": "RNN", "start_pos": 42, "end_pos": 45, "type": "DATASET", "confidence": 0.8158209323883057}]}, {"text": "Extraction performance, however lagged this year's best system submission.", "labels": [], "entities": [{"text": "Extraction", "start_pos": 0, "end_pos": 10, "type": "METRIC", "confidence": 0.8714701533317566}]}, {"text": "For document creation time relations, we again use DeepDive.", "labels": [], "entities": [{"text": "document creation time relations", "start_pos": 4, "end_pos": 36, "type": "TASK", "confidence": 0.7528369799256325}]}, {"text": "Our system examined a simple temporal distant supervision rule for labeling time expressions and linking them to nearby event mentions via inference rules.", "labels": [], "entities": []}, {"text": "Overall system performance was better than this year's median submission, but again fell short of the best system.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 2: TIMEX3 spans extraction performance for the test set", "labels": [], "entities": [{"text": "TIMEX3", "start_pos": 10, "end_pos": 16, "type": "METRIC", "confidence": 0.8421295285224915}]}, {"text": " Table 3: EVENT spans extraction performance.", "labels": [], "entities": [{"text": "EVENT", "start_pos": 10, "end_pos": 15, "type": "METRIC", "confidence": 0.9897264838218689}, {"text": "extraction", "start_pos": 22, "end_pos": 32, "type": "TASK", "confidence": 0.9617452025413513}]}, {"text": " Table 4: Phase 2: EVENT Document Creation Time Relation", "labels": [], "entities": [{"text": "EVENT Document Creation Time Relation", "start_pos": 19, "end_pos": 56, "type": "TASK", "confidence": 0.8462677478790284}]}]}