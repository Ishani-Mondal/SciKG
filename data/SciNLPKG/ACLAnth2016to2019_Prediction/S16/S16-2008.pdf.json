{"title": [], "abstractContent": [{"text": "Ina complex sentence comprised of one or more subclauses, the overt or hidden attitudes between the various entities depend on the factuality projection of the verbs, their polar effects, and the modality and affirmative status (negated or not) of the clauses.", "labels": [], "entities": []}, {"text": "If factuality is given, some refer-ents might even be considered to benefit or to suffer from the (effects of the) described situation, independently of their relations to the other referents.", "labels": [], "entities": []}, {"text": "An interesting question is, how the reader evaluates all this from his/her perspective.", "labels": [], "entities": []}, {"text": "We introduce an approach based on Description Logics that integrates these various perspectives into a joint model.", "labels": [], "entities": []}], "introductionContent": [{"text": "Sentences can express a positive or negative relationship between people, organizations, and nations etc.", "labels": [], "entities": []}, {"text": "For instance, in the sentence \"the EU supports Greece\", a positive attitude of the EU towards Greece is expressed.", "labels": [], "entities": []}, {"text": "At the same time, a positive effect that is meant to be true, is asserted.", "labels": [], "entities": []}, {"text": "That is, Greece benefits from the situation described.", "labels": [], "entities": []}, {"text": "If the reader has a negative attitude towards the beneficiary (Greece), he might regard the apparent benefactor (EU) as his opponent.", "labels": [], "entities": []}, {"text": "However, if the sentence is embedded into a non-factive verb like \"to pretend\" (\"The EU pretends to support Greece\"), neither the positive relationship between the referents nor the positive effect on Greece hold any longer.", "labels": [], "entities": []}, {"text": "Instead, the matrix verb \"to pretend\" casts a negative effect on the EU.", "labels": [], "entities": []}, {"text": "If the reader adheres to this commonsense verb connotation, he will adopt the negative attitude towards the EU.", "labels": [], "entities": []}, {"text": "Furthermore, if some actor criticizes that the EU supports Greece, factuality of the embedded clause is given (compared to \"pretend\").", "labels": [], "entities": []}, {"text": "Thus, the positive effect on Greece still takes place, but now there is a negative attitude of this actor of the matrix clause towards both referents of the complement clause.", "labels": [], "entities": []}, {"text": "Finally, if an actor criticizes that the EU does not support Greece, his attitude towards Greece is positive (but negative towards the EU).", "labels": [], "entities": []}, {"text": "Given a text, we would like to be able to answer the following questions: What is good or bad for the entities mentioned in the text?", "labels": [], "entities": []}, {"text": "What is good or bad of these entities?", "labels": [], "entities": []}, {"text": "What are the attitudes of the entities towards each other?", "labels": [], "entities": []}, {"text": "And last but not least, what follows from the reader's stance, i.e. his prior attitudes towards some entities?", "labels": [], "entities": []}, {"text": "A user of our system then could mine texts for proponents and opponents of his, in the sense that entities that do things (or like others that) he likes are proponents, and entities that act in the opposite way (or like others he dislikes) are opponents.", "labels": [], "entities": []}, {"text": "In contrast to existing work (e.g.), we stress the point that verb signatures in the sense of that capture (non-)factuality information regarding complement clauses need to betaken into account in order to properly draw such inferences.", "labels": [], "entities": []}, {"text": "We focus on complex sentences where a matrix verb restricts its subclauses with respect to factuality depending on its affirmative status (i.e. whether the matrix clause is affirmative or negated).", "labels": [], "entities": []}, {"text": "The interplay of (non-)factuality with negation, the various polar restrictions projected by the verbs, and the aforementioned relational layer give rise to a complex model.", "labels": [], "entities": []}, {"text": "We have implemented a joint model with Description Logics (DL), namely OWL (Horrocks and Patel-Schneider, 2011) and SWRL).", "labels": [], "entities": []}, {"text": "However, the mapping from a sentence to input structures is mediated by a dependency parser, a predicate-argument extractor and a verb lexicon covering the polar restric-tions -these components are language-dependent.", "labels": [], "entities": []}, {"text": "We give English examples in this paper, although our pipeline (and the empirical evaluation) is for German.", "labels": [], "entities": []}, {"text": "Our English example sentences were manually converted to OWL representations.", "labels": [], "entities": []}], "datasetContent": [{"text": "Our inference rules were tuned on the basis of 80 constructed development sentences (Dev80) that concisely capture our modelled phenomena.", "labels": [], "entities": []}, {"text": "They combine verbs from our lexicon in sentences that are comprised of subclause embeddings up to three levels.", "labels": [], "entities": []}, {"text": "Affirmative and negated use of these verbs are combined with (non-)factuality at each level of embedding.", "labels": [], "entities": []}, {"text": "This was meant to base our model on an increased generative complexity of natural language -even if such sentences are rare in real texts.", "labels": [], "entities": []}, {"text": "Our goal was to model competence and at same time make it applicable.", "labels": [], "entities": []}, {"text": "The sample sentence S from the last section is an example of such a constructed sentence.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 8: Statistics for Test80: Annotators A and  B, the adjudicated gold standard G, and the system  output (setting I)", "labels": [], "entities": [{"text": "Test80", "start_pos": 25, "end_pos": 31, "type": "DATASET", "confidence": 0.9308961033821106}]}]}