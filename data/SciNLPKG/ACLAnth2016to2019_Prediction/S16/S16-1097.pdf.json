{"title": [{"text": "DTSim at SemEval-2016 Task 1: Semantic Similarity Model Including Multi-Level Alignment and Vector-Based Compositional Semantics", "labels": [], "entities": [{"text": "Multi-Level Alignment", "start_pos": 66, "end_pos": 87, "type": "TASK", "confidence": 0.6509273797273636}]}], "abstractContent": [{"text": "In this paper we describe our system (DT-Sim) submitted at SemEval-2016 Task 1: Semantic Textual Similarity (STS Core).", "labels": [], "entities": [{"text": "SemEval-2016 Task 1", "start_pos": 59, "end_pos": 78, "type": "TASK", "confidence": 0.7245103120803833}, {"text": "STS Core)", "start_pos": 109, "end_pos": 118, "type": "DATASET", "confidence": 0.7115246653556824}]}, {"text": "We developed Support Vector Regression model with various features including the similarity scores calculated using alignment based methods and semantic composition based methods.", "labels": [], "entities": []}, {"text": "The correlations between our system output and the human ratings were above 0.8 in three datasets.", "labels": [], "entities": []}], "introductionContent": [{"text": "The task of measuring the Semantic Textual Similarity (STS) is to quantify the degree of semantic similarity between the given pair of texts.", "labels": [], "entities": [{"text": "Semantic Textual Similarity (STS)", "start_pos": 26, "end_pos": 59, "type": "TASK", "confidence": 0.7240766286849976}]}, {"text": "For example, the similarity score of 0 means that the texts are not similar at all and 5 means that they have same meaning.", "labels": [], "entities": [{"text": "similarity score", "start_pos": 17, "end_pos": 33, "type": "METRIC", "confidence": 0.9798934161663055}]}, {"text": "In this paper, we describe our system DTSim and the submitted three different runs in this year's SemEval shared task on Semantic Textual Similarity English track (STS Core;).", "labels": [], "entities": [{"text": "SemEval shared task", "start_pos": 98, "end_pos": 117, "type": "TASK", "confidence": 0.8728252251942953}, {"text": "Semantic Textual Similarity English track", "start_pos": 121, "end_pos": 162, "type": "TASK", "confidence": 0.6963673055171966}, {"text": "STS Core", "start_pos": 164, "end_pos": 172, "type": "DATASET", "confidence": 0.7707595527172089}]}, {"text": "We applied Support Vector Regression (SVR) with various features in order to predict the similarity score for the given sentence pairs.", "labels": [], "entities": [{"text": "Support Vector Regression (SVR)", "start_pos": 11, "end_pos": 42, "type": "METRIC", "confidence": 0.8273897369702657}, {"text": "similarity score", "start_pos": 89, "end_pos": 105, "type": "METRIC", "confidence": 0.9560403823852539}]}, {"text": "The features of the model included semantic similarity scores calculated using individual methods (described in Section 3) and other general features.", "labels": [], "entities": []}, {"text": "The pipeline of components in DTSim is shown in.", "labels": [], "entities": [{"text": "DTSim", "start_pos": 30, "end_pos": 35, "type": "DATASET", "confidence": 0.8800658583641052}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 2: Results of our submitted runs on test data.", "labels": [], "entities": []}]}