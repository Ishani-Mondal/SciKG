{"title": [{"text": "NRU-HSE at SemEval-2016 Task 4: Comparative Analysis of Two Iterative Methods Using Quantification Library", "labels": [], "entities": [{"text": "NRU-HSE", "start_pos": 0, "end_pos": 7, "type": "DATASET", "confidence": 0.9198046326637268}, {"text": "SemEval-2016 Task 4", "start_pos": 11, "end_pos": 30, "type": "TASK", "confidence": 0.5355016986529032}]}], "abstractContent": [{"text": "In many areas, such as social science, politics or market research, people need to track sentiment and their changes overtime.", "labels": [], "entities": []}, {"text": "For sentiment analysis in this field it is more important to correctly estimate proportions of each sentiment expressed in the set of documents (quantification task) than to accurately estimate sentiment of a particular document (classification).", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 4, "end_pos": 22, "type": "TASK", "confidence": 0.9485913813114166}]}, {"text": "Basically, our study was aimed to analyze the effectiveness of two iterative quantification techniques and to compare their effectiveness with baseline methods.", "labels": [], "entities": []}, {"text": "All the techniques are evaluated using a set of synthesized data and the SemEval-2016 Task4 dataset.", "labels": [], "entities": [{"text": "SemEval-2016 Task4 dataset", "start_pos": 73, "end_pos": 99, "type": "DATASET", "confidence": 0.8542337616284689}]}, {"text": "We made the quantification methods from this paper available as a Python open source library.", "labels": [], "entities": []}, {"text": "The results of comparison and possible limitations of the quantifica-tion techniques are discussed.", "labels": [], "entities": []}], "introductionContent": [{"text": "In many areas, such as customer-relationship management or opinion mining, people need to track changes overtime and measure proportions of documents expressing different sentiments.", "labels": [], "entities": [{"text": "customer-relationship management", "start_pos": 23, "end_pos": 55, "type": "TASK", "confidence": 0.8325672149658203}, {"text": "opinion mining", "start_pos": 59, "end_pos": 73, "type": "TASK", "confidence": 0.7540670335292816}]}, {"text": "In these situations, the task of accurate categorization of each document is replaced by the task of providing accurate proportions of documents from each class (quantification).", "labels": [], "entities": []}, {"text": "George Forman suggested defining the 'quantification task' as finding the best estimate for the amount of cases in each class in a test set, using a training set with substantially different class distribution.", "labels": [], "entities": []}, {"text": "Application of the quantification approach in opinion mining ( , network-behavior analysis (, word-sense disambiguation), remote sensing (), quality control (, monitoring support-call logs) and credit scoring) showed high performance even with a relatively small training set.", "labels": [], "entities": [{"text": "opinion mining", "start_pos": 46, "end_pos": 60, "type": "TASK", "confidence": 0.8318328559398651}, {"text": "network-behavior analysis", "start_pos": 65, "end_pos": 90, "type": "TASK", "confidence": 0.7282917201519012}, {"text": "word-sense disambiguation)", "start_pos": 94, "end_pos": 120, "type": "TASK", "confidence": 0.7606720228989919}]}, {"text": "Although quantification techniques are able to provide accurate sentiment analysis of proportions in situations of distribution drift, the question of optimal technique for analysis of tweets still raises a lot of questions.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 64, "end_pos": 82, "type": "TASK", "confidence": 0.781364917755127}]}, {"text": "It is worth mentioning that sentiment analysis of tweets presents additional challenges to natural language processing, because of the small amount of text (less than 140 characters in each document), usage of creative spelling (e.g. \"happpyyy\", \"some1 yg bner2 tulus\"), abbreviations (such as \"wth\" or \"lol\"), informal constructions (\"hahahaha yava quiet so !ma I m bored av even home nw\") and hashtags (BREAKING: US GDP growth is back!", "labels": [], "entities": [{"text": "sentiment analysis of tweets", "start_pos": 28, "end_pos": 56, "type": "TASK", "confidence": 0.9326818734407425}, {"text": "BREAKING", "start_pos": 405, "end_pos": 413, "type": "METRIC", "confidence": 0.9858323335647583}]}, {"text": "#kidding), which area type of tagging for Twitter messages.", "labels": [], "entities": [{"text": "kidding", "start_pos": 1, "end_pos": 8, "type": "METRIC", "confidence": 0.8861819505691528}]}, {"text": "In our paper we used several quantification methods mentioned in literature as the best ones and evaluated them by comparing their effectiveness with one another and with baseline methods.", "labels": [], "entities": []}, {"text": "The paper is organized as follows.", "labels": [], "entities": []}, {"text": "In Section 2, we first look at the notation, then we briefly overview six methods to solve the quantification problem.", "labels": [], "entities": []}, {"text": "Section 3 describes two datasets we use in our research.", "labels": [], "entities": []}, {"text": "Section 4 describes the results of our experiments, while Section 5 concludes the work defining open research issues for further investigation.", "labels": [], "entities": []}], "datasetContent": [{"text": "This section describes our experimental setup.", "labels": [], "entities": []}, {"text": "It describes the datasets we use, the specific experiments we run and the classifier induction algorithm we employ.", "labels": [], "entities": []}, {"text": "To evaluate the algorithms on the real data pated in the SemEval-2016 Task 4 called \"Sentiment Analysis in Twitter\".", "labels": [], "entities": [{"text": "Sentiment Analysis", "start_pos": 85, "end_pos": 103, "type": "TASK", "confidence": 0.9051699638366699}]}, {"text": "Its dataset consists of sages (aka observations) divided Task 4 consists of five subtasks, but wed in subtasks D and E: tweet quantification according to a two-point scale and five These subtasks are evaluated topics, and the final result is counted as an average of evaluation measure out of all the topics 2016).", "labels": [], "entities": []}, {"text": "The organizers provide a default split of the data into training, development and development tasets.", "labels": [], "entities": []}, {"text": "The algorithms evaluation is performed these subsets.", "labels": [], "entities": []}, {"text": "The training subset is used as a TRAIN set, development and development are used as a TEST set.", "labels": [], "entities": [{"text": "TRAIN", "start_pos": 33, "end_pos": 38, "type": "METRIC", "confidence": 0.837629497051239}, {"text": "TEST", "start_pos": 86, "end_pos": 90, "type": "METRIC", "confidence": 0.8171453475952148}]}, {"text": "Since observation x in this dataset is a message wri ten in a natural language, we first need to transform it to the vector representation X.", "labels": [], "entities": []}, {"text": "Based on a study by and Sebastiani, 2015), we choose the following comp nents of the feature vector: \uf0b7 TFIDF for word n-grams with n 4 \uf0b7 TFIDF character n-grams where n 5.", "labels": [], "entities": [{"text": "\uf0b7", "start_pos": 101, "end_pos": 102, "type": "METRIC", "confidence": 0.9912806153297424}, {"text": "TFIDF", "start_pos": 103, "end_pos": 108, "type": "METRIC", "confidence": 0.7959251999855042}]}, {"text": "Feature vector is extracted with a We also perform data preprocessing terns (e.g. links, emoticons, numbers) w with their substitutes.", "labels": [], "entities": []}, {"text": "For word n matization using WordNetLemmatizer.", "labels": [], "entities": [{"text": "word n matization", "start_pos": 4, "end_pos": 21, "type": "TASK", "confidence": 0.7617100477218628}, {"text": "WordNetLemmatizer", "start_pos": 28, "end_pos": 45, "type": "DATASET", "confidence": 0.9628835916519165}]}, {"text": "It is interesting to characterize messages using SentiWordNet library.", "labels": [], "entities": []}, {"text": "For each token we obtain its polarity value from the SentiWordNet.", "labels": [], "entities": []}, {"text": "First, we recognize the part of speech using tagger from the NLTK library cond, we get the SentiWordNet first polarity value for this token using the part of speech information.", "labels": [], "entities": [{"text": "NLTK library", "start_pos": 61, "end_pos": 73, "type": "DATASET", "confidence": 0.9203575849533081}]}, {"text": "We used polarity values to extend vector represent tion of documents in two ways the polarity score as a sum of positive minus negative polarity values and add this feature to tor representation of a document.", "labels": [], "entities": []}, {"text": "Second the sum of positive polarities and a quality evaluation metrics for quantifiTo evaluate the algorithms on the real data, we partici-2016 Task 4 called \"Sentiment Its dataset consists of Twitter mesdivided into several topics.", "labels": [], "entities": []}, {"text": "Task 4 consists of five subtasks, but we only participat-D and E: tweet quantification according point scale and five-point scale, respectively.", "labels": [], "entities": [{"text": "E", "start_pos": 63, "end_pos": 64, "type": "METRIC", "confidence": 0.9683365821838379}]}, {"text": "independently for different final result is counted as an average of evaluation measure out of all the topics (Nakov et al., default split of the data into training, development and development-time testing datasets.", "labels": [], "entities": []}, {"text": "The algorithms evaluation is performed using raining subset is used as a TRAIN set, development and development-time testing subsets in this dataset is a message written in a natural language, we first need to transform it to . Based on a study by (Gao , we choose the following compograms with n varying from 1 to grams where n varies from 3 to extracted with a Scikit_Learn tool 3 . We also perform data preprocessing .Several text patlinks, emoticons, numbers) were replaced For word n-grams we apply lemmatization using WordNetLemmatizer.", "labels": [], "entities": [{"text": "TRAIN", "start_pos": 73, "end_pos": 78, "type": "METRIC", "confidence": 0.9559659361839294}, {"text": "WordNetLemmatizer", "start_pos": 524, "end_pos": 541, "type": "DATASET", "confidence": 0.9580246806144714}]}, {"text": "It is interesting to characterize messages using the SentiWordNet library.", "labels": [], "entities": []}, {"text": "For each token xi in document X obtain its polarity value from the SentiWordNet.", "labels": [], "entities": []}, {"text": "part of speech using a speech NLTK library (.", "labels": [], "entities": []}, {"text": "Seget the SentiWordNet first polarity value for part of speech information.", "labels": [], "entities": []}, {"text": "We used polarity values to extend vector representation of documents in two ways: first we simply calculate sum of positive minus a sum of negative polarity values and add this feature to the vecpresentation of a document.", "labels": [], "entities": []}, {"text": "Second, we calculate sum of positive polarities and the sum of negative learn.org/stable/modules/generated/sklearn.feature_extraction.", "labels": [], "entities": []}, {"text": "polarities and add these two features to the vector representation of a document.", "labels": [], "entities": []}, {"text": "The metrics that we use to evaluate the classifier performance are described in (Nakov et al., 2016) and are not described here.", "labels": [], "entities": []}, {"text": "We apply six quantification methods mentioned above in Section 2: CC, PCC, ACC, PACC, EM, CDEIterate and compare them.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table1: Comparison of methods on test sample with a two- point scale (SemEval-2016 Task4 Subtask D).", "labels": [], "entities": []}, {"text": " Table 3, show that the new features  increase quantification accuracy for CC, ACC, but sur- prisingly decrease it for PCC, PACC, EM, CDEIterate  and CDEIterate-U.", "labels": [], "entities": [{"text": "quantification", "start_pos": 47, "end_pos": 61, "type": "METRIC", "confidence": 0.8833509683609009}, {"text": "accuracy", "start_pos": 62, "end_pos": 70, "type": "METRIC", "confidence": 0.8875887989997864}]}]}