{"title": [{"text": "AUEB-ABSA at SemEval-2016 Task 5: Ensembles of Classifiers and Embeddings for Aspect Based Sentiment Analysis", "labels": [], "entities": [{"text": "AUEB-ABSA at SemEval-2016 Task 5", "start_pos": 0, "end_pos": 32, "type": "DATASET", "confidence": 0.7966254353523254}, {"text": "Aspect Based Sentiment Analysis", "start_pos": 78, "end_pos": 109, "type": "TASK", "confidence": 0.662847489118576}]}], "abstractContent": [{"text": "This paper describes our submissions to the Aspect Based Sentiment Analysis task of SemEval-2016.", "labels": [], "entities": [{"text": "Aspect Based Sentiment Analysis task of SemEval-2016", "start_pos": 44, "end_pos": 96, "type": "TASK", "confidence": 0.769423131431852}]}, {"text": "For Aspect Category Detection (Subtask1/Slot1), we used multiple ensembles , based on Support Vector Machine classifiers.", "labels": [], "entities": [{"text": "Aspect Category Detection", "start_pos": 4, "end_pos": 29, "type": "TASK", "confidence": 0.7669464548428854}]}, {"text": "For Opinion Target Expression extraction (Subtask1/Slot2), we used a sequence labeling approach with Conditional Random Fields.", "labels": [], "entities": [{"text": "Opinion Target Expression extraction", "start_pos": 4, "end_pos": 40, "type": "TASK", "confidence": 0.7674106955528259}]}, {"text": "For Polarity Detection (Sub-task1/Slot3), we used an ensemble of two supervised classifiers, one based on hand crafted features and one based on word embeddings.", "labels": [], "entities": [{"text": "Polarity Detection", "start_pos": 4, "end_pos": 22, "type": "TASK", "confidence": 0.700638622045517}]}, {"text": "Our systems were ranked in the top 6 positions in all the tasks we participated.", "labels": [], "entities": []}, {"text": "The source code of our systems is publicly available.", "labels": [], "entities": []}], "introductionContent": [{"text": "The amount of user-generated content on the web has grown rapidly in recent years, leading to increased interest in sentiment analysis and, more generally, opinion mining.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 116, "end_pos": 134, "type": "TASK", "confidence": 0.9627276659011841}, {"text": "opinion mining", "start_pos": 156, "end_pos": 170, "type": "TASK", "confidence": 0.8579898178577423}]}, {"text": "The task of Aspect Based Sentiment Analysis of and SemEval-2015 (SE-ABSA15) was concerned with identifying the aspects of given target entities and extracting the sentiment expressed towards each aspect (.", "labels": [], "entities": [{"text": "Aspect Based Sentiment Analysis", "start_pos": 12, "end_pos": 43, "type": "TASK", "confidence": 0.7480081617832184}]}, {"text": "The task of Aspect Based Sentiment Analysis of SemEval-2016 (SE-ABSA16) is a continuation of those tasks ().", "labels": [], "entities": [{"text": "Aspect Based Sentiment Analysis", "start_pos": 12, "end_pos": 43, "type": "TASK", "confidence": 0.6359827592968941}]}, {"text": "We participated in Aspect Category Detection (ACD, Subtask1/Slot1), Opinion Target Expression (OTE, Subtask1/Slot2), and Polarity Detection (PD, Subtask1/Slot3).", "labels": [], "entities": [{"text": "Aspect Category Detection", "start_pos": 19, "end_pos": 44, "type": "TASK", "confidence": 0.63984348376592}, {"text": "Polarity Detection", "start_pos": 121, "end_pos": 139, "type": "TASK", "confidence": 0.6945884376764297}]}, {"text": "In ACD, we participated in the English language, for both Laptops and Restaurants, submitting both constrained and unconstrained systems.", "labels": [], "entities": []}, {"text": "Our constrained system used only the provided training data for the corresponding domain.", "labels": [], "entities": []}, {"text": "Features were extracted from lexicons created from the training data.", "labels": [], "entities": []}, {"text": "One Support Vector Machine (SVM) classifier) was trained for each Entity and Attribute category (called E and A respectively).", "labels": [], "entities": []}, {"text": "Our unconstrained system used word embeddings as additional resources).", "labels": [], "entities": []}, {"text": "For each category (E or A), we used an ensemble of two systems: our constrained system and one new system, which was based on word embeddings.", "labels": [], "entities": []}, {"text": "In OTE, we participated with both a constrained and an unconstrained system.", "labels": [], "entities": [{"text": "OTE", "start_pos": 3, "end_pos": 6, "type": "DATASET", "confidence": 0.6534075140953064}]}, {"text": "The task is to identify aspects of given target entities.", "labels": [], "entities": []}, {"text": "We addressed the problem as a sequential labeling task, assigning one label to each word in a sentence, indicating whether the word was an aspect term or not.", "labels": [], "entities": []}, {"text": "In this task, we used Conditional Random Fields ().", "labels": [], "entities": []}, {"text": "Similarly to ACD, our unconstrained system differed in that it also used word embeddings as features.", "labels": [], "entities": []}, {"text": "In PD, we participated only with an unconstrained system, in both domains, in the English language.", "labels": [], "entities": [{"text": "PD", "start_pos": 3, "end_pos": 5, "type": "TASK", "confidence": 0.9602877497673035}]}, {"text": "We used an ensemble of two classifiers.", "labels": [], "entities": []}, {"text": "The first classifier used hand crafted features and sentiment lexicons with scores.", "labels": [], "entities": []}, {"text": "The second classifier was based on IDF-weighted centroids of the word embeddings of each sentence (.", "labels": [], "entities": []}, {"text": "The remainder of this paper is structured as follows.", "labels": [], "entities": []}, {"text": "In Section 2, we describe our systems in detail, including data preprocessing and feature de-scriptions.", "labels": [], "entities": []}, {"text": "In Sections 3 and 4, we present our official results and experiments, respectively.", "labels": [], "entities": []}, {"text": "Finally, Section 5 summarizes our work and proposes future directions.", "labels": [], "entities": []}], "datasetContent": [{"text": "As described in Section 2.1, our unconstrained ACD system used an ensemble of two systems, one based on word embeddings and one based on features calculated only on the training data.", "labels": [], "entities": []}, {"text": "Preliminary experiments showed that the ensemble is better than each system alone and better than a single system combining all the features of the two systems.", "labels": [], "entities": []}, {"text": "In the same task, experiments in the domain of Restaurants showed that there is no important difference between having one classifier for each possible E#A label, and having separate classifiers for each E and each A label.", "labels": [], "entities": []}, {"text": "However, in Laptops, the latter approach led to slightly better results and, hence, it was preferred.", "labels": [], "entities": [{"text": "Laptops", "start_pos": 12, "end_pos": 19, "type": "DATASET", "confidence": 0.9274806380271912}]}, {"text": "In the task of OTE, our constrained system is below the median participant (6th out of 8 submissions).", "labels": [], "entities": [{"text": "OTE", "start_pos": 15, "end_pos": 18, "type": "TASK", "confidence": 0.7405545711517334}]}, {"text": "However, when extended with features based on word embeddings (our unconstrained system), its performance is outstanding (2nd out of 19 submissions).", "labels": [], "entities": []}, {"text": "It is also worth noting that, in preliminary experiments for OTE, the use of a context vector (i.e., concatenated embeddings of words in a 5-context window of the word in question) gave far better results than using the centroid of these word embeddings.", "labels": [], "entities": [{"text": "OTE", "start_pos": 61, "end_pos": 64, "type": "TASK", "confidence": 0.743966817855835}]}], "tableCaptions": [{"text": " Table 1: AUEB-ABSA's evaluation in Aspect Category Detec-", "labels": [], "entities": [{"text": "AUEB-ABSA", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.8606263995170593}, {"text": "Aspect Category Detec", "start_pos": 36, "end_pos": 57, "type": "TASK", "confidence": 0.5928176542123159}]}, {"text": " Table 2: AUEB-ABSA's evaluation in Opinion Target Expres-", "labels": [], "entities": [{"text": "AUEB-ABSA", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.8726166486740112}]}]}