{"title": [{"text": "IIIT at SemEval-2016 Task 11: Complex Word Identification using Nearest Centroid Classification", "labels": [], "entities": [{"text": "IIIT", "start_pos": 0, "end_pos": 4, "type": "TASK", "confidence": 0.8299843072891235}, {"text": "Complex Word Identification", "start_pos": 30, "end_pos": 57, "type": "TASK", "confidence": 0.7009190022945404}]}], "abstractContent": [{"text": "This paper describes the system that was submitted to SemEval2016 Task 11: Complex Word Identification.", "labels": [], "entities": [{"text": "SemEval2016 Task 11", "start_pos": 54, "end_pos": 73, "type": "TASK", "confidence": 0.8639310201009115}, {"text": "Complex Word Identification", "start_pos": 75, "end_pos": 102, "type": "TASK", "confidence": 0.6657272378603617}]}, {"text": "It presents a preliminary investigation into exploring word difficulty for non-native English speakers.", "labels": [], "entities": []}, {"text": "We developed two systems using Nearest Centroid Classification technique to distinguish complex words from simple words.", "labels": [], "entities": [{"text": "Nearest Centroid Classification", "start_pos": 31, "end_pos": 62, "type": "TASK", "confidence": 0.5540532569090525}]}, {"text": "Optimized over G-score, the presented solution obtained a G-score of 0.67, while the winner achieved a G-score of 0.77 and the average G-score of all the submitted systems in the task was 0.56.", "labels": [], "entities": [{"text": "G-score", "start_pos": 15, "end_pos": 22, "type": "METRIC", "confidence": 0.9310275912284851}, {"text": "G-score", "start_pos": 58, "end_pos": 65, "type": "METRIC", "confidence": 0.9925865530967712}, {"text": "G-score", "start_pos": 103, "end_pos": 110, "type": "METRIC", "confidence": 0.9841252565383911}, {"text": "G-score", "start_pos": 135, "end_pos": 142, "type": "METRIC", "confidence": 0.9797605872154236}]}], "introductionContent": [{"text": "Lexical Simplification aims at improving the readability and comprehensibility of text by transforming complex text into simple text.", "labels": [], "entities": [{"text": "Lexical Simplification", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.8830721974372864}]}, {"text": "Lexical Simplification () is the process of replacing a word in a given context with its simplest substitute to enhance the readability of the text.", "labels": [], "entities": [{"text": "Lexical Simplification", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.859540194272995}]}, {"text": "The process should make sure that while replacing words with other variants, the meaning of the text is preserved.", "labels": [], "entities": []}, {"text": "Lexical Simplification) is useful to a wide variety of target audience like people with aphasia, children and also non-native speakers.", "labels": [], "entities": [{"text": "Lexical Simplification", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.8473105728626251}]}, {"text": "Complex Word Identification) is considered to be the first step in the pipeline of Lexical Simplification.", "labels": [], "entities": [{"text": "Complex Word Identification", "start_pos": 0, "end_pos": 27, "type": "TASK", "confidence": 0.6169378062089285}, {"text": "Lexical Simplification", "start_pos": 83, "end_pos": 105, "type": "TASK", "confidence": 0.9142862558364868}]}, {"text": "The overall performance of a Lexical Simplification system is thus crucially dependent upon Complex Word Identification.", "labels": [], "entities": [{"text": "Lexical Simplification", "start_pos": 29, "end_pos": 51, "type": "TASK", "confidence": 0.8509131371974945}, {"text": "Complex Word Identification", "start_pos": 92, "end_pos": 119, "type": "TASK", "confidence": 0.5865959326426188}]}, {"text": "The problem of Complex Word Identification is relatively new in the field of Natural Language Processing.", "labels": [], "entities": [{"text": "Complex Word Identification", "start_pos": 15, "end_pos": 42, "type": "TASK", "confidence": 0.6366419196128845}, {"text": "Natural Language Processing", "start_pos": 77, "end_pos": 104, "type": "TASK", "confidence": 0.6421138644218445}]}, {"text": "However, a few approaches have been previously proposed for this task.", "labels": [], "entities": []}, {"text": "The simplicity score) of a word is computed by integrating both, frequency and length of a word.", "labels": [], "entities": [{"text": "simplicity score", "start_pos": 4, "end_pos": 20, "type": "METRIC", "confidence": 0.989988774061203}]}, {"text": "They consider a threshold value and simplify words only if the word's frequency is lower than the fixed threshold.", "labels": [], "entities": []}, {"text": "Matthew Shardlow (2013) explores the frequency thresholding to differentiate between simple and complex words by experimenting with each threshold value on a particular corpus.", "labels": [], "entities": []}, {"text": "However, this approach is not practically convincing.", "labels": [], "entities": []}, {"text": "The same author also frames the problem as a machine learning classification problem by designing a few features.", "labels": [], "entities": [{"text": "machine learning classification", "start_pos": 45, "end_pos": 76, "type": "TASK", "confidence": 0.6977521379788717}]}, {"text": "We approach the problem at hand on similar lines.", "labels": [], "entities": []}, {"text": "The Complex Word Identification (CWI) task is framed as a binary classification problem.", "labels": [], "entities": [{"text": "Complex Word Identification (CWI) task", "start_pos": 4, "end_pos": 42, "type": "TASK", "confidence": 0.799258611031941}]}, {"text": "Given a word in a sentence, the task is to predict whether the word is simple or complex.", "labels": [], "entities": []}, {"text": "A word is tagged with 0 if it is simple and 1 if the word is found to be complex.", "labels": [], "entities": []}, {"text": "1 C is the set of complex words, S is the set of simple words and c(w) represents the class of the word.", "labels": [], "entities": []}, {"text": "Here is an example of a sentence taken from the training dataset provided by the organizers.", "labels": [], "entities": []}, {"text": "A frenulum is a small fold of tissue that secures or restricts the motion of a mobile organ in the body.", "labels": [], "entities": []}, {"text": "In the above example, the task requires a system to spae the words in bold as complex.", "labels": [], "entities": []}, {"text": "The remainder of this paper is structured as follows.", "labels": [], "entities": []}, {"text": "In Section 2, we describe our systems and Section 3 discusses experiments and results.", "labels": [], "entities": []}, {"text": "We conclude in Section 4.", "labels": [], "entities": []}], "datasetContent": [{"text": "The official evaluation metric of the task is G-score.", "labels": [], "entities": [{"text": "G-score", "start_pos": 46, "end_pos": 53, "type": "METRIC", "confidence": 0.9966805577278137}]}, {"text": "It is the harmonic mean of Accuracy (A) and Recall (R).", "labels": [], "entities": [{"text": "Accuracy (A)", "start_pos": 27, "end_pos": 39, "type": "METRIC", "confidence": 0.9572614282369614}, {"text": "Recall (R)", "start_pos": 44, "end_pos": 54, "type": "METRIC", "confidence": 0.9608891010284424}]}, {"text": "shows the average G-score obtained using different classifiers for 5-fold cross-validation on the training data.", "labels": [], "entities": [{"text": "G-score", "start_pos": 18, "end_pos": 25, "type": "METRIC", "confidence": 0.9977496266365051}]}, {"text": "For experiments using the Nearest Centroid Classification, we explored 24 different distance metrics, of which Manhattan and Standardised Euclidean metrics performed the best.", "labels": [], "entities": []}, {"text": "Based on G-score, our systems were ranked 15th and 23rd in the task.", "labels": [], "entities": [{"text": "G-score", "start_pos": 9, "end_pos": 16, "type": "METRIC", "confidence": 0.9955506324768066}]}, {"text": "Our first system was able to beat all the baseline systems including the threshold-based and the lexicon-based systems.", "labels": [], "entities": []}, {"text": "pertain only to the finalized feature set discussed in Section 3.", "labels": [], "entities": []}, {"text": "also shows the results obtained on the test data using different classifiers with the same set of features employed for System 1 and System 2.", "labels": [], "entities": []}, {"text": "At this point of time, we are not sure about why few classifiers like AdaBoost and Random Forest performed way better than System 1 and System 2 on the test data.", "labels": [], "entities": [{"text": "AdaBoost", "start_pos": 70, "end_pos": 78, "type": "DATASET", "confidence": 0.9451051950454712}]}, {"text": "A possible reason for the poor performance of the Nearest Centroid Classifier in comparison to other systems could be the imbalance between the training and the test data size.", "labels": [], "entities": []}, {"text": "The test data being highly skewed could probably be another reason.", "labels": [], "entities": []}, {"text": "AdaBoost 8 classifier) was found to achieve a G-score of 0.772 on test data.", "labels": [], "entities": [{"text": "AdaBoost 8 classifier", "start_pos": 0, "end_pos": 21, "type": "DATASET", "confidence": 0.892474353313446}, {"text": "G-score", "start_pos": 46, "end_pos": 53, "type": "METRIC", "confidence": 0.9978227615356445}]}, {"text": "This suggests that both, the proposed feature set and the approach presented are competent.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2 shows the per- formance of System 1 and System 2 on the test data.", "labels": [], "entities": []}]}