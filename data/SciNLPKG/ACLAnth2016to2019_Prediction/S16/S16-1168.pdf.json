{"title": [{"text": "SemEval-2016 Task 13: Taxonomy Extraction Evaluation (TExEval-2)", "labels": [], "entities": [{"text": "Taxonomy Extraction Evaluation", "start_pos": 22, "end_pos": 52, "type": "TASK", "confidence": 0.8482150832811991}]}], "abstractContent": [{"text": "This paper describes the second edition of the shared task on Taxonomy Extraction Evaluation organised as part of SemEval 2016.", "labels": [], "entities": [{"text": "Taxonomy Extraction Evaluation organised as part of SemEval 2016", "start_pos": 62, "end_pos": 126, "type": "TASK", "confidence": 0.7529093093342252}]}, {"text": "This task aims to extract hypernym-hyponym relations between a given list of domain-specific terms and then to construct a domain taxon-omy based on them.", "labels": [], "entities": []}, {"text": "TExEval-2 introduced a multilingual setting for this task, covering four different languages including English, Dutch, Italian and French from domains as diverse as environment, food and science.", "labels": [], "entities": [{"text": "TExEval-2", "start_pos": 0, "end_pos": 9, "type": "DATASET", "confidence": 0.9365424513816833}]}, {"text": "A total of 62 runs submitted by 5 different teams were evaluated using structural measures, by comparison with gold standard taxonomies and by manual quality assessment of novel relations.", "labels": [], "entities": []}], "introductionContent": [{"text": "Taxonomies are useful tools for content organisation, navigation, and retrieval, providing valuable input for semantically intensive tasks such as question answering ( and textual entailment).", "labels": [], "entities": [{"text": "content organisation", "start_pos": 32, "end_pos": 52, "type": "TASK", "confidence": 0.720383495092392}, {"text": "question answering", "start_pos": 147, "end_pos": 165, "type": "TASK", "confidence": 0.8712619543075562}, {"text": "textual entailment)", "start_pos": 172, "end_pos": 191, "type": "TASK", "confidence": 0.7801219324270884}]}, {"text": "In general, a hierarchical relation is any asymmetrical relation that indicates subordination between two terms, but in this task we focus on hyponym-hypernym relations.", "labels": [], "entities": []}, {"text": "Taxonomy learning from text is a challenging task that can be divided in several subtasks, including term extraction, hypernym identification and taxonomy construction.", "labels": [], "entities": [{"text": "Taxonomy learning from text", "start_pos": 0, "end_pos": 27, "type": "TASK", "confidence": 0.9252249896526337}, {"text": "term extraction", "start_pos": 101, "end_pos": 116, "type": "TASK", "confidence": 0.7446354031562805}, {"text": "hypernym identification", "start_pos": 118, "end_pos": 141, "type": "TASK", "confidence": 0.7920845746994019}, {"text": "taxonomy construction", "start_pos": 146, "end_pos": 167, "type": "TASK", "confidence": 0.8644294738769531}]}, {"text": "Existing approaches for hypernym identification from text rely on lexico-syntactic patterns), cooccurrence information, substring inclusion, or exploit semantic relations provided in textual definitions (.", "labels": [], "entities": [{"text": "hypernym identification from text", "start_pos": 24, "end_pos": 57, "type": "TASK", "confidence": 0.8745776563882828}]}, {"text": "This stage usually produces a large number of noisy, inconsistent relations, which assign multiple parents to anode and contain cycles.", "labels": [], "entities": []}, {"text": "Hence, the third stage of taxonomy learning, taxonomy construction, focuses on the overall structure of the resulting graph and aims to organise terms in a hierarchical structure, more specifically a directed acyclic graph ().", "labels": [], "entities": [{"text": "taxonomy construction", "start_pos": 45, "end_pos": 66, "type": "TASK", "confidence": 0.8376109898090363}]}, {"text": "More recently, the hypernym identification subtask has attracted an increased interest from the distributional semantics community (, as part of a wider effort to distinguish between different semantic relations which exist between distributional similar words (.", "labels": [], "entities": [{"text": "hypernym identification subtask", "start_pos": 19, "end_pos": 50, "type": "TASK", "confidence": 0.8099871873855591}]}, {"text": "Although this is a promising direction of research, that addresses some of the limitations of pattern-based approaches, including low coverage of domain-specific terms, most participants in this shared task opted for traditional approaches for hypernym identification, with the exception of one system.", "labels": [], "entities": [{"text": "hypernym identification", "start_pos": 244, "end_pos": 267, "type": "TASK", "confidence": 0.8127586543560028}]}, {"text": "TexEval-2 is mainly concerned with automatically extracting hierarchical relations from text and subsequent taxonomy construction, therefore we make the assumption that a list of terms is readily available.", "labels": [], "entities": [{"text": "TexEval-2", "start_pos": 0, "end_pos": 9, "type": "DATASET", "confidence": 0.9645423889160156}, {"text": "taxonomy construction", "start_pos": 108, "end_pos": 129, "type": "TASK", "confidence": 0.7343201637268066}]}, {"text": "This simplifies evaluation by providing a common ground for all the systems, but participants are allowed to add additional nodes, i.e. terms, in the hierarchy as they consider appropriate.", "labels": [], "entities": []}, {"text": "To avoid the need for term extraction, terms are extracted from existing taxonomies, providing participants with a domain lexicon that has to be organised in a hierarchical structure.", "labels": [], "entities": [{"text": "term extraction", "start_pos": 22, "end_pos": 37, "type": "TASK", "confidence": 0.7173451334238052}]}], "datasetContent": [{"text": "We selected three target domains (i.e. Environment, Food and Science) with three root concepts (i.e. \"environment\", \"food\" and \"science\", respectively).", "labels": [], "entities": []}, {"text": "Then, for each domain we considered different sources for gathering gold standard taxonomies, including a multilingual thesaurus, Eurovoc 1 , a large lexical database of English, WordNet, and a general purpose resource, the Wikipedia Bitaxonomy ().", "labels": [], "entities": [{"text": "Eurovoc 1", "start_pos": 130, "end_pos": 139, "type": "DATASET", "confidence": 0.9200795292854309}, {"text": "WordNet", "start_pos": 179, "end_pos": 186, "type": "DATASET", "confidence": 0.9269700646400452}, {"text": "Wikipedia Bitaxonomy", "start_pos": 224, "end_pos": 244, "type": "DATASET", "confidence": 0.8973042368888855}]}, {"text": "We also considered other domainspecific resources including \"The Google product taxonomy\" 2 for Food, and the \"Taxonomy of Fields and their Subfields\" 3 for Science.", "labels": [], "entities": []}, {"text": "English taxonomies The English gold standard taxonomies are collected from each of the sources described above as follows.", "labels": [], "entities": [{"text": "English gold standard taxonomies", "start_pos": 23, "end_pos": 55, "type": "DATASET", "confidence": 0.79325370490551}]}, {"text": "Gold standards are gathered from WordNet by selecting concepts and relationships in the hypernym-hyponym hierarchy rooted on the corresponding root concept for each domain.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 33, "end_pos": 40, "type": "DATASET", "confidence": 0.9323923587799072}]}, {"text": "Relations extracted from Wikipedia are combined together with relations extracted from domain-specific resources, to obtain high-coverage domain-specific taxonomies.", "labels": [], "entities": []}, {"text": "Hierarchical relations from Eurovoc were used integrally without any modification, but currently Eurovoc covers only the Environment and Science domains.", "labels": [], "entities": [{"text": "Eurovoc", "start_pos": 28, "end_pos": 35, "type": "DATASET", "confidence": 0.9674000144004822}, {"text": "Eurovoc", "start_pos": 97, "end_pos": 104, "type": "DATASET", "confidence": 0.960054874420166}]}, {"text": "It is worth nothing that the English gold standard taxonomies gathered from WordNet and from combined resources were also used as test data in the previous edition of this shared task (.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 76, "end_pos": 83, "type": "DATASET", "confidence": 0.5393156409263611}]}, {"text": "Multilingual taxonomies For the three other languages, the collected English gold standards were manually translated by six linguists (two computational linguists and four master students of the Ghent University Translation, Communication and Interpreting department).", "labels": [], "entities": [{"text": "English gold standards", "start_pos": 69, "end_pos": 91, "type": "DATASET", "confidence": 0.7766567667325338}, {"text": "Ghent University Translation, Communication and Interpreting", "start_pos": 195, "end_pos": 255, "type": "TASK", "confidence": 0.7626948271478925}]}, {"text": "Ina first step, the English term lists were translated in Excel by one annotator per language.", "labels": [], "entities": [{"text": "Excel", "start_pos": 58, "end_pos": 63, "type": "DATASET", "confidence": 0.928472101688385}]}, {"text": "The first annotator was allowed to mark entries that needed to be revised by a second annotator.", "labels": [], "entities": []}, {"text": "In addition, the annotators could make remarks in an additional column.", "labels": [], "entities": []}, {"text": "Some of the English terms could not be properly translated in the specific domain (e.g. \"center\" in the food domain) and were left out.", "labels": [], "entities": []}, {"text": "Ina second step, the translated term lists were used to automatically replace the English terms in the gold standard taxonomies with their corresponding translation.", "labels": [], "entities": []}, {"text": "The translation of English gold standards revealed a number of issues.", "labels": [], "entities": [{"text": "translation", "start_pos": 4, "end_pos": 15, "type": "TASK", "confidence": 0.9837205410003662}, {"text": "English gold standards", "start_pos": 19, "end_pos": 41, "type": "DATASET", "confidence": 0.7646497289339701}]}, {"text": "First of all, some of the translations were near-synonyms in the other language, which eventually lead to cycles in the taxonomy.", "labels": [], "entities": []}, {"text": "Examples in Italian are for instance \"cibo\" (English: food) and \"vitto\" (English: fare) which are in Italian almost synonymous, whereas their English counterparts have a more distinctive meaning.", "labels": [], "entities": []}, {"text": "Another problematic example are the Italian words \"condimento\" (English: seasoning, sauce, dressing) and \"salsa\" (English: dressing, sauce), which can be hypernyms of each other, depending on the exact meaning of the word.", "labels": [], "entities": []}, {"text": "The translated taxonomies also revealed errors in the original English taxonomy, such as for instance \"conserve\" is a kind of \"confiture\", which is incorrect.", "labels": [], "entities": []}, {"text": "shows the resulting number of vertices |V | and edges |E| of the produced gold standard taxonomies for each considered domain, source and language.", "labels": [], "entities": []}, {"text": "We also report structural information about the number of intermediate nodes (#i.i), the number of connected components (#c.c.) and the number of cycles.", "labels": [], "entities": []}, {"text": "Test data for this task consists of six lists of domain-specific terms for each language that were provided to participants as a shared basis to construct the taxonomies.", "labels": [], "entities": []}, {"text": "The initial English taxonomies provide connections from the root node to all the other nodes, as they form one connected component.", "labels": [], "entities": []}, {"text": "As some of the terms did not have a correspondent in all the other languages, some of the translated taxonomies have several components.", "labels": [], "entities": []}, {"text": "This is specifically the case for the food domain that is highly dependent on the language and that shows the largest variation in number of nodes.", "labels": [], "entities": []}, {"text": "For example, 127 terms from the Combined English taxonomy for Food could not be translated into Dutch and 279 terms could not be translated into Italian.", "labels": [], "entities": [{"text": "Combined English taxonomy for Food", "start_pos": 32, "end_pos": 66, "type": "DATASET", "confidence": 0.8183850526809693}]}, {"text": "Additionally, four cycles are erroneously introduced for the WordNet Italian taxonomy for Food, including \"cibo\"-\"vitto\"-\"cibo\" and \"piatto principale\"-\"piatto\"-\"piatto principale\".", "labels": [], "entities": [{"text": "WordNet Italian taxonomy for Food", "start_pos": 61, "end_pos": 94, "type": "DATASET", "confidence": 0.9530290484428405}]}, {"text": "Slight differences exist between the Eurovoc taxonomies constructed for different languages as well, and these taxonomies underwent a thorough review process.", "labels": [], "entities": [{"text": "Eurovoc taxonomies", "start_pos": 37, "end_pos": 55, "type": "DATASET", "confidence": 0.9625420570373535}]}, {"text": "The construction of taxonomies is a challenging task even for humans but evaluating a taxonomy is not a trivial task either.", "labels": [], "entities": []}, {"text": "In this shared task, taxonomies are evaluated through comparison with gold standard relations collected from WordNet and other well known, freely available taxonomies.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 109, "end_pos": 116, "type": "DATASET", "confidence": 0.9641256928443909}]}, {"text": "This is complemented by a manual evaluation of relations that are not covered by the gold standard and through quantitative and qualitative structural analysis of the resulting graph.", "labels": [], "entities": []}, {"text": "The evaluation methodology is sim-: Structural analysis of the submitted taxonomies and the string-based baseline for the monolingual setting ilar to the approach introduced in the first edition of TExEval, with the main difference that we also report separate overall rankings of the participant systems for each of the subtasks.", "labels": [], "entities": [{"text": "TExEval", "start_pos": 198, "end_pos": 205, "type": "DATASET", "confidence": 0.8024085164070129}]}, {"text": "Let S = (V S , E S ) bean output taxonomy produced by a system fora given domain, where V S includes the set of domain concepts initially provided by the task organizers and E S is the set of taxonomy edges extracted by the system.", "labels": [], "entities": []}, {"text": "To broadly analyze the quality of the produced set of hypernymy relationships E S , these results are benchmarked against the string-based baseline described in Section 4.1, using the following evaluation approaches: i) analyse the graph structure and check if the produced taxonomy is a Directed Acyclic Graph (DAG); ii) compare the edges E S , against the set of relations from each type of gold standard; iii) manually validate a sample of novel relationships produced by the system that are not contained in the gold standard.", "labels": [], "entities": []}, {"text": "The final ranking of the systems takes into consideration these three types of evaluation by aggregating the achieved ranks using a voting scheme.", "labels": [], "entities": []}, {"text": "First, the output taxonomies are ranked on the basis of the average performance obtained for each evaluated aspect and for each domain.", "labels": [], "entities": []}, {"text": "The resulting ranks are simply summed up, favoring systems at the top of the ranked list and penalizing systems at the lower end.", "labels": [], "entities": []}, {"text": "Even the most complete and up to date taxonomy can be extended with additional nodes and relations, therefore it is possible for systems to identify correct relations that are not covered by the gold standard.", "labels": [], "entities": []}, {"text": "A problem faced by gold standard evaluation is that these relations are considered incorrect when relying on a direct comparison with the gold standard taxonomy.", "labels": [], "entities": []}, {"text": "This is why we additionally evaluate by hand a subset of new relations proposed by each system to estimate the number of relations in E S that do not belong to E G . Due to limited resources, we extract only a random sample of novel relations from each submission and manually annotate them to compute precision P as: |correctISA|/|sample|.", "labels": [], "entities": [{"text": "precision", "start_pos": 302, "end_pos": 311, "type": "METRIC", "confidence": 0.9907530546188354}, {"text": "correctISA", "start_pos": 319, "end_pos": 329, "type": "METRIC", "confidence": 0.9469699263572693}]}, {"text": "At most 100 relations were evaluated by one annotator for each system, domain, and language fora total of 6200 term pairs.", "labels": [], "entities": []}, {"text": "Two different annotators were tasked to evaluate submissions for the monolingual subtask (English) and for the multilingual subtask (Dutch, French, Italian).", "labels": [], "entities": []}, {"text": "The annotators were provided with a list of term pairs organized by domain and were asked if the relation was a correct ISA relation, if the relation and the terms were domain specific, and if the relation was too generic.", "labels": [], "entities": []}, {"text": "Overall, a relation is considered correct only if it is considered a correct hypernymhyponym relation, if it is relevant for the given domain and not over-generic.", "labels": [], "entities": []}, {"text": "Take for example the following edges from the food domain: (linguine, pasta) and (lemon, food).", "labels": [], "entities": []}, {"text": "Both edges are correct ISA relations and are domain specific, but the second edge is over-generic because lemons can be categorized more precisely as fruits.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Structural measures of gold standard taxonomies, including number of vertices (|V |), edges (|E|), interme- diate nodes (#i.i), connected components (#c.c.) and cycles.", "labels": [], "entities": []}, {"text": " Table 2: Structural analysis of the submitted taxonomies and the string-based baseline for the monolingual setting", "labels": [], "entities": []}, {"text": " Table 3: Gold standard comparison using Fscore and Cumulative F&M measure for the monolingual setting, where B  stands for the string-based baseline", "labels": [], "entities": [{"text": "Fscore", "start_pos": 41, "end_pos": 47, "type": "METRIC", "confidence": 0.990330696105957}, {"text": "Cumulative F&M measure", "start_pos": 52, "end_pos": 74, "type": "METRIC", "confidence": 0.8042045950889587}]}, {"text": " Table 4: Manual evaluation of 100 (at most) randomly selected novel relations based on precision for English", "labels": [], "entities": [{"text": "precision", "start_pos": 88, "end_pos": 97, "type": "METRIC", "confidence": 0.9992048144340515}]}, {"text": " Table 5: Average scores achieved by the systems for the monolingual subtasks.", "labels": [], "entities": [{"text": "Average scores", "start_pos": 10, "end_pos": 24, "type": "METRIC", "confidence": 0.9423140287399292}]}, {"text": " Table 6: Overall ranking of the systems for the monolingual subtasks on Taxonomy Construction (TC) and Hypernym  Indentification (HI).", "labels": [], "entities": [{"text": "Taxonomy Construction (TC)", "start_pos": 73, "end_pos": 99, "type": "TASK", "confidence": 0.779049414396286}]}, {"text": " Table 6. The  scores used to generate the rankings for the Hyper- nym Identification (HI) subtask are mainly the last  three properties, namely the Fscore with the gold  standard, the number of domains, and the precision  from manual evaluation. All the seven taxonomi- cal properties described above are used for ranking  systems for the Taxonomy Construction (TC) sub- task. The TAXI system achieves the best results  based on most of these measures, coming third only  for the categorization property. This brings the sys- tem to the first place both for the Hypernym Iden- tification and the Taxonomy Construction subtasks,  in the monolingual setting. There is a tie with the  USAAR system, but only for the Hypernym Iden- tification subtask. The second placed system is the  QASSIT system, that is ranked on the top three po- sitions for most of the properties with the exception", "labels": [], "entities": [{"text": "Fscore", "start_pos": 149, "end_pos": 155, "type": "METRIC", "confidence": 0.9902037382125854}, {"text": "precision", "start_pos": 212, "end_pos": 221, "type": "METRIC", "confidence": 0.9987504482269287}, {"text": "USAAR", "start_pos": 683, "end_pos": 688, "type": "DATASET", "confidence": 0.9747825264930725}]}, {"text": " Table 7: Average scores of the systems for the multilin- gual subtasks.", "labels": [], "entities": []}, {"text": " Table 8: Overall ranking of the systems for the multilin- gual subtasks on Taxonomy Construction (TC) and Hy- pernym Indentification (HI).", "labels": [], "entities": [{"text": "Taxonomy Construction (TC)", "start_pos": 76, "end_pos": 102, "type": "TASK", "confidence": 0.7503417670726776}, {"text": "Hy- pernym Indentification (HI)", "start_pos": 107, "end_pos": 138, "type": "TASK", "confidence": 0.57407517518316}]}]}