{"title": [{"text": "ICL-HD at SemEval-2016 Task 8: Meaning Representation Parsing - Augmenting AMR Parsing with a Preposition Semantic Role Labeling Neural Network", "labels": [], "entities": [{"text": "Meaning Representation Parsing - Augmenting AMR Parsing", "start_pos": 31, "end_pos": 86, "type": "TASK", "confidence": 0.8030946680477687}]}], "abstractContent": [{"text": "We describe our submission system to the SemEval-2016 Task 8 on Abstract Meaning Representation (AMR) Parsing.", "labels": [], "entities": [{"text": "SemEval-2016 Task 8 on Abstract Meaning Representation (AMR) Parsing", "start_pos": 41, "end_pos": 109, "type": "TASK", "confidence": 0.8470330455086448}]}, {"text": "We attempt to improve AMR parsing by exploiting preposition semantic role labeling information retrieved from a multi-layer feed-forward neu-ral network.", "labels": [], "entities": [{"text": "AMR parsing", "start_pos": 22, "end_pos": 33, "type": "TASK", "confidence": 0.9765702486038208}, {"text": "preposition semantic role labeling information", "start_pos": 48, "end_pos": 94, "type": "TASK", "confidence": 0.6844412088394165}]}, {"text": "Prepositional semantics is included as features into the transition-based AMR parsing system CAMR (Wang, Xue, and S. Pradhan 2015a).", "labels": [], "entities": [{"text": "AMR parsing", "start_pos": 74, "end_pos": 85, "type": "TASK", "confidence": 0.8395215272903442}]}, {"text": "The inclusion of the features modifies the behavior of CAMR when creating meaning representations triggered by prepositional semantics.", "labels": [], "entities": []}, {"text": "Despite the usefulness of preposition semantic role labeling information for AMR parsing, it does not have an impact to the parsing F-score of CAMR, but reduces the parsing recall by 1%.", "labels": [], "entities": [{"text": "preposition semantic role labeling", "start_pos": 26, "end_pos": 60, "type": "TASK", "confidence": 0.6305315494537354}, {"text": "AMR parsing", "start_pos": 77, "end_pos": 88, "type": "TASK", "confidence": 0.960003674030304}, {"text": "parsing", "start_pos": 124, "end_pos": 131, "type": "TASK", "confidence": 0.9484422206878662}, {"text": "F-score", "start_pos": 132, "end_pos": 139, "type": "METRIC", "confidence": 0.8094717264175415}, {"text": "parsing", "start_pos": 165, "end_pos": 172, "type": "TASK", "confidence": 0.9464322924613953}, {"text": "recall", "start_pos": 173, "end_pos": 179, "type": "METRIC", "confidence": 0.9075506925582886}]}], "introductionContent": [{"text": "Progress in Natural Language Processing has led to a multitude of well-motivated tasks that each represent part of a sentence's meaning but result in a meaning description spread over separate, unconnected descriptions.", "labels": [], "entities": []}, {"text": "These separate levels of semantic annotation, like co-reference or named entities, and the lack of simple human-readable corpora where whole sentence meanings are encoded led to the Abstract Meaning Representation (AMR) formalism ().", "labels": [], "entities": [{"text": "Abstract Meaning Representation (AMR) formalism", "start_pos": 182, "end_pos": 229, "type": "TASK", "confidence": 0.761318496295384}]}, {"text": "AMR structures capture sentence meanings with rooted, directed and labeled graphs where sentences with the same meaning receive the same AMR.", "labels": [], "entities": [{"text": "AMR structures capture sentence meanings", "start_pos": 0, "end_pos": 40, "type": "TASK", "confidence": 0.7792401432991027}]}, {"text": "These graphs are encoded in a bracketed format and can be visually represented in a human-understandable way (see).", "labels": [], "entities": []}, {"text": "AMR structures are organized with nodes representing concepts and the semantic relationships that hold between these concepts 1 . Hence, AMRs can be useful for every NLP component that relies on or exploits semantic meaning resources.", "labels": [], "entities": []}, {"text": "Particular application areas are, among others, entity linking (), event detection () and machine translation.", "labels": [], "entities": [{"text": "entity linking", "start_pos": 48, "end_pos": 62, "type": "TASK", "confidence": 0.7950586378574371}, {"text": "event detection", "start_pos": 67, "end_pos": 82, "type": "TASK", "confidence": 0.7664105594158173}, {"text": "machine translation", "start_pos": 90, "end_pos": 109, "type": "TASK", "confidence": 0.844460129737854}]}, {"text": "An example fora AMR graph is given in: there is a concept RECOMMEND-01 which is the root of the graph and there is a concept OFFER-01 that stands in semantic relationship to RECOMMEND-01 with the edge ARG1.", "labels": [], "entities": [{"text": "RECOMMEND-01", "start_pos": 58, "end_pos": 70, "type": "METRIC", "confidence": 0.8656835556030273}, {"text": "OFFER-01", "start_pos": 125, "end_pos": 133, "type": "METRIC", "confidence": 0.9781624674797058}, {"text": "ARG1", "start_pos": 201, "end_pos": 205, "type": "DATASET", "confidence": 0.7320897579193115}]}, {"text": "We augment the existing AMR parser CAMR (Wang, Xue, and S. Pradhan 2015a) with a preposition semantic role labeling (prepSRL) neural network with the intention to improve the AMR graph creation accuracy.", "labels": [], "entities": [{"text": "AMR parser CAMR", "start_pos": 24, "end_pos": 39, "type": "TASK", "confidence": 0.8138081232706705}, {"text": "AMR graph creation", "start_pos": 175, "end_pos": 193, "type": "TASK", "confidence": 0.8680089116096497}, {"text": "accuracy", "start_pos": 194, "end_pos": 202, "type": "METRIC", "confidence": 0.7673229575157166}]}, {"text": "Prepositions in conjunction with their arguments make a crucial contribution to the meaning of sentences and are therefore a very intuitive supplement to AMR parsing.", "labels": [], "entities": [{"text": "AMR parsing", "start_pos": 154, "end_pos": 165, "type": "TASK", "confidence": 0.9512312114238739}]}, {"text": "For example, see how in the meaning of the preposition in is involved in the creation of the AMR edge :LOCA-TION.", "labels": [], "entities": [{"text": "LOCA-TION", "start_pos": 103, "end_pos": 112, "type": "METRIC", "confidence": 0.9777895212173462}]}, {"text": "in semantically expresses the agency's spatial location and therefore triggers the identically named AMR edge :LOCATION.", "labels": [], "entities": [{"text": "AMR edge", "start_pos": 101, "end_pos": 109, "type": "METRIC", "confidence": 0.860522449016571}, {"text": "LOCATION", "start_pos": 111, "end_pos": 119, "type": "METRIC", "confidence": 0.7643446326255798}]}, {"text": "Prepositional semantics is a knowledge resource that has not yet been exploited for the domain of AMR parsing.", "labels": [], "entities": [{"text": "Prepositional semantics", "start_pos": 0, "end_pos": 23, "type": "TASK", "confidence": 0.7880529165267944}, {"text": "AMR parsing", "start_pos": 98, "end_pos": 109, "type": "TASK", "confidence": 0.9736518859863281}]}, {"text": "Moreover, CAMR has problems in correctly creating AMR edges triggered by prepositional relations.", "labels": [], "entities": [{"text": "CAMR", "start_pos": 10, "end_pos": 14, "type": "TASK", "confidence": 0.9167178273200989}, {"text": "AMR edges triggered by prepositional relations", "start_pos": 50, "end_pos": 96, "type": "TASK", "confidence": 0.8408999045689901}]}, {"text": "We should offer earthquake workers our full understanding.", "labels": [], "entities": []}], "datasetContent": [{"text": "We first preprocessed the 16, 831 sentences of the DEFT corpus training section () that we used for training CAMR with the prepSRL features.", "labels": [], "entities": [{"text": "DEFT corpus training section", "start_pos": 51, "end_pos": 79, "type": "DATASET", "confidence": 0.9650911390781403}]}, {"text": "Preprocessing information for the AMR parser includes lemmas, POS tags, named entities and dependency parses . In addition, we preprocessed the training sentences with the ClearNLP toolkit for the training of the neural network.", "labels": [], "entities": [{"text": "AMR parser", "start_pos": 34, "end_pos": 44, "type": "TASK", "confidence": 0.7485829591751099}]}, {"text": "We used the tokenization and POS tag components of ClearNLP and replaced the generated dependencies for compatibility reasons with the dependencies generated by the BLLIP parser.", "labels": [], "entities": [{"text": "ClearNLP", "start_pos": 51, "end_pos": 59, "type": "DATASET", "confidence": 0.9084600210189819}]}, {"text": "After preprocessing, the alignments between the AMR graphs and their sentences were created with the JAMR aligner.", "labels": [], "entities": [{"text": "JAMR", "start_pos": 101, "end_pos": 105, "type": "DATASET", "confidence": 0.8295636177062988}]}, {"text": "ASSERT-generated SRL files were provided to us by Sameer Pradhan for the training and test inputs, enabling us to run CAMR with the SRL features.", "labels": [], "entities": [{"text": "ASSERT-generated SRL", "start_pos": 0, "end_pos": 20, "type": "TASK", "confidence": 0.4399305731058121}]}, {"text": "Separately, the neural network for prepSRL is trained with PTB-style preposition labels.", "labels": [], "entities": []}, {"text": "We parsed our training corpora with the resulting model and generated the feature files for the prepSRL information.", "labels": [], "entities": []}, {"text": "We trained CAMR in four different feature settings that are shown in.", "labels": [], "entities": []}, {"text": "The generated models were tested on the DEFT corpus test set that contains 1371 sentences.", "labels": [], "entities": [{"text": "DEFT corpus test set", "start_pos": 40, "end_pos": 60, "type": "DATASET", "confidence": 0.9832611978054047}]}], "tableCaptions": [{"text": " Table 1: Error analysis of CAMR based on parses of sen-", "labels": [], "entities": [{"text": "Error", "start_pos": 10, "end_pos": 15, "type": "METRIC", "confidence": 0.9532372355461121}, {"text": "CAMR", "start_pos": 28, "end_pos": 32, "type": "TASK", "confidence": 0.8872284889221191}]}, {"text": " Table 2: Preposition Semantic Role Labeling results. Corpus", "labels": [], "entities": [{"text": "Preposition Semantic Role Labeling", "start_pos": 10, "end_pos": 44, "type": "TASK", "confidence": 0.6877821385860443}, {"text": "Corpus", "start_pos": 54, "end_pos": 60, "type": "DATASET", "confidence": 0.9257537126541138}]}, {"text": " Table 4. They reveal that the prepSRL features  have a slightly negative influence on the parsing ac- curacy of CAMR. The Smatch F-score remains the  same over all trained models, but the recall is re- duced by 1% when adding the prepSRL features.  The model with prepSRL achieves a Smatch score  of 0.60 on the SemEval-2016 Task 8 test data. One  possible explanation for the prepSRL results could  be the ambiguity concerned with prepositions:", "labels": [], "entities": [{"text": "F-score", "start_pos": 130, "end_pos": 137, "type": "METRIC", "confidence": 0.5552331209182739}, {"text": "recall", "start_pos": 189, "end_pos": 195, "type": "METRIC", "confidence": 0.9990150928497314}, {"text": "SemEval-2016 Task 8 test data", "start_pos": 313, "end_pos": 342, "type": "DATASET", "confidence": 0.6701687276363373}]}, {"text": " Table 5. If compared with the previous  results in Table 1, the :LOCATION relation shows a  minor improvement of precision and recall, where  all other relations either show no difference or are  parsed worse than before.", "labels": [], "entities": [{"text": "LOCATION", "start_pos": 66, "end_pos": 74, "type": "METRIC", "confidence": 0.9988492727279663}, {"text": "precision", "start_pos": 114, "end_pos": 123, "type": "METRIC", "confidence": 0.9995710253715515}, {"text": "recall", "start_pos": 128, "end_pos": 134, "type": "METRIC", "confidence": 0.9993322491645813}]}]}