{"title": [{"text": "WHUNlp at SemEval-2016 Task DiMSUM: A Pilot Study in Detecting Minimal Semantic Units and their Meanings using Supervised Models", "labels": [], "entities": [{"text": "WHUNlp", "start_pos": 0, "end_pos": 6, "type": "DATASET", "confidence": 0.8752323985099792}, {"text": "SemEval-2016 Task DiMSUM", "start_pos": 10, "end_pos": 34, "type": "TASK", "confidence": 0.8017123540242513}, {"text": "Detecting Minimal Semantic Units and their Meanings", "start_pos": 53, "end_pos": 104, "type": "TASK", "confidence": 0.7611168367522103}]}], "abstractContent": [{"text": "This paper describes our approach towards the SemEval-2016 Task 10: Detecting Minimal Semantic Units and their Meanings (DiM-SUM).", "labels": [], "entities": [{"text": "SemEval-2016 Task 10", "start_pos": 46, "end_pos": 66, "type": "TASK", "confidence": 0.9028924107551575}, {"text": "Detecting Minimal Semantic Units and their Meanings", "start_pos": 68, "end_pos": 119, "type": "TASK", "confidence": 0.8248983451298305}]}, {"text": "We consider that the two problems are similar to multiword expression detection and supersense tagging, respectively.", "labels": [], "entities": [{"text": "multiword expression detection", "start_pos": 49, "end_pos": 79, "type": "TASK", "confidence": 0.7963152527809143}, {"text": "supersense tagging", "start_pos": 84, "end_pos": 102, "type": "TASK", "confidence": 0.7912984490394592}]}, {"text": "The former problem is formalized as a sequence labeling problem solved by first-order CRFs, and the latter one is formalized as a classification problem solved by Maximum Entropy Algorithm.", "labels": [], "entities": [{"text": "sequence labeling", "start_pos": 38, "end_pos": 55, "type": "TASK", "confidence": 0.5850722789764404}]}, {"text": "To carryout our pilot study quickly, we extract some simple features such as words or part-of-speech tags from the training set, and avoid using external resources such as Word-Net or Brown clusters which are allowed in the supervised closed condition.", "labels": [], "entities": [{"text": "Word-Net", "start_pos": 172, "end_pos": 180, "type": "DATASET", "confidence": 0.9422102570533752}]}, {"text": "Experimental results show that much further work on feature engineering and model optimization needs to be explored.", "labels": [], "entities": [{"text": "feature engineering", "start_pos": 52, "end_pos": 71, "type": "TASK", "confidence": 0.8687846064567566}, {"text": "model optimization", "start_pos": 76, "end_pos": 94, "type": "TASK", "confidence": 0.7237044721841812}]}], "introductionContent": [{"text": "In the community of natural language processing, multiword expressions (MWEs) detection) and supersense tagging) have received much research attention due to their various applications such as syntactic parsing), semantic parsing (, and machine translation).", "labels": [], "entities": [{"text": "natural language processing", "start_pos": 20, "end_pos": 47, "type": "TASK", "confidence": 0.6734761397043864}, {"text": "multiword expressions (MWEs) detection", "start_pos": 49, "end_pos": 87, "type": "TASK", "confidence": 0.6945154219865799}, {"text": "supersense tagging", "start_pos": 93, "end_pos": 111, "type": "TASK", "confidence": 0.726225882768631}, {"text": "syntactic parsing", "start_pos": 193, "end_pos": 210, "type": "TASK", "confidence": 0.7405174374580383}, {"text": "semantic parsing", "start_pos": 213, "end_pos": 229, "type": "TASK", "confidence": 0.7978285551071167}, {"text": "machine translation", "start_pos": 237, "end_pos": 256, "type": "TASK", "confidence": 0.8027209341526031}]}, {"text": "However, not much attention has been paid to the relationship between MWEs and supersenses (.", "labels": [], "entities": []}, {"text": "Input: Security N OU N increased V ERB in ADP Mumbai P ROP N amid ADP terror N OU N threats N OU N ahead ADP of ADP Ganeshotsav P ROP N Output: Security n.state increased v.change in Mumbai n.location amid terror threats n.communication ahead of Ganeshotsav n.event: An DiMSUM Example.", "labels": [], "entities": [{"text": "V ERB", "start_pos": 33, "end_pos": 38, "type": "METRIC", "confidence": 0.8307107090950012}]}, {"text": "Given a tokenized and POS-tagged sentence, outputs will be a representation annotated with MWEs and supersenses.", "labels": [], "entities": []}, {"text": "Noun and verb supersenses start with \"n.\" and \"v.\", respectively.", "labels": [], "entities": []}, {"text": "\" \" joins tokens within a MWE.", "labels": [], "entities": []}, {"text": "The DiMSUM shared task ( at SemEval 2016 aims to predict a broad-coverage representation of lexical semantics giving an English sentence.", "labels": [], "entities": []}, {"text": "This representation consists of two facets: a segmentation into minimal semantic units, and a labeling of some of those units with semantic classes.", "labels": [], "entities": []}, {"text": "Based on the task descriptions, we consider the concepts of minimal semantic units and semantic classes are identical to those of MWEs and supersenses, respectively.", "labels": [], "entities": []}, {"text": "shows an input example and its corresponding outputs of DiMSUM task.", "labels": [], "entities": []}, {"text": "Prior work on MWE detection using unsupervised methods includes lexicon lookup, statistical association measures (, parallel corpora (Tsvetkov and Wintner, 2010), or hybrid methods).", "labels": [], "entities": [{"text": "MWE detection", "start_pos": 14, "end_pos": 27, "type": "TASK", "confidence": 0.9920001924037933}]}, {"text": "More sophisticated methods use supervised techniques such as conditional random fields (CRFs) ( or structured perceptron 918 (, and usually achieve better performance.", "labels": [], "entities": []}, {"text": "Compared to most aforementioned systems, MWEs in the DiMSUM task maybe not contiguous or restricted by syntactic construction, which increases the detection difficulty.", "labels": [], "entities": []}, {"text": "Supersense tagging has been studied on diverse languages such as English (,), Chinese (Qiu et al., 2011) and Arabic (.", "labels": [], "entities": [{"text": "Supersense tagging", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.8054119050502777}]}, {"text": "It is usually formalized as a multi-classification problem solved by supervised approaches such as perceptron.", "labels": [], "entities": []}, {"text": "In the DiM-SUM task, both single-word and multiword expressions that holistically function as noun or verb, can be considered as units for supersense tagging.", "labels": [], "entities": [{"text": "supersense tagging", "start_pos": 139, "end_pos": 157, "type": "TASK", "confidence": 0.7271165251731873}]}, {"text": "Following prior work using supervised approaches, we divide DiMSUM task into two subtasks: first, MWEs detection is treated as a sequence labeling task using first-order CRFs; second, supersense tagging is treated as a multi-classification task using Maximum Entropy Algorithm.", "labels": [], "entities": [{"text": "MWEs detection", "start_pos": 98, "end_pos": 112, "type": "TASK", "confidence": 0.9573252201080322}, {"text": "supersense tagging", "start_pos": 184, "end_pos": 202, "type": "TASK", "confidence": 0.7356502711772919}]}, {"text": "We focus on the supervised closed condition, so only the training set are used for training both submodels separately.", "labels": [], "entities": []}, {"text": "Then results generated on the test set are submitted for official evaluation.", "labels": [], "entities": []}, {"text": "The evaluation results show that our system performance are not as good as those of other teams, since we leverage only some simple features such as words, POS, etc.", "labels": [], "entities": []}, {"text": "Syntactic features and semantic resources such as WordNet and Brown clusters are not used.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 50, "end_pos": 57, "type": "DATASET", "confidence": 0.9591183066368103}]}, {"text": "This suggests that further work needs to be done on feature engineering and model optimization.", "labels": [], "entities": [{"text": "feature engineering", "start_pos": 52, "end_pos": 71, "type": "TASK", "confidence": 0.8630509078502655}, {"text": "model optimization", "start_pos": 76, "end_pos": 94, "type": "TASK", "confidence": 0.7901172935962677}]}], "datasetContent": [{"text": "There are three conditions in the DiMSUM 1 shared task at SemEval 2016.", "labels": [], "entities": [{"text": "DiMSUM 1 shared task at SemEval 2016", "start_pos": 34, "end_pos": 70, "type": "TASK", "confidence": 0.6015514305659703}]}, {"text": "In the supervised closed condition, only the training set, WordNet and Brown clusters are allowed to be used.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 59, "end_pos": 66, "type": "DATASET", "confidence": 0.9719139933586121}]}, {"text": "In the semisupervised closed condition, all of the above are permitted, plus the Yelp Academic Dataset.", "labels": [], "entities": [{"text": "Yelp Academic Dataset", "start_pos": 81, "end_pos": 102, "type": "DATASET", "confidence": 0.9504447976748148}]}, {"text": "In the open condition, all available resources can be used.", "labels": [], "entities": []}, {"text": "We carryout our experiments according to the demands in the supervised closed condition, but WordNet and Brown clusters are not used.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 93, "end_pos": 100, "type": "DATASET", "confidence": 0.9776062965393066}]}, {"text": "The test set consists of 16,500 words in 1,000 English sentences which are drawn from the following sources: reviews from the TrustPilot corpus (, tweets from the Tweebank corpus (), TED talks from the WIT3 archive (.", "labels": [], "entities": [{"text": "TrustPilot corpus", "start_pos": 126, "end_pos": 143, "type": "DATASET", "confidence": 0.9608144164085388}, {"text": "Tweebank corpus", "start_pos": 163, "end_pos": 178, "type": "DATASET", "confidence": 0.8895643055438995}, {"text": "WIT3 archive", "start_pos": 202, "end_pos": 214, "type": "DATASET", "confidence": 0.9610280096530914}]}, {"text": "During the development period, we split 30% data from the training set as our development set and use the remainder for training.", "labels": [], "entities": []}, {"text": "The maximum training iteration is set as 500.", "labels": [], "entities": []}, {"text": "The evaluation scripts (v1.5) released by task organizers are used for tuning parameters and features.", "labels": [], "entities": []}, {"text": "During the official evaluation period, we use all the training set to train our CRF and Maximum Entropy models, and prediction results on the test set are submitted.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Feature templates for MWE Detection.", "labels": [], "entities": [{"text": "MWE Detection", "start_pos": 32, "end_pos": 45, "type": "TASK", "confidence": 0.9333972334861755}]}, {"text": " Table 3: Feature templates for Supersense Tagging.  swe or mwe denotes a single or multiple word ex- pression. mwe i , mwe i\u22121 and mwe i+1 denote curren- t, previous and next multiple word expressions, re- spectively. w 1 w 2 ...w n and t 1 t 2 ...t n denote word and  POS combinations, respectively.", "labels": [], "entities": [{"text": "Supersense Tagging", "start_pos": 32, "end_pos": 50, "type": "TASK", "confidence": 0.8885191082954407}]}, {"text": " Table 4: Subtable (a) and (b) dennote contribution- s of features in Table 1 and 3, respectively. \"+\"  denotes that only the feature in the current line is  added. The numbers in the first column correspond  to the ones in Table 1 and 3, respectively.", "labels": [], "entities": [{"text": "dennote contribution- s", "start_pos": 31, "end_pos": 54, "type": "METRIC", "confidence": 0.9426979869604111}]}, {"text": " Table 5: Official Evaluation Results (in %) of DiMSUM 2016.", "labels": [], "entities": [{"text": "DiMSUM 2016", "start_pos": 48, "end_pos": 59, "type": "DATASET", "confidence": 0.7588310241699219}]}, {"text": " Table 6: Expanded Feature templates and their im- proved performance on the development set. w i de- notes the current word and t i denotes the POS of cur- rent word. swe i or mwe i denotes the current single  or multiple word expression.", "labels": [], "entities": [{"text": "POS", "start_pos": 145, "end_pos": 148, "type": "METRIC", "confidence": 0.9756229519844055}]}, {"text": " Table 7: Top 10 false positive and false negative  patterns for MWE detection.", "labels": [], "entities": [{"text": "MWE detection", "start_pos": 65, "end_pos": 78, "type": "TASK", "confidence": 0.9881643652915955}]}, {"text": " Table 8: Top 10 false positive and false negative  supersenses.", "labels": [], "entities": []}]}