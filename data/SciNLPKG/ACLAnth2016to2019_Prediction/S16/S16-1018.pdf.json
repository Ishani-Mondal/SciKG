{"title": [{"text": "PUT at SemEval-2016 Task 4: The ABC of Twitter Sentiment Analysis", "labels": [], "entities": [{"text": "PUT", "start_pos": 0, "end_pos": 3, "type": "METRIC", "confidence": 0.8903920650482178}, {"text": "Twitter Sentiment Analysis", "start_pos": 39, "end_pos": 65, "type": "TASK", "confidence": 0.6199311514695486}]}], "abstractContent": [{"text": "This paper describes a classification system that participated in SemEval-2016 Task 4: Sentiment Analysis in Twitter.", "labels": [], "entities": [{"text": "SemEval-2016 Task 4", "start_pos": 66, "end_pos": 85, "type": "TASK", "confidence": 0.8450946609179179}, {"text": "Sentiment Analysis in Twitter", "start_pos": 87, "end_pos": 116, "type": "TASK", "confidence": 0.8584823310375214}]}, {"text": "The proposed approach competed in subtasks A, B, and C, which involved tweet polarity classification, tweet classification according to a two-point scale, and tweet classification according to a five-point scale.", "labels": [], "entities": [{"text": "tweet polarity classification", "start_pos": 71, "end_pos": 100, "type": "TASK", "confidence": 0.792863130569458}, {"text": "tweet classification", "start_pos": 102, "end_pos": 122, "type": "TASK", "confidence": 0.6772849857807159}, {"text": "tweet classification", "start_pos": 159, "end_pos": 179, "type": "TASK", "confidence": 0.7164139598608017}]}, {"text": "Our system is based on an ensemble consisting of Random Forests, SVMs, and Gradient Boosting Trees, and involves the use of a wide range of features including: n-grams, Brown clustering, sentiment lexicons, Wordnet, and part-of-speech tagging.", "labels": [], "entities": [{"text": "Wordnet", "start_pos": 207, "end_pos": 214, "type": "DATASET", "confidence": 0.898218035697937}, {"text": "part-of-speech tagging", "start_pos": 220, "end_pos": 242, "type": "TASK", "confidence": 0.6759311407804489}]}, {"text": "The proposed system achieved 14 th , 6 th , and 3 rd place in subtasks A, B, and C, respectively.", "labels": [], "entities": []}], "introductionContent": [{"text": "In recent years, sentiment analysis ( has become a common yardstick for many new text mining algorithms.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 17, "end_pos": 35, "type": "TASK", "confidence": 0.9683369398117065}, {"text": "text mining", "start_pos": 81, "end_pos": 92, "type": "TASK", "confidence": 0.818057119846344}]}, {"text": "This trend is a direct result of the rapid growth of social media, where users express their views and opinions regarding a wide range of topics.", "labels": [], "entities": []}, {"text": "As a result, social networks like Twitter have become a crucial resource in product design, assessing marketing campaigns, and detecting news bursts (.", "labels": [], "entities": [{"text": "detecting news bursts", "start_pos": 127, "end_pos": 148, "type": "TASK", "confidence": 0.8491275707880656}]}, {"text": "However, while the merits of resources such as Twitter are evident, there are several difficulties with the use of social media data.", "labels": [], "entities": []}, {"text": "In contrast to classical sentiment analysis methods, which were originally designed for dealing with well-written product reviews, texts from social media often contain misspellings, letter substitutions, ambiguities, nonstandard abbreviations, and improper use of grammar (.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 25, "end_pos": 43, "type": "TASK", "confidence": 0.923088401556015}]}, {"text": "Furthermore, resources such as Twitter generate thousands of new texts per second and introduce challenges characteristic for stream processing ().", "labels": [], "entities": []}, {"text": "Moreover, the limited length of these texts makes classical ngram feature vectors extremely sparse, which in turn hinders generalization abilities of classification algorithms.", "labels": [], "entities": []}, {"text": "Finally, sentiments are usually unevenly distributed (), resulting in class imbalance and, therefore, additional difficulties for classifiers.", "labels": [], "entities": []}, {"text": "To promote research in this area, Task 4 of SemEval-2016 was devoted to sentiment analysis in Twitter.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 72, "end_pos": 90, "type": "TASK", "confidence": 0.9241677820682526}]}, {"text": "The task consisted of five subtasks involving standard classification, ordinal classification, and distribution estimation; fora more detailed description see (.", "labels": [], "entities": [{"text": "ordinal classification", "start_pos": 71, "end_pos": 93, "type": "TASK", "confidence": 0.7338697910308838}, {"text": "distribution estimation", "start_pos": 99, "end_pos": 122, "type": "TASK", "confidence": 0.7557686269283295}]}, {"text": "In this paper, we present our approach to learn a classification system which participated in subtasks A, B, and C of SemEval-2016 Sentiment Analysis in Twitter.", "labels": [], "entities": [{"text": "SemEval-2016 Sentiment Analysis", "start_pos": 118, "end_pos": 149, "type": "TASK", "confidence": 0.7595800161361694}]}, {"text": "The proposed approach combines Random Forests, Support Vector Machines, and Gradient Boosting Trees, trained on a wide range of lexical and semantic features including: n-grams, kgrams, Brown clustering, sentiment lexicons, SentiWordNet, and part of speech tagged 1-grams.", "labels": [], "entities": []}, {"text": "These components were carefully combined and optimized to create a separate version of the system for each of the tackled subtasks.", "labels": [], "entities": []}, {"text": "In the following sections, we describe each group of features used in our system.", "labels": [], "entities": []}, {"text": "Moreover, we explain the details of the proposed classification algorithm with respect to each realized subtask.", "labels": [], "entities": []}, {"text": "Finally, we conclude the paper with a discussion on the ob-tained results, importance of each feature group, and possible lines of future research.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Overall performance of the system.", "labels": [], "entities": []}, {"text": " Table 2: Relative feature importances (%) of top 15 features.", "labels": [], "entities": [{"text": "Relative feature importances", "start_pos": 10, "end_pos": 38, "type": "METRIC", "confidence": 0.9510275522867838}]}, {"text": " Table 3: Relative feature importances (%) for features groups.", "labels": [], "entities": [{"text": "Relative feature importances", "start_pos": 10, "end_pos": 38, "type": "METRIC", "confidence": 0.9418421785036722}]}]}