{"title": [{"text": "LIMSI-COT at SemEval-2016 Task 12: Temporal relation identification using a pipeline of classifiers", "labels": [], "entities": [{"text": "SemEval-2016 Task 12", "start_pos": 13, "end_pos": 33, "type": "TASK", "confidence": 0.5254758795102438}, {"text": "Temporal relation identification", "start_pos": 35, "end_pos": 67, "type": "TASK", "confidence": 0.9070024291674296}]}], "abstractContent": [{"text": "SemEval 2016 Task 12 addresses temporal reasoning in the clinical domain.", "labels": [], "entities": [{"text": "SemEval 2016 Task 12", "start_pos": 0, "end_pos": 20, "type": "DATASET", "confidence": 0.7001320272684097}]}, {"text": "In this paper, we present our participation for relation extraction based on gold standard entities (sub-tasks DR and CR).", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 48, "end_pos": 67, "type": "TASK", "confidence": 0.8991170525550842}]}, {"text": "We used a supervised approach comparing plain lexical features to word embeddings for temporal relation identification , and obtained above-median scores.", "labels": [], "entities": [{"text": "temporal relation identification", "start_pos": 86, "end_pos": 118, "type": "TASK", "confidence": 0.6574803988138834}]}], "introductionContent": [{"text": "SemEval 2016 Task 12 offers 6 subtasks addressing temporal reasoning in the clinical domain using the THYME corpus).", "labels": [], "entities": [{"text": "SemEval 2016 Task 12", "start_pos": 0, "end_pos": 20, "type": "DATASET", "confidence": 0.7875014394521713}, {"text": "THYME corpus", "start_pos": 102, "end_pos": 114, "type": "DATASET", "confidence": 0.8626924455165863}]}, {"text": "This corpus provides annotated clinical and pathological notes from colon cancer patients.", "labels": [], "entities": []}, {"text": "The first group of subtasks concerns the identification of time and event expressions within raw text.", "labels": [], "entities": [{"text": "identification of time and event expressions within raw text", "start_pos": 41, "end_pos": 101, "type": "TASK", "confidence": 0.8106846809387207}]}, {"text": "The second group of subtasks deals with the identification of temporal relations.", "labels": [], "entities": [{"text": "identification of temporal relations", "start_pos": 44, "end_pos": 80, "type": "TASK", "confidence": 0.8672446310520172}]}, {"text": "The latter consists of two subtasks.", "labels": [], "entities": []}, {"text": "In the Document Creation Time Relation subtask (DR), participants are challenged to identify relations between the events and the document creation time.", "labels": [], "entities": [{"text": "Document Creation Time Relation subtask (DR)", "start_pos": 7, "end_pos": 51, "type": "TASK", "confidence": 0.8063285499811172}]}, {"text": "For the Container Relation subtask (CR), participants have to identity container relations between entities.", "labels": [], "entities": [{"text": "Container Relation subtask (CR)", "start_pos": 8, "end_pos": 39, "type": "TASK", "confidence": 0.8397945066293081}]}, {"text": "Participants may submit either a complete system extracting entities and relations or focus on either the entity extraction or relation extraction (using the gold standard entities provided by the organizers).", "labels": [], "entities": [{"text": "entity extraction", "start_pos": 106, "end_pos": 123, "type": "TASK", "confidence": 0.7515436410903931}, {"text": "relation extraction", "start_pos": 127, "end_pos": 146, "type": "TASK", "confidence": 0.721551701426506}]}, {"text": "More details about the task and the definition of each subtask can be found in.", "labels": [], "entities": []}, {"text": "In this paper, we present our submission for the CR and DR subtasks based on gold-standard entities (phase 2).", "labels": [], "entities": [{"text": "DR", "start_pos": 56, "end_pos": 58, "type": "METRIC", "confidence": 0.6177861094474792}]}, {"text": "Our global approach, which is illustrated in, tackles the identification of temporal relations as a set of supervised classification tasks.", "labels": [], "entities": []}, {"text": "We submitted two runs, one using plain lexical features and one using word embeddings computed on a large clinical corpus.", "labels": [], "entities": []}, {"text": "We obtained scores well above the median scores in both subtasks.", "labels": [], "entities": []}, {"text": "The remainder of this paper is organized as follows.", "labels": [], "entities": []}, {"text": "Section 2 presents our system for the DR subtask while Section 3 describes our system for the CR subtask.", "labels": [], "entities": [{"text": "DR subtask", "start_pos": 38, "end_pos": 48, "type": "DATASET", "confidence": 0.9526190459728241}, {"text": "CR subtask", "start_pos": 94, "end_pos": 104, "type": "DATASET", "confidence": 0.9083935916423798}]}, {"text": "Section 4 gives an overview of the system implementation.", "labels": [], "entities": []}, {"text": "Finally, Section 5 presents our results.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: CONTAINS relations according to", "labels": [], "entities": [{"text": "CONTAINS", "start_pos": 10, "end_pos": 18, "type": "TASK", "confidence": 0.694764256477356}]}, {"text": " Table 2: Machine learning algorithms and parameters used for the final submission", "labels": [], "entities": []}, {"text": " Table 3: DCT and CONTAINER model accuracies", "labels": [], "entities": [{"text": "DCT", "start_pos": 10, "end_pos": 13, "type": "TASK", "confidence": 0.5462687015533447}, {"text": "CONTAINER model accuracies", "start_pos": 18, "end_pos": 44, "type": "METRIC", "confidence": 0.7235895991325378}]}, {"text": " Table 4: DR subtask -Evaluation script output", "labels": [], "entities": []}]}