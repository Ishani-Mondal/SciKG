{"title": [{"text": "Driving inversion transduction grammar induction with semantic evaluation", "labels": [], "entities": [{"text": "Driving inversion transduction grammar induction", "start_pos": 0, "end_pos": 48, "type": "TASK", "confidence": 0.6460756957530975}]}], "abstractContent": [{"text": "We describe anew technique for improving statistical machine translation training by adopting scores from a recent crosslin-gual semantic frame based evaluation metric , XMEANT, as outside probabilities in expectation-maximization based ITG (inversion transduction grammars) alignment.", "labels": [], "entities": [{"text": "statistical machine translation training", "start_pos": 41, "end_pos": 81, "type": "TASK", "confidence": 0.7782058492302895}]}, {"text": "Our new approach strongly biases early-stage SMT learning towards semantically valid alignments.", "labels": [], "entities": [{"text": "SMT learning", "start_pos": 45, "end_pos": 57, "type": "TASK", "confidence": 0.9399000406265259}]}, {"text": "Unlike previous attempts that have proposed using semantic frame based evaluation metrics as the objective function for late-stage tuning of less than a dozen loglinear mixture weights, our approach instead applies the semantic metric atone of the earliest stages of SMT training, where it may impact millions of model parameters.", "labels": [], "entities": [{"text": "SMT training", "start_pos": 267, "end_pos": 279, "type": "TASK", "confidence": 0.9276866614818573}]}, {"text": "The choice of XMEANT is motivated by empirical studies that have shown ITG constraints to cover almost all crosslingual semantic frame alternations, which resemble the crosslingual semantic frame matching measured by XMEANT.", "labels": [], "entities": []}, {"text": "Our experiments purposely restrict training data to small amounts to show the technique's utility in the absence of a huge corpus, to study the effects of semantic generalizations while avoiding overreliance on mem-orization.", "labels": [], "entities": []}, {"text": "Results show that directly driving ITG training with the crosslingual semantic frame based objective function not only helps to further sharpen the ITG constraints , but still avoids excising relevant portions of the search space, and leads to better performance than either conventional ITG or GIZA++ based approaches.", "labels": [], "entities": []}], "introductionContent": [{"text": "We propose anew technique that biases early stage statistical machine translation (SMT) learning towards semantics.", "labels": [], "entities": [{"text": "statistical machine translation (SMT) learning", "start_pos": 50, "end_pos": 96, "type": "TASK", "confidence": 0.8102804975850242}]}, {"text": "Our algorithm adopts the crosslingual evaluation metric XMEANT ) to initialize expectation-maximization (EM) outside probabilities during inversion transduction grammar or ITG (Wu, 1997) induction.", "labels": [], "entities": [{"text": "expectation-maximization (EM)", "start_pos": 79, "end_pos": 108, "type": "METRIC", "confidence": 0.7029770314693451}]}, {"text": "We show that injecting a crosslingual semantic frame based objective function in the actual learning of the translation model helps to bias the training of the SMT model towards semantically more relevant structures.", "labels": [], "entities": [{"text": "SMT", "start_pos": 160, "end_pos": 163, "type": "TASK", "confidence": 0.9870163798332214}]}, {"text": "Our approach is highly motivated by recent research which showed that including a semantic frame based objective function during the formal feature weights tuning stage increases the translation quality.", "labels": [], "entities": []}, {"text": "More precisely,; ;;  showed that tuning against a semantic frame based evaluation metric like MEANT , improves the translation adequacy.", "labels": [], "entities": [{"text": "MEANT", "start_pos": 94, "end_pos": 99, "type": "METRIC", "confidence": 0.7625561952590942}]}, {"text": "Our choice to improve ITG alignments is motivated by the fact that they have already previously been empirically shown to cover essentially 100% of crosslingual semantic frame alternations, even though they rule out the majority of incorrect alignments.", "labels": [], "entities": [{"text": "ITG alignments", "start_pos": 22, "end_pos": 36, "type": "TASK", "confidence": 0.7296919226646423}]}, {"text": "Our technique uses XMEANT for rewarding good translations while learning bilingual correlations of the translation model.", "labels": [], "entities": []}, {"text": "We also show that integrating a semantic frame based objective function much earlier in the training pipeline not only produces more semantically correct alignments but also helps to learn bilingual correlations without memorizing from a huge amounts of parallel corpora.", "labels": [], "entities": []}, {"text": "We report results and examples showing that this way for inducing ITGs gives a better translation quality compared to the conventional ITGs and GIZA++ ) alignments.", "labels": [], "entities": [{"text": "translation", "start_pos": 86, "end_pos": 97, "type": "TASK", "confidence": 0.9198443293571472}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Comparison of translation quality for three methods used to train Moses for Chinese-English  MT under small corpus IWSLT 2007 conditions  cased  uncased  System  BLEU TER BLEU TER  Giza++ based induction  19.23 63.94 19.83 63.40  ITG based induction  20.05 63.19 20.42 62.61  XMEANT outside probabilities based 27.59 59.48 28.54 58.81", "labels": [], "entities": [{"text": "MT", "start_pos": 103, "end_pos": 105, "type": "TASK", "confidence": 0.8217485547065735}, {"text": "IWSLT 2007", "start_pos": 125, "end_pos": 135, "type": "DATASET", "confidence": 0.9065360128879547}, {"text": "BLEU TER BLEU TER", "start_pos": 172, "end_pos": 189, "type": "METRIC", "confidence": 0.8534432798624039}, {"text": "XMEANT", "start_pos": 286, "end_pos": 292, "type": "METRIC", "confidence": 0.973630428314209}]}]}