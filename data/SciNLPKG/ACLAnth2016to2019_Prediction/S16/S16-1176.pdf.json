{"title": [{"text": "RIGA at SemEval-2016 Task 8: Impact of Smatch Extensions and Character-Level Neural Translation on AMR Parsing Accuracy", "labels": [], "entities": [{"text": "Character-Level Neural Translation", "start_pos": 61, "end_pos": 95, "type": "TASK", "confidence": 0.641300787528356}, {"text": "AMR Parsing Accuracy", "start_pos": 99, "end_pos": 119, "type": "TASK", "confidence": 0.8496347467104594}]}], "abstractContent": [{"text": "Two extensions to the AMR smatch scoring script are presented.", "labels": [], "entities": [{"text": "AMR smatch scoring", "start_pos": 22, "end_pos": 40, "type": "TASK", "confidence": 0.6368027528127035}]}, {"text": "The first extension combines the smatch scoring script with the C6.0 rule-based classifier to produce a human-readable report on the error patterns frequency observed in the scored AMR graphs.", "labels": [], "entities": []}, {"text": "This first extension results in 4% gain over the state-of-art CAMR baseline parser by adding to it a manually crafted wrapper fixing the identified CAMR parser errors.", "labels": [], "entities": [{"text": "CAMR baseline parser", "start_pos": 62, "end_pos": 82, "type": "TASK", "confidence": 0.593480626742045}]}, {"text": "The second extension combines a per-sentence smatch with an ensemble method for selecting the best AMR graph among the set of AMR graphs for the same sentence.", "labels": [], "entities": []}, {"text": "This second modification automatically yields further 0.4% gain when applied to outputs of two nondeterministic AMR parsers: a CAMR+wrapper parser and a novel character-level neural translation AMR parser.", "labels": [], "entities": [{"text": "AMR parsers", "start_pos": 112, "end_pos": 123, "type": "TASK", "confidence": 0.9132855832576752}]}, {"text": "For AMR parsing task the character-level neu-ral translation attains surprising 7% gain over the carefully optimized word-level neural translation.", "labels": [], "entities": [{"text": "AMR parsing", "start_pos": 4, "end_pos": 15, "type": "TASK", "confidence": 0.966177225112915}, {"text": "character-level neu-ral translation", "start_pos": 25, "end_pos": 60, "type": "TASK", "confidence": 0.5525422592957815}, {"text": "word-level neural translation", "start_pos": 117, "end_pos": 146, "type": "TASK", "confidence": 0.6125624378522238}]}, {"text": "Overall, we achieve smatch F1=62% on the SemEval-2016 official scoring set and F1=67% on the LDC2015E86 test set.", "labels": [], "entities": [{"text": "F1", "start_pos": 27, "end_pos": 29, "type": "METRIC", "confidence": 0.9856227040290833}, {"text": "SemEval-2016 official scoring set", "start_pos": 41, "end_pos": 74, "type": "DATASET", "confidence": 0.8812575489282608}, {"text": "F1", "start_pos": 79, "end_pos": 81, "type": "METRIC", "confidence": 0.9996705055236816}, {"text": "LDC2015E86 test set", "start_pos": 93, "end_pos": 112, "type": "DATASET", "confidence": 0.9825892051060995}]}], "introductionContent": [{"text": "Abstract Meaning Representation (AMR) () initially was envisioned as an intermediate representation for semantic machine translation, but has found applications in other NLP fields such as information extraction.", "labels": [], "entities": [{"text": "Abstract Meaning Representation (AMR)", "start_pos": 0, "end_pos": 37, "type": "TASK", "confidence": 0.8531311253706614}, {"text": "semantic machine translation", "start_pos": 104, "end_pos": 132, "type": "TASK", "confidence": 0.648469090461731}, {"text": "information extraction", "start_pos": 189, "end_pos": 211, "type": "TASK", "confidence": 0.874912828207016}]}, {"text": "Available at http://c60.ailab.lv For SemEval-2016 Task 8 on Meaning Representation Parsing we took a dual approach: besides developing our own neural AMR parser, we also extended the AMR smatch scoring tool ) with a rule-based C6.0 classifier 1 to guide development of an accuracy-increasing wrapper for the state-of-art AMR parser CAMR (.", "labels": [], "entities": [{"text": "SemEval-2016 Task 8 on Meaning Representation Parsing", "start_pos": 37, "end_pos": 90, "type": "TASK", "confidence": 0.7756658622196743}, {"text": "AMR parser", "start_pos": 150, "end_pos": 160, "type": "TASK", "confidence": 0.7453183531761169}, {"text": "accuracy-increasing", "start_pos": 272, "end_pos": 291, "type": "METRIC", "confidence": 0.9964538812637329}, {"text": "AMR parser CAMR", "start_pos": 321, "end_pos": 336, "type": "TASK", "confidence": 0.796615481376648}]}, {"text": "A minor gain was also achieved by combining these two approaches in an ensemble.", "labels": [], "entities": []}, {"text": "The paper starts with the description of our smatch extensions, followed by the description of our AMR parser and wrapper, and concludes with the results section evaluating the contributions of described techniques to our final SemEval result.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": []}