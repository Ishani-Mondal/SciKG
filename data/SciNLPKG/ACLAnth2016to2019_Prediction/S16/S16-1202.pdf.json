{"title": [{"text": "NUIG-UNLP at SemEval-2016 Task 13: A Simple Word Embedding-based Approach for Taxonomy Extraction", "labels": [], "entities": [{"text": "NUIG-UNLP at SemEval-2016 Task 13", "start_pos": 0, "end_pos": 33, "type": "DATASET", "confidence": 0.6658519506454468}, {"text": "Taxonomy Extraction", "start_pos": 78, "end_pos": 97, "type": "TASK", "confidence": 0.7944449186325073}]}], "abstractContent": [{"text": "This paper describes the NUIG-UNLP system submitted to SemEval-2016, Task 13.", "labels": [], "entities": []}, {"text": "We implement a semi-supervised method that extracts hypernym candidates for the terms provided in the test list.", "labels": [], "entities": []}, {"text": "The main assumption of our system is that hypernyms maybe induced by adding a vector offset to the corresponding hyponym word embedding.", "labels": [], "entities": []}, {"text": "The vector offset is obtained as the average offset between 200 pairs of hyponym-hypernym in the same vector space.", "labels": [], "entities": []}, {"text": "Our approach ranked second on connectivity (c.c.) and categorisation (i.i.) for the English taxonomy construction, and fifth on the overall ranking.", "labels": [], "entities": []}, {"text": "Despite of these modest results, our system achieved comparable evaluations scores with the other participants.", "labels": [], "entities": []}], "introductionContent": [{"text": "Hyponyms and hypernyms (sometimes called subordinate and superordinate terms, respectively) describe a type of relation which, in general, can be defined in terms of asymmetric entailment: given the hyponym of feline, cat, and its hypernym, feline, we can state that all cats are felines, but not that all felines are cats.", "labels": [], "entities": []}, {"text": "Likewise, the relations that hyponyms and hypernyms signal can also be characterized as a isa relation between a hyponym X and hypernym Y : for nouns, X is a Kind of Y or X is a type of Y (Saint-).", "labels": [], "entities": []}, {"text": "These particular type / kind-of relations form the backbone of the construction of Lexical Taxonomies and Ontologies, and those in turn plays a essential role in many Natural Language Processing applications: Question Answering, Textual Entailment, Natural Language Inference, or Text Summarization (.", "labels": [], "entities": [{"text": "Question Answering", "start_pos": 209, "end_pos": 227, "type": "TASK", "confidence": 0.8670457005500793}, {"text": "Textual Entailment", "start_pos": 229, "end_pos": 247, "type": "TASK", "confidence": 0.751604288816452}, {"text": "Natural Language Inference", "start_pos": 249, "end_pos": 275, "type": "TASK", "confidence": 0.6124631861845652}, {"text": "Text Summarization", "start_pos": 280, "end_pos": 298, "type": "TASK", "confidence": 0.7747431993484497}]}, {"text": "In this regard, despite the fact that taxonomy construction can be addressed from a diversity of approaches, the lexico-syntactic patterns-based are still the most widely used.", "labels": [], "entities": [{"text": "taxonomy construction", "start_pos": 38, "end_pos": 59, "type": "TASK", "confidence": 0.9182880818843842}]}, {"text": "Nevertheless, in the last years some vector space-based approaches have emerged for learning semantic hierarchies (.", "labels": [], "entities": []}, {"text": "In the next sections we will mainly turn our attention to this type of approaches.", "labels": [], "entities": []}], "datasetContent": [{"text": "We describe in this section our taxonomy extraction system.", "labels": [], "entities": [{"text": "taxonomy extraction", "start_pos": 32, "end_pos": 51, "type": "TASK", "confidence": 0.8712025880813599}]}, {"text": "In this section we present the results obtained in the second task on Taxonomy Extraction Evaluation as part of SemEval-2016.", "labels": [], "entities": [{"text": "Taxonomy Extraction Evaluation", "start_pos": 70, "end_pos": 100, "type": "TASK", "confidence": 0.8900779485702515}]}, {"text": "The metrics correspond to the structural analysis and the comparison against the Gold Standard effectuated by.", "labels": [], "entities": [{"text": "Gold Standard", "start_pos": 81, "end_pos": 94, "type": "DATASET", "confidence": 0.9403263628482819}]}, {"text": "The best results among all the systems appear in a bold font (note that Euclidean 5 and Cosine 5 have been excluded as they were not submitted on time).", "labels": [], "entities": []}, {"text": "shows the structural analysis of our system and the corresponding results when compared to Gold Standard.", "labels": [], "entities": [{"text": "Gold Standard", "start_pos": 91, "end_pos": 104, "type": "DATASET", "confidence": 0.9151220619678497}]}, {"text": "We were only able to submit the first system (Euclidean 10), and we had to exclude the food domains due to time limitations.", "labels": [], "entities": []}, {"text": "However, we will also present here metrics beyond the official system submission, i.e, Euclidean 5 and Cosine 5 covering all domains provided on the test data.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Official Evaluation metrics for Euclidean measure top 10, 5 and Cosine measure 5 with substring  inclusion. Number of nodes and edges |V|), |E|, connected components (c.c.), cycles, intermediate nodes  (i.n.), number of vertices, vertices coverage and vertex novelty (#VC, %VC, VN), number of edges, edge  coverage and edge novelty (#EC, %EC and EN)", "labels": [], "entities": []}, {"text": " Table 2: Precision, Recall and F-Score for Euclidean Distance 10, 5 and Cosine 5", "labels": [], "entities": [{"text": "Precision", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9993570446968079}, {"text": "Recall", "start_pos": 21, "end_pos": 27, "type": "METRIC", "confidence": 0.9985650181770325}, {"text": "F-Score", "start_pos": 32, "end_pos": 39, "type": "METRIC", "confidence": 0.9993482232093811}]}]}