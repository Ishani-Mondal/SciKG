{"title": [{"text": "Unsupervised Text Segmentation Using Semantic Relatedness Graphs", "labels": [], "entities": [{"text": "Unsupervised Text Segmentation", "start_pos": 0, "end_pos": 30, "type": "TASK", "confidence": 0.6044290959835052}]}], "abstractContent": [{"text": "Segmenting text into semantically coherent fragments improves readability of text and facilitates tasks like text summariza-tion and passage retrieval.", "labels": [], "entities": [{"text": "text summariza-tion", "start_pos": 109, "end_pos": 128, "type": "TASK", "confidence": 0.656241238117218}, {"text": "passage retrieval", "start_pos": 133, "end_pos": 150, "type": "TASK", "confidence": 0.8643592596054077}]}, {"text": "In this paper , we present a novel unsupervised algorithm for linear text segmentation (TS) that exploits word embeddings and a measure of semantic relatedness of short texts to construct a semantic relatedness graph of the document.", "labels": [], "entities": [{"text": "linear text segmentation (TS)", "start_pos": 62, "end_pos": 91, "type": "TASK", "confidence": 0.8467092116673788}]}, {"text": "Semantically coherent segments are then derived from maximal cliques of the relatedness graph.", "labels": [], "entities": []}, {"text": "The algorithm performs competitively on a standard synthetic dataset and outperforms the best-performing method on a real-world (i.e., non-artificial) dataset of political manifestos .", "labels": [], "entities": []}], "introductionContent": [{"text": "Despite the fact that in mainstream natural language processing (NLP) and information retrieval (IR) texts are modeled as bags of unordered words, texts are sequences of semantically coherent segments, designed (often very thoughtfully) to ease readability and understanding of the ideas conveyed by the authors.", "labels": [], "entities": [{"text": "information retrieval (IR) texts", "start_pos": 74, "end_pos": 106, "type": "TASK", "confidence": 0.8500950535138448}]}, {"text": "Although authors may explicitly define coherent segments (e.g., as paragraphs), many texts, especially on the web, lack any explicit segmentation.", "labels": [], "entities": []}, {"text": "Linear text segmentation aims to represent texts as sequences of semantically coherent segments.", "labels": [], "entities": [{"text": "Linear text segmentation", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.686136782169342}]}, {"text": "Besides improving readability and understandability of texts for readers, automated text segmentation is beneficial for NLP and IR tasks such as text summarization ( and passage retrieval (.", "labels": [], "entities": [{"text": "text segmentation", "start_pos": 84, "end_pos": 101, "type": "TASK", "confidence": 0.732422947883606}, {"text": "text summarization", "start_pos": 145, "end_pos": 163, "type": "TASK", "confidence": 0.730243444442749}, {"text": "passage retrieval", "start_pos": 170, "end_pos": 187, "type": "TASK", "confidence": 0.8403199315071106}]}, {"text": "Whereas early approaches to unsupervised text segmentation measured the coherence of segments via raw term overlaps between sentences), more recent methods ( addressed the issue of sparsity of term-based representations by replacing term-vectors with vectors of latent topics.", "labels": [], "entities": []}, {"text": "A topical representation of text is, however, merely a vague approximation of its meaning.", "labels": [], "entities": []}, {"text": "Considering that the goal of TS is to identify semantically coherent segments, we propose a TS algorithm aiming to directly capture the semantic relatedness between segments, instead of approximating it via topical similarity.", "labels": [], "entities": [{"text": "TS", "start_pos": 29, "end_pos": 31, "type": "TASK", "confidence": 0.9436029195785522}]}, {"text": "We employ word embeddings () and a measure of semantic relatedness of short texts) to construct a relatedness graph of the text in which nodes denote sentences and edges are added between semantically related sentences.", "labels": [], "entities": []}, {"text": "We then derive segments using the maximal cliques of such similarity graphs.", "labels": [], "entities": []}, {"text": "The proposed algorithm displays competitive performance on the artifically-generated benchmark TS dataset) and, more importantly, outperforms the best-performing topic modeling-based TS method on a real-world dataset of political manifestos.", "labels": [], "entities": [{"text": "TS dataset", "start_pos": 95, "end_pos": 105, "type": "DATASET", "confidence": 0.7347945272922516}]}], "datasetContent": [{"text": "In this section, we first introduce the two evaluation datasets that we use one being the commonly used synthetic dataset and the other a realistic dataset of politi-cal manifestos.", "labels": [], "entities": []}, {"text": "Following, we present the experimental setting and finally describe and discuss the results achieved by our GRAPHSEG algorithm and how it compares to other TS models.", "labels": [], "entities": [{"text": "GRAPHSEG", "start_pos": 108, "end_pos": 116, "type": "METRIC", "confidence": 0.8854446411132812}]}, {"text": "Unsupervised methods for text segmentation have most often been evaluated on synthetic datasets with segments from different sources being concatenated in artificial documents.", "labels": [], "entities": [{"text": "text segmentation", "start_pos": 25, "end_pos": 42, "type": "TASK", "confidence": 0.7417533993721008}]}, {"text": "Segmenting such artificial texts is easier than segmenting real-world documents.", "labels": [], "entities": []}, {"text": "This is why besides on the artificial Choi dataset we also evaluate GRAPHSEG on a real-world dataset of political texts from the Manifesto Project, 2,3 manually labeled by domain experts with segments of seven different topics (e.g., economy and welfare, quality of life, foreign affairs).", "labels": [], "entities": [{"text": "artificial Choi dataset", "start_pos": 27, "end_pos": 50, "type": "DATASET", "confidence": 0.6748127043247223}, {"text": "GRAPHSEG", "start_pos": 68, "end_pos": 76, "type": "METRIC", "confidence": 0.9828563332557678}]}, {"text": "The selected manifestos contain between 1000 and 2500 sentences, with segments ranging in length from 1 to 78 sentences, which is in sharp contrast to the Choi dataset where all segments are of similar size.", "labels": [], "entities": [{"text": "Choi dataset", "start_pos": 155, "end_pos": 167, "type": "DATASET", "confidence": 0.9358302056789398}]}, {"text": "To allow for comparison with previous work, we evaluate GRAPHSEG on four subsets of the Choi dataset, differing in number of sentences the seg-2008, and 2012 U.S. elections ments contain.", "labels": [], "entities": [{"text": "GRAPHSEG", "start_pos": 56, "end_pos": 64, "type": "METRIC", "confidence": 0.9874542951583862}, {"text": "Choi dataset", "start_pos": 88, "end_pos": 100, "type": "DATASET", "confidence": 0.9569691717624664}]}, {"text": "For the evaluation on the Choi dataset, the GRAPHSEG algorithm made use of the publicly available word embeddings built from a Google News dataset.", "labels": [], "entities": [{"text": "Choi dataset", "start_pos": 26, "end_pos": 38, "type": "DATASET", "confidence": 0.9658237099647522}, {"text": "GRAPHSEG", "start_pos": 44, "end_pos": 52, "type": "METRIC", "confidence": 0.9421355128288269}, {"text": "Google News dataset", "start_pos": 127, "end_pos": 146, "type": "DATASET", "confidence": 0.7555302083492279}]}, {"text": "Both LDA-based models ( and GRAPHSEG rely on corpus-derived word representations.", "labels": [], "entities": [{"text": "GRAPHSEG", "start_pos": 28, "end_pos": 36, "type": "METRIC", "confidence": 0.7588973045349121}]}, {"text": "Thus, we evaluated on the Manifesto dataset both the domainadapted and domain-unadapted variants of these methods.", "labels": [], "entities": [{"text": "Manifesto dataset", "start_pos": 26, "end_pos": 43, "type": "DATASET", "confidence": 0.9758711457252502}]}, {"text": "The domain-adapted variants of the models used the unlabeled domain corpus -a test set of 466 unlabeled political manifestos -to train the domain-specific word representations.", "labels": [], "entities": []}, {"text": "This means that we obtain (1) in-domain topics for the LDAbased TopicTiling model of and domain-specific embeddings for the GRAPHSEG algorithm.", "labels": [], "entities": []}, {"text": "On the Manifesto dataset we also evaluate a baseline that randomly (50% chance) starts anew segment at points m sentences apart, with m being set to half of the average length of gold segments.", "labels": [], "entities": [{"text": "Manifesto dataset", "start_pos": 7, "end_pos": 24, "type": "DATASET", "confidence": 0.9622748494148254}]}, {"text": "We evaluate the performance using two standard TS evaluation metrics -P k () and WindowDiff (WD)).", "labels": [], "entities": [{"text": "TS evaluation", "start_pos": 47, "end_pos": 60, "type": "TASK", "confidence": 0.8053353428840637}]}, {"text": "P k is the probability that two randomly drawn sentences mutually k sentences apart are classified incorrectly -either as belonging to the same segment when they are in different gold segments or as being in different segments when they are in the same gold segment.", "labels": [], "entities": []}, {"text": "Following, we set k to half of the document length divided by the number of gold segments.", "labels": [], "entities": []}, {"text": "WindowDiff is a stricter version of P k as, instead of only checking if the randomly chosen sentences are in the same predicted segment or not, it compares the exact number of segments between the sentences in the predicted segmentation with the number of segments in between the same sentences in the gold standard.", "labels": [], "entities": [{"text": "WindowDiff", "start_pos": 0, "end_pos": 10, "type": "DATASET", "confidence": 0.835378110408783}]}, {"text": "Lower scores indicate better performance for both these metrics.", "labels": [], "entities": []}, {"text": "The GRAPHSEG algorithm has two parameters: (1) the sentence similarity treshold \u03c4 which is used when creating edges of the sentence relatedness graph and (2) the minimal segment size n, which we utilize to merge adjacent segments that are too small.", "labels": [], "entities": []}, {"text": "In all experiments we use grid-search in a folded cross-validation setting to jointly optimize both parameters.", "labels": [], "entities": []}, {"text": "In view of comparison with other models, the parameter optimization is justified be-, also have parameters (e.g., number of topics for the topic model) which are optimized using cross-validation.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Performance on different portions of the Choi dataset (*with domain-adapted topic model).", "labels": [], "entities": [{"text": "Choi dataset", "start_pos": 51, "end_pos": 63, "type": "DATASET", "confidence": 0.960446685552597}]}, {"text": " Table 3: Performance on the Manifesto dataset  (*domain-adapted variant).", "labels": [], "entities": [{"text": "Manifesto dataset", "start_pos": 29, "end_pos": 46, "type": "DATASET", "confidence": 0.9562796652317047}]}]}