{"title": [{"text": "Tohoku at SemEval-2016 Task 6: Feature-based Model versus Convolutional Neural Network for Stance Detection", "labels": [], "entities": [{"text": "Tohoku at SemEval-2016 Task 6", "start_pos": 0, "end_pos": 29, "type": "DATASET", "confidence": 0.8526017546653748}, {"text": "Stance Detection", "start_pos": 91, "end_pos": 107, "type": "TASK", "confidence": 0.9368545114994049}]}], "abstractContent": [{"text": "In this paper, we compare feature-based and Neural Network-based approaches on the supervised stance classification task for tweets in SemEval-2016 Task 6 Subtask A (Moham-mad et al., 2016).", "labels": [], "entities": [{"text": "stance classification task", "start_pos": 94, "end_pos": 120, "type": "TASK", "confidence": 0.7514091233412424}, {"text": "SemEval-2016 Task 6 Subtask A (Moham-mad et al., 2016)", "start_pos": 135, "end_pos": 189, "type": "TASK", "confidence": 0.5470088794827461}]}, {"text": "In the feature-based approach , we use external resources such as lexicons and crawled texts.", "labels": [], "entities": []}, {"text": "The Neural Network based approach employs Convolutional Neu-ral Network (CNN).", "labels": [], "entities": []}, {"text": "Our results show that the feature-based model outperformed the CNN model on the test data although the CNN model was better than the feature-based model in the cross validation on the training data.", "labels": [], "entities": []}], "introductionContent": [{"text": "To solve supervised short text classification tasks, there are two major approaches; feature-based and Neural Network based approaches.", "labels": [], "entities": [{"text": "solve supervised short text classification tasks", "start_pos": 3, "end_pos": 51, "type": "TASK", "confidence": 0.6606897314389547}]}, {"text": "In traditional feature-based approaches, we extract various features from a text.", "labels": [], "entities": []}, {"text": "The features are usually constructed from n-grams (e.g., bigrams) of the texts and external resources such as lexicons and unlabeled corpora.", "labels": [], "entities": []}, {"text": "In Neural Network based approaches, a number of models for text classifications exist; for example, Feed-Forward Neural Network model using an average of embeddings of target word sequences as the input layer, Recursive Neural Network, and Convolutional Neural Network (CNN).", "labels": [], "entities": [{"text": "text classifications", "start_pos": 59, "end_pos": 79, "type": "TASK", "confidence": 0.7119495570659637}]}, {"text": "In this paper, we compare feature-based and Neural Network based approaches on the supervised stance classification task for tweets, SemEval-2016 Task 6 Subtask A (.", "labels": [], "entities": [{"text": "stance classification task", "start_pos": 94, "end_pos": 120, "type": "TASK", "confidence": 0.7618478238582611}, {"text": "SemEval-2016 Task 6 Subtask A", "start_pos": 133, "end_pos": 162, "type": "DATASET", "confidence": 0.709104037284851}]}, {"text": "The feature-based approach classifies tweets using logistic regression model.", "labels": [], "entities": []}, {"text": "The features are extracted using external knowledge such as SentiWordNet () and a collection of crawled tweets, in addition to unigrams or bigrams in the target tweet.", "labels": [], "entities": []}, {"text": "For the Neural Network approach, we implement CNN based on.", "labels": [], "entities": []}, {"text": "As the input embeddings, we use word embeddings trained by Continuous Bag-Of-Words (CBOW) model) on Wikipedia articles.", "labels": [], "entities": []}, {"text": "The experimental results show that the CNN based approach performed the best in the cross validation on the training data.", "labels": [], "entities": []}, {"text": "However the tendency was opposite on the test data probably because the CNN model overfitted to the training data.", "labels": [], "entities": []}, {"text": "In contrast, the feature-based approach was more robust, leveraging the external knowledge.", "labels": [], "entities": []}], "datasetContent": [{"text": "We use the dataset of the SemEval-2016 Task 6 Subtask A, which is a supervised tweet classification task for five topics.", "labels": [], "entities": [{"text": "SemEval-2016 Task 6 Subtask", "start_pos": 26, "end_pos": 53, "type": "TASK", "confidence": 0.6177388578653336}, {"text": "tweet classification task", "start_pos": 79, "end_pos": 104, "type": "TASK", "confidence": 0.7966172099113464}]}, {"text": "There are three stances to classify; NONE, FAVOR, AGAINST.", "labels": [], "entities": [{"text": "NONE", "start_pos": 37, "end_pos": 41, "type": "METRIC", "confidence": 0.9660488367080688}, {"text": "FAVOR", "start_pos": 43, "end_pos": 48, "type": "METRIC", "confidence": 0.9924027919769287}, {"text": "AGAINST", "start_pos": 50, "end_pos": 57, "type": "METRIC", "confidence": 0.9979484677314758}]}, {"text": "shows the topics and distributions of the training data.: Distributions of the labels for each topics in the training data.", "labels": [], "entities": []}, {"text": "We trained 300 dimensional word embeddings using Word2Vec 3 with Wikipedia articles 4 (3950598 articles in total) . We set N to 100, which exceeds the maximum length of all tweets.", "labels": [], "entities": []}, {"text": "We use (300 \u00d7 k) \u00d7 200 matrix as W and three fully connected layers that consist of 200-50-3 units (Threeway Polarity Classifier) or 200-50-2 units (Topic Classifier or Two-way Polarity Classifier).", "labels": [], "entities": []}, {"text": "We measured the performance on 10-fold cross validation.", "labels": [], "entities": []}, {"text": "We evaluated each model by a macro average of micro-F1 scores of FAVOR and AGAINST for each topic and all topics.", "labels": [], "entities": [{"text": "FAVOR", "start_pos": 65, "end_pos": 70, "type": "METRIC", "confidence": 0.999093770980835}, {"text": "AGAINST", "start_pos": 75, "end_pos": 82, "type": "METRIC", "confidence": 0.9987701773643494}]}], "tableCaptions": [{"text": " Table 1: Distributions of the labels for each topics in the train-", "labels": [], "entities": []}, {"text": " Table 4: Comparison of 3-way Polarity Classifier with Topic + 2-way Polarity Classifier on 10-fold cross validation using the", "labels": [], "entities": []}, {"text": " Table 5: Ablation Test of Topic + 2-way Polarity Classifier on 10-fold cross validation using the feature-based approach. The", "labels": [], "entities": [{"text": "Ablation", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9917484521865845}]}, {"text": " Table 6: Comparison of 3-way Polarity Classifier with Topic + 2-way Polarity Classifier on 10-fold cross validation using CNN", "labels": [], "entities": []}, {"text": " Table 7: Tuning of window size per word k on 10-fold cross validation using CNN based approach. The scores were measured in", "labels": [], "entities": []}, {"text": " Table 8: Comparison of Feature-based Model and CNN Model on test data. The scores were measured in a macro average of", "labels": [], "entities": []}]}