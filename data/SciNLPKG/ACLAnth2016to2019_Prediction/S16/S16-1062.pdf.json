{"title": [{"text": "pkudblab at SemEval-2016 Task 6 : A Specific Convolutional Neural Network System for Effective Stance Detection", "labels": [], "entities": [{"text": "Effective Stance Detection", "start_pos": 85, "end_pos": 111, "type": "TASK", "confidence": 0.6549889246622721}]}], "abstractContent": [{"text": "In this paper, we develop a convolutional neu-ral network for stance detection in tweets.", "labels": [], "entities": [{"text": "stance detection", "start_pos": 62, "end_pos": 78, "type": "TASK", "confidence": 0.8469677567481995}]}, {"text": "According to the official results, our system ranks 1 st on subtask B (among 9 teams) and ranks 2 nd on subtask A (among 19 teams) on the twitter test set of SemEval2016 Task 6.", "labels": [], "entities": [{"text": "twitter test set of SemEval2016 Task 6", "start_pos": 138, "end_pos": 176, "type": "DATASET", "confidence": 0.8061777225562504}]}, {"text": "The main contribution of our work is as follows.", "labels": [], "entities": []}, {"text": "We design a \"vote scheme\" for prediction instead of predicting when the accuracy of validation set reaches its maximum.", "labels": [], "entities": [{"text": "prediction", "start_pos": 30, "end_pos": 40, "type": "TASK", "confidence": 0.9659140706062317}, {"text": "accuracy", "start_pos": 72, "end_pos": 80, "type": "METRIC", "confidence": 0.9992018342018127}]}, {"text": "Besides, we make some improvement on the specific sub-tasks.", "labels": [], "entities": []}, {"text": "For subtask A, we separate datasets into five sub-datasets according to their targets , and train and test five separate models.", "labels": [], "entities": []}, {"text": "For subtask B, we establish a two-class training dataset from the official domain corpus, and then modify the softmax layer to perform three-class classification.", "labels": [], "entities": [{"text": "official domain corpus", "start_pos": 66, "end_pos": 88, "type": "DATASET", "confidence": 0.6807839075724283}]}, {"text": "Our system can be easily re-implemented and optimized for other related tasks.", "labels": [], "entities": []}], "introductionContent": [{"text": "There are several requirements for stance detecting applications on the internet.", "labels": [], "entities": [{"text": "stance detecting", "start_pos": 35, "end_pos": 51, "type": "TASK", "confidence": 0.9664515256881714}]}, {"text": "However it is unpractical for humans to classify massive amounts of tweets.", "labels": [], "entities": []}, {"text": "Twitter stance detection aims to automatically determine the emotional tendency of tweets.", "labels": [], "entities": [{"text": "Twitter stance detection", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.5445484320322672}]}, {"text": "To classify tweets polarity, mainstream approaches are based on Pang (), like regression problem, using machine learning algorithm to build classifiers from tweets with manually annotated polarity to classify the polarity of a tweet.", "labels": [], "entities": [{"text": "classify tweets polarity", "start_pos": 3, "end_pos": 27, "type": "TASK", "confidence": 0.8403235276540121}]}, {"text": "In this direction, most studies focus on designing effective features to obtain better classification performance.", "labels": [], "entities": []}, {"text": "For example, Mohammad) implements some sentiment lexicons and several manually-selected features.", "labels": [], "entities": []}, {"text": "To leverage massive tweets containing positive and negative emoticons for automatically feature learning, Tang ( ) proposes to learn sentiment-specific word embedding.", "labels": [], "entities": []}, {"text": "We transfer this method to detect tweets stance.", "labels": [], "entities": []}, {"text": "In this paper, we develop a specific convolutional neural network learning model for stance detection.", "labels": [], "entities": [{"text": "stance detection", "start_pos": 85, "end_pos": 101, "type": "TASK", "confidence": 0.949580192565918}]}, {"text": "Firstly, we learn word embedding from Google News database as the input of our system.", "labels": [], "entities": [{"text": "Google News database", "start_pos": 38, "end_pos": 58, "type": "DATASET", "confidence": 0.7928035855293274}]}, {"text": "Afterwards, we train the CNN model with the SemEval2016 Task 6 dataset.", "labels": [], "entities": [{"text": "SemEval2016 Task 6 dataset", "start_pos": 44, "end_pos": 70, "type": "DATASET", "confidence": 0.7226321697235107}]}, {"text": "Finally, we design a \"vote scheme\" using the softmax results to predict the label of test set.", "labels": [], "entities": []}, {"text": "We also make some task specific improvement.", "labels": [], "entities": []}, {"text": "For subtask A, we separate datasets into five sub-dataset, and train and test five separate models.", "labels": [], "entities": []}, {"text": "For subtask B, we establish a twoclass training dataset from the official domain corpus based on several special expressions.", "labels": [], "entities": [{"text": "official domain corpus", "start_pos": 65, "end_pos": 87, "type": "DATASET", "confidence": 0.6897820830345154}]}, {"text": "We evaluate our deep learning system on the test set of SemEval2016 Task 6.", "labels": [], "entities": [{"text": "SemEval2016 Task 6", "start_pos": 56, "end_pos": 74, "type": "DATASET", "confidence": 0.5916143655776978}]}, {"text": "Our system ranks 1 st on subtask B and 2 nd on subtask A.", "labels": [], "entities": []}, {"text": "The good performance in the Task 6 evaluation verifies the effectiveness of our model and schemes.", "labels": [], "entities": []}], "datasetContent": [{"text": "For subtask A, the training set is the official training data for Task A (  described in Session 2.1, the dimensionality dis 300.", "labels": [], "entities": []}, {"text": "We design three different width filters, 100 in width 3, 100 in width 4 and 100 in width 5, which means that there are 300 filters in total.", "labels": [], "entities": []}, {"text": "We choose ReLU as activation function and we use max-pooling.", "labels": [], "entities": []}, {"text": "L2-norm regularization term is set to 1e-6, the probability of dropout is set to 0.5.", "labels": [], "entities": []}, {"text": "Bias vector b, as well as wk and bk in softmax layer are all set to zero vectors.", "labels": [], "entities": []}, {"text": "We perform contrast experiments on subtask A.", "labels": [], "entities": []}, {"text": "The results of the \"divide and conquer\" model and its contrast integral model, as well as the five separate models are shown in.", "labels": [], "entities": []}, {"text": "The description of these models is in Session 3.", "labels": [], "entities": []}, {"text": "We can see from that \"divide and conquer\" model does not always have a better performance.", "labels": [], "entities": []}, {"text": "However, since the words using in the sentences which belong to the same target are expected to be more similar, the \"divide\" model still performs much better on some dataset (e.g. Atheism).", "labels": [], "entities": []}, {"text": "The \"divide and conquer\" model is the one we submit for evaluation.", "labels": [], "entities": []}, {"text": "Part of the official rankings for both subtask A and B are summarized in.", "labels": [], "entities": []}, {"text": "As we can see our model performs well on both subtasks.", "labels": [], "entities": []}, {"text": "Our model ranks 2 nd on subtask A, whose official metric is only 0.5% lower than the first team.", "labels": [], "entities": []}, {"text": "On subtask B our model ranks 1 st , and the official metric is 56.28%, about 10% higher than the second team.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Task 6 dataset.", "labels": [], "entities": [{"text": "Task 6 dataset", "start_pos": 10, "end_pos": 24, "type": "DATASET", "confidence": 0.6936072607835134}]}, {"text": " Table 3: Part of the official result.", "labels": [], "entities": []}]}