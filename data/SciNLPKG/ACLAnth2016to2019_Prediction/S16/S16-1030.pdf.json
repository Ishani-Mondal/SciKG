{"title": [{"text": "SENSEI-LIF at SemEval-2016 Task 4: Polarity embedding fusion for robust sentiment analysis", "labels": [], "entities": [{"text": "SemEval-2016 Task", "start_pos": 14, "end_pos": 31, "type": "TASK", "confidence": 0.7633090913295746}, {"text": "robust sentiment analysis", "start_pos": 65, "end_pos": 90, "type": "TASK", "confidence": 0.6104176342487335}]}], "abstractContent": [{"text": "This paper describes the system developed at LIF for the SemEval-2016 evaluation campaign.", "labels": [], "entities": [{"text": "SemEval-2016 evaluation campaign", "start_pos": 57, "end_pos": 89, "type": "TASK", "confidence": 0.8442858258883158}]}, {"text": "The goal of Task 4.A was to identify sentiment polarity in tweets.", "labels": [], "entities": [{"text": "identify sentiment polarity in tweets", "start_pos": 28, "end_pos": 65, "type": "TASK", "confidence": 0.7392835497856141}]}, {"text": "The system extends the Convolutional Neural Networks (CNN) state of the art approach.", "labels": [], "entities": []}, {"text": "We initialize the input representations with embed-dings trained on different units: lexical, part-of-speech, and sentiment embeddings.", "labels": [], "entities": []}, {"text": "Neural networks for each input space are trained separately , and then the representations extracted from their hidden layers are concatenated as input of a fusion neural network.", "labels": [], "entities": []}, {"text": "The system ranked 2nd at SemEval-2016 and obtained an average F1 of 63.0%.", "labels": [], "entities": [{"text": "SemEval-2016", "start_pos": 25, "end_pos": 37, "type": "DATASET", "confidence": 0.5853700637817383}, {"text": "F1", "start_pos": 62, "end_pos": 64, "type": "METRIC", "confidence": 0.9995567202568054}]}], "introductionContent": [{"text": "This paper describes the system developed at LIF for the SemEval-2016 sentiment analysis evaluation task (.", "labels": [], "entities": [{"text": "SemEval-2016 sentiment analysis evaluation task", "start_pos": 57, "end_pos": 104, "type": "TASK", "confidence": 0.9541462421417236}]}, {"text": "The goal of our participation was to apply approaches developed for the European FP7 project SENSEI 1 based on the study of human conversations according to feelings, opinions, emotions of the participants, in corpora such as transcripts of telephone speech and web comments.", "labels": [], "entities": [{"text": "FP7 project SENSEI 1", "start_pos": 81, "end_pos": 101, "type": "DATASET", "confidence": 0.8665548712015152}]}, {"text": "We have participated in Subtask A: sentiment analysis at the message level.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 35, "end_pos": 53, "type": "TASK", "confidence": 0.8716119229793549}]}, {"text": "It consists in determining the message polarity of each tweet in the test set.", "labels": [], "entities": []}, {"text": "The sentiment polarity classification task is set as a three-class problem: positive, negative and neutral.", "labels": [], "entities": [{"text": "sentiment polarity classification task", "start_pos": 4, "end_pos": 42, "type": "TASK", "confidence": 0.9037983566522598}]}, {"text": "The sentiment analysis task is often modeled as a classification problem which relies on features ex-1 http://www.sensei-conversation.eu/ tracted from the text in order to feed a classifier.", "labels": [], "entities": [{"text": "sentiment analysis task", "start_pos": 4, "end_pos": 27, "type": "TASK", "confidence": 0.9440943598747253}]}, {"text": "Recent work has shown that Convolutional Neural Networks (CNN) using word representations as input are well suited for sentence classification problems and have been shown to produce state-of-the-art results for sentiment polarity classification (.", "labels": [], "entities": [{"text": "sentence classification", "start_pos": 119, "end_pos": 142, "type": "TASK", "confidence": 0.7383464127779007}, {"text": "sentiment polarity classification", "start_pos": 212, "end_pos": 245, "type": "TASK", "confidence": 0.850671390692393}]}, {"text": "Pre-trained word embeddings are used to initialize the word representations, which are then taken as input of a text CNN.", "labels": [], "entities": []}, {"text": "Our approach consists in learning polarity classifiers for three types of embeddings, based on the same CNN architecture.", "labels": [], "entities": []}, {"text": "Each set of word embedding models the tweet according to a different point of view: lexical, part-of-speech and sentiment.", "labels": [], "entities": []}, {"text": "A final fusion step is applied, based on concatenating the hidden layers of the CNNs and training a deep neural network for the fusion.", "labels": [], "entities": []}, {"text": "Our contributions are as follows: \u2022 We extend the deep CNN architecture proposed in () and introduce lexical information similar to).", "labels": [], "entities": []}, {"text": "\u2022 We introduce polarity embeddings, tweet representations extracted from the hidden layer of CNNs with different word embeddings as input.", "labels": [], "entities": []}, {"text": "\u2022 We fuse polarity embeddings by concatenating them and feeding them to a neural network trained on the final task.", "labels": [], "entities": []}, {"text": "\u2022 The source code of our system, the models trained for the evaluation, and the corpus collected for creating word embeddings are made 202 available to the community to help future research 2 . The paper is structured as follows.", "labels": [], "entities": []}, {"text": "Section 2 presents the system architecture.", "labels": [], "entities": []}, {"text": "Section 3 reviews the implementation details.", "labels": [], "entities": []}, {"text": "Then we detail the different word embeddings and other features used in our system (Section 4).", "labels": [], "entities": []}, {"text": "Results and discussion appear in Section 5.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 3: Statistics of the successfully downloaded part of the", "labels": [], "entities": []}, {"text": " Table 2: Ablation experiment: macro-averaged F-scores obtained on the Twitter 2016 test sets with each of the feature groups", "labels": [], "entities": [{"text": "Ablation", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9913169145584106}, {"text": "F-scores", "start_pos": 46, "end_pos": 54, "type": "METRIC", "confidence": 0.9343428611755371}, {"text": "Twitter 2016 test sets", "start_pos": 71, "end_pos": 93, "type": "DATASET", "confidence": 0.8064423501491547}]}, {"text": " Table 4: Overall performance of the SENSEI-LIF sentiment", "labels": [], "entities": [{"text": "SENSEI-LIF", "start_pos": 37, "end_pos": 47, "type": "DATASET", "confidence": 0.35052457451820374}]}, {"text": " Table 5: Overall performance using different methods of fu-", "labels": [], "entities": []}]}