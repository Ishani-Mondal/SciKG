{"title": [{"text": "Generating Responses with a Specific Emotion in Dialog", "labels": [], "entities": []}], "abstractContent": [{"text": "It is desirable for dialog systems to have capability to express specific emotions during a conversation, which has a direct, quantifiable impact on improvement of their usability and user satisfaction.", "labels": [], "entities": []}, {"text": "After a careful investigation of real-life conversation data, we found that there are at least two ways to express emotions with language.", "labels": [], "entities": []}, {"text": "One is to describe emotional states by explicitly using strong emotional words; another is to increase the intensity of the emotional experiences by implicitly combining neutral words in distinct ways.", "labels": [], "entities": []}, {"text": "We propose an emotional dialogue system (EmoDS) that can generate the meaningful responses with a coherent structure fora post, and meanwhile express the desired emotion explicitly or implicitly within a unified framework.", "labels": [], "entities": []}, {"text": "Experimental results showed EmoDS performed better than the baselines in BLEU, diversity and the quality of emotional expression.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 73, "end_pos": 77, "type": "METRIC", "confidence": 0.9987416863441467}, {"text": "diversity", "start_pos": 79, "end_pos": 88, "type": "METRIC", "confidence": 0.9676648378372192}]}], "introductionContent": [{"text": "Humans have the unique capacity to perceive complex, nuanced emotions, and also have the unique capability to communicate those experiences to one another with language.", "labels": [], "entities": []}, {"text": "Although recent studies () provide much evidence that the systems capable of expressing emotions significantly improve the user satisfaction, it is still a great challenge to make dialogue systems more \"emotional\" in their responses.", "labels": [], "entities": []}, {"text": "In early representative work, manually prepared rules are applied to deliberately select the desired \"emotional\" responses from a conversation corpus.", "labels": [], "entities": []}, {"text": "Those rules were written by persons with expertise after careful investigation in the corpus, which makes it hard to express complex, various emotions, and difficult to scale well to large datasets.", "labels": [], "entities": []}, {"text": "I bought a beautiful dress yesterday!", "labels": [], "entities": []}, {"text": "Explicit: Wearing beautiful dress makes me happy!", "labels": [], "entities": []}, {"text": "Implicit: Wow, you must feel walking on air!", "labels": [], "entities": []}, {"text": "Post: The rose is really beautiful!", "labels": [], "entities": []}, {"text": "Explicit: I love rose!", "labels": [], "entities": []}, {"text": "Implicit: I am keen on rose.", "labels": [], "entities": []}, {"text": "Post: I lost my computer today!", "labels": [], "entities": []}, {"text": "Explicit: It is really an annoying thing.", "labels": [], "entities": []}, {"text": "Implicit: Oh, you must feel hot under the collar.: Examples of two (explicit and implicit) ways in emotional expressions.", "labels": [], "entities": []}, {"text": "For each post, one emotional response for each way is listed below.", "labels": [], "entities": []}, {"text": "The emotional words associated with strong feelings are highlighted in bold blue font.", "labels": [], "entities": []}, {"text": "Most recently, a sequence to sequence (seq2seq) learning framework with recurrent neural networks (RNNs) has been successfully used to build conversational agents (also known as chatbots)) due to their capability to bridge arbitrary time lags.", "labels": [], "entities": []}, {"text": "Such framework was also tried to address the problem of emotional expression in a chatbot, called emotional chat machine (ECM) by Zhou el al.", "labels": [], "entities": []}, {"text": "However, the authors reported that ECM tends to express the emotion category (say \"joy\" or \"neutral\") with much more training samples than others, although it is explicitly asked to express another (\"anger\" for example).", "labels": [], "entities": []}, {"text": "It suffers from exploring the overwhelming samples belonging to a certain emotion category.", "labels": [], "entities": []}, {"text": "Language plays an important role in emotion because it supports the conceptual knowledge used to make meaning of sensations in a given context.", "labels": [], "entities": []}, {"text": "As shown in, we found there are at least two ways to put feelings into words.", "labels": [], "entities": []}, {"text": "One is to describe emotional states (such as \"anger,\" \"disgust,\" \"contentment,\" \"joy,\" \"sadness,\" etc.) by explicitly using strong emotional words associated with the categories; another is to increase the intensity of the emotional experiences not by using words in emotion lexicon, but by implicitly combining neutral words in distinct ways on emotion.", "labels": [], "entities": []}, {"text": "In this study, we propose an emotional dialogue system (EmoDS) that is able to put a specific feeling into words with a coherent structure in an explicit or implicit manner.", "labels": [], "entities": []}, {"text": "The seq2seq framework has been extended with a lexicon-based attention mechanism that encourages to replace the words of the response with their synonyms in an emotion lexicon.", "labels": [], "entities": []}, {"text": "The response generation process is guided by a sequence-level emotion classifier that not only increases the intensity of emotional expression, but also helps to recognize the emotional sentences not containing any emotional word.", "labels": [], "entities": [{"text": "response generation", "start_pos": 4, "end_pos": 23, "type": "TASK", "confidence": 0.7480882406234741}]}, {"text": "We also present a semi-supervised method to create an emotion lexicon that is relatively \"accurate\" representation of the emotional states that humans are prepared to experience and perceive.", "labels": [], "entities": []}, {"text": "Experimental results with both automatic and human evaluations show that fora given post and an emotion category, our EmoDS can express the desired emotion explicitly (if possible) or implicitly (if necessary), and meanwhile successfully generate the meaningful responses with a coherent structure.", "labels": [], "entities": []}], "datasetContent": [{"text": "Following the protocols defined in ( , we employed a human evaluation method designed from the content and emotion levels to better understand the quality of the generated re-  sponses.", "labels": [], "entities": []}, {"text": "First, two hundred posts were randomly sampled from the test set and for each of them, all models except Seq2Seq generated six responses for six emotion categories.", "labels": [], "entities": []}, {"text": "Instead, Seq2Seq model generated top 6 responses in beam search for each post.", "labels": [], "entities": []}, {"text": "Later the triples of (post, response, emotion) were presented to three human judges with order disrupted.", "labels": [], "entities": []}, {"text": "They evaluated each response from the content level by 3-scale rating (0, 1, 2) and emotion level by 2-scale rating (0, 1).", "labels": [], "entities": []}, {"text": "Evaluation from the content level assesses whether a response is coherent and meaningful for the context.", "labels": [], "entities": []}, {"text": "Evaluation from the emotion level decides if a response reveals the desired emotion property.", "labels": [], "entities": []}, {"text": "Agreements to measure inter-rater consistency among three annotators were calculated with the Fleiss's kappa.", "labels": [], "entities": []}, {"text": "Finally, the Fleiss's kappa for content and emotion is 0.513 and 0.811, indicating \"Moderate agreement\" and \"Substantial agreement\", respectively.", "labels": [], "entities": [{"text": "kappa", "start_pos": 22, "end_pos": 27, "type": "METRIC", "confidence": 0.9507976174354553}, {"text": "Moderate", "start_pos": 84, "end_pos": 92, "type": "METRIC", "confidence": 0.9824884533882141}]}], "tableCaptions": [{"text": " Table 3: Statistics of emotion-labeled STC dataset.", "labels": [], "entities": [{"text": "STC dataset", "start_pos": 40, "end_pos": 51, "type": "DATASET", "confidence": 0.8005240857601166}]}, {"text": " Table 4: Classification accuracy on the NLPCC dataset.", "labels": [], "entities": [{"text": "Classification", "start_pos": 10, "end_pos": 24, "type": "TASK", "confidence": 0.9584099054336548}, {"text": "accuracy", "start_pos": 25, "end_pos": 33, "type": "METRIC", "confidence": 0.9871731996536255}, {"text": "NLPCC dataset", "start_pos": 41, "end_pos": 54, "type": "DATASET", "confidence": 0.9872817695140839}]}, {"text": " Table 5: Results reported in the embedding scores, BLEU, diversity, and the quality of emotional expression.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 52, "end_pos": 56, "type": "METRIC", "confidence": 0.9994798302650452}, {"text": "diversity", "start_pos": 58, "end_pos": 67, "type": "METRIC", "confidence": 0.981240451335907}]}, {"text": " Table 6: The results of human evaluation. Cont. and Emot. denote content and emotion, respectively.", "labels": [], "entities": []}, {"text": " Table 7: The distribution (%) of Content-Emotion  scores.", "labels": [], "entities": []}, {"text": " Table 8: Preference test (%) between any two models.", "labels": [], "entities": [{"text": "Preference test", "start_pos": 10, "end_pos": 25, "type": "METRIC", "confidence": 0.9671991169452667}]}]}