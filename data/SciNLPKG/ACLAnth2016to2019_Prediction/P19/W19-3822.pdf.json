{"title": [{"text": "Automatic Gender Identification and Reinflection in Arabic", "labels": [], "entities": [{"text": "Automatic Gender Identification and Reinflection", "start_pos": 0, "end_pos": 48, "type": "TASK", "confidence": 0.7185845077037811}]}], "abstractContent": [{"text": "The impressive progress in many Natural Language Processing (NLP) applications has increased the awareness of some of the biases these NLP systems have with regards to gender identities.", "labels": [], "entities": []}, {"text": "In this paper, we propose an approach to extend biased single-output gender-blind NLP systems with gender-specific alternative reinflections.", "labels": [], "entities": []}, {"text": "We focus on Ara-bic, a gender-marking morphologically rich language, in the context of machine translation (MT) from English, and for first-person-singular constructions only.", "labels": [], "entities": [{"text": "machine translation (MT)", "start_pos": 87, "end_pos": 111, "type": "TASK", "confidence": 0.8373860836029052}]}, {"text": "Our contributions are the development of a system-independent gender-awareness wrapper, and the building of a corpus for training and evaluating first-person-singular gender identification and re-inflection in Arabic.", "labels": [], "entities": [{"text": "first-person-singular gender identification and re-inflection in Arabic", "start_pos": 145, "end_pos": 216, "type": "TASK", "confidence": 0.7926597424915859}]}, {"text": "Our results successfully demonstrate the viability of this approach with 8% relative increase in BLEU score for first-person-singular feminine, and 5.3% comparable increase for first-person-singular masculine on top of a state-of-the-art gender-blind MT system on a held-out test set.", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 97, "end_pos": 107, "type": "METRIC", "confidence": 0.9758472442626953}, {"text": "MT", "start_pos": 251, "end_pos": 253, "type": "TASK", "confidence": 0.9185965657234192}]}], "introductionContent": [{"text": "The impressive progress in the last decade in many Natural Language Processing (NLP) applications, from machine translation (MT) to dialogue system, has increased awareness of some of the biases these systems have with regards to gender identities.", "labels": [], "entities": [{"text": "machine translation (MT)", "start_pos": 104, "end_pos": 128, "type": "TASK", "confidence": 0.8537247180938721}]}, {"text": "A casein point is the I-am-a-doctor/ I-am-a-nurse MT problem in many morphologically rich languages.", "labels": [], "entities": [{"text": "MT", "start_pos": 50, "end_pos": 52, "type": "TASK", "confidence": 0.8861345648765564}]}, {"text": "While English uses genderneutral terms that hide the ambiguity of the firstperson gender reference, many morphologically rich languages need to use different grammatically gender-specific terms for these two expressions.", "labels": [], "entities": []}, {"text": "In Arabic, as in other languages with grammatical gender, gender-blind single-output MT from English often results in \u00c2nA Tbyb 'I am a doctor'/ \u00c2nA mmrD 'I am a [female] nurse', which is inappropriate for female doctors and male nurses, respectively.", "labels": [], "entities": [{"text": "MT", "start_pos": 85, "end_pos": 87, "type": "TASK", "confidence": 0.7408080697059631}, {"text": "\u00c2nA Tbyb 'I am a doctor'/ \u00c2nA mmrD", "start_pos": 118, "end_pos": 152, "type": "METRIC", "confidence": 0.6863730907440185}]}, {"text": "Part of this problem comes from humangenerated data that mirrors the social biases and inequalities of the world we live in, and that results in biased models and representations.", "labels": [], "entities": []}, {"text": "Many research efforts responded to this problem by debiasing and balancing the models created from the data through model modification or data augmentation.", "labels": [], "entities": []}, {"text": "However, ultimately, even the most balanced and unbiased of models can be useless in gender-blind systems that are designed to generate a single text output.", "labels": [], "entities": []}, {"text": "Such systems are doomed to unsurprisingly pass on the biases of the models they use, as demonstrated in the doctor/nurse example above.", "labels": [], "entities": []}, {"text": "In contrast, gender-aware systems should be designed to produce outputs that are as gender-specific as the input information they have access to.", "labels": [], "entities": []}, {"text": "The input gender information maybe contextual (e.g., the input 'she is a doctor'), or extra linguistics (e.g., the gender feature provided in the user profile in social media).", "labels": [], "entities": []}, {"text": "But, there maybe contexts where the gender information is unavailable to the system (e.g., 'the student is a nurse').", "labels": [], "entities": []}, {"text": "In such cases, generating both gender-specific forms or a gender-neutral (gender-ambiguous) form is more appropriate.", "labels": [], "entities": []}, {"text": "In this paper, we propose an approach that extends the possibly biased output of gender-blind NLP systems with gender-specific reinflections.", "labels": [], "entities": []}, {"text": "This is a monolingual postprocessing rephrasing task that wraps around a gender-blind system to make it gender-aware, through identifying if there are gender-specific phrases in its output and of-fering alternative reinflections instead.", "labels": [], "entities": []}, {"text": "The selection of the gender-specific form is then left to the user or another automatic component has access to extra-linguistic information, such as profile gender.", "labels": [], "entities": []}, {"text": "For example, the Arabic gender-blind MT output translating  . Since the output of the gender-blind NLP system is not necessarily always masculine or feminine, our approach requires two components: gender identification and gender reinflection, which can be modeled jointly or in cascade.", "labels": [], "entities": [{"text": "MT output translating", "start_pos": 37, "end_pos": 58, "type": "TASK", "confidence": 0.7773588101069132}, {"text": "gender identification", "start_pos": 197, "end_pos": 218, "type": "TASK", "confidence": 0.6946372240781784}]}, {"text": "The approach is systemindependent and can be used with MT, dialogue systems, etc., as well as, to balance corpora through augmentation by adding reinflected copies of gender-specific constructions.", "labels": [], "entities": [{"text": "MT", "start_pos": 55, "end_pos": 57, "type": "TASK", "confidence": 0.9605034589767456}]}, {"text": "We focus on Arabic, a gender-marking morphologically rich language, in the context of MT from English, and for first-person-singular constructions only.", "labels": [], "entities": [{"text": "MT", "start_pos": 86, "end_pos": 88, "type": "TASK", "confidence": 0.9719153046607971}]}, {"text": "We only work on first-person constructions because they tend to be gender-neutral in English.", "labels": [], "entities": []}, {"text": "Furthermore, as sentences may involve multiple gendered references, we wanted to control for the number of combinations.", "labels": [], "entities": []}, {"text": "We plan to extend to multiple references in future work.", "labels": [], "entities": []}, {"text": "Our contributions are the development of a system-independent gender-awareness wrapper, and the building of a corpus for training and evaluating first-person-singular gender identification and reinflection in Arabic.", "labels": [], "entities": [{"text": "first-person-singular gender identification and reinflection in Arabic", "start_pos": 145, "end_pos": 215, "type": "TASK", "confidence": 0.7917798331805638}]}, {"text": "For gender identification, we compare rule-based and machine learning methods using our annotated corpus.", "labels": [], "entities": [{"text": "gender identification", "start_pos": 4, "end_pos": 25, "type": "TASK", "confidence": 0.7585110366344452}]}, {"text": "For gender reinflection, we use a character-level neural MT (NMT) model in a single step (identify and reinflect, jointly), and as the second part of a twostep (identify then reinflect) system.", "labels": [], "entities": [{"text": "gender reinflection", "start_pos": 4, "end_pos": 23, "type": "TASK", "confidence": 0.7454476654529572}]}, {"text": "Our results successfully demonstrate the viability of this approach with 8% relative increase in BLEU score for first-person-singular feminine, and 5.3% comparable increase for first-person-singular masculine on top of a state-of-the-art gender-blind MT system on a held-out test set.", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 97, "end_pos": 107, "type": "METRIC", "confidence": 0.9758472442626953}, {"text": "MT", "start_pos": 251, "end_pos": 253, "type": "TASK", "confidence": 0.9185965657234192}]}, {"text": "Next, we discuss some related work (Section 2) and Arabic linguistic facts (Section 3).", "labels": [], "entities": []}, {"text": "We present our Arabic parallel gender corpus in Section 4, gender identification in Section 5, and gender reinflection and MT results in Section 6.", "labels": [], "entities": [{"text": "gender identification", "start_pos": 59, "end_pos": 80, "type": "TASK", "confidence": 0.761088490486145}, {"text": "MT", "start_pos": 123, "end_pos": 125, "type": "TASK", "confidence": 0.858912467956543}]}], "datasetContent": [{"text": "The character-based NMT reinflection models are trained using the 8,566 TRAIN sentence pairs and the 226,175 synthetic corpus sentence pairs (as discussed above).", "labels": [], "entities": [{"text": "TRAIN", "start_pos": 72, "end_pos": 77, "type": "METRIC", "confidence": 0.93442302942276}]}, {"text": "The DEV and TEST sets comprise 1,224 and 2,448 sentences, respectively.", "labels": [], "entities": [{"text": "DEV", "start_pos": 4, "end_pos": 7, "type": "DATASET", "confidence": 0.9052140712738037}, {"text": "TEST sets", "start_pos": 12, "end_pos": 21, "type": "DATASET", "confidence": 0.8717896938323975}]}, {"text": "We compare two input settings: (a) the Balanced Input DEV and TEST, and (b) the English-to-Arabic Google Translate output of the English sentences corresponding the Balanced Input DEV and TEST, DEV GT and TEST GT (Section 4).", "labels": [], "entities": []}, {"text": "We evaluate sentence gender reinflection against the DEV and TEST portions of the Target F and Target M corpora as references (also, Section 4).", "labels": [], "entities": [{"text": "sentence gender reinflection", "start_pos": 12, "end_pos": 40, "type": "TASK", "confidence": 0.6258434851964315}, {"text": "TEST", "start_pos": 61, "end_pos": 65, "type": "METRIC", "confidence": 0.9321250319480896}]}, {"text": "In addition to the single and two-step system, we include a \"do-nothing\" baseline that simply passes the input to the output as is.", "labels": [], "entities": []}, {"text": "Reinflection Evaluation Reinflection results for each setup are reported in  words are not changed between input and reference.", "labels": [], "entities": []}, {"text": "The single system in fact introduced errors that made it worse than the do-nothing baseline.", "labels": [], "entities": []}, {"text": "While in the baseline, 91.75% of DEV sentences are fully accurate; the two-step system sentence accuracy is 95.42% (M) and 94.68% (F), a \u223c40% error reduction on average.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 96, "end_pos": 104, "type": "METRIC", "confidence": 0.977588415145874}, {"text": "F)", "start_pos": 131, "end_pos": 133, "type": "METRIC", "confidence": 0.9501036703586578}, {"text": "error", "start_pos": 142, "end_pos": 147, "type": "METRIC", "confidence": 0.9571174383163452}]}, {"text": "For the Google Translate results, the single system outperforms the two-step system and the baseline.", "labels": [], "entities": []}, {"text": "On the TEST GT set, the single system has an 8% relative increase in BLEU score for Target F, and 5.3% relative increase for Target M. The BLEU scores are much lower than the Balanced Input case since the actual input to the Google MT was English and many gender and non-gender related translation errors occur.", "labels": [], "entities": [{"text": "TEST GT set", "start_pos": 7, "end_pos": 18, "type": "DATASET", "confidence": 0.9301936229070028}, {"text": "BLEU score", "start_pos": 69, "end_pos": 79, "type": "METRIC", "confidence": 0.9834531247615814}, {"text": "BLEU", "start_pos": 139, "end_pos": 143, "type": "METRIC", "confidence": 0.9990792274475098}]}, {"text": "Also, we only have a single MT reference to compare against.", "labels": [], "entities": []}, {"text": "We suspect that the reason the two-step system did not do as well is that the gender identification component was not trained with the kind of input (and noise) generated by MT systems.", "labels": [], "entities": [{"text": "gender identification", "start_pos": 78, "end_pos": 99, "type": "TASK", "confidence": 0.716683954000473}, {"text": "MT", "start_pos": 174, "end_pos": 176, "type": "TASK", "confidence": 0.9746066331863403}]}, {"text": "One possible solution in the future is to train the gender identification component with MT/NLP output specifically.", "labels": [], "entities": [{"text": "gender identification", "start_pos": 52, "end_pos": 73, "type": "TASK", "confidence": 0.7139930576086044}, {"text": "MT/NLP", "start_pos": 89, "end_pos": 95, "type": "TASK", "confidence": 0.8419299324353536}]}, {"text": "Finally, an interesting side observation from this experiment is that automatic gender identification for the Google Translate Arabic output showed a 10-to-1 bias of M versus F, compared to the 50-50 distribution in the Balanced Corpus and the 2-to-1 bias in the Original Corpus.", "labels": [], "entities": [{"text": "gender identification", "start_pos": 80, "end_pos": 101, "type": "TASK", "confidence": 0.6991806328296661}, {"text": "Google Translate Arabic output", "start_pos": 110, "end_pos": 140, "type": "DATASET", "confidence": 0.7584053874015808}, {"text": "Balanced Corpus", "start_pos": 220, "end_pos": 235, "type": "DATASET", "confidence": 0.8118464648723602}, {"text": "Original Corpus", "start_pos": 263, "end_pos": 278, "type": "DATASET", "confidence": 0.9593337178230286}]}, {"text": "This further confirms the bias towards masculine forms in single-output MT systems.", "labels": [], "entities": [{"text": "MT", "start_pos": 72, "end_pos": 74, "type": "TASK", "confidence": 0.9507943987846375}]}, {"text": "Error Examples in MT output We conducted a limited analysis to understand the behavior of the NMT reinflection systems.", "labels": [], "entities": [{"text": "MT", "start_pos": 18, "end_pos": 20, "type": "TASK", "confidence": 0.9655805826187134}]}, {"text": "While there were many cases that were handled properly, and cases of under-correction where the input is passed to the output as is; there were also cases of overcorrection where words that should maintain their form are treated as gender-specific and modified.", "labels": [], "entities": []}, {"text": "One example is the input word lld\u03b3d\u03b3h 'for tickling', which is erroneously turned into the nonsense word lld\u03b3d.", "labels": [], "entities": []}, {"text": "There were also a few cases of very long repetitions in the output; as well as reduced output -simply leading to sentence length mismatch.", "labels": [], "entities": []}, {"text": "All of these phenomena are unsurprising side effects of using characterbased NMT models.", "labels": [], "entities": []}, {"text": "In our experiments, they happened infrequently, but we plan to address them in future work.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Statistics of the original corpus we annotated and the balanced version we report on in the paper experi- ments. Words M F refers to the count of gender-marking words, specifically. M r and F r are the reinflected versions  of the F and M labelled sentences, respectively, in the same rows they appear in.", "labels": [], "entities": []}, {"text": " Table 5: BLEU results (all AYT normalized) for the Baseline, Single and Select systems on the DEV and TEST  sets of the Balanced Corpus Input (Input ar ) and English-Arabic Google Translate output (Input GT ) for both F and  M targets.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9993340373039246}, {"text": "AYT", "start_pos": 28, "end_pos": 31, "type": "METRIC", "confidence": 0.9735417366027832}, {"text": "DEV and TEST  sets", "start_pos": 95, "end_pos": 113, "type": "DATASET", "confidence": 0.7504105195403099}]}]}