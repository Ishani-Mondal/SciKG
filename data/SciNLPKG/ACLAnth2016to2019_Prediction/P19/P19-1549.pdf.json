{"title": [{"text": "Modeling Semantic Relationship in Multi-turn Conversations with Hierarchical Latent Variables", "labels": [], "entities": []}], "abstractContent": [{"text": "Multi-turn conversations consist of complex semantic structures, and it is still a challenge to generate coherent and diverse responses given previous utterances.", "labels": [], "entities": []}, {"text": "It's practical that a conversation takes place under a background, meanwhile, the query and response are usually most related and they are consistent in topic but also different in content.", "labels": [], "entities": []}, {"text": "However, little work focuses on such hierarchical relationship among utterances.", "labels": [], "entities": []}, {"text": "To address this problem, we propose a Conversational Semantic Relationship RNN (CSRR) model to construct the dependency explicitly.", "labels": [], "entities": []}, {"text": "The model contains latent variables in three hierarchies.", "labels": [], "entities": []}, {"text": "The discourse-level one captures the global background, the pair-level one stands for the common topic information between query and response, and the utterance-level ones try to represent differences in content.", "labels": [], "entities": []}, {"text": "Experimental results show that our model significantly improves the quality of responses in terms of fluency, coherence and diversity compared to baseline methods.", "labels": [], "entities": []}], "introductionContent": [{"text": "Inspired by the observation that real-world human conversations are usually multi-turn, some studies have focused on multi-turn conversations and taken context (history utterances in previous turns) into account for response generation.", "labels": [], "entities": [{"text": "response generation", "start_pos": 216, "end_pos": 235, "type": "TASK", "confidence": 0.773042768239975}]}, {"text": "How to model the relationship between the response and context is essential to generate coherent and logical conversations.", "labels": [], "entities": []}, {"text": "Currently, the researchers employ some hierarchical architectures to model the relationship.", "labels": [], "entities": []}, {"text": "use a context RNN to integrate historical information, sum up all utterances weighted by the similarity score between an utterance and the query, while apply attention mechanism on history utterances.", "labels": [], "entities": []}, {"text": "Besides, add a word-level attention to capture finegrained features.", "labels": [], "entities": []}, {"text": "In practice, we usually need to understand the meaning of utterances and capture their semantic dependency, not just word-level alignments).", "labels": [], "entities": []}, {"text": "As shown in, this short conversation is about speaker A asks the current situation of speaker B.", "labels": [], "entities": []}, {"text": "At the beginning, they talk about B's position.", "labels": [], "entities": [{"text": "B", "start_pos": 34, "end_pos": 35, "type": "METRIC", "confidence": 0.9800915122032166}]}, {"text": "Then in the last two utterances, both speakers think about the way for B to comeback.", "labels": [], "entities": [{"text": "B to comeback", "start_pos": 71, "end_pos": 84, "type": "TASK", "confidence": 0.7712146639823914}]}, {"text": "A mentions \"umbrella\", while B wants A to \"pick him/her up\".", "labels": [], "entities": []}, {"text": "What's more, there is no \"word-to-word\" matching in query and response.", "labels": [], "entities": []}, {"text": "Unfortunately, the aforementioned hierarchical architectures do not model the meaning of each utterance explicitly and has to summarize the meaning of utterances on the fly during generating the response, and hence there is no guarantee that the inferred meaning is adequate to the original utterance.", "labels": [], "entities": []}, {"text": "To address this problem, variational autoencoders (VAEs) are introduced to learn the meaning of utterances explicitly and a reconstruction loss is employed to make sure the learned meaning is faithful to the corresponding utterance.", "labels": [], "entities": []}, {"text": "Besides, more variations are imported into utterance level to help generate more diverse responses.", "labels": [], "entities": []}, {"text": "A: Where are you?", "labels": [], "entities": []}, {"text": "B: I'm stuck in my office with rain.", "labels": [], "entities": [{"text": "B", "start_pos": 0, "end_pos": 1, "type": "METRIC", "confidence": 0.9850769639015198}]}, {"text": "A: Didn't you bring your umbrella?", "labels": [], "entities": []}, {"text": "B: No. Please come and pick me up.", "labels": [], "entities": [{"text": "B", "start_pos": 0, "end_pos": 1, "type": "METRIC", "confidence": 0.9811573624610901}]}, {"text": "However, all these frameworks ignore the practical situation that a conversation usually takes place under a background with two speakers communicating interactively and query is the most relevant utterance to the response.", "labels": [], "entities": []}, {"text": "Hence we need to pay more attention to the relationship between query and response.", "labels": [], "entities": []}, {"text": "To generate a coherent and engaging conversation, query and response should be consistent in topic and have some differences in content, the logical connection between which makes sure the conversation can goon smoothly.", "labels": [], "entities": []}, {"text": "On these grounds, we propose a novel Conversational Semantic Relationship RNN (CSRR) to explicitly learn the semantic dependency in multiturn conversations.", "labels": [], "entities": []}, {"text": "CSRR employs hierarchical latent variables based on VAEs to represent the meaning of utterances and meanwhile learns the relationship between query and response.", "labels": [], "entities": [{"text": "VAEs", "start_pos": 52, "end_pos": 56, "type": "METRIC", "confidence": 0.9279306530952454}]}, {"text": "Specifically, CSRR draws the background of the conversation with a discourse-level latent variable and then models the consistent semantics between query and response, e.g. the topic, with a common latent variable shared by the query and response pair, and finally models the specific meaning of the query and the response with a certain latent variable for each of them to capture the content difference.", "labels": [], "entities": []}, {"text": "With these latent variables, we can learn the relationship between utterances hierarchically, especially the logical connection between the query and response.", "labels": [], "entities": []}, {"text": "What is the most important, the latent variables are constrained to reconstruct the original utterances according to the hierarchical structure we define, making sure the semantics flow through the latent variables without any loss.", "labels": [], "entities": []}, {"text": "Experimental results on two public datasets show that our model outperforms baseline methods in generating high-quality responses.", "labels": [], "entities": []}], "datasetContent": [{"text": "Open-domain response generation does not have a standard criterion for automatic evaluation, like BLEU () for machine translation.", "labels": [], "entities": [{"text": "Open-domain response generation", "start_pos": 0, "end_pos": 31, "type": "TASK", "confidence": 0.6481462121009827}, {"text": "BLEU", "start_pos": 98, "end_pos": 102, "type": "METRIC", "confidence": 0.9957700371742249}, {"text": "machine translation", "start_pos": 110, "end_pos": 129, "type": "TASK", "confidence": 0.7840472459793091}]}, {"text": "Our model is designed to improve the co-  The left part of is about automatic evaluation on test set.", "labels": [], "entities": []}, {"text": "The proposed CSRR model significantly outperforms other baselines on three embedding-based metrics on both datasets.", "labels": [], "entities": []}, {"text": "The improvement of our model indicates our semantic relationship modeling better reflects the structure of real-world conversations, and the responses generated by our models are more relevant to context.", "labels": [], "entities": []}, {"text": "As for diversity, CSRR also gets the highest Dist-1 and Dist-2 scores.", "labels": [], "entities": [{"text": "Dist-1", "start_pos": 45, "end_pos": 51, "type": "METRIC", "confidence": 0.9849020838737488}, {"text": "Dist-2", "start_pos": 56, "end_pos": 62, "type": "METRIC", "confidence": 0.9175813794136047}]}, {"text": "For Ubuntu Dialog dataset, VHRED+w.d is the worst.", "labels": [], "entities": [{"text": "Ubuntu Dialog dataset", "start_pos": 4, "end_pos": 25, "type": "DATASET", "confidence": 0.9163044889767965}, {"text": "VHRED", "start_pos": 27, "end_pos": 32, "type": "DATASET", "confidence": 0.7284517288208008}]}, {"text": "With the help of discourse-level latent variable and utterance drop, VHCR+u.d leads to better performance.", "labels": [], "entities": []}, {"text": "However, HRED is the worst on the Cornell Movie dataset.", "labels": [], "entities": [{"text": "HRED", "start_pos": 9, "end_pos": 13, "type": "METRIC", "confidence": 0.9754835367202759}, {"text": "Cornell Movie dataset", "start_pos": 34, "end_pos": 55, "type": "DATASET", "confidence": 0.9913862744967142}]}, {"text": "empirically explained the difference based on that Cornell Movie Dialog dataset is small in size, but very diverse and complex in content and style, and models like HRED often fail to generate appropriate responses for the context.", "labels": [], "entities": [{"text": "Cornell Movie Dialog dataset", "start_pos": 51, "end_pos": 79, "type": "DATASET", "confidence": 0.9734288901090622}]}, {"text": "The right part of is about human evaluation results on 400 (100\u00d74) responses.", "labels": [], "entities": []}, {"text": "First, it is clear that CSRR model receives the best evaluation on three aspects, which proves the effectiveness of CSRR on generating high quality responses.", "labels": [], "entities": []}, {"text": "Second, because of the existence of discourse-level and pair-level latent variables, responses are more coherent.", "labels": [], "entities": []}, {"text": "Since these two kinds of variables learn high level semantic information, utterance-level ones serve better on expression diversion, also improve sentence fluency and informativeness.", "labels": [], "entities": [{"text": "expression diversion", "start_pos": 111, "end_pos": 131, "type": "TASK", "confidence": 0.7322647869586945}]}, {"text": "easy questions, like greeting (Example 4), both HRED and CSRR perform well.", "labels": [], "entities": [{"text": "greeting", "start_pos": 21, "end_pos": 29, "type": "TASK", "confidence": 0.9601026773452759}, {"text": "HRED", "start_pos": 48, "end_pos": 52, "type": "METRIC", "confidence": 0.9793205261230469}]}, {"text": "In contrast, VHRED+w.d and VHCR+u.d tend to generate general and meaningless responses.", "labels": [], "entities": []}, {"text": "For hard questions, like some technical ones (Example 1 to 3), the proposed CSRR obviously outperforms other baselines.", "labels": [], "entities": []}, {"text": "Note that VHCR is to show the effectiveness of z c and it can also be considered as the ablation study of CSRR to illustrate the validity of z p . From above cases, we empirically find that with the help of z p , response generated by CSRR are not only relevant and consistent to context, but also informative and meaningful.", "labels": [], "entities": [{"text": "VHCR", "start_pos": 10, "end_pos": 14, "type": "DATASET", "confidence": 0.6711689233779907}]}], "tableCaptions": [{"text": " Table 2: Automatic and human evaluation results on Ubuntu Dialog Corpus and Cornell Movie Dialog Corpus.", "labels": [], "entities": [{"text": "Ubuntu Dialog Corpus", "start_pos": 52, "end_pos": 72, "type": "DATASET", "confidence": 0.9773416121800741}, {"text": "Cornell Movie Dialog Corpus", "start_pos": 77, "end_pos": 104, "type": "DATASET", "confidence": 0.9731795638799667}]}]}