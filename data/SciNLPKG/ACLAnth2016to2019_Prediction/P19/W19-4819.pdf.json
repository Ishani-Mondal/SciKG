{"title": [{"text": "Hierarchical Representation in Neural Language Models: Suppression and Recovery of Expectations", "labels": [], "entities": [{"text": "Hierarchical Representation", "start_pos": 0, "end_pos": 27, "type": "TASK", "confidence": 0.7625684440135956}, {"text": "Suppression and Recovery of Expectations", "start_pos": 55, "end_pos": 95, "type": "TASK", "confidence": 0.6826543092727662}]}], "abstractContent": [{"text": "Deep learning sequence models have led to a marked increase in performance fora range of Natural Language Processing tasks, but it remains an open question whether they are able to induce proper hierarchical generalizations for representing natural language from linear input alone.", "labels": [], "entities": []}, {"text": "Work using artificial languages as training input has shown that LSTMs are capable of inducing the stack-like data structures required to represent context-free and certain mildly context-sensitive languages (Weiss et al., 2018)-formal language classes which correspond in theory to the hierarchical structures of natural language.", "labels": [], "entities": []}, {"text": "Here we present a suite of experiments probing whether neu-ral language models trained on linguistic data induce these stack-like data structures and deploy them while incrementally predicting words.", "labels": [], "entities": []}, {"text": "We study two natural language phenomena: center embedding sentences and syntactic island constraints on the filler-gap dependency.", "labels": [], "entities": []}, {"text": "In order to properly predict words in these structures, a model must be able to temporarily suppress certain expectations and then recover those expectations later, essentially pushing and popping these expectations on a stack.", "labels": [], "entities": []}, {"text": "Our results provide evidence that models can successfully suppress and recover expectations in many cases, but do not fully recover their previous grammatical state.", "labels": [], "entities": []}], "introductionContent": [{"text": "Deep learning sequence models such as RNNs) have led to a marked increase in performance fora range of Natural Language Processing tasks), but it remains an open question whether they are able to induce hierarchical generalizations from linear input alone.", "labels": [], "entities": []}, {"text": "Answering this question is important both for technical outcomes-models with explicit hierarchical structure show performance gains, at least when training on relatively small datasets ()-and for the scientific aim of understanding what biases, learning objectives and training regimes led to humanlike linguistic knowledge.", "labels": [], "entities": []}, {"text": "Previous work has approached this question by either examining models' internal state) or by studying model behavior.", "labels": [], "entities": []}, {"text": "For this latter approach, much work has assessed sensitivity to hierarchy by examining whether the expectations associated with longdistance dependencies can be maintained even in the presence of intervening distractor words (.", "labels": [], "entities": []}, {"text": "For example, fed RNNs with the prefix The keys to the cabinet.", "labels": [], "entities": []}, {"text": "If models assigned higher probability to the grammatical continuation are over the ungrammatical continuation is, they can be said to have learned the correct structural relationship between the subject and the verb, ignoring the syntactically-irrelevant singular distractor, the cabinet.", "labels": [], "entities": []}, {"text": "Work in this paradigm has uncovered a complex pattern in terms of what specific hierarchical structures are and are not represented by neural language models.", "labels": [], "entities": []}, {"text": "At the same time, work using artificial languages as input has demonstrated that LSTMs are capable of inducing the data structures required to produce hierarchically-structured sequences.", "labels": [], "entities": []}, {"text": "For example, showed that LSTMs can learn to produce strings of the form an b n , corresponding to context-free languages), and an b n c n , corresponding to mildly context-sensitive languages.", "labels": [], "entities": []}, {"text": "Producing these strings requires a stack-like data structure where some number of as are pushed onto the stack so that the same number of bs can be popped from: Anatomy of a center embedding sentence.", "labels": [], "entities": []}, {"text": "At each point marked PUSH, comprehenders need to push the expectations generated by the subject noun onto a stack-like data structure, and suppress those expectations going forward.", "labels": [], "entities": [{"text": "PUSH", "start_pos": 21, "end_pos": 25, "type": "METRIC", "confidence": 0.9753606915473938}]}, {"text": "At the points marked POP, they must recover those expectations. it.", "labels": [], "entities": [{"text": "POP", "start_pos": 21, "end_pos": 24, "type": "METRIC", "confidence": 0.9946874380111694}]}, {"text": "The hierarchical structures of natural language are widely believed to be mildly context-sensitive, so this result shows that LSTMs are practically capable of inducing the proper data structures to handle the hierarchical structure of natural language.", "labels": [], "entities": []}, {"text": "What remains to be seen in a general way is that LSTMs induce and use these structures when trained on natural language input, rather than artificial language input.", "labels": [], "entities": []}, {"text": "In this work, we present two suites of experiments that probe for evidence of hierarchical generalizations using two linguistic structures: center embedding sentences and syntactic island constraints on the filler-gap dependency.", "labels": [], "entities": []}, {"text": "These structures exemplify context-free hierarchical structure in natural language.", "labels": [], "entities": []}, {"text": "In order to correctly predict words in these structures, a model must use something like a stack data structure: certain expectations must be temporarily suppressed (pushed onto a stack), then recovered later at the right time and in the right order (popped from the stack in last-in-first-out order), as shown in.", "labels": [], "entities": []}, {"text": "For both of these contexts we assess how well RNNs can suppress local expectations within intervening blocking-structures and recover expectations on the far side.", "labels": [], "entities": []}, {"text": "Success at these tasks would provide evidence that models not only ignore intervening material, but modulate and recover local expectations based on relative location within a syntactic structure.", "labels": [], "entities": []}, {"text": "Center embeddings are sentences in which a clause is embedded within the center of another clause, such that the expectations based on the external clause must be temporarily suppressed during the internal clause, and then recovered once the internal clause is complete.", "labels": [], "entities": []}, {"text": "Such sentences were used as the original argument that natural language is not a regular language, but rather at least context-free).", "labels": [], "entities": []}, {"text": "We find that neural language models can successfully suppress and recover expectations in sentences with twolayer embedding depth, but their accuracy depends on the particular lexical items used.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 141, "end_pos": 149, "type": "METRIC", "confidence": 0.9954882264137268}]}, {"text": "Syntactic Islands are structural configurations that block the filler-gap dependency, which is the dependency between a wh-word, such as who or what, and a gap, which is an empty syntactic position.", "labels": [], "entities": []}, {"text": "Using controlled experimental material, we find that models are able to suppress expectations for gaps inside two island constructions and partially recover them on the far side.", "labels": [], "entities": []}, {"text": "However, the recovered expectation is far weaker than in nonisland sentences and only robust in one of the models tested.", "labels": [], "entities": [{"text": "recovered expectation", "start_pos": 13, "end_pos": 34, "type": "METRIC", "confidence": 0.9199174642562866}]}, {"text": "Together, both experiments provide new evidence that RNN language models can approximate a soft notion of hierarchy to drive predictions, suppressing local expectations in some contexts and reactivating them based on relative syntactic position.", "labels": [], "entities": []}, {"text": "Overall our results show that the LSTMs tested have learned an approximate stack-like data structure to predict natural language, but the deployment of this structure depends on the particular lexical items used, and the recovery of expectations is often imperfect, especially for structures requiring deep stacks.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this work, we adapt psycholinguistic experimental techniques for neural model assessment.", "labels": [], "entities": [{"text": "neural model assessment", "start_pos": 68, "end_pos": 91, "type": "TASK", "confidence": 0.6457793513933817}]}, {"text": "In this paradigm, neural models are fed handcrafted sentences designed to belie underlying network knowledge.", "labels": [], "entities": []}, {"text": "Following standard practice in psycholinguistics, statistical significance is derived from linear mixed-effects models (, with sum-coded fixed-effect predictors and maximal random slope structure (.", "labels": [], "entities": []}, {"text": "This method permits us to factor out by-item variation and focus on differences in model behavior on materials differing only in the linguistic features of critical interest.", "labels": [], "entities": []}], "tableCaptions": []}