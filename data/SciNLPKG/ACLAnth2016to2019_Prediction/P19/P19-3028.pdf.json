{"title": [{"text": "Parallax: Visualizing and Understanding the Semantics of Embedding Spaces via Algebraic Formulae", "labels": [], "entities": []}], "abstractContent": [{"text": "Embeddings area fundamental component of many modern machine learning and natural language processing models.", "labels": [], "entities": []}, {"text": "Understanding them and visualizing them is essential for gathering insights about the information they capture and the behavior of the models.", "labels": [], "entities": []}, {"text": "In this paper, we introduce Parallax 1 , a tool explicitly designed for this task.", "labels": [], "entities": []}, {"text": "Parallax allows the user to use both state-of-the-art embedding analysis methods (PCA and t-SNE) and a simple yet effective task-oriented approach where users can explicitly define the axes of the projection through algebraic formulae.", "labels": [], "entities": []}, {"text": "In this approach, embeddings are projected into a semantically meaningful subspace, which enhances inter-pretability and allows for more fine-grained analysis.", "labels": [], "entities": []}, {"text": "We demonstrate 2 the power of the tool and the proposed methodology through a series of case studies and a user study.", "labels": [], "entities": []}], "introductionContent": [{"text": "Learning representations is an important part of modern machine learning and natural language processing.", "labels": [], "entities": []}, {"text": "These representations are often realvalued vectors also called embeddings and are obtained both as byproducts of supervised learning or as the direct goal of unsupervised methods.", "labels": [], "entities": []}, {"text": "Independently of how the embeddings are learned, there is much value in understanding what information they capture, how they relate to each other and how the data they are learned from influences them.", "labels": [], "entities": []}, {"text": "A better understanding of the embedded space may lead to a better understanding of the data, of the problem and the behavior of the model, and may lead to critical insights in improving such models.", "labels": [], "entities": []}, {"text": "Because of their high-dimensional nature, they are hard to visualize effectively.", "labels": [], "entities": []}, {"text": "* Work done while at Purdue University 1 http://github.com/uber-research/parallax 2 https://youtu.be/CSkJGVsFPIg In this paper, we introduce Parallax, a tool for visualizing embedding spaces.", "labels": [], "entities": []}, {"text": "The most widely adopted projection techniques (Principal Component Analysis (PCA) and tDistributed Stochastic Neighbor Embedding (t-SNE)) are available in Parallax.", "labels": [], "entities": []}, {"text": "They are useful for obtaining an overall view of the embedding space, but they have a few shortcomings: 1) projections may not preserve distance in the original space, 2) they are not comparable across models and 3) do not provide interpretable axes, preventing more detailed analysis and understanding.", "labels": [], "entities": []}, {"text": "PCA projects embeddings on a lower dimensional space that has the directions of the highest variance in the dataset as axes.", "labels": [], "entities": []}, {"text": "Those dimensions do not carry any interpretable meaning, so by visualizing the first two dimensions of a PCA projection, the only insight obtainable is semantic relatedness () between points by observing their relative closeness, and therefore, topical clusters can be identified.", "labels": [], "entities": []}, {"text": "Moreover, as the directions of highest variance differ from embedding space to embedding space, the projections are incompatible among different embeddings spaces, and this makes them incomparable, a common issue among dimensionality reduction techniques.", "labels": [], "entities": [{"text": "dimensionality reduction", "start_pos": 219, "end_pos": 243, "type": "TASK", "confidence": 0.7474339604377747}]}, {"text": "t-SNE, differently from PCA, optimizes a loss that encourages embeddings that are in their respective close neighborhoods in the original highdimensional space to be close in the lower dimensional projection space.", "labels": [], "entities": []}, {"text": "t-SNE projections visually approximate better the original embedding space and topical clusters are more clearly distinguishable, but do not solve the issue of comparability of two different sets of embeddings, nor do they solve the lack of interpretability of the axes or allow for fine-grained inspection.", "labels": [], "entities": []}, {"text": "For these reasons, there is value in mapping embeddings into a more specific, controllable and interpretable semantic space.", "labels": [], "entities": []}, {"text": "In this paper, anew and simple method to inspect, explore and debug embedding spaces at a fine-grained level is proposed.", "labels": [], "entities": []}, {"text": "This technique is made available in Parallax alongside PCA and t-SNE for goal-oriented analysis of the embedding spaces.", "labels": [], "entities": []}, {"text": "It consists of explicitly defining the axes of projection through formulae in vector algebra that use embedding labels as atoms.", "labels": [], "entities": []}, {"text": "Explicit axis definition assigns interpretable and fine-grained semantics to the axes of projection.", "labels": [], "entities": []}, {"text": "This makes it possible to analyze in detail how embeddings relate to each other with respect to interpretable dimensions of variability, as carefully crafted formulas can map (to a certain extent) to semantically meaningful portions of the space.", "labels": [], "entities": []}, {"text": "The explicit axes definition also allows for the comparison of embeddings obtained from different datasets, as long as they have common labels and are equally normalized.", "labels": [], "entities": []}, {"text": "We demonstrate three visualizations that Parallax provides for analyzing subspaces of interest of embedding spaces and a set of example case studies including bias detection, polysemy analysis and fine-grained embedding analysis, but additional ones, like diachronic analysis and the analysis of representations obtained through graph learning or any other means, maybe performed as easily.", "labels": [], "entities": [{"text": "bias detection", "start_pos": 159, "end_pos": 173, "type": "TASK", "confidence": 0.7252040505409241}]}, {"text": "Moreover, the proposed visualizations can be used for debugging purposes and, in general, for obtaining a better understanding of the embedding spaces learned by different models and representation learning approaches.", "labels": [], "entities": []}, {"text": "We show how this methodology can be widely used through a series of case studies on well known models and data, and furthermore, we validate its usefulness for goal-oriented analysis through a user study.", "labels": [], "entities": []}, {"text": "Parallax interface, shown in, presents a plot on the left side (scatter or polar) and controls on the right side that allow users to define parameters of the projection (what measure to use, values for the hyperparameters, the formuale for the axes in case of explicit axes projections are selected, etc.) and additional filtering and visualization parameters.", "labels": [], "entities": []}, {"text": "Filtering parameters define logic rules applied to embeddings metadata to decide which of them should be visualized, e.g., the user can decide to visualize only the most frequent words or only verbs if metadata about part-of-speech tags is made available.", "labels": [], "entities": []}, {"text": "Filters on the embeddings themselves can also be defined, e.g., the user can decide to visualize only the embeddings with cosine similarity above 0.5 to the embedding of \"horse\".", "labels": [], "entities": []}, {"text": "In particular, Parallax's capability of explicitly defining axes is useful for goal-oriented analyses, e.g., when the user has a specific analysis goal in mind, like detecting bias in the embeddings space.", "labels": [], "entities": []}, {"text": "Goals are defined in terms of dimensions of variability (axes of projection) and items to visualize (all the embeddings that are projected, after filtering).", "labels": [], "entities": []}, {"text": "In the case of a few dimensions of variability (up to three) and potentially many items of interest, a Cartesian view is ideal.", "labels": [], "entities": []}, {"text": "Each axis is the vector obtained by evaluating the algebraic formula it is associated with, and the coordinates displayed are similarities or distances of the items with respect to each axis.", "labels": [], "entities": []}, {"text": "shows an example of a bi-dimensional Cartesian view.", "labels": [], "entities": []}, {"text": "In the case where the goal is defined in terms of many dimensions of variability, a polar view is preferred.", "labels": [], "entities": []}, {"text": "The polar view can visualize many more axes by showing them in a circle, but it is limited in the number of items it can display, as each item will be displayed as a polygon with each vertex lying on a different axis and too many overlapping polygons would make the visualization cluttered.", "labels": [], "entities": []}, {"text": "shows an example of a five-dimensional polar view.", "labels": [], "entities": []}, {"text": "The use of explicit axes allows for interpretable comparison of different embedding spaces, trained on different corpora or on the same corpora but with different models, or even trained on two different time slices of the same corpora.", "labels": [], "entities": []}, {"text": "The only requirement for embedding spaces to be comparable is that they contain embeddings for all labels present in the formulae defining the axes.", "labels": [], "entities": []}, {"text": "Moreover, embeddings in the two spaces do not need to be of the same dimension, but they need to be normalized.", "labels": [], "entities": []}, {"text": "Items will now have two sets of coordinates, one for each embedding space, and thus they will be displayed as lines.", "labels": [], "entities": []}, {"text": "Short lines are interpreted as items being embedded similarly in the subspaces defined by the axes in both embedding spaces, while long lines are interpreted as really different locations in the subspaces, and their direction gives insight on how items shift in the two subspaces.", "labels": [], "entities": []}, {"text": "The bottom side of shows an example of how to use the Cartesian comparison view to compare embeddings in two datasets.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Two-way ANOVA analyses of Task (Com- monality vs. Polarization) and Obfuscation (Obfus- cated vs. Non-obfuscated) over Projection (Explicit  Formulae vs. t-SNE).", "labels": [], "entities": [{"text": "Obfuscation", "start_pos": 78, "end_pos": 89, "type": "METRIC", "confidence": 0.9546042680740356}]}]}