{"title": [], "abstractContent": [{"text": "This paper describes the two submissions of Universitat d'Alacant to the English-to-Kazakh news translation task at WMT 2019.", "labels": [], "entities": [{"text": "English-to-Kazakh news translation task at WMT 2019", "start_pos": 73, "end_pos": 124, "type": "TASK", "confidence": 0.6998185004506793}]}, {"text": "Our submissions take advantage of monolin-gual data and parallel data from other language pairs by means of iterative backtransla-tion, pivot backtranslation and transfer learning.", "labels": [], "entities": []}, {"text": "They also use linguistic information in two ways: morphological segmentation of Kazakh text, and integration of the output of a rule-based machine translation system.", "labels": [], "entities": []}, {"text": "Our systems were ranked 2 nd in terms of chrF++ despite being built from an ensemble of only 2 independent training runs.", "labels": [], "entities": []}], "introductionContent": [{"text": "This paper describes the Universitat d'Alacant submissions to the WMT 2019 news translation task.", "labels": [], "entities": [{"text": "WMT 2019 news translation task", "start_pos": 66, "end_pos": 96, "type": "TASK", "confidence": 0.7388581454753875}]}, {"text": "Our two submissions address the low-resource English-to-Kazakh language pair, for which only a few thousand in-domain parallel sentences are available.", "labels": [], "entities": []}, {"text": "In order to build competitive neural machine translation (NMT) systems, we generated synthetic training data.", "labels": [], "entities": [{"text": "competitive neural machine translation (NMT)", "start_pos": 18, "end_pos": 62, "type": "TASK", "confidence": 0.8480475289481026}]}, {"text": "We took advantage of the available English-Russian (en-ru) and Kazakh-Russian (kk-ru) parallel data by means of pivot backtranslation and transfer learning, and integrated monolingual data by means of iterative backtranslation.", "labels": [], "entities": []}, {"text": "In addition, we used linguistic information in two different ways: we morphologically segmented the Kazakh text to make the system generalize better from the training data; and we built a hybrid system combining NMT and the Apertium English-to-Kazakh rule-based machine translation (RBMT) system.", "labels": [], "entities": [{"text": "Apertium English-to-Kazakh rule-based machine translation (RBMT)", "start_pos": 224, "end_pos": 288, "type": "TASK", "confidence": 0.6318081729114056}]}, {"text": "The rest of the paper is organized as follows.", "labels": [], "entities": []}, {"text": "Section 2 describes how corpora were filtered and preprocessed, and the steps followed to train NMT systems from them.", "labels": [], "entities": []}, {"text": "Section 3 outlines the process followed to obtain synthetic training data.", "labels": [], "entities": []}, {"text": "Sections 4 and 5 describe respectively morphological segmentation and hybridization with Apertium.", "labels": [], "entities": [{"text": "morphological segmentation", "start_pos": 39, "end_pos": 65, "type": "TASK", "confidence": 0.8057142496109009}, {"text": "Apertium", "start_pos": 89, "end_pos": 97, "type": "DATASET", "confidence": 0.9694613814353943}]}, {"text": "The model ensembles we submitted are then presented in Section 6.", "labels": [], "entities": []}, {"text": "The paper ends with some concluding remarks.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 3: Results obtained by the different strategies  evaluated for combining the available parallel corpora.", "labels": [], "entities": []}, {"text": " Table 4: Results obtained by the different strategies  evaluated for combining parallel corpora and the back- translated data.", "labels": [], "entities": []}, {"text": " Table 5: Examples of Kazakh words, their morphological analyses, and their segmentation.", "labels": [], "entities": []}, {"text": " Table 6: Results obtained by the different strate- gies evaluated for integrating the Apertium English-to- Kazakh rule-based machine translation system into an  NMT system. Scores of hybrid systems are shown in  bold if they outperform the corresponding pure NMT  system by a statistically significant margin.", "labels": [], "entities": [{"text": "Apertium English-to- Kazakh rule-based machine translation", "start_pos": 87, "end_pos": 145, "type": "TASK", "confidence": 0.6489721621785846}]}, {"text": " Table 7: Results obtained by our submissions, single- model alternatives, and systems submitted by other  teams, computed on newstest2019. There are no  statistically significant differences for any of the evalu- ation metrics between our 5-Transformer ensemble and  the NEU submission.", "labels": [], "entities": [{"text": "newstest2019", "start_pos": 126, "end_pos": 138, "type": "DATASET", "confidence": 0.965090274810791}, {"text": "NEU submission", "start_pos": 272, "end_pos": 286, "type": "DATASET", "confidence": 0.9373831450939178}]}]}