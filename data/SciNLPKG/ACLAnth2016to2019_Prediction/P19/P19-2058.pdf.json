{"title": [{"text": "Detecting Adverse Drug Reactions from Biomedical Texts With Neural Networks", "labels": [], "entities": [{"text": "Detecting Adverse Drug Reactions from Biomedical Texts With Neural Networks", "start_pos": 0, "end_pos": 75, "type": "TASK", "confidence": 0.8209106534719467}]}], "abstractContent": [{"text": "Detection of adverse drug reactions in post-approval periods is a crucial challenge for pharmacology.", "labels": [], "entities": [{"text": "Detection of adverse drug reactions", "start_pos": 0, "end_pos": 35, "type": "TASK", "confidence": 0.8523079633712769}]}, {"text": "Social media and electronic clinical reports are becoming increasingly popular as a source for obtaining health-related information.", "labels": [], "entities": []}, {"text": "In this work, we focus on extraction information of adverse drug reactions from various sources of biomedical text-based information, including biomedical literature and social media.", "labels": [], "entities": [{"text": "extraction information of adverse drug reactions", "start_pos": 26, "end_pos": 74, "type": "TASK", "confidence": 0.8266127705574036}]}, {"text": "We formulate the problem as a binary classification task and compare the performance of four state-of-the-art attention-based neural networks in terms of the F-measure.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 158, "end_pos": 167, "type": "METRIC", "confidence": 0.9682263731956482}]}, {"text": "We show the effectiveness of these methods on four different benchmarks.", "labels": [], "entities": []}], "introductionContent": [{"text": "Detection of adverse drug reactions (ADRs) in the post-marketing period is becoming increasingly popular, as evidenced by the growth of ADR monitoring systems.", "labels": [], "entities": [{"text": "Detection of adverse drug reactions (ADRs)", "start_pos": 0, "end_pos": 42, "type": "TASK", "confidence": 0.8919838815927505}]}, {"text": "Information about adverse drug reactions can be found in the texts of social media, health-related forums, and electronic health records.", "labels": [], "entities": []}, {"text": "We formulated the problem as a binary classification task.", "labels": [], "entities": [{"text": "binary classification task", "start_pos": 31, "end_pos": 57, "type": "TASK", "confidence": 0.7773968974749247}]}, {"text": "The ADR classification task addresses two sub-tasks: (a) detecting the presence of ADRs in a textual message (messagelevel task) and (b) detecting the class of an entity within a message (entity-level task).", "labels": [], "entities": [{"text": "ADR classification task", "start_pos": 4, "end_pos": 27, "type": "TASK", "confidence": 0.8948226173718771}, {"text": "detecting the presence of ADRs in a textual message", "start_pos": 57, "end_pos": 108, "type": "TASK", "confidence": 0.7445462544759115}]}, {"text": "In this paper, we focus on the latter task.", "labels": [], "entities": []}, {"text": "Different from the message-level classification task, which aims to determine whether a textual fragment such as tweet or an abstract of a paper includes an ADR mention or not, the objective of the entity-level task is to detect whether a given entity (a single word or a multi-word expression) conveys adverse drug effect in the context of a message.", "labels": [], "entities": [{"text": "message-level classification", "start_pos": 19, "end_pos": 47, "type": "TASK", "confidence": 0.7707384824752808}]}, {"text": "For example, in \"He was unable to sleep last night because of pain\", the health condition 'pain' trigger insomnia.", "labels": [], "entities": []}, {"text": "Meanwhile, in \"after 3 days on this drug I was unable to sleep due to symptoms like a very bad attack of RLS\", there is an entity 'unable to sleep' associated with drug use and can be classified as ADR.", "labels": [], "entities": [{"text": "RLS", "start_pos": 105, "end_pos": 108, "type": "METRIC", "confidence": 0.9228853583335876}]}, {"text": "Inspired by recent successful methods, we investigated various deep neural network models for entity-level ADR classification).", "labels": [], "entities": [{"text": "ADR classification", "start_pos": 107, "end_pos": 125, "type": "TASK", "confidence": 0.8186491131782532}]}, {"text": "Our previous experiments showed that Interactive Attention Neural network (IAN) () outperforms other models based on LSTM.", "labels": [], "entities": []}, {"text": "In this paper, we continue our study and compare IAN with the following attention-based neural networks for entity-level ADR classification: (i) Attention-over-Attention (AOA) model; (ii) Attentional Encoder Network (AEN) (; (iii) Attention-based LSTM with Aspect Embedding (ATAE-LSTM) (.", "labels": [], "entities": [{"text": "ADR classification", "start_pos": 121, "end_pos": 139, "type": "TASK", "confidence": 0.80201855301857}]}, {"text": "We conduct extensive experiments on four benchmarks which consist of scientific abstracts and user-generated texts about drug therapy.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section, we compare the performance of the discussed neural networks with Interactive Attention Neural Network.", "labels": [], "entities": []}, {"text": "All models were evaluated by 5-fold crossvalidation.", "labels": [], "entities": []}, {"text": "We utilized the F-measure to evaluate 1 https://github.com/songyouwei/ABSA-PyTorch the quality of the classification.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 16, "end_pos": 25, "type": "METRIC", "confidence": 0.9912961721420288}]}, {"text": "The results are presented in.", "labels": [], "entities": []}, {"text": "The results show that IAN outperformed other models on all corpora.", "labels": [], "entities": [{"text": "IAN", "start_pos": 22, "end_pos": 25, "type": "METRIC", "confidence": 0.6985860466957092}]}, {"text": "IAN obtained the most significant increase in results compared to other models on Cadec and Twitter-Pubmed corpora with 81.5% and 87.4% of the macro F-measures, respectively.", "labels": [], "entities": [{"text": "IAN", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.689304769039154}, {"text": "Cadec", "start_pos": 82, "end_pos": 87, "type": "DATASET", "confidence": 0.9769831895828247}, {"text": "F-measures", "start_pos": 149, "end_pos": 159, "type": "METRIC", "confidence": 0.8277226090431213}]}, {"text": "We assume that the superiority of the IAN results in comparison with other models is due to the small number of parameters being trained and the small size of the corpora.", "labels": [], "entities": [{"text": "IAN", "start_pos": 38, "end_pos": 41, "type": "TASK", "confidence": 0.5070775747299194}]}, {"text": "The AOA model achieved the second-place result on all corpora except Twitter.", "labels": [], "entities": [{"text": "AOA", "start_pos": 4, "end_pos": 7, "type": "METRIC", "confidence": 0.8751086592674255}]}, {"text": "The AOA results for PsyTAR (81.5%) and Twimed-Twitter (79.5%) corpora state on par with IAN model, while for the rest corpora, the results are significantly lower.", "labels": [], "entities": [{"text": "AOA", "start_pos": 4, "end_pos": 7, "type": "METRIC", "confidence": 0.9953717589378357}]}, {"text": "This leads to the conclusion that the model is unstable for highly imbalanced corpora.", "labels": [], "entities": []}, {"text": "The ATAE-LSTM model with 78.6% of macro F-measure outperformed AEN and AOA models results on Twitter corpora and achieved comparable with AOA results on Twimed-Pubmed corpora (80.1%).", "labels": [], "entities": [{"text": "ATAE-LSTM", "start_pos": 4, "end_pos": 13, "type": "METRIC", "confidence": 0.9690365195274353}, {"text": "AEN", "start_pos": 63, "end_pos": 66, "type": "METRIC", "confidence": 0.9858120679855347}, {"text": "AOA", "start_pos": 71, "end_pos": 74, "type": "METRIC", "confidence": 0.9545885324478149}, {"text": "AOA", "start_pos": 138, "end_pos": 141, "type": "METRIC", "confidence": 0.9949883222579956}]}, {"text": "This result shows that ATAE-LSTM applicable to a small size imbalanced corpora.", "labels": [], "entities": [{"text": "ATAE-LSTM", "start_pos": 23, "end_pos": 32, "type": "METRIC", "confidence": 0.975186288356781}]}, {"text": "The AEN model achieved comparable with other models results on PsyTAR (80.2%) corpora and significantly lower results on Twitter (66.7%), Cadec (49%) and Twimed-Pubmed (74.3%) corpora.", "labels": [], "entities": [{"text": "AEN", "start_pos": 4, "end_pos": 7, "type": "METRIC", "confidence": 0.9012459516525269}, {"text": "Cadec", "start_pos": 138, "end_pos": 143, "type": "DATASET", "confidence": 0.8925632834434509}]}, {"text": "72.4% of F-measure on Twimed-Twitter corpus states on par with the ATAE-LSTM model (73.5%).", "labels": [], "entities": [{"text": "F-measure", "start_pos": 9, "end_pos": 18, "type": "METRIC", "confidence": 0.9922037124633789}, {"text": "Twimed-Twitter corpus", "start_pos": 22, "end_pos": 43, "type": "DATASET", "confidence": 0.9568994045257568}, {"text": "ATAE-LSTM", "start_pos": 67, "end_pos": 76, "type": "METRIC", "confidence": 0.9644798636436462}]}, {"text": "This leads to the conclusion that the presence of multiple attention layers did not give the improvement in results.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Summary statistics of corpora.", "labels": [], "entities": []}, {"text": " Table 2: Macro F-measure classification results of the compared methods for each datasets.", "labels": [], "entities": [{"text": "Macro F-measure classification", "start_pos": 10, "end_pos": 40, "type": "TASK", "confidence": 0.7003265122572581}]}]}