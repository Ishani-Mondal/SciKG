{"title": [{"text": "Every child should have parents: a taxonomy refinement algorithm based on hyperbolic term embeddings", "labels": [], "entities": []}], "abstractContent": [{"text": "We introduce the use of Poincar\u00e9 embeddings to improve existing state-of-the-art approaches to domain-specific taxonomy induction from text as a signal for both relocating wrong hy-ponym terms within a (pre-induced) taxonomy as well as for attaching disconnected terms in a taxonomy.", "labels": [], "entities": [{"text": "taxonomy induction", "start_pos": 111, "end_pos": 129, "type": "TASK", "confidence": 0.7036461681127548}]}, {"text": "This method substantially improves previous state-of-the-art results on the SemEval-2016 Task 13 on taxonomy extraction.", "labels": [], "entities": [{"text": "SemEval-2016 Task 13", "start_pos": 76, "end_pos": 96, "type": "TASK", "confidence": 0.752520481745402}, {"text": "taxonomy extraction", "start_pos": 100, "end_pos": 119, "type": "TASK", "confidence": 0.8143163919448853}]}, {"text": "We demonstrate the superiority of Poincar\u00e9 embeddings over distributional semantic representations, supporting the hypothesis that they can better capture hierarchical lexical-semantic relationships than embed-dings in the Euclidean space.", "labels": [], "entities": []}], "introductionContent": [{"text": "The task of taxonomy induction aims at creating a semantic hierarchy of entities by using hyponym-hypernym relations -called taxonomyfrom text corpora.", "labels": [], "entities": [{"text": "taxonomy induction", "start_pos": 12, "end_pos": 30, "type": "TASK", "confidence": 0.8669081628322601}]}, {"text": "Compared to many other domains of natural language processing that make use of pre-trained dense representations, state-ofthe-art taxonomy learning is still highly relying on traditional approaches like extraction of lexicalsyntactic patterns or co-occurrence information.", "labels": [], "entities": []}, {"text": "Despite the success of pattern-based approaches, most taxonomy induction systems suffer from a significant number of disconnected terms, since the extracted relationships are too specific to cover most words (.", "labels": [], "entities": [{"text": "taxonomy induction", "start_pos": 54, "end_pos": 72, "type": "TASK", "confidence": 0.7948547005653381}]}, {"text": "The use of distributional semantics for hypernym identification and relation representation has thus received increasing attention.", "labels": [], "entities": [{"text": "hypernym identification", "start_pos": 40, "end_pos": 63, "type": "TASK", "confidence": 0.8432039022445679}, {"text": "relation representation", "start_pos": 68, "end_pos": 91, "type": "TASK", "confidence": 0.8199427425861359}]}, {"text": "However, observe that many proposed supervised approaches instead learn prototypical hypernyms (that are hypernyms to many other terms), not taking into account the relation between both terms in classification.", "labels": [], "entities": []}, {"text": "Therefore, past applications of distributional semantics appear to be rather unsuitable to be directly applied to taxonomy induction as the sole signal (.", "labels": [], "entities": [{"text": "taxonomy induction", "start_pos": 114, "end_pos": 132, "type": "TASK", "confidence": 0.832856684923172}]}, {"text": "We address that issue by introducing a series of simple and parameter-free refinement steps that employ word embeddings in order to improve existing domain-specific taxonomies, induced from text using traditional approaches in an unsupervised fashion.", "labels": [], "entities": []}, {"text": "We compare two types of dense vector embeddings: the standard word2vec CBOW model (, that embeds terms in Euclidean space based on distributional similarity, and the more recent Poincar\u00e9 embeddings (, which capture similarity as well as hierarchical relationships in a hyperbolic space.", "labels": [], "entities": []}, {"text": "The source code has been published 1 to recreate the employed embedding, to refine taxonomies as well as to enable further research of Poincar\u00e9 embeddings for other semantic tasks.", "labels": [], "entities": []}], "datasetContent": [{"text": "Proposed methods are evaluated on the data of SemEval2016 TExEval (Bordea et al., 2016) for submitted systems that created taxonomies for all domains of the task 4 , namely the task-winning system TAXI () as well as the systems USAAR ( and JUNLP (.", "labels": [], "entities": [{"text": "SemEval2016 TExEval", "start_pos": 46, "end_pos": 65, "type": "DATASET", "confidence": 0.45934535562992096}, {"text": "USAAR", "start_pos": 228, "end_pos": 233, "type": "DATASET", "confidence": 0.9697253108024597}]}, {"text": "TAXI harvests hypernyms with substring inclusion and lexicalsyntactic patterns by obtaining domain-specific texts via focused web crawling.", "labels": [], "entities": []}, {"text": "USAAR and JUNLP heavily rely on rule-based approaches.", "labels": [], "entities": [{"text": "USAAR", "start_pos": 0, "end_pos": 5, "type": "DATASET", "confidence": 0.9830369353294373}, {"text": "JUNLP", "start_pos": 10, "end_pos": 15, "type": "DATASET", "confidence": 0.9052270650863647}]}, {"text": "While USAAR exploits the endocentric nature of hyponyms, JUNLP combines two string inclusion heuristics with semantic relations from BabelNet.", "labels": [], "entities": [{"text": "USAAR", "start_pos": 6, "end_pos": 11, "type": "DATASET", "confidence": 0.9639061093330383}]}, {"text": "We use the taxonomies created by these systems as our baseline and additionally ensured that taxonomies do neither have circles nor in-going edges to the taxonomy root by applying the Tarjan algorithm, removing a random link from detected cycles.", "labels": [], "entities": []}, {"text": "This causes slight differences between the baseline results in and (Bordea et al., 2016).", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Example words with respective parent(s) in the input taxonomy and after refinement using our domain- specfic Poincar\u00e9 embeddings, as well as the word's closest three neighbors (incl. orphans) in embeddings.", "labels": [], "entities": []}, {"text": " Table 2: Number of attached orphans in taxonomies  created by TAXI using different embeddings.", "labels": [], "entities": [{"text": "TAXI", "start_pos": 63, "end_pos": 67, "type": "DATASET", "confidence": 0.9108082056045532}]}, {"text": " Table 3: F 1 comparison between original (TAXI) and  refined taxonomy using domain-specific embeddings.", "labels": [], "entities": [{"text": "F", "start_pos": 10, "end_pos": 11, "type": "METRIC", "confidence": 0.9763245582580566}]}]}