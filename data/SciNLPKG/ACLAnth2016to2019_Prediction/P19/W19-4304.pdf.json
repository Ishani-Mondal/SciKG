{"title": [{"text": "An Evaluation of Language-Agnostic Inner-Attention-Based Representations in Machine Translation", "labels": [], "entities": [{"text": "Machine Translation", "start_pos": 76, "end_pos": 95, "type": "TASK", "confidence": 0.721613347530365}]}], "abstractContent": [{"text": "In this paper, we explore a multilingual translation model with a cross-lingually shared layer that can be used as fixed-size sentence representation in different downstream tasks.", "labels": [], "entities": []}, {"text": "We systematically study the impact of the size of the shared layer and the effect of including additional languages in the model.", "labels": [], "entities": []}, {"text": "In contrast to related previous work, we demonstrate that the performance in translation does correlate with trainable downstream tasks.", "labels": [], "entities": [{"text": "translation", "start_pos": 77, "end_pos": 88, "type": "TASK", "confidence": 0.9708238244056702}]}, {"text": "In particular , we show that larger intermediate layers not only improve translation quality, especially for long sentences, but also push the accuracy of trainable classification tasks.", "labels": [], "entities": [{"text": "translation", "start_pos": 73, "end_pos": 84, "type": "TASK", "confidence": 0.9616693258285522}, {"text": "accuracy", "start_pos": 143, "end_pos": 151, "type": "METRIC", "confidence": 0.999065101146698}, {"text": "trainable classification tasks", "start_pos": 155, "end_pos": 185, "type": "TASK", "confidence": 0.6847910682360331}]}, {"text": "On the other hand, shorter representations lead to increased compression that is beneficial in non-trainable similarity tasks.", "labels": [], "entities": [{"text": "compression", "start_pos": 61, "end_pos": 72, "type": "METRIC", "confidence": 0.9554880261421204}]}, {"text": "We hypothesize that the training procedure on the downstream task enables the model to identify the encoded information that is useful for the specific task whereas non-trainable benchmarks can be confused by other types of information also encoded in the representation of a sentence.", "labels": [], "entities": []}], "introductionContent": [{"text": "Neural Machine Translation (NMT) has rapidly become the new Machine Translation (MT) paradigm, significantly improving over the traditional statistical machine translation procedure ( . Recently, several models and variants have been proposed with increased research efforts towards multilingual machine translation (.", "labels": [], "entities": [{"text": "Neural Machine Translation (NMT)", "start_pos": 0, "end_pos": 32, "type": "TASK", "confidence": 0.7808229078849157}, {"text": "Machine Translation (MT)", "start_pos": 60, "end_pos": 84, "type": "TASK", "confidence": 0.8689581036567688}, {"text": "statistical machine translation", "start_pos": 140, "end_pos": 171, "type": "TASK", "confidence": 0.7303773562113444}, {"text": "multilingual machine translation", "start_pos": 283, "end_pos": 315, "type": "TASK", "confidence": 0.6816710432370504}]}, {"text": "The main motivation of multilingual models is the effect of transfer learning that enables machine translation systems to benefit from relationships between languages and training signals that come from different datasets (.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 91, "end_pos": 110, "type": "TASK", "confidence": 0.694356307387352}]}, {"text": "Another aspect that draws interest in translation models is the effective computation of sentence representations using the translation task as an auxiliary semantic signal ().", "labels": [], "entities": [{"text": "translation", "start_pos": 38, "end_pos": 49, "type": "TASK", "confidence": 0.9631416201591492}]}, {"text": "An important feature that enables an immediate use of the MT-based representations in other downstream tasks is the creation of fixed-sized sentence embeddings.", "labels": [], "entities": [{"text": "MT-based representations", "start_pos": 58, "end_pos": 82, "type": "TASK", "confidence": 0.8967004716396332}]}, {"text": "However, the effects of the size of sentence embeddings and the relation between translation performance and meaning representation quality are not entirely clear.", "labels": [], "entities": []}, {"text": "Recent studies based on NMT either focus entirely on the use of MT-based sentence embeddings in other tasks, on translation quality (), on speed comparison (, or only exploring a bilingual scenario.", "labels": [], "entities": [{"text": "MT-based sentence embeddings", "start_pos": 64, "end_pos": 92, "type": "TASK", "confidence": 0.8680156071980795}]}, {"text": "In this paper, we are interested in exploring a cross-lingual intermediate shared layer (called attention bridge) in an attentive encoder-decoder MT model.", "labels": [], "entities": [{"text": "MT", "start_pos": 146, "end_pos": 148, "type": "TASK", "confidence": 0.8681963086128235}]}, {"text": "This shared layer serves as a fixedsize sentence representation that can be straightforwardly applied to downstream tasks.", "labels": [], "entities": []}, {"text": "We examine this model with a systematic evaluation on different sizes of the attention bridge and extensive experiments to study the abstractions it learns from multiple translation tasks.", "labels": [], "entities": []}, {"text": "In contrast to previous work, we demonstrate that there is a correlation between translation performance and trainable downstream tasks when adjusting the size of the intermediate layer.", "labels": [], "entities": [{"text": "translation", "start_pos": 81, "end_pos": 92, "type": "TASK", "confidence": 0.9619702696800232}]}, {"text": "The trend is different for non-trainable tasks that benefit from the increased compression that denser representations achieve, which typically hurts the translation performance because of the decreased capacity of the model.", "labels": [], "entities": []}, {"text": "We also show that multilingual models improve trainable downstream tasks even further, demonstrating the additional abstraction that is pushed into the representations through additional translation tasks involved in training.", "labels": [], "entities": []}], "datasetContent": [{"text": "All models are implemented using the OpenNMT framework () trained using the same set of hyper-parameters.", "labels": [], "entities": []}, {"text": "We use embedding layers of 512 dimensions, two stacked bidirectional LSTM layers with 512 hidden units (256 per direction) and an attentive decoder composed of two unidirectional LSTM layers with 512 units.", "labels": [], "entities": []}, {"text": "Regarding the attention bridge, we experimented with four different configurations: 1, 10, 25 and 50 attention heads with 1024 hidden units each.", "labels": [], "entities": []}, {"text": "For multilingual models, we used a language-rotating scheduler, in which each mini-batch contains sentences from a different language pair, cycling through all the language pairs uniformly.", "labels": [], "entities": []}, {"text": "We selected the best model according to the BLEU score on the validation set.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 44, "end_pos": 48, "type": "METRIC", "confidence": 0.9991568326950073}]}, {"text": "We train all the models using the Europarl Corpus v7, focusing on 4 languages: English (EN), French (FR), German (DE) and Spanish (ES).", "labels": [], "entities": [{"text": "Europarl Corpus v7", "start_pos": 34, "end_pos": 52, "type": "DATASET", "confidence": 0.9872164527575175}]}, {"text": "First we train bilingual models for EN\u2192DE; then we train multilingual models {DE,ES,FR}\u2194EN; lastly we train a final Many-to-Many model using the biggest size, i.e., 50 attention heads, involving all translation directions between the three languages, i.e., we also include DE-ES, DE-FR and ES-FR.", "labels": [], "entities": []}, {"text": "To evaluate the sentence representations we utilize the SentEval toolkit ( sentences.", "labels": [], "entities": []}, {"text": "In order to obtain a sentence vector out of multiple attention heads we apply mean pooling over the attention bridge.", "labels": [], "entities": []}, {"text": "We are also interested in the translation quality to verify the appropriateness of our models with respect to the main objective they are trained for.", "labels": [], "entities": [{"text": "translation", "start_pos": 30, "end_pos": 41, "type": "TASK", "confidence": 0.9694759845733643}]}, {"text": "For this, we adopt the in-domain development and evaluation dataset from the ACL-WMT07 shared task.", "labels": [], "entities": []}, {"text": "Sentences are encoded using Byte-Pair Encoding (, with 32,000 merge operations for each language.", "labels": [], "entities": []}, {"text": "shows the performance of our models on two popular tasks (SNLI and SICK-E) as in as well as the average of all 10 SentEval downstream tasks.", "labels": [], "entities": []}, {"text": "The experiments reveal two important findings:", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Accuracy of different models on two SentE- val tasks as well as the overall average accuracy on all  of them. The general trend is that a higher number of  attention heads and multilingual models are beneficial.  Results with  \u2020 taken from C\u00edfka and Bojar (2018).", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9916337728500366}, {"text": "accuracy", "start_pos": 94, "end_pos": 102, "type": "METRIC", "confidence": 0.9990338087081909}]}, {"text": " Table 2: Results from supervised similarity tasks  (SICK-R and STSB), measured using Pearson's (r) and  Spearman's (\u03c1) correlation coefficients (r/\u03c1). The av- erage across unsupervised similarity tasks on Pearson's  measures are displayed in the right-most column. Re- sults with  \u2020 taken from", "labels": [], "entities": [{"text": "Pearson's (r) and  Spearman's (\u03c1) correlation", "start_pos": 86, "end_pos": 131, "type": "METRIC", "confidence": 0.7383880838751793}, {"text": "av- erage", "start_pos": 156, "end_pos": 165, "type": "METRIC", "confidence": 0.8594969113667806}, {"text": "Re- sults", "start_pos": 266, "end_pos": 275, "type": "METRIC", "confidence": 0.9503972133000692}]}, {"text": " Table 3: BLEU scores for multilingual models. Base- line system in the right-most column.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9982851147651672}]}]}