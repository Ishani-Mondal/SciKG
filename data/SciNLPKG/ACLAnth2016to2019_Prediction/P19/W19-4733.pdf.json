{"title": [{"text": "Modeling a historical variety of a low-resource language: Language contact effects in the verbal cluster of Early-Modern Frisian", "labels": [], "entities": []}], "abstractContent": [{"text": "Certain phenomena of interest to linguists mainly occur in low-resource languages, such as contact-induced language change.", "labels": [], "entities": []}, {"text": "We show that it is possible to study contact-induced language change computationally in a historical variety of a low-resource language, Early-Modern Frisian, by creating a model using features that were established to be relevant in a closely related language, modern Dutch.", "labels": [], "entities": []}, {"text": "This allows us to test two hypotheses on two types of language contact that may have taken place between Frisian and Dutch during this time.", "labels": [], "entities": []}, {"text": "Our model shows that Frisian verb cluster word orders are associated with different context features than Dutch verb orders, supporting the 'learned borrowing' hypothesis.", "labels": [], "entities": []}], "introductionContent": [{"text": "If we want to use computational methods to answer linguistic research questions, a major restriction is that the data-driven methods that are popular in natural language processing today are only applicable to a tiny part of the world's language varieties.", "labels": [], "entities": []}, {"text": "Last decade, it was estimated that significant computational resources were available for \"perhaps 20 or 30 languages\" ().", "labels": [], "entities": []}, {"text": "Efforts to address this have been proposed, such as the Human Language Project (, and to a limited degree executed (i.e. the Universal Dependencies project,).", "labels": [], "entities": []}, {"text": "However, the reality is still that relatively few languages are being studied using quantitative methods.", "labels": [], "entities": []}, {"text": "Many phenomena that are of interest to linguists do not occur in these 20 or 30 languages, of which the larger available corpora mainly contain modern standard varieties in common registers and within easily recorded domains of language.", "labels": [], "entities": []}, {"text": "Specifically, certain phenomena of interest to linguists are characteristic of minority languages, which are by definition used less, and are less likely to have computational resources available.", "labels": [], "entities": []}, {"text": "For example, in cases of language contact where there is a majority language and a lesser used language, contact-induced language change is more likely to occur in the lesser used language.", "labels": [], "entities": []}, {"text": "Furthermore, certain phenomena are better studied in historical varieties of languages.", "labels": [], "entities": []}, {"text": "Taking the example of language change, it is more interesting to study a specific language change once it has already been completed, such that one can study the change itself in historical texts as well as the subsequent outcome of the change.", "labels": [], "entities": []}, {"text": "For these reasons, contact-induced language change is difficult to study computationally, and we consider it a great test case for applying some insights from the recent wave of articles discussing computational linguistics for low-resource languages.", "labels": [], "entities": []}, {"text": "In this work, we apply computational methods, to the extent that it is possible, to gain insight into the nature of language change that occurred in historical West-Frisian, a lesser-used language spoken in the Dutch province of Frysl\u00e2n.", "labels": [], "entities": []}], "datasetContent": [{"text": "We automatically annotate verb clusters and extract their features from the corpus using a Python script that detects verb clusters based on the information already available in the annotation.", "labels": [], "entities": []}, {"text": "In previous work on Dutch, verb clusters were defined using dependency structure or phrase structure, with one verb being the syntactic head of the other.", "labels": [], "entities": []}, {"text": "However, as no syntactic annotation is available, we must rely on part-of-speech tags.", "labels": [], "entities": []}, {"text": "As there is no gold standard data for this task, and little data in general, a statistical modeling approach is infeasible.", "labels": [], "entities": [{"text": "statistical modeling", "start_pos": 79, "end_pos": 99, "type": "TASK", "confidence": 0.7763384878635406}]}, {"text": "Therefore, the script is rule-based, and we define a verb cluster based on the occurrence of bigrams of verbs (according to the existing annotation), or trigrams containing grammatical verb cluster interruptions, as well as the verb classes in the annotation.", "labels": [], "entities": []}, {"text": "The word order of the verb cluster is then determined based on the relative positions of its constituent verbs (a main verb and an auxiliary verb) in the linear order of the sentence.", "labels": [], "entities": []}, {"text": "This procedure is not 100% reliable, especially in clusters with infinitival auxiliary verbs, where auxiliary verbs and main verbs may have the same form.", "labels": [], "entities": []}, {"text": "We checked the classification of a random sample of 50 1-2 order clusters and 50 2-1 order clusters, using only prose text for this evaluation because the script appears to make more mistakes there.", "labels": [], "entities": []}, {"text": "We evaluate only for precision, not for recall, as we have no gold standard data for evaluating recall.", "labels": [], "entities": [{"text": "precision", "start_pos": 21, "end_pos": 30, "type": "METRIC", "confidence": 0.9994440674781799}, {"text": "recall", "start_pos": 40, "end_pos": 46, "type": "METRIC", "confidence": 0.9988436698913574}, {"text": "recall", "start_pos": 96, "end_pos": 102, "type": "METRIC", "confidence": 0.9948891401290894}]}, {"text": "Of the 50 automatically extracted candidate 1-2 clusters, 34 were found to be actual two-verb clusters from subordinate clauses: a precision of 68%.", "labels": [], "entities": [{"text": "precision", "start_pos": 131, "end_pos": 140, "type": "METRIC", "confidence": 0.9987706542015076}]}, {"text": "Of the 50 2-1 clusters, all 50 met this requirement (100% precision).", "labels": [], "entities": [{"text": "precision", "start_pos": 58, "end_pos": 67, "type": "METRIC", "confidence": 0.9981885552406311}]}, {"text": "Most of the erroneous candidate 1-2 order clusters were cases of a finite auxiliary verb in V2 position in a main clause, immediately followed by the main verb in final position, with no intervening objects.", "labels": [], "entities": []}, {"text": "This looks exactly like a 1-2 order cluster consisting of a finite auxiliary verb and a main verb at the end of a subordinate clause.", "labels": [], "entities": []}, {"text": "Main clause clusters cannot look like 2-1 order clusters, which explains the 100% precision for the 2-1 order.", "labels": [], "entities": [{"text": "precision", "start_pos": 82, "end_pos": 91, "type": "METRIC", "confidence": 0.9987936019897461}]}, {"text": "This evaluation shows that a statistical model based on this annotation is likely to overestimate the probability of 1-2 orders.", "labels": [], "entities": []}, {"text": "Due to annotation limitations, several features from Dutch model could not be extracted from our corpus: the tree depth of the verb cluster, the definiteness of the preceding noun, extraposition of the prepositional object, multiword units and the length of the clause.", "labels": [], "entities": []}, {"text": "Verb frequency was estimated by counting over the entire Early-Modern Frisian part of the TDB.", "labels": [], "entities": [{"text": "Verb frequency", "start_pos": 0, "end_pos": 14, "type": "METRIC", "confidence": 0.9369445443153381}, {"text": "Early-Modern Frisian part of the TDB", "start_pos": 57, "end_pos": 93, "type": "DATASET", "confidence": 0.7907639543215433}]}, {"text": "Another factor is that Dutch 1-2 orders have a more uniform information density.", "labels": [], "entities": []}, {"text": "This was found by training a n-gram language model on Dutch corpus data, and then measuring its perplexity over sentences containing verb clusters that were not in its training data.", "labels": [], "entities": [{"text": "Dutch corpus data", "start_pos": 54, "end_pos": 71, "type": "DATASET", "confidence": 0.8346688946088155}]}, {"text": "A 145 million word corpus was used for this, but for Early-Modern Frisian we have less than 0.5 million words available.", "labels": [], "entities": []}, {"text": "A model trained on such diverse texts spanning hundreds of years would require more training data to achieve reasonable perplexity rates than a model trained on newspaper text from a small range of years, thus we cannot reliably operationalize this factor.", "labels": [], "entities": []}, {"text": "However, the Dutch result is likely to apply to Frisian as well, as the reasons for the perplexity values that were found for Dutch can equally apply to Frisian: in both languages, there are few clustering auxiliary verbs and many possible main verbs, and in both languages, the first verb of a cluster helps to predict its second verb and is highly unlikely to be followed by something that is not a verb, as verb cluster interruption rarely occurs in present-day Frisian (.", "labels": [], "entities": []}, {"text": "The main difference between the languages in this regard is that present-day Frisian shows more noun incorporation into the verb cluster's main verb, which may increase informativity of the main verb compared to Dutch in 1-2 orders, but seems rare.", "labels": [], "entities": []}, {"text": "Therefore, we can transfer the knowledge gained with a Dutch language model to Frisian and assume that there is not much difference between the languages regarding verb cluster information density.", "labels": [], "entities": []}, {"text": "Next, we have created a multifactorial logistic regression model using the remaining features.", "labels": [], "entities": []}, {"text": "We model verb cluster order as a binary variable predicted by these features, in which the order can be 1-2 or 2-1.", "labels": [], "entities": [{"text": "verb cluster order", "start_pos": 9, "end_pos": 27, "type": "TASK", "confidence": 0.6285871267318726}]}, {"text": "The advantage of this method over neural networks or other methods involving dimension reduction is that the contribution of each feature is transparent.", "labels": [], "entities": [{"text": "dimension reduction", "start_pos": 77, "end_pos": 96, "type": "TASK", "confidence": 0.712408035993576}]}, {"text": "The goal is after all not to make an optimal classifier for 1-2 and 2-1 order contexts, but to find out more about why language users pro-duced a 1-2 or 2-1 order given a context.", "labels": [], "entities": []}, {"text": "shows the contribution of each feature to the model.", "labels": [], "entities": []}, {"text": "The effect size of each variable is given as an odds ratio, and inline with previous work, we are reporting associations with the 1-2 order.", "labels": [], "entities": []}, {"text": "The model has acceptable multicollinearity (VIF < 1.3) 6 . The text type and year features were not used in previous work, but are necessary control factors when working with historical text.", "labels": [], "entities": [{"text": "VIF", "start_pos": 44, "end_pos": 47, "type": "METRIC", "confidence": 0.994805634021759}]}, {"text": "Much of the text is rhyme, which affects word order: 1-2 orders are estimated to be 18.69 times more likely in rhyming text.", "labels": [], "entities": [{"text": "rhyme", "start_pos": 20, "end_pos": 25, "type": "METRIC", "confidence": 0.9744554758071899}]}], "tableCaptions": [{"text": " Table 1: Effect of different features on the likelihood of  1-2 verbal cluster orders. ** p < 0.01, *** p < 0.001.", "labels": [], "entities": []}]}