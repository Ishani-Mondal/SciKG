{"title": [{"text": "Effective Adversarial Regularization for Neural Machine Translation", "labels": [], "entities": [{"text": "Effective Adversarial Regularization", "start_pos": 0, "end_pos": 36, "type": "TASK", "confidence": 0.5454241037368774}, {"text": "Neural Machine Translation", "start_pos": 41, "end_pos": 67, "type": "TASK", "confidence": 0.7411749362945557}]}], "abstractContent": [{"text": "A regularization technique based on adversar-ial perturbation, which was initially developed in the field of image processing, has been successfully applied to text classification tasks and has yielded attractive improvements.", "labels": [], "entities": [{"text": "image processing", "start_pos": 109, "end_pos": 125, "type": "TASK", "confidence": 0.7708167433738708}, {"text": "text classification tasks", "start_pos": 160, "end_pos": 185, "type": "TASK", "confidence": 0.8797244628270467}]}, {"text": "We aim to further leverage this promising methodology into more sophisticated and critical neu-ral models in the natural language processing field, i.e., neural machine translation (NMT) models.", "labels": [], "entities": [{"text": "neural machine translation (NMT)", "start_pos": 154, "end_pos": 186, "type": "TASK", "confidence": 0.8243393699328104}]}, {"text": "However, it is not trivial to apply this methodology to such models.", "labels": [], "entities": []}, {"text": "Thus, this paper investigates the effectiveness of several possible configurations of applying the adversar-ial perturbation and reveals that the adversar-ial regularization technique can significantly and consistently improve the performance of widely used NMT models, such as LSTM-based and Transformer-based models.", "labels": [], "entities": []}], "introductionContent": [{"text": "The existence of (small) perturbations that induce a critical prediction error in machine learning models was first discovered and discussed in the field of image processing ().", "labels": [], "entities": [{"text": "image processing", "start_pos": 157, "end_pos": 173, "type": "TASK", "confidence": 0.8337323367595673}]}, {"text": "Such perturbed inputs are often referred to as adversarial examples in the literature.", "labels": [], "entities": []}, {"text": "Subsequently, proposed a learning framework that simultaneously leverages adversarial examples as additional training data for reducing the prediction errors.", "labels": [], "entities": []}, {"text": "This learning framework is referred to as adversarial training.", "labels": [], "entities": []}, {"text": "In the field of natural language processing (NLP), the input is a sequence of discrete symbols, such as words or sentences.", "labels": [], "entities": [{"text": "natural language processing (NLP)", "start_pos": 16, "end_pos": 49, "type": "TASK", "confidence": 0.819347987572352}]}, {"text": "Since it is unreasonable to add a small perturbation to the symbols, applying the idea of adversarial training to NLP tasks has been recognized as a challenging problem.", "labels": [], "entities": []}, {"text": "Recently,  , % , +-\" Figure 1: An intuitive sketch that explains how we add adversarial perturbations to atypical NMT model structure for adversarial regularization.", "labels": [], "entities": [{"text": "adversarial regularization", "start_pos": 138, "end_pos": 164, "type": "TASK", "confidence": 0.643296480178833}]}, {"text": "The definitions of e i and f j can be found in Eq.", "labels": [], "entities": []}, {"text": "2. Moreover, those of\u02c6r of\u02c6 of\u02c6r i and\u02c6rand\u02c6 and\u02c6r 0 j are in Eq.", "labels": [], "entities": []}, {"text": "8 and 13, respectively. and reported excellent performance improvements on multiple benchmark datasets of text classification task.", "labels": [], "entities": [{"text": "text classification task", "start_pos": 106, "end_pos": 130, "type": "TASK", "confidence": 0.8637223442395529}]}, {"text": "The key idea of their success is to apply adversarial perturbations into the input embedding layer instead of the inputs themselves as used in image processing tasks.", "labels": [], "entities": []}, {"text": "An important implication of their study is that their method can be interpreted as a regularization method, and thus, they do not focus on generating adversarial examples.", "labels": [], "entities": []}, {"text": "We refer to this regularization technique as adversarial regularization.", "labels": [], "entities": []}, {"text": "We aim to further leverage this promising methodology into more sophisticated and critical neural models, i.e., neural machine translation (NMT) models, since NMT models recently play one of the central roles in the NLP research community; NMT models have been widely utilized for not only NMT but also many other NLP tasks, such as text summarization, grammatical error correction (, dialog generation (, and parsing (.", "labels": [], "entities": [{"text": "neural machine translation (NMT)", "start_pos": 112, "end_pos": 144, "type": "TASK", "confidence": 0.8462187647819519}, {"text": "text summarization", "start_pos": 333, "end_pos": 351, "type": "TASK", "confidence": 0.783846914768219}, {"text": "grammatical error correction", "start_pos": 353, "end_pos": 381, "type": "TASK", "confidence": 0.7051028807957967}, {"text": "dialog generation", "start_pos": 385, "end_pos": 402, "type": "TASK", "confidence": 0.7768547534942627}]}, {"text": "Unfortunately, this application is not fully trivial since we potentially have several configurations for applying adversarial perturbations into NMT models (see details in Section 5).", "labels": [], "entities": []}, {"text": "illustrates the model architecture of NMT models with adversarial perturbation.", "labels": [], "entities": []}, {"text": "Therefore, the goal of this paper is to re-veal the effectiveness of the adversarial regularization in NMT models and encourage researchers/developers to apply the adversarial regularization as a common technique for further improving the performance of their NMT models.", "labels": [], "entities": []}, {"text": "We investigate the effectiveness of several possible configurations that can significantly and consistently improve the performance of typical baseline NMT models, such as LSTM-based and Transformer-based models,", "labels": [], "entities": []}], "datasetContent": [{"text": "We conducted experiments on the IWSLT evaluation campaign dataset ().", "labels": [], "entities": [{"text": "IWSLT evaluation campaign dataset", "start_pos": 32, "end_pos": 65, "type": "DATASET", "confidence": 0.912477508187294}]}, {"text": "We used the IWSLT 2016 training set for training models, 2012 test set (test2012) as the development set, and 2013 and 2014 test sets (test2013 and test2014) as our test sets.", "labels": [], "entities": [{"text": "IWSLT 2016 training set", "start_pos": 12, "end_pos": 35, "type": "DATASET", "confidence": 0.9476791024208069}]}, {"text": "shows the statistics of datasets used in our experiments.", "labels": [], "entities": []}, {"text": "For preprocessing of our experimental datasets, we used the Moses tokenizer 2 and the truecaser 3 . We removed sentences over 50 words from the training set.", "labels": [], "entities": []}, {"text": "We also applied the byte-pair encoding (BPE) based subword splitting script 4 with 16,000 merge operations (Sennrich et al., 2016b).", "labels": [], "entities": [{"text": "subword splitting script 4", "start_pos": 51, "end_pos": 77, "type": "TASK", "confidence": 0.81123948097229}]}], "tableCaptions": [{"text": " Table 1: Number of sentences in our datasets (Datasets  are cleaned from the original dataset).", "labels": [], "entities": []}, {"text": " Table 2: BLEU scores averaged over five models in var- ious configurations of perturbation positions (enc-emb,  dec-emb, or enc-dec-emb) and adversarial regulariza- tion techniques (AdvT or VAT).", "labels": [], "entities": [{"text": "BLEU", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9930917024612427}]}, {"text": " Table 3: BLEU scores averaged over five models in four different language pairs (directions). (b) Results with  using training data increased by back-translation method (BT).", "labels": [], "entities": [{"text": "BLEU", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9954290390014648}, {"text": "BT)", "start_pos": 171, "end_pos": 174, "type": "METRIC", "confidence": 0.8779334723949432}]}]}