{"title": [{"text": "TIGS: An Inference Algorithm for Text Infilling with Gradient Search", "labels": [], "entities": [{"text": "Text Infilling", "start_pos": 33, "end_pos": 47, "type": "TASK", "confidence": 0.7367821335792542}]}], "abstractContent": [{"text": "Text infilling is defined as a task for filling in the missing part of a sentence or paragraph , which is suitable for many real-world natural language generation scenarios.", "labels": [], "entities": [{"text": "natural language generation", "start_pos": 135, "end_pos": 162, "type": "TASK", "confidence": 0.787407636642456}]}, {"text": "However , given a well-trained sequential genera-tive model, generating missing symbols conditioned on the context is challenging for existing greedy approximate inference algorithms.", "labels": [], "entities": []}, {"text": "In this paper, we propose an iterative inference algorithm based on gradient search, which is the first inference algorithm that can be broadly applied to any neural sequence gener-ative models for text infilling tasks.", "labels": [], "entities": []}, {"text": "We compare the proposed method with strong base-lines on three text infilling tasks with various mask ratios and different mask strategies.", "labels": [], "entities": []}, {"text": "The results show that our proposed method is effective and efficient for fill-in-the-blank tasks, consistently outperforming all baselines.", "labels": [], "entities": []}], "introductionContent": [{"text": "Text infilling aims at filling in the missing part of a sentence or paragraph by making use of the past and future information around the missing part, which can be used in many real-world natural language generation scenarios, for example, fill-in-the-blank image captioning (, lexically constrained sentence generation (), missing value reconstruction (e.g. for damaged or historical documents), acrostic poetry generation (, and text representation learning.", "labels": [], "entities": [{"text": "fill-in-the-blank image captioning", "start_pos": 241, "end_pos": 275, "type": "TASK", "confidence": 0.6730593939622244}, {"text": "lexically constrained sentence generation", "start_pos": 279, "end_pos": 320, "type": "TASK", "confidence": 0.7062980532646179}, {"text": "missing value reconstruction", "start_pos": 325, "end_pos": 353, "type": "TASK", "confidence": 0.6538472870985667}, {"text": "acrostic poetry generation", "start_pos": 398, "end_pos": 424, "type": "TASK", "confidence": 0.6242177486419678}, {"text": "text representation learning", "start_pos": 432, "end_pos": 460, "type": "TASK", "confidence": 0.7894983490308126}]}, {"text": "Text infilling is an under-explored challenging task in the field of text generation.", "labels": [], "entities": [{"text": "Text infilling", "start_pos": 0, "end_pos": 14, "type": "TASK", "confidence": 0.7332093417644501}, {"text": "text generation", "start_pos": 69, "end_pos": 84, "type": "TASK", "confidence": 0.743782639503479}]}, {"text": "Recently, sequence generative models like sequenceto-sequence (seq2seq) models (Sutskever et al., * Correspondence to Jiancheng Lv.", "labels": [], "entities": [{"text": "sequence generative", "start_pos": 10, "end_pos": 29, "type": "TASK", "confidence": 0.621379479765892}]}, {"text": "Our code and data are available at https://github.com/dayihengliu/ Text-Infilling-Gradient-Search", "labels": [], "entities": []}], "datasetContent": [{"text": "In the experiments, we evaluate the proposed method on three text infilling tasks with three widely used publicly available corpora.", "labels": [], "entities": []}, {"text": "The first task is conversation reply with a template (denoted as Dialog) which is conducted on the DailyDialog (  its single-turn data, which contains 82,792 conversation pairs.", "labels": [], "entities": [{"text": "DailyDialog", "start_pos": 99, "end_pos": 110, "type": "DATASET", "confidence": 0.9386173486709595}]}, {"text": "The query sentence is taken as encoder input x, and the reply sentence is taken as y.", "labels": [], "entities": []}, {"text": "The second task is Chinese acrostic poetry generation (denoted as Poetry).", "labels": [], "entities": [{"text": "Chinese acrostic poetry generation", "start_pos": 19, "end_pos": 53, "type": "TASK", "confidence": 0.6404897794127464}]}, {"text": "Here we use a publicly available Chinese poetry dataset 4 which contains 232,670 Chinese four-line poems.", "labels": [], "entities": [{"text": "Chinese poetry dataset 4", "start_pos": 33, "end_pos": 57, "type": "DATASET", "confidence": 0.7028670310974121}]}, {"text": "For each poem, the first two lines are used as encoder input x, and the last two lines are y.", "labels": [], "entities": []}, {"text": "The third task is infilling product reviews (denoted as APRC).", "labels": [], "entities": [{"text": "APRC)", "start_pos": 56, "end_pos": 61, "type": "TASK", "confidence": 0.564737543463707}]}, {"text": "The Amazon Product Reviews Corpus (APRC) (, which is built upon Amazon product data and contains 347,061 reviews, is used in this task.", "labels": [], "entities": [{"text": "Amazon Product Reviews Corpus (APRC)", "start_pos": 4, "end_pos": 40, "type": "DATASET", "confidence": 0.8980621695518494}, {"text": "Amazon product data", "start_pos": 64, "end_pos": 83, "type": "DATASET", "confidence": 0.7803007761637369}]}, {"text": "Unlike the first two tasks, this task is an unconditional text infilling task (without conditional input x).", "labels": [], "entities": []}, {"text": "We use each product review in as y.", "labels": [], "entities": []}, {"text": "For each task, we take 5,000 samples in the test set to construct the data with blanks (y B ) for testing, we create a variety of test samples by masking out text y with varying missing ratios and two mask strategies.", "labels": [], "entities": []}, {"text": "More specifically, the first mask strategy is called middle which is followed as the setting in, namely, removing r = 25%, 50%, or 75% of the words from the middle of y for each data.", "labels": [], "entities": [{"text": "middle", "start_pos": 53, "end_pos": 59, "type": "METRIC", "confidence": 0.9749888181686401}]}, {"text": "The second mask strategy is called random, namely, randomly removing r = 25%, 50%, or 75% of the words in y for each data.", "labels": [], "entities": []}, {"text": "To sum up, we have three test tasks, and each task has six types of test sets (two mask strategies and three mask ratios).", "labels": [], "entities": []}, {"text": "Each test set contains 5,000 test samples.", "labels": [], "entities": []}, {"text": "We show some data examples in.", "labels": [], "entities": []}, {"text": "We also conduct the human evaluation to further compare TIGS, BiRNN-BiBS, BiRNN-GSN, and Mask-Self-attn.", "labels": [], "entities": [{"text": "TIGS", "start_pos": 56, "end_pos": 60, "type": "METRIC", "confidence": 0.8719297051429749}, {"text": "BiRNN-BiBS", "start_pos": 62, "end_pos": 72, "type": "METRIC", "confidence": 0.8577650189399719}, {"text": "BiRNN-GSN", "start_pos": 74, "end_pos": 83, "type": "METRIC", "confidence": 0.8214598894119263}]}, {"text": "Following the setting in, we collect generations of each of the four methods on 50 randomly-selected test instances.", "labels": [], "entities": []}, {"text": "Then we launch a crowd-sourcing online study, asking 10 evaluators to rank the generations.", "labels": [], "entities": []}, {"text": "now i write <num> more words so i can submit . Mask-Seq2Seq so much better than the first one . loved it . and now i have <num> more words to submit this submit . Mask-Self-attn so much better than the first one . loved it . now now i need <num> more words to describe and submit . BiRNN-BiBS so much better than the first one . loved it . and now i have <num> more to read . i submit . BiRNN-GSN so much better than the first one . i cried . so now i have <num> more words to go to submit . TIGS so much better than the first one . highly recommend . but now i need <num> more words to go to submit .", "labels": [], "entities": [{"text": "TIGS", "start_pos": 492, "end_pos": 496, "type": "METRIC", "confidence": 0.9914449453353882}]}], "tableCaptions": [{"text": " Table 1: BLEU and NLL results.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9933164119720459}, {"text": "NLL", "start_pos": 19, "end_pos": 22, "type": "DATASET", "confidence": 0.6779151558876038}]}, {"text": " Table 2: Human evaluation resutls", "labels": [], "entities": []}]}