{"title": [{"text": "Controllable Text Simplification with Lexical Constraint Loss", "labels": [], "entities": [{"text": "Text Simplification", "start_pos": 13, "end_pos": 32, "type": "TASK", "confidence": 0.5200490057468414}]}], "abstractContent": [{"text": "We propose a method to control the level of a sentence in a text simplification task.", "labels": [], "entities": [{"text": "text simplification task", "start_pos": 60, "end_pos": 84, "type": "TASK", "confidence": 0.7727552056312561}]}, {"text": "Text simplification is a monolingual translation task translating a complex sentence into a simpler and easier to understand the alternative.", "labels": [], "entities": [{"text": "Text simplification", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.785569578409195}]}, {"text": "In this study, we use the grade level of the US education system as the level of the sentence.", "labels": [], "entities": []}, {"text": "Our text simplification method succeeds in translating an input into a specific grade level by considering levels of both sentences and words.", "labels": [], "entities": []}, {"text": "Sentence level is considered by adding the target grade level as input.", "labels": [], "entities": [{"text": "Sentence", "start_pos": 0, "end_pos": 8, "type": "TASK", "confidence": 0.8994180560112}]}, {"text": "By contrast, the word level is considered by adding weights to the training loss based on words that frequently appear in sentences of the desired grade level.", "labels": [], "entities": []}, {"text": "Although existing models that consider only the sentence level may control the syntactic complexity , they tend to generate words beyond the target level.", "labels": [], "entities": []}, {"text": "Our approach can control both the lexical and syntactic complexity and achieve an aggressive rewriting.", "labels": [], "entities": []}, {"text": "Experiment results indicate that the proposed method improves the metrics of both BLEU and SARI.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 82, "end_pos": 86, "type": "METRIC", "confidence": 0.99413001537323}, {"text": "SARI", "start_pos": 91, "end_pos": 95, "type": "METRIC", "confidence": 0.6255106925964355}]}], "introductionContent": [{"text": "Text simplification) is the task of rewriting a complex text into a simpler form while preserving its meaning.", "labels": [], "entities": [{"text": "Text simplification)", "start_pos": 0, "end_pos": 20, "type": "TASK", "confidence": 0.8326894044876099}]}, {"text": "Its applications include reading comprehension assistance and language education support.", "labels": [], "entities": []}, {"text": "Because each target user has different reading abilities and/or knowledge, we need a text simplification system that translates an input sentence into a sentence of an appropriate difficulty level for each user.", "labels": [], "entities": []}, {"text": "According to the input hypothesis, educational materials slightly beyond the learner's level effectively improve their reading abilities.", "labels": [], "entities": []}, {"text": "On the contrary, materials that are too difficult for learners deteriorate their learning motivation.", "labels": [], "entities": []}, {"text": "In the context of language education, teachers manually simplify", "labels": [], "entities": []}], "datasetContent": [{"text": "We evaluated whether our method can control the grade levels in a text simplification using the Newsela corpus.", "labels": [], "entities": [{"text": "Newsela corpus", "start_pos": 96, "end_pos": 110, "type": "DATASET", "confidence": 0.9875069260597229}]}, {"text": "The Newsela corpus provides Here, D = 11 because we use grade levels 2 to 12.", "labels": [], "entities": [{"text": "Newsela corpus", "start_pos": 4, "end_pos": 18, "type": "DATASET", "confidence": 0.9754900336265564}, {"text": "D", "start_pos": 34, "end_pos": 35, "type": "METRIC", "confidence": 0.9827471971511841}]}, {"text": "news articles of different levels, which have been manually rewritten by human experts.", "labels": [], "entities": []}, {"text": "It conforms to the grade levels in the US education system, where the levels range from 2 to 12.", "labels": [], "entities": []}, {"text": "We use the publicly available version of the Newsela corpus 3 that has been sentence-aligned by and divided into 94k, 1k, and 1k sentences for the training, development, and test, respectively, by.", "labels": [], "entities": [{"text": "Newsela corpus 3", "start_pos": 45, "end_pos": 61, "type": "DATASET", "confidence": 0.9674804210662842}]}, {"text": "As in previous studies, we regard each sentence in an article as sharing the same level as the entire article.", "labels": [], "entities": []}, {"text": "first divided the set of articles and then extracted sentence pairs to avoid the same sentences appearing in both the training and test sets.", "labels": [], "entities": []}, {"text": "Note that the Newsela corpus used in) is different from the present corpus, and is preprocessed differently.", "labels": [], "entities": [{"text": "Newsela corpus", "start_pos": 14, "end_pos": 28, "type": "DATASET", "confidence": 0.9707375466823578}]}, {"text": "Due to these differences, the training, development, and test sets used in (Scarton and Specia, 2018) are unreproducible.", "labels": [], "entities": []}, {"text": "Therefore, we reimplemented () and compared it to our method using our public corpus.", "labels": [], "entities": []}, {"text": "shows statistics for the Newsela corpus, which clearly present the tendency that lower grade sentences are significantly shorter than those of higher grades.", "labels": [], "entities": [{"text": "Newsela corpus", "start_pos": 25, "end_pos": 39, "type": "DATASET", "confidence": 0.96953484416008}]}, {"text": "This indicates that aggressive omission of phrases is required to simplify sentences of grade 8 to 12 into those of grade 2 to 7.", "labels": [], "entities": []}, {"text": "Following previous studies on text simplification, e.g.,, BLEU 6 () and SARI 7 ( were used to evaluate the overall performance.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 58, "end_pos": 62, "type": "METRIC", "confidence": 0.997901201248169}, {"text": "SARI 7", "start_pos": 72, "end_pos": 78, "type": "METRIC", "confidence": 0.9366733431816101}]}, {"text": "In addition, we investigate the scores of BLEU ST , mean absolute error (MAE) of sentence length (MAE LEN ), and mean PMI (MPMI) fora detailed analysis.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 42, "end_pos": 46, "type": "METRIC", "confidence": 0.9994322657585144}, {"text": "ST", "start_pos": 47, "end_pos": 49, "type": "METRIC", "confidence": 0.7843174338340759}, {"text": "mean absolute error (MAE) of sentence length (MAE LEN )", "start_pos": 52, "end_pos": 107, "type": "METRIC", "confidence": 0.9124291309943566}, {"text": "mean PMI (MPMI)", "start_pos": 113, "end_pos": 128, "type": "METRIC", "confidence": 0.9076619744300842}]}, {"text": "BLEU ST computes a BLEU score by taking the source and output sentences as input, which allows evaluating the degree of rewrites made by a model.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 0, "end_pos": 4, "type": "METRIC", "confidence": 0.9551287293434143}, {"text": "BLEU score", "start_pos": 19, "end_pos": 29, "type": "METRIC", "confidence": 0.9787009656429291}]}, {"text": "The lower BLEU ST is, the more actively the model rewrites the source sentence.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9990311861038208}, {"text": "ST", "start_pos": 15, "end_pos": 17, "type": "METRIC", "confidence": 0.730654239654541}]}, {"text": "In addition, MAE LEN approximately evaluates the syntactic complexity of the output based on its length: where N is the number of sentences in the test set, and Len(\u00b7) provides the number of words in a sentence.", "labels": [], "entities": [{"text": "MAE LEN", "start_pos": 13, "end_pos": 20, "type": "METRIC", "confidence": 0.7488705217838287}]}, {"text": "The lower the MAE LEN is, the more appropriate the length of the output.", "labels": [], "entities": [{"text": "MAE LEN", "start_pos": 14, "end_pos": 21, "type": "METRIC", "confidence": 0.7736591994762421}]}, {"text": "MPMI evaluates to what extent the levels of the output words match with the target level: where Wis the number of words appearing in the output and l sis the grade level of sentence s.", "labels": [], "entities": []}, {"text": "PMI scores were pre-computed using the training data.", "labels": [], "entities": [{"text": "PMI", "start_pos": 0, "end_pos": 3, "type": "TASK", "confidence": 0.7444295883178711}]}, {"text": "The higher the MPMI is, the more words of the target level are generated by the model.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Statistics for the Newsela corpus, where S- length shows the average number of words in a sen- tence.", "labels": [], "entities": [{"text": "Newsela corpus", "start_pos": 29, "end_pos": 43, "type": "DATASET", "confidence": 0.9449380934238434}, {"text": "S- length", "start_pos": 51, "end_pos": 60, "type": "METRIC", "confidence": 0.8575475215911865}]}, {"text": " Table 3: Results on the Newsela test set.", "labels": [], "entities": [{"text": "Newsela test set", "start_pos": 25, "end_pos": 41, "type": "DATASET", "confidence": 0.9889922539393107}]}, {"text": " Table 4: Example of model outputs. Here, s2s+grade+PPMI successfully simplified some complex words (high- lighted in bold) and deleted the underlined phrases.", "labels": [], "entities": []}, {"text": " Table 5: FKGL and MPMI of s2s+grade (prev.) and  s2s+grade+PPMI (prop.) for each grade level. Models  suitable for the target level are highlighted in bold.", "labels": [], "entities": [{"text": "FKGL", "start_pos": 10, "end_pos": 14, "type": "DATASET", "confidence": 0.6006686687469482}]}]}