{"title": [], "abstractContent": [{"text": "In this work we approach the task of learning multilingual word representations in an of-fline manner by fitting a generative latent variable model to a multilingual dictionary.", "labels": [], "entities": []}, {"text": "We model equivalent words in different languages as different views of the same word generated by a common latent variable representing their latent lexical meaning.", "labels": [], "entities": []}, {"text": "We explore the task of alignment by querying the fitted model for multilingual embeddings achieving competitive results across a variety of tasks.", "labels": [], "entities": [{"text": "alignment", "start_pos": 23, "end_pos": 32, "type": "TASK", "confidence": 0.906565248966217}]}, {"text": "The proposed model is robust to noise in the embedding space making it a suitable method for distributed representations learned from noisy corpora.", "labels": [], "entities": []}], "introductionContent": [{"text": "Popular approaches for multilingual alignment of word embeddings base themselves on the observation in, which noticed that continuous word embedding spaces () exhibit similar structures across languages.", "labels": [], "entities": [{"text": "multilingual alignment of word embeddings", "start_pos": 23, "end_pos": 64, "type": "TASK", "confidence": 0.7737197518348694}]}, {"text": "This observation has led to multiple successful methods in which a direct linear mapping between the two spaces is learned through a least squares based objective () using a paired bilingual dictionary.", "labels": [], "entities": []}, {"text": "An alternate set of approaches based on Canonical Correlation Analysis (CCA) seek to project monolingual embeddings into a shared multilingual space.", "labels": [], "entities": [{"text": "Canonical Correlation Analysis (CCA)", "start_pos": 40, "end_pos": 76, "type": "TASK", "confidence": 0.7619497080643972}]}, {"text": "Both these methods aim to exploit the correlations between the monolingual vector spaces when projecting into the aligned multilingual space.", "labels": [], "entities": []}, {"text": "The multilingual embeddings from are shown to improve on word level semantic tasks, which sustains the authors' claim that multilingual information enhances semantic spaces.", "labels": [], "entities": []}, {"text": "In this paper we present anew non-iterative method based on variants of factor analysis for aligning monolingual representations into a multilingual space.", "labels": [], "entities": []}, {"text": "Our generative modelling assumes that a single word translation pair is generated by an embedding representing the lexical meaning of the underlying concept.", "labels": [], "entities": []}, {"text": "We achieve competitive results across a wide range of tasks compared to state-of-the-art methods, and we conjecture that our multilingual latent variable model has sound generative properties that match those of psycholinguistic theories of the bilingual mind.", "labels": [], "entities": []}, {"text": "Furthermore, we show how our model extends to more than two languages within the generative framework which is something that previous alignment models are not naturally suited to, instead resorting to combining bilingual models with a pivot as in (.", "labels": [], "entities": []}, {"text": "Additionally the general benefit of the probabilistic setup as discussed in) is that it offers the potential to extend the scope of conventional alignment methods to model and exploit linguistic structure more accurately.", "labels": [], "entities": []}, {"text": "An example of such a benefit could be modelling how corresponding word translations can be generated by more than just a single latent concept.", "labels": [], "entities": []}, {"text": "This assumption can be encoded by a mixture of Factor Analysers ( to model word polysemy in a similar fashion to, where mixtures of Gaussians are used to reflect the different meanings of a word.", "labels": [], "entities": []}, {"text": "The main contribution of this work is the application of a well-studied graphical model to a novel domain, outperforming previous approaches on word and sentence-level translation retrieval tasks.", "labels": [], "entities": [{"text": "word and sentence-level translation retrieval tasks", "start_pos": 144, "end_pos": 195, "type": "TASK", "confidence": 0.6928070982297262}]}, {"text": "We put the model through a battery of tests, showing it aligns embeddings across languages well, while retaining performance on monolingual word-level and sentence-level tasks.", "labels": [], "entities": []}, {"text": "Finally, we apply a natural extension of this model to more languages in order to align three languages into a single common space.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section, we empirically demonstrate the effectiveness of our generative approach on several benchmarks, and compare it with state-of-the-art methods.", "labels": [], "entities": [{"text": "generative", "start_pos": 69, "end_pos": 79, "type": "TASK", "confidence": 0.967438280582428}]}, {"text": "We first present cross-lingual (wordtranslation) evaluation tasks to evaluate the quality of our multi-lingual word embeddings.", "labels": [], "entities": []}, {"text": "As a follow-up to the word retrieval task we also run experiments on cross-lingual sentence retrieval tasks.", "labels": [], "entities": [{"text": "word retrieval", "start_pos": 22, "end_pos": 36, "type": "TASK", "confidence": 0.7775005400180817}, {"text": "cross-lingual sentence retrieval tasks", "start_pos": 69, "end_pos": 107, "type": "TASK", "confidence": 0.738963894546032}]}, {"text": "We further demonstrate the quality of our multi-lingual word embeddings on monolingual word-and sentence-level similarity tasks from), which we believe provides empirical evidence that the aligned embeddings preserve and even potentially enhance their monolingual quality.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Precision @1 for cross-lingual word similarity tasks. Rows labelled AdvR are copies of Adversarial - Refine rows in (Lample et al., 2018). Results marked with a * differ from the ones shown in (Lample et al., 2018)  due to pre-processing done on their part. SVD and IBFA in the semi-supervised setting use the pseudo-dictionary,  while AdvR uses frequency information. CSLS is the post-processing technique proposed in (Lample et al., 2018).", "labels": [], "entities": [{"text": "cross-lingual word similarity tasks", "start_pos": 27, "end_pos": 62, "type": "TASK", "confidence": 0.7176562398672104}]}, {"text": " Table 2: Comparisons without post-processing of methods. Results reproduced from (Smith et al., 2017) for fair  comparison. Left: Comparisons using the same expert dictionary as (Smith et al., 2017). Right: Comparisons  using the pseudo-dictionary from (Smith et al., 2017).", "labels": [], "entities": []}, {"text": " Table 3: Spearman correlation for English word similarity tasks. First row represents monolingual fasttext vectors  (Joulin et al., 2017) in English, the rest are bilingual embeddings.", "labels": [], "entities": [{"text": "English word similarity tasks", "start_pos": 35, "end_pos": 64, "type": "TASK", "confidence": 0.6615731492638588}]}, {"text": " Table 4: Spearman correlation for Semantic Textual Similarity (STS) tasks in English. All results use the sentence  embeddings described in (Arora et al., 2016). First row represents monolingual FastText vectors (Joulin et al.,  2017) in English, the rest are bilingual embeddings. *STS13 excludes the proprietary SMT dataset.", "labels": [], "entities": [{"text": "Semantic Textual Similarity (STS) tasks", "start_pos": 35, "end_pos": 74, "type": "TASK", "confidence": 0.792586203132357}, {"text": "SMT dataset", "start_pos": 315, "end_pos": 326, "type": "DATASET", "confidence": 0.9081205129623413}]}, {"text": " Table 5: Sentence translation precisions @1, @5, @10 on 2,000 English-Italian pairs samples from a set of 200k  sentences from Europarl (Koehn, 2005) on Dinu embeddings. AdvR is copied from Adversarial -Refined in  (Lample et al., 2018). Rows with copied from (Smith et al., 2017).", "labels": [], "entities": [{"text": "Sentence translation", "start_pos": 10, "end_pos": 30, "type": "TASK", "confidence": 0.7593532502651215}, {"text": "precisions", "start_pos": 31, "end_pos": 41, "type": "METRIC", "confidence": 0.5714704394340515}, {"text": "Europarl (Koehn, 2005)", "start_pos": 128, "end_pos": 150, "type": "DATASET", "confidence": 0.8985255757967631}]}, {"text": " Table 6: Precision @1 when aligning English, French and Italian embeddings to a common space. For SVD, this  common space is English, while for MBFA it is the latent space.", "labels": [], "entities": [{"text": "Precision", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9904665350914001}]}, {"text": " Table 8: Precision @1 between MBFA fitted for 1K iterations and MBFA fitted for 20K iterations.", "labels": [], "entities": [{"text": "Precision", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9973586201667786}, {"text": "MBFA", "start_pos": 31, "end_pos": 35, "type": "METRIC", "confidence": 0.6722265481948853}]}]}