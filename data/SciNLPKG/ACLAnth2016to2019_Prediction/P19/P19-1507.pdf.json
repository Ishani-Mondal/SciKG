{"title": [{"text": "Relating Simple Sentence Representations in Deep Neural Networks and the Brain", "labels": [], "entities": [{"text": "Relating Simple Sentence Representations", "start_pos": 0, "end_pos": 40, "type": "TASK", "confidence": 0.8956830650568008}]}], "abstractContent": [{"text": "What is the relationship between sentence representations learned by deep recurrent models against those encoded by the brain?", "labels": [], "entities": []}, {"text": "Is there any correspondence between hidden layers of these recurrent models and brain regions when processing sentences?", "labels": [], "entities": []}, {"text": "Can these deep models be used to synthesize brain data which can then be utilized in other extrin-sic tasks?", "labels": [], "entities": []}, {"text": "We investigate these questions using sentences with simple syntax and semantics (e.g., The bone was eaten by the dog.).", "labels": [], "entities": []}, {"text": "We consider multiple neural network archi-tectures, including recently proposed ELMo and BERT.", "labels": [], "entities": [{"text": "BERT", "start_pos": 89, "end_pos": 93, "type": "METRIC", "confidence": 0.9890404343605042}]}, {"text": "We use magnetoencephalography (MEG) brain recording data collected from human subjects when they were reading these simple sentences.", "labels": [], "entities": []}, {"text": "Overall, we find that BERT's activations correlate the best with MEG brain data.", "labels": [], "entities": [{"text": "BERT", "start_pos": 22, "end_pos": 26, "type": "METRIC", "confidence": 0.9939093589782715}, {"text": "MEG brain data", "start_pos": 65, "end_pos": 79, "type": "DATASET", "confidence": 0.6886982520421346}]}, {"text": "We also find that the deep network representation can be used to generate brain data from new sentences to augment existing brain data.", "labels": [], "entities": []}, {"text": "To the best of our knowledge, this is the first work showing that the MEG brain recording when reading a word in a sentence can be used to distinguish earlier words in the sentence.", "labels": [], "entities": []}, {"text": "Our exploration is also the first to use deep neural network representations to generate synthetic brain data and to show that it helps in improving subsequent stimuli decoding task accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 182, "end_pos": 190, "type": "METRIC", "confidence": 0.9477118849754333}]}], "introductionContent": [{"text": "Deep learning methods for natural language processing have been very successful in a variety of Natural Language Processing (NLP) tasks.", "labels": [], "entities": [{"text": "natural language processing", "start_pos": 26, "end_pos": 53, "type": "TASK", "confidence": 0.6535737911860148}]}, {"text": "However, the representation of language learned by such methods is still opaque.", "labels": [], "entities": []}, {"text": "The human brain is an excellent language processing engine, and the brain representation of language is of course very effective.", "labels": [], "entities": []}, {"text": "Even though both brain and deep learning methods are representing language, the relationships among these representations are not thoroughly studied. and studied this question in some limited capacity.) studied the processing of a story context at a word level during language model computation.", "labels": [], "entities": []}, {"text": "studied the syntactic composition in RNNG model () with human encephalography (EEG) data.", "labels": [], "entities": []}, {"text": "We extend this line of research by investigating the following three questions: what is the relationship between sentence representations learned by deep learning networks and those encoded by the brain; (2) is there any correspondence between hidden layer activations in these deep models and brain regions; and (3) is it possible for deep recurrent models to synthesize brain data so that they can effectively be used for brain data augmentation.", "labels": [], "entities": [{"text": "brain data augmentation", "start_pos": 424, "end_pos": 447, "type": "TASK", "confidence": 0.6571227510770162}]}, {"text": "In order to evaluate these questions, we focus on representations of simple sentences.", "labels": [], "entities": []}, {"text": "We employ various deep network architectures, including recently proposed ELMo () and BERT) networks.", "labels": [], "entities": [{"text": "BERT", "start_pos": 86, "end_pos": 90, "type": "METRIC", "confidence": 0.991174042224884}]}, {"text": "We use MagnetoEncephaloGraphy (MEG) brain recording data of simple sentences as the target reference.", "labels": [], "entities": []}, {"text": "We then correlate the representations learned by these various networks with the MEG recordings.", "labels": [], "entities": []}, {"text": "Overall, we observe that BERT representations are the most predictive of MEG data.", "labels": [], "entities": [{"text": "BERT", "start_pos": 25, "end_pos": 29, "type": "METRIC", "confidence": 0.9913057684898376}, {"text": "MEG data", "start_pos": 73, "end_pos": 81, "type": "DATASET", "confidence": 0.7576932311058044}]}, {"text": "We also observe that the deep network models are effective at synthesizing brain data which are useful in overcoming data sparsity in stimuli decoding tasks involving brain data.", "labels": [], "entities": []}, {"text": "In summary, in this paper we make the following contributions.", "labels": [], "entities": []}, {"text": "\u2022 We initiate a study to relate representations of simple sentences learned by various deep networks with those encoded in the brain.", "labels": [], "entities": []}, {"text": "We establish correspondences between activations in deep network layers with brain ar-eas.", "labels": [], "entities": []}, {"text": "\u2022 We demonstrate that deep networks are capable of predicting change in brain activity due to differences in previously processed words in the sentence.", "labels": [], "entities": []}, {"text": "\u2022 We demonstrate effectiveness of using deep networks to synthesize brain data for downstream data augmentation.", "labels": [], "entities": []}, {"text": "We have made our code and data 1 publicly available to support further research in this area.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section, we describe the MEG dataset and Simple Sentence Corpus used in the paper.", "labels": [], "entities": [{"text": "MEG dataset", "start_pos": 33, "end_pos": 44, "type": "DATASET", "confidence": 0.8882442116737366}]}, {"text": "Magnetoencephalography (MEG) is a noninvasive functional brain imaging technique which records magnetic fields produced by electrical currents in the brain.", "labels": [], "entities": [{"text": "Magnetoencephalography (MEG)", "start_pos": 0, "end_pos": 28, "type": "TASK", "confidence": 0.5750440806150436}]}, {"text": "Sensors in the MEG helmet allow for recording of magnetic fluctuations caused by changes in neural activity of the brain.", "labels": [], "entities": [{"text": "MEG helmet", "start_pos": 15, "end_pos": 25, "type": "DATASET", "confidence": 0.810440719127655}]}, {"text": "For the experiments in this paper, we used three different MEG datasets collected when subjects were shown simple sentences as stimulus.", "labels": [], "entities": [{"text": "MEG datasets collected", "start_pos": 59, "end_pos": 81, "type": "DATASET", "confidence": 0.7638227244218191}]}, {"text": "These datasets are summarized in, please see) for more details.", "labels": [], "entities": []}, {"text": "Additional dataset details are mentioned in appendix section A.1.", "labels": [], "entities": []}, {"text": "In the MEG helmet, 306 sensors were distributed over 102 locations and sampled at 1kHz.", "labels": [], "entities": [{"text": "MEG helmet", "start_pos": 7, "end_pos": 17, "type": "DATASET", "confidence": 0.7746761739253998}]}, {"text": "Native English speaking subjects were asked to read simple sentences.", "labels": [], "entities": []}, {"text": "Each word within a sentence was presented for 300ms with 200ms subsequent rest.", "labels": [], "entities": []}, {"text": "To reduce noise in the brain recordings, we represent a word's brain activity by averaging 10 sentence repetitions (Sudre et al., 2012).", "labels": [], "entities": []}, {"text": "Comprehension questions followed 10% of sentences, to ensure semantic engagement.", "labels": [], "entities": []}, {"text": "MEG data was acquired using a 306 channel Elekta Neuromag device.", "labels": [], "entities": [{"text": "MEG data", "start_pos": 0, "end_pos": 8, "type": "DATASET", "confidence": 0.8960733115673065}]}, {"text": "Preprocessing included spatial filtering using temporal signal space separation (tSSS), low-pass filtering 150Hz with notch filters at 60 and 120Hz, and downsampling to 500Hz).", "labels": [], "entities": [{"text": "spatial filtering", "start_pos": 23, "end_pos": 40, "type": "TASK", "confidence": 0.7060632556676865}]}, {"text": "Artifacts from tSSS-filtered same-day empty room measurements, ocular and cardiac artifacts were removed via Signal Space Projection (SSP).: MEG datasets used in this paper.", "labels": [], "entities": [{"text": "Signal Space Projection (SSP).", "start_pos": 109, "end_pos": 139, "type": "TASK", "confidence": 0.5870576749245325}, {"text": "MEG datasets", "start_pos": 141, "end_pos": 153, "type": "DATASET", "confidence": 0.8162566721439362}]}, {"text": "Column 'Voice' refers to the sentence voice, 'P' is for passive sentences and 'A' is for active.", "labels": [], "entities": []}, {"text": "Repetition is the number of times the human subject saw a sentence.", "labels": [], "entities": [{"text": "Repetition", "start_pos": 0, "end_pos": 10, "type": "METRIC", "confidence": 0.9223858118057251}]}, {"text": "For our experiments, we average MEG data corresponding to multiple repetitions of a single sentence.", "labels": [], "entities": [{"text": "MEG", "start_pos": 32, "end_pos": 35, "type": "METRIC", "confidence": 0.9774107336997986}]}, {"text": "With human brain as the reference language processing engine, we investigate the relationship between deep neural network representation and brain activity recorded while processing the same sentence.", "labels": [], "entities": []}, {"text": "For this task, we perform experiments at both the macro and micro sentence context level.", "labels": [], "entities": []}, {"text": "The macro-context experiments evaluate the overall performance of deep neural networks in predicting brain data for input words (all words, nouns, verbs etc.).", "labels": [], "entities": []}, {"text": "The micro-context experiments, by contrast, focus on evaluating the performance of deep neural network representations in detecting minor changes in sentence context prior to the token being processed.", "labels": [], "entities": []}, {"text": "Regression task: Similar to previous research (), we use a classification task to align model representations with brain data.", "labels": [], "entities": [{"text": "Regression", "start_pos": 0, "end_pos": 10, "type": "METRIC", "confidence": 0.9595391750335693}]}, {"text": "MEG data (Section 2.1) is used for these experiments.", "labels": [], "entities": [{"text": "MEG data", "start_pos": 0, "end_pos": 8, "type": "DATASET", "confidence": 0.8344806134700775}]}, {"text": "The task classifies between a candidate word and the true word a subject is reading at the time of brain activity recording.", "labels": [], "entities": []}, {"text": "The classifier uses an intermediate regression step to predict the MEG activity from deep neural network representation for the true and the candidate word.", "labels": [], "entities": []}, {"text": "The classifier then chooses the word with least Euclidean distance between the predicted and the true brain activity.", "labels": [], "entities": [{"text": "Euclidean distance", "start_pos": 48, "end_pos": 66, "type": "METRIC", "confidence": 0.8939592242240906}]}, {"text": "A correct classification suggests that the deep neural network representation captures important information to differentiate between brain activity at words in different contexts.", "labels": [], "entities": []}, {"text": "Detailed steps of this process are described as follows.", "labels": [], "entities": []}, {"text": "Regression training: We perform regression from the neural-network representation (for each layer) to the brain activity for the same input words in context.", "labels": [], "entities": []}, {"text": "We normalized, preprocessed and trained on the MEG data as described by) (Section 2.3.2).", "labels": [], "entities": [{"text": "MEG data", "start_pos": 47, "end_pos": 55, "type": "DATASET", "confidence": 0.9144613444805145}]}, {"text": "We average the signal from every sensor (total 306) over 100ms non-overlapping windows, yielding a 306\u00d75 sized MEG data for each word.", "labels": [], "entities": []}, {"text": "To train the regression model, we take the training portion of the data in each fold, (X, Y ), in the tuple (x i , y i ), xi is the layer representation for an input word i in a neural network model, and y i is the corresponding MEG recording of size 1530 (flattened 306*5).", "labels": [], "entities": []}, {"text": "The Ridge regression model (f)) is learned with generalized cross-validation to select \u03bb parameter ().", "labels": [], "entities": []}, {"text": "Ridge regression model's \u03b1 parameter is selected from range [0.1, . .", "labels": [], "entities": [{"text": "Ridge regression", "start_pos": 0, "end_pos": 16, "type": "TASK", "confidence": 0.6839320659637451}]}, {"text": ",. The trained regression model is used to estimate MEG activity from the stimulus features, i.e., \u02c6 y i = f (x i ).", "labels": [], "entities": []}, {"text": "Regression testing: The trained regression model is used to predict\u02c6ypredict\u02c6 predict\u02c6y i for each word stimulus (x i ) in the test fold during cross-validation.", "labels": [], "entities": []}, {"text": "We perform a pair-wise test for the classification accuracy (Acc) ().", "labels": [], "entities": [{"text": "classification", "start_pos": 36, "end_pos": 50, "type": "TASK", "confidence": 0.864682137966156}, {"text": "accuracy", "start_pos": 51, "end_pos": 59, "type": "METRIC", "confidence": 0.9151638746261597}, {"text": "Acc)", "start_pos": 61, "end_pos": 65, "type": "METRIC", "confidence": 0.976195216178894}]}, {"text": "The chance accuracy of this measure is 0.5.", "labels": [], "entities": [{"text": "chance", "start_pos": 4, "end_pos": 10, "type": "METRIC", "confidence": 0.9844453930854797}, {"text": "accuracy", "start_pos": 11, "end_pos": 19, "type": "METRIC", "confidence": 0.8668281435966492}]}, {"text": "We use Euclidean distance (E dist ) as given in for the measure.", "labels": [], "entities": [{"text": "Euclidean distance (E dist )", "start_pos": 7, "end_pos": 35, "type": "METRIC", "confidence": 0.8211811780929565}]}, {"text": "The macro-context experiments aggregate classification performance of each model's layer on the entire stimuli set.", "labels": [], "entities": []}, {"text": "We also evaluate on smaller sets such as only the nouns, verbs, passive sentence words, active sentence words, etc.", "labels": [], "entities": []}, {"text": "The macro experiments help us to compare all the models on a large stimuli set.", "labels": [], "entities": []}, {"text": "In summary, we observe the following:  we observe that BERT and ELMo outperform the simple models in predicting brain activity data.", "labels": [], "entities": [{"text": "BERT", "start_pos": 55, "end_pos": 59, "type": "METRIC", "confidence": 0.9978146553039551}, {"text": "ELMo", "start_pos": 64, "end_pos": 68, "type": "METRIC", "confidence": 0.9377548098564148}]}, {"text": "In the neural network language models, the middle layers perform better at predicting brain activity than the shallower or deeper layers.", "labels": [], "entities": [{"text": "predicting brain activity", "start_pos": 75, "end_pos": 100, "type": "TASK", "confidence": 0.8559132615725199}]}, {"text": "This could be due to the fact that the shallower layers represent low-level features and the deeper layers represent more task-oriented features.", "labels": [], "entities": []}, {"text": "We tested this hypothesis by examining the performance scores at each lobe of the brain.", "labels": [], "entities": []}, {"text": "For each area, we tested the left and right hemispheres independently and compared these performances with the bilateral frontal lobe as well as the activity across all regions.", "labels": [], "entities": []}, {"text": "In particular, we examined the primary visual areas (left and right occipital lobe), speech and language processing areas (left temporal) and verbal memory (right temporal), sensory perception (left parietal) and integration (right parietal), language related movements (left frontal) and nonverbal functioning (right frontal).", "labels": [], "entities": []}, {"text": "The frontal lobe was tested bilaterally as it is associated with higher level processing such as problem solving, language processing, memory, judgement, and social behavior.", "labels": [], "entities": [{"text": "problem solving", "start_pos": 97, "end_pos": 112, "type": "TASK", "confidence": 0.72678641974926}]}, {"text": "From our results, we observe that lower layers such as BERT layer 5 have very high accuracy for right occipital and left occipital lobe associated with low-level visual processing task.", "labels": [], "entities": [{"text": "BERT", "start_pos": 55, "end_pos": 59, "type": "METRIC", "confidence": 0.991952121257782}, {"text": "accuracy", "start_pos": 83, "end_pos": 91, "type": "METRIC", "confidence": 0.9989778995513916}]}, {"text": "In contrast, higher layers such as linear layers in the Multitask Model and in Language Model have the highest accuracy in the left temporal region of the brain.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 111, "end_pos": 119, "type": "METRIC", "confidence": 0.998542308807373}]}, {"text": "shows the pairwise classification accuracy fora given brain region for best layers from each model.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 34, "end_pos": 42, "type": "METRIC", "confidence": 0.9327734708786011}]}, {"text": "The accuracy is highest in left temporal region, responsible for syntactic and semantic processing of language.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 4, "end_pos": 12, "type": "METRIC", "confidence": 0.9996819496154785}]}, {"text": "These results establish correspondences between representations learned by deep neural methods and those in the brain.", "labels": [], "entities": []}, {"text": "Further experiments are needed to improve our understanding of this relationship.", "labels": [], "entities": []}, {"text": "We performed additional experiments to predict on a restricted stimuli set.", "labels": [], "entities": []}, {"text": "In each of these experiments, a subset of stimuli, for example active sentences, passive sentences, noun, and verb stimuli were used in classification training and testing.", "labels": [], "entities": [{"text": "classification training", "start_pos": 136, "end_pos": 159, "type": "TASK", "confidence": 0.931731790304184}]}, {"text": "Detailed results for this experiment are documented in the appendix section.", "labels": [], "entities": []}, {"text": "From the results, we observe that active sentences are predicted better (best accuracy = 0.93) than passive sentences (best accuracy = 0.87).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 78, "end_pos": 86, "type": "METRIC", "confidence": 0.9772883057594299}, {"text": "accuracy", "start_pos": 124, "end_pos": 132, "type": "METRIC", "confidence": 0.9616175293922424}]}, {"text": "This might be attributed to the nature of training datasets for  deep neural networks, as active sentences are dominant in the training data of most of the pre-trained models.", "labels": [], "entities": []}, {"text": "We also observe that for passive sentences, our simple multitask model (trained using about 250K active and passive sentences) has a lower performance gap between active and passive sentence as compared to ELMO and BERT models.", "labels": [], "entities": [{"text": "BERT", "start_pos": 215, "end_pos": 219, "type": "METRIC", "confidence": 0.9591198563575745}]}, {"text": "This maybe due to a more balanced active and passive sentence used to train the multitask model.", "labels": [], "entities": []}, {"text": "Noun stimuli are predicted with the highest accuracy of 0.81, while the accuracy for verbs is 0.65.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 44, "end_pos": 52, "type": "METRIC", "confidence": 0.9992477893829346}, {"text": "accuracy", "start_pos": 72, "end_pos": 80, "type": "METRIC", "confidence": 0.9993215799331665}]}, {"text": "Both Multitask and ELMo models dominate verb prediction results, while BERT lags in this category.", "labels": [], "entities": [{"text": "verb prediction", "start_pos": 40, "end_pos": 55, "type": "TASK", "confidence": 0.8097114861011505}, {"text": "BERT", "start_pos": 71, "end_pos": 75, "type": "METRIC", "confidence": 0.9954937696456909}]}, {"text": "Further experiments should be done to compare the ability of Transformer () versus Recurrent Neural Network based models to represent verbs.", "labels": [], "entities": []}, {"text": "In these micro-context experiments, we evaluate if our models are able to retain information from words in the sentence prior to the word being processed.", "labels": [], "entities": []}, {"text": "For such context sensitivity tests, we only use the first repetition of the sentence shown to human subjects.", "labels": [], "entities": []}, {"text": "This helps to ensure that the sentence has not been memorized by the subjects, which might affect the context sensitivity tests.", "labels": [], "entities": []}, {"text": "Training: The micro-context experiment setup is illustrated in.", "labels": [], "entities": []}, {"text": "To train the regression model, each training instance corresponding to a word has the form (x i , y i ), where xi is the layer representation for an input word i in a neural network model, and y i is the corresponding MEG brain recording data of size 1530 (flattened 306 \u00d7 5).", "labels": [], "entities": []}, {"text": "During testing, we restrict the pairwise tests to word pairs (x i , x j ) which satisfy some conditions.", "labels": [], "entities": []}, {"text": "For example in noun context sensitivity test, the pair of words should be such that, they appear in a sentence with the same words except the noun.", "labels": [], "entities": [{"text": "noun context sensitivity", "start_pos": 15, "end_pos": 39, "type": "TASK", "confidence": 0.7908737659454346}]}, {"text": "We describe these candidate word test pairs, in detail, in the following sections.", "labels": [], "entities": []}, {"text": "In each of the following sensitivity tests, we perform a pair-wise accuracy test among the same candidate word (bold items) from sentences which are identical except for one word (underlined items).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 67, "end_pos": 75, "type": "METRIC", "confidence": 0.9409965872764587}]}, {"text": "We vary the non-identical word type (noun, verb, adjective, determiner) among the two sentences to test the contribution of each of these word types to the context representation further in sentence.", "labels": [], "entities": []}, {"text": "This test helps us understand what parts of the context are retained or forgotten by the neural network model representation.", "labels": [], "entities": []}, {"text": "Detailed results of each test are included in the appendix section ().", "labels": [], "entities": [{"text": "appendix", "start_pos": 50, "end_pos": 58, "type": "METRIC", "confidence": 0.9769064784049988}]}, {"text": "Please note that the part of BERT word embedding is the sentence embedding, therefore the BERT embedding performs better than 0.5, unlike other embeddings.", "labels": [], "entities": [{"text": "BERT", "start_pos": 90, "end_pos": 94, "type": "METRIC", "confidence": 0.8271257281303406}]}, {"text": "Following are the sentences used in the paper for experiments described in Section 4.", "labels": [], "entities": []}, {"text": "We list down the sentences in PassAct1 dataset and the generated sentences in the sections Section A.1.1 and Section A.1.2 respectively.", "labels": [], "entities": [{"text": "PassAct1 dataset", "start_pos": 30, "end_pos": 46, "type": "DATASET", "confidence": 0.9830514788627625}, {"text": "Section A.1.2", "start_pos": 109, "end_pos": 122, "type": "DATASET", "confidence": 0.7802968621253967}]}, {"text": "The two datasets are disjoint in terms of the sentences they contain, but are built using the same vocabulary.", "labels": [], "entities": []}, {"text": "Datasets PassAct2 dataset and Act3 dataset are detailed in subsections A.1.3 and A.1.4 respectively.", "labels": [], "entities": [{"text": "Datasets PassAct2 dataset", "start_pos": 0, "end_pos": 25, "type": "DATASET", "confidence": 0.6992469231287638}, {"text": "Act3 dataset", "start_pos": 30, "end_pos": 42, "type": "DATASET", "confidence": 0.9560847878456116}, {"text": "A.1.4", "start_pos": 81, "end_pos": 86, "type": "DATASET", "confidence": 0.8878374695777893}]}, {"text": "We observe that noun and verbs are retained in the context with same accuracy followed by determiner and then adjective.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 69, "end_pos": 77, "type": "METRIC", "confidence": 0.9985161423683167}]}], "tableCaptions": [{"text": " Table 1: MEG datasets used in this paper. Column  'Voice' refers to the sentence voice, 'P' is for passive  sentences and 'A' is for active. Repetition is the number  of times the human subject saw a sentence. For our  experiments, we average MEG data corresponding to  multiple repetitions of a single sentence.", "labels": [], "entities": [{"text": "MEG datasets", "start_pos": 10, "end_pos": 22, "type": "DATASET", "confidence": 0.7012229114770889}]}]}