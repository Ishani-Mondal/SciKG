{"title": [{"text": "Deep Neural Model Inspection and Comparison via Functional Neuron Pathways", "labels": [], "entities": [{"text": "Deep Neural Model Inspection", "start_pos": 0, "end_pos": 28, "type": "TASK", "confidence": 0.5347227603197098}]}], "abstractContent": [{"text": "We introduce a general method for the interpretation and comparison of neural models.", "labels": [], "entities": []}, {"text": "The method is used to factor a complex neural model into its functional components, which are comprised of sets of co-firing neurons that cut across layers of the network architecture, and which we call neural pathways.", "labels": [], "entities": []}, {"text": "The function of these pathways can be understood by identifying correlated task level and linguistic heuristics in such away that this knowledge acts as a lens for approximating what the network has learned to apply to its intended task.", "labels": [], "entities": []}, {"text": "As a case study for investigating the utility of these pathways, we present an examination of pathways identified in models trained for two standard tasks, namely Named Entity Recognition and Recognizing Textual Entailment.", "labels": [], "entities": [{"text": "Named Entity Recognition", "start_pos": 163, "end_pos": 187, "type": "TASK", "confidence": 0.6047451297442118}, {"text": "Recognizing Textual Entailment", "start_pos": 192, "end_pos": 222, "type": "TASK", "confidence": 0.7348199089368185}]}], "introductionContent": [{"text": "Interpretation of neural models is a difficult task because the knowledge learned within neural networks is distributed across hundreds of thousands of parameters.", "labels": [], "entities": [{"text": "Interpretation of neural models", "start_pos": 0, "end_pos": 31, "type": "TASK", "confidence": 0.8743674904108047}]}, {"text": "Interpreting the significance of any individual neuron is tantamount to reconstructing a forest based on a single pine needle.", "labels": [], "entities": []}, {"text": "More specifically, the contribution of each individual neuron is a minuscule part in the overall representation of the learned solution, and the mapping between neurons and function maybe many-to-many (.", "labels": [], "entities": []}, {"text": "As a response to this, the contribution of this paper is anew method of network interpretation that enables a more abstract view of what a network has learned, which we refer to as neural pathways.", "labels": [], "entities": [{"text": "network interpretation", "start_pos": 72, "end_pos": 94, "type": "TASK", "confidence": 0.7713195383548737}]}, {"text": "In this approach, inspired by the concept of biological neural pathways used in neuroscience research to understand physical brain function (), a network is factored into functional groups of co-firing neurons * Work was done as a graduate student at Carnegie Mellon University. that cut across layers in a complex network architecture.", "labels": [], "entities": []}, {"text": "Rather than attempt interpretation of the activation pattern through a single neuron at a time, we instead attempt interpretation of a functional group of neurons where the activation pattern of the group can then be more effectively associated with task and linguistic knowledge.", "labels": [], "entities": []}, {"text": "This enables understanding the neuron groups as working together to accomplish a comprehensible sub-task.", "labels": [], "entities": []}, {"text": "These pathways help conceptualize what task and linguistic knowledge a model maybe using in an approximate way, the benefit of which is that it does not depend on an isomorphism between network architectures.", "labels": [], "entities": []}, {"text": "This method, which can be applied simply in a purely post-hoc analysis, independent of the training process, can enable both understanding of individual models and comparison across models.", "labels": [], "entities": []}, {"text": "The interpretation process enables investigation of which identified functional groups correspond to linguistic or task level heuristics that maybe employed in well understood non-neural methods for performing the task.", "labels": [], "entities": []}, {"text": "Furthermore, it enables comparison across very different architectures in terms of the extent and the manner in which each architecture has approximated use of such knowledge.", "labels": [], "entities": []}, {"text": "In so doing, the method can also be used to formulate explanations for differences in performance between models based on relevant linguistic or task knowledge that is identified as learned or not learned by the models.", "labels": [], "entities": []}, {"text": "This approach builds on and extends prior work using linguistic and task knowledge to understand the behavior and the results of modern neural models (.", "labels": [], "entities": []}, {"text": "In the remainder of the paper we review common techniques for network interpretation followed by a detailed description of the neural pathways approach.", "labels": [], "entities": [{"text": "network interpretation", "start_pos": 62, "end_pos": 84, "type": "TASK", "confidence": 0.704706609249115}]}, {"text": "Next, we apply the neural pathways approach to previously published neural models, namely models for the task of named entity recognition (NER) (Ma and Hovy, 2016) on CoNLL 2003 data for English ( and recognizing textual entailment (.", "labels": [], "entities": [{"text": "named entity recognition (NER)", "start_pos": 113, "end_pos": 143, "type": "TASK", "confidence": 0.7586604456106821}, {"text": "CoNLL 2003 data", "start_pos": 167, "end_pos": 182, "type": "DATASET", "confidence": 0.9585181077321371}]}, {"text": "We compare across different neural architectures through a shared lens comprising linguistic and task-level heuristics for the two target tasks and draw conclusions about learning outcomes on those tasks.", "labels": [], "entities": []}], "datasetContent": [{"text": "To evaluate our interpretation technique on real world data, we applied our method on four trained models over two tasks: recognizing textual entailment using the Multi-genre Natural Language Inference corpus (Williams et al., 2018) and named entity recognition using the for English NER.", "labels": [], "entities": [{"text": "recognizing textual entailment", "start_pos": 122, "end_pos": 152, "type": "TASK", "confidence": 0.7690290013949076}, {"text": "named entity recognition", "start_pos": 237, "end_pos": 261, "type": "TASK", "confidence": 0.6523201962312063}]}, {"text": "The analysis was implemented using Scikit-Learn (Pedregosa et al., 2011) and SciPy ( and unless otherwise noted used default hyperparameters.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: F1 score for each model on the development  set for the entailment task and the NER task.", "labels": [], "entities": [{"text": "F1 score", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9801829755306244}, {"text": "NER task", "start_pos": 90, "end_pos": 98, "type": "TASK", "confidence": 0.8409146070480347}]}, {"text": " Table 2: Linear probe F1 score for the presence of pro- vided external task knowledge given the neural activa- tions and the difference between the two models. Top:  entailment stress test data instance categories. Bottom:  NER surface features. All performance metrics have  p < 0.05.", "labels": [], "entities": [{"text": "Linear probe F1 score", "start_pos": 10, "end_pos": 31, "type": "METRIC", "confidence": 0.7505254447460175}]}, {"text": " Table 3: Most correlated neural pathway along with the  rank correlation coefficient for each model for each task  studied. Top: entailment stress test data instance cate- gories. Bottom: NER surface features. All rank corre- lations have p < 0.001.", "labels": [], "entities": [{"text": "rank correlation coefficient", "start_pos": 57, "end_pos": 85, "type": "METRIC", "confidence": 0.8574172655741373}]}]}