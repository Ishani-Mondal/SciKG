{"title": [{"text": "Modeling Semantic Compositionality with Sememe Knowledge", "labels": [], "entities": [{"text": "Modeling Semantic Compositionality", "start_pos": 0, "end_pos": 34, "type": "TASK", "confidence": 0.6458579003810883}]}], "abstractContent": [{"text": "Semantic compositionality (SC) refers to the phenomenon that the meaning of a complex linguistic unit can be composed of the meanings of its constituents.", "labels": [], "entities": [{"text": "Semantic compositionality (SC)", "start_pos": 0, "end_pos": 30, "type": "TASK", "confidence": 0.9023080587387085}]}, {"text": "Most related works focus on using complicated compositional-ity functions to model SC while few works consider external knowledge in models.", "labels": [], "entities": []}, {"text": "In this paper, we verify the effectiveness of se-memes, the minimum semantic units of human languages, in modeling SC by a confir-matory experiment.", "labels": [], "entities": [{"text": "SC", "start_pos": 115, "end_pos": 117, "type": "TASK", "confidence": 0.8973327279090881}]}, {"text": "Furthermore, we make the first attempt to incorporate sememe knowledge into SC models, and employ the sememe-incorporated models in learning representations of multiword expressions, atypical task of SC.", "labels": [], "entities": []}, {"text": "In experiments, we implement our models by incorporating knowledge from a famous sememe knowledge base HowNet and perform both intrinsic and extrinsic evaluations.", "labels": [], "entities": [{"text": "HowNet", "start_pos": 103, "end_pos": 109, "type": "DATASET", "confidence": 0.7871262431144714}]}, {"text": "Experimental results show that our models achieve significant performance boost as compared to the baseline methods without considering se-meme knowledge.", "labels": [], "entities": []}, {"text": "We further conduct quantitative analysis and case studies to demonstrate the effectiveness of applying sememe knowledge in modeling SC.", "labels": [], "entities": []}, {"text": "All the code and data of this paper can be obtained on https: //github.com/thunlp/Sememe-SC.", "labels": [], "entities": []}], "introductionContent": [{"text": "Semantic compositionality (SC) is defined as the linguistic phenomenon that the meaning of a syntactically complex unit is a function of meanings of the complex unit's constituents and their combination rule.", "labels": [], "entities": [{"text": "Semantic compositionality (SC)", "start_pos": 0, "end_pos": 30, "type": "TASK", "confidence": 0.9040278792381287}]}, {"text": "Some linguists regard SC as the fundamental truth of semantics).", "labels": [], "entities": []}, {"text": "In the field of NLP, SC has proved effective in many tasks including language model- * Indicates equal contribution \u2020 Work done during internship at Tsinghua University \u2021 Corresponding author ing (, sentiment analysis (), syntactic parsing), etc.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 199, "end_pos": 217, "type": "TASK", "confidence": 0.8774654269218445}, {"text": "syntactic parsing", "start_pos": 222, "end_pos": 239, "type": "TASK", "confidence": 0.7246744483709335}]}, {"text": "Most literature on SC pays attention to using vector-based distributional models of semantics to learn representations of multiword expressions (MWEs), i.e., embeddings of phrases or compounds.", "labels": [], "entities": [{"text": "SC", "start_pos": 19, "end_pos": 21, "type": "TASK", "confidence": 0.9683064222335815}]}, {"text": "conduct a pioneering work in which they introduce a general framework to formulate this task: where f is the compositionality function, p denotes the embedding of an MWE, w 1 and w 2 represent the embeddings of the MWE's two constituents, R stands for the combination rule and K refers to the additional knowledge which is needed to construct the semantics of the MWE.", "labels": [], "entities": []}, {"text": "Among the proposed approaches for this task, most of them ignore Rand K, centering on reforming compositionality function f (.", "labels": [], "entities": []}, {"text": "Some try to integrate combination rule R into SC models.", "labels": [], "entities": [{"text": "combination rule R", "start_pos": 22, "end_pos": 40, "type": "TASK", "confidence": 0.6679333051045736}]}, {"text": "Few works consider external knowledge K. try to incorporate task-specific knowledge into an LSTM model for sentence-level SC.", "labels": [], "entities": []}, {"text": "As far as we know, however, no previous work attempts to use general knowledge in modeling SC.", "labels": [], "entities": []}, {"text": "In fact, there exists general linguistic knowledge which can be used in modeling SC, e.g., sememes.", "labels": [], "entities": []}, {"text": "Sememes are defined as the minimum semantic units of human languages Sp = S w1 \u222a S w2 \u519c\u6c11\u8d77\u4e49(peasant uprising) \u4e8b\u60c5|fact,\u804c\u4f4d|occupation,\u653f|politics,\u66b4\u52a8|uprise,\u4eba|human,\u519c|agricultural \u51e0\u4f55\u56fe\u5f62(geometric \u6570\u5b66|math,\u56fe\u50cf|image \u51e0\u4f55 (geometry; how much) \u6570 \u6570 \u6570\u5b66 \u5b66 \u5b66|math,\u77e5\u8bc6|knowledge,\u7591\u95ee|question,\u529f\u80fd\u8bcd|funcword \u5e94\u8003(engage a test) \u8003\u8bd5|exam,\u4ece\u4e8b|engage \u5e94 (deal with; echo; agree) \u5904\u7406|handle,\u56de\u5e94|respond,\u540c\u610f|agree,\u9075\u5faa|obey,\u529f\u80fd\u8bcd|funcword,\u59d3|surname words can be composed of a limited set of sememes, which is similar to the idea of semantic primes.", "labels": [], "entities": []}, {"text": "HowNet () is a widely acknowledged sememe knowledge base (KB), which defines about 2,000 sememes and uses them to annotate over 100,000 Chinese words together with their English translations.", "labels": [], "entities": [{"text": "HowNet", "start_pos": 0, "end_pos": 6, "type": "DATASET", "confidence": 0.9376223683357239}]}, {"text": "Sememes and HowNet have been successfully utilized in a variety of NLP tasks including sentiment analysis, word representation learning (, language modeling (, etc.", "labels": [], "entities": [{"text": "HowNet", "start_pos": 12, "end_pos": 18, "type": "DATASET", "confidence": 0.9069819450378418}, {"text": "sentiment analysis", "start_pos": 87, "end_pos": 105, "type": "TASK", "confidence": 0.9804361760616302}, {"text": "word representation learning", "start_pos": 107, "end_pos": 135, "type": "TASK", "confidence": 0.8525246977806091}, {"text": "language modeling", "start_pos": 139, "end_pos": 156, "type": "TASK", "confidence": 0.7108598947525024}]}, {"text": "In this paper, we argue that sememes are beneficial to modeling SC 2 . To verify this, we first design a simple SC degree (SCD) measurement experiment and find that the SCDs of MWEs computed by simple sememe-based formulae are highly correlated with human judgment.", "labels": [], "entities": [{"text": "SC 2", "start_pos": 64, "end_pos": 68, "type": "TASK", "confidence": 0.8845696747303009}, {"text": "SC degree (SCD) measurement", "start_pos": 112, "end_pos": 139, "type": "METRIC", "confidence": 0.7718370954195658}]}, {"text": "This result shows that sememes can finely depict meanings of MWEs and their constituents, and capture the semantic relations between the two sides.", "labels": [], "entities": []}, {"text": "Therefore, we believe that sememes are appropriate for modeling SC and can improve the performance of SC-related tasks like MWE representation learning.", "labels": [], "entities": [{"text": "MWE representation learning", "start_pos": 124, "end_pos": 151, "type": "TASK", "confidence": 0.9303126136461893}]}, {"text": "We propose two sememe-incorporated SC models for learning embeddings of MWEs, namely Semantic Compositionality with Aggregated Sememe (SCAS) model and Semantic Compositionality with Mutual Sememe Attention (SCMSA) model.", "labels": [], "entities": []}, {"text": "When learning the embedding of an MWE, SCAS model concatenates the embeddings of the MWE's constituents and their sememes, while SCMSA model considers the mutual attention be-tween a constituent's sememes and the other constituent.", "labels": [], "entities": []}, {"text": "We also integrate the combination rule, i.e., R in Eq.", "labels": [], "entities": []}, {"text": "(1), into the two models.", "labels": [], "entities": []}, {"text": "We evaluate our models on the task of MWE similarity computation, finding our models obtain significant performance improvement as compared to baseline methods.", "labels": [], "entities": [{"text": "MWE similarity computation", "start_pos": 38, "end_pos": 64, "type": "TASK", "confidence": 0.9221330285072327}]}, {"text": "Furthermore, we propose to evaluate SC models on a downstream task sememe prediction, and our models also exhibit favorable outcomes.", "labels": [], "entities": []}], "datasetContent": [{"text": "We evaluate our sememe-incorporated SC models on two tasks including MWE similarity computation and MWE sememe prediction.", "labels": [], "entities": [{"text": "MWE similarity computation", "start_pos": 69, "end_pos": 95, "type": "TASK", "confidence": 0.6492882271607717}, {"text": "MWE sememe prediction", "start_pos": 100, "end_pos": 121, "type": "TASK", "confidence": 0.7278918623924255}]}, {"text": "For the latter, we also conduct further quantitative analysis and case study.", "labels": [], "entities": []}, {"text": "We We use pretrained word embeddings of MWEs (needed for training in the MWE similarity task) and constituents, which are trained using GloVe) on the Sogou-T corpus . We also utilize pretrained sememe embeddings obtained from the results of a sememe-based word representation learning model 5 (.", "labels": [], "entities": [{"text": "MWE similarity task", "start_pos": 73, "end_pos": 92, "type": "TASK", "confidence": 0.8117143114407858}, {"text": "Sogou-T corpus", "start_pos": 150, "end_pos": 164, "type": "DATASET", "confidence": 0.8875315189361572}]}, {"text": "And we build a dataset consisting of 51,034 Chinese MWEs, each of which and its two constituents are annotated with sememes in HowNet and have pretrained word embeddings simultaneously.", "labels": [], "entities": [{"text": "HowNet", "start_pos": 127, "end_pos": 133, "type": "DATASET", "confidence": 0.9829521775245667}]}, {"text": "We randomly split the dataset into training, validation and test sets in the ratio of 8 : 1 : 1.", "labels": [], "entities": []}, {"text": "Baseline Methods We choose several typical SC models as the baseline methods, including: (1) ADD and MUL, the simple additive and elementwise multiplicative models (; SCAS-S, the ablated version of our SCAS model which removes sememe knowledge 6 . These baseline methods range from the simplest additive model to complicated tensor-based model, all of which take no knowledge into consideration.", "labels": [], "entities": [{"text": "MUL", "start_pos": 101, "end_pos": 104, "type": "METRIC", "confidence": 0.85392165184021}]}, {"text": "Combination Rules For simplicity, we divide all the MWEs in our dataset into four combination types, i.e., adjective-noun (Adj-N), noun-noun (N-N), verb-noun (V-N) and other (Other), whose instance numbers are 1302, 8276, 4242 and 37214 respectively.", "labels": [], "entities": []}, {"text": "And we use the suffix +R to signify integrating combination rules into the model.", "labels": [], "entities": []}, {"text": "We use two popular Chinese word similarity datasets, namely WordSim-240 (WS240) and WordSim-297 (WS297), and a newly built one, COS960, all of which consist of word pairs together with human-assigned similarity scores.", "labels": [], "entities": [{"text": "WordSim-240 (WS240", "start_pos": 60, "end_pos": 78, "type": "DATASET", "confidence": 0.8274097442626953}, {"text": "WordSim-297 (WS297)", "start_pos": 84, "end_pos": 103, "type": "DATASET", "confidence": 0.8383187651634216}, {"text": "COS960", "start_pos": 128, "end_pos": 134, "type": "DATASET", "confidence": 0.8563920259475708}]}, {"text": "The first two datasets have 86 and 97 word pairs appearing in our MWE dataset respectively, and their humanassigned similarity scores are based on relatedness.", "labels": [], "entities": [{"text": "MWE dataset", "start_pos": 66, "end_pos": 77, "type": "DATASET", "confidence": 0.971696525812149}]}, {"text": "On the other hand, COS960 has 960 word pairs and all of them are in our MWE dataset.", "labels": [], "entities": [{"text": "COS960", "start_pos": 19, "end_pos": 25, "type": "DATASET", "confidence": 0.8993605375289917}, {"text": "MWE dataset", "start_pos": 72, "end_pos": 83, "type": "DATASET", "confidence": 0.9818751215934753}]}, {"text": "Moreover, its similarity scores are based on similarity.", "labels": [], "entities": [{"text": "similarity", "start_pos": 14, "end_pos": 24, "type": "METRIC", "confidence": 0.9955026507377625}, {"text": "similarity", "start_pos": 45, "end_pos": 55, "type": "METRIC", "confidence": 0.9944812059402466}]}, {"text": "We calculate the Spearman's rank correlation coefficient between cosine similarities of word pairs computed byword embeddings of SC models and human-annotated scores.", "labels": [], "entities": [{"text": "Spearman's rank correlation coefficient", "start_pos": 17, "end_pos": 56, "type": "METRIC", "confidence": 0.6342188358306885}]}, {"text": "We use the above-mentioned test set for evaluation.", "labels": [], "entities": []}, {"text": "As for the evaluation protocol, we adopt mean average precision (MAP) and F1 score following previous sememe prediction works).", "labels": [], "entities": [{"text": "mean average precision (MAP)", "start_pos": 41, "end_pos": 69, "type": "METRIC", "confidence": 0.940825879573822}, {"text": "F1 score", "start_pos": 74, "end_pos": 82, "type": "METRIC", "confidence": 0.9865631461143494}]}, {"text": "Since our SC models and baseline methods yield a score for each se-meme in the whole sememe set, we pick the sememes with scores higher than \u03b4 to compute F1 score, where \u03b4 is a hyper-parameter and also tuned to the best on the validation set.", "labels": [], "entities": [{"text": "F1 score", "start_pos": 154, "end_pos": 162, "type": "METRIC", "confidence": 0.9890899956226349}]}, {"text": "The overall sememe prediction results are exhibited in.", "labels": [], "entities": [{"text": "sememe prediction", "start_pos": 12, "end_pos": 29, "type": "TASK", "confidence": 0.8158868253231049}]}], "tableCaptions": [{"text": " Table 2: Spearman's rank correlation coefficient (\u03c1 \u00d7  100) between similarity scores assigned by composi- tional models with human ratings.", "labels": [], "entities": [{"text": "Spearman's rank correlation coefficient (\u03c1 \u00d7  100)", "start_pos": 10, "end_pos": 60, "type": "METRIC", "confidence": 0.7203902930021286}]}, {"text": " Table 3: Overall MWE sememe prediction results of all  the models.", "labels": [], "entities": [{"text": "MWE sememe prediction", "start_pos": 18, "end_pos": 39, "type": "TASK", "confidence": 0.8721505999565125}]}, {"text": " Table 4: Sememe prediction MAP of our models on  MWEs with different SCDs. The numbers of MWEs  with the four SCDs are 180, 2540, 1686 and 698 re- spectively.", "labels": [], "entities": [{"text": "Sememe prediction MAP", "start_pos": 10, "end_pos": 31, "type": "TASK", "confidence": 0.8250322143236796}]}, {"text": " Table 5: Sememe prediction MAP of our models on  MWEs with different combination rules and average  SCDs of the four subsets. The numbers of MWEs with  the four combination rules are 157, 893, 443 and 3,611  respectively.", "labels": [], "entities": [{"text": "Sememe prediction MAP", "start_pos": 10, "end_pos": 31, "type": "TASK", "confidence": 0.8301714658737183}]}]}