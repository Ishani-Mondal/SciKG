{"title": [{"text": "Linguistically-Driven Strategy for Concept Prerequisites Learning on Italian", "labels": [], "entities": []}], "abstractContent": [{"text": "We present anew concept prerequisite learning method for Learning Object (LO) ordering that exploits only linguistic features extracted from textual educational resources.", "labels": [], "entities": [{"text": "Learning Object (LO) ordering", "start_pos": 57, "end_pos": 86, "type": "TASK", "confidence": 0.6744126975536346}]}, {"text": "The method was tested in a cross-and in-domain scenario both for Italian and English.", "labels": [], "entities": []}, {"text": "Additionally, we performed experiments based on a incremental training strategy to study the impact of the training set size on the classi-fier performances.", "labels": [], "entities": []}, {"text": "The paper also introduces ITA-PREREQ, to the best of our knowledge the first Italian dataset annotated with prerequisite relations between pairs of educational concepts, and describe the automatic strategy devised to build it.", "labels": [], "entities": []}], "introductionContent": [{"text": "Learning Objects (LO) are digital or non-digital educational resources deliverable over the Internet that can be employed in technology-supported learning).", "labels": [], "entities": []}, {"text": "According to the Learning Technology Standards Committee, being small and re-usable educational elements (e.g. lecture notes, multimedia content, presentations) is what mostly distinguishes LOs form other educational resources.", "labels": [], "entities": []}, {"text": "Recommendations for creating LOs in fact suggest that, although there is no standard LO structure, the content should be direct, succinct and homogeneous).", "labels": [], "entities": []}, {"text": "Grounded in the notion of object-oriented computing and programming, LO are designed according to the idea that combining small chunks of knowledge is what builds up an effective learning path.", "labels": [], "entities": []}, {"text": "In order to promote sharing and re-usability, LO repositories were made available on the web, where LOs are stored, collected and can be searched by means of metadata provided by their authors ().", "labels": [], "entities": []}, {"text": "Teachers and instructional designers can highly benefit from LO repositories since they can use them to build educational materials such as textbooks, courses or, more in general, learning paths by combining various LOs of the same subject.", "labels": [], "entities": []}, {"text": "Being able to give a pedagogical meaning to the content of a set of LOs by ordering them respecting their pedagogical precedence is not trivial: uncovering educational relationship between LOs is a difficult and time consuming practice usually performed by domain experts).", "labels": [], "entities": []}, {"text": "Among all pedagogical relations, the most fundamental is the prerequisite relation, which best describes pedagogical precedence since it defines what one needs to know before approaching anew content.", "labels": [], "entities": []}, {"text": "Previous work in course and LO sequencing and knowledge tracing infers prerequisite relation between LOs based on their metadata and/or students' preferences and competences.", "labels": [], "entities": [{"text": "LO sequencing", "start_pos": 28, "end_pos": 41, "type": "TASK", "confidence": 0.6495603322982788}, {"text": "knowledge tracing", "start_pos": 46, "end_pos": 63, "type": "TASK", "confidence": 0.7297567278146744}]}, {"text": "Educational Data Mining methods usually rely also on graph information of ontologies, university programs or Wikipedia graph structure (.", "labels": [], "entities": [{"text": "Educational Data Mining", "start_pos": 0, "end_pos": 23, "type": "TASK", "confidence": 0.6043199400107065}]}, {"text": "In this paper we present a novel method based on deep learning applied to the task of automatic prerequisite relations identification between concepts to automatically create pedagogically motivated sequences of LOs.", "labels": [], "entities": [{"text": "automatic prerequisite relations identification between concepts", "start_pos": 86, "end_pos": 150, "type": "TASK", "confidence": 0.746295173962911}]}, {"text": "To the best of our knowledge, this is the first method that exploits exclusively linguistic feature extracted from textual resources.", "labels": [], "entities": []}, {"text": "Considering only textual content is possibly the most complex condition to infer relationships between educational concepts since it cannot rely on any structured information.", "labels": [], "entities": []}, {"text": "At the same time this is also the closest condition to areal world scenario, hence we aim to demonstrate that textual content can be sufficient to infer a pedagogically motivated ordering of LO pairs.", "labels": [], "entities": []}, {"text": "To verify the effectiveness of our strategy, we performed experiments on the AL-CPL dataset (), an English dataset manually annotated with prerequisite relations between educational concepts, and on an Italian dataset we created.", "labels": [], "entities": [{"text": "AL-CPL dataset", "start_pos": 77, "end_pos": 91, "type": "DATASET", "confidence": 0.7805853188037872}, {"text": "Italian dataset", "start_pos": 202, "end_pos": 217, "type": "DATASET", "confidence": 0.7918556928634644}]}, {"text": "Hence, we introduce ITA-PREREQ 1 , the first Italian dataset, to the best of our knowledge, annotated with prerequisite relations between pairs of concepts, built completely automatically.", "labels": [], "entities": [{"text": "Italian dataset", "start_pos": 45, "end_pos": 60, "type": "DATASET", "confidence": 0.8152991235256195}]}, {"text": "Along the paper, we use the terms Learning Object (LO) and Wikipedia page interchangeably: in abroad sense, Wikipedia entries can be considered Ls, moreover previous work in related fields represent educational units as Wikipedia pages (.", "labels": [], "entities": []}, {"text": "This fits our needs since a Wikipedia page consists of textual content pertaining to a single unit of learning.", "labels": [], "entities": []}, {"text": "The term concept is also frequently used in the literature referring to educational units in general, and annotated dataset are usually described as identifying prerequisite relations between concepts.", "labels": [], "entities": []}, {"text": "In this paper we use the term concept relying on the same sense of as equivalent to the term LO.", "labels": [], "entities": [{"text": "LO", "start_pos": 93, "end_pos": 95, "type": "METRIC", "confidence": 0.8456323742866516}]}, {"text": "The remaining part of the paper is organised as follows.", "labels": [], "entities": []}, {"text": "First we present related work (Sec 2), then, after briefly presenting our approach (Sec. 3), we describe in more detail the data (Sec. 3.1), used features (3.2) and the classifier (Sec. 3.3).", "labels": [], "entities": []}, {"text": "We also provide an insight of feature analysis in Sec 3.2.1.", "labels": [], "entities": [{"text": "feature analysis", "start_pos": 30, "end_pos": 46, "type": "TASK", "confidence": 0.789402961730957}]}, {"text": "Experiments, results and incremental training tests are described in Section 4.", "labels": [], "entities": []}, {"text": "In Section 5 we conclude the paper.", "labels": [], "entities": []}, {"text": "In this paper, we present: (i) the first system based on neural network which exploits only linguistic features extracted from LO content and does not rely on Wikipedia graph or LO metadata information; (ii) the first Italian dataset annotated with prerequisite relations between pairs of concepts (ITA-PREREQ) and the automatic strategy devised to construct it; (iii) the first system for prerequisite relations extraction on Italian.", "labels": [], "entities": [{"text": "prerequisite relations extraction", "start_pos": 390, "end_pos": 423, "type": "TASK", "confidence": 0.6871919929981232}]}], "datasetContent": [{"text": "For our experiments on the English language, we relied on the AL-CPL Dataset (, which is in turn based on the Wiki Concept Map dataset ( ).", "labels": [], "entities": [{"text": "AL-CPL Dataset", "start_pos": 62, "end_pos": 76, "type": "DATASET", "confidence": 0.801251620054245}, {"text": "Wiki Concept Map dataset", "start_pos": 110, "end_pos": 134, "type": "DATASET", "confidence": 0.8471576571464539}]}, {"text": "The Wiki Concept Map dataset is a manually constructed dataset consisting of binary-labelled concept pairs collected from textbooks on different educational domains: data mining, geometry, physics and precalculus.", "labels": [], "entities": [{"text": "Wiki Concept Map dataset", "start_pos": 4, "end_pos": 28, "type": "DATASET", "confidence": 0.8668813854455948}]}, {"text": "Concepts mentioned in the textbooks and appearing in the title of a Wikipedia page were considered domain concepts.", "labels": [], "entities": []}, {"text": "Among them, key concepts and prerequisite relationships between them were annotated by experts for each domain, resulting in a concept map, a specific type of knowledge graph where each node is a scientific concept and edges represent pedagogical relations.", "labels": [], "entities": []}, {"text": "Pairs not having prerequisite relation were also annotated, therefore the final dataset consists of both positive and negative pairs.", "labels": [], "entities": []}, {"text": "(2018b) the dataset was expanded by adding (i) irreflexive and (ii) transitive relations: considering A, B and C as distinct concepts, (i) add (B, A) as a negative sample of (A, B); (ii) add (A, C) as positive sample if (A, B) and (B, C) are positive samples.", "labels": [], "entities": []}, {"text": "The AL-CPL dataset was also used by us to build ITA-PREREQ, the first Italian dataset annotated with prerequisite relation between pair of concepts, which we used to test our model on Italian.", "labels": [], "entities": [{"text": "AL-CPL dataset", "start_pos": 4, "end_pos": 18, "type": "DATASET", "confidence": 0.7906355857849121}]}, {"text": "Considering the concepts of the AL-CPL dataset, we retrieved their Italian Wikipedia pages by matching the page title with the concept name.", "labels": [], "entities": [{"text": "AL-CPL dataset", "start_pos": 32, "end_pos": 46, "type": "DATASET", "confidence": 0.7474612295627594}, {"text": "Italian Wikipedia pages", "start_pos": 67, "end_pos": 90, "type": "DATASET", "confidence": 0.9020081162452698}]}, {"text": "If the Italian page of a concept was not available, the concept was excluded from the dataset.", "labels": [], "entities": []}, {"text": "At the end of this process, we obtained an automatically constructed version of the AL-CPL dataset for Italian with a subset of 418 concepts (77.40% of the original dataset).", "labels": [], "entities": [{"text": "AL-CPL dataset", "start_pos": 84, "end_pos": 98, "type": "DATASET", "confidence": 0.7769323885440826}]}, {"text": "Note that the dataset only provides concept names (i.e. page titles), which means that downloading the pages from Wikipedia at different times might results in a slightly different corpus, since Wikipedia pages are frequently edited.", "labels": [], "entities": []}, {"text": "In our case, we used the latest Wikipedia dump at the time of the experiments.", "labels": [], "entities": []}, {"text": "Considering such Wikipedia impact factors (i.e. editing and differences between languages), we created a third dataset, again generated starting from AL-CPL.", "labels": [], "entities": []}, {"text": "We call this version English Reduced since it is built excluding all those English Wikipedia pages that do not have a corresponding Italian one.", "labels": [], "entities": []}, {"text": "Therefore, the size of English Reduced is the same of ITA-PREREQ.", "labels": [], "entities": [{"text": "ITA-PREREQ", "start_pos": 54, "end_pos": 64, "type": "DATASET", "confidence": 0.8199995756149292}]}, {"text": "The aim of having this dataset is to check the real impact of languages differences by balancing the number of pages taken into account, as we will discuss further in the next Section.", "labels": [], "entities": []}, {"text": "summarises the statistics of the three datasets.", "labels": [], "entities": []}, {"text": "Although ITA-PREREQ and English Reduced resulted in smaller datasets in terms of both concepts and relations, their sizes are suited for training our systems.", "labels": [], "entities": [{"text": "ITA-PREREQ", "start_pos": 9, "end_pos": 19, "type": "DATASET", "confidence": 0.8806663155555725}]}, {"text": "We tested our approach predicting in-domain and cross-domain prerequisite relationships.", "labels": [], "entities": []}, {"text": "Since the majority of (A, B) pairs do not present a prerequisite relation, we balanced the training and test sets by oversampling the minority class.", "labels": [], "entities": []}, {"text": "All experiments were performed on AL-CPL, ITA-PREREQ and English Reduced datasets.", "labels": [], "entities": [{"text": "ITA-PREREQ", "start_pos": 42, "end_pos": 52, "type": "DATASET", "confidence": 0.8486014604568481}, {"text": "English Reduced datasets", "start_pos": 57, "end_pos": 81, "type": "DATASET", "confidence": 0.784573495388031}]}, {"text": "As baseline, we used the Zero Rule algorithm, and FScore as evaluation metric.", "labels": [], "entities": [{"text": "FScore", "start_pos": 50, "end_pos": 56, "type": "METRIC", "confidence": 0.9679639339447021}]}, {"text": "We run experiments using the three classifiers presented in Sec 3.3 on each dataset, considering each of the four domains independently (i.e Data Mining, Geometry, Physics and Precalculus).", "labels": [], "entities": []}, {"text": "Each classifier was tested both in a in-domain and crossdomain scenario.", "labels": [], "entities": []}, {"text": "To perform in-domain experiments, we trained and tested the classifiers on concept pairs belonging to the same domain.", "labels": [], "entities": []}, {"text": "The evaluation is performed using a 5-fold cross validation.", "labels": [], "entities": []}, {"text": "Crossdomain experiments were performed in a leaveone-domain-out manner: classifiers were trained on three domains and tested on the fourth.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Number of concepts, pairs, pairs show- ing a prerequisite relation for each domain of each  dataset and total values considering all domains for  each dataset.", "labels": [], "entities": []}, {"text": " Table 3: In-and cross-domain results in terms of F-Score obtained by the three models and the baseline on each  domain for each dataset. The in-domain setting also shows results obtained by Liang et al. (2018a) using a Random  Forest (RF) classifier.", "labels": [], "entities": [{"text": "F-Score", "start_pos": 50, "end_pos": 57, "type": "METRIC", "confidence": 0.9945074915885925}]}]}