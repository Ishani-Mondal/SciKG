{"title": [{"text": "SphereRE: Distinguishing Lexical Relations with Hyperspherical Relation Embeddings", "labels": [], "entities": [{"text": "SphereRE", "start_pos": 0, "end_pos": 8, "type": "TASK", "confidence": 0.8234786987304688}, {"text": "Distinguishing Lexical Relations with Hyperspherical Relation Embeddings", "start_pos": 10, "end_pos": 82, "type": "TASK", "confidence": 0.7401342136519296}]}], "abstractContent": [{"text": "Lexical relations describe how meanings of terms relate to each other.", "labels": [], "entities": []}, {"text": "Typical relations include hypernymy, synonymy, meronymy, etc.", "labels": [], "entities": []}, {"text": "Automatic distinction of lexical relations is vital for NLP applications, and is also challenging due to the lack of contextual signals to discriminate between such relations.", "labels": [], "entities": [{"text": "Automatic distinction of lexical relations", "start_pos": 0, "end_pos": 42, "type": "TASK", "confidence": 0.7698567152023316}]}, {"text": "In this work, we present a neural representation learning model to distinguish lexical relations among term pairs based on Hyperspherical Relation Embeddings (SphereRE).", "labels": [], "entities": []}, {"text": "Rather than learning embeddings for individual terms, the model learns representations of relation triples by mapping them to the hyperspherical embedding space, where relation triples of different lexical relations are well separated.", "labels": [], "entities": []}, {"text": "We further introduce a Monte-Carlo based sampling and learning algorithm to train the model via transductive learning.", "labels": [], "entities": []}, {"text": "Experiments over several benchmarks confirm SphereRE outper-forms state-of-the-arts.", "labels": [], "entities": [{"text": "SphereRE", "start_pos": 44, "end_pos": 52, "type": "DATASET", "confidence": 0.6041980981826782}, {"text": "outper-forms", "start_pos": 53, "end_pos": 65, "type": "METRIC", "confidence": 0.6973780989646912}]}], "introductionContent": [{"text": "Lexical relations are relations between terms in lexicons.", "labels": [], "entities": []}, {"text": "Types of lexical relations include hypernymy, synonymy, meronymy, etc.", "labels": [], "entities": []}, {"text": "Such relations are treated as key resources for various NLP applications, e.g., question answering (, taxonomy induction (, machine translation ( , natural language inference, lexical database construction (, etc.", "labels": [], "entities": [{"text": "question answering", "start_pos": 80, "end_pos": 98, "type": "TASK", "confidence": 0.9243996143341064}, {"text": "taxonomy induction", "start_pos": 102, "end_pos": 120, "type": "TASK", "confidence": 0.7917582988739014}, {"text": "machine translation", "start_pos": 124, "end_pos": 143, "type": "TASK", "confidence": 0.7394155859947205}, {"text": "lexical database construction", "start_pos": 176, "end_pos": 205, "type": "TASK", "confidence": 0.649869958559672}]}, {"text": "Due to its importance, automatic acquisition of lexical relations is a research focus in NLP.", "labels": [], "entities": [{"text": "automatic acquisition of lexical relations", "start_pos": 23, "end_pos": 65, "type": "TASK", "confidence": 0.7863248586654663}]}, {"text": "In early years, lexical relations in WordNet were manually compiled by linguists.", "labels": [], "entities": []}, {"text": "Recently, path-based and distributional approaches are two major paradigms to classify a term pair into a fixed inventory of lexical relations, or to predict it as random (meaning the two terms are un-related).", "labels": [], "entities": []}, {"text": "Path-based approaches use dependency paths connecting two terms to infer lexical relations ().", "labels": [], "entities": []}, {"text": "The paths usually describe relations between terms explicitly, but require the two terms co-occur in a sentence, leading to the \"low coverage\" problem.", "labels": [], "entities": []}, {"text": "Apart from Hearst patterns, there are few high-quality textual patterns to recognize lexical relations other than hypernymy.", "labels": [], "entities": []}, {"text": "Distributional approaches consider the global contexts of terms to predict lexical relations using word embeddings (.", "labels": [], "entities": []}, {"text": "They are reported to outperform several path-based approaches, but can suffer from the \"lexical memorization\" problem (.", "labels": [], "entities": []}, {"text": "This is because some supervised distributional approaches learn properties of two terms separately, instead of how two terms relate to each other in the embedding space.", "labels": [], "entities": []}, {"text": "In this paper, we aim at improving distributional approaches by learning lexical relation representations in hyperspherical embedding space, named hyperSpherical Relation Embeddings (SphereRE).", "labels": [], "entities": []}, {"text": "Consider the example w.r.t. car in.", "labels": [], "entities": []}, {"text": "Word embeddings of these terms are similar to each other due to their contextual similarity.", "labels": [], "entities": []}, {"text": "Hence, embedding offsets of term pairs cannot distin-guish the three types of lexical relations well (i.e., hypernymy, synonymy and meronymy).", "labels": [], "entities": []}, {"text": "Instead of learning individual term embeddings, we directly map all the relation triples to the hyperspherical embedding space such that different types of lexical relations have diverse embeddings in terms of angles.", "labels": [], "entities": []}, {"text": "For example, the angle between embeddings of (car, hypernymy, vehicle) and (car, synonymy, auto) is large.", "labels": [], "entities": []}, {"text": "In contrast, that of (car, synonymy, automobile) and (car, synonymy, auto) is small.", "labels": [], "entities": []}, {"text": "As a result, different types of lexical relations can be distinguished.", "labels": [], "entities": []}, {"text": "Moreover, by learning representations of lexical relation triples explicitly, our work addresses \"lexical memorization\" () from a distributional aspect.", "labels": [], "entities": []}, {"text": "To learn SphereRE vectors for lexical relation triples, we minimize embedding distances of term pairs that are likely to share the same lexical relation in both labeled and unlabeled data, and maximize embedding distances of different lexical relations.", "labels": [], "entities": []}, {"text": "The distances in the hyperspherical space are defined based on the angles of embeddings.", "labels": [], "entities": []}, {"text": "In this work, we first propose a relation-aware semantic projection model to estimate probabilistic distributions of lexical relations over unlabeled data.", "labels": [], "entities": [{"text": "relation-aware semantic projection", "start_pos": 33, "end_pos": 67, "type": "TASK", "confidence": 0.6071819961071014}]}, {"text": "The SphereRE vectors are efficiently learned by Monte-Carlo techniques by transductive learning.", "labels": [], "entities": []}, {"text": "Finally, a neural network based classifier is trained using all the features to make the final predictions of lexical relations overall unlabeled data.", "labels": [], "entities": []}, {"text": "We evaluate SphereRE over four benchmark datasets and the CogALex-V shared task (, and confirm that SphereRE is highly effective, outperforming state-of-the-art.", "labels": [], "entities": []}, {"text": "We also evaluate the embedding quality of SphereRE.", "labels": [], "entities": []}, {"text": "The rest of this paper is organized as follows.", "labels": [], "entities": []}, {"text": "Section 2 summarizes the related work.", "labels": [], "entities": []}, {"text": "We present SphereRE in Section 3.", "labels": [], "entities": []}, {"text": "Experiments are illustrated in Section 4, with the conclusion shown in Section 5.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section, we conduct extensive experiments to evaluate SphereRE and compare it with stateof-the-art to make the convincing conclusion.", "labels": [], "entities": []}, {"text": "In the experiments, we train a fastText model) over the English Wikipedia corpus to generate term embeddings.", "labels": [], "entities": [{"text": "English Wikipedia corpus", "start_pos": 56, "end_pos": 80, "type": "DATASET", "confidence": 0.909459133942922}]}, {"text": "The dimensionality dis set to 300.", "labels": [], "entities": []}, {"text": "To evaluate the effectiveness of SphereRE, we use four public datasets for multi-way classification of lexical relations: K&H+N (, BLESS (Baroni and Lenci, 2011), ROOT09 () and EVALution ().", "labels": [], "entities": [{"text": "BLESS", "start_pos": 131, "end_pos": 136, "type": "METRIC", "confidence": 0.9985826015472412}, {"text": "ROOT09", "start_pos": 163, "end_pos": 169, "type": "METRIC", "confidence": 0.9648249745368958}, {"text": "EVALution", "start_pos": 177, "end_pos": 186, "type": "METRIC", "confidence": 0.7069487571716309}]}, {"text": "We also evaluate SphereRE over the subtask 2 of the CogALex-V shared task ().", "labels": [], "entities": []}, {"text": "The statistics are summarized in.", "labels": [], "entities": []}, {"text": "We follow the exact same experimental settings to partition the four public datasets into training, validation and testing sets as in.", "labels": [], "entities": []}, {"text": "The partition of the CogALex dataset is the same as those in the default settings of the CogALex-V shared task ().", "labels": [], "entities": [{"text": "CogALex dataset", "start_pos": 21, "end_pos": 36, "type": "DATASET", "confidence": 0.9054107666015625}]}, {"text": "The default settings for SphereRE are as follows: \u00b5 = 0.001, d r = 300, |D mini | = 20, |S| = 100, \u03b3 = 2 and l = 3.", "labels": [], "entities": [{"text": "\u00b5", "start_pos": 50, "end_pos": 51, "type": "METRIC", "confidence": 0.9685849547386169}, {"text": "D mini", "start_pos": 73, "end_pos": 79, "type": "METRIC", "confidence": 0.8810338973999023}]}, {"text": "We run Algorithm 1 in 500 iterations.", "labels": [], "entities": []}, {"text": "We also report how the changes of the neural network architecture and parameters affect the performance over the validation sets afterwards.", "labels": [], "entities": []}, {"text": "It should be further noted that we do not set the values of \u03bb 1 and \u03bb 2 in the implementation because we employ sampling based techniques to learn r i , instead of directly optimizing J(\u0398).", "labels": [], "entities": []}, {"text": "We report the results of SphereRE and compare it with state-of-the-art over four public datasets.", "labels": [], "entities": []}, {"text": "We evaluate SphereRE over the CogALex-V shared task (), where participants are asked to classify 4,260 term pairs into 5 lexical relations: synonymy, antonymy, hypernymy, meronymy and random.", "labels": [], "entities": []}, {"text": "The training set contains 3,054 pairs.", "labels": [], "entities": []}, {"text": "This task is the most challenging because i) it considers random relations as noise, discarding it from the averaged F1 score; ii) the training set is small; and iii) it enforces lexical spilt of the training and testing sets, disabling \"lexical memorization\" ().", "labels": [], "entities": [{"text": "F1 score", "start_pos": 117, "end_pos": 125, "type": "METRIC", "confidence": 0.9757179915904999}]}, {"text": "In this shared task, GHHH (Attia et al., 2016) and are toptwo systems with the highest performance.", "labels": [], "entities": [{"text": "GHHH", "start_pos": 21, "end_pos": 25, "type": "METRIC", "confidence": 0.5391442179679871}]}, {"text": "The most recent work on CogALex-V is STM (.", "labels": [], "entities": [{"text": "STM", "start_pos": 37, "end_pos": 40, "type": "DATASET", "confidence": 0.5900509357452393}]}, {"text": "SphereRE achieves the averaged F1 score of 47.1% (excluding the random relations), outperforming state-of-the-art.", "labels": [], "entities": [{"text": "F1 score", "start_pos": 31, "end_pos": 39, "type": "METRIC", "confidence": 0.9871072471141815}]}, {"text": "Additionally, as reported in previous studies, the \"lexical memorization\" effect () is rather severe for hypernymy relations.", "labels": [], "entities": []}, {"text": "Although SphereRE is fully distributional, it achieves the highest F1 score of 53.8%.", "labels": [], "entities": [{"text": "F1 score", "start_pos": 67, "end_pos": 75, "type": "METRIC", "confidence": 0.9883389472961426}]}], "tableCaptions": [{"text": " Table 1: The choice of w i,j according to different conditions.", "labels": [], "entities": []}, {"text": " Table 2: Statistics of all datasets. Relation names in all datasets have been mapped to relation names in WordNet.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 107, "end_pos": 114, "type": "DATASET", "confidence": 0.977603018283844}]}, {"text": " Table 3: Performance comparison of lexical relation classification over four public datasets.", "labels": [], "entities": [{"text": "lexical relation classification", "start_pos": 36, "end_pos": 67, "type": "TASK", "confidence": 0.6882946888605753}]}, {"text": " Table 4: Feature analysis in terms of F1 score.", "labels": [], "entities": [{"text": "F1 score", "start_pos": 39, "end_pos": 47, "type": "METRIC", "confidence": 0.9777923822402954}]}, {"text": " Table 5: Performance comparison over the CogALex- V shared task. (Due to space limitation, we only list  the performance of top systems in CogALex-V.)", "labels": [], "entities": [{"text": "CogALex- V shared task", "start_pos": 42, "end_pos": 64, "type": "TASK", "confidence": 0.6485839366912842}]}, {"text": " Table 6: Performance of top-k similar relation retrieval over five datasets in terms of Average Precision@k.", "labels": [], "entities": [{"text": "Precision", "start_pos": 97, "end_pos": 106, "type": "METRIC", "confidence": 0.8218971490859985}]}]}