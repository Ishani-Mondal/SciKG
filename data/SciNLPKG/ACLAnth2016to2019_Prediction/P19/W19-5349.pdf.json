{"title": [], "abstractContent": [{"text": "Machine translation is one of the most popular areas in natural language processing.", "labels": [], "entities": [{"text": "Machine translation", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.8673085272312164}, {"text": "natural language processing", "start_pos": 56, "end_pos": 83, "type": "TASK", "confidence": 0.6503807306289673}]}, {"text": "WMT is a conference to assess the level of machine translation capabilities of organizations around the world, which is the evaluation activity we participated in.", "labels": [], "entities": [{"text": "WMT", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.82098788022995}, {"text": "machine translation", "start_pos": 43, "end_pos": 62, "type": "TASK", "confidence": 0.7135875225067139}]}, {"text": "In this review we participated in a two-way translation track from Russian to English and English to Rus-sian.", "labels": [], "entities": []}, {"text": "We used official training data, 38 million parallel corpora, and 10 million monolin-gual corpora.", "labels": [], "entities": []}, {"text": "The overall framework we use is the Transformer(Vaswani et al., 2017) neu-ral machine translation model, supplemented by data filtering, post-processing, reordering and other related processing methods.", "labels": [], "entities": [{"text": "Transformer(Vaswani et al., 2017) neu-ral machine translation", "start_pos": 36, "end_pos": 97, "type": "TASK", "confidence": 0.5532914698123932}]}, {"text": "The BLEU(Papineni et al., 2002) value of our final translation result from Russian to English is 38.7, ranking 5th, while from English to Rus-sian is 27.8, ranking 10th.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 4, "end_pos": 8, "type": "METRIC", "confidence": 0.9983841180801392}]}], "introductionContent": [{"text": "Neural machine translation has been widely used in the field of machine translation, because it is more accurate than statistical machine translation inmost cases.", "labels": [], "entities": [{"text": "Neural machine translation", "start_pos": 0, "end_pos": 26, "type": "TASK", "confidence": 0.7590225140253702}, {"text": "machine translation", "start_pos": 64, "end_pos": 83, "type": "TASK", "confidence": 0.8346150517463684}, {"text": "statistical machine translation", "start_pos": 118, "end_pos": 149, "type": "TASK", "confidence": 0.6277228196461996}]}, {"text": "The proposed attention mechanism brought anew revolution in the neural machine translation, making the overall effect of translation much better than before.", "labels": [], "entities": [{"text": "neural machine translation", "start_pos": 64, "end_pos": 90, "type": "TASK", "confidence": 0.7368595004081726}]}, {"text": "Then, the Transformer that makes full use of the attention mechanism , both in terms of performance and effectiveness.", "labels": [], "entities": []}, {"text": "Up to now, most of the work has been carried out on Transformer, and its superiority has been widely recognized.", "labels": [], "entities": [{"text": "Transformer", "start_pos": 52, "end_pos": 63, "type": "TASK", "confidence": 0.5113180875778198}]}, {"text": "From the beginning of machine translation research, there has been the development of twoway translation between Russian and English.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 22, "end_pos": 41, "type": "TASK", "confidence": 0.7959980666637421}, {"text": "twoway translation", "start_pos": 86, "end_pos": 104, "type": "TASK", "confidence": 0.6859117597341537}]}, {"text": "As early as 1954, Georgetown University in the United States under the IBM company completed the English-Russian machine translation experiment with IBM-701 computer, which opened the prelude of machine translation research.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 113, "end_pos": 132, "type": "TASK", "confidence": 0.6908033788204193}, {"text": "machine translation research", "start_pos": 195, "end_pos": 223, "type": "TASK", "confidence": 0.8659135301907858}]}, {"text": "During the period, there are three core technologies, rule-based machine translation, statistical machine translation( and neural machine translation(), which continue to develop.", "labels": [], "entities": [{"text": "rule-based machine translation", "start_pos": 54, "end_pos": 84, "type": "TASK", "confidence": 0.6052941977977753}, {"text": "statistical machine translation", "start_pos": 86, "end_pos": 117, "type": "TASK", "confidence": 0.7549524704615275}, {"text": "neural machine translation", "start_pos": 123, "end_pos": 149, "type": "TASK", "confidence": 0.6870366136233012}]}, {"text": "However, as the application fields of machine translation become more and more complex, the limitations of different technologies begin to appear.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 38, "end_pos": 57, "type": "TASK", "confidence": 0.763810932636261}]}, {"text": "Because of the more application scenarios and the higher requirements for accuracy, the problem of model optimization appeared.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 74, "end_pos": 82, "type": "METRIC", "confidence": 0.9984446167945862}, {"text": "model optimization", "start_pos": 99, "end_pos": 117, "type": "TASK", "confidence": 0.79072704911232}]}, {"text": "The translation between Russian and English is extremely difficult because their linguistic features are distinguished and the lexical composition and grammatical structure of Russian are more complicated than English.", "labels": [], "entities": [{"text": "translation", "start_pos": 4, "end_pos": 15, "type": "TASK", "confidence": 0.9792272448539734}]}, {"text": "Early statistical machine translations were hoped to be implemented through phrase-based methods(), including rule-based lexical, phrase analysis systems, and related techniques for language models and translation models.", "labels": [], "entities": [{"text": "statistical machine translations", "start_pos": 6, "end_pos": 38, "type": "TASK", "confidence": 0.6441082060337067}, {"text": "phrase analysis", "start_pos": 130, "end_pos": 145, "type": "TASK", "confidence": 0.6751057803630829}, {"text": "translation models", "start_pos": 202, "end_pos": 220, "type": "TASK", "confidence": 0.901220977306366}]}, {"text": "These methods have solved the translation problem between Russian and English to a certain extent.", "labels": [], "entities": [{"text": "translation", "start_pos": 30, "end_pos": 41, "type": "TASK", "confidence": 0.9827080368995667}]}, {"text": "However, at the same time, there is still a problem that the time cost is long and the translation result is not good enough.", "labels": [], "entities": [{"text": "translation", "start_pos": 87, "end_pos": 98, "type": "TASK", "confidence": 0.9497292637825012}]}, {"text": "Therefore, the emergence of neural machine translation has brought anew dawn for the translation between Russian and English.", "labels": [], "entities": [{"text": "neural machine translation", "start_pos": 28, "end_pos": 54, "type": "TASK", "confidence": 0.7251012523969015}, {"text": "translation between Russian and English", "start_pos": 85, "end_pos": 124, "type": "TASK", "confidence": 0.7987035870552063}]}, {"text": "The basic modeling framework for neural machine translation is an end-to-end sequence generation model, a framework and method for transforming input sequences into output sequences.", "labels": [], "entities": [{"text": "neural machine translation", "start_pos": 33, "end_pos": 59, "type": "TASK", "confidence": 0.6826771398385366}]}, {"text": "There are two points in the core part.", "labels": [], "entities": []}, {"text": "One is to represent the input sequence through the encoder, and the other is to obtain the output sequence through the decoder.", "labels": [], "entities": []}, {"text": "In addition, for machine translation, neural machine translation not only includes encoding and decoding, but also uses RNN() or other methods to encode sentence pairs.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 17, "end_pos": 36, "type": "TASK", "confidence": 0.8030861616134644}, {"text": "neural machine translation", "start_pos": 38, "end_pos": 64, "type": "TASK", "confidence": 0.7058182756106058}]}, {"text": "It also introduces an additional mechanism, the attention mechanism(, to help us to convert sequences.", "labels": [], "entities": []}, {"text": "The translation results thus obtained more expectations than before.", "labels": [], "entities": [{"text": "translation", "start_pos": 4, "end_pos": 15, "type": "TASK", "confidence": 0.9649161696434021}]}, {"text": "Later, Transformer appeared, which greatly enhances neural machine translation in terms of performance and effect.", "labels": [], "entities": [{"text": "neural machine translation", "start_pos": 52, "end_pos": 78, "type": "TASK", "confidence": 0.6458355387051901}]}, {"text": "This paper is based on Transformer, a neural machine translation network structure, to develop a two-way evaluation task between Russian and English.", "labels": [], "entities": []}, {"text": "Taking into account the language characteristics of Russian and English, we have done appropriate operations in data preprocessing, including removing duplicates, deleting unreasonable sentence pairs, lowercase and Latinization operations, and judging sentence alignment problems, removing the parallel corpus with problems.", "labels": [], "entities": [{"text": "judging sentence alignment", "start_pos": 244, "end_pos": 270, "type": "TASK", "confidence": 0.7459282477696737}]}, {"text": "The filtered parallel corpus is then sent to the model for training and the training results are tested.", "labels": [], "entities": []}, {"text": "After getting the trained model, we start to consider using the back-translation operation to augment the data, continuing to filter the generated artificial corpus, and put it into the model training together with the original parallel corpus.", "labels": [], "entities": []}, {"text": "Finally, ensemble), average and rerank) operations are implemented on different models to improve the overall performance of the translation system.", "labels": [], "entities": []}], "datasetContent": [{"text": "For this evaluation task, we start from the data preprocessing, through the data augmentation operation, get the parallel corpus that needs to be trained, input the Transformer model for training, and test the training results, and finally ensemble results according to the model generated by different strategies, average and rerank operations, for the best results.", "labels": [], "entities": []}, {"text": "Next, the experimental content will be elaborated separately.", "labels": [], "entities": []}, {"text": "The overall experimental process is shown in.", "labels": [], "entities": []}], "tableCaptions": []}