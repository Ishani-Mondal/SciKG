{"title": [{"text": "Self-Attention Architectures for Answer-Agnostic Neural Question Generation", "labels": [], "entities": [{"text": "Answer-Agnostic Neural Question Generation", "start_pos": 33, "end_pos": 75, "type": "TASK", "confidence": 0.8293638974428177}]}], "abstractContent": [{"text": "Neural architectures based on self-attention, such as Transformers, recently attracted interest from the research community, and obtained significant improvements over the state of the art in several tasks.", "labels": [], "entities": []}, {"text": "We explore how Transformers can be adapted to the task of Neu-ral Question Generation without constraining the model to focus on a specific answer passage.", "labels": [], "entities": [{"text": "Neu-ral Question Generation", "start_pos": 58, "end_pos": 85, "type": "TASK", "confidence": 0.7492666840553284}]}, {"text": "We study the effect of several strategies to deal with out-of-vocabulary words such as copy mechanisms, placeholders, and contex-tual word embeddings.", "labels": [], "entities": []}, {"text": "We report improvements obtained over the state-of-the-art on the SQuAD dataset according to automated metrics (BLEU, ROUGE), as well as qualitative human assessments of the system outputs.", "labels": [], "entities": [{"text": "SQuAD dataset", "start_pos": 65, "end_pos": 78, "type": "DATASET", "confidence": 0.8767990469932556}, {"text": "BLEU", "start_pos": 111, "end_pos": 115, "type": "METRIC", "confidence": 0.9954342246055603}, {"text": "ROUGE", "start_pos": 117, "end_pos": 122, "type": "METRIC", "confidence": 0.9787484407424927}]}], "introductionContent": [{"text": "The Machine Reading Comprehension (MRC) community focuses on the development of models and algorithms allowing machines to correctly represent the meaning imbued in natural sentences, in order to perform useful and valuable high-level downstream tasks such as providing answers to questions, generate summaries, and generate relevant questions given apiece of text.", "labels": [], "entities": [{"text": "Machine Reading Comprehension (MRC)", "start_pos": 4, "end_pos": 39, "type": "TASK", "confidence": 0.7767249743143717}]}, {"text": "Performance on those downstream tasks is indicative of the extent to which the different proposed architectures are able to capture meaning from natural language input.", "labels": [], "entities": []}, {"text": "Recently, neural architectures based on selfattention have obtained significant improvements over the state of the art in several tasks such as language modelling and machine translation, for which abundant data is available.", "labels": [], "entities": [{"text": "language modelling", "start_pos": 144, "end_pos": 162, "type": "TASK", "confidence": 0.7630337774753571}, {"text": "machine translation", "start_pos": 167, "end_pos": 186, "type": "TASK", "confidence": 0.805608481168747}]}, {"text": "Yet, they have not been thoroughly evaluated on problems for which relatively scarcer datasets are available.", "labels": [], "entities": []}, {"text": "We thus investigate the application of Transformers to the task of Neural Question Generation (NQG): given a text snippet, the model is called to generate relevant and meaningful questions about it.", "labels": [], "entities": [{"text": "Neural Question Generation (NQG)", "start_pos": 67, "end_pos": 99, "type": "TASK", "confidence": 0.7818455100059509}]}, {"text": "Question Generation (QG) is an active field of research within the context of machine reading.", "labels": [], "entities": [{"text": "Question Generation (QG)", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.8360125780105591}, {"text": "machine reading", "start_pos": 78, "end_pos": 93, "type": "TASK", "confidence": 0.826710969209671}]}, {"text": "it matches human behavior when assessing comprehension on a given topic: an expert is able to ask the relevant questions to others to assess their competences.", "labels": [], "entities": []}, {"text": "Its potential applications cover abroad range of scenarios, such as Information Retrieval, chat-bots, AI-supported learning technologies.", "labels": [], "entities": [{"text": "Information Retrieval", "start_pos": 68, "end_pos": 89, "type": "TASK", "confidence": 0.8194149434566498}]}, {"text": "Furthermore, it can be used as a strategy for data augmentation in the context of Question Answering systems.", "labels": [], "entities": [{"text": "data augmentation", "start_pos": 46, "end_pos": 63, "type": "TASK", "confidence": 0.7253766357898712}, {"text": "Question Answering", "start_pos": 82, "end_pos": 100, "type": "TASK", "confidence": 0.7607040405273438}]}, {"text": "The QG task has been originally tackled using rule-based systems (, with the research community turning to neural approaches in recent years.", "labels": [], "entities": [{"text": "QG task", "start_pos": 4, "end_pos": 11, "type": "TASK", "confidence": 0.7981650233268738}]}, {"text": "In its most popular declination, the task is answer-aware, i.e. the target answer within the source text is known and given as input to the QG model (.", "labels": [], "entities": []}, {"text": "Under this scenario, proposed a generative model, jointly trained for question generation and answering.", "labels": [], "entities": [{"text": "question generation", "start_pos": 70, "end_pos": 89, "type": "TASK", "confidence": 0.8303791582584381}]}, {"text": "More recently, obtained state-of-the-art results using a gated selfattention encoder and a maxout pointer decoder.", "labels": [], "entities": []}, {"text": "All these works employ the SQuAD () Question Answering dataset, thus directly leveraging the provided answer spans.", "labels": [], "entities": [{"text": "SQuAD () Question Answering dataset", "start_pos": 27, "end_pos": 62, "type": "DATASET", "confidence": 0.7183363556861877}]}, {"text": "Conversely, the answer-agnostic scenario lifts the constraint of knowing the target answers before generating the questions; proposed an end-to-end sequence to sequence approach, based on a RNN encoder-decoder architecture with a global attention mechanism.", "labels": [], "entities": []}, {"text": "While casting NQG as answer-aware is certainly relevant and useful (for instance, as a data-augmentation strategy for question answering data), the ability of generating questions without such constraint is very attractive.", "labels": [], "entities": [{"text": "question answering data", "start_pos": 118, "end_pos": 141, "type": "TASK", "confidence": 0.7981626391410828}]}, {"text": "Indeed, removing the dependency on an answer-selection component allows to reduce the bias towards named entities, thus increasing the model's degrees of freedom.", "labels": [], "entities": []}, {"text": "This makes the task more challenging, but potentially more useful for certain applications -e.g. those requiring a natural interaction with a final user.", "labels": [], "entities": []}, {"text": "In this work we follow the task as originally defined by: we avoid constraining the generation based on a specific answer, effectively operating in an end-to-end answer-agnostic scenario.", "labels": [], "entities": []}, {"text": "To adapt Transformers to the NQG task, we complement the base architecture with a copying mechanism, placeholders, and contextual word embeddings: those mechanisms are useful for the treatment of out-of-vocabulary words, which are more likely to affect performance in data-scarce tasks.", "labels": [], "entities": []}, {"text": "We study the effect of each of those mechanisms on architectures based on self-attention, reporting improvements over the state-of-the-art systems.", "labels": [], "entities": []}], "datasetContent": [{"text": "Ina preliminary experiment, we observed poor performances when applying a Vanilla Transformer architecture to the NQG task: we thus investigate how several mechanisms can be exploited within a Transformer architecture and how they affect the performances on the task.", "labels": [], "entities": []}, {"text": "In the following, we describe and evaluate the benefits of augmenting the base Transformer architecture with: \u2022 a copying mechanism; \u2022 a placeholding strategy; \u2022 and, contextualized word embeddings.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Comparison with SOTA; the last column reports the percentage of OOV/placeholders tokens propagated  correctly (according to the ground truth) from the source contexts to the generated questions. To assess model  stability, we independently trained 10 models with our best architecture, and computed the standard deviation of  their BLUE4 performances on the test set: std < 0.009.", "labels": [], "entities": [{"text": "BLUE4", "start_pos": 342, "end_pos": 347, "type": "METRIC", "confidence": 0.9522944092750549}]}, {"text": " Table 2: Human assessment: two-tailed t-test results are reported for our best method compared to Du et al. (2017)  ( *  : p < 0.05,  *  *  : p < 0.005).", "labels": [], "entities": []}]}