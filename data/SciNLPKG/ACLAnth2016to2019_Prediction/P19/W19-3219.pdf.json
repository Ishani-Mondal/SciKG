{"title": [{"text": "Give it a shot: Few-shot learning to normalize ADR mentions in Social Media posts", "labels": [], "entities": [{"text": "normalize ADR mentions in Social Media", "start_pos": 37, "end_pos": 75, "type": "TASK", "confidence": 0.7697214583555857}]}], "abstractContent": [{"text": "This paper describes the system that team MYTOMORROWS-TU DELFT developed for the 2019 Social Media Mining for Health Applications (SMM4H) Shared Task 3, for the end-to-end normalization of ADR tweet mentions to their corresponding MEDDRA codes.", "labels": [], "entities": [{"text": "DELFT", "start_pos": 57, "end_pos": 62, "type": "METRIC", "confidence": 0.8189863562583923}, {"text": "2019 Social Media Mining for Health Applications (SMM4H) Shared Task 3", "start_pos": 81, "end_pos": 151, "type": "TASK", "confidence": 0.7415055907689608}, {"text": "end-to-end normalization of ADR tweet mentions", "start_pos": 161, "end_pos": 207, "type": "TASK", "confidence": 0.6493985503911972}]}, {"text": "For the first two steps, we reuse a state-of-the-art approach, focusing our contribution on the final entity-linking step.", "labels": [], "entities": []}, {"text": "For that we propose a simple Few-Shot learning approach, based on pre-trained word embeddings and data from the UMLS, combined with the provided training data.", "labels": [], "entities": [{"text": "UMLS", "start_pos": 112, "end_pos": 116, "type": "DATASET", "confidence": 0.9481646418571472}]}, {"text": "Our system (relaxed F1: 0.337-0.345) outperforms the average (relaxed F1 0.2972) of the participants in this task, demonstrating the potential feasibility of few-shot learning in the context of medical text normal-ization.", "labels": [], "entities": [{"text": "F1", "start_pos": 20, "end_pos": 22, "type": "METRIC", "confidence": 0.908041775226593}, {"text": "F1 0.2972)", "start_pos": 70, "end_pos": 80, "type": "METRIC", "confidence": 0.911764919757843}]}], "introductionContent": [{"text": "Team MYTOMORROWS-TU DELFT participated in subtask 3 of the 2019 Social Media Mining for Health Applications (SMM4H)) workshop, which is an end-toend task.", "labels": [], "entities": [{"text": "DELFT", "start_pos": 20, "end_pos": 25, "type": "METRIC", "confidence": 0.7983234524726868}, {"text": "Social Media Mining for Health Applications (SMM4H)) workshop", "start_pos": 64, "end_pos": 125, "type": "TASK", "confidence": 0.770776778459549}]}, {"text": "The goal is, given a tweet, to 1) automatically classify tweets containing an adverse drug reaction mention; 2) extract the exact ADR mention; 3) normalize the extracted ADR to its corresponding Medical Dictionary for Regulatory Activities (MEDDRA) code.", "labels": [], "entities": [{"text": "Medical Dictionary for Regulatory Activities (MEDDRA) code", "start_pos": 195, "end_pos": 253, "type": "DATASET", "confidence": 0.6326219704416063}]}, {"text": "The task is evaluated based on strict and relaxed F-score, precision and recall.", "labels": [], "entities": [{"text": "F-score", "start_pos": 50, "end_pos": 57, "type": "METRIC", "confidence": 0.9987072944641113}, {"text": "precision", "start_pos": 59, "end_pos": 68, "type": "METRIC", "confidence": 0.9996756315231323}, {"text": "recall", "start_pos": 73, "end_pos": 79, "type": "METRIC", "confidence": 0.9988906979560852}]}, {"text": "From an NLP perspective, this task poses a significant challenge as there is a large gap between the informal language used in social media and the formal medical language.", "labels": [], "entities": []}, {"text": "Moreover, there is an absence of large annotated datasets, and datasets which are available often suffer from class imbalance.", "labels": [], "entities": []}, {"text": "Illustrating this, provides an overview of the number of samples per class in the SMM4H task 3 dataset.", "labels": [], "entities": [{"text": "SMM4H task 3 dataset", "start_pos": 82, "end_pos": 102, "type": "DATASET", "confidence": 0.868963286280632}]}, {"text": "Our end-to-end system consists of existing state-of-the-art for the first two steps.", "labels": [], "entities": []}, {"text": "We focus our efforts on the third -normalization-step, which we formulate as a Few-Shot Learning problem (FSL), following the definition by.", "labels": [], "entities": [{"text": "Few-Shot Learning problem (FSL)", "start_pos": 79, "end_pos": 110, "type": "TASK", "confidence": 0.4709566334883372}]}, {"text": "In the following sections, we describe (1) the datasets that we worked on, (2) our approach in more detail and finally (3) our results and conclusions.", "labels": [], "entities": []}], "datasetContent": [{"text": "With the three subtasks, three manually annotated datasets were provided.", "labels": [], "entities": []}, {"text": "All datasets contain tweets containing an ADR (positive) and without an ADR (negative).", "labels": [], "entities": [{"text": "ADR", "start_pos": 42, "end_pos": 45, "type": "METRIC", "confidence": 0.9785324931144714}, {"text": "ADR", "start_pos": 72, "end_pos": 75, "type": "METRIC", "confidence": 0.9740002155303955}]}, {"text": "A brief overview of these datasets is provided in, but for more context we refer to).", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Statistics of the training data used for task 1, 2  and 3", "labels": [], "entities": []}]}