{"title": [{"text": "Searching for Effective Neural Extractive Summarization: What Works and What's Next", "labels": [], "entities": [{"text": "Effective Neural Extractive Summarization", "start_pos": 14, "end_pos": 55, "type": "TASK", "confidence": 0.6962842345237732}]}], "abstractContent": [{"text": "The recent years have seen remarkable success in the use of deep neural networks on text summarization.", "labels": [], "entities": [{"text": "text summarization", "start_pos": 84, "end_pos": 102, "type": "TASK", "confidence": 0.8108562529087067}]}, {"text": "However, there is no clear understanding of why they perform so well, or how they might be improved.", "labels": [], "entities": []}, {"text": "In this paper, we seek to better understand how neural extractive summarization systems could benefit from different types of model architectures, transfer-able knowledge and learning schemas.", "labels": [], "entities": [{"text": "neural extractive summarization", "start_pos": 48, "end_pos": 79, "type": "TASK", "confidence": 0.7647670308748881}]}, {"text": "Additionally , we find an effective way to improve current frameworks and achieve the state-of-the-art result on CNN/DailyMail by a large margin based on our observations and analyses.", "labels": [], "entities": [{"text": "CNN/DailyMail", "start_pos": 113, "end_pos": 126, "type": "DATASET", "confidence": 0.9159575502077738}]}, {"text": "Hopefully, our work could provide more clues for future research on extractive sum-marization.", "labels": [], "entities": []}, {"text": "Source code will be available on Github 1 .", "labels": [], "entities": [{"text": "Github 1", "start_pos": 33, "end_pos": 41, "type": "DATASET", "confidence": 0.8724858462810516}]}], "introductionContent": [{"text": "Recent years has seen remarkable success in the use of deep neural networks for text summarization (.", "labels": [], "entities": [{"text": "text summarization", "start_pos": 80, "end_pos": 98, "type": "TASK", "confidence": 0.8332163989543915}]}, {"text": "So far, most research utilizing the neural network for text summarization has revolved around architecture engineering (.", "labels": [], "entities": [{"text": "text summarization", "start_pos": 55, "end_pos": 73, "type": "TASK", "confidence": 0.7691021859645844}]}, {"text": "Despite their success, it remains poorly understood why they perform well and what their shortcomings are, which limits our ability to design better architectures.", "labels": [], "entities": []}, {"text": "The rapid development of neural architectures calls fora detailed empirical study of analyzing and understanding existing models.", "labels": [], "entities": []}, {"text": "In this paper, we primarily focus on extractive summarization since they are computationally efficient, and can generate grammatically and coherent summaries (. and seek to * These two authors contributed equally.", "labels": [], "entities": [{"text": "extractive summarization", "start_pos": 37, "end_pos": 61, "type": "TASK", "confidence": 0.5980824530124664}]}, {"text": "1 https://github.com/fastnlp/fastNLP better understand how neural network-based approaches to this task could benefit from different types of model architectures, transferable knowledge, and learning schemas, and how they might be improved.", "labels": [], "entities": []}, {"text": "Architectures Architecturally, the better performance usually comes at the cost of our understanding of the system.", "labels": [], "entities": []}, {"text": "To date, we know little about the functionality of each neural component and the differences between them (, which raises the following typical questions: 1) How does the choice of different neural architectures (CNN, RNN, Transformer) influence the performance of the summarization system?", "labels": [], "entities": [{"text": "summarization", "start_pos": 269, "end_pos": 282, "type": "TASK", "confidence": 0.9734790325164795}]}, {"text": "2) Which part of components matters for specific dataset?", "labels": [], "entities": []}, {"text": "3) Do current models suffer from the over-engineering problem?", "labels": [], "entities": []}, {"text": "Understanding the above questions cannot only help us to choose suitable architectures in different application scenarios, but motivate us to move forward to more powerful frameworks.", "labels": [], "entities": []}, {"text": "External Transferable Knowledge and Learning schemas Clearly, the improvement inaccuracy and performance is not merely because of the shift from feature engineering to structure engineering, but the flexible ways to incorporate external knowledge ( and learning schemas to introduce extra instructive constraints (.", "labels": [], "entities": []}, {"text": "For this part, we make some first steps toward answers to the following questions: 1) Which type of pre-trained models (supervised or unsupervised pre-training) is more friendly to the summarization task?", "labels": [], "entities": [{"text": "summarization task", "start_pos": 185, "end_pos": 203, "type": "TASK", "confidence": 0.9292241930961609}]}, {"text": "2) When architectures are explored exhaustively, can we push the state-of-the-art results to anew level by introducing external transferable knowledge or changing another learning schema?", "labels": [], "entities": []}, {"text": "To make a comprehensive study of above an- To peer into the internal working mechanism of above testing cases, we provide sufficient evaluation scenarios in the testing environment.", "labels": [], "entities": []}, {"text": "Concretely, we present a multi-domain test, sentence shuffling test, and analyze models by different metrics: repetition, sentence length, and position bias, which we additionally developed to provide a better understanding of the characteristics of different datasets.", "labels": [], "entities": [{"text": "repetition", "start_pos": 110, "end_pos": 120, "type": "METRIC", "confidence": 0.9685770869255066}]}, {"text": "Empirically, our main observations are summarized as: 1) Architecturally speaking, models with autoregressive decoder are prone to achieving better performance against non auto-regressive decoder.", "labels": [], "entities": []}, {"text": "Besides, LSTM is more likely to suffer from the architecture overfitting problem while Transformer is more robust.", "labels": [], "entities": []}, {"text": "2) The success of extractive summarization system on the CNN/DailyMail corpus heavily relies on the ability to learn positional information of the sentence.", "labels": [], "entities": [{"text": "extractive summarization", "start_pos": 18, "end_pos": 42, "type": "TASK", "confidence": 0.6874354481697083}, {"text": "CNN/DailyMail corpus", "start_pos": 57, "end_pos": 77, "type": "DATASET", "confidence": 0.9398138076066971}]}, {"text": "3) Unsupervised transferable knowledge is more useful than supervised transferable knowl-edge since the latter one is easily influenced by the domain shift problem.", "labels": [], "entities": []}, {"text": "4) We find an effective way to improve the current system, and achieving the state-of-the-art result on CNN/DailyMail by a large margin with the help of unsupervised transferable knowledge (42.39 R-1 score).", "labels": [], "entities": [{"text": "CNN/DailyMail", "start_pos": 104, "end_pos": 117, "type": "DATASET", "confidence": 0.919087827205658}, {"text": "R-1", "start_pos": 196, "end_pos": 199, "type": "METRIC", "confidence": 0.8564227819442749}]}, {"text": "And this result can be further enhanced by introducing reinforcement learning (42.69 R-1 score).", "labels": [], "entities": [{"text": "R-1 score", "start_pos": 85, "end_pos": 94, "type": "METRIC", "confidence": 0.8701156079769135}]}, {"text": "Hopefully, this detailed empirical study can provide more hints for the follow-up researchers to design better architectures and explore new stateof-the-art results along aright direction.", "labels": [], "entities": []}], "datasetContent": [{"text": "where Count is used to count the number of ngrams and Uniq is used to eliminate n-gram duplication.", "labels": [], "entities": [{"text": "Count", "start_pos": 6, "end_pos": 11, "type": "METRIC", "confidence": 0.9916858077049255}]}, {"text": "The closer the word-based repetition score is to 1, the lower the repeatability of the words in summary.", "labels": [], "entities": [{"text": "repetition score", "start_pos": 26, "end_pos": 42, "type": "METRIC", "confidence": 0.9522843956947327}]}, {"text": "Positional Bias It is meaningful to study whether the ground truth distribution of the datasets is different and how it affects different architectures.", "labels": [], "entities": []}, {"text": "To achieve this we design a positional bias to describe the uniformity of ground truth distribution in different datasets, which can be calcu-lated as: We divide each article into k parts (we choose k = 30 because articles from CNN/DailyMail and NEWSROOM have 30 sentences by average) and p(i) denotes the probability that the first golden label is in part i of the articles.", "labels": [], "entities": [{"text": "CNN/DailyMail", "start_pos": 228, "end_pos": 241, "type": "DATASET", "confidence": 0.8422724008560181}]}, {"text": "Sentence Length Sentence length will affect different metrics to some extent.", "labels": [], "entities": []}, {"text": "We count the average length of the k-th sentence extracted from different decoders to explore whether the decoder could perceive the length information of sentences.", "labels": [], "entities": []}, {"text": "Sentence Shuffling We attempt to explore the impact of sentence position information on different structures.", "labels": [], "entities": [{"text": "Sentence Shuffling", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.8818227648735046}]}, {"text": "Therefore, we shuffle the orders of sentences and observe the robustness of different architectures to out-of-order sentences.", "labels": [], "entities": []}, {"text": "Instead of evaluating model solely on a single dataset, we care more about how our testing models perform on different types of data, which allows us to know if current models suffer from the over-engineering problem.", "labels": [], "entities": []}, {"text": "Next, we will show our findings and analyses in terms of architectures and external transferable knowledge.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Statistics of multi-domain datasets based on  CNN/DailyMail and NEWSROOM.", "labels": [], "entities": [{"text": "CNN/DailyMail", "start_pos": 56, "end_pos": 69, "type": "DATASET", "confidence": 0.9133726159731547}, {"text": "NEWSROOM", "start_pos": 74, "end_pos": 82, "type": "DATASET", "confidence": 0.7782410979270935}]}, {"text": " Table 3: Results of different architectures over different domains, where Enc. and Dec. represent document en- coder and decoder respectively. Lead means to extract the first k sentences as the summary, usually as a competitive  lower bound. Oracle represents the ground truth extracted by the greedy algorithm (", "labels": [], "entities": []}, {"text": " Table 4: Results of Transformer with SeqLab using  different proportions of sentence embedding and po- sitional embedding on CNN/DailyMail. The input of  Transformer is \u03b1  *  sentence embedding plus \u03b2  *  posi- tional embedding 6 . The bottom half of the table con- tains models that have similar performance with Trans- former that only know positional information.", "labels": [], "entities": [{"text": "CNN/DailyMail", "start_pos": 126, "end_pos": 139, "type": "DATASET", "confidence": 0.9410690863927206}]}, {"text": " Table 5: Results of different architectures with different pre-trained knowledge on CNN/DailyMail, where Enc.  and Dec. represent document encoder and decoder respectively.", "labels": [], "entities": [{"text": "CNN/DailyMail", "start_pos": 85, "end_pos": 98, "type": "DATASET", "confidence": 0.9097860256830851}]}, {"text": " Table 6: Evaluation on CNN/DailyMail. The top half  of the table is currently state-of-the-art models, and the  lower half is our models.", "labels": [], "entities": [{"text": "CNN/DailyMail", "start_pos": 24, "end_pos": 37, "type": "DATASET", "confidence": 0.8856172760327657}]}]}