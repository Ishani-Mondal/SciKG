{"title": [{"text": "Cross-Domain NER using Cross-Domain Language Modeling", "labels": [], "entities": [{"text": "Cross-Domain Language Modeling", "start_pos": 23, "end_pos": 53, "type": "TASK", "confidence": 0.5613238712151846}]}], "abstractContent": [{"text": "Due to limitation of labeled resources, cross-domain named entity recognition (NER) has been a challenging task.", "labels": [], "entities": [{"text": "cross-domain named entity recognition (NER)", "start_pos": 40, "end_pos": 83, "type": "TASK", "confidence": 0.7699287789208549}]}, {"text": "Most existing work considers a supervised setting, making use of labeled data for both the source and target domains.", "labels": [], "entities": []}, {"text": "A disadvantage of such methods is that they cannot train for domains without NER data.", "labels": [], "entities": []}, {"text": "To address this issue, we consider using cross-domain LM as abridge cross-domains for NER domain adaptation, performing cross-domain and cross-task knowledge transfer by designing a novel parameter generation network.", "labels": [], "entities": [{"text": "NER domain adaptation", "start_pos": 86, "end_pos": 107, "type": "TASK", "confidence": 0.9397006630897522}, {"text": "cross-task knowledge transfer", "start_pos": 137, "end_pos": 166, "type": "TASK", "confidence": 0.6331116656462351}]}, {"text": "Results show that our method can effectively extract domain differences from cross-domain LM contrast, allowing unsupervised domain adaptation while also giving state-of-the-art results among supervised domain adaptation methods.", "labels": [], "entities": [{"text": "domain adaptation", "start_pos": 125, "end_pos": 142, "type": "TASK", "confidence": 0.7725638151168823}]}], "introductionContent": [{"text": "Named entity recognition (NER) is a fundamental task in information extraction and text understanding.", "labels": [], "entities": [{"text": "Named entity recognition (NER)", "start_pos": 0, "end_pos": 30, "type": "TASK", "confidence": 0.8051876425743103}, {"text": "information extraction", "start_pos": 56, "end_pos": 78, "type": "TASK", "confidence": 0.7924349009990692}, {"text": "text understanding", "start_pos": 83, "end_pos": 101, "type": "TASK", "confidence": 0.8049371838569641}]}, {"text": "Due to large variations in entity names and flexibility in entity mentions, NER has been a challenging task in NLP.", "labels": [], "entities": [{"text": "NER", "start_pos": 76, "end_pos": 79, "type": "TASK", "confidence": 0.9784528613090515}]}, {"text": "Cross-domain NER adds to the difficulty of modeling due to the difference in text genre and entity names.", "labels": [], "entities": []}, {"text": "Existing methods make use of feature transfer) and parameters sharing ( for supervised NER domain adaptation.", "labels": [], "entities": [{"text": "feature transfer", "start_pos": 29, "end_pos": 45, "type": "TASK", "confidence": 0.7045018076896667}, {"text": "NER domain adaptation", "start_pos": 87, "end_pos": 108, "type": "TASK", "confidence": 0.8220867911974589}]}, {"text": "Language modeling (LM) has been shown useful for NER, both via multi-task learning and via pre-training (.", "labels": [], "entities": [{"text": "Language modeling (LM)", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.8119210004806519}, {"text": "NER", "start_pos": 49, "end_pos": 52, "type": "TASK", "confidence": 0.9826298952102661}]}, {"text": "Intuitively, both noun entities and context patterns can be captured during LM training, which benefits the recognition of named entities.", "labels": [], "entities": []}, {"text": "A natural question that arises is whether cross-domain * Work done when visiting Westlake University.", "labels": [], "entities": [{"text": "Westlake University", "start_pos": 81, "end_pos": 100, "type": "DATASET", "confidence": 0.9161648154258728}]}, {"text": "We are interested in transferring NER knowledge from the news domain to the target domain by contrasting large raw data in both domains through cross-domain LM training.", "labels": [], "entities": [{"text": "NER knowledge", "start_pos": 34, "end_pos": 47, "type": "TASK", "confidence": 0.8958858251571655}]}, {"text": "Naive multi-task learning by parameter sharing does notwork effectively in this multi-task, multi-domain setting due to potential conflict of information.", "labels": [], "entities": []}, {"text": "To achieve cross-domain information transfer as shown in the red arrow, two types of connections must be made: (1) cross-task links between NER and LM (for vertical transfer) and (2) cross-domain links (for horizontal transfer).", "labels": [], "entities": [{"text": "cross-domain information transfer", "start_pos": 11, "end_pos": 44, "type": "TASK", "confidence": 0.6163812577724457}]}, {"text": "We investigate a novel parameter generator network to this end, by decomposing the parameters \u03b8 of the NER or LM task on the source or target text domain into the combination \u03b8 = f (W, ID d , IT t ) of a set of meta parameters W, a task embedding vector IT t (t \u2208 {ner, lm}) and a domain embedding vector ID d, so that domain and task-correlations can be learned through similarities between the respective domain and task embedding vectors.", "labels": [], "entities": []}, {"text": "In, the values of W, {I T t }, {I D d } and the parameter generation network f (\u00b7, \u00b7, \u00b7) are all trained in a multi-task learning process optimizing NER and LM training objectives.", "labels": [], "entities": []}, {"text": "Through the process, connections between the sets of parameters \u03b8 src,ner , \u03b8 src,lm , \u03b8 tgt,ner and \u03b8 tgt,lm are decomposed into two dimensions and distilled into two task embedding vectors IT ner , IT lm and two domain embedding vectors ID src , ID tgt , respectively.", "labels": [], "entities": []}, {"text": "Compared with traditional multi-task learning, our method has a modular control over cross-domain and cross-task knowledge transfer.", "labels": [], "entities": [{"text": "cross-task knowledge transfer", "start_pos": 102, "end_pos": 131, "type": "TASK", "confidence": 0.6159196098645529}]}, {"text": "In addition, the four embedding vectors IT ner , IT lm , ID src and ID tgt can also be trained by optimizing on only three datasets for \u03b8 src,ner , \u03b8 src,lm and \u03b8 tgt,lm , therefore achieving zero-shot NER learning on the target domain by deriving \u03b8 tgt,ner automatically.", "labels": [], "entities": [{"text": "NER learning", "start_pos": 202, "end_pos": 214, "type": "TASK", "confidence": 0.9100946187973022}]}, {"text": "Results on three different cross-domain datasets show that our method outperforms naive multitask learning and a wide range of domain adaptation methods.", "labels": [], "entities": []}, {"text": "To our knowledge, we are the first to consider unsupervised domain adaptation for NER via cross-domain LM tasks and the first to work on NER transfer learning between domains with completely different entity types (i.e. news vs. biomedical).", "labels": [], "entities": [{"text": "domain adaptation", "start_pos": 60, "end_pos": 77, "type": "TASK", "confidence": 0.7945377230644226}, {"text": "NER", "start_pos": 82, "end_pos": 85, "type": "TASK", "confidence": 0.9307880401611328}, {"text": "NER transfer learning", "start_pos": 137, "end_pos": 158, "type": "TASK", "confidence": 0.944623331228892}]}, {"text": "We released our data and code at https://github.com/ jiachenwestlake/Cross-Domain_NER.", "labels": [], "entities": []}, {"text": "extend the model by using character CNN.", "labels": [], "entities": []}, {"text": "Most recent work uses LSTM-CRF (.", "labels": [], "entities": []}, {"text": "We choose BiLSTM-CRF as our method since it gives stateof-the-art resutls on standard benchmarks.", "labels": [], "entities": []}, {"text": "Most existing work on cross-domain NER investigates the supervised setting, where both source and target domains have labeled data.", "labels": [], "entities": [{"text": "cross-domain NER", "start_pos": 22, "end_pos": 38, "type": "TASK", "confidence": 0.6031834483146667}]}, {"text": "Daum\u00e9 III (2009) maps entity label space between the source and target domains. and use label embeddings instead of entities themselves as the features for cross-domain transfer.", "labels": [], "entities": [{"text": "cross-domain transfer", "start_pos": 156, "end_pos": 177, "type": "TASK", "confidence": 0.7540047764778137}]}, {"text": "perform label-aware feature representation transfer based on text representation learned by BiLSTM networks.", "labels": [], "entities": [{"text": "label-aware feature representation transfer", "start_pos": 8, "end_pos": 51, "type": "TASK", "confidence": 0.6637560874223709}]}, {"text": "Recently, parameters transfer approaches have seen increasing popularity for cross-domain NER.", "labels": [], "entities": [{"text": "parameters transfer", "start_pos": 10, "end_pos": 29, "type": "TASK", "confidence": 0.7247402518987656}, {"text": "NER", "start_pos": 90, "end_pos": 93, "type": "TASK", "confidence": 0.6863109469413757}]}, {"text": "Such approaches first initialize a target model with parameters learned from source-domain NER () or LM ( , and then fine-tune the model using labeled NER data from the target domain.", "labels": [], "entities": []}, {"text": "jointly train source-and target-domain models with shared parameters, add adaptation layers on top of existing networks.", "labels": [], "entities": []}, {"text": "Except for , all the above methods use crossdomain NER data only.", "labels": [], "entities": []}, {"text": "In contrast, we leverage both NER data and raw data for both domains.", "labels": [], "entities": []}, {"text": "In addition, our method can deal with a zero-shot learning setting for unsupervised NER domain adaptation, which no existing work considers.", "labels": [], "entities": [{"text": "NER domain adaptation", "start_pos": 84, "end_pos": 105, "type": "TASK", "confidence": 0.797217865784963}]}, {"text": "There has been related work using task vector representations for multi-task learning.", "labels": [], "entities": []}, {"text": "learn language embeddings for multi-lingual parsing.", "labels": [], "entities": [{"text": "multi-lingual parsing", "start_pos": 30, "end_pos": 51, "type": "TASK", "confidence": 0.6645634174346924}]}, {"text": "learn treebank embeddings for cross-annotation-style parsing.", "labels": [], "entities": [{"text": "cross-annotation-style parsing", "start_pos": 30, "end_pos": 60, "type": "TASK", "confidence": 0.6758477091789246}]}, {"text": "These methods use \"task\" embeddings to augment word embedding inputs, distilling \"task\" characteristics into these vectors for preserving word embeddings.", "labels": [], "entities": []}, {"text": "learn domain embeddings for multi-domain sentiment classification.", "labels": [], "entities": [{"text": "multi-domain sentiment classification", "start_pos": 28, "end_pos": 65, "type": "TASK", "confidence": 0.7290762066841125}]}, {"text": "They combine domain vectors with domainindependent representation of the input sentences to obtain a domain-specific input representation.", "labels": [], "entities": []}, {"text": "A salient difference between our work and the methods above is that we use domain and task embeddings to obtain domain and task-specific parameters, rather than input representations.", "labels": [], "entities": []}, {"text": "Closer in spirit to our work, learn language vectors, using them to generate parameters for multi-lingual machine translation.", "labels": [], "entities": [{"text": "multi-lingual machine translation", "start_pos": 92, "end_pos": 125, "type": "TASK", "confidence": 0.6310164133707682}]}, {"text": "While one of their main motivation is to save the parameter space when the number of langauges grows, our main goal is to investigate the modularization of transferable knowledge in a cross-domain and cross-task setting.", "labels": [], "entities": []}, {"text": "To our knowledge, we are the first to study \"task\" embeddings in a multi-dimensional parameter decomposition setting (e.g. domain + task).", "labels": [], "entities": []}], "datasetContent": [{"text": ", the sentence-level negative loglikehood loss is used for training: Language modeling.", "labels": [], "entities": [{"text": "Language modeling", "start_pos": 69, "end_pos": 86, "type": "TASK", "confidence": 0.745599091053009}]}, {"text": "Given a raw data set D lm = {(x n )} N n=1 , LM f and LM bare trained jointly using Negative Sampling Softmax.", "labels": [], "entities": []}, {"text": "Negative samples are drawn based on word frequency distribution in D lm . The loss function is: Joint training.", "labels": [], "entities": []}, {"text": "To perform joint training for NER and language modeling on both the source and target domains, we minimize the overall loss: where \u03bb dis a domain weight and \u03bb t is a task weight.", "labels": [], "entities": [{"text": "NER", "start_pos": 30, "end_pos": 33, "type": "TASK", "confidence": 0.9640465974807739}, {"text": "language modeling", "start_pos": 38, "end_pos": 55, "type": "TASK", "confidence": 0.6499641388654709}]}, {"text": "\u03bb is the L 2 regularization parameters and \u0398 represents the parameters set.", "labels": [], "entities": []}, {"text": "if do supervised learning then  Data.", "labels": [], "entities": []}, {"text": "We take the CoNLL-2003 English NER data ( as our sourcedomain data.", "labels": [], "entities": [{"text": "CoNLL-2003 English NER data", "start_pos": 12, "end_pos": 39, "type": "DATASET", "confidence": 0.9126130640506744}]}, {"text": "In addition, 377,592 sentences from the Reuters are used for source-domain LM training in unsupervised domain adaptation.", "labels": [], "entities": [{"text": "Reuters", "start_pos": 40, "end_pos": 47, "type": "DATASET", "confidence": 0.8779060244560242}, {"text": "unsupervised domain adaptation", "start_pos": 90, "end_pos": 120, "type": "TASK", "confidence": 0.739385724067688}]}, {"text": "Three sets of target-domain data are used, including two publicly available biomedical NER datasets, BioNLP13PC (13PC) and BioNLP13CG (13CG) and a science and technology dataset we collected and labeled.", "labels": [], "entities": []}, {"text": "Statistics of the datasets are shown in.", "labels": [], "entities": []}, {"text": "CoNLL For the science and technology dataset, we collect 620 articles from CBS SciTech News 3 , manually labeling them as a test set for unsupervised domain adaptation.", "labels": [], "entities": [{"text": "CoNLL", "start_pos": 0, "end_pos": 5, "type": "DATASET", "confidence": 0.9253302216529846}, {"text": "science and technology dataset", "start_pos": 14, "end_pos": 44, "type": "DATASET", "confidence": 0.5991568565368652}, {"text": "CBS SciTech News 3", "start_pos": 75, "end_pos": 93, "type": "DATASET", "confidence": 0.9546860903501511}, {"text": "unsupervised domain adaptation", "start_pos": 137, "end_pos": 167, "type": "TASK", "confidence": 0.7731296817461649}]}, {"text": "It consists of four types of entities following the CoNLL-2003 standard.", "labels": [], "entities": [{"text": "CoNLL-2003 standard", "start_pos": 52, "end_pos": 71, "type": "DATASET", "confidence": 0.9384101033210754}]}, {"text": "The numbers of each entity type are comparable to the CoNLL test set, as listed in   gle Task Model (STM-TARGET) for the strongest baseline according to development experiments, while the multi-task models use SGD with a learning rate of 0.015 as ( . We use domain embeddings and task embeddings of size 8 to fit the model in one GPU of 8GB memory.", "labels": [], "entities": [{"text": "CoNLL test set", "start_pos": 54, "end_pos": 68, "type": "DATASET", "confidence": 0.9004877408345541}]}, {"text": "The word embeddings for all models are initialized with GloVe 100-dimension vectors (Pennington et al., 2014) and fine-tuned during training.", "labels": [], "entities": []}, {"text": "Character embeddings are randomly initialized.", "labels": [], "entities": []}, {"text": "We report a set of development experiments on the biomedical datasets 13PC and 13CG.", "labels": [], "entities": [{"text": "biomedical datasets 13PC", "start_pos": 50, "end_pos": 74, "type": "DATASET", "confidence": 0.7660003900527954}]}, {"text": "shows the F1-scores against the number of training iterations on the 13CG development set.", "labels": [], "entities": [{"text": "F1-scores", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9955974221229553}, {"text": "13CG development set", "start_pos": 69, "end_pos": 89, "type": "DATASET", "confidence": 0.9653924504915873}]}, {"text": "STM-TARGET is our single task model trained on the target-domain training set T ner ; FINETUNE is a model pre-trained using the source-domain training data S ner and then fine-tuned using the target-domain data T ner ; MULTITASK simultaneously trains source-domain NER and target-domain NER following.", "labels": [], "entities": [{"text": "FINETUNE", "start_pos": 86, "end_pos": 94, "type": "METRIC", "confidence": 0.991470992565155}, {"text": "MULTITASK", "start_pos": 219, "end_pos": 228, "type": "DATASET", "confidence": 0.5401045680046082}]}, {"text": "For STM+ELMO, we mix the source-and target-domain raw data for training a contextualized ELMo representation (, which is then used as inputs to an STM-TARGET model.", "labels": [], "entities": [{"text": "STM+ELMO", "start_pos": 4, "end_pos": 12, "type": "TASK", "confidence": 0.8723566134770712}]}, {"text": "This model shows a different way of transfer by using raw data, which is different from FINETUNE and MULTITASK.", "labels": [], "entities": [{"text": "FINETUNE", "start_pos": 88, "end_pos": 96, "type": "METRIC", "confidence": 0.6736894845962524}, {"text": "MULTITASK", "start_pos": 101, "end_pos": 110, "type": "DATASET", "confidence": 0.7369109392166138}]}, {"text": "Note that due to differences in the label sets, FINETUNE and MUL-TITASK both share parameters between the two models except for the CRF layers.", "labels": [], "entities": [{"text": "FINETUNE", "start_pos": 48, "end_pos": 56, "type": "METRIC", "confidence": 0.9299780130386353}, {"text": "MUL-TITASK", "start_pos": 61, "end_pos": 71, "type": "DATASET", "confidence": 0.5202348828315735}]}, {"text": "As can be seen from, the F1 of all models increase as the number of training iteration increases from 1 to 50, with only small fluctuations.", "labels": [], "entities": [{"text": "F1", "start_pos": 25, "end_pos": 27, "type": "METRIC", "confidence": 0.9995842576026917}]}, {"text": "All of the models converge to a plateau range when the iteration number increases to 100.", "labels": [], "entities": []}, {"text": "All transfer learning methods outperform the STM-TARGET method, showing the usefulness of using source data to enhance target labeling.", "labels": [], "entities": [{"text": "STM-TARGET", "start_pos": 45, "end_pos": 55, "type": "TASK", "confidence": 0.8740840554237366}]}, {"text": "The strong performance of STM+ELMO over FINE-TUNE and MULTITASK shows the usefulness of raw text.", "labels": [], "entities": [{"text": "STM+ELMO", "start_pos": 26, "end_pos": 34, "type": "TASK", "confidence": 0.5727119743824005}, {"text": "FINE-TUNE", "start_pos": 40, "end_pos": 49, "type": "DATASET", "confidence": 0.7897813320159912}, {"text": "MULTITASK", "start_pos": 54, "end_pos": 63, "type": "METRIC", "confidence": 0.7291955947875977}]}, {"text": "By simultaneously using source-domain raw text and target-domain raw text, our model gives the best F1 overall iterations.", "labels": [], "entities": []}, {"text": "Effect of language model for transfer.", "labels": [], "entities": []}, {"text": "shows the results of source language modeling, target language modeling, source NER and target NER for both development datasets when the number of training iterations increases.", "labels": [], "entities": [{"text": "target language modeling", "start_pos": 47, "end_pos": 71, "type": "TASK", "confidence": 0.612129400173823}]}, {"text": "As can be seen, multi-task learning under our framework brings benefit to all tasks, without being negatively influenced by potential conflicts between tasks (", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Entity numbers of the CoNLL dataset and the  CBS SciTech News dataset.", "labels": [], "entities": [{"text": "CoNLL dataset", "start_pos": 32, "end_pos": 45, "type": "DATASET", "confidence": 0.9746534824371338}, {"text": "CBS SciTech News dataset", "start_pos": 55, "end_pos": 79, "type": "DATASET", "confidence": 0.9712725281715393}]}, {"text": " Table 3: F1-scores on 13PC and 13CG.  \u2020 indicates that  the FINAL results are statistically significant compared  to all transfer baselines and ablation baselines with p <  0.01 by t-test.", "labels": [], "entities": [{"text": "F1-scores", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9990528225898743}, {"text": "13CG", "start_pos": 32, "end_pos": 36, "type": "DATASET", "confidence": 0.7760811448097229}, {"text": "FINAL", "start_pos": 61, "end_pos": 66, "type": "METRIC", "confidence": 0.9984424710273743}]}, {"text": " Table 4: Three metrics on CBS SciTech News. We  use the CoNLL dev set to select the hyperparameters of  our models. ELMo and Ours are given the same over- all raw data, SELF-TRAIN and DANN use the selected  raw data from overall raw data for better performances.   \u2020 indicates that our results are statistically significant  compared to all baselines with p < 0.01 by t-test.", "labels": [], "entities": [{"text": "CBS SciTech News", "start_pos": 27, "end_pos": 43, "type": "DATASET", "confidence": 0.9655022025108337}, {"text": "CoNLL dev set", "start_pos": 57, "end_pos": 70, "type": "DATASET", "confidence": 0.827876607577006}, {"text": "SELF-TRAIN", "start_pos": 170, "end_pos": 180, "type": "METRIC", "confidence": 0.9877759218215942}]}, {"text": " Table 5: Growth rate of correctly recognized enetity  number in comparison with the STM-SOURCE. \u2206 rep- resents the growth with respect to the total number of  entities in the CBS SciTech News test set.", "labels": [], "entities": [{"text": "Growth rate", "start_pos": 10, "end_pos": 21, "type": "METRIC", "confidence": 0.9658266305923462}, {"text": "\u2206 rep- resents", "start_pos": 97, "end_pos": 111, "type": "METRIC", "confidence": 0.8209968507289886}, {"text": "CBS SciTech News test set", "start_pos": 176, "end_pos": 201, "type": "DATASET", "confidence": 0.9661554574966431}]}]}