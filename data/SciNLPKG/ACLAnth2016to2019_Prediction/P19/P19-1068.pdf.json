{"title": [{"text": "MOROCO: The Moldavian and Romanian Dialectal Corpus", "labels": [], "entities": [{"text": "MOROCO", "start_pos": 0, "end_pos": 6, "type": "METRIC", "confidence": 0.6458381414413452}]}], "abstractContent": [{"text": "In this work, we introduce the Moldavian and Romanian Dialectal Corpus (MOROCO), which is freely available for download at https://github.com/butnaruandrei/MOROCO.", "labels": [], "entities": [{"text": "Moldavian and Romanian Dialectal Corpus (MOROCO)", "start_pos": 31, "end_pos": 79, "type": "DATASET", "confidence": 0.6452895924448967}]}, {"text": "The corpus contains 33564 samples of text (with over 10 million tokens) collected from the news domain.", "labels": [], "entities": []}, {"text": "The samples belong to one of the following six topics: culture, finance, politics, science, sports and tech.", "labels": [], "entities": []}, {"text": "The data set is divided into 21719 samples for training, 5921 samples for validation and another 5924 samples for testing.", "labels": [], "entities": []}, {"text": "For each sample, we provide corresponding dialectal and category labels.", "labels": [], "entities": []}, {"text": "This allows us to perform empirical studies on several classification tasks such as (i) binary discrimination of Moldavian versus Romanian text samples, (ii) intra-dialect multi-class categorization by topic and (iii) cross-dialect multi-class categorization by topic.", "labels": [], "entities": [{"text": "binary discrimination of Moldavian versus Romanian text samples", "start_pos": 88, "end_pos": 151, "type": "TASK", "confidence": 0.730154812335968}]}, {"text": "We perform experiments using a shallow approach based on string kernels, as well as a novel deep approach based on character-level convolutional neural networks containing Squeeze-and-Excitation blocks.", "labels": [], "entities": []}, {"text": "We also present and analyze the most discrim-inative features of our best performing model, before and after named entity removal.", "labels": [], "entities": []}], "introductionContent": [{"text": "The high number of evaluation campaigns on spoken or written dialect identification conducted in recent years ( prove that dialect identification is an interesting and challenging natural language processing (NLP) task, actively studied by researchers in nowadays.", "labels": [], "entities": [{"text": "spoken or written dialect identification", "start_pos": 43, "end_pos": 83, "type": "TASK", "confidence": 0.7963654398918152}, {"text": "dialect identification", "start_pos": 123, "end_pos": 145, "type": "TASK", "confidence": 0.7456688582897186}, {"text": "natural language processing (NLP) task", "start_pos": 180, "end_pos": 218, "type": "TASK", "confidence": 0.7413756591933114}]}, {"text": "Due to the recent interest in dialect identification, we introduce the Moldavian and Romanian Dialectal Corpus (MOROCO), which is composed of 33564 samples of text collected from the news domain.", "labels": [], "entities": [{"text": "dialect identification", "start_pos": 30, "end_pos": 52, "type": "TASK", "confidence": 0.7639989852905273}, {"text": "Moldavian and Romanian Dialectal Corpus (MOROCO)", "start_pos": 71, "end_pos": 119, "type": "DATASET", "confidence": 0.6888797245919704}]}, {"text": "Romanian is part of the Balkan-Romance group that evolved from several dialects of Vulgar Latin, which separated from the Western Romance branch of languages from the fifth century (.", "labels": [], "entities": []}, {"text": "In order to distinguish Romanian within the Balkan-Romance group in comparative linguistics, it is referred to as Daco-Romanian.", "labels": [], "entities": []}, {"text": "Along with Daco-Romanian, which is currently spoken in Romania, there are three other dialects in the Balkan-Romance branch, namely Aromanian, Istro-Romanian, and Megleno-Romanian.", "labels": [], "entities": []}, {"text": "Moldavian is a subdialect of Daco-Romanian, that is spoken in the Republic of Moldova and in northeastern Romania.", "labels": [], "entities": []}, {"text": "The delimitation of the Moldavian dialect, as with all other Romanian dialects, is made primarily by analyzing its phonetic features and only marginally by morphological, syntactical, and lexical characteristics.", "labels": [], "entities": []}, {"text": "Although the spoken dialects in Romania and the Republic of Moldova are different, the two countries share the same literary standard).", "labels": [], "entities": []}, {"text": "Some linguists consider that the border between Romania and the Republic of Moldova (see) does not correspond to any significant isoglosses to justify a dialectal division.", "labels": [], "entities": []}, {"text": "One question that arises in this context is whether we can train a machine to accurately distinguish literary text samples written by people in Romania from literary text samples written by people in the Republic of Moldova.", "labels": [], "entities": [{"text": "accurately distinguish literary text samples written by people in Romania from literary text samples written by people in the Republic of Moldova", "start_pos": 78, "end_pos": 223, "type": "TASK", "confidence": 0.6948868049816652}]}, {"text": "If we can construct such a machine, then what are the discriminative features employed by this machine?", "labels": [], "entities": []}, {"text": "Our corpus formed of text samples collected from Romanian and Moldavian news websites, enables us to answer these questions.", "labels": [], "entities": []}, {"text": "Furthermore, MOROCO provides a benchmark for the evaluation of dialect identification methods.", "labels": [], "entities": [{"text": "MOROCO", "start_pos": 13, "end_pos": 19, "type": "DATASET", "confidence": 0.5320680141448975}, {"text": "dialect identification", "start_pos": 63, "end_pos": 85, "type": "TASK", "confidence": 0.7120939195156097}]}, {"text": "To this end, we consider two state-of-the-art methods, string kernels () and character-level convolutional neural networks (CNNs), which obtained the first two places) in the Arabic Dialect Identification Shared Task of the 2018 VarDial Evaluation Campaign ().", "labels": [], "entities": []}, {"text": "We also experiment with a novel CNN architecture inspired the recently introduced Squeeze-and-Excitation (SE) networks (, which exhibit state-of-the-art performance in object recognition from images.", "labels": [], "entities": [{"text": "object recognition from images", "start_pos": 168, "end_pos": 198, "type": "TASK", "confidence": 0.803416945040226}]}, {"text": "To our knowledge, we are the first to introduce Squeeze-andExcitation networks in the text domain.", "labels": [], "entities": []}, {"text": "As we provide category labels for the collected text samples, we can perform additional experiments on various text categorization by topic tasks.", "labels": [], "entities": []}, {"text": "One type of task is intra-dialect multi-class categorization by topic, i.e. the task is to classify the samples written either in the Moldavian dialect or in the Romanian dialect into one of the following six topics: culture, finance, politics, science, sports and tech.", "labels": [], "entities": []}, {"text": "Another type of task is cross-dialect multi-class categorization by topic, i.e. the task is to classify the samples written in one dialect, e.g. Romanian, into six topics, using a model trained on samples written in the other dialect, e.g. Moldavian.", "labels": [], "entities": []}, {"text": "These experiments are aimed at showing if the considered text categorization methods are robust to the dialect shift between training and testing.", "labels": [], "entities": []}, {"text": "In summary, our contribution is threefold: \u2022 We introduce a novel large corpus containing 33564 text samples written in the Moldavian and the Romanian dialects.", "labels": [], "entities": []}, {"text": "\u2022 We introduce Squeeze-and-Excitation networks to the text domain.", "labels": [], "entities": []}, {"text": "\u2022 We analyze the discriminative features that help the best performing method, string kernels, in (i) distinguishing the Moldavian and the Romanian dialects and in (ii) categorizing the text samples by topic.", "labels": [], "entities": []}, {"text": "We organize the remainder of this paper as follows.", "labels": [], "entities": []}, {"text": "We discuss related work in Section 2.", "labels": [], "entities": []}, {"text": "We describe the MOROCO data set in Section 3.", "labels": [], "entities": [{"text": "MOROCO data set", "start_pos": 16, "end_pos": 31, "type": "DATASET", "confidence": 0.8009417752424876}]}, {"text": "We present the chosen classification methods in Section 4.", "labels": [], "entities": []}, {"text": "We show empirical results in Section 5, and we provide a discussion on the discriminative features in Section 6.", "labels": [], "entities": []}, {"text": "Finally, we draw our conclusion in Section 7.", "labels": [], "entities": []}], "datasetContent": [{"text": "In order to tune the parameters of each model, we used the MOROCO validation set.", "labels": [], "entities": [{"text": "MOROCO validation set", "start_pos": 59, "end_pos": 80, "type": "DATASET", "confidence": 0.7524629831314087}]}, {"text": "We first carried out a set of preliminary dialect classification experiments to determine the optimal choice of n-grams length for the presence bits string kernel and the regularization parameter \u03bb of the KRR classifier.", "labels": [], "entities": [{"text": "dialect classification", "start_pos": 42, "end_pos": 64, "type": "TASK", "confidence": 0.7551353871822357}]}, {"text": "We present results for these preliminary experiments in.", "labels": [], "entities": []}, {"text": "We notice that both \u03bb = 10 \u22124 and \u03bb = 10 \u22125 are good regularization choices, with \u03bb = 10 \u22125 being slightly better for all n-grams lengths between 5 and 8.", "labels": [], "entities": []}, {"text": "Although 6-grams, 7-grams and 8-grams attain almost equally good results, the best choice according to the validation results is to use 6-grams.", "labels": [], "entities": []}, {"text": "Therefore, in the subsequent experiments, we employ the presence bits string kernel based on n-grams of length 6 and KRR with \u03bb = 10 \u22125 . For the baseline CNN, we set the learning rate to 5 \u00b7 10 \u22124 and use mini-batches of 128 samples during training.", "labels": [], "entities": [{"text": "KRR", "start_pos": 117, "end_pos": 120, "type": "METRIC", "confidence": 0.945722222328186}]}, {"text": "We use the same parameters for the SE network.", "labels": [], "entities": [{"text": "SE network", "start_pos": 35, "end_pos": 45, "type": "DATASET", "confidence": 0.8306150436401367}]}, {"text": "Both deep networks are trained for 50 epochs.", "labels": [], "entities": []}, {"text": "For the SE blocks, we set the reduction ratio tor = 64, which results in a bottleneck layer with two neurons.", "labels": [], "entities": [{"text": "reduction ratio tor", "start_pos": 30, "end_pos": 49, "type": "METRIC", "confidence": 0.9488630294799805}]}, {"text": "We also tried lower reduction ratios, e.g. 32 and 16, but we obtained lower performance for these values.", "labels": [], "entities": [{"text": "reduction", "start_pos": 20, "end_pos": 29, "type": "METRIC", "confidence": 0.9628255367279053}]}, {"text": "In we present the accuracy, the weighted F 1 -scores and the macro-averaged F 1 -scores obtained by the three classification models (string kernels, CNN and SE networks) for all the classification tasks, on the validation set as well as the test set.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 18, "end_pos": 26, "type": "METRIC", "confidence": 0.9994081258773804}, {"text": "F 1 -scores", "start_pos": 41, "end_pos": 52, "type": "METRIC", "confidence": 0.945384219288826}, {"text": "F 1 -scores", "start_pos": 76, "end_pos": 87, "type": "METRIC", "confidence": 0.9156568646430969}]}, {"text": "Regarding the binary classification by dialect task, we notice that all models attain good results, above 90%.", "labels": [], "entities": []}, {"text": "SE blocks bring only minor improvements over the baseline CNN.", "labels": [], "entities": []}, {"text": "Our deep models, CNN and CNN+SE, attain results around 93%, while the string kernels obtain results above 94%.", "labels": [], "entities": [{"text": "CNN", "start_pos": 17, "end_pos": 20, "type": "DATASET", "confidence": 0.9188900589942932}, {"text": "SE", "start_pos": 29, "end_pos": 31, "type": "METRIC", "confidence": 0.4612577557563782}]}, {"text": "We thus conclude that written text samples from the Moldavian and the Romanian dialects can be accurately discriminated by both shallow and deep learning models.", "labels": [], "entities": []}, {"text": "This answers our first question from Section 1.", "labels": [], "entities": []}, {"text": "Regarding the Moldavian intra-dialect 6-way categorization (by topic) task, we notice that string kernels perform quite well in comparison with the CNN and the CNN+SE models.", "labels": [], "entities": [{"text": "CNN", "start_pos": 148, "end_pos": 151, "type": "DATASET", "confidence": 0.9217299222946167}]}, {"text": "In terms of the macro-averaged F 1 scores, SE blocks bring improvements higher than 1% over the baseline CNN.", "labels": [], "entities": [{"text": "F 1 scores", "start_pos": 31, "end_pos": 41, "type": "METRIC", "confidence": 0.8972075581550598}, {"text": "SE", "start_pos": 43, "end_pos": 45, "type": "METRIC", "confidence": 0.9241061806678772}, {"text": "CNN", "start_pos": 105, "end_pos": 108, "type": "METRIC", "confidence": 0.8757408857345581}]}, {"text": "In the MD\u2192RO cross-dialect 6-way categorization task, our models attain the lowest performance on the Romanian test set.", "labels": [], "entities": [{"text": "Romanian test set", "start_pos": 102, "end_pos": 119, "type": "DATASET", "confidence": 0.9425152142842611}]}, {"text": "We would like to note that in both cross-dialect settings, we use the validation set from the same dialect as the training set, in order to prevent any use of information about the test dialect during training.", "labels": [], "entities": []}, {"text": "In other words, the settings are intra-dialect with re-   spect to the validation set and cross-dialect with respect to the test set.", "labels": [], "entities": []}, {"text": "The Romanian intra-dialect 6-way categorization task seems to be much more difficult than the Moldavian intra-dialect categorization task, since all models obtain scores that are roughly 20% lower.", "labels": [], "entities": []}, {"text": "In terms of the macroaveraged F 1 scores, SE blocks bring improvements of around 4% over the baseline CNN.", "labels": [], "entities": [{"text": "F 1 scores", "start_pos": 30, "end_pos": 40, "type": "METRIC", "confidence": 0.8489348689715067}, {"text": "SE", "start_pos": 42, "end_pos": 44, "type": "METRIC", "confidence": 0.973922848701477}, {"text": "CNN", "start_pos": 102, "end_pos": 105, "type": "METRIC", "confidence": 0.8915360569953918}]}, {"text": "However, the results of CNN+SE are still much under those of the presence bits string kernel.", "labels": [], "entities": [{"text": "CNN+", "start_pos": 24, "end_pos": 28, "type": "DATASET", "confidence": 0.6647455394268036}, {"text": "SE", "start_pos": 28, "end_pos": 30, "type": "METRIC", "confidence": 0.3158149719238281}]}, {"text": "Regarding the RO\u2192MD cross-dialect 6-way categorization task, we find that the models learned on the Romanian training set obtain better results on the Moldavian (cross-dialect) test set than on the Romanian (intra-dialect) test set.", "labels": [], "entities": []}, {"text": "Once again, this provides additional evidence that the 6-way categorization by topic task is more difficult for Romanian than for Moldavian.", "labels": [], "entities": []}, {"text": "In all the intradialect or cross-dialect 6-way categorization tasks, we observe a high performance gap between deep and shallow models.", "labels": [], "entities": []}, {"text": "These results are consistent with the recent reports of the VarDial evaluation campaigns (, which point out that shallow approaches such as string kernels (Butnaru and Ionescu, 2018; Ionescu and Butnaru, 2017) surpass deep models in dialect and similar language discrimination tasks.", "labels": [], "entities": []}, {"text": "Although deep models obtain generally lower results, our proposal of integrating Squeeze-and-Excitation blocks seems to be a steady step towards improving CNN models: Accuracy rates, weighted F 1 scores and macro-averaged F 1 -scores (in %) of the KRR based on the presence bits string kernel for the five evaluation tasks, before and after named entity removal (NER).", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 167, "end_pos": 175, "type": "METRIC", "confidence": 0.9928272366523743}, {"text": "F 1 scores", "start_pos": 192, "end_pos": 202, "type": "METRIC", "confidence": 0.9293103615442911}, {"text": "macro-averaged F 1 -scores", "start_pos": 207, "end_pos": 233, "type": "METRIC", "confidence": 0.7701117038726807}, {"text": "named entity removal (NER)", "start_pos": 341, "end_pos": 367, "type": "TASK", "confidence": 0.7943519651889801}]}, {"text": "for language identification, as SE blocks improve performance across all the experiments presented in, and, in some cases, the performance gains are considerable.", "labels": [], "entities": [{"text": "language identification", "start_pos": 4, "end_pos": 27, "type": "TASK", "confidence": 0.8009806871414185}]}], "tableCaptions": [{"text": " Table 1: The number of samples (#samples) and the  number of tokens (#tokens) contained in the training,  validation and test sets included in our corpus.", "labels": [], "entities": []}, {"text": " Table 2: Accuracy rates, weighted F 1 scores and macro-averaged", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9990295171737671}, {"text": "F 1 scores", "start_pos": 35, "end_pos": 45, "type": "METRIC", "confidence": 0.9219155708948771}]}, {"text": " Table 3: Accuracy rates, weighted F 1 scores and  macro-averaged F 1 -scores (in %) of the KRR based on  the presence bits string kernel for the five evaluation  tasks, before and after named entity removal (NER).", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9985039234161377}, {"text": "F 1 scores", "start_pos": 35, "end_pos": 45, "type": "METRIC", "confidence": 0.8949452638626099}, {"text": "macro-averaged F 1 -scores", "start_pos": 51, "end_pos": 77, "type": "METRIC", "confidence": 0.8088416695594788}, {"text": "named entity removal (NER)", "start_pos": 187, "end_pos": 213, "type": "TASK", "confidence": 0.8136528531710306}]}, {"text": " Table 6: Accuracy rates (in %) of the KRR based on  string kernels for Romanian dialect identification ver- sus Arabic (Ali et al., 2016) and German (Samard\u017ei\u00b4Samard\u017ei\u00b4c  et al., 2016) dialect identification, respectively. The re- sults for the Arabic and German dialect identification  tasks are taken from our previous work (Ionescu and  Butnaru, 2017). For each corpus, we include the num- ber of dialects (#dialects) and the average number of  tokens in each sample (#tokens per sample).", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9887048602104187}, {"text": "Samard\u017ei\u00b4Samard\u017ei\u00b4c  et al., 2016) dialect identification", "start_pos": 151, "end_pos": 208, "type": "TASK", "confidence": 0.7944640964269638}]}]}