{"title": [{"text": "Word2Sense : Sparse Interpretable Word Embeddings", "labels": [], "entities": []}], "abstractContent": [{"text": "We present an unsupervised method to generate Word2Sense word embeddings that are interpretable-each dimension of the embedding space corresponds to a fine-grained sense, and the non-negative value of the embedding along the j-th dimension represents the relevance of the j-th sense to the word.", "labels": [], "entities": []}, {"text": "The underlying LDA-based generative model can be extended to refine the representation of a polysemous word in a short context, allowing us to use the embeddings in con-textual tasks.", "labels": [], "entities": [{"text": "LDA-based generative", "start_pos": 15, "end_pos": 35, "type": "TASK", "confidence": 0.5982310473918915}]}, {"text": "On computational NLP tasks, Word2Sense embeddings compare well with other word embeddings generated by unsuper-vised methods.", "labels": [], "entities": []}, {"text": "Across tasks such as word similarity , entailment, sense induction, and con-textual interpretation, Word2Sense is competitive with the state-of-the-art method for that task.", "labels": [], "entities": [{"text": "word similarity", "start_pos": 21, "end_pos": 36, "type": "TASK", "confidence": 0.765317291021347}, {"text": "sense induction", "start_pos": 51, "end_pos": 66, "type": "TASK", "confidence": 0.7337136566638947}, {"text": "con-textual interpretation", "start_pos": 72, "end_pos": 98, "type": "TASK", "confidence": 0.7937681078910828}]}, {"text": "Word2Sense embeddings are at least as sparse and fast to compute as prior art.", "labels": [], "entities": [{"text": "Word2Sense", "start_pos": 0, "end_pos": 10, "type": "DATASET", "confidence": 0.9160616397857666}]}], "introductionContent": [{"text": "Several unsupervised methods such as and) have demonstrated that co-occurrence data from large corpora can be used to compute low-dimensional representations of words (a.k.a. embeddings) that are useful in computational NLP tasks.", "labels": [], "entities": []}, {"text": "While not as accurate as semi-supervised methods such as BERT ( and ELM O () that are trained on various downstream tasks, they do not require massive amounts of compute unaccessible to all but few.", "labels": [], "entities": [{"text": "BERT", "start_pos": 57, "end_pos": 61, "type": "METRIC", "confidence": 0.9793621301651001}, {"text": "ELM O", "start_pos": 68, "end_pos": 73, "type": "METRIC", "confidence": 0.8880201876163483}]}, {"text": "Nearly all such methods produce dense representations for words whose coordinates in themselves have no meaningful interpretation.", "labels": [], "entities": []}, {"text": "The numerical values of a word's embedding are meaningful only in relation to representations of other words.", "labels": [], "entities": []}, {"text": "A unitary rotation can be applied to many of these embeddings retaining their utility for computational tasks, and yet completely changing the values of individual coordinates.", "labels": [], "entities": []}, {"text": "Can we design an interpretable embedding whose coordinates have a clear meaning to humans?", "labels": [], "entities": []}, {"text": "Ideally such an embedding would capture the multiple senses of a word, while being effective at computational tasks that use inter-word spacing of embeddings.", "labels": [], "entities": []}, {"text": "Loosely, a sense is a set of semantically similar words that collectively evoke a bigger picture than individual words in the reader's mind.", "labels": [], "entities": []}, {"text": "In this work, we mathematically define a sense to be a probability distribution over the vocabulary, just as topics in topic models.", "labels": [], "entities": []}, {"text": "A human can relate to a sense through the words with maximum probability in the sense's probability distribution.", "labels": [], "entities": []}, {"text": "presents the top 10 words fora few senses.", "labels": [], "entities": []}, {"text": "We describe precisely such an embedding of words in a space where each dimension corresponds to a sense.", "labels": [], "entities": []}, {"text": "Words are represented as probability distributions over senses so that the magnitude of each coordinate represents the relative importance of the corresponding sense to the word.", "labels": [], "entities": []}, {"text": "Such embeddings would naturally capture the polysemous nature of words.", "labels": [], "entities": []}, {"text": "For instance, the embedding fora word such as cell with many senses -e.g. \"biological entity\", \"mobile phones\", \"excel sheet\", \"blocks\", \"prison\" and \"battery\" (see) -will have support overall such senses.", "labels": [], "entities": []}, {"text": "To recover senses from a corpus and to represent word embeddings as (sparse) probability distributions over senses, we propose a generative model) for the co-occurrence matrix: (1) associate with each word w a sense distribution \u03b8 w with Dirichlet prior; (2) form a context around a target word w by sampling senses z according to \u03b8 w , and sample words from the distribution of sense z.", "labels": [], "entities": []}, {"text": "This allows us to use fast inference tools such as) to recover few thousand fine-grained senses from large cor-", "labels": [], "entities": []}], "datasetContent": [{"text": "We demonstrate that the above construction of a word's representation disambiguated in a context is useful by comparing with state-of-the-art unsupervised methods for polysemy disambiguation on two tasks: Word Sense Induction and contextual similarity.", "labels": [], "entities": [{"text": "Word Sense Induction", "start_pos": 205, "end_pos": 225, "type": "TASK", "confidence": 0.6971182624499003}]}, {"text": "Specifically, we compare with MSSG, the K-Grassmeans model of (, and the sparse coding method of ().", "labels": [], "entities": [{"text": "MSSG", "start_pos": 30, "end_pos": 34, "type": "DATASET", "confidence": 0.7427557110786438}]}, {"text": "We show the effectiveness of our embeddings at capturing multiple senses of a polysemous word in.", "labels": [], "entities": []}, {"text": "For e.g. \"tie\" can be used as a verb to mean tying a rope, or drawing a match, or as a noun to mean clothing material.", "labels": [], "entities": []}, {"text": "These three senses are captured in the top 3 dimensions of W ord2Sense embedding for \"tie\".", "labels": [], "entities": []}, {"text": "Similarly, the embedding for \"cell\" captures the 5 senses discussed in section 1 within the top 15 dimensions of the embedding.", "labels": [], "entities": []}, {"text": "The remaining top senses capture fine grained senses such as different kinds of biological cells -e.g. bone marrow cell, liver cell, neuron -that a subject expert might relate to.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Top senses of polysemous words as identified Word2Sense embeddings. Each row lists the rank of the  sense in terms of its weight in the word's embedding, and the top 10 words in the senses' probability distribution.", "labels": [], "entities": []}, {"text": " Table 2: Comparison of word embeddings on word similarity eval- uation datasets. For MSSG learned for top 30K and 6k words, we  report the similarity of the global vectors of word, which we find  to be better than comparing all the local vectors of words. For  W ord2GM , we report numbers from our tuning as well as from  the paper (in paranthesis). Note that we report higher numbers  in all cases, except on WS353-S and WS353-R datasets. We at- tribute this to fewer passes over the data and possibly different  pre-processing. a 0.353 with a different metric.", "labels": [], "entities": [{"text": "WS353-S", "start_pos": 412, "end_pos": 419, "type": "DATASET", "confidence": 0.9599274396896362}, {"text": "WS353-R datasets", "start_pos": 424, "end_pos": 440, "type": "DATASET", "confidence": 0.9606287181377411}]}, {"text": " Table 3: Comparison of embeddings on  word entailment. The number reported  for (Baroni et al., 2012) has been taken  from original paper and uses the balAP- inc metric. For W ord2GM , we were  able to reproduce results in the original  paper; we report results using both Co- sine and KL divergence metrics. For  W ord2Sense , we use KL divergence.", "labels": [], "entities": [{"text": "word entailment", "start_pos": 39, "end_pos": 54, "type": "TASK", "confidence": 0.7230427861213684}, {"text": "balAP- inc metric", "start_pos": 152, "end_pos": 169, "type": "METRIC", "confidence": 0.9551596194505692}]}, {"text": " Table 4: Comparison on benchmark downstream tasks.", "labels": [], "entities": []}, {"text": " Table 5: Comparison of embeddings on for Word Intru- sion tasks. The second column indicates the inter an- notator agreement -the first number is the fraction of  questions for which at least 2 annotators agreed and the  second indicates the fraction on which all three agreed.  The last column is the precision of the majority vote.", "labels": [], "entities": [{"text": "precision", "start_pos": 303, "end_pos": 312, "type": "METRIC", "confidence": 0.9995898604393005}]}, {"text": " Table 6: Comparison of W ordCtx2Sense with the  state-of-the-art methods for Word Sense Induction on  MakeSense-2016 and SemEval-2010 dataset. We report F- score and V-measure scores multiplied by 100.", "labels": [], "entities": [{"text": "Word Sense Induction", "start_pos": 78, "end_pos": 98, "type": "TASK", "confidence": 0.5971233050028483}, {"text": "SemEval-2010 dataset", "start_pos": 122, "end_pos": 142, "type": "DATASET", "confidence": 0.7861160635948181}, {"text": "F- score", "start_pos": 154, "end_pos": 162, "type": "METRIC", "confidence": 0.9868509372075399}]}, {"text": " Table 8: Performance of W ord2vec at different embedding size, in similarity tasks.", "labels": [], "entities": []}, {"text": " Table 9: Performance of W ord2GM , with spherical covariance matrix for each embeddding, at different embed- ding sizes in similarity tasks 0.612  0.593  0.724", "labels": [], "entities": []}, {"text": " Table 10: Performance of W ord2Sense as computed in eq. 3 without the P roject step in similarity tasks, at  different hyperparameter settings.", "labels": [], "entities": []}]}