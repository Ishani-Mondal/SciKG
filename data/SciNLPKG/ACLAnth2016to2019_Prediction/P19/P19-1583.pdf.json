{"title": [{"text": "Target Conditioned Sampling: Optimizing Data Selection for Multilingual Neural Machine Translation", "labels": [], "entities": [{"text": "Target Conditioned Sampling", "start_pos": 0, "end_pos": 27, "type": "TASK", "confidence": 0.6712221006552378}, {"text": "Multilingual Neural Machine Translation", "start_pos": 59, "end_pos": 98, "type": "TASK", "confidence": 0.6253374665975571}]}], "abstractContent": [{"text": "To improve low-resource Neural Machine Translation (NMT) with multilingual corpora, training on the most related high-resource language only is often more effective than using all data available (Neubig and Hu, 2018).", "labels": [], "entities": [{"text": "low-resource Neural Machine Translation (NMT)", "start_pos": 11, "end_pos": 56, "type": "TASK", "confidence": 0.7993784461702619}]}, {"text": "However, it is possible that an intelligent data selection strategy can further improve low-resource NMT with data from other auxiliary languages.", "labels": [], "entities": []}, {"text": "In this paper, we seek to construct a sampling distribution overall multilingual data, so that it minimizes the training loss of the low-resource language.", "labels": [], "entities": []}, {"text": "Based on this formulation , we propose an efficient algorithm, Target Conditioned Sampling (TCS), which first samples a target sentence, and then conditionally samples its source sentence.", "labels": [], "entities": [{"text": "Target Conditioned Sampling (TCS)", "start_pos": 63, "end_pos": 96, "type": "TASK", "confidence": 0.7372367282708486}]}, {"text": "Experiments show that TCS brings significant gains of up to 2 BLEU on three of four languages we test, with minimal training overhead 1 .", "labels": [], "entities": [{"text": "TCS", "start_pos": 22, "end_pos": 25, "type": "TASK", "confidence": 0.7750325202941895}, {"text": "BLEU", "start_pos": 62, "end_pos": 66, "type": "METRIC", "confidence": 0.9990662932395935}]}], "introductionContent": [{"text": "Multilingual NMT has led to impressive gains in translation accuracy of low-resource languages (LRL) ().", "labels": [], "entities": [{"text": "translation", "start_pos": 48, "end_pos": 59, "type": "TASK", "confidence": 0.948470950126648}, {"text": "accuracy", "start_pos": 60, "end_pos": 68, "type": "METRIC", "confidence": 0.9354647397994995}]}, {"text": "Many real world datasets provide sentences that are multi-parallel, with the same content in a variety of languages.", "labels": [], "entities": []}, {"text": "Examples include TED (, Europarl (, and many others.", "labels": [], "entities": [{"text": "TED", "start_pos": 17, "end_pos": 20, "type": "DATASET", "confidence": 0.8707879185676575}, {"text": "Europarl", "start_pos": 24, "end_pos": 32, "type": "DATASET", "confidence": 0.9513277411460876}]}, {"text": "These datasets open up the tantalizing prospect of training a system on many different languages to improve accuracy, but previous work has found methods that use only a single related (HRL) often out-perform systems trained on all available data.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 108, "end_pos": 116, "type": "METRIC", "confidence": 0.9976315498352051}]}, {"text": "In addition, because the resulting training corpus is smaller, using a single language is also substantially faster to train, speeding experimental cycles.", "labels": [], "entities": []}, {"text": "In this paper, we go a step further and ask the question: can we design an intelligent data selection strategy that allows us to choose the most relevant multilingual data to further boost NMT performance and training speed for LRLs?", "labels": [], "entities": []}, {"text": "Prior work has examined data selection from the view of domain adaptation, selecting good training data from out-of-domain text to improve indomain performance.", "labels": [], "entities": [{"text": "domain adaptation", "start_pos": 56, "end_pos": 73, "type": "TASK", "confidence": 0.7954456210136414}]}, {"text": "In general, these methods select data that score above a preset threshold according to some metric, such as the difference between in-domain and out-of-domain language models or sentence embedding similarity ().", "labels": [], "entities": []}, {"text": "Other works use all the data but weight training instances by domain similarity (, or sample subsets of training data at each epoch (van der.", "labels": [], "entities": []}, {"text": "However, none of these methods are trivially applicable to multilingual parallel datasets, which usually contain many different languages from the same domain.", "labels": [], "entities": []}, {"text": "Moreover, most of these methods need to pretrain language models or NMT models with a reasonable amount of data, and accuracy can suffer in low-resource settings like those encountered for LRLs (.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 117, "end_pos": 125, "type": "METRIC", "confidence": 0.9987707734107971}]}, {"text": "In this paper, we create a mathematical framework for data selection in multilingual MT that selects data from all languages, such that minimizing the training objective over the sampled data approximately minimizes the loss of the LRL MT model.", "labels": [], "entities": [{"text": "data selection", "start_pos": 54, "end_pos": 68, "type": "TASK", "confidence": 0.7239972651004791}, {"text": "MT", "start_pos": 85, "end_pos": 87, "type": "TASK", "confidence": 0.8430765271186829}]}, {"text": "The formulation leads to an simple, efficient, and effective algorithm that first samples a target sentence and then conditionally samples which of several source sentences to use for training.", "labels": [], "entities": []}, {"text": "We name the method Target Conditioned Sampling (TCS).", "labels": [], "entities": [{"text": "Target Conditioned Sampling (TCS)", "start_pos": 19, "end_pos": 52, "type": "TASK", "confidence": 0.7274800688028336}]}, {"text": "We also propose and experiment with several design choices for TCS, which are especially effective for LRLs.", "labels": [], "entities": [{"text": "TCS", "start_pos": 63, "end_pos": 66, "type": "TASK", "confidence": 0.9036720991134644}]}, {"text": "On the TED multilin-gual corpus, TCS leads to large improvements of up to 2 BLEU on three of the four languages we test, and no degradation on the fourth, with only slightly increased training time.", "labels": [], "entities": [{"text": "TED multilin-gual corpus", "start_pos": 7, "end_pos": 31, "type": "DATASET", "confidence": 0.7370902101198832}, {"text": "TCS", "start_pos": 33, "end_pos": 36, "type": "METRIC", "confidence": 0.6002762317657471}, {"text": "BLEU", "start_pos": 76, "end_pos": 80, "type": "METRIC", "confidence": 0.9991932511329651}]}, {"text": "To our knowledge, this is the first successful application of data selection to multilingual NMT.", "labels": [], "entities": [{"text": "data selection", "start_pos": 62, "end_pos": 76, "type": "TASK", "confidence": 0.7241695821285248}]}], "datasetContent": [{"text": "We use the 58-language-to-English TED dataset (.", "labels": [], "entities": [{"text": "TED dataset", "start_pos": 34, "end_pos": 45, "type": "DATASET", "confidence": 0.6686109751462936}]}, {"text": "Following the setup in prior work (, we use three low-resource languages Azerbaijani (aze), Belarusian (bel), Galician (glg) to English, and a slightly higher-resource dataset, Slovak (slk) to English.", "labels": [], "entities": []}, {"text": "We use multiple settings for baselines: 1) Bi: each LRL is paired with its related HRL, following.", "labels": [], "entities": [{"text": "Bi", "start_pos": 43, "end_pos": 45, "type": "METRIC", "confidence": 0.9965060949325562}]}, {"text": "The statistics of the LRL and their corresponding HRL are listed in Table 1; 2) All: we train a model on all 58 languages; 3) Copied: following, we use the union of all English sentences as monolingual data by copying them to the source side.", "labels": [], "entities": []}, {"text": "A standard sequence-to-sequence () NMT model with attention is used for all experiments.", "labels": [], "entities": []}, {"text": "Byte Pair Encoding (BPE) () with vocabulary size of 8000 is applied for each language individually.", "labels": [], "entities": [{"text": "Byte Pair Encoding (BPE)", "start_pos": 0, "end_pos": 24, "type": "METRIC", "confidence": 0.5710131078958511}]}, {"text": "Details of other hyperparameters can be found in Appendix A.1.", "labels": [], "entities": [{"text": "Appendix A.1", "start_pos": 49, "end_pos": 61, "type": "DATASET", "confidence": 0.8844848871231079}]}], "tableCaptions": [{"text": " Table 1: Statistics of our datasets.", "labels": [], "entities": []}, {"text": " Table 2: BLEU scores on four languages. Statistical signifi-", "labels": [], "entities": [{"text": "BLEU", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9978479146957397}]}, {"text": " Table 3: BLEU scores using SDE as word encoding. Sta-", "labels": [], "entities": [{"text": "BLEU", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9976546168327332}]}]}