{"title": [{"text": "Inter-sentence Relation Extraction with Document-level Graph Convolutional Neural Network", "labels": [], "entities": [{"text": "Inter-sentence Relation Extraction", "start_pos": 0, "end_pos": 34, "type": "TASK", "confidence": 0.8068217734495798}]}], "abstractContent": [{"text": "Inter-sentence relation extraction deals with a number of complex semantic relationships in documents, which require local, non-local, syntactic and semantic dependencies.", "labels": [], "entities": [{"text": "Inter-sentence relation extraction", "start_pos": 0, "end_pos": 34, "type": "TASK", "confidence": 0.8531661629676819}]}, {"text": "Existing methods do not fully exploit such dependencies.", "labels": [], "entities": []}, {"text": "We present a novel inter-sentence relation extraction model that builds a labelled edge graph convolutional neural network model on a document-level graph.", "labels": [], "entities": [{"text": "inter-sentence relation extraction", "start_pos": 19, "end_pos": 53, "type": "TASK", "confidence": 0.643184075752894}]}, {"text": "The graph is constructed using various inter-and intra-sentence dependencies to capture local and non-local dependency information.", "labels": [], "entities": []}, {"text": "In order to predict the relation of an entity pair, we utilise multi-instance learning with bi-affine pairwise scoring.", "labels": [], "entities": []}, {"text": "Experimental results show that our model achieves comparable performance to the state-of-the-art neural models on two biochemistry datasets.", "labels": [], "entities": []}, {"text": "Our analysis shows that all the types in the graph are effective for inter-sentence relation extraction.", "labels": [], "entities": [{"text": "inter-sentence relation extraction", "start_pos": 69, "end_pos": 103, "type": "TASK", "confidence": 0.7574459711710612}]}], "introductionContent": [{"text": "Semantic relationships between named entities often span across multiple sentences.", "labels": [], "entities": []}, {"text": "In order to extract inter-sentence relations, most approaches utilise distant supervision to automatically generate document-level corpora (.", "labels": [], "entities": []}, {"text": "Recently, introduced multi-instance learning (MIL) () to treat multiple mentions of target entities in a document.", "labels": [], "entities": [{"text": "multi-instance learning (MIL)", "start_pos": 21, "end_pos": 50, "type": "TASK", "confidence": 0.7382284522056579}]}, {"text": "Inter-sentential relations depend not only on local but also on non-local dependencies.", "labels": [], "entities": []}, {"text": "Dependency trees are often used to extract local dependencies of semantic relations () in intra-sentence * Corresponding author.", "labels": [], "entities": []}, {"text": "relation extraction (RE).", "labels": [], "entities": [{"text": "relation extraction (RE)", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.8037169694900512}]}, {"text": "However, such dependencies are not adequate for inter-sentence RE, since different sentences have different dependency trees.", "labels": [], "entities": [{"text": "inter-sentence RE", "start_pos": 48, "end_pos": 65, "type": "TASK", "confidence": 0.4903421550989151}]}, {"text": "illustrates such a case between Oxytocin and hypotension.", "labels": [], "entities": []}, {"text": "To capture their relation, it is essential to connect the co-referring entities Oxytocin and Oxt.", "labels": [], "entities": []}, {"text": "RNNs and CNNs, which are often used for intra-sentence RE (, are not effective on longer sequences () thus failing to capture such non-local dependencies.", "labels": [], "entities": []}, {"text": "We propose a novel inter-sentence RE model that builds a labelled edge Graph CNN (GCNN) model) on a document-level graph.", "labels": [], "entities": []}, {"text": "The graph nodes correspond to words and edges represent local and nonlocal dependencies among them.", "labels": [], "entities": []}, {"text": "The documentlevel graph is formed by connecting words with local dependencies from syntactic parsing and sequential information, as well as non-local dependencies from coreference resolution and other semantic dependencies (.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 168, "end_pos": 190, "type": "TASK", "confidence": 0.9130952954292297}]}, {"text": "We infer relations between entities using MIL-based bi-affine pairwise scoring function () on the entity node representations.", "labels": [], "entities": []}, {"text": "Firstly, we pro- The input word sequence is mapped to a graph structure, where nodes are words and edges correspond to dependencies.", "labels": [], "entities": []}, {"text": "We omit several edges, such as self-node edges of all words and syntactic dependency edges of different labels, for brevity.", "labels": [], "entities": []}, {"text": "GCNN is employed to encode the graph and a bi-affine layer aggregates all mention pairs.", "labels": [], "entities": [{"text": "GCNN", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.8297560811042786}]}, {"text": "pose a novel model for inter-sentence RE using GCNN to capture local and non-local dependencies.", "labels": [], "entities": [{"text": "inter-sentence RE", "start_pos": 23, "end_pos": 40, "type": "TASK", "confidence": 0.5272670984268188}, {"text": "GCNN", "start_pos": 47, "end_pos": 51, "type": "DATASET", "confidence": 0.8618614673614502}]}, {"text": "Secondly, we apply the model on two biochemistry corpora and show its effectiveness.", "labels": [], "entities": []}, {"text": "Finally, we developed a novel, distantly supervised dataset with chemical reactant-product relations from PubMed abstracts.", "labels": [], "entities": [{"text": "PubMed abstracts", "start_pos": 106, "end_pos": 122, "type": "DATASET", "confidence": 0.9528056681156158}]}], "datasetContent": [{"text": "We first briefly describe the datasets where the proposed model is evaluated along with their preprocessing.", "labels": [], "entities": []}, {"text": "We then introduce the baseline models we use for comparison.", "labels": [], "entities": []}, {"text": "Finally, we show the training settings.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Statistics of the CDR and CHR datasets.", "labels": [], "entities": [{"text": "CHR datasets", "start_pos": 36, "end_pos": 48, "type": "DATASET", "confidence": 0.7928901016712189}]}, {"text": " Table 2: Performance on the CDR and CHR test sets in com-", "labels": [], "entities": [{"text": "CHR test sets", "start_pos": 37, "end_pos": 50, "type": "DATASET", "confidence": 0.843859593073527}]}, {"text": " Table 3: Ablation analysis on the CDR development set, in", "labels": [], "entities": [{"text": "Ablation", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.932393491268158}, {"text": "CDR development set", "start_pos": 35, "end_pos": 54, "type": "DATASET", "confidence": 0.9603830575942993}]}]}