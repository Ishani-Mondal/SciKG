{"title": [{"text": "Confusionset-guided Pointer Networks for Chinese Spelling Check", "labels": [], "entities": [{"text": "Chinese Spelling Check", "start_pos": 41, "end_pos": 63, "type": "TASK", "confidence": 0.7234303951263428}]}], "abstractContent": [{"text": "This paper proposes Confusionset-guided Pointer Networks for Chinese Spell Check (CSC) task.", "labels": [], "entities": [{"text": "Chinese Spell Check (CSC) task", "start_pos": 61, "end_pos": 91, "type": "TASK", "confidence": 0.8204678084169116}]}, {"text": "More concretely, our approach utilizes the off-the-shelf confusionset for guiding the character generation.", "labels": [], "entities": [{"text": "character generation", "start_pos": 86, "end_pos": 106, "type": "TASK", "confidence": 0.7977493703365326}]}, {"text": "To this end, our novel Seq2Seq model jointly learns to copy a correct character from an input sentence through a pointer network, or generate a character from the confusionset rather than the entire vocabulary.", "labels": [], "entities": []}, {"text": "We conduct experiments on three human-annotated datasets, and results demonstrate that our proposed generative model outperforms all competitor models by a large margin of up to 20% F1 score, achieving state-of-the-art performance on three datasets.", "labels": [], "entities": [{"text": "generative", "start_pos": 100, "end_pos": 110, "type": "TASK", "confidence": 0.9664697051048279}, {"text": "F1 score", "start_pos": 182, "end_pos": 190, "type": "METRIC", "confidence": 0.9876550436019897}]}], "introductionContent": [{"text": "In our everyday writing, there exists different types of errors, one of which that frequently occurs is misspelling a character due to the characters' similarity in terms of sound, shape, and/or meaning.", "labels": [], "entities": []}, {"text": "Spelling check is a task to detect and correct such problematic usage of language.", "labels": [], "entities": [{"text": "Spelling check", "start_pos": 0, "end_pos": 14, "type": "TASK", "confidence": 0.8842710554599762}]}, {"text": "Although these tools been useful, detecting and fixing errors in natural language, especially in Chinese, remains far from solved.", "labels": [], "entities": []}, {"text": "Notably, Chinese is very different from other alphabetical languages (e.g., English).", "labels": [], "entities": []}, {"text": "First, there are no word delimiters between the Chinese words.", "labels": [], "entities": []}, {"text": "Second, the error detection task is difficult due to its context-sensitive nature, i.e., errors can be only often determined at phrase/sentence level and not at character-level.", "labels": [], "entities": [{"text": "error detection task", "start_pos": 12, "end_pos": 32, "type": "TASK", "confidence": 0.7509970863660177}]}, {"text": "In this paper, we propose a novel neural architecture for the Chinese Spelling Check (CSC) task.", "labels": [], "entities": [{"text": "Chinese Spelling Check (CSC) task", "start_pos": 62, "end_pos": 95, "type": "TASK", "confidence": 0.7906503677368164}]}, {"text": "For the task at hand, it is intuitive that the generated sentence and the input sentence would usually share most characters, along with same sentence structure with a slight exception for several incorrect characters.", "labels": [], "entities": []}, {"text": "This is unlike other generative tasks (e.g., neural machine translation or dialog translation) in which the output would differ greatly from the input.", "labels": [], "entities": [{"text": "neural machine translation", "start_pos": 45, "end_pos": 71, "type": "TASK", "confidence": 0.6367386976877848}, {"text": "dialog translation)", "start_pos": 75, "end_pos": 94, "type": "TASK", "confidence": 0.7993039886156718}]}, {"text": "To this end, this paper proposes a novel Confusionset-guided copy mechanism which achieves significant performance gain over competitor approaches.", "labels": [], "entities": []}, {"text": "Copy mechanisms, enable the copying of words directly from the input via pointing, providing an extremely appropriate inductive bias for the CSC task.", "labels": [], "entities": []}, {"text": "More concretely, our model jointly learns the selection of appropriate characters to copy or to generate a correct character from the vocabulary when an incorrect character occurs.", "labels": [], "entities": []}, {"text": "The clear novelty of our work, however, is the infusion of Confusionsets 1 with Pointer Networks, which help reduce the search space and vastly improve the probability of generating correct characters.", "labels": [], "entities": []}, {"text": "Experimental results on three benchmark datasets demonstrate that our model outperforms all competitor models, obtaining performance gains of up to 20%.", "labels": [], "entities": []}], "datasetContent": [{"text": "Train data We use the large annotated corpus which contains spelling errors, either visually or phonologically resembled characters, by an automatic approach proposed in ( . In addition, a small fraction of three humanannotated training datasets provided in () are also included in our training data.", "labels": [], "entities": []}, {"text": "Test data To evaluate the effectiveness of our proposed model, we test our trained model on benchmark datasets from three shared tasks of CSC (.", "labels": [], "entities": []}, {"text": "Since these testing datasets are written in traditional Chinese, we convert them into simplified Chinese characters using OpenCC . Details of experimental data statistics information, including the training datasets, the testing datasets and the Confusionsets used in our model, are shown in.", "labels": [], "entities": [{"text": "OpenCC", "start_pos": 122, "end_pos": 128, "type": "DATASET", "confidence": 0.9436538219451904}]}, {"text": "Evaluation metrics We adopt precision, recall and F1 scores as our evaluation metrics, which are widely used as evaluation metrics in CSC tasks.", "labels": [], "entities": [{"text": "precision", "start_pos": 28, "end_pos": 37, "type": "METRIC", "confidence": 0.9993131160736084}, {"text": "recall", "start_pos": 39, "end_pos": 45, "type": "METRIC", "confidence": 0.9975937008857727}, {"text": "F1 scores", "start_pos": 50, "end_pos": 59, "type": "METRIC", "confidence": 0.9756546914577484}]}, {"text": "Baseline models We compare our model with two baseline methods for CSC: one is N-gram language modeling with a pre-constructed confusionset (LMC), and for its simplicity and power, it is widely used in CSC (   and.", "labels": [], "entities": []}, {"text": "By utilizing the confusionset to replace characters in a sentence, the sentence probability is calculated after and before the replacement, which is then used to determine whether the sentence contains spelling errors.", "labels": [], "entities": []}, {"text": "We re-implement the pipline proposed in (; Another is the sequence labeling method (SL), which casts Chinese spelling error detection into a sequence tagging problem on characters, in which the correct and incorrect characters are tagged as 1 and 0, respectively.", "labels": [], "entities": [{"text": "sequence labeling", "start_pos": 58, "end_pos": 75, "type": "TASK", "confidence": 0.6215633004903793}, {"text": "Chinese spelling error detection", "start_pos": 101, "end_pos": 133, "type": "TASK", "confidence": 0.6605674028396606}]}, {"text": "We follow the baseline model ( ) that implements a LSTM based sequence tagging model.", "labels": [], "entities": [{"text": "LSTM based sequence tagging", "start_pos": 51, "end_pos": 78, "type": "TASK", "confidence": 0.6155814975500107}]}], "tableCaptions": [{"text": " Table 1: Experimental Data Statistics Information.", "labels": [], "entities": [{"text": "Experimental Data Statistics Information", "start_pos": 10, "end_pos": 50, "type": "DATASET", "confidence": 0.7340271770954132}]}, {"text": " Table 2: Experimental results of detection-level and correction-level performance on three testing datasets (%). +  and -denote using Confusionsets and not using Confusionsets, respectively.", "labels": [], "entities": [{"text": "correction-level", "start_pos": 54, "end_pos": 70, "type": "METRIC", "confidence": 0.9257920384407043}]}]}