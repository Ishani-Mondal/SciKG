{"title": [{"text": "Joint Learning of Named Entity Recognition and Entity Linking", "labels": [], "entities": [{"text": "Joint Learning of Named Entity Recognition", "start_pos": 0, "end_pos": 42, "type": "TASK", "confidence": 0.52710689107577}, {"text": "Entity Linking", "start_pos": 47, "end_pos": 61, "type": "TASK", "confidence": 0.7647925317287445}]}], "abstractContent": [{"text": "Named entity recognition (NER) and entity linking (EL) are two fundamentally related tasks, since in order to perform EL, first the mentions to entities have to be detected.", "labels": [], "entities": [{"text": "Named entity recognition (NER)", "start_pos": 0, "end_pos": 30, "type": "TASK", "confidence": 0.7723433723052343}, {"text": "entity linking (EL)", "start_pos": 35, "end_pos": 54, "type": "TASK", "confidence": 0.8387856006622314}]}, {"text": "However , most entity linking approaches disregard the mention detection part, assuming that the correct mentions have been previously detected.", "labels": [], "entities": [{"text": "entity linking", "start_pos": 15, "end_pos": 29, "type": "TASK", "confidence": 0.7460865676403046}, {"text": "mention detection", "start_pos": 55, "end_pos": 72, "type": "TASK", "confidence": 0.682019516825676}]}, {"text": "In this paper, we perform joint learning of NER and EL to leverage their related-ness and obtain a more robust and generalis-able system.", "labels": [], "entities": []}, {"text": "For that, we introduce a model inspired by the Stack-LSTM approach (Dyer et al., 2015).", "labels": [], "entities": []}, {"text": "We observe that, in fact, doing multi-task learning of NER and EL improves the performance in both tasks when comparing with models trained with individual objectives.", "labels": [], "entities": []}, {"text": "Furthermore, we achieve results competitive with the state-of-the-art in both NER and EL.", "labels": [], "entities": [{"text": "NER", "start_pos": 78, "end_pos": 81, "type": "DATASET", "confidence": 0.5470086336135864}, {"text": "EL", "start_pos": 86, "end_pos": 88, "type": "DATASET", "confidence": 0.7006659507751465}]}], "introductionContent": [{"text": "In order to build high quality systems for complex natural language processing (NLP) tasks, it is useful to leverage the output information of lower level tasks, such as named entity recognition (NER) and entity linking (EL).", "labels": [], "entities": [{"text": "named entity recognition (NER)", "start_pos": 170, "end_pos": 200, "type": "TASK", "confidence": 0.8181513547897339}, {"text": "entity linking (EL)", "start_pos": 205, "end_pos": 224, "type": "TASK", "confidence": 0.8095138192176818}]}, {"text": "Therefore NER and EL are two fundamental NLP tasks.", "labels": [], "entities": [{"text": "NER", "start_pos": 10, "end_pos": 13, "type": "TASK", "confidence": 0.8379066586494446}, {"text": "EL", "start_pos": 18, "end_pos": 20, "type": "METRIC", "confidence": 0.7464877963066101}]}, {"text": "NER corresponds to the process of detecting mentions of named entities in a text and classifying them with predefined types such as person, location and organisation.", "labels": [], "entities": [{"text": "NER corresponds to the process of detecting mentions of named entities in a text and classifying them with predefined types such as person, location and organisation", "start_pos": 0, "end_pos": 165, "type": "Description", "confidence": 0.7516472571425967}]}, {"text": "However, the majority of the detected mentions can refer to different entities as in the example of, in which the mention \"Leeds\" can refer to \"Leeds\", the city, and \"Leeds United A.F.C.\", the football club.", "labels": [], "entities": []}, {"text": "To solve this ambiguity EL is performed.", "labels": [], "entities": [{"text": "EL", "start_pos": 24, "end_pos": 26, "type": "METRIC", "confidence": 0.9734897613525391}]}, {"text": "It consists in determining to which entity a particular mention refers to, by assigning a knowledge base entity id.", "labels": [], "entities": []}, {"text": "In this example, the knowledge base id of the entity \"Leeds United A.F.C.\" should be selected.", "labels": [], "entities": [{"text": "Leeds United A.F.C.\"", "start_pos": 54, "end_pos": 74, "type": "DATASET", "confidence": 0.9498568475246429}]}, {"text": "In real world applications, EL systems have to perform two tasks: mention detection or NER and entity disambiguation.", "labels": [], "entities": [{"text": "mention detection", "start_pos": 66, "end_pos": 83, "type": "TASK", "confidence": 0.7483766078948975}, {"text": "entity disambiguation", "start_pos": 95, "end_pos": 116, "type": "TASK", "confidence": 0.7263611108064651}]}, {"text": "However, most approaches have only focused on the latter, being the mentions that have to be disambiguated given.", "labels": [], "entities": []}, {"text": "In this work we do joint learning of NER and EL in order to leverage the information of both tasks at every decision.", "labels": [], "entities": [{"text": "NER", "start_pos": 37, "end_pos": 40, "type": "TASK", "confidence": 0.697001039981842}, {"text": "EL", "start_pos": 45, "end_pos": 47, "type": "METRIC", "confidence": 0.6787592768669128}]}, {"text": "Furthermore, by having a flow of information between the computation of the representations used for NER and EL we are able to improve the model.", "labels": [], "entities": [{"text": "NER", "start_pos": 101, "end_pos": 104, "type": "TASK", "confidence": 0.7467613816261292}]}, {"text": "One example of the advantage of doing joint learning is showed in, in which the joint model is able to predict the correct entity, by knowing that the type predicted by NER is Organisation.", "labels": [], "entities": []}, {"text": "This paper introduces two main contributions: \u2022 A system that jointly performs NER and EL, with competitive results in both tasks.", "labels": [], "entities": [{"text": "NER", "start_pos": 79, "end_pos": 82, "type": "TASK", "confidence": 0.7865028381347656}, {"text": "EL", "start_pos": 87, "end_pos": 89, "type": "METRIC", "confidence": 0.8908489346504211}]}, {"text": "\u2022 A empirical qualitative analysis of the advantage of doing joint learning vs using separate models and of the influence of the different components to the result obtained.", "labels": [], "entities": []}], "datasetContent": [{"text": "We trained and evaluated our model on the biggest NER-EL English dataset, the AIDA/CoNLL dataset).", "labels": [], "entities": [{"text": "NER-EL English dataset", "start_pos": 50, "end_pos": 72, "type": "DATASET", "confidence": 0.9017227292060852}, {"text": "AIDA/CoNLL dataset", "start_pos": 78, "end_pos": 96, "type": "DATASET", "confidence": 0.8806373625993729}]}, {"text": "It is a collection of news wire articles from Reuters, composed by a training set of 18,448 linked mentions in 946 documents, a validation set of 4,791 mentions in 216 documents, and a test set of 4,485 mentions in 231 documents.", "labels": [], "entities": [{"text": "Reuters", "start_pos": 46, "end_pos": 53, "type": "DATASET", "confidence": 0.8526292443275452}]}, {"text": "In this dataset, the entity mentions are classified as person, location, organisation and miscellaneous.", "labels": [], "entities": []}, {"text": "It also contains the knowledge base id of the respective entities in Wikipedia.", "labels": [], "entities": [{"text": "Wikipedia", "start_pos": 69, "end_pos": 78, "type": "DATASET", "confidence": 0.9710713028907776}]}, {"text": "For the NER experiments we report the F1 score while for the EL we report the micro and macro F1 scores.", "labels": [], "entities": [{"text": "NER", "start_pos": 8, "end_pos": 11, "type": "TASK", "confidence": 0.6227102875709534}, {"text": "F1 score", "start_pos": 38, "end_pos": 46, "type": "METRIC", "confidence": 0.987670361995697}, {"text": "EL", "start_pos": 61, "end_pos": 63, "type": "METRIC", "confidence": 0.6242734789848328}, {"text": "F1", "start_pos": 94, "end_pos": 96, "type": "METRIC", "confidence": 0.8644940257072449}]}, {"text": "The EL scores were obtained with the Gerbil benchmarking platform, which offers a reliable evaluation and comparison with the stateof-the-art models.", "labels": [], "entities": [{"text": "EL", "start_pos": 4, "end_pos": 6, "type": "METRIC", "confidence": 0.9001336097717285}, {"text": "Gerbil benchmarking", "start_pos": 37, "end_pos": 56, "type": "DATASET", "confidence": 0.8901036083698273}]}, {"text": "The results were obtained using strong matching settings, which requires exactly predicting the gold mention boundaries and their corresponding entity.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 3: NER results in CoNLL 2003 test set.", "labels": [], "entities": [{"text": "NER", "start_pos": 10, "end_pos": 13, "type": "TASK", "confidence": 0.7701025605201721}, {"text": "CoNLL 2003 test set", "start_pos": 25, "end_pos": 44, "type": "DATASET", "confidence": 0.9665688574314117}]}, {"text": " Table 4: End-to-end EL results on validation and test  sets in AIDA/CoNLL.", "labels": [], "entities": [{"text": "AIDA/CoNLL", "start_pos": 64, "end_pos": 74, "type": "DATASET", "confidence": 0.862437923749288}]}, {"text": " Table 5: Comparison of Named Entity Recognition  multi-task results with single model results.", "labels": [], "entities": [{"text": "Named Entity Recognition  multi-task", "start_pos": 24, "end_pos": 60, "type": "TASK", "confidence": 0.6868855878710747}]}, {"text": " Table 6: Comparison of Entity Linking results multi- task results with single model results.", "labels": [], "entities": [{"text": "Comparison of Entity Linking", "start_pos": 10, "end_pos": 38, "type": "TASK", "confidence": 0.5879282429814339}]}, {"text": " Table 7: Ablation test for Named Entity Recognition.", "labels": [], "entities": [{"text": "Ablation", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9922463893890381}, {"text": "Named Entity Recognition", "start_pos": 28, "end_pos": 52, "type": "TASK", "confidence": 0.7642228205998739}]}, {"text": " Table 8: Ablation test for Entity Linking.", "labels": [], "entities": [{"text": "Ablation", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9945178627967834}, {"text": "Entity Linking", "start_pos": 28, "end_pos": 42, "type": "TASK", "confidence": 0.8543276786804199}]}]}