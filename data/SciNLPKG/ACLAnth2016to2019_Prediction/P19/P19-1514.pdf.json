{"title": [{"text": "Scaling Up Open Tagging from Tens to Thousands: Comprehension Empowered Attribute Value Extraction from Product Title", "labels": [], "entities": [{"text": "Scaling Up Open Tagging from Tens to Thousands", "start_pos": 0, "end_pos": 46, "type": "TASK", "confidence": 0.7893127240240574}, {"text": "Attribute Value Extraction from Product Title", "start_pos": 72, "end_pos": 117, "type": "TASK", "confidence": 0.6222635557254156}]}], "abstractContent": [{"text": "Supplementing product information by extracting attribute values from title is a crucial task in e-Commerce domain.", "labels": [], "entities": [{"text": "Supplementing product information", "start_pos": 0, "end_pos": 33, "type": "TASK", "confidence": 0.8925574620564779}]}, {"text": "Previous studies treat each attribute only as an entity type and build one set of NER tags (e.g., BIO) for each of them, leading to a scalability issue which unfits to the large sized attribute system in real world e-Commerce.", "labels": [], "entities": [{"text": "BIO", "start_pos": 98, "end_pos": 101, "type": "METRIC", "confidence": 0.9462862610816956}]}, {"text": "In this work, we propose a novel approach to support value extraction scaling up to thousands of attributes without losing performance: (1) We propose to regard attribute as a query and adopt only one global set of BIO tags for any attributes to reduce the burden of attribute tag or model explosion; (2) We explicitly model the semantic representations for attribute and title, and develop an attention mechanism to capture the interactive semantic relations in-between to enforce our framework to be attribute comprehensive.", "labels": [], "entities": [{"text": "value extraction", "start_pos": 53, "end_pos": 69, "type": "TASK", "confidence": 0.7221397310495377}]}, {"text": "We conduct extensive experiments in real-life datasets.", "labels": [], "entities": []}, {"text": "The results show that our model not only outperforms existing state-of-the-art N-ER tagging models, but also is robust and generates promising results for up to 8, 906 attributes .", "labels": [], "entities": []}], "introductionContent": [{"text": "Product attributes are vital to e-Commerce as platforms need attribute details to make recommendations and customers need attribute information to compare products and make purchase decisions.", "labels": [], "entities": []}, {"text": "However, attribute information is often noisy and incomplete because of the inevitable hurdles posed to retailers by the extremely huge and complex e-Commerce attribute system.", "labels": [], "entities": []}, {"text": "On the other hand, product titles which are carefully designed by retailers are packed tightly with details to highlight all important aspects of products.", "labels": [], "entities": []}, {"text": "shows the product page of a 'dress' from AliExpress 1 which is an emerging and fast- growth global e-Commerce platform.", "labels": [], "entities": []}, {"text": "The product title \"2019 Summer Women Button Decorated Print Dress Off-shoulder Party Beach Sundress Boho Spaghetti Long Dresses Plus Size FICUS-RONG\" contains attribute values: (1) already listed in Item Specifics, such as 'Women' for Gender, 'Summer' for Season, etc; (2) missing in Item Specifics, such as In this paper, we are interested in supplementing attribute information from product titles, especially for the real world e-Commerce attribute system with thousands of attributes built-in and new attributes and values popping out everyday.", "labels": [], "entities": [{"text": "2019 Summer Women Button Decorated Print Dress Off-shoulder Party Beach Sundress Boho Spaghetti Long Dresses", "start_pos": 19, "end_pos": 127, "type": "TASK", "confidence": 0.6385527948538462}, {"text": "FICUS-RONG", "start_pos": 138, "end_pos": 148, "type": "METRIC", "confidence": 0.9779776334762573}]}, {"text": "Previous work (;) on attribute value extraction suffered from Closed World Assumption which heavily depends on certain pre-defined attribute value vocabularies.", "labels": [], "entities": [{"text": "attribute value extraction", "start_pos": 21, "end_pos": 47, "type": "TASK", "confidence": 0.7224665880203247}, {"text": "Closed World Assumption", "start_pos": 62, "end_pos": 85, "type": "TASK", "confidence": 0.5540318886439005}]}, {"text": "These methods were unable to distinguish polysemy values such as 'camel' which could be the Color fora sweater rather than its Brand Name, or find new attribute values which have not been seen before.", "labels": [], "entities": []}, {"text": "More recently, many research works formulate attribute value extraction problem as a special case of Named Entity Recognition (NER) task ().", "labels": [], "entities": [{"text": "formulate attribute value extraction", "start_pos": 35, "end_pos": 71, "type": "TASK", "confidence": 0.7566684857010841}, {"text": "Named Entity Recognition (NER) task", "start_pos": 101, "end_pos": 136, "type": "TASK", "confidence": 0.7890956486974444}]}, {"text": "They adopted sequence tagging models in NER as an attempt to address the Open World Assumption purely from the attribute value point of view.", "labels": [], "entities": [{"text": "sequence tagging", "start_pos": 13, "end_pos": 29, "type": "TASK", "confidence": 0.7026738077402115}, {"text": "Open World Assumption", "start_pos": 73, "end_pos": 94, "type": "TASK", "confidence": 0.5079399446646372}]}, {"text": "However, such tagging approach still failed to resolve two fundamental challenges in real world e-Commerce domain: Challenge 1.", "labels": [], "entities": []}, {"text": "Need to scale up to fit the large sized attribute system in the real world.", "labels": [], "entities": []}, {"text": "Product attribute system in e-Commerce is huge and may overlap cross domains because each industry designs its own standards.", "labels": [], "entities": []}, {"text": "The attribute size typically falls into the range from tens of thousands to millions, conservatively.", "labels": [], "entities": []}, {"text": "For example, Sports & Entertainment category from AliExpress alone contains 344, 373 products (may vary daily) with 77, 699 attributes and 482, 780 values.", "labels": [], "entities": [{"text": "Sports & Entertainment category from AliExpress", "start_pos": 13, "end_pos": 60, "type": "DATASET", "confidence": 0.7230453491210938}]}, {"text": "Previous NER tagging models have to introduce one set of entity tags (e.g., BIO tags) for each attribute.", "labels": [], "entities": [{"text": "NER tagging", "start_pos": 9, "end_pos": 20, "type": "TASK", "confidence": 0.8826647102832794}]}, {"text": "Thus, the large attribute size in reality renders previous works an infeasible choice to model attribute extraction.", "labels": [], "entities": [{"text": "attribute extraction", "start_pos": 95, "end_pos": 115, "type": "TASK", "confidence": 0.7562077939510345}]}, {"text": "Moreover, the distribution of attributes is severely skewed.", "labels": [], "entities": []}, {"text": "For example, 85% of attributes appear in less than 100 Sports & Entertainment products.", "labels": [], "entities": []}, {"text": "Model performance could be significantly degraded for such rarely occurring attributes (e.g., Sleeve Style, Astronomy, etc.) due to insufficient data.", "labels": [], "entities": []}, {"text": "Need to extend Open World Assumption to include new attribute.", "labels": [], "entities": []}, {"text": "With the rapid development of e-Commerce, both new attributes and values for newly launched products are emerging everyday.", "labels": [], "entities": []}, {"text": "For example, with the recent announcement of 'foldable mobile phone, anew attribute Fold Type is created to describe how the mobile phone can be folded with corresponding new attribute values 'inward fold', 'outward fold', etc.", "labels": [], "entities": [{"text": "Fold Type", "start_pos": 84, "end_pos": 93, "type": "METRIC", "confidence": 0.9501658976078033}]}, {"text": "Previous NER tagging models view each attribute as a separate entity type and neglect the hidden semantic connections between attributes.", "labels": [], "entities": [{"text": "NER tagging", "start_pos": 9, "end_pos": 20, "type": "TASK", "confidence": 0.853178471326828}]}, {"text": "Thus, they all fail to identify new attributes with zero manual annotations.", "labels": [], "entities": []}, {"text": "In this paper, to address the above two issues, we propose a novel attribute-comprehension based approach.", "labels": [], "entities": []}, {"text": "Inspired by Machine Reading Comprehension (MRC), we regard the product title and product attribute as 'context' and 'query' respectively, then the 'answer' extracted from 'context' equals to the attribute value wanted.", "labels": [], "entities": [{"text": "Machine Reading Comprehension (MRC)", "start_pos": 12, "end_pos": 47, "type": "TASK", "confidence": 0.7331859270731608}]}, {"text": "Specifically, we model the contexts of title and attribute respectively, capture the semantic interaction between them by attention mechanism, and then use Conditional Random Fields (CRF) () as output layer to identify the corresponding attribute value.", "labels": [], "entities": []}, {"text": "The main contributions of our work are summarized as follows: \u2022 Model.", "labels": [], "entities": []}, {"text": "To our knowledge, this is the first framework to treat attribute beyond NER type alone but leverage its contextual representation and interaction with title to extract corresponding attribute value.", "labels": [], "entities": []}, {"text": "Instead of the common BIO setting where each attribute has its own BIO tags, we adopt a novel BIO schema with only one output tag set for all attributes.", "labels": [], "entities": []}, {"text": "This is enabled by our model designed to embed attribute contextually rather than attribute tag along.", "labels": [], "entities": []}, {"text": "Then learning to extract thousands of attributes first becomes feasible.", "labels": [], "entities": []}, {"text": "Extensive experiments in real world dataset are conducted to demonstrate the efficacy of our model.", "labels": [], "entities": []}, {"text": "The proposed attribute-comprehension based model outperforms state-of-the-art models by average 3% in F 1 score.", "labels": [], "entities": [{"text": "F 1 score", "start_pos": 102, "end_pos": 111, "type": "METRIC", "confidence": 0.9823598464330038}]}, {"text": "Moreover, the proposed model scales up to 8, 906 attributes with an overall F 1 score of 79.12%.", "labels": [], "entities": [{"text": "F 1 score", "start_pos": 76, "end_pos": 85, "type": "METRIC", "confidence": 0.9927786191304525}]}, {"text": "This proves its ability to produce stable and promising results for not only low and rare frequency attributes, but also new attributes with zero extra annotations.", "labels": [], "entities": []}, {"text": "To the best of our knowledge, this is the first framework to address the two fundamental real world issues for open attribute value extraction: scalability and new-attribute.", "labels": [], "entities": [{"text": "open attribute value extraction", "start_pos": 111, "end_pos": 142, "type": "TASK", "confidence": 0.6301937997341156}]}, {"text": "Our proposed model does not make any assumptions on attribute size, attribute frequencies or the amount of additional annotations needed for new attributes.", "labels": [], "entities": []}, {"text": "The rest of the paper is organized as follows.", "labels": [], "entities": []}, {"text": "Section 2 gives a formal problem statement for this task.", "labels": [], "entities": []}, {"text": "Section 3 depicts our proposed model in details.", "labels": [], "entities": []}, {"text": "Section 4 lists the experimental settings of this work.", "labels": [], "entities": []}, {"text": "Section 5 reports the experimental results and analysis.", "labels": [], "entities": []}, {"text": "Section 6 summarizes the related work, followed by a conclusion in Section 7.", "labels": [], "entities": []}], "datasetContent": [{"text": "We use precision, recall and F 1 score as evaluation metrics denoted as P , Rand F 1 . We follow Exact Match criteria in which the full sequence of extracted value need to be correct.", "labels": [], "entities": [{"text": "precision", "start_pos": 7, "end_pos": 16, "type": "METRIC", "confidence": 0.999455988407135}, {"text": "recall", "start_pos": 18, "end_pos": 24, "type": "METRIC", "confidence": 0.9992532134056091}, {"text": "F 1 score", "start_pos": 29, "end_pos": 38, "type": "METRIC", "confidence": 0.9896496931711832}, {"text": "Rand F 1", "start_pos": 76, "end_pos": 84, "type": "METRIC", "confidence": 0.9564136068026224}]}, {"text": "Clearly, this is a strict criteria as one example gets credit only when the tag of each word is correct.", "labels": [], "entities": [{"text": "credit", "start_pos": 55, "end_pos": 61, "type": "METRIC", "confidence": 0.9628654718399048}]}], "tableCaptions": [{"text": " Table 1: The statistics and examples of 8, 906 attributes with different frequencies in dataset AE-650K.", "labels": [], "entities": [{"text": "AE-650K", "start_pos": 97, "end_pos": 104, "type": "DATASET", "confidence": 0.7591139078140259}]}, {"text": " Table 2: Statistics of dataset AE-110K.", "labels": [], "entities": [{"text": "AE-110K", "start_pos": 32, "end_pos": 39, "type": "DATASET", "confidence": 0.4242178797721863}]}, {"text": " Table 3: Performance comparison between our mod- el and three baselines on four frequent attributes. For  baselines, only the performance on AE-110K is re- ported since they do not scale up to large set of at- tributes; while for our model, the performances on both  AE-110K and AE-650K are reported.", "labels": [], "entities": [{"text": "AE-110K", "start_pos": 142, "end_pos": 149, "type": "DATASET", "confidence": 0.9597505927085876}, {"text": "AE-110K", "start_pos": 268, "end_pos": 275, "type": "DATASET", "confidence": 0.969076931476593}, {"text": "AE-650K", "start_pos": 280, "end_pos": 287, "type": "DATASET", "confidence": 0.9487137794494629}]}, {"text": " Table 4: Performance of our model in discovering val- ues for new attributes.", "labels": [], "entities": []}]}