{"title": [{"text": "Automated Essay Scoring with Discourse-Aware Neural Models", "labels": [], "entities": [{"text": "Automated Essay Scoring", "start_pos": 0, "end_pos": 23, "type": "TASK", "confidence": 0.6482417484124502}]}], "abstractContent": [{"text": "Automated essay scoring systems typically rely on hand-crafted features to predict essay quality, but such systems are limited by the cost of feature engineering.", "labels": [], "entities": [{"text": "essay scoring", "start_pos": 10, "end_pos": 23, "type": "TASK", "confidence": 0.6873245388269424}]}, {"text": "Neural networks offer an alternative to feature engineering , but they typically require more annotated data.", "labels": [], "entities": []}, {"text": "This paper explores network structures, contextualized embeddings and pre-training strategies aimed at capturing discourse characteristics of essays.", "labels": [], "entities": []}, {"text": "Experiments on three essay scoring tasks show benefits from all three strategies in different combinations, with simpler architectures being more effective when less training data is available.", "labels": [], "entities": [{"text": "essay scoring tasks", "start_pos": 21, "end_pos": 40, "type": "TASK", "confidence": 0.8030127286911011}]}], "introductionContent": [{"text": "In the context of large scale testing and online learning systems, automated essay scoring (AES) is an important problem.", "labels": [], "entities": [{"text": "automated essay scoring (AES)", "start_pos": 67, "end_pos": 96, "type": "TASK", "confidence": 0.7248551100492477}]}, {"text": "There has been work on both improving the performance of these systems and on validity studies.", "labels": [], "entities": [{"text": "validity", "start_pos": 78, "end_pos": 86, "type": "METRIC", "confidence": 0.7861604690551758}]}, {"text": "The ability to evaluate student writing has always been important for language teaching and learning; now it also extends to science, since the focus is shifting towards assessments that can more accurately gauge construct knowledge as compared to multiple choice questions).", "labels": [], "entities": []}, {"text": "Most existing systems for automatic essay scoring leverage hand crafted features, ranging from wordcounts to argumentation structure and coherence, in linear regression and logistic regression models (.", "labels": [], "entities": [{"text": "automatic essay scoring", "start_pos": 26, "end_pos": 49, "type": "TASK", "confidence": 0.6509937345981598}]}, {"text": "Improving feature-based models requires extensive redesigning of features.", "labels": [], "entities": []}, {"text": "Due to high variability in types of student essays, feature-based systems are often individually designed for specific prompts ( . This poses a challenge for building essay scoring systems.", "labels": [], "entities": []}, {"text": "These problems (and the success of deep learning in other areas of language processing) have led to the development of neural methods for automatic essay scoring, moving away from feature engineering.", "labels": [], "entities": [{"text": "automatic essay scoring", "start_pos": 138, "end_pos": 161, "type": "TASK", "confidence": 0.6231970091660818}, {"text": "feature engineering", "start_pos": 180, "end_pos": 199, "type": "TASK", "confidence": 0.7936403751373291}]}, {"text": "A variety of studies (mostly LSTM-based) have reported AES performance comparable to or better than feature-based models (.", "labels": [], "entities": [{"text": "AES", "start_pos": 55, "end_pos": 58, "type": "METRIC", "confidence": 0.9130874872207642}]}, {"text": "However, the current state-of-the-art models still use a combination of neural models and hand-crafted features (.", "labels": [], "entities": []}, {"text": "While vanilla RNNs, particularly LSTMs, are good at representing text sequences, essays are longer structured documents and less well suited to an RNN representation.", "labels": [], "entities": []}, {"text": "Thus, our work looks at advancing AES by exploring other architectures that incorporate document structure for longer documents.", "labels": [], "entities": [{"text": "AES", "start_pos": 34, "end_pos": 37, "type": "TASK", "confidence": 0.823661744594574}]}, {"text": "Discourse structure and coherence are important aspects of essay writing and are often explicitly apart of grading rubrics.", "labels": [], "entities": [{"text": "Discourse structure", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.6442683339118958}, {"text": "essay writing", "start_pos": 59, "end_pos": 72, "type": "TASK", "confidence": 0.7218513637781143}]}, {"text": "We explore methods that aim at discourse-aware models, through design of the model structure, use of discourse-based auxiliary pretraining tasks, and use of contextualized embeddings trained with cross-sentence context.", "labels": [], "entities": []}, {"text": "In order to better understand the relative advantages of these methods, we compare performance on three essay scoring tasks with different characteristics, contrasting results with a strong feature-based system.", "labels": [], "entities": []}, {"text": "Our work makes two main contributions.", "labels": [], "entities": []}, {"text": "First, we demonstrate that both discourse-aware structures and discourse-related pre-training (via auxiliary tasks or contextualized embeddings) benefit performance of neural network systems.", "labels": [], "entities": []}, {"text": "Ina TOEFL essay scoring task, we obtain a substantial improvement over the state-of-the-art.", "labels": [], "entities": [{"text": "TOEFL essay scoring task", "start_pos": 4, "end_pos": 28, "type": "TASK", "confidence": 0.6592177599668503}]}, {"text": "Second, we show that complex contextualized embedding models are not useful for tasks with small annotated training sets.", "labels": [], "entities": []}, {"text": "Simpler discourse-aware neural models are still useful, but they benefit from combination with a feature-based model.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Label distribution in LDC TOEFL dataset.  Data is split into training and test sets: split 1 (upper  part) and split 2 (lower part).", "labels": [], "entities": [{"text": "LDC TOEFL dataset", "start_pos": 32, "end_pos": 49, "type": "DATASET", "confidence": 0.7934713363647461}]}, {"text": " Table 2: Data statistics for essay sets 1 and 2 of ASAP  corpus.", "labels": [], "entities": [{"text": "ASAP  corpus", "start_pos": 52, "end_pos": 64, "type": "DATASET", "confidence": 0.8966881632804871}]}, {"text": " Table 4: Results for the essay scoring task on LDC  TOEFL corpus for both splits reported in QWK.", "labels": [], "entities": [{"text": "LDC  TOEFL corpus", "start_pos": 48, "end_pos": 65, "type": "DATASET", "confidence": 0.8198648889859518}, {"text": "QWK", "start_pos": 94, "end_pos": 97, "type": "DATASET", "confidence": 0.9510189294815063}]}, {"text": " Table 5: Results for the essay scoring task for ASAP  sets 1 and 2 reported in QWK.", "labels": [], "entities": [{"text": "ASAP", "start_pos": 49, "end_pos": 53, "type": "TASK", "confidence": 0.806453287601471}, {"text": "QWK", "start_pos": 80, "end_pos": 83, "type": "DATASET", "confidence": 0.8870713710784912}]}, {"text": " Table 6: Correlation of sim 2 and sim all with the true  essay scores for LDC TOEFL split 1.", "labels": [], "entities": [{"text": "Correlation", "start_pos": 10, "end_pos": 21, "type": "METRIC", "confidence": 0.9441920518875122}, {"text": "LDC", "start_pos": 75, "end_pos": 78, "type": "DATASET", "confidence": 0.3841250538825989}, {"text": "TOEFL", "start_pos": 79, "end_pos": 84, "type": "METRIC", "confidence": 0.5384583473205566}]}]}