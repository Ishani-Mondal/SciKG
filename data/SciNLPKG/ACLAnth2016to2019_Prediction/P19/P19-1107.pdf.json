{"title": [{"text": "Gated Embeddings in End-to-End Speech Recognition for Conversational-Context Fusion", "labels": [], "entities": [{"text": "End-to-End Speech Recognition", "start_pos": 20, "end_pos": 49, "type": "TASK", "confidence": 0.6058476169904073}]}], "abstractContent": [{"text": "We present a novel conversational-context aware end-to-end speech recognizer based on a gated neural network that incorporates conversational-context/word/speech em-beddings.", "labels": [], "entities": [{"text": "conversational-context aware end-to-end speech recognizer", "start_pos": 19, "end_pos": 76, "type": "TASK", "confidence": 0.5645374894142151}]}, {"text": "Unlike conventional speech recognition models, our model learns longer conversational-context information that spans across sentences and is consequently better at recognizing long conversations.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 20, "end_pos": 38, "type": "TASK", "confidence": 0.7187920361757278}]}, {"text": "Specifically , we propose to use text-based external word and/or sentence embeddings (i.e., fast-Text, BERT) within an end-to-end framework, yielding significant improvement in word error rate with better conversational-context representation.", "labels": [], "entities": [{"text": "BERT", "start_pos": 103, "end_pos": 107, "type": "METRIC", "confidence": 0.9929333925247192}, {"text": "word error rate", "start_pos": 177, "end_pos": 192, "type": "METRIC", "confidence": 0.6433785955111185}]}, {"text": "We evaluated the models on the Switchboard conversational speech corpus and show that our model outperforms standard end-to-end speech recognition models.", "labels": [], "entities": [{"text": "Switchboard conversational speech corpus", "start_pos": 31, "end_pos": 71, "type": "DATASET", "confidence": 0.6193741485476494}]}], "introductionContent": [{"text": "Ina long conversation, there exists a tendency of semantically related words, or phrases reoccur across sentences, or there exists topical coherence.", "labels": [], "entities": []}, {"text": "Existing speech recognition systems are built at individual, isolated utterance level in order to make building systems computationally feasible.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 9, "end_pos": 27, "type": "TASK", "confidence": 0.7159653156995773}]}, {"text": "However, this may lose important conversational context information.", "labels": [], "entities": []}, {"text": "There have been many studies that have attempted to inject a longer context information (;;), all of these models are developed on text data for language modeling task.", "labels": [], "entities": [{"text": "language modeling", "start_pos": 145, "end_pos": 162, "type": "TASK", "confidence": 0.7718341648578644}]}, {"text": "There has been recent work attempted to use the conversational-context information within a end-to-end speech recognition framework.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 103, "end_pos": 121, "type": "TASK", "confidence": 0.6945469826459885}]}, {"text": "The new end-to-end speech recognition approach (;) integrates all available information within a single neural network model, allows to make fusing conversational-context information possible.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 19, "end_pos": 37, "type": "TASK", "confidence": 0.6755336076021194}]}, {"text": "However, these are limited to encode only one preceding utterance and learn from a few hundred hours of annotated speech corpus, leading to minimal improvements.", "labels": [], "entities": []}, {"text": "Meanwhile, neural language models, such as fastText (,), OpenAI GPT (, and Bidirectional Encoder Representations from Transformers (BERT), that encode words and sentences in fixed-length dense vectors, embeddings, have achieved impressive results on various natural language processing tasks.", "labels": [], "entities": [{"text": "OpenAI GPT", "start_pos": 57, "end_pos": 67, "type": "DATASET", "confidence": 0.9029413759708405}]}, {"text": "Such general word/sentence embeddings learned on large text corpora (i.e., Wikipedia) has been used extensively and plugged in a variety of downstream tasks, such as question-answering and natural language inference,, to drastically improve their performance in the form of transfer learning.", "labels": [], "entities": []}, {"text": "In this paper, we create a conversational-context aware end-to-end speech recognizer capable of incorporating a conversational-context to better process long conversations.", "labels": [], "entities": [{"text": "conversational-context aware end-to-end speech recognizer", "start_pos": 27, "end_pos": 84, "type": "TASK", "confidence": 0.5709749937057496}]}, {"text": "Specifically, we propose to exploit external word and/or sentence embeddings which trained on massive amount of text resources, (i.e. fastText, BERT) so that the model can learn better conversational-context representations.", "labels": [], "entities": [{"text": "BERT", "start_pos": 144, "end_pos": 148, "type": "METRIC", "confidence": 0.9918318390846252}]}, {"text": "So far, the use of such pre-trained embeddings have found limited success in the speech recognition task.", "labels": [], "entities": [{"text": "speech recognition task", "start_pos": 81, "end_pos": 104, "type": "TASK", "confidence": 0.8998820185661316}]}, {"text": "We also add a gating mechanism to the decoder network that can integrate all the available embeddings (word, speech, conversational-context) efficiently with increase representational power using multiplicative interactions.", "labels": [], "entities": []}, {"text": "Additionally, we explore away to train our speech recognition model even with text-only data in the form of pre-training and joint-training approaches.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 43, "end_pos": 61, "type": "TASK", "confidence": 0.8107803463935852}]}, {"text": "We evaluate our model on the Switchboard conversational speech corpus, and show that our model outperforms the sentence-level end-to-end speech recognition model.", "labels": [], "entities": [{"text": "Switchboard conversational speech corpus", "start_pos": 29, "end_pos": 69, "type": "DATASET", "confidence": 0.638890340924263}, {"text": "sentence-level end-to-end speech recognition", "start_pos": 111, "end_pos": 155, "type": "TASK", "confidence": 0.5831914469599724}]}, {"text": "The main contributions of our work are as follows: \u2022 We introduce a contextual gating mechanism to incorporate multiple types of embeddings, word, speech, and conversationalcontext embeddings.", "labels": [], "entities": []}, {"text": "\u2022 We exploit the external word (fastText) and/or sentence embeddings (BERT) for learning better conversational-context representation.", "labels": [], "entities": [{"text": "BERT", "start_pos": 70, "end_pos": 74, "type": "METRIC", "confidence": 0.8607393503189087}, {"text": "conversational-context representation", "start_pos": 96, "end_pos": 133, "type": "TASK", "confidence": 0.7626548409461975}]}, {"text": "\u2022 We perform an extensive analysis of ways to represent the conversational-context in terms of the number of utterance history, and sampling strategy considering to use the generated sentences or the true preceding utterance.", "labels": [], "entities": []}, {"text": "\u2022 We explore away to train the model jointly even with text-only dataset in addition to annotated speech data.", "labels": [], "entities": []}], "datasetContent": [{"text": "To evaluate our proposed conversational end-toend speech recognition model, we use the Switchboard (SWBD) LDC corpus (97S62) task.", "labels": [], "entities": [{"text": "conversational end-toend speech recognition", "start_pos": 25, "end_pos": 68, "type": "TASK", "confidence": 0.6713128313422203}, {"text": "Switchboard (SWBD) LDC corpus (97S62) task", "start_pos": 87, "end_pos": 129, "type": "DATASET", "confidence": 0.6620033085346222}]}, {"text": "We split 300 hours of the SWBD training set into two: 285 hours of data for the model training, and 5 hours of data for the hyper-parameter tuning.", "labels": [], "entities": [{"text": "SWBD training set", "start_pos": 26, "end_pos": 43, "type": "DATASET", "confidence": 0.7155458927154541}]}, {"text": "We evaluate the model performance on the HUB5 Eval2000 which consists of the Callhome English (CH) and Switchboard (SWBD) (LDC2002S09, LDC2002T43).", "labels": [], "entities": [{"text": "HUB5 Eval2000", "start_pos": 41, "end_pos": 54, "type": "DATASET", "confidence": 0.8580568432807922}]}, {"text": "In, we show the number of conversations and the average number of utterances per a single conversation.", "labels": [], "entities": []}, {"text": "The audio data is sampled at 16kHz, and then each frame is converted to a 83-dimensional feature vector consisting of 80-dimensional log-mel filterbank coefficients and 3-dimensional pitch features as suggested in (.", "labels": [], "entities": []}, {"text": "The number of our word-level output tokens is 10,038, which includes 47 single character units as described in Section 3.2.", "labels": [], "entities": []}, {"text": "Note that no pronunciation lexicon was used in any of the experiments.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Experimental dataset description. We used  300 hours of Switchboard conversational corpus. Note  that any pronunciation lexicon or Fisher transcription  was not used.", "labels": [], "entities": [{"text": "Switchboard conversational corpus", "start_pos": 66, "end_pos": 99, "type": "DATASET", "confidence": 0.8126245538393656}]}]}