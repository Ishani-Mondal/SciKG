{"title": [{"text": "Embedding time expressions for deep temporal ordering models", "labels": [], "entities": []}], "abstractContent": [{"text": "Data-driven models have demonstrated state-of-the-art performance in inferring the temporal ordering of events in text.", "labels": [], "entities": []}, {"text": "However, these models often overlook explicit temporal signals, such as dates and time windows.", "labels": [], "entities": []}, {"text": "Rule-based methods can be used to identify the temporal links between these time expressions (timexes), but they fail to capture timexes' interactions with events and are hard to integrate with the distributed representations of neural net models.", "labels": [], "entities": []}, {"text": "In this paper, we introduce a framework to infuse temporal awareness into such models by learning a pre-trained model to embed timexes.", "labels": [], "entities": []}, {"text": "We generate synthetic data consisting of pairs of timexes, then train a character LSTM to learn embeddings and classify the timexes' temporal relation.", "labels": [], "entities": []}, {"text": "We evaluate the utility of these embeddings in the context of a strong neural model for event temporal ordering, and show a small increase in performance on the MATRES dataset and more substantial gains on an automatically collected dataset with more frequent event-timex interactions.", "labels": [], "entities": [{"text": "event temporal ordering", "start_pos": 88, "end_pos": 111, "type": "TASK", "confidence": 0.6507715781529745}, {"text": "MATRES dataset", "start_pos": 161, "end_pos": 175, "type": "DATASET", "confidence": 0.9021737277507782}]}], "introductionContent": [{"text": "Understanding the temporal ordering of events in a document is an important component of document understanding and plays an integral role in tasks such as timeline creation (, temporal question answering () and causality inference ().", "labels": [], "entities": [{"text": "document understanding", "start_pos": 89, "end_pos": 111, "type": "TASK", "confidence": 0.7244120836257935}, {"text": "timeline creation", "start_pos": 156, "end_pos": 173, "type": "TASK", "confidence": 0.7847355306148529}, {"text": "temporal question answering", "start_pos": 177, "end_pos": 204, "type": "TASK", "confidence": 0.642390509446462}]}, {"text": "Inferring temporal event order is challenging as it often disagrees with the narrative order in text.", "labels": [], "entities": [{"text": "Inferring temporal event order", "start_pos": 0, "end_pos": 30, "type": "TASK", "confidence": 0.614842027425766}]}, {"text": "Past work on temporal relation extraction has exploited cues such as global constraints on the temporal graph structure, world knowledge (Ning et al., Data and code are available at https://github.", "labels": [], "entities": [{"text": "temporal relation extraction", "start_pos": 13, "end_pos": 41, "type": "TASK", "confidence": 0.6711691121260325}]}, {"text": "com/tagoyal/Temporal-event-ordering 2018b), grouping of events (, or fusing these cues more effectively with deep models (.", "labels": [], "entities": []}, {"text": "One key component of temporal understanding is time expressions (timexes) that help anchor events to the time axis, but few recent systems effectively use the knowledge derivable from time expressions in their models.", "labels": [], "entities": []}, {"text": "They either give timexes no special treatment ( or rely on rule-based post-processing modules to remove inconsistencies with explicit timexes (.", "labels": [], "entities": []}, {"text": "In this work, we address this shortcoming by introducing a framework for including rich representations of timexes in neural models.", "labels": [], "entities": []}, {"text": "These models implicitly capture some information via word embeddings () or contextualized embeddings such as ELMo (.", "labels": [], "entities": []}, {"text": "However, these embeddings do not encode the full richness of temporal information needed for this task.", "labels": [], "entities": []}, {"text": "For example, these systems fail to infer the correct event relation in the following sentence: He visited France in 1992 and went to Germany in 1963.", "labels": [], "entities": []}, {"text": "partially because the dates 1992 and 1963 do not have temporally-informed embeddings.", "labels": [], "entities": []}, {"text": "We devise a method for embedding timexes that more explicitly reflects their temporal status.", "labels": [], "entities": []}, {"text": "Specifically, we sample pairs of time expressions from synthetic data, train character LSTM models to encode these time expressions and classify their temporal ordering.", "labels": [], "entities": []}, {"text": "Due to the amount and type of data they are trained on, these time embeddings will naturally capture the temporal ordering of events in standard text and generalize to things like unseen timex values.", "labels": [], "entities": []}, {"text": "We incorporate these embeddings into neural models for temporal relation extraction.", "labels": [], "entities": [{"text": "temporal relation extraction", "start_pos": 55, "end_pos": 83, "type": "TASK", "confidence": 0.6687143941720327}]}, {"text": "When used in an improved version of the model from, we show a small im-provement in performance on the benchmark MA-TRES dataset).", "labels": [], "entities": [{"text": "MA-TRES dataset", "start_pos": 113, "end_pos": 128, "type": "DATASET", "confidence": 0.8453485667705536}]}, {"text": "Additionally, to evaluate the full potential of the proposed approach, we construct another dataset with more frequent event-timex interactions using distant supervision.", "labels": [], "entities": []}, {"text": "On this dataset, our proposed approach substantially outperforms the ELMoequipped baseline model.", "labels": [], "entities": []}], "datasetContent": [{"text": "We evaluate on the MATRES dataset proposed in.", "labels": [], "entities": [{"text": "MATRES dataset", "start_pos": 19, "end_pos": 33, "type": "DATASET", "confidence": 0.783504992723465}]}, {"text": "This dataset is designed to be less ambiguous than TimeBank-Dense ().", "labels": [], "entities": [{"text": "TimeBank-Dense", "start_pos": 51, "end_pos": 65, "type": "DATASET", "confidence": 0.9126116037368774}]}, {"text": "MATRES contains temporal annotations for documents from the TimeBank (Pustejovsky et al., 2003), AQUAINT) and Platinum datasets ().", "labels": [], "entities": [{"text": "TimeBank", "start_pos": 60, "end_pos": 68, "type": "DATASET", "confidence": 0.9527927041053772}, {"text": "AQUAINT", "start_pos": 97, "end_pos": 104, "type": "METRIC", "confidence": 0.599985659122467}, {"text": "Platinum datasets", "start_pos": 110, "end_pos": 127, "type": "DATASET", "confidence": 0.7288506180047989}]}, {"text": "We follow standard practice and use TimeBank and AQUAINT (256 articles) for training and Platinum (20 articles) for testing.", "labels": [], "entities": [{"text": "TimeBank", "start_pos": 36, "end_pos": 44, "type": "DATASET", "confidence": 0.8131279945373535}, {"text": "AQUAINT", "start_pos": 49, "end_pos": 56, "type": "METRIC", "confidence": 0.9087349772453308}]}, {"text": "outlines the performance of the proposed approach on MATRES.", "labels": [], "entities": [{"text": "MATRES", "start_pos": 53, "end_pos": 59, "type": "TASK", "confidence": 0.6639254093170166}]}, {"text": "We implemented the model proposed by and compare against it.", "labels": [], "entities": []}, {"text": "We evaluate the models using both GloVe and ELMo embeddings.", "labels": [], "entities": []}, {"text": "Our results show substantial improvement over this baseline model.", "labels": [], "entities": []}, {"text": "Moreover, including time embeddings as additional input to the improved models leads to a small improvement in the overall accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 123, "end_pos": 131, "type": "METRIC", "confidence": 0.9983172416687012}]}, {"text": "However, we did not find the results to be statistically significant according to a bootstrap resampling test (GloVe p-value = 0.349, ELMo p-value = 0.267).", "labels": [], "entities": [{"text": "GloVe", "start_pos": 111, "end_pos": 116, "type": "METRIC", "confidence": 0.9672767519950867}, {"text": "ELMo", "start_pos": 134, "end_pos": 138, "type": "METRIC", "confidence": 0.9601753950119019}]}, {"text": "Note that only a fraction of examples in the MATRES dataset contain distinct time expressions Augmenting word embeddings with time embeddings increases the number of network parameters; however, additional experiments revealed that increasing the size of the GloVe embeddings in the basic temporal model did not lead to an improvement in performance.", "labels": [], "entities": [{"text": "MATRES dataset", "start_pos": 45, "end_pos": 59, "type": "DATASET", "confidence": 0.8279800117015839}, {"text": "Augmenting word embeddings", "start_pos": 94, "end_pos": 120, "type": "TASK", "confidence": 0.8374005953470866}]}, {"text": "Therefore, it does not seem that extra parameters in the model contribute to the observed improvements.", "labels": [], "entities": []}, {"text": "In MATRES, only a fraction of the examples contain time expressions and are consequently affected by inclusion of time embeddings.", "labels": [], "entities": []}, {"text": "Therefore, to test the full potential of the proposed approach, we additionally collect a test dataset of examples with explicit timexes that expose their temporal relation; we view the timexes as distant supervision for the event pairs.", "labels": [], "entities": []}, {"text": "To identify such examples, we use two high precision classifiers proposed in: (a) an eventtimex classifier that identifies the temporal relation between adjacent verb and time expressions (precision = 0.92), (b) a timex-timex classifier that identifies the temporal relation between two time expressions (precision = 0.88).", "labels": [], "entities": [{"text": "precision", "start_pos": 189, "end_pos": 198, "type": "METRIC", "confidence": 0.991081953048706}, {"text": "precision", "start_pos": 305, "end_pos": 314, "type": "METRIC", "confidence": 0.9847574234008789}]}, {"text": "These classifiers can allow us to directly infer the time relation be-: Performance of our models on the distantlylabeled event ordering data.", "labels": [], "entities": []}, {"text": "We report overall accuracy values.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 18, "end_pos": 26, "type": "METRIC", "confidence": 0.9997196793556213}]}, {"text": "In both the GloVe and ELMo settings, our timex embeddings lead to higher performance.", "labels": [], "entities": []}, {"text": "The ELMo model gets substantially worse when timexes are masked, indicating that it is organically exploiting these better than GloVe is. tween an event pair where each event is linked to a timex.", "labels": [], "entities": []}, {"text": "An example event pair from the distant data thus collected is: \"Riyadh suspended aid to the Palestinians in 1990 when it accused Arafat of siding with Iraq after the 1990 invasion of Kuwait, but it restored aid in 1994.\"", "labels": [], "entities": []}, {"text": "6 Note that the classifiers used have very low recall in general, but by running the system on Gigaword (, we can extract a large dataset in spite of this.", "labels": [], "entities": [{"text": "recall", "start_pos": 47, "end_pos": 53, "type": "METRIC", "confidence": 0.9991973042488098}, {"text": "Gigaword", "start_pos": 95, "end_pos": 103, "type": "DATASET", "confidence": 0.940159797668457}]}, {"text": "Since this distant data is created using rulebased classifiers, given a large amount of training data, the baseline model can achieve high performance as it learns to infer these rules.", "labels": [], "entities": []}, {"text": "However, our aim is to improve the performance of the event ordering model on moderately sized datasets, where the knowledge induction from timex embeddings play a larger role.", "labels": [], "entities": [{"text": "event ordering", "start_pos": 54, "end_pos": 68, "type": "TASK", "confidence": 0.6991942375898361}]}, {"text": "Therefore, we report results on training sets of size 2000, 3000, and 4000 samples.", "labels": [], "entities": []}, {"text": "The test set is kept constant with 1000 samples.", "labels": [], "entities": []}, {"text": "outlines the performance of the temporal models on this dataset.", "labels": [], "entities": []}, {"text": "We evaluate our models across three settings: (a) our event ordering model without including timex embeddings, (b) our event ordering model with masking of time tokens (replacing it with UNK tokens) and (c) our full model including timex embeddings.", "labels": [], "entities": []}, {"text": "We evaluate the models using both GloVe and ELMo embeddings as input.", "labels": [], "entities": []}, {"text": "In both settings, incorporating our timexes leads to higher performance.", "labels": [], "entities": []}, {"text": "For GloVe, the performance of the basic temporal model is similar to that when the time expression See the appendix for more samples from the distant data. is masked out.", "labels": [], "entities": []}, {"text": "This demonstrates that the temporal model does not use the knowledge from time expressions when making temporal relation predictions.", "labels": [], "entities": []}, {"text": "However, in the ELMo setting, we observed a larger drop in performance by masking out the time expressions compared to GloVe embeddings.", "labels": [], "entities": []}, {"text": "This demonstrates that the ELMo embeddings are not agnostic to time-expressions in the sentence, although they still show improvement by inclusion of timex embeddings trained specifically with the temporal classification objective on small datasets.", "labels": [], "entities": [{"text": "temporal classification", "start_pos": 197, "end_pos": 220, "type": "TASK", "confidence": 0.7248441576957703}]}], "tableCaptions": [{"text": " Table 1: Performance on the synthetic timex dataset,  classifying a pair of timexes as before, after, or simul- taneous. Including a biLSTM layer (as depicted in", "labels": [], "entities": []}, {"text": " Table 2: Performance of our event temporal ordering  model on the MATRES dataset. We report the mean  accuracy over 3 runs of each model. Our model im- proves substantially over", "labels": [], "entities": [{"text": "MATRES dataset", "start_pos": 67, "end_pos": 81, "type": "DATASET", "confidence": 0.9318620562553406}, {"text": "accuracy", "start_pos": 103, "end_pos": 111, "type": "METRIC", "confidence": 0.8000656962394714}]}, {"text": " Table 3: Performance of our models on the distantly- labeled event ordering data. We report overall accu- racy values. In both the GloVe and ELMo settings, our  timex embeddings lead to higher performance. The  ELMo model gets substantially worse when timexes  are masked, indicating that it is organically exploiting  these better than GloVe is.", "labels": [], "entities": [{"text": "accu- racy", "start_pos": 101, "end_pos": 111, "type": "METRIC", "confidence": 0.9464595913887024}]}]}