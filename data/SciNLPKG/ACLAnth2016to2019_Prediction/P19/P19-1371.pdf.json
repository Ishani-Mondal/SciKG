{"title": [{"text": "Learning to Abstract for Memory-augmented Conversational Response Generation", "labels": [], "entities": [{"text": "Memory-augmented Conversational Response Generation", "start_pos": 25, "end_pos": 76, "type": "TASK", "confidence": 0.6284221187233925}]}], "abstractContent": [{"text": "Neural generative models for open-domain chitchat conversations have become an active area of research in recent years.", "labels": [], "entities": [{"text": "Neural generative", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.7346578538417816}]}, {"text": "A critical issue with most existing generative models is that the generated responses lack informa-tiveness and diversity.", "labels": [], "entities": []}, {"text": "A few researchers attempt to leverage the results of retrieval models to strengthen the generative models, but these models are limited by the quality of the retrieval results.", "labels": [], "entities": []}, {"text": "In this work, we propose a memory-augmented generative model, which learns to abstract from the training corpus and saves the useful information to the memory to assist the response generation.", "labels": [], "entities": [{"text": "response generation", "start_pos": 173, "end_pos": 192, "type": "TASK", "confidence": 0.7115406692028046}]}, {"text": "Our model clusters query-response samples, extracts characteristics of each cluster, and learns to utilize these characteristics for response generation.", "labels": [], "entities": [{"text": "response generation", "start_pos": 133, "end_pos": 152, "type": "TASK", "confidence": 0.7368470430374146}]}, {"text": "Experimental results show that our model outperforms other competitive base-lines.", "labels": [], "entities": []}], "introductionContent": [{"text": "Automatic human-computer dialogue / conversation is a core topic in natural language processing.", "labels": [], "entities": [{"text": "Automatic human-computer dialogue / conversation", "start_pos": 0, "end_pos": 48, "type": "TASK", "confidence": 0.7926389575004578}, {"text": "natural language processing", "start_pos": 68, "end_pos": 95, "type": "TASK", "confidence": 0.6524431904157003}]}, {"text": "There is a boom in research on open-domain chit-chat dialogue systems due to the availability of vast conversational data online.", "labels": [], "entities": []}, {"text": "Most existing models of dialogue systems can be divided into retrieval-based models and generative models.", "labels": [], "entities": []}, {"text": "Given a query, retrieval-based () models search for the most similar query stored in the training corpus and directly copy its corresponding response as the result.", "labels": [], "entities": []}, {"text": "These models cannot create new replies customized for the given queries.", "labels": [], "entities": []}, {"text": "Generative models () learn a query-response mapping to generate responses by maximizing P (r|q), where q is the input query and r is the response.", "labels": [], "entities": []}, {"text": "The most popular generative model is the Sequence-to-Sequence * Work done while Zhiliang Tian was collaborating with Tencent AI Lab.", "labels": [], "entities": [{"text": "generative", "start_pos": 17, "end_pos": 27, "type": "TASK", "confidence": 0.9659835696220398}]}, {"text": "(Seq2Seq) model), which generates new utterances tailored for queries and achieves high coherence between queries and generated utterances.", "labels": [], "entities": []}, {"text": "However, existing generative models often generate uninformative and universal responses ().", "labels": [], "entities": []}, {"text": "To address these issues, several researchers leverage retrieved results R to augment the information used in generative models.", "labels": [], "entities": []}, {"text": "Such methods are called retrieval-augmented generative models and their objectives are to maximize P (r|q, R), where R is one or a few (at most 3 in practice) retrieved results.", "labels": [], "entities": []}, {"text": "Particularly, some researchers ( build the combination of retrieval and generative models, which retrieve one or a few responses r + , and then feeds both the query q and r + into the generative model to maximize P (r|q, R = r + ).", "labels": [], "entities": []}, {"text": "It enriches generated responses by informatively retrieved responses but can only utilize a limited number of retrieved results due to their model architecture.", "labels": [], "entities": []}, {"text": "edit the retrieved response r + with the Seq2Seq model based on the lexical differences between the input query q and its retrieved query q + , whose objective is to maximize P (r|q, R = r + , q + ).", "labels": [], "entities": []}, {"text": "It edits retrieved responses r + to make them relevant to queries, but their edited results rely heavily on the sentence pattern of r + . Generally, the responses from such models are more informative and diverse than those from plain generative models, while maintain better relevance than the retrieved responses.", "labels": [], "entities": []}, {"text": "Although current retrieval-augmented generative models have achieved promising results, they still have following weaknesses: Firstly, they are limited by the quality of the retrieved results.", "labels": [], "entities": []}, {"text": "Retrieval results are less coherent and relevant with query than generative models'.", "labels": [], "entities": []}, {"text": "Irrelevant retrieved results would mislead the response generation.", "labels": [], "entities": []}, {"text": "Secondly, these models can only utilize individual retrieved results, which makes the generation sensitive to those results, leading to a high variance in the performance.", "labels": [], "entities": []}, {"text": "Moreover, the information from very few retrieved results may not be sufficient to enrich the response generation.", "labels": [], "entities": []}, {"text": "In this paper, we propose a memory-augmented generative model that memorizes and utilizes the common characteristics M of groups of queryresponse (q-r) pairs to enhance the response generation by maximizing P (r|q, M ).", "labels": [], "entities": []}, {"text": "The advantage is that our model is less sensitive to the quality of individual q-r pairs and hence increases the robustness of response generation.", "labels": [], "entities": []}, {"text": "In particular, we divide the training corpus into multiple groups by clustering, extract common characteristics of each group, and learn to utilize the characteristics to assist generation.", "labels": [], "entities": []}, {"text": "The idea is illustrated in, the training corpus is divided into two sets of closely related queries and their responses.", "labels": [], "entities": []}, {"text": "We abstract query-response relationship hidden in those q-r pairs, save them to the memory, and use those relationships for response generation.", "labels": [], "entities": [{"text": "response generation", "start_pos": 124, "end_pos": 143, "type": "TASK", "confidence": 0.752358466386795}]}, {"text": "Our contributions can be summaried as: 1.", "labels": [], "entities": []}, {"text": "We are the first to extract information from clusters of query-response pairs using a learnable memory, and to use the information to enhance the performance of conversation systems.", "labels": [], "entities": []}, {"text": "2. We propose a novel framework where the Seq2Seq, autoencoder and clustering model are jointly trained to abstract the training corpus and generate responses.", "labels": [], "entities": []}, {"text": "3. Our model outperforms state-of-the-art generative models and retrieval-augmented generative models in single-round conversation scenarios.", "labels": [], "entities": []}], "datasetContent": [{"text": "In our experiments, we validate the performance of our model on the context-independent (singleround) conversation task setting in which each sample is a query-response (q-r) pair.", "labels": [], "entities": []}, {"text": "We utilize the benchmark dataset (, which collects about 4 millions q-r pairs from a popular Chinese social network website, Weibo.", "labels": [], "entities": [{"text": "Weibo", "start_pos": 125, "end_pos": 130, "type": "DATASET", "confidence": 0.8818127512931824}]}, {"text": "1 For both testing set and validation set, we randomly select 900 queries, and then select randomly 5 responses under each query, thus both our testing set and validation set consist of 4.5k samples.", "labels": [], "entities": []}, {"text": "Sentences are tokenized into word sequences with the Jieba word segmentation tool.", "labels": [], "entities": [{"text": "Jieba word segmentation", "start_pos": 53, "end_pos": 76, "type": "TASK", "confidence": 0.8305655916531881}]}, {"text": "The vocabulary consists of the top 50k tokens (a mixture of Chinese words and characters), covering 99.98% words in this corpus, and all the out-of-vocabulary words are replaced with UNK.", "labels": [], "entities": [{"text": "UNK", "start_pos": 183, "end_pos": 186, "type": "DATASET", "confidence": 0.9153423309326172}]}, {"text": "Following previous work on response generation ( 2.", "labels": [], "entities": [{"text": "response generation", "start_pos": 27, "end_pos": 46, "type": "TASK", "confidence": 0.9094915986061096}]}, {"text": "Sim-A, Sim-M. They measure the relevance between the query and its response by their word embedding cosine similarity.", "labels": [], "entities": []}, {"text": "Sim-A is the similarity between two sentence-level embeddings composed by averaging all word embeddings, while Sim-M is maximal word-word similarity among all the words of two sentences as ( ).", "labels": [], "entities": []}, {"text": "Distinct-1 and Distinct-2 ( are the metrics to evaluate the diversity of generated responses, which count the percentage of unique unigrams and bigrams among all test responses., which is computed by averaging overall the character-level entropy within responses.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: The overall performance for all competing methods on quality, relevance, diversity and informativeness.", "labels": [], "entities": []}, {"text": " Table 2: The performance of MemGM-H with different  memory size K, where K = |D| means the extreme  setting that each sample occupies a memory slot.", "labels": [], "entities": []}, {"text": " Table 3: The statistics on the size of memory slots  (|m|), cluster number (Cluster #), query number  (Query #), and query proportion over all queries (Query  %) for the three memory slot types.", "labels": [], "entities": []}]}