{"title": [{"text": "A Dataset for Semantic Role Labelling of Hindi-English Code-Mixed Tweets", "labels": [], "entities": [{"text": "Semantic Role Labelling of Hindi-English Code-Mixed Tweets", "start_pos": 14, "end_pos": 72, "type": "TASK", "confidence": 0.7855295496327537}]}], "abstractContent": [{"text": "We present a data set of 1460 Hindi-English code-mixed tweets consisting of 20,949 tokens labelled with Proposition Bank labels marking their semantic roles.", "labels": [], "entities": []}, {"text": "We created verb frames for complex predicates present in the corpus and formulated mappings from Paninian dependency labels to Proposition Bank labels.", "labels": [], "entities": []}, {"text": "With the help of these mappings and the dependency tree, we propose a baseline rule based system for Semantic Role Labelling of Hindi-English code-mixed data.", "labels": [], "entities": [{"text": "Semantic Role Labelling of Hindi-English code-mixed data", "start_pos": 101, "end_pos": 157, "type": "TASK", "confidence": 0.8290972454207284}]}, {"text": "We obtain an accuracy of 96.74% for Argument Identification and are able to further classify 73.93% of the labels correctly.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 13, "end_pos": 21, "type": "METRIC", "confidence": 0.9995879530906677}, {"text": "Argument Identification", "start_pos": 36, "end_pos": 59, "type": "TASK", "confidence": 0.7666211128234863}]}, {"text": "While there is relevant ongoing research on Semantic Role Labelling (SRL) and on building tools for code-mixed social media data, this is the first attempt at labelling semantic roles in Hindi-English code-mixed data, to the best of our knowledge.", "labels": [], "entities": [{"text": "Semantic Role Labelling (SRL)", "start_pos": 44, "end_pos": 73, "type": "TASK", "confidence": 0.7914869536956152}]}], "introductionContent": [{"text": "In recent times, social media has gained a lot of popularity and serves as a medium for people across the globe to communicate and express their opinions.", "labels": [], "entities": []}, {"text": "Forums like Facebook and Twitter are used excessively for this purpose.", "labels": [], "entities": []}, {"text": "Increasing availability of such resources online provide a large corpus and subsequently the need for linguistic analysis and tools for automated understanding of this data.", "labels": [], "entities": [{"text": "linguistic analysis", "start_pos": 102, "end_pos": 121, "type": "TASK", "confidence": 0.6981095969676971}]}, {"text": "Code-mixing is a phenomenon observed largely in social media text.", "labels": [], "entities": []}, {"text": "It refers to \"the embedding of linguistic units such as phrases, words and morphemes of one language into an utterance of another language \".", "labels": [], "entities": []}, {"text": "It is usually an intra-sentential phenomenon observed in multilingual societies in colloquial as well as online usage.", "labels": [], "entities": []}, {"text": "Benchmark NLP tools are majorly based on monolingual corpora which strictly follow the patterns and conform to the rules of the given language in terms of structure, syntax, morphology and soon.", "labels": [], "entities": []}, {"text": "However, social media data deviate from these rules.", "labels": [], "entities": []}, {"text": "Hence, numerous technologies perform poorly on social media data irrespective of it being monolingual or a mixture of languages (.", "labels": [], "entities": []}, {"text": "Code-mixed data in particular introduces further variation in the morphology and syntax of the language which leads to poor performance of standard NLP tools.", "labels": [], "entities": []}, {"text": "Following area few instances of Hindi-English code-mixed tweets from the corpus: T1: \"Lagta hai aaj Sri has not spoken to msd\" Translation: \"It looks like Sri has not spoken to MSD today\" T2: \"Lalu Yadav claimed that Yadav quota ke hisab se Umesh Yadav ko ye wkt mil jana chahiye tha\" Translation: \"Lalu Yadav claimed that according to the Yadav quota, Umesh Yadav should have taken a wicket\" In the above two examples we observe how the two languages are mixed in each utterance.", "labels": [], "entities": []}, {"text": "Each tweet has tokens from both English and Hindi.", "labels": [], "entities": []}, {"text": "T2 in particular shows a problem common to social media data.", "labels": [], "entities": [{"text": "T2", "start_pos": 0, "end_pos": 2, "type": "DATASET", "confidence": 0.7695626616477966}]}, {"text": "The token 'wkt' doesn't correspond to any word.", "labels": [], "entities": []}, {"text": "This maybe a typo made by the user or simply a shorthand way of writing adopted by many users online.", "labels": [], "entities": []}, {"text": "Here 'wkt' could mean \"waqta\" which means 'time' in Hindi, or \"wicket\" in the domain of cricket.", "labels": [], "entities": []}, {"text": "As we have the context of the whole tweet and world knowledge about Umesh Yadav who is an Indian cricketer, we are able to disambiguate the usage of the token 'wkt', though this may not always be the case.", "labels": [], "entities": []}, {"text": "In this paper, we present a data set of HindiEnglish code-mixed tweets labelled with semantic roles.", "labels": [], "entities": [{"text": "HindiEnglish code-mixed tweets", "start_pos": 40, "end_pos": 70, "type": "DATASET", "confidence": 0.862806499004364}]}, {"text": "These labels provide us with information of the role played by an argument with respect to a verb in a given sentence.", "labels": [], "entities": []}, {"text": "We seek to gain semantic information irrespective of the syntactic variation a sentence or an utterance may have.", "labels": [], "entities": []}, {"text": "Semantic Role Labelling for code-mixed data will aid in better understanding of these texts and further the research of any understanding based tasks such as information retrieval (, document classification (, questioning answering systems and soon.", "labels": [], "entities": [{"text": "Semantic Role Labelling", "start_pos": 0, "end_pos": 23, "type": "TASK", "confidence": 0.7023263971010844}, {"text": "information retrieval", "start_pos": 158, "end_pos": 179, "type": "TASK", "confidence": 0.7750149667263031}, {"text": "document classification", "start_pos": 183, "end_pos": 206, "type": "TASK", "confidence": 0.7738909423351288}, {"text": "questioning answering", "start_pos": 210, "end_pos": 231, "type": "TASK", "confidence": 0.6775934100151062}]}, {"text": "A Proposition Bank (Propbank) is a corpus of annotated semantic predicate-argument labels).", "labels": [], "entities": []}, {"text": "This is done with the help of verb frame files and the Proposition Bank tagset.", "labels": [], "entities": [{"text": "Proposition Bank tagset", "start_pos": 55, "end_pos": 78, "type": "DATASET", "confidence": 0.8338363170623779}]}, {"text": "The frame files contain the semantic roles needed for each verb and all the possible context variations of each verb (sense of the verb).", "labels": [], "entities": []}, {"text": "To annotate, one must first identify the 'sense id' (Roleset id) of the verb present according to its usage, and then mark the corresponding labels present in its frame file.", "labels": [], "entities": []}, {"text": "We follow exactly this process for the manual annotation of our corpus.", "labels": [], "entities": []}, {"text": "The structure of this paper is as follows.", "labels": [], "entities": []}, {"text": "Section 2 talks about relevant work in the domains of Semantic Role Labelling and code-mixed data.", "labels": [], "entities": [{"text": "Semantic Role Labelling", "start_pos": 54, "end_pos": 77, "type": "TASK", "confidence": 0.8512975176175436}]}, {"text": "We discuss our annotation scheme in section 3.", "labels": [], "entities": []}, {"text": "In section 4, we propose a baseline rule based system for manual annotation of the data using dependency label information.", "labels": [], "entities": []}, {"text": "Section 5 talks about the results and working of our baseline system.", "labels": [], "entities": []}, {"text": "We analyse cases of high errors in classification and explore reasons for the same.", "labels": [], "entities": [{"text": "classification", "start_pos": 35, "end_pos": 49, "type": "TASK", "confidence": 0.9501410126686096}]}, {"text": "In Section 6 we shed light on future scope and conclude the paper.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 4: Distribution of unique Complex Predicates in  the corpus", "labels": [], "entities": []}, {"text": " Table 8: Data Distribution 3.2.2", "labels": [], "entities": [{"text": "Data Distribution 3.2.2", "start_pos": 10, "end_pos": 33, "type": "DATASET", "confidence": 0.7788531184196472}]}, {"text": " Table 14. We also compute  our scores separately for Numbered arguments and  Modifier arguments.", "labels": [], "entities": []}, {"text": " Table 14: Accuracy scores achieved for identification  of Numbered and Modifier arguments by our rule based  model along with their distribution in the data set.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 11, "end_pos": 19, "type": "METRIC", "confidence": 0.9964168071746826}]}, {"text": " Table 15: Precision, Recall and F-scores achieved for  all labels with our rule based model. Also shows over- all distribution of the labels in our data set.", "labels": [], "entities": [{"text": "Precision", "start_pos": 11, "end_pos": 20, "type": "METRIC", "confidence": 0.9993434548377991}, {"text": "Recall", "start_pos": 22, "end_pos": 28, "type": "METRIC", "confidence": 0.9965470433235168}, {"text": "F-scores", "start_pos": 33, "end_pos": 41, "type": "METRIC", "confidence": 0.9978442192077637}]}]}