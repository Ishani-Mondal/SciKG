{"title": [{"text": "Negative Lexically Constrained Decoding for Paraphrase Generation", "labels": [], "entities": [{"text": "Negative Lexically Constrained Decoding", "start_pos": 0, "end_pos": 39, "type": "TASK", "confidence": 0.7661618888378143}]}], "abstractContent": [{"text": "Paraphrase generation can be regarded as monolingual translation.", "labels": [], "entities": [{"text": "Paraphrase generation", "start_pos": 0, "end_pos": 21, "type": "TASK", "confidence": 0.9233017861843109}]}, {"text": "Unlike bilingual machine translation, paraphrase generation rewrites only a limited portion of an input sentence.", "labels": [], "entities": [{"text": "bilingual machine translation", "start_pos": 7, "end_pos": 36, "type": "TASK", "confidence": 0.6989768147468567}, {"text": "paraphrase generation", "start_pos": 38, "end_pos": 59, "type": "TASK", "confidence": 0.9178853929042816}]}, {"text": "Hence, previous methods based on machine translation often perform conservatively to fail to make necessary rewrites.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 33, "end_pos": 52, "type": "TASK", "confidence": 0.7090413123369217}]}, {"text": "To solve this problem, we propose a neural model for paraphrase generation that first identifies words in the source sentence that should be paraphrased.", "labels": [], "entities": [{"text": "paraphrase generation", "start_pos": 53, "end_pos": 74, "type": "TASK", "confidence": 0.9546750485897064}]}, {"text": "Then, these words are paraphrased by the negative lexically constrained decoding that avoids outputting these words as they are.", "labels": [], "entities": []}, {"text": "Experiments on text simplification and formality transfer show that our model improves the quality of paraphrasing by making necessary rewrites to an input sentence.", "labels": [], "entities": [{"text": "text simplification", "start_pos": 15, "end_pos": 34, "type": "TASK", "confidence": 0.7428946197032928}, {"text": "formality transfer", "start_pos": 39, "end_pos": 57, "type": "TASK", "confidence": 0.7978478670120239}]}], "introductionContent": [{"text": "Paraphrase generation is a generic term for tasks that generate sentences semantically equivalent to input sentences.", "labels": [], "entities": [{"text": "Paraphrase generation", "start_pos": 0, "end_pos": 21, "type": "TASK", "confidence": 0.8766229450702667}]}, {"text": "These techniques make it possible to control information other than the meaning of the text.", "labels": [], "entities": []}, {"text": "Typical paraphrase generation tasks include subtasks such as text simplification to control complexity, formality transfer to control formality, grammatical error correction to control fluency, and sentence compression to control sentence length.", "labels": [], "entities": [{"text": "paraphrase generation", "start_pos": 8, "end_pos": 29, "type": "TASK", "confidence": 0.8913100361824036}, {"text": "formality transfer", "start_pos": 104, "end_pos": 122, "type": "TASK", "confidence": 0.7102069556713104}, {"text": "sentence compression", "start_pos": 198, "end_pos": 218, "type": "TASK", "confidence": 0.7411163449287415}]}, {"text": "These paraphrase generation applications not only support communication and language learning but also contribute to the performance improvement of other natural language processing applications.", "labels": [], "entities": [{"text": "paraphrase generation", "start_pos": 6, "end_pos": 27, "type": "TASK", "confidence": 0.7726045548915863}]}, {"text": "Paraphrase generation can be considered as a monolingual machine translation problem.", "labels": [], "entities": [{"text": "Paraphrase generation", "start_pos": 0, "end_pos": 21, "type": "TASK", "confidence": 0.9445856809616089}, {"text": "machine translation", "start_pos": 57, "end_pos": 76, "type": "TASK", "confidence": 0.7818378508090973}]}, {"text": "Sentential paraphrases with different complexities ( and formalities were created manually, and parallel corpora specialized for each subtask were constructed.", "labels": [], "entities": []}, {"text": "As in the field of machine translation, phrasebased ( and syntax-based () methods were proposed early.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 19, "end_pos": 38, "type": "TASK", "confidence": 0.7381322979927063}]}, {"text": "In recent years, the encode-decoder model based on the attention mechanism () has been studied, inspired by the success of neural machine translation (.", "labels": [], "entities": [{"text": "neural machine translation", "start_pos": 123, "end_pos": 149, "type": "TASK", "confidence": 0.7504447897275289}]}, {"text": "In machine translation, all words appearing in an input sentence must be rewritten in the target language.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 3, "end_pos": 22, "type": "TASK", "confidence": 0.7687464356422424}]}, {"text": "However, paraphrase generation does not require rewriting of all words.", "labels": [], "entities": [{"text": "paraphrase generation", "start_pos": 9, "end_pos": 30, "type": "TASK", "confidence": 0.9692281186580658}]}, {"text": "When some criteria are provided, words not satisfying the criteria in the input sentence are identified and rewritten.", "labels": [], "entities": []}, {"text": "For example, the criterion for text simplification is the textual complexity, and rewrites complex words to simpler synonymous words.", "labels": [], "entities": [{"text": "text simplification", "start_pos": 31, "end_pos": 50, "type": "TASK", "confidence": 0.7916175127029419}]}, {"text": "Owing to the characteristics of the task where only a limited portion of an input sentence needs to be rewritten, previous methods based on machine translation often perform conservatively and fail to produce necessary rewrites (.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 140, "end_pos": 159, "type": "TASK", "confidence": 0.7558782398700714}]}, {"text": "To solve the problem of conservative paraphrasing that copies many parts of the input sentence, we propose a neural model for paraphrase generation that first identifies words in the source sentence requiring paraphrasing.", "labels": [], "entities": [{"text": "paraphrase generation", "start_pos": 126, "end_pos": 147, "type": "TASK", "confidence": 0.8544208407402039}]}, {"text": "Subsequently, these words are paraphrased by the negative lexically constrained decoding that avoids outputting them as they are.", "labels": [], "entities": []}, {"text": "We evaluate the performance of the proposed method with two major paraphrase generation tasks.", "labels": [], "entities": [{"text": "paraphrase generation", "start_pos": 66, "end_pos": 87, "type": "TASK", "confidence": 0.7258580923080444}]}, {"text": "Experiments on text simplification () and formality transfer ( show that our model improves the quality of paraphrasing by performing necessary rewrites to an input sentence.", "labels": [], "entities": [{"text": "text simplification", "start_pos": 15, "end_pos": 34, "type": "TASK", "confidence": 0.7634743452072144}, {"text": "formality transfer", "start_pos": 42, "end_pos": 60, "type": "TASK", "confidence": 0.8263922035694122}]}], "datasetContent": [{"text": "We evaluate the performance of the proposed method on two major paraphrase generation tasks.", "labels": [], "entities": [{"text": "paraphrase generation tasks", "start_pos": 64, "end_pos": 91, "type": "TASK", "confidence": 0.8429860472679138}]}, {"text": "We conduct experiments on text simplification and formality transfer using datasets shown in Table 1.", "labels": [], "entities": [{"text": "text simplification", "start_pos": 26, "end_pos": 45, "type": "TASK", "confidence": 0.813448965549469}, {"text": "formality transfer", "start_pos": 50, "end_pos": 68, "type": "TASK", "confidence": 0.8040435612201691}]}, {"text": "For text simplification, we identify complex words in the input sentence and generate simple paraphrase sentence without using these complex words.", "labels": [], "entities": [{"text": "text simplification", "start_pos": 4, "end_pos": 23, "type": "TASK", "confidence": 0.7582035064697266}]}, {"text": "Similarly, for formality transfer, we identify informal words in the input sentence and generate formal paraphrase sentence without using these informal words.", "labels": [], "entities": [{"text": "formality transfer", "start_pos": 15, "end_pos": 33, "type": "TASK", "confidence": 0.7983768284320831}]}], "tableCaptions": [{"text": " Table 1: Number of sentence pairs for each dataset.", "labels": [], "entities": []}, {"text": " Table 2: Performance of our paraphrase generation models on text simplification (complex \u2192 simple) in Newsela  dataset and formality transfer (informal \u2192 formal) in GYAFC dataset. For both RNN and SAN models, our method  consistently improves BLEU and SARI scores across styles or domains. In addition, a consistent improvement on  Add and Del means that our method promotes active rewriting.", "labels": [], "entities": [{"text": "paraphrase generation", "start_pos": 29, "end_pos": 50, "type": "TASK", "confidence": 0.7552944421768188}, {"text": "Newsela  dataset", "start_pos": 103, "end_pos": 119, "type": "DATASET", "confidence": 0.9883281588554382}, {"text": "formality transfer", "start_pos": 124, "end_pos": 142, "type": "TASK", "confidence": 0.7094647735357285}, {"text": "GYAFC dataset", "start_pos": 166, "end_pos": 179, "type": "DATASET", "confidence": 0.9891965091228485}, {"text": "BLEU", "start_pos": 244, "end_pos": 248, "type": "METRIC", "confidence": 0.9985848665237427}]}, {"text": " Table 3: Comparison with previous models on text simplification in Newsela dataset and formality transfer in  GYAFC dataset. Our models achieved the best BLEU scores across styles and domains.", "labels": [], "entities": [{"text": "Newsela dataset", "start_pos": 68, "end_pos": 83, "type": "DATASET", "confidence": 0.9894748628139496}, {"text": "formality transfer", "start_pos": 88, "end_pos": 106, "type": "TASK", "confidence": 0.773871511220932}, {"text": "GYAFC dataset", "start_pos": 111, "end_pos": 124, "type": "DATASET", "confidence": 0.981514036655426}, {"text": "BLEU", "start_pos": 155, "end_pos": 159, "type": "METRIC", "confidence": 0.999038577079773}]}]}