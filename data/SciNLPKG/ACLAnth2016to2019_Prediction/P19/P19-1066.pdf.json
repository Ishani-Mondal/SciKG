{"title": [], "abstractContent": [{"text": "A key challenge in coreference resolution is to capture properties of entity clusters, and use those in the resolution process.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 19, "end_pos": 41, "type": "TASK", "confidence": 0.9647295773029327}]}, {"text": "Here we provide a simple and effective approach for achieving this, via an \"Entity Equalization\" mechanism.", "labels": [], "entities": [{"text": "Entity Equalization", "start_pos": 76, "end_pos": 95, "type": "TASK", "confidence": 0.6006762236356735}]}, {"text": "The Equalization approach represents each mention in a cluster via an approximation of the sum of all mentions in the cluster.", "labels": [], "entities": [{"text": "Equalization", "start_pos": 4, "end_pos": 16, "type": "TASK", "confidence": 0.9793545007705688}]}, {"text": "We show how this can be done in a fully differentiable end-to-end manner, thus enabling high-order inferences in the resolution process.", "labels": [], "entities": [{"text": "resolution process", "start_pos": 117, "end_pos": 135, "type": "TASK", "confidence": 0.8881358206272125}]}, {"text": "Our approach, which also employs BERT embeddings, results in new state-of-the-art results on the CoNLL-2012 corefer-ence resolution task, improving average F1 by 3.6%.", "labels": [], "entities": [{"text": "BERT", "start_pos": 33, "end_pos": 37, "type": "METRIC", "confidence": 0.9873096346855164}, {"text": "CoNLL-2012 corefer-ence resolution task", "start_pos": 97, "end_pos": 136, "type": "TASK", "confidence": 0.8227998316287994}, {"text": "F1", "start_pos": 156, "end_pos": 158, "type": "METRIC", "confidence": 0.9899888038635254}]}], "introductionContent": [{"text": "Coreference resolution is the task of grouping mentions into entities.", "labels": [], "entities": [{"text": "Coreference resolution", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.9108467102050781}, {"text": "grouping mentions into entities", "start_pos": 38, "end_pos": 69, "type": "TASK", "confidence": 0.8305754065513611}]}, {"text": "A key challenge in this task is that information about an entity is spread across multiple mentions.", "labels": [], "entities": []}, {"text": "Thus, deciding whether to assign a given mention to a candidate entity could require entity-level information that needs to be aggregated from all mentions.", "labels": [], "entities": []}, {"text": "Most coreference resolution systems rely on pairwise scoring of entity mentions.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 5, "end_pos": 27, "type": "TASK", "confidence": 0.9565941393375397}]}, {"text": "As such they are prone to missing global entity information.", "labels": [], "entities": []}, {"text": "The problem of entity-level representation (also referred to as high-order coreference models) has attracted considerable interest recently, with methods ranging from imitation learning to iterative refinement ( ).", "labels": [], "entities": [{"text": "entity-level representation", "start_pos": 15, "end_pos": 42, "type": "TASK", "confidence": 0.7137695550918579}]}, {"text": "Specifically,  tackled this problem by iteratively averaging the antecedents of each mention to create mention representations that are more \"global\" (i.e., reflect information about the entity to which the mention refers).", "labels": [], "entities": []}, {"text": "Here we propose an approach that provides an entity-level representation in a simple and intuitive manner, and also facilitates end-to-end optimization.", "labels": [], "entities": []}, {"text": "Our \"Entity Equalization\" approach posits that each entity should be represented via the sum of its corresponding mention representations.", "labels": [], "entities": [{"text": "Entity Equalization\"", "start_pos": 5, "end_pos": 25, "type": "TASK", "confidence": 0.8139971295992533}]}, {"text": "It is not immediately obvious how to perform this equalization, which relies on the entity-to-mention mapping, but we provide a natural smoothed representation of this mapping, and demonstrate how to use it for equalization.", "labels": [], "entities": [{"text": "equalization", "start_pos": 50, "end_pos": 62, "type": "TASK", "confidence": 0.9698044657707214}, {"text": "equalization", "start_pos": 211, "end_pos": 223, "type": "TASK", "confidence": 0.9751139879226685}]}, {"text": "Now that each mention contains information about all its corresponding entities, we can use a standard pairwise scoring model, and this model will be able to use global entity-level information.", "labels": [], "entities": []}, {"text": "Similar to recent coreference models, our approach uses contextual embeddings as input mention representations.", "labels": [], "entities": []}, {"text": "While previous approaches employed the ELMo model ( , we propose to use BERT embeddings, motivated by the impressive empirical performance of BERT on other tasks.", "labels": [], "entities": [{"text": "BERT", "start_pos": 72, "end_pos": 76, "type": "METRIC", "confidence": 0.9821780323982239}, {"text": "BERT", "start_pos": 142, "end_pos": 146, "type": "METRIC", "confidence": 0.8809164762496948}]}, {"text": "It is challenging to apply BERT to the coreference resolution setting because BERT is limited to a fixed sequence length which is shorter than most coreference resolution documents.", "labels": [], "entities": [{"text": "BERT", "start_pos": 27, "end_pos": 31, "type": "METRIC", "confidence": 0.94395512342453}, {"text": "coreference resolution", "start_pos": 39, "end_pos": 61, "type": "TASK", "confidence": 0.9378766417503357}, {"text": "BERT", "start_pos": 78, "end_pos": 82, "type": "METRIC", "confidence": 0.9942967295646667}, {"text": "coreference resolution", "start_pos": 148, "end_pos": 170, "type": "TASK", "confidence": 0.8294680118560791}]}, {"text": "We show that this can be done by using BERT in a fully convolutional manner.", "labels": [], "entities": [{"text": "BERT", "start_pos": 39, "end_pos": 43, "type": "METRIC", "confidence": 0.9945501685142517}]}, {"text": "Our work is the first to use BERT for the task of coreference resolution, and we demonstrate that this results in significant improvement over current state-of-the-art.", "labels": [], "entities": [{"text": "BERT", "start_pos": 29, "end_pos": 33, "type": "METRIC", "confidence": 0.9974898099899292}, {"text": "coreference resolution", "start_pos": 50, "end_pos": 72, "type": "TASK", "confidence": 0.972562164068222}]}, {"text": "In summary, our contributions are: a.", "labels": [], "entities": []}, {"text": "A simple and intuitive approach for entity-level representation via the notion of Entity-Equalization. b. The first use of BERT embeddings in coreferenceresolution. c. New state-of-the-art performance on the CoNLL-2012 coreference resolution task, improving over previous F1 performance by 3.6%.", "labels": [], "entities": [{"text": "BERT", "start_pos": 123, "end_pos": 127, "type": "METRIC", "confidence": 0.986276388168335}, {"text": "CoNLL-2012 coreference resolution task", "start_pos": 208, "end_pos": 246, "type": "TASK", "confidence": 0.773922011256218}]}], "datasetContent": [{"text": "Data for all our experiments is taken from the English portion of the CoNLL-2012 coreference resolution tasks.", "labels": [], "entities": [{"text": "CoNLL-2012 coreference resolution tasks", "start_pos": 70, "end_pos": 109, "type": "TASK", "confidence": 0.7581403702497482}]}, {"text": "Our experimental setup is very similar to , and our code is built on theirs.", "labels": [], "entities": []}, {"text": "We did not change the optimizer or any of the training hyperparameters.", "labels": [], "entities": []}, {"text": "The following changes were made to the model: \u2022 We used BERT word embeddings instead of ELMo as input to the LSTM (see Section 4).", "labels": [], "entities": [{"text": "BERT", "start_pos": 56, "end_pos": 60, "type": "METRIC", "confidence": 0.9831191897392273}]}, {"text": "\u2022 We replaced the span representation refinement mechanism with our Entity Equalization approach (see Section 3).", "labels": [], "entities": [{"text": "span representation refinement", "start_pos": 18, "end_pos": 48, "type": "TASK", "confidence": 0.8355508844057719}, {"text": "Entity Equalization", "start_pos": 68, "end_pos": 87, "type": "TASK", "confidence": 0.6730378121137619}]}], "tableCaptions": [{"text": " Table 1: Results on the test set of the English CoNLL-2012 shared task. The average F1 of MUC, B 3 and CEAF \u03c64  is the main evaluation metric.", "labels": [], "entities": [{"text": "English CoNLL-2012 shared task", "start_pos": 41, "end_pos": 71, "type": "DATASET", "confidence": 0.890201061964035}, {"text": "F1", "start_pos": 85, "end_pos": 87, "type": "METRIC", "confidence": 0.9977548718452454}, {"text": "MUC", "start_pos": 91, "end_pos": 94, "type": "DATASET", "confidence": 0.5320500135421753}, {"text": "CEAF \u03c64", "start_pos": 104, "end_pos": 111, "type": "DATASET", "confidence": 0.5022660344839096}]}]}