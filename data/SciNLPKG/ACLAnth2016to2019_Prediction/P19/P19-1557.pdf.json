{"title": [{"text": "Towards Integration of Statistical Hypothesis Tests into Deep Neural Networks", "labels": [], "entities": []}], "abstractContent": [{"text": "We report our ongoing work about anew deep architecture working in tandem with a statistical test procedure for jointly training texts and their label descriptions for multi-label and multi-class classification tasks.", "labels": [], "entities": [{"text": "multi-class classification tasks", "start_pos": 184, "end_pos": 216, "type": "TASK", "confidence": 0.7628460228443146}]}, {"text": "A statistical hypothesis testing method is used to extract the most informative words for each given class.", "labels": [], "entities": []}, {"text": "These words are used as a class description for more label-aware text classification.", "labels": [], "entities": [{"text": "label-aware text classification", "start_pos": 53, "end_pos": 84, "type": "TASK", "confidence": 0.6320332288742065}]}, {"text": "Intuition is to help the model to concentrate on more informative words rather than more frequent ones.", "labels": [], "entities": []}, {"text": "The model leverages the use of label descriptions in addition to the input text to enhance text classification performance.", "labels": [], "entities": [{"text": "text classification", "start_pos": 91, "end_pos": 110, "type": "TASK", "confidence": 0.744185596704483}]}, {"text": "Our method is entirely data-driven, has no dependency on other sources of information than the training data, and is adaptable to different classification problems by providing appropriate training data without major hyper-parameter tuning.", "labels": [], "entities": []}, {"text": "We trained and tested our system on several publicly available datasets, where we managed to improve the state-of-the-art on one set with a high margin, and to obtain competitive results on all other ones.", "labels": [], "entities": []}], "introductionContent": [{"text": "Text classification is a complex problem in Natural Language Processing (NLP) with lots of applications from sentiment analysis to question answering) or abusive language detection, to name just a few.", "labels": [], "entities": [{"text": "Text classification", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.8228684067726135}, {"text": "sentiment analysis", "start_pos": 109, "end_pos": 127, "type": "TASK", "confidence": 0.9362347722053528}, {"text": "question answering", "start_pos": 131, "end_pos": 149, "type": "TASK", "confidence": 0.7103201448917389}, {"text": "abusive language detection", "start_pos": 154, "end_pos": 180, "type": "TASK", "confidence": 0.6214667956034342}]}, {"text": "Text classification is defined as the task of assigning a certain pre-defined class to a document.", "labels": [], "entities": [{"text": "Text classification", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.7980251312255859}]}, {"text": "The number of classes can be arbitrarily large in multi-class classification, whereas there are only two classes for binary classification.", "labels": [], "entities": []}, {"text": "In multilabel classification, the number of labels attached to each document is not known and usually larger than one, while in multi-class classification, only one class is assigned to each document.", "labels": [], "entities": [{"text": "multilabel classification", "start_pos": 3, "end_pos": 28, "type": "TASK", "confidence": 0.7837932705879211}]}, {"text": "There exist numerous approaches for text classification, ranging from simple hand-crafted lexicallevel features with Naive Bayes or Support Vector Machines (SVM) ( to self-learning approaches with Deep Neural Networks (DNN) (.", "labels": [], "entities": [{"text": "text classification", "start_pos": 36, "end_pos": 55, "type": "TASK", "confidence": 0.789237767457962}]}, {"text": "For the latter, several architectures such as Convolutional or Recurrent Neural Networks (CNN or RNN)) have been proposed.", "labels": [], "entities": []}, {"text": "These architectures learn different levels of textual representation in their layers, which are an essential source of information for the classification process.", "labels": [], "entities": []}, {"text": "As an alternative, attention networks are also introduced ( to capture the features with the highest discriminative power regarding the class and irrespective of their distance.", "labels": [], "entities": []}, {"text": "On the other hand, the field of Statistics has since long developed and optimized various methods to capture 'relevant' properties of a given dataset.", "labels": [], "entities": []}, {"text": "In this work, we extend DNNs with statistical hypothesis testing methods to enhance their performance in assessing feature relevancy on the input data.", "labels": [], "entities": []}, {"text": "More precisely, our approach works as follows: -For each class, we generate a class description, which is a set of 'most informative words' that will help to distinguish the class from others.", "labels": [], "entities": []}, {"text": "-To achieve this, we apply two statistical hypothesis testing approaches called \u03c7 2 test) and Analysis of Variance test (ANOVA).", "labels": [], "entities": [{"text": "Analysis of Variance test (ANOVA)", "start_pos": 94, "end_pos": 127, "type": "METRIC", "confidence": 0.8123316935130528}]}, {"text": "-We then extend a DNN that is based on bidirectional Gated Recurrent Units (GRU) with an additional input channel for encoding the class descriptions.", "labels": [], "entities": []}, {"text": "This channel uses attention, in addition, to enable the network to focus on the most informative words for each document and given each class.", "labels": [], "entities": []}, {"text": "Our experiments on four standard datasets show that this approach can already reach or even outperform state-of-the-art solutions for these datasets.", "labels": [], "entities": []}, {"text": "While this is very promising, we want to stress already here that this is ongoing work, and that it needs extensive further experiments to fully understand when and why the proposed method works.", "labels": [], "entities": []}, {"text": "The main contributions of this work are the use of statistical hypothesis testing methods specifically for class descriptor extraction rather than feature extraction, and anew deep architecture working in tandem with a statistical test procedure with state-of-the-art performance in multilabel and multi-class classification.", "labels": [], "entities": [{"text": "class descriptor extraction", "start_pos": 107, "end_pos": 134, "type": "TASK", "confidence": 0.6546502808729807}, {"text": "feature extraction", "start_pos": 147, "end_pos": 165, "type": "TASK", "confidence": 0.7043517380952835}, {"text": "multi-class classification", "start_pos": 298, "end_pos": 324, "type": "TASK", "confidence": 0.6981332153081894}]}, {"text": "We organize the remaining content into the following sections.", "labels": [], "entities": []}, {"text": "After a review on state of the art in Section 2, we describe how we extract the class descriptors in Section 3.", "labels": [], "entities": []}, {"text": "Then we continue with a description of our deep architecture, followed by the system setup for our experiments in Sections 4 and 5, respectively.", "labels": [], "entities": []}, {"text": "Finally we report our results in Section 6 and conclude in Section 7.", "labels": [], "entities": []}], "datasetContent": [{"text": "We also ran preliminary experiments on class description vectors with different dimensions (50 vs. 100), indicated by the suffix of each name in.", "labels": [], "entities": []}, {"text": "By dimension, we mean the number of words given each label and not the dimension of word vectors which are all the same for both channels (i.e., 300).", "labels": [], "entities": []}, {"text": "It turns out that in all but one case, the more words, the better the performance.", "labels": [], "entities": []}, {"text": "However, we did not get statistically significant results with class descriptors with dimensions higher than 100.", "labels": [], "entities": []}, {"text": "It seems that the range 50-100 is the optimal dimension for this approach and these datasets.", "labels": [], "entities": []}, {"text": "Bigger vectors such as 150 did not yield any statistically significant improvement in performance, and 200-, and 300-dimensional vectors deteriorated the performance.", "labels": [], "entities": []}, {"text": "We observed that the decline in the performance comes mainly from two sources: the network over-fit, and the similar words in different classes.", "labels": [], "entities": []}, {"text": "By increasing the number of informative words, the number of similar words in different classes increases which leads to sub-optimal classification decision boundaries.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Types, number of classes, and number of train- ing/testing samples in the datasets used for training in  this work", "labels": [], "entities": []}, {"text": " Table 3: The results of our system on the Hate Speech  and Kaggle datasets. With one exception, in all cases  longer class description leads to better performance.  The results of the Kaggle dataset are only reported in  AUC to be comparable with other systems in the multi- label category.", "labels": [], "entities": [{"text": "Hate Speech  and Kaggle datasets", "start_pos": 43, "end_pos": 75, "type": "DATASET", "confidence": 0.7874290347099304}, {"text": "Kaggle dataset", "start_pos": 185, "end_pos": 199, "type": "DATASET", "confidence": 0.7839770913124084}, {"text": "AUC", "start_pos": 222, "end_pos": 225, "type": "DATASET", "confidence": 0.9151480197906494}]}, {"text": " Table 4: Competitive results on DBpedia and AG News  reported in accuracy (%) without any hyper-parameter  tuning.", "labels": [], "entities": [{"text": "DBpedia", "start_pos": 33, "end_pos": 40, "type": "DATASET", "confidence": 0.9392237067222595}, {"text": "AG News", "start_pos": 45, "end_pos": 52, "type": "DATASET", "confidence": 0.9501517713069916}, {"text": "accuracy", "start_pos": 66, "end_pos": 74, "type": "METRIC", "confidence": 0.9996395111083984}]}]}