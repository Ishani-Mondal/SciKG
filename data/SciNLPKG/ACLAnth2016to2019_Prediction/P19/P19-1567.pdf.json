{"title": [{"text": "Improving Neural Conversational Models with Entropy-Based Data Filtering", "labels": [], "entities": [{"text": "Improving Neural Conversational Models", "start_pos": 0, "end_pos": 38, "type": "TASK", "confidence": 0.8958523124456406}]}], "abstractContent": [{"text": "Current neural network-based conversational models lack diversity and generate boring responses to open-ended utterances.", "labels": [], "entities": []}, {"text": "Priors such as persona, emotion, or topic provide additional information to dialog models to aid response generation, but annotating a dataset with priors is expensive and such annotations are rarely available.", "labels": [], "entities": [{"text": "response generation", "start_pos": 97, "end_pos": 116, "type": "TASK", "confidence": 0.7313318103551865}]}, {"text": "While previous methods for improving the quality of open-domain response generation focused on either the underlying model or the training objective, we present a method of filtering dialog datasets by removing generic utterances from training data using a simple entropy-based approach that does not require human supervision.", "labels": [], "entities": [{"text": "open-domain response generation", "start_pos": 52, "end_pos": 83, "type": "TASK", "confidence": 0.6400147676467896}]}, {"text": "We conduct extensive experiments with different variations of our method, and compare dialog models across 17 evaluation metrics to show that training on datasets filtered this way results in better conversational quality as chat-bots learn to output more diverse responses.", "labels": [], "entities": []}], "introductionContent": [{"text": "Current open-domain neural conversational models (NCM) are trained on pairs of source and target utterances in an effort to maximize the likelihood of each target given the source (.", "labels": [], "entities": []}, {"text": "However, real-world conversations are much more complex, and a plethora of suitable targets (responses) can be adequate fora given input.", "labels": [], "entities": []}, {"text": "We propose a data filtering approach where the \"most open-ended\" inputs -determined by calculating the entropy of the distribution over target utterances -are excluded from the training set.", "labels": [], "entities": [{"text": "data filtering", "start_pos": 13, "end_pos": 27, "type": "TASK", "confidence": 0.7401796877384186}]}, {"text": "We show that dialog models can be improved using this simple unsupervised method which can be applied to any conversational dataset.", "labels": [], "entities": []}, {"text": "We conduct several experiments to uncover how some of the current open-domain dialog evaluation methods behave with respect to overfitting and random data.", "labels": [], "entities": []}, {"text": "Our software for filtering dialog data and automatic evaluation using 17 metrics is released on GitHub under an MIT license 12 .", "labels": [], "entities": []}], "datasetContent": [{"text": "We use transformer () as our dialog model, an encoder-decoder architecture relying solely on attention mechanisms.", "labels": [], "entities": []}, {"text": "transformer has already been applied to a plethora of natural language processing tasks, including dialog modeling (.", "labels": [], "entities": [{"text": "dialog modeling", "start_pos": 99, "end_pos": 114, "type": "TASK", "confidence": 0.8223798871040344}]}, {"text": "We used the official implementation 6 (see Appendix A.2 fora report of hyperparameters).", "labels": [], "entities": []}, {"text": "In this section the model and parameter setups are presented along with 17 evaluation metrics.", "labels": [], "entities": []}, {"text": "Limitations of these metrics are discussed and a comparison between our filtering methods is presented on DailyDialog (Section 5.3), and other datasets (Section 5.4).", "labels": [], "entities": [{"text": "DailyDialog", "start_pos": 106, "end_pos": 117, "type": "DATASET", "confidence": 0.9616727828979492}]}, {"text": "As mentioned in Section 2, automatic evaluation of chatbots is an open research problem.", "labels": [], "entities": []}, {"text": "In order to get as complete a picture as possible, we use 17 metrics that have been applied to dialog models over the past years, briefly described below.", "labels": [], "entities": []}, {"text": "These metrics assess different aspects of response quality, thus models should be compared on the whole set of metrics.", "labels": [], "entities": []}, {"text": "The per-word entropy H w = \u2212 1 |U | w\u2208U log 2 p(w) of responses is measured to determine their non-genericness ().", "labels": [], "entities": []}, {"text": "Probabilities are calculated based on frequencies observed in the training data.", "labels": [], "entities": [{"text": "Probabilities", "start_pos": 0, "end_pos": 13, "type": "METRIC", "confidence": 0.9149816036224365}]}, {"text": "We introduce the bigram version of this metric, to measure diversity at the bigram level as well.", "labels": [], "entities": []}, {"text": "Utterance entropy is the product of H wand |U |, also reported at the bigram level.", "labels": [], "entities": [{"text": "Utterance entropy", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.7677217423915863}]}, {"text": "We use the KL divergence between model and ground truth (GT) response sets to measure how well a model can approximate the GT distribution of words.", "labels": [], "entities": []}, {"text": "Specifically, we define distributions p gt and pm based on each set of responses and calculate the KL divergence pm(w) for each GT response.", "labels": [], "entities": [{"text": "pm", "start_pos": 47, "end_pos": 49, "type": "METRIC", "confidence": 0.9708564877510071}, {"text": "KL divergence pm(w)", "start_pos": 99, "end_pos": 118, "type": "METRIC", "confidence": 0.8669119377930959}]}, {"text": "The bigram version of this metric is also reported.", "labels": [], "entities": []}, {"text": "Embedding average, extrema, and greedy are widely used metrics (.", "labels": [], "entities": []}, {"text": "average measures the cosine similarity between the averages of word vectors of response and target utterances.", "labels": [], "entities": []}, {"text": "extrema constructs a representation by taking the greatest absolute value for each dimension among the word vectors in the response and target utterances and measures the cosine similarity between them.", "labels": [], "entities": []}, {"text": "Finally, greedy matches each response token to a target token (and vice versa) based on the cosine similarity between their embeddings and averages the total score across all words.", "labels": [], "entities": []}, {"text": "For word embeddings and average word embedding representations, we used the same setup as in AVG-EMBEDDING.", "labels": [], "entities": [{"text": "AVG-EMBEDDING", "start_pos": 93, "end_pos": 106, "type": "DATASET", "confidence": 0.9141651391983032}]}, {"text": "We measure the cosine similarity between pairs of input and response (.", "labels": [], "entities": []}, {"text": "Although a coherence value of 1 would indicate that input and response are the same, generally a higher value seems better as model responses tend to have lower coherence than targets.", "labels": [], "entities": []}, {"text": "Distinct-1 and distinct-2 are widely used in the literature (, measuring the ratio of unique unigrams/bigrams to the total number of unigrams/bigrams in a set of responses.", "labels": [], "entities": [{"text": "Distinct-1", "start_pos": 0, "end_pos": 10, "type": "METRIC", "confidence": 0.9468276500701904}]}, {"text": "However, they are very sensitive to the test data size, since increasing the number of examples in itself lowers their value.", "labels": [], "entities": []}, {"text": "While the number of total words increases linearly, the number of unique words is limited by the vocabulary, and we found that the ratio decreases even inhuman data (see Appendix A.3 for details).", "labels": [], "entities": []}, {"text": "It is therefore important to only compare distinct metrics computed on the same test data.", "labels": [], "entities": []}, {"text": "Measuring n-gram overlap between response and target is widely used in the machine learning and dialog literature).", "labels": [], "entities": []}, {"text": "We report BLEU-1, BLUE-2, BLEU-3, and BLEU-4 computed with the 4th smoothing algorithm described in.", "labels": [], "entities": [{"text": "BLEU-1", "start_pos": 10, "end_pos": 16, "type": "METRIC", "confidence": 0.9978939890861511}, {"text": "BLUE-2", "start_pos": 18, "end_pos": 24, "type": "METRIC", "confidence": 0.9928431510925293}, {"text": "BLEU-3", "start_pos": 26, "end_pos": 32, "type": "METRIC", "confidence": 0.9972223043441772}, {"text": "BLEU-4", "start_pos": 38, "end_pos": 44, "type": "METRIC", "confidence": 0.9974665641784668}]}, {"text": "Normally metrics are computed at the validation loss minimum of a model, however in the case of chatbot models loss may not be a good indicator of response quality (Section 2), thus we also looked at how our metrics progress during training.", "labels": [], "entities": []}, {"text": "shows how coherence and the 3 embedding metrics saturate after about 80-100k steps, and never decrease (we ran the training for 300k steps, roughly 640 epochs).", "labels": [], "entities": []}, {"text": "Most metrics show a similar trend of increasing until 100k steps, and then stagnating (see Appendix A.3 for more figures).", "labels": [], "entities": []}, {"text": "In contrast, validation loss for the same training reaches its minimum after about 10-20k steps ().", "labels": [], "entities": [{"text": "validation", "start_pos": 13, "end_pos": 23, "type": "TASK", "confidence": 0.8754293918609619}]}, {"text": "This again suggests the inadequacy of   the loss function, but it also questions the validity of these metrics, as they seem to favor a model that overfitted the training data, which we can assume after 640 epochs.", "labels": [], "entities": []}, {"text": "This could be due to the many identical inputs in train and test splits, because of the nature of dialog data.", "labels": [], "entities": []}, {"text": "Most interesting are embedding metrics and BLEU scores (Section 5.3), since they show that even after overfitting responses do not get farther from targets.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 43, "end_pos": 47, "type": "METRIC", "confidence": 0.9988259673118591}]}, {"text": "This is inline with other findings reporting that qualitatively responses are better after overfitting, however occasionally they also tend to be too specific and irrelevant.", "labels": [], "entities": []}, {"text": "We leave it for future work to conduct human evaluation between non-overfitted and overfitted models to solidify these claims.", "labels": [], "entities": []}, {"text": "In light of these issues, we compare trainings on the DailyDialog dataset both at the validation loss minimum and at an overfitted point (150 epochs).", "labels": [], "entities": [{"text": "DailyDialog dataset", "start_pos": 54, "end_pos": 73, "type": "DATASET", "confidence": 0.992043137550354}]}, {"text": "Unfiltered is the model trained on unfiltered data, and IDENTITY TARGET is the model trained on IDENTITY, TARGET filtered data.", "labels": [], "entities": [{"text": "TARGET", "start_pos": 65, "end_pos": 71, "type": "METRIC", "confidence": 0.854851245880127}]}, {"text": "Overfitted means that the respective model is evaluated at an overfitted point.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Entropy threshold (Th.) and amount of data  filtered for all datasets in the 3 filtering scenarios. ID  stands for IDENTITY, AE stands for AVG-EMBEDDING,  and SC for SENT2VEC.", "labels": [], "entities": [{"text": "Entropy threshold (Th.)", "start_pos": 10, "end_pos": 33, "type": "METRIC", "confidence": 0.9538431525230407}, {"text": "AE", "start_pos": 135, "end_pos": 137, "type": "METRIC", "confidence": 0.9918578267097473}, {"text": "AVG-EMBEDDING", "start_pos": 149, "end_pos": 162, "type": "METRIC", "confidence": 0.7186462879180908}]}, {"text": " Table 2: Metrics computed at the minimum of the validation loss on the unfiltered test set (DailyDialog). TRF  refers to transformer, ID to IDENTITY, AE to AVG-EMBEDDING, and SC to SENT2VEC. SOURCE-side,  TARGET-side, and filtering BOTH sides are denoted by initials. Best results are highlighted with bold and best  results separately for each entropy computing method are in italic (and those within a 95% confidence interval).", "labels": [], "entities": [{"text": "TRF", "start_pos": 107, "end_pos": 110, "type": "METRIC", "confidence": 0.9803228378295898}, {"text": "AE", "start_pos": 151, "end_pos": 153, "type": "METRIC", "confidence": 0.9842692613601685}, {"text": "TARGET-side", "start_pos": 206, "end_pos": 217, "type": "METRIC", "confidence": 0.9810108542442322}, {"text": "BOTH", "start_pos": 233, "end_pos": 237, "type": "METRIC", "confidence": 0.9106720089912415}]}, {"text": " Table 3: Metrics computed on the unfiltered test set (DailyDialog) after 150 epochs of training. TRF refers to  transformer, ID to IDENTITY, AE to AVG-EMBEDDING, and SC to SENT2VEC. SOURCE-side, TARGET-side,  and filtering BOTH sides are denoted by initials. Best results are highlighted with bold and best results separately  for each entropy computing method are in italic (and those within a 95% confidence interval). GT refers to ground  truth responses and RT refers to randomly selected responses from the training set.", "labels": [], "entities": [{"text": "TRF", "start_pos": 98, "end_pos": 101, "type": "METRIC", "confidence": 0.950673520565033}, {"text": "AE", "start_pos": 142, "end_pos": 144, "type": "METRIC", "confidence": 0.9786558151245117}, {"text": "TARGET-side", "start_pos": 196, "end_pos": 207, "type": "METRIC", "confidence": 0.9805760979652405}, {"text": "BOTH", "start_pos": 224, "end_pos": 228, "type": "METRIC", "confidence": 0.9083706736564636}, {"text": "RT", "start_pos": 463, "end_pos": 465, "type": "METRIC", "confidence": 0.9450066089630127}]}, {"text": " Table 5: Metrics on the unfiltered test set (Cornell) at the validation loss minimum. TRF refers to transformer,  ID to IDENTITY. TARGET-side, and filtering BOTH sides are denoted by initials. Best results are highlighted with  bold. GT refers to ground truth responses and RT refers to randomly selected responses from the training set.", "labels": [], "entities": [{"text": "unfiltered test set (Cornell)", "start_pos": 25, "end_pos": 54, "type": "DATASET", "confidence": 0.70261017481486}, {"text": "TRF", "start_pos": 87, "end_pos": 90, "type": "METRIC", "confidence": 0.990068256855011}, {"text": "TARGET-side", "start_pos": 131, "end_pos": 142, "type": "METRIC", "confidence": 0.9925122261047363}, {"text": "BOTH", "start_pos": 158, "end_pos": 162, "type": "METRIC", "confidence": 0.8800542950630188}, {"text": "RT", "start_pos": 275, "end_pos": 277, "type": "METRIC", "confidence": 0.9070044159889221}]}, {"text": " Table 6: Metrics on the unfiltered test set (Twitter) at the validation loss minimum. TRF refers to transformer,  ID to IDENTITY. TARGET-side, and filtering BOTH sides are denoted by initials. Best results are highlighted with  bold. GT refers to ground truth responses and RT refers to randomly selected responses from the training set.", "labels": [], "entities": [{"text": "TRF", "start_pos": 87, "end_pos": 90, "type": "METRIC", "confidence": 0.9893361330032349}, {"text": "TARGET-side", "start_pos": 131, "end_pos": 142, "type": "METRIC", "confidence": 0.9909875988960266}, {"text": "BOTH", "start_pos": 158, "end_pos": 162, "type": "METRIC", "confidence": 0.8498510122299194}, {"text": "RT", "start_pos": 275, "end_pos": 277, "type": "METRIC", "confidence": 0.8920795917510986}]}, {"text": " Table 7: Top 20 source utterances (from DailyDialog)  sorted by entropy. The entropy was calculated with", "labels": [], "entities": [{"text": "DailyDialog", "start_pos": 41, "end_pos": 52, "type": "DATASET", "confidence": 0.9827874898910522}]}]}