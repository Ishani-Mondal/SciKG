{"title": [{"text": "Constructing Interpretive Spatio-Temporal Features for Multi-Turn Responses Selection", "labels": [], "entities": []}], "abstractContent": [{"text": "Response selection plays an important role in fully automated dialogue systems.", "labels": [], "entities": [{"text": "Response selection", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.8930864334106445}]}, {"text": "Given the dialogue context, the goal of response selection is to identify the best-matched next-utterance (i.e., response) from multiple candidates.", "labels": [], "entities": [{"text": "response selection", "start_pos": 40, "end_pos": 58, "type": "TASK", "confidence": 0.7427675724029541}]}, {"text": "Despite the efforts of many previous useful models, this task remains challenging due to the huge semantic gap and also the large size of candidate set.", "labels": [], "entities": []}, {"text": "To address these issues, we propose a Spatio-Temporal Matching network (STM) for response selection.", "labels": [], "entities": [{"text": "response selection", "start_pos": 81, "end_pos": 99, "type": "TASK", "confidence": 0.9105568826198578}]}, {"text": "In detail, soft alignment is first used to obtain the local relevance between the context and the response.", "labels": [], "entities": [{"text": "soft alignment", "start_pos": 11, "end_pos": 25, "type": "TASK", "confidence": 0.6667419075965881}]}, {"text": "And then, we construct spatio-temporal features by aggregating attention images in time dimension and make use of 3D convolution and pooling operations to extract matching information.", "labels": [], "entities": []}, {"text": "Evaluation on two large-scale multi-turn response selection tasks has demonstrated that our proposed model significantly outperforms the state-of-the-art model.", "labels": [], "entities": [{"text": "multi-turn response selection tasks", "start_pos": 30, "end_pos": 65, "type": "TASK", "confidence": 0.6741304993629456}]}, {"text": "Particularly, visualization analysis shows that the spatio-temporal features enables matching information in segment pairs and time sequences, and have good inter-pretability for multi-turn text matching.", "labels": [], "entities": [{"text": "multi-turn text matching", "start_pos": 179, "end_pos": 203, "type": "TASK", "confidence": 0.6860193510850271}]}], "introductionContent": [{"text": "Fully automated dialogue systems () are becoming increasingly important area in natural language processing.", "labels": [], "entities": [{"text": "natural language processing", "start_pos": 80, "end_pos": 107, "type": "TASK", "confidence": 0.6661724150180817}]}, {"text": "An important research topic in dialogue systems is response selection, as illustrated in, which aims to select an optimal response from a pre-defined pool of potential responses.", "labels": [], "entities": [{"text": "response selection", "start_pos": 51, "end_pos": 69, "type": "TASK", "confidence": 0.8843294680118561}]}, {"text": "Practical methods to response selection are usually retrieval-based, that focus on matching the semantic similarity between the response and utterances in the dialogue history (.", "labels": [], "entities": [{"text": "response selection", "start_pos": 21, "end_pos": 39, "type": "TASK", "confidence": 0.8728193044662476}]}, {"text": "Recently, convolutional operation, as a useful attempt to explore local correlation, has been in- vestigated to extract the matching features from the attention grid (.", "labels": [], "entities": []}, {"text": "Unfortunately, these methods usually do not perform well when there are many candidate responses.", "labels": [], "entities": []}, {"text": "In fact, in multi-turn dialogues, the next sentence is generally based on what was presented before and tends to match a recent local context.", "labels": [], "entities": []}, {"text": "This is because the topic in a conversation may changeover time, and the effective matching between the dialogue may only appear in a local time period.", "labels": [], "entities": []}, {"text": "This phenomena generally appear in video processing (), image caption ) and action recognition (.", "labels": [], "entities": [{"text": "image caption )", "start_pos": 56, "end_pos": 71, "type": "TASK", "confidence": 0.8283227483431498}, {"text": "action recognition", "start_pos": 76, "end_pos": 94, "type": "TASK", "confidence": 0.8415521383285522}]}, {"text": "Therefore, it is natural to adopt convolutional structure or attention mechanism to extract local matching information from the sentence sequences.", "labels": [], "entities": []}, {"text": "Analogously, each turn of dialogue can be regarded as a frame of a video.", "labels": [], "entities": []}, {"text": "This motivates us to propose the Spatio-Temporal Matching block (STM) to construct the spatio-temporal features of local semantic relation between each turn of dialog and candidates by soft-attention mechanism.", "labels": [], "entities": [{"text": "Spatio-Temporal Matching block (STM", "start_pos": 33, "end_pos": 68, "type": "TASK", "confidence": 0.6979142785072326}]}, {"text": "In detail, we model the response selection problem as a multi-class classification problem with sequences as input, where the label of the true response is set to one and the other candidates are set to zero.", "labels": [], "entities": [{"text": "response selection problem", "start_pos": 24, "end_pos": 50, "type": "TASK", "confidence": 0.890051265557607}]}, {"text": "As illustrated in, the proposed STM framework includes two parts: (i) representation module and (ii) matching block.", "labels": [], "entities": []}, {"text": "Specifically, representations of the dialogue context and candidate answers are first learned through from dual encoders, and deep 3D ConvNets ( are then used to match attentions between the dialogue contexts and candidate answers.", "labels": [], "entities": []}, {"text": "Evaluation on the NOESIS datasets has demonstrated the outstanding performance of our proposed model against other well-known frameworks.", "labels": [], "entities": [{"text": "NOESIS datasets", "start_pos": 18, "end_pos": 33, "type": "DATASET", "confidence": 0.9851115643978119}]}, {"text": "Furthermore, our model enjoys a merit of good interpretation with the visualization of the attention weight as a thermal map.", "labels": [], "entities": []}, {"text": "Our code is released under https://github.com/CSLujunyu/ Spatio-Temporal-Matching-Network.", "labels": [], "entities": []}], "datasetContent": [{"text": "The ongoing DSTC series starts as an initiative to provide a common testbed for the task of Di-  We consider at most 9 turns and 50 words for each utterance and responses in our experiments.", "labels": [], "entities": []}, {"text": "Word embeddings are initialized by GloVe) as the optimizer, set the initial learning rate is 0.001, and we employ early-stopping() as a regularization strategy.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Experiment Result on the Ubuntu Corpus.", "labels": [], "entities": [{"text": "Ubuntu Corpus", "start_pos": 35, "end_pos": 48, "type": "DATASET", "confidence": 0.9329825639724731}]}, {"text": " Table 2: Experiment Results on the Advising Dataset.", "labels": [], "entities": []}]}