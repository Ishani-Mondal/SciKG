{"title": [{"text": "KCAT: A Knowledge-Constraint Typing Annotation Tool", "labels": [], "entities": [{"text": "Knowledge-Constraint Typing Annotation Tool", "start_pos": 8, "end_pos": 51, "type": "TASK", "confidence": 0.710668608546257}]}], "abstractContent": [{"text": "Fine-grained Entity Typing is a tough task which suffers from noise samples extracted from distant supervision.", "labels": [], "entities": [{"text": "Entity Typing", "start_pos": 13, "end_pos": 26, "type": "TASK", "confidence": 0.7884281873703003}]}, {"text": "Thousands of manually annotated samples can achieve greater performance than millions of samples generated by the previous distant supervision method.", "labels": [], "entities": []}, {"text": "Whereas, it's hard for human beings to differentiate and memorize thousands of types, thus making large-scale human labeling hardly possible.", "labels": [], "entities": []}, {"text": "In this paper, we introduce a Knowledge-Constraint Typing Annotation Tool (KCAT 1), which is efficient for fine-grained entity typing annotation.", "labels": [], "entities": []}, {"text": "KCAT reduces the size of candidate types to an acceptable range for human beings through entity linking and provides a Multi-step Typing scheme to revise the entity linking result.", "labels": [], "entities": [{"text": "KCAT", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.8374173641204834}, {"text": "entity linking", "start_pos": 89, "end_pos": 103, "type": "TASK", "confidence": 0.7309455722570419}]}, {"text": "Moreover, KCAT provides an efficient Anno-tator Client to accelerate the annotation process and a comprehensive Manager Module to analyse crowdsourcing annotations.", "labels": [], "entities": []}, {"text": "Experiment shows that KCAT can significantly improve annotation efficiency, the time consumption increases slowly as the size of typeset expands .", "labels": [], "entities": []}], "introductionContent": [{"text": "Recent years Natural Language Processing community has seen a surge of interests in fine-grained entity typing (FET) as it serves as an important cornerstone of several nature language processing tasks including relation extraction (, entity linking, and knowledge base completion (.", "labels": [], "entities": [{"text": "entity typing (FET)", "start_pos": 97, "end_pos": 116, "type": "TASK", "confidence": 0.8038550972938537}, {"text": "relation extraction", "start_pos": 212, "end_pos": 231, "type": "TASK", "confidence": 0.8063342869281769}, {"text": "entity linking", "start_pos": 235, "end_pos": 249, "type": "TASK", "confidence": 0.7830853462219238}, {"text": "knowledge base completion", "start_pos": 255, "end_pos": 280, "type": "TASK", "confidence": 0.6374108294645945}]}, {"text": "Given an entity mention (i.e. a sequence of token spans representing an entity) in the corpus, FET aims at uncovering its contextdependent type.", "labels": [], "entities": [{"text": "FET", "start_pos": 95, "end_pos": 98, "type": "TASK", "confidence": 0.4547683000564575}]}, {"text": "includes Fine-grained Entity Typing datasets in recent years, the target types often form a type hierarchy.", "labels": [], "entities": [{"text": "Fine-grained Entity Typing", "start_pos": 9, "end_pos": 35, "type": "TASK", "confidence": 0.57987380027771}]}, {"text": "The difficulty of FET and FET Annotation both increase rapidly with the growth of type hierarchy's depth.", "labels": [], "entities": [{"text": "FET", "start_pos": 18, "end_pos": 21, "type": "METRIC", "confidence": 0.6135855913162231}, {"text": "FET Annotation", "start_pos": 26, "end_pos": 40, "type": "TASK", "confidence": 0.509486123919487}]}, {"text": "Previous research work mainly focus on generating train corpus with distant supervision (.", "labels": [], "entities": []}, {"text": "In spite of its efficiency, distant supervision brings the problem of noisy labels, for example, {Other, brand} are noisy labels for 'Kobe' in \"Kobe scored 60 points in the final game.\".", "labels": [], "entities": []}, {"text": "According to, 6000 manually labeled samples achieved greater performance than millions of samples generated by distant supervision.", "labels": [], "entities": []}, {"text": "( observed that noisy samples may even cause damage to the performance of FET model.", "labels": [], "entities": [{"text": "FET", "start_pos": 74, "end_pos": 77, "type": "DATASET", "confidence": 0.5121386647224426}]}, {"text": "( proposed label noise reduction methods, which are pretty complicated and hard to migrate.", "labels": [], "entities": [{"text": "label noise reduction", "start_pos": 11, "end_pos": 32, "type": "TASK", "confidence": 0.6614097456137339}]}, {"text": "Thus the annotation corpus for FET is important and necessary.", "labels": [], "entities": [{"text": "FET", "start_pos": 31, "end_pos": 34, "type": "TASK", "confidence": 0.7450461387634277}]}, {"text": "However, it is not easy to annotate a corpus for FET since it's hard for human beings to differentiate and memorize thousands of types.", "labels": [], "entities": [{"text": "FET", "start_pos": 49, "end_pos": 52, "type": "TASK", "confidence": 0.6106835007667542}]}, {"text": "To solve this extremely hard annotation task, we use Entity Linking (EL) to constrain the candidate types of the entity mention.", "labels": [], "entities": []}, {"text": "Entity Linking, which tries to link entity mention to a unique entity in a specific knowledge base (i.e. Yago or Freebase), has been studied for years.", "labels": [], "entities": [{"text": "Entity Linking", "start_pos": 0, "end_pos": 14, "type": "TASK", "confidence": 0.7387298196554184}, {"text": "Yago or Freebase", "start_pos": 105, "end_pos": 121, "type": "DATASET", "confidence": 0.7316535711288452}]}, {"text": "The state-of-the-art EL system yields 0.93 F1 score in Conll2003), while the F1 scores of FET vary from 0.40) to 0.79 () on different datasets.", "labels": [], "entities": [{"text": "EL", "start_pos": 21, "end_pos": 23, "type": "METRIC", "confidence": 0.629291296005249}, {"text": "F1 score", "start_pos": 43, "end_pos": 51, "type": "METRIC", "confidence": 0.9848961234092712}, {"text": "Conll2003", "start_pos": 55, "end_pos": 64, "type": "DATASET", "confidence": 0.9055088758468628}, {"text": "F1 scores", "start_pos": 77, "end_pos": 86, "type": "METRIC", "confidence": 0.9816584289073944}, {"text": "FET", "start_pos": 90, "end_pos": 93, "type": "METRIC", "confidence": 0.8277587294578552}]}, {"text": "With the help of EL, the candidate types of a mention can be greatly reduced as shown in the \u2022 Knowledge-Constraint: it visualizes candidate types hierarchically, which is extracted from Knowledge Base and reduced by entity linking.", "labels": [], "entities": []}, {"text": "\u2022 Efficient: it supports multiple shortcuts to improve annotation efficiency; entity description of the wiki and type description to help distinguish candidate types.", "labels": [], "entities": []}, {"text": "\u2022 Portable: it is only required to replace a few json files to complete the migration of different datasets.", "labels": [], "entities": []}, {"text": "\u2022 Comprehensive: it supports crowdsourcing results comparison and integration.", "labels": [], "entities": [{"text": "Comprehensive", "start_pos": 2, "end_pos": 15, "type": "METRIC", "confidence": 0.9480152726173401}, {"text": "crowdsourcing results comparison", "start_pos": 29, "end_pos": 61, "type": "TASK", "confidence": 0.7802988489468893}]}, {"text": "The rest of the paper is organized as: Section 2 briefly describes recent research in FET.", "labels": [], "entities": [{"text": "FET", "start_pos": 86, "end_pos": 89, "type": "TASK", "confidence": 0.8763328790664673}]}, {"text": "Section 3 introduces the overview of our framework.", "labels": [], "entities": []}, {"text": "Section 4 describes the architecture of KCAT and its detail functions.", "labels": [], "entities": [{"text": "KCAT", "start_pos": 40, "end_pos": 44, "type": "TASK", "confidence": 0.7216160297393799}]}, {"text": "Section 5 analyses the efficiency comparison and annotation quality in different annotation mode.", "labels": [], "entities": []}, {"text": "Finally, Section 6 concludes this paper.", "labels": [], "entities": []}], "datasetContent": [{"text": "In order to verify the efficiency of KCAT, we conduct a mock annotation experiment.", "labels": [], "entities": []}, {"text": "100 sentences are extracted from the English dataset of) as the corpus to be annotated.", "labels": [], "entities": [{"text": "English dataset", "start_pos": 37, "end_pos": 52, "type": "DATASET", "confidence": 0.7927811443805695}]}, {"text": "The entity mention spans in these sentences have been annotated.", "labels": [], "entities": []}, {"text": "Type hierarchy is extracted from following three datasets: (1) Conll 2003; (2) BBN(Ren et al., 2016a); (3) FIGER(; and YAGO Knowledge Base().", "labels": [], "entities": [{"text": "Conll 2003", "start_pos": 63, "end_pos": 73, "type": "DATASET", "confidence": 0.8924949467182159}, {"text": "BBN", "start_pos": 79, "end_pos": 82, "type": "METRIC", "confidence": 0.9323550462722778}, {"text": "FIGER", "start_pos": 107, "end_pos": 112, "type": "METRIC", "confidence": 0.9370864033699036}, {"text": "YAGO Knowledge Base", "start_pos": 119, "end_pos": 138, "type": "DATASET", "confidence": 0.8128019571304321}]}, {"text": "The mappings between entity and its related types are provided by these datasets.", "labels": [], "entities": []}, {"text": "We have chosen two annotation modes: (a) without pre-linking, directly through top-down search or flatten search; (b) filtering out types that are inconsistent with entity types through entity linking.", "labels": [], "entities": []}, {"text": "Pairwise accuracy is used to measure the consistence between arbitrary two annotators.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 9, "end_pos": 17, "type": "METRIC", "confidence": 0.798773467540741}]}, {"text": "For multiple annotators, we can generate a heat map, each element of the heat map represents pairwise accuracy, darker color means higher accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 102, "end_pos": 110, "type": "METRIC", "confidence": 0.9951369166374207}, {"text": "accuracy", "start_pos": 138, "end_pos": 146, "type": "METRIC", "confidence": 0.996407687664032}]}, {"text": "In, the User 1, 2, and 3 adopt the mode (b), and the User 4, 5 and 6 adopts the mode (a), and it can be observed that the labeling quality of 1, 2, and 3 is significantly better than 4, 5, 6 as the former have higher consistency.", "labels": [], "entities": [{"text": "consistency", "start_pos": 217, "end_pos": 228, "type": "METRIC", "confidence": 0.990848183631897}]}], "tableCaptions": [{"text": " Table 1: Size of Candidate Types before and after  Knowledge-Constraint on Different Datasets, and the  ratio of the latter to the former", "labels": [], "entities": [{"text": "Size of Candidate Types", "start_pos": 10, "end_pos": 33, "type": "TASK", "confidence": 0.8211497515439987}]}, {"text": " Table 2: Time Consumption (minute) of Annotating  60 Sentences on Different Datasets", "labels": [], "entities": [{"text": "Time Consumption (minute)", "start_pos": 10, "end_pos": 35, "type": "METRIC", "confidence": 0.8874096512794495}]}]}