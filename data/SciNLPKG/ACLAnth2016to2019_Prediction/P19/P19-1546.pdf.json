{"title": [{"text": "SUMBT: Slot-Utterance Matching for Universal and Scalable Belief Tracking", "labels": [], "entities": [{"text": "SUMBT", "start_pos": 0, "end_pos": 5, "type": "TASK", "confidence": 0.7779322862625122}, {"text": "Slot-Utterance Matching", "start_pos": 7, "end_pos": 30, "type": "TASK", "confidence": 0.8617709875106812}, {"text": "Universal and Scalable Belief Tracking", "start_pos": 35, "end_pos": 73, "type": "TASK", "confidence": 0.5526378154754639}]}], "abstractContent": [{"text": "In goal-oriented dialog systems, belief track-ers estimate the probability distribution of slot-values at every dialog turn.", "labels": [], "entities": []}, {"text": "Previous neu-ral approaches have modeled domain-and slot-dependent belief trackers, and have difficulty in adding new slot-values, resulting in lack of flexibility of domain ontology configurations.", "labels": [], "entities": []}, {"text": "In this paper, we propose anew approach to universal and scalable belief tracker, called slot-utterance matching belief tracker (SUMBT).", "labels": [], "entities": [{"text": "slot-utterance matching belief tracker", "start_pos": 89, "end_pos": 127, "type": "TASK", "confidence": 0.6456512212753296}]}, {"text": "The model learns the relations between domain-slot-types and slot-values appearing in utterances through attention mechanisms based on contextual semantic vectors.", "labels": [], "entities": []}, {"text": "Furthermore, the model predicts slot-value labels in a non-parametric way.", "labels": [], "entities": []}, {"text": "From our experiments on two dialog corpora , WOZ 2.0 and MultiWOZ, the proposed model showed performance improvement in comparison with slot-dependent methods and achieved the state-of-the-art joint accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 199, "end_pos": 207, "type": "METRIC", "confidence": 0.9796062111854553}]}], "introductionContent": [{"text": "As the prevalent use of conversational agents, goal-oriented systems have received increasing attention from both academia and industry.", "labels": [], "entities": []}, {"text": "The goal-oriented systems help users to achieve goals such as making restaurant reservations or booking flights at the end of dialogs.", "labels": [], "entities": []}, {"text": "As the dialog progresses, the system is required to update a distribution over dialog states which consist of users' intent, informable slots, and requestable slots.", "labels": [], "entities": []}, {"text": "This is called belief tracking or dialog state tracking (DST).", "labels": [], "entities": [{"text": "belief tracking or dialog state tracking (DST)", "start_pos": 15, "end_pos": 61, "type": "TASK", "confidence": 0.730832835038503}]}, {"text": "For instance, fora given domain and slottypes (e.g., 'restaurant' domain and 'food' slottype), it estimates the probability of corresponding slot-value candidates (e.g., 'Korean' and 'Modern *Hwaran Lee and Jinsik Lee equally contributed to this work. European') that are pre-defined in a domain ontology.", "labels": [], "entities": [{"text": "Modern *Hwaran Lee", "start_pos": 184, "end_pos": 202, "type": "DATASET", "confidence": 0.8399300426244736}]}, {"text": "Since the system uses the predicted outputs of DST to choose the next action based on a dialog policy, the accuracy of DST is crucial to improve the overall performance of the system.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 107, "end_pos": 115, "type": "METRIC", "confidence": 0.999315619468689}]}, {"text": "Moreover, dialog systems should be able to deal with newly added domains and slots 1 in a flexible manner, and thus developing scalable dialog state trackers is inevitable.", "labels": [], "entities": []}, {"text": "Regarding to this, has proposed a model to capture relations from intentutterance pairs for intent expansion.", "labels": [], "entities": [{"text": "intent expansion", "start_pos": 92, "end_pos": 108, "type": "TASK", "confidence": 0.6953132003545761}]}, {"text": "Traditional statistical belief trackers) are vulnerable to lexical and morphological variations because they depend on manually constructed semantic dictionaries.", "labels": [], "entities": []}, {"text": "With the rise of deep learning approaches, several neural belief trackers (NBT) have been proposed and improved the performance by learning semantic neural representations of words.", "labels": [], "entities": []}, {"text": "However, the scalability still remains as a challenge; the previously proposed methods either individually model each domain and/or slot ( or have difficulty in adding new slot-values that are not defined in the ontology (.", "labels": [], "entities": []}, {"text": "In this paper, we focus on developing a \"scalable\" and \"universal\" belief tracker, whereby only a single belief tracker serves to handle any domain and slot-type.", "labels": [], "entities": []}, {"text": "To tackle this problem, we propose anew approach, called slot-utterance matching belief tracker (SUMBT), which is a domainand slot-independent belief tracker as shown in.", "labels": [], "entities": [{"text": "slot-utterance matching belief tracker", "start_pos": 57, "end_pos": 95, "type": "TASK", "confidence": 0.6554615050554276}]}, {"text": "Inspired by machine reading comprehension techniques, SUMBT considers a domain-slot-type (e.g., 'restaurant-food') as a question and finds the corresponding slot-value in a pair of user and system utterances, assuming the desirable answer exists in the utterances.", "labels": [], "entities": [{"text": "SUMBT", "start_pos": 54, "end_pos": 59, "type": "TASK", "confidence": 0.9551506638526917}]}, {"text": "SUMBT encodes system and user utterances using recently proposed BERT) which provides the contextualized semantic representation of sentences.", "labels": [], "entities": [{"text": "BERT", "start_pos": 65, "end_pos": 69, "type": "METRIC", "confidence": 0.9916783571243286}]}, {"text": "Moreover, the domain-slot-types and slotvalues are also literally encoded by BERT.", "labels": [], "entities": [{"text": "BERT", "start_pos": 77, "end_pos": 81, "type": "METRIC", "confidence": 0.8644641637802124}]}, {"text": "Then SUMBT learns the way whereto attend that is related to the domain-slot-type information among the utterance words based on their contextual semantic vectors.", "labels": [], "entities": []}, {"text": "The model predicts the slot-value label in a non-parametric way based on a certain metric, which enables the model architecture not to structurally depend on domains and slot-types.", "labels": [], "entities": []}, {"text": "Consequently, a single SUMBT can deal with any pair of domain-slot-type and slot-value, and also can utilize shared knowledge among multiple domains and slots.", "labels": [], "entities": []}, {"text": "We will experimentally demonstrate the efficacy of the proposing model on two goal-oriented dialog corpora: WOZ 2.0 and MultiWOZ.", "labels": [], "entities": []}, {"text": "We will also qualitatively analyze how the model works.", "labels": [], "entities": []}], "datasetContent": [{"text": "To demonstrate the performance of our approach, we conducted experiments over WOZ 2.0 (", "labels": [], "entities": [{"text": "WOZ 2.0", "start_pos": 78, "end_pos": 85, "type": "DATASET", "confidence": 0.909154087305069}]}], "tableCaptions": [{"text": " Table 1: Joint goal accuracy on the evaluation dataset  of WOZ 2.0 corpus.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 21, "end_pos": 29, "type": "METRIC", "confidence": 0.9204123020172119}, {"text": "WOZ 2.0 corpus", "start_pos": 60, "end_pos": 74, "type": "DATASET", "confidence": 0.8722861011823019}]}, {"text": " Table 2: Joint goal accuracy on the evaluation dataset  of MultiWOZ corpus.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 21, "end_pos": 29, "type": "METRIC", "confidence": 0.8914034962654114}, {"text": "MultiWOZ corpus", "start_pos": 60, "end_pos": 75, "type": "DATASET", "confidence": 0.880054235458374}]}]}