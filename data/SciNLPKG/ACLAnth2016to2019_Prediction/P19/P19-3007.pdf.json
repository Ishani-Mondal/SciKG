{"title": [{"text": "A Multiscale Visualization of Attention in the Transformer Model", "labels": [], "entities": []}], "abstractContent": [{"text": "The Transformer is a sequence model that for-goes traditional recurrent architectures in favor of a fully attention-based approach.", "labels": [], "entities": []}, {"text": "Besides improving performance, an advantage of using attention is that it can also help to interpret a model by showing how the model assigns weight to different input elements.", "labels": [], "entities": []}, {"text": "However, the multi-layer, multi-head attention mechanism in the Transformer model can be difficult to decipher.", "labels": [], "entities": []}, {"text": "To make the model more accessible , we introduce an open-source tool that visualizes attention at multiple scales, each of which provides a unique perspective on the attention mechanism.", "labels": [], "entities": []}, {"text": "We demonstrate the tool on BERT and OpenAI GPT-2 and present three example use cases: detecting model bias, locating relevant attention heads, and linking neurons to model behavior.", "labels": [], "entities": [{"text": "BERT", "start_pos": 27, "end_pos": 31, "type": "METRIC", "confidence": 0.8691845536231995}, {"text": "OpenAI GPT-2", "start_pos": 36, "end_pos": 48, "type": "DATASET", "confidence": 0.9605462849140167}]}], "introductionContent": [{"text": "In 2018, the BERT (Bidirectional Encoder Representations from Transformers) language representation model achieved state-of-the-art performance across NLP tasks ranging from sentiment analysis to question answering (.", "labels": [], "entities": [{"text": "BERT", "start_pos": 13, "end_pos": 17, "type": "METRIC", "confidence": 0.9952085614204407}, {"text": "Bidirectional Encoder Representations from Transformers) language representation", "start_pos": 19, "end_pos": 99, "type": "TASK", "confidence": 0.6109106205403805}, {"text": "sentiment analysis", "start_pos": 174, "end_pos": 192, "type": "TASK", "confidence": 0.9547082781791687}, {"text": "question answering", "start_pos": 196, "end_pos": 214, "type": "TASK", "confidence": 0.8636648058891296}]}, {"text": "Recently, the OpenAI GPT-2 (Generative Pretrained Transformer-2) model outperformed other models on several language modeling benchmarks in a zero-shot setting.", "labels": [], "entities": [{"text": "OpenAI GPT-2", "start_pos": 14, "end_pos": 26, "type": "DATASET", "confidence": 0.8567894399166107}]}, {"text": "Underlying BERT and GPT-2 is the Transformer model, which uses a fully attention-based approach in contrast to traditional sequence models based on recurrent architectures ().", "labels": [], "entities": [{"text": "BERT", "start_pos": 11, "end_pos": 15, "type": "METRIC", "confidence": 0.9941704869270325}, {"text": "GPT-2", "start_pos": 20, "end_pos": 25, "type": "DATASET", "confidence": 0.8471922874450684}]}, {"text": "An advantage of using attention is that it can help interpret a model by showing how the model assigns weight to different input elements (, although its value in explaining individual predictions maybe limited.", "labels": [], "entities": []}, {"text": "Various tools have been developed to visualize attention in NLP models, ranging from attention-matrix heatmaps () to bipartite graph representations (.", "labels": [], "entities": []}, {"text": "One challenge for visualizing attention in the Transformer is that it uses a multi-layer, multihead attention mechanism, which produces different attention patterns for each layer and head.", "labels": [], "entities": []}, {"text": "BERT-Large, for example, which has 24 layers and 16 heads, generates 24 \u00d7 16 = 384 unique attention structures for each input.", "labels": [], "entities": [{"text": "BERT-Large", "start_pos": 0, "end_pos": 10, "type": "METRIC", "confidence": 0.9655368328094482}]}, {"text": "Jones (2017) designed a visualization tool specifically for multihead attention, which visualizes attention over multiple heads in a layer by superimposing their attention patterns (.", "labels": [], "entities": []}, {"text": "In this paper, we extend the work of Jones (2017) by visualizing attention in the Transformer at multiple scales.", "labels": [], "entities": []}, {"text": "We introduce a high-level model view, which visualizes all of the layers and attention heads in a single interface, and a lowlevel neuron view, which shows how individual neurons interact to produce attention.", "labels": [], "entities": []}, {"text": "We also adapt the tool from the original encoder-decoder implementation to the decoder-only GPT-2 model and the encoder-only BERT model.", "labels": [], "entities": [{"text": "BERT", "start_pos": 125, "end_pos": 129, "type": "METRIC", "confidence": 0.9801794290542603}]}], "datasetContent": [], "tableCaptions": []}