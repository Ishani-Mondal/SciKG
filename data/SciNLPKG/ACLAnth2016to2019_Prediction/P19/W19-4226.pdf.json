{"title": [{"text": "The SIGMORPHON 2019 Shared Task: Morphological Analysis in Context and Cross-Lingual Transfer for Inflection", "labels": [], "entities": [{"text": "Morphological Analysis", "start_pos": 33, "end_pos": 55, "type": "TASK", "confidence": 0.9077657461166382}, {"text": "Cross-Lingual Transfer", "start_pos": 71, "end_pos": 93, "type": "TASK", "confidence": 0.7107710540294647}]}], "abstractContent": [{"text": "The SIGMORPHON 2019 shared task on cross-lingual transfer and contextual analysis in morphology examined transfer learning of inflection between 100 language pairs, as well as contextual lemmatization and morphosyn-tactic description in 66 languages.", "labels": [], "entities": [{"text": "cross-lingual transfer", "start_pos": 35, "end_pos": 57, "type": "TASK", "confidence": 0.7486787736415863}]}, {"text": "The first task evolves past years' inflection tasks by examining transfer of morphological inflection knowledge from a high-resource language to a low-resource language.", "labels": [], "entities": []}, {"text": "This year also presents anew second challenge on lemmatization and morphological feature analysis in context.", "labels": [], "entities": [{"text": "morphological feature analysis", "start_pos": 67, "end_pos": 97, "type": "TASK", "confidence": 0.6227418382962545}]}, {"text": "All submissions featured a neural component and built on either this year's strong baselines or highly ranked systems from previous years' shared tasks.", "labels": [], "entities": []}, {"text": "Every participating team improved inaccuracy over the baselines for the inflection task (though not Levenshtein distance), and every team in the contextual analysis task improved on both state-of-the-art neu-ral and non-neural baselines.", "labels": [], "entities": [{"text": "Levenshtein distance", "start_pos": 100, "end_pos": 120, "type": "METRIC", "confidence": 0.7470296919345856}]}], "introductionContent": [{"text": "While producing a sentence, humans combine various types of knowledge to produce fluent outputvarious shades of meaning are expressed through word selection and tone, while the language is made to conform to underlying structural rules via syntax and morphology.", "labels": [], "entities": []}, {"text": "Native speakers are often quick to identify disfluency, even if the meaning of a sentence is mostly clear.", "labels": [], "entities": []}, {"text": "Automatic systems must also consider these constraints when constructing or processing language.", "labels": [], "entities": []}, {"text": "Strong enough language models can often reconstruct common syntactic structures, but are insufficient to properly model morphology.", "labels": [], "entities": []}, {"text": "Many languages implement large inflectional paradigms that mark both function and content words with a varying levels of morphosyntactic information.", "labels": [], "entities": []}, {"text": "For instance, Romanian verb forms inflect for person, number, tense, mood, and voice; meanwhile, Archi verbs can take on thousands of forms).", "labels": [], "entities": []}, {"text": "Such complex paradigms produce large inventories of words, all of which must be producible by a realistic system, even though a large percentage of them will never be observed over billions of lines of linguistic input.", "labels": [], "entities": []}, {"text": "Compounding the issue, good inflectional systems often require large amounts of supervised training data, which is infeasible in many of the world's languages.", "labels": [], "entities": []}, {"text": "This year's shared task is concentrated on encouraging the construction of strong morphological systems that perform two related but different inflectional tasks.", "labels": [], "entities": []}, {"text": "The first task asks participants to create morphological inflectors fora large number of under-resourced languages, encouraging systems that use highly-resourced, related languages as a cross-lingual training signal.", "labels": [], "entities": []}, {"text": "The second task welcomes submissions that invert this operation in light of contextual information: Given an unannotated sentence, lemmatize each word, and tag them with a morphosyntactic description.", "labels": [], "entities": []}, {"text": "Both of these tasks extend upon previous morphological competitions, and the best submitted systems now represent the state of the art in their respective tasks.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 2: Task 1 Team Scores, averaged across all Lan- guages; * indicates submissions were only applied to a  subset of languages, making scores incomparable.  \u2020 in- dicates that additional resources were used for training.", "labels": [], "entities": []}, {"text": " Table 3: Task 1 Accuracy scores", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 17, "end_pos": 25, "type": "METRIC", "confidence": 0.985018789768219}]}, {"text": " Table 4: Task 1 Levenshtein scores", "labels": [], "entities": []}, {"text": " Table 5: Task 2 Team Scores, averaged across all treebanks; * indicates submissions were only applied to a subset  of languages, making scores incomparable.  \u2020 indicates that additional external resources were used for training,  and  \u2021 indicates that training data were shared across languages or treebanks.", "labels": [], "entities": []}, {"text": " Table 6: Task 2 Lemma Accuracy scores", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 23, "end_pos": 31, "type": "METRIC", "confidence": 0.9201214909553528}]}, {"text": " Table 7: Task 2 Lemma Levenshtein scores", "labels": [], "entities": []}, {"text": " Table 8: Task 2 Morph Accuracy scores", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 23, "end_pos": 31, "type": "METRIC", "confidence": 0.9741966724395752}]}, {"text": " Table 9: Task 2 Morph F1 scores", "labels": [], "entities": []}]}