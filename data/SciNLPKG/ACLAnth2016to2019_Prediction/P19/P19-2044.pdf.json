{"title": [{"text": "Improving Neural Entity Disambiguation with Graph Embeddings\u00a8Ozge", "labels": [], "entities": [{"text": "Improving Neural Entity Disambiguation", "start_pos": 0, "end_pos": 38, "type": "TASK", "confidence": 0.9080741256475449}]}], "abstractContent": [{"text": "Entity Disambiguation (ED) is the task of linking an ambiguous entity mention to a corresponding entry in a knowledge base.", "labels": [], "entities": [{"text": "Entity Disambiguation (ED)", "start_pos": 0, "end_pos": 26, "type": "TASK", "confidence": 0.8092951953411103}]}, {"text": "Current methods have mostly focused on unstruc-tured text data to learn representations of entities , however, there is structured information in the knowledge base itself that should be useful to disambiguate entities.", "labels": [], "entities": []}, {"text": "In this work, we propose a method that uses graph embeddings for integrating structured information from the knowledge base with unstructured information from text-based representations.", "labels": [], "entities": []}, {"text": "Our experiments confirm that graph embeddings trained on a graph of hyperlinks between Wikipedia articles improve the performances of simple feed-forward neural ED model and a state-of-the-art neural ED system.", "labels": [], "entities": []}], "introductionContent": [{"text": "The inherent and omnipresent ambiguity of language at the lexical level results in ambiguity of words, named entities, and other lexical units.", "labels": [], "entities": []}, {"text": "Word Sense Disambiguation (WSD)) deals with individual ambiguous words such as nouns, verbs, and adjectives.", "labels": [], "entities": [{"text": "Word Sense Disambiguation (WSD))", "start_pos": 0, "end_pos": 32, "type": "TASK", "confidence": 0.7828198323647181}]}, {"text": "The task of Entity Linking (EL)) is devoted to the disambiguation of mentions of named entities such as persons, locations, and organizations.", "labels": [], "entities": [{"text": "Entity Linking (EL))", "start_pos": 12, "end_pos": 32, "type": "TASK", "confidence": 0.8079205274581909}, {"text": "disambiguation of mentions of named entities such as persons, locations", "start_pos": 51, "end_pos": 122, "type": "TASK", "confidence": 0.8542654514312744}]}, {"text": "Basically, EL aims to resolve such ambiguity by creating an automatic reference between an ambiguous entity mention/span in a context and an entity in a knowledge base.", "labels": [], "entities": []}, {"text": "These entities can be Wikipedia articles and/or DBpedia ()/Freebase () entries.", "labels": [], "entities": [{"text": "DBpedia ()/Freebase", "start_pos": 48, "end_pos": 67, "type": "DATASET", "confidence": 0.8363948067029318}]}, {"text": "EL can be divided into two subtasks: (i) Mention Detection (MD) or Name Entity Recognition (NER) () finds entity references from a given raw text; (ii) and Entity Disambiguation (ED) assigns entity references fora given mention in context.", "labels": [], "entities": [{"text": "Name Entity Recognition (NER)", "start_pos": 67, "end_pos": 96, "type": "TASK", "confidence": 0.7303924163182577}]}, {"text": "This work deals with the entity disambiguation task.", "labels": [], "entities": [{"text": "entity disambiguation task", "start_pos": 25, "end_pos": 51, "type": "TASK", "confidence": 0.8107421199480692}]}, {"text": "The goal of an ED system is resolving the ambiguity of entity mentions, such as Mars, Galaxy, and Bounty are all delicious.", "labels": [], "entities": []}, {"text": "It is hard for an algorithm to identify whether the entity is an astronomical structure 1 or a brand of milk chocolate 2 . Current neural approaches to EL/ED attempt to use context and word embeddings (and sometimes entity embeddings on mentions in text) (.", "labels": [], "entities": [{"text": "EL/ED", "start_pos": 152, "end_pos": 157, "type": "TASK", "confidence": 0.7720895210901896}]}, {"text": "Whereas these and most other previous approaches employ embeddings trained from text, we aim to create entity embeddings based on structured data (i.e. hyperlinks) using graph embeddings and integrate them into the ED models.", "labels": [], "entities": []}, {"text": "Graph embeddings aim at representing nodes in a graph, or subgraph structure, by finding a mapping between a graph structure and the points in a low-dimensional vector space (.", "labels": [], "entities": [{"text": "Graph embeddings", "start_pos": 0, "end_pos": 16, "type": "TASK", "confidence": 0.82579705119133}]}, {"text": "The goal is to preserve the features of the graph structure and map these features to the geometric relationships, such as distances between different nodes, in the embedding space.", "labels": [], "entities": []}, {"text": "Using fixed-length dense vector embeddings as opposed to operating on the knowledge bases' graph structure allows the access of the information encoded in the graph structure in an efficient and straightforward manner in modern neural architectures.", "labels": [], "entities": []}, {"text": "Our claim is that including graph structure features of the knowledge base has a great potential to make an impact on ED.", "labels": [], "entities": [{"text": "ED", "start_pos": 118, "end_pos": 120, "type": "TASK", "confidence": 0.852262020111084}]}, {"text": "In our first experiment, we present a method based on a simple neural network with the inputs of a context, entity mention/span, explanation of a candidate entity, and a candidate entity.", "labels": [], "entities": []}, {"text": "Each entity is represented by graph embeddings, which are created using the knowledge base, containing hyperlinks between entities.", "labels": [], "entities": []}, {"text": "We perform ablation tests on the types of inputs, which allows us to judge the impact of the single inputs as well as their interplay.", "labels": [], "entities": []}, {"text": "Ina second experiment, we enhance a state-of-the-art neural entity disambiguation system called end2end () with our graph embeddings: The original system relies on character, word and entity embeddings; we replace respectively complement these with our graph embeddings.", "labels": [], "entities": []}, {"text": "Both experiments confirm the hypothesis that structured information in the form of graph embeddings are an efficient and effective way of improving ED.", "labels": [], "entities": [{"text": "ED", "start_pos": 148, "end_pos": 150, "type": "TASK", "confidence": 0.9640038013458252}]}, {"text": "Our main contribution is a creation of a simple technique for integration of structured information into an ED system with graph embeddings.", "labels": [], "entities": []}, {"text": "There is no obvious way to use large structured knowledge bases directly in a neural ED system.", "labels": [], "entities": []}, {"text": "We provide a simple solution based on graph embeddings and confirm experimentally its effectiveness.", "labels": [], "entities": []}], "datasetContent": [{"text": "In our first experiment, we build a simple neural ED system based on a feed-forward network and test the utility of the graph embeddings as compared to text-based embeddings.", "labels": [], "entities": []}, {"text": "Datasets: We train the neural end2end system in its default configuration with the combination of MSNBC  Implementation Details: We have not changed hyper-parameters for training the end2end system 4 (We used their base model + global for ED setting).", "labels": [], "entities": [{"text": "MSNBC", "start_pos": 98, "end_pos": 103, "type": "DATASET", "confidence": 0.8966735601425171}, {"text": "Implementation", "start_pos": 105, "end_pos": 119, "type": "METRIC", "confidence": 0.509519636631012}]}, {"text": "We create graph embeddings with the same technique used before, however, to keep everything the same, we decided to also use 300 dimensions for the graph embeddings in this experiment to match the dimensionality of end2end's space.", "labels": [], "entities": []}, {"text": "We create the embeddings file with the same format they used.", "labels": [], "entities": []}, {"text": "They give an id for each entity and call it \"wiki id\".", "labels": [], "entities": []}, {"text": "First, we generate a map between this wiki id and our graph id (id of our entity).", "labels": [], "entities": []}, {"text": "Then, we replace each entity vector corresponding to the wiki id with our graph embeddings, which refers to the entity.", "labels": [], "entities": []}, {"text": "Sometimes there is no corresponding graph entity for the entity in the end2end system, in this case, we supply a zero vector.", "labels": [], "entities": []}, {"text": "They have a stopping condition, which applies after 6 consecutive evaluations with no significant improvement in the Macro F1 score.", "labels": [], "entities": [{"text": "stopping condition", "start_pos": 12, "end_pos": 30, "type": "METRIC", "confidence": 0.9821330904960632}, {"text": "F1 score", "start_pos": 123, "end_pos": 131, "type": "METRIC", "confidence": 0.8771410286426544}]}, {"text": "We have changed this hyperparameter to 10, accounting for our observation that the training converges slower when operating on graph embeddings.", "labels": [], "entities": []}, {"text": "reports ED performance evaluated on DBpedia Spotlight and Reuters-128 datasets.", "labels": [], "entities": [{"text": "ED", "start_pos": 8, "end_pos": 10, "type": "METRIC", "confidence": 0.6845126152038574}, {"text": "DBpedia Spotlight", "start_pos": 36, "end_pos": 53, "type": "DATASET", "confidence": 0.968663364648819}, {"text": "Reuters-128 datasets", "start_pos": 58, "end_pos": 78, "type": "DATASET", "confidence": 0.8315445482730865}]}, {"text": "There are three models, end2end trained using their text entity vectors, our graph embeddings and the combination of them.", "labels": [], "entities": []}, {"text": "Training datasets and implementation details are the same for all models.", "labels": [], "entities": []}, {"text": "We train: Entity disambiguation performance: The end2end () system based on the original text-based embeddings, our graph embeddings and a combination of both evaluated using the GERBIL platform on DBpedia Spotlight and Reuters-128 datasets.", "labels": [], "entities": [{"text": "Entity disambiguation", "start_pos": 10, "end_pos": 31, "type": "TASK", "confidence": 0.6729346662759781}, {"text": "GERBIL", "start_pos": 179, "end_pos": 185, "type": "DATASET", "confidence": 0.8928558230400085}, {"text": "DBpedia Spotlight and Reuters-128 datasets", "start_pos": 198, "end_pos": 240, "type": "DATASET", "confidence": 0.7978781580924987}]}, {"text": "the models for 10 times and removed the models that did not converge (1 non-converging run for each single type of embedding and 2 for the combination).", "labels": [], "entities": []}, {"text": "The standard deviations of the models are between 0.02 \u2212 0.05 in the DBpedia Spotlight dataset and 0.01 \u2212 0.03 in the Reuters-128 dataset overall scores.", "labels": [], "entities": [{"text": "DBpedia Spotlight dataset", "start_pos": 69, "end_pos": 94, "type": "DATASET", "confidence": 0.9701130986213684}, {"text": "Reuters-128 dataset overall scores", "start_pos": 118, "end_pos": 152, "type": "DATASET", "confidence": 0.9457350522279739}]}, {"text": "Scores are produced using the GERBIL platform; these are Micro-averaged over the set of annotations in the dataset and Macro-averaged over the average performance per document.", "labels": [], "entities": [{"text": "GERBIL", "start_pos": 30, "end_pos": 36, "type": "DATASET", "confidence": 0.849199652671814}, {"text": "Micro-averaged", "start_pos": 57, "end_pos": 71, "type": "METRIC", "confidence": 0.92916339635849}]}, {"text": "The results are improved by including graph embeddings.", "labels": [], "entities": []}, {"text": "When we compare two models, trained by graph embeddings and trained by entity vectors, the results are improved up to 0.03 in Macro F1 scores and Micro Precision, and up to 0.07 in Macro Precision.", "labels": [], "entities": [{"text": "F1 scores", "start_pos": 132, "end_pos": 141, "type": "METRIC", "confidence": 0.9408651292324066}]}, {"text": "However, the improvement of the combination model is higher in Macro F1 and Recall.", "labels": [], "entities": [{"text": "F1", "start_pos": 69, "end_pos": 71, "type": "METRIC", "confidence": 0.7808653116226196}, {"text": "Recall", "start_pos": 76, "end_pos": 82, "type": "DATASET", "confidence": 0.9014468789100647}]}, {"text": "Micro-averaged results follow a similar trend.", "labels": [], "entities": []}, {"text": "When we look at the scores of) dataset, the combination model improves Macro F1 and Recall and Micro Recall up to 0.02, 0.015, and 0.013 respectively.", "labels": [], "entities": [{"text": "F1", "start_pos": 77, "end_pos": 79, "type": "METRIC", "confidence": 0.7317456007003784}, {"text": "Recall", "start_pos": 84, "end_pos": 90, "type": "METRIC", "confidence": 0.9604119658470154}, {"text": "Micro Recall", "start_pos": 95, "end_pos": 107, "type": "METRIC", "confidence": 0.8561312258243561}]}, {"text": "In the Micro-averaged evaluation, the combination model scores slightly below the model using graph embeddings alone.", "labels": [], "entities": []}, {"text": "To summarize the evaluation, our graph embeddings alone already lead to improvements over the original text-based embeddings, and their combination is even more beneficial.", "labels": [], "entities": []}, {"text": "This suggests that test-based and graph-based representations in fact encode somewhat complementary information.", "labels": [], "entities": []}, {"text": "to analyze the effect of graph embeddings.", "labels": [], "entities": []}, {"text": "We have two types of training sets, where the creation of negative samples differs (in one of them, we have filtered negative samples randomly, whereas, in the other, we filtered them by selecting the closest ones, as explained in Section 4.1).", "labels": [], "entities": []}, {"text": "In, the upper part shows the Accuracy, Precision, Recall, and F1 values of the training set filtered randomly while the lower part results refer to the training set filtered by selecting closest neighbors.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 29, "end_pos": 37, "type": "METRIC", "confidence": 0.9991573095321655}, {"text": "Precision", "start_pos": 39, "end_pos": 48, "type": "METRIC", "confidence": 0.9692497849464417}, {"text": "Recall", "start_pos": 50, "end_pos": 56, "type": "METRIC", "confidence": 0.9675731658935547}, {"text": "F1", "start_pos": 62, "end_pos": 64, "type": "METRIC", "confidence": 0.9961714148521423}]}, {"text": "The first bar in the charts contains the result of the input, which concatenates context and long abstract embeddings (in this condition the input size becomes 200), here entity information only comes from its long abstract.", "labels": [], "entities": []}, {"text": "The second bar presents the results of the input combination, context, word/span, and long abstract embeddings (the size of the input is 300).", "labels": [], "entities": []}, {"text": "In the third bar, the input is the concatenation of context, long abstract, and graph embeddings (the input size is 600).", "labels": [], "entities": []}, {"text": "Finally, the last bar indicates results for the concatenation of all types of inputs, for an input size of 700.", "labels": [], "entities": []}, {"text": "For each configuration, we run the model 5 times and get the mean and standard deviation values.", "labels": [], "entities": []}, {"text": "In, charts show the mean values and the lines on the charts indicate standard deviation.", "labels": [], "entities": []}, {"text": "Comparing the first and third bars (or the second and last bars) in, we can clearly seethe results are increased when the input includes the graph embeddings for both variants of negative sampling.", "labels": [], "entities": []}, {"text": "Comparing the third and last bars (or the first and second bars), we observe that including the span representation slightly decreases results for both sampling variants.", "labels": [], "entities": []}, {"text": "We attribute this to the presence of the context embedding, which already includes the span, thus this increases the number of parameters of the network without sub-  Embeddings in the end2end ED System", "labels": [], "entities": []}], "tableCaptions": []}