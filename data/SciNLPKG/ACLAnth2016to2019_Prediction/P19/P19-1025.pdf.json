{"title": [{"text": "Spatial Aggregation Facilitates Discovery of Spatial Topics", "labels": [], "entities": [{"text": "Spatial Aggregation Facilitates Discovery of Spatial Topics", "start_pos": 0, "end_pos": 59, "type": "TASK", "confidence": 0.8824044380869184}]}], "abstractContent": [{"text": "Spatial aggregation refers to merging of documents created at the same spatial location.", "labels": [], "entities": [{"text": "Spatial aggregation", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.8576579689979553}]}, {"text": "We show that by spatial aggregation of a large collection of documents and applying a traditional topic discovery algorithm on the ag-gregated data we can efficiently discover spatially distinct topics.", "labels": [], "entities": [{"text": "topic discovery", "start_pos": 98, "end_pos": 113, "type": "TASK", "confidence": 0.7287172675132751}]}, {"text": "By looking at topic discovery through matrix factorization lenses we show that spatial aggregation allows low rank approximation of the original document-word matrix, in which spatially distinct topics are preserved and non-spatial topics are aggre-gated into a single topic.", "labels": [], "entities": [{"text": "topic discovery", "start_pos": 14, "end_pos": 29, "type": "TASK", "confidence": 0.7171998172998428}]}, {"text": "Our experiments on synthetic data confirm this observation.", "labels": [], "entities": []}, {"text": "Our experiments on 4.7 million tweets collected during the Sandy Hurricane in 2012 show that spatial and temporal aggregation allows rapid discovery of relevant spatial and temporal topics during that period.", "labels": [], "entities": []}, {"text": "Our work indicates that different forms of document aggregation might be effective in rapid discovery of various types of distinct topics from large collections of documents.", "labels": [], "entities": []}], "introductionContent": [{"text": "Social microblogging sites such as Twitter generate large volumes of short documents through the activity of hundreds of millions of users around the world.", "labels": [], "entities": []}, {"text": "This provides an unprecedented access to the pulse of the global society.", "labels": [], "entities": []}, {"text": "Due to the sheer volume and diversity of the generated content, topic discovery has been an invaluable tool in an effort to make sense of this data.", "labels": [], "entities": [{"text": "topic discovery", "start_pos": 64, "end_pos": 79, "type": "TASK", "confidence": 0.8811111450195312}]}, {"text": "Regardless of a precise definition of a topic and a particular topic model, topics discovery is used to describe pertinent themes in a document corpus and serve to identify events, trends, and interests at the global, local, or asocial group level.", "labels": [], "entities": [{"text": "topics discovery", "start_pos": 76, "end_pos": 92, "type": "TASK", "confidence": 0.7696071863174438}]}, {"text": "Among the most popular topic modeling techniques are Latent Dirichlet Allocation (LDA), Latent Semantic Analysis (LSA), and Non-negative Matrix factorization (NMF).", "labels": [], "entities": []}, {"text": "When applying those techniques for topic discovery from microblogs, there are three main challenges: (1) how to improve computational speed, (2) how to extract useful topics, and (3) how to deal with short texts.", "labels": [], "entities": [{"text": "topic discovery", "start_pos": 35, "end_pos": 50, "type": "TASK", "confidence": 0.757698267698288}]}, {"text": "Many papers were published that address one or more of these challenges and most of them propose to modify the original topic models.", "labels": [], "entities": []}, {"text": "In this paper, we are focusing on aggregation (also referred to as pooling))) (), a particular document preprocessing technique that has been empirically shown to be useful for topic discovery from microblogs.", "labels": [], "entities": [{"text": "topic discovery from microblogs", "start_pos": 177, "end_pos": 208, "type": "TASK", "confidence": 0.8561282157897949}]}, {"text": "The main idea of aggregation is to combine multiple documents into a single document according to some external criterion and to apply a topic discovery algorithm on the aggregated documents.", "labels": [], "entities": [{"text": "topic discovery", "start_pos": 137, "end_pos": 152, "type": "TASK", "confidence": 0.7012173980474472}]}, {"text": "The earliest mentions of aggregation ())() are motivated by the difficulty when applying NMF and LDA to very short text documents.", "labels": [], "entities": []}, {"text": "This difficulty in finding useful topics is often attributed to the sparseness of the document-word matrix () (, which fails to provide confident counts of word cooccurrence and information about the shared context (.", "labels": [], "entities": []}, {"text": "Microblogs often come with metadata such as hashtags, author name, timestamp, or location.", "labels": [], "entities": []}, {"text": "By aggregating the microblogs according to such metadata, the intuition is that the resulting aggregated documents contain a sufficient number of words for topic modeling schemes to identify meaningful topics.", "labels": [], "entities": []}, {"text": "In addition, the authors of those early papers observe that aggregating microblogs that are similar in some sense (semantically, temporally) enriches the content present in a single document and results in better topics ().", "labels": [], "entities": []}, {"text": "Finally, due to reduction in a number of documents, aggregation also leads to computational savings.", "labels": [], "entities": []}, {"text": "While aggregation has received interest in the research community and there are several empirical studies illustrating its benefits, we are not aware of a study that manages to provide, beyond brief intuitive arguments, an insight into why aggregation works and what are its advantages and limitations.", "labels": [], "entities": []}, {"text": "In this paper we attempt to provide such an insight from the perspective of discovering spatially specific topics.", "labels": [], "entities": []}, {"text": "As will be evident, our insights extend to other means of aggregation.", "labels": [], "entities": []}, {"text": "Our argument will be given in the context of matrix factorization, where a document-word matrix X is represented as a product W \u00b7 H, where j-th row of matrix H represents word distribution in j-th topic and i-th row of matrix W represents a distribution of topics in i-th document.", "labels": [], "entities": []}, {"text": "We adopt the terminology from (, which distinguishes between common and distinct topics (see), where distribution of common topics within the corpus is not impacted by the aggregation metadata such as location, time, or author of a microblog, and distribution of distinct topics is correlated with the metadata.", "labels": [], "entities": []}, {"text": "We show that factorization of the aggregated matrix X a , obtained by merging documents based on metadata (e.g., location), allows its low rank approximation as W a \u00b7 Ha , where the resulting topic matrix Ha retains the distinct topics from H (e.g., spatial topics) and where the common topics from H are merged into a single topic in Ha . We will show empirical results confirming this observation both on synthetic and real-life data.", "labels": [], "entities": []}, {"text": "In particular, we will demonstrate this behavior in case of spatial and temporal aggregation.", "labels": [], "entities": []}, {"text": "The main contribution of this paper is in demonstrating that applying standard topic discovery algorithms such as NMF and LDA on aggregated documents results in discovery of topics related to the aggregation method.", "labels": [], "entities": [{"text": "topic discovery", "start_pos": 79, "end_pos": 94, "type": "TASK", "confidence": 0.7113166004419327}]}, {"text": "Moreover, since the aggregated matrix X a can be orders of magnitude smaller than the original matrix X, the computational cost can also be reduced by orders of magnitude.", "labels": [], "entities": []}, {"text": "Finally, as observed in the previous work, aggregation also alleviates the problem of sparsity when discovering topics in microblogs.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section, we use synthetic data to study the effect of document aggregation on topic discovery.", "labels": [], "entities": [{"text": "topic discovery", "start_pos": 86, "end_pos": 101, "type": "TASK", "confidence": 0.7636338770389557}]}, {"text": "Following the setup provided in Section 3.1, we created a dataset using a simplistic generative model.", "labels": [], "entities": []}, {"text": "Words in each document in the dataset are generated from two common topics (C1 and C2) and four spatially distinct topics (D1, D2, D3 and D4).", "labels": [], "entities": []}, {"text": "Each common and distinct topic uses a vocabulary with 100 words.", "labels": [], "entities": []}, {"text": "Each document is associated with a single topic.", "labels": [], "entities": []}, {"text": "To generate a document, a topic is chosen first, then 10 words are sampled randomly from the 100 words associated with that particular topic.", "labels": [], "entities": []}, {"text": "Documents generated from the common topics are distributed randomly within the square.", "labels": [], "entities": []}, {"text": "For each distinct topic, a circular region is defined within the square and the documents associated with that topic are placed by uniformly sampling within the circle.", "labels": [], "entities": []}, {"text": "The placement of the circular regions is shown in.", "labels": [], "entities": []}, {"text": "A total of 10, 000 documents are generated for each common topic and 1, 000 documents for each spatially distinct topic.", "labels": [], "entities": []}, {"text": "We call this dataset the non-aggregated dataset.", "labels": [], "entities": []}, {"text": "To demonstrate how aggregation affects the topic discovery, we divided the entire region in 4 \u00d7 4 small squares.", "labels": [], "entities": [{"text": "topic discovery", "start_pos": 43, "end_pos": 58, "type": "TASK", "confidence": 0.7763961255550385}]}, {"text": "Then we merged all the documents from each small square into a single aggregated document.", "labels": [], "entities": []}, {"text": "In this way, we constructed 16 aggregated documents.", "labels": [], "entities": []}, {"text": "We call this dataset the aggregated dataset.", "labels": [], "entities": []}, {"text": "NMF set to find 5 topics was applied to the nonaggregated and the aggregated datasets.", "labels": [], "entities": [{"text": "NMF set", "start_pos": 0, "end_pos": 7, "type": "DATASET", "confidence": 0.8640724122524261}]}, {"text": "In, we show the distribution of words in each of the 5 identified topic.", "labels": [], "entities": []}, {"text": "For example, the first bin in the left subplot shows that discovered topic 1 has 91 unique words, all belonging to common topic C1.", "labels": [], "entities": []}, {"text": "On the other hand, the first bin in the right subplot shows that discovered topic 1 has 100 unique words, 38 belonging to common topic C1 and 58 to common topic C2.", "labels": [], "entities": []}, {"text": "We can see that none of the spatially distinct topics are discovered when we apply NMF on the non-aggregated data.", "labels": [], "entities": []}, {"text": "All five identified topics contain words from the 2 common topics.", "labels": [], "entities": []}, {"text": "On the other hand, in the aggregated dataset, the first identified topic contains a mixture of words from the 2 common topics, while the remaining 4 are almost entirely comprised of words from the 4 spatially distinct topics.", "labels": [], "entities": []}, {"text": "This result ex-  Identifying spatially distinct topics in areal life dataset is a challenging task.", "labels": [], "entities": [{"text": "Identifying spatially distinct topics", "start_pos": 17, "end_pos": 54, "type": "TASK", "confidence": 0.8906464725732803}]}, {"text": "As we will demonstrate, we found that the aggregation scheme is quite successful in identifying distinct topics.", "labels": [], "entities": []}, {"text": "We performed our experiments on Hurricane Sandy Twitter corpus downloaded through Twitter search API 1 using the tweet IDs released in (.", "labels": [], "entities": []}, {"text": "The downloaded corpus contains 4.7 million tweets that temporally span 12 days surrounding the Hurricane Sandy and a few other distinguishable events between October 22nd, 2012 and November 2nd, 2012.", "labels": [], "entities": []}, {"text": "Every tweet in the dataset is also geotagged to one of 13 states along the East Coast of the U.S. During preprocessing we transformed all characters to lowercase and removed stopwords and special characters.", "labels": [], "entities": []}, {"text": "We also excluded repetitive letters that convey enthusiasm (e.g., birthdayy, birthdayyy, birthdayyyy).", "labels": [], "entities": []}, {"text": "Finally, TF-IDF document-word matrix is constructed using the 20, 000 most frequent words in the corpus.", "labels": [], "entities": []}, {"text": "Since the spatial distribution of tweets is highly imbalanced, we decided not to use a regular spatial grid.", "labels": [], "entities": []}, {"text": "Instead, we employed k-means clustering on the latitude and longitude information for each tweet to identify 200 cluster centers in space.", "labels": [], "entities": []}, {"text": "Each tweet is assigned to its nearest cluster center for spatial aggregation.", "labels": [], "entities": []}, {"text": "shows different clusters on 50, 000 tweets randomly sampled from the corpus.", "labels": [], "entities": []}, {"text": "We can observe that the density of clusters is much larger within heavily populated urban areas along the East Coast.", "labels": [], "entities": []}, {"text": "NMF was employed to find 500 topics with \u03b1 = 0.1 and \u03c1 = 0.5.", "labels": [], "entities": [{"text": "NMF", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.8233135938644409}, {"text": "\u03c1", "start_pos": 53, "end_pos": 54, "type": "METRIC", "confidence": 0.9535292983055115}]}, {"text": "Only 107 rows of H were found to have at least one nonzero entry.", "labels": [], "entities": []}, {"text": "Application of NMF on the 200 aggregated documents identifies some spatially distinct topics covering regions of varying size., shows word clouds for two large state-specific distinct topics.", "labels": [], "entities": [{"text": "NMF", "start_pos": 15, "end_pos": 18, "type": "DATASET", "confidence": 0.8224004507064819}]}, {"text": "We also found that large metropolitan areas such as New York City, Philadelphia, and Pittsburgh are represented as separate spatially distinct topics.", "labels": [], "entities": []}, {"text": "One such example is shown in.", "labels": [], "entities": []}, {"text": "Almost all the words in this topic are related to New York City airports.", "labels": [], "entities": []}, {"text": "In addition to spatial aggregation, we also performed experiments by aggregating data in space and time.", "labels": [], "entities": []}, {"text": "In addition to the k = 200 spatial clusters we divided the time interval into 12 days, resulting in a total of 2, 400 spatio-temporally aggregated documents.", "labels": [], "entities": []}, {"text": "As expected, this aggregation reveals distinct spatio-temporal topics.", "labels": [], "entities": []}, {"text": "We identified several purely temporal topics in this way, including the Halloween topic shown in.", "labels": [], "entities": []}, {"text": "It is interesting to observe that this topic also contains words related to the season opening To better illustrate this CMA-related topic, in we show several representative tweets.", "labels": [], "entities": []}, {"text": "These tweets were randomly selected from tweets containing at least one of the most frequent 10 words in the CMA-related topic.", "labels": [], "entities": []}, {"text": "Looking at word clouds is a descriptive way to evaluate the quality of discovered topics.", "labels": [], "entities": []}, {"text": "In this subsection we will present experimental results attempting to quantitatively evaluate the quality of the discovered topics.", "labels": [], "entities": []}, {"text": "To achieve this we use the space-time scan statistics implemented in the SaTScan software.", "labels": [], "entities": [{"text": "SaTScan software", "start_pos": 73, "end_pos": 89, "type": "DATASET", "confidence": 0.9185546338558197}]}, {"text": "We selected the 10 most frequent words in each discovered topic and labeled each tweet from the corpus based on the presence of these words.", "labels": [], "entities": []}, {"text": "If a tweet contains any of the 10 words it is assigned to the corresponding topic.", "labels": [], "entities": []}, {"text": "We call all tweets assigned to the given topic the positive tweets.", "labels": [], "entities": []}, {"text": "If the topic is strongly spatial, we would expect the assigned tweets to be strongly spatially clustered.", "labels": [], "entities": []}, {"text": "If the topic is strongly spatio-temporal, we would expect the assigned tweets to cluster within a particular spatio-temporal area.", "labels": [], "entities": []}, {"text": "The space-time scan statistic is employed to measure enrichment by positive tweets of cylindrical windows covering a circular spatial region and a temporal interval.", "labels": [], "entities": []}, {"text": "The cylindrical window is moved in space and time to search for the statistically strongest clusters).", "labels": [], "entities": []}, {"text": "The cylinder with the strongest enrichment of positive tweets (e.g., based on the ratio between positive tweets and all tweets within the cylinder) is a potential candidate for the significant spatio-temporal cluster.", "labels": [], "entities": []}, {"text": "Distributional properties of scan statistics can be used to evaluate the statistical significance of the strongest cylinder.", "labels": [], "entities": []}, {"text": "This is done by permuting the labels of tweets multiple times (999 times in this study) and calculating the score of the strongest cylinder in each permutation.", "labels": [], "entities": []}, {"text": "The p-value is then calculated by counting the fraction of the permuted scores larger than the score on the actual data.", "labels": [], "entities": []}, {"text": "The p-value reported in this experiment can bethought of as a measure of the spatio-temporal distinctiveness of the identified topic.", "labels": [], "entities": []}, {"text": "Characterization of distinct topics using p-value has some limitations.", "labels": [], "entities": []}, {"text": "We observed that many distinct topics discovered through aggregation receive p-value equal to zero, making it impossible to identify the strongest distinct topic.", "labels": [], "entities": []}, {"text": "For this reason, we used deviation (\u2206), which measures how many standard deviations apart is the score of the best cylinder observed on the actual data compared to the scores of the best cylinders observed on the permuted data.", "labels": [], "entities": []}, {"text": "In, we show the strongest topics based on the deviation (\u2206).", "labels": [], "entities": []}, {"text": "In each case, the p-value was 0.", "labels": [], "entities": []}, {"text": "For topics labeled with stars in Table 2,.", "labels": [], "entities": []}, {"text": "It maybe noted that New York City, being a very large metropolitan area, has multiple identified topics.", "labels": [], "entities": []}, {"text": "One such topic, called NYC airport, was previously presented in.", "labels": [], "entities": []}, {"text": "Another such topic, called NYC, is presented in.", "labels": [], "entities": []}, {"text": "The spatiotemporal region called Power outage is shown in.", "labels": [], "entities": []}, {"text": "10, 000 tweets in this figure are labeled as positive or negative based on the presence or absence of the keywords of this topic.", "labels": [], "entities": []}, {"text": "This topic corresponds to multiple power outages in the aftermath of the Sandy Hurricane.", "labels": [], "entities": []}], "tableCaptions": []}