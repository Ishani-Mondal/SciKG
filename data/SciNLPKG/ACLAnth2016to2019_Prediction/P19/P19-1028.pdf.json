{"title": [{"text": "Augmenting Neural Networks with First-order Logic", "labels": [], "entities": [{"text": "Augmenting Neural Networks", "start_pos": 0, "end_pos": 26, "type": "TASK", "confidence": 0.886963963508606}]}], "abstractContent": [{"text": "Today, the dominant paradigm for training neural networks involves minimizing task loss on a large dataset.", "labels": [], "entities": []}, {"text": "Using world knowledge to inform a model, and yet retain the ability to perform end-to-end training remains an open question.", "labels": [], "entities": []}, {"text": "In this paper, we present a novel framework for introducing declarative knowledge to neural network architectures in order to guide training and prediction.", "labels": [], "entities": []}, {"text": "Our framework systematically compiles logical statements into computation graphs that augment a neural network without extra learnable parameters or manual redesign.", "labels": [], "entities": []}, {"text": "We evaluate our modeling strategy on three tasks: machine comprehension, natural language inference , and text chunking.", "labels": [], "entities": [{"text": "text chunking", "start_pos": 106, "end_pos": 119, "type": "TASK", "confidence": 0.7640256881713867}]}, {"text": "Our experiments show that knowledge-augmented networks can strongly improve over baselines, especially in low-data regimes.", "labels": [], "entities": []}], "introductionContent": [{"text": "Neural models demonstrate remarkable predictive performance across abroad spectrum of NLP tasks: e.g., natural language inference (, machine comprehension (, machine translation (, and summarization ().", "labels": [], "entities": [{"text": "machine translation", "start_pos": 158, "end_pos": 177, "type": "TASK", "confidence": 0.7861160635948181}, {"text": "summarization", "start_pos": 185, "end_pos": 198, "type": "TASK", "confidence": 0.9865275025367737}]}, {"text": "These successes can be attributed to their ability to learn robust representations from data.", "labels": [], "entities": []}, {"text": "However, such end-to-end training demands a large number of training examples; for example, training atypical network for machine translation may require millions of sentence pairs (e.g..", "labels": [], "entities": [{"text": "machine translation", "start_pos": 122, "end_pos": 141, "type": "TASK", "confidence": 0.748965859413147}]}, {"text": "The difficulties and expense of curating large amounts of annotated data are well understood and, consequently, massive datasets may not be available for new tasks, domains or languages.", "labels": [], "entities": []}, {"text": "In this paper, we argue that we can combat the data hungriness of neural networks by taking advantage of domain knowledge expressed as  first-order logic.", "labels": [], "entities": []}, {"text": "As an example, consider the task of reading comprehension, where the goal is to answer a question based on a paragraph of text (.", "labels": [], "entities": []}, {"text": "Attention-driven models such as BiDAF () learn to align words in the question with words in the text as an intermediate step towards identifying the answer.", "labels": [], "entities": []}, {"text": "While alignments (e.g. author to writing) can be learned from data, we argue that models can reduce their data dependence if they were guided by easily stated rules such as: Prefer aligning phrases that are marked as similar according to an external resource, e.g., ConceptNet ().", "labels": [], "entities": []}, {"text": "If such declaratively stated rules can be incorporated into training neural networks, then they can provide the inductive bias that can reduce data dependence for training.", "labels": [], "entities": []}, {"text": "That general neural networks can represent such Boolean functions is known and has been studied both from the theoretical and empirical perspectives (e.g..", "labels": [], "entities": []}, {"text": "Recently, exploit this property to train a neural network to mimic a teacher network that uses structured rules.", "labels": [], "entities": []}, {"text": "In this paper, we seek to directly incorporate such structured knowledge into a neural network architecture without substantial changes to the training methods.", "labels": [], "entities": []}, {"text": "We focus on three questions: 1.", "labels": [], "entities": []}, {"text": "Can we integrate declarative rules with endto-end neural network training?", "labels": [], "entities": []}, {"text": "2. Can such rules help ease the need for data?", "labels": [], "entities": []}, {"text": "3. How does incorporating domain expertise compare against large training resources powered by pre-trained representations?", "labels": [], "entities": []}, {"text": "The first question poses the key technical challenge we address in this paper.", "labels": [], "entities": []}, {"text": "On one hand, we wish to guide training and prediction with neural networks using logic, which is non-differentiable.", "labels": [], "entities": [{"text": "prediction", "start_pos": 43, "end_pos": 53, "type": "TASK", "confidence": 0.9029837250709534}]}, {"text": "On the other hand, we seek to retain the advantages of gradient-based learning without having to redesign the training scheme.", "labels": [], "entities": []}, {"text": "To this end, we propose a framework that allows us to systematically augment an existing network architecture using constraints about its nodes by deterministically converting rules into differentiable computation graphs.", "labels": [], "entities": []}, {"text": "To allow for the possibility of such rules being incorrect, our framework is designed to admit soft constraints from the ground up.", "labels": [], "entities": []}, {"text": "Our framework is compatible with off-the-shelf neural networks without extensive redesign or any additional trainable parameters.", "labels": [], "entities": []}, {"text": "To address the second and the third questions, we empirically evaluate our framework on three tasks: machine comprehension, natural language inference, and text chunking.", "labels": [], "entities": [{"text": "text chunking", "start_pos": 156, "end_pos": 169, "type": "TASK", "confidence": 0.7616601288318634}]}, {"text": "In each case, we use a general off-the-shelf model for the task, and study the impact of simple logical constraints on observed neurons (e.g., attention) for different data sizes.", "labels": [], "entities": []}, {"text": "We show that our framework can successfully improve an existing neural design, especially when the number of training examples is limited.", "labels": [], "entities": []}, {"text": "In summary, our contributions are: 1.", "labels": [], "entities": []}, {"text": "We introduce anew framework for incorporating first-order logic rules into neural network design in order to guide both training and prediction.", "labels": [], "entities": []}, {"text": "2. We evaluate our approach on three different NLP tasks: machine comprehension, textual entailment, and text chunking.", "labels": [], "entities": [{"text": "text chunking", "start_pos": 105, "end_pos": 118, "type": "TASK", "confidence": 0.7669136822223663}]}, {"text": "We show that augmented models lead to large performance gains in the low training data regimes.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section, we will answer the research questions raised in \u00a71 by focusing on the effectiveness of our augmentation framework.", "labels": [], "entities": []}, {"text": "Specifically, we will explore three types of constraints by augmenting: 1) intermediate decisions (i.e. attentions); 2) output decisions constrained by intermediate states; 3) output decisions constrained using label dependencies.", "labels": [], "entities": []}, {"text": "To this end, we instantiate our framework on three tasks: machine comprehension, natural language inference, and text chunking.", "labels": [], "entities": [{"text": "text chunking", "start_pos": 113, "end_pos": 126, "type": "TASK", "confidence": 0.7630322575569153}]}, {"text": "Across all experiments, our goal is to study the modeling flexibility of our framework and its ability to improve performance, especially with decreasing amounts of training data.", "labels": [], "entities": []}, {"text": "To study low data regimes, our augmented networks are trained using varying amounts of training data to see how performances vary from baselines.", "labels": [], "entities": []}, {"text": "For detailed model setup, please refer to the appendices.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Impact of constraints on BiDAF. Each score  represents the average span F 1 on our test set (i.e. offi- cial dev set) among 3 random runs. Constrained mod- els and ELMo models are built on top of BiDAF. We  set \u03c1 = 2 for both R 1 and R 2 across all percentages.", "labels": [], "entities": [{"text": "BiDAF", "start_pos": 206, "end_pos": 211, "type": "DATASET", "confidence": 0.8820162415504456}]}, {"text": " Table 3: Impact of constraints on L-DAtt network.  Each score represents the average accuracy on SNLI  test set among 3 random runs. For both N 1 and N 2 , we  set \u03c1 =", "labels": [], "entities": [{"text": "accuracy", "start_pos": 86, "end_pos": 94, "type": "METRIC", "confidence": 0.9993176460266113}, {"text": "SNLI  test set", "start_pos": 98, "end_pos": 112, "type": "DATASET", "confidence": 0.8874470392862955}]}, {"text": " Table 4: Impact of constraints on BiLSTM tagger.  Each score represents the average accuracy on test set  of 3 random runs. The columns of +CRF, +C 1:5 , and  +CRF,C 1:5 are on top of the BiLSTM baseline. For  C 1:4 , \u03c1 = 4 for all percentages. For C 5 , \u03c1 = 16.", "labels": [], "entities": [{"text": "BiLSTM tagger", "start_pos": 35, "end_pos": 48, "type": "TASK", "confidence": 0.7946017384529114}, {"text": "accuracy", "start_pos": 85, "end_pos": 93, "type": "METRIC", "confidence": 0.9993627667427063}, {"text": "BiLSTM baseline", "start_pos": 189, "end_pos": 204, "type": "DATASET", "confidence": 0.8886193633079529}]}]}