{"title": [], "abstractContent": [{"text": "In this paper we discuss the usefulness of applying a checking procedure to existing thesauri.", "labels": [], "entities": []}, {"text": "The procedure is based on the analysis of discrepancies of corpus-based and thesaurus-based word similarities.", "labels": [], "entities": []}, {"text": "We applied the procedure to more than 30 thousand words of the Russian wordnet and found some serious errors in word sense description, including inaccurate relationships and missing senses of ambiguous words.", "labels": [], "entities": [{"text": "word sense description", "start_pos": 112, "end_pos": 134, "type": "TASK", "confidence": 0.656538854042689}]}], "introductionContent": [{"text": "Large thesauri such as Princeton WordNet and wordnets created for other languages) are important instruments for natural language processing.", "labels": [], "entities": [{"text": "Princeton WordNet", "start_pos": 23, "end_pos": 40, "type": "DATASET", "confidence": 0.9051142930984497}, {"text": "natural language processing", "start_pos": 113, "end_pos": 140, "type": "TASK", "confidence": 0.6476091146469116}]}, {"text": "Developing and maintaining such resources is a very expensive and time-consuming procedure.", "labels": [], "entities": []}, {"text": "At the same time, contemporary computational systems, which can translate texts with almost human quality, cannot automatically create such thesauri from scratch providing a structure somehow similar to resources created by professionals.", "labels": [], "entities": []}, {"text": "But if such a thesaurus exists, the developers should have approaches to maintain and improve it.", "labels": [], "entities": []}, {"text": "In previous works, various methods on lexical enrichment of thesauri have been studied).", "labels": [], "entities": []}, {"text": "But another issue was not practically discussed: how to find mistakes in existing thesaurus descriptions: incorrect relations or missed significant senses of ambiguous words, which were not included accidentally or appeared recently.", "labels": [], "entities": []}, {"text": "In fact, it is much more difficult to reveal missed and novel senses or wrong relations, if compared to detect novel words ().", "labels": [], "entities": []}, {"text": "So it is known that such missed senses are often found during semantic annotation of a corpus and this is an additional problem for such annotation.", "labels": [], "entities": []}, {"text": "In this paper, we consider an approach that uses embedding models to reveal problems in a thesaurus.", "labels": [], "entities": []}, {"text": "Previously, distributional and embedding methods were evaluated in comparison with manual data ().", "labels": [], "entities": []}, {"text": "But we can use them in the opposite way: to utilize embeddingbased similarities and try to detect some problems in a thesaurus.", "labels": [], "entities": []}, {"text": "We study such similarities for more than 30 thousand words presented in Russian wordnet RuWordNet ( . RuWordNet was created on the basis of another Russian thesaurus RuThes in 2016, which was developed as a tool for natural language processing during more than 20 years ().", "labels": [], "entities": []}, {"text": "Currently, the published version of RuWordNet includes 110 thousand Russian words and expressions.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1. Distribution of parts of speech among  problematic words", "labels": [], "entities": [{"text": "Distribution of parts of speech among  problematic words", "start_pos": 10, "end_pos": 66, "type": "TASK", "confidence": 0.8733959794044495}]}, {"text": " Table 2. Explanations of discrepancies between  thesaurus and distributional similarities for Top-100 of  ProblemList", "labels": [], "entities": [{"text": "ProblemList", "start_pos": 107, "end_pos": 118, "type": "TASK", "confidence": 0.5393410921096802}]}, {"text": " Table 3. Examples of found ambiguous words with missed senses", "labels": [], "entities": []}]}