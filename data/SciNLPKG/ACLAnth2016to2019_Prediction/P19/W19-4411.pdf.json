{"title": [{"text": "How to account for mispellings: Quantifying the benefit of character representations in neural content scoring models", "labels": [], "entities": []}], "abstractContent": [{"text": "Character-based representations in neural models have been claimed to be a tool to overcome spelling variation in word token-based input.", "labels": [], "entities": []}, {"text": "We examine this claim in neural models for content scoring.", "labels": [], "entities": [{"text": "content scoring", "start_pos": 43, "end_pos": 58, "type": "TASK", "confidence": 0.770453691482544}]}, {"text": "We formulate precise hypotheses about the possible effects of adding character representations to word-based models and test these hypotheses on large-scale real-world content scoring datasets.", "labels": [], "entities": []}, {"text": "We find that, while character representations may provide small performance gains in general, their effectiveness in accounting for spelling variation maybe limited.", "labels": [], "entities": [{"text": "spelling variation", "start_pos": 132, "end_pos": 150, "type": "TASK", "confidence": 0.7406091392040253}]}, {"text": "We show that spelling correction can provide larger gains than character representations, and that spelling correction improves the performance of models with character representations.", "labels": [], "entities": [{"text": "spelling correction", "start_pos": 13, "end_pos": 32, "type": "TASK", "confidence": 0.8815003037452698}, {"text": "spelling correction", "start_pos": 99, "end_pos": 118, "type": "TASK", "confidence": 0.8264198899269104}]}, {"text": "With these insights, we report anew state of the art on the ASAP-SAS short content scoring dataset.", "labels": [], "entities": [{"text": "ASAP-SAS short content scoring dataset", "start_pos": 60, "end_pos": 98, "type": "DATASET", "confidence": 0.6492193698883056}]}], "introductionContent": [{"text": "Character-based representations have recently been explored in a variety of models in natural language processing, including sequence labeling () and machine translation.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 150, "end_pos": 169, "type": "TASK", "confidence": 0.8281405866146088}]}, {"text": "In educational applications such as content and essay scoring, character-based representations have been claimed to hold promise as away to account for variation in spelling without resorting to spelling correction () -particularly in assessments of K-12 populations or English language learners -in part because spelling correction can introduce mistakes from bad corrections.", "labels": [], "entities": [{"text": "essay scoring", "start_pos": 48, "end_pos": 61, "type": "TASK", "confidence": 0.7077795267105103}, {"text": "spelling correction", "start_pos": 313, "end_pos": 332, "type": "TASK", "confidence": 0.7121764868497849}]}, {"text": "To the extent that character-based representations can in fact help overcome noise from spelling and other errors, they could be a useful component of robust scoring models.", "labels": [], "entities": []}, {"text": "For content scoring applications in particular, where scoring rubrics specif- * Work carried out while at ETS.", "labels": [], "entities": [{"text": "content scoring", "start_pos": 4, "end_pos": 19, "type": "TASK", "confidence": 0.7954756915569305}, {"text": "ETS", "start_pos": 106, "end_pos": 109, "type": "DATASET", "confidence": 0.9660313129425049}]}, {"text": "ically exclude spelling variation from consideration in scoring, it is important that credit is given for the intended words and ideas regardless of spelling.", "labels": [], "entities": []}, {"text": "However, the contributions of character-based representations to automated scoring performance have rarely been systematically studied.", "labels": [], "entities": []}, {"text": "To date, no large-scale study of the effect of character representations in real-world scoring scenarios has been carried out.", "labels": [], "entities": []}, {"text": "In particular, given the success and proliferation of neural network-based character-based representations in related tasks, there is a need to assess the potential of neural character representations for educational scoring applications.", "labels": [], "entities": []}, {"text": "The rationale for adoption and use of character representations, especially to augment a backbone of word representations in neural models, is typically based on enriching the input representations with morphological information (, accounting for noise, out-of-vocabulary inputs), or both (.", "labels": [], "entities": []}, {"text": "We distinguish two main claims that are made for employing character representations in order to account for noise in inputs, sometimes implicitly.", "labels": [], "entities": []}, {"text": "One claim is that including character representations in a model accounts for spelling errors in the input.", "labels": [], "entities": []}, {"text": "The idea is that models sensitive to characters can implicitly learn the correspondence between incorrect and correct spellings of words from the character-sequence-to-score associations (as opposed to word-to-score associations) across the training data ( . If this is the case, then models without access to character representations should perform more poorly on responses with more misspelled words, since standard word-only neural models ignore these tokens (because the tokens are unlikely to appear in sets of word embeddings and hence are typically treated as an unknown token).", "labels": [], "entities": []}, {"text": "Therefore, one way to operationalize this claim is the following hypothesis: \u2022 Hypothesis 1: On responses with more spelling errors, models with additional character representations should improve model performance relative to models with only word representations.", "labels": [], "entities": []}, {"text": "This result should be manifested in a statistical interaction between the addition of character representations to a model and number of misspellings in the input.", "labels": [], "entities": []}, {"text": "A second claim, based on the first claim, is that the addition of character representations to a model's representational repertoire should be sufficient to match the use of spelling correction on the input (without adding character representations).", "labels": [], "entities": []}, {"text": "This claim leads to two hypotheses: \u2022 Hypothesis 2.1: Models with additional character representations should achieve performance similar to models without character representations trained on spell-corrected input.", "labels": [], "entities": []}, {"text": "\u2022 Hypothesis 2.2: The performance of models with additional character representations should be similar whether or not they are trained on spell-corrected input.", "labels": [], "entities": []}, {"text": "In this paper, we test these hypotheses on a large and diverse collection of content-based questions spanning formative and summative assessments.", "labels": [], "entities": []}, {"text": "We focus on neural models for content scoring.", "labels": [], "entities": [{"text": "content scoring", "start_pos": 30, "end_pos": 45, "type": "TASK", "confidence": 0.7733063399791718}]}, {"text": "Content scoring scenarios offer a good testbed for exploring the potential contributions of characterbased models because the rubrics of questions focus solely on the content of responses and ignore writing quality metrics such as spelling and mechanics errors.", "labels": [], "entities": []}, {"text": "Neural models have seen the most active research on character-based representation and may make possible more flexible and expressive character representations compared with nonneural models.", "labels": [], "entities": []}, {"text": "We leave a more general exploration of the contribution of character-based models across both neural and non-neural contexts to future work.", "labels": [], "entities": []}, {"text": "Our work makes the following contributions: \u2022 We demonstrate that, while neural models with additional character representations show a small but durable edge over wordonly models in representative real-world contexts, this improvement does not increase significantly as the number of spelling errors increases.", "labels": [], "entities": []}, {"text": "\u2022 We show that spell-corrected input improves model performance more than the addition of character representations, and that models with additional character representations can be improved further by using spell correction.", "labels": [], "entities": [{"text": "spell correction", "start_pos": 208, "end_pos": 224, "type": "TASK", "confidence": 0.7244996428489685}]}, {"text": "\u2022 We achieve anew state of the art on the ASAP-SAS dataset.", "labels": [], "entities": [{"text": "ASAP-SAS dataset", "start_pos": 42, "end_pos": 58, "type": "DATASET", "confidence": 0.8960146605968475}]}], "datasetContent": [{"text": "To summarize model performance, we report mean squared error (MSE) and quadratic weighted kappa (QWK).", "labels": [], "entities": [{"text": "mean squared error (MSE)", "start_pos": 42, "end_pos": 66, "type": "METRIC", "confidence": 0.9536860982577006}, {"text": "quadratic weighted kappa (QWK)", "start_pos": 71, "end_pos": 101, "type": "METRIC", "confidence": 0.9065098961194357}]}, {"text": "For the ASAP-SAS dataset, we also report the Fisher-weighted mean QWK across questions, which was the official metric of the ASAP competition.", "labels": [], "entities": [{"text": "ASAP-SAS dataset", "start_pos": 8, "end_pos": 24, "type": "DATASET", "confidence": 0.9339548051357269}, {"text": "Fisher-weighted mean QWK", "start_pos": 45, "end_pos": 69, "type": "METRIC", "confidence": 0.8938287099202474}, {"text": "ASAP competition", "start_pos": 125, "end_pos": 141, "type": "TASK", "confidence": 0.617014080286026}]}, {"text": "To analyze the robustness of performance improvements with character representations, we employ generalized linear mixed-effect models (GLMMs).", "labels": [], "entities": []}, {"text": "Mixed-effect models can better capture variation across individual questions by modeling questions as random effects.", "labels": [], "entities": []}, {"text": "In contrast with previous work in NLP that analyzes model performance with mixed-effect models, we analyze per-response prediction errors using real-valued regression model predictions.", "labels": [], "entities": []}, {"text": "Since the prediction errors are not normally distributed, using standard linear mixed effect models (even with transformation of the dependent variable) can result in Type I errors.", "labels": [], "entities": []}, {"text": "Analysis of the prediction error data showed that gamma distributions provided the best fit.", "labels": [], "entities": []}, {"text": "Hence we employ gamma GLMMs with a log link function.", "labels": [], "entities": []}, {"text": "We investigated the interaction predicted by Hypothesis 1 with the following GLMM: feat is the representation type (w vs. w+c), missp is the misspelling bin, and feat * missp is their interaction.", "labels": [], "entities": []}, {"text": "#words is the number of words in the response, and score is the response's human-assigned score.", "labels": [], "entities": [{"text": "score", "start_pos": 51, "end_pos": 56, "type": "METRIC", "confidence": 0.9613977670669556}]}, {"text": "(1|question) represents a random intercept for each question.", "labels": [], "entities": []}, {"text": "This model estimates the effect of the representation type and the number of misspellings and their interaction, while controlling for the effect of number of words and assigned score.", "labels": [], "entities": []}, {"text": "Hypothesis 2 was examined with a GLMM model of the form: where sp is the presence or absence of spelling correction.", "labels": [], "entities": []}, {"text": "For each dataset, we address Hypothesis 2 first, since the evidence relating to this hypothesis is the relative performance of the different models.", "labels": [], "entities": [{"text": "Hypothesis", "start_pos": 29, "end_pos": 39, "type": "METRIC", "confidence": 0.8998661637306213}]}, {"text": "Then, looking at model predictions by bins of responses for numbers of misspellings, we examine evidence for Hypothesis 1.", "labels": [], "entities": []}, {"text": "shows the mean MSE, mean QWK, and mean Fisher-transformed QWK across the 10 questions in the ASAP-SAS dataset.", "labels": [], "entities": [{"text": "ASAP-SAS dataset", "start_pos": 93, "end_pos": 109, "type": "DATASET", "confidence": 0.9281227886676788}]}, {"text": "First, we see that the models with character representations outperform their word-only counterparts (w+c vs. w; lower MSE and higher QWK).", "labels": [], "entities": []}, {"text": "Second, the spellcorrected models outperform the corresponding uncorrected models (+sp vs. -sp) with the same representations.", "labels": [], "entities": []}, {"text": "The spell-corrected model with character representations achieves the highest performance.", "labels": [], "entities": []}, {"text": "The Fisher-transformed mean QWK of 0.7788 represents anew state of the art for the ASAP-SAS dataset for the official test set for single models without data augmentation.", "labels": [], "entities": [{"text": "Fisher-transformed mean QWK", "start_pos": 4, "end_pos": 31, "type": "METRIC", "confidence": 0.6732542117436727}, {"text": "ASAP-SAS dataset", "start_pos": 83, "end_pos": 99, "type": "DATASET", "confidence": 0.8445368111133575}]}, {"text": "With regard to Hypothesis 2.1, that character representations should improve performance as much as spell correction, the results demonstrate that adding character representations (w+c, -sp: mean MSE = 0.2218) can outperform spell correction of a word-only model (w, +sp: mean MSE = 0.2236) (although this is not reflected in the QWK results).", "labels": [], "entities": [{"text": "spell correction", "start_pos": 100, "end_pos": 116, "type": "TASK", "confidence": 0.8021048903465271}, {"text": "spell correction", "start_pos": 225, "end_pos": 241, "type": "TASK", "confidence": 0.7113350927829742}, {"text": "QWK", "start_pos": 330, "end_pos": 333, "type": "DATASET", "confidence": 0.9082626700401306}]}], "tableCaptions": [{"text": " Table 1: Overview of the datasets used in this work. The number of responses covers both the official train and  test splits for ASAP-SAS. The mean number of responses and words were computed over the official training set  for ASAP-SAS and over 5-fold splits of each question's data (80% train) for the remaining datasets.", "labels": [], "entities": [{"text": "ASAP-SAS", "start_pos": 130, "end_pos": 138, "type": "DATASET", "confidence": 0.7611269354820251}, {"text": "ASAP-SAS", "start_pos": 229, "end_pos": 237, "type": "DATASET", "confidence": 0.6810013651847839}]}, {"text": " Table 2: Human-machine agreement across models on  ASAP-SAS. w = word representations, w+c = word  and character representations, -sp = no spelling correc- tion, +sp = spelling correction.", "labels": [], "entities": []}, {"text": " Table 3: GLMM parameter estimates, standard errors,  and p-values for model prediction error across all mod- els on ASAP-SAS. Feature set is w vs. w+c. Spelling  is +/-spelling correction.", "labels": [], "entities": [{"text": "standard errors", "start_pos": 36, "end_pos": 51, "type": "METRIC", "confidence": 0.9341844320297241}, {"text": "ASAP-SAS", "start_pos": 117, "end_pos": 125, "type": "DATASET", "confidence": 0.8616465926170349}]}, {"text": " Table 4: GLMM summary for model prediction error  on ASAP-SAS for the models without spelling correc- tion. Feature set is w vs. w+c. Missp {1,2+} are bins  of number of misspellings. Score is human-assigned  response score.", "labels": [], "entities": [{"text": "model prediction", "start_pos": 27, "end_pos": 43, "type": "TASK", "confidence": 0.7206749022006989}, {"text": "ASAP-SAS", "start_pos": 54, "end_pos": 62, "type": "DATASET", "confidence": 0.78886878490448}, {"text": "Score", "start_pos": 185, "end_pos": 190, "type": "METRIC", "confidence": 0.9647328853607178}]}, {"text": " Table 5: Human-machine agreement across models on  Formative-K12-SAS.", "labels": [], "entities": []}, {"text": " Table 6: GLMM parameter estimates, standard errors,  and p-values for model prediction error across all mod- els on Formative-K12-SAS.", "labels": [], "entities": []}, {"text": " Table 7: GLMM summary for model prediction er- ror on Formative-K12-SAS for the models without  spelling correction.", "labels": [], "entities": [{"text": "GLMM", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.651032030582428}, {"text": "model prediction", "start_pos": 27, "end_pos": 43, "type": "TASK", "confidence": 0.7573043704032898}, {"text": "er- ror", "start_pos": 44, "end_pos": 51, "type": "METRIC", "confidence": 0.8198386232058207}]}, {"text": " Table 8: Human-machine agreement across models on  Summative-LAS.", "labels": [], "entities": []}, {"text": " Table 9: GLMM parameter estimates, standard errors,  and p-values for model prediction error across all mod- els on Summative-LAS.", "labels": [], "entities": []}, {"text": " Table 10: GLMM summary for model prediction er- ror on Summative-LAS for the models without spelling  correction.", "labels": [], "entities": [{"text": "GLMM", "start_pos": 11, "end_pos": 15, "type": "METRIC", "confidence": 0.695207953453064}, {"text": "model prediction er- ror", "start_pos": 28, "end_pos": 52, "type": "METRIC", "confidence": 0.7424532830715179}]}, {"text": " Table 11: Human-machine agreement on ASAP-SAS  by prompt.", "labels": [], "entities": [{"text": "ASAP-SAS", "start_pos": 38, "end_pos": 46, "type": "TASK", "confidence": 0.8237510919570923}]}]}