{"title": [{"text": "Huawei's NMT Systems for the WMT 2019 Biomedical Translation Task", "labels": [], "entities": [{"text": "WMT 2019 Biomedical Translation", "start_pos": 29, "end_pos": 60, "type": "TASK", "confidence": 0.7264725118875504}]}], "abstractContent": [{"text": "This paper describes Huawei's neural machine translation systems for the WMT 2019 biomedical translation shared task.", "labels": [], "entities": [{"text": "neural machine translation", "start_pos": 30, "end_pos": 56, "type": "TASK", "confidence": 0.6569413940111796}, {"text": "WMT 2019 biomedical translation shared task", "start_pos": 73, "end_pos": 116, "type": "TASK", "confidence": 0.8138389984766642}]}, {"text": "We trained and fine-tuned our systems on a combination of out-of-domain and in-domain parallel corpora for six translation directions covering English-Chinese, English-French and English-German language pairs.", "labels": [], "entities": []}, {"text": "Our submitted systems achieve the best BLEU scores on English-French and English-German language pairs according to the official evaluation results.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 39, "end_pos": 43, "type": "METRIC", "confidence": 0.9987931251525879}]}, {"text": "In the English-Chinese translation task, our systems are in the second place.", "labels": [], "entities": [{"text": "English-Chinese translation task", "start_pos": 7, "end_pos": 39, "type": "TASK", "confidence": 0.6843775709470113}]}, {"text": "The enhanced performance is attributed to more in-domain training and more sophisticated models developed.", "labels": [], "entities": []}, {"text": "Development of translation models and transfer learning (or domain adaptation) methods has significantly contributed to the progress of the task.", "labels": [], "entities": [{"text": "translation", "start_pos": 15, "end_pos": 26, "type": "TASK", "confidence": 0.9760807752609253}, {"text": "transfer learning (or domain adaptation)", "start_pos": 38, "end_pos": 78, "type": "TASK", "confidence": 0.7313403572354998}]}], "introductionContent": [{"text": "In recent years, neural machine translation (NMT) has achieved substantial progress and outperforms statistical machine translation (SMT), especially when large volumes of parallel corpora are available.", "labels": [], "entities": [{"text": "neural machine translation (NMT)", "start_pos": 17, "end_pos": 49, "type": "TASK", "confidence": 0.82127778728803}, {"text": "statistical machine translation (SMT)", "start_pos": 100, "end_pos": 137, "type": "TASK", "confidence": 0.7744264205296835}]}, {"text": "However, compared to out-of-domain (OOD) data, in-domain data is typically in a small volume and hard to obtain.", "labels": [], "entities": []}, {"text": "Therefore, a lot of research focuses on how to make use of OOD data to improvement in-domain NMT systems.", "labels": [], "entities": [{"text": "OOD data", "start_pos": 59, "end_pos": 67, "type": "DATASET", "confidence": 0.6913417428731918}]}, {"text": "Among them, a well-accepted method for domain adaptation is to fine-tune a pre-trained baseline model using in-domain data.", "labels": [], "entities": [{"text": "domain adaptation", "start_pos": 39, "end_pos": 56, "type": "TASK", "confidence": 0.8061850368976593}]}, {"text": "In this paper, we present Huawei's practices on adapting our NMT systems from general-domain to in-domain.", "labels": [], "entities": []}, {"text": "In addition to fine-tuning our OOD systems on in-domain data, we also resort to a * Co-first author broader spectrum of domain adaptation settings (, including training models from scratch on a mixture of shuffled OOD and indomain data and ensemble various models at the decoding stage.", "labels": [], "entities": []}, {"text": "Final systems are submitted to the biomedical shared task of WMT 2019 on six translation directions for English-Chinese, EnglishFrench and English-German language pairs.", "labels": [], "entities": [{"text": "WMT 2019", "start_pos": 61, "end_pos": 69, "type": "DATASET", "confidence": 0.7608014047145844}]}, {"text": "This paper is organized as below: Section 2 illustrates the system architecture followed by details of parallel corpora for training in Section 3.", "labels": [], "entities": []}, {"text": "Section 4 presents our experimental settings.", "labels": [], "entities": []}, {"text": "Results are presented and discussed in Section 5.", "labels": [], "entities": []}, {"text": "In Section 6, we conclude the paper and unveil future work.", "labels": [], "entities": []}], "datasetContent": [{"text": "The data depicted in are mixed, preprocessed and split into training and development sets.", "labels": [], "entities": []}, {"text": "The development data is created by random  selection 1% from the mixed data sets.", "labels": [], "entities": []}, {"text": "We also pre-processed the WMT 2018 test data and treated it as test data to benchmark the models trained under various settings.", "labels": [], "entities": [{"text": "WMT 2018 test data", "start_pos": 26, "end_pos": 44, "type": "DATASET", "confidence": 0.9181971698999405}]}, {"text": "We experimented with more than twenty models in total trained on different combinations of various data and under different settings.", "labels": [], "entities": []}, {"text": "sacrebleu.py (Post, 2018) and multi-bleu.perl from Moses 10 are used to evaluate translations on the development and test data.", "labels": [], "entities": [{"text": "sacrebleu.py (Post, 2018)", "start_pos": 0, "end_pos": 25, "type": "DATASET", "confidence": 0.769141693909963}]}, {"text": "shows BLEU scores on WMT 2018 test set under different settings.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 6, "end_pos": 10, "type": "METRIC", "confidence": 0.9989053010940552}, {"text": "WMT 2018 test set", "start_pos": 21, "end_pos": 38, "type": "DATASET", "confidence": 0.9729620665311813}]}, {"text": "We found that models from fine-tuning on in-domain data outperform models trained on the mixed data set when reasonable volumes of in-domain data are available (e.g., on EN-FR and EN-DE).", "labels": [], "entities": []}, {"text": "By contrast, the mixed method performs the best on EN-ZH where we do not have genuine in-domain data for fine-tuning.", "labels": [], "entities": [{"text": "EN-ZH", "start_pos": 51, "end_pos": 56, "type": "DATASET", "confidence": 0.887796938419342}]}, {"text": "Another interesting finding is that the ensemble decoding consistently takes the middle place when we simply combine the best two models under the three settings.", "labels": [], "entities": []}, {"text": "We presume this is caused by domain issues as at least one of the two models used was not well trained on in-domain data.", "labels": [], "entities": []}, {"text": "The results in terms of official BLEU scores of our submissions for WMT 2019 are presented in.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 33, "end_pos": 37, "type": "METRIC", "confidence": 0.9959105253219604}, {"text": "WMT 2019", "start_pos": 68, "end_pos": 76, "type": "TASK", "confidence": 0.579946368932724}]}, {"text": "Our final systems achieve the best BLEU scores on English-French and English-German language pairs according to the official evaluation results.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 35, "end_pos": 39, "type": "METRIC", "confidence": 0.998715877532959}]}, {"text": "In the English-Chinese translation task, our systems are in the second place.", "labels": [], "entities": [{"text": "English-Chinese translation task", "start_pos": 7, "end_pos": 39, "type": "TASK", "confidence": 0.6843775709470113}]}, {"text": "We can also find from the tables that training with the mixed data, fine-tuning on indomain data have contributed to a number of winning models on different language pairs.", "labels": [], "entities": []}, {"text": "While the mixed method works better than the Finetuned method on English-Chinese and English-: BLEU scores of the trained models measured against a subset of the test data for WMT 18 biomedical task (bold fonts show the best scores).", "labels": [], "entities": [{"text": "BLEU", "start_pos": 95, "end_pos": 99, "type": "METRIC", "confidence": 0.9998100399971008}, {"text": "WMT 18 biomedical task", "start_pos": 176, "end_pos": 198, "type": "TASK", "confidence": 0.5726364850997925}]}, {"text": "German, the fine-tuned method outperforms on French-English (EN2FR Run1) due to a reasonable volume of high-quality in-domain data included.", "labels": [], "entities": [{"text": "EN2FR Run1", "start_pos": 61, "end_pos": 71, "type": "DATASET", "confidence": 0.7399738729000092}]}, {"text": "It is noted that the submission (EN2FR Run3) based on the ensemble decoding method has resulted in much lower performance.", "labels": [], "entities": [{"text": "EN2FR Run3", "start_pos": 33, "end_pos": 43, "type": "DATASET", "confidence": 0.8316408693790436}]}, {"text": "According to our experiments and experiences, we reached the same conclusion as that from the WMT biomedical task organizers (: the enhanced performance is attributed to more in-domain training and more sophisticated models developed (i.e., Transformers).", "labels": [], "entities": [{"text": "WMT biomedical task organizers", "start_pos": 94, "end_pos": 124, "type": "DATASET", "confidence": 0.6780178397893906}]}, {"text": "The development of translation models and transfer learning (or domain adaptation) methods have significantly contributed to the progress of the task.", "labels": [], "entities": [{"text": "translation", "start_pos": 19, "end_pos": 30, "type": "TASK", "confidence": 0.9739255905151367}, {"text": "transfer learning (or domain adaptation)", "start_pos": 42, "end_pos": 82, "type": "TASK", "confidence": 0.6923981394086566}]}], "tableCaptions": [{"text": " Table 1: Hyperparameters of our systems.", "labels": [], "entities": []}, {"text": " Table 3: BLEU scores of the trained models measured against a subset of the test data for WMT 18 biomedical  task (bold fonts show the best scores).", "labels": [], "entities": [{"text": "BLEU", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9995284080505371}, {"text": "WMT 18 biomedical  task", "start_pos": 91, "end_pos": 114, "type": "TASK", "confidence": 0.547951340675354}]}, {"text": " Table 4: Official BLEU scores of ARC submission for WMT 19 biomedical task test sets with all sentences (bold  fonts show the best official scores).", "labels": [], "entities": [{"text": "BLEU", "start_pos": 19, "end_pos": 23, "type": "METRIC", "confidence": 0.9534726142883301}, {"text": "WMT 19 biomedical task test sets", "start_pos": 53, "end_pos": 85, "type": "DATASET", "confidence": 0.7872697611649832}]}, {"text": " Table 5: Official BLEU scores of our submissions for WMT 19 biomedical task with OK-aligned test sets (bold  fonts show the best official scores).", "labels": [], "entities": [{"text": "BLEU", "start_pos": 19, "end_pos": 23, "type": "METRIC", "confidence": 0.9333688020706177}, {"text": "WMT 19 biomedical task", "start_pos": 54, "end_pos": 76, "type": "DATASET", "confidence": 0.8344354331493378}]}]}