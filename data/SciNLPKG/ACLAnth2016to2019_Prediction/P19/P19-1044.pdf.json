{"title": [{"text": "Time-Out: Temporal Referencing for Robust Modeling of Lexical Semantic Change", "labels": [], "entities": [{"text": "Temporal Referencing", "start_pos": 10, "end_pos": 30, "type": "TASK", "confidence": 0.8160082995891571}, {"text": "Robust Modeling of Lexical Semantic Change", "start_pos": 35, "end_pos": 77, "type": "TASK", "confidence": 0.7486149420340856}]}], "abstractContent": [{"text": "State-of-the-art models of lexical semantic change detection suffer from noise stemming from vector space alignment.", "labels": [], "entities": [{"text": "lexical semantic change detection", "start_pos": 27, "end_pos": 60, "type": "TASK", "confidence": 0.6824533492326736}, {"text": "vector space alignment", "start_pos": 93, "end_pos": 115, "type": "TASK", "confidence": 0.6250147223472595}]}, {"text": "We have empirically tested the Temporal Referencing method for lexical semantic change and show that, by avoiding alignment, it is less affected by this noise.", "labels": [], "entities": [{"text": "Temporal Referencing", "start_pos": 31, "end_pos": 51, "type": "TASK", "confidence": 0.9067571461200714}, {"text": "lexical semantic change", "start_pos": 63, "end_pos": 86, "type": "TASK", "confidence": 0.6551211476325989}]}, {"text": "We show that, trained on a diachronic corpus, the skip-gram with negative sampling architecture with temporal referencing outper-forms alignment models on a synthetic task as well as a manual testset.", "labels": [], "entities": []}, {"text": "We introduce a prin-cipled way to simulate lexical semantic change and systematically control for possible biases.", "labels": [], "entities": []}], "introductionContent": [{"text": "These past years have seen the rise of computational methods to detect, track, qualify, and quantify how a word's sense -or senses -change overtime.", "labels": [], "entities": []}, {"text": "These tasks are critical challenges that are relevant to a range of NLP fields, including the study of historical semantic change.", "labels": [], "entities": []}, {"text": "The successful outcome of semantic change detection is relevant to any diachronic textual analysis, including machine translation or normalization of historical texts, the detection of cultural semantic shifts ( or applications in digital humanities).", "labels": [], "entities": [{"text": "semantic change detection", "start_pos": 26, "end_pos": 51, "type": "TASK", "confidence": 0.8286737600962321}, {"text": "machine translation or normalization of historical texts", "start_pos": 110, "end_pos": 166, "type": "TASK", "confidence": 0.78655287197658}, {"text": "detection of cultural semantic shifts", "start_pos": 172, "end_pos": 209, "type": "TASK", "confidence": 0.8502181053161622}]}, {"text": "However, currently, the best-performing models () require a complex alignment procedure and have been shown to suffer from biases (.", "labels": [], "entities": []}, {"text": "This exposes them to various sources of noise influencing their predictions; a fact which has long gone unnoticed because of the lack of standard evaluation procedures in the field.", "labels": [], "entities": []}, {"text": "We examine the modeling approach of Temporal Referencing (TR) which avoids post hoc align-ment and is applicable to any vector space learning technique.", "labels": [], "entities": [{"text": "Temporal Referencing (TR)", "start_pos": 36, "end_pos": 61, "type": "TASK", "confidence": 0.8042395949363709}]}, {"text": "We show that it (i) is less affected by noise and (ii) clearly outperforms state-of-the-art alignment models on a synthetic change detection task.", "labels": [], "entities": [{"text": "synthetic change detection task", "start_pos": 114, "end_pos": 145, "type": "TASK", "confidence": 0.7420365735888481}]}, {"text": "The task is based on data from a synchronic corpus into which we artificially inject lexical semantic change (LSC) in a controlled and semantically principled way.", "labels": [], "entities": []}, {"text": "We further evaluate the models on a manual testset of diachronic LSC and examine their properties.", "labels": [], "entities": []}, {"text": "In this paper, we focus on skip-gram with negative sampling (SGNS) models) and PPMI ( and make use of TR to share context information across time periods, while learning individual embeddings fora target word in each time period.", "labels": [], "entities": []}, {"text": "We evaluate models in two ways: on the one hand, through the comparison of model performance between semantically changing and stable words.", "labels": [], "entities": []}, {"text": "This is achieved through the synthetic introduction (and removal) of polysemy, mimicking;;.", "labels": [], "entities": []}, {"text": "We differ from previous work by creating those changes in a more structured way, and for many time points.", "labels": [], "entities": []}, {"text": "The second type of evaluation put forward is a study built on a smaller number of words manually classified as changed or stable.", "labels": [], "entities": []}, {"text": "Our contributions are the following: \u2022 Noise Reduction: We avoid post hoc alignment by TR and show that it outperforms other models and is robust to noise.", "labels": [], "entities": [{"text": "Noise Reduction", "start_pos": 39, "end_pos": 54, "type": "TASK", "confidence": 0.7085104584693909}]}, {"text": "\u2022 LSC Simulation: We propose a systematic and principled method of injecting semantic change in a controlled fashion.", "labels": [], "entities": [{"text": "LSC Simulation", "start_pos": 2, "end_pos": 16, "type": "TASK", "confidence": 0.6351553946733475}]}, {"text": "\u2022 Evaluation: We evaluate (i) by testing for noise reduction in a control condition, (ii) on large and controlled artificial data and (iii) on a manually annotated LSC testset.", "labels": [], "entities": []}, {"text": "\u2022 Framework: The above comprises a frame-work to test any model of semantic change for their levels of noise and sensitivity in detecting simulated semantic change.", "labels": [], "entities": [{"text": "sensitivity", "start_pos": 113, "end_pos": 124, "type": "METRIC", "confidence": 0.9718419313430786}]}], "datasetContent": [{"text": "To test our methods we performed three main experiments, comparing the performances of TR to the existing state-of-the-art diachronic model alignment.", "labels": [], "entities": []}, {"text": "In the first experiment, we compare the models' performance under control conditions that address complementary (potential) weaknesses.", "labels": [], "entities": []}, {"text": "The second experiment tests different synthetic change types and assesses whether better models improve detection of lexical semantic change, in a controlled setting.", "labels": [], "entities": [{"text": "detection of lexical semantic change", "start_pos": 104, "end_pos": 140, "type": "TASK", "confidence": 0.6500906765460968}]}, {"text": "Finally, we test our methods on a manually created testset on a genuine corpus, and manually inspect the results.", "labels": [], "entities": []}, {"text": "In this experiment, we trained each model on two corpora, one genuine diachronic corpus with natural semantic change, and one shuffled where the diachronic change is distributed equally across all time periods (see Sec. 5.1).", "labels": [], "entities": []}, {"text": "We study the average change of cosine distance as a proxy for semantic change.", "labels": [], "entities": []}, {"text": "Following we consider the average cosine distance (acd) trained on the genuine corpus to correspond to true semantic change + noise.", "labels": [], "entities": [{"text": "cosine distance (acd)", "start_pos": 34, "end_pos": 55, "type": "METRIC", "confidence": 0.8091549456119538}]}, {"text": "In contrast, the average cosine distance on the shuffled corpus corresponds to pure noise.", "labels": [], "entities": []}, {"text": "Therefore, the difference between the two equals to true signal, or in other words, true lexical semantic change.", "labels": [], "entities": []}, {"text": "Importantly, we are interested in investigating, and hopefully mitigating, possible sources of the noise that might be found in some of the models.", "labels": [], "entities": []}, {"text": "Specifically, we hypothesize that the alignment procedure adds considerable noise to the acd, and plan to test how TR can alleviate some of that noise.", "labels": [], "entities": [{"text": "TR", "start_pos": 115, "end_pos": 117, "type": "TASK", "confidence": 0.7663293480873108}]}, {"text": "Moreover, TR is assumed to contribute not only by circumventing the alignment, but also by producing more stable context vectors due to the increased amount of data on which they are trained.", "labels": [], "entities": [{"text": "TR", "start_pos": 10, "end_pos": 12, "type": "TASK", "confidence": 0.8431776165962219}]}, {"text": "7 Therefore, we first tease-apart these factors using the following comparisons between the different models.", "labels": [], "entities": []}, {"text": "1. For all models, we consider the difference in average cosine distance between genuine and shuffled conditions (acd genuine \u2212 acd shuf f led ) as being inversely proportional to the amount of noise that the original model unknowingly captures.", "labels": [], "entities": []}, {"text": "Hence, the larger the difference, the less noisier (and better) the model is.", "labels": [], "entities": []}, {"text": "We consider this to bean approximation of the true semantic change.", "labels": [], "entities": []}, {"text": "2. Focusing on the differences between the two PPMI models allows us to test the independent contribution of TR in providing more accurate context vectors because the intersection of the PPMI vectors are inherently aligned.", "labels": [], "entities": []}, {"text": "3. Focusing on the SGNS models conflates the potential benefits from more accurate context vectors with the disadvantage of Procrustes alignment (which is necessary for SGNS AL but not for SGNS TR ).", "labels": [], "entities": [{"text": "SGNS AL", "start_pos": 169, "end_pos": 176, "type": "TASK", "confidence": 0.8735460042953491}, {"text": "SGNS TR", "start_pos": 189, "end_pos": 196, "type": "TASK", "confidence": 0.7823269665241241}]}, {"text": "4. The difference between the last two would allow us to evaluate the independent contribution of these two sources on the (presumably) less noisy SGNS TR model scores.", "labels": [], "entities": [{"text": "SGNS TR model scores", "start_pos": 147, "end_pos": 167, "type": "DATASET", "confidence": 0.7288547903299332}]}, {"text": "Results (experiment 1) We start analyzing the true semantic change for each of the models (PPMI AL to PPMI TR and SGNS AL to SGNS TR ) over the corpus.", "labels": [], "entities": []}, {"text": "In, we can see that temporal referencing introduces less noise throughout the 5 decadal comparisons.", "labels": [], "entities": []}, {"text": "For both PPMI and SGNS, the true semantic change increases for the TR models compared to the aligned.", "labels": [], "entities": []}, {"text": "Importantly, shows that for the PPMI models, Temporal Referencing has a much smaller improvement over the aligned model (.005) compared to the SGNS models (.026) (all reported differences are statistically significant, t-test p < .01).", "labels": [], "entities": [{"text": "Temporal Referencing", "start_pos": 45, "end_pos": 65, "type": "TASK", "confidence": 0.9237048923969269}]}, {"text": "Temporal Referencing influences the PPMI models only by creating more stable context vectors.", "labels": [], "entities": [{"text": "Temporal Referencing", "start_pos": 0, "end_pos": 20, "type": "TASK", "confidence": 0.8955240547657013}]}, {"text": "In contrast, for the SGNS models the introduction of Temporal Referencing circumvents the use of alignment in addition to creating more stable context vectors.", "labels": [], "entities": [{"text": "Temporal Referencing", "start_pos": 53, "end_pos": 73, "type": "TASK", "confidence": 0.7894476652145386}]}, {"text": "Therefore, the results support our hypothesis that TR has two complementing factors that improve prior models; firstly, it avoids the need for alignment altogether (and the noise that usually comes with it), and secondly, it produces more stable context vectors due to the increased volume of data when using the full corpus.: Difference in average cosine distance between genuine and shuffled conditions (true semantic change) for each method, collapsed over the 5 time bins  In contrast, if a model captures stochastic fluctuations in the words' vectors instead of true semantic change, then such a shift in the distribution will be less prominent.", "labels": [], "entities": [{"text": "TR", "start_pos": 51, "end_pos": 53, "type": "TASK", "confidence": 0.935830295085907}]}, {"text": "We plot the distribution of the words' cosine distances with increasing time intervals (relative to 1920) for both SGNS models in.", "labels": [], "entities": []}, {"text": "Both models show a gradual transition from left (smaller change scores) to right (larger change scores).", "labels": [], "entities": []}, {"text": "This corroborates our basic assumption that words change more as the time interval for comparison increases.", "labels": [], "entities": []}, {"text": "Crucially, Temporal Referencing shows a more constant cumulative progression of cosine distances overtime in contrast to alignment where decadal cosine distance distributions seem to be more volatile.", "labels": [], "entities": [{"text": "Temporal Referencing", "start_pos": 11, "end_pos": 31, "type": "TASK", "confidence": 0.9470939636230469}]}, {"text": "We follow in interpreting these results as attesting for the relatively high noise factor in the SGNS AL over the SGNS TR . Overall, the different analyses converge to the same conclusion: Temporal Referencing is a better model for capturing a word's semantic information from diachronic text because it introduces less noise.", "labels": [], "entities": [{"text": "SGNS TR", "start_pos": 114, "end_pos": 121, "type": "DATASET", "confidence": 0.7831908166408539}, {"text": "Temporal Referencing", "start_pos": 189, "end_pos": 209, "type": "TASK", "confidence": 0.8920360207557678}, {"text": "capturing a word's semantic information from diachronic text", "start_pos": 232, "end_pos": 292, "type": "TASK", "confidence": 0.7656757003731198}]}, {"text": "Next, we will investigate if a less noisy model is also better at detecting semantic change.", "labels": [], "entities": []}, {"text": "This experiment aims to see how well our methods can find different synthetic change types.", "labels": [], "entities": []}, {"text": "In order to minimize natural semantic change in the dataset, we made use of the synchronic dataset COCA which we randomly shuffled, and simulated a diachronic corpus for which we have 7 time-bins.", "labels": [], "entities": []}, {"text": "We randomly assigned a seventh of COCA to each of our artificial time periods, labeled t 1 tot 7 . Sentences in which either word of the synthetic semantic change pairs (see Sec.", "labels": [], "entities": []}, {"text": "4) or their corresponding control words appeared were held out.", "labels": [], "entities": []}, {"text": "These sentences were subsequently added back to COCA according to the procedure outlined in Section 4, which enabled us to control for the fixed ratio incremental steps between the recipient and donor words (i.e., changes to the injection ratio were made only fort 2 -t 3 , t 3 -t 4 , t 4 -t 5 , and t 5 -t 6 , while t 1 -t 2 and t 6 -t 7 had no such changes).", "labels": [], "entities": [{"text": "COCA", "start_pos": 48, "end_pos": 52, "type": "DATASET", "confidence": 0.8491095304489136}]}, {"text": "All four models were trained on the 7 synthetic time-bins exactly as in Experiment 1.", "labels": [], "entities": []}, {"text": "The target words were the 356 words with synthetic lexical semantic change and their 356 control words that were matched with the same frequency increase but otherwise are considered semantically stable.", "labels": [], "entities": []}, {"text": "For each target word, the cosine distances between two consecutive synthetic time-bins were computed, resulting in 6 change scores per word.", "labels": [], "entities": []}, {"text": "We analyze the peak distribution of the individual words.", "labels": [], "entities": []}, {"text": "We defined the peak position of each word as its vector argmax (the position in which it shows the maximum cosine distance).", "labels": [], "entities": [{"text": "argmax", "start_pos": 56, "end_pos": 62, "type": "METRIC", "confidence": 0.9426510334014893}]}, {"text": "In order to evaluate the models' ability to truly detect semantic change, we formulate a na\u00a8\u0131vena\u00a8\u0131ve binary classification task based on the words' peak positions.", "labels": [], "entities": []}, {"text": "For each word, if the peak is in position 2-5, we classify it as changed, and otherwise as stable and measure accuracy and F1-score.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 110, "end_pos": 118, "type": "METRIC", "confidence": 0.9997071623802185}, {"text": "F1-score", "start_pos": 123, "end_pos": 131, "type": "METRIC", "confidence": 0.9989612102508545}]}, {"text": "Results shows the acd of the four models for the change and stable words separately, according to the different sense injection ratios.", "labels": [], "entities": [{"text": "acd", "start_pos": 18, "end_pos": 21, "type": "METRIC", "confidence": 0.9946999549865723}]}, {"text": "The two plots differ markedly.", "labels": [], "entities": []}, {"text": "For the semantic change words (upper plot), all four models show a noticeable peak when the new sense was first injected (step 2), followed by a steady decrease in acd until step 6.", "labels": [], "entities": [{"text": "acd", "start_pos": 164, "end_pos": 167, "type": "METRIC", "confidence": 0.9865736961364746}]}, {"text": "In contrast, the stable words only show the steady decrease starting from step 1, without any noticeable peaks.", "labels": [], "entities": []}, {"text": "This decrease probably stems from the target words' increased frequency that can lead to more accurate word embeddings.", "labels": [], "entities": [{"text": "frequency", "start_pos": 62, "end_pos": 71, "type": "METRIC", "confidence": 0.9526832103729248}]}, {"text": "Because peaks in acd are interpreted as points were semantic change was the most profound, the results support the models' ability to detect synthetic semantic changes.", "labels": [], "entities": []}, {"text": "Although the majority of peaks for the semantic change words fall in step 2, as expected by the acd analysis above, words had their peaks in other step positions as well (see Appendix B).", "labels": [], "entities": []}, {"text": "8 reports accuracy and F-scores for the four models in the binary classification task.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9997507929801941}, {"text": "F-scores", "start_pos": 23, "end_pos": 31, "type": "METRIC", "confidence": 0.9981586337089539}, {"text": "binary classification task", "start_pos": 59, "end_pos": 85, "type": "TASK", "confidence": 0.7400935689608256}]}, {"text": "As clearly seen, all four models perform better than chance even under these very rudimentary conditions (finding the argmax of a vector of length 6).", "labels": [], "entities": []}, {"text": "Crucially, SGNS TR outperforms the rest of the models, and especially SGNS AL that shows the worst performance.", "labels": [], "entities": [{"text": "SGNS TR", "start_pos": 11, "end_pos": 18, "type": "TASK", "confidence": 0.5481751263141632}]}, {"text": "These results corroborate our hypothesis from Experiment 1 that noise is negatively influencing task performance.", "labels": [], "entities": []}, {"text": "By alleviating the noise factor that exists in SGNS AL (due to alignment), SGNS TR is able to show substantial gains in this binary classification task.: Accuracy (averaged, and split into individual classes) and F1-scores for semantic change detection.", "labels": [], "entities": [{"text": "SGNS TR", "start_pos": 75, "end_pos": 82, "type": "TASK", "confidence": 0.7315750420093536}, {"text": "Accuracy", "start_pos": 154, "end_pos": 162, "type": "METRIC", "confidence": 0.9974931478500366}, {"text": "F1-scores", "start_pos": 213, "end_pos": 222, "type": "METRIC", "confidence": 0.9991651773452759}, {"text": "semantic change detection", "start_pos": 227, "end_pos": 252, "type": "TASK", "confidence": 0.8738865454991659}]}, {"text": "For stable words (control words), peaks at 1 and 6 steps are correct.", "labels": [], "entities": []}, {"text": "For change words, peaks at steps 2-5 are correct.", "labels": [], "entities": []}, {"text": "We see that all methods find unrelated change better than related change, and that SGNS TR outperforms the other methods.", "labels": [], "entities": [{"text": "SGNS TR", "start_pos": 83, "end_pos": 90, "type": "TASK", "confidence": 0.7495789527893066}]}, {"text": "Discussion shows that SGNS TR gains its performance advantage over SGNS AL mainly from a better classification of the stable words (0.37 vs. 0.57).", "labels": [], "entities": [{"text": "SGNS TR", "start_pos": 22, "end_pos": 29, "type": "TASK", "confidence": 0.7132367193698883}]}, {"text": "In order to understand this better, we inspect their mean cosine distance curves only for stable words in.", "labels": [], "entities": []}, {"text": "SGNS TR 's curve clearly declines, while SGNS AL 's curve declines much less and is more volatile.", "labels": [], "entities": [{"text": "SGNS TR", "start_pos": 0, "end_pos": 7, "type": "DATASET", "confidence": 0.769520103931427}]}, {"text": "We attribute the decline of both curves to the diminishing noise that comes from the continuous increase in frequency of the control words (.", "labels": [], "entities": []}, {"text": "It seems that this diminishing frequency noise is counteracted by the alignment noise, yielding a flatter curve for SGNS AL . The latter increases SGNS AL 's chance to have peaks in one of the center injection steps producing false positives in our classification task.", "labels": [], "entities": [{"text": "SGNS AL", "start_pos": 116, "end_pos": 123, "type": "TASK", "confidence": 0.7333568632602692}]}, {"text": "However, this property may also have a positive influence on SGNS AL in related LSC detection tasks ().", "labels": [], "entities": [{"text": "SGNS AL", "start_pos": 61, "end_pos": 68, "type": "TASK", "confidence": 0.8963741660118103}, {"text": "LSC detection tasks", "start_pos": 80, "end_pos": 99, "type": "TASK", "confidence": 0.8961200515429179}]}, {"text": "So far, the results have been based on either a large random sample to show general tendencies for the language in the corpus as a whole, or synthetically injected semantic change.", "labels": [], "entities": []}, {"text": "In this part, we test the behavior of our methods on a small, manually created testset for semantic change.", "labels": [], "entities": []}, {"text": "We use the Word Sense Change Testset (Tahmasebi and) that consists of words and the different associated change events, for the time span In this experiment, we ignore the sense changes and consider only words as changed or stable, and restrict our change words to those that have change events between 1920 and 1970.", "labels": [], "entities": []}, {"text": "In total we have 13 changed and 19 stable words (excluding words with a total frequency \u2264 100).", "labels": [], "entities": []}, {"text": "In we see acd of each model on the changed and stable words.", "labels": [], "entities": [{"text": "acd", "start_pos": 10, "end_pos": 13, "type": "METRIC", "confidence": 0.9680066108703613}]}, {"text": "We find that for all methods, SGNS AL , SGNS TR , PPMI AL and PPMI TR , the acd for the changed words is statistically significantly higher (p values \u2264 0.01) than for the stable words which nicely corresponds to intuition; words with true semantic change should have vectors that differ more than words without change.", "labels": [], "entities": [{"text": "acd", "start_pos": 76, "end_pos": 79, "type": "METRIC", "confidence": 0.9920287728309631}]}, {"text": "The mean difference between the stable and the changed words, that gives us some notion of how well the two different classes are separated, is highest for SGNS TR . Because of the limited size of the testset, the results are indicative rather than conclusive and we continue with a manual analysis of the nearest neighboring words.", "labels": [], "entities": [{"text": "SGNS TR", "start_pos": 156, "end_pos": 163, "type": "TASK", "confidence": 0.6129298806190491}]}, {"text": "We carryout a qualitative evaluation for the closest neighbors for computer (see), a word we expect to have changed after the invention of the digital computer in the 1940s, for the SGNS aligned version and SGNS with Temporal Referencing.", "labels": [], "entities": []}, {"text": "SGNS AL has only a few words in common in , and while the digital computer is showing here, there are few overlapping words.", "labels": [], "entities": [{"text": "SGNS AL", "start_pos": 0, "end_pos": 7, "type": "DATASET", "confidence": 0.7609209418296814}]}, {"text": "The time periods  have no common words.", "labels": [], "entities": []}, {"text": "In comparison, the SGNS TR show clear patterns.", "labels": [], "entities": [{"text": "SGNS TR", "start_pos": 19, "end_pos": 26, "type": "TASK", "confidence": 0.5555393695831299}]}, {"text": "We see a clear break between 1940 and 1950, without any overlapping word, and a pattern between 1950-1970; the closest words are the other computer This is exactly the pattern that we expected to see using the sense injection; stable senses can be distinguished from changing senses by their relationship to the other temporally referenced vectors.", "labels": [], "entities": []}, {"text": "Next, we study a word for which we expect no sense change, namely ship (see Appendix E).", "labels": [], "entities": [{"text": "Appendix", "start_pos": 76, "end_pos": 84, "type": "METRIC", "confidence": 0.91531902551651}]}, {"text": "The SGNS AL show a fairly low acd, but still there are large differences in the top neighboring words.", "labels": [], "entities": [{"text": "acd", "start_pos": 30, "end_pos": 33, "type": "METRIC", "confidence": 0.9939862489700317}]}, {"text": "The SGNS TR show what we expect; the most similar words are the other ship  , and overtime we see that the 'self-similarity' decreases.", "labels": [], "entities": [{"text": "SGNS TR", "start_pos": 4, "end_pos": 11, "type": "DATASET", "confidence": 0.7248304784297943}]}, {"text": "For almost all decades, the most similar words are ship from the decade before and after.", "labels": [], "entities": []}, {"text": "The lower words also help describe the meaning of ship, as a boat and later also as a spaceship.", "labels": [], "entities": []}, {"text": "The pattern of stability is much more clear for SGNS TR than SGNS AL and holds for most other stable words as well.", "labels": [], "entities": [{"text": "SGNS TR", "start_pos": 48, "end_pos": 55, "type": "TASK", "confidence": 0.5156895667314529}]}, {"text": "For the word tape, that has a change in dominant sense (or an addition of another strong sense) with the addition of the music tape to adhesive tape, we seethe same patterns as for ship, but the bottom words contain ribbon, paper, adhesive For both the real change in and the synthetic change in, we find that SGNS TR is best at differentiating between the stable and the change classes for both datasets (50% for WSC and 26% for synthetic change).", "labels": [], "entities": [{"text": "SGNS TR", "start_pos": 310, "end_pos": 317, "type": "TASK", "confidence": 0.6868083477020264}]}], "tableCaptions": [{"text": " Table 1: Difference in average cosine distance between  genuine and shuffled conditions (true semantic change)  for each method, collapsed over the 5 time bins", "labels": [], "entities": []}, {"text": " Table 2: Accuracy (averaged, and split into individual  classes) and F1-scores for semantic change detection.  For stable words (control words), peaks at 1 and 6 steps  are correct. For change words, peaks at steps 2-5 are  correct. We see that all methods find unrelated change  better than related change, and that SGNS TR outper- forms the other methods.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9977675676345825}, {"text": "F1-scores", "start_pos": 70, "end_pos": 79, "type": "METRIC", "confidence": 0.9987382292747498}, {"text": "semantic change detection", "start_pos": 84, "end_pos": 109, "type": "TASK", "confidence": 0.8021841446558634}, {"text": "SGNS TR", "start_pos": 318, "end_pos": 325, "type": "TASK", "confidence": 0.6767834424972534}]}, {"text": " Table 3: acd for WSC testset. Var \u2208 (0.0 \u2212 0.01). CH  = changed word, ST = stable word, DIFF = difference  between ACD for change and stable in percent.", "labels": [], "entities": [{"text": "WSC", "start_pos": 18, "end_pos": 21, "type": "TASK", "confidence": 0.8075056672096252}, {"text": "Var", "start_pos": 31, "end_pos": 34, "type": "METRIC", "confidence": 0.9836687445640564}, {"text": "DIFF", "start_pos": 89, "end_pos": 93, "type": "METRIC", "confidence": 0.9973093271255493}]}, {"text": " Table 4: acd for synthetic change. Var \u2208 (0.0 \u2212 0.01).", "labels": [], "entities": [{"text": "Var", "start_pos": 36, "end_pos": 39, "type": "METRIC", "confidence": 0.9779821038246155}]}]}