{"title": [{"text": "(Almost) Unsupervised Grammatical Error Correction using a Synthetic Comparable Corpus", "labels": [], "entities": [{"text": "Grammatical Error Correction", "start_pos": 22, "end_pos": 50, "type": "TASK", "confidence": 0.7240949670473734}]}], "abstractContent": [{"text": "We introduce unsupervised techniques based on phrase-based statistical machine translation for grammatical error correction (GEC) trained on a pseudo learner corpus created by Google Translation.", "labels": [], "entities": [{"text": "phrase-based statistical machine translation", "start_pos": 46, "end_pos": 90, "type": "TASK", "confidence": 0.5882099643349648}, {"text": "grammatical error correction (GEC)", "start_pos": 95, "end_pos": 129, "type": "TASK", "confidence": 0.7680376470088959}]}, {"text": "We verified our GEC system through experiments on a low resource track of the shared task at Building Educational Applications 2019 (BEA2019).", "labels": [], "entities": [{"text": "GEC", "start_pos": 16, "end_pos": 19, "type": "DATASET", "confidence": 0.7853872179985046}, {"text": "Building Educational Applications 2019 (BEA2019)", "start_pos": 93, "end_pos": 141, "type": "TASK", "confidence": 0.6033031472137996}]}, {"text": "As a result , we achieved an F 0.5 score of 28.31 points with the test data.", "labels": [], "entities": [{"text": "F 0.5 score", "start_pos": 29, "end_pos": 40, "type": "METRIC", "confidence": 0.9912761449813843}]}], "introductionContent": [{"text": "Research on grammatical error correction (GEC) has gained considerable attention recently.", "labels": [], "entities": [{"text": "grammatical error correction (GEC)", "start_pos": 12, "end_pos": 46, "type": "TASK", "confidence": 0.7951470911502838}]}, {"text": "Many studies treat GEC as a task that involves translation from a grammatically erroneous sentence (sourceside) into a correct sentence (target-side) and thus, leverage methods based on machine translation (MT) for GEC.", "labels": [], "entities": [{"text": "GEC", "start_pos": 19, "end_pos": 22, "type": "TASK", "confidence": 0.9674853682518005}, {"text": "machine translation (MT)", "start_pos": 186, "end_pos": 210, "type": "TASK", "confidence": 0.8262076854705811}, {"text": "GEC", "start_pos": 215, "end_pos": 218, "type": "TASK", "confidence": 0.9062255024909973}]}, {"text": "For instance, some GEC systems use large parallel corpora and synthetic data.", "labels": [], "entities": []}, {"text": "We introduce an unsupervised method based on MT for GEC that does not use parallel learner data.", "labels": [], "entities": [{"text": "MT", "start_pos": 45, "end_pos": 47, "type": "TASK", "confidence": 0.7330362200737}, {"text": "GEC", "start_pos": 52, "end_pos": 55, "type": "DATASET", "confidence": 0.7899301648139954}]}, {"text": "In particular, we use methods proposed by,, and.", "labels": [], "entities": []}, {"text": "These methods are based on phrase-based statistical machine translation (SMT) and phrase table refinements.", "labels": [], "entities": [{"text": "phrase-based statistical machine translation (SMT)", "start_pos": 27, "end_pos": 77, "type": "TASK", "confidence": 0.7286190049988883}, {"text": "phrase table refinements", "start_pos": 82, "end_pos": 106, "type": "TASK", "confidence": 0.6884804964065552}]}, {"text": "Forward refinement used by simply augments a learner corpus with automatic corrections.", "labels": [], "entities": []}, {"text": "We also use forward refinement for improvement of phrase table.", "labels": [], "entities": []}, {"text": "Unsupervised MT techniques do not require a parallel but a comparable corpus as training data.", "labels": [], "entities": [{"text": "MT", "start_pos": 13, "end_pos": 15, "type": "TASK", "confidence": 0.9929994344711304}]}, {"text": "Therefore, we use comparable translated texts using Google Translation as the source-side data.", "labels": [], "entities": []}, {"text": "Specifically, we use News Crawl written in English as target-side data and News Crawl written in another language translated into English as source-side data.", "labels": [], "entities": []}, {"text": "We verified our GEC system through experiments fora low resource track of the shared task at Building Educational Applications 2019 (BEA2019).", "labels": [], "entities": [{"text": "GEC", "start_pos": 16, "end_pos": 19, "type": "DATASET", "confidence": 0.8063404560089111}, {"text": "Building Educational Applications 2019 (BEA2019)", "start_pos": 93, "end_pos": 141, "type": "TASK", "confidence": 0.6157559837613787}]}, {"text": "The experimental results show that our system achieved an F 0.5 score of 28.31 points.", "labels": [], "entities": [{"text": "F 0.5 score", "start_pos": 58, "end_pos": 69, "type": "METRIC", "confidence": 0.9903325041135153}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Data statics: train and dev data size.", "labels": [], "entities": []}, {"text": " Table 2: GEC results with test data.", "labels": [], "entities": [{"text": "GEC", "start_pos": 10, "end_pos": 13, "type": "DATASET", "confidence": 0.4782605767250061}]}, {"text": " Table 3: GEC results with dev data. The bold scores  represent the best score without the spell checker.", "labels": [], "entities": [{"text": "GEC", "start_pos": 10, "end_pos": 13, "type": "TASK", "confidence": 0.49448978900909424}]}, {"text": " Table 4: Error types for which our best system cor- rected errors well or mostly did not correct on the dev  data. Top2 denotes the top two errors, and Bottom2  denotes the lowest two errors in terms of the F 0.5  10 .", "labels": [], "entities": [{"text": "F 0.5  10", "start_pos": 208, "end_pos": 217, "type": "METRIC", "confidence": 0.9038122296333313}]}]}