{"title": [{"text": "Graph Neural Networks with Generated Parameters for Relation Extraction", "labels": [], "entities": [{"text": "Relation Extraction", "start_pos": 52, "end_pos": 71, "type": "TASK", "confidence": 0.8579376339912415}]}], "abstractContent": [{"text": "In this paper, we propose a novel graph neu-ral network with generated parameters (GP-GNNs).", "labels": [], "entities": []}, {"text": "The parameters in the propagation module, i.e. the transition matrices used in message passing procedure, are produced by a generator taking natural language sentences as inputs.", "labels": [], "entities": [{"text": "message passing", "start_pos": 79, "end_pos": 94, "type": "TASK", "confidence": 0.7896758317947388}]}, {"text": "We verify GP-GNNs in relation extraction from text, both on bag-and instance-settings.", "labels": [], "entities": [{"text": "relation extraction from text", "start_pos": 21, "end_pos": 50, "type": "TASK", "confidence": 0.8142030537128448}]}, {"text": "Experimental results on a human-annotated dataset and two distantly supervised datasets show that multi-hop reasoning mechanism yields significant improvements.", "labels": [], "entities": []}, {"text": "We also perform a qualitative analysis to demonstrate that our model could discover more accurate relations by multi-hop relational reasoning.", "labels": [], "entities": []}, {"text": "Codes and data are released at https: //github.com/thunlp/gp-gnn.", "labels": [], "entities": []}], "introductionContent": [{"text": "In recent years, graph neural networks have been applied to various fields of machine learning, including node classification (, relation classification (, molecular property prediction (, few-shot learning (, and achieved promising results on these tasks.", "labels": [], "entities": [{"text": "node classification", "start_pos": 106, "end_pos": 125, "type": "TASK", "confidence": 0.7491036355495453}, {"text": "relation classification", "start_pos": 129, "end_pos": 152, "type": "TASK", "confidence": 0.8305979669094086}, {"text": "molecular property prediction", "start_pos": 156, "end_pos": 185, "type": "TASK", "confidence": 0.6406221687793732}]}, {"text": "These works have demonstrated GNNs' strong power to process relational reasoning on graphs.", "labels": [], "entities": []}, {"text": "Relational reasoning aims to abstractly reason about entities/objects and their relations, which is an important part of human intelligence.", "labels": [], "entities": [{"text": "Relational reasoning", "start_pos": 0, "end_pos": 20, "type": "TASK", "confidence": 0.9207333028316498}]}, {"text": "Besides graphs, relational reasoning is also of great importance in many natural language processing The original idea comes from several discussions between Hao Zhu and Jie Fu while Hao Zhu visiting NUS; Hao Zhu designed research, prepared datasets, and conducted experiments; Jie Fu, Yankai Lin, and Zhiyuan Liu also participated in discussion while planning experiments; Zhiyuan Liu, Tat-seng Chua and Maosong Sun proofread the paper.", "labels": [], "entities": [{"text": "relational reasoning", "start_pos": 16, "end_pos": 36, "type": "TASK", "confidence": 0.860374242067337}, {"text": "NUS", "start_pos": 200, "end_pos": 203, "type": "DATASET", "confidence": 0.9470310807228088}]}, {"text": "Zhiyuan Liu serves as the corresponding author.", "labels": [], "entities": []}, {"text": "tasks such as question answering, relation extraction, summarization, etc.", "labels": [], "entities": [{"text": "question answering", "start_pos": 14, "end_pos": 32, "type": "TASK", "confidence": 0.9036678075790405}, {"text": "relation extraction", "start_pos": 34, "end_pos": 53, "type": "TASK", "confidence": 0.8674439191818237}, {"text": "summarization", "start_pos": 55, "end_pos": 68, "type": "TASK", "confidence": 0.9739954471588135}]}, {"text": "Consider the example shown in, existing relation extraction models could easily extract the facts that Luc Besson directed a film L\u00e9on: The Professional and that the film is in English, but fail to infer the relationship between Luc Besson and English without multi-hop relational reasoning.", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 40, "end_pos": 59, "type": "TASK", "confidence": 0.7718174755573273}]}, {"text": "By considering the reasoning patterns, one can discover that Luc Besson could speak English following a reasoning logic that Luc Besson directed L\u00e9on: The Professional and this film is in English indicates Luc Besson could speak English.", "labels": [], "entities": []}, {"text": "However, most existing GNNs can only process multi-hop relational reasoning on pre-defined graphs and cannot be directly applied in natural language relational reasoning.", "labels": [], "entities": [{"text": "natural language relational reasoning", "start_pos": 132, "end_pos": 169, "type": "TASK", "confidence": 0.6252736672759056}]}, {"text": "Enabling multi-hop relational reasoning in natural languages remains an open problem.", "labels": [], "entities": [{"text": "multi-hop relational reasoning", "start_pos": 9, "end_pos": 39, "type": "TASK", "confidence": 0.5550854106744131}]}, {"text": "To address this issue, in this paper, we propose graph neural networks with generated parameters (GP-GNNs), to adapt graph neural networks to solve the natural language relational reasoning task.", "labels": [], "entities": [{"text": "natural language relational reasoning task", "start_pos": 152, "end_pos": 194, "type": "TASK", "confidence": 0.640025281906128}]}, {"text": "GP-GNNs first constructs a fullyconnected graph with the entities in the sequence of text.", "labels": [], "entities": []}, {"text": "After that, it employs three modules to process relational reasoning: (1) an encoding module which enables edges to encode rich information from natural languages, (2) a propagation module which propagates relational information among various nodes, and (3) a classification module which makes predictions with node representations.", "labels": [], "entities": []}, {"text": "As compared to traditional GNNs, GP-GNNs could learn edge parameters from natural languages, extending it from performing inference on only non-relational graphs or graphs with a limited number of edge types to unstructured inputs such as texts.", "labels": [], "entities": []}, {"text": "In the experiments, we apply GP-GNNs to a classic natural language relational reasoning task:: An example of relation extraction from plain text.", "labels": [], "entities": [{"text": "relation extraction from plain text", "start_pos": 109, "end_pos": 144, "type": "TASK", "confidence": 0.8496507167816162}]}, {"text": "Given a sentence with several entities marked, we model the interaction between these entities by generating the weights of graph neural networks.", "labels": [], "entities": []}, {"text": "Modeling the relationship between \"L\u00e9on\" and \"English\" as well as \"Luc Besson\" helps discover the relationship between \"Luc Besson\" and \"English\".", "labels": [], "entities": []}, {"text": "We carryout experiments on Wikipedia corpus aligned with Wikidata knowledge base and build a human annotated test set as well as two distantly labeled test sets with different levels of denseness.Experiment results show that our model outperforms other models on relation extraction task by considering multi-hop relational reasoning.", "labels": [], "entities": [{"text": "Wikipedia corpus", "start_pos": 27, "end_pos": 43, "type": "DATASET", "confidence": 0.8970551192760468}, {"text": "Wikidata knowledge base", "start_pos": 57, "end_pos": 80, "type": "DATASET", "confidence": 0.885014812151591}, {"text": "relation extraction", "start_pos": 263, "end_pos": 282, "type": "TASK", "confidence": 0.8560443818569183}]}, {"text": "We also perform a qualitative analysis which shows that our model could discover more relations by reasoning more robustly as compared to baseline models.", "labels": [], "entities": []}, {"text": "Our main contributions are in two-fold: (1) We extend a novel graph neural network model with generated parameters, to enable relational message-passing with rich text information, which could be applied to process relational reasoning on unstructured inputs such as natural language.", "labels": [], "entities": []}, {"text": "(2) We verify our GP-GNNs on the task of relation extraction from text, which demonstrates its ability on multi-hop relational reasoning as compared to those models which extract relationships separately.", "labels": [], "entities": [{"text": "relation extraction from text", "start_pos": 41, "end_pos": 70, "type": "TASK", "confidence": 0.8351371437311172}]}, {"text": "Moreover, we also present three datasets, which could help future researchers compare their models in different settings.", "labels": [], "entities": []}], "datasetContent": [{"text": "Our experiments mainly aim at: (1) showing that our best models could improve the performance of relation extraction under a variety of settings; (2) illustrating that how the number of layers affect the performance of our model; and (3) performing a qualitative investigation to highlight the difference between our models and baseline models.", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 97, "end_pos": 116, "type": "TASK", "confidence": 0.7852765321731567}]}, {"text": "In both part (1) and part (2), we do three subparts of experiments: (i) we will first show that our models could improve instance-level relation extraction on a human annotated test set, and (ii) then we will show that our models could also help enhance the performance of bag-level relation extraction on a distantly labeled test set 4 , and (iii) we also split a subset of distantly labeled test set, where the number of entities and edges is large.", "labels": [], "entities": [{"text": "instance-level relation extraction", "start_pos": 121, "end_pos": 155, "type": "TASK", "confidence": 0.6654031276702881}, {"text": "bag-level relation extraction", "start_pos": 273, "end_pos": 302, "type": "TASK", "confidence": 0.7202099760373434}]}, {"text": "Distantly labeled set have proposed a dataset with Wikipedia corpora.", "labels": [], "entities": []}, {"text": "There is a small difference between our task and theirs: our task is to extract the relationship between every pair of entities in the sentence, whereas their task is to extract the relationship between the given entity pair and the context entity pairs.", "labels": [], "entities": []}, {"text": "Therefore, we need to modify their dataset: (1) We added reversed edges if they are missing from a given triple, e.g. if triple (Earth, part of, Solar System) exists in the sentence, we add a reversed label, (Solar System, has a member, Earth), to it; (2) For all of the entity pairs with no relations, we added \"NA\" labels to them.", "labels": [], "entities": []}, {"text": "We use the same training set for all of the experiments.", "labels": [], "entities": []}, {"text": "Human annotated test set Based on the test set provided by, 5 annotators 6 are asked to label the dataset.", "labels": [], "entities": []}, {"text": "They are asked to decide whether or not the distant supervision is right for every pair of entities.", "labels": [], "entities": []}, {"text": "Only the instances accepted by all 5 annotators are incorporated into the human annotated test set.", "labels": [], "entities": [{"text": "human annotated test set", "start_pos": 74, "end_pos": 98, "type": "DATASET", "confidence": 0.7258567065000534}]}, {"text": "There are 350 sentences and 1,230 triples in this test set.", "labels": [], "entities": []}, {"text": "Dense distantly labeled test set We further split a dense test set from the distantly labeled test set.", "labels": [], "entities": []}, {"text": "Our criteria are: (1) the number of entities should be strictly larger than 2; and (2) there must beat least one circle (with at least three entities) in the ground-truth label of the sentence . This test set could be used to test our methods' performance on sentences with the complex interaction between entities.", "labels": [], "entities": []}, {"text": "There are 1,350 sentences and more than 17,915 triples and 7,906 relational facts in this test set.", "labels": [], "entities": []}, {"text": "So far, we have only talked about the way to implement sentence-level relation extraction.", "labels": [], "entities": [{"text": "sentence-level relation extraction", "start_pos": 55, "end_pos": 89, "type": "TASK", "confidence": 0.6389812131722769}]}, {"text": "To evaluate our models and baseline models in bag-level, we utilize a bag of sentences with a given entity pair to score the relations between them.", "labels": [], "entities": []}, {"text": "formalize the bag-level relation extraction as multi-instance learning.", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 24, "end_pos": 43, "type": "TASK", "confidence": 0.6957489103078842}]}, {"text": "Here, we fol-8 https://github.com/UKPLab/ emnlp2017-relation-extraction We set all dns to be the same as we do not see improvements using different dns  low their idea and define the score function of an entity pair and its corresponding relation r as a max-one setting:", "labels": [], "entities": [{"text": "UKPLab", "start_pos": 34, "end_pos": 40, "type": "DATASET", "confidence": 0.9724294543266296}]}], "tableCaptions": [{"text": " Table 2: Results on human annotated dataset", "labels": [], "entities": []}, {"text": " Table 3: Results on distantly labeled test set", "labels": [], "entities": []}]}