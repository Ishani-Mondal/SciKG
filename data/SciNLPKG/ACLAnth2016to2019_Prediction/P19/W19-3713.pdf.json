{"title": [{"text": "Multilingual Named Entity Recognition Using Pretrained Embeddings, Attention Mechanism and NCRF", "labels": [], "entities": [{"text": "Multilingual Named Entity Recognition", "start_pos": 0, "end_pos": 37, "type": "TASK", "confidence": 0.7045440524816513}, {"text": "NCRF", "start_pos": 91, "end_pos": 95, "type": "DATASET", "confidence": 0.9287520051002502}]}], "abstractContent": [{"text": "In this paper we tackle multilingual named entity recognition task.", "labels": [], "entities": [{"text": "multilingual named entity recognition", "start_pos": 24, "end_pos": 61, "type": "TASK", "confidence": 0.5756263136863708}]}, {"text": "We use the BERT Language Model as embeddings with bidirectional recurrent network, attention, and NCRF on the top.", "labels": [], "entities": [{"text": "BERT", "start_pos": 11, "end_pos": 15, "type": "METRIC", "confidence": 0.7996452450752258}]}, {"text": "We apply multilingual BERT only as embedder without any fine-tuning.", "labels": [], "entities": [{"text": "BERT", "start_pos": 22, "end_pos": 26, "type": "METRIC", "confidence": 0.9833858609199524}]}, {"text": "We test out model on the dataset of the BSNLP shared task, which consists of texts in Bulgar-ian, Czech, Polish and Russian languages.", "labels": [], "entities": [{"text": "BSNLP shared task", "start_pos": 40, "end_pos": 57, "type": "DATASET", "confidence": 0.7855256597201029}]}], "introductionContent": [{"text": "Sequence labeling is one of the most fundamental NLP models, which is used for many tasks such as named entity recognition (NER), chunking, word segmentation and part-of-speech (POS) tagging.", "labels": [], "entities": [{"text": "Sequence labeling", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.9112400114536285}, {"text": "named entity recognition (NER)", "start_pos": 98, "end_pos": 128, "type": "TASK", "confidence": 0.7979967445135117}, {"text": "word segmentation", "start_pos": 140, "end_pos": 157, "type": "TASK", "confidence": 0.7633284330368042}, {"text": "part-of-speech (POS) tagging", "start_pos": 162, "end_pos": 190, "type": "TASK", "confidence": 0.6578383088111878}]}, {"text": "It has been traditionally investigated using statistical approaches (), where conditional random fields (CRF) () has been proven to bean effective framework, by taking discrete features as the representation of input sequence.", "labels": [], "entities": []}, {"text": "With the advances of deep learning, neural sequence labeling models have achieved state-of theart results for many tasks (.", "labels": [], "entities": [{"text": "neural sequence labeling", "start_pos": 36, "end_pos": 60, "type": "TASK", "confidence": 0.6610465248425802}]}, {"text": "For the purpose of this paper, we consider neural network solution for multilingual named entity recognition for Bulgarian, Czech, Polish and Russian languages for the BSNLP 2019 Shared Task (.", "labels": [], "entities": [{"text": "multilingual named entity recognition", "start_pos": 71, "end_pos": 108, "type": "TASK", "confidence": 0.6081483587622643}, {"text": "BSNLP 2019 Shared Task", "start_pos": 168, "end_pos": 190, "type": "DATASET", "confidence": 0.8240070939064026}]}, {"text": "Our solution is based on BERT language model, use bidirectional LSTM (Hochreiter and Schmidhuber, 1996), Multi-Head attention (, NCRFpp (Yang and Zhang, 2018) (being neural network version of CRF++framework for sequence labelling) and Pooling Classifier (for language classification) on the top as additional information.", "labels": [], "entities": [{"text": "BERT", "start_pos": 25, "end_pos": 29, "type": "METRIC", "confidence": 0.6818981766700745}, {"text": "language classification", "start_pos": 259, "end_pos": 282, "type": "TASK", "confidence": 0.7152683436870575}]}], "datasetContent": [{"text": "As baseline for BSNLP Shared Task we use a simple CRF tagger and obtain exact word level f1-score 0.372 on the development dataset.", "labels": [], "entities": [{"text": "exact word level f1-score 0.372", "start_pos": 72, "end_pos": 103, "type": "METRIC", "confidence": 0.8010651588439941}]}, {"text": "Finally we use joint model for named entity recognition task and language classification task because the model without part of the classification gave a result by several percent less than proposed final model.", "labels": [], "entities": [{"text": "named entity recognition task", "start_pos": 31, "end_pos": 60, "type": "TASK", "confidence": 0.7000781521201134}, {"text": "language classification task", "start_pos": 65, "end_pos": 93, "type": "TASK", "confidence": 0.8413283824920654}]}, {"text": "This means that the joint model pays attention to a specific language morphology and some connections between words within one language.", "labels": [], "entities": []}, {"text": "For proposed neural network architecture the evaluation of the training stage was produced on development dataset.", "labels": [], "entities": []}, {"text": "shows span-level metrics precision, recall, and f1-measure.", "labels": [], "entities": [{"text": "precision", "start_pos": 25, "end_pos": 34, "type": "METRIC", "confidence": 0.9621872305870056}, {"text": "recall", "start_pos": 36, "end_pos": 42, "type": "METRIC", "confidence": 0.9997389912605286}]}, {"text": "For development set, we obtained the following scores: language classification quality (f1-score): 0.998 and Multilingual Named Entity Recognition quality (f1-score): 0.70 for exact word level matching and 0.578 for exact full entities matching.", "labels": [], "entities": [{"text": "exact word level matching", "start_pos": 176, "end_pos": 201, "type": "TASK", "confidence": 0.5426254197955132}]}, {"text": "Also we train model without language classification, which resulted in f1-score equal to 0.66 . This confirms the impact of language classification.", "labels": [], "entities": [{"text": "language classification", "start_pos": 28, "end_pos": 51, "type": "TASK", "confidence": 0.6967950463294983}, {"text": "f1-score", "start_pos": 71, "end_pos": 79, "type": "METRIC", "confidence": 0.9412961006164551}, {"text": "language classification", "start_pos": 124, "end_pos": 147, "type": "TASK", "confidence": 0.7322666496038437}]}, {"text": "Our model significantly outperforms the CRF baseline.", "labels": [], "entities": []}, {"text": "The evaluation of test dataset presented in Table 2 (relaxed partial matching) and", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Evaluation metrics on development dataset", "labels": [], "entities": []}, {"text": " Table 2: Evaluation metrics on test dataset", "labels": [], "entities": []}]}