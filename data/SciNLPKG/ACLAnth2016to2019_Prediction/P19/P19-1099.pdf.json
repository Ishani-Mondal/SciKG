{"title": [{"text": "Global Optimization under Length Constraint for Neural Text Summarization", "labels": [], "entities": [{"text": "Length", "start_pos": 26, "end_pos": 32, "type": "METRIC", "confidence": 0.9651311039924622}, {"text": "Neural Text Summarization", "start_pos": 48, "end_pos": 73, "type": "TASK", "confidence": 0.7808308800061544}]}], "abstractContent": [{"text": "We propose a global optimization method under length constraint (GOLC) for neural text summarization models.", "labels": [], "entities": [{"text": "neural text summarization", "start_pos": 75, "end_pos": 100, "type": "TASK", "confidence": 0.6290007730325063}]}, {"text": "GOLC increases the probabilities of generating summaries that have high evaluation scores, ROUGE in this paper, within a desired length.", "labels": [], "entities": [{"text": "GOLC", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.49915391206741333}, {"text": "ROUGE", "start_pos": 91, "end_pos": 96, "type": "METRIC", "confidence": 0.9983745813369751}]}, {"text": "We compared GOLC with two optimization methods , a maximum log-likelihood and a minimum risk training, on CNN/Daily Mail and a Japanese single document summarization data set of The Mainichi Shimbun Newspapers.", "labels": [], "entities": [{"text": "GOLC", "start_pos": 12, "end_pos": 16, "type": "TASK", "confidence": 0.750794529914856}, {"text": "CNN/Daily Mail", "start_pos": 106, "end_pos": 120, "type": "DATASET", "confidence": 0.9428011476993561}, {"text": "Japanese single document summarization data set of The Mainichi Shimbun Newspapers", "start_pos": 127, "end_pos": 209, "type": "DATASET", "confidence": 0.7308703200383619}]}, {"text": "The experimental results show that a state-of-the-art neural summarization model optimized with GOLC generates fewer overlength summaries while maintaining the fastest processing speed; only 6.70% overlength summaries on CNN/Daily and 7.8% on long summary of Mainichi, compared to the approximately 20% to 50% on CNN/Daily Mail and 10% to 30% on Mainichi with the other optimization methods.", "labels": [], "entities": [{"text": "CNN/Daily", "start_pos": 221, "end_pos": 230, "type": "DATASET", "confidence": 0.9629002809524536}, {"text": "Mainichi", "start_pos": 259, "end_pos": 267, "type": "DATASET", "confidence": 0.8533321022987366}, {"text": "CNN/Daily Mail", "start_pos": 313, "end_pos": 327, "type": "DATASET", "confidence": 0.8235303610563278}, {"text": "Mainichi", "start_pos": 346, "end_pos": 354, "type": "DATASET", "confidence": 0.9808381199836731}]}, {"text": "We also demonstrate the importance of the generation of in-length summaries for post-editing with the dataset Mainich that is created with strict length constraints.", "labels": [], "entities": [{"text": "Mainich", "start_pos": 110, "end_pos": 117, "type": "DATASET", "confidence": 0.8927130699157715}]}, {"text": "The experimental results show approximately 30% to 40% improved post-editing time by use of in-length summaries.", "labels": [], "entities": []}], "introductionContent": [{"text": "Automatic text summarization aims at generating a short and coherent summary of a given text.", "labels": [], "entities": [{"text": "text summarization", "start_pos": 10, "end_pos": 28, "type": "TASK", "confidence": 0.6315624564886093}]}, {"text": "In text summarization, while the generated summaries should contain the important content of the input text, their lengths should also be controlled, e.g., the summary should be as long as the width of target devices such as smart-phones and digital signage.", "labels": [], "entities": [{"text": "text summarization", "start_pos": 3, "end_pos": 21, "type": "TASK", "confidence": 0.6775330007076263}]}, {"text": "Therefore, editors have to summarize a source text under a length constraint by reordering and paraphrasing.", "labels": [], "entities": []}, {"text": "For summarization, both extractive and abstractive methods have been widely studied.", "labels": [], "entities": [{"text": "summarization", "start_pos": 4, "end_pos": 17, "type": "TASK", "confidence": 0.990473210811615}]}, {"text": "Extractive methods are based on selection of sentences from source texts without using reordering or paraphrasing.", "labels": [], "entities": []}, {"text": "In contrast, abstractive methods generate summaries as new sentences.", "labels": [], "entities": []}, {"text": "Therefore, abstractive methods can rely on the reordering and paraphrasing required for summary and title generation.", "labels": [], "entities": [{"text": "summary and title generation", "start_pos": 88, "end_pos": 116, "type": "TASK", "confidence": 0.6152850687503815}]}, {"text": "However, most abstractive summarization methods are notable to control the summary length.", "labels": [], "entities": [{"text": "abstractive summarization", "start_pos": 14, "end_pos": 39, "type": "TASK", "confidence": 0.5494703203439713}]}, {"text": "To this problem, and proposed abstractive summarization models with a capability of summary length control.", "labels": [], "entities": []}, {"text": "One is an LSTM based summarization model, and the other is a CNN based one.", "labels": [], "entities": [{"text": "summarization", "start_pos": 21, "end_pos": 34, "type": "TASK", "confidence": 0.8994101881980896}]}, {"text": "They proposed to enforce the desired length in the decoding of training and generation.", "labels": [], "entities": [{"text": "length", "start_pos": 37, "end_pos": 43, "type": "METRIC", "confidence": 0.9919366836547852}]}, {"text": "Their models, however, leave much room for improvement, at least with regard to two aspects.", "labels": [], "entities": []}, {"text": "One aspect is that the summarization performance is still worse than other state-of-the-art models.", "labels": [], "entities": [{"text": "summarization", "start_pos": 23, "end_pos": 36, "type": "TASK", "confidence": 0.9790835976600647}]}, {"text": "The other is that their models sometimes fail to control the output length.", "labels": [], "entities": []}, {"text": "In this paper, we address these two issues by incorporating global training based on a minimum risk training (MRT) under the length constraint.", "labels": [], "entities": []}, {"text": "MRT is used to optimize a model globally for an arbitrary evaluation metric.", "labels": [], "entities": [{"text": "MRT", "start_pos": 0, "end_pos": 3, "type": "TASK", "confidence": 0.777815580368042}]}, {"text": "It was also applied for optimizing the neural summarization model for headline generation with respect to ROUGE (, which is based on an overlap of words with reference summaries.", "labels": [], "entities": [{"text": "headline generation", "start_pos": 70, "end_pos": 89, "type": "TASK", "confidence": 0.8439310193061829}, {"text": "ROUGE", "start_pos": 106, "end_pos": 111, "type": "METRIC", "confidence": 0.9628617167472839}]}, {"text": "However, how to use MRT under a length constraint was an open problem; thus we propose a global optimization under length constraint (GOLC) for neural summarization models.", "labels": [], "entities": [{"text": "MRT", "start_pos": 20, "end_pos": 23, "type": "TASK", "confidence": 0.9742406010627747}]}, {"text": "We show that neural summarization models trained with GOLC can control the output length better than the existing methods.", "labels": [], "entities": [{"text": "neural summarization", "start_pos": 13, "end_pos": 33, "type": "TASK", "confidence": 0.5667577981948853}]}, {"text": "This is because our training procedure makes use of overlength summaries.", "labels": [], "entities": []}, {"text": "While the probabilities of generating sum-maries that satisfy the length constraint increase, overlength summaries are penalized and hence the probabilities of generating such summaries decrease.", "labels": [], "entities": []}, {"text": "We conducted experiments on CNN/Daily Mail and a Japanese single document summarization dataset of the Mainichi Shimbun Newspapers.", "labels": [], "entities": [{"text": "CNN/Daily Mail", "start_pos": 28, "end_pos": 42, "type": "DATASET", "confidence": 0.9469237178564072}, {"text": "Japanese single document summarization dataset of the Mainichi Shimbun Newspapers", "start_pos": 49, "end_pos": 130, "type": "DATASET", "confidence": 0.7015944123268127}]}, {"text": "Models trained with GOLC showed better ROUGE scores than those of maximum loglikelihood based methods while generating summaries satisfying the length constraint.", "labels": [], "entities": [{"text": "ROUGE", "start_pos": 39, "end_pos": 44, "type": "METRIC", "confidence": 0.9976099729537964}]}, {"text": "In contrast to the approximately 20% and 50% of overlength summaries generated by the other state-ofthe-art models, our method only generated 6.70% of overlength summaries on CNN/Daily and 7.8% on long summary of Mainichi while improving ROUGE scores.", "labels": [], "entities": [{"text": "CNN/Daily", "start_pos": 175, "end_pos": 184, "type": "DATASET", "confidence": 0.9746702710787455}, {"text": "long summary of", "start_pos": 197, "end_pos": 212, "type": "DATASET", "confidence": 0.6422954201698303}, {"text": "Mainichi", "start_pos": 213, "end_pos": 221, "type": "DATASET", "confidence": 0.5516079068183899}, {"text": "ROUGE", "start_pos": 238, "end_pos": 243, "type": "METRIC", "confidence": 0.9950760006904602}]}, {"text": "We also demonstrate the importance of the generation of in-length summaries for post-editing.", "labels": [], "entities": []}, {"text": "The experimental results of post-editing generated summaries showed that generated in-length summaries contributed to an approximately 30% to 40% improved post-editing time.", "labels": [], "entities": []}], "datasetContent": [{"text": "We compare our optimization method GOLC with two different optimization methods, MLE and MRT by applying the optimization methods to LSTM and CNN-based summarization models on an English and a Japanese dataset.", "labels": [], "entities": [{"text": "MRT", "start_pos": 89, "end_pos": 92, "type": "TASK", "confidence": 0.4966934025287628}]}, {"text": "We implemented summarization models with Chainer () and all summarization models were trained on NVIDIA Tesla P100.", "labels": [], "entities": [{"text": "summarization", "start_pos": 15, "end_pos": 28, "type": "TASK", "confidence": 0.9599031209945679}, {"text": "NVIDIA Tesla P100", "start_pos": 97, "end_pos": 114, "type": "DATASET", "confidence": 0.8456041216850281}]}, {"text": "Note that the test data were randomly sampled from the 2017 data.", "labels": [], "entities": []}, {"text": "The sizes of the training data and test data are 163,220 and 2,000.", "labels": [], "entities": []}, {"text": "Half of the dataset is document-long summary pairs, and the rest of the dataset is document-short summary pairs.", "labels": [], "entities": []}, {"text": "The vocabulary was created by collecting words that occur more than two times in the training data.", "labels": [], "entities": []}, {"text": "Words that are not included in the vocabulary were replaced with the special token, <UNK>.", "labels": [], "entities": []}, {"text": "ROUGE We used ROUGE F-score on CNN/Daily.", "labels": [], "entities": [{"text": "ROUGE", "start_pos": 0, "end_pos": 5, "type": "METRIC", "confidence": 0.9391042590141296}, {"text": "ROUGE", "start_pos": 14, "end_pos": 19, "type": "METRIC", "confidence": 0.9688788056373596}, {"text": "F-score", "start_pos": 20, "end_pos": 27, "type": "METRIC", "confidence": 0.785187840461731}, {"text": "CNN/Daily", "start_pos": 31, "end_pos": 40, "type": "DATASET", "confidence": 0.9615258773167928}]}, {"text": "When calculating ROUGE F-score, full-length summaries are used.", "labels": [], "entities": [{"text": "ROUGE", "start_pos": 17, "end_pos": 22, "type": "METRIC", "confidence": 0.9893276691436768}, {"text": "F-score", "start_pos": 23, "end_pos": 30, "type": "METRIC", "confidence": 0.8273452520370483}]}, {"text": "We also used ROUGE recall on Mainichi with a length constraint, which is the length of a reference summary.", "labels": [], "entities": [{"text": "ROUGE", "start_pos": 13, "end_pos": 18, "type": "METRIC", "confidence": 0.9909273386001587}, {"text": "recall", "start_pos": 19, "end_pos": 25, "type": "METRIC", "confidence": 0.6067348718643188}, {"text": "Mainichi", "start_pos": 29, "end_pos": 37, "type": "DATASET", "confidence": 0.9831072092056274}, {"text": "length constraint", "start_pos": 45, "end_pos": 62, "type": "METRIC", "confidence": 0.9832067787647247}, {"text": "length", "start_pos": 77, "end_pos": 83, "type": "METRIC", "confidence": 0.967979907989502}]}, {"text": "Overlength summaries are truncated to the length constraint for evaluating ROUGE recall scores.", "labels": [], "entities": [{"text": "length constraint", "start_pos": 42, "end_pos": 59, "type": "METRIC", "confidence": 0.9705349802970886}, {"text": "ROUGE", "start_pos": 75, "end_pos": 80, "type": "METRIC", "confidence": 0.9311309456825256}, {"text": "recall", "start_pos": 81, "end_pos": 87, "type": "METRIC", "confidence": 0.7006884217262268}]}, {"text": "We used pyrouge 3 , which is the same evaluation script used by, scores on CNN/Daily.", "labels": [], "entities": [{"text": "pyrouge 3", "start_pos": 8, "end_pos": 17, "type": "METRIC", "confidence": 0.9582374095916748}, {"text": "CNN/Daily", "start_pos": 75, "end_pos": 84, "type": "DATASET", "confidence": 0.9706881841023763}]}, {"text": "This is because the pyrouge does not support Japanese.", "labels": [], "entities": []}, {"text": "Therefore, we used sumeval 4 with the MeCab on the ROUGE evaluation of the Mainichi dataset.", "labels": [], "entities": [{"text": "sumeval", "start_pos": 19, "end_pos": 26, "type": "TASK", "confidence": 0.9377477169036865}, {"text": "MeCab", "start_pos": 38, "end_pos": 43, "type": "DATASET", "confidence": 0.9439980387687683}, {"text": "ROUGE", "start_pos": 51, "end_pos": 56, "type": "METRIC", "confidence": 0.9485231637954712}, {"text": "Mainichi dataset", "start_pos": 75, "end_pos": 91, "type": "DATASET", "confidence": 0.9940550327301025}]}, {"text": "Length controllability For evaluating the capability of summary length control, we use two metrics.", "labels": [], "entities": [{"text": "summary length control", "start_pos": 56, "end_pos": 78, "type": "TASK", "confidence": 0.7320447762807211}]}, {"text": "The first one is the variance of a summary length c * (y i ) against the desired length l i (: The other is %over that is calculated by dividing the number of overlength summaries with the number of test data.", "labels": [], "entities": []}, {"text": "Because of the difference of the length unit between LenEmb and LC, Var and %over of LenEmb and those of LC are not comparable.", "labels": [], "entities": [{"text": "LenEmb", "start_pos": 53, "end_pos": 59, "type": "DATASET", "confidence": 0.8622564077377319}, {"text": "Var", "start_pos": 68, "end_pos": 71, "type": "METRIC", "confidence": 0.999090313911438}, {"text": "LenEmb", "start_pos": 85, "end_pos": 91, "type": "DATASET", "confidence": 0.8337509036064148}]}, {"text": "Since GOLC optimizes length controllable models, we compare models optimized by GOLC with models trained with other optimization methods.", "labels": [], "entities": []}, {"text": "The length of a reference summary was used as a desired length for length controllable models.", "labels": [], "entities": []}, {"text": "LC originally has capability of summary length control.", "labels": [], "entities": [{"text": "LC", "start_pos": 0, "end_pos": 2, "type": "DATASET", "confidence": 0.8901511430740356}, {"text": "summary length control", "start_pos": 32, "end_pos": 54, "type": "TASK", "confidence": 0.9148884614308676}]}, {"text": "Therefore, we only compare the differences obtained with optimization methods.", "labels": [], "entities": []}, {"text": "time indicates a number for the average summary generation time (seconds).", "labels": [], "entities": []}, {"text": "Human Evaluation We also evaluate postediting time of automatically generated summaries for human post-editing.", "labels": [], "entities": []}, {"text": "shows ROUGE scores (F-scores of full length summaries), Var, and %over on CNN/Daily.", "labels": [], "entities": [{"text": "ROUGE scores", "start_pos": 6, "end_pos": 18, "type": "METRIC", "confidence": 0.9771578013896942}, {"text": "F-scores", "start_pos": 20, "end_pos": 28, "type": "METRIC", "confidence": 0.8969699144363403}, {"text": "Var", "start_pos": 56, "end_pos": 59, "type": "METRIC", "confidence": 0.9980466365814209}, {"text": "CNN/Daily", "start_pos": 74, "end_pos": 83, "type": "DATASET", "confidence": 0.9787545204162598}]}, {"text": "PG w/ LE trained with GOLC shows better ROUGE scores and better %over than those of MLE.", "labels": [], "entities": [{"text": "GOLC", "start_pos": 22, "end_pos": 26, "type": "DATASET", "confidence": 0.4130883812904358}, {"text": "ROUGE", "start_pos": 40, "end_pos": 45, "type": "METRIC", "confidence": 0.999086856842041}, {"text": "MLE", "start_pos": 84, "end_pos": 87, "type": "METRIC", "confidence": 0.5926973223686218}]}, {"text": "Although ROUGE scores of PG w/ LE trained with MRT showed better ROUGE scores than GOLC, %overs are higher than those of GOLC.", "labels": [], "entities": [{"text": "ROUGE", "start_pos": 9, "end_pos": 14, "type": "METRIC", "confidence": 0.9787805080413818}, {"text": "MRT", "start_pos": 47, "end_pos": 50, "type": "TASK", "confidence": 0.9431536793708801}, {"text": "ROUGE", "start_pos": 65, "end_pos": 70, "type": "METRIC", "confidence": 0.9971383810043335}, {"text": "GOLC", "start_pos": 121, "end_pos": 125, "type": "DATASET", "confidence": 0.812911868095398}]}, {"text": "From these results, we see that GOLC improves ability to generate summaries under length constraints while maintaining ROUGE scores.", "labels": [], "entities": [{"text": "GOLC", "start_pos": 32, "end_pos": 36, "type": "METRIC", "confidence": 0.4290134310722351}, {"text": "ROUGE", "start_pos": 119, "end_pos": 124, "type": "METRIC", "confidence": 0.9938217401504517}]}, {"text": "ROUGE scores of LCs are lower than those of pointer-generator () and PG of our implementation.", "labels": [], "entities": [{"text": "ROUGE", "start_pos": 0, "end_pos": 5, "type": "METRIC", "confidence": 0.9894294142723083}]}, {"text": "This is because LC could not copy words of a source text into its target text.", "labels": [], "entities": []}, {"text": "The difference between ROUGE scores and V ar w of LC and reported scores in is due to differences of hyperparameters between ours and the original paper.", "labels": [], "entities": [{"text": "ROUGE", "start_pos": 23, "end_pos": 28, "type": "METRIC", "confidence": 0.9968023300170898}]}, {"text": "shows ROUGE scores (recall of truncated summaries), Var, and %over on Mainichi.", "labels": [], "entities": [{"text": "ROUGE scores", "start_pos": 6, "end_pos": 18, "type": "METRIC", "confidence": 0.9785971939563751}, {"text": "recall", "start_pos": 20, "end_pos": 26, "type": "METRIC", "confidence": 0.9914174675941467}, {"text": "Var", "start_pos": 52, "end_pos": 55, "type": "METRIC", "confidence": 0.99941086769104}, {"text": "Mainichi", "start_pos": 70, "end_pos": 78, "type": "DATASET", "confidence": 0.982441246509552}]}, {"text": "ROUGE scores of PG w/ LE are higher than those of PG.", "labels": [], "entities": [{"text": "ROUGE", "start_pos": 0, "end_pos": 5, "type": "METRIC", "confidence": 0.9896982312202454}, {"text": "PG w/ LE", "start_pos": 16, "end_pos": 24, "type": "METRIC", "confidence": 0.6355457156896591}, {"text": "PG", "start_pos": 50, "end_pos": 52, "type": "DATASET", "confidence": 0.7714744806289673}]}, {"text": "This is because PG w/ LE was able to trained with two times larger training data compared to PG.", "labels": [], "entities": []}, {"text": "Since PG cannot control summary length, two models were trained for short summaries and for long summaries separately.", "labels": [], "entities": []}, {"text": "Although ROUGE scores of neural summarization models are lower than those of LEAD-3sents on CNN/Daily, ROUGE scores of neural summarization models are higher than those of LEAD54chars and LEAD-17chars.", "labels": [], "entities": [{"text": "ROUGE", "start_pos": 9, "end_pos": 14, "type": "METRIC", "confidence": 0.9944629073143005}, {"text": "CNN/Daily", "start_pos": 92, "end_pos": 101, "type": "DATASET", "confidence": 0.879167894522349}, {"text": "ROUGE", "start_pos": 103, "end_pos": 108, "type": "METRIC", "confidence": 0.9820649027824402}]}, {"text": "These results come from the difference between the writing rules of summaries and ones of news articles in Mainichi.", "labels": [], "entities": [{"text": "Mainichi", "start_pos": 107, "end_pos": 115, "type": "DATASET", "confidence": 0.9755741357803345}]}, {"text": "For example, yomigana that indicates phonetic symbols of Japanese kanji characters sometimes follow person names and location names of kanji characters in a news article but not in a summary.", "labels": [], "entities": []}, {"text": "Furthermore, noun phrases are often rewritten to shorter paraphrases.", "labels": [], "entities": []}, {"text": "In order to demonstrate the importance of the generation of in-length summaries, we evaluate the post-editing time of generated summaries.", "labels": [], "entities": []}, {"text": "We recruited 7 Japanese native speakers for this evaluation as editors.", "labels": [], "entities": []}, {"text": "The editors are required to edit summaries generated by summarization models if they are overlength and have grammatical errors and factual errors.", "labels": [], "entities": [{"text": "summaries generated by summarization", "start_pos": 33, "end_pos": 69, "type": "TASK", "confidence": 0.7568883746862411}]}, {"text": "We randomly collected 10 overlength summaries and 10 in-length summaries from summaries generated by PG, PG w/LE (MLE), PG w/LE (MRT) and PG w/LE (GOLC) because our objective is to evaluate the importance of the generation of in-length summaries, not comparison of optimization methods.", "labels": [], "entities": []}, {"text": "shows the average time of post-editing.", "labels": [], "entities": []}, {"text": "The experimental results show that overlength summaries require longer editing time.", "labels": [], "entities": [{"text": "overlength summaries", "start_pos": 35, "end_pos": 55, "type": "TASK", "confidence": 0.5601657330989838}]}, {"text": "The reduction is approximately 39.4% for 17 chars and 29.1% for 54 chars.", "labels": [], "entities": [{"text": "reduction", "start_pos": 4, "end_pos": 13, "type": "METRIC", "confidence": 0.9661997556686401}]}, {"text": "This result indicates that the generation of in-length summaries is important when we use generated summaries for assisting workers.", "labels": [], "entities": []}, {"text": "Combined with the, we estimate use of GOLC-based summarizer contributed to approximately 10% reduction of postediting time compared with MRT-based one.", "labels": [], "entities": []}, {"text": "We used readability and informativeness for subjective evaluation of the articles of postediting: Readability (Read.) is evaluation of grammatical correctness of summaries.", "labels": [], "entities": []}, {"text": "Informativeness (Info.) is evaluation of coverage of important parts of the original source text under the length constraint.", "labels": [], "entities": []}, {"text": "We asked the editors to assign a five scale of 1 (bad) to 5 (good) to summaries of readability and informativeness.  editing.", "labels": [], "entities": []}, {"text": "Therefore, we seethe post-editing results were reasonable.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Hyperparamters used in experiments of  CNN/Daily (C) and Mainichi (M).", "labels": [], "entities": [{"text": "CNN/Daily (C)", "start_pos": 49, "end_pos": 62, "type": "DATASET", "confidence": 0.9606971144676208}, {"text": "Mainichi (M)", "start_pos": 67, "end_pos": 79, "type": "DATASET", "confidence": 0.8282091915607452}]}, {"text": " Table 2: Experimental results of three summarization models (Sum. Model), PG and LC on CNN/Daily, with three  optimization methods (Opt. Method), MLE, MRT and GOLC. The best score in each column is shown in bold.", "labels": [], "entities": [{"text": "CNN/Daily", "start_pos": 88, "end_pos": 97, "type": "DATASET", "confidence": 0.9724886616071066}, {"text": "MLE", "start_pos": 147, "end_pos": 150, "type": "METRIC", "confidence": 0.7166246771812439}, {"text": "MRT", "start_pos": 152, "end_pos": 155, "type": "METRIC", "confidence": 0.5468116402626038}, {"text": "GOLC", "start_pos": 160, "end_pos": 164, "type": "METRIC", "confidence": 0.6014707088470459}]}, {"text": " Table 3: Experimental results of (a) long summary and (b) short summary on Mainichi with three optimization  methods. The meaning of each item in the first column is the same as", "labels": [], "entities": [{"text": "Mainichi", "start_pos": 76, "end_pos": 84, "type": "DATASET", "confidence": 0.9471383094787598}]}, {"text": " Table 2. Summaries generated by mod- els were truncated to the length constraints for calculating ROUGE scores. Length constraints are 17 for short  summaries and 54 for long summaries for PG and the number of words in a reference summary in LC.", "labels": [], "entities": [{"text": "ROUGE", "start_pos": 99, "end_pos": 104, "type": "METRIC", "confidence": 0.8937890529632568}]}, {"text": " Table 5: Evaluation results of Readability (Read.) and  Informativeness (Info.).", "labels": [], "entities": []}]}