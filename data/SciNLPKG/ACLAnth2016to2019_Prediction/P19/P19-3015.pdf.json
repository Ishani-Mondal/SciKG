{"title": [{"text": "NeuralClassifier: An Open-source Neural Hierarchical Multi-label Text Classification Toolkit", "labels": [], "entities": [{"text": "Neural Hierarchical Multi-label Text Classification Toolkit", "start_pos": 33, "end_pos": 92, "type": "TASK", "confidence": 0.6272591998179754}]}], "abstractContent": [{"text": "In this paper, we introduce NeuralClassifier, a toolkit for neural hierarchical multi-label text classification.", "labels": [], "entities": [{"text": "neural hierarchical multi-label text classification", "start_pos": 60, "end_pos": 111, "type": "TASK", "confidence": 0.5811542093753814}]}, {"text": "NeuralClassifier is designed for quick implementation of neural models for hierarchical multi-label classification task, which is more challenging and common in real-world scenarios.", "labels": [], "entities": [{"text": "multi-label classification task", "start_pos": 88, "end_pos": 119, "type": "TASK", "confidence": 0.7644176383813223}]}, {"text": "A salient feature is that NeuralClassifier currently provides a variety of text encoders, such as FastText, TextCNN, TextRNN, RCNN, VDCNN, DPCNN, DRNN, AttentiveConvNet and Transformer encoder, etc.", "labels": [], "entities": []}, {"text": "It also supports other text classification scenarios, including binary-class and multi-class classification.", "labels": [], "entities": [{"text": "text classification", "start_pos": 23, "end_pos": 42, "type": "TASK", "confidence": 0.7061904072761536}, {"text": "multi-class classification", "start_pos": 81, "end_pos": 107, "type": "TASK", "confidence": 0.6982181668281555}]}, {"text": "Built on PyTorch 1 , the core operations are calculated in batch, making the toolkit efficient with the acceleration of GPU.", "labels": [], "entities": []}, {"text": "Experiments show that models builtin our toolkit achieve comparable performance with reported results in the literature.", "labels": [], "entities": []}], "introductionContent": [{"text": "Text classification is an important task in Natural Language Processing with many applications, such as web search, information retrieval, ranking and document classification.", "labels": [], "entities": [{"text": "Text classification", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.8209832012653351}, {"text": "information retrieval", "start_pos": 116, "end_pos": 137, "type": "TASK", "confidence": 0.8006638586521149}, {"text": "document classification", "start_pos": 151, "end_pos": 174, "type": "TASK", "confidence": 0.7742219269275665}]}, {"text": "As a result of the great success of deep neural networks, a series of classification models based on neural networks that achieve very good performance in practice have been proposed. and single-label text classification, it aims at considering the interrelationships among labels and classifying the text document into multiple labels, which are organized into a hierarchical structure of tree or DAG (Directed Acyclic Graph).", "labels": [], "entities": [{"text": "single-label text classification", "start_pos": 188, "end_pos": 220, "type": "TASK", "confidence": 0.6403573652108511}]}, {"text": "Regularizing the deep architecture with the dependency among labels adopted by the existing solutions () is more naturally for solving hierarchical multi-label text classification problem, especially for large scale datasets.", "labels": [], "entities": [{"text": "multi-label text classification", "start_pos": 148, "end_pos": 179, "type": "TASK", "confidence": 0.6117193400859833}]}, {"text": "It has a wide variety of real-world applications such as question answering (, online advertising (, and scientific literature organization (.", "labels": [], "entities": [{"text": "question answering", "start_pos": 57, "end_pos": 75, "type": "TASK", "confidence": 0.9136191010475159}, {"text": "scientific literature organization", "start_pos": 105, "end_pos": 139, "type": "TASK", "confidence": 0.6506436268488566}]}, {"text": "There exist several open-source statistical hierarchical or multi-label text classification toolkits, such as scikit-multilearn 2 , sklearn-hierarchicalclassification 3 , which provide users with various hierarchical or multi-label classification modules based on scikit-learn's interfaces and conventions.", "labels": [], "entities": [{"text": "statistical hierarchical or multi-label text classification", "start_pos": 32, "end_pos": 91, "type": "TASK", "confidence": 0.6434239248434702}]}, {"text": "On the other hand, there is limited choice for neural hierarchical multi-label text classification toolkits.", "labels": [], "entities": [{"text": "neural hierarchical multi-label text classification", "start_pos": 47, "end_pos": 98, "type": "TASK", "confidence": 0.5470913052558899}]}, {"text": "Although many researchers have released their codes along with their hierarchical or multi-  label text classification papers (, but the implementations are mostly focused on specific model structures and specific tasks, which greatly limit their extensions for other similar tasks.", "labels": [], "entities": [{"text": "multi-  label text classification", "start_pos": 85, "end_pos": 118, "type": "TASK", "confidence": 0.689872395992279}]}, {"text": "In this paper, we introduce an open-source toolkit, NeuralClassifier 4 , a neural hierarchical multi-label text classification toolkit based on PyTorch.", "labels": [], "entities": [{"text": "neural hierarchical multi-label text classification", "start_pos": 75, "end_pos": 126, "type": "TASK", "confidence": 0.6846199989318847}]}, {"text": "It is designed for solving the hierarchical multi-label text classification problem with effective and efficient neural models.", "labels": [], "entities": [{"text": "multi-label text classification problem", "start_pos": 44, "end_pos": 83, "type": "TASK", "confidence": 0.690967321395874}]}, {"text": "It provides a variety of models and features, users can utilize a comfortable configuration file with neural feature design and utilization.", "labels": [], "entities": []}, {"text": "We take the layerwise implementation, which includes input layer, embedding layer, encoder layer and output layer.", "labels": [], "entities": []}, {"text": "To our best knowledge, our work is the first neural hierarchical multi-label text classification toolkit with rich models.", "labels": [], "entities": [{"text": "multi-label text classification", "start_pos": 65, "end_pos": 96, "type": "TASK", "confidence": 0.6177333295345306}]}, {"text": "For the details, we give a summary comparison with existing toolkits in.", "labels": [], "entities": []}, {"text": "NeuralClassifier is: \u2022 Rich in models and features: An important feature of our work is that, compared with existing toolkits, NeuralClassifier reimplements a very large number of the state-of-the-art text encoders, including.", "labels": [], "entities": []}, {"text": "Meanwhile, NeuralClassifier involves a variety of useful features or widgets, i.e., word-based and char-based input, optimizers, loss functions, embedding methods and attention mechanisms, etc.", "labels": [], "entities": []}, {"text": "All those above can be configured through a configuration file.", "labels": [], "entities": []}, {"text": "shows a segment of configuration file.", "labels": [], "entities": []}, {"text": "Note that users can configure different text encoders and features through the configuration file, and can easily modify the source code to achieve more advanced developments.", "labels": [], "entities": []}, {"text": "\u2022 Suitable for almost all text classification tasks: NeuralClassifier is designed for hierarchical and multi-label classification, which naturally also supports binary-class and multi-class classification, so it can be considered a universal toolkit for text classification tasks.", "labels": [], "entities": [{"text": "text classification tasks", "start_pos": 26, "end_pos": 51, "type": "TASK", "confidence": 0.7819127241770426}, {"text": "multi-label classification", "start_pos": 103, "end_pos": 129, "type": "TASK", "confidence": 0.7496438920497894}, {"text": "text classification tasks", "start_pos": 254, "end_pos": 279, "type": "TASK", "confidence": 0.822681744893392}]}, {"text": "Especially in hierarchical multi-label classification task, the taxonomy can be organized in the form of a tree or DAG, and instances are multi-labeled during training and testing.", "labels": [], "entities": [{"text": "multi-label classification task", "start_pos": 27, "end_pos": 58, "type": "TASK", "confidence": 0.7569541533788046}]}, {"text": "It also provides a complete evaluation mechanism.", "labels": [], "entities": []}, {"text": "An illustration with results is shown in.", "labels": [], "entities": []}, {"text": "Users can choose their task types only through a comfortable configuration file without any code work.", "labels": [], "entities": []}, {"text": "\u2022 Effective and efficient: We conduct the experiments based on a variety of models and features provided by NeuralClassifier.", "labels": [], "entities": []}, {"text": "Experiments show models builtin our toolkit output comparable performance with reported results in the literature.", "labels": [], "entities": []}, {"text": "Furthermore, NeuralClassifier is implemented using batch calculation that can be accelerated using GPU.", "labels": [], "entities": []}, {"text": "Our experiments demonstrate that NeuralClassifier is an effective and efficient toolkit.", "labels": [], "entities": []}, {"text": "The rest of this paper is organized as follows: Section 2 describes the detail of architecture of NeuralClassifier.", "labels": [], "entities": []}, {"text": "The experimental evaluations and results are discussed in Section 3.", "labels": [], "entities": []}, {"text": "Finally, Section 4 concludes this paper.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section, we conduct several experiments to evaluate the performance of NeuralClassifier using datasets from two public benchmarks, namely, RCV1 () and Yelp 5 . The experiments consist of three parts: (1) Results of using rich models and features in Section 3.1; (2) influence of hierarchical information in Section 3.2; (3) speed with batch size in Section 3.3.", "labels": [], "entities": [{"text": "speed", "start_pos": 332, "end_pos": 337, "type": "METRIC", "confidence": 0.9936650991439819}]}], "tableCaptions": [{"text": " Table 2: Results on the two benchmarks.", "labels": [], "entities": []}, {"text": " Table 3: Results of different text encoders.", "labels": [], "entities": []}, {"text": " Table 4: Results of hierarchical and flat classification  on RCV1.", "labels": [], "entities": [{"text": "RCV1", "start_pos": 62, "end_pos": 66, "type": "DATASET", "confidence": 0.9737977981567383}]}]}