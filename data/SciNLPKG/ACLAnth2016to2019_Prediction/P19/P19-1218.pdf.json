{"title": [{"text": "Token-level Dynamic Self-Attention Network for Multi-Passage Reading Comprehension", "labels": [], "entities": [{"text": "Multi-Passage Reading Comprehension", "start_pos": 47, "end_pos": 82, "type": "TASK", "confidence": 0.7159200509389242}]}], "abstractContent": [{"text": "Multi-passage reading comprehension requires the ability to combine cross-passage information and reason over multiple passages to infer the answer.", "labels": [], "entities": [{"text": "Multi-passage reading comprehension", "start_pos": 0, "end_pos": 35, "type": "TASK", "confidence": 0.8165426055590311}]}, {"text": "In this paper, we introduce the Dynamic Self-attention Network (Dyn-SAN) for multi-passage reading comprehension task, which processes cross-passage information at token-level and meanwhile avoids substantial computational costs.", "labels": [], "entities": [{"text": "multi-passage reading comprehension task", "start_pos": 77, "end_pos": 117, "type": "TASK", "confidence": 0.7950090914964676}]}, {"text": "The core module of the dynamic self-attention is a proposed gated token selection mechanism, which dynamically selects important tokens from a sequence.", "labels": [], "entities": []}, {"text": "These chosen tokens will attend to each other via a self-attention mechanism to model long-range dependencies.", "labels": [], "entities": []}, {"text": "Besides, con-volutional layers are combined with the dynamic self-attention to enhance the model's capacity of extracting local semantic.", "labels": [], "entities": []}, {"text": "The experimental results show that the proposed DynSAN achieves new state-of-the-art performance on the SearchQA, Quasar-T and Wiki-Hop datasets.", "labels": [], "entities": [{"text": "SearchQA", "start_pos": 104, "end_pos": 112, "type": "DATASET", "confidence": 0.9560303688049316}, {"text": "Wiki-Hop datasets", "start_pos": 127, "end_pos": 144, "type": "DATASET", "confidence": 0.868541955947876}]}, {"text": "Further ablation study also validates the effectiveness of our model components .", "labels": [], "entities": []}], "introductionContent": [{"text": "As a critical approach for evaluating the ability of an intelligent agent to understand natural language, reading comprehension (RC) is a challenging research direction, attracting many researchers' interest.", "labels": [], "entities": [{"text": "reading comprehension (RC)", "start_pos": 106, "end_pos": 132, "type": "TASK", "confidence": 0.6941811203956604}]}, {"text": "In real application scenarios, such as web search, the passages maybe multiple and extended, and maybe comprised of relevant and irrelevant contents.", "labels": [], "entities": []}, {"text": "It involves the problem of multi-passage reading comprehension.", "labels": [], "entities": []}, {"text": "In multi-passage setting, cross-passage information interaction is vital for modeling long-range dependencies, co-references between entities in different passages (, crosspassage answer verification (, and multihop reasoning (, etc.", "labels": [], "entities": []}, {"text": "Great efforts have been made to develop models for multi-passage task, such as.", "labels": [], "entities": []}, {"text": "The common practice of these approaches is that all the embeddings in a passage or a span are integrated into a single vector and the cross-passage information interactions are based on these coarse-grain semantic representations.", "labels": [], "entities": []}, {"text": "However, it may cause potential issues.", "labels": [], "entities": []}, {"text": "As is pointed out in;, compressing all the necessary information into a single vector may lead to \"sacrifice\" some critical information due to the allocated capacity to remember other information.", "labels": [], "entities": []}, {"text": "This problem is prevalent in Neural Machine Translation (NMT), the recent models, such as the Transformer (), workaround this issue by decoding on token-level context encodings of the source text.", "labels": [], "entities": [{"text": "Neural Machine Translation (NMT)", "start_pos": 29, "end_pos": 61, "type": "TASK", "confidence": 0.7926603655020396}]}, {"text": "As such, we hypothesize that fine-grain representations may keep precise semantic information, and maybe beneficial to cross-passage information interactions in RC tasks.", "labels": [], "entities": []}, {"text": "In this paper, we focus on an architecture which deals with the cross-passage information at token-level.", "labels": [], "entities": []}, {"text": "The proposed architecture is a variant of the Self-attention Network (SAN) ().", "labels": [], "entities": []}, {"text": "Our model employs a self-attention mechanism to combine tokenlevel supportive information from all passages in a multi-step process.", "labels": [], "entities": []}, {"text": "Directly applying selfattention overall tokens is computationally expensive.", "labels": [], "entities": []}, {"text": "Instead, in each step, the most important tokens are dynamically selected from all passages, and information interaction only happens over these chosen tokens via the self-attention mechanism.", "labels": [], "entities": []}, {"text": "The motivation behind it is an observation that the information used to answer the question is usually concentrated on a few words.", "labels": [], "entities": []}, {"text": "Our experiments verify this observation to a certain extent.", "labels": [], "entities": []}, {"text": "We expect that our model can automatically find out these important tokens.", "labels": [], "entities": []}, {"text": "Thus we propose a gated token selection mechanism and equip it with the self-attention module.", "labels": [], "entities": []}, {"text": "We intend the model to achieve a balance in speed, memory, and accuracy.", "labels": [], "entities": [{"text": "speed", "start_pos": 44, "end_pos": 49, "type": "METRIC", "confidence": 0.9961481094360352}, {"text": "memory", "start_pos": 51, "end_pos": 57, "type": "METRIC", "confidence": 0.9926348328590393}, {"text": "accuracy", "start_pos": 63, "end_pos": 71, "type": "METRIC", "confidence": 0.9985094666481018}]}, {"text": "While the selfattention mechanism is widely used in end-to-end models to capture long-range dependency, it is intrinsically inefficient in memory usage.", "labels": [], "entities": []}, {"text": "The memory required to store the attention matrix grows quadratically with the sequence length.", "labels": [], "entities": []}, {"text": "Considering real scenarios, such as web search, in which the retrieval system returns hundreds of articles, and each contains hundreds or thousands of words, thus applying self-attention on all tokens in the supporting passages is computationally expensive.", "labels": [], "entities": []}, {"text": "Compared to recurrent neural networks, such as LSTM), SAN is highly parallelizable and usually faster on long sequence (.", "labels": [], "entities": [{"text": "SAN", "start_pos": 54, "end_pos": 57, "type": "TASK", "confidence": 0.961516261100769}]}, {"text": "The proposed method accomplishes necessary cross-passage information interaction with a time/memory complexity linear in the length of the sequence and do not add much extra calculation burden.", "labels": [], "entities": []}, {"text": "Our contributions in this work are as follows: (1) We propose Dynamic Self-attention (DynSA) for information interaction in along sequence.", "labels": [], "entities": []}, {"text": "(2) Token-level cross-passage information interaction is implemented through the application of the proposed DynSA at relatively less computational costs.", "labels": [], "entities": []}, {"text": "(3) Our Dynamic Self-attention Network (DynSAN) achieves new state-of-the-art performance compared with previously published results on SearchQA, Quasar-T and WikiHop benchmarks.", "labels": [], "entities": [{"text": "SearchQA", "start_pos": 136, "end_pos": 144, "type": "DATASET", "confidence": 0.9550026059150696}]}], "datasetContent": [{"text": "We conduct experiments to study the performance of the proposed approach on three publicly available multi-passage RC datasets.", "labels": [], "entities": []}, {"text": "SearchQA () is an open domain QA dataset including about 140k questions crawled from J!", "labels": [], "entities": [{"text": "QA dataset", "start_pos": 30, "end_pos": 40, "type": "DATASET", "confidence": 0.6595893055200577}]}, {"text": "Archive, and about 50 web page snippets, which are retrieved from the Google search engine, as the supporting passages for each question.", "labels": [], "entities": []}, {"text": "The authors of SearchQA have provided a processed version of this dataset, in which all words are lower-cased, and tokenization has been completed.", "labels": [], "entities": []}, {"text": "Our experiments are based on this processed version.", "labels": [], "entities": []}, {"text": "Quasar-T () is an open domain QA dataset including about 43k trivia questions collected from various internet sources, and 100 supporting passages for each question.", "labels": [], "entities": [{"text": "Quasar-T", "start_pos": 0, "end_pos": 8, "type": "DATASET", "confidence": 0.8277547955513}, {"text": "QA dataset", "start_pos": 30, "end_pos": 40, "type": "DATASET", "confidence": 0.6850888282060623}]}, {"text": "These supporting passages are given in an order ranked by a search engine.", "labels": [], "entities": []}, {"text": "WikiHop () is a multiple choice QA dataset constructed using a structured knowledge base.", "labels": [], "entities": [{"text": "WikiHop", "start_pos": 0, "end_pos": 7, "type": "DATASET", "confidence": 0.8839631676673889}]}, {"text": "One has to submit the model and work with the author to obtain the test score.", "labels": [], "entities": []}, {"text": "For this dataset, a binary feature is concatenated with word embeddings and character embeddings to indicate whether a token is belong to any candidate answers.", "labels": [], "entities": []}, {"text": "The above three datasets have their official train/dev/test sets, so we do not split them by ourselves.", "labels": [], "entities": []}, {"text": "Some of the above datasets provide additional meta-data, we do not use this additional information in our experiments.", "labels": [], "entities": []}, {"text": "We observe that those low-ranked passages play a critical role in improving the accuracy, thus we remain all supporting passages as the inputs of our model.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 80, "end_pos": 88, "type": "METRIC", "confidence": 0.9995104074478149}]}, {"text": "The averages/medians of the total length of the concatenation of all supporting passages for each question are around 1.9k/2k, 2.4k/2.4k, and 1.2k/1k in SearchQA, Quasar-T, and WikiHop respectively.", "labels": [], "entities": [{"text": "SearchQA", "start_pos": 153, "end_pos": 161, "type": "DATASET", "confidence": 0.9471874833106995}]}, {"text": "Thus, we limit the maximum length not to exceed 5k tokens and discard a few exceptionally long cases.", "labels": [], "entities": []}, {"text": "Tokenization is completed using spaCy 1 during preprocessing.", "labels": [], "entities": []}, {"text": "In the DynSAN, the kernel size is 7 for all convolutional layers, the standard dimension Dis 128, the number of heads H is 8, the number of chosen tokens K is 256.", "labels": [], "entities": [{"text": "Dis", "start_pos": 89, "end_pos": 92, "type": "METRIC", "confidence": 0.8658140897750854}]}, {"text": "In the cross-passage attention layer, we stack N = 4 layers of DynSA blocks.", "labels": [], "entities": []}, {"text": "The mini-batch size is set to 32.", "labels": [], "entities": []}, {"text": "For regularization, we adopt dropout between every two layers and the dropout rate is 0.1.", "labels": [], "entities": [{"text": "regularization", "start_pos": 4, "end_pos": 18, "type": "TASK", "confidence": 0.9735192656517029}]}, {"text": "Adam () with learning rate 0.001 is used for tuning the model parameters.", "labels": [], "entities": []}, {"text": "We use a learning rate warm-up scheme in which the learning rate increases linearly from 0 to 0.001 in the first 500 steps.", "labels": [], "entities": []}, {"text": "The models for multi-passage reading comprehension are trained on four 12GB K80 GPUs using synchronous SGD (.", "labels": [], "entities": [{"text": "multi-passage reading comprehension", "start_pos": 15, "end_pos": 50, "type": "TASK", "confidence": 0.7415725390116373}]}, {"text": "Exponential moving average is adopted with a decay rate 0.9999.", "labels": [], "entities": [{"text": "Exponential moving average", "start_pos": 0, "end_pos": 26, "type": "METRIC", "confidence": 0.9084347486495972}]}], "tableCaptions": [{"text": " Table 1: Performance of DynSAN and competing ap- proaches on the test sets of two extractive QA tasks:  SearchQA and Quasar-T. Competing approaches in- clude DrQA (Chen et al., 2017), R 3 (Wang et al.,  2018a), TraCRNet (Dehghani et al., 2019a), Shared- Norm (Clark and Gardner, 2018), HAS-QA (Pang  et al., 2019). Human performance is referenced from  the dataset paper.", "labels": [], "entities": [{"text": "DrQA", "start_pos": 159, "end_pos": 163, "type": "DATASET", "confidence": 0.9583920240402222}]}, {"text": " Table 2: Performance of DynSAN and competing ap- proaches on multiple choice QA dataset: WikiHop.", "labels": [], "entities": [{"text": "QA dataset", "start_pos": 78, "end_pos": 88, "type": "DATASET", "confidence": 0.6204306930303574}, {"text": "WikiHop", "start_pos": 90, "end_pos": 97, "type": "DATASET", "confidence": 0.8882105946540833}]}, {"text": " Table 3: Ablation study on SearchQA test set. \"\u2212\"/\"+\"  denotes removing/adding a model component, the in- dent in (e) and (h) means removing/adding a model  component on the basis of the previous line.", "labels": [], "entities": [{"text": "SearchQA test set", "start_pos": 28, "end_pos": 45, "type": "DATASET", "confidence": 0.93650750319163}]}, {"text": " Table 4: The time cost and memory consumption  on SQuAD. The time cost is shown through the  speedup rate with respect to Bi-LSTM. Both the train- ing speedup rate and inference speedup rate are re- ported. The memory usage is measured in Megabyte.  |\u03b8| denotes the amount of trainable parameters in a  model. Accuracy is measured by EM and F1.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 311, "end_pos": 319, "type": "METRIC", "confidence": 0.999461829662323}, {"text": "EM", "start_pos": 335, "end_pos": 337, "type": "METRIC", "confidence": 0.9598321914672852}, {"text": "F1", "start_pos": 342, "end_pos": 344, "type": "METRIC", "confidence": 0.9969095587730408}]}]}