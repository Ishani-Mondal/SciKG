{"title": [{"text": "Incorporating Syntactic and Semantic Information in Word Embeddings using Graph Convolutional Networks", "labels": [], "entities": []}], "abstractContent": [{"text": "Word embeddings have been widely adopted across several NLP applications.", "labels": [], "entities": []}, {"text": "Most existing word embedding methods utilize sequential context of a word to learn its embedding.", "labels": [], "entities": []}, {"text": "While there have been some attempts at utilizing syntactic context of a word, such methods result in an explosion of the vocabulary size.", "labels": [], "entities": []}, {"text": "In this paper, we overcome this problem by proposing SynGCN, a flexible Graph Convolution based method for learning word embeddings.", "labels": [], "entities": []}, {"text": "SynGCN utilizes the dependency context of a word without increasing the vocabulary size.", "labels": [], "entities": []}, {"text": "Word embeddings learned by SynGCN outperform existing methods on various intrinsic and extrinsic tasks and provide an advantage when used with ELMo.", "labels": [], "entities": []}, {"text": "We also propose SemGCN, an effective framework for incorporating diverse semantic knowledge for further enhancing learned word representations.", "labels": [], "entities": []}, {"text": "We make the source code of both models available to encourage reproducible research .", "labels": [], "entities": []}], "introductionContent": [{"text": "Representing words as real-valued vectors is an effective and widely adopted technique in NLP.", "labels": [], "entities": []}, {"text": "Such representations capture properties of words based on their usage and allow them to generalize across tasks.", "labels": [], "entities": []}, {"text": "Meaningful word embeddings have been shown to improve performance on several relevant tasks, such as named entity recognition (NER) (), parsing , and part-of-speech (POS) tagging.", "labels": [], "entities": [{"text": "named entity recognition (NER)", "start_pos": 101, "end_pos": 131, "type": "TASK", "confidence": 0.7935997446378072}, {"text": "parsing", "start_pos": 136, "end_pos": 143, "type": "TASK", "confidence": 0.9686601161956787}, {"text": "part-of-speech (POS) tagging", "start_pos": 150, "end_pos": 178, "type": "TASK", "confidence": 0.6226506054401397}]}, {"text": "Using word embeddings for initializing Deep Neural Networks has also been found to be quite useful).", "labels": [], "entities": [{"text": "initializing Deep Neural Networks", "start_pos": 26, "end_pos": 59, "type": "TASK", "confidence": 0.8761227428913116}]}, {"text": "Most popular methods for learning word embeddings are based on the distributional hypothesis, which utilizes the co-occurrence statistics * Contributed equally to the from sequential context of words for learning word representations ().", "labels": [], "entities": []}, {"text": "More recently, this approach has been extended to include syntactic contexts () derived from dependency parse of text.", "labels": [], "entities": [{"text": "dependency parse of text", "start_pos": 93, "end_pos": 117, "type": "TASK", "confidence": 0.8037201911211014}]}, {"text": "Higher order dependencies have also been exploited by;.", "labels": [], "entities": []}, {"text": "Syntax-based embeddings encode functional similarity (in-place substitutable words) rather than topical similarity (topically related words) which provides an advantage on specific tasks like question classification (.", "labels": [], "entities": [{"text": "question classification", "start_pos": 192, "end_pos": 215, "type": "TASK", "confidence": 0.8116346597671509}]}, {"text": "However, current approaches incorporate syntactic context by concatenating words with their dependency relations.", "labels": [], "entities": []}, {"text": "For instance, in scientists_subj, water_obj, and mars_nmod needs to be included as apart of vocabulary for utilizing the dependency context of discover.", "labels": [], "entities": []}, {"text": "This severely expands the vocabulary, thus limiting the scalability of models on large corpora.", "labels": [], "entities": []}, {"text": "For instance, in and, the context vocabulary explodes to around 1.3 million for learning embeddings of 220k words.", "labels": [], "entities": []}, {"text": "Incorporating relevant signals from semantic knowledge sources such as WordNet, FrameNet (, and Paraphrase Database (PPDB) () has been shown to improve the quality of word embeddings.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 71, "end_pos": 78, "type": "DATASET", "confidence": 0.9670720100402832}]}, {"text": "Recent works utilize these by incorporating them in a neural language modeling objective function (, or as a post-processing step.", "labels": [], "entities": []}, {"text": "Although existing approaches improve the quality of word embeddings, they require explicit modification for handling different types of semantic information.", "labels": [], "entities": []}, {"text": "Recently proposed Graph Convolutional Networks (GCN) Figure 1: Overview of SynGCN: SynGCN employs Graph Convolution Network for utilizing dependency context for learning word embeddings.", "labels": [], "entities": []}, {"text": "For each word in vocabulary, the model learns its representation by aiming to predict each word based on its dependency context encoded using GCNs.", "labels": [], "entities": []}, {"text": "Please refer Section 5 for more details.", "labels": [], "entities": []}, {"text": "Welling, 2016) have been found to be useful for encoding structural information in graphs.", "labels": [], "entities": []}, {"text": "Even though GCNs have been successfully employed for several NLP tasks such as machine translation (, semantic role labeling , document dating () and text classification (, they have so far not been used for learning word embeddings, especially leveraging cues such as syntactic and semantic information.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 79, "end_pos": 98, "type": "TASK", "confidence": 0.8181430101394653}, {"text": "semantic role labeling", "start_pos": 102, "end_pos": 124, "type": "TASK", "confidence": 0.6587922672430674}, {"text": "document dating", "start_pos": 127, "end_pos": 142, "type": "TASK", "confidence": 0.7456186711788177}, {"text": "text classification", "start_pos": 150, "end_pos": 169, "type": "TASK", "confidence": 0.7744140326976776}]}, {"text": "GCNs provide flexibility to represent diverse syntactic and semantic relationships between words all within one framework, without requiring relation-specific special handling as in previous methods.", "labels": [], "entities": []}, {"text": "Recognizing these benefits, we make the following contributions in this paper.", "labels": [], "entities": []}], "datasetContent": [{"text": "In our experiments, we use Wikipedia 2 corpus for training the models.", "labels": [], "entities": [{"text": "Wikipedia 2 corpus", "start_pos": 27, "end_pos": 45, "type": "DATASET", "confidence": 0.8541994492212931}]}, {"text": "After discarding too long and too short sentences, we get an average sentence length of nearly 20 words.", "labels": [], "entities": []}, {"text": "The corpus consists of 57 million sentences with 1.1 billion tokens and 1 billion syntactic dependencies.", "labels": [], "entities": []}, {"text": "To evaluate the effectiveness of our proposed methods, we compare them against the baselines on the following intrinsic and extrinsic tasks 3 : \u2022 Intrinsic Tasks: Word Similarity is the task of evaluating closeness between semantically similar words.", "labels": [], "entities": [{"text": "Word Similarity", "start_pos": 163, "end_pos": 178, "type": "TASK", "confidence": 0.7110595703125}]}, {"text": "Following  The evaluation results on intrinsic tasks -word similarity, concept categorization, and analogyare summarized in.", "labels": [], "entities": []}, {"text": "We report Spearman correlation for word similarity and analogy tasks and cluster purity for concept categorization task.", "labels": [], "entities": [{"text": "Spearman correlation", "start_pos": 10, "end_pos": 30, "type": "METRIC", "confidence": 0.660044252872467}, {"text": "cluster purity", "start_pos": 73, "end_pos": 87, "type": "METRIC", "confidence": 0.8867877125740051}]}, {"text": "Overall, we find that SynGCN, our proposed method, outperforms all the existing word embed-   ding approaches in 9 out of 10 settings.", "labels": [], "entities": []}, {"text": "The inferior performance of SynGCN and other dependency context based methods on WS353R dataset compared to sequential context based methods is consistent with the observation reported in;.", "labels": [], "entities": [{"text": "WS353R dataset", "start_pos": 81, "end_pos": 95, "type": "DATASET", "confidence": 0.9827225506305695}]}, {"text": "This is because the syntactic context based embeddings capture functional similarity rather than topical similarity (as discussed in Section 1).", "labels": [], "entities": []}, {"text": "On average, we obtain around 1.5%, 5.7% and 7.5% absolute increase in performance on word similarity, concept categorization and analogy tasks compared to the best performing baseline.", "labels": [], "entities": []}, {"text": "The results demonstrate that the learned embeddings from SynGCN more effectively capture semantic and syntactic properties of words.", "labels": [], "entities": []}, {"text": "We also evaluate the performance of different word embedding approaches on the downstream tasks as defined in Section 8.3.", "labels": [], "entities": []}, {"text": "The experimental results are summarized in.", "labels": [], "entities": []}, {"text": "Overall, we find that SynGCN either outperforms or performs comparably to other methods on all four tasks.", "labels": [], "entities": []}, {"text": "Compared to the sequential context based methods, dependency based methods perform superior at question answering task as they effectively encode syntactic information.", "labels": [], "entities": [{"text": "question answering task", "start_pos": 95, "end_pos": 118, "type": "TASK", "confidence": 0.8030688365300497}]}, {"text": "This is consistent with the observation of  In this section, we compare SemGCN against the methods listed in Section 8.2 for incorporating diverse semantic information in pre-trained embeddings.", "labels": [], "entities": []}, {"text": "We use hypernym, hyponym, and antonym relations from WordNet, and synonym relations from PPDB as semantic information.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 53, "end_pos": 60, "type": "DATASET", "confidence": 0.9502084851264954}]}, {"text": "For each method, we provide the semantic information that it can utilize, e.g., Retro-fit can only make use of synonym relation 4 . In our results, M(X, R) denotes the fine-tuned embeddings obtained using method M while taking X as initialization embeddings.", "labels": [], "entities": [{"text": "Retro-fit", "start_pos": 80, "end_pos": 89, "type": "DATASET", "confidence": 0.4973646104335785}]}, {"text": "R denotes the types of semantic information used as defined below.", "labels": [], "entities": []}, {"text": "\u2022 R=1: Only synonym information.", "labels": [], "entities": [{"text": "R", "start_pos": 2, "end_pos": 3, "type": "METRIC", "confidence": 0.9914147257804871}]}, {"text": "\u2022 R=2: Synonym and antonym information.", "labels": [], "entities": [{"text": "R", "start_pos": 2, "end_pos": 3, "type": "METRIC", "confidence": 0.9897434115409851}]}, {"text": "\u2022 R=4: Synonym, antonym, hypernym and hyponym information.", "labels": [], "entities": [{"text": "R", "start_pos": 2, "end_pos": 3, "type": "METRIC", "confidence": 0.9853478074073792}]}, {"text": "For instance, Counter-fit (GloVe, 2) represents GloVe embeddings fine-tuned by Counter-fit using synonym and antonym information.", "labels": [], "entities": []}, {"text": "Similar to Section 9.1, the evaluation is performed on the three intrinsic tasks.", "labels": [], "entities": []}, {"text": "Due to space limitations, we report results on one representative dataset per task.", "labels": [], "entities": []}, {"text": "The results are summarized   in.", "labels": [], "entities": []}, {"text": "We find that in 13 out of 15 settings, SemGCN outperforms other methods.", "labels": [], "entities": []}, {"text": "Overall, we observe that SemGCN, when initialized with Syn-GCN, gives the best performance on all the tasks (highlighted by \u00b7 in).", "labels": [], "entities": []}, {"text": "For comparing performance on the extrinsic tasks, we first fine-tune SynGCN embeddings using different methods for incorporating semantic information.", "labels": [], "entities": []}, {"text": "The embeddings obtained by this process are then evaluated on extrinsic tasks, as in Section 9.1.", "labels": [], "entities": []}, {"text": "The results are shown in.", "labels": [], "entities": []}, {"text": "We use the same M (X, R) notation to represent methods as in Section 9.2.", "labels": [], "entities": []}, {"text": "We observe that while the other methods do not always consistently give improvement over the baseline SynGCN, SemGCN is able to improve upon SynGCN in all settings (better or comparable).", "labels": [], "entities": []}, {"text": "Overall, we observe that SynGCN along with SemGCN is the most suitable method for incorporating both syntactic and semantic information.", "labels": [], "entities": []}, {"text": "In this section, we compare SemGCN against other baselines when provided with the same semantic information: synonyms from PPDB.", "labels": [], "entities": []}, {"text": "Similar to Section 9.2, we compare both on intrinsic and extrinsic tasks with different initializations.", "labels": [], "entities": []}, {"text": "The evaluation results of fine-tuned SynGCN embeddings by different methods on SQuAD are shown in the.", "labels": [], "entities": []}, {"text": "The remaining results are included in the supplementary and S2).", "labels": [], "entities": [{"text": "supplementary", "start_pos": 42, "end_pos": 55, "type": "METRIC", "confidence": 0.9830157160758972}]}, {"text": "We observe that compared to other methods, SemGCN is most effective at incorporating semantic constraints across all the initializations and outperforms others at both intrinsic and extrinsic tasks.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: SynGCN Intrinsic Evaluation: Performance on word similarity (Spearman correlation), concept cate- gorization (cluster purity), and word analogy (Spearman correlation). Overall, SynGCN outperforms other existing  approaches in 9 out of 10 settings. Please refer to Section 9.1 for more details.", "labels": [], "entities": [{"text": "word analogy", "start_pos": 141, "end_pos": 153, "type": "TASK", "confidence": 0.6676557809114456}]}, {"text": " Table 2: SynGCN Extrinsic Evaluation: Comparison  on parts-of-speech tagging (POS), question answering  (SQuAD), named entity recognition (NER), and co- reference resolution (Coref). SynGCN performs com- parable or outperforms all existing approaches on all  tasks. Refer Section 9.1 for details.", "labels": [], "entities": [{"text": "SynGCN Extrinsic Evaluation", "start_pos": 10, "end_pos": 37, "type": "TASK", "confidence": 0.7737148801485697}, {"text": "parts-of-speech tagging (POS)", "start_pos": 54, "end_pos": 83, "type": "TASK", "confidence": 0.8112900376319885}, {"text": "question answering", "start_pos": 85, "end_pos": 103, "type": "TASK", "confidence": 0.752041757106781}, {"text": "named entity recognition (NER)", "start_pos": 114, "end_pos": 144, "type": "TASK", "confidence": 0.7728900760412216}]}, {"text": " Table 4: SemGCN Intrinsic Evaluation: Evaluation of different methods for incorporating diverse semantic  constraints initialized using various pre-trained embeddings (X). M(X, R) denotes the fine-tuned embeddings using  method M taking X as initialization embeddings. R denotes the type of semantic relations used as defined in  Section 9.2. SemGCN outperforms other methods in 13 our of 15 settings. SemGCN with SynGCN gives the best  performance across all tasks (highlighted using \u00b7 ). Please refer Section 9.2 for details.", "labels": [], "entities": []}, {"text": " Table 5: Comparison of ELMo with SynGCN and  SemGCN embeddings on multiple extrinsic tasks. For  each task, models use a linear combination of the pro- vided embeddings whose weights are learned. Results  show that our proposed methods encode complemen- tary information which is not captured by ELMo.", "labels": [], "entities": []}]}