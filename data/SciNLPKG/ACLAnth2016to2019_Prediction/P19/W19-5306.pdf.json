{"title": [{"text": "Machine Translation with parfda, Moses, kenlm, nplm, and PRO", "labels": [], "entities": [{"text": "Machine Translation", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.6154916882514954}, {"text": "PRO", "start_pos": 57, "end_pos": 60, "type": "DATASET", "confidence": 0.4937514364719391}]}], "abstractContent": [{"text": "We build parfda Moses statistical machine translation (SMT) models for most language pairs in the news translation task.", "labels": [], "entities": [{"text": "statistical machine translation (SMT)", "start_pos": 22, "end_pos": 59, "type": "TASK", "confidence": 0.8160203496615092}, {"text": "news translation task", "start_pos": 98, "end_pos": 119, "type": "TASK", "confidence": 0.7862222095330557}]}, {"text": "We experiment with a hybrid approach using neural language models integrated into Moses.", "labels": [], "entities": []}, {"text": "We obtain the constrained data statistics on the machine translation task, the coverage of the test sets, and the upper bounds on the translation results.", "labels": [], "entities": [{"text": "machine translation task", "start_pos": 49, "end_pos": 73, "type": "TASK", "confidence": 0.8510908683141073}]}, {"text": "We also contribute anew testsuite for the German-English language pair and anew automated key phrase extraction technique for the evaluation of the testsuite translations.", "labels": [], "entities": [{"text": "key phrase extraction", "start_pos": 90, "end_pos": 111, "type": "TASK", "confidence": 0.7301163673400879}]}], "introductionContent": [{"text": "Parallel feature weight decay algorithms (parfda)) is an instance selection tool we use to select training and language model instances to build Moses ( phrase-based machine translation (MT) systems to translate the test sets in the news translation task at WMT19 (.", "labels": [], "entities": [{"text": "phrase-based machine translation (MT)", "start_pos": 153, "end_pos": 190, "type": "TASK", "confidence": 0.8088847001393636}, {"text": "news translation task", "start_pos": 233, "end_pos": 254, "type": "TASK", "confidence": 0.7835490008195242}, {"text": "WMT19", "start_pos": 258, "end_pos": 263, "type": "DATASET", "confidence": 0.9162315130233765}]}, {"text": "The importance of parfda increase with the increasing size of the parallel and monolingual data available for building SMT systems.", "labels": [], "entities": [{"text": "SMT", "start_pos": 119, "end_pos": 122, "type": "TASK", "confidence": 0.9896544218063354}]}, {"text": "In the light of last year's evidence that shows that parfda phrase-based SMT can obtain the 2nd best results on a testsuite in the English-Turkish language pair when generating the translations of key phrases that are important for conveying the meaning, we obtain phrase-based Moses results and its extension with a neural LM in addition to the n-gram based LM that we use.", "labels": [], "entities": [{"text": "SMT", "start_pos": 73, "end_pos": 76, "type": "TASK", "confidence": 0.7002900838851929}]}, {"text": "We experiment with neural probabilistic LM (NPLM) ().", "labels": [], "entities": []}, {"text": "We record the statistics of the data and the resources used.", "labels": [], "entities": []}, {"text": "Our contributions are: \u2022 a test suite for machine translation that is out of the domain of news task to take the chance of taking a closer look at the current status of SMT technology used by the task participants when translating 38 sentences about international relations concerning cultural artifacts, \u2022 parfda Moses phrase-based MT results and data statistics for the following translation directions: -English-Czech (en-cs) RussianEnglish (ru-en), \u2022 upperbounds on the translation performance using lowercased coverage to identify which models used data in addition to the parallel corpus.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 42, "end_pos": 61, "type": "TASK", "confidence": 0.7856718301773071}, {"text": "SMT", "start_pos": 169, "end_pos": 172, "type": "TASK", "confidence": 0.9898616075515747}, {"text": "translating 38 sentences about international relations concerning cultural artifacts", "start_pos": 219, "end_pos": 303, "type": "TASK", "confidence": 0.7203873925738864}, {"text": "MT", "start_pos": 333, "end_pos": 335, "type": "TASK", "confidence": 0.8900247812271118}]}, {"text": "The sections that follow discuss the instance selection model (Section 2), the machine translation model (Section 3), the testsuite used for evaluating MT in en-de and de-en, and the results.: Statistics for the training and LM corpora in the constrained (C) setting compared with the parfda selected data.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 79, "end_pos": 98, "type": "TASK", "confidence": 0.772436648607254}, {"text": "MT", "start_pos": 152, "end_pos": 154, "type": "TASK", "confidence": 0.9461532831192017}]}, {"text": "#words is in millions (M) and #sents in thousands (K).", "labels": [], "entities": []}, {"text": "tcov is target 2-gram coverage.: Constrained training data lowercased source feature coverage (scov) and target feature coverage (tcov) of the test set for n-grams.", "labels": [], "entities": []}, {"text": "2 Instance Selection with parfda parfda parallelize feature decay algorithms (FDA), a class of instance selection algorithms that decay feature weights, for fast deployment of accurate SMT systems.", "labels": [], "entities": [{"text": "Instance Selection", "start_pos": 2, "end_pos": 20, "type": "TASK", "confidence": 0.7349440157413483}, {"text": "feature decay algorithms (FDA)", "start_pos": 52, "end_pos": 82, "type": "METRIC", "confidence": 0.5967313796281815}, {"text": "SMT", "start_pos": 185, "end_pos": 188, "type": "TASK", "confidence": 0.9653900265693665}]}, {"text": "depicts parfda Moses SMT workflow.", "labels": [], "entities": [{"text": "SMT workflow", "start_pos": 21, "end_pos": 33, "type": "TASK", "confidence": 0.8656366467475891}]}, {"text": "We use the test set source sentences to select the training data and the target side of the selected training data to select the LM data.", "labels": [], "entities": []}, {"text": "We decay the weights for both the source features of the test set and the target features that we already select to increase the diversity.", "labels": [], "entities": []}, {"text": "We select about 2.2 million instances for training data and about 12 million sentences for each LM data not including the selected training set, which is added later.", "labels": [], "entities": []}, {"text": "shows size differences with the constrained dataset (C).", "labels": [], "entities": []}, {"text": "We use 3-grams to select training data and 2-grams for LM data and split the hyphenated words 1 Available at https://github.com/bicici/ parfdaWMT2019 using the \"-a\" option of the tokenizer used in Moses (.", "labels": [], "entities": []}, {"text": "tcov lists the target coverage in terms of the 2-grams of the test set.", "labels": [], "entities": []}, {"text": "The maximum sentence length is set to 126.", "labels": [], "entities": []}, {"text": "lists the lowercased coverage of the test set by the constrained training data of WMT19.", "labels": [], "entities": [{"text": "WMT19", "start_pos": 82, "end_pos": 87, "type": "DATASET", "confidence": 0.6709838509559631}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Statistics for the training and LM corpora in the constrained (C) setting compared with the parfda  selected data. #words is in millions (M) and #sents in thousands (K). tcov is target 2-gram coverage.", "labels": [], "entities": []}, {"text": " Table 2: Constrained training data lowercased source feature coverage (scov) and target feature coverage (tcov) of  the test set for n-grams.", "labels": [], "entities": [{"text": "target feature coverage (tcov)", "start_pos": 82, "end_pos": 112, "type": "METRIC", "confidence": 0.772921954592069}]}, {"text": " Table 3: parfda BLEU cased results with different LM on text that is not hyphen splitted compared with after  hyphen splitting.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 17, "end_pos": 21, "type": "METRIC", "confidence": 0.9834219813346863}]}, {"text": " Table 4: parfda results compared with the top results in WMT19 and their difference. 2", "labels": [], "entities": [{"text": "parfda", "start_pos": 10, "end_pos": 16, "type": "METRIC", "confidence": 0.9485882520675659}, {"text": "WMT19", "start_pos": 58, "end_pos": 63, "type": "DATASET", "confidence": 0.842610776424408}]}, {"text": " Table 6: Information contribution from granular parts  of a sentence.", "labels": [], "entities": []}, {"text": " Table 8: de-en testsuite F 1 scores with key phrases.", "labels": [], "entities": [{"text": "F 1 scores", "start_pos": 26, "end_pos": 36, "type": "METRIC", "confidence": 0.9406495094299316}]}]}