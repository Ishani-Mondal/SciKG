{"title": [{"text": "THOMAS: The Hegemonic OSU Morphological Analyzer using Seq2seq", "labels": [], "entities": [{"text": "THOMAS", "start_pos": 0, "end_pos": 6, "type": "DATASET", "confidence": 0.7353752255439758}]}], "abstractContent": [{"text": "This paper describes the OSU submission to the SIGMORPHON 2019 shared task, Crosslinguality and Context in Morphology.", "labels": [], "entities": [{"text": "SIGMORPHON 2019 shared task", "start_pos": 47, "end_pos": 74, "type": "TASK", "confidence": 0.7407085001468658}, {"text": "Crosslinguality and Context in Morphology", "start_pos": 76, "end_pos": 117, "type": "TASK", "confidence": 0.6888481020927429}]}, {"text": "Our system addresses the contextual morphological analysis subtask of Task 2, which is to produce the morphosyntactic description (MSD) of each fully inflected word within a given sentence.", "labels": [], "entities": []}, {"text": "We frame this as a sequence generation task and employ a neu-ral encoder-decoder (seq2seq) architecture to generate the sequence of MSD tags given the encoded representation of each token.", "labels": [], "entities": []}, {"text": "Follow-up analyses reveal that our system most significantly improves performance on morphologically complex languages whose inflected word forms typically have longer MSD tag sequences.", "labels": [], "entities": []}, {"text": "In addition, our system seems to capture the structured correlation between MSD tags, such as that between the verb V tag and TAM-related tags.", "labels": [], "entities": []}], "introductionContent": [{"text": "For many natural language processing (NLP) applications such as parsing and machine translation, correctly analyzing the part-of-speech and finegrained morphological information (e.g. tense, mood, and aspect) of a given string of words is crucial for satisfactory performance.", "labels": [], "entities": [{"text": "parsing", "start_pos": 64, "end_pos": 71, "type": "TASK", "confidence": 0.9760751128196716}, {"text": "machine translation", "start_pos": 76, "end_pos": 95, "type": "TASK", "confidence": 0.7512216567993164}]}, {"text": "This task depends on the system's ability to learn reliable representations of the sequence on two distinct levels -one at the character-level, which is indicative of the morphosyntactic values of the word, and the other at the word-level, which is informative of subsequent words that are likely to appear in the sequence.", "labels": [], "entities": []}, {"text": "In addition, the system needs to have representational flexibility in order to be used in a cross-linguistic setting, as languages with typologically distinct morphological systems (e.g. isolating, agglutinative, and fusional) have different methods of realizing morphological information.", "labels": [], "entities": []}, {"text": "Ordering determined by dice roll.", "labels": [], "entities": [{"text": "Ordering", "start_pos": 0, "end_pos": 8, "type": "TASK", "confidence": 0.9560480117797852}]}], "datasetContent": [{"text": "Training data Following the shared task guidelines, six different treebanks from the UniMorph dataset () provided the data for training and evaluating the model.", "labels": [], "entities": [{"text": "UniMorph dataset", "start_pos": 85, "end_pos": 101, "type": "DATASET", "confidence": 0.924290269613266}]}, {"text": "The six treebanks -English-EWT, Spanish-Ancora, Hindi-HDTB, Russian-GSD, Turkish-IMST, and Chinese-GSD -cover a wide spectrum of morphological typology, thus making it suitable to assess the generalizability of each morphological analysis system.", "labels": [], "entities": []}, {"text": "The descriptive statistics of each training set are outlined in.", "labels": [], "entities": []}, {"text": "Training and evaluation procedure For the binary relevance model, most of the hyperparameters followed the default settings of the baseline system code 4 ; characters were embedded into 128-dimension representations, and the characterlevel biLSTM was trained to output a 256-dimension representation.", "labels": [], "entities": []}, {"text": "Adam () was used as the optimizer, using the default settings of the PyTorch deep learning library ().", "labels": [], "entities": [{"text": "PyTorch deep learning library", "start_pos": 69, "end_pos": 98, "type": "DATASET", "confidence": 0.8444075137376785}]}, {"text": "The model was trained for five epochs using batches of size 16, with early stopping.", "labels": [], "entities": []}, {"text": "The same hyperparameters were used   to train the encoder portion of the seq2seq model.", "labels": [], "entities": []}, {"text": "As for the GRU decoder, the maximum sequence length was fixed as the maximum sequence length seen during training.", "labels": [], "entities": [{"text": "GRU decoder", "start_pos": 11, "end_pos": 22, "type": "DATASET", "confidence": 0.9185694754123688}, {"text": "sequence length", "start_pos": 36, "end_pos": 51, "type": "METRIC", "confidence": 0.8515367209911346}]}, {"text": "Following prior work (, the order of the output tags was fixed to be in decreasing order of frequency of occurrence in the training set.", "labels": [], "entities": []}, {"text": "Decoding took place in a greedy manner, and only the highest scoring hypothesis at the previous timestep was further pursued.", "labels": [], "entities": []}, {"text": "The model was trained without any teacher forcing, as preliminary results showed that a teacher forcing ratio of 0.5 resulted in a decrease in model performance.", "labels": [], "entities": []}, {"text": "After training was complete, the models' accuracy was evaluated on the held-out test portion of the six treebanks that were used to train the models.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 41, "end_pos": 49, "type": "METRIC", "confidence": 0.9992759823799133}]}, {"text": "As per the shared task guidelines, the exact match accuracy and micro-averaged F1 scores were calculated for each of the trained models. that the default settings of the code were used to train them.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 51, "end_pos": 59, "type": "METRIC", "confidence": 0.7999675869941711}, {"text": "F1 scores", "start_pos": 79, "end_pos": 88, "type": "METRIC", "confidence": 0.9639390707015991}]}, {"text": "The only changes to the default settings when training the binary relevance model were in the training epochs (default 10 epochs) and batch size (not implemented, therefore default size 1).", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Descriptive statistics for the six UniMorph  treebanks used for training. Number of tags refers to  the number of different MSD tag dimensions, and the  number of combinations refers to the number of differ- ent MSD tag combinations present in each training set.", "labels": [], "entities": [{"text": "UniMorph  treebanks", "start_pos": 45, "end_pos": 64, "type": "DATASET", "confidence": 0.774372935295105}]}, {"text": " Table 4: Number of instances where two tag dimen- sions that do not co-occur in the test portion of the  dataset were predicted together by each model.", "labels": [], "entities": []}, {"text": " Table 5: Comparison of the number of MSD tag di- mensions predicted by each model and that in the gold  annotation, sorted according to the number of tags in  the gold annotation. P refers to the number of tags pre- dicted by the model, and G refers to the number of tags  that are in the gold annotation.", "labels": [], "entities": []}, {"text": " Table 6: Performance of the two models on TAM- related tokens in the Turkish test set. For each TAM- related tag dimension, the best results under each met- ric are in bold.", "labels": [], "entities": [{"text": "Turkish test set", "start_pos": 70, "end_pos": 86, "type": "DATASET", "confidence": 0.944545308748881}]}]}