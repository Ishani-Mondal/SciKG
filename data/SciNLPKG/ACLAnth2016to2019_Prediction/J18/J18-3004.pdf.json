{"title": [{"text": "On the Complexity of CCG Parsing", "labels": [], "entities": [{"text": "Parsing", "start_pos": 25, "end_pos": 32, "type": "TASK", "confidence": 0.6602650284767151}]}], "abstractContent": [{"text": "We study the parsing complexity of Combinatory Categorial Grammar (CCG) in the formalism of Vijay-Shanker and Weir (1994).", "labels": [], "entities": [{"text": "parsing complexity of Combinatory Categorial Grammar (CCG)", "start_pos": 13, "end_pos": 71, "type": "TASK", "confidence": 0.7505342496765984}]}, {"text": "As our main result, we prove that any parsing algorithm for this formalism will take in the worst case exponential time when the size of the grammar, and not only the length of the input sentence, is included in the analysis.", "labels": [], "entities": []}, {"text": "This sets the formalism of Vijay-Shanker and Weir (1994) apart from weakly equivalent formalisms such as Tree Adjoining Grammar, for which parsing can be performed in time polynomial in the combined size of grammar and input sentence.", "labels": [], "entities": [{"text": "Tree Adjoining Grammar", "start_pos": 105, "end_pos": 127, "type": "TASK", "confidence": 0.7031691471735636}]}, {"text": "Our results contribute to a refined understanding of the class of mildly context-sensitive grammars, and inform the search for new, mildly context-sensitive versions of CCG.", "labels": [], "entities": []}], "introductionContent": [{"text": "Combinatory Categorial Grammar (CCG; Steedman and Baldridge 2011) is a wellestablished grammatical framework that has supported a large amount of work both in linguistic analysis and natural language processing.", "labels": [], "entities": [{"text": "Combinatory Categorial Grammar (CCG; Steedman and Baldridge 2011)", "start_pos": 0, "end_pos": 65, "type": "TASK", "confidence": 0.7902204990386963}, {"text": "linguistic analysis", "start_pos": 159, "end_pos": 178, "type": "TASK", "confidence": 0.7320153117179871}, {"text": "natural language processing", "start_pos": 183, "end_pos": 210, "type": "TASK", "confidence": 0.6259074211120605}]}, {"text": "From the perspective of linguistics, the two most prominent features of CCG are its tight coupling of syntactic and semantic information, and its capability to compactly encode this information entirely within the lexicon.", "labels": [], "entities": []}, {"text": "Despite the strong lexicalization that characterizes CCG, it is able to handle non-local dependencies in a simple and effective way.", "labels": [], "entities": []}, {"text": "After the release of annotated data sets, there has been a surge of interest in CCG within statistical and, more recently, neural natural language processing.", "labels": [], "entities": [{"text": "neural natural language processing", "start_pos": 123, "end_pos": 157, "type": "TASK", "confidence": 0.6659716665744781}]}, {"text": "The wide range of applications for which CCG has been used includes data-driven syntactic parsing, natural language generation, machine translation (, and broad-coverage semantic parsing (.", "labels": [], "entities": [{"text": "data-driven syntactic parsing", "start_pos": 68, "end_pos": 97, "type": "TASK", "confidence": 0.6769454677899679}, {"text": "natural language generation", "start_pos": 99, "end_pos": 126, "type": "TASK", "confidence": 0.6703056295712789}, {"text": "machine translation", "start_pos": 128, "end_pos": 147, "type": "TASK", "confidence": 0.8473928868770599}, {"text": "broad-coverage semantic parsing", "start_pos": 155, "end_pos": 186, "type": "TASK", "confidence": 0.6486732165018717}]}, {"text": "In this article we study the parsing complexity of CCG.", "labels": [], "entities": [{"text": "parsing", "start_pos": 29, "end_pos": 36, "type": "TASK", "confidence": 0.9747301936149597}]}, {"text": "Our point of departure is the work of, who presented the first polynomial-time parsing algorithm for CCG.", "labels": [], "entities": []}, {"text": "The runtime complexity of this algorithm is in O(n 6 ), where n is the length of the input sentence.", "labels": [], "entities": [{"text": "O", "start_pos": 47, "end_pos": 48, "type": "METRIC", "confidence": 0.9412668943405151}]}, {"text": "This matches the runtime complexity of standard parsing algorithms for Tree Adjoining Grammar (TAG;, which fits nicely with the celebrated result that CCG and TAG are weakly equivalent (.", "labels": [], "entities": []}, {"text": "However, although the runtime of Vijay-Shanker and Weir's algorithm is polynomial in the length of the input sentence, it is exponential in the size of the grammar.", "labels": [], "entities": []}, {"text": "This is in contrast with the situation for TAG, where the runtime is (roughly) quadratic with respect to grammar size).", "labels": [], "entities": []}, {"text": "The only other polynomial-time parsing algorithms for CCG that we are aware of exhibit the same behavior.", "labels": [], "entities": []}, {"text": "ask whether parsing maybe inherently more complex for CCG than for TAG when grammar size is taken into account.", "labels": [], "entities": []}, {"text": "Our main technical result in this article is that the answer to this question is positive: We show that any parsing algorithm for CCG in the formalism considered by Vijay-Shanker and Weir will necessarily take in the worst case exponential time when the size of the grammar is included in the analysis.", "labels": [], "entities": []}, {"text": "Formally, we prove that the universal recognition problem for this formalism is EXPTIME-complete.", "labels": [], "entities": [{"text": "universal recognition", "start_pos": 28, "end_pos": 49, "type": "TASK", "confidence": 0.6730257421731949}]}, {"text": "The following paragraphs provide some context to this result.", "labels": [], "entities": []}, {"text": "The Mild Context-Sensitivity of Modern CCG.", "labels": [], "entities": [{"text": "Modern CCG", "start_pos": 32, "end_pos": 42, "type": "DATASET", "confidence": 0.6149914860725403}]}, {"text": "Our interest in the computational properties of CCG is motivated by our desire to better understand modern incarnations of this framework from a mathematical point of view.", "labels": [], "entities": []}, {"text": "Theoretical work on CCG has always emphasized the importance of keeping the computational and generative power of the grammar as low as possible (see, for instance, Steedman 2000, page 23, and Baldridge 2002, Section 2.5), and in doing so has followed the tradition of the so-called mildly context-sensitive theories of grammar.", "labels": [], "entities": []}, {"text": "The aforementioned polynomial-time parsing algorithm and the weak equivalence with TAG established the membership of CCG in this class of grammars even on a formal level.", "labels": [], "entities": [{"text": "TAG", "start_pos": 83, "end_pos": 86, "type": "METRIC", "confidence": 0.7769771814346313}]}, {"text": "However, recent work has drawn attention to the fact that the specific formalism for which these results were obtained, and which we will refer to as VW-CCG (after Vijay-Shanker and Weir), differs from contemporary versions of CCG in several important aspects.", "labels": [], "entities": [{"text": "VW-CCG", "start_pos": 150, "end_pos": 156, "type": "DATASET", "confidence": 0.9622393250465393}]}, {"text": "In particular, it allows one to restrict and even ban the use of combinatory rules on a per-grammar basis, whereas modern CCG postulates one universal set of rules, controlled by a fully lexicalized mechanism based on typed slashes, as in other approaches to categorial grammar (Baldridge 2002; Steedman and Baldridge 2011).", "labels": [], "entities": []}, {"text": "The difference is important because the weak equivalence result crucially depends on the availability of grammar-specific rule restrictions-without this feature, the generative power of VW-CCG is strictly smaller than that of TAG (.", "labels": [], "entities": [{"text": "VW-CCG", "start_pos": 186, "end_pos": 192, "type": "DATASET", "confidence": 0.9114277958869934}]}, {"text": "At the same time, modern CCG includes combinatory rules that are absent from VW-CCG, specifically substitution and type-raising, and there is the possibility that this can counterbalance the loss of generative power that comes with the lexicalization of the rule control mechanism.", "labels": [], "entities": [{"text": "VW-CCG", "start_pos": 77, "end_pos": 83, "type": "DATASET", "confidence": 0.926045298576355}]}, {"text": "Then again, these new rules are not supported by existing polynomial-time parsing algorithms.", "labels": [], "entities": []}, {"text": "Moreover, the weak equivalence proof uses another feature of VW-CCG that is not available in contemporary versions of CCG: the ability to assign lexicon entries to the empty string.", "labels": [], "entities": [{"text": "VW-CCG", "start_pos": 61, "end_pos": 67, "type": "DATASET", "confidence": 0.9733036160469055}]}, {"text": "Such \"empty categories\" are ruled out by one of the fundamental linguistic principles of CCG, the Principle of Adjacency, and it is far from obvious that the weak equivalence proof can be re-written without them.", "labels": [], "entities": []}, {"text": "In summary, the formalism of Vijay-Shanker and Weir is the only CCG formalism that has been proved to be weakly equivalent to TAG, 1 and the only one that has been shown to be parsable in polynomial time.", "labels": [], "entities": []}, {"text": "As such, it is arguably the only CCG formalism that has been shown to be mildly context-sensitive, which is why we consider it to be of continued interest from a mathematical point of view.", "labels": [], "entities": []}, {"text": "At the same time, we hope that the insights that we can obtain from the analysis of VW-CCG will eventually lead to the development of linguistically more adequate, provably mildly context-sensitive formalisms for CCG.", "labels": [], "entities": [{"text": "VW-CCG", "start_pos": 84, "end_pos": 90, "type": "DATASET", "confidence": 0.9582046270370483}]}, {"text": "The universal recognition problem fora class of grammars G is the problem defined as follows: Given as input a grammar G in G and a string w, decide whether w is in L(G), the language generated by G. The computational complexity of this problem is measured as a function of the combined size of G and w.", "labels": [], "entities": [{"text": "universal recognition", "start_pos": 4, "end_pos": 25, "type": "TASK", "confidence": 0.7416372001171112}]}, {"text": "The universal recognition problem should be contrasted with the membership problem for any specific grammar G in G, whose complexity is measured as a function solely of the length of w.", "labels": [], "entities": [{"text": "universal recognition", "start_pos": 4, "end_pos": 25, "type": "TASK", "confidence": 0.7616821229457855}]}, {"text": "The complexity of the universal recognition problem is generally higher than that of the membership problem.", "labels": [], "entities": [{"text": "universal recognition problem", "start_pos": 22, "end_pos": 51, "type": "TASK", "confidence": 0.8734845519065857}]}, {"text": "For instance, the universal recognition problem for context-free grammars is PTIME-complete (complete for decision problems solvable in deterministic polynomial time), whereas the membership problem for these grammars defines the class LOGCFL (decision problems reducible in logarithmic space to a context-free language), which is generally conjectured to be a proper subset of PTIME.", "labels": [], "entities": [{"text": "PTIME-complete", "start_pos": 77, "end_pos": 91, "type": "DATASET", "confidence": 0.6185304522514343}, {"text": "PTIME", "start_pos": 378, "end_pos": 383, "type": "DATASET", "confidence": 0.9572402238845825}]}, {"text": "The definitions of the universal recognition problem and the membership problem often generate some confusion.", "labels": [], "entities": [{"text": "universal recognition problem", "start_pos": 23, "end_pos": 52, "type": "TASK", "confidence": 0.8676116466522217}, {"text": "membership problem", "start_pos": 61, "end_pos": 79, "type": "TASK", "confidence": 0.92448291182518}]}, {"text": "For instance, in applications such as parsing or translation, we work with a fixed grammar, so it might seem that the universal recognition problem is of little practical relevance.", "labels": [], "entities": [{"text": "parsing or translation", "start_pos": 38, "end_pos": 60, "type": "TASK", "confidence": 0.6929148932298025}, {"text": "universal recognition", "start_pos": 118, "end_pos": 139, "type": "TASK", "confidence": 0.6733738034963608}]}, {"text": "However, it is worth remembering that for these applications, we are primarily interested in the structural descriptions that the grammar assigns to a generated sentence, not in the membership of the sentence per se.", "labels": [], "entities": []}, {"text": "Therefore, the universal recognition problem is a more accurate model of parsing than the membership problem, as the latter also admits decision procedures where the grammar is replaced with some other mechanism that may produce no or completely different descriptions than the ones we are interested in.", "labels": [], "entities": [{"text": "universal recognition", "start_pos": 15, "end_pos": 36, "type": "TASK", "confidence": 0.775822639465332}]}, {"text": "The universal recognition problem is also favored when the ambition is to characterize parsing time in terms of all relevant inputs-both the length of the input string and the size and structure of the grammar.", "labels": [], "entities": [{"text": "universal recognition", "start_pos": 4, "end_pos": 25, "type": "TASK", "confidence": 0.779160887002945}, {"text": "characterize parsing", "start_pos": 74, "end_pos": 94, "type": "TASK", "confidence": 0.8584168553352356}]}, {"text": "Such an analysis often reveals (and does so even in this article) how specific features of the grammar contribute to the complexity of the parsing task.", "labels": [], "entities": [{"text": "parsing task", "start_pos": 139, "end_pos": 151, "type": "TASK", "confidence": 0.912857860326767}]}, {"text": "More precisely, when investigating the universal recognition problem one expresses the computational complexity of parsing in terms of several parameters (other than the input string length), as for instance the number of nonterminals, maximum size of rules, or maximum length of unary derivations.", "labels": [], "entities": [{"text": "universal recognition", "start_pos": 39, "end_pos": 60, "type": "TASK", "confidence": 0.6824676394462585}]}, {"text": "This provides a much more finegrained picture than the one that we obtain when analyzing the membership problem, and discloses the effects that each individual feature of the grammar has on parsing.", "labels": [], "entities": []}, {"text": "The remainder of this article is structured as follows.", "labels": [], "entities": []}, {"text": "After presenting the VW-CCG formalism in Section 2, we first study in Section 3 the universal recognition problem fora restricted class of VW-CCG, where each category is \"lexicalized\" in the sense of the Principle of Adjacency.", "labels": [], "entities": [{"text": "universal recognition", "start_pos": 84, "end_pos": 105, "type": "TASK", "confidence": 0.6949262619018555}]}, {"text": "We show that for this subclass, universal recognition is NP-complete.", "labels": [], "entities": [{"text": "universal recognition", "start_pos": 32, "end_pos": 53, "type": "TASK", "confidence": 0.776061087846756}]}, {"text": "Under the assumption that PTIME = NP, this already implies our main result that parsing algorithms for VW-CCG will take in the worst case exponential time in the combined size of the grammar and the input string.", "labels": [], "entities": [{"text": "PTIME", "start_pos": 26, "end_pos": 31, "type": "METRIC", "confidence": 0.9590872526168823}, {"text": "VW-CCG", "start_pos": 103, "end_pos": 109, "type": "DATASET", "confidence": 0.9614928960800171}]}, {"text": "In Section 4 we analyze the general case and show that the universal recognition problem for unrestricted VW-CCG is EXPTIME-complete.", "labels": [], "entities": [{"text": "universal recognition", "start_pos": 59, "end_pos": 80, "type": "TASK", "confidence": 0.7019626200199127}, {"text": "VW-CCG", "start_pos": 106, "end_pos": 112, "type": "DATASET", "confidence": 0.862302303314209}]}, {"text": "This is a stronger result than the one in Section 3, as it does not rely on any assumptions.", "labels": [], "entities": []}, {"text": "However, we anticipate that many readers will be content with the result in Section 3, especially because the proofs of the more general result are considerably more complex.", "labels": [], "entities": []}, {"text": "Finally, Section 5 is devoted to a general discussion of our results, its ramifications, and its relevance for current research.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": []}