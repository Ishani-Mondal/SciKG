{"title": [{"text": "Weighted DAG Automata for Semantic Graphs under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International (CC BY-NC-ND 4.0) license", "labels": [], "entities": []}], "abstractContent": [{"text": "Graphs have a variety of uses in natural language processing, particularly as representations of linguistic meaning.", "labels": [], "entities": []}, {"text": "A deficit in this area of research is a formal framework for creating, combining, and using models involving graphs that parallels the frameworks of finite automata for strings and finite tree automata for trees.", "labels": [], "entities": []}, {"text": "A possible starting point for such a framework is the formalism of directed acyclic graph (DAG) automata, defined by Kamimura and Slutzki and extended by Quernheim and Knight.", "labels": [], "entities": []}, {"text": "In this article, we study the latter in depth, demonstrating several new results, including a practical recognition algorithm that can be used for inference and learning with models defined on DAG automata.", "labels": [], "entities": []}, {"text": "We also propose an extension to graphs with unbounded node degree and show that our results carryover to the extended formalism.", "labels": [], "entities": []}], "introductionContent": [{"text": "Statistical models of natural language semantics are making rapid progress.", "labels": [], "entities": [{"text": "natural language semantics", "start_pos": 22, "end_pos": 48, "type": "TASK", "confidence": 0.6670131882031759}]}, {"text": "At the risk of oversimplifying, work in this area can be divided into two streams.", "labels": [], "entities": []}, {"text": "One stream, semantic parsing, aims to map from sentences to logical forms that can be executed (for example, to query a knowledge base); work in this stream tends to be on small, narrow-domain data sets like GeoQuery.", "labels": [], "entities": [{"text": "semantic parsing", "start_pos": 12, "end_pos": 28, "type": "TASK", "confidence": 0.7416918575763702}]}, {"text": "The other stream aims for broader coverage, and historically tackled shallower, piecemeal tasks, like semantic role labeling (, word sense disambiguation (, coreference resolution, and soon.", "labels": [], "entities": [{"text": "semantic role labeling", "start_pos": 102, "end_pos": 124, "type": "TASK", "confidence": 0.6814903616905212}, {"text": "word sense disambiguation", "start_pos": 128, "end_pos": 153, "type": "TASK", "confidence": 0.6706969837347666}, {"text": "coreference resolution", "start_pos": 157, "end_pos": 179, "type": "TASK", "confidence": 0.9447216689586639}]}, {"text": "Correspondingly, resources like OntoNotes () provided separate resources for each of these tasks.", "labels": [], "entities": []}, {"text": "This piecemeal situation parallels that of early work on syntactic parsing, which focused on subtasks like part-of-speech tagging, noun-phrase chunking (, prepositional phrase attachment (, and soon.", "labels": [], "entities": [{"text": "syntactic parsing", "start_pos": 57, "end_pos": 74, "type": "TASK", "confidence": 0.8353619575500488}, {"text": "part-of-speech tagging", "start_pos": 107, "end_pos": 129, "type": "TASK", "confidence": 0.7333388924598694}, {"text": "noun-phrase chunking", "start_pos": 131, "end_pos": 151, "type": "TASK", "confidence": 0.7774829268455505}, {"text": "prepositional phrase attachment", "start_pos": 155, "end_pos": 186, "type": "TASK", "confidence": 0.6597710649172465}]}, {"text": "As the field matured, these tasks were increasingly synthesized into a single process.", "labels": [], "entities": []}, {"text": "This was made possible because of a single representation (phrase structure or dependency trees) that captures all of these phenomena; because of corpora annotated with these representations, like the Penn Treebank; and because of formalisms, like context-free grammars, which can model these representations practically).", "labels": [], "entities": [{"text": "Penn Treebank", "start_pos": 201, "end_pos": 214, "type": "DATASET", "confidence": 0.993959367275238}]}, {"text": "Ina similar way, more recent work in semantic processing consolidates various semantics-related tasks into one.", "labels": [], "entities": [{"text": "semantic processing", "start_pos": 37, "end_pos": 56, "type": "TASK", "confidence": 0.8551002144813538}]}, {"text": "For example, the Abstract Meaning Representation (AMR) Bank () began as an effort to unify the various annotation layers of OntoNotes.", "labels": [], "entities": [{"text": "Abstract Meaning Representation (AMR)", "start_pos": 17, "end_pos": 54, "type": "TASK", "confidence": 0.7563489427169164}]}, {"text": "It has driven the development of many systems, chiefly string-to-AMR parsers like JAMR () and CAMR (, as well as many other systems submitted to the AMR Parsing task at SemEvalr Path languages are regular, as is desirable fora formal model of AMRs (Section 4.1).", "labels": [], "entities": [{"text": "JAMR", "start_pos": 82, "end_pos": 86, "type": "DATASET", "confidence": 0.8170226216316223}, {"text": "AMR Parsing task at SemEvalr Path languages", "start_pos": 149, "end_pos": 192, "type": "TASK", "confidence": 0.7828543441636222}]}, {"text": "r The class of hyperedge-replacement languages is closed under intersection with languages recognized by DAG automata (Section 4.2).", "labels": [], "entities": []}, {"text": "r Emptiness is decidable in polynomial time).", "labels": [], "entities": [{"text": "Emptiness", "start_pos": 2, "end_pos": 11, "type": "METRIC", "confidence": 0.9951862692832947}]}, {"text": "We then turn to the recognition problem for our formalism, and show the following: r The recognition problem is NP-complete even for fixed automata (Section 5.1).", "labels": [], "entities": []}, {"text": "r For input graphs of bounded treewidth, there is an efficient algorithm for recognition or summing over computations of an automaton for an input graph (Section 5.2).", "labels": [], "entities": [{"text": "summing over computations", "start_pos": 92, "end_pos": 117, "type": "TASK", "confidence": 0.7606726090113322}]}, {"text": "r The recognition/summation algorithm can be asymptotically improved using specialized binarization techniques (Section 6).", "labels": [], "entities": [{"text": "recognition/summation", "start_pos": 6, "end_pos": 27, "type": "TASK", "confidence": 0.7877092957496643}]}, {"text": "We expect that nodes of potentially unbounded degree will be important in natural language processing to handle phenomena such as coreference and optional modifiers.", "labels": [], "entities": []}, {"text": "We show how to extend our formalism to handle nodes of unbounded degree, and demonstrate the following additional results: r All closure and decidability properties mentioned above continue to hold for the extended model, and the path languages stay regular (Section 7.3).", "labels": [], "entities": []}, {"text": "r We provide a practical recognition/summation algorithm for the novel model (Section 7.4).", "labels": [], "entities": [{"text": "recognition/summation", "start_pos": 25, "end_pos": 46, "type": "TASK", "confidence": 0.7404034932454427}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 1  Statistics on AMR graphs, out of 20,628 total. original = as provided in the corpus; reversed =  with all edge labels of the form *-of reversed; reified = with certain roles reified as needed to  break cycles. A graph with no edges is counted as having zero treewidth.", "labels": [], "entities": [{"text": "AMR graphs", "start_pos": 24, "end_pos": 34, "type": "TASK", "confidence": 0.670807272195816}]}]}