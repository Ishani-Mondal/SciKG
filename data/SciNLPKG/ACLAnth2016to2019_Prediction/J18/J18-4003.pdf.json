{"title": [{"text": "Reproducibility in Computational Linguistics: Are We Willing to Share? under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International (CC BY-NC-ND 4.0) license", "labels": [], "entities": []}], "abstractContent": [{"text": "This study focuses on an essential precondition for reproducibility in computational linguistics: the willingness of authors to share relevant source code and data.", "labels": [], "entities": []}, {"text": "Ten years after Ted Pedersen's influential \"Last Words\" contribution in Computational Linguistics, we investigate to what extent researchers in computational linguistics are willing and able to share their data and code.", "labels": [], "entities": [{"text": "Last Words\" contribution in Computational Linguistics", "start_pos": 44, "end_pos": 97, "type": "TASK", "confidence": 0.5397177168301174}]}, {"text": "We surveyed all 395 full papers presented at the 2011 and 2016 ACL Annual Meetings, and identified whether links to data and code were provided.", "labels": [], "entities": [{"text": "ACL Annual Meetings", "start_pos": 63, "end_pos": 82, "type": "DATASET", "confidence": 0.7701538801193237}]}, {"text": "If working links were not provided, authors were requested to provide this information.", "labels": [], "entities": []}, {"text": "Although data were often available, code was shared less often.", "labels": [], "entities": []}, {"text": "When working links to code or data were not provided in the paper, authors provided the code in about one third of cases.", "labels": [], "entities": []}, {"text": "For a selection often papers, we attempted to reproduce the results using the provided data and code.", "labels": [], "entities": []}, {"text": "We were able to reproduce the results approximately for six papers.", "labels": [], "entities": []}, {"text": "For only a single paper did we obtain the exact same results.", "labels": [], "entities": []}, {"text": "Our findings show that even though the situation appears to have improved comparing 2016 to 2011, empiricism in computational linguistics still largely remains a matter of faith.", "labels": [], "entities": []}, {"text": "Nevertheless, we are somewhat optimistic about the future.", "labels": [], "entities": []}, {"text": "Ensuring reproducibility is not only important for the field as a whole, but also seems worthwhile for individual researchers: The median citation count for studies with working links to the source code is higher.", "labels": [], "entities": [{"text": "citation count", "start_pos": 138, "end_pos": 152, "type": "METRIC", "confidence": 0.9273093938827515}]}], "introductionContent": [{"text": "Reproducibility 1 of experimental research results has become an important topic in the scientific debate across many disciplines.", "labels": [], "entities": [{"text": "Reproducibility 1 of experimental research", "start_pos": 0, "end_pos": 42, "type": "TASK", "confidence": 0.9116613864898682}]}, {"text": "There now even is a Wikipedia page on the topic entitled \"Replication Crisis,\" 2 with a description of some of the most worrying results and links to the relevant studies.", "labels": [], "entities": [{"text": "Replication Crisis", "start_pos": 58, "end_pos": 76, "type": "TASK", "confidence": 0.9888572692871094}]}, {"text": "Ina survey conducted by Nature in 2016, more than half of over 1,500 participating scientists claim that there is a \"significant reproducibility crisis.\"", "labels": [], "entities": []}, {"text": "For computational linguistics, one might initially be optimistic about reproducibility, given that we mostly work with relatively \"static\" data sets and computer programs-rather than, for instance, with human participants or chemical substances.", "labels": [], "entities": [{"text": "computational linguistics", "start_pos": 4, "end_pos": 29, "type": "TASK", "confidence": 0.7637081146240234}]}, {"text": "points out in a very recognizable \"Last Words\" contribution in Computational Linguistics that it is often impossible to obtain the relevent data and software.", "labels": [], "entities": [{"text": "Computational Linguistics", "start_pos": 63, "end_pos": 88, "type": "TASK", "confidence": 0.7098981738090515}]}, {"text": "Our study, ten years later, investigates whether this basic prerequisite for reproducibility is now in a better state.", "labels": [], "entities": []}, {"text": "Reproducing the outcome of an experiment is often difficult because there are many details that influence the outcome, and more often than not those details are not properly documented.", "labels": [], "entities": [{"text": "Reproducing the outcome of an experiment", "start_pos": 0, "end_pos": 40, "type": "TASK", "confidence": 0.8018629948298136}]}, {"text": "Observations about reproducibility difficulties have been made frequently in the past., for instance, attempted to reproduce the parsing results of Collins (1999) but initially did not obtain nearly the same results.", "labels": [], "entities": [{"text": "parsing", "start_pos": 129, "end_pos": 136, "type": "TASK", "confidence": 0.9652950763702393}]}, {"text": "Bikel then continued to show that implementing Collins' model using only the published details caused an 11% increase in relative error over Collins' own published results.", "labels": [], "entities": [{"text": "error", "start_pos": 130, "end_pos": 135, "type": "METRIC", "confidence": 0.5111499428749084}]}, {"text": "report on two failed reproduction efforts.", "labels": [], "entities": []}, {"text": "Their results indicate that even if data and code are available, reproduction is far from trivial, and they provide a careful analysis of why reproduction is difficult.", "labels": [], "entities": []}, {"text": "They show that many details (including pre-processing, the experimental set-up, versioning, system output, and system variations) are important in reproducing the exact results of published research.", "labels": [], "entities": []}, {"text": "In most cases, such details are not documented in the publication, nor elsewhere.", "labels": [], "entities": []}, {"text": "Their results are the more striking because one of the co-authors of that study was the original author of the paper documenting the experiments that the authors set out to reproduce.", "labels": [], "entities": []}, {"text": "It is clear, therefore, that in computational linguistics reproducibility cannot betaken for granted either-as is also illustrated by recent initiatives, such as the IJCAI workshop on replicability and reproduciblity in NLP in 2015, the set-up of a dedicated LREC workshop series \"4Real\" with workshops in 2016 and 2018, and the introduction of a special section of Language Resources and Evaluation (.", "labels": [], "entities": []}, {"text": "Our study extends the study of Mieskes (2017).", "labels": [], "entities": []}, {"text": "She investigated how often studies published at various computational linguistics conferences provided a link to the data.", "labels": [], "entities": []}, {"text": "She found that about 40% of the papers collected new data or changed existing data.", "labels": [], "entities": []}, {"text": "Only in about 65% of these papers was a link to the data provided.", "labels": [], "entities": []}, {"text": "A total of 18% of these links did not appear to work.", "labels": [], "entities": []}, {"text": "In our study, we focus on another essential precondition for reproduction, namely, the availability of the underlying source code.", "labels": [], "entities": []}, {"text": "We evaluate how often data and source code are shared.", "labels": [], "entities": []}, {"text": "We did not only followup on links given in the papers, but we contacted authors of papers by e-mail with requests for their data and code as well.", "labels": [], "entities": []}, {"text": "In addition, we investigate to what extent we are able to reproduce results often studies for which we were able to obtain the relevant data and software.", "labels": [], "entities": []}, {"text": "Our study is related to the study of, who investigated the frequency with which they could obtain the source code and data for publications in ACM conferences and journals, and whether the received code could be compiled.", "labels": [], "entities": []}, {"text": "They found that only in about one third of the cases were they able to obtain and build the code without any special effort.", "labels": [], "entities": []}, {"text": "Importantly, we also evaluate (a rough indication of) the impact of each study via the citation counts of each study.", "labels": [], "entities": []}, {"text": "Specifically, we assess whether there are observable differences in impact when comparing papers whose authors share their code directly (i.e., via a link in the paper) versus those that do not.", "labels": [], "entities": []}, {"text": "Because we establish that papers that provide links to the code are typically somewhat more often cited than papers that do not, we hope to provide researchers in computational linguistics with additional motivation to make their source code available.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1  Distribution of data and code availability in both 2011 and 2016.", "labels": [], "entities": []}]}