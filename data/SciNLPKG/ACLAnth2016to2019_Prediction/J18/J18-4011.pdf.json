{"title": [{"text": "Combining Deep Learning and Argumentative Reasoning for the Analysis of Social Media Textual Content Using Small Data Sets", "labels": [], "entities": [{"text": "Analysis of Social Media Textual Content", "start_pos": 60, "end_pos": 100, "type": "TASK", "confidence": 0.7677568892637888}]}], "abstractContent": [{"text": "The use of social media has become a regular habit for many and has changed the way people interact with each other.", "labels": [], "entities": []}, {"text": "In this article, we focus on analyzing whether news headlines support tweets and whether reviews are deceptive by analyzing the interaction or the influence that these texts have on the others, thus exploiting contextual information.", "labels": [], "entities": []}, {"text": "Concretely, we define a deep learning method for relation-based argument mining to extract argumentative relations of attack and support.", "labels": [], "entities": [{"text": "relation-based argument mining", "start_pos": 49, "end_pos": 79, "type": "TASK", "confidence": 0.6233169039090475}]}, {"text": "We then use this method for determining whether news articles support tweets, a useful task in fact-checking settings, where determining agreement toward a statement is a useful step toward determining its truthfulness.", "labels": [], "entities": []}, {"text": "Furthermore, we use our method for extracting bipolar argumentation frameworks from reviews to help detect whether they are deceptive.", "labels": [], "entities": []}, {"text": "We show experimentally that our method performs well in both settings.", "labels": [], "entities": []}, {"text": "In particular, in the case of deception detection, our method contributes a novel argumentative feature that, when used in combination with other features in standard supervised classifiers, outperforms the latter even on small data sets.", "labels": [], "entities": [{"text": "deception detection", "start_pos": 30, "end_pos": 49, "type": "TASK", "confidence": 0.9306570291519165}]}], "introductionContent": [{"text": "The use of social media has become a regular habit for many and has changed the way people interact with each other.", "labels": [], "entities": []}, {"text": "In this article, we focus on analyzing whether news headlines support tweets and whether reviews are deceptive by analyzing the interaction or the influence that these texts have on the others, thus exploiting contextual information.", "labels": [], "entities": []}, {"text": "The recent success of deep learning has led to a widespread use of deep neural networks in a number of domains, from natural language understanding to computer vision, that typically require very large data sets).", "labels": [], "entities": [{"text": "natural language understanding", "start_pos": 117, "end_pos": 147, "type": "TASK", "confidence": 0.6989942987759908}]}, {"text": "In this article, we propose a deep learning method to extract relations of attack and support between chunks of text, as required to construct bipolar argumentation frameworks (BAFs), and show how it can be deployed effectively also with small data sets.", "labels": [], "entities": []}, {"text": "BAFs can be seen as graphs with arguments as nodes and two types of directed edges between nodes, representing attack and support between the arguments.", "labels": [], "entities": []}, {"text": "An example of a BAF is given in.", "labels": [], "entities": [{"text": "BAF", "start_pos": 16, "end_pos": 19, "type": "METRIC", "confidence": 0.7518703937530518}]}, {"text": "Mining attack and support from natural language texts is the main task in relation-based argument mining (RbAM), which amounts to identifying arguments in text as well as dialectical relations between these arguments).", "labels": [], "entities": [{"text": "relation-based argument mining (RbAM)", "start_pos": 74, "end_pos": 111, "type": "TASK", "confidence": 0.7786331673463186}]}, {"text": "We define a deep learning architecture based on a long-short term memory (LSTM) model to determine relations of attack, support, and neither attack nor support between any two pieces of text.", "labels": [], "entities": []}, {"text": "Within our deep network architecture, each input text is fed into a LSTM model, which produces a vector representation of the text being analyzed.", "labels": [], "entities": []}, {"text": "The two vectors are then merged using various techniques and the resulting vector is finally fed into a softmax classifier, which predicts the label for the relation between the two texts.", "labels": [], "entities": []}, {"text": "We achieve 89.53% accuracy using LSTMs and concatenation as the merge layer, considerably outperforming the results with feature-based supervised classifiers reported in the study that introduced the corpus used in this article.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 18, "end_pos": 26, "type": "METRIC", "confidence": 0.9991395473480225}]}, {"text": "We then test our best-performing deep learning model on different data sets consisting of news article headlines to determine whether these support tweets, and show that our model generalizes well.", "labels": [], "entities": []}, {"text": "We use two data sets introduced in: one consisting of pairs of tweets-headlines related to the FBI's investigative involvement in Hillary Clinton's e-mail leak and the second one adapted from.", "labels": [], "entities": []}, {"text": "For example, consider the following: Our model can predict that the headline supports the tweet.", "labels": [], "entities": []}, {"text": "Making these predictions can be a useful task in fact-checking settings, particularly for testing whether tweets are backed by any information.", "labels": [], "entities": []}, {"text": "Indeed, the Fake News Challenge 2 indicates that determining agreement toward a statement is a useful step toward determining its truthfulness.) and restaurant (see).", "labels": [], "entities": [{"text": "Fake News Challenge", "start_pos": 12, "end_pos": 31, "type": "DATASET", "confidence": 0.6101279854774475}]}, {"text": "We show that deep learning, combined with argumentative reasoning, improves on the task of determining whether a review is truthful or deceptive and is also able to handle the small data set issue.", "labels": [], "entities": []}, {"text": "Albeit small, the improvements show promise in the integration of deep learning and symbolic, argumentative reasoning.", "labels": [], "entities": []}, {"text": "The remainder of this article is organized as follows.", "labels": [], "entities": []}, {"text": "In Section 2, we discuss related work.", "labels": [], "entities": []}, {"text": "In Section 3, we review relevant background information in LSTM models and argumentation and give an overview of the data sets used in this article.", "labels": [], "entities": []}, {"text": "In Section 4, we describe our deep learning architecture.", "labels": [], "entities": []}, {"text": "We report the performance of our deep learning model in identifying the support relation between headlines of news articles and tweets in Section 5.", "labels": [], "entities": [{"text": "Section 5", "start_pos": 138, "end_pos": 147, "type": "DATASET", "confidence": 0.9187040328979492}]}, {"text": "In Section 6, we describe our approach to extracting arguments from reviews and building BAFs, and define the argumentative features drawn from these frameworks.", "labels": [], "entities": [{"text": "extracting arguments from reviews and building BAFs", "start_pos": 42, "end_pos": 93, "type": "TASK", "confidence": 0.5859806452478681}]}, {"text": "We also report results when using these argumentative features in determining whether reviews are deceptive.", "labels": [], "entities": []}, {"text": "In Section 7, we show how deep learning and argumentative reasoning can handle the case of small data sets in our domain of interest.", "labels": [], "entities": [{"text": "argumentative reasoning", "start_pos": 44, "end_pos": 67, "type": "TASK", "confidence": 0.780372679233551}]}, {"text": "We conclude the article and propose directions for future work in Section 8.", "labels": [], "entities": []}], "datasetContent": [{"text": "We report the classification results on the task of determining whether a review is truthful or false on two domains, hotel and restaurant.", "labels": [], "entities": []}, {"text": "We evaluate the performance of various techniques of extracting topics from reviews as presented in Section 6.1.2 and the impact our novel argumentative features have on the classifier's performance.", "labels": [], "entities": []}, {"text": "All the results are obtained using 5-fold cross-validation and an ensemble method, RFs (Breiman 2001), with 10 trees in the forest, Gini impurity criterion, and the minimum number of samples required to split an internal node set to 2.", "labels": [], "entities": [{"text": "RFs", "start_pos": 83, "end_pos": 86, "type": "METRIC", "confidence": 0.9604160785675049}]}, {"text": "As a baseline, we extract features used previously in studies of deception (see Section 2.2).", "labels": [], "entities": []}, {"text": "These features are the result of part-of-speech (POS) tag analysis using nltk and are summarized in.", "labels": [], "entities": [{"text": "part-of-speech (POS) tag analysis", "start_pos": 33, "end_pos": 66, "type": "TASK", "confidence": 0.6657236516475677}]}, {"text": "Additionally, we include tf-idf features obtained from all reviews using scikit-learn ().", "labels": [], "entities": []}, {"text": "To calculate these, we use the lemmas obtained by analyzing the lowercase form of words and their POS tag.", "labels": [], "entities": []}, {"text": "We present results of different approaches of constructing BAFs from reviews and hence including the argumentative features related to the impact each review has on the \"goodness\" of the item (hotel or restaurant) being reviewed (see Section 6.2 on how these features are computed).", "labels": [], "entities": []}, {"text": "We experimented with two techniques for topic modeling, LDA and NMF (hence having features representing the impact of each review on the \"goodness\" of the item being reviewed for each of these methods, respectively).", "labels": [], "entities": [{"text": "topic modeling", "start_pos": 40, "end_pos": 54, "type": "TASK", "confidence": 0.7303293645381927}]}, {"text": "For each approach of topic modeling, we identify the topic that has the highest probability of being associated with the review, as well as all the topics with probability greater than 0.2 of being associated with the review.", "labels": [], "entities": [{"text": "topic modeling", "start_pos": 21, "end_pos": 35, "type": "TASK", "confidence": 0.7343428432941437}]}, {"text": "In both cases, we extract the sentences that contain any of the top words related to the topics that have been associated with the review.", "labels": [], "entities": []}, {"text": "To identify the relations between arguments associated with each topic, we chose the best performing instance of our deep neural architecture trained on the full RbAM data set.", "labels": [], "entities": [{"text": "RbAM data set", "start_pos": 162, "end_pos": 175, "type": "DATASET", "confidence": 0.946432630221049}]}, {"text": "We also report results when using the topic-noun approach and a RF classifier with features shown in.", "labels": [], "entities": []}, {"text": "For each method of constructing the BAF, we create anew argumentative feature from computing the difference between the strength of arguments from all reviews and the strength of the arguments from all reviews except the one whose impact we aim at determining.", "labels": [], "entities": [{"text": "BAF", "start_pos": 36, "end_pos": 39, "type": "TASK", "confidence": 0.3497096598148346}]}, {"text": "The classifiers' performances on the hotel data set are shown in.", "labels": [], "entities": [{"text": "hotel data set", "start_pos": 37, "end_pos": 51, "type": "DATASET", "confidence": 0.8599497079849243}]}, {"text": "We see that adding the tf-idf features gives 76% accuracy, resulting in a dramatic improvement of 12% compared with the baseline, where the syntactic features from were used.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 49, "end_pos": 57, "type": "METRIC", "confidence": 0.9995349645614624}]}, {"text": "Using argumentative features extracted from the BAF constructed from topics being associated with nouns in reviews and using RFs for RbAM yields lower results compared to using syntactic features and tf-idf features, achieving 74.88% accuracy.", "labels": [], "entities": [{"text": "BAF constructed from topics being associated with nouns in reviews", "start_pos": 48, "end_pos": 114, "type": "TASK", "confidence": 0.5776793986558915}, {"text": "accuracy", "start_pos": 234, "end_pos": 242, "type": "METRIC", "confidence": 0.9980966448783875}]}, {"text": "Using argumentative features extracted from the BAF constructed using LDA and NMF for topic modeling and LSTMs for RbAM yields better results than using a standard classifier (RFs) and a simple topic extraction method (nouns \u223c topics) with accuracy 76.38%.", "labels": [], "entities": [{"text": "topic modeling", "start_pos": 86, "end_pos": 100, "type": "TASK", "confidence": 0.7483310997486115}, {"text": "topic extraction", "start_pos": 194, "end_pos": 210, "type": "TASK", "confidence": 0.697626069188118}, {"text": "accuracy", "start_pos": 240, "end_pos": 248, "type": "METRIC", "confidence": 0.9990935325622559}]}, {"text": "Indeed, the best results are obtained using more advanced techniques for topic modeling rather than simple associations of topics \u223c nouns, and LSTMs for RbAM, with 0.38% improvement compared with using syntactic features and tf-idf features.", "labels": [], "entities": [{"text": "topic modeling", "start_pos": 73, "end_pos": 87, "type": "TASK", "confidence": 0.8063561618328094}, {"text": "RbAM", "start_pos": 153, "end_pos": 157, "type": "DATASET", "confidence": 0.6620501279830933}]}, {"text": "The classifiers' performance on the restaurant data set are shown in.", "labels": [], "entities": [{"text": "restaurant data set", "start_pos": 36, "end_pos": 55, "type": "DATASET", "confidence": 0.8169275124867758}]}, {"text": "Here as well, we see that adding the tf-idf features results in a dramatic improvement of 9% compared with the baseline.", "labels": [], "entities": []}, {"text": "In contrast to the hotel data set, using argumentative features extracted from the BAF constructed from topics being associated with nouns in reviews and using RFs for RbAM results in an improvement of 1.5% compared with using only syntactic features.", "labels": [], "entities": [{"text": "hotel data set", "start_pos": 19, "end_pos": 33, "type": "DATASET", "confidence": 0.8281880815823873}]}, {"text": "Using argumentative features extracted from the BAF constructed using LDA and NMF for topic modeling and LSTMs for RbAM also gives better results than using a standard classifier (RFs) and a simple topic extraction method (nouns \u223c topics) with accuracy 72.5%.", "labels": [], "entities": [{"text": "topic modeling", "start_pos": 86, "end_pos": 100, "type": "TASK", "confidence": 0.7469574511051178}, {"text": "RbAM", "start_pos": 115, "end_pos": 119, "type": "DATASET", "confidence": 0.7487009763717651}, {"text": "topic extraction", "start_pos": 198, "end_pos": 214, "type": "TASK", "confidence": 0.6954983323812485}, {"text": "accuracy", "start_pos": 244, "end_pos": 252, "type": "METRIC", "confidence": 0.998569130897522}]}, {"text": "Here again, the best results are obtained using more advanced techniques for topic modeling and LSTMs for RbAM, with 2.75% improvement compared with using syntactic features and tf-idf features.", "labels": [], "entities": [{"text": "topic modeling", "start_pos": 77, "end_pos": 91, "type": "TASK", "confidence": 0.777108371257782}]}, {"text": "We showed that combining deep learning and argumentative reasoning outperforms standard machine learning techniques for deception detection in both domains, hotel and restaurant.", "labels": [], "entities": [{"text": "deception detection", "start_pos": 120, "end_pos": 139, "type": "TASK", "confidence": 0.9449260830879211}]}, {"text": "The results are encouraging and show that argumentative reasoning can indeed be used to improve classifications.", "labels": [], "entities": []}, {"text": "We did not carryout any direct comparison with the results documented in the papers that introduced the reviews data sets we used (), as the tasks we focused on were different from the ones in the original papers.", "labels": [], "entities": []}, {"text": "Concretely, Ott et al.", "labels": [], "entities": []}, {"text": "(2011) experiment with a subset of the hotel data set used in this article, whereas Ott, Cardie, and Hancock (2013) focus on classifier performances on the hotel reviews data set based on the sentiment of the reviews (i.e., positive deceptive opinions and negative deceptive opinions).", "labels": [], "entities": [{"text": "hotel data set", "start_pos": 39, "end_pos": 53, "type": "DATASET", "confidence": 0.8069341778755188}, {"text": "hotel reviews data set", "start_pos": 156, "end_pos": 178, "type": "DATASET", "confidence": 0.8011969178915024}]}, {"text": "Furthermore, focus on classifier performances in cross-domain adaptation and on performances on intra-domain multiclass classification tasks, with the aim of classifying reviews based on their source (reviews written by customers, employees, Turkers).", "labels": [], "entities": [{"text": "cross-domain adaptation", "start_pos": 49, "end_pos": 72, "type": "TASK", "confidence": 0.756976842880249}]}], "tableCaptions": [{"text": " Table 1  Hyperparameters for our LSTM and BiLSTM models.", "labels": [], "entities": []}, {"text": " Table 5  Performance of our model on the tweet data sets.", "labels": [], "entities": [{"text": "tweet data sets", "start_pos": 42, "end_pos": 57, "type": "DATASET", "confidence": 0.8332662979761759}]}, {"text": " Table 8  Classifier performance on the hotel data set.", "labels": [], "entities": [{"text": "hotel data set", "start_pos": 40, "end_pos": 54, "type": "DATASET", "confidence": 0.8682554165522257}]}, {"text": " Table 9  Classifier performance on the restaurant data set.", "labels": [], "entities": [{"text": "restaurant data set", "start_pos": 40, "end_pos": 59, "type": "DATASET", "confidence": 0.8206828236579895}]}, {"text": " Table 10  Classifier performance on the hotel data set using subsets of the data set.", "labels": [], "entities": [{"text": "hotel data set", "start_pos": 41, "end_pos": 55, "type": "DATASET", "confidence": 0.8503479361534119}]}]}