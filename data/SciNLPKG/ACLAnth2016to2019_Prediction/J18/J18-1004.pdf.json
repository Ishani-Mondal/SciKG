{"title": [{"text": "Cache Transition Systems for Graph Parsing", "labels": [], "entities": [{"text": "Graph Parsing", "start_pos": 29, "end_pos": 42, "type": "TASK", "confidence": 0.7514331340789795}]}], "abstractContent": [{"text": "Motivated by the task of semantic parsing, we describe a transition system that generalizes standard transition-based dependency parsing techniques to generate a graph rather than a tree.", "labels": [], "entities": [{"text": "semantic parsing", "start_pos": 25, "end_pos": 41, "type": "TASK", "confidence": 0.7344754487276077}, {"text": "transition-based dependency parsing", "start_pos": 101, "end_pos": 136, "type": "TASK", "confidence": 0.7315166393915812}]}, {"text": "Our system includes a cache with fixed size m, and we characterize the relationship between the parameter m and the class of graphs that can be produced through the graph-theoretic concept of tree decomposition.", "labels": [], "entities": []}, {"text": "We find empirically that small cache sizes cover a high percentage of sentences in existing semantic corpora.", "labels": [], "entities": []}], "introductionContent": [{"text": "As statistical natural language processing systems have progressed to provide deeper representations, there has been renewed interest in graph-based representations of semantic structures and in algorithms to produce them.", "labels": [], "entities": []}, {"text": "Typically, these algorithms behave similarly to standard parsing algorithms for retrieving syntactic representations: They take as input a sentence and produce as output a graph representation of the semantics of the sentence itself.", "labels": [], "entities": []}, {"text": "At the same time, recent years have seen a general trend from chart-based syntactic parsers toward stack-based transition systems, as the accuracy of transition systems has increased, and as speed has become increasingly important for real-world applications.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 138, "end_pos": 146, "type": "METRIC", "confidence": 0.9988740086555481}]}, {"text": "On the syntactic side, stack-based transition systems for projective dependency parsing run in time O(n), where n is the sentence length; fora general overview of these systems, see, for instance, the presentation of.", "labels": [], "entities": [{"text": "projective dependency parsing", "start_pos": 58, "end_pos": 87, "type": "TASK", "confidence": 0.6743442614873251}]}, {"text": "There have also been a number of extensions of stack-based transition systems to handle non-projective trees (e.g.,.", "labels": [], "entities": []}, {"text": "Stack-based transition systems can produce general graphs rather than trees.", "labels": [], "entities": []}, {"text": "Perhaps the simplest way to generate graphs is to shift one word at a time onto the stack, and then consider building all possible arcs between each word on the stack and the next word in the buffer.", "labels": [], "entities": []}, {"text": "This is essentially the algorithm of, generalized to produce graphs rather than non-projective trees.", "labels": [], "entities": []}, {"text": "This algorithm was also cast as a stack-based transition system by.", "labels": [], "entities": []}, {"text": "The algorithm runs in time O(n 2 ), and requires the system to discriminate the arcs to be built from a large set of possibilities, potentially leading to errors.", "labels": [], "entities": []}, {"text": "Traditional stack-based parsing, which is restricted to trees, and the Covington algorithm as generalized to graph parsing can bethought of as two extremes, with a wide set of possible intermediate approaches staking out different trade-offs between expressiveness, on the one hand, and time and the discrimination required of machine learning components on the other.", "labels": [], "entities": [{"text": "stack-based parsing", "start_pos": 12, "end_pos": 31, "type": "TASK", "confidence": 0.5522845983505249}, {"text": "graph parsing", "start_pos": 109, "end_pos": 122, "type": "TASK", "confidence": 0.7882095575332642}]}, {"text": "In this article, we mathematically explore this tradeoff and precisely characterize the relationship between parsing systems and the set of graphs they can build.", "labels": [], "entities": []}, {"text": "We describe a parsing system based on adding a working set, which we refer to as a cache, to the traditional stack and buffer.", "labels": [], "entities": []}, {"text": "With cache size 2, our algorithm can only build trees, while with unbounded cache, our algorithm can build any graph, because it is then equivalent to the Covington algorithm generalized to graphs.", "labels": [], "entities": []}, {"text": "We speculate that small, fixed cache sizes provide a good trade-off for fast and accurate string-to-graph parsing.", "labels": [], "entities": []}, {"text": "We analyze the class of graphs that can be successfully constructed by our parsing system, making use of the graph-theoretic notion of treewidth.", "labels": [], "entities": []}, {"text": "The treewidth of a graph gives a measure of how tightly interconnected it is: Trees have treewidth 1, and fully connected graphs on n vertices have treewidth n \u2212 1.", "labels": [], "entities": []}, {"text": "We show that the class of graphs constructed by our parser is precisely characterized by treewidth: A transition system of cache size m can produce graphs of treewidth m \u2212 1.", "labels": [], "entities": []}, {"text": "Our framework assumes an input order of vertices, corresponding to the word order of the string, and we define a concept of relative treewidth to characterize the set of graphs that the parser can produce given a fixed input order of vertices.", "labels": [], "entities": []}, {"text": "Finally, we develop an oracle algorithm for our parsing system, and prove its correctness.", "labels": [], "entities": [{"text": "parsing", "start_pos": 48, "end_pos": 55, "type": "TASK", "confidence": 0.9634506702423096}]}, {"text": "We also provide an algorithm for computing the minimal cache size needed to parse a given data set.", "labels": [], "entities": []}, {"text": "In general, a graph's relative treewidth with respect to an input order maybe much higher than its absolute treewidth.", "labels": [], "entities": []}, {"text": "However, if relative treewidth with respect to the real English word order is low, and not significantly higher than the absolute treewidth, this indicates that the word order provides valuable information about the graph structure to be predicted, and that efficient parsing is possible by making use of this information.", "labels": [], "entities": []}, {"text": "We test this hypothesis with experiments on Abstract Meaning Representation (), a semantic formalism where the meaning of a sentence is encoded as a directed graph.", "labels": [], "entities": [{"text": "Abstract Meaning Representation", "start_pos": 44, "end_pos": 75, "type": "TASK", "confidence": 0.6688491106033325}]}, {"text": "We find that, for English sentences, these structures have low relative treewidth with respect to the English word order, and can thus be parsed efficiently using a transition-based parser with small cache size.", "labels": [], "entities": []}, {"text": "In order to compare across a wider variety of the semantic representations that have been 86 proposed (, we also experiment with three sets of semantic dependencies from the Semeval 2015 semantic dependency parsing task ().", "labels": [], "entities": [{"text": "Semeval 2015 semantic dependency parsing task", "start_pos": 174, "end_pos": 219, "type": "TASK", "confidence": 0.6267253359158834}]}, {"text": "With these data sets, which are generally closer to the surface string structure than Abstract Meaning Representation, we find somewhat higher relative treewidth.", "labels": [], "entities": [{"text": "Abstract Meaning Representation", "start_pos": 86, "end_pos": 117, "type": "TASK", "confidence": 0.5805952747662863}]}, {"text": "In every data set that we analyzed, over 99% of sentences can be covered with a cache size of eight.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section we consider several families of graph-based representations of semantic structures for natural language that are commonly used nowadays.", "labels": [], "entities": []}, {"text": "We run experiments on graph data sets for these representations, with the aim to assess the coverage that our cache parser provides with different cache sizes.", "labels": [], "entities": []}, {"text": "We first evaluate our algorithm on Abstract Meaning Representation (AMR) ().", "labels": [], "entities": [{"text": "Abstract Meaning Representation (AMR)", "start_pos": 35, "end_pos": 72, "type": "TASK", "confidence": 0.8395913739999136}]}, {"text": "AMR is a semantic formalism where the meaning of a sentence is encoded as a rooted, directed graph.", "labels": [], "entities": []}, {"text": "shows an example of an AMR graph in which the nodes represent the AMR concepts and the edges represent the relations between the concepts they connect.", "labels": [], "entities": []}, {"text": "AMR concepts consist of predicate senses, named entity annotations, and in some cases, simply lemmas of English words.", "labels": [], "entities": []}, {"text": "AMR relations consist of core semantic roles drawn from the Propbank (Palmer, Gildea, and Kingsbury 2005) as well as very fine-grained semantic relations defined specifically for AMR.", "labels": [], "entities": [{"text": "Propbank", "start_pos": 60, "end_pos": 68, "type": "DATASET", "confidence": 0.9465780854225159}]}, {"text": "We use the training set of LDC2015E86 for SemEval 2016 task 8 on meaning representation parsing (May 2016), which contains 16,833 sentences.", "labels": [], "entities": [{"text": "SemEval 2016 task 8", "start_pos": 42, "end_pos": 61, "type": "TASK", "confidence": 0.7786626666784286}, {"text": "meaning representation parsing (May 2016)", "start_pos": 65, "end_pos": 106, "type": "TASK", "confidence": 0.8497136575835091}]}, {"text": "This data set covers various domains including newswire and Web discussion forums.", "labels": [], "entities": []}, {"text": "For each graph, we derive a vertex order corresponding to the English word order by using the automatically generated alignments provided with the data set, which", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1  Relative treewidth statistics with respect to different vertex orders: \"real\" means the real  treewidth of the data, \"string\" means using the string order constraint, \"gold\" means using the  gold alignment.", "labels": [], "entities": []}, {"text": " Table 2  Relative treewidth statistics for SemEval 2015 semantic dependency graphs.", "labels": [], "entities": [{"text": "SemEval 2015 semantic dependency graphs", "start_pos": 44, "end_pos": 83, "type": "TASK", "confidence": 0.8098909854888916}]}]}