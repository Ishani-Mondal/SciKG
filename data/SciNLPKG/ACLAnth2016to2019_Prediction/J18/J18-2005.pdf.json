{"title": [{"text": "Tree Structured Dirichlet Processes for Hierarchical Morphological Segmentation", "labels": [], "entities": [{"text": "Hierarchical Morphological Segmentation", "start_pos": 40, "end_pos": 79, "type": "TASK", "confidence": 0.7712507049242655}]}], "abstractContent": [{"text": "This article presents a probabilistic hierarchical clustering model for morphological segmenta-tion.", "labels": [], "entities": []}, {"text": "In contrast to existing approaches to morphology learning, our method allows learning hierarchical organization of word morphology as a collection of tree structured paradigms.", "labels": [], "entities": [{"text": "learning hierarchical organization of word morphology", "start_pos": 77, "end_pos": 130, "type": "TASK", "confidence": 0.6769923071066538}]}, {"text": "The model is fully unsupervised and based on the hierarchical Dirichlet process.", "labels": [], "entities": []}, {"text": "Tree hierarchies are learned along with the corresponding morphological paradigms simultaneously.", "labels": [], "entities": []}, {"text": "Our model is evaluated on Morpho Challenge and shows competitive performance when compared to state-of-the-art unsupervised morphological segmentation systems.", "labels": [], "entities": [{"text": "Morpho Challenge", "start_pos": 26, "end_pos": 42, "type": "DATASET", "confidence": 0.8235089778900146}]}, {"text": "Although we apply this model for morphological segmentation, the model itself can also be used for hierarchical clustering of other types of data.", "labels": [], "entities": [{"text": "morphological segmentation", "start_pos": 33, "end_pos": 59, "type": "TASK", "confidence": 0.7553691267967224}]}], "introductionContent": [{"text": "Unsupervised learning of morphology has been an important task because of the benefits it provides to many other natural language processing applications such as machine translation, information retrieval, question answering, and so forth.", "labels": [], "entities": [{"text": "Unsupervised learning of morphology", "start_pos": 0, "end_pos": 35, "type": "TASK", "confidence": 0.6862654164433479}, {"text": "machine translation", "start_pos": 162, "end_pos": 181, "type": "TASK", "confidence": 0.7873101532459259}, {"text": "information retrieval", "start_pos": 183, "end_pos": 204, "type": "TASK", "confidence": 0.7892923057079315}, {"text": "question answering", "start_pos": 206, "end_pos": 224, "type": "TASK", "confidence": 0.8967573344707489}]}, {"text": "Morphological paradigms provide a natural way to capture the internal morphological structure of a group of morphologically related words.", "labels": [], "entities": []}, {"text": "Following and, we use the term paradigm as consisting of a set of stems and a set of suffixes where each combination of a stem and a suffix leads to a valid word form, for example, {walk,talk,order,yawn}{s,ed,ing} generating the surface forms walk+ed, walk+s, walk+ing, talk+ed, talk+s, talk+ing, order+s, order+ed, order+ing, yawn+ed, yawn+s, yawn+ing.", "labels": [], "entities": []}, {"text": "A sample paradigm is given in.", "labels": [], "entities": []}, {"text": "Recently, we introduced a probabilistic hierarchical clustering model for learning hierarchical morphological paradigms.", "labels": [], "entities": []}, {"text": "Each node in the hierarchical tree corresponds to a morphological paradigm and each leaf node consists of a word.", "labels": [], "entities": []}, {"text": "A singletree is learned, where different branches on the hierarchical tree learn morphological families that share the same stem, such as faithful, faithfully, unfaithful, faithless, and soon, that are all derived from faith.", "labels": [], "entities": []}, {"text": "Those morphological families are learned as a graph and called morphological forests, which deviates from the meaning of the term forest we refer in this article.", "labels": [], "entities": []}, {"text": "Although learning morphological families has been studied as a graph learning problem in, in this work, we learn paradigms that generalize morphological families within a collection of hierarchical structures.", "labels": [], "entities": []}, {"text": "Narasimhan, Barzilay, and Jaakkola (2015) model the word formation with morphological chains in terms of parent-child relations.", "labels": [], "entities": [{"text": "word formation", "start_pos": 52, "end_pos": 66, "type": "TASK", "confidence": 0.7267271131277084}]}, {"text": "For example, play and playful have a parent-child relationship as a result of adding the morpheme ful at the end of play.", "labels": [], "entities": []}, {"text": "These relations are modeled by using log-linear models in order to predict the parent relations.", "labels": [], "entities": []}, {"text": "Semantic features as given by word2vec () are used in their model in addition to orthographic features for the prediction of parent-child relations.", "labels": [], "entities": []}, {"text": "Narasimhan, Barzilay, and Jaakkola use contrastive estimation and generate corrupted examples as pseudo negative examples within their approach.", "labels": [], "entities": []}, {"text": "Our model is an extension of our previous hierarchical clustering algorithm.", "labels": [], "entities": []}, {"text": "In that algorithm, a singletree is learned that corresponds to a hierarchical organization of morphological paradigms.", "labels": [], "entities": []}, {"text": "The parent nodes merge the paradigms from the child nodes.", "labels": [], "entities": []}, {"text": "But such merging of paradigms into a single structure causes unrelated paradigms to be merged resulting in lower segmentation accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 126, "end_pos": 134, "type": "METRIC", "confidence": 0.9550406336784363}]}, {"text": "The current model addresses this issue by learning a forest of tree structures.", "labels": [], "entities": []}, {"text": "Within each tree structure the parent nodes merge the paradigms from the child nodes.", "labels": [], "entities": []}, {"text": "Multiple trees ensure that paradigms that should not be merged are kept separated.", "labels": [], "entities": []}, {"text": "Additionally, in singletree hierarchical clustering, a manually defined context free grammar was employed to generate the segmentation of a word.", "labels": [], "entities": [{"text": "singletree hierarchical clustering", "start_pos": 17, "end_pos": 51, "type": "TASK", "confidence": 0.6472494304180145}]}, {"text": "In the current model, we predict the segmentation of a word without using any manually defined grammar rules.", "labels": [], "entities": [{"text": "predict the segmentation of a word", "start_pos": 25, "end_pos": 59, "type": "TASK", "confidence": 0.7453992565472921}]}], "datasetContent": [{"text": "We used publicly available Morpho Challenge data sets for English, German, and Turkish for training.", "labels": [], "entities": [{"text": "Morpho Challenge data sets", "start_pos": 27, "end_pos": 53, "type": "DATASET", "confidence": 0.9160147905349731}]}, {"text": "The English data set consists of 878,034 words, the German data set consists of 2,338,323 words, and the Turkish data set consists of 617,298 words.", "labels": [], "entities": [{"text": "English data set", "start_pos": 4, "end_pos": 20, "type": "DATASET", "confidence": 0.8976877927780151}, {"text": "German data set", "start_pos": 52, "end_pos": 67, "type": "DATASET", "confidence": 0.8347691098848978}, {"text": "Turkish data set", "start_pos": 105, "end_pos": 121, "type": "DATASET", "confidence": 0.8595341046651205}]}, {"text": "Although frequency of each word was available in the training set, we did not make use of this information.", "labels": [], "entities": [{"text": "frequency", "start_pos": 9, "end_pos": 18, "type": "METRIC", "confidence": 0.9831938743591309}]}, {"text": "In other words, we use only the word types (not tokens) in training.", "labels": [], "entities": []}, {"text": "We do not address the ambiguity of words in this work and leave this as future research.", "labels": [], "entities": []}, {"text": "In all experiments, the initial temperature of the system is set \u03b3 = 2 and it is reduced to \u03b3 = 0.01 with decrements \u03b7 = 0.0001 (see Equation).", "labels": [], "entities": []}, {"text": "shows the time required for the log likelihoods of the trees of sizes 10K, 16K, and 22K to converge.", "labels": [], "entities": []}, {"text": "We fixed \u03b1 s = \u03b1 m = \u03b2 s = \u03b2 m = 0.01 and \u03b1 = 0.0005 in all our experiments.", "labels": [], "entities": []}, {"text": "The hyperparameters are set manually as a result of several experiments.", "labels": [], "entities": []}, {"text": "These are the optimum values obtained from a number of experiments.", "labels": [], "entities": []}, {"text": "Precision, recall, and F-score values against training set sizes are given in for English and Turkish, respectively.", "labels": [], "entities": [{"text": "Precision", "start_pos": 0, "end_pos": 9, "type": "METRIC", "confidence": 0.9967436790466309}, {"text": "recall", "start_pos": 11, "end_pos": 17, "type": "METRIC", "confidence": 0.9970986843109131}, {"text": "F-score", "start_pos": 23, "end_pos": 30, "type": "METRIC", "confidence": 0.9993436932563782}]}, {"text": "Although we experimented with different sizes of training sets, we used a randomly chosen 600K words from the English and 200K words from the Turkish and German data sets for evaluation purposes.", "labels": [], "entities": [{"text": "Turkish and German data sets", "start_pos": 142, "end_pos": 170, "type": "DATASET", "confidence": 0.6698280513286591}]}, {"text": "Evaluation is performed according to the method proposed in Morpho Challenge (), which in turn is based on evaluation used by  For additional experiments, we compare our model with Morpho Chain (Narasimhan, Barzilay, and Jaakkola 2015) based on their evaluation method that differs from the Morpho Challenge evaluation method.", "labels": [], "entities": []}, {"text": "Their evaluation method is based on counting the correct segmentation points.", "labels": [], "entities": []}, {"text": "For example, if the result segmentation is booking+s and the gold segmentation is book+ing+s, 1 point is counted.", "labels": [], "entities": []}, {"text": "Precision and recall are) that provide segmentation points.", "labels": [], "entities": [{"text": "Precision", "start_pos": 0, "end_pos": 9, "type": "METRIC", "confidence": 0.988860547542572}, {"text": "recall", "start_pos": 14, "end_pos": 20, "type": "METRIC", "confidence": 0.9977959394454956}]}, {"text": "We used the same trained models as in our Morpho Challenge evaluation.", "labels": [], "entities": [{"text": "Morpho Challenge evaluation", "start_pos": 42, "end_pos": 69, "type": "DATASET", "confidence": 0.8045581380526224}]}, {"text": "The English test set contains 2,218 words and the Turkish test set contains 2,534 words.", "labels": [], "entities": [{"text": "English test set", "start_pos": 4, "end_pos": 20, "type": "DATASET", "confidence": 0.9134041666984558}, {"text": "Turkish test set", "start_pos": 50, "end_pos": 66, "type": "DATASET", "confidence": 0.9250887036323547}]}, {"text": "The English results are given in and Turkish results are given in.", "labels": [], "entities": []}, {"text": "For all systems, Morpho Chain evaluation scores are comparably higher than the Morpho Challenge scores.", "labels": [], "entities": []}, {"text": "There are several reasons for this.", "labels": [], "entities": []}, {"text": "In the Morpho Challenge evaluation, the morpheme labels are considered rather than the surface forms of the morphemes.", "labels": [], "entities": [{"text": "Morpho Challenge evaluation", "start_pos": 7, "end_pos": 34, "type": "DATASET", "confidence": 0.7954870462417603}]}, {"text": "For example, pantolon+u+yla [with his trousers] and emel+ler+i+yle [with his desires] have got both possessive morpheme (u and i) that is labeled with POS and relational morpheme (yla and yle) labeled with REL in common.", "labels": [], "entities": [{"text": "POS", "start_pos": 151, "end_pos": 154, "type": "METRIC", "confidence": 0.6746577024459839}, {"text": "REL", "start_pos": 206, "end_pos": 209, "type": "METRIC", "confidence": 0.9918881058692932}]}, {"text": "This increases the total number of points that is computed overall word pairs, and therefore lowers the scores.", "labels": [], "entities": []}, {"text": "Secondly, in the Morpho Chain evaluation, only the gold segmentation that has the maximum match with the result segmentation is chosen for each word (e.g., yaz\u0131m\u0131za has two gold segmentations: yaz+\u0131+m\u0131z+a [to our summer] and yaz\u0131+m\u0131z+a;).", "labels": [], "entities": []}, {"text": "In contrast, in the Morpho Challenge evaluation all segmentations in the gold segmentation are evaluated.", "labels": [], "entities": [{"text": "Morpho Challenge evaluation", "start_pos": 20, "end_pos": 47, "type": "DATASET", "confidence": 0.8406163056691488}]}, {"text": "This is another factor that increases the scores in Morpho Chain evaluation.", "labels": [], "entities": [{"text": "Morpho Chain evaluation", "start_pos": 52, "end_pos": 75, "type": "TASK", "confidence": 0.6167892714341482}]}, {"text": "Thus, the Morpho Chain evaluation favors precision over recall.", "labels": [], "entities": [{"text": "Morpho Chain evaluation", "start_pos": 10, "end_pos": 33, "type": "DATASET", "confidence": 0.8218564589818319}, {"text": "precision", "start_pos": 41, "end_pos": 50, "type": "METRIC", "confidence": 0.9992250204086304}, {"text": "recall", "start_pos": 56, "end_pos": 62, "type": "METRIC", "confidence": 0.9975956082344055}]}, {"text": "Indeed, in the Morpho Challenge evaluation, the Morpho Chain system has high precision but their model suffers from low recall due to undersegmentation (see).", "labels": [], "entities": [{"text": "Morpho Challenge evaluation", "start_pos": 15, "end_pos": 42, "type": "DATASET", "confidence": 0.7822441260019938}, {"text": "precision", "start_pos": 77, "end_pos": 86, "type": "METRIC", "confidence": 0.999030590057373}, {"text": "recall", "start_pos": 120, "end_pos": 126, "type": "METRIC", "confidence": 0.9991353154182434}]}, {"text": "It should be noted that the output of our system is not only the segmentation points, but also the hierarchical organization of morphological paradigms that we believe is novel in this work.", "labels": [], "entities": []}, {"text": "However, because of the difficulty in measuring the quality of hierarchical paradigms, which will require a corresponding hierarchically organized gold data set, we are unable to provide an objective measure of the quality of hierarchical structures learned.", "labels": [], "entities": []}, {"text": "We present different portions from the obtained trees in Appendix B (see.", "labels": [], "entities": []}, {"text": "It can be seen that words sharing the same suffixes are gathered closer to each other, such as reestablish+ed, reclassifi+ed, circl+ed, uncloth+ed, and so forth.", "labels": [], "entities": []}, {"text": "Secondly, related morphological families gather closer to each other, such as impress+ively, impress+ionist, impress+ions, impress+ion.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2  Morpho Challenge 2010 experimental results for English.", "labels": [], "entities": [{"text": "Morpho Challenge 2010 experimental", "start_pos": 10, "end_pos": 44, "type": "DATASET", "confidence": 0.8339645713567734}]}, {"text": " Table 3  Morpho Challenge 2010 experimental results for German.", "labels": [], "entities": [{"text": "Morpho Challenge 2010", "start_pos": 10, "end_pos": 31, "type": "DATASET", "confidence": 0.735687792301178}, {"text": "German", "start_pos": 57, "end_pos": 63, "type": "DATASET", "confidence": 0.8898475766181946}]}, {"text": " Table 4  Morpho Challenge 2010 experimental results for Turkish.", "labels": [], "entities": [{"text": "Morpho Challenge 2010", "start_pos": 10, "end_pos": 31, "type": "DATASET", "confidence": 0.8042803804079691}, {"text": "Turkish", "start_pos": 57, "end_pos": 64, "type": "DATASET", "confidence": 0.8235427141189575}]}, {"text": " Table 5  Comparison with Single Tree Probabilistic Clustering for English.", "labels": [], "entities": []}, {"text": " Table 6  Comparison with Single Tree Probabilistic Clustering for German.", "labels": [], "entities": []}, {"text": " Table 7  Comparison with Single Tree Probabilistic Clustering for Turkish.", "labels": [], "entities": []}, {"text": " Table 8  Comparison with Morpho Chain model for English based on Morpho Chain evaluation.", "labels": [], "entities": []}, {"text": " Table 9.  For all systems, Morpho Chain evaluation scores are comparably higher than the  Morpho Challenge scores. There are several reasons for this. In the Morpho Challenge  evaluation, the morpheme labels are considered rather than the surface forms of the  morphemes. For example, pantolon+u+yla [with his trousers] and emel+ler+i+yle [with  his desires] have got both possessive morpheme (u and i) that is labeled with POS and  relational morpheme (yla and yle) labeled with REL in common. This increases the total  number of points that is computed over all word pairs, and therefore lowers the scores.", "labels": [], "entities": [{"text": "REL", "start_pos": 481, "end_pos": 484, "type": "METRIC", "confidence": 0.9910544753074646}]}]}