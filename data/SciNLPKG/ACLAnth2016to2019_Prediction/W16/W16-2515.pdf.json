{"title": [{"text": "Evaluating multi-sense embeddings for semantic resolution monolingually and in word translation", "labels": [], "entities": [{"text": "semantic resolution monolingually", "start_pos": 38, "end_pos": 71, "type": "TASK", "confidence": 0.7894896467526754}, {"text": "word translation", "start_pos": 79, "end_pos": 95, "type": "TASK", "confidence": 0.7150871753692627}]}], "abstractContent": [{"text": "Multi-sense word embeddings (MSEs) model different meanings of word forms with different vectors.", "labels": [], "entities": []}, {"text": "We propose two new methods for evaluating MSEs, one based on monolingual dictionaries, and the other exploiting the principle that words maybe ambiguous as far as the postulated senses translate to different words in some other language.", "labels": [], "entities": []}], "introductionContent": [{"text": "Gladkova and Drozd (2016) calls polysemy \"the elephant in the room\" as far as evaluating embeddings are concerned.", "labels": [], "entities": []}, {"text": "Here we attack this problem head on, by proposing two methods for evaluating multi-sense word embeddings (MSEs) where polysemous words have multiple vectors, ideally one per sense.", "labels": [], "entities": []}, {"text": "Section 2 discusses the first method, based on sense distinctions made in traditional monolingual dictionaries.", "labels": [], "entities": []}, {"text": "We investigate the correlation between the number of senses of each word-form in the embedding and in the manually created inventory as a proxy measure of how well embedding vectors correspond to concepts in speakers' (or at least, the lexicographers') mind.", "labels": [], "entities": []}, {"text": "The other evaluation method, discussed in Section 3, is bilingual, based on the method of, who formulate word translation as a linear mapping from the source language embedding to the target one, trained on a seed of a few thousand word pairs.", "labels": [], "entities": [{"text": "formulate word translation", "start_pos": 95, "end_pos": 121, "type": "TASK", "confidence": 0.7279267907142639}]}, {"text": "Our proposal is to perform such translations from MSEs, with the idea that what are different senses in the source language will very often translate to different words in the target language.", "labels": [], "entities": []}, {"text": "This way, we can use single-sense embeddings on the target side and thereby reduce the noise of MSEs.", "labels": [], "entities": []}, {"text": "Altogether we present a preliminary evaluation of four MSE implementations by these two methods on two languages, English and Hungarian: the released result of the spherical context clustering method huang (; the learning process of with adaptive sense numbers (we report results using their release MSEs and their tool itself, calling both neela); the parametrized Bayesian learner of where the number of senses is controlled by a parameter \u03b1 for semantic resolution, here referred to as.", "labels": [], "entities": [{"text": "semantic resolution", "start_pos": 448, "end_pos": 467, "type": "TASK", "confidence": 0.7178822159767151}]}, {"text": "MSEs with multiple instances are suffixed with their most important parameters, i.e. the learning rate for AdaGram (a = 0.5); the number of multi-prototype words and whether the model is adaptive (NP) for release neela; and the number of induced word senses (s = 4) for our non-adaptive neela runs.", "labels": [], "entities": [{"text": "AdaGram", "start_pos": 107, "end_pos": 114, "type": "DATASET", "confidence": 0.8784120678901672}]}, {"text": "Some very preliminary conclusions are offered in Section 4, more in regards to the feasibility of the two evaluation methods we propose than about the merits of the systems we evaluated.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Sense distribution, size (in words), mean, and standard deviation of the English and Hungarian  lexicographic and automatically generated resources", "labels": [], "entities": [{"text": "mean", "start_pos": 47, "end_pos": 51, "type": "METRIC", "confidence": 0.9554370045661926}]}, {"text": " Table 2: Word sense distribution similarity be- tween various resources", "labels": [], "entities": [{"text": "Word sense distribution", "start_pos": 10, "end_pos": 33, "type": "TASK", "confidence": 0.6753556330998739}]}, {"text": " Table 3: Word sense distribution similarity with  POS tag perplexity (top panel) and word frequency  (bottom panel)", "labels": [], "entities": []}, {"text": " Table 4: Hungarian to English translation. Target  embedding from Mikolov et al. (2013a)", "labels": [], "entities": [{"text": "Hungarian to English translation", "start_pos": 10, "end_pos": 42, "type": "TASK", "confidence": 0.5517328083515167}]}]}