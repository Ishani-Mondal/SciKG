{"title": [{"text": "A Recurrent Neural Network Architecture for De-identifying Clinical Records", "labels": [], "entities": []}], "abstractContent": [{"text": "Electronic Medical Records contains a rich source of information for medical finding.", "labels": [], "entities": [{"text": "Electronic Medical Records", "start_pos": 0, "end_pos": 26, "type": "DATASET", "confidence": 0.8936805327733358}, {"text": "medical finding", "start_pos": 69, "end_pos": 84, "type": "TASK", "confidence": 0.7331174910068512}]}, {"text": "However, the access to the medical record is limited to only de-identified form so as to protect the confidentiality of patient.", "labels": [], "entities": []}, {"text": "According to Health Insurance Portability and Accountability Act, there are 18 PHI categories that should be enclosed before making the EMR publicly available.", "labels": [], "entities": [{"text": "Health Insurance Portability and Accountability", "start_pos": 13, "end_pos": 60, "type": "TASK", "confidence": 0.6677093267440796}]}, {"text": "With the rapid growth of EMR and a limited amount of de-identified text, the manual curation is quite unfeasible and time-consuming, which has drawn the attention of several researchers to propose automated de-identification system.", "labels": [], "entities": []}, {"text": "In this paper, we proposed deep neural network based architecture for de-identification of 7 PHI categories with 25 associated sub-categories.", "labels": [], "entities": []}, {"text": "We used standard benchmark dataset from i2b2-2014 de-identification challenge and performed the comparison with very strong baseline based on Conditional Random Field.", "labels": [], "entities": []}, {"text": "We also perform the comparison with the state-of-art.", "labels": [], "entities": [{"text": "comparison", "start_pos": 20, "end_pos": 30, "type": "TASK", "confidence": 0.9606603384017944}]}, {"text": "Results show that our proposed system achieves significant improvement over baseline and comparable performance over state-of-art.", "labels": [], "entities": []}], "introductionContent": [{"text": "Appreciable amount of information extracted from Electronic Medical Record (EMR) have flourished Medical Natural Language Processing in recent past.", "labels": [], "entities": [{"text": "Electronic Medical Record (EMR)", "start_pos": 49, "end_pos": 80, "type": "DATASET", "confidence": 0.7290385464827219}, {"text": "Medical Natural Language Processing", "start_pos": 97, "end_pos": 132, "type": "TASK", "confidence": 0.630508080124855}]}, {"text": "In general, the medical records are restricted according to Health Insurance Portability and Accountability Act (HIPAA).", "labels": [], "entities": []}, {"text": "Before making it publicly available, the medical records should be de-identified which refers to hiding the personal details.", "labels": [], "entities": []}, {"text": "De-identification can be thus seen as the task of enclosing the private health information (PHI) while maintaining the exact sense of the record.", "labels": [], "entities": []}, {"text": "According to the HIPAA standards, total of 18 PHI categories have to enclosed before making records publicly available.", "labels": [], "entities": []}, {"text": "Taking into account, the vast size of available EMR, manual de-identification could be expensive and unfeasible.", "labels": [], "entities": []}, {"text": "These motivate us to develop an automated de-identification system for this task.", "labels": [], "entities": []}, {"text": "De-identification shares the common property with the traditional named entity recognition which aims to identify the proper labeled sequence for the given input sequence.", "labels": [], "entities": [{"text": "named entity recognition", "start_pos": 66, "end_pos": 90, "type": "TASK", "confidence": 0.762873649597168}]}, {"text": "However, detection of PHI entities suffers from several challenges such as: (1) Terminological variation and irregularities: PHI entities can occur within text in different variations, for example '3041023MARY' is the combination of two different PHI categories '3041023' which represents the MEDICALRECORD and 'MARY' which is another PHI category.", "labels": [], "entities": [{"text": "MARY", "start_pos": 312, "end_pos": 316, "type": "METRIC", "confidence": 0.9260042905807495}]}, {"text": "(2) Lexical variations: In EMR same entities are often written in different lexical form.", "labels": [], "entities": []}, {"text": "For example, variation of the entities such as the '50 yo m', '50 yo M', '55 YO MALE'.", "labels": [], "entities": [{"text": "YO", "start_pos": 77, "end_pos": 79, "type": "METRIC", "confidence": 0.9739903807640076}, {"text": "MALE", "start_pos": 80, "end_pos": 84, "type": "METRIC", "confidence": 0.5268839001655579}]}, {"text": "(3) Inter-PHI ambiguity: Ambiguity of PHI terms with the non-PHI terms.", "labels": [], "entities": []}, {"text": "For e.g., 'Brown' can be identified as the PHI term 'Name (Doctor)' as well as non-PHI term.", "labels": [], "entities": []}, {"text": "(4) Intra-PHI ambiguity: Ambiguity of PHI terms with the other PHI terms.", "labels": [], "entities": []}, {"text": "For e.g., '30s' can be identified as the PHI term (Age) as well as other PHI terms.", "labels": [], "entities": []}, {"text": "Recently several shared tasks have been organized to solve the de-identification problem such as Center of Informatics for Integrating Biology (i2b2) 2 . The traditional de-identification system generally falls into three different categories viz.", "labels": [], "entities": []}, {"text": "machinelearning-based system, rule based system and hybrid system (based on the machine learning and rule based).", "labels": [], "entities": []}, {"text": "Rule based system depends on the patterns formed by the regular expressions and gazetteers which are developed by humans.", "labels": [], "entities": []}, {"text": "Rule based techniques might be very successful for one domain but fail to show significant improvements when domain changes.", "labels": [], "entities": []}, {"text": "To overcome these difficulties, supervised machine learning techniques were proposed to solve the de-identification task.", "labels": [], "entities": []}, {"text": "The popular machine learning models were based on decision tree (), support vector machine), (), log-linear models and popular conditional random fields (.", "labels": [], "entities": []}, {"text": "However, existing techniques based on machine learning suffer from the following drawbacks: (1) requirement of significant amount of labeled data, (2) involves an extensive feature engineering or rule generation step necessitating human effort.", "labels": [], "entities": [{"text": "rule generation", "start_pos": 196, "end_pos": 211, "type": "TASK", "confidence": 0.7052822262048721}]}, {"text": "Hence, both the techniques require manual intervention for designing features and rules which are restricted to single domain and thus incur time and cost.", "labels": [], "entities": []}, {"text": "The introduction of deep learning technique has facilitated to learn effective features without any manual intervention i.e., there is no requirement of feature engineering.", "labels": [], "entities": []}, {"text": "The models could learn implicitly relevant features byword in the form of vectors known as the word embedding.", "labels": [], "entities": []}, {"text": "These embedding are jointly learned by other hyperparameters which are initialized randomly or can be pre-trained on large unlabeled corpus.", "labels": [], "entities": []}, {"text": "Pretraining is much beneficial in improving performance as it effectively captures the linguistic variations and patterns.", "labels": [], "entities": [{"text": "Pretraining", "start_pos": 0, "end_pos": 11, "type": "METRIC", "confidence": 0.9794638156890869}]}, {"text": "Recently, there has been significant success of deep learning techniques in solving various natural language processing tasks such as text classification, language modeling (, machine translation (), spoken language understanding () as well as named entity recognition).", "labels": [], "entities": [{"text": "text classification", "start_pos": 134, "end_pos": 153, "type": "TASK", "confidence": 0.7747742831707001}, {"text": "language modeling", "start_pos": 155, "end_pos": 172, "type": "TASK", "confidence": 0.7159029543399811}, {"text": "machine translation", "start_pos": 176, "end_pos": 195, "type": "TASK", "confidence": 0.7155979722738266}, {"text": "spoken language understanding", "start_pos": 200, "end_pos": 229, "type": "TASK", "confidence": 0.6392282744248708}, {"text": "named entity recognition", "start_pos": 244, "end_pos": 268, "type": "TASK", "confidence": 0.6199224293231964}]}, {"text": "Motivated by the success of deep learning techniques, in this paper, we have adopted in particular Recurrent Neural Network (RNN) ( architecture to capture PHI terms.", "labels": [], "entities": []}, {"text": "RNN has shown advantages over other machine learning and rule based techniques.", "labels": [], "entities": []}, {"text": "RNN unlike other techniques does not require features explicitly developed for the classifier learning.", "labels": [], "entities": []}, {"text": "The virtue of system learning by itself makes the system adaptable and scalable.", "labels": [], "entities": []}, {"text": "This work is an extension of our previous work) where we identified only 7 PHI category (Patient, Doctor, Hospital, Location, Date, Age, ID) irrespective of subcategories using only i2b2-2014 training dataset.", "labels": [], "entities": []}, {"text": "The current work provide comprehensive experimentation on i2b2-2014 challenge dataset to deidentify 7 categories and 25 subcategories.", "labels": [], "entities": [{"text": "i2b2-2014 challenge dataset", "start_pos": 58, "end_pos": 85, "type": "DATASET", "confidence": 0.6555848817030588}]}, {"text": "We have formulated this task as the sequence labeling problem and developed the baseline model using a supervised machine learning technique.", "labels": [], "entities": [{"text": "sequence labeling problem", "start_pos": 36, "end_pos": 61, "type": "TASK", "confidence": 0.7957196633021036}]}, {"text": "Conditional random field (CRF) () along with a set of handcrafted features are used to build the base classifier.", "labels": [], "entities": []}, {"text": "In the current study, we performed comparative analysis with two different variants of RNN network model viz Elman-type networks) and Jordan-type networks.", "labels": [], "entities": []}, {"text": "A thorough comparison of these two RNN variants with strong baseline based on CRF is apart of the paper.", "labels": [], "entities": [{"text": "CRF", "start_pos": 78, "end_pos": 81, "type": "METRIC", "confidence": 0.4916902184486389}]}, {"text": "The results obtained show the effectiveness of RNN over traditional CRF based model.", "labels": [], "entities": []}, {"text": "We further compared our deep learning model with state-of-art results on de-identification task.", "labels": [], "entities": []}, {"text": "We have shown that RNN achieves comparable results with the state-of-art using machine learning techniques.", "labels": [], "entities": []}], "datasetContent": [{"text": "In the current study, we have used the standard benchmark dataset of i2b2-2014 challenge () to evaluate our model.", "labels": [], "entities": []}, {"text": "The challenge was part of 2014 i2b2/UTHealth shared task Track 1 (.", "labels": [], "entities": [{"text": "2014 i2b2/UTHealth shared task Track 1", "start_pos": 26, "end_pos": 64, "type": "DATASET", "confidence": 0.760291300714016}]}, {"text": "Total ten teams have participated in the shared task resulting in 25 different submissions.", "labels": [], "entities": []}, {"text": "The i2b2-2014 dataset is the largest publicly available de-identification dataset collected from \"Research Patient Data Repository of Partners Healthcare\".", "labels": [], "entities": [{"text": "i2b2-2014 dataset", "start_pos": 4, "end_pos": 21, "type": "DATASET", "confidence": 0.8243190944194794}, {"text": "Research Patient Data Repository of Partners Healthcare\"", "start_pos": 98, "end_pos": 154, "type": "DATASET", "confidence": 0.8298978321254253}]}, {"text": "A total of 1304 medical records of 297 patients were manually annotated which were divided into training and test set comprising of 790 and 514 records, respectively.", "labels": [], "entities": []}, {"text": "There are 17, 045 and 11, 462 PHI instances in the training and test sets, respectively.", "labels": [], "entities": []}, {"text": "This was manually annotated using seven types with twenty-five subcategories as: (1) Name (subtypes: Patient, Doctor, Username), (2) Profession, (3) Location (subtypes: Hospital, Department, Organization, Room, Street, City, State, Country, ZIP), (4) Age, (5) Date, (6) Contact (subtypes: Phone, Fax, Email, URL, IPAddress), provides detailed distribution of PHI terms in both the sets.", "labels": [], "entities": []}, {"text": "For the evaluation of our model, we adopted similar evaluation metrics as used in i2b2 challenge such as recall (R), precision (P) and F-Measure  We have trained our RNN model using stochastic gradient descent.", "labels": [], "entities": [{"text": "recall (R)", "start_pos": 105, "end_pos": 115, "type": "METRIC", "confidence": 0.9497105777263641}, {"text": "precision (P)", "start_pos": 117, "end_pos": 130, "type": "METRIC", "confidence": 0.9609012752771378}, {"text": "F-Measure", "start_pos": 135, "end_pos": 144, "type": "METRIC", "confidence": 0.9809232950210571}]}, {"text": "RNN can be tuned with hyper-parameters such as number of hidden layers (H), context window size (m), learning rate (\u03bb), dropout probability (p) and no of epochs.", "labels": [], "entities": [{"text": "learning rate (\u03bb)", "start_pos": 101, "end_pos": 118, "type": "METRIC", "confidence": 0.9294838547706604}, {"text": "dropout probability (p)", "start_pos": 120, "end_pos": 143, "type": "METRIC", "confidence": 0.8434285044670105}]}, {"text": "In order to fine tune our system, we have conducted experiments on development set which is 10 % of our training data.", "labels": [], "entities": []}, {"text": "For training the RNN model, we have performed mini batch gradient descent approach considering only one sentence per mini batch, minimizing negative log-likelihood.", "labels": [], "entities": []}, {"text": "We have initialized the embedding and weight matrices in the range of [\u22121, 1] following uniform distribution.", "labels": [], "entities": []}, {"text": "shows the optimized hyperparameter values for both the RNN models.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Data set statistics: distribution of differ- ent classes in training and test sets.", "labels": [], "entities": []}, {"text": " Table 3: Optimal hyper-parameter values for El- man and Jordan model", "labels": [], "entities": []}, {"text": " Table 4: Impact of fine-tuned word embed- ding technique on PDI using Elman architecture.  RNNLM: The word embedding obtained from  RNN language modeling technique(Mikolov et  al., 2010). CBOW: The continuous CBOW takes  the context word as the input and tries to predict  the target word.", "labels": [], "entities": []}, {"text": " Table 5: Performance of CRF and RNN based models for identifying PHI at entity level. CRF is the  baseline model based on Conditional Random Field. Elman and Jordan are two variants of RNN model.  Our system is evaluated w.r.t recall(R), precision (P) and F-measure (F). All the values are reported in  %", "labels": [], "entities": [{"text": "recall", "start_pos": 228, "end_pos": 234, "type": "METRIC", "confidence": 0.9846188426017761}, {"text": "precision (P)", "start_pos": 239, "end_pos": 252, "type": "METRIC", "confidence": 0.9427280575037003}, {"text": "F-measure (F)", "start_pos": 257, "end_pos": 270, "type": "METRIC", "confidence": 0.9527058452367783}]}]}