{"title": [], "abstractContent": [{"text": "In this paper, we describe ROOT 18, a classifier using the scores of several unsupervised dis-tributional measures as features to discriminate between semantically related and unrelated words, and then to classify the related pairs according to their semantic relation (i.e. synonymy, antonymy, hypernymy, part-whole meronymy).", "labels": [], "entities": [{"text": "ROOT 18", "start_pos": 27, "end_pos": 34, "type": "METRIC", "confidence": 0.8137027621269226}]}, {"text": "Our classifier participated in the CogALex-V Shared Task, showing a solid performance on the first subtask, but a poor performance on the second subtask.", "labels": [], "entities": []}, {"text": "The low scores reported on the second subtask suggest that distributional measures are not sufficient to discriminate between multiple semantic relations at once.", "labels": [], "entities": []}], "introductionContent": [{"text": "The system described in this paper has been designed for the CogALex-V Shared Task, focusing on the corpus-based identification of semantic relations.", "labels": [], "entities": [{"text": "corpus-based identification of semantic relations", "start_pos": 100, "end_pos": 149, "type": "TASK", "confidence": 0.7135679662227631}]}, {"text": "Since Distributional Semantic Models (henceforth DSMs) were proposed as a special topic of interest for the current edition of the CogALex workshop, we decided to base our classifier on a number of distributional measures that have been used by past Natural Language Processing (NLP) research to discriminate between a specific semantic relation and other relation types.", "labels": [], "entities": []}, {"text": "The task is splitted into the following subtasks: \u2022 for each word pair, the participating systems have to decide whether the terms are semantically related or not (TRUE and FALSE are the only possible outcomes); \u2022 for each word pair, the participating systems have to decide which semantic relation holds between the terms of the pair.", "labels": [], "entities": [{"text": "TRUE", "start_pos": 164, "end_pos": 168, "type": "METRIC", "confidence": 0.9176061749458313}, {"text": "FALSE", "start_pos": 173, "end_pos": 178, "type": "METRIC", "confidence": 0.9735399484634399}]}, {"text": "The five possible semantic relations are synonymy (SYN), antonymy (ANT), hypernymy (HYPER), meronymy (PART OF) and no semantic relation at all (RANDOM).", "labels": [], "entities": [{"text": "hypernymy (HYPER)", "start_pos": 73, "end_pos": 90, "type": "METRIC", "confidence": 0.8433500975370407}, {"text": "meronymy (PART OF)", "start_pos": 92, "end_pos": 110, "type": "METRIC", "confidence": 0.849802029132843}, {"text": "RANDOM", "start_pos": 144, "end_pos": 150, "type": "METRIC", "confidence": 0.9077357053756714}]}, {"text": "Our system managed to achieve good results in discriminating between related and random pairs in the first subtask, but unfortunately it struggled in the second one, also due to the high difficulty of the task itself.", "labels": [], "entities": []}, {"text": "In particular, the recall for some of the semantic relations of interest seems to be extremely low, suggesting that our unsupervised distributional measures do not provide sufficient information to characterize them, and that it could be probably useful to integrate such scores with other sources of evidence (e.g. information on lexical patterns of word co-occurrence).", "labels": [], "entities": [{"text": "recall", "start_pos": 19, "end_pos": 25, "type": "METRIC", "confidence": 0.9995280504226685}]}, {"text": "The paper is organized as follows: in section 2, we summarize related works on the task of semantic relation identification; in section 3, we introduce our system, by describing the classifier and the features.", "labels": [], "entities": [{"text": "semantic relation identification", "start_pos": 91, "end_pos": 123, "type": "TASK", "confidence": 0.7074199716250101}]}, {"text": "Finally, in section 4 we present and discuss our results.", "labels": [], "entities": []}], "datasetContent": [{"text": "The task organizers provided a training and a test set extracted from EVALution 1.0, a resource that was specifically designed for evaluating systems on the identification of semantic relations ( . EVALution 1.0 was derived from WordNet and ConceptNet () and it consists of almost 7500 word pairs, instantiating several semantic relations.", "labels": [], "entities": []}, {"text": "The training and the test set included, respectively, 3054 and 4260 word pairs and they are lexical-split, that is, the two sets do not share any pair.", "labels": [], "entities": []}, {"text": "Since words were not tagged, we performed POS-tagging with the TreeTagger.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Precision, Recall and F-measure scores for subtask 1 and 2. The numbers between parentheses  in the ROOT18 rows refer to the number of estimators used by the classifier.", "labels": [], "entities": [{"text": "Precision", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9981074333190918}, {"text": "Recall", "start_pos": 21, "end_pos": 27, "type": "METRIC", "confidence": 0.9899148941040039}, {"text": "F-measure scores", "start_pos": 32, "end_pos": 48, "type": "METRIC", "confidence": 0.9678025245666504}]}, {"text": " Table 2: Precision, recall and F-measure for each relation in subtask 2 (ROOT-18 with 500 estimators).", "labels": [], "entities": [{"text": "Precision", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9977501034736633}, {"text": "recall", "start_pos": 21, "end_pos": 27, "type": "METRIC", "confidence": 0.9991206526756287}, {"text": "F-measure", "start_pos": 32, "end_pos": 41, "type": "METRIC", "confidence": 0.9981796741485596}, {"text": "ROOT-18", "start_pos": 74, "end_pos": 81, "type": "METRIC", "confidence": 0.7739654779434204}]}, {"text": " Table 3: Confusion matrix for subtask 2 (ROOT-18 with 500 estimators).", "labels": [], "entities": [{"text": "ROOT-18", "start_pos": 42, "end_pos": 49, "type": "METRIC", "confidence": 0.6570903658866882}]}]}