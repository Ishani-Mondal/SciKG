{"title": [{"text": "Incorporating Selectional Preferences in Multi-hop Relation Extraction", "labels": [], "entities": [{"text": "Incorporating Selectional Preferences", "start_pos": 0, "end_pos": 37, "type": "TASK", "confidence": 0.757732500632604}, {"text": "Multi-hop Relation Extraction", "start_pos": 41, "end_pos": 70, "type": "TASK", "confidence": 0.8005591233571371}]}], "abstractContent": [{"text": "Relation extraction is one of the core challenges in automated knowledge base construction.", "labels": [], "entities": [{"text": "Relation extraction", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.9398930072784424}, {"text": "automated knowledge base construction", "start_pos": 53, "end_pos": 90, "type": "TASK", "confidence": 0.6003856509923935}]}, {"text": "One line of approach for relation extraction is to perform multi-hop reasoning on the paths connecting an entity pair to infer new relations.", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 25, "end_pos": 44, "type": "TASK", "confidence": 0.9227507710456848}]}, {"text": "While these methods have been successfully applied for knowledge base completion , they do not utilize the entity or the entity type information to make predictions.", "labels": [], "entities": [{"text": "knowledge base completion", "start_pos": 55, "end_pos": 80, "type": "TASK", "confidence": 0.7693769534428915}]}, {"text": "In this work, we incorporate selectional preferences , i.e., relations enforce constraints on the allowed entity types for the candidate entities , to multi-hop relation extraction by including entity type information.", "labels": [], "entities": [{"text": "multi-hop relation extraction", "start_pos": 151, "end_pos": 180, "type": "TASK", "confidence": 0.6250173250834147}]}, {"text": "We achieve a 17.67% (relative) improvement in MAP score in a relation extraction task when compared to a method that does not use entity type information .", "labels": [], "entities": [{"text": "MAP score", "start_pos": 46, "end_pos": 55, "type": "METRIC", "confidence": 0.7388641834259033}, {"text": "relation extraction task", "start_pos": 61, "end_pos": 85, "type": "TASK", "confidence": 0.858101507027944}]}], "introductionContent": [{"text": "Knowledge Bases (KB's) are structured knowledge sources widely used in applications like question answering () and search engines like Google Search and Microsoft Bing.", "labels": [], "entities": [{"text": "question answering", "start_pos": 89, "end_pos": 107, "type": "TASK", "confidence": 0.8094508945941925}]}, {"text": "This has led to the creation of large KB's like Freebase (, and NELL).", "labels": [], "entities": [{"text": "Freebase", "start_pos": 48, "end_pos": 56, "type": "DATASET", "confidence": 0.9789807200431824}]}, {"text": "KB's contains millions of facts usually in the form of triples (entity1, relation, entity2).", "labels": [], "entities": [{"text": "KB's", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.9008839130401611}]}, {"text": "However, KB's are woefully incomplete, missing important facts, and hence limiting their usefulness in downstream tasks. and, hence, the model of Neelakantan (2015) will assign them the same score for the relation AirportServesPlace without considering the fact that Yankee Stadium is not an airport.", "labels": [], "entities": []}, {"text": "To overcome this difficulty, Knowledge Base Completion (KBC) methods aim to complete the KB using existing facts.", "labels": [], "entities": []}, {"text": "For example, we can infer nationality of a person from their place of birth.", "labels": [], "entities": []}, {"text": "A common approach in many KBC methods for relation extraction is reasoning on individual relations (single-hop reasoning) to predict new relations ().", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 42, "end_pos": 61, "type": "TASK", "confidence": 0.8833189904689789}]}, {"text": "For example, predicting Nationality(X, Y) from BornIn(X, Y).", "labels": [], "entities": [{"text": "predicting Nationality", "start_pos": 13, "end_pos": 35, "type": "TASK", "confidence": 0.8295465409755707}]}, {"text": "The performance of relation extraction methods have been greatly improved by incorporating selectional preferences, i.e., relations enforce constraints on the allowed entity types for the candidate entities, both in sentence level and KB relation extraction (, and in learning entailment rules.", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 19, "end_pos": 38, "type": "TASK", "confidence": 0.7781832218170166}, {"text": "KB relation extraction", "start_pos": 235, "end_pos": 257, "type": "TASK", "confidence": 0.5628849864006042}]}, {"text": "Another line of work in relation extraction performs reasoning on the paths (multi-hop reasoning on paths of length \u2265 1) connecting an entity pair.", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 24, "end_pos": 43, "type": "TASK", "confidence": 0.9023417234420776}]}, {"text": "For example, these models can infer the relation PlaysInLeague(Tom Brady, NFL) from the facts PlaysForTeam(Tom Brady, New England Patriots) and PartOf(New England Patriots, NFL).", "labels": [], "entities": []}, {"text": "All these methods utilize only the relations in the path and do not include any information about the entities.", "labels": [], "entities": []}, {"text": "In this work, we extend the method of Neelakantan (2015) by incorporating entity type information.", "labels": [], "entities": []}, {"text": "Their method can generalize to paths unseen in training by composing embeddings of relations in the path non-linearly using a Recurrent Neural Network (RNN).", "labels": [], "entities": []}, {"text": "While entity type information has been successfully incorporated into relation extraction methods that perform single hop reasoning, here, we include them for multi-hop relation extraction.", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 70, "end_pos": 89, "type": "TASK", "confidence": 0.8274364769458771}, {"text": "multi-hop relation extraction", "start_pos": 159, "end_pos": 188, "type": "TASK", "confidence": 0.631848027308782}]}, {"text": "For example, illustrates an example where reasoning without type information would score both the paths equally although the latter path should receive a lesser score since there is an entity type mismatch for the first entity.", "labels": [], "entities": []}, {"text": "Our approach constructs vector representation of paths in the KB graph from representations of relations and entity types occurring in the path.", "labels": [], "entities": []}, {"text": "We achieve a 17.67% improvement in Mean Average Precision (MAP) scores in a relation extraction task when compared to a method that does not use entity type information.", "labels": [], "entities": [{"text": "Mean Average Precision (MAP) scores", "start_pos": 35, "end_pos": 70, "type": "METRIC", "confidence": 0.9745767116546631}, {"text": "relation extraction task", "start_pos": 76, "end_pos": 100, "type": "TASK", "confidence": 0.8696074883143107}]}, {"text": "Lastly, the SHERLOCK system () also discovers multihop clauses using typed predicates from web text, but, unlike our RNN approach it employs a Inductive Logic Programming method.", "labels": [], "entities": []}], "datasetContent": [{"text": "In all of our experiments, we set the dimension of the relations, entity and their type embeddings to be 50.", "labels": [], "entities": []}, {"text": "For a fair comparison with our model, which has more number of parameters due to the entity and/or type embeddings, we experiment by varying the dimension of the relation embeddings between 50, 100 and 150 for the baseline model.", "labels": [], "entities": []}, {"text": "We use Adam () for optimization with the default hyperparameter settings.", "labels": [], "entities": []}, {"text": "The models are trained for 15 epochs beyond which we observed overfitting on a held-out development set.", "labels": [], "entities": []}, {"text": "We set l = 7 and k = 5 in our experiments.", "labels": [], "entities": []}, {"text": "We experiment with 12 target relations.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Statistics of the dataset", "labels": [], "entities": []}, {"text": " Table 2: Mean Average Precision scores averaged  over 12 relations. The number in the parentheses  denotes the dimension of the embedding of the rela- tions type in the baseline model.", "labels": [], "entities": [{"text": "Mean Average Precision scores", "start_pos": 10, "end_pos": 39, "type": "METRIC", "confidence": 0.8636713624000549}]}]}