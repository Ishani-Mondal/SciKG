{"title": [], "abstractContent": [{"text": "This paper describes the University of Ed-inburgh's phrase-based and syntax-based submissions to the shared translation tasks of the ACL 2016 First Conference on Machine Translation (WMT16).", "labels": [], "entities": [{"text": "shared translation tasks of the ACL 2016 First Conference on Machine Translation (WMT16)", "start_pos": 101, "end_pos": 189, "type": "TASK", "confidence": 0.8205710132916768}]}, {"text": "We submitted five phrase-based and five syntax-based systems for the news task, plus one phrase-based system for the biomedical task.", "labels": [], "entities": []}], "introductionContent": [{"text": "Edinburgh's submissions to the WMT 2016 news translation task fall into two distinct groups: neural translation systems and statistical translation systems.", "labels": [], "entities": [{"text": "WMT 2016 news translation task", "start_pos": 31, "end_pos": 61, "type": "TASK", "confidence": 0.8103098511695862}, {"text": "neural translation", "start_pos": 93, "end_pos": 111, "type": "TASK", "confidence": 0.7310283184051514}, {"text": "statistical translation", "start_pos": 124, "end_pos": 147, "type": "TASK", "confidence": 0.6844192296266556}]}, {"text": "In this paper, we describe the statistical systems, which includes a mix of phrase-based and syntax-based approaches.", "labels": [], "entities": []}, {"text": "We also include a brief description of our phrase-based submission to the WMT16 biomedical translation task.", "labels": [], "entities": [{"text": "WMT16 biomedical translation task", "start_pos": 74, "end_pos": 107, "type": "TASK", "confidence": 0.8359140753746033}]}, {"text": "Our neural systems are described separately in.", "labels": [], "entities": []}, {"text": "In most cases, our statistical systems build on last year's, incorporating recent modelling refinements and adding this year's new training data.", "labels": [], "entities": []}, {"text": "For Romanian-a new language this year-we paid particular attention to language-specific processing of diacritics.", "labels": [], "entities": []}, {"text": "For English\u2192Czech, we experimented with a string-to-tree system, first using Treex 1 (formerly TectoMT;) to produce Czech dependency parses, then converting them to constituency representation and extracting GHKM rules.", "labels": [], "entities": []}, {"text": "In the next two sections, we describe the phrasebased systems, first describing the core setup in Section 2 and then describing system-specific extensions and experimental results for each individual language pair in Section 3.", "labels": [], "entities": []}, {"text": "We describe the 1 http://ufal.mff.cuni.cz/treex core syntax-based setup and experiments in Sections 4 and 5.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Comparison of different language model  combinations and preprocessing regimes for  Finnish\u2192English and for Romanian\u2192English.  The submitted system is shown in bold. The pre- processing variant uses the same language model  combination as the submitted system. Cased  BLEU scores are on newstest2016.", "labels": [], "entities": [{"text": "Cased", "start_pos": 271, "end_pos": 276, "type": "METRIC", "confidence": 0.9264206886291504}, {"text": "BLEU", "start_pos": 278, "end_pos": 282, "type": "METRIC", "confidence": 0.892096757888794}, {"text": "newstest2016", "start_pos": 297, "end_pos": 309, "type": "DATASET", "confidence": 0.9730837941169739}]}, {"text": " Table 2: Effect of each of the language models  used in the English\u2192Romanian system. The ex- periments are not cumulative, so we first try prun- ing the \"all\" language model, then go back to the  unpruned version and remove each LM in turn, ob- serving the effect. The submitted system used all  four LMs, and the scores shown are uncased BLEU  scores on newstest2016.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 340, "end_pos": 344, "type": "METRIC", "confidence": 0.9965642094612122}, {"text": "newstest2016", "start_pos": 356, "end_pos": 368, "type": "DATASET", "confidence": 0.9576318860054016}]}, {"text": " Table 3: Experimental results with phrase-based systems for German\u2192English and English\u2192German.  We report case-sensitive BLEU scores on each of the newstest2013-2016 test sets.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 122, "end_pos": 126, "type": "METRIC", "confidence": 0.9745007753372192}, {"text": "newstest2013-2016 test sets", "start_pos": 149, "end_pos": 176, "type": "DATASET", "confidence": 0.967447022596995}]}, {"text": " Table 4: Parameter settings for rule composition.  The parameters were relaxed for systems that used  binarization to allow for the increase in tree node  density.", "labels": [], "entities": [{"text": "rule composition", "start_pos": 33, "end_pos": 49, "type": "TASK", "confidence": 0.7362973690032959}]}, {"text": " Table 5. We used hard constraints and re- used the baseline weights (re-tuning did not appear  to give additional gains", "labels": [], "entities": []}, {"text": " Table 5: Translation results on the development  system for English\u2192Czech with unification-based  constraints. Cased BLEU scores are shown. They  are averaged over three tuning runs (note that base- line weights are reused in the experiments with  constraints).", "labels": [], "entities": [{"text": "Translation", "start_pos": 10, "end_pos": 21, "type": "TASK", "confidence": 0.9770292639732361}, {"text": "BLEU", "start_pos": 118, "end_pos": 122, "type": "METRIC", "confidence": 0.9550074934959412}]}, {"text": " Table 6: Translation results on the final system  for English\u2192Czech with unification-based con- straints. Cased BLEU scores are shown. Note  that baseline weights are reused in the experiments  with constraints.", "labels": [], "entities": [{"text": "Translation", "start_pos": 10, "end_pos": 21, "type": "TASK", "confidence": 0.9628422260284424}, {"text": "BLEU", "start_pos": 113, "end_pos": 117, "type": "METRIC", "confidence": 0.9619421362876892}]}, {"text": " Table 8: Translation results of English\u2192German  string-to-tree translation system on dev (news- test2015) and test (newstest2016).", "labels": [], "entities": []}, {"text": " Table 9: Comparison of different preprocessing  and language model regimes for Finnish\u2192English  (syntax-based). Cased BLEU scores are given for  the newstest2015 and newstest2016 test sets, aver- aged over three tuning runs.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 119, "end_pos": 123, "type": "METRIC", "confidence": 0.9342000484466553}, {"text": "newstest2016 test sets", "start_pos": 167, "end_pos": 189, "type": "DATASET", "confidence": 0.8858973582585653}]}, {"text": " Table 10: Translation results of German\u2192English  string-to-tree translation system on dev (news- test2015) and test (newstest2016). *submitted sys- tem.", "labels": [], "entities": []}, {"text": " Table  11:  Translation  results  of  Romanian\u2192English string-to-tree translation  system on dev (half of newsdev2016) and test  (newstest2016). *submitted system.", "labels": [], "entities": [{"text": "Romanian\u2192English string-to-tree translation", "start_pos": 39, "end_pos": 82, "type": "TASK", "confidence": 0.6430796682834625}]}]}