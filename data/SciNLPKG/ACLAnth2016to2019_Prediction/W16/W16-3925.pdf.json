{"title": [{"text": "ASU: An Experimental Study on Applying Deep Learning in Twitter Named Entity Recognition", "labels": [], "entities": [{"text": "ASU", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.8541187047958374}, {"text": "Named Entity Recognition", "start_pos": 64, "end_pos": 88, "type": "TASK", "confidence": 0.5803503493467966}]}], "abstractContent": [{"text": "This paper describes the ASU system submitted in the COLING W-NUT 2016 Twitter Named Entity Recognition (NER) task.", "labels": [], "entities": [{"text": "ASU", "start_pos": 25, "end_pos": 28, "type": "TASK", "confidence": 0.8980835676193237}, {"text": "COLING W-NUT 2016 Twitter Named Entity Recognition (NER) task", "start_pos": 53, "end_pos": 114, "type": "TASK", "confidence": 0.7662393179806796}]}, {"text": "We present an experimental study on applying deep learning to extracting named entities (NEs) from tweets.", "labels": [], "entities": [{"text": "extracting named entities (NEs) from tweets", "start_pos": 62, "end_pos": 105, "type": "TASK", "confidence": 0.844099797308445}]}, {"text": "We built two Long Short-Term Memory (LSTM) models for the task.", "labels": [], "entities": []}, {"text": "The first model was built to extract named entities without types while the second model was built to extract and then classify them into 10 fine-grained entity classes.", "labels": [], "entities": []}, {"text": "In this effort, we show detailed experimentation results on the effectiveness of word embeddings, brown clusters, part-of-speech (POS) tags, shape features, gazetteers, and local context for the tweet input vector representation to the LSTM model.", "labels": [], "entities": []}, {"text": "Also, we present a set of experiments, to better design the network parameters for the Twitter NER task.", "labels": [], "entities": [{"text": "Twitter NER task", "start_pos": 87, "end_pos": 103, "type": "TASK", "confidence": 0.6443122426668803}]}, {"text": "Our system was ranked the fifth out often participants with a final f1-score for the typed classes of 39% and 55% for the non typed ones.", "labels": [], "entities": []}], "introductionContent": [{"text": "The social media dominance, especially Twitter, rapidly drives the text processing technologies for more automated understanding.", "labels": [], "entities": []}, {"text": "Daily, there are billions of short, noisy, user-generated text fragments that represent and summarize the whole world.", "labels": [], "entities": []}, {"text": "Although Natural Language Processing (NLP), in general, is a very challenging task, the importance of automatically processing those huge amounts of big data pushes the technology in dealing with more short and noisy data.", "labels": [], "entities": [{"text": "Natural Language Processing (NLP)", "start_pos": 9, "end_pos": 42, "type": "TASK", "confidence": 0.7859926819801331}]}, {"text": "The open world of social media, like Twitter, makes it easy for NLP researchers to grasp lots of information to present a holistic view of the world as represented by millions of users.", "labels": [], "entities": []}, {"text": "Through NLP research on social media, one can analyze the political polarity of the crowds, identify trending events that attract parts of the world, key people, and hot areas instantaneously, detect emotion storylines and what can lead to or change people's attitudes, identify and collect data in disasters including natural ones to help in risk management, grasp the sentiment against new products or decisions, understand and predict actions based on opinion mining, and many more.", "labels": [], "entities": []}, {"text": "Entity extraction is the basic unit in all these NLP tasks whether to be a singer, president, player, movie, song, or any entity of interest.", "labels": [], "entities": [{"text": "Entity extraction", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.8306950628757477}]}, {"text": "The coarse-grained classes like person, location, and organization are not sufficient fora better representation and understanding of the vibrant world.", "labels": [], "entities": []}, {"text": "That is why the fine-grained NERs are of utmost interest.", "labels": [], "entities": [{"text": "NERs", "start_pos": 29, "end_pos": 33, "type": "TASK", "confidence": 0.8296071290969849}]}, {"text": "Our submission in COLING W-NUT 2016 Named Entity Recognition shared task in Twitter, in its second edition, () relied on an experimental study on applying deep learning to the task.", "labels": [], "entities": [{"text": "COLING W-NUT 2016 Named Entity Recognition shared task", "start_pos": 18, "end_pos": 72, "type": "TASK", "confidence": 0.6828094720840454}]}, {"text": "We experimented with many representations to define the network's input vector.", "labels": [], "entities": []}, {"text": "The contribution of word embeddings (WEs), brown clusters (BCs), POS tags, along list of shape features, vocabulary, and gazetteers was experimentally evaluated in details for the NER task.", "labels": [], "entities": [{"text": "NER task", "start_pos": 180, "end_pos": 188, "type": "TASK", "confidence": 0.9362291693687439}]}, {"text": "In addition, a series of experiments were directed to best tune our network design.", "labels": [], "entities": []}, {"text": "Two different LSTM models were prepared: One for detecting entities regardless of entity type (non typed) and the other was trained for detecting and classifying the entities (typed).", "labels": [], "entities": []}, {"text": "The rest of the paper is organized as follows; In Section 2, we present the data sets available for the task and how we used them in ASU system.", "labels": [], "entities": []}, {"text": "Section 3, illustrates an overview of our system and the process we followed.", "labels": [], "entities": []}, {"text": "In Section 4, we present in details our experimental study in an incremental approach in which we experimented with lots of representations one-by-one and also, with the network parameters.", "labels": [], "entities": []}, {"text": "Finally, we conclude in Section 5.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section, all experiments we conducted are presented with details in how we built our LSTM models: Basically, we have two models.", "labels": [], "entities": []}, {"text": "One for the non typed extractions and the other for the typed ones which work on ten entity classes.", "labels": [], "entities": []}, {"text": "illustrates our experimentation efforts for the typed model while summarizes the history of the non typed model.", "labels": [], "entities": []}, {"text": "We plot the f1-scores of the overall system on the training and the development sets for both models.", "labels": [], "entities": []}, {"text": "Each experiment in the figures is given an integer identifier which will also be used in the following subsections.", "labels": [], "entities": []}, {"text": "While we report the progress in the coming subsections, we preserved the best system as the first record in each table for reference.", "labels": [], "entities": []}, {"text": "Also, we appended the index for the previous experiment on which we based the new experiment.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: W-NUT 2016 Twitter NER Data Sets Statistics.", "labels": [], "entities": [{"text": "W-NUT 2016 Twitter NER Data Sets Statistics", "start_pos": 10, "end_pos": 53, "type": "DATASET", "confidence": 0.7662354579993657}]}, {"text": " Table 2: POS Tags in ASU for Typed/Non Typed Models on the Training/Dev. Sets.", "labels": [], "entities": [{"text": "Training/Dev. Sets", "start_pos": 60, "end_pos": 78, "type": "DATASET", "confidence": 0.6391948819160461}]}, {"text": " Table 3: Brown Clusters in ASU for Typed/Non Typed Models on the Training/Dev. Sets.", "labels": [], "entities": [{"text": "ASU", "start_pos": 28, "end_pos": 31, "type": "DATASET", "confidence": 0.7079319357872009}, {"text": "Training/Dev. Sets", "start_pos": 66, "end_pos": 84, "type": "DATASET", "confidence": 0.638760632276535}]}, {"text": " Table 4: Word Embeddings in ASU for Typed/Non Typed Models on the Training/Dev. Sets.", "labels": [], "entities": [{"text": "Training/Dev. Sets", "start_pos": 67, "end_pos": 85, "type": "DATASET", "confidence": 0.6221267998218536}]}, {"text": " Table 5: Shape Features in ASU for Typed/Non Typed Models on the Training/Dev. Sets.", "labels": [], "entities": [{"text": "Training/Dev. Sets", "start_pos": 66, "end_pos": 84, "type": "DATASET", "confidence": 0.6160950303077698}]}, {"text": " Table 6: Non Entity Features in ASU for Typed/Non Typed Models on the Training/Dev. Sets.", "labels": [], "entities": [{"text": "Training/Dev. Sets", "start_pos": 71, "end_pos": 89, "type": "DATASET", "confidence": 0.5942536473274231}]}, {"text": " Table 7: Vocabulary in ASU for Typed/Non Typed Models on the Training/Dev. Sets.", "labels": [], "entities": [{"text": "ASU", "start_pos": 24, "end_pos": 27, "type": "TASK", "confidence": 0.6176508069038391}, {"text": "Training/Dev. Sets", "start_pos": 62, "end_pos": 80, "type": "DATASET", "confidence": 0.6150113463401794}]}, {"text": " Table 8: Embedding Layer Size Tuning in ASU for Typed/Non Typed Models on the Training/Dev. Sets.", "labels": [], "entities": [{"text": "Embedding Layer Size Tuning", "start_pos": 10, "end_pos": 37, "type": "TASK", "confidence": 0.7223150134086609}, {"text": "Training/Dev. Sets", "start_pos": 79, "end_pos": 97, "type": "DATASET", "confidence": 0.6155469417572021}]}, {"text": " Table 9: Hidden Layer Size Tuning in ASU for Typed/Non Typed Models on the Training/Dev. Sets.", "labels": [], "entities": [{"text": "Training/Dev. Sets", "start_pos": 76, "end_pos": 94, "type": "DATASET", "confidence": 0.6349947392940521}]}, {"text": " Table 10: Number of Hidden Layers Tuning in ASU for Typed/Non Typed Models on the Training/Dev.  Sets.", "labels": [], "entities": [{"text": "Training/Dev.  Sets", "start_pos": 83, "end_pos": 102, "type": "DATASET", "confidence": 0.6268336653709412}]}, {"text": " Table 11: Number of Epochs Tuning in ASU for Typed/Non Typed Models on the Training/Dev. Sets.", "labels": [], "entities": [{"text": "ASU", "start_pos": 38, "end_pos": 41, "type": "DATASET", "confidence": 0.6660380363464355}, {"text": "Training/Dev. Sets", "start_pos": 76, "end_pos": 94, "type": "DATASET", "confidence": 0.6464659571647644}]}, {"text": " Table 12: Gazetteers in ASU for Typed/Non Typed Models on the Training/Dev. Sets..", "labels": [], "entities": [{"text": "ASU", "start_pos": 25, "end_pos": 28, "type": "DATASET", "confidence": 0.579740047454834}, {"text": "Training/Dev. Sets.", "start_pos": 63, "end_pos": 82, "type": "DATASET", "confidence": 0.6710660755634308}]}, {"text": " Table 13. We report our final precision, recall, and f1-score  on the training, development, and the testing sets. After we tuned the two models, we appended the  training and development sets to act as a new training set for our final model which was used in the final  submission as detailed in Section 2.", "labels": [], "entities": [{"text": "precision", "start_pos": 31, "end_pos": 40, "type": "METRIC", "confidence": 0.9973973035812378}, {"text": "recall", "start_pos": 42, "end_pos": 48, "type": "METRIC", "confidence": 0.9988106489181519}, {"text": "f1-score", "start_pos": 54, "end_pos": 62, "type": "METRIC", "confidence": 0.9940555095672607}]}, {"text": " Table 13: Results of ASU System on Training, Development, and Testing Set.", "labels": [], "entities": [{"text": "ASU", "start_pos": 22, "end_pos": 25, "type": "TASK", "confidence": 0.6717260479927063}]}]}