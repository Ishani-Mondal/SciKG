{"title": [], "abstractContent": [{"text": "In this paper we present our approach to the Bilingual Document Alignment Task (WMT16), where the main goal was to reach the best recall on extracting aligned pages within the provided data.", "labels": [], "entities": [{"text": "Bilingual Document Alignment Task (WMT16)", "start_pos": 45, "end_pos": 86, "type": "TASK", "confidence": 0.7884925433567592}, {"text": "recall", "start_pos": 130, "end_pos": 136, "type": "METRIC", "confidence": 0.9988168478012085}]}, {"text": "Our approach consists of tree main parts: data preprocessing, keyword extraction and text pairs scoring based on keyword matching.", "labels": [], "entities": [{"text": "keyword extraction", "start_pos": 62, "end_pos": 80, "type": "TASK", "confidence": 0.8413934707641602}]}, {"text": "For text preprocessing we use the Tree-Tagger pipeline that contains the Unitok tool (Michelfeit et al., 2014) for tokeniza-tion and the TreeTagger morphological an-alyzer (Schmid, 1994).", "labels": [], "entities": [{"text": "text preprocessing", "start_pos": 4, "end_pos": 22, "type": "TASK", "confidence": 0.7294611632823944}]}, {"text": "After keywords extraction from the texts according TF-IDF scoring our system searches for comparable English-French pairs.", "labels": [], "entities": []}, {"text": "Using a statistical dictionary created from a large English-French parallel corpus , the system is able to find comaparable documents.", "labels": [], "entities": []}, {"text": "At the end this procedure is combined with the baseline algorithm and best one-to-one pairing is selected.", "labels": [], "entities": []}, {"text": "The result reaches 91.6% recall on provided training data.", "labels": [], "entities": [{"text": "recall", "start_pos": 25, "end_pos": 31, "type": "METRIC", "confidence": 0.9986639022827148}]}, {"text": "After a deep error analysis (see section 5) the recall reached 97.4%.", "labels": [], "entities": [{"text": "recall", "start_pos": 48, "end_pos": 54, "type": "METRIC", "confidence": 0.9994539618492126}]}], "introductionContent": [{"text": "In this paper we describe our approach to solve the Bilingual Document Alignment Task (WMT16).", "labels": [], "entities": [{"text": "Bilingual Document Alignment Task (WMT16)", "start_pos": 52, "end_pos": 93, "type": "TASK", "confidence": 0.8302006295749119}]}, {"text": "It consists of tree main parts: data preprocessing, keyword extraction and text pairs scoring based on keyword matching.", "labels": [], "entities": [{"text": "keyword extraction", "start_pos": 52, "end_pos": 70, "type": "TASK", "confidence": 0.8241991400718689}]}, {"text": "According to these steps, the text is divided into three main sections.", "labels": [], "entities": []}, {"text": "Section 2 describes the data preprocessing that was crucial for key-word extraction.", "labels": [], "entities": [{"text": "key-word extraction", "start_pos": 64, "end_pos": 83, "type": "TASK", "confidence": 0.8272767961025238}]}, {"text": "In the next section we describe the keyword extraction process, and Section 4 describes scoring of comparable English-French pairs.", "labels": [], "entities": [{"text": "keyword extraction", "start_pos": 36, "end_pos": 54, "type": "TASK", "confidence": 0.8562349379062653}]}, {"text": "The final results on the training data are summarized in Section 5 where we also discuss errors of our system and problematic features of the provided data.", "labels": [], "entities": []}], "datasetContent": [{"text": "The goal of this task was to find English-French URL pairs.", "labels": [], "entities": []}, {"text": "Some training pairs were provided by authors of this task.", "labels": [], "entities": []}, {"text": "Our procedure does not include any learning from the training data, therefore we can use them for quite a reliable evaluation.", "labels": [], "entities": []}, {"text": "With regard to that data, our solution reached 91.6% recall, using the most successful TF-IDF equation 3; the results for the other equations are comparable and are summarized in.", "labels": [], "entities": [{"text": "recall", "start_pos": 53, "end_pos": 59, "type": "METRIC", "confidence": 0.9987896084785461}]}, {"text": "If we did not include the baseline algorithm into the procedure, the recall was 82%.", "labels": [], "entities": [{"text": "recall", "start_pos": 69, "end_pos": 75, "type": "METRIC", "confidence": 0.9997654557228088}]}, {"text": "After a detailed error analysis we found out that the provided data contain duplicate web pages with different URLs.", "labels": [], "entities": []}, {"text": "This is an important problem -our error analysis shows that we have found: Overall results according to \"keyness\" Equations a correct document pair in many cases, but a document with a different URL (and identical text) was marked as correct in the data.", "labels": [], "entities": []}, {"text": "We went through the document pairs marked as errors of our algorithm and manually evaluated them for correctness.", "labels": [], "entities": []}, {"text": "If we exclude the false errors (correct document pairs evaluated as incorrect), the recall is 97.4%.", "labels": [], "entities": [{"text": "recall", "start_pos": 84, "end_pos": 90, "type": "METRIC", "confidence": 0.999751627445221}]}, {"text": "Some examples of these URL pairs are given in -as we can see, in many cases the duplicity is clear directly from the URL.", "labels": [], "entities": []}, {"text": "Unfortunately, we were unable to assess the number of duplicates in the data by the submission deadline.", "labels": [], "entities": []}, {"text": "However, we believe it will be done, as the mentioned duplicates significantly reduce the soundness of such evaluation.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Overall results according to \"keyness\"  Equations", "labels": [], "entities": [{"text": "keyness\"  Equations", "start_pos": 40, "end_pos": 59, "type": "METRIC", "confidence": 0.5735969940821329}]}]}