{"title": [{"text": "LABDA at the 2016 BioASQ challenge task 4a: Semantic Indexing by using ElasticSearch", "labels": [], "entities": [{"text": "BioASQ challenge task 4a", "start_pos": 18, "end_pos": 42, "type": "TASK", "confidence": 0.6662033200263977}, {"text": "Semantic Indexing", "start_pos": 44, "end_pos": 61, "type": "TASK", "confidence": 0.7169025242328644}]}], "abstractContent": [{"text": "This paper describes the participation of LABDA team in the 2016 BioASQ Task 4a on large-scale online biomedical semantic indexing.", "labels": [], "entities": [{"text": "large-scale online biomedical semantic indexing", "start_pos": 83, "end_pos": 130, "type": "TASK", "confidence": 0.5715132415294647}]}, {"text": "Our approach is based on the use of the open source search engine ElasticSearch.", "labels": [], "entities": []}, {"text": "Experimental results show that our approach achieves high recall while keeping processing time low.", "labels": [], "entities": [{"text": "recall", "start_pos": 58, "end_pos": 64, "type": "METRIC", "confidence": 0.9995597004890442}]}, {"text": "Although more work needs to be done to improve our results, we can conclude that ElasticSearch is a competitive and scalable system for indexing biomedical literature.", "labels": [], "entities": [{"text": "indexing biomedical literature", "start_pos": 136, "end_pos": 166, "type": "TASK", "confidence": 0.8925630450248718}]}], "introductionContent": [{"text": "Biomedical Natural Language Processing (BioNLP) has made great advances in the last decade thanks to different community-wide challenge evaluations, such as BioCreative (, BioNLP shared tasks), i2b2) DDIExtraction (, etc.", "labels": [], "entities": [{"text": "Biomedical Natural Language Processing (BioNLP)", "start_pos": 0, "end_pos": 47, "type": "TASK", "confidence": 0.7273431760924203}, {"text": "BioCreative", "start_pos": 157, "end_pos": 168, "type": "METRIC", "confidence": 0.7234615087509155}]}, {"text": "While most of them have pursued the further development of research on informations extraction tasks, the BioASQ Challenge 1 focuses on biomedical semantic indexing and question answering fields.", "labels": [], "entities": [{"text": "informations extraction tasks", "start_pos": 71, "end_pos": 100, "type": "TASK", "confidence": 0.8002126812934875}, {"text": "biomedical semantic indexing", "start_pos": 136, "end_pos": 164, "type": "TASK", "confidence": 0.6531891326109568}, {"text": "question answering", "start_pos": 169, "end_pos": 187, "type": "TASK", "confidence": 0.8194477558135986}]}, {"text": "Biomedical Semantic Indexing is to identify the MeSH categories that best describe a PubMed article and is a crucial task to facilitate literature search.", "labels": [], "entities": [{"text": "Biomedical Semantic Indexing", "start_pos": 0, "end_pos": 28, "type": "TASK", "confidence": 0.814910372098287}]}, {"text": "This process is manually performed by human experts, thus becoming a costly, time-consuming and laborious task).", "labels": [], "entities": []}, {"text": "Therefore there is an urgent need to explore automatic methods to support this task.", "labels": [], "entities": []}, {"text": "As in previous editions, BioASQ 2016 consists of two 1 http://www.bioasq.org/ different tasks: large-scale online biomedical semantic indexing (Task 4a) and question answering).", "labels": [], "entities": [{"text": "large-scale online biomedical semantic indexing", "start_pos": 95, "end_pos": 142, "type": "TASK", "confidence": 0.6084322452545166}, {"text": "question answering", "start_pos": 157, "end_pos": 175, "type": "TASK", "confidence": 0.8719736635684967}]}, {"text": "This paper describes our participation in Task 4a.", "labels": [], "entities": []}, {"text": "The goal of the task is to automatically predict the most relevant MeSH labels fora given document.", "labels": [], "entities": []}, {"text": "One of the major challenges of the task is to manage scalability due to the great amount of documents that have to be indexed.", "labels": [], "entities": []}, {"text": "More than 750,000 articles were added in 2014 with a load of 2000-4000 documents per day.", "labels": [], "entities": []}, {"text": "Search systems such as ElasticSearch, an open source search engine, could be adequate frameworks to cope with this information overload problem.", "labels": [], "entities": []}, {"text": "To the best of our knowledge, this is the first work that addresses semantic indexing by using ElasticSearch.", "labels": [], "entities": [{"text": "semantic indexing", "start_pos": 68, "end_pos": 85, "type": "TASK", "confidence": 0.7523948550224304}]}, {"text": "Due to the horizontal scalability provided by ElasticSearch, it is possible to index large collections of documents, as is the case of the Medline/PubMed database with more than 22 million citations to date.", "labels": [], "entities": [{"text": "Medline/PubMed database", "start_pos": 139, "end_pos": 162, "type": "DATASET", "confidence": 0.9075291603803635}]}, {"text": "Our approach is to index the training set provided by the BioASQ organizers with ElasticSearch.", "labels": [], "entities": [{"text": "BioASQ organizers", "start_pos": 58, "end_pos": 75, "type": "DATASET", "confidence": 0.7819771468639374}]}, {"text": "Then, each document in the test set is translated into a query, that is fired against the index built from the training set, returning the most relevant documents and their MeSH categories.", "labels": [], "entities": []}, {"text": "Finally, each MeSH category is ranked using a scoring system based on the frequency of the category and the similarity of relevant documents, which contain the category, with the test document to classify.", "labels": [], "entities": []}, {"text": "Up to date at which we write this paper, no official definitive results have been published for any of our submissions yet.", "labels": [], "entities": []}, {"text": "To evaluate our approach, we generated our own development set from a random sample of 1099 training documents.", "labels": [], "entities": []}, {"text": "To avoid any potential bias, these documents were removed from the training set.", "labels": [], "entities": []}, {"text": "Tested on this development set, our approach achieves a recall of 80.6%, precision of 45.4% and an F1 of 56.3%.", "labels": [], "entities": [{"text": "recall", "start_pos": 56, "end_pos": 62, "type": "METRIC", "confidence": 0.9997959733009338}, {"text": "precision", "start_pos": 73, "end_pos": 82, "type": "METRIC", "confidence": 0.9997896552085876}, {"text": "F1", "start_pos": 99, "end_pos": 101, "type": "METRIC", "confidence": 0.9998278617858887}]}, {"text": "In comparison to the Medical Text Indexer (MTI), which is considered the baseline system of the task, our system does not only provide an improvement of more than 1% in F1, but also has a much better time response (15 seconds per document) than the MTI system (30-45 seconds per document).", "labels": [], "entities": [{"text": "Medical Text Indexer (MTI)", "start_pos": 21, "end_pos": 47, "type": "TASK", "confidence": 0.6263728737831116}, {"text": "F1", "start_pos": 169, "end_pos": 171, "type": "METRIC", "confidence": 0.9980524778366089}, {"text": "time response", "start_pos": 200, "end_pos": 213, "type": "METRIC", "confidence": 0.8688693940639496}]}, {"text": "The rest of the paper is organized as follows: related work is presented in Section 2.", "labels": [], "entities": []}, {"text": "Section 3 presents a description of our method and the datasets used in this study.", "labels": [], "entities": []}, {"text": "Then, we report and discuss some preliminary results of our approach in section 4.", "labels": [], "entities": []}, {"text": "Finally, section 5 presents conclusion and future work.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 2: Experimental results on the test batch 3, week 5 (Annotated articles:302/3130).", "labels": [], "entities": [{"text": "Annotated", "start_pos": 60, "end_pos": 69, "type": "METRIC", "confidence": 0.9809108972549438}]}]}