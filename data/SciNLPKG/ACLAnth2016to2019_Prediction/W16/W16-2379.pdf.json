{"title": [], "abstractContent": [{"text": "This paper presents an automatic post-editing (APE) method to improve the translation quality produced by an English-German (EN-DE) statistical machine translation (SMT) system.", "labels": [], "entities": [{"text": "English-German (EN-DE) statistical machine translation (SMT)", "start_pos": 109, "end_pos": 169, "type": "TASK", "confidence": 0.7074435830116272}]}, {"text": "Our system is based on Operation Sequential Model (OSM) combined with phrased-based statistical MT (PB-SMT) system.", "labels": [], "entities": []}, {"text": "The system is trained on monolingual settings between MT outputs (T L M T) produced by a black-box MT system and their corresponding post-edited version (T LP E).", "labels": [], "entities": [{"text": "MT", "start_pos": 54, "end_pos": 56, "type": "TASK", "confidence": 0.9535918235778809}]}, {"text": "Our system achieves considerable improvement over T L MT on a held-out development set.", "labels": [], "entities": [{"text": "T L MT", "start_pos": 50, "end_pos": 56, "type": "TASK", "confidence": 0.5266767740249634}]}, {"text": "The reported system achieves 64.10 BLEU (1.99 absolute points and 3.2% relative improvement in BLEU over raw MT output) and 24.14 TER and a TER score of 24.14 (0.66 absolute points and 0.25% relative improvement in TER over raw MT output) in the official test set.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 35, "end_pos": 39, "type": "METRIC", "confidence": 0.9994255304336548}, {"text": "BLEU", "start_pos": 95, "end_pos": 99, "type": "METRIC", "confidence": 0.9988940358161926}, {"text": "TER", "start_pos": 130, "end_pos": 133, "type": "METRIC", "confidence": 0.9991551637649536}, {"text": "TER score", "start_pos": 140, "end_pos": 149, "type": "METRIC", "confidence": 0.9833483397960663}, {"text": "TER", "start_pos": 215, "end_pos": 218, "type": "METRIC", "confidence": 0.984338104724884}]}], "introductionContent": [{"text": "Translations produced by machine translation (MT) systems have improved substantially over the past few decades.", "labels": [], "entities": [{"text": "Translations", "start_pos": 0, "end_pos": 12, "type": "TASK", "confidence": 0.952262282371521}, {"text": "machine translation (MT)", "start_pos": 25, "end_pos": 49, "type": "TASK", "confidence": 0.8249563992023468}]}, {"text": "This is particularly noticeable for some language pairs (e.g. English to German and English to French) and for domain specific language (e.g. technical documentation).", "labels": [], "entities": []}, {"text": "Texts produced by MT systems are now widely used in the translation and localization industry.", "labels": [], "entities": [{"text": "MT", "start_pos": 18, "end_pos": 20, "type": "TASK", "confidence": 0.9461238980293274}, {"text": "translation", "start_pos": 56, "end_pos": 67, "type": "TASK", "confidence": 0.9798145890235901}]}, {"text": "MT output is post-edited by professional translators and it has become an important part of the translation workflow.", "labels": [], "entities": [{"text": "MT output", "start_pos": 0, "end_pos": 9, "type": "TASK", "confidence": 0.8794188499450684}, {"text": "translation workflow", "start_pos": 96, "end_pos": 116, "type": "TASK", "confidence": 0.8899239301681519}]}, {"text": "A number of studies confirm that post-editing MT output improves translators' performance in terms of productivity and it may also impact translation quality and consistency.", "labels": [], "entities": [{"text": "MT output", "start_pos": 46, "end_pos": 55, "type": "TASK", "confidence": 0.8913503885269165}, {"text": "consistency", "start_pos": 162, "end_pos": 173, "type": "METRIC", "confidence": 0.9589033126831055}]}, {"text": "With this respect the ultimate goal of MT systems is to provide output that can be post-edited with the least effort as possible by human translators.", "labels": [], "entities": [{"text": "MT", "start_pos": 39, "end_pos": 41, "type": "TASK", "confidence": 0.9923396110534668}]}, {"text": "One of the strategies to improve MT output is to apply automatic post-editing (APE) methods).", "labels": [], "entities": [{"text": "MT output", "start_pos": 33, "end_pos": 42, "type": "TASK", "confidence": 0.9000199437141418}]}, {"text": "APE methods work under the assumption that some errors in MT systems are recurrent and they can be corrected automatically in a post-processing stage thus providing output that is more adequate to be post-edited.", "labels": [], "entities": [{"text": "APE", "start_pos": 0, "end_pos": 3, "type": "TASK", "confidence": 0.7715476155281067}, {"text": "MT", "start_pos": 58, "end_pos": 60, "type": "TASK", "confidence": 0.9753575921058655}]}, {"text": "APE methods are applied before human post-editing increasing translators' productivity.", "labels": [], "entities": []}, {"text": "This paper presents anew approach to APE which was submitted by the USAAR team to the Automatic Post-editing (APE) shared task at WMT-2016.", "labels": [], "entities": [{"text": "APE", "start_pos": 37, "end_pos": 40, "type": "TASK", "confidence": 0.9527781009674072}, {"text": "USAAR team", "start_pos": 68, "end_pos": 78, "type": "DATASET", "confidence": 0.9617317914962769}, {"text": "Automatic Post-editing (APE) shared task at WMT-2016", "start_pos": 86, "end_pos": 138, "type": "TASK", "confidence": 0.6172453363736471}]}, {"text": "Our system combines two models: monolingual phrase-based and operation sequential model with an edit distance based word alignment between an English-German (EN-DE) Machine translation output and the corresponding human post-edited version of German Translation (.", "labels": [], "entities": []}, {"text": "Usually APE tasks focus on fluency errors produced by the MT system.", "labels": [], "entities": [{"text": "APE tasks", "start_pos": 8, "end_pos": 17, "type": "TASK", "confidence": 0.8804534375667572}, {"text": "MT", "start_pos": 58, "end_pos": 60, "type": "TASK", "confidence": 0.9407751560211182}]}, {"text": "The most frequent ones are incorrect lexical choices, incorrect word ordering, the insertion of a word, the deletion of a word.", "labels": [], "entities": [{"text": "word ordering", "start_pos": 64, "end_pos": 77, "type": "TASK", "confidence": 0.672632172703743}]}, {"text": "For the WMT2016 APE task, in order to automatically post-editing, we adopt operation sequential model (OSM) for SMT to build our Statistical APE (SAPE) System.", "labels": [], "entities": [{"text": "WMT2016 APE task", "start_pos": 8, "end_pos": 24, "type": "TASK", "confidence": 0.69151504834493}, {"text": "SMT", "start_pos": 112, "end_pos": 115, "type": "TASK", "confidence": 0.9895983934402466}, {"text": "Statistical APE (SAPE)", "start_pos": 129, "end_pos": 151, "type": "TASK", "confidence": 0.7092986762523651}]}, {"text": "We inspired from the work of and.", "labels": [], "entities": []}, {"text": "Since, in OSM model, the translation and reordering operations are coupled in a single generative story: the reordering decisions may depend on preceding translation decisions and translation decisions may depend on preceding reordering decisions.", "labels": [], "entities": []}, {"text": "The model provides a natural re-ordering mechanism and deal with both local and long-distance re-orderings consistently.", "labels": [], "entities": []}, {"text": "The remainder of the paper is organized as follows.", "labels": [], "entities": []}, {"text": "Section 2 describes our proposed system, in particular PB-SMT coupled OSM model.", "labels": [], "entities": []}, {"text": "In Section 3, we outline the data used for experiments and complete experimental setup.", "labels": [], "entities": []}, {"text": "Section 4 presents the results of the automatic evaluation, followed by conclusion and future work in Section 5.", "labels": [], "entities": []}], "datasetContent": [{"text": "The effectiveness of the present work is demonstrated by using the standard log-linear PB-SMT model for our phrase based SAPE (PB-SAPE) model.", "labels": [], "entities": []}, {"text": "The MT outputs are provided by WMT-2016 APE task (c.f) are considered as baseline system translation.", "labels": [], "entities": [{"text": "MT", "start_pos": 4, "end_pos": 6, "type": "TASK", "confidence": 0.9754897356033325}, {"text": "WMT-2016 APE task", "start_pos": 31, "end_pos": 48, "type": "DATASET", "confidence": 0.8172971407572428}, {"text": "system translation", "start_pos": 82, "end_pos": 100, "type": "TASK", "confidence": 0.7234373986721039}]}, {"text": "For building our SAPE system, we experimented with various maximum phrase lengths for the translation model and n-gram settings for the language model.", "labels": [], "entities": []}, {"text": "We found that using a maximum phrase length of 10 for the translation model and a 6-gram language model produces the best results in terms of BLEU () scores for our SAPE model.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 142, "end_pos": 146, "type": "METRIC", "confidence": 0.9992905855178833}]}, {"text": "The other experimental settings were concerned with word alignment model between T L MT and T LP E are trained on three different aligners: Berkeley Aligner (), METEOR aligner ( and TER ().", "labels": [], "entities": [{"text": "word alignment", "start_pos": 52, "end_pos": 66, "type": "TASK", "confidence": 0.8139052987098694}, {"text": "METEOR", "start_pos": 161, "end_pos": 167, "type": "METRIC", "confidence": 0.9172682762145996}, {"text": "TER", "start_pos": 182, "end_pos": 185, "type": "METRIC", "confidence": 0.9540477395057678}]}, {"text": "The phraseextraction () and hierarchical phrase-extraction () are used to build our PB-SAPE and hierarchical phrase-based statistical (HPB-SAPE) system respectively.", "labels": [], "entities": []}, {"text": "The reordering model was trained with the hierarchical, monotone, swap, left to right bidirectional (hiermslr-bidirectional) method ( and conditioned on both source and target language.", "labels": [], "entities": []}, {"text": "The 5-gram target language model was trained using KenLM.", "labels": [], "entities": [{"text": "KenLM", "start_pos": 51, "end_pos": 56, "type": "METRIC", "confidence": 0.5577716827392578}]}, {"text": "Phrase pairs that occur only once in the training data are assigned an unduly high probability mass (i.e. 1).", "labels": [], "entities": []}, {"text": "To compensate this shortcoming, we performed smoothing of the phrase table using the GoodTuring smoothing technique).", "labels": [], "entities": []}, {"text": "System tuning was carried out using Minimum Error Rate Training (MERT) optimized with k-best MIRA (Cherry and Foster, 2012) on a held out development set of size 500 sentences randomly extracted from training data.", "labels": [], "entities": [{"text": "Minimum Error Rate Training (MERT)", "start_pos": 36, "end_pos": 70, "type": "METRIC", "confidence": 0.8038930169173649}, {"text": "MIRA", "start_pos": 93, "end_pos": 97, "type": "METRIC", "confidence": 0.9406062960624695}]}, {"text": "Therefore, all model has been build on 11,500 parallel T L MT -T LP E sentences.", "labels": [], "entities": [{"text": "MT -T LP E", "start_pos": 59, "end_pos": 69, "type": "DATASET", "confidence": 0.6710444450378418}]}, {"text": "After the parameters were tuned, decoding was carried out on the held out development test set ('Dev' in) as well as test set.", "labels": [], "entities": []}, {"text": "presents the statistics of the training, development and test sets released for the English-German APE Task organized in WMT-2016.", "labels": [], "entities": [{"text": "APE Task organized in WMT-2016", "start_pos": 99, "end_pos": 129, "type": "DATASET", "confidence": 0.66907799243927}]}, {"text": "These data sets did not require any preprocessing in terms of encoding or alignment.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Systematic Evaluation on the WMT-2016 APE Shared Task Development Set", "labels": [], "entities": [{"text": "WMT-2016 APE Shared Task Development", "start_pos": 39, "end_pos": 75, "type": "TASK", "confidence": 0.5357749819755554}]}, {"text": " Table 3: Evaluation on the WMT-2016 APE  Shared Task Test Set", "labels": [], "entities": [{"text": "WMT-2016 APE  Shared Task Test Set", "start_pos": 28, "end_pos": 62, "type": "DATASET", "confidence": 0.6736844182014465}]}]}