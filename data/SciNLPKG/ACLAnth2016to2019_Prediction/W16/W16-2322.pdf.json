{"title": [], "abstractContent": [{"text": "This paper presents the systems submitted by the Abu-MaTran project to the English-to-Finnish language pair at the WMT 2016 news translation task.", "labels": [], "entities": [{"text": "WMT 2016 news translation task", "start_pos": 115, "end_pos": 145, "type": "TASK", "confidence": 0.7462664425373078}]}, {"text": "We applied morphological segmentation and deep learning in order to address (i) the data scarcity problem caused by the lack of in-domain parallel data in the constrained task and (ii) the complex morphology of Finnish.", "labels": [], "entities": [{"text": "morphological segmentation", "start_pos": 11, "end_pos": 37, "type": "TASK", "confidence": 0.7671234607696533}]}, {"text": "We submitted a neural machine translation system, a statistical machine translation system reranked with a neural language model and the combination of their outputs tuned on character sequences.", "labels": [], "entities": [{"text": "neural machine translation", "start_pos": 15, "end_pos": 41, "type": "TASK", "confidence": 0.6964757243792216}, {"text": "statistical machine translation", "start_pos": 52, "end_pos": 83, "type": "TASK", "confidence": 0.6587370832761129}]}, {"text": "The combination and the neural system were ranked first and second respectively according to automatic evaluation metrics and tied for the first place in the human evaluation.", "labels": [], "entities": []}], "introductionContent": [{"text": "This paper presents the machine translation (MT) systems submitted by the Abu-MaTran project to the WMT 2016 news translation task.", "labels": [], "entities": [{"text": "machine translation (MT)", "start_pos": 24, "end_pos": 48, "type": "TASK", "confidence": 0.8187478363513947}, {"text": "WMT 2016 news translation task", "start_pos": 100, "end_pos": 130, "type": "TASK", "confidence": 0.8315820813179016}]}, {"text": "We participated in the English-to-Finnish constrained task.", "labels": [], "entities": []}, {"text": "English-to-Finnish is a particularly challenging language pair for corpus-based MT because of the lack of in-domain parallel data (the only available parallel corpus in the shared task is Europarl) and the complex morphology of Finnish.", "labels": [], "entities": [{"text": "MT", "start_pos": 80, "end_pos": 82, "type": "TASK", "confidence": 0.9308221340179443}, {"text": "Europarl", "start_pos": 188, "end_pos": 196, "type": "DATASET", "confidence": 0.9576608538627625}]}, {"text": "The fact that the same root can be inflected in many different ways and that nouns can be joined together in order to build compound words exacerbates the aforementioned lack of parallel data problem.", "labels": [], "entities": []}, {"text": "As in our last year's submission (, we used morphological segmentation on the Finnish side in order to deal with data scarcity and reduce the size of the Finnish vocabulary.", "labels": [], "entities": []}, {"text": "We also used character-level evaluation metrics during the development of our systems, which correlate better than word-based ones with human judgements according to the results of last year's metrics shared task for English-to-Finnish.", "labels": [], "entities": []}, {"text": "When a Finnish sentence is morphologically segmented, it becomes much longer (number of tokens) than its English counterpart.", "labels": [], "entities": []}, {"text": "This results in the distance between the Finnish tokens that depend on each other to produce a correct translation increasing too.", "labels": [], "entities": []}, {"text": "We addressed this potential issue by introducing deep learning in our systems: we submitted a neural MT (NMT) system and a phrase-based statistical MT (SMT) system enhanced with a neural language model (LM).", "labels": [], "entities": [{"text": "phrase-based statistical MT (SMT)", "start_pos": 123, "end_pos": 156, "type": "TASK", "confidence": 0.6909171144167582}]}, {"text": "In the latter, we reduced the length of the Finnish segmented sentences by joining the most frequent sequences of morphs.", "labels": [], "entities": []}, {"text": "We also submitted a system that combines the outputs of our best NMT and SMT systems and is tuned on character sequences.", "labels": [], "entities": [{"text": "SMT", "start_pos": 73, "end_pos": 76, "type": "TASK", "confidence": 0.8529824614524841}]}, {"text": "The paper is organised as follows: the data and tools used are described in Section 2, while our NMT, SMT and combined submissions are presented respectively in sections 3, 4 and 5.", "labels": [], "entities": [{"text": "NMT", "start_pos": 97, "end_pos": 100, "type": "DATASET", "confidence": 0.7683069705963135}, {"text": "SMT", "start_pos": 102, "end_pos": 105, "type": "TASK", "confidence": 0.8532636165618896}]}, {"text": "The paper ends with some concluding remarks.", "labels": [], "entities": []}], "datasetContent": [{"text": "We preprocessed the training corpora with scripts included in the Moses toolkit (.", "labels": [], "entities": []}, {"text": "We performed the following operations: punctuation normalisation, tokenisation, true-casing and escaping of problematic characters.", "labels": [], "entities": [{"text": "punctuation normalisation", "start_pos": 39, "end_pos": 64, "type": "TASK", "confidence": 0.8631109595298767}, {"text": "tokenisation", "start_pos": 66, "end_pos": 78, "type": "TASK", "confidence": 0.969331681728363}]}, {"text": "The truecaser is lexicon-based and it was trained on all the monolingual data.", "labels": [], "entities": []}, {"text": "In addition, we removed sentence pairs from the parallel corpora where either side is longer than 80 tokens.: English monolingual data, after preprocessing, used to train the LM of the Finnish-toEnglish SMT system we used to backtranslate the Finnish News Crawl monolingual corpora into English (see Section 3).", "labels": [], "entities": [{"text": "SMT", "start_pos": 203, "end_pos": 206, "type": "TASK", "confidence": 0.7020471096038818}, {"text": "Finnish News Crawl monolingual corpora", "start_pos": 243, "end_pos": 281, "type": "DATASET", "confidence": 0.8051752805709839}]}, {"text": "The last filtering is necessary because it is relatively common in the corpus to find the same sentence with some segment missing at the end.", "labels": [], "entities": []}, {"text": "If these lines were kept, n-gram counts from which LM probabilities are estimated would be less reliable.", "labels": [], "entities": []}, {"text": "As a result of these preprocessing steps, around 43 million sentences were removed.", "labels": [], "entities": []}, {"text": "shows the Finnish monolingual corpora we used together with their size and shows the same information for the parallel corpora.", "labels": [], "entities": []}, {"text": "We used an additional synthetic parallel corpus to train our NMT system, which was obtained by backtranslating the Finnish News Crawl corpora into English with an SMT system (see Section 3).", "labels": [], "entities": [{"text": "Finnish News Crawl corpora", "start_pos": 115, "end_pos": 141, "type": "DATASET", "confidence": 0.8555008918046951}]}, {"text": "The monolingual corpora used for training its LM are listed in.", "labels": [], "entities": []}, {"text": "Throughout the paper we evaluate the systems we build in terms on three automatic evaluation metrics: BLEU (),: Parallel data, after preprocessing, used to train our SMT and NMT systems.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 102, "end_pos": 106, "type": "METRIC", "confidence": 0.9991095662117004}, {"text": "SMT", "start_pos": 166, "end_pos": 169, "type": "TASK", "confidence": 0.9709200859069824}]}, {"text": "As the performance obtained in the development (newsdev2015) and validation (newstest2015) sets guides our decisions, we believe it is sensible to use three metrics with different underlying methodologies and that work on different elements (words and characters).", "labels": [], "entities": []}, {"text": "Statistical significance of the difference between systems is computed with paired bootstrap resampling) (p \u2264 0.05, 1 000 iterations).", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Finnish monolingual data, after prepro- cessing, used to train the LMs of our SMT sub- mission.", "labels": [], "entities": [{"text": "Finnish monolingual data", "start_pos": 10, "end_pos": 34, "type": "DATASET", "confidence": 0.6328962842623392}, {"text": "SMT sub- mission", "start_pos": 88, "end_pos": 104, "type": "TASK", "confidence": 0.8710674494504929}]}, {"text": " Table 2: English monolingual data, after prepro- cessing, used to train the LM of the Finnish-to- English SMT system we used to backtranslate the  Finnish News Crawl monolingual corpora into En- glish (see Section 3).", "labels": [], "entities": [{"text": "Finnish-to- English SMT", "start_pos": 87, "end_pos": 110, "type": "TASK", "confidence": 0.4513392746448517}, {"text": "Finnish News Crawl monolingual corpora", "start_pos": 148, "end_pos": 186, "type": "DATASET", "confidence": 0.7804328203201294}]}, {"text": " Table 3: Parallel data, after preprocessing, used to  train our SMT and NMT systems.", "labels": [], "entities": [{"text": "SMT", "start_pos": 65, "end_pos": 68, "type": "TASK", "confidence": 0.9267877340316772}]}, {"text": " Table 6: Results of the evaluation on newstest2016  of our NMT submission (in bold), the simpler  strategy for translating unknown words by", "labels": [], "entities": [{"text": "newstest2016", "start_pos": 39, "end_pos": 51, "type": "DATASET", "confidence": 0.9529947638511658}, {"text": "NMT submission", "start_pos": 60, "end_pos": 74, "type": "DATASET", "confidence": 0.7913663983345032}, {"text": "translating unknown words", "start_pos": 112, "end_pos": 137, "type": "TASK", "confidence": 0.8905753890673319}]}, {"text": " Table 7: Results of the evaluation on newstest2016  of the SMT systems built. The best score for each  metric is shown in bold. An arrow pointing up- wards (\u2191) means that the corresponding system  outperforms the system without segmentation by  a statistically significant margin.", "labels": [], "entities": [{"text": "newstest2016", "start_pos": 39, "end_pos": 51, "type": "DATASET", "confidence": 0.961323618888855}, {"text": "SMT", "start_pos": 60, "end_pos": 63, "type": "TASK", "confidence": 0.9783267378807068}]}, {"text": " Table 8: Results of the different reranking strate- gies applied to the best SMT system (Omorfi +  BPE) on newstest2016. The best score for each  metric is shown in bold, as is the system submit- ted. An arrow pointing upwards (\u2191) means that  the corresponding system outperforms the sys- tem without reranking by a statistically significant  margin.", "labels": [], "entities": [{"text": "SMT", "start_pos": 78, "end_pos": 81, "type": "TASK", "confidence": 0.9698081612586975}, {"text": "Omorfi +  BPE) on newstest2016", "start_pos": 90, "end_pos": 120, "type": "DATASET", "confidence": 0.5799434433380762}]}, {"text": " Table 9: Results of the system combination exper- iments on newstest2016. The best score for each  metric is shown in bold, as is the system submit- ted. An arrow pointing upwards (\u2191) means that the  corresponding system outperforms the best NMT  system by a statistically significant margin.", "labels": [], "entities": [{"text": "newstest2016", "start_pos": 61, "end_pos": 73, "type": "DATASET", "confidence": 0.9622657895088196}]}]}