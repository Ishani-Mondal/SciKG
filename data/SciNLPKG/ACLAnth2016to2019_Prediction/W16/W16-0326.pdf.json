{"title": [], "abstractContent": [{"text": "As part of the 2016 Computational Linguistics and Clinical Psychology (CLPsych) shared task, participants were asked to construct systems to automatically classify mental health forum posts into four categories, representing how urgently posts require moderator attention.", "labels": [], "entities": [{"text": "2016 Computational Linguistics and Clinical Psychology (CLPsych) shared task", "start_pos": 15, "end_pos": 91, "type": "TASK", "confidence": 0.6503475877371702}]}, {"text": "This paper details the system implementation from the University of Florida, in which we compare several distinct models and show that best performance is achieved with domain-specific preprocessing, n-gram feature extraction, and cross-validated linear models.", "labels": [], "entities": [{"text": "n-gram feature extraction", "start_pos": 200, "end_pos": 225, "type": "TASK", "confidence": 0.6554170747598013}]}], "introductionContent": [{"text": "As more and more social interaction takes place online, the wealth of data provided by these online platforms is proving to be a useful source of information for identifying early warning signs for poor mental health.", "labels": [], "entities": []}, {"text": "The goal of 2016 CLPsych shared task was to predict the degree of moderator attention required for posts on the ReachOut forum, an online youth mental health service that provides support to young people aged 14-25.", "labels": [], "entities": []}, {"text": "Along with the analysis of forum-specific metainformation, this task includes aspects of sentiment analysis, the field of study that analyzes people's opinions, sentiments, attitudes, and emotions from written language, where several studies have explored the categorization and prediction of user sentiment in social media platforms such as Twitter (; Kouloumpis et 1 https://au.reachout.com/ al.,).", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 89, "end_pos": 107, "type": "TASK", "confidence": 0.8541867733001709}]}, {"text": "Other studies have also applied sentiment analysis techniques to MOOC discussion forums () and suicide notes, both highly relevant to this shared task.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 32, "end_pos": 50, "type": "TASK", "confidence": 0.963289886713028}, {"text": "MOOC discussion forums", "start_pos": 65, "end_pos": 87, "type": "TASK", "confidence": 0.8012702862421671}]}, {"text": "Our straightforward approach draws from successful text classification and sentiment analysis methods, including the use of a sentiment lexicon (Liu, 2010) and Word2Vec distributed word embeddings (, along with more traditional methods such as normalized n-gram counts.", "labels": [], "entities": [{"text": "text classification and sentiment analysis", "start_pos": 51, "end_pos": 93, "type": "TASK", "confidence": 0.711975234746933}]}, {"text": "We utilize these linguistic features, as well as several hand-crafted features derived from the metainformation of posts and their authors, to construct logistic regression classifiers for predicting the status label of ReachOut forum posts.", "labels": [], "entities": [{"text": "predicting the status label of ReachOut forum posts", "start_pos": 189, "end_pos": 240, "type": "TASK", "confidence": 0.6366465501487255}]}], "datasetContent": [{"text": "As part of the shared task, participants were provided a collection of ReachOut forum posts from July 2012 to June 2015.", "labels": [], "entities": [{"text": "ReachOut forum posts from July 2012", "start_pos": 71, "end_pos": 106, "type": "DATASET", "confidence": 0.8993941048781077}]}, {"text": "In addition to the textual post content, posts also contained meta-information such as author ID, author rank/affiliation, post time, thread ID, etc.", "labels": [], "entities": []}, {"text": "A training set of 947 such posts was provided, each with a corresponding moderator attention label (green, amber, red, or crisis).", "labels": [], "entities": []}, {"text": "An additional 65,024 unlabeled posts was also provided.", "labels": [], "entities": []}, {"text": "The test set consisted of 241 unlabeled forum posts.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Classification results on the test set using a single logistic regression model trained on each set of features. (Post) denotes", "labels": [], "entities": []}, {"text": " Table 3: Detailed classification results for our final model. No", "labels": [], "entities": []}]}