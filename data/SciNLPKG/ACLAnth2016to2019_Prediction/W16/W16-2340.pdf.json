{"title": [], "abstractContent": [{"text": "We present DTED, a submission to the WMT 2016 Metrics Task using structural information generated by dependency parsing and evaluated using tree edit distances.", "labels": [], "entities": [{"text": "WMT 2016 Metrics Task", "start_pos": 37, "end_pos": 58, "type": "TASK", "confidence": 0.5730087608098984}, {"text": "dependency parsing", "start_pos": 101, "end_pos": 119, "type": "TASK", "confidence": 0.7099955081939697}]}, {"text": "In this paper we apply this system to translations produced during WMT 2015, and compare our scores with human rankings from that year.", "labels": [], "entities": [{"text": "translations produced during WMT 2015", "start_pos": 38, "end_pos": 75, "type": "TASK", "confidence": 0.6610553085803985}]}, {"text": "We find moderate correlations, despite the human judgements being based on all aspects of the sentences while our metric is based only on word order.", "labels": [], "entities": []}], "introductionContent": [{"text": "In the ever-growing field of translation metrics, a number of systems exist which attempt to provide an overall rating fora sentence.", "labels": [], "entities": [{"text": "translation metrics", "start_pos": 29, "end_pos": 48, "type": "TASK", "confidence": 0.9352041780948639}]}, {"text": "Most of these use one or more reference translations produced by a human as a gold standard.", "labels": [], "entities": []}, {"text": "One of the earliest examples of such a metric maybe BLEU), using an adapted version of the well-known principle of Precision.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 52, "end_pos": 56, "type": "METRIC", "confidence": 0.9986706972122192}, {"text": "Precision", "start_pos": 115, "end_pos": 124, "type": "METRIC", "confidence": 0.9025006294250488}]}, {"text": "More recently, NIST and) have used n-gram analysis to provide similar heuristics, and many other techniques have been proposed).", "labels": [], "entities": [{"text": "NIST", "start_pos": 15, "end_pos": 19, "type": "DATASET", "confidence": 0.9043475985527039}]}, {"text": "These metrics are useful when making highlevel comparisons between several machine translation systems, but they offer very limited insight into the linguistic workings of the machine translation process.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 75, "end_pos": 94, "type": "TASK", "confidence": 0.7298252284526825}, {"text": "machine translation process", "start_pos": 176, "end_pos": 203, "type": "TASK", "confidence": 0.7991430560747782}]}, {"text": "They can be used in automatic processes such as training systems through hillclimbing iterations, or as broad descriptions of a system's overall quality.", "labels": [], "entities": []}, {"text": "It is however difficult to use this kind of score to gain more precise insights into a system's features; for example, different tasks may have different priorities for which errors are least desirable.", "labels": [], "entities": []}, {"text": "Deeper analysis might also be able to pinpoint specific areas of improvement within a system.", "labels": [], "entities": []}, {"text": "With these and other goals in mind, granular metrics have been created to evaluate individual aspects of the translated output in isolation.", "labels": [], "entities": []}, {"text": "When developing such granular metrics, the question of which linguistic aspects of translations to focus on is far from trivial.", "labels": [], "entities": []}, {"text": "While there has been much related discussion in the professional and educational spheres of the factors which can affect understanding of a given translation, the academic sphere has been less prolific.", "labels": [], "entities": [{"text": "understanding of a given translation", "start_pos": 121, "end_pos": 157, "type": "TASK", "confidence": 0.8632527947425842}]}, {"text": "Nonetheless, a widely-used taxonomy on the distinct problem types which can be observed has been produced by, while investigated those which most affect overall understanding of a translation.", "labels": [], "entities": []}, {"text": "One of the prime factors identified by was word order, and metrics have been produced since then which focus on this factor).", "labels": [], "entities": []}, {"text": "These metrics apply various techniques, but most are based on the concept of comparing individual substrings of a source and reference sentence.", "labels": [], "entities": []}, {"text": "While these techniques allow lightweight algorithms to produce rough scores, they ignore how the structure of a sentence can dramatically affect the impact of a mistake in ordering.", "labels": [], "entities": []}, {"text": "For example, the mistake in the hypothesis of sentence 1 of is much less significant than that of sentence 2, despite the latter being closer in a 'flat' judgement.", "labels": [], "entities": [{"text": "mistake", "start_pos": 17, "end_pos": 24, "type": "METRIC", "confidence": 0.9732391238212585}]}, {"text": "In an attempt to mitigate these problems, though without the explicit goal of focusing on word order, some work has been done using structural evaluation of sentences through dependency parsing.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 175, "end_pos": 193, "type": "TASK", "confidence": 0.7243105471134186}]}, {"text": "These systems either focus on applying BLEU-style n-gram matching to a tree context ( or focus on specific relationships between Reference Hypothesis 1 I spoke to him there.", "labels": [], "entities": [{"text": "BLEU-style", "start_pos": 39, "end_pos": 49, "type": "METRIC", "confidence": 0.975475013256073}]}, {"text": "2 She let it be and left.", "labels": [], "entities": []}, {"text": "She let it and be left. and groupings of nodes in the trees and compare those features between hypothesis and reference trees to produce holistic judgements).", "labels": [], "entities": []}, {"text": "The approach of our system, named DTED (Dependency-based Tree Edit Distance), differs from existing word order literature by including dependency structures, but adds to the body of dependency-based work by focusing on node order rather than attempting to give an overall score.", "labels": [], "entities": []}, {"text": "We work on complete dependency trees, rather than specific subsections, to produce an edit distance between the hypothesis and reference trees.", "labels": [], "entities": []}, {"text": "A tree edit distance is a count of the actions required to convert one ordered tree into another.", "labels": [], "entities": []}, {"text": "In the manner of Levenshtein distances and Word Error Rate (), these actions are limited to Renaming, Deleting an existing node, or Inserting anew one.", "labels": [], "entities": [{"text": "Word Error Rate", "start_pos": 43, "end_pos": 58, "type": "METRIC", "confidence": 0.7147247195243835}, {"text": "Renaming", "start_pos": 92, "end_pos": 100, "type": "TASK", "confidence": 0.9726375937461853}]}, {"text": "A number of variants on this model have been proposed, many attempting to improve the efficiency of the algorithm when applied in large-scale or highthroughput areas).", "labels": [], "entities": []}, {"text": "The algorithm we have implemented is an extension of that proposed by, which is worst-case optimal, running in O(n 3 ) time where n is the number of words in the shorter sentence.", "labels": [], "entities": []}, {"text": "Its output is thus a count of required modifications, which is in turn converted to a normalised score between 0 and 1.", "labels": [], "entities": []}, {"text": "This is coupled with a weighting, indicating when aggregating scores to a system level what proportion of nodes were indicated as aligned by a preprocessing step.", "labels": [], "entities": []}, {"text": "Our assumption is that the position of an aligned word is more reliable than an unaligned one, so when calculating corpus-wide scores we should disproportionately consider the information of those with many aligned words.", "labels": [], "entities": []}, {"text": "Our algorithm thus requires nothing more than the source and reference pairs, plus tools to calculate alignments and dependency trees for the chosen target language.", "labels": [], "entities": []}, {"text": "We have used English, but the methodology would be easily applicable to any other target language for which these two components exist.", "labels": [], "entities": []}], "datasetContent": [{"text": "It should be noted that while DTED is intended to evaluate word order in isolation, rankings at WMT were based on all features of the sentences.", "labels": [], "entities": [{"text": "WMT", "start_pos": 96, "end_pos": 99, "type": "DATASET", "confidence": 0.6803408265113831}]}, {"text": "As no data of sufficient quantity and quality was available for human judgements specifically of word order, we have used the holistic data.", "labels": [], "entities": [{"text": "word order", "start_pos": 97, "end_pos": 107, "type": "TASK", "confidence": 0.7690246999263763}]}, {"text": "As such, we do not expect cutting-edge correlational values for this data; instead, such comparisons are provided for two separate reasons.", "labels": [], "entities": []}, {"text": "First, as word order is clearly involved in some non-trivial way inhuman judgements, we can assume that holistic ranks contain an implicit word order component.", "labels": [], "entities": []}, {"text": "A limited level of similarity between human judgements and DTED is thus to be expected, as they are at least partially measuring the same phenomenon.", "labels": [], "entities": [{"text": "similarity", "start_pos": 19, "end_pos": 29, "type": "METRIC", "confidence": 0.9878859519958496}]}, {"text": "In addition, while the DTED algorithm is intended to measure word order alone, the structure and alignment of the trees we use may themselves depend on other factors.", "labels": [], "entities": []}, {"text": "For example, a badly chosen word may occupy a different role in its sentence than the reference choice would, resulting in an unpredictable change in the actions needed to correct it.", "labels": [], "entities": []}, {"text": "Second, if we assume DTED's results to be successfully representative of a sentence's word order quality and human judgements to contain a word order component, the level of correlation can begin to quantify the significance of word order within the overall judgement.", "labels": [], "entities": []}, {"text": "In the ideal theoretical case where DTED perfectly simulated human intuition on word order, such correlational coefficients would give direct insight into the significance of that intuition to overall quality judgements.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 4: System-level correlations of word order metrics with normalised human rankings", "labels": [], "entities": []}, {"text": " Table 5: Sizes of corpora used for all empirical calculations, all produced during WMT 2015", "labels": [], "entities": [{"text": "WMT 2015", "start_pos": 84, "end_pos": 92, "type": "DATASET", "confidence": 0.7247697710990906}]}]}