{"title": [{"text": "Leveraging Entity Linking and Related Language Projection to Improve Name Transliteration", "labels": [], "entities": [{"text": "Leveraging Entity Linking", "start_pos": 0, "end_pos": 25, "type": "TASK", "confidence": 0.6003110806147257}, {"text": "Improve Name Transliteration", "start_pos": 61, "end_pos": 89, "type": "TASK", "confidence": 0.8535695473353068}]}], "abstractContent": [{"text": "Traditional name transliteration methods largely ignore source context information and inter-dependency among entities for entity disambiguation.", "labels": [], "entities": [{"text": "entity disambiguation", "start_pos": 123, "end_pos": 144, "type": "TASK", "confidence": 0.7447612583637238}]}, {"text": "We propose a novel approach to leverage state-of-the-art Entity Linking (EL) techniques to automatically correct name transliteration results, using collective inference from source contexts and additional evidence from knowledge base.", "labels": [], "entities": [{"text": "state-of-the-art Entity Linking (EL)", "start_pos": 40, "end_pos": 76, "type": "TASK", "confidence": 0.8089686532815298}]}, {"text": "Experiments on transliterating names from seven languages to English demonstrate that our approach achieves 2.6% to 15.7% absolute gain over the baseline model, and significantly advances state-of-the-art.", "labels": [], "entities": [{"text": "transliterating names from seven languages to English", "start_pos": 15, "end_pos": 68, "type": "TASK", "confidence": 0.845793970993587}, {"text": "absolute gain", "start_pos": 122, "end_pos": 135, "type": "METRIC", "confidence": 0.9539607167243958}]}, {"text": "When contextual information exists, our approach can achieve further gains (24.2%) by collectively translit-erating and disambiguating multiple related entities.", "labels": [], "entities": []}, {"text": "We also prove that combining Entity Linking and projecting resources from related languages obtained comparable performance as the method using the same amount of training pairs in the original languages without Entity Linking.", "labels": [], "entities": [{"text": "Entity Linking", "start_pos": 29, "end_pos": 43, "type": "TASK", "confidence": 0.8033731877803802}]}], "introductionContent": [{"text": "In Machine Translation and Cross-lingual Information Extraction tasks, an important problem is translating out-of-vocabulary words, mostly names.", "labels": [], "entities": [{"text": "Machine Translation", "start_pos": 3, "end_pos": 22, "type": "TASK", "confidence": 0.834448903799057}, {"text": "Cross-lingual Information Extraction", "start_pos": 27, "end_pos": 63, "type": "TASK", "confidence": 0.7356433471043905}, {"text": "translating out-of-vocabulary words", "start_pos": 95, "end_pos": 130, "type": "TASK", "confidence": 0.8853607177734375}]}, {"text": "For some names, we can perform transliteration, namely converting them to their approximate phonetic equivalents.", "labels": [], "entities": []}, {"text": "Previous methods have generally followed the two-step approach proposed by): Generating transliteration hypotheses based on phoneme, grapheme or correspondence, and validating or re-ranking hypotheses using language modeling or Information Extraction from the target language (.", "labels": [], "entities": [{"text": "Generating transliteration hypotheses based on phoneme, grapheme or correspondence", "start_pos": 77, "end_pos": 159, "type": "TASK", "confidence": 0.8168516457080841}]}, {"text": "In this paper, we focus on back-transliteration from languages lacking in Natural Language Processing (NLP) resources to English for two reasons: (1) In NLP tasks such as name tagging, we can take advantage of rich English resources by transliterating a name to English.", "labels": [], "entities": [{"text": "name tagging", "start_pos": 171, "end_pos": 183, "type": "TASK", "confidence": 0.7376905381679535}]}, {"text": "Our analysis of 986 transliteration pairs from the Named Entities Workshop 2015 (NEWS2015) 2 Bengali development set shows that 574 English names can be found in the DBpedia 3 , while only 47 Bengali names exist in the same knowledge base (KB).", "labels": [], "entities": [{"text": "Named Entities Workshop 2015 (NEWS2015) 2 Bengali development set", "start_pos": 51, "end_pos": 116, "type": "DATASET", "confidence": 0.691956641999158}, {"text": "DBpedia 3", "start_pos": 166, "end_pos": 175, "type": "DATASET", "confidence": 0.9284816980361938}]}, {"text": "(2) Back-transliterating names in other languages to English make them understandable by more users since English is widely spoken as a global lingua franca.", "labels": [], "entities": []}, {"text": "In this paper we analyze the following remaining challenges from previous methods: Challenge 1: Lack of Entity Grounding.", "labels": [], "entities": []}, {"text": "Previous methods developed for transliteration benchmark tasks such as Named Entity Workshop (NEWS) Shared Task () usually focus on transliterating independent names without properties (or contextual information).", "labels": [], "entities": [{"text": "transliteration benchmark tasks", "start_pos": 31, "end_pos": 62, "type": "TASK", "confidence": 0.9075173139572144}]}, {"text": "For example, \"Kalashnikov\" and \"Calashnikov\" are both acceptable transliterations for \"\" (k\u01ce l\u0101 sh\u00ed n\u00ed k\u0113 f\u016b) in terms of pronunciation.", "labels": [], "entities": []}, {"text": "If we know that it refers to a rifle series, however, we should transliterate \"\" to \"Ka\" instead of \"Ca\" here.", "labels": [], "entities": []}, {"text": "Therefore, we propose to ground the transliteration results to a KB whenever the contexts are available.", "labels": [], "entities": []}, {"text": "As pointed out in, the informationlosing problem of transliteration makes it difficult to invert.", "labels": [], "entities": []}, {"text": "For example, \"la\" and \"ra\" are two distinct sounds in English, while they usually collapse to \"\" (l\u0101) in Chinese, which lacks the English \"ra\" sound.", "labels": [], "entities": []}, {"text": "To tackle these two challenges, we propose a novel approach that links a given name to a KB in target language, and subsequently exploits the linking results to correct transliteration hypotheses.", "labels": [], "entities": []}, {"text": "shows some instances which require entity disambiguation before transliteration.", "labels": [], "entities": [{"text": "entity disambiguation", "start_pos": 35, "end_pos": 56, "type": "TASK", "confidence": 0.7021021246910095}]}, {"text": "Take the name \"\" (y\u00e0 s\u00e8) as an example, it has several possible transliteration hypotheses.", "labels": [], "entities": []}, {"text": "If we find \"\"(Lackey) in the same document, we can apply collective inference to link their transliteration candidates to a KB.", "labels": [], "entities": []}, {"text": "Since \"James Lackey\" appears in the infobox of \"Usher (Singer)\", we take \"Usher\" and \"Lackey\" as transliterations for \"\" and \"\" respectively.", "labels": [], "entities": []}, {"text": "Challenge 4: Lack of Training Pairs.", "labels": [], "entities": []}, {"text": "Statistical transliteration models usually rely on thousands of name pairs for training.", "labels": [], "entities": []}, {"text": "However, it might be costly to collect required training data for lowresource languages.", "labels": [], "entities": []}, {"text": "To address this issue, we propose a simple but effective method which transliterates names in a low-resource language using a model trained on one of its similar languages by means of a character mapping table derived from Unicode charts.", "labels": [], "entities": []}, {"text": "illustrates the overall framework of our approach, which consists of four steps as follows.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section we will present experimental results for context-independent, context-dependent, and cross-lingual projection settings respectively.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: A comparison of different baseline sys- tems on transliteration accuracy (%). Scores of  DTL (DDDDDTL+), SEQ (SSSSSSSS), and SMT  (statistical machine translation) are reported in", "labels": [], "entities": [{"text": "accuracy", "start_pos": 74, "end_pos": 82, "type": "METRIC", "confidence": 0.9760478138923645}, {"text": "statistical machine translation)", "start_pos": 141, "end_pos": 173, "type": "TASK", "confidence": 0.663073904812336}]}, {"text": " Table 4: # of name pairs in NEWS2015 data sets.", "labels": [], "entities": [{"text": "NEWS2015 data sets", "start_pos": 29, "end_pos": 47, "type": "DATASET", "confidence": 0.9644723931948344}]}, {"text": " Table 5:  Back-transliteration accuracy on  NEWS2015 development sets (%).", "labels": [], "entities": [{"text": "Back-transliteration", "start_pos": 11, "end_pos": 31, "type": "METRIC", "confidence": 0.8977972269058228}, {"text": "accuracy", "start_pos": 32, "end_pos": 40, "type": "METRIC", "confidence": 0.9190590977668762}, {"text": "NEWS2015 development sets", "start_pos": 45, "end_pos": 70, "type": "DATASET", "confidence": 0.9370975693066915}]}]}