{"title": [{"text": "Towards Abstraction from Extraction: Multiple Timescale Gated Recurrent Unit for Summarization", "labels": [], "entities": [{"text": "Summarization", "start_pos": 81, "end_pos": 94, "type": "TASK", "confidence": 0.9768238663673401}]}], "abstractContent": [{"text": "In this work, we introduce temporal hierarchies to the sequence to sequence (seq2seq) model to tackle the problem of abstractive summarization of scientific articles.", "labels": [], "entities": [{"text": "abstractive summarization of scientific articles", "start_pos": 117, "end_pos": 165, "type": "TASK", "confidence": 0.7865200638771057}]}, {"text": "The proposed Multiple Timescale model of the Gated Recurrent Unit (MT-GRU) is implemented in the encoder-decoder setting to better deal with the presence of multiple compositionalities in larger texts.", "labels": [], "entities": []}, {"text": "The proposed model is compared to the conventional RNN encoder-decoder, and the results demonstrate that our model trains faster and shows significant performance gains.", "labels": [], "entities": []}, {"text": "The results also show that the temporal hierarchies help improve the ability of seq2seq models to capture compositionalities better without the presence of highly complex architectural hierarchies.", "labels": [], "entities": []}], "introductionContent": [], "datasetContent": [{"text": "We trained two seq2seq models, the first model using the conventional GRU in the RNN encoder decoder, and the second model using the newly proposed MTGRU.", "labels": [], "entities": [{"text": "RNN encoder decoder", "start_pos": 81, "end_pos": 100, "type": "DATASET", "confidence": 0.9114587108294169}, {"text": "MTGRU", "start_pos": 148, "end_pos": 153, "type": "DATASET", "confidence": 0.9256042838096619}]}, {"text": "Both models are trained using the same hyperparamenter settings with the optimal configuration which fits our existing hardware capability.", "labels": [], "entities": []}, {"text": "Following, the inputs are divided into multiple buckets.", "labels": [], "entities": []}, {"text": "Both GRU and MT-   GRU models consist of 4 layers and 1792 hidden units.", "labels": [], "entities": []}, {"text": "As our models take longer input and target sequence sizes, the hidden units size and number of layers are limited.", "labels": [], "entities": []}, {"text": "An embedding size of 512 was used for both networks.", "labels": [], "entities": []}, {"text": "The timescale constant \u03c4 for each layer is set to 1, 1.25, 1.5, 1.7, respectively.", "labels": [], "entities": []}, {"text": "The models are trained on 110k textsummary pairs.", "labels": [], "entities": []}, {"text": "The source text are the paragraphs extracted from the introduction of academic articles and the targets are the most salient sentence extracted from the paragraphs using TF-IDF scores.", "labels": [], "entities": [{"text": "TF-IDF", "start_pos": 170, "end_pos": 176, "type": "METRIC", "confidence": 0.6398297548294067}]}, {"text": "For comparison of the training speed of the models, shows the plot of the training curve until the train perplexity reaches 9.5.", "labels": [], "entities": []}, {"text": "Both of the models are trained using 2 Nvidia Ge-Force GTX Titan X GPUs which takes roughly 4 days and 3 days respectively.", "labels": [], "entities": [{"text": "Nvidia Ge-Force GTX Titan X GPUs", "start_pos": 39, "end_pos": 71, "type": "DATASET", "confidence": 0.9024467766284943}]}, {"text": "During test, greedy decoding was used to generate the most likely output given a source Introduction.", "labels": [], "entities": []}, {"text": "For evaluation, we adopt the Recall-Oriented Understudy for Gisting Evaluation (ROUGE) metrics proposed by    the n-gram recall between the candidate summary and gold summaries.", "labels": [], "entities": [{"text": "Recall-Oriented Understudy for Gisting Evaluation (ROUGE) metrics", "start_pos": 29, "end_pos": 94, "type": "METRIC", "confidence": 0.7052130930953555}, {"text": "recall", "start_pos": 121, "end_pos": 127, "type": "METRIC", "confidence": 0.8731305599212646}]}, {"text": "In this work, we only have one gold summary which is the Abstract of an article, thus the ROUGE score is calculated as given in.", "labels": [], "entities": [{"text": "Abstract", "start_pos": 57, "end_pos": 65, "type": "METRIC", "confidence": 0.9973512887954712}, {"text": "ROUGE score", "start_pos": 90, "end_pos": 101, "type": "METRIC", "confidence": 0.9831933379173279}]}, {"text": "ROUGE-1, ROUGE-2 and ROUGE-L are used to report the performance of the models.", "labels": [], "entities": [{"text": "ROUGE-1", "start_pos": 0, "end_pos": 7, "type": "METRIC", "confidence": 0.954313337802887}, {"text": "ROUGE-2", "start_pos": 9, "end_pos": 16, "type": "METRIC", "confidence": 0.9494606256484985}, {"text": "ROUGE-L", "start_pos": 21, "end_pos": 28, "type": "METRIC", "confidence": 0.982990026473999}]}, {"text": "For the performance evaluation, both the models are trained up to 74750 steps where the training perplexity of GRU and MTGRU are shown in.", "labels": [], "entities": [{"text": "GRU", "start_pos": 111, "end_pos": 114, "type": "METRIC", "confidence": 0.6520688533782959}, {"text": "MTGRU", "start_pos": 119, "end_pos": 124, "type": "DATASET", "confidence": 0.7233971953392029}]}, {"text": "This step was chosen as the early stopping point as at this step we get the lowest test perplexity of the GRU model.", "labels": [], "entities": [{"text": "GRU", "start_pos": 106, "end_pos": 109, "type": "DATASET", "confidence": 0.747485876083374}]}, {"text": "The ROUGE scores calculated using these trained networks are shown in for the GRU and MT-GRU models, respectively.", "labels": [], "entities": [{"text": "ROUGE", "start_pos": 4, "end_pos": 9, "type": "METRIC", "confidence": 0.9849308729171753}, {"text": "GRU", "start_pos": 78, "end_pos": 81, "type": "DATASET", "confidence": 0.7436977028846741}]}, {"text": "A sample summary generated by the MTGRU model is shown in.", "labels": [], "entities": [{"text": "MTGRU", "start_pos": 34, "end_pos": 39, "type": "DATASET", "confidence": 0.6650679111480713}]}], "tableCaptions": [{"text": " Table 1: Network Parameters for each model.", "labels": [], "entities": []}, {"text": " Table 2: Training results of the Models.", "labels": [], "entities": []}, {"text": " Table 3: ROUGE scores of GRU Model", "labels": [], "entities": [{"text": "ROUGE", "start_pos": 10, "end_pos": 15, "type": "METRIC", "confidence": 0.9794709086418152}, {"text": "GRU", "start_pos": 26, "end_pos": 29, "type": "DATASET", "confidence": 0.7188420295715332}]}, {"text": " Table 4: ROUGE scores of MTGRU Model", "labels": [], "entities": [{"text": "ROUGE", "start_pos": 10, "end_pos": 15, "type": "METRIC", "confidence": 0.9826431274414062}, {"text": "MTGRU", "start_pos": 26, "end_pos": 31, "type": "TASK", "confidence": 0.4859822690486908}]}]}