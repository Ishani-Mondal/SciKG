{"title": [{"text": "Part-of-speech Tagging of Code-mixed Social Media Content: Pipeline, Stacking and Joint Modelling", "labels": [], "entities": [{"text": "Part-of-speech Tagging of Code-mixed Social Media Content", "start_pos": 0, "end_pos": 57, "type": "TASK", "confidence": 0.8017573654651642}]}], "abstractContent": [{"text": "Multilingual users of social media sometimes use multiple languages during conversation.", "labels": [], "entities": []}, {"text": "Mixing multiple languages in content is known as code-mixing.", "labels": [], "entities": []}, {"text": "We annotate a subset of a trilingual code-mixed corpus (Barman et al., 2014) with part-of-speech (POS) tags.", "labels": [], "entities": []}, {"text": "We investigate two state-of-the-art POS tagging techniques for code-mixed content and combine the features of the two systems to build a better POS tagger.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 36, "end_pos": 47, "type": "TASK", "confidence": 0.7397987544536591}, {"text": "POS tagger", "start_pos": 144, "end_pos": 154, "type": "TASK", "confidence": 0.6665478348731995}]}, {"text": "Furthermore, we investigate the use of a joint model which performs language identification (LID) and part-of-speech (POS) tagging simultaneously.", "labels": [], "entities": [{"text": "language identification (LID)", "start_pos": 68, "end_pos": 97, "type": "TASK", "confidence": 0.7886644303798676}, {"text": "part-of-speech (POS) tagging", "start_pos": 102, "end_pos": 130, "type": "TASK", "confidence": 0.6660291910171509}]}], "introductionContent": [{"text": "Automatic processing of code-mixed social media content is an emerging topic in NLP ().", "labels": [], "entities": [{"text": "Automatic processing of code-mixed social media content", "start_pos": 0, "end_pos": 55, "type": "TASK", "confidence": 0.7387922193322863}]}, {"text": "Code-mixing is a linguistic phenomenon where language switching occurs at a sentence boundary (inter-sentential), or within a sentence (intra-sentential) or within a word (word-level).", "labels": [], "entities": []}, {"text": "This phenomenon can be observed among multilingual speakers and in many languages.", "labels": [], "entities": []}, {"text": "Additionally, non-English speakers often use Roman script to write something in social media.", "labels": [], "entities": []}, {"text": "This is known as Romanisation.", "labels": [], "entities": []}, {"text": "The following comment taken from a Facebook group of Indian students is an example of trilingual code-mixed content: Original: Yaar tu to, GOD hain.", "labels": [], "entities": []}, {"text": "tui JU te ki korchis?", "labels": [], "entities": []}, {"text": "Translation: Buddy you are GOD.", "labels": [], "entities": [{"text": "Translation", "start_pos": 0, "end_pos": 11, "type": "TASK", "confidence": 0.9196224212646484}, {"text": "GOD", "start_pos": 27, "end_pos": 30, "type": "METRIC", "confidence": 0.9945607781410217}]}, {"text": "What are you doing in JU?", "labels": [], "entities": [{"text": "JU", "start_pos": 22, "end_pos": 24, "type": "DATASET", "confidence": 0.9132449626922607}]}, {"text": "Three languages are present in this comment: English, Hindi (italics) and Bengali (bold).", "labels": [], "entities": []}, {"text": "Bengali and Hindi words are written in romanised forms.", "labels": [], "entities": []}, {"text": "These phenomena (code-mixing and Romanisation) can occur simultaneously and increase the ambiguity of words.", "labels": [], "entities": []}, {"text": "For example, in the previous comment, 'to' could be mistaken as an English word but it is a romanised Hindi word.", "labels": [], "entities": []}, {"text": "Moreover, the romanised form of a native word may vary according to the user's preference.", "labels": [], "entities": []}, {"text": "In such situations automatic processing is challenging.", "labels": [], "entities": []}, {"text": "POS tagging in code-mixed data) is an interesting problem because of its word-level ambiguity.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 0, "end_pos": 11, "type": "TASK", "confidence": 0.8343174159526825}]}, {"text": "Traditional NLP systems trained in one language perform poorly on such multilingual code-mixed data.", "labels": [], "entities": []}, {"text": "In this paper, we present a data set manually annotated with part of speech and language . We implement and explore two state-of-the-art methods for POS tagging in code-mixed data, i.e. (1) a stacked system (Solorio and Liu, 2008) 2 and (2) a pipeline system ().", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 149, "end_pos": 160, "type": "TASK", "confidence": 0.9103823900222778}]}, {"text": "To our knowledge, a comparison between these two POS tagging methods for code-mixed content, i.e. (1) and (2), has not been carried out before.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 49, "end_pos": 60, "type": "TASK", "confidence": 0.7255125194787979}]}, {"text": "In our study we compare these two POS tagging approaches which is an important contribution of this paper.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 34, "end_pos": 45, "type": "TASK", "confidence": 0.8427502810955048}]}, {"text": "In romanised and code-mixed text, words of different languages may take the same lexical form.", "labels": [], "entities": []}, {"text": "As a result, language and POS ambiguity are in-creased.", "labels": [], "entities": []}, {"text": "POS labels often depend on the language in code-mixed content.", "labels": [], "entities": [{"text": "POS labels", "start_pos": 0, "end_pos": 10, "type": "TASK", "confidence": 0.7180101573467255}]}, {"text": "Thus, modelling the interaction between language labels and POS labels maybe useful.", "labels": [], "entities": []}, {"text": "Furthermore, joint modelling avoids error propagation.", "labels": [], "entities": [{"text": "joint modelling", "start_pos": 13, "end_pos": 28, "type": "TASK", "confidence": 0.7884841859340668}]}, {"text": "We compare our joint model for LID and POS tagging to the stacked model and the pipeline system.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 39, "end_pos": 50, "type": "TASK", "confidence": 0.6479095965623856}]}, {"text": "We use Factorial Conditional Random Fields (FCRF) () as the joint model in our study.", "labels": [], "entities": []}, {"text": "The rest of the paper is organised as follows: in Section 2, we discuss related work.", "labels": [], "entities": []}, {"text": "In Section 3 we describe our data for this task.", "labels": [], "entities": []}, {"text": "Our experiments are described in Section 4.", "labels": [], "entities": []}, {"text": "Section 5 contains analysis of the results.", "labels": [], "entities": []}, {"text": "Finally, we conclude and suggest ways to extend this work in Section 6.", "labels": [], "entities": []}], "datasetContent": [{"text": "We divide the experiments into four parts.", "labels": [], "entities": []}, {"text": "We implement baselines for POS tagging in Section 4.1.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 27, "end_pos": 38, "type": "TASK", "confidence": 0.8709179759025574}]}, {"text": "In Section 4.2 we implement pipeline systems.", "labels": [], "entities": []}, {"text": "In Section 4.3 we present our stacking systems and in Section 4.4 we present our joint model.", "labels": [], "entities": [{"text": "stacking", "start_pos": 30, "end_pos": 38, "type": "TASK", "confidence": 0.9641024470329285}]}, {"text": "We perform five fold cross-validation with the data and report average cross-validation accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 88, "end_pos": 96, "type": "METRIC", "confidence": 0.9858027696609497}]}, {"text": "We investigate the use of handcrafted features and features that can be obtained from monolingual POS taggers (stacking).", "labels": [], "entities": []}, {"text": "We perform experiments with different combinations of these feature sets.", "labels": [], "entities": []}, {"text": "The following are the features used in our experiments.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Language label distri-", "labels": [], "entities": [{"text": "Language label distri-", "start_pos": 10, "end_pos": 32, "type": "TASK", "confidence": 0.6225385889410973}]}, {"text": " Table 2: POS label distribu-", "labels": [], "entities": [{"text": "POS label distribu-", "start_pos": 10, "end_pos": 29, "type": "TASK", "confidence": 0.6993099376559258}]}, {"text": " Table 3: Average cross-validation accuracy of POS tagging sys-", "labels": [], "entities": [{"text": "accuracy", "start_pos": 35, "end_pos": 43, "type": "METRIC", "confidence": 0.9552591443061829}, {"text": "POS tagging sys", "start_pos": 47, "end_pos": 62, "type": "TASK", "confidence": 0.8261077602704366}]}, {"text": " Table 4: Top error categories produced by top three POS tagging", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 53, "end_pos": 64, "type": "TASK", "confidence": 0.7101965546607971}]}, {"text": " Table 5: POS tagging accuracy of V1, V2 and S2 with gold", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 10, "end_pos": 21, "type": "TASK", "confidence": 0.6371924728155136}, {"text": "accuracy", "start_pos": 22, "end_pos": 30, "type": "METRIC", "confidence": 0.9827190637588501}]}, {"text": " Table 6: Performance of FCRF with handcrafted, stacking and", "labels": [], "entities": [{"text": "FCRF", "start_pos": 25, "end_pos": 29, "type": "DATASET", "confidence": 0.7307051420211792}, {"text": "stacking", "start_pos": 48, "end_pos": 56, "type": "TASK", "confidence": 0.9600426554679871}]}]}