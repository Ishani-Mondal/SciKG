{"title": [{"text": "Deeper Machine Translation and Evaluation for German", "labels": [], "entities": [{"text": "Deeper Machine Translation and Evaluation", "start_pos": 0, "end_pos": 41, "type": "TASK", "confidence": 0.6238507091999054}]}], "abstractContent": [{"text": "This paper describes a hybrid Machine Translation (MT) system built for translating from En-glish to German in the domain of technical documentation.", "labels": [], "entities": [{"text": "Machine Translation (MT)", "start_pos": 30, "end_pos": 54, "type": "TASK", "confidence": 0.858082914352417}]}, {"text": "The system is based on three different MT engines (phrase-based SMT, RBMT, neural) that are joined by a selection mechanism that uses deep linguistic features within a machine learning process.", "labels": [], "entities": [{"text": "MT", "start_pos": 39, "end_pos": 41, "type": "TASK", "confidence": 0.9610960483551025}, {"text": "phrase-based SMT", "start_pos": 51, "end_pos": 67, "type": "TASK", "confidence": 0.43558813631534576}]}, {"text": "It also presents a detailed source-driven manual error analysis we have performed using a dedicated \"test suite\" that contains selected examples of relevant phenomena.", "labels": [], "entities": []}, {"text": "While automatic scores show huge differences between the engines, the overall average number or errors they (do not) make is very similar for all systems.", "labels": [], "entities": []}, {"text": "However, the detailed error breakdown shows that the systems behave very differently concerning the various phenomena.", "labels": [], "entities": []}], "introductionContent": [{"text": "This paper describes a hybrid Machine Translation (MT) system built for translating from English to German in the domain of technical documentation.", "labels": [], "entities": [{"text": "Machine Translation (MT)", "start_pos": 30, "end_pos": 54, "type": "TASK", "confidence": 0.8580593228340149}]}, {"text": "The system builds upon the general architecture described in , but in the current version several components have been improved or replaced.", "labels": [], "entities": []}, {"text": "As detailed in the previous paper, the design of the system was driven by the assumptions that a) none of today's common MT approaches, phrase-based statistical (PB-SMT) or rule-based (RBMT), is on its own capable of providing enough good translations to be useful in an outbound translation scenario without human intervention, and b) \"deep\" linguistic knowledge should help to improve translation quality.", "labels": [], "entities": [{"text": "MT", "start_pos": 121, "end_pos": 123, "type": "TASK", "confidence": 0.974460244178772}]}, {"text": "Instead of building a completely new system, our goal is to adjust and combine existing systems in a smart way using linguistic knowledge.", "labels": [], "entities": []}, {"text": "The system has been developed within the QTLeap project . The goal of the project is to explore different combinations of shallow and deep processing for improving MT quality w.r.t areal use-case scenario (translating user queries and expert answers in a chat-based PC helpdesk scenario).", "labels": [], "entities": [{"text": "QTLeap project", "start_pos": 41, "end_pos": 55, "type": "DATASET", "confidence": 0.9023353159427643}, {"text": "MT", "start_pos": 164, "end_pos": 166, "type": "TASK", "confidence": 0.9879970550537109}]}, {"text": "The system presented in this paper is the final one in a series of system prototypes developed in the project.", "labels": [], "entities": []}, {"text": "The most visible change compared to our earlier system described in) is that we added a neural MT system for the obvious reason that this method has shown state-of-the-art performance, e.g., in the WMT-2016 translation challenge (.", "labels": [], "entities": [{"text": "WMT-2016 translation challenge", "start_pos": 198, "end_pos": 228, "type": "TASK", "confidence": 0.738073726495107}]}, {"text": "We wanted to see how this new type of SMT engine can improve our hybrid system.", "labels": [], "entities": [{"text": "SMT", "start_pos": 38, "end_pos": 41, "type": "TASK", "confidence": 0.9898494482040405}]}, {"text": "In line with our general strategy to include language experts in the MT development cycle described in, we have performed a detailed source-driven error analysis using a dedicated \"test suite\" that contains selected examples of relevant phenomena.", "labels": [], "entities": [{"text": "MT development cycle", "start_pos": 69, "end_pos": 89, "type": "TASK", "confidence": 0.9148350954055786}]}, {"text": "Especially when using MT approaches other than SMT, this makes sure that researchers striving for insights and ideas for improvement are not discouraged by using (only) automatic scores like BLEU that are by design unable to detect changes at the needed level of detail.", "labels": [], "entities": [{"text": "MT", "start_pos": 22, "end_pos": 24, "type": "TASK", "confidence": 0.9702430367469788}, {"text": "SMT", "start_pos": 47, "end_pos": 50, "type": "TASK", "confidence": 0.9883050918579102}, {"text": "BLEU", "start_pos": 191, "end_pos": 195, "type": "METRIC", "confidence": 0.993680477142334}]}, {"text": "This paper is organised as follows: section 2 describes the component of our architecture and section 3 our evaluation efforts.", "labels": [], "entities": []}, {"text": "Section 4 sums up and concludes the paper.", "labels": [], "entities": []}], "datasetContent": [{"text": "As mentioned earlier, the hybrid system is developed and tested on a technical domain.", "labels": [], "entities": []}, {"text": "All results following are done on the second batch of the QTLeap corpus.", "labels": [], "entities": [{"text": "QTLeap corpus", "start_pos": 58, "end_pos": 71, "type": "DATASET", "confidence": 0.9797532856464386}]}, {"text": "shows BLEU scores for the systems that we finally chose to feed into our selection mechanism.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 6, "end_pos": 10, "type": "METRIC", "confidence": 0.999273955821991}]}, {"text": "As reference, we also show scores for the baseline phrase-based SMT system without any of improvements described above.", "labels": [], "entities": [{"text": "SMT", "start_pos": 64, "end_pos": 67, "type": "TASK", "confidence": 0.8914391994476318}]}, {"text": "For evaluation, we have used MTComparEval (.", "labels": [], "entities": [{"text": "MTComparEval", "start_pos": 29, "end_pos": 41, "type": "DATASET", "confidence": 0.5608199238777161}]}, {"text": "While BLEU scores suggest that both statistical systems are clearly outperforming the RBMT system and also the selection mechanism, inspection of examples did not show such a clear picture.: Automatic scores of the independent components and the selection mechanism In order to get more insights into the strengths and weaknesses of the systems, we performed a more systematic and detailed manual error analysis on the results.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 6, "end_pos": 10, "type": "METRIC", "confidence": 0.9990449547767639}]}, {"text": "In context of the QT21 project 5 , we have constructed an expansive test suite containing a wide range of various linguistic phenomena that provides a basis for manual analyses in different contexts.", "labels": [], "entities": [{"text": "QT21 project 5", "start_pos": 18, "end_pos": 32, "type": "DATASET", "confidence": 0.9165393312772115}]}, {"text": "Depending on the focus of a manual inspection, different subsections of the test suite can be used to test and evaluate systems.", "labels": [], "entities": []}, {"text": "Inspired by the performance of the systems reported hereon the test suite, we have constructed a domain-specific test suite based on examples from the QTLeap corpus that represent interesting linguistic phenomena.", "labels": [], "entities": [{"text": "QTLeap corpus", "start_pos": 151, "end_pos": 164, "type": "DATASET", "confidence": 0.9471571743488312}]}, {"text": "The \"linguistic phenomena\" are understood in a pragmatic sense and cover various aspects that influence the translation quality.", "labels": [], "entities": []}, {"text": "Therefore, our phenomena include morpho-syntactic and semantic categories as well as formatting issues, issues of style, etc.", "labels": [], "entities": []}, {"text": "Starting from our evaluation in our contribution to the WMT2016 IT task ( , we have by now developed an efficient manual evaluation process, performed by a professional German linguist.", "labels": [], "entities": [{"text": "WMT2016 IT task", "start_pos": 56, "end_pos": 71, "type": "DATASET", "confidence": 0.7043558756510416}]}, {"text": "This procedure consists of the following steps: 1.", "labels": [], "entities": []}, {"text": "The linguist has a close look at the output of the different MT systems and identifies systematically occurring translation errors that are related to linguistic phenomena.", "labels": [], "entities": [{"text": "MT", "start_pos": 61, "end_pos": 63, "type": "TASK", "confidence": 0.9803006052970886}]}, {"text": "2. For each of these linguistic phenomena that seem to be prone to translation errors, 100 segments containing the phenomenon in the source language are extracted, as inspecting the complete test set would be too time-consuming.", "labels": [], "entities": []}, {"text": "3. For each phenomenon, the total occurrences in the source language are counted.", "labels": [], "entities": []}, {"text": "4. Consequently, the total occurrences in the outputs of the different MT systems are counted.", "labels": [], "entities": [{"text": "MT", "start_pos": 71, "end_pos": 73, "type": "TASK", "confidence": 0.9595245718955994}]}, {"text": "5. The accuracy of the MT outputs for the phenomena is measured by dividing the overall number of correctly translated instances by the overall number of instances in the source segments.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 7, "end_pos": 15, "type": "METRIC", "confidence": 0.9994257688522339}, {"text": "MT", "start_pos": 23, "end_pos": 25, "type": "TASK", "confidence": 0.9910203814506531}]}, {"text": "The phenomena that we found to be prone to translation errors in this context were imperatives, compounds, menu item separators (separated by \">\"), quotation marks, verbs, phrasal verbs and terminology.", "labels": [], "entities": []}, {"text": "As there may always be several correct translations, an occurrence of a phenomenon is not only counted as correctly translated when it matches the reference translation but also when it is for example realized in a different structure that correctly translates the meaning.", "labels": [], "entities": []}, {"text": "The following examples demonstrate the manual evaluation technique: (1) source: Yes, type, for example: 50 miles in km.", "labels": [], "entities": [{"text": "type", "start_pos": 85, "end_pos": 89, "type": "METRIC", "confidence": 0.9655601382255554}]}, {"text": "PB-SMT: Ja, Typ, zum Beispiel, 50 Meilen in km.", "labels": [], "entities": [{"text": "PB-SMT", "start_pos": 0, "end_pos": 6, "type": "DATASET", "confidence": 0.8793988823890686}, {"text": "Typ", "start_pos": 12, "end_pos": 15, "type": "DATASET", "confidence": 0.8496679663658142}]}, {"text": "neural: Ja, Typ, beispielsweise: 50 Meilen in km.", "labels": [], "entities": [{"text": "Typ", "start_pos": 12, "end_pos": 15, "type": "METRIC", "confidence": 0.4809221029281616}]}, {"text": "RBMT-imp.: Tippen Sie zum Beispiel, ja: 50 Meilen in km.", "labels": [], "entities": [{"text": "RBMT-imp.", "start_pos": 0, "end_pos": 9, "type": "DATASET", "confidence": 0.9543620944023132}]}, {"text": "reference: Ja, geben Sie, zum Beispiel: 50 Meilen in km ein.", "labels": [], "entities": []}, {"text": "In example 1, the source segment contains one imperative: \"type\".", "labels": [], "entities": []}, {"text": "A correct German translation needs to have the right verb from + the personal pronoun \"Sie\" in this context.", "labels": [], "entities": []}, {"text": "In most of the cases, the imperative \"type\" is mistranslated as the German noun \"Typ\" instead of the verb \"tippen\" or \"eingeben\", e.g., in the PB-SMT and neural output.", "labels": [], "entities": []}, {"text": "The improved RBMT system on the other hand correctly translates the imperative.", "labels": [], "entities": [{"text": "RBMT", "start_pos": 13, "end_pos": 17, "type": "METRIC", "confidence": 0.39278191328048706}]}, {"text": "Note that the reference translation contains the phrasal verb \"eingeben\" and due to the imperative construction the suffix \"ein\" moves to the end of the sentence.", "labels": [], "entities": []}, {"text": "(2) source: Example 2 depicts the analysis of the menu item separators.", "labels": [], "entities": []}, {"text": "The source contains two instances.", "labels": [], "entities": []}, {"text": "The PB-SMT output treats the words before and after the first separator as a compound, adding a hyphen after the separator.", "labels": [], "entities": []}, {"text": "Therefore, only the second separator counts as correct.", "labels": [], "entities": []}, {"text": "The RBMT treats the separators similarly, adding hyphens before and behind the separators, resulting in no correct instances.", "labels": [], "entities": [{"text": "RBMT", "start_pos": 4, "end_pos": 8, "type": "DATASET", "confidence": 0.7136910557746887}]}, {"text": "The improved RBMT version treats all separators correctly.", "labels": [], "entities": []}, {"text": "The manual evaluation for the paper at hand includes the five systems described above: PB-SMT, RBMT, RBMT-improved, the neural system and the selection mechanism.", "labels": [], "entities": [{"text": "RBMT", "start_pos": 95, "end_pos": 99, "type": "METRIC", "confidence": 0.7278651595115662}, {"text": "RBMT-improved", "start_pos": 101, "end_pos": 114, "type": "METRIC", "confidence": 0.7151559591293335}]}, {"text": "For the aforementioned seven linguistic phenomena, 657 source segments were extracted 6 . In those 657 source segments, 2105 instances of the different phenomena were found overall, as it was often the case that more than one instance occurred per segment.", "labels": [], "entities": []}, {"text": "The results appear in: Translation accuracy on manually evaluated sentences focusing on particular phenomena.", "labels": [], "entities": [{"text": "Translation", "start_pos": 23, "end_pos": 34, "type": "TASK", "confidence": 0.9570465683937073}, {"text": "accuracy", "start_pos": 35, "end_pos": 43, "type": "METRIC", "confidence": 0.9735345840454102}]}, {"text": "Testsets consist of hand-picked source sentences that include the respective phenomenon.", "labels": [], "entities": []}, {"text": "Simple RBMT is separated as it does not participate in the selection mechanism.", "labels": [], "entities": [{"text": "RBMT", "start_pos": 7, "end_pos": 11, "type": "TASK", "confidence": 0.7070350050926208}]}, {"text": "The percentage of the best system in each category is bold-faced, whereas (*) indicates that there is no significant difference (\u03b1 = 0.05) between the selection mechanism and the best system.", "labels": [], "entities": []}, {"text": "As it can be seen in the table, the overall average performance of the components is very similar with no statistically significant difference.", "labels": [], "entities": []}, {"text": "The phrase-based SMT and the RBMT system have the highest overall average scores but interestingly their performances on the different linguistic phenomena are quite complimentary: While the baseline PB-SMT system operates best of all systems on the menu item separators (\">\"), the quotation marks and terminology, the baseline RBMT system performs best on the remaining linguistic categories, namely the imperatives, compounds, verbs and phrasal verbs, as well as the quotation marks.", "labels": [], "entities": [{"text": "SMT", "start_pos": 17, "end_pos": 20, "type": "TASK", "confidence": 0.7087196111679077}]}, {"text": "The PB-SMT system is furthermore doing well on imperatives and verbs but it has the lowest score of all systems regarding the phrasal verbs.", "labels": [], "entities": []}, {"text": "The RBMT system on the other hand also reaches a high score for the quotation marks but has the lowest scores for the menu item separators.", "labels": [], "entities": []}, {"text": "The improved version of the RBMT system, namely the RBMT-improved, has the same performance in the overall average compared to its base system.", "labels": [], "entities": [{"text": "RBMT-improved", "start_pos": 52, "end_pos": 65, "type": "DATASET", "confidence": 0.8475503325462341}]}, {"text": "Likewise, it ranks among the best-performing systems in terms of imperatives, compounds, verbs and phrasal verbs.", "labels": [], "entities": []}, {"text": "Furthermore, it significantly improved on the category it was developed for, i.e. the menu item separator \">\".", "labels": [], "entities": []}, {"text": "At the same time it has visibly lower scores for the quotation marks (as aside effect of the improved treatment of menu items, the treatment of quotation marks is much worse than for the RBMT baseline system).", "labels": [], "entities": []}, {"text": "The neural system reaches a slightly lower score than the other systems.", "labels": [], "entities": []}, {"text": "It ranks among the best systems regarding the imperatives, quotation marks and verbs.", "labels": [], "entities": []}, {"text": "Furthermore it also shows high scores for the menu item separators.", "labels": [], "entities": []}, {"text": "Its score for the compounds on the other hand is the lowest of all systems, close to that of the phrase-based SMT.", "labels": [], "entities": [{"text": "phrase-based SMT", "start_pos": 97, "end_pos": 113, "type": "TASK", "confidence": 0.5115000456571579}]}, {"text": "The selection mechanism obtains the lowest average value of all systems but this score is only three percentage points less than the highest average value.", "labels": [], "entities": []}, {"text": "The selection mechanism is one of the best performing systems on imperatives and verbs.", "labels": [], "entities": []}, {"text": "For the other phenomena it mostly reaches a score that is lower than the scores of its component systems.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Size of corpora used for SMT.", "labels": [], "entities": [{"text": "SMT", "start_pos": 35, "end_pos": 38, "type": "TASK", "confidence": 0.9959751963615417}]}, {"text": " Table 2: Improvements on the RBMT system measured on part of the QTLeap corpus.", "labels": [], "entities": [{"text": "RBMT", "start_pos": 30, "end_pos": 34, "type": "TASK", "confidence": 0.741609513759613}, {"text": "QTLeap corpus", "start_pos": 66, "end_pos": 79, "type": "DATASET", "confidence": 0.9806630611419678}]}, {"text": " Table 3: Automatic scores of the independent components and the selection mechanism", "labels": [], "entities": []}, {"text": " Table 4: Translation accuracy on manually evaluated sentences focusing on particular phenomena. Test- sets consist of hand-picked source sentences that include the respective phenomenon. Simple RBMT is  separated as it does not participate in the selection mechanism. The percentage of the best system in each  category is bold-faced, whereas (*) indicates that there is no significant difference (\u03b1 = 0.05) between  the selection mechanism and the best system.", "labels": [], "entities": [{"text": "Translation", "start_pos": 10, "end_pos": 21, "type": "TASK", "confidence": 0.9717841744422913}, {"text": "accuracy", "start_pos": 22, "end_pos": 30, "type": "METRIC", "confidence": 0.9355890154838562}]}]}