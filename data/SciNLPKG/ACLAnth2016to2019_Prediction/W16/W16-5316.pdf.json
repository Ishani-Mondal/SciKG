{"title": [{"text": "CogALex-V Shared Task: HsH-Supervised -Supervised similarity learning using entry wise product of context vectors", "labels": [], "entities": [{"text": "similarity learning", "start_pos": 50, "end_pos": 69, "type": "TASK", "confidence": 0.7338590323925018}]}], "abstractContent": [{"text": "The CogALex-V Shared Task provides two datasets that consists of pairs of words along with a classification of their semantic relation.", "labels": [], "entities": []}, {"text": "The dataset for the first task distinguishes only between related and unrelated, while the second data set distinguishes several types of semantic relations.", "labels": [], "entities": []}, {"text": "A number of recent papers propose to construct a feature vector that represents a pair of words by applying a pairwise simple operation to all elements of the feature vector.", "labels": [], "entities": []}, {"text": "Subsequently, the pairs can be classified by training any classification algorithm on these vectors.", "labels": [], "entities": []}, {"text": "In the present paper we apply this method to the provided datasets.", "labels": [], "entities": []}, {"text": "We see that the results are not better than from the given simple baseline.", "labels": [], "entities": []}, {"text": "We conclude that the results of the investigated method are strongly depended on the type of data to which it is applied.", "labels": [], "entities": []}], "introductionContent": [{"text": "In distributional semantics words are represented by a large number context features.", "labels": [], "entities": []}, {"text": "In most cases, words context features are based on co-occurrences number or probabilities with other words.", "labels": [], "entities": []}, {"text": "It turns out that words with similar vectors of co-occurrence based features are semantically related.", "labels": [], "entities": []}, {"text": "A simple approach to decide whether two words are semantically related or not, can be based directly on the similarity of their associated vectors.", "labels": [], "entities": []}, {"text": "This approach has been used in a large number of studies.", "labels": [], "entities": []}, {"text": "In order to improve on the quality reached by this simple approach, a number of papers recently proposed to use derived distributional features to represent each pair of words by a large distributional feature vector.", "labels": [], "entities": []}, {"text": "Such a vector can be constructed by taking the pairwise sum or pairwise product of the vectors of two words.", "labels": [], "entities": []}, {"text": "Now, the similarity between two words can be learned by a supervised classification method.", "labels": [], "entities": []}, {"text": "In the following, we will see, how this method can be applied to the first part of the shared task.", "labels": [], "entities": []}, {"text": "Since we have feature representations for each pair of words, we can also try to learn several different relations.", "labels": [], "entities": []}, {"text": "We will do so for the second part of the task.", "labels": [], "entities": []}, {"text": "The rest of the paper is organized as follows.", "labels": [], "entities": []}, {"text": "Section 2 discusses the related works.", "labels": [], "entities": []}, {"text": "In section 3 we will have a short look at the data and the shared task.", "labels": [], "entities": []}, {"text": "Section 4 explains the distributional feature construction, pairwise feature generation and the classification methods.", "labels": [], "entities": [{"text": "distributional feature construction", "start_pos": 23, "end_pos": 58, "type": "TASK", "confidence": 0.6622405548890432}, {"text": "pairwise feature generation", "start_pos": 60, "end_pos": 87, "type": "TASK", "confidence": 0.6420142650604248}]}, {"text": "In section 5 and 6, we present and discuss the results.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section, we will explain the task description, the feature construction for the words, and our approach to the task.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Performance of the HsH-Supervised method and two baselines for both tasks on the test set", "labels": [], "entities": []}]}