{"title": [{"text": "Contextual stance classification of opinions: A step towards enthymeme reconstruction in online reviews", "labels": [], "entities": [{"text": "Contextual stance classification of opinions", "start_pos": 0, "end_pos": 44, "type": "TASK", "confidence": 0.7989470958709717}, {"text": "enthymeme reconstruction", "start_pos": 61, "end_pos": 85, "type": "TASK", "confidence": 0.7531285583972931}]}], "abstractContent": [{"text": "Enthymemes, that are arguments with missing premises, are common in natural language text.", "labels": [], "entities": []}, {"text": "They pose a challenge for the field of argument mining, which aims to extract arguments from such text.", "labels": [], "entities": [{"text": "argument mining", "start_pos": 39, "end_pos": 54, "type": "TASK", "confidence": 0.8113201558589935}]}, {"text": "If we can detect whether a premise is missing in an argument, then we can either fill the missing premise from similar/related arguments , or discard such enthymemes altogether and focus on complete arguments.", "labels": [], "entities": []}, {"text": "In this paper, we draw a connection between explicit vs. implicit opinion classification in reviews, and detecting arguments from enthymemes.", "labels": [], "entities": [{"text": "explicit vs. implicit opinion classification", "start_pos": 44, "end_pos": 88, "type": "TASK", "confidence": 0.7565110683441162}]}, {"text": "For this purpose, we train a binary classifier to detect explicit vs. implicit opinions using a manually labelled dataset.", "labels": [], "entities": []}, {"text": "Experimental results show that the proposed method can discriminate explicit opinions from implicit ones, thereby providing encouraging first step towards enthymeme detection in natural language texts.", "labels": [], "entities": [{"text": "enthymeme detection", "start_pos": 155, "end_pos": 174, "type": "TASK", "confidence": 0.7212708294391632}]}], "introductionContent": [{"text": "Argumentation has become an area of increasing study in artificial intelligence.", "labels": [], "entities": []}, {"text": "Drawing on work from philosophy, which attempts to provide a realistic account of human reasoning, researchers in artificial intelligence have developed computational models of this form of reasoning.", "labels": [], "entities": []}, {"text": "A relatively new sub-field of argumentation is argument mining, which deals with the identification of arguments in text, with an eye to extracting these arguments for later processing, possibly using the tools developed in other areas of argumentation.", "labels": [], "entities": [{"text": "argument mining", "start_pos": 47, "end_pos": 62, "type": "TASK", "confidence": 0.8494420349597931}, {"text": "identification of arguments in text", "start_pos": 85, "end_pos": 120, "type": "TASK", "confidence": 0.8493510723114014}]}, {"text": "Examining arguments that are found in natural language texts quickly leads to the recognition that many such arguments are incomplete (.", "labels": [], "entities": []}, {"text": "That is if you consider an argument to be a set of premises and a conclusion that follows from those premises, one or more of these elements can be missing in natural language texts.", "labels": [], "entities": []}, {"text": "A premise is a statement that indicates support or reason fora conclusion.", "labels": [], "entities": []}, {"text": "In the case where a premise is missing, such incomplete arguments are known as enthymemes.", "labels": [], "entities": []}, {"text": "One classic example is given below.", "labels": [], "entities": []}, {"text": "Major premise All humans are mortal (unstated).", "labels": [], "entities": []}], "datasetContent": [{"text": "Having covered the features we considered, this section describes the experimental setup and the results we obtained.", "labels": [], "entities": []}, {"text": "We used the scikit-learn toolkit library to conduct three experiments.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: F1-scores of 5-fold cross validation results per- formed with different classifiers. The bold figures are the  highest in each column.", "labels": [], "entities": [{"text": "F1-scores", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.999168872833252}]}, {"text": " Table 3: The results of the experiment to identify the best feature set. The table gives the F1 scores for training set and test set  using different sets of features. False positive rate on the test set is also listed. All results were obtained using the Linear SVM  classifier except the baseline classifier. The bold numbers are the highest classification rates in each column, or the lowest false  positive rate for the column, as appropriate.", "labels": [], "entities": [{"text": "F1", "start_pos": 94, "end_pos": 96, "type": "METRIC", "confidence": 0.9989062547683716}, {"text": "False positive rate", "start_pos": 169, "end_pos": 188, "type": "METRIC", "confidence": 0.9857523242632548}]}]}