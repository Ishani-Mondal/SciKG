{"title": [{"text": "Shamela: A Large-Scale Historical Arabic Corpus", "labels": [], "entities": [{"text": "Large-Scale Historical Arabic Corpus", "start_pos": 11, "end_pos": 47, "type": "TASK", "confidence": 0.5016423612833023}]}], "abstractContent": [{"text": "Arabic is a widely-spoken language with a rich and long history spanning more than fourteen centuries.", "labels": [], "entities": []}, {"text": "Yet existing Arabic corpora largely focus on the modern period or lack sufficient di-achronic information.", "labels": [], "entities": []}, {"text": "We develop a large-scale, historical corpus of Arabic of about 1 billion words from diverse periods of time.", "labels": [], "entities": []}, {"text": "We clean this corpus, process it with a morphological ana-lyzer, and enhance it by detecting parallel passages and automatically dating undated texts.", "labels": [], "entities": []}, {"text": "We demonstrate its utility with selected case-studies in which we show its application to the digital humanities.", "labels": [], "entities": []}], "introductionContent": [{"text": "Arabic has been used as a written language for more than fourteen centuries.", "labels": [], "entities": []}, {"text": "While Arabic attracts significant interest from the natural language processing (NLP) community, leading to large corpora and other valuable resources, mostly in Modern Standard Arabic (MSA), we still lack a large-scale, historical corpus of Arabic that covers this entire time period.", "labels": [], "entities": []}, {"text": "This lacuna affects three research communities: it hinders linguists from making corpus-driven historical analyses of the Arabic language; it prevents digital humanities (DH) scholars from investigating the history and culture of the Arabic-speaking people; and it makes it difficult for NLP researchers to develop applications for texts from specific historical periods.", "labels": [], "entities": []}, {"text": "We aim to close this gap by developing a large-scale historical Arabic corpus.", "labels": [], "entities": []}, {"text": "Our corpus is drawn from the Al-Maktaba Al-Shamela website, 1 a website of Arabic texts from the early stages of the language (7th century) to the modern era.", "labels": [], "entities": [{"text": "Al-Maktaba Al-Shamela website", "start_pos": 29, "end_pos": 58, "type": "DATASET", "confidence": 0.752293586730957}]}, {"text": "We have cleaned these texts and organized useful metadata information about them in a semi-automatic process.", "labels": [], "entities": []}, {"text": "We have also lemmatized the entire corpus to facilitate semantic analysis.", "labels": [], "entities": [{"text": "semantic analysis", "start_pos": 56, "end_pos": 73, "type": "TASK", "confidence": 0.874722421169281}]}, {"text": "This step is especially important given the rich morphology of the Arabic language.", "labels": [], "entities": []}, {"text": "The result is a corpus of over 6,000 texts, totaling around 1 billion words, of which 800 million words are from dated texts.", "labels": [], "entities": []}, {"text": "We describe these procedures in some detail to facilitate future similar work.", "labels": [], "entities": []}, {"text": "We present several case-studies showing how this corpus can be used for digital humanities research.", "labels": [], "entities": []}, {"text": "The corpus itself will be made available to the research community.", "labels": [], "entities": []}, {"text": "Finally, we improve and enhance our corpus in two different ways.", "labels": [], "entities": []}, {"text": "First, we detect approximatelymatching parallel passages in the entire corpus.", "labels": [], "entities": []}, {"text": "This turns out to be a computationally challenging task, but yields a very large number of parallel passages.", "labels": [], "entities": []}, {"text": "After excluding 18.6 million words of frequently recurring passages within the corpus, we proceeded to compare each of the texts against the entirety of the corpus.", "labels": [], "entities": []}, {"text": "Our initial run compared one third of the corpus (over 308 million words) with the rest of the corpus and yielded more than 5 million pairwise matches of passages over 20 words in length.", "labels": [], "entities": []}, {"text": "We shed some light on the nature of parallel passages with our analysis.", "labels": [], "entities": []}, {"text": "algorithm based on language modeling in order to date the large portion of undated texts in the corpus (1,200 texts).", "labels": [], "entities": []}, {"text": "We validate the text dating quality both quantitatively and qualitatively.", "labels": [], "entities": [{"text": "text dating", "start_pos": 16, "end_pos": 27, "type": "TASK", "confidence": 0.7076119780540466}]}, {"text": "The remainder of this paper is organized as follows.", "labels": [], "entities": []}, {"text": "In the next section we review related work on Arabic corpora.", "labels": [], "entities": []}, {"text": "We then describe the initial corpus preparation (Section 3) and our enhancements (Section 4).", "labels": [], "entities": []}, {"text": "We demonstrate the application of this corpus with several case-studies in Section 5 before concluding with ideas for future work.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Average date and total number of  texts for example genres.", "labels": [], "entities": [{"text": "Average date", "start_pos": 10, "end_pos": 22, "type": "METRIC", "confidence": 0.8196862637996674}]}, {"text": " Table 2: Accuracy@k of the text dating algorithm.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9971578121185303}, {"text": "text dating", "start_pos": 28, "end_pos": 39, "type": "TASK", "confidence": 0.7619105577468872}]}]}