{"title": [{"text": "Processing non-canonical or noisy text: fortuitous data to the rescue", "labels": [], "entities": []}], "abstractContent": [{"text": "Real world data differs radically from the benchmark corpora we use in NLP, resulting in large performance drops.", "labels": [], "entities": []}, {"text": "The reason for this problem is obvious: NLP models are trained on limited samples from canonical varieties considered standard.", "labels": [], "entities": []}, {"text": "However, there are many dimensions, e.g., sociodemographic, language, genre, sentence type, etc.", "labels": [], "entities": []}, {"text": "on which texts can differ from the standard.", "labels": [], "entities": []}, {"text": "The solution is not obvious: we cannot control for all factors, and it is not clear how to best go beyond the current practice of training on homogeneous data from a single domain and language.", "labels": [], "entities": []}, {"text": "In this talk, I review the notion of canonicity, and how it shapes our community's approach to language.", "labels": [], "entities": []}, {"text": "I argue for the use of fortuitous data.", "labels": [], "entities": []}, {"text": "Fortuitous data is data out there that just waits to be harvested.", "labels": [], "entities": []}, {"text": "It includes data which is in plain sight, but is often neglected, and more distant sources like behavioral data, which first need to be refined.", "labels": [], "entities": []}, {"text": "They provide additional contexts and a myriad of opportunities to build more adaptive language technology, some of which I will explore in this talk.", "labels": [], "entities": []}, {"text": "This work is licensed under a Creative Commons Attribution 4.0 International Licence.", "labels": [], "entities": []}, {"text": "Licence details: http:// creativecommons.org/licenses/by/4.0/ 1", "labels": [], "entities": []}], "introductionContent": [], "datasetContent": [], "tableCaptions": []}