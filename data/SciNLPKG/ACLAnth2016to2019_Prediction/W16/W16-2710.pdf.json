{"title": [{"text": "Applying Neural Networks to English-Chinese Named Entity Transliteration", "labels": [], "entities": [{"text": "Applying Neural Networks", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.7340025703112284}]}], "abstractContent": [{"text": "This paper presents the machine translit-eration systems that we employ for our participation in the NEWS 2016 machine transliteration shared task.", "labels": [], "entities": [{"text": "NEWS 2016 machine transliteration shared task", "start_pos": 101, "end_pos": 146, "type": "TASK", "confidence": 0.6876866022745768}]}, {"text": "Based on the prevalent deep learning models developed for general sequence processing tasks, we use convolutional neural networks to extract character level information from the transliteration units and stack a simple recurrent neural network on top for sequence processing.", "labels": [], "entities": []}, {"text": "The systems are applied to the standard runs for both English to Chi-nese and Chinese to English transliteration tasks.", "labels": [], "entities": []}, {"text": "Our systems achieve competitive results according to the official evaluation.", "labels": [], "entities": []}], "introductionContent": [{"text": "Transliteration is the process of transcribing the source characters ideally accurately as well as unambiguously into a target language that uses a different writing system while preserving the pronunciation.", "labels": [], "entities": []}, {"text": "Machine transliteration is useful in corpus alignment, cross-language information retrieval and extraction.", "labels": [], "entities": [{"text": "corpus alignment", "start_pos": 37, "end_pos": 53, "type": "TASK", "confidence": 0.7603320777416229}, {"text": "cross-language information retrieval", "start_pos": 55, "end_pos": 91, "type": "TASK", "confidence": 0.7417093714078268}]}, {"text": "It is also a good supplement to general machine translation systems for handling out-of-vocabulary-words.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 40, "end_pos": 59, "type": "TASK", "confidence": 0.7414217293262482}]}, {"text": "In this paper, we present a novel transliteration system that is composed of various types of neural networks.", "labels": [], "entities": []}, {"text": "First, we preprocess the training data, pairs of parallel person names, to retrieve segmentations of the transliteration units and their alignments in an unsupervised fashion by using the M2M aligner (.", "labels": [], "entities": []}, {"text": "We start to build the neural network from the character level afterwards.", "labels": [], "entities": []}, {"text": "A convolutional layer is employed to capture the information encoded in the character sequences.", "labels": [], "entities": []}, {"text": "With respect to the transliteration units, the outputs of convolutional layers are fed into a recurrent neural network for sequence to sequence transaction.", "labels": [], "entities": []}, {"text": "Our systems are trained and evaluated on the official English to Chinese and Chinese to English datasets provided by the NEWS 2016 transliteration shared task ().", "labels": [], "entities": [{"text": "NEWS 2016 transliteration shared task", "start_pos": 121, "end_pos": 158, "type": "DATASET", "confidence": 0.9176103591918945}]}, {"text": "We also compare our neural network model with the best performing phrase-based system on English-Chinese transliteration in the 2015 shared task () that is built with the popular machine translation framework Moses ().", "labels": [], "entities": []}], "datasetContent": [{"text": "The ACC and MRR scores of the neural network models in both transliteration directions are not significantly different, which reveals that there are no significant distinctions between the models of the ten best epochs according to their outputs.", "labels": [], "entities": [{"text": "ACC", "start_pos": 4, "end_pos": 7, "type": "METRIC", "confidence": 0.9705408811569214}, {"text": "MRR", "start_pos": 12, "end_pos": 15, "type": "METRIC", "confidence": 0.8720923066139221}]}, {"text": "The Phrase-based SMT system remains very successful and outperforms the neural network model significantly.", "labels": [], "entities": [{"text": "Phrase-based SMT", "start_pos": 4, "end_pos": 20, "type": "TASK", "confidence": 0.5876741111278534}]}, {"text": "The primary reason is that the phrase-based model has a very powerful higherorder language model to harmonise the generated transliteration as a whole sequence.", "labels": [], "entities": []}, {"text": "It is also capable of resolving some segmentation errors via utilising more coarse-grained phrases as transliteration units, whereas the neural network heavily depends on the quality of segmentation.", "labels": [], "entities": []}, {"text": "Besides, for English to Chinese, the neural network model is actually a pipeline system that handles segmentation and decoding separately similarly to the CRF-based models.", "labels": [], "entities": []}, {"text": "The errors arising at the segmentation stage will propagate to the decoding stage and inevitably detriment the overall transliteration accuracy.", "labels": [], "entities": [{"text": "segmentation", "start_pos": 26, "end_pos": 38, "type": "TASK", "confidence": 0.9671643376350403}, {"text": "accuracy", "start_pos": 135, "end_pos": 143, "type": "METRIC", "confidence": 0.9855238795280457}]}, {"text": "For Chinese to English, we use the romanisations of the Chinese characters to build the transliteration system.", "labels": [], "entities": []}, {"text": "It is quite possible that some useful information in the characters for transliteration is lost during the conversion.", "labels": [], "entities": [{"text": "transliteration", "start_pos": 72, "end_pos": 87, "type": "TASK", "confidence": 0.9593487977981567}]}], "tableCaptions": []}