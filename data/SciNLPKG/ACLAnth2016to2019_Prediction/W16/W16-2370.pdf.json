{"title": [], "abstractContent": [{"text": "We participated in the Bilingual Document Alignment shared task of WMT 2016 with the intent of testing plain cross-lingual information retrieval platform built on top of the Apache Lucene framework.", "labels": [], "entities": [{"text": "Bilingual Document Alignment shared task of WMT 2016", "start_pos": 23, "end_pos": 75, "type": "TASK", "confidence": 0.7689934857189655}]}, {"text": "We devised a number of interesting variants, including one that only considers the URLs of the pages, and that offers-without any heuristic-surprisingly high performances.", "labels": [], "entities": []}, {"text": "We finally submitted the output of a system that combines two informa-tions (text and url) from documents and a post-treatment for an accuracy that reaches 92% on the development dataset distributed for the shared task.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 134, "end_pos": 142, "type": "METRIC", "confidence": 0.9993764758110046}]}], "introductionContent": [{"text": "While many recent efforts within the machine translation community are geared toward exploiting bilingual comparable corpora -see () fora pioneering work and () for an extensive review -there is comparatively much less work devoted to identifying parallel documents in a (potentially huge) collection.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 37, "end_pos": 56, "type": "TASK", "confidence": 0.7605665922164917}]}, {"text": "See () for two notable exceptions.", "labels": [], "entities": []}, {"text": "This is due in large part to conventional wisdom that holds that comparable corpora can be found more easily and in larger quantity than parallel data.", "labels": [], "entities": []}, {"text": "Still, we believe that parallel data should not be neglected and should even be preferred when available.", "labels": [], "entities": []}, {"text": "The Bilingual Document Alignment shared task of WMT 2016 is designed for precisely identifying parallel data in a (huge) collection of bilingual documents mined over the Web.", "labels": [], "entities": [{"text": "Bilingual Document Alignment shared task", "start_pos": 4, "end_pos": 44, "type": "TASK", "confidence": 0.8668098092079163}]}, {"text": "The collection has been processed by the organizers in such away that this is easy to test systems: the language of the documents is already detected, and we have access to the content of the Web pages.", "labels": [], "entities": []}, {"text": "Although the organizers encouraged participants to test their own way of pre-processing data, we decided (for the sake of simplicity) to use the data as prepared.", "labels": [], "entities": []}, {"text": "We describe the overall architecture of the BA DLU C framework as well as its components in Section 2.", "labels": [], "entities": [{"text": "BA DLU C framework", "start_pos": 44, "end_pos": 62, "type": "DATASET", "confidence": 0.9482685029506683}]}, {"text": "We explain in Section 3 the experiments we conducted and provide some analysis in Section 4.", "labels": [], "entities": []}, {"text": "We conclude in Section 5.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Performances of some selected variants we tested. The MLT meta-parameters are [tf ,  mindf , maxdf , minwl, maxwl, size, stop], while those specific to the translation process are [keep,  nbT rans]. See Section 2 for more.", "labels": [], "entities": []}, {"text": " Table 2: TOP@1 of the post-processors we tested.", "labels": [], "entities": [{"text": "TOP", "start_pos": 10, "end_pos": 13, "type": "METRIC", "confidence": 0.981105387210846}]}]}