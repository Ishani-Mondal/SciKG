{"title": [], "abstractContent": [{"text": "Recently, researchers in speech recognition have started to reconsider using whole words as the basic modeling unit, instead of phonetic units.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 25, "end_pos": 43, "type": "TASK", "confidence": 0.7924129366874695}]}, {"text": "These systems rely on a function that embeds an arbitrary or fixed dimensional speech segments to a vector in a fixed-dimensional space, named acoustic word embedding.", "labels": [], "entities": []}, {"text": "Thus, speech segments of words that sound similarly will be projected in a close area in a continuous space.", "labels": [], "entities": []}, {"text": "This paper focuses on the evaluation of acoustic word embed-dings.", "labels": [], "entities": []}, {"text": "We propose two approaches to evaluate the intrinsic performances of acoustic word embeddings in comparison to ortho-graphic representations in order to evaluate whether they capture discriminative phonetic information.", "labels": [], "entities": []}, {"text": "Since French language is targeted in experiments, a particular focus is made on homophone words.", "labels": [], "entities": []}], "introductionContent": [{"text": "Recent studies have started to reconsider the use of whole words as the basic modeling unit in speech recognition and query applications, instead of phonetic units.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 95, "end_pos": 113, "type": "TASK", "confidence": 0.7346094101667404}]}, {"text": "These systems are based on the use of acoustic word embedding, which are projection of arbitrary or fixed dimensional speech segments into a continuous space, in a manner that preserve acoustic similarity between words.", "labels": [], "entities": []}, {"text": "Thus, speech segments of words that sound similarly will have similar embeddings.", "labels": [], "entities": []}, {"text": "Acoustic word embedding were successfully used in a queryby-example search system ( and in a ASR lattice re-scoring system).", "labels": [], "entities": []}, {"text": "The authors in) proposed an approach to build acoustic word embeddings from an orthographic representation of the word.", "labels": [], "entities": []}, {"text": "This paper focuses on the evaluation of these acoustic word embeddings.", "labels": [], "entities": []}, {"text": "We propose two approaches to evaluate the intrinsic performances of acoustic word embeddings in comparison to orthographic representations.", "labels": [], "entities": []}, {"text": "In particular we want to evaluate whether they capture discriminative information about their pronunciation, approximated by their phonetic representation.", "labels": [], "entities": []}, {"text": "In our experiments, we focus on French language whose particularity is to be rich of homophone words.", "labels": [], "entities": []}, {"text": "This aspect is also studied in this work.", "labels": [], "entities": []}], "datasetContent": [{"text": "In the literature (), a word discrimination task was used to evaluate acoustic embeddings s.", "labels": [], "entities": [{"text": "word discrimination task", "start_pos": 24, "end_pos": 48, "type": "TASK", "confidence": 0.7969107031822205}]}, {"text": "Given a pair of acoustic segments, this task consists on deciding whether the segments correspond to the same words or not.", "labels": [], "entities": []}, {"text": "This evaluation task can be performed on many ways, for example through the use of a dynamic time warping (DTW) to quantify the similarity between two segments when using frame level embeddings, or by using the euclidean distance or the cosine similarity between embeddings representing the segments.", "labels": [], "entities": []}, {"text": "In) the evaluation was conducted on two collections of words (train and test) coming from the Switchboard English corpus.", "labels": [], "entities": [{"text": "Switchboard English corpus", "start_pos": 94, "end_pos": 120, "type": "DATASET", "confidence": 0.7871529857317606}]}, {"text": "After training the model on the training corpus, the cosine similarity is computed between the embeddings of each pair of words in the test set.", "labels": [], "entities": [{"text": "cosine similarity", "start_pos": 53, "end_pos": 70, "type": "METRIC", "confidence": 0.7901565730571747}]}, {"text": "These pairs are classified as similar or different by applying a threshold on their distance, and a precisionrecall curve is obtained by varying the threshold.", "labels": [], "entities": [{"text": "precisionrecall curve", "start_pos": 100, "end_pos": 121, "type": "METRIC", "confidence": 0.9754756987094879}]}, {"text": "In this study, we propose two approaches to evaluate acoustic word embeddings w + . We suggest to build different evaluation sets in order to assess the acoustic word embeddings (w + ) performances on orthographic and phonetic similarity and homophones detection tasks.", "labels": [], "entities": [{"text": "homophones detection tasks", "start_pos": 242, "end_pos": 268, "type": "TASK", "confidence": 0.7816863258679708}]}, {"text": "We remind that the acoustic word embedding w + is a projection of an orthographic word representation o + into the space of acoustic signal embeddings s.", "labels": [], "entities": []}, {"text": "In our evaluation, we would like to measure the loss of orthographic information carried by w + and the potential gain of acoustic information due to this projection, in comparison to the information carried by o + . The evaluation sets are built as follows: given a list L of n frequent words (candidate words) in the vocabulary composed of m words, a list of n \u00d7 m word pairs was created.", "labels": [], "entities": []}, {"text": "Then, two alignments were performed between each word pair based on their orthographic (letters) and phonetic (phonemes) representations, using the sclite 1 tool.", "labels": [], "entities": []}, {"text": "From these alignment two edition distances are computed with respect to the alignment results of orthographic and phonetic representations.", "labels": [], "entities": []}, {"text": "The Edition distance is computed as follows: #In + #Sub + #Del #symbols in the reference where SER stands for Symbol Error rate, symbols correspond to the letters for orthographic representations, and to the phonemes for phonetic ones, and In, Sub and Del correspond respectively to insertion, substitution and deletion.", "labels": [], "entities": [{"text": "SER", "start_pos": 95, "end_pos": 98, "type": "METRIC", "confidence": 0.996425449848175}, {"text": "Symbol Error rate", "start_pos": 110, "end_pos": 127, "type": "METRIC", "confidence": 0.8045730590820312}]}, {"text": "Next, we compute two similarity scores that correspond to the orthographic and phonetic similarity scores sim score attributed for each pair of words, which are defined as: where min() is a function used to have an edition distance between 0 and 10.", "labels": [], "entities": []}, {"text": "Then, for each candidate word in the list L we extract its orthographically and phonetically 10 nearest words.", "labels": [], "entities": []}, {"text": "This results in two lists for orthographic and phonetic similarity tasks.", "labels": [], "entities": []}, {"text": "For each candidate word in the list L, the Orthographic list contains its ten closest words in terms of orthographic similarity scores and the Phonetic list contains its ten closest words in terms of phonetic similarity scores.", "labels": [], "entities": []}, {"text": "Finally, the Homophones list, used for the homophone detection task, contains the homophone words (i.e. sharing the same phonetic representation).", "labels": [], "entities": [{"text": "homophone detection task", "start_pos": 43, "end_pos": 67, "type": "TASK", "confidence": 0.8473280072212219}]}, {"text": "shows an example of the content of the three lists.", "labels": [], "entities": []}, {"text": "The training set for the CNN consists of 488 hours of French Broadcast News with manual transcriptions.", "labels": [], "entities": [{"text": "French Broadcast News", "start_pos": 54, "end_pos": 75, "type": "DATASET", "confidence": 0.9614228208859762}]}, {"text": "This dataset is composed of data coming from the ESTER1 (), ES-TER2 () and EPAC) corpora.", "labels": [], "entities": [{"text": "ESTER1", "start_pos": 49, "end_pos": 55, "type": "DATASET", "confidence": 0.9121505618095398}, {"text": "EPAC) corpora", "start_pos": 75, "end_pos": 88, "type": "DATASET", "confidence": 0.8761454224586487}]}, {"text": "It contains 52k unique words that have been seen at least twice each in the corpus.", "labels": [], "entities": []}, {"text": "All of them corresponds to a total of 5.75 millions occurrences.", "labels": [], "entities": []}, {"text": "In French language, many words have the same pronunciation without sharing the same spelling, and they can have different meanings; e.g. the sound [so] corresponds to four homophones: sot (fool), saut (jump), sceau (seal) and seau (bucket), and twice more by taking into account their plural forms that have the same pronunciation: sots, sauts, sceaux, and seaux.", "labels": [], "entities": []}, {"text": "When a CNN is trained to predict a word given an acoustic sequence, these frequent homophones can introduce a bias to evaluate the recognition error.", "labels": [], "entities": []}, {"text": "To avoid this, we merged all the homophones existing among the 52k unique words of the training corpus.", "labels": [], "entities": []}, {"text": "As a result, we obtained anew reduced dictionary containing 45k words and classes of homophones.", "labels": [], "entities": []}, {"text": "Acoustic features provided to the CNN are logfilterbanks, computed every 10ms over a 25ms window yielding a 23-dimension vector for each frame.", "labels": [], "entities": []}, {"text": "A forced alignment between manual transcriptions and speech signal was performed on the training set in order to detect word boundaries.", "labels": [], "entities": []}, {"text": "The statistics computed from this alignment reveal that 99% of words are shorter than 1 second.", "labels": [], "entities": []}, {"text": "Hence we decided to represent each word by 100 frames, thus, by a vector of 2300 dimensions.", "labels": [], "entities": []}, {"text": "When words are shorter they are padded with zero equally on both ends, while longer words are cut equally on both ends.", "labels": [], "entities": []}, {"text": "The CNN and DNN deep architectures are trained on 90% of the training set and the remaining 10% are used for validation.", "labels": [], "entities": []}, {"text": "The embeddings we evaluate are built from two different vocabularies: the one used to train the neural network models, composed of 52k words present in the manual transcriptions of the 488 hours of audio; and another one composed of 160k words.", "labels": [], "entities": []}, {"text": "The words present in the 52k vocabulary are nearly all present in the 160k vocabulary.", "labels": [], "entities": []}, {"text": "The evaluation sets described in section 2.2 are generated from these two vocabularies: in the 52k vocabulary, all the acoustic word embeddings w + are related to words which have been observed during the training of the CNN.", "labels": [], "entities": []}, {"text": "This means that at least two acoustic signal embeddings have been computed from the audio for each one of these words; in the 160k vocabulary, about 110k acoustic word embeddings were computed for words never observed in the audio data.", "labels": [], "entities": []}, {"text": "The quantitative evaluation of the acoustic word embeddings w + is performed on orthographic similarity, phonetic similarity, and homophones detection tasks.", "labels": [], "entities": [{"text": "homophones detection", "start_pos": 130, "end_pos": 150, "type": "TASK", "confidence": 0.7216638922691345}]}, {"text": "Results are summarized in: Evaluation results of similarity (\u03c1 \u00d7 100) and homophone detection tasks (precision).", "labels": [], "entities": [{"text": "similarity", "start_pos": 49, "end_pos": 59, "type": "METRIC", "confidence": 0.9689220190048218}, {"text": "homophone detection tasks", "start_pos": 74, "end_pos": 99, "type": "TASK", "confidence": 0.7250481446584066}, {"text": "precision", "start_pos": 101, "end_pos": 110, "type": "METRIC", "confidence": 0.9989792108535767}]}, {"text": "They show that the acoustic word embeddings w + are more relevant for the phonetic similarity task, while o + are obviously the best ones on the orthographic similarity task.", "labels": [], "entities": []}, {"text": "These results show that the projection of the orthographic embeddings o + into the acoustic embeddings space s changes their properties, since they have captured more information about word pronunciation while they have lost information about spelling.", "labels": [], "entities": []}, {"text": "So, in addition to making possible a measure of similarity distance between the acoustic signal (represented by s) and a word (represented by w + ), acoustic word embeddings are better than orthographic ones to measure the phonetic proximity between two words.", "labels": [], "entities": []}, {"text": "For the homophone detection task, the Homophones list is computed from the 160k vocabulary: that results to 53869 homophone pairs in total.", "labels": [], "entities": [{"text": "homophone detection task", "start_pos": 8, "end_pos": 32, "type": "TASK", "confidence": 0.8819813330968221}]}, {"text": "The 52k vocabulary contains 13561 homophone pairs which are included in the pairs present in the 160k vocabulary.", "labels": [], "entities": []}, {"text": "As we can see, thew + acoustic embeddings outperform the orthographic ones on this task on the two data sets.", "labels": [], "entities": []}, {"text": "This confirms that acoustic word embeddings have captured additional information about word pronunciation than the one carried by orthographic word embeddings.", "labels": [], "entities": []}, {"text": "For this task we cannot compare the results between the two vocabularies, since the precision measure is dependent to the number of events.", "labels": [], "entities": [{"text": "precision measure", "start_pos": 84, "end_pos": 101, "type": "METRIC", "confidence": 0.9823096394538879}]}, {"text": "For the Spearman's correlation, a comparison is roughly possible and results show that the way to compute w + is effective to generalize this computation to word not observed in the audio training data.", "labels": [], "entities": []}, {"text": "To give more insight into the difference of the quality of the orthographic word embeddings o + and the acoustic ones w + , we propose an empirical comparison by showing the nearest neighbours of a given set of words.", "labels": [], "entities": []}, {"text": "shows examples of such neighbour.", "labels": [], "entities": []}, {"text": "It can be seen that, as expected, neighbour of any given word share the same spelling with it when they are induced by the orthographic embeddings and arguably sound like it when they are induced by the acoustic word ones.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Evaluation results of similarity (\u03c1 \u00d7 100)  and homophone detection tasks (precision).", "labels": [], "entities": [{"text": "homophone detection tasks", "start_pos": 58, "end_pos": 83, "type": "TASK", "confidence": 0.7468918363253275}, {"text": "precision", "start_pos": 85, "end_pos": 94, "type": "METRIC", "confidence": 0.999376118183136}]}]}