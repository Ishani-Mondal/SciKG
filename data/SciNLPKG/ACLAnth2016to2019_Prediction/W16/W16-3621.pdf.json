{"title": [{"text": "Syntactic parsing of chat language in contact center conversation corpus", "labels": [], "entities": [{"text": "Syntactic parsing", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.9019286632537842}]}], "abstractContent": [{"text": "Chat language is often referred to as Computer-mediated communication (CMC).", "labels": [], "entities": [{"text": "Computer-mediated communication (CMC)", "start_pos": 38, "end_pos": 75, "type": "TASK", "confidence": 0.6692464351654053}]}, {"text": "Most of the previous studies on chat language has been dedicated to collecting \"chat room\" data as it is the kind of data which is the most accessible on the WEB.", "labels": [], "entities": [{"text": "WEB", "start_pos": 158, "end_pos": 161, "type": "DATASET", "confidence": 0.9805096387863159}]}, {"text": "This kind of data falls under the informal register whereas we are interested in this paper in understanding the mechanisms of a more formal kind of CMC: dialog chat in contact centers.", "labels": [], "entities": []}, {"text": "The particularities of this type of dialogs and the type of language used by customers and agents is the focus of this paper towards understanding this new kind of CMC data.", "labels": [], "entities": []}, {"text": "The challenges for processing chat data comes from the fact that Natural Language Processing tools such as syntactic parsers and part of speech taggers are typically trained on mismatched conditions, we describe in this study the impact of such a mismatch fora syntactic parsing task.", "labels": [], "entities": [{"text": "syntactic parsing task", "start_pos": 261, "end_pos": 283, "type": "TASK", "confidence": 0.7973315517107645}]}], "introductionContent": [{"text": "Chat language received attention in recent years as part of the general social media galaxy.", "labels": [], "entities": []}, {"text": "More precisely it is often referred to as.", "labels": [], "entities": []}, {"text": "This term refers to any human communication that occurs through the use of two or more electronic devices such as instant messaging, email or chat rooms.", "labels": [], "entities": []}, {"text": "According to, who conducted an early work on data gathered through the Internet Relay Chat protocol and through emails: \"eletronic discourse is neither writing nor speech, but rather written speech or spoken writing, or something unique\".", "labels": [], "entities": []}, {"text": "Recent projects in Europe, such as the CoMeRe () or the STAC (Asher, 2011) project gathered collections of CMC data in several languages in order to study this new kind of language.", "labels": [], "entities": [{"text": "CoMeRe", "start_pos": 39, "end_pos": 45, "type": "DATASET", "confidence": 0.9059156775474548}, {"text": "STAC (Asher, 2011) project gathered collections of CMC data", "start_pos": 56, "end_pos": 115, "type": "DATASET", "confidence": 0.7915344585975012}]}, {"text": "Most of the effort has been dedicated to \"chat room\" data as it is the kind of data which is the most accessible on the WEB.", "labels": [], "entities": [{"text": "WEB", "start_pos": 120, "end_pos": 123, "type": "DATASET", "confidence": 0.9750670194625854}]}, {"text": "() constituted a corpus in French.", "labels": [], "entities": []}, {"text": "( and) describe similar corpora in English.", "labels": [], "entities": []}, {"text": "have studied the relational structure of such conversations through a deep discursive analysis of chat sessions in an online video game.", "labels": [], "entities": []}, {"text": "This kind of data falls under the informal register whereas we are interested in this paper in understanding the mechanisms of a more formal kind of CMC: dialog chat in contact centers.", "labels": [], "entities": []}, {"text": "This study is realized in the context of the DATCHA project, a collaborative project funded by the French National Research Agency, which aims at performing unsupervised knowledge extraction from very large databases of WEB chat conversations between operators and clients in customer contact centers.", "labels": [], "entities": [{"text": "French National Research Agency", "start_pos": 99, "end_pos": 130, "type": "DATASET", "confidence": 0.846374899148941}, {"text": "knowledge extraction from very large databases of WEB chat conversations between operators and clients in customer contact centers", "start_pos": 170, "end_pos": 300, "type": "TASK", "confidence": 0.7965523468123542}]}, {"text": "As the proportion of online chat interaction is constantly growing in companies' Customer Relationship Management (CRM), it is important to study such data in order to increase the scope of Business Analytics.", "labels": [], "entities": [{"text": "Customer Relationship Management (CRM)", "start_pos": 81, "end_pos": 119, "type": "TASK", "confidence": 0.7995315492153168}]}, {"text": "Furthermore, uch corpora can help us build automatic humanmachine online dialog systems.", "labels": [], "entities": []}, {"text": "Among the few works that have been published on contact center chat conversations, () propose a study from the perspective of the strategies adopted by agents in favor of mutual comprehension, with a focus on discontinuity phenomena, trying to understand the reasons why miscomprehension can arise.", "labels": [], "entities": []}, {"text": "() propose a typology of communication modes between customers and agents through a study on a conversa-tion interface.", "labels": [], "entities": []}, {"text": "In this paper we are interested in evaluating syntactic parsing on such data, with a particular focus on the impact of language deviations.", "labels": [], "entities": [{"text": "syntactic parsing", "start_pos": 46, "end_pos": 63, "type": "TASK", "confidence": 0.7793651223182678}]}, {"text": "After a description of the data and the domain in section 2, we introduce the issue of syntactic parsing in this particular context in section 3.", "labels": [], "entities": [{"text": "syntactic parsing", "start_pos": 87, "end_pos": 104, "type": "TASK", "confidence": 0.800212562084198}]}, {"text": "Then a detailed analysis of language deviations observed in chat conversations is proposed in section 4.", "labels": [], "entities": []}, {"text": "Finaly, experiments of part of speech (pos hereafter) tagging and syntactic parsing are presented in section 5.", "labels": [], "entities": [{"text": "part of speech (pos hereafter) tagging", "start_pos": 23, "end_pos": 61, "type": "TASK", "confidence": 0.6232212893664837}, {"text": "syntactic parsing", "start_pos": 66, "end_pos": 83, "type": "TASK", "confidence": 0.7307616472244263}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Language deviation error rates", "labels": [], "entities": []}, {"text": " Table 2: Proportion (in %) of the different types of  language deviations", "labels": [], "entities": [{"text": "Proportion", "start_pos": 10, "end_pos": 20, "type": "METRIC", "confidence": 0.9567386507987976}]}, {"text": " Table 3: Language deviation by pos: proportion of  each pos in the corpus and corresponding Substi- tution Error Rate", "labels": [], "entities": [{"text": "Substi- tution Error Rate", "start_pos": 93, "end_pos": 118, "type": "METRIC", "confidence": 0.81155846118927}]}, {"text": " Table 4: Description of the DEV corpus in terms of number of words, different words and words occur- ring only once. Figures vary because of splits and agglutinations.", "labels": [], "entities": [{"text": "DEV corpus", "start_pos": 29, "end_pos": 39, "type": "DATASET", "confidence": 0.9142731428146362}]}, {"text": " Table 5: in case of an agglutination, the tag of the  agglutinated token t in the hypothesis is compared  to the tag of the first token in the reference (see  left part of table 5, where the two tags compared  are in bold face). In case of a split, the tag of the  first token in the hypothesis is compared to the tag  of the token in the reference (see right part of the", "labels": [], "entities": []}, {"text": " Table 5: Conventions defined when computing the  accuracy of the tagger for a token. Tags in bold  face are compared", "labels": [], "entities": [{"text": "accuracy", "start_pos": 50, "end_pos": 58, "type": "METRIC", "confidence": 0.9984915256500244}]}, {"text": " Table 7: Influence of token errors on pos tagging,  computed on the customer side of the TEST cor- pus.", "labels": [], "entities": [{"text": "pos tagging", "start_pos": 39, "end_pos": 50, "type": "TASK", "confidence": 0.7419158518314362}, {"text": "TEST cor- pus", "start_pos": 90, "end_pos": 103, "type": "DATASET", "confidence": 0.7826551049947739}]}, {"text": " Table 8: Influence of token errors on pos tagging,  computed on the agent side of the TEST corpus.", "labels": [], "entities": [{"text": "pos tagging", "start_pos": 39, "end_pos": 50, "type": "TASK", "confidence": 0.7317666262388229}, {"text": "TEST corpus", "start_pos": 87, "end_pos": 98, "type": "DATASET", "confidence": 0.8572539389133453}]}, {"text": " Table 9: LAS of the parser output for three types  of input: original tokens (O) and predicted pos  tags, corrected tokens (C) and predicted pos tags  and original tokens and gold pos tags, computed  on the TEST corpus for the customer and the agent  parts of the corpus.", "labels": [], "entities": [{"text": "LAS", "start_pos": 10, "end_pos": 13, "type": "METRIC", "confidence": 0.9767260551452637}, {"text": "TEST corpus", "start_pos": 208, "end_pos": 219, "type": "DATASET", "confidence": 0.888036459684372}]}]}