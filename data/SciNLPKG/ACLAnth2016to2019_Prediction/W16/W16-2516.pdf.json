{"title": [{"text": "Subsumption Preservation as a Comparative Measure for Evaluating Sense-Directed Embeddings", "labels": [], "entities": [{"text": "Subsumption Preservation", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.9737230241298676}]}], "abstractContent": [{"text": "While there has been a growing body of work on word embeddings, and recent directions better reflect sense-level representations , evaluation remains a challenge.", "labels": [], "entities": []}, {"text": "We propose a method of query inventory generation for embedding evaluation that recasts the principle of subsumption preservation, a desirable property of semantic graph-based similarity measures, as a comparative similarity measure as applied to existing lexical resources.", "labels": [], "entities": [{"text": "query inventory generation", "start_pos": 23, "end_pos": 49, "type": "TASK", "confidence": 0.6383307675520579}]}, {"text": "We aim that this method is immediately applied to populate query inventories and perform evaluation with the ordered triple-based approach set forth, and inspires future refinements to existing notions of evaluating sense-directed embeddings.", "labels": [], "entities": []}], "introductionContent": [{"text": "Work in the area of word embeddings has exploded in the last several years.", "labels": [], "entities": [{"text": "word embeddings", "start_pos": 20, "end_pos": 35, "type": "TASK", "confidence": 0.7525738775730133}]}, {"text": "Approaches based on word prediction ( show improvement over traditional and recent work on count based vectors ().", "labels": [], "entities": [{"text": "word prediction", "start_pos": 20, "end_pos": 35, "type": "TASK", "confidence": 0.8025340437889099}]}, {"text": "There has been gradual movement toward sense-directed or sense-level embeddings () while existing evaluation strategies based on applications, human rankings, and solving word choice problems have limitations (.", "labels": [], "entities": []}, {"text": "A limitation of relying on downstream applications for evaluation is that results vary depending on the application (.", "labels": [], "entities": []}, {"text": "In recent work, Tsvetkov (2015) leverages alignment with existing manually crafted lexical resources as a standard for evaluation, which shows a strong correlation with downstream applications.", "labels": [], "entities": []}, {"text": "Along this vein, there is an increasing need for methodologies for word-sense level evaluation measures.", "labels": [], "entities": []}, {"text": "The utility of word embeddings is to reflect notions of similarity and relatedness, and word embeddings intended to represent senses should in turn reflect structured relations like hypernymy and meronymy.", "labels": [], "entities": []}, {"text": "Most existing resources on lexical similarity and relatedness rely on subjective scores assigned between word pairs.", "labels": [], "entities": []}, {"text": "This style of evaluation suffers from limited size of the evaluation sets and subjectivity of annotators.", "labels": [], "entities": []}, {"text": "To address the first issue, we propose a method for exploiting existing knowledge formalized in lexical resources and ontologies as a means to automating the process of populating a query inventory.", "labels": [], "entities": []}, {"text": "To address the second issue, we propose an evaluation approach that, instead of human scoring of word pairs, relies on comparative similarity given a semantic ordering represented as 3-tuples (henceforth triples).", "labels": [], "entities": []}, {"text": "The method applies the principle of subsumption preservation as a standard by which to generate a query inventory and evaluate word embedding by geometric similarity.", "labels": [], "entities": [{"text": "subsumption preservation", "start_pos": 36, "end_pos": 60, "type": "TASK", "confidence": 0.7491000592708588}]}, {"text": "For example, subsumption is preserved when the similarity score of embeddings representing ferry and boat is greater than that of ferry and vessel.", "labels": [], "entities": [{"text": "similarity score", "start_pos": 47, "end_pos": 63, "type": "METRIC", "confidence": 0.9243837296962738}]}, {"text": "In the following section we illuminate the method, evaluation approach, an exploratory experiment, its results, related work, and next steps.", "labels": [], "entities": []}], "datasetContent": [{"text": "Traditionally word pairs of a query inventory are scored by similarity with a value between 0-1.", "labels": [], "entities": []}, {"text": "We propose a different approach based on the unit of ordered triple instead of pairs, and that is relative rather than absolute and quantitative.", "labels": [], "entities": []}, {"text": "Given a set of tuples of a relation rel that sim is potentially constrained by under subsumption preservation, we consider the candidate triples as instances of a query inventory for evaluation.", "labels": [], "entities": []}, {"text": "A similar approach has been applied in the evaluation of machine translation.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 57, "end_pos": 76, "type": "TASK", "confidence": 0.7573570609092712}]}, {"text": "Kahn (2009) describes a family of dependency pair match measures that are composed of precision and recall over various decompositions of a syntactic dependency tree.", "labels": [], "entities": [{"text": "precision", "start_pos": 86, "end_pos": 95, "type": "METRIC", "confidence": 0.9991185069084167}, {"text": "recall", "start_pos": 100, "end_pos": 106, "type": "METRIC", "confidence": 0.9958614706993103}]}, {"text": "A dependency parser determines the relevant word triples where the relation is the second element.", "labels": [], "entities": []}, {"text": "Reference and hypothesis sentences are converted to a labeled syntactic dependence tree, and the relations from each tree are extracted and compared.", "labels": [], "entities": []}, {"text": "We draw inspiration from this approach, where the unit of evaluation is the ordered triple.", "labels": [], "entities": []}, {"text": "Given the nature of our task we apply the measure of accuracy on the triples.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 53, "end_pos": 61, "type": "METRIC", "confidence": 0.9995707869529724}]}, {"text": "For evaluation the BLESS dataset is selected as the basis for selecting a triple-based query inventory, (), focusing on hypernymy and leaving meronymy as a future consider-ation.", "labels": [], "entities": [{"text": "BLESS", "start_pos": 19, "end_pos": 24, "type": "METRIC", "confidence": 0.9854897260665894}]}, {"text": "For pairs that are related by hypernymy we identify intermediate words within the hypernym graph to generate candidate triples, including only nouns.", "labels": [], "entities": []}, {"text": "For embeddings we used word2vec-based embeddings generated from google corpora.", "labels": [], "entities": []}, {"text": "For the similarity measure we selected cosine similarity, although the evaluation approach assumes embeddings and a similarity measure are two variables.", "labels": [], "entities": []}, {"text": "So for example the score of sim(broccoli, vegetable) is greater than sim(broccoli,produce), therefore one part of the subsumption preservation principle is conformed to for the triple broccoli, vegetable, produce.", "labels": [], "entities": []}, {"text": "Also, sim(vegetable, produce) is greater than sim(broccoli, produce), therefore the triple is also in conformance with the other part of the subsumption preserved principle, namely reverse subsumption preservation.", "labels": [], "entities": [{"text": "reverse subsumption preservation", "start_pos": 181, "end_pos": 213, "type": "TASK", "confidence": 0.6211871405442556}]}, {"text": "We consider two approaches for calculating cosine similarity between words within the word2vec generated embeddings.", "labels": [], "entities": []}, {"text": "The first is the simple approach and is performed by calculating the cosine between two word embeddings.", "labels": [], "entities": []}, {"text": "The second is the aggregate approach, and requires, for each of the two words, exhaustively collecting all sister lemmas for the senses each word is a lemma of, calculating the centroid for all corresponding embeddings, and calculating cosine similarity between the resultant pair of centroid embeddings.", "labels": [], "entities": []}, {"text": "The aggregate approach is in effort to simulate sense level embeddings for this exploration.", "labels": [], "entities": []}, {"text": "We also consider the role of word generality in the evaluation.", "labels": [], "entities": [{"text": "word generality", "start_pos": 29, "end_pos": 44, "type": "TASK", "confidence": 0.6835555285215378}]}], "tableCaptions": [{"text": " Table 1: Accuracy figures for the triple-based  query inventory generated from the BLESS  dataset and WordNet.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9961686730384827}, {"text": "BLESS  dataset", "start_pos": 84, "end_pos": 98, "type": "DATASET", "confidence": 0.7850518822669983}, {"text": "WordNet", "start_pos": 103, "end_pos": 110, "type": "DATASET", "confidence": 0.9585370421409607}]}]}