{"title": [{"text": "A Comparison of Event Representations in DEFT", "labels": [], "entities": [{"text": "DEFT", "start_pos": 41, "end_pos": 45, "type": "TASK", "confidence": 0.4860885441303253}]}], "abstractContent": [{"text": "This paper will discuss and compare event representations across a variety of types of event annotation: Rich Entities, Relations, and Events (Rich ERE), Light Entities, Relations, and Events (Light ERE), Event Nugget (EN), Event Argument Extraction (EAE), Richer Event Descriptions (RED), and Event-Event Relations (EER).", "labels": [], "entities": []}, {"text": "Comparisons of event representations are presented, along with a comparison of data annotated according to each event representation.", "labels": [], "entities": []}, {"text": "An event annotation experiment is also discussed, including annotation for all of these representations on the same set of sample data, with the purpose of being able to compare actual annotation across all of these approaches as directly as possible.", "labels": [], "entities": []}, {"text": "We walk through a brief example to illustrate the various annotation approaches, and to show the intersections among the various annotated data sets.", "labels": [], "entities": []}], "introductionContent": [{"text": "This paper will discuss and compare event representations across the various types of event annotation that are part of the Deep Exploration and Filtering of Text (DEFT) program: Rich Entities, Relations, and Events (Rich ERE), Light Entities, Relations, and Events (Light ERE), Event Nugget (EN), Event Argument Extraction (EAE), Richer Event Descriptions (RED), and Event-Event Relations (EER).", "labels": [], "entities": []}, {"text": "The DEFT program seeks to improve state-of-the-art capabilities in automated deep natural language processing, with a particular focus on technologies dealing with inference, causal relationships, and anomaly detection across several languages.", "labels": [], "entities": []}, {"text": "The processing of events and event-event relations underlies this focus.", "labels": [], "entities": []}, {"text": "The annotation of events and event-event relations is a crucial part of supporting work on these technologies, and a variety of approaches are currently underway.", "labels": [], "entities": []}, {"text": "This paper presents a comparison of event representations, the data annotated, and possible future plans for event annotation.", "labels": [], "entities": [{"text": "event annotation", "start_pos": 109, "end_pos": 125, "type": "TASK", "confidence": 0.715974360704422}]}, {"text": "An event annota-tion experiment is also discussed, in which the same set of sample data was annotated in each of the above representations, with the purpose of being able to compare actual annotation across all of these approaches as directly as possible.", "labels": [], "entities": []}, {"text": "The paper walks through a brief example to illustrate the various annotation approaches, and to show the intersections among the various annotated data sets.", "labels": [], "entities": []}], "datasetContent": [{"text": "As a result of this diversity in event annotation within DEFT, the Event Working Group which is focusing on events within DEFT has initiated an experiment in which participating teams perform event annotations on the same set of data using all of the different annotation schemas.", "labels": [], "entities": [{"text": "DEFT", "start_pos": 57, "end_pos": 61, "type": "DATASET", "confidence": 0.8795756697654724}, {"text": "DEFT", "start_pos": 122, "end_pos": 126, "type": "DATASET", "confidence": 0.9257242679595947}]}, {"text": "The goal of the experiment is to make the differences and similarities between the approaches more apparent and to facilitate comparison.", "labels": [], "entities": []}, {"text": "The 50 documents that had been dually assessed for EAE in 2014 were chosen as the data set for the experiment, as both system output and human assessment already exists for the data.", "labels": [], "entities": []}, {"text": "Additionally, five newswire documents from the EAE pilot data pool were identified as particularly challenging for event annotation, and so these five documents were also included in the experiment set.", "labels": [], "entities": [{"text": "EAE pilot data pool", "start_pos": 47, "end_pos": 66, "type": "DATASET", "confidence": 0.9287736862897873}, {"text": "event annotation", "start_pos": 115, "end_pos": 131, "type": "TASK", "confidence": 0.799819678068161}]}, {"text": "The annotation for this experiment has been completed and released to the DEFT community (LDC, 2015) and will be subsequently published in LDC's catalog, making it available to the broader research community.", "labels": [], "entities": [{"text": "DEFT community (LDC, 2015)", "start_pos": 74, "end_pos": 100, "type": "DATASET", "confidence": 0.9339942676680428}]}, {"text": "EN annotation in this experiment adopted the 2014 annotation schema, instead of the 2015 schema.", "labels": [], "entities": [{"text": "EN", "start_pos": 0, "end_pos": 2, "type": "DATASET", "confidence": 0.8569456934928894}]}, {"text": "Additionally EAE annotation in the experiment did not group arguments of the same event.", "labels": [], "entities": [{"text": "EAE", "start_pos": 13, "end_pos": 16, "type": "METRIC", "confidence": 0.9026196599006653}]}, {"text": "To illustrate the differences of the annotation tasks, below are the annotations in each represention for the following two sentences:", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 4: Volume of data manually annotated for the Event Experiment, for 2014, and for 2015.", "labels": [], "entities": []}]}