{"title": [{"text": "Semantic Indexing of Multilingual Corpora and its Application on the History Domain", "labels": [], "entities": [{"text": "Semantic Indexing of Multilingual Corpora", "start_pos": 0, "end_pos": 41, "type": "TASK", "confidence": 0.8631470441818238}, {"text": "History Domain", "start_pos": 69, "end_pos": 83, "type": "DATASET", "confidence": 0.9317891895771027}]}], "abstractContent": [{"text": "The increasing amount of multilingual text collections available in different domains makes its automatic processing essential for the development of a given field.", "labels": [], "entities": []}, {"text": "However, standard processing techniques based on statistical clues and keyword searches have clear limitations.", "labels": [], "entities": []}, {"text": "Instead, we propose a knowledge-based processing pipeline which overcomes most of the limitations of these techniques.", "labels": [], "entities": []}, {"text": "This, in turn, enables direct comparison across texts in different languages without the need of translation.", "labels": [], "entities": []}, {"text": "In this paper we show the potential of this approach for semantically indexing multilingual text collections in the history domain.", "labels": [], "entities": [{"text": "semantically indexing multilingual text collections", "start_pos": 57, "end_pos": 108, "type": "TASK", "confidence": 0.7646540403366089}]}, {"text": "In our experiments we used aversion of the Bible translated in four different languages, evaluating the precision of our semantic indexing pipeline and showing its reliability on the cross-lingual text retrieval task.", "labels": [], "entities": [{"text": "precision", "start_pos": 104, "end_pos": 113, "type": "METRIC", "confidence": 0.9988119602203369}, {"text": "cross-lingual text retrieval", "start_pos": 183, "end_pos": 211, "type": "TASK", "confidence": 0.6362154384454092}]}], "introductionContent": [{"text": "In recent years there has been a growing interest in automatically processing historical corpora due to the increasing number of available text collections in the field (.", "labels": [], "entities": []}, {"text": "However, few software applications for non-expert users have been developed for processing and indexing historical texts, and these applications are in the main based on statistical processing techniques only.", "labels": [], "entities": [{"text": "indexing historical texts", "start_pos": 95, "end_pos": 120, "type": "TASK", "confidence": 0.8871836463610331}]}, {"text": "Even though these techniques have been and are currently widely used, they have clear limitations.", "labels": [], "entities": []}, {"text": "First, standard statistical processing techniques based on keywords do not handle the inherent ambiguity within language.", "labels": [], "entities": []}, {"text": "Second, occurrences of the same concept/event/entity are often referred to via different lexicalizations (e.g. Louis XIV, Louis the Great and Sun King), which are not captured by keyword-based text retrieval techniques.", "labels": [], "entities": []}, {"text": "Finally, these approaches are bound to remain monolingual by nature, limiting their applicability to multilingual corpora, which is growing in interest over the years.", "labels": [], "entities": []}, {"text": "There have been recent approaches to automatically link cultural heritage items from text corpora to knowledge bases () but without going beyond the monolingual level.", "labels": [], "entities": []}, {"text": "In fact, to date most approaches towards the accessibility of cultural heritage content in multiple languages have focused on the generation of natural language content through knowledge bases or via the Semantic Web.", "labels": [], "entities": []}, {"text": "Instead, we propose a knowledge-based pipeline for automatically processing multilingual corpora which overcomes all previously mentioned limitations by going beyond standard statistical techniques and keyword-based queries.", "labels": [], "entities": []}, {"text": "Our approach is based on the disambiguation of text corpora through a knowledge base.", "labels": [], "entities": []}, {"text": "Disambiguation is then exploited for semantically indexing multilingual text collections by associating each concept/entity with a unique identifier independent on the language and the surface form.", "labels": [], "entities": []}, {"text": "This in turn enables direct applications across languages such as cross-lingual text retrieval, and opens up new lines of research to study cross-cultural differences from multilingual text corpora ().", "labels": [], "entities": [{"text": "cross-lingual text retrieval", "start_pos": 66, "end_pos": 94, "type": "TASK", "confidence": 0.6302110155423483}]}], "datasetContent": [{"text": "We perform an evaluation to test the disambiguation quality of our multilingual semantic processing pipeline (Section 4.1) and the cross-lingual text retrieval application (Section 4.2).", "labels": [], "entities": [{"text": "cross-lingual text retrieval", "start_pos": 131, "end_pos": 159, "type": "TASK", "confidence": 0.593576451142629}]}, {"text": "For both evaluations we use the same reference corpus, which is the Bible 6 translated into four different languages: English, Spanish, French, and Russian.", "labels": [], "entities": []}, {"text": "Each language version consists of 1189 chapters of different sizes, ranging from 21 to 2423 words (588 words on average).", "labels": [], "entities": []}, {"text": "Given a chapter of the Bible in one language (i.e., input language), the task consists of retrieving the same chapter in another language (i.e., output language) among the 1189 possible chapters . Formally, given a chapter of the Bible in the input language, the system calculates the similarity between the given chapter and all the chapters in the output language.", "labels": [], "entities": []}, {"text": "The chapter of the output language obtaining the highest similarity score is selected as retrieved chapter for the system.", "labels": [], "entities": [{"text": "similarity score", "start_pos": 57, "end_pos": 73, "type": "METRIC", "confidence": 0.9626092910766602}]}, {"text": "This task is intended to test the cross-lingual text retrieval application proposed in Section 3, which is based in the semantic indexing presented in Section 2.2.: Accuracy (%) of all comparison systems for the cross-lingual text retrieval task in the Bible.", "labels": [], "entities": [{"text": "cross-lingual text retrieval", "start_pos": 34, "end_pos": 62, "type": "TASK", "confidence": 0.6162578066190084}, {"text": "Accuracy", "start_pos": 165, "end_pos": 173, "type": "METRIC", "confidence": 0.9958240985870361}, {"text": "cross-lingual text retrieval task", "start_pos": 212, "end_pos": 245, "type": "TASK", "confidence": 0.7096240445971489}]}, {"text": "We include two baselines relying on monolingual text similarity measures after translation, using English as pivot language.", "labels": [], "entities": []}, {"text": "This monolingual similarity measurement after translation is the most common approach in cross-lingual text similarity tasks (.", "labels": [], "entities": [{"text": "cross-lingual text similarity tasks", "start_pos": 89, "end_pos": 124, "type": "TASK", "confidence": 0.6570210158824921}]}, {"text": "For these baselines all the Bible chapters in languages other than English were automatically translated to English using the Bing Translator Machine Translation system 10 , which covers the four languages considered in the evaluation.", "labels": [], "entities": [{"text": "Bing Translator Machine Translation", "start_pos": 126, "end_pos": 161, "type": "TASK", "confidence": 0.6570752114057541}]}, {"text": "The first baseline system (MT+Jacc.) calculates the similarity between the content words of the output texts after translation by using the Jaccard index.", "labels": [], "entities": [{"text": "MT+Jacc.", "start_pos": 27, "end_pos": 35, "type": "DATASET", "confidence": 0.632672111193339}]}, {"text": "The second baseline (MT+W2V) leverages word embeddings to calculate the similarity between the translated texts.", "labels": [], "entities": []}, {"text": "The similarity measure consists of the cosine similarity between the average vector of the content word embeddings of both respective translated texts.", "labels": [], "entities": []}, {"text": "This approach based on the centroid vector is often used in the literature to obtain representations of sentences and documents).", "labels": [], "entities": []}, {"text": "As word embeddings we use the pre-trained Word2Vec () vectors trained on the Google News corpus 11 . shows the accuracy 12 results of all comparison systems in the cross-lingual text retrieval task using the Bible as gold standard comparable corpus for four different languages: English, Spanish, French, and Russian.", "labels": [], "entities": [{"text": "Google News corpus 11", "start_pos": 77, "end_pos": 98, "type": "DATASET", "confidence": 0.8349904268980026}, {"text": "accuracy", "start_pos": 111, "end_pos": 119, "type": "METRIC", "confidence": 0.9992750287055969}, {"text": "cross-lingual text retrieval", "start_pos": 164, "end_pos": 192, "type": "TASK", "confidence": 0.6565964221954346}]}, {"text": "Given the current state of MT systems, the high results obtained by the translationbased system are not surprising.", "labels": [], "entities": [{"text": "MT", "start_pos": 27, "end_pos": 29, "type": "TASK", "confidence": 0.978544294834137}]}, {"text": "However, our simple system based on inherently imperfect disambiguation achieves comparable results to the baseline based on the lexical similarity measure after translation (MT+Jacc.) and improves considerably the results of the system based on word embeddings after translation (MT+W2V).", "labels": [], "entities": [{"text": "MT+W2V", "start_pos": 281, "end_pos": 287, "type": "DATASET", "confidence": 0.7333466410636902}]}, {"text": "This improvement over the system based on word embeddings maybe due to two main factors.", "labels": [], "entities": []}, {"text": "First, since the translation is carried out automatically, it maybe prompt to errors.", "labels": [], "entities": [{"text": "translation", "start_pos": 17, "end_pos": 28, "type": "TASK", "confidence": 0.9794529676437378}]}, {"text": "Second, even though word embeddings have already shown its potential in obtaining accurate semantic representations of lexical items, they may not be so accurate to model larger semantic units such as documents.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Precision (%) of Babelfy after preprocessing and the MCS baseline in the Bible.", "labels": [], "entities": [{"text": "Precision", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9978736639022827}]}, {"text": " Table 2: Accuracy (%) of all comparison systems for the cross-lingual text retrieval task in the Bible.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9990260601043701}, {"text": "cross-lingual text retrieval task", "start_pos": 57, "end_pos": 90, "type": "TASK", "confidence": 0.7026727646589279}]}]}