{"title": [{"text": "Contextual term equivalent search using domain-driven disambiguation", "labels": [], "entities": [{"text": "Contextual term equivalent search", "start_pos": 0, "end_pos": 33, "type": "TASK", "confidence": 0.7427724897861481}]}], "abstractContent": [{"text": "This article presents a domain-driven algorithm for the task of term sense disambiguation (TSD).", "labels": [], "entities": [{"text": "term sense disambiguation (TSD)", "start_pos": 64, "end_pos": 95, "type": "TASK", "confidence": 0.8239914973576864}]}, {"text": "TSD aims at automatically choosing which term record from a term bank best represents the meaning of a term occurring in a particular context.", "labels": [], "entities": [{"text": "TSD", "start_pos": 0, "end_pos": 3, "type": "TASK", "confidence": 0.7097750306129456}]}, {"text": "Ina translation environment, finding the contextually appropriate term record is necessary to access the proper equivalent to be used in the target language text.", "labels": [], "entities": []}, {"text": "The term bank TERMIUM Plus R , recently published as an open access repository, is chosen as a domain-rich resource for testing our TSD algorithm, using English and French as source and target languages.", "labels": [], "entities": [{"text": "TERMIUM Plus R", "start_pos": 14, "end_pos": 28, "type": "METRIC", "confidence": 0.917276660601298}]}, {"text": "We devise an experiment using over 1300 English terms found in scientific articles, and show that our domain-driven TSD algorithm is able to bring the best term record, and therefore the best French equivalent, at the average rank of 1.69 compared to a baseline random rank of 3.51.", "labels": [], "entities": []}], "introductionContent": [{"text": "We will start this article by introducing, in Section 2, a terminological database called TERMIUM Plus R (referred to as TERMIUM for the rest of the article), which was manually constructed over many years by expert terminologists at the Translation Bureau of Canada.", "labels": [], "entities": [{"text": "TERMIUM Plus R", "start_pos": 90, "end_pos": 104, "type": "METRIC", "confidence": 0.9643760919570923}, {"text": "TERMIUM", "start_pos": 121, "end_pos": 128, "type": "METRIC", "confidence": 0.8581677079200745}]}, {"text": "TERMIUM full terminological database has recently been released in an open-data format allowing its use for various research experiments in computational terminology, such as database-wide statistical measures.", "labels": [], "entities": [{"text": "TERMIUM", "start_pos": 0, "end_pos": 7, "type": "METRIC", "confidence": 0.6001736521720886}]}, {"text": "One particular measure of interest is the notion of similarity between domains, which we present in Section 3.", "labels": [], "entities": []}, {"text": "Section 4 describes our main research contribution, a domain-driven term sense disambiguation (TSD) algorithm.", "labels": [], "entities": [{"text": "term sense disambiguation (TSD)", "start_pos": 68, "end_pos": 99, "type": "TASK", "confidence": 0.7397201706965765}]}, {"text": "TSD aims at automatically determining which term record from a term bank best represents the meaning of a term given its context.", "labels": [], "entities": [{"text": "TSD", "start_pos": 0, "end_pos": 3, "type": "TASK", "confidence": 0.6227500438690186}]}, {"text": "This is a task that translators must perform on a regular basis when translating specialized texts containing specialized terminology.", "labels": [], "entities": []}, {"text": "Finding the contextually appropriate term record leads the translator to the proper equivalent to use in his or her translation.", "labels": [], "entities": []}, {"text": "Making the algorithm domain-driven means that the information that will be used to perform the disambiguation task is the domain information provided in each term record of the term bank.", "labels": [], "entities": []}, {"text": "For example, according to TERMIUM, the French equivalent promontoire would be proper for the word head found in a text segment about the TOPONYMY domain, but the equivalent t\u00eate would be more appropriate in other domains such as STRING INSTRUMENT, or In Section 5, we present an experiment to evaluate the performances of our algorithm.", "labels": [], "entities": [{"text": "TERMIUM", "start_pos": 26, "end_pos": 33, "type": "METRIC", "confidence": 0.9534404873847961}, {"text": "TOPONYMY domain", "start_pos": 137, "end_pos": 152, "type": "DATASET", "confidence": 0.855417788028717}, {"text": "STRING", "start_pos": 229, "end_pos": 235, "type": "METRIC", "confidence": 0.5553463101387024}, {"text": "INSTRUMENT", "start_pos": 236, "end_pos": 246, "type": "METRIC", "confidence": 0.4587315320968628}]}, {"text": "We will describe the dataset composed of 1500 terms found in abstracts of scientific publications, the human annotation performed to build a gold standard, the algorithm parameter optimisation using a subset of 200 terms, and the final results on the remaining 1300 terms.", "labels": [], "entities": []}, {"text": "Domain-driven TSD is definitely an underexplored task within the Natural Language Processing literature, and Section 6 will give some pointers to only a few related works which rather use domain information as complementing other information for disambiguation.", "labels": [], "entities": [{"text": "TSD", "start_pos": 14, "end_pos": 17, "type": "TASK", "confidence": 0.6895624399185181}]}, {"text": "Term disambiguation in general, domain-driven or not, is rarely explored perhaps due to a misconception that terms are monosemous and that disambiguation is not necessary in specialized domains.", "labels": [], "entities": [{"text": "Term disambiguation", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.9314109086990356}]}, {"text": "Although that statement is true of most multi-word terms, it is certainly not true of the many single-word terms found in specialized texts which tend to lead to multiple term records.", "labels": [], "entities": []}, {"text": "Finally, in Section 7, we conclude and give an outlook to future work.", "labels": [], "entities": []}], "datasetContent": [{"text": "This section describes a term sense disambiguation experiment applied on a large dataset of 1500 terms.", "labels": [], "entities": [{"text": "term sense disambiguation", "start_pos": 25, "end_pos": 50, "type": "TASK", "confidence": 0.6951300799846649}]}, {"text": "We first describe the dataset and the human domain annotation performed to obtain our gold standard.", "labels": [], "entities": []}, {"text": "Then, we describe the various parameter adjustments performed on a subset of 200 annotated terms which we used as our development set.", "labels": [], "entities": []}, {"text": "Finally, we describe the results of the fine-tuned algorithm on the remaining set of 1300 terms.", "labels": [], "entities": []}, {"text": "For our experiment, we use a dataset described in) of scientific abstracts from various journals published by the Research Press of National Research Council of Canada 5 . In total, the dataset contains 3347 abstracts from eleven journals covering topics of biology, earth science, chemistry, and more.", "labels": [], "entities": []}, {"text": "The short example text used in Section 4 for describing the algorithm was taken from an abstract of an article in a biology journal.", "labels": [], "entities": []}, {"text": "The abstracts are usually followed by three to five author-provided specialized keywords (terms).", "labels": [], "entities": []}, {"text": "We earlier discussed how nucleus could be such a possible term from this abstract.", "labels": [], "entities": []}, {"text": "For a term to be included in our dataset, we require that it be present in TERMIUM and be polysemous.", "labels": [], "entities": [{"text": "TERMIUM", "start_pos": 75, "end_pos": 82, "type": "METRIC", "confidence": 0.9484673142433167}]}, {"text": "Given these constraints, we gathered 1500 terms for testing from which 200 terms were used for development.", "labels": [], "entities": []}, {"text": "The degree of polysemy varies largely among the dataset.", "labels": [], "entities": []}, {"text": "To provide a few statistics, we measured that 38.3% of the terms led to only 2 records, 22.8% led to 3 and 4 records, but there are also 20.7% of the terms leading to more than 10 records, providing quite a challenge for automatic disambiguation.", "labels": [], "entities": []}, {"text": "In the same way that our development set was reduced from 200 terms to 178 terms given the various cases encountered during the annotation effort, the evaluation dataset also ended up being reduced from 1300 terms to 1175 terms.", "labels": [], "entities": []}, {"text": "On these 1175 terms, the random rank was evaluated at 3.51 and the domain-driven disambiguation algorithm, using the best combination of parameters (PMI, monosemic terms, keeping only nouns), reduced that rank to 1.69, showing a significant improvement.", "labels": [], "entities": []}, {"text": "In, we further show the proportion of terms leading to the various ranks.", "labels": [], "entities": []}, {"text": "It is interesting to see that for almost 75% of the terms, the algorithm succeeds in bringing the best record to the top (rank 1).", "labels": [], "entities": []}, {"text": "From an application point of view, the most interesting result lies in the disambiguation capability of the algorithm for largely polysemous terms, since those would be time-consuming for translators, requiring them to go through multiple records to find the appropriate record given the context.", "labels": [], "entities": []}, {"text": "For example, the term disturbance has 12 term records, roughness has 13, binding has 25 and cluster has 40, and for all those terms, the algorithm was able to bring the contextually appropriate term record to the top rank.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Examples of terms in TERMIUM", "labels": [], "entities": [{"text": "TERMIUM", "start_pos": 31, "end_pos": 38, "type": "TASK", "confidence": 0.8185918927192688}]}, {"text": " Table 7: Examples of ranking term records for the term nucleus", "labels": [], "entities": []}, {"text": " Table 8: Percentage of terms per rank obtained for the correct answer", "labels": [], "entities": []}]}