{"title": [{"text": "Learning pressures reduce morphological complexity: Linking corpus, computational and experimental evidence", "labels": [], "entities": []}], "abstractContent": [{"text": "The morphological complexity of languages differs widely and changes overtime.", "labels": [], "entities": []}, {"text": "Pathways of change are often driven by the interplay of multiple competing factors, and are hard to disentangle.", "labels": [], "entities": []}, {"text": "We here focus on a paradigmatic scenario of language change: the reduction of morphological complexity from Latin towards the Romance languages.", "labels": [], "entities": []}, {"text": "To establish a causal explanation for this phenomenon, we employ three lines of evidence: 1) analyses of parallel corpora to measure the complexity of words in actual language production, 2) applications of NLP tools to further tease apart the contribution of inflectional morphology to word complexity, and 3) experimental data from artificial language learning, which illustrate the learning pressures at play when morphology simplifies.", "labels": [], "entities": []}, {"text": "These three lines of evidence converge to show that pressures associated with imperfect language learning are good candidates to causally explain the reduction in morphological complexity in the Latin-to-Romance scenario.", "labels": [], "entities": []}, {"text": "More generally, we argue that combining corpus, computational and experimental evidence is the way forward in historical linguistics and linguistic typology.", "labels": [], "entities": []}], "introductionContent": [{"text": "Sounds are added or removed from phoneme inventories, morphological markers are grammaticalized or lost, word orders permute in historical variants.", "labels": [], "entities": []}, {"text": "Causal explanations for these phenomena are often complex -or lacking all together -since they have to cope with the interplay of learning and usage in a multitude of social settings, at different times, in different places.", "labels": [], "entities": []}, {"text": "We here focus on a prominent change from Latin towards the Modern Romance languages: the systematic loss of morphological markers in all descendant languages of the common proto-language over hundreds and thousands of years.", "labels": [], "entities": []}, {"text": "Latin marked grammatical functions by means of inflectional variants of the same word root, thus displaying complex word forms.", "labels": [], "entities": []}, {"text": "For example, the Latin word for \"brother\" frater was inflected to yield fratres, fratribus, fratris, fratrum, fratri, fratre, etc.", "labels": [], "entities": []}, {"text": "according to singular/plural and case distinctions.", "labels": [], "entities": []}, {"text": "This complexity is considerably reduced in Modern Romance languages, where there are often simpler singular/plural distinctions as in Italian fratello/fratelli, French fr\u00e8re/fr\u00e8res, and Spanish hermano/hermanos.", "labels": [], "entities": []}, {"text": "A theory currently gaining ground at the interface of historical linguistics, linguistic typology and sociolinguistics maintains that reduction in morphological complexity might be driven by learning pressures, namely imperfect learning by non-native adults.", "labels": [], "entities": []}, {"text": "Adults learning a foreign language often lack the breadth of exposure to the target language that a native speaker would have.", "labels": [], "entities": [{"text": "breadth", "start_pos": 50, "end_pos": 57, "type": "METRIC", "confidence": 0.9641315937042236}]}, {"text": "Thus, they only partially learn the range of inflectional variants of a word, and omit morphological markers in their language production ().", "labels": [], "entities": []}, {"text": "If non-native speakers represent a considerable part of the overall speaker population, they might drive the language towards morphological simplification.", "labels": [], "entities": []}, {"text": "This line of reasoning was recently backed by quantitative analyses.", "labels": [], "entities": []}, {"text": "Across different language families and areas it was shown that languages spoken by more people (a proxy for the proportion of non-native speakers) tend to have lower morphological complexity (, that languages with more non-native speakers have less complex morphological case marking, and that languages with more non-native speakers have fewer word forms more generally (.", "labels": [], "entities": []}, {"text": "Our hypothesis is that imperfect language learning might also explain the loss of inflections from Classical Latin towards the Romance languages.", "labels": [], "entities": []}, {"text": "These formed as the Roman empire expanded into the European continent, and later evolved into modern day Romance languages.", "labels": [], "entities": []}, {"text": "In the process of expansion, Vulgar Latin varieties must have \"recruited\" considerable numbers of non-native speakers, which might have reduced the range of word forms in usage across the whole population of speakers.", "labels": [], "entities": []}, {"text": "Over several generations, this mechanism can lead to considerable loss of morphological marking.", "labels": [], "entities": []}, {"text": "We here present three lines of evidence to give such language change hypotheses an empirical and quantitative foundation.", "labels": [], "entities": []}, {"text": "1. A growing number of diachronic and synchronic corpora (see) are available to measure patterns of change, rather than using single, isolated examples.", "labels": [], "entities": []}, {"text": "Typological analyses based on corpora have the advantage of reflecting actual language production and usage, rather than expert judgement only.", "labels": [], "entities": []}, {"text": "They are reproducible and transparent.", "labels": [], "entities": []}, {"text": "In line with a range of earlier studies, we here apply corpus-based methods to measure morphological complexity.", "labels": [], "entities": []}, {"text": "2. NLP tools allow us to automatically and efficiently analyze large collections of texts.", "labels": [], "entities": []}, {"text": "This is here illustrated with lemmatization, i.e. neutralization of inflected word forms to their base forms, also called lemmas.", "labels": [], "entities": []}, {"text": "Thus we can tease apart the effect of inflections from other factors influencing the complexity of words.", "labels": [], "entities": []}, {"text": "3. Psycholinguistic experiments elicit the learning pressures that drive language change.", "labels": [], "entities": []}, {"text": "So-called iterated learning experiments are particularly helpful to understand multiple factors shaping information encoding strategies in artificial languages (.", "labels": [], "entities": []}, {"text": "We here reanalyse data gathered in an artificial language learning experiment where inflectional marking is transmitted over several generations of \"normal\" and \"imperfect\" learners (Berdicevskis and Semenuks, forthcoming).", "labels": [], "entities": []}, {"text": "We would argue more generally that an integration of corpus, computational and experimental evidence is a valid strategy for understanding changes in any other set of languages and their phonological, morphological and syntactic features.", "labels": [], "entities": []}], "datasetContent": [{"text": "The missing link to explain the entropy reduction in natural languages is the actual behaviour of language learners and users.", "labels": [], "entities": [{"text": "entropy reduction", "start_pos": 32, "end_pos": 49, "type": "TASK", "confidence": 0.7403194010257721}]}, {"text": "Their impact on word entropy is illustrated herewith data gathered from epsilon.", "labels": [], "entities": []}, {"text": "gives an overview of the entropy change in the aggregated epsilon variants over 10 generations of transmission.", "labels": [], "entities": []}, {"text": "The left panel shows the word entropy change in the three different learning conditions (normal, temporarily interrupted, permanently interrupted), while the right panel shows lemma entropy change (words neutralized for inflections).", "labels": [], "entities": []}, {"text": "Focusing on the left panel first: in the normal condition (black), the entropy slightly decreases (from 7.23 to 7.15, i.e. ca. \u22121.1%) over 10 generations.", "labels": [], "entities": []}, {"text": "For the temporarily interrupted condition (light grey), the word entropy decreases more sharply by 7.23 to 6.93 (\u22124.1%).", "labels": [], "entities": [{"text": "entropy", "start_pos": 65, "end_pos": 72, "type": "METRIC", "confidence": 0.5132699012756348}]}, {"text": "In the permanently interrupted condition (dark grey), it also continuously drops from 7.23 to 6.95, i.e. by \u22123.9%.", "labels": [], "entities": []}, {"text": "The right panel further illustrates -as we would expect -that entropy drops for lemmas compared to words, namely from 7.23 to 6.23, i.e. by 1 bit or \u221214% (in generation 0).", "labels": [], "entities": []}, {"text": "However, for lemmas there is less of a systematic pattern in entropy changeover 10 generations.", "labels": [], "entities": []}, {"text": "In fact, for the normal and permanently interrupted conditions there is almost no change at all.", "labels": [], "entities": []}, {"text": "Only for the temporarily interrupted condition does the lemma entropy drop somewhat from 6.23 to 6.09 (\u22122.2%).", "labels": [], "entities": [{"text": "entropy", "start_pos": 62, "end_pos": 69, "type": "METRIC", "confidence": 0.7558026909828186}]}, {"text": "In other words, the entropy drop in word forms over 10 generations of learning is mainly due to loss of morphological markers (e.g. losing plural marking -l, or agreement marking -o and -i), rather than a change in the base vocabulary (e.g. replacing vocabulary or using the noun seg where fuv should actually be used).", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Information on the parallel corpora used.", "labels": [], "entities": []}, {"text": " Table 2: Information on number and percentage of tokens unknown to the TreeTagger in a combined  corpus of the PBC and UDHR. Note that only verses of the PBC which are parallel across several hundred  languages were taken into account here. This explains the relatively low number of tokens.", "labels": [], "entities": [{"text": "UDHR", "start_pos": 120, "end_pos": 124, "type": "DATASET", "confidence": 0.6151852607727051}]}]}