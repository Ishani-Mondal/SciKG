{"title": [], "abstractContent": [{"text": "In this paper, we address the task of automatically aligning/detecting the bilingual documents that are translations of each other from a single web-domain as part of WMT 2016.", "labels": [], "entities": [{"text": "WMT 2016", "start_pos": 167, "end_pos": 175, "type": "DATASET", "confidence": 0.8657226264476776}]}, {"text": "1 Given the large amounts of data available in each web-domain, a brute force approach like finding similarities between every possible pair is a com-putationally expensive operation.", "labels": [], "entities": []}, {"text": "Therefore , we start with a simple approach on matching just the web page urls after some pre-processing to reduce the number of possible pairings to a small extent.", "labels": [], "entities": []}, {"text": "This simple approach obtained a recall of 50% and the exact matches from this approach are removed from further consideration.", "labels": [], "entities": [{"text": "recall", "start_pos": 32, "end_pos": 38, "type": "METRIC", "confidence": 0.9996755123138428}]}, {"text": "We built on top of this using an n-gram based approach that uses the partial En-glish translations of French web pages and achieved a recall of 93.71% on the training pairs provided.", "labels": [], "entities": [{"text": "recall", "start_pos": 134, "end_pos": 140, "type": "METRIC", "confidence": 0.9996253252029419}]}, {"text": "We also outline an IR-based approach that uses both content and the metadata of each web page url, thereby obtaining a recall of 56.31%.", "labels": [], "entities": [{"text": "recall", "start_pos": 119, "end_pos": 125, "type": "METRIC", "confidence": 0.9996935129165649}]}, {"text": "Our final submission to this shared task using n-gram based approach achieved a recall of 93.92%.", "labels": [], "entities": [{"text": "recall", "start_pos": 80, "end_pos": 86, "type": "METRIC", "confidence": 0.9997754693031311}]}], "introductionContent": [{"text": "Statistical Machine Translation systems rely a lot on the availability of parallel corpora and the automatic collection of such data so far has been ad hoc and limited in scale.", "labels": [], "entities": [{"text": "Statistical Machine Translation", "start_pos": 0, "end_pos": 31, "type": "TASK", "confidence": 0.7212488651275635}]}, {"text": "In this paper, we would like to tackle the problem of aligning bilingual documents from crawled websites which is presented as one of the new shared tasks introduced at WMT 2016 i.e., the task of identifying pairs of English 1 http://www.statmt.org/wmt16/bilingual-task.html and French documents from a given collection of documents such that one document is a translation of another.", "labels": [], "entities": [{"text": "WMT 2016", "start_pos": 169, "end_pos": 177, "type": "DATASET", "confidence": 0.8303303420543671}]}, {"text": "For each web-domain, we consider all the possible pairs for which the source side has been identified as English and the target side as French.", "labels": [], "entities": []}, {"text": "1,624 EN-FR pairs from 49 web-domains are provided as training data.", "labels": [], "entities": []}, {"text": "The number of pairs per web-domain varies between 4 and over 200.", "labels": [], "entities": []}, {"text": "All pairs are from within a single web-domain and possible matches between two different webdomains e.g. siemens.de and siemens.com are not considered in this task.", "labels": [], "entities": []}, {"text": "Mirrors of all the web pages in each domain which were crawled using httrack are provided.", "labels": [], "entities": []}, {"text": "Each page has the following information: Language ID (e.g. en), Mime type (always text/html), Encoding (always charset=utf-8), URL, HTML in Base64 encoding and Text in Base64 encoding.", "labels": [], "entities": []}, {"text": "Additionally, the English translations of French pages using MT for identified spans of text were produced by the organizers.", "labels": [], "entities": []}, {"text": "However, it doesn't imply that we have full translations for each and every French web page.", "labels": [], "entities": []}, {"text": "In other words, we only have partial translations fora random subset of French web pages.", "labels": [], "entities": []}, {"text": "shows the various statistics of the training data set.", "labels": [], "entities": [{"text": "training data set", "start_pos": 36, "end_pos": 53, "type": "DATASET", "confidence": 0.7848972181479136}]}, {"text": "Among 49 web-domains, www.nauticnews.com has the most possible pairings, 1,047,069,625, while schackportalen.nu has the least ones, 957.", "labels": [], "entities": []}, {"text": "Each web-domain has roughly 87 million pairs on average.", "labels": [], "entities": []}, {"text": "The rest of the paper is organized as follows: Section 2 discusses the various challenges involved in this task.", "labels": [], "entities": []}, {"text": "Section 3 gives an overview of the related work happened.", "labels": [], "entities": []}, {"text": "The methodology and implementation details are provided in Section 4.", "labels": [], "entities": []}, {"text": "Section 5 covers evaluation, results and analysis of the errors on the training data set given.", "labels": [], "entities": [{"text": "training data set", "start_pos": 71, "end_pos": 88, "type": "DATASET", "confidence": 0.8164317806561788}]}, {"text": "Section 6 concludes the paper with possible future directions: Various statistics on the training data.", "labels": [], "entities": []}, {"text": "The first row shows the web-domain with most possible pairs and the second row shows the web-domain with the least possible pairs.", "labels": [], "entities": []}, {"text": "The last row is the average statistics across 49 domains.", "labels": [], "entities": []}], "datasetContent": [{"text": "The evaluation for this problem has been well defined in terms of recall as part of the shared task i.e., what percentage of the test-set pairs are found Approach Baseline URL Patterns IR-based n-gram based Recall 67.92 50.00 56.31 93.71: Recall on the training set pairs using different approaches on the predicted test pairs after enforcing the 1-1 rule (each source web page will be matched with at most one target web page and later occurrences of the source web pages are excluded from the evaluation).", "labels": [], "entities": [{"text": "recall", "start_pos": 66, "end_pos": 72, "type": "METRIC", "confidence": 0.9985841512680054}, {"text": "Approach Baseline URL Patterns IR-based n-gram based Recall", "start_pos": 154, "end_pos": 213, "type": "METRIC", "confidence": 0.8168920055031776}]}, {"text": "The performance of the model will be tuned on the training data set provided by the shared task organizers.", "labels": [], "entities": []}, {"text": "The performance on the training data set (1624 pairs) is listed in.", "labels": [], "entities": [{"text": "training data set", "start_pos": 23, "end_pos": 40, "type": "DATASET", "confidence": 0.7862439453601837}]}, {"text": "As we observe in, the IR-based approach didn't work well and in fact it performed worse than the baseline provided by the task organizers.", "labels": [], "entities": []}, {"text": "On the other hand, the n-gram based approach worked very well with a recall of 93.71%.", "labels": [], "entities": [{"text": "recall", "start_pos": 69, "end_pos": 75, "type": "METRIC", "confidence": 0.999754011631012}]}, {"text": "We found that out of 49 web-domains, we got a recall of 100% in 31 web-domains.", "labels": [], "entities": [{"text": "recall", "start_pos": 46, "end_pos": 52, "type": "METRIC", "confidence": 0.9991645812988281}]}, {"text": "We have also performed an error analysis on the incorrect pairs to get a good understanding of the errors produced by the n-gram based approach.", "labels": [], "entities": []}, {"text": "Based on our analysis, it has been found that relying mainly alone on the cosine similarity between a pair of possible candidate pairs is not itself alone, and have to do some re-ranking after computing the initial cosine similarity.", "labels": [], "entities": []}, {"text": "One of the interesting observations we made when looking at the errors is sometimes there exists no one-to-one correspondence between the source web page and target web page.", "labels": [], "entities": []}, {"text": "This happens if a target web page is split into multiple target web pages and given only the availability of partial translations, aligning the source web page to maximum similar target web page requires some additional information.", "labels": [], "entities": []}, {"text": "Since we only have the partial translations, there is no positional information of each n-gram which will be very useful in calculating the similarity metric.", "labels": [], "entities": []}, {"text": "Most of these errors can be easily mitigated if we were provided the entire translation of each French web page instead of providing translations only for some text spans.", "labels": [], "entities": []}, {"text": "However, obtaining the full translations for each and every web page is computationally intensive.", "labels": [], "entities": []}, {"text": "We submitted our results on the test set to this shared task using the best approach that is based on n-grams.", "labels": [], "entities": []}, {"text": "Our system obtained a recall of 93.92%.", "labels": [], "entities": [{"text": "recall", "start_pos": 22, "end_pos": 28, "type": "METRIC", "confidence": 0.9981241822242737}]}, {"text": "It would be very interesting to see how these results change once the re-ranking phase is successfully implemented which serves as a promising future direction.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Various statistics on the training data. The first row shows the web-domain with most possible  pairs and the second row shows the web-domain with the least possible pairs. The last row is the average  statistics across 49 domains.", "labels": [], "entities": []}]}