{"title": [{"text": "Extracting Social Networks from Literary Text with Word Embedding Tools", "labels": [], "entities": [{"text": "Extracting Social Networks from Literary Text", "start_pos": 0, "end_pos": 45, "type": "TASK", "confidence": 0.8862372239430746}]}], "abstractContent": [{"text": "In this paper asocial network is extracted from a literary text.", "labels": [], "entities": []}, {"text": "The social network shows, how frequent the characters interact and how similar their social behavior is.", "labels": [], "entities": []}, {"text": "Two types of similarity measures are used: the first applies co-occurrence statistics, while the second exploits cosine similarity on different types of word embedding vectors.", "labels": [], "entities": []}, {"text": "The results are evaluated by a paid micro-task crowdsourcing survey.", "labels": [], "entities": []}, {"text": "The experiments suggest that specific types of word embed-dings like word2vec are well-suited for the task at hand and the specific circumstances of literary fiction text.", "labels": [], "entities": []}], "introductionContent": [{"text": "Word embeddings are language modeling techniques that transform the vocabulary of an input corpus into a continuous and low-dimensional vector representation.", "labels": [], "entities": []}, {"text": "Word embeddings have shown state-ofthe-art performance as language technology (LT) tools esp.", "labels": [], "entities": []}, {"text": "for word similarity estimations, but also for more sophisticated operations like word analogies and as input component to various natural language processing (NLP) tasks.", "labels": [], "entities": [{"text": "word similarity estimations", "start_pos": 4, "end_pos": 31, "type": "TASK", "confidence": 0.8148605624834696}]}, {"text": "Word embeddings use artificial neural networks for generating the vector representations.", "labels": [], "entities": []}, {"text": "Neural networks have become very popular and successful tools in NLP in the last couple of years, esp. with recent improvements in the deep learning field.", "labels": [], "entities": []}, {"text": "The performance of word embeddings in various task when using huge corpora of unstructured text has already been demonstrated in previous work.", "labels": [], "entities": []}, {"text": "Here, we study the suitability of different types of word embeddings as a LT tool to extract social networks from literary fiction, ie. to a specific task and domain, and a comparably small corpus size.", "labels": [], "entities": []}, {"text": "More precisely, we apply word embeddings to the text from the \"A Song of Ice and Fire\" book series by George R.", "labels": [], "entities": [{"text": "A Song of Ice and Fire\" book series by George R", "start_pos": 63, "end_pos": 110, "type": "DATASET", "confidence": 0.6420985758304596}]}, {"text": "The goal is to find book characters with the strongest relations to a given input character, and to compare the results from word embeddings to a very intuitive system, which uses term co-occurrence to determine the relatedness of characters.", "labels": [], "entities": []}, {"text": "Furthermore, we evaluate the results from different word embedding tools and from a method based on co-occurrence statistics with human judgements generated with crowdsourcing.", "labels": [], "entities": []}, {"text": "In this study, we did not focus on the detection and merging of character names, which is an interesting topic by itself, discussed for example in (.", "labels": [], "entities": [{"text": "detection and merging of character names", "start_pos": 39, "end_pos": 79, "type": "TASK", "confidence": 0.8116284906864166}]}, {"text": "In this publication, we want to address the following research questions: (i) How well does a traditional method based on co-occurrence statistics, such as the one presented in (, perform against state-of-the-art LT tools such as word embeddings for the task of social networks extraction in literary fiction?", "labels": [], "entities": [{"text": "social networks extraction in literary fiction", "start_pos": 262, "end_pos": 308, "type": "TASK", "confidence": 0.8039247194925944}]}, {"text": "(ii) Are there any differences between various types of word embeddings in the particular task of social networks extraction in literary fiction?", "labels": [], "entities": [{"text": "social networks extraction in literary fiction", "start_pos": 98, "end_pos": 144, "type": "TASK", "confidence": 0.7956582605838776}]}, {"text": "(iii) Furthermore, how well is paid micro-task crowdsourcing suited to evaluate facts in a domain with a lot of background necessary, such as a book series in the fantasy novel domain.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section, we evaluate and compare the six methods to extract relations from text fora given set of input terms: (i) co-occurrence statistics on a chapter level, (ii) co-occurrence statistics on a paragraph level, (iii) co-occurrence statistics on a sentence level, (iv) word2vec, (v) GloVe, and (vi) word2vec-fsee Section 3 for details about the methods.", "labels": [], "entities": []}, {"text": "Text corpus: For the evaluation we used the plain text versions of the first four books of the \"A Song of Ice and Fire\" (ASOIF) book series by George R.", "labels": [], "entities": [{"text": "A Song of Ice and Fire\" (ASOIF) book series by George R", "start_pos": 96, "end_pos": 151, "type": "DATASET", "confidence": 0.5816774129867553}]}, {"text": "ASOIF is a series of fantasy novels.", "labels": [], "entities": []}, {"text": "The action takes place in an fictional medieval-like universe.", "labels": [], "entities": []}, {"text": "Although the number of character is immense, the are up to 40 main characters which communicate throughout the series.", "labels": [], "entities": []}, {"text": "While narration is almost linear with minor flashbacks, the story is told in the first person.", "labels": [], "entities": []}, {"text": "However there are different narrators telling the story from different viewpoints, i.e. different POVs.", "labels": [], "entities": []}, {"text": "The raw books amounts to 6.9M of plain text, and contain 204 chapters with a mostly chronological storyline.", "labels": [], "entities": []}, {"text": "There are 121098 sentences in total.", "labels": [], "entities": []}, {"text": "Each chapter features a point of view character, which may live in any part of the ASOIF world.", "labels": [], "entities": []}, {"text": "There area few reasons behind our motivation to use ASOIF as the main source of data: (i) it is popular nowadays, which gives the hope that the crowd will cope with the questions; (ii) there is relatively large group of main characters, which interact intensively with each other in different circumstances, so that the social network might quite dense; (iii) the book gives us more or less enough data to train selected word embedding models and conduct the powerful comparison.", "labels": [], "entities": []}, {"text": "Character detection: The problem of character detection was not a focus of our work, it has already been tackled for example by).", "labels": [], "entities": [{"text": "Character detection", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.9236578345298767}, {"text": "character detection", "start_pos": 36, "end_pos": 55, "type": "TASK", "confidence": 0.9207408428192139}]}, {"text": "We applied a very simple heuristic, which selects the 30 most frequent names of characters from the total list of characters -most frequent in the sense of counting the number of appearances per character in different chapters.", "labels": [], "entities": []}, {"text": "If a character appears in various different chapters of the book series, this strongly hints at importance of the character to the story.", "labels": [], "entities": []}, {"text": "Relation selection: In order to make the results comparable for any of the three methods, we did the following: For any character in the list of 30 characters: get the two strongest connections to other characters on the list.", "labels": [], "entities": []}, {"text": "As described in Section 3, for method (i), (ii) and (iii) we selected the two characters with the strongest relation by co-occurrence between characters on a chapter, paragraph and sentence level, and for methods (iv)-(vi) we applied the different word embedding methods and tools.", "labels": [], "entities": []}, {"text": "For word embedding LT we used the gensim-word2vec toolkit.", "labels": [], "entities": []}, {"text": "With Gensim, for any given character we compute the similarity to any other character -and then pick the two characters with the highest (cosine) similarity as strongest relations.", "labels": [], "entities": []}, {"text": "Gensim 3 is a Python library, which provides tools for unsupervised semantic modeling from plain text, and also includes an implementation and extension of the original word2vec tool, which was written in C.", "labels": [], "entities": []}, {"text": "We used the results of crowdsourcing as a gold standard, and compared them to the results for the automated methods (LT methods).", "labels": [], "entities": []}, {"text": "We are aware that using results from crowd workers as gold standard is not without risk -so we also manually inspected the results retrieved to ensure high quality.", "labels": [], "entities": []}, {"text": "The crowdsourcing platform we used, CrowdFlower (CF), yields two types of results, the aggregated results, and the detailed results.", "labels": [], "entities": []}, {"text": "In the aggregated results, CF gives exactly one ASOIF character which 16.7% 20.0%: Percentage where the suggested character of CF is also the No. 1 selection by the LT-method (Top 1), and where it is among the top 2 of automatically generated relations (Top 2). has, according to the crowd workers, the strongest connection to the input character.", "labels": [], "entities": []}, {"text": "And in the detailed results, CF gives all the single votes which where done by the individual crowd workers, which we then used to select the characters with the strongest connections.", "labels": [], "entities": [{"text": "CF", "start_pos": 29, "end_pos": 31, "type": "DATASET", "confidence": 0.6991134285926819}]}, {"text": "We used both aggregated and detailed results for evaluation, in Sections 4.2.1 and 4.2.2, respectively.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Percentage where the suggested character of CF is also the No. 1 selection by the LT-method  (Top 1), and where it is among the top 2 of automatically generated relations (Top 2).", "labels": [], "entities": []}, {"text": " Table 2: Agreement between the sets of suggested character relations from CF workers and the LT  methods, according to the score in Eq. 2.", "labels": [], "entities": []}]}