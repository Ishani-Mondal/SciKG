{"title": [{"text": "LVCSR System on a Hybrid GPU-CPU Embedded Platform for Real-Time Dialog Applications", "labels": [], "entities": [{"text": "Real-Time Dialog Applications", "start_pos": 55, "end_pos": 84, "type": "TASK", "confidence": 0.7565827469031016}]}], "abstractContent": [{"text": "We present the implementation of a large-vocabulary continuous speech recognition (LVCSR) system on NVIDIA's Tegra K1 hyprid GPU-CPU embedded platform.", "labels": [], "entities": [{"text": "large-vocabulary continuous speech recognition (LVCSR)", "start_pos": 35, "end_pos": 89, "type": "TASK", "confidence": 0.779643850667136}]}, {"text": "The system is trained on a standard 1000-hour corpus, LibriSpeech, features a tri-gram WFST-based language model, and achieves state-of-the-art recognition accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 156, "end_pos": 164, "type": "METRIC", "confidence": 0.9701607823371887}]}, {"text": "The fact that the system is real-time-able and consumes less than 7.5 watts peak makes the system perfectly suitable for fast, but precise, offline spoken dialog applications, such as in robotics, portable gaming devices, or in-car systems.", "labels": [], "entities": []}], "introductionContent": [{"text": "Many of nowadays' spoken dialog systems are distributed systems whose major components, such as speech recognition, spoken language understanding, and dialog managers, are located in the cloud.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 96, "end_pos": 114, "type": "TASK", "confidence": 0.735454648733139}, {"text": "spoken language understanding", "start_pos": 116, "end_pos": 145, "type": "TASK", "confidence": 0.6168273190657297}]}, {"text": "For example, interactive voice response (IVR) systems are often connected to conventional telephony networks and handle a substantial portion of customer service interactions for numerous organizations and enterprises.", "labels": [], "entities": [{"text": "interactive voice response (IVR)", "start_pos": 13, "end_pos": 45, "type": "TASK", "confidence": 0.8382758498191833}]}, {"text": "One of the advantages of cloud-based systems is the strong computational power such systems can have which is believed to be critical for some of the components to produce an adequate performance (see for example recent advances in commercial speech recognition systems ().", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 243, "end_pos": 261, "type": "TASK", "confidence": 0.7143840938806534}]}, {"text": "Despite their advantages, cloud-based spoken dialog systems have several limitations.", "labels": [], "entities": []}, {"text": "E.g. they not only real-time-able speech recognizers, which poses a number of additional constraints to the implementation of the system (), but, first and foremost, they require a high-speed, high-reliability, and high-fidelity connection to the client device.", "labels": [], "entities": [{"text": "speech recognizers", "start_pos": 34, "end_pos": 52, "type": "TASK", "confidence": 0.6959259212017059}]}, {"text": "If this precondition is not met, spoken dialog systems cease to be what they promise to be: dialog systems.", "labels": [], "entities": []}, {"text": "Slow, clunky, and intermittent connections maybe acceptable with pseudodialog applications such as the ones typical in virtual assistants), but they are not suited for realistic conversational applications such as in customer care (, virtual tutoring (, or command and control.", "labels": [], "entities": []}, {"text": "Even more importantly, there are numerous applications for spoken dialog systems which require operation in offline mode altogether, for example in moving vehicles (), with robots in adverse conditions), in certain medical devices, or with portable video game consoles and toys).", "labels": [], "entities": []}, {"text": "Maintaining a cloud application server farm, capable of supporting the mass service comes at a recurring operational cost, which limits the range of possible revenue models with which the spoken dialog system can be offered.", "labels": [], "entities": []}, {"text": "A way to solve this problem is to transfer the necessary hardware to the client device and let the customer naturally cover the processing power costs.", "labels": [], "entities": []}, {"text": "Thus, reduction of the complexity of the involved technology and reducing its power consumption become critical figures of merit according to which the portable systems such as robots, portable game consoles, and toys are going to compete.", "labels": [], "entities": []}, {"text": "In Section 2 we present a large vocabulary speech recognition system architecture designed for NVIDIA's Tegra K1 hybrid GPU-CPU embedded System-on-a-Chip (SoC).", "labels": [], "entities": []}, {"text": "We show that its recognition accuracy performs on par with stateof-the-art systems while maintaining low power consumption and real-time ability in Section 3.", "labels": [], "entities": [{"text": "recognition", "start_pos": 17, "end_pos": 28, "type": "TASK", "confidence": 0.933472752571106}, {"text": "accuracy", "start_pos": 29, "end_pos": 37, "type": "METRIC", "confidence": 0.9800662994384766}]}], "datasetContent": [{"text": "In order to verify our design we have used a set of the models, generated by the standard Kaldi model-generating recipe for the LibriSpeech acoustic corpus.", "labels": [], "entities": [{"text": "LibriSpeech acoustic corpus", "start_pos": 128, "end_pos": 155, "type": "DATASET", "confidence": 0.8630989988644918}]}, {"text": "Specifically,  The evaluation has been performed with the standard LibriSpeech test sets, namely: \"DC\" -2703 clean development recordings (\u2248 5h.", "labels": [], "entities": [{"text": "LibriSpeech test sets", "start_pos": 67, "end_pos": 88, "type": "DATASET", "confidence": 0.9477516412734985}]}, {"text": "24 min.); \"DN\" -2864 noisy development recordings (\u2248 5h. 8 min.); \"TC\" -2620 clean test recordings (\u2248 5h. 25 min.); \"TN\" -2939 noisy test recordings (\u2248 5h. 21 min.).", "labels": [], "entities": []}, {"text": "The evaluation is performed as the single-pass recognition with online acoustic adaptation within the speaker-specific utterance sets in order to simulate operation of the speech recognizer in short single-user dialogues.", "labels": [], "entities": [{"text": "single-pass recognition", "start_pos": 35, "end_pos": 58, "type": "TASK", "confidence": 0.7004183530807495}]}, {"text": "We compare performance of our Tegra-based speech engine with the reference implementation of the Kaldi online2-wav-nnet2-latgen-faster decoder that is running on a system powered by the Intel Core i7-4930K CPU at 3.40GHz clock frequency.", "labels": [], "entities": []}, {"text": "All operating parameters (the pruning beam widths, model mixing coefficients, etc.) are kept the same between the reference and the presented system.: Accuracy and speed of compared recognizers.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 151, "end_pos": 159, "type": "METRIC", "confidence": 0.9975118637084961}]}, {"text": "WER -word error rate; \"CPU 1/xRT\" -the inverse of the real-time factor (i.e. the processingproduction speed ratio) for the reference system; 'TK1 1/xRT\" -inverse real-time factor for the presented system.", "labels": [], "entities": [{"text": "WER -word error rate", "start_pos": 0, "end_pos": 20, "type": "METRIC", "confidence": 0.9085383415222168}, {"text": "processingproduction speed ratio)", "start_pos": 81, "end_pos": 114, "type": "METRIC", "confidence": 0.8895854204893112}]}, {"text": "Power consumption is 150W for the \"CPU\" and 7.5W for the \"TK1\" systems.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Accuracy and speed of compared recog- nizers. WER -word error rate; \"CPU 1/xRT\" -the  inverse of the real-time factor (i.e. the processing- production speed ratio) for the reference system;  'TK1 1/xRT\" -inverse real-time factor for the pre- sented system. Power consumption is 150W for  the \"CPU\" and 7.5W for the \"TK1\" systems.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9897638559341431}, {"text": "WER -word error rate", "start_pos": 56, "end_pos": 76, "type": "METRIC", "confidence": 0.9440202116966248}, {"text": "processing- production speed ratio)", "start_pos": 138, "end_pos": 173, "type": "METRIC", "confidence": 0.6955490956703821}]}]}