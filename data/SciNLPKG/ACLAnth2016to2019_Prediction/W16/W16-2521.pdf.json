{"title": [{"text": "Evaluating word embeddings with fMRI and eye-tracking", "labels": [], "entities": []}], "abstractContent": [{"text": "The workshop CfP assumes that downstream evaluation of word embeddings is impractical, and that a valid evaluation metric for pairs of word embeddings can be found.", "labels": [], "entities": []}, {"text": "I argue below that if so, the only meaningful evaluation procedure is comparison with measures of human word processing in the wild.", "labels": [], "entities": []}, {"text": "Such evaluation is non-trivial, but I present a practical procedure here, evaluating word embeddings as features in a multi-dimensional regression model predicting brain imaging or eye-tracking word-level aggregate statistics.", "labels": [], "entities": []}, {"text": "What's the meaning of embeddings?", "labels": [], "entities": []}, {"text": "In order to decide how to evaluate word embeddings, we first need to decide what word embeddings are supposed to encode.", "labels": [], "entities": []}, {"text": "If we assume that word embeddings are primarily representations of the meaning of words, it makes sense to consult lexical semantic theories.", "labels": [], "entities": []}, {"text": "Here's a very, very, very (very,.", "labels": [], "entities": []}, {"text": ".) crude characterization of lexical semantics: Researchers disagree whether words are defined by their co-occurrences (Firth, 1957), the contexts in which they are used (Wittgenstein, 1953), how they are organized in the brain (Miller and Fellbaum, 1992), or the referents they denote in the real world (Montague, 1973).", "labels": [], "entities": []}, {"text": "I realize this is a ridiculously simplistic reduction of modern lexical semantics , but I think it suffices for our discussion of how best to evaluate word embeddings.", "labels": [], "entities": []}, {"text": "From (one or more of) these theories we want to derive a valid evaluation metric.", "labels": [], "entities": []}, {"text": "In my view, a valid metric satisfies two principles: (i) that it measures what we want to measure (adequacy), and (ii) that it cannot easily be 1 See the discussion in the last paragraph. hacked.", "labels": [], "entities": []}, {"text": "What I mean by (i) is that we want word embeddings to capture the meaning of words; and by (ii), that the reason we want to play the evaluation game is because it isn't obvious what the meaning of a word is.", "labels": [], "entities": []}, {"text": "If the meaning of a word was given directly by its character sequence, I would not be writing this paper, and this workshop would not have been proposed.", "labels": [], "entities": []}, {"text": "The question then is, do any of the four theories above provide us with a valid metric for the general quality of word embeddings?", "labels": [], "entities": []}, {"text": "Below, I argue that none of the four theories leave us with fully valid evaluation metrics, except maybe COGNITIVE LEXICAL SEMANTICS.", "labels": [], "entities": [{"text": "COGNITIVE LEXICAL SEMANTICS", "start_pos": 105, "end_pos": 132, "type": "METRIC", "confidence": 0.5255678991476694}]}, {"text": "I suggest evaluating embeddings by direct comparison with brain-imaging and eye-tracking data rather than word association norms, as an alternative approach to COGNITIVE LEXICAL SEMANTICS.", "labels": [], "entities": [{"text": "COGNITIVE LEXICAL SEMANTICS", "start_pos": 160, "end_pos": 187, "type": "TASK", "confidence": 0.4622829059759776}]}, {"text": "I show that state-of-the-art embeddings correlate poorly with such data, but argue that this is nevertheless the only valid metric left on the table, if downstream evaluation is not an option-and that, practically, we can evaluate embeddings by the error of a multi-dimensional regression model predicting brain imaging or eye-tracking data using the embeddings as features.", "labels": [], "entities": []}, {"text": "Co-occurrence theory In CO-OCCURRENCE THEORY, the meaning of a word is defined by its co-occurrences with other words-e.g., the meaning of big is given by its co-occurrence with words such as house and small, i.e., its value in a co-occurrence matrix.", "labels": [], "entities": [{"text": "THEORY", "start_pos": 38, "end_pos": 44, "type": "METRIC", "confidence": 0.8152472376823425}]}, {"text": "Word embeddings should therefore predict lexical co-occurrences, which can be evaluated in terms of perplexity or word error rate.", "labels": [], "entities": [{"text": "word error rate", "start_pos": 114, "end_pos": 129, "type": "METRIC", "confidence": 0.6885537703831991}]}, {"text": "This was how embeddings were evaluated in the early papers, e.g., (Mikolov et al., 2010).", "labels": [], "entities": []}, {"text": "But note that constructing co-occurrence matrices is also an integral part of standard approaches to inducing embeddings (Levy et al., 2015).", "labels": [], "entities": []}], "introductionContent": [], "datasetContent": [], "tableCaptions": []}