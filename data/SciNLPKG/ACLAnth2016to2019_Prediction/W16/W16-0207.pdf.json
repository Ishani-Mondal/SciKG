{"title": [{"text": "Bilingual Chronological Classification of Hafez's Poems", "labels": [], "entities": [{"text": "Bilingual Chronological Classification of Hafez's Poems", "start_pos": 0, "end_pos": 55, "type": "TASK", "confidence": 0.8170877269336155}]}], "abstractContent": [{"text": "We present a novel task: the chronological classification of Hafez's poems (ghazals).", "labels": [], "entities": [{"text": "chronological classification of Hafez's poems (ghazals)", "start_pos": 29, "end_pos": 84, "type": "TASK", "confidence": 0.8563665151596069}]}, {"text": "We compiled a bilingual corpus in digital form, with consistent idiosyncratic properties.", "labels": [], "entities": []}, {"text": "We have used Hooman's labeled ghazals in order to train automatic classifiers to classify the remaining ghazals.", "labels": [], "entities": []}, {"text": "Our classification framework uses a Support Vector Machine (SVM) classifier with similarity features based on Latent Dirichlet Allocation (LDA).", "labels": [], "entities": [{"text": "Latent Dirichlet Allocation (LDA)", "start_pos": 110, "end_pos": 143, "type": "METRIC", "confidence": 0.8178609708944956}]}, {"text": "In our analysis of the results we use the LDA topics' main terms that are passed onto a Principal Component Analysis (PCA) module.", "labels": [], "entities": []}], "introductionContent": [{"text": "Chronological classification of any artwork is a worthwhile task.", "labels": [], "entities": [{"text": "Chronological classification", "start_pos": 0, "end_pos": 28, "type": "TASK", "confidence": 0.9145997166633606}]}, {"text": "We focus on the poetry of the giant of Persian poetry, Hafez from Shiraz.", "labels": [], "entities": []}, {"text": "The purpose of our automatic chronological classification of Hafez's ghazals is to establish the relative timing of any poem concerning Hafez's lifetime, and thus to help understand his poetry better, while applying a semantic analysis approach.", "labels": [], "entities": [{"text": "automatic chronological classification of Hafez's ghazals", "start_pos": 19, "end_pos": 76, "type": "TASK", "confidence": 0.7171838794435773}]}, {"text": "The objective of this research is to classify ghazals using machine learning (ML) techniques with scholarly benefits rooted in literary analysis and hermeneutics.", "labels": [], "entities": [{"text": "literary analysis", "start_pos": 127, "end_pos": 144, "type": "TASK", "confidence": 0.7335526645183563}]}, {"text": "Harsh political conditions of Hafez's time required a unique type of encryption and mystical quality to the poems.", "labels": [], "entities": []}, {"text": "As a result, scholars have argued for centuries about the ghazals' possible interpretations and engaged in enduring polemics over the subject.", "labels": [], "entities": []}, {"text": "We draw on the work of an outstanding author, Dr. Mahmood Hooman.", "labels": [], "entities": []}, {"text": "In his seminal book about Hafez from about 80 years ago, he has partially done this chronological classification by hand.", "labels": [], "entities": [{"text": "chronological classification", "start_pos": 84, "end_pos": 112, "type": "TASK", "confidence": 0.7873214781284332}]}, {"text": "Hooman provides a psychological and personality-growth perspective on the poet Hafez.", "labels": [], "entities": []}, {"text": "This perspective plays an integral role in the interpretation of the poems and their chronological classification -see.", "labels": [], "entities": [{"text": "chronological classification", "start_pos": 85, "end_pos": 113, "type": "TASK", "confidence": 0.7552950382232666}]}, {"text": "This analytical spectrum of Hafez and his ghazals has been our guidance in deciding to apply Natural Language Processing (NLP) semantic-based methods in the chronological classification of Hafez's ghazals.", "labels": [], "entities": [{"text": "chronological classification of Hafez's ghazals", "start_pos": 157, "end_pos": 204, "type": "TASK", "confidence": 0.7775842050711314}]}, {"text": "We considered the task as a deserving candidate for automatic text classification by ML.", "labels": [], "entities": [{"text": "text classification", "start_pos": 62, "end_pos": 81, "type": "TASK", "confidence": 0.6990898698568344}, {"text": "ML", "start_pos": 85, "end_pos": 87, "type": "DATASET", "confidence": 0.5576491951942444}]}, {"text": "From the very beginning, we realized the great challenges involved.", "labels": [], "entities": []}, {"text": "Most important, there was no large and reliable corpus of Hafez poems available in electronic form.", "labels": [], "entities": []}, {"text": "Therefore we built one composed of all the 468 ghazals, each about 10 lines.", "labels": [], "entities": []}, {"text": "We were able to include good English version only for 71 of them.", "labels": [], "entities": []}, {"text": "In addition to classification, we also decided that we need some means of providing an intuitive rationale for each prediction.", "labels": [], "entities": [{"text": "classification", "start_pos": 15, "end_pos": 29, "type": "TASK", "confidence": 0.9620992541313171}]}, {"text": "Therefore, in the end, we applied a Topic-Term analysis to the poems to address that.", "labels": [], "entities": []}, {"text": "English translations are by Shahriar Shahriari.", "labels": [], "entities": []}], "datasetContent": [{"text": "The baseline accuracy for the classification of the three amalgamated classes is 58.2.% In, we show the results of tenfold crossvalidation for our SVM classifiers with different sets of features.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 13, "end_pos": 21, "type": "METRIC", "confidence": 0.9971753358840942}]}, {"text": "The evaluation measure is the weighted average of the F-measures proportional to the num- The Baseline is a classifier that always chooses the most frequent class, b , out of the three.", "labels": [], "entities": []}, {"text": "ber of elements in each of the three classes, as calculated by WEKA.", "labels": [], "entities": [{"text": "WEKA", "start_pos": 63, "end_pos": 67, "type": "DATASET", "confidence": 0.6706420183181763}]}, {"text": "In our first experiment, we created the BOW training data as input to the SVM classifier and increased the F-measure to 61%.", "labels": [], "entities": [{"text": "BOW training data", "start_pos": 40, "end_pos": 57, "type": "DATASET", "confidence": 0.6751976509888967}, {"text": "F-measure", "start_pos": 107, "end_pos": 116, "type": "METRIC", "confidence": 0.9719024896621704}]}, {"text": "The LDA factors alone did not go above the baseline of 58%.", "labels": [], "entities": [{"text": "LDA", "start_pos": 4, "end_pos": 7, "type": "METRIC", "confidence": 0.973210334777832}]}, {"text": "Keeping the BOW and adding the LSI or LDA factors only slightly improved the F-measure over the BOW alone.", "labels": [], "entities": [{"text": "BOW", "start_pos": 12, "end_pos": 15, "type": "METRIC", "confidence": 0.9655928015708923}, {"text": "LSI", "start_pos": 31, "end_pos": 34, "type": "METRIC", "confidence": 0.9719291925430298}, {"text": "LDA", "start_pos": 38, "end_pos": 41, "type": "METRIC", "confidence": 0.5853666067123413}, {"text": "F-measure", "start_pos": 77, "end_pos": 86, "type": "METRIC", "confidence": 0.9981604218482971}, {"text": "BOW", "start_pos": 96, "end_pos": 99, "type": "METRIC", "confidence": 0.7621139883995056}]}, {"text": "A t-test showed a 95% confidence that the results improved significantly when we added the English translations.", "labels": [], "entities": []}, {"text": "At that point, we hypothesized that the LSI-or -LDA-driven similarity factors alone should provide us with strong enough training features.", "labels": [], "entities": []}, {"text": "Therefore, in the next experiments, we went back and created the SVM training data only with normalized similarity factors, once with LSI and once with LDA.", "labels": [], "entities": []}, {"text": "LDA driven similarity factors proved stronger than those of LSI.", "labels": [], "entities": []}, {"text": "That is, as we observed the remarkable strength of these features, we only kept the BOW and LDA factors in the similarity factor calculations, in the final SVM training data.", "labels": [], "entities": [{"text": "BOW", "start_pos": 84, "end_pos": 87, "type": "METRIC", "confidence": 0.9990853071212769}, {"text": "LDA", "start_pos": 92, "end_pos": 95, "type": "METRIC", "confidence": 0.9566594362258911}, {"text": "SVM training", "start_pos": 156, "end_pos": 168, "type": "TASK", "confidence": 0.8306282162666321}]}, {"text": "Yet this method brought the accuracy of the classifier to our best result of 79.5% using our Persian training dataset.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 28, "end_pos": 36, "type": "METRIC", "confidence": 0.9995940327644348}, {"text": "Persian training dataset", "start_pos": 93, "end_pos": 117, "type": "DATASET", "confidence": 0.8275371392567953}]}, {"text": "The English addition, only in this case, reached a plateau.", "labels": [], "entities": []}, {"text": "That, we believe, was due to the scarcity of the features -only three.", "labels": [], "entities": []}, {"text": "To analyze the errors made by the classifier, we looked at the confusion matrix with columns showing the \"classified as\".", "labels": [], "entities": []}, {"text": "We noticed that the classifications faults were often caused by classes a and c , which makeup the smaller sections of the corpus; they are under-represented: We have also used the trained model for predicting the classes of the unlabelled ghazals.", "labels": [], "entities": []}, {"text": "We then asked our two experts, who consistently validated the labelling results, fora few of the unlabelled ghazals.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: SVM Classification Results for 3 classes (F-measure)", "labels": [], "entities": [{"text": "SVM Classification", "start_pos": 10, "end_pos": 28, "type": "TASK", "confidence": 0.6585709452629089}, {"text": "F-measure", "start_pos": 52, "end_pos": 61, "type": "METRIC", "confidence": 0.9613384008407593}]}]}