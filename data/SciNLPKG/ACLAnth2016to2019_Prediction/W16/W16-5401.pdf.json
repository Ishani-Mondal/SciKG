{"title": [{"text": "An extension of ISO-Space for annotating object direction", "labels": [], "entities": [{"text": "ISO-Space", "start_pos": 16, "end_pos": 25, "type": "DATASET", "confidence": 0.9329718351364136}]}], "abstractContent": [{"text": "In this paper, we extend an existing annotation scheme ISO-Space for annotating necessary spatial information for the task placing an specified object at a specified location with a specified direction according to a natural language instruction.", "labels": [], "entities": [{"text": "ISO-Space", "start_pos": 55, "end_pos": 64, "type": "DATASET", "confidence": 0.9022070169448853}]}, {"text": "We call such task the spatial placement problem.", "labels": [], "entities": [{"text": "spatial placement problem", "start_pos": 22, "end_pos": 47, "type": "TASK", "confidence": 0.8096188902854919}]}, {"text": "Our extension particularly focuses on describing the object direction, when the object is placed on the 2D plane.", "labels": [], "entities": []}, {"text": "We conducted an annotation experiment in which a corpus of 20 situated dialogues were annotated.", "labels": [], "entities": []}, {"text": "The annotation result showed the number of newly introduced tags by our proposal is not negligible.", "labels": [], "entities": []}, {"text": "We also implemented an analyser that automatically assigns the proposed tags to the corpus and evaluated its performance.", "labels": [], "entities": []}, {"text": "The result showed that the performance for entity tags was quite high ranging from 0.68 to 0.99 in F-measure, but not the case for relation tags, i.e. less than 0.4 in F-measure.", "labels": [], "entities": []}], "introductionContent": [{"text": "Understanding spatial relations in natural language dialogue is an important issue, particularly in situated dialogues (, as in the following interaction between a worker and a client in a moving setting.", "labels": [], "entities": [{"text": "Understanding spatial relations in natural language dialogue", "start_pos": 0, "end_pos": 60, "type": "TASK", "confidence": 0.5889034143515995}]}, {"text": "Assuming a computer agent as a worker being asked to put things at specified places, the agent has to be able to interpret the client's instructions through identifying the target object to move, the location at which the target object should be placed and often the direction of the target object itself.", "labels": [], "entities": []}, {"text": "We call this kind of task the spatial placement problem, namely the task placing an specified object at a specified location with a specified direction according to a natural language instruction.", "labels": [], "entities": [{"text": "spatial placement problem", "start_pos": 30, "end_pos": 55, "type": "TASK", "confidence": 0.8402858376502991}]}, {"text": "As a necessary first step to realising a computer agent that is capable of dealing with the spatial placement problem, the present paper proposes an annotation scheme to represent spatial relations by extending an existing scheme.", "labels": [], "entities": [{"text": "spatial placement problem", "start_pos": 92, "end_pos": 117, "type": "TASK", "confidence": 0.8056850433349609}]}, {"text": "In order to represent spatial relations, proposed an annotation scheme that annotates spatial objects and relations between them.", "labels": [], "entities": []}, {"text": "However, their scheme does not handle object direction.", "labels": [], "entities": [{"text": "object direction", "start_pos": 38, "end_pos": 54, "type": "TASK", "confidence": 0.7448574006557465}]}, {"text": "In the above example, the Mani's scheme annotates the spatial relation \"next to\" between the two objects \"the refrigerator\" and \"the sink\", but does not annotate the direction of the refrigerator specified by \"to this side\".", "labels": [], "entities": []}, {"text": "As long as using their annotation scheme, the annotated corpus lacks the information of the object direction.", "labels": [], "entities": []}, {"text": "When taking a machine learning approach with the annotated corpus to deal with the spatial placement problem, annotating object directions in the corpus is indispensable.", "labels": [], "entities": []}, {"text": "To tackle this problem, we extend an existing annotation scheme so that it can describe the spatial direction of objects in addition to the spatial relations between objects.", "labels": [], "entities": []}, {"text": "Based on the proposed scheme, we annotate an existing dialogue corpus, and construct an analyser that extracts the spatial information necessary for solving the spatial placement problem.", "labels": [], "entities": [{"text": "spatial placement problem", "start_pos": 161, "end_pos": 186, "type": "TASK", "confidence": 0.7965953548749288}]}, {"text": "The effectiveness of the proposed scheme is evaluated through the annotation result and the performance of the analyser.", "labels": [], "entities": []}, {"text": "In what follows, we briefly survey previous studies that deal with spatial information in natural language processing (section 2), then describes the spatial placement problem in detail which is the main 1 objective of the present study (section 3).", "labels": [], "entities": [{"text": "spatial placement", "start_pos": 150, "end_pos": 167, "type": "TASK", "confidence": 0.7244550883769989}]}, {"text": "The rest of the paper describes the proposed annotation scheme (section 4) and its evaluation through automatic tagging using the proposed scheme (section 5).", "labels": [], "entities": []}, {"text": "Finally we conclude the paper and argue the future work in section 6.", "labels": [], "entities": []}], "datasetContent": [{"text": "To argue the efficacy of our proposal, we have conducted an annotation exercise using an existing dialogue corpus.", "labels": [], "entities": []}, {"text": "The annotation target is the REX corpus, a Japanese dialogue corpus in which two participants jointly solve the Tangram puzzle on the computer simulator ().", "labels": [], "entities": [{"text": "REX corpus", "start_pos": 29, "end_pos": 39, "type": "DATASET", "confidence": 0.7625114023685455}]}, {"text": "The goal of the puzzle is arranging the seven pieces into a given goal shape.", "labels": [], "entities": []}, {"text": "Both participants share the same working area where the puzzle pieces are arranged, but play different roles.", "labels": [], "entities": []}, {"text": "One was given the goal shape but not a mouse to manipulate the pieces, while the other was given a mouse but not the goal shape.", "labels": [], "entities": []}, {"text": "Due to such asymmetric task setting, the participant with the goal shape mostly played as an instructor and the other played as a worker.", "labels": [], "entities": []}, {"text": "Thus this task can be considered as atypical spatial placement problem.", "labels": [], "entities": [{"text": "spatial placement", "start_pos": 45, "end_pos": 62, "type": "TASK", "confidence": 0.7409252226352692}]}, {"text": "The following is an excerpt of a dialogue 1 and shows a screenshot of the Tangram puzzle simulator in which the goal shape \"bowl\" is shown on the left.", "labels": [], "entities": []}, {"text": "(Slide it leftward and fit it (to them).) worker : hai.", "labels": [], "entities": []}, {"text": "(I see.) instructor: de, heikousihenkei wo 45 do kaiten sasete.", "labels": [], "entities": []}, {"text": "(Then, rotate the parallelogram by 45 degrees.)", "labels": [], "entities": []}, {"text": "Goal shape Working area In this annotation experiment, we annotated the corpus with tags in in which the underlined elements are newly introduced in our proposal.", "labels": [], "entities": []}, {"text": "Although the ISO-Space scheme provides more than these tags, we used a minimum tag set necessary for describing the location and direction of objects for solving the spatial placement problem.", "labels": [], "entities": [{"text": "ISO-Space", "start_pos": 13, "end_pos": 22, "type": "DATASET", "confidence": 0.9189565181732178}]}, {"text": "We annotated 20 dialogues with the tags listed in.", "labels": [], "entities": []}, {"text": "The total number of utterances by the instructors was 2,020 including 360 instructional utterances.", "labels": [], "entities": []}, {"text": "Among these 360 instructions, 60 (16.7%) of them mentioned the object direction.", "labels": [], "entities": []}, {"text": "shows the distribution of annotated tags in number.", "labels": [], "entities": []}, {"text": "The table shows the number of the Directional Signal tag is comparable to that of the Spatial Signal tag, which is used for indicating spatial relations.", "labels": [], "entities": []}, {"text": "According to this preliminary investigation, information of the object direction is not negligible in the spatial placement problem.", "labels": [], "entities": []}, {"text": "In order to evaluate feasibility of automatic tagging with our proposal, we implemented a system that assigns the tags shown in.", "labels": [], "entities": []}, {"text": "Thus the goal of the system is assigning the tags to given utterances as shown in.", "labels": [], "entities": []}, {"text": "Given an instructional utterance, the task of the system is twofold: by linking the spans identified in step 1.", "labels": [], "entities": []}, {"text": "In the following subsections, each of the steps is described in more detail.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Distribution of annotated tags", "labels": [], "entities": []}, {"text": " Table 5: Result of labelling", "labels": [], "entities": [{"text": "labelling", "start_pos": 20, "end_pos": 29, "type": "TASK", "confidence": 0.6319570541381836}]}, {"text": " Table 6: Result of relation identification", "labels": [], "entities": [{"text": "Result of relation identification", "start_pos": 10, "end_pos": 43, "type": "TASK", "confidence": 0.7570842355489731}]}]}