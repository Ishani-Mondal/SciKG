{"title": [{"text": "Detection of Text Reuse in French Medical Corpora", "labels": [], "entities": [{"text": "Detection of Text Reuse", "start_pos": 0, "end_pos": 23, "type": "TASK", "confidence": 0.8315814137458801}, {"text": "French Medical Corpora", "start_pos": 27, "end_pos": 49, "type": "DATASET", "confidence": 0.7919913729031881}]}], "abstractContent": [{"text": "Electronic Health Records (EHRs) are increasingly available in modern healthcare institutions either through the direct creation of electronic documents in hospitals' health information systems , or through the digitization of historical paper records.", "labels": [], "entities": []}, {"text": "Each EHR creation method yields the need for sophisticated text reuse detection tools in order to prepare the EHR collections for efficient secondary use relying on Natural Language Processing methods.", "labels": [], "entities": [{"text": "EHR creation", "start_pos": 5, "end_pos": 17, "type": "TASK", "confidence": 0.6466345489025116}, {"text": "text reuse detection", "start_pos": 59, "end_pos": 79, "type": "TASK", "confidence": 0.7597839534282684}]}, {"text": "Herein, we address the detection of two types of text reuse in French EHRs: 1)", "labels": [], "entities": [{"text": "French EHRs", "start_pos": 63, "end_pos": 74, "type": "DATASET", "confidence": 0.6836561262607574}]}], "introductionContent": [{"text": "Over the last decade a large number of hospitals and medical institutions have adopted the use of Electronic Health Records (EHRs) to store patient records and medical details.", "labels": [], "entities": []}, {"text": "Simultaneously, the lowered cost of computational resources has given rise to digitization efforts of existing (paper) collections.", "labels": [], "entities": []}, {"text": "While the presence of such large, digital corpora opens up exciting possibilities for medical data and text mining or modelization efforts, this is not without certain caveats.", "labels": [], "entities": [{"text": "text mining", "start_pos": 103, "end_pos": 114, "type": "TASK", "confidence": 0.8014650046825409}]}, {"text": "The resulting digital collections often are noisy, with several issues that can have an impact on the accuracy of subsequent text mining processes, such as encoding errors, missing files, OCR errors, etc.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 102, "end_pos": 110, "type": "METRIC", "confidence": 0.9980533123016357}, {"text": "text mining", "start_pos": 125, "end_pos": 136, "type": "TASK", "confidence": 0.7650703489780426}]}, {"text": "One interesting issue in cumulatively constructed text corpora is the problem of 'text reuse'.", "labels": [], "entities": []}, {"text": "Text reuse is defined here as the intentional or unintentional reusing of existing text (fragments) to create anew text, for example, by copy-pasting text fragments from one document to fit into anew document; or by adapting a report and saving both the old and the new version as separate documents.", "labels": [], "entities": [{"text": "Text reuse", "start_pos": 0, "end_pos": 10, "type": "TASK", "confidence": 0.7076967656612396}]}, {"text": "Text reuse is a complex phenomenon which has been studied in multiple settings such as newspaper journalism), programming code (, the analysis of text reuse in blogs and web pages, etc.", "labels": [], "entities": [{"text": "Text reuse", "start_pos": 0, "end_pos": 10, "type": "TASK", "confidence": 0.7540475726127625}, {"text": "analysis of text reuse in blogs and web pages", "start_pos": 134, "end_pos": 179, "type": "TASK", "confidence": 0.7222572035259671}]}, {"text": "It is quite prevalent in the medical domain ( and often seen as a negative factor: found that copy-pasting practices in US hospitals have a significant negative impact on the accuracy of the subsequent text mining systems on the clinical notes.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 175, "end_pos": 183, "type": "METRIC", "confidence": 0.9967107772827148}]}, {"text": "However, when text reuse is considered as a diachronic phenomenon, it has some interesting aspects.", "labels": [], "entities": []}, {"text": "By identifying which text (fragments) have been reused we can follow the flow of information overtime in a patient's file.", "labels": [], "entities": []}, {"text": "Moreover, adjustments that are made to copied text (fragments) can give an insight into the thought process of the acting clinicians and may help identify potential errors or adjustments during the treatment process).", "labels": [], "entities": []}, {"text": "Text reuse has been studied extensively in the context of authorship attribution and plagiarism detection.", "labels": [], "entities": [{"text": "Text reuse", "start_pos": 0, "end_pos": 10, "type": "TASK", "confidence": 0.6521768867969513}, {"text": "authorship attribution", "start_pos": 58, "end_pos": 80, "type": "TASK", "confidence": 0.7515086233615875}, {"text": "plagiarism detection", "start_pos": 85, "end_pos": 105, "type": "TASK", "confidence": 0.7867263853549957}]}, {"text": "In general we can distinguish between two main types of text reuse: 'global text reuse' in which the task is to pair up (near-) duplicate documents that exists in different locations, or whose differences are linked to version control issues; and 'local text reuse' which occurs when people borrow or plagiarize smaller text fragments such as sentences or passages from various sources to incorporate in anew text.", "labels": [], "entities": []}, {"text": "Both types are included in this study.", "labels": [], "entities": []}, {"text": "While the goal is the same, there are some key differences between plagiarism detection and text reuse detection in the medical domain.", "labels": [], "entities": [{"text": "plagiarism detection", "start_pos": 67, "end_pos": 87, "type": "TASK", "confidence": 0.74959996342659}, {"text": "text reuse detection", "start_pos": 92, "end_pos": 112, "type": "TASK", "confidence": 0.8342450459798177}]}, {"text": "Medical professionals work under an enormous time pressure, so rather than rewriting an existing text (fragment), they will merely add new information or adjust existing information, and at best edit out some orthographic errors or write out acronyms that existed in the previous version.", "labels": [], "entities": []}, {"text": "Consequently, our methods can focus on literal string matching, rather than employing semantic similarity measures (other than detecting spelled-out variants of acronyms) or paraphrase detection.", "labels": [], "entities": [{"text": "literal string matching", "start_pos": 39, "end_pos": 62, "type": "TASK", "confidence": 0.70402991771698}, {"text": "paraphrase detection", "start_pos": 174, "end_pos": 194, "type": "TASK", "confidence": 0.8094246983528137}]}, {"text": "Furthermore, redundancy detection is usually performed within a closed reference collection (as opposed to plagiarism detection systems that use the entire internet as a reference base).", "labels": [], "entities": [{"text": "redundancy detection", "start_pos": 13, "end_pos": 33, "type": "TASK", "confidence": 0.87388876080513}]}, {"text": "Another difference is the quality of the written text.", "labels": [], "entities": []}, {"text": "Depending on the quality and the nature of the text formatting tools that are available, electronic health records may contain an astounding number of orthographic errors or in the case of a digitized corpus, a large variety of OCR errors.", "labels": [], "entities": []}, {"text": "Another source of potential minor surface variation is the de-identification process in which personal health identifiers (PHI) such as patients names, phone numbers, record numbers are replaced by plausible synthetic surrogates.", "labels": [], "entities": []}, {"text": "Depending on how the process is implemented, for example with the inclusion of random substitution, numbers that were the same in the original documents can appear with slight variations in the de-identified documents.", "labels": [], "entities": []}, {"text": "Text reuse metric tools in this domain therefore need to be robust to the noise of these sources of surface variation and correctly detect similar text segments even when the surface forms do not match 100%.", "labels": [], "entities": []}, {"text": "The current paper presents a simple but effective tool for text reuse detection in the medical domain, both for global and local text reuse detection, which proves robust to surface variation prevalent in medical texts by allowing for character gaps when calculating the blocks of reused texts.", "labels": [], "entities": [{"text": "text reuse detection", "start_pos": 59, "end_pos": 79, "type": "TASK", "confidence": 0.8212768832842509}, {"text": "global and local text reuse detection", "start_pos": 112, "end_pos": 149, "type": "TASK", "confidence": 0.7127457161744436}]}, {"text": "The tool is meant to figure as a module in a larger framework, i.e. a pipeline which normalizes and extracts information from documents in a patient file in order to model the patient's treatment overtime.", "labels": [], "entities": []}, {"text": "This adds a practical component to the evaluation of the proposed tool.", "labels": [], "entities": []}, {"text": "Missing a case of text reuse is a more grievous error than (mis)labeling a false positive.", "labels": [], "entities": []}, {"text": "A mislabeled case, i.e either not correctly determining between different degrees of reuse, or erroneously spotting text reuse, can be spotted by the information extraction module later on in the pipeline.", "labels": [], "entities": [{"text": "information extraction", "start_pos": 150, "end_pos": 172, "type": "TASK", "confidence": 0.7425900101661682}]}, {"text": "When a case of text reuse is not identified, however, no subsequent processing will occur for that document pair and the information is effectively lost for the information extraction process.", "labels": [], "entities": [{"text": "information extraction", "start_pos": 161, "end_pos": 183, "type": "TASK", "confidence": 0.7962216138839722}]}, {"text": "In this paper we present and evaluate the text reuse detection tool in isolation and discuss its strengths and weaknesses.", "labels": [], "entities": [{"text": "text reuse detection", "start_pos": 42, "end_pos": 62, "type": "TASK", "confidence": 0.7813587188720703}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 2: Precision and Recall scores for EHR corpus (LTR)", "labels": [], "entities": [{"text": "Precision", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9918672442436218}, {"text": "Recall", "start_pos": 24, "end_pos": 30, "type": "METRIC", "confidence": 0.9663464426994324}, {"text": "EHR corpus (LTR", "start_pos": 42, "end_pos": 57, "type": "METRIC", "confidence": 0.7984766960144043}]}, {"text": " Table 3: Precision and Recall scores for OCRed corpus (GTR)", "labels": [], "entities": [{"text": "Precision", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9843452572822571}, {"text": "Recall", "start_pos": 24, "end_pos": 30, "type": "METRIC", "confidence": 0.9505957365036011}, {"text": "OCRed corpus (GTR)", "start_pos": 42, "end_pos": 60, "type": "TASK", "confidence": 0.678086256980896}]}]}