{"title": [{"text": "CYUT-III System at Chinese Grammatical Error Diagnosis Task", "labels": [], "entities": [{"text": "Chinese Grammatical Error Diagnosis", "start_pos": 19, "end_pos": 54, "type": "TASK", "confidence": 0.7514267861843109}]}], "abstractContent": [{"text": "This paper describe the CYUT-III system on grammar error detection in the 2016 NLP-TEA Chinese Grammar Error Detection shared task CGED.", "labels": [], "entities": [{"text": "grammar error detection", "start_pos": 43, "end_pos": 66, "type": "TASK", "confidence": 0.5834591388702393}, {"text": "NLP-TEA Chinese Grammar Error Detection shared task CGED", "start_pos": 79, "end_pos": 135, "type": "TASK", "confidence": 0.7873892560601234}]}, {"text": "In this task a system has to detect four types of errors, including redundant word error, missing word error, word selection error and word ordering error.", "labels": [], "entities": []}, {"text": "Based on the conditional random fields (CRF) model, our system is a linear tagger that can detect the errors in learners' essays.", "labels": [], "entities": []}, {"text": "Since the system performance depends on the features heavily, in this paper, we are going to report how to integrate the collocation feature into the CRF model.", "labels": [], "entities": []}, {"text": "Our system presents the best detection accuracy and Identification accuracy on the TOCFL dataset, which is in traditional Chinese.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 39, "end_pos": 47, "type": "METRIC", "confidence": 0.941400945186615}, {"text": "Identification", "start_pos": 52, "end_pos": 66, "type": "METRIC", "confidence": 0.8691432476043701}, {"text": "accuracy", "start_pos": 67, "end_pos": 75, "type": "METRIC", "confidence": 0.7996193766593933}, {"text": "TOCFL dataset", "start_pos": 83, "end_pos": 96, "type": "DATASET", "confidence": 0.9546968042850494}]}, {"text": "The same system also works well on the simplified Chinese HSK dataset.", "labels": [], "entities": [{"text": "Chinese HSK dataset", "start_pos": 50, "end_pos": 69, "type": "DATASET", "confidence": 0.8106059432029724}]}], "introductionContent": [{"text": "Chinese essay writing is hard for foreign learners, not only on the aspect of learning pictograph Chinese characters but also on that of learning Chinese grammar that has no strong syntax rules.", "labels": [], "entities": [{"text": "Chinese essay writing", "start_pos": 0, "end_pos": 21, "type": "TASK", "confidence": 0.7382294535636902}]}, {"text": "An automatic grammar error detection system might help the learners to get instant feedback when they are writing an essay in a computer aided language learning environment.", "labels": [], "entities": [{"text": "grammar error detection", "start_pos": 13, "end_pos": 36, "type": "TASK", "confidence": 0.5909960468610128}]}, {"text": "In order to develop a grammar error detection system with the statistical natural language processing technology, developers need a large learner corpus ().", "labels": [], "entities": [{"text": "grammar error detection", "start_pos": 22, "end_pos": 45, "type": "TASK", "confidence": 0.6416301329930624}]}, {"text": "However, currently there is no publicly available large leaner corpus in Chinese essay writing.", "labels": [], "entities": [{"text": "Chinese essay writing", "start_pos": 73, "end_pos": 94, "type": "TASK", "confidence": 0.6317886710166931}]}, {"text": "That puts off the research in this field.", "labels": [], "entities": []}, {"text": "The NLP-TEA workshop has been holding a Chinese Grammar Error Detection (CGED) shared task in the workshop for two years since 2014 () ().", "labels": [], "entities": [{"text": "Chinese Grammar Error Detection (CGED) shared task", "start_pos": 40, "end_pos": 90, "type": "TASK", "confidence": 0.7356137666437361}]}, {"text": "They provides a set of learner corpus and a clear definition on 4 major Grammar error types in the foreign learner corpus.", "labels": [], "entities": []}, {"text": "The shared tasks stimulated the research and drew many participants.", "labels": [], "entities": []}, {"text": "The goal of the shared task is to develop a system that can detect the four types of grammar errors in learner corpus.", "labels": [], "entities": []}, {"text": "Comparing to the task definition of CGED in 2014 and 2015, the major difference in this year is the sentences might contain multiple errors.", "labels": [], "entities": [{"text": "CGED", "start_pos": 36, "end_pos": 40, "type": "DATASET", "confidence": 0.9212136268615723}]}, {"text": "And the organizers provide two data sets: one is in traditional Chinese, the TOCFL dataset; the other is in simplified Chinese, the HSK dataset. and 2 are examples of the four error types, where redundant word is abbreviated 'R', missing word 'M', word selection error 'S', and word ordering error 'W'.", "labels": [], "entities": [{"text": "TOCFL dataset", "start_pos": 77, "end_pos": 90, "type": "DATASET", "confidence": 0.9483625292778015}, {"text": "HSK dataset.", "start_pos": 132, "end_pos": 144, "type": "DATASET", "confidence": 0.9770672619342804}]}, {"text": "Based on the conditional random fields (CRF) model, we build a linear tagger that can detect the errors in learners' essays.", "labels": [], "entities": []}, {"text": "The major improvement of our system is integrating the collocation feature into the CRF model.", "labels": [], "entities": []}, {"text": "Since there is no publicly available Chinese collocation dataset, we will also report how we collect collocation.", "labels": [], "entities": []}, {"text": "The paper is organized as follows: Section 2 describes our methodology, section 3 shows our system architecture, section 4 is the discussion, and the final part is the conclusions.", "labels": [], "entities": []}], "datasetContent": [{"text": "The system evaluation metrics of CGED shared task includes three levels.", "labels": [], "entities": []}, {"text": "We focus on the identification level: this level is a multi-class categorization problem.", "labels": [], "entities": []}, {"text": "All error types should be identified, i.e., Redundant, Missing, Word ordering, and Selection.", "labels": [], "entities": [{"text": "Word ordering", "start_pos": 64, "end_pos": 77, "type": "TASK", "confidence": 0.6816108524799347}]}, {"text": "The metrics used are accuracy, precision, recall, and F1-score.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 21, "end_pos": 29, "type": "METRIC", "confidence": 0.9997370839118958}, {"text": "precision", "start_pos": 31, "end_pos": 40, "type": "METRIC", "confidence": 0.9997090697288513}, {"text": "recall", "start_pos": 42, "end_pos": 48, "type": "METRIC", "confidence": 0.9997139573097229}, {"text": "F1-score", "start_pos": 54, "end_pos": 62, "type": "METRIC", "confidence": 0.9990662932395935}]}, {"text": "We send respectively three runs for both data set this year, and the major difference for each experiment settings is the size of training set.", "labels": [], "entities": []}, {"text": "Our system is based on traditional Chinese processing, the simplified Chinese is translated into traditional Chinse by Microsoft Word in advance.", "labels": [], "entities": []}, {"text": "Our training data consists of data from NLP-TEA1() Training Data, Test Data, and the Training Data from NLP-TEA2 and NLP-TEA3.", "labels": [], "entities": [{"text": "NLP-TEA1() Training Data", "start_pos": 40, "end_pos": 64, "type": "DATASET", "confidence": 0.8377108573913574}, {"text": "NLP-TEA3", "start_pos": 117, "end_pos": 125, "type": "DATASET", "confidence": 0.8381050229072571}]}, {"text": "shows the number of sentences in our training set.", "labels": [], "entities": []}, {"text": "Run1 settings: Use all the available data as the training set.", "labels": [], "entities": []}, {"text": "For TOCFL, the training set is the union of the training sets in the NLP-TEA1, NLP-TEA2, and TOCFL in NLP-TEA3.", "labels": [], "entities": [{"text": "TOCFL", "start_pos": 4, "end_pos": 9, "type": "TASK", "confidence": 0.8718579411506653}, {"text": "TOCFL", "start_pos": 93, "end_pos": 98, "type": "DATASET", "confidence": 0.7007477283477783}]}, {"text": "For HSK, the training set is the union of the one used for TOCFL and HSK in NLP-TEA3.", "labels": [], "entities": [{"text": "HSK", "start_pos": 4, "end_pos": 7, "type": "TASK", "confidence": 0.816777765750885}, {"text": "TOCFL", "start_pos": 59, "end_pos": 64, "type": "DATASET", "confidence": 0.6082808375358582}, {"text": "NLP-TEA3", "start_pos": 76, "end_pos": 84, "type": "DATASET", "confidence": 0.7494263648986816}]}, {"text": "Run2 settings: Almost the same as those in Run1, the only difference is the correct sentences are excluded from the training set.", "labels": [], "entities": []}, {"text": "We believe that they provide no help for finding errors.", "labels": [], "entities": []}, {"text": "Run3 settings: Almost the same as those in Run1.", "labels": [], "entities": [{"text": "Run3", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.9165213108062744}, {"text": "Run1", "start_pos": 43, "end_pos": 47, "type": "DATASET", "confidence": 0.9165068864822388}]}, {"text": "The difference is how our system treats the continuous errors.", "labels": [], "entities": []}, {"text": "If two errors of the same type occurred continuously, our system will combine them as one longer error.", "labels": [], "entities": []}, {"text": "For example, two errors of the same type: A2-0019-1, 10, 12, S A2-0019-1, 13, 13, S will be reported as: A2-0019-1, 10, 13, S.  In the formal run of NLP-TEA-3 CGED shared task, there are 5 participants, and each team submits 3 runs in TOCFL, totally 15 runs.", "labels": [], "entities": [{"text": "NLP-TEA-3 CGED shared task", "start_pos": 149, "end_pos": 175, "type": "DATASET", "confidence": 0.6878238916397095}, {"text": "TOCFL", "start_pos": 235, "end_pos": 240, "type": "METRIC", "confidence": 0.8330258131027222}]}, {"text": "There are 8 participants in HSK, totally 21 runs.", "labels": [], "entities": [{"text": "HSK", "start_pos": 28, "end_pos": 31, "type": "DATASET", "confidence": 0.6781741380691528}]}, {"text": "shows the false positive rate.", "labels": [], "entities": [{"text": "false positive rate", "start_pos": 10, "end_pos": 29, "type": "METRIC", "confidence": 0.9096760948499044}]}, {"text": "Our system has 0.082 false positive rate.", "labels": [], "entities": [{"text": "false positive rate", "start_pos": 21, "end_pos": 40, "type": "METRIC", "confidence": 0.9664976994196574}]}, {"text": "The average of all runs is calculated from 15 runs for TOCFL and 21 runs for HSK.,, and show the formal run result of our system compared with the average in Detection level, Identification level, and Position level respectively.", "labels": [], "entities": [{"text": "TOCFL", "start_pos": 55, "end_pos": 60, "type": "METRIC", "confidence": 0.5708023905754089}, {"text": "HSK.", "start_pos": 77, "end_pos": 81, "type": "DATASET", "confidence": 0.85159832239151}, {"text": "Detection level", "start_pos": 158, "end_pos": 173, "type": "METRIC", "confidence": 0.8821056485176086}, {"text": "Identification level", "start_pos": 175, "end_pos": 195, "type": "METRIC", "confidence": 0.9633886516094208}, {"text": "Position level", "start_pos": 201, "end_pos": 215, "type": "METRIC", "confidence": 0.9794473052024841}]}, {"text": "Our system achieves the highest Accuracy in Detection Level(TOCFL) and Identification-Level (TOCFL).", "labels": [], "entities": [{"text": "Accuracy in Detection Level(TOCFL)", "start_pos": 32, "end_pos": 66, "type": "METRIC", "confidence": 0.9149239148412432}, {"text": "Identification-Level (TOCFL)", "start_pos": 71, "end_pos": 99, "type": "METRIC", "confidence": 0.9430280476808548}]}, {"text": "The numbers in boldface are the best performance among all formal runs.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2. Sample statistics of word frequency in the training set  Sample  pairs", "labels": [], "entities": []}, {"text": " Table 3. Templates and the corresponding value  Template  Corresponding", "labels": [], "entities": []}, {"text": " Table 4. Training set size  size  NLP-TEA1 NLP-TEA2 NLP-TEA3  Redundant  1830  434  10010  Correct  874  0  0  Selection  827  849  20846  Disorder  (word ordering)", "labels": [], "entities": [{"text": "Training set size  size  NLP-TEA1 NLP-TEA2 NLP-TEA3  Redundant  1830  434  10010  Correct  874  0  0  Selection  827  849  20846  Disorder", "start_pos": 10, "end_pos": 148, "type": "METRIC", "confidence": 0.5170510314404965}, {"text": "word ordering", "start_pos": 151, "end_pos": 164, "type": "TASK", "confidence": 0.6763688921928406}]}, {"text": " Table 5: The false positive rate in Detection Level (the lower the better)", "labels": [], "entities": [{"text": "false positive rate", "start_pos": 14, "end_pos": 33, "type": "METRIC", "confidence": 0.9220220843950907}, {"text": "Detection", "start_pos": 37, "end_pos": 46, "type": "TASK", "confidence": 0.6494086980819702}]}, {"text": " Table 6: Performance evaluation in Detection Level", "labels": [], "entities": [{"text": "Detection", "start_pos": 36, "end_pos": 45, "type": "TASK", "confidence": 0.9668743014335632}]}, {"text": " Table 7: Performance evaluation in Identification Level", "labels": [], "entities": []}, {"text": " Table 8: Performance evaluation in Position Level.", "labels": [], "entities": []}]}