{"title": [{"text": "Dealing with word-internal modification and spelling variation in data-driven lemmatization", "labels": [], "entities": [{"text": "word-internal modification", "start_pos": 13, "end_pos": 39, "type": "TASK", "confidence": 0.6974911242723465}]}], "abstractContent": [{"text": "This paper describes our contribution to two challenges in data-driven lemmatiza-tion.", "labels": [], "entities": []}, {"text": "We approach lemmatization in the framework of a two-stage process, where first lemma candidates are generated and afterwards a ranker chooses the most probable lemma from these candidates.", "labels": [], "entities": []}, {"text": "The first challenge is that languages with rich morphology like Modern German can feature morphological changes of different kinds, in particular word-internal modification.", "labels": [], "entities": []}, {"text": "This makes the generation of the correct lemma a harder task than just removing suffixes (stemming).", "labels": [], "entities": []}, {"text": "The second challenge that we address is spelling variation as it appears in non-standard texts.", "labels": [], "entities": [{"text": "spelling variation", "start_pos": 40, "end_pos": 58, "type": "TASK", "confidence": 0.8378840088844299}]}, {"text": "We experiment with different generators that are specifically tailored to deal with these two challenges.", "labels": [], "entities": []}, {"text": "We show in an oracle setting that there is a possible increase in lemmatization accuracy of 14% with our methods to generate lemma candidates on Middle Low German, a group of historical dialects of German (1200-1650 AD).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 80, "end_pos": 88, "type": "METRIC", "confidence": 0.9618808627128601}, {"text": "Middle Low German, a group of historical dialects of German (1200-1650 AD)", "start_pos": 145, "end_pos": 219, "type": "DATASET", "confidence": 0.8666357894738516}]}, {"text": "Using a log-linear model to choose the correct lemma from the set, we obtain an actual increase of 5.56%.", "labels": [], "entities": []}], "introductionContent": [{"text": "Lemmatization is the task of finding the lemma or base form fora given word token.", "labels": [], "entities": []}, {"text": "It is used as a preprocessing step for information retrieval and other NLP applications for languages with rich morphology and has been shown to outperform stemming for some tasks ().", "labels": [], "entities": [{"text": "information retrieval", "start_pos": 39, "end_pos": 60, "type": "TASK", "confidence": 0.81944939494133}]}, {"text": "Lemmatization can be formalized as a string transduction task where for an input sequence of tokens t 1 . .", "labels": [], "entities": []}, {"text": "tn an output sequence of lemmas l 1 . .", "labels": [], "entities": []}, {"text": "This task has been approached in a variety of ways, e.g. by combining morphological rules with dictionary lookups.", "labels": [], "entities": []}, {"text": "introduced a sequencelabeling approach to lemmatization in which a token is labeled with a rule that transforms it to its lemma.", "labels": [], "entities": []}, {"text": "The set of rules from which the labels are chosen are induced automatically from the training data.", "labels": [], "entities": []}, {"text": "use a similar setting, but, instead of choosing a rule to apply, they apply all possible rules and afterwards use a ranker to select the lemma.", "labels": [], "entities": []}, {"text": "Conceptually, this is a two-stage approach towards lemmatizationfirst generating lemma candidates fora given type, i.e. an inflected word form, and then choosing the best of these candidates for the token.", "labels": [], "entities": []}, {"text": "We follow this approach and present generators that increase the number of correct lemma candidates that can be generated for out-of-vocabulary (OOV) words in the case of word-internal modification and spelling variation: (i) Word-internal modifications like the umlaut (Schl\u00e4ge -Schlag \"strikes -(the) strike\") and infixation (aufgegessen -aufessen \"eaten up -eat up\") in Modern German (DEU) 1 pose special problems to lemma candidate generation.", "labels": [], "entities": [{"text": "lemma candidate generation", "start_pos": 420, "end_pos": 446, "type": "TASK", "confidence": 0.7026242216428121}]}, {"text": "In order to improve the generalization capabilities of the rules induced from the training data, we substitute the edit trees (ET) used by  with lexical correspondences (LC).", "labels": [], "entities": []}, {"text": "(ii) Spelling variation as it appears in historical language or computer-mediated communication results in an increase in data sparsity and therefore a large number of OOV words.", "labels": [], "entities": [{"text": "Spelling variation", "start_pos": 5, "end_pos": 23, "type": "TASK", "confidence": 0.936334103345871}]}, {"text": "We add a generator that returns the lemma candidates for the most similar in-vocabulary (IV) word(s).", "labels": [], "entities": []}, {"text": "Thereby, the lemmatization can be made more ro-bust against simple misspellings or spelling variations, since the correct lemma can be returned even in these cases.", "labels": [], "entities": []}, {"text": "We test our approach on Middle Low German (GML) texts.", "labels": [], "entities": [{"text": "Middle Low German (GML) texts", "start_pos": 24, "end_pos": 53, "type": "DATASET", "confidence": 0.774165153503418}]}, {"text": "GML is a group of historical dialects of German (1200-1650 AD), which -like DEU -features word-internal modification.", "labels": [], "entities": [{"text": "GML", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.8935297131538391}]}, {"text": "Also, as a historical language, GML exhibits spelling variation.", "labels": [], "entities": []}, {"text": "In order to see how hard these features make the task of lemmatizing GML, we compare it with lemmatizing DEU newswire texts.", "labels": [], "entities": [{"text": "GML", "start_pos": 69, "end_pos": 72, "type": "DATASET", "confidence": 0.7270338535308838}, {"text": "DEU newswire texts", "start_pos": 105, "end_pos": 123, "type": "DATASET", "confidence": 0.9470138152440389}]}], "datasetContent": [{"text": "In this section we evaluate the effects of using lexical correspondences and the generation of lemma candidates from similar IV types.", "labels": [], "entities": []}, {"text": "We test our approach on Middle Low German (GML).", "labels": [], "entities": [{"text": "Middle Low German (GML)", "start_pos": 24, "end_pos": 47, "type": "DATASET", "confidence": 0.8749736348787943}]}, {"text": "The data comes from the 'Reference Corpus Middle Low German/ Low Rhenish (1200-1650)' (ReN)).", "labels": [], "entities": [{"text": "Reference Corpus Middle Low German/ Low Rhenish (1200-1650)' (ReN))", "start_pos": 25, "end_pos": 92, "type": "DATASET", "confidence": 0.9358897720064435}]}, {"text": "We use two texts: Johannes (19,641 tokens) as training data and Griseldis (9,057 tokens), that we split into two nearly equal parts, as development set (4,505 tokens) and test set (4,552 tokens).", "labels": [], "entities": [{"text": "Johannes", "start_pos": 18, "end_pos": 26, "type": "DATASET", "confidence": 0.9666391015052795}, {"text": "Griseldis", "start_pos": 64, "end_pos": 73, "type": "METRIC", "confidence": 0.9165757894515991}]}, {"text": "Full bibliographical information is given in the bibliography.", "labels": [], "entities": []}, {"text": "To assess the difficulty of lemmatizing GML, we compare our results with the accuracy on Modern German (DEU) newswire texts.", "labels": [], "entities": [{"text": "lemmatizing GML", "start_pos": 28, "end_pos": 43, "type": "TASK", "confidence": 0.6627548336982727}, {"text": "accuracy", "start_pos": 77, "end_pos": 85, "type": "METRIC", "confidence": 0.999313235282898}, {"text": "Modern German (DEU) newswire texts", "start_pos": 89, "end_pos": 123, "type": "DATASET", "confidence": 0.8853902816772461}]}, {"text": "For this, we use the TIGER corpus (Release 2.2) () with the same splits as . In order to make the tasks on GML and DEU more comparable, we limit the training data to roughly 20,000 tokens and lowercase all types and lemmas in both datasets.", "labels": [], "entities": [{"text": "TIGER corpus", "start_pos": 21, "end_pos": 33, "type": "DATASET", "confidence": 0.8373142778873444}, {"text": "GML", "start_pos": 107, "end_pos": 110, "type": "DATASET", "confidence": 0.9670544266700745}, {"text": "DEU", "start_pos": 115, "end_pos": 118, "type": "DATASET", "confidence": 0.7455534934997559}]}, {"text": "Examples for word-internal modification in DEU have been given in).", "labels": [], "entities": [{"text": "word-internal modification", "start_pos": 13, "end_pos": 39, "type": "TASK", "confidence": 0.6709985136985779}, {"text": "DEU", "start_pos": 43, "end_pos": 46, "type": "DATASET", "confidence": 0.783768892288208}]}, {"text": "An example for spelling variation in GML is the pair of types vigenbome and vighenbome \"(the) fig tree.SG.DAT\" (Johannes).", "labels": [], "entities": [{"text": "spelling variation", "start_pos": 15, "end_pos": 33, "type": "TASK", "confidence": 0.8301878869533539}]}, {"text": "The corresponding lemma v\u02c6\u0131genb\u00f4mv\u02c6\u0131genb\u00f4m also illustrates a special convention in the lemmatization of the GML texts: diacritics are added.", "labels": [], "entities": [{"text": "GML texts", "start_pos": 109, "end_pos": 118, "type": "DATASET", "confidence": 0.9438321590423584}]}, {"text": "In this case they denote the length of the vowels.", "labels": [], "entities": []}, {"text": "These diacritics have the same effect as word-internal modification for the lemmatization.", "labels": [], "entities": []}, {"text": "We evaluated the effects of different parameter settings on the development set.", "labels": [], "entities": []}, {"text": "The numbers in this section report the performance of selected settings on the test set measured on tokens.", "labels": [], "entities": []}, {"text": "Note that the corpus is still under construction.", "labels": [], "entities": []}, {"text": "The tokenization and the annotations used are prefinal.", "labels": [], "entities": []}, {"text": "Therefore, the size of the texts might deviate from the numbers given elsewhere.", "labels": [], "entities": []}, {"text": "We do not train and evaluate the lemmatization accuracy on splits of the same text as we are interested in the performance of the lemmatization in the situation were a set of lemmatized texts exists for training and the obtained model is applied to anew text.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 47, "end_pos": 55, "type": "METRIC", "confidence": 0.9586119651794434}]}, {"text": "The lemmas also contain numbers to disambiguate meanings.", "labels": [], "entities": []}, {"text": "Since this adds a word-sense-disambiguation task to the lemmatization, they have been removed for the experiments.", "labels": [], "entities": []}, {"text": "The results can be found in Appendix B.  First, we look at the coverage of the different generators described in the previous sections, i.e. the number of tokens for which the generated set of lemma candidates contains the correct lemma, in other words, the accuracy given an oracle that chooses the correct lemma.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 258, "end_pos": 266, "type": "METRIC", "confidence": 0.9990174770355225}]}, {"text": "We train the generators on the training set.", "labels": [], "entities": []}, {"text": "In addition to the lemma candidates generated by the rules induced from the training data, we always extend the set of lemma candidates by all the lemmas that an IV type appears within the training data.", "labels": [], "entities": []}, {"text": "Coverage should be increased because it sets an upper bound to the lemmatization accuracy.", "labels": [], "entities": [{"text": "Coverage", "start_pos": 0, "end_pos": 8, "type": "METRIC", "confidence": 0.9786934852600098}, {"text": "accuracy", "start_pos": 81, "end_pos": 89, "type": "METRIC", "confidence": 0.9818184971809387}]}, {"text": "At the same time, the average size of the candidate sets should be kept as small as possible, to make the task of the ranker easier, i.e. choosing the correct lemma in real-life settings without an oracle.", "labels": [], "entities": []}, {"text": "We experimented with using only rules that appear at least n times with type-lemma pairs in the training data.", "labels": [], "entities": []}, {"text": "In addition, we tested whether a POS-tag dependent application of the rules would limit the amount of overgeneration.", "labels": [], "entities": []}, {"text": "We found that using all rules POS-tag dependently gave the best trade-off between coverage and average candidate set size on the development set.", "labels": [], "entities": [{"text": "coverage", "start_pos": 82, "end_pos": 90, "type": "METRIC", "confidence": 0.9904955625534058}]}, {"text": "Table 1 and 2 give the results from the experiments on the test data.", "labels": [], "entities": []}, {"text": "contains a comparison between DEU and GML.", "labels": [], "entities": [{"text": "DEU", "start_pos": 30, "end_pos": 33, "type": "DATASET", "confidence": 0.9087418913841248}, {"text": "GML", "start_pos": 38, "end_pos": 41, "type": "DATASET", "confidence": 0.9633349180221558}]}, {"text": "The results show that lemmatizing GML is harder than lemmatizing DEU.", "labels": [], "entities": [{"text": "GML", "start_pos": 34, "end_pos": 37, "type": "DATASET", "confidence": 0.7117238640785217}, {"text": "DEU", "start_pos": 65, "end_pos": 68, "type": "DATASET", "confidence": 0.8023031949996948}]}, {"text": "Given a similar amount of training data (about 20,000 tokens), there is a difference of about 24.5% in the coverage between the two languages -using ETs the coverage drops from 98.92% for DEU to 74.3% for GML.", "labels": [], "entities": [{"text": "DEU", "start_pos": 188, "end_pos": 191, "type": "DATASET", "confidence": 0.9221556186676025}, {"text": "GML", "start_pos": 205, "end_pos": 208, "type": "DATASET", "confidence": 0.9518730640411377}]}, {"text": "While for DEU all of the generators reach a high coverage with a small average number of lemma candidates ( cand.) the coverage for GML is significantly lower with an average size of the candidate sets that is more than three times larger than for DEU.", "labels": [], "entities": [{"text": "GML", "start_pos": 132, "end_pos": 135, "type": "DATASET", "confidence": 0.843005359172821}, {"text": "DEU", "start_pos": 248, "end_pos": 251, "type": "DATASET", "confidence": 0.9108747243881226}]}, {"text": "The reason for the drop in coverage and the increase in the average number of lemma candidates might be more word internal modifications and the existence of spelling variation in GML.", "labels": [], "entities": [{"text": "coverage", "start_pos": 27, "end_pos": 35, "type": "METRIC", "confidence": 0.9883461594581604}, {"text": "GML", "start_pos": 180, "end_pos": 183, "type": "DATASET", "confidence": 0.8734995722770691}]}, {"text": "Following, we present the improvements coming from the methods we introduced to deal with word-internal modification and spelling variation.", "labels": [], "entities": [{"text": "word-internal modification", "start_pos": 90, "end_pos": 116, "type": "TASK", "confidence": 0.7457297444343567}, {"text": "spelling variation", "start_pos": 121, "end_pos": 139, "type": "TASK", "confidence": 0.8096687495708466}]}, {"text": "We used gold tags for the training and evaluation.", "labels": [], "entities": []}, {"text": "When using predicted POS tags, the performance of POS-tag dependent candidate generation depends on the quality of the predictions.", "labels": [], "entities": []}, {"text": "Next to the results for ETs, gives the coverage results for lexical correspondences (LC) and lexical correspondences with anchored insertions (LC-AI, see section 3) on the test data.", "labels": [], "entities": [{"text": "coverage", "start_pos": 39, "end_pos": 47, "type": "METRIC", "confidence": 0.9940218329429626}]}, {"text": "The improvements in coverage coming from the better modeling of word-internal modifications are the same for LCs and LC-AIs for both languages while LC-AIs effectively reduce the number of wrongly generated lemma candidates compared with pure LCs.", "labels": [], "entities": [{"text": "coverage", "start_pos": 20, "end_pos": 28, "type": "METRIC", "confidence": 0.9859063625335693}]}, {"text": "This is especially visible for GML.", "labels": [], "entities": [{"text": "GML", "start_pos": 31, "end_pos": 34, "type": "DATASET", "confidence": 0.9590076804161072}]}, {"text": "For DEU, using LC(-AI)s leads to a small improvement for OOV words of 0.41% which is an error reduction of about 10%.", "labels": [], "entities": [{"text": "DEU", "start_pos": 4, "end_pos": 7, "type": "DATASET", "confidence": 0.7796792387962341}, {"text": "OOV", "start_pos": 57, "end_pos": 60, "type": "METRIC", "confidence": 0.9339035153388977}, {"text": "error reduction", "start_pos": 88, "end_pos": 103, "type": "METRIC", "confidence": 0.9722374975681305}]}, {"text": "Given the homogeneity of data in the TIGER corpus, this only leads to an overall improvement of the coverage of 0.12%.", "labels": [], "entities": [{"text": "TIGER corpus", "start_pos": 37, "end_pos": 49, "type": "DATASET", "confidence": 0.9131204187870026}, {"text": "coverage", "start_pos": 100, "end_pos": 108, "type": "METRIC", "confidence": 0.9941885471343994}]}, {"text": "These numbers decrease further when more training material is used.", "labels": [], "entities": []}, {"text": "Using about 100,000 tokens from the TIGER corpus for training, the coverage goes up to 99.50% (OOV: 97.84%) with ETs and 99.54% (OOV: 98%) with LC-AIs.", "labels": [], "entities": [{"text": "TIGER corpus", "start_pos": 36, "end_pos": 48, "type": "DATASET", "confidence": 0.8142397999763489}, {"text": "coverage", "start_pos": 67, "end_pos": 75, "type": "METRIC", "confidence": 0.9673447012901306}, {"text": "OOV", "start_pos": 95, "end_pos": 98, "type": "METRIC", "confidence": 0.8851456046104431}]}, {"text": "However, the numbers indicate that even languages with moderate word-internal modification can benefit from the usage of LCs, especially when the amount of training data is limited and the lemmatizer has to deal with a large number of OOV types.", "labels": [], "entities": []}, {"text": "As has been expected, the effect of using LC(-AI)s is bigger for GML, leading to an overall increase of 1.25% points.", "labels": [], "entities": [{"text": "GML", "start_pos": 65, "end_pos": 68, "type": "DATASET", "confidence": 0.8685384392738342}]}, {"text": "However, the gap in performance between DEU and GML remains huge.", "labels": [], "entities": [{"text": "DEU", "start_pos": 40, "end_pos": 43, "type": "DATASET", "confidence": 0.8917801976203918}, {"text": "GML", "start_pos": 48, "end_pos": 51, "type": "DATASET", "confidence": 0.9425895810127258}]}, {"text": "The additional complexity of the task on GML is at least partially due to spelling variation.", "labels": [], "entities": [{"text": "GML", "start_pos": 41, "end_pos": 44, "type": "DATASET", "confidence": 0.8865160942077637}]}, {"text": "To deal with this, we carried out experiments with a regularized 17 version of the data and compare it with the generation of lemma candidates from similar IV types described in Section 4.", "labels": [], "entities": []}, {"text": "The regularized version of the data is created using a rule-based approach with 26 handcrafted rewrite rules (in the form of regular expressions and substitutions), which was created by experts on GML for the purpose of reducing the spelling variation.", "labels": [], "entities": [{"text": "GML", "start_pos": 197, "end_pos": 200, "type": "DATASET", "confidence": 0.9418339729309082}]}, {"text": "dates are generated using all LC-AIs learned from the training data POS-tag dependently.", "labels": [], "entities": []}, {"text": "For IV types, all their lemmas from the training data are added as well.", "labels": [], "entities": []}, {"text": "Firstly, we determined an upper bound by adding all lemmas that appeared in the training data to the candidate sets.", "labels": [], "entities": []}, {"text": "shows that the coverage increases from 74.3% to 88.31% using our method.", "labels": [], "entities": [{"text": "coverage", "start_pos": 15, "end_pos": 23, "type": "METRIC", "confidence": 0.9977444410324097}]}, {"text": "This is a potential gain of about 14% -7.58% more than with regularization (80.73%).", "labels": [], "entities": []}, {"text": "However, using all lemma candidates for OOV types increases the average candidate set size to 302.46.", "labels": [], "entities": []}, {"text": "Secondly, we tested the trade-off between coverage and set size for our method of generating lemma candidates only from similar IV types (cf. Section 4).", "labels": [], "entities": [{"text": "coverage", "start_pos": 42, "end_pos": 50, "type": "METRIC", "confidence": 0.9791508913040161}]}, {"text": "gives examplary results on the test set.", "labels": [], "entities": [{"text": "examplary", "start_pos": 6, "end_pos": 15, "type": "METRIC", "confidence": 0.960142195224762}]}, {"text": "We explored the effects of different paramater settings on the development set.", "labels": [], "entities": []}, {"text": "For the Levenshtein distance, we used the maximal distance as parameter and Levenshtein automata () for finding candidates efficiently.", "labels": [], "entities": [{"text": "maximal distance", "start_pos": 42, "end_pos": 58, "type": "METRIC", "confidence": 0.9466356337070465}]}, {"text": "For the Jaccard Index, we varied the minimal similarity (between 0 and 0.7 in steps of 0.1, adding 0.25 and a smaller step size of 0.11 between 0.1 and 0.2), the minimal size of character n-grams, the maximal size of ngrams ({2, 3, 4, \u221e}) and the maximal size of skips.", "labels": [], "entities": [{"text": "Jaccard Index", "start_pos": 8, "end_pos": 21, "type": "DATASET", "confidence": 0.7981853187084198}]}, {"text": "Furthermore, we optionally applied the frequency-based weighting on the similarity features.", "labels": [], "entities": []}, {"text": "To improve the precision, we calculated the probability of the possible spelling variants returned by the best parameter set- We used the implementation from https: //github.com/universal-automata/ liblevenshtein-java.", "labels": [], "entities": [{"text": "precision", "start_pos": 15, "end_pos": 24, "type": "METRIC", "confidence": 0.9995747208595276}]}, {"text": "tings for different thresholds on the set size), using the product of the P (e) estimated by Equation 2.", "labels": [], "entities": [{"text": "P (e)", "start_pos": 74, "end_pos": 79, "type": "METRIC", "confidence": 0.9355873912572861}, {"text": "Equation", "start_pos": 93, "end_pos": 101, "type": "METRIC", "confidence": 0.9375365972518921}]}, {"text": "We tested different thresholds on the probability below which the pair was excluded (between 0.5 and 0.2, decreasing by 0.1 and decreasing by 0.025 between 0.2 and 0).", "labels": [], "entities": []}, {"text": "The Levenshtein distance is an easy to use method, leading to good results with a distance of 1 or 2.", "labels": [], "entities": [{"text": "Levenshtein distance", "start_pos": 4, "end_pos": 24, "type": "METRIC", "confidence": 0.6172536611557007}]}, {"text": "Using a distance of 1 already leads to a better coverage than the regularization with only a small increase in the average set size.", "labels": [], "entities": [{"text": "coverage", "start_pos": 48, "end_pos": 56, "type": "METRIC", "confidence": 0.9614182710647583}]}, {"text": "The Jaccard Index has more parameters.", "labels": [], "entities": [{"text": "Jaccard Index", "start_pos": 4, "end_pos": 17, "type": "DATASET", "confidence": 0.7986111342906952}]}, {"text": "With tuning them, it is possible to reach better coverage for any given upper bound on the average set size than with Levenshtein.", "labels": [], "entities": [{"text": "coverage", "start_pos": 49, "end_pos": 57, "type": "METRIC", "confidence": 0.9725250005722046}]}, {"text": "In sum, we get best results by using the Jaccard Index with a small similarity threshold, ngrams up to the length of the type, allowing skips in the n-grams, and weighting the features by their inverse frequency.", "labels": [], "entities": []}, {"text": "In addition, using the probabilities for edit operations to exclude unlikely pairs helped to improve precision.", "labels": [], "entities": [{"text": "precision", "start_pos": 101, "end_pos": 110, "type": "METRIC", "confidence": 0.9979548454284668}]}], "tableCaptions": [{"text": " Table 1: Coverage statistics  Coverage (%): number of tokens for which the candidate set contains the correct lemma;  cand.: the average size of the candidate sets.", "labels": [], "entities": []}, {"text": " Table 2: Coverage for lemma generation with handling of spelling variation on GML  Parameter for Levenshtein: maximal distance; Parameters for Jaccard: minimal similarity, minimal and  maximal size of character n-grams, maximal size of skips; P denotes the product of the P(e).", "labels": [], "entities": [{"text": "lemma generation", "start_pos": 23, "end_pos": 39, "type": "TASK", "confidence": 0.7257404029369354}, {"text": "GML", "start_pos": 79, "end_pos": 82, "type": "DATASET", "confidence": 0.9569222331047058}, {"text": "Parameter", "start_pos": 84, "end_pos": 93, "type": "METRIC", "confidence": 0.4597829282283783}, {"text": "maximal distance", "start_pos": 111, "end_pos": 127, "type": "METRIC", "confidence": 0.8825052380561829}]}]}