{"title": [{"text": "Verb Sense Disambiguation in Machine Translation", "labels": [], "entities": [{"text": "Verb Sense Disambiguation in Machine Translation", "start_pos": 0, "end_pos": 48, "type": "TASK", "confidence": 0.6641134768724442}]}], "abstractContent": [{"text": "We describe experiments in Machine Translation using word sense disambiguation (WSD) information.", "labels": [], "entities": [{"text": "Machine Translation", "start_pos": 27, "end_pos": 46, "type": "TASK", "confidence": 0.811663031578064}, {"text": "word sense disambiguation (WSD) information", "start_pos": 53, "end_pos": 96, "type": "TASK", "confidence": 0.766424902847835}]}, {"text": "This work focuses on WSD in verbs, based on two different approaches-verbal patterns based on corpus pattern analysis and verbal word senses from valency frames.", "labels": [], "entities": [{"text": "WSD", "start_pos": 21, "end_pos": 24, "type": "TASK", "confidence": 0.9943804144859314}]}, {"text": "We evaluate several options of using verb senses in the source-language sentences as an additional factor for the Moses statistical machine translation system.", "labels": [], "entities": [{"text": "Moses statistical machine translation", "start_pos": 114, "end_pos": 151, "type": "TASK", "confidence": 0.5152328088879585}]}, {"text": "Our results show a statistically significant translation quality improvement in terms of the BLEU metric for the valency frames approach, but in manual evaluation, both WSD methods bring improvements.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 93, "end_pos": 97, "type": "METRIC", "confidence": 0.9979363679885864}]}], "introductionContent": [{"text": "The possibility of using word sense disambiguation (WSD) systems in machine translation (MT) has recently been investigated in several ways: Output of WSD systems has been incorporated into MT to improve translation quality -at the decoding step of a phrase-based statistical machine translation (PB-SMT) system or as contextual features in maximum entropy (MaxEnt) models and).", "labels": [], "entities": [{"text": "word sense disambiguation (WSD)", "start_pos": 25, "end_pos": 56, "type": "TASK", "confidence": 0.7847921202580134}, {"text": "machine translation (MT)", "start_pos": 68, "end_pos": 92, "type": "TASK", "confidence": 0.8507496476173401}, {"text": "MT", "start_pos": 190, "end_pos": 192, "type": "TASK", "confidence": 0.9552148580551147}, {"text": "phrase-based statistical machine translation (PB-SMT)", "start_pos": 251, "end_pos": 304, "type": "TASK", "confidence": 0.7400534493582589}]}, {"text": "In addition, WSD has also been used in MT evaluation, for example in METEOR ().", "labels": [], "entities": [{"text": "WSD", "start_pos": 13, "end_pos": 16, "type": "TASK", "confidence": 0.5392186045646667}, {"text": "MT evaluation", "start_pos": 39, "end_pos": 52, "type": "TASK", "confidence": 0.9732747077941895}]}, {"text": "These works indicate that WSD can be beneficial to different MT tasks, in case of using senses as contextual features for MaxEnt models achieve statistically significant improvement over the baseline for English-to-Portuguese translation.", "labels": [], "entities": [{"text": "WSD", "start_pos": 26, "end_pos": 29, "type": "TASK", "confidence": 0.8824679255485535}, {"text": "MT tasks", "start_pos": 61, "end_pos": 69, "type": "TASK", "confidence": 0.9216420948505402}]}, {"text": "And report that usage of WSD can establish better sense correspondences and improve its correlation with human judgments of translation quality.", "labels": [], "entities": [{"text": "WSD", "start_pos": 25, "end_pos": 28, "type": "TASK", "confidence": 0.8600248694419861}]}, {"text": "In this research, we have investigated the possibilities of integrating two different approaches to verbal WSD into a PB-SMT system -verb patterns based on corpus pattern analysis (CPA) and verbal word senses in valency frames.", "labels": [], "entities": []}, {"text": "The focus on verbs was motivated by the ideas that verbs carry a crucial part of the meaning of the sentence and thus accurate translation of the verb is critical for the understanding of the translation.", "labels": [], "entities": []}, {"text": "Therefore, improvement of the translation of verbs can lead to overall increase of the translation quality.", "labels": [], "entities": []}, {"text": "Therefore, improvement of the translation of verbs can lead to an overall increase of translation quality.", "labels": [], "entities": []}, {"text": "The outputs of automatic verb sense disambiguation systems using both CPA and valency frames were integrated into Moses statistical machine translation system( . Both kinds of verb senses were added as additional factors ).", "labels": [], "entities": [{"text": "statistical machine translation", "start_pos": 120, "end_pos": 151, "type": "TASK", "confidence": 0.6090302566687266}]}, {"text": "Section 4.1 shows that we obtain statistically significant improvement in terms of BLEU scores () and manual evaluation of translations validated that.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 83, "end_pos": 87, "type": "METRIC", "confidence": 0.9985894560813904}]}, {"text": "The novelty of this work lies not only in our focus only on verbs senses, but also in the fact that we are comparing the impact of two WSD approaches on the statistical machine translation.", "labels": [], "entities": [{"text": "statistical machine translation", "start_pos": 157, "end_pos": 188, "type": "TASK", "confidence": 0.6169100304444631}]}, {"text": "The following Section 2 describes the initial setup of our experiments.", "labels": [], "entities": []}, {"text": "Section 3 and Section 4 depict the idea behind corpus pattern analysis and verb valency frames representations and show evaluation results of incorporation of these sense to phrase-based statistical machine translation.", "labels": [], "entities": [{"text": "corpus pattern analysis", "start_pos": 47, "end_pos": 70, "type": "TASK", "confidence": 0.6407610774040222}, {"text": "phrase-based statistical machine translation", "start_pos": 174, "end_pos": 218, "type": "TASK", "confidence": 0.6034287139773369}]}, {"text": "The next section (Section 5) is devoted to the discussion of results obtained during the evaluation.", "labels": [], "entities": []}, {"text": "And finally Section 6 describes our plan of the future work.", "labels": [], "entities": []}], "datasetContent": [{"text": "For our experiments, we have used a subset of the Czech-English corpus CzEng 1.0 ( ; the respective numbers of sentences and tokens in each of training, development and test sets are shown in.", "labels": [], "entities": [{"text": "Czech-English corpus CzEng 1.0", "start_pos": 50, "end_pos": 80, "type": "DATASET", "confidence": 0.903660774230957}]}, {"text": "For our experiments, 28 different English verbs were selected and automatically annotated with corpus pattern analysis senses, and 3,306 verbs annotated using valency frames.", "labels": [], "entities": []}, {"text": "The subset has been selected to include verbs annotated with CPA, so the effect of WSD would be visible.", "labels": [], "entities": [{"text": "WSD", "start_pos": 83, "end_pos": 86, "type": "TASK", "confidence": 0.5806443095207214}]}, {"text": "All the experiments were carried out in the Eman experiment management system) using the Moses PB-SMT system (  as the core and minimum error rate training) to optimize the decoder feature weights on the development set.", "labels": [], "entities": [{"text": "Eman experiment management system", "start_pos": 44, "end_pos": 77, "type": "DATASET", "confidence": 0.9395964592695236}, {"text": "minimum error rate training", "start_pos": 128, "end_pos": 155, "type": "METRIC", "confidence": 0.7712622433900833}]}, {"text": "The evaluation was performed using the BLEU score (), but the results of each setup were then thoroughly examined and verified using the MT-ComparEval system (  Based on the results of the experiments shown in Section 3.1, we have decided to focus only on the following configurations: Form\u2192Form+Tag, Form+Sense\u2192Form+Tag and their combination: Evaluation results for valency frames annotation, best MERT for each configuration Form\u2192Form+Tag + Form+Sense\u2192Form+Tag.", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 39, "end_pos": 49, "type": "METRIC", "confidence": 0.9615302681922913}, {"text": "MERT", "start_pos": 399, "end_pos": 403, "type": "METRIC", "confidence": 0.9991317391395569}]}, {"text": "shows the results for best MERT runs for each configuration.", "labels": [], "entities": [{"text": "MERT", "start_pos": 27, "end_pos": 31, "type": "TASK", "confidence": 0.6309481263160706}]}, {"text": "MultEval MERT evaluation for the all configurations mentioned above, with Form\u2192Form+Tag as a baseline, is shown in Table 6.", "labels": [], "entities": [{"text": "MultEval", "start_pos": 0, "end_pos": 8, "type": "METRIC", "confidence": 0.7377458214759827}]}, {"text": "The table shows that the average Form+Sense\u2192Form+Tag model results are still 0.1% BLEU worse than the Form\u2192Form+Tag model, but the average results of the combined Form\u2192Form+Tag + Form+Sense\u2192Form+Tag model are 0.1% BLEU better than the average results of Form\u2192Form+Tag.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 82, "end_pos": 86, "type": "METRIC", "confidence": 0.9994843006134033}, {"text": "Form\u2192Form+Tag + Form+Sense\u2192Form+Tag", "start_pos": 163, "end_pos": 198, "type": "TASK", "confidence": 0.49215699846927935}, {"text": "BLEU", "start_pos": 214, "end_pos": 218, "type": "METRIC", "confidence": 0.9994230270385742}]}, {"text": "The results of MultEval's stratified approximate randomization test) allow us to claim that the combination of these two models is statistically significantly better than the baseline.", "labels": [], "entities": []}, {"text": "The same is true for METEOR and TER tests results, shown in the same table.", "labels": [], "entities": [{"text": "METEOR", "start_pos": 21, "end_pos": 27, "type": "METRIC", "confidence": 0.9295046925544739}, {"text": "TER", "start_pos": 32, "end_pos": 35, "type": "METRIC", "confidence": 0.9875863790512085}]}, {"text": "It also shows that the valency frames approach to WSD has more impact on MT than CPA in our case.", "labels": [], "entities": [{"text": "WSD", "start_pos": 50, "end_pos": 53, "type": "TASK", "confidence": 0.9354445338249207}, {"text": "MT", "start_pos": 73, "end_pos": 75, "type": "TASK", "confidence": 0.984098494052887}]}], "tableCaptions": [{"text": " Table 1. For our experiments, 28 different English verbs were selected and automatically annotated  with corpus pattern analysis senses, and 3,306 verbs annotated using valency frames. The subset has  been selected to include verbs annotated with CPA, so the effect of WSD would be visible. All the  experiments were carried out in the Eman experiment management system", "labels": [], "entities": [{"text": "WSD", "start_pos": 270, "end_pos": 273, "type": "TASK", "confidence": 0.5382755398750305}, {"text": "Eman experiment management", "start_pos": 337, "end_pos": 363, "type": "DATASET", "confidence": 0.9557803074518839}]}, {"text": " Table 1: Data set composition", "labels": [], "entities": []}, {"text": " Table 3: Evaluation results for corpus pattern analysis annotation, best MERT run", "labels": [], "entities": [{"text": "corpus pattern analysis annotation", "start_pos": 33, "end_pos": 67, "type": "TASK", "confidence": 0.8079205602407455}, {"text": "MERT", "start_pos": 74, "end_pos": 78, "type": "METRIC", "confidence": 0.9324511885643005}]}, {"text": " Table 4: Multeval results for corpus pattern analysis, based on 36 MERT runs", "labels": [], "entities": [{"text": "Multeval", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.8934965133666992}, {"text": "corpus pattern analysis", "start_pos": 31, "end_pos": 54, "type": "TASK", "confidence": 0.8258499701817831}, {"text": "MERT", "start_pos": 68, "end_pos": 72, "type": "METRIC", "confidence": 0.8621626496315002}]}, {"text": " Table 5: Evaluation results for valency frames annotation, best MERT for each configuration", "labels": [], "entities": [{"text": "MERT", "start_pos": 65, "end_pos": 69, "type": "METRIC", "confidence": 0.9974455833435059}]}, {"text": " Table 6: MultEval results for valency frames, based on 8 MERT runs", "labels": [], "entities": [{"text": "MultEval", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.8936103582382202}, {"text": "MERT", "start_pos": 58, "end_pos": 62, "type": "METRIC", "confidence": 0.9026108384132385}]}]}