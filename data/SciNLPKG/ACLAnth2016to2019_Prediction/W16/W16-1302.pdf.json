{"title": [{"text": "Discovering Entity Knowledge Bases on the Web", "labels": [], "entities": [{"text": "Discovering Entity Knowledge Bases", "start_pos": 0, "end_pos": 34, "type": "TASK", "confidence": 0.8669328391551971}]}], "abstractContent": [{"text": "Recognition and disambiguation of named entities in text is a knowledge-intensive task.", "labels": [], "entities": [{"text": "Recognition and disambiguation of named entities in text", "start_pos": 0, "end_pos": 56, "type": "TASK", "confidence": 0.8645050004124641}]}, {"text": "Systems are typically bound by the resources and coverage of a single target knowledge base (KB).", "labels": [], "entities": []}, {"text": "In place of a fixed knowledge base, we attempt to infer a set of endpoints which reliably disambiguate entity mentions on the web.", "labels": [], "entities": []}, {"text": "We propose a method for discovering web KBs and our preliminary results suggest that web KBs allow linking to entities that can be found on the web, but may not merit a major KB entry.", "labels": [], "entities": []}], "introductionContent": [{"text": "Entity linking (EL) resolves textual mentions to the correct node in a knowledge base (KB).", "labels": [], "entities": [{"text": "Entity linking (EL) resolves textual mentions", "start_pos": 0, "end_pos": 45, "type": "TASK", "confidence": 0.8552257940173149}]}, {"text": "Linking systems typically rely on semantic resources like Wikipedia as endpoints for disambiguation.", "labels": [], "entities": []}, {"text": "These sources provide context for entity modelling, but impose an upper bound on recall based on their domain of coverage.", "labels": [], "entities": [{"text": "entity modelling", "start_pos": 34, "end_pos": 50, "type": "TASK", "confidence": 0.71509850025177}, {"text": "recall", "start_pos": 81, "end_pos": 87, "type": "METRIC", "confidence": 0.9983726143836975}]}, {"text": "Wide domain KBs like Wikipedia constrain coverage based on notability, while narrow domain sources like IMDb 1 or MusicBrainz give depth at the expense of breadth.", "labels": [], "entities": [{"text": "MusicBrainz", "start_pos": 114, "end_pos": 125, "type": "DATASET", "confidence": 0.8423045873641968}, {"text": "breadth", "start_pos": 155, "end_pos": 162, "type": "METRIC", "confidence": 0.9562726020812988}]}, {"text": "While it is possible to merge resources from multiple KBs in some applications, an explicit reconciliation of distinct entity sets and KB schemata is often problematic.", "labels": [], "entities": []}, {"text": "We explore a relaxed definition of a KB -any URI which reliably disambiguates linked mentions on the web.", "labels": [], "entities": []}, {"text": "This covers resources which both work as a KB by design (e.g. a Wikipedia article) and those   which do so implicitly by disambiguating mentions.", "labels": [], "entities": []}, {"text": "We focus on the latter case, by trying to identify and exploit class-instance URI patterns.", "labels": [], "entities": []}, {"text": "shows these patterns extracted from a website URIs listing classes of entity and instances of them -the entity endpoints.", "labels": [], "entities": []}, {"text": "We start by reviewing existing views of KBs, then discussing the content editing and publishing behaviours that we seek to exploit.", "labels": [], "entities": []}, {"text": "To actually exploit these resources, we must first infer their existence on the web.", "labels": [], "entities": []}, {"text": "We refer to this task as Knowledge Base Discovery (KBD) and introduce a supervised classification setting for endpoint discovery leveraging information from inbound links and silver standard mention annotation.", "labels": [], "entities": [{"text": "Knowledge Base Discovery (KBD)", "start_pos": 25, "end_pos": 55, "type": "TASK", "confidence": 0.6350932121276855}, {"text": "endpoint discovery leveraging information", "start_pos": 110, "end_pos": 151, "type": "TASK", "confidence": 0.8032298758625984}]}, {"text": "We evaluate performance for this task using crowdsourced judgements over a held outset of candidate URIs.", "labels": [], "entities": []}, {"text": "This paper introduces web KBs extracted from a collection of news articles and we plan to release evaluation data, code and crowdsourced annotation.", "labels": [], "entities": []}, {"text": "While our initial extraction is not perfect, we propose that web KBs make for compelling endpoints against which to disambiguate mentions of less prominent entities.", "labels": [], "entities": []}, {"text": "Furthermore, we believe that a mixture of domain-specific KBs can assist entity linking to traditional KBs.", "labels": [], "entities": []}], "datasetContent": [{"text": "We validate the KBD approach described above on an internal corpus of links collected from 2,948,841 web news articles.", "labels": [], "entities": []}, {"text": "We leverage named entity recognition to identify likely entity references as link anchors that align to predicted mentions for person, location and organisation entity types.", "labels": [], "entities": [{"text": "named entity recognition", "start_pos": 12, "end_pos": 36, "type": "TASK", "confidence": 0.6670942107836405}]}, {"text": "And we convert target URIs to endpoint patterns by normalising to lowercase, removing protocol (e.g., http) and domain (e.g., sfgate.com), and removing entity identifiers (e.g., query=\"Elon+Musk\").", "labels": [], "entities": []}, {"text": "includes statistics of the full link corpus (Total) and the NER-aligned subset (Aligned).", "labels": [], "entities": []}, {"text": "The full corpus includes a total of 14,462,659 links.", "labels": [], "entities": []}, {"text": "3,436,033 of these align to NER mentions, yielding 1,029,405 candidate entity endpoints across 309,182 URI patterns.", "labels": [], "entities": []}, {"text": "We select a threshold on held out instances from our development split..2 shows the precisionrecall tradeoff across possible threshold values.", "labels": [], "entities": [{"text": "precisionrecall", "start_pos": 84, "end_pos": 99, "type": "METRIC", "confidence": 0.9934666752815247}]}, {"text": "We select a threshold of P (m|u) >= 0.825 here as this maximises F-score at 0.64 and is in the middle of the threshold range.", "labels": [], "entities": [{"text": "P", "start_pos": 25, "end_pos": 26, "type": "METRIC", "confidence": 0.9766470193862915}, {"text": "F-score", "start_pos": 65, "end_pos": 72, "type": "METRIC", "confidence": 0.9990447163581848}]}, {"text": "shows a sample of URI patterns predicted by this model and the number of corresponding entity endpoints discovered from the seed corpus.", "labels": [], "entities": []}, {"text": "Encouragingly, apart from general news, we see two of the behaviour categories from Section 3: domain-specific news topic pages from Sports Illustrated and Cycling News, and professional profile pages like LinkedIn and legal web sites, which can inform disambiguation models for long-tail entities.", "labels": [], "entities": []}, {"text": "To evaluate how well our model for P (m|u) estimates P (e, m|u), we construct a corpus of humanannotated endpoint URIs.", "labels": [], "entities": []}, {"text": "While it would be possible to randomly sample URIs, this would give us a highly imbalanced set with very few positive instances.", "labels": [], "entities": []}, {"text": "We design a crowd task to collect pairwise identity judgements within clusters of candidate coreference pairs.", "labels": [], "entities": []}, {"text": "To build clusters, we retrain our model over combined silver standard data (train + test) and use it to collect endpoints from the complete seed corpus with classification confidence above our threshold.", "labels": [], "entities": []}, {"text": "We use the anchor-URI graph to build candidate clusters from randomly selected seed URIs by enumerating inlink anchors and then collecting all target URIs linked to from these anchors.", "labels": [], "entities": []}, {"text": "We repeat this a second time to create candidate clusters based on various names for the seed URI to help account for synonymy.", "labels": [], "entities": []}, {"text": "Ambiguity means clusters also include endpoints corresponding to different underlying entities that share a name with the seed entity.", "labels": [], "entities": [{"text": "Ambiguity", "start_pos": 0, "end_pos": 9, "type": "METRIC", "confidence": 0.9179031848907471}]}, {"text": "Finally, we randomly select a pair of URIs from the cluster for evaluation.", "labels": [], "entities": []}, {"text": "We post 500 URI pairs to Crowdflower 3 and ask three workers to judge whether each endpoint is an entity page.", "labels": [], "entities": []}, {"text": "We also ask whether they refer to the same underlying entity.", "labels": [], "entities": []}, {"text": "The evaluation shows that 71.2% of the 1,000 endpoints are confirmed as entities.", "labels": [], "entities": []}, {"text": "Of the 277 pairs that include two true endpoints, 70.8% are judged as coreferent providing reasonably balanced data for evaluating future endpoint reconciliation experiments.", "labels": [], "entities": [{"text": "endpoint reconciliation", "start_pos": 138, "end_pos": 161, "type": "TASK", "confidence": 0.7189056724309921}]}, {"text": "Finally, we estimate the extent to which our approach can be used to extend knowledge beyond standard Wikipedia KBs.", "labels": [], "entities": []}, {"text": "We sample 100 endpoints validated in the crowd annotation and search fora corresponding Wikipedia page.", "labels": [], "entities": []}, {"text": "20% of endpoints represent entities that are not in Wikipedia.", "labels": [], "entities": []}, {"text": "This suggests that the approach does discover useful knowledge further down the tail of notability.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Statistics of the corpus in millions. The first column", "labels": [], "entities": []}]}