{"title": [{"text": "Improving Fluency in Narrative Text Generation With Grammatical Transformations and Probabilistic Parsing", "labels": [], "entities": [{"text": "Narrative Text Generation", "start_pos": 21, "end_pos": 46, "type": "TASK", "confidence": 0.799106220404307}]}], "abstractContent": [{"text": "In research on automatic generation of narrative text, story events are often formally represented as a causal graph.", "labels": [], "entities": [{"text": "automatic generation of narrative text", "start_pos": 15, "end_pos": 53, "type": "TASK", "confidence": 0.8380456864833832}]}, {"text": "When serializing and realizing this causal graph as natural language text, simple approaches produce cumbersome sentences with repetitive syntactic structure, e.g. long chains of \"because\" clauses.", "labels": [], "entities": []}, {"text": "In our research, we show that the fluency of narrative text generated from causal graphs can be improved by applying rule-based grammatical transformations to generate many sentence variations with equivalent semantics, then selecting the variation that has the highest probability using a probabilistic syntactic parser.", "labels": [], "entities": []}, {"text": "We evaluate our approach by generating narrative text from causal graphs that encode 100 brief stories involving the same three characters , based on a classic film of experimental social psychology.", "labels": [], "entities": []}, {"text": "Crowdsourced workers judged the writing quality of texts generated with ranked transformations as significantly higher than those without, and not significantly lower than human-authored narratives of the same situations.", "labels": [], "entities": []}], "introductionContent": [], "datasetContent": [{"text": "We evaluated the quality of our narrative NLG approach by soliciting ratings of writing quality from crowdsourced annotators, comparing the output of our system, our baseline NLG system, and original human-authored narratives for each of the 100 questions in the Triangle-COPA question set.", "labels": [], "entities": [{"text": "Triangle-COPA question set", "start_pos": 263, "end_pos": 289, "type": "DATASET", "confidence": 0.8451838493347168}]}, {"text": "In each annotation task, the annotator watched the short movie associated with a given question, read the text associated with the question randomly selected from our three conditions, then rated the writing quality of the text on a 5-point Likert scale -from (1) Horrible gibberish to (5) Excellent, professional quality.", "labels": [], "entities": []}, {"text": "In addition, we asked raters to answer a factual multiplechoice question about each movie to validate their effort on this crowdsourced task.", "labels": [], "entities": []}, {"text": "After filtering annotators who failed this validation task, we analyzed 717 ratings evenly distributed across the three conditions and 100 questions, shown in.", "labels": [], "entities": []}, {"text": "Significant gains in quality ratings were observed for our approach over the Baseline NLG system.", "labels": [], "entities": [{"text": "Baseline NLG system", "start_pos": 77, "end_pos": 96, "type": "DATASET", "confidence": 0.8759137392044067}]}, {"text": "The differences observed between human-authored narratives and our system were not significant.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1. Signif- icant gains in quality ratings were observed for our  approach over the Baseline NLG system. The differ- ences observed between human-authored narratives  and our system were not significant.", "labels": [], "entities": [{"text": "Baseline NLG system", "start_pos": 90, "end_pos": 109, "type": "DATASET", "confidence": 0.8258362213770548}]}, {"text": " Table 1: Ratings of writing quality. (*) significant at p<0.05", "labels": [], "entities": []}]}