{"title": [{"text": "Coreference Resolution for the Basque Language with BART", "labels": [], "entities": [{"text": "Coreference Resolution", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.9351287186145782}, {"text": "BART", "start_pos": 52, "end_pos": 56, "type": "TASK", "confidence": 0.7951174378395081}]}], "abstractContent": [{"text": "In this paper we present our work on Coref-erence Resolution in Basque, a unique language which poses interesting challenges for the problem of coreference.", "labels": [], "entities": [{"text": "Coref-erence Resolution", "start_pos": 37, "end_pos": 60, "type": "TASK", "confidence": 0.8625733554363251}]}, {"text": "We explain how we extend the coreference resolution toolkit, BART, in order to enable it to process Basque.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 29, "end_pos": 51, "type": "TASK", "confidence": 0.8116694092750549}, {"text": "BART", "start_pos": 61, "end_pos": 65, "type": "METRIC", "confidence": 0.8324915766716003}]}, {"text": "Then we run four different experiments showing both a significant improvement by extending a baseline feature set and the effect of calculating performance of hand-parsed mentions vs. automatically parsed mentions.", "labels": [], "entities": []}, {"text": "Finally , we discuss some key characteristics of Basque which make it particularly challenging for coreference and draw a road map for future work.", "labels": [], "entities": [{"text": "coreference", "start_pos": 99, "end_pos": 110, "type": "TASK", "confidence": 0.9770978689193726}]}], "introductionContent": [{"text": "Basque is a language spoken by nearly three quarters of a million people, most of which live in the Basque country, a region spanning parts of northern Spain and southwestern France.", "labels": [], "entities": []}, {"text": "One of the most surprising findings about the Basque language is that it cannot be linked with any of its Indo-European neighbours in Europe and, hence, has been classified as a language isolate.", "labels": [], "entities": []}, {"text": "It differs considerably in grammar from the languages spoken in surrounding regions.", "labels": [], "entities": []}, {"text": "It is an agglutinative, head-final, pro-drop, free-word order language.", "labels": [], "entities": []}, {"text": "Naturally, the Basque language has also inspired a lot of work in Computational Linguistics with tools for automatically processing it becoming increasingly available (.", "labels": [], "entities": [{"text": "Computational Linguistics", "start_pos": 66, "end_pos": 91, "type": "TASK", "confidence": 0.7985727190971375}]}, {"text": "However, as it is the case with most less-resourced languages, there are tools for the core processing levels, such as tokenisation, sentence splitting, morphological analysis, syntactic parsing/chunking, but much less so for higher semantic levels required in end goal applications such as Question Answering), Text Summarisation ( or Information Extraction.", "labels": [], "entities": [{"text": "sentence splitting", "start_pos": 133, "end_pos": 151, "type": "TASK", "confidence": 0.7362531274557114}, {"text": "syntactic parsing/chunking", "start_pos": 177, "end_pos": 203, "type": "TASK", "confidence": 0.7808855772018433}, {"text": "Question Answering", "start_pos": 291, "end_pos": 309, "type": "TASK", "confidence": 0.8350725471973419}, {"text": "Text Summarisation", "start_pos": 312, "end_pos": 330, "type": "TASK", "confidence": 0.8312843441963196}, {"text": "Information Extraction", "start_pos": 336, "end_pos": 358, "type": "TASK", "confidence": 0.7074971795082092}]}, {"text": "One such intermediate problem which has been underresearched for Basque, and hence, no readily usable tools are publicly available yet, is that of Coreference Resolution (.", "labels": [], "entities": [{"text": "Coreference Resolution", "start_pos": 147, "end_pos": 169, "type": "TASK", "confidence": 0.9188527762889862}]}, {"text": "However, preliminary work on Coreference for Basque is starting to emerge, and in this paper we describe our work on extending the coreference resolution toolkit, BART) to the Basque language.", "labels": [], "entities": [{"text": "Coreference for Basque", "start_pos": 29, "end_pos": 51, "type": "TASK", "confidence": 0.8310046394666036}, {"text": "coreference resolution toolkit", "start_pos": 131, "end_pos": 161, "type": "TASK", "confidence": 0.8385017911593119}, {"text": "BART", "start_pos": 163, "end_pos": 167, "type": "METRIC", "confidence": 0.8842805624008179}]}, {"text": "BART benefits from an open architecture and provides a mechanism through language plugins which makes it particularly suitable for adaptations to new languages, and it attained good performance in the shared task on Multilingual Coreference at CoNLL 2012 ().", "labels": [], "entities": [{"text": "BART", "start_pos": 0, "end_pos": 4, "type": "TASK", "confidence": 0.4668368399143219}, {"text": "CoNLL 2012", "start_pos": 244, "end_pos": 254, "type": "DATASET", "confidence": 0.7178307473659515}]}, {"text": "For our experiments we use the EPEC corpus annotated for coreference () and we run experiments across two dimensions.", "labels": [], "entities": [{"text": "EPEC corpus annotated", "start_pos": 31, "end_pos": 52, "type": "DATASET", "confidence": 0.9537070790926615}, {"text": "coreference", "start_pos": 57, "end_pos": 68, "type": "TASK", "confidence": 0.9045607447624207}]}, {"text": "First, we use a baseline model based on () vs. a model that includes extra features reliably extracted for Basque with the tools at hand.", "labels": [], "entities": []}, {"text": "Second, we measure performance on hand-parsed mentions vs. performance on automatically parsed mentions which illustrates the effect of pre-processing quality on the end results.", "labels": [], "entities": []}, {"text": "One of the key challenges that the Basque language introduces for Coreference is that it uses a genderless system for pronouns.", "labels": [], "entities": [{"text": "Coreference", "start_pos": 66, "end_pos": 77, "type": "TASK", "confidence": 0.9542255997657776}]}, {"text": "In our experiments we look in more depth around this issue and show the challenges it presents as well as suggest viable solutions to model it with machine learning techniques.", "labels": [], "entities": []}, {"text": "The remainder of this paper is organised as follows: Section \u00a72 briefly surveys related work, Section \u00a73 gives details of EPEC, a coreference corpus, Section \u00a74 describes the extension of BART to Basque, Section \u00a75 presents results and provides a discussion on the challenges for coreference in Basque, and towards the end we draw conclusions and pointers to future work.", "labels": [], "entities": [{"text": "BART", "start_pos": 188, "end_pos": 192, "type": "TASK", "confidence": 0.7773380875587463}, {"text": "coreference in Basque", "start_pos": 280, "end_pos": 301, "type": "TASK", "confidence": 0.8355587919553121}]}], "datasetContent": [{"text": "We have tested the two models presented in Subsection 4.3 in two different environments.", "labels": [], "entities": []}, {"text": "In the first one automatically detected mentions are provided to the models and in the second one the mentions are gold.", "labels": [], "entities": []}, {"text": "The metrics used in our evaluations are MUC (Vilain et al., 1995), B 3 (Bagga and   In the case of automatically detected mentions, Basque model outperforms the Soon baseline model Basque with BART, at this stage we were unable to incorporate all features in the original () model.", "labels": [], "entities": [{"text": "MUC", "start_pos": 40, "end_pos": 43, "type": "METRIC", "confidence": 0.9904679656028748}, {"text": "B 3", "start_pos": 67, "end_pos": 70, "type": "METRIC", "confidence": 0.9620770215988159}, {"text": "BART", "start_pos": 193, "end_pos": 197, "type": "METRIC", "confidence": 0.8881641030311584}]}, {"text": "We maintain this feature with the aim of not modifying the () model.", "labels": [], "entities": []}, {"text": "When gold mentions are used the Basque model also outperforms the Soon baseline according to all the metrics, except B 3 . The official CoNLL metric is outperformed by 5.61 points.", "labels": [], "entities": [{"text": "Soon baseline", "start_pos": 66, "end_pos": 79, "type": "DATASET", "confidence": 0.6761834025382996}, {"text": "CoNLL metric", "start_pos": 136, "end_pos": 148, "type": "DATASET", "confidence": 0.6557281613349915}]}, {"text": "Comparing the results obtained when gold mentions are used with those obtained with the automatic mentions, there is a considerable difference.", "labels": [], "entities": []}, {"text": "CoNLL F 1 of Soon baseline is 50.05 when automatic mentions are provided, while providing gold mentions this value raises to 66.81, an increase of 16.76.", "labels": [], "entities": [{"text": "CoNLL F 1", "start_pos": 0, "end_pos": 9, "type": "METRIC", "confidence": 0.7363141576449076}, {"text": "Soon baseline", "start_pos": 13, "end_pos": 26, "type": "DATASET", "confidence": 0.7915521562099457}]}, {"text": "Similar increase in CoNLL F 1 happens with the Basque model.", "labels": [], "entities": [{"text": "CoNLL F 1", "start_pos": 20, "end_pos": 29, "type": "METRIC", "confidence": 0.8489658435185751}, {"text": "Basque model", "start_pos": 47, "end_pos": 59, "type": "DATASET", "confidence": 0.9433860778808594}]}, {"text": "In this case, there is an increase The CoNLL metric is the arithmetic mean of MUC, B 3 and CEAFe metrics. of 18.7 points, from 53.72 with automatic mentions to 72.42 when gold mentions are used.", "labels": [], "entities": [{"text": "CoNLL metric", "start_pos": 39, "end_pos": 51, "type": "METRIC", "confidence": 0.9024693965911865}, {"text": "MUC, B 3 and CEAFe metrics.", "start_pos": 78, "end_pos": 105, "type": "DATASET", "confidence": 0.7050887261118207}]}, {"text": "We also had a look at the pronoun resolution performance alone, but only MUC scores on automatic mentions as the CoNLL scorer does not provide a break-down of scores per anaphor type, and there was a small gain in performance from the Soon baseline to the Basque model from F 1 = 27.4 to F 1 = 33.0, respectively.", "labels": [], "entities": [{"text": "pronoun resolution", "start_pos": 26, "end_pos": 44, "type": "TASK", "confidence": 0.6701306402683258}, {"text": "MUC", "start_pos": 73, "end_pos": 76, "type": "METRIC", "confidence": 0.9752402305603027}, {"text": "CoNLL scorer", "start_pos": 113, "end_pos": 125, "type": "DATASET", "confidence": 0.8541649281978607}, {"text": "Soon baseline", "start_pos": 235, "end_pos": 248, "type": "DATASET", "confidence": 0.9224565625190735}, {"text": "F 1", "start_pos": 274, "end_pos": 277, "type": "METRIC", "confidence": 0.9733425080776215}, {"text": "F 1", "start_pos": 288, "end_pos": 291, "type": "METRIC", "confidence": 0.9541378021240234}]}, {"text": "The gain is due mostly to higher precision, suggesting the additional features in the Basque model help discriminate better erroneously resolved pronouns in the baseline model, however, more work will need to be devoted to improving recall, which is particularly challenging in the case of Basque due to the lack of gender in the Basque pronoun system.", "labels": [], "entities": [{"text": "precision", "start_pos": 33, "end_pos": 42, "type": "METRIC", "confidence": 0.9992363452911377}, {"text": "recall", "start_pos": 233, "end_pos": 239, "type": "METRIC", "confidence": 0.998759388923645}]}], "tableCaptions": [{"text": " Table 1: EPEC-coref corpus division information.", "labels": [], "entities": [{"text": "EPEC-coref corpus division information", "start_pos": 10, "end_pos": 48, "type": "DATASET", "confidence": 0.8271459639072418}]}, {"text": " Table 3: Scores with automatic mentions.", "labels": [], "entities": []}, {"text": " Table 4: Scores with gold mentions.", "labels": [], "entities": []}]}