{"title": [{"text": "Faster decoding for subword level Phrase-based SMT between related languages", "labels": [], "entities": [{"text": "Phrase-based SMT between related languages", "start_pos": 34, "end_pos": 76, "type": "TASK", "confidence": 0.8545913577079773}]}], "abstractContent": [{"text": "A common and effective way to train translation systems between related languages is to consider sub-word level basic units.", "labels": [], "entities": []}, {"text": "However, this increases the length of the sentences resulting in increased decoding time.", "labels": [], "entities": []}, {"text": "The increase in length is also impacted by the specific choice of data format for representing the sentences as subwords.", "labels": [], "entities": [{"text": "length", "start_pos": 16, "end_pos": 22, "type": "METRIC", "confidence": 0.9539661407470703}]}, {"text": "Ina phrase-based SMT framework, we investigate different choices of decoder parameters as well as data format and their impact on decoding time and translation accuracy.", "labels": [], "entities": [{"text": "SMT", "start_pos": 17, "end_pos": 20, "type": "TASK", "confidence": 0.9216326475143433}, {"text": "accuracy", "start_pos": 160, "end_pos": 168, "type": "METRIC", "confidence": 0.8581328392028809}]}, {"text": "We suggest best options for these settings that significantly improve decoding time with little impact on the translation accuracy.", "labels": [], "entities": [{"text": "translation", "start_pos": 110, "end_pos": 121, "type": "TASK", "confidence": 0.9505237936973572}, {"text": "accuracy", "start_pos": 122, "end_pos": 130, "type": "METRIC", "confidence": 0.8504092693328857}]}], "introductionContent": [{"text": "Related languages are those that exhibit lexical and structural similarities on account of sharing a common ancestry or being in contact fora long period of time ( . Examples of languages related by common ancestry are Slavic and Indo-Aryan languages.", "labels": [], "entities": []}, {"text": "Prolonged contact leads to convergence of linguistic properties even if the languages are not related by ancestry and could lead to the formation of linguistic areas).", "labels": [], "entities": []}, {"text": "Examples of such linguistic areas are the Indian subcontinent), Balkan and Standard Average European) linguistic areas.", "labels": [], "entities": []}, {"text": "Both forms of language relatedness lead to related languages sharing vocabulary and structural features.", "labels": [], "entities": []}, {"text": "There is substantial government, commercial and cultural communication among people speaking related languages (Europe, India and South-East Asia being prominent examples and linguistic regions in Africa possibly in the future).", "labels": [], "entities": []}, {"text": "As these regions integrate more closely and move to a digital society, translation between related languages is becoming an important requirement.", "labels": [], "entities": [{"text": "translation between related languages", "start_pos": 71, "end_pos": 108, "type": "TASK", "confidence": 0.8819490820169449}]}, {"text": "In addition, translation to/from related languages to a lingua franca like English is also very important.", "labels": [], "entities": []}, {"text": "However, in spite of significant communication between people speaking related languages, most of these languages have few parallel corpora resources.", "labels": [], "entities": []}, {"text": "It is therefore important to leverage the relatedness of these languages to build good-quality statistical machine translation (SMT) systems given the lack of parallel corpora.", "labels": [], "entities": [{"text": "statistical machine translation (SMT)", "start_pos": 95, "end_pos": 132, "type": "TASK", "confidence": 0.7831212679545084}]}, {"text": "Modelling the lexical similarity among related languages is the key to building good-quality SMT systems with limited parallel corpora.", "labels": [], "entities": [{"text": "SMT", "start_pos": 93, "end_pos": 96, "type": "TASK", "confidence": 0.991526186466217}]}, {"text": "Lexical similarity implies that the languages share many words with the similar form (spelling/pronunciation) and meaning e.g. blindness is andhapana in Hindi, aandhaLepaNaa in Marathi.", "labels": [], "entities": []}, {"text": "These words could be cognates, lateral borrowings or loan words from other languages.", "labels": [], "entities": []}, {"text": "Sub-word level transformations are an effective way for translation of such shared words.", "labels": [], "entities": [{"text": "translation", "start_pos": 56, "end_pos": 67, "type": "TASK", "confidence": 0.9669585227966309}]}, {"text": "Using subwords as basic units of translation has been shown to be effective in improving translation quality with limited parallel corpora.", "labels": [], "entities": []}, {"text": "Subword units like character (), character n-gram ( and orthographic syllables  have been explored and have been shown to improve translation quality to varying degrees.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section, we describe the language pairs and datasets used, the details of our experiments and evaluation methodology.", "labels": [], "entities": []}, {"text": "We experimented with four language pairs (Bengali-Hindi, Malayalam-Hindi, Hindi-Malayalam and Telugu-Malayalam).", "labels": [], "entities": []}, {"text": "Telugu and Malayalam belong to the Dravidian language family which are agglutinative.", "labels": [], "entities": []}, {"text": "Bengali and Hindi are Indo-Aryan languages with a relatively poor morphology.", "labels": [], "entities": []}, {"text": "The language pairs chosen cover different combinations of morphological complexity between source and target languages.", "labels": [], "entities": []}, {"text": "We used the multilingual ILCI corpus for our experiments (Jha, 2012), consisting of sentences from tourism and health domains.", "labels": [], "entities": [{"text": "ILCI corpus", "start_pos": 25, "end_pos": 36, "type": "DATASET", "confidence": 0.7271677404642105}]}, {"text": "The data split is as follows -training: 44,777, tuning: 1000, test: 500 sentences.", "labels": [], "entities": [{"text": "training", "start_pos": 30, "end_pos": 38, "type": "METRIC", "confidence": 0.9619834423065186}, {"text": "tuning", "start_pos": 48, "end_pos": 54, "type": "METRIC", "confidence": 0.9774328470230103}]}, {"text": "We use BLEU () for evaluating translation accuracy.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 7, "end_pos": 11, "type": "METRIC", "confidence": 0.9988465309143066}, {"text": "translation", "start_pos": 30, "end_pos": 41, "type": "TASK", "confidence": 0.9445094466209412}, {"text": "accuracy", "start_pos": 42, "end_pos": 50, "type": "METRIC", "confidence": 0.8067132830619812}]}, {"text": "We use the sum of user and system time minus the time for loading the phrase table (all reported by Moses) to determine the time taken for decoding the test set.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 3: Translation accuracy and Relative decoding time for character level translation using different  decoding methods and parameters. Relative decoding time is indicated as a multiple of word-level decod- ing time. Translation accuracy and decode time per sentence for word-level decoding (in milliseconds)  is shown on the last line for comparison.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 22, "end_pos": 30, "type": "METRIC", "confidence": 0.9222949147224426}, {"text": "character level translation", "start_pos": 62, "end_pos": 89, "type": "TASK", "confidence": 0.6233064830303192}, {"text": "Relative decoding time", "start_pos": 140, "end_pos": 162, "type": "METRIC", "confidence": 0.8381927609443665}, {"text": "accuracy", "start_pos": 233, "end_pos": 241, "type": "METRIC", "confidence": 0.8863574266433716}]}, {"text": " Table 4: Translation accuracy and Relative decoding time for orthographic syllable level translation using  different data formats. Relative decoding time is indicated as a multiple of word-level decoding time.  Translation accuracy and decode time per sentence (in milliseconds) for word-level decoding is shown  on the last line for comparison.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 22, "end_pos": 30, "type": "METRIC", "confidence": 0.9507883787155151}, {"text": "orthographic syllable level translation", "start_pos": 62, "end_pos": 101, "type": "TASK", "confidence": 0.6130323484539986}, {"text": "Relative decoding time", "start_pos": 133, "end_pos": 155, "type": "METRIC", "confidence": 0.825772762298584}, {"text": "accuracy", "start_pos": 225, "end_pos": 233, "type": "METRIC", "confidence": 0.9088629484176636}]}]}