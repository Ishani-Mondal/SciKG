{"title": [{"text": "\"Look, some green circles!\": Learning to quantify from images *", "labels": [], "entities": []}], "abstractContent": [{"text": "In this paper, we investigate whether a neural network model can learn the meaning of natural language quantifiers (no, some and all) from their use in visual contexts.", "labels": [], "entities": []}, {"text": "We show that memory networks perform well in this task, and that explicit counting is not necessary to the system's performance, supporting psycholinguistic evidence on the acquisition of quantifiers.", "labels": [], "entities": []}], "introductionContent": [{"text": "Multimodal representations of meaning have recently gained a lot of attention in the computational semantics literature.", "labels": [], "entities": []}, {"text": "It has been shown, in particular, that the meaning of content words can be modelled in a cognitively -and even neuroscientifically -plausible way by learning representations from both the linguistic and visual contexts in which a lexical item has been observed (.", "labels": [], "entities": []}, {"text": "Such work has been crucial to advance the development of both a) a computational theory of meaning rooted in situated language use, as pursued by the field of Distributional Semantics) and b) vision-based applications such as image caption generation and visual question answering (, going towards genuine image understanding.", "labels": [], "entities": [{"text": "image caption generation", "start_pos": 226, "end_pos": 250, "type": "TASK", "confidence": 0.8633615175882975}, {"text": "visual question answering", "start_pos": 255, "end_pos": 280, "type": "TASK", "confidence": 0.626541664203008}]}, {"text": "Both distributional semantics and visual applications, however, struggle with providing plausible representations for function words.", "labels": [], "entities": []}, {"text": "This has theoretical and practical consequences.", "labels": [], "entities": []}, {"text": "On the theoretical side, it simply reduces the explanatory power of the model, in particular with respect to accounting for the compositionality of language.", "labels": [], "entities": []}, {"text": "On the practical side, current vision systems are forced to rely on background language models instead of truly interpreting the words of a query or caption in the given visual context.", "labels": [], "entities": []}, {"text": "As a consequence, if e.g. the sentence I see some cats is more frequent than I see no cat, language modelbased applications will tend to generate the first even when the second would be more appropriate.", "labels": [], "entities": []}, {"text": "In this paper, we start remedying this situation by investigating one important class of function words: natural language quantifiers (e.g. no, some, all).", "labels": [], "entities": []}, {"text": "Quantifiers are an emerging field of research in distributional semantics and, so far, haven't been studied in relation with visual data and grounding.", "labels": [], "entities": []}, {"text": "We make a first step in this direction by asking whether the meaning of quantifier words can be learnt by observing their use in the presence of visual information.", "labels": [], "entities": []}, {"text": "We observe that in grounded contexts, children learn to make quantification estimates before being able to count), using their Approximate Number Sense (ANS).", "labels": [], "entities": [{"text": "Approximate Number Sense (ANS)", "start_pos": 127, "end_pos": 157, "type": "METRIC", "confidence": 0.9542713562647501}]}, {"text": "We ask whether Neural Networks (NNs) can model this ability, and we evaluate several neural network models, with and without numerical processing ability, on the task of matching a non-cardinal to a referent in a grounded situation.", "labels": [], "entities": []}, {"text": "NNs have been shown to perform well in tasks related to quantification, from counting to simulating the ANS., for instance, explore the task of counting occurrences of an object in an image using convolutional NNs, and demonstrate that object identification can be learnt as a surrogate of counting.", "labels": [], "entities": [{"text": "object identification", "start_pos": 236, "end_pos": 257, "type": "TASK", "confidence": 0.7293425053358078}]}, {"text": "show that the ANS emerges as a statistical property of images in deep networks that learn a hi-erarchical generative model of visual input.", "labels": [], "entities": [{"text": "ANS", "start_pos": 14, "end_pos": 17, "type": "TASK", "confidence": 0.9258547425270081}]}, {"text": "To our knowledge, however, there hasn't been any attempt so far to model the use of non-cardinals (no, some, all) in a visual quantification task.", "labels": [], "entities": []}, {"text": "Our paper builds on previous work by proposing a NN model of quantifier terms which can be related to the acquisition of the ANS, with two main contributions: First, we propose a novel experimental setup in which, given a set of objects with different properties (e.g., circles of different colors), the model learns to apply the correct quantifier to the situation (e.g. no, some, all circles are red).", "labels": [], "entities": [{"text": "ANS", "start_pos": 125, "end_pos": 128, "type": "TASK", "confidence": 0.5300584435462952}]}, {"text": "Second, we show that, as observed in children, our best model does not need to be able to count in order to quantify.", "labels": [], "entities": []}], "datasetContent": [{"text": "Linguistic quantifiers and their logical properties have been a major object of study in the field of formal semantics since its inception.", "labels": [], "entities": []}, {"text": "It is posited that, in an example such as some circles are green, the quantifier (some) expresses a relation between a domain restrictor (circles) and the quantifier's scope (are green).", "labels": [], "entities": []}, {"text": "In this paper, we fix the domain and focus on the scope: We ask whether, given an image with objects from a single domain (circles), a model can learn to globally quantify the objects with a certain property, deciding whether all, some, or no circles have that property.", "labels": [], "entities": []}, {"text": "Here, we use color as an example property to quantify over.", "labels": [], "entities": []}, {"text": "In order to focus on the quantification task, barring out any effect from data preprocessing, we create an artificial dataset with clear visual properties (see below).", "labels": [], "entities": []}, {"text": "Our dataset consists of images with 1 to 16 circles of 15 different colors, and we generate all possible combinations of different numbers of circles (from 1 to 16) with all possible combinations of colors.", "labels": [], "entities": []}, {"text": "presents one of the images in the dataset.", "labels": [], "entities": []}, {"text": "In order to avoid effects from visual pre-processing, the dataset is presented to the quantification network with (automatically produced) gold standard information about image segmentation and object identification.", "labels": [], "entities": [{"text": "image segmentation", "start_pos": 171, "end_pos": 189, "type": "TASK", "confidence": 0.7324261665344238}, {"text": "object identification", "start_pos": 194, "end_pos": 215, "type": "TASK", "confidence": 0.7560213506221771}]}, {"text": "That is, the network knows where objects are, and what they are (circles of different, easily identifiable colors).", "labels": [], "entities": []}, {"text": "Concretely, we represent each picture as a set of up to 16 circles (e.g. ure 1) placed in 16 fixed image cells.", "labels": [], "entities": []}, {"text": "Furthermore, we associate each of the circle-color combination with real-valued vectors of dimensionality 20 that are normalized to unit norm.", "labels": [], "entities": []}, {"text": "All circles are identical in shape and size, so the differences observable in the vector representations can betaken to express the color property of the objects.", "labels": [], "entities": []}, {"text": "We ensure that the dataset does not include 'confusable' objects by further constraining the vectors to have low pairwise similarity.", "labels": [], "entities": []}, {"text": "On the other hand, to prevent overfitting, we add a small amount of noise to all vectors, generated for each dimension from a Gaussian distribution with mean 0 and variance 1/5 of the original variance of that dimension.", "labels": [], "entities": []}, {"text": "Intuitively, the Gaussian noise simulates natural variations in a given property, e.g., two tennis balls being of slightly different shades of yellow.", "labels": [], "entities": []}, {"text": "This is applied to both training and test data.", "labels": [], "entities": []}, {"text": "Finally, our images may contain empty cells, viz.", "labels": [], "entities": []}, {"text": "parts of the image with no object in it (e.g., in there are 5 empty cells.)", "labels": [], "entities": []}, {"text": "These are similarly represented by a vector, randomly generated so that it be orthogonal to all the other object vectors.", "labels": [], "entities": []}, {"text": "Queries Each image in the dataset is associated with a query, i.e., the property we want to quantify over, and the task of the model is to associate the correct quantifier with the query for the image.", "labels": [], "entities": []}, {"text": "For instance, the query associated to the image in is green and the correct quantifier is some.", "labels": [], "entities": []}, {"text": "Some encodes \"at least one but not all circles have color X\", all encodes \"all circles have color X\" and no \"no circle has color X\".", "labels": [], "entities": []}, {"text": "Our dataset contains 5K <image, query, quantifier> datapoints split equally amongst the three quantifiers, 3 which will be used to evaluate our models.", "labels": [], "entities": []}, {"text": "We randomly divide the 5K data points into training, validation and test set (70%, 10% and 20%).", "labels": [], "entities": []}, {"text": "We test the models in 3 experimental setups.", "labels": [], "entities": []}, {"text": "The first setup, familiar, is the simplest, and tests whether models are able to quantify previously observed (\"familiar\") colors and quantities.", "labels": [], "entities": []}, {"text": "In the unseen quantities setup, we create training and test sets so that there is no overlap with respect to the number of objects in the image: 4, 9 or 13 objects are used attest time and all other quantities at training/validation time (i.e.,).", "labels": [], "entities": []}, {"text": "Finally, in the unseen colors setup, we make sure training and test sets differ with respect to objects' color: The models are trained/validated on  10 colors and tested on 5 additional, unseen colors.", "labels": [], "entities": []}, {"text": "We expect that the use of the gist in our model, which implements global quantification over objects of a certain property, will allow it to generalize well when tested against unseen quantities.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Model accuracies (in %).", "labels": [], "entities": [{"text": "accuracies", "start_pos": 16, "end_pos": 26, "type": "METRIC", "confidence": 0.5633050203323364}]}]}