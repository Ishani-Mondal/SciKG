{"title": [], "abstractContent": [{"text": "In this paper, we present our new experimental system of merging dependency representations of two parallel sentences into one dependency tree.", "labels": [], "entities": []}, {"text": "All the inner nodes in dependency tree represent source-target pairs of words, the extra words are inform of leaf nodes.", "labels": [], "entities": []}, {"text": "We use Universal Dependencies annotation style, in which the function words, whose usage often differs between languages, are annotated as leaves.", "labels": [], "entities": []}, {"text": "The parallel tree-bank is parsed in minimally supervised way.", "labels": [], "entities": []}, {"text": "Unaligned words are there automatically pushed to leaves.", "labels": [], "entities": []}, {"text": "We present a simple translation system trained on such merged trees and evaluate it in WMT 2016 English-to-Czech and Czech-to-English translation task.", "labels": [], "entities": [{"text": "WMT", "start_pos": 87, "end_pos": 90, "type": "DATASET", "confidence": 0.7561535835266113}, {"text": "Czech-to-English translation", "start_pos": 117, "end_pos": 145, "type": "TASK", "confidence": 0.5996395796537399}]}, {"text": "Even though the model is so far very simple and no language model and word-reordering model were used, the Czech-to-English variant reached similar BLEU score as another established tree-based system.", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 148, "end_pos": 158, "type": "METRIC", "confidence": 0.9824880361557007}]}], "introductionContent": [{"text": "Tree-based machine translation systems () are alternatives to the leading phrasebased MT systems () and newly very progressive neural MT systems (.", "labels": [], "entities": [{"text": "Tree-based machine translation", "start_pos": 0, "end_pos": 30, "type": "TASK", "confidence": 0.6171413461367289}]}, {"text": "Our approach aims to produce bilingual dependency trees, in which both source and target sentences are encoded together.", "labels": [], "entities": []}, {"text": "We adapt the Universal Dependencies annotation style, in which the functional words 1 are in the leaf nodes and therefore the grammatical differences between the languages does not much affect the common dependency structure.", "labels": [], "entities": []}, {"text": "We were partially inspired by the Stochastic inversion transduction grammars.", "labels": [], "entities": [{"text": "Stochastic inversion transduction grammars", "start_pos": 34, "end_pos": 76, "type": "TASK", "confidence": 0.6609918773174286}]}, {"text": "Our merged dependency trees are defined in Section 2.", "labels": [], "entities": []}, {"text": "The data we use and necessary preprocessing is in Section 3.", "labels": [], "entities": []}, {"text": "The merging algorithm itself, which merges two parallel sentences into one, is described in Section 4.", "labels": [], "entities": []}, {"text": "Section 5 presents the minimally supervised parsing of the merged sentences.", "labels": [], "entities": []}, {"text": "The experimental translation system using the merged trees is described in Section 6.", "labels": [], "entities": []}, {"text": "Finally, we present our results (Section 7) and conclusions (Section 8).", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 2: Stop probabilities priors set for individual  POS tags.", "labels": [], "entities": [{"text": "Stop probabilities priors", "start_pos": 10, "end_pos": 35, "type": "METRIC", "confidence": 0.8558181524276733}]}, {"text": " Table 4: Our system BLEU scores.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 21, "end_pos": 25, "type": "METRIC", "confidence": 0.9989225268363953}]}]}