{"title": [{"text": "Automatically Extracting Topical Components fora Response-to-Text Writing Assessment", "labels": [], "entities": [{"text": "Response-to-Text Writing Assessment", "start_pos": 49, "end_pos": 84, "type": "TASK", "confidence": 0.7597137888272604}]}], "abstractContent": [{"text": "We investigate automatically extracting multi-word topical components to replace information currently provided by experts that is used to score the Evidence dimension of a writing in response to text assessment.", "labels": [], "entities": []}, {"text": "Our goal is to reduce the amount of expert effort and improve the scalability of an automatic scoring system.", "labels": [], "entities": []}, {"text": "Experimental results show that scoring performance using automatically extracted data-driven topical components is promising.", "labels": [], "entities": []}], "introductionContent": [{"text": "Automatic essay scoring has increasingly been investigated in recent years.", "labels": [], "entities": [{"text": "Automatic essay scoring", "start_pos": 0, "end_pos": 23, "type": "TASK", "confidence": 0.677140345176061}]}, {"text": "One important aspect of writing assessment, specifically in source-based writing, is evaluation of content.", "labels": [], "entities": [{"text": "writing assessment", "start_pos": 24, "end_pos": 42, "type": "TASK", "confidence": 0.8496313691139221}]}, {"text": "Different methods have been used to assess the content of essays, e.g., bag of words (, semantic similarity (), content vector analysis and cosine similarity), and Latent Dirichlet Allocation (LDA) topic modeling ().", "labels": [], "entities": [{"text": "Latent Dirichlet Allocation (LDA) topic modeling", "start_pos": 164, "end_pos": 212, "type": "TASK", "confidence": 0.6477883644402027}]}, {"text": "These prior studies differ from our research in several ways.", "labels": [], "entities": []}, {"text": "Much of the prior work does not target source-based writing and thus does not make use of source materials.", "labels": [], "entities": []}, {"text": "Approaches that do make use of source materials are typically designed to detect only if an essay is on-topic.", "labels": [], "entities": []}, {"text": "Our source-based assessment, in contrast, is also concerned with localizing in the student essay pieces of evidence that students provided from the source material.", "labels": [], "entities": []}, {"text": "This is because our goal is to not only score an essay, but also to provide feedback based on detailed essay content.", "labels": [], "entities": []}, {"text": "Various kinds of source-based assessments of content (both in essay and short answering scoring) typically require some expert work in advance.", "labels": [], "entities": []}, {"text": "Experts have provided reference answers () or manually crafted patterns (.", "labels": [], "entities": []}, {"text": "Using manually provided information helps increase the accuracy of a scoring system and its ability to provide meaningful feedback related to the scoring rubric.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 55, "end_pos": 63, "type": "METRIC", "confidence": 0.9992510676383972}]}, {"text": "But involving experts in the scoring process is a drawback for automatically scoring at scale.", "labels": [], "entities": []}, {"text": "Research to reduce expert effort has been underway to increase the scalability of scoring systems.", "labels": [], "entities": []}, {"text": "A semi-supervised method is used to reduce the amount of required hand-annotated data.", "labels": [], "entities": []}, {"text": "Text templates or patterns are automatically identified for short answer scoring.", "labels": [], "entities": [{"text": "short answer scoring", "start_pos": 60, "end_pos": 80, "type": "TASK", "confidence": 0.6162270704905192}]}, {"text": "Content importance models) are used to predict source material that students should select.", "labels": [], "entities": []}, {"text": "In this paper, our goal is to use natural language processing to automatically extract from source material a comprehensive list of topics which include: a) important topic words, and b) specific expressions (N-grams with N > 1) that students need to provide in their essays.", "labels": [], "entities": []}, {"text": "We call this comprehensive list \"topical components\".", "labels": [], "entities": []}, {"text": "Automatic extraction of topical components helps to reduce expert effort before the automatic assessment process.", "labels": [], "entities": []}, {"text": "We evaluate the usefulness of our method for extracting topical components on the Response-to-Text Assessment (RTA) Excerpt from the article: Many kids in Sauri did not attend school because their parents could not afford school fees.", "labels": [], "entities": [{"text": "Response-to-Text Assessment (RTA)", "start_pos": 82, "end_pos": 115, "type": "METRIC", "confidence": 0.7894981622695922}]}, {"text": "Some kids are needed to help with chores, such as fetching water and wood.", "labels": [], "entities": [{"text": "fetching", "start_pos": 50, "end_pos": 58, "type": "TASK", "confidence": 0.9708095192909241}]}, {"text": "In 2004, the schools had minimal supplies like books, paper and pencils, but the students wanted to learn.", "labels": [], "entities": []}, {"text": "All of them worked hard with the few supplies they had.", "labels": [], "entities": []}, {"text": "It was hard for them to concentrate, though, as there was no midday meal.", "labels": [], "entities": []}, {"text": "By the end of the day, kids didn't have any energy.", "labels": [], "entities": []}, {"text": "Prompt: The author provided one specific example of how the quality of life can be improved by the Millennium Villages Project in Sauri, Kenya.", "labels": [], "entities": []}, {"text": "Based on the article, did the author provide a convincing argument that winning the fight against poverty is achievable in our lifetime?", "labels": [], "entities": []}, {"text": "Explain why or why not with 3-4 examples from the text to support your answer.", "labels": [], "entities": []}, {"text": "Essay with score of 4 on Evidence dimension: I was convinced that winning the fight of poverty is achievable in our lifetime.", "labels": [], "entities": []}, {"text": "Many people couldn't afford medicine or bed nets to be treated for malaria . Many children had died from this dieseuse even though it could be treated easily.", "labels": [], "entities": []}, {"text": "But now, bed nets are used in every sleeping site . And the medicine is free of charge.", "labels": [], "entities": []}, {"text": "Another example is that the farmers' crops are dying because they could not afford the nessacary fertilizer and irrigation . But they are now, making progess.", "labels": [], "entities": []}, {"text": "Farmers now have fertilizer and water to give to the crops.", "labels": [], "entities": []}, {"text": "Also with seeds and the proper tools . Third, kids in Sauri were not well educated.", "labels": [], "entities": []}, {"text": "Many families couldn't afford school . Even at school there was no lunch . Students were exhausted from each day of school.", "labels": [], "entities": []}, {"text": "Now, school is free . Children excited to learn now can and they do have midday meals . Finally, Sauri is making great progress.", "labels": [], "entities": [{"text": "Sauri", "start_pos": 97, "end_pos": 102, "type": "TASK", "confidence": 0.8567642569541931}]}, {"text": "If they keep it up that city will no longer be in poverty.", "labels": [], "entities": []}, {"text": "Then the Millennium Village project can move onto help other countries in need.: An excerpt from the source text, the prompt, and a high-scoring essay with highlighted evidence ().", "labels": [], "entities": [{"text": "Millennium Village project", "start_pos": 9, "end_pos": 35, "type": "DATASET", "confidence": 0.9550602436065674}]}, {"text": "(. RTA is developed to assess analytical writing in response to text), e.g., making claims and marshalling evidence from a source text to support a viewpoint.", "labels": [], "entities": []}, {"text": "Automatic scoring of the Evidence dimension of the RTA was previously investigated in ().", "labels": [], "entities": [{"text": "RTA", "start_pos": 51, "end_pos": 54, "type": "TASK", "confidence": 0.7572283148765564}]}, {"text": "The Evidence dimension evaluates how well students use selected details from a text to support and extend a key idea.", "labels": [], "entities": []}, {"text": "A set of rubric-based features enabled by topical components manually provided by experts were used in () to automatically assess Evidence.", "labels": [], "entities": []}, {"text": "In this paper, we propose to use a model enabled by LDA topic modeling to automatically extract the topical components (i.e., topic words and significant N-grams (N \u2265 1)) needed for our scoring approach . We hypothesize that extracting rubricbased features based on data-driven topical components can perform as well as extracting features from manually provided topical components.", "labels": [], "entities": [{"text": "LDA topic modeling", "start_pos": 52, "end_pos": 70, "type": "TASK", "confidence": 0.5946068267027537}]}, {"text": "Results show that our method for automatically extracting topical components is promising but still needs improvement.", "labels": [], "entities": [{"text": "automatically extracting topical components", "start_pos": 33, "end_pos": 76, "type": "TASK", "confidence": 0.7442444041371346}]}], "datasetContent": [{"text": "We configure experiments to test the validity of the hypothesis that scoring models that extract features based on automatically extracted LDA-enabled topical components can perform as well as models which extract features from topical components manually provided by experts.", "labels": [], "entities": []}, {"text": "All experiments use 10 fold cross validation with Random Forest as a classifier (max-depth=5).", "labels": [], "entities": []}, {"text": "We report performance using Quadratic Weighted Kappa, a standard evaluation measure for essay assessment.", "labels": [], "entities": [{"text": "Quadratic Weighted Kappa", "start_pos": 28, "end_pos": 52, "type": "METRIC", "confidence": 0.9184428056081136}, {"text": "essay assessment", "start_pos": 88, "end_pos": 104, "type": "TASK", "confidence": 0.7489174008369446}]}, {"text": "Paired student t-test with p-value < 0.05 is used to measure statistical significance.", "labels": [], "entities": [{"text": "Paired student t-test", "start_pos": 0, "end_pos": 21, "type": "METRIC", "confidence": 0.8475384513537089}]}, {"text": "We compare results for models that extracted features from topical components with a baseline model which uses the top 500 unigrams as features (chosen based on a chi-squared feature selection method), and with an upper-bound model which is the best model reported in ().", "labels": [], "entities": []}, {"text": "The only difference between our model and the upper-bound model is that in our model the topical components were extracted automatically instead of manually.", "labels": [], "entities": []}, {"text": "To train LDA, we use a set of 591 not-scored essays (which are not used in our cross validation experiments) from grades 6-8, and the text.", "labels": [], "entities": [{"text": "LDA", "start_pos": 9, "end_pos": 12, "type": "TASK", "confidence": 0.8503056764602661}]}, {"text": "We use the LDA-C implementation ( with default values for the parameters and seeded initialization of topics to a distribution smoothed from a randomly chosen document.", "labels": [], "entities": []}, {"text": "The number of topics is chosen equal to the number of topics provided by experts (K = 8).", "labels": [], "entities": []}, {"text": "The Turbo-Topic parameters are set as P-value = 0.001 and min-count = 10 based on our intuition that it is better to discard less.", "labels": [], "entities": [{"text": "P-value", "start_pos": 38, "end_pos": 45, "type": "METRIC", "confidence": 0.9882189035415649}]}, {"text": "The cutoff threshold for removing less frequent N-grams is intuitively set to the top 20 most frequent N-grams in a topic.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: The two dataset's statistics.", "labels": [], "entities": []}, {"text": " Table 3: Distribution of the Evidence scores.", "labels": [], "entities": [{"text": "Distribution", "start_pos": 10, "end_pos": 22, "type": "TASK", "confidence": 0.9234473705291748}]}, {"text": " Table 6: Performance of models using automatically extracted", "labels": [], "entities": []}]}