{"title": [{"text": "Regular polysemy: from sense vectors to sense patterns", "labels": [], "entities": []}], "abstractContent": [{"text": "Regular polysemy was extensively investigated in lexical semantics, but this phenomenon has been very little studied in distributional semantics.", "labels": [], "entities": []}, {"text": "We propose a model for regular polysemy detection that is based on sense vectors and allows to work directly with senses in semantic vector space.", "labels": [], "entities": [{"text": "regular polysemy detection", "start_pos": 23, "end_pos": 49, "type": "TASK", "confidence": 0.6250312427679697}]}, {"text": "Our method is able to detect polysemous words that have the same regular sense alternation as in a given example (a word with two automatically induced senses that represent one polysemy pattern, such as ANIMAL / FOOD).", "labels": [], "entities": [{"text": "ANIMAL / FOOD", "start_pos": 204, "end_pos": 217, "type": "METRIC", "confidence": 0.7223735253016154}]}, {"text": "The method works equally well for nouns, verbs and adjectives and achieves an average recall of 0.55 and an average precision of 0.59 for ten different polysemy patterns.", "labels": [], "entities": [{"text": "recall", "start_pos": 86, "end_pos": 92, "type": "METRIC", "confidence": 0.9986211061477661}, {"text": "precision", "start_pos": 116, "end_pos": 125, "type": "METRIC", "confidence": 0.9901031255722046}]}], "introductionContent": [{"text": "Polysemy is widely spread in natural language.", "labels": [], "entities": []}, {"text": "Many studies in linguistics show evidence that certain word classes share polysemy patterns, which means that there are regularities in the way polysemous words vary in their meaning).", "labels": [], "entities": []}, {"text": "These regularities can be explained by analogical processes like semantic shifts (lamb can denote either ANIMAL or FOOD), metonymy (church can denote either ORGANIZATION or LOCATION) and metaphor (e.g. dirty in contexts such as dirty shoes and dirty words).", "labels": [], "entities": [{"text": "ANIMAL", "start_pos": 105, "end_pos": 111, "type": "METRIC", "confidence": 0.9331899881362915}, {"text": "FOOD", "start_pos": 115, "end_pos": 119, "type": "METRIC", "confidence": 0.731311023235321}]}, {"text": "Because of its significance, regular polysemy has been extensively investigated in lexical semantics).", "labels": [], "entities": []}, {"text": "However, this phenomenon has been little studied in computational semantics and even less in distributional semantics.", "labels": [], "entities": []}, {"text": "Several studies that aimed to model regular polysemy in semantic vector space were focused on word vectors.", "labels": [], "entities": []}, {"text": "Del proposed a method, based on word embeddings and regular semantic alternations, that allows detecting polysemous nouns among all nouns and representing them in away that accounts for asymmetry in sense predominance.", "labels": [], "entities": []}, {"text": "Di Pietro (2013) detected sense alternations by performing word sense disambiguation using vectors of words that denoted sense domains, such as ANIMAL or FOOD.", "labels": [], "entities": [{"text": "word sense disambiguation", "start_pos": 59, "end_pos": 84, "type": "TASK", "confidence": 0.6485530336697897}, {"text": "ANIMAL", "start_pos": 144, "end_pos": 150, "type": "METRIC", "confidence": 0.912415623664856}, {"text": "FOOD", "start_pos": 154, "end_pos": 158, "type": "METRIC", "confidence": 0.7923747301101685}]}, {"text": "Boleda and colleagues (2012b) compare word vectors for polysemous nouns with average vectors of monosemous words in predefined sense domains.", "labels": [], "entities": []}, {"text": "Their study relied on the CoreLex meta sense inventory that was built using WordNet.", "labels": [], "entities": [{"text": "CoreLex meta sense inventory", "start_pos": 26, "end_pos": 54, "type": "DATASET", "confidence": 0.8257853388786316}, {"text": "WordNet", "start_pos": 76, "end_pos": 83, "type": "DATASET", "confidence": 0.9839414954185486}]}, {"text": "Thus, the aforementioned methods all use semantic word vectors to detect sense alternations.", "labels": [], "entities": []}, {"text": "For the task of regular polysemy detection, we use sense vectors and not word vectors.", "labels": [], "entities": [{"text": "regular polysemy detection", "start_pos": 16, "end_pos": 42, "type": "TASK", "confidence": 0.6449045638243357}]}, {"text": "We believe that this is a more natural approach to the problem, because it allows us to study regular sense alternations as they are: we deal directly with senses and their location in semantic vector space.", "labels": [], "entities": []}, {"text": "Our approach has two major advantages: first, we believe that it is less affected by sense skewness than methods based on word vectors, because vectors of different senses are distinct, even if senses have very different frequencies, while in case of word vectors, a much more frequent sense will determine the word vector, as noted by Del.", "labels": [], "entities": []}, {"text": "Second, theoretically our approach is not limited by regular alternation between just two senses, as in previous studies), but can be naturally extended to three or more senses.", "labels": [], "entities": []}, {"text": "The sense vectors we use in our study are built automatically on a big corpus.", "labels": [], "entities": []}, {"text": "The technique of automatic word sense induction (WSI) allows us to represent senses as clusters of semantically similar instances.", "labels": [], "entities": [{"text": "word sense induction (WSI)", "start_pos": 27, "end_pos": 53, "type": "TASK", "confidence": 0.7966868778069814}]}, {"text": "Usually, the technique does not use any external resources such as dictionaries, thesauri or sense-tagged data.", "labels": [], "entities": []}, {"text": "WSI was successfully applied to the lexicographical task of novel sense detection, i.e. identifying words which have taken on new senses overtime ().", "labels": [], "entities": [{"text": "WSI", "start_pos": 0, "end_pos": 3, "type": "TASK", "confidence": 0.42211878299713135}, {"text": "novel sense detection", "start_pos": 60, "end_pos": 81, "type": "TASK", "confidence": 0.6283253928025564}]}, {"text": "Besides, WSI provides data for the study of diachronic variation in word senses (.", "labels": [], "entities": [{"text": "WSI", "start_pos": 9, "end_pos": 12, "type": "DATASET", "confidence": 0.7858457565307617}]}, {"text": "Although Boleda and colleagues noted that automatic word sense induction could lead to more flexible and realistic models of regular polysemy, to the best of our knowledge, the WSI technique was not used in any previous research of this type.", "labels": [], "entities": [{"text": "word sense induction", "start_pos": 52, "end_pos": 72, "type": "TASK", "confidence": 0.7199937403202057}]}, {"text": "In this study, we propose a model for regular polysemy detection that is based on sense vectors and allows us to work directly with senses in semantic vector space.", "labels": [], "entities": [{"text": "regular polysemy detection", "start_pos": 38, "end_pos": 64, "type": "TASK", "confidence": 0.6396818061669668}]}, {"text": "We performed an experiment on Russian nouns, verbs and adjectives and subsequently discuss the limitations of our method.", "labels": [], "entities": []}], "datasetContent": [{"text": "We aimed to study how well the proposed technique detects polysemous words that have the same regular sense alternation as in a given example.", "labels": [], "entities": []}, {"text": "An example is a word with two automatically induced senses that represent one polysemy pattern (such as ANIMAL / FOOD).", "labels": [], "entities": [{"text": "ANIMAL", "start_pos": 104, "end_pos": 110, "type": "METRIC", "confidence": 0.9346486330032349}, {"text": "FOOD", "start_pos": 113, "end_pos": 117, "type": "METRIC", "confidence": 0.5141582489013672}]}, {"text": "We manually selected ten polysemy patterns: four for nouns, three for verbs and three for adjectives, nine of them from the most famous and reliable description of regular polysemy for Russian, Lexical Semantics by Jury Apresjan, in which he thoroughly classifies and illustrates more than 80 productive and non-productive regular polysemy types for the aforementioned parts of speech.", "labels": [], "entities": []}, {"text": "We also took one polysemy pattern for verbs from an ongoing work led by Valentina Apresjan.", "labels": [], "entities": []}, {"text": "Besides, we checked that word senses, which were part of the polysemy pattern in question, were presented in the corpus and were thus detected by the AdaGram model (e.g. zheleznyj 'iron': iron gates is sense #3 in AdaGram / iron will is sense #4 in AdaGram).", "labels": [], "entities": [{"text": "AdaGram", "start_pos": 249, "end_pos": 256, "type": "DATASET", "confidence": 0.9185662865638733}]}, {"text": "Polysemy patterns for nouns: ANIMAL / FOOD (e.g. gus' 'goose'); AMOUNT / CONTAINER (e.g. butylka 'bottle'); ACTION / RESULT (e.g. ushyb 'injury' / 'bruise'); MUSIC / DANCE (e.g. val's 'waltz ').", "labels": [], "entities": [{"text": "ANIMAL", "start_pos": 29, "end_pos": 35, "type": "METRIC", "confidence": 0.995142936706543}, {"text": "FOOD", "start_pos": 38, "end_pos": 42, "type": "METRIC", "confidence": 0.7527637481689453}, {"text": "AMOUNT", "start_pos": 64, "end_pos": 70, "type": "METRIC", "confidence": 0.927304208278656}, {"text": "ACTION / RESULT", "start_pos": 108, "end_pos": 123, "type": "METRIC", "confidence": 0.7712423006693522}, {"text": "MUSIC / DANCE", "start_pos": 158, "end_pos": 171, "type": "METRIC", "confidence": 0.6909868915875753}]}, {"text": "Polysemy patterns for verbs: AUTONOMOUS RELOCATION / NONAUTONOMOUS RELOCATION (e.g. jehat' 'to move (about a car)' / 'to drive (a car)'); PRODUCE SOUND / SPEAK (e.g. blejat' 'to bleat'); CEASE TO EXIST / RUN OUT OF INNER RESOURCE (e.g. tajat' 'to melt' / 'to melt away').", "labels": [], "entities": [{"text": "CEASE", "start_pos": 187, "end_pos": 192, "type": "METRIC", "confidence": 0.8339188098907471}, {"text": "RUN OUT OF INNER RESOURCE", "start_pos": 204, "end_pos": 229, "type": "METRIC", "confidence": 0.7668056964874268}]}, {"text": "Polysemy patterns for adjectives: MADE OF SOME MATERIAL / MAKING A SIMILAR IMPRESSION (e.g. derevjannyj 'wooden'); SURFACE PROPERTY / HUMAN PROPERTY (e.g. nezhnyi 'delicate'); HAVING SOME TASTE / MAKING A SIMILAR IMPRESSION (e.g. kislyj 'sour').", "labels": [], "entities": [{"text": "MADE", "start_pos": 34, "end_pos": 38, "type": "METRIC", "confidence": 0.9480445384979248}]}, {"text": "Then, for each pattern we selected 4-7 examples that were used for evaluation.", "labels": [], "entities": []}, {"text": "All the examples were extracted from Lexical Semantics (1995) or from (Apresjan, 2016).", "labels": [], "entities": [{"text": "Lexical Semantics (1995)", "start_pos": 37, "end_pos": 61, "type": "DATASET", "confidence": 0.6304421544075012}]}, {"text": "We were guided by the following principle: Words should be semantically similar, namely synonyms, antonyms or co-hyponyms.", "labels": [], "entities": []}, {"text": "In the study by Jury Apresjan (1995), polysemy patterns such as ACTION / RESULT embrace a large number of semantically very different words from ushyb 'injury' / 'bruise' to risunok 'drawing' and ispravleniye 'correction'.", "labels": [], "entities": [{"text": "ACTION", "start_pos": 64, "end_pos": 70, "type": "METRIC", "confidence": 0.9329608082771301}, {"text": "RESULT", "start_pos": 73, "end_pos": 79, "type": "METRIC", "confidence": 0.6282888054847717}, {"text": "ispravleniye 'correction", "start_pos": 196, "end_pos": 220, "type": "TASK", "confidence": 0.6854448219140371}]}, {"text": "For the purpose of the present study, we chose words from one semantic domain (e.g. ushyb 'injury' / 'bruise'; ukus 'bite' / 'wound'; perelom 'breaking of a bone' / 'fracture'; porez 'cut', words denoting different injuries and their result on/in the human body).", "labels": [], "entities": []}, {"text": "The experimental setup was as follows: Sense vectors were built using AdaGram with \u03b1 = 0.10, window size 5, vector dimension 300, maximum number of senses 10 and minimal token frequency 100.", "labels": [], "entities": [{"text": "AdaGram", "start_pos": 70, "end_pos": 77, "type": "DATASET", "confidence": 0.910386323928833}]}, {"text": "Corpus used for training contained about 2 billion tokens and was a combination of ruWac (a representative snapshot of the Russian Web), lib.ru (a Russian online library) and Russian Wikipedia.", "labels": [], "entities": []}, {"text": "Corpus was lemmatized with Mystem 3, lowercased and cleared of punctuation.", "labels": [], "entities": [{"text": "Corpus", "start_pos": 0, "end_pos": 6, "type": "DATASET", "confidence": 0.9287803173065186}]}, {"text": "In order to study how well our method is able to detect word sense alternations, we evaluated recall and precision in two separate experiments.", "labels": [], "entities": [{"text": "recall", "start_pos": 94, "end_pos": 100, "type": "METRIC", "confidence": 0.9987648725509644}, {"text": "precision", "start_pos": 105, "end_pos": 114, "type": "METRIC", "confidence": 0.9990924596786499}]}, {"text": "In both cases, two words were selected from each polysemous pattern group as \"anchor\" words, while other words of the group were treated as \"target\" words.", "labels": [], "entities": []}, {"text": "Each of the anchor words (with its two senses) was given as input to the method, thus defining a sense alternation by an example.", "labels": [], "entities": []}, {"text": "In the recall evaluation we checked how many of the target words were actually produced, given the anchor word.", "labels": [], "entities": [{"text": "recall", "start_pos": 7, "end_pos": 13, "type": "METRIC", "confidence": 0.9932071566581726}]}, {"text": "Recall was evaluated with two different limits on the number of detected words N lim , 5 and 50.", "labels": [], "entities": [{"text": "Recall", "start_pos": 0, "end_pos": 6, "type": "METRIC", "confidence": 0.7069185972213745}]}, {"text": "Note that we did not expect a high recall with N lim = 5, as we believe that there can be other words besides target words that have the same alternation.", "labels": [], "entities": [{"text": "recall", "start_pos": 35, "end_pos": 41, "type": "METRIC", "confidence": 0.9988773465156555}]}, {"text": "Another reason is that there were sometimes more than 5 target words in the group, therefore it was impossible to achieve perfect recall with just N lim = 5.", "labels": [], "entities": [{"text": "recall", "start_pos": 130, "end_pos": 136, "type": "METRIC", "confidence": 0.9828746318817139}]}, {"text": "Different parts of speech did not show significant variation of recall.", "labels": [], "entities": [{"text": "recall", "start_pos": 64, "end_pos": 70, "type": "METRIC", "confidence": 0.8889484405517578}]}, {"text": "The average recall for ten groups was 0.22 for N lim = 5 and 0.55 for N lim = 50.", "labels": [], "entities": [{"text": "recall", "start_pos": 12, "end_pos": 18, "type": "METRIC", "confidence": 0.9993661046028137}]}, {"text": "In order to evaluate precision, we took anchor words and for each of them extracted the top five candidates (N lim = 5) that were produced by our method.", "labels": [], "entities": [{"text": "precision", "start_pos": 21, "end_pos": 30, "type": "METRIC", "confidence": 0.9991850256919861}]}, {"text": "These candidates were checked by a lexicographer: if a candidate shared the same polysemy pattern with the anchor word, it was accepted.", "labels": [], "entities": []}, {"text": "The average precision for ten groups was 0.59, with three groups having perfect precision.", "labels": [], "entities": [{"text": "precision", "start_pos": 12, "end_pos": 21, "type": "METRIC", "confidence": 0.9995906949043274}, {"text": "precision", "start_pos": 80, "end_pos": 89, "type": "METRIC", "confidence": 0.9962339997291565}]}, {"text": "In most cases, words that were rejected were semantically similar to the anchor word, but they did not exhibit the polysemy pattern in focus.", "labels": [], "entities": []}, {"text": "For example, wrong candidates for the word ukus 'bite' / 'wound' were snake, insect and mosquito, which can be subjects of the action; wrong candidates for the word stakan 'glass' were tea and coffee, which denote the content; and wrong candidates for the word kislyj 'sour' were garlicky and fried, which mean HAVING SOME TASTE, but do not exhibit the meaning MAKING SIMILAR IMPRESSION.", "labels": [], "entities": [{"text": "HAVING SOME TASTE", "start_pos": 311, "end_pos": 328, "type": "METRIC", "confidence": 0.7736672361691793}, {"text": "meaning MAKING SIMILAR IMPRESSION", "start_pos": 353, "end_pos": 386, "type": "METRIC", "confidence": 0.5076522678136826}]}], "tableCaptions": []}