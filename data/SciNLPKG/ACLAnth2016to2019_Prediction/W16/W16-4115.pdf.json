{"title": [{"text": "Using Ambiguity Detection to Streamline Linguistic Annotation", "labels": [], "entities": [{"text": "Ambiguity Detection", "start_pos": 6, "end_pos": 25, "type": "TASK", "confidence": 0.6547963172197342}]}], "abstractContent": [{"text": "Arabic writing is typically underspecified for short vowels and other markups, referred to as diacritics.", "labels": [], "entities": []}, {"text": "In addition to the lexical ambiguity exhibited inmost languages, the lack of diacritics in written Arabic adds another layer of ambiguity which is an artifact of the orthography.", "labels": [], "entities": []}, {"text": "In this paper, we present the details of three annotation experimental conditions designed to study the impact of automatic ambiguity detection, on annotation speed and quality in a large scale annotation project.", "labels": [], "entities": [{"text": "automatic ambiguity detection", "start_pos": 114, "end_pos": 143, "type": "TASK", "confidence": 0.6419646541277567}]}], "introductionContent": [{"text": "Written Modern Standard Arabic (MSA) poses many challenges for natural language processing (NLP).", "labels": [], "entities": [{"text": "Written Modern Standard Arabic (MSA)", "start_pos": 0, "end_pos": 36, "type": "TASK", "confidence": 0.5108272007533482}, {"text": "natural language processing (NLP)", "start_pos": 63, "end_pos": 96, "type": "TASK", "confidence": 0.7934777637322744}]}, {"text": "Most written Arabic text lacks short vowels and diacritics rendering a mostly consonantal orthography).", "labels": [], "entities": []}, {"text": "Arabic diacritization is an orthographic way to describe Arabic word pronunciation, and avoid word reading ambiguity.", "labels": [], "entities": []}, {"text": "In Arabic, diacritics are marks that reflect the phonological, morphological and grammatical rules.", "labels": [], "entities": []}, {"text": "The lack of diacritics leads usually to considerable lexical and morphological ambiguity.", "labels": [], "entities": []}, {"text": "Full diacritization has been shown to improve state-of-the-art Arabic automatic systems such as automatic speech recognition (ASR) systems) and statistical machine translation (SMT) (.", "labels": [], "entities": [{"text": "automatic speech recognition (ASR)", "start_pos": 96, "end_pos": 130, "type": "TASK", "confidence": 0.8060935537020365}, {"text": "statistical machine translation (SMT)", "start_pos": 144, "end_pos": 181, "type": "TASK", "confidence": 0.8419823050498962}]}, {"text": "Hence, diacritization has been receiving increased attention in several Arabic NLP applications (.", "labels": [], "entities": []}, {"text": "Building models to assign diacritics to each letter in a word requires a large amount of annotated training corpora covering different topics and domains to overcome the sparseness problem.", "labels": [], "entities": []}, {"text": "The currently available MSA diacritized corpora are generally limited to religious texts such as the Holy Quran, educational texts or newswire stories distributed by the Linguistic Data Consortium.", "labels": [], "entities": []}, {"text": "This paper presents a work carried out within a project to create an optimal diacritization scheme for Arabic orthographic representation (OptDiac) project (.", "labels": [], "entities": [{"text": "Arabic orthographic representation", "start_pos": 103, "end_pos": 137, "type": "TASK", "confidence": 0.631893535455068}]}, {"text": "The overreaching goal of our project is to manually create a large-scale annotated corpus with the diacritics fora variety of Arabic texts.", "labels": [], "entities": []}, {"text": "The creation of manually annotated corpora presents many challenges and issues related to the linguistic complexity of the Arabic language.", "labels": [], "entities": []}, {"text": "In order to streamline the annotation process, we designed various annotation experimental conditions in order to answer the following questions: Can we automatically detect linguistic difficulties such as linguistic ambiguity?", "labels": [], "entities": []}, {"text": "To what extent is there agreement between machines and human annotators when it comes to detecting ambiguity?", "labels": [], "entities": []}, {"text": "Can the automatic detection of the ambiguity speedup the annotation process?", "labels": [], "entities": []}, {"text": "In the next two sections we discuss related work (Section2) and the annotation framework (Section 3).", "labels": [], "entities": []}, {"text": "Afterwards, we present the experimental setup in Section 4.", "labels": [], "entities": []}, {"text": "In Section 5, we present the results of the evaluation experiment and in Section 6, we analyze the annotation disagreement errors found during the evaluation.", "labels": [], "entities": []}], "datasetContent": [{"text": "We use the corpus of contemporary Arabic (CCA) compiled by Al-.", "labels": [], "entities": [{"text": "corpus of contemporary Arabic (CCA) compiled by Al-.", "start_pos": 11, "end_pos": 63, "type": "DATASET", "confidence": 0.8431494136651357}]}, {"text": "It is a balanced corpus divided into the following genres: autobiography, short stories, children's stories, economics, education, health and medicine, interviews, politics, recipes, religion, sociology, science, sports, tourism and travel.", "labels": [], "entities": []}, {"text": "The CCA corpus text genres were carefully selected by its compilers since the target users of the corpus were mostly language teachers and teachers of Arabic as a foreign language.", "labels": [], "entities": [{"text": "CCA corpus text genres", "start_pos": 4, "end_pos": 26, "type": "DATASET", "confidence": 0.925545796751976}]}, {"text": "Various metadata information are included in the corpus such as the information about the text, the author and the source.", "labels": [], "entities": []}, {"text": "In order to use the CCA corpus, a normalization effort was done to produce a consistent XML mark-up format to be used in our annotation tool.", "labels": [], "entities": [{"text": "CCA corpus", "start_pos": 20, "end_pos": 30, "type": "DATASET", "confidence": 0.9250355064868927}]}, {"text": "Furthermore, we split paragraphs and sentences by period and remove repeated sentences after the initial segmentation in order to start the annotation process.", "labels": [], "entities": []}, {"text": "For the evaluation, we used a sample of 10K-Words from the CCA corpus representing 4 domains with approximately 2.5K-words per domain (children stories, economics,sports and politics).", "labels": [], "entities": [{"text": "CCA corpus", "start_pos": 59, "end_pos": 69, "type": "DATASET", "confidence": 0.9746910929679871}]}, {"text": "We have three experimental conditions for three evaluations carried over a period of six weeks.", "labels": [], "entities": []}, {"text": "1. The first condition (COND1): In the first experimental condition (COND1), four annotators were given raw undiacritized sentences and were asked to add the missing diacritics as per the guidelines.", "labels": [], "entities": []}, {"text": "They either select one of the top three diacritization choices computed by MADAMIRA or manually edit the word.", "labels": [], "entities": [{"text": "MADAMIRA", "start_pos": 75, "end_pos": 83, "type": "METRIC", "confidence": 0.6610574722290039}]}, {"text": "2. The second condition (COND2): In the second experimental condition (COND2), we provided the raw undiacritized sentences to a first group of two annotators (Group 1) and we asked them to mark and add the required diacritics only to the words they believe are ambiguous while ignoring the rest of the non ambiguous words in the sentence.", "labels": [], "entities": []}, {"text": "3. The third condition (COND3): For the third experimental condition (COND3), we gave, to a different group of two annotators (Group 2), the same sentences assigned to Group 1 while having the sentences explicitly marked as potentially ambiguous using the MADAMIRA as explained previously (again the top three MADAMIRA choices were provided).", "labels": [], "entities": []}, {"text": "Furthermore, in COND3, the annotators were asked to tell whether they agree or not with the ambiguity class provided for each word using the tool and also by adding the missing diacritics in case they agree that the given word is ambiguous.", "labels": [], "entities": [{"text": "COND3", "start_pos": 16, "end_pos": 21, "type": "DATASET", "confidence": 0.8604674935340881}]}, {"text": "The Inter-Annotator Agreement (IAA) is measured by using pairwise percent agreement averaged overall pairs of annotations (APP).", "labels": [], "entities": [{"text": "Inter-Annotator Agreement (IAA)", "start_pos": 4, "end_pos": 35, "type": "METRIC", "confidence": 0.8636415243148804}, {"text": "pairwise percent agreement averaged overall pairs of annotations (APP)", "start_pos": 57, "end_pos": 127, "type": "METRIC", "confidence": 0.7865653850815513}]}, {"text": "The pairwise percent agreement (also called observed agreement) is computed as the percentage of times two annotators assign the same label to a unit.", "labels": [], "entities": [{"text": "pairwise percent agreement (also called observed agreement)", "start_pos": 4, "end_pos": 63, "type": "METRIC", "confidence": 0.6958218846056197}]}, {"text": "If a single letter in a given word has one diacritization mismatch, then the whole word is considered as disagreement.", "labels": [], "entities": []}, {"text": "A high APP score denotes that at least two annotators agree on the annotation and therefore, the probability that the annotation is erroneous is very small.", "labels": [], "entities": [{"text": "APP score", "start_pos": 7, "end_pos": 16, "type": "METRIC", "confidence": 0.9339590966701508}]}], "tableCaptions": [{"text": " Table 2: Average annotated words per minute recorded during the evaluation of 10K-words from the  CCA dataset in three experimental conditions", "labels": [], "entities": [{"text": "CCA dataset", "start_pos": 99, "end_pos": 110, "type": "DATASET", "confidence": 0.9755910038948059}]}]}