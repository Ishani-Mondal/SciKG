{"title": [{"text": "Learning Non-Linear Functions for Text Classification", "labels": [], "entities": [{"text": "Text Classification", "start_pos": 34, "end_pos": 53, "type": "TASK", "confidence": 0.7824333012104034}]}], "abstractContent": [{"text": "In this paper, we show that generative clas-sifiers are capable of learning non-linear decision boundaries and that non-linear generative models can outperform a number of linear classifiers on some text cate-gorization tasks.", "labels": [], "entities": []}, {"text": "We first prove that 3-layer multinomial hierarchical generative (Bayesian) classi-fiers, under a particular independence assumption , can only learn the same linear decision boundaries as a multinomial naive Bayes classifier.", "labels": [], "entities": []}, {"text": "We then goon to show that making a different independence assumption results in nonlinearization, thereby enabling us to learn non-linear decision boundaries.", "labels": [], "entities": []}, {"text": "We finally evaluate the performance of these non-linear classifiers on a series of text classification tasks.", "labels": [], "entities": [{"text": "text classification tasks", "start_pos": 83, "end_pos": 108, "type": "TASK", "confidence": 0.8090920050938925}]}], "introductionContent": [{"text": "Probabilistic classifiers predict a class c given a set of features F of the data point being classified, by selecting the most probable class given the features, as shown in Equation 1.", "labels": [], "entities": []}, {"text": "The multilayer perceptron, a 3-layer classifier with an input layer, a hidden layer and an output layer, is capable of learning non-linear decision boundaries).", "labels": [], "entities": []}, {"text": "It is therefore only to be expected that 3-layer generative models should also be capable of learning the same.", "labels": [], "entities": []}, {"text": "However, it turns that under certain conditions, 3-layer generative models for classification are only as powerful as 2-layer models, and under other conditions, are capable of learning non-linear decision boundaries.", "labels": [], "entities": []}, {"text": "In this paper, we study 3-layer hierarchical multinomial generative models, and define the conditions under which their decision boundaries are linear or non-linear.", "labels": [], "entities": []}, {"text": "The main contributions of the paper are the following: \u2022 We prove that a certain set of independence assumptions results in linear decision boundaries and identical classification performance to a naive Bayes classifier.", "labels": [], "entities": []}, {"text": "\u2022 We demonstrate that a different set of independence assumptions makes models with the same parameters capable of learning nonlinear decision boundaries and certain nonlinear functions, for instance, a scaled and shifted XOR function.", "labels": [], "entities": []}, {"text": "\u2022 We show through experiments that such nonlinear hierarchical Bayesian models can outperform many commonly used machine learning models at certain text classification tasks.", "labels": [], "entities": [{"text": "text classification tasks", "start_pos": 148, "end_pos": 173, "type": "TASK", "confidence": 0.7998320758342743}]}], "datasetContent": [{"text": "We conducted four sets of experiments to evaluate the performance of non-linear hierarchical Bayesian classifiers trained using repeated soft expectation maximization.", "labels": [], "entities": []}, {"text": "In the first three experiments, the multinomial version was used and in 214 the last, the Gaussian version was used.", "labels": [], "entities": []}, {"text": "With both the naive Bayes classifier and the hierarchical Bayesian models, the smoothing used was Laplace smoothing.", "labels": [], "entities": []}, {"text": "The SVM classifier used a linear kernel.", "labels": [], "entities": []}, {"text": "The first experiment was run on the large movie review dataset () which consists of 50, 000 movie reviews labelled as either positive or negative (according to whether they expressed positive or negative sentiment about a movie).", "labels": [], "entities": [{"text": "movie review dataset", "start_pos": 42, "end_pos": 62, "type": "DATASET", "confidence": 0.6154795785744985}]}, {"text": "The training set size was varied between 5, 000 and 35, 000 in steps of 5, 000 (with half the reviews drawn from positively labelled data and the other half drawn from negatively labelled data).", "labels": [], "entities": []}, {"text": "Of the remaining data, we used 5, 000 reviews (2, 500 positive and 2, 500 negative) as a validation set.", "labels": [], "entities": []}, {"text": "The rest were used as test data.", "labels": [], "entities": []}, {"text": "The accuracies for different training set sizes and hidden nodes are as shown in.", "labels": [], "entities": []}, {"text": "The accuracies obtained when training on 25, 000 reviews and testing on 20, 000 (with the remaining 5000 documents of the test set used for validation) are shown in .  We tested the performance of the various classifiers (the hierarchical Bayes classifier was configured with 2 hidden nodes per class) on the Reuters R8, R52 and 20 Newsgroups datasets preprocessed and split as described in).", "labels": [], "entities": [{"text": "Reuters R8, R52 and 20 Newsgroups datasets preprocessed", "start_pos": 309, "end_pos": 364, "type": "DATASET", "confidence": 0.9172923432456123}]}, {"text": "10% of the training data was held back for validation.", "labels": [], "entities": []}, {"text": "The results are shown in Table 2.", "labels": [], "entities": []}, {"text": "The accuracies of different classifiers (including a hierarchical Bayes classifier with 4 hidden nodes per class trained through 50 repetitions of 10 iterations of expectation maximization) on the query dataset are as shown in.", "labels": [], "entities": []}, {"text": "The error margins are large enough to render all comparisons on this dataset devoid of significance.", "labels": [], "entities": [{"text": "error margins", "start_pos": 4, "end_pos": 17, "type": "METRIC", "confidence": 0.9398307800292969}]}, {"text": "A total of 2250 points were generated at random positions (x, y) inside a square of width 500.", "labels": [], "entities": []}, {"text": "Those falling inside each of the four shaded shapes shown in were labelled 1 and the rest of the points (falling outside the shaded areas of the square) were labelled 0.", "labels": [], "entities": []}, {"text": "For each shape, 1000 of the points were used for training, 250 as the validation set and the remaining 1000 as the test set.", "labels": [], "entities": []}, {"text": "Naive Bayes and nonlinear hierarchical Bayes classifiers that assumed the Gaussian distribution were used.", "labels": [], "entities": []}, {"text": "The Gaussian naive Bayes (GNB) classifier and the non-linear Gaussian hierarchical Bayes (GHB) classifier (10 hidden nodes per class), trained with 10 repetitions of 100 iterations of expectation maximization were tested on the artificial dataset.", "labels": [], "entities": []}, {"text": "Their accuracies are as shown in.", "labels": [], "entities": [{"text": "accuracies", "start_pos": 6, "end_pos": 16, "type": "METRIC", "confidence": 0.9912749528884888}]}, {"text": "Shape GNB GHB ring 0.664 0.949 dots 0.527 0.926 XOR 0.560 0.985 S 0.770 0.973: Accuracy on the artificial dataset.", "labels": [], "entities": [{"text": "Shape GNB GHB ring 0.664 0.949 dots 0.527 0.926 XOR 0.560 0.985 S 0.770 0.973", "start_pos": 0, "end_pos": 77, "type": "METRIC", "confidence": 0.7656639496485392}, {"text": "Accuracy", "start_pos": 79, "end_pos": 87, "type": "METRIC", "confidence": 0.9778026342391968}]}], "tableCaptions": [{"text": " Table 1: Accuracy on the movie reviews dataset  when trained on 25,000 reviews.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9989362359046936}, {"text": "movie reviews dataset", "start_pos": 26, "end_pos": 47, "type": "DATASET", "confidence": 0.6112098892529806}]}, {"text": " Table 2: Accuracy on Reuters R8, R52 and 20  Newsgroups.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9970670342445374}, {"text": "Reuters R8, R52 and 20  Newsgroups", "start_pos": 22, "end_pos": 56, "type": "DATASET", "confidence": 0.7171164325305394}]}]}