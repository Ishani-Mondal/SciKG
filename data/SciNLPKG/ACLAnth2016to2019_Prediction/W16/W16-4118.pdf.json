{"title": [{"text": "Similarity-Based Alignment of Monolingual Corpora for Text Simplification Purposes", "labels": [], "entities": [{"text": "Similarity-Based Alignment", "start_pos": 0, "end_pos": 26, "type": "TASK", "confidence": 0.661825880408287}, {"text": "Text Simplification Purposes", "start_pos": 54, "end_pos": 82, "type": "TASK", "confidence": 0.744795560836792}]}], "abstractContent": [{"text": "Comparable or parallel corpora are beneficial for many NLP tasks.", "labels": [], "entities": []}, {"text": "The automatic collection of corpora enables large-scale resources, even for less-resourced languages, which in turn can be useful for deducing rules and patterns for text rewriting algorithms, a subtask of automatic text simplification.", "labels": [], "entities": [{"text": "text rewriting algorithms", "start_pos": 166, "end_pos": 191, "type": "TASK", "confidence": 0.7894409795602163}]}, {"text": "We present two methods for the alignment of Swedish easy-to-read text segments to text segments from a reference corpus.", "labels": [], "entities": [{"text": "alignment of Swedish easy-to-read text segments", "start_pos": 31, "end_pos": 78, "type": "TASK", "confidence": 0.8298566440741221}]}, {"text": "The first method (M1) was originally developed for the task of text reuse detection, measuring sentence similarity by a modified version of a TF-IDF vector space model.", "labels": [], "entities": [{"text": "text reuse detection", "start_pos": 63, "end_pos": 83, "type": "TASK", "confidence": 0.8518628279368082}]}, {"text": "A second method (M2), also accounting for part-of-speech tags, was developed , and the methods were compared.", "labels": [], "entities": []}, {"text": "For evaluation, a crowdsourcing platform was built for human judgement data collection, and preliminary results showed that cosine similarity relates better to human ranks than the Dice coefficient.", "labels": [], "entities": [{"text": "human judgement data collection", "start_pos": 55, "end_pos": 86, "type": "TASK", "confidence": 0.6193901747465134}, {"text": "cosine similarity", "start_pos": 124, "end_pos": 141, "type": "METRIC", "confidence": 0.7996042668819427}]}, {"text": "We also saw a tendency that including syntactic context to the TF-IDF vector space model is beneficial for this kind of paraphrase alignment task.", "labels": [], "entities": [{"text": "paraphrase alignment task", "start_pos": 120, "end_pos": 145, "type": "TASK", "confidence": 0.8936235507329305}]}], "introductionContent": [{"text": "Automatic text simplification is defined as the process of reducing text complexity, while maintaining most of the content.", "labels": [], "entities": [{"text": "Automatic text simplification", "start_pos": 0, "end_pos": 29, "type": "TASK", "confidence": 0.6230984926223755}]}, {"text": "While the first approaches handled the task of automatically simplifying texts by the application of hand-crafted rules, cf. fora recent example for Swedish, data-driven methods have gained momentum in text simplification, as in other areas within natural language processing.", "labels": [], "entities": [{"text": "text simplification", "start_pos": 202, "end_pos": 221, "type": "TASK", "confidence": 0.7525911927223206}]}, {"text": "By using large corpora of aligned monolingual material, it is possible to automatically extract patterns or rules but since such induction requires large amounts of aligned material, hand-crafted systems are often the only practically performable alternative for languages without such resources.", "labels": [], "entities": []}, {"text": "To automatically collect comparable corpora would result in large-scale resources useful for deducing rules and patterns for text rewriting algorithms, particularly beneficial for less-resourced languages with sparse linguistic resources.", "labels": [], "entities": [{"text": "text rewriting algorithms", "start_pos": 125, "end_pos": 150, "type": "TASK", "confidence": 0.8020531932512919}]}, {"text": "In this study, we hypothesized that we could extend the work of Sanchez-, originally developed for test reuse detection, to detect paraphrased segments from two corpora; one of them containing only easy-to-read material, and the other representing the full spectra of Swedish texts.", "labels": [], "entities": [{"text": "test reuse detection", "start_pos": 99, "end_pos": 119, "type": "TASK", "confidence": 0.6625265876452128}]}, {"text": "We replicated the algorithm proposed by, and contrasted this method to a method that included part-of-speech tags as context.", "labels": [], "entities": []}, {"text": "An ongoing crowdsourcing evalutation is presented, in terms of evaluation design and preliminary results.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this study, crowdsourcing was used to assess the two methods.The aligned items used for evaluation were chosen by only considering the RS that were paired with at least one ES at every cosine value (0.40, 0.50, 0.60, 0.70, 0.80), rounded to 2 decimals.", "labels": [], "entities": []}, {"text": "When multiple sentences with the same cosine value were encountered, one was randomly chosen.", "labels": [], "entities": []}, {"text": "The aim of this heuristic was to be able to better assess the cosine threshold values.", "labels": [], "entities": []}, {"text": "Typically, the recruitment process is managed by an employer, such as Amazon's Mechanical Turk.", "labels": [], "entities": [{"text": "Amazon's Mechanical Turk", "start_pos": 70, "end_pos": 94, "type": "DATASET", "confidence": 0.8162282258272171}]}, {"text": "Since our evaluation task treated texts in Swedish, we constructed our own platform to host the tasks and collect the annotated data.", "labels": [], "entities": []}, {"text": "For this project, the recruitment was made by public postings on Facebook and e-mails to current graduate students at a Swedish University.", "labels": [], "entities": []}, {"text": "The recruitment post stated the aim of the tasks and contained a link to our web page.", "labels": [], "entities": []}, {"text": "The web page presented the RS randomly to annotators followed by the (randomly ordered) aligned ES.", "labels": [], "entities": []}, {"text": "3. The two items share many of the same important ideas, concepts, or actions, but those expressed in the smaller text are similar but not identical to the most important in the larger text.", "labels": [], "entities": []}, {"text": "2. The two items have dissimilar meaning, but the shared concepts, ideas, and actions in the smaller text are related (but not similar) to those of the large text.", "labels": [], "entities": []}, {"text": "1. The two items describe dissimilar concepts, ideas and actions, but might be likely to be found together in a longer document on the same topic.", "labels": [], "entities": []}, {"text": "0. The two items do not mean the same thing and are not on the same topic.", "labels": [], "entities": []}, {"text": "All categories were translated into Swedish.", "labels": [], "entities": []}, {"text": "Even though presented results that favour choosing 3 ordinal categories over 5, we believe that the nuances introduced by letting the crowdworkers annotate 5 categories will result in a richer understanding on how to choose the threshold value.", "labels": [], "entities": []}, {"text": "The participants were not trained for the task, i.e. no example task was shown prior to the test.", "labels": [], "entities": []}, {"text": "Studies have shown that training can render more precise results for individual workers (.", "labels": [], "entities": []}, {"text": "As we had no experience on how the ranked categories relate to paraphrases, we chose to omit a training phase for the crowdworkers.", "labels": [], "entities": []}, {"text": "There was no time restriction for the individual tasks, nor for the crowdsourcing test as a whole.", "labels": [], "entities": []}, {"text": "When every aligned text item had been judged, the annotator was able to proceed.", "labels": [], "entities": []}, {"text": "This process was repeated until reaching an end, where all aligned items had been given a ranking, or until leaving the annotation web page by choice.", "labels": [], "entities": []}, {"text": "The preliminary results of the mapping of Dice similarity and participant ranking is presented in with Dice values divided into intervals.", "labels": [], "entities": [{"text": "Dice similarity", "start_pos": 42, "end_pos": 57, "type": "TASK", "confidence": 0.6905091106891632}]}, {"text": "The results of the first and last intervals clearly differ from the remaining intervals due to skewed data, and can in this context be considered outliers.", "labels": [], "entities": []}, {"text": "From interval 0.31-0.40 to interval 0.71-0.80, the Dice similarity seems to stabilise for values over 0.5.", "labels": [], "entities": [{"text": "Dice similarity", "start_pos": 51, "end_pos": 66, "type": "METRIC", "confidence": 0.8386737406253815}]}, {"text": "These prelim- inary results propose that M2 provides a more stable relationship between the human ranked categories and the similarity measures.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Comparison of M1 and M2 regarding descriptive features.", "labels": [], "entities": []}, {"text": " Table 2: Feature values of corpora, alignments and subsets for M1 and M2.", "labels": [], "entities": []}, {"text": " Table 3: Examples sentences per rank category for sentences aligned by M1 and M2.", "labels": [], "entities": []}]}