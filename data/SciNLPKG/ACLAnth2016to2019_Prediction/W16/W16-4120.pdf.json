{"title": [{"text": "Testing the Processing Hypothesis of word order variation using a probabilistic language model", "labels": [], "entities": []}], "abstractContent": [{"text": "This work investigates the application of a measure of surprisal to modeling a grammatical variation phenomenon between near-synonymous constructions.", "labels": [], "entities": []}, {"text": "We investigate a particular variation phenomenon, word order variation in Dutch two-verb clusters, where it has been established that word order choice is affected by processing cost.", "labels": [], "entities": [{"text": "word order variation in Dutch two-verb clusters", "start_pos": 50, "end_pos": 97, "type": "TASK", "confidence": 0.7339149500642504}]}, {"text": "Several multifactorial corpus studies of Dutch verb clusters have used other measures of processing complexity to show that this factor affects word order choice.", "labels": [], "entities": []}, {"text": "This previous work allows us to compare the surprisal measure, which is based on constraint satisfaction theories of language modeling, to those previously used measures , which are more directly linked to empirical observations of processing complexity.", "labels": [], "entities": []}, {"text": "Our results show that surprisal does not predict the word order choice by itself, but is a significant predictor when used in a measure of uniform information density (UID).", "labels": [], "entities": [{"text": "word order choice", "start_pos": 53, "end_pos": 70, "type": "TASK", "confidence": 0.6671026349067688}]}, {"text": "This lends support to the view that human language processing is facilitated not so much by predictable sequences of words but more by sequences of words in which information is spread evenly.", "labels": [], "entities": []}], "introductionContent": [{"text": "According to functionalist theories of language, the way humans process language has shaped the grammars of natural languages.", "labels": [], "entities": []}, {"text": "While it is not always clear whether a particular grammatical rule or construction can be viewed as a consequence of general language processing mechanisms, there is certainly evidence suggesting that processing efficiency plays a role -speakers may choose to use different constructions in more complex contexts.", "labels": [], "entities": []}, {"text": "This is particularly clear in contexts where grammatical variation is possible.", "labels": [], "entities": []}, {"text": "Sometimes a speaker can choose between different constructions to express a similar meaning.", "labels": [], "entities": []}, {"text": "A well-known example of two such near-synonymous constructions in English is the dative alternation: or.", "labels": [], "entities": []}, {"text": "When a ditransitive verb is used, a speaker can almost always choose between those two constructions.", "labels": [], "entities": []}, {"text": "For this particular alternation, and others like it, many studies have shown that a wide range of factors affect the choice), including factors related to language processing, and that the choice is not random.", "labels": [], "entities": []}, {"text": "These near-synonymous constructions area particularly interesting case for the study of language processing, because other factors that may affect linguistic form, such as (most aspects of) meaning and grammaticality, are the same across both constructions.", "labels": [], "entities": [{"text": "language processing", "start_pos": 88, "end_pos": 107, "type": "TASK", "confidence": 0.735923558473587}]}, {"text": "Nevertheless, usage differences can be observed between the two alternatives, even when produced by the same speaker.", "labels": [], "entities": []}, {"text": "What remains to explain these differences is other factors such as information structure, other pragmatic factors or (relative) processing complexity.", "labels": [], "entities": []}, {"text": "To be able to take such factors into account, near-synonymous constructions are often studied using (large) text corpora and multifactorial statistical models.", "labels": [], "entities": []}, {"text": "A range of variables that are considered to be empirical operationalizations of relevant factors (e.g. a factor such as DEFINITENESS, which can be related to information structure or processing complexity) are measured for each instance of the construction in the corpus, and modeled statistically.", "labels": [], "entities": [{"text": "DEFINITENESS", "start_pos": 120, "end_pos": 132, "type": "METRIC", "confidence": 0.795967161655426}]}, {"text": "The model can then show how much each of those variables contributes to explaining the variation.", "labels": [], "entities": []}, {"text": "This approach was first taken by for English optional particle movement, studying the alternation between constructions where the particle 'up' is placed before or after the noun phrase: (1) John picked up the book.", "labels": [], "entities": [{"text": "English optional particle movement", "start_pos": 37, "end_pos": 71, "type": "TASK", "confidence": 0.5713522285223007}]}, {"text": "(2) John picked the book up.", "labels": [], "entities": [{"text": "John picked the book up", "start_pos": 4, "end_pos": 27, "type": "DATASET", "confidence": 0.7446078419685364}]}, {"text": "The dative alternation was also studied using this method, by.", "labels": [], "entities": []}, {"text": "The variables that are found to be significant predictors in these multifactorial corpus studies are often related to language processing.", "labels": [], "entities": []}, {"text": "Finding that construction (1) is preferred in contexts that are more difficult to process, proposed the Processing Hypothesis for particle movement: The multitude of variables (most of which are concerned with the direct object NP) that seems to be related to Particle Movement can all be related to the processing effort of the utterance.", "labels": [], "entities": [{"text": "particle movement", "start_pos": 130, "end_pos": 147, "type": "TASK", "confidence": 0.7158701121807098}]}, {"text": "( However, the definition of processing effort or processing complexity used in these studies is generally quite broad.", "labels": [], "entities": []}, {"text": "A wide variety of measures and features that can be linked to processing complexity are used, as well as theoretical notions applying to various domains of language.", "labels": [], "entities": []}, {"text": "While the results of this approach are interesting, it is difficult to generalize over the factors discussed in such studies when so many different things constitute processing complexity.", "labels": [], "entities": []}, {"text": "There are also more specific theories of language processing that are internally consistent and that have been used to account fora range of phenomena.", "labels": [], "entities": []}, {"text": "While they may not coverall domains of linguistic complexity, they help to make the notion of processing effort more directly quantifiable.", "labels": [], "entities": []}, {"text": "This means that they can be used as a single measure, that they can therefore be tested on large corpora.", "labels": [], "entities": []}, {"text": "In this work, we test such a specific theory.", "labels": [], "entities": []}, {"text": "We test a basic implementation of constraint satisfaction models of language processing by applying an n-gram language model to a case of grammatical variation between near-synonymous constructions.", "labels": [], "entities": []}, {"text": "We use this n-gram model as a measure of surprisal, which, according to constraint satisfaction models of language processing, is a measure of processing complexity.", "labels": [], "entities": []}, {"text": "This particular case of variation, Dutch verb clusters, has previously been studied using the type of multifactorial statistical model just described, and significant effects of processing complexity were found in these studies.", "labels": [], "entities": []}, {"text": "By comparing our results to the results of these studies, our study can serve as a test of n-gram language models as a measure of processing complexity, and perhaps even of the surprisal theory it is based on.", "labels": [], "entities": []}, {"text": "We will start by introducing our case study of Dutch verb clusters in section 2.", "labels": [], "entities": [{"text": "Dutch verb clusters", "start_pos": 47, "end_pos": 66, "type": "TASK", "confidence": 0.5351228912671407}]}, {"text": "Section 3 will address models of language processing and how language processing has been argued to affect grammatical variation in previous work.", "labels": [], "entities": []}, {"text": "Section 4 describes our data, in section 5 we describe our language model, and in section 6 we present our results.", "labels": [], "entities": []}, {"text": "The results are discussed in section 7.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: List of factors in the Bloem et al. (in press) model of verb cluster order variation, ranked by  information gain.", "labels": [], "entities": [{"text": "verb cluster order variation", "start_pos": 66, "end_pos": 94, "type": "TASK", "confidence": 0.695745937526226}]}, {"text": " Table 2: Perplexity per word (PPW) results for the two word orders, over all test-set clusters.", "labels": [], "entities": [{"text": "Perplexity per word (PPW)", "start_pos": 10, "end_pos": 35, "type": "METRIC", "confidence": 0.8919320404529572}]}, {"text": " Table 3: Perplexity per word (PPW) results for various conditions, over all test-set clusters.", "labels": [], "entities": [{"text": "Perplexity per word (PPW)", "start_pos": 10, "end_pos": 35, "type": "METRIC", "confidence": 0.7920711040496826}]}]}