{"title": [{"text": "Storyline detection and tracking using Dynamic Latent Dirichlet Allocation", "labels": [], "entities": [{"text": "Storyline detection", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.6429865062236786}]}], "abstractContent": [{"text": "In this paper we consider the problem of detecting and tracking storylines overtime using news text corpora.", "labels": [], "entities": [{"text": "detecting and tracking storylines overtime", "start_pos": 41, "end_pos": 83, "type": "TASK", "confidence": 0.7448235630989075}]}, {"text": "World wide web creates vast amounts of information and handling, managing and utilizing this information is difficult without having systems that are able to identify trends, arcs and stories and how they evolve through time.", "labels": [], "entities": []}, {"text": "The proposed approach utilizes a dynamic version of Latent Dirichlet Allocation (DLDA) over discrete time steps and makes it possible to identify topics within storylines as they appear and track them through time.", "labels": [], "entities": [{"text": "Latent Dirichlet Allocation (DLDA", "start_pos": 52, "end_pos": 85, "type": "METRIC", "confidence": 0.8329269766807557}]}, {"text": "Moreover, a graphical tool for visualizing topics and changes is implemented and allows for easy navigation through the topics and their corresponding documents.", "labels": [], "entities": []}, {"text": "Experimental analysis on Reuters RCV1 corpus reveals that the proposed approach can be effectively used as a tool for identifying turning points in sto-rylines and their evolutions while at the same time allowing for an efficient visu-alization.", "labels": [], "entities": [{"text": "Reuters RCV1 corpus", "start_pos": 25, "end_pos": 44, "type": "DATASET", "confidence": 0.9712043404579163}]}], "introductionContent": [{"text": "Growth of internet came along with an increasingly complex amount of text data from emails, news sources, forums, etc.", "labels": [], "entities": []}, {"text": "As a consequence, it is impossible for individuals to keep track of all relevant storylines and moreover to detect changes in emerging trends or topics.", "labels": [], "entities": []}, {"text": "Many stakeholders (companies, individuals, policy makers, etc.) would be interested to harness the amount of free text data available in the web in order to develop intelligent algorithms that are able to react to emerging topics as fast as possible and at the same time track existing topics overlong time spans.", "labels": [], "entities": []}, {"text": "There are many techniques about topic extraction like Nonnegative Matrix Factorization (NMF)) or Latent Dirichlet Allocation (LDA) () but there are not many extensions to dynamic data handling.", "labels": [], "entities": [{"text": "topic extraction", "start_pos": 32, "end_pos": 48, "type": "TASK", "confidence": 0.774088054895401}, {"text": "dynamic data handling", "start_pos": 171, "end_pos": 192, "type": "TASK", "confidence": 0.6913254857063293}]}, {"text": "Time dependent modeling of documents can be computationally expensive and complex) and despite the fact that such approaches can be effective, none of these effectively handles the visualization issue which can make results more intuitive.", "labels": [], "entities": []}, {"text": "Thus, effective approaches in terms of both computation and visualization of the results need to be pursued.", "labels": [], "entities": []}, {"text": "This research work aims at implementing a technique to present stories and their changes from a news items flow by detecting and tracking topics through time.", "labels": [], "entities": []}, {"text": "Results will be visualized and evaluated using the (fully annotated and immediately available) RCV1 Reuters corpus (810.000 documents) which is partly utilized in this work.", "labels": [], "entities": [{"text": "RCV1 Reuters corpus", "start_pos": 95, "end_pos": 114, "type": "DATASET", "confidence": 0.9804874658584595}]}, {"text": "The remainder of the paper is organized as follows.", "labels": [], "entities": []}, {"text": "Section 2 presents an overview of current research work in the area.", "labels": [], "entities": []}, {"text": "The proposed approach is described in Section 3, while experimental results are presented in Section 4.", "labels": [], "entities": []}, {"text": "Finally, Section 5 concludes the paper and presents future improvement work.", "labels": [], "entities": []}], "datasetContent": [{"text": "The process described in Section 3.1 is applied to the text content of the news articles from August and September 1996 of the RCV1 corpus () to obtain a vocabulary containing terms, that are as meaningful and descriptive as possible while eliminating as much noise, consisting of not descriptive or ambiguous terms, as possible.", "labels": [], "entities": [{"text": "RCV1 corpus", "start_pos": 127, "end_pos": 138, "type": "DATASET", "confidence": 0.8516811430454254}]}, {"text": "The first two months of the RCV1 corpus contain 83.650 documents, which is about 10% of the corpus documents overall.", "labels": [], "entities": [{"text": "RCV1 corpus", "start_pos": 28, "end_pos": 39, "type": "DATASET", "confidence": 0.9749626219272614}]}], "tableCaptions": [{"text": " Table 1: Terms and vocabulary for documents  of August and September 1996 of RCV1", "labels": [], "entities": [{"text": "RCV1", "start_pos": 78, "end_pos": 82, "type": "DATASET", "confidence": 0.5662683248519897}]}, {"text": " Table 2: Number of documents per week in Au- gust and September 1996 of RVC1", "labels": [], "entities": [{"text": "Au- gust and September 1996 of", "start_pos": 42, "end_pos": 72, "type": "DATASET", "confidence": 0.9236230083874294}, {"text": "RVC1", "start_pos": 73, "end_pos": 77, "type": "DATASET", "confidence": 0.8544484972953796}]}, {"text": " Table 6: Topic cosine similarities for both top- ics, Iraq and Kurdish Civil War, for each time  step", "labels": [], "entities": []}]}