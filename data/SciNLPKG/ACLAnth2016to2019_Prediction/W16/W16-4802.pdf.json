{"title": [{"text": "Discriminating similar languages: experiments with linear SVMs and neural networks", "labels": [], "entities": []}], "abstractContent": [{"text": "This paper describes the systems we experimented with for participating in the discriminating between similar languages (DSL) shared task 2016.", "labels": [], "entities": []}, {"text": "We submitted results of a single system based on support vector machines (SVM) with linear kernel and using character ngram features, which obtained the first rank at the closed training track for test set A.", "labels": [], "entities": []}, {"text": "Besides the linear SVM, we also report additional experiments with a number of deep learning architectures.", "labels": [], "entities": []}, {"text": "Despite our intuition that non-linear deep learning methods should be advantageous, linear models seem to fare better in this task, at least with the amount of data and the amount of effort we spent on tuning these models.", "labels": [], "entities": []}], "introductionContent": [{"text": "Automatic language identification if often considered a solved task.", "labels": [], "entities": [{"text": "Automatic language identification", "start_pos": 0, "end_pos": 33, "type": "TASK", "confidence": 0.6384476621945699}]}, {"text": "Very high levels of accuracies in automatic identification of languages from text had been reported in studies over two decades ago.", "labels": [], "entities": [{"text": "automatic identification of languages from text", "start_pos": 34, "end_pos": 81, "type": "TASK", "confidence": 0.7891840736071268}]}, {"text": "For example, reports over 99 % accuracy for test strings of 100 characters, the reported accuracy goes up to 99.90 % for 500-character strings.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 31, "end_pos": 39, "type": "METRIC", "confidence": 0.9977777600288391}, {"text": "accuracy", "start_pos": 89, "end_pos": 97, "type": "METRIC", "confidence": 0.990328848361969}]}, {"text": "Even short strings of 20 characters were enough for over 90 % accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 62, "end_pos": 70, "type": "METRIC", "confidence": 0.9973800778388977}]}, {"text": "The results above were obtained when a training set of 50k characters were considered 'large' training data, and many of the machine learning methods were in their infancy.", "labels": [], "entities": []}, {"text": "Considering the amount of data, computation power and the methods we have at hand today, the automatic language identification task is, indeed, an almost solved problem.", "labels": [], "entities": [{"text": "automatic language identification task", "start_pos": 93, "end_pos": 131, "type": "TASK", "confidence": 0.7179983854293823}]}, {"text": "However, there are at least two cases where we are not close to the solution yet.", "labels": [], "entities": []}, {"text": "The first is when the languages to be discriminated are closely related (, and the second is when the documents of interest contain multiple languages, including code mixing or code switching.", "labels": [], "entities": [{"text": "code mixing", "start_pos": 162, "end_pos": 173, "type": "TASK", "confidence": 0.6882258653640747}, {"text": "code switching", "start_pos": 177, "end_pos": 191, "type": "TASK", "confidence": 0.6994580328464508}]}, {"text": "Discriminating between Similar Languages (DSL) shared task () aims to address the first issue.", "labels": [], "entities": [{"text": "Discriminating between Similar Languages (DSL) shared task", "start_pos": 0, "end_pos": 58, "type": "TASK", "confidence": 0.8244252138667636}]}, {"text": "This paper describes the models we experimented with for participating in the DSL shared task.", "labels": [], "entities": [{"text": "DSL shared task", "start_pos": 78, "end_pos": 93, "type": "TASK", "confidence": 0.5915279189745585}]}, {"text": "In this work, we describe and report results from two families of models.", "labels": [], "entities": []}, {"text": "The first family is the linear models with character-ngram features, including the linear support vector machine (SVM) model which obtained the first rank at the closed training track for test set A, and obtained fair results in other test sets despite the fact that it was not particularly optimized for them.", "labels": [], "entities": []}, {"text": "In our experiments, the (simple) linear models with character ngram features were proven difficult to beat.", "labels": [], "entities": []}, {"text": "The second family of models we experimented with area number of deep neural network architectures.", "labels": [], "entities": []}, {"text": "These models has been our initial motivation for participating in the shared task.", "labels": [], "entities": []}, {"text": "Besides their recent success in many natural language processing methods, these models are interesting for discriminating between similar languages because of (at least) two reasons.", "labels": [], "entities": []}, {"text": "First, it seems success in discriminating between distant/different languages and discriminating between similar languages require different types of models and/or features.", "labels": [], "entities": []}, {"text": "This observation is supported by the fact that one of the most popular and successful approaches in earlier DSL shared tasks has been hierarchical systems that use different models for discriminating language groups and individual languages within each group ().", "labels": [], "entities": []}, {"text": "The potential benefit of a deep learning model here is the possibility of building a single (hierarchical) model that addresses both issues jointly.", "labels": [], "entities": []}, {"text": "The second potential benefit of deep learning architectures comes from the fact that, unlike linear models, they can capture non-additive non-linear interactions between input features.", "labels": [], "entities": []}, {"text": "For example, although none of the features marked with boldface in (1) below are conclusive for 3-way discrimination between Bosnian (1a), Croatian (1b) and Serbian (1c), a non-linear combination of these features are definitely useful.", "labels": [], "entities": []}, {"text": "Svako ima pravo na \u017eivot, slobodu i li\u010dnu sigurnost. b. \u02c7 Clanak 3.", "labels": [], "entities": [{"text": "\u02c7 Clanak 3", "start_pos": 56, "end_pos": 66, "type": "DATASET", "confidence": 0.7912182807922363}]}, {"text": "Svatko ima pravo na \u017eivot, slobodu i osobnu sigurnost. c. \u02c7 Clan 3.", "labels": [], "entities": [{"text": "\u02c7 Clan 3", "start_pos": 58, "end_pos": 66, "type": "DATASET", "confidence": 0.7649074594179789}]}, {"text": "Svako ima pravo na \u017eivot, slobodu i li\u010dnu bezb(j)ednost.", "labels": [], "entities": []}, {"text": "Everyone has the right to life, liberty and security of person.", "labels": [], "entities": []}, {"text": "As a result, given enough training data and appropriate model architecture, we expect deep networks to perform well in discriminating both languages across the language groups and languages within the language groups.", "labels": [], "entities": []}, {"text": "Below, we describe both family of models in detail (Section 2), report results of both on the shared task training data (Section 3), and discuss the results obtained (Section 4).", "labels": [], "entities": []}], "datasetContent": [{"text": "This section presents the results obtained with the approaches described in Section 2.", "labels": [], "entities": []}, {"text": "We first introduce the data sets used briefly.", "labels": [], "entities": []}, {"text": "Then we present the result we received from the shared task organizers, followed by the results from the models that we did not submit to the shared task.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: The DSL 2016 data set for the task 1. The number of documents in both training (18 000)  and development (2 000) sets were balanced. The columns labeled 'characters' and 'tokens' present the  average number of non-space characters and white-space-separated tokens for the documents belonging  to each language variety in the training set.", "labels": [], "entities": [{"text": "DSL 2016 data set", "start_pos": 14, "end_pos": 31, "type": "DATASET", "confidence": 0.9545308500528336}]}, {"text": " Table 2: The DSL 2016 data set for the task 2. The column 'documents' number of documents that belong  to each language variety in the training set. The columns labeled 'characters' and 'tokens' present the  average number of non-space characters and white-space-separated tokens for documents belonging to  each language variety.", "labels": [], "entities": [{"text": "DSL 2016 data set", "start_pos": 14, "end_pos": 31, "type": "DATASET", "confidence": 0.940161406993866}]}, {"text": " Table 4: Confusion table for task 1, test set A. The language labels are explained in Table 1.", "labels": [], "entities": []}, {"text": " Table 3. Gulf variety seems to be difficult to identify for the  system, without a clear pattern. We also observe a relatively poor recall for the North African variety  which is mostly confused with, probably not surprisingly, Egyptian Arabic.", "labels": [], "entities": [{"text": "recall", "start_pos": 133, "end_pos": 139, "type": "METRIC", "confidence": 0.9980354905128479}]}, {"text": " Table 6: Confusion table for test set C. The language labels are explained in Table 2.", "labels": [], "entities": []}]}