{"title": [{"text": "Automatic Verification and Augmentation of Multilingual Lexicons", "labels": [], "entities": [{"text": "Automatic Verification and Augmentation of Multilingual Lexicons", "start_pos": 0, "end_pos": 64, "type": "TASK", "confidence": 0.5680502780846187}]}], "abstractContent": [{"text": "We present an approach for automatic verification and augmentation of multilingual lexica.", "labels": [], "entities": []}, {"text": "We exploit existing parallel and monolingual corpora to extract multilingual correspondents via tri-angulation.", "labels": [], "entities": []}, {"text": "We demonstrate the efficacy of our approach on two publicly available resources: Tharwa, a three-way lexicon comprising Dialectal Arabic, Modern Standard Arabic and English lemmas among other information (Diab et al., 2014); and BabelNet, a multilingual thesaurus comprising over 276 languages including Arabic variant entries (Navigli and Ponzetto, 2012).", "labels": [], "entities": []}, {"text": "Our automated approach yields an F1-score of 71.71% in generating correct multilingual correspondents against gold Tharwa, and 54.46% against gold BabelNet without any human intervention .", "labels": [], "entities": [{"text": "F1-score", "start_pos": 33, "end_pos": 41, "type": "METRIC", "confidence": 0.9997178912162781}]}], "introductionContent": [{"text": "Machine readable multilingual lexica are typically created by a combination of manual and automatic (semi-automatic) techniques.", "labels": [], "entities": []}, {"text": "This illustrates the need for continuous verification of the quality of the lexica during the development process.", "labels": [], "entities": []}, {"text": "Approaches exploited for lexicon evaluation and verification mainly comprise manual assessment and human verification.", "labels": [], "entities": []}, {"text": "This process is expensive and poses several limitations in terms of domain coverage as well as the amount of data that can be manually evaluated.", "labels": [], "entities": []}, {"text": "Hence, efforts to automate the evaluation process and reduce manual annotation expenses are quite desireable.", "labels": [], "entities": []}, {"text": "Researchers have mainly resorted to using manual evaluation to verify coverage, automatically extend and measure accuracy of different lexical resources such as multilingual lexica and WordNets.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 113, "end_pos": 121, "type": "METRIC", "confidence": 0.99220871925354}]}, {"text": "For example, propose an approach for extracting an Arabic-English dictionary while exploiting different human annotated samples to measure accuracy of the extracted dictionary.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 139, "end_pos": 147, "type": "METRIC", "confidence": 0.9986334443092346}]}, {"text": "De use human annotated samples to measure accuracy of the multilingual dictionary they extract.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 42, "end_pos": 50, "type": "METRIC", "confidence": 0.9989218711853027}]}, {"text": "More recently, Navigli and Ponzetto (2012) benefit from manual evaluation by expert annotators to assess coverage of additional lexicalizations provided by their resource and not covered in existing lexical knowledge bases.", "labels": [], "entities": []}, {"text": "In this paper, we devise a framework for automatic verification and augmentation of multilingual lexica using evidence leveraging parallel and monolingual corpora.", "labels": [], "entities": []}, {"text": "The proposed method is capable of detecting inconsistencies in the lexicon entries and possibly providing/suggesting candidates to replace them.", "labels": [], "entities": []}, {"text": "Accordingly, one can exploit this method to automatically augment multilingual lexica with partially or completely new entries.", "labels": [], "entities": []}, {"text": "Naturally the method lends itself to also bootstrapping multilingual lexica from scratch, however, this is outside the scope of the present work.", "labels": [], "entities": []}, {"text": "We demonstrate the efficacy of our proposed framework in the context of verifying and augmenting a publicly available lexicon that is manually created Tharwa ().", "labels": [], "entities": []}, {"text": "Tharwa is an electronic three-way lexicon comprising Egyptian Dialectal Arabic (EGY), Modern Standard Arabic (MSA) and English correspondents (EN).", "labels": [], "entities": []}, {"text": "The entries in Tharwa are in lemma form.", "labels": [], "entities": [{"text": "Tharwa", "start_pos": 15, "end_pos": 21, "type": "DATASET", "confidence": 0.8544765114784241}]}, {"text": "We show that our approach obtains F1-score of 71.71% in generating multilingual correspondents which match with a gold Tharwa set.", "labels": [], "entities": [{"text": "F1-score", "start_pos": 34, "end_pos": 42, "type": "METRIC", "confidence": 0.9997262358665466}]}, {"text": "We further evaluate our approach against the Arabic entries in BabelNet ().", "labels": [], "entities": []}, {"text": "We show that our automated approach reaches F1-score of 54.46% in generating correct correspondents for BabelNet Arabic entries.", "labels": [], "entities": [{"text": "F1-score", "start_pos": 44, "end_pos": 52, "type": "METRIC", "confidence": 0.9996906518936157}]}], "datasetContent": [{"text": "We measure quality of the correspondents generated by our approach represented in TransDict via two multilingual resources.", "labels": [], "entities": []}, {"text": "BabelNet (Navigli and Ponzetto, 2012), a multilingual semantic network comprising concepts and named entities lexicalized in different languages including MSA, EGY and EN; and, Tharwa, a three-way lexicon containing MSA, EGY and EN correspondents.", "labels": [], "entities": []}, {"text": "All entries in both resources are in lemma form and marked with a POS tag.", "labels": [], "entities": []}, {"text": "BabelNet is comprised of multilingual synsets.", "labels": [], "entities": []}, {"text": "Each synset consists of multilingual senses including MSA, EGY and EN.", "labels": [], "entities": []}, {"text": "First, we iterate overall synsets of type CONCEPT 4 and extract tuples in the form MSA-EN-EGY from each synset which satisfy the following conditions: \u2022 None of MSA, EN and EGY words are out of vocabulary with respect to our MSA, EN and MSA corpora independently;: Precision, recall and F-score of different correspondence learning methods against BabelNet and Tharwa, respectively.", "labels": [], "entities": [{"text": "Precision", "start_pos": 265, "end_pos": 274, "type": "METRIC", "confidence": 0.9833810329437256}, {"text": "recall", "start_pos": 276, "end_pos": 282, "type": "METRIC", "confidence": 0.9990756511688232}, {"text": "F-score", "start_pos": 287, "end_pos": 294, "type": "METRIC", "confidence": 0.999275267124176}]}, {"text": "\u2022 MSA, EN and EGY, each, are not composed of more than a single word.", "labels": [], "entities": [{"text": "EGY", "start_pos": 14, "end_pos": 17, "type": "METRIC", "confidence": 0.6728119254112244}]}, {"text": "We acquired 8381 BabelNet tuples applying the above constraints.", "labels": [], "entities": []}, {"text": "It is worth emphasizing that this evaluation is limited to measuring quality of the generated multilingual correspondents in TransDict.", "labels": [], "entities": []}, {"text": "First constraint ensures that no mismatch happens due to domain divergence.", "labels": [], "entities": []}, {"text": "Also since TransDict contains only single-word correspondents, we limit the set of extracted BabelNet tuples to the singletons.", "labels": [], "entities": []}, {"text": "Tharwa We define a particular subset of the Tharwa lexicon as the gold standard to measure performance of generated correspondents.", "labels": [], "entities": [{"text": "Tharwa", "start_pos": 0, "end_pos": 6, "type": "DATASET", "confidence": 0.8584438562393188}, {"text": "Tharwa lexicon", "start_pos": 44, "end_pos": 58, "type": "DATASET", "confidence": 0.9167617857456207}]}, {"text": "Similar to BabelNet, gold Tharwa contains MSA-EN-EGY tuples from original Tharwa where none of their correspondent words is out of vocabulary with respect to all the MSA, EN and MSA corpora, respectively.", "labels": [], "entities": []}, {"text": "Gold Tharwa obtained according to above conditions contains 19459 rows.", "labels": [], "entities": []}, {"text": "We focus on the three main fields in Tharwa, namely: EGY lemma, MSA lemma, and EN lemma equivalents and their corresponding POS tags.", "labels": [], "entities": [{"text": "EGY lemma", "start_pos": 53, "end_pos": 62, "type": "DATASET", "confidence": 0.8131758272647858}]}, {"text": "This condition ensures that none of the mismatches is caused by domain divergence between Tharwa and TransDict.", "labels": [], "entities": [{"text": "TransDict", "start_pos": 101, "end_pos": 110, "type": "DATASET", "confidence": 0.6669082641601562}]}, {"text": "We have devised the following settings: PARL Only parallel data is used to generate correspondents in TransDict.", "labels": [], "entities": [{"text": "PARL", "start_pos": 40, "end_pos": 44, "type": "METRIC", "confidence": 0.9782465696334839}]}, {"text": "We consider this to be our baseline.", "labels": [], "entities": []}, {"text": "WC This is where we expand the lemmas in a source language (MSA or EGY) using lemma clusters induced over word2vec vectors in addition to PARL.", "labels": [], "entities": []}, {"text": "SYN This is where we expand the lemmas in a source language (MSA or EGY) using cross-lingual synonyms by leveraging cross-lingual CCA (SYN) together with PARL.", "labels": [], "entities": []}, {"text": "EN-WSD This the condition where we expand English lemmas using word sense disambiguation to generate WordNet synsets for the pivot language EN.", "labels": [], "entities": [{"text": "EN-WSD", "start_pos": 0, "end_pos": 6, "type": "DATASET", "confidence": 0.9065407514572144}, {"text": "word sense disambiguation", "start_pos": 63, "end_pos": 88, "type": "TASK", "confidence": 0.6206654111544291}]}, {"text": "We present the results in terms of Precision, Recall and the harmonic mean F1-score.", "labels": [], "entities": [{"text": "Precision", "start_pos": 35, "end_pos": 44, "type": "METRIC", "confidence": 0.9990399479866028}, {"text": "Recall", "start_pos": 46, "end_pos": 52, "type": "METRIC", "confidence": 0.9986664056777954}, {"text": "F1-score", "start_pos": 75, "end_pos": 83, "type": "METRIC", "confidence": 0.5011042356491089}]}, {"text": "fully matched BabelNet/Tharwa entries including POS tag match.", "labels": [], "entities": []}, {"text": "This is the harshest metric to evaluate against.", "labels": [], "entities": []}, {"text": "We note the following observations.We note similar trends across the two evaluation data sets.", "labels": [], "entities": []}, {"text": "In general recall is quite low for BabelNet compared to Tharwa which might be relegated to some domain divergence between our corpora and BabelNet resources where a word might not be out of vocabulary but a sense of a word is hence it is not found in TransDict.", "labels": [], "entities": [{"text": "recall", "start_pos": 11, "end_pos": 17, "type": "METRIC", "confidence": 0.9995452761650085}]}, {"text": "It should be noted that we only constrained the entries in the gold by being in vocabulary for our corpora without checking if the senses were in vocabulary.", "labels": [], "entities": []}, {"text": "We don't observe this effect in Tharwa as much due to the relative sizes of BabelNet (almost 9K entries) and Tharwa (almost 20K entries", "labels": [], "entities": [{"text": "Tharwa", "start_pos": 109, "end_pos": 115, "type": "DATASET", "confidence": 0.921085774898529}]}], "tableCaptions": [{"text": " Table 1: Examples of partially-matched tuples generated by T compared to a Tharwa entry.", "labels": [], "entities": []}, {"text": " Table 2: Precision, recall and F-score of different correspondence learning methods against BabelNet  and Tharwa, respectively.", "labels": [], "entities": [{"text": "Precision", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.998390793800354}, {"text": "recall", "start_pos": 21, "end_pos": 27, "type": "METRIC", "confidence": 0.999160647392273}, {"text": "F-score", "start_pos": 32, "end_pos": 39, "type": "METRIC", "confidence": 0.9990203380584717}]}, {"text": " Table 3: Precision, Recall and F1-score of TransDict dialectal component EGY against Tharwa.", "labels": [], "entities": [{"text": "Precision", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9986207485198975}, {"text": "Recall", "start_pos": 21, "end_pos": 27, "type": "METRIC", "confidence": 0.9976842403411865}, {"text": "F1-score", "start_pos": 32, "end_pos": 40, "type": "METRIC", "confidence": 0.9996405839920044}]}, {"text": " Table 4: Precision, Recall and F1-score of PARL+EN-WSD+EGY-WC+MSA-WC for different number  of word clusters (k=500 and k=9228) and different POS constraints.", "labels": [], "entities": [{"text": "Precision", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9978575110435486}, {"text": "Recall", "start_pos": 21, "end_pos": 27, "type": "METRIC", "confidence": 0.9976508021354675}, {"text": "F1-score", "start_pos": 32, "end_pos": 40, "type": "METRIC", "confidence": 0.9994213581085205}, {"text": "PARL", "start_pos": 44, "end_pos": 48, "type": "METRIC", "confidence": 0.8217701315879822}]}]}