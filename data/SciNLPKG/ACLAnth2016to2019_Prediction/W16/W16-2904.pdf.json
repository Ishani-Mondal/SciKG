{"title": [], "abstractContent": [{"text": "The rapidly growing biomedical literature has been a challenging target for natural language processing algorithms.", "labels": [], "entities": [{"text": "natural language processing algorithms", "start_pos": 76, "end_pos": 114, "type": "TASK", "confidence": 0.7086077705025673}]}, {"text": "One of the tasks these algorithms focus on is called named entity recognition (NER), often employed to tag gene mentions.", "labels": [], "entities": [{"text": "named entity recognition (NER)", "start_pos": 53, "end_pos": 83, "type": "TASK", "confidence": 0.7653205593427023}]}, {"text": "Here we describe anew approach for this task, an approach that uses graph-based semi-supervised learning to train a Conditional Random Field (CRF) model.", "labels": [], "entities": []}, {"text": "Benchmarking it on the BioCreative II Gene Mention tagging task, we achieved statistically significant improvements in F-measure over BANNER, a widely used biomedical NER system.", "labels": [], "entities": [{"text": "BioCreative II Gene Mention tagging task", "start_pos": 23, "end_pos": 63, "type": "TASK", "confidence": 0.7215337703625361}, {"text": "F-measure", "start_pos": 119, "end_pos": 128, "type": "METRIC", "confidence": 0.9960780739784241}, {"text": "BANNER", "start_pos": 134, "end_pos": 140, "type": "METRIC", "confidence": 0.7055404186248779}]}, {"text": "We note that our tool is transductive and modular in nature, and can be integrated with other CRF-based supervised NER tools.", "labels": [], "entities": []}], "introductionContent": [{"text": "Detecting biomedical named entities such as genes and proteins is one of the first steps in many natural language processing systems that analyze biomedical text.", "labels": [], "entities": [{"text": "Detecting biomedical named entities such as genes and proteins", "start_pos": 0, "end_pos": 62, "type": "TASK", "confidence": 0.8356667028533088}]}, {"text": "Finding relations between entities, and expanding knowledge bases are examples of research that highly depend on the accuracy of gene and protein mention tagging.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 117, "end_pos": 125, "type": "METRIC", "confidence": 0.998730480670929}, {"text": "gene and protein mention tagging", "start_pos": 129, "end_pos": 161, "type": "TASK", "confidence": 0.5669150233268738}]}, {"text": "Named entity recognition is typically modelled as a sequence tagging problem.", "labels": [], "entities": [{"text": "Named entity recognition", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.7149257063865662}, {"text": "sequence tagging", "start_pos": 52, "end_pos": 68, "type": "TASK", "confidence": 0.7122247815132141}]}, {"text": "One of the most commonly used models for sequence tagging is a Conditional Random Field (CRF) (.", "labels": [], "entities": [{"text": "sequence tagging", "start_pos": 41, "end_pos": 57, "type": "TASK", "confidence": 0.7333813607692719}]}, {"text": "Many popular and best performing biomedical named entity recognition systems, such as BAN-NER (, and BANNER-CHEMDNER () use CRF as their core machine learning model built on the MALLET toolkit).", "labels": [], "entities": [{"text": "biomedical named entity recognition", "start_pos": 33, "end_pos": 68, "type": "TASK", "confidence": 0.6055212244391441}, {"text": "BAN-NER", "start_pos": 86, "end_pos": 93, "type": "DATASET", "confidence": 0.8349308371543884}]}, {"text": "Inspired by the success of graph-based semisupervised learning methods in other NLP tasks (), we integrated the graph based semi-supervised algorithm of and adapted their approach to improve on the results from BANNER.", "labels": [], "entities": [{"text": "BANNER", "start_pos": 211, "end_pos": 217, "type": "DATASET", "confidence": 0.9103684425354004}]}, {"text": "We show that our approach achieves a statistically significant improvement in terms of F-measure on the BioCreative II dataset for gene mention tagging.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 87, "end_pos": 96, "type": "METRIC", "confidence": 0.9986010193824768}, {"text": "BioCreative II dataset", "start_pos": 104, "end_pos": 126, "type": "DATASET", "confidence": 0.8339584072430929}, {"text": "gene mention tagging", "start_pos": 131, "end_pos": 151, "type": "TASK", "confidence": 0.6578474541505178}]}, {"text": "Semi-supervised learning for gene mention tagging is not without precedent.", "labels": [], "entities": [{"text": "gene mention tagging", "start_pos": 29, "end_pos": 49, "type": "TASK", "confidence": 0.8384806513786316}]}, {"text": "There has been several semi-supervised approaches for the gene mention task and they have always been more successful than fully supervised approaches (.", "labels": [], "entities": [{"text": "gene mention task", "start_pos": 58, "end_pos": 75, "type": "TASK", "confidence": 0.8750628630320231}]}, {"text": "used a semi-supervised approach, Alternative Structure Optimization or ASO, in the BioCreative II gene mention shared task along with other extensions, such as using a lexicon or combining several classifiers.", "labels": [], "entities": [{"text": "Alternative Structure Optimization or ASO", "start_pos": 33, "end_pos": 74, "type": "TASK", "confidence": 0.6484875619411469}, {"text": "BioCreative II gene mention shared task", "start_pos": 83, "end_pos": 122, "type": "DATASET", "confidence": 0.779956579208374}]}, {"text": "ASO ranked first among all competitors in the shared task competition 2007.", "labels": [], "entities": []}, {"text": "Ando reported usage of unlabeled data as the most useful part of his system improving the F-measure of the baseline by 2.09 points where the complete (winning) system had a total improvement of 3.23 points over the baseline CRF.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 90, "end_pos": 99, "type": "METRIC", "confidence": 0.9986205101013184}]}, {"text": "used conditional entropy over the unlabeled data combined with the conditional likelihood over the labeled data in the objective function of CRF ().", "labels": [], "entities": []}, {"text": "trained word representations using Brown clustering) and word2vec () on MEDLINE and PMC document collections and used them as features along with traditional features in a CRF.", "labels": [], "entities": [{"text": "MEDLINE and PMC document collections", "start_pos": 72, "end_pos": 108, "type": "DATASET", "confidence": 0.7337069809436798}]}, {"text": "Like many of these approaches we also use unlabeled data to augment our baseline CRF model.", "labels": [], "entities": []}, {"text": "In all these previous studies the unlabelled data was orders of magnitude more than labelled data and distinct from the test data.", "labels": [], "entities": []}, {"text": "In this paper we take a transductive approach and use the test set as our unlabelled data.", "labels": [], "entities": []}, {"text": "Moreover, our approach is orthogonal to all these approaches and can be used to augment many of them.", "labels": [], "entities": []}, {"text": "This approach can be easily implemented as a post-processing step in any system that uses a CRF model.", "labels": [], "entities": []}, {"text": "Examples of such systems include and BANNER-CHEMNDNER ().", "labels": [], "entities": [{"text": "BANNER-CHEMNDNER", "start_pos": 37, "end_pos": 53, "type": "METRIC", "confidence": 0.9603433609008789}]}, {"text": "These tools have achieved the highest F-scores in the literature after ASO.", "labels": [], "entities": [{"text": "F-scores", "start_pos": 38, "end_pos": 46, "type": "METRIC", "confidence": 0.9981800317764282}, {"text": "ASO", "start_pos": 71, "end_pos": 74, "type": "DATASET", "confidence": 0.5250762701034546}]}, {"text": "Our approach relies on the extraction of label distributions from the CRF and augments the decoding algorithm to incorporate the new information about gene mentions from the graph-based learning approach we describe in this paper.", "labels": [], "entities": []}], "datasetContent": [{"text": "We show improvements over BANNER on the dataset of BioCreative II Gene Mention Tagging Task.", "labels": [], "entities": [{"text": "BANNER", "start_pos": 26, "end_pos": 32, "type": "METRIC", "confidence": 0.9686715006828308}, {"text": "BioCreative II Gene Mention Tagging Task", "start_pos": 51, "end_pos": 91, "type": "TASK", "confidence": 0.7247523615757624}]}, {"text": "This data set contains 15,000 training sentences and 5,000 test sentences.", "labels": [], "entities": []}, {"text": "Annotations are given by the starting character index and finishing character index of the gene in the sentence (space characters are ignored).", "labels": [], "entities": [{"text": "Annotations", "start_pos": 0, "end_pos": 11, "type": "METRIC", "confidence": 0.7865723967552185}]}, {"text": "Some sentences have alternative annotations presented in a separate file.", "labels": [], "entities": []}, {"text": "The upper part of shows the results of BANNER; Graph-Based SSL without postprocessing; and Graph-Based SSL with postprocessing.", "labels": [], "entities": [{"text": "BANNER", "start_pos": 39, "end_pos": 45, "type": "METRIC", "confidence": 0.6141881942749023}]}, {"text": "The hyper-parameters of GraphBased SSL were chosen by cross-validation over different train/test splits with different hyperparameters tested for each split (\u03b1 = 0.02, \u00b5 = 10 \u22126 , \u03bd = 10 \u22124 , and number of iterations = 2).", "labels": [], "entities": [{"text": "GraphBased SSL", "start_pos": 24, "end_pos": 38, "type": "DATASET", "confidence": 0.7298532128334045}]}, {"text": "shows that the improvement we get in F-measure is due to better precision which is further boosted by dropping the candidates with unmatched parentheses (which is our only postprocessing step).", "labels": [], "entities": [{"text": "F-measure", "start_pos": 37, "end_pos": 46, "type": "METRIC", "confidence": 0.8500796556472778}, {"text": "precision", "start_pos": 64, "end_pos": 73, "type": "METRIC", "confidence": 0.9993345141410828}]}, {"text": "The lower part of puts our method in context.", "labels": [], "entities": []}, {"text": "Although our method is competitive with these best performing methods in the literature, it has not outperformed any of them other than BANNER.", "labels": [], "entities": [{"text": "BANNER", "start_pos": 136, "end_pos": 142, "type": "DATASET", "confidence": 0.7014901638031006}]}, {"text": "Its precision however, is better than all other methods with the exception of Gimli.", "labels": [], "entities": [{"text": "precision", "start_pos": 4, "end_pos": 13, "type": "METRIC", "confidence": 0.9995833039283752}]}, {"text": "It would be interesting to integrate the graph-based approach to the ones with CRF as their machine   learning core (BANNER-ChemdNER, Gimli, and the approach of ( ) to further test the utility of the graph approach.", "labels": [], "entities": [{"text": "BANNER-ChemdNER", "start_pos": 117, "end_pos": 132, "type": "METRIC", "confidence": 0.5962939858436584}]}], "tableCaptions": [{"text": " Table 3: Graph-based SSL improves BANNER by increasing the precision.", "labels": [], "entities": [{"text": "SSL", "start_pos": 22, "end_pos": 25, "type": "TASK", "confidence": 0.7622447609901428}, {"text": "BANNER", "start_pos": 35, "end_pos": 41, "type": "METRIC", "confidence": 0.7702233195304871}, {"text": "precision", "start_pos": 60, "end_pos": 69, "type": "METRIC", "confidence": 0.999526858329773}]}]}