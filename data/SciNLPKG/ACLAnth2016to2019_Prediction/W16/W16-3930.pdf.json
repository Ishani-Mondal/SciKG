{"title": [{"text": "Geolocation Prediction in Twitter Using Location Indicative Words and Textual Features", "labels": [], "entities": [{"text": "Geolocation Prediction", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.751395970582962}]}], "abstractContent": [{"text": "Knowing the location of asocial media user and their posts is important for various purposes, such as the recommendation of location-based items/services, and locality detection of cri-sis/disasters.", "labels": [], "entities": [{"text": "locality detection of cri-sis/disasters", "start_pos": 159, "end_pos": 198, "type": "TASK", "confidence": 0.8342805604139963}]}, {"text": "This paper describes our submission to the shared task \"Geolocation Prediction in Twitter\" of the 2nd Workshop on Noisy User-generated Text.", "labels": [], "entities": [{"text": "Geolocation Prediction in Twitter\" of the 2nd Workshop on Noisy User-generated Text", "start_pos": 56, "end_pos": 139, "type": "TASK", "confidence": 0.8105506713573749}]}, {"text": "In this shared task, we propose an algorithm to predict the location of Twitter users and tweets using a multinomial Naive Bayes classifier trained on Location Indicative Words and various textual features (such as city/country names, #hashtags and @mentions).", "labels": [], "entities": []}, {"text": "We compared our approach against various baselines based on Location Indicative Words, city/country names, #hashtags and @mentions as individual feature sets, and experimental results show that our approach outperforms these baselines in terms of classification accuracy, mean and median error distance.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 262, "end_pos": 270, "type": "METRIC", "confidence": 0.9600390195846558}, {"text": "mean and median error distance", "start_pos": 272, "end_pos": 302, "type": "METRIC", "confidence": 0.797839367389679}]}], "introductionContent": [{"text": "Determining the location of asocial media user and where a message is posted from is important for location-based recommendation (, crisis detection and management, detecting location-centric communities (, demographics analysis ( and targeted advertising.", "labels": [], "entities": [{"text": "crisis detection and management", "start_pos": 132, "end_pos": 163, "type": "TASK", "confidence": 0.7766472846269608}]}, {"text": "This work aims to assign a geographical location (most probable location from a list of pre-defined locations, such as cities or countries) to apiece of text.", "labels": [], "entities": []}, {"text": "For this textual content, we focus on the Twitter social networking site, which boosts more than 500 million tweets posted on a daily basis.", "labels": [], "entities": []}, {"text": "In Twitter, tweets are short messages of 140 characters or less, and can also include #hashtags to indicate the topic of the tweet and @mentions to refer to another user.", "labels": [], "entities": []}, {"text": "shows an example of a tweet that contains a text message with a mention of @westernbulldogs, two hashtags of #7NewsMelb and #bemorebulldog, along with an embedded image.", "labels": [], "entities": []}, {"text": "Despite the popularity of Twitter and a large volume of tweets, only a small amount of tweets (les than 1%) are geotagged with the location that they were posted from (, thus restricting the usability of many tweets for location-based services and studies.", "labels": [], "entities": []}, {"text": "Due to this motivating factor, the geolocation prediction of tweets and Twitter users have garnered immense interest in recent years.", "labels": [], "entities": [{"text": "geolocation prediction", "start_pos": 35, "end_pos": 57, "type": "TASK", "confidence": 0.7206185460090637}]}, {"text": "In this paper, we describe our submitted geolocation prediction algorithm for the shared task \"Geolocation Prediction in Twitter\" in the 2nd Workshop on Noisy User-generated Text (.", "labels": [], "entities": [{"text": "geolocation prediction", "start_pos": 41, "end_pos": 63, "type": "TASK", "confidence": 0.7503280341625214}, {"text": "Geolocation Prediction", "start_pos": 95, "end_pos": 117, "type": "TASK", "confidence": 0.7945564985275269}]}, {"text": "Our algorithm utilizes a multinomial Naive Bayes classifier, using a textual feature set that includes a combination of location indicative words, city/country names, #hashtags and @mentions, which are automatically learnt from a large collection of Twitter data.", "labels": [], "entities": []}, {"text": "Here, we use two examples respectively from tweet level and user level to describe the basic application of our method.", "labels": [], "entities": []}, {"text": "From tweet level, for instance, \"I plan to take a tram to the federation square this arvo to watch the cricket...\" is assigned to Melbourne, Victoria, Australia.", "labels": [], "entities": []}, {"text": "The text doesn't contain gazetted terms such as \"Melbourne\", but our geotagger is able to geolocate this text on basis of location indicative words like \"tram\", \"federation square\" and \"arvo\" and other textual features.", "labels": [], "entities": [{"text": "Melbourne", "start_pos": 49, "end_pos": 58, "type": "DATASET", "confidence": 0.9456446766853333}]}, {"text": "From the user level, we can see an example from.", "labels": [], "entities": []}, {"text": "In, the input is the twitter ID of Barack Obama (the president of United States), and the predicted location is Washington.: A simple demo from the Twitter user level prediction task.", "labels": [], "entities": []}], "datasetContent": [{"text": "To evaluate these six algorithms, we use the following evaluation metrics: \u2022 Accuracy.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 77, "end_pos": 85, "type": "METRIC", "confidence": 0.9993602633476257}]}, {"text": "The proportion of tweets (and users) that is correctly classified to their home location (city), out of all tweets (and users).", "labels": [], "entities": []}, {"text": "This metric allows us to measure the correctness of our prediction algorithm in terms of percentage of correct labelled cities.", "labels": [], "entities": []}, {"text": "The average error, in terms of distance, between the predicted cities and the ground truth cities of the tweets (and users).", "labels": [], "entities": []}, {"text": "Even for mislabelled cities, a mislabelled city that is nearer to the ground truth city is deemed better, e.g., New York mislabelled as Chicago, is considered better than New York mislabelled as London.", "labels": [], "entities": []}, {"text": "This metric aims to measure this aspect.", "labels": [], "entities": []}, {"text": "The median error, in terms of distance, between the predicted cities and the ground truth cities of the tweets (and users).", "labels": [], "entities": []}, {"text": "Similar to the Mean Error Distance, except that we are measuring the error distance in terms of median values  In this section, we describe the dataset used in our experiment, highlight our experimental setup and discuss the key results of our proposed algorithm and various baselines.", "labels": [], "entities": [{"text": "Mean Error Distance", "start_pos": 15, "end_pos": 34, "type": "METRIC", "confidence": 0.9539719025293986}, {"text": "error distance", "start_pos": 69, "end_pos": 83, "type": "METRIC", "confidence": 0.9198675453662872}]}, {"text": "As part of the shared task, a total of 12 million tweets were made available, which the participants have to retrieve via the Twitter API.", "labels": [], "entities": []}, {"text": "However, due to inactive Twitter accounts, deleted tweets and time constraint, we were only able to crawl a total of 9.05 million tweets.", "labels": [], "entities": []}, {"text": "Similarly, for the validation dataset, we were only able to crawl 7,215 users and 7,789 tweets out of the 10,000 users and 10,000 tweets.", "labels": [], "entities": [{"text": "validation", "start_pos": 19, "end_pos": 29, "type": "TASK", "confidence": 0.9586242437362671}]}, {"text": "As the testing dataset was directly provided by the organizers, we were able to experiment on all 10,000 users and tweets.", "labels": [], "entities": []}, {"text": "shows the summary statistics of our training, validation, and testing dataset.", "labels": [], "entities": []}, {"text": "Our experimental setup is aligned to the setup of the shared task and comprises three main phrases.", "labels": [], "entities": []}, {"text": "In the first phrase, we use the training dataset to extract our various feature sets and train our geolocation predictors (MNB-LIW, MNB-CC, MNB-HASH, MNB-MENT, MNB-ALL, MNB-PART).", "labels": [], "entities": [{"text": "MNB-PART", "start_pos": 169, "end_pos": 177, "type": "DATASET", "confidence": 0.8517237305641174}]}, {"text": "In the second phase, we evaluate our trained predictors (models) on the validation dataset.", "labels": [], "entities": []}, {"text": "For the final phrase, we rerun our various predictors on the testing dataset.", "labels": [], "entities": []}, {"text": "As the ground truth labels for the testing dataset was made available only after the shared task, we selected the best performing predictor (MNB-PART) from the second phrase and submitted it to the shared task for the third phrase.", "labels": [], "entities": []}, {"text": "shows the geolocation prediction results for the tweet-level, in terms of accuracy, mean and median error distances.", "labels": [], "entities": [{"text": "geolocation prediction", "start_pos": 10, "end_pos": 32, "type": "TASK", "confidence": 0.7190662026405334}, {"text": "accuracy", "start_pos": 74, "end_pos": 82, "type": "METRIC", "confidence": 0.9995707869529724}]}, {"text": "The results show that our proposed MNB-PART algorithm outperforms all baselines for the validation and testing datasets, in terms of all three evaluation metrics.", "labels": [], "entities": []}, {"text": "In particular, MNB-PART shows a relative improvement of more than 16% compared to MNB-LIW in terms of accuracy, and offers predictions with less than half the mean error distances than that of MNB-LIW.", "labels": [], "entities": [{"text": "MNB-PART", "start_pos": 15, "end_pos": 23, "type": "DATASET", "confidence": 0.6249492168426514}, {"text": "accuracy", "start_pos": 102, "end_pos": 110, "type": "METRIC", "confidence": 0.9995325803756714}]}, {"text": "Similarly, shows the user-level geolocation prediction results, in terms of the same three evaluation metrics.", "labels": [], "entities": [{"text": "user-level geolocation prediction", "start_pos": 21, "end_pos": 54, "type": "TASK", "confidence": 0.5905400017897288}]}, {"text": "In terms of accuracy, MNB-PART shows a relative improvement of 7.1% over MNB-LIW for the testing dataset, while MNB-LIW out-performs MNB-PART by 4.5% for the validation dataset.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 12, "end_pos": 20, "type": "METRIC", "confidence": 0.9995670914649963}]}, {"text": "In terms of mean and median error distances, MNB-PART incurs less than half the mean error distances and less than two-thirds of the median error distances for the testing dataset.", "labels": [], "entities": [{"text": "mean and median error distances", "start_pos": 12, "end_pos": 43, "type": "METRIC", "confidence": 0.759113484621048}, {"text": "mean error distances", "start_pos": 80, "end_pos": 100, "type": "METRIC", "confidence": 0.8367702762285868}]}], "tableCaptions": [{"text": " Table 2: Results for Tweet-level Geolocation Prediction. The bolded results indicate the best performing  statistics (highest value for accuracy and lowest value for mean/median error) for the validation and  testing set.", "labels": [], "entities": [{"text": "Tweet-level Geolocation Prediction", "start_pos": 22, "end_pos": 56, "type": "TASK", "confidence": 0.7708836992581686}, {"text": "accuracy", "start_pos": 137, "end_pos": 145, "type": "METRIC", "confidence": 0.9985873699188232}, {"text": "mean/median error", "start_pos": 167, "end_pos": 184, "type": "METRIC", "confidence": 0.7297512292861938}]}, {"text": " Table 3: Results for User-level Geolocation Prediction. The bolded results indicate the best performing  statistics (highest value for accuracy and lowest value for mean/median error) for the validation and  testing set.", "labels": [], "entities": [{"text": "Geolocation Prediction", "start_pos": 33, "end_pos": 55, "type": "TASK", "confidence": 0.7370098382234573}, {"text": "accuracy", "start_pos": 136, "end_pos": 144, "type": "METRIC", "confidence": 0.9986268281936646}, {"text": "mean/median error", "start_pos": 166, "end_pos": 183, "type": "METRIC", "confidence": 0.7282280176877975}]}]}