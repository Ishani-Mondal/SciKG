{"title": [{"text": "Character based String Kernels for Bio-Entity Relation Detection", "labels": [], "entities": [{"text": "Bio-Entity Relation Detection", "start_pos": 35, "end_pos": 64, "type": "TASK", "confidence": 0.8087781469027201}]}], "abstractContent": [{"text": "Extracting bio-entity relations has emerged as an important task due to the ever-growing number of bio-medical documents.", "labels": [], "entities": [{"text": "Extracting bio-entity relations", "start_pos": 0, "end_pos": 31, "type": "TASK", "confidence": 0.8888298670450846}]}, {"text": "In this paper, we present a simple and novel representation for extracting bio-entity relationships.", "labels": [], "entities": [{"text": "extracting bio-entity relationships", "start_pos": 64, "end_pos": 99, "type": "TASK", "confidence": 0.8594293395678202}]}, {"text": "The state-of-the-art systems for such tasks rely on word based representations and variations of linguistic driven features.", "labels": [], "entities": []}, {"text": "In contrast, we model bio-text by the most basic character based string representation with a family of string kernels.", "labels": [], "entities": []}, {"text": "This eliminates time consuming parsing, issue of rare words and domain specific pre-processing.", "labels": [], "entities": [{"text": "parsing", "start_pos": 31, "end_pos": 38, "type": "TASK", "confidence": 0.9770702123641968}]}, {"text": "This simple representation makes our approach fast and flexible for any bio-NLP dataset.", "labels": [], "entities": []}, {"text": "We demonstrate comparable performance and faster computation time of our approach versus previous state-of-the-art kernel methods.", "labels": [], "entities": []}], "introductionContent": [{"text": "Relation extraction from biomedical documents is an important task in knowledge representation and inference.", "labels": [], "entities": [{"text": "Relation extraction from biomedical documents", "start_pos": 0, "end_pos": 45, "type": "TASK", "confidence": 0.9312828421592713}, {"text": "knowledge representation", "start_pos": 70, "end_pos": 94, "type": "TASK", "confidence": 0.7358087301254272}]}, {"text": "It helps to construct and enhance structured knowledge-bases and in turn support automatic question answering and decision making.", "labels": [], "entities": [{"text": "question answering", "start_pos": 91, "end_pos": 109, "type": "TASK", "confidence": 0.7914345264434814}, {"text": "decision making", "start_pos": 114, "end_pos": 129, "type": "TASK", "confidence": 0.8598046004772186}]}, {"text": "In today's era of vast amount of information collection and retrieval, the task of naming and identifying the relations between annotated bioentities can become complex and time consuming.", "labels": [], "entities": [{"text": "information collection and retrieval", "start_pos": 33, "end_pos": 69, "type": "TASK", "confidence": 0.7635134011507034}, {"text": "naming and identifying the relations between annotated bioentities", "start_pos": 83, "end_pos": 149, "type": "TASK", "confidence": 0.7665862217545509}]}, {"text": "This can be deducted from the fact that the MED-LINE database has more than 22 million journal articles related to biomedicine.", "labels": [], "entities": [{"text": "MED-LINE database", "start_pos": 44, "end_pos": 61, "type": "DATASET", "confidence": 0.94300177693367}]}, {"text": "Many state-ofthe art methods have been applied for the popular tasks of extracting protein-protein interaction (PPI) and drug-drug interaction (DDI) as apart of BioCreative shared task challenges.", "labels": [], "entities": [{"text": "extracting protein-protein interaction (PPI)", "start_pos": 72, "end_pos": 116, "type": "TASK", "confidence": 0.8262080748875936}]}, {"text": "While these methods have achieved good performance, they mostly rely on word-level features, are dependent on timeconsuming parsers or require domain knowledge for pre-processing.", "labels": [], "entities": []}, {"text": "This paper uses characters instead of words for bio-entity relation extraction.", "labels": [], "entities": [{"text": "bio-entity relation extraction", "start_pos": 48, "end_pos": 78, "type": "TASK", "confidence": 0.704335073630015}]}, {"text": "Characters are the most fundamental building blocks in any language.", "labels": [], "entities": []}, {"text": "We propose to model bio-text using its most basic character-based string representation.", "labels": [], "entities": []}, {"text": "Through a string kernel implementation, in the framework of support vector machine (SVM), we separate positive and negative interaction instances to detect bio-entity relationships.", "labels": [], "entities": []}, {"text": "This basic representation is independent of parsers, does not require domain-related pre-processing and eliminates the rare words problem.", "labels": [], "entities": []}, {"text": "It not only performs comparable to other state-of-the-art methods but also provides an exploration of new and simple feature sets (complementary to existing features) that have not been previously studied for bio-NLP shared tasks.", "labels": [], "entities": []}], "datasetContent": [{"text": "Datasets We demonstrate the benchmark implementations of our approach on three datasets with different sample sizes.", "labels": [], "entities": []}, {"text": "They include MEDLINE corpus from the DDI extraction task (Segura, and the AIMed and LLL corpus from the PPI extraction task ().", "labels": [], "entities": [{"text": "DDI extraction task", "start_pos": 37, "end_pos": 56, "type": "TASK", "confidence": 0.7270066837469736}, {"text": "PPI extraction task", "start_pos": 104, "end_pos": 123, "type": "TASK", "confidence": 0.7670786182085673}]}, {"text": "The details of the datasets have been presented in.", "labels": [], "entities": []}, {"text": "These string kernels were implemented using gkmsvm (Ghandi et al., 2014a) tool.", "labels": [], "entities": []}, {"text": "The character level dictionary, \u03a3 = {a, ..., z, 0, 1, ...9} (size=36), is consistent for all the datasets and kernels.", "labels": [], "entities": []}, {"text": "Evaluation Metrics We performed 10-fold document level cross-validation on each selected corpus and calculated the AUC score (area under the receiver operating characteristic curve) for performance evaluation.", "labels": [], "entities": [{"text": "AUC score", "start_pos": 115, "end_pos": 124, "type": "METRIC", "confidence": 0.9772573709487915}]}, {"text": "( confirmed that AUC score is more stable to parameter modifications and less sensitive to the ratio of positive/negative pairs in the corpus than F-score.", "labels": [], "entities": [{"text": "AUC score", "start_pos": 17, "end_pos": 26, "type": "METRIC", "confidence": 0.9672838151454926}, {"text": "F-score", "start_pos": 147, "end_pos": 154, "type": "METRIC", "confidence": 0.9295482635498047}]}, {"text": "Hence, AUC score is our choice for performance metric.", "labels": [], "entities": [{"text": "AUC score", "start_pos": 7, "end_pos": 16, "type": "METRIC", "confidence": 0.9463381469249725}]}, {"text": "We also recorded the kernel calculation times (in seconds) for all four string kernels.", "labels": [], "entities": []}, {"text": "The AUC scores for APG and SL kernels for MedLine corpus have been reported in ( , while scores of all baseline kernels for AIMed and LLL corpus are reported in.", "labels": [], "entities": [{"text": "AUC", "start_pos": 4, "end_pos": 7, "type": "METRIC", "confidence": 0.9734622240066528}, {"text": "MedLine corpus", "start_pos": 42, "end_pos": 56, "type": "DATASET", "confidence": 0.888006716966629}]}, {"text": "Our string kernel approaches, with simple character features, (WK,MK, and GK), outperform the baseline kernels on the MedLine corpus.", "labels": [], "entities": [{"text": "MedLine corpus", "start_pos": 118, "end_pos": 132, "type": "DATASET", "confidence": 0.9462112784385681}]}, {"text": "For the AIMed corpus, SK, GK, and WK give higher AUC score than the baseline kB-SPS kernel.", "labels": [], "entities": [{"text": "AIMed corpus", "start_pos": 8, "end_pos": 20, "type": "DATASET", "confidence": 0.720753625035286}, {"text": "SK", "start_pos": 22, "end_pos": 24, "type": "METRIC", "confidence": 0.9289482235908508}, {"text": "AUC score", "start_pos": 49, "end_pos": 58, "type": "METRIC", "confidence": 0.9846693277359009}]}, {"text": "Our methods give reasonable performance for LLL corpus as well, however not as good as the three baseline kernels.", "labels": [], "entities": []}, {"text": "The parameters giving the best AUC performance are also reported.", "labels": [], "entities": [{"text": "AUC", "start_pos": 31, "end_pos": 34, "type": "METRIC", "confidence": 0.621354877948761}]}, {"text": "Our representation is complementary and can be plugged into state-of-the-art baselines to further improve their systems.", "labels": [], "entities": []}, {"text": "presents the kernel computation time comparison of all four character-based string kernels versus the baselines.", "labels": [], "entities": []}, {"text": "We compare this with the estimated parsing times.", "labels": [], "entities": [{"text": "parsing", "start_pos": 35, "end_pos": 42, "type": "TASK", "confidence": 0.9661906361579895}]}, {"text": "For the baseline kernels, these have been reported and calculated in.", "labels": [], "entities": []}, {"text": "Unlike baseline kernels, we use character level features directly and thus do not need the parsing step.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Statistics (number of sentences, pos- itive, negative and total instances) of the MED- LINE corpus about DDI and, AIMed and LLL cor- pus about PPI extraction respectively.", "labels": [], "entities": [{"text": "MED- LINE corpus", "start_pos": 92, "end_pos": 108, "type": "DATASET", "confidence": 0.5815220922231674}, {"text": "PPI extraction", "start_pos": 153, "end_pos": 167, "type": "TASK", "confidence": 0.8802542090415955}]}, {"text": " Table 2: Using AUC score to compare four character-based string kernels with APG, kBSPS and SL  baselines. The best performing kernel parameters are also presented. AUC scores for APG and SL  kernels for MEDLINE corpus have been reported in (Thomas et al., 2013), while scores of all three  baseline kernels for AIMed and LLL corpus are reported in (Tikk et al., 2010).", "labels": [], "entities": [{"text": "AUC score", "start_pos": 16, "end_pos": 25, "type": "METRIC", "confidence": 0.939222902059555}, {"text": "AUC", "start_pos": 166, "end_pos": 169, "type": "METRIC", "confidence": 0.9447688460350037}, {"text": "MEDLINE corpus", "start_pos": 205, "end_pos": 219, "type": "DATASET", "confidence": 0.7926797568798065}]}]}