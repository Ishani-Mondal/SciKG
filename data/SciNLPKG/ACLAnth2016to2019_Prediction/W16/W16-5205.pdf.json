{"title": [{"text": "Recurrent Neural Network with Word Embedding for Complaint Classification", "labels": [], "entities": [{"text": "Recurrent Neural Network", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.7356664339701334}]}], "abstractContent": [{"text": "Complaint classification aims at using information to deliver greater insights to enhance user experience after purchasing the products or services.", "labels": [], "entities": [{"text": "Complaint classification", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.8510499000549316}]}, {"text": "Categorized information can help us quickly collect emerging problems in order to provide a support needed.", "labels": [], "entities": []}, {"text": "Indeed, the response to the complaint without the delay will grant users highest satisfaction.", "labels": [], "entities": []}, {"text": "In this paper, we aim to deliver a novel approach which can clarify the complaints precisely with the aim to classify each complaint into nine predefined classes i.e. accessibility , company brand, competitors, facilities, process, product feature, staff quality, timing respectively and others.", "labels": [], "entities": [{"text": "timing", "start_pos": 264, "end_pos": 270, "type": "METRIC", "confidence": 0.9930124878883362}]}, {"text": "Given the idea that one word usually conveys ambiguity and it has to be interpreted by its context, the word embedding technique is used to provide word features while applying deep learning techniques for classifying a type of complaints.", "labels": [], "entities": [{"text": "classifying a type of complaints", "start_pos": 206, "end_pos": 238, "type": "TASK", "confidence": 0.7638040542602539}]}, {"text": "The dataset we use contains 8,439 complaints of one company.", "labels": [], "entities": []}], "introductionContent": [{"text": "While Space Vector Model (SVM) with TF-IDF is widely used as a traditional method for text classification, we cannot neglect that the deep learning with word embedding technique outperforms traditional method so far until now in many comparison reports such as sentiment analysis, named entity recognition, semantic relation extraction and soon.", "labels": [], "entities": [{"text": "text classification", "start_pos": 86, "end_pos": 105, "type": "TASK", "confidence": 0.7497396171092987}, {"text": "sentiment analysis", "start_pos": 261, "end_pos": 279, "type": "TASK", "confidence": 0.9315976500511169}, {"text": "named entity recognition", "start_pos": 281, "end_pos": 305, "type": "TASK", "confidence": 0.6144507825374603}, {"text": "semantic relation extraction", "start_pos": 307, "end_pos": 335, "type": "TASK", "confidence": 0.7048853238423666}]}, {"text": "It is undeniable truth that word embedding with neural network can be effectively applied to the natural language processing task nowadays with highly accurate results.", "labels": [], "entities": [{"text": "natural language processing task", "start_pos": 97, "end_pos": 129, "type": "TASK", "confidence": 0.727950431406498}]}, {"text": "This is the especially for the Recurrent Neural Network (RNN) which is able to detect the hidden relationship between inputs as well as to provide a precise sequence prediction with the state-of-the-art result in various machine learning domains such as computer vision (L. and language modeling (Y..", "labels": [], "entities": [{"text": "language modeling", "start_pos": 278, "end_pos": 295, "type": "TASK", "confidence": 0.744523674249649}]}, {"text": "Because of the long term dependency detection capability, pattern recognition tasks such as speech recognition (Y. and handwriting recognition) also shown great results when applied with RNN.", "labels": [], "entities": [{"text": "dependency detection", "start_pos": 25, "end_pos": 45, "type": "TASK", "confidence": 0.7347282767295837}, {"text": "pattern recognition", "start_pos": 58, "end_pos": 77, "type": "TASK", "confidence": 0.7402871549129486}, {"text": "speech recognition", "start_pos": 92, "end_pos": 110, "type": "TASK", "confidence": 0.7110790312290192}, {"text": "handwriting recognition", "start_pos": 119, "end_pos": 142, "type": "TASK", "confidence": 0.8244867026805878}]}, {"text": "This paper presents a classification recurrent neural network model that deals with the complaint classification task.", "labels": [], "entities": [{"text": "classification recurrent neural network", "start_pos": 22, "end_pos": 61, "type": "TASK", "confidence": 0.8587528169155121}, {"text": "complaint classification task", "start_pos": 88, "end_pos": 117, "type": "TASK", "confidence": 0.8581811388333639}]}, {"text": "The model is compared with TF-IDF, SVM and CBOW methods which are widely used for the text classification.", "labels": [], "entities": [{"text": "text classification", "start_pos": 86, "end_pos": 105, "type": "TASK", "confidence": 0.8251160681247711}]}, {"text": "The experiment shows that the model can outperform other methods for the complaint classification significantly.", "labels": [], "entities": [{"text": "complaint classification", "start_pos": 73, "end_pos": 97, "type": "TASK", "confidence": 0.7976131737232208}]}], "datasetContent": [{"text": "To conduct an empirical evaluation of our proposed method, we compare it with the traditional TF-IDF model and also other popular machine learning model such as Feedforward Neural Network (FNN), LSTM and also try with a different combination of LSTM and GRU with the same training and test set.", "labels": [], "entities": []}, {"text": "F1 score is used to evaluate our result.", "labels": [], "entities": [{"text": "F1 score", "start_pos": 0, "end_pos": 8, "type": "METRIC", "confidence": 0.980541855096817}]}, {"text": "With our data about 8,439 complaints annotated in nine classes, we separate our data into 80% and 20% for training and testing respectively.", "labels": [], "entities": []}, {"text": "Therefore, we have 6,755 and 1,684 sentences for using in training set and test set respectively.", "labels": [], "entities": []}, {"text": "By using Bag-of-Words with TF-IDF, we can get the F1 score for prediction reach only about 75%, which all of Embedding Layer with Neural Network hidden layer can completely surpass this F1 score after a few epochs of training.", "labels": [], "entities": [{"text": "F1 score", "start_pos": 50, "end_pos": 58, "type": "METRIC", "confidence": 0.9881294965744019}, {"text": "prediction", "start_pos": 63, "end_pos": 73, "type": "TASK", "confidence": 0.9419931173324585}, {"text": "F1 score", "start_pos": 186, "end_pos": 194, "type": "METRIC", "confidence": 0.9856836199760437}]}, {"text": "For the other models which are based on neural network, we first provide the same initial weight for each word by using Word2Vec for representing each word in our embedding layer.", "labels": [], "entities": [{"text": "Word2Vec", "start_pos": 120, "end_pos": 128, "type": "DATASET", "confidence": 0.9363746643066406}]}, {"text": "The weight of unknown word is obtained by replacing rare words to unknown word in the corpus before passing those rare words into Word2Vec as we cannot obtain many information from the word that rarely appear in a corpus.", "labels": [], "entities": [{"text": "Word2Vec", "start_pos": 130, "end_pos": 138, "type": "DATASET", "confidence": 0.9641554951667786}]}, {"text": "As a result, we could obtain a well-balanced weight for unknown word.", "labels": [], "entities": []}, {"text": "As the training set is not a very big corpus and the number of vocabularies is not quite high, the more dimensions for word embedding seem to cause the extremely varying vector of similar words.", "labels": [], "entities": []}, {"text": "The best word embed-ding we can achieve is obtained by using 100 dimensions for word embedding with ADAM (D.) optimization.", "labels": [], "entities": []}, {"text": "After running both training and test sets with fnn with 64 hidden units, the highest accuracy on training set can almost get a perfect score on training set with a fastest convergence, but, fora test set, it barely passed 80% which given the lowest F1 score among all other neural network models.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 85, "end_pos": 93, "type": "METRIC", "confidence": 0.9985173344612122}, {"text": "F1", "start_pos": 249, "end_pos": 251, "type": "METRIC", "confidence": 0.9992341995239258}]}, {"text": "By increasing the number of hidden units, the gap of F1 score between training set and test set keeps increasing.", "labels": [], "entities": [{"text": "F1 score", "start_pos": 53, "end_pos": 61, "type": "METRIC", "confidence": 0.9857488572597504}]}, {"text": "LSTM and GRU are experimented with the same number of hidden units.", "labels": [], "entities": [{"text": "LSTM", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.8761016726493835}, {"text": "GRU", "start_pos": 9, "end_pos": 12, "type": "DATASET", "confidence": 0.8715001344680786}]}, {"text": "The F1 score of the prediction is clearly better than MLP.", "labels": [], "entities": [{"text": "F1 score", "start_pos": 4, "end_pos": 12, "type": "METRIC", "confidence": 0.9862553477287292}, {"text": "MLP", "start_pos": 54, "end_pos": 57, "type": "METRIC", "confidence": 0.9059101939201355}]}, {"text": "There is no doubt that it can find along term dependency between words.", "labels": [], "entities": []}, {"text": "In addition, the model is able to Figure out some combination order of words used to classify an output class.", "labels": [], "entities": []}, {"text": "Also, it seems likely that GRU converges a little bit faster than LSTM, while the prediction is almost on par, but much more stable fora long term training as shown in.", "labels": [], "entities": [{"text": "GRU", "start_pos": 27, "end_pos": 30, "type": "METRIC", "confidence": 0.938300609588623}]}, {"text": "Furthermore, the lstm-lstm, gru-gru, lstm-gru and gru-lstm combinations are experimented in bidirectional architectures phase.", "labels": [], "entities": []}, {"text": "The bidirectional GRU and LSTM are converged faster and more accurate than the composition between LSTM and GRU.", "labels": [], "entities": []}, {"text": "Also, the F1 score is same as a single direction LSTM or GRU.", "labels": [], "entities": [{"text": "F1 score", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9845538139343262}, {"text": "GRU", "start_pos": 57, "end_pos": 60, "type": "METRIC", "confidence": 0.5330063104629517}]}, {"text": "However, the bidirectional models sometime provide better results than the single direction average results and also converge much faster as shown in. shows that all of our approach with Neural Network model has surpassed the baseline set by TF-IDF which is 75% with no difficulty.", "labels": [], "entities": []}, {"text": "It is our concrete evidence that the word embedding provides more information for the model to be able to detect dependencies used for classifying the document.", "labels": [], "entities": []}, {"text": "Moreover, the FNN can achieve best prediction result after a few epochs of training but self-declining from an overfitting effect is inevitable after continuous training.", "labels": [], "entities": [{"text": "FNN", "start_pos": 14, "end_pos": 17, "type": "DATASET", "confidence": 0.8677265644073486}]}, {"text": "The GRU recurrent neural network has the most stability in maintaining its states once it converged.", "labels": [], "entities": []}, {"text": "Also, it converges much faster than LSTM.", "labels": [], "entities": []}, {"text": "However, in a long-term training, the result of LSTM seems to be better.", "labels": [], "entities": []}, {"text": "The bidirectional model seems not to be very convinced.", "labels": [], "entities": []}, {"text": "But, it is still too soon to conclude that backward dependency detection is unnecessary.", "labels": [], "entities": [{"text": "backward dependency detection", "start_pos": 43, "end_pos": 72, "type": "TASK", "confidence": 0.6883373856544495}]}, {"text": "In the, it can be seen that the model which uses a bidirectional GRU or LSTM can converge much faster than the single direction GRU/LSTM.", "labels": [], "entities": []}, {"text": "A comparison of F1 score between fnn (red), lstm (green) and gru (blue) for training set (higher line) and test set (lower line) is shown in.", "labels": [], "entities": [{"text": "F1 score", "start_pos": 16, "end_pos": 24, "type": "METRIC", "confidence": 0.9834794104099274}]}, {"text": "Also, the comparison of F1 score between lstm-gru (blue), lstm-lstm (green), grulstm (red) and gru-gru (violet) for training set (higher line) and test set (lower line) is shown in.", "labels": [], "entities": [{"text": "F1 score", "start_pos": 24, "end_pos": 32, "type": "METRIC", "confidence": 0.9837925732135773}]}], "tableCaptions": []}