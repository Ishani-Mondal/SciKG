{"title": [{"text": "Bi-LSTM Neural Networks for Chinese Grammatical Error Diagnosis", "labels": [], "entities": [{"text": "Chinese Grammatical Error Diagnosis", "start_pos": 28, "end_pos": 63, "type": "TASK", "confidence": 0.7838707268238068}]}], "abstractContent": [{"text": "Grammatical Error Diagnosis for Chinese has always been a challenge for both foreign learners and NLP researchers, for the variousity of grammar and the flexibility of expression.", "labels": [], "entities": [{"text": "Grammatical Error Diagnosis", "start_pos": 0, "end_pos": 27, "type": "TASK", "confidence": 0.9305545091629028}]}, {"text": "In this paper, we present a model based on Bidirectional Long Short-Term Memory(Bi-LSTM) neural networks, which treats the task as a sequence labeling problem, so as to detect Chinese grammatical errors, to identify the error types and to locate the error positions.", "labels": [], "entities": []}, {"text": "In the corpora of this year's shared task, there can be multiple errors in a single offset of a sentence, to address which, we simutaneously train three Bi-LSTM models sharing word embeddings which label Missing, Redundant and Selection errors respectively.", "labels": [], "entities": []}, {"text": "We regard word ordering error as a special kind of word selection error which is longer during training phase, and then separate them by length during testing phase.", "labels": [], "entities": [{"text": "word ordering", "start_pos": 10, "end_pos": 23, "type": "TASK", "confidence": 0.8461112678050995}, {"text": "word selection", "start_pos": 51, "end_pos": 65, "type": "TASK", "confidence": 0.7054342031478882}]}, {"text": "In NLP-TEA 3 shared task for Chinese Grammatical Error Diagnosis(CGED), Our system achieved relatively high F1 for all the three levels in the traditional Chinese track and for the detection level in the Simpified Chinese track.", "labels": [], "entities": [{"text": "Chinese Grammatical Error Diagnosis(CGED)", "start_pos": 29, "end_pos": 70, "type": "TASK", "confidence": 0.749389146055494}, {"text": "F1", "start_pos": 108, "end_pos": 110, "type": "METRIC", "confidence": 0.9996522665023804}, {"text": "Simpified Chinese track", "start_pos": 204, "end_pos": 227, "type": "DATASET", "confidence": 0.8920447627703348}]}], "introductionContent": [{"text": "As China plays a more and more important role of the world, learning Chinese as a foreign language is becoming a growing trend, which brings opportunities as well as challenges.", "labels": [], "entities": []}, {"text": "Due to the variousity of grammar and the flexibility of expression, Chinese Grammatical Error Dignosis(CGED) poses a serious challenge to both foreign learners and NLP researchers.", "labels": [], "entities": [{"text": "Chinese Grammatical Error Dignosis(CGED)", "start_pos": 68, "end_pos": 108, "type": "TASK", "confidence": 0.7307929481778827}]}, {"text": "Unlike inflectional languages such as English which follows grammatical rules strictly(i.e. subject-verb agreement, strict tenses and voices), Chinese, as an isolated language, has no morphological changes.", "labels": [], "entities": []}, {"text": "Various characters are arranged in a sentence to represent meanings as well as the tense and the voice.", "labels": [], "entities": []}, {"text": "These features make it easy for beginners to make mistakes in speaking or writing.", "labels": [], "entities": []}, {"text": "Thus it is necessary to build an automatic grammatical error detection system to help them learn Chinese better and faster.", "labels": [], "entities": [{"text": "grammatical error detection", "start_pos": 43, "end_pos": 70, "type": "TASK", "confidence": 0.6110981305440267}]}, {"text": "In NLP-TEA 3 shared task for Chinese Grammatical Error Diagnosis(CGED), four types of errors are defined: 'M' for missing word error, 'R' for redundant errors, 'S' for word selection error and 'W' for word ordering error.", "labels": [], "entities": [{"text": "Chinese Grammatical Error Diagnosis(CGED)", "start_pos": 29, "end_pos": 70, "type": "TASK", "confidence": 0.766121723822185}, {"text": "word ordering", "start_pos": 201, "end_pos": 214, "type": "TASK", "confidence": 0.6935484707355499}]}, {"text": "Some typical examples of the errors are shown in.", "labels": [], "entities": []}, {"text": "Different from the two previous editions for the CGED shared task, each input sentence contains at least one of defined error types.", "labels": [], "entities": []}, {"text": "What's more, there can be multiple errors in a single offset of a sentence, which means we can no longer treat it a simple multi-class classification problem.", "labels": [], "entities": [{"text": "multi-class classification", "start_pos": 123, "end_pos": 149, "type": "TASK", "confidence": 0.7280725538730621}]}, {"text": "As a result of that, we cannot simply rely on some existing error detection systems but can only seek fora new solution.", "labels": [], "entities": [{"text": "error detection", "start_pos": 60, "end_pos": 75, "type": "TASK", "confidence": 0.7063530534505844}]}], "datasetContent": [{"text": "In the TOCFL track, the data we used for training includes training and testing data from NLP-TEA 1 ( ), training data from NLP-TEA 2 (, and training data from NLP-TEA 3.", "labels": [], "entities": [{"text": "TOCFL track", "start_pos": 7, "end_pos": 18, "type": "DATASET", "confidence": 0.6631420254707336}, {"text": "NLP-TEA 1", "start_pos": 90, "end_pos": 99, "type": "DATASET", "confidence": 0.8923635184764862}]}, {"text": "We used the testing data from NLP-TEA 2 for validation.", "labels": [], "entities": [{"text": "NLP-TEA 2", "start_pos": 30, "end_pos": 39, "type": "DATASET", "confidence": 0.8855008780956268}]}, {"text": "In the HSK track, despite of the training set provided by the organizers, we simplified the training data from TOCFL track as supplements.", "labels": [], "entities": [{"text": "HSK track", "start_pos": 7, "end_pos": 16, "type": "DATASET", "confidence": 0.9043377339839935}, {"text": "TOCFL track", "start_pos": 111, "end_pos": 122, "type": "DATASET", "confidence": 0.8211976587772369}]}, {"text": "However, the simplified data from TOCFL track seem to be no use to the evaluation results.", "labels": [], "entities": [{"text": "TOCFL track", "start_pos": 34, "end_pos": 45, "type": "DATASET", "confidence": 0.7403022348880768}]}, {"text": "shows the statistics of our training sets.", "labels": [], "entities": []}, {"text": "Due to the limitation of time and resource, the word embeddings and POS tag embeddings we used are all random initialized.", "labels": [], "entities": []}, {"text": "In the formal run of NLP-TEA 3 CGED shared task, there are 5 teams submitting 15 runs in total for the TOCFL dataset track and 8 teams submitting 21 runs in total for the HSK dataset track.", "labels": [], "entities": [{"text": "NLP-TEA 3 CGED shared task", "start_pos": 21, "end_pos": 47, "type": "TASK", "confidence": 0.6398703336715699}, {"text": "TOCFL dataset track", "start_pos": 103, "end_pos": 122, "type": "DATASET", "confidence": 0.919249951839447}, {"text": "HSK dataset track", "start_pos": 171, "end_pos": 188, "type": "DATASET", "confidence": 0.9355519811312357}]}, {"text": "Our system achieved relatively high F1 for all the three levels in the traditional Chinese track and for the detection level in the Simpified Chinese track.", "labels": [], "entities": [{"text": "F1", "start_pos": 36, "end_pos": 38, "type": "METRIC", "confidence": 0.999782383441925}, {"text": "detection", "start_pos": 109, "end_pos": 118, "type": "METRIC", "confidence": 0.9706640839576721}, {"text": "Simpified Chinese track", "start_pos": 132, "end_pos": 155, "type": "DATASET", "confidence": 0.9413317640622457}]}, {"text": "Since our evaluation results for HSK dataset are not good, here we only display the evaluation results compared with the average values for TOCFL dataset.", "labels": [], "entities": [{"text": "HSK dataset", "start_pos": 33, "end_pos": 44, "type": "DATASET", "confidence": 0.9373654723167419}, {"text": "TOCFL dataset", "start_pos": 140, "end_pos": 153, "type": "DATASET", "confidence": 0.9448190033435822}]}, {"text": "The performance evaluations in detection level, identification level and position level are shown as follows:", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Statistics of training sets", "labels": [], "entities": []}, {"text": " Table 3: Performance evaluation in detection level", "labels": [], "entities": []}, {"text": " Table 4: Performance evaluation in identification level", "labels": [], "entities": [{"text": "identification", "start_pos": 36, "end_pos": 50, "type": "TASK", "confidence": 0.9589017629623413}]}]}