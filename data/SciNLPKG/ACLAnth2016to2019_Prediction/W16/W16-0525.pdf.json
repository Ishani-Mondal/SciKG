{"title": [{"text": "Combined Tree Kernel-based classifiers for Assessing Quality of Scientific Text *", "labels": [], "entities": [{"text": "Assessing Quality of Scientific Text", "start_pos": 43, "end_pos": 79, "type": "TASK", "confidence": 0.8807812690734863}]}], "abstractContent": [{"text": "This document describes Tree Kernel-SVM based methods for identifying sentences that could be improved in scientific text.", "labels": [], "entities": []}, {"text": "This has the goal of contributing to the body of knowledge that attempt to build assistive tools to aid scientist improve the quality of their writings.", "labels": [], "entities": []}, {"text": "Our methods consist of a combination of the output from multiple support vector machines which use Tree Kernel computations.", "labels": [], "entities": []}, {"text": "Therefore , features for individual sentences are trees that reflect their grammatical structure.", "labels": [], "entities": []}, {"text": "For the AESW 2016 Shared Task we built systems that provide probabilistic and binary outputs by using these models for trees comparisons.", "labels": [], "entities": [{"text": "AESW 2016 Shared Task", "start_pos": 8, "end_pos": 29, "type": "DATASET", "confidence": 0.8794923275709152}]}], "introductionContent": [{"text": "The system described in this article was submitted to the Automated Evaluation of Scientific Writing (AESW) Shared Task (.", "labels": [], "entities": [{"text": "Automated Evaluation of Scientific Writing (AESW) Shared Task", "start_pos": 58, "end_pos": 119, "type": "TASK", "confidence": 0.6207668572664261}]}, {"text": "English is the most common language used for scientific writing across the world.", "labels": [], "entities": []}, {"text": "Other things being equal, many scientific writers are non-native English speakers, what leads to a demand for assisting tools that employ \"grammar error correction technologies\" to compose scientific articles.", "labels": [], "entities": [{"text": "grammar error correction", "start_pos": 139, "end_pos": 163, "type": "TASK", "confidence": 0.6790167291959127}]}, {"text": "Several competitions similar to the one this article addresses have been organized, namely: the Helping Our Own (HOO) Shared Task (), The CoNLL-2014 shared task on Grammatical Error Correction (Ng et * Both authors contributed equally to the contents and experiments described in this paper. al., 2014).", "labels": [], "entities": [{"text": "CoNLL-2014 shared task on Grammatical Error Correction", "start_pos": 138, "end_pos": 192, "type": "TASK", "confidence": 0.5676043885094779}]}, {"text": "Those evaluations make use of human annotated examples of correct and incorrect grammar ().", "labels": [], "entities": []}, {"text": "Particularly, provide a comprehensive overview of various aspects related to grammar error detection research.", "labels": [], "entities": [{"text": "grammar error detection research", "start_pos": 77, "end_pos": 109, "type": "TASK", "confidence": 0.7833636701107025}]}, {"text": "This paper is organized as follows: Section 2 briefly describes the goals of the task our models attempt to address, Section 3 describes our experiments including the proposed Tree Kernel models, whose results are reported in Section 4.", "labels": [], "entities": []}, {"text": "Section 5 further comments on the results, and Section 6 concludes with some summarizing remarks.", "labels": [], "entities": []}], "datasetContent": [{"text": "For our experiments we used constituent trees corresponding to the examples from the training dataset.", "labels": [], "entities": []}, {"text": "This dataset provided by the shared task organizers comprises parse tree structures which were generated by using the Stanford parser).", "labels": [], "entities": []}, {"text": "Unfortunately, the computation of kernels for all SubSet Trees is highly demanding in terms of computation time.", "labels": [], "entities": []}, {"text": "Due to hardware limitations, for all three models the training data set was split into 100 sub-datasets, and a Support Vector Machine model was trained for each sub-dataset.", "labels": [], "entities": []}, {"text": "Then, predictions were computed by using each of those hundred Support Vector Machine models over the unlabelled test dataset provided by the task organizers.", "labels": [], "entities": []}, {"text": "The overall numerical categorization value fora system was calculated by averaging over these predictions.", "labels": [], "entities": []}, {"text": "This categorization value was normalized to generate the probability of a sentence needing improvement OutputP rob using formula(1), where (1) Because the formula aims to estimate probabilities, if OutputP rob > 1 then it is floored down to one, if OutputP rob < 0, then it is rounded up to zero.", "labels": [], "entities": []}, {"text": "Some issues related to the use Stanford parser emerged during the evaluation stage.", "labels": [], "entities": []}, {"text": "The parsing procedure for examples from the testing set was expected to produce a parse tree per example, which thereafter would be formatted properly for testing our systems.", "labels": [], "entities": []}, {"text": "However, the parser failed to identify the boundaries of some sentences, particularly if there was an abbreviation with a period or a colon symbol occurring in them.", "labels": [], "entities": []}, {"text": "For instance, abbreviations such as \"etc.\" or \"i e.\" caused the parser produce two parse trees fora single sentence.", "labels": [], "entities": []}, {"text": "This issue was overcame by running a script that matches the tree structure with the original sentence if the tree structure contained at least 50% of the words in the original sentence, for which no more than 10 consecutive sentences or consecutive trees can be unmatched.", "labels": [], "entities": []}, {"text": "This procedure left 188 sentences without a match (which is negligible amount of the total testing set: 0.13%).", "labels": [], "entities": []}, {"text": "For these sentences a probability of 0.5 or a label 'false' was assigned.", "labels": [], "entities": []}, {"text": "shows the results for the systems submitted to the task organizers.", "labels": [], "entities": []}], "tableCaptions": []}