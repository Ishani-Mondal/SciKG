{"title": [{"text": "Scrutable Feature Sets for Stance Classification", "labels": [], "entities": [{"text": "Stance Classification", "start_pos": 27, "end_pos": 48, "type": "TASK", "confidence": 0.9895212948322296}]}], "abstractContent": [{"text": "This paper describes and evaluates a novel feature set for stance classification of argumentative texts; i.e. deciding whether a post by a user is for or against the issue being debated.", "labels": [], "entities": [{"text": "stance classification of argumentative texts", "start_pos": 59, "end_pos": 103, "type": "TASK", "confidence": 0.8535378217697144}]}, {"text": "We model the debate both as attitude bearing features, including a set of automatically acquired 'topic terms' associated with a Distributional Lexical Model (DLM) that captures the writer's attitude towards the topic term, and as dependency features that represent the points being made in the debate.", "labels": [], "entities": []}, {"text": "The stance of the text towards the issue being debated is then learnt in a supervised framework as a function of these features.", "labels": [], "entities": []}, {"text": "The main advantage of our feature set is that it is scrutable: The reasons fora classification can be explained to a human user in natural language.", "labels": [], "entities": []}, {"text": "We also report that our method outperforms previous approaches to stance classification as well as a range of baselines based on sentiment analysis and topic-sentiment analysis.", "labels": [], "entities": [{"text": "stance classification", "start_pos": 66, "end_pos": 87, "type": "TASK", "confidence": 0.9211084842681885}, {"text": "sentiment analysis", "start_pos": 129, "end_pos": 147, "type": "TASK", "confidence": 0.8903748393058777}, {"text": "topic-sentiment analysis", "start_pos": 152, "end_pos": 176, "type": "TASK", "confidence": 0.6905010640621185}]}], "introductionContent": [{"text": "In recent years, stance classification for online debates has received increasing research interest ().", "labels": [], "entities": [{"text": "stance classification", "start_pos": 17, "end_pos": 38, "type": "TASK", "confidence": 0.9828487932682037}]}, {"text": "Given a post belonging to a two-sided debate on an issue (e.g. abortion rights; see), the task is classify the post as for or against the issue.", "labels": [], "entities": []}, {"text": "The argumentative nature of such posts makes stance classification difficult; for example, one has to follow the reasoning quite closely to decide which of the posts in argues for or against abortion.", "labels": [], "entities": [{"text": "stance classification", "start_pos": 45, "end_pos": 66, "type": "TASK", "confidence": 0.9088939726352692}]}, {"text": "In, the posts are monologic (independent of each other), but even with the availability of dialogic structure connecting posts, both humans and classifiers experience difficulties instance classification), in part because posts that contain rebuttal arguments do not provide clear evidence that they are arguing for or against the main issue being debated.", "labels": [], "entities": []}, {"text": "Stance classification is considered particularly challenging however when the posts are monologic since the lack of dialogic structure means all features for classification have to be extracted from the text itself.", "labels": [], "entities": [{"text": "Stance classification", "start_pos": 0, "end_pos": 21, "type": "TASK", "confidence": 0.9356605410575867}]}, {"text": "Indeed studies to classify such independent posts have previously found it difficult to even beat a unigram classifier baseline; for example, achieved only a 1.5% increase inaccuracy from the use of more sophisticated features such as opinion and arguing expressions over a simple unigram model.", "labels": [], "entities": []}, {"text": "In this paper, we propose anew feature set for stance classification of independent posts that, unlike previous work, captures two key characteristics of such debates; namely, writers express their attitudes towards a range of topics associated with the issue being debated and also argue by making logical points.", "labels": [], "entities": [{"text": "stance classification of independent posts", "start_pos": 47, "end_pos": 89, "type": "TASK", "confidence": 0.8656246662139893}]}, {"text": "We model the debate using a combination of the following features.", "labels": [], "entities": []}, {"text": "\u2022 topic-stance features -a set of automatically extracted 'topic terms' (for abortion rights, these would include, for example, 'fetus', 'baby', 'woman' and 'life'), where each topic term is associated with a distributional lexical model (DLM) that captures the writer's stance towards that topic.", "labels": [], "entities": []}, {"text": "\u2022 stance bearing terminology -words related", "labels": [], "entities": [{"text": "stance bearing terminology", "start_pos": 2, "end_pos": 28, "type": "TASK", "confidence": 0.7945934732755026}]}], "datasetContent": [{"text": "We used the dataset created by Somasundaran and Wiebe (2010) containing monologic posts about five issues: abortion, creation, gay rights, god and gun rights.", "labels": [], "entities": []}, {"text": "reported results on a balanced subset of the corpus with equal numbers of posts for and against each issue.", "labels": [], "entities": []}, {"text": "We adopted the same methodology as them to create a balanced subset and evaluated on our balanced dataset containing 4870 posts in total, with  We developed our ideas by manual examination of the abortion rights debate, leaving the other four debates unseen.", "labels": [], "entities": []}, {"text": "We report results for both the development set and the four unseen test sets.", "labels": [], "entities": []}, {"text": "We conducted experiments using Multinomial Naive Bayes classifier implemented in the Weka toolkit ().", "labels": [], "entities": [{"text": "Weka toolkit", "start_pos": 85, "end_pos": 97, "type": "DATASET", "confidence": 0.9760843217372894}]}, {"text": "The Multinomial Naive Bayes model has been previously shown to perform better on text classification tasks with increasing vocabulary size, taking into account word frequencies, and this was also our experience.", "labels": [], "entities": [{"text": "text classification tasks", "start_pos": 81, "end_pos": 106, "type": "TASK", "confidence": 0.8183434009552002}]}, {"text": "For feature sets produced by each model described in the Methods section, we used the FilteredAttributeEval method available in Weka for feature selection, retaining all features with a score greater than zero.", "labels": [], "entities": [{"text": "Weka", "start_pos": 128, "end_pos": 132, "type": "DATASET", "confidence": 0.9767326712608337}]}, {"text": "Feature counts were normalised by tf*idf.", "labels": [], "entities": []}, {"text": "The performance of the classifier is reported using the accuracy metric, which is most appropriate fora balanced dataset.", "labels": [], "entities": [{"text": "accuracy metric", "start_pos": 56, "end_pos": 71, "type": "METRIC", "confidence": 0.9781505465507507}]}], "tableCaptions": [{"text": " Table 5: Results of supervised learning experiments using Naive Bayes Multinomial model", "labels": [], "entities": []}, {"text": " Table 6: Percentage of posts containing at  least one feature for each feature set (following  feature selection)", "labels": [], "entities": []}]}