{"title": [{"text": "Feature Derivation for Exploitation of Distant Annotation via Pattern Induction against Dependency Parses", "labels": [], "entities": []}], "abstractContent": [{"text": "We consider the use of distant supervision for biological information extraction, and introduce two understudied corpora of this form, the Biological Expression Language (BEL) Large Corpus and the Pathway Logic (PL) Datum Corpus.", "labels": [], "entities": [{"text": "biological information extraction", "start_pos": 47, "end_pos": 80, "type": "TASK", "confidence": 0.6174789369106293}]}, {"text": "Each resource eschews annotation at the sentence constituent level, and the PL corpus requires synthesis of information across multiple sentences to construct composite knowledge frames.", "labels": [], "entities": []}, {"text": "Decomposing this problem into feature induction for slot-level attributes, followed by event assembly over this space of features, we introduce a novel, general-purpose pattern induction procedure, evaluating it against these two corpora, demonstrating its ability to induce effective detection against dependency parses.", "labels": [], "entities": []}], "introductionContent": [{"text": "Biological event and relation extraction have been the focus of considerable study in recent years, resulting in the availability of annotated corpora ().", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 21, "end_pos": 40, "type": "TASK", "confidence": 0.7772828340530396}]}, {"text": "In the interest of replicability and progress on critical challenges, such resources typically decompose the hard problem of factual understanding into several simpler problems, such as entity recognition, binary relation detection, and co-reference resolution.", "labels": [], "entities": [{"text": "replicability", "start_pos": 19, "end_pos": 32, "type": "TASK", "confidence": 0.9760629534721375}, {"text": "entity recognition", "start_pos": 186, "end_pos": 204, "type": "TASK", "confidence": 0.8015892207622528}, {"text": "binary relation detection", "start_pos": 206, "end_pos": 231, "type": "TASK", "confidence": 0.6947400172551473}, {"text": "co-reference resolution", "start_pos": 237, "end_pos": 260, "type": "TASK", "confidence": 0.759167492389679}]}, {"text": "This methodology is subject to several criticisms.", "labels": [], "entities": []}, {"text": "The reliance on thorough annotation imposes overheads that prevent rapid progress.", "labels": [], "entities": []}, {"text": "The targeting of a fixed set of simplified, typically binary relations does justice neither to the complexity of information expressed in atypical sentence, nor to the biological processes under discussion.", "labels": [], "entities": []}, {"text": "And the methodology places a emphasis on pieces of information amenable to expression in individual sentences, leaving untouched information that can be assembled only through traversal of paragraphs or complete documents.", "labels": [], "entities": []}, {"text": "Some of these limitations can be mitigated through distant supervision, a technique deriving noisy annotation through the heuristic alignment of structured knowledge resources to texts).", "labels": [], "entities": []}, {"text": "The biological domain affords a number of high-quality knowledge resources with good coverage, making possible strongly competitive distantly supervised solutions (.", "labels": [], "entities": []}, {"text": "However, the distance between resource and text is often not great in such work, which focuses on relations for which entity co-occurrence in a sentence is strong evidence that the sentence expresses the target relation.", "labels": [], "entities": []}, {"text": "In this paper we attempt to exploit two knowledge resources, neither of which has received much attention from the BioNLP community, that increase this distance in interesting and distinct ways.", "labels": [], "entities": []}, {"text": "The Biological Expression Language (BEL) is a knowledge interchange format intended to encode qualitative causal and correlative relations that supports nested knowledge frames.", "labels": [], "entities": []}, {"text": "One product of the OpenBEL initiative 1 is the \"Large BEL Corpus,\" which explicitly pairs a large number of literature excerpts with the BEL assertions that each supports.", "labels": [], "entities": [{"text": "BEL Corpus", "start_pos": 54, "end_pos": 64, "type": "DATASET", "confidence": 0.7344820201396942}]}, {"text": "The relation between sentence and BEL statement is many-to-many, with no provisions for aligning specific statement components with specific sentence constituents.", "labels": [], "entities": [{"text": "BEL", "start_pos": 34, "end_pos": 37, "type": "METRIC", "confidence": 0.9369544982910156}]}, {"text": "The Pathway Logic (PL) project pursues highfidelity signaling pathway models centering on Ras ().", "labels": [], "entities": []}, {"text": "Part of the effort involves a manual curation of experimental results, which has resulted in approximately 40K records, each containing a detailed formal representation of an experiment and its outcomes.", "labels": [], "entities": []}, {"text": "Such records, called datums, retain pointers to the papers and figures from which they were derived.", "labels": [], "entities": []}, {"text": "In general, assembling the rich information contained in a datum requires traversing multiple sentences, both in figure captions and paper bodies.", "labels": [], "entities": []}, {"text": "We view the problem of extracting composite knowledge frames based on these attenuated supervisory signals as having two parts.", "labels": [], "entities": []}, {"text": "First, we seek to generate a set of features highly indicative of various aspects of the target frame (its type, various attributes, etc.).", "labels": [], "entities": []}, {"text": "Second, we view the problem of assembling frames from the resulting enriched feature space as one of structured classification.", "labels": [], "entities": []}, {"text": "Recent work on structured classification lends confidence that such empirical assembly models are possible in principle) and applicable to discourse-level event extraction (.", "labels": [], "entities": [{"text": "structured classification", "start_pos": 15, "end_pos": 40, "type": "TASK", "confidence": 0.7653422653675079}, {"text": "discourse-level event extraction", "start_pos": 139, "end_pos": 171, "type": "TASK", "confidence": 0.6242143710454305}]}, {"text": "In this paper we address the first problem, the derivation of features for downstream extraction.", "labels": [], "entities": [{"text": "downstream extraction", "start_pos": 75, "end_pos": 96, "type": "TASK", "confidence": 0.7486224472522736}]}, {"text": "We treat this problem as one of sentence classification via pattern (or rule) set induction against dependency parses.", "labels": [], "entities": [{"text": "sentence classification", "start_pos": 32, "end_pos": 55, "type": "TASK", "confidence": 0.7141713052988052}]}, {"text": "Compared with related work involving rules in the BioNLP literature (), our approach exhibits some interesting features, particularly the eschewal of domain heuristics and the nonreliance on constituent-level annotations.", "labels": [], "entities": [{"text": "BioNLP literature", "start_pos": 50, "end_pos": 67, "type": "DATASET", "confidence": 0.8232490420341492}]}, {"text": "Our work can be viewed as complementary to manual rule writing, and we present evidence that our learned patterns outperform rules written by hand.", "labels": [], "entities": [{"text": "rule writing", "start_pos": 50, "end_pos": 62, "type": "TASK", "confidence": 0.6793853640556335}]}, {"text": "Our contributions in this paper are twofold: \u2022 We present and evaluate a novel, generalpurpose approach to the induction of classification and extraction patterns from dependency parses.", "labels": [], "entities": [{"text": "induction of classification and extraction patterns from dependency parses", "start_pos": 111, "end_pos": 185, "type": "TASK", "confidence": 0.8642748263147142}]}, {"text": "\u2022 We evaluate this approach against two BioNLP corpora that have received little attention in the literature.", "labels": [], "entities": []}, {"text": "Each corpus presents an extraction problem of greater complexity than can be addressed by current methods, providing avenues toward models of greater scope and biological fidelity.", "labels": [], "entities": []}, {"text": "The remainder of the paper is organized as follows.", "labels": [], "entities": []}, {"text": "In the next section, we describe these two data sources and the problems they pose.", "labels": [], "entities": []}, {"text": "In Section 3 we present our approach to pattern induction.", "labels": [], "entities": [{"text": "pattern induction", "start_pos": 40, "end_pos": 57, "type": "TASK", "confidence": 0.8543048202991486}]}, {"text": "Then, we describe and discuss our experiments in Section 4.", "labels": [], "entities": []}, {"text": "Finally, we compare our approach in Section 5 to related work.", "labels": [], "entities": []}], "datasetContent": [{"text": "We evaluated our pattern induction procedure on the BEL and PL corpora for its effectiveness in detecting sentences expressing information needed for composite knowledge frames.", "labels": [], "entities": [{"text": "pattern induction", "start_pos": 17, "end_pos": 34, "type": "TASK", "confidence": 0.6670781522989273}, {"text": "BEL", "start_pos": 52, "end_pos": 55, "type": "METRIC", "confidence": 0.9750311970710754}]}, {"text": "We converted BEL statements into a set of overlapping binary distinctions, called fragments, each a possible abstraction of the statement.", "labels": [], "entities": []}, {"text": "Our objective is to convert each BEL extraction into a large set of redundant simpler problems, from which the original statement might be reconstituted.", "labels": [], "entities": [{"text": "BEL extraction", "start_pos": 33, "end_pos": 47, "type": "TASK", "confidence": 0.767718106508255}]}, {"text": "For example, the BEL statement \"p(HGNC:CCND1) =\u21d2 kin(p(HGNC:CDK4))\" yields (among other fragments) \"kin\" (describes kinase activity), \"kin(p)\" (kinase activity of a protein), and \" =\u21d2 kin(p)\" (kinase activity of a protein resulting from unspecified cause).", "labels": [], "entities": [{"text": "BEL", "start_pos": 17, "end_pos": 20, "type": "METRIC", "confidence": 0.8614515662193298}]}, {"text": "Generating BEL fragments from fully specified BEL statements proceeds by first abstracting away any entity or numeric function arguments.", "labels": [], "entities": [{"text": "Generating BEL fragments from fully specified BEL statements", "start_pos": 0, "end_pos": 60, "type": "TASK", "confidence": 0.7706946134567261}]}, {"text": "Then, fragments are generated for every subtree in the abstract syntax tree of the statement.", "labels": [], "entities": []}, {"text": "(We distinguish between functions occurring in the statement's subject and object position, in other words treating \"subject\" and \"object\" as a named element of the syntax tree.)", "labels": [], "entities": []}, {"text": "Additionally, a fragment is generated for the relationship type and all functions occurring anywhere in the statement.", "labels": [], "entities": []}, {"text": "lists examples of BEL fragments with the number of positive training set sentences associated with each of them in the corpus.: Example BEL statement fragments (p = proteinAbundance; r = rnaAbundance; bp = biologicalP rocess; trans = translocation; c = complexAbundance).", "labels": [], "entities": []}, {"text": "From the \u223c74,000 BEL statements associated with validated evidence, this process generates \u223c3k unique fragments, of which we retained those associated with at least 20 sentences (resulting in \u223c400 unique fragments).", "labels": [], "entities": [{"text": "BEL", "start_pos": 17, "end_pos": 20, "type": "METRIC", "confidence": 0.9658230543136597}]}, {"text": "For each unique fragment, all sentences associated with the fragment were labeled as positive, and all other sentences were labeled as negative.", "labels": [], "entities": []}, {"text": "Patterns were then induced and evaluated on a 60/20/20% train/validation/test split defined on each of the sets.", "labels": [], "entities": []}, {"text": "Note that the corpus sometimes associates BEL statements with multiple sentences, e.g., and entire paragraph, which means our labeling procedure sometimes treats proximal sentences as positive, even though they may not directly instantiate a target statement.", "labels": [], "entities": [{"text": "BEL", "start_pos": 42, "end_pos": 45, "type": "METRIC", "confidence": 0.8878291249275208}]}, {"text": "The inductive procedure, which assumes that the target class is a disjunction of mutually exclusive cases, handles such \"noise\" well, essentially failing to derive patterns from (i.e., ignoring) the superfluous \"positive\" examples.", "labels": [], "entities": []}, {"text": "We evaluate the induced rule ensembles by calculating an idealized F1 score, identifying a threshold for classification based upon the validation estimated precision of the ensemble match (Eq. 2) that maximizes F1 on the test set.", "labels": [], "entities": [{"text": "F1 score", "start_pos": 67, "end_pos": 75, "type": "METRIC", "confidence": 0.977734237909317}, {"text": "precision", "start_pos": 156, "end_pos": 165, "type": "METRIC", "confidence": 0.5916170477867126}, {"text": "F1", "start_pos": 211, "end_pos": 213, "type": "METRIC", "confidence": 0.9980767965316772}]}, {"text": "We acknowledge that finding this threshold using test data produces an overly-optimistic result, but doing so provides us with an informative upper bound.", "labels": [], "entities": []}, {"text": "In practice, the threshld would be tuned using an alternative validation set to prevent overfitting.", "labels": [], "entities": []}, {"text": "The mean cardinality of the induced rule ensembles was 7, with a total of 2991 rules (2402 unique) induced across the \u223c400 fragments.", "labels": [], "entities": []}, {"text": "Results are plotted in, with one dot per classification experiment, each being an application of the rule induction approach against a single unique BEL statement fragment.", "labels": [], "entities": [{"text": "BEL", "start_pos": 149, "end_pos": 152, "type": "METRIC", "confidence": 0.8736615180969238}]}, {"text": "For each experiment, the F1 classification result is plotted against the size of the positive training set.", "labels": [], "entities": [{"text": "F1 classification result", "start_pos": 25, "end_pos": 49, "type": "METRIC", "confidence": 0.8881685535113016}]}, {"text": "The plot also contains a line showing the F1 results of a random chance baseline.", "labels": [], "entities": [{"text": "F1", "start_pos": 42, "end_pos": 44, "type": "METRIC", "confidence": 0.9991876482963562}]}, {"text": "To calculate the baseline, we assume a classifier that randomly labels sentences as positive or negative with the same marginal probabilities as observed in the training set.", "labels": [], "entities": []}, {"text": "We next conducted a set of experiments targeting classification of sentences associated with various PL datum fragments.", "labels": [], "entities": []}, {"text": "In this case, we employed named entity resolution for proteins, label-: F1 performance in the extraction of datum fields by learned and hand-written rules.", "labels": [], "entities": [{"text": "named entity resolution", "start_pos": 26, "end_pos": 49, "type": "TASK", "confidence": 0.7077411015828451}, {"text": "F1", "start_pos": 72, "end_pos": 74, "type": "METRIC", "confidence": 0.8870476484298706}]}, {"text": "ing parse nodes as to whether they refer to the value of associated Subject or Treatment fields, and restricting rules to necessarily include nodes that match the protein mention.", "labels": [], "entities": []}, {"text": "These experiments targeted the two datum fields (subject and treatment) that correspond to extractible entities, and focus on the three important assay types (phos, ubiq, and GTP-assoc) for which we had written ODIN rules while implementing our heuristic datum extractor.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 3: F1 performance in the extraction of da- tum fields by learned and hand-written rules.", "labels": [], "entities": [{"text": "F1", "start_pos": 10, "end_pos": 12, "type": "METRIC", "confidence": 0.9987115859985352}, {"text": "extraction of da- tum fields", "start_pos": 32, "end_pos": 60, "type": "TASK", "confidence": 0.8167900045712789}]}]}