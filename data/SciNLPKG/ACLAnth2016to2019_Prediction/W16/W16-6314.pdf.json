{"title": [{"text": "Constraint Grammar-based conversion of Dependency Treebanks", "labels": [], "entities": [{"text": "Constraint Grammar-based conversion", "start_pos": 0, "end_pos": 35, "type": "TASK", "confidence": 0.6359299818674723}, {"text": "Dependency Treebanks", "start_pos": 39, "end_pos": 59, "type": "DATASET", "confidence": 0.6088315099477768}]}], "abstractContent": [{"text": "This paper presents anew method for the conversion of one style of dependency treebanks into another, using contextual, Constraint Grammar-based transformation rules for both structural changes (attachment) and changes in syntactic-functional tags (edge labels).", "labels": [], "entities": []}, {"text": "In particular, we address the conversion of traditional syntactic dependency annotation into the semantically motivated dependency annotation used in the Universal Dependencies (UD) Framework, evaluating this task for the Portuguese Floresta Sint\u00e1(c)tica treebank.", "labels": [], "entities": [{"text": "Portuguese Floresta Sint\u00e1(c)tica treebank", "start_pos": 222, "end_pos": 263, "type": "DATASET", "confidence": 0.8079915642738342}]}, {"text": "Finally, we examine the effect of the UD converter on a rule-based dependency parser for English (EngGram).", "labels": [], "entities": []}, {"text": "Exploiting the ensuing comparability and using the existing UD Web treebank as a gold standard, we discuss the parser's performance and the validity of UD-mediated evaluation.", "labels": [], "entities": [{"text": "UD Web treebank", "start_pos": 60, "end_pos": 75, "type": "DATASET", "confidence": 0.846174399058024}]}], "introductionContent": [{"text": "Dependency parsers have become a standard module in language technology program pipelines, providing structural information for higher-level tasks such as Information Extraction) and Machine Translation ().", "labels": [], "entities": [{"text": "Dependency parsers", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.7730910778045654}, {"text": "Information Extraction", "start_pos": 155, "end_pos": 177, "type": "TASK", "confidence": 0.7441137433052063}, {"text": "Machine Translation", "start_pos": 183, "end_pos": 202, "type": "TASK", "confidence": 0.8273149132728577}]}, {"text": "Dependency links are computationally easy to process because they are token-based, but they also provide a syntactic bridge for the assignment or approximation of semantic relations.", "labels": [], "entities": [{"text": "assignment or approximation of semantic relations", "start_pos": 132, "end_pos": 181, "type": "TASK", "confidence": 0.703086331486702}]}, {"text": "In order to facilitate such a semantic interpretation of dependency trees, some descriptive conventions within dependency grammar have moved from syntactically motivated attachment to direct links between content words, regarding function words auxiliaries, subordinating conjunctions) as dependents -and never heads -of content words (nouns, verbs, adjectives).", "labels": [], "entities": []}, {"text": "Such semantic dependencies are used, for instance, to link semantic roles in the tecto-grammatical layer of the Prague Dependency treebank (B\u00f6hmov\u00e1 2013), and they are also an important design feature in Universal Dependencies (), anew standard for dependency annotation designed to facilitate the exchange of tools and data across languages.", "labels": [], "entities": [{"text": "Prague Dependency treebank (B\u00f6hmov\u00e1 2013)", "start_pos": 112, "end_pos": 153, "type": "DATASET", "confidence": 0.9465212821960449}]}, {"text": "In addition, being a descriptive rather than a procedural standard, the Universal Dependencies (UD) framework not only makes it easier to use a given tool with input from different languages, but also to use different tools for the same language in a comparable fashion, making the output interpretable across paradigms, and allowing higher-level applications to work independently of the dependency technology used.", "labels": [], "entities": []}, {"text": "In order for this setup to work, however, interoperability is important, and the output from existing parsers (or, in machine learning, their input from training treebanks) has to be converted into the new formalism.", "labels": [], "entities": []}, {"text": "Syntactic conversion tasks are not anew issue: For instance, many dependency treebanks are converted versions of constituent treebanks, usually employing hand-written rules (e.g. tregex patterns,).", "labels": [], "entities": [{"text": "Syntactic conversion", "start_pos": 0, "end_pos": 20, "type": "TASK", "confidence": 0.7250712215900421}]}, {"text": "In this paper, we describe a method for the conversion of syntactic Constraint Grammar (CG) dependencies, using the same type of rules (i.e. CG) for the conversion as are used in the parser itself.", "labels": [], "entities": [{"text": "conversion of syntactic Constraint Grammar (CG) dependencies", "start_pos": 44, "end_pos": 104, "type": "TASK", "confidence": 0.8357711964183383}]}, {"text": "This way, all contextual information can be integrated seamlessly, and unlike simple regular expressions, a CG conversion rule can make use of complex contextual constraints and relational information, such as propagated dependency links.", "labels": [], "entities": [{"text": "CG conversion", "start_pos": 108, "end_pos": 121, "type": "TASK", "confidence": 0.7246566116809845}]}, {"text": "Also, topological constraints (n-gram context or unbounded left-or right-searches) and nontopological constraints (dependencies) can be addressed at the same time, or even in the same rule.", "labels": [], "entities": []}, {"text": "Since CG rules are run in modular batches and allow the use of environment variables or input-driven flags, language-specific conversion needs can be addressed in a flexible way within the same grammar..", "labels": [], "entities": []}], "datasetContent": [{"text": "Though our method allows the formulation of conversion rules for any kind of dependency treebank, we chose UD conversion of two specific treebanks for testing -the Danish Arboretum treebank 8 (423.000 tokens) and the Portuguese Floresta treebank 9 (210.000 tokens,, both using the afore-mentioned VISL annotation style . In this setting, conversion speed was about 25.000 tokens/sec on a single 4-core machine with a Linux OS.", "labels": [], "entities": [{"text": "UD conversion", "start_pos": 107, "end_pos": 120, "type": "TASK", "confidence": 0.7846675515174866}, {"text": "Danish Arboretum treebank 8", "start_pos": 164, "end_pos": 191, "type": "DATASET", "confidence": 0.9526151567697525}, {"text": "Portuguese Floresta treebank 9", "start_pos": 217, "end_pos": 247, "type": "DATASET", "confidence": 0.6999045088887215}]}, {"text": "Ina live parsing pipeline using rule-based parsers 11 this amounts to only a slight increase in CPU time.", "labels": [], "entities": []}, {"text": "The Floresta treebank uses ordinary function labels for the constituents in coordination ellipsis -the same ones that would have been used in the presence of a -repeated -verb.", "labels": [], "entities": [{"text": "Floresta treebank", "start_pos": 4, "end_pos": 21, "type": "DATASET", "confidence": 0.7465545535087585}]}, {"text": "evaluation of just the conversion method, comparing live, UD-converted EngGram output against the English test section of the UD Web Treebank . While UD-conversion did make a direct comparison possible, we also encountered along list of unexpected problems even in the face of converted labels and attachments, caused in particular by conflicts between the publically available UD Web Treebank and official UD guidelines (e.g. name heads, punctuation attachment).", "labels": [], "entities": [{"text": "UD Web Treebank", "start_pos": 126, "end_pos": 141, "type": "DATASET", "confidence": 0.9139989415804545}, {"text": "UD Web Treebank", "start_pos": 378, "end_pos": 393, "type": "DATASET", "confidence": 0.7844781478246053}]}, {"text": "Any such difference will look like a performance error in the evaluated system, while in reality it is a consistency error in the treebank.", "labels": [], "entities": []}, {"text": "These problems were furhter aggravated by some lexicon-based \"idiosyncratic\" tokenization in both the UD treebank (e.g. some hyphenated words are split, some aren't) and the input parsers (that used closed-class MWEs).", "labels": [], "entities": [{"text": "UD treebank", "start_pos": 102, "end_pos": 113, "type": "DATASET", "confidence": 0.8155114948749542}]}, {"text": "Forcing the latter to accept the tokenization of the former with the help of an additional preprocessor improved alignment, but at the price of potentially detrimental changes in rule performance, for instance where a contextual reference to a given MWE cannot be instantiated, because it has been split.", "labels": [], "entities": [{"text": "alignment", "start_pos": 113, "end_pos": 122, "type": "METRIC", "confidence": 0.9313115477561951}]}, {"text": "Performance figures naturally reflect all of these issues on top of EngGram and conversion accuracy as such.", "labels": [], "entities": [{"text": "EngGram", "start_pos": 68, "end_pos": 75, "type": "DATASET", "confidence": 0.8217153549194336}, {"text": "accuracy", "start_pos": 91, "end_pos": 99, "type": "METRIC", "confidence": 0.9729906916618347}]}, {"text": "In addition, the \"as-is\" run on force-tokenized raw test also includes errors from the morphosyntactic stage of EngGram, propagating into the dependency stage.", "labels": [], "entities": []}, {"text": "Thus, providing the dependency stage with hand-corrected morphosyntactic input improved performance, providing a cleaner picture of structural and categorial conversion efficiency.", "labels": [], "entities": []}, {"text": "This treebank uses the CoNLL format (), for which EngGram has an export option.", "labels": [], "entities": [{"text": "CoNLL format", "start_pos": 23, "end_pos": 35, "type": "DATASET", "confidence": 0.8824303150177002}, {"text": "EngGram", "start_pos": 50, "end_pos": 57, "type": "DATASET", "confidence": 0.9291884303092957}]}], "tableCaptions": [{"text": " Table 2: Performance of Conversion Grammar", "labels": [], "entities": []}]}