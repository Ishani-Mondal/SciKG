{"title": [{"text": "Do Characters Abuse More Than Words?", "labels": [], "entities": []}], "abstractContent": [{"text": "Although word and character n-grams have been used as features in different NLP applications, no systematic comparison or analysis has shown the power of character-based features for detecting abusive language.", "labels": [], "entities": []}, {"text": "In this study, we investigate the effectiveness of such features for abusive language detection in user-generated online comments, and show that such methods outperform previous state-of-the-art approaches and other strong baselines.", "labels": [], "entities": [{"text": "abusive language detection", "start_pos": 69, "end_pos": 95, "type": "TASK", "confidence": 0.7333906690279642}]}], "introductionContent": [{"text": "The rise of online communities over the last ten years, in various forms such as message boards, twitter, discussion forums, etc., have allowed people from disparate backgrounds to connect in away that would not have been possible before.", "labels": [], "entities": []}, {"text": "However, the ease of communication online has made it possible for both anonymous and nonanonymous posters to hurl insults, bully, and threaten through the use of profanity and hate speech, all of which can be framed as \"abusive language.\"", "labels": [], "entities": []}, {"text": "Although detection of some of the more straightforward examples of abusive language can be handled effectively through blacklists and regular expressions, as in \"I am surprised these fuckers reported on this crap\", more complex methods are required to address the more nuanced cases, as in \"Add anotherJEW fined a bi$$ion for stealing like a lil maggot.", "labels": [], "entities": []}, {"text": "In that example, there are tokenization and normalization issues, as well as a conscious bastardization of words in an effort to evade blacklists or to add color to the post.", "labels": [], "entities": []}, {"text": "While previous work for detecting abusive language has been dominated by lexical-based approaches, we claim that morphological features play a more significant role in this task.", "labels": [], "entities": [{"text": "detecting abusive language", "start_pos": 24, "end_pos": 50, "type": "TASK", "confidence": 0.8791728019714355}]}, {"text": "This is based on the observation that user language evolves either consciously or unconsciously based on standards and guidelines imposed by media companies that users must adhere to, in conjunction with regular expressions and blacklists, to catch bad language and consequently remove a post.", "labels": [], "entities": []}, {"text": "Essentially, users learn overtime not to use common lexical items and words to convey certain language.", "labels": [], "entities": []}, {"text": "Thus, characters often play an important role in the comment language.", "labels": [], "entities": []}, {"text": "Characters, in combination with words, can act as basic phonetic, morpho-lexical and semantic units in comments such as \"ki11 yrslef a$$hole\".", "labels": [], "entities": []}, {"text": "Character n-grams have been proven useful for other NLP tasks such as authorship identification, native language identification) and machine translation), but surprisingly have not been the focus in prior work for abusive language.", "labels": [], "entities": [{"text": "authorship identification", "start_pos": 70, "end_pos": 95, "type": "TASK", "confidence": 0.8591079711914062}, {"text": "native language identification", "start_pos": 97, "end_pos": 127, "type": "TASK", "confidence": 0.609372744957606}, {"text": "machine translation", "start_pos": 133, "end_pos": 152, "type": "TASK", "confidence": 0.7706656157970428}]}, {"text": "In this paper, we investigate the role that character n-grams play in this task by exploring their use in two different algorithms.", "labels": [], "entities": []}, {"text": "We compare their results to two state-of-the-art approaches by evaluating on a corpus of nearly 1M comments.", "labels": [], "entities": []}, {"text": "Briefly, our contributions are summarized as follows: 1) character n-grams outperform word n-grams in both algorithms, and 2) the models proposed in this work outperform the previous state-of-the-art for this dataset.", "labels": [], "entities": []}], "datasetContent": [{"text": "We use the same dataset employed in and.", "labels": [], "entities": []}, {"text": "The labels came from a combination of in-house raters, users reactively flagging bad comments and abusive language pattern detectors.", "labels": [], "entities": []}, {"text": "To date, this is the largest dataset available for abusive language detection.", "labels": [], "entities": [{"text": "abusive language detection", "start_pos": 51, "end_pos": 77, "type": "TASK", "confidence": 0.6557413836320242}]}, {"text": "We use this dataset so as to directly compare with that prior work, and in doing so, we also adopt their evaluation methodology and employ 5-fold cross-validation and report AUC, in addition to recall, precision and F-1.", "labels": [], "entities": [{"text": "AUC", "start_pos": 174, "end_pos": 177, "type": "METRIC", "confidence": 0.8029757142066956}, {"text": "recall", "start_pos": 194, "end_pos": 200, "type": "METRIC", "confidence": 0.9996515512466431}, {"text": "precision", "start_pos": 202, "end_pos": 211, "type": "METRIC", "confidence": 0.9995612502098083}, {"text": "F-1", "start_pos": 216, "end_pos": 219, "type": "METRIC", "confidence": 0.9938293099403381}]}, {"text": "As an additional baseline, we developed a token n-gram classifier with n = 1..5 using a logistic regression classifier.", "labels": [], "entities": []}, {"text": "shows the results of all experiments.", "labels": [], "entities": []}, {"text": "The four baselines (,, token n-grams and C2V) are listed in the first seven rows, and the NBVSM and RNNLM experiments are listed under the double line.", "labels": [], "entities": [{"text": "NBVSM", "start_pos": 90, "end_pos": 95, "type": "DATASET", "confidence": 0.9637387990951538}, {"text": "RNNLM", "start_pos": 100, "end_pos": 105, "type": "DATASET", "confidence": 0.6156896948814392}]}, {"text": "We also show the results of a method which combines the token n-grams with the features from the best performing versions of the C2V, NBSVM and RNNLM classes, using our SVM classifier (\"Combination\").", "labels": [], "entities": [{"text": "NBSVM", "start_pos": 134, "end_pos": 139, "type": "DATASET", "confidence": 0.8932335376739502}]}], "tableCaptions": []}