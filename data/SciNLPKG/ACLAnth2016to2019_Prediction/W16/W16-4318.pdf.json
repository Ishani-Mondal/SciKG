{"title": [{"text": "A domain-agnostic approach for opinion prediction on speech", "labels": [], "entities": [{"text": "opinion prediction", "start_pos": 31, "end_pos": 49, "type": "TASK", "confidence": 0.8582397103309631}]}], "abstractContent": [{"text": "We explore a domain-agnostic approach for analyzing speech with the goal of opinion prediction.", "labels": [], "entities": [{"text": "opinion prediction", "start_pos": 76, "end_pos": 94, "type": "TASK", "confidence": 0.7962470948696136}]}, {"text": "We represent the speech signal by mel-frequency cepstral coefficients and apply long short-term memory neural networks to automatically learn temporal regularities in speech.", "labels": [], "entities": []}, {"text": "In contrast to previous work, our approach does not require complex feature engineering and works without textual transcripts.", "labels": [], "entities": []}, {"text": "As a consequence, it can easily be applied on various speech analysis tasks for different languages and the results show that it can nevertheless be competitive to the state-of-the-art in opinion prediction.", "labels": [], "entities": [{"text": "speech analysis tasks", "start_pos": 54, "end_pos": 75, "type": "TASK", "confidence": 0.7858052055040995}, {"text": "opinion prediction", "start_pos": 188, "end_pos": 206, "type": "TASK", "confidence": 0.8351757228374481}]}, {"text": "Ina detailed error analysis for opinion mining we find that our approach performs well in identifying speaker-specific characteristics, but should be combined with additional information if subtle differences in the linguistic content need to be identified.", "labels": [], "entities": [{"text": "opinion mining", "start_pos": 32, "end_pos": 46, "type": "TASK", "confidence": 0.8413797616958618}]}], "introductionContent": [{"text": "Traditional natural language processing approaches have focused on the analysis of linguistic content and the represented information.", "labels": [], "entities": []}, {"text": "With the increasing availability of recorded speech, the interest shifted from pure content processing to analyzing the states and traits of speakers (.", "labels": [], "entities": []}, {"text": "For this purpose, paralinguistic features such as pitch and loudness of voice are playing an important role because they are very predictive social markers.", "labels": [], "entities": []}, {"text": "They influence our persuasiveness (), indicate our emotional state and correlate with our personality traits (.", "labels": [], "entities": []}, {"text": "The ability to analyze paralinguistic features has led to progress in a multitude of speech processing tasks such as age identification, personality recognition () and emotion recognition (.", "labels": [], "entities": [{"text": "age identification", "start_pos": 117, "end_pos": 135, "type": "TASK", "confidence": 0.6750550717115402}, {"text": "personality recognition", "start_pos": 137, "end_pos": 160, "type": "TASK", "confidence": 0.7122048139572144}, {"text": "emotion recognition", "start_pos": 168, "end_pos": 187, "type": "TASK", "confidence": 0.7147833555936813}]}, {"text": "A subset of these problems is tackled every year as shared tasks in the Computational Paralinguistics Challenge at the INTERSPEECH conference ().", "labels": [], "entities": [{"text": "INTERSPEECH conference", "start_pos": 119, "end_pos": 141, "type": "DATASET", "confidence": 0.9352131187915802}]}, {"text": "For the winning methods of the last editions from these shared tasks, thorough task-specific feature engineering has usually been the key point.", "labels": [], "entities": []}, {"text": "In this paper, we aim at reducing the engineering effort and the dependence on domain-specific knowledge in speech processing tasks for opinion prediction.", "labels": [], "entities": [{"text": "opinion prediction", "start_pos": 136, "end_pos": 154, "type": "TASK", "confidence": 0.8868593275547028}]}, {"text": "We approach this goal by applying deep learning methods which have been shown to automatically learn more complex and high-level features from basic features extracted from the signal ().", "labels": [], "entities": []}, {"text": "The main challenge for applying these approaches lies in determining a good representation of the data and choosing a suitable architecture for the task at hand.", "labels": [], "entities": []}, {"text": "For our approach, we use only the speech signal as input, so that expensive textual transcripts are not required.", "labels": [], "entities": []}, {"text": "We work on the frame level 2 and choose mel-frequency cepstral coefficients (MFCCs) as our unit of representation because they correspond well to the human auditory system and are very discriminative for speech processing tasks, such as phoneme recognition 2016).", "labels": [], "entities": [{"text": "mel-frequency cepstral coefficients (MFCCs)", "start_pos": 40, "end_pos": 83, "type": "METRIC", "confidence": 0.7586050232251486}, {"text": "phoneme recognition", "start_pos": 237, "end_pos": 256, "type": "TASK", "confidence": 0.7443912029266357}]}, {"text": "analyzes that speech perception is strongly influenced by temporal dependencies.", "labels": [], "entities": []}, {"text": "We therefore model the speech signal as a time series and use long short-term neural networks as machine learning method.", "labels": [], "entities": []}, {"text": "In contrast to previous approaches in computational paralinguistics, we do not need to compute additional task-specific statistics on the features extracted from the frames because LSTM networks are able to learn the temporal regularities automatically from the input signal.", "labels": [], "entities": []}, {"text": "This makes it possible to apply our approach to different tasks without additional engineering.", "labels": [], "entities": []}, {"text": "In order to test whether our approach can compete with state-of-the-art methods, we focus on two interesting tasks concerning speech: opinion mining and persuasiveness prediction.", "labels": [], "entities": [{"text": "opinion mining", "start_pos": 134, "end_pos": 148, "type": "TASK", "confidence": 0.8441130220890045}, {"text": "persuasiveness prediction", "start_pos": 153, "end_pos": 178, "type": "TASK", "confidence": 0.7308961600065231}]}, {"text": "For both tasks, the goal can be framed as opinion prediction, but the perspective differs.", "labels": [], "entities": [{"text": "opinion prediction", "start_pos": 42, "end_pos": 60, "type": "TASK", "confidence": 0.7505813241004944}]}, {"text": "In the first task, our goal is to predict the opinion of a user speaking about a product.", "labels": [], "entities": [{"text": "predict the opinion of a user speaking about a product", "start_pos": 34, "end_pos": 88, "type": "TASK", "confidence": 0.7829541862010956}]}, {"text": "In the second task, we aim at predicting the influence of a speaker on the opinion of an audience.", "labels": [], "entities": [{"text": "predicting the influence of a speaker", "start_pos": 30, "end_pos": 67, "type": "TASK", "confidence": 0.7994057238101959}]}, {"text": "Previous approaches to these tasks developed a sophisticated feature set to capture the recognition of emotions for opinion mining ( and the characteristics of voice quality for persuasiveness prediction.", "labels": [], "entities": [{"text": "opinion mining", "start_pos": 116, "end_pos": 130, "type": "TASK", "confidence": 0.8535606563091278}, {"text": "persuasiveness prediction", "start_pos": 178, "end_pos": 203, "type": "TASK", "confidence": 0.7392180562019348}]}, {"text": "We find that the results of our domain-agnostic approach come close to the performance of domainspecific ones that apply thorough feature engineering.", "labels": [], "entities": []}, {"text": "As we use the same features for different tasks, we minimize the risk of overfitting to the data.", "labels": [], "entities": []}, {"text": "Our error analysis explain in more details the issues with our approach in both datasets, but also highlight how far a generic computational method based solely on speech can go in tasks related to opinion prediction.", "labels": [], "entities": [{"text": "opinion prediction", "start_pos": 198, "end_pos": 216, "type": "TASK", "confidence": 0.8973165452480316}]}], "datasetContent": [{"text": "The Multimodal Opinion Utterance Dataset () is a collection of video blogs extracted from YouTube.", "labels": [], "entities": []}, {"text": "It consists of videos from 80 Spanish native speakers (15 male, 65 female) who express their opinion about movies, books and cosmetics.", "labels": [], "entities": []}, {"text": "shows an example of a review and the corresponding speech signal from the utterance.", "labels": [], "entities": []}, {"text": "The speakers' age ranges from 20 to 60 years.", "labels": [], "entities": []}, {"text": "manually extracted a 30 seconds opinion snippet from each video and segmented it into utterances yielding a total of 498 utterances.", "labels": [], "entities": []}, {"text": "Each utterance was then analyzed by two annotators to determine whether the speaker reveals a positive, neutral or negative sentiment towards the product.", "labels": [], "entities": []}, {"text": "They report an inter-annotator agreement of 0.88 and a kappa of 0.81.", "labels": [], "entities": [{"text": "kappa", "start_pos": 55, "end_pos": 60, "type": "METRIC", "confidence": 0.9805172085762024}]}, {"text": "Conflicting annotations were subsequently resolved by discussions.", "labels": [], "entities": []}, {"text": "We use the publicly available dataset and exclude utterances with a neutral label from our experiments to be consistent with previous work).", "labels": [], "entities": []}, {"text": "The MFCCs were extracted using the python library python speech features.", "labels": [], "entities": []}, {"text": "The window size was 25 ms with a sliding window of 10 ms.", "labels": [], "entities": []}, {"text": "The Keras framework 9 was used for implementing the LSTMs.", "labels": [], "entities": [{"text": "Keras framework 9", "start_pos": 4, "end_pos": 21, "type": "DATASET", "confidence": 0.8688792785008749}]}, {"text": "The code from both experiments is available on GitHub.", "labels": [], "entities": []}, {"text": "Opinion Mining The audio files from this dataset have a sampling rate of 44,100 Hz.", "labels": [], "entities": [{"text": "Opinion Mining", "start_pos": 0, "end_pos": 14, "type": "TASK", "confidence": 0.6920902878046036}]}, {"text": "We have implemented a bi-directional LSTM with 128 nodes at each hidden layer.", "labels": [], "entities": []}, {"text": "The batch size is 128 and the dataset is divided into 10 folds in order to perform cross-validation.", "labels": [], "entities": []}, {"text": "Each utterance is preprocessed, and sequences with a length greater than 236 were truncated.", "labels": [], "entities": []}, {"text": "Adam is used as optimizer and binary cross-entropy is used as loss function.", "labels": [], "entities": []}, {"text": "We use hyperbolic tangent as activation function for all hidden layers and for the merging layer.", "labels": [], "entities": []}, {"text": "The last fully connected layer which assigns the binary label to the sequence uses sigmoid as activation function.", "labels": [], "entities": []}, {"text": "All hyperparameters were set based on empirical evidence obtained from experiments on a single fold.", "labels": [], "entities": []}, {"text": "Persuasion Prediction We extracted the speech signal for each debater with FFmpeg.", "labels": [], "entities": [{"text": "Persuasion Prediction", "start_pos": 0, "end_pos": 21, "type": "TASK", "confidence": 0.7681721150875092}, {"text": "FFmpeg", "start_pos": 75, "end_pos": 81, "type": "METRIC", "confidence": 0.669209897518158}]}, {"text": "The audio segments have a sampling rate of 48,000 Hz.", "labels": [], "entities": []}, {"text": "In contrast to the input sequences from the MOUD dataset which were split into utterances and lasted only a few seconds, the segments in the Intelligence Squared dataset last a few minutes resulting in up to 25,000 frames.", "labels": [], "entities": [{"text": "MOUD dataset", "start_pos": 44, "end_pos": 56, "type": "DATASET", "confidence": 0.9324758648872375}, {"text": "Intelligence Squared dataset", "start_pos": 141, "end_pos": 169, "type": "DATASET", "confidence": 0.8195237517356873}]}, {"text": "We apply padding to the shorter sequences.", "labels": [], "entities": []}, {"text": "We implemented an LSTM network with hidden layers containing 64 nodes in the Keras framework.", "labels": [], "entities": [{"text": "Keras framework", "start_pos": 77, "end_pos": 92, "type": "DATASET", "confidence": 0.9064133763313293}]}, {"text": "We use hyperbolic tangent as activation function and a dropout of 0.2 for both the matrix and the recurrent weights.", "labels": [], "entities": []}, {"text": "The last layer is a fully connected layer with a single node and a sigmoid activation function which assigns the label to the sequence.", "labels": [], "entities": []}, {"text": "The label indicates whether the debater belongs to the winning or the losing team.", "labels": [], "entities": []}, {"text": "We use binary cross-entropy as loss function, RMSProp as optimizer, and a batch size of 1.", "labels": [], "entities": []}, {"text": "The hyperparameters were set based on empirical evidence from experiments on a single fold.", "labels": [], "entities": []}, {"text": "Like, we perform a leave-one-debate-out cross-validation to avoid a topic-specific bias.", "labels": [], "entities": []}, {"text": "The data is split into 30 different folds, each using 29 debates for training and the remaining debate for testing.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Accuracy results for persuasion prediction at the individual level and the debate level.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.99897301197052}, {"text": "persuasion prediction", "start_pos": 31, "end_pos": 52, "type": "TASK", "confidence": 0.9190982282161713}]}, {"text": " Table 3: Number of corrected predictions, ties and wrong predictions for the debate-level.", "labels": [], "entities": [{"text": "Number", "start_pos": 10, "end_pos": 16, "type": "METRIC", "confidence": 0.9807140231132507}]}]}