{"title": [{"text": "Detecting novel metaphor using selectional preference information", "labels": [], "entities": [{"text": "Detecting", "start_pos": 0, "end_pos": 9, "type": "TASK", "confidence": 0.9694294929504395}]}], "abstractContent": [{"text": "Recent work on metaphor processing often employs selectional preference information.", "labels": [], "entities": [{"text": "metaphor processing", "start_pos": 15, "end_pos": 34, "type": "TASK", "confidence": 0.9677680432796478}]}, {"text": "We present a comparison of different approaches to the modelling of selectional preferences , based on various ways of generalizing over corpus frequencies.", "labels": [], "entities": []}, {"text": "We evaluate on the VU Amsterdam Metaphor corpus, abroad corpus of metaphor.", "labels": [], "entities": [{"text": "VU Amsterdam Metaphor corpus", "start_pos": 19, "end_pos": 47, "type": "DATASET", "confidence": 0.9066953659057617}, {"text": "abroad corpus of metaphor", "start_pos": 49, "end_pos": 74, "type": "DATASET", "confidence": 0.8817654103040695}]}, {"text": "We find that using only selectional preference information is enough to outperform an all-metaphor baseline classification , but that generalization through prediction or clustering is not beneficial.", "labels": [], "entities": []}, {"text": "A possible explanation for this lies in the nature of the evaluation data, and lack of power of se-lectional preference information on its own for non-novel metaphor detection.", "labels": [], "entities": [{"text": "metaphor detection", "start_pos": 157, "end_pos": 175, "type": "TASK", "confidence": 0.7255156934261322}]}, {"text": "To better investigate the role of metaphor type in metaphor detection, we suggest a resource with annotation of novel metaphor should be created.", "labels": [], "entities": [{"text": "metaphor detection", "start_pos": 51, "end_pos": 69, "type": "TASK", "confidence": 0.9037315845489502}]}], "introductionContent": [{"text": "Within natural language processing (NLP), there has been an increasing interest in the processing of figurative language in recent years.", "labels": [], "entities": [{"text": "natural language processing (NLP)", "start_pos": 7, "end_pos": 40, "type": "TASK", "confidence": 0.8132878839969635}]}, {"text": "This increasing interest is exemplified by the (NA)ACL workshops on metaphor in NLP, and shared tasks like SemEval-2015, Task 11, about sentiment analysis of figurative language in Twitter.", "labels": [], "entities": [{"text": "sentiment analysis of figurative language", "start_pos": 136, "end_pos": 177, "type": "TASK", "confidence": 0.8868456721305847}]}, {"text": "The main benefits of improved treatment of figurative language within NLP lie with high-level tasks dependent on semantics, such as semantic parsing.", "labels": [], "entities": [{"text": "semantic parsing", "start_pos": 132, "end_pos": 148, "type": "TASK", "confidence": 0.7218209207057953}]}, {"text": "For example, in multilingual semantic parsing, one would like to see both the English 'This textbook costs an arm and a leg.' and the Dutch 'Dit lesboek kost een rib uit het lijf.'", "labels": [], "entities": [{"text": "multilingual semantic parsing", "start_pos": 16, "end_pos": 45, "type": "TASK", "confidence": 0.6510179738203684}]}, {"text": "(lit. 'This textbook costs a rib from the body.')", "labels": [], "entities": []}, {"text": "to be mapped to the same meaning representation, which should not include references to any of the body parts used in the idiomatic expressions.", "labels": [], "entities": []}, {"text": "In this paper, we focus on one area of figurative language processing, namely the detection of novel metaphor, and especially the utility of selectional preference features for this task.", "labels": [], "entities": [{"text": "figurative language processing", "start_pos": 39, "end_pos": 69, "type": "TASK", "confidence": 0.7585039734840393}, {"text": "detection of novel metaphor", "start_pos": 82, "end_pos": 109, "type": "TASK", "confidence": 0.7711930871009827}]}, {"text": "By doing this, we hope to answer a two-fold question: can selectional preference information be used to successfully detect novel metaphor?", "labels": [], "entities": []}, {"text": "And how do generalization methods influence the effectiveness of selectional preference information?", "labels": [], "entities": []}], "datasetContent": [{"text": "We evaluate the approaches on the VU Amsterdam Metaphor corpus (VUAMC) . The corpus is preprocessed by extracting all raw text, and marking each word with the attribute function=\"mrw\", which indicates a metaphor-related word, as metaphor.", "labels": [], "entities": [{"text": "VU Amsterdam Metaphor corpus (VUAMC)", "start_pos": 34, "end_pos": 70, "type": "DATASET", "confidence": 0.922757089138031}]}, {"text": "This results in a corpus of 40,622 verbs, of which 23,069 have at least one subject or object relation.", "labels": [], "entities": []}, {"text": "We split the data three-way: verbs with only a subject (13,466 pairs), verbs with only an object (3,913 pairs), and verbs with both a subject and an object (5,539 triples).", "labels": [], "entities": []}, {"text": "We use this corpus since it is the largest corpus with metaphor annotations available.", "labels": [], "entities": []}, {"text": "The downside is that it includes a large number of very conventionalized metaphors, and there is no annotation of novel metaphor or a degree of metaphoricity.", "labels": [], "entities": []}, {"text": "Evaluation is performed using a logistic regression classifier, which takes one or more of the selectional preference-based features.", "labels": [], "entities": []}, {"text": "The features used are: conditional probability, log probability, selectional preference strength and selectional association, for subject-verb and object-verb pairs, and based on corpus frequencies, predictions or clusterings.", "labels": [], "entities": []}, {"text": "We use only those features which are available, i.e. for the subject dataset we only use the four features for subject-verb pairs, while in the subject-andobject dataset we use eight features, four based on the subject-verb pair and four based on the objectverb pair.", "labels": [], "entities": []}, {"text": "Model fitting and evaluation is done using 10-fold cross validation, and l2-regularization with strength 1 is applied.", "labels": [], "entities": [{"text": "Model fitting", "start_pos": 0, "end_pos": 13, "type": "TASK", "confidence": 0.6666753441095352}]}, {"text": "In case of missing data points (e.g. no cluster available for the verb/noun), the majority class (non-metaphor) is assigned.", "labels": [], "entities": []}, {"text": "As a baseline, we calculate the score when classifying all items as metaphor.", "labels": [], "entities": []}, {"text": "In addition, we evaluate the effect of re-weighting examples.", "labels": [], "entities": []}, {"text": "Beigman, who also evaluated their metaphor detection system on the VUAMC, showed that re-weighting training examples can have a large impact on performance, due to the large class imbalance in the VUAMC (mostly non-metaphor).", "labels": [], "entities": [{"text": "metaphor detection", "start_pos": 34, "end_pos": 52, "type": "TASK", "confidence": 0.7532017529010773}, {"text": "VUAMC", "start_pos": 67, "end_pos": 72, "type": "DATASET", "confidence": 0.9821745157241821}, {"text": "VUAMC", "start_pos": 197, "end_pos": 202, "type": "DATASET", "confidence": 0.963509202003479}]}, {"text": "They find that re-weighting examples increases F1-score by sacrificing precision fora large increase in recall.", "labels": [], "entities": [{"text": "F1-score", "start_pos": 47, "end_pos": 55, "type": "METRIC", "confidence": 0.9994311928749084}, {"text": "precision", "start_pos": 71, "end_pos": 80, "type": "METRIC", "confidence": 0.999032735824585}, {"text": "recall", "start_pos": 104, "end_pos": 110, "type": "METRIC", "confidence": 0.9982349872589111}]}], "tableCaptions": [{"text": " Table 3: F1-scores on metaphor identification using Brown", "labels": [], "entities": [{"text": "F1-scores", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9988403916358948}, {"text": "metaphor identification", "start_pos": 23, "end_pos": 46, "type": "TASK", "confidence": 0.9781294465065002}]}, {"text": " Table 4: F1-scores on metaphor identification using word", "labels": [], "entities": [{"text": "F1-scores", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9986932873725891}, {"text": "metaphor identification", "start_pos": 23, "end_pos": 46, "type": "TASK", "confidence": 0.9648425877094269}]}]}