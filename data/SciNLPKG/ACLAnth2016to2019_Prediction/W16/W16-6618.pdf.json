{"title": [{"text": "Statistics-Based Lexical Choice for NLG from Quantitative Information", "labels": [], "entities": []}], "abstractContent": [{"text": "We discuss a fully statistical approach to the expression of quantitative information in En-glish.", "labels": [], "entities": []}, {"text": "We outline the approach, focussing on the problem of Lexical Choice.", "labels": [], "entities": [{"text": "Lexical Choice", "start_pos": 53, "end_pos": 67, "type": "TASK", "confidence": 0.849309116601944}]}, {"text": "An initial evaluation experiment suggests that it is worth investigating the method further.", "labels": [], "entities": []}], "introductionContent": [{"text": "NLG systems express information inhuman language.", "labels": [], "entities": []}, {"text": "To do this well, these systems need to \"know\"what expressions are most suitable for expressing a given piece of information.", "labels": [], "entities": []}, {"text": "The most direct way to define words in NLG systems is manual coding, as it was done in systems such as FoG ( and SumTime-Mousam (.", "labels": [], "entities": [{"text": "FoG", "start_pos": 103, "end_pos": 106, "type": "DATASET", "confidence": 0.9607463479042053}]}, {"text": "However, manual coding is time consuming, it can be argued to be theoretically unsatisfactory, and it is error prone even when performed by domain experts.", "labels": [], "entities": []}, {"text": "The process is complicated in the fact that words like pink) and evening () have different meanings for individual speakers.", "labels": [], "entities": []}, {"text": "Recent NLG approaches learn the use of words through statistical analysis of data-text corpora.", "labels": [], "entities": []}, {"text": "For example, Belz's semi-automatic system for weather forecasting automatically learns a grammar based on a pre-existing (i.e., manually coded) set of grammar rules.", "labels": [], "entities": [{"text": "weather forecasting", "start_pos": 46, "end_pos": 65, "type": "TASK", "confidence": 0.7079672366380692}]}, {"text": "developed a fully statistical alignment-based algorithm that automatically acquires a mapping from quantitative information to English words by adopting a hierarchical hidden semi-Markov model trained by Expectation Maximization.", "labels": [], "entities": [{"text": "Expectation Maximization", "start_pos": 204, "end_pos": 228, "type": "TASK", "confidence": 0.7111894488334656}]}, {"text": "introduced a generation model based on Liang's algorithm . However, these existing approaches have difficulty handling situations in which a word expresses a combination of data dimensions, for example as when the word \"mild\u00ebxpresses a combination of warm temperatures and low wind speed.", "labels": [], "entities": []}, {"text": "In this paper, we discuss anew approach to the problem; the approach is fully statistical and it is able to handle situations in which a word or phrase maps to a combination of data dimensions.", "labels": [], "entities": []}, {"text": "We focus on Lexical Choice but are investigating applications to other areas of NLG.", "labels": [], "entities": [{"text": "Lexical Choice", "start_pos": 12, "end_pos": 26, "type": "TASK", "confidence": 0.8534831404685974}]}], "datasetContent": [], "tableCaptions": []}