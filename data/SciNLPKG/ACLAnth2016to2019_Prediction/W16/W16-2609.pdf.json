{"title": [{"text": "Babler -Data Collection from the Web to Support Speech Recognition and Keyword Search", "labels": [], "entities": [{"text": "Babler -Data Collection", "start_pos": 0, "end_pos": 23, "type": "DATASET", "confidence": 0.8085903972387314}, {"text": "Speech Recognition", "start_pos": 48, "end_pos": 66, "type": "TASK", "confidence": 0.756060928106308}, {"text": "Keyword Search", "start_pos": 71, "end_pos": 85, "type": "TASK", "confidence": 0.6904354393482208}]}], "abstractContent": [{"text": "We describe a system to collect web data for Low Resource Languages, to augment language model training data for Automatic Speech Recognition (ASR) and keyword search by reducing the Out-of-Vocabulary (OOV) rates-words in the test set that did not appear in the training set for ASR.", "labels": [], "entities": [{"text": "Automatic Speech Recognition (ASR)", "start_pos": 113, "end_pos": 147, "type": "TASK", "confidence": 0.7916238208611807}, {"text": "keyword search", "start_pos": 152, "end_pos": 166, "type": "TASK", "confidence": 0.697947770357132}, {"text": "Out-of-Vocabulary (OOV) rates-words", "start_pos": 183, "end_pos": 218, "type": "METRIC", "confidence": 0.8100622534751892}, {"text": "ASR", "start_pos": 279, "end_pos": 282, "type": "TASK", "confidence": 0.9589053988456726}]}, {"text": "We test this system on seven Low Resource Languages from the IARPA Babel Program: Paraguayan Guarani, Igbo, Amharic, Halh Mongolian, Javanese, Pashto, and Dholuo.", "labels": [], "entities": [{"text": "IARPA Babel Program", "start_pos": 61, "end_pos": 80, "type": "DATASET", "confidence": 0.9111814697583517}]}, {"text": "The success of our system compared with other web collection systems is due to the targeted collection sources (blogs, twitter, forums) and the inclusion of a separate language identification component in its pipeline, which filters the data initially collected before finally saving it.", "labels": [], "entities": []}, {"text": "Our results show a major reduction of OOV rates relative to those calculated from training corpora alone and major reductions in OOV rates calculated in terms of keywords in the training development set.", "labels": [], "entities": [{"text": "OOV", "start_pos": 38, "end_pos": 41, "type": "METRIC", "confidence": 0.990113377571106}, {"text": "OOV", "start_pos": 129, "end_pos": 132, "type": "METRIC", "confidence": 0.9820110201835632}]}, {"text": "We also describe differences among genres in this reduction, which vary by language but show a pronounced influence for augmentation from Twitter data for most languages .", "labels": [], "entities": []}], "introductionContent": [{"text": "Collecting data from the web for commercial and research purposes has become a popular task, used fora wide variety of purposes in text and speech processing.", "labels": [], "entities": [{"text": "text and speech processing", "start_pos": 131, "end_pos": 157, "type": "TASK", "confidence": 0.6290080025792122}]}, {"text": "However, to date, most of this data collection has been done for English and other High Resource Languages (HRLs).", "labels": [], "entities": []}, {"text": "These languages are characterized by having extensive computational tools and large amounts of readily available web data and include languages such as French, Spanish, Mandarin, and German.", "labels": [], "entities": []}, {"text": "Low Resource Languages (LRLs), although many are spoken by millions of people, are much less likely and much more difficult to mine, due largely to the smaller presence these languages have on the web.", "labels": [], "entities": []}, {"text": "These include languages such as Paraguayan Guarni, Igbo, Amharic, Halh Mongolian, Javanese, Pashto, and Dholuo, inter alia.", "labels": [], "entities": []}, {"text": "In this paper we describe anew system which addresses the problem of collecting large amounts of LRL data from multiple web sources.", "labels": [], "entities": []}, {"text": "Unlike current HRL collection systems, Babler provides a targeted collection pipeline for social networks and conversational style text.", "labels": [], "entities": [{"text": "HRL collection", "start_pos": 15, "end_pos": 29, "type": "TASK", "confidence": 0.8699968755245209}]}, {"text": "The purpose of this data collection is to augment the training data used by Automatic Speech Recognition (ASR) to create language models ASR and for Keyword Search (KWS) for LRLs.", "labels": [], "entities": [{"text": "Automatic Speech Recognition (ASR)", "start_pos": 76, "end_pos": 110, "type": "TASK", "confidence": 0.7746553917725881}]}, {"text": "The more specific goal is to reduce the Out-of-Vocabulary (OOV) rates for languages when the amount of data in the training set is small and thus words in the test set may not occur in the training set.", "labels": [], "entities": [{"text": "the Out-of-Vocabulary (OOV) rates", "start_pos": 36, "end_pos": 69, "type": "METRIC", "confidence": 0.9107306698958079}]}, {"text": "Web data can add many additional words to the ASR and KWS lexicon which is shown to improve performance over WER and KW hit rate.", "labels": [], "entities": [{"text": "KWS lexicon", "start_pos": 54, "end_pos": 65, "type": "DATASET", "confidence": 0.8125681579113007}, {"text": "WER", "start_pos": 109, "end_pos": 112, "type": "METRIC", "confidence": 0.7366654276847839}]}, {"text": "Critically, this web data must be in a genre close to that of the ASR training and test sets which is the main reason we developed a pipeline that focuses on conversational style text.", "labels": [], "entities": [{"text": "ASR training", "start_pos": 66, "end_pos": 78, "type": "TASK", "confidence": 0.8608998954296112}]}, {"text": "In this paper we describe the properties which LRL web collection requires of systems, compare ours with other popular web collection and scraping software, and describe results achieved for reducing Word Error Rate (WER) for ASR and OOVs and improvements in the IARPA Babel keyword search task.", "labels": [], "entities": [{"text": "LRL web collection", "start_pos": 47, "end_pos": 65, "type": "TASK", "confidence": 0.7874637246131897}, {"text": "Word Error Rate (WER)", "start_pos": 200, "end_pos": 221, "type": "METRIC", "confidence": 0.8482494503259659}, {"text": "IARPA Babel keyword search task", "start_pos": 263, "end_pos": 294, "type": "TASK", "confidence": 0.6426618814468383}]}, {"text": "In Section 2 we describe previous research in web collection for speech recognition and keyword search.", "labels": [], "entities": [{"text": "web collection", "start_pos": 46, "end_pos": 60, "type": "TASK", "confidence": 0.731145828962326}, {"text": "speech recognition", "start_pos": 65, "end_pos": 83, "type": "TASK", "confidence": 0.8373426496982574}, {"text": "keyword search", "start_pos": 88, "end_pos": 102, "type": "TASK", "confidence": 0.7360505163669586}]}, {"text": "In Section 3 we briefly describe the IARPA Babel project and we describe its language resources.", "labels": [], "entities": [{"text": "IARPA Babel project", "start_pos": 37, "end_pos": 56, "type": "DATASET", "confidence": 0.8160905838012695}]}, {"text": "In Section 4 we describe the components of our web collection systems.", "labels": [], "entities": []}, {"text": "In Section 5 we identify the web sources we use.", "labels": [], "entities": []}, {"text": "In Section 6 we compare our system to other tools for web data collection.", "labels": [], "entities": [{"text": "web data collection", "start_pos": 54, "end_pos": 73, "type": "TASK", "confidence": 0.6911884347597758}]}, {"text": "In Section 7 we describe subsequent text normalization used to prepare the collection material for language modeling.", "labels": [], "entities": [{"text": "text normalization", "start_pos": 36, "end_pos": 54, "type": "TASK", "confidence": 0.7160825580358505}, {"text": "language modeling", "start_pos": 99, "end_pos": 116, "type": "TASK", "confidence": 0.7985651195049286}]}, {"text": "In Section 8 we describe results of adding collected web data to available Babel training data in reducing OOV rates.", "labels": [], "entities": [{"text": "Babel training data", "start_pos": 75, "end_pos": 94, "type": "DATASET", "confidence": 0.866841713587443}, {"text": "OOV rates", "start_pos": 107, "end_pos": 116, "type": "METRIC", "confidence": 0.7489683032035828}]}, {"text": "We conclude in Section 9 and discuss future research.", "labels": [], "entities": []}], "datasetContent": [{"text": "Our goal in collecting web data is to supplement language models for ASR and KWS by increasing the lexicon available from the ASR training corpus in order to reduce the number of OOV words available for ASR and KWS.", "labels": [], "entities": [{"text": "ASR training corpus", "start_pos": 126, "end_pos": 145, "type": "DATASET", "confidence": 0.7972997029622396}]}, {"text": "That is, if new words can be added to the lexicon from sources similar in genre to the training and test data, then there is a greater chance that these words can be identified in ASR and KWS on the test corpus.", "labels": [], "entities": []}, {"text": "For evaluation purposes here, we calculate OOV reduction by comparing the web-data-augmented lexicon with each of the Babel LLP lexicons for the six Babel OP3 languages -Pashto, Paraguayan Guarani, Igbo, Amharic, Halh Mongolian, and Javanese in lexicon that was distributed with the Limited Language Pack for each language, and \"+web\" is the union of all of the words in the LLP lexicon and all of the words that we found in the web data.", "labels": [], "entities": [{"text": "OOV reduction", "start_pos": 43, "end_pos": 56, "type": "METRIC", "confidence": 0.8447924554347992}]}, {"text": "The \"%rel.ch\" row shows the percent relative change in OOV rate when the web data is added to the lexicon.", "labels": [], "entities": [{"text": "OOV rate", "start_pos": 55, "end_pos": 63, "type": "METRIC", "confidence": 0.9659835696220398}]}, {"text": "\"OOV KW Rate %\" shows the percentage of KWS development queries containing an out-ofvocabulary tokens, both before and after our web data is added to the lexicon.", "labels": [], "entities": [{"text": "OOV KW Rate %\"", "start_pos": 1, "end_pos": 15, "type": "METRIC", "confidence": 0.8521293997764587}]}, {"text": "\"OOV Hit Rate %\" is a similar measure, except that each query term is weighted by the number of times that it actually appears in the development transcripts; in this metric, keywords that appear more often have a greater impact.", "labels": [], "entities": [{"text": "OOV Hit Rate %\"", "start_pos": 1, "end_pos": 16, "type": "METRIC", "confidence": 0.9055588692426682}]}, {"text": "Size (K)\" shows the size of the vocabulary (in thousands of words), before and after adding web data.", "labels": [], "entities": []}, {"text": "We see that, for each language, the percentage of OOV queries is significantly reduced; in particular, most Halh Mongolian and Javanese OOV keywords missing from the original lexicons are in fact added to the lexicon by the web data collection.", "labels": [], "entities": []}, {"text": "While text normalization is important if we are to use the web data for training a language model for ASR, we must also consider the extent to which normalization processes data may in fact remove useful words.", "labels": [], "entities": [{"text": "text normalization", "start_pos": 6, "end_pos": 24, "type": "TASK", "confidence": 0.7805418372154236}, {"text": "ASR", "start_pos": 102, "end_pos": 105, "type": "TASK", "confidence": 0.9882396459579468}]}, {"text": "shows OOV reduction when adding the normalized web data collected.", "labels": [], "entities": [{"text": "OOV", "start_pos": 6, "end_pos": 9, "type": "METRIC", "confidence": 0.9968506693840027}]}, {"text": "Surprisingly, using the normalized web data to augment the vocabulary actually helps in some instances over using the unnormalized data.", "labels": [], "entities": []}, {"text": "This is probably because the removal of special characters and punctuation attached to words results inexact matches for keywords.", "labels": [], "entities": []}, {"text": "Finally, we are interested in seeing the individual contribution of each of the web data genres we collected.", "labels": [], "entities": []}, {"text": "shows the percent relative reduction in OOVs for both OOV keywords and OOV hit rate in the development data when adding our normalized web data, by language and by genre.", "labels": [], "entities": [{"text": "OOVs", "start_pos": 40, "end_pos": 44, "type": "METRIC", "confidence": 0.9045858383178711}, {"text": "OOV hit rate", "start_pos": 71, "end_pos": 83, "type": "METRIC", "confidence": 0.8384899695714315}]}, {"text": "It is apparent that the genre that best reduces OOVs varies by language, but tweets were the most generally useful, resulting in the largest OOV reduction for Pashto, Igbo, Halh Mongolian, Javanese, and Dholuo.", "labels": [], "entities": []}, {"text": "In fact, tweets were the only useful genre for Dholuo.", "labels": [], "entities": []}, {"text": "Paraguayan Guarani saw the largest OOV reduction from forum posts, and Amharic from blogs.", "labels": [], "entities": [{"text": "OOV", "start_pos": 35, "end_pos": 38, "type": "METRIC", "confidence": 0.9607354998588562}]}], "tableCaptions": [{"text": " Table 1: OOV Reduction on Unnormalized Data", "labels": [], "entities": [{"text": "OOV Reduction", "start_pos": 10, "end_pos": 23, "type": "TASK", "confidence": 0.7352667450904846}]}, {"text": " Table 2: OOV Rate on Normalized Data", "labels": [], "entities": [{"text": "OOV Rate", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9585248827934265}]}, {"text": " Table 3: OOV Rates for Languages by Genre", "labels": [], "entities": [{"text": "OOV Rates", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.7755405008792877}]}]}