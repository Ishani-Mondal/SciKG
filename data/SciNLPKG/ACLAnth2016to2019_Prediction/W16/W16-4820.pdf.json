{"title": [{"text": "HeLI, a Word-Based Backoff Method for Language Identification", "labels": [], "entities": [{"text": "Language Identification", "start_pos": 38, "end_pos": 61, "type": "TASK", "confidence": 0.7254465669393539}]}], "abstractContent": [{"text": "In this paper we describe the Helsinki language identification method, HeLI, and the resources we created for and used in the 3rd edition of the Discriminating between Similar Languages (DSL) shared task, which was organized as part of the VarDial 2016 workshop.", "labels": [], "entities": [{"text": "Helsinki language identification", "start_pos": 30, "end_pos": 62, "type": "TASK", "confidence": 0.6681232750415802}, {"text": "Discriminating between Similar Languages (DSL) shared task", "start_pos": 145, "end_pos": 203, "type": "TASK", "confidence": 0.7055041359530555}]}, {"text": "The shared task comprised of a total of 8 tracks, of which we participated in 7.", "labels": [], "entities": []}, {"text": "The shared task had a record number of participants, with 17 teams providing results for the closed track of the test set A.", "labels": [], "entities": []}, {"text": "Our system reached the 2nd position in 4 tracks (A closed and open, B1 open and B2 open) and in this paper we are focusing on the methods and data used for those tracks.", "labels": [], "entities": []}, {"text": "We describe our word-based backoff method in mathematical notation.", "labels": [], "entities": []}, {"text": "We also describe how we selected the corpus we used in the open tracks.", "labels": [], "entities": []}], "introductionContent": [{"text": "The 3rd edition of the Discriminating between Similar Languages (DSL) shared task, ( , was divided into two sub-tasks: \"Similar Languages and Language Varieties\" and \"Arabic dialects\".", "labels": [], "entities": [{"text": "Discriminating between Similar Languages (DSL) shared task", "start_pos": 23, "end_pos": 81, "type": "TASK", "confidence": 0.7137569619549645}, {"text": "Similar Languages and Language Varieties", "start_pos": 120, "end_pos": 160, "type": "TASK", "confidence": 0.6212583899497985}]}, {"text": "Furthermore, the first sub-task was divided into three test sets: A, B1 and B2.", "labels": [], "entities": []}, {"text": "Each of the test sets for both tasks had a closed and an open track.", "labels": [], "entities": []}, {"text": "On the closed track the participants were allowed to use only the training data provided by the organizers, whereas on the open track the participants could use any data source they had at their disposal.", "labels": [], "entities": []}, {"text": "The first sub-task had a language selection comparable to the 1st ( ) and 2nd () editions of the shared task.", "labels": [], "entities": []}, {"text": "The languages and varieties of the sub-task 1 are listed in the Table 2.", "labels": [], "entities": []}, {"text": "The differences from the previous year's shared task were the inclusion of the French language varieties and the Mexican Spanish, as well as the exclusion of Bulgarian, Macedonian, Czech, and Slovak.", "labels": [], "entities": []}, {"text": "The four latter languages were practically 100% correct inmost of the submissions to the 2nd edition of the shared task.", "labels": [], "entities": []}, {"text": "On the other hand, discriminating between the two French varieties could be expected to be more difficult.", "labels": [], "entities": []}, {"text": "Also the extra category \"unknown language\" introduced in 2015 was left out from the 3rd edition repertoire.", "labels": [], "entities": []}, {"text": "These changes resulted in a drop of the best reported accuracy of any team (test set A) from the 95.54% of the 2nd edition closed track to the 89.38% of the 3rd edition closed track.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 54, "end_pos": 62, "type": "METRIC", "confidence": 0.980402946472168}]}, {"text": "The second sub-task comprised of discriminating between Modern Standard Arabic and four dialects: Egyptian, Gulf, Levantine, and North-African.", "labels": [], "entities": []}, {"text": "The Arabic dialects were included in the shared task for the first time.", "labels": [], "entities": []}, {"text": "For the 2015 edition of the task, we used the word-based backoff language identification method first introduced in 2010 and made several modifications to it in order to improve the method for the task of discriminating similar languages and to cope with the unknown language ().", "labels": [], "entities": [{"text": "word-based backoff language identification", "start_pos": 46, "end_pos": 88, "type": "TASK", "confidence": 0.5520348027348518}]}, {"text": "In the 3rd edition of the task, the unknown language was left out, which meant that the original method was directly applicable.", "labels": [], "entities": []}, {"text": "We also felt that the modifications we made in 2015 complicated the system and did not really improve the results that much, so we decided to use the basic method out-of-the-box for the 3rd edition of the shared task.", "labels": [], "entities": []}, {"text": "The word-based backoff method, now named HeLI, is a general purpose language identification method which we have used for collecting text material written in Uralic languages in the Finno-Ugric Languages and the Internet project) funded by the Kone foundation.", "labels": [], "entities": [{"text": "general purpose language identification", "start_pos": 52, "end_pos": 91, "type": "TASK", "confidence": 0.6818654090166092}]}, {"text": "We have also used the method as a language identifier part when developing a method for language set identification in multilingual documents).", "labels": [], "entities": [{"text": "language set identification in multilingual documents", "start_pos": 88, "end_pos": 141, "type": "TASK", "confidence": 0.742562269171079}]}, {"text": "The language identifier tool using the HeLI-method is available as open source from GitHub 1 .", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 2: The languages and varieties of the sub-task 1 and the collected domains for the corpus used in  the open tracks.", "labels": [], "entities": []}, {"text": " Table 3. On the closed track we used all of the training and the development data to create the  language models.", "labels": [], "entities": []}, {"text": " Table 3: Results for test set A (closed training).", "labels": [], "entities": []}, {"text": " Table 4: Results for test set B1 (closed training).", "labels": [], "entities": []}, {"text": " Table 5: Results for test set B1 (open training).", "labels": [], "entities": []}, {"text": " Table 6: Results for test set B2 (closed training).", "labels": [], "entities": []}, {"text": " Table 7: Results for test set B2 (open training).", "labels": [], "entities": []}, {"text": " Table 8: Results for test set C (closed training).", "labels": [], "entities": []}]}