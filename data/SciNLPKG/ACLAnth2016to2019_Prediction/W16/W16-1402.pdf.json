{"title": [], "abstractContent": [{"text": "Language processing tools suffer from significant performance drops in social media domain due to its continuously evolving language.", "labels": [], "entities": []}, {"text": "Transforming non-standard words into their standard forms has been studied as a step towards proper processing of ill-formed texts.", "labels": [], "entities": [{"text": "Transforming non-standard words", "start_pos": 0, "end_pos": 31, "type": "TASK", "confidence": 0.8795463442802429}]}, {"text": "This work describes a normalization system that considers contextual and lexical similarities between standard and non-standard words for removing noise in texts.", "labels": [], "entities": []}, {"text": "A bipartite graph that represents contexts shared by words in a large unlabeled text corpus is utilized for exploring normalization candidates via random walks.", "labels": [], "entities": []}, {"text": "Input context of a non-standard word in a given sentence is tailored in cases where a direct match to shared contexts is not possible.", "labels": [], "entities": []}, {"text": "The performance of the system was evaluated on Turkish social media texts.", "labels": [], "entities": [{"text": "Turkish social media texts", "start_pos": 47, "end_pos": 73, "type": "DATASET", "confidence": 0.883195772767067}]}], "introductionContent": [{"text": "Social media has been an integral part of personal communication in the last decade.", "labels": [], "entities": []}, {"text": "Everyday, people willingly produce millions of multilingual texts since they are free in the way how they express themselves.", "labels": [], "entities": []}, {"text": "Grammatical rules and language structures do not have to be all in place, even the words might not be properly written.", "labels": [], "entities": []}, {"text": "However, free-style writing and ever-growing nature of the language hinder the utility of social media texts in computational linguistics studies.", "labels": [], "entities": []}, {"text": "For instance, non-standard words (e.g.,\"comin soon\" for \"coming soon\") and phonetic substitutions (e.g., \"4u\" for \"for you\") that are often seen in social media texts degrade the performance of many NLP tools such as parsers and named entity recognizers.", "labels": [], "entities": [{"text": "named entity recognizers", "start_pos": 229, "end_pos": 253, "type": "TASK", "confidence": 0.6249783337116241}]}, {"text": "Being trained on formal texts is the major drawback of these tools in processing ill-formed texts.", "labels": [], "entities": []}, {"text": "In addition, different social media genres have their own characteristics and various factors (e.g., demographic background and age) trigger linguistic changes in social media language overtime ().", "labels": [], "entities": []}, {"text": "Normalizing ill-formed texts is a promising preprocessing step to address experienced accuracy drops in existing NLP tools.", "labels": [], "entities": [{"text": "Normalizing ill-formed texts", "start_pos": 0, "end_pos": 28, "type": "TASK", "confidence": 0.8704150319099426}, {"text": "accuracy", "start_pos": 86, "end_pos": 94, "type": "METRIC", "confidence": 0.9873782992362976}]}, {"text": "This paper proposes a normalization system that transforms non-standard out of vocabulary (OOV) words into their standard in vocabulary (IV) forms.", "labels": [], "entities": []}, {"text": "We argue that contextual and lexical characteristics of words are of the greatest importance in normalization.", "labels": [], "entities": []}, {"text": "To encode contextual similarities of words, a bipartite graph acquired from a corpus of formal and informal texts is utilized.", "labels": [], "entities": []}, {"text": "The first bipartite of the graph consists of words that appear in the contexts represented by the second bipartite.", "labels": [], "entities": []}, {"text": "This graphical representation not only captures the way how words are used in real texts but also presents lexical variants of the same word in similar contexts.", "labels": [], "entities": []}, {"text": "A non-standard word might be restored to different words depending on its context in a sentence.", "labels": [], "entities": []}, {"text": "In this work, one consideration that is exploited in determining the right form of a non-standard word is its input context and the similarity of this context to other contexts captured by the underlying graph.", "labels": [], "entities": []}, {"text": "At the core of our normalization system lies a novel use of a tailoring approach on input contexts.", "labels": [], "entities": []}, {"text": "Tailored input contexts are shown to be effective in finding similar contexts in the graph.", "labels": [], "entities": []}, {"text": "To normalize a nonstandard word, our system determines contextually similar candidate normalizations by performing random walks through similar contexts.", "labels": [], "entities": []}, {"text": "Additional normalization candidates are extracted from a word lexicon by measuring their lexical distances to the illformed word via a well-known similarity metric.", "labels": [], "entities": []}, {"text": "We evaluated our normalization system on 715 Turkish social media sentences with 1190 ill-formed words in total and our promising results revealed that we improve on state-of-the-art in Turkish.", "labels": [], "entities": []}], "datasetContent": [{"text": "In order to evaluate the performance of our language-independent system, we experimented with Turkish social media texts.", "labels": [], "entities": []}, {"text": "For the study, we first collected a large corpus of noisy and clean Turkish texts from different resources.", "labels": [], "entities": []}, {"text": "The corpus consisted of tweets (\u223c11GB) that were retrieved via Twitter Streaming API from April to October 2015, 20 million publicly available tweets 6 , and clean Turkish texts (\u223c6GB).", "labels": [], "entities": []}, {"text": "The corpus was preprocessed by first discarding non-Turkish content as identified by a language detection tool.", "labels": [], "entities": []}, {"text": "Later, tweet-specific terms (e.g., # and RT), URLs, some punctuations, and repetitive characters were cleaned from the corpus.", "labels": [], "entities": []}, {"text": "Finally, the remaining sentences of \u223c9GB were tokenized into 7,401,321 distinct words.", "labels": [], "entities": []}, {"text": "We constructed a bipartite graph from the collected corpus using 5-gram word sequences.", "labels": [], "entities": []}, {"text": "The word sequences contained one or more OOV words and in cases where there was only one OOV word, it might not beat the center.", "labels": [], "entities": []}, {"text": "Statistics about the constructed graph is given in.", "labels": [], "entities": []}, {"text": "In the study, if more than one initial node was determined for an ill-formed word, an equal number of random walks were performed from each of these nodes rather than selecting only one.", "labels": [], "entities": []}, {"text": "50 random walks with a maximum of 6 steps were performed from each initial node.", "labels": [], "entities": []}, {"text": "Tailoring threshold was set to 1 for central contexts (a tailored context might have at most three \u2205 symbols) whereas to 2 for sliding contexts.", "labels": [], "entities": []}, {"text": "The edit distance threshold was set to 2 and contextually/positionally similar normalization candidates with a higher edit distance were discarded from consideration.", "labels": [], "entities": [{"text": "edit distance threshold", "start_pos": 4, "end_pos": 27, "type": "METRIC", "confidence": 0.8377024928728739}]}, {"text": "Words were preprocessed before computing their edit distances.", "labels": [], "entities": []}, {"text": "For instance, repetition of characters was reduced to a single character and words were deasciified to restore Turkish characters (if necessary).", "labels": [], "entities": []}, {"text": "It is noteworthy to mention that our system do not normalize a word if an IV word candidate is not identified for that word.", "labels": [], "entities": []}, {"text": "Our test set consisted of 715 sentences that were retrieved from Twitter.", "labels": [], "entities": []}, {"text": "The ill-formed words in these sentences were manually identified and normalized by two native Turkish speakers.", "labels": [], "entities": []}, {"text": "483 of these sentences contained only one ill-formed word.", "labels": [], "entities": []}, {"text": "However, the remaining 232 sentences had at least two ill-formed words at different positions.", "labels": [], "entities": []}, {"text": "Some sentences even had a number of ill-formed words in sequence.", "labels": [], "entities": []}, {"text": "Our test set consisted of 1190 ill-formed words in total.", "labels": [], "entities": []}, {"text": "Moreover, we observed different kinds of transformations between ill-formed words and their normalized forms (e.g., asciified Turkish characters, omitted characters, and typos).", "labels": [], "entities": []}, {"text": "As an example, consider one of our test sentences where ill-formed words are underlined \"insan\u0131ar k\u00f6pr\u00fc kuracak\u0131ar\u0131 yerde duvar\u00f6rd\u00fck\u0131eriduvar\u00a8duvar\u00f6rd\u00fck\u0131eri i\u00e7in ya\u0131n\u0131z ka\u0131\u0131r\u0131ar\"{People remain alone since they put up walls rather than building bridges}.", "labels": [], "entities": []}, {"text": "Neither the normalization system (TE N) nor the spellchecker (SP C) utilizes the context of an OOV word during normalization.", "labels": [], "entities": []}, {"text": "shows the normalization results that we achieved on the whole test set along with the results of other normalizers.", "labels": [], "entities": []}, {"text": "The third row (Con. Sim.) shows the performance of our system once only contextual similarities were considered during normalization (\u03bb 1 = 1, \u03bb 2 = 0, \u03bb 3 = 0).", "labels": [], "entities": []}, {"text": "Similarly, the fourth and fifth rows show the system's performance once positional and lexical similarities were considered respectively.", "labels": [], "entities": []}, {"text": "The sixth row presents our baseline where all kinds of similarities had an equal effect on normalization (\u03bb 1 = 1, \u03bb 2 = 1, \u03bb 3 = 1).", "labels": [], "entities": []}, {"text": "The last row shows the results of our proposed system whose \u03bb values were tuned on a development set of 200 sentences.", "labels": [], "entities": []}, {"text": "As shown in, a very low recall and the highest precision were obtained once the system considered only positional similarities between an OOV word and its IV word candidates.", "labels": [], "entities": [{"text": "recall", "start_pos": 24, "end_pos": 30, "type": "METRIC", "confidence": 0.9995025396347046}, {"text": "precision", "start_pos": 47, "end_pos": 56, "type": "METRIC", "confidence": 0.9994640946388245}]}, {"text": "Moreover, our system achieved the highest F-measure and recall, and the second highest precision among all normalizers.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 42, "end_pos": 51, "type": "METRIC", "confidence": 0.9992783665657043}, {"text": "recall", "start_pos": 56, "end_pos": 62, "type": "METRIC", "confidence": 0.998542070388794}, {"text": "precision", "start_pos": 87, "end_pos": 96, "type": "METRIC", "confidence": 0.9994223117828369}]}, {"text": "show the results obtained by our baseline and our system on sentences with only one OOV word and multiple OOV words respectively.", "labels": [], "entities": []}, {"text": "Our system obtained higher scores in test sentences with multiple OOV words as compared to those with a single OOV word.", "labels": [], "entities": []}, {"text": "This might be explained by the fact that a sentence written by the same person might contain multiple OOV words that underwent the same transformation (such as repetitive characters) which can be normalized by our system.", "labels": [], "entities": []}, {"text": "On the other hand, several sentences might contain a single OOV word that experienced different kinds of transformations, some of which might not be handled by our system.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Statistics about the graph.", "labels": [], "entities": []}, {"text": " Table 2: Evaluation of all test sentences.", "labels": [], "entities": []}, {"text": " Table 3: Evaluation of sentences with one OOV word.", "labels": [], "entities": []}, {"text": " Table 4: Evaluation of sentences with multiple OOV words.", "labels": [], "entities": []}]}