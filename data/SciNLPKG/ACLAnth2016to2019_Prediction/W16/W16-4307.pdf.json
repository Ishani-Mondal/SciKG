{"title": [{"text": "Detecting Opinion Polarities using Kernel Methods", "labels": [], "entities": [{"text": "Detecting Opinion Polarities", "start_pos": 0, "end_pos": 28, "type": "TASK", "confidence": 0.8961831529935201}]}], "abstractContent": [{"text": "We investigate the application of kernel methods to representing both structural and lexical knowledge for predicting polarity of opinions in consumer product review.", "labels": [], "entities": [{"text": "predicting polarity of opinions in consumer product review", "start_pos": 107, "end_pos": 165, "type": "TASK", "confidence": 0.7964803576469421}]}, {"text": "We introduce any-gram kernels which model lexical information in a significantly faster way than the traditional n-gram features, while capturing all possible orders of n-grams (n) in a sequence without the need to explicitly present a pre-specified set of such orders.", "labels": [], "entities": []}, {"text": "We also modify the traditional tree kernel function to compute the similarity based on word embedding vectors instead of exact string match and present experiments using the new models.", "labels": [], "entities": []}], "introductionContent": [{"text": "The automatic identification and analysis of opinion and sentiment in text () has emerged as a major natural language processing task in recent years, due in part to the abundance of opinions now available online.", "labels": [], "entities": [{"text": "automatic identification and analysis of opinion and sentiment in text", "start_pos": 4, "end_pos": 74, "type": "TASK", "confidence": 0.8604495227336884}]}, {"text": "Initially, much of the focus of sentiment analysis research was on detecting the overall sentiment of documents and sentences (.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 32, "end_pos": 50, "type": "TASK", "confidence": 0.8868682980537415}, {"text": "detecting the overall sentiment of documents and sentences", "start_pos": 67, "end_pos": 125, "type": "TASK", "confidence": 0.7870668172836304}]}, {"text": "This kind of analysis is insufficient when the sentence or document contains multiple opinions directed towards multiple targets and the goal is to identify each of them individually.", "labels": [], "entities": []}, {"text": "For example, a review of a laptop may discuss various features of the product such as battery life, speed and memory.", "labels": [], "entities": []}, {"text": "While the review may carry a positive assessment of the laptop in general, the sentiment towards some of these aspects maybe negative.", "labels": [], "entities": []}, {"text": "Aspect-based sentiment analysis (ABSA) () aims to tackle this problem.", "labels": [], "entities": [{"text": "Aspect-based sentiment analysis (ABSA)", "start_pos": 0, "end_pos": 38, "type": "TASK", "confidence": 0.7943348288536072}]}, {"text": "In this work, we address the problem of aspect-based sentiment analysis and follow recent SemEval shared tasks in using consumer reviews of laptops and restaurants as our test domains.", "labels": [], "entities": [{"text": "aspect-based sentiment analysis", "start_pos": 40, "end_pos": 71, "type": "TASK", "confidence": 0.6376949747403463}]}, {"text": "The majority of machine learning approaches to sentiment analysis have relied on bag-of-ngrams (.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 47, "end_pos": 65, "type": "TASK", "confidence": 0.9613907635211945}]}, {"text": "However, n-grams lead to large sparse feature sets which are not computationally efficient.", "labels": [], "entities": []}, {"text": "Moreover, only a limited number of orders of n-grams (i.e. n) can be used and the choice of n requires tuning.", "labels": [], "entities": []}, {"text": "To tackle this issue, we introduce any-gram kernels which 1) capture all orders of n-grams and 2) are faster while 3) performing at the same level as traditional n-gram features.", "labels": [], "entities": []}, {"text": "Recent research has shown that structural features extracted from syntactic analysis of text can boost the performance of surface-oriented models, by capturing information that these models cannot).", "labels": [], "entities": []}, {"text": "For example, in If you like spicy food get the chicken vindaloo., a lexicon-based model assigns a positive sentiment to the aspect term spicy food due to the nearby presence of like , whereas a syntax-based model has the potential to recognise that like does not convey an opinion when it is modified by if.", "labels": [], "entities": []}, {"text": "We use tree kernels to model both the constituency and dependency structure of the sentences.", "labels": [], "entities": []}, {"text": "This approach is more efficient than hand-crafted syntactic features, as it requires less engineering effort and is faster to develop.", "labels": [], "entities": []}, {"text": "Traditional tree kernel function computes the similarity of trees based on the exact string match of the node labels including words.", "labels": [], "entities": []}, {"text": "This method overlooks the similarity between words which can be used interchangeably in the context.", "labels": [], "entities": []}, {"text": "address this problem by generalizing words using word clusters and latent semantic analysis (LSA).", "labels": [], "entities": [{"text": "latent semantic analysis", "start_pos": 67, "end_pos": 91, "type": "TASK", "confidence": 0.6174776752789816}]}, {"text": "Word embeddings (, which have been used successfully in tasks involving similarity between words (, are an alternative approach to obtain this generalization.", "labels": [], "entities": []}, {"text": "We modify the tree kernel function so that the similarity of trees are computed based on the similarity of pre-trained word embedding vectors.", "labels": [], "entities": []}, {"text": "We conduct experiments using the new kernel function and find that these similarities are not conclusively more useful than mere string matches.", "labels": [], "entities": []}], "datasetContent": [{"text": "Data We use the data released for Task 4 of SemEval 2014 () (called SE14 hereafter), which is concerned with ABSA.", "labels": [], "entities": [{"text": "ABSA", "start_pos": 109, "end_pos": 113, "type": "TASK", "confidence": 0.8291444182395935}]}, {"text": "The data is in the form of consumer reviews from two domains: laptops and restaurants.", "labels": [], "entities": []}, {"text": "shows various characteristics of the data including the number of sentences and aspect terms and the percentage of each polarity type.", "labels": [], "entities": []}, {"text": "As seen in, the restaurant dataset contains more aspect terms than the laptop ones, as most of its sentences have more than one aspect term.", "labels": [], "entities": []}, {"text": "In terms of the polarity class distribution, the conflict polarity accounts for only a tiny portion of the aspect terms, whereas the positive polarity dominates the datasets except for the laptop training set where it has a similar share as the negative polarity.", "labels": [], "entities": [{"text": "laptop training set", "start_pos": 189, "end_pos": 208, "type": "DATASET", "confidence": 0.813524862130483}]}, {"text": "The proportion of neutral and negative polarities tend to be similar, which is also consistent across the four datasets.", "labels": [], "entities": []}, {"text": "Experiment Details To obtain the syntactic analysis of the data, we parse them into their constituency structures using a PCFG-LA parser ().", "labels": [], "entities": []}, {"text": "The parser is trained on the entire Wall Street Journal section of the Penn Treebank (.", "labels": [], "entities": [{"text": "Wall Street Journal section of the Penn Treebank (", "start_pos": 36, "end_pos": 86, "type": "DATASET", "confidence": 0.9527761803732978}]}, {"text": "We then obtain dependency parses by converting these constituency parses using the Stanford converter (.", "labels": [], "entities": [{"text": "dependency parses", "start_pos": 15, "end_pos": 32, "type": "TASK", "confidence": 0.8802858591079712}]}, {"text": "To apply tree kernels, we use the SVMLight-TK implementation . Based on a set of preliminary experiments, we use subset tree kernels and the one-versus-one (OVO) method to convert the binary output of the SVM to multi-class (positive, negative, neutral and conflict).", "labels": [], "entities": []}, {"text": "The error/margin trade-off of the SVM (C) is tuned using development sets randomly extracted from the official training sets.", "labels": [], "entities": [{"text": "error/margin trade-off", "start_pos": 4, "end_pos": 26, "type": "METRIC", "confidence": 0.8657526671886444}]}, {"text": "For tree kernels with word embeddings, we use cosine similarity for sim in equation 4.", "labels": [], "entities": []}, {"text": "The \u03b8 parameter is tuned on the development set, where the optimum value is selected from {0.7, 0.8, 0.9}.", "labels": [], "entities": []}, {"text": "The pre-trained word vectors used are the publicly available ones trained using GloVe () trained on 42B-token corpus of Common Crawl (1.9M vocabulary) with 300 dimensions.", "labels": [], "entities": [{"text": "42B-token corpus of Common Crawl (1.9M vocabulary", "start_pos": 100, "end_pos": 149, "type": "DATASET", "confidence": 0.8794149830937386}]}], "tableCaptions": [{"text": " Table 1: Number of sentences, aspect terms and their polarity distributions in the data sets", "labels": [], "entities": []}, {"text": " Table 2: Accuracy of majority baseline, hand-crafted (HC) unigram+bigram features, any-gram kernel  (NGTK) and syntax tree kernel systems (SyTK) and best SemEval 2014 system, evaluated on the laptop  and restaurant development and test sets, based on exact string match and word embedding similarity", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9785309433937073}, {"text": "exact string match", "start_pos": 252, "end_pos": 270, "type": "METRIC", "confidence": 0.7799230019251505}]}]}