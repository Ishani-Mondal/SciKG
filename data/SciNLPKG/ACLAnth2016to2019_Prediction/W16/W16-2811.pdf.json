{"title": [], "abstractContent": [{"text": "In this paper we examine the application of an unsupervised extractive summari-sation algorithm, TextRank, on a different task, the identification of argumentative components.", "labels": [], "entities": []}, {"text": "Our main motivation is to examine whether there is any potential overlap between extractive summari-sation and argument mining, and whether approaches used in summarisation (which typically model a document as a whole) can have a positive effect on tasks of argument mining.", "labels": [], "entities": [{"text": "argument mining", "start_pos": 111, "end_pos": 126, "type": "TASK", "confidence": 0.7396203428506851}, {"text": "summarisation", "start_pos": 159, "end_pos": 172, "type": "TASK", "confidence": 0.9776015281677246}, {"text": "argument mining", "start_pos": 258, "end_pos": 273, "type": "TASK", "confidence": 0.7590809762477875}]}, {"text": "Evaluation has been performed on two corpora containing user posts from an on-line debating forum and persuasive essays.", "labels": [], "entities": []}, {"text": "Evaluation results suggest that graph-based approaches and approaches targeting extractive summarisa-tion can have a positive effect on tasks related to argument mining.", "labels": [], "entities": [{"text": "argument mining", "start_pos": 153, "end_pos": 168, "type": "TASK", "confidence": 0.8139133751392365}]}], "introductionContent": [{"text": "Argumentation is a branch of philosophy that studies the actor process of forming reasons and of drawing conclusions in the context of a discussion, dialogue, or conversation.", "labels": [], "entities": [{"text": "Argumentation is a branch of philosophy that studies the actor process of forming reasons and of drawing conclusions in the context of a discussion, dialogue, or conversation", "start_pos": 0, "end_pos": 174, "type": "Description", "confidence": 0.7969120761443829}]}, {"text": "Being an important element of human communication, its use is very frequent in texts, as a means to convey meaning to the reader.", "labels": [], "entities": []}, {"text": "As a result, argumentation has attracted significant research focus from many disciplines, ranging from philosophy to artificial intelligence.", "labels": [], "entities": [{"text": "argumentation", "start_pos": 13, "end_pos": 26, "type": "TASK", "confidence": 0.9700102806091309}]}, {"text": "Central to argumentation is the notion of argument, which according to) is a set of assumptions (i.e. information from which conclusions can be drawn), together with a conclusion that can be obtained by one or more reasoning steps (i.e. steps of deduction).", "labels": [], "entities": []}, {"text": "The conclusion of the argument is often called the claim, or equivalently the consequent or the conclusion of the argument.", "labels": [], "entities": []}, {"text": "The assumptions are called the support, or equivalently the premises of the argument, which provide the reason (or equivalently the justification) for the claim of the argument.", "labels": [], "entities": []}, {"text": "The process of extracting conclusions/claims along with their supporting premises, both of which compose an argument, is known as argument mining () and constitutes an emerging research field.", "labels": [], "entities": [{"text": "argument mining", "start_pos": 130, "end_pos": 145, "type": "TASK", "confidence": 0.7835972309112549}]}, {"text": "Several approaches have been already presented for addressing various subtasks of argument mining, including the identification of argumentative sentences (i.e. sentences that contain argumentation components such as claims and premises), argumentation components, relations between such components, and resources for supporting argument mining, like discourse indicators and other expressions indicating the presence of argumentative components.", "labels": [], "entities": [{"text": "argument mining", "start_pos": 82, "end_pos": 97, "type": "TASK", "confidence": 0.7188403308391571}]}, {"text": "Proposed methods mostly relate to supervised machine learning exploiting a plethora of features (, including the combination of several techniques, such as the work presented in (.", "labels": [], "entities": []}, {"text": "One of the difficulties associated to argument mining relates to the fact that the identification of argument components usually depends on the context in which they appear in.", "labels": [], "entities": [{"text": "argument mining", "start_pos": 38, "end_pos": 53, "type": "TASK", "confidence": 0.8655980229377747}]}, {"text": "The locality of this context can vary significantly, based not only on the domain, but possibly even to personal writing style.", "labels": [], "entities": []}, {"text": "On one hand, discourse indicators, markers and phrases can provide a strong and localised contextual information, but their use is not very frequent).", "labels": [], "entities": []}, {"text": "On the other hand, the local context of a phrase may indicate that the phrase is a fact, suggesting low or no argumentativeness at all, while at the same time, the same phrase may contradict to another phrase several sentences before or after the phrase in question, constituting the phrase under ques-tion an argumentative component.", "labels": [], "entities": []}, {"text": "While it is quite easy to handle local context through suitable representations and learning techniques, complexity may increase significantly when a broader context is required, especially when relations exist among various parts of a document.", "labels": [], "entities": []}, {"text": "In this paper we want to examine approaches that are able to handle interactions and relations that are not local, especially the ones that can model a document as a whole.", "labels": [], "entities": []}, {"text": "An example of a task where documents are modelled in their entirety, is document summarisation (.", "labels": [], "entities": [{"text": "document summarisation", "start_pos": 72, "end_pos": 94, "type": "TASK", "confidence": 0.6054015010595322}]}, {"text": "Extractive summarisation typically examines the importance of each sentence with respect to the rest of the sentences in a document, in order to select a small set of sentences that are more \"representative\" fora given document.", "labels": [], "entities": [{"text": "Extractive summarisation", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.9362490773200989}]}, {"text": "A typical extractive summarisation system is expected to select sentences that contain a lot of information in a compact form, and capture the different pieces of information that are expressed in a document.", "labels": [], "entities": [{"text": "extractive summarisation", "start_pos": 10, "end_pos": 34, "type": "TASK", "confidence": 0.5564862489700317}]}, {"text": "The main idea behind this paper is to examine whether there is any potential overlap between these sentences that summarise a document, and argumentation components that can exist in a document.", "labels": [], "entities": []}, {"text": "Assuming that in a document the author expresses one or more claims, which can be potentially justified through a series of premises or support statements, it will be interesting to examine whether any of these argumentation components will be assessed as significant enough to be included in an automatically generated summary.", "labels": [], "entities": []}, {"text": "Willa summarisation algorithm capture at least the claims, and characterise them as important enough to be included in the produced summary?", "labels": [], "entities": [{"text": "summarisation", "start_pos": 6, "end_pos": 19, "type": "TASK", "confidence": 0.9531233310699463}]}, {"text": "In order to examine if there is any overlap between extractive summarisation and argument mining (at least the identification of sentences that contain some argumentation components, such as claims), we wanted to avoid any influence from the documents and the thematic domains under examination.", "labels": [], "entities": [{"text": "argument mining", "start_pos": 81, "end_pos": 96, "type": "TASK", "confidence": 0.7259553819894791}]}, {"text": "Ruling out supervised approaches, we examined summarisation algorithms that are either unsupervised, or can be trained in different domains than the ones they will be applied on.", "labels": [], "entities": [{"text": "summarisation", "start_pos": 46, "end_pos": 59, "type": "TASK", "confidence": 0.9782848954200745}]}, {"text": "Finally, we opted for an unsupervised algorithm, TextRank (), a graphbased ranking model, which can be applied on extractive summarisation by exploiting \"similarity\" among sentences, based on their content overlap.", "labels": [], "entities": []}, {"text": "We conducted our study on two corpora in English.", "labels": [], "entities": []}, {"text": "The first one is a corpus of user generated content, compiled by from online debate forums on four topics: \"abortion\", \"gay rights\", \"marijuana\", and \"Obama\".", "labels": [], "entities": []}, {"text": "The second corpus, compiled by, contains 90 persuasive essays on various topics.", "labels": [], "entities": []}, {"text": "Initial results are promising, suggesting that there is an overlap between extractive summarisation and argumentation component identification, and the ranking of sentences from TextRank can help in tasks related to argument mining, possibly as a feature in cooperation with an argumentation mining approach.", "labels": [], "entities": [{"text": "argumentation component identification", "start_pos": 104, "end_pos": 142, "type": "TASK", "confidence": 0.626896063486735}, {"text": "argument mining", "start_pos": 216, "end_pos": 231, "type": "TASK", "confidence": 0.7648783326148987}]}, {"text": "The rest of the paper is organised as follows: Section 2 presents an brief overview of approaches related to argument mining, while section 3 presents our approach on applying TextRank for identifying sentences that contain argumentation components.", "labels": [], "entities": [{"text": "argument mining", "start_pos": 109, "end_pos": 124, "type": "TASK", "confidence": 0.818068116903305}]}, {"text": "Section 4 presents the experimental setting and evaluation results, with section 5 concluding this paper and proposing some directions for further research.", "labels": [], "entities": []}], "datasetContent": [{"text": "In order to evaluate our hypothesis, that there is a potential overlap between automatic summarisation (as represented by extractive approaches such as TextRank) and argument mining (at least claim identification), we have applied TextRank on two corpora written in English.", "labels": [], "entities": [{"text": "summarisation", "start_pos": 89, "end_pos": 102, "type": "TASK", "confidence": 0.8626889586448669}, {"text": "argument mining", "start_pos": 166, "end_pos": 181, "type": "TASK", "confidence": 0.7974800169467926}, {"text": "claim identification", "start_pos": 192, "end_pos": 212, "type": "TASK", "confidence": 0.7341558039188385}]}, {"text": "The first corpus has been compiled from online debate forums, containing user posts concerning four thematic domains, while the second corpus contains 90 persuasive essays on various topics).", "labels": [], "entities": []}, {"text": "The first corpus that has been used in our study has been compiled and manually annotated as described in).", "labels": [], "entities": []}, {"text": "User generated content has been collected from an online debate forum 1 . Debate posts from four popular domains were collected: \"abortion\", \"gay rights\", \"marijuana\", and \"Obama\".", "labels": [], "entities": []}, {"text": "These posts are either in favour or against the domain, depending on whether the author of the post supports or opposes abortion, gay rights, the legalisation of marijuana, or Obama respectively.", "labels": [], "entities": []}, {"text": "The posts were manually examined, in order to identify the reasons for the stance (in favour or against) of each post.", "labels": [], "entities": []}, {"text": "A set of 56 reasons were identified for the four domains, which were subsequently used for annotating the posts: for each post, segments that correspond to any of these reasons were manually annotated.", "labels": [], "entities": []}, {"text": "We have processed the aforementioned corpus, and we have removed the posts where the annotated segments span more than a single sentence, keeping only the posts where the annotated segments are contained within a single sentence.", "labels": [], "entities": []}, {"text": "The resulting number of posts for each domain are shown in.", "labels": [], "entities": []}, {"text": "The TextRank implementation used in the evaluation has been written in Python 2 , and is publicly available through.", "labels": [], "entities": []}, {"text": "Each post is associated with one (and in some cases more than one) segment that expresses the main reason for the author to be in favour or against the domain.", "labels": [], "entities": []}, {"text": "In order to examine whether there is an overlap between argument mining and summarisation, we have applied TextRank on each post, and we have examined whether the single, top ranked sentence by TextRank, contains the segment marked as the reason.", "labels": [], "entities": [{"text": "argument mining", "start_pos": 56, "end_pos": 71, "type": "TASK", "confidence": 0.7434049546718597}, {"text": "summarisation", "start_pos": 76, "end_pos": 89, "type": "TASK", "confidence": 0.964958906173706}]}, {"text": "In case the segment is contained in the top ranked sentence returned by TextRank, the post is classified as correctly identified.", "labels": [], "entities": [{"text": "TextRank", "start_pos": 72, "end_pos": 80, "type": "DATASET", "confidence": 0.9491233825683594}]}, {"text": "If the reason segment is not contained in the returned sentence, the post is characterised as an error.", "labels": [], "entities": []}, {"text": "Evaluation results are reported through accuracy (proportion of true results among the total number of cases examined).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 40, "end_pos": 48, "type": "METRIC", "confidence": 0.9994438290596008}]}, {"text": "Finally, two experiments were performed, with the only difference being the number of sentences selected from TextRank to form the summary.", "labels": [], "entities": [{"text": "TextRank", "start_pos": 110, "end_pos": 118, "type": "DATASET", "confidence": 0.9341129660606384}]}, {"text": "During the first experiment (labelled as E 1 ), only a single sentence was selected (the top-ranked sentence as determined by TextRank), while during the second experiment (labelled as E 2 ) we have selected the two top-ranked sentences.", "labels": [], "entities": [{"text": "TextRank", "start_pos": 126, "end_pos": 134, "type": "DATASET", "confidence": 0.8660023808479309}]}, {"text": "The main motivation for selecting the corpus compiled by was the fact that most of its documents have been manually annotated with a single claim, which was associated with a text fragment that most of the times is contained within a sentence.", "labels": [], "entities": []}, {"text": "Having a single sentence as a target constitutes the evaluation of an approach such as the one presented in this paper easier, as the single sentence that represents the main claim of the document can be compared to the topranked sentence by the extractive summarisation algorithm.", "labels": [], "entities": []}, {"text": "A corpus that has similar properties, in the sense that there is a \"major\" claim represented by a text fragment that is contained within a sentence, has been compiled by.", "labels": [], "entities": []}, {"text": "This corpus contains 90 documents that are persuasive essays, and have been manually annotated with an annotation scheme that includes a \"major\" claim for each document, a series of arguments that support or attack the major claim, and series or premises that underpin the validity of an argument.", "labels": [], "entities": []}, {"text": "Despite being a smaller corpus than the first corpus used for evaluation, having only 1675 sentences, that fact that it contains only 90 documents suggests that its documents are slightly larger than the posts of the first document by).", "labels": [], "entities": []}, {"text": "The average length of a persuasive essay is 18.61 sentences in this second evaluation corpus, which is larger than the aver-\"abortion\" \"gay rights\" \"marijuana\" \"Obama\" all: Baseline results (for experiments E 1 and E 2 ) -second evaluation corpus).", "labels": [], "entities": []}, {"text": "age post size of 8.25 sentences of the first corpus.", "labels": [], "entities": []}, {"text": "As a result, the second corpus that will be used for evaluation provides the opportunity to evaluate TextRank on larger documents, where the selection of the sentence that represents the \"major\" claim is potentially more difficult, as the set of potential candidate sentences is larger.", "labels": [], "entities": []}, {"text": "Finally, there is a single \"major\" claim for each persuasive essay, and the mean number of all claims (including the \"major\" claim) is 5.64 per persuasive essay.", "labels": [], "entities": []}, {"text": "As described in the experimental setting, we have performed two experiments.", "labels": [], "entities": []}, {"text": "During the first experiment (E 1 ) we have generated a \"summary\" of a single sentence (the top-ranked sentence by TextRank), while for the second experiment (E 2 ) we have selected the two top-ranked sentences as the generated \"summary\".", "labels": [], "entities": []}, {"text": "In both experiments, each post is characterised as correct if the reason segment is contained in the extracted \"summary\"; otherwise the post is characterised as an error.", "labels": [], "entities": []}, {"text": "The evaluation results are shown in for experiment E 1 and for experiment E 2 . As can be seen from, TextRank has achieved better performance (as measured by accuracy) than our baseline in both experiments, E 1 and E 2 . For experiment E 1 , accuracy has increased from 0.44 (of the baseline) to 0.51, while in experiment E 2 , accuracy has increased from 0.63 to 0.71, when considering all four domains.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 158, "end_pos": 166, "type": "METRIC", "confidence": 0.9980043768882751}, {"text": "accuracy", "start_pos": 242, "end_pos": 250, "type": "METRIC", "confidence": 0.9986133575439453}, {"text": "accuracy", "start_pos": 328, "end_pos": 336, "type": "METRIC", "confidence": 0.9990854263305664}]}, {"text": "In addition, TextRank has achieved better performance for all individual domains than the baseline, which randomly selects sentences.", "labels": [], "entities": []}, {"text": "Another factor is document size: the mean size of posts (measured as the number of contained sentences) seems to vary between the four domains, ranging from 6.5 sentences for domains \"Obama\" and \"marijuana\" to 11 sentences for domain \"abortion\".", "labels": [], "entities": []}, {"text": "TextRank has exhibited better performance than the baseline even for the domains with larger).", "labels": [], "entities": [{"text": "TextRank", "start_pos": 0, "end_pos": 8, "type": "DATASET", "confidence": 0.9399400949478149}]}, {"text": "posts, such as \"abortion\".", "labels": [], "entities": [{"text": "\"abortion\"", "start_pos": 15, "end_pos": 25, "type": "TASK", "confidence": 0.7422148585319519}]}, {"text": "Of course, as the size of documents increases the task of selecting one or two sentences becomes more difficult, and this is evident by the drop in performance (for both TextRank and the baseline) for domains \"abortion\" and \"gay rights\" when compared to the rest of the domains.", "labels": [], "entities": [{"text": "TextRank", "start_pos": 170, "end_pos": 178, "type": "DATASET", "confidence": 0.9324477910995483}]}, {"text": "Results are similar for the second evaluation corpus of persuasive essays, as is shown in Table 6.", "labels": [], "entities": []}, {"text": "Again TextRank has achieved better performance than the baseline for both experiments, E 1 and E 2 . The overall performance of both TextRank and the baseline is lower than the first corpus, mainly due to the increased size of persuasive essays compared to posts (having an average size of 18.61 and 8.25 sentences respectively).", "labels": [], "entities": []}, {"text": "For the second corpus an additional experiment has been performed, which expands the set of claims that have to be identified, from only the \"major\" claim, to all the claims (including the \"major\" one) in an essay.", "labels": [], "entities": []}, {"text": "This experiment (labelled as \"E 1 (all claims)\" and \"E 2 (all claims)\" in Table 6) examines whether the top-ranked sentence (experiment \"E 1 (all claims)\") by TextRank is a claim, or whether the first two sentences as ranked by TextRank contain a claim (experiment \"E 2 (all claims)\").", "labels": [], "entities": []}, {"text": "As expected, the performance of both TextRank and the baseline has been increased, as this is an easier task.", "labels": [], "entities": [{"text": "TextRank", "start_pos": 37, "end_pos": 45, "type": "DATASET", "confidence": 0.9417484998703003}]}, {"text": "The mean number of all claims (including the \"major\" claim) is 5.64 per persuasive essay.", "labels": [], "entities": []}, {"text": "Regarding the overall performance of the summarisation algorithm and its use for identifying a sentence containing an argumentation component, TextRank has managed to achieve a noticeable increase in performance over the baseline, despite the fact that it is an unsupervised algorithm, requiring no training or any form of adaptation to the domain.", "labels": [], "entities": [{"text": "summarisation algorithm", "start_pos": 41, "end_pos": 64, "type": "TASK", "confidence": 0.9178150296211243}]}, {"text": "This suggests that an algorithm that models a document as a whole can provide positive information for argument mining, even if the algorithm has been designed fora different task, as is the case for TextRank variation used, which targets extractive summarisation.", "labels": [], "entities": [{"text": "argument mining", "start_pos": 103, "end_pos": 118, "type": "TASK", "confidence": 0.7908762991428375}]}, {"text": "In addition, the evaluation results suggest that there is some overlap between argument mining and summarisation, leading to the conclusion that there are potential benefits for approaches performing argument mining through the synergy with approaches that perform document summarisation.", "labels": [], "entities": [{"text": "argument mining", "start_pos": 79, "end_pos": 94, "type": "TASK", "confidence": 0.7660173773765564}, {"text": "summarisation", "start_pos": 99, "end_pos": 112, "type": "TASK", "confidence": 0.9804438352584839}, {"text": "argument mining", "start_pos": 200, "end_pos": 215, "type": "TASK", "confidence": 0.7236581146717072}, {"text": "document summarisation", "start_pos": 265, "end_pos": 287, "type": "TASK", "confidence": 0.6116002202033997}]}], "tableCaptions": [{"text": " Table 1: Number of posts per domain in the first corpus used for evaluation (Hasan and Ng, 2014).", "labels": [], "entities": []}, {"text": " Table 2: Baseline results (for experiments E 1 and E 2 ) -first evaluation corpus (Hasan and Ng, 2014).", "labels": [], "entities": []}, {"text": " Table 3: Baseline results (for experiments E 1  and E 2 ) -second evaluation corpus", "labels": [], "entities": []}, {"text": " Table 4: Evaluation Results (for experiment E 1 ) -first evaluation corpus (Hasan and Ng, 2014).", "labels": [], "entities": []}, {"text": " Table 5: Evaluation Results (for experiment E 2 ) -first evaluation corpus (Hasan and Ng, 2014).", "labels": [], "entities": []}, {"text": " Table 6: Evaluation Results -second evaluation corpus (", "labels": [], "entities": []}]}