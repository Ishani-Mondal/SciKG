{"title": [{"text": "An Assessment of Experimental Protocols for Tracing Changes in Word Semantics Relative to Accuracy and Reliability", "labels": [], "entities": [{"text": "Tracing Changes in Word Semantics Relative", "start_pos": 44, "end_pos": 86, "type": "TASK", "confidence": 0.7265458703041077}]}], "abstractContent": [{"text": "Our research aims at tracking the semantic evolution of the lexicon overtime.", "labels": [], "entities": []}, {"text": "For this purpose, we investigated two well-known training protocols for neural language models in a synchronic experiment and encountered several problems relating to accuracy and reliability.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 167, "end_pos": 175, "type": "METRIC", "confidence": 0.9987579584121704}]}, {"text": "We were able to identify critical parameters for improving the underlying protocols in order to generate more adequate diachronic language models.", "labels": [], "entities": []}], "introductionContent": [{"text": "The lexicon can be considered the most dynamic part of all linguistic knowledge sources overtime.", "labels": [], "entities": []}, {"text": "There are two innovative change strategies typical for lexical systems: the creation of entirely new lexical items, commonly reflecting the emergence of novel ideas, technologies or artifacts, on the one hand, and, on the other hand, shifts in the meaning of already existing lexical items, a process which usually takes place over larger periods of time.", "labels": [], "entities": []}, {"text": "Tracing semantic changes of the latter type is the main focus of our research.", "labels": [], "entities": [{"text": "Tracing semantic changes", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.9184379577636719}]}, {"text": "Meaning shift has recently been investigated with emphasis on neural language models (.", "labels": [], "entities": [{"text": "Meaning shift", "start_pos": 0, "end_pos": 13, "type": "TASK", "confidence": 0.8881834149360657}]}, {"text": "This work is based on the assumption that the measurement of semantic change patterns can be reduced to the measurement of lexical similarity between lexical items.", "labels": [], "entities": []}, {"text": "Neural language models, originating from the word2vec algorithm (), are currently considered as state-of-the-art solutions for implementing this assumption (.", "labels": [], "entities": []}, {"text": "Within this approach, changes in similarity relations between lexical items at two different points of time are interpreted as a signal for meaning shift.", "labels": [], "entities": [{"text": "meaning shift", "start_pos": 140, "end_pos": 153, "type": "TASK", "confidence": 0.7405644655227661}]}, {"text": "Accordingly, lexical items which are very similar to the lexical item under scrutiny can be considered as approximating its meaning at a given point in time.", "labels": [], "entities": []}, {"text": "Both techniques were already combined in prior work to show, e.g., the increasing association of the lexical item \"gay\" with the meaning dimension of \"homosexuality\" (.", "labels": [], "entities": []}, {"text": "We here investigate the accuracy and reliability of such similarity judgments derived from different training protocols dependent on word frequency, word ambiguity and the number of training epochs (i.e., iterations overall training material).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 24, "end_pos": 32, "type": "METRIC", "confidence": 0.9961004257202148}]}, {"text": "Accuracy renders a judgment of the overall model quality, whereas reliability between repeated experiments ensures that qualitative judgments can indeed be transferred between experiments.", "labels": [], "entities": []}, {"text": "Based on the identification of critical conditions in the experimental set-up of previously employed protocols, we recommend improved training strategies for more adequate neural language models dealing with diachronic lexical change patterns.", "labels": [], "entities": []}, {"text": "Our results concerning reliability also cast doubt on the reproducibility of experiments where semantic similarity between lexical items is taken as a computationally valid indicator for properly capturing lexical meaning (and, consequently, meaning shifts) under a diachronic perspective.", "labels": [], "entities": []}], "datasetContent": [{"text": "For comparability with earlier studies, we use the fiction part of the GOOGLE BOOKS NGRAM corpus).", "labels": [], "entities": [{"text": "GOOGLE BOOKS NGRAM corpus", "start_pos": 71, "end_pos": 96, "type": "DATASET", "confidence": 0.7612240612506866}]}, {"text": "This part of the corpus is also less affected by sampling irregularities than other parts).", "labels": [], "entities": []}, {"text": "Due to the opaque nature of GOOGLE's corpus acquisition strategy, the influence of OCR errors on our results cannot be reasonably estimated, yet we assume that they will affect all experiments in an equal manner.", "labels": [], "entities": [{"text": "GOOGLE", "start_pos": 28, "end_pos": 34, "type": "DATASET", "confidence": 0.8282938599586487}, {"text": "corpus acquisition", "start_pos": 37, "end_pos": 55, "type": "TASK", "confidence": 0.7019942402839661}]}, {"text": "The wide range of experimental parameters described in Section 2 makes it virtually impossible to test all their possible combinations, especially as repeated experiments are necessary to probe a method's reliability.", "labels": [], "entities": []}, {"text": "We thus concentrate on two experimental protocols-the one described by (referred to as Kim protocol) and the one from (referred to as Kulkarni protocol), including close variations thereof.", "labels": [], "entities": []}, {"text": "Kulkarni's protocol operates on all 5-grams occurring during five consecutive years (e.g.,) and trains models independently of each other.", "labels": [], "entities": []}, {"text": "Kim's protocol operates on uniformly sized samples of 10M 5-grams for each year from 1850 onwards in a continuous fashion (years before 1900 are used for initialization only).", "labels": [], "entities": [{"text": "initialization", "start_pos": 154, "end_pos": 168, "type": "TASK", "confidence": 0.9609823226928711}]}, {"text": "Its constant sampling sizes result in both oversampling and undersampling as is evident from.", "labels": [], "entities": []}, {"text": "We use the PYTHON-based GENSIM 1 implementation of word2vec for our experiments; the relevant code is made available via GITHUB.", "labels": [], "entities": [{"text": "PYTHON-based GENSIM 1", "start_pos": 11, "end_pos": 32, "type": "DATASET", "confidence": 0.7381100455919901}, {"text": "GITHUB", "start_pos": 121, "end_pos": 127, "type": "DATASET", "confidence": 0.768526554107666}]}, {"text": "Due to the 5-gram nature of the corpus, a context window covering four neighboring words is used for all experiments.", "labels": [], "entities": []}, {"text": "Only words with at least 10 occurrences in a sample are modeled.", "labels": [], "entities": []}, {"text": "Training for each sample is repeated until convergence 3 is achieved or 10 epochs have passed.", "labels": [], "entities": []}, {"text": "Following both protocols, we use word vectors with 200: Accuracy and reliability among top n words for threefold application of different training protocols.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 56, "end_pos": 64, "type": "METRIC", "confidence": 0.9934220910072327}, {"text": "reliability", "start_pos": 69, "end_pos": 80, "type": "METRIC", "confidence": 0.9910075068473816}]}, {"text": "Reliability is given as fraction of the maximum for n.", "labels": [], "entities": [{"text": "Reliability", "start_pos": 0, "end_pos": 11, "type": "METRIC", "confidence": 0.9711967706680298}]}, {"text": "Standard deviation for accuracy \u00b10, if not noted otherwise; reliability is based on the evaluation of all lexical items, thus no standard deviation.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 23, "end_pos": 31, "type": "METRIC", "confidence": 0.9990878105163574}, {"text": "reliability", "start_pos": 60, "end_pos": 71, "type": "METRIC", "confidence": 0.9976187348365784}]}, {"text": "We tested both negative sampling and hierarchical softmax training strategies, the latter being canonical for Kulkarni's protocol, whereas Kim's protocol is underspecified in this regard.", "labels": [], "entities": []}, {"text": "We evaluate accuracy by using the test set developed by.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 12, "end_pos": 20, "type": "METRIC", "confidence": 0.99940025806427}]}, {"text": "This test set is based on present-day English language and world knowledge, yet we assume it to be a viable proxy for overall model quality.", "labels": [], "entities": []}, {"text": "It contains groups of four words connected via the analogy relation '::' and the similarity relation '\u223c', as exemplified by the expression king \u223c queen :: man \u223c woman.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Accuracy and reliability among top n words for threefold application of different training  protocols. Reliability is given as fraction of the maximum for n. Standard deviation for accuracy \u00b10, if  not noted otherwise; reliability is based on the evaluation of all lexical items, thus no standard deviation.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9894376993179321}, {"text": "reliability", "start_pos": 23, "end_pos": 34, "type": "METRIC", "confidence": 0.9855051636695862}, {"text": "Reliability", "start_pos": 113, "end_pos": 124, "type": "METRIC", "confidence": 0.9982050657272339}, {"text": "accuracy", "start_pos": 191, "end_pos": 199, "type": "METRIC", "confidence": 0.9968764781951904}, {"text": "reliability", "start_pos": 229, "end_pos": 240, "type": "METRIC", "confidence": 0.9834378957748413}]}]}