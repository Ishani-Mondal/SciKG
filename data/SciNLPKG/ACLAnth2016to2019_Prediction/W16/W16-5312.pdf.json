{"title": [{"text": "CogALex-V Shared Task: Mach5 A traditional DSM approach to semantic relatedness", "labels": [], "entities": [{"text": "semantic relatedness", "start_pos": 59, "end_pos": 79, "type": "TASK", "confidence": 0.7037152349948883}]}], "abstractContent": [{"text": "This contribution provides a strong baseline result for the CogALex-V shared task using a traditional \"count\"-type DSM (placed in rank 2 out of 7 in subtask 1 and rank 3 out of 6 in subtask 2).", "labels": [], "entities": []}, {"text": "Parameter tuning experiments reveal some surprising effects and suggest that the use of random word pairs as negative examples maybe problematic, guiding the parameter optimization in an undesirable direction.", "labels": [], "entities": [{"text": "Parameter tuning", "start_pos": 0, "end_pos": 16, "type": "TASK", "confidence": 0.7315531224012375}, {"text": "parameter optimization", "start_pos": 158, "end_pos": 180, "type": "TASK", "confidence": 0.7563717663288116}]}], "introductionContent": [{"text": "It is generally assumed that traditional \"count\"-type distributional semantic models (DSM) are good at identifying attributionally similar words, but cannot distinguish between different semantic relations (e.g. synonyms, antonyms, hypernyms) and work poorly for other forms of semantic relatedness such as meronymy ().", "labels": [], "entities": []}, {"text": "Moreover, DSMs based on syntactic dependency relations are supposed to achieve better results than window-based models.", "labels": [], "entities": [{"text": "DSMs", "start_pos": 10, "end_pos": 14, "type": "TASK", "confidence": 0.9592620134353638}]}, {"text": "The goal of the present paper is to test how well traditional DSMs can be tuned to identify different types of semantic relations in the CogALex-V shared task.", "labels": [], "entities": []}, {"text": "It can thus be seen as a strong baseline against which more specialized approaches can be compared.", "labels": [], "entities": []}, {"text": "The system developed here is nicknamed , or Mach5 1 in English.", "labels": [], "entities": []}, {"text": "According to the distributional hypothesis, semantically related words should have a smaller distance in a distributional space than unrelated words, especially if they are attributionally similar.", "labels": [], "entities": []}, {"text": "This suggests a simple strategy for the identification of semantically related words in subtask 1: candidate pairs are predicted to be related if their distributional distance is below a specified threshold value \u03b8.", "labels": [], "entities": [{"text": "identification of semantically related words", "start_pos": 40, "end_pos": 84, "type": "TASK", "confidence": 0.7993831634521484}]}, {"text": "The choice of \u03b8 determines the trade-off between precision and recall as visualized in the left panel of, where the thin dotted line shows precision (P ) and the thin dashed line shows recall (R) for different values of \u03b8.", "labels": [], "entities": [{"text": "precision", "start_pos": 49, "end_pos": 58, "type": "METRIC", "confidence": 0.9993082284927368}, {"text": "recall", "start_pos": 63, "end_pos": 69, "type": "METRIC", "confidence": 0.9979748129844666}, {"text": "precision (P )", "start_pos": 139, "end_pos": 153, "type": "METRIC", "confidence": 0.9430535137653351}, {"text": "recall (R)", "start_pos": 185, "end_pos": 195, "type": "METRIC", "confidence": 0.9631735682487488}]}, {"text": "The optimal threshold \u03b8 * = 80.7 \u2022 -indicated by a circle and a thin vertical line -is chosen to maximize F 1 -score, the harmonic mean of precision and recall, which is also the main evaluation criterion in the CogALex-V task.", "labels": [], "entities": [{"text": "F 1 -score", "start_pos": 106, "end_pos": 116, "type": "METRIC", "confidence": 0.9886341542005539}, {"text": "precision", "start_pos": 139, "end_pos": 148, "type": "METRIC", "confidence": 0.998342752456665}, {"text": "recall", "start_pos": 153, "end_pos": 159, "type": "METRIC", "confidence": 0.9980941414833069}]}, {"text": "In this example, the DSM achieves P = 76.27%, R = 74.38% and F 1 = 75.31% on the training data.", "labels": [], "entities": [{"text": "DSM", "start_pos": 21, "end_pos": 24, "type": "DATASET", "confidence": 0.9155362248420715}, {"text": "P", "start_pos": 34, "end_pos": 35, "type": "METRIC", "confidence": 0.9988376498222351}, {"text": "R", "start_pos": 46, "end_pos": 47, "type": "METRIC", "confidence": 0.9978881478309631}, {"text": "F 1", "start_pos": 61, "end_pos": 64, "type": "METRIC", "confidence": 0.9949609637260437}]}, {"text": "DSM distances cannot be used in the same way to discriminate between semantic relations in subtask 2 because antonyms, synonyms, hypernyms, etc.", "labels": [], "entities": []}, {"text": "will all be relatively close in semantic space and their distance distributions are similar (.", "labels": [], "entities": []}, {"text": "Therefore, Mach5 implements a simple machine learning approach for this subtask, as described in Sec.", "labels": [], "entities": []}, {"text": "3. Parameters of the underlying DSM are tuned based on the overall identification of semantically related words (Sec. 2).", "labels": [], "entities": [{"text": "Parameters", "start_pos": 3, "end_pos": 13, "type": "METRIC", "confidence": 0.9742285013198853}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Evaluation results of different Mach5 runs on the training data (10-fold cross-validation) and  test data, using the official F 1 -scores in subtask 1 and weighted average \u00af  F 1 across the four semantic  relations in subtask 2. Runs selected for the competition are shown in bold font, the best results obtained  in follow-up experiments are shown in italics.", "labels": [], "entities": [{"text": "F 1 -scores", "start_pos": 136, "end_pos": 147, "type": "METRIC", "confidence": 0.9629342555999756}, {"text": "F 1", "start_pos": 185, "end_pos": 188, "type": "METRIC", "confidence": 0.9641225934028625}]}]}