{"title": [{"text": "Microblog Emotion Classification by Computing Similarity in Text, Time, and Space", "labels": [], "entities": [{"text": "Microblog Emotion Classification", "start_pos": 0, "end_pos": 32, "type": "TASK", "confidence": 0.6764378547668457}]}], "abstractContent": [{"text": "Most work in NLP analysing microblogs focuses on textual content thus neglecting temporal and spatial information.", "labels": [], "entities": [{"text": "NLP analysing microblogs", "start_pos": 13, "end_pos": 37, "type": "TASK", "confidence": 0.7896930575370789}]}, {"text": "We present anew interdisciplinary method for emotion classification that combines linguistic, temporal, and spatial information into a single metric.", "labels": [], "entities": [{"text": "emotion classification", "start_pos": 45, "end_pos": 67, "type": "TASK", "confidence": 0.8141560852527618}]}, {"text": "We create a graph of labeled and unlabeled tweets that encodes the relations between neighboring tweets with respect to their emotion labels.", "labels": [], "entities": []}, {"text": "Graph-based semi-supervised learning labels all tweets with an emotion.", "labels": [], "entities": []}], "introductionContent": [], "datasetContent": [{"text": "For the experiments we use the gold standard constructed in Section 3 divided into 50% seed data for the semi-supervised graph-based machine learning algorithm and 50% testing data.", "labels": [], "entities": []}, {"text": "Graph construction is guided by the similarity computation method described in Section 4.", "labels": [], "entities": [{"text": "Graph construction", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.8849848806858063}]}, {"text": "Classification is performed by Modified Adsorption, the semi-supervised label propagation algorithm implemented in the Junto-toolkit 4 (.", "labels": [], "entities": [{"text": "Classification", "start_pos": 0, "end_pos": 14, "type": "TASK", "confidence": 0.9586848020553589}, {"text": "label propagation", "start_pos": 72, "end_pos": 89, "type": "TASK", "confidence": 0.7439258396625519}]}, {"text": "From the gold standard we use level 4, i.e. all tweets which have been annotated with the same label by at least four out of five annotators.", "labels": [], "entities": []}, {"text": "This way we make use of more than 75% of the annotated data while ensuring high quality annotations for learning and evaluation.", "labels": [], "entities": []}, {"text": "In addition we use 10,000 unlabeled tweets for learning.", "labels": [], "entities": []}, {"text": "We set the threshold for edges (minimum weight) to 0.5.", "labels": [], "entities": []}, {"text": "In we report the results in terms of micro-and macro-average precision, recall and F-measure.", "labels": [], "entities": [{"text": "precision", "start_pos": 61, "end_pos": 70, "type": "METRIC", "confidence": 0.8249785304069519}, {"text": "recall", "start_pos": 72, "end_pos": 78, "type": "METRIC", "confidence": 0.9997815489768982}, {"text": "F-measure", "start_pos": 83, "end_pos": 92, "type": "METRIC", "confidence": 0.998388409614563}]}, {"text": "Since the classes have a skewed distribution, results for micro-and macro-average show a large difference.", "labels": [], "entities": []}, {"text": "We apply McNemar's test to report statistically significant differences.", "labels": [], "entities": []}, {"text": "Random and majority decisions serve as baselines for comparison.", "labels": [], "entities": []}, {"text": "The macro-average results should be compared with the random baseline, the micro-average results with the majority baseline.", "labels": [], "entities": []}, {"text": "Most of the linguistic features taken on its own perform just like the majority class classification, i.e., they classify each tweet as none.", "labels": [], "entities": []}, {"text": "Only ANEW and emojis manage to classify some tweets differently.", "labels": [], "entities": [{"text": "ANEW", "start_pos": 5, "end_pos": 9, "type": "METRIC", "confidence": 0.7440359592437744}]}, {"text": "With ANEW this leads to a slight decrease in performance, with emojis to an improvement (statistically significant improvement in recall).", "labels": [], "entities": [{"text": "ANEW", "start_pos": 5, "end_pos": 9, "type": "METRIC", "confidence": 0.49564510583877563}, {"text": "recall", "start_pos": 130, "end_pos": 136, "type": "METRIC", "confidence": 0.9985331296920776}]}, {"text": "A closer inspection of the results shows that both features pickup on the second largest class and label some tweets correctly with happiness.", "labels": [], "entities": [{"text": "pickup", "start_pos": 60, "end_pos": 66, "type": "METRIC", "confidence": 0.9636885523796082}]}, {"text": "See for some tweets correctly labeled with happiness in the final setting.", "labels": [], "entities": []}, {"text": "When combining the strongest linguistic feature emojis with other lingustic features, ANEW and POS lead to slight decrease in performance while combining emojis and words achieves the best results in F-measure which is due to a higher precision.", "labels": [], "entities": [{"text": "ANEW", "start_pos": 86, "end_pos": 90, "type": "METRIC", "confidence": 0.9743263721466064}, {"text": "POS", "start_pos": 95, "end_pos": 98, "type": "METRIC", "confidence": 0.9879155158996582}, {"text": "F-measure", "start_pos": 200, "end_pos": 209, "type": "METRIC", "confidence": 0.9908561706542969}, {"text": "precision", "start_pos": 235, "end_pos": 244, "type": "METRIC", "confidence": 0.9970499277114868}]}, {"text": "Adding further linguistic features does not cause any improvement.", "labels": [], "entities": []}, {"text": "Temporal and spatial features on their own do not classify anything correctly.", "labels": [], "entities": []}, {"text": "When combining emojis with temporal features (with a range of different values for \u03b1) we observe a drop in performance.", "labels": [], "entities": []}, {"text": "When combining with spatial features and with spatial and temporal features, there is no difference to just emojis.", "labels": [], "entities": []}, {"text": "Further experiments with temporal and spatial features show that they lead to a small but statistically not significant improvement when weighted much higher than linguistic similarity (e.g. \u00d7 5).", "labels": [], "entities": []}, {"text": "Highest values for \u03b1 performed best (i.e. lowest curves in).", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 4: Number of gold standard labels per emotion class and agreement level", "labels": [], "entities": []}, {"text": " Table 6: 30 most frequent hashtags in the data set.", "labels": [], "entities": []}, {"text": " Table 7: Results using Modified Adsorption, agreement level 4, minimum edge weight 0.5", "labels": [], "entities": [{"text": "agreement level 4", "start_pos": 45, "end_pos": 62, "type": "METRIC", "confidence": 0.9648962815602621}, {"text": "minimum edge weight 0.5", "start_pos": 64, "end_pos": 87, "type": "METRIC", "confidence": 0.7646715119481087}]}]}