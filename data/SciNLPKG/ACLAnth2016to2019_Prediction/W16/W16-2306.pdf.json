{"title": [{"text": "ParFDA for Instance Selection for Statistical Machine Translation", "labels": [], "entities": [{"text": "Instance Selection", "start_pos": 11, "end_pos": 29, "type": "TASK", "confidence": 0.9346711933612823}, {"text": "Statistical Machine Translation", "start_pos": 34, "end_pos": 65, "type": "TASK", "confidence": 0.8495369156201681}]}], "abstractContent": [{"text": "We build parallel feature decay algorithms (ParFDA) Moses statistical machine translation (SMT) systems for all language pairs in the translation task at the first conference on statistical machine translation (Bojar et al., 2016a) (WMT16).", "labels": [], "entities": [{"text": "statistical machine translation (SMT)", "start_pos": 58, "end_pos": 95, "type": "TASK", "confidence": 0.7776160637537638}, {"text": "statistical machine translation", "start_pos": 178, "end_pos": 209, "type": "TASK", "confidence": 0.6588054895401001}, {"text": "WMT16)", "start_pos": 233, "end_pos": 239, "type": "DATASET", "confidence": 0.779655784368515}]}, {"text": "ParFDA obtains results close to the top constrained phrase-based SMT with an average of 2.52 BLEU points difference using significantly less computation for building SMT systems than the computation that would be spent using all available corpora.", "labels": [], "entities": [{"text": "SMT", "start_pos": 65, "end_pos": 68, "type": "TASK", "confidence": 0.8232772350311279}, {"text": "BLEU points difference", "start_pos": 93, "end_pos": 115, "type": "METRIC", "confidence": 0.9522735277811686}]}, {"text": "We obtain BLEU bounds based on target coverage and show that ParFDA results can be improved by 12.6 BLEU points on average.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9990969896316528}, {"text": "ParFDA", "start_pos": 61, "end_pos": 67, "type": "METRIC", "confidence": 0.9179600477218628}, {"text": "BLEU", "start_pos": 100, "end_pos": 104, "type": "METRIC", "confidence": 0.9989466071128845}]}, {"text": "Similar bounds show that top constrained SMT results at WMT16 can be improved by 8 BLEU points on average while German to En-glish and Romanian to English translations results are already close to the bounds.", "labels": [], "entities": [{"text": "SMT", "start_pos": 41, "end_pos": 44, "type": "TASK", "confidence": 0.9893434047698975}, {"text": "WMT16", "start_pos": 56, "end_pos": 61, "type": "DATASET", "confidence": 0.8799277544021606}, {"text": "BLEU", "start_pos": 83, "end_pos": 87, "type": "METRIC", "confidence": 0.9988442659378052}]}], "introductionContent": [], "datasetContent": [{"text": "The importance of ParFDA increases with the proliferation of training resources available for building SMT systems.", "labels": [], "entities": [{"text": "SMT", "start_pos": 103, "end_pos": 106, "type": "TASK", "confidence": 0.9910159111022949}]}, {"text": "Compared with WMT15, WMT16 observed significant increase in monolingual and parallel training data made available.", "labels": [], "entities": [{"text": "WMT15", "start_pos": 14, "end_pos": 19, "type": "DATASET", "confidence": 0.8964517116546631}, {"text": "WMT16", "start_pos": 21, "end_pos": 26, "type": "DATASET", "confidence": 0.8129249215126038}]}, {"text": "presents the statistics of the available training and LM corpora for the constrained (C) systems in WMT16 () as well as the statistics of the ParFDA selected subset training and LM data from C.", "labels": [], "entities": [{"text": "WMT16", "start_pos": 100, "end_pos": 105, "type": "DATASET", "confidence": 0.9203705787658691}]}, {"text": "TCOV lists the target coverage in terms of the 2-grams of the test set.", "labels": [], "entities": [{"text": "TCOV", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.852608323097229}]}, {"text": "Compared with last year, this year we do not use Common Crawl parallel corpus except for en-ru.", "labels": [], "entities": [{"text": "Common Crawl parallel corpus", "start_pos": 49, "end_pos": 77, "type": "DATASET", "confidence": 0.8502281755208969}]}, {"text": "We use Common Crawl monolingual corpus fi, ro, and tr datasets and we extended the LM corpora with previous years' corpora.", "labels": [], "entities": [{"text": "Common Crawl monolingual corpus fi, ro, and tr datasets", "start_pos": 7, "end_pos": 62, "type": "DATASET", "confidence": 0.7395219071344896}]}, {"text": "We also use CzEng16pre () for en-cs.", "labels": [], "entities": []}, {"text": "We have increased the size of the training data selected to about 1.6 million instances to help with the reduction of out-of-vocabulary items.", "labels": [], "entities": []}, {"text": "Except for translation directions involving Romanian and Turkish, this corresponds to increased training set size compared with ParFDA experiments in 2015, where we were able to obtain the top translation error rate (TER) performance in French to English translation using 1.261 million training sentences ( . Due to the presence of peaks in SMT performance with increasing training set size, increasing the training set size need not improve the performance.", "labels": [], "entities": [{"text": "translation error rate (TER)", "start_pos": 193, "end_pos": 221, "type": "METRIC", "confidence": 0.8582007686297098}, {"text": "SMT", "start_pos": 342, "end_pos": 345, "type": "TASK", "confidence": 0.9893395304679871}]}, {"text": "We select about 15 million sentences for each LM not including the selected training set, which is added later.", "labels": [], "entities": []}, {"text": "shows the significant size differences between the constrained dataset (C) and the ParFDA selected data.", "labels": [], "entities": [{"text": "ParFDA selected data", "start_pos": 83, "end_pos": 103, "type": "DATASET", "confidence": 0.823712428410848}]}, {"text": "We use 3-grams for selecting training data and 2-grams for LM corpus selection.", "labels": [], "entities": [{"text": "LM corpus selection", "start_pos": 59, "end_pos": 78, "type": "TASK", "confidence": 0.7442389329274496}]}, {"text": "Task specific data selection also improves the LM perplexity and the performance of the selected LM can be observed in.", "labels": [], "entities": []}, {"text": "We truecase all of the corpora, set the maximum sentence length to 126, use 150-best lists during tuning, set the LM order to 6 for all language pairs, and train the LM using KENLM (.", "labels": [], "entities": []}, {"text": "For word alignment, we use mgiza ( where GIZA++ () parameters set max-fertility to 10, the number of iterations to 7,3,5,5,7 for IBM models 1,2,3,4, and the HMM model, and learn 50 word classes in three iterations with the mkcls tool during training.", "labels": [], "entities": [{"text": "word alignment", "start_pos": 4, "end_pos": 18, "type": "TASK", "confidence": 0.8547374308109283}]}, {"text": "The development set contains up to 3000 sentences randomly sampled from previous years' development sets and remaining come from the development set for WMT16.", "labels": [], "entities": [{"text": "WMT16", "start_pos": 153, "end_pos": 158, "type": "DATASET", "confidence": 0.9382944107055664}]}, {"text": "ParFDA Moses SMT workflow is depicted in.", "labels": [], "entities": [{"text": "ParFDA", "start_pos": 0, "end_pos": 6, "type": "DATASET", "confidence": 0.8262193202972412}, {"text": "SMT workflow", "start_pos": 13, "end_pos": 25, "type": "TASK", "confidence": 0.5860551297664642}]}, {"text": "ParFDA Moses SMT results for each translation direction at WMT16 are in using BLEU over cased text, and F 1 (Bi\u00e7ici, 2011).", "labels": [], "entities": [{"text": "SMT", "start_pos": 13, "end_pos": 16, "type": "TASK", "confidence": 0.7925735712051392}, {"text": "WMT16", "start_pos": 59, "end_pos": 64, "type": "DATASET", "confidence": 0.9272399544715881}, {"text": "BLEU", "start_pos": 78, "end_pos": 82, "type": "METRIC", "confidence": 0.9979479908943176}, {"text": "F 1", "start_pos": 104, "end_pos": 107, "type": "METRIC", "confidence": 0.972213864326477}]}, {"text": "We compare ParFDA results with the top constrained submissions at WMT16 in.", "labels": [], "entities": [{"text": "ParFDA", "start_pos": 11, "end_pos": 17, "type": "METRIC", "confidence": 0.6680869460105896}, {"text": "WMT16", "start_pos": 66, "end_pos": 71, "type": "DATASET", "confidence": 0.9178998470306396}]}, {"text": "The average difference to the top constrained (TopC) submission in WMT16 is 5.26 BLEU points whereas the difference was 3.2 BLEU points in WMT15 . Performance compared with the TopC phrase-based SMT improved over WMT15 results with 2.52 BLEU points difference on av-   creased performance difference is due to improvements obtained by BPE in TopC BPE results.", "labels": [], "entities": [{"text": "WMT16", "start_pos": 67, "end_pos": 72, "type": "DATASET", "confidence": 0.9346044659614563}, {"text": "BLEU", "start_pos": 81, "end_pos": 85, "type": "METRIC", "confidence": 0.9987204074859619}, {"text": "BLEU", "start_pos": 124, "end_pos": 128, "type": "METRIC", "confidence": 0.9955358505249023}, {"text": "WMT15", "start_pos": 139, "end_pos": 144, "type": "DATASET", "confidence": 0.9557554125785828}, {"text": "SMT", "start_pos": 195, "end_pos": 198, "type": "TASK", "confidence": 0.48562929034233093}, {"text": "WMT15", "start_pos": 213, "end_pos": 218, "type": "DATASET", "confidence": 0.83622145652771}, {"text": "BLEU", "start_pos": 237, "end_pos": 241, "type": "METRIC", "confidence": 0.991312563419342}, {"text": "BPE", "start_pos": 335, "end_pos": 338, "type": "METRIC", "confidence": 0.6492061614990234}, {"text": "TopC BPE", "start_pos": 342, "end_pos": 350, "type": "DATASET", "confidence": 0.7653107345104218}]}, {"text": "compares the perplexity of the ParFDA selected LM with a LM trained on the ParFDA selected training data and a LM trained using all of the available training corpora and shows reductions in the number of OOV tokens reaching up to 45% and the perplexity up to 45%.", "labels": [], "entities": [{"text": "ParFDA selected training data", "start_pos": 75, "end_pos": 104, "type": "DATASET", "confidence": 0.9020536243915558}]}, {"text": "also presents the average log probability of tokens and the log probability of token <unk> returned by KENLM to token <unk>.", "labels": [], "entities": []}, {"text": "The increase in the ratio between them in the last column shows that OOV in ParFDA LM are not just less but also less likely at the same time.: Perplexity comparison of the LM built from the training corpus (train), ParFDA selected training data (FDA5 train), and the ParFDA selected LM data (FDA5 LM).", "labels": [], "entities": [{"text": "OOV", "start_pos": 69, "end_pos": 72, "type": "METRIC", "confidence": 0.9972677230834961}, {"text": "ParFDA selected training data", "start_pos": 216, "end_pos": 245, "type": "DATASET", "confidence": 0.6866061687469482}, {"text": "ParFDA selected LM data", "start_pos": 268, "end_pos": 291, "type": "DATASET", "confidence": 0.761695995926857}]}, {"text": "%red is proportion of reduction and prob. is used for probability.", "labels": [], "entities": [{"text": "reduction", "start_pos": 22, "end_pos": 31, "type": "METRIC", "confidence": 0.7297956347465515}, {"text": "probability", "start_pos": 54, "end_pos": 65, "type": "METRIC", "confidence": 0.9597946405410767}]}], "tableCaptions": [{"text": " Table 1: Data statistics for the available training and LM corpora in the constrained (C) setting compared  with the ParFDA selected training and LM data. #words is in millions (M) and #sents in thousands (K).  TCOV is target 2-gram coverage.", "labels": [], "entities": [{"text": "TCOV", "start_pos": 212, "end_pos": 216, "type": "METRIC", "confidence": 0.9402564764022827}]}, {"text": " Table 2: ParFDA results at WMT16.", "labels": [], "entities": [{"text": "ParFDA", "start_pos": 10, "end_pos": 16, "type": "METRIC", "confidence": 0.7221037745475769}, {"text": "WMT16", "start_pos": 28, "end_pos": 33, "type": "DATASET", "confidence": 0.920478343963623}]}, {"text": " Table 3: ParFDA results compared with the top constrained results in WMT16 (TopC, from matrix.  statmt.org) and their difference.", "labels": [], "entities": [{"text": "ParFDA", "start_pos": 10, "end_pos": 16, "type": "METRIC", "confidence": 0.8344308137893677}, {"text": "WMT16", "start_pos": 70, "end_pos": 75, "type": "DATASET", "confidence": 0.9264131188392639}]}, {"text": " Table 4: Perplexity comparison of the LM built from the training corpus (train), ParFDA selected training  data (FDA5 train), and the ParFDA selected LM data (FDA5 LM). %red is proportion of reduction and  prob. is used for probability.", "labels": [], "entities": [{"text": "ParFDA selected training  data", "start_pos": 82, "end_pos": 112, "type": "DATASET", "confidence": 0.7865148484706879}, {"text": "ParFDA selected LM data", "start_pos": 135, "end_pos": 158, "type": "DATASET", "confidence": 0.8233198523521423}, {"text": "reduction", "start_pos": 192, "end_pos": 201, "type": "METRIC", "confidence": 0.7671955823898315}, {"text": "probability", "start_pos": 225, "end_pos": 236, "type": "METRIC", "confidence": 0.9518206119537354}]}, {"text": " Table 5: 1,2,3,4,5-gram TCOV BLEU bounds compared with WMT16 results. bold are close to a bound.", "labels": [], "entities": [{"text": "TCOV", "start_pos": 25, "end_pos": 29, "type": "METRIC", "confidence": 0.9570304155349731}, {"text": "BLEU", "start_pos": 30, "end_pos": 34, "type": "METRIC", "confidence": 0.7869483828544617}, {"text": "WMT16", "start_pos": 56, "end_pos": 61, "type": "DATASET", "confidence": 0.6691206693649292}]}]}