{"title": [{"text": "Generating English from Abstract Meaning Representations", "labels": [], "entities": [{"text": "Generating English from Abstract Meaning Representations", "start_pos": 0, "end_pos": 56, "type": "TASK", "confidence": 0.8328664402167002}]}], "abstractContent": [{"text": "We present a method for generating English sentences from Abstract Meaning Representation (AMR) graphs, exploiting a parallel corpus of AMRs and English sentences.", "labels": [], "entities": [{"text": "generating English sentences from Abstract Meaning Representation (AMR)", "start_pos": 24, "end_pos": 95, "type": "TASK", "confidence": 0.6543251007795334}]}, {"text": "We treat AMR-to-English generation as phrase-based machine translation (PBMT).", "labels": [], "entities": [{"text": "AMR-to-English generation", "start_pos": 9, "end_pos": 34, "type": "TASK", "confidence": 0.958858460187912}, {"text": "phrase-based machine translation", "start_pos": 38, "end_pos": 70, "type": "TASK", "confidence": 0.6096621553103129}]}, {"text": "We introduce a method that learns to linearize tokens of AMR graphs into an English-like order.", "labels": [], "entities": []}, {"text": "Our lin-earization reduces the amount of distortion in PBMT and increases generation quality.", "labels": [], "entities": []}, {"text": "We report a Bleu score of 26.8 on the standard AMR/English test set.", "labels": [], "entities": [{"text": "Bleu score", "start_pos": 12, "end_pos": 22, "type": "METRIC", "confidence": 0.9827179610729218}, {"text": "AMR/English test set", "start_pos": 47, "end_pos": 67, "type": "DATASET", "confidence": 0.886561107635498}]}], "introductionContent": [{"text": "introduce Abstract Meaning Representation (AMR) graphs to represent sentence level semantics.", "labels": [], "entities": [{"text": "Abstract Meaning Representation (AMR)", "start_pos": 10, "end_pos": 47, "type": "TASK", "confidence": 0.7743435104688009}]}, {"text": "Human annotators have created a dataset of more than 10, 000 AMR/English string pairs.", "labels": [], "entities": [{"text": "AMR/English string pairs", "start_pos": 61, "end_pos": 85, "type": "TASK", "confidence": 0.5378892898559571}]}, {"text": "AMRs are directed acyclic graphs, where leaves are labeled with concepts, internal nodes are labeled with variables representing instances of those concepts, and edges are labeled with roles that relate pairs of concepts.", "labels": [], "entities": []}, {"text": "For instance, the sentence The boy wants to go is represented as: Colons discriminate roles from concepts.", "labels": [], "entities": []}, {"text": "In this paper, :instance-of is our way of writing the slash (/) found in the AMR corpus.", "labels": [], "entities": [{"text": "AMR corpus", "start_pos": 77, "end_pos": 87, "type": "DATASET", "confidence": 0.899766594171524}]}, {"text": "Because AMR and English are highly cognate, the AMR-to-English generation problem might seem similar to previous natural language generation (NLG) problems such as bag generation, restoring order to unordered dependency trees) or generation from logical form).", "labels": [], "entities": [{"text": "AMR-to-English generation", "start_pos": 48, "end_pos": 73, "type": "TASK", "confidence": 0.8775554299354553}, {"text": "bag generation", "start_pos": 164, "end_pos": 178, "type": "TASK", "confidence": 0.7176928073167801}]}, {"text": "However, AMR's deeper logic provides a serious challenge for English realization.", "labels": [], "entities": [{"text": "English realization", "start_pos": 61, "end_pos": 80, "type": "TASK", "confidence": 0.7828164398670197}]}, {"text": "AMR also abstracts away details of time, number, and voice, which must be inserted.", "labels": [], "entities": [{"text": "AMR", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.6332875490188599}]}, {"text": "introduced Nitrogen, which used a precursor of AMR for generating English.", "labels": [], "entities": []}, {"text": "Recently, presented the first trained AMR-to-English generator.", "labels": [], "entities": [{"text": "AMR-to-English generator", "start_pos": 38, "end_pos": 62, "type": "TASK", "confidence": 0.8049079477787018}]}, {"text": "They generate spanning trees from AMR graphs and apply tree-to-string transducers to the trees to generate English.", "labels": [], "entities": []}, {"text": "We attack AMR-to-English generation using the tools of phrase-based machine translation (PBMT).", "labels": [], "entities": [{"text": "AMR-to-English generation", "start_pos": 10, "end_pos": 35, "type": "TASK", "confidence": 0.9764154255390167}, {"text": "phrase-based machine translation (PBMT)", "start_pos": 55, "end_pos": 94, "type": "TASK", "confidence": 0.7160119364658991}]}, {"text": "PBMT has already been applied to natural language generation from simple semantic structures (), but deep semantic representations such as AMR are more challenging to deal with.", "labels": [], "entities": [{"text": "natural language generation", "start_pos": 33, "end_pos": 60, "type": "TASK", "confidence": 0.7245579560597738}]}, {"text": "PBMT expects strings for its source and target languages, so we cannot work with AMR graphs as input.", "labels": [], "entities": [{"text": "PBMT", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.8475809693336487}]}, {"text": "Therefore, we develop a method that learns to linearize AMR graphs into AMR strings.", "labels": [], "entities": []}, {"text": "Our linearization strives to put AMR tokens roughly into English word order, making the transformation to English easier.", "labels": [], "entities": []}, {"text": "It may seem surprising that we ignore much of the structure of AMR, but we follow string-based statistical MT, which ignored much of the structure of language but nonetheless provided a strong baseline.", "labels": [], "entities": [{"text": "AMR", "start_pos": 63, "end_pos": 66, "type": "TASK", "confidence": 0.7800443768501282}, {"text": "MT", "start_pos": 107, "end_pos": 109, "type": "TASK", "confidence": 0.7923929691314697}]}, {"text": "shows our pipeline for generating English from AMR.", "labels": [], "entities": [{"text": "AMR", "start_pos": 47, "end_pos": 50, "type": "DATASET", "confidence": 0.8322381973266602}]}, {"text": "Our contributions are: 1.", "labels": [], "entities": []}, {"text": "We present a strong baseline method for AMRto-English generation.", "labels": [], "entities": [{"text": "AMRto-English generation", "start_pos": 40, "end_pos": 64, "type": "TASK", "confidence": 0.8101654648780823}]}, {"text": "2. We introduce a method that learns to linearize AMR tokens into an order resembling English.", "labels": [], "entities": []}, {"text": "3. We obtain a Bleu score of 26.8 on the standard AMR/English test set, which is 4.9 points higher than previous work.", "labels": [], "entities": [{"text": "Bleu score", "start_pos": 15, "end_pos": 25, "type": "METRIC", "confidence": 0.9862589538097382}, {"text": "AMR/English test set", "start_pos": 50, "end_pos": 70, "type": "DATASET", "confidence": 0.8915733098983765}]}], "datasetContent": [{"text": "We use AMR/English data from the AMR 1.0 corpus, 1 along with the provided train/development/test split.", "labels": [], "entities": [{"text": "AMR/English data", "start_pos": 7, "end_pos": 23, "type": "DATASET", "confidence": 0.7869101613759995}, {"text": "AMR 1.0 corpus", "start_pos": 33, "end_pos": 47, "type": "DATASET", "confidence": 0.9216084281603495}]}, {"text": "We implement the method of to construct alignments for the training set.", "labels": [], "entities": []}, {"text": "We train the linearization function introduced in Section 3 on the aligned training set and use it to re-linearize that training set, maintaining the alignment links.", "labels": [], "entities": []}, {"text": "This gives us aligned string-to-string training data for PBMT.", "labels": [], "entities": [{"text": "PBMT", "start_pos": 57, "end_pos": 61, "type": "TASK", "confidence": 0.5843695998191833}]}, {"text": "We use the same trained linearization function to linearize development and test AMRs.", "labels": [], "entities": [{"text": "AMRs", "start_pos": 81, "end_pos": 85, "type": "TASK", "confidence": 0.8997223377227783}]}, {"text": "To measure the quality of linearization, we make calculations on the development set, using alignments to references (these alignments are used only for this experiment, and not for decoding).", "labels": [], "entities": []}, {"text": "A good linearization function should: (a) reduce the number of crossings in the alignment links, and (b) correctly identify concepts to be dropped.", "labels": [], "entities": []}, {"text": "shows the total number of crossings and number of crossings between adjacent alignment links after linearizing development AMRs with the three methods introduced in Section 3.", "labels": [], "entities": [{"text": "AMRs", "start_pos": 123, "end_pos": 127, "type": "TASK", "confidence": 0.6140161752700806}]}, {"text": "Both advanced methods highly reduce the number of crossings.", "labels": [], "entities": []}, {"text": "The Classifier Method reduces the number of adjacent crossings much more than the Majority Method, helping to enhance locality.", "labels": [], "entities": []}, {"text": "End-to-end experiments show that the Classifier Method outperforms the Majority Method in improving Bleu score.", "labels": [], "entities": [{"text": "Bleu score", "start_pos": 100, "end_pos": 110, "type": "METRIC", "confidence": 0.9732307493686676}]}, {"text": "With respect to concept dropping, 97% of the concepts dropped by the Classifier Method are in fact not aligned, and the method correctly drops 87% of the unaligned concepts.", "labels": [], "entities": [{"text": "concept dropping", "start_pos": 16, "end_pos": 32, "type": "TASK", "confidence": 0.7135487943887711}]}, {"text": "Next, we use the Moses () system for our PBMT implementation.", "labels": [], "entities": []}, {"text": "Phrase extraction, limited to maximum phrase length 9, yields 1.2m phrase pairs.", "labels": [], "entities": [{"text": "Phrase extraction", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.8841121792793274}]}, {"text": "We use a 5-gram language model trained on 1.7b tokens of Gigaword English.", "labels": [], "entities": []}, {"text": "We use MERT for tuning, and we decode linearized AMRs into English with a maximum stack size of 1000.", "labels": [], "entities": [{"text": "MERT", "start_pos": 7, "end_pos": 11, "type": "METRIC", "confidence": 0.8537785410881042}]}, {"text": "We find that better linearization methods lead to better Bleu scores.", "labels": [], "entities": [{"text": "Bleu scores", "start_pos": 57, "end_pos": 68, "type": "METRIC", "confidence": 0.9725976884365082}]}, {"text": "The Majority Method outperforms Pre-order DFS by 3.1 Bleu on test data, and the Classifier Method adds another 1.2 Bleu.", "labels": [], "entities": []}, {"text": "We also find that steps of cleaning and specialized name/number/date generators significantly improve Bleu.", "labels": [], "entities": [{"text": "Bleu", "start_pos": 102, "end_pos": 106, "type": "METRIC", "confidence": 0.4934757947921753}]}, {"text": "Compared to) our best system achives 4.5 Bleu points improvement on dev and 4.9 points improvement on test data.", "labels": [], "entities": [{"text": "Bleu points improvement", "start_pos": 41, "end_pos": 64, "type": "METRIC", "confidence": 0.9473589857419332}]}], "tableCaptions": [{"text": " Table 1: Data for AMR-to-English generation.", "labels": [], "entities": [{"text": "AMR-to-English generation", "start_pos": 19, "end_pos": 44, "type": "TASK", "confidence": 0.9202525913715363}]}, {"text": " Table 2: Total alignment crossings, and crossings between ad-", "labels": [], "entities": []}, {"text": " Table 3: Results for AMR-to-English generation on develop-", "labels": [], "entities": [{"text": "AMR-to-English generation", "start_pos": 22, "end_pos": 47, "type": "TASK", "confidence": 0.9679155051708221}, {"text": "develop", "start_pos": 51, "end_pos": 58, "type": "DATASET", "confidence": 0.9792424440383911}]}]}