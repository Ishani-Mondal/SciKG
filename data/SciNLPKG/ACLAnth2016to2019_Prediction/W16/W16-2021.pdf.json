{"title": [{"text": "Inferring Morphotactics from Interlinear Glossed Text: Combining Clustering and Precision Grammars", "labels": [], "entities": []}], "abstractContent": [{"text": "In this paper I present a k-means clustering approach to inferring morphological position classes (morphotactics) from Interlinear Glossed Text (IGT), data collections available for some endangered and low-resource languages.", "labels": [], "entities": []}, {"text": "While the experiment is not restricted to low-resource languages, they are meant to be the targeted domain.", "labels": [], "entities": []}, {"text": "Specifically my approach is meant to be for field linguists who do not necessarily know how many position classes there are in the language they work with and what the position classes are, but have the expertise to evaluate different hypotheses.", "labels": [], "entities": []}, {"text": "It builds on an existing approach (Wax, 2014), but replaces the core heuristic with a clustering algorithm.", "labels": [], "entities": []}, {"text": "The results mainly illustrate two points.", "labels": [], "entities": []}, {"text": "First, they are largely negative, which shows that the baseline algorithm (summarized in the paper) uses a very predictive feature to determine whether affixes belong to the same position class, namely edge overlap in the affix graph.", "labels": [], "entities": []}, {"text": "At the same time, unlike the baseline method that relies entirely on a single feature, k-means clustering can account for different features and helps discover more morphological phenomena , e.g. circumfixation.", "labels": [], "entities": []}, {"text": "I conclude that unsuper-vised learning algorithms such as k-means clustering can in principle be used for morphotactics inference , though the algorithm should probably weigh certain features more than others.", "labels": [], "entities": [{"text": "morphotactics inference", "start_pos": 106, "end_pos": 129, "type": "TASK", "confidence": 0.7194869220256805}]}, {"text": "Most importantly, I conclude that clustering is a promising approach for diverse morphotactics and as such it can facilitate linguistic analysis of field languages.", "labels": [], "entities": []}], "introductionContent": [{"text": "Morphological analysis is a critical component in NLP systems for morphologically rich languages ().", "labels": [], "entities": [{"text": "Morphological analysis", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.9362487196922302}]}, {"text": "Yet, while automatic morphological analysis maybe well-developed for languages like English and Spanish, the list of these languages is rather short.", "labels": [], "entities": []}, {"text": "There are at least two reasons for that.", "labels": [], "entities": []}, {"text": "One is that high-resource languages offer big training corpora.", "labels": [], "entities": []}, {"text": "This makes the use of various machine learning algorithms easier.", "labels": [], "entities": []}, {"text": "Another reason is that many high-resource languages, most notably English, happen to feature fairly simple morphology.", "labels": [], "entities": []}, {"text": "A morphological analyzer fora language like English does not need to model complex morphotactics, the constraints on the ordering of the morphemes types.", "labels": [], "entities": []}, {"text": "While there are many systems which are capable of segmenting words into morphemes and some systems which include more sophisticated morphological analyzers and use supervised machine learning for some tasks (), there do not seem to be many systems out there which can actually infer morphotactics in an unsupervised fashion.", "labels": [], "entities": []}, {"text": "Yet many languages exhibit complex morphotactics.", "labels": [], "entities": []}, {"text": "Furthermore, most of the world's languages are low-resource, meaning that there are few digitized resources that can be used in computational projects.", "labels": [], "entities": []}, {"text": "Many are also understudied, meaning that the properties of the language including its morphotactics are not welldocumented or well-understood.", "labels": [], "entities": []}, {"text": "Documenting morphological rules of understudied languages which often also have endangered status is of critical importance for the purposes of both linguistic research and cultural diversity conservation efforts.", "labels": [], "entities": []}, {"text": "At the same time, the scarcity of data makes many modern learning approaches that rely on big data inapplicable in this domain.", "labels": [], "entities": []}, {"text": "However, field linguists who work on these languages have small sized but richly annotated data, Interlinear Glossed Text (IGT), and so the richness can be leveraged to compensate for the modest size of the corpora.", "labels": [], "entities": []}, {"text": "An example of IGT from Chintang [ctn] 1 is given below asThe younger brother took it to the river.'", "labels": [], "entities": [{"text": "IGT from Chintang [ctn] 1", "start_pos": 14, "end_pos": 39, "type": "DATASET", "confidence": 0.7166437123503003}]}, {"text": "( I take an existing approach to automatically extracting morphological rules from IGT as the baseline ( and present a k-means clustering approach to the same problem.", "labels": [], "entities": []}, {"text": "I evaluate the results by morphological parsing (analyzing a list of verbs by finding for each verb a sequence of morphological rule applications that would produce this form) on several languages from different language families, including some low-resource languages.", "labels": [], "entities": [{"text": "morphological parsing", "start_pos": 26, "end_pos": 47, "type": "TASK", "confidence": 0.7575413882732391}]}, {"text": "I show that grammars obtained using k-means are generally worse than the baseline though they can be on par with it in a particularly noisy setting.", "labels": [], "entities": []}, {"text": "K-means still strongly outperforms a grammar hand-built by language experts because automated processing ensures better recall.", "labels": [], "entities": [{"text": "recall", "start_pos": 120, "end_pos": 126, "type": "METRIC", "confidence": 0.9908846020698547}]}, {"text": "I notice that, unlike the baseline approach, k-means is capable of picking up non-canonical phenomena like circumfixation.", "labels": [], "entities": []}, {"text": "I conclude that unsupervised classification methods like k-means clustering can help the field linguists come up with more complete hypotheses about morphotactics (accounting for more affixes and more relationships between them) and also discover non-canonical morphological phenomena in their data.", "labels": [], "entities": []}], "datasetContent": [{"text": "For evaluation, I use automatically generated precision grammars, a type of digitized language resource.", "labels": [], "entities": []}, {"text": "A precision grammar consists of a lexicon and a hierarchy of lexical and phrasal rules written according to the HPSG theory of syntax (.", "labels": [], "entities": []}, {"text": "The term 'precision' is meant to emphasize that any parse or generation by the grammar will comply with the rules and will in that sense be linguistically sound, or precise.", "labels": [], "entities": [{"text": "precision", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9980252981185913}]}, {"text": "In combination with software such as the LKB system), precision grammars can generate syntactic trees of complete feature structures 3 along with semantic representations.", "labels": [], "entities": [{"text": "LKB system", "start_pos": 41, "end_pos": 51, "type": "DATASET", "confidence": 0.9491661787033081}]}, {"text": "Lexical morphological rules apply first to construct words, and then phrasal rules apply to construct sentences.", "labels": [], "entities": []}, {"text": "Such grammars are useful to evaluate the quality of linguistic analyses).", "labels": [], "entities": []}, {"text": "In particular, I used precision grammars to evaluate my results by parsing.", "labels": [], "entities": []}, {"text": "I used the Grammar Matrix customization system ( to compile precision grammars from the specifications which were output by either the baseline or by my k-means system.", "labels": [], "entities": []}, {"text": "In both cases, the morphotactics is represented internally as a directed acyclic graph (DAG) where nodes are affix types (position classes) and edges mean that one class serves as input to another.", "labels": [], "entities": []}, {"text": "Cycles are not allowed mainly because of the internal Grammar Matrix restrictions, though iterating position classes are indeed rare.", "labels": [], "entities": []}, {"text": "The DAG implementation is provided entirely by the customization system, as are all the other functional parts of the grammar.", "labels": [], "entities": []}, {"text": "The baseline and the k-means system supply only the specification for the DAG inform of nodes and edges.", "labels": [], "entities": []}, {"text": "Below area sample entry fora verb position class from a specification file () and the relevant snippet from the grammar itself, in HPSG-style type description language ()).", "labels": [], "entities": []}, {"text": "The customization system reads in the specification file and, in this case, it would create anode in the DAG that corresponds to verb-slot1 (verb position class 1) and an edge to it from the stems node (called simply 'verb' in the figure).", "labels": [], "entities": []}, {"text": "For clarity, the examples are from a toy English grammar.", "labels": [], "entities": []}, {"text": "The lexical rule which is illustrated will add a suffix ing to verbs to produce the participial form.", "labels": [], "entities": []}, {"text": "This way a string like walking will be parsed and a feature structure will be produced which will capture the fact that this is a non-finite verb form, for example.", "labels": [], "entities": []}, {"text": "It should be stated upfront that the results of this study seem most interesting if analyzed qualitatively, in terms of what kind of affixes get clustered together and whether this can be helpful to a filed linguist in anyway.", "labels": [], "entities": []}, {"text": "At the same time, it is appropriate to include quantitative results.", "labels": [], "entities": []}, {"text": "For this, I use morphological parsing.", "labels": [], "entities": [{"text": "morphological parsing", "start_pos": 16, "end_pos": 37, "type": "TASK", "confidence": 0.680126428604126}]}, {"text": "Morphological parsing is analyzing isolated words (e.g. extracted from a held-out test set) lexically, defaulting the phrase structure rules, in that each word (such as a verb) can be analyzed as a full sentence, provided there is a path in the morphotactic DAG that generates this word.", "labels": [], "entities": [{"text": "Morphological parsing", "start_pos": 0, "end_pos": 21, "type": "TASK", "confidence": 0.9487117528915405}]}, {"text": "This is an appropriate evaluation method given that labeled data for morphotactic inference virtually does not exist for most languages, be it high-resource or not.", "labels": [], "entities": []}, {"text": "I am assuming that a grammar which achieves better coverage on a held out dataset may better represent the real grammar of the language, especially if k is kept modest.", "labels": [], "entities": []}, {"text": "The Chintang Oracle grammar I also use indirectly, looking at its performance in terms of morphological parsing and comparing to both the baseline and the k-means systems.", "labels": [], "entities": [{"text": "Chintang Oracle grammar", "start_pos": 4, "end_pos": 27, "type": "DATASET", "confidence": 0.8709998528162638}]}, {"text": "All grammars, including the Oracle, were normalized with respect to the lexicon and only differ in morphological rules.", "labels": [], "entities": []}, {"text": "The test sets were filtered to just contain one instance of each verb.", "labels": [], "entities": []}, {"text": "As such, the evaluation does not take into account how frequent the verbs are.", "labels": [], "entities": []}, {"text": "The test sets for most languages are rather small (Chintang is the biggest with 708 unique verbs in the set).", "labels": [], "entities": []}, {"text": "This is a realistic setting for low-resource language research.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Morphological parsing results.", "labels": [], "entities": [{"text": "Morphological parsing", "start_pos": 10, "end_pos": 31, "type": "TASK", "confidence": 0.9233593940734863}]}]}