{"title": [{"text": "Chinese Grammatical Error Diagnosis Using Single Word Embedding", "labels": [], "entities": [{"text": "Chinese Grammatical Error Diagnosis", "start_pos": 0, "end_pos": 35, "type": "TASK", "confidence": 0.7782168537378311}]}], "abstractContent": [{"text": "Automatic grammatical error detection for Chinese has been a big challenge for NLP researchers.", "labels": [], "entities": [{"text": "grammatical error detection", "start_pos": 10, "end_pos": 37, "type": "TASK", "confidence": 0.6839228769143423}]}, {"text": "Due to the formal and strict grammar rules in Chinese, it is hard for foreign students to master Chinese.", "labels": [], "entities": []}, {"text": "A computer-assisted learning tool which can automatically detect and correct Chinese grammatical errors is necessary for those foreign students.", "labels": [], "entities": []}, {"text": "Some of the previous works have sought to identify Chinese grammatical errors using template-and learning-based methods.", "labels": [], "entities": [{"text": "identify Chinese grammatical errors", "start_pos": 42, "end_pos": 77, "type": "TASK", "confidence": 0.7658105939626694}]}, {"text": "In contrast, this study introduced convolutional neural network (CNN) and long-short term memory (LSTM) for the shared task of Chinese Grammatical Error Diagnosis (CGED).", "labels": [], "entities": [{"text": "long-short term memory (LSTM)", "start_pos": 74, "end_pos": 103, "type": "METRIC", "confidence": 0.7423360745112101}, {"text": "Chinese Grammatical Error Diagnosis (CGED)", "start_pos": 127, "end_pos": 169, "type": "TASK", "confidence": 0.7949711339814323}]}, {"text": "Different from traditional word-based embedding, single word embedding was used as input of CNN and LSTM.", "labels": [], "entities": [{"text": "CNN", "start_pos": 92, "end_pos": 95, "type": "DATASET", "confidence": 0.8747470378875732}]}, {"text": "The proposed single word embedding can capture both semantic and syntactic information to detect those four type grammatical error.", "labels": [], "entities": []}, {"text": "In experimental evaluation, the recall and f1-score of our submitted results Run1 of the TOCFL testing data ranked the fourth place in all submissions in detection-level.", "labels": [], "entities": [{"text": "recall", "start_pos": 32, "end_pos": 38, "type": "METRIC", "confidence": 0.999747097492218}, {"text": "f1-score", "start_pos": 43, "end_pos": 51, "type": "METRIC", "confidence": 0.977117121219635}, {"text": "TOCFL testing data", "start_pos": 89, "end_pos": 107, "type": "DATASET", "confidence": 0.8879867593447367}]}], "introductionContent": [{"text": "The growing global influence of China has prompted a surge of interest in learning Chinese as a foreign language (CFL) ( ).", "labels": [], "entities": [{"text": "learning Chinese as a foreign language (CFL)", "start_pos": 74, "end_pos": 118, "type": "TASK", "confidence": 0.7370802561442057}]}, {"text": "The number of commonly used Chinese characters are about 2000, but there area large number of corresponding vocabulary.", "labels": [], "entities": []}, {"text": "In this way, some same words may have different meanings because of different contexts and moods.", "labels": [], "entities": []}, {"text": "This has caused difficulties for foreigners to learn Chinese.", "labels": [], "entities": []}, {"text": "However, while many learning tools of computer-assisted have been developed for students of English as a Foreign Language (EFL), there is relatively little support for CFL learners.", "labels": [], "entities": []}, {"text": "Especially, these tools cannot automatically detect and correct Chinese grammatical errors.", "labels": [], "entities": []}, {"text": "For example, although Microsoft Word has been integrated with robust English spelling and grammar checking for many years, the tools for Chinese are still primitive ( ).", "labels": [], "entities": [{"text": "English spelling and grammar checking", "start_pos": 69, "end_pos": 106, "type": "TASK", "confidence": 0.6269702911376953}]}, {"text": "The aim of Chinese Grammatical Error Diagnosis (CGED) shared task is to develop computer-assisted tools to help detect four types of grammatical errors in the written Chinese, including missing word (M), redundant word (R), word ordering error (W) and word selection error (S).", "labels": [], "entities": [{"text": "Chinese Grammatical Error Diagnosis (CGED)", "start_pos": 11, "end_pos": 53, "type": "TASK", "confidence": 0.8278955348900386}, {"text": "word ordering error (W)", "start_pos": 224, "end_pos": 247, "type": "METRIC", "confidence": 0.6871409515539805}, {"text": "word selection error (S)", "start_pos": 252, "end_pos": 276, "type": "METRIC", "confidence": 0.7533433785041174}]}, {"text": "The shared task is divided into three levels, including detection-, identification-and position-level.", "labels": [], "entities": []}, {"text": "Detection-level task can be considered as a binary classification of a given sentence, i.e., corrector incorrect should be exactly as same as the gold standard.", "labels": [], "entities": [{"text": "corrector incorrect", "start_pos": 93, "end_pos": 112, "type": "METRIC", "confidence": 0.9200766086578369}]}, {"text": "All error types will be treated as incorrect.", "labels": [], "entities": []}, {"text": "Identification-level task could be considered as a multi-label classification task.", "labels": [], "entities": [{"text": "multi-label classification task", "start_pos": 51, "end_pos": 82, "type": "TASK", "confidence": 0.7691973547140757}]}, {"text": "In addition to the correct instance, all error types should be clearly identified.", "labels": [], "entities": []}, {"text": "This level identified the error types for the wrong sentence.", "labels": [], "entities": []}, {"text": "Besides identifying the error types, the position-level also judges the positions of erroneous range.", "labels": [], "entities": []}, {"text": "Some of the previous works have sought to identify Chinese grammatical errors using templateand learning-based methods.", "labels": [], "entities": [{"text": "identify Chinese grammatical errors", "start_pos": 42, "end_pos": 77, "type": "TASK", "confidence": 0.73394725471735}]}, {"text": "proposed a combination of relative position and analytic template language model to detect Chinese errors written by American learners.", "labels": [], "entities": []}, {"text": "used simplified Chinese corpus to study word ordering errors (W) in Chinese and proposed syntactic features, external corpus features and perturbation features for W detection.", "labels": [], "entities": [{"text": "word ordering errors (W)", "start_pos": 40, "end_pos": 64, "type": "TASK", "confidence": 0.716537411014239}, {"text": "W detection", "start_pos": 164, "end_pos": 175, "type": "TASK", "confidence": 0.9432465434074402}]}, {"text": "detected and corrected word ordering errors by using conditional random field (CRF) and support vector machine (SVM) together with frequency learning from a large n-gram corpus.", "labels": [], "entities": [{"text": "word ordering errors", "start_pos": 23, "end_pos": 43, "type": "TASK", "confidence": 0.7180528144041697}]}, {"text": "used frequent n-grams and news corpus as a reference corpus to detect errors in the written by CFL learners.", "labels": [], "entities": []}, {"text": "used conditional random fields based on word attributes and grammar rules to detect Chinese syntax errors.", "labels": [], "entities": []}, {"text": "However, there are several limitations of the existing methods, these methods on the one hand only consider part of the grammar rules, and the other hand only consider the order of the word or relationship.", "labels": [], "entities": []}, {"text": "They didn't consider the semantic relationship between words and the flexible expression and irregular grammar in Chinese.", "labels": [], "entities": []}, {"text": "In this paper, we introduced convolutional neural network (CNN) and long-short term memory (LSTM) for the task of Chinese Grammatical Error Diagnosis.", "labels": [], "entities": [{"text": "long-short term memory (LSTM)", "start_pos": 68, "end_pos": 97, "type": "METRIC", "confidence": 0.7499164690574011}, {"text": "Chinese Grammatical Error Diagnosis", "start_pos": 114, "end_pos": 149, "type": "TASK", "confidence": 0.8633295446634293}]}, {"text": "In contrast of traditional word-based embedding (, single word embedding was used as input of CNN and LSTM, which is similar to character-level embedding in English.", "labels": [], "entities": [{"text": "CNN", "start_pos": 94, "end_pos": 97, "type": "DATASET", "confidence": 0.8963361978530884}]}, {"text": "The proposed single word embedding can capture both semantic and syntactic information to detect those four type grammatical error.", "labels": [], "entities": []}, {"text": "Then, the single word vectors were used to establish the sentence representation for detection-level and identificationlevel tasks.", "labels": [], "entities": []}, {"text": "In position-level, this paper also used single word embedding as input feature to train a multi-class support vector machine (SVM) to identify the error type of each word.", "labels": [], "entities": []}, {"text": "The recall and f1-score of the submitted results Run1 of the TOCFL testing data ranked the fourth place in all submissions in detection-level.", "labels": [], "entities": [{"text": "recall", "start_pos": 4, "end_pos": 10, "type": "METRIC", "confidence": 0.9997022747993469}, {"text": "f1-score", "start_pos": 15, "end_pos": 23, "type": "METRIC", "confidence": 0.9781067371368408}, {"text": "TOCFL testing data", "start_pos": 61, "end_pos": 79, "type": "DATASET", "confidence": 0.9197959701220194}]}, {"text": "In identification-level, the recall score also ranked in the fourth place.", "labels": [], "entities": [{"text": "identification-level", "start_pos": 3, "end_pos": 23, "type": "TASK", "confidence": 0.8698974251747131}, {"text": "recall score", "start_pos": 29, "end_pos": 41, "type": "METRIC", "confidence": 0.9811815023422241}]}, {"text": "The remainder of this paper is organized as follows.", "labels": [], "entities": []}, {"text": "Section 2 describes the learning method that used for Chinese grammatical error diagnosis.", "labels": [], "entities": [{"text": "Chinese grammatical error diagnosis", "start_pos": 54, "end_pos": 89, "type": "TASK", "confidence": 0.8406390249729156}]}, {"text": "Section 3 shows the experimental results.", "labels": [], "entities": []}, {"text": "Conclusions are drawn in section 4.", "labels": [], "entities": []}], "datasetContent": [{"text": "A total of 15 teams participated in the sharing of tasks, nine teams submitted the results of the operation in the final.", "labels": [], "entities": []}, {"text": "For TOCFL training set, only 5 teams submitted the results of the operation.", "labels": [], "entities": [{"text": "TOCFL training set", "start_pos": 4, "end_pos": 22, "type": "DATASET", "confidence": 0.6612013479073843}]}, {"text": "For the HSK test set, 9 teams have submitted the results of the operation.", "labels": [], "entities": [{"text": "HSK test set", "start_pos": 8, "end_pos": 20, "type": "DATASET", "confidence": 0.8428331613540649}]}, {"text": "We have submitted three runs of results for both test sets.", "labels": [], "entities": []}, {"text": "shows the false positive rate.", "labels": [], "entities": [{"text": "false positive rate", "start_pos": 10, "end_pos": 29, "type": "METRIC", "confidence": 0.9096760948499044}]}, {"text": "show the formal run results in detection-level, identification-level, and position-level respectively.", "labels": [], "entities": []}, {"text": "As shown in, the accuracy of the following two levels is reduced due to the high false positives.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 17, "end_pos": 25, "type": "METRIC", "confidence": 0.9996451139450073}]}, {"text": "The results of Run1 and Run2 shows that the performance of word vectors trained by word2vec are better than that by fastText, since the fastText model makes the distance between similar words smaller.", "labels": [], "entities": []}, {"text": "For example, the meaning of \"trading\" (\u8d38\u6613) is close to the \"transaction\" (\u4ea4\u6613) in Chinese, and word2vec can reflect this relationship.", "labels": [], "entities": []}, {"text": "However, in the fastText, \"trading\" (\u8d38\u6613) is even more closer to \"trade laws\" (\u8d38\u6613\u6cd5), which makes word vector by fastText cannot accurately reflect the sentence characteristics.", "labels": [], "entities": []}, {"text": "Similarly, by comparing the results of Run1 and Run2, we can find that the classification performance of LSTM is better than CNN.", "labels": [], "entities": [{"text": "Run1", "start_pos": 39, "end_pos": 43, "type": "DATASET", "confidence": 0.912227988243103}, {"text": "Run2", "start_pos": 48, "end_pos": 52, "type": "DATASET", "confidence": 0.9067626595497131}, {"text": "CNN", "start_pos": 125, "end_pos": 128, "type": "METRIC", "confidence": 0.5345195531845093}]}, {"text": "Although CNN considers the local characteristics of the sentence, which makes it easy to high degree of similarity between the two sentences, LSTM can consider the relationship between the contexts of the sentence, which is particularly important in Chinese.", "labels": [], "entities": []}, {"text": "Therefore, LSTM can capture the logical relationship between the sentences, e.g. cause and contrast relationship, etc.", "labels": [], "entities": []}, {"text": "Since the number of sentence in different label (correct and incorrect) is unbalanced, which will impact the result in all detection-, identification-and position-level.", "labels": [], "entities": []}, {"text": "Hence, the wrong sentences are the majority in testing date.", "labels": [], "entities": []}, {"text": "If all the sentences in the testing set are classified as wrong, the learning model will get high accuracy, precision, recall and f1-score, and even a higher false positive rate.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 98, "end_pos": 106, "type": "METRIC", "confidence": 0.9995606541633606}, {"text": "precision", "start_pos": 108, "end_pos": 117, "type": "METRIC", "confidence": 0.9997826218605042}, {"text": "recall", "start_pos": 119, "end_pos": 125, "type": "METRIC", "confidence": 0.9997358918190002}, {"text": "f1-score", "start_pos": 130, "end_pos": 138, "type": "METRIC", "confidence": 0.9632951021194458}]}, {"text": "Two Chinese corpus are given in this shared task: TOCFL and HSK.", "labels": [], "entities": [{"text": "TOCFL", "start_pos": 50, "end_pos": 55, "type": "METRIC", "confidence": 0.6507396697998047}]}, {"text": "TOCFL is the traditional Chinese training set, and HSK is the simplified Chinese training set.", "labels": [], "entities": [{"text": "TOCFL", "start_pos": 0, "end_pos": 5, "type": "METRIC", "confidence": 0.588703989982605}, {"text": "HSK", "start_pos": 51, "end_pos": 54, "type": "METRIC", "confidence": 0.6749211549758911}]}, {"text": "Apart from the difference between traditional and simplified, there is almost no difference of grammar and expression.", "labels": [], "entities": []}, {"text": "In the training set, each id corresponds to two sentences, including a wrong sentence, and a corrected formation of this sentence.", "labels": [], "entities": []}, {"text": "The error type, as well as the location of the error range are also provided.", "labels": [], "entities": []}, {"text": "Each wrong sentence may have one error type, or more.", "labels": [], "entities": []}, {"text": "These data sets were preprocessed to extract the single words, the error types and the error positions.", "labels": [], "entities": []}, {"text": "The TOCFL corpus consists of 10693 training texts and 3528 testing texts.", "labels": [], "entities": [{"text": "TOCFL corpus", "start_pos": 4, "end_pos": 16, "type": "DATASET", "confidence": 0.7784063220024109}]}, {"text": "Similarly, the HSK corpus consists of 10072 training texts and 3011 testing texts.", "labels": [], "entities": [{"text": "HSK corpus", "start_pos": 15, "end_pos": 25, "type": "DATASET", "confidence": 0.8740535974502563}]}], "tableCaptions": [{"text": " Table 1: The cross-validation results of different methods using word2vec embedding", "labels": [], "entities": []}, {"text": " Table 2: The false positive rate results of different methods.", "labels": [], "entities": [{"text": "false positive rate", "start_pos": 14, "end_pos": 33, "type": "METRIC", "confidence": 0.8905522425969442}]}]}