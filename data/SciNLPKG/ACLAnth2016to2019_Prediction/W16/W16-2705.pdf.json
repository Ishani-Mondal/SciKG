{"title": [{"text": "Spanish NER with Word Representations and Conditional Random Fields", "labels": [], "entities": [{"text": "Spanish NER", "start_pos": 0, "end_pos": 11, "type": "DATASET", "confidence": 0.7517740726470947}]}], "abstractContent": [{"text": "Word Representations such as word em-beddings have been shown to significantly improve (semi-)supervised NER for the English language.", "labels": [], "entities": [{"text": "Word Representations", "start_pos": 0, "end_pos": 20, "type": "TASK", "confidence": 0.6182295978069305}, {"text": "NER", "start_pos": 105, "end_pos": 108, "type": "TASK", "confidence": 0.9177046418190002}]}, {"text": "In this work we investigate whether word representations can also boost (semi-)supervised NER in Spanish.", "labels": [], "entities": []}, {"text": "To do so, we use word representations as additional features in a linear chain Conditional Random Field (CRF) classifier.", "labels": [], "entities": []}, {"text": "Experimental results (82.44 F-score on the CoNLL-2002 corpus) show that our approach is comparable to some state-of-the-art Deep Learning approaches for Spanish, in particular when using cross-lingual Word Representations.", "labels": [], "entities": [{"text": "F-score", "start_pos": 28, "end_pos": 35, "type": "METRIC", "confidence": 0.9904677271842957}, {"text": "CoNLL-2002 corpus", "start_pos": 43, "end_pos": 60, "type": "DATASET", "confidence": 0.971981555223465}, {"text": "cross-lingual Word Representations", "start_pos": 187, "end_pos": 221, "type": "TASK", "confidence": 0.6178047955036163}]}], "introductionContent": [{"text": "Supervised NER models require large amounts of (manually) labeled data to achieve good performance, data that often is hard to acquire or generate.", "labels": [], "entities": [{"text": "NER", "start_pos": 11, "end_pos": 14, "type": "TASK", "confidence": 0.9599846601486206}]}, {"text": "However, it is possible to take advantage of unlabeled data to learn word representations to enrich and boost supervised NER models learned over small gold standards.", "labels": [], "entities": [{"text": "NER", "start_pos": 121, "end_pos": 124, "type": "TASK", "confidence": 0.9480961561203003}]}, {"text": "In supervised NER the common practice has been to use domain-specific lexicon (list of words related with named entity types) ().", "labels": [], "entities": []}, {"text": "More recently, it has been shown that supervised NER can be boosted via specific word features induced from very large unsupervised word representations (, and in particular, from (i) very large word clusters (, and (ii) very large word embeddings; dos.", "labels": [], "entities": [{"text": "NER", "start_pos": 49, "end_pos": 52, "type": "TASK", "confidence": 0.84706050157547}]}, {"text": "For English NER, ( show that (large) word embeddings yield better results than clustering.", "labels": [], "entities": []}, {"text": "However, when combined and fed as features to linear chain conditional random field (CRF) sequence classifiers, they yield models comparable to state-of-the-art deep learning approaches, but with the added value of a very large coverage (.", "labels": [], "entities": []}, {"text": "In this paper we investigate whether these techniques can be successfully applied to NER in Spanish.", "labels": [], "entities": [{"text": "NER in Spanish", "start_pos": 85, "end_pos": 99, "type": "TASK", "confidence": 0.8834449251492819}]}, {"text": "In order to do so, we follow's approach combining probabilistic graphical models learned from the CoNLL 2002 corpus, with word representations learned from large unlabeled Spanish corpora, while exploring the optimal setting and feature combinations that match state-of-the-art algorithms for NER in Spanish.", "labels": [], "entities": [{"text": "CoNLL 2002 corpus", "start_pos": 98, "end_pos": 115, "type": "DATASET", "confidence": 0.953457772731781}]}, {"text": "The paper is organized as follows.", "labels": [], "entities": []}, {"text": "In Section 2, we provide a review of Spanish NER, and NER using word representations as features.", "labels": [], "entities": [{"text": "Spanish NER", "start_pos": 37, "end_pos": 48, "type": "DATASET", "confidence": 0.7170085906982422}]}, {"text": "Section 3 describes the structure of the word representations used.", "labels": [], "entities": []}, {"text": "Section 4 shows our experimental setting and results.", "labels": [], "entities": []}, {"text": "Section 5 presents our final remarks.", "labels": [], "entities": []}], "datasetContent": [{"text": "Unlike previous approaches, our work focuses on using word representations as features for supervised NER for Spanish.", "labels": [], "entities": []}, {"text": "We do it within a probabilistic grahical model framework: Conditional Random Fields (CRFs).", "labels": [], "entities": []}, {"text": "CRFs allows us to intensively explore available resources (unlabeled data) within a simple graphical model setting (in contrast to complex Deep Learning approaches).", "labels": [], "entities": []}, {"text": "We trained our (enriched) model over the (Spanish) CoNLL 2002 corpus, and built our Word Representations over, on the one hand, the Spanish Billion Corpus, and on the other hand, English Wikipedia.", "labels": [], "entities": [{"text": "CoNLL 2002 corpus", "start_pos": 51, "end_pos": 68, "type": "DATASET", "confidence": 0.8429368734359741}, {"text": "Spanish Billion Corpus", "start_pos": 132, "end_pos": 154, "type": "DATASET", "confidence": 0.9166924357414246}, {"text": "English Wikipedia", "start_pos": 179, "end_pos": 196, "type": "DATASET", "confidence": 0.9019268453121185}]}, {"text": "For Spanish this is a novel approach.", "labels": [], "entities": []}, {"text": "The experimental results show it achieves competitive performance w.r.t. the current (Deep learningdriven) state-of-the-art for Spanish NER, in particular when using cross-or multi-lingual Word Representations.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Entities in CoNLL-2002 (Spanish).", "labels": [], "entities": [{"text": "CoNLL-2002", "start_pos": 22, "end_pos": 32, "type": "DATASET", "confidence": 0.7624503374099731}]}, {"text": " Table 2: Brown cluster computed from SBW.", "labels": [], "entities": [{"text": "SBW", "start_pos": 38, "end_pos": 41, "type": "DATASET", "confidence": 0.7909995317459106}]}, {"text": " Table 3: Binarized embeddings from SBW for  word \"equipo\".", "labels": [], "entities": []}, {"text": " Table 4: Clustering embeddings from SBW for  word \"Maria\".", "labels": [], "entities": []}, {"text": " Table 5: CoNLL-2002 Spanish Prototypes.", "labels": [], "entities": [{"text": "CoNLL-2002 Spanish Prototypes", "start_pos": 10, "end_pos": 39, "type": "DATASET", "confidence": 0.9080156683921814}]}]}