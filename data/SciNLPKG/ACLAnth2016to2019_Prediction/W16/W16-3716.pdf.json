{"title": [{"text": "Query Translation for Cross-Language Information Retrieval using Multilingual Word Clusters", "labels": [], "entities": [{"text": "Query Translation", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.7513189017772675}, {"text": "Cross-Language Information Retrieval", "start_pos": 22, "end_pos": 58, "type": "TASK", "confidence": 0.7485165397326151}]}], "abstractContent": [{"text": "In Cross-Language Information Retrieval, finding the appropriate translation of the source language query has always been a difficult problem to solve.", "labels": [], "entities": [{"text": "Cross-Language Information Retrieval", "start_pos": 3, "end_pos": 39, "type": "TASK", "confidence": 0.8230430285135905}]}, {"text": "We propose a technique towards solving this problem with the help of multilingual word clusters obtained from multilingual word embeddings.", "labels": [], "entities": []}, {"text": "We use word embeddings of the languages projected to a common vector space on which a community-detection algorithm is applied to find clusters such that words that represent the same concept from different languages fall in the same group.", "labels": [], "entities": []}, {"text": "We utilize these multilingual word clusters to perform query translation for Cross-Language Information Retrieval for three languages-English, Hindi and Bengali.", "labels": [], "entities": [{"text": "query translation", "start_pos": 55, "end_pos": 72, "type": "TASK", "confidence": 0.7640975713729858}, {"text": "Cross-Language Information Retrieval", "start_pos": 77, "end_pos": 113, "type": "TASK", "confidence": 0.757893959681193}]}, {"text": "We have experimented with the FIRE 2012 and Wikipedia datasets and have shown improvements over several standard methods like dictionary-based method, a transliteration-based model and Google Translate.", "labels": [], "entities": [{"text": "FIRE 2012", "start_pos": 30, "end_pos": 39, "type": "DATASET", "confidence": 0.9421483278274536}, {"text": "Wikipedia datasets", "start_pos": 44, "end_pos": 62, "type": "DATASET", "confidence": 0.8365778028964996}]}], "introductionContent": [{"text": "With the advancement of the Web and availability of multilingual contents, searching over the Web is not limited only to one's native language but is extended to other languages as well.", "labels": [], "entities": []}, {"text": "Relevant and adequate information may not always be available in only one particular language but maybe spread across other languages.", "labels": [], "entities": []}, {"text": "This gives rise to the necessity of Cross-Language Information Retrieval (CLIR, where only two languages are involved) and Multilingual Information Retrieval (MLIR, where more than two languages are involved), where the query and the documents do not belong to a single language only.", "labels": [], "entities": [{"text": "Cross-Language Information Retrieval", "start_pos": 36, "end_pos": 72, "type": "TASK", "confidence": 0.6111140648523966}, {"text": "Multilingual Information Retrieval", "start_pos": 123, "end_pos": 157, "type": "TASK", "confidence": 0.6665505369504293}]}, {"text": "Specifically, in CLIR, the user query is in a language different than the collection.", "labels": [], "entities": []}, {"text": "Since the language of the query is different from the language of the documents in CLIR and MLIR, a translation phase is necessary.", "labels": [], "entities": [{"text": "MLIR", "start_pos": 92, "end_pos": 96, "type": "DATASET", "confidence": 0.7401283383369446}]}, {"text": "Translating documents is a tedious task.", "labels": [], "entities": [{"text": "Translating documents", "start_pos": 0, "end_pos": 21, "type": "TASK", "confidence": 0.9158679246902466}]}, {"text": "So the general standard is to translate the query and we follow the query translation approach for CLIR.", "labels": [], "entities": [{"text": "query translation", "start_pos": 68, "end_pos": 85, "type": "TASK", "confidence": 0.7090412974357605}, {"text": "CLIR", "start_pos": 99, "end_pos": 103, "type": "DATASET", "confidence": 0.8428075909614563}]}, {"text": "Common or popular approaches for query translation include, but are not limited to, leveraging bilingual or multilingual dictionaries, Statistical Machine Translation (SMT) systems, transliteration based models, graph-based models and online translation systems like Bing and Google Translate.", "labels": [], "entities": [{"text": "query translation", "start_pos": 33, "end_pos": 50, "type": "TASK", "confidence": 0.7843144834041595}, {"text": "Statistical Machine Translation (SMT)", "start_pos": 135, "end_pos": 172, "type": "TASK", "confidence": 0.7840974032878876}]}, {"text": "Each of the approaches have their own advantages and disadvantages.", "labels": [], "entities": []}, {"text": "For instance, SMTs require parallel corpus and for languages such as Indian languages where such resources are scarce, SMTs are not very suitable.", "labels": [], "entities": [{"text": "SMTs", "start_pos": 14, "end_pos": 18, "type": "TASK", "confidence": 0.9896920323371887}, {"text": "SMTs", "start_pos": 119, "end_pos": 123, "type": "TASK", "confidence": 0.9822089076042175}]}, {"text": "The dictionary based approaches require substantial word pair translations and suffer from coverage issues and data sparsity problems.", "labels": [], "entities": [{"text": "word pair translations", "start_pos": 52, "end_pos": 74, "type": "TASK", "confidence": 0.6388392349084219}]}, {"text": "We study the effectiveness of word embeddings in such a scenario where we want to have good quality translations that can improve CLIR performance in spite of having a scarcity in data-aligned resources.", "labels": [], "entities": []}, {"text": "Representing words using low dimensional vectors, called word embeddings, are now being widely used in many Natural Language Processing tasks.", "labels": [], "entities": [{"text": "Natural Language Processing tasks", "start_pos": 108, "end_pos": 141, "type": "TASK", "confidence": 0.6883108988404274}]}, {"text": "Each dimension of the vector represents a latent feature capturing useful properties.", "labels": [], "entities": []}, {"text": "It has been seen that in the distributional space defined by the vector dimensions, syntactically and semantically similar words are close to each other.", "labels": [], "entities": []}, {"text": "In the multilingual space, the objective is to have similar representations of similar words across different languages.", "labels": [], "entities": []}, {"text": "However, using the translations obtained from multilingual word embeddings directly has some drawbacks -words that are not much relevant to the source language word, may also come up as a translation.", "labels": [], "entities": []}, {"text": "For instance, for the word \"desha\" (meaning, country) in Hindi, although correct translations like \"country\" and \"democracy\" were provided, irrelevant words like \"aspiration\" and \"kind\" also showed up as potential translations.", "labels": [], "entities": []}, {"text": "Inclusion of such non-related words in a query greatly harms the IR performance.", "labels": [], "entities": [{"text": "IR", "start_pos": 65, "end_pos": 67, "type": "TASK", "confidence": 0.9938527345657349}]}, {"text": "To address this problem, we propose to use multilingual clustering.", "labels": [], "entities": []}, {"text": "In multilingual clustering, words from the same as well as across language, that more likely to represent similar concepts, fall in the same group.", "labels": [], "entities": []}, {"text": "We use the multilingual embeddings to build these clusters.", "labels": [], "entities": []}, {"text": "When multilingual clusters were used, candidate English translations besides \"country\" and \"democracy\" for our running example \"desha\" were \"nation\" and \"cities\".", "labels": [], "entities": []}, {"text": "Our proposed method has shown significant improvements over dictionary-based method, a transliteration-based model and Google Translate.", "labels": [], "entities": []}, {"text": "The rest of the paper is organized as follows: Section 2 discusses recent work in the fields of CrossLanguage Information Retrieval and Word Embeddinggs.", "labels": [], "entities": [{"text": "CrossLanguage Information Retrieval", "start_pos": 96, "end_pos": 131, "type": "TASK", "confidence": 0.6062808434168497}]}, {"text": "In Section 3, we describe our proposed approach.", "labels": [], "entities": []}, {"text": "The experimental settings and results have been covered in Section 4.", "labels": [], "entities": []}, {"text": "Finally, we conclude in Section 5.", "labels": [], "entities": []}], "datasetContent": [{"text": "For obtaining multilingual word embeddings, we use two different approaches requiring two kinds of corpora: one approach requires comparable monolingual corpora for each of the three languages (English, Bengali and Hindi) and dictionaries containing Hindi-English and Bengali-English translations.", "labels": [], "entities": []}, {"text": "The other approach requires document-aligned corpora for the three languages.", "labels": [], "entities": []}, {"text": "The dataset details are as follows : \u2022 Comparable Corpora : We have used FIRE (Forum for Information Retrieval Evaluation, developed as a South-Asian counterpart of CLEF, TREC, NTCIR) 2012 dataset 1 . The documents were obtained from the newspapers, 'The Telegraph' and 'BDNews24' for English; 'Amar Ujala' and 'Navbharat Times' for Hindi; 'Anandabazar Patrika' and 'BDNews24' for Bengali.", "labels": [], "entities": [{"text": "FIRE", "start_pos": 73, "end_pos": 77, "type": "METRIC", "confidence": 0.9734489917755127}, {"text": "Information Retrieval Evaluation", "start_pos": 89, "end_pos": 121, "type": "TASK", "confidence": 0.7642556230227152}, {"text": "NTCIR) 2012 dataset", "start_pos": 177, "end_pos": 196, "type": "DATASET", "confidence": 0.7979945540428162}, {"text": "The Telegraph", "start_pos": 251, "end_pos": 264, "type": "DATASET", "confidence": 0.9564439654350281}]}, {"text": "There were 1,427,986 English; 1,164,526 Hindi and 500,122 Bengali documents.", "labels": [], "entities": []}, {"text": "\u2022 Document-Aligned Corpora: We have used the Wikipedia dumps 2 available for download for each of the three languages, English, Bengali and Hindi.", "labels": [], "entities": []}, {"text": "In order to get the cross-lingual articles, we made use of the inter-wiki links that exist in the corresponding Wikipedia pages.", "labels": [], "entities": []}, {"text": "There were 55,949 EnglishHindi pages; 34,234 English-Bengali pages and 12,324 English-Bengali-Hindi pages.", "labels": [], "entities": []}, {"text": "\u2022 Cross-Language Information Retrieval: We used the FIRE 2012 queries for Hindi and Bengali for Hindi to English and Bengali to English CLIR.", "labels": [], "entities": [{"text": "Cross-Language Information Retrieval", "start_pos": 2, "end_pos": 38, "type": "TASK", "confidence": 0.7779093186060587}, {"text": "FIRE 2012 queries", "start_pos": 52, "end_pos": 69, "type": "DATASET", "confidence": 0.9613425135612488}]}, {"text": "There were 50 queries with topics numbered from 176-225.", "labels": [], "entities": []}, {"text": "We used the title fields for querying.", "labels": [], "entities": []}, {"text": "\u2022 Other resources: We used a Hindi-English dictionary 3 that had 26,485 translation-pairs, BengaliEnglish dictionary 4 containing 29,890 translation-pairs, Stopword lists 5 and an English Named-Entity Recognizer . Louvain Method for community detection algorithm () was used for clustering.", "labels": [], "entities": [{"text": "community detection", "start_pos": 233, "end_pos": 252, "type": "TASK", "confidence": 0.7103805541992188}]}, {"text": "We perform the basic pre-processing tasks on the documents, like removing the html tags, sentence boundaries and reducing all the letters to lowercase (for English).", "labels": [], "entities": []}, {"text": "We obtain word vectors from this document set.", "labels": [], "entities": []}, {"text": "We count the term frequencies of the words and remove stopwords, top 50 most frequently occurring words and words below frequency of 20 (for Wikipedia dataset), 50 (for English and Bengali  FIRE dataset) and 20 (for Hindi FIRE dataset).", "labels": [], "entities": [{"text": "Wikipedia dataset", "start_pos": 141, "end_pos": 158, "type": "DATASET", "confidence": 0.9566827416419983}, {"text": "FIRE dataset", "start_pos": 222, "end_pos": 234, "type": "DATASET", "confidence": 0.7191793769598007}]}, {"text": "We choose these numbers so that we have balanced number of words for the three languages.", "labels": [], "entities": []}, {"text": "We then obtain the embeddings of the remaining words.", "labels": [], "entities": []}, {"text": "We used Apache Solr version 4.1 as the monolingual retrieval engine.", "labels": [], "entities": []}, {"text": "The similarity score between the query and the documents is the default TF-IDF Similarity . The human relevance judgments were available from FIRE.", "labels": [], "entities": [{"text": "similarity score", "start_pos": 4, "end_pos": 20, "type": "METRIC", "confidence": 0.9674660861492157}, {"text": "TF-IDF Similarity", "start_pos": 72, "end_pos": 89, "type": "METRIC", "confidence": 0.6990995407104492}, {"text": "FIRE", "start_pos": 142, "end_pos": 146, "type": "DATASET", "confidence": 0.9646205902099609}]}, {"text": "Each query had about 500 documents that were manually judged as relevant or non-relevant (0).", "labels": [], "entities": []}, {"text": "We then used the trec-eval tool 10 for finding the Mean Average Precision (MAP), Precision at 5 (P5) and Precision at 10 (P10).", "labels": [], "entities": [{"text": "Mean Average Precision (MAP)", "start_pos": 51, "end_pos": 79, "type": "METRIC", "confidence": 0.9657586812973022}, {"text": "Precision", "start_pos": 81, "end_pos": 90, "type": "METRIC", "confidence": 0.9446040391921997}, {"text": "Precision", "start_pos": 105, "end_pos": 114, "type": "METRIC", "confidence": 0.8078234791755676}]}], "tableCaptions": [{"text": " Table 1: Statistics of the number of words (vertices) used to create word clusters, separately for FIRE  and Wikipedia Datasets  Pair  Multi  English-Hindi  English-Bengali  English-Hindi-Bengali  English Hindi English Bengali English Hindi Bengali  FIRE  129,688 84,773 129,688 93,057 129,688 84,773 93,057  Wikipedia 106,746 35,361 77,302  24,794  50,620 16,534 13,490", "labels": [], "entities": [{"text": "FIRE", "start_pos": 100, "end_pos": 104, "type": "DATASET", "confidence": 0.8728839755058289}, {"text": "Wikipedia Datasets  Pair  Multi  English-Hindi  English-Bengali  English-Hindi-Bengali  English Hindi English Bengali English Hindi Bengali  FIRE  129,688 84,773 129,688 93,057 129,688 84,773 93,057  Wikipedia 106,746", "start_pos": 110, "end_pos": 327, "type": "DATASET", "confidence": 0.9154902224739393}]}, {"text": " Table 2: Statistics of the Bilingual and Multilingual Clusters  # Levels  # Clusters  English-Hindi English-Bengali English-Hindi English-Bengali", "labels": [], "entities": []}, {"text": " Table 3: Performance of the Baseline Approaches for Hindi to English and Bengali to English CLIR on  FIRE 2012 Dataset  Hindi to English CLIR Bengali to English CLIR  MAP  P5  P10  MAP  P5  P10  English Monolingual  0.3218  0.56  0.522 0.3218 0.56  0.522", "labels": [], "entities": [{"text": "FIRE 2012 Dataset  Hindi to English CLIR Bengali to English CLIR  MAP  P5  P10  MAP  P5  P10  English Monolingual  0.3218  0.56  0.522 0.3218 0.56  0.522", "start_pos": 102, "end_pos": 255, "type": "DATASET", "confidence": 0.9200389003753662}]}, {"text": " Table 4: Performance of the Proposed Cluster-based Approach for Hindi to English and Bengali to  English CLIR on FIRE 2012 Dataset", "labels": [], "entities": [{"text": "FIRE 2012 Dataset", "start_pos": 114, "end_pos": 131, "type": "DATASET", "confidence": 0.9266213377316793}]}, {"text": " Table 5: Some example queries and their performances", "labels": [], "entities": []}]}