{"title": [{"text": "Analysis of Policy Agendas: Lessons Learned from Automatic Topic Classification of Croatian Political Texts", "labels": [], "entities": [{"text": "Analysis of Policy Agendas", "start_pos": 0, "end_pos": 26, "type": "TASK", "confidence": 0.8761264532804489}, {"text": "Topic Classification of Croatian Political Texts", "start_pos": 59, "end_pos": 107, "type": "TASK", "confidence": 0.7612980504830679}]}], "abstractContent": [{"text": "Policy agenda research is concerned with measuring the policymaker activities.", "labels": [], "entities": [{"text": "Policy agenda research", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.6516425212224325}]}, {"text": "Topic classification has proven a valuable tool for policy agenda research.", "labels": [], "entities": [{"text": "Topic classification", "start_pos": 0, "end_pos": 20, "type": "TASK", "confidence": 0.8620670437812805}]}, {"text": "However, manual topic coding is extremely costly and time-consuming.", "labels": [], "entities": [{"text": "topic coding", "start_pos": 16, "end_pos": 28, "type": "TASK", "confidence": 0.7545130550861359}]}, {"text": "Supervised topic classification offers a cost-effective and reliable alternative, yet it introduces new challenges , the most significant of which are the training set coding, classifier design, and accuracy-efficiency trade-off.", "labels": [], "entities": [{"text": "topic classification", "start_pos": 11, "end_pos": 31, "type": "TASK", "confidence": 0.709343209862709}, {"text": "training set coding", "start_pos": 155, "end_pos": 174, "type": "TASK", "confidence": 0.6267663836479187}, {"text": "classifier design", "start_pos": 176, "end_pos": 193, "type": "TASK", "confidence": 0.867649495601654}, {"text": "accuracy-efficiency", "start_pos": 199, "end_pos": 218, "type": "METRIC", "confidence": 0.9721457958221436}]}, {"text": "In this work, we address these challenges in the context of the recently launched Croatian Policy Agendas project.", "labels": [], "entities": [{"text": "Croatian Policy Agendas project", "start_pos": 82, "end_pos": 113, "type": "DATASET", "confidence": 0.9002044796943665}]}, {"text": "We describe anew policy agenda dataset, explore the many system design choices, and report on the insights gained.", "labels": [], "entities": []}, {"text": "Our best-performing model reaches 77% and 68% of F 1-score for major topics and subtopics, respectively.", "labels": [], "entities": [{"text": "F 1-score", "start_pos": 49, "end_pos": 58, "type": "METRIC", "confidence": 0.9883235096931458}]}], "introductionContent": [{"text": "Understanding politics means understanding what political actors are saying and writing, i.e., understanding the content of the messages.", "labels": [], "entities": []}, {"text": "Accordingly, content analysis plays an important role in political science.", "labels": [], "entities": [{"text": "content analysis", "start_pos": 13, "end_pos": 29, "type": "TASK", "confidence": 0.8015537858009338}, {"text": "political science", "start_pos": 57, "end_pos": 74, "type": "TASK", "confidence": 0.8404560685157776}]}, {"text": "Probably the most prominent form of content analysis is topic classification.", "labels": [], "entities": [{"text": "content analysis", "start_pos": 36, "end_pos": 52, "type": "TASK", "confidence": 0.7331651449203491}, {"text": "topic classification", "start_pos": 56, "end_pos": 76, "type": "TASK", "confidence": 0.907787561416626}]}, {"text": "In topic classification, the individual documents are assigned to a limited set of categories.", "labels": [], "entities": [{"text": "topic classification", "start_pos": 3, "end_pos": 23, "type": "TASK", "confidence": 0.8833416998386383}]}, {"text": "Once documents have been assigned categories, they can be searched more efficiently than when using traditional keyword-based methods.", "labels": [], "entities": []}, {"text": "Moreover, categories area prerequisite for the analysis of patterns and changes in political content across time.", "labels": [], "entities": []}, {"text": "As noted by, among others,, reliable topic classification can save significant research time.", "labels": [], "entities": [{"text": "topic classification", "start_pos": 37, "end_pos": 57, "type": "TASK", "confidence": 0.8051080703735352}]}, {"text": "One strand of research in which topic classification has proven beneficial is the analysis of policy agendas: the set of issues arising in the decision-making process.", "labels": [], "entities": [{"text": "topic classification", "start_pos": 32, "end_pos": 52, "type": "TASK", "confidence": 0.7209492027759552}]}, {"text": "The main idea is that the frequency with which the issues occur in political texts can be used as a measure of policy attention.", "labels": [], "entities": []}, {"text": "This strand of research has been particularly influenced by the Policy Agendas Project (PAP), initiated by Bryan Jones and Frank Baumgartner in 1993, with the intention to track changes in policy activity within particular areas of policy-making over longer periods of time).", "labels": [], "entities": []}, {"text": "The main issue PAP addressed is that of reliably measuring the policymaker activities across time.", "labels": [], "entities": [{"text": "PAP", "start_pos": 15, "end_pos": 18, "type": "TASK", "confidence": 0.8482895493507385}]}, {"text": "To this end, PAP developed an exhaustive and consistent codebook comprised of 19 major topic and 225 subtopic codes, by which all policymaker activities were categorized.", "labels": [], "entities": []}, {"text": "Building on this idea, the Comparative Agendas Project (CAP)) extended the PAP codebook, originally developed for the United States.", "labels": [], "entities": [{"text": "PAP codebook", "start_pos": 75, "end_pos": 87, "type": "DATASET", "confidence": 0.7857697308063507}]}, {"text": "While PAP was focused on ensuring longitudinal measurement reliability, CAP extended this methodological framework to also study policy changes comparatively, across time and space (countries).", "labels": [], "entities": []}, {"text": "The CAP codebook consists of 21 major topics and more than 200 subtopics, used for coding of political texts for over 18 countries.", "labels": [], "entities": [{"text": "CAP codebook", "start_pos": 4, "end_pos": 16, "type": "DATASET", "confidence": 0.7993913888931274}, {"text": "coding of political texts", "start_pos": 83, "end_pos": 108, "type": "TASK", "confidence": 0.853571742773056}]}, {"text": "Consequently, CAP-coded data have been used as the primary source fora number of policy agenda studies (e.g.,), and have been a foundation for one of the largest and most productive research networks in political science.", "labels": [], "entities": []}, {"text": "The perennial problem of topic classificationand content analysis in general -is the sheer volume of political texts.", "labels": [], "entities": [{"text": "topic classificationand content analysis", "start_pos": 25, "end_pos": 65, "type": "TASK", "confidence": 0.8758796900510788}]}, {"text": "Manual coding is extremely time-consuming and costly, and thus does not scale to large text collections.", "labels": [], "entities": [{"text": "Manual coding", "start_pos": 0, "end_pos": 13, "type": "TASK", "confidence": 0.713092029094696}]}, {"text": "Consequently, as pointed out by, analyzing large text collections is impossible for all but the most well-funded projects.", "labels": [], "entities": []}, {"text": "Moreover, manual coding can be unreliable and inconsistent.", "labels": [], "entities": []}, {"text": "For this reason, social scientists are increasingly relying on automated topic classification (ATC) (.", "labels": [], "entities": [{"text": "topic classification (ATC)", "start_pos": 73, "end_pos": 99, "type": "TASK", "confidence": 0.7617094695568085}]}, {"text": "ATC has two compelling advantages over human coding: reliability and efficiency.", "labels": [], "entities": [{"text": "reliability", "start_pos": 53, "end_pos": 64, "type": "METRIC", "confidence": 0.9908389449119568}]}, {"text": "From a computational perspective, ATC is an instance of a more general text categorization task, which falls within the purview of natural language processing and machine learning.", "labels": [], "entities": [{"text": "ATC", "start_pos": 34, "end_pos": 37, "type": "TASK", "confidence": 0.9168009757995605}]}, {"text": "The task is typically framed as a supervised machine learning problem, either multi-class (a single topic per document) or multi-label (multiple topics per document).", "labels": [], "entities": []}, {"text": "Note that policy agenda research typically adopts the single-topic approach.", "labels": [], "entities": []}, {"text": "While arguably more efficient than human coding, ATC does come with its problems.", "labels": [], "entities": [{"text": "ATC", "start_pos": 49, "end_pos": 52, "type": "TASK", "confidence": 0.9462541341781616}]}, {"text": "First and foremost, ATC does not get around the problem of validity: ATC generally cannot detect nuances in the text as well as a human can, thereby limiting the validity of content analysis results.", "labels": [], "entities": [{"text": "ATC", "start_pos": 20, "end_pos": 23, "type": "TASK", "confidence": 0.8296744227409363}, {"text": "validity", "start_pos": 59, "end_pos": 67, "type": "METRIC", "confidence": 0.8566537499427795}]}, {"text": "Secondly, there area number of practical challenges involved insetting up a high-performance ATC system.", "labels": [], "entities": []}, {"text": "Building an ATC system requires a high-quality manually coded dataset with a sufficiently large coverage.", "labels": [], "entities": []}, {"text": "Furthermore, there area lot of design choices involved, which greatly affect the system's performance.", "labels": [], "entities": []}, {"text": "In the end, one does typically not want to compromise the quality otherwise obtainable by human coding, which means that a trade off has to be found between accuracy and human coding effort.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 157, "end_pos": 165, "type": "METRIC", "confidence": 0.998615026473999}]}, {"text": "This can be done by estimating the confidence of classifier decisions for each individual document, and then forwarding to a human coder the (hopefully small) subset of documents for which the decision confidence is low.", "labels": [], "entities": []}, {"text": "For this to work, however, we need reliable estimates of classifier confidence, which turns out to be far from trivial.", "labels": [], "entities": []}, {"text": "In this work, we address the above challenges in the context of automatic topic classification of Croatian political texts.", "labels": [], "entities": [{"text": "automatic topic classification of Croatian political texts", "start_pos": 64, "end_pos": 122, "type": "TASK", "confidence": 0.7823273965290615}]}, {"text": "We first present anew dataset, built within the Croatian Policy Agendas Project, and a first such dataset for Croatian.", "labels": [], "entities": [{"text": "Croatian Policy Agendas Project", "start_pos": 48, "end_pos": 79, "type": "DATASET", "confidence": 0.9331599771976471}]}, {"text": "The dataset has been manually coded according to the CAP codebook, with additional measures taken to ensure reliability.", "labels": [], "entities": [{"text": "CAP codebook", "start_pos": 53, "end_pos": 65, "type": "DATASET", "confidence": 0.9377446472644806}, {"text": "reliability", "start_pos": 108, "end_pos": 119, "type": "METRIC", "confidence": 0.9727687239646912}]}, {"text": "An additional challenge lies in the fact that the dataset consists only of titles, which further exacerbates the data sparsity problem.", "labels": [], "entities": []}, {"text": "We use this dataset to train and evaluate a number of text classification models, also experimenting with two problem-specific extensions.", "labels": [], "entities": [{"text": "text classification", "start_pos": 54, "end_pos": 73, "type": "TASK", "confidence": 0.7261395454406738}]}, {"text": "Finally, we consider various confidence estimation strategies.", "labels": [], "entities": []}, {"text": "The main research questions we answer are as follows: (1) Can we use the hierarchical structure of our topic scheme to improve classification performance?; (2) Can we make use of idiosyncratic coding rules?; and (3) What confidence estimation strategy gives best accuracy-efficiency trade-off?", "labels": [], "entities": [{"text": "accuracy-efficiency", "start_pos": 263, "end_pos": 282, "type": "METRIC", "confidence": 0.9579818248748779}]}, {"text": "We hope that the lessons learned from these experiments will be useful to others working on the same or similar task for other languages.", "labels": [], "entities": []}, {"text": "The rest of the paper is structured as follows.", "labels": [], "entities": []}, {"text": "In the next section, we briefly review the related work on ATC.", "labels": [], "entities": [{"text": "ATC", "start_pos": 59, "end_pos": 62, "type": "TASK", "confidence": 0.6441630125045776}]}, {"text": "In Section 3, we describe the Croatian Policy Agendas Project and the corresponding dataset.", "labels": [], "entities": [{"text": "Croatian Policy Agendas Project", "start_pos": 30, "end_pos": 61, "type": "DATASET", "confidence": 0.9254851043224335}]}, {"text": "Section 4 focuses on the classification models.", "labels": [], "entities": []}, {"text": "In Section 5, we present the experimental results.", "labels": [], "entities": []}, {"text": "Section 6 concludes the paper and outlines future work.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section, we report on the results for the different classification models and rejection strategies on the Croatian Policy Agendas Project dataset.", "labels": [], "entities": [{"text": "Croatian Policy Agendas Project dataset", "start_pos": 114, "end_pos": 153, "type": "DATASET", "confidence": 0.9551792144775391}]}], "tableCaptions": [{"text": " Table 2: Calibration inter-annotator agreement", "labels": [], "entities": []}]}