{"title": [{"text": "Leveraging coreference to identify arms in medical abstracts: An experimental study", "labels": [], "entities": []}], "abstractContent": [{"text": "Performing systematic reviews is a critical yet manual, labor-intensive step in evidence-based medicine.", "labels": [], "entities": []}, {"text": "Automating systematic reviews is an active area of research, requiring innovations in machine learning and computational linguistics.", "labels": [], "entities": [{"text": "Automating systematic reviews", "start_pos": 0, "end_pos": 29, "type": "TASK", "confidence": 0.859516978263855}]}, {"text": "We examine how corefer-ence resolution can aid in identifying the arms of a study, an often overlooked piece of information needed to synthesize the results in a systematic review.", "labels": [], "entities": [{"text": "corefer-ence resolution", "start_pos": 15, "end_pos": 38, "type": "TASK", "confidence": 0.8908833861351013}]}, {"text": "A classification model 1 that performs better with the coreference features supports the intuition that coreference is able to capture the discourse salience of arms.", "labels": [], "entities": []}, {"text": "We note that control arms do not benefit as much from these features.", "labels": [], "entities": []}], "introductionContent": [{"text": "Evidence-based medicine (EBM) is a paradigm that seeks to inform medical practitioners of the optimal treatment, based on the totality of the available evidence (i.e., the results of all relevant clinical trials).", "labels": [], "entities": [{"text": "Evidence-based medicine (EBM)", "start_pos": 0, "end_pos": 29, "type": "TASK", "confidence": 0.8014689862728119}]}, {"text": "To this end, teams of medical experts often conduct systematic reviews, which synthesize all published medical literature pertaining to a specific clinical question.", "labels": [], "entities": []}, {"text": "The first step in a systematic review is to formulate the research question to be investigated, and then find all of the relevant citations.", "labels": [], "entities": []}, {"text": "Abstracts and then full texts are screened to exclude irrelevant trials.", "labels": [], "entities": []}, {"text": "Once a set of trials pertinent to the research question are identified (typically 10-20 trials), key pieces of information are extracted from each trial.", "labels": [], "entities": []}, {"text": "This information generally consists https://github.com/elisaF/extractGroups of the patient Population understudy, the Intervention(s) being tested, the Comparison and the Outcomes (abbreviated as PICO).", "labels": [], "entities": []}, {"text": "Results from all identified trials are typically statistically combined via meta-analysis to produce an aggregated result.", "labels": [], "entities": []}, {"text": "Producing systematic reviews is a timeconsuming, largely manual process.", "labels": [], "entities": [{"text": "Producing systematic reviews", "start_pos": 0, "end_pos": 28, "type": "TASK", "confidence": 0.631747841835022}]}, {"text": "This is exacerbated by the rapidly growing evidence base: PubMed 2 contains 800,000+ publications on clinical trials in humans (, and on average reports of 75 new trials are published daily.", "labels": [], "entities": [{"text": "PubMed 2", "start_pos": 58, "end_pos": 66, "type": "DATASET", "confidence": 0.9251023530960083}]}, {"text": "A single systematic review can takeover a year to produce -at which point it risks becoming outdated.", "labels": [], "entities": []}, {"text": "Therefore, automating evidence synthesis poses an enormous yet enticing challenge for automation.", "labels": [], "entities": [{"text": "evidence synthesis", "start_pos": 22, "end_pos": 40, "type": "TASK", "confidence": 0.7630982398986816}]}, {"text": "A crucial step towards automating synthesis is identifying the arms, or groups, in trials.", "labels": [], "entities": [{"text": "automating synthesis", "start_pos": 23, "end_pos": 43, "type": "TASK", "confidence": 0.7626970708370209}]}, {"text": "A clinical trial consists of one control arm, and one or more intervention arms.", "labels": [], "entities": []}, {"text": "For example, a study comparing the efficacy of aspirin versus a placebo would consist of two arms: those taking aspirin (the intervention group), and those taking the placebo (the control group).", "labels": [], "entities": []}, {"text": "Previous work has mostly focused on identifying the PICO elements.", "labels": [], "entities": []}, {"text": "However, the PICO elements alone are insufficient to convey the design of the study, a key piece of evidence necessary in the downstream task of data synthesis and analysis.", "labels": [], "entities": [{"text": "data synthesis and analysis", "start_pos": 145, "end_pos": 172, "type": "TASK", "confidence": 0.7011576443910599}]}, {"text": "Thus, the present study focuses on improving the automated identification of arms.", "labels": [], "entities": [{"text": "automated identification of arms", "start_pos": 49, "end_pos": 81, "type": "TASK", "confidence": 0.7789216339588165}]}, {"text": "We observed that arms are often salient in the discourse of the abstract, in that they corefer more often than other to-Randomised controlled trial with 12 month intervention.", "labels": [], "entities": []}, {"text": "Change in body mass index (BMI) standard deviation score (SDS) over 12 months with assessment 18 months after the start of the intervention.", "labels": [], "entities": [{"text": "body mass index (BMI) standard deviation score (SDS)", "start_pos": 10, "end_pos": 62, "type": "METRIC", "confidence": 0.8791553849975268}]}, {"text": "Using the last available data on all participants (n=106), those in the Mandometer group arm1 had significantly lower mean BMI SDS at 12 months compared with standard care arm2 . The mean meal size in the Mandometer group arm1 fell by 45 g.", "labels": [], "entities": [{"text": "Mandometer group arm1", "start_pos": 72, "end_pos": 93, "type": "DATASET", "confidence": 0.8711725870768229}, {"text": "BMI SDS", "start_pos": 123, "end_pos": 130, "type": "METRIC", "confidence": 0.9631922245025635}, {"text": "Mandometer group arm1", "start_pos": 205, "end_pos": 226, "type": "DATASET", "confidence": 0.8847445050875345}]}, {"text": "Those in the Mandometer group also had greater improvement in concentration of high density lipoprotein cholesterol.: Excerpt from medical abstract illustrating the discourse salience of the intervention arm, arm1, where the control arm is arm2 (note that not all mentions of the arms are annotated in the gold data, as discussed in section 5.3).", "labels": [], "entities": [{"text": "Mandometer group", "start_pos": 13, "end_pos": 29, "type": "DATASET", "confidence": 0.8887828290462494}]}, {"text": "Those in chain3 the Mandometer group also had greater improvement in concentration of high density lipoprotein cholesterol.: Medical abstract with annotated arms and coreference chains.", "labels": [], "entities": []}, {"text": "The chains were automatically determined as described in section 4.3.", "labels": [], "entities": []}, {"text": "All phrases with the same chain label are judged to co-refer.", "labels": [], "entities": []}], "datasetContent": [{"text": "The goal of this experiment is to explore empirically whether incorporating coreference features improves the performance of a classifier for arm identification, as compared to a baseline model without coref features (note that we do not aim to necessarily achieve state-of-the-art results on this task).", "labels": [], "entities": [{"text": "arm identification", "start_pos": 142, "end_pos": 160, "type": "TASK", "confidence": 0.7531481385231018}]}, {"text": "The task of the classifier is to label a token as either part of an armor not.", "labels": [], "entities": []}, {"text": "Sentences were tokenized, lower-cased and stop words were removed . Each token was paired with its abstract to form an pair to uniquely correlate the token with the medical abstract where it appeared (e.g. [abstract 3, \"intervention\"], [abstract 129, \"intervention\"]).", "labels": [], "entities": []}, {"text": "A binary classifier was implemented to label each token as belonging to an armor not (scikit-learn implementation of Support Vector Machine,).", "labels": [], "entities": []}, {"text": "Due to the imbalance of classes (9% positive), the class weights in the model were adjusted to be inversely proportional to the class frequencies in the corpus.", "labels": [], "entities": []}, {"text": "We performed five-fold cross validation.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Excerpt from medical abstract illustrating the discourse salience of the intervention arm, arm1, where the  control arm is arm2 (note that not all mentions of the arms are annotated in the gold data, as discussed in section 5.3).", "labels": [], "entities": []}, {"text": " Table 2: Medical abstract with annotated arms and coreference chains. The chains were automatically determined as  described in section 4.3. All phrases with the same chain label are judged to co-refer.", "labels": [], "entities": []}, {"text": " Table 4: Results averaged across 5-folds on the two models with their variances in parentheses.", "labels": [], "entities": []}]}