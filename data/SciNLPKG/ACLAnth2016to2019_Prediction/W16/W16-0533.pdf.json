{"title": [{"text": "Sentence Similarity Measures for Fine-Grained Estimation of Topical Relevance in Learner Essays", "labels": [], "entities": [{"text": "Sentence Similarity Measures", "start_pos": 0, "end_pos": 28, "type": "TASK", "confidence": 0.8880836367607117}, {"text": "Fine-Grained Estimation of Topical Relevance", "start_pos": 33, "end_pos": 77, "type": "TASK", "confidence": 0.6515265464782715}]}], "abstractContent": [{"text": "We investigate the task of assessing sentence-level prompt relevance in learner essays.", "labels": [], "entities": []}, {"text": "Various systems using word overlap, neural em-beddings and neural compositional models are evaluated on two datasets of learner writing.", "labels": [], "entities": [{"text": "word overlap", "start_pos": 22, "end_pos": 34, "type": "TASK", "confidence": 0.7158040106296539}]}, {"text": "We propose anew method for sentence-level similarity calculation, which learns to adjust the weights of pre-trained word embed-dings fora specific task, achieving substantially higher accuracy compared to other relevant baselines.", "labels": [], "entities": [{"text": "sentence-level similarity calculation", "start_pos": 27, "end_pos": 64, "type": "TASK", "confidence": 0.7199288407961527}, {"text": "accuracy", "start_pos": 184, "end_pos": 192, "type": "METRIC", "confidence": 0.9975225329399109}]}], "introductionContent": [{"text": "Evaluating the relevance of learner essays with respect to the assigned prompt is an important part of automated writing assessment (.", "labels": [], "entities": []}, {"text": "Students with limited relevant vocabulary may attempt to shift the topic of the essay in a more familiar direction, which grammatical error detection systems are notable to capture.", "labels": [], "entities": []}, {"text": "In an automated examination framework, this weakness could be further exploited by memorising a grammatically correct essay and presenting it in response to any prompt.", "labels": [], "entities": []}, {"text": "Being able to detect topical relevance can help prevent such weaknesses, provide useful feedback to the students, and is also a step towards evaluating more creative aspects of learner writing.", "labels": [], "entities": []}, {"text": "Most existing work on assigning topical relevance scores has been done using supervised methods.", "labels": [], "entities": [{"text": "assigning topical relevance", "start_pos": 22, "end_pos": 49, "type": "TASK", "confidence": 0.8803266882896423}]}, {"text": "trained a linear regression model for detecting relevance to each prompt, but this approach requires substantial training data for all the possible prompts.", "labels": [], "entities": []}, {"text": "addressed off-topic detection by measuring the cosine similarity between tf-idf vector representations of the prompt and the entire essay.", "labels": [], "entities": [{"text": "off-topic detection", "start_pos": 10, "end_pos": 29, "type": "TASK", "confidence": 0.7118717133998871}]}, {"text": "However, as this method only captures similarity using exact matching at the word-level, it can miss many topically relevant word occurrences in the essay.", "labels": [], "entities": []}, {"text": "In order to overcome this limitation, investigated a number of methods that expand the prompt with related words, such as morphological variations.", "labels": [], "entities": []}, {"text": "Ideally, the assessment system should be able to handle the introduction of new prompts, i.e. ones for which no previous data exists.", "labels": [], "entities": []}, {"text": "This allows the list of available topics to be edited dynamically, and students or teachers can insert their own unique prompts for every essay.", "labels": [], "entities": []}, {"text": "We can achieve this by constructing an unsupervised function that measures similarity between the prompt and the learner writing.", "labels": [], "entities": []}, {"text": "While previous work on prompt relevance assessment has mostly focussed on full essays, scoring individual sentences for prompt relevance has been relatively underexplored.", "labels": [], "entities": [{"text": "prompt relevance assessment", "start_pos": 23, "end_pos": 50, "type": "TASK", "confidence": 0.9464452862739563}]}, {"text": "used a supervised SVM classifier to train a binary sentence-based relevance model with 18 sentencelevel features.", "labels": [], "entities": []}, {"text": "We extend this line of work and investigate unsupervised methods using neural embeddings for the task of assessing topical relevance of individual sentences.", "labels": [], "entities": [{"text": "assessing topical relevance of individual sentences", "start_pos": 105, "end_pos": 156, "type": "TASK", "confidence": 0.7174153377612432}]}, {"text": "By providing sentence-level feedback, our approach is able to highlight specific areas of the text that require more attention, as opposed to showing a single overall score.", "labels": [], "entities": []}, {"text": "Sentencebased relevance scores could also be used for estimating coherence in an essay, or be combined with a more general score for indicating sentence quality).", "labels": [], "entities": []}, {"text": "In the following sections we explore a number of alternative similarity functions for this task.", "labels": [], "entities": []}, {"text": "The evaluation of the methods was performed on two different publicly available datasets and revealed that alternative approaches are required, depending on the nature of the prompts.", "labels": [], "entities": []}, {"text": "We propose anew method which achieves substantially better performance on one of the datasets, and construct a combination approach which provides more robust results independent of the prompt type.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Accuracy and mean reciprocal rank for the task of", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9994232654571533}, {"text": "mean reciprocal rank", "start_pos": 23, "end_pos": 43, "type": "METRIC", "confidence": 0.8879626194636027}]}]}