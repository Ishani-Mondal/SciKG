{"title": [{"text": "Modeling Complement Types in Phrase-Based SMT", "labels": [], "entities": [{"text": "Modeling Complement Types", "start_pos": 0, "end_pos": 25, "type": "TASK", "confidence": 0.8125653862953186}, {"text": "SMT", "start_pos": 42, "end_pos": 45, "type": "TASK", "confidence": 0.7754647135734558}]}], "abstractContent": [{"text": "We explore two approaches to model complement types (NPs and PPs) in an English-to-German SMT system: A simple abstract representation inserts pseudo-prepositions that mark the beginning of noun phrases, to improve the symmetry of source and target complement types, and to provide a flat structural information on phrase boundaries.", "labels": [], "entities": [{"text": "SMT", "start_pos": 90, "end_pos": 93, "type": "TASK", "confidence": 0.8938727974891663}]}, {"text": "An extension of this representation generates context-aware synthetic phrase-table entries conditioned on the source side, to model complement types in terms of grammatical case and preposition choice.", "labels": [], "entities": []}, {"text": "Both the simple preposition-informed system and the context-aware system significantly improve over the baseline; and the context-aware system is slightly better than the system without context information.", "labels": [], "entities": []}], "introductionContent": [{"text": "SMT output is often incomprehensible because it confuses complement types (noun phrases/NPs vs. prepositional phrases/PPs) by generating a wrong grammatical case, by choosing an incorrect preposition, or by arranging the complements in a meaningless way.", "labels": [], "entities": [{"text": "SMT output", "start_pos": 0, "end_pos": 10, "type": "TASK", "confidence": 0.9093306958675385}]}, {"text": "However, the choice of complement types in a translation represents important information at the syntax-semantics interface: The case of an NP determines its syntactic function and its semantic role; similarly, the choice of preposition in a PP sets the semantic role of the prepositional phrase.", "labels": [], "entities": []}, {"text": "While the lexical content of a target-language phrase is defined by the source sentence, the exact choice of preposition and case strongly depends on the target context, and most specifically on the target verb.", "labels": [], "entities": []}, {"text": "For example, the English verb phrase to call for sth.", "labels": [], "entities": []}, {"text": "can be translated into German by etw.", "labels": [], "entities": []}, {"text": "erfordern (subcategorizing a direct-object NP but no preposition) or by (nach) etw.", "labels": [], "entities": [{"text": "erfordern", "start_pos": 0, "end_pos": 9, "type": "METRIC", "confidence": 0.8153699040412903}]}, {"text": "verlangen (subcategorizing either a direct-object NP or a PP headed by the preposition nach).", "labels": [], "entities": [{"text": "verlangen", "start_pos": 0, "end_pos": 9, "type": "METRIC", "confidence": 0.9326727390289307}]}, {"text": "Differences in grammatical case and syntactic functions between source and target side include phenomena like subjectobject shifting: OBJ . Here, the English object corresponds to a German subject, whereas the English subject corresponds to the indirect object in the German sentence.", "labels": [], "entities": [{"text": "subjectobject shifting", "start_pos": 110, "end_pos": 132, "type": "TASK", "confidence": 0.7047203034162521}, {"text": "OBJ", "start_pos": 134, "end_pos": 137, "type": "METRIC", "confidence": 0.9745491147041321}]}, {"text": "Selecting the wrong complement type or an incorrect preposition obviously has a major effect on the fluency of SMT output, and also has a strong impact on the perception of semantic roles.", "labels": [], "entities": [{"text": "SMT output", "start_pos": 111, "end_pos": 121, "type": "TASK", "confidence": 0.8965445756912231}]}, {"text": "Consider the sentence John looks for his book.", "labels": [], "entities": []}, {"text": "When the preposition for is translated literally by the preposition f\u00fcr, the meaning of the translated sentence John sucht f\u00fcr sein Buch shifts, such that the book is no longer the object that is searched, but rather a recipient of the search.", "labels": [], "entities": []}, {"text": "To preserve the source meaning, the prepositional phrase headed by for must be translated as a direct object of the verb suchen, or as a PP headed by the preposition nach.", "labels": [], "entities": []}, {"text": "Since prepositions tend to be highly ambiguous, the choice of a preposition depends on various factors.", "labels": [], "entities": []}, {"text": "Often, there is a predominant translation, such as for \u2192 f\u00fcr, which is appropriate in many contexts, but unsuitable in other contexts.", "labels": [], "entities": []}, {"text": "Such translation options are often difficult to override, even when there are clues that the translation is wrong.", "labels": [], "entities": []}, {"text": "Furthermore, even though prepositions are highly frequent words, there can be coverage problems if a preposition is not aligned with the specific preposition required by the context, due to structural mismatches.", "labels": [], "entities": [{"text": "coverage", "start_pos": 78, "end_pos": 86, "type": "METRIC", "confidence": 0.9070149660110474}]}, {"text": "This paper presents two novel approaches to improve the modeling of complement types.", "labels": [], "entities": []}, {"text": "A simple approach introduces an abstract representation of \"placeholder prepositions\" at the beginning of noun phrases on the source and target sides.", "labels": [], "entities": []}, {"text": "The insertion of these placeholder prepositions leads to a more symmetric structure and consequently to a better coverage of prepositions, as all NPs are effectively transformed into PPs, and prepositions in one language without a direct equivalent in the other language can be aligned.", "labels": [], "entities": []}, {"text": "Furthermore, the placeholder prepositions function as explicit phrase boundaries and are annotated with grammatical case, so they provide flat structural information about the syntactic function of the phrase.", "labels": [], "entities": []}, {"text": "The placeholder representation leads to a significant improvement over a baseline system without prepositional placeholders.", "labels": [], "entities": []}, {"text": "Our second approach enhances the abstract placeholder representation, and integrates sourceside context into the phrase table of the SMT system to model different complement types.", "labels": [], "entities": [{"text": "SMT", "start_pos": 133, "end_pos": 136, "type": "TASK", "confidence": 0.9861667156219482}]}, {"text": "This is done by generating synthetic phrase-table entries containing contextually predicted prepositions.", "labels": [], "entities": []}, {"text": "With this process, we aim to (i) improve the preposition choice conditioned on the source sentence, and to (ii) manipulate the scores in the generated entries to favour context-appropriate translations.", "labels": [], "entities": []}, {"text": "Generating phrase-table entries allows to create prepositions in contexts not observed in the parallel training data.", "labels": [], "entities": []}, {"text": "The resulting phrase-table entries are unique for each context and provide the best selection of translation options in terms of complement realization on token-level.", "labels": [], "entities": []}, {"text": "This variant significantly outperforms the baseline, and is slightly better than the system with inserted placeholder prepositions.", "labels": [], "entities": []}], "datasetContent": [{"text": "We compare the preposition-informed system with the synthetic-phrases system where we explore different ways to integrate the synthetic phrases.", "labels": [], "entities": []}, {"text": "All systems were built using the Moses phrasebased framework.", "labels": [], "entities": []}, {"text": "We used 4.592.139 parallel sentences aligned with GIZA++ for translation model training, and 45M sentences (News14+parallel data) to build a 5-gram language model.", "labels": [], "entities": [{"text": "translation model", "start_pos": 61, "end_pos": 78, "type": "TASK", "confidence": 0.9053143262863159}, {"text": "News14+parallel data", "start_pos": 108, "end_pos": 128, "type": "DATASET", "confidence": 0.8088520169258118}]}, {"text": "We used NewsTest13 (3000 sentences) for development and NewsTest14 (3003 sentences) as test set.", "labels": [], "entities": [{"text": "NewsTest13", "start_pos": 8, "end_pos": 18, "type": "DATASET", "confidence": 0.9586901664733887}, {"text": "NewsTest14", "start_pos": 56, "end_pos": 66, "type": "DATASET", "confidence": 0.960225522518158}]}, {"text": "These System BLEU baseline-1 Surface forms 19.17 baseline-2 Stemmed 19.35 prep-informed Stemmed + \u2205-CASE 19.76 system (P-1) prep-informed Stemmed + \u2205-CASE-top-20 19.73 system (P-2): Variants of the synthetic-phrases system.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 13, "end_pos": 17, "type": "METRIC", "confidence": 0.9967306852340698}]}, {"text": "* marks significant improvement over system P-2 (with pair-wise bootstrap resampling with sample size 1,000 and a p-value of 0.05) datasets are from the WMT2015 shared task.", "labels": [], "entities": [{"text": "WMT2015 shared task", "start_pos": 153, "end_pos": 172, "type": "DATASET", "confidence": 0.844083309173584}]}, {"text": "To predict the four morphological features number, gender, case and strong/weak for inflecting the stemmed output, we trained 4 CRF sequence models on the target-side of the parallel data.", "labels": [], "entities": []}, {"text": "These features are predicted as a sequence of labels (i.e. case/number/etc of consecutive words in an NP/PP) at sentence level.", "labels": [], "entities": []}, {"text": "For the prediction of the placeholder prepositions, we trained a maximum entropy model on the parallel training data.", "labels": [], "entities": []}, {"text": "In contrast to the morphological features, each preposition in a phrase is predicted independently.", "labels": [], "entities": []}, {"text": "For all models, we used the toolkit Wapiti ().", "labels": [], "entities": []}, {"text": "The German data was parsed with BitPar and German inflected forms were generated with the morphological resource SMOR ( ).", "labels": [], "entities": [{"text": "German data", "start_pos": 4, "end_pos": 15, "type": "DATASET", "confidence": 0.7487283945083618}]}, {"text": "We carried out a small manual evaluation for 50 sentences (length 10-20 words) randomly chosen from system SP-3b in table 7, the best overall system, in comparison to the preposition-informed system P-2.", "labels": [], "entities": []}, {"text": "Two native speakers annotated errors concerning missing or incorrect verbs, nouns and prepositions, as well as incorrect grammatical case.", "labels": [], "entities": []}, {"text": "depicts the outcome: The number of errors found in the categories preposition and grammatical case are similar for both systems.", "labels": [], "entities": []}, {"text": "A slight improvement EN this is mainly due to the higher contribution from the administrative budget ...", "labels": [], "entities": [{"text": "EN", "start_pos": 21, "end_pos": 23, "type": "METRIC", "confidence": 0.9685640335083008}]}], "tableCaptions": [{"text": " Table 1: Source and target side features for the prediction of placeholders in the phrase for weapons \u2192  PREP Waffe<Pl>", "labels": [], "entities": [{"text": "PREP Waffe", "start_pos": 106, "end_pos": 116, "type": "TASK", "confidence": 0.5006867796182632}]}, {"text": " Table 3: Scores for baselines and preposition- informed system.", "labels": [], "entities": []}, {"text": " Table 4: Variants of the synthetic-phrases system.  * marks significant improvement over system P-2  (with pair-wise bootstrap resampling with sample  size 1,000 and a p-value of 0.05)", "labels": [], "entities": []}, {"text": " Table 5: Number of newly generated and regular  phrase-table entries used to translate the test set  (3003 sentences).", "labels": [], "entities": []}, {"text": " Table 7: Results when filtering out infrequent  nouns in the ME training data (1) or reducing the  amount of source-target-alignment triples used for  ME training (2). * marks significant improvement  over system P-2.", "labels": [], "entities": [{"text": "ME training data", "start_pos": 62, "end_pos": 78, "type": "DATASET", "confidence": 0.6699832479159037}]}, {"text": " Table 8: Manual error analysis of 50 randomly  selected sentences.", "labels": [], "entities": []}]}