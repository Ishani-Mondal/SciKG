{"title": [{"text": "Proceedings of The 9th International Natural Language Generation conference", "labels": [], "entities": [{"text": "International Natural Language Generation", "start_pos": 23, "end_pos": 64, "type": "TASK", "confidence": 0.6137285456061363}]}], "abstractContent": [{"text": "The need for natural language generation (NLG) arises in diverse, multimodal contexts: ranging from describing stories captured in a photograph, to instructing how to prepare a dish using a given set of ingredients, and to composing a sonnet fora given topic phrase.", "labels": [], "entities": [{"text": "natural language generation (NLG)", "start_pos": 13, "end_pos": 46, "type": "TASK", "confidence": 0.8441775639851888}]}, {"text": "One common challenge among these types of NLG tasks is that the generation model often needs to work with relatively loose semantic correspondence between the input prompt and the desired output text.", "labels": [], "entities": []}, {"text": "For example, an image caption that appeals to readers may require pragmatic interpretation of the scene beyond the literal content of the image.", "labels": [], "entities": [{"text": "image caption", "start_pos": 16, "end_pos": 29, "type": "TASK", "confidence": 0.7521614134311676}]}, {"text": "Similarly, composing anew recipe requires working out detailed how-to instructions that are not directly specified by the given set of ingredient names.", "labels": [], "entities": []}, {"text": "In this talk, I will discuss our recent approaches to generating contextual, creative , and coherent text given a relatively lean and noisy input prompt with respect to three NLG tasks: (1) creative image captioning, (2) recipe composition, and (3) sonnet composition.", "labels": [], "entities": [{"text": "creative image captioning", "start_pos": 190, "end_pos": 215, "type": "TASK", "confidence": 0.6429767111937205}, {"text": "recipe composition", "start_pos": 221, "end_pos": 239, "type": "TASK", "confidence": 0.8197228908538818}, {"text": "sonnet composition", "start_pos": 249, "end_pos": 267, "type": "TASK", "confidence": 0.8241876065731049}]}, {"text": "A recurring theme is that our models learn most of the end-to-end mappings between the input and the output directly from data without requiring manual annotations for intermediate meaning representations.", "labels": [], "entities": []}, {"text": "I will conclude the talk by discussing the strengths and the limitations of these types of data-driven approaches and point to avenues for future research.", "labels": [], "entities": []}], "introductionContent": [], "datasetContent": [], "tableCaptions": []}