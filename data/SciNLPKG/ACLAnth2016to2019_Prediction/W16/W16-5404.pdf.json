{"title": [{"text": "Developing Corpus of Lecture Utterances Aligned to Slide Components", "labels": [], "entities": [{"text": "Developing Corpus of Lecture Utterances Aligned to Slide Components", "start_pos": 0, "end_pos": 67, "type": "TASK", "confidence": 0.7285027338398827}]}], "abstractContent": [{"text": "The approach which formulates the automatic text summarization as a maximum coverage problem with knapsack constraint over a set of textual units and a set of weighted conceptual units is promising.", "labels": [], "entities": [{"text": "text summarization", "start_pos": 44, "end_pos": 62, "type": "TASK", "confidence": 0.6591855436563492}]}, {"text": "However, it is quite important and difficult to determine the appropriate granularity of conceptual units for this formulation.", "labels": [], "entities": []}, {"text": "In order to resolve this problem, we are examining to use components of presentation slides as conceptual units to generate a summary of lecture utterances , instead of other possible conceptual units like base noun phrases or important nouns.", "labels": [], "entities": []}, {"text": "This paper explains our developing corpus designed to evaluate our proposing approach, which consists of presentation slides and lecture utterances aligned to presentation slide components.", "labels": [], "entities": []}], "introductionContent": [{"text": "Automatic text summarization is one of the tasks that have long been studied in natural language processing area.", "labels": [], "entities": [{"text": "Automatic text summarization", "start_pos": 0, "end_pos": 28, "type": "TASK", "confidence": 0.7267147699991862}]}, {"text": "One of well-known approaches for automatic text summarization is an extractive method which picks important textual units (e.g. sentences) from given documents ().", "labels": [], "entities": [{"text": "automatic text summarization", "start_pos": 33, "end_pos": 61, "type": "TASK", "confidence": 0.5921176075935364}]}, {"text": "() introduced conceptual units to represent meaning components, and formulated the extractive method of text summarization as a maximum coverage problem with knapsack constraint (henceforth, denoted as MCKP).", "labels": [], "entities": [{"text": "text summarization", "start_pos": 104, "end_pos": 122, "type": "TASK", "confidence": 0.7198876142501831}]}, {"text": "Suppose a finite set T of textual units which means whole given documents, and a finite set C of conceptual units which represents whole information described by T . In this representation, a textual unit may describe one or more conceptual units, and an information overlap between picked textual units is considered as a redundant conceptual unit(s) which is described by plural textual units.", "labels": [], "entities": []}, {"text": "In other words, the meaning of each textual unit is regarded as a subset of C, and the extractive method of text summarization is defined as a problem to find a subset of T which satisfies the constraint of its total length and describes as many conceptual units as possible.", "labels": [], "entities": [{"text": "text summarization", "start_pos": 108, "end_pos": 126, "type": "TASK", "confidence": 0.6938472837209702}]}, {"text": "Various methods including greedy algorithm (), stack decoding ( and linear programming solver were employed to solve text summarization in this representation.", "labels": [], "entities": [{"text": "linear programming solver", "start_pos": 68, "end_pos": 93, "type": "TASK", "confidence": 0.6164675255616506}, {"text": "text summarization", "start_pos": 117, "end_pos": 135, "type": "TASK", "confidence": 0.6536237597465515}]}, {"text": "This representation provides a concrete and concise formulation of text summarization, however, a big problem still remains: the appropriate granularity of conceptual units.", "labels": [], "entities": [{"text": "text summarization", "start_pos": 67, "end_pos": 85, "type": "TASK", "confidence": 0.6476020961999893}]}, {"text": "() proposed to use basic elements as conceptual units, which are dependency subtrees obtained by trimming dependency trees.", "labels": [], "entities": []}, {"text": "( proposed to use weighted content words as conceptual units, whose weights reflect their importance.", "labels": [], "entities": []}, {"text": "Although these possible conceptual units treat linguistic clues of original documents, they do not represent the intuition of the writer (or the speaker) of the original documents.", "labels": [], "entities": []}, {"text": "In order to resolve this problem, we are examining to extract dependency structure between primitive objects such as texts, pictures, lines and basic diagrams, and to use these objects as conceptual units when generating a summary of lecture utterances.", "labels": [], "entities": []}, {"text": "We think that this approach has two advantages than the previous approach of conceptual units.", "labels": [], "entities": []}, {"text": "The first is that terminology and character formatting of these objects may reflect the intuition of the lecturer about his/her talk, because these objects are selected Place license statement here for the camera-ready version, see Section ?? of the instructions for preparing a manuscript. and located by him/herself.", "labels": [], "entities": []}, {"text": "For example, he/she will use either a larger point font or a bold style font, to represent an important part of his/her talk.", "labels": [], "entities": []}, {"text": "The second is that this approach naturally introduces multi-level granularity of conceptual units because our using method proposed by extracts relationship between objects as a tree structure.", "labels": [], "entities": []}, {"text": "When multi-level granularity of conceptual units is available, the remaining problem to decide appropriate granularity of conceptual units can be considered as a simple optimization problem.", "labels": [], "entities": []}, {"text": "This paper explains our developing corpus which consists of lecture utterances, presentation slides, and their alignment information.", "labels": [], "entities": []}, {"text": "We think that this corpus will give a foundation to evaluate our assumption about conceptual units.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Statistics of CJLC", "labels": [], "entities": [{"text": "CJLC", "start_pos": 24, "end_pos": 28, "type": "DATASET", "confidence": 0.8329092264175415}]}, {"text": " Table 2: Age of Speakers, their teaching history and number of their courses", "labels": [], "entities": []}, {"text": " Table 3: Result of Manual Annotation  # of  # of slide  # of  # of labels  \u03ba statistics  Lecture ID slides components utterances  I  B E  O coarse fine  L11M0010  21  370  742  578  4 26 134  0.68 0.61  L11M0011  29  431  704  584 11 14  95  0.58 0.72  L11M0012  12  276  811  546  2  5 258  0.83 0.65  L11M0030  58  822  680  414 41 57 168  0.92 0.75  L11M0050  22  159  2362 1280 39 81 962  0.68  0.6  L11M0064  27  469  1110  559 51 58 442  0.69 0.72", "labels": [], "entities": []}, {"text": " Table 4: Result of Automatic Alignment (L11M0030)  \u03bb  Accuracy  Recall  Overall accuracy  I  O  I  O  0 0.0896 0.656 0.113 0.734  0.247  0.25  0.329 0.693 0.424 0.734  0.425  0.5  0.335 0.693 0.432 0.734  0.429  0.75  0.341 0.697 0.440 0.734  0.434  1  0.248 0.699 0.321 0.728  0.365", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 55, "end_pos": 63, "type": "METRIC", "confidence": 0.9971715807914734}, {"text": "accuracy  I  O  I  O  0", "start_pos": 81, "end_pos": 104, "type": "METRIC", "confidence": 0.8822746773560842}]}]}