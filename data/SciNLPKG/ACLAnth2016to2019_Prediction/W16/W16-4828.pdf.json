{"title": [{"text": "QCRI @ DSL 2016: Spoken Arabic Dialect Identification Using Textual Features", "labels": [], "entities": [{"text": "QCRI @ DSL 2016", "start_pos": 0, "end_pos": 15, "type": "DATASET", "confidence": 0.8341855704784393}, {"text": "Spoken Arabic Dialect Identification", "start_pos": 17, "end_pos": 53, "type": "TASK", "confidence": 0.775772750377655}]}], "abstractContent": [{"text": "The paper describes the QCRI submissions to the shared task of automatic Arabic dialect classification into 5 Arabic variants, namely Egyptian, Gulf, Levantine, North-African (Maghrebi), and Modern Standard Arabic (MSA).", "labels": [], "entities": [{"text": "automatic Arabic dialect classification", "start_pos": 63, "end_pos": 102, "type": "TASK", "confidence": 0.6029955893754959}, {"text": "Modern Standard Arabic (MSA)", "start_pos": 191, "end_pos": 219, "type": "DATASET", "confidence": 0.7392842372258505}]}, {"text": "The relatively small training set is automatically generated from an ASR system.", "labels": [], "entities": [{"text": "ASR", "start_pos": 69, "end_pos": 72, "type": "TASK", "confidence": 0.8482569456100464}]}, {"text": "To avoid over-fitting on such small data, we selected and designed features that capture the morphological essence of the different dialects.", "labels": [], "entities": []}, {"text": "We submitted four runs to the Arabic sub-task.", "labels": [], "entities": []}, {"text": "For all runs, we used a combined feature vector of character bigrams, trigrams, 4-grams, and 5-grams.", "labels": [], "entities": []}, {"text": "We tried several machine-learning algorithms, namely Logistic Regression , Naive Bayes, Neural Networks, and Support Vector Machines (SVM) with linear and string kernels.", "labels": [], "entities": [{"text": "Logistic Regression", "start_pos": 53, "end_pos": 72, "type": "TASK", "confidence": 0.8068297505378723}]}, {"text": "Our submitted runs used SVM with a linear kernel.", "labels": [], "entities": []}, {"text": "In the closed submission, we got the best accuracy of 0.5136 and the third best weighted F1 score, with a difference of less than 0.002 from the best system.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 42, "end_pos": 50, "type": "METRIC", "confidence": 0.9997236132621765}, {"text": "F1 score", "start_pos": 89, "end_pos": 97, "type": "METRIC", "confidence": 0.9779678285121918}]}], "introductionContent": [{"text": "The Arabic language has various dialects and variants that exist in a continuous spectrum.", "labels": [], "entities": []}, {"text": "They area result of an interweave between the Arabic language that spread throughout the Middle East and North Africa and the indigenous languages in different countries.", "labels": [], "entities": []}, {"text": "With the passage of time and the juxtaposition of cultures, dialects and variants of Arabic evolved and mutated.", "labels": [], "entities": []}, {"text": "Among the varieties of Arabic, so-called Modern Standard Arabic (MSA) is the lingua franca of the Arab world, and it typically used in written and formal communications.", "labels": [], "entities": []}, {"text": "On the other hand, Arabic dialects, such as Egyptian and Levantine, are usually spoken and used in informal communications, especially on social networks such as Twitter and Facebook.", "labels": [], "entities": []}, {"text": "Automatically identifying the dialect of apiece of text or of a spoken utterance can be beneficial fora variety of practical applications.", "labels": [], "entities": [{"text": "identifying the dialect of apiece of text", "start_pos": 14, "end_pos": 55, "type": "TASK", "confidence": 0.8172895397458758}]}, {"text": "For instance, it can aid Machine Translation (MT) systems in choosing the most appropriate model for translation.", "labels": [], "entities": [{"text": "Machine Translation (MT)", "start_pos": 25, "end_pos": 49, "type": "TASK", "confidence": 0.8503429174423218}]}, {"text": "In this paper we describe our dialect identification system that we used for Arabic dialect identification (sub-task 2) in the 2016 DSL shared task ().", "labels": [], "entities": [{"text": "dialect identification", "start_pos": 30, "end_pos": 52, "type": "TASK", "confidence": 0.7254063189029694}, {"text": "Arabic dialect identification", "start_pos": 77, "end_pos": 106, "type": "TASK", "confidence": 0.6092895666758219}]}, {"text": "We submitted a total of 4 runs to the shared task; 2 closed runs and 2 open runs.", "labels": [], "entities": []}, {"text": "For closed runs, participants are only allowed to use the provided training set.", "labels": [], "entities": []}, {"text": "For open runs, external resources are allowed.", "labels": [], "entities": []}, {"text": "We tried several combinations of features such as bag-of-words features based-on words or character n-grams where terms are weighed by term frequency (tf) or term frequency and inverse document frequency (tf-idf).", "labels": [], "entities": []}, {"text": "We also experimented with several machine learning classifiers including logistic regression, naive Bayes, neural networks, and Support Vector Machines (SVM) with different kernels.", "labels": [], "entities": []}, {"text": "Our best run used an SVM classifier with a linear kernel trained on character n-gram features.", "labels": [], "entities": []}, {"text": "Our best run achieved an accuracy of 0.5136 and an F-measure 0.5112.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 25, "end_pos": 33, "type": "METRIC", "confidence": 0.9997629523277283}, {"text": "F-measure", "start_pos": 51, "end_pos": 60, "type": "METRIC", "confidence": 0.9993889331817627}]}, {"text": "Compared to the systems that participated in the shared task, our system obtained the best accuracy and the third highest weighted F1 score, with a difference of less than 0.002 from the best system.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 91, "end_pos": 99, "type": "METRIC", "confidence": 0.9996700286865234}, {"text": "F1 score", "start_pos": 131, "end_pos": 139, "type": "METRIC", "confidence": 0.9845608472824097}]}], "datasetContent": [{"text": "This section analyzes the dataset provided by the shared task and discusses the methodologies and approaches for both preparing the data and for developing our Arabic dialect identification system.", "labels": [], "entities": [{"text": "Arabic dialect identification", "start_pos": 160, "end_pos": 189, "type": "TASK", "confidence": 0.6444708506266276}]}, {"text": "The DSL organizers provided a training dataset that is composed of Automatic Speech Recognition (ASR) transcripts , where utterances (or sentences) are labeled as Egyptian (EGY), Gulf (GLF), Levantine (LAV), North-African (NOR), or Modern Standard Arabic (MSA).", "labels": [], "entities": [{"text": "Automatic Speech Recognition (ASR) transcripts", "start_pos": 67, "end_pos": 113, "type": "TASK", "confidence": 0.7464600801467896}, {"text": "Modern Standard Arabic (MSA)", "start_pos": 232, "end_pos": 260, "type": "DATASET", "confidence": 0.8697688480218252}]}, {"text": "Each sentence is provided in a separate line in the following tab-delimited format: The Arabic sentences are transliterated into the Buckwalter encoding scheme.", "labels": [], "entities": [{"text": "Buckwalter", "start_pos": 133, "end_pos": 143, "type": "DATASET", "confidence": 0.9645946621894836}]}, {"text": "The training set has 7,619 sentences with a total of 315,829 words, of which 55,992 are unique.", "labels": [], "entities": []}, {"text": "The average sentence length is 41 words.", "labels": [], "entities": []}, {"text": "As expected, the frequent words are mostly stopwords with the words fy (in), mn (from), and mA (what) being the most frequent words across dialects.", "labels": [], "entities": []}, {"text": "We retained stopwords as they are important for identifying dialects.", "labels": [], "entities": []}, {"text": "The data used in this shared task is different from data mentioned in the literature in that it is composed of ASR transcripts, and dialects are more common in conversational speech.", "labels": [], "entities": []}, {"text": "Since the data was not manually revised (as part of the challenge), we found the following drawbacks in the data: \u2022 The sentences are often quite incoherent and many sentences make no sense.", "labels": [], "entities": []}, {"text": "\u2022 Some lines have identical sentences, but with different dialect labels.", "labels": [], "entities": []}, {"text": "Consider the following example (line 16 through line 19 in the dataset file): Such problems complicate the dialect identification task.", "labels": [], "entities": [{"text": "dialect identification task", "start_pos": 107, "end_pos": 134, "type": "TASK", "confidence": 0.849403460820516}]}, {"text": "Furthermore, the nature and the distribution of the words and phrases in such data is different than the one extracted from sources such as blogs, forums, and tweets.", "labels": [], "entities": []}, {"text": "Therefore, using such data to train a classifier (without taking into consideration the aforementioned issues) may yield a classifier that does not capture real patterns fora generalized dialect identifier.", "labels": [], "entities": []}, {"text": "Data Preparation: To perform offline experiments before submitting the official shared task runs, we split the provided training data into an 80/20 train/dev partitions, which would allow us to measure the effectiveness of different classification schemes.", "labels": [], "entities": []}, {"text": "However, we used the entire set for training when submitting the final runs.", "labels": [], "entities": []}, {"text": "For some runs, we excluded sentences that are shorter than a certain threshold of words.", "labels": [], "entities": []}, {"text": "We tried several threshold between 1 and 5.", "labels": [], "entities": []}, {"text": "Furthermore, we also considered removing words with document frequency less than and/or greater than certain thresholds.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: The distribution of sentences, words, and unique words for the different Arabic variants.", "labels": [], "entities": []}, {"text": " Table 2: Accuracy on dev set with various word-level features", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9933953881263733}]}, {"text": " Table 3: Accuracy on dev set with various character-level features", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9956895709037781}]}, {"text": " Table 4: Results for all runs on the hidden test set.", "labels": [], "entities": []}]}