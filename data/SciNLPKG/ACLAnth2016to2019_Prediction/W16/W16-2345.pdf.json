{"title": [], "abstractContent": [{"text": "We describe the design, the evaluation setup, and the results of the 2016 WMT shared task on cross-lingual pronoun prediction.", "labels": [], "entities": [{"text": "WMT shared task", "start_pos": 74, "end_pos": 89, "type": "TASK", "confidence": 0.6996396581331888}, {"text": "cross-lingual pronoun prediction", "start_pos": 93, "end_pos": 125, "type": "TASK", "confidence": 0.7397185961405436}]}, {"text": "This is a classification task in which participants are asked to provide predictions on what pronoun class label should replace a placeholder value in the target-language text, provided in lemma-tised and PoS-tagged form.", "labels": [], "entities": []}, {"text": "We provided four subtasks, for the English-French and English-German language pairs, in both directions.", "labels": [], "entities": []}, {"text": "Eleven teams participated in the shared task; nine for the English-French subtask, five for French-English, nine for English-German, and six for German-English.", "labels": [], "entities": []}, {"text": "Most of the submissions outperformed two strong language-model-based baseline systems, with systems using deep recurrent neural networks outper-forming those using other architectures for most language pairs.", "labels": [], "entities": []}], "introductionContent": [{"text": "Pronoun translation poses a problem for current state-of-the-art Statistical Machine Translation (SMT) systems.", "labels": [], "entities": [{"text": "Pronoun translation", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.870769590139389}, {"text": "Statistical Machine Translation (SMT)", "start_pos": 65, "end_pos": 102, "type": "TASK", "confidence": 0.7804865737756094}]}, {"text": "Problems arise fora number of reasons.", "labels": [], "entities": []}, {"text": "In general, pronoun systems in natural language do not map well across languages, e.g., due to differences in gender, number, case, formality, or animacy/humanness, as well as due to differences in where pronouns maybe used.", "labels": [], "entities": []}, {"text": "To this is added the problem of functional ambiguity, whereby pronouns with the same surface form may perform multiple functions.", "labels": [], "entities": []}, {"text": "For example, the English pronoun \"it\" may function as an anaphoric, pleonastic, or event reference pronoun.", "labels": [], "entities": []}, {"text": "An anaphoric pronoun corefers with a noun phrase (NP).", "labels": [], "entities": []}, {"text": "A pleonastic pronoun does not refer to anything, but it is required by syntax to fill the subject position.", "labels": [], "entities": []}, {"text": "An event reference pronoun may refer to a verb phrase (VP), a clause, an entire sentence, or a longer passage of text.", "labels": [], "entities": []}, {"text": "Examples of each of these pronoun functions are provided in.", "labels": [], "entities": []}, {"text": "It is clear that instances of the English pronoun \"it\" belonging to each of these functions would have different translation requirements in French and German.", "labels": [], "entities": []}, {"text": "The problem of pronouns in machine translation has long been studied.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 27, "end_pos": 46, "type": "TASK", "confidence": 0.7376129627227783}]}, {"text": "In particular, for SMT systems, the recent previous studies cited above have focused on the translation of anaphoric pronouns.", "labels": [], "entities": [{"text": "SMT", "start_pos": 19, "end_pos": 22, "type": "TASK", "confidence": 0.9952549934387207}, {"text": "translation of anaphoric pronouns", "start_pos": 92, "end_pos": 125, "type": "TASK", "confidence": 0.8248866647481918}]}, {"text": "In this case, a well-known constraint of languages with grammatical gender is that agreement must hold between an anaphoric pronoun and the NP with which it corefers, called its antecedent.", "labels": [], "entities": []}, {"text": "The pronoun and its antecedent may occur in the same sentence (intra-sentential anaphora) or in different sentences (inter-sentential anaphora).", "labels": [], "entities": []}, {"text": "Most SMT systems translate sentences in isolation, so inter-sentential anaphoric pronouns will be translated without knowledge of their antecedent and as such, pronoun-antecedent agreement cannot be guaranteed.", "labels": [], "entities": [{"text": "SMT", "start_pos": 5, "end_pos": 8, "type": "TASK", "confidence": 0.9839748740196228}]}, {"text": "The accurate translation of intrasentential anaphoric pronouns may also cause problems as the pronoun and its antecedent may fall into different translation units (e.g., n-gram or syntactic tree fragment).", "labels": [], "entities": []}, {"text": "The above constraints start playing a role in pronoun translation in situations where several translation options are possible fora given sourcelanguage pronoun, a large number of options being likely to affect negatively the translation accuracy.", "labels": [], "entities": [{"text": "pronoun translation", "start_pos": 46, "end_pos": 65, "type": "TASK", "confidence": 0.8109573125839233}, {"text": "accuracy", "start_pos": 238, "end_pos": 246, "type": "METRIC", "confidence": 0.9763985276222229}]}, {"text": "In other words, pronoun types that exhibit significant translation divergencies are more likely to be erroneously translated by an SMT system that is not aware of the above constraints.", "labels": [], "entities": [{"text": "SMT", "start_pos": 131, "end_pos": 134, "type": "TASK", "confidence": 0.9795589447021484}]}, {"text": "For example, when translating the English pronoun \"she\" into French, there is one main option, \"elle\" (exceptions occur, though, e.g., in references to ships).", "labels": [], "entities": [{"text": "translating the English pronoun \"she\"", "start_pos": 18, "end_pos": 55, "type": "TASK", "confidence": 0.8206149509974888}]}, {"text": "However, several options exist for the translation of anaphoric \"it\": \"il\" (for an antecedent that is masculine in French) or \"elle\" (feminine), but also \"cela\", \"c \u00b8a\" or sometimes \"ce\" (non-gendered demonstratives).", "labels": [], "entities": [{"text": "translation of anaphoric \"it\"", "start_pos": 39, "end_pos": 68, "type": "TASK", "confidence": 0.7968587776025137}]}, {"text": "The challenges of correct pronoun translation gradually raised the interest in a shared task, which would allow the comparison of various proposals and the quantification of their claims to improve pronoun translation.", "labels": [], "entities": [{"text": "correct pronoun translation", "start_pos": 18, "end_pos": 45, "type": "TASK", "confidence": 0.6395276784896851}, {"text": "pronoun translation", "start_pos": 198, "end_pos": 217, "type": "TASK", "confidence": 0.7828692197799683}]}, {"text": "However, evaluating pronoun translation comes with its own challenges, as reference-based evaluation cannot take into account the legitimate variations of translated pronouns, or their placement in the sentence.", "labels": [], "entities": [{"text": "evaluating pronoun translation", "start_pos": 9, "end_pos": 39, "type": "TASK", "confidence": 0.6463526487350464}]}, {"text": "Building upon the experience from a 2015 shared task, the WMT 2016 shared task on pronoun prediction has been designed to test capacities for correct pronoun translation in a framework that allows for objective evaluation, as we now explain.", "labels": [], "entities": [{"text": "WMT 2016 shared task on pronoun prediction", "start_pos": 58, "end_pos": 100, "type": "TASK", "confidence": 0.5278230820383344}, {"text": "correct pronoun translation", "start_pos": 142, "end_pos": 169, "type": "TASK", "confidence": 0.7740061084429423}]}], "datasetContent": [{"text": "While in 2015 we used macro-averaged F 1 as an official evaluation measure, this year we adopted macro-averaged recall, which was also recently adopted by some other competitions, e.g., by.", "labels": [], "entities": [{"text": "F 1", "start_pos": 37, "end_pos": 40, "type": "METRIC", "confidence": 0.9108245670795441}, {"text": "recall", "start_pos": 112, "end_pos": 118, "type": "METRIC", "confidence": 0.961286187171936}]}, {"text": "Moreover, as in 2015, we also report accuracy as a secondary evaluation measure.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 37, "end_pos": 45, "type": "METRIC", "confidence": 0.9995500445365906}]}, {"text": "Macro-averaged recall ranges in, where a value of 1 is achieved by the perfect classifier, 8 and a value of 0 is achieved by the classifier that misclassifies all examples.", "labels": [], "entities": [{"text": "recall", "start_pos": 15, "end_pos": 21, "type": "METRIC", "confidence": 0.994809627532959}]}, {"text": "The value of 1/C, where C is the number of classes, is achieved by a trivial classifier that assigns the same class to all examples (regardless of which class is chosen), and is also the expected value of a random classifier.", "labels": [], "entities": []}, {"text": "8 If the test data did not have any instances of some of the classes, we excluded these classes from the macro-averaging, i.e., we only macro-averaged over classes that are present in the gold standard.", "labels": [], "entities": []}, {"text": "The advantage of macro-averaged recall over accuracy is that it is more robust to class imbalance.", "labels": [], "entities": [{"text": "recall", "start_pos": 32, "end_pos": 38, "type": "METRIC", "confidence": 0.9800966382026672}, {"text": "accuracy", "start_pos": 44, "end_pos": 52, "type": "METRIC", "confidence": 0.9993485808372498}]}, {"text": "For instance, the accuracy of the majorityclass classifier maybe much higher than 1/C if the test dataset is imbalanced.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 18, "end_pos": 26, "type": "METRIC", "confidence": 0.9995145797729492}]}, {"text": "Thus, one cannot interpret the absolute value of accuracy (e.g., is 0.7 a good or a bad value?) without comparing it to a baseline that must be computed for each specific test dataset.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 49, "end_pos": 57, "type": "METRIC", "confidence": 0.8437493443489075}]}, {"text": "In contrast, for macro-averaged recall, it is clear that a value of, e.g., 0.7, is well above the majority-class and the random baselines, which are both always 1/C (e.g., 0.5 with two classes, 0.33 with three classes, etc.).", "labels": [], "entities": [{"text": "recall", "start_pos": 32, "end_pos": 38, "type": "METRIC", "confidence": 0.9038234949111938}]}, {"text": "Standard F 1 and macro-averaged F 1 are also sensitive to class imbalance for the same reason; see Sebastiani for more detail.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Statistics about 2016 test datasets.", "labels": [], "entities": [{"text": "2016 test datasets", "start_pos": 27, "end_pos": 45, "type": "DATASET", "confidence": 0.6622122228145599}]}, {"text": " Table 2: Test dataset documents: English to French/German.", "labels": [], "entities": [{"text": "Test dataset documents", "start_pos": 10, "end_pos": 32, "type": "DATASET", "confidence": 0.7799199223518372}]}, {"text": " Table 3: Test dataset documents: French/German to English.", "labels": [], "entities": [{"text": "Test dataset documents", "start_pos": 10, "end_pos": 32, "type": "DATASET", "confidence": 0.7848384181658427}]}, {"text": " Table 4: Evaluation of German-English align- ments for all links and pronouns using different  alignment models and symmetrisation.", "labels": [], "entities": []}, {"text": " Table 5: Number of pronouns for the different classes in the IWSLT15 data before and after filtering.", "labels": [], "entities": [{"text": "IWSLT15 data", "start_pos": 62, "end_pos": 74, "type": "DATASET", "confidence": 0.9723640382289886}]}]}