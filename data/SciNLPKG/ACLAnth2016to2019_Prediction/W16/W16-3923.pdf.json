{"title": [{"text": "Learning to Search for Recognizing Named Entities in Twitter", "labels": [], "entities": [{"text": "Learning to Search for Recognizing Named Entities in Twitter", "start_pos": 0, "end_pos": 60, "type": "TASK", "confidence": 0.6752356853750017}]}], "abstractContent": [{"text": "This paper describes our participation in the shared task Named Entity Recognition in Twitter organized as part of the 2nd Workshop on Noisy User-generated Text.", "labels": [], "entities": [{"text": "Entity Recognition in Twitter", "start_pos": 64, "end_pos": 93, "type": "TASK", "confidence": 0.7955957055091858}]}, {"text": "The shared task comprises two sub-tasks, concerning a) the detection of the boundaries of entities and b) the classification of the entities into one of 10 possible types.", "labels": [], "entities": [{"text": "detection of the boundaries of entities", "start_pos": 59, "end_pos": 98, "type": "TASK", "confidence": 0.8154171109199524}]}, {"text": "The proposed approach is based on Linked Open Data for extracting rich features along with standard ones which are then used by a learning to search algorithm in order to build the tagger.", "labels": [], "entities": []}, {"text": "The submitted system scored 46.16 and 60.24 in terms of F-measure and ranked 2nd and 3rd for the classification and segmentation tasks respectively.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 56, "end_pos": 65, "type": "METRIC", "confidence": 0.9992949962615967}, {"text": "segmentation", "start_pos": 116, "end_pos": 128, "type": "TASK", "confidence": 0.6566046476364136}]}], "introductionContent": [{"text": "Named-Entity Recognition (NER) is a well-studied task for over two decades now with notable success for noise-free and grammatically well-structured documents.", "labels": [], "entities": [{"text": "Named-Entity Recognition (NER)", "start_pos": 0, "end_pos": 30, "type": "TASK", "confidence": 0.8277431130409241}]}, {"text": "The final goal of a NER system is to classify textual segments in a predefined set of categories, for example persons, organizations, and locations.", "labels": [], "entities": [{"text": "NER", "start_pos": 20, "end_pos": 23, "type": "TASK", "confidence": 0.9522128105163574}]}, {"text": "While current NER systems achieve very high performance fora narrow set of entities, in applications like in Twitter 1 where text is short, using an informal style and with an unreliable use of capitalization, the recognition of entities becomes a challenging task (.", "labels": [], "entities": []}, {"text": "For example, in the 2015 NER in Twitter competition the best system achieved an F-score of around 56% for ten entities (.", "labels": [], "entities": [{"text": "NER in Twitter competition", "start_pos": 25, "end_pos": 51, "type": "TASK", "confidence": 0.5109946727752686}, {"text": "F-score", "start_pos": 80, "end_pos": 87, "type": "METRIC", "confidence": 0.9993879795074463}]}, {"text": "In this context, the shared task for Named-Entity Recognition in Twitter has been organized in order to provide standard benchmarks for this task.", "labels": [], "entities": [{"text": "Named-Entity Recognition", "start_pos": 37, "end_pos": 61, "type": "TASK", "confidence": 0.6831740885972977}]}, {"text": "In this paper we describe our participation in the 2nd edition of the Named-Entity Recognition in Twitter shared task which was organized in the framework of the Workshop on Noisy User-generated Text.", "labels": [], "entities": [{"text": "Named-Entity Recognition in Twitter shared task", "start_pos": 70, "end_pos": 117, "type": "TASK", "confidence": 0.8471820304791132}]}, {"text": "We cast the problem as a sequence labeling task and used a learning to search approach for solving it.", "labels": [], "entities": [{"text": "sequence labeling task", "start_pos": 25, "end_pos": 47, "type": "TASK", "confidence": 0.7655610044797262}]}, {"text": "The proposed system, called Talos, combines an approach based on Linked-Open Data for extracting rich contextual features along with standard ones that are usually included in NER systems.", "labels": [], "entities": []}, {"text": "A total of 3,814 annotated tweets were provided by the organizers while the test set contained 3,850 examples.", "labels": [], "entities": []}, {"text": "Our system ranked second in the classification and third in the segmentation (only detecting the boundaries) sub-tasks achieving F-scores of 46.16 and 60.24 respectively.", "labels": [], "entities": [{"text": "F-scores", "start_pos": 129, "end_pos": 137, "type": "METRIC", "confidence": 0.9988250136375427}]}, {"text": "In the following sections we present a description of the method we developed for tackling the tasks and provide evaluations of its performance.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1 presents the distribution for each  entity type in the training and development sets. We observe that person, geo-loc and other are  the dominating classes in both sets.", "labels": [], "entities": []}, {"text": " Table 3: Results for the no-types task in terms of Precision, Recall and F-score. The development test of  2016 corresponds to the test set of 2015 for which we present the best two systems.", "labels": [], "entities": [{"text": "Precision", "start_pos": 52, "end_pos": 61, "type": "METRIC", "confidence": 0.9992712140083313}, {"text": "Recall", "start_pos": 63, "end_pos": 69, "type": "METRIC", "confidence": 0.993109941482544}, {"text": "F-score", "start_pos": 74, "end_pos": 81, "type": "METRIC", "confidence": 0.9966543912887573}]}, {"text": " Table 4: Results for the no-entity task. The development test of 2016 corresponds to the test set of 2015  for which we present the best two systems.", "labels": [], "entities": []}, {"text": " Table 5: Results per entity type for Talos.", "labels": [], "entities": []}]}