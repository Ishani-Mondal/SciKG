{"title": [{"text": "Insights from Russian second language readability classification: complexity-dependent training requirements, and feature evaluation of multiple categories", "labels": [], "entities": [{"text": "Russian second language readability classification", "start_pos": 14, "end_pos": 64, "type": "TASK", "confidence": 0.5283575356006622}]}], "abstractContent": [{"text": "I investigate Russian second language read-ability assessment using a machine-learning approach with a range of lexical, morphological , syntactic, and discourse features.", "labels": [], "entities": [{"text": "Russian second language read-ability assessment", "start_pos": 14, "end_pos": 61, "type": "TASK", "confidence": 0.5426403522491455}]}, {"text": "Testing the model with anew collection of Russian L2 readability corpora achieves an F-score of 0.671 and adjacent accuracy 0.919 on a 6-level classification task.", "labels": [], "entities": [{"text": "F-score", "start_pos": 85, "end_pos": 92, "type": "METRIC", "confidence": 0.9996121525764465}, {"text": "adjacent", "start_pos": 106, "end_pos": 114, "type": "METRIC", "confidence": 0.9334160089492798}, {"text": "accuracy", "start_pos": 115, "end_pos": 123, "type": "METRIC", "confidence": 0.7116743922233582}]}, {"text": "Information gain and feature subset evaluation shows that morphological features are collectively the most informative.", "labels": [], "entities": [{"text": "Information gain", "start_pos": 0, "end_pos": 16, "type": "TASK", "confidence": 0.7413569986820221}]}, {"text": "Learning curves for binary classifiers reveal that fewer training data are needed to distinguish between beginning reading levels than are needed to distinguish between intermediate reading levels.", "labels": [], "entities": []}], "introductionContent": [{"text": "Reading is one of the core skills in both first and second language learning, and it is arguably the most important means of accessing information in the modern world.", "labels": [], "entities": []}, {"text": "Modern second language pedagogy typically includes reading as a major component of foreign language instruction.", "labels": [], "entities": []}, {"text": "There has been debate regarding the use of authentic materials versus contrived materials, where authentic materials are defined as \"A stretch of real language, produced by areal speaker or writer fora real audience and designed to convey areal message of some sort\".", "labels": [], "entities": []}, {"text": "Many empirical studies have demonstrated advantages to using authentic materials, including increased linguistic, pragmatic, and discourse competence.", "labels": [], "entities": []}, {"text": "However, notes that \"Finding appropriate authentic texts and designing tasks for them can, in itself, bean extremely time-consuming process.\"", "labels": [], "entities": []}, {"text": "An appropriate text should arguably be interesting, linguistically relevant, authentic, recent, and at the appropriate reading level.", "labels": [], "entities": []}, {"text": "Tools to automatically identify a given text's complexity would help remove one of the most timeconsuming steps of text selection, allowing teachers to focus on pedagogical aspects of text selection.", "labels": [], "entities": [{"text": "text selection", "start_pos": 115, "end_pos": 129, "type": "TASK", "confidence": 0.7230076640844345}, {"text": "text selection", "start_pos": 184, "end_pos": 198, "type": "TASK", "confidence": 0.7188563793897629}]}, {"text": "Furthermore, these tools would also make it possible for learners to find appropriate texts for themselves.", "labels": [], "entities": []}, {"text": "A thorough conceptual and historical overview of readability research can be found in Vajjala (2015, \u00a72.2).", "labels": [], "entities": [{"text": "Vajjala (2015, \u00a72.2)", "start_pos": 86, "end_pos": 106, "type": "DATASET", "confidence": 0.9001211524009705}]}, {"text": "The last decade has seen arise in research on readability classification, primarily focused on English, but also including French, German, Italian, Portuguese, and Swedish (.", "labels": [], "entities": [{"text": "readability classification", "start_pos": 46, "end_pos": 72, "type": "TASK", "confidence": 0.8244641721248627}]}, {"text": "Broadly speaking, these languages have limited morphology in comparison with Russian, which has relatively rich morphology among major world languages.", "labels": [], "entities": []}, {"text": "It is therefore not surprising that morphology has received little attention in studies of automatic readability classification.", "labels": [], "entities": [{"text": "automatic readability classification", "start_pos": 91, "end_pos": 127, "type": "TASK", "confidence": 0.6388360063234965}]}, {"text": "One important exception is which examines lexical, syntactic and morphological features with a two-level corpus of German magazine articles.", "labels": [], "entities": []}, {"text": "In their study, morphological features are collectively the most predictive category of features.", "labels": [], "entities": []}, {"text": "Furthermore, when combining feature categories in groups of two or three, the highest performing combinations included the morphology category.", "labels": [], "entities": []}, {"text": "If morphological features figure so prominently in German readability classification, then there is good reason to expect that they will be similarly informative for Russian second-language readability classification.", "labels": [], "entities": [{"text": "German readability classification", "start_pos": 51, "end_pos": 84, "type": "TASK", "confidence": 0.5261375109354655}, {"text": "Russian second-language readability classification", "start_pos": 166, "end_pos": 216, "type": "TASK", "confidence": 0.5550455451011658}]}, {"text": "This article explores to what extent textual features based on morphological analysis can lead to successful readability classification of Russian texts for language learning.", "labels": [], "entities": []}, {"text": "In Section 2, I give an overview of previous research on readability, including some work on Russian.", "labels": [], "entities": []}, {"text": "The corpora collected for use in this study are described in Section 3.", "labels": [], "entities": []}, {"text": "The features extracted for machine learning are outlined in Section 4.", "labels": [], "entities": [{"text": "machine learning", "start_pos": 27, "end_pos": 43, "type": "TASK", "confidence": 0.7626327276229858}]}, {"text": "Results are discussed in Sections 5 and 6, and conclusions and outlook for future research are presented in Section 7.", "labels": [], "entities": []}], "datasetContent": [{"text": "As summarized in Section 4.5, this study makes use of 179 features, divided into 7 categories: DISC, LEXC, LEXF, LEXV, MORPH, SENT, and SYNT.", "labels": [], "entities": [{"text": "LEXF", "start_pos": 107, "end_pos": 111, "type": "METRIC", "confidence": 0.8980225324630737}, {"text": "LEXV", "start_pos": 113, "end_pos": 117, "type": "METRIC", "confidence": 0.8949880003929138}, {"text": "MORPH", "start_pos": 119, "end_pos": 124, "type": "METRIC", "confidence": 0.9639818668365479}, {"text": "SENT", "start_pos": 126, "end_pos": 130, "type": "METRIC", "confidence": 0.9245139956474304}]}, {"text": "Many of the features used in this study are taken from previous research of related topics, and some features are proposed for the first time here.", "labels": [], "entities": []}, {"text": "Previous researchers of Russian readability have not included morphological features, so the results of these features are of particular interest here.", "labels": [], "entities": []}, {"text": "In this section, I explore the extent to which the selected corpora can support the relevance and impact of these features in Russian second language readability classification.", "labels": [], "entities": [{"text": "Russian second language readability classification", "start_pos": 126, "end_pos": 176, "type": "TASK", "confidence": 0.5686123490333557}]}, {"text": "One rough test for the value of each category of features is to run crossvalidation with models trained on only one category of features.", "labels": [], "entities": []}, {"text": "In  The results in show that MORPH, has the highest F-score of any single category, with an Fscore just 0.053 below a model trained on all 179 features.", "labels": [], "entities": [{"text": "MORPH", "start_pos": 29, "end_pos": 34, "type": "METRIC", "confidence": 0.5190349221229553}, {"text": "F-score", "start_pos": 52, "end_pos": 59, "type": "METRIC", "confidence": 0.9994457364082336}, {"text": "Fscore", "start_pos": 92, "end_pos": 98, "type": "METRIC", "confidence": 0.9980173110961914}]}, {"text": "True comparisons between categories are problematic because the number of features per category varies significantly.", "labels": [], "entities": []}, {"text": "In order to evaluate the usefulness of each feature as a member of a feature set, I used the correlationbased feature subset selection algorithm (CfsSubsetEval), which selects the most predictive subset of features by minimizing redundant information, based on feature correlation.", "labels": [], "entities": []}, {"text": "Out of 179 features, the CfsSubsetEval algorithm selected 32 features.", "labels": [], "entities": []}, {"text": "Many of the features selected for the optimal feature set are also among the top 30 most informative features according to information gain.", "labels": [], "entities": []}, {"text": "However, the morphological features-which had only 7 features among the top 30 for information gain-now include 14 features, which indicates that although these features are not as informative, the information that they contribute is unique.", "labels": [], "entities": [{"text": "information gain-now", "start_pos": 83, "end_pos": 103, "type": "TASK", "confidence": 0.8695842027664185}]}, {"text": "A classifier trained on only these 32 features with the Combined corpus achieved precision 0.674 and recall 0.665 (F-score 0.659), which is only 0.01 worse than the model trained on all 179 features.", "labels": [], "entities": [{"text": "Combined corpus", "start_pos": 56, "end_pos": 71, "type": "DATASET", "confidence": 0.9371204078197479}, {"text": "precision", "start_pos": 81, "end_pos": 90, "type": "METRIC", "confidence": 0.9993139505386353}, {"text": "recall", "start_pos": 101, "end_pos": 107, "type": "METRIC", "confidence": 0.9995278120040894}, {"text": "F-score", "start_pos": 115, "end_pos": 122, "type": "METRIC", "confidence": 0.9747870564460754}]}], "tableCaptions": [{"text": " Table 1: Distribution of documents per level for each corpus", "labels": [], "entities": []}, {"text": " Table 2: Median words per document for each level of each", "labels": [], "entities": []}, {"text": " Table 3: Distribution of features across categories", "labels": [], "entities": [{"text": "Distribution of features", "start_pos": 10, "end_pos": 34, "type": "TASK", "confidence": 0.8489313920338949}]}, {"text": " Table 4: Baseline and RandomForest results with Combined", "labels": [], "entities": []}, {"text": " Table 5: Confusion matrix for RandomForest, all features,", "labels": [], "entities": []}, {"text": " Table 6. Red Kalinka and LQsupp (the  second largest subcorpus of LingQ)-which were  judged to be the most reliable subcorpora-were  also examined individually.", "labels": [], "entities": [{"text": "LingQ", "start_pos": 67, "end_pos": 72, "type": "DATASET", "confidence": 0.9698306918144226}]}, {"text": " Table 6: Evalution metrics for binary classifiers: RandomFor-", "labels": [], "entities": [{"text": "RandomFor-", "start_pos": 52, "end_pos": 62, "type": "DATASET", "confidence": 0.8557249307632446}]}, {"text": " Table 7: Precision, recall, and F-score for six-level Random", "labels": [], "entities": [{"text": "Precision", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.999224066734314}, {"text": "recall", "start_pos": 21, "end_pos": 27, "type": "METRIC", "confidence": 0.9990002512931824}, {"text": "F-score", "start_pos": 33, "end_pos": 40, "type": "METRIC", "confidence": 0.9994156360626221}]}]}