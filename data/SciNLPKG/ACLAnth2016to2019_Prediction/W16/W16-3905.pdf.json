{"title": [{"text": "From Noisy Questions to Minecraft Texts: Annotation Challenges in Extreme Syntax Scenarios", "labels": [], "entities": []}], "abstractContent": [{"text": "User-generated content presents many challenges for its automatic processing.", "labels": [], "entities": []}, {"text": "While many of them do come from out-of-vocabulary effects, others spawn from different linguistic phenomena such as unusual syntax.", "labels": [], "entities": []}, {"text": "In this work we present a French three-domain data set made up of question headlines from a cooking forum, game chat logs and associated forums from two popular online games (MINECRAFT & LEAGUE OF LEGENDS).", "labels": [], "entities": [{"text": "French three-domain data set", "start_pos": 26, "end_pos": 54, "type": "DATASET", "confidence": 0.8615924417972565}, {"text": "MINECRAFT", "start_pos": 175, "end_pos": 184, "type": "METRIC", "confidence": 0.7524502277374268}]}, {"text": "We chose these domains because they encompass different degrees of lexical and syntactic compliance with canonical language.", "labels": [], "entities": []}, {"text": "We conduct an automatic and manual evaluation of the difficulties of processing these domains for part-of-speech prediction, and introduce a pilot study to determine whether dependency analysis lends itself well to annotate these data.", "labels": [], "entities": [{"text": "part-of-speech prediction", "start_pos": 98, "end_pos": 123, "type": "TASK", "confidence": 0.7491339445114136}]}, {"text": "We also discuss the development cost of our data set.", "labels": [], "entities": []}], "introductionContent": [{"text": "The continuous growth of the volume of user-generated content (UGC) published on the web stresses the need for efficient way to automatically process this type of data.", "labels": [], "entities": []}, {"text": "Yet not only the volume of UGC increases; it also becomes increasingly varied, resulting in the need for domain-and register-adaptation methods and resources for processing UGC in all its diversity.", "labels": [], "entities": []}, {"text": "In this work, we present a feasibility study on dependency syntax annotation for three UGC domains in French, namely a cooking forum, in-game chat logs, and associated gaming forums.", "labels": [], "entities": []}, {"text": "While these data sources are very different, they share the characteristic that their content was produced within time or space constraints.", "labels": [], "entities": []}, {"text": "Such constraints force the users to resort to a variety of linguistic strategies to efficiently convey their message.", "labels": [], "entities": []}, {"text": "The work described here shows that, on top of the well-known problem of out-of-vocabulary words, automatic annotation and processing of UGC presents a double challenge.", "labels": [], "entities": []}, {"text": "First, in order to interpret most of the data , it is crucial to take into account the interplay between context and domain knowledge on the one hand and their linguistic impact.", "labels": [], "entities": []}, {"text": "This is because most messages can only be fully analysed with a good knowledge of the domain and context at hand.", "labels": [], "entities": []}, {"text": "For instance, in-game chat logs can only be understood with a knowledge of the video game being played and of many game-specific terms, a representation of the game situation when a chat message is written and of, as well as a model of the ongoing dialogue, as such data is conversational by nature.", "labels": [], "entities": []}, {"text": "Also, time-or space-constrained writing favors fragmentary writing that is more prone to ellipses, which makes linguistic analysis, especially parsing, more difficult.", "labels": [], "entities": []}, {"text": "In addition to this highly contextual nature, the many idiosyncrasies plaguing UGC and make its analysis more challenging than regular out-of-domain text force most morpho-syntactic processing to be extremely robust at all levels of analysis.", "labels": [], "entities": []}, {"text": "In Section 3 we describe the data collection process, and give a first quantiative description of how our datasets are different from standard datasets.", "labels": [], "entities": [{"text": "data collection", "start_pos": 29, "end_pos": 44, "type": "TASK", "confidence": 0.7375593483448029}]}, {"text": "Two of our datasets were already annotated, and we manually annotated the third one.", "labels": [], "entities": []}, {"text": "In Section 4 we provide a threefold categorisation of lexical variation in UGC.", "labels": [], "entities": []}, {"text": "Finally, Section 5 is dedicated to our feasibility study regarding dependency annotation of our data using the Universal Dependencies annotation scheme.", "labels": [], "entities": []}, {"text": "It also includes a brief discussion about annotation costs, an issue rarely explicitely discussed.", "labels": [], "entities": []}, {"text": "Our contribution is threefold: (i) an empirical account of the phenomena behind domain-shift performance drops in French UGC data processing, (ii) a syntactic study on the applicability of Universal Dependencies to French UGC, and (iii) the first corpus obtained from MINECRAFT and LEAGUE OF LEGENDS gaming logs.", "labels": [], "entities": [{"text": "French UGC data processing", "start_pos": 114, "end_pos": 140, "type": "DATASET", "confidence": 0.8637478053569794}, {"text": "French UGC", "start_pos": 215, "end_pos": 225, "type": "DATASET", "confidence": 0.8452651798725128}, {"text": "MINECRAFT", "start_pos": 268, "end_pos": 277, "type": "DATASET", "confidence": 0.794623851776123}]}, {"text": "All corpora and annotations are freely available.", "labels": [], "entities": []}, {"text": "Before the global availability of social-media feeds, studies on the difficulties of out-of-domain statistical parsing have been focusing mainly on slightly different newspaper texts), biomedical data ( or balanced corpora mixing different genres).", "labels": [], "entities": [{"text": "statistical parsing", "start_pos": 99, "end_pos": 118, "type": "TASK", "confidence": 0.7620192468166351}]}, {"text": "For such data, which is as edited as standard data sources, the problem is \"simply\" a matter of domain adaptation.", "labels": [], "entities": []}, {"text": "It is far from being the case for UGC data, as shown by.", "labels": [], "entities": [{"text": "UGC data", "start_pos": 34, "end_pos": 42, "type": "DATASET", "confidence": 0.8424077033996582}]}, {"text": "Indeed, in her seminal work on parsing web data, different issues preventing reasonably good parsing performance were highlighted; most of them were tied to lexical differences (coming from either genuine unknown words, typographical divergences, bad segmentation, etc.) or syntactic structures absent from training data (imperative usage, direct discourse, slang, etc.).", "labels": [], "entities": [{"text": "parsing web", "start_pos": 31, "end_pos": 42, "type": "TASK", "confidence": 0.9167967736721039}]}, {"text": "This suboptimal parsing behavior on web data was in turn confirmed in follow-up works on Twitter and IRC chat).", "labels": [], "entities": []}, {"text": "They were again confirmed during the SANCL shared task, organised by Google, aimed at assessing the performances of parsers on various genres of Web texts.", "labels": [], "entities": [{"text": "SANCL shared task", "start_pos": 37, "end_pos": 54, "type": "TASK", "confidence": 0.4587593774000804}]}, {"text": "Foster (2010) and noted that simple lexical and tokenisation convention adaptation to the Wall-Street Journal text genre could increase the parsing performance by a large margin.", "labels": [], "entities": [{"text": "tokenisation convention adaptation", "start_pos": 48, "end_pos": 82, "type": "TASK", "confidence": 0.8519277373949686}, {"text": "Wall-Street Journal text genre", "start_pos": 90, "end_pos": 120, "type": "DATASET", "confidence": 0.9506298303604126}]}, {"text": "In addition,  showed that a certain amount of normalisation brought a large improvement in POS tagger performance of French social media texts.", "labels": [], "entities": [{"text": "POS tagger", "start_pos": 91, "end_pos": 101, "type": "TASK", "confidence": 0.7124235033988953}]}, {"text": "These normalisation steps mostly apply at the lexical level, at the very definition of what constitutes a minimal unit.", "labels": [], "entities": []}, {"text": "attempt to quantify how much of the domain-specific variation of POS labeling is a result of different interpretations, and how much is arguably just noise.", "labels": [], "entities": [{"text": "POS labeling", "start_pos": 65, "end_pos": 77, "type": "TASK", "confidence": 0.7578191459178925}]}, {"text": "Regarding the study of French UGC, our starting point is the part-of-speech and phrase-structure annotation guidelines by . However, we conduct our syntactic analysis in terms of dependency structures.", "labels": [], "entities": [{"text": "French UGC", "start_pos": 23, "end_pos": 33, "type": "DATASET", "confidence": 0.9041043519973755}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 2: noisiness levels for each of our sub-corpora.", "labels": [], "entities": []}, {"text": " Table 3: POS tagging results using MElt trained on the French Treebank with and without normalisation.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 10, "end_pos": 21, "type": "TASK", "confidence": 0.7855594158172607}, {"text": "French Treebank", "start_pos": 56, "end_pos": 71, "type": "DATASET", "confidence": 0.9669575989246368}]}, {"text": " Table 5: Corpus-wise percentages of annotation difficulties.", "labels": [], "entities": []}, {"text": " Table 6: Treebanking Cost at the Alpage team. Morph.: morpho-syntactic annotation, Const: Phrase-based annota-", "labels": [], "entities": [{"text": "Alpage team", "start_pos": 34, "end_pos": 45, "type": "DATASET", "confidence": 0.9494603872299194}]}]}