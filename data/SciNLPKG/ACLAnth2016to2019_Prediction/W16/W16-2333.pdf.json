{"title": [], "abstractContent": [{"text": "This paper presents the JU-USAAR English-German domain adaptive machine translation (MT) system submitted to the IT domain translation task organized in WMT-2016.", "labels": [], "entities": [{"text": "JU-USAAR English-German domain adaptive machine translation (MT)", "start_pos": 24, "end_pos": 88, "type": "TASK", "confidence": 0.7286798622873094}, {"text": "IT domain translation task organized in WMT-2016", "start_pos": 113, "end_pos": 161, "type": "TASK", "confidence": 0.7160559807504926}]}, {"text": "Our system brings improvements over the in-domain base-line system by incorporating out-domain knowledge.", "labels": [], "entities": []}, {"text": "We applied two methodolo-gies to accelerate the performance of our in-domain MT system: (i) additional training material extraction from out-domain data using data selection method, and (ii) language model and translation model adaptation through interpolation.", "labels": [], "entities": [{"text": "MT", "start_pos": 77, "end_pos": 79, "type": "TASK", "confidence": 0.9570779204368591}, {"text": "translation model adaptation", "start_pos": 210, "end_pos": 238, "type": "TASK", "confidence": 0.8448176185290018}]}, {"text": "Our primary submission obtained a BLEU score of 34.5 (14.5 absolute and 72.5% relative improvements over baseline) and a TER score of 54.0 (14.7 absolute and 21.4% relative improvements over baseline).", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 34, "end_pos": 44, "type": "METRIC", "confidence": 0.9784767925739288}, {"text": "TER score", "start_pos": 121, "end_pos": 130, "type": "METRIC", "confidence": 0.9824432134628296}]}], "introductionContent": [{"text": "Statistical Machine Translation (SMT) is the currently dominant MT technology.", "labels": [], "entities": [{"text": "Statistical Machine Translation (SMT)", "start_pos": 0, "end_pos": 37, "type": "TASK", "confidence": 0.8620742162068685}, {"text": "MT", "start_pos": 64, "end_pos": 66, "type": "TASK", "confidence": 0.9908281564712524}]}, {"text": "The underlying statistical models in SMT always tend to closely approximate the empirical distributions of the bilingual training data and monolingual target-language text.", "labels": [], "entities": [{"text": "SMT", "start_pos": 37, "end_pos": 40, "type": "TASK", "confidence": 0.9929231405258179}]}, {"text": "However, the performance of SMT systems quickly degrades when testing conditions deviate from training conditions.", "labels": [], "entities": [{"text": "SMT", "start_pos": 28, "end_pos": 31, "type": "TASK", "confidence": 0.9940845370292664}]}, {"text": "In order to achieve optimal performance, an SMT system should be trained on data from the same domain.", "labels": [], "entities": [{"text": "SMT", "start_pos": 44, "end_pos": 47, "type": "TASK", "confidence": 0.9947073459625244}]}, {"text": "Now-a-days domain adaptation has gained interest in SMT to cope with this performance drop.", "labels": [], "entities": [{"text": "domain adaptation", "start_pos": 11, "end_pos": 28, "type": "TASK", "confidence": 0.7521577179431915}, {"text": "SMT", "start_pos": 52, "end_pos": 55, "type": "TASK", "confidence": 0.9901871681213379}]}, {"text": "The basic aim of domain adaptation is to maintain the identity of the in-domain data while using the best of the out-domain data.", "labels": [], "entities": [{"text": "domain adaptation", "start_pos": 17, "end_pos": 34, "type": "TASK", "confidence": 0.7932673990726471}]}, {"text": "However, large amount of additional out-domain data may bias the resultant distribution towards the out-domain.", "labels": [], "entities": []}, {"text": "In practice, it is often difficult to obtain sufficient amount of in-domain parallel data to train a system which can provide good performance in a specific domain.", "labels": [], "entities": []}, {"text": "The performance of an in-domain model can be improved by selecting a subset from the out-domain data which is very similar to the indomain data, or by re-weighting the probability distributions () in favor of the in-domain data.", "labels": [], "entities": []}, {"text": "In this task, the information technology (IT) domain English-German parallel corpus released in the WMT-2016 IT-domain shared task serves as the in-domain data and the Europarl, News and Common Crawl English-German parallel corpus released in the Translation Task are treated as outdomain data.", "labels": [], "entities": [{"text": "WMT-2016 IT-domain shared task", "start_pos": 100, "end_pos": 130, "type": "DATASET", "confidence": 0.8298285007476807}, {"text": "Europarl", "start_pos": 168, "end_pos": 176, "type": "DATASET", "confidence": 0.9617694616317749}, {"text": "News and Common Crawl English-German parallel corpus", "start_pos": 178, "end_pos": 230, "type": "DATASET", "confidence": 0.6947557628154755}, {"text": "Translation Task", "start_pos": 247, "end_pos": 263, "type": "TASK", "confidence": 0.9052952527999878}]}, {"text": "In this paper we describe the joint submission of Jadavpur University (JU) and Saarland University (USAAR) English-German machine translation (MT) system (JU-USAAR) to the shared task on IT domain translation organized in WMT-2016.", "labels": [], "entities": [{"text": "English-German machine translation (MT)", "start_pos": 107, "end_pos": 146, "type": "TASK", "confidence": 0.7459767411152521}, {"text": "IT domain translation", "start_pos": 187, "end_pos": 208, "type": "TASK", "confidence": 0.6384807328383127}, {"text": "WMT-2016", "start_pos": 222, "end_pos": 230, "type": "DATASET", "confidence": 0.6110220551490784}]}, {"text": "In our approach we initially applied data selection method where we directly measured cross entropy for the source side of the text; successively we applied Moore and Lewis (2010) method of data selection and ranked the out-domain bilingual parallel data according to cross entropy difference.", "labels": [], "entities": []}, {"text": "Finally, we built domain specific language models on both in-domain and selected out-domain target language monolingual corpus, linearly interpolate them choosing weights that minimize perplexity on a held out in-domain development set.", "labels": [], "entities": []}, {"text": "In addition, we also interpolated the translation models trained on the in-domain and selected out-domain parallel corpora.", "labels": [], "entities": []}, {"text": "However, instead of using bilingual cross-entropy difference, we applied bilingual cross-perplexity difference to model our data selection process.", "labels": [], "entities": []}, {"text": "first proposed domain adaptation in SMT by integrating terminological lexicons in the translation model, as a result of which there was a significant reduction in word error rate (WER).", "labels": [], "entities": [{"text": "domain adaptation", "start_pos": 15, "end_pos": 32, "type": "TASK", "confidence": 0.7205133885145187}, {"text": "SMT", "start_pos": 36, "end_pos": 39, "type": "TASK", "confidence": 0.9857361912727356}, {"text": "word error rate (WER)", "start_pos": 163, "end_pos": 184, "type": "METRIC", "confidence": 0.882032165924708}]}, {"text": "Over the last decade, many researchers) investigated the problem of combining multi-domain datasets.", "labels": [], "entities": []}], "datasetContent": [{"text": "We first accumulate all the domain specific corpus and clean them.", "labels": [], "entities": []}, {"text": "We also use out of domain data to accelerate the performance of the in-domain MT system.", "labels": [], "entities": [{"text": "MT", "start_pos": 78, "end_pos": 80, "type": "TASK", "confidence": 0.9726019501686096}]}, {"text": "The following subsections describe the datasets used for the experiments, detailed experimental settings and systematic evaluation on both the development set and test set.", "labels": [], "entities": []}, {"text": "In-domain Data: The detailed statistics of indomain data is reported in.", "labels": [], "entities": []}, {"text": "We considered all the data provided by the WMT-2016 organizers for the IT translation task.", "labels": [], "entities": [{"text": "WMT-2016 organizers", "start_pos": 43, "end_pos": 62, "type": "DATASET", "confidence": 0.9108261466026306}, {"text": "IT translation task", "start_pos": 71, "end_pos": 90, "type": "TASK", "confidence": 0.8449813524881998}]}, {"text": "We combined all data and performed cleaning in two steps: (i) Cleaning-1: following the cleaning process described in (, and (ii) Cleaning 2: using the Moses () corpus cleaning scripts with minimum and maximum number of tokens set to 1 and 80 respectively.", "labels": [], "entities": []}, {"text": "Additionally, 1000 sentences are used for development set ('Batch 1' in) and anther 1000 sentences are used for development test set ('Batch2' in.", "labels": [], "entities": []}, {"text": "Out-domain Data: We utilized all the parallel training data provided by the WMT-2016 shared task organizers for the English-German translation task.", "labels": [], "entities": [{"text": "WMT-2016 shared task organizers", "start_pos": 76, "end_pos": 107, "type": "DATASET", "confidence": 0.8388584554195404}]}, {"text": "The out of domain training data includes Europarl, News Commentary and Common Crawl.", "labels": [], "entities": [{"text": "Europarl", "start_pos": 41, "end_pos": 49, "type": "DATASET", "confidence": 0.9822753667831421}, {"text": "Common Crawl", "start_pos": 71, "end_pos": 83, "type": "DATASET", "confidence": 0.9078227579593658}]}, {"text": "this corpus is noisy and contains some non-German, as well as, non-English words and sentences.", "labels": [], "entities": []}, {"text": "Therefore, we applied a language identifier (Shuyo, 2010) on both bilingual EnglishGerman parallel data and monolingual German corpora.", "labels": [], "entities": [{"text": "EnglishGerman parallel data", "start_pos": 76, "end_pos": 103, "type": "DATASET", "confidence": 0.7509914040565491}]}, {"text": "We discarded those parallel sentences from the bilingual training data which were detected as belonging to some different languages by the language identifier.", "labels": [], "entities": []}, {"text": "The same method was also applied to the monolingual data.", "labels": [], "entities": []}, {"text": "Successively, the corpus cleaning process was carried out first by calculating the global mean ratio of the number of characters in a source sentence to that in the corresponding target sentence and then filtering out sentence pairs that exceed or fall below 20% of the global ratio ().", "labels": [], "entities": [{"text": "corpus cleaning", "start_pos": 18, "end_pos": 33, "type": "TASK", "confidence": 0.7317939102649689}, {"text": "global mean ratio", "start_pos": 83, "end_pos": 100, "type": "METRIC", "confidence": 0.7747052113215128}]}, {"text": "Tokenization and punctuation normalization were performed using Moses scripts.", "labels": [], "entities": [{"text": "punctuation normalization", "start_pos": 17, "end_pos": 42, "type": "TASK", "confidence": 0.7446247935295105}]}, {"text": "In the final step of cleaning, we filtered the parallel training data on maximum allowable sentence length of 80 and sentence length ratio of 1:2 (either direction).", "labels": [], "entities": [{"text": "sentence length ratio", "start_pos": 117, "end_pos": 138, "type": "METRIC", "confidence": 0.6135194003582001}]}, {"text": "Approximately 36% sentences were removed from the total training data during the cleaning process.", "labels": [], "entities": []}, {"text": "shows the out-domain data statistics after filtering.", "labels": [], "entities": []}, {"text": "We used the standard log-linear PB-SMT model for our experiments.", "labels": [], "entities": []}, {"text": "All the experiments were carried out using a maximum phrase length of 7 for the translation model and 5-gram language models.", "labels": [], "entities": []}, {"text": "The other experimental settings involved word alignment model between EN-DE trained with Berkeley Aligner ().", "labels": [], "entities": [{"text": "word alignment", "start_pos": 41, "end_pos": 55, "type": "TASK", "confidence": 0.8198902308940887}]}, {"text": "The phraseextraction heuristics of ( were used to build the phrase-based SMT systems.", "labels": [], "entities": [{"text": "SMT", "start_pos": 73, "end_pos": 76, "type": "TASK", "confidence": 0.855562150478363}]}, {"text": "The reordering model was trained with the hierarchical, monotone, swap, left to right bidirectional (hier-mslr-bidirectional) () method and conditioned on both the source and target languages.", "labels": [], "entities": []}, {"text": "The 5-gram language models were built using KenLM.", "labels": [], "entities": [{"text": "KenLM", "start_pos": 44, "end_pos": 49, "type": "DATASET", "confidence": 0.6857410669326782}]}, {"text": "Phrase pairs that occur only once in the training data are assigned an unduly high probability mass (i.e., 1).", "labels": [], "entities": []}, {"text": "To alleviate this shortcoming, we performed smoothing of the phrase table using the Good-Turing smoothing technique ().", "labels": [], "entities": []}, {"text": "System tuning was carried out using Minimum Error Rate Training (MERT)) on a held out development set (Batch1 in) of size 1,000 sentences provided by the WMT-2016 task organizers.", "labels": [], "entities": [{"text": "Minimum Error Rate Training (MERT))", "start_pos": 36, "end_pos": 71, "type": "METRIC", "confidence": 0.8152875985418048}, {"text": "WMT-2016 task organizers", "start_pos": 154, "end_pos": 178, "type": "DATASET", "confidence": 0.8800135453542074}]}, {"text": "After the parameters were tuned, decoding was carried out on the held out development test set (Batch2 in) as well as test set released by the shared task organizers.", "labels": [], "entities": [{"text": "development test set (Batch2 in)", "start_pos": 74, "end_pos": 106, "type": "DATASET", "confidence": 0.7223669631140572}]}, {"text": "We evaluated the systems using three well known automatic MT evaluation metrics: BLEU (), METEOR ( and TER ().", "labels": [], "entities": [{"text": "MT evaluation", "start_pos": 58, "end_pos": 71, "type": "TASK", "confidence": 0.8825066387653351}, {"text": "BLEU", "start_pos": 81, "end_pos": 85, "type": "METRIC", "confidence": 0.9991717338562012}, {"text": "METEOR", "start_pos": 90, "end_pos": 96, "type": "METRIC", "confidence": 0.9968581199645996}, {"text": "TER", "start_pos": 103, "end_pos": 106, "type": "METRIC", "confidence": 0.9977909326553345}]}, {"text": "The evaluation results of our baseline systems trained on in-domain and out-domain data are reported in", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: In-domain data statistics, Cleaning-1: tokenization and cleaning (Pal et al., 2015) and Cleaning- 2 is MOSES cleaner with minimum token is set to 1 and maximum 80", "labels": [], "entities": []}, {"text": " Table 2: Out-domain cleaned data statistics", "labels": [], "entities": [{"text": "Out-domain cleaned data statistics", "start_pos": 10, "end_pos": 44, "type": "DATASET", "confidence": 0.6473730504512787}]}, {"text": " Table 3: Experiment result of Baseline system trained on in-domain and out-domain data respectively", "labels": [], "entities": []}, {"text": " Table 4: Systematic evaluation on test set", "labels": [], "entities": []}]}