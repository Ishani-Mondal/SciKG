{"title": [], "abstractContent": [{"text": "Better Embeddings In the long run, the new tasks presented, promoted, and inspired by this workshop should act as a catalyst for faster both technological and scientific progress in representation learning and natural language understanding in general.", "labels": [], "entities": [{"text": "natural language understanding", "start_pos": 210, "end_pos": 240, "type": "TASK", "confidence": 0.6669749220212301}]}, {"text": "Specifically, they will drive the development of techniques for learning embeddings that add significant value to downstream applications, and, at the same time, enable a better understanding of the information that they capture.", "labels": [], "entities": []}, {"text": "iii Submissions We received 39 submissions, of which 26 were accepted.", "labels": [], "entities": []}], "introductionContent": [{"text": "This workshop deals with evaluating vector representations of linguistic units (morphemes, words, phrases, sentences, documents, etc).", "labels": [], "entities": []}, {"text": "What marks out these representations -which are colloquially referred to as embeddings -is that they are not trained with a specific application in mind, but rather to capture a characteristic of the data itself.", "labels": [], "entities": []}, {"text": "Another way to view their usage is through the lense of transfer learning; the embeddings are trained with one objective, but applied to assist some others.", "labels": [], "entities": []}, {"text": "We therefore do not discuss internal representations of deep models that are induced by and applied in the same task.", "labels": [], "entities": []}], "datasetContent": [{"text": "Since embeddings are trained in a generally unsupervised setting, it is often difficult to predict their usefulness fora particular task a priori.", "labels": [], "entities": []}, {"text": "The best way to assess an embedding's utility is, of course, to use it in a \"downstream\" application.", "labels": [], "entities": []}, {"text": "However, this knowledge tends not to transfer well among different tasks; for example, a 12 To avoid these issues, many papers have chosen to concentrate their evaluation on \"intrinsic\" (perhaps the more appropriate word is \"simple\") tasks such as lexical similarity (see, for example:.", "labels": [], "entities": []}, {"text": "However, recent work ( has shown that, just like sophisticated downstream applications, these intrinsic tasks are not accurate predictors of an embedding's utility in other tasks.", "labels": [], "entities": []}, {"text": "One notable issue with current evaluation options is their lack of diversity; despite the large number of intrinsic benchmarks (23 by some counts), and their many differences in size, quality, and domain, the majority of them focus on replicating human ratings of the similarity or relatedness of two words.", "labels": [], "entities": []}, {"text": "Even the challenge of analogy recovery through vector arithmetic, which seemed like a more nuanced metric (, has been shown to be reducible to a linear combination of lexical similarities (.", "labels": [], "entities": [{"text": "analogy recovery", "start_pos": 22, "end_pos": 38, "type": "TASK", "confidence": 0.9638911783695221}]}, {"text": "As a result, many other interesting linguistic phenomena that are inherent in downstream applications have not received enough attention from the representation learning community.", "labels": [], "entities": []}], "tableCaptions": []}