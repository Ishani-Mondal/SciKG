{"title": [], "abstractContent": [{"text": "Comparable corpora have been shown to be useful in several multilingual natural language processing (NLP) tasks.", "labels": [], "entities": []}, {"text": "Many previous papers have focused on how to improve the extraction of parallel data from this kind of corpus on different levels.", "labels": [], "entities": []}, {"text": "In this paper, we are interested in improving the quality of bilingual comparable corpora according to increased document alignment score.", "labels": [], "entities": [{"text": "document alignment score", "start_pos": 113, "end_pos": 137, "type": "METRIC", "confidence": 0.691702276468277}]}, {"text": "We describe our participation in the bilingual document alignment shared task of the First Conference on Machine Translation (WMT16).", "labels": [], "entities": [{"text": "bilingual document alignment shared task of the First Conference on Machine Translation (WMT16)", "start_pos": 37, "end_pos": 132, "type": "TASK", "confidence": 0.6769708375136058}]}, {"text": "We propose a technique based on source-to-target sentence-and word-based scores and the fraction of matched source named entities.", "labels": [], "entities": []}, {"text": "We performed our experiments on English-to-French document alignments for this bilingual task.", "labels": [], "entities": [{"text": "English-to-French document alignments", "start_pos": 32, "end_pos": 69, "type": "TASK", "confidence": 0.6315836807092031}]}], "introductionContent": [{"text": "Parallel corpora (or \"bitexts\"), comprising bilingual/multilingual texts extracted from parallel documents, are crucial resources for building SMT systems.", "labels": [], "entities": [{"text": "SMT", "start_pos": 143, "end_pos": 146, "type": "TASK", "confidence": 0.9940630793571472}]}, {"text": "Unfortunately, parallel documents area scarce resource for many language pairs with the exception of English, French, Spanish, Arabic, Chinese and some European languages included in Europarl 1 () and OPUS.", "labels": [], "entities": [{"text": "Europarl 1", "start_pos": 183, "end_pos": 193, "type": "DATASET", "confidence": 0.955056756734848}, {"text": "OPUS", "start_pos": 201, "end_pos": 205, "type": "DATASET", "confidence": 0.944871187210083}]}, {"text": "Furthermore, these existing available corpora do not cover some special domains or subdomains.", "labels": [], "entities": []}, {"text": "For the field of SMT, this can be problematic, because MT systems trained on data from a specific domain (e.g. parliamentary proceedings) perform poorly when applied to other domains, e.g. sports news articles.", "labels": [], "entities": [{"text": "SMT", "start_pos": 17, "end_pos": 20, "type": "TASK", "confidence": 0.9928279519081116}, {"text": "MT", "start_pos": 55, "end_pos": 57, "type": "TASK", "confidence": 0.991356611251831}]}, {"text": "As a result, the area of domain adaptation has been a hot topic in MT over the past few years.", "labels": [], "entities": [{"text": "domain adaptation", "start_pos": 25, "end_pos": 42, "type": "TASK", "confidence": 0.7474872767925262}, {"text": "MT", "start_pos": 67, "end_pos": 69, "type": "TASK", "confidence": 0.9699429869651794}]}, {"text": "One way to overcome this lack of data is to exploit comparable corpora which are much more easily available (.", "labels": [], "entities": []}, {"text": "A comparable corpus is a collection of texts composed independently in their respective languages and combined on the basis of similarity of content.", "labels": [], "entities": []}, {"text": "These are bilingual/multilingual documents that are comparable in content and form to various degrees and dimensions.", "labels": [], "entities": []}, {"text": "Potential sources of textual comparable corpora are the output from multilingual news organizations such as Agence France Presse (AFP), Xinhua, Reuters, CNN, BBC, etc.", "labels": [], "entities": []}, {"text": "These texts are widely available on the Web for many language pairs.", "labels": [], "entities": []}, {"text": "Another example is Euronews, which proposes news text in several languages clustered by domain (e.g. sports, finance, etc.).", "labels": [], "entities": [{"text": "Euronews", "start_pos": 19, "end_pos": 27, "type": "DATASET", "confidence": 0.9748493432998657}]}, {"text": "The degree of parallelism can vary considerably, from noisy parallel texts, to 'quasi parallel' texts.", "labels": [], "entities": []}, {"text": "No matter what data we are dealing with, if we want to automatically create large amounts of parallel documents for SMT training, the ability to detect parallel sentences or sub-sentences contained in these kinds of comparable corpus is crucial.", "labels": [], "entities": [{"text": "SMT training", "start_pos": 116, "end_pos": 128, "type": "TASK", "confidence": 0.9196049273014069}]}, {"text": "However, for some specific domains, such as news, the problem of document alignment can drastically reduce the quantity of the final parallel data extracted.", "labels": [], "entities": [{"text": "document alignment", "start_pos": 65, "end_pos": 83, "type": "TASK", "confidence": 0.7121874541044235}]}, {"text": "For example, showed that they were able to extract only 20% of an expected 1.9M-token parallel sentence collection using their automatic parallel data extraction method.", "labels": [], "entities": []}, {"text": "For this reason, they tried to improve this method by exploiting parallel phrases (i.e. not just parallel sentences) which increased the quantity of extracted data.", "labels": [], "entities": []}, {"text": "However, the precision of such automatic meth-ods is still much less than expected.", "labels": [], "entities": [{"text": "precision", "start_pos": 13, "end_pos": 22, "type": "METRIC", "confidence": 0.999519944190979}]}, {"text": "We contend that the main problem comes from the document alignment of such comparable corpora.", "labels": [], "entities": [{"text": "document alignment", "start_pos": 48, "end_pos": 66, "type": "TASK", "confidence": 0.6496513336896896}]}, {"text": "One of the challenges of our research is to build data and techniques for some under-resourced domains.", "labels": [], "entities": []}, {"text": "We propose to investigate the improvement of alignment of bilingual comparable documents in order to solve this problem.", "labels": [], "entities": []}, {"text": "Accordingly, in this paper we describe an experimental framework designed to address a situation when we have large quantities of non-aligned parallel or comparable documents in different languages that we need to exploit.", "labels": [], "entities": []}, {"text": "Our document alignment methods are based on anew scoring technique for parallel document detection based on the word-length and sentence-length ratio and named entity recognition (NER).", "labels": [], "entities": [{"text": "document alignment", "start_pos": 4, "end_pos": 22, "type": "TASK", "confidence": 0.7192279547452927}, {"text": "parallel document detection", "start_pos": 71, "end_pos": 98, "type": "TASK", "confidence": 0.6412331064542135}, {"text": "named entity recognition (NER)", "start_pos": 154, "end_pos": 184, "type": "TASK", "confidence": 0.7078998734553655}]}, {"text": "Apart from this, we also compared the total number of source and target named entities (NEs) so that they should not differ significantly which can play a major role in determining the comparability of two texts.", "labels": [], "entities": []}, {"text": "The remainder of the paper is structured as follows.", "labels": [], "entities": []}, {"text": "The related work on parallel data extraction and comparability measures is briefly discussed in Section 2.", "labels": [], "entities": [{"text": "parallel data extraction", "start_pos": 20, "end_pos": 44, "type": "TASK", "confidence": 0.6159025629361471}]}, {"text": "In Section 3, we detail our proposed method and provide the results of our experiments on WMT-2016 data in Section 4.", "labels": [], "entities": [{"text": "WMT-2016 data", "start_pos": 90, "end_pos": 103, "type": "DATASET", "confidence": 0.9398241341114044}]}, {"text": "In Section 5, we present the conclusion and directions for future work.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Weights assigned to different features  with different combinations.", "labels": [], "entities": []}, {"text": " Table 2: Results of document alignment method  used in our experiments.", "labels": [], "entities": [{"text": "document alignment", "start_pos": 21, "end_pos": 39, "type": "TASK", "confidence": 0.7622597515583038}]}, {"text": " Table 3: Detailed results of 10 web-domains of the  development data.", "labels": [], "entities": []}, {"text": " Table 4: Published results with an extension of  precision values.", "labels": [], "entities": [{"text": "precision", "start_pos": 50, "end_pos": 59, "type": "METRIC", "confidence": 0.9975780844688416}]}, {"text": " Table 5: Results obtained after applying tuned fea- ture weights.", "labels": [], "entities": []}]}