{"title": [{"text": "An Investigation of Recurrent Neural Architectures for Drug Name Recognition", "labels": [], "entities": [{"text": "Drug Name Recognition", "start_pos": 55, "end_pos": 76, "type": "TASK", "confidence": 0.7087696890036265}]}], "abstractContent": [{"text": "Drug name recognition (DNR) is an essential step in the Pharmacovigilance (PV) pipeline.", "labels": [], "entities": [{"text": "Drug name recognition (DNR)", "start_pos": 0, "end_pos": 27, "type": "TASK", "confidence": 0.7890073557694753}]}, {"text": "DNR aims to find drug name mentions in un-structured biomedical texts and classify them into predefined categories.", "labels": [], "entities": [{"text": "DNR", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.6643120050430298}]}, {"text": "State-of-the-art DNR approaches heavily rely on hand-crafted features and domain-specific resources which are difficult to collect and tune.", "labels": [], "entities": []}, {"text": "For this reason , this paper investigates the effectiveness of contemporary recurrent neural architectures-the Elman and Jordan networks and the bidi-rectional LSTM with CRF decoding-at performing DNR straight from the text.", "labels": [], "entities": [{"text": "DNR straight from the text", "start_pos": 197, "end_pos": 223, "type": "TASK", "confidence": 0.8312775135040283}]}, {"text": "The experimental results achieved on the authoritative SemEval-2013 Task 9.1 benchmarks show that the bidirectional LSTM-CRF ranks closely to highly-dedicated, hand-crafted systems .", "labels": [], "entities": [{"text": "SemEval-2013 Task 9.1 benchmarks", "start_pos": 55, "end_pos": 87, "type": "DATASET", "confidence": 0.7149085253477097}]}], "introductionContent": [{"text": "Pharmacovigilance (PV) is defined by the World Health Organization as the science and activities concerned with the detection, assessment, understanding and prevention of adverse effects of drugs or any other drug-related problems.", "labels": [], "entities": [{"text": "Pharmacovigilance (PV) is", "start_pos": 0, "end_pos": 25, "type": "TASK", "confidence": 0.7060861170291901}, {"text": "detection, assessment, understanding and prevention of adverse effects of drugs", "start_pos": 116, "end_pos": 195, "type": "TASK", "confidence": 0.7911119585235914}]}, {"text": "Drug name recognition (DNR) is a fundamental step in the PV pipeline, similarly to the well-studied Named Entity Recognition (NER) task for general natural language processing (NLP).", "labels": [], "entities": [{"text": "Drug name recognition (DNR)", "start_pos": 0, "end_pos": 27, "type": "TASK", "confidence": 0.7883050342400869}, {"text": "Named Entity Recognition (NER) task", "start_pos": 100, "end_pos": 135, "type": "TASK", "confidence": 0.8055776953697205}, {"text": "general natural language processing (NLP)", "start_pos": 140, "end_pos": 181, "type": "TASK", "confidence": 0.7409003674983978}]}, {"text": "DNR aims to find drug mentions in unstructured biomedical texts and classify them into predefined categories in order to link drug names with their effects and explore drug-drug interactions.", "labels": [], "entities": []}, {"text": "Conventional approaches to DNR sub-divide as rule-based, dictionary-based and machine learning-based.", "labels": [], "entities": []}, {"text": "Intrinsically, rule-based systems are hard to scale, time-consuming to assemble and ineffective in the presence of informal sentences and abbreviated phrases.", "labels": [], "entities": []}, {"text": "Dictionarybased systems identify drug names by matching text chunks against drug dictionaries.", "labels": [], "entities": []}, {"text": "These systems typically achieve high precision, but suffer from low recall (i.e., they miss a significant number of mentions) due to spelling errors or drug name variants not present in the dictionaries ().", "labels": [], "entities": [{"text": "precision", "start_pos": 37, "end_pos": 46, "type": "METRIC", "confidence": 0.9985609650611877}, {"text": "recall", "start_pos": 68, "end_pos": 74, "type": "METRIC", "confidence": 0.999194324016571}]}, {"text": "Conversely, machine-learning approaches have the potential to overcome all these limitations since their foundations are intrinsically robust to variants.", "labels": [], "entities": []}, {"text": "The current state-of-the-art machine learning approaches follow a two-step process of feature engineering and classification.", "labels": [], "entities": []}, {"text": "Feature engineering refers to the task of representing text by dedicated numeric vectors using domain knowledge.", "labels": [], "entities": [{"text": "Feature engineering", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.8474481403827667}]}, {"text": "Similarly to the design of rule-based systems, this task requires much expert knowledge, is typically challenging and time-consuming, and has a major impact on the final accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 170, "end_pos": 178, "type": "METRIC", "confidence": 0.9943676590919495}]}, {"text": "For this reason, this paper explores the performance of contemporary recurrent neural networks (RNNs) at providing endto-end DNR straight from text, without any manual feature engineering stage.", "labels": [], "entities": []}, {"text": "The tested RNNs include the popular Elman and Jordan networks and the bidirectional long short-term memory (LSTM) with decoding provided by a conditional random field (CRF)).", "labels": [], "entities": []}, {"text": "The experimental results over the SemEval-2013 Task 9.1 benchmarks show an interesting accuracy from the LSTM-CRF 1 that exceeds that of various manually-engineered systems and approximates the best result in the literature.", "labels": [], "entities": [{"text": "SemEval-2013 Task 9.1 benchmarks", "start_pos": 34, "end_pos": 66, "type": "DATASET", "confidence": 0.6996406465768814}, {"text": "accuracy", "start_pos": 87, "end_pos": 95, "type": "METRIC", "confidence": 0.9992503523826599}]}], "datasetContent": [{"text": "The DDIExtraction 2013 shared task challenge from) has provided a benchmark corpus for DNR and DDI extraction.", "labels": [], "entities": [{"text": "DDIExtraction 2013 shared task", "start_pos": 4, "end_pos": 34, "type": "DATASET", "confidence": 0.8422292321920395}, {"text": "DDI extraction", "start_pos": 95, "end_pos": 109, "type": "TASK", "confidence": 0.6958634853363037}]}, {"text": "The corpus contains manuallyannotated pharmacological substances and drugdrug interactions (DDIs) fora total of 18, 502 pharmacological substances and 5, 028 DDIs.", "labels": [], "entities": []}, {"text": "It collates two distinct datasets: DDI-DrugBank and DDIMedLine ( . summarizes the basic statistics of the training and test datasets used in our experiments.", "labels": [], "entities": [{"text": "DDIMedLine", "start_pos": 52, "end_pos": 62, "type": "DATASET", "confidence": 0.8962403535842896}]}, {"text": "For proper comparison, we follow the same settings as, using the training data of the DNR task along with the test data for the DDI task for training and validation of DNR.", "labels": [], "entities": []}, {"text": "We split this joint dataset into a training and validation sets with approximately 70% of sentences for training and the remaining for validation.", "labels": [], "entities": []}, {"text": "Our models have been blindly evaluated on unseen DNR test data using the strict evaluation metrics.", "labels": [], "entities": [{"text": "DNR test data", "start_pos": 49, "end_pos": 62, "type": "DATASET", "confidence": 0.7569122612476349}]}, {"text": "With this evaluation, the predicted entities have to match the ground-truth entities exactly, both in boundary and class.", "labels": [], "entities": []}, {"text": "To facilitate the replication of our experimental results, we have used a publicly-available library for the implementation 1 (i.e., the Theano neural network toolkit ().", "labels": [], "entities": [{"text": "Theano neural network toolkit", "start_pos": 137, "end_pos": 166, "type": "DATASET", "confidence": 0.930546909570694}]}, {"text": "The experiments have been run over a range of values for the hyper-parameters, using the validation set for selection).", "labels": [], "entities": []}, {"text": "The hyper-parameters include the number of hidden-layer nodes, H 2 {25, 50, 100}, the context window size, s 2 {1, 3, 5}, and the embedding dimension, d 2 {50, 100, 300, 500, 1000}.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Example sentence in a DNR task with entity classes represented in IOB format.", "labels": [], "entities": []}, {"text": " Table 2: Statistics of training and test datasets used for SemEval-2013 Task 9.1.", "labels": [], "entities": [{"text": "SemEval-2013 Task 9.1", "start_pos": 60, "end_pos": 81, "type": "TASK", "confidence": 0.8369310895601908}]}, {"text": " Table 3: Performance comparison between the recurrent neural networks (bottom three lines) and state-of-the-art systems (top", "labels": [], "entities": []}, {"text": " Table 4: SemEval-2013 Task 9.1 results by entity for the bidirectional LSTM-CRF.", "labels": [], "entities": [{"text": "SemEval-2013 Task 9.1", "start_pos": 10, "end_pos": 31, "type": "TASK", "confidence": 0.7699670592943827}]}]}