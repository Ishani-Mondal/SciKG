{"title": [{"text": "Processing Document Collections to Automatically Extract Linked Data: Semantic Storytelling Technologies for Smart Curation Workflows", "labels": [], "entities": []}], "abstractContent": [{"text": "We develop a system that operates on a document collection and represents the contained information to enable the intuitive and efficient exploration of the collection.", "labels": [], "entities": []}, {"text": "Using various NLP, IE and Semantic Web methods, we generate a semantic layer on top of the collection, from which we take the key concepts.", "labels": [], "entities": []}, {"text": "We define templates for structured reorgan-isation and rearrange the information related to the key concepts to fit the respective template.", "labels": [], "entities": []}, {"text": "The use case of the system is to support knowledge workers (journalists, editors, curators, etc.) in their task of processing large amounts of documents by sum-marising the information contained in these documents and suggesting potential story paths that the knowledge worker can then process further.", "labels": [], "entities": []}], "introductionContent": [], "datasetContent": [{"text": "To assess the suitability of the platform for the tasks of template filling and interactive collection exploration, we have asked four humans to perform these tasks and in the process evaluate the platform.", "labels": [], "entities": [{"text": "template filling", "start_pos": 59, "end_pos": 75, "type": "TASK", "confidence": 0.8500906527042389}, {"text": "interactive collection exploration", "start_pos": 80, "end_pos": 114, "type": "TASK", "confidence": 0.6546590427557627}]}, {"text": "For evaluation, three collections were used, two of them real-world use-cases provided by the SME partners of the project: (i) a collection of letters sent by the architect Erich Mendelsohn and his wife 5 and (ii) a private document collection on Vikings.", "labels": [], "entities": [{"text": "SME", "start_pos": 94, "end_pos": 97, "type": "TASK", "confidence": 0.5512376427650452}]}, {"text": "The third collection is the WikiWars corpus . The subjects were asked to check how many slots in the templates could be filled with the relations extracted.", "labels": [], "entities": [{"text": "WikiWars corpus", "start_pos": 28, "end_pos": 43, "type": "DATASET", "confidence": 0.8653886020183563}]}, {"text": "For the biography template some relevant relations were found in the Viking corpus: Edward, marry, Edith, which can fill the spouse slot and William, raise, Malcolm, which could fill the children slot (though it of course does not imply that Malcolm really is a child of William).", "labels": [], "entities": [{"text": "Viking corpus", "start_pos": 69, "end_pos": 82, "type": "DATASET", "confidence": 0.9594592452049255}, {"text": "Edward", "start_pos": 84, "end_pos": 90, "type": "METRIC", "confidence": 0.9054903984069824}, {"text": "Malcolm", "start_pos": 157, "end_pos": 164, "type": "METRIC", "confidence": 0.9430261254310608}]}, {"text": "Be-5 http://ema.smb.museum/en/home/ 6 http://timexportal.", "labels": [], "entities": []}, {"text": "wikidot.com/forum/t-275092/ wikiwars-is-available-for-download cause we have not created a gold standard from these corpora, measuring recall is problematic.", "labels": [], "entities": [{"text": "recall", "start_pos": 135, "end_pos": 141, "type": "METRIC", "confidence": 0.9951152801513672}]}, {"text": "As a result, it is not clear whether the approach failed to extract the relations that could lead to populating templates, or whether this information was not present in the corpus.", "labels": [], "entities": []}, {"text": "It is clear however that the real-world scenario would primarily rely on getting information from the ontology.", "labels": [], "entities": []}, {"text": "An observation that was made by all test subjects was that the quality of the relations extracted from the WikiWars and the Viking corpus was much higher than that of relations extracted from the Mendelsohn corpus.", "labels": [], "entities": [{"text": "Viking corpus", "start_pos": 124, "end_pos": 137, "type": "DATASET", "confidence": 0.798189640045166}]}, {"text": "This is probably due to the fact that the first two corpora are meant to be descriptive and clear records of historical events, whereas the Mendelsohn corpus consists of private letters that were probably not intended to be descriptive for the general public.", "labels": [], "entities": []}, {"text": "In addition, the Mendelsohn letters contained many cases of you and I, which were not recognized by the NER component (because resolution to a URI is not in all cases straightforward), hence these sentences were not considered.", "labels": [], "entities": []}, {"text": "With regard to the task of exploring the document collection and selecting possible events to base anew story on, the subjects reported that several useful relations were extracted, again with the exception of the Mendelsohn corpus.] from the WikiWars corpus.", "labels": [], "entities": [{"text": "WikiWars corpus", "start_pos": 243, "end_pos": 258, "type": "DATASET", "confidence": 0.8941131234169006}]}, {"text": "These pieces of information also display the advantage of a non-seed-based approach.", "labels": [], "entities": []}, {"text": "To capture the above relations, we would need to have trained for relations of the extort-, leave-, annexand unite-type.", "labels": [], "entities": []}, {"text": "The point however is that upfront the potentially interesting relations that need to be extracted are of unknown types.", "labels": [], "entities": []}, {"text": "A drawback of the current approach is the fact that only binary relations (a predicate with two arguments) are extracted.", "labels": [], "entities": []}, {"text": "Ditransitive verbs are not fully captured.", "labels": [], "entities": []}, {"text": "Instead, we end up with relations like, where an important piece of the expressed relation is missing.", "labels": [], "entities": []}, {"text": "Another drawback is the requirement that the two entities are connected through the same verb node in the dependency graph.", "labels": [], "entities": []}, {"text": "We have no concrete figures on recall, but the number of extracted relations were relatively low for all corpora.", "labels": [], "entities": [{"text": "recall", "start_pos": 31, "end_pos": 37, "type": "METRIC", "confidence": 0.9949224591255188}]}, {"text": "A third observed issue were errors introduced by the dependency parser.", "labels": [], "entities": []}, {"text": "Relations like and were extracted, where apparently member and better were tagged as a verb, hence considered by our analysis.", "labels": [], "entities": []}], "tableCaptions": []}