{"title": [{"text": "The NTNU-YZU System in the AESW Shared Task: Automated Evalua- tion of Scientific Writing Using a Convolutional Neural Network", "labels": [], "entities": []}], "abstractContent": [{"text": "This study describes the design of the NTNU-YZU system for the automated evaluation of scientific writing shared task.", "labels": [], "entities": [{"text": "NTNU-YZU", "start_pos": 39, "end_pos": 47, "type": "DATASET", "confidence": 0.8122341632843018}]}, {"text": "We employ a convolutional neural network with the Word2Vec/GloVe embedding representation to predict whether a sentence needs language editing.", "labels": [], "entities": [{"text": "Word2Vec/GloVe embedding representation", "start_pos": 50, "end_pos": 89, "type": "DATASET", "confidence": 0.9017222762107849}]}, {"text": "For the Boolean prediction track, our best F-score of 0.6108 ranked second among the ten submissions.", "labels": [], "entities": [{"text": "Boolean prediction track", "start_pos": 8, "end_pos": 32, "type": "DATASET", "confidence": 0.9512396057446798}, {"text": "F-score", "start_pos": 43, "end_pos": 50, "type": "METRIC", "confidence": 0.9985069632530212}]}, {"text": "Our system also achieved an F-score of 0.7419 for the probabilistic estimation track, ranking fourth among the nine submissions .", "labels": [], "entities": [{"text": "F-score", "start_pos": 28, "end_pos": 35, "type": "METRIC", "confidence": 0.9997158646583557}]}], "introductionContent": [{"text": "Automated grammatical error detection and correction are important tasks and research topics in computational linguistics.", "labels": [], "entities": [{"text": "Automated grammatical error detection and correction", "start_pos": 0, "end_pos": 52, "type": "TASK", "confidence": 0.7380580554405848}]}, {"text": "A number of competitive tasks have been organized to encourage innovation in this direction ().", "labels": [], "entities": []}, {"text": "For examples, Helping Our Own (HOO) was a series of shared tasks used for correcting grammatical errors of English texts written by non-native speakers ().", "labels": [], "entities": [{"text": "Helping Our Own (HOO)", "start_pos": 14, "end_pos": 35, "type": "TASK", "confidence": 0.6486704051494598}, {"text": "correcting grammatical errors of English texts written by non-native speakers", "start_pos": 74, "end_pos": 151, "type": "TASK", "confidence": 0.879823100566864}]}, {"text": "The CoNLL 2013/2014 shared tasks aimed to correct grammatical errors among learners of English as a foreign language in the educational application ().", "labels": [], "entities": [{"text": "CoNLL 2013/2014", "start_pos": 4, "end_pos": 19, "type": "DATASET", "confidence": 0.9393662810325623}]}, {"text": "The first NLP-TEA workshop featured a shared task on grammatical error diagnosis for learners of Chinese as a foreign language ().", "labels": [], "entities": [{"text": "grammatical error diagnosis", "start_pos": 53, "end_pos": 80, "type": "TASK", "confidence": 0.6060556670029958}]}, {"text": "The following year, a similar Chinese grammatical error diagnosis shared task was held in the second NLP-TEA workshop in conjunction with ACL-IJCNLP 2015 (.", "labels": [], "entities": [{"text": "Chinese grammatical error diagnosis shared task", "start_pos": 30, "end_pos": 77, "type": "TASK", "confidence": 0.7620383004347483}]}, {"text": "These competitions reflect the need for automated writing assistance for various applications.", "labels": [], "entities": []}, {"text": "The Automated Evaluation of Scientific Writing (AESW) shared task seeks to promote the use of NLP tools to help improve the quality of scientific writing in English by predicting whether a given sentence needs language editing or not.", "labels": [], "entities": [{"text": "Automated Evaluation of Scientific Writing (AESW) shared task", "start_pos": 4, "end_pos": 65, "type": "TASK", "confidence": 0.680543914437294}]}, {"text": "The AESW shared task contains two tracks: (1) a Boolean prediction track in which a sentence in need of editing will result in a binary classifier outputting true; otherwise the system should return false; and (2) a probabilistic estimation track in which the system estimates the editing probability (between 0 and 1) of each input sentence.", "labels": [], "entities": []}, {"text": "A sentence is assigned 1 if it requires editing, and 0 otherwise.", "labels": [], "entities": []}, {"text": "Each participating team can submit multiple results using different approaches for evaluation, but the final performance comparisons are limited to two designated submissions for each track.", "labels": [], "entities": []}, {"text": "This study describes the joint efforts between National Taiwan Normal University and Yuan Ze University (NTNU-YZU) in the AESW shared task.", "labels": [], "entities": [{"text": "National Taiwan Normal University", "start_pos": 47, "end_pos": 80, "type": "DATASET", "confidence": 0.8921873718500137}, {"text": "AESW shared task", "start_pos": 122, "end_pos": 138, "type": "TASK", "confidence": 0.5368250211079916}]}, {"text": "We introduce a convolutional neural network and its use for predicting language editing of scientific writing at the sentence level.", "labels": [], "entities": [{"text": "predicting language editing of scientific writing", "start_pos": 60, "end_pos": 109, "type": "TASK", "confidence": 0.8706154028574625}]}, {"text": "The input sentence is represented as a sequence of words using distributed vectors looked up in a word embedding matrix.", "labels": [], "entities": []}, {"text": "The datasets provided by the AESW organizers are used to train the neural network for the prediction task.", "labels": [], "entities": [{"text": "AESW organizers", "start_pos": 29, "end_pos": 44, "type": "DATASET", "confidence": 0.8344119489192963}, {"text": "prediction task", "start_pos": 90, "end_pos": 105, "type": "TASK", "confidence": 0.8883853554725647}]}, {"text": "The output is a value for probabilistic estimation.", "labels": [], "entities": []}, {"text": "If the output value exceeds a certain threshold, it is considered as true for binary decision.", "labels": [], "entities": []}, {"text": "Our best results in terms of F-score are 0.6108 (ranked at 2/10) and 0.7419 (4/9), respectively for the Boolean prediction track and the probabilistic estimation track.", "labels": [], "entities": [{"text": "F-score", "start_pos": 29, "end_pos": 36, "type": "METRIC", "confidence": 0.9992523789405823}, {"text": "Boolean prediction track", "start_pos": 104, "end_pos": 128, "type": "DATASET", "confidence": 0.5485463937123617}]}, {"text": "The rest of this paper is organized as follows.", "labels": [], "entities": []}, {"text": "Section 2 introduces existing studies for grammatical error detection and correction.", "labels": [], "entities": [{"text": "grammatical error detection and correction", "start_pos": 42, "end_pos": 84, "type": "TASK", "confidence": 0.7645524144172668}]}, {"text": "Section 3 describes the details of the NTNU-YZU system architecture for the AESW shared task.", "labels": [], "entities": [{"text": "AESW shared task", "start_pos": 76, "end_pos": 92, "type": "TASK", "confidence": 0.6201781829198202}]}, {"text": "Section 4 presents the evaluation results and their performance comparison.", "labels": [], "entities": []}, {"text": "Section 5 elaborates on the implications and lessons learned.", "labels": [], "entities": []}, {"text": "Conclusions are finally drawn in Section 6.", "labels": [], "entities": []}], "datasetContent": [{"text": "In the first set of experiments, we fine-tuned several parameter combinations to obtain the Convolutional Neural Network (CNN).", "labels": [], "entities": []}, {"text": "Three main parameters may affect system performance: (1) Number of epochs, which is the number of iterations required to learning the network parameters (set from 3 to 5); (2) Number of filters, which is regarded as the number of features used to train the network (100 and 250 in this experiment); and (3) Filter length, which denotes the number of contexts for convolution (set from 2 to 4).", "labels": [], "entities": [{"text": "Filter length", "start_pos": 307, "end_pos": 320, "type": "METRIC", "confidence": 0.7817058861255646}]}, {"text": "We used minibatches to train the network.", "labels": [], "entities": []}, {"text": "The size of each minibatch was set as 100.", "labels": [], "entities": []}, {"text": "We also considered the number of learning instances.", "labels": [], "entities": []}, {"text": "In addition to adopting training instances used only for network learning, we incorporate sentences from the development datasets for model training.", "labels": [], "entities": []}, {"text": "To optimize training CNN efficiently, this set of experiments adopts the conventional bag-of-word vectors used to index a word as vocabulary.", "labels": [], "entities": []}, {"text": "In addition, the default threshold was set as 0.5 for binary decisions.", "labels": [], "entities": [{"text": "default threshold", "start_pos": 17, "end_pos": 34, "type": "METRIC", "confidence": 0.9623969793319702}]}, {"text": "In the second set of experiments, we compared the effects of different word embedding methods including Word2Vec and Glove.", "labels": [], "entities": [{"text": "Word2Vec", "start_pos": 104, "end_pos": 112, "type": "DATASET", "confidence": 0.9666124582290649}]}, {"text": "We also evaluated the influence of the number of dimensions used for word representation.", "labels": [], "entities": [{"text": "word representation", "start_pos": 69, "end_pos": 88, "type": "TASK", "confidence": 0.7983923256397247}]}, {"text": "In the third set of experiments, we adopted the best settings generated from the above experiments to fine-tune the threshold for Boolean decision.", "labels": [], "entities": []}, {"text": "We increase the threshold from 0.1 to 0.9 in increments of 0.1, and then fine tune in increments of 0.01 to obtain approximately optimal performance for the CNN model.", "labels": [], "entities": []}, {"text": "shows the Boolean results with different parameter settings.", "labels": [], "entities": []}, {"text": "A greater number of epochs do not always produce the better results.", "labels": [], "entities": []}, {"text": "A smaller number of filters obtained better outcomes in more than two-thirds of testing cases with the same settings.", "labels": [], "entities": []}, {"text": "Similarly, a longer filter length does not guarantee better results.", "labels": [], "entities": []}, {"text": "In more than half of testing cases, using more sentences from the development dataset in model training did not produce better F-scores.", "labels": [], "entities": [{"text": "F-scores", "start_pos": 127, "end_pos": 135, "type": "METRIC", "confidence": 0.9937171936035156}]}, {"text": "In summary, 4 epochs, 100 filters, and a filter length of 3 achieved the best recall of 0.5251 and an F-score of 0.5526.", "labels": [], "entities": [{"text": "recall", "start_pos": 78, "end_pos": 84, "type": "METRIC", "confidence": 0.9996992349624634}, {"text": "F-score", "start_pos": 102, "end_pos": 109, "type": "METRIC", "confidence": 0.9994833469390869}]}, {"text": "We used these parameter settings for the following experiments.", "labels": [], "entities": []}, {"text": "shows the results of our CNN model with different word embedding methods for the Boolean prediction track.", "labels": [], "entities": [{"text": "Boolean prediction track", "start_pos": 81, "end_pos": 105, "type": "DATASET", "confidence": 0.8035820325215658}]}, {"text": "Within the GloVe representation, the Twitter dataset (only 200 dimensions) does not achieve good results, possibly due to the poor suitability of textual usages of social media for the automated evaluation of scientific writing.", "labels": [], "entities": [{"text": "Twitter dataset", "start_pos": 37, "end_pos": 52, "type": "DATASET", "confidence": 0.7090437710285187}]}, {"text": "With 300 dimensions each, trained word vectors from Wikipedia and Gigaword obtained relatively better effects than that from common crawl data.", "labels": [], "entities": [{"text": "Wikipedia", "start_pos": 52, "end_pos": 61, "type": "DATASET", "confidence": 0.9500943422317505}]}, {"text": "In addition, more dimensions usually lead to better results.", "labels": [], "entities": []}, {"text": "Comparing the representations of GloVe and Word2Vec, the GloVe achieves better recall and a higher F-score than Word2Vec, while Word2Vec provides higher precision.", "labels": [], "entities": [{"text": "Word2Vec", "start_pos": 43, "end_pos": 51, "type": "DATASET", "confidence": 0.9608051180839539}, {"text": "recall", "start_pos": 79, "end_pos": 85, "type": "METRIC", "confidence": 0.9996040463447571}, {"text": "F-score", "start_pos": 99, "end_pos": 106, "type": "METRIC", "confidence": 0.9988619089126587}, {"text": "Word2Vec", "start_pos": 112, "end_pos": 120, "type": "DATASET", "confidence": 0.9406179785728455}, {"text": "Word2Vec", "start_pos": 128, "end_pos": 136, "type": "DATASET", "confidence": 0.9441530108451843}, {"text": "precision", "start_pos": 153, "end_pos": 162, "type": "METRIC", "confidence": 0.9978310465812683}]}, {"text": "Again, using more sentences to train the CNN does not result in better performance in this set of experiments.", "labels": [], "entities": []}, {"text": "In summary, the Word2Vec training from the Google News data obtains the best precision at 0.6717.", "labels": [], "entities": [{"text": "Google News data", "start_pos": 43, "end_pos": 59, "type": "DATASET", "confidence": 0.8801113963127136}, {"text": "precision", "start_pos": 77, "end_pos": 86, "type": "METRIC", "confidence": 0.9982479810714722}]}, {"text": "The best recall 0.5344 and F-score 0.5618 were achieved using the GloVe representation learning from Wikipedia and Gigaword (300 dimensions).", "labels": [], "entities": [{"text": "recall 0.5344", "start_pos": 9, "end_pos": 22, "type": "METRIC", "confidence": 0.9754261374473572}, {"text": "F-score", "start_pos": 27, "end_pos": 34, "type": "METRIC", "confidence": 0.9986787438392639}]}], "tableCaptions": [{"text": " Table 1: Boolean results of our CNN model with different parameters.", "labels": [], "entities": []}, {"text": " Table 3: Probabilistic results of our CNN model with different word embedding methods.", "labels": [], "entities": []}, {"text": " Table 2: Boolean results of our CNN model with different word embedding methods.", "labels": [], "entities": []}]}