{"title": [{"text": "The Effect of Multiple Grammatical Errors on Processing Non-Native Writing", "labels": [], "entities": []}], "abstractContent": [{"text": "In this work, we estimate the deterioration of NLP processing given an estimate of the amount and nature of grammatical errors in a text.", "labels": [], "entities": [{"text": "NLP processing", "start_pos": 47, "end_pos": 61, "type": "TASK", "confidence": 0.8825474083423615}]}, {"text": "From a corpus of essays written by English-language learners, we extract un-grammatical sentences, controlling the number and types of errors in each sentence.", "labels": [], "entities": []}, {"text": "We focus on six categories of errors that are commonly made by English-language learners, and consider sentences containing one or more of these errors.", "labels": [], "entities": []}, {"text": "To evaluate the effect of grammatical errors, we measure the deterioration of ungrammatical dependency parses using the labeled F-score, an adaptation of the labeled attachment score.", "labels": [], "entities": [{"text": "F-score", "start_pos": 128, "end_pos": 135, "type": "METRIC", "confidence": 0.937228798866272}]}, {"text": "We find notable differences between the influence of individual error types on the dependency parse, as well as interactions between multiple errors.", "labels": [], "entities": [{"text": "dependency parse", "start_pos": 83, "end_pos": 99, "type": "TASK", "confidence": 0.686303436756134}]}], "introductionContent": [{"text": "With the large number of English-language learners and the prevalence of informal web text, noisy text containing grammatical errors is widespread.", "labels": [], "entities": []}, {"text": "However, the majority of NLP tools are developed and trained over clean, grammatical text and the performance of these tools maybe negatively affected when processing errorful text.", "labels": [], "entities": []}, {"text": "One possible workaround is to adapt tools for noisy text, e.g. ().", "labels": [], "entities": []}, {"text": "However, it is often preferable to use tools trained on clean text, mainly because of the resources necessary for training and the limited availability of large-scale annotated corpora, but also because tools should work correctly in the presence of well-formed text.", "labels": [], "entities": []}, {"text": "Our goal is to measure the performance degradation of an automatic NLP task based on an estimate of grammatical errors in a text.", "labels": [], "entities": []}, {"text": "For example, if we are processing student responses within an NLP application, and the responses contain a mix of native and non-native texts, it would be useful to be able to estimate the difference in performance (if any) of the NLP application on both types of texts.", "labels": [], "entities": []}, {"text": "We choose dependency parsing as our prototypic task because it is often one of the first complex downstream tasks in NLP pipelines.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 10, "end_pos": 28, "type": "TASK", "confidence": 0.8240822553634644}]}, {"text": "We will consider six common grammatical errors made by nonnative speakers of English and systematically control the number and types of errors present in a sentence.", "labels": [], "entities": []}, {"text": "As errors are introduced to a sentence, the degradation of the dependency parse is measured by the decrease in the F-score over dependency relations.", "labels": [], "entities": [{"text": "dependency parse", "start_pos": 63, "end_pos": 79, "type": "TASK", "confidence": 0.719294548034668}, {"text": "F-score", "start_pos": 115, "end_pos": 122, "type": "METRIC", "confidence": 0.993823766708374}]}, {"text": "In this work, we will show that \u2022 increasing the number of errors in a sentence decreases the accuracy of the dependency parse (Section 4.1); \u2022 the distance between errors does not affect the accuracy (Section 4.2); \u2022 some types of grammatical errors have a greater impact, alone or in combination with other errors (Section 4.3).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 94, "end_pos": 102, "type": "METRIC", "confidence": 0.999110996723175}, {"text": "accuracy", "start_pos": 192, "end_pos": 200, "type": "METRIC", "confidence": 0.9983965754508972}]}, {"text": "While these findings may seem self-evident, they have not previously been quantified on a large corpus of naturally occurring errors.", "labels": [], "entities": []}, {"text": "Our analysis will serve as the first step to understanding what happens to a NLP pipeline when confronted with grammatical errors.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: The number of NUCLE sentences contain- ing at least n errors, the number of sentences with n  errors that were generated from them, and the num- ber of NUCLE sentences with exactly n errors.", "labels": [], "entities": []}, {"text": " Table 1. We also gen- erated a grammatical sentence with all of the correc- tions applied for comparison.  We parsed each sentence with the ZPar con- stituent parser (", "labels": [], "entities": []}]}