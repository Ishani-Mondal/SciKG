{"title": [{"text": "Issues in evaluating semantic spaces using word analogies", "labels": [], "entities": []}], "abstractContent": [{"text": "The offset method for solving word analogies has become a standard evaluation tool for vector-space semantic models: it is considered desirable fora space to represent semantic relations as consistent vector offsets.", "labels": [], "entities": []}, {"text": "We show that the method's reliance on cosine similarity conflates offset consistency with largely irrelevant neighborhood structure, and propose simple baselines that should be used to improve the utility of the method in vector space evaluation.", "labels": [], "entities": []}], "introductionContent": [{"text": "Vector space models of semantics (VSMs) represent words as points in a high-dimensional space.", "labels": [], "entities": []}, {"text": "There is considerable interest in evaluating VSMs without needing to embed them in a complete NLP system.", "labels": [], "entities": [{"text": "VSMs", "start_pos": 45, "end_pos": 49, "type": "TASK", "confidence": 0.9237430095672607}]}, {"text": "One such intrinsic evaluation strategy that has gained in popularity in recent years uses the offset approach to solving word analogy problems (.", "labels": [], "entities": [{"text": "word analogy", "start_pos": 121, "end_pos": 133, "type": "TASK", "confidence": 0.7214213609695435}]}, {"text": "This method assesses whether a linguistic relation -for example, between the base and gerund form of a verb (debug and debugging) -is consistently encoded as a particular linear offset in the space.", "labels": [], "entities": []}, {"text": "If that is the case, estimating the offset using one pair of words related in a particular way should enable us to go back and forth between other pairs of words that are related in the same way, e.g., scream and screaming in the base-to-gerund case).", "labels": [], "entities": []}, {"text": "Since VSMs are typically continuous spaces, adding the offset between debug and debugging to scream is unlikely to land us exactly on any particular word.", "labels": [], "entities": []}, {"text": "The solution to the analogy problem is therefore taken to be the word closest in wherein our example a is debug, a * is debugging and b is scream, then the proposed answer to the analogy problem is where The central role of cosine similarity in this method raises the concern that the method does not only evaluate the consistency of the offsets a * \u2212 a and b * \u2212 b but also the neighborhood structure of x = a * \u2212a+b.", "labels": [], "entities": []}, {"text": "For instance, if a * and a are very similar to each other (as scream and screaming are likely to be) the nearest word to x may simply be the nearest neighbor of b.", "labels": [], "entities": []}, {"text": "If in a given set of analogies the nearest neighbor of b tends to be b * , then, the method may give the correct answer regardless of the consistency of the offsets ().", "labels": [], "entities": []}, {"text": "In this note we assess to what extent the performance of the offset method provides evidence for offset consistency despite its potentially problematic reliance on cosine similarity.", "labels": [], "entities": []}, {"text": "First, we propose new baselines that perform the task without using the offset a * \u2212 a and argue that the performance of the offset method should be compared to those baselines.", "labels": [], "entities": []}, {"text": "Second, we measure how the performance of the method is affected by reversing the direction of each analogy problem).", "labels": [], "entities": []}, {"text": "If the method truly measures offset consistency, this reversal should not affect its accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 85, "end_pos": 93, "type": "METRIC", "confidence": 0.9976937174797058}]}], "datasetContent": [{"text": "Analogy problems: We use the analogy dataset proposed by.", "labels": [], "entities": []}, {"text": "This dataset, which has become a standard VSM evaluation set (, contains 14 categories; see fora full list.", "labels": [], "entities": [{"text": "VSM evaluation set", "start_pos": 42, "end_pos": 60, "type": "DATASET", "confidence": 0.6594624916712443}]}, {"text": "A number of these categories, sometimes referred to as \"syntactic\", test whether the structure of the space captures simple morphological relations, such as the relation between the base and gerund form of a verb (scream : screaming).", "labels": [], "entities": []}, {"text": "Others evaluate the knowledge that the space encodes about the world, e.g., the relation between a country and its currency (latvia : lats).", "labels": [], "entities": []}, {"text": "A final category that doesn't fit neatly into either of those groups is the relation between masculine and feminine versions of the same concept (groom : bride).", "labels": [], "entities": []}, {"text": "We follow   ther side of the focus word.", "labels": [], "entities": []}, {"text": "In s 5 it included five words on either side of the focus word, and was \"dynamic\" -that is, it was expanded if any of the context words were excluded for low or high frequency (for details, see).", "labels": [], "entities": []}, {"text": "Finally, the context in s 10 was a dynamic window often words on either side.", "labels": [], "entities": []}, {"text": "All other hyperparameters were set to standard values.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: The analogy categories of Mikolov et al.  (2013a) and the number of problems per category.", "labels": [], "entities": []}, {"text": " Table 2: Overall scores and the advantage of ADD  over two of the baselines across spaces.", "labels": [], "entities": [{"text": "ADD", "start_pos": 46, "end_pos": 49, "type": "METRIC", "confidence": 0.8020831346511841}]}]}