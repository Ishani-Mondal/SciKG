{"title": [{"text": "Discovering Potential Terminological Relationships from Twitter's Timed Content", "labels": [], "entities": [{"text": "Discovering Potential Terminological Relationships", "start_pos": 0, "end_pos": 50, "type": "TASK", "confidence": 0.8273867815732956}, {"text": "Twitter's Timed Content", "start_pos": 56, "end_pos": 79, "type": "DATASET", "confidence": 0.6614415571093559}]}], "abstractContent": [{"text": "This paper presents a method to discover possible terminological relationships from tweets.", "labels": [], "entities": []}, {"text": "We match the histories of terms (frequency patterns).", "labels": [], "entities": []}, {"text": "Similar history indicates a possible relationship between terms.", "labels": [], "entities": []}, {"text": "For example, if two terms (t1, t2) appeared frequently in Twitter at particular days, and there is a 'similarity' in the frequencies over a period of time, then t1 and t2 can be related.", "labels": [], "entities": []}, {"text": "Maintaining standard terminological repository with updated relationships can be difficult; especially in a dynamic domain such as social media where thousands of new terms (neology) are coined everyday.", "labels": [], "entities": []}, {"text": "So we propose to construct a raw repository of lexical units with unconfirmed relationships.", "labels": [], "entities": []}, {"text": "We have experimented our method on time-sensitive Arabic terms used by the online Arabic community of Twitter.", "labels": [], "entities": []}, {"text": "We draw relationships between these terms by matching their similar frequency patterns (timelines).", "labels": [], "entities": []}, {"text": "We use dynamic time warping as a similarity measure.", "labels": [], "entities": []}, {"text": "For evaluation, we have selected 630 possible terms (we call them preterms) and we matched the similarity of these terms over a period of 30 days.", "labels": [], "entities": []}, {"text": "Around 270 correct relationships were discovered with a precision of 0.61.", "labels": [], "entities": [{"text": "precision", "start_pos": 56, "end_pos": 65, "type": "METRIC", "confidence": 0.9978690147399902}]}, {"text": "These relationships were extracted without considering the textual context of the term.", "labels": [], "entities": []}], "introductionContent": [{"text": "Internet users are producing 10,000 Microposts on average every second (internetlivestats 2015).", "labels": [], "entities": []}, {"text": "Microposts are short messages containing few sentences written in several languages.", "labels": [], "entities": []}, {"text": "These messages tend to talk about time sensitive topics (Grinev,) (Kwak,).", "labels": [], "entities": []}, {"text": "Microposts are rich with terminology), not only old and well defined terminology but also newly coined terms).", "labels": [], "entities": []}, {"text": "Building and maintaining an up-to-date terminological repository is very important for several applications), like machine translation (Vasconcellos,), information retrieval)\u2026 However, finding terminology (terms and relationships) is a very difficult task (Cabre and Sager 1999), especially for poorly equipped languages, and when the domain is active and changing everyday (new concepts appear every day).", "labels": [], "entities": [{"text": "machine translation", "start_pos": 115, "end_pos": 134, "type": "TASK", "confidence": 0.7529427707195282}, {"text": "information retrieval", "start_pos": 152, "end_pos": 173, "type": "TASK", "confidence": 0.8254816830158234}]}, {"text": "Classical approaches in building terminology depend heavily on terminologists and subject-matter experts).", "labels": [], "entities": [{"text": "building terminology", "start_pos": 24, "end_pos": 44, "type": "TASK", "confidence": 0.864481121301651}]}, {"text": "This approach is very expensive, and it achieves poor coverage ) because terminologists have limited capability and subject matter experts are rare for contemporary domains.", "labels": [], "entities": [{"text": "coverage", "start_pos": 54, "end_pos": 62, "type": "METRIC", "confidence": 0.9711455702781677}]}, {"text": "Statistical approaches on the other hand are less expensive, but they need large and processed corpus/corpora.", "labels": [], "entities": []}, {"text": "Besides, statistical methods might find a list of candidate terms without relationships, so mapping these terms into a lexical network can be difficult.", "labels": [], "entities": []}, {"text": "Microblogs are massive and can solve the problem of the availability of a large textual corpus, however, these microblogs have little textual context (A micropost in Twitter is 140 characters only) and they are usually poorly written).", "labels": [], "entities": []}, {"text": "We are working on analyzing terms that appear on microblogs over a period of time to monitor their evolutions.", "labels": [], "entities": []}, {"text": "Our idea is that terms with similar histories (frequency patterns over a period of time) are probably similar.", "labels": [], "entities": []}, {"text": "For example, if two terms are peaking at the same dates then there is a chance that these terms are used by the internet users synonymously.", "labels": [], "entities": []}, {"text": "That way rather than using textual context (which is almost nonexistent in microblogs), we are using historical context to relate between terms.", "labels": [], "entities": []}, {"text": "And that will make social media a legitimate source of terminology (terms and relationships).", "labels": [], "entities": []}, {"text": "Building a terminological database is still challenging), because terminology must be standardized and must have a formal body to approve it.", "labels": [], "entities": []}, {"text": "We are proposing to extract unconfirmed terminological relationships (preterminology relationships)) rather than standard terminology.", "labels": [], "entities": []}, {"text": "Preterminology is considered as raw material for terminology that can be refined to produce standard terminology.", "labels": [], "entities": []}, {"text": "Matching timelines for terms is a classical time series problem, where time series are searched for similarities.", "labels": [], "entities": []}, {"text": "There are several approaches to search time series.", "labels": [], "entities": [{"text": "search time series", "start_pos": 32, "end_pos": 50, "type": "TASK", "confidence": 0.7677013675371805}]}, {"text": "The performance of these approaches depends on the application).", "labels": [], "entities": []}, {"text": "We use an algorithm originally used for speech recognition called Dynamic Time Warping algorithm (Sakoe and Chiba 1978) with a normalized Euclidean distance function.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 40, "end_pos": 58, "type": "TASK", "confidence": 0.7734435796737671}]}, {"text": "This approach will not only measure the distance between timelines, but it will consider the slight shifts in the timelines.", "labels": [], "entities": []}, {"text": "And this is very suitable for our application because related terms might not peak on the exact same days.", "labels": [], "entities": []}, {"text": "This article is organized as follows; the following section introduces terminology evolution in big data.", "labels": [], "entities": [{"text": "terminology evolution", "start_pos": 71, "end_pos": 92, "type": "TASK", "confidence": 0.7701385319232941}]}, {"text": "The third section presents our approach in finding historical similarity between terms.", "labels": [], "entities": []}, {"text": "The fourth section shows our data collection method.", "labels": [], "entities": [{"text": "data collection", "start_pos": 29, "end_pos": 44, "type": "TASK", "confidence": 0.6400028169155121}]}, {"text": "The fifth section shows the experimental results and evaluation, and finally we will draw some conclusions.", "labels": [], "entities": []}], "datasetContent": [{"text": "Arabic tweets collected by the online platform during the month of May 2016 were analyzed.", "labels": [], "entities": []}, {"text": "We selected 630 timelines for the most popular preterms in that month.", "labels": [], "entities": []}, {"text": "Then we searched for similarities between them.", "labels": [], "entities": []}, {"text": "The produced relationships were evaluated based on precision and recall.", "labels": [], "entities": [{"text": "precision", "start_pos": 51, "end_pos": 60, "type": "METRIC", "confidence": 0.9995713829994202}, {"text": "recall", "start_pos": 65, "end_pos": 71, "type": "METRIC", "confidence": 0.9983104467391968}]}, {"text": "The top 1108 relationships were rated by 2 evaluators (E1 and E2).", "labels": [], "entities": []}, {"text": "Relationship between t1 and t2 is considered correct if the two evaluators found that t1 and t2 are event related or if they found that there is a terminological relationship (synonymy, acronym, hyponymy, antinomy, and hypernymy) between them.", "labels": [], "entities": []}, {"text": "Using Cohen's Kappa coefficient (Cohen 1960) the inter-agreement score was 0.93 which indicates a substantial agreement between the evaluators.", "labels": [], "entities": []}], "tableCaptions": []}