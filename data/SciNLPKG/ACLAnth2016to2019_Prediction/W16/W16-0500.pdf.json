{"title": [], "abstractContent": [], "introductionContent": [{"text": "We are excited to be holding the 11th edition of the BEA workshop.", "labels": [], "entities": [{"text": "BEA workshop", "start_pos": 53, "end_pos": 65, "type": "DATASET", "confidence": 0.7658735513687134}]}, {"text": "Since starting in 1997, the BEA workshop, now one of the largest workshops at NAACL/ACL, has become one of the leading venues for publishing innovative work that uses NLP to develop educational applications.", "labels": [], "entities": [{"text": "BEA", "start_pos": 28, "end_pos": 31, "type": "METRIC", "confidence": 0.7235895395278931}, {"text": "NAACL/ACL", "start_pos": 78, "end_pos": 87, "type": "DATASET", "confidence": 0.8754712144533793}]}, {"text": "The consistent interest and growth of the workshop has clear ties to challenges in education, especially with regard to supporting literacy.", "labels": [], "entities": []}, {"text": "The research presented at the workshop illustrates advances in the technology, and the maturity of the NLP/education field that are responses to those challenges with capabilities that support instructor practices and learner needs.", "labels": [], "entities": []}, {"text": "NLP capabilities now support an array of learning domains, including writing, speaking, reading, and mathematics.", "labels": [], "entities": []}, {"text": "In the writing and speech domains, automated writing evaluation (AWE) and speech assessment applications, respectively, are commercially deployed in high-stakes assessment and instructional settings, including Massive Open Online Courses (MOOCs).", "labels": [], "entities": [{"text": "automated writing evaluation (AWE)", "start_pos": 35, "end_pos": 69, "type": "TASK", "confidence": 0.7141986091931661}]}, {"text": "We also see widely-used commercial applications for plagiarism detection and peer review.", "labels": [], "entities": [{"text": "plagiarism detection", "start_pos": 52, "end_pos": 72, "type": "TASK", "confidence": 0.7312006056308746}, {"text": "peer review", "start_pos": 77, "end_pos": 88, "type": "TASK", "confidence": 0.7346076369285583}]}, {"text": "There has been a renewed interest in spoken dialog and multi-modal systems for instruction and assessment as well as feedback.", "labels": [], "entities": []}, {"text": "We are also seeing explosive growth of mobile applications for game-based applications for instruction and assessment.", "labels": [], "entities": []}, {"text": "The current educational and assessment landscape, especially in the United States, continues to foster a strong interest and high demand that pushes the state-of-the-art in AWE capabilities to expand the analysis of written responses to writing genres other than those traditionally found in standardized assessments, especially writing tasks requiring use of sources and argumentative discourse.", "labels": [], "entities": []}, {"text": "The use of NLP in educational applications has gained visibility outside of the NLP community.", "labels": [], "entities": []}, {"text": "First, the Hewlett Foundation reached out to public and private sectors and sponsored two competitions: one for automated essay scoring, and another for scoring of short answer, subject-matter-based response items.", "labels": [], "entities": [{"text": "Hewlett Foundation", "start_pos": 11, "end_pos": 29, "type": "DATASET", "confidence": 0.8188751637935638}, {"text": "automated essay scoring", "start_pos": 112, "end_pos": 135, "type": "TASK", "confidence": 0.5834243496259054}]}, {"text": "The motivation driving these competitions was to engage the larger scientific community in this enterprise.", "labels": [], "entities": []}, {"text": "MOOCs are now beginning to incorporate AWE systems to manage the thousands of constructed-response assignments collected during a single MOOC course.", "labels": [], "entities": [{"text": "AWE", "start_pos": 39, "end_pos": 42, "type": "METRIC", "confidence": 0.9213485717773438}]}, {"text": "Learning@Scale is another venue that discusses NLP research in education.", "labels": [], "entities": []}, {"text": "The Speech and Language Technology in Education (SLaTE), now in its seventh year, promotes the use of speech and language technology for educational purposes.", "labels": [], "entities": [{"text": "Speech and Language Technology in Education (SLaTE)", "start_pos": 4, "end_pos": 55, "type": "TASK", "confidence": 0.6947078042560153}]}, {"text": "Another breakthrough for educational applications within the CL community is the presence of a number of shared-task competitions over the last three years.", "labels": [], "entities": []}, {"text": "There have been four shared tasks on grammatical error correction with the last two held at.", "labels": [], "entities": [{"text": "grammatical error correction", "start_pos": 37, "end_pos": 65, "type": "TASK", "confidence": 0.7139856219291687}]}, {"text": "In 2014 alone, there were four shared tasks for NLP and Education-related areas.", "labels": [], "entities": []}, {"text": "We are pleased to announce a unique shared task at BEA this year: Automated Evaluation of Scientific Writing.", "labels": [], "entities": [{"text": "BEA", "start_pos": 51, "end_pos": 54, "type": "DATASET", "confidence": 0.8551524877548218}, {"text": "Automated Evaluation of Scientific Writing", "start_pos": 66, "end_pos": 108, "type": "TASK", "confidence": 0.7536592125892639}]}, {"text": "As a community, we continue to improve existing capabilities, and to identify and generate innovative ways to use NLP in applications for writing, reading, speaking, critical thinking, curriculum development, and assessment.", "labels": [], "entities": []}, {"text": "Steady growth in the development of NLP-based applications for education has prompted an increased number of workshops, typically focusing on one specific subfield.", "labels": [], "entities": []}, {"text": "In this workshop, we present papers from the following subfields: tools for automated scoring of text and speech, automated test-item generation, curriculum development, collaborative problem solving, content evaluation in text, dialogue and intelligent tutoring, evaluation of genres beyond essays, feedback studies, and grammatical error detection.", "labels": [], "entities": [{"text": "automated test-item generation", "start_pos": 114, "end_pos": 144, "type": "TASK", "confidence": 0.7122699618339539}, {"text": "collaborative problem solving", "start_pos": 170, "end_pos": 199, "type": "TASK", "confidence": 0.806331217288971}, {"text": "grammatical error detection", "start_pos": 322, "end_pos": 349, "type": "TASK", "confidence": 0.6228020687898}]}, {"text": "This year we received a record 46 submissions, and accepted 8 papers as oral presentations and 20 as poster presentation and/or demos, for an overall acceptance rate of 61%.", "labels": [], "entities": [{"text": "acceptance rate", "start_pos": 150, "end_pos": 165, "type": "METRIC", "confidence": 0.9364274740219116}]}, {"text": "Each paper was reviewed by three members of the Program Committee who were believed to be most appropriate for each paper.", "labels": [], "entities": []}, {"text": "We continue to have a very strong policy to deal with conflicts of interest.", "labels": [], "entities": []}, {"text": "First, we made a concerted effort to not assign papers to reviewers to evaluate if the paper had an author from their institution.", "labels": [], "entities": []}, {"text": "Second, with respect to the organizing committee, authors of papers for which there was a conflict of interest recused themselves from the discussions.", "labels": [], "entities": []}, {"text": "While the field is growing, we do recognize that there is a core group of institutions and researchers who work in this area.", "labels": [], "entities": []}, {"text": "With a higher acceptance rate, we were able to include papers from a wider variety of topics and institutions.", "labels": [], "entities": [{"text": "acceptance", "start_pos": 14, "end_pos": 24, "type": "METRIC", "confidence": 0.8792348504066467}]}, {"text": "The papers accepted were selected on the basis of several factors, including the relevance to a core educational problem space, the novelty of the approach or domain, and the strength of the research.", "labels": [], "entities": []}, {"text": "The accepted papers were highly diverse -an indicator of the growing variety of foci in this field.", "labels": [], "entities": []}, {"text": "For short-answer scoring, Horbach & Palmer explore the suitability of active learning for automatic short-answer assessment on the ASAP corpus; Banjade et al present a corpus that contains student answers annotated for their correctness in context, in addition to a baseline for predicting the correctness label; and Rudzewitz explores the practical usefulness of the combination of features from three different fields -short answer scoring, authorship attribution, and plagiarism detection -for two tasks: semantic learner language classification, and plagiarism detection for evaluating short answers.", "labels": [], "entities": [{"text": "short-answer scoring", "start_pos": 4, "end_pos": 24, "type": "TASK", "confidence": 0.8215891122817993}, {"text": "ASAP corpus", "start_pos": 131, "end_pos": 142, "type": "DATASET", "confidence": 0.8240988552570343}, {"text": "short answer scoring", "start_pos": 421, "end_pos": 441, "type": "TASK", "confidence": 0.6022724310557047}, {"text": "authorship attribution", "start_pos": 443, "end_pos": 465, "type": "TASK", "confidence": 0.7281721830368042}, {"text": "semantic learner language classification", "start_pos": 508, "end_pos": 548, "type": "TASK", "confidence": 0.706541121006012}]}, {"text": "For collaborative problem solving, Flor et al present a novel situational task that integrates collaborative problem solving behavior with testing in a science domain.", "labels": [], "entities": [{"text": "problem solving", "start_pos": 18, "end_pos": 33, "type": "TASK", "confidence": 0.703355222940445}]}, {"text": "For accessibility, Martinez-Santiago et al discuss computer-designed tools in order to help people with Autism Spectrum Disorder to palliate or overcome such verbal limitations.", "labels": [], "entities": []}, {"text": "As noted earlier, this year we are excited to host the first Shared Task in Automated Evaluation of Scientific Writing (http://textmining.lt/aesw/index.html).", "labels": [], "entities": []}, {"text": "The task involves automatically predicting whether sentences found in scientific language are in need of editing.", "labels": [], "entities": [{"text": "predicting whether sentences found in scientific language", "start_pos": 32, "end_pos": 89, "type": "TASK", "confidence": 0.7648330245699201}]}, {"text": "Six teams competed and their system description papers are found in these proceedings and are presented as posters in conjunction with the BEA11 poster session.", "labels": [], "entities": [{"text": "BEA11 poster session", "start_pos": 139, "end_pos": 159, "type": "DATASET", "confidence": 0.8868752320607504}]}, {"text": "A summary report of the shared task (Daudaravicius et al) is also found in the proceedings and will be presented orally.", "labels": [], "entities": []}, {"text": "We wish to thank everyone who showed interest and submitted a paper, all of the authors for their vi contributions, the members of the Program Committee for their thoughtful reviews, and everyone who attended this workshop.", "labels": [], "entities": []}, {"text": "We would especially like to thank our sponsors; at the Gold Level: American Institutes for Research (AIR), Cambridge Assessment, Educational Testing Service, Grammarly, Pacific Metrics and Turnitin / Lightside, and at the Silver Level: Cognii and iLexIR.", "labels": [], "entities": [{"text": "Cambridge Assessment", "start_pos": 107, "end_pos": 127, "type": "DATASET", "confidence": 0.9221372604370117}, {"text": "Educational Testing Service", "start_pos": 129, "end_pos": 156, "type": "DATASET", "confidence": 0.857538104057312}]}, {"text": "Their contributions allow us to subsidize students at the workshop dinner, and make workshop t-shirts!", "labels": [], "entities": []}, {"text": "We would like to thank Joya Tetreault for creating the t-shirt design (again!).", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": []}