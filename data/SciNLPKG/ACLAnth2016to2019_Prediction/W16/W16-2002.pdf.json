{"title": [{"text": "The SIGMORPHON 2016 Shared Task-Morphological Reinflection", "labels": [], "entities": [{"text": "SIGMORPHON 2016 Shared Task-Morphological Reinflection", "start_pos": 4, "end_pos": 58, "type": "TASK", "confidence": 0.7468760013580322}]}], "abstractContent": [{"text": "The 2016 SIGMORPHON Shared Task was devoted to the problem of morphological reinflection.", "labels": [], "entities": [{"text": "morphological reinflection", "start_pos": 62, "end_pos": 88, "type": "TASK", "confidence": 0.7986112534999847}]}, {"text": "It introduced morphological datasets for 10 languages with diverse ty-pological characteristics.", "labels": [], "entities": []}, {"text": "The shared task drew submissions from 9 teams representing 11 institutions reflecting a variety of approaches to addressing supervised learning of reinflection.", "labels": [], "entities": []}, {"text": "For the simplest task, inflection generation from lemmas, the best system averaged 95.56% exact-match accuracy across all languages, ranging from Maltese (88.99%) to Hungarian (99.30%).", "labels": [], "entities": [{"text": "inflection generation", "start_pos": 23, "end_pos": 44, "type": "TASK", "confidence": 0.7843742668628693}, {"text": "exact-match", "start_pos": 90, "end_pos": 101, "type": "METRIC", "confidence": 0.9639551043510437}, {"text": "accuracy", "start_pos": 102, "end_pos": 110, "type": "METRIC", "confidence": 0.83643639087677}]}, {"text": "With the relatively large training datasets provided, recurrent neural network architec-tures consistently performed best-in fact, there was a significant margin between neu-ral and non-neural approaches.", "labels": [], "entities": []}, {"text": "The best neural approach, averaged overall tasks and languages, outperformed the best non-neural one by 13.76% absolute; on individual tasks and languages the gap inaccuracy sometimes exceeded 60%.", "labels": [], "entities": []}, {"text": "Overall, the results show a strong state of the art, and serve as encouragement for future shared tasks that explore morphological analysis and generation with varying degrees of supervision .", "labels": [], "entities": [{"text": "morphological analysis and generation", "start_pos": 117, "end_pos": 154, "type": "TASK", "confidence": 0.6750471740961075}]}], "introductionContent": [{"text": "Many languages use systems of rich overt morphological marking in the form of affixes (i.e. suffixes, prefixes, and infixes) to convey syntactic and semantic distinctions.", "labels": [], "entities": []}, {"text": "For example, each English count noun has both singular and plural forms (e.g. robot/robots, process/processes), and these are known as the inflected forms of the noun.", "labels": [], "entities": []}, {"text": "While English has relatively little inflectional morphology, Russian nouns, for example, can have a total of 10 distinct word forms for any given  lemma and 30 for an imperfective verb.", "labels": [], "entities": []}, {"text": "In the extreme, demonstrates that even by a conservative count, a verb conjugation in Archi (Nakh-Daghestanian) consists of 1,725 forms, and if all sources of complexity are considered, a single verb lemma may give rise to up to 1,502,839 distinct forms.", "labels": [], "entities": []}, {"text": "The fact that inflected forms are systematically related to each other, as shown in, is what allows humans to generate and analyze words despite this level of morphological complexity.", "labels": [], "entities": []}, {"text": "A core problem that arises in languages with rich morphology is data sparsity.", "labels": [], "entities": []}, {"text": "When a single lexical item can appear in many different word forms, the probability of encountering any single word form decreases, reducing the effectiveness of frequency-based techniques in performing tasks like word alignment and language modeling).", "labels": [], "entities": [{"text": "word alignment", "start_pos": 214, "end_pos": 228, "type": "TASK", "confidence": 0.8024107217788696}, {"text": "language modeling", "start_pos": 233, "end_pos": 250, "type": "TASK", "confidence": 0.7238571047782898}]}, {"text": "Techniques like lemmatization and stemming can ameliorate data sparsity), but these rely on morphological knowledge, particularly the mapping from inflected forms to lemmas and the list of morphs together with their ordering.", "labels": [], "entities": []}, {"text": "Developing systems that can accurately learn and capture these mappings, overt affixes, and the principles that govern how those affixes combine is crucial to maximizing the crosslinguistic capabilities of most human language technology.", "labels": [], "entities": []}, {"text": "The goal of the 2016 SIGMORPHON Shared Task 2 was to spur the development of systems that could accurately generate morphologically inflected words fora set of 10 languages based on a range of training parameters.", "labels": [], "entities": [{"text": "SIGMORPHON Shared Task 2", "start_pos": 21, "end_pos": 45, "type": "TASK", "confidence": 0.7817337661981583}]}, {"text": "These 10 languages included low resource languages with diverse morphological characteristics, and the training parameters reflected a significant expansion upon the traditional task of predicting a full paradigm from a lemma.", "labels": [], "entities": []}, {"text": "Of the systems submitted, the neural network-based systems performed best, clearly demonstrating the effectiveness of recurrent neural networks (RNNs) for morphological generation and analysis.", "labels": [], "entities": [{"text": "morphological generation and analysis", "start_pos": 155, "end_pos": 192, "type": "TASK", "confidence": 0.7391691654920578}]}, {"text": "We are releasing the shared task data and evaluation scripts for use in future research.", "labels": [], "entities": []}], "datasetContent": [{"text": "Up to the present, the task of morphological inflection has been narrowly defined as the generation of a complete inflectional paradigm from a lemma, based on training from a corpus of complete paradigms.", "labels": [], "entities": [{"text": "morphological inflection", "start_pos": 31, "end_pos": 55, "type": "TASK", "confidence": 0.7202958166599274}]}, {"text": "This task implicitly assumes the availability of a traditional dictionary or gazetteer, does not require explicit morphological analysis, and, though it mimics a common task in second language (L2) pedagogy, it is not a realistic learning setting for first language (L1) acquisition.", "labels": [], "entities": [{"text": "first language (L1) acquisition", "start_pos": 251, "end_pos": 282, "type": "TASK", "confidence": 0.6243918538093567}]}, {"text": "Systems developed for the 2016 Shared Task had to carryout reinflection of an already inflected form.", "labels": [], "entities": [{"text": "Shared Task", "start_pos": 31, "end_pos": 42, "type": "TASK", "confidence": 0.7191864252090454}]}, {"text": "This involved analysis of an already in-2 Official website: http://ryancotterell.", "labels": [], "entities": []}, {"text": "github.io/sigmorphon2016/ 3 A paradigm is defined here as the set of inflected word forms associated with a single lemma (or lexeme), for example, a noun declension or verb conjugation.: Systems were required to generate the target form, given the information above the line.", "labels": [], "entities": []}, {"text": "Two examples are shown for each task-one in English and one in Spanish.", "labels": [], "entities": []}, {"text": "Task 1 is inflection; tasks 2-3 are reinflection.", "labels": [], "entities": []}, {"text": "Restricted Standard Bonus 1, 2 1, 2, M 1, 2, 3 1, 2, 3, M flected word form, together with synthesis of a different inflection of that form.", "labels": [], "entities": []}, {"text": "The systems had to learn from limited data: they were not given complete paradigms to train on, nor a dictionary of lemmas.", "labels": [], "entities": []}, {"text": "Specifically, systems competed on the three tasks illustrated in, of increasing difficulty.", "labels": [], "entities": []}, {"text": "Notice that each task can be regarded as mapping a source string to a target string, with other input arguments (such as the target tag) that specify which version of the mapping is desired.", "labels": [], "entities": []}, {"text": "For each language and each task, participants were provided with supervised training data: a collection of input tuples, each paired with the correct output string (target form).", "labels": [], "entities": []}, {"text": "Each system could compete on a task under any of three tracks.", "labels": [], "entities": []}, {"text": "Under the restricted track, only data for that task could be used, while for the standard track, data from that task and any from a lower task could be used.", "labels": [], "entities": []}, {"text": "The bonus track was the same as the standard track, but allowed the use of monolingual data in the form of Wikipedia dumps from 2 November 2015.", "labels": [], "entities": []}, {"text": "Each system was required to produce, for every input given attest time, either a single string or a ranked list of up to 20 predicted strings for each task.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 4: Percentage of inflected word forms that have modi- fied each part of the lemma, as estimated from the \"lemma \u2192  inflected\" pairs in task 1 training data. A sum < 100% for a  language implies that sometimes source and target forms are  identical; a sum > 100% implies that sometimes multiple  parts are modified.", "labels": [], "entities": []}, {"text": " Table 5: Accuracy results for the baseline system on the stan- dard track test set.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9991348385810852}, {"text": "stan- dard track test set", "start_pos": 58, "end_pos": 83, "type": "DATASET", "confidence": 0.7056151578823725}]}, {"text": " Table 6: Summary of results, showing average rank (with respect to other competitors) and average accuracy (equally weighted  average over the 10 languages and marked in parentheses) by system. Oracle ensemble (ORACLE.E) accuracy represents the  probability that at least one of the submitted systems predicted the correct form.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 99, "end_pos": 107, "type": "METRIC", "confidence": 0.9907083511352539}, {"text": "Oracle ensemble (ORACLE.E) accuracy", "start_pos": 195, "end_pos": 230, "type": "METRIC", "confidence": 0.5901814301808676}]}]}