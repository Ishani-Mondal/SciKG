{"title": [{"text": "A Proposal for Linguistic Similarity Datasets Based on Commonality Lists", "labels": [], "entities": []}], "abstractContent": [{"text": "Similarity is a core notion that is used in psychology and two branches of linguistics: theoretical and computational.", "labels": [], "entities": [{"text": "Similarity", "start_pos": 0, "end_pos": 10, "type": "TASK", "confidence": 0.9550842642784119}]}, {"text": "The similarity datasets that come from the two fields differ in design: psychological datasets are focused around a certain topic such as fruit names, while linguistic datasets contain words from various categories.", "labels": [], "entities": []}, {"text": "The later makes humans assign low similarity scores to the words that have nothing in common and to the words that have contrast in meaning, making similarity scores ambiguous.", "labels": [], "entities": []}, {"text": "In this work we discuss the similarity collection procedure fora multi-category dataset that avoids score ambiguity and suggest changes to the evaluation procedure to reflect the insights of psychological literature for word, phrase and sentence similarity.", "labels": [], "entities": [{"text": "similarity collection", "start_pos": 28, "end_pos": 49, "type": "TASK", "confidence": 0.6570360064506531}, {"text": "word, phrase and sentence similarity", "start_pos": 220, "end_pos": 256, "type": "TASK", "confidence": 0.6142789671818415}]}, {"text": "We suggest to ask humans to provide a list of commonalities and differences instead of numerical similarity scores and employ the structure of human judgements beyond pairwise similarity for model evaluation.", "labels": [], "entities": []}, {"text": "We believe that the proposed approach will give rise to datasets that test meaning representation models more thoroughly with respect to the human treatment of similarity.", "labels": [], "entities": []}], "introductionContent": [{"text": "Similarity is the degree of resemblance between two objects or events and plays a crucial role in psychological theories of knowledge and behaviour, where it is used to explain such phenomena as classification and conceptualisation.", "labels": [], "entities": []}, {"text": "Fruit is a category because it is a practical generalisation.", "labels": [], "entities": []}, {"text": "Fruits are sweet and constitute deserts, so when one is presented with an unknown fruit, one can hypothesise that it is served toward the end of a dinner.", "labels": [], "entities": []}, {"text": "Generalisations are extremely powerful in describing a language as well.", "labels": [], "entities": []}, {"text": "The verb runs requires its subject to be singular.", "labels": [], "entities": []}, {"text": "Verb, subject and singular are categories that are used to describe English grammar.", "labels": [], "entities": []}, {"text": "When one encounters an unknown word and is told that it is a verb, one will immediately have an idea about how to use it assuming that it is used similarly to other English verbs.", "labels": [], "entities": []}, {"text": "The semantic formalisation of similarity is based on two ideas.", "labels": [], "entities": [{"text": "semantic formalisation of similarity", "start_pos": 4, "end_pos": 40, "type": "TASK", "confidence": 0.6810554265975952}]}, {"text": "The occurrence pattern of a word defines its meaning, while the difference in occurrence between two words quantifies the difference in their meaning.", "labels": [], "entities": []}, {"text": "From a computational perspective, this motivates and guides development of similarity components that are embedded into natural language processing systems that deal with tasks such as word sense disambiguation, information retrieval, machine translation (, dependency parsing (, and dialogue act tagging.", "labels": [], "entities": [{"text": "word sense disambiguation", "start_pos": 185, "end_pos": 210, "type": "TASK", "confidence": 0.6536532739798228}, {"text": "information retrieval", "start_pos": 212, "end_pos": 233, "type": "TASK", "confidence": 0.7817999124526978}, {"text": "machine translation", "start_pos": 235, "end_pos": 254, "type": "TASK", "confidence": 0.8312048017978668}, {"text": "dependency parsing", "start_pos": 258, "end_pos": 276, "type": "TASK", "confidence": 0.7242725789546967}, {"text": "dialogue act tagging", "start_pos": 284, "end_pos": 304, "type": "TASK", "confidence": 0.6451529860496521}]}, {"text": "Because it is difficult to measure performance of a single (similarity) component in a pipeline, datasets that focus on similarity are popular among computational linguists.", "labels": [], "entities": []}, {"text": "Apart from a pragmatic attempt to alleviate the problems of evaluating similarity components, these datasets serve as an empirical test of the hypotheses of Firth and Harris, bringing together our understanding of human mind, language and technology.", "labels": [], "entities": []}, {"text": "Two datasets, namely MEN () and SimLex-999 (, are currently widely used.", "labels": [], "entities": [{"text": "MEN", "start_pos": 21, "end_pos": 24, "type": "DATASET", "confidence": 0.800656259059906}]}, {"text": "They are designed especially for meaning representation evaluation and surpass datasets stemming from psychology, information retrieval () and computational linguistics) in quantity by having more entries and, in case of SimLex-999, attention to the evaluated relation by distinguishing similarity from relatedness.", "labels": [], "entities": [{"text": "meaning representation evaluation", "start_pos": 33, "end_pos": 66, "type": "TASK", "confidence": 0.9050671656926473}]}, {"text": "The datasets provide similarity (relatedness) scores between word pairs.", "labels": [], "entities": [{"text": "similarity (relatedness) scores", "start_pos": 21, "end_pos": 52, "type": "METRIC", "confidence": 0.8320979952812195}]}, {"text": "In contrast to linguistic datasets which contain randomly paired words from abroad selection, datasets that come from psychology contain entries that belong to a single category such as verbs of judging or animal terms.", "labels": [], "entities": []}, {"text": "The reason for category oriented similarity studies is that \"stimuli can only be compared in so far as they have already been categorised as identical, alike, or equivalent at some higher level of abstraction\".", "labels": [], "entities": []}, {"text": "Moreover, because of the extension effect (, the similarity of two entries in a context is less than the similarity between the same entries when the context is extended.", "labels": [], "entities": []}, {"text": "\"For example, black and white received a similarity rating of 2.2 when presented by themselves; this rating increased to 4.0 when black was simultaneously compared with white and red (red only increased 4.2 to 4.9)\").", "labels": [], "entities": [{"text": "similarity", "start_pos": 41, "end_pos": 51, "type": "METRIC", "confidence": 0.9576475024223328}]}, {"text": "In the first case black and white are more dissimilar because they are located on the extremes of the greyscale, but in the presence of red they become more similar because they are both monochromes.", "labels": [], "entities": []}, {"text": "Both MEN and SimLex-999 provide pairs that do not share any similarity to control for false positives, and they do not control for the comparison scale.", "labels": [], "entities": [{"text": "MEN", "start_pos": 5, "end_pos": 8, "type": "DATASET", "confidence": 0.8854804635047913}]}, {"text": "This makes similarity judgements ambiguous as it is not clear what low similarity values mean: incomparable notions, contrast in meaning or even the difference in comparison context.", "labels": [], "entities": []}, {"text": "SimLex-999 assigns low similarity scores to the incomparable pairs (0.48, trick and size) and to antonymy (0.55, smart and dumb), but smart and dumb have relatively much more in common than trick and size!", "labels": [], "entities": []}, {"text": "The present contribution investigates how a similarity dataset with multiple categories should be built and considers what sentence similarity means in this context.", "labels": [], "entities": []}], "datasetContent": [{"text": "Human similarity judgements To build a similarity dataset that contains non-overlapping categories, one needs to avoid comparison of incomparable pairs.", "labels": [], "entities": [{"text": "Human similarity judgements", "start_pos": 0, "end_pos": 27, "type": "TASK", "confidence": 0.5853316982587179}]}, {"text": "However, that itself requires an a priori knowledge of item similarity or belongingness to a category, making the problem circular.", "labels": [], "entities": []}, {"text": "To get out of this vicious circle, one might erroneously refer to an already existing taxonomy such as WordNet.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 103, "end_pos": 110, "type": "DATASET", "confidence": 0.9847079515457153}]}, {"text": "But in case of similarity, as Turney (2012) points out, categories that emerge from similarity judgements are different from taxonomies.", "labels": [], "entities": []}, {"text": "For example, traffic and water might be considered to be similar because of a functional similarity exploited in hydrodynamic models of traffic, but their lowest common ancestor in WordNet is entity.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 181, "end_pos": 188, "type": "DATASET", "confidence": 0.9454334378242493}]}, {"text": "Since there is noway of deciding upfront whether there is a similarity relation between two words, the data collection procedure needs to test for both: relation existence and its strength.", "labels": [], "entities": []}, {"text": "Numerical values, as has been shown in the introduction, do not fit this role due to ambiguity.", "labels": [], "entities": []}, {"text": "One way to avoid the issue is to avoid asking humans for numerical similarity judgements, but instead to ask them to list commonalities and differences between the objects.", "labels": [], "entities": []}, {"text": "As one might expect, similarity scores correlate with the number of listed commonalities).", "labels": [], "entities": [{"text": "similarity", "start_pos": 21, "end_pos": 31, "type": "METRIC", "confidence": 0.981357991695404}]}, {"text": "For incomparable pairs, the commonality list should be empty, but the differences will enumerate properties that belong to one entity, but not to another.", "labels": [], "entities": []}, {"text": "Verbally produced features (norms) for empirically derived conceptual representation of is a good example of what and how the data should be collected.", "labels": [], "entities": []}, {"text": "But in contrast to-where explicit comparison of concepts was avoided-participants should be asked to produce commonalities as part of similarity comparison.", "labels": [], "entities": []}, {"text": "The entries in the dataset So far, we have proposed a similarity judgement collection method that is robust to incomparable pairings.", "labels": [], "entities": [{"text": "similarity judgement collection", "start_pos": 54, "end_pos": 85, "type": "TASK", "confidence": 0.6702111661434174}]}, {"text": "It also naturally gives rise to categories, because the absence of a relation between two entries means the absence of a common category.", "labels": [], "entities": []}, {"text": "It still needs to be decided which words to include in the dataset.", "labels": [], "entities": []}, {"text": "To get a list of words that constitute the dataset, one might think of categories such as sports, fruits, vegetables, judging verbs, countries, colours and soon.", "labels": [], "entities": []}, {"text": "Note, that at this point its acceptable to think of categories, because later the arbitrary category assignments will be reevaluated.", "labels": [], "entities": []}, {"text": "Once the list of categories is ready, each of them is populated with category instances, e.g. plum, banana and lemon are all fruits.", "labels": [], "entities": []}, {"text": "When the data is prepared, humans are asked to provide commonalities and differences between all pairs of every group.", "labels": [], "entities": []}, {"text": "First, all expected sim-ilarities are judged, producing a dataset that can be seen as a merged version of category specific datasets.", "labels": [], "entities": []}, {"text": "At this point, a good similarity model should provide meaning representation that are easily split to clusters: fruit members and sport members have to be separable.", "labels": [], "entities": []}, {"text": "Intra-category comparisons should be also performed, but because it is impractical to collect all possible pairwise judgements between the number of words of magnitude of hundreds, a reasonable sample should betaken.", "labels": [], "entities": []}, {"text": "The intra-category comparisons will lead to unexpected category pairings, such as food that contains vegetables and fruits, so the sampling procedure might be directed by the discovery of comparable pairs: when a banana and potato are said to be similar, fruits and vegetables members should be more likely to be assessed.", "labels": [], "entities": []}, {"text": "Given the dynamic nature of score collection, we suggest setting up a game with a purpose (see an example) where players are rewarded for contributing their commonality lists.", "labels": [], "entities": []}, {"text": "Another option would be to crowdsource the human judgements (.", "labels": [], "entities": []}, {"text": "Evaluation beyond proximity Human judgements validate the initial category assignment of items and provide new ones.", "labels": [], "entities": []}, {"text": "If a category contains a superordinate, similarity judgements arrange category members around it.", "labels": [], "entities": []}, {"text": "For example, similarity judgements given by humans arrange fruit names around the word fruit in such away that it is their nearest neighbour, making fruit the focal point of the category of fruits.", "labels": [], "entities": []}, {"text": "As an additional evaluation method, the model should be able to retrieve focal points.", "labels": [], "entities": []}, {"text": "Therefore, a precaution should betaken before human judgement collection.", "labels": [], "entities": [{"text": "human judgement collection", "start_pos": 46, "end_pos": 72, "type": "TASK", "confidence": 0.5979769031206766}]}, {"text": "If possible, categories should contain a superordinate.", "labels": [], "entities": []}, {"text": "Similarity evaluation needs to focus on how well a model is able to recover human similarity intuitions expressed as groupings, possibly around their focal points.", "labels": [], "entities": [{"text": "Similarity evaluation", "start_pos": 0, "end_pos": 21, "type": "TASK", "confidence": 0.9579494893550873}]}, {"text": "We propose to treat it as a soft multi-class clustering problem (, where two entities belong to the same class if there is a similarity judgement for them (e.g. apple and banana are similar because they are fruits) and the strength is proportional to the number of such judgements, so we could express that apple is more a fruit than it is a company.", "labels": [], "entities": []}, {"text": "In contrast to the current evaluation based on correlation, models also need to be tested on the geometric arrangement of subordinates around the focal points, as only the proximity based evaluation does not capture this).", "labels": [], "entities": []}], "tableCaptions": []}