{"title": [{"text": "On Why Coarse Class Classification is a Bottleneck for Noun Compound Interpretation", "labels": [], "entities": [{"text": "Coarse Class Classification", "start_pos": 7, "end_pos": 34, "type": "TASK", "confidence": 0.5256077150503794}]}], "abstractContent": [{"text": "Sequences of long nouns, i.e., noun compounds , occur frequently and are productive.", "labels": [], "entities": []}, {"text": "Their interpretation is important fora variety of tasks located at various layers of NLP.", "labels": [], "entities": []}, {"text": "Major reasons behind the poor performance of automatic noun compound interpretation are: (a) lack of a well defined inventory of semantic relations and (b) non-availability of sufficient, annotated, high-quality dataset.", "labels": [], "entities": [{"text": "noun compound interpretation", "start_pos": 55, "end_pos": 83, "type": "TASK", "confidence": 0.7047229210535685}]}, {"text": "Tratz and Hovy (2010) presented an inventory of semantic relations.", "labels": [], "entities": []}, {"text": "They compared existing inventories with their two-level hierarchy, and created a large annotated dataset.", "labels": [], "entities": []}, {"text": "We performed both theoretical as well as data-driven analysis of this inventory.", "labels": [], "entities": []}, {"text": "Theoretical analysis reveal ambiguities in the coarse relations.", "labels": [], "entities": []}, {"text": "Data-driven analysis report similar performance for coarse as well as fine relations prediction.", "labels": [], "entities": [{"text": "fine relations prediction", "start_pos": 70, "end_pos": 95, "type": "TASK", "confidence": 0.660802960395813}]}, {"text": "Our experiments show that improving the coarse classification accuracy can improve the performance of fine class predic-tor by 13 to 30 points in F-score.", "labels": [], "entities": [{"text": "coarse classification", "start_pos": 40, "end_pos": 61, "type": "TASK", "confidence": 0.6523350477218628}, {"text": "accuracy", "start_pos": 62, "end_pos": 70, "type": "METRIC", "confidence": 0.9400524497032166}, {"text": "F-score", "start_pos": 146, "end_pos": 153, "type": "METRIC", "confidence": 0.9920433163642883}]}], "introductionContent": [{"text": "An important characteristic of a language is the process of creating new words by means of compounding.", "labels": [], "entities": []}, {"text": "Especially, in English, technical and scientific literature produces long sequences of nouns, such as laptop screen, Internet connection, colon cancer symptoms, etc.", "labels": [], "entities": []}, {"text": "Following's definition (for English language), these long sequences of nouns, acting as single noun, are known as noun compounds (NCs).", "labels": [], "entities": []}, {"text": "NLP tasks cannot ignore such long sequences of nouns as they are abundant and productive type of compounds in English.", "labels": [], "entities": []}, {"text": "Most noun compounds appear only once in a large corpus.", "labels": [], "entities": []}, {"text": "analyzed the BNC corpus and found that 63.4% of total noun compounds appear only once in the corpus.", "labels": [], "entities": [{"text": "BNC corpus", "start_pos": 13, "end_pos": 23, "type": "DATASET", "confidence": 0.9549665451049805}]}, {"text": "In addition to the productive nature, noun compounds are compositional.", "labels": [], "entities": []}, {"text": "These characteristics of the noun compounds make them a special case, and demand a special treatment.", "labels": [], "entities": []}, {"text": "The conventional approach to tackle this problem is a pipeline of three steps: (1) find noun compounds from text, (2) parse them if required, and (3) extract the semantic relationships between components of the noun compounds.", "labels": [], "entities": []}, {"text": "The task of extracting semantic relations between components of a noun compound, or paraphrasing it using verbs and/or prepositions is known as interpretation of noun compound (or noun compound interpretation).", "labels": [], "entities": [{"text": "interpretation of noun compound", "start_pos": 144, "end_pos": 175, "type": "TASK", "confidence": 0.8342756032943726}, {"text": "noun compound interpretation)", "start_pos": 180, "end_pos": 209, "type": "TASK", "confidence": 0.6656006574630737}]}, {"text": "Our primary interest resides in interpretation of twoword noun compounds using predefined semantic labels as classes.", "labels": [], "entities": [{"text": "interpretation of twoword noun compounds", "start_pos": 32, "end_pos": 72, "type": "TASK", "confidence": 0.8327975273132324}]}, {"text": "The labels have been arranged in a two level hierarchy -coarse classes and fine classes.", "labels": [], "entities": []}, {"text": "In this paper, we report the technical and linguistic challenges that we faced while performing classification task.", "labels": [], "entities": [{"text": "classification task", "start_pos": 96, "end_pos": 115, "type": "TASK", "confidence": 0.9226137399673462}]}, {"text": "Particularly, we discuss the challenges with coarse level classification.", "labels": [], "entities": [{"text": "coarse level classification", "start_pos": 45, "end_pos": 72, "type": "TASK", "confidence": 0.5825915038585663}]}, {"text": "The rest of the paper is organized as follows: Section 2 covers the related work.", "labels": [], "entities": []}, {"text": "Section 3 discusses our approach, the experiments and results for the same are shown in Section 4.", "labels": [], "entities": []}, {"text": "Section 5 discusses the results, which is followed by conclusion and future work.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section we explain dataset creation, experiment setup, and the results.", "labels": [], "entities": [{"text": "dataset creation", "start_pos": 27, "end_pos": 43, "type": "TASK", "confidence": 0.7646444141864777}]}, {"text": "An analysis of experiments is discussed in the next section.", "labels": [], "entities": []}, {"text": "For our experiment, we used Tratz and Hovy (2010)'s relation inventory and dataset.", "labels": [], "entities": []}, {"text": "This inventory has 43 fine relations, grouped under 9 coarse relations.", "labels": [], "entities": [{"text": "coarse", "start_pos": 54, "end_pos": 60, "type": "METRIC", "confidence": 0.9393491744995117}]}, {"text": "In this dataset, each example has been labeled with one of 43 fine semantic relations.", "labels": [], "entities": []}, {"text": "We can get coarse class label indirectly as each fine relation belongs to exactly one coarse relation.", "labels": [], "entities": []}, {"text": "There are totally 19036 examples of noun-noun compounds in the Tratz and Hovy (2010)'s dataset.", "labels": [], "entities": [{"text": "Tratz and Hovy (2010)'s dataset", "start_pos": 63, "end_pos": 94, "type": "DATASET", "confidence": 0.6217226721346378}]}, {"text": "Some examples in the dataset contain more than one word as a component, e.g., health-care legislation, real-estate speculation.", "labels": [], "entities": []}, {"text": "We also eliminate examples for which at least one components has no word vector.", "labels": [], "entities": []}, {"text": "This result in 18857 examples.", "labels": [], "entities": []}, {"text": "We used Google's pre-trained word vectors to create feature vectors.", "labels": [], "entities": []}, {"text": "For example, feature vector of passenger traffic is concatenation of two vectors: vector of passenger and vector of traffic.", "labels": [], "entities": []}, {"text": "We shuffled our dataset, and split it into three disjoint sets: train set (65%), validation set (15%), and test set (20%).", "labels": [], "entities": []}, {"text": "The system was trained on the train set.", "labels": [], "entities": []}, {"text": "The validation set was used for validation and hyperparameter searching.", "labels": [], "entities": [{"text": "validation", "start_pos": 32, "end_pos": 42, "type": "TASK", "confidence": 0.9600638747215271}, {"text": "hyperparameter searching", "start_pos": 47, "end_pos": 71, "type": "TASK", "confidence": 0.7488757967948914}]}, {"text": "The system was evaluated on the test set.", "labels": [], "entities": []}, {"text": "To check our hypothesis, we defined four types of systems.", "labels": [], "entities": []}, {"text": "Table 2 defines system types based on the input feature vector and the output classes.", "labels": [], "entities": []}, {"text": "Given the word embeddings of a noun compound, Type-3 and Type-4 systems predict a coarse relation and a fine relation, respectively.", "labels": [], "entities": []}, {"text": "Type-1 and Type-2 systems are modeled as follows: given a noun compound and true coarse relation, predict a fine relation.", "labels": [], "entities": []}, {"text": "The sole difference between them is how coarse-class information is represented.", "labels": [], "entities": []}, {"text": "It is represented as 1-hot encoding in Type-1 system, whereas as a single numeric value in Type-2.", "labels": [], "entities": []}, {"text": "For all of these multi-class classifications, we used one-vs-one and one-vs-rest techniques.", "labels": [], "entities": []}, {"text": "Performance of the system in both sets of techniques are very similar.", "labels": [], "entities": []}, {"text": "summarizes the results of various classifiers with different settings.", "labels": [], "entities": []}, {"text": "SVM with polynomial kernel (degree=2, and soft margin constant C=10) outperforms all classifiers for all the mentioned systems.", "labels": [], "entities": [{"text": "SVM", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.6583940386772156}, {"text": "soft margin constant C", "start_pos": 42, "end_pos": 64, "type": "METRIC", "confidence": 0.9333906918764114}]}, {"text": "SVM results are separately shown in: SVM (polynomial, degree 2, C 10) Results for all system types.", "labels": [], "entities": [{"text": "SVM", "start_pos": 37, "end_pos": 40, "type": "DATASET", "confidence": 0.759635865688324}]}], "tableCaptions": [{"text": " Table 1: Performance of past approaches for noun compound interpretation. Note that (almost) all methods use  different relation inventory and different dataset making it difficult to compare performance.", "labels": [], "entities": [{"text": "noun compound interpretation", "start_pos": 45, "end_pos": 73, "type": "TASK", "confidence": 0.8523678779602051}]}, {"text": " Table 3: SVM (polynomial, degree 2, C 10) Results for  all system types.", "labels": [], "entities": []}, {"text": " Table 4: Confusion matrix for the coarse class pre- dictor (Type-3) using SVM. (C1: \"Causal Group\",  C2: \"Function / Purpose Clusters\", C3: \"Ownership,  Employment, and Use\", C4: \"Time\", C5: \"Location  & Whole+Part\", C6: \"Composition / Containment\",  C7: \"Topical\", C8: \"Coreferential / Attributive\", C9:  \"Other\")", "labels": [], "entities": []}, {"text": " Table 5: Confusion matrix for the coarse class predictor  (Type-3) using SVM. For the labels, refer Table 4.", "labels": [], "entities": []}]}