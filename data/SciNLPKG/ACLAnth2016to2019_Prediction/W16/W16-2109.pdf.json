{"title": [{"text": "Semi-automated annotation of page-based documents within the Genre and Multimodality framework", "labels": [], "entities": []}], "abstractContent": [{"text": "This paper describes ongoing work on a tool developed for annotating document images for their multimodal features and compiling this information into a corpus.", "labels": [], "entities": []}, {"text": "The tool leverages open source computer vision and natural language processing libraries to describe the content and structure of multimodal documents and to generate multiple layers of XML annotation.", "labels": [], "entities": []}, {"text": "The paper introduces the annotation schema, describes the document processing pipeline and concludes with a brief description of future work.", "labels": [], "entities": []}], "introductionContent": [{"text": "Multimodality -or how multiple modes of communication interact and co-operate -has become a concern within many fields that fall under the umbrella of digital humanities).", "labels": [], "entities": []}, {"text": "Whereas gestures, gaze and postures accompany spoken language in faceto-face conversation, written language works together with photographs, diagrams, typography and other communicative resources in documents.", "labels": [], "entities": []}, {"text": "Given the inherent complexity of multimodal phenomena, combined with the variation arising from contextual factors, corpus-based approaches have been suggested as necessary for bringing multimodality under increased analytical control.", "labels": [], "entities": []}, {"text": "This paper contributes to the empirical study of multimodality in page-based documents by presenting a prototype tool for creating multimodal corpora from document images that were not born digital.", "labels": [], "entities": []}, {"text": "The tool generates stand-off XML annotation following the Genre and Multimodality (GeM) model, which provides an annotation schema with multiple layers of description that attend to the content, layout, appearance and discourse relations in page-based documents).", "labels": [], "entities": []}, {"text": "The GeM annotation schema, which is intended to \"function as a tool for isolating significant patterns against the mass of detail that multimodal documents naturally present\", has proven useful for comparing the multimodality of documents across cultures and describing their changeover time).", "labels": [], "entities": []}, {"text": "Yet the GeM model has not been adopted widely, because applying the multi-layered annotation schema requires ample time and resources.", "labels": [], "entities": []}, {"text": "This requirement arises from the aforementioned mass of detail that occurs in multimodal documents.", "labels": [], "entities": []}, {"text": "The tool presented in this paper attacks the bottleneck issues of time and resources by leveraging several open source computer vision and optical character recognition libraries for the semiautomatic annotation of multimodal documents.", "labels": [], "entities": [{"text": "optical character recognition", "start_pos": 139, "end_pos": 168, "type": "TASK", "confidence": 0.6480424006779989}]}, {"text": "To support this task, the paper proposes a variant of the GeM annotation schema named auto-GeM.", "labels": [], "entities": []}, {"text": "This variant of the annotation schema is geared towards generating machine-readable annotation, which maybe studied using tools developed for the purpose, while also providing ground truths for specific document genres, whose availability is considered a prerequisite for automating other parts of the annotation process.", "labels": [], "entities": []}, {"text": "The paper begins with a brief introduction to the GeM model and its annotation schema, relating the work on the prototype tool to previous attempts at automating parts of the annotation process.", "labels": [], "entities": []}, {"text": "The document processing pipeline and the proposed auto-GeM annotation schema are then described in greater detail.", "labels": [], "entities": []}, {"text": "Finally, the conclusion outlines current challenges and sketches future work on the tool.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": []}