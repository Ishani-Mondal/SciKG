{"title": [], "abstractContent": [{"text": "The increasing amount of biomedical information that is available for researchers and clinicians makes it harder to quickly find the right information.", "labels": [], "entities": []}, {"text": "Automatic summarization of multiple texts can provide summaries specific to the user's information needs.", "labels": [], "entities": [{"text": "summarization of multiple texts", "start_pos": 10, "end_pos": 41, "type": "TASK", "confidence": 0.8747399896383286}]}, {"text": "In this paper we look into the use named-entity recognition for graph-based summarization.", "labels": [], "entities": [{"text": "named-entity recognition", "start_pos": 35, "end_pos": 59, "type": "TASK", "confidence": 0.7542427778244019}, {"text": "summarization", "start_pos": 76, "end_pos": 89, "type": "TASK", "confidence": 0.7358987331390381}]}, {"text": "We extend the LexRank algorithm with information about named entities and present EntityRank, a multi-document graph-based summarization algorithm that is solely based on named entities.", "labels": [], "entities": []}, {"text": "We evaluate our system on a datasets of 1009 human written summaries provided by BioASQ and on 1974 gene summaries, fetched from the Entrez Gene database.", "labels": [], "entities": [{"text": "BioASQ", "start_pos": 81, "end_pos": 87, "type": "DATASET", "confidence": 0.8948501348495483}, {"text": "Entrez Gene database", "start_pos": 133, "end_pos": 153, "type": "DATASET", "confidence": 0.9642572402954102}]}, {"text": "The results show that the addition of named-entity information increases the performance of graph-based summarizers and that the EntityRank significantly outperforms the other methods with regard to the ROUGE measures.", "labels": [], "entities": [{"text": "ROUGE", "start_pos": 203, "end_pos": 208, "type": "METRIC", "confidence": 0.7515782713890076}]}], "introductionContent": [{"text": "There is an overload of textual information, also in the biomedical domain, where new research articles are published daily.", "labels": [], "entities": []}, {"text": "Text summarization can support to deal with this textual data deluge by providing automatically generated summaries on certain topics, e.g., a gene or a disease, as well as supporting answers returned by question answering (QA) systems.", "labels": [], "entities": [{"text": "Text summarization", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.7598950862884521}, {"text": "question answering (QA)", "start_pos": 204, "end_pos": 227, "type": "TASK", "confidence": 0.8246686100959778}]}, {"text": "However, the adoption of these technologies in the biomedical domain is not straightforward.", "labels": [], "entities": []}, {"text": "The domain specific language has different requirements for information extraction compared to news articles, where who, when, what, and where elements are often the most important.", "labels": [], "entities": [{"text": "information extraction", "start_pos": 60, "end_pos": 82, "type": "TASK", "confidence": 0.7484833896160126}]}, {"text": "Additionally, there are less resources available in biomedicine for text summarization, such as benchmarking corpora or knowledge bases.", "labels": [], "entities": [{"text": "text summarization", "start_pos": 68, "end_pos": 86, "type": "TASK", "confidence": 0.7745935916900635}]}, {"text": "Finally, requirements for summaries, such completeness or correctness, are even more important in this domain when compared to others, as important decision might betaken based on them.", "labels": [], "entities": [{"text": "summaries", "start_pos": 26, "end_pos": 35, "type": "TASK", "confidence": 0.9693116545677185}]}, {"text": "Therefore, text summarization for biomedicine raises new challenges that still need to be addressed.", "labels": [], "entities": [{"text": "text summarization", "start_pos": 11, "end_pos": 29, "type": "TASK", "confidence": 0.7014991044998169}]}, {"text": "Searching for specific information in biomedical publications is a hard task that involves screening many entries in PubMed 1 , the most popular search engine in biomedicine.", "labels": [], "entities": [{"text": "Searching for specific information in biomedical publications", "start_pos": 0, "end_pos": 61, "type": "TASK", "confidence": 0.8658856664385114}]}, {"text": "PubMed contains over 24 million records and is growing exponentially.", "labels": [], "entities": [{"text": "PubMed", "start_pos": 0, "end_pos": 6, "type": "DATASET", "confidence": 0.9577864408493042}]}, {"text": "Two thirds of all queries to PubMed return more than 20 results, which is probably the reason why 47% of all queries get followed by a subsequent query without accessing any abstract or article of the search result ().", "labels": [], "entities": []}, {"text": "In average, users read four documents to find the information they search for.", "labels": [], "entities": []}, {"text": "Text summarization can support this task by providing summaries of many publications fora certain query or topic.", "labels": [], "entities": [{"text": "Text summarization", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.729323148727417}]}, {"text": "Automatic text summarization has also the potential to support database curation by automatically generating short summaries about a topic, such as the ones manually created for the Entrez Gene database.", "labels": [], "entities": [{"text": "text summarization", "start_pos": 10, "end_pos": 28, "type": "TASK", "confidence": 0.6930376291275024}, {"text": "database curation", "start_pos": 63, "end_pos": 80, "type": "TASK", "confidence": 0.6851218342781067}, {"text": "Entrez Gene database", "start_pos": 182, "end_pos": 202, "type": "DATASET", "confidence": 0.9173100392023722}]}, {"text": "In this work, we propose two graph-based summarization algorithms based on named entities for improving automatic multi-document summarization for the biomedical domain.", "labels": [], "entities": [{"text": "multi-document summarization", "start_pos": 114, "end_pos": 142, "type": "TASK", "confidence": 0.6150388270616531}]}, {"text": "While the first approach extends the lexical PageRank () with information from the NER, the second approach is solely based on named-entity recognition (NER).", "labels": [], "entities": [{"text": "named-entity recognition (NER)", "start_pos": 127, "end_pos": 157, "type": "TASK", "confidence": 0.8360592365264893}]}, {"text": "Additionally, we show how to adapt these algorithms for particular uses cases in biomedicine by including a bonus score.", "labels": [], "entities": []}, {"text": "We evaluate our methods in two uses cases: generation of ideal answers for question answering (QA) systems and for gene summaries.", "labels": [], "entities": [{"text": "question answering (QA)", "start_pos": 75, "end_pos": 98, "type": "TASK", "confidence": 0.8122590541839599}, {"text": "gene summaries", "start_pos": 115, "end_pos": 129, "type": "TASK", "confidence": 0.5225842446088791}]}, {"text": "The remainder of this paper is structured as follows: next section presents related work on text sumarization.", "labels": [], "entities": [{"text": "text sumarization", "start_pos": 92, "end_pos": 109, "type": "TASK", "confidence": 0.7633443176746368}]}, {"text": "Section 3.2 introduces our summarization algorithms, followed by an evaluation of these in section 4.", "labels": [], "entities": [{"text": "summarization", "start_pos": 27, "end_pos": 40, "type": "TASK", "confidence": 0.9799923300743103}]}, {"text": "Finally, we present a discussion on the results, identify the limitations of our work, and propose future work in section 5.", "labels": [], "entities": []}], "datasetContent": [{"text": "Unlike other domains, there are not gold-standard dataset for the evaluation of text summarization for biomedicine.", "labels": [], "entities": [{"text": "text summarization", "start_pos": 80, "end_pos": 98, "type": "TASK", "confidence": 0.6769147366285324}]}, {"text": "Most papers introduce their own evaluation datasets, based either on abstracts from documents or on manual evaluation by experts.", "labels": [], "entities": []}, {"text": "In this section, we evaluate our algorithms on the test collection provided by BioASQ and on a set of human summaries from the EntrezGene database.", "labels": [], "entities": [{"text": "BioASQ", "start_pos": 79, "end_pos": 85, "type": "DATASET", "confidence": 0.9095234274864197}, {"text": "EntrezGene database", "start_pos": 127, "end_pos": 146, "type": "DATASET", "confidence": 0.9534808695316315}]}, {"text": "Tuning of parameters in our methods were solely based on the training sets.", "labels": [], "entities": []}], "tableCaptions": []}