{"title": [{"text": "Cross-lingual Dependency Transfer : What Matters? Assessing the Impact of Pre-and Post-processing", "labels": [], "entities": [{"text": "Cross-lingual Dependency Transfer", "start_pos": 0, "end_pos": 33, "type": "TASK", "confidence": 0.6655864914258321}]}], "abstractContent": [{"text": "In this paper, we propose to analyze the pre-and post-processing steps applied in the context of cross-lingual dependency transfer.", "labels": [], "entities": [{"text": "cross-lingual dependency transfer", "start_pos": 97, "end_pos": 130, "type": "TASK", "confidence": 0.6848163704077402}]}, {"text": "To this aim, we employ a simple transfer strategy that operates on partially annotated projected data.", "labels": [], "entities": []}, {"text": "We show that a good data selection strategy is a key point in successfully transferring dependencies and that better data selection techniques need to be developed in order to achieve the performance of fully supervised methods.", "labels": [], "entities": [{"text": "data selection", "start_pos": 20, "end_pos": 34, "type": "TASK", "confidence": 0.7092742323875427}, {"text": "data selection", "start_pos": 117, "end_pos": 131, "type": "TASK", "confidence": 0.6899552196264267}]}], "introductionContent": [{"text": "Supervised learning techniques nowadays lie at the core of most Natural Language Processing (NLP) tools.", "labels": [], "entities": []}, {"text": "Their use is however hindered by the scarcity of annotated data, which are only available fora restricted number of tasks, genres, domain, and languages.", "labels": [], "entities": []}, {"text": "The supervision information that exists for well-resourced languages can however be transferred to under-resourced languages through the use of cross-lingual techniques.", "labels": [], "entities": []}, {"text": "In this work, we focus on the transfer of syntactic dependency annotations.", "labels": [], "entities": []}, {"text": "Two main transfer strategies have been proposed in the literature: direct transfer model and annotation transfer.", "labels": [], "entities": [{"text": "annotation transfer", "start_pos": 93, "end_pos": 112, "type": "TASK", "confidence": 0.686605378985405}]}, {"text": "The first approach is mainly based on delexicalized parsing) which assumes of common morpho-syntactic representation (e.g. PoS tags) between the source and target languages.", "labels": [], "entities": []}, {"text": "It has been improved with the use of self-training, data selection, relexicalization and multi-source transfer).", "labels": [], "entities": [{"text": "data selection", "start_pos": 52, "end_pos": 66, "type": "TASK", "confidence": 0.802071213722229}, {"text": "multi-source transfer", "start_pos": 89, "end_pos": 110, "type": "TASK", "confidence": 0.6974892318248749}]}, {"text": "The second approach (transfer of annotations), relies on parallel corpora to project, through alignment links, the dependencies automatically predicted from a resource-rich language to a resourcepoor language.", "labels": [], "entities": [{"text": "transfer of annotations)", "start_pos": 21, "end_pos": 45, "type": "TASK", "confidence": 0.8789945989847183}]}, {"text": "This approach pioneered by requires various heuristic transformation rules to cope with the non-isomorphism between the source and target structures as well as with the noise in source annotations and in alignments.", "labels": [], "entities": []}, {"text": "It has since enjoyed a great popularity and been improved by many works (see the overview in Section 2).", "labels": [], "entities": []}, {"text": "In spite of the simplicity of the annotation transfer principle, all these methods have several (hidden) parameters, such as the symmetrization heuristic or filtering thresholds, that make any direct comparison of their performance very hard.", "labels": [], "entities": []}, {"text": "That is why, in this work, we aim at analyzing the impact of external factors used as pre-and post-processing steps and their significance in the whole transfer process.", "labels": [], "entities": []}, {"text": "To this end, we propose to use the simple transfer strategy exploiting partially annotated data introduced in to systematically compare various design decisions.", "labels": [], "entities": []}, {"text": "The transfer strategy used in our experiments is explained in Section 2.", "labels": [], "entities": []}, {"text": "We then propose to explore and analyze different external factors: projected data filtering (Section 3.1), enhancement of the parsing strategy (Section 3.2) and multi-source transfer (Section 3.3).", "labels": [], "entities": [{"text": "parsing", "start_pos": 126, "end_pos": 133, "type": "TASK", "confidence": 0.9692980647087097}]}, {"text": "Finally, we compare the efficiency of dependency transfer and supervised parsing and analyze the performance achieved for the different kind of labels In this Section, we describe the two main steps of the transfer process considered in our experiments: the projection of the dependencies through word alignments from a source language to a target language and the training method of for transition-based parser that can learn a parser from partial dependency trees.", "labels": [], "entities": [{"text": "dependency transfer", "start_pos": 38, "end_pos": 57, "type": "TASK", "confidence": 0.7890492677688599}]}, {"text": "We also present the dataset used in our experiments and evaluate the proposed approach.", "labels": [], "entities": []}], "datasetContent": [{"text": "All our experiments are carried out on six languages 2 of the Universal Dependency Treebank Project v2.0 (UDT) (: German (de), English (en), Spanish (es), French (fr), Italian (it) and Swedish (sv).", "labels": [], "entities": [{"text": "Universal Dependency Treebank Project v2.0 (UDT)", "start_pos": 62, "end_pos": 110, "type": "DATASET", "confidence": 0.7962858453392982}]}, {"text": "We consider as parallel corpora a subset of the Europarl corpus that have exactly the same English sentences, collecting 1, 231, 216 parallel sentences for the 6 language pairs.", "labels": [], "entities": [{"text": "Europarl corpus", "start_pos": 48, "end_pos": 63, "type": "DATASET", "confidence": 0.9946058690547943}]}, {"text": "For the evaluation, the original splits (train/test/dev) of the UDT corpora are kept for training the source and evaluate the target.", "labels": [], "entities": [{"text": "UDT corpora", "start_pos": 64, "end_pos": 75, "type": "DATASET", "confidence": 0.789827972650528}]}, {"text": "The parallel sentences are aligned in both directions with.", "labels": [], "entities": []}, {"text": "These alignments are then merged with the intersection and grow-diag heuristics.", "labels": [], "entities": []}, {"text": "For each language pair, the source dataset (Europarl) is PoS-tagged and parsed using the transition-based version of the MateParser (Bohnet and Nivre, 2012) with abeam of 40, which was trained on the UDT corpus.", "labels": [], "entities": [{"text": "UDT corpus", "start_pos": 200, "end_pos": 210, "type": "DATASET", "confidence": 0.971750944852829}]}, {"text": "These predicted annotations are then partially projected on the target language data using the projection strategy described in Section 2.1.", "labels": [], "entities": []}, {"text": "To train a parser on partially projected target data, we used our own implementation of the arceager dependency parser, using the features described in.", "labels": [], "entities": []}, {"text": "The greedy version of the parser is used in all but one experiments of the Section 3 while a beam-search (with a beamsize of 8 for learning & parsing) is used to achieve 2 These are the languages present in both Europarl and UDT.", "labels": [], "entities": [{"text": "Europarl", "start_pos": 212, "end_pos": 220, "type": "DATASET", "confidence": 0.9827483296394348}, {"text": "UDT", "start_pos": 225, "end_pos": 228, "type": "DATASET", "confidence": 0.7860552072525024}]}, {"text": "the best performances of the proposed method (Section 2.5).", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Results of our transfer method. 'sup' present the fully", "labels": [], "entities": []}, {"text": " Table 2. First,  these results show that the alignments are not good  enough to reflect improvements in (source) parsing  quality on the target data: the use of beam-search on  parsing the source language allows an average im- provement of 0.2 UAS point on the target languages,  while the source (English) performance is improved  by 2.3. The use of clusters does not improve the", "labels": [], "entities": []}, {"text": " Table 3: English-to-French transfer scores per dependency la-", "labels": [], "entities": []}]}