{"title": [], "abstractContent": [{"text": "This paper describes the statistical machine translation system developed at RWTH Aachen University for the English\u2192Romanian translation task of the ACL 2016 First Conference on Machine Translation (WMT 2016).", "labels": [], "entities": [{"text": "statistical machine translation", "start_pos": 25, "end_pos": 56, "type": "TASK", "confidence": 0.6230199933052063}, {"text": "English\u2192Romanian translation task of the ACL 2016 First Conference on Machine Translation (WMT 2016)", "start_pos": 108, "end_pos": 208, "type": "TASK", "confidence": 0.8231595026122199}]}, {"text": "We combined three different state-of-the-art systems in a system combination: A phrase-based system, a hierarchical phrase-based system and an attention-based neural machine translation system.", "labels": [], "entities": [{"text": "attention-based neural machine translation", "start_pos": 143, "end_pos": 185, "type": "TASK", "confidence": 0.6543045714497566}]}, {"text": "The phrase-based and the hierarchical phrase-based systems make use of a language model trained on all available data, a language model trained on the bilingual data and a word class language model.", "labels": [], "entities": []}, {"text": "In addition, we utilized a recurrent neu-ral network language model and a bidi-rectional recurrent neural network translation model for reranking the output of both systems.", "labels": [], "entities": [{"text": "bidi-rectional recurrent neural network translation", "start_pos": 74, "end_pos": 125, "type": "TASK", "confidence": 0.7361439228057861}]}, {"text": "The attention-based neural machine translation system was trained using all bilingual data together with the back-translated data from the News Crawl 2015 corpora.", "labels": [], "entities": [{"text": "attention-based neural machine translation", "start_pos": 4, "end_pos": 46, "type": "TASK", "confidence": 0.6111745834350586}, {"text": "News Crawl 2015 corpora", "start_pos": 139, "end_pos": 162, "type": "DATASET", "confidence": 0.9639621526002884}]}], "introductionContent": [{"text": "We describe the statistical machine translation (SMT) systems developed by RWTH Aachen University for English\u2192Romanian language pair for the evaluation campaign of WMT 2016.", "labels": [], "entities": [{"text": "statistical machine translation (SMT)", "start_pos": 16, "end_pos": 53, "type": "TASK", "confidence": 0.7723711282014847}, {"text": "WMT 2016", "start_pos": 164, "end_pos": 172, "type": "DATASET", "confidence": 0.7896653711795807}]}, {"text": "Combining several single machine translation engines has proven to be highly effective in previous submissions, e.g. (. We therefore used a similar approach for this evaluation.", "labels": [], "entities": []}, {"text": "We trained individual systems using state-of-the-art phrasebased, hierarchical phrase-based translation engines, and attention-based recurrent neural networks ensemble.", "labels": [], "entities": [{"text": "phrase-based translation", "start_pos": 79, "end_pos": 103, "type": "TASK", "confidence": 0.6290904581546783}]}, {"text": "Each single system was optimized and the best systems were used in a system combination.", "labels": [], "entities": []}, {"text": "This paper is organized as follows.", "labels": [], "entities": []}, {"text": "In Sections 2.2 through 2.5 we describe our translation software and baseline setups.", "labels": [], "entities": [{"text": "translation", "start_pos": 44, "end_pos": 55, "type": "TASK", "confidence": 0.9686393737792969}]}, {"text": "Sections 2.6 describes the neural network models used in our translation systems.", "labels": [], "entities": []}, {"text": "The attention based recurrent neural network ensemble is described in Section 2.7.", "labels": [], "entities": []}, {"text": "Sections 2.8 explains the system combination pipeline applied on the individual systems for obtaining the combined system.", "labels": [], "entities": []}, {"text": "Our experiments for each track are summarized in Section 3 and we conclude with Section 4.", "labels": [], "entities": []}], "datasetContent": [{"text": "All three systems use the same preprocessing as described in Section 2.1.", "labels": [], "entities": []}, {"text": "The phrase-based system in its baseline configuration was improved by 0.6 BLEU and 0.7 TER points on newstest2016 by adding the synthetic data as described in Section 2.4.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 74, "end_pos": 78, "type": "METRIC", "confidence": 0.9990917444229126}, {"text": "TER", "start_pos": 87, "end_pos": 90, "type": "METRIC", "confidence": 0.9977782368659973}, {"text": "newstest2016", "start_pos": 101, "end_pos": 113, "type": "DATASET", "confidence": 0.9490114450454712}]}, {"text": "The neural networks (Section 2.6 improve the The neural networks also improve the hierarchical phrase-based system by 1.0 BLEU and 2.9 TER.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 122, "end_pos": 126, "type": "METRIC", "confidence": 0.996795117855072}, {"text": "TER", "start_pos": 135, "end_pos": 138, "type": "METRIC", "confidence": 0.9895071387290955}]}, {"text": "We did not try to add the synthetic data to the hierarchical system.", "labels": [], "entities": []}, {"text": "Adding the synthetic data to the NMT system improve the baseline system by 3.8 BLEU and 3.5 TER.", "labels": [], "entities": [{"text": "NMT", "start_pos": 33, "end_pos": 36, "type": "DATASET", "confidence": 0.8033736348152161}, {"text": "BLEU", "start_pos": 79, "end_pos": 83, "type": "METRIC", "confidence": 0.9997268319129944}, {"text": "TER", "start_pos": 92, "end_pos": 95, "type": "METRIC", "confidence": 0.9981116056442261}]}, {"text": "An ensemble of four similarly trained networks gives an additional improvement of 2.1 BLEU and in 3.1 TER.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 86, "end_pos": 90, "type": "METRIC", "confidence": 0.999505877494812}, {"text": "TER", "start_pos": 102, "end_pos": 105, "type": "METRIC", "confidence": 0.9949219822883606}]}, {"text": "The final step was to combine all three systems using the system combination (Section 2.8) which added another 0.8 BLEU points on top of the neural network system, but caused a small degradation in TER by 0.5 points.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 115, "end_pos": 119, "type": "METRIC", "confidence": 0.9989604949951172}, {"text": "TER", "start_pos": 198, "end_pos": 201, "type": "METRIC", "confidence": 0.9978308081626892}]}, {"text": "The lower BLEU and higher TER score in for the NMT system show that the translations created by it differ more from the PBT and HPBT system then there translation between each other.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9994250535964966}, {"text": "TER score", "start_pos": 26, "end_pos": 35, "type": "METRIC", "confidence": 0.9811595380306244}, {"text": "NMT system", "start_pos": 47, "end_pos": 57, "type": "DATASET", "confidence": 0.861942857503891}, {"text": "PBT", "start_pos": 120, "end_pos": 123, "type": "DATASET", "confidence": 0.8947532773017883}]}], "tableCaptions": [{"text": " Table 1: Results of the individual systems for the English\u2192Romanian task. BLEU and TER scores are  case-sensitive and given in %.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 75, "end_pos": 79, "type": "METRIC", "confidence": 0.9995489716529846}, {"text": "TER", "start_pos": 84, "end_pos": 87, "type": "METRIC", "confidence": 0.9960720539093018}]}, {"text": " Table 2: Comparing the systems against each other  by computing the BLEU and TER score on the  newstest2016. Each system is used as reference  once, the reported value is the average between  both which makes these value symmetrical. The  upper half lists BLEU scores, the lower half TER  scores. All values are given in %.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 69, "end_pos": 73, "type": "METRIC", "confidence": 0.9990112781524658}, {"text": "TER score", "start_pos": 78, "end_pos": 87, "type": "METRIC", "confidence": 0.9724516570568085}, {"text": "newstest2016", "start_pos": 96, "end_pos": 108, "type": "DATASET", "confidence": 0.9779485464096069}, {"text": "BLEU", "start_pos": 257, "end_pos": 261, "type": "METRIC", "confidence": 0.9989700317382812}, {"text": "TER", "start_pos": 285, "end_pos": 288, "type": "METRIC", "confidence": 0.9960856437683105}]}]}