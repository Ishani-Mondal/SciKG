{"title": [{"text": "Unsupervised Sentence Simplification Using Deep Semantics", "labels": [], "entities": [{"text": "Sentence Simplification", "start_pos": 13, "end_pos": 36, "type": "TASK", "confidence": 0.8351402282714844}]}], "abstractContent": [{"text": "We present a novel approach to sentence simplification which departs from previous work in two main ways.", "labels": [], "entities": [{"text": "sentence simplification", "start_pos": 31, "end_pos": 54, "type": "TASK", "confidence": 0.7975345551967621}]}, {"text": "First, it requires neither handwritten rules nor a training corpus of aligned standard and simplified sentences.", "labels": [], "entities": []}, {"text": "Second, sentence splitting operates on deep semantic structure.", "labels": [], "entities": [{"text": "sentence splitting", "start_pos": 8, "end_pos": 26, "type": "TASK", "confidence": 0.7812422513961792}]}, {"text": "We show (i) that the unsupervised framework we propose is competitive with four state-of-the-art supervised systems and (ii) that our semantic based approach allows fora principled and effective handling of sentence splitting.", "labels": [], "entities": [{"text": "sentence splitting", "start_pos": 207, "end_pos": 225, "type": "TASK", "confidence": 0.717959389090538}]}], "introductionContent": [{"text": "Sentence simplification maps a sentence to a simpler, more readable one approximating its content.", "labels": [], "entities": [{"text": "Sentence simplification", "start_pos": 0, "end_pos": 23, "type": "TASK", "confidence": 0.9304339587688446}]}, {"text": "As has been argued in, sentence simplification has many potential applications.", "labels": [], "entities": [{"text": "sentence simplification", "start_pos": 23, "end_pos": 46, "type": "TASK", "confidence": 0.8365810811519623}]}, {"text": "It is useful as a preprocessing step fora variety of NLP systems such as parsers and machine translation systems, summarisation), sentence fusion ( and semantic role labelling (.", "labels": [], "entities": [{"text": "parsers and machine translation", "start_pos": 73, "end_pos": 104, "type": "TASK", "confidence": 0.6605842933058739}, {"text": "summarisation", "start_pos": 114, "end_pos": 127, "type": "TASK", "confidence": 0.9824480414390564}, {"text": "sentence fusion", "start_pos": 130, "end_pos": 145, "type": "TASK", "confidence": 0.8213527202606201}, {"text": "semantic role labelling", "start_pos": 152, "end_pos": 175, "type": "TASK", "confidence": 0.6591890056927999}]}, {"text": "It also has wide ranging potential societal applications as a reading aid for people with aphasia), for low literacy readers () and for nonnative speakers.", "labels": [], "entities": []}, {"text": "In this paper, we present a novel approach to sentence simplification which departs from previous work in two main ways.", "labels": [], "entities": [{"text": "sentence simplification", "start_pos": 46, "end_pos": 69, "type": "TASK", "confidence": 0.8104726672172546}]}, {"text": "First, it requires neither handwritten rules nor a training corpus of aligned standard and simplified sentences.", "labels": [], "entities": []}, {"text": "Instead, we exploit nonaligned Simple and English Wikipedia to learn the probability of lexical simplifications, of the semantics of simple sentences and of optional phrases i.e., phrase which maybe deleted when simplifying.", "labels": [], "entities": []}, {"text": "Second, sentence splitting is semantic based.", "labels": [], "entities": [{"text": "sentence splitting", "start_pos": 8, "end_pos": 26, "type": "TASK", "confidence": 0.7754299938678741}]}, {"text": "We show (i) that our unsupervised framework is competitive with four stateof-the-art systems and (ii) that our semantic based approach allows fora principled and effective handling of sentence splitting.", "labels": [], "entities": [{"text": "sentence splitting", "start_pos": 184, "end_pos": 202, "type": "TASK", "confidence": 0.7183837741613388}]}], "datasetContent": [{"text": "We evaluate our approach both globally and by module focusing in particular on the splitting component of our simplification approach.", "labels": [], "entities": []}, {"text": "The testset provided by was used by four supervised systems for automatic evaluation using metrics such as BLEU, sentence length and number of edits.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 107, "end_pos": 111, "type": "METRIC", "confidence": 0.9989551305770874}]}, {"text": "In addition, most recent simplification approaches carryout a human evaluation on a small set of randomly selected complex/simple sentence pairs.", "labels": [], "entities": []}, {"text": "Thus, and Siddharthan and Mandya (2014) carryout a human evaluation on 20, 20 and 25 sentences respectively.", "labels": [], "entities": []}, {"text": "For example in    been simplified) and the average Levenshtein distance (LD) between the system output and both the complex and the simple reference sentences.", "labels": [], "entities": [{"text": "Levenshtein distance (LD)", "start_pos": 51, "end_pos": 76, "type": "METRIC", "confidence": 0.9692626833915711}]}, {"text": "We use BLEU 9 as a means to evaluate how close the systems output are to the reference corpus.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 7, "end_pos": 11, "type": "METRIC", "confidence": 0.984716534614563}]}, {"text": "shows the results of the automatic evaluation.", "labels": [], "entities": []}, {"text": "The most noticeable result is that our unsupervised system yields results that are similar to those of the supervised approaches.", "labels": [], "entities": []}, {"text": "The results also show that, in contrast to Woodsend system which often leaves the input unsimplified (24% of the input), our system almost always modifies the input sentence (only 3% of the input are not simplified); and that the number of simplifications including a split is relatively high (49% of the cases) suggesting a good ability to split complex sentences into simpler ones.", "labels": [], "entities": [{"text": "Woodsend system", "start_pos": 43, "end_pos": 58, "type": "DATASET", "confidence": 0.9432770907878876}]}, {"text": "Human Evaluation Human judges were asked to rate input/output pairs w.r.t. to adequacy (How much does the simplified sentence(s) preserve the meaning of the input?), to simplification (How much does the generated sentence(s) simplify the complex input?) and to fluency (how grammatical and fluent are the sentences?).", "labels": [], "entities": []}, {"text": "We randomly selected 18 complex sentences from Zhu's test corpus and included in the evaluation corpus: the corresponding simple (Gold) sentence from Zhu's test corpus, the output of our system (UNSUP) and the output of the other four systems (Zhu, Woodsend, Narayan and Wubben) which were provided to us by the system authors . We collected ratings from 18 participants.", "labels": [], "entities": [{"text": "Zhu's test corpus", "start_pos": 47, "end_pos": 64, "type": "DATASET", "confidence": 0.6224194839596748}, {"text": "Zhu's test corpus", "start_pos": 150, "end_pos": 167, "type": "DATASET", "confidence": 0.7204590737819672}]}, {"text": "All were either native speakers or proficient in English, having taken part in a Master taught in English or lived in an English speaking country for an extended period of time.", "labels": [], "entities": []}, {"text": "The evaluation was done online using the LG-Eval toolkit ( and a Latin Square Experimental Design (LSED) was used to ensure a fair distribution of the systems and the data across raters.", "labels": [], "entities": [{"text": "LG-Eval toolkit", "start_pos": 41, "end_pos": 56, "type": "DATASET", "confidence": 0.9274307489395142}, {"text": "Latin Square Experimental Design (LSED)", "start_pos": 65, "end_pos": 104, "type": "METRIC", "confidence": 0.5612656218664986}]}, {"text": "To assess the relative impact of each module (lexical simplification, deletion and sentence splitting), we also conduct an automated evaluation on each module separately.", "labels": [], "entities": [{"text": "sentence splitting", "start_pos": 83, "end_pos": 101, "type": "TASK", "confidence": 0.7200415879487991}]}, {"text": "The results are shown in.", "labels": [], "entities": []}, {"text": "One first observation is that each module has an impact on simplification.", "labels": [], "entities": []}, {"text": "Thus the average Levenshtein Edit distance (LD) to the source clause (complex) is never null for any module while the number of \"No edit\" indicates that lexical simplification modifies the input sentence in 78%, sentence splitting 49% and deletion 96% of the cases.", "labels": [], "entities": [{"text": "Levenshtein Edit distance (LD)", "start_pos": 17, "end_pos": 47, "type": "METRIC", "confidence": 0.9257990221182505}, {"text": "sentence splitting", "start_pos": 212, "end_pos": 230, "type": "TASK", "confidence": 0.7188760340213776}]}, {"text": "In terms of output quality and in particular, similarity with respect to the target clause, deletion is the most effective (smallest LD, best BLEU score w.r.t. target).", "labels": [], "entities": [{"text": "BLEU score w.r.t. target", "start_pos": 142, "end_pos": 166, "type": "METRIC", "confidence": 0.9273927509784698}]}, {"text": "Further, the results for average token length indicate that lexical simplification is effective in producing shorter words (smaller average length for this module compared to the other two modules).", "labels": [], "entities": []}, {"text": "Predictably, combining modules yields systems that have stronger impact on the source clause (higher LD to complex, lower number of No Edits) with the full system (i.e., the system combining the 3 modules) showing the largest LD to the sources (LD to complex) and the smallest number of source sentences without simplification (3 No Edits).", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Split Feature Table (SFT) showing some of the", "labels": [], "entities": []}, {"text": " Table 2: Automatic evaluation results. Zhu, Woodsend, Wubben, Narayan are the best output of the models of Zhu et al.", "labels": [], "entities": []}, {"text": " Table 3: Automated Metrics for Simplification: Modular evaluation. LexSimpl-Split-Deletion is our final system UNSUP.", "labels": [], "entities": [{"text": "LexSimpl-Split-Deletion", "start_pos": 68, "end_pos": 91, "type": "DATASET", "confidence": 0.8549166321754456}, {"text": "UNSUP", "start_pos": 112, "end_pos": 117, "type": "DATASET", "confidence": 0.8115146160125732}]}, {"text": " Table 4: Average Human Ratings for simplicity, fluency", "labels": [], "entities": [{"text": "simplicity", "start_pos": 36, "end_pos": 46, "type": "METRIC", "confidence": 0.9949315190315247}]}]}