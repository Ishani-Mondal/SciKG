{"title": [{"text": "The Kyutech corpus and topic segmentation using a combined method", "labels": [], "entities": [{"text": "Kyutech corpus", "start_pos": 4, "end_pos": 18, "type": "DATASET", "confidence": 0.8667104542255402}, {"text": "topic segmentation", "start_pos": 23, "end_pos": 41, "type": "TASK", "confidence": 0.7351895570755005}]}], "abstractContent": [{"text": "Summarization of multi-party conversation is one of the important tasks in natural language processing.", "labels": [], "entities": [{"text": "Summarization of multi-party conversation", "start_pos": 0, "end_pos": 41, "type": "TASK", "confidence": 0.8506388664245605}, {"text": "natural language processing", "start_pos": 75, "end_pos": 102, "type": "TASK", "confidence": 0.6413473089536031}]}, {"text": "In this paper, we explain a Japanese corpus and a topic segmentation task.", "labels": [], "entities": [{"text": "topic segmentation task", "start_pos": 50, "end_pos": 73, "type": "TASK", "confidence": 0.7845351099967957}]}, {"text": "To the best of our knowledge, the corpus is the first Japanese corpus annotated for summarization tasks and freely available to anyone.", "labels": [], "entities": [{"text": "summarization tasks", "start_pos": 84, "end_pos": 103, "type": "TASK", "confidence": 0.9189748466014862}]}, {"text": "We call it \"the Kyutech corpus.\"", "labels": [], "entities": [{"text": "Kyutech corpus", "start_pos": 16, "end_pos": 30, "type": "DATASET", "confidence": 0.8195549845695496}]}, {"text": "The task of the corpus is a decision-making task with four participants and it contains utterances with time information, topic segmentation and reference summaries.", "labels": [], "entities": []}, {"text": "As a case study for the corpus, we describe a method combined with LCSeg and TopicTiling fora topic segmentation task.", "labels": [], "entities": [{"text": "topic segmentation task", "start_pos": 94, "end_pos": 117, "type": "TASK", "confidence": 0.7726952830950419}]}, {"text": "We discuss the effectiveness and the problems of the combined method through the experiment with the Kyutech corpus.", "labels": [], "entities": [{"text": "Kyutech corpus", "start_pos": 101, "end_pos": 115, "type": "DATASET", "confidence": 0.9522483050823212}]}], "introductionContent": [{"text": "In collaborative work, people share information, discuss it, and then make decisions through multi-party conversations, such as meetings.", "labels": [], "entities": []}, {"text": "Therefore, understanding such conversations and meetings is one of the most important tasks in natural language processing.", "labels": [], "entities": [{"text": "natural language processing", "start_pos": 95, "end_pos": 122, "type": "TASK", "confidence": 0.6451370716094971}]}, {"text": "Conversation summarization is useful to understand the content of conversations for both participants and non-participants.", "labels": [], "entities": [{"text": "Conversation summarization", "start_pos": 0, "end_pos": 26, "type": "TASK", "confidence": 0.8978683948516846}]}, {"text": "Many researchers have studied meeting and conversation summarization ().", "labels": [], "entities": [{"text": "meeting and conversation summarization", "start_pos": 30, "end_pos": 68, "type": "TASK", "confidence": 0.8717790842056274}]}, {"text": "For the summarization tasks, corpora are very important to analyze characteristics of conversations and to construct a method for summary generation.", "labels": [], "entities": [{"text": "summarization tasks", "start_pos": 8, "end_pos": 27, "type": "TASK", "confidence": 0.9045372307300568}, {"text": "summary generation", "start_pos": 130, "end_pos": 148, "type": "TASK", "confidence": 0.8189706802368164}]}, {"text": "There are some corpora in English, such as the AMI corpus and the ICSI corpus (.", "labels": [], "entities": [{"text": "AMI corpus", "start_pos": 47, "end_pos": 57, "type": "DATASET", "confidence": 0.915831446647644}, {"text": "ICSI corpus", "start_pos": 66, "end_pos": 77, "type": "DATASET", "confidence": 0.9333437979221344}]}, {"text": "In contrast, there is no corpus for conversation summarization tasks in Japanese.", "labels": [], "entities": [{"text": "conversation summarization tasks", "start_pos": 36, "end_pos": 68, "type": "TASK", "confidence": 0.769792228937149}]}, {"text": "In this study, we construct a Japanese conversation corpus about a decision-making task with four participants.", "labels": [], "entities": []}, {"text": "We call it \"the Kyutech corpus.\"", "labels": [], "entities": [{"text": "Kyutech corpus", "start_pos": 16, "end_pos": 30, "type": "DATASET", "confidence": 0.8195549845695496}]}, {"text": "To the best of our knowledge, the Kyutech corpus is the first Japanese corpus annotated for summarization tasks and freely available to anyone . The final goal of our study is to generate a summary from a multi-party conversation.", "labels": [], "entities": [{"text": "Kyutech corpus", "start_pos": 34, "end_pos": 48, "type": "DATASET", "confidence": 0.930781751871109}, {"text": "summarization tasks", "start_pos": 92, "end_pos": 111, "type": "TASK", "confidence": 0.915017306804657}]}, {"text": "Topic segmentation has often been used as the first process in summarization ().", "labels": [], "entities": [{"text": "Topic segmentation", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.8463921546936035}, {"text": "summarization", "start_pos": 63, "end_pos": 76, "type": "TASK", "confidence": 0.9865781664848328}]}, {"text": "Ina similar way, we apply topic segmentation to the Kyutech corpus.", "labels": [], "entities": [{"text": "topic segmentation", "start_pos": 26, "end_pos": 44, "type": "TASK", "confidence": 0.7443831264972687}, {"text": "Kyutech corpus", "start_pos": 52, "end_pos": 66, "type": "DATASET", "confidence": 0.9413240253925323}]}, {"text": "In this paper, we combine two different text segmentation methods; LCSeg ( and TopicTiling (.", "labels": [], "entities": [{"text": "text segmentation", "start_pos": 40, "end_pos": 57, "type": "TASK", "confidence": 0.7166098207235336}]}, {"text": "We evaluate the effectiveness of the methods on the Kyutech corpus.", "labels": [], "entities": [{"text": "Kyutech corpus", "start_pos": 52, "end_pos": 66, "type": "DATASET", "confidence": 0.9288934469223022}]}, {"text": "The contributions of this paper are as follows: \u2022 We open the Kyutech corpus, a freely available Japanese conversation corpus fora decision-making task, on the web.", "labels": [], "entities": [{"text": "Kyutech corpus", "start_pos": 62, "end_pos": 76, "type": "DATASET", "confidence": 0.9182376265525818}]}, {"text": "This is the first Japanese corpus for summarization.", "labels": [], "entities": [{"text": "summarization", "start_pos": 38, "end_pos": 51, "type": "TASK", "confidence": 0.9894646406173706}]}, {"text": "\u2022 As a case study, we examine a combined method based on LCSeg and TopicTiling for topic segmentation with the Kyutech corpus.", "labels": [], "entities": [{"text": "topic segmentation", "start_pos": 83, "end_pos": 101, "type": "TASK", "confidence": 0.7361564934253693}, {"text": "Kyutech corpus", "start_pos": 111, "end_pos": 125, "type": "DATASET", "confidence": 0.9693009257316589}]}, {"text": "This is the first step of our conversation summarization.", "labels": [], "entities": [{"text": "conversation summarization", "start_pos": 30, "end_pos": 56, "type": "TASK", "confidence": 0.7342428267002106}]}], "datasetContent": [{"text": "We evaluated these methods with the Kyutech corpus.", "labels": [], "entities": [{"text": "Kyutech corpus", "start_pos": 36, "end_pos": 50, "type": "DATASET", "confidence": 0.9586088955402374}]}, {"text": "The details of the Kyutech corpus are shown in.", "labels": [], "entities": [{"text": "Kyutech corpus", "start_pos": 19, "end_pos": 33, "type": "DATASET", "confidence": 0.9214977324008942}]}, {"text": "In the experiment, we used the main tags as the topic sequence.", "labels": [], "entities": []}, {"text": "In other words, a changing point of the main tags is a border of two topics, e.g., the 7th utterance in.", "labels": [], "entities": []}, {"text": "We used one conversation (Conv9) as the development data for the method.", "labels": [], "entities": []}, {"text": "Hence we evaluated the methods with eight conversations without Conv9.", "labels": [], "entities": []}, {"text": "In the experiment, we compared two weight factors wf = 0.3 and wf = 0.7.", "labels": [], "entities": []}, {"text": "For the LDA, we compared three types of the number of topics, 10, 20 and 30.", "labels": [], "entities": [{"text": "LDA", "start_pos": 8, "end_pos": 11, "type": "TASK", "confidence": 0.6801710724830627}]}, {"text": "Parameters on LCSeg, such as the window size, were based on (.: The F-measure on complete match and partial match.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 68, "end_pos": 77, "type": "METRIC", "confidence": 0.987531840801239}]}, {"text": "We evaluated these methods with two criteria; complete matching and partial matching that were used in.", "labels": [], "entities": []}, {"text": "We computed the F-measure from the recall and precision rates for the complete and partial matching.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 16, "end_pos": 25, "type": "METRIC", "confidence": 0.9986715316772461}, {"text": "recall", "start_pos": 35, "end_pos": 41, "type": "METRIC", "confidence": 0.9994533658027649}, {"text": "precision", "start_pos": 46, "end_pos": 55, "type": "METRIC", "confidence": 0.9962530136108398}]}, {"text": "The values are computed as follows: where Br is the set of the sentence IDs before each topic change.", "labels": [], "entities": [{"text": "Br", "start_pos": 42, "end_pos": 44, "type": "METRIC", "confidence": 0.9920337796211243}]}, {"text": "B h is the set of the outputs from each method.", "labels": [], "entities": []}, {"text": "where The F-measure is the harmonic mean between the recall and precision rates.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9979974627494812}, {"text": "recall", "start_pos": 53, "end_pos": 59, "type": "METRIC", "confidence": 0.9990981817245483}, {"text": "precision", "start_pos": 64, "end_pos": 73, "type": "METRIC", "confidence": 0.9684126377105713}]}, {"text": "shows the experimental result about the complete match and the partial match.", "labels": [], "entities": []}, {"text": "Topic and Comb are the methods with TopicTiling and the combined methods, respectively.", "labels": [], "entities": []}, {"text": "Topic(\u03b2) in the table denotes the number of topics in LDA and \u03b2 = {10, 20, 30}.", "labels": [], "entities": []}, {"text": "\u03b2 and wf in Comb(\u03b2, wf ) denote the number of topics and the value of the weight factor (wf \u2208 {0.3, 0.7}).", "labels": [], "entities": []}, {"text": "For the complete matching, LCSeg produced the best performance.", "labels": [], "entities": []}, {"text": "For the partial matching, Comb(10,0.3) obtained the highest Fmeasure value although there is no dramatic improvement as compared with the single methods, LCSeg and TopicTiling.", "labels": [], "entities": [{"text": "Fmeasure", "start_pos": 60, "end_pos": 68, "type": "METRIC", "confidence": 0.9978760480880737}]}, {"text": "TopicTiling-based methods were low accuracy on the whole.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 35, "end_pos": 43, "type": "METRIC", "confidence": 0.9990134239196777}]}, {"text": "This is one reason that the combined methods did not improve the accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 65, "end_pos": 73, "type": "METRIC", "confidence": 0.9988466501235962}]}, {"text": "The size of the Kyutech corpus is not always sufficient for the statistical methods, as compared with the AMI corpus.", "labels": [], "entities": [{"text": "Kyutech corpus", "start_pos": 16, "end_pos": 30, "type": "DATASET", "confidence": 0.9393758177757263}, {"text": "AMI corpus", "start_pos": 106, "end_pos": 116, "type": "DATASET", "confidence": 0.9361527562141418}]}, {"text": "For the TopicTiling-based methods, we need a larger dataset.", "labels": [], "entities": []}, {"text": "Moreover, the values on the F-measure were not high (0.401 even on the partial match scheme).", "labels": [], "entities": [{"text": "F-measure", "start_pos": 28, "end_pos": 37, "type": "METRIC", "confidence": 0.969363272190094}]}, {"text": "reported that a feature-based segmentation method outperformed LCSeg.", "labels": [], "entities": []}, {"text": "Applying a supervised method into our task leads to the improvement of the accuracy of the topic segmentation.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 75, "end_pos": 83, "type": "METRIC", "confidence": 0.998999297618866}, {"text": "topic segmentation", "start_pos": 91, "end_pos": 109, "type": "TASK", "confidence": 0.7160238474607468}]}, {"text": "In general, machine learning methods need a large dataset to generate a strong classifier.", "labels": [], "entities": []}, {"text": "Therefore, scaling up the Kyutech corpus is the most important future work.", "labels": [], "entities": [{"text": "Kyutech corpus", "start_pos": 26, "end_pos": 40, "type": "DATASET", "confidence": 0.9262813925743103}]}], "tableCaptions": [{"text": " Table 3: The number of utterances and segments of each conversation in the Kyutech corpus.", "labels": [], "entities": [{"text": "Kyutech corpus", "start_pos": 76, "end_pos": 90, "type": "DATASET", "confidence": 0.8770271837711334}]}, {"text": " Table 4: The F-measure on complete match and partial match.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 14, "end_pos": 23, "type": "METRIC", "confidence": 0.9987972974777222}]}]}