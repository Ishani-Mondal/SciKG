{"title": [{"text": "Estimating the Amenability of New Domains for Deception Detection", "labels": [], "entities": [{"text": "Estimating the Amenability of New Domains", "start_pos": 0, "end_pos": 41, "type": "TASK", "confidence": 0.742528423666954}, {"text": "Deception Detection", "start_pos": 46, "end_pos": 65, "type": "TASK", "confidence": 0.9181392192840576}]}], "abstractContent": [{"text": "In this paper we present an initial experiment in the estimation of the amenability of new domains to true/false classification.", "labels": [], "entities": [{"text": "true/false classification", "start_pos": 102, "end_pos": 127, "type": "TASK", "confidence": 0.6520531475543976}]}, {"text": "We choose four domains, two of which have been classified for deception, and use the out-of-rank distance measure on n-grams to aid in deciding whether the third and fourth domains are amenable to T/F classification.", "labels": [], "entities": [{"text": "out-of-rank distance measure", "start_pos": 85, "end_pos": 113, "type": "METRIC", "confidence": 0.8355866074562073}, {"text": "T/F classification", "start_pos": 197, "end_pos": 215, "type": "TASK", "confidence": 0.5271963179111481}]}, {"text": "We then use a classifier covered in the literature to train on the verified domains and test on the new domains to determine whether the relative distance measure can be a predictor of classification accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 200, "end_pos": 208, "type": "METRIC", "confidence": 0.7910236716270447}]}], "introductionContent": [{"text": "Recent research in natural language processing has supported the notion that verbal behavior can differentiate truthful from deceptive narratives in several domains, including \uf0b7 spoken personal narratives \uf0b7 online hotel reviews \uf0b7 online book reviews \uf0b7 spoken and written criminal narratives \uf0b7 CEO quarterly conference calls \uf0b7 emailed cooperative task completion These studies result inaccuracy rates at predicting True versus False of 70% to 90%.", "labels": [], "entities": [{"text": "\uf0b7 spoken personal narratives \uf0b7 online hotel reviews \uf0b7 online book reviews \uf0b7 spoken and written criminal narratives \uf0b7 CEO quarterly conference calls \uf0b7 emailed cooperative task completion", "start_pos": 176, "end_pos": 361, "type": "TASK", "confidence": 0.6553323918155262}, {"text": "True versus False", "start_pos": 414, "end_pos": 431, "type": "METRIC", "confidence": 0.6376592715581259}]}, {"text": "The question we address here is whether an approach similar to this recent work can perform equally successfully across different language domains.", "labels": [], "entities": []}, {"text": "Each study, with the exception of subsequent studies of the online hotel reviews, has built anew data set to analyze its particular domain.", "labels": [], "entities": []}, {"text": "Each of these data sets comes at more than typical cost for NLP applications because of the necessity of establishing the truth or falsity of the claim(s) in the data -the \"ground truth,\" either through factchecking or laboratory experiment -in addition to assembling the narrative data itself.", "labels": [], "entities": []}, {"text": "However, might there be similarities in the language of lies across these various domains?", "labels": [], "entities": []}, {"text": "There is a substantial literature in psychology and criminal justice that views false narratives as sharing characteristics in common because they describe imagined rather than real events and attitudes.", "labels": [], "entities": []}, {"text": "Criteria-based content analysis and Reality Monitoring, used in some European courts, rely on such differences, and find differences in parts-of-speech in imaginative as opposed to informative language, for which] finds corroboration in the false vs. true hotel reviews.", "labels": [], "entities": [{"text": "Criteria-based content analysis", "start_pos": 0, "end_pos": 31, "type": "TASK", "confidence": 0.8135237097740173}, {"text": "Reality Monitoring", "start_pos": 36, "end_pos": 54, "type": "TASK", "confidence": 0.6851043552160263}]}, {"text": "So, while we would certainly expect content word choice to depend on the domain, there maybe broader characteristics of the narrative that we could capitalize on that might capture deception in a variety of domains.", "labels": [], "entities": []}, {"text": "If so, could we create tools to estimate the difficulty of differentiating deceptive from truthful statements in anew domain based on what we know about this differentiation in previously analyzed domains?", "labels": [], "entities": []}, {"text": "This paper examines the ability of data from known domains to predict the difficulty of adapting a T/F classifier to anew domain.", "labels": [], "entities": []}, {"text": "To do this, we apply the out-of-rank distance metric on the most frequently occurring words in four domains, two related to each other and two unrelated, as a measure of domain distance in order to estimate how difficult it would be to adapt a classifier to the new domain.", "labels": [], "entities": []}, {"text": "We then test a classifier on the four domains in order to learn whether the distance measure has predicted whether the domains are close enough to be successfully classified for veracity and included in a growing corpus of T/F data.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1 shows the do- mains and their characteristics.", "labels": [], "entities": []}, {"text": " Table 2 shows the rank comparison scores for  each document. Lower scores indicate a higher re- lationship between two documents with respect to  the rank order of their most frequently occurring  words.", "labels": [], "entities": [{"text": "re- lationship", "start_pos": 93, "end_pos": 107, "type": "METRIC", "confidence": 0.9170807600021362}]}, {"text": " Table 2. Second, the 1  S.D. confidence interval for the inter-document  rank order score does not overlap the intervals for  the cross-document rank order scores, as shown in", "labels": [], "entities": [{"text": "S.D. confidence interval", "start_pos": 25, "end_pos": 49, "type": "METRIC", "confidence": 0.6211305856704712}]}, {"text": " Table 3: D4 intra-document score interval  compared to D1, D2, and D3.", "labels": [], "entities": [{"text": "D4 intra-document score interval", "start_pos": 10, "end_pos": 42, "type": "METRIC", "confidence": 0.8161389231681824}]}, {"text": " Table 5: Cross-domain classification results on  features using a Na\u00efve Bayes classifier (%)", "labels": [], "entities": [{"text": "Cross-domain classification", "start_pos": 10, "end_pos": 37, "type": "TASK", "confidence": 0.8453298509120941}, {"text": "Na\u00efve Bayes classifier", "start_pos": 67, "end_pos": 89, "type": "DATASET", "confidence": 0.8705567320187887}]}, {"text": " Table 6: Train/test classification results (%)  on unigrams using a Na\u00efve Bayes classifier.", "labels": [], "entities": [{"text": "Train/test classification", "start_pos": 10, "end_pos": 35, "type": "TASK", "confidence": 0.5179548189043999}, {"text": "Na\u00efve Bayes classifier", "start_pos": 69, "end_pos": 91, "type": "DATASET", "confidence": 0.8663102388381958}]}]}