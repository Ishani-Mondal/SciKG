{"title": [{"text": "A Graphical Pronoun Analysis Tool for the PROTEST Pronoun Evaluation Test Suite", "labels": [], "entities": [{"text": "Graphical Pronoun Analysis", "start_pos": 2, "end_pos": 28, "type": "TASK", "confidence": 0.6260464191436768}, {"text": "PROTEST Pronoun Evaluation Test", "start_pos": 42, "end_pos": 73, "type": "TASK", "confidence": 0.5503392741084099}]}], "abstractContent": [{"text": "We present a graphical pronoun analysis tool and a set of guidelines for manual evaluation to be used with the PROTEST pronoun test suite for machine translation (MT).", "labels": [], "entities": [{"text": "machine translation (MT)", "start_pos": 142, "end_pos": 166, "type": "TASK", "confidence": 0.8183849155902863}]}, {"text": "The tool provides a means for researchers to evaluate the performance of their MT systems and browse individual pronoun translations.", "labels": [], "entities": [{"text": "MT", "start_pos": 79, "end_pos": 81, "type": "TASK", "confidence": 0.9825654029846191}]}, {"text": "MT systems maybe evaluated automatically by comparing the translation of the test suite pronoun tokens in the MT output with those in the reference translation.", "labels": [], "entities": [{"text": "MT", "start_pos": 0, "end_pos": 2, "type": "TASK", "confidence": 0.9279634952545166}]}, {"text": "Those translations that do not match the reference are referred for manual evaluation, which is supported by the graphical pronoun analysis tool and its accompanying annotation guidelines.", "labels": [], "entities": []}, {"text": "By encouraging the manual examination and evaluation of individual pronoun tokens, we hope to understand better how well MT systems perform when translating different categories of pronouns , and gain insights as to where MT systems perform poorly and why.", "labels": [], "entities": [{"text": "MT", "start_pos": 121, "end_pos": 123, "type": "TASK", "confidence": 0.978222131729126}]}], "introductionContent": [{"text": "Pronoun translation poses a problem for statistical machine translation (SMT).", "labels": [], "entities": [{"text": "Pronoun translation", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.8811068534851074}, {"text": "statistical machine translation (SMT)", "start_pos": 40, "end_pos": 77, "type": "TASK", "confidence": 0.8255787988503774}]}, {"text": "Despite recent efforts, little progress has been made).", "labels": [], "entities": []}, {"text": "Most recently, the results of the DiscoMT 2015 shared task on pronoun translation  revealed that even discourse-aware Machine Translation (MT) systems were unable to beat a simple phrase-based SMT baseline.", "labels": [], "entities": [{"text": "DiscoMT 2015 shared task on pronoun translation", "start_pos": 34, "end_pos": 81, "type": "TASK", "confidence": 0.5800231908048902}, {"text": "discourse-aware Machine Translation (MT)", "start_pos": 102, "end_pos": 142, "type": "TASK", "confidence": 0.8057504097620646}]}, {"text": "We believe that there are two important obstacles that currently limit progress in pronoun translation.", "labels": [], "entities": [{"text": "pronoun translation", "start_pos": 83, "end_pos": 102, "type": "TASK", "confidence": 0.7638018131256104}]}, {"text": "Firstly, we need to obtain a deeper understanding of the problems that MT systems face when translating pronouns, and of the performance of our systems when faced with these problems.", "labels": [], "entities": [{"text": "MT", "start_pos": 71, "end_pos": 73, "type": "TASK", "confidence": 0.9779865145683289}]}, {"text": "Secondly, we lack evaluation methodologies that specifically target pronoun translation and that are capable of providing a detailed overview of system performance.", "labels": [], "entities": [{"text": "pronoun translation", "start_pos": 68, "end_pos": 87, "type": "TASK", "confidence": 0.7594815492630005}]}, {"text": "In this paper, we present a graphical tool and an evaluation methodology for manual assessment and investigation of pronoun translation that address both of these factors.", "labels": [], "entities": [{"text": "pronoun translation", "start_pos": 116, "end_pos": 135, "type": "TASK", "confidence": 0.7298727929592133}]}, {"text": "When dealing with pronouns, many of the fundamental assumptions cherished by the MT community breakdown.", "labels": [], "entities": [{"text": "MT community", "start_pos": 81, "end_pos": 93, "type": "TASK", "confidence": 0.8525193929672241}]}, {"text": "MT researchers routinely rely on automatic evaluation metrics such as BLEU () to guide their development efforts.", "labels": [], "entities": [{"text": "MT", "start_pos": 0, "end_pos": 2, "type": "TASK", "confidence": 0.9751013517379761}, {"text": "BLEU", "start_pos": 70, "end_pos": 74, "type": "METRIC", "confidence": 0.9987255930900574}]}, {"text": "These automated metrics typically assume that overlap of the MT output with a humangenerated reference translation maybe used as a proxy for correctness.", "labels": [], "entities": [{"text": "MT", "start_pos": 61, "end_pos": 63, "type": "TASK", "confidence": 0.9246257543563843}]}, {"text": "This assumption fails for certain types of pronouns.", "labels": [], "entities": []}, {"text": "In particular, it does not hold in the important case of anaphoric pronouns, which refer back to a mention introduced earlier in the discourse (an antecedent): If the pronoun's antecedent is translated in away that differs from the reference translation, a different pronoun maybe required.", "labels": [], "entities": []}, {"text": "One that matches the reference translation may in fact be wrong.", "labels": [], "entities": []}, {"text": "In less complex cases, too, the syntactic variability in pronoun translation is generally high even in closely parallel texts, which creates difficulties both for translation modelling and for MT evaluation.", "labels": [], "entities": [{"text": "pronoun translation", "start_pos": 57, "end_pos": 76, "type": "TASK", "confidence": 0.7358797937631607}, {"text": "translation modelling", "start_pos": 163, "end_pos": 184, "type": "TASK", "confidence": 0.9650281369686127}, {"text": "MT evaluation", "start_pos": 193, "end_pos": 206, "type": "TASK", "confidence": 0.9747381806373596}]}, {"text": "We hope that our contribution will make it easier for MT researchers to anchor their decisions in descriptive corpus data and face the full complexity of pronoun translation.", "labels": [], "entities": [{"text": "MT", "start_pos": 54, "end_pos": 56, "type": "TASK", "confidence": 0.9925494194030762}, {"text": "pronoun translation", "start_pos": 154, "end_pos": 173, "type": "TASK", "confidence": 0.7486576735973358}]}], "datasetContent": [{"text": "To address the problem of evaluation, suggests using a test suite composed of carefully selected pronoun tokens which can then be checked individually to evaluate pronoun correctness.", "labels": [], "entities": []}, {"text": "In we introduce PROTEST, a test suite comprising 250 hand-selected pronoun tokens exposing particular problems in English-French pronoun translation, along with an automatic evaluation script.", "labels": [], "entities": [{"text": "English-French pronoun translation", "start_pos": 114, "end_pos": 148, "type": "TASK", "confidence": 0.7079198360443115}]}, {"text": "The pronoun analysis tool and methodology presented here are specifically designed to be used with the PROTEST test suite.", "labels": [], "entities": [{"text": "PROTEST test suite", "start_pos": 103, "end_pos": 121, "type": "DATASET", "confidence": 0.814251979192098}]}, {"text": "They can be applied to any parallel corpus with (manual or automatic) coreference resolution and word alignments, although pro-drop languages might require changes to the guidelines.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 70, "end_pos": 92, "type": "TASK", "confidence": 0.757442831993103}, {"text": "word alignments", "start_pos": 97, "end_pos": 112, "type": "TASK", "confidence": 0.7198759764432907}]}, {"text": "The pronoun tokens in PROTEST are extracted from the DiscoMT2015.test dataset (, which has been manually annotated according to the ParCor annotation guidelines ().", "labels": [], "entities": [{"text": "DiscoMT2015.test dataset", "start_pos": 53, "end_pos": 77, "type": "DATASET", "confidence": 0.9856386482715607}]}, {"text": "The pronoun tokens are categorised according to a range of different problems that MT systems face when translating pronouns.", "labels": [], "entities": [{"text": "MT", "start_pos": 83, "end_pos": 85, "type": "TASK", "confidence": 0.9739287495613098}]}, {"text": "At the top level the categories capture pronoun function, with four different functions represented in the test suite.", "labels": [], "entities": []}, {"text": "Anaphoric pronouns refer to an antecedent.", "labels": [], "entities": []}, {"text": "Pleonastic pronouns, in contrast, do not refer to anything.", "labels": [], "entities": []}, {"text": "Event reference pronouns refer to a verb, verb phrase, clause or even an entire sentence.", "labels": [], "entities": []}, {"text": "Finally, addressee reference pronouns are used to refer to the reader/audience.", "labels": [], "entities": []}, {"text": "At a second level of classification, we distinguish other features like morphosyntactic properties, pronoun-antecedent distance, and different types of addressee reference.", "labels": [], "entities": []}, {"text": "The PROTEST test suite comes with an automatic pronoun evaluation tool, which compares the translation of each pronoun token in the MT output with that in the reference translation.", "labels": [], "entities": [{"text": "PROTEST test suite", "start_pos": 4, "end_pos": 22, "type": "DATASET", "confidence": 0.7982328732808431}]}, {"text": "For the purpose of automatic evaluation, pronouns are broadly split into two groups.", "labels": [], "entities": [{"text": "automatic evaluation", "start_pos": 19, "end_pos": 39, "type": "TASK", "confidence": 0.705115795135498}]}, {"text": "Anaphoric pronouns must meet the following criteria: The translation of both the pronoun and the head of its antecedent must match that in the reference.", "labels": [], "entities": []}, {"text": "For all other pronoun functions, only the translation of the pronoun is considered.", "labels": [], "entities": []}, {"text": "Pronoun  translations that do no match the reference are not necessarily incorrect, but must be manually checked.", "labels": [], "entities": []}, {"text": "This is a prime use case of the pronoun analysis tool described here.", "labels": [], "entities": [{"text": "pronoun analysis", "start_pos": 32, "end_pos": 48, "type": "TASK", "confidence": 0.7567519843578339}]}, {"text": "In this section, we introduce a set of guidelines for manual annotation and evaluation of pronoun translations in the context of our pronoun analysis tool.", "labels": [], "entities": [{"text": "pronoun translations", "start_pos": 90, "end_pos": 110, "type": "TASK", "confidence": 0.6815593093633652}, {"text": "pronoun analysis", "start_pos": 133, "end_pos": 149, "type": "TASK", "confidence": 0.7044921666383743}]}, {"text": "The aim of the annotation is to assess the ability of MT systems to translate pronouns.", "labels": [], "entities": [{"text": "MT", "start_pos": 54, "end_pos": 56, "type": "TASK", "confidence": 0.9778509736061096}]}, {"text": "It is also possible to use the examples annotated as correctly translated as additional reference translations in conjunction with the automatic pronoun evaluation tool in the PROTEST test suite.", "labels": [], "entities": [{"text": "PROTEST test suite", "start_pos": 176, "end_pos": 194, "type": "DATASET", "confidence": 0.8827011187871298}]}, {"text": "In the annotation, we focus on the correctness of the highlighted pronouns and their antecedents.", "labels": [], "entities": []}, {"text": "The correctness of other words in the translated sentences is not considered, except where this makes it impossible to assess the correctness of the pronoun and antecedent head translations.", "labels": [], "entities": []}, {"text": "For each example we gather the following information: -Overall assessment: Decide whether or not the pronoun is translated correctly.", "labels": [], "entities": []}, {"text": "In the case of anaphoric pronouns, the translation of the pronoun's antecedent head must also be assessed.", "labels": [], "entities": [{"text": "translation of the pronoun's antecedent head", "start_pos": 39, "end_pos": 83, "type": "TASK", "confidence": 0.7077721697943551}]}, {"text": "-Token selection: For those translations marked as \"correct\", select the minimum set of tokens that constitute a correct translation.", "labels": [], "entities": []}, {"text": "-Tags: Certain recurring patterns are marked by assigning tags.", "labels": [], "entities": []}, {"text": "The set of standard tags and their use is described in Section 4.3.", "labels": [], "entities": []}, {"text": "-Remarks: Free-form notes maybe added for each example.", "labels": [], "entities": [{"text": "Remarks", "start_pos": 1, "end_pos": 8, "type": "METRIC", "confidence": 0.9546515345573425}]}, {"text": "This function is used to record any information that maybe useful in the interpretation or evaluation of the annotations.", "labels": [], "entities": []}, {"text": "For example, the annotator maybe unsure about the annotation of an example, or may have made assumptions about the interpretation of the text.", "labels": [], "entities": []}, {"text": "Pronoun tokens are annotated according to the general guidelines outlined in Section 4.1.", "labels": [], "entities": []}, {"text": "In the case of anaphoric pronouns, additional guidelines apply (see Section 4.2).", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1. Annotation results over a sample set of 116 pronoun translations", "labels": [], "entities": []}, {"text": " Table 2. Inter-Annotator Agreement Scores", "labels": [], "entities": []}]}