{"title": [{"text": "Joint Online Spoken Language Understanding and Language Modeling with Recurrent Neural Networks", "labels": [], "entities": [{"text": "Spoken Language Understanding", "start_pos": 13, "end_pos": 42, "type": "TASK", "confidence": 0.8082678914070129}, {"text": "Language Modeling", "start_pos": 47, "end_pos": 64, "type": "TASK", "confidence": 0.7173786014318466}]}], "abstractContent": [{"text": "Speaker intent detection and semantic slot filling are two critical tasks in spoken language understanding (SLU) for dialogue systems.", "labels": [], "entities": [{"text": "Speaker intent detection", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.7928412755330404}, {"text": "semantic slot filling", "start_pos": 29, "end_pos": 50, "type": "TASK", "confidence": 0.7110672493775686}, {"text": "spoken language understanding (SLU)", "start_pos": 77, "end_pos": 112, "type": "TASK", "confidence": 0.8384149869283041}]}, {"text": "In this paper, we describe a recurrent neural network (RNN) model that jointly performs intent detection, slot filling , and language modeling.", "labels": [], "entities": [{"text": "intent detection", "start_pos": 88, "end_pos": 104, "type": "TASK", "confidence": 0.8005606830120087}, {"text": "slot filling", "start_pos": 106, "end_pos": 118, "type": "TASK", "confidence": 0.8754445612430573}, {"text": "language modeling", "start_pos": 125, "end_pos": 142, "type": "TASK", "confidence": 0.772062748670578}]}, {"text": "The neural network model keeps updating the intent prediction as word in the transcribed utterance arrives and uses it as contextual features in the joint model.", "labels": [], "entities": []}, {"text": "Evaluation of the language model and online SLU model is made on the ATIS benchmarking data set.", "labels": [], "entities": [{"text": "ATIS benchmarking data set", "start_pos": 69, "end_pos": 95, "type": "DATASET", "confidence": 0.9862397164106369}]}, {"text": "On language modeling task, our joint model achieves 11.8% relative reduction on perplexity comparing to the independent training language model.", "labels": [], "entities": [{"text": "language modeling", "start_pos": 3, "end_pos": 20, "type": "TASK", "confidence": 0.7675720751285553}]}, {"text": "On SLU tasks, our joint model outperforms the independent task training model by 22.3% on intent detection error rate, with slight degradation on slot filling F1 score.", "labels": [], "entities": [{"text": "SLU tasks", "start_pos": 3, "end_pos": 12, "type": "TASK", "confidence": 0.8644849956035614}, {"text": "intent detection error rate", "start_pos": 90, "end_pos": 117, "type": "TASK", "confidence": 0.6669925674796104}, {"text": "F1 score", "start_pos": 159, "end_pos": 167, "type": "METRIC", "confidence": 0.9179298877716064}]}, {"text": "The joint model also shows advantageous performance in the realistic ASR settings with noisy speech input.", "labels": [], "entities": [{"text": "ASR", "start_pos": 69, "end_pos": 72, "type": "TASK", "confidence": 0.9897890686988831}]}], "introductionContent": [{"text": "As a critical component in spoken dialogue systems, spoken language understanding (SLU) system interprets the semantic meanings conveyed by speech signals.", "labels": [], "entities": [{"text": "spoken language understanding (SLU) system interprets the semantic meanings conveyed by speech signals", "start_pos": 52, "end_pos": 154, "type": "TASK", "confidence": 0.7818933526674906}]}, {"text": "Major components in SLU systems include identifying speaker's intent and extracting semantic constituents from the natural language query, two tasks that are often referred to as intent detection and slot filling.", "labels": [], "entities": [{"text": "SLU", "start_pos": 20, "end_pos": 23, "type": "TASK", "confidence": 0.9490950703620911}, {"text": "intent detection", "start_pos": 179, "end_pos": 195, "type": "TASK", "confidence": 0.6988317370414734}, {"text": "slot filling", "start_pos": 200, "end_pos": 212, "type": "TASK", "confidence": 0.7734164893627167}]}, {"text": "Intent detection can be treated as a semantic utterance classification problem, and slot filling can be treated as a sequence labeling task.", "labels": [], "entities": [{"text": "Intent detection", "start_pos": 0, "end_pos": 16, "type": "TASK", "confidence": 0.8345531821250916}, {"text": "semantic utterance classification", "start_pos": 37, "end_pos": 70, "type": "TASK", "confidence": 0.7309085031350454}, {"text": "slot filling", "start_pos": 84, "end_pos": 96, "type": "TASK", "confidence": 0.8367598652839661}, {"text": "sequence labeling task", "start_pos": 117, "end_pos": 139, "type": "TASK", "confidence": 0.7397171854972839}]}, {"text": "These two tasks are usually processed separately by different models.", "labels": [], "entities": []}, {"text": "For intent detection, a number of standard classifiers can be applied, such as support vector machines (SVMs) () and convolutional neural networks (CNNs) (.", "labels": [], "entities": [{"text": "intent detection", "start_pos": 4, "end_pos": 20, "type": "TASK", "confidence": 0.9195600748062134}]}, {"text": "For slot filling, popular approaches include using sequence models such as maximum entropy Markov models (MEMMs) (), conditional random fields (CRFs), and recurrent neural networks (RNNs) (.", "labels": [], "entities": [{"text": "slot filling", "start_pos": 4, "end_pos": 16, "type": "TASK", "confidence": 0.9562965035438538}]}, {"text": "Recently, neural network based models that jointly perform intent detection and slot filling have been reported.", "labels": [], "entities": [{"text": "intent detection", "start_pos": 59, "end_pos": 75, "type": "TASK", "confidence": 0.7775514721870422}, {"text": "slot filling", "start_pos": 80, "end_pos": 92, "type": "TASK", "confidence": 0.8881607353687286}]}, {"text": "proposed using CNN based triangular CRF for joint intent detection and slot filling.", "labels": [], "entities": [{"text": "joint intent detection", "start_pos": 44, "end_pos": 66, "type": "TASK", "confidence": 0.6480237543582916}, {"text": "slot filling", "start_pos": 71, "end_pos": 83, "type": "TASK", "confidence": 0.8720177710056305}]}, {"text": "proposed using a recursive neural network (RecNN) that learns hierarchical representations of the input text for the joint task.", "labels": [], "entities": []}, {"text": "Such joint models simplify SLU systems, as only one model needs to be trained and deployed.", "labels": [], "entities": [{"text": "SLU", "start_pos": 27, "end_pos": 30, "type": "TASK", "confidence": 0.9779734015464783}]}, {"text": "The previously proposed joint SLU models, however, are unsuitable for online tasks where it is desired to produce outputs as the input sequence arrives.", "labels": [], "entities": []}, {"text": "In speech recognition, instead of receiving the transcribed text at the end of the speech, users typically prefer to seethe ongoing transcription while speaking.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 3, "end_pos": 21, "type": "TASK", "confidence": 0.7931172847747803}]}, {"text": "In spoken language understanding, with real time intent identification and semantic constituents extraction, the downstream systems will be able to perform corresponding search or query while the user dictates.", "labels": [], "entities": [{"text": "spoken language understanding", "start_pos": 3, "end_pos": 32, "type": "TASK", "confidence": 0.7222165664037069}, {"text": "real time intent identification", "start_pos": 39, "end_pos": 70, "type": "TASK", "confidence": 0.6893153637647629}, {"text": "semantic constituents extraction", "start_pos": 75, "end_pos": 107, "type": "TASK", "confidence": 0.7154685258865356}]}, {"text": "The joint SLU models proposed in previous work typically require intent and slot label predictions to be conditioned on the entire transcribed word sequence.", "labels": [], "entities": []}, {"text": "This limits the usage of these models in the online setting.", "labels": [], "entities": []}, {"text": "In this paper, we propose an RNN-based online joint SLU model that performs intent detection and slot filling as the input word arrives.", "labels": [], "entities": [{"text": "RNN-based online joint SLU", "start_pos": 29, "end_pos": 55, "type": "TASK", "confidence": 0.6218327134847641}, {"text": "intent detection", "start_pos": 76, "end_pos": 92, "type": "TASK", "confidence": 0.7222807854413986}, {"text": "slot filling", "start_pos": 97, "end_pos": 109, "type": "TASK", "confidence": 0.7185817211866379}]}, {"text": "In addition, we suggest that the generated intent class and slot labels are useful for next word prediction in online automatic speech recognition (ASR).", "labels": [], "entities": [{"text": "next word prediction", "start_pos": 87, "end_pos": 107, "type": "TASK", "confidence": 0.6879840592543284}, {"text": "online automatic speech recognition (ASR)", "start_pos": 111, "end_pos": 152, "type": "TASK", "confidence": 0.7551900105816978}]}, {"text": "Therefore, we propose to perform intent detection, slot filling, and language modeling jointly in a conditional RNN model.", "labels": [], "entities": [{"text": "intent detection", "start_pos": 33, "end_pos": 49, "type": "TASK", "confidence": 0.7792846262454987}, {"text": "slot filling", "start_pos": 51, "end_pos": 63, "type": "TASK", "confidence": 0.9069791436195374}, {"text": "language modeling", "start_pos": 69, "end_pos": 86, "type": "TASK", "confidence": 0.7306747585535049}]}, {"text": "The proposed joint model can be further extended for belief tracking in dialogue systems when considering the dialogue history beyond the current utterance.", "labels": [], "entities": [{"text": "belief tracking", "start_pos": 53, "end_pos": 68, "type": "TASK", "confidence": 0.7584564685821533}]}, {"text": "Moreover, it can be used as the RNN decoder in an end-to-end trainable sequence-to-sequence speech recognition model . The remainder of the paper is organized as follows.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 92, "end_pos": 110, "type": "TASK", "confidence": 0.6898033767938614}]}, {"text": "In section 2, we introduce the background on using RNNs for intent detection, slot filling, and language modeling.", "labels": [], "entities": [{"text": "intent detection", "start_pos": 60, "end_pos": 76, "type": "TASK", "confidence": 0.8541722297668457}, {"text": "slot filling", "start_pos": 78, "end_pos": 90, "type": "TASK", "confidence": 0.9273338317871094}, {"text": "language modeling", "start_pos": 96, "end_pos": 113, "type": "TASK", "confidence": 0.7688575983047485}]}, {"text": "In section 3, we describe the proposed joint online SLU-LM model and its variations.", "labels": [], "entities": []}, {"text": "Section 4 discusses the experiment setup and results on ATIS benchmarking task, using both text and noisy speech inputs.", "labels": [], "entities": [{"text": "ATIS benchmarking task", "start_pos": 56, "end_pos": 78, "type": "TASK", "confidence": 0.567103644212087}]}, {"text": "Section 5 gives the conclusion.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: ATIS Test set results on intent detection error, slot filling F1 score, and language modeling  perplexity. Related joint models: RecNN: Joint intent detection and slot filling model using recursive  neural network (Guo et al., 2014). RecNN+Viterbi: Joint intent detection and slot filling model using  recursive neural network with Viterbi sequence optimization for slot filling (Guo et al., 2014).", "labels": [], "entities": [{"text": "ATIS Test set", "start_pos": 10, "end_pos": 23, "type": "DATASET", "confidence": 0.8395052353541056}, {"text": "slot filling F1 score", "start_pos": 59, "end_pos": 80, "type": "TASK", "confidence": 0.7485253810882568}, {"text": "Joint intent detection", "start_pos": 146, "end_pos": 168, "type": "TASK", "confidence": 0.630851944287618}, {"text": "slot filling", "start_pos": 173, "end_pos": 185, "type": "TASK", "confidence": 0.7030542492866516}, {"text": "Joint intent detection", "start_pos": 259, "end_pos": 281, "type": "TASK", "confidence": 0.667943149805069}, {"text": "slot filling", "start_pos": 286, "end_pos": 298, "type": "TASK", "confidence": 0.7336173057556152}, {"text": "slot filling", "start_pos": 376, "end_pos": 388, "type": "TASK", "confidence": 0.8071098923683167}]}, {"text": " Table 2: ATIS test set results on ASR word error rate, intent detection error, and slot filling F1 score with  noisy speech input.", "labels": [], "entities": [{"text": "ATIS test set", "start_pos": 10, "end_pos": 23, "type": "DATASET", "confidence": 0.8340122898419698}, {"text": "ASR word error rate", "start_pos": 35, "end_pos": 54, "type": "METRIC", "confidence": 0.7294798716902733}, {"text": "intent detection", "start_pos": 56, "end_pos": 72, "type": "TASK", "confidence": 0.7164739966392517}, {"text": "slot filling F1 score", "start_pos": 84, "end_pos": 105, "type": "METRIC", "confidence": 0.7128540202975273}]}]}