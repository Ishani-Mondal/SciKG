{"title": [{"text": "Memory access during incremental sentence processing causes reading time latency", "labels": [], "entities": [{"text": "reading time latency", "start_pos": 60, "end_pos": 80, "type": "METRIC", "confidence": 0.5564764440059662}]}], "abstractContent": [{"text": "Studies on the role of memory as a predictor of reading time latencies (1) differ in their predictions about when memory effects should occur in processing and (2) have had mixed results, with strong positive effects emerging from isolated constructed stimuli and weak or even negative effects emerging from naturally-occurring stimuli.", "labels": [], "entities": []}, {"text": "Our study addresses these concerns by comparing several implementations of prominent sentence processing theories on an exploratory corpus and evaluating the most successful of these on a confirmatory corpus, using anew self-paced reading corpus of seemingly natural narratives constructed to contain an unusually high proportion of memory-intensive constructions.", "labels": [], "entities": []}, {"text": "We show highly significant and complementary broad-coverage latency effects both for predictors based on the Dependency Locality Theory and for predictors based on a left-corner parsing model of sentence processing.", "labels": [], "entities": []}, {"text": "Our results indicate that memory access during sentence processing does take time, but suggest that stimuli requiring many memory access events maybe necessary in order to observe the effect.", "labels": [], "entities": [{"text": "memory access", "start_pos": 26, "end_pos": 39, "type": "TASK", "confidence": 0.6301186233758926}, {"text": "sentence processing", "start_pos": 47, "end_pos": 66, "type": "TASK", "confidence": 0.6525069028139114}]}], "introductionContent": [{"text": "Any incremental model of sentence processing where an abstract meaning representation is built up word-by-word must involve storage and retrieval of information about previously encountered material from some memory store.", "labels": [], "entities": [{"text": "sentence processing", "start_pos": 25, "end_pos": 44, "type": "TASK", "confidence": 0.7178324311971664}]}, {"text": "The retrieval operations have been hypothesized to be associated with increased processing time, and this prediction has been borne out in experiments using constructed stimuli.", "labels": [], "entities": []}, {"text": "However, memory-based latency effects have been null or even negative in broad-coverage reading time experiments using naturally-occurring text data that included baseline controls for n-gram and probabilistic phrase-structure grammar (PCFG) surprisal.", "labels": [], "entities": []}, {"text": "The failure of experimental latency effects to generalize to naturally-occurring data raises doubts about their existence.", "labels": [], "entities": []}, {"text": "The effects observed in constructed stimuli could be due to (1) information theoretic phenomena (e.g., surprisal) that such experiments rarely control for, (2) limited syntactic domain (e.g., relative clauses), or (3) 'oddball' effects -i.e. effects related to the semantic strangeness and decontextualized nature of the input, rather than due to difficulty retrieving information from working memory.", "labels": [], "entities": []}, {"text": "On the other hand, the lack of positive latency effects in studies using naturally-occurring input could be (1) because of the small number of subjects -ten -in the Dundee corpus ( used by e.g. and van or (2) because naturally-occurring newswire texts might contain too low a proportion of memory-intensive constructions to reveal a generalized memory effect.", "labels": [], "entities": [{"text": "Dundee corpus", "start_pos": 165, "end_pos": 178, "type": "DATASET", "confidence": 0.9900125861167908}]}, {"text": "In addition to the problem of conflicting results between constructed vs. naturally-occurring stimuli, research on the role of memory in sentence processing must also contend with the open question of where and what kinds of memory effects are predicted during sentence processing.", "labels": [], "entities": [{"text": "sentence processing", "start_pos": 137, "end_pos": 156, "type": "TASK", "confidence": 0.7056849598884583}]}, {"text": "One of the first and most well-known memory-based theories of sentence processing is the Dependency Locality Theory (DLT), which predicts processing difficulty proportional to the number of discourse referents intervening between the current word and any dependencies it shares with words in its preceding context., on the other hand, predict difficulty as a function of memory decay during the retrieval operations of an incremental left-corner parser.", "labels": [], "entities": [{"text": "sentence processing", "start_pos": 62, "end_pos": 81, "type": "TASK", "confidence": 0.7374866604804993}]}, {"text": "Note that both of these accounts are localitybased (difficulty is predicted to increase with distance), modeling the notion that decay overtime may make it more difficult (and hence time-consuming) to recall items from working memory.", "labels": [], "entities": []}, {"text": "However, it is conceivable that processing difficulty may have less to do with locality than simply with whether or not a memory access or recall event has occurred, a hypothesis explored by van with mixed results.", "labels": [], "entities": [{"text": "recall", "start_pos": 139, "end_pos": 145, "type": "METRIC", "confidence": 0.9063389301300049}]}, {"text": "The present work seeks to answer these questions by evaluating many plausible implementations of prominent theories of sentence processing as predictors of reading times on the new Natural Stories corpus.", "labels": [], "entities": [{"text": "Natural Stories corpus", "start_pos": 181, "end_pos": 203, "type": "DATASET", "confidence": 0.6754729648431143}]}, {"text": "The Natural Stories corpus is constructed in order to embed an unusually-high proportion of rare words and memory-intensive constructions in narratives designed to resemble naturally-occurring text.", "labels": [], "entities": []}, {"text": "It therefore occupies an intermediary position -which we will refer to as 'constructed-natural' -between isolated constructed stimuli and naturally-occurring text that might help overcome the limitations of both.", "labels": [], "entities": []}, {"text": "We evaluate against a strong baseline model that includes controls for n-gram and PCFG surprisal.", "labels": [], "entities": []}, {"text": "We find clear evidence for (1) a locality effect when constructing dependencies to preceding words and (2) a locality-independent 'reinstatement' effect whenever derivation fragments must be recalled from working memory during the operation of a left-corner parser.", "labels": [], "entities": []}, {"text": "We show that both of these effects contribute independently to model fit.", "labels": [], "entities": []}, {"text": "Our findings therefore support the existence of memory-based processing difficulty and shed light on the specific role of memory in sentence processing.", "labels": [], "entities": [{"text": "sentence processing", "start_pos": 132, "end_pos": 151, "type": "TASK", "confidence": 0.7478388547897339}]}], "datasetContent": [{"text": "The Natural Stories corpus) is a set of 10 texts written to sound fluent while containing many low-frequency and marked syntactic constructions, especially subject-and object-extracted relative clauses, clefts, topicalized structures, extraposed relative clauses, sentential subjects, sentential complements, local structural ambiguity, and idioms.", "labels": [], "entities": []}, {"text": "Self-paced reading time data was collected over these texts from 181 native English speakers.", "labels": [], "entities": []}, {"text": "One reason that previous corpus studies might have failed to find locality and integration effects is that the texts might not have included the low-frequency constructions where such effects emerge.", "labels": [], "entities": []}, {"text": "Naturalistic texts, such as the newspaper columns forming the Dundee corpus, are produced and edited to be understood, so they will not frequently contain the kinds of low-frequency, hard-to-process events that bring out differences between processing models.", "labels": [], "entities": [{"text": "Dundee corpus", "start_pos": 62, "end_pos": 75, "type": "DATASET", "confidence": 0.9859579801559448}]}, {"text": "The Natural Stories corpus is designed to exercise such models using constructions which are known to be difficult, providing an opportunity for memory effects to emerge where they have been obscured otherwise.", "labels": [], "entities": [{"text": "Natural Stories corpus", "start_pos": 4, "end_pos": 26, "type": "DATASET", "confidence": 0.6718923151493073}]}, {"text": "The Natural Stories corpus contains 848,207 reading events.", "labels": [], "entities": [{"text": "Natural Stories corpus", "start_pos": 4, "end_pos": 26, "type": "DATASET", "confidence": 0.7098451852798462}]}, {"text": "To control for edge effects, we filtered out all tokens occurring at sentence start and end, leaving 768,023 events.", "labels": [], "entities": []}, {"text": "These were then divided into an exploratory corpus of 255,554 events and a confirmatory corpus of 512,469 events.", "labels": [], "entities": []}, {"text": "Each of our 80 predictors was evaluated via likelihood ratio test of two linear mixed-effects (LME) models fitted to the exploratory dataset: a baseline model with the main fixed effect omitted, and a test model with the main fixed effect included.", "labels": [], "entities": []}, {"text": "All models included sentence position, word length, 5-gram forward surprisal, and total PCFG surprisal as fixed effects, along with by-subject random slopes for each of these, a by-subject random slope for the main effect, and random intercepts for each subject and word.", "labels": [], "entities": []}, {"text": "To control for sentence-level confounds, we additionally included a by-subject random slope and random intercept for sentence ID.", "labels": [], "entities": [{"text": "sentence ID", "start_pos": 117, "end_pos": 128, "type": "TASK", "confidence": 0.6699119657278061}]}, {"text": "To facilitate convergence and maintain comparability between predictors, all predictors were centered and z-transformed prior to fitting.", "labels": [], "entities": []}, {"text": "The likelihood ratio test assumes normally-distributed data, so we used the transform (\u03bb \u2248 \u22120.63) to assure that the data match these assumptions as closely as possible.", "labels": [], "entities": []}, {"text": "5 Significant improvement to model fit fora given main effect indicates that it predicts reading times independently of all controls.", "labels": [], "entities": []}, {"text": "The most significantly predictive effects on the exploratory corpus were selected for evaluation on the confirmatory corpus (see \u00a7 4.1 for discussion of the exploratory/confirmatory partition).", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Evaluation results. Upper: Best left-corner (NoF-S1) and DLT (DLT-CM) predictors. Lower:  Canonical DLT and left-corner (REINST) predictors. Left: Results on exploratory corpus. Right:", "labels": [], "entities": []}]}