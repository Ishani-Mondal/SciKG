{"title": [{"text": "Improving Patent Translation using Bilingual Term Extraction and Re-tokenization for Chinese-Japanese", "labels": [], "entities": [{"text": "Improving Patent Translation", "start_pos": 0, "end_pos": 28, "type": "TASK", "confidence": 0.85122017065684}]}], "abstractContent": [{"text": "Unlike European languages, many Asian languages like Chinese and Japanese do not have typographic boundaries in written system.", "labels": [], "entities": []}, {"text": "Word segmentation (tokenization) that break sentences down into individual words (tokens) is normally treated as the first step for machine translation (MT).", "labels": [], "entities": [{"text": "Word segmentation (tokenization)", "start_pos": 0, "end_pos": 32, "type": "TASK", "confidence": 0.8120489537715911}, {"text": "machine translation (MT)", "start_pos": 132, "end_pos": 156, "type": "TASK", "confidence": 0.819771659374237}]}, {"text": "For Chinese and Japanese, different rules and segmentation tools lead different segmen-tation results in different level of granularity between Chinese and Japanese.", "labels": [], "entities": []}, {"text": "To improve the translation accuracy, we adjust and balance the granularity of segmentation results around terms for Chinese-Japanese patent corpus for training translation model.", "labels": [], "entities": [{"text": "translation", "start_pos": 15, "end_pos": 26, "type": "TASK", "confidence": 0.9498475193977356}, {"text": "accuracy", "start_pos": 27, "end_pos": 35, "type": "METRIC", "confidence": 0.8774381875991821}]}, {"text": "In this paper, we describe a statistical machine translation (SMT) system which is built on re-tokenized Chinese-Japanese patent training corpus using extracted bilingual multi-word terms.", "labels": [], "entities": [{"text": "statistical machine translation (SMT)", "start_pos": 29, "end_pos": 66, "type": "TASK", "confidence": 0.7862815906604131}]}], "introductionContent": [{"text": "China and Japan are producing a large amount of patents in their respective languages.", "labels": [], "entities": []}, {"text": "Making Chinese patents available in Japanese, and Japanese patents in Chinese is an important task for increasing economical development in Asia and international world.", "labels": [], "entities": []}, {"text": "The translation of patents is a key issue that should be helped by the use of SMT.", "labels": [], "entities": [{"text": "translation of patents", "start_pos": 4, "end_pos": 26, "type": "TASK", "confidence": 0.9197258353233337}, {"text": "SMT", "start_pos": 78, "end_pos": 81, "type": "TASK", "confidence": 0.9840064644813538}]}, {"text": "Word segmentation is normally treated as the first step for SMT between Chinese and Japanese.", "labels": [], "entities": [{"text": "Word segmentation", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.6671253442764282}, {"text": "SMT", "start_pos": 60, "end_pos": 63, "type": "TASK", "confidence": 0.997880220413208}]}, {"text": "Patents contain large amounts of domain-specific terms in words or multi-word expressions.", "labels": [], "entities": []}, {"text": "This brings up the question of word segmentation: we may not want to tokenize terms in specific domains in patents.", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 31, "end_pos": 48, "type": "TASK", "confidence": 0.7087982296943665}]}, {"text": "But we cannot control the tokenization of the multi-word terms: a large number of multi-word terms are always segmented into several single-word terms in one language but may not be segmented in another language, or some of the multi-word terms in two languages have different levels of granularity in segmentation because of different conventions of segmentation in different languages.", "labels": [], "entities": []}, {"text": "The related work by shows that segmentation granularity of Chinese word segmentation affects the translation accuracy and that it is very important for MT.", "labels": [], "entities": [{"text": "Chinese word segmentation", "start_pos": 59, "end_pos": 84, "type": "TASK", "confidence": 0.6713782946268717}, {"text": "accuracy", "start_pos": 109, "end_pos": 117, "type": "METRIC", "confidence": 0.9481056928634644}, {"text": "MT", "start_pos": 152, "end_pos": 154, "type": "TASK", "confidence": 0.9905726313591003}]}, {"text": "In (, for improving the translation accuracy of scientific papers, they make use of a constructed mapping table for adjusting Chinese segmentation results according to Japanese segmentation based on characters shared between Chinese and Japanese.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 36, "end_pos": 44, "type": "METRIC", "confidence": 0.8964565396308899}]}, {"text": "In our work, we focus on terms and patent segmentation and translation.", "labels": [], "entities": []}, {"text": "To improve SMT translation accuracy, we change and adjust the segmentation for terms using extracted bilingual multi-word terms for both languages (not only for Chinese or Japanese).", "labels": [], "entities": [{"text": "SMT translation", "start_pos": 11, "end_pos": 26, "type": "TASK", "confidence": 0.9556981325149536}, {"text": "accuracy", "start_pos": 27, "end_pos": 35, "type": "METRIC", "confidence": 0.8020366430282593}]}, {"text": "describes a combination of linguistic and statistical methods (C-value/NC-value) for the automatic extraction of multi-word terms from English corpora.", "labels": [], "entities": [{"text": "automatic extraction of multi-word terms from English corpora", "start_pos": 89, "end_pos": 150, "type": "TASK", "confidence": 0.8311738148331642}]}, {"text": "In, it is showed that the C-/NC-value method is an efficient domain-independent multi-word term recognition not only in English but in Japanese as well.", "labels": [], "entities": [{"text": "multi-word term recognition", "start_pos": 80, "end_pos": 107, "type": "TASK", "confidence": 0.6650389730930328}]}, {"text": "In this paper, we adopt the C-value method to extract monolingual multi-word terms in Chinese and Japanese, and combine it with the sampling-based alignment method) and kanji-hanzi conversion method for bilingual multi-word term extraction.", "labels": [], "entities": [{"text": "kanji-hanzi conversion", "start_pos": 169, "end_pos": 191, "type": "TASK", "confidence": 0.6899896115064621}, {"text": "bilingual multi-word term extraction", "start_pos": 203, "end_pos": 239, "type": "TASK", "confidence": 0.5747173875570297}]}, {"text": "We build SMT systems based on re-tokenized Chinese-Japanese patent training corpus using the extracted bilingual multi-word terms.: Examples of Chinese-Japanese patent segmentation.", "labels": [], "entities": [{"text": "SMT", "start_pos": 9, "end_pos": 12, "type": "TASK", "confidence": 0.9945400357246399}]}, {"text": "Terms in different languages are tokenized at different levels of granularity.", "labels": [], "entities": []}, {"text": "Segmentation tools used are Stanford for Chinese and Juman for Japanese.", "labels": [], "entities": [{"text": "Stanford", "start_pos": 28, "end_pos": 36, "type": "DATASET", "confidence": 0.7256879210472107}]}, {"text": "The words given in the box are the multi-word terms or single-word terms in Chinese or Japanese.", "labels": [], "entities": []}, {"text": "The words in the same color have corresponding translation relations between two languages.", "labels": [], "entities": []}, {"text": "2 Word Segmentation for Chinese-Japanese Patent Corpus gives the examples for Chinese-Japanese patent sentences which are tokenized at different levels of granularity based on different segmentation tools.", "labels": [], "entities": [{"text": "Word Segmentation", "start_pos": 2, "end_pos": 19, "type": "TASK", "confidence": 0.6636694669723511}, {"text": "Chinese-Japanese Patent Corpus", "start_pos": 24, "end_pos": 54, "type": "DATASET", "confidence": 0.6567427416642507}]}, {"text": "For instance, the multi-word term \u94bd\u9633/\u6781\u4f53 ('tantalum anode body') in Chinese has a translation relation with the multi-word // in Japanese, but actually, they do not have any correspondence in word-to-word alignments.", "labels": [], "entities": []}, {"text": "Similar examples are given as \u5f02\u6c30/\u9178\u916f\u57fa ('isocyanate group') in Chinese and / in Japanese, \u653e\u5c04\u7ebf/\u91cf ('radiation dose') in Chinese and / in Japanese.", "labels": [], "entities": []}, {"text": "Another case is that some terms are multi-word terms in one language but single-word terms in another language.", "labels": [], "entities": []}, {"text": "For instance, the single-word term \u80ba\u6c14\u80bf ('emphysema') in Chinese and the multi-word term / in Japanese.", "labels": [], "entities": []}, {"text": "For keeping the direct and exact translations between Chinese and Japanese terms, we intend to re-tokenize Chinese-Japanese parallel sentences center around bilingual multi-word terms.", "labels": [], "entities": []}, {"text": "As such, correspondence and meaning of terms come into focus when adjusting word tokenization granularity.", "labels": [], "entities": []}, {"text": "To do this, we extract bilingual multi-word terms from an existing Chinese-Japanese training corpus, then we build SMT systems based on the re-tokenized training corpus using these extracted bilingual multi-word terms by enforcing them to be considered as one token.", "labels": [], "entities": [{"text": "SMT", "start_pos": 115, "end_pos": 118, "type": "TASK", "confidence": 0.9939917922019958}]}], "datasetContent": [{"text": "The Chinese-Japanese parallel sentences used in our experiments are randomly extracted from the Chinese-Japanese JPO Patent Corpus (JPC) . JPC consists of about 1 million parallel sentences with four sections (Chemistry, Electricity, Mechanical engineering, and Physics).", "labels": [], "entities": [{"text": "JPO Patent Corpus (JPC)", "start_pos": 113, "end_pos": 136, "type": "DATASET", "confidence": 0.8718367516994476}]}, {"text": "It is already divided into training, tuning and test sets: 1 million sentences, 4,000 sentences and 2,000 sentences respectively.", "labels": [], "entities": []}, {"text": "For our experiments, we randomly extract 100,000 parallel sentences from the training part, 1,000 parallel sentences from the tuning part, and 1,000 from the test part.: Statistics on our experimental data sets (after tokenizing and lowercasing).", "labels": [], "entities": []}, {"text": "Here 'mean \u00b1 std.dev' gives the average length of the sentences in words.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Extraction of Chinese-Japanese bilingual multi-word terms by setting a threshold P with 0.6  for both directions. and \u00d7 show the bilingual multi-word term alignment that are kept or excluded.  \u221a", "labels": [], "entities": [{"text": "Extraction of Chinese-Japanese bilingual multi-word terms", "start_pos": 10, "end_pos": 67, "type": "TASK", "confidence": 0.7907801767190298}]}, {"text": " Table 5: Statistics on our experimental data sets (after tokenizing and lowercasing). Here 'mean \u00b1  std.dev' gives the average length of the sentences in words.", "labels": [], "entities": [{"text": "tokenizing", "start_pos": 58, "end_pos": 68, "type": "TASK", "confidence": 0.9619388580322266}]}]}