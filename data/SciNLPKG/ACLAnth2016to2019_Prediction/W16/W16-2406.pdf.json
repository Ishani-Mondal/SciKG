{"title": [{"text": "Data-Driven Spelling Correction using Weighted Finite-State Methods", "labels": [], "entities": [{"text": "Data-Driven Spelling Correction", "start_pos": 0, "end_pos": 31, "type": "TASK", "confidence": 0.6061129868030548}]}], "abstractContent": [{"text": "This paper presents two systems for spelling correction formulated as a sequence labeling task.", "labels": [], "entities": [{"text": "spelling correction", "start_pos": 36, "end_pos": 55, "type": "TASK", "confidence": 0.9707527458667755}, {"text": "sequence labeling task", "start_pos": 72, "end_pos": 94, "type": "TASK", "confidence": 0.7598545749982198}]}, {"text": "One of the systems is an unstructured classifier and the other one is structured.", "labels": [], "entities": []}, {"text": "Both systems are implemented using weighted finite-state methods.", "labels": [], "entities": []}, {"text": "The structured system delivers state-of-the-art results on the task of tweet nor-malization when compared with the recent AliSeTra system introduced by Eger et al.", "labels": [], "entities": []}, {"text": "(2016) even though the system presented in the paper is simpler than AliSeTra because it does not include a model for input segmentation.", "labels": [], "entities": [{"text": "AliSeTra", "start_pos": 69, "end_pos": 77, "type": "DATASET", "confidence": 0.8629443645477295}]}, {"text": "In addition to experiments on tweet normalization, we present experiments on OCR post-processing using an Early Modern Finnish corpus of OCR processed newspaper text.", "labels": [], "entities": [{"text": "tweet normalization", "start_pos": 30, "end_pos": 49, "type": "TASK", "confidence": 0.8476365208625793}, {"text": "Early Modern Finnish corpus of OCR processed newspaper text", "start_pos": 106, "end_pos": 165, "type": "DATASET", "confidence": 0.7832585473855337}]}], "introductionContent": [{"text": "Spelling correction is one of the most widely applied language technological utilities.", "labels": [], "entities": [{"text": "Spelling correction", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.9700261354446411}]}, {"text": "The most obvious application of spelling correction is as a writer's aid.", "labels": [], "entities": [{"text": "spelling correction", "start_pos": 32, "end_pos": 51, "type": "TASK", "confidence": 0.9369388818740845}]}, {"text": "However, many natural language processing applications can also benefit from a spelling correction component.", "labels": [], "entities": [{"text": "spelling correction", "start_pos": 79, "end_pos": 98, "type": "TASK", "confidence": 0.915763646364212}]}, {"text": "For example, many existing NLP systems are trained on newswire which tends to closely adhere to orthographical and grammatical norms.", "labels": [], "entities": []}, {"text": "These systems may incur a substantial hit in performance when they are applied to noisy domains like social media.", "labels": [], "entities": []}, {"text": "When spelling correction is applied as a preprocessing step, performance can be better.", "labels": [], "entities": [{"text": "spelling correction", "start_pos": 5, "end_pos": 24, "type": "TASK", "confidence": 0.9430260956287384}]}, {"text": "Digitization of documents is another domain where spelling correction is useful.", "labels": [], "entities": [{"text": "Digitization of documents", "start_pos": 0, "end_pos": 25, "type": "TASK", "confidence": 0.9130119681358337}, {"text": "spelling correction", "start_pos": 50, "end_pos": 69, "type": "TASK", "confidence": 0.8700328767299652}]}, {"text": "Digitization often aims to transform physical documents into digital representations which support free text search.", "labels": [], "entities": [{"text": "Digitization", "start_pos": 0, "end_pos": 12, "type": "TASK", "confidence": 0.960968554019928}]}, {"text": "This requires the use of an optical character recoginput Am . c output Ann \u03b5 e: Post-editing as sequence labeling.", "labels": [], "entities": []}, {"text": "The input to the post-editor is \"Am.c\" and the correct output is \"Anne\".", "labels": [], "entities": [{"text": "Am.c", "start_pos": 33, "end_pos": 37, "type": "DATASET", "confidence": 0.8475452661514282}, {"text": "Anne", "start_pos": 66, "end_pos": 70, "type": "METRIC", "confidence": 0.8606830835342407}]}, {"text": "This representation corresponds to the 1-to-n alignment of because each input symbol is associated with a possibly empty sequence of outputs.", "labels": [], "entities": []}, {"text": "nition (OCR) engine.", "labels": [], "entities": [{"text": "nition", "start_pos": 0, "end_pos": 6, "type": "TASK", "confidence": 0.8783283233642578}]}, {"text": "Depending on the quality of the engine and source documents, this can succeed to varying degrees.", "labels": [], "entities": []}, {"text": "Spelling correction can be applied as a post-processing step in order to improve quality.", "labels": [], "entities": [{"text": "Spelling correction", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.9787065088748932}]}, {"text": "Spelling correction is an instance of the more general task of string-to-string translation.", "labels": [], "entities": [{"text": "Spelling correction", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.9840410351753235}, {"text": "string-to-string translation", "start_pos": 63, "end_pos": 91, "type": "TASK", "confidence": 0.7355257868766785}]}, {"text": "In spelling correction, the objective is to transform a possibly erroneous input string, for example a misspelling or OCR error, into a correct output string.", "labels": [], "entities": [{"text": "spelling correction", "start_pos": 3, "end_pos": 22, "type": "TASK", "confidence": 0.9407530128955841}]}, {"text": "Like many string-to-string translation tasks, spelling correction can be formulated as sequence labeling: the correction system receives a string of input symbols and associates each input symbol with a (possibly empty) sequence of output symbols as shown in.", "labels": [], "entities": [{"text": "spelling correction", "start_pos": 46, "end_pos": 65, "type": "TASK", "confidence": 0.9720493853092194}]}, {"text": "The input to the correction system can represent a line of text or an isolated word.", "labels": [], "entities": []}, {"text": "We will only consider the case of isolated word correction in the present work.", "labels": [], "entities": [{"text": "word correction", "start_pos": 43, "end_pos": 58, "type": "TASK", "confidence": 0.6767972260713577}]}, {"text": "This paper presents two models for supervised spelling correction.", "labels": [], "entities": [{"text": "supervised spelling correction", "start_pos": 35, "end_pos": 65, "type": "TASK", "confidence": 0.6788903872172037}]}, {"text": "Both treat the task as sequence labeling but one of the models is structured and the other one is unstructured.", "labels": [], "entities": [{"text": "sequence labeling", "start_pos": 23, "end_pos": 40, "type": "TASK", "confidence": 0.6708201467990875}]}, {"text": "Both systems are implemented as finite-state machines and are trained on data consisting of word pairs aligned at character level.", "labels": [], "entities": []}, {"text": "Our unstructured model is a finite-state transducer compiled from a set of weighted contextsensitive replace rules that are used to generate correction candidates from input strings.", "labels": [], "entities": []}, {"text": "These substitutions and their contexts are extracted from training data.", "labels": [], "entities": []}, {"text": "This approach was first presented by for generating multilingual spelling variants of scientific and medical terms originating from Latin and Greek, but it also suitable for other tasks involving probabilistic string-to-string translation.", "labels": [], "entities": [{"text": "string-to-string translation", "start_pos": 210, "end_pos": 238, "type": "TASK", "confidence": 0.7343758940696716}]}, {"text": "Our structured model is an averaged perceptron tagger.", "labels": [], "entities": []}, {"text": "We represent the classifier as a composition of two weighted finite-state machines which incorporate the unstructured and structured features and parameters of the tagger.", "labels": [], "entities": []}, {"text": "When these are combined with an input string, the resulting finitestate machine encodes all correction candidates with their respective weights assigned by the tagger.", "labels": [], "entities": []}, {"text": "The finite-state implementation allows us to extract a given amount of the best scoring correction candidates using well-known and efficient algorithms that are widely available.", "labels": [], "entities": []}, {"text": "The finite-state implementation also allows for restricting candidates to those found in a dictionary.", "labels": [], "entities": []}, {"text": "The paper is structured in the following way.", "labels": [], "entities": []}, {"text": "Section 2 presents earlier approaches to spelling correction and the more general task of string-tostring translation.", "labels": [], "entities": [{"text": "spelling correction", "start_pos": 41, "end_pos": 60, "type": "TASK", "confidence": 0.9706206917762756}, {"text": "string-tostring translation", "start_pos": 90, "end_pos": 117, "type": "TASK", "confidence": 0.6945216655731201}]}, {"text": "In Section 3, we present the unstructured and structured models used for spelling correction.", "labels": [], "entities": [{"text": "spelling correction", "start_pos": 73, "end_pos": 92, "type": "TASK", "confidence": 0.954724907875061}]}, {"text": "In Section 4, we present the features utilized by the correction systems and in Section 5, we show how the systems can be implemented using finite-state methods.", "labels": [], "entities": []}, {"text": "In Section 6, we present the data sets used in the experiments and in Section 7, we present the experimental setup of the paper and the results of the experiments.", "labels": [], "entities": []}, {"text": "Finally, we discuss the results in Section 8 and conclude the paper in Section 9.", "labels": [], "entities": []}], "datasetContent": [{"text": "We perform experiments on the Twitter data and Early Modern Finnish OCR data in the same manner.", "labels": [], "entities": [{"text": "Twitter data", "start_pos": 30, "end_pos": 42, "type": "DATASET", "confidence": 0.8829611539840698}, {"text": "Early Modern Finnish OCR data", "start_pos": 47, "end_pos": 76, "type": "DATASET", "confidence": 0.7861561059951783}]}, {"text": "For each data set, we measure the performance of the unstructured and structured correction system using tenfold cross-validation on the tp Number of erroneous inputs which are corrected.", "labels": [], "entities": []}, {"text": "f p Number of correct inputs which are changed to an incorrect output.", "labels": [], "entities": []}, {"text": "f n Number of erroneous input which are not corrected.", "labels": [], "entities": []}, {"text": "Both of the models presented in the paper incorporate hyper-parameters.", "labels": [], "entities": []}, {"text": "We first set the hyperparameters using development data, then combined the development and training data and use the combination to train the final system which is used to process the test data.", "labels": [], "entities": []}, {"text": "The FinnPos tagger toolkit () is used to train the models for the structured system and the HFST Python interface) is used for constructing and operating finite-state machines.", "labels": [], "entities": [{"text": "FinnPos tagger toolkit", "start_pos": 4, "end_pos": 26, "type": "DATASET", "confidence": 0.85889999071757}]}, {"text": "When training FinnPos models, we used default settings for most hyperparameters.", "labels": [], "entities": [{"text": "FinnPos", "start_pos": 14, "end_pos": 21, "type": "DATASET", "confidence": 0.9291731715202332}]}, {"text": "Only the number of training epochs is determined using development data.", "labels": [], "entities": []}, {"text": "For experiments using a lexicon, we additionally use development data to set the number of top correction candidates N which are looked up in the lexicon as explained in Section 5.6.", "labels": [], "entities": []}, {"text": "For tweet normalization, we use N = 80 and for Finnish OCR post processing, we use N = 5.", "labels": [], "entities": [{"text": "tweet normalization", "start_pos": 4, "end_pos": 23, "type": "TASK", "confidence": 0.8262346386909485}, {"text": "OCR post processing", "start_pos": 55, "end_pos": 74, "type": "TASK", "confidence": 0.5736309985319773}]}, {"text": "As an evaluation metrics, we use correction rate (CR) defined as where tp, f p and f n are defined in: Results for tweet normalization.", "labels": [], "entities": [{"text": "correction rate (CR)", "start_pos": 33, "end_pos": 53, "type": "METRIC", "confidence": 0.9891048550605774}, {"text": "tweet normalization", "start_pos": 115, "end_pos": 134, "type": "TASK", "confidence": 0.7789645791053772}]}, {"text": "UC refers to the unstructured classifier presented in Section 3.1, PT to the perceptron tagger presented in Section 3.2 and AliSeTra to the system presented by.", "labels": [], "entities": [{"text": "PT", "start_pos": 67, "end_pos": 69, "type": "METRIC", "confidence": 0.957158088684082}]}, {"text": "No lexicon (%) Lexicon (%) UC 20.02 \u00b1 1.29 21.58 \u00b1 2.11 PT 32.05 \u00b1 1.97 35.09 \u00b1 2.08: Results for Finnish historical OCR.", "labels": [], "entities": [{"text": "Finnish historical OCR", "start_pos": 98, "end_pos": 120, "type": "DATASET", "confidence": 0.7984135945638021}]}, {"text": "For the Finnish OCR data, the structured perceptron correction system clearly outperforms the unstructured system both without using a lexicon and when using a lexicon.", "labels": [], "entities": [{"text": "Finnish OCR data", "start_pos": 8, "end_pos": 24, "type": "DATASET", "confidence": 0.824221690495809}]}, {"text": "The difference in performance is statistically significant in both cases at the 95% confidence level.", "labels": [], "entities": []}, {"text": "Because the AliSeTra system is not freely available, we do not have results for that system on the Finnish OCR data.", "labels": [], "entities": [{"text": "Finnish OCR data", "start_pos": 99, "end_pos": 115, "type": "DATASET", "confidence": 0.8506024479866028}]}, {"text": "For the Twitter data, both AliSeTra and the perceptron tagger deliver superior accuracy when compared with the unstructured system.", "labels": [], "entities": [{"text": "Twitter data", "start_pos": 8, "end_pos": 20, "type": "DATASET", "confidence": 0.8076417148113251}, {"text": "AliSeTra", "start_pos": 27, "end_pos": 35, "type": "DATASET", "confidence": 0.8419477343559265}, {"text": "accuracy", "start_pos": 79, "end_pos": 87, "type": "METRIC", "confidence": 0.9991152882575989}]}, {"text": "The average performance of the perceptron tagger in this experiment is superior to the performance of the AliSeTra system as reported by.", "labels": [], "entities": []}, {"text": "The difference in performance is, however, not statistically significant.", "labels": [], "entities": []}, {"text": "It should be noted that the data splits used in this work differ from the splits used by.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Results for tweet normalization. UC  refers to the unstructured classifier presented in  Section 3.1, PT to the perceptron tagger presented  in Section 3.2 and AliSeTra to the system pre- sented by", "labels": [], "entities": [{"text": "tweet normalization", "start_pos": 22, "end_pos": 41, "type": "TASK", "confidence": 0.8082166314125061}, {"text": "PT", "start_pos": 112, "end_pos": 114, "type": "METRIC", "confidence": 0.9688077569007874}]}]}