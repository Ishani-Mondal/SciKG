{"title": [], "abstractContent": [{"text": "We participated in the WMT 2016 shared news translation task by building neural translation systems for four language pairs, each trained in both directions: English\u2194Czech, English\u2194German, English\u2194Romanian and English\u2194Russian.", "labels": [], "entities": [{"text": "WMT 2016 shared news translation task", "start_pos": 23, "end_pos": 60, "type": "TASK", "confidence": 0.7047453125317892}]}, {"text": "Our systems are based on an attentional encoder-decoder, using BPE subword segmentation for open-vocabulary translation with a fixed vocabulary.", "labels": [], "entities": [{"text": "BPE subword segmentation", "start_pos": 63, "end_pos": 87, "type": "TASK", "confidence": 0.6675917307535807}, {"text": "open-vocabulary translation", "start_pos": 92, "end_pos": 119, "type": "TASK", "confidence": 0.7260028421878815}]}, {"text": "We experimented with using automatic back-translations of the monolingual News corpus as additional training data, pervasive dropout, and target-bidirectional models.", "labels": [], "entities": [{"text": "News corpus", "start_pos": 74, "end_pos": 85, "type": "DATASET", "confidence": 0.8199920952320099}]}, {"text": "All reported methods give substantial improvements, and we see improvements of 4.3-11.2 BLEU over our baseline systems.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 88, "end_pos": 92, "type": "METRIC", "confidence": 0.9959891438484192}]}, {"text": "In the human evaluation, our systems were the (tied) best constrained system for 7 out of 8 translation directions in which we participated.", "labels": [], "entities": []}], "introductionContent": [{"text": "We participated in the WMT 2016 shared news translation task by building neural translation systems for four language pairs: English\u2194Czech, English\u2194German, English\u2194Romanian and English\u2194Russian.", "labels": [], "entities": [{"text": "WMT 2016 shared news translation task", "start_pos": 23, "end_pos": 60, "type": "TASK", "confidence": 0.7089272439479828}]}, {"text": "Our systems are based on an attentional encoder-decoder (, using BPE subword segmentation for open-vocabulary translation with a fixed vocabulary ().", "labels": [], "entities": [{"text": "BPE subword segmentation", "start_pos": 65, "end_pos": 89, "type": "TASK", "confidence": 0.6794827580451965}, {"text": "open-vocabulary translation", "start_pos": 94, "end_pos": 121, "type": "TASK", "confidence": 0.7242717146873474}]}, {"text": "We experimented with using automatic back-translations of the We have released the implementation that we used for the experiments as an open source toolkit: https://github.", "labels": [], "entities": []}, {"text": "com/rsennrich/nematus We have released scripts, sample configs, synthetic training data and trained models: https://github.com/ rsennrich/wmt16-scripts monolingual News corpus as additional training data (), pervasive dropout (, and target-bidirectional models.", "labels": [], "entities": [{"text": "News corpus", "start_pos": 164, "end_pos": 175, "type": "DATASET", "confidence": 0.8754223585128784}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Amount of parallel and synthetic training  data (number of sentences, in millions) for EN- * language pairs. For synthetic data, we separate  the data according to whether the original mono- lingual language is English or not.", "labels": [], "entities": []}, {"text": " Table 2: English\u2194German translation results  (BLEU) on dev (newstest2015) and test (new- stest2016). Submitted system in bold.", "labels": [], "entities": [{"text": "BLEU)", "start_pos": 47, "end_pos": 52, "type": "METRIC", "confidence": 0.9542601108551025}]}, {"text": " Table 3: English\u2194Czech translation results  (BLEU) on dev (newstest2015) and test (new- stest2016). Submitted system in bold.", "labels": [], "entities": [{"text": "BLEU)", "start_pos": 46, "end_pos": 51, "type": "METRIC", "confidence": 0.9631398618221283}]}, {"text": " Table 4: Czech\u2192English translation results  (BLEU) on dev (newstest2015) and test (new- stest2016), after continued training with increas- ing amounts of back-translated synthetic data. For  each row, training was continued from the baseline  model until convergence.", "labels": [], "entities": [{"text": "Czech\u2192English translation", "start_pos": 10, "end_pos": 35, "type": "TASK", "confidence": 0.4988683685660362}, {"text": "BLEU", "start_pos": 46, "end_pos": 50, "type": "METRIC", "confidence": 0.9963434338569641}]}, {"text": " Table 5: English\u2194Romanian translation results  (BLEU) on dev (newsdev2016), and test (new- stest2016). Submitted system in bold.", "labels": [], "entities": [{"text": "BLEU)", "start_pos": 49, "end_pos": 54, "type": "METRIC", "confidence": 0.9170508086681366}]}, {"text": " Table 6: English\u2194Russian translation results  (BLEU) on dev (newstest2015) and test (new- stest2016). Submitted system in bold.", "labels": [], "entities": [{"text": "BLEU)", "start_pos": 48, "end_pos": 53, "type": "METRIC", "confidence": 0.9564476609230042}]}, {"text": " Table 7: Automatic (BLEU) and human ranking  of our submitted systems (uedin-nmt) at WMT16  shared news translation task. Automatic rankings  are taken from http://matrix.statmt.  org , only considering primary systems. Human  rankings include anonymous online systems, and  for EN\u2194CS, systems from the tuning task.", "labels": [], "entities": [{"text": "Automatic (BLEU)", "start_pos": 10, "end_pos": 26, "type": "METRIC", "confidence": 0.8027097433805466}, {"text": "WMT16  shared news translation task", "start_pos": 86, "end_pos": 121, "type": "TASK", "confidence": 0.8351612329483032}]}]}