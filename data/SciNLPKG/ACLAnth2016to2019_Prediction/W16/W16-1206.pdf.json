{"title": [{"text": "Leveraging Data-Driven Methods in Word-Level Language Identification fora Multilingual Alpine Heritage Corpus", "labels": [], "entities": [{"text": "Word-Level Language Identification", "start_pos": 34, "end_pos": 68, "type": "TASK", "confidence": 0.5945354998111725}, {"text": "Multilingual Alpine Heritage Corpus", "start_pos": 74, "end_pos": 109, "type": "DATASET", "confidence": 0.6657530665397644}]}], "abstractContent": [{"text": "This paper presents a data-driven, simple cluster-and-label approach using optimized count-based methods for word-level language identification fora large domain-specific multilingual diachronic corpus of periodicals published at least yearly between 1864 and 2014 in Switzerland.", "labels": [], "entities": [{"text": "word-level language identification", "start_pos": 109, "end_pos": 143, "type": "TASK", "confidence": 0.6584104498227438}]}, {"text": "Our system requires no annotated data or training, only minimal human effort in evaluating and labeling 50 clusters fora corpus of almost 40 million tokens.", "labels": [], "entities": []}, {"text": "Despite being unsupervised, our results show an accuracy that is comparable to the corpus annotations which result from an existing code switching algorithm and the combined usage of two supervised systems using character and byte n-gram models (Volk and Clematide, 2014).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 48, "end_pos": 56, "type": "METRIC", "confidence": 0.9996702671051025}]}], "introductionContent": [{"text": "Language identification (LID) is important in NLP so long as the applications and tools designed and used are language-specific.", "labels": [], "entities": [{"text": "Language identification (LID)", "start_pos": 0, "end_pos": 29, "type": "TASK", "confidence": 0.8253031015396118}]}, {"text": "Many tokenizers, POStaggers, lemmatization and NER systems suffer in performance when met with sporadic sequences of foreign/unknown elements -this is especially the case when the languages in question are lesser known, the domain is more specific, and/or the training material is scarce.", "labels": [], "entities": []}, {"text": "The view that LID is a \"solved task\" is unfortunately a misconception that is based on the success of work that dealt with documentlevel LID in a small number of languages.", "labels": [], "entities": []}, {"text": "Real world data, esp.", "labels": [], "entities": []}, {"text": "those with much code switching (CS), the phenomenon that occurs when speakers/writers switchback and forth between at least two languages in communication, on smaller spans of texts or with mixed genres, continue to pose challenges.", "labels": [], "entities": [{"text": "code switching (CS)", "start_pos": 16, "end_pos": 35, "type": "TASK", "confidence": 0.8168170332908631}]}, {"text": "In this paper, we present our initial LID effort fora large, domain-specific, yet very diverse in themes and styles, multilingual diachronic corpus of periodicals published by the Swiss Alpine Club (SAC) abound with intrasentential CS instances.", "labels": [], "entities": [{"text": "Swiss Alpine Club (SAC)", "start_pos": 180, "end_pos": 203, "type": "DATASET", "confidence": 0.8449545204639435}]}, {"text": "CS in this corpus has previously been addressed in who use a set of heuristics to identify code-switching candidates and label these using langid.py 1 (, an off-the-shelf Python package providing a supervised multinomial Naive Bayes classifier that has been trained over a mixture of byte n-grams (1\u2264n\u2264 4) on 97 languages.", "labels": [], "entities": []}, {"text": "In contrast, we attempt to tackle this task through a simple cluster-and-label approach with unsupervised word vectors.", "labels": [], "entities": []}, {"text": "Our system -requiring only minimal human intervention when labeling the induced clusters -achieves comparable performance to the existing CS annotations, demonstrating the feasibility of unsupervised word clustering for LID for our corpus.", "labels": [], "entities": []}], "datasetContent": [{"text": "These annotations result from the implementation of the CS detection algorithm from Volk and Clematide (2014) (hereafter: VCCS) which uses a combination of four factors (the presence of quotation marks, at least 2 tokens being outside of these quotation marks, lemma tags unknown, and minimum CS segment length of 15 characters) as cues to identify CS instances.", "labels": [], "entities": [{"text": "CS detection", "start_pos": 56, "end_pos": 68, "type": "TASK", "confidence": 0.7588030993938446}]}, {"text": "According to these criteria, 194 of the 209 yearbook files contain at least one CS sentence.", "labels": [], "entities": []}, {"text": "We randomly select one CS sentence from each of these 194 files to evaluate TBLID based on word-level language label accuracy and to compare our labels to the TB annotations which are output of langid.py for the intrasentential CS segments and Lingua-Ident on the sentence level.", "labels": [], "entities": [{"text": "TBLID", "start_pos": 76, "end_pos": 81, "type": "METRIC", "confidence": 0.9183682799339294}, {"text": "accuracy", "start_pos": 117, "end_pos": 125, "type": "METRIC", "confidence": 0.6046943068504333}]}, {"text": "(Classifying words one by one using langid.py alone for these 194 sentences yielded an overall accuracy of approximately 36%, hence it will not be used for comparison in this study.)", "labels": [], "entities": [{"text": "accuracy", "start_pos": 95, "end_pos": 103, "type": "METRIC", "confidence": 0.9991965889930725}]}, {"text": "Word-level language identification accuracy is the percentage of the correctly labeled word tokens (i.e. tokens containing no numeric element or punctuation except for hyphen(s), apostrophe(s), and period(s)) from all sentences with CS.", "labels": [], "entities": [{"text": "Word-level language identification", "start_pos": 0, "end_pos": 34, "type": "TASK", "confidence": 0.5506345331668854}, {"text": "accuracy", "start_pos": 35, "end_pos": 43, "type": "METRIC", "confidence": 0.8781064748764038}]}, {"text": "2 of these 194 sentences are disqualified for evaluation due to indecipherability as they consist exclusively of numeric elements and abbreviations, most of which are potential OCR errors.", "labels": [], "entities": []}, {"text": "This leaves us with a total of 5,073 word tokens.", "labels": [], "entities": []}, {"text": "All word tokens are evaluated in context, in the particular instance, not for their potentiality to take on a certain label.", "labels": [], "entities": []}, {"text": "E.g. the two word tokens par an meaning yearly in a FR segment should both be labeled FR, even though par can be DE/EN/FR/IT/RM, and an can bean EN, FR, DE, as well as a RM word, if evaluated independently.", "labels": [], "entities": [{"text": "FR", "start_pos": 86, "end_pos": 88, "type": "METRIC", "confidence": 0.9871165156364441}]}, {"text": "We will return to the issue of multilingual homographs in our discussion in Section 6.1 below.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Accuracy scores (rounded to 2 digits) from non-parametric (Dirichlet Process Gaussian Mixture Model) vs. parametric", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9987369179725647}]}]}