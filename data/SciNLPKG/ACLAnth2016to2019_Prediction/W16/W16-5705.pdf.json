{"title": [{"text": "Automatic Identification of Narrative Diegesis and Point of View", "labels": [], "entities": [{"text": "Narrative Diegesis", "start_pos": 28, "end_pos": 46, "type": "TASK", "confidence": 0.7623133957386017}]}], "abstractContent": [{"text": "The style of narrative news affects how it is interpreted and received by readers.", "labels": [], "entities": []}, {"text": "Two key stylistic characteristics of narrative text are point of view and diegesis: respectively, whether the narrative recounts events personally or impersonally, and whether the narrator is involved in the events of the story.", "labels": [], "entities": []}, {"text": "Although central to the interpretation and reception of news, and of narratives more generally, there has been no prior work on automatically identifying these two characteristics in text.", "labels": [], "entities": [{"text": "interpretation and reception of news", "start_pos": 24, "end_pos": 60, "type": "TASK", "confidence": 0.8173536419868469}]}, {"text": "We develop automatic classifiers for point of view and diegesis, and compare the performance of different feature sets for both.", "labels": [], "entities": []}, {"text": "We built a gold-standard corpus where we double-annotated to substantial agreement (\u03ba > 0.59) 270 En-glish novels for point of view and diegesis.", "labels": [], "entities": []}, {"text": "As might be expected, personal pronouns comprise the best features for point of view classification , achieving an average F 1 of 0.928.", "labels": [], "entities": [{"text": "point of view classification", "start_pos": 71, "end_pos": 99, "type": "TASK", "confidence": 0.7051806747913361}, {"text": "F 1", "start_pos": 123, "end_pos": 126, "type": "METRIC", "confidence": 0.9962309002876282}]}, {"text": "For diegesis, the best features were personal pronouns and the occurrences of first person pronouns in the argument of verbs, achieving an average F 1 of 0.898.", "labels": [], "entities": [{"text": "F 1", "start_pos": 147, "end_pos": 150, "type": "METRIC", "confidence": 0.99588343501091}]}, {"text": "We apply the clas-sifier to nearly 40,000 news texts across five different corpora comprising multiple genres (including newswire, opinion, blog posts, and scientific press releases), and show that the point of view and diegesis correlates largely as expected with the nominal genre of the texts.", "labels": [], "entities": []}, {"text": "We release the training data and the classifier for use by the community.", "labels": [], "entities": []}], "introductionContent": [{"text": "Interpreting a text's veridicality, correctly identifying the implications of its events, and properly delimiting the scope of its references are all challenging and important problems that are critical to achieving complete automatic understanding of news stories and, indeed, text generally.", "labels": [], "entities": []}, {"text": "There has been significant progress on some of these problems for certain sorts of texts, for example, recognizing implications on short, impersonal, factual text in the long-running Recognizing Textual Entailment challenge (RTE 1 ).", "labels": [], "entities": [{"text": "Recognizing Textual Entailment challenge (RTE 1 )", "start_pos": 183, "end_pos": 232, "type": "TASK", "confidence": 0.7646653391420841}]}, {"text": "On the other hand, narrative text (including much news writing) presents additional complications, in that to accomplish the tasks above one must take into account the narrator's point of view (i.e., first person or third person), as well as the narrator's personal involvement in the story (a feature that narratologists call diegesis).", "labels": [], "entities": []}, {"text": "In news stories specifically writers are encouraged to use the third person point of view when they wish to emphasize their objectivity regarding the news they are reporting.", "labels": [], "entities": []}, {"text": "In opinion pieces or blog posts, on the other hand, first person is more common and implies a more personal (and perhaps more subjective) view.", "labels": [], "entities": []}, {"text": "News writers are also often in the position of reporting on events which they themselves have not directly observed, and in these cases can use an uninvolved style (known as hetereodiegetic narration) to communicate their relative remove from the action.", "labels": [], "entities": []}, {"text": "When writers observe or participate in events directly, however, or are reporting on their own lives (such as in blog posts), they can use an involved narrative style (i.e., homodiegetic narration) to emphasize their personal knowledge and subjective, perhaps biased, orientation.", "labels": [], "entities": []}, {"text": "Before we can integrate knowledge of point of view (POV) or diegesis into text understanding, we must be able to identify them, but there are no systems which enable automatic classification of these features.", "labels": [], "entities": []}, {"text": "In this paper we develop reliable classifiers for both POV and diegesis, apply the classifiers to texts drawn from five different news genres, demonstrate the accuracy of the classifiers on these news texts, and show that the POV and diegesis correlates much as expected with the genre.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 159, "end_pos": 167, "type": "METRIC", "confidence": 0.9989054203033447}]}, {"text": "We release the classifiers and the training data so the field may build on our work and integrate these features into other text processing systems.", "labels": [], "entities": []}, {"text": "Regarding the point of view of the narrator, narratologist Mieke Bal claimed \"The different relationships of the narrative 'I' to the objects of narration are constant within each narrative text.", "labels": [], "entities": []}, {"text": "This means that one can immediately, already on the first page, see which is the.\"", "labels": [], "entities": []}, {"text": "This assertion inspired the development of the classifiers presented here: we had annotators mark narrative POV and diegesis from the first 60 lines of each of 270 English novels, which is a generous simulation of \"the first page\".", "labels": [], "entities": []}, {"text": "This observation allowed us to transform the collection of data for supervised machine learning from an unmanageable burden (i.e., having annotators read every novel from start to finish) into a tractable task (reading only the first page).", "labels": [], "entities": []}, {"text": "We chose novels for training, instead of news texts themselves, because of the novels' greater diversity of language and style.", "labels": [], "entities": []}, {"text": "The classifiers allowed us to quickly assess the POV and diegesis of the texts and show how expectations of objectivity or involvement differ across genres.", "labels": [], "entities": [{"text": "POV", "start_pos": 49, "end_pos": 52, "type": "METRIC", "confidence": 0.8735053539276123}]}, {"text": "The paper proceeds as follows.", "labels": [], "entities": []}, {"text": "In \u00a72 we define point of view and diegesis, and discuss their different attributes.", "labels": [], "entities": []}, {"text": "In \u00a73 we describe the annotation of the training and testing corpus, and then in \u00a74 describe the development of the classifiers.", "labels": [], "entities": []}, {"text": "In \u00a75 we detail the results of applying the classifiers to the news texts.", "labels": [], "entities": []}, {"text": "In \u00a76 we outline related work, and in \u00a77 we discuss how shortcomings of the work and how it might be improved.", "labels": [], "entities": []}, {"text": "We summarize the contributions in \u00a78.", "labels": [], "entities": []}, {"text": "In short, this paper asks the qeustion: can point of view and deigesis be automatically classified?", "labels": [], "entities": []}, {"text": "The experimental results in this paper show that it can be done.", "labels": [], "entities": []}], "datasetContent": [{"text": "To determine the best sets of features for classification, we conducted two experiments, one each for POV and diegesis.", "labels": [], "entities": [{"text": "classification", "start_pos": 43, "end_pos": 57, "type": "TASK", "confidence": 0.9633630514144897}]}, {"text": "In each case, texts were preprocessed as described above ( \u00a74.1), and various features were extracted as described below.", "labels": [], "entities": []}, {"text": "Then we partitioned the corpus training and testing sets using ten-fold cross-validation.", "labels": [], "entities": []}, {"text": "Precisely, this was done as follows: for POV, the texts annotated as first person were divided into ten sets containing nearly equal numbers of texts, and we did the same for the third person texts.", "labels": [], "entities": []}, {"text": "Then the first set of both the first person and third person texts were designated as the test sets and the classifier was trained on the remaining nine sets from each class.", "labels": [], "entities": []}, {"text": "This was repeated with each set (second, third, fourth, etc.", "labels": [], "entities": []}, {"text": "), designating each set in order as the test set, with the remaining sets used for training.", "labels": [], "entities": []}, {"text": "There are more third person narrators in the corpus; hence, each training fold has more examples of third person narrators than first person narrators.", "labels": [], "entities": []}, {"text": "We performed cross-validation for diegesis in exactly the same manner.", "labels": [], "entities": []}, {"text": "We then trained an SVM classifier on the training fold using specific features as described below ().", "labels": [], "entities": [{"text": "SVM classifier", "start_pos": 19, "end_pos": 33, "type": "TASK", "confidence": 0.8340709805488586}]}, {"text": "To evaluate performance of the classifiers we report macro-averaged precision, recall, and F 1 measure.", "labels": [], "entities": [{"text": "precision", "start_pos": 68, "end_pos": 77, "type": "METRIC", "confidence": 0.9309051632881165}, {"text": "recall", "start_pos": 79, "end_pos": 85, "type": "METRIC", "confidence": 0.9996718168258667}, {"text": "F 1 measure", "start_pos": 91, "end_pos": 102, "type": "METRIC", "confidence": 0.9896569649378458}]}, {"text": "This is done by averaging, without any weighting, the precision, recall, and F 1 from each fold.", "labels": [], "entities": [{"text": "precision", "start_pos": 54, "end_pos": 63, "type": "METRIC", "confidence": 0.9997382760047913}, {"text": "recall", "start_pos": 65, "end_pos": 71, "type": "METRIC", "confidence": 0.9991845488548279}, {"text": "F 1", "start_pos": 77, "end_pos": 80, "type": "METRIC", "confidence": 0.9962958097457886}]}, {"text": "We also report the average of F 1 for overall performance (weighted by number of texts).", "labels": [], "entities": [{"text": "F 1", "start_pos": 30, "end_pos": 33, "type": "METRIC", "confidence": 0.9937599897384644}]}], "tableCaptions": [{"text": " Table 3: Performance of point of view classification for different feature sets. The left hand column describes different sets of", "labels": [], "entities": [{"text": "point of view classification", "start_pos": 25, "end_pos": 53, "type": "TASK", "confidence": 0.7081694155931473}]}, {"text": " Table 4: Performance of diegesis classification for different feature sets. The \"co-occurence\" feature is explained in the text. The", "labels": [], "entities": [{"text": "diegesis classification", "start_pos": 25, "end_pos": 48, "type": "TASK", "confidence": 0.8704957067966461}]}, {"text": " Table 5: POV and Diegesis classifications of texts across corpora. Total number of texts was 39,653. The columns labeled \"1st", "labels": [], "entities": [{"text": "POV", "start_pos": 10, "end_pos": 13, "type": "DATASET", "confidence": 0.6901047825813293}]}]}