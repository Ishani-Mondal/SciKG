{"title": [{"text": "Romanized Berber and Romanized Arabic Automatic Language Identification Using Machine Learning", "labels": [], "entities": [{"text": "Automatic Language Identification", "start_pos": 38, "end_pos": 71, "type": "TASK", "confidence": 0.5421089828014374}]}], "abstractContent": [{"text": "The identification of the language of text/speech input is the first step to be able to properly do any language-dependent natural language processing.", "labels": [], "entities": [{"text": "identification of the language of text/speech input", "start_pos": 4, "end_pos": 55, "type": "TASK", "confidence": 0.7719622386826409}]}, {"text": "The task is called Automatic Language Identification (ALI).", "labels": [], "entities": [{"text": "Automatic Language Identification (ALI)", "start_pos": 19, "end_pos": 58, "type": "TASK", "confidence": 0.711780309677124}]}, {"text": "Being a well-studied field since early 1960's, various methods have been applied to many standard languages.", "labels": [], "entities": []}, {"text": "The ALI standard methods require datasets for training and use character/word-based n-gram models.", "labels": [], "entities": []}, {"text": "However, social media and new technologies have contributed to the rise of informal and minority languages on the Web.", "labels": [], "entities": []}, {"text": "The state-of-the-art automatic language identifiers fail to properly identify many of them.", "labels": [], "entities": []}, {"text": "Romanized Arabic (RA) and Romanized Berber (RB) are cases of these informal languages which are under-resourced.", "labels": [], "entities": []}, {"text": "The goal of this paper is twofold: detect RA and RB, at a document level, as separate languages and distinguish between them as they coexist in North Africa.", "labels": [], "entities": [{"text": "RB", "start_pos": 49, "end_pos": 51, "type": "METRIC", "confidence": 0.6663075089454651}]}, {"text": "We consider the task as a classification problem and use supervised machine learning to solve it.", "labels": [], "entities": []}, {"text": "For both languages, character-based 5-grams combined with additional lexicons score the best, F-score of 99.75% and 97.77% for RB and RA respectively.", "labels": [], "entities": [{"text": "F-score", "start_pos": 94, "end_pos": 101, "type": "METRIC", "confidence": 0.9987712502479553}, {"text": "RB", "start_pos": 127, "end_pos": 129, "type": "METRIC", "confidence": 0.9913449287414551}, {"text": "RA", "start_pos": 134, "end_pos": 136, "type": "METRIC", "confidence": 0.6598197221755981}]}], "introductionContent": [{"text": "Social media and new technology devices have facilitated the emergence of new languages on the Web which are mainly written forms of colloquial languages.", "labels": [], "entities": []}, {"text": "Most of these languages are under-resourced and do not adhere to any standard grammar or orthography.", "labels": [], "entities": []}, {"text": "Romanized Arabic (RA) or Arabic written in Latin script (called often Arabizi) is an informal language.", "labels": [], "entities": [{"text": "Romanized Arabic (RA)", "start_pos": 0, "end_pos": 21, "type": "TASK", "confidence": 0.5678098440170288}]}, {"text": "However, Romanized Berber (RB) is one of the Berber or Tamazight 1 standard forms.", "labels": [], "entities": [{"text": "Romanized Berber (RB", "start_pos": 9, "end_pos": 29, "type": "METRIC", "confidence": 0.4249841496348381}, {"text": "Berber or Tamazight 1 standard forms", "start_pos": 45, "end_pos": 81, "type": "DATASET", "confidence": 0.8138191203276316}]}, {"text": "Both RA and RB are under-resourced and unknown languages to the available language identification tools 2 . To be able to automatically process and analyze content in RA and RB, it is necessary to properly recognize the languages.", "labels": [], "entities": [{"text": "language identification", "start_pos": 74, "end_pos": 97, "type": "TASK", "confidence": 0.7374462485313416}]}, {"text": "Otherwise, there is a large risk of getting misleading information.", "labels": [], "entities": []}, {"text": "Moreover, it is crucial to be able to distinguish between them.", "labels": [], "entities": []}, {"text": "The reason is that RA and RB coexist in North Africa, which is a rich multilingual region, and they share a considerable amount of vocabulary due to the close contact between them.", "labels": [], "entities": [{"text": "RB", "start_pos": 26, "end_pos": 28, "type": "METRIC", "confidence": 0.8402382135391235}]}, {"text": "Undoubtedly, this type of tool will help to build NLP applications for both.", "labels": [], "entities": []}, {"text": "There is some work done to automatically transliterate RA into Arabic script (Al- ).", "labels": [], "entities": [{"text": "transliterate RA into Arabic script (Al- )", "start_pos": 41, "end_pos": 83, "type": "TASK", "confidence": 0.6933506528536478}]}, {"text": "However, this is very limited because RA perfectly adheres to the principle 'write as you speak', i.e. there is no standardized orthography.", "labels": [], "entities": [{"text": "RA", "start_pos": 38, "end_pos": 40, "type": "TASK", "confidence": 0.928054928779602}]}, {"text": "Furthermore, the Arabic Chat Alphabet (ACA), designed for Romanized Arabic used in social media, is just a suggested writing system and not necessarily a Natural Language Processing (NLP) tool for RA.", "labels": [], "entities": [{"text": "RA", "start_pos": 197, "end_pos": 199, "type": "TASK", "confidence": 0.9742276668548584}]}, {"text": "To overcome the various challenges faced when dealing with RA automatic processing, namely the use of non-standardized orthography, spelling errors and the lack of linguistic resources, we believe that it is better to consider RA as a stand-alone language and try to find better ways to deal with it instead of using only transliteration.", "labels": [], "entities": [{"text": "RA automatic processing", "start_pos": 59, "end_pos": 82, "type": "TASK", "confidence": 0.9032779932022095}]}, {"text": "RB is already a stand-alone language.", "labels": [], "entities": []}, {"text": "It is important to clarify that considering both RA and RB as a stand-alone languages does not suggest, at any point, that the use of the Latin alphabet is a sufficient criteria to define them as such.", "labels": [], "entities": []}, {"text": "Our main motivation is to make their automatic processing easier.", "labels": [], "entities": []}, {"text": "We start the paper with a general overview about the work done for informal Arabic NLP in Section 2.", "labels": [], "entities": [{"text": "informal Arabic NLP", "start_pos": 67, "end_pos": 86, "type": "TASK", "confidence": 0.5733686685562134}]}, {"text": "We then give some brief information about RA and RB in Section 3.", "labels": [], "entities": [{"text": "RA", "start_pos": 42, "end_pos": 44, "type": "METRIC", "confidence": 0.7905531525611877}, {"text": "RB", "start_pos": 49, "end_pos": 51, "type": "METRIC", "confidence": 0.9614224433898926}]}, {"text": "Next, in Section 4, we describe how we proceed to build the linguistic resources used to build our system.", "labels": [], "entities": []}, {"text": "In Section 5, we explain the used methods and describe the experiments and discuss the results.", "labels": [], "entities": []}, {"text": "We conclude by general findings and future directions.", "labels": [], "entities": []}], "datasetContent": [{"text": "Various methods have been applied to Automatic Language Identification since early 1960's.", "labels": [], "entities": [{"text": "Automatic Language Identification", "start_pos": 37, "end_pos": 70, "type": "TASK", "confidence": 0.7665008902549744}]}, {"text": "In this paper, we use two techniques of supervised machine learning, namely Cavnar's method and Support Vector Machines (SVM).", "labels": [], "entities": []}, {"text": "As features, we experiment with both character-based and word based n-grams of different lengths.", "labels": [], "entities": []}, {"text": "We use the term frequency-inverse document frequency 17 (TF-IFD) scheme to weight the importance of the features.", "labels": [], "entities": []}, {"text": "Both methods require training data which we pre-processed to filter unimportant tokens such as punctuation, emoticons, etc.", "labels": [], "entities": []}, {"text": "We also want to build an automatic language identifier which learns linguistic information rather than learning topical and country specific words.", "labels": [], "entities": []}, {"text": "Therefore, we remove all Named Entities (NE) such as names of people, organizations and locations using a large NE database which includes both RA and RB NEs we compiled for an ongoing project.", "labels": [], "entities": []}, {"text": "For experiments, we use a balanced dataset of 500 documents (between 4,506 -117,000 words) for each language (total of 3,000 documents or 640,207 words) divided into 1,800 documents or 420,300 words (300 documents for each language) for training and the remaining 1,200 documents or 219,907 words for evaluation.", "labels": [], "entities": []}, {"text": "As mentioned before, a document is an entire user's comment which may contain between 2 to 5 sentences depending on the social media platform.", "labels": [], "entities": []}, {"text": "We use text maximum length of 140 characters when using character-based n-gram and text maximum length of 15 words 21 for word-based n-grams.", "labels": [], "entities": []}, {"text": "The classification results are shown in.", "labels": [], "entities": []}, {"text": "In another experiment, we use the same previous experimental setup but this time we combine the wordbased unigram with the entries of the compiled lexicons as features.", "labels": [], "entities": []}, {"text": "The SVM classifier accuracy has slightly improved to 97.50% compared to using only the word unigram 95.91%.", "labels": [], "entities": [{"text": "SVM classifier", "start_pos": 4, "end_pos": 18, "type": "TASK", "confidence": 0.7431327104568481}, {"text": "accuracy", "start_pos": 19, "end_pos": 27, "type": "METRIC", "confidence": 0.9746485352516174}]}, {"text": "This indicates that combining the word unigram with the lexicon entries (language-specific word) has a positive effect on the classification.", "labels": [], "entities": []}, {"text": "Still there is confusion between RP and RA caused mainly by false friends.", "labels": [], "entities": [{"text": "RP and RA", "start_pos": 33, "end_pos": 42, "type": "TASK", "confidence": 0.516256699959437}]}, {"text": "Furthermore, we combine character-based 5-grams with the entries of the compiled lexicons using the same experimental setup.", "labels": [], "entities": []}, {"text": "The SVM accuracy has increased to 99.02%.", "labels": [], "entities": [{"text": "SVM", "start_pos": 4, "end_pos": 7, "type": "METRIC", "confidence": 0.6508152484893799}, {"text": "accuracy", "start_pos": 8, "end_pos": 16, "type": "METRIC", "confidence": 0.9445919990539551}]}, {"text": "summarizes the SVM performance using the combination of character-based 5-grams and the entries of the compiled lexicons as features.: SVM classification using the combination of character-based 5-grams and lexicons.", "labels": [], "entities": [{"text": "SVM classification", "start_pos": 135, "end_pos": 153, "type": "TASK", "confidence": 0.8599798083305359}]}, {"text": "The classifier's macro-average F-score is 99.00%.", "labels": [], "entities": [{"text": "F-score", "start_pos": 31, "end_pos": 38, "type": "METRIC", "confidence": 0.9622474908828735}]}, {"text": "Using the combination of the character-based 5-grams and the entries of the compiled lexicons as features has improved the overall accuracy of the SVM 99.02% compared to 98.75% using only character-based 5-grams.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 131, "end_pos": 139, "type": "METRIC", "confidence": 0.9993504881858826}]}, {"text": "It has also positive effect on each language except for RA where the F-score has slightly decreased to 97.77% compared to 98.24%.", "labels": [], "entities": [{"text": "RA", "start_pos": 56, "end_pos": 58, "type": "TASK", "confidence": 0.5231730937957764}, {"text": "F-score", "start_pos": 69, "end_pos": 76, "type": "METRIC", "confidence": 0.999242901802063}]}, {"text": "To be able to compare the word-based n-grams and character-based n-grams, we rerun the same experiment using text full length.", "labels": [], "entities": []}, {"text": "Still, the character-based 5-grams outperform the word-based n-grams, F-score of 99.77% and 97.89% respectively.", "labels": [], "entities": [{"text": "F-score", "start_pos": 70, "end_pos": 77, "type": "METRIC", "confidence": 0.9990901947021484}]}, {"text": "There area few misclassifications between different languages as shown in.", "labels": [], "entities": []}, {"text": "The few errors are caused by false friends between close/similar languages such as RA and RP and also in case of mixlanguages, for instance between RA and FR where the former uses lots of words from the latter.", "labels": [], "entities": []}, {"text": "An error analysis of the sample shows that most errors occurred in very short documents (less than 10 words in our case).: The confusion matrix of the system for the same settings as in.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Cavnar's classification per language using character-based bigrams.", "labels": [], "entities": []}, {"text": " Table 2: SVM performance using different features.", "labels": [], "entities": []}, {"text": " Table 3: SVM classification using the combination of character-based unigram and trigrams.", "labels": [], "entities": [{"text": "SVM classification", "start_pos": 10, "end_pos": 28, "type": "TASK", "confidence": 0.8759195804595947}]}, {"text": " Table 4: SVM classification using the combination of character-based 5-grams and lexicons.", "labels": [], "entities": [{"text": "SVM classification", "start_pos": 10, "end_pos": 28, "type": "TASK", "confidence": 0.9060774743556976}]}]}