{"title": [{"text": "A Web-based Tool for the Integrated Annotation of Semantic and Syntactic Structures", "labels": [], "entities": [{"text": "Integrated Annotation of Semantic and Syntactic Structures", "start_pos": 25, "end_pos": 83, "type": "TASK", "confidence": 0.7023941874504089}]}], "abstractContent": [{"text": "We introduce the third major release of WebAnno, a generic web-based annotation tool for distributed teams.", "labels": [], "entities": []}, {"text": "New features in this release focus on semantic annotation tasks (e.g. semantic role labelling or event annotation) and allow the tight integration of semantic annotations with syntactic annotations.", "labels": [], "entities": [{"text": "semantic role labelling", "start_pos": 70, "end_pos": 93, "type": "TASK", "confidence": 0.6267657577991486}]}, {"text": "In particular, we introduce the concept of slot features, a novel constraint mechanism that allows modelling the interaction between semantic and syntactic annotations, as well as anew annotation user interface.", "labels": [], "entities": []}, {"text": "The new features were developed and used in an annotation project for semantic roles on German texts.", "labels": [], "entities": []}, {"text": "The paper briefly introduces this project and reports on experiences performing annotations with the new tool.", "labels": [], "entities": []}, {"text": "On a comparative evaluation, our tool reaches significant speedups over WebAnno 2 fora semantic annotation task.", "labels": [], "entities": []}], "introductionContent": [{"text": "As natural language processing pushes towards natural language understanding, i.e. the ability fora machine to process the meaning of language rather than just its structure, there is a growing need for corpora analysed on the semantic level.", "labels": [], "entities": [{"text": "natural language understanding", "start_pos": 46, "end_pos": 76, "type": "TASK", "confidence": 0.721011241277059}]}, {"text": "Semantic structures pose different requirements for annotation tools than morphological or syntactic annotation.", "labels": [], "entities": []}, {"text": "For example, the rich sets of semantic categories used in tasks such as semantic role labelling (SRL) or event annotation require special support to avoid the choice becoming a burden to the annotator.", "labels": [], "entities": [{"text": "semantic role labelling (SRL)", "start_pos": 72, "end_pos": 101, "type": "TASK", "confidence": 0.780832772453626}]}, {"text": "Also, due to the interaction of semantics with other levels of linguistic analysis, particularly syntax, it is desirable to work with generic annotation tools that simultaneously support multiple levels of annotation.", "labels": [], "entities": []}, {"text": "Generic web-based annotation tools do not sufficiently support the annotation of semantic structures with their rich tagsets.", "labels": [], "entities": []}, {"text": "Also, specialised annotation tools, in particular for SRL, are not flexibly adaptable to other annotation schemes, and many of them are technologically outdated.", "labels": [], "entities": [{"text": "SRL", "start_pos": 54, "end_pos": 57, "type": "TASK", "confidence": 0.959955096244812}]}, {"text": "WebAnno 3 1 is the third major release of the web-based annotation tool WebAnno () introducing new functionalities enabling the annotation of semantic structures: 1.", "labels": [], "entities": []}, {"text": "Slot-features allow the appropriate modelling of predicate-argument structures for SRL.", "labels": [], "entities": [{"text": "SRL", "start_pos": 83, "end_pos": 86, "type": "TASK", "confidence": 0.9852455258369446}]}, {"text": "We also support the following additional semantic annotation types: participants and circumstances for event annotation, n-ary relations for relation extraction, and slot-filling tasks for information extraction.", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 141, "end_pos": 160, "type": "TASK", "confidence": 0.7509642541408539}, {"text": "information extraction", "start_pos": 189, "end_pos": 211, "type": "TASK", "confidence": 0.8296570479869843}]}, {"text": "2. Constraints help annotators by performing a context-sensitive filtering of the rich semantic tagsets.", "labels": [], "entities": []}, {"text": "For example, the sense of a semantic predicate determines available argument roles.", "labels": [], "entities": []}, {"text": "Such a filtering is necessary to avoid loosing valuable time by having annotators search through a large number of tags or to manually type in tags.", "labels": [], "entities": []}, {"text": "Constraint rules can be defined manually or they can be automatically generated, e.g. from machine-readable lexical resources.", "labels": [], "entities": []}, {"text": "To our knowledge, there is no other web-based annotation tool offering a comparable functionality.", "labels": [], "entities": []}, {"text": "3. An improved annotation interface fora streamlined annotation process using a permanently visible sidebar instead of a pop-up dialog for editing annotations and their features.", "labels": [], "entities": []}, {"text": "These new functionalities integrate well with the existing functionalities in WebAnno 2, in particular its support for the annotation of syntactic structures, thus enabling semantic annotation in coordination with syntactic annotation.", "labels": [], "entities": []}, {"text": "To our knowledge, WebAnno 3 is presently the only web-based and team-oriented annotation tool to support both, the annotation of semantic as well as syntactic structures.", "labels": [], "entities": []}, {"text": "This includes, but is not limited to the tools mentioned in Section 2.", "labels": [], "entities": []}, {"text": "WebAnno 3 was developed and implemented in close coordination with users in the context of an annotation project (cf.) for word sense disambiguation (WSD) and SRL on German texts and driven by its practical requirements.", "labels": [], "entities": [{"text": "word sense disambiguation (WSD)", "start_pos": 123, "end_pos": 154, "type": "TASK", "confidence": 0.7789872735738754}]}, {"text": "SRL is the task of identifying semantic predicates, their arguments, and assigning roles to these arguments.", "labels": [], "entities": [{"text": "SRL", "start_pos": 0, "end_pos": 3, "type": "TASK", "confidence": 0.9553391933441162}]}, {"text": "It is a difficult task usually performed by experts.", "labels": [], "entities": []}, {"text": "Examples of well-known SRL schemes motivated by different linguistic theories are FrameNet (),), and VerbNet).", "labels": [], "entities": [{"text": "SRL", "start_pos": 23, "end_pos": 26, "type": "TASK", "confidence": 0.9808835983276367}]}, {"text": "SRL annotation is typically based on syntactic structures obtained from treebanks, such as the constituent-based Penn Treebank (for PropBank annotation), or the German TIGER treebank for FrameNet-style annotation).", "labels": [], "entities": [{"text": "SRL annotation", "start_pos": 0, "end_pos": 14, "type": "TASK", "confidence": 0.9248955845832825}, {"text": "Penn Treebank", "start_pos": 113, "end_pos": 126, "type": "DATASET", "confidence": 0.978494793176651}, {"text": "German TIGER treebank", "start_pos": 161, "end_pos": 182, "type": "DATASET", "confidence": 0.6021512945493063}]}, {"text": "An argument is typically identified by the span of its syntactic head or syntactic constituent.", "labels": [], "entities": []}, {"text": "For some annotation schemes (e.g. FrameNet), the task also includes WSD.", "labels": [], "entities": [{"text": "WSD", "start_pos": 68, "end_pos": 71, "type": "DATASET", "confidence": 0.5643029808998108}]}, {"text": "In this case, the sense label typically determines the available argument slots.", "labels": [], "entities": []}, {"text": "The example below shows an annotation using FrameNet; the predicate ask receives the frame label Questioning (corresponding to its word sense) and its arguments are annotated as Addressee, Speaker, Message, and Iterations: Fred Role:Addressee didn't answer.", "labels": [], "entities": []}, {"text": "(2) While I Role:Speaker had asked Frame:Questioning this question Role:Message twice Role:Iterations before.", "labels": [], "entities": []}, {"text": "Note that there are multiple interdependencies between annotations involved here.", "labels": [], "entities": []}, {"text": "E.g. the available sense labels for the semantic predicate depend on its lemma.", "labels": [], "entities": []}, {"text": "Also, the available argument roles depend on the sense label.", "labels": [], "entities": []}, {"text": "We further describe the annotation project and the application of WebAnno 3 within the project in Section 4.", "labels": [], "entities": []}, {"text": "While joint WSD and SRL annotations are conveniently supported and facilitated using constraints, they can also be performed separately and independently of one another.", "labels": [], "entities": [{"text": "WSD and SRL annotations", "start_pos": 12, "end_pos": 35, "type": "TASK", "confidence": 0.5440628752112389}]}], "datasetContent": [{"text": "After the development has been finalised, we conducted a comparative evaluation study in order to measure whether our efforts in tool engineering translate into annotation time speedups, which directly influences annotation cost.", "labels": [], "entities": [{"text": "annotation time speedups", "start_pos": 161, "end_pos": 185, "type": "METRIC", "confidence": 0.76621013879776}]}, {"text": "For this, we chose the following setup: an annotator was presented with a static display of gold standard predicate-argument annotations like the ones shown in.", "labels": [], "entities": []}, {"text": "In this way, we minimise fluctuations caused by cognitive load for choosing the right labels, simulating a maximally trained annotator.", "labels": [], "entities": []}, {"text": "The annotator had ample experience with both the annotation tools, but not with the specific settings.", "labels": [], "entities": []}, {"text": "Thus, for each setting, the annotator became familiar with the setup on a small training document.", "labels": [], "entities": []}, {"text": "We conducted this annotation in three different settings: a) using WebAnno 2 (version 2.3.1), modelling the annotation task as outlined in Section 2.1, b) using WebAnno 3 without constraints and c) using WebAnno 3 with constraints for rules that re-order semantic predicates according to the lemma value, as exemplified in.", "labels": [], "entities": []}, {"text": "To avoid interpersonal differences in annotation speed, the same annotator worked on all three settings.", "labels": [], "entities": []}, {"text": "The data set on which time was measured included four documents with a total of 64 semantic predicates, filling a total of 115 slots with overall 94 semantic arguments (SemArg in).", "labels": [], "entities": []}, {"text": "Note that the same semantic argument can fill slots of different predicates.", "labels": [], "entities": []}, {"text": "shows the times in minutes and seconds measured for the four documents.", "labels": [], "entities": []}, {"text": "The improvements of the user interface insetting b) already results in a speedup of about 23% less time compared to WebAnno 2.", "labels": [], "entities": [{"text": "speedup", "start_pos": 73, "end_pos": 80, "type": "METRIC", "confidence": 0.967829167842865}]}, {"text": "In combination with constraints, a speedup of over 34% is reached insetting c), meaning that the same annotator can produce 50% more annotations in the same time.", "labels": [], "entities": []}, {"text": "The annotator reported that she needed to perform considerably fewer interactions insetting c).", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Annotation times in minutes:seconds for WebAnno 2 and 3 with and without constraints.", "labels": [], "entities": [{"text": "Annotation", "start_pos": 10, "end_pos": 20, "type": "METRIC", "confidence": 0.9796072244644165}]}]}