{"title": [{"text": "Ranking Automatically Generated Questions Using Common Human Queries", "labels": [], "entities": []}], "abstractContent": [{"text": "In this paper, we challenge a form of paragraph-to-question generation task.", "labels": [], "entities": [{"text": "paragraph-to-question generation task", "start_pos": 38, "end_pos": 75, "type": "TASK", "confidence": 0.8155040740966797}]}, {"text": "We propose a question generation system which can generate a set of comprehensive questions from a body of text.", "labels": [], "entities": [{"text": "question generation", "start_pos": 13, "end_pos": 32, "type": "TASK", "confidence": 0.7622028589248657}]}, {"text": "Besides the tree kernel functions to assess the grammatically of the generated questions, our goal is to rank them by using community-based question answering systems to calculate the importance of the generated questions.", "labels": [], "entities": []}, {"text": "The main assumption behind our work is that each body of text is related to a topic of interest and it has a comprehensive information about the topic.", "labels": [], "entities": []}], "introductionContent": [{"text": "Human beings are not very good at asking questions about topics.", "labels": [], "entities": []}, {"text": "They are often forgetful, which causes difficulties in expressing what is in their minds.", "labels": [], "entities": []}, {"text": "Also sometimes, Humans, in front of a search engine, have difficulties to express their needs and intents as query terms.", "labels": [], "entities": []}, {"text": "Imagine that you want to find out what was the first logo for Apple Inc.", "labels": [], "entities": []}, {"text": "You may use a search engine such as Google and the search query Apple Logos, the result might have the exact information that you need.", "labels": [], "entities": [{"text": "Apple Logos", "start_pos": 64, "end_pos": 75, "type": "DATASET", "confidence": 0.9069251716136932}]}, {"text": "However, they may also include other information, such as who designed the logo or where it was designed or any other information that you are not interested in.", "labels": [], "entities": []}, {"text": "We believe if before showing the list of websites the search engine had shown some suggested queries you would benefit from this question generation (QG) system.", "labels": [], "entities": []}, {"text": "This way search engines' users will be able to use right queries to gain what they are looking for.", "labels": [], "entities": []}, {"text": "Suggestions could be questions like: What is the logo of Apple Inc.?", "labels": [], "entities": []}, {"text": "What was the first logo designed for Apple Inc.?", "labels": [], "entities": []}, {"text": "Do we have any information about where Apple's logo was designed?", "labels": [], "entities": [{"text": "Apple's logo", "start_pos": 39, "end_pos": 51, "type": "DATASET", "confidence": 0.8918675978978475}]}, {"text": "In this paper, we address the challenge of generating questions from topics, which is motivated by the fact that people do not always obtain the desired results from search engines.", "labels": [], "entities": []}, {"text": "In this task, we assume that for each search-engine user's query there is a body of text having useful information about it.", "labels": [], "entities": []}, {"text": "Our goal is to generate and show a few questions to the user in order to help her/him to find exactly what she/he is looking for.", "labels": [], "entities": []}, {"text": "We need to rank the questions because the number of generated questions could be many to be shown and we may have to show only top-ranked ones.", "labels": [], "entities": []}, {"text": "We generate the questions fora given topic in two steps.", "labels": [], "entities": []}, {"text": "First, we tag the name entities in the topic and its associated body.", "labels": [], "entities": []}, {"text": "Then, we apply some general rules and generate the basic questions.", "labels": [], "entities": []}, {"text": "At this level, the answers for the basic questions may not be in the body of the text, but the reason of generating them is to have more variety.", "labels": [], "entities": []}, {"text": "Second, we use predicates and their arguments from the sentences in the given body of text to generate specific questions, which answers can be generated from the text.", "labels": [], "entities": []}, {"text": "As the number of generated questions maybe too large we rank them and show the top ones to the users.", "labels": [], "entities": []}, {"text": "The ranking of question consists of two steps.", "labels": [], "entities": []}, {"text": "First, we investigate other questions being asked by people in community-based question answering (CQA) systems such as Yahoo!", "labels": [], "entities": [{"text": "community-based question answering (CQA)", "start_pos": 63, "end_pos": 103, "type": "TASK", "confidence": 0.8155092000961304}]}, {"text": "Answers to see how common our questions are.", "labels": [], "entities": []}, {"text": "Second, we apply the tree kernel functions in order to compute the syntactic similarity 217 between each question and the text from which the question is generated.", "labels": [], "entities": [{"text": "syntactic similarity 217", "start_pos": 67, "end_pos": 91, "type": "METRIC", "confidence": 0.7305620114008585}]}, {"text": "This way we can determine the correctness of the grammatically of the generated questions.", "labels": [], "entities": []}, {"text": "Then, the questions are ranked by their importance and grammatical correctness.", "labels": [], "entities": []}], "datasetContent": [{"text": "Our methodology to evaluate the performance of our automated question generation system is inspired by.", "labels": [], "entities": [{"text": "question generation", "start_pos": 61, "end_pos": 80, "type": "TASK", "confidence": 0.7033659964799881}]}, {"text": "Three unknown native English speakers were chosen to judge the result of our system.", "labels": [], "entities": []}, {"text": "They were asked to score the generated questions according to two criteria: syntactic correctness and topic relevance.", "labels": [], "entities": []}, {"text": "Judges give scores between 1 (very poor) and 5 (very good).", "labels": [], "entities": []}, {"text": "There were four scores for each generated question.", "labels": [], "entities": []}, {"text": "To evaluate the topic relevance criterion, judges were given three aspects, and they score each question according to each aspect.", "labels": [], "entities": []}, {"text": "Aspects were: 1) questions' semantic correctness 2) question type correctness and 3) clarity of referential.", "labels": [], "entities": [{"text": "clarity", "start_pos": 85, "end_pos": 92, "type": "METRIC", "confidence": 0.9934948086738586}]}, {"text": "For syntactic correctness, they score the generated questions considering if they are grammatically corrector not.", "labels": [], "entities": [{"text": "syntactic correctness", "start_pos": 4, "end_pos": 25, "type": "TASK", "confidence": 0.7615818083286285}]}, {"text": "Then the average of the judges' scores is calculated for each question.", "labels": [], "entities": []}, {"text": "To evaluate our system, we compare it with the state-of-the-art question generation system proposed by.", "labels": [], "entities": [{"text": "question generation", "start_pos": 64, "end_pos": 83, "type": "TASK", "confidence": 0.6973432004451752}]}, {"text": "To do so, we use a publicly available question generation system by Heilman and Smith (2010a) as a benchmark.", "labels": [], "entities": [{"text": "question generation", "start_pos": 38, "end_pos": 57, "type": "TASK", "confidence": 0.7342012822628021}]}, {"text": "In our evaluation, we generated the questions from 20 randomly chosen texts and then select the top 10 ranked questions.", "labels": [], "entities": []}, {"text": "We also generate the questions for the same texts by question generation toolkit and again select top 10 ranked ones.", "labels": [], "entities": []}, {"text": "The human judges were presented with 20 questions per text, top 10 from our system and top 10 from the system proposed by.", "labels": [], "entities": []}, {"text": "We have 20 texts for the total number of 400 questions for each judge.", "labels": [], "entities": []}, {"text": "After comparing our system with Heilman and Smith (2010a) system, we calculate our system advancement in comparison with the one created by. lists the average of syntactic correctness and topic relevance scores for each system.", "labels": [], "entities": [{"text": "advancement", "start_pos": 90, "end_pos": 101, "type": "METRIC", "confidence": 0.9079523682594299}]}, {"text": "These results confirm that our proposed automated question generation system outperforms the Heilman and Smith system (2010a) by 29.39%, and 18.71%, and over the Chali and Hasan system (2015) by 25.38%, and 14.04%, respectively.", "labels": [], "entities": [{"text": "question generation", "start_pos": 50, "end_pos": 69, "type": "TASK", "confidence": 0.7313142120838165}]}, {"text": "In this paper, we have shown that by using semantic similarity between a topic of interest and a group of pre-asked questions we can extract related ones to the concept of the topic and then we can use them to find the importance of anew generated question.", "labels": [], "entities": []}], "tableCaptions": []}