{"title": [{"text": "A Framework for Discriminative Rule Selection in Hierarchical Moses", "labels": [], "entities": [{"text": "Discriminative Rule Selection", "start_pos": 16, "end_pos": 45, "type": "TASK", "confidence": 0.6117436091105143}]}], "abstractContent": [{"text": "Training discriminative rule selection models is usually expensive because of the very large size of the hierarchical grammar.", "labels": [], "entities": []}, {"text": "Previous approaches reduced the training costs either by (i) using models that are local to the source side of the rules or (ii) by heavily pruning out negative samples.", "labels": [], "entities": []}, {"text": "Moreover, all previous evaluations were performed on small scale translation tasks, containing at most 250,000 sentence pairs.", "labels": [], "entities": []}, {"text": "We propose two contributions to discriminative rule selection.", "labels": [], "entities": [{"text": "rule selection", "start_pos": 47, "end_pos": 61, "type": "TASK", "confidence": 0.6813763380050659}]}, {"text": "First, we test previous approaches on two French-English translation tasks in domains for which only limited resources are available and show that they fail to improve translation quality.", "labels": [], "entities": [{"text": "French-English translation tasks", "start_pos": 42, "end_pos": 74, "type": "TASK", "confidence": 0.7261077165603638}]}, {"text": "To improve on such tasks, we propose a rule selection model that is (i) global with rich label-dependent features (ii) trained with all available negative samples.", "labels": [], "entities": [{"text": "rule selection", "start_pos": 39, "end_pos": 53, "type": "TASK", "confidence": 0.807577520608902}]}, {"text": "Our global model yields significant improvements, up to 1 BLEU point, over previously proposed rule selection models.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 58, "end_pos": 62, "type": "METRIC", "confidence": 0.9993958473205566}, {"text": "rule selection", "start_pos": 95, "end_pos": 109, "type": "TASK", "confidence": 0.8093585073947906}]}, {"text": "Second, we successfully scale rule selection models to large translation tasks but have so far failed to produce significant improvements in BLEU on these tasks.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 141, "end_pos": 145, "type": "METRIC", "confidence": 0.9981377124786377}]}], "introductionContent": [{"text": "Hierarchical phrase-based machine translation) performs non-local reordering in a formally syntax-based way.", "labels": [], "entities": [{"text": "Hierarchical phrase-based machine translation", "start_pos": 0, "end_pos": 45, "type": "TASK", "confidence": 0.5563032552599907}]}, {"text": "It allows flexible rule extraction and application by using a grammar without linguistic annotation.", "labels": [], "entities": [{"text": "rule extraction", "start_pos": 19, "end_pos": 34, "type": "TASK", "confidence": 0.7317517548799515}]}, {"text": "As a consequence, many hierarchical rules can be used to translate a given input segment even though only a subset of these yield a correct translation.", "labels": [], "entities": []}, {"text": "For instance, rules r 1 tor 3 can be applied to translate the French sentence F 1 below although only r 1 yields the correct translation E.", "labels": [], "entities": []}, {"text": "Models that use the syntactic structure of the source and target sentence have been proposed by).", "labels": [], "entities": []}, {"text": "These approaches exclusively take into account syntactic structure and do not model rule selection (see Section 6 fora detailed discussion).", "labels": [], "entities": [{"text": "rule selection", "start_pos": 84, "end_pos": 98, "type": "TASK", "confidence": 0.7048250138759613}]}, {"text": "Following the work on phrase-sense disambiguation by, other authors improve rule selection by defining features on the structure of hierarchical rules and combining these with information about the source sentence (.", "labels": [], "entities": [{"text": "phrase-sense disambiguation", "start_pos": 22, "end_pos": 49, "type": "TASK", "confidence": 0.7354623973369598}, {"text": "rule selection", "start_pos": 76, "end_pos": 90, "type": "TASK", "confidence": 0.7199534475803375}]}, {"text": "In these approaches, rule selection is the task of selecting the target side of a rule given its source side as well as contextual information about the source sentence.", "labels": [], "entities": [{"text": "rule selection", "start_pos": 21, "end_pos": 35, "type": "TASK", "confidence": 0.8264335989952087}]}, {"text": "This task is modeled as a multiclass classification problem.", "labels": [], "entities": [{"text": "multiclass classification", "start_pos": 26, "end_pos": 51, "type": "TASK", "confidence": 0.6880021542310715}]}, {"text": "Because of the very large size of hierarchical grammars, the training procedure for discriminative rule selection models is typically very expensive: multiclass classification is performed over millions of classes (one for each possible target side of a hierarchical rule).", "labels": [], "entities": [{"text": "multiclass classification", "start_pos": 150, "end_pos": 175, "type": "TASK", "confidence": 0.7075752466917038}]}, {"text": "To overcome this problem, previous approaches reduced the training costs by either (i) using models that are local to the source side of hierarchical rules or (ii) heavily pruning out negative samples from the training data.) train one (local) classifier for each source side or pattern of hierarchical rules instead of defining a (global) model overall rules.", "labels": [], "entities": []}, {"text": "train global models but in addition to rule table pruning, they heavily prune out negative instances.", "labels": [], "entities": []}, {"text": "Finally, in all previous approaches, a small amount of fixed features is used for training and prediction.", "labels": [], "entities": [{"text": "prediction", "start_pos": 95, "end_pos": 105, "type": "TASK", "confidence": 0.9535081386566162}]}, {"text": "While previous approaches have been shown to work on a small 1 English-Chinese news translation task, we show (in Section 4) that on FrenchEnglish tasks on domains for which only a limited amount of training data is available (which we call low resource tasks), they fail to improve over a hierarchical baseline.", "labels": [], "entities": [{"text": "English-Chinese news translation task", "start_pos": 63, "end_pos": 100, "type": "TASK", "confidence": 0.7451004683971405}]}, {"text": "This failure is caused by the fact that the models proposed so far do not take advantage of all information available in the training data.", "labels": [], "entities": []}, {"text": "Local models prevent feature sharing between rules with different source sides or patterns (see Section 2.3) while aggressive pruning removes important information from the training data (see Section 3.2).", "labels": [], "entities": []}, {"text": "On low resource translation tasks, this loss hurts translation quality.", "labels": [], "entities": []}, {"text": "Moreover, the small set of features used in previous work does not provide a representation of the training data that is as powerful as it could be for classification (see Section 2.2).", "labels": [], "entities": [{"text": "classification", "start_pos": 152, "end_pos": 166, "type": "TASK", "confidence": 0.9603126049041748}]}, {"text": "We improve on previous work in two ways.", "labels": [], "entities": []}, {"text": "First, we define a global rule selection model with a rich set of feature combinations.", "labels": [], "entities": []}, {"text": "Our global model enables feature sharing while the large amount of features we use offers a complete representation of the available training data.", "labels": [], "entities": []}, {"text": "We train our model with all acquired training examples.", "labels": [], "entities": []}, {"text": "The exhaustive training of a feature rich global model allows us to take full advantage of the training data.", "labels": [], "entities": []}, {"text": "We show on two low-resource FrenchEnglish translation tasks that local and pruned models often fail to improve over a hierarchical baseline while our global model with exhaustive training yields significant improvements on scientific and medical texts (see Section 4).", "labels": [], "entities": [{"text": "FrenchEnglish translation", "start_pos": 28, "end_pos": 53, "type": "TASK", "confidence": 0.7032729983329773}]}, {"text": "Ina second contribution, we successfully scale rule selection models to large scale translation tasks but fail to produce significant improvements in BLEU over a hierarchical baseline on these tasks.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 150, "end_pos": 154, "type": "METRIC", "confidence": 0.9973684549331665}]}, {"text": "Because our approach needs scaling to a large amount of training examples, we need a classifier that is fast and supports online streaming.", "labels": [], "entities": []}, {"text": "We use the high-speed classifier Vowpal Wabbit 2 (VW) which we fully integrate in the syntax component) of the Moses machine translation toolkit (.", "labels": [], "entities": [{"text": "Vowpal Wabbit 2 (VW)", "start_pos": 33, "end_pos": 53, "type": "METRIC", "confidence": 0.6764685263236364}]}, {"text": "To allow researchers to replicate our results and improve on our work, we make our implementation publicly available as part of Moses.", "labels": [], "entities": []}], "datasetContent": [{"text": "Ina first set of experiments, we evaluate our approach on two low resource French-English trans- lation tasks: (i) a set of scientific articles and (ii) a set of biomedical texts.", "labels": [], "entities": [{"text": "trans- lation", "start_pos": 90, "end_pos": 103, "type": "TASK", "confidence": 0.6273187299569448}]}, {"text": "As these data sets cover small domains, they allow us to investigate the usefulness of our approach in this context.", "labels": [], "entities": []}, {"text": "The goal of our experiments is to verify three hypotheses: h 1 Our approach beats a hierarchical baseline.", "labels": [], "entities": []}, {"text": "h 2 Our global model outperforms its local variants.", "labels": [], "entities": []}, {"text": "h 3 Our exhaustive training procedure beats systems trained with pruned data.", "labels": [], "entities": [{"text": "exhaustive", "start_pos": 8, "end_pos": 18, "type": "METRIC", "confidence": 0.9424740672111511}]}, {"text": "Our scientific data consists of the scientific abstracts provided by We train the model in the standard way, using GIZA++.", "labels": [], "entities": []}, {"text": "After training, we reduce the number of translation rules using significance testing.", "labels": [], "entities": []}, {"text": "For feature extraction, we parse the French part of our training data using the Berkeley parser () and lemmatize and POS tag it using Morfette (.", "labels": [], "entities": [{"text": "feature extraction", "start_pos": 4, "end_pos": 22, "type": "TASK", "confidence": 0.836794912815094}]}, {"text": "We train the rule-selection model using VW.", "labels": [], "entities": [{"text": "VW", "start_pos": 40, "end_pos": 42, "type": "DATASET", "confidence": 0.8985019326210022}]}, {"text": "All systems are tuned using batch MIRA.", "labels": [], "entities": [{"text": "MIRA", "start_pos": 34, "end_pos": 38, "type": "METRIC", "confidence": 0.9562904834747314}]}, {"text": "We measure the overall translation quality using 4-gram BLEU (), which is computed on tokenized and lowercased data for all systems.", "labels": [], "entities": [{"text": "translation", "start_pos": 23, "end_pos": 34, "type": "TASK", "confidence": 0.9589077830314636}, {"text": "BLEU", "start_pos": 56, "end_pos": 60, "type": "METRIC", "confidence": 0.9933406710624695}]}, {"text": "Statistical significance is computed with the pairwise bootstrap resampling technique of).", "labels": [], "entities": []}, {"text": "Ina second set of experiments, we evaluate the usefulness of our approach on two large scale translation tasks: (i) a French-to-English news translation task trained on 1,500,000 parallel sentences and (ii) an English-to-Romanian news translation task trained on 600,000 parallel sentences.", "labels": [], "entities": [{"text": "French-to-English news translation task", "start_pos": 118, "end_pos": 157, "type": "TASK", "confidence": 0.6524819880723953}, {"text": "English-to-Romanian news translation task", "start_pos": 210, "end_pos": 251, "type": "TASK", "confidence": 0.7217225357890129}]}, {"text": "The training data for the first task consists of the French-English part of the Europarlv4 corpus.", "labels": [], "entities": [{"text": "Europarlv4 corpus", "start_pos": 80, "end_pos": 97, "type": "DATASET", "confidence": 0.9910823702812195}]}, {"text": "Development and test sets are from the French-to-English news translation task of WMT 2009).", "labels": [], "entities": [{"text": "French-to-English news translation task", "start_pos": 39, "end_pos": 78, "type": "TASK", "confidence": 0.6554837375879288}, {"text": "WMT 2009", "start_pos": 82, "end_pos": 90, "type": "DATASET", "confidence": 0.8326142132282257}]}, {"text": "For the second task, we use the English-Romanian part of the Europarl-v8 corpus.", "labels": [], "entities": [{"text": "Europarl-v8 corpus", "start_pos": 61, "end_pos": 79, "type": "DATASET", "confidence": 0.9649852216243744}]}, {"text": "Development and test sets are from the English-to-Romanian news translation task of WMT 2016.", "labels": [], "entities": [{"text": "English-to-Romanian news translation", "start_pos": 39, "end_pos": 75, "type": "TASK", "confidence": 0.6475425561269125}, {"text": "WMT 2016", "start_pos": 84, "end_pos": 92, "type": "DATASET", "confidence": 0.7887228429317474}]}, {"text": "The setup of these experiments is the same as described in Section 4.1 except for the language model of the Englishto-Romanian task, which was trained using lmplz   Our goal is to verify if on large scale translation tasks our global rule selection model outperforms a hierarchical baseline (hypothesis h 1 above).", "labels": [], "entities": []}, {"text": "The results, given in, show that on large scale tasks, rule selection models with syntactic features yield small improvements over the hierarchical baseline.", "labels": [], "entities": []}, {"text": "However, none of these is statistically significant.", "labels": [], "entities": []}, {"text": "Hence hypothesis h 1 does not hold on large domains.) improve hierarchical machine translation by augmenting the translation model with fine-grained syntactic features of the source sentence.", "labels": [], "entities": [{"text": "hierarchical machine translation", "start_pos": 62, "end_pos": 94, "type": "TASK", "confidence": 0.6178874870141348}]}, {"text": "The used features reward rules that match syntactic constituents and punish non-matching rules.", "labels": [], "entities": []}, {"text": "() integrate these features into a translation model containing a large number of other features such as discount or insertion features.) extends the approach in by also including syntactic information of the target sentence that is built during decoding while () define a discriminative model over source side constituent labels instead of rewarding matching constituents.", "labels": [], "entities": []}, {"text": "The training data for their model is based on source sentence derivations.", "labels": [], "entities": []}, {"text": "In contrast to this work, we define a rule selection model, i.e. a discriminative model on the target side of hierarchical rules.", "labels": [], "entities": []}, {"text": "The training data for our model is based on the hierarchical rule extraction procedure: we acquire training instances by labeling candidate rules extracted from the same sentence pairs.", "labels": [], "entities": [{"text": "hierarchical rule extraction", "start_pos": 48, "end_pos": 76, "type": "TASK", "confidence": 0.743305524190267}]}, {"text": "Similar to our work, ( ) define a discriminative rule selection model including lexical features, similar to the ones we presented in Section 2.2.", "labels": [], "entities": []}, {"text": "Their work bases on () which integrate a word sense disambiguation system into a hierarchical system.", "labels": [], "entities": [{"text": "word sense disambiguation system", "start_pos": 41, "end_pos": 73, "type": "TASK", "confidence": 0.7114348858594894}]}, {"text": "As opposed to ( , this work focuses on hierarchical rules containing only terminal symbols and having length 2.", "labels": [], "entities": []}, {"text": "These approaches train rule selection models that are local to the source side of hierarchical rules.", "labels": [], "entities": []}, {"text": "( generalize this work by defining a model that is local to source patterns instead of the source side of each rule.", "labels": [], "entities": []}, {"text": "We extend these approaches by defining a global model that generalizes to all rules instead of rules with the same source side or source pattern.", "labels": [], "entities": []}, {"text": "We also extend the feature set by defining models on syntactic features.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Number of training examples (Examp.)  The last line shows the average amount of negative  samples (avg 1) for each training example.", "labels": [], "entities": [{"text": "avg 1)", "start_pos": 109, "end_pos": 115, "type": "METRIC", "confidence": 0.9654374917348226}]}, {"text": " Table 2: Evaluation of global models against hi- erarchical baseline. The results in bold are statis- tically significant improvements over the Baseline  (at confidence p < 0.05).", "labels": [], "entities": []}, {"text": " Table 3: Evaluation of global models against local.  We use * to mark global systems that yield sta- tistically significant (at confidence p < 0.05) im- provements over their local variants. The results  in bold are statistically significant improvements  over the hierarchical baseline.", "labels": [], "entities": []}, {"text": " Table 4: Evaluation of global model against  pruned. The results in bold are statistically sig- nificant improvements over the Baseline (at confi- dence p < 0.05).", "labels": [], "entities": []}, {"text": " Table 5: Evaluation of large scale tasks. No signif- icant difference in performance between the eval- uated models.", "labels": [], "entities": []}]}