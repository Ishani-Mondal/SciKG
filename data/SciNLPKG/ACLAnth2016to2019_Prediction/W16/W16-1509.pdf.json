{"title": [{"text": "A Study of Reuse and Plagiarism in Speech and Natural Language Processing papers", "labels": [], "entities": []}], "abstractContent": [{"text": "The aim of this experiment is to present an easy way to compare fragments of texts in order to detect (supposed) results of copy & paste operations between articles in the domain of Natural Language Processing, including Speech Processing (NLP).", "labels": [], "entities": []}, {"text": "The search space of the comparisons is a corpus labelled as NLP4NLP, which includes 34 different sources and gathers a large part of the publications in the NLP field over the past 50 years.", "labels": [], "entities": [{"text": "NLP4NLP", "start_pos": 60, "end_pos": 67, "type": "DATASET", "confidence": 0.9389671087265015}]}, {"text": "This study considers the similarity between the papers of each individual source and the complete set of papers in the whole corpus, according to four different types of relationship (self-reuse, self-plagiarism, reuse and plagiarism) and in both directions: a source paper borrowing a fragment of text from another paper of the collection, or in the reverse direction, fragments of text from the source paper being borrowed and inserted in another paper of the collection.", "labels": [], "entities": []}], "introductionContent": [{"text": "Everything starts with a copy & paste and, of course the flood of documents that we see today could not exist without the practical ease of copy & paste.", "labels": [], "entities": []}, {"text": "This is not new but what is new is that the availability of archives allows us to study avast amount of papers in our domain (i.e. Natural Language Processing, NLP, both for written and spoken materials) and to figure out the level of reuse and plagiarism in this area.", "labels": [], "entities": []}], "datasetContent": [{"text": "Ina first implementation, we compared the raw character strings with a segmentation based on space and punctuation.", "labels": [], "entities": []}, {"text": "But, due to the fact that the input is the result of PDF formatting, the texts may contain variable caesura for line endings or some little textual variations.", "labels": [], "entities": []}, {"text": "Some rubbish sequence of characters (e.g. a series of hyphens) were also detected and cleaned.", "labels": [], "entities": []}, {"text": "Given that a parser takes all these variations and cleanings into account, we decided to apply a full linguistic parsing, as a second strategy.", "labels": [], "entities": [{"text": "linguistic parsing", "start_pos": 102, "end_pos": 120, "type": "TASK", "confidence": 0.6725187599658966}]}, {"text": "The syntactic structures and relations are ignored.", "labels": [], "entities": []}, {"text": "Then a module for entity linking is called in order to bind different names referring to the same entity, a process often labeled as \"entity linking\" in the . Thus \"British National Corpus\" is considered as possibly abbreviated to \"BNC\", as well as less regular names like \"ItalWordNet\" possibly abbreviated to \"IWN\".", "labels": [], "entities": [{"text": "entity linking", "start_pos": 18, "end_pos": 32, "type": "TASK", "confidence": 0.7304845154285431}, {"text": "British National Corpus\"", "start_pos": 165, "end_pos": 189, "type": "DATASET", "confidence": 0.9507050812244415}]}, {"text": "Each entry of the Knowledge Base has a canonical form, possibly associated with different variants: the aim is to normalize into a canonical form to neutralize proper noun obfuscations based on variant substitutions.", "labels": [], "entities": []}, {"text": "After this processing, only the sentences with at least a verb are considered.", "labels": [], "entities": []}, {"text": "We examined the differences between those two strategies concerning all types of copy & paste situations above the threshold, choosing the LREC source as the focus.", "labels": [], "entities": []}, {"text": "The results are presented in, with the last column adding the two other columns without the duplicates produced by the couples of the same year.", "labels": [], "entities": []}, {"text": "The strategy based on linguistic processing provides more pairs (+158) and we examined these differences.", "labels": [], "entities": []}, {"text": "Among these pairs, the vast majority (80%) concerns caesura: this is normal because most conferences demand a double column format, so the authors frequently use caesura to save place 13 . The other differences (20%) are mainly caused by lexical variations and spellchecking.", "labels": [], "entities": []}, {"text": "Thus, the results show that using raw texts gives a more \"silent\" system.", "labels": [], "entities": []}, {"text": "The drawback is that the computation is much longer 14 , but we think that it is worth the value.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1. Detail of NLP4NLP, with the convention that an asterisk indicates that the corpus is in the ACL Anthology.", "labels": [], "entities": [{"text": "ACL Anthology", "start_pos": 102, "end_pos": 115, "type": "DATASET", "confidence": 0.9562300741672516}]}, {"text": " Table 2. Comparison of the two strategies on the LREC corpus", "labels": [], "entities": [{"text": "LREC corpus", "start_pos": 50, "end_pos": 61, "type": "DATASET", "confidence": 0.9312364459037781}]}, {"text": " Table 3. Self-reuse and Self-Plagiarism Matrix, with indication of the 7 most using and used sources.", "labels": [], "entities": []}, {"text": " Table 4. Reuse and Plagiarism Matrix, with indication of the 5 most using and used sources", "labels": [], "entities": []}]}