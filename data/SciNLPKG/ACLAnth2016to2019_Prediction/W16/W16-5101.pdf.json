{"title": [{"text": "Cancer Hallmark Text Classification Using Convolutional Neural Networks", "labels": [], "entities": [{"text": "Cancer Hallmark Text Classification", "start_pos": 0, "end_pos": 35, "type": "TASK", "confidence": 0.7473020851612091}]}], "abstractContent": [{"text": "Methods based on deep learning approaches have recently achieved state-of-the-art performance in a range of machine learning tasks and are increasingly applied to natural language processing (NLP).", "labels": [], "entities": [{"text": "natural language processing (NLP)", "start_pos": 163, "end_pos": 196, "type": "TASK", "confidence": 0.754666268825531}]}, {"text": "Despite strong results in various established NLP tasks involving general domain texts, there is only limited work applying these models to biomedical NLP.", "labels": [], "entities": []}, {"text": "In this paper, we consider a Convolutional Neural Network (CNN) approach to biomedical text classification.", "labels": [], "entities": [{"text": "biomedical text classification", "start_pos": 76, "end_pos": 106, "type": "TASK", "confidence": 0.689018984635671}]}, {"text": "Evaluation using a recently introduced cancer domain dataset involving the categorization of documents according to the well-established hallmarks of cancer shows that a basic CNN model can achieve a level of performance competitive with a Support Vector Machine (SVM) trained using complex manually engineered features optimized to the task.", "labels": [], "entities": []}, {"text": "We further show that simple modifications to the CNN hyperparameters, initialization, and training process allow the model to notably outperform the SVM, establishing anew state of the art result at this task.", "labels": [], "entities": [{"text": "initialization", "start_pos": 70, "end_pos": 84, "type": "TASK", "confidence": 0.9580719470977783}]}, {"text": "We make all of the resources and tools introduced in this study available under open licenses from https://cambridgeltl.github.io/cancer-hallmark-cnn/ .", "labels": [], "entities": []}], "introductionContent": [{"text": "A major goal of cancer research is to understand the biological mechanisms involved in tumorous growths starting in the body, being sustained, and turning malignant.", "labels": [], "entities": []}, {"text": "Cancer is often described in the biomedical literature by its hallmarks; a set of interrelated biological properties and behaviors that enable cancer to thrive in the body.", "labels": [], "entities": []}, {"text": "The hallmarks of cancer were first introduced in the seminal paper of, the most cited paper in the journal Cell.", "labels": [], "entities": []}, {"text": "The paper introduces six hallmarks, which were then extended in a follow-up paper () by another four, forming the set often hallmarks that are known today.", "labels": [], "entities": []}, {"text": "The current set of hallmarks distill our knowledge of the disease into a fixed set of alterations in cell physiology that affect malignant growth, such as self-sufficiency in growth signals, insensitivity to growth-inhibitors, evasion of programmed cell death, limitless replicative potential, sustained angiogenesis, and tissue invasion.", "labels": [], "entities": []}, {"text": "In the context of biomedical text mining, the original six hallmarks of cancer were used as an organizing principle in the BioNLP Shared Task 2013 Cancer Genetics task (), which involved the extraction of events (biological processes) from cancer domain texts.", "labels": [], "entities": [{"text": "biomedical text mining", "start_pos": 18, "end_pos": 40, "type": "TASK", "confidence": 0.6311799089113871}, {"text": "BioNLP Shared Task 2013 Cancer Genetics task", "start_pos": 123, "end_pos": 167, "type": "DATASET", "confidence": 0.6798056874956403}, {"text": "extraction of events (biological processes) from cancer domain texts", "start_pos": 191, "end_pos": 259, "type": "TASK", "confidence": 0.6698715144937689}]}, {"text": "The hallmarks have also inspired other information extraction efforts and the development of tools such as OncoSearch ( and.", "labels": [], "entities": [{"text": "information extraction", "start_pos": 39, "end_pos": 61, "type": "TASK", "confidence": 0.8488397896289825}]}, {"text": "In recent work, introduced a corpus comprised of over 1,800 abstracts from biomedical publications annotated with the ten hallmarks of cancer.", "labels": [], "entities": []}, {"text": "Baker et al. also proposed a machine learning based method for classifying text according to the hallmarks.", "labels": [], "entities": []}, {"text": "The approach utilizes a conventional NLP pipeline that extracts a feature-rich representation that is used to train support vector machine (SVM) classifiers.", "labels": [], "entities": []}, {"text": "The method achieves a respectable level of performance, identifying hallmarks with an average F-score of 77%, but with the cost of involving a lengthy and computationally demanding NLP pipeline.", "labels": [], "entities": [{"text": "F-score", "start_pos": 94, "end_pos": 101, "type": "METRIC", "confidence": 0.9991119503974915}]}, {"text": "In this work, our focus is on studying biomedical text classification using machine learning methods that emphasize feature learning rather than manual feature engineering.", "labels": [], "entities": [{"text": "biomedical text classification", "start_pos": 39, "end_pos": 69, "type": "TASK", "confidence": 0.6418767273426056}]}, {"text": "We adopt the task setting and dataset of, but instead of SVMs, we focus on convolutional neural networks (CNN).", "labels": [], "entities": []}, {"text": "CNNs were first proposed for image processing ( and have been recently shown to achieve state-of-the-art performance in a range of NLP tasks, in particular in text classification (.", "labels": [], "entities": [{"text": "image processing", "start_pos": 29, "end_pos": 45, "type": "TASK", "confidence": 0.821181058883667}, {"text": "text classification", "start_pos": 159, "end_pos": 178, "type": "TASK", "confidence": 0.8268232047557831}]}, {"text": "While neural network-based methods in general and \"deep\" networks in particular are increasingly popular for general domain NLP, there has been comparatively little work applying this class of methods to biomedical text.", "labels": [], "entities": [{"text": "general domain NLP", "start_pos": 109, "end_pos": 127, "type": "TASK", "confidence": 0.579243004322052}]}, {"text": "One recent study applying a CNN model to biomedical text classification task was presented by, who applied CNNs to the task of adverse drug reaction detection in social media messages ().", "labels": [], "entities": [{"text": "biomedical text classification task", "start_pos": 41, "end_pos": 76, "type": "TASK", "confidence": 0.691460095345974}, {"text": "adverse drug reaction detection in social media messages", "start_pos": 127, "end_pos": 183, "type": "TASK", "confidence": 0.7677558287978172}]}, {"text": "In addition to the specific subdomain of the source texts and the novel categories represented by the hallmarks of cancer, one factor that sets apart the task here from this previous work is the length of the texts: instead of sentences or brief social media messages, our task involves the classification of publication abstracts typically consisting of hundreds of words.", "labels": [], "entities": []}], "datasetContent": [{"text": "Classifier performance is evaluated using the standard precision, recall, and F-score metrics as well as with the area under the receiver operating characteristic curve (AUC).", "labels": [], "entities": [{"text": "precision", "start_pos": 55, "end_pos": 64, "type": "METRIC", "confidence": 0.9993641972541809}, {"text": "recall", "start_pos": 66, "end_pos": 72, "type": "METRIC", "confidence": 0.9970845580101013}, {"text": "F-score", "start_pos": 78, "end_pos": 85, "type": "METRIC", "confidence": 0.9991139769554138}, {"text": "receiver operating characteristic curve (AUC)", "start_pos": 129, "end_pos": 174, "type": "METRIC", "confidence": 0.9011048248835972}]}, {"text": "Unlike precision and F-score, AUC is invariant to the positive/negative class distribution.", "labels": [], "entities": [{"text": "precision", "start_pos": 7, "end_pos": 16, "type": "METRIC", "confidence": 0.9995719790458679}, {"text": "F-score", "start_pos": 21, "end_pos": 28, "type": "METRIC", "confidence": 0.9932832717895508}, {"text": "AUC", "start_pos": 30, "end_pos": 33, "type": "METRIC", "confidence": 0.9522094130516052}]}, {"text": "AUC is also more sensitive in summarizing performance overall possible classification thresholds and eliminates the need to pick a specific threshold for evaluation.", "labels": [], "entities": [{"text": "AUC", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.616875410079956}]}, {"text": "AUC is therefore recommended for evaluating imbalanced datasets (.", "labels": [], "entities": [{"text": "AUC", "start_pos": 0, "end_pos": 3, "type": "METRIC", "confidence": 0.3971385359764099}]}, {"text": "As the dataset is comparatively small and the number of positive examples in particular is very limited for many labels, the random factors in CNN initialization and training can have a substantial effect on the resulting model.", "labels": [], "entities": [{"text": "CNN initialization", "start_pos": 143, "end_pos": 161, "type": "TASK", "confidence": 0.8725219070911407}]}, {"text": "To address this issue, we systematically repeated each CNN experiment 10 times and report the mean of the evaluation results.", "labels": [], "entities": []}, {"text": "To address overfitting in the CNN, we apply a form of early stopping, testing only the model that achieved the highest results on the development set.", "labels": [], "entities": []}, {"text": "In the development experiments, we correspondingly report the highest f-score and AUC from any epoch.", "labels": [], "entities": [{"text": "f-score", "start_pos": 70, "end_pos": 77, "type": "METRIC", "confidence": 0.9886608123779297}, {"text": "AUC", "start_pos": 82, "end_pos": 85, "type": "METRIC", "confidence": 0.9958655834197998}]}], "tableCaptions": [{"text": " Table 4: Comparison of test results using F-score", "labels": [], "entities": [{"text": "F-score", "start_pos": 43, "end_pos": 50, "type": "METRIC", "confidence": 0.9863807559013367}]}, {"text": " Table 5: Comparison of test results using AUC", "labels": [], "entities": [{"text": "AUC", "start_pos": 43, "end_pos": 46, "type": "TASK", "confidence": 0.5344389081001282}]}]}