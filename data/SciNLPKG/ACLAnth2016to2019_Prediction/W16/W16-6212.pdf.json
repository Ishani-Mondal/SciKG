{"title": [{"text": "Hierarchical Character-Word Models for Language Identification", "labels": [], "entities": [{"text": "Language Identification", "start_pos": 39, "end_pos": 62, "type": "TASK", "confidence": 0.7373530268669128}]}], "abstractContent": [{"text": "Social media messages' brevity and uncon-ventional spelling pose a challenge to language identification.", "labels": [], "entities": [{"text": "language identification", "start_pos": 80, "end_pos": 103, "type": "TASK", "confidence": 0.73500856757164}]}, {"text": "We introduce a hierarchical model that learns character and con-textualized word-level representations for language identification.", "labels": [], "entities": [{"text": "language identification", "start_pos": 107, "end_pos": 130, "type": "TASK", "confidence": 0.7153162509202957}]}, {"text": "Our method performs well against strong baselines, and can also reveal code-switching.", "labels": [], "entities": []}], "introductionContent": [{"text": "Language identification (language ID), despite being described as a solved problem more than ten years ago), remains a difficult problem.", "labels": [], "entities": [{"text": "Language identification (language ID)", "start_pos": 0, "end_pos": 37, "type": "TASK", "confidence": 0.846407026052475}]}, {"text": "Particularly when working with short texts, informal styles, or closely related language pairs, it is an active area of research (.", "labels": [], "entities": []}, {"text": "These difficult cases are often found in social media content.", "labels": [], "entities": []}, {"text": "Progress on language ID is needed especially since downstream tasks, like translation and semantic parsing, depend on correct language ID.", "labels": [], "entities": [{"text": "language ID", "start_pos": 12, "end_pos": 23, "type": "TASK", "confidence": 0.747301459312439}, {"text": "translation and semantic parsing", "start_pos": 74, "end_pos": 106, "type": "TASK", "confidence": 0.6356412246823311}]}, {"text": "This paper brings continuous representations for language data, which have produced new states of the art for language modeling, machine translation (, and other tasks, to language ID.", "labels": [], "entities": [{"text": "language modeling", "start_pos": 110, "end_pos": 127, "type": "TASK", "confidence": 0.7063934952020645}, {"text": "machine translation", "start_pos": 129, "end_pos": 148, "type": "TASK", "confidence": 0.7926585376262665}, {"text": "language ID", "start_pos": 172, "end_pos": 183, "type": "TASK", "confidence": 0.7308663576841354}]}, {"text": "We adapt a hierarchical character-word neural architecture from, demonstrating that it works well for language ID.", "labels": [], "entities": [{"text": "language ID", "start_pos": 102, "end_pos": 113, "type": "TASK", "confidence": 0.7246669679880142}]}, {"text": "Our model, which we call C2V2L (\"character to vector to language\") is hierarchical in the sense that it explicitly builds a continuous representation for each word from its character sequence, capturing orthographic and morphology-related patterns, and then combines those word level representations in context, finally classifying the full word sequence.", "labels": [], "entities": []}, {"text": "Our model does not require any special handling of casing or punctuation nor do we need to remove URLs, usernames, or hashtags, and it is trained end-to-end using standard procedures.", "labels": [], "entities": []}, {"text": "We demonstrate the model's state-of-the-art performance in experiments on two datasets consisting of tweets.", "labels": [], "entities": []}, {"text": "This hierarchical technique works well compared to classifiers using character or word n-gram features as well as a similar neural model that treats an entire tweet as a single character sequence.", "labels": [], "entities": []}, {"text": "We find further that the model can benefit from additional out-of-domain data, unlike much previous work, and with little modification can annotate word-level code-switching.", "labels": [], "entities": []}, {"text": "We also confirm that smoothed character n-gram language models perform very well for language ID tasks.", "labels": [], "entities": [{"text": "language ID tasks", "start_pos": 85, "end_pos": 102, "type": "TASK", "confidence": 0.8235857685407003}]}], "datasetContent": [{"text": "We consider two datasets: TweetLID and Twitter70.", "labels": [], "entities": [{"text": "Twitter70", "start_pos": 39, "end_pos": 48, "type": "DATASET", "confidence": 0.9259341955184937}]}, {"text": "Summary statistics for each of the datasets are provided in.", "labels": [], "entities": []}, {"text": "For all the studies below on language identification, we compare to two baselines: i) langid.py, a popular open-source language ID package, and ii) a classifier using n-gram character language models.", "labels": [], "entities": [{"text": "language identification", "start_pos": 29, "end_pos": 52, "type": "TASK", "confidence": 0.7153356075286865}]}, {"text": "For the TweetLID dataset, additional comparisons are included as described next.", "labels": [], "entities": [{"text": "TweetLID dataset", "start_pos": 8, "end_pos": 24, "type": "DATASET", "confidence": 0.9385602474212646}]}, {"text": "In addition, we test our model's word-level performance on a codeswitching dataset.", "labels": [], "entities": []}, {"text": "The first baseline, based on the langid.py package, uses a na\u00efve Bayes classifier over byte ngram features).", "labels": [], "entities": []}, {"text": "The pretrained model distributed with the package is designed to perform well on a wide range of domains, and achieved high performance on \"microblog messages\" (tweets) in the original paper.", "labels": [], "entities": []}, {"text": "langid.py uses feature selection for domain adaptation and to reduce the model size; thus, retraining it on indomain data as we do in this paper does not provide an entirely fair comparison.", "labels": [], "entities": [{"text": "langid.py", "start_pos": 0, "end_pos": 9, "type": "DATASET", "confidence": 0.9482524394989014}, {"text": "domain adaptation", "start_pos": 37, "end_pos": 54, "type": "TASK", "confidence": 0.7543776333332062}]}, {"text": "However, we include it for its popularity and importance.", "labels": [], "entities": []}, {"text": "The second baseline is built from character ngram language models.", "labels": [], "entities": []}, {"text": "It assigns each tweet according to language * = arg max p(tweet | ), i.e., applying Bayes' rule with a uniform class prior.", "labels": [], "entities": []}, {"text": "For TweetLID, the rare 'und' was handled with a rejection model.", "labels": [], "entities": []}, {"text": "Specifically, after * is chosen, a log likelihood ratio testis applied to decide whether to reject the decision in favor of the 'und' class, using the language models for * and 'und' with a threshold chosen to optimize F 1 on the development set.", "labels": [], "entities": [{"text": "F 1", "start_pos": 219, "end_pos": 222, "type": "METRIC", "confidence": 0.9794057905673981}]}, {"text": "The models were trained using WittenBell smoothing (), but otherwise the default parameters of the SRILM toolkit) were used.", "labels": [], "entities": []}, {"text": "5 N-gram model training ignores tweets labeled as ambiguous or containing multiple languages, and the unconstrained models use a simple interpolation of TweetLID and Wikipedia component models.", "labels": [], "entities": []}, {"text": "The n-gram order was chosen to minimize perplexity with 5-fold cross validation, yielding n=5 for TweetLID and Twitter70, and n=6 for Wikipedia.", "labels": [], "entities": [{"text": "Twitter70", "start_pos": 111, "end_pos": 120, "type": "DATASET", "confidence": 0.9097105264663696}]}, {"text": "Note that both of these baselines are generative, learning separate models for each language.", "labels": [], "entities": []}, {"text": "In contrast, the neural network models explored here are trained on all languages, so parameters maybe shared across languages.", "labels": [], "entities": []}, {"text": "In particular, a character sequence corresponding to a word in more than one language (e.g., \"no\" in English and Portuguese) has a language-independent word embedding.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Hyperparameter settings for selected models.", "labels": [], "entities": []}, {"text": " Table 3: F 1 scores on the TweetLID language ID task (constrained track), averaged and per language category (in- cluding undetermined and ambiguous). The scores for Hurtado et al. (2014) and Gamallo et al. (2014) are 75.2 and  75.6 respectively, as reported in Zubiaga et al. (2014); per-language scores are not available.", "labels": [], "entities": [{"text": "F 1", "start_pos": 10, "end_pos": 13, "type": "METRIC", "confidence": 0.9865588843822479}, {"text": "TweetLID language ID task", "start_pos": 28, "end_pos": 53, "type": "TASK", "confidence": 0.6949418783187866}]}, {"text": " Table 4: F 1 scores for the unconstrained data track of  the TweetLID language ID task. \u2206 measures change in  absolute F 1 score from the constrained condition.", "labels": [], "entities": [{"text": "F 1", "start_pos": 10, "end_pos": 13, "type": "METRIC", "confidence": 0.9873359799385071}, {"text": "TweetLID language ID task", "start_pos": 62, "end_pos": 87, "type": "TASK", "confidence": 0.6099931076169014}, {"text": "F 1 score", "start_pos": 120, "end_pos": 129, "type": "METRIC", "confidence": 0.9051153858502706}]}, {"text": " Table 5: Top seven most similar words from the training data and their cosine similarities for inputs \"couldn't\",  \"@maria_sanchez\", and \"noite\".", "labels": [], "entities": []}]}