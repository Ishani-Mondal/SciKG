{"title": [{"text": "Integrating WordNet for Multiple Sense Embeddings in Vector Semantics", "labels": [], "entities": []}], "abstractContent": [{"text": "Popular distributional approaches to semantics allow for only a single embedding of any particular word.", "labels": [], "entities": []}, {"text": "A single embedding per word conflates the distinct meanings of the word and their appropriate contexts , irrespective of whether those usages are related or completely disjoint.", "labels": [], "entities": []}, {"text": "We compare models that use the graph structure of the knowledge base WordNet as a post-processing step to improve vector-space models with multiple sense embed-dings for each word, and explore the application to word sense disambiguation.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 69, "end_pos": 76, "type": "DATASET", "confidence": 0.8860982656478882}, {"text": "word sense disambiguation", "start_pos": 212, "end_pos": 237, "type": "TASK", "confidence": 0.6857493817806244}]}], "introductionContent": [{"text": "Vector semantics is a computational model of written language that encodes the usage of words in a vector space, which facilitates performing mathematical manipulations on words as vectors.", "labels": [], "entities": [{"text": "Vector semantics", "start_pos": 0, "end_pos": 16, "type": "TASK", "confidence": 0.7085198760032654}]}, {"text": "These vectors encode the contexts of words across a corpus, and are learned based on word distributions throughout the text.", "labels": [], "entities": []}, {"text": "Vectors can then be compared by various distance metrics, usually the cosine function, to determine the similarity of the underlying words.", "labels": [], "entities": []}, {"text": "They also seem to possess some modest degree of compositionality, in the sense that the addition and subtraction of vectors can sometimes result in equations that appear to reflect semantically meaningful relationships between words).", "labels": [], "entities": []}, {"text": "Because it allows for the use of these well studied techniques from linear algebra to be brought to bear on the difficult domain of semantics, vector space models (VSMs) have been the focus of much recent research in NLP.", "labels": [], "entities": []}, {"text": "While vector representations of word meaning are capable of capturing important semantic features of words and performing tasks like meaning comparison and analogizing, one of their shortcomings is their implicit assumption that a single written word type has exactly one meaning (or distribution) in a language.", "labels": [], "entities": [{"text": "meaning comparison", "start_pos": 133, "end_pos": 151, "type": "TASK", "confidence": 0.7277058362960815}]}, {"text": "But many words clearly have different senses corresponding to distinct appropriate contexts.", "labels": [], "entities": []}, {"text": "Building distributional vector space models that account for this polysemous behavior would allow for better performance on tasks involving context-sensitive words, most obviously word sense disambiguation.", "labels": [], "entities": [{"text": "word sense disambiguation", "start_pos": 180, "end_pos": 205, "type": "TASK", "confidence": 0.6361527244249979}]}, {"text": "Previous research that attempted to resolve this issue is discussed at length in the next section.", "labels": [], "entities": []}, {"text": "Most common methods either use clustering or introduce knowledge from an ontology.", "labels": [], "entities": []}, {"text": "The goal of the present research is to develop or improve upon methods that take advantage of the semantic groups and relations codified in WordNet, and specifically to focus on the downstream WSD task, which is often neglected in favor of less useful similarity judgment evaluations.", "labels": [], "entities": []}, {"text": "The algorithm we examine in depth can in principle be implemented with any ontology, but in the present paper we focus exclusively on WordNet.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 134, "end_pos": 141, "type": "DATASET", "confidence": 0.954017162322998}]}, {"text": "WordNet (WN) is a knowledge base for English language semantics.", "labels": [], "entities": [{"text": "WordNet (WN)", "start_pos": 0, "end_pos": 12, "type": "DATASET", "confidence": 0.901228740811348}, {"text": "English language semantics", "start_pos": 37, "end_pos": 63, "type": "TASK", "confidence": 0.621142307917277}]}, {"text": "It consists of small collections of synonymous words called synsets, interconnected with labeled links corresponding to different forms of semantic or lexical relations.", "labels": [], "entities": []}, {"text": "We will be particularly interested in the synset relation of hypernymy/hyponymy.", "labels": [], "entities": []}, {"text": "Hyponyms can bethought of as semantic subsets: If A is a hyponym of B, then x is A implies x is B, but the converse is not true.", "labels": [], "entities": []}, {"text": "WordNet is also equipped with a dictionary definition for each synset, along with example sentences featuring varying synonymous words.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 0, "end_pos": 7, "type": "DATASET", "confidence": 0.965711236000061}]}, {"text": "Often implementations that use WordNet's graph structure fail to make use of these other features, which we will 2 show can improve performance on several tasks.", "labels": [], "entities": []}], "datasetContent": [{"text": "We train three variations of the RETROFIT algorithm on the 50-dimensional global context vectors produced by: the unmodified RETROFIT, RETROFIT with gloss words and multi-word lemmas (which we refer to as Modified RETROFIT), and Weighted RETROFIT with weighted senses as discussed above.", "labels": [], "entities": [{"text": "RETROFIT", "start_pos": 135, "end_pos": 143, "type": "METRIC", "confidence": 0.9450117945671082}]}, {"text": "Training time is similar between the first two; weighted RETROFIT takes about twice as long.", "labels": [], "entities": [{"text": "RETROFIT", "start_pos": 57, "end_pos": 65, "type": "METRIC", "confidence": 0.8459323048591614}]}, {"text": "All converge to a solution within 0.01 within fifteen iterations.", "labels": [], "entities": []}, {"text": "The models are evaluated on two different tasks: Synonym Selection and Word Sense Disambiguation.", "labels": [], "entities": [{"text": "Synonym Selection", "start_pos": 49, "end_pos": 66, "type": "TASK", "confidence": 0.8936189711093903}, {"text": "Word Sense Disambiguation", "start_pos": 71, "end_pos": 96, "type": "TASK", "confidence": 0.6130484739939371}]}, {"text": "We first include and discuss results from some similarity judgment tasks, but these serve more as steppingstone than an as a rigorous measure of model quality.", "labels": [], "entities": [{"text": "similarity judgment tasks", "start_pos": 47, "end_pos": 72, "type": "TASK", "confidence": 0.7430322964986166}]}, {"text": "give a comprehensive assessment of the inadequacies of evaluating the quality of embeddings on word similarity tasks.", "labels": [], "entities": [{"text": "word similarity tasks", "start_pos": 95, "end_pos": 116, "type": "TASK", "confidence": 0.7693478862444559}]}, {"text": "In general, these tasks are fairly subjective and a model's performance on them does not correlate with performance on downstream NLP tasks.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Performance on RG-65 word similarity dataset. Scores are Spearman's rank correlation.", "labels": [], "entities": [{"text": "RG-65 word similarity dataset", "start_pos": 25, "end_pos": 54, "type": "DATASET", "confidence": 0.6813216358423233}, {"text": "Spearman's rank correlation", "start_pos": 67, "end_pos": 94, "type": "METRIC", "confidence": 0.46937184035778046}]}, {"text": " Table 2: Percent accuracy on ESL-50 and TOEFL  synonym selection using maxSim comparison", "labels": [], "entities": [{"text": "accuracy", "start_pos": 18, "end_pos": 26, "type": "METRIC", "confidence": 0.8967034816741943}, {"text": "TOEFL  synonym selection", "start_pos": 41, "end_pos": 65, "type": "TASK", "confidence": 0.636261373758316}]}, {"text": " Table 3: Semeval 2015 task 13 F1 scores of the models using the contextMax disambiguation function.", "labels": [], "entities": [{"text": "F1", "start_pos": 31, "end_pos": 33, "type": "METRIC", "confidence": 0.9987263083457947}, {"text": "contextMax disambiguation", "start_pos": 65, "end_pos": 90, "type": "TASK", "confidence": 0.6804016530513763}]}, {"text": " Table 4: Semeval 2015 task 13 F1 scores of the models using the contextMax disambiguation function,  restricted to correct POS", "labels": [], "entities": [{"text": "F1", "start_pos": 31, "end_pos": 33, "type": "METRIC", "confidence": 0.9952380657196045}]}, {"text": " Table 5: Semeval 2015 task 13 F1 scores of the models using the localGlobal disambiguation function", "labels": [], "entities": [{"text": "F1", "start_pos": 31, "end_pos": 33, "type": "METRIC", "confidence": 0.9942863583564758}, {"text": "localGlobal disambiguation", "start_pos": 65, "end_pos": 91, "type": "TASK", "confidence": 0.7122814357280731}]}, {"text": " Table 6: Semeval 2015 task 13 F1 scores of the models using the localGlobal disambiguation function,  restricted to correct POS", "labels": [], "entities": [{"text": "F1", "start_pos": 31, "end_pos": 33, "type": "METRIC", "confidence": 0.9967361092567444}]}]}