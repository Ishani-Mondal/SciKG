{"title": [{"text": "Advances in Ngram-based Discrimination of Similar Languages", "labels": [], "entities": [{"text": "Ngram-based Discrimination of Similar Languages", "start_pos": 12, "end_pos": 59, "type": "TASK", "confidence": 0.8307073175907135}]}], "abstractContent": [{"text": "We describe the systems entered by the National Research Council in the 2016 shared task on discriminating similar languages.", "labels": [], "entities": [{"text": "National Research Council", "start_pos": 39, "end_pos": 64, "type": "DATASET", "confidence": 0.9409384330113729}]}, {"text": "Like previous years, we relied on character ngram features, and a combination of discriminative and generative statistical classifiers.", "labels": [], "entities": []}, {"text": "We mostly investigated the influence of the amount of data on the performance, in the open task, and compared the two-stage approach (predicting language/group, then variant) to a flat approach.", "labels": [], "entities": []}, {"text": "Results suggest that ngrams are still state-of-the-art for language and variant identification, that additional data has a small but decisive impact, and that the two-stage approach performs slightly better, everything else being kept equal, than the flat approach.", "labels": [], "entities": [{"text": "language and variant identification", "start_pos": 59, "end_pos": 94, "type": "TASK", "confidence": 0.6609856933355331}]}], "introductionContent": [{"text": "We describe the systems submitted by the National Research Council Canada to the 2016 shared task on discriminating similar languages.", "labels": [], "entities": [{"text": "National Research Council Canada", "start_pos": 41, "end_pos": 73, "type": "DATASET", "confidence": 0.8555597066879272}]}, {"text": "Discriminating similar languages and language variants is useful for several purposes.", "labels": [], "entities": [{"text": "Discriminating similar languages and language variants", "start_pos": 0, "end_pos": 54, "type": "TASK", "confidence": 0.8158074816068014}]}, {"text": "As the typical linguistic processing pipeline is tailored to a specific language and variant, it is important to have a reliable prediction of the language a text is written in, in order to use the appropriate linguistic tools.", "labels": [], "entities": []}, {"text": "It may also be used for filtering data in order to build these specialized linguistic processing tools.", "labels": [], "entities": []}, {"text": "In education, and language learning in particular, it may also be useful to identify precisely the variant familiar to a learner so that feedback can be tailored to the vocabulary or linguistic constructions they are familiar with.", "labels": [], "entities": []}, {"text": "Finally, in security, it is highly relevant to identify the regional variant of the language used by a writer or poster.", "labels": [], "entities": []}, {"text": "Shared tasks on discriminating similar languages were organized in 2014 ( ) and 2015 (.", "labels": [], "entities": []}, {"text": "This year's task continues in the same track, removing some of the easy languages (Czech and Slovak; Macedonian and Bulgarian), providing additional material for some of the harder variants (Serbo-Croat-Bosnian; Indonesian and Malay; Portuguese; Spanish), and adding new groups or variants (Mexican Spanish; French from Canada and France).", "labels": [], "entities": []}, {"text": "Like previous years, we relied on character ngram features, and a mixture of discriminative and generative statistical classifiers.", "labels": [], "entities": []}, {"text": "Due to lack of time, we decided to eschew a full optimization of the feature sets and model combination, despite the fact that it provided excellent results in previous years (.", "labels": [], "entities": []}, {"text": "Instead, we focused on two issues: the influence of the amount of data on the performance (open versus closed data), and the difference between a two-stage approach (predicting language/group, then variant) and a flat approach predicting the variant directly.", "labels": [], "entities": [{"text": "predicting language/group", "start_pos": 166, "end_pos": 191, "type": "TASK", "confidence": 0.8565497845411301}]}, {"text": "To be clear, the \"Advances\" in the title of this paper do not relate to the performance and model we used this year, which are mostly similar to successful models of prior years.", "labels": [], "entities": []}, {"text": "The intent is to advance our understanding of how these models works and what configurations are more effective.", "labels": [], "entities": []}, {"text": "An overview of the results of this shared task is presented in the shared task report . It provides a wider context for interpreting the results reported here, which we only compare to a few top systems.", "labels": [], "entities": []}, {"text": "The shared task report also provides references to related work.", "labels": [], "entities": []}, {"text": "The reader may also lang DSLCC v1.0 DSLCC v2.", "labels": [], "entities": [{"text": "DSLCC v1.0 DSLCC v2", "start_pos": 25, "end_pos": 44, "type": "DATASET", "confidence": 0.8864059746265411}]}, {"text": "bs find a lot of references to related work (within and outside the shared tasks) in Section 2 of).", "labels": [], "entities": []}, {"text": "In the following section, we describe the data we worked with, the features we extracted from the data, and the models we trained on these features.", "labels": [], "entities": []}, {"text": "Section 3 summarizes our results on the shared task test set and compared them to a few key systems from other participants.", "labels": [], "entities": []}, {"text": "Finally, we discuss those results and their significance in Section 4.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Statistics on the training data used for training our systems. (  *  : 2016 data was actually identical  to DSLCC v2.1 data)", "labels": [], "entities": [{"text": "DSLCC v2.1 data", "start_pos": 118, "end_pos": 133, "type": "DATASET", "confidence": 0.9139556884765625}]}, {"text": " Table 2: Predictive accuracy (in %) for the 2016 open track runs, for our two runs and two runner-ups, on  the three official test sets and overall. Rightmost column gives cross-validation estimate, for comparison.", "labels": [], "entities": [{"text": "Predictive", "start_pos": 10, "end_pos": 20, "type": "METRIC", "confidence": 0.9981228709220886}, {"text": "accuracy", "start_pos": 21, "end_pos": 29, "type": "METRIC", "confidence": 0.8894554376602173}]}, {"text": " Table 3: Predictive accuracy (in %) for the 2016 closed track runs, on the three official test sets and  overall. Rightmost column gives cross-validation estimate, for comparison.", "labels": [], "entities": [{"text": "Predictive", "start_pos": 10, "end_pos": 20, "type": "METRIC", "confidence": 0.9970121383666992}, {"text": "accuracy", "start_pos": 21, "end_pos": 29, "type": "METRIC", "confidence": 0.8830926418304443}]}, {"text": " Table 4: Language group confusion on test set A, run1: reference in rows, predicted in columns.", "labels": [], "entities": []}, {"text": " Table 5: Language variant confusion for run1: reference in rows, predicted in columns.", "labels": [], "entities": []}]}