{"title": [{"text": "Combining Translation Memories and Syntax-Based SMT Experiments with Real Industrial Data", "labels": [], "entities": [{"text": "Combining Translation Memories", "start_pos": 0, "end_pos": 30, "type": "TASK", "confidence": 0.6865241130193075}, {"text": "SMT", "start_pos": 48, "end_pos": 51, "type": "TASK", "confidence": 0.7821333408355713}]}], "abstractContent": [{"text": "One major drawback of using Translation Memories (TMs) in phrase-based Machine Translation (MT) is that only continuous phrases are considered.", "labels": [], "entities": [{"text": "Translation Memories (TMs)", "start_pos": 28, "end_pos": 54, "type": "TASK", "confidence": 0.8110494971275329}, {"text": "phrase-based Machine Translation (MT)", "start_pos": 58, "end_pos": 95, "type": "TASK", "confidence": 0.7697306176026663}]}, {"text": "In contrast, syntax-based MT allows phrasal discontinuity by learning translation rules containing non-terminals.", "labels": [], "entities": [{"text": "MT", "start_pos": 26, "end_pos": 28, "type": "TASK", "confidence": 0.9167996048927307}]}, {"text": "In this paper, we combine a TM with syntax-based MT via sparse features.", "labels": [], "entities": [{"text": "TM", "start_pos": 28, "end_pos": 30, "type": "TASK", "confidence": 0.9418991804122925}, {"text": "MT", "start_pos": 49, "end_pos": 51, "type": "TASK", "confidence": 0.901004433631897}]}, {"text": "These features are extracted during decoding based on translation rules and their corresponding patterns in the TM.", "labels": [], "entities": []}, {"text": "We have tested this approach by carrying out experiments on real English-Spanish industrial data.", "labels": [], "entities": []}, {"text": "Our results show that these TM features significantly improve syntax-based MT.", "labels": [], "entities": [{"text": "MT", "start_pos": 75, "end_pos": 77, "type": "TASK", "confidence": 0.8849378228187561}]}, {"text": "Our final system yields improvements of up to +3.1 BLEU, +1.6 METEOR, and-2.6 TER when compared with a state-of-the-art phrase-based MT system.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 51, "end_pos": 55, "type": "METRIC", "confidence": 0.9986439347267151}, {"text": "METEOR", "start_pos": 62, "end_pos": 68, "type": "METRIC", "confidence": 0.9935810565948486}, {"text": "TER", "start_pos": 78, "end_pos": 81, "type": "METRIC", "confidence": 0.9994621872901917}, {"text": "MT", "start_pos": 133, "end_pos": 135, "type": "TASK", "confidence": 0.8835723996162415}]}], "introductionContent": [{"text": "A Translation Memory (TM) is a database which stores legacy translations.", "labels": [], "entities": [{"text": "Translation Memory (TM)", "start_pos": 2, "end_pos": 25, "type": "TASK", "confidence": 0.8970383882522583}]}, {"text": "Translators use them in their work because TMs allow them to increase their productivity by retrieving past translations and help them to enhance terminology and style cohesion across projects.", "labels": [], "entities": []}, {"text": "Given an input sentence, a TM provides the most similar source sentence in the database together with its target translation as the reference for post-editing.", "labels": [], "entities": []}, {"text": "If the input sentence was already translated in the past, the translator does not necessarily post-edit it.", "labels": [], "entities": []}, {"text": "In the case of similar sentences (called \"fuzzy matches\"), the Computer Assisted Translation tool highlights the differences between the input sentence and the one stored in the TM to enhance the post-editing task.", "labels": [], "entities": [{"text": "Computer Assisted Translation", "start_pos": 63, "end_pos": 92, "type": "TASK", "confidence": 0.648870180050532}]}, {"text": "Different coloring schemes are used to highlight changes and additions to the source text in the TM to help the translator spot quicker the post-edits needed.", "labels": [], "entities": []}, {"text": "As TMs can help produce high quality and consistent translations for repetitive materials, they are believed to be useful for Statistical Machine Translation (SMT).", "labels": [], "entities": [{"text": "Statistical Machine Translation (SMT)", "start_pos": 126, "end_pos": 163, "type": "TASK", "confidence": 0.8760123749574026}]}, {"text": "The combination of TM and SMT (henceforth referred as \"TM combination\") has been explored in many ways and it has shown to improve translation quality.", "labels": [], "entities": [{"text": "SMT", "start_pos": 26, "end_pos": 29, "type": "TASK", "confidence": 0.9418445229530334}]}, {"text": "Unlike the well-known pipeline approaches (), which use a TM combination at sentence-level, run-time TM combination (namely, combining the TM and SMT during decoding) can make a better use of the matched sub-sentences ().", "labels": [], "entities": []}, {"text": "Such run-time combination has been explored on Phrase-Based (PB) MT (.", "labels": [], "entities": [{"text": "Phrase-Based (PB) MT", "start_pos": 47, "end_pos": 67, "type": "TASK", "confidence": 0.4034729301929474}]}, {"text": "However, PBMT systems making use of TMs only take into consideration continuous segments and thus generalizations such as the translation of the English call.", "labels": [], "entities": [{"text": "translation of the English call", "start_pos": 126, "end_pos": 157, "type": "TASK", "confidence": 0.8399699211120606}]}, {"text": "off into the Spanish cancelar cannot be learned.", "labels": [], "entities": [{"text": "Spanish cancelar", "start_pos": 13, "end_pos": 29, "type": "DATASET", "confidence": 0.8331764936447144}]}, {"text": "In this paper, we explore the possibility of using a run-time TM combination on syntax-based MT.", "labels": [], "entities": [{"text": "MT", "start_pos": 93, "end_pos": 95, "type": "TASK", "confidence": 0.8849753737449646}]}, {"text": "Syntax-based MT learns translation rules which can be easily extrapolated to new sentences by allowing non-terminals.", "labels": [], "entities": [{"text": "MT", "start_pos": 13, "end_pos": 15, "type": "TASK", "confidence": 0.816554069519043}]}, {"text": "In our approach, for each applied translation rule during decoding, we identify a corresponding pattern in the TM and then extract sparse features which are subsequently added to our system.", "labels": [], "entities": []}, {"text": "In our experiments, the TM combination is done on the hierarchical phrase-based (HPB) model) and the dependency-to-string (D2S) model).", "labels": [], "entities": [{"text": "TM", "start_pos": 24, "end_pos": 26, "type": "TASK", "confidence": 0.9771013855934143}]}, {"text": "The experimental results on real English-Spanish data show that syntax-based models produce significantly better translations than phrase-based models.", "labels": [], "entities": []}, {"text": "After adding the TM features, the syntax-based models are further significantly improved.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1. Statistics of English-Spanish (EN-ES) corpus.", "labels": [], "entities": [{"text": "English-Spanish (EN-ES) corpus", "start_pos": 24, "end_pos": 54, "type": "DATASET", "confidence": 0.6031059145927429}]}, {"text": " Table 2. Metric scores for all systems on English-Spanish. Each score is the average score over  three MIRA runs", "labels": [], "entities": [{"text": "MIRA", "start_pos": 104, "end_pos": 108, "type": "METRIC", "confidence": 0.6083924174308777}]}]}