{"title": [{"text": "Supporting Spoken Assistant Systems with a Graphical User Interface that Signals Incremental Understanding and Prediction State", "labels": [], "entities": [{"text": "Signals Incremental Understanding", "start_pos": 73, "end_pos": 106, "type": "TASK", "confidence": 0.7854071259498596}]}], "abstractContent": [{"text": "Arguably, spoken dialogue systems are most often used not in hands/eyes-busy situations, but rather in settings where a graphical display is also available, such as a mobile phone.", "labels": [], "entities": []}, {"text": "We explore the use of a graphical output modality for signalling incremental understanding and prediction state of the dialogue system.", "labels": [], "entities": [{"text": "signalling incremental understanding", "start_pos": 54, "end_pos": 90, "type": "TASK", "confidence": 0.7197268803914388}]}, {"text": "By visual-ising the current dialogue state and possible continuations of it as a simple tree, and allowing interaction with that visual-isation (e.g., for confirmations or corrections), the system provides both feedback on past user actions and guidance on possible future ones, and it can span the continuum from slot filling to full prediction of user intent (such as GoogleNow).", "labels": [], "entities": [{"text": "slot filling", "start_pos": 314, "end_pos": 326, "type": "TASK", "confidence": 0.7779208421707153}]}, {"text": "We evaluate our system with real users and report that they found the system intuitive and easy to use, and that incremental and adaptive settings enable users to accomplish more tasks.", "labels": [], "entities": []}], "introductionContent": [{"text": "Current virtual personal assistants (PAs) require users to either formulate complex intents in one utterance (e.g., \"call Peter Miller on his mobile phone\") or go through tedious sub-dialogues (e.g., \"phone call\" -who would you like to call?", "labels": [], "entities": []}, {"text": "-\"Peter Miller\" -I have a mobile number and a work number.", "labels": [], "entities": [{"text": "Peter Miller\"", "start_pos": 2, "end_pos": 15, "type": "DATASET", "confidence": 0.8812191883722941}]}, {"text": "Which one do you want?).", "labels": [], "entities": []}, {"text": "This is not how one would interact with a human assistant, where the request would be naturally structured into smaller chunks that individually get acknowledged (e.g., \"Can you make a connection for me?\"", "labels": [], "entities": []}, {"text": "-sure -\"with Peter Miller\" -uh huh -\"on his mobile\" -dialling now).", "labels": [], "entities": []}, {"text": "Current PAs signal ongoing understanding by displaying the state of the recognised speech (ASR) to the user, but not their semantic interpretation of it.", "labels": [], "entities": []}, {"text": "Another type of assistant system forgoes enquiring user intent altogether and infers likely intents from context.", "labels": [], "entities": []}, {"text": "GoogleNow, for example, might present traffic information to a user picking up their mobile phone at their typical commute time.", "labels": [], "entities": [{"text": "GoogleNow", "start_pos": 0, "end_pos": 9, "type": "DATASET", "confidence": 0.9388560056686401}]}, {"text": "These systems display their \"understanding\" state, but do not allow any type of interaction with it apart from dismissing the provided information.", "labels": [], "entities": []}, {"text": "In this work, we explore adding a graphical user interface (GUI) modality that makes it possible to see these interaction styles as extremes on a continuum, and to realise positions between these extremes and present a mixed graphical/voice enabled PA that can provide feedback of understanding to the user incrementally as the user's utterance unfolds-allowing users to make requests in instalments instead of fully thought-out requests.", "labels": [], "entities": []}, {"text": "It does this by signalling ongoing understanding in an intuitive tree-like GUI that can be displayed on a mobile device.", "labels": [], "entities": []}, {"text": "We evaluate our system by directing users to perform tasks using it under nonincremental (i.e., ASR endpointing) and incremental conditions and then compare the two conditions.", "labels": [], "entities": []}, {"text": "We further compare a non-adaptive with an adaptive (i.e., infers likely events) version of our system.", "labels": [], "entities": []}, {"text": "We report that the users found the interface intuitive and easy to use, and that users were able to perform tasks more efficiently with incremental as well as adaptive variants of the system.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section, we describe two experiments where we evaluated our system.", "labels": [], "entities": []}, {"text": "It is our primary goal to show that our GUI is useful and signals understanding to the user.", "labels": [], "entities": []}, {"text": "We also wish to show that incremental presentation of such a GUI is more effective than an endpointed system.", "labels": [], "entities": []}, {"text": "We further want to show that an adaptive system is more effective than a non-adaptive system (though both would process incrementally).", "labels": [], "entities": []}, {"text": "In order to best evaluate our system, we recruited participants to interact with our system in varied settings to compare endpointed (i.e., non-incremental) and nonadaptive as well as adaptive versions.", "labels": [], "entities": []}, {"text": "We describe how the data were collected from the participants, then explain each experiment and give results.", "labels": [], "entities": []}, {"text": "In this section we report the results of the evaluation between the endpointed (i.e., nonincremental; Phase 1) variant vs the incremental (Phase 2) variant of our system.", "labels": [], "entities": []}, {"text": "Subjective Results We applied a multinomial test of significance to the results, treating all four possible answers as equally likely (with Bonferroni correction of 10).", "labels": [], "entities": [{"text": "correction", "start_pos": 151, "end_pos": 161, "type": "METRIC", "confidence": 0.6888054609298706}]}, {"text": "The item The interface was useful and easy to understand with the answer of Both was significant (\u03c7 2 (4, N = 12) = 9.0, p < .005), as was The assistant was easy and intuitive to use also with the answer Both (\u03c7 2 (4, N = 12) = 9.0, p < .005).", "labels": [], "entities": []}, {"text": "The item I always understood what the system wanted from me was also answered Both significantly more times than other answers (\u03c7 2 (4, N = 14) = 9.0, p < .005), similarly for It was sometimes unclear tome if the assistant understood me with the answer of Both (\u03c7 2 (4, N = 12) = 10.0, p < .005).", "labels": [], "entities": []}, {"text": "These responses tell us that though the participants did not report preference for either system variant, they reported a general positive impression of the GUI (in both variants).", "labels": [], "entities": []}, {"text": "This is a nice result; the GUI could be used in either system with benefit to the users.", "labels": [], "entities": []}, {"text": "Objective Results The endpointed (Phase 1) and incremental (Phase 2) columns in show the results of the objective evaluation.", "labels": [], "entities": [{"text": "Objective", "start_pos": 0, "end_pos": 9, "type": "METRIC", "confidence": 0.9127100706100464}]}, {"text": "incremental variant, the total number of tasks for the incremental variant was higher.", "labels": [], "entities": []}, {"text": "Manual inspection of logs indicate that participants took advantage of the system's flexibility of understanding instalments (i.e., filling frames incrementally).", "labels": [], "entities": []}, {"text": "This is evidenced in that participants often uttered words understood by the system as being negative (e.g., nein/no), either as a result of an explicit confirmation request by the system (e.g., Thai?) or after a slot was incorrectly filled (something very easily determined through the GUI).", "labels": [], "entities": []}, {"text": "This is a desired outcome of using our system; participants were able to repair local areas of misunderstanding as they took place instead of needing to correct an entire intent (i.e., frame).", "labels": [], "entities": []}, {"text": "However, we cannot fully empirically measure these tendencies given our data.", "labels": [], "entities": []}, {"text": "In this section we report results for the evaluation between the incremental (Phase 2) and incremental-adaptive (henceforth just adaptive; Phase 3) systems.", "labels": [], "entities": []}, {"text": "Subjective Results We applied the same significance test as Experiment 1 (with Bonferroni correction of 12).", "labels": [], "entities": []}, {"text": "The item The interface was useful and easy to understand was answered with Both significantly (\u03c7 2 (4, N = 14) = 10.0, p < .0042), The item I had the feeling that the assistant attempted to learn about me was answered with Neither (\u03c7 2 (4, N = 14) = 8.0, p < .0042), though Phase 3 was also marked (6 times).", "labels": [], "entities": []}, {"text": "All other items were not significant.", "labels": [], "entities": []}, {"text": "Here again we see that there is a general positive impression of the GUI under all conditions.", "labels": [], "entities": [{"text": "GUI", "start_pos": 69, "end_pos": 72, "type": "DATASET", "confidence": 0.8704919815063477}]}, {"text": "If anyone noticed that a system variant was attempting to learn a user model at all, they noticed that it was in Phase 3, as expected.", "labels": [], "entities": []}, {"text": "Objective Results The incremental (Phase 2) and adaptive (Phase 3) columns in show the results for the objective evaluation for this experiment.", "labels": [], "entities": [{"text": "Objective", "start_pos": 0, "end_pos": 9, "type": "METRIC", "confidence": 0.9632624983787537}]}, {"text": "There is a clear difference between the two variants, with the adaptive showing more completed tasks, more fully correct frames, and a higher average fscore (all three likely due to the fact that frames were potentially pre-filled).", "labels": [], "entities": [{"text": "fscore", "start_pos": 150, "end_pos": 156, "type": "METRIC", "confidence": 0.9798832535743713}]}], "tableCaptions": [{"text": " Table 1: Objective measures for Experiments 1 & 2: count  of completed tasks, number of fully correct frames, average  fscore (over all participants), and average elapsed time per  task (over all participants).", "labels": [], "entities": [{"text": "Objective", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9661495685577393}, {"text": "count", "start_pos": 52, "end_pos": 57, "type": "METRIC", "confidence": 0.9914400577545166}, {"text": "fscore", "start_pos": 120, "end_pos": 126, "type": "METRIC", "confidence": 0.9673985838890076}]}]}