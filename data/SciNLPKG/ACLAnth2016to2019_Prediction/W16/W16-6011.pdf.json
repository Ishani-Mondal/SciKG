{"title": [{"text": "Using Language Groundings for Context-Sensitive Text Prediction", "labels": [], "entities": [{"text": "Context-Sensitive Text Prediction", "start_pos": 30, "end_pos": 63, "type": "TASK", "confidence": 0.623050183057785}]}], "abstractContent": [{"text": "In this paper, we present the concept of using language groundings for context-sensitive text prediction using a semantically informed, context-aware language model.", "labels": [], "entities": [{"text": "context-sensitive text prediction", "start_pos": 71, "end_pos": 104, "type": "TASK", "confidence": 0.6096185346444448}]}, {"text": "We show initial findings from a preliminary study investigating how users react to a communication interface driven by context-based prediction using a simple language model.", "labels": [], "entities": []}, {"text": "We suggest that the results support further exploration using a more informed semantic model and more realistic context.", "labels": [], "entities": []}], "introductionContent": [{"text": "Advances in natural language and world perception have led to a resurgence of work on the language grounding problem.", "labels": [], "entities": []}, {"text": "Most work to date has focused on learning a model of language describing the world, then using it to understand novel language, e.g., following directions, () or learning to understand commands in a space of plans or commands ().", "labels": [], "entities": []}, {"text": "Generating language based on context is arguably more difficult, although the additional information provided by context makes this a promising area for natural language generation in general.", "labels": [], "entities": [{"text": "natural language generation", "start_pos": 153, "end_pos": 180, "type": "TASK", "confidence": 0.6849346955617269}]}, {"text": "There is a growing body of work on context-based generation in limited domains, such as sportscasting, asking questions (), or generating spatial descriptions or narratives.", "labels": [], "entities": []}, {"text": "In order to provide communication suggestions for users, it is not necessary to solve the problem of arbitrary natural language generation.", "labels": [], "entities": [{"text": "arbitrary natural language generation", "start_pos": 101, "end_pos": 138, "type": "TASK", "confidence": 0.7223687618970871}]}, {"text": "Instead, the system must be able to provide predictions that support a predictive language interface, in which a user is continuously provided with a set of suggestions for possible speech.", "labels": [], "entities": []}, {"text": "We propose an approach, in which a joint linguistic/perceptual model is used to drive a predictive text tool, targeting augmentative and alternative communication (AAC) tools for wheelchair users with motor apraxia of speech.", "labels": [], "entities": []}, {"text": "We propose to use the speaker's environment as context to make more relevant predictions.", "labels": [], "entities": []}, {"text": "Sensed context will be used to drive the probability of predictions and reduce ambiguity; for example, while \"button\" may refer to a fastener for clothing or a control for an electronic device, someone in front of an elevator is probably referring to the latter, which in turn focuses what they are likely to want to say.", "labels": [], "entities": []}, {"text": "Instrumented wheelchairs can capture a large corpus of language paired with context to support development of a user-specific model trained before and during degradation of the ability to speak.", "labels": [], "entities": []}, {"text": "This paper discusses a pilot study using a preliminary language model with simulated context.", "labels": [], "entities": []}, {"text": "Participants responded to scenarios using a prototype interface to communicate.", "labels": [], "entities": []}, {"text": "Using results and observations from this user study, we hypothesize that context-based predictive lan-guage can improve usability of a predictive text interface and represents a promising direction for future work.", "labels": [], "entities": []}], "datasetContent": [{"text": "An interface was developed to test four different methods for generating predictions, of which three are novel to this work.", "labels": [], "entities": []}, {"text": "These methods vary in the length of generated predictions: users were presented with combinations of single words, short phrases, or full sentences (see).", "labels": [], "entities": []}, {"text": "A simulated qwerty keyboard was available for fallback text entry.", "labels": [], "entities": [{"text": "fallback text entry", "start_pos": 46, "end_pos": 65, "type": "TASK", "confidence": 0.6537475287914276}]}, {"text": "A new pool of participants were asked to use the interface to communicate responses to the same four scenarios, rather than typing responses on a keyboard.", "labels": [], "entities": []}, {"text": "In order to generate a predictive language model that is context driven based on these scenarios, n-gram models were constructed using the Presage predictive text entry program 1 . Four different prediction methods were tested using this model (see).", "labels": [], "entities": [{"text": "Presage predictive text entry", "start_pos": 139, "end_pos": 168, "type": "TASK", "confidence": 0.5953258201479912}]}], "tableCaptions": []}