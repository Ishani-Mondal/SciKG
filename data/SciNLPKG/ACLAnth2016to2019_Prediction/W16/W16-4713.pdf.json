{"title": [{"text": "A semiautomatic annotation approach for ontological and terminological knowledge acquisition", "labels": [], "entities": []}], "abstractContent": [{"text": "We propose a semi-automatic method for the acquisition of specialised ontological and terminological knowledge.", "labels": [], "entities": [{"text": "acquisition of specialised ontological and terminological knowledge", "start_pos": 43, "end_pos": 110, "type": "TASK", "confidence": 0.6717634967395237}]}, {"text": "An ontology and a terminology are automatically built from domain experts' annotations.", "labels": [], "entities": []}, {"text": "The ontology formalizes the common and shared conceptual vocabulary of those experts.", "labels": [], "entities": []}, {"text": "Its associated terminology defines a glossary linking annotated terms to their semantic categories.", "labels": [], "entities": []}, {"text": "These two resources evolve incrementally and are used for an automatic annotation of anew corpus at each iteration.", "labels": [], "entities": []}, {"text": "The annotated corpus concerns the evaluation of French higher education and science institutions.", "labels": [], "entities": []}], "introductionContent": [{"text": "For several years, French higher education and science institutions have been evaluated by an external institution.", "labels": [], "entities": []}, {"text": "Most often this evaluation is conducted by the High Council for the Evaluation of.", "labels": [], "entities": []}, {"text": "Each year the HCERES recruits and trains academic experts participating in the evaluation of one or more institutions.", "labels": [], "entities": []}, {"text": "These evaluations lead to the production of publicly accessible reports.", "labels": [], "entities": []}, {"text": "These reports are rather standardized documents as their writing follows an established evaluation template.", "labels": [], "entities": []}, {"text": "This evaluation template can be divided into ten fields : Training, Governance, International Relations, Management, Piloting, Research, Student achievement, Scientific Culture and Valorization.", "labels": [], "entities": [{"text": "International Relations", "start_pos": 80, "end_pos": 103, "type": "TASK", "confidence": 0.7941297888755798}, {"text": "Piloting", "start_pos": 117, "end_pos": 125, "type": "TASK", "confidence": 0.9248065948486328}]}, {"text": "Each field may then be divided into several sub-fields (only twenty are explicitly named).", "labels": [], "entities": []}, {"text": "Each report summarizes in its conclusion the strengths and weaknesses of the evaluated institution according to the evaluation template's fields.", "labels": [], "entities": []}, {"text": "Each year positive or negative assessments are manually classified by the HCERES experts according to the fields they refer to, in order to synthesise strengths and weaknesses of evaluated institutions over the same year.", "labels": [], "entities": []}, {"text": "In the reports, classifying an assessment means simultaneously identifying a term denoting afield and a term denoting an opinion.", "labels": [], "entities": []}, {"text": "Sentences (1) and (2) below respectively contain a positive assessment on the field training and a negative assessment on the field Valorization.", "labels": [], "entities": [{"text": "Valorization", "start_pos": 132, "end_pos": 144, "type": "METRIC", "confidence": 0.9189374446868896}]}, {"text": "Sentences (3) and (4) contain more than one assessment, which is representative of the sentences of the conclusions.", "labels": [], "entities": []}, {"text": "Thus, although sentences are generally well written, the aggregation of assessments can make them quite long and complex.", "labels": [], "entities": []}, {"text": "Throughout this article, terms denoting afield appear in bold and terms denoting an opinion appear in italic.", "labels": [], "entities": []}, {"text": "1. une formation doctorale tr\u00e8s attractive.", "labels": [], "entities": []}, {"text": "/ (A very attractive doctoral training.)", "labels": [], "entities": []}, {"text": "2. une politique de valorisation de la recherche peu lisible.", "labels": [], "entities": []}, {"text": "/ (A most unclear policy of research valorization.)", "labels": [], "entities": []}, {"text": "3. Une pr\u00e9sidence forte mais une gouvernance \u00e0 revoir.", "labels": [], "entities": []}, {"text": "/ (A strong presidency but governance must be overhauled.)", "labels": [], "entities": []}, {"text": "4. Une difficult\u00e9 de pr\u00e9vision des recettes et un manque d'approche politique dans la construction du budget.", "labels": [], "entities": []}, {"text": "/ (Some difficulty in forecasting revenues and alack of apolitical approach in budget drafting.)", "labels": [], "entities": [{"text": "budget drafting", "start_pos": 79, "end_pos": 94, "type": "TASK", "confidence": 0.7460624873638153}]}, {"text": "This work of classification is along, complex and subjective task fora human being.", "labels": [], "entities": []}, {"text": "Given the amount of work, experts have to restrict their annotation to the ten major fields.", "labels": [], "entities": []}, {"text": "Moreover, the work has to be shared out among several academic experts, hence no expert can have a global view of all reports.", "labels": [], "entities": []}, {"text": "Since the number of reports keeps increasing, it has becomes necessary to automate this classification task by training an opinion mining system.", "labels": [], "entities": [{"text": "opinion mining", "start_pos": 123, "end_pos": 137, "type": "TASK", "confidence": 0.7473755180835724}]}, {"text": "The main issue of the described work is the classification of opinions into fields and sub-fields.", "labels": [], "entities": [{"text": "classification of opinions into fields", "start_pos": 44, "end_pos": 82, "type": "TASK", "confidence": 0.8390096187591553}]}, {"text": "Indeed, it appeared that for the HCERES experts the ambiguity of term denoting a polarity as fort (strong) is almost nil.", "labels": [], "entities": [{"text": "HCERES", "start_pos": 33, "end_pos": 39, "type": "DATASET", "confidence": 0.9048187136650085}]}, {"text": "Identifying fields and their associated terms is a prerequisite to training an opinion mining system.", "labels": [], "entities": [{"text": "Identifying fields", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.8846085667610168}, {"text": "opinion mining", "start_pos": 79, "end_pos": 93, "type": "TASK", "confidence": 0.8035902976989746}]}, {"text": "Due to the number and the diversity of the evaluated institutions, a comprehensive and consensual listing of all possible sub-fields appeared to be hardly feasible for the HCERES experts.", "labels": [], "entities": []}, {"text": "Hence, we propose to identify and structure the different fields empirically by performing an annotation task, during which each expert is allowed to suggest new sub-fields when he feels the need.", "labels": [], "entities": []}, {"text": "Suggested fields are then consensually validated or rejected.", "labels": [], "entities": []}, {"text": "The resulting consensual annotations are used to automatically build an ontology conceptualising the fields validated during the annotation task as well as a terminology linking the annotated terms to the fields they refer to.", "labels": [], "entities": []}, {"text": "These resources serve to train an automatic annotation system.", "labels": [], "entities": []}, {"text": "Afterwards, anew corpus is automatically annotated before being submitted to the experts who may validate, corrector add missing annotations.", "labels": [], "entities": []}, {"text": "This whole process represents one iteration.", "labels": [], "entities": []}, {"text": "The resulting ontology, terminology and annotated corpus are available on request.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": []}