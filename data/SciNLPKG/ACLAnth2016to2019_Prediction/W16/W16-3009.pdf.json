{"title": [{"text": "Deep Learning with Minimal Training Data: TurkuNLP Entry in the BioNLP Shared Task 2016", "labels": [], "entities": []}], "abstractContent": [{"text": "We present the TurkuNLP entry to the BioNLP Shared Task 2016 Bacteria Biotopes event extraction (BB3-event) subtask.", "labels": [], "entities": [{"text": "BioNLP Shared Task 2016 Bacteria Biotopes event extraction (BB3-event)", "start_pos": 37, "end_pos": 107, "type": "TASK", "confidence": 0.6671407358212904}]}, {"text": "We propose a deep learning-based approach to event extraction using a combination of several Long Short-Term Memory (LSTM) networks over syntactic dependency graphs.", "labels": [], "entities": [{"text": "event extraction", "start_pos": 45, "end_pos": 61, "type": "TASK", "confidence": 0.8349636495113373}]}, {"text": "Features for the proposed neural network are generated based on the shortest path connecting the two candidate entities in the dependency graph.", "labels": [], "entities": []}, {"text": "We further detail how this network can be efficiently trained to have good generalization performance even when only a very limited number of training examples are available and part-of-speech (POS) and dependency type feature representations must be learned from scratch.", "labels": [], "entities": []}, {"text": "Our method ranked second among the entries to the shared task, achieving an F-score of 52.1% with 62.3% precision and 44.8% recall .", "labels": [], "entities": [{"text": "F-score", "start_pos": 76, "end_pos": 83, "type": "METRIC", "confidence": 0.9997021555900574}, {"text": "precision", "start_pos": 104, "end_pos": 113, "type": "METRIC", "confidence": 0.9995182752609253}, {"text": "recall", "start_pos": 124, "end_pos": 130, "type": "METRIC", "confidence": 0.9990906715393066}]}], "introductionContent": [{"text": "The BioNLP Shared Task 2016 was the fourth in the series to focus on event extraction, an information extraction task targeting structured associations of biomedical entities.", "labels": [], "entities": [{"text": "event extraction", "start_pos": 69, "end_pos": 85, "type": "TASK", "confidence": 0.7180905342102051}, {"text": "information extraction task targeting structured associations of biomedical entities", "start_pos": 90, "end_pos": 174, "type": "TASK", "confidence": 0.7577649321821001}]}, {"text": "The 2016 task was also the third to include a Bacteria Biotopes (BB) subtask focusing on microorganisms and their habitats).", "labels": [], "entities": []}, {"text": "Here, we present the TurkuNLP entry to the BioNLP Shared Task 2016 Bacteria Biotope event extraction (BB3-event) subtask.", "labels": [], "entities": [{"text": "BioNLP Shared Task 2016 Bacteria Biotope event extraction (BB3-event)", "start_pos": 43, "end_pos": 112, "type": "TASK", "confidence": 0.6622748889706351}]}, {"text": "Our approach builds on proven tools and ideas from previous tasks and is novel in its application of deep learning methods to biomedical event extraction.", "labels": [], "entities": [{"text": "biomedical event extraction", "start_pos": 126, "end_pos": 153, "type": "TASK", "confidence": 0.7048148413499197}]}, {"text": "The BB task was first organized in 2011, then consisting of named entity recognition (NER) targeting mentions of bacteria and locations, followed by the detection of two types of relations involving these entities).", "labels": [], "entities": [{"text": "BB task", "start_pos": 4, "end_pos": 11, "type": "TASK", "confidence": 0.8224955201148987}, {"text": "named entity recognition (NER) targeting mentions of bacteria and locations", "start_pos": 60, "end_pos": 135, "type": "TASK", "confidence": 0.7344697366158167}]}, {"text": "Three teams participated in this task, with the best Fscore of 45% achieved by the INRA Bibliome group with the Alvis system, which used dictionary mapping, ontology inference and semantic analysis for NER, and co-occurrence-based rules for detecting relations between the entities).", "labels": [], "entities": [{"text": "Fscore", "start_pos": 53, "end_pos": 59, "type": "METRIC", "confidence": 0.9997566342353821}, {"text": "INRA Bibliome group", "start_pos": 83, "end_pos": 102, "type": "DATASET", "confidence": 0.913851002852122}, {"text": "dictionary mapping", "start_pos": 137, "end_pos": 155, "type": "TASK", "confidence": 0.6759988516569138}]}, {"text": "The 2013 BB task defined three subtasks), the first one concerning NER, targeting bacteria habitat entities and their normalization, and the other two subtasks involving relation extraction, the task targeted also by the system presented here.", "labels": [], "entities": [{"text": "2013 BB task", "start_pos": 4, "end_pos": 16, "type": "DATASET", "confidence": 0.6650665799776713}, {"text": "NER", "start_pos": 67, "end_pos": 70, "type": "TASK", "confidence": 0.8842182755470276}, {"text": "relation extraction", "start_pos": 170, "end_pos": 189, "type": "TASK", "confidence": 0.7942324280738831}]}, {"text": "Similarly to the current BB3-event subtask, the 2013 subtask 2 concerned only relation extraction, and subtask 3 extended this with NER.", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 78, "end_pos": 97, "type": "TASK", "confidence": 0.8417840898036957}, {"text": "NER", "start_pos": 132, "end_pos": 135, "type": "DATASET", "confidence": 0.8836917877197266}]}, {"text": "Four teams participated in these tasks, with the UTurku TEES system achieving the first places with F-scores of 42% and 14%.", "labels": [], "entities": [{"text": "UTurku", "start_pos": 49, "end_pos": 55, "type": "DATASET", "confidence": 0.5498862266540527}, {"text": "TEES", "start_pos": 56, "end_pos": 60, "type": "METRIC", "confidence": 0.863819420337677}, {"text": "F-scores", "start_pos": 100, "end_pos": 108, "type": "METRIC", "confidence": 0.999300479888916}]}, {"text": "We next present the 2016 BB3-event subtask and its data and then proceed to detail our method, its results and analysis.", "labels": [], "entities": [{"text": "BB3-event subtask", "start_pos": 25, "end_pos": 42, "type": "DATASET", "confidence": 0.8370488584041595}]}, {"text": "We conclude with a discussion of considered alternative approaches and future work.", "labels": [], "entities": []}], "datasetContent": [{"text": "For evaluation of the test set, we applied the proposed model with the voting approach presented above): 15 neural network models with different random initializations were trained for 4 epochs on the combination of the training and the development sets.", "labels": [], "entities": []}, {"text": "Each trained model was then used to produce one set of predictions for the test set.", "labels": [], "entities": []}, {"text": "To obtain the final test set predictions, the outputs of the 15 classifiers were aggregated using the voting algorithm with a threshold t = 4.", "labels": [], "entities": []}, {"text": "Our method achieved an F-score of 52.1% with a recall of 44.8% and precision of 62.3%, ranking second among the entries to the shared task.", "labels": [], "entities": [{"text": "F-score", "start_pos": 23, "end_pos": 30, "type": "METRIC", "confidence": 0.9997058510780334}, {"text": "recall", "start_pos": 47, "end_pos": 53, "type": "METRIC", "confidence": 0.9995445609092712}, {"text": "precision", "start_pos": 67, "end_pos": 76, "type": "METRIC", "confidence": 0.9998069405555725}]}, {"text": "We again emphasize that our approach ignored all potential relations between entities belonging to different sentences, which may in part explain the comparatively low recall.", "labels": [], "entities": [{"text": "recall", "start_pos": 168, "end_pos": 174, "type": "METRIC", "confidence": 0.99741530418396}]}], "tableCaptions": [{"text": " Table 1: BB3-event data statistics. (The relation  annotations of the test set have not been released.)", "labels": [], "entities": [{"text": "BB3-event data statistics", "start_pos": 10, "end_pos": 35, "type": "DATASET", "confidence": 0.8621184627215067}]}, {"text": " Table 2: Development set results for 15 repeti- tions with different initial random initializations  with mean (\u00af x) and standard deviation (\u03c3). Results  are sorted by F-score.", "labels": [], "entities": [{"text": "standard deviation (\u03c3)", "start_pos": 122, "end_pos": 144, "type": "METRIC", "confidence": 0.9442854523658752}, {"text": "F-score", "start_pos": 169, "end_pos": 176, "type": "METRIC", "confidence": 0.9981266856193542}]}, {"text": " Table 3: Development set results for voting based  on the predictions of the 15 different classifiers.  Best results for each metric shown in bold.", "labels": [], "entities": []}]}