{"title": [{"text": "Statistical Natural Language Generation from Tabular Non-textual Data", "labels": [], "entities": [{"text": "Statistical Natural Language Generation", "start_pos": 0, "end_pos": 39, "type": "TASK", "confidence": 0.5240899920463562}]}], "abstractContent": [{"text": "Most of the existing natural language generation (NLG) techniques employing statistical methods are typically resource and time intensive.", "labels": [], "entities": [{"text": "natural language generation (NLG)", "start_pos": 21, "end_pos": 54, "type": "TASK", "confidence": 0.8166577219963074}]}, {"text": "On the other hand, handcrafted rule-based and template-based NLG systems typically require significant human/designer efforts.", "labels": [], "entities": []}, {"text": "In this paper, we proposed a statistical NLG technique which does not require any semantic relational knowledge and takes much less time to generate output text.", "labels": [], "entities": []}, {"text": "The system can be used in those cases where source non-textual data are in the form of tuple in some tabular dataset.", "labels": [], "entities": []}, {"text": "We carried out our experiments on the Prodigy-METEO wind forecasting dataset.", "labels": [], "entities": [{"text": "Prodigy-METEO wind forecasting dataset", "start_pos": 38, "end_pos": 76, "type": "DATASET", "confidence": 0.8746625334024429}]}, {"text": "For the evaluation purpose, we used both human evaluation and automatic evaluation.", "labels": [], "entities": []}, {"text": "From the evaluation results we found that the linguistic quality and correct-ness of the texts generated by the system are better than many existing NLG systems.", "labels": [], "entities": [{"text": "correct-ness", "start_pos": 69, "end_pos": 81, "type": "METRIC", "confidence": 0.9739160537719727}]}], "introductionContent": [{"text": "The aim of a natural language generation (NLG) system is to produce apprehensible natural language text from non-textual data source which could be a table, an image, numerical data or graphical data.", "labels": [], "entities": [{"text": "natural language generation (NLG)", "start_pos": 13, "end_pos": 46, "type": "TASK", "confidence": 0.8186930119991302}]}, {"text": "NLG is just the reverse process of the natural language understanding task.", "labels": [], "entities": [{"text": "natural language understanding task", "start_pos": 39, "end_pos": 74, "type": "TASK", "confidence": 0.7125369906425476}]}, {"text": "Although many NLG systems have been proposed so far, there are mainly two types of language generation systems: knowledge-intensive systems and knowledge-light systems.", "labels": [], "entities": []}, {"text": "Knowledge-intensive NLG systems can be categorized mainly into two categories: templatebased systems and handcrafted rule-based systems.", "labels": [], "entities": []}, {"text": "Knowledge-intensive generation approaches take significant human effort or expert advise for building an NLG system.", "labels": [], "entities": []}, {"text": "Some examples of this type of NLG systems are SumTime system), FoG system (, PLANDOC system (, etc.", "labels": [], "entities": []}, {"text": "On the other hand, knowledge-light NLG systems mostly use statistical methods to generate output text and take less human effort.", "labels": [], "entities": []}, {"text": "Being automatic systems, knowledge-light systems mostly employ machine learning and data mining techniques.", "labels": [], "entities": []}, {"text": "There are many types of knowledge-light systems; n-gram based NLG (, neural network based NLG), case based NLG (), etc.", "labels": [], "entities": []}, {"text": "However, it has been observed that knowledge-intensive systems typically perform better than knowledge-light systems as per human evaluation.", "labels": [], "entities": []}, {"text": "Beside knowledge-intensive and knowledge-light NLG systems, there are also some NLG systems which can be built through semi-automatic techniques.", "labels": [], "entities": []}, {"text": "Probabilistic synchronous context free grammar (PSCFG) based NLG system falls into this category of NLG systems.", "labels": [], "entities": []}, {"text": "In this paper we propose a novel, knowledge-light approach based NLG system which converts a tuple of tabular-formed non-textual data into its corresponding natural language text data.", "labels": [], "entities": []}, {"text": "Unlike most of the existing NLG systems, our system does not require any human effort or domain expert help.", "labels": [], "entities": []}, {"text": "Moreover, the system does not require much time and computer resources (i.e., hardware equipments) for training and generation purpose.", "labels": [], "entities": []}, {"text": "Most of the neural network (especially Recurrent Neural Net-work) based knowledge-light NLG systems demand advanced computer resources and processing time for training.", "labels": [], "entities": []}, {"text": "Contrastingly, without taking much human effort and resources, our system is able to generate intelligible and readable text output.", "labels": [], "entities": []}, {"text": "The remainder of the paper is organized as follows.", "labels": [], "entities": []}, {"text": "Section 2 briefly presents relevant related work.", "labels": [], "entities": []}, {"text": "The proposed NLG system is described in Section 3.", "labels": [], "entities": []}, {"text": "Section 4 elaborates the experimental settings, dataset and the corresponding results.", "labels": [], "entities": []}, {"text": "Section 5 concludes the paper.", "labels": [], "entities": []}], "datasetContent": [{"text": "This section presents the dataset used in our experiments and the evaluation results of our system compared to some other NLG systems.", "labels": [], "entities": []}, {"text": "As mentioned in Section 3.2, a non-textual-textual parallel dataset is required to train our system.", "labels": [], "entities": []}, {"text": "The parallelism should be in such a form that each nontextual data can be represented as a tuple of attribute value instances and most of those attribute values should be present in its corresponding textual data.", "labels": [], "entities": []}, {"text": "We used the Prodigy-METEO 2 corpus (Belz, 2009), a wind forecast dataset, for our experiment.", "labels": [], "entities": [{"text": "Prodigy-METEO 2 corpus (Belz, 2009), a wind forecast dataset", "start_pos": 12, "end_pos": 72, "type": "DATASET", "confidence": 0.8110074951098516}]}, {"text": "In the Prodigy-METEO corpus a single pair of non-textual-textual data stands fora particular day's wind forecast report.", "labels": [], "entities": [{"text": "Prodigy-METEO corpus", "start_pos": 7, "end_pos": 27, "type": "DATASET", "confidence": 0.9701198935508728}]}, {"text": "A non-textual data in that dataset is represented by a seven-component vector, where each component expresses a particular feature of wind data measurement at a moment of time.", "labels": [], "entities": []}, {"text": "The seven components belong to a vector represented by [id, direction, speed min, speed max, gust-speed min, gust-speed max, time].", "labels": [], "entities": []}, {"text": "In that vector representation id stands for identification of the vector, direction mentions the wind speed direction, speed max and speed min denote the maximum and mnimum wind speed respectively, gust max and gust min represent the maximum and minimum wind gust speed respectively, and the last component time denotes the specific time instance 2 http://www.nltg.brighton.ac.uk/home/Anja.Belz/Prodigy when rest of components' readings were measured.", "labels": [], "entities": [{"text": "Anja.Belz", "start_pos": 385, "end_pos": 394, "type": "METRIC", "confidence": 0.9554624557495117}]}, {"text": "For example, 1st April, 2001 wind forecast data is represented in this dataset as,] , where '-' represents a missing reading value.", "labels": [], "entities": [{"text": "1st April, 2001 wind forecast data", "start_pos": 13, "end_pos": 47, "type": "DATASET", "confidence": 0.8540411421230861}]}, {"text": "As mentioned earlier our proposed model can process only a single tuple formed non-textual data at a time.", "labels": [], "entities": []}, {"text": "However, the Prodigy-METEO corpus represents each non-textual data (wind forecast data fora particular day) by a sequence of multi-component vectors.", "labels": [], "entities": [{"text": "Prodigy-METEO corpus", "start_pos": 13, "end_pos": 33, "type": "DATASET", "confidence": 0.9463624954223633}]}, {"text": "For this reason, we merge all the vectors of a particular day's wind forecast data into a single tuple formed data.", "labels": [], "entities": []}, {"text": "The merging of a particular day's wind forecast data vectors is illustrated in.", "labels": [], "entities": []}, {"text": "The Prodigy-METEO corpus comes with five pre-  We evaluated our system using both automatic evaluation metrics and human evaluation.", "labels": [], "entities": [{"text": "Prodigy-METEO corpus", "start_pos": 4, "end_pos": 24, "type": "DATASET", "confidence": 0.7055069655179977}]}, {"text": "For both human and automatic evaluation, we compared our system with ten existing NLG systems whose outputs on the Prodigy-METEO testset are also available in the Prodigy-METEO corpus.", "labels": [], "entities": [{"text": "Prodigy-METEO testset", "start_pos": 115, "end_pos": 136, "type": "DATASET", "confidence": 0.8198614120483398}, {"text": "Prodigy-METEO corpus", "start_pos": 163, "end_pos": 183, "type": "DATASET", "confidence": 0.8756105601787567}]}, {"text": "These ten NLG systems are PCFG-Greedy, PSCFG-Semantic, PSCFG-Unstructured, PCFG-Viterbii, PCFG2gram, PCFG-Roulette, PBSMT-Unstructured, SumTime-Hybrid, PBSMT-Structured and PCFGRandom ().", "labels": [], "entities": []}, {"text": "shows a sample input and outputs of all the above mentioned systems including our system.", "labels": [], "entities": []}, {"text": "For automatic evaluation, we used two automatic evaluation metrics; BLEU () and METEOR ().", "labels": [], "entities": [{"text": "BLEU", "start_pos": 68, "end_pos": 72, "type": "METRIC", "confidence": 0.9992183446884155}, {"text": "METEOR", "start_pos": 80, "end_pos": 86, "type": "METRIC", "confidence": 0.9958280920982361}]}, {"text": "Both BLEU and METEOR were originally proposed for evaluation of machine translation (MT) systems However, due to the similarity between the two tasks (i.e., MT and NLG) from the point of view of their working principles, most of the NLG systems are also evaluated using these two automatic MT evaluation metrics.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 5, "end_pos": 9, "type": "METRIC", "confidence": 0.9982855916023254}, {"text": "METEOR", "start_pos": 14, "end_pos": 20, "type": "METRIC", "confidence": 0.9251671433448792}, {"text": "evaluation of machine translation (MT)", "start_pos": 50, "end_pos": 88, "type": "TASK", "confidence": 0.7629429910864148}, {"text": "MT evaluation", "start_pos": 290, "end_pos": 303, "type": "TASK", "confidence": 0.9074114263057709}]}, {"text": "Because of the relatively small size of the dataset, we took a five-fold cross validation policy which was predefined in the Prodigy-METEO corpus.", "labels": [], "entities": [{"text": "Prodigy-METEO corpus", "start_pos": 125, "end_pos": 145, "type": "DATASET", "confidence": 0.950013130903244}]}, {"text": "Table 1 presents the evaluation results obtained with BLEU and METEOR on our system along with the ten other NLG systems.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 54, "end_pos": 58, "type": "METRIC", "confidence": 0.9985685348510742}, {"text": "METEOR", "start_pos": 63, "end_pos": 69, "type": "METRIC", "confidence": 0.932845950126648}]}, {"text": "Evaluation using automatic evaluation metrics is very popular among researchers and developers since automatic evaluation is very fast and cheap.", "labels": [], "entities": []}, {"text": "Automatic evaluation metrics are good indicators of system performance and they greatly help day-today system development.", "labels": [], "entities": []}, {"text": "However, despite being very time intensive and costly, human evaluation still serves as the de-facto evaluation standard and the worth of automatic evaluation metrics are typically judged based on how well they correlate with human evaluation.", "labels": [], "entities": []}, {"text": "We also evaluated the systems using human evaluation on apart of the test dataset.", "labels": [], "entities": []}, {"text": "We carried out human evaluation to measure the clarity and readability of the texts generated by the NLG systems.", "labels": [], "entities": [{"text": "clarity", "start_pos": 47, "end_pos": 54, "type": "METRIC", "confidence": 0.9886103272438049}]}, {"text": "Clarity measures truthfulness and correctness of a textual data whereas readability concerns fluency of the textual data.", "labels": [], "entities": []}, {"text": "30 instances (out of total 232) were randomly chosen from the testset for the pilot human evaluation and the output from 11 different systems along with the corresponding non-textual data were presented to the human evaluators.", "labels": [], "entities": []}, {"text": "Five students from different backgrounds who acted as human evaluators were asked to rate 72 outputs each in a 10 point scale.", "labels": [], "entities": []}, {"text": "The output of human evaluation is presented in.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Comparison using automatic metric evaluation", "labels": [], "entities": []}]}