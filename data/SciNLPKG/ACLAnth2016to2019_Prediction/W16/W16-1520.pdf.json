{"title": [{"text": "Trainable Citation-enhanced Summarization of Scientific Articles", "labels": [], "entities": [{"text": "Summarization of Scientific Articles", "start_pos": 28, "end_pos": 64, "type": "TASK", "confidence": 0.8496370315551758}]}], "abstractContent": [{"text": "In order to cope with the growing number of relevant scientific publications to consider at a given time, automatic text summariza-tion is a useful technique.", "labels": [], "entities": []}, {"text": "However, summarizing scientific papers poses important challenges for the natural language processing community.", "labels": [], "entities": []}, {"text": "In recent years a number of evaluation challenges have been proposed to address the problem of summarizing a scientific paper taking advantage of its citation network (i.e., the papers that cite the given paper).", "labels": [], "entities": [{"text": "summarizing a scientific paper", "start_pos": 95, "end_pos": 125, "type": "TASK", "confidence": 0.8777922838926315}]}, {"text": "Here, we present our trainable technology to address a number of challenges in the context of the 2nd Computational Linguistics Scientific Document Summarization Shared Task.", "labels": [], "entities": [{"text": "Computational Linguistics Scientific Document Summarization Shared Task", "start_pos": 102, "end_pos": 173, "type": "TASK", "confidence": 0.6976839942591531}]}], "introductionContent": [{"text": "During the last decade the amount of scientific information available on-line increased at an unprecedented rate with recent estimates reporting anew paper published every 20 seconds.", "labels": [], "entities": []}, {"text": "In this scenario of scientific information overload, researchers are overwhelmed by an enormous and continuously growing number of articles to consider in their research work: from the exploration of advances in specific topics, to peer reviewing, writing and evaluation.", "labels": [], "entities": []}, {"text": "In order to cope with the growing number of relevant publications to consider at a given time, automatic text summarization is a useful technique.", "labels": [], "entities": [{"text": "text summarization", "start_pos": 105, "end_pos": 123, "type": "TASK", "confidence": 0.6197333037853241}]}, {"text": "However, generic text summarization techniques may notwork well in specialized genres such as the scientific genre and domain specific techniques maybe needed.", "labels": [], "entities": [{"text": "generic text summarization", "start_pos": 9, "end_pos": 35, "type": "TASK", "confidence": 0.6155721644560496}]}, {"text": "Scientific publications are characterized by several structural, linguistic and semantic peculiarities.", "labels": [], "entities": []}, {"text": "Articles include common structural elements (title, authors, abstract, sections, figures, tables, citations, bibliography) that often require specific text processing tools.", "labels": [], "entities": []}, {"text": "Additionally, scientific documents have specific discourse structure.", "labels": [], "entities": []}, {"text": "Another important aspect of scientific papers is their network of citations that identifies links among research works, making them also particularly interesting from the social viewpoint.", "labels": [], "entities": []}, {"text": "Although citation counts had been used to assess some aspects of research output fora longtime, citation semantics has started to be exploited in several context including opinion mining and scientific text summarization.", "labels": [], "entities": [{"text": "opinion mining", "start_pos": 172, "end_pos": 186, "type": "TASK", "confidence": 0.7903364598751068}, {"text": "scientific text summarization", "start_pos": 191, "end_pos": 220, "type": "TASK", "confidence": 0.5973989764849345}]}, {"text": "Considering the urgent need for new, automated approaches to browse and aggregate scientific information, in recent years a number of natural language processing challenges have been proposed: the Biomedical Summarization Task (BioSumm2014) carried out in the context of the Text Analysis Conferences 1 provided a forum for researchers interested in exploring the summarization of clusters of documents where one of the documents is a reference paper and the rest of the documents in the cluster are citing papers which cite the reference paper.", "labels": [], "entities": [{"text": "Biomedical Summarization Task (BioSumm2014)", "start_pos": 197, "end_pos": 240, "type": "TASK", "confidence": 0.7102986921866735}, {"text": "Text Analysis Conferences 1", "start_pos": 275, "end_pos": 302, "type": "TASK", "confidence": 0.8117848262190819}, {"text": "summarization of clusters of documents", "start_pos": 364, "end_pos": 402, "type": "TASK", "confidence": 0.8922509551048279}]}, {"text": "In particular, the BioSumm2014 evaluation released a dataset consisting of 20 collections of annotated papers (i.e., clusters), each one including a reference article and 10 citing articles.", "labels": [], "entities": [{"text": "BioSumm2014 evaluation", "start_pos": 19, "end_pos": 41, "type": "DATASET", "confidence": 0.8250983953475952}]}, {"text": "Similarly, a pilot task on summarization of Computational Linguistic papers was proposed in 2014.", "labels": [], "entities": [{"text": "summarization of Computational Linguistic papers", "start_pos": 27, "end_pos": 75, "type": "TASK", "confidence": 0.8586327910423279}]}, {"text": "Unfortunately, none of the evaluation contests provided with official evaluation results.", "labels": [], "entities": []}, {"text": "In this paper, we report our efforts to develop a system to participate in the CLSciSumm 2016 evaluation which is a renewed effort to address the challenges proposed in 2014.", "labels": [], "entities": [{"text": "CLSciSumm 2016 evaluation", "start_pos": 79, "end_pos": 104, "type": "DATASET", "confidence": 0.8482066591580709}]}, {"text": "Ina nutshell, participants were given a set of clusters, each one composed of n documents where one is a reference paper (RP) and the n-1 remaining documents are referred to as citing papers (CPs) since they cite the reference paper.", "labels": [], "entities": []}, {"text": "Participants have to develop automatic procedures to perform the following tasks: -Task 1A: For each citance (i.e., a reference to the RP), identify the spans of text (cited text spans) in the RP that most accurately reflect the citance.", "labels": [], "entities": []}, {"text": "-Task 1B: For each cited text span, identify what facet of the paper it belongs to, from a predefined set of facets, namely: Aim, Hypothesis, Implication, Results or Method.", "labels": [], "entities": []}, {"text": "-Task 2: Finally, an optional task consists on generating a structured (of up to 250 words) summary of the RP from the cited text spans of the RP.", "labels": [], "entities": []}, {"text": "In the rest of this paper we first present related work on summarization of research articles to then explain how we have addressed the different summarization tasks.", "labels": [], "entities": [{"text": "summarization of research articles", "start_pos": 59, "end_pos": 93, "type": "TASK", "confidence": 0.8722102493047714}, {"text": "summarization", "start_pos": 146, "end_pos": 159, "type": "TASK", "confidence": 0.9759570956230164}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 1. J48 performance on testing data (10-fold cross validation) for the ci- tance/reference matching problem (Task 1A). Last row of the table contains weighted  average values.", "labels": [], "entities": []}, {"text": " Table 2. SMO performance on testing data (10-fold cross validation) for the facet  identification problem (Task 1B). Last row of the table contains weighted average  values.", "labels": [], "entities": [{"text": "SMO", "start_pos": 10, "end_pos": 13, "type": "TASK", "confidence": 0.8972813487052917}, {"text": "facet  identification problem", "start_pos": 77, "end_pos": 106, "type": "TASK", "confidence": 0.7985129356384277}]}, {"text": " Table 3. Linear regression learnt weights for two conditions: relevance to cited text  spans and relevance to a community-based summary. Last row indicates correlation  cohefficient of the model (in 10-fold cross-validation).", "labels": [], "entities": []}]}