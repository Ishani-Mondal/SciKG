{"title": [], "abstractContent": [{"text": "The cross-lingual pronoun prediction task at WMT 2016 requires to restore the missing target pronouns from source text and target lemmatized and POS-tagged translations.", "labels": [], "entities": [{"text": "cross-lingual pronoun prediction", "start_pos": 4, "end_pos": 36, "type": "TASK", "confidence": 0.740571141242981}, {"text": "WMT 2016", "start_pos": 45, "end_pos": 53, "type": "DATASET", "confidence": 0.7108009457588196}]}, {"text": "We study the benefits for this task of a specific Pronoun Language Model (PLM), which captures the likelihood of a pronoun given the gender and number of the nouns or pronouns preceding it, on the target-side only.", "labels": [], "entities": []}, {"text": "Experimenting with the English-to-French subtask, we select the best candidate pronoun by applying the PLM and additional heuristics based on French grammar rules to the target-side texts provided in the subtask.", "labels": [], "entities": [{"text": "PLM", "start_pos": 103, "end_pos": 106, "type": "METRIC", "confidence": 0.9912480115890503}]}, {"text": "Although the PLM helps to outperform a random baseline, it still scores far lower than system using both source and target texts.", "labels": [], "entities": []}], "introductionContent": [{"text": "The translation of pronouns has been recognized as a challenge since the early years of machine translation (MT), as pronoun systems do not map 1:1 across languages.", "labels": [], "entities": [{"text": "machine translation (MT)", "start_pos": 88, "end_pos": 112, "type": "TASK", "confidence": 0.8452231824398041}]}, {"text": "Recently, specific strategies for translating pronouns have been proposed and evaluated, as reviewed by Hardmeier (2014, Section 2.3.1) and by Guillou (.", "labels": [], "entities": [{"text": "translating pronouns", "start_pos": 34, "end_pos": 54, "type": "TASK", "confidence": 0.8899375200271606}]}, {"text": "Following the DiscoMT 2015 shared task on pronoun-focused translation , the goal of the 2016 WMT pronoun shared task ( ) is to compare systems that are able to predict the translation of a source pronoun among a small, closed set of target candidates.", "labels": [], "entities": [{"text": "DiscoMT 2015 shared task", "start_pos": 14, "end_pos": 38, "type": "DATASET", "confidence": 0.822203204035759}, {"text": "pronoun-focused translation", "start_pos": 42, "end_pos": 69, "type": "TASK", "confidence": 0.6265690475702286}, {"text": "WMT pronoun shared task", "start_pos": 93, "end_pos": 116, "type": "TASK", "confidence": 0.8263929039239883}]}, {"text": "The task was proposed for four language pairs: English/German and English/French, in both directions.", "labels": [], "entities": []}, {"text": "Besides the original source documents (transcripts of TED talks), participants were given the formatted target documents, where all words were lemmatized and POS-tagged, and all pronouns were hidden.", "labels": [], "entities": []}, {"text": "Participants were required to restore (or predict) each translated pronoun, in a fully inflected form.", "labels": [], "entities": []}, {"text": "We participate in the subtask of English-toFrench pronoun prediction, with the main goal of testing the merits of a simple target-only approach.", "labels": [], "entities": [{"text": "English-toFrench pronoun prediction", "start_pos": 33, "end_pos": 68, "type": "TASK", "confidence": 0.5588860213756561}]}, {"text": "In previous work, we found that this approach improved the translation of neuter English pronouns it and they into French, and outperformed the DiscoMT 2015 baseline by about 5% relative improvement on an automatic metric.", "labels": [], "entities": [{"text": "translation of neuter English pronouns", "start_pos": 59, "end_pos": 97, "type": "TASK", "confidence": 0.793481171131134}, {"text": "DiscoMT 2015 baseline", "start_pos": 144, "end_pos": 165, "type": "DATASET", "confidence": 0.9371098478635153}]}, {"text": "Our method uses only the fact that the antecedent of a pronoun is likely to be one of the noun phrases preceding it closely.", "labels": [], "entities": []}, {"text": "Therefore, if a majority of these nouns exhibit the same gender and number, it is more likely that the correct French pronoun agrees in gender and number with them.", "labels": [], "entities": []}, {"text": "We model this majority gender and number as a Pronoun Language Model).", "labels": [], "entities": []}, {"text": "This knowledge-lean approach does not make any hypothesis on which of the nouns is the antecedent, though it is augmented, for the 2016 shared task, with language-dependent grammar heuristics to determine the right candidate for neuter French pronouns, which are less constrained in gender and number.", "labels": [], "entities": []}, {"text": "In what follows, after introducing briefly the method (Section 3), we explain how to represent these intuitions in a formal probabilistic modelthe PLM -that is learned from French data (Section 4) and we describe the grammar heuristics to deal with neuter pronouns as well (Section 5).", "labels": [], "entities": []}, {"text": "Then, we show how these two resources are used to determine the target pronoun as required by the 2016 shared task (Section 6) and we analyze our results for both development and test sets, showing that the benefits of our system remain inferior to those of systems using both the source and the target sides.", "labels": [], "entities": []}, {"text": "But first, we present a brief state of the art in pronoun translation in order to compare our proposal with related work.", "labels": [], "entities": [{"text": "pronoun translation", "start_pos": 50, "end_pos": 69, "type": "TASK", "confidence": 0.7414019405841827}]}], "datasetContent": [{"text": "We employ the TEDdev dataset from the 2015 shared task , containing 1,664 sentences with reference translations, 563 it and they instances, as the development set to investigate the usefulness of the proposed PLM and rules.", "labels": [], "entities": [{"text": "TEDdev dataset from the 2015 shared task", "start_pos": 14, "end_pos": 54, "type": "DATASET", "confidence": 0.9147808040891375}]}, {"text": "Firstly, the PLM is used independently for the prediction, and then it is incorporated with the grammar rules for detecting on and other classes.", "labels": [], "entities": []}, {"text": "Unlike the development set, the test set of the 2016 task (with 1,213 sentence pairs and 373 instances of it and they) comes in a lemmatized representation, which prevents participants from extracting explicitly the number of the target nouns and pronouns, though their gender is available.", "labels": [], "entities": []}, {"text": "Hence, we only make use of the gender of the target word and the number of the source word aligned to it, using the alignment information provided.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: The per-class micro-averaged Precision, Recall and F-score of PLM+rules (primary system),  PLM (contrastive system) and Baseline on the development set and on the test set.", "labels": [], "entities": [{"text": "Precision", "start_pos": 39, "end_pos": 48, "type": "METRIC", "confidence": 0.9467792510986328}, {"text": "Recall", "start_pos": 50, "end_pos": 56, "type": "METRIC", "confidence": 0.993347704410553}, {"text": "F-score", "start_pos": 61, "end_pos": 68, "type": "METRIC", "confidence": 0.9786922335624695}]}]}