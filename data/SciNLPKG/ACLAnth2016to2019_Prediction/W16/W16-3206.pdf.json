{"title": [{"text": "Interactively learning visually grounded word meanings from a human tutor", "labels": [], "entities": [{"text": "learning visually grounded word meanings", "start_pos": 14, "end_pos": 54, "type": "TASK", "confidence": 0.6011023938655853}]}], "abstractContent": [{"text": "We present a multi-modal dialogue system for interactive learning of perceptually grounded word meanings from a human tutor.", "labels": [], "entities": [{"text": "interactive learning of perceptually grounded word meanings", "start_pos": 45, "end_pos": 104, "type": "TASK", "confidence": 0.6350504245076861}]}, {"text": "The system integrates an incremen-tal, semantic parsing/generation framework Dynamic Syntax and Type Theory with Records (DS-TTR)-with a set of visual classifiers that are learned throughout the interaction and which ground the meaning representations that it produces.", "labels": [], "entities": [{"text": "semantic parsing/generation framework Dynamic Syntax and Type Theory", "start_pos": 39, "end_pos": 107, "type": "TASK", "confidence": 0.6806295096874238}]}, {"text": "We use this system in interaction with a simulated human tutor to study the effect of different dialogue policies and capabilities on accuracy of learned meanings, learning rates, and efforts/costs to the tutor.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 134, "end_pos": 142, "type": "METRIC", "confidence": 0.9942024350166321}]}, {"text": "We show that the overall performance of the learning agent is affected by (1) who takes initiative in the dialogues; (2) the ability to express/use their confidence level about visual attributes; and (3) the ability to process elliptical as well as in-crementally constructed dialogue turns.", "labels": [], "entities": []}], "introductionContent": [{"text": "Identifying, classifying, and talking about objects or events in the surrounding environment are key capabilities for intelligent, goal-driven systems that interact with other agents and the external world (e.g. robots, smart spaces, and other automated systems).", "labels": [], "entities": [{"text": "Identifying, classifying, and talking about objects or events in the surrounding environment", "start_pos": 0, "end_pos": 92, "type": "TASK", "confidence": 0.5945382373673576}]}, {"text": "To this end, there has recently been a surge of interest and significant progress made on a variety of related tasks, including generation of Natural Language (NL) descriptions of images, or identifying images based on NL descriptions e.g. ().", "labels": [], "entities": [{"text": "generation of Natural Language (NL) descriptions of images", "start_pos": 128, "end_pos": 186, "type": "TASK", "confidence": 0.7735374927520752}]}, {"text": "Another strand of work has focused on learning to generate object descriptions and object classification based on low level concepts/features (such as colour, shape and material), enabling systems to identify and describe novel, unseen images.", "labels": [], "entities": [{"text": "object classification", "start_pos": 83, "end_pos": 104, "type": "TASK", "confidence": 0.7123793512582779}]}, {"text": "Our goal is to build interactive systems that can learn grounded word meanings relating to their perceptions of real-world objects -this is different from previous work such as e.g., that learn groundings from descriptions without any interaction, and more recent work using Deep Learning methods (e.g. ().", "labels": [], "entities": []}, {"text": "Most of these systems using machine learning rely on training data of high quantity with no possibility of online error correction.", "labels": [], "entities": []}, {"text": "Furthermore, they are unsuitable for robots and multimodal systems that need to continuously, and incrementally learn from the environment, and may encounter objects they haven't seen in training data.", "labels": [], "entities": []}, {"text": "These limitations should be alleviated if systems can learn concepts as and when needed, from situated dialogue with humans.", "labels": [], "entities": []}, {"text": "Interaction with human tutors also enables systems to take initiative and seek information they need by e.g. asking questions with the highest information gain (see e.g. (), and).", "labels": [], "entities": []}, {"text": "For example, a robot could ask questions to learn the colour of a \"square\" or to request to be presented with more \"red\" things to improve its performance on the concept (see e.g.).", "labels": [], "entities": []}, {"text": "Furthermore, such systems could allow for meaning negotiation in the form of clarifica-tion interactions with the tutor.", "labels": [], "entities": [{"text": "meaning negotiation", "start_pos": 42, "end_pos": 61, "type": "TASK", "confidence": 0.7801284193992615}]}, {"text": "This setting means that the system must be trainable from little data, compositional, adaptive, and able to handle natural human dialogue with all its glorious context-sensitivity and messiness -for instance so that it can learn visual concepts suitable for specific tasks/domains, or even those specific to a particular user.", "labels": [], "entities": []}, {"text": "Interactive systems that learn continuously, and over the long run from humans need to do so incrementally, quickly, and with minimal effort/cost to human tutors.", "labels": [], "entities": []}, {"text": "In this paper, we use an implemented dialogue system (see and architecture in) that integrates an incremental, semantic grammar framework, especially suited to dialogue processing -Dynamic Syntax and Type Theory with Records (DS-TTR 1 () with visual classifiers which are learned during the interaction, and which provide perceptual grounding for the basic semantic atoms in the semantic representations (Record Types in TTR) produced by the parser (see).", "labels": [], "entities": []}, {"text": "We use this system in interaction with a simulated human tutor, to test hypotheses about how the accuracy of learned meanings, learning rates, and the overall cost/effort for the human tutor are affected by different dialogue policies and capabilities; specifically: (1) who takes initiative in the dialogues; (2) the agent's ability to utilise their level of uncertainty about an object's attributes; and (3) their ability to process elliptical as well as incrementally constructed dialogue turns.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 97, "end_pos": 105, "type": "METRIC", "confidence": 0.9854446053504944}]}, {"text": "The results show that differences along these dimensions have significant impact both on the accuracy of the learned, grounded word meanings, and the processing effort required by the tutors.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 93, "end_pos": 101, "type": "METRIC", "confidence": 0.9986967444419861}]}], "datasetContent": [{"text": "Our goal in this paper is an experimental study of the effect of different dialogue policies and capabilities on the overall performance of the learning agent, which, as we describe below is a measure that combines accuracy of learned meanings with the cost of tutoring overtime.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 215, "end_pos": 223, "type": "METRIC", "confidence": 0.9908975958824158}]}, {"text": "We use the dialogue system outlined above to carryout our main experiment with a 2 \u00d7 2 \u00d7 2 factorial design, i.e. with three factors each with two levels.", "labels": [], "entities": []}, {"text": "Together, these factors determine the learner's dialogue behaviour: (1) Initiative (Learner/Tutor): determines who takes initiative in the dialogues.", "labels": [], "entities": []}, {"text": "When the tutor takes initiative, s/he is the one that drives the conversation forward, by asking questions to the learner (e.g. \"What colour is this?\" or \"So this is a ....\"", "labels": [], "entities": []}, {"text": ") or making a statement about the attributes of the object.", "labels": [], "entities": []}, {"text": "On the other hand, when the learner has initiative, it makes statements, asks questions, initiates topics etc.", "labels": [], "entities": []}, {"text": "(2) Uncertainty (+UC/-UC): determines whether the learner takes into account, in its dialogue behaviour, its own subjective confidence about the attributes of the presented object.", "labels": [], "entities": []}, {"text": "The confidence is the probability assigned by any of its attribute classifiers of the object being a positive instance of an attribute (e.g. 'red') -see below for how a confidence threshold is used here.", "labels": [], "entities": []}, {"text": "In +UC, the agent will not ask a question if it is confident about the answer, and it will hedge the answer to a tutor question if it is not confident, e.g. \"T: What is this?", "labels": [], "entities": []}, {"text": "L: errm, maybe a square?\".", "labels": [], "entities": []}, {"text": "In -UC, the agent always takes itself to know the attributes of the given object (as given by its currently trained Tutor Simulation and Policy: To run our experiment on a large-scale, we have hand-crafted an Interactive Tutoring Simulator, which simulates the behaviour of a human tutor.", "labels": [], "entities": []}, {"text": "The tutor policy is kept constant across all conditions.", "labels": [], "entities": []}, {"text": "Its policy is that of an always truthful, helpful and omniscient one: it (1) has complete access to the labels of each object; and (2) always acts as the context of the dialogue dictates: answers any question asked, confirms or rejects when the learner describes an object; and (3) always corrects the learner when it describes an object erroneously.", "labels": [], "entities": []}, {"text": "Confidence Threshold: To determine when and how the agent properly copes with its attributebased predictions, we use confidence-score thresholds.", "labels": [], "entities": []}, {"text": "It consists of two values, abase threshold (e.g. 0.5) and a positive threshold (e.g. 0.9).", "labels": [], "entities": []}, {"text": "If the confidences of all classifiers are under the base threshold (i.e. the learner has no attribute label that it is confident about), the agent will ask for information directly from the tutor via questions (e.g. \"L: what is this?\").", "labels": [], "entities": []}, {"text": "On the other hand, if one or more classifiers score above the base threshold, then the positive threshold is used to judge to what extent the agent trusts its prediction or not.", "labels": [], "entities": []}, {"text": "If the confidence score of a classifier is between the positive and base thresholds, the learner is not very confident about its knowledge, and will check with the tutor, e.g. \"L: is this red?\".", "labels": [], "entities": []}, {"text": "However, if the confidence score of a classifier is above the positive threshold, the learner is confident enough in its knowledge not to bother verifying it with the tutor.", "labels": [], "entities": []}, {"text": "This will lead to less effort needed from the tutor as the learner becomes more confident about its knowledge.", "labels": [], "entities": []}, {"text": "However, since a learner with high confidence will not ask for assistance from the tutor, a low positive threshold may reduce the chances that allow the tutor to correct the learner's mistakes.", "labels": [], "entities": []}, {"text": "Hence, we setup an auxiliary experiment, in which we kept all other conditions constant (i.e. assume that the learner has initiative (L) and always considers the prediction confidence(+U)), but only varied the threshold values.", "labels": [], "entities": [{"text": "initiative (L)", "start_pos": 122, "end_pos": 136, "type": "METRIC", "confidence": 0.8498300462961197}]}, {"text": "This additional experiment determined a 0.5 base threshold and a 0.9 positive threshold as the most appropriate values for an interactive learning process -i.e. Recognition score: We follow metrics proposed by.", "labels": [], "entities": []}, {"text": "'Recognition score' measures the overall accuracy of the learned word meanings / classifiers, which \"rewards successful classifications (i.e. true positives and true negatives) and penalizes incorrect predictions (i.e. false positives and false negatives)\".", "labels": [], "entities": [{"text": "Recognition score", "start_pos": 1, "end_pos": 18, "type": "METRIC", "confidence": 0.7402783334255219}, {"text": "accuracy", "start_pos": 41, "end_pos": 49, "type": "METRIC", "confidence": 0.9983323216438293}]}, {"text": "As the proposed system considers both correctness of predicted labels and prediction confidence on learning tasks, the measure will also take the true labels with lower confidence into account, as shown in; \"LowYes\" means that the system made positive predictions but with lower confidence.", "labels": [], "entities": []}, {"text": "In this case, the system can generate a polar question to request tutor feedback.", "labels": [], "entities": []}, {"text": "\"LowNo\" is similar to \"LowYes\", but for negative predictions.", "labels": [], "entities": []}, {"text": "Cost: This measure reflects the effort needed by a human tutor in interacting with the system.", "labels": [], "entities": [{"text": "Cost", "start_pos": 0, "end_pos": 4, "type": "METRIC", "confidence": 0.9109976887702942}]}, {"text": "point out that a teachable system should learn as autonomously as possible, rather than involving the human tutor too frequently.", "labels": [], "entities": []}, {"text": "There are several possible costs that the tutor might incur, see: C inf refers to the cost of the tutor providing information on a single attribute (e.g. \"this is red\" or \"this is a square\"); C ack is the cost fora simple confirmation (like \"yes\", \"right\") or rejection (such as \"no\"); C crt is the cost of correction fora single concept (e.g. \"no, it is blue\").", "labels": [], "entities": []}, {"text": "We associate a higher cost with correction of statements than that of polar questions.", "labels": [], "entities": []}, {"text": "This is to penalise the learning agent when it confidently makes a false statement -thereby incorporating an aspect of trust in the metric (humans will not trust systems which confidently make false statements).", "labels": [], "entities": []}, {"text": "And finally, parsing (C parse ) as well as production (C production ) costs for tutor are taken into account: each single word costs 0.5 when parsed by the tutor, and 1 if generated (production costs twice as much as parsing).", "labels": [], "entities": [{"text": "parsing", "start_pos": 13, "end_pos": 20, "type": "TASK", "confidence": 0.9548205137252808}]}, {"text": "Performance Score: As mentioned above, an efficient learner dialogue policy should consider both classification accuracy (Recognition score) and tutor effort (Cost).", "labels": [], "entities": [{"text": "classification accuracy (Recognition score)", "start_pos": 97, "end_pos": 140, "type": "METRIC", "confidence": 0.8204460243384043}, {"text": "tutor effort (Cost)", "start_pos": 145, "end_pos": 164, "type": "METRIC", "confidence": 0.9155914664268494}]}, {"text": "We thus define an integrated measure -the Overall Performance Ratio (R per f ) -that we use to compare the learner's overall performance across the different conditions: i.e. the increase in Recognition Score (S recog ) per unit of the cost, or equivalently the gradient of the curve in.", "labels": [], "entities": [{"text": "Overall Performance Ratio (R per f )", "start_pos": 42, "end_pos": 78, "type": "METRIC", "confidence": 0.8393861800432205}, {"text": "Recognition Score (S recog )", "start_pos": 191, "end_pos": 219, "type": "METRIC", "confidence": 0.9397832552591959}]}, {"text": "We seek dialogue strategies that maximise this.", "labels": [], "entities": []}, {"text": "We performed a 20-fold cross validation with 500 images for training and 100 for testing (see () for details of the dataset).", "labels": [], "entities": []}, {"text": "For each training instance, the learning system interacts (only through dialogue) with the simulated tutor.", "labels": [], "entities": []}, {"text": "Each interaction episode ends either when both the shape and the colour of the object are agreed upon, or when the learner requests to be presented with the next image.", "labels": [], "entities": []}, {"text": "We define a learning step as comprised of 10 such episodes.", "labels": [], "entities": []}, {"text": "At the end of each learning step, the system is tested using the test set.", "labels": [], "entities": []}, {"text": "The values used for the Tutoring Cost and the Recognition Score at each learning step correspond to averages across the 20 folds.", "labels": [], "entities": [{"text": "Recognition Score", "start_pos": 46, "end_pos": 63, "type": "METRIC", "confidence": 0.7945662140846252}]}, {"text": "shows example interactions between the learner and the tutor in some of the experimental conditions.", "labels": [], "entities": []}, {"text": "Note how the system is able to deal with (parse and generate) utterance continuations as in T +UC+CD, short answers as in L+UC+CD, and polar answers as in T + UC + CD.", "labels": [], "entities": [{"text": "parse and generate) utterance continuations", "start_pos": 42, "end_pos": 85, "type": "TASK", "confidence": 0.6177232712507248}, {"text": "T +UC+CD", "start_pos": 92, "end_pos": 100, "type": "DATASET", "confidence": 0.7375721335411072}, {"text": "T + UC + CD", "start_pos": 155, "end_pos": 166, "type": "DATASET", "confidence": 0.827131712436676}]}, {"text": "plots Recognition Score against Tutoring Cost directly.", "labels": [], "entities": [{"text": "Recognition Score", "start_pos": 6, "end_pos": 23, "type": "METRIC", "confidence": 0.9627066850662231}]}, {"text": "Note that it is expected that the curves should not terminate in the same place on the x-axis since the different conditions incur different total costs for the tutor.", "labels": [], "entities": []}, {"text": "The gradient of this curve corresponds to increase in Recognition Score per unit of the Tutoring Cost.", "labels": [], "entities": [{"text": "Recognition Score", "start_pos": 54, "end_pos": 71, "type": "METRIC", "confidence": 0.9698362648487091}]}, {"text": "There is also a significant Initiative\u00d7Uncertainty interaction (p < 0.01; F = 181.72).", "labels": [], "entities": [{"text": "F", "start_pos": 74, "end_pos": 75, "type": "METRIC", "confidence": 0.994240403175354}]}], "tableCaptions": [{"text": " Table 1: Recognition Score Table  Yes LowYes LowNo No  Yes  1  0.5  -0.5  -1  No  -1  -0.5  0.5  1", "labels": [], "entities": [{"text": "Recognition Score Table  Yes LowYes LowNo No  Yes  1  0.5  -0.5  -1  No  -1  -0.5  0.5", "start_pos": 10, "end_pos": 96, "type": "METRIC", "confidence": 0.835370910167694}]}, {"text": " Table 2: Tutoring Cost Table  C in f C ack C crt C parsing C production  1  0.25  1  0.5  1", "labels": [], "entities": [{"text": "Tutoring", "start_pos": 10, "end_pos": 18, "type": "TASK", "confidence": 0.9743561148643494}, {"text": "ack C crt C parsing C production  1  0.25", "start_pos": 40, "end_pos": 81, "type": "METRIC", "confidence": 0.662354889843199}]}]}