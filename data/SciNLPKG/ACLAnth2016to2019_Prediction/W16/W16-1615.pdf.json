{"title": [{"text": "Decomposing Bilexical Dependencies into Semantic and Syntactic Vectors", "labels": [], "entities": []}], "abstractContent": [{"text": "Bilexical dependencies have been commonly used to help identify the most likely parses of a sentence.", "labels": [], "entities": []}, {"text": "The probability of a word occurring as the dependent of a given head within a particular structure provides a measure of semantic plausibil-ity that complements the purely syntactic part of the parsing model.", "labels": [], "entities": []}, {"text": "Here, we attempt to use the distribu-tional information within these bilexical dependencies to construct representations that decompose into semantic and syntactic components.", "labels": [], "entities": []}, {"text": "In particular, we compare two different approaches to composing vectors to explore how syntactic and semantic representations should interact within such a model.", "labels": [], "entities": []}, {"text": "Our results suggest a tensor product approach has advantages, which we believe could be exploited in making more effective use of the information captured in these bilexical dependencies.", "labels": [], "entities": []}], "introductionContent": [{"text": "Using points within the geometry of a vector space to represent the way words are distributed across contexts has proven to be a fruitful tactic for many language processing tasks.", "labels": [], "entities": []}, {"text": "For example, projected raw tf-idf scores of occurrence across a set of documents down into lower dimensional vectors using a technique called singular value decomposition.", "labels": [], "entities": [{"text": "singular value decomposition", "start_pos": 142, "end_pos": 170, "type": "TASK", "confidence": 0.7211466630299886}]}, {"text": "The resulting semantic representations were then applied to semantic dismbiguation and to predict synonyms in a TOEFL test.", "labels": [], "entities": [{"text": "semantic dismbiguation", "start_pos": 60, "end_pos": 82, "type": "TASK", "confidence": 0.7826223969459534}, {"text": "TOEFL test", "start_pos": 112, "end_pos": 122, "type": "DATASET", "confidence": 0.5968590378761292}]}, {"text": "Working instead with the linear structure of raw text, trained a neural language model to induce word vectors in the hidden layer of their network.", "labels": [], "entities": []}, {"text": "These versatile representations were then applied to a wide range of tasks including part-of-speech tagging, chunking, named entity recognition, and semantic role labeling.", "labels": [], "entities": [{"text": "part-of-speech tagging", "start_pos": 85, "end_pos": 107, "type": "TASK", "confidence": 0.6935064494609833}, {"text": "named entity recognition", "start_pos": 119, "end_pos": 143, "type": "TASK", "confidence": 0.6229075789451599}, {"text": "semantic role labeling", "start_pos": 149, "end_pos": 171, "type": "TASK", "confidence": 0.6720200578371683}]}, {"text": "Two key elements within any such approach to constructing representations are the contexts across which the distribution of a word is tracked and how vectors are constructed from these occurrences.", "labels": [], "entities": []}, {"text": "Here, we investigate the construction of distributional representations from bilexical dependencies found in a parser and explore how such vectors can be decomposed into semantic and syntactic components.", "labels": [], "entities": []}, {"text": "Although, distributional approaches have commonly become most strongly associated with semantic representations and tasks, they have also seen applications to syntax.", "labels": [], "entities": []}, {"text": "In fact, distributional analysis was first applied by linguists to syntactic categories rather than the representation of meaning and Ross (1972) presented a continuous, or at least graded, conception of syntax long before the recent surge of interest in vectorial approaches to semantics.", "labels": [], "entities": [{"text": "distributional analysis", "start_pos": 9, "end_pos": 32, "type": "TASK", "confidence": 0.7283485680818558}]}, {"text": "Practical applications of these distributional techniques to syntactic problems have included work on the induction () or learning of categories and the computational problems of tagging) and parsing.", "labels": [], "entities": [{"text": "parsing", "start_pos": 192, "end_pos": 199, "type": "TASK", "confidence": 0.9688558578491211}]}, {"text": "The latter problem of parsing brings to the foreground the question of how syntactic and semantic representations relate to and interact with each other, as the optimal parse must maximise both syntactic and semantic plausibility, in an integrated structure.", "labels": [], "entities": [{"text": "parsing", "start_pos": 22, "end_pos": 29, "type": "TASK", "confidence": 0.9773135781288147}]}, {"text": "An unmodified PCFG, modelling just the dependencies between syntactic categories, is generally inadequate to derive robust parses, and lexicalisation is commonly used to enhance such models.", "labels": [], "entities": []}, {"text": "In particular, bilexical dependencies introduce a measure of the plausibility of combining specific heads and dependents within the possible syntactic structures.", "labels": [], "entities": []}, {"text": "These dependencies contain much the same information used by and to construct semantic representations, and we can easily see that the plausibility of cake as an object of bake, eat and regret tells us something about the semantic properties of cake.", "labels": [], "entities": []}, {"text": "Nonetheless, these dependencies contain substantial quantities of syntactic information, too.", "labels": [], "entities": []}, {"text": "The dependencies observed for cake and eat, for example, are substantially different because the former is a noun while the latter is a verb.", "labels": [], "entities": []}, {"text": "However, the sparsity of the resulting counts can mean these dependencies may contribute little to parser performance, particulaly on out of domain data.", "labels": [], "entities": []}, {"text": "One solution, proposed by, is to smooth the bilexical dependencies using a similarity measure.", "labels": [], "entities": []}, {"text": "For example, if counts for publication as an object of read are lacking we might instead leverage the similarity of publication to book to use the counts for book as an object of read to make a reasonable inference about the unseen dependency.", "labels": [], "entities": []}, {"text": "Alternatively, we might try to use some form of dimensionality reduction to smooth out the sparsity.", "labels": [], "entities": []}, {"text": "use a modified version of word2vec ( to induce 300 dimensional representations from word distributions across 900,000 dependency contexts.", "labels": [], "entities": []}, {"text": "They find that these word vectors capture a form of functional similarity, with the closest words in the space typically being cohyponyms within the same syntactic class.", "labels": [], "entities": []}, {"text": "This syntactic specificity is not particularly surprising, as we would expect the strongest effects within these dependencies to relate to the syntactic class of a word -e.g. only a noun can be the subject of a verb -with semantic factors having a weaker influence merely on word choice within the correct syntactic class.", "labels": [], "entities": []}, {"text": "In this paper, we will consider a couple of approaches that attempt to separate out semantic and syntactic components of the dependencies, boosting performance on both types of task.", "labels": [], "entities": []}, {"text": "One popular method of boosting semantic performance has been to ignore or average over syntactic structure.", "labels": [], "entities": []}, {"text": "By treating the context a target occurs in as a bagof-words, syntactic information is washed out and semantic information is retained.", "labels": [], "entities": []}, {"text": "Conversely, distributional approaches to syntactic tasks typically make use of the sequential structure contained in bigrams or longer n-grams).", "labels": [], "entities": []}, {"text": "Recent work,, has attempted to use both types of information in a single model that decomposes representations into syntactic and semantic components.", "labels": [], "entities": []}, {"text": "An open question, however, is the most effective way of forming these combined representations.", "labels": [], "entities": []}, {"text": "explicitly employ a direct sum -i.e. concatenation -of semantic and syntactic vectors.", "labels": [], "entities": []}, {"text": "On the other hand, the multiplicative combination used by is much closer to a tensor product formulation.", "labels": [], "entities": []}, {"text": "also pursue the representation of semantics and syntax in a single distributional model.", "labels": [], "entities": []}, {"text": "They integrate a topic model and HMM to produce a model of the sequential structure of raw text in which each word is either semantic -chosen by the topic model to fit the long range semantic context -or syntactic -chosen to fit the short range dependencies of the HMM.", "labels": [], "entities": []}, {"text": "This either/or assumption is rejected by Boyd-graber and Blei (2009) who moreover work with parsed sentences, rather than raw text.", "labels": [], "entities": []}, {"text": "In this model, each word is chosen based on a product of a document topic distribution and a set of syntactic transition probabilities, determined top-down within the parse tree. are also concerned with inducing distributional representations within the stucture of parse trees.", "labels": [], "entities": []}, {"text": "Their neural network model composes vectors recursively from the bottom up to represent possible phrases and from those representations computes how likely each is to be a valid constituent.", "labels": [], "entities": []}, {"text": "Although, parsing may seem, initially, to be the ideal task in which to explore the relationship between semantic and syntactic representations, the complexity of a working system -which Bikel (2004a) describes as an intractable behemothmakes it difficult to isolate and investigate just this question on its own.", "labels": [], "entities": []}, {"text": "Parser performance depends on a multitiude of interacting components, and could only obliquely produce insights into the merit of the approaches to representation we want to consider here.", "labels": [], "entities": []}, {"text": "Instead, we follow the advice of to treat the model as data, and make direct eval-uations of distributional representations induced from the parameters of a wide coverage model.", "labels": [], "entities": []}, {"text": "We focus in on just the bilexical dependencies within the BLLIP parser) and explore models of these parameters in which the representation for each word decomposes into a semantic and a syntactic vector.", "labels": [], "entities": []}, {"text": "We evaluate both a direct sum and a tensor product approach to this decomposition of the representation space and find that the latter has advantages.", "labels": [], "entities": []}, {"text": "In the next section, we describe the BLLIP parser and the data we extract from the wide coverage model of.", "labels": [], "entities": [{"text": "BLLIP", "start_pos": 37, "end_pos": 42, "type": "METRIC", "confidence": 0.6441928148269653}]}, {"text": "Then in Sections 3 and 4 we describe the models applied to this data and their evaluation.", "labels": [], "entities": []}, {"text": "Finally, we present our results and conclusions in Sections 5 and 6.", "labels": [], "entities": []}], "datasetContent": [{"text": "We evaluate our models in a number of ways.", "labels": [], "entities": []}, {"text": "We assess the quality of the word representations in terms of two similarity tasks on the semantic vectors, a, and a POS induction task on the syntactic vectors, b.", "labels": [], "entities": [{"text": "POS induction task", "start_pos": 117, "end_pos": 135, "type": "METRIC", "confidence": 0.9378985563913981}]}, {"text": "In addition, both these tasks are applied to the raw data and to the vectors induced by the undecomposed models, Eq.", "labels": [], "entities": []}, {"text": "11. We also investigate the ability of our models to differentiate semantically and syntactically implausible adjective-noun constructions.", "labels": [], "entities": []}, {"text": "Finally, we list a sample of nearest neighbours to allow a qualitative insight into the best performing model.", "labels": [], "entities": []}, {"text": "Our semantic similarity tasks are based on the ratings in two datasets, on both of which we evaluate our models using Spearman correlation.", "labels": [], "entities": []}, {"text": "The first is the WordSim353 dataset () containing ratings from 16 participants between pairs of nouns.", "labels": [], "entities": [{"text": "WordSim353 dataset", "start_pos": 17, "end_pos": 35, "type": "DATASET", "confidence": 0.9797504246234894}]}, {"text": "The second dataset contains similarity ratings for noun-verb pairs.", "labels": [], "entities": []}, {"text": "The former measures the ability of the model to capture semantic similarity within a POS class, while the latter tells about its representation of similarity across classes.", "labels": [], "entities": []}, {"text": "This cross-class measure is useful in determining how effective the model has been in separating semantic from syntactic information.", "labels": [], "entities": [{"text": "separating semantic from syntactic information", "start_pos": 86, "end_pos": 132, "type": "TASK", "confidence": 0.7734493851661682}]}, {"text": "A model that bundles both into a single representation may identify the similarity in disappear-vanish but will typically fail to make the same judgement about disappearance-vanish.", "labels": [], "entities": []}, {"text": "Making that judgement requires ignoring the syntactic difference between nouns and verbs, which we achieve in our models by representing that information separately.", "labels": [], "entities": []}, {"text": "Our syntactic task is POS induction.", "labels": [], "entities": [{"text": "POS induction", "start_pos": 22, "end_pos": 35, "type": "TASK", "confidence": 0.7797032296657562}]}, {"text": "We cluster the vocabulary into 45 classes using k-means, and evaluate in terms of the many-to-one measure using the PTB POS classes as a gold standard.", "labels": [], "entities": [{"text": "PTB POS classes", "start_pos": 116, "end_pos": 131, "type": "DATASET", "confidence": 0.8562086820602417}]}, {"text": "Although POS class information is already present in the bilexical dependency data, we use this task as a means of determining the quality of syntactic information contained in the vectors, rather than as an example of a practical application.", "labels": [], "entities": []}, {"text": "We then examine how our models differentiate semantic and syntactic plausibility.", "labels": [], "entities": []}, {"text": "Our semantic plausibility dataset is constructed by combining a set of food nouns (e.g. milk, meat, bread, etc.) with either food appropriate adjectives (e.g. hot, bitter, sweet, etc.) or implausible political adjectives (e.g. bipartisan, legislative, constituional, etc.).", "labels": [], "entities": []}, {"text": "To create an equivalent syntactic plausibility dataset we combine common singular and plural nouns (e.g. year -years, player -players, etc.) with the modifier several.", "labels": [], "entities": []}, {"text": "In each case, we calculate a semantic plausibility for the resulting adjective-noun phrase.", "labels": [], "entities": []}, {"text": "Comparing the distribution of these measures in the high and low plausibility cases allows us to investigate further the extent to which the model separates semantic and syntactic dependencies.", "labels": [], "entities": []}, {"text": "Finally, we evaluate the best performing model -based on a tensor product of vectors -qualitatively by examining the closest neighbours of set of nouns, adjectives and verbs.", "labels": [], "entities": []}, {"text": "gives the correlations and many-to-one measures for the raw data, the simple undecomposed model (Eq.", "labels": [], "entities": []}, {"text": "2), the symmetric undecomposed model, the direct sum model (Eq. 8) and the tensor product model (Eq. 9).", "labels": [], "entities": []}, {"text": "Looking at the first two rows of the table, to compare the raw data to the simple model, we can see that the latter outpeforms the fomer on the POS clustering task, but is worse on the semantic similarity tasks.", "labels": [], "entities": [{"text": "POS clustering task", "start_pos": 144, "end_pos": 163, "type": "TASK", "confidence": 0.783237636089325}]}, {"text": "The improvement in performance on the clustering task can probably be put down to the excessive dimensionality (= number of headtree contexts) of the input space in the case of the raw data.", "labels": [], "entities": []}, {"text": "Reduction of this space using a latent variable model appears to make the clustering more effective.", "labels": [], "entities": []}, {"text": "On the other hand, achieving this dimensionality reduction requires preserving the strongest, typically syntactic, dependencies and discarding weaker, frequently semantic, dependencies with the result that performance on semantic similarity tasks degrades.", "labels": [], "entities": []}, {"text": "The predicted noun-verb similarities for both approaches is only weakly correlated with the human ratings, which we ascribe to the fact that neither model has a mechanism for finding the commonalities between words found in distinct sets of syntactic contexts.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Correlations of model cosines with hu- man similarity ratings on the noun-verb (NV) and  WordSim353 (WS353) datasets, alongside many- to-one (MTO) measures of cluster quality on the  POS clustering task, for the raw data (raw), the  simple undecomposed model (v), the symmetric  undecomposed model (a), the direct sum model  (\u00af a \u2295 \u00af  b) and the tensor product model (\u02dc a \u2297 \u02dc  b).", "labels": [], "entities": [{"text": "WordSim353 (WS353) datasets", "start_pos": 99, "end_pos": 126, "type": "DATASET", "confidence": 0.8868263244628907}, {"text": "POS clustering task", "start_pos": 193, "end_pos": 212, "type": "TASK", "confidence": 0.7269437710444132}]}]}