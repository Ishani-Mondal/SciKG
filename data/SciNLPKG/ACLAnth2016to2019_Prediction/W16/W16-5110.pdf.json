{"title": [{"text": "BioDCA Identifier: A System for Automatic Identification of Discourse Connective and Arguments from Biomedical Text", "labels": [], "entities": [{"text": "BioDCA", "start_pos": 0, "end_pos": 6, "type": "DATASET", "confidence": 0.8336822986602783}, {"text": "Automatic Identification of Discourse Connective and Arguments from Biomedical Text", "start_pos": 32, "end_pos": 115, "type": "TASK", "confidence": 0.7480888217687607}]}], "abstractContent": [{"text": "This paper describes a Natural language processing system developed for automatic identification of explicit connectives, its sense and arguments.", "labels": [], "entities": [{"text": "automatic identification of explicit connectives", "start_pos": 72, "end_pos": 120, "type": "TASK", "confidence": 0.7438931345939637}]}, {"text": "Prior work has shown that the difference in usage of connectives across corpora affects the cross domain connective identification task negatively.", "labels": [], "entities": [{"text": "cross domain connective identification task", "start_pos": 92, "end_pos": 135, "type": "TASK", "confidence": 0.6724650502204895}]}, {"text": "Hence the development of domain specific discourse parser has become indispensable.", "labels": [], "entities": [{"text": "domain specific discourse parser", "start_pos": 25, "end_pos": 57, "type": "TASK", "confidence": 0.641854353249073}]}, {"text": "Here, we present a corpus annotated with discourse relations on Medline abstracts.", "labels": [], "entities": [{"text": "Medline abstracts", "start_pos": 64, "end_pos": 81, "type": "DATASET", "confidence": 0.9150269627571106}]}, {"text": "Kappa score is calculated to check the annotation quality of our corpus.", "labels": [], "entities": [{"text": "Kappa score", "start_pos": 0, "end_pos": 11, "type": "METRIC", "confidence": 0.6818610727787018}]}, {"text": "The previous works on discourse analysis in bio-medical data have concentrated only on the identification of connectives and hence we have developed an end-end parser for connective and argument identification using Conditional Random Fields algorithm.", "labels": [], "entities": [{"text": "discourse analysis", "start_pos": 22, "end_pos": 40, "type": "TASK", "confidence": 0.7159685492515564}, {"text": "connective and argument identification", "start_pos": 171, "end_pos": 209, "type": "TASK", "confidence": 0.6205625683069229}]}, {"text": "The type and sub-type of the connective sense is also identified.", "labels": [], "entities": []}, {"text": "The results obtained are encouraging.", "labels": [], "entities": []}], "introductionContent": [{"text": "Due to advancements in bio-medical field, a large number of bio-medical literatures are available.", "labels": [], "entities": []}, {"text": "It is crucial to extract knowledge from these literatures, to prevent the loss of important findings required for progression in bio-medical field.", "labels": [], "entities": []}, {"text": "For extracting the information from the text, the text needs to be analyzed linguistically and it is absolutely essential to add such linguistic information to the text for future research.", "labels": [], "entities": []}, {"text": "Natural language processing (NLP) methods are being widely used to analyse bio-medical text by performing tasks like automatic summarization, translation, named entity recognition, discourse analysis, speech recognition, etc.,.", "labels": [], "entities": [{"text": "Natural language processing (NLP)", "start_pos": 0, "end_pos": 33, "type": "TASK", "confidence": 0.738061711192131}, {"text": "summarization", "start_pos": 127, "end_pos": 140, "type": "TASK", "confidence": 0.8634012341499329}, {"text": "named entity recognition", "start_pos": 155, "end_pos": 179, "type": "TASK", "confidence": 0.577438622713089}, {"text": "discourse analysis", "start_pos": 181, "end_pos": 199, "type": "TASK", "confidence": 0.7525948584079742}, {"text": "speech recognition", "start_pos": 201, "end_pos": 219, "type": "TASK", "confidence": 0.8171226382255554}]}, {"text": "Discourse analysis is one such fundamental topic in NLP domain that makes a text linguistically rich.", "labels": [], "entities": [{"text": "Discourse analysis", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.875763326883316}]}, {"text": "Discourse analysis is the study of the relation between phrase, clauses or sentences in a text.", "labels": [], "entities": [{"text": "Discourse analysis", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.8124983608722687}]}, {"text": "The basic units of discourse relations are discourse markers and their arguments.", "labels": [], "entities": []}, {"text": "Discourse markers are words or phrases that establish a relation between two discourse units thereby connecting two events.", "labels": [], "entities": []}, {"text": "Example a) Embryonic Stem cells have a high mitotic index and form colonies.", "labels": [], "entities": []}, {"text": "So, experiments can be completed rapidly and easily.", "labels": [], "entities": []}, {"text": "b) Clinical lung cancers containing a higher abundance of ALDH and CD44 co expressing cells were associated with lower recurrence free survival.", "labels": [], "entities": [{"text": "recurrence free survival", "start_pos": 119, "end_pos": 143, "type": "METRIC", "confidence": 0.9434061845143636}]}, {"text": "In the above Example 1 (a) \"so\" is the discourse connective that indicates a relation between two discourse units.", "labels": [], "entities": []}, {"text": "These discourse units are labeled as arguments.", "labels": [], "entities": []}, {"text": "It is not easy to identify the discourse connectives, as all connectives are not discourse markers.", "labels": [], "entities": []}, {"text": "In some cases it acts as conjunction simply unifying two words.", "labels": [], "entities": []}, {"text": "Consider the Example 1 (b), where \"and\" acts as a conjunction connecting two bio-medical named entities \"ALDH\" and \"CD44 co expressing cells\".", "labels": [], "entities": []}, {"text": "The intended goal of our present work is to study the \"discourse relation\" in Medline abstracts and develop a system to automatically extract these relations. has examined the structural and linguistic aspects of abstracts and bodies of full text articles.", "labels": [], "entities": []}, {"text": "Their work shows that full parsing of article bodies is more difficult than abstracts as article bodies has longer sentences.", "labels": [], "entities": [{"text": "parsing of article bodies", "start_pos": 27, "end_pos": 52, "type": "TASK", "confidence": 0.8132316768169403}]}, {"text": "They also assessed the incidence of conjunctions in abstracts and article bodies.", "labels": [], "entities": []}, {"text": "The difference between abstracts and bodies was not statistically significant with only slightly more conjunction in article bodies than in abstracts.", "labels": [], "entities": []}, {"text": "Hence, we used abstracts to develop the system instead of whole articles.", "labels": [], "entities": []}, {"text": "Since abstracts give an overview of a work, the sentences in the abstract need to be coherent.", "labels": [], "entities": []}, {"text": "Hence it is well connected by connectives.", "labels": [], "entities": []}, {"text": "The occurrence and type of discourse connectives in the bio-medical domain vary from other domain.", "labels": [], "entities": []}, {"text": "Example Furthermore, juglone blocked the adipogenic medium-induced activation of PPAR, C/EBP, C/EBP, and ERK pathways, which was rescued by Ad-PIN1 infection.", "labels": [], "entities": []}, {"text": "In summary, the present study shows for the first time that PIN1 acts as a significant modulator of odontogenic and adipogenic differentiation of HDPSCs, and may have clinical implications for regenerative dentistry.", "labels": [], "entities": []}, {"text": "In the above Example 2, the discourse marker \"In summary\" occurs commonly in bio-medical abstracts, whereas in general domain it is used to a lesser extent.", "labels": [], "entities": []}, {"text": "There are many such connectives that occur in biomedical domain and mayor may not occur in other domains.", "labels": [], "entities": []}, {"text": "Also, work done by show that the classifier trained on open domain performs poorly on bio-medical domain.", "labels": [], "entities": []}, {"text": "Hence there is a demand to spring up a discourse parser for bio-medical domain.", "labels": [], "entities": []}, {"text": "Our work makes a substantial contribution to the development of the discourse annotated corpus for bio-medical domain.", "labels": [], "entities": []}, {"text": "At this period, there is no end-end discourse parser available for automatically identifying the connectives, sense and its arguments in bio-medical domain; hence we have developed a discourse parser for explicit relation identification from bio-medical corpus.", "labels": [], "entities": [{"text": "relation identification", "start_pos": 213, "end_pos": 236, "type": "TASK", "confidence": 0.6796182841062546}]}, {"text": "This system can further be used in NLP tasks like machine comprehension, extraction of semantic relations, co-reference resolution, etc.", "labels": [], "entities": [{"text": "extraction of semantic relations", "start_pos": 73, "end_pos": 105, "type": "TASK", "confidence": 0.8353592902421951}, {"text": "co-reference resolution", "start_pos": 107, "end_pos": 130, "type": "TASK", "confidence": 0.7398364543914795}]}, {"text": "In the next section, works related to discourse analysis are detailed.", "labels": [], "entities": [{"text": "discourse analysis", "start_pos": 38, "end_pos": 56, "type": "TASK", "confidence": 0.7901760339736938}]}, {"text": "Section 3 describes the annotation task.", "labels": [], "entities": []}, {"text": "Section 4 explains the method used.", "labels": [], "entities": []}, {"text": "Results are demonstrated and discussed in section 5.", "labels": [], "entities": []}, {"text": "We conclude and outline our future work in section 6.", "labels": [], "entities": []}], "datasetContent": [{"text": "The annotated corpus was preprocessed, before training it using ML algorithms.", "labels": [], "entities": []}, {"text": "The sentences were tokenized and PoS tags and chunks were added using the GENIA tagger ().", "labels": [], "entities": [{"text": "GENIA", "start_pos": 74, "end_pos": 79, "type": "DATASET", "confidence": 0.774208664894104}]}, {"text": "After analyzing the corpus, features were extracted.", "labels": [], "entities": []}, {"text": "Based on the extracted features, language models were built using CRFs algorithm.", "labels": [], "entities": []}, {"text": "We used CRF++ tool (, an open source implementation of CRFs algorithm.", "labels": [], "entities": []}, {"text": "Using the language model the explicit connectives, its sense and argument boundaries were automatically identified from the test set.", "labels": [], "entities": []}, {"text": "The experiments were performed as two tasks.", "labels": [], "entities": []}, {"text": "Connective classification and sense identification: In the first task, the system was trained for classification of connectives.", "labels": [], "entities": [{"text": "Connective classification", "start_pos": 0, "end_pos": 25, "type": "TASK", "confidence": 0.782636970281601}, {"text": "sense identification", "start_pos": 30, "end_pos": 50, "type": "TASK", "confidence": 0.7133744359016418}]}, {"text": "Using the features described in section 4.1, the model was built for connective identification.", "labels": [], "entities": [{"text": "connective identification", "start_pos": 69, "end_pos": 94, "type": "TASK", "confidence": 0.8379562497138977}]}, {"text": "The built model was used for identifying the connectives from the test data.", "labels": [], "entities": []}, {"text": "Further, post-processing rules were applied to improve the system's performance.", "labels": [], "entities": []}, {"text": "After classifying the tokens as connectives and non-connectives, sense of the connectives were identified.", "labels": [], "entities": []}, {"text": "In our work we have also identified the type and sub-type of the connective sense.", "labels": [], "entities": []}, {"text": "We developed one-stage model and multi-stage model to identify the sense.", "labels": [], "entities": []}, {"text": "For one stage model, a single model is developed for all types of sense.", "labels": [], "entities": []}, {"text": "While for multi-stage model, four separate models were developed for each type of sense based on its upper level class.", "labels": [], "entities": []}, {"text": "After identifying the senses separately, the output was combined from each model.", "labels": [], "entities": []}, {"text": "The connectives having overlapping senses were merged based on confidence scores (i.e. sense having large probability).", "labels": [], "entities": []}, {"text": "Argument identification: After identifying the connectives, the second task was performed, where the arguments were identified.", "labels": [], "entities": [{"text": "Argument identification", "start_pos": 0, "end_pos": 23, "type": "TASK", "confidence": 0.9133461117744446}]}, {"text": "To overcome the problem of overlapping sequence, we processed each connective separately for argument identification.", "labels": [], "entities": [{"text": "argument identification", "start_pos": 93, "end_pos": 116, "type": "TASK", "confidence": 0.719371035695076}]}, {"text": "We developed two types of models, first by partitioning these sentences into inter and intra-sentential relations and second as a one-stage model without partitioning the sentences.", "labels": [], "entities": []}, {"text": "Intra-sentential connectives are those that occur within a sentence, while intersentential connectives are those that occur outside the sentence.", "labels": [], "entities": []}, {"text": "For inter-sentential connectives mostly previous sentence acts as argument.", "labels": [], "entities": []}, {"text": "In few cases the arguments span across sentences.", "labels": [], "entities": []}, {"text": "For the one-stage model the output from connective identification was given as such after extracting the features without dividing them as inter-sentential or intra-sentential connectives.", "labels": [], "entities": [{"text": "connective identification", "start_pos": 40, "end_pos": 65, "type": "TASK", "confidence": 0.7761843204498291}]}, {"text": "We developed gold standard parser and automatic parser for argument identification using features mentioned in . For gold standard parser the gold standard connectives were used to train the system.", "labels": [], "entities": [{"text": "argument identification", "start_pos": 59, "end_pos": 82, "type": "TASK", "confidence": 0.7409174144268036}]}, {"text": "For automatic parser the output from the connective identification task was fed as input to the argument identification task.", "labels": [], "entities": [{"text": "connective identification task", "start_pos": 41, "end_pos": 71, "type": "TASK", "confidence": 0.7751818398634592}, {"text": "argument identification task", "start_pos": 96, "end_pos": 124, "type": "TASK", "confidence": 0.7986374696095785}]}, {"text": "For identifying the arguments we followed the method used by.", "labels": [], "entities": []}, {"text": "They presented their work on automatic identification of the cause-effect relation from Tamil text.", "labels": [], "entities": [{"text": "automatic identification", "start_pos": 29, "end_pos": 53, "type": "TASK", "confidence": 0.5609976202249527}]}, {"text": "In their work they developed separate models for each boundary.", "labels": [], "entities": []}, {"text": "Similarly, we built 4 models for each boundary of the arguments, i.e. identification of arg1 start and end and arg2 start and end.", "labels": [], "entities": []}, {"text": "The argument boundaries were identified in the following series, arg2 start, arg1 end, arg1 start and arg2 end.", "labels": [], "entities": [{"text": "arg1 start", "start_pos": 87, "end_pos": 97, "type": "METRIC", "confidence": 0.9568018019199371}, {"text": "arg2 end", "start_pos": 102, "end_pos": 110, "type": "METRIC", "confidence": 0.961131364107132}]}, {"text": "The output from one model is fed as input to the next model.", "labels": [], "entities": []}, {"text": "The choice of order of identification of bounds was made with the idea that it is easier to identify the boundaries that are close to the connective.", "labels": [], "entities": []}, {"text": "After identifying the boundaries, the outputs were merged.", "labels": [], "entities": []}, {"text": "Thus connective, sense and arguments were identified.", "labels": [], "entities": []}, {"text": "The results are detailed in the next section.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 3. The  connectives are mostly conjunction and hence the PoS features contribute most to the identification of  connectives. Chunk features help to identify the boundary of the connectives and arguments. Since a  discourse connective connects two clauses, clause start and end can be used as feature for connective  identification. For sense identification, we have used syntactic features. In addition to features used for  connective identification, connective itself is used as a feature for identifying the sense of the connective.", "labels": [], "entities": [{"text": "connective  identification", "start_pos": 311, "end_pos": 337, "type": "TASK", "confidence": 0.7430428266525269}, {"text": "sense identification", "start_pos": 343, "end_pos": 363, "type": "TASK", "confidence": 0.7230417281389236}, {"text": "connective identification", "start_pos": 432, "end_pos": 457, "type": "TASK", "confidence": 0.7229757457971573}]}, {"text": " Table 2: Features used for connective identification (syntactic and sense).", "labels": [], "entities": [{"text": "connective identification", "start_pos": 28, "end_pos": 53, "type": "TASK", "confidence": 0.7842349708080292}]}, {"text": " Table 4: Results for connective classification.", "labels": [], "entities": [{"text": "connective classification", "start_pos": 22, "end_pos": 47, "type": "TASK", "confidence": 0.9400157034397125}]}, {"text": " Table 5: Results for sense identification in %.", "labels": [], "entities": [{"text": "sense identification", "start_pos": 22, "end_pos": 42, "type": "TASK", "confidence": 0.8645882308483124}]}, {"text": " Table 6: Results for intra-sentential argument identification in %.", "labels": [], "entities": [{"text": "intra-sentential argument identification", "start_pos": 22, "end_pos": 62, "type": "TASK", "confidence": 0.692506730556488}]}, {"text": " Table 7: Results for inter-sentential argument identification in %.", "labels": [], "entities": [{"text": "inter-sentential argument identification", "start_pos": 22, "end_pos": 62, "type": "TASK", "confidence": 0.6919135451316833}]}, {"text": " Table 8: Results for one-stage model argument identification in%.", "labels": [], "entities": [{"text": "one-stage model argument identification", "start_pos": 22, "end_pos": 61, "type": "TASK", "confidence": 0.609588585793972}]}]}