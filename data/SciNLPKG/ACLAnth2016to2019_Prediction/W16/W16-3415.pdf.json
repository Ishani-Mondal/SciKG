{"title": [{"text": "Interactive-Predictive Translation based on Multiple Word-Segments", "labels": [], "entities": [{"text": "Interactive-Predictive Translation", "start_pos": 0, "end_pos": 34, "type": "TASK", "confidence": 0.619154617190361}]}], "abstractContent": [{"text": "Current machine translation systems require human revision to produce high-quality translations.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 8, "end_pos": 27, "type": "TASK", "confidence": 0.727615088224411}]}, {"text": "This is achieved through a post-editing processor by means of an interactive human computer collaboration.", "labels": [], "entities": []}, {"text": "Most protocols belonging to the last scenario follow a left-to-right strategy, where the prefix of the translation is iteratively increased by successive validations and corrections made by the user.", "labels": [], "entities": []}, {"text": "In this work, we propose anew interactive protocol which allows the user to validate all correct word sequences in the translation generated by the system, breaking the left-to-right barrier.", "labels": [], "entities": []}, {"text": "We evaluated our proposal through simulated experiments, obtaining large reductions of the human effort.", "labels": [], "entities": []}], "introductionContent": [{"text": "Machine Translation (MT) technology is still far from producing perfect translations.", "labels": [], "entities": [{"text": "Machine Translation (MT)", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.8772324442863464}]}, {"text": "Therefore, translation errors must be corrected by a human in a later post-editing stage.", "labels": [], "entities": [{"text": "translation", "start_pos": 11, "end_pos": 22, "type": "TASK", "confidence": 0.9583840370178223}]}, {"text": "The Interactive-Predictive Machine Translation (IMT) field arose as an alternative to classic post-editing systems, aiming to reduce human post-editing effort and increase efficiency.", "labels": [], "entities": [{"text": "Interactive-Predictive Machine Translation (IMT)", "start_pos": 4, "end_pos": 52, "type": "TASK", "confidence": 0.7860284596681595}]}, {"text": "This paradigm strives for combining the knowledge of a human translator and the efficiency of an MT system.", "labels": [], "entities": [{"text": "MT", "start_pos": 97, "end_pos": 99, "type": "TASK", "confidence": 0.9823445081710815}]}, {"text": "Notable contributions to IMT technology were carried out around the TransType (), TransType2 () projects, among others.", "labels": [], "entities": [{"text": "IMT", "start_pos": 25, "end_pos": 28, "type": "TASK", "confidence": 0.9501973390579224}]}, {"text": "Especially interesting is the so-called prefix-based IMT ().", "labels": [], "entities": []}, {"text": "In this approach, the user corrected the first wrong word (from left-to-right) of the translation suggested by the system.", "labels": [], "entities": []}, {"text": "Then, the system proposed an alternative hypothesis, compatible with the user feedback.", "labels": [], "entities": []}, {"text": "A cumbersome phenomenon noticed in this protocol happened when the non-validated part of the sentence contained correct words.", "labels": [], "entities": []}, {"text": "If such words were modified by the system in following predictions, the user had to edit words that were correct in previous iterations.", "labels": [], "entities": []}, {"text": "Therefore, the effort made by the user was increased and the system had an annoying behavior.", "labels": [], "entities": []}, {"text": "To overcome this weakness, we propose anew IMT approach which allows the user to select, at each interaction, all correctly translated word segments.", "labels": [], "entities": [{"text": "IMT", "start_pos": 43, "end_pos": 46, "type": "TASK", "confidence": 0.9605816602706909}]}, {"text": "Hence, correct parts of the current translation are kept in successive hypothesis produced during the human-machine interaction, reducing the number of corrections required and avoiding the aforementioned issue.", "labels": [], "entities": []}, {"text": "This approach relies on the idea from of breaking down the prefix constraint.", "labels": [], "entities": []}, {"text": "The proposed protocol shares some similarities within that we select word segments from a translation hypothesis.", "labels": [], "entities": []}, {"text": "However, on the one hand, our protocol contains more types of user interactions such as word corrections and word deletions (see Section 2); and, on the other hand, we have different goals in mind: aim at increasing translation quality with the help of a human user, and we aim at reducing the human effort of generating a translation in an IMT framework.", "labels": [], "entities": [{"text": "word corrections", "start_pos": 88, "end_pos": 104, "type": "TASK", "confidence": 0.6979248374700546}]}, {"text": "The rest of this paper is structured as follows: Section 2 describes our segment-based IMT approach.", "labels": [], "entities": [{"text": "IMT", "start_pos": 87, "end_pos": 90, "type": "TASK", "confidence": 0.8787669539451599}]}, {"text": "After that, in Section 3, we report the experiments conducted in order to assess our proposal and the results of those experiments.", "labels": [], "entities": []}, {"text": "Finally, conclusions of the work are drawn in Section 4.", "labels": [], "entities": []}], "datasetContent": [{"text": "Since the evaluation with human agents is too slow and expensive to be applied frequently during system development, we carried out an automatic evaluation with simulated users.", "labels": [], "entities": []}, {"text": "For this evaluation, we considered the references in the corpora as the translations the user desires.", "labels": [], "entities": []}, {"text": "Furthermore, without loss of generality and for the sake of simplicity, we assumed that the user always corrected the left-most wrong word.", "labels": [], "entities": [{"text": "simplicity", "start_pos": 60, "end_pos": 70, "type": "METRIC", "confidence": 0.9760237336158752}]}, {"text": "At each iteration of the IMT session, we selected those segments that were common with the reference.", "labels": [], "entities": [{"text": "IMT session", "start_pos": 25, "end_pos": 36, "type": "TASK", "confidence": 0.8916423320770264}]}, {"text": "After that, following a left-to-right order, we compared each word of the current translation with those of the reference.", "labels": [], "entities": []}, {"text": "When we found a different word in translation and reference, if that reference word was the first one of the next selected segment, we deleted all the words between those two segments; otherwise, we input that word (merging all previous segments into one).", "labels": [], "entities": []}, {"text": "Once translation and reference were the same, we moved onto the next sentence.", "labels": [], "entities": [{"text": "translation", "start_pos": 5, "end_pos": 16, "type": "TASK", "confidence": 0.9340914487838745}]}, {"text": "shows the user-effort results of our segment-based protocol against the prefixbased approach.", "labels": [], "entities": []}, {"text": "Prefix-based results were obtained following the work of and are similar to those reported on the literature).", "labels": [], "entities": [{"text": "Prefix-based", "start_pos": 0, "end_pos": 12, "type": "METRIC", "confidence": 0.989777147769928}]}, {"text": "The quality of the initial translation is also displayed as an indicative of the difficulty of each task.", "labels": [], "entities": []}, {"text": "Our proposal clearly improves prefix-based IMT in terms of user physical effort of typing corrections.", "labels": [], "entities": [{"text": "IMT", "start_pos": 43, "end_pos": 46, "type": "TASK", "confidence": 0.8027918934822083}]}, {"text": "The WSR is always reduced, yielding diminishes up to 29 points.", "labels": [], "entities": [{"text": "WSR", "start_pos": 4, "end_pos": 7, "type": "METRIC", "confidence": 0.9502315521240234}]}, {"text": "This reduction of typing effort comes with an increase in the number of mouse actions (from 4 up to 6.5 points of MAR), which is always smaller than the effort reduction.", "labels": [], "entities": [{"text": "MAR", "start_pos": 114, "end_pos": 117, "type": "METRIC", "confidence": 0.9701833724975586}]}, {"text": "An exception to this comes with the En-Zh language pair since, due to Chinese nature, words have fewer number of characters, which penalizes MAR metric.", "labels": [], "entities": [{"text": "MAR metric", "start_pos": 141, "end_pos": 151, "type": "METRIC", "confidence": 0.893915444612503}]}, {"text": "This penalization results in a greater increase in MAR, although this increase is still smaller than the effort reduction.", "labels": [], "entities": [{"text": "MAR", "start_pos": 51, "end_pos": 54, "type": "METRIC", "confidence": 0.9602979421615601}]}, {"text": "Moreover, as mentioned before, WSR and MAR account for different phenomena and thus have different cost from a human point of view ().", "labels": [], "entities": [{"text": "WSR", "start_pos": 31, "end_pos": 34, "type": "TASK", "confidence": 0.5629795789718628}]}, {"text": "Therefore, the physical effort is substantially decreased, while the cognitive one is slightly increased.", "labels": [], "entities": []}, {"text": "Nonetheless, we need to test these considerations with real human users before reaching to categorical conclusions.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Corpora statistics. K denotes thousands and M millions. |S| stands for number of sentences,  |W| for number of words and |V| for size of the vocabulary.", "labels": [], "entities": []}, {"text": " Table 2: Results of our segment-based IMT proposal, in comparison with the prefix-based approach.  The quality of the initial translation is shown as an indicative of the difficulty of each task. All  values are reported as percentages.", "labels": [], "entities": [{"text": "IMT", "start_pos": 39, "end_pos": 42, "type": "TASK", "confidence": 0.8414186835289001}]}]}