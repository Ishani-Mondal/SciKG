{"title": [{"text": "Part of Speech Tagging for Code Switched Data", "labels": [], "entities": [{"text": "Speech Tagging for Code Switched Data", "start_pos": 8, "end_pos": 45, "type": "TASK", "confidence": 0.763185515999794}]}], "abstractContent": [{"text": "We address the problem of Part of Speech tagging (POS) in the context of linguistic code switching (CS).", "labels": [], "entities": [{"text": "Part of Speech tagging (POS)", "start_pos": 26, "end_pos": 54, "type": "TASK", "confidence": 0.8183053391320365}, {"text": "linguistic code switching (CS)", "start_pos": 73, "end_pos": 103, "type": "TASK", "confidence": 0.8062315682570139}]}, {"text": "CS is the phenomenon where a speaker switches between two languages or variants of the same language within or across utterances, known as intra-sentential or inter-sentential CS, respectively.", "labels": [], "entities": []}, {"text": "Processing CS data is especially challenging in intra-sentential data given state of the art monolin-gual NLP technology since such technology is geared toward the processing of one language at a time.", "labels": [], "entities": []}, {"text": "In this paper we explore multiple strategies of applying state of the art POS tag-gers to CS data.", "labels": [], "entities": []}, {"text": "We investigate the landscape in two CS language pairs, Spanish-English and Modern Standard Arabic-Arabic dialects.", "labels": [], "entities": []}, {"text": "We compare the use of two POS taggers vs. a unified tagger trained on CS data.", "labels": [], "entities": [{"text": "POS taggers", "start_pos": 26, "end_pos": 37, "type": "TASK", "confidence": 0.6422716975212097}]}, {"text": "Our results show that applying a machine learning framework using two state fof the art POS taggers achieves better performance compared to all other approaches that we investigate.", "labels": [], "entities": [{"text": "POS taggers", "start_pos": 88, "end_pos": 99, "type": "TASK", "confidence": 0.6973009407520294}]}], "introductionContent": [{"text": "Linguistic Code Switching (CS) is a phenomenon that occurs when multilingual speakers alternate between two or more languages or dialects.", "labels": [], "entities": [{"text": "Linguistic Code Switching (CS)", "start_pos": 0, "end_pos": 30, "type": "TASK", "confidence": 0.7733103980620702}]}, {"text": "CS is noticeable in countries that have large immigrant groups, naturally leading to bilingualism.", "labels": [], "entities": []}, {"text": "Typically people who code switch master two (or more) languages: a common first language (lang1) and another prevalent language as a second language (lang2).", "labels": [], "entities": []}, {"text": "The languages could be completely distinct such as Mandarin and English, or Hindi and English, or they can be variants of one another such as in the case of Modern Standard Arabic (MSA) and Arabic regional dialects (e.g. Egyptian dialect-EGY).", "labels": [], "entities": []}, {"text": "CS is traditionally prevalent in spoken language but with the proliferation of social media such as Facebook, Instagram, and Twitter, CS is becoming ubiquitous in written modalities and genres () CS can be observed in different linguistic levels of representation for different language pairs: phonological, morphological, lexical, syntactic, semantic, and discourse/pragmatic.", "labels": [], "entities": []}, {"text": "It may occur within (intra-sentential) or across utterances (inter-sentential).", "labels": [], "entities": []}, {"text": "For example, the following Arabic excerpt exhibits both lexical and syntactic CS.", "labels": [], "entities": []}, {"text": "The speaker alternates between two variants of Arabic MSA and EGY.", "labels": [], "entities": [{"text": "EGY", "start_pos": 62, "end_pos": 65, "type": "METRIC", "confidence": 0.6127370595932007}]}, {"text": "Arabic Intra-sentential CS: 1 wlkn AjhztnA AljnA}yp lAnhA m$ xyAl Elmy lm tjd wlw mElwmp wAHdp.", "labels": [], "entities": []}, {"text": "English Translation: Since our crime investigation departments are not dealing with science fiction, they did not find a single piece of information.", "labels": [], "entities": []}, {"text": "The speaker in the example switched from MSA to EGY dialect by using the word m$/not which is an Egyptian negation particle, while s/he could have used the MSA word lyst/not.", "labels": [], "entities": []}, {"text": "The span of the CS in this example is only one token, but it can be more than one example.", "labels": [], "entities": []}, {"text": "Such divergence causes serious problems for automatic analysis.", "labels": [], "entities": [{"text": "automatic analysis", "start_pos": 44, "end_pos": 62, "type": "TASK", "confidence": 0.8023489117622375}]}, {"text": "CS poses serious challenges for language technologies, including parsing, Information Extraction (IE), Machine Translation (MT), Information Retrieval (IR), and others.", "labels": [], "entities": [{"text": "Information Extraction (IE)", "start_pos": 74, "end_pos": 101, "type": "TASK", "confidence": 0.7779835820198059}, {"text": "Machine Translation (MT)", "start_pos": 103, "end_pos": 127, "type": "TASK", "confidence": 0.8531315445899963}, {"text": "Information Retrieval (IR)", "start_pos": 129, "end_pos": 155, "type": "TASK", "confidence": 0.8432331323623657}]}, {"text": "The majority of these technologies are trained and exposed to one language at a time.", "labels": [], "entities": []}, {"text": "However, performance of these technologies degrades sharply when exposed to CS data.", "labels": [], "entities": []}, {"text": "In this paper, we address the problem of part of Speech tagging (POS) for CS data on the intrasentential level.", "labels": [], "entities": [{"text": "Speech tagging (POS)", "start_pos": 49, "end_pos": 69, "type": "TASK", "confidence": 0.798740667104721}]}, {"text": "POS tagging is the task where each word in text is contextually labeled with grammatical labels such as, noun, verb, proposition, adjective, etc.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 0, "end_pos": 11, "type": "TASK", "confidence": 0.8151983320713043}]}, {"text": "We focus on two language pairs SpanishEnglish (SPA-ENG) and Modern Standard Arabicand the Egyptian Arabic dialect (MSA-EGY).", "labels": [], "entities": []}, {"text": "We use the same POS tag sets for both language pairs, the Universal POS tagset).", "labels": [], "entities": [{"text": "Universal POS tagset", "start_pos": 58, "end_pos": 78, "type": "DATASET", "confidence": 0.7207959691683451}]}, {"text": "We examine various strategies to take advantage of the available monolingual resources for each language in the language pairs and compare against dedicated POS taggers trained on CS data for each of the language pairs.", "labels": [], "entities": []}, {"text": "Our contributions are the following: \u2022 We explore different strategies to leverage monolingual resources for POS tagging CS data.", "labels": [], "entities": [{"text": "POS tagging CS data", "start_pos": 109, "end_pos": 128, "type": "TASK", "confidence": 0.8822575658559799}]}, {"text": "\u2022 We present the first empirical evaluation on POS tagging with two different language pairs.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 47, "end_pos": 58, "type": "TASK", "confidence": 0.8959603011608124}]}, {"text": "All of the previous work focused on a single language pair combination.", "labels": [], "entities": []}], "datasetContent": [{"text": "COMB1:LID-MonoLT: Language identification followed by monolingual tagging Given a sentence, we apply a token level language identification We are grateful to the MADAMIRA team for providing us with the MADAMIRA training code to carryout our experiments.", "labels": [], "entities": [{"text": "LID-MonoLT", "start_pos": 6, "end_pos": 16, "type": "METRIC", "confidence": 0.9659624099731445}, {"text": "Language identification", "start_pos": 18, "end_pos": 41, "type": "TASK", "confidence": 0.7426438927650452}, {"text": "MADAMIRA training code", "start_pos": 202, "end_pos": 224, "type": "DATASET", "confidence": 0.7944837411244711}]}, {"text": "process to the words in the sentence.", "labels": [], "entities": []}, {"text": "The chunks of words identified as lang1 are processed by the monolingual lang1 POS tagger and chunks of words identified as lang2 are processed by the monolingual lang2 POS tagger.", "labels": [], "entities": []}, {"text": "Finally we integrate the POS tags from both monolingual taggers creating the POS tag sequence for the sentence.", "labels": [], "entities": []}, {"text": "shows a diagram representing this approach for the MSA-EGY language pair.", "labels": [], "entities": []}, {"text": "For MSA-EGY, we used the Automatic Identification of Dialectal Arabic (AIDA2) tool (Al-) to perform token level language identification for the EGY and MSA tokens in context.", "labels": [], "entities": [{"text": "token level language identification", "start_pos": 100, "end_pos": 135, "type": "TASK", "confidence": 0.67513108253479}]}, {"text": "It takes plain Arabic text in Arabic UTF8 encoding or Buckwalter encoding as input and outputs: 1) Class Identification (CI) of the input text to specify whether the tokens are MSA, EGY, as well as other information such as name entity, foreign word, or unknown labels per token.", "labels": [], "entities": [{"text": "Class Identification (CI)", "start_pos": 99, "end_pos": 124, "type": "METRIC", "confidence": 0.6521799087524414}]}, {"text": "Furthermore, it provides the results with a confidence score; 2)Dialect Classification (DC) of the input text to specify whether it is Egyptian.", "labels": [], "entities": [{"text": "Dialect Classification (DC)", "start_pos": 64, "end_pos": 91, "type": "METRIC", "confidence": 0.8158211946487427}]}, {"text": "For SPA-ENG, we trained language models (LM) on English and Spanish data to assign Language IDs to each token in context.", "labels": [], "entities": [{"text": "SPA-ENG", "start_pos": 4, "end_pos": 11, "type": "TASK", "confidence": 0.9347090721130371}]}, {"text": "We trained 6-gram character language models using the SRILM Toolkit (.", "labels": [], "entities": [{"text": "SRILM Toolkit", "start_pos": 54, "end_pos": 67, "type": "DATASET", "confidence": 0.9440862834453583}]}, {"text": "The English language model was trained on the AFP section of the English GigaWord ( while the Spanish language model was trained on the AFP section of the Spanish GigaWord ().", "labels": [], "entities": [{"text": "AFP", "start_pos": 46, "end_pos": 49, "type": "DATASET", "confidence": 0.9342772364616394}, {"text": "English GigaWord", "start_pos": 65, "end_pos": 81, "type": "DATASET", "confidence": 0.8419817984104156}, {"text": "AFP section of the Spanish GigaWord", "start_pos": 136, "end_pos": 171, "type": "DATASET", "confidence": 0.9015403787295023}]}, {"text": "COMB2:MonoLT-LID: Monolingual tagging then Language ID Similar to Condition COMB1, this experimental condition applies language ID in addition to monolingual tagging, however the order is reversed.", "labels": [], "entities": [{"text": "COMB2", "start_pos": 0, "end_pos": 5, "type": "DATASET", "confidence": 0.8633668422698975}]}, {"text": "In this condition we apply the two monolingual language specific POS taggers to the input CS sentence as a whole, then apply the language id component to the sentence, and then choose the POS tags assigned by the respective POS tagger per token as per its language id tag.", "labels": [], "entities": []}, {"text": "The difference between this condition and condition 1 is that the monolingual POS tagger is processing an entire sentence rather than a chunk.", "labels": [], "entities": [{"text": "POS tagger", "start_pos": 78, "end_pos": 88, "type": "TASK", "confidence": 0.6683161109685898}]}, {"text": "It should be highlighted that all four monolingual POS taggers (ENG, SPA, MSA, EGY) are trained as sequence taggers expecting full sentence data as input.", "labels": [], "entities": [{"text": "POS taggers", "start_pos": 51, "end_pos": 62, "type": "TASK", "confidence": 0.6846647709608078}]}, {"text": "shows a diagram representing this approach Graphic representation of the COMB2:MonoLT-LID approach.", "labels": [], "entities": [{"text": "COMB2", "start_pos": 73, "end_pos": 78, "type": "DATASET", "confidence": 0.8761836886405945}]}, {"text": "INT1:CSD In this condition, we train a supervised ML framework on exclusively code switched POS manually annotated data.", "labels": [], "entities": [{"text": "INT1", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.7641065120697021}]}, {"text": "In the case of Arabic, we retrain a MADAMIRA model exclusively with the CS data extracted from ARZ1-5 training data, yielding a MADAMIRA-CS model.", "labels": [], "entities": [{"text": "ARZ1-5 training data", "start_pos": 95, "end_pos": 115, "type": "DATASET", "confidence": 0.9079698522885641}]}, {"text": "For SPA-ENG, we trained a CS model using TreeTagger.", "labels": [], "entities": [{"text": "SPA-ENG", "start_pos": 4, "end_pos": 11, "type": "TASK", "confidence": 0.8517611622810364}]}, {"text": "This provides consistency to the experimental setup but also allows us to compare the COMB and INT approaches.", "labels": [], "entities": [{"text": "COMB", "start_pos": 86, "end_pos": 90, "type": "METRIC", "confidence": 0.4930442273616791}]}, {"text": "For MSA-EGY, we use the LDC Egyptian Arabic Treebanks 1-5 (ARZ1-5) (  MADAMIRA-MSA and MADAMIRA-CS based on training data from ARZ1-5 training data portion.", "labels": [], "entities": [{"text": "LDC Egyptian Arabic Treebanks 1-5 (ARZ1-5", "start_pos": 24, "end_pos": 65, "type": "DATASET", "confidence": 0.858303964138031}, {"text": "ARZ1-5 training data", "start_pos": 127, "end_pos": 147, "type": "DATASET", "confidence": 0.8440640767415365}]}, {"text": "AIDA2 has a sentence level identification component that we used to identify the purity of the sentences from the training corpus ARZ1-5 training data.", "labels": [], "entities": [{"text": "AIDA2", "start_pos": 0, "end_pos": 5, "type": "DATASET", "confidence": 0.9091054797172546}, {"text": "training corpus ARZ1-5 training data", "start_pos": 114, "end_pos": 150, "type": "DATASET", "confidence": 0.7173555493354797}]}, {"text": "Specifically, we used the AIDA2 identified EGY sentences for training the MADAMIRA-EGY models, the MSA AIDA2 identified sentences for training the MADAMIRA-MSA models, and the CS identified AIDA2 sentences for training the MADAMIRA-CS models.", "labels": [], "entities": []}, {"text": "For SPA-ENG data, We used two SPA-ENG CS data sets, one is the transcribed conversation used in the work by, referred to as Spanglish.", "labels": [], "entities": [{"text": "SPA-ENG CS data sets", "start_pos": 30, "end_pos": 50, "type": "DATASET", "confidence": 0.7037924751639366}]}, {"text": "The Spanglish data set has \u223c8K tokens and was transcribed and annotated by the authors of that paper.", "labels": [], "entities": [{"text": "Spanglish data set", "start_pos": 4, "end_pos": 22, "type": "DATASET", "confidence": 0.9515989820162455}]}, {"text": "While this is a small data set we include it in our work since it allows us to compare with previous work.", "labels": [], "entities": []}, {"text": "The second SPA-ENG CS data is the Bangor Miami corpus, referred to as Bangor.", "labels": [], "entities": [{"text": "SPA-ENG CS data", "start_pos": 11, "end_pos": 26, "type": "DATASET", "confidence": 0.7062810858090719}, {"text": "Bangor Miami corpus", "start_pos": 34, "end_pos": 53, "type": "DATASET", "confidence": 0.9750643173853556}, {"text": "Bangor", "start_pos": 70, "end_pos": 76, "type": "DATASET", "confidence": 0.986327052116394}]}, {"text": "This corpus is also conversational speech involving a total of 84 speakers living in Miami, FL.", "labels": [], "entities": []}, {"text": "In total, the corpus consists of 242,475 words of text from 35 hours of recorded conversation.", "labels": [], "entities": []}, {"text": "Around 63% of transcribed words are in English, 34% in Spanish and 3% in an indeterminate language.", "labels": [], "entities": []}, {"text": "The transcriptions were carried out manually at the utterance level by a team of transcribers.", "labels": [], "entities": []}, {"text": "They include beginning time and end time of utterance as well as language id for each word.", "labels": [], "entities": []}, {"text": "shows more details about the various data sets.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Data set details.", "labels": [], "entities": []}, {"text": " Table 2: Data set distribution.", "labels": [], "entities": []}, {"text": " Table 3: POS tagging accuracy (%) for monolingual", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 10, "end_pos": 21, "type": "TASK", "confidence": 0.6994883567094803}, {"text": "accuracy", "start_pos": 22, "end_pos": 30, "type": "METRIC", "confidence": 0.9743483066558838}]}, {"text": " Table 4: Accuracy (%) Results for ARZTest Dataset", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9996172189712524}, {"text": "ARZTest Dataset", "start_pos": 35, "end_pos": 50, "type": "DATASET", "confidence": 0.9447380900382996}]}, {"text": " Table 5: Accuracy (%) Results for Bangor Corpus", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9996351003646851}, {"text": "Bangor", "start_pos": 35, "end_pos": 41, "type": "DATASET", "confidence": 0.9904747605323792}]}, {"text": " Table 6: Accuracy (%) Results for Spanglish Corpus", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9995129108428955}]}]}