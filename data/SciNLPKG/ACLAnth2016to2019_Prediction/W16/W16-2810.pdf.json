{"title": [{"text": "Towards Feasible Guidelines for the Annotation of Argument Schemes", "labels": [], "entities": [{"text": "Annotation of Argument Schemes", "start_pos": 36, "end_pos": 66, "type": "TASK", "confidence": 0.7814246416091919}]}], "abstractContent": [{"text": "The annotation of argument schemes represents an important step for argumenta-tion mining.", "labels": [], "entities": [{"text": "argumenta-tion mining", "start_pos": 68, "end_pos": 89, "type": "TASK", "confidence": 0.7066041529178619}]}, {"text": "General guidelines for the annotation of argument schemes, applicable to any topic, are still missing due to the lack of a suitable taxonomy in Argu-mentation Theory and the need for highly trained expert annotators.", "labels": [], "entities": [{"text": "Argu-mentation Theory", "start_pos": 144, "end_pos": 165, "type": "TASK", "confidence": 0.6207561492919922}]}, {"text": "We present a set of guidelines for the annotation of argument schemes, taking as a framework the Argumentum Model of Topics (Rigotti and Morasso, 2010; Rigotti, 2009).", "labels": [], "entities": []}, {"text": "We show that this approach can contribute to solving the theoretical problems, since it offers a hierarchical and finite taxonomy of argument schemes as well as systematic, linguistically-informed criteria to distinguish various types of argument schemes.", "labels": [], "entities": []}, {"text": "We describe a pilot annotation study of 30 persuasive essays using multiple minimally trained non-expert annotators .Our findings from the confusion matrixes pinpoint problematic parts of the guidelines and the underlying annotation of claims and premises.", "labels": [], "entities": []}, {"text": "We conduct a second annotation with refined guidelines and trained annotators on the 10 essays which received the lowest agreement initially.", "labels": [], "entities": []}, {"text": "A significant improvement of the inter-annotator agreement shows that the annotation of argument schemes requires highly trained annotators and an accurate annotation of argumentative components (premises and claims).", "labels": [], "entities": []}], "introductionContent": [{"text": "Argumentation is a type of discourse in which various participants make arguments, presenting some premises in support of certain conclusions, with the aim of negotiating different opinions and reaching consensus).", "labels": [], "entities": [{"text": "Argumentation is a type of discourse in which various participants make arguments, presenting some premises in support of certain conclusions, with the aim of negotiating different opinions and reaching consensus", "start_pos": 0, "end_pos": 212, "type": "Description", "confidence": 0.8195377588272095}]}, {"text": "The automatic identification and evaluation of arguments require three main stages: 1) the identification, segmentation and classification of argumentative discourse units (ADUs), 2) the identification and classification of the relations between ADUs (Peldszus and Stede, 2013a), and 3) the identification of argument schemes, namely the implicit and explicit inferential relations within and across ADUs.", "labels": [], "entities": []}, {"text": "Although considerable steps have been taken towards the first two stages (), the third stage still constitutes a major challenge because large corpora systematically annotated with argument schemes are lacking.", "labels": [], "entities": []}, {"text": "As noticed by, this is due to the proliferation in Argumentation Theory of different taxonomies of argument schemes based on weak distinctive criteria, which makes it difficult to develop intersubjective guidelines for annotation.", "labels": [], "entities": []}, {"text": "In the Araucaria dataset (), for example, two argument scheme sets other than Walton's are used as annotation protocols (.", "labels": [], "entities": [{"text": "Araucaria dataset", "start_pos": 7, "end_pos": 24, "type": "DATASET", "confidence": 0.86757031083107}]}, {"text": "To overcome this problem, the most successfully applied strategy has been to pre-select from existing larger typologies, such as that of, a subset of argument schemes which is most frequent in a particular text genre, domain or context) and provide annotators with critical questions as a means to identify the appropriate scheme.", "labels": [], "entities": []}, {"text": "Such a bottom up approach allows one to improve the identi-82 fication conditions fora set of argument schemes, but it is hardly generalizable since it is restricted to specific argumentative contexts.", "labels": [], "entities": []}, {"text": "Moreover, while critical questions constitute useful tools to evaluate the soundness of arguments (), they are far less suitable as a means to identify the presence of arguments: adopting a normative approach, annotators would conflate the notion of \"making an argument\" with that of \"making a sound argument\", while defeasibility should not be considered as an identification condition for the mere retrieval of arguments in texts.", "labels": [], "entities": []}, {"text": "We hypothesize that the Argumentum Model of Topics (, an enthymematic approach for the study of the inferential configuration of arguments, has the potential to enhance the recognition of argument schemes.", "labels": [], "entities": []}, {"text": "Unlike other approaches, it offers a taxonomic hierarchy of argument schemes based on criteria which are distinctive and mutually exclusive and which appeal to semantic properties of the state of affairs expressed by premises/claims, and not to the logical forms (deductive, inductive, abductive) of arguments, whose boundaries are still debated (Section 2).", "labels": [], "entities": []}, {"text": "However, even if these semantic properties are linguistically encoded, and hence potentially measurable, they might call for some background knowledge in frame semantics to be identified as well as for quite specific analytic skills.", "labels": [], "entities": []}, {"text": "Moreover, the cognitive load requested by the annotation of argument schemes is higher than that needed for the annotation of the argumentative discourse structure (e.g., argument components such as claims and premises, and argument relations such as support/attack).", "labels": [], "entities": []}, {"text": "As stated by with regard to the annotation of argument structure in short texts, the inter-annotator agreement among minimally trained annotators is bound to below due to different personal commitments as well as interpretative skills of the texts.", "labels": [], "entities": [{"text": "annotation of argument structure", "start_pos": 32, "end_pos": 64, "type": "TASK", "confidence": 0.6019357368350029}]}, {"text": "We wanted to test whether this conclusion is valid for our annotation task.", "labels": [], "entities": []}, {"text": "We conducted a pilot annotation study using 9 minimally trained non-expert annotators.", "labels": [], "entities": []}, {"text": "As a corpus we used 30 short persuasive essays already annotated as to premises, claims and support/attack relations.", "labels": [], "entities": []}, {"text": "Section 3 presents the set of guidelines and our study.", "labels": [], "entities": []}, {"text": "Our findings from measuring the interannotator agreement (IAA) support previous findings that annotation of argument schemes would require highly trained annotators (Section 4).", "labels": [], "entities": [{"text": "interannotator agreement (IAA)", "start_pos": 32, "end_pos": 62, "type": "METRIC", "confidence": 0.5665243983268737}]}, {"text": "We also performed an analysis of confusion matrices to see which argument schemes were more difficult to identify, and which parts of the guidelines might need refinement (Section 4).", "labels": [], "entities": []}, {"text": "Another finding of this study is that the identification of argument schemes constitutes a means to refine the annotation of premises and claims (Section 5).", "labels": [], "entities": []}, {"text": "We refined the guidelines and tested them through the annotation of the 10 essays which received the lowest inter-annotator agreement using 2 trained non-expert annotators and 1 expert annotator (Section 6).", "labels": [], "entities": []}, {"text": "The results show an improvement in the inter-annotator agreement.", "labels": [], "entities": []}, {"text": "The confusion matrix suggests that the frequency of nonargumentative relations between premises/claims, claims/major claims highly affects disagreement.", "labels": [], "entities": []}, {"text": "The guidelines and the annotated files are available at: https://github.com/elenamusi/ argscheme_aclworkshop2016.", "labels": [], "entities": []}], "datasetContent": [{"text": "In order to evaluate the reliability of the annotations we measured the inter-annotators agreement (IAA) using Fleiss' \u03ba to account for multiple annotators.", "labels": [], "entities": [{"text": "inter-annotators agreement (IAA)", "start_pos": 72, "end_pos": 104, "type": "METRIC", "confidence": 0.8943084478378296}]}, {"text": "When considering the middle level annotation schemes, the IAA is \u03ba=0.1, which shows only slight agreement.", "labels": [], "entities": [{"text": "IAA", "start_pos": 58, "end_pos": 61, "type": "METRIC", "confidence": 0.9930843114852905}]}, {"text": "This finding supports the hypothesis that for annotating argument schemes the IAA is low when using minimally training nonexpert annotators.", "labels": [], "entities": [{"text": "IAA", "start_pos": 78, "end_pos": 81, "type": "METRIC", "confidence": 0.9978975057601929}]}, {"text": "We also measured the IAA between the top level arguments (Intrinsic, Extrinsic, Complex, NoArgument), but did not find any significant difference in the Fleiss' \u03ba score.", "labels": [], "entities": [{"text": "IAA", "start_pos": 21, "end_pos": 24, "type": "METRIC", "confidence": 0.9977697134017944}]}, {"text": "represents some descriptive statistics about the annotations.", "labels": [], "entities": []}, {"text": "Out of 302 argumentative relations to be annotated, for 30 cases (10%) all three annotators agree, while for 179 cases (59%) at least two out of the three annotators agree.", "labels": [], "entities": []}, {"text": "When all three annotators agree the distribution of the argument schemes is: 7 Intrinsic:Causal, 9 Intrinsic:Mereorogical, 1 Intrinsic:Definitional, 6 Extrinsic:Practical Evaluation and 7 NoArgument.", "labels": [], "entities": []}, {"text": "When at least two out of the three annotators agree, the distribution of the argument schemes (majority voting) is: 60 (33.5%) Intrinsic:Causal, 46 (25.7%) Intrinsic:Mereorogical, 16 (8.9%) Intrinsic:Definitional, 28 (15.6%) Extrinsic:Practical Evaluation, 3(1%) Extrinsic:Alternatives' , 3(1%) Extrinsic:Opposition and 23 (12.8%) NoArgument').", "labels": [], "entities": [{"text": "Mereorogical", "start_pos": 166, "end_pos": 178, "type": "METRIC", "confidence": 0.9306749701499939}]}, {"text": "When considering the 3 top level argument schemes plus NoArgument, out of 302 argumentative relations to be annotated, for 260 instances (86%) at least two annotators agreed.", "labels": [], "entities": [{"text": "NoArgument", "start_pos": 55, "end_pos": 65, "type": "DATASET", "confidence": 0.8859991431236267}]}, {"text": "The distribution of majority voting labels in these cases is: 185 (71%) are Intrinsic, 52 (20%) are Extrinsic, and 23 (8.8%) are NoArgument.", "labels": [], "entities": [{"text": "Intrinsic", "start_pos": 76, "end_pos": 85, "type": "METRIC", "confidence": 0.9329257607460022}, {"text": "NoArgument", "start_pos": 129, "end_pos": 139, "type": "DATASET", "confidence": 0.8927143216133118}]}, {"text": "One goal of this pilot study was to determine whether confusion exists among particular argument schemes with the aim to improve the guidelines.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Descriptive Statistics about the annota- tions", "labels": [], "entities": []}, {"text": " Table 2: Confusion Matrix on 30 essays (3 minimally trained non-expert annotators)", "labels": [], "entities": []}, {"text": " Table 3: Confusion Matrix on a set of 10 essays (highly trained annotators: 2 non-experts and 1 expert)", "labels": [], "entities": []}]}