{"title": [{"text": "EmpiriST: AIPHES Robust Tokenization and POS-Tagging for Different Genres", "labels": [], "entities": [{"text": "EmpiriST", "start_pos": 0, "end_pos": 8, "type": "DATASET", "confidence": 0.9232807159423828}]}], "abstractContent": [{"text": "We present our system used for the AIPHES team submission in the context of the EmpiriST shared task on \"Auto-matic Linguistic Annotation of Computer-Mediated Communication / Social Me-dia\".", "labels": [], "entities": [{"text": "EmpiriST shared task", "start_pos": 80, "end_pos": 100, "type": "DATASET", "confidence": 0.8739393353462219}]}, {"text": "Our system is based on a rule-based tokenizer and a machine learning sequence labelling POS tagger using a variety of features.", "labels": [], "entities": [{"text": "machine learning sequence labelling POS tagger", "start_pos": 52, "end_pos": 98, "type": "TASK", "confidence": 0.6769516964753469}]}, {"text": "We show that the system is robust across the two tested gen-res: German computer mediated communication (CMC) and general German web data (WEB).", "labels": [], "entities": []}, {"text": "We achieve the second rank in three of four scenarios.", "labels": [], "entities": []}, {"text": "Also, the presented systems are freely available as open source components.", "labels": [], "entities": []}], "introductionContent": [{"text": "Tokenization and part-of-speech (POS) tagging are considered core tasks in a standard Natural Language Processing (NLP) pipeline.", "labels": [], "entities": [{"text": "part-of-speech (POS) tagging", "start_pos": 17, "end_pos": 45, "type": "TASK", "confidence": 0.6520256638526917}]}, {"text": "NLP tasks, such as summarization, information extraction, event detection, machine translation, and many others, are typically based on machine learning algorithms which use the outcome of lower level NLP tasks, such as tokens or intermediate linguistic phenomena including parts-of-speech or grammatical relations, as features.", "labels": [], "entities": [{"text": "summarization", "start_pos": 19, "end_pos": 32, "type": "TASK", "confidence": 0.9910178184509277}, {"text": "information extraction", "start_pos": 34, "end_pos": 56, "type": "TASK", "confidence": 0.7503517866134644}, {"text": "event detection", "start_pos": 58, "end_pos": 73, "type": "TASK", "confidence": 0.729089766740799}, {"text": "machine translation", "start_pos": 75, "end_pos": 94, "type": "TASK", "confidence": 0.7975762188434601}]}, {"text": "Though tokenization and part-of-speech tagging are considered simple tasks, it is highly important to achieve high-quality results, as errors propagate to downstream applications, where they are hard to repair and may cause notable consequential errors.", "labels": [], "entities": [{"text": "tokenization", "start_pos": 7, "end_pos": 19, "type": "TASK", "confidence": 0.9702535271644592}, {"text": "part-of-speech tagging", "start_pos": 24, "end_pos": 46, "type": "TASK", "confidence": 0.6890229880809784}]}, {"text": "Thus, a major goal is the minimization of the propagation of errors by using methods that perform as accurate as possible in lower level tasks on a diversity of texts and genres.", "labels": [], "entities": []}, {"text": "In this paper we present a simple, yet flexible and universally applicable system for tokenization and POS tagging German text.", "labels": [], "entities": [{"text": "tokenization", "start_pos": 86, "end_pos": 98, "type": "TASK", "confidence": 0.9799536466598511}, {"text": "POS tagging German text", "start_pos": 103, "end_pos": 126, "type": "TASK", "confidence": 0.8777159601449966}]}, {"text": "Our system participated in the EmpiriST shared task on \"Automatic Linguistic Annotation of Computer-Mediated Communication / Social Media\".", "labels": [], "entities": [{"text": "EmpiriST", "start_pos": 31, "end_pos": 39, "type": "DATASET", "confidence": 0.9042136669158936}, {"text": "Automatic Linguistic Annotation of Computer-Mediated Communication / Social Media", "start_pos": 56, "end_pos": 137, "type": "TASK", "confidence": 0.776996460225847}]}, {"text": "For this task, we applied our solution to texts from two different genres: a) general, html-stripped web data and b) colloquial language from social media texts.", "labels": [], "entities": []}, {"text": "The paper is organized as follows: We first describe the shared task and related work Section 2.", "labels": [], "entities": []}, {"text": "Our systems for tokenization and POS tagging are laid out in Section 3 and evaluated in Section 4, which includes a detailed error analysis.", "labels": [], "entities": [{"text": "tokenization", "start_pos": 16, "end_pos": 28, "type": "TASK", "confidence": 0.9841050505638123}, {"text": "POS tagging", "start_pos": 33, "end_pos": 44, "type": "TASK", "confidence": 0.8391911387443542}]}], "datasetContent": [{"text": "Following the EmpiriST task setup, we evaluate our tokenizer by measuring precision P , recall R, and the F 1 score as in.", "labels": [], "entities": [{"text": "precision P", "start_pos": 74, "end_pos": 85, "type": "METRIC", "confidence": 0.9612091481685638}, {"text": "recall R", "start_pos": 88, "end_pos": 96, "type": "METRIC", "confidence": 0.9753822088241577}, {"text": "F 1 score", "start_pos": 106, "end_pos": 115, "type": "METRIC", "confidence": 0.9832802613576254}]}, {"text": "Precision denotes the proportion of correctly identified token boundaries over the total number of token boundaries proposed by our tokenizer and recall denotes the proportion of correctly identified token boundaries over the total number of token boundaries in the gold standard.", "labels": [], "entities": [{"text": "Precision", "start_pos": 0, "end_pos": 9, "type": "METRIC", "confidence": 0.9791225790977478}, {"text": "recall", "start_pos": 146, "end_pos": 152, "type": "METRIC", "confidence": 0.999330997467041}]}, {"text": "The F 1 score is the harmonic mean of precision and recall.", "labels": [], "entities": [{"text": "F 1 score", "start_pos": 4, "end_pos": 13, "type": "METRIC", "confidence": 0.9833449323972067}, {"text": "precision", "start_pos": 38, "end_pos": 47, "type": "METRIC", "confidence": 0.9995266199111938}, {"text": "recall", "start_pos": 52, "end_pos": 58, "type": "METRIC", "confidence": 0.9971224665641785}]}, {"text": "For our POS tagger, we report the tagging accuracy.", "labels": [], "entities": [{"text": "POS tagger", "start_pos": 8, "end_pos": 18, "type": "TASK", "confidence": 0.5898235142230988}, {"text": "accuracy", "start_pos": 42, "end_pos": 50, "type": "METRIC", "confidence": 0.9890727400779724}]}, {"text": "That is, we measure the fraction of correct tag guesses over the total number of tokens to tag.", "labels": [], "entities": []}, {"text": "To enable a comparison of our tagger's results with previous work on German, we additionally use the STTS mapping provided by the shared task organizers and measure the tagging accuracy using the mapped tags.", "labels": [], "entities": [{"text": "STTS", "start_pos": 101, "end_pos": 105, "type": "METRIC", "confidence": 0.7649539113044739}, {"text": "accuracy", "start_pos": 177, "end_pos": 185, "type": "METRIC", "confidence": 0.9571275115013123}]}, {"text": "Below, we first discuss our results according to these standardized metrics and then conduct a careful analysis of the most prominent errors of our tools.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Tokenization results. We achieved  rank two of six submissions in both categories.  Two submissions were non-competitive but do not  change our rank.", "labels": [], "entities": []}, {"text": " Table 2: POS tagging results. Among 17 submis- sions from eight teams, of which two were out of  competition, we ranked second on the web data  and fifth on the CMC data.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 10, "end_pos": 21, "type": "TASK", "confidence": 0.7638225853443146}, {"text": "CMC data", "start_pos": 162, "end_pos": 170, "type": "DATASET", "confidence": 0.9593634605407715}]}, {"text": " Table 3: Distribution of new POS tag labels in the  test sets.", "labels": [], "entities": []}, {"text": " Table 4: Confusion matrix for POS tag prefixes (errors only)", "labels": [], "entities": [{"text": "POS tag prefixes", "start_pos": 31, "end_pos": 47, "type": "TASK", "confidence": 0.6973514159520467}]}, {"text": " Table 5: POS tagging error classes", "labels": [], "entities": [{"text": "POS tagging error", "start_pos": 10, "end_pos": 27, "type": "TASK", "confidence": 0.8008635838826498}]}]}