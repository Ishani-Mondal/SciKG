{"title": [{"text": "Bidirectional LSTM for Named Entity Recognition in Twitter Messages", "labels": [], "entities": [{"text": "Bidirectional LSTM", "start_pos": 0, "end_pos": 18, "type": "METRIC", "confidence": 0.7667850852012634}, {"text": "Named Entity Recognition", "start_pos": 23, "end_pos": 47, "type": "TASK", "confidence": 0.6508109271526337}]}], "abstractContent": [{"text": "In this paper, we present our approach for named entity recognition in Twitter messages that we used in our participation in the Named Entity Recognition in Twitter shared task at the COL-ING 2016 Workshop on Noisy User-generated text (WNUT).", "labels": [], "entities": [{"text": "named entity recognition", "start_pos": 43, "end_pos": 67, "type": "TASK", "confidence": 0.6726582149664561}, {"text": "Named Entity Recognition in Twitter shared task at the COL-ING 2016 Workshop on Noisy User-generated text (WNUT)", "start_pos": 129, "end_pos": 241, "type": "TASK", "confidence": 0.8466711452132777}]}, {"text": "The main challenge that we aim to tackle in our participation is the short, noisy and colloquial nature of tweets, which makes named entity recognition in Twitter messages a challenging task.", "labels": [], "entities": [{"text": "named entity recognition in Twitter messages", "start_pos": 127, "end_pos": 171, "type": "TASK", "confidence": 0.81512650847435}]}, {"text": "In particular, we investigate an approach for dealing with this problem by enabling bidirectional long short-term memory (LSTM) to automatically learn orthographic features without requiring feature engineering.", "labels": [], "entities": []}, {"text": "In comparison with other systems participating in the shared task, our system achieved the most effective performance on both the 'segmentation and categorisation' and the 'segmentation only' sub-tasks.", "labels": [], "entities": []}], "introductionContent": [{"text": "Named entity recognition (NER), which is one of the first and important stages in a natural language processing (NLP) pipeline, is to identify mentions of entities (e.g. persons, locations and organisations) within unstructured text.", "labels": [], "entities": [{"text": "Named entity recognition (NER)", "start_pos": 0, "end_pos": 30, "type": "TASK", "confidence": 0.8091405679782232}, {"text": "identify mentions of entities (e.g. persons, locations and organisations) within unstructured text", "start_pos": 134, "end_pos": 232, "type": "TASK", "confidence": 0.7114385525385539}]}, {"text": "Traditionally, most of the effective NER approaches are based on machine learning techniques, such as conditional random field (CRF), support vector machine (SVM) and perceptrons (.", "labels": [], "entities": [{"text": "NER", "start_pos": 37, "end_pos": 40, "type": "TASK", "confidence": 0.9665378332138062}]}, {"text": "For instance, effectively learned a perceptron model using features, including word classes induced using Brown clustering (, and gazetteer extracted from Wikipedia.", "labels": [], "entities": []}, {"text": "Twitter NER is an NER task that aims to identify mentions of entities in Twitter messages (i.e. tweets) ().", "labels": [], "entities": []}, {"text": "Twitter NER is particularly challenging because of the unique characteristics of tweets.", "labels": [], "entities": [{"text": "NER", "start_pos": 8, "end_pos": 11, "type": "TASK", "confidence": 0.4324833154678345}]}, {"text": "For instance, tweets are typically short as the number of characters in a particular tweet is restricted to 140; hence, the contextual information is limited.", "labels": [], "entities": []}, {"text": "In addition, the use of colloquial language makes it difficult for existing NER approaches a general domain, such as newswire to be reused (.", "labels": [], "entities": []}, {"text": "Consequently, state-of-the-art NER software (e.g. Standford NER) is less effective on Twitter NER tasks.", "labels": [], "entities": []}, {"text": "For our participation in the Named Entity Recognition in Twitter shared task at the COLING 2016 Workshop on Noisy User-generated text (WNUT) (, we aim to investigate a novel approach that allows neural network to explicitly learn and leverage orthographic features.", "labels": [], "entities": [{"text": "Named Entity Recognition in Twitter shared task at the COLING 2016 Workshop on Noisy User-generated text (WNUT)", "start_pos": 29, "end_pos": 140, "type": "TASK", "confidence": 0.7928545584804133}]}, {"text": "We focus on orthographic features as they have shown to be effective and widely used in several NER systems.", "labels": [], "entities": [{"text": "NER", "start_pos": 96, "end_pos": 99, "type": "TASK", "confidence": 0.9459518194198608}]}, {"text": "Importantly, orthographic features are used by majority of the systems (including the best system) participating in the Twitter NER shared task at the 2015 WNUT workshop (", "labels": [], "entities": [{"text": "Twitter NER shared task at the 2015 WNUT workshop", "start_pos": 120, "end_pos": 169, "type": "DATASET", "confidence": 0.6970312065548367}]}], "datasetContent": [{"text": "The Twitter NER shared task datasets consist of training set (i.e. '2015 train'+'2015 dev'), development set (i.e. '2015 test'), additional set (i.e. additional 'dev 2015') and test set, respectively.", "labels": [], "entities": [{"text": "Twitter NER shared task datasets", "start_pos": 4, "end_pos": 36, "type": "DATASET", "confidence": 0.6268630087375641}]}, {"text": "The numbers of tweets and tokens of each set are shown in.", "labels": [], "entities": []}, {"text": "The shared task focuses on finding 10 types of target entities, including company, facility, geo-location, movie, music-artist, other, person, product, sport team and TV show.", "labels": [], "entities": []}, {"text": "In particular, the shared task can be divided to to sub-tasks: 'segmentation only' and 'segmentation and categorisation'.", "labels": [], "entities": []}, {"text": "The former focuses only on finding the boundaries of entities; meanwhile, the latter requires both the boundaries of entities and the correct categories of entity types.", "labels": [], "entities": []}, {"text": "Next, we discuss the performance of our proposed approach.", "labels": [], "entities": []}, {"text": "compares the performances of our approach with the other systems participating in the Twitter NER shared task at the 2016 WNUT workshop, in terms of F1, precision and recall measures, on both the 'segmentation and categorisation' and 'segmentation only' sub-tasks.", "labels": [], "entities": [{"text": "Twitter NER shared task at the 2016 WNUT workshop", "start_pos": 86, "end_pos": 135, "type": "DATASET", "confidence": 0.820900387234158}, {"text": "F1", "start_pos": 149, "end_pos": 151, "type": "METRIC", "confidence": 0.9996048808097839}, {"text": "precision", "start_pos": 153, "end_pos": 162, "type": "METRIC", "confidence": 0.9988186955451965}, {"text": "recall", "start_pos": 167, "end_pos": 173, "type": "METRIC", "confidence": 0.9972389936447144}]}, {"text": "From, we observed that our approach achieved the best F1 score for both sub-tasks.", "labels": [], "entities": [{"text": "F1 score", "start_pos": 54, "end_pos": 62, "type": "METRIC", "confidence": 0.989285796880722}]}, {"text": "In particular, our approach attains F1 scores of 52.41 and 65.89 for the 'segmentation and categorisation' and 'segmentation only' sub-tasks, respectively.", "labels": [], "entities": [{"text": "F1", "start_pos": 36, "end_pos": 38, "type": "METRIC", "confidence": 0.9997994303703308}]}, {"text": "Importantly, for the 'segmentation and categorisation' subtask, our approach significantly outperformed the second best system (namely, Talos) by 6.2 F1 score.", "labels": [], "entities": [{"text": "segmentation and categorisation'", "start_pos": 22, "end_pos": 54, "type": "TASK", "confidence": 0.8019838482141495}, {"text": "F1", "start_pos": 150, "end_pos": 152, "type": "METRIC", "confidence": 0.9988844990730286}]}, {"text": "showed the performance of our approach broken down into entity types.", "labels": [], "entities": []}, {"text": "Our approach performed effectively on entities related to geo-location, person and company.", "labels": [], "entities": []}, {"text": "Meanwhile, it was less effective on the entity types tvshow, musicartist and movie.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Statistics of the WNUT 2016 NER shared task datasets.", "labels": [], "entities": [{"text": "WNUT 2016 NER shared task datasets", "start_pos": 28, "end_pos": 62, "type": "DATASET", "confidence": 0.8714604675769806}]}, {"text": " Table 3: Performances in terms of F1, precision and recall of our approach and the participating systems  on the 'segmention and categorisation' (10-type) and the 'segmentation only' (no-type) sub-tasks.", "labels": [], "entities": [{"text": "F1", "start_pos": 35, "end_pos": 37, "type": "METRIC", "confidence": 0.9997047781944275}, {"text": "precision", "start_pos": 39, "end_pos": 48, "type": "METRIC", "confidence": 0.999667763710022}, {"text": "recall", "start_pos": 53, "end_pos": 59, "type": "METRIC", "confidence": 0.9995369911193848}]}, {"text": " Table 4: Performances of our approach broken down by entity types.", "labels": [], "entities": []}]}