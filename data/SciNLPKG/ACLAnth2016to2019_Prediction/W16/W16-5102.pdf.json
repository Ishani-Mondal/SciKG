{"title": [{"text": "Learning Orthographic Features in Bi-directional LSTM for Biomedical Named Entity Recognition", "labels": [], "entities": [{"text": "Biomedical Named Entity Recognition", "start_pos": 58, "end_pos": 93, "type": "TASK", "confidence": 0.6428035423159599}]}], "abstractContent": [{"text": "End-to-end neural network models for named entity recognition (NER) have shown to achieve effective performances on general domain datasets (e.g. newswire), without requiring additional hand-crafted features.", "labels": [], "entities": [{"text": "named entity recognition (NER)", "start_pos": 37, "end_pos": 67, "type": "TASK", "confidence": 0.7990860193967819}]}, {"text": "However, in biomedical domain, recent studies have shown that hand-engineered features (e.g. orthographic features) should be used to attain effective performance, due to the complexity of biomedical terminology (e.g. the use of acronyms and complex gene names).", "labels": [], "entities": []}, {"text": "In this work, we propose a novel approach that allows a neural network model based on along short-term memory (LSTM) to automatically learn orthographic features and incorporate them into a model for biomedical NER.", "labels": [], "entities": [{"text": "biomedical NER", "start_pos": 200, "end_pos": 214, "type": "TASK", "confidence": 0.5435585081577301}]}, {"text": "Importantly, our bi-directional LSTM model learns and leverages orthographic features on an end-to-end basis.", "labels": [], "entities": []}, {"text": "We evaluate our approach by comparing against existing neural network models for NER using three well-established biomedical datasets.", "labels": [], "entities": [{"text": "NER", "start_pos": 81, "end_pos": 84, "type": "TASK", "confidence": 0.9872845411300659}]}, {"text": "Our experimental results show that the proposed approach consistently outperforms these strong baselines across all of the three datasets.", "labels": [], "entities": []}], "introductionContent": [{"text": "Named entity recognition (NER) is one of the first and important stages in a natural language processing (NLP) pipeline.", "labels": [], "entities": [{"text": "Named entity recognition (NER)", "start_pos": 0, "end_pos": 30, "type": "TASK", "confidence": 0.8230452239513397}]}, {"text": "In particular, an NER task is to identify mentions of entities (e.g. persons, locations and organisations) within unstructured text.", "labels": [], "entities": [{"text": "NER", "start_pos": 18, "end_pos": 21, "type": "TASK", "confidence": 0.9926447868347168}, {"text": "identify mentions of entities (e.g. persons, locations and organisations) within unstructured text", "start_pos": 33, "end_pos": 131, "type": "TASK", "confidence": 0.5596122364203135}]}, {"text": "In biomedical domain, NER tasks are particularly difficult, since the entities of interests are mainly genes, proteins, and chemical substances, which by nature (1) consist of millions of entities, (2) are created continuously, and (3) are non-standardised and can be referred to using different names (e.g. the use of acronyms and polysemy) (.", "labels": [], "entities": [{"text": "NER tasks", "start_pos": 22, "end_pos": 31, "type": "TASK", "confidence": 0.9273295402526855}]}, {"text": "Traditionally, most of the effective NER approaches are based on machine learning techniques, such as conditional random field (CRF), support vector machine (SVM) and perceptrons ().", "labels": [], "entities": [{"text": "NER", "start_pos": 37, "end_pos": 40, "type": "TASK", "confidence": 0.9705612063407898}]}, {"text": "For instance, effectively learned a perceptron model using features, including word classes induced using Brown clustering (, and gazetteer extracted from Wikipedia.", "labels": [], "entities": []}, {"text": "achieved effective performances for several biomedical NER tasks by learning a CRF model using multiple sets of features, including orthographic, morphological, linguistic-based, conjunctions and dictionary-based.", "labels": [], "entities": [{"text": "NER tasks", "start_pos": 55, "end_pos": 64, "type": "TASK", "confidence": 0.8438609838485718}]}, {"text": "However, these approaches rely heavily on feature engineering and domain knowledge (e.g. gazetteers), which are costly to develop.", "labels": [], "entities": []}, {"text": "Consequently, they are difficult to be adapted to anew domain, since hand-engineered features are mostly specific to a target domain.", "labels": [], "entities": []}, {"text": "Recent advances in word vector representation (i.e. word embeddings) (), which represents a word in the form of a low-dimensional vector of real values, allow machine learning approaches to exploit semantic and syntactic information from word vectors, induced This work is licensed under a Creative Commons Attribution 4.0 International Licence.", "labels": [], "entities": [{"text": "word vector representation", "start_pos": 19, "end_pos": 45, "type": "TASK", "confidence": 0.6489068567752838}]}, {"text": "Licence details: http: //creativecommons.org/licenses/by/4.0/ from a large dataset, for several NLP tasks, such as NER, part-of-speech (POS) tagging, sentiment analysis and concept normalisation.", "labels": [], "entities": [{"text": "NER", "start_pos": 115, "end_pos": 118, "type": "TASK", "confidence": 0.9448314905166626}, {"text": "part-of-speech (POS) tagging", "start_pos": 120, "end_pos": 148, "type": "TASK", "confidence": 0.5623670279979706}, {"text": "sentiment analysis", "start_pos": 150, "end_pos": 168, "type": "TASK", "confidence": 0.9641803503036499}, {"text": "concept normalisation", "start_pos": 173, "end_pos": 194, "type": "TASK", "confidence": 0.7710446715354919}]}, {"text": "For example, effectively used word embeddings as inputs of a feed-forward neural network for sequence labelling tasks, such as NER and POS tagging.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 135, "end_pos": 146, "type": "TASK", "confidence": 0.6927369832992554}]}, {"text": "learned a CRF model using word embeddings as input features for NER and chunking tasks.", "labels": [], "entities": []}, {"text": "In the biomedical domain,  investigated the the use of different word embeddings in a feed-forward neural network for biomedical NER tasks.", "labels": [], "entities": [{"text": "NER tasks", "start_pos": 129, "end_pos": 138, "type": "TASK", "confidence": 0.7974821031093597}]}, {"text": "However, when using with word embedding features, traditional features (e.g. orthography and gazetteers) have shown to further improve the performance of an NER system.", "labels": [], "entities": []}, {"text": "In this work, we investigate a novel approach that allows an end-to-end neural network system for biomedical NER to explicitly learn and leverage orthographic features.", "labels": [], "entities": [{"text": "NER", "start_pos": 109, "end_pos": 112, "type": "TASK", "confidence": 0.640543520450592}]}, {"text": "Our approach is based on bidirectional long short-term memory (LSTM)) that learns to identify named entities in a sentence using both word and character embeddings as inputs.", "labels": [], "entities": []}, {"text": "In particular, for each input sentence, we propose to generate and feed an orthographic sentence into a bi-directional LSTM to enable the model to explicitly learn orthographic features.", "labels": [], "entities": []}, {"text": "We evaluate our proposed approach using three different well-established biomedical test collections, including the BioCreative II Gene Mention task corpus (BC2) (), the BioNLP 2009 shared task on event extraction (BioNLP09) () and the NCBI disease corpus (NCBI)).", "labels": [], "entities": [{"text": "BioCreative II Gene Mention task corpus (BC2)", "start_pos": 116, "end_pos": 161, "type": "DATASET", "confidence": 0.6896999610794915}, {"text": "BioNLP 2009 shared task on event extraction (BioNLP09", "start_pos": 170, "end_pos": 223, "type": "TASK", "confidence": 0.6531525519159105}, {"text": "NCBI disease corpus (NCBI))", "start_pos": 236, "end_pos": 263, "type": "DATASET", "confidence": 0.9323672453562418}]}, {"text": "Our experimental results show that the proposed approach consistently outperforms existing effective baselines in term of the f1-score measure.", "labels": [], "entities": []}, {"text": "The main contributions of this paper are three-folds: 1.", "labels": [], "entities": []}, {"text": "We investigate the use of both word and character embeddings in bi-directional LSTM for biomedical NER tasks.", "labels": [], "entities": [{"text": "NER tasks", "start_pos": 99, "end_pos": 108, "type": "TASK", "confidence": 0.791057288646698}]}, {"text": "2. We propose a novel approach that enables bi-directional LSTM to automatically learn and leverage orthographic features without requiring feature engineering.", "labels": [], "entities": []}, {"text": "3. We thoroughly evaluate our proposed approach using three different standardised datasets for biomedical NER.", "labels": [], "entities": [{"text": "biomedical NER", "start_pos": 96, "end_pos": 110, "type": "TASK", "confidence": 0.5746086537837982}]}, {"text": "The remainder of this paper is organised as follows.", "labels": [], "entities": []}, {"text": "In Section 2, we discuss related work and position our paper in the literature.", "labels": [], "entities": []}, {"text": "In Section 3, we introduce our approach to learn and leverage orthographic features in bi-directional LSTM for biomedical NER.", "labels": [], "entities": [{"text": "biomedical NER", "start_pos": 111, "end_pos": 125, "type": "TASK", "confidence": 0.57403364777565}]}, {"text": "In Sections 4 and 5, we describe our experimental setup and empirically evaluate our approach, respectively.", "labels": [], "entities": []}, {"text": "Section 6 provides concluding remarks.", "labels": [], "entities": []}], "datasetContent": [{"text": "To evaluate our proposed approach, we use three different well-estabished biomedical NER datasets, which are the BioCreative II Gene Mention task corpus (BC2) (), the BioNLP 2009 shared task on event extraction (BioNLP09) () and the NCBI disease corpus (NCBI)), respectively.", "labels": [], "entities": [{"text": "BioCreative II Gene Mention task corpus (BC2)", "start_pos": 113, "end_pos": 158, "type": "DATASET", "confidence": 0.6847262647416856}, {"text": "BioNLP 2009 shared task on event extraction", "start_pos": 167, "end_pos": 210, "type": "TASK", "confidence": 0.6902140719549996}, {"text": "NCBI disease corpus (NCBI))", "start_pos": 233, "end_pos": 260, "type": "DATASET", "confidence": 0.9167952537536621}]}, {"text": "shows the information of the three datasets.", "labels": [], "entities": []}, {"text": "Firstly, the BC2 dataset consists of 20,000 sentences extracted from MEDLINE abstracts (15,000 sentences for training and 5,000 sentences for testing), where the task is to annotate the mentions of genes.", "labels": [], "entities": [{"text": "BC2 dataset", "start_pos": 13, "end_pos": 24, "type": "DATASET", "confidence": 0.8982496559619904}, {"text": "MEDLINE abstracts", "start_pos": 69, "end_pos": 86, "type": "DATASET", "confidence": 0.8138330280780792}]}, {"text": "In order to create a development set, we randomly split the original 15,000 training sentences into 10,000 and 5,000 training and development sentences.", "labels": [], "entities": []}, {"text": "Secondly, the BioNLP09 dataset is composed of 7,449, 1,450 and 2,447 sentences for training, development and testing, respectively.", "labels": [], "entities": [{"text": "BioNLP09 dataset", "start_pos": 14, "end_pos": 30, "type": "DATASET", "confidence": 0.8304522037506104}]}, {"text": "The target entities are bio-molecular events.", "labels": [], "entities": []}, {"text": "Thirdly, the NCBI dataset contains more than 6,000 sentences from 793 PubMed articles (593, 100 and 100 articles for training, development and testing, respectively).", "labels": [], "entities": [{"text": "NCBI dataset", "start_pos": 13, "end_pos": 25, "type": "DATASET", "confidence": 0.9869870543479919}]}, {"text": "The task aims to identify mentions of diseases in a given sentence.", "labels": [], "entities": []}, {"text": "We evaluate the performance on the three biomedical NER tasks in terms of f1-score, precision and recall measures: where T P (true positive) is the number of named entity chunks that are correctly identified, F P (false positive) is the number of chunks that are mistakenly identified as entities, and F N (false negative) are the number of named entity chunks that are not identified.", "labels": [], "entities": [{"text": "NER tasks", "start_pos": 52, "end_pos": 61, "type": "TASK", "confidence": 0.8428560495376587}, {"text": "f1-score", "start_pos": 74, "end_pos": 82, "type": "METRIC", "confidence": 0.9261922240257263}, {"text": "precision", "start_pos": 84, "end_pos": 93, "type": "METRIC", "confidence": 0.999639630317688}, {"text": "recall", "start_pos": 98, "end_pos": 104, "type": "METRIC", "confidence": 0.9994847774505615}]}, {"text": "In this section, we compare the performance of our approach for learning and leveraging orthographic features in bi-directional LSTM for biomedical NER (denoted, ORTH-CNN-BiLSTM) against the four baselines introduced in Section 4.5.", "labels": [], "entities": [{"text": "ORTH-CNN-BiLSTM", "start_pos": 162, "end_pos": 177, "type": "METRIC", "confidence": 0.9125332832336426}]}, {"text": "compares the performances of our proposed approach with the baselines in terms of f1-score, precision and recall on the three datasets (i.e. BC2, BioNLP09 and NCBI).", "labels": [], "entities": [{"text": "f1-score", "start_pos": 82, "end_pos": 90, "type": "METRIC", "confidence": 0.9535665512084961}, {"text": "precision", "start_pos": 92, "end_pos": 101, "type": "METRIC", "confidence": 0.999625563621521}, {"text": "recall", "start_pos": 106, "end_pos": 112, "type": "METRIC", "confidence": 0.999626636505127}, {"text": "BC2", "start_pos": 141, "end_pos": 144, "type": "DATASET", "confidence": 0.9098946452140808}, {"text": "BioNLP09", "start_pos": 146, "end_pos": 154, "type": "DATASET", "confidence": 0.7987393140792847}, {"text": "NCBI", "start_pos": 159, "end_pos": 163, "type": "DATASET", "confidence": 0.9322370290756226}]}, {"text": "From, we firstly observe that FeedForward is the weakest baseline, especially in terms of the f1-score.", "labels": [], "entities": [{"text": "FeedForward", "start_pos": 30, "end_pos": 41, "type": "DATASET", "confidence": 0.6499398350715637}]}, {"text": "This is intuitive as feed-forward neural network is a simple model in comparison with bi-directional LSTM that could learn long-distance dependencies from sequences of words.", "labels": [], "entities": []}, {"text": "Next, we compare the performance of BiLSTM and CNN-BiLSTM (Char-only).", "labels": [], "entities": [{"text": "CNN-BiLSTM", "start_pos": 47, "end_pos": 57, "type": "DATASET", "confidence": 0.9059857130050659}]}, {"text": "Both BiLSTM and CNN-BiLSTM (Char-only) share a similar architecture for identifying named entities.", "labels": [], "entities": [{"text": "CNN-BiLSTM", "start_pos": 16, "end_pos": 26, "type": "DATASET", "confidence": 0.9191496968269348}]}, {"text": "The only difference is that BiL-STM uses pre-trained word embeddings for representing words in a sentence; meanwhile, CNN-BiLSTM (Char-only) learns word representation from character embeddings using a convolutional neural network.", "labels": [], "entities": [{"text": "CNN-BiLSTM", "start_pos": 118, "end_pos": 128, "type": "DATASET", "confidence": 0.9128629565238953}]}, {"text": "We observe that CNN-BiLSTM (Char-only) achieves better performances than BiLSTM in terms of all the three reported measures (i.e. f1-score, precision and recall), across the three datasets.", "labels": [], "entities": [{"text": "precision", "start_pos": 140, "end_pos": 149, "type": "METRIC", "confidence": 0.9992372989654541}, {"text": "recall", "start_pos": 154, "end_pos": 160, "type": "METRIC", "confidence": 0.9973125457763672}]}, {"text": "This highlights the importance of the character-based word representation that could help to deal with non-standardised and continuously-growing biomedical vocabularies.", "labels": [], "entities": []}, {"text": "Furthermore, we found that CNN-BiLSTM, which uses both pre-trained word embeddings and character-based word representation in a bi-directional LSTM model, further improves the f1-score and recall performances on all of the three datasets.", "labels": [], "entities": [{"text": "CNN-BiLSTM", "start_pos": 27, "end_pos": 37, "type": "DATASET", "confidence": 0.8528673648834229}, {"text": "recall", "start_pos": 189, "end_pos": 195, "type": "METRIC", "confidence": 0.9985670447349548}]}, {"text": "On the other hand, our approach, ORTH-CNN-BiLSTM, outperforms all of the baselines on the three datasets.", "labels": [], "entities": [{"text": "ORTH-CNN-BiLSTM", "start_pos": 33, "end_pos": 48, "type": "METRIC", "confidence": 0.9086371064186096}]}, {"text": "In particular, ORTH-CNN-BiLSTM performs better than CNN-BiLSTM, which is the most effective baseline, in terms of f1-score and precision for all of the BC2, BioNLP09 and NCBI datasets.", "labels": [], "entities": [{"text": "ORTH-CNN-BiLSTM", "start_pos": 15, "end_pos": 30, "type": "METRIC", "confidence": 0.9288906455039978}, {"text": "f1-score", "start_pos": 114, "end_pos": 122, "type": "METRIC", "confidence": 0.9581217765808105}, {"text": "precision", "start_pos": 127, "end_pos": 136, "type": "METRIC", "confidence": 0.9993091821670532}, {"text": "BC2", "start_pos": 152, "end_pos": 155, "type": "DATASET", "confidence": 0.8878899216651917}, {"text": "NCBI datasets", "start_pos": 170, "end_pos": 183, "type": "DATASET", "confidence": 0.8384699821472168}]}, {"text": "Importantly, we observe that our approach for automatically learning orthographic features could effectively boost the performance in term of precision.", "labels": [], "entities": [{"text": "precision", "start_pos": 142, "end_pos": 151, "type": "METRIC", "confidence": 0.9983262419700623}]}, {"text": "For example, for the BC2 and NCBI datasets, ORTH-CNN-BiLSTM achieved 83.01% and 86.67% precision, while CNN-BiLSTM attains 80.75% and 84.33% precision, respectively.", "labels": [], "entities": [{"text": "BC2", "start_pos": 21, "end_pos": 24, "type": "DATASET", "confidence": 0.8450749516487122}, {"text": "NCBI datasets", "start_pos": 29, "end_pos": 42, "type": "DATASET", "confidence": 0.8268027305603027}, {"text": "ORTH-CNN-BiLSTM", "start_pos": 44, "end_pos": 59, "type": "METRIC", "confidence": 0.902285635471344}, {"text": "precision", "start_pos": 87, "end_pos": 96, "type": "METRIC", "confidence": 0.9975091218948364}, {"text": "precision", "start_pos": 141, "end_pos": 150, "type": "METRIC", "confidence": 0.9973515272140503}]}, {"text": "When analysing the performance of ORTH-CNN-BiLSTM, we observe that the induced orthographic features could help to effectively identify complex biomedical entities, such as 'CrkII-23', 'ch-IAP1', 'HC-toxin', 'E.coli manX equivalent', 'cathepsin K', 'IL-2', and 'A-T', that do not appear in the training set by learning from the orthographic patterns of words.", "labels": [], "entities": []}, {"text": "This shows the importance of orthographic features in biomedical NER tasks.", "labels": [], "entities": [{"text": "NER tasks", "start_pos": 65, "end_pos": 74, "type": "TASK", "confidence": 0.8090026080608368}]}, {"text": "Importantly, our approach shows a potential of enabling bi-directional LSTM to capture these patterns without resorting to hand-engineered features.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Examples of biomedical sentences and their corresponding orthographic sentence.", "labels": [], "entities": []}, {"text": " Table 3: Performances in terms of f1-score, precision and recall of our proposed approach and the  baselines on the BC2, BioNLP09 and NCBI datasets.", "labels": [], "entities": [{"text": "f1-score", "start_pos": 35, "end_pos": 43, "type": "METRIC", "confidence": 0.9398501515388489}, {"text": "precision", "start_pos": 45, "end_pos": 54, "type": "METRIC", "confidence": 0.9996222257614136}, {"text": "recall", "start_pos": 59, "end_pos": 65, "type": "METRIC", "confidence": 0.9995323419570923}, {"text": "BC2", "start_pos": 117, "end_pos": 120, "type": "DATASET", "confidence": 0.9206724762916565}, {"text": "BioNLP09", "start_pos": 122, "end_pos": 130, "type": "DATASET", "confidence": 0.7319765686988831}, {"text": "NCBI datasets", "start_pos": 135, "end_pos": 148, "type": "DATASET", "confidence": 0.9082604348659515}]}]}