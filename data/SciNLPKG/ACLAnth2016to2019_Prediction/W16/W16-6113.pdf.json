{"title": [{"text": "Hybrid methods for ICD-10 coding of death certificates", "labels": [], "entities": [{"text": "ICD-10 coding of death certificates", "start_pos": 19, "end_pos": 54, "type": "TASK", "confidence": 0.881181538105011}]}], "abstractContent": [{"text": "ICD-10 coding of death certificates has received renewed attention recently with the organization of the CLEF eHealth 2016 clinical information extraction task (CLEF eHealth 2016 Task 2).", "labels": [], "entities": [{"text": "ICD-10 coding of death certificates", "start_pos": 0, "end_pos": 35, "type": "TASK", "confidence": 0.8697007894515991}, {"text": "CLEF eHealth 2016 clinical information extraction task", "start_pos": 105, "end_pos": 159, "type": "TASK", "confidence": 0.8486958827291217}, {"text": "CLEF eHealth 2016 Task 2)", "start_pos": 161, "end_pos": 186, "type": "DATASET", "confidence": 0.6882354517777761}]}, {"text": "This task has been addressed either with dictionary projection methods or with supervised machine learning methods, but none of the participants have tried to design hybrid methods to process these data.", "labels": [], "entities": [{"text": "dictionary projection", "start_pos": 41, "end_pos": 62, "type": "TASK", "confidence": 0.681176170706749}]}, {"text": "The goal of the present paper is to explore such hybrid methods.", "labels": [], "entities": []}, {"text": "It proposes several hybrid methods which outperform both plain dictionary projection and supervised machine learning on the training set.", "labels": [], "entities": [{"text": "plain dictionary projection", "start_pos": 57, "end_pos": 84, "type": "TASK", "confidence": 0.6226445138454437}]}, {"text": "On the official test set, it obtains an F-measure of 0.8586 which is 1pt above the best published results so far on this corpus (p < 10 \u22124).", "labels": [], "entities": [{"text": "F-measure", "start_pos": 40, "end_pos": 49, "type": "METRIC", "confidence": 0.9991177916526794}]}, {"text": "Moreover, it does so with no manual dictionary tuning, and thus has potential for generalization to other languages with little effort.", "labels": [], "entities": []}], "introductionContent": [{"text": "Biomedical information processing crucially relies on a normalized representation of medical information in the form or standardized terminologies and ontologies, be it for clinical care (SNOMED, LOINC), for public health statistics and health management (International Classification of Diseases) or for literature search (MeSH).", "labels": [], "entities": [{"text": "Biomedical information processing", "start_pos": 0, "end_pos": 33, "type": "TASK", "confidence": 0.8619012037913004}]}, {"text": "Automatically generating such a normalized representation from naturally occurring sources such as text is therefore a long-studied goal.", "labels": [], "entities": []}, {"text": "Basically, it consists in deciding which concepts in the target representation (e.g., signs and symptom concepts in SNOMED CT, or disease classes in the ICD-10 classification) best represent the contents of a given text (e.g., a patient discharge summary).", "labels": [], "entities": [{"text": "SNOMED CT", "start_pos": 116, "end_pos": 125, "type": "TASK", "confidence": 0.579646959900856}]}, {"text": "It can be decomposed into the detection of text mentions of biomedical concepts of the suitable types (entity recognition) and the determination of the target concepts (concept normalization) which best represent the text mentions in the context of the source text and the given use case.", "labels": [], "entities": [{"text": "entity recognition", "start_pos": 103, "end_pos": 121, "type": "TASK", "confidence": 0.763143390417099}]}, {"text": "The state of the art of biomedical entity recognition and biomedical concept normalization has been established and published in a number of shared tasks which addressed clinical texts (, biomedical literature, sometimes in multiple languages.", "labels": [], "entities": [{"text": "biomedical entity recognition", "start_pos": 24, "end_pos": 53, "type": "TASK", "confidence": 0.6683854361375173}, {"text": "biomedical concept normalization", "start_pos": 58, "end_pos": 90, "type": "TASK", "confidence": 0.6266064345836639}]}, {"text": "This paper focuses on ICD-10 coding.", "labels": [], "entities": [{"text": "ICD-10 coding", "start_pos": 22, "end_pos": 35, "type": "TASK", "confidence": 0.9205918610095978}]}, {"text": "ICD coding has been studied in the past (e.g., as early as), but only recently has a large dataset been released for ICD-10 coding of death certificates.", "labels": [], "entities": [{"text": "ICD coding", "start_pos": 0, "end_pos": 10, "type": "TASK", "confidence": 0.8387136459350586}, {"text": "ICD-10 coding of death certificates", "start_pos": 117, "end_pos": 152, "type": "TASK", "confidence": 0.9019339680671692}]}, {"text": "In that context, mention that participants in the CLEF eHealth 2016 ICD-10 coding task either used dictionary-based methods or supervised machine learning methods, and that none tried hybrid methods.", "labels": [], "entities": [{"text": "CLEF eHealth 2016 ICD-10 coding task", "start_pos": 50, "end_pos": 86, "type": "DATASET", "confidence": 0.9096796015898386}]}, {"text": "The goal of this paper is to explore this direction.", "labels": [], "entities": []}, {"text": "Our contributions are the following: \u2022 We explore hybrid methods for ICD-10 coding which combine dictionary projection and supervised machine learning.", "labels": [], "entities": [{"text": "ICD-10 coding", "start_pos": 69, "end_pos": 82, "type": "TASK", "confidence": 0.8601905703544617}, {"text": "dictionary projection", "start_pos": 97, "end_pos": 118, "type": "TASK", "confidence": 0.7670565247535706}]}, {"text": "\u2022 We show that simple hybrid combinations with union and intersection yield improved results.", "labels": [], "entities": []}, {"text": "\u2022 We propose methods which improve the precision of dictionary projection, including hybrid 'calibration' methods.", "labels": [], "entities": [{"text": "precision", "start_pos": 39, "end_pos": 48, "type": "METRIC", "confidence": 0.9984190464019775}, {"text": "dictionary projection", "start_pos": 52, "end_pos": 73, "type": "TASK", "confidence": 0.7528044283390045}]}, {"text": "\u2022 The methods which fare best on the training corpus, when applied to the test corpus, are on par with the best published results on this corpus, with no manual dictionary tuning, and have thus potential for generalization to other languages with little effort.", "labels": [], "entities": []}, {"text": "In the remainder of the paper, we report the methods used by the best-performing participants in the CLEF eHealth 2016 shared task (Section 2), present the methods we explored and the data on which we applied them (Section 3), the results we obtained on the development and test data (Section 4), discuss them (Section 5) and conclude (Section 6).", "labels": [], "entities": [{"text": "CLEF eHealth 2016 shared task", "start_pos": 101, "end_pos": 130, "type": "DATASET", "confidence": 0.931118392944336}]}], "datasetContent": [{"text": "Teams were allowed to submit up to three runs to the task.", "labels": [], "entities": []}, {"text": "In the present work, we emulated the same situation and selected three methods to run on the test corpus based on their F-measures in our experiments on the training corpus.", "labels": [], "entities": [{"text": "F-measures", "start_pos": 120, "end_pos": 130, "type": "METRIC", "confidence": 0.9835180044174194}]}, {"text": "This prevented us from biasing the final results by tuning them on the test corpus.", "labels": [], "entities": []}, {"text": "To apply these methods to the test corpus, we retrained them on the full training corpus with a more recent dictionary: \u2022 The supervised classifier (Linear SVM, tc3y) was trained on the full training corpus.", "labels": [], "entities": []}, {"text": "\u2022 Dictionary projection methods used the 2012 dictionary instead of the 2011 dictionary.", "labels": [], "entities": [{"text": "Dictionary projection", "start_pos": 2, "end_pos": 23, "type": "TASK", "confidence": 0.6326592564582825}]}, {"text": "\u2022 Dictionary projection was calibrated on the full training corpus.", "labels": [], "entities": [{"text": "Dictionary projection", "start_pos": 2, "end_pos": 23, "type": "TASK", "confidence": 0.7113268375396729}]}, {"text": "\u2022 Supervised classifier and calibrated dictionary projection were applied to the test corpus.", "labels": [], "entities": []}, {"text": "\u2022 The union of their results was computed and used as final predictions.", "labels": [], "entities": []}, {"text": "Precision, recall and F-measure were computed for each experiment, by our own programs for convenience during development; when applied to the test corpus, they were computed with the official scoring program provided to the CLEF eHealth participants.", "labels": [], "entities": [{"text": "Precision", "start_pos": 0, "end_pos": 9, "type": "METRIC", "confidence": 0.9966975450515747}, {"text": "recall", "start_pos": 11, "end_pos": 17, "type": "METRIC", "confidence": 0.9983969330787659}, {"text": "F-measure", "start_pos": 22, "end_pos": 31, "type": "METRIC", "confidence": 0.9982025623321533}, {"text": "CLEF eHealth participants", "start_pos": 225, "end_pos": 250, "type": "DATASET", "confidence": 0.9398186802864075}]}], "tableCaptions": [{"text": " Table 1: The C\u00e9piDC French Death Certificates Corpus (from", "labels": [], "entities": [{"text": "The C\u00e9piDC French Death Certificates Corpus", "start_pos": 10, "end_pos": 53, "type": "DATASET", "confidence": 0.8075316747029623}]}, {"text": " Table 4: 2011 dictionary calibration experiments on our test", "labels": [], "entities": []}, {"text": " Table 5: 2011 dictionary experiments on our test split: Union", "labels": [], "entities": [{"text": "Union", "start_pos": 57, "end_pos": 62, "type": "DATASET", "confidence": 0.8089200258255005}]}]}