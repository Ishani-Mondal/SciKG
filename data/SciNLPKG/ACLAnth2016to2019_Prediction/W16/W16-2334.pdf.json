{"title": [], "abstractContent": [{"text": "We describe our submission to the IT-domain translation task of WMT 2016.", "labels": [], "entities": [{"text": "IT-domain translation task of WMT 2016", "start_pos": 34, "end_pos": 72, "type": "TASK", "confidence": 0.7306563705205917}]}, {"text": "We perform domain adaptation with dictionary data on already trained MT systems with no further retraining.", "labels": [], "entities": [{"text": "domain adaptation", "start_pos": 11, "end_pos": 28, "type": "TASK", "confidence": 0.8513804376125336}, {"text": "MT", "start_pos": 69, "end_pos": 71, "type": "TASK", "confidence": 0.971657395362854}]}, {"text": "We apply our approach to two conceptually different systems developed within the QTLeap project: TectoMT and Moses, as well as Chimera, their combination.", "labels": [], "entities": []}, {"text": "In all settings , our method improves the translation quality.", "labels": [], "entities": [{"text": "translation", "start_pos": 42, "end_pos": 53, "type": "TASK", "confidence": 0.9663248658180237}]}, {"text": "Moreover, the basic variant of our approach is applicable to any MT system, including a black-box one.", "labels": [], "entities": [{"text": "MT", "start_pos": 65, "end_pos": 67, "type": "TASK", "confidence": 0.983036458492279}]}], "introductionContent": [{"text": "In this paper, we describe our work on domain adaptation of machine translation systems, performed in close collaboration with numerous partners within the QTLeap project.", "labels": [], "entities": [{"text": "domain adaptation of machine translation", "start_pos": 39, "end_pos": 79, "type": "TASK", "confidence": 0.6786195695400238}, {"text": "QTLeap project", "start_pos": 156, "end_pos": 170, "type": "DATASET", "confidence": 0.8405072391033173}]}, {"text": "The project focuses on high-quality translation for the IT domain, and our systems were submitted to the ITdomain translation task of the First Conference on Machine Translation (WMT16).", "labels": [], "entities": [{"text": "ITdomain translation task of the First Conference on Machine Translation (WMT16)", "start_pos": 105, "end_pos": 185, "type": "TASK", "confidence": 0.6645002731910119}]}, {"text": "The experiments relate to our previous work on domain adaptation (, in which we also surveyed and evaluated common domain adaptation techniques.", "labels": [], "entities": [{"text": "domain adaptation", "start_pos": 47, "end_pos": 64, "type": "TASK", "confidence": 0.7594797015190125}]}, {"text": "The aim of our work is to find away to perform domain adaptation of an already trained MT system without having to retrain it, which maybe a useful ability for reasons discussed in \u00a7 2.", "labels": [], "entities": [{"text": "domain adaptation", "start_pos": 47, "end_pos": 64, "type": "TASK", "confidence": 0.7147612124681473}, {"text": "MT", "start_pos": 87, "end_pos": 89, "type": "TASK", "confidence": 0.7963290810585022}]}, {"text": "We focus on forced translation of domain-specific entities according to a bilingual lexicon, as described in \u00a7 3.", "labels": [], "entities": []}, {"text": "We explore several methods based on preprocessing and postprocessing of the data before and after processing them by the MT system, and provide both system-specific and systemindependent approaches.", "labels": [], "entities": []}, {"text": "We employ the MT systems used and further developed by us and our partners within the QTLeap project, namely Moses (, TectoMT ( \u02c7 Zabokrtsk\u00b4y, and their combination Chimera (.", "labels": [], "entities": []}, {"text": "We briefly describe the systems in \u00a7 4.", "labels": [], "entities": []}, {"text": "In \u00a7 5, we evaluate our domain-adaptation methods (as well as the standard method of retraining the system with all available data) applied to these MT systems for translation from English to Czech (EN\u2192CS), Spanish (EN\u2192ES), Dutch (EN\u2192NL), and Portuguese (EN\u2192PT).", "labels": [], "entities": [{"text": "MT", "start_pos": 149, "end_pos": 151, "type": "TASK", "confidence": 0.9574922919273376}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: BLEU evaluation of two forced trans- lation styles for Moses: XXX placeholders and  XML markup. For comparison, the non-adapted  system is also included.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9964227080345154}]}, {"text": " Table 2: BLEU evaluation of the domain adap- tation, using Treex annotations for TectoMT and  XML annotations for Moses (except for EN\u2192CS,  which uses XXX annotations in Moses).", "labels": [], "entities": [{"text": "BLEU", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9962497353553772}]}, {"text": " Table 3: Human evaluation ranks of constrained  systems in WMT2016 IT-domain task.", "labels": [], "entities": [{"text": "WMT2016 IT-domain task", "start_pos": 60, "end_pos": 82, "type": "DATASET", "confidence": 0.7198984821637472}]}, {"text": " Table 4: BLEU evaluation of the Moses system  on EN\u2192NL, comparing the baseline non-adapted  Moses, Moses adapted by forced translations an- notated with XML markup, and Moses using a  secondary in-domain phrase table.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9982635378837585}]}]}