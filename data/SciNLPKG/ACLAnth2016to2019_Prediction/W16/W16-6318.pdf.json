{"title": [{"text": "A method for Automatic Text Summarization using Consensus of Multiple Similarity Measures and Ranking Techniques", "labels": [], "entities": [{"text": "Automatic Text Summarization", "start_pos": 13, "end_pos": 41, "type": "TASK", "confidence": 0.7312702536582947}]}], "abstractContent": [{"text": "In the era of information overload, text sum-marization can be defined as the process of extracting useful information from a large space of available content using traditional filtering methods.", "labels": [], "entities": []}, {"text": "One of the major challenges in the domain of extraction based summariza-tion is that a single statistical measure is not sufficient to produce efficient summaries which would be close to human-made 'gold standard', since each measure suffers from individual weaknesses.", "labels": [], "entities": []}, {"text": "We deal with this problem by proposing a text summarization model that combines various statistical measures so that the pitfalls of an individual technique could be compensated by the strengths of others.", "labels": [], "entities": [{"text": "text summarization", "start_pos": 41, "end_pos": 59, "type": "TASK", "confidence": 0.5968021601438522}]}, {"text": "Experimental results are presented to demonstrate the effectiveness of the proposed method using the TAC 2011 Multiling pilot dataset for English language and ROUGE summary evaluation tool.", "labels": [], "entities": [{"text": "TAC 2011 Multiling pilot dataset", "start_pos": 101, "end_pos": 133, "type": "DATASET", "confidence": 0.9215455174446106}]}], "introductionContent": [{"text": "What is the need of text summarization?", "labels": [], "entities": [{"text": "text summarization", "start_pos": 20, "end_pos": 38, "type": "TASK", "confidence": 0.7606688141822815}]}, {"text": "One of the major reasons is Information explosion.", "labels": [], "entities": [{"text": "Information explosion", "start_pos": 28, "end_pos": 49, "type": "TASK", "confidence": 0.6823662966489792}]}, {"text": "A study ( by IBM in 2013 estimated that everyday 2.5 Quintillion bytes of new information were born on the internet.", "labels": [], "entities": []}, {"text": "The velocity with which this is increasing can be estimated from the fact that 90 percent of total data on web at that time was created in the previous two years alone.", "labels": [], "entities": []}, {"text": "Thus there is a progressing need to effectively extract useful content from big data and use streamlined filtering methods to make it comprehensible and non-redundant.", "labels": [], "entities": []}, {"text": "In this paper, we have introduced a novel technique for automatic single-document extractionbased text summarization.", "labels": [], "entities": [{"text": "single-document extractionbased text summarization", "start_pos": 66, "end_pos": 116, "type": "TASK", "confidence": 0.8242183029651642}]}, {"text": "The proposed approach uses a number of statistical models such as Pearson Correlation Coefficient, Cosine Similarity and Jaccard Similarity) that compute multiple summaries of a text and combine them, using configurable consensus methods.", "labels": [], "entities": [{"text": "Pearson Correlation Coefficient", "start_pos": 66, "end_pos": 97, "type": "METRIC", "confidence": 0.8470557530721029}]}, {"text": "Finally, we stretch a step further and use machinelearning to make the summary domain-specific or personalized.", "labels": [], "entities": []}, {"text": "Our basic focus is on designing a technique to improve the weighing constants in the consensus step by using a genre-specific training set.", "labels": [], "entities": []}], "datasetContent": [{"text": "For testing our approach, we have used the following two datasets: (1) TAC 2011 Multiling pilot summarization task dataset) which is derived from publicly available WikiNews (http://www.wikinews.org/).", "labels": [], "entities": [{"text": "TAC 2011 Multiling pilot summarization task dataset", "start_pos": 71, "end_pos": 122, "type": "DATASET", "confidence": 0.6626479455402919}]}, {"text": "It is divided into ten collections with each collection containing ten documents.", "labels": [], "entities": []}, {"text": "A single collection has all documents of the same topic.", "labels": [], "entities": []}, {"text": "We have only tested on the English version of the documents.", "labels": [], "entities": [{"text": "English version of the documents", "start_pos": 27, "end_pos": 59, "type": "DATASET", "confidence": 0.7553151428699494}]}, {"text": "The dataset contains at least one \"golden-summary\" for comparison.", "labels": [], "entities": []}, {"text": "(2) Six English News document collections retrieved for Summarization-research purpose in 2012 (http://dbdmg.polito.it/wordpress/ research/document-summarization/).", "labels": [], "entities": [{"text": "English News document collections retrieved", "start_pos": 8, "end_pos": 51, "type": "DATASET", "confidence": 0.922784399986267}]}, {"text": "Each collection is made up often news documents of the same topic each.", "labels": [], "entities": []}, {"text": "This data set was retrieved from Google News for research related to TAC2011 MultiLing Pilot Overview ().", "labels": [], "entities": [{"text": "TAC2011 MultiLing Pilot Overview", "start_pos": 69, "end_pos": 101, "type": "TASK", "confidence": 0.6017783209681511}]}, {"text": "We divided the ten documents in each collection into a training set and a testing test randomly with each set consisting of 5 documents.", "labels": [], "entities": []}, {"text": "The upper limit of the summary size was kept to be 250 words.", "labels": [], "entities": []}, {"text": "The widely used summary evaluation tool 'ROUGE') was used to compare the results with several other summarizers.", "labels": [], "entities": [{"text": "ROUGE", "start_pos": 41, "end_pos": 46, "type": "METRIC", "confidence": 0.9847745299339294}]}, {"text": "Our competitors consist of summarization methods that competed in the TAC 2011 conference (UBSummarizer and UoEssex), a widely used summarizer which is integrated with Microsoft-Word (autosummarize) and the recently proposed Association Mixture Text Summarization (AMTS) ().", "labels": [], "entities": [{"text": "summarization", "start_pos": 27, "end_pos": 40, "type": "TASK", "confidence": 0.9641465544700623}, {"text": "TAC 2011 conference", "start_pos": 70, "end_pos": 89, "type": "DATASET", "confidence": 0.8193249503771464}, {"text": "Association Mixture Text Summarization (AMTS)", "start_pos": 225, "end_pos": 270, "type": "TASK", "confidence": 0.732914400952203}]}, {"text": "Test results the Recall, Precision and Fmeasure using ROUGE-2 and ROUGE-SU4 summary evaluation techniques that is shown in", "labels": [], "entities": [{"text": "Recall", "start_pos": 17, "end_pos": 23, "type": "METRIC", "confidence": 0.8347439169883728}, {"text": "Precision", "start_pos": 25, "end_pos": 34, "type": "METRIC", "confidence": 0.9428205490112305}, {"text": "Fmeasure", "start_pos": 39, "end_pos": 47, "type": "METRIC", "confidence": 0.9848029017448425}, {"text": "ROUGE-2", "start_pos": 54, "end_pos": 61, "type": "METRIC", "confidence": 0.854742705821991}]}], "tableCaptions": [{"text": " Table 1: Test Results using ROUGE-2", "labels": [], "entities": [{"text": "ROUGE-2", "start_pos": 29, "end_pos": 36, "type": "METRIC", "confidence": 0.9780752658843994}]}, {"text": " Table 2: Test Results using ROUGE-SU4", "labels": [], "entities": [{"text": "ROUGE-SU4", "start_pos": 29, "end_pos": 38, "type": "METRIC", "confidence": 0.969832718372345}]}]}