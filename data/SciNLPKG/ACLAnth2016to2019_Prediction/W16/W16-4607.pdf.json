{"title": [{"text": "Neural Reordering Model Considering Phrase Translation and Word Alignment for Phrase-based Translation", "labels": [], "entities": [{"text": "Neural Reordering", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.8120999038219452}, {"text": "Phrase Translation", "start_pos": 36, "end_pos": 54, "type": "TASK", "confidence": 0.8449394404888153}, {"text": "Word Alignment", "start_pos": 59, "end_pos": 73, "type": "TASK", "confidence": 0.6995351314544678}, {"text": "Phrase-based Translation", "start_pos": 78, "end_pos": 102, "type": "TASK", "confidence": 0.7200453728437424}]}], "abstractContent": [{"text": "This paper presents an improved lexicalized reordering model for phrase-based statistical machine translation using a deep neural network.", "labels": [], "entities": [{"text": "phrase-based statistical machine translation", "start_pos": 65, "end_pos": 109, "type": "TASK", "confidence": 0.6100338026881218}]}, {"text": "Lexicalized reordering suffers from reordering ambiguity, data sparseness and noises in a phrase table.", "labels": [], "entities": []}, {"text": "Previous neural reordering model is successful to solve the first and second problems but fails to address the third one.", "labels": [], "entities": []}, {"text": "Therefore, we propose new features using phrase translation and word alignment to construct phrase vectors to handle inherently noisy phrase translation pairs.", "labels": [], "entities": [{"text": "phrase translation", "start_pos": 41, "end_pos": 59, "type": "TASK", "confidence": 0.7888021171092987}, {"text": "word alignment", "start_pos": 64, "end_pos": 78, "type": "TASK", "confidence": 0.7534900903701782}]}, {"text": "The experimental results show that our proposed method improves the accuracy of phrase reordering.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 68, "end_pos": 76, "type": "METRIC", "confidence": 0.9990143775939941}, {"text": "phrase reordering", "start_pos": 80, "end_pos": 97, "type": "TASK", "confidence": 0.7954620122909546}]}, {"text": "We confirm that the proposed method works well with phrase pairs including NULL alignments.", "labels": [], "entities": []}], "introductionContent": [{"text": "Phrase-based statistical machine translation (PBSMT) () has been widely used in the last decade.", "labels": [], "entities": [{"text": "Phrase-based statistical machine translation (PBSMT)", "start_pos": 0, "end_pos": 52, "type": "TASK", "confidence": 0.6844475822789329}]}, {"text": "One major problem with PBSMT is word reordering.", "labels": [], "entities": [{"text": "word reordering", "start_pos": 32, "end_pos": 47, "type": "TASK", "confidence": 0.7877152562141418}]}, {"text": "Since PBSMT models the translation process using a phrase table, it is not easy to incorporate global information during translation.", "labels": [], "entities": []}, {"text": "There are many methods to address this problem, such as lexicalized reordering, distance-based reordering (, pre-ordering (, and post-ordering ).", "labels": [], "entities": []}, {"text": "However, word reordering still faces serious errors, especially when the word order greatly differs in two languages, such as the case between English and Japanese.", "labels": [], "entities": [{"text": "word reordering", "start_pos": 9, "end_pos": 24, "type": "TASK", "confidence": 0.8149735033512115}]}, {"text": "In this paper, we focus on the lexicalized reordering model (LRM), which directly constrains reordering of phrases in PBSMT.", "labels": [], "entities": []}, {"text": "LRM addresses the problem of a simple distance-based reordering approach in distant language pairs.", "labels": [], "entities": []}, {"text": "However, there are some disadvantages: (1) reordering ambiguity, (2) data sparsity and (3) noisy phrases pairs.", "labels": [], "entities": []}, {"text": "addressed the problem of reordering ambiguity and data sparsity using a neural reordering model (NRM) that assigns reordering probabilities on the words of both the current and the previous phrase pairs.", "labels": [], "entities": []}, {"text": "Also, tackled the problem of reordering ambiguity by including much longer context information on the source side than other LRMs including NRMs to determine phrase orientations using Long Short-Term Memory (LSTM).", "labels": [], "entities": [{"text": "phrase orientations", "start_pos": 158, "end_pos": 177, "type": "TASK", "confidence": 0.6620046198368073}]}, {"text": "However, there area large number of noisy phrase pairs in the phrase table.", "labels": [], "entities": []}, {"text": "One of the deficiencies of their NRMs is that they generated a phrase vector by simply embedding word vectors of the source and target language phrases and did not consider the adequacy of the translation between the phrase pair and the alignment of words in the phrases.", "labels": [], "entities": []}, {"text": "It maybe problematic especially when a phrase contains the NULL alignment, such as \",\" in \" ||| in Japan ,\".", "labels": [], "entities": []}, {"text": "In addition, it is difficult to integrate the model of into stack decoding because their model is now conditioned not only on the words of each phrase pair but also on the history of decoded phrases.", "labels": [], "entities": []}, {"text": "Furthermore, because they did not compare their model with the original NRM of, it is possible that their model is inferior to the previous approach.", "labels": [], "entities": [{"text": "NRM", "start_pos": 72, "end_pos": 75, "type": "DATASET", "confidence": 0.8229673504829407}]}, {"text": "Therefore, we propose to use phrase translation probability and word alignment features for NRM to address the problem of noisy phrase pairs.", "labels": [], "entities": [{"text": "phrase translation", "start_pos": 29, "end_pos": 47, "type": "TASK", "confidence": 0.8215407133102417}, {"text": "word alignment", "start_pos": 64, "end_pos": 78, "type": "TASK", "confidence": 0.75506991147995}]}, {"text": "Both intrinsic and extrinsic experiments show that our features indeed improve the original NRM.", "labels": [], "entities": [{"text": "NRM", "start_pos": 92, "end_pos": 95, "type": "DATASET", "confidence": 0.7851038575172424}]}, {"text": "The main contributions of this paper are as follows: \u2022 We propose anew NRM incorporating phrase translation probabilities and word alignment in a phrase pair as features to handle inherently noisy phrase pairs more correctly.", "labels": [], "entities": [{"text": "phrase translation probabilities", "start_pos": 89, "end_pos": 121, "type": "TASK", "confidence": 0.8088712096214294}, {"text": "word alignment", "start_pos": 126, "end_pos": 140, "type": "TASK", "confidence": 0.7191803306341171}]}, {"text": "\u2022 The experimental results show that our proposed method improves the accuracy of phrase reordering.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 70, "end_pos": 78, "type": "METRIC", "confidence": 0.9990233182907104}, {"text": "phrase reordering", "start_pos": 82, "end_pos": 99, "type": "TASK", "confidence": 0.8072699904441833}]}, {"text": "In particular, the proposed method works well with phrase pairs including NULL alignments.", "labels": [], "entities": []}, {"text": "\u2022 We evaluate the proposed method on Japanese-to-English and English-to-Japanese translation using automatic and human evaluation.", "labels": [], "entities": []}], "datasetContent": [{"text": "We conduct two kinds of experiments: intrinsic evaluation of reordering accuracy and extrinsic evaluation of MT quality.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 72, "end_pos": 80, "type": "METRIC", "confidence": 0.9606900215148926}, {"text": "MT", "start_pos": 109, "end_pos": 111, "type": "TASK", "confidence": 0.9808385372161865}]}, {"text": "Furthermore, in NRMs, the use of phrase translation and the word alignment improves the accuracy by 0.31 and 0.82 points, respectively.", "labels": [], "entities": [{"text": "phrase translation", "start_pos": 33, "end_pos": 51, "type": "TASK", "confidence": 0.7606021463871002}, {"text": "word alignment", "start_pos": 60, "end_pos": 74, "type": "TASK", "confidence": 0.7080735862255096}, {"text": "accuracy", "start_pos": 88, "end_pos": 96, "type": "METRIC", "confidence": 0.9995310306549072}]}, {"text": "Considering both these features, the accuracy of NRM is improved by 1.67 points.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 37, "end_pos": 45, "type": "METRIC", "confidence": 0.9998499155044556}]}, {"text": "vector even if the phrase in the test data is not included in the training data.", "labels": [], "entities": []}, {"text": "As a result, the accuracy of the trained NRM is superior to that of LRM, only seeing 50K instances.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 17, "end_pos": 25, "type": "METRIC", "confidence": 0.9996572732925415}]}, {"text": "When we increase the size of the training data, the number of unknown words and unknown phrases decreases and the accuracy is improved further.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 114, "end_pos": 122, "type": "METRIC", "confidence": 0.9995965361595154}]}, {"text": "However, most of the unknown words in the training corpus are named entities such as, \" (Kiyomizu-dera Temple),\" which is a Japanese famous temple, because there are many traditional named entities in the KFTT corpus.", "labels": [], "entities": [{"text": "KFTT corpus", "start_pos": 205, "end_pos": 216, "type": "DATASET", "confidence": 0.8776079714298248}]}, {"text": "Furthermore, it is possible that anew unknown word not in the phrase table appears in decoding.", "labels": [], "entities": []}, {"text": "Therefore we expect NRMs to exhibit higher accuracy than LRM owing to their ability to recognize the unknown word.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 43, "end_pos": 51, "type": "METRIC", "confidence": 0.9985663294792175}]}, {"text": "shows the reordering accuracy at each epoch.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 21, "end_pos": 29, "type": "METRIC", "confidence": 0.9642277359962463}]}, {"text": "Our proposed NRM+PT+WA method always achieves better accuracy than the baseline method of NRM.", "labels": [], "entities": [{"text": "PT+WA", "start_pos": 17, "end_pos": 22, "type": "METRIC", "confidence": 0.689225435256958}, {"text": "accuracy", "start_pos": 53, "end_pos": 61, "type": "METRIC", "confidence": 0.9991348385810852}]}, {"text": "The accuracy is maximized around the 10th epoch in the test data.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 4, "end_pos": 12, "type": "METRIC", "confidence": 0.9996091723442078}]}, {"text": "After that, the accuracy gradually decreases.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 16, "end_pos": 24, "type": "METRIC", "confidence": 0.9997931122779846}]}, {"text": "The test loss shows the same tendency (negatively correlated with accuracy).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 66, "end_pos": 74, "type": "METRIC", "confidence": 0.9994105100631714}]}, {"text": "We investigate whether our reordering system improves translation accuracy.", "labels": [], "entities": [{"text": "translation", "start_pos": 54, "end_pos": 65, "type": "TASK", "confidence": 0.9509596228599548}, {"text": "accuracy", "start_pos": 66, "end_pos": 74, "type": "METRIC", "confidence": 0.8646434545516968}]}, {"text": "We use our reordering model for N-best re-ranking and optimize BLEU () using minimum error rate training (MERT).", "labels": [], "entities": [{"text": "BLEU", "start_pos": 63, "end_pos": 67, "type": "METRIC", "confidence": 0.9990448355674744}, {"text": "minimum error rate training (MERT)", "start_pos": 77, "end_pos": 111, "type": "METRIC", "confidence": 0.8557537623814174}]}, {"text": "We output a 1,000-best candidate list of translations that Moses generated for development data and replace the lexical reordering score of Moses with the score of the proposed method.", "labels": [], "entities": []}, {"text": "Then, we re-tune the weights of the Moses features using MERT again.", "labels": [], "entities": [{"text": "MERT", "start_pos": 57, "end_pos": 61, "type": "METRIC", "confidence": 0.9715883135795593}]}, {"text": "BLEU-4, RIBES (Isozaki et al., 2010a) and WER are used as measures for evaluation.", "labels": [], "entities": [{"text": "BLEU-4", "start_pos": 0, "end_pos": 6, "type": "METRIC", "confidence": 0.9846360683441162}, {"text": "RIBES", "start_pos": 8, "end_pos": 13, "type": "METRIC", "confidence": 0.9949821829795837}, {"text": "WER", "start_pos": 42, "end_pos": 45, "type": "METRIC", "confidence": 0.9958245754241943}]}, {"text": "shows the BLEU, RIBES and WER scores of the basic system and our proposed system.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9995891451835632}, {"text": "RIBES", "start_pos": 16, "end_pos": 21, "type": "METRIC", "confidence": 0.9968233108520508}, {"text": "WER scores", "start_pos": 26, "end_pos": 36, "type": "METRIC", "confidence": 0.9680042564868927}]}, {"text": "Bold scores represent the highest accuracies.", "labels": [], "entities": [{"text": "accuracies", "start_pos": 34, "end_pos": 44, "type": "METRIC", "confidence": 0.9909067153930664}]}, {"text": "When we compare the plain NRM and the proposed method with LRM, we confirm significant differences in BLEU, RIBES and WER scores on Japanese-to-English and English-to-Japanese translations using bootstrap resampling.", "labels": [], "entities": [{"text": "LRM", "start_pos": 59, "end_pos": 62, "type": "METRIC", "confidence": 0.9278530478477478}, {"text": "BLEU", "start_pos": 102, "end_pos": 106, "type": "METRIC", "confidence": 0.9997027516365051}, {"text": "RIBES", "start_pos": 108, "end_pos": 113, "type": "METRIC", "confidence": 0.9937653541564941}, {"text": "WER", "start_pos": 118, "end_pos": 121, "type": "METRIC", "confidence": 0.997752845287323}]}, {"text": "Unfortunately, the proposed method is notable to identify significant differences in comparison with NRM.", "labels": [], "entities": [{"text": "NRM", "start_pos": 101, "end_pos": 104, "type": "DATASET", "confidence": 0.8534591197967529}]}, {"text": "The reordering accuracy does not necessarily relate to the translation accuracy because we make the training and test data without checking the decoding step.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 15, "end_pos": 23, "type": "METRIC", "confidence": 0.897000789642334}, {"text": "translation", "start_pos": 59, "end_pos": 70, "type": "TASK", "confidence": 0.9295509457588196}, {"text": "accuracy", "start_pos": 71, "end_pos": 79, "type": "METRIC", "confidence": 0.5289991497993469}]}, {"text": "We consider this to be partly of the reason why the BLEU score did not improve.", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 52, "end_pos": 62, "type": "METRIC", "confidence": 0.9432518184185028}]}, {"text": "We conduct ablation tests to investigate which reordering orientation contributes most to BLEU score.", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 90, "end_pos": 100, "type": "METRIC", "confidence": 0.9778503179550171}]}, {"text": "The results show that Swap, which contains mostly NULL alignment, accounts for 0.17 points of improvement of the BLEU score in the proposed method.", "labels": [], "entities": [{"text": "Swap", "start_pos": 22, "end_pos": 26, "type": "METRIC", "confidence": 0.8934496641159058}, {"text": "NULL alignment", "start_pos": 50, "end_pos": 64, "type": "METRIC", "confidence": 0.8001150488853455}, {"text": "BLEU score", "start_pos": 113, "end_pos": 123, "type": "METRIC", "confidence": 0.9748411178588867}]}, {"text": "Other labels contribute only 0.01 -0.05 points.", "labels": [], "entities": []}, {"text": "Consequently, we consider that there is little influence on the translation results, because the change in each label of reordering is small, although the reordering accuracy rate of the NRM and the proposed method differ by 1.67 points.", "labels": [], "entities": [{"text": "translation", "start_pos": 64, "end_pos": 75, "type": "TASK", "confidence": 0.9530789256095886}, {"text": "accuracy", "start_pos": 166, "end_pos": 174, "type": "METRIC", "confidence": 0.9398239254951477}, {"text": "NRM", "start_pos": 187, "end_pos": 190, "type": "DATASET", "confidence": 0.8587928414344788}]}, {"text": "In addition, we conducted human evaluation on Japanese-English translation by randomly choosing 100 sentences from test data.", "labels": [], "entities": [{"text": "Japanese-English translation", "start_pos": 46, "end_pos": 74, "type": "TASK", "confidence": 0.6465866714715958}]}, {"text": "Two evaluators compared the proposed method with NRM fluency and adequacy.", "labels": [], "entities": []}, {"text": "As a result, the proposed method improved fluency (NRM:NRM+PT+WA = 17.5:20) but not adequacy (NRM:NRM+PT+WA = 19:14.5).", "labels": [], "entities": []}, {"text": "Although the outputs of two methods are similar, the proposed method favored fluent translation and resulted in slight improvements in BLEU and RIBES.", "labels": [], "entities": [{"text": "fluent translation", "start_pos": 77, "end_pos": 95, "type": "TASK", "confidence": 0.6820968687534332}, {"text": "BLEU", "start_pos": 135, "end_pos": 139, "type": "METRIC", "confidence": 0.9971950054168701}, {"text": "RIBES", "start_pos": 144, "end_pos": 149, "type": "METRIC", "confidence": 0.7373508810997009}]}], "tableCaptions": [{"text": " Table 2: Recall and accuracy of reordering phrases.", "labels": [], "entities": [{"text": "Recall", "start_pos": 10, "end_pos": 16, "type": "METRIC", "confidence": 0.9667724370956421}, {"text": "accuracy", "start_pos": 21, "end_pos": 29, "type": "METRIC", "confidence": 0.9992891550064087}]}, {"text": " Table 3: Data size and the accuracy of reordering. Vocab size reflects the vocabulary in the training data.  The numbers of UNK words and UNK phrases are calculated in the test data. A pre-trained word2vec  vector was given as the initial value for UNK words. Vocab sizes of test data are en:3,583 and ja:3,470.  Phrase sizes of test data are en:8,187 and ja:7,945.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 28, "end_pos": 36, "type": "METRIC", "confidence": 0.9994717240333557}]}, {"text": " Table 4: Recall and accuracy of reordering phrases that contain NULL alignment.", "labels": [], "entities": [{"text": "Recall", "start_pos": 10, "end_pos": 16, "type": "METRIC", "confidence": 0.9862138628959656}, {"text": "accuracy", "start_pos": 21, "end_pos": 29, "type": "METRIC", "confidence": 0.9994729161262512}]}, {"text": " Table 5: Evaluation of translation quality. The symbols of * means statistically significant difference for  LRM in bootstrap resampling (p < 0.01).", "labels": [], "entities": [{"text": "translation", "start_pos": 24, "end_pos": 35, "type": "TASK", "confidence": 0.9586646556854248}]}]}