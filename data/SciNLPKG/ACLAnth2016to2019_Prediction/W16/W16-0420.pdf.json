{"title": [{"text": "Improve Sentiment Analysis of Citations with Author Modelling", "labels": [], "entities": [{"text": "Improve Sentiment Analysis of Citations", "start_pos": 0, "end_pos": 39, "type": "TASK", "confidence": 0.9126027703285218}]}], "abstractContent": [{"text": "In this paper, we introduce a novel approach to sentiment polarity classification of citations, which integrates data about the authors' reputation.", "labels": [], "entities": [{"text": "sentiment polarity classification of citations", "start_pos": 48, "end_pos": 94, "type": "TASK", "confidence": 0.8318295300006866}]}, {"text": "More specifically, our method extends the h-index with citation polarities and utilizes it in sentiment classification of citation sentences.", "labels": [], "entities": [{"text": "sentiment classification of citation sentences", "start_pos": 94, "end_pos": 140, "type": "TASK", "confidence": 0.9167541027069092}]}, {"text": "Our computational results show that our method yields significant improvement in terms of classification performance.", "labels": [], "entities": [{"text": "classification", "start_pos": 90, "end_pos": 104, "type": "TASK", "confidence": 0.9563355445861816}]}], "introductionContent": [], "datasetContent": [{"text": "In our experimental implementation, we used the Python module SciKit-Learn 4 for machine learning, feature extraction and evaluation.", "labels": [], "entities": [{"text": "feature extraction", "start_pos": 99, "end_pos": 117, "type": "TASK", "confidence": 0.7534492313861847}]}, {"text": "Support Vector Machine (SVM) is chosen as the classification algorithm.", "labels": [], "entities": []}, {"text": "SVM is a widely used algorithm for text classification).", "labels": [], "entities": [{"text": "text classification", "start_pos": 35, "end_pos": 54, "type": "TASK", "confidence": 0.8132382929325104}]}, {"text": "Since our main contribution is improving classification performance using p-index, we mainly focus on the effects caused by replacing the h-index by the p-index.", "labels": [], "entities": [{"text": "classification", "start_pos": 41, "end_pos": 55, "type": "TASK", "confidence": 0.9628298878669739}]}, {"text": "The SVM hyper-parameter is one of the settings that stay identical in all experiments.", "labels": [], "entities": []}, {"text": "Therefore, in our on-going work, we have not broadly explored the parameter grid of penalty parameter C and kernel coefficient \u00ed \u00b5\u00ed\u00bb\u00be, which are the main parameters of SVM with Radial Basis Function (RBF) kernel ().", "labels": [], "entities": [{"text": "kernel coefficient \u00ed \u00b5\u00ed", "start_pos": 108, "end_pos": 131, "type": "METRIC", "confidence": 0.7270925045013428}]}, {"text": "In order to answer our research question in section 1, we performed the experiment in a comparative manner.", "labels": [], "entities": []}, {"text": "Firstly, we partition the corpus into 10 subsets and prepare 10 pairs of train and test sets.", "labels": [], "entities": []}, {"text": "Then, for each pair, we perform the following procedure: 1.", "labels": [], "entities": []}, {"text": "Run the classifier with h-index to obtain the baseline performance, denoted by F1 bin the following.", "labels": [], "entities": [{"text": "F1", "start_pos": 79, "end_pos": 81, "type": "METRIC", "confidence": 0.9957720637321472}]}, {"text": "2. Calculate the p-indices of authors as defined in Formula (2).", "labels": [], "entities": []}, {"text": "3. Update data instances of both train and test set: replace h-index value with p-index 4.", "labels": [], "entities": []}, {"text": "Run the classifier on the new train and test set.", "labels": [], "entities": []}, {"text": "It yields the test result F1 t . 5. Calculate the relative improvement from baseline to test result as: \"O\" is the sentiment annotation, meaning \"objective\" (neutral).", "labels": [], "entities": [{"text": "F1", "start_pos": 26, "end_pos": 28, "type": "METRIC", "confidence": 0.998676598072052}, {"text": "O", "start_pos": 105, "end_pos": 106, "type": "METRIC", "confidence": 0.9776304364204407}]}, {"text": "This procedure is applied to all the train and test set pairs.", "labels": [], "entities": []}, {"text": "Next we calculate the average of all of these relative improvement.", "labels": [], "entities": []}, {"text": "This is the final result of one experiment; it measures the effectiveness of our method under one specific setting.", "labels": [], "entities": []}, {"text": "Since the p-index depends on the positive and negative citation coefficients, \u00ed \u00b5\u00ed\u00bb\u00bc and \u00ed \u00b5\u00ed\u00bb\u00bd, the final relative improvement depends significantly on the choice of \u00ed \u00b5\u00ed\u00bb\u00bc and \u00ed \u00b5\u00ed\u00bb\u00bd.", "labels": [], "entities": []}, {"text": "Systematic results are presented in the following section.", "labels": [], "entities": []}, {"text": "In the field of text classification, Macro-F1 is widely used to evaluate the performance.", "labels": [], "entities": [{"text": "text classification", "start_pos": 16, "end_pos": 35, "type": "TASK", "confidence": 0.8192704617977142}]}, {"text": "It is especially suitable for our work, because the Citation Sentiment Corpus is highly imbalanced.", "labels": [], "entities": [{"text": "Citation Sentiment Corpus", "start_pos": 52, "end_pos": 77, "type": "DATASET", "confidence": 0.8430937131245931}]}, {"text": "We did not compare our results with others.", "labels": [], "entities": []}, {"text": "As a consequence of different data preparation, algorithm setting and many other detailed factors, it is nontrivial to reproduce the results reported in other work.", "labels": [], "entities": [{"text": "algorithm setting", "start_pos": 48, "end_pos": 65, "type": "TASK", "confidence": 0.784040242433548}]}, {"text": "Moreover, in principle, our work is to examine the effectiveness of a novel feature on author level, which is independent to the utilization of other features on sentence level, etc.", "labels": [], "entities": []}, {"text": "(Athar, 2011 and Abujbara et al., 2013).", "labels": [], "entities": []}], "tableCaptions": []}