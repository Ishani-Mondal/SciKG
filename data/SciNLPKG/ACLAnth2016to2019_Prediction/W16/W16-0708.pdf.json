{"title": [], "abstractContent": [{"text": "We consider several antecedent prediction models that use no pipelined features generated by upstream systems.", "labels": [], "entities": []}, {"text": "Models trained in this way are interesting because they allow for side-stepping the intricacies of upstream models, and because we might expect them to generalize better to situations in which upstream features are unavailable or unreliable.", "labels": [], "entities": []}, {"text": "Through quantitative and qualitative error analysis we identify what sorts of cases are particularly difficult for such models, and suggest some directions for further improvement.", "labels": [], "entities": []}], "introductionContent": [{"text": "Most recent approaches to identity coreference resolution rely on a set of pipelined features generated by relatively accurate upstream systems.", "labels": [], "entities": [{"text": "identity coreference resolution", "start_pos": 26, "end_pos": 57, "type": "TASK", "confidence": 0.8649685382843018}]}, {"text": "For instance, the CoNLL 2012 coreference datasets, which are based on the OntoNotes corpus (), make available both gold and predicted parse, part-of-speech, and namedentity information for each sentence in the corpus.", "labels": [], "entities": [{"text": "CoNLL 2012 coreference datasets", "start_pos": 18, "end_pos": 49, "type": "DATASET", "confidence": 0.9447795748710632}, {"text": "OntoNotes corpus", "start_pos": 74, "end_pos": 90, "type": "DATASET", "confidence": 0.9340521991252899}]}, {"text": "While recent systems have managed to improve on the state of the art in coreference resolution by taking advantage of such information, we might be interested in systems that do not use pipelined features for several reasons: first, pipelined systems are known to accumulate errors throughout the stages of the pipeline.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 72, "end_pos": 94, "type": "TASK", "confidence": 0.9694176614284515}]}, {"text": "Second, unpipelined models do not need to contend with the intricacies of the various systems in the pipeline, which may have little impact on the target task.", "labels": [], "entities": []}, {"text": "Finally, models that do not require pipelined features maybe more applicable to regimes in which upstream features are unavailable or unreliable, such as those arising from predicting coreference in lowresource languages or in social media text.", "labels": [], "entities": []}, {"text": "Indeed, to the extent that it is easier to obtain coreference annotations than it is to obtain (for instance) parse annotations in such regimes, an unpipelined strategy maybe particularly practical.", "labels": [], "entities": []}, {"text": "Accordingly, in this paper we consider systems that attempt to move beyond OntoNotes by making coreference predictions without access to pipelined features, using only a document's words and sentence boundaries.", "labels": [], "entities": []}, {"text": "In the hopes of shedding light on whether this is a viable strategy, we consider, as a case study, how well coreference systems without access to upstream features can perform on English.", "labels": [], "entities": []}, {"text": "Given the amount of research that has gone into resolving English coreference resolution with pipelined features, by also considering the English \"unpipelined\" setting we can expect to get a rather accurate sense of how much we sacrifice by ignoring these features.", "labels": [], "entities": [{"text": "English coreference resolution", "start_pos": 58, "end_pos": 88, "type": "TASK", "confidence": 0.6558611492315928}]}, {"text": "Moreover, in addition to the benefits of unpipelined models noted above, the proposed line of research is congenial to the recent trend in NLP of using as few hand-engineered features as possible (as advocated, for instance, in).", "labels": [], "entities": []}, {"text": "We report preliminary experiments on the subtask of antecedent prediction (defined in and reviewed below) on the CoNLL 2012 English dataset in this unpipelined setting.", "labels": [], "entities": [{"text": "antecedent prediction", "start_pos": 52, "end_pos": 73, "type": "TASK", "confidence": 0.6802506148815155}, {"text": "CoNLL 2012 English dataset", "start_pos": 113, "end_pos": 139, "type": "DATASET", "confidence": 0.9796929061412811}]}, {"text": "In particular, we will assume that we have automatically extracted mentions from a document, but that no other pipelined information is available.", "labels": [], "entities": []}, {"text": "We emphasize that this is a strong assumption (since pipelined features, such as parse trees, are often used to extract mentions), and so what follows should be interpreted as an attempt to obtain an upper bound on the performance possible in such a setting.", "labels": [], "entities": []}, {"text": "We conclude by analyzing the errors made by the proposed unpipelined systems, and discussing how these systems might be made more competitive.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Example mentions x which the baseline MLP correctly predicts (middle column), but the Convolutional  Model (right column) does not. Heads of each mention (unseen by the Convolutional Model) are in brackets.", "labels": [], "entities": []}, {"text": " Table 2: Accuracy of models described in text (and base- line) on predicting antecedents on CoNLL Development  set.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9917451739311218}, {"text": "CoNLL Development  set", "start_pos": 93, "end_pos": 115, "type": "DATASET", "confidence": 0.9573177297910055}]}]}