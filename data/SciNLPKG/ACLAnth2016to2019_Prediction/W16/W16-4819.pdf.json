{"title": [{"text": "A Character-level Convolutional Neural Network for Distinguishing Similar Languages and Dialects", "labels": [], "entities": [{"text": "Distinguishing Similar Languages and Dialects", "start_pos": 51, "end_pos": 96, "type": "TASK", "confidence": 0.8117491126060485}]}], "abstractContent": [{"text": "Discriminating between closely-related language varieties is considered a challenging and important task.", "labels": [], "entities": [{"text": "Discriminating between closely-related language varieties", "start_pos": 0, "end_pos": 57, "type": "TASK", "confidence": 0.8205011010169982}]}, {"text": "This paper describes our submission to the DSL 2016 shared-task, which included two sub-tasks: one on discriminating similar languages and one on identifying Arabic dialects.", "labels": [], "entities": []}, {"text": "We developed a character-level neural network for this task.", "labels": [], "entities": []}, {"text": "Given a sequence of characters, our model embeds each character in vector space, runs the sequence through multiple convolutions with different filter widths, and pools the convolutional representations to obtain a hidden vector representation of the text that is used for predicting the language or dialect.", "labels": [], "entities": []}, {"text": "We primarily focused on the Arabic dialect identification task and obtained an F1 score of 0.4834, ranking 6th out of 18 participants.", "labels": [], "entities": [{"text": "Arabic dialect identification task", "start_pos": 28, "end_pos": 62, "type": "TASK", "confidence": 0.6628411263227463}, {"text": "F1 score", "start_pos": 79, "end_pos": 87, "type": "METRIC", "confidence": 0.9869693219661713}]}, {"text": "We also analyze errors made by our system on the Arabic data in some detail, and point to challenges such an approach is faced with.", "labels": [], "entities": [{"text": "Arabic data", "start_pos": 49, "end_pos": 60, "type": "DATASET", "confidence": 0.7024335563182831}]}], "introductionContent": [{"text": "Automatic language identification is an important first step in many applications.", "labels": [], "entities": [{"text": "Automatic language identification", "start_pos": 0, "end_pos": 33, "type": "TASK", "confidence": 0.7503232955932617}]}, {"text": "For many languages and texts, this is a fairly easy step that can be solved with familiar methods like n-gram language models.", "labels": [], "entities": []}, {"text": "However, distinguishing between similar languages is not so easy.", "labels": [], "entities": []}, {"text": "The shared-task on discriminating between similar languages (DSL) has offered a test bed for evaluating models on this task since).", "labels": [], "entities": []}, {"text": "The 2016 shared-task included two sub-tasks: (1) discriminating between similar languages from several groups; and (2) discriminating between Arabic dialects ( ).", "labels": [], "entities": []}, {"text": "The following language varieties were considered in sub-task 1: Bosnian, Croatian, and Serbian; Malay and Indonesian; Portuguese of Brazil and Portugal; Spanish of Argentina, Mexico, and Spain; and French of France and Canada.", "labels": [], "entities": []}, {"text": "In sub-task 2, the following Arabic varieties were considered: Levantine, Gulf, Egyptian, North African, and Modern Standard Arabic (MSA).", "labels": [], "entities": [{"text": "Modern Standard Arabic (MSA)", "start_pos": 109, "end_pos": 137, "type": "DATASET", "confidence": 0.7242131680250168}]}, {"text": "The training datasets released in the two sub-tasks were very different.", "labels": [], "entities": []}, {"text": "Sub-task 1 was comprised of journalistic texts and included training and development sets.", "labels": [], "entities": []}, {"text": "Sub-task 2 had automatic transcriptions of spoken recordings and included only a training set.", "labels": [], "entities": []}, {"text": "This was the first time DSL has offered a task on Arabic dialects.", "labels": [], "entities": []}, {"text": "The shared-task also included an open track that allows additional resources, but we have only participated in the closed track.", "labels": [], "entities": []}, {"text": "Previous DSL competitions attracted a variety of methods, achieving very high results with accuracies of over 95%.", "labels": [], "entities": [{"text": "accuracies", "start_pos": 91, "end_pos": 101, "type": "METRIC", "confidence": 0.9987441301345825}]}, {"text": "Most teams used character and word n-grams with various classifiers.", "labels": [], "entities": []}, {"text": "One team in 2015 used vector embeddings of words and sentences, achieving very good, though not state-of-the-art results.", "labels": [], "entities": []}, {"text": "They trained unsupervised vectors and fed them as input to a classifier.", "labels": [], "entities": []}, {"text": "Here we are interested in character-level neural network models.", "labels": [], "entities": []}, {"text": "Such models showed recent success in other tasks (, among many others).", "labels": [], "entities": []}, {"text": "The basic question we ask is this: how well can a character-level neural network perform on this task without the notion of a word?", "labels": [], "entities": []}, {"text": "To answer this, our model takes as input a sequence of characters, embeds them in vector space, and generates a high-level representation of the sequence through multiple convolutional layers.", "labels": [], "entities": []}, {"text": "At the top of the network, we output a probability distribution over labels and backpropagate errors, such that the entire network can be learned end-to-end.", "labels": [], "entities": []}, {"text": "We experimented with several configurations of convolutional layers, focusing on Arabic dialect identification (sub-task 2).", "labels": [], "entities": [{"text": "Arabic dialect identification", "start_pos": 81, "end_pos": 110, "type": "TASK", "confidence": 0.5743942757447561}]}, {"text": "We also participated in sub-task 1, but have not tuned our system to this scenario.", "labels": [], "entities": []}, {"text": "Our best system obtained an F1 score of 0.4834 on the Arabic sub-task, ranking 6th out of 18 participants.", "labels": [], "entities": [{"text": "F1 score", "start_pos": 28, "end_pos": 36, "type": "METRIC", "confidence": 0.9844673871994019}]}, {"text": "The same system did not perform well on sub-task 1 (ranked 2nd to last), although we have not spent much time on adapting it to this task.", "labels": [], "entities": []}, {"text": "In the next section, we discuss related work on identifying similar languages and dialects.", "labels": [], "entities": []}, {"text": "We then present our methodology and results, and conclude with a discussion and a short error analysis for the Arabic system that sheds light on potential sources of errors.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 2: Results for our submitted runs. Best results out of our runs are in bold; best overall systems  shown in italics for reference. Refer to the text for a description of runs and baselines.", "labels": [], "entities": []}]}