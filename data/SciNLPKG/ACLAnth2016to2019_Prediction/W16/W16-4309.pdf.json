{"title": [{"text": "Generating Sentiment Lexicons for German Twitter", "labels": [], "entities": [{"text": "Generating Sentiment Lexicons", "start_pos": 0, "end_pos": 29, "type": "TASK", "confidence": 0.7982625365257263}]}], "abstractContent": [{"text": "Despite substantial progress made in developing new sentiment lexicon generation (SLG) methods for English, the task of transferring these approaches to other languages and domains in a sound way still remains open.", "labels": [], "entities": [{"text": "sentiment lexicon generation (SLG)", "start_pos": 52, "end_pos": 86, "type": "TASK", "confidence": 0.8260154873132706}]}, {"text": "In this paper, we contribute to the solution of this problem by systematically comparing semi-automatic translations of common English polarity lists with the results of the original automatic SLG algorithms, which were applied directly to German data.", "labels": [], "entities": []}, {"text": "We evaluate these lexicons on a corpus of 7,992 manually annotated tweets.", "labels": [], "entities": []}, {"text": "In addition to that, we also collate the results of dictionary-and corpus-based SLG methods in order to find out which of these paradigms is better suited for the inherently noisy domain of social media.", "labels": [], "entities": []}, {"text": "Our experiments show that semi-automatic translations notably outperform automatic systems (reaching a macro-averaged F 1-score of 0.589), and that dictionary-based techniques produce much better polarity lists as compared to corpus-based approaches (whose best F 1-scores run up to 0.479 and 0.419 respectively) even for the non-standard Twitter genre.", "labels": [], "entities": [{"text": "F 1-score", "start_pos": 118, "end_pos": 127, "type": "METRIC", "confidence": 0.9592642784118652}]}, {"text": "All reimplementa-tions of the compared systems and the resulting lexicons of these methods are available online at https://github.com/WladimirSidorenko/SentiLex.", "labels": [], "entities": []}], "introductionContent": [{"text": "Sentiment lexicons play a crucial role in many existing and emerging opinion mining applications.", "labels": [], "entities": [{"text": "opinion mining", "start_pos": 69, "end_pos": 83, "type": "TASK", "confidence": 0.7738677263259888}]}, {"text": "Not only do they serve as a valuable source of features for supervised classifiers) but they also achieve competitive results when used as the main component of a sentiment analysis system).", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 163, "end_pos": 181, "type": "TASK", "confidence": 0.9229767620563507}]}, {"text": "Due to this high impact and tremendous costs of building such lexicons manually, devising new algorithms for an automatic generation of polarity lists has always been an area of active research in the sentiment analysis literature.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 201, "end_pos": 219, "type": "TASK", "confidence": 0.9357436299324036}]}, {"text": "Nevertheless, despite some obvious progress in this field (, the applicability of these approaches to other languages and text genres still raises questions: It is, for instance, unclear whether simply translating the existing English sentiment resources would produce better results than applying the methods that were initially proposed for their creation directly to the target language.", "labels": [], "entities": []}, {"text": "Furthermore, for automatic systems which draw their knowledge from lexical taxonomies, such as WORDNET, it remains unanswered whether these approaches would also work for languages in which such resources are much smaller in size, and, even if they would, whether the resulting lexicons would then be general enough to carryover to more colloquial texts.", "labels": [], "entities": []}, {"text": "Finally, for methods which derive their polarity lists from text corpora, it is not clear whether these approaches would still yield an acceptable quality when operating on inherently noisy input data.", "labels": [], "entities": []}, {"text": "In this paper, we try to analyze these and other problems in detail, using the example of German Twitter.", "labels": [], "entities": [{"text": "German Twitter", "start_pos": 90, "end_pos": 104, "type": "DATASET", "confidence": 0.8978919088840485}]}, {"text": "More precisely, given a collection of German microblogs with manually labeled polar terms and prior polarities of these expressions, we want to find an SLG method that can best predict these terms and their semantic orientation.", "labels": [], "entities": []}, {"text": "For this purpose, we compare the existing German sentiment lexicons (most of which were semi-automatically translated from popular English resources) with the results of common automatic dictionary-and corpus-based SLG approaches.", "labels": [], "entities": []}, {"text": "We begin our study by describing the data set which will be used in our evaluation.", "labels": [], "entities": []}, {"text": "Afterwards, in Section 3, we introduce the metrics with which we will assess the quality of various polarity lists.", "labels": [], "entities": []}, {"text": "Then, in Section 4, we evaluate three most popular existing German sentiment lexicons-the German Polarity Clues,, and Zurich Polarity List of, subsequently comparing them with popular automatic SLG approaches in Section 5.", "labels": [], "entities": [{"text": "German sentiment lexicons-the German Polarity Clues", "start_pos": 60, "end_pos": 111, "type": "DATASET", "confidence": 0.7170092463493347}, {"text": "Zurich Polarity List", "start_pos": 118, "end_pos": 138, "type": "DATASET", "confidence": 0.7024523516496023}]}, {"text": "Finally, after estimating the impact of different seed sets on the automatic methods and performing a qualitative analysis of their entries, we draw our conclusions and outline directions for future research in the final part of this paper.", "labels": [], "entities": []}, {"text": "To avoid unnecessary repetitions, we deliberately omit a summary of related work, since most of the popular SLG algorithms will be referenced in the respective evaluation sections anyway.", "labels": [], "entities": []}, {"text": "We should, however, note that, apart from the research on the automatic lexicon generation, our study is also closely related to the experiments of and the \"Sentiment Analysis in Twitter\" track of the SemEval competition (.", "labels": [], "entities": [{"text": "automatic lexicon generation", "start_pos": 62, "end_pos": 90, "type": "TASK", "confidence": 0.6779019037882487}]}, {"text": "In contrast to the former work, however, where the authors trained a supervised classifier on one domain and applied it to another in order to determine the polarities of the sentences, we explicitly model a situation where no annotated training data are available, thus looking for the most general unsupervised SLG strategy which performs best regardless of the target domain, and we also evaluate these strategies on the level of lexical phrases only.", "labels": [], "entities": []}, {"text": "Furthermore, unlike in the SemEval track, where the organizers also provided participants with sufficient labeled in-domain training sets and then asked them to predict the contextual polarity of pre-annotated polar expressions in the test data, we simultaneously try to predict polar terms and their prior polarities, learning both of them without supervision.", "labels": [], "entities": []}], "datasetContent": [{"text": "A central question to our experiments are the evaluation metrics that we should use for measuring lexicon quality.", "labels": [], "entities": []}, {"text": "Usually, this quality is estimated either intrinsically (i.e., taking a lexicon in isolation and immediately assessing its accuracy) or extrinsically (i.e., considering the lexicon within the scope of a bigger application such as a supervised classifier which utilizes lexicon's entries as features).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 123, "end_pos": 131, "type": "METRIC", "confidence": 0.992732584476471}]}, {"text": "Traditionally, intrinsic evaluation of English sentiment lexicons amounts to comparing these polarity lists with the General Inquirer (GI; Stone, 1966)-a manually compiled set of 11,895 words annotated with their semantic categories-by taking the intersection of the two resources and estimating the percentage of matches in which automatically induced polar terms have the same polarity as the GI entries.", "labels": [], "entities": [{"text": "evaluation of English sentiment lexicons", "start_pos": 25, "end_pos": 65, "type": "TASK", "confidence": 0.6461979925632477}, {"text": "General Inquirer (GI; Stone, 1966)-a manually compiled set", "start_pos": 117, "end_pos": 175, "type": "DATASET", "confidence": 0.8455006663615887}]}, {"text": "This evaluation method, however, is somewhat problematic: First of all, it is not easily transferable to other languages, since even a manual translation of the GI lexicon is not guaranteed to coverall languageand domain-specific polar expressions.", "labels": [], "entities": []}, {"text": "Secondly, due to the intersection, this method does not penalize fora low recall so that a lexicon consisting of just two terms good + and bad \u2212 will have the highest possible score, often surpassing polarity lists with a greater number of entries.", "labels": [], "entities": [{"text": "recall", "start_pos": 74, "end_pos": 80, "type": "METRIC", "confidence": 0.9971619844436646}]}, {"text": "Finally, this comparison does not account for polysemy.", "labels": [], "entities": []}, {"text": "As a result, an ambiguous word only one of whose (possibly rare) senses is subjective will always be ranked the same as a purely polar term.", "labels": [], "entities": []}, {"text": "Unfortunately, an extrinsic evaluation does not always provide a solution in this case, since, depending on the type of the extrinsic system (e.g., a document classifier), it might still presuppose a large data set for training other system components and, furthermore, might yield overly high scores, which, however, are mainly due to these extrinsic modules rather than the quality of the lexicons themselves.", "labels": [], "entities": []}, {"text": "Instead of using these approaches, we opt fora direct comparison of the induced polarity lists with an existing annotated corpus, since this type of evaluation allows us to solve at least three of the previously mentioned issues: It does account for the recall, it does accommodate polysemous words, and it does preclude intermediate components which might artificially boost the results.", "labels": [], "entities": [{"text": "recall", "start_pos": 254, "end_pos": 260, "type": "METRIC", "confidence": 0.9882065653800964}]}, {"text": "In particular, in order to check a lexicon against the PotTS data set, we construct a case-insensitive trie) from the lexicon entries and match this trie against the contiguously running corpus text, simultaneously comparing it with the actual word forms and lemmas of corpus tokens.", "labels": [], "entities": [{"text": "PotTS data set", "start_pos": 55, "end_pos": 69, "type": "DATASET", "confidence": 0.9775378902753195}]}, {"text": "7 A match is considered correct iff the matched entry absolutely corresponds to the (possibly lemmatized) expert's annotation and has the same polarity as the one specified by the human coder.", "labels": [], "entities": []}, {"text": "That way, we estimate the precision, recall, and F 1 -score for each particular polarity class (positive, negative, and neutral), considering all words absent in the lexicons (not annotated in the corpus) as neutral.", "labels": [], "entities": [{"text": "precision", "start_pos": 26, "end_pos": 35, "type": "METRIC", "confidence": 0.9996578693389893}, {"text": "recall", "start_pos": 37, "end_pos": 43, "type": "METRIC", "confidence": 0.9990941286087036}, {"text": "F 1 -score", "start_pos": 49, "end_pos": 59, "type": "METRIC", "confidence": 0.9905652850866318}]}], "tableCaptions": [{"text": " Table 1: Evaluation of semi-automatic German sentiment lexicons.  GPC -German Polarity Clues", "labels": [], "entities": [{"text": "GPC -German Polarity Clues", "start_pos": 67, "end_pos": 93, "type": "DATASET", "confidence": 0.8461865305900573}]}, {"text": " Table 2: Evaluation of dictionary-based approaches.  HL -Hu and Liu (2004), BG -Blair-Goldensohn et al. (2008), KH -Kim and Hovy (2004), ES -Esuli and Sebastiani (2006),  RR -Rao and Ravichandran (2009), AR -Awadallah and Radev (2010)", "labels": [], "entities": []}]}