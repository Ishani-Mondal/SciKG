{"title": [{"text": "Combining fast align with Hierarchical Sub-sentential Alignment for Better Word Alignments", "labels": [], "entities": [{"text": "Hierarchical Sub-sentential Alignment", "start_pos": 26, "end_pos": 63, "type": "TASK", "confidence": 0.6070595979690552}, {"text": "Word Alignments", "start_pos": 75, "end_pos": 90, "type": "TASK", "confidence": 0.7113323658704758}]}], "abstractContent": [{"text": "fast align is a simple and fast word alignment tool which is widely used in state-of-the-art machine translation systems.", "labels": [], "entities": [{"text": "word alignment", "start_pos": 32, "end_pos": 46, "type": "TASK", "confidence": 0.714088961482048}, {"text": "machine translation", "start_pos": 93, "end_pos": 112, "type": "TASK", "confidence": 0.7392062842845917}]}, {"text": "It yields comparable results in the end-to-end translation experiments of various language pairs.", "labels": [], "entities": []}, {"text": "However, fast align does not perform as well as GIZA++ when applied to language pairs with distinct word orders, like English and Japanese.", "labels": [], "entities": []}, {"text": "In this paper, given the lexical translation table output by fast align, we propose to realign words using the hierarchical sub-sentential alignment approach.", "labels": [], "entities": []}, {"text": "Experimental results show that simple additional processing improves the performance of word alignment, which is measured by counting alignment matches in comparison with fast align.", "labels": [], "entities": [{"text": "word alignment", "start_pos": 88, "end_pos": 102, "type": "TASK", "confidence": 0.7550301551818848}]}, {"text": "We also report the result of final machine translation in both English-Japanese and Japanese-English.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 35, "end_pos": 54, "type": "TASK", "confidence": 0.5163539052009583}]}, {"text": "We show our best system provided significant improvements over the baseline as measured by BLEU and RIBES.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 91, "end_pos": 95, "type": "METRIC", "confidence": 0.9987142086029053}, {"text": "RIBES", "start_pos": 100, "end_pos": 105, "type": "METRIC", "confidence": 0.9747899174690247}]}], "introductionContent": [{"text": "Since state-of-the-art machine translation systems start with word aligned data, the processing of word alignment plays a fundamental role in machine translation.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 23, "end_pos": 42, "type": "TASK", "confidence": 0.748613715171814}, {"text": "word alignment", "start_pos": 99, "end_pos": 113, "type": "TASK", "confidence": 0.7202565222978592}, {"text": "machine translation", "start_pos": 142, "end_pos": 161, "type": "TASK", "confidence": 0.8440040349960327}]}, {"text": "A reliable and accurate word aligner is considered as an essential component in the various implementations of machine translation, e.g., wordbased model (, phrase-based model (, hierarchical phrase-based model ( and tree-to-tree model.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 111, "end_pos": 130, "type": "TASK", "confidence": 0.7112480252981186}]}, {"text": "In general, word alignment is prerequisite for extracting rules or sub-translations (word pairs, phrase pairs or partial tree templates) for translation.", "labels": [], "entities": [{"text": "word alignment", "start_pos": 12, "end_pos": 26, "type": "TASK", "confidence": 0.8135682046413422}]}, {"text": "The most widely used word aligner is GIZA++), which is based on generative models, like IBM models ( and HMM-based model (, in which parameters are estimated using the Expectation-Maximization (EM) algorithm.", "labels": [], "entities": []}, {"text": "This generative approach allows GIZA++ to automatically extract bilingual lexicon from parallel corpus without any annotated data.", "labels": [], "entities": []}, {"text": "Besides, a variation of IBM model 2 was implemented as fast align, which allows an effective alignment of words.", "labels": [], "entities": []}, {"text": "There is no doubt that fast align is almost the fastest word aligner, while keeping the quality of alignment, compared to the baseline using GIZA++ 2 (Och and Ney, 2003), or MGIZA++ 3 (.", "labels": [], "entities": []}, {"text": "However, demonstrated that fast align does not outperform the baseline GIZA++, especially for the distantly related language pairs, like English-Japanese or Chinese-English.", "labels": [], "entities": []}, {"text": "The reason maybe explained by the fact that, given a source word, fast align tends to limit the probable target translation and its alignment nearest as possible to the diagonal in the alignment matrix according to the overall word orders, which is the drawback of IBM-model 2 ( and its variations, in terms of being insensitive to word orders.", "labels": [], "entities": []}, {"text": "The word alignments output by fast align are often more compact represented in alignment matrices.", "labels": [], "entities": []}, {"text": "For the case of distinct language pairs, this strategy damages the quality of the final alignment result.", "labels": [], "entities": []}, {"text": "Since IBM Model is restriction of one-to-many (1-m) alignments, some multi-word units cannot be correctly aligned.", "labels": [], "entities": [{"text": "IBM Model", "start_pos": 6, "end_pos": 15, "type": "DATASET", "confidence": 0.8954043388366699}]}, {"text": "It is necessary to train models in both directions, and merge the outcome of monodirectional alignments using some symmetrization methods, for example, grow-diag-final-and (.", "labels": [], "entities": []}, {"text": "Though this method can overcome the mentioned deficiency to some degree, the strong assumption of 1-m alignment forces the aligner to generate 1-best alignments, which is prone to learn noisy rules due to alignment or segmentation mistakes.", "labels": [], "entities": []}, {"text": "Another problem exists is that the production of 1-m alignment losses the structural information of the whole sentence while phrase-based (or other kinds of statistical machine translation systems) relies on the continuous translation fragments.", "labels": [], "entities": [{"text": "statistical machine translation", "start_pos": 157, "end_pos": 188, "type": "TASK", "confidence": 0.7113282283147176}]}, {"text": "It has been proved that by applying structural models such as Inversion Transduction Grammars (ITG) (Wu, 1997) will achieve some gain.", "labels": [], "entities": []}, {"text": "ITG has been widely applied to word alignment, bilingual parsing, etc., due to its simplicity and effectiveness of modeling bilingual correspondence.", "labels": [], "entities": [{"text": "word alignment", "start_pos": 31, "end_pos": 45, "type": "TASK", "confidence": 0.8208973705768585}, {"text": "bilingual parsing", "start_pos": 47, "end_pos": 64, "type": "TASK", "confidence": 0.7802220284938812}]}, {"text": "However, inducing ITGs from parallel data would be time-consuming.", "labels": [], "entities": []}, {"text": "In this paper, in order to integrate ITG with IBM model, we propose to apply the hierarchical subsentential alignment (HSSA) () approach to realign word alignments.", "labels": [], "entities": [{"text": "realign word alignments", "start_pos": 140, "end_pos": 163, "type": "TASK", "confidence": 0.6318225860595703}]}, {"text": "HSSA is an online word alignment approach, which was first introduced as complementary to Anymalign 4 . When fed with the lexical weights output by Anymalign, it yields comparable results with baseline MGIZA++.", "labels": [], "entities": [{"text": "HSSA", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.8704965710639954}, {"text": "word alignment", "start_pos": 18, "end_pos": 32, "type": "TASK", "confidence": 0.7493274807929993}]}, {"text": "In fact, an important advantage of this approach is that it can be combined with any other existing approach by reusing the lexical weights output by this other approach.", "labels": [], "entities": []}, {"text": "We make use of the structure named soft alignment matrix () to represent the alignment distribution fora given sentence pair, which cells are weighted by the lexical weights output by fast align.", "labels": [], "entities": []}, {"text": "With the recursive binary segmentation processing in HSSA, we realign the sentence pairs top-down.", "labels": [], "entities": [{"text": "HSSA", "start_pos": 53, "end_pos": 57, "type": "DATASET", "confidence": 0.8073580265045166}]}, {"text": "We also present a simple but effective method to deal with error alignment points produced by this hybrid method, i.e., conflicting cells in soft alignment matrices.", "labels": [], "entities": []}, {"text": "In Section 2 and Section 3, the notion of soft alignment matrix and HSSA will be introduced.", "labels": [], "entities": [{"text": "soft alignment matrix", "start_pos": 42, "end_pos": 63, "type": "TASK", "confidence": 0.6577549080053965}, {"text": "HSSA", "start_pos": 68, "end_pos": 72, "type": "METRIC", "confidence": 0.5302433371543884}]}, {"text": "The hybrid combination architecture of our proposed method will be illustrated in Section 4.", "labels": [], "entities": []}, {"text": "Experimental results and the analysis will be given in the following Section 4.", "labels": [], "entities": []}, {"text": "Finally, Section 6 draws the conclusion and future work.", "labels": [], "entities": []}], "datasetContent": [{"text": "English-Japanese alignment and translation is a much harder task for fast align than French-English alignment).", "labels": [], "entities": [{"text": "translation", "start_pos": 31, "end_pos": 42, "type": "TASK", "confidence": 0.9188001751899719}]}, {"text": "In our experiments, standard phrase-based statistical machine translation systems were built by using the Moses toolkit (, Minimum Error Rate Training, and the KenLM language model).", "labels": [], "entities": [{"text": "phrase-based statistical machine translation", "start_pos": 29, "end_pos": 73, "type": "TASK", "confidence": 0.5791735723614693}, {"text": "Minimum Error Rate Training", "start_pos": 123, "end_pos": 150, "type": "METRIC", "confidence": 0.7731789797544479}]}, {"text": "The default training pipeline for phrasebased SMT is adopted with default distortion-limit 6.", "labels": [], "entities": [{"text": "phrasebased SMT", "start_pos": 34, "end_pos": 49, "type": "TASK", "confidence": 0.5831589102745056}]}, {"text": "Two baseline systems, one built with GIZA++ and another built with fast align, are prepared for result comparison.", "labels": [], "entities": [{"text": "GIZA", "start_pos": 37, "end_pos": 41, "type": "METRIC", "confidence": 0.7463315725326538}]}, {"text": "For the evaluation of machine translation quality, some standard automatic evaluation metrics have been used, like BLEU () and RIBES () in all experiments.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 22, "end_pos": 41, "type": "TASK", "confidence": 0.7597882151603699}, {"text": "BLEU", "start_pos": 115, "end_pos": 119, "type": "METRIC", "confidence": 0.998831570148468}, {"text": "RIBES", "start_pos": 127, "end_pos": 132, "type": "METRIC", "confidence": 0.9925931096076965}]}, {"text": "Since BLEU is insensitive to long-distance displacements of large sequences of words, we also use RIBES which was designed to take distinct word orders into consideration.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 6, "end_pos": 10, "type": "METRIC", "confidence": 0.9959695339202881}, {"text": "RIBES", "start_pos": 98, "end_pos": 103, "type": "METRIC", "confidence": 0.9600192904472351}]}, {"text": "In order to ensure a consistent, repeatable and reproducible experiment, we use the original training, tuning and test sets provided in KFTT corpus 8 . We first report the performance of various alignment profiles in terms of precision, recall and alignment error rate (AER) on the basis of human annotated alignment data provided with the KFTT corpus in.", "labels": [], "entities": [{"text": "KFTT corpus 8", "start_pos": 136, "end_pos": 149, "type": "DATASET", "confidence": 0.9535951018333435}, {"text": "precision", "start_pos": 226, "end_pos": 235, "type": "METRIC", "confidence": 0.9993129968643188}, {"text": "recall", "start_pos": 237, "end_pos": 243, "type": "METRIC", "confidence": 0.9973503351211548}, {"text": "alignment error rate (AER)", "start_pos": 248, "end_pos": 274, "type": "METRIC", "confidence": 0.9536732335885366}, {"text": "KFTT corpus", "start_pos": 340, "end_pos": 351, "type": "DATASET", "confidence": 0.9838941097259521}]}, {"text": "The first and second lines show the alignment difference using GIZA++ and fast align.", "labels": [], "entities": [{"text": "alignment", "start_pos": 36, "end_pos": 45, "type": "METRIC", "confidence": 0.9929900169372559}, {"text": "GIZA", "start_pos": 63, "end_pos": 67, "type": "METRIC", "confidence": 0.9204718470573425}]}, {"text": "The original HSSA, which allows 1-to-many or many-to-1 alignments, outperforms the fast align baseline from the point view of matching alignments and recall against the reference.", "labels": [], "entities": [{"text": "HSSA", "start_pos": 13, "end_pos": 17, "type": "DATASET", "confidence": 0.7637764811515808}, {"text": "recall", "start_pos": 150, "end_pos": 156, "type": "METRIC", "confidence": 0.9941336512565613}]}, {"text": "The total number of alignments is much higher than with fast align which victim of the \"noisy alignments\" problem mentioned in Section 4.", "labels": [], "entities": []}, {"text": "AER and precision are behind fast align, even more than GIZA++ baseline.", "labels": [], "entities": [{"text": "AER", "start_pos": 0, "end_pos": 3, "type": "METRIC", "confidence": 0.993802011013031}, {"text": "precision", "start_pos": 8, "end_pos": 17, "type": "METRIC", "confidence": 0.9996222257614136}, {"text": "GIZA++ baseline", "start_pos": 56, "end_pos": 71, "type": "DATASET", "confidence": 0.6284933686256409}]}, {"text": "However,) question the link between this word alignment quality metrics and translation results, like whether improvements in alignment quality metrics lead to improvements in phrase-based machine translation performance.", "labels": [], "entities": [{"text": "phrase-based machine translation", "start_pos": 176, "end_pos": 208, "type": "TASK", "confidence": 0.6174465119838715}]}, {"text": "A lower AER does not imply a better translation accuracy.", "labels": [], "entities": [{"text": "AER", "start_pos": 8, "end_pos": 11, "type": "METRIC", "confidence": 0.9993226528167725}, {"text": "accuracy", "start_pos": 48, "end_pos": 56, "type": "METRIC", "confidence": 0.8765249252319336}]}, {"text": "We show it in the following discussion.", "labels": [], "entities": []}, {"text": "When sampling the alignment results, we found that the output of the proposed hybrid approach usually generates better alignments than the baseline.", "labels": [], "entities": []}, {"text": "Experimental results in both direction for English-Japanese and Japanese-English are shown in the right part of.", "labels": [], "entities": []}, {"text": "Specially for Japanese, we skip the particles like {ga, wo, ha} and remove them from the data before implementing word alignments.", "labels": [], "entities": [{"text": "word alignments", "start_pos": 114, "end_pos": 129, "type": "TASK", "confidence": 0.7214042544364929}]}, {"text": "Translation in both direction is improved significantly over the fast align baseline 9 in BLEU and RIBES.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 90, "end_pos": 94, "type": "METRIC", "confidence": 0.9939914345741272}, {"text": "RIBES", "start_pos": 99, "end_pos": 104, "type": "METRIC", "confidence": 0.8603987097740173}]}, {"text": "It is not surprising that the pruning processing performs worse on Japanese-English not as well as English-Japanese, because a single English word maybe aligned with several Japanese words.", "labels": [], "entities": []}, {"text": "Perhaps deleting low confidence alignments in the many-to-1 case impacts consistency in phrases during phrase extraction.", "labels": [], "entities": [{"text": "consistency", "start_pos": 73, "end_pos": 84, "type": "METRIC", "confidence": 0.9825736880302429}, {"text": "phrase extraction", "start_pos": 103, "end_pos": 120, "type": "TASK", "confidence": 0.7694444060325623}]}], "tableCaptions": [{"text": " Table 1: Word alignment scores on English-Japanese and translation scores (BLEU and RIBES) in both  directions (English-Japanese and Japanese-English). prune is the case when filtering all alignments in  1-n/n-1 blocks using a threshold \u03b3 > 0.001. Boldface indicates no significantly different with GIZA++  baseline (  \u2020 : p < 0.05,  \u2021 : p < 0.01 ) .", "labels": [], "entities": [{"text": "BLEU", "start_pos": 76, "end_pos": 80, "type": "METRIC", "confidence": 0.9943273663520813}, {"text": "RIBES", "start_pos": 85, "end_pos": 90, "type": "METRIC", "confidence": 0.9291680455207825}, {"text": "prune", "start_pos": 153, "end_pos": 158, "type": "METRIC", "confidence": 0.9718400835990906}, {"text": "GIZA++  baseline", "start_pos": 300, "end_pos": 316, "type": "DATASET", "confidence": 0.8403459787368774}]}]}