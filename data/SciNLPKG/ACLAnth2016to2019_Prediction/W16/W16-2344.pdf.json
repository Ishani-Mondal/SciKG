{"title": [], "abstractContent": [{"text": "This paper describes our submission to the Tuning Task of WMT16.", "labels": [], "entities": [{"text": "Tuning Task of WMT16", "start_pos": 43, "end_pos": 63, "type": "TASK", "confidence": 0.7532858997583389}]}, {"text": "We replace the grid search implemented as part of standard minimum-error rate training (MERT) in the Moses toolkit with a search based on particle swarm optimization (PSO).", "labels": [], "entities": [{"text": "minimum-error rate training (MERT)", "start_pos": 59, "end_pos": 93, "type": "METRIC", "confidence": 0.7189028163750967}, {"text": "particle swarm optimization (PSO)", "start_pos": 138, "end_pos": 171, "type": "TASK", "confidence": 0.7956412136554718}]}, {"text": "An older variant of PSO has been previously successfully applied and we now test it in optimizing the Tuning Task model for English-to-Czech translation.", "labels": [], "entities": [{"text": "Tuning Task", "start_pos": 102, "end_pos": 113, "type": "TASK", "confidence": 0.8785958588123322}]}, {"text": "We also adapt the method in some aspects to allow for even easier parallelization of the search.", "labels": [], "entities": []}], "introductionContent": [{"text": "Common models of statistical machine translation (SMT) consist of multiple features which assign probabilities or scores to possible translations.", "labels": [], "entities": [{"text": "statistical machine translation (SMT)", "start_pos": 17, "end_pos": 54, "type": "TASK", "confidence": 0.7929652084906896}]}, {"text": "These are then combined in a weighted sum to determine the best translation given by the model.", "labels": [], "entities": []}, {"text": "Tuning within SMT refers to the process of finding the optimal weights for these features on a given tuning set.", "labels": [], "entities": [{"text": "SMT", "start_pos": 14, "end_pos": 17, "type": "TASK", "confidence": 0.7744567394256592}]}, {"text": "This paper describes our submission to WMT16 Tuning Task 1 , a shared task where all the SMT model components and the tuning set are given and task participants are expected to provide only the weight settings.", "labels": [], "entities": [{"text": "WMT16 Tuning Task 1", "start_pos": 39, "end_pos": 58, "type": "TASK", "confidence": 0.71564581990242}, {"text": "SMT", "start_pos": 89, "end_pos": 92, "type": "TASK", "confidence": 0.9794619679450989}]}, {"text": "We took part only in English-to-Czech system tuning.", "labels": [], "entities": []}, {"text": "Our solution is based on the standard tuning method of Minimum Error-Rate Training).", "labels": [], "entities": [{"text": "Minimum Error-Rate Training", "start_pos": 55, "end_pos": 82, "type": "METRIC", "confidence": 0.6499071518580118}]}, {"text": "The MERT algorithm described in is the default tuning method in the Moses SMT toolkit (.", "labels": [], "entities": [{"text": "MERT", "start_pos": 4, "end_pos": 8, "type": "METRIC", "confidence": 0.7354710698127747}, {"text": "Moses SMT toolkit", "start_pos": 68, "end_pos": 85, "type": "DATASET", "confidence": 0.7744991978009542}]}, {"text": "The inner loop of the algorithm performs optimization on a space of weight vectors with a given translation metric 2 . The standard optimization is a variant of grid search and in our work, we replace it with the Particle Swarm Optimization (PSO, algorithm.", "labels": [], "entities": [{"text": "Particle Swarm Optimization (PSO", "start_pos": 213, "end_pos": 245, "type": "TASK", "confidence": 0.782361876964569}]}, {"text": "Particle Swarm Optimization is a good candidate for an efficient implementation of the inner loop of MERT due to the nature of the optimization space.", "labels": [], "entities": [{"text": "Particle Swarm Optimization", "start_pos": 0, "end_pos": 27, "type": "TASK", "confidence": 0.6935826142628988}]}, {"text": "The so-called Traditional PSO (TPSO) has already been tested by, with a success.", "labels": [], "entities": [{"text": "Traditional PSO (TPSO", "start_pos": 14, "end_pos": 35, "type": "DATASET", "confidence": 0.7142885625362396}]}, {"text": "Improved versions of the PSO algorithm, known as Standard PSO (SPSO), have been summarized in.", "labels": [], "entities": []}, {"text": "In this paper, we test a modified version of the latest SPSO2011 algorithm within the Moses toolkit and compare its results and computational costs with the standard Moses implementation of MERT.", "labels": [], "entities": [{"text": "MERT", "start_pos": 190, "end_pos": 194, "type": "DATASET", "confidence": 0.7362609505653381}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: The final best BLEU score after the runs of the inner loop for PSO without and with the  termination condition with 16 and 64 threads respectively and standard Moses MERT implementation  with 16 threads.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 25, "end_pos": 29, "type": "METRIC", "confidence": 0.9991344809532166}]}, {"text": " Table 2: Average run times and reached scores. The \u00b1 are standard deviations.", "labels": [], "entities": [{"text": "Average run times and reached scores", "start_pos": 10, "end_pos": 46, "type": "METRIC", "confidence": 0.7825425763924917}]}]}