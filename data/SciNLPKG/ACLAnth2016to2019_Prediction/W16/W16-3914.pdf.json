{"title": [{"text": "Analysis of Twitter Data for Postmarketing Surveillance in Pharmacovigilance", "labels": [], "entities": [{"text": "Postmarketing Surveillance", "start_pos": 29, "end_pos": 55, "type": "TASK", "confidence": 0.7308352291584015}]}], "abstractContent": [{"text": "Postmarketing surveillance (PMS) has the vital aim to monitor effects of drugs after release for use by the general population , but suffers from under-reporting and limited coverage.", "labels": [], "entities": [{"text": "Postmarketing surveillance (PMS)", "start_pos": 0, "end_pos": 32, "type": "TASK", "confidence": 0.8323475122451782}]}, {"text": "Automatic methods for detecting drug effect reports, especially for social media, could vastly increase the scope of PMS.", "labels": [], "entities": [{"text": "detecting drug effect reports", "start_pos": 22, "end_pos": 51, "type": "TASK", "confidence": 0.8528489768505096}, {"text": "PMS", "start_pos": 117, "end_pos": 120, "type": "TASK", "confidence": 0.9826216697692871}]}, {"text": "Very few automatic PMS methods are currently available , in particular for the messy text types encountered on Twitter.", "labels": [], "entities": [{"text": "PMS", "start_pos": 19, "end_pos": 22, "type": "TASK", "confidence": 0.9748945832252502}]}, {"text": "In this paper we describe first results for developing PMS methods specifically for tweets.", "labels": [], "entities": [{"text": "PMS", "start_pos": 55, "end_pos": 58, "type": "TASK", "confidence": 0.9896600246429443}]}, {"text": "We describe the corpus of 125,669 tweets we have created and annotated to train and test the tools.", "labels": [], "entities": []}, {"text": "We find that generic tools perform well for tweet-level language identification and tweet-level sentiment analysis (both 0.94 F1-Score).", "labels": [], "entities": [{"text": "tweet-level language identification", "start_pos": 44, "end_pos": 79, "type": "TASK", "confidence": 0.7191291948159536}, {"text": "tweet-level sentiment analysis", "start_pos": 84, "end_pos": 114, "type": "TASK", "confidence": 0.7507266203562418}, {"text": "F1-Score", "start_pos": 126, "end_pos": 134, "type": "METRIC", "confidence": 0.9960059523582458}]}, {"text": "For detection of effect mentions we are able to achieve 0.87 F1-Score, while effect-level adverse-vs.-beneficial analysis proves harder with an F1-Score of 0.64.", "labels": [], "entities": [{"text": "detection of effect mentions", "start_pos": 4, "end_pos": 32, "type": "TASK", "confidence": 0.8292929977178574}, {"text": "F1-Score", "start_pos": 61, "end_pos": 69, "type": "METRIC", "confidence": 0.998499870300293}, {"text": "F1-Score", "start_pos": 144, "end_pos": 152, "type": "METRIC", "confidence": 0.999139666557312}]}, {"text": "Among other things, our results indicate that MetaMap semantic types provide a very promising basis for identifying drug effect mentions in tweets.", "labels": [], "entities": [{"text": "identifying drug effect mentions in tweets", "start_pos": 104, "end_pos": 146, "type": "TASK", "confidence": 0.814679741859436}]}], "introductionContent": [{"text": "Postmarketing surveillance (PMS) is a vital part of pharmacovigilance, taking place during the final, post-licensing phase of drug development when the effects on larger numbers of users, who may have other conditions and take other medicines than those included in pre-approval tests, can be assessed.", "labels": [], "entities": [{"text": "Postmarketing surveillance (PMS)", "start_pos": 0, "end_pos": 32, "type": "TASK", "confidence": 0.8112019419670105}]}, {"text": "PMS is implemented in passive national reporting schemes such as the Yellow Card Scheme in the UK and MedWatch in the US; it is also implemented as active surveillance, e.g. organisations such as the MHRA in the UK and the FDA in the US conduct post-approval studies and postmarketing surveys.", "labels": [], "entities": [{"text": "PMS", "start_pos": 0, "end_pos": 3, "type": "TASK", "confidence": 0.8177074193954468}, {"text": "Yellow Card Scheme", "start_pos": 69, "end_pos": 87, "type": "DATASET", "confidence": 0.9174636006355286}, {"text": "MHRA", "start_pos": 200, "end_pos": 204, "type": "DATASET", "confidence": 0.8575329184532166}]}, {"text": "Existing PMS methods either rely on health practitioners and patients to report adverse effects to which only a small (self-selected) proportion of patients in particular will contribute (reporting schemes), or they involve single products and small numbers of participants (surveys).", "labels": [], "entities": [{"text": "PMS", "start_pos": 9, "end_pos": 12, "type": "TASK", "confidence": 0.9821228384971619}]}, {"text": "More generally, such methods are more likely to identify (i) very serious problems, and (ii) problems relating to newly released drugs and drugs already under continuous surveillance.", "labels": [], "entities": []}, {"text": "The ultimate goal of our work is to develop text analysis techniques to facilitate automatic, continuous and large-scale monitoring of adverse drug reactions (ADRs), and more generally of effects, beneficial or otherwise, reported forgiven drugs.", "labels": [], "entities": []}, {"text": "There is currently huge interest in such methods in the pharmaceutical industry, in particular where they can be used to monitor what is being said on social media about specific drugs.", "labels": [], "entities": []}, {"text": "Automatic PMS methods are also of interest to national regulatory bodies.", "labels": [], "entities": [{"text": "PMS", "start_pos": 10, "end_pos": 13, "type": "TASK", "confidence": 0.9639526605606079}]}, {"text": "The potential benefits of high-precision automatic ADR detection methods for social media are great: such methods would ameliorate the recognised problem of under-reporting of ADRs via existing channels (, and could inform the design of post-approval studies.", "labels": [], "entities": [{"text": "ADR detection", "start_pos": 51, "end_pos": 64, "type": "TASK", "confidence": 0.9529509544372559}]}, {"text": "Studies have already demonstrated that analysis of social media contents (manual analysis so far) can lead to the discovery of serious side effects, e.g. Abou retrospectively identified a severe side effect on the basis of user content posted months before the drug in question was withdrawn because of the same side effect.", "labels": [], "entities": []}, {"text": "The challenge is to automate this process so that suitably large portions of social media can be scanned.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Language identification results for Twit- ter tags and three language identification tools on  test set A of 300 manually annotated tweets (Re- call, Precision, F1-Score, for the English class).", "labels": [], "entities": [{"text": "Language identification", "start_pos": 10, "end_pos": 33, "type": "TASK", "confidence": 0.714934915304184}, {"text": "F1-Score", "start_pos": 171, "end_pos": 179, "type": "METRIC", "confidence": 0.9923586249351501}]}, {"text": " Table 2: Tweet-level sentiment analysis results for  3 best sentiment analysis tools on test set B of 300  manually annotated tweets (weighted-average F1- score over POS, NEG and NEU labels; Accuracy).", "labels": [], "entities": [{"text": "Tweet-level sentiment analysis", "start_pos": 10, "end_pos": 40, "type": "TASK", "confidence": 0.9148328502972921}, {"text": "sentiment analysis", "start_pos": 61, "end_pos": 79, "type": "TASK", "confidence": 0.7411733865737915}, {"text": "F1- score", "start_pos": 152, "end_pos": 161, "type": "METRIC", "confidence": 0.9544931451479594}, {"text": "Accuracy", "start_pos": 192, "end_pos": 200, "type": "METRIC", "confidence": 0.9991825222969055}]}, {"text": " Table 3: Results for detection of effect mentions (ME) on test set B of 300 manually annotated tweets  with 10-fold cross-validation (Recall, Precision, F1-scores for all classes, ME class, and not ME class).", "labels": [], "entities": [{"text": "effect mentions (ME)", "start_pos": 35, "end_pos": 55, "type": "METRIC", "confidence": 0.6164300382137299}, {"text": "Recall", "start_pos": 135, "end_pos": 141, "type": "METRIC", "confidence": 0.9464597105979919}, {"text": "Precision", "start_pos": 143, "end_pos": 152, "type": "METRIC", "confidence": 0.93780517578125}, {"text": "F1-scores", "start_pos": 154, "end_pos": 163, "type": "METRIC", "confidence": 0.9875316023826599}]}, {"text": " Table 4: Effect-level sentiment analysis results for  4 best sentiment analysis tools on test set B of 300  manually annotated tweets (weighted-average F1- score over ADV, BEN and NEU labels; Accuracy).", "labels": [], "entities": [{"text": "Effect-level sentiment analysis", "start_pos": 10, "end_pos": 41, "type": "TASK", "confidence": 0.6545238693555196}, {"text": "sentiment analysis", "start_pos": 62, "end_pos": 80, "type": "TASK", "confidence": 0.7766889333724976}, {"text": "F1- score", "start_pos": 153, "end_pos": 162, "type": "METRIC", "confidence": 0.9625841577847799}, {"text": "BEN", "start_pos": 173, "end_pos": 176, "type": "METRIC", "confidence": 0.9819336533546448}, {"text": "Accuracy", "start_pos": 193, "end_pos": 201, "type": "METRIC", "confidence": 0.9991781115531921}]}]}