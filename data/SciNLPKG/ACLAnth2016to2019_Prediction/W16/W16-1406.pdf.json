{"title": [], "abstractContent": [{"text": "We present a tool for dynamic reference graph visualization.", "labels": [], "entities": [{"text": "dynamic reference graph visualization", "start_pos": 22, "end_pos": 59, "type": "TASK", "confidence": 0.6567986160516739}]}, {"text": "A reference graph is a graph based on key phrases retrieved from a time-indexed natural language text corpus.", "labels": [], "entities": []}, {"text": "This tool maybe useful for the analysis of connected pairs of latent topics, changes in the significance of these topics as well as in the relationship between them over various time periods.", "labels": [], "entities": []}], "introductionContent": [{"text": "\"Text visualization\" is a rather ambiguous term.", "labels": [], "entities": []}, {"text": "One of the approaches to text visualization is scene generation, as described in ().", "labels": [], "entities": [{"text": "text visualization", "start_pos": 25, "end_pos": 43, "type": "TASK", "confidence": 0.8177498281002045}, {"text": "scene generation", "start_pos": 47, "end_pos": 63, "type": "TASK", "confidence": 0.7194545716047287}]}, {"text": "In our work, however, text visualization has a different meaning.", "labels": [], "entities": [{"text": "text visualization", "start_pos": 22, "end_pos": 40, "type": "TASK", "confidence": 0.856955885887146}]}, {"text": "Our interest lies in plotting meaningful elements from texts such as key phrases, named entities or terms.", "labels": [], "entities": []}, {"text": "Retrieved plots may serve as a tool for information extraction and summarization.", "labels": [], "entities": [{"text": "information extraction", "start_pos": 40, "end_pos": 62, "type": "TASK", "confidence": 0.8486805558204651}, {"text": "summarization", "start_pos": 67, "end_pos": 80, "type": "TASK", "confidence": 0.9819215536117554}]}, {"text": "As shown in, there are many techniques for textual data analysis and visualization, and their number is rapidly growing.", "labels": [], "entities": [{"text": "textual data analysis", "start_pos": 43, "end_pos": 64, "type": "TASK", "confidence": 0.6582996845245361}]}, {"text": "In fact, the problem of text visualizaton can be divided into two subproblems: visualization of static and temporal textual data.", "labels": [], "entities": []}, {"text": "The most known static text visualization technique is called \"tag clouds\".", "labels": [], "entities": []}, {"text": "Many visualization techniques extend the idea of a tag cloud.", "labels": [], "entities": []}, {"text": "For instance, in () key phrases are used to construct a concept lattice fora dataset of publications.", "labels": [], "entities": []}, {"text": "Lattice is visualized as an interactive tag cloud browser.", "labels": [], "entities": []}, {"text": "In, tags extracted from tweets are colored according to the political preferences of tweet authors.", "labels": [], "entities": []}, {"text": "Vennclouds, introduced in () present another extention of tags clouds, comparing two texts by showing three tag clouds: one cloud containing tags from the first text, another one with tags from second text, and the third cloud showing words and phrases that appear in both texts.", "labels": [], "entities": [{"text": "Vennclouds", "start_pos": 0, "end_pos": 10, "type": "DATASET", "confidence": 0.9060649275779724}]}, {"text": "Approaches based on tag cloud construction are also quite successful in the visualization of temporal textual data.", "labels": [], "entities": [{"text": "tag cloud construction", "start_pos": 20, "end_pos": 42, "type": "TASK", "confidence": 0.6606866121292114}]}, {"text": "For example, the ThemeRiver visualization tool, introduced in (), shows thematic variations overtime within a large collection of documents.", "labels": [], "entities": []}, {"text": "In (, tag clouds are placed inside graph nodes.", "labels": [], "entities": []}, {"text": "The nodes are connected by an edge if they have a lot in common, and are placed on the time axis as well.", "labels": [], "entities": []}, {"text": "Tag graphs are another extension of tag clouds.", "labels": [], "entities": []}, {"text": "To construct a tag graph, one needs to introduce some sort of relation between tags.", "labels": [], "entities": []}, {"text": "For example, in), the tags stand for named entities and one draws edges between tags that co-occur.) present a dynamic visualization technique for these temporal co-occurence graphs.", "labels": [], "entities": []}, {"text": "In this paper, we suggest an approach to temporal textual data analysis which is based on dynamical reference graphs.", "labels": [], "entities": [{"text": "temporal textual data analysis", "start_pos": 41, "end_pos": 71, "type": "TASK", "confidence": 0.6210023388266563}]}, {"text": "The main difference of these reference graphs from co-occurence graphs is that they are oriented.", "labels": [], "entities": []}, {"text": "This allows to analyze how one term \"refers\" to another, as well as to retrieve more patterns describing the relations between terms.", "labels": [], "entities": []}, {"text": "Our visualization also allows to analyze how the significance of certain terms changes overtime.", "labels": [], "entities": []}], "datasetContent": [{"text": "Our test collection corresponds to the topic of newspaper analysis.", "labels": [], "entities": [{"text": "newspaper analysis", "start_pos": 48, "end_pos": 66, "type": "TASK", "confidence": 0.7615921795368195}]}, {"text": "We have collected a set of articles on economics from four Russian newsportals (\"Izvestia\", \"Kommersant\", \"Moscow Komsomoltes\", \"Nezavisimaya gazeta\") that were published in 2014.", "labels": [], "entities": []}, {"text": "This corpus (called \"RuNeWC\" -Russian Newspaper Web Corpus ) contains 4061 Russian language articles, divided into 26 time periods.", "labels": [], "entities": [{"text": "RuNeWC\" -Russian Newspaper Web Corpus", "start_pos": 21, "end_pos": 58, "type": "DATASET", "confidence": 0.6904529418264117}]}, {"text": "Every period has a length of 2 weeks.", "labels": [], "entities": []}, {"text": "Concepts were extracted automatically using the strategy proposed in, which consists of 2 steps.", "labels": [], "entities": []}, {"text": "The first step was to extract candidate words and phrases that satisfy certain speech patterns, adopted from (Mitrofanova and Zaharov, 2009) (ex.: ADJECTIVE+NOUN, NOUN+NOUN, etc.).", "labels": [], "entities": []}, {"text": "The next step was to form the list of concepts, which resulted in 250 most frequent phrases and 100 most frequent words.", "labels": [], "entities": []}, {"text": "Finally, we manually removed some concepts that are not semantically important (ex.: \"Kommersant reporter\" [\"Korrespondent ).", "labels": [], "entities": []}, {"text": "For graph visualization, we set the confidence threshold at 28 and support threshold at 0.9.", "labels": [], "entities": [{"text": "confidence threshold", "start_pos": 36, "end_pos": 56, "type": "METRIC", "confidence": 0.9677445888519287}, {"text": "support threshold", "start_pos": 67, "end_pos": 84, "type": "METRIC", "confidence": 0.9780614078044891}]}, {"text": "An example of dynamic graph visualisation for RuNeWC is presented in.", "labels": [], "entities": []}, {"text": "In order to provide an even more clear example, we created an English language corpus based on four books from a series of popular epic fantasy novels \"A Song of Ice and Fire\" (ASOIAF) written by George R.", "labels": [], "entities": [{"text": "A Song of Ice and Fire\" (ASOIAF)", "start_pos": 152, "end_pos": 184, "type": "TASK", "confidence": 0.48822161257267}]}, {"text": "If we take the list of characters of that novel as an initial set of concepts the reference graph then shows the co-occurence of characters in the book pages, typical clusters of characters, the significance of characters, as well as the change of these parameters over the time.", "labels": [], "entities": []}, {"text": "The plot in the first four books develops linearly: every next chapter describes actions that occurred after the actions of a previous one.", "labels": [], "entities": []}, {"text": "To construct our corpus, we divided each chapter into several equal parts (2-7 parts, depending on the size of that chapter).", "labels": [], "entities": []}, {"text": "Each part was then taken to the corpus as a single document.", "labels": [], "entities": []}, {"text": "Then, the set of all documents was divided into groups of 50 sequential documents, forming 14 time periods.", "labels": [], "entities": []}, {"text": "We didn't take one chapter as a single time period, as the story of each chapter goes on behalf of one specific character, and he automatically becomes the most important one.", "labels": [], "entities": []}, {"text": "In constrast, the division of each chapter into several documents increased the precision of our support and confidence estimations for the concepts from the book.", "labels": [], "entities": [{"text": "precision", "start_pos": 80, "end_pos": 89, "type": "METRIC", "confidence": 0.9995575547218323}]}, {"text": "In our experiment, we set the term frequency threshold \u03c3 = 1, i.e. considered a concept to be mentioned in a document if it appeared in that document two or more times.", "labels": [], "entities": [{"text": "term frequency threshold \u03c3", "start_pos": 30, "end_pos": 56, "type": "METRIC", "confidence": 0.8463263511657715}]}, {"text": "The threshold for the support value was set at the level of 5, and minimum confidence value to 0.3.", "labels": [], "entities": [{"text": "minimum confidence value", "start_pos": 67, "end_pos": 91, "type": "METRIC", "confidence": 0.9214291175206503}]}, {"text": "As a result, we obtained a dynamic reference graph visualization that may serve as a schematic retelling of \"Song of Ice and Fire\" novel.", "labels": [], "entities": []}, {"text": "Examples of dynamic graph visualisation for ASOIAF corpus are presented in figs. 2 to 4 1 .", "labels": [], "entities": [{"text": "ASOIAF corpus", "start_pos": 44, "end_pos": 57, "type": "DATASET", "confidence": 0.7743539214134216}]}], "tableCaptions": []}