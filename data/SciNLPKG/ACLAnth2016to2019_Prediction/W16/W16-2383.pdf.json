{"title": [{"text": "UAlacant word-level and phrase-level machine translation quality estimation systems at WMT 2016", "labels": [], "entities": [{"text": "UAlacant", "start_pos": 0, "end_pos": 8, "type": "DATASET", "confidence": 0.8890925645828247}, {"text": "phrase-level machine translation quality estimation", "start_pos": 24, "end_pos": 75, "type": "TASK", "confidence": 0.6447392463684082}, {"text": "WMT", "start_pos": 87, "end_pos": 90, "type": "DATASET", "confidence": 0.8768661022186279}]}], "abstractContent": [{"text": "This paper describes the Universitat d'Alacant submissions (labeled as UAla-cant) to the machine translation quality estimation (MTQE) shared task at WMT 2016, where we have participated in the word-level and phrase-level MTQE sub-tasks.", "labels": [], "entities": [{"text": "machine translation quality estimation (MTQE) shared task at WMT 2016", "start_pos": 89, "end_pos": 158, "type": "TASK", "confidence": 0.80160919825236}]}, {"text": "Our systems use external sources of bilingual information as a black box to spot sub-segment correspondences between the source segment and the translation hypothesis.", "labels": [], "entities": []}, {"text": "For our submissions, two sources of bilingual information have been used: machine translation (Lucy LT KWIK Translator and Google Translate) and the bilingual concordancer Reverso Context.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 74, "end_pos": 93, "type": "TASK", "confidence": 0.6949851661920547}, {"text": "Lucy LT KWIK Translator", "start_pos": 95, "end_pos": 118, "type": "DATASET", "confidence": 0.8814514726400375}]}, {"text": "Building upon the word-level approach implemented for WMT 2015, a method for phrase-based MTQE is proposed which builds on the probabilities obtained for word-level MTQE.", "labels": [], "entities": [{"text": "WMT 2015", "start_pos": 54, "end_pos": 62, "type": "TASK", "confidence": 0.5262738764286041}, {"text": "MTQE", "start_pos": 90, "end_pos": 94, "type": "TASK", "confidence": 0.8171952962875366}]}, {"text": "For each sub-task we have submitted two systems: one using the features produced exclusively based on on-line sources of bilingual information, and one combining them with the baseline features provided by the organisers of the task.", "labels": [], "entities": []}], "introductionContent": [{"text": "Machine translation quality estimation (MTQE) () has aroused the interest of both the scientific community and translation companies on account of its noticeable advantages: it can be used to help professional translators in post-editing, to estimate the translation productivity for different translation technologies, or even for budgeting translation projects.", "labels": [], "entities": [{"text": "Machine translation quality estimation (MTQE)", "start_pos": 0, "end_pos": 45, "type": "TASK", "confidence": 0.8030014208384922}]}, {"text": "In this context, the WMT 2016 MTQE shared task becomes one of the best scenarios in which different approaches to MTQE can be evaluated and compared for different granularities: segment-level (sub-task 1), phrase-level and word-level (sub-task 2), and document-level (sub-task 3).", "labels": [], "entities": [{"text": "WMT 2016 MTQE shared task", "start_pos": 21, "end_pos": 46, "type": "DATASET", "confidence": 0.7459898114204406}]}, {"text": "For the second consecutive year, the submissions of the UAlacant team tackle the word-level MTQE sub-task, but this year they also cover phrase-level MTQE.", "labels": [], "entities": [{"text": "UAlacant team", "start_pos": 56, "end_pos": 69, "type": "DATASET", "confidence": 0.869134783744812}]}, {"text": "This year, the shared task featured a dataset obtained by translating segments in English into German using MT, for which it is needed to identify which words and phrases are inadequately translated.", "labels": [], "entities": []}, {"text": "In the case of words, this means detecting which words need to be deleted or replaced, while in the case of phrases this means detecting which phrases contain words translated inadequately, but also if there are missing words, or the order of the words in the phrase is not correct.", "labels": [], "entities": []}, {"text": "The systems participating in the task are required to apply the labels BAD and OK, either to words or phrases.", "labels": [], "entities": [{"text": "BAD", "start_pos": 71, "end_pos": 74, "type": "METRIC", "confidence": 0.974492073059082}]}, {"text": "In this paper we describe the approach behind the submissions of the Universitat d'Alacant team to these sub-tasks.", "labels": [], "entities": []}, {"text": "For our word-level submissions we have applied the approach proposed byEsp\u00ec a-, where we used black-box bilingual on-line resources.", "labels": [], "entities": []}, {"text": "The new task tackles MTQE for translating English into German.", "labels": [], "entities": [{"text": "MTQE", "start_pos": 21, "end_pos": 25, "type": "TASK", "confidence": 0.3919354975223541}, {"text": "translating English into German", "start_pos": 30, "end_pos": 61, "type": "TASK", "confidence": 0.8748893737792969}]}, {"text": "For this task we have combined two on-line-available MT systems, 1 Lucy LT KWIK Translator 2 and Google Translate, and the bilingual concordancer Reverso In the original approach byEsp\u00ec a- Apertium was one of these MT systems, but this year it was replaced since it does not provide a translation system for the languages of the current year's task.", "labels": [], "entities": [{"text": "MT", "start_pos": 53, "end_pos": 55, "type": "TASK", "confidence": 0.9479502439498901}]}, {"text": "2 http://www.lucysoftware.com/english/ machine-translation/kwik-translator 3 http://translate.google.com", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Precision (P ), recall (R), and F1 score obtained for the four systems submitted to the shared task on MTQE at WMT  2016. Two of them are based exclusively on the use of sources of bilingual information (SBI, see Section 2), and two more  combine these SBI with the baseline features provided by the organisers of the task (SBI+baseline). The table also includes the  results obtained when training the same binary classifier exclusively on the baseline features (baseline).", "labels": [], "entities": [{"text": "Precision (P )", "start_pos": 10, "end_pos": 24, "type": "METRIC", "confidence": 0.9462541341781616}, {"text": "recall (R)", "start_pos": 26, "end_pos": 36, "type": "METRIC", "confidence": 0.9507195353507996}, {"text": "F1 score", "start_pos": 42, "end_pos": 50, "type": "METRIC", "confidence": 0.9865868091583252}, {"text": "MTQE at WMT  2016", "start_pos": 113, "end_pos": 130, "type": "DATASET", "confidence": 0.8944540023803711}]}]}