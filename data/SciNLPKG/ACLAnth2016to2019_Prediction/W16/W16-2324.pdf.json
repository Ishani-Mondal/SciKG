{"title": [], "abstractContent": [{"text": "This paper presents the University of Cam-bridge submission to WMT16.", "labels": [], "entities": [{"text": "University of Cam-bridge submission to WMT16", "start_pos": 24, "end_pos": 68, "type": "DATASET", "confidence": 0.9010930260022482}]}, {"text": "Motivated by the complementary nature of syntac-tical machine translation and neural machine translation (NMT), we exploit the synergies of Hiero and NMT in different combination schemes.", "labels": [], "entities": [{"text": "syntac-tical machine translation", "start_pos": 41, "end_pos": 73, "type": "TASK", "confidence": 0.634897897640864}, {"text": "Hiero", "start_pos": 140, "end_pos": 145, "type": "DATASET", "confidence": 0.8192908763885498}]}, {"text": "Starting outwith a simple neural lattice rescoring approach, we show that the Hiero lattices are often too narrow for NMT ensembles.", "labels": [], "entities": []}, {"text": "Therefore , instead of a hard restriction of the NMT search space to the lattice, we propose to loosely couple NMT and Hiero by composition with a modified version of the edit distance transducer.", "labels": [], "entities": [{"text": "Hiero", "start_pos": 119, "end_pos": 124, "type": "DATASET", "confidence": 0.8358300924301147}]}, {"text": "The loose combination outperforms lattice rescoring, especially when using multiple NMT systems in an ensemble.", "labels": [], "entities": []}], "introductionContent": [{"text": "Previous work suggests that syntactic machine translation such as Hiero and Neural Machine Translation (NMT) are very different and have complementary strengths and weaknesses.", "labels": [], "entities": [{"text": "syntactic machine translation", "start_pos": 28, "end_pos": 57, "type": "TASK", "confidence": 0.7302189668019613}, {"text": "Neural Machine Translation (NMT)", "start_pos": 76, "end_pos": 108, "type": "TASK", "confidence": 0.8053921858469645}]}, {"text": "Recent attempts to combine syntactic SMT and NMT report large gains over both baselines.", "labels": [], "entities": [{"text": "syntactic SMT", "start_pos": 27, "end_pos": 40, "type": "TASK", "confidence": 0.5504253506660461}]}, {"text": "Authors in () used NMT to rescore n-best lists which were generated with a syntax-based system.", "labels": [], "entities": []}, {"text": "They report that even with 1000-best lists, the gains of using the NMT rescorer often do not saturate.", "labels": [], "entities": [{"text": "NMT rescorer", "start_pos": 67, "end_pos": 79, "type": "DATASET", "confidence": 0.5948245674371719}]}, {"text": "Syntactically Guided NMT ( constrains the NMT search space to Hiero translation lattices which contain significantly more hypotheses than n-best lists.", "labels": [], "entities": []}, {"text": "In SGNMT, an NMT beam decoder with a relatively small beam can explore spaces much larger than n-best lists, yielding BLEU score improvements with far fewer expensive NMT evaluations.", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 118, "end_pos": 128, "type": "METRIC", "confidence": 0.9713910818099976}]}, {"text": "However, these rescoring approaches enforce an exact match between the NMT and syntactic decoders.", "labels": [], "entities": []}, {"text": "In general, this kind of hard restriction is best avoided when combining diverse systems (.", "labels": [], "entities": []}, {"text": "For example, in speech recognition, ROVER (Fiscus, 1997) is a system combination approach based on a soft voting scheme.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 16, "end_pos": 34, "type": "TASK", "confidence": 0.7743917107582092}, {"text": "ROVER", "start_pos": 36, "end_pos": 41, "type": "METRIC", "confidence": 0.9770918488502502}]}, {"text": "In machine translation, minimum Bayes-risk (MBR) decoding ( can be used to combine multiple systems (de.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 3, "end_pos": 22, "type": "TASK", "confidence": 0.7709197700023651}]}, {"text": "MBR also does not enforce exact agreement between systems as it distinguishes between the hypothesis space and the evidence space.", "labels": [], "entities": [{"text": "MBR", "start_pos": 0, "end_pos": 3, "type": "TASK", "confidence": 0.635425865650177}]}, {"text": "We find that Hiero lattices generated by grammars extracted with the usual heuristics do not provide enough variety to explore the full potential of neural models, especially when using NMT ensembles.", "labels": [], "entities": []}, {"text": "Therefore, we present a \"soft\" lattice-based combination scheme which uses standard operations on finite state transducers such as composition.", "labels": [], "entities": []}, {"text": "Our method replaces the hard combination in previous methods with a similarity measure based on the edit distance, and gives the NMT decoder more freedom to diverge from the Hiero translations.", "labels": [], "entities": [{"text": "NMT decoder", "start_pos": 129, "end_pos": 140, "type": "DATASET", "confidence": 0.8626908659934998}]}, {"text": "We find that this loose coupling scheme is especially useful when using NMT ensembles.", "labels": [], "entities": []}], "datasetContent": [{"text": "The parallel training data includes Europarl v7, Common Crawl, and News Commentary v10.", "labels": [], "entities": [{"text": "Europarl", "start_pos": 36, "end_pos": 44, "type": "DATASET", "confidence": 0.9811036586761475}, {"text": "Common Crawl", "start_pos": 49, "end_pos": 61, "type": "DATASET", "confidence": 0.8974096775054932}]}, {"text": "Sentence pairs with sentences longer than 80 words or length ratios exceeding 2.4:1 were deleted, as were Common Crawl sentences from other languages.", "labels": [], "entities": []}, {"text": "We use news-test2014 (the filtered version) as a development set, and keep news-test2015 and news-test2016 as test sets.", "labels": [], "entities": []}, {"text": "The NMT systems are built using the Blocks framework based on the Theano library () with the network architecture and hyper-parameters as in (: the encoder and decoder networks consist of 1000 gated recurrent units ().", "labels": [], "entities": [{"text": "Theano library", "start_pos": 66, "end_pos": 80, "type": "DATASET", "confidence": 0.9734542369842529}]}, {"text": "The decoder uses a single maxout () output layer with the feed-forward attention model described in ().", "labels": [], "entities": []}, {"text": "In our final ensemble, we use 8 independently trained NMT systems with vocabulary sizes between 30,000 and 60,000.", "labels": [], "entities": []}, {"text": "Rules for our En-De Hiero system were extracted as described in.", "labels": [], "entities": [{"text": "En-De Hiero system", "start_pos": 14, "end_pos": 32, "type": "DATASET", "confidence": 0.8633870681126913}]}, {"text": "A 5-gram language model for the Hiero system was trained on WMT16 parallel and monolingual data (.", "labels": [], "entities": [{"text": "Hiero system", "start_pos": 32, "end_pos": 44, "type": "DATASET", "confidence": 0.8882292211055756}]}, {"text": "We apply gentle post-processing to the German output for fixing small number and currency formatting issues.", "labels": [], "entities": [{"text": "fixing small number and currency formatting", "start_pos": 57, "end_pos": 100, "type": "TASK", "confidence": 0.7435911893844604}]}, {"text": "The English source sentences in the training corpus are lower-cased.", "labels": [], "entities": []}, {"text": "During decoding, we lowercase only in-vocabulary words, and pass through OOVs with correct casing.", "labels": [], "entities": []}, {"text": "We apply a simple heuristic for recognizing surnames to avoid literal translation of them into German 3 . Setup news-test2014 news-test2015 news-test2016 Best in competition 20", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: English-German lower-cased BLEU scores calculated with Moses mteval-v13a.pl.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 37, "end_pos": 41, "type": "METRIC", "confidence": 0.9832321405410767}]}, {"text": " Table 2: Projection methods on news-test2016  with NMT 8-ensemble.", "labels": [], "entities": [{"text": "NMT 8-ensemble", "start_pos": 52, "end_pos": 66, "type": "DATASET", "confidence": 0.7950522303581238}]}, {"text": " Table 3: Breakdown of the distances measured between NMT and Hiero along the shortest path in C on  news-test2016.", "labels": [], "entities": [{"text": "Breakdown", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9592365622520447}, {"text": "NMT", "start_pos": 54, "end_pos": 57, "type": "DATASET", "confidence": 0.8798936009407043}, {"text": "Hiero", "start_pos": 62, "end_pos": 67, "type": "DATASET", "confidence": 0.8041452169418335}, {"text": "news-test2016", "start_pos": 101, "end_pos": 114, "type": "DATASET", "confidence": 0.9686698317527771}]}, {"text": " Table 4: BLEU scores on news-test2016 for dif- ferent vocabulary sizes (single NMT). Each indi- vidual NMT system is combined with Hiero as de- scribed in Sec. 2.3.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9984198808670044}]}]}