{"title": [], "abstractContent": [{"text": "This paper describes the AMU-UEDIN submissions to the WMT 2016 shared task on news translation.", "labels": [], "entities": [{"text": "WMT 2016 shared task on news translation", "start_pos": 54, "end_pos": 94, "type": "TASK", "confidence": 0.7043362515313285}]}, {"text": "We explore methods of decode-time integration of attention-based neural translation models with phrase-based statistical machine translation.", "labels": [], "entities": [{"text": "attention-based neural translation", "start_pos": 49, "end_pos": 83, "type": "TASK", "confidence": 0.6713907817999522}, {"text": "phrase-based statistical machine translation", "start_pos": 96, "end_pos": 140, "type": "TASK", "confidence": 0.6152468919754028}]}, {"text": "Efficient batch-algorithms for GPU-querying are proposed and implemented.", "labels": [], "entities": []}, {"text": "For English-Russian, our system stays behind the state-of-the-art pure neu-ral models in terms of BLEU.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 98, "end_pos": 102, "type": "METRIC", "confidence": 0.9952566027641296}]}, {"text": "Among restricted systems, manual evaluation places it in the first cluster tied with the pure neu-ral model.", "labels": [], "entities": []}, {"text": "For the Russian-English task, our submission achieves the top BLEU result , outperforming the best pure neural system by 1.1 BLEU points and our own phrase-based baseline by 1.6 BLEU.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 62, "end_pos": 66, "type": "METRIC", "confidence": 0.9992009997367859}, {"text": "BLEU", "start_pos": 125, "end_pos": 129, "type": "METRIC", "confidence": 0.995140790939331}, {"text": "BLEU", "start_pos": 178, "end_pos": 182, "type": "METRIC", "confidence": 0.9931532144546509}]}, {"text": "After manual evaluation, this system is the best restricted system in its own cluster.", "labels": [], "entities": []}, {"text": "In follow-up experiments we improve results by additional 0.8 BLEU.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 62, "end_pos": 66, "type": "METRIC", "confidence": 0.9987722039222717}]}], "introductionContent": [{"text": "This paper describes the AMU-UEDIN submissions to the WMT 2016 shared task on news translation.", "labels": [], "entities": [{"text": "WMT 2016 shared task on news translation", "start_pos": 54, "end_pos": 94, "type": "TASK", "confidence": 0.7043362515313285}]}, {"text": "We explore methods of decode-time integration of attention-based neural translation models with phrase-based decoding.", "labels": [], "entities": [{"text": "attention-based neural translation", "start_pos": 49, "end_pos": 83, "type": "TASK", "confidence": 0.6723450024922689}]}, {"text": "Experiments have been conducted for the English-Russian language pair in both translation directions.", "labels": [], "entities": []}, {"text": "For these experiments we re-implemented the inference step of the models described in (more exactly the DL4MT 1 variant also present in Nematus 2 ) in efficient https://github.com/nyu-dl/ dl4mt-tutorial 2 https://github.com/rsennrich/nematus C++/CUDA code that can be directly compiled as a Moses feature function.", "labels": [], "entities": []}, {"text": "The GPU-based computations come with their own peculiarities which we reconcile with the two most popular phrasebased decoding algorithms -stack-decoding and cube-pruning.", "labels": [], "entities": []}, {"text": "While it seems at first that for English-Russian our phrase-based system is holding back the neural models in terms of BLEU, the manual evaluation reveals that our systems is tied with the pure neural systems, occupying the same top cluster for restricted systems with an even slightly higher TrueSkill score.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 119, "end_pos": 123, "type": "METRIC", "confidence": 0.9987645149230957}]}, {"text": "We achieve the top BLEU result for the Russian-English task, outperforming the best pure neural system by 1.1 BLEU points and our own phrase-based baseline by 1.6 BLEU.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 19, "end_pos": 23, "type": "METRIC", "confidence": 0.9991242289543152}, {"text": "BLEU", "start_pos": 110, "end_pos": 114, "type": "METRIC", "confidence": 0.9960594177246094}, {"text": "BLEU", "start_pos": 163, "end_pos": 167, "type": "METRIC", "confidence": 0.9927558302879333}]}, {"text": "After manual evaluation, this system is the best restricted system in its own cluster.", "labels": [], "entities": []}, {"text": "Our implementation is available as a Moses fork from https://github.com/emjotde/ mosesdecoder_nmt", "labels": [], "entities": []}], "datasetContent": [{"text": "For decoding, we use the cube-pruning algorithm with stack size of 1,000 and cube-pruning pop limit of 2,000 during tuning.", "labels": [], "entities": []}, {"text": "At test time, a stacksize of 1,000 is kept, but the cube-pruning pop limit is increased to 5,000.", "labels": [], "entities": [{"text": "stacksize", "start_pos": 16, "end_pos": 25, "type": "METRIC", "confidence": 0.9097548127174377}]}, {"text": "We set a distortion limit of 12.", "labels": [], "entities": [{"text": "distortion limit", "start_pos": 9, "end_pos": 25, "type": "METRIC", "confidence": 0.9832994341850281}]}, {"text": "We run 10 iterations of Batch-Mira (Cherry and Foster, 2012) and choose the best set of weights based on the development set.", "labels": [], "entities": [{"text": "Batch-Mira (Cherry and Foster, 2012)", "start_pos": 24, "end_pos": 60, "type": "DATASET", "confidence": 0.8433660417795181}]}, {"text": "Our development set is a subset of 2,000 sentences from the newstest-2014 test set.", "labels": [], "entities": [{"text": "newstest-2014 test set", "start_pos": 60, "end_pos": 82, "type": "DATASET", "confidence": 0.9584067265192667}]}, {"text": "Sentences have been selected to be shorter than 40 words to avoid GPUmemory problems.", "labels": [], "entities": []}, {"text": "Our GPUs are three Nvidia GeForce GTX-970 cards with 4GB RAM each.", "labels": [], "entities": [{"text": "Nvidia GeForce GTX-970", "start_pos": 19, "end_pos": 41, "type": "DATASET", "confidence": 0.8084180553754171}]}, {"text": "We rely on the hypothesis recombination controlled by the states of the other feature functions.", "labels": [], "entities": []}, {"text": "It is worth mentioning again that our phrase-based baseline features a 9-gram wordclass language model which should be rather prohibitive of recombinations.", "labels": [], "entities": []}, {"text": "If recombination was only allowed for hypotheses with the same partial translations, results were considerably worse.", "labels": [], "entities": []}, {"text": "Frustrated by the limited memory of our GPU cards and against better knowledge 6 , we computed The neural network lore seems to suggest that this should notwork, as neural networks are non-linear models.", "labels": [], "entities": []}, {"text": "We only found one paper with evidence to the contrary: the element-wise average of all model weights in the NMT ensembles and saved the resulting model.", "labels": [], "entities": []}, {"text": "Interestingly, the performance of these new models (NMT-4-Avg) is not much worse than the actual ensemble (NMT-4), while being four times smaller and four times faster at decodetime.", "labels": [], "entities": []}, {"text": "The average models outperforms any single model or the smaller 2-ensembles.", "labels": [], "entities": []}, {"text": "All models taking part in the average are parameter dumps saved at different points in time during the same training run.", "labels": [], "entities": []}, {"text": "This seem to bean interesting results for model compression and deployment settings.", "labels": [], "entities": [{"text": "model compression", "start_pos": 42, "end_pos": 59, "type": "TASK", "confidence": 0.7940213084220886}, {"text": "deployment", "start_pos": 64, "end_pos": 74, "type": "TASK", "confidence": 0.9545692205429077}]}, {"text": "We can also average more models: for the Russian-English direction we experiment with the parameter-wise average often models (NMT-10-Avg) which even slightly outperforms the real four-model ensemble With this smaller model it is easier to tune and deploy our feature function.", "labels": [], "entities": []}, {"text": "The performance of our combined setup improves for both translation directions.", "labels": [], "entities": []}, {"text": "For English-Russian, however, the pure NMT system (NMT-4) remains ahead of our WMT 2016 submission.", "labels": [], "entities": [{"text": "WMT 2016 submission", "start_pos": 79, "end_pos": 98, "type": "DATASET", "confidence": 0.7592914899190267}]}, {"text": "For Russian-English we get another improvement of 0.8 BLEU, which sets the new state-of-the-art for this direction.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 54, "end_pos": 58, "type": "METRIC", "confidence": 0.9986395239830017}]}], "tableCaptions": [{"text": " Table 1: Systems marked with subm. are our final WMT 2016 submissions.", "labels": [], "entities": [{"text": "WMT 2016 submissions", "start_pos": 50, "end_pos": 70, "type": "DATASET", "confidence": 0.6920127073923746}]}, {"text": " Table 2: Translation speed for different configura- tions in words per second.", "labels": [], "entities": [{"text": "Translation", "start_pos": 10, "end_pos": 21, "type": "TASK", "confidence": 0.937085747718811}]}]}