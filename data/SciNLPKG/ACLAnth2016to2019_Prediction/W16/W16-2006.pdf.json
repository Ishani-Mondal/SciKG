{"title": [{"text": "Morphological Reinflection with Conditional Random Fields and Unsupervised Features", "labels": [], "entities": [{"text": "Morphological Reinflection", "start_pos": 0, "end_pos": 26, "type": "TASK", "confidence": 0.744609147310257}]}], "abstractContent": [{"text": "This paper describes our participation in the SIGMORPHON 2016 shared task on morphological reinflection.", "labels": [], "entities": [{"text": "SIGMORPHON 2016 shared task on morphological reinflection", "start_pos": 46, "end_pos": 103, "type": "TASK", "confidence": 0.7006713109357017}]}, {"text": "In the task, we use a linear-chain conditional random field model to learn to map sequences of input characters to sequences of output characters and focus on developing features that are useful for predicting inflectional behavior.", "labels": [], "entities": []}, {"text": "Since the training data in the task is limited, we also generalize the training data by extracting, in an unsupervised fashion, the types of consonant-vowel sequences that trigger inflectional behavior, and by extending the available training data through inference of unlabeled morphosyntactic descriptions .", "labels": [], "entities": []}], "introductionContent": [{"text": "Our approach to the shared task focuses on expanding well-known methods to learning inflections.", "labels": [], "entities": []}, {"text": "As our starting point, we assume a discriminative model akin to,, and the baseline system provided by the organizers of the shared task, all very similar systems at the core.", "labels": [], "entities": []}, {"text": "To improve performance and to address the more difficult reinflection tasks introduced in the shared task, we explore methods of expanding the training data, performing better alignment on the training data for our discriminative sequence classifier, feature development, and using unsupervised features for better generalization from training data.", "labels": [], "entities": [{"text": "feature development", "start_pos": 251, "end_pos": 270, "type": "TASK", "confidence": 0.6927996277809143}]}, {"text": "In what follows, we describe a baseline system we developed, the system we actually participated with, and present the results, together with some analysis.", "labels": [], "entities": []}], "datasetContent": [{"text": "To assess the difficulty of the task and the variation of inflectional behavior in the data sets, we ran a preliminary test with the data using a simple, suffix-based inflection strategy to complement the SIGMORPHON baseline.", "labels": [], "entities": [{"text": "SIGMORPHON baseline", "start_pos": 205, "end_pos": 224, "type": "DATASET", "confidence": 0.729554608464241}]}, {"text": "The method simply learns to transform input word form suffixes to suffixes of inflected forms.", "labels": [], "entities": []}, {"text": "It works as follows: from each Levenshtein-aligned example pair x \u2192 y belonging to some morphosyntactic description (MSD) m source \u2192 m target , we extract all the possible suffix-based string-to-string mapping rules that describe this mapping.", "labels": [], "entities": []}, {"text": "In task 1, where the source MSD is not known, we assume that the source mapping is the lemma form.", "labels": [], "entities": []}, {"text": "The rationale for this baseline is that many: Results of a simple suffix-based baseline on task 1.", "labels": [], "entities": []}, {"text": "Results are on the dev-set, and results in parentheses describe performance on the dev-set duplicates from the training-set removed.", "labels": [], "entities": []}, {"text": "hand-written models of morphology for various languages focus on suffixes to predict morphological behavior (.", "labels": [], "entities": []}, {"text": "As is seen in table 1, this yields comparably strong results for those languages that have largely suffixing inflections in the shared task (Finnish, Georgian, German, Hungarian, Spanish).", "labels": [], "entities": []}, {"text": "It also identifies the difficult languages of the task for both--Arabic, Maltese, and Navajo.", "labels": [], "entities": []}, {"text": "These are languages that exhibit significant stem-internal alternations and prefixation processes that thus lie outside the scope of this simple method.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 3: Our approach on the Durrett and DeN- ero (2013) dataset, comparing our model with that  work (D&DN13) and the simple suffix-replacing  model introduced earlier.", "labels": [], "entities": [{"text": "Durrett and DeN- ero (2013) dataset", "start_pos": 30, "end_pos": 65, "type": "DATASET", "confidence": 0.8026788930098215}, {"text": "D&DN13)", "start_pos": 104, "end_pos": 111, "type": "DATASET", "confidence": 0.8749775290489197}]}]}