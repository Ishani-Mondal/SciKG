{"title": [{"text": "An Efficient and Effective Online Sentence Segmenter for Simultaneous Interpretation", "labels": [], "entities": [{"text": "Online Sentence Segmenter", "start_pos": 27, "end_pos": 52, "type": "TASK", "confidence": 0.6717502474784851}, {"text": "Simultaneous Interpretation", "start_pos": 57, "end_pos": 84, "type": "TASK", "confidence": 0.8908869922161102}]}], "abstractContent": [{"text": "Simultaneous interpretation is a very challenging application of machine translation in which the input is a stream of words from a speech recognition engine.", "labels": [], "entities": [{"text": "Simultaneous interpretation", "start_pos": 0, "end_pos": 27, "type": "TASK", "confidence": 0.8672774434089661}, {"text": "machine translation", "start_pos": 65, "end_pos": 84, "type": "TASK", "confidence": 0.7300019860267639}]}, {"text": "The key problem is how to segment the stream in an online manner into units suitable for translation.", "labels": [], "entities": []}, {"text": "The segmentation process proceeds by calculating a confidence score for each word that indicates the soundness of placing a sentence boundary after it, and then heuristics are employed to determine the position of the boundaries.", "labels": [], "entities": []}, {"text": "Multiple variants of the confidence scoring method and segmentation heuristics were studied.", "labels": [], "entities": [{"text": "segmentation heuristics", "start_pos": 55, "end_pos": 78, "type": "TASK", "confidence": 0.8932405412197113}]}, {"text": "Experimental results show that the best performing strategy is not only efficient in terms of average latency per word, but also achieved end-to-end translation quality close to an offline baseline, and close to oracle segmentation.", "labels": [], "entities": [{"text": "oracle segmentation", "start_pos": 212, "end_pos": 231, "type": "TASK", "confidence": 0.7456879317760468}]}], "introductionContent": [{"text": "Simultaneous interpretation performs spoken language translation in a online manner.", "labels": [], "entities": []}, {"text": "A spoken language translation system automatically translates text from an automatic speech recognition (ASR) system into another language.", "labels": [], "entities": [{"text": "spoken language translation", "start_pos": 2, "end_pos": 29, "type": "TASK", "confidence": 0.8278645674387614}, {"text": "automatic speech recognition (ASR)", "start_pos": 75, "end_pos": 109, "type": "TASK", "confidence": 0.8057458599408468}]}, {"text": "Spoken language translation itself is an important application of machine translation (MT) because it takes one of the most natural forms of human communication -speech -as input).", "labels": [], "entities": [{"text": "Spoken language translation", "start_pos": 0, "end_pos": 27, "type": "TASK", "confidence": 0.8386643926302592}, {"text": "machine translation (MT)", "start_pos": 66, "end_pos": 90, "type": "TASK", "confidence": 0.8442552804946899}]}, {"text": "Simultaneous interpretation is even more demanding than spoken language translation because the processing must occur online.", "labels": [], "entities": [{"text": "Simultaneous interpretation", "start_pos": 0, "end_pos": 27, "type": "TASK", "confidence": 0.893854945898056}, {"text": "spoken language translation", "start_pos": 56, "end_pos": 83, "type": "TASK", "confidence": 0.8068610231081644}]}, {"text": "Simultaneous interpretation can bridge the language gap in people's daily lives transparently because of its ability to respond immediately to users' speech input.", "labels": [], "entities": [{"text": "Simultaneous interpretation", "start_pos": 0, "end_pos": 27, "type": "TASK", "confidence": 0.6880998909473419}]}, {"text": "Simultaneous interpretation systems recognize and translate speech at the same time the speakers are speaking, thus the audience can hear the translation and catch the meaning without delay.", "labels": [], "entities": []}, {"text": "Potential applications of simultaneous interpretation include interpreting speeches and supporting cross-lingual conversation.", "labels": [], "entities": [{"text": "simultaneous interpretation", "start_pos": 26, "end_pos": 53, "type": "TASK", "confidence": 0.6980282664299011}, {"text": "interpreting speeches", "start_pos": 62, "end_pos": 83, "type": "TASK", "confidence": 0.9175390601158142}]}, {"text": "This paper is devoted to online sentence segmentation methods for simultaneous interpretation.", "labels": [], "entities": [{"text": "online sentence segmentation", "start_pos": 25, "end_pos": 53, "type": "TASK", "confidence": 0.6521097322305044}, {"text": "simultaneous interpretation", "start_pos": 66, "end_pos": 93, "type": "TASK", "confidence": 0.6971010267734528}]}, {"text": "Simultaneous interpretation systems are normally comprised of ASR systems and MT systems.", "labels": [], "entities": [{"text": "Simultaneous interpretation", "start_pos": 0, "end_pos": 27, "type": "TASK", "confidence": 0.7692693471908569}, {"text": "MT", "start_pos": 78, "end_pos": 80, "type": "TASK", "confidence": 0.9536420106887817}]}, {"text": "The output of ASR systems is typically streams of words, but the input to MT systems is normally sentences.", "labels": [], "entities": [{"text": "ASR", "start_pos": 14, "end_pos": 17, "type": "TASK", "confidence": 0.9779631495475769}, {"text": "MT", "start_pos": 74, "end_pos": 76, "type": "TASK", "confidence": 0.9594777822494507}]}, {"text": "Sentence segmenters bridge this gap by segmenting stream of words into sentences.", "labels": [], "entities": [{"text": "Sentence segmenters", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.9109471142292023}]}, {"text": "A number of segmentation methods have been proposed to pipeline ASR and MT, yet most of them require along context of future words that follow sentence boundaries.", "labels": [], "entities": [{"text": "ASR", "start_pos": 64, "end_pos": 67, "type": "TASK", "confidence": 0.9248822331428528}, {"text": "MT", "start_pos": 72, "end_pos": 74, "type": "TASK", "confidence": 0.9541828632354736}]}, {"text": "In addition, they are often computationally expensive.", "labels": [], "entities": []}, {"text": "These shortages make them unattractive for use in simultaneous interpretation.", "labels": [], "entities": [{"text": "simultaneous interpretation", "start_pos": 50, "end_pos": 77, "type": "TASK", "confidence": 0.6959940493106842}]}, {"text": "To the best of our knowledge, there are no published ready-to-use online sentence segmenters, and this motivated this paper.", "labels": [], "entities": [{"text": "sentence segmenters", "start_pos": 73, "end_pos": 92, "type": "TASK", "confidence": 0.7345306873321533}]}, {"text": "The proposed method is crafted in away that requires little computation and minimum future words in order to achieve efficiency.", "labels": [], "entities": []}, {"text": "Also the proposed method is directly optimized against the widely used measurement of translation quality -BLEU () -in order to achieve effectiveness.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 107, "end_pos": 111, "type": "METRIC", "confidence": 0.7416845560073853}]}, {"text": "We believe that this work can directly contribute to the development of real-world simultaneous interpretation systems.", "labels": [], "entities": []}, {"text": "The main contributions of this paper are, \u2022 proposing a segment boundary confidence score; \u2022 proposing a hybrid online sentence segmenter; \u2022 an empirical study and analysis of the proposed method on two translation tasks.", "labels": [], "entities": [{"text": "sentence segmenter", "start_pos": 119, "end_pos": 137, "type": "TASK", "confidence": 0.7524092197418213}]}, {"text": "The rest of this paper is organized as follows.", "labels": [], "entities": []}, {"text": "Section 2 reviews related works on segmentation methods.", "labels": [], "entities": [{"text": "segmentation", "start_pos": 35, "end_pos": 47, "type": "TASK", "confidence": 0.9861542582511902}]}, {"text": "Section 3 describes our methods.", "labels": [], "entities": []}, {"text": "Section 4 presents experiments between English and Japanese.", "labels": [], "entities": []}, {"text": "Section 5 concludes this paper with a description of future work.", "labels": [], "entities": []}], "datasetContent": [{"text": "Experiments were performed on translation between Japanese and English in both directions.", "labels": [], "entities": [{"text": "translation between Japanese and English", "start_pos": 30, "end_pos": 70, "type": "TASK", "confidence": 0.8879249811172485}]}, {"text": "The word orders of these two languages are very different, thus long-distance reordering is often obligatory during translation.", "labels": [], "entities": []}, {"text": "This makes simultaneous interpretation a very challenging task, and therefore we choose this language pair for experiments.", "labels": [], "entities": [{"text": "simultaneous interpretation", "start_pos": 11, "end_pos": 38, "type": "TASK", "confidence": 0.6784958839416504}]}, {"text": "The experimental corpus was a union of corpora from multiple sources, including shared tasks such as the Basic Travel Expression Corpus (), the NTCIR Patent Machine Translation Corpus (, crawled web data and several in-house parallel resources.", "labels": [], "entities": [{"text": "Basic Travel Expression Corpus", "start_pos": 105, "end_pos": 135, "type": "DATASET", "confidence": 0.5522039607167244}, {"text": "NTCIR Patent Machine Translation Corpus", "start_pos": 144, "end_pos": 183, "type": "DATASET", "confidence": 0.8306614875793457}]}, {"text": "shows the statistics of sentences and words in the training, development and test sets.", "labels": [], "entities": []}, {"text": "The corpora were pre-processed using standard procedures for MT.", "labels": [], "entities": [{"text": "MT", "start_pos": 61, "end_pos": 63, "type": "TASK", "confidence": 0.9917667508125305}]}, {"text": "The Japanese text was segmented into words using Mecab ().", "labels": [], "entities": []}, {"text": "The English text was tokenized with the tokenization script released with the Europarl corpus () and converted to lowercase.", "labels": [], "entities": [{"text": "Europarl corpus", "start_pos": 78, "end_pos": 93, "type": "DATASET", "confidence": 0.9925573766231537}]}, {"text": "Two treatments were applied to the development and test sets in order to simulate the output from ASR engines.", "labels": [], "entities": [{"text": "ASR", "start_pos": 98, "end_pos": 101, "type": "TASK", "confidence": 0.9430399537086487}]}, {"text": "First, because ASR engines normally do not output punctuation, punctuation was removed.", "labels": [], "entities": [{"text": "ASR", "start_pos": 15, "end_pos": 18, "type": "TASK", "confidence": 0.9509268403053284}, {"text": "punctuation", "start_pos": 63, "end_pos": 74, "type": "METRIC", "confidence": 0.9525678753852844}]}, {"text": "Second, because ASR engines output steams of tokens which are split by long pauses that may contain a few sentences, a random number (from 1 to 10) of sentences were concatenated to form the input.", "labels": [], "entities": [{"text": "ASR", "start_pos": 16, "end_pos": 19, "type": "TASK", "confidence": 0.9415010809898376}]}, {"text": "After segmentation using the proposed methods, punctuation was inserted into the sentences with a hidden N-gram model model () prior to translation.", "labels": [], "entities": []}, {"text": "In, this method was shown to be the most effective strategy for the translation of unpunctuated text.", "labels": [], "entities": [{"text": "translation of unpunctuated text", "start_pos": 68, "end_pos": 100, "type": "TASK", "confidence": 0.8770963251590729}]}, {"text": "The time efficiency of segmenters were measured by average latency per source word using the definition given in ().", "labels": [], "entities": []}, {"text": "The quality of segmenters were measured by the BLEU of end-to-end translation, and because the segmented source sentences did not necessarily agree with the oracle, translations were aligned to reference sentences through edit distance in order to calculate BLEU ().", "labels": [], "entities": [{"text": "BLEU", "start_pos": 47, "end_pos": 51, "type": "METRIC", "confidence": 0.999136745929718}, {"text": "BLEU", "start_pos": 258, "end_pos": 262, "type": "METRIC", "confidence": 0.9992427825927734}]}, {"text": "The parameters (all of the \u03b8's in the 'Parameters' column in) were set by grid search to maximize the BLEU score on the development set.", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 102, "end_pos": 112, "type": "METRIC", "confidence": 0.9770990908145905}]}, {"text": "5-gram interpolated modified Kneser-Ney smoothed language models were used to calculate the confidence.", "labels": [], "entities": [{"text": "confidence", "start_pos": 92, "end_pos": 102, "type": "METRIC", "confidence": 0.9838220477104187}]}, {"text": "These were trained on the training corpus using the SRILM) tools.", "labels": [], "entities": [{"text": "SRILM", "start_pos": 52, "end_pos": 57, "type": "DATASET", "confidence": 0.6611555218696594}]}, {"text": "The machine translation system was an in-house phrasebased system that pre-ordered the input.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 4, "end_pos": 23, "type": "TASK", "confidence": 0.7780068814754486}]}, {"text": "The performance of the interpretation systems using different sentence segmenters is presented in Table 2.", "labels": [], "entities": []}, {"text": "The following observations can be made.", "labels": [], "entities": []}, {"text": "First, the three proposed online sentence segmenters -the threshold-based, latency-based and hybrid ones -work reasonably well.", "labels": [], "entities": [{"text": "sentence segmenters", "start_pos": 33, "end_pos": 52, "type": "TASK", "confidence": 0.7391194105148315}]}, {"text": "They are much better than the trivial method of fixed-length segmentation, and comparable to the offline method using hidden N-gram models and also to the oracle sentence segmentation.", "labels": [], "entities": [{"text": "oracle sentence segmentation", "start_pos": 155, "end_pos": 183, "type": "TASK", "confidence": 0.6433521111806234}]}, {"text": "Second, the proposed threshold-latency-based segmenter consistently outperformed the thresholdbased and latency-based segmenters in terms of both end-to-end translation quality and time efficiency.", "labels": [], "entities": []}, {"text": "Third, for Japanese-to-English translation, the threshold-based segmenter outperformed the latencybased segmenter.", "labels": [], "entities": [{"text": "Japanese-to-English translation", "start_pos": 11, "end_pos": 42, "type": "TASK", "confidence": 0.5210011750459671}]}, {"text": "The reason might be that Japanese language has obvious end of sentence indicators such as \"MA SU\" and \"DE SU\", and the segmentation confidence scores immediately following them: Performance of using different numbers of future words to calculate confidence scores.", "labels": [], "entities": [{"text": "MA", "start_pos": 91, "end_pos": 93, "type": "METRIC", "confidence": 0.9249429106712341}, {"text": "DE", "start_pos": 103, "end_pos": 105, "type": "METRIC", "confidence": 0.9801148772239685}]}, {"text": "will be quite high, allowing the threshold-based segmenter to easily identify the corresponding segment boundaries.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Experimental Corpora.  \u2020 Including punctuations.", "labels": [], "entities": []}, {"text": " Table 2: Performance of interpretation systems that use different sentence segmenters. The confidence  scores in threshold-based, latency-based and threshold-latency-based segmenters were calculated using  Equation 4.  \u2020 Employed the segment tool from the SRILM toolkit.  \u2021 The method is not online since it  operates on a whole sequence of words, thus the measurement of latency is not applicable.", "labels": [], "entities": [{"text": "SRILM toolkit", "start_pos": 257, "end_pos": 270, "type": "DATASET", "confidence": 0.8515669107437134}]}, {"text": " Table 3: Performance of using different numbers of future words to calculate confidence scores.", "labels": [], "entities": []}]}