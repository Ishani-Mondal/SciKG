{"title": [{"text": "Visualizing the Content of a Children's Story in a Virtual World: Lessons Learned", "labels": [], "entities": [{"text": "Visualizing the Content of a Children's Story in a Virtual World", "start_pos": 0, "end_pos": 64, "type": "TASK", "confidence": 0.8548421810070673}]}], "abstractContent": [{"text": "We present the problem of \"bringing text to life\" via 3D interactive storytelling, where natural language processing (NLP) techniques are used to transform narrative text into events in a virtual world that the user can interact with.", "labels": [], "entities": []}, {"text": "This is a challenging problem, which requires deep understanding of the semantics of a story and the ability to ground those semantic elements to the actors and events of the 3D world's graphical engine.", "labels": [], "entities": []}, {"text": "We show how this problem has motivated interesting extensions to some classic NLP tasks, identify some of the key lessons learned from the work so far, and propose some future research directions.", "labels": [], "entities": []}], "introductionContent": [{"text": "Our primary goal is to take as input natural language text, such as children's stories, translate the text into formal knowledge that represents the actions, actors, plots, and surrounding world, and render this formal representation as virtual 3D worlds via a graphical engine.", "labels": [], "entities": []}, {"text": "We believe that translating text to another modality (in our case, a visual modality) is a good test case for evaluating language understanding systems.", "labels": [], "entities": []}, {"text": "We have developed an initial approach to this textto-virtual-world translation problem based on a probabilistic graphical model that maps text and its semantic annotations (generated by more traditional NLP modules, like semantic role labelers or coreference resolvers) to the knowledge representation of the graphical engine, which is defined in predicate logic.", "labels": [], "entities": [{"text": "textto-virtual-world translation", "start_pos": 46, "end_pos": 78, "type": "TASK", "confidence": 0.7147936224937439}]}, {"text": "In the process, we discovered several failings of traditional NLP systems when faced with this task: Semantic Role Labeling We observed that current state-of-the-art semantic role labeling (SRL) systems perform poorly on children's stories, failing to recognize many of the expressed argument roles.", "labels": [], "entities": [{"text": "Semantic Role Labeling", "start_pos": 101, "end_pos": 123, "type": "TASK", "confidence": 0.7511534293492635}, {"text": "semantic role labeling (SRL)", "start_pos": 166, "end_pos": 194, "type": "TASK", "confidence": 0.8291023174921671}]}, {"text": "Much of this is due to the domain mismatch between the available training data (primarily newswire) and our evaluation (stories for 3D visualization).", "labels": [], "entities": []}, {"text": "To address this, we introduced a technique based on recurrent neural networks for automatically generating additional training data that was similar to the target domain ().", "labels": [], "entities": []}, {"text": "For each selected word (predicate, argument head word) from the source domain, a list of replacement words from the target domain which we believe can occur at the same position as the selected word, are generated by using a recurrent neural network (RNN) language model).", "labels": [], "entities": []}, {"text": "In addition, linguistic resources such as part of speech tags, WordNet, and VerbNet (, are used as filters to select the best replacement words.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 63, "end_pos": 70, "type": "DATASET", "confidence": 0.9671287536621094}, {"text": "VerbNet", "start_pos": 76, "end_pos": 83, "type": "DATASET", "confidence": 0.8416874408721924}]}, {"text": "We primarily targeted improving the results of the four circumstance roles AM-LOC, AM-TMP, AM-MNR and AM-DIR, which are important for semantic frame understanding but not well recognized by standard SRL systems.", "labels": [], "entities": [{"text": "semantic frame understanding", "start_pos": 134, "end_pos": 162, "type": "TASK", "confidence": 0.744729479153951}]}, {"text": "New training examples were generated specifically for the four selected roles.", "labels": [], "entities": []}, {"text": "In an experiment with the out-of-domain setting of the CoNLL 2009 shared task and the SRL system of, training the semantic role labeller on the expanded training data outperforms the model trained on the original training data by +3.36%, +2.77%, +2.84% and +14% F1 over the roles AM-LOC, AM-TMP, AM-MNR and AM-DIR respectively (), but we still need linguistic resources to filter the words obtained by the language model.", "labels": [], "entities": [{"text": "CoNLL 2009 shared task", "start_pos": 55, "end_pos": 77, "type": "DATASET", "confidence": 0.8831502944231033}, {"text": "F1", "start_pos": 262, "end_pos": 264, "type": "METRIC", "confidence": 0.9995597004890442}]}, {"text": "In an experiment where the same model was again trained on CoNLL 2009 training data, but the RNN training included a collection of 252 children stories (mostly fairy tales), we obtained F1 gains of +9.19,% +7.67%, +17.92% and +7.84% respectively over the four selected roles AM-LOC, AM-TMP, AM-MNR and AM-DIR, when testing on the story \"The Day Tuk Became a Hunter\" (Ronald and Carol, 1967) ().", "labels": [], "entities": [{"text": "CoNLL 2009 training data", "start_pos": 59, "end_pos": 83, "type": "DATASET", "confidence": 0.9721262007951736}, {"text": "RNN training", "start_pos": 93, "end_pos": 105, "type": "DATASET", "confidence": 0.8380302488803864}, {"text": "F1", "start_pos": 186, "end_pos": 188, "type": "METRIC", "confidence": 0.999517560005188}, {"text": "The Day Tuk Became a Hunter\" (Ronald and Carol, 1967)", "start_pos": 337, "end_pos": 390, "type": "DATASET", "confidence": 0.6514303982257843}]}, {"text": "Coreference Resolution We observed that current state-of-the-art coreference resolution systems are ignorant of some constraints that are important in storytelling.", "labels": [], "entities": [{"text": "Coreference Resolution", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.8888455033302307}, {"text": "coreference resolution", "start_pos": 65, "end_pos": 87, "type": "TASK", "confidence": 0.9111955761909485}]}, {"text": "For example, a character is often first presented as an indefinite noun phrase (such as \"a woman\"), then later as a definite noun phrase (such as \"the woman\"), but this change in definiteness often resulted on missed coreference links.", "labels": [], "entities": []}, {"text": "To address this, we replaced the inference of the Berkeley coreference resolution system) with a global inference algorithm which incorporated narrative specific constraints through integer linear programming (.", "labels": [], "entities": []}, {"text": "Our formulation models three phenomena that are important for short narrative stories: local discourse coherence, which we model via centering theory constraints, speakerlistener relations, which we model via direct speech act constraints, and character-naming, which we model via definite noun phrase and exact match constraints.", "labels": [], "entities": []}, {"text": "When testing on the UMIREC 1 and N2 2 corpora with the coreference resolution system of (Durrett and Klein, 2013) trained on OntoNotes 3 , our inference substantially improves the original inference on the CoNLL 2011 AVG score by +5.42 (for UMIREC) and +5.22 (for N2) points when using gold mentions and by +1.15 (for UMIREC) and +2.36 (for N2) points when using predicted mentions.", "labels": [], "entities": [{"text": "CoNLL 2011 AVG score", "start_pos": 206, "end_pos": 226, "type": "DATASET", "confidence": 0.929247573018074}]}, {"text": "When testing on the story \"The Day Tuk Became a Hunter\", our inference outperforms the original inference by 4.46 points on the CoNLL 2011 AVG score 4 . Having corrected some of the more serious failures of NLP systems on stories, we turn to the problem of mapping the semantic analysis of these NLP systems to the knowledge representation of the graphical engine.", "labels": [], "entities": [{"text": "The Day Tuk Became a Hunter\"", "start_pos": 27, "end_pos": 55, "type": "TASK", "confidence": 0.5002687914030892}, {"text": "CoNLL 2011 AVG score", "start_pos": 128, "end_pos": 148, "type": "DATASET", "confidence": 0.9324133545160294}]}, {"text": "Our initial approach is implemented as a probabilistic graphical model, where the input is a sentence and its (probabilistic) semantic and coreference annotations, and the output is a set of logical predicate-argument structures.", "labels": [], "entities": []}, {"text": "Each structure represents an action and the parameters of that action (e.g., person/object performing the action, location of the action).", "labels": [], "entities": []}, {"text": "The domain is bounded by a finite set of actions, actors and objects, representable by the graphical environment.", "labels": [], "entities": []}, {"text": "In our implementation, decoding of the model is done through an efficient formulation of a genetic algorithm that exploits conditional independence and improves parallel scalability.", "labels": [], "entities": []}, {"text": "In an evaluation on three stories (\"The Day Tuk Became a Hunter\", \"The Bear and the Travellers\" 5 , and \"The First Tears\" 6 ), this model achieved F1 scores of 81% on recognizing the correct graphical engine actions, and above 60% on recognizing the correct action parameters (Ludwig et al., Under review).", "labels": [], "entities": [{"text": "The Day Tuk Became a Hunter\"", "start_pos": 36, "end_pos": 64, "type": "TASK", "confidence": 0.5285262039729527}, {"text": "F1", "start_pos": 147, "end_pos": 149, "type": "METRIC", "confidence": 0.9997867941856384}]}, {"text": "Example scenes generated by the MUSE software are shown in, and a web-based demonstration can be accessed at http: //roshi.cs.kuleuven.be/muse_demon/.", "labels": [], "entities": [{"text": "MUSE", "start_pos": 32, "end_pos": 36, "type": "TASK", "confidence": 0.7184585928916931}]}], "datasetContent": [], "tableCaptions": []}