{"title": [{"text": "Syntactic analyses and named entity recognition for PubMed and PubMed Central -up-to-the-minute", "labels": [], "entities": [{"text": "named entity recognition", "start_pos": 23, "end_pos": 47, "type": "TASK", "confidence": 0.6108712454636892}, {"text": "PubMed", "start_pos": 52, "end_pos": 58, "type": "DATASET", "confidence": 0.9433070421218872}]}], "abstractContent": [{"text": "Although advanced text mining methods specifically adapted to the biomedical domain are continuously being developed, their applications on large scale have been scarce.", "labels": [], "entities": [{"text": "text mining", "start_pos": 18, "end_pos": 29, "type": "TASK", "confidence": 0.7817628681659698}]}, {"text": "One of the main reasons for this is the lack of computational resources and workforce required for processing large text corpora.", "labels": [], "entities": []}, {"text": "In this paper we present a publicly available resource distributing preprocessed biomedical literature including sentence splitting, tokenization, part-of-speech tagging , syntactic parses and named entity recognition.", "labels": [], "entities": [{"text": "sentence splitting", "start_pos": 113, "end_pos": 131, "type": "TASK", "confidence": 0.7527613937854767}, {"text": "tokenization", "start_pos": 133, "end_pos": 145, "type": "TASK", "confidence": 0.9632772207260132}, {"text": "part-of-speech tagging", "start_pos": 147, "end_pos": 169, "type": "TASK", "confidence": 0.6787660270929337}, {"text": "syntactic parses", "start_pos": 172, "end_pos": 188, "type": "TASK", "confidence": 0.7289787232875824}, {"text": "named entity recognition", "start_pos": 193, "end_pos": 217, "type": "TASK", "confidence": 0.6644501288731893}]}, {"text": "The aim of this work is to support the future development of large-scale text mining resources by eliminating the time consuming but necessary prepro-cessing steps.", "labels": [], "entities": [{"text": "text mining", "start_pos": 73, "end_pos": 84, "type": "TASK", "confidence": 0.8047842681407928}]}, {"text": "This resource covers the whole of PubMed and PubMed Central Open Access section , currently containing 26M abstracts and 1.4M full articles, constituting over 388M analyzed sentences.", "labels": [], "entities": [{"text": "PubMed", "start_pos": 34, "end_pos": 40, "type": "DATASET", "confidence": 0.9536710381507874}, {"text": "PubMed Central Open Access section", "start_pos": 45, "end_pos": 79, "type": "DATASET", "confidence": 0.862081515789032}]}, {"text": "The resource is based on a fully automated pipeline, guaranteeing that the distributed data is always up-to-date.", "labels": [], "entities": []}, {"text": "The resource is available at https://turkunlp.", "labels": [], "entities": []}, {"text": "github.io/pubmed_parses/.", "labels": [], "entities": []}], "introductionContent": [{"text": "Due to the rapid growth of biomedical literature, the maintenance of manually curated databases, usually updated following new discoveries published in articles, has become unfeasible.", "labels": [], "entities": []}, {"text": "This has led to a significant interest in developing automated text mining methods specifically for the biomedical domain.", "labels": [], "entities": [{"text": "text mining", "start_pos": 63, "end_pos": 74, "type": "TASK", "confidence": 0.7019380033016205}]}, {"text": "* These authors contributed equally.", "labels": [], "entities": []}, {"text": "Various community efforts, mainly in the form of shared tasks, have resulted in steady improvement in biomedical text mining methods).", "labels": [], "entities": [{"text": "biomedical text mining", "start_pos": 102, "end_pos": 124, "type": "TASK", "confidence": 0.6719017525513967}]}, {"text": "For instance the GENIA shared tasks focusing on extracting biological events, such as gene regulations, have consistently gathered wide interest and have led to the development of several text mining tools (.", "labels": [], "entities": [{"text": "GENIA", "start_pos": 17, "end_pos": 22, "type": "DATASET", "confidence": 0.8082070350646973}]}, {"text": "These methods have been also succesfully applied on a large scale and several biomedical text mining databases are publicly available).", "labels": [], "entities": [{"text": "biomedical text mining", "start_pos": 78, "end_pos": 100, "type": "TASK", "confidence": 0.6054187417030334}]}, {"text": "Although these resources exist, their number does not reflect the vast amount of fundamental research invested in the underlying methods, mainly due to the nontrivial amount of manual labor and computational resources required to process large quantities of textual data.", "labels": [], "entities": []}, {"text": "Another issue arising from the challenging text preprocessing is the lack of maintenance of the existing databases which in effect nullifies the purpose of text mining as these resources tend to be almost as much out-of-date as their manually curated counterparts.", "labels": [], "entities": [{"text": "text preprocessing", "start_pos": 43, "end_pos": 61, "type": "TASK", "confidence": 0.7717788815498352}, {"text": "text mining", "start_pos": 156, "end_pos": 167, "type": "TASK", "confidence": 0.7748411595821381}]}, {"text": "According to MEDLINE statistics 1 806,326 new articles were indexed during 2015 and thus a text mining resource will miss on average 67 thousand articles each month it hasn't been updated.", "labels": [], "entities": [{"text": "MEDLINE", "start_pos": 13, "end_pos": 20, "type": "DATASET", "confidence": 0.9031575918197632}, {"text": "text mining", "start_pos": 91, "end_pos": 102, "type": "TASK", "confidence": 0.8083819448947906}]}, {"text": "In this paper we present a resource aiming to support the development and maintenance of large-scale biomedical text mining.", "labels": [], "entities": [{"text": "biomedical text mining", "start_pos": 101, "end_pos": 123, "type": "TASK", "confidence": 0.636001835266749}]}, {"text": "The resource includes all PubMed abstracts as well as full articles from the open access section of PubMed Central (PMCOA), with the fundamental language technology building blocks, such as part-ofspeech (POS) tagging and syntactic parses, readily available.", "labels": [], "entities": [{"text": "PubMed Central (PMCOA)", "start_pos": 100, "end_pos": 122, "type": "DATASET", "confidence": 0.8199734091758728}, {"text": "part-ofspeech (POS) tagging", "start_pos": 190, "end_pos": 217, "type": "TASK", "confidence": 0.6200510323047638}]}, {"text": "In addition, recognition of several bio-logically relevant named entities, such as proteins and chemicals is included.", "labels": [], "entities": [{"text": "recognition", "start_pos": 13, "end_pos": 24, "type": "TASK", "confidence": 0.9558320045471191}]}, {"text": "Hence we hope that this resource eliminates the need of the tedious preprocessing involved in utilizing the PubMed data and allows swifter development of new information extraction databases.", "labels": [], "entities": [{"text": "PubMed data", "start_pos": 108, "end_pos": 119, "type": "DATASET", "confidence": 0.9798208177089691}, {"text": "information extraction databases", "start_pos": 158, "end_pos": 190, "type": "TASK", "confidence": 0.7701305945714315}]}, {"text": "The resource is constructed with an automated pipeline which provides weekly updates with the latest articles indexed in PubMed and PubMed Central, ensuring the timeliness of the distributed data.", "labels": [], "entities": [{"text": "PubMed", "start_pos": 121, "end_pos": 127, "type": "DATASET", "confidence": 0.9577100276947021}, {"text": "PubMed Central", "start_pos": 132, "end_pos": 146, "type": "DATASET", "confidence": 0.8442955911159515}, {"text": "timeliness", "start_pos": 161, "end_pos": 171, "type": "METRIC", "confidence": 0.9833088517189026}]}, {"text": "All the data is downloadable in an easily handleable XML format, also used by the widely adapted event extraction system TEES (.", "labels": [], "entities": [{"text": "event extraction", "start_pos": 97, "end_pos": 113, "type": "TASK", "confidence": 0.7149693965911865}, {"text": "TEES", "start_pos": 121, "end_pos": 125, "type": "DATASET", "confidence": 0.7242274284362793}]}, {"text": "A detailed description of this format is available on the website.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Evaluation of the named entity recognition for each entity type on the test sets, measured with  strict entity level metrics. Reported results for corresponding state-of-the-art approaches are shown for  comparison.  * The evaluation of the best performing system for disease mentions is the combination of named entity  recognition and normalization.  ** The official BioCreative II evaluation for our GGP model results in 84.67, 84.54 and 84.60 for preci- sion, recall and F-score respectively. These numbers are comparable to the listed state-of-the-art method.", "labels": [], "entities": [{"text": "named entity  recognition", "start_pos": 317, "end_pos": 342, "type": "TASK", "confidence": 0.7535910407702128}, {"text": "recall", "start_pos": 474, "end_pos": 480, "type": "METRIC", "confidence": 0.9919015765190125}, {"text": "F-score", "start_pos": 485, "end_pos": 492, "type": "METRIC", "confidence": 0.9965950846672058}]}]}