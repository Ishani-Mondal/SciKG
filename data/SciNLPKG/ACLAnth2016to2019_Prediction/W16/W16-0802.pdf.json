{"title": [{"text": "Fake News or Truth? Using Satirical Cues to Detect Potentially Misleading News", "labels": [], "entities": []}], "abstractContent": [{"text": "Satire is an attractive subject in deception detection research: it is a type of deception that intentionally incorporates cues revealing its own de-ceptiveness.", "labels": [], "entities": [{"text": "deception detection research", "start_pos": 35, "end_pos": 63, "type": "TASK", "confidence": 0.8795419931411743}]}, {"text": "Whereas other types of fabrications aim to instill a false sense of truth in the reader, a successful satirical hoax must eventually be exposed as a jest.", "labels": [], "entities": []}, {"text": "This paper provides a conceptual overview of satire and humor, elaborating and illustrating the unique features of satirical news, which mimics the format and style of journalistic reporting.", "labels": [], "entities": []}, {"text": "Satirical news stories were carefully matched and examined in contrast with their legitimate news counterparts in 12 contemporary news topics in 4 domains (civics, science, business , and \"soft\" news).", "labels": [], "entities": []}, {"text": "Building on previous work in satire detection, we proposed an SVM-based algorithm, enriched with 5 predictive features (Absurdity, Humor, Grammar, Negative Affect , and Punctuation) and tested their combinations on 360 news articles.", "labels": [], "entities": [{"text": "satire detection", "start_pos": 29, "end_pos": 45, "type": "TASK", "confidence": 0.8542709350585938}]}, {"text": "Our best predicting feature combination (Absurdity, Grammar and Punctuation) detects satirical news with a 90% precision and 84% recall (F-score=87%).", "labels": [], "entities": [{"text": "precision", "start_pos": 111, "end_pos": 120, "type": "METRIC", "confidence": 0.9983059167861938}, {"text": "recall", "start_pos": 129, "end_pos": 135, "type": "METRIC", "confidence": 0.9996166229248047}, {"text": "F-score", "start_pos": 137, "end_pos": 144, "type": "METRIC", "confidence": 0.9914363026618958}]}, {"text": "Our work in algorithmically identifying satirical news pieces can aid in minimizing the potential deceptive impact of satire.", "labels": [], "entities": [{"text": "algorithmically identifying satirical news pieces", "start_pos": 12, "end_pos": 61, "type": "TASK", "confidence": 0.6884938538074493}]}], "introductionContent": [{"text": "In the course of news production, dissemination, and consumption, there are ample opportunities to deceive and be deceived.", "labels": [], "entities": [{"text": "news production, dissemination", "start_pos": 17, "end_pos": 47, "type": "TASK", "confidence": 0.7236678898334503}]}, {"text": "Direct falsifications such as journalistic fraud or social media hoaxes pose obvious predicaments.", "labels": [], "entities": []}, {"text": "While fake or satirical news maybe less malicious, they may still mislead inattentive readers.", "labels": [], "entities": []}, {"text": "Taken at face value, satirical news can intentionally create a false belief in the readers' minds, per classical definitions of deception).", "labels": [], "entities": []}, {"text": "The falsehoods are intentionally poorly concealed, and beg to be unveiled.", "labels": [], "entities": []}, {"text": "Yet some readers simply miss the joke, and the fake news is further propagated, with often costly consequences ).", "labels": [], "entities": []}], "datasetContent": [{"text": "In this study we collected and analyzed a dataset of 360 news articles as a wide-ranging and diverse data sample, representative of the scope of US and Canadian national newspapers.", "labels": [], "entities": []}, {"text": "The dataset was collected in 2 sets.", "labels": [], "entities": []}, {"text": "The first set was collected from 2 satirical news sites (The Onion and The Beaverton) and 2 legitimate news sources (The Toronto Star and The New York Times) in 2015.", "labels": [], "entities": [{"text": "The Onion and The Beaverton", "start_pos": 57, "end_pos": 84, "type": "DATASET", "confidence": 0.6581128537654877}]}, {"text": "The 240 articles were aggregated by a 2 x 2 x 4 x 3 design (US/Canadian; satirical/legitimate online news; varying across 4 domains (civics, science, business, and \"soft\" news) with 3 distinct topics within each of the 4 domains (see).", "labels": [], "entities": []}, {"text": "For each of the 12 topics, 5 Canadian (from The Beaverton) and 5 American (from the Onion) satirical articles were collected.", "labels": [], "entities": [{"text": "The Beaverton)", "start_pos": 44, "end_pos": 58, "type": "DATASET", "confidence": 0.8321155905723572}]}, {"text": "Each satirical piece was then matched to a legitimate news article that was published in the same country, and as closely related in subject matter as possible.", "labels": [], "entities": []}, {"text": "For example, in the Environment topic, the Beaverton article \"Invasive homo sapiens species meet at forestry conference to discuss pine beetles\" was paired with a Toronto Star article on invasive species: \"'Dan- gerous and invasive' Khapra beetle intercepted at Pearson\".", "labels": [], "entities": [{"text": "Pearson", "start_pos": 262, "end_pos": 269, "type": "DATASET", "confidence": 0.6679481267929077}]}, {"text": "See for the pairing of the articles about Hillary Clinton in the Elections topic.", "labels": [], "entities": []}, {"text": "An additional set of 120 articles was collected in 2016 to expand the inventory of sources and topics, and to serve as a reliability test for the manual findings within the first set.", "labels": [], "entities": [{"text": "reliability", "start_pos": 121, "end_pos": 132, "type": "METRIC", "confidence": 0.950348436832428}]}, {"text": "The second set, still evenly distributed between satirical and legitimate news, was drawn from 6 legitimate 3 and 6 satirical 4 North American online news sources.", "labels": [], "entities": []}, {"text": "Analysis: A trained linguist content-analyzed each pair (legitimate vs. satirical), looking for insights on similarities and differences as well as trends in language use and rhetorical devices.", "labels": [], "entities": []}, {"text": "For machine learning we used the combined set of 360, reserving random 25% of the combined 2 sets data for testing, and performing 10-fold cross-validation on the training set.", "labels": [], "entities": []}, {"text": "The complete dataset is available from the lab's public website 5 .  We conducted multiple experiments to identify the best-performing combination of features for satirical news identification.", "labels": [], "entities": [{"text": "satirical news identification", "start_pos": 163, "end_pos": 192, "type": "TASK", "confidence": 0.6538521647453308}]}, {"text": "We used scikit-learn) and the tf*idf F-measure as the baseline), with features added incrementally.", "labels": [], "entities": []}, {"text": "Scikit-learn library contains several tools designed for machine learning applications in Python , and has been utilized in the supervised learning applications of real and fake news detection).", "labels": [], "entities": [{"text": "real and fake news detection", "start_pos": 164, "end_pos": 192, "type": "TASK", "confidence": 0.8034451603889465}]}, {"text": "The Sklearn.svm package is a set of supervised learning methods used for classification, regression and outlier detection, capable of performing multi-class classification.", "labels": [], "entities": [{"text": "Sklearn.svm package", "start_pos": 4, "end_pos": 23, "type": "DATASET", "confidence": 0.8237163424491882}, {"text": "outlier detection", "start_pos": 104, "end_pos": 121, "type": "TASK", "confidence": 0.6676982641220093}, {"text": "multi-class classification", "start_pos": 145, "end_pos": 171, "type": "TASK", "confidence": 0.68856380879879}]}, {"text": "We assigned two classes: satirical news (1) and legitimate news (0), and used Sklearn.svm.SVC (Support Vector Classification) for supervised training with a linear kernel algorithm, which is suitable for 2 class training data.", "labels": [], "entities": []}, {"text": "Our model was trained on 270 and tested on a set of 90 news articles, with equal proportions of satirical and legitimate news.", "labels": [], "entities": []}, {"text": "presents the measures of precision, recall, and F-score with associated 10-fold cross validation confidence results for our satire detection model.", "labels": [], "entities": [{"text": "precision", "start_pos": 25, "end_pos": 34, "type": "METRIC", "confidence": 0.9996188879013062}, {"text": "recall", "start_pos": 36, "end_pos": 42, "type": "METRIC", "confidence": 0.999387264251709}, {"text": "F-score", "start_pos": 48, "end_pos": 55, "type": "METRIC", "confidence": 0.9990028738975525}, {"text": "satire detection", "start_pos": 124, "end_pos": 140, "type": "TASK", "confidence": 0.9279241561889648}]}, {"text": "The F-score was maximized in the case when Grammar, Punctuation and Absurdity features were used.", "labels": [], "entities": [{"text": "F-score", "start_pos": 4, "end_pos": 11, "type": "METRIC", "confidence": 0.9976535439491272}]}, {"text": "Precision was highest when Punctuation and Grammar were included.", "labels": [], "entities": [{"text": "Precision", "start_pos": 0, "end_pos": 9, "type": "METRIC", "confidence": 0.9922143816947937}]}, {"text": "Absurdity showed the highest recall performance.", "labels": [], "entities": [{"text": "recall", "start_pos": 29, "end_pos": 35, "type": "METRIC", "confidence": 0.9996919631958008}]}], "tableCaptions": [{"text": " Table 2: Satirical news detection evaluation results with 10- fold cross-validation. [Legend: Base= baseline tf-idf topic vector;", "labels": [], "entities": [{"text": "Satirical news detection evaluation", "start_pos": 10, "end_pos": 45, "type": "TASK", "confidence": 0.9156893044710159}]}]}