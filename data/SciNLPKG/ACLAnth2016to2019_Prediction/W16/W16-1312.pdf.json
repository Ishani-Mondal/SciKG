{"title": [], "abstractContent": [{"text": "Universal schema jointly embeds knowledge bases and textual patterns to reason about entities and relations for automatic knowledge base construction and information extraction.", "labels": [], "entities": [{"text": "automatic knowledge base construction", "start_pos": 112, "end_pos": 149, "type": "TASK", "confidence": 0.7143205553293228}, {"text": "information extraction", "start_pos": 154, "end_pos": 176, "type": "TASK", "confidence": 0.7774392068386078}]}, {"text": "In the past, entity pairs and relations were represented as learned vectors with compatibility determined by a scoring function, limiting generalization to unseen text patterns and entities.", "labels": [], "entities": []}, {"text": "Recently, 'column-less' versions of Universal Schema have used compositional pattern encoders to generalize to all text patterns.", "labels": [], "entities": []}, {"text": "In this work we take the next step and propose a 'row-less' model of universal schema, removing explicit entity pair representations.", "labels": [], "entities": []}, {"text": "Instead of learning vector representations for each entity pair in our training set, we treat an entity pair as a function of its relation types.", "labels": [], "entities": []}, {"text": "In experimental results on the FB15k-237 benchmark we demonstrate that we can match the performance of a comparable model with explicit entity pair representations using a model of attention over relation types.", "labels": [], "entities": [{"text": "FB15k-237 benchmark", "start_pos": 31, "end_pos": 50, "type": "DATASET", "confidence": 0.961287260055542}]}, {"text": "We further demonstrate that the model performs with nearly the same accuracy on entity pairs never seen during training.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 68, "end_pos": 76, "type": "METRIC", "confidence": 0.9989387392997742}]}], "introductionContent": [{"text": "Automatic knowledge base construction (AKBC) is the task of building a structured knowledge base (KB) of facts using raw text evidence, and often an initial seed KB to be augmented (.", "labels": [], "entities": [{"text": "Automatic knowledge base construction (AKBC)", "start_pos": 0, "end_pos": 44, "type": "TASK", "confidence": 0.7257788309029171}]}, {"text": "Extracted facts about entities and their relations are useful for many downstream tasks such as question answering and query understanding.", "labels": [], "entities": [{"text": "question answering", "start_pos": 96, "end_pos": 114, "type": "TASK", "confidence": 0.8912732005119324}, {"text": "query understanding", "start_pos": 119, "end_pos": 138, "type": "TASK", "confidence": 0.7906972765922546}]}, {"text": "An effective approach to AKBC is Universal Schema, in which relation extraction is modeled as a matrix factorization problem wherein each row of the matrix is an entity pair and each column represents a relation between entities.", "labels": [], "entities": [{"text": "AKBC", "start_pos": 25, "end_pos": 29, "type": "TASK", "confidence": 0.817234992980957}, {"text": "relation extraction", "start_pos": 60, "end_pos": 79, "type": "TASK", "confidence": 0.792338490486145}]}, {"text": "Relations derived from a KB schema and from free text are thus embedded into a shared space allowing fora rich representation of KB relations, the union of all KB schemata.", "labels": [], "entities": []}, {"text": "This formulation is still limited in terms of its generalization, however.", "labels": [], "entities": []}, {"text": "In its original form, Universal Schema can reason only about entity pairs and text relations explicitly seen at train time; it cannot predict relations between new entity pairs.", "labels": [], "entities": []}, {"text": "In this work we present a 'rowless' extension of Universal Schema.", "labels": [], "entities": []}, {"text": "Rather than representing each entity pair with an explicit dense vector, we encode entity pairs as aggregate functions over their relation types.", "labels": [], "entities": []}, {"text": "This allows Universal Schema to form predictions for all entity pairs regardless of whether that pair was seen during training, and provides a direct connection between the prediction and its provenance.", "labels": [], "entities": []}, {"text": "Many models exist which address this issue by operating at the level of entities rather than entity pairs.", "labels": [], "entities": []}, {"text": "A knowledge base is naturally described as a graph, in which entities are nodes and relations are labeled edges).", "labels": [], "entities": []}, {"text": "In the case of knowledge graph completion, the task is akin to link prediction, assuming an initial set of (s, r, o) triples.", "labels": [], "entities": [{"text": "knowledge graph completion", "start_pos": 15, "end_pos": 41, "type": "TASK", "confidence": 0.671158105134964}, {"text": "link prediction", "start_pos": 63, "end_pos": 78, "type": "TASK", "confidence": 0.8292077481746674}]}, {"text": "No accompanying text data is necessary, since links can be predicted using properties of the graph, such as transitivity.", "labels": [], "entities": []}, {"text": "In order to generalize well, prediction is often posed as low-rank matrix or tensor factorization.", "labels": [], "entities": [{"text": "prediction", "start_pos": 29, "end_pos": 39, "type": "TASK", "confidence": 0.9742828011512756}]}, {"text": "A variety of model variants have been suggested, where the probability of a given edge existing depends on a multi-linear form, or non-linear interactions between s, r, and o ().", "labels": [], "entities": []}, {"text": "These entity-based models have recall advantages over entity pairs.", "labels": [], "entities": [{"text": "recall", "start_pos": 31, "end_pos": 37, "type": "METRIC", "confidence": 0.9991881251335144}]}, {"text": "The model can predict relations between any two entity pairs in the absence of other information such as the pair's contextual occurrence in text.", "labels": [], "entities": []}, {"text": "However, entity models have been shown to be less precise than entity pair models when text is used to augment knowledge base facts.", "labels": [], "entities": []}, {"text": "Both and observe that the entity pair model outperforms entity models in cases where the entity pair was seen at training time.", "labels": [], "entities": []}, {"text": "Since Universal Schema leverages large amounts of unlabeled text we desire the benefits of entity pair modeling, and row-less Universal Schema facilitates learning entity pairs without the drawbacks of the traditional one-embedding-per-pair approach.", "labels": [], "entities": [{"text": "entity pair modeling", "start_pos": 91, "end_pos": 111, "type": "TASK", "confidence": 0.7096929649511973}]}, {"text": "In this paper we investigate Universal Schema models without explicit entity pair representations.", "labels": [], "entities": []}, {"text": "Instead, entity pairs are represented using an aggregation function over their relation types.", "labels": [], "entities": []}, {"text": "This allows our model to naturally make predictions about any entity pair in new textual mentions, regardless of whether they were seen at train time additionally giving the model direct access to provenance.", "labels": [], "entities": []}, {"text": "We show that an attention-based aggregation function outperforms several simpler functions and matches a model using explicit entity pairs.", "labels": [], "entities": []}, {"text": "We then demonstrate that these 'row-less' models accurately predict on entity pairs unseen during training.", "labels": [], "entities": []}], "datasetContent": [{"text": "We evaluate our models on the FB15k-237 dataset from.", "labels": [], "entities": [{"text": "FB15k-237 dataset", "start_pos": 30, "end_pos": 47, "type": "DATASET", "confidence": 0.9917963147163391}]}, {"text": "The data is composed of a small set of 237 Freebase relations and approximately 4 million textual patterns from Clueweb with entities linked to Freebase ( ).", "labels": [], "entities": [{"text": "Freebase", "start_pos": 144, "end_pos": 152, "type": "DATASET", "confidence": 0.9500163197517395}]}, {"text": "In past studies, for each (subject, relation, object) test triple, negative examples are generated by replacing the object with all other entities, filtering out triples that are positive in the data set.", "labels": [], "entities": []}, {"text": "The positive triple is then be ranked among the negatives.", "labels": [], "entities": []}, {"text": "In our experiments we limit the possible generated negatives to those entity pairs that have textual mentions in our training set.", "labels": [], "entities": []}, {"text": "This way we can evaluate how well the model classifies textual mentions as Freebase relations.", "labels": [], "entities": []}, {"text": "We also filter textual patterns with length greater than 35.", "labels": [], "entities": []}, {"text": "We report the percentage of positive triples ranked in the top 10 amongst their negatives as well as the MRR scaled by 100.", "labels": [], "entities": [{"text": "MRR", "start_pos": 105, "end_pos": 108, "type": "METRIC", "confidence": 0.9245420098304749}]}], "tableCaptions": [{"text": " Table 1: The percentage of positive triples ranked in the  top 10 amongst their negatives as well as the mean re- ciprocal rank (MRR) scaled by 100 on a subset of the  FB15K-237 dataset. Negative examples were restricted  to entity pairs that occurred in the KB or text portion of  the training set.", "labels": [], "entities": [{"text": "mean re- ciprocal rank (MRR)", "start_pos": 106, "end_pos": 134, "type": "METRIC", "confidence": 0.8235926777124405}, {"text": "FB15K-237 dataset", "start_pos": 169, "end_pos": 186, "type": "DATASET", "confidence": 0.9924887120723724}]}, {"text": " Table 2: Predicting entity pairs that were not seen at train  time. The percentage of positive triples ranked in the top  10 amongst their negatives as well as the mean reciprocal  rank (MRR) scaled by 100 on a subset of the FB15K- 237 dataset. Also shown is the percent relative decrease  in MRR and Hits@10 between Table 1 (entity pairs seen  during training) and this table (entity pairs unseen during  training).", "labels": [], "entities": [{"text": "mean reciprocal  rank (MRR)", "start_pos": 165, "end_pos": 192, "type": "METRIC", "confidence": 0.7948398093382517}, {"text": "FB15K- 237 dataset", "start_pos": 226, "end_pos": 244, "type": "DATASET", "confidence": 0.9492982029914856}, {"text": "MRR", "start_pos": 294, "end_pos": 297, "type": "METRIC", "confidence": 0.9766747951507568}]}]}