{"title": [{"text": "Discontinuity (Re) 2 visited: A Minimalist Approach to Pseudoprojective Constituent Parsing", "labels": [], "entities": []}], "abstractContent": [{"text": "In this paper, we use insights from Minimalist Grammars (Keenan and Stabler, 2003) to argue fora context-free approximation of discontinuous structures that is both easy to parse for state-of-the-art dynamic programming constituent parsers and has a simple and effective method for the reconstruction of dis-continuous tree structures.", "labels": [], "entities": []}, {"text": "The results achieved on the Tiger treebank-paired with state-of-the-art constituent parsers such as the BLLIP and Berkeley parsers-both improve on existing transformation-based approaches for representing discontin-uous structures and the state-of-the-art results of Fern\u00e1ndez-Gonz\u00e1lez and Martins' (2015) parsing-as-reduction approach.", "labels": [], "entities": [{"text": "Tiger treebank-paired", "start_pos": 28, "end_pos": 49, "type": "DATASET", "confidence": 0.9564708769321442}, {"text": "BLLIP", "start_pos": 104, "end_pos": 109, "type": "DATASET", "confidence": 0.5125051140785217}]}], "introductionContent": [{"text": "For languages with free(r) word order and richer morphology, predicate-argument structure (dependencies of words and their heads/governors) and topology (contiguous phrases or regions in the sentence) do not always match up.", "labels": [], "entities": []}, {"text": "Hence, constituency parsing techniques that rely on a context-free backbone either have to do with a language-dependent approximation that puts topology at the center (e.g. the T\u00fcBa-D/Z treebank of, based on topological fields) or can only produce an approximation of the actual predicate-argument structures (as is the case with most parsing approaches targeting the Negra and Tiger treebanks, cf..", "labels": [], "entities": [{"text": "constituency parsing", "start_pos": 7, "end_pos": 27, "type": "TASK", "confidence": 0.8364081382751465}, {"text": "T\u00fcBa-D/Z treebank", "start_pos": 177, "end_pos": 194, "type": "DATASET", "confidence": 0.7203177958726883}, {"text": "Negra and Tiger treebanks", "start_pos": 368, "end_pos": 393, "type": "DATASET", "confidence": 0.8532425165176392}]}, {"text": "As an alternative to this procrustean choice, practitioners have traditionally preferred dependency *Work was done at the University of Heidelberg structures, which today offer straightforward ways to deal with nonprojective structures in practical ways despite the fact that exact parsing of nonprojective dependencies with second-order factors is intractable in general).", "labels": [], "entities": []}, {"text": "In the following, we present a principled treatment for approximating discontinuous syntactic structures by context-free ones.", "labels": [], "entities": []}, {"text": "The resulting novel technique for pseudoprojective parsing is well suited for lexicalized as well as unlexicalized projective parsers, and yields a feasible solution for accurate probabilistic parsing of discontinuous structures.", "labels": [], "entities": []}], "datasetContent": [{"text": "In the following parsing experiments, we want to compare more directly the accuracy of our LR scheme of projectivization and reattachment to that of, e.g. Boyd's proposal while taking into account many of the concerns that occur in practical parsing today, in particular the compatibility with other techniques used to improve parsing accuracy (linguistic tree transformations, products of latent variable grammars, word clustering-based generalizations of words).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 75, "end_pos": 83, "type": "METRIC", "confidence": 0.9994168281555176}, {"text": "parsing", "start_pos": 327, "end_pos": 334, "type": "TASK", "confidence": 0.9563901424407959}, {"text": "accuracy", "start_pos": 335, "end_pos": 343, "type": "METRIC", "confidence": 0.6837050914764404}, {"text": "word clustering-based generalizations of words", "start_pos": 416, "end_pos": 462, "type": "TASK", "confidence": 0.809216296672821}]}, {"text": "As we are specifically concerned about the behaviour with more unknown words and different distributions of syntactic constructions that occurs in out-of-domain corpora, we exclusively use the partof-speech tags assigned by the parsing model itself.", "labels": [], "entities": []}, {"text": "Corpora used As an in-domain corpus that we split into a training, development and testing set, we use the Tiger treebank (), which encodes argument and adjunct relations in a discontinuous constituent structure with edge labels.", "labels": [], "entities": [{"text": "Tiger treebank", "start_pos": 107, "end_pos": 121, "type": "DATASET", "confidence": 0.8498706817626953}]}, {"text": "We use two splits that were used in the literature for parsing experiments: the first, called the SPMRL split reproduces the train/development/test portions of and was used in the SPMRL shared tasks of 2013 for dependency and constituency parsing, using sentences 1-40474 as training set, the next 5000 as development set, and the remaining 5000 as a test set.", "labels": [], "entities": [{"text": "parsing", "start_pos": 55, "end_pos": 62, "type": "TASK", "confidence": 0.9649611711502075}, {"text": "SPMRL shared tasks of 2013", "start_pos": 180, "end_pos": 206, "type": "TASK", "confidence": 0.5969655156135559}, {"text": "constituency parsing", "start_pos": 226, "end_pos": 246, "type": "TASK", "confidence": 0.794979065656662}]}, {"text": "The second split was first used in the experiments of and uses folds 9 and 10 in a 10-fold setup as development and testing portions, respectively.", "labels": [], "entities": []}, {"text": "As an out-of-domain dataset, we use the Smultron treebanks of, which include portions of a novel (sophie), business reports (economy), texts about mountaineering (alpine) as well as extracts from the manual of a DVD player (dvdman).", "labels": [], "entities": [{"text": "Smultron treebanks", "start_pos": 40, "end_pos": 58, "type": "DATASET", "confidence": 0.8682500123977661}]}, {"text": "The annotation of the Smultron treebanks is loosely based on the Tiger scheme but differs in two important respects: on one hand, the Tiger scheme merges PP nodes with the noun phrases that is the argument of the preposition, yielding one single PP phrase; on the other hand, the Smultron annotation scheme uses extra nodes for unary noun, verb and adjective phrases that would be elided in the Tiger scheme.", "labels": [], "entities": [{"text": "Smultron treebanks", "start_pos": 22, "end_pos": 40, "type": "DATASET", "confidence": 0.7859133780002594}]}, {"text": "For a sensible comparison, we use a transformed version of the Smultron treebanks where unary nodes are deleted and argu- clip.", "labels": [], "entities": [{"text": "Smultron treebanks", "start_pos": 63, "end_pos": 81, "type": "DATASET", "confidence": 0.8671894073486328}]}, {"text": "\"If the plans become more concrete, the Frankfurt group, which had its 125-year anniversary in January 1988 would cut the the connection to their historical roots.\"", "labels": [], "entities": [{"text": "Frankfurt group", "start_pos": 40, "end_pos": 55, "type": "DATASET", "confidence": 0.9733540415763855}]}, {"text": "Parsing models For reasons of simplicity, we limit ourselves to a small number of generative parsing models that have been shown to work well for context-free parsing.", "labels": [], "entities": [{"text": "generative parsing", "start_pos": 82, "end_pos": 100, "type": "TASK", "confidence": 0.9335523247718811}]}, {"text": "The BLLIP parser (of which we use the generative model only and not the discriminative reranking part) uses a \"maximum-entropy-inspired\" probabilistic model that produces head-lexicalized constituents from the inside out while conditioning on the two previous neighbours, the grandparent constituents, and their heads).", "labels": [], "entities": []}, {"text": "The PCFG-LA parsing model of) uses a zeroth-order right-markovized version of the treebank which is subsequently augmented with latent symbol refinements in order to improve the fit, using smoothing and a split-merge procedure to avoid overfitting in the EM-based refinement process.", "labels": [], "entities": [{"text": "PCFG-LA parsing", "start_pos": 4, "end_pos": 19, "type": "TASK", "confidence": 0.7854594588279724}]}, {"text": "We found that four split-merge iterations (instead of the default six) gave the best results with the linguistically transformed trees.", "labels": [], "entities": []}, {"text": "As the PCFG-LA model learns a latent-variable augmentation of the treebank trees and most often reaches a non-unique local maximum of the EM objective, it is possible and useful to combine multiple PCFG-LA models to reach an even better performance using a product grammar approach where each rule is scored by a product-of-experts of multiple parsers.", "labels": [], "entities": []}, {"text": "For the out-of-domain parsing, Candito and Seddah found that replacing words with clusters improved the generalization ability of parsers.", "labels": [], "entities": []}, {"text": "After preliminary experiments showed that replacing all words with clusters actually had a negative effect, our setting using word clusters only replaces words that occur fewer than five times, using word clusters derived with the Marlin tool and text from the DECOW corpus 2 , limiting the vocabulary size to the most frequent 250 000 word types as done by M\u00fcller and Sch\u00fctze.", "labels": [], "entities": [{"text": "DECOW corpus 2", "start_pos": 261, "end_pos": 275, "type": "DATASET", "confidence": 0.9046793580055237}]}, {"text": "Finally, we also include in our investigation the use of linguistic tree transformations, which e.g. as well as found useful both for unlexicalized and discriminative PCFG parsing.", "labels": [], "entities": [{"text": "PCFG parsing", "start_pos": 167, "end_pos": 179, "type": "TASK", "confidence": 0.664169430732727}]}, {"text": "In particular, we use lowering of parenthetic material as proposed by to reduce the complexity of discontinuities, but also markers for relative clauses and comparative phrases, linguistically motivated subcategorization information for sentences, added case information to noun phrases, as well as refing part-of-speech classes using some morphological information.", "labels": [], "entities": []}, {"text": "If we compare the accuracy of the POS assignment from the PCFG-LA parsing models to both the tagging results of and our own, in each case using the Marmot CRF tagger, we see that in all cases (except for the Alpine domain) the parser is able to make use of the syntactic context to achieve improved part-ofspeech accuracy, even if the overall difficulty of the out-of-domain texts is higher.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 18, "end_pos": 26, "type": "METRIC", "confidence": 0.9991505146026611}, {"text": "PCFG-LA parsing", "start_pos": 58, "end_pos": 73, "type": "TASK", "confidence": 0.7316828072071075}, {"text": "accuracy", "start_pos": 313, "end_pos": 321, "type": "METRIC", "confidence": 0.9609642624855042}]}, {"text": "Use of word clusters seems to be especially helpful in those cases where the parser has difficulty at the POS level.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Comparison on the Tiger development set, sentences with \u2264 70 words", "labels": [], "entities": [{"text": "Tiger development set", "start_pos": 28, "end_pos": 49, "type": "DATASET", "confidence": 0.9391491413116455}]}, {"text": " Table 3: Comparative results for parsing the SMULTRON tree-", "labels": [], "entities": [{"text": "parsing", "start_pos": 34, "end_pos": 41, "type": "TASK", "confidence": 0.9834439754486084}, {"text": "SMULTRON tree", "start_pos": 46, "end_pos": 59, "type": "DATASET", "confidence": 0.713616669178009}]}, {"text": " Table 4: Test set results on the split of", "labels": [], "entities": [{"text": "split", "start_pos": 34, "end_pos": 39, "type": "TASK", "confidence": 0.9179893732070923}]}]}