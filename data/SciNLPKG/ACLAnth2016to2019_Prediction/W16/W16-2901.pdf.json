{"title": [{"text": "A Machine Learning Approach to Clinical Terms Normalization", "labels": [], "entities": [{"text": "Clinical Terms Normalization", "start_pos": 31, "end_pos": 59, "type": "TASK", "confidence": 0.7715419630209605}]}], "abstractContent": [{"text": "We propose a machine learning approach for semantic recognition and normaliza-tion of clinical term descriptions.", "labels": [], "entities": [{"text": "semantic recognition", "start_pos": 43, "end_pos": 63, "type": "TASK", "confidence": 0.8909977376461029}, {"text": "normaliza-tion of clinical term descriptions", "start_pos": 68, "end_pos": 112, "type": "TASK", "confidence": 0.6003046631813049}]}, {"text": "Clinical terms considered here are noisy descriptions in Spanish language written by healthcare professionals in our electronic health record system.", "labels": [], "entities": []}, {"text": "These description terms contain clinical findings, family history , suspected disease, among other categories of concepts.", "labels": [], "entities": []}, {"text": "Descriptions are usually very short texts presenting high lexical variability containing synonymy, acronyms, abbreviations and typographical errors.", "labels": [], "entities": []}, {"text": "Mapping description terms to normalized descriptions requires medical expertise which makes it difficult to develop a rule-based knowledge engineering approach.", "labels": [], "entities": [{"text": "Mapping description terms", "start_pos": 0, "end_pos": 25, "type": "TASK", "confidence": 0.8719650308291117}]}, {"text": "In order to build a training dataset we use those descriptions that have been previously matched by terminolo-gists to the hospital thesaurus database.", "labels": [], "entities": []}, {"text": "We generate a set of feature vectors based on pairs of descriptions involving their individual and joint characteristics.", "labels": [], "entities": []}, {"text": "We propose an unsupervised learning approach to discover term equivalence classes including synonyms, abbreviations, acronyms and frequent typographical errors.", "labels": [], "entities": []}, {"text": "We evaluate different combinations of features to train MaxEnt and XGBoost models.", "labels": [], "entities": [{"text": "MaxEnt", "start_pos": 56, "end_pos": 62, "type": "DATASET", "confidence": 0.925592839717865}]}, {"text": "Our system achieves an F 1 score of 89% on the Hospital Italiano de Buenos Aires (HIBA) problem list.", "labels": [], "entities": [{"text": "F 1 score", "start_pos": 23, "end_pos": 32, "type": "METRIC", "confidence": 0.9918593962987264}, {"text": "Hospital Italiano de Buenos Aires (HIBA) problem list", "start_pos": 47, "end_pos": 100, "type": "DATASET", "confidence": 0.7348732024431228}]}], "introductionContent": [{"text": "Some electronic health records (EHR) implementations allow users to introduce free text descriptions to capture clinical problems information enabling higher level of expressiveness and flexibility to physicians.", "labels": [], "entities": []}, {"text": "Those descriptions must be encoded according to their meaning in order to allow the information to be consumed by other systems.", "labels": [], "entities": []}, {"text": "Descriptions are grouped into concepts according to the meaning.", "labels": [], "entities": []}, {"text": "The following descriptions correspond to the same concept 1 : ( Free text descriptions written by healthcare professionals contain typos as in cancer plumnoar: a variation of description (2).", "labels": [], "entities": []}, {"text": "It should be noted also that description (4) does not represent a synonym in a strict terminological sense.", "labels": [], "entities": []}, {"text": "However it represents the same concept because the string desde 2009 (since 2009) does not add relevant information from a problem list perspective (in the sense of EHR and terminology tradition).", "labels": [], "entities": [{"text": "EHR", "start_pos": 165, "end_pos": 168, "type": "DATASET", "confidence": 0.8947173953056335}]}, {"text": "Mapping strings to concepts has been along standing problem in BioNLP, string similarity techniques as well as machine learning approaches have been applied.", "labels": [], "entities": [{"text": "BioNLP", "start_pos": 63, "end_pos": 69, "type": "DATASET", "confidence": 0.8151914477348328}]}, {"text": "Automatic mapping of key concepts from text in clinical notes to a reference terminology is an important task to achieve, in order to extract clinical information present in notes and patient reports.", "labels": [], "entities": []}, {"text": "One of the problems of bio-1 medical data integration is variation of terms usage.", "labels": [], "entities": [{"text": "bio-1 medical data integration", "start_pos": 23, "end_pos": 53, "type": "TASK", "confidence": 0.5501755848526955}]}, {"text": "Exact string matching often fails to associate a string with its bio-medical concept (represented by an ID or accession number in the database) due to differences of string occurrences.", "labels": [], "entities": [{"text": "string matching", "start_pos": 6, "end_pos": 21, "type": "TASK", "confidence": 0.7860989570617676}]}, {"text": "Soft string matching algorithms are able to find the relevant concept by considering the string similarity between candidate strings.", "labels": [], "entities": [{"text": "string matching", "start_pos": 5, "end_pos": 20, "type": "TASK", "confidence": 0.7963964641094208}]}, {"text": "However, the accuracy of soft matching highly depends on the similarity measure employed.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 13, "end_pos": 21, "type": "METRIC", "confidence": 0.9991803765296936}]}, {"text": "String similarity techniques have been applied to a variety of problems in BioNLP, such as UMLS concepts normalization), UMLS clinical terms, disease normalization (), gene and protein names, to interface terminologies () and different databases).", "labels": [], "entities": [{"text": "BioNLP", "start_pos": 75, "end_pos": 81, "type": "DATASET", "confidence": 0.7543928027153015}, {"text": "UMLS concepts normalization", "start_pos": 91, "end_pos": 118, "type": "TASK", "confidence": 0.5824613372484843}]}, {"text": "String similarity can be used for named entity recognition (SNOMED-CT taggers) and reference resolution) alias extraction (, acronym-expansion extraction, e.g. ().", "labels": [], "entities": [{"text": "named entity recognition", "start_pos": 34, "end_pos": 58, "type": "TASK", "confidence": 0.6128757695357004}, {"text": "SNOMED-CT taggers", "start_pos": 60, "end_pos": 77, "type": "TASK", "confidence": 0.7480388283729553}, {"text": "reference resolution) alias extraction", "start_pos": 83, "end_pos": 121, "type": "TASK", "confidence": 0.6927882194519043}, {"text": "acronym-expansion extraction", "start_pos": 125, "end_pos": 153, "type": "TASK", "confidence": 0.7285618335008621}]}, {"text": "On a similar view there area number of works on automated clinical coding).", "labels": [], "entities": [{"text": "clinical coding", "start_pos": 58, "end_pos": 73, "type": "TASK", "confidence": 0.6993338465690613}]}, {"text": "This work explores traditional soft string matching methods along with n-gram character and word features in a machine learning approach using MaxEnt and XGBoost classifiers.", "labels": [], "entities": [{"text": "soft string matching", "start_pos": 31, "end_pos": 51, "type": "TASK", "confidence": 0.6446574926376343}]}, {"text": "An unsupervised learning approach to generate new features by detecting synonyms, abbreviations and typos is presented to improve classification performance.", "labels": [], "entities": []}, {"text": "The models are compared to a baseline obtained by a vector space model configuration based on character n-grams and a TF-IDF weighting scheme, implemented in Apache Lucene.", "labels": [], "entities": []}, {"text": "The remainder of this paper is structured as follows: in Section 2, we describe the data set we used.", "labels": [], "entities": []}, {"text": "In Section 3, we discuss the similarity metrics and similarity features for machine learning algorithms.", "labels": [], "entities": []}, {"text": "In Section 4 we discuss the experimentation and results.", "labels": [], "entities": []}, {"text": "Finally in Section 5 we report our conclusions and expected future work.", "labels": [], "entities": []}], "datasetContent": [{"text": "Our experiments were conducted by using scikitlearn machine learning library (Pedregosa et al., 2011) with liblinear (Fan et al., 2008) solver for MaxEnt, considering L2 regularization.", "labels": [], "entities": []}, {"text": "Hyperparameter C was determined by 5-fold crossvalidation considering F1 measure.", "labels": [], "entities": [{"text": "Hyperparameter C", "start_pos": 0, "end_pos": 16, "type": "METRIC", "confidence": 0.9400677978992462}, {"text": "F1 measure", "start_pos": 70, "end_pos": 80, "type": "METRIC", "confidence": 0.9688120186328888}]}, {"text": "We trained XGBoost model, with binary logistic objective and F1 score as evaluation metric, by using XGBoost library described in.", "labels": [], "entities": [{"text": "F1 score", "start_pos": 61, "end_pos": 69, "type": "METRIC", "confidence": 0.9865425825119019}]}, {"text": "Connected components in graph and label propagation algorithm for graph clustering were conducted by using igraph library.", "labels": [], "entities": [{"text": "label propagation", "start_pos": 34, "end_pos": 51, "type": "TASK", "confidence": 0.7571707963943481}, {"text": "graph clustering", "start_pos": 66, "end_pos": 82, "type": "TASK", "confidence": 0.7536315321922302}]}, {"text": "In order to generate word equivalence classes for S10 we found 278,555 concepts in the thesaurus with at least two associated descriptions which generate 5,956,368 potential pairs of descriptions connected to the same concept.", "labels": [], "entities": []}, {"text": "Filtering pairs of descriptions such that both shares the same words except one, we obtain 505,447 word associations.", "labels": [], "entities": []}, {"text": "By taking the connected components of G we get 505, 447 edges and 805 groups.", "labels": [], "entities": []}, {"text": "Finally, clustering connected components for which more than one meaning are represented, we obtain 4,711 words in 957 group of words.", "labels": [], "entities": []}, {"text": "We compare the predictive power to classify a pair of descriptions as a positive match by calculating the F1 measure on different models.", "labels": [], "entities": [{"text": "F1 measure", "start_pos": 106, "end_pos": 116, "type": "METRIC", "confidence": 0.9808332324028015}]}, {"text": "Also, we compare the ability to rank the retrieved results using the classification model probability as scoring by calculating P@1, R@1 and the mean reciprocal rank (MRR).", "labels": [], "entities": [{"text": "mean reciprocal rank (MRR)", "start_pos": 145, "end_pos": 171, "type": "METRIC", "confidence": 0.8585532704989115}]}, {"text": "By using IR score with some fixed threshold we define a classifier algorithm with its respective precision and recall (as threshold increases, recall decreases and precision increase).", "labels": [], "entities": [{"text": "precision", "start_pos": 97, "end_pos": 106, "type": "METRIC", "confidence": 0.9992000460624695}, {"text": "recall", "start_pos": 111, "end_pos": 117, "type": "METRIC", "confidence": 0.9980024695396423}, {"text": "recall", "start_pos": 143, "end_pos": 149, "type": "METRIC", "confidence": 0.9988057613372803}, {"text": "precision", "start_pos": 164, "end_pos": 173, "type": "METRIC", "confidence": 0.9988928437232971}]}, {"text": "shows IR score precision-recall curve against string metrics features based fitted models.", "labels": [], "entities": [{"text": "IR score", "start_pos": 6, "end_pos": 14, "type": "METRIC", "confidence": 0.8754995465278625}, {"text": "precision-recall", "start_pos": 15, "end_pos": 31, "type": "METRIC", "confidence": 0.5916687846183777}]}, {"text": "shows MaxEnt and XGBoost F1 score for string features based models.", "labels": [], "entities": [{"text": "MaxEnt", "start_pos": 6, "end_pos": 12, "type": "DATASET", "confidence": 0.8605954647064209}, {"text": "XGBoost F1 score", "start_pos": 17, "end_pos": 33, "type": "METRIC", "confidence": 0.6755561431248983}]}, {"text": "By considering F1 measure on string metrics (S1) and vector space model representation of descriptions (S2, S3, S4, S5), XGBoost showed a considerable improvement on bi-gram character features based (see) either on frequency (S4) or TF-IDF (S5) weight schemas, outperforming MaxEnt. freq.", "labels": [], "entities": [{"text": "F1 measure", "start_pos": 15, "end_pos": 25, "type": "METRIC", "confidence": 0.9767047464847565}, {"text": "MaxEnt. freq", "start_pos": 275, "end_pos": 287, "type": "DATASET", "confidence": 0.919573187828064}]}, {"text": "0.57 0.76 (S5) d1, d2 tf-idf 0.56 0.74 (S7) d12, d21 freq.", "labels": [], "entities": []}, {"text": "0.58 0.76 (S9) d12, d21, c freq.", "labels": [], "entities": []}, {"text": "0.72 0.77 Each XGBoost bi-gram character features based model (dashed lines with markers) outperforms the word features based models (solid lines).", "labels": [], "entities": []}, {"text": "Precision values are given across all recall levels).", "labels": [], "entities": [{"text": "Precision", "start_pos": 0, "end_pos": 9, "type": "METRIC", "confidence": 0.9943243265151978}, {"text": "recall", "start_pos": 38, "end_pos": 44, "type": "METRIC", "confidence": 0.9980911612510681}]}, {"text": "We can see in that word features based models improves performance over bi-gram character feature based models using MaxEnt (each source is represented by a marker type, e.g. a triangle for the source d 12 , d 21 ).", "labels": [], "entities": []}, {"text": "S8 and S9 features outperform the others features on MaxEnt.", "labels": [], "entities": []}, {"text": "Results on word features are detailed in.", "labels": [], "entities": []}, {"text": "With respect to the set of features considering word difference between pairs of descriptions (S6, S7), XGBoost also performs the task better when consider bi-gram character features (S7) tf-idf 0.59 0.58 (S6) d12, d21 binary 0.63 0.62 (S8) d12, d21, c binary 0.76 0.62 as shown in, while MaxEnt works better on word features (S6) as shown in.", "labels": [], "entities": []}, {"text": "When context vector is present along with word difference representation (S6 vs S8 and S7 vs S9), MaxEnt showed a considerable improvement in S8 respect to S6 (see) but XGBoost achieves a slightly improvement in S9 compared to S7 (see, S6 vs S8 and S7 vs S9).", "labels": [], "entities": [{"text": "word difference representation", "start_pos": 42, "end_pos": 72, "type": "TASK", "confidence": 0.7623409728209177}]}, {"text": "Word difference vector representation worked better in MaxEnt, than combining string metric and traditional word or n-gram based representation of descriptions, while XGBoost achieves similar performance when consider that combination.", "labels": [], "entities": [{"text": "Word difference vector representation", "start_pos": 0, "end_pos": 37, "type": "TASK", "confidence": 0.6512863710522652}]}, {"text": "When word equivalence classes features based models are considered (S10), MaxEnt and XGBoost achieves similar performance (see).", "labels": [], "entities": []}, {"text": "By combining (S1, S8, S10) features MaxEnt achieves an F1 score of 0.87, while XGBoost achieves an F1 score of 0.86 by combining (S1, S9, S10) as showed in and improving the previous models.", "labels": [], "entities": [{"text": "MaxEnt", "start_pos": 36, "end_pos": 42, "type": "DATASET", "confidence": 0.8000847697257996}, {"text": "F1 score", "start_pos": 55, "end_pos": 63, "type": "METRIC", "confidence": 0.9888639748096466}, {"text": "F1 score", "start_pos": 99, "end_pos": 107, "type": "METRIC", "confidence": 0.9885415732860565}]}, {"text": "To evaluate these models performance on ranked results, we compute the P@1, R@1 and mean reciprocal rank (MRR) metrics showed in.", "labels": [], "entities": [{"text": "mean reciprocal rank (MRR) metrics", "start_pos": 84, "end_pos": 118, "type": "METRIC", "confidence": 0.94842871597835}]}], "tableCaptions": [{"text": " Table 1: Correlation (Pearson) between string  metrics", "labels": [], "entities": [{"text": "Correlation (Pearson)", "start_pos": 10, "end_pos": 31, "type": "METRIC", "confidence": 0.7143566608428955}]}, {"text": " Table 4: MaxEnt and XGBoost F1-score over string met-", "labels": [], "entities": [{"text": "MaxEnt", "start_pos": 10, "end_pos": 16, "type": "DATASET", "confidence": 0.7841448187828064}, {"text": "F1-score", "start_pos": 29, "end_pos": 37, "type": "METRIC", "confidence": 0.6460199952125549}]}, {"text": " Table 7: MaxEnt and XGBoost F1-score over word equiv-", "labels": [], "entities": [{"text": "F1-score", "start_pos": 29, "end_pos": 37, "type": "METRIC", "confidence": 0.8129107356071472}]}, {"text": " Table 8: MaxEnt and XGBoost F1-score over feature sets", "labels": [], "entities": [{"text": "MaxEnt", "start_pos": 10, "end_pos": 16, "type": "DATASET", "confidence": 0.8691919445991516}, {"text": "F1-score", "start_pos": 29, "end_pos": 37, "type": "METRIC", "confidence": 0.8429675102233887}]}, {"text": " Table 9: MaxEnt and XGBoost F1-score over feature sets", "labels": [], "entities": [{"text": "MaxEnt", "start_pos": 10, "end_pos": 16, "type": "DATASET", "confidence": 0.8761575818061829}, {"text": "F1-score", "start_pos": 29, "end_pos": 37, "type": "METRIC", "confidence": 0.8448635339736938}]}]}