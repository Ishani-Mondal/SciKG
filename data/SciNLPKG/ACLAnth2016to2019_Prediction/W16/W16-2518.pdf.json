{"title": [{"text": "Thematic fit evaluation: an aspect of selectional preferences", "labels": [], "entities": [{"text": "Thematic fit evaluation", "start_pos": 0, "end_pos": 23, "type": "TASK", "confidence": 0.7806543906529745}]}], "abstractContent": [{"text": "In this paper, we discuss the human thematic fit judgement correlation task in the context of real-valued vector space word representations.", "labels": [], "entities": [{"text": "human thematic fit judgement correlation task", "start_pos": 30, "end_pos": 75, "type": "TASK", "confidence": 0.6636098275581995}]}, {"text": "Thematic fit is the extent to which an argument fulfils the se-lectional preference of a verb given a role: for example, how well \"cake\" fulfils the patient role of \"cut\".", "labels": [], "entities": [{"text": "Thematic fit", "start_pos": 0, "end_pos": 12, "type": "METRIC", "confidence": 0.918853759765625}]}, {"text": "In recent work, systems have been evaluated on this task by finding the correlations of their output judgements with human-collected judgement data.", "labels": [], "entities": []}, {"text": "This task is a representation-independent way of evaluating models that can be applied whenever a system score can be generated, and it is applicable wherever predicate-argument relations are significant to performance in end-user tasks.", "labels": [], "entities": []}, {"text": "Significant progress has been made on this cognitive modeling task, leaving considerable space for future, more comprehensive types of evaluation.", "labels": [], "entities": [{"text": "cognitive modeling task", "start_pos": 43, "end_pos": 66, "type": "TASK", "confidence": 0.7509441177050272}]}], "introductionContent": [{"text": "In this paper, we discuss away of evaluating real-valued semantic representations: human thematic fit judgement correlations.", "labels": [], "entities": []}, {"text": "This evaluation method permits us to model the relationship between the construction of these semantic representation spaces and the cognitive decision-making process that goes into predicate-argument compositionality inhuman language users.", "labels": [], "entities": []}, {"text": "We focus hereon verb-noun compositionality as a special case of thematic fit judgement evaluation.", "labels": [], "entities": [{"text": "verb-noun compositionality", "start_pos": 16, "end_pos": 42, "type": "TASK", "confidence": 0.7743213474750519}]}, {"text": "A verb typically evokes expectations regarding the participants in the event that the verb describes.", "labels": [], "entities": []}, {"text": "By generalizing over different verbs, we can create a scheme of thematic roles, which characterize different ways to be a participant.", "labels": [], "entities": []}, {"text": "Schemes vary, but most contain agent, patient, instrument, and location (Aarts, 1997).", "labels": [], "entities": []}, {"text": "The verb \"cut\" creates an expectation, among others, fora patient role that is to be fulfilled by something that is cuttable.", "labels": [], "entities": []}, {"text": "This role-specific expectation is called the patient selectional preference of \"cut\".", "labels": [], "entities": []}, {"text": "The noun \"cake\" fulfils the patient selectional preference of \"cut\", \"form\" less so.", "labels": [], "entities": []}, {"text": "As such, we can see that selectional preferences are likely to be graded.", "labels": [], "entities": []}, {"text": "We define thematic fit to be the extent to which a noun fulfils the selectional preference of a verb given a role.", "labels": [], "entities": []}, {"text": "This can be quantified in thematic fit ratings, human judgements that apply to combinations of verb, role, and noun . One of the goals of this type of evaluation is both for cognitive modeling and for future application.", "labels": [], "entities": []}, {"text": "From a cognitive modeling perspective, thematic fit judgements offer a window into the decision-making process of language users in assigning semantic representations to complex expressions.", "labels": [], "entities": []}, {"text": "Psycholinguistic work has shown that these introspective judgements map well to underlying processing notions.", "labels": [], "entities": []}, {"text": "One of our goals in developing this type of evaluation is to provide another method of testing systems designed for applications in which predicateargument relations may have a significant effect on performance, especially in user interaction.", "labels": [], "entities": []}, {"text": "This particularly applies in tasks where non-local dependencies have semantic relevance, for example, such as in judging the plausibility of a candidate coreferent from elsewhere in the discourse.", "labels": [], "entities": [{"text": "judging the plausibility of a candidate coreferent from elsewhere in the discourse", "start_pos": 113, "end_pos": 195, "type": "TASK", "confidence": 0.7286450912555059}]}, {"text": "Such applications include statistical sentence generation in spoken dialog contexts, where systems must make plausible lexical choices in context.", "labels": [], "entities": [{"text": "statistical sentence generation", "start_pos": 26, "end_pos": 57, "type": "TASK", "confidence": 0.7227077086766561}]}, {"text": "This is particularly important as dialog systems grow steadily less task-specific.", "labels": [], "entities": []}, {"text": "Indeed, applications that depends on predicting or generating match-ing predicate-argument pairs in a human-plausible way, such as question-answering, summarization, or machine translation, may benefit from this form of thematic fit evaluation.", "labels": [], "entities": [{"text": "predicting or generating match-ing predicate-argument pairs", "start_pos": 37, "end_pos": 96, "type": "TASK", "confidence": 0.7594030996163686}, {"text": "summarization", "start_pos": 151, "end_pos": 164, "type": "TASK", "confidence": 0.9724583029747009}, {"text": "machine translation", "start_pos": 169, "end_pos": 188, "type": "TASK", "confidence": 0.6793380677700043}]}, {"text": "Both from the cognitive modeling perspective and from the applications perspective, there is still significant work to be done in constructing models, including distributional representations.", "labels": [], "entities": []}, {"text": "We thus need to determine whether and how we can find judgements that area suitable gold standard for evaluating automatic systems.", "labels": [], "entities": []}, {"text": "We seek in this paper to shed some light on the aspects of this problem relevant to vector-space word representation and to highlight the evaluation data currently available for this task.", "labels": [], "entities": [{"text": "vector-space word representation", "start_pos": 84, "end_pos": 116, "type": "TASK", "confidence": 0.6189618607362112}]}, {"text": "This task differs from other ways of evaluating word representations because it focuses partly on the psychological plausibility of models of predicate-argument function application.", "labels": [], "entities": [{"text": "evaluating word representations", "start_pos": 37, "end_pos": 68, "type": "TASK", "confidence": 0.6345081528027853}]}, {"text": "Analogy task evaluations, for example, involve comparisons of word representations that are similar in their parts of speech ().", "labels": [], "entities": [{"text": "Analogy task evaluations", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.7827810446421305}]}, {"text": "Here we are evaluating relations between words that are \"counterparts\" of one another and that exist overall in complementary distribution to one another.", "labels": [], "entities": []}, {"text": "There are other forms of evaluation that attempt to replicate role assignments or predict more plausible role-fillers given observed text data (Van de Cruys, 2014), but this does not directly capture human biases as to plausibility: infrequent predicate-argument combinations can nevertheless have high human ratings.", "labels": [], "entities": []}, {"text": "Consequently, we view this task as a useful contribution to the family of evaluations that would test different aspects of general-purpose word representations.", "labels": [], "entities": []}], "datasetContent": [{"text": "The first datasets of human judgements were obtained in the context of a larger scientific discussion on human sentence processing.", "labels": [], "entities": [{"text": "human sentence processing", "start_pos": 105, "end_pos": 130, "type": "TASK", "confidence": 0.7021919886271158}]}, {"text": "In particular, proposed incremental evaluation of thematic fit for the arguments in potential parses as a method of parse comparison.", "labels": [], "entities": [{"text": "parse comparison", "start_pos": 116, "end_pos": 132, "type": "TASK", "confidence": 0.8788878917694092}]}, {"text": "Human judgements of thematic fit were needed for incorporation into this model.", "labels": [], "entities": []}, {"text": "solicited thematic fit ratings on a scale from 1 (least common) to 7 (most common) using \"How common is it fora {snake, nurse, monster, baby, cat} to frighten someone/something?\"", "labels": [], "entities": []}, {"text": "(for agents) and \"How common is it fora {snake, nurse, monster, baby, cat} to be verb role-filler agent patient accept friend 6.1 5.8 accept student 5 frightened by someone/something?\"", "labels": [], "entities": []}, {"text": "A small sample of scores from this dataset is given in.", "labels": [], "entities": []}, {"text": "Each (role-filler, verb, role) triple received ratings from 37 different participants.", "labels": [], "entities": []}, {"text": "The 37 ratings for each triple were averaged to generate a final thematic fit score.", "labels": [], "entities": []}, {"text": "The verbs were all transitive, thus allowing an agent rating and patient rating for each verb-noun pair.", "labels": [], "entities": []}, {"text": "As shown, many nouns were chosen such that they fit at least one role very well.", "labels": [], "entities": []}, {"text": "This meant that some verbroles in this dataset have no poorly-fitting rolefillers, e.g., patients of \"accept\" and \"agents of \"admire\".", "labels": [], "entities": []}, {"text": "This had strong ramifications for the \"difficulty\" of this dataset for correlation with automatic systems because extreme differences inhuman judgements are much easier to model than fine-grained ones.", "labels": [], "entities": []}, {"text": "MST98, a 200 item subset of the McRae et al.", "labels": [], "entities": [{"text": "MST98", "start_pos": 0, "end_pos": 5, "type": "DATASET", "confidence": 0.9212081432342529}, {"text": "McRae et al.", "start_pos": 32, "end_pos": 44, "type": "DATASET", "confidence": 0.9064044803380966}]}, {"text": "(1997) dataset created for, has two animate role-fillers for each verb.", "labels": [], "entities": []}, {"text": "The first was a good agent and a poor patient, and the other a poor agent and a good patient.", "labels": [], "entities": []}, {"text": "The ratings were still well-distributed, but these conditions made correlation with automatic systems easier.", "labels": [], "entities": [{"text": "correlation", "start_pos": 67, "end_pos": 78, "type": "TASK", "confidence": 0.9738448262214661}]}, {"text": "created a dataset of 248 instrument ratings (F-Inst) and a dataset of 274 location ratings (F-Loc) using questions of the form \"How common is it for someone to use each of the following to perform the action of stirring?\"", "labels": [], "entities": [{"text": "F-Inst", "start_pos": 45, "end_pos": 51, "type": "METRIC", "confidence": 0.887026309967041}]}, {"text": "(instruments) and \"How common is it for someone to skate in each of the following locations?\".", "labels": [], "entities": []}, {"text": "40 participants supplied ratings on a seven point scale.", "labels": [], "entities": []}, {"text": "Ken McRae, Michael Spivey-Knowlton, Maryellen MacDonald, Mike Tanenhaus, Neal Pearlmutter and Ulrike Pad\u00f3 compiled a master list of thematic fit judgements from,,, a replication of [Experiment B], and follow-up studies of [Experiment C].", "labels": [], "entities": []}, {"text": "These studies had slightly different requirements for the kinds of verbs and nouns used and significant overlap in stimuli due to collaboration.", "labels": [], "entities": []}, {"text": "This represents the largest to-date dataset of agent-patient thematic fit ratings (1,444 single-word verb/noun judgements), referenced herein as MSTNN.", "labels": [], "entities": [{"text": "MSTNN", "start_pos": 145, "end_pos": 150, "type": "DATASET", "confidence": 0.971362829208374}]}, {"text": "Pad\u00f3 created anew dataset of 414 agent and patient ratings (P07) to be included in a sentence processing model.", "labels": [], "entities": []}, {"text": "The verbs were chosen based on their frequencies in the Penn Treebank and FrameNet.", "labels": [], "entities": [{"text": "Penn Treebank", "start_pos": 56, "end_pos": 69, "type": "DATASET", "confidence": 0.9941687881946564}, {"text": "FrameNet", "start_pos": 74, "end_pos": 82, "type": "DATASET", "confidence": 0.5944482088088989}]}, {"text": "Role-fillers were selected to give a wide distribution of scores within each verb.", "labels": [], "entities": []}, {"text": "The final dataset contains fine-grained distinctions from FrameNet, which many systems map to familiar agent and patient roles.", "labels": [], "entities": []}, {"text": "Judgements were obtained on a seven point scale using questions of the form \"How common is it for an analyst to tell?\"", "labels": [], "entities": []}, {"text": "(subject) and \"How common is it for an analyst to be told?\"", "labels": [], "entities": []}, {"text": "Finally, Greenberg et al.", "labels": [], "entities": []}, {"text": "(2015a) created a dataset of 720 patient ratings (GDS-all) that were designed to be different from the others in two ways.", "labels": [], "entities": []}, {"text": "First, they changed the format of the judgement elicitation question, since they believed that asking how common/typical something is would lead the participants to consider frequency of occurrence rather than semantic plausibility.", "labels": [], "entities": []}, {"text": "Instead, they asked participants how much they agreed on a 1-7 scale with statements such as \"cream is something that is whipped\".", "labels": [], "entities": []}, {"text": "This dataset was constructed to vary word frequency and verb polysemy systematically; the experimental subset of the dataset contained frequency-matched monosemous verbs (GDS-mono) and polysemous verbs (GDS-poly).", "labels": [], "entities": []}, {"text": "Synonymous pairs of nouns (one frequent and one infrequent) were chosen to fit a frequent sense, an infrequent sense (for polysemous verbs only), or no senses per verb.", "labels": [], "entities": []}, {"text": "The dominant approach in recent work in thematic fit evaluation has been, given a verb/role/noun combination, to use the vector space to construct a prototype filler of the given role for the given verb, and then to compare the given noun to that prototype (.", "labels": [], "entities": [{"text": "thematic fit evaluation", "start_pos": 40, "end_pos": 63, "type": "TASK", "confidence": 0.8728309075037638}]}, {"text": "The prototype fillers are constructed by averaging some number of \"typical\" (e.g., most common by frequency or by some information statistic) role-fillers for that verb-the verb's vector is not itself directly used in the comparison.", "labels": [], "entities": []}, {"text": "Most recent work instead varies in the construction of the vector space and the use of the space to build the prototype.", "labels": [], "entities": []}, {"text": "The importance of the vector space A semantic model should recognize that cutting a cake with an improbable item like a sword is still highly plausible, even if cakes and swords rarely appear in the same genres or discourses; that is, it should recognize that swords and knives (more typically used to cut cakes) are both cutting-instruments, even if their typical genre contexts are different.", "labels": [], "entities": []}, {"text": "Because of their indirect relationship to probability, real-valued vector spaces have produced the most successful recent high-coverage models for the thematic fit judgement correlation task.", "labels": [], "entities": [{"text": "thematic fit judgement correlation task", "start_pos": 151, "end_pos": 190, "type": "TASK", "confidence": 0.6821539878845215}]}, {"text": "Even if cakes and swords may rarely appear in the same discourses, swords and knives sometimes may.", "labels": [], "entities": []}, {"text": "A robust vector space allows the representation of unseen indirect associations between these items.", "labels": [], "entities": []}, {"text": "In order to understand the progress made on the thematic fit question, we therefore look at a sample of recent attempts at exploring the feature space and the handling of the vector space as a whole.", "labels": [], "entities": []}, {"text": "Comparing recent results In table 2, we sample results from recent vector-space modeling efforts in the literature in order to understand the progress made.", "labels": [], "entities": []}, {"text": "The table contains: BL2010 Results from the TypeDM system of Baroni and.", "labels": [], "entities": [{"text": "BL2010", "start_pos": 20, "end_pos": 26, "type": "METRIC", "confidence": 0.932644248008728}, {"text": "TypeDM", "start_pos": 44, "end_pos": 50, "type": "TASK", "confidence": 0.8438834547996521}]}, {"text": "This space is constructed from counts of rule-selected dependency tree snippets taken from a large web crawl corpus, adjusted via local mutual information (LMI) but is otherwise unsupervised.", "labels": [], "entities": []}, {"text": "The approach they take generates a vector space above a 100 million dimensions.", "labels": [], "entities": []}, {"text": "The top 20 typical role-fillers by LMI are chosen for prototype construction.", "labels": [], "entities": [{"text": "LMI", "start_pos": 35, "end_pos": 38, "type": "DATASET", "confidence": 0.8004273176193237}]}, {"text": "Some of the datasets presented were only created and tested later by", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Sample of McRae et al. (1997) ratings.", "labels": [], "entities": [{"text": "Sample", "start_pos": 10, "end_pos": 16, "type": "METRIC", "confidence": 0.8690391182899475}, {"text": "McRae et al. (1997) ratings", "start_pos": 20, "end_pos": 47, "type": "DATASET", "confidence": 0.9162097498774529}]}, {"text": " Table 2: Spearman's \u03c1 values (\u00d7100) for different datasets with results collected from different evalua- tion attempts. All models evaluated have coverage higher than 95% over all datasets.", "labels": [], "entities": [{"text": "coverage", "start_pos": 147, "end_pos": 155, "type": "METRIC", "confidence": 0.9552372694015503}]}]}