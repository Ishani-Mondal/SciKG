{"title": [{"text": "German NER with a Multilingual Rule Based Information Extraction System: Analysis and Issues", "labels": [], "entities": [{"text": "German NER", "start_pos": 0, "end_pos": 10, "type": "DATASET", "confidence": 0.85085329413414}, {"text": "Multilingual Rule Based Information Extraction", "start_pos": 18, "end_pos": 64, "type": "TASK", "confidence": 0.6385124504566193}]}], "abstractContent": [{"text": "This paper presents a rule-based approach to Named Entity Recognition for the Ger-man language.", "labels": [], "entities": [{"text": "Named Entity Recognition", "start_pos": 45, "end_pos": 69, "type": "TASK", "confidence": 0.8803869088490804}]}, {"text": "The approach rests upon deep linguistic parsing and has already been applied to English and Russian.", "labels": [], "entities": [{"text": "linguistic parsing", "start_pos": 29, "end_pos": 47, "type": "TASK", "confidence": 0.745314210653305}]}, {"text": "In this paper we present the first results of our system, ABBYY InfoExtractor, on Ger-mEval 2014 Shared Task corpus.", "labels": [], "entities": [{"text": "ABBYY", "start_pos": 58, "end_pos": 63, "type": "DATASET", "confidence": 0.559783399105072}, {"text": "Ger-mEval 2014 Shared Task corpus", "start_pos": 82, "end_pos": 115, "type": "DATASET", "confidence": 0.8838255167007446}]}, {"text": "We focus on the main challenges of German NER that we have encountered when adapting our system to German and possible solutions for them.", "labels": [], "entities": [{"text": "German NER", "start_pos": 35, "end_pos": 45, "type": "DATASET", "confidence": 0.6697823405265808}]}], "introductionContent": [{"text": "Named Entity Recognition (NER), which is a subtask of information extraction, is a well-studied, yet challenging task.", "labels": [], "entities": [{"text": "Named Entity Recognition (NER)", "start_pos": 0, "end_pos": 30, "type": "TASK", "confidence": 0.7962744683027267}, {"text": "information extraction", "start_pos": 54, "end_pos": 76, "type": "TASK", "confidence": 0.7727221548557281}]}, {"text": "Various competitions have been held to evaluate quality of named entity recognition for different languages.", "labels": [], "entities": [{"text": "named entity recognition", "start_pos": 59, "end_pos": 83, "type": "TASK", "confidence": 0.6979215145111084}]}, {"text": "German is no exception: there have already been two evaluation tracks for German, and).", "labels": [], "entities": []}, {"text": "The best results reported for the tracks are 72.41% and 76.38% respectively, which is still considerably below the results for English.", "labels": [], "entities": []}, {"text": "One of the observed reasons is that noun capitalization in German differs considerably from that in English.", "labels": [], "entities": [{"text": "noun capitalization", "start_pos": 36, "end_pos": 55, "type": "TASK", "confidence": 0.7506214380264282}]}, {"text": "Another reason is the smaller number of gazetteers and other linguistic resources available for German.", "labels": [], "entities": []}, {"text": "In this paper we present an overview of our approach to Named Entity Recognition and discuss the issues that we have observed while adapting our information extraction system to German.", "labels": [], "entities": [{"text": "Named Entity Recognition", "start_pos": 56, "end_pos": 80, "type": "TASK", "confidence": 0.8650384545326233}, {"text": "information extraction", "start_pos": 145, "end_pos": 167, "type": "TASK", "confidence": 0.7776252031326294}]}, {"text": "ABBYY InfoExtractor has already been applied to English and Russian.", "labels": [], "entities": [{"text": "ABBYY InfoExtractor", "start_pos": 0, "end_pos": 19, "type": "DATASET", "confidence": 0.6402656435966492}]}, {"text": "We evaluated our named entity recognition system for English on MUC-6 corpus and achieved the F-measure of approximately 83% with no prior adjustments.", "labels": [], "entities": [{"text": "named entity recognition", "start_pos": 17, "end_pos": 41, "type": "TASK", "confidence": 0.6695985198020935}, {"text": "MUC-6 corpus", "start_pos": 64, "end_pos": 76, "type": "DATASET", "confidence": 0.9863222539424896}, {"text": "F-measure", "start_pos": 94, "end_pos": 103, "type": "METRIC", "confidence": 0.9994494318962097}]}, {"text": "We performed this evaluation ourselves.", "labels": [], "entities": []}, {"text": "As for the Russian language, we took part in FactRuEval 2016 competition and showed the best results in the Russian Named Entity Recognition Track with the F-measure of 86.7% (.", "labels": [], "entities": [{"text": "FactRuEval 2016 competition", "start_pos": 45, "end_pos": 72, "type": "DATASET", "confidence": 0.8759975632031759}, {"text": "Russian Named Entity Recognition", "start_pos": 108, "end_pos": 140, "type": "TASK", "confidence": 0.49115417152643204}, {"text": "F-measure", "start_pos": 156, "end_pos": 165, "type": "METRIC", "confidence": 0.9994503855705261}]}, {"text": "The paper is structured as follows.", "labels": [], "entities": []}, {"text": "In Section 2 we review some of the previous works in the field of German NER.", "labels": [], "entities": [{"text": "German NER", "start_pos": 66, "end_pos": 76, "type": "TASK", "confidence": 0.6020370423793793}]}, {"text": "In Section 3 an outline of the system architecture is given.", "labels": [], "entities": []}, {"text": "In Section 4 we discuss the issues that we have faced in German NER and comment on them.", "labels": [], "entities": [{"text": "German NER", "start_pos": 57, "end_pos": 67, "type": "DATASET", "confidence": 0.8631250858306885}]}, {"text": "In Section 5 we present performance of our system on GermEval 2014 corpus.", "labels": [], "entities": [{"text": "GermEval 2014 corpus", "start_pos": 53, "end_pos": 73, "type": "DATASET", "confidence": 0.9501649339993795}]}, {"text": "Section 6 provides conclusion and discussion of our future work.", "labels": [], "entities": []}], "datasetContent": [{"text": "Precision (%) Recall (%) FB1 (%) 45.", "labels": [], "entities": [{"text": "Precision", "start_pos": 0, "end_pos": 9, "type": "METRIC", "confidence": 0.981684148311615}, {"text": "Recall", "start_pos": 14, "end_pos": 20, "type": "METRIC", "confidence": 0.9884871244430542}, {"text": "FB1", "start_pos": 25, "end_pos": 28, "type": "METRIC", "confidence": 0.9708867073059082}]}, {"text": "44.87 45.04: Overall results.", "labels": [], "entities": []}, {"text": "Strict metric We have tested our system on GermEval 2014 corpus using the evaluation script provided by the organizers.", "labels": [], "entities": [{"text": "GermEval 2014 corpus", "start_pos": 43, "end_pos": 63, "type": "DATASET", "confidence": 0.9489455421765646}]}, {"text": "Overall results of strict evaluation are presented in, 4, 5.", "labels": [], "entities": []}, {"text": "Predictably, extraction of organizations has turned out to be the most challenging task for us, due to the parsing problems mentioned above.", "labels": [], "entities": [{"text": "parsing", "start_pos": 107, "end_pos": 114, "type": "TASK", "confidence": 0.9670705795288086}]}, {"text": "We hope that the implementation of changes to the parser suggested in Section 4 will improve the quality of parse trees and entity extraction.", "labels": [], "entities": [{"text": "entity extraction", "start_pos": 124, "end_pos": 141, "type": "TASK", "confidence": 0.7644595205783844}]}, {"text": "Enrichment of Organization gazetteer is also likely to help.", "labels": [], "entities": []}, {"text": "The results of \"Person\" type extraction are quite unexpected, first of all, because recall-better-thanprecision pattern is not typical for us.", "labels": [], "entities": [{"text": "Person\" type extraction", "start_pos": 16, "end_pos": 39, "type": "TASK", "confidence": 0.5146481841802597}, {"text": "recall-better-thanprecision pattern", "start_pos": 84, "end_pos": 119, "type": "METRIC", "confidence": 0.9613721966743469}]}, {"text": "These results require further analysis, which is beyond the scope of this paper.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Results for PER (in %)", "labels": [], "entities": [{"text": "PER", "start_pos": 22, "end_pos": 25, "type": "METRIC", "confidence": 0.9140533208847046}]}, {"text": " Table 3: Results for LOC (in %)", "labels": [], "entities": [{"text": "LOC", "start_pos": 22, "end_pos": 25, "type": "METRIC", "confidence": 0.629034698009491}]}, {"text": " Table 4: Results for ORG (in %)", "labels": [], "entities": [{"text": "ORG", "start_pos": 22, "end_pos": 25, "type": "METRIC", "confidence": 0.9914918541908264}]}, {"text": " Table 5: Results for OTH (in %)", "labels": [], "entities": [{"text": "OTH", "start_pos": 22, "end_pos": 25, "type": "METRIC", "confidence": 0.5440483093261719}]}]}