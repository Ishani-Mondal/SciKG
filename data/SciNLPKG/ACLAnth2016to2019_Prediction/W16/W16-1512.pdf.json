{"title": [{"text": "Lexical and Syntactic cues to identify Reference Scope of Citance", "labels": [], "entities": []}], "abstractContent": [{"text": "In this paper, we present our system addressing Task 1 of CL-SciSumm Shared Task at BIRNDL 2016.", "labels": [], "entities": [{"text": "BIRNDL 2016", "start_pos": 84, "end_pos": 95, "type": "DATASET", "confidence": 0.7980648875236511}]}, {"text": "Our system makes use of lexical and syntactic dependency cues, and applies rule-based approach to extract text spans in the Reference Paper that accurately reflect the citances.", "labels": [], "entities": []}, {"text": "Further, we make use of lexical cues to identify discourse facets of the paper to which cited text belongs.", "labels": [], "entities": []}, {"text": "The lexical and syntactic cues are obtained on pre-processed text of the ci-tances, and the reference paper.", "labels": [], "entities": []}, {"text": "We report our results obtained for development set using our system for identifying reference scope of citances in this paper.", "labels": [], "entities": []}, {"text": "1 Introduction The scientific research community needs different viewpoints of research contributions in summarized form.", "labels": [], "entities": []}, {"text": "Abstract of the research contribution presents summary from the author(s) perspective.", "labels": [], "entities": []}, {"text": "Citations of a reference paper reflect the viewpoint of the citing authors for that reference paper, and possibly in a certain context only.", "labels": [], "entities": []}, {"text": "Summary drawn fora reference paper from its citations can put forward a different and interesting context of that reference paper.", "labels": [], "entities": []}, {"text": "There have been several efforts towards extracting reference scope of citances, and such citations-based summary in recent years like [1], [2] etc.", "labels": [], "entities": []}, {"text": "[3] have shown through their Computational Linguistics Summarization (CL-Summ) Pilot task that citation based summary of scientific documentation is important to create for understanding different perspectives of a reference paper.", "labels": [], "entities": [{"text": "Computational Linguistics Summarization (CL-Summ)", "start_pos": 29, "end_pos": 78, "type": "TASK", "confidence": 0.7431946247816086}]}, {"text": "Further to that pilot task, Computational Linguistics Scientific Document Summarization (CL-SciSumm-2016 1) shared task has been designed with the goal of exploring automated summarization of scientific contributions for the computational linguistics research domain.", "labels": [], "entities": [{"text": "Computational Linguistics Scientific Document Summarization", "start_pos": 28, "end_pos": 87, "type": "TASK", "confidence": 0.6698500990867615}, {"text": "summarization of scientific contributions", "start_pos": 175, "end_pos": 216, "type": "TASK", "confidence": 0.8442555963993073}]}], "introductionContent": [{"text": "The scientific research community needs different viewpoints of research contributions in summarized form.", "labels": [], "entities": []}, {"text": "Abstract of the research contribution presents summary from the author(s) perspective.", "labels": [], "entities": []}, {"text": "Citations of a reference paper reflect the viewpoint of the citing authors for that reference paper, and possibly in a certain context only.", "labels": [], "entities": []}, {"text": "Summary drawn fora reference paper from its citations can put forward a different and interesting context of that reference paper.", "labels": [], "entities": []}, {"text": "There have been several efforts towards extracting reference scope of citances, and such citations-based summary in recent years like, etc.", "labels": [], "entities": []}, {"text": "Kokil et al. have shown through their Computational Linguistics Summarization (CL-Summ) Pilot task that citation based summary of scientific documentation is important to create for understanding different perspectives of a reference paper.", "labels": [], "entities": [{"text": "Computational Linguistics Summarization (CL-Summ)", "start_pos": 38, "end_pos": 87, "type": "TASK", "confidence": 0.7366798470417658}]}, {"text": "Further to that pilot task, Computational Linguistics Scientific Document Summarization (CL-SciSumm-2016 1 ) shared task has been designed with the goal of exploring automated summarization of scientific contributions for the computational linguistics research domain.", "labels": [], "entities": [{"text": "Computational Linguistics Scientific Document Summarization", "start_pos": 28, "end_pos": 87, "type": "TASK", "confidence": 0.6698498785495758}, {"text": "summarization of scientific contributions", "start_pos": 176, "end_pos": 217, "type": "TASK", "confidence": 0.8442555963993073}]}, {"text": "The organizers of CL-SciSumm shared task have divided the task into two parts: (1) For each citance, identify the spans of text (cited text spans) in the Reference Paper (RP) that most accurately reflect the citance, and identify the facet of the paper it belongs to; (2) Generate a structured summary of the RP from the cited text spans of the RP.", "labels": [], "entities": []}, {"text": "However, task-1 is required to create citations-based summary of the RP.", "labels": [], "entities": []}, {"text": "This makes task-1 crucial and important step in creating citations-based summary of any scientific document.", "labels": [], "entities": []}, {"text": "The corpus of CL-SciSumm shared task has been created by sampling documents from ACL Anthology corpus and selecting their citing papers.", "labels": [], "entities": [{"text": "ACL Anthology corpus", "start_pos": 81, "end_pos": 101, "type": "DATASET", "confidence": 0.9375906785329183}]}, {"text": "We have worked on task-1 ('a' and 'b') to develop our system for identifying the reference scope of the citance in the RP.", "labels": [], "entities": []}, {"text": "We present the details of our system in Section -2 below.", "labels": [], "entities": []}, {"text": "This is followed by evaluation of our system, as presented in section 3, and observations in section 4.", "labels": [], "entities": []}, {"text": "We finally present concluding remarks in Section 5.", "labels": [], "entities": []}], "datasetContent": [{"text": "We have computed ROUGE-N metric with 'N' as 2 for bi-grams to evaluate our system.", "labels": [], "entities": [{"text": "ROUGE-N metric", "start_pos": 17, "end_pos": 31, "type": "METRIC", "confidence": 0.9687921404838562}]}, {"text": "below presents the average results for identifying reference scope (task -1a) for each topic in the development set, and an average overall performance of the system for the development set for task -1a: For task 1b, we have computed accuracy of reporting discourse facet of the paper as the ratio of correctly identified facets in an annotation file fora topic and the total number of citances for that topic.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 234, "end_pos": 242, "type": "METRIC", "confidence": 0.9992672801017761}]}, {"text": "presents the discourse-facet accuracy corresponding to the development set:", "labels": [], "entities": [{"text": "accuracy", "start_pos": 29, "end_pos": 37, "type": "METRIC", "confidence": 0.8573561310768127}]}], "tableCaptions": [{"text": " Table 1. Task 1a performance in terms of ROUGE-N for development set", "labels": [], "entities": [{"text": "ROUGE-N", "start_pos": 42, "end_pos": 49, "type": "METRIC", "confidence": 0.9855925440788269}]}, {"text": " Table 2. Discourse Facet Accuracy for development set", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 26, "end_pos": 34, "type": "METRIC", "confidence": 0.9836002588272095}]}]}