{"title": [{"text": "Providing and Analyzing NLP Terms for our Community", "labels": [], "entities": [{"text": "Analyzing NLP Terms", "start_pos": 14, "end_pos": 33, "type": "TASK", "confidence": 0.6573023498058319}]}], "abstractContent": [{"text": "By its own nature, the Natural Language Processing (NLP) community is a priori the best equipped to study the evolution of its own publications, but works in this direction are rare and only recently have we seen a few attempts at charting the field.", "labels": [], "entities": []}, {"text": "In this paper, we use the algorithms , resources, standards, tools and common practices of the NLP field to build a list of terms characteristic of ongoing research, by mining a large corpus of scientific publications, aiming at the largest possible exhaustivity and covering the largest possible time span.", "labels": [], "entities": []}, {"text": "Study of the evolution of this term list through time reveals interesting insights on the dynamics of field and the availability of the term database and of the corpus (for a large part) make possible many further comparative studies in addition to providing a test field fora new graphic interface designed to perform visual time analytics of large sized thesauri.", "labels": [], "entities": []}], "introductionContent": [{"text": "In the NLP community, we have tools, algorithms, resources, standards and common practices, but do we have a good knowledge of the terms that we use?", "labels": [], "entities": []}, {"text": "The work we present here is an attempt at improving the situation.", "labels": [], "entities": []}, {"text": "Our corpus contains articles from NLP conferences and journals about written, spoken and fora relatively small part, signed language processing, which is to our knowledge the largest ever collected in our field.", "labels": [], "entities": [{"text": "signed language processing", "start_pos": 117, "end_pos": 143, "type": "TASK", "confidence": 0.679839551448822}]}, {"text": "It covers a time period from 1965 to 2015 and holds approximately 65,000 papers.", "labels": [], "entities": []}, {"text": "Using OCR and PDF converters, we extracted the textual content of the documents and linked it into a database with cleaned metadata about the associated events.", "labels": [], "entities": []}, {"text": "After an NLP analysis of the content by means of lemmatizing, syntactic parsing, Named Entity recognition and various semantic lexical filtering with both large sized general language resources and some domain related ones, we produced a database of community specific terms which was manually checked.", "labels": [], "entities": [{"text": "syntactic parsing", "start_pos": 62, "end_pos": 79, "type": "TASK", "confidence": 0.7494220435619354}, {"text": "Named Entity recognition", "start_pos": 81, "end_pos": 105, "type": "TASK", "confidence": 0.5950230360031128}]}, {"text": "The result is a collection of terms annotated with various attributes like document-authors first appearance, alternative forms, occurrence statistics along different dimensions, including time, conferences etc.", "labels": [], "entities": []}, {"text": "which is made available to the community along with the public part of the corpus for further comparative studies and enhancements.", "labels": [], "entities": []}, {"text": "In the next two sections, we present related works and our corpus.", "labels": [], "entities": []}, {"text": "Then we describe in detail the preprocessing applied to the corpus and the term extraction process.", "labels": [], "entities": []}, {"text": "With the resulting term database, we present a study about \"creation\" (first appearance of a term in the corpus) and \"impact\" (relative dominance of a term in the last year of the time period covered by the corpus), introducing on this occasion a dedicated graphic interface designed for visual time analytics of large sized thesauri.", "labels": [], "entities": []}, {"text": "Before concluding, we provide some interesting insights on the global dynamics of our field, revealed by the evolution of a few characteristic terms.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 3: Basic results: the 10 most frequent terms over 1965-2015.", "labels": [], "entities": []}, {"text": " Table 4: Terms with highest impacts.", "labels": [], "entities": [{"text": "Terms", "start_pos": 10, "end_pos": 15, "type": "TASK", "confidence": 0.9508025050163269}]}]}