{"title": [{"text": "The CogALex-V Shared Task on the Corpus-Based Identification of Semantic Relations", "labels": [], "entities": [{"text": "Corpus-Based Identification of Semantic Relations", "start_pos": 33, "end_pos": 82, "type": "TASK", "confidence": 0.7667260110378266}]}], "abstractContent": [{"text": "The shared task of the 5th Workshop on Cognitive Aspects of the Lexicon (CogALex-V) aims at providing a common benchmark for testing current corpus-based methods for the identification of lexical semantic relations (synonymy, antonymy, hypernymy, part-whole meronymy) and at gaining a better understanding of their respective strengths and weaknesses.", "labels": [], "entities": [{"text": "identification of lexical semantic relations", "start_pos": 170, "end_pos": 214, "type": "TASK", "confidence": 0.8398943185806275}]}, {"text": "The shared task uses a challenging dataset extracted from EVALution 1.0 (Santus et al., 2015b), which contains word pairs holding the above-mentioned relations as well as semantically unrelated control items (random).", "labels": [], "entities": []}, {"text": "The task is split into two subtasks: (i) identification of related word pairs vs. unrelated ones; (ii) classification of the word pairs according to their semantic relation.", "labels": [], "entities": [{"text": "identification of related word pairs", "start_pos": 41, "end_pos": 77, "type": "TASK", "confidence": 0.8382722973823548}]}, {"text": "This paper describes the subtasks, the dataset, the evaluation metrics, the seven participating systems and their results.", "labels": [], "entities": []}, {"text": "The best performing system in subtask 1 is GHHH (F 1 = 0.790), while the best system in subtask 2 is LexNet (F 1 = 0.445).", "labels": [], "entities": [{"text": "GHHH", "start_pos": 43, "end_pos": 47, "type": "METRIC", "confidence": 0.6104442477226257}, {"text": "F 1", "start_pos": 49, "end_pos": 52, "type": "METRIC", "confidence": 0.9268824756145477}, {"text": "LexNet", "start_pos": 101, "end_pos": 107, "type": "DATASET", "confidence": 0.975335955619812}]}, {"text": "The dataset and the task description are available at https://sites.google.com/site/cogalex2016/home/shared-task.", "labels": [], "entities": []}], "introductionContent": [{"text": "Determining automatically if words are semantically related, and in what way, is important for Natural Language Processing (NLP) applications such as thesaurus generation, ontology learning, paraphrase generation and identification, as well as for drawing inferences.", "labels": [], "entities": [{"text": "thesaurus generation", "start_pos": 150, "end_pos": 170, "type": "TASK", "confidence": 0.7814899981021881}, {"text": "paraphrase generation and identification", "start_pos": 191, "end_pos": 231, "type": "TASK", "confidence": 0.7606902420520782}]}, {"text": "Many NLP applications make use of handcrafted resources such as WordNet.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 64, "end_pos": 71, "type": "DATASET", "confidence": 0.9604251980781555}]}, {"text": "However, creating these resources is expensive and time-consuming; they are available for only a few languages, and their coverage inevitably lags behind the lexical and conceptual proliferation.", "labels": [], "entities": []}, {"text": "In the last decades, a number of corpus-based approaches have investigated the possibility of identifying lexical semantic relations by observing word usage.", "labels": [], "entities": [{"text": "identifying lexical semantic relations", "start_pos": 94, "end_pos": 132, "type": "TASK", "confidence": 0.7839933484792709}]}, {"text": "Even though these methods are still far from being able to provide a comprehensive model of how semantic relations work, pattern-based and distributional approaches (both supervised or unsupervised) have confirmed the existence of a strong connection between word meaning and word distribution.", "labels": [], "entities": []}, {"text": "The practical utility of this finding matches its theoretical significance.", "labels": [], "entities": []}, {"text": "The connection between word meanings and their usage is gaining prominence in theories of the mental lexicon) and language acquisition.", "labels": [], "entities": [{"text": "language acquisition", "start_pos": 114, "end_pos": 134, "type": "TASK", "confidence": 0.7514749765396118}]}, {"text": "The status of distributional semantics vis-` a-vis linguistics and cognitive science) depends on making progress in this area.", "labels": [], "entities": []}, {"text": "To further assess and explore how much we can learn about semantic relations from word distribution, we propose a shared task as part of the 5th Workshop on Cognitive Aspects of the Lexicon (CogALex-V), co-located with COLING 2016 in Osaka, Japan.", "labels": [], "entities": []}, {"text": "The CogALex-V shared task is intended to provide a common benchmark for testing current corpusbased methods for the identification of lexical semantic relations in order to gain a better understanding of their respective strengths and weaknesses.", "labels": [], "entities": [{"text": "identification of lexical semantic relations", "start_pos": 116, "end_pos": 160, "type": "TASK", "confidence": 0.7901557207107544}]}, {"text": "It is articulated into two subtasks: (i) identification of semantically related word pairs vs. unrelated ones; (ii) classification of the word pairs according to their semantic relation.", "labels": [], "entities": [{"text": "identification of semantically related word pairs", "start_pos": 41, "end_pos": 90, "type": "TASK", "confidence": 0.8257196048895518}]}, {"text": "Participants were provided with training and test datasets extracted from EVALution 1.0 (, as well as a scoring script for evaluating the output of their systems.", "labels": [], "entities": [{"text": "EVALution 1.0", "start_pos": 74, "end_pos": 87, "type": "DATASET", "confidence": 0.8628844022750854}]}, {"text": "The shared task has been intended and designed as a \"friendly competition\": the goal was to identify strengths and weaknesses of various methods, rather than just \"crowning\" the best-performing model.", "labels": [], "entities": []}, {"text": "In total, seven systems participated in the shared task.", "labels": [], "entities": []}, {"text": "Most of them exploited Distributional Semantic Models (DSMs), either of the count-based or word-embedding type ().", "labels": [], "entities": []}, {"text": "Most of them relied on distance or nearest neighbors in subtask 1, and on machine learning classifiers (e.g., Support Vector Machine (SVM), Convolutional Neural Network (CNN) and Random Forest (RF)) in subtask 2.", "labels": [], "entities": []}, {"text": "Some systems enriched the DSM representation by adopting patterns (e.g., LexNet, the best system in subtask 2) or extracting distributional properties with unsupervised measures (e.g., ROOT18).", "labels": [], "entities": [{"text": "LexNet", "start_pos": 73, "end_pos": 79, "type": "DATASET", "confidence": 0.9730916023254395}]}, {"text": "This paper reports the results achieved by the participating systems, providing insights about their respective strengths and weaknesses.", "labels": [], "entities": []}, {"text": "It is organized as follows.", "labels": [], "entities": []}, {"text": "Section 2 surveys similar shared tasks and provides an overview of existing methods for identifying lexical semantic relations.", "labels": [], "entities": [{"text": "identifying lexical semantic relations", "start_pos": 88, "end_pos": 126, "type": "TASK", "confidence": 0.7276512086391449}]}, {"text": "Section 3 introduces the task, the datasets, and the participating systems (each of them described in detail in a separate paper included in the workshop proceedings).", "labels": [], "entities": []}, {"text": "1 Section 4 lists the performance of the participating systems, analyzing it from several perspectives.", "labels": [], "entities": []}, {"text": "Section 5 summarizes the findings, highlights the contribution of the shared task and suggests a few directions for future research.", "labels": [], "entities": []}], "datasetContent": [{"text": "The training and test datasets were constructed on the basis of EVALution 1.0 (Santus et al., 2015b), a dataset for evaluating distributional semantic models that was derived from WordNet 4.0 and ConceptNet 5.0 (), and then refined through automatic filters and crowdsourcing.", "labels": [], "entities": []}, {"text": "EVALution 1.0 includes various parts of speech, both single words and multi-word units (e.g., grow up).", "labels": [], "entities": []}, {"text": "2 Words have been stemmed (e.g. feeling appears as feel).", "labels": [], "entities": []}, {"text": "This increases ambiguity in the dataset, but it is also consistent with the fact that semantic relations between lexical items are typically independent from their morphosyntactic realization (e.g. the hypernymic pair anger -feel now represents morphological variants such as anger -feeling and anger -to feel).", "labels": [], "entities": []}, {"text": "After being extracted from WordNet or ConceptNet, the pairs (e.g. sweet SYN candy) were evaluated by CrowdFlower workers in order to obtain native speaker judgments, which can be used as a proxy for the prototypicality of the relations.", "labels": [], "entities": []}, {"text": "The crowdsourcing task was to rate the truthfulness of sentences generated from the word pairs (according to the templates presented in table 1) on a scale from 1 to 5, where 1=completely disagree and 5=completely agree.", "labels": [], "entities": []}, {"text": "Five judgments were collected for each sentence.", "labels": [], "entities": []}, {"text": "The CrowdFlower workers also tagged the general domains in which the relata were found more appropriate, such as \"nature\", \"culture\" or \"emotion\".", "labels": [], "entities": []}, {"text": "Unfortunately the reliability of these tags is fairly low, as some workers applied them randomly.", "labels": [], "entities": [{"text": "reliability", "start_pos": 18, "end_pos": 29, "type": "METRIC", "confidence": 0.9965358972549438}]}, {"text": "We can therefore consider trustworthy only tags that were selected by a high number of voters.", "labels": [], "entities": []}, {"text": "In addition to domains, EVALution contains other metadata, either concerning the pairs (e.g., from which resource the pair is inherited) or the single words (e.g., word frequency, capitalization distribution, morphological distribution, part-of-speech distribution, etc.).", "labels": [], "entities": []}, {"text": "This metadata can be used for subsequent analysis of the performance of the systems.", "labels": [], "entities": []}, {"text": "For this shared task, we extracted a subset of EVALution 1.0 that covers 747 target words (318 in the training set and 429 in the test set) with at least one of the following relata: synonym, antonym, hypernym and part-whole meronym; only pairs with average rating \u2265 4 were considered.", "labels": [], "entities": []}, {"text": "In order to increase the difficulty of the identification task, for every target word we generated several random pairs by switching: Semantic relations in the shared task dataset the relata.", "labels": [], "entities": []}, {"text": "These pairs -approximately three times as many as related pairs -are intended to act as noise for the models.", "labels": [], "entities": []}, {"text": "They may contain associated words (e.g. coffee -cup, brick -build), but pairs accidentally holding any of the four semantic relations above were filtered out manually.", "labels": [], "entities": []}, {"text": "The dataset is particularly challenging for several reasons.", "labels": [], "entities": []}, {"text": "First, it does not provide part-of-speech information for the words in the pairs, leaving the participant systems with the burden of disambiguation (e.g. fire -shoot are synonyms only when both are interpreted as verbs).", "labels": [], "entities": []}, {"text": "Second, several words were interpreted in a specific meaning that does not always correspond to the dominant sense (e.g. compact -car, where compact is a noun referring to a specific kind of car).", "labels": [], "entities": []}, {"text": "Third, it combines relations inherited from a lexical resource like WordNet with relations that were obtained by crowdsourcing and pattern-based extraction (in ConceptNet), making their definitions less consistent.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 68, "end_pos": 75, "type": "DATASET", "confidence": 0.9409484267234802}]}, {"text": "Fourth, the terms in EVALution are stemmed, thereby denying systems the possibility of using morphological clues as features for the classification.", "labels": [], "entities": [{"text": "EVALution", "start_pos": 21, "end_pos": 30, "type": "DATASET", "confidence": 0.7180754542350769}]}, {"text": "Finding semantic relations between morphologically heterogeneous words is an additional challenge, but it is very likely that NLP applications (e.g. those for paraphrase generation and entailment verification) would benefit from the ability to focus on semantics while ignoring morphological differences.", "labels": [], "entities": [{"text": "paraphrase generation", "start_pos": 159, "end_pos": 180, "type": "TASK", "confidence": 0.8603004813194275}, {"text": "entailment verification", "start_pos": 185, "end_pos": 208, "type": "TASK", "confidence": 0.7305075228214264}]}, {"text": "These difficulties sometimes appear together, e.g. in the hypernymic pair stablebuild, where stable is used in the sense of \"a building with stalls where horses, cattle, etc., are kept and fed\" 5 and build is the stemmed form of building.", "labels": [], "entities": []}, {"text": "The participants were provided with a Python script for the evaluation.", "labels": [], "entities": []}, {"text": "Given the gold standard and a system output file as input, it calculated precision, recall and their harmonic mean F 1 for related pairs (in subtask 1) or semantic relations (in subtask 2), ignoring the unrelated pairs.", "labels": [], "entities": [{"text": "precision", "start_pos": 73, "end_pos": 82, "type": "METRIC", "confidence": 0.9995632767677307}, {"text": "recall", "start_pos": 84, "end_pos": 90, "type": "METRIC", "confidence": 0.999582827091217}, {"text": "harmonic mean F 1", "start_pos": 101, "end_pos": 118, "type": "METRIC", "confidence": 0.7068775445222855}]}, {"text": "In subtask 2, for example, scores were computed for synonymy (SYN), antonymy (ANT), hypernymy (HYPER) and partwhole meronymy (PART OF); the overall ranking of the systems was based on their weighted average.", "labels": [], "entities": [{"text": "partwhole meronymy (PART OF)", "start_pos": 106, "end_pos": 134, "type": "METRIC", "confidence": 0.6265449672937393}]}, {"text": "The script requires that the gold standard and the output file contain exactly the same pairs, in the same order, and using the same annotation labels.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Semantic relations in the shared task dataset", "labels": [], "entities": []}, {"text": " Table 2: Description of the participating systems", "labels": [], "entities": []}, {"text": " Table 3: Participating systems ranked by their F 1 scores in subtask 1 (left) and subtask 2 (right)", "labels": [], "entities": [{"text": "F 1 scores", "start_pos": 48, "end_pos": 58, "type": "METRIC", "confidence": 0.9627745151519775}]}]}