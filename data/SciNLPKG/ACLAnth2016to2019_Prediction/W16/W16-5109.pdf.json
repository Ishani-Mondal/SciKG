{"title": [{"text": "Supervised classification of end-of-lines in clinical text with no manual annotation", "labels": [], "entities": [{"text": "Supervised classification", "start_pos": 0, "end_pos": 25, "type": "TASK", "confidence": 0.6183106601238251}]}], "abstractContent": [{"text": "In some plain text documents, end-of-line marks mayor may not mark the boundary of a text unit (e.g., of a paragraph).", "labels": [], "entities": []}, {"text": "This vexing problem is likely to impact subsequent natural language processing components, but is seldom addressed in the literature.", "labels": [], "entities": []}, {"text": "We propose a method which uses no manual annotation to classify whether end-of-lines must actually be seen as simple spaces (soft line breaks) or as true text unit boundaries.", "labels": [], "entities": []}, {"text": "This method, which includes self-training and co-training steps based on token and line length features, achieves 0.943 F-measure on a corpus of short e-books with controlled format, F=0.904 on a random sample of 24 clinical texts with soft line breaks, and F=0.898 on a larger set of mixed clinical texts which mayor may not contain soft line breaks, a fairly high value fora method with no manual annotation.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 120, "end_pos": 129, "type": "METRIC", "confidence": 0.9977487921714783}, {"text": "F", "start_pos": 183, "end_pos": 184, "type": "METRIC", "confidence": 0.9988560676574707}, {"text": "F", "start_pos": 258, "end_pos": 259, "type": "METRIC", "confidence": 0.9990339279174805}]}], "introductionContent": [{"text": "Text segmentation is a low-level task which contributes to the higher-level information extraction tasks performed by natural language processing; for instance, Smith (2011, p.", "labels": [], "entities": [{"text": "Text segmentation", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.7385950237512589}, {"text": "information extraction", "start_pos": 76, "end_pos": 98, "type": "TASK", "confidence": 0.754429817199707}]}, {"text": "5) states that \"If we build a language model on poorly segmented text, for instance, its predictive performance will suffer.\"", "labels": [], "entities": []}, {"text": "Specifically, splitting a text into sentences, despite its looking like a largely solved problem, continues to raise nagging issues for some ill-formatted texts such as clinical texts.", "labels": [], "entities": []}, {"text": "Most methods and software performing higher-level tasks (e.g., cTAKES) and others), such as part-ofspeech tagging, syntactic parsing, entity and relation extraction, depend on low-level processes such as sentence segmentation.", "labels": [], "entities": [{"text": "part-ofspeech tagging", "start_pos": 92, "end_pos": 113, "type": "TASK", "confidence": 0.7420656979084015}, {"text": "syntactic parsing", "start_pos": 115, "end_pos": 132, "type": "TASK", "confidence": 0.7048690170049667}, {"text": "entity and relation extraction", "start_pos": 134, "end_pos": 164, "type": "TASK", "confidence": 0.5755004212260246}, {"text": "sentence segmentation", "start_pos": 204, "end_pos": 225, "type": "TASK", "confidence": 0.7208323180675507}]}, {"text": "This paper focuses on a little-addressed, basic component in the NLP pipeline, which impacts sentence splitting and hence subsequent processes.", "labels": [], "entities": [{"text": "sentence splitting", "start_pos": 93, "end_pos": 111, "type": "TASK", "confidence": 0.7483921647071838}]}, {"text": "This component maybe seen as the determination of paragraph boundaries, or the classification of end-of-lines.", "labels": [], "entities": []}, {"text": "The problem can be described as follows.", "labels": [], "entities": []}, {"text": "In some plain text documents, such as e-mail messages, text fields in databases, or PDF documents converted into text, the line break or end-of-line mark mayor not play the role of a boundary marker fora text unit (a title, a paragraph, etc.) and hence mayor not mark a sentence boundary.", "labels": [], "entities": []}, {"text": "In some text documents the end-of-line mark is always a paragraph (or title) boundary, and no problem occurs: subsequent processes such as sentence splitting can be run within each paragraph.", "labels": [], "entities": [{"text": "sentence splitting", "start_pos": 139, "end_pos": 157, "type": "TASK", "confidence": 0.7256273478269577}]}, {"text": "But in some text documents, an end-of-line mark may occur in the midst of a paragraph, typically to \"wrap\" paragraphs that exceed some set length: depending on the origin of the text and on input and formatting conditions, this may have been caused by an automatic process ('hard' line wrapping in some text editors) or by manual intervention of the typist.", "labels": [], "entities": []}, {"text": "Often enough these originating conditions are not precisely known at the time these documents are submitted to natural language processing.", "labels": [], "entities": []}, {"text": "Preprocessing must then address this situation and include some solution to the classification of end-of-line marks (henceforth noted <EOL>), i.e., to determine whether an <EOL> must be considered as an actual text unit boundary (henceforth <TUB>) or should be considered as standing fora simple space (<SP>), meaning that this line has incurred \"paragraph wrapping\" and should be considered together with (e.g., pasted to) the next line to form a larger text unit.", "labels": [], "entities": [{"text": "paragraph wrapping", "start_pos": 347, "end_pos": 365, "type": "TASK", "confidence": 0.7515281140804291}]}, {"text": "This situation is mentioned by some authors, e.g., by for the MIMIC II clinical texts, or by for the i2b2/UTHealth 2014 NLP challenge documents (.", "labels": [], "entities": [{"text": "MIMIC II clinical texts", "start_pos": 62, "end_pos": 85, "type": "DATASET", "confidence": 0.8529052436351776}, {"text": "UTHealth 2014 NLP challenge documents", "start_pos": 106, "end_pos": 143, "type": "DATASET", "confidence": 0.9241751551628112}]}, {"text": "It is probably present in a much larger set of text collections, hence is likely to create some problems for many systems and teams working with these documents.", "labels": [], "entities": []}, {"text": "While the impact of these problems still needs to be assessed precisely (see, e.g.,) for limited examples), and may depend on the type of processing that follows, the number of situations where they are likely to occur warrants an investigation into general methods to address the task of classifying <EOL> marks.", "labels": [], "entities": [{"text": "classifying <EOL> marks", "start_pos": 289, "end_pos": 312, "type": "TASK", "confidence": 0.7716691255569458}]}, {"text": "End-of-line classification is therefore the topic of the present paper.", "labels": [], "entities": [{"text": "End-of-line classification", "start_pos": 0, "end_pos": 26, "type": "TASK", "confidence": 0.7188439965248108}]}, {"text": "We address it as a problem in itself, independently of its impact on subsequent tasks, and thus perform intrinsic evaluations of its performance; extrinsic evaluations, for instance through its impact on sentence splitting accuracy, are left for future work.", "labels": [], "entities": [{"text": "sentence splitting", "start_pos": 204, "end_pos": 222, "type": "TASK", "confidence": 0.7307131141424179}, {"text": "accuracy", "start_pos": 223, "end_pos": 231, "type": "METRIC", "confidence": 0.5826408863067627}]}, {"text": "Because <EOL> classification, although often needed, is only a small piece of preprocessing in a larger natural language processing pipeline whose adaptation to a given clinical task generally already requires some human annotation effort, a supervised method requiring more human annotation is not desirable.", "labels": [], "entities": [{"text": "EOL> classification", "start_pos": 9, "end_pos": 28, "type": "TASK", "confidence": 0.5283053318659464}]}, {"text": "We therefore endeavored to investigate methods which require no human annotation to perform this task.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Corpora. Lines are measured on the wn version of the documents, paragraphs on the ln version.", "labels": [], "entities": []}, {"text": " Table 2: Experiments on multi-format e-books and on the i2b2 evaluation corpus (+wrap = only files  with paragraph wrapping); Acc = accuracy, P = precision, R = recall, F = F-measure. Note that e-books:  ln has no wrapped paragraph hence no positive space hence no true positive, therefore it has P=R=F=0.", "labels": [], "entities": [{"text": "Acc", "start_pos": 127, "end_pos": 130, "type": "METRIC", "confidence": 0.9992890357971191}, {"text": "accuracy", "start_pos": 133, "end_pos": 141, "type": "METRIC", "confidence": 0.9585103988647461}, {"text": "precision", "start_pos": 147, "end_pos": 156, "type": "METRIC", "confidence": 0.9808890223503113}, {"text": "recall", "start_pos": 162, "end_pos": 168, "type": "METRIC", "confidence": 0.8291707634925842}, {"text": "F-measure", "start_pos": 174, "end_pos": 183, "type": "METRIC", "confidence": 0.9242416024208069}]}]}