{"title": [{"text": "Towards grounding computational linguistic approaches to readability: Modeling reader-text interaction for easy and difficult texts", "labels": [], "entities": []}], "abstractContent": [{"text": "Computational approaches to readability assessment are generally built and evaluated using gold standard corpora labeled by publishers or teachers rather than being grounded in observations about human performance.", "labels": [], "entities": [{"text": "readability assessment", "start_pos": 28, "end_pos": 50, "type": "TASK", "confidence": 0.857660710811615}]}, {"text": "Considering that both the reading process and the outcome can be observed, there is an empirical wealth that could be used to ground computational analysis of text readability.", "labels": [], "entities": []}, {"text": "This will also support explicit readability models connecting text complexity and the reader's language proficiency to the reading process and outcomes.", "labels": [], "entities": []}, {"text": "This paper takes a step in this direction by reporting on an experiment to study how the relation between text complexity and reader's language proficiency affects the reading process and performance outcomes of readers after reading We modeled the reading process using three eye tracking variables: fixation count, average fixation count, and second pass reading duration.", "labels": [], "entities": [{"text": "average fixation count", "start_pos": 317, "end_pos": 339, "type": "METRIC", "confidence": 0.749444842338562}, {"text": "second pass reading duration", "start_pos": 345, "end_pos": 373, "type": "METRIC", "confidence": 0.6578899770975113}]}, {"text": "Our models for these variables explained 78.9%, 74% and 67.4% variance, respectively.", "labels": [], "entities": [{"text": "variance", "start_pos": 62, "end_pos": 70, "type": "METRIC", "confidence": 0.9805245399475098}]}, {"text": "Performance outcome was modeled through recall and comprehension questions, and these models explained 58.9% and 27.6% of the variance, respectively.", "labels": [], "entities": [{"text": "recall", "start_pos": 40, "end_pos": 46, "type": "METRIC", "confidence": 0.9979477524757385}]}, {"text": "While the online models give us a better understanding of the cognitive correlates of reading with text complexity and language proficiency, modeling of the offline measures can be particularly relevant for incorporating user aspects into readability models.", "labels": [], "entities": []}], "introductionContent": [{"text": "Automatic Readability Assessment (ARA) has been an active area of research in computational linguistics over the past two decades, resulting in a wide range of supervised machine learning models that used both theory driven and data driven features, for example).", "labels": [], "entities": [{"text": "Automatic Readability Assessment (ARA)", "start_pos": 0, "end_pos": 38, "type": "TASK", "confidence": 0.7892536818981171}]}, {"text": "Though the purpose of ARA is to predict text complexity, the eventual goal is ensure that the predictions reflect the comprehension difficulties in the reader.", "labels": [], "entities": []}, {"text": "However, so far, ARA models primarily used training corpora that were based on judgements of teachers and other language experts, and not based on the actual reading performance of students, as was also recently criticized by education researchers (.", "labels": [], "entities": []}, {"text": "While this can be considered a shortcoming, obtaining large amounts of data on the actual reading performance of target population is difficult and time consuming.", "labels": [], "entities": []}, {"text": "One way to tackle this is to develop a hybrid ARA model, which separately models text complexity and user's language comprehension ability and link them through another model.", "labels": [], "entities": []}, {"text": "In this paper, we describe one approach to integrate reader and text characteristics into a single model for automatic readability assessment.", "labels": [], "entities": [{"text": "automatic readability assessment", "start_pos": 109, "end_pos": 141, "type": "TASK", "confidence": 0.5502148469289144}]}, {"text": "Eye-tracking was employed as a method to understand various NLP problems such as annotation task difficulty, translation difficulty (, and studying reader eye movements using standard corpora.", "labels": [], "entities": [{"text": "translation", "start_pos": 109, "end_pos": 120, "type": "TASK", "confidence": 0.9717446565628052}]}, {"text": "Cognitive psychologists have fora longtime studied eye-movement patterns of readers to understand the cognitive processes in reading and comprehension, and what causes reading difficulty.", "labels": [], "entities": []}, {"text": "Studying the eye movements of readers during reading considering both text and reader factors will give us a better understanding about the online link (during reading) between text complexity and reader proficiency.", "labels": [], "entities": []}, {"text": "Asking readers to answer questions about the text will give us an understanding about the offline link (after reading) between text complexity and reader proficiency.", "labels": [], "entities": []}, {"text": "Finally, having a means to combine readability models with a model of readers' language proficiency will provide us a solution to create efficient content recommendation system for readers, considering reader characteristics into account.", "labels": [], "entities": []}, {"text": "On this background, we report on an experiment that studies the relation between text complexity and reader proficiency during and after reading.", "labels": [], "entities": []}, {"text": "To our knowledge, this is the first reported study to combine online and and offline measures in one experiment, and develop models for more than one form of questions.", "labels": [], "entities": []}, {"text": "In sum, the contributions of this paper are: 1.", "labels": [], "entities": []}, {"text": "We explored modeling the cognitive correlates of text complexity and reader proficiency by studying the eye movements of readers using three eye-tracking measures: fixation count, average fixation count, and second pass reading durations.", "labels": [], "entities": [{"text": "average fixation count", "start_pos": 180, "end_pos": 202, "type": "METRIC", "confidence": 0.8549355864524841}, {"text": "second pass reading durations", "start_pos": 208, "end_pos": 237, "type": "METRIC", "confidence": 0.6317485794425011}]}, {"text": "2. We modeled how readers will respond to two types of questions (recall and comprehension) after reading the texts of varying reading difficulty, based on their language proficiency.", "labels": [], "entities": [{"text": "recall", "start_pos": 66, "end_pos": 72, "type": "METRIC", "confidence": 0.9983067512512207}]}, {"text": "We believe that this model paves way for the development of better text recommendation systems for readers based on their proficiency and the readability of the text itself.", "labels": [], "entities": [{"text": "text recommendation", "start_pos": 67, "end_pos": 86, "type": "TASK", "confidence": 0.7316484153270721}]}, {"text": "The paper is organized as follows: Section 2 surveys existing literature on the topic and puts our research in context.", "labels": [], "entities": []}, {"text": "Section 3 explains the experimental procedure, Section 4 explains the data analysis methods and variables studied, Section 5 describes the results and Section 6 summarizes the main conclusions of this paper.", "labels": [], "entities": []}], "datasetContent": [{"text": "Participants: 48 non-native English speakers studying in a German university participated in this study.", "labels": [], "entities": []}, {"text": "Their English proficiency was evaluated using a standardized online c-test used at the University for placement testing, and the average score of the participants was 72.6 (range:) where a score of 100+ is considered highly proficient.", "labels": [], "entities": []}, {"text": "The participants came from different L1 backgrounds.", "labels": [], "entities": []}, {"text": "We collected this information but it was not used in the analyses reported here.", "labels": [], "entities": []}, {"text": "Texts: Four texts, each written in two versions (advanced and beginner), taken from onestopenglish.com, were used in this study.", "labels": [], "entities": []}, {"text": "Texts from the same source were used in related research ().", "labels": [], "entities": []}, {"text": "Since the participants read the text from an eye-tracker, we restricted the length of texts used to 300-350 words in both versions.", "labels": [], "entities": []}, {"text": "They read a practice text and answered questions before starting the actual experiment.", "labels": [], "entities": []}, {"text": "Eight recall questions and six comprehension questions per text were created, which had the same answer in both versions of a text.", "labels": [], "entities": [{"text": "recall", "start_pos": 6, "end_pos": 12, "type": "METRIC", "confidence": 0.9960718154907227}]}, {"text": "While the recall questions primarily dealt with the factual information in the text and had short answers spanning a few words, comprehension questions were yes/no questions that needed drawing inferences.", "labels": [], "entities": [{"text": "recall", "start_pos": 10, "end_pos": 16, "type": "METRIC", "confidence": 0.9857299327850342}]}, {"text": "All the authors worked together to create the questions, and the final list of questions was created after a discussion to reach consensus about the questions and answers to the questions.", "labels": [], "entities": []}, {"text": "The responses of participants were manually evaluated by a graduate student, by comparing them with the gold standard answers.", "labels": [], "entities": []}, {"text": "shows some statistics about the texts used, along with additional information about the complexity of the texts based on automated approaches.", "labels": [], "entities": []}, {"text": "Flesch-Kincaid Grade) is a standard readability formula.", "labels": [], "entities": [{"text": "Flesch-Kincaid Grade)", "start_pos": 0, "end_pos": 21, "type": "METRIC", "confidence": 0.750936766465505}]}, {"text": "VM refers to the readability score assigned by the model of, which is a regression model based on several lexical and syntactic features, and outputs a score between 1-6, with higher values indicating more difficult texts.", "labels": [], "entities": [{"text": "VM", "start_pos": 0, "end_pos": 2, "type": "DATASET", "confidence": 0.501533567905426}]}, {"text": "Surprisal is a psycholinguistic measure of expected cognitive load during sentence processing, based on information theory.", "labels": [], "entities": [{"text": "Surprisal", "start_pos": 0, "end_pos": 9, "type": "METRIC", "confidence": 0.9205389022827148}]}, {"text": "We took the average total surprisal for all sentences from Roark parser) as a measure of surprisal for each text.", "labels": [], "entities": []}, {"text": "Though we modeled different notions of complexity, we only report about the models with the binary complexity from onestopenglish.com in this paper.", "labels": [], "entities": []}, {"text": "Procedure: We employed Latin square design for the experiment, making sure each participant read all four texts, alternating between easy and difficult versions.", "labels": [], "entities": []}, {"text": "No participant read the same text in two versions.", "labels": [], "entities": []}, {"text": "They answered questions on paper after each text and the eye-tracker was re-calibrated for their next reading.", "labels": [], "entities": []}, {"text": "Participants were randomly assigned to one of the four experimental conditions, which differed in the order of texts read.", "labels": [], "entities": []}, {"text": "We conducted the experiment using iViewX TM Hi-speed eye-tracker from Senso Motoric Instruments (SMI) and collected the reading data through SMI BeGaze 2 software with Reading package.", "labels": [], "entities": []}, {"text": "Dependent Variables: We report on three eye-tracking variables and two reader performance measures as our dependent variables: Three eye-tracking measures -average fixation count (average number of times a reader fixates on a word) and average fixation duration (average duration of such fixations in milliseconds), and average second pass reading time (in milliseconds) -were analyzed to study study how the relation between text complexity and reader proficiency affects online processing of these texts.", "labels": [], "entities": [{"text": "second pass reading time", "start_pos": 328, "end_pos": 352, "type": "METRIC", "confidence": 0.6587895750999451}]}, {"text": "Previous research in cognitive psychology has shown that a reader's comprehension difficulties are reflected in eye-movements through increased) and longer) fixations.", "labels": [], "entities": []}, {"text": "Both these measures are also known to correlate with text difficulty in the experiment described by.", "labels": [], "entities": []}, {"text": "Two reader performance outcome measures -number of correct answers for recall and comprehension questions -were used as dependent variables related to offline measures.", "labels": [], "entities": [{"text": "recall", "start_pos": 71, "end_pos": 77, "type": "METRIC", "confidence": 0.9688069820404053}]}, {"text": "Each text had eight recall and six comprehension questions, which are the maximum scores the participants can get per text respectively.", "labels": [], "entities": [{"text": "recall", "start_pos": 20, "end_pos": 26, "type": "METRIC", "confidence": 0.9979537725448608}]}, {"text": "Independent (fixed effect) Variables: We considered the binary text complexity (categorical: elementary and advanced as easy and difficult respectively) and the reader's English proficiency (numeric) as two primary independent variables.", "labels": [], "entities": []}, {"text": "Additionally, hypothesizing that there could be some effect of reading texts one after another, we also considered the order in which the participant read a given text (which depends on the experimental condition) as another independent variable.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Number of words in the texts used for the experiment", "labels": [], "entities": []}, {"text": " Table 2: Best Performing Model for Fixation Count (* indicates statistically significant)", "labels": [], "entities": [{"text": "Fixation Count", "start_pos": 36, "end_pos": 50, "type": "TASK", "confidence": 0.6583848297595978}]}, {"text": " Table 3: Summary of the GAMM model for Average Fixation Duration", "labels": [], "entities": [{"text": "GAMM", "start_pos": 25, "end_pos": 29, "type": "TASK", "confidence": 0.5854414701461792}, {"text": "Average Fixation Duration", "start_pos": 40, "end_pos": 65, "type": "METRIC", "confidence": 0.859866221745809}]}, {"text": " Table 4: Best Performing Model for Second Pass Duration", "labels": [], "entities": [{"text": "Second Pass Duration", "start_pos": 36, "end_pos": 56, "type": "METRIC", "confidence": 0.8303139011065165}]}, {"text": " Table 5: Best Performing Model for Recall", "labels": [], "entities": [{"text": "Recall", "start_pos": 36, "end_pos": 42, "type": "TASK", "confidence": 0.8781846165657043}]}, {"text": " Table 6: Summary of the GAMM model for Comprehension Scores", "labels": [], "entities": [{"text": "GAMM", "start_pos": 25, "end_pos": 29, "type": "TASK", "confidence": 0.6807848811149597}]}]}