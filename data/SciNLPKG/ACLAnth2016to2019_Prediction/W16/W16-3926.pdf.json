{"title": [{"text": "UQAM-NTL: Named entity recognition in Twitter messages", "labels": [], "entities": [{"text": "Named entity recognition", "start_pos": 10, "end_pos": 34, "type": "TASK", "confidence": 0.6107517083485922}]}], "abstractContent": [{"text": "This paper describes our system used in the 2 nd Workshop on Noisy User-generated Text (WNUT) shared task for Named Entity Recognition (NER) in Twitter, in conjunction with Coling 2016.", "labels": [], "entities": [{"text": "2 nd Workshop on Noisy User-generated Text (WNUT) shared task for Named Entity Recognition (NER) in Twitter", "start_pos": 44, "end_pos": 151, "type": "TASK", "confidence": 0.6784216491948991}, {"text": "Coling 2016", "start_pos": 173, "end_pos": 184, "type": "DATASET", "confidence": 0.9529010951519012}]}, {"text": "Our system is based on supervised machine learning by applying Conditional Random Fields (CRF) to train two classifiers for two different evaluations.", "labels": [], "entities": []}, {"text": "The first evaluation aims at predicting the 10 fine-grained types of named entities; while the second evaluation aims at predicting no type of named entities.", "labels": [], "entities": []}, {"text": "The experimental results show that our method has significantly improved Twitter NER performance.", "labels": [], "entities": [{"text": "NER", "start_pos": 81, "end_pos": 84, "type": "TASK", "confidence": 0.9406607151031494}]}], "introductionContent": [{"text": "Named entity recognition is one of the key information extraction tasks.", "labels": [], "entities": [{"text": "Named entity recognition", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.7154475251833597}, {"text": "information extraction", "start_pos": 43, "end_pos": 65, "type": "TASK", "confidence": 0.7496244013309479}]}, {"text": "This concerns the identification of named entities and the classification of named entities such as person, organisation, location, time and event (.", "labels": [], "entities": [{"text": "identification of named entities", "start_pos": 18, "end_pos": 50, "type": "TASK", "confidence": 0.8457914143800735}]}, {"text": "The existing standard NER systems are usually trained on formal texts, such as the newswire.", "labels": [], "entities": [{"text": "NER", "start_pos": 22, "end_pos": 25, "type": "TASK", "confidence": 0.9422580599784851}]}, {"text": "However, these linguistic tools do notwork well on the new and challenging noisy tweet messages because the style of Tweet messages is short (length upto 140 characters) and unstructured.", "labels": [], "entities": []}, {"text": "The content is highly noisy, contains many ill-formed words and covers several topics.", "labels": [], "entities": []}, {"text": "Sometimes even human annotators do not have enough context to disambiguate the entities reliably (.", "labels": [], "entities": []}, {"text": "Our team at UQAM is interested by social media analysis research within the NLP context.", "labels": [], "entities": [{"text": "UQAM", "start_pos": 12, "end_pos": 16, "type": "DATASET", "confidence": 0.9232434034347534}]}, {"text": "Thus, our participation at the 2nd Workshop on Noisy User-generated Text (WNUT) shared task for Named Entity Recognition in Twitter, in conjunction with Coling 2016, is very fruitful.", "labels": [], "entities": [{"text": "2nd Workshop on Noisy User-generated Text (WNUT) shared task for Named Entity Recognition", "start_pos": 31, "end_pos": 120, "type": "TASK", "confidence": 0.5511640687783559}, {"text": "Coling 2016", "start_pos": 153, "end_pos": 164, "type": "DATASET", "confidence": 0.9155898690223694}]}, {"text": "This shared task consists of two separate evaluations aiming at: (1) predicting the 10 fine-grained types of named entities, and (2) predicting the no-type of named entities.", "labels": [], "entities": [{"text": "predicting the no-type of named entities", "start_pos": 133, "end_pos": 173, "type": "TASK", "confidence": 0.6814768314361572}]}, {"text": "For both evaluation, our system is based on supervised machine learning and trained with a sequential labeling algorithm, using Conditional Random Fields (CRF).", "labels": [], "entities": []}, {"text": "Our contribution here consists of the proposal about the new features regarding the polysemy count based on an lexicalized semantic network and ontology, such as an encyclopedic dictionary, and the longest n-gram sequence length of each word in a tweet based on a language model about actualities, news and also syntactic features by parsing each tweet.", "labels": [], "entities": []}, {"text": "The present paper is organized as follows: In the section 2, we report the proposed system about the features extraction.", "labels": [], "entities": [{"text": "features extraction", "start_pos": 101, "end_pos": 120, "type": "TASK", "confidence": 0.7177302539348602}]}, {"text": "The experimentations and the evaluations are presented in the sections 3 and 4 respectively.", "labels": [], "entities": []}, {"text": "Finally, the section 5 summarizes our work and gives future perspective.", "labels": [], "entities": []}], "datasetContent": [{"text": "In the preprocessing phase, we apply Twitter tokenization, POS tagging on tokenized data with TwitIE 3 (Bontcheva et al., 2013).", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 59, "end_pos": 70, "type": "TASK", "confidence": 0.6544191539287567}]}, {"text": "Once the final feature extraction has been completed, in the training phase, we make use of Conditional Random Fields (CRF) () as machine learning technique.", "labels": [], "entities": []}, {"text": "We use the CRF implementation Wapiti 4 , version 1.5.0 toolkit to create our model.", "labels": [], "entities": [{"text": "CRF implementation Wapiti 4", "start_pos": 11, "end_pos": 38, "type": "DATASET", "confidence": 0.6899066269397736}]}, {"text": "The optimization algorithm is l-bfgs (Limited-memory Broyden-Fletcher-Goldfarb-Shanno).", "labels": [], "entities": []}, {"text": "During decoding phase, our model classifies, from a test corpus, whether a word should be labelled as named entities.", "labels": [], "entities": []}, {"text": "Our model was evaluated on two tasks: (1) to predict 10 fine-grained types of named entities and  The features for the tokens in the templates are in uni-grams (Template 1), bi-grams (Template 2), tri-grams (Template 3) and within a context window of size 3 (previous token, current token, next token) (see).", "labels": [], "entities": []}, {"text": "We combine the train data, the dev data for training our model.", "labels": [], "entities": []}, {"text": "We use the metrics of precision, recall and weighted harmonic mean of precision and recall (F1) to evaluate the performance of the proposed system in two cases: (1) 10 types of named entities and (2) no-types of named entities.", "labels": [], "entities": [{"text": "precision", "start_pos": 22, "end_pos": 31, "type": "METRIC", "confidence": 0.9994487166404724}, {"text": "recall", "start_pos": 33, "end_pos": 39, "type": "METRIC", "confidence": 0.9989162683486938}, {"text": "precision", "start_pos": 70, "end_pos": 79, "type": "METRIC", "confidence": 0.5211309790611267}, {"text": "recall (F1)", "start_pos": 84, "end_pos": 95, "type": "METRIC", "confidence": 0.8386736065149307}]}, {"text": "The experiments are performed by training the model on all the features defined in section 2.", "labels": [], "entities": []}, {"text": "We have trained, tested and evaluated iteratively the system in order to find out the best fitting feature sets.", "labels": [], "entities": []}, {"text": "The results are presented in table 5 with models trained on the combination of training and development data with 2 814 tweets, then tested on the dev_2015 with 1 000 tweets which are used in the baseline system (see README 5 file of WNUT-2016 workshop).", "labels": [], "entities": [{"text": "README 5 file of WNUT-2016 workshop", "start_pos": 217, "end_pos": 252, "type": "DATASET", "confidence": 0.7541760255893072}]}], "tableCaptions": [{"text": " Table 1. Statistics of the n-gram of the language model from WMT-2016", "labels": [], "entities": [{"text": "WMT-2016", "start_pos": 62, "end_pos": 70, "type": "DATASET", "confidence": 0.9060651063919067}]}, {"text": " Table 2. Statistics of the corpora provided by the 2 nd shared task at WNUT-2016", "labels": [], "entities": [{"text": "WNUT-2016", "start_pos": 72, "end_pos": 81, "type": "DATASET", "confidence": 0.8504704236984253}]}, {"text": " Table 3. Statistics of the 10 fine-grained types of named entities in the training data and the  development data provided by the 2 nd shared task at WNUT-2016", "labels": [], "entities": [{"text": "WNUT-2016", "start_pos": 151, "end_pos": 160, "type": "DATASET", "confidence": 0.8207118511199951}]}, {"text": " Table 5. Evaluations with model trained by applying tree templates  with (train, dev, test) = (2 814, 0, 1 000) tweets", "labels": [], "entities": []}, {"text": " Table 6. Effect of each features on the classifier when added to the baseline system  with (train, dev, test) = (2 814, 0, 1 000) tweets", "labels": [], "entities": []}, {"text": " Table 7. Evaluations with model trained with template 3,  Experiment 1: (train, dev, test) = (2 814, 0, 3 856) tweets,  Experiment 2: (train, dev, test) = (3 534, 280, 3 856) tweets", "labels": [], "entities": []}]}