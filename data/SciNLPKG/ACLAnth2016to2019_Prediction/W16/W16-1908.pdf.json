{"title": [{"text": "Learning Phone Embeddings for Word Segmentation of Child-Directed Speech", "labels": [], "entities": [{"text": "Word Segmentation of Child-Directed Speech", "start_pos": 30, "end_pos": 72, "type": "TASK", "confidence": 0.8312641620635987}]}], "abstractContent": [{"text": "This paper presents a novel model that learns and exploits embeddings of phone ngrams for word segmentation in child language acquisition.", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 90, "end_pos": 107, "type": "TASK", "confidence": 0.7299047410488129}, {"text": "child language acquisition", "start_pos": 111, "end_pos": 137, "type": "TASK", "confidence": 0.6102971931298574}]}, {"text": "Embedding-based models are evaluated on a phonemi-cally transcribed corpus of child-directed speech, in comparison with their symbolic counterparts using the common learning framework and features.", "labels": [], "entities": []}, {"text": "Results show that learning embeddings significantly improves performance.", "labels": [], "entities": []}, {"text": "We make use of extensive visualization to understand what the model has learned.", "labels": [], "entities": []}, {"text": "We show that the learned embeddings are informative for both word segmentation and phonology in general.", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 61, "end_pos": 78, "type": "TASK", "confidence": 0.7128303349018097}]}], "introductionContent": [{"text": "Segmentation is a prevalent problem in language processing.", "labels": [], "entities": [{"text": "Segmentation", "start_pos": 0, "end_pos": 12, "type": "TASK", "confidence": 0.965924859046936}]}, {"text": "Both humans and computers process language as a combination of linguistic units, such as words.", "labels": [], "entities": []}, {"text": "However, spoken language does not include reliable cues to word boundaries that are found in many writing systems.", "labels": [], "entities": []}, {"text": "The hearers need to extract words from a continuous stream of sounds using their linguistic knowledge and the cues in the input signal.", "labels": [], "entities": []}, {"text": "Although the problem is still non-trivial, competent language users utilize their knowledge of the input language, e.g., the (mental) lexicon, to a large extent to aid extraction of lexical units from the input stream.", "labels": [], "entities": []}, {"text": "Word segmentation in early language acquisition is especially interesting and challenging, as early language learners barely have a lexicon or any other linguistic knowledge to start with.", "labels": [], "entities": [{"text": "Word segmentation", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.6901516765356064}, {"text": "early language acquisition", "start_pos": 21, "end_pos": 47, "type": "TASK", "confidence": 0.6319061021010081}]}, {"text": "Consequently, it has been studied extensively through psycholinguistic experiments and computational modeling.", "labels": [], "entities": []}, {"text": "The majority of the state-of-the-art computational models use symbolic representations for input units.", "labels": [], "entities": []}, {"text": "Due to Zipf's law, most linguistic units, however, are rare and thus the input provides little evidence for their properties that are useful for solving the task at hand.", "labels": [], "entities": []}, {"text": "In machine learning terms, the learner has to deal with the data sparseness problem due to the rare units whose parameters cannot be estimated reliably.", "labels": [], "entities": []}, {"text": "A model using distributed representations can counteract the data sparseness problem by exploiting the similarities between the units for parameter estimation.", "labels": [], "entities": []}, {"text": "This has motivated the introduction of embeddings (), a family of low-dimensional, real-valued vector representation of features that are learned from data.", "labels": [], "entities": []}, {"text": "Unlike purely symbolic representations, such distributed representations allow input units that appear in similar contexts to share similar vectors (embeddings).", "labels": [], "entities": []}, {"text": "The model can, then, exploit the similarities between the embeddings during segmentation and learning.", "labels": [], "entities": []}, {"text": "This paper studies the learning and use of embeddings of phone 1 uni-and bi-grams for computational models of word segmentation in child language acquisition.", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 110, "end_pos": 127, "type": "TASK", "confidence": 0.7140678614377975}, {"text": "child language acquisition", "start_pos": 131, "end_pos": 157, "type": "TASK", "confidence": 0.6094318429629008}]}, {"text": "Our work is inspired by recent success of embeddings in NLP (, especially in Chinese word segmentation (.", "labels": [], "entities": [{"text": "Chinese word segmentation", "start_pos": 77, "end_pos": 102, "type": "TASK", "confidence": 0.6632226308186849}]}, {"text": "However, this work differs from Chinese word segmenta-tion models in two aspects.", "labels": [], "entities": []}, {"text": "(1) The model (Section 2) learns from a phonemically transcribed corpus of child-directed speech (Section 3.1) instead of large written text input.", "labels": [], "entities": []}, {"text": "(2) The learning (Section 2.2) only relies on utterance boundaries in input as opposed to explicitly marked word boundaries.", "labels": [], "entities": []}, {"text": "Although the number of phone types is small, higher level ngrams of phones inevitably increase the severity of data sparseness.", "labels": [], "entities": []}, {"text": "Thus we expect embeddings to be particularly useful when larger phoneme ngrams are used as input units.", "labels": [], "entities": []}, {"text": "The contributions of this paper are three-fold: \u2022 A novel model that constructs and uses embeddings of phone ngrams for word segmentation in child language acquisition; \u2022 Empirical evaluations of symbolic and embedding representations for this task on the benchmark data, which suggest that learning embeddings boosts the performance; \u2022 A deeper analysis of the learned embeddings through visualizations and clustering, showing that the learned embeddings capture information relevant to segmentation and phonology in general.", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 120, "end_pos": 137, "type": "TASK", "confidence": 0.7240526527166367}]}, {"text": "In the next section we define the distributed representations we use in this study, phoneembeddings, and a method for learning the embeddings and the segmentation parameters simultaneously from a corpus without word boundaries.", "labels": [], "entities": []}, {"text": "Then we present a set of experiments for comparing embedding and symbolic representations (Section 3).", "labels": [], "entities": []}, {"text": "We show our visualization and clustering analyses of the learned embeddings (Section 4) before discussing our results further in the context of previous work (Section 5) and concluding the paper.", "labels": [], "entities": []}], "datasetContent": [{"text": "The learning framework described in Section 2 can also be adopted for symbolic representations where the ngram features for each position are represented by a sparse binary vector.", "labels": [], "entities": []}, {"text": "In the symbolic representation, each distinct uni-or bi-gram is represented by a distinct dimension in the input vector.", "labels": [], "entities": []}, {"text": "In that case, the learning framework is equivalent to a logistic regression model, the training of which only updates the weight vector but not the feature representations.", "labels": [], "entities": []}, {"text": "In this section, we run experiments to compare the performances of embedding-and symbolic-based models using the same learning framework with the same features.", "labels": [], "entities": []}, {"text": "Before presenting the experiments and the results, we describe the data and evaluation metrics.", "labels": [], "entities": []}, {"text": "As a measure of success, we report F-score, the harmonic mean of precision and recall.", "labels": [], "entities": [{"text": "F-score", "start_pos": 35, "end_pos": 42, "type": "METRIC", "confidence": 0.9975317716598511}, {"text": "precision", "start_pos": 65, "end_pos": 74, "type": "METRIC", "confidence": 0.9986061453819275}, {"text": "recall", "start_pos": 79, "end_pos": 85, "type": "METRIC", "confidence": 0.9969935417175293}]}, {"text": "F-score is a well-known evaluation metric originated in information retrieval).", "labels": [], "entities": [{"text": "F-score", "start_pos": 0, "end_pos": 7, "type": "METRIC", "confidence": 0.956076443195343}]}, {"text": "The calculation of these measures depend on true positive (TP), false positive (FP) and false negative (FN) values for each decision.", "labels": [], "entities": [{"text": "true positive (TP), false positive (FP) and false negative (FN)", "start_pos": 44, "end_pos": 107, "type": "METRIC", "confidence": 0.7302419701043297}]}, {"text": "Following earlier studies, we report three varieties of F-scores.", "labels": [], "entities": [{"text": "F-scores", "start_pos": 56, "end_pos": 64, "type": "METRIC", "confidence": 0.9943028688430786}]}, {"text": "The boundary F-score (BF) considers individual boundary decisions.", "labels": [], "entities": [{"text": "boundary F-score (BF)", "start_pos": 4, "end_pos": 25, "type": "METRIC", "confidence": 0.8207522869110108}]}, {"text": "The word F-score (WF) quantifies the accuracy of recognizing word to-kens.", "labels": [], "entities": [{"text": "word F-score (WF)", "start_pos": 4, "end_pos": 21, "type": "METRIC", "confidence": 0.8670960545539856}, {"text": "accuracy", "start_pos": 37, "end_pos": 45, "type": "METRIC", "confidence": 0.9977396726608276}]}, {"text": "And the lexicon F-scores (LF) are calculated based on the gold-standard lexicon and lexicon learned by the model.", "labels": [], "entities": [{"text": "F-scores (LF)", "start_pos": 16, "end_pos": 29, "type": "METRIC", "confidence": 0.946873813867569}]}, {"text": "For details of the metrics, see . Following the literature, the utterance boundaries are not included in boundary F-score calculations, while lexicon/word metrics include first and the last words in utterance.", "labels": [], "entities": [{"text": "F-score", "start_pos": 114, "end_pos": 121, "type": "METRIC", "confidence": 0.8745049238204956}]}, {"text": "Besides these standard scores we also present over-segmentation (EO) and under-segmentation (EU) error rate (lower is better) defined as: where TN is true negatives of boundaries.", "labels": [], "entities": [{"text": "under-segmentation (EU) error rate", "start_pos": 73, "end_pos": 107, "type": "METRIC", "confidence": 0.7786003053188324}]}, {"text": "Besides providing a different look at the models' behavior, it is straightforward to calculate the statistical uncertainty around them since they resemble N Bernoulli trials with a particular error rate, where N is number of boundary and word-internal positions for EU and EO respectively.", "labels": [], "entities": []}, {"text": "The results of our model in this paper are directly comparable with the results of previous work on the BR corpus using the above metrics.", "labels": [], "entities": [{"text": "BR corpus", "start_pos": 104, "end_pos": 113, "type": "DATASET", "confidence": 0.924414187669754}]}, {"text": "The utterance boundary information that our method uses is also available to any \"pure\" unsupervised method in literature, such as the EMbased algorithm of Brent (1999) and the Bayesian approach of . In these methods, word hypotheses that cross utterance boundaries are not considered, which implicitly utilizes utterance boundary \"supervision.\"", "labels": [], "entities": []}, {"text": "To show the differences between the symbolic and embedding representations, we train both models on the BR corpus, and present the performance and error scores on the complete corpus.", "labels": [], "entities": [{"text": "BR corpus", "start_pos": 104, "end_pos": 113, "type": "DATASET", "confidence": 0.9905824363231659}, {"text": "error", "start_pos": 147, "end_pos": 152, "type": "METRIC", "confidence": 0.865180253982544}]}, {"text": "The training of all models use the linear decay scheme of learning rate with the initial value of 0.05 and the regularization factor is set to 0.001 throughout the experiments.", "labels": [], "entities": []}, {"text": "presents the results, including standard errors for EO and EU, for emb(edding)-and sym(bolic)-based models using unigram features (uni) and unigram+bigram features (all), respectively.", "labels": [], "entities": []}, {"text": "shows the average of the results obtained from 10 independent runs.", "labels": [], "entities": []}, {"text": "For each run, we take the scores from the 10th iteration of the whole data set, where the scores are stabilized.", "labels": [], "entities": []}, {"text": "All models learn quickly and have good performance after the first iteration already.", "labels": [], "entities": []}, {"text": "And the differences between the scores of subsequent iterations are rather small.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Performance of embedding and symbolic  models. Numbers in percentage.", "labels": [], "entities": []}, {"text": " Table 2: Comparisoin of the best performance of  our model (bottom) with the state-of-the-art sys- tems on the task (upper) and the models using ut- terance boundaries as the main cue (middle). U:  using utterance boundary only; PUW: using pre- dictability, utterance boundary and the learned lex- icon. Numbers in percentage.", "labels": [], "entities": [{"text": "PUW", "start_pos": 230, "end_pos": 233, "type": "METRIC", "confidence": 0.756490170955658}]}]}