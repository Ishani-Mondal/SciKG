{"title": [{"text": "An Unsupervised Morphological Criterion for Discriminating Similar Languages", "labels": [], "entities": []}], "abstractContent": [{"text": "In this study conducted on the occasion of the Discriminating between Similar Languages shared task, I introduce an additional decision factor focusing on the token and subtoken level.", "labels": [], "entities": [{"text": "Discriminating between Similar Languages shared task", "start_pos": 47, "end_pos": 99, "type": "TASK", "confidence": 0.8046422799428304}]}, {"text": "The motivation behind this submission is to test whether a morphologically-informed criterion can add linguistically relevant information to global categorization and thus improve performance.", "labels": [], "entities": []}, {"text": "The contributions of this paper are (1) a description of the unsupervised, low-resource method; (2) an evaluation and analysis of its raw performance; and (3) an assessment of its impact within a model comprising common indicators used in language identification.", "labels": [], "entities": [{"text": "language identification", "start_pos": 239, "end_pos": 262, "type": "TASK", "confidence": 0.7593491077423096}]}, {"text": "I present and discuss the systems used in the task A, a 12-way language identification task comprising varieties of five main language groups.", "labels": [], "entities": [{"text": "language identification task", "start_pos": 63, "end_pos": 91, "type": "TASK", "confidence": 0.8059299190839132}]}, {"text": "Additionally I introduce anew off-the-shelf Naive Bayes classifier using a contrastive word and subword n-gram model (\"Bayesline\") which outperforms the best submissions.", "labels": [], "entities": [{"text": "Naive Bayes classifier", "start_pos": 44, "end_pos": 66, "type": "TASK", "confidence": 0.8106258908907572}]}], "introductionContent": [{"text": "Language identification is the task of predicting the language(s) that a given document is written in.", "labels": [], "entities": [{"text": "Language identification", "start_pos": 0, "end_pos": 23, "type": "TASK", "confidence": 0.6920889616012573}]}, {"text": "It can be seen as a text categorization task in which documents are assigned to pre-existing categories.", "labels": [], "entities": []}, {"text": "This research field has found renewed interest in the 1990s due to advances in statistical approaches and it has been active ever since, particularly since the methods developed have also been deemed relevant for text categorization, native language identification, authorship attribution, text-based geolocation, and dialectal studies.", "labels": [], "entities": [{"text": "text categorization", "start_pos": 213, "end_pos": 232, "type": "TASK", "confidence": 0.7603479027748108}, {"text": "native language identification", "start_pos": 234, "end_pos": 264, "type": "TASK", "confidence": 0.6285703082879385}, {"text": "authorship attribution", "start_pos": 266, "end_pos": 288, "type": "TASK", "confidence": 0.7243764251470566}]}, {"text": "As of 2014 and the first Discriminating between Similar Languages (DSL) shared task ( ), a unified dataset ( ) comprising news texts of closely-related language varieties has been used to test and benchmark systems.", "labels": [], "entities": [{"text": "Discriminating between Similar Languages (DSL) shared task", "start_pos": 25, "end_pos": 83, "type": "TASK", "confidence": 0.6825043426619636}]}, {"text": "A second shared task took place in 2015 (, an analysis of recent developments can be found in.", "labels": [], "entities": []}, {"text": "The documents to be classified are quite short and may even be difficult to distinguish for humans, thus adding to the difficulty and the interest of the task.", "labels": [], "entities": []}, {"text": "Not all varieties are to be considered equally since differences may stem from extra-linguistic factors.", "labels": [], "entities": []}, {"text": "It is for instance assumed that Malay and Indonesian derive from a milleniumold lingua franca, so that shorter texts have been considered to be a problem for language identification).", "labels": [], "entities": [{"text": "language identification", "start_pos": 158, "end_pos": 181, "type": "TASK", "confidence": 0.7169060707092285}]}, {"text": "Besides, the Bosnian/Serbian language pair seems to be difficult to tell apart whereas Croatian distinguishes itself from the two other varieties mostly because of political motives).", "labels": [], "entities": []}, {"text": "The contributions of this paper are (1) a description of an unsupervised, low-resource method comprising morphological features; (2) an evaluation and analysis of its raw performance; and (3) an assessment of its impact in a model comprising common indicators used in language identification.", "labels": [], "entities": [{"text": "language identification", "start_pos": 268, "end_pos": 291, "type": "TASK", "confidence": 0.7543548345565796}]}, {"text": "In addition, I will demonstrate that an off-the-shelf method working on the subtoken level can outperform the best submissions in the shared task.", "labels": [], "entities": []}, {"text": "The remainder of this paper is organized as follows: in section 2 the method is presented, a evaluation follows in section 3, the systems used for the shared task is described and anew baseline for task A is proposed in section 4.", "labels": [], "entities": []}], "datasetContent": [{"text": "After empirical testing, the smallest possible token length for learning and searching is fixed to 5 characters, there is no upper bound on token length, and the maximum affix length is set to 2 to provide a safer setting overall, although affix lengths of 3 or 4 occasionally lead to better results.", "labels": [], "entities": []}, {"text": "Despite the possibility of populating a blacklist out of common tokens present in the lower and higher frequency ranges, experiments have not been conclusive, so that no blacklisting has been used for the task.", "labels": [], "entities": []}, {"text": "describes the results of morphological training.", "labels": [], "entities": []}, {"text": "The coverage displayed is the total percentage of words considered to be in-dictionary by the model, for the target language and for the concurrent language(s) respectively.", "labels": [], "entities": [{"text": "coverage", "start_pos": 4, "end_pos": 12, "type": "METRIC", "confidence": 0.9619175791740417}]}, {"text": "For Southeastern-European languages, I find a lower lexical overlap than Tiedemann and Ljube\u0161i\u00b4Ljube\u0161i\u00b4c (2012).", "labels": [], "entities": []}, {"text": "The Spanish varieties have the smallest coverage spread.", "labels": [], "entities": [{"text": "coverage spread", "start_pos": 40, "end_pos": 55, "type": "METRIC", "confidence": 0.9534359276294708}]}, {"text": "The assumption that Malay and Indonesian feature more than 90% lexical similarity) is only partially confirmed: it seems that Indonesian has more to do with Malay than vice versa and the news samples used for the tests seem to be relatively easy to tell apart, since they feature the largest coverage spread.", "labels": [], "entities": []}, {"text": "This distinction within the Bahasa complex and the rest is reflected as being traditionally assumed in language typology.", "labels": [], "entities": []}, {"text": "However, finer differences do exist between fusional/inflectional languages (Dryer and Haspelmath, 2013) 1 , and the results of the morphological induction phase constitute further evidence of subtle differences, among other things on the morpholexical level.", "labels": [], "entities": []}, {"text": "Concerning the benchmark, the method is compared to a unigram baseline in terms of raw precision: for each instance, potential candidates (alphabetic tokens of 5 characters and more) are analyzed and classified as in-or out-of-vocabulary.", "labels": [], "entities": [{"text": "precision", "start_pos": 87, "end_pos": 96, "type": "METRIC", "confidence": 0.9136939644813538}]}, {"text": "The number of in-vocabulary tokens is divided by the number of candidates, and the instance is classified according to the model which yields the highest proportion of recognized tokens.", "labels": [], "entities": []}, {"text": "This proportion has to be strictly superior to all others, which means that this indicator (as all unigram models) can be undecided due to coverage problems, especially in short instances.", "labels": [], "entities": [{"text": "coverage", "start_pos": 139, "end_pos": 147, "type": "METRIC", "confidence": 0.9809898734092712}]}, {"text": "Thus, I used precision as a benchmark in order to judge cases where the indicator actually predicts something, in other words the positive predictive value.", "labels": [], "entities": [{"text": "precision", "start_pos": 13, "end_pos": 22, "type": "METRIC", "confidence": 0.9991098046302795}]}], "tableCaptions": [{"text": " Table 1: Results of morphological induction on training set in terms of coverage and precision of classi- fication on the development set. The unigram baseline and unigram Bayesline (Tan et al. 2014) are given  for comparison.", "labels": [], "entities": [{"text": "precision", "start_pos": 86, "end_pos": 95, "type": "METRIC", "confidence": 0.9980691075325012}]}, {"text": " Table 3: Results for test set A (closed training). Bayeslines inspired by", "labels": [], "entities": []}]}