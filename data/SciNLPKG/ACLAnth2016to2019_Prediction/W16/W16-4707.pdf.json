{"title": [{"text": "Evaluation of distributional semantic models: a holistic approach", "labels": [], "entities": []}], "abstractContent": [{"text": "We investigate how both model-related factors and application-related factors affect the accuracy of distributional semantic models (DSMs) in the context of specialized lexicography, and how these factors interact.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 89, "end_pos": 97, "type": "METRIC", "confidence": 0.9974634647369385}]}, {"text": "This holistic approach to the evaluation of DSMs provides valuable guidelines for the use of these models and insight into the kind of semantic information they capture.", "labels": [], "entities": [{"text": "evaluation of DSMs", "start_pos": 30, "end_pos": 48, "type": "TASK", "confidence": 0.6083610157171885}]}], "introductionContent": [{"text": "Distributional semantic models (DSMs) can be very useful tools for specialized lexicography, as they can help identify semantic or conceptual relations between terms based on corpus data, among other uses.", "labels": [], "entities": [{"text": "Distributional semantic models (DSMs", "start_pos": 0, "end_pos": 36, "type": "TASK", "confidence": 0.7324068963527679}]}, {"text": "The quality of the results produced by these models depends on two types of factors: model-related factors and application-related factors.", "labels": [], "entities": []}, {"text": "First, they depend on the type of model and the settings used for each of the model's (hyper)parameters.", "labels": [], "entities": []}, {"text": "Second, they depend on various aspects of the target application.", "labels": [], "entities": []}, {"text": "In the case of specialized lexicography, these factors include the kinds of terms that will be included in the lexical resource and the kinds of relations that will be described therein.", "labels": [], "entities": []}, {"text": "The target relations can include typical paradigmatic relations such as (near-)synonymy (e.g. preserve\u2192protect), but also others such as syntactic derivation.", "labels": [], "entities": []}, {"text": "There may also be interactions between the various factors: for instance, the optimal parameter settings may depend on the target relations.", "labels": [], "entities": []}, {"text": "We investigated how these two types of factors affect the quality of the results produced by DSMs, and how they interact, i.e. how various aspects of specialized lexicography must be accounted for when choosing and tuning a model.", "labels": [], "entities": []}, {"text": "The aspects considered in this paper are the the part-of-speech (POS) of the terms included in the resource, the descriptive framework, and the target relations.", "labels": [], "entities": []}, {"text": "To this end, we carried out an experiment in which DSMs were built on domain-specific corpora and evaluated on gold standard data we extracted from specialized dictionaries.", "labels": [], "entities": [{"text": "DSMs", "start_pos": 51, "end_pos": 55, "type": "TASK", "confidence": 0.9555264711380005}]}], "datasetContent": [{"text": "If we compare the maximum MAP obtained on each of the datasets (by either BOW or W2V), we see that DSMs capture syntactic derivatives even more accurately than near-synonyms if the models are tuned for this relation.", "labels": [], "entities": [{"text": "MAP", "start_pos": 26, "end_pos": 29, "type": "METRIC", "confidence": 0.985178530216217}, {"text": "BOW", "start_pos": 74, "end_pos": 77, "type": "METRIC", "confidence": 0.9731268286705017}]}, {"text": "Antonyms are captured almost as accurately as synonyms, but the MAP obtained on hypernyms/hyponyms is quite a bit lower.", "labels": [], "entities": [{"text": "MAP", "start_pos": 64, "end_pos": 67, "type": "METRIC", "confidence": 0.9974574446678162}]}, {"text": "As for the POS, DSMs model adjectives most accurately, followed by nouns, then verbs.", "labels": [], "entities": []}, {"text": "The MAP achieved on the SETS is lower than on all the semantic relations except for hypernyms/hyponyms.", "labels": [], "entities": [{"text": "MAP", "start_pos": 4, "end_pos": 7, "type": "METRIC", "confidence": 0.9860455393791199}, {"text": "SETS", "start_pos": 24, "end_pos": 28, "type": "TASK", "confidence": 0.5593427419662476}]}, {"text": "This is due to at least two factors.", "labels": [], "entities": []}, {"text": "First, the SETS contain a relatively high number of verbs, and as we have seen, verbs are the most challenging POS for these two DSMs.", "labels": [], "entities": [{"text": "SETS", "start_pos": 11, "end_pos": 15, "type": "TASK", "confidence": 0.9189060926437378}]}, {"text": "Second, the sets of frame-evoking terms represent a mixture of syntactic derivation and typical paradigmatic relations, especially synonymy, and although we achieve a high MAP on both of these relations, the (hyper)parameter settings that work best for each are very different, as we will show below.", "labels": [], "entities": [{"text": "MAP", "start_pos": 172, "end_pos": 175, "type": "METRIC", "confidence": 0.9988049268722534}]}, {"text": "Now that we have assessed the quality of the results with respect to various aspects of the target application (the descriptive framework, the target relations, the POS) and compared the two DSMs, we turn our attention to the influence of their (hyper)parameters.", "labels": [], "entities": []}, {"text": "For each such parameter, we will observe the average MAP for each setting of that parameter.", "labels": [], "entities": [{"text": "MAP", "start_pos": 53, "end_pos": 56, "type": "METRIC", "confidence": 0.9853730797767639}]}, {"text": "We use the average MAP instead of the maximum in order to determine which settings produce consistently good results, regardless of the settings used for the other parameters.", "labels": [], "entities": [{"text": "MAP", "start_pos": 19, "end_pos": 22, "type": "METRIC", "confidence": 0.987759530544281}]}, {"text": "Interactions between the parameters are not accounted for in the analysis presented in this paper.", "labels": [], "entities": []}, {"text": "The influence of the window size on the accuracy of both DSMs is illustrated in.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 40, "end_pos": 48, "type": "METRIC", "confidence": 0.9995073080062866}]}, {"text": "This figure shows that for the three paradigmatic relations (QSYN, ANTI, and HYP), the optimal window size is small, i.e. 1-3 words.", "labels": [], "entities": [{"text": "ANTI", "start_pos": 67, "end_pos": 71, "type": "METRIC", "confidence": 0.8865293264389038}, {"text": "HYP", "start_pos": 77, "end_pos": 80, "type": "METRIC", "confidence": 0.9556941390037537}]}, {"text": "Though the figure does not show the results for each POS separately, this is true for every POS.", "labels": [], "entities": []}, {"text": "The optimal size is 1 for adjectives, and accuracy quickly drops off as window size increases.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 42, "end_pos": 50, "type": "METRIC", "confidence": 0.9994210004806519}]}, {"text": "The optimal size is 1 for verbs also, and 1 or 3 for nouns (BOW and W2V respectively).", "labels": [], "entities": [{"text": "BOW", "start_pos": 60, "end_pos": 63, "type": "METRIC", "confidence": 0.9888110160827637}]}, {"text": "On the other hand, the optimal window size for DRVs is quite large.", "labels": [], "entities": []}, {"text": "The average MAP does not seem to have peaked even with a window size of 10, however the maximum MAP we observed was achieved with a window of 9 words (with both models).", "labels": [], "entities": [{"text": "MAP", "start_pos": 12, "end_pos": 15, "type": "METRIC", "confidence": 0.8317394256591797}]}, {"text": "Thus, narrow windows capture paradigmatic relations most accurately, but wider windows are better for syntactic derivatives.", "labels": [], "entities": []}, {"text": "This maybe due to a tendency of syntactic derivatives to co-occur, as wider windows lead to co-occurring words having more similar distributional representations.", "labels": [], "entities": []}, {"text": "For instance, if we observe the sequence of words ax y b, then a is a context of both x and y (if the window size is at least 2), and so is b.", "labels": [], "entities": []}, {"text": "Every time x and y appear next to each other (or close enough, depending on the size of the window), they share contexts, which increases the similarity of their representations.", "labels": [], "entities": []}, {"text": "As for sets of frame-evoking terms, the window size should beat least 3, but the average MAP does not vary much with respect to window size beyond this point.", "labels": [], "entities": [{"text": "MAP", "start_pos": 89, "end_pos": 92, "type": "METRIC", "confidence": 0.9512872695922852}]}, {"text": "As the window size increases, accuracy improves on DRVs, but worsens on paradigmatic relations, such that accuracy on the SETS, which represent a mixture of these relations, remains relatively stable.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 30, "end_pos": 38, "type": "METRIC", "confidence": 0.999347984790802}, {"text": "accuracy", "start_pos": 106, "end_pos": 114, "type": "METRIC", "confidence": 0.999051034450531}]}, {"text": "The figure also shows that the influence of the window size is very similar in the BOW and W2V models.", "labels": [], "entities": [{"text": "BOW", "start_pos": 83, "end_pos": 86, "type": "DATASET", "confidence": 0.6568127870559692}]}, {"text": "We could investigate whether this is the case for other (hyper)parameters that are applicable to both models (e.g. the window shape) or can be adapted from one model to the other (e.g. context distribution smoothing for the negative sampling function ().", "labels": [], "entities": []}, {"text": "Instead of comparing the influence of the same parameters in both models, we chose to investigate the influence of a set of parameters that are typical of each model.", "labels": [], "entities": []}, {"text": "Our observations on the influence of the window size suggest that the influence of parameters that are common to both DSMs would be very similar.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Datasets used for evaluation.", "labels": [], "entities": []}, {"text": " Table 3: Average MAP of BOW models wrt to window type, window shape, and weighting scheme.  .", "labels": [], "entities": [{"text": "MAP", "start_pos": 18, "end_pos": 21, "type": "METRIC", "confidence": 0.8755859136581421}]}, {"text": " Table 4: Average MAP of W2V models wrt the architecture, the number of negative samples for training,  the threshold for subsampling and the dimensionality of word embeddings.", "labels": [], "entities": [{"text": "MAP", "start_pos": 18, "end_pos": 21, "type": "METRIC", "confidence": 0.811561107635498}]}]}