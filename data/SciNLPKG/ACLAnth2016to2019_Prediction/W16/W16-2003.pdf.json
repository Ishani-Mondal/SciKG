{"title": [{"text": "Morphological reinflection with convolutional neural networks", "labels": [], "entities": [{"text": "Morphological reinflection", "start_pos": 0, "end_pos": 26, "type": "TASK", "confidence": 0.7472574412822723}]}], "abstractContent": [{"text": "We present a system for morphological reinflection based on an encoder-decoder neural network model with extra convo-lutional layers.", "labels": [], "entities": []}, {"text": "In spite of its simplicity, the method performs reasonably well on all the languages of the SIGMORPHON 2016 shared task, particularly for the most challenging problem of limited-resources reinflection (track 2, task 3).", "labels": [], "entities": [{"text": "SIGMORPHON 2016 shared task", "start_pos": 92, "end_pos": 119, "type": "TASK", "confidence": 0.504934698343277}]}, {"text": "We also find that using only convolution achieves surprisingly good results in this task, surpassing the accuracy of our encoder-decoder model for several languages.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 105, "end_pos": 113, "type": "METRIC", "confidence": 0.9994838237762451}]}], "introductionContent": [{"text": "Morphological reinflection is the task of predicting one form from a morphological paradigm given another form, e.g. predicting the English present participle ringing given the past tense rang.", "labels": [], "entities": [{"text": "Morphological reinflection", "start_pos": 0, "end_pos": 26, "type": "TASK", "confidence": 0.8822453916072845}, {"text": "predicting the English present participle ringing", "start_pos": 117, "end_pos": 166, "type": "TASK", "confidence": 0.830298920472463}]}, {"text": "The SIGMORPHON shared task considers three variants of this problem, with decreasing amounts of information available beyond the source form and the morphological features of the target form: 1.", "labels": [], "entities": [{"text": "SIGMORPHON shared task", "start_pos": 4, "end_pos": 26, "type": "TASK", "confidence": 0.8055950403213501}]}, {"text": "The source form is always the citation form.", "labels": [], "entities": []}, {"text": "2. The source form's morphological features are not fixed, but given.", "labels": [], "entities": []}, {"text": "3. Only the source form itself is given.", "labels": [], "entities": []}, {"text": "The first and simplest case is the most wellresearched, and is essentially equivalent to the task of predicting morphological paradigms.", "labels": [], "entities": [{"text": "predicting morphological paradigms", "start_pos": 101, "end_pos": 135, "type": "TASK", "confidence": 0.8917776942253113}]}, {"text": "This paper presents our system for morphological reinflection, which was submitted for the SIG-MORPHON 2016 shared task.", "labels": [], "entities": [{"text": "morphological reinflection", "start_pos": 35, "end_pos": 61, "type": "TASK", "confidence": 0.8424636423587799}, {"text": "SIG-MORPHON 2016 shared task", "start_pos": 91, "end_pos": 119, "type": "TASK", "confidence": 0.5963894873857498}]}, {"text": "To complement the description given here, the source code of our implementation is available as free software.", "labels": [], "entities": []}], "datasetContent": [{"text": "All results reported in this section refer to accuracy, computed using the official SIGMORPHON 2016 development data and scoring script.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 46, "end_pos": 54, "type": "METRIC", "confidence": 0.9997321963310242}, {"text": "SIGMORPHON 2016 development data", "start_pos": 84, "end_pos": 116, "type": "DATASET", "confidence": 0.7988157123327255}]}, {"text": "on the following page shows the result on the official test set, and a full comparison to other systems is available on the shared task website 2 (our system is labeled 'HEL').", "labels": [], "entities": [{"text": "official test set", "start_pos": 46, "end_pos": 63, "type": "DATASET", "confidence": 0.708877166112264}, {"text": "HEL", "start_pos": 170, "end_pos": 173, "type": "METRIC", "confidence": 0.9212812185287476}]}, {"text": "We participate only in track 2, which only allows training data from the same task that is evaluated.", "labels": [], "entities": []}, {"text": "Training data from other (lower-numbered) tasks, as track 1 allows, could trivially be appended to the training data of our model, but this was not done since we focused on exploring the core problem of learning reinflection.", "labels": [], "entities": []}, {"text": "The same constraints are followed in all experiments described here.", "labels": [], "entities": []}, {"text": "Note that due to time constraints, we were notable to explore the full set of parameters before submitting the test set results.", "labels": [], "entities": []}, {"text": "Of the models that had finished training by the deadline, we chose the one which had the highest accuracy on the development set.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 97, "end_pos": 105, "type": "METRIC", "confidence": 0.9994198083877563}]}, {"text": "The results reported here are from later experiments which were carried out to systematically test the effects of our proposed changes.", "labels": [], "entities": []}, {"text": "shows that using convolutional layers improves accuracy in almost all cases, whereas adding an extra LSTM layer does not bring any systematic improvement.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 47, "end_pos": 55, "type": "METRIC", "confidence": 0.9982288479804993}]}, {"text": "Results when using only convolutional layers or convolutional layers followed by a GRU recurrent layer can be found in table 3 on the following page.", "labels": [], "entities": []}, {"text": "To our surprise, we found that convolution alone is sufficient to achieve results comparable to or better than several of the other systems in the shared task, and for some languages it beats our own submitted results.", "labels": [], "entities": []}, {"text": "There is no clear benefit across languages of adding a final GRU decoder: Results of our convolutional encoderdecoder system on the official SIGMORPHON shared task development set for task 3 (reinflection).", "labels": [], "entities": [{"text": "SIGMORPHON shared task development set", "start_pos": 141, "end_pos": 179, "type": "DATASET", "confidence": 0.6322229981422425}]}, {"text": "The first column contains results of models with both convolutions (4 layers) and deep LSTMs (2 layers), the second uses a single LSTM layer, and the third one uses no convolutional layers.", "labels": [], "entities": []}, {"text": "Language layer, but increasing the depth of the network and in particular the width of the convolution seem to benefit accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 119, "end_pos": 127, "type": "METRIC", "confidence": 0.9968016147613525}]}], "tableCaptions": [{"text": " Table 1: Results of our convolutional encoder- decoder system on the official SIGMORPHON  shared task test set.  Language  Accuracy (percent)  Task 1 Task 2 Task 3  Arabic  89.52 69.53 70.43  Finnish  95.14 88.42 87.55  Georgian  97.02 92.84 91.85  German  94.40 91.73 89.14  Hungarian 98.38 96.25 96.46  Maltese  86.16 73.17 75.54  Navajo  82.10 77.37 83.21  Russian  89.94 86.60 84.59  Spanish  98.35 95.35 94.85  Turkish  97.93 91.69 91.25", "labels": [], "entities": [{"text": "SIGMORPHON  shared task test set", "start_pos": 79, "end_pos": 111, "type": "DATASET", "confidence": 0.6818383395671844}, {"text": "Accuracy", "start_pos": 124, "end_pos": 132, "type": "METRIC", "confidence": 0.8794501423835754}, {"text": "Finnish  95.14 88.42 87.55  Georgian  97.02 92.84 91.85  German  94.40 91.73 89.14  Hungarian 98.38 96.25 96.46  Maltese  86.16 73.17 75.54  Navajo  82.10 77.37 83.21  Russian  89.94 86.60 84.59  Spanish  98.35 95.35 94.85  Turkish  97.93 91.69 91.25", "start_pos": 193, "end_pos": 443, "type": "DATASET", "confidence": 0.7160873785614967}]}, {"text": " Table 2: Results of our convolutional encoder- decoder system on the official SIGMORPHON  shared task development set for task 3 (re- inflection). The first column contains results of  models with both convolutions (4 layers) and deep  LSTMs (2 layers), the second uses a single LSTM  layer, and the third one uses no convolutional lay- ers.", "labels": [], "entities": [{"text": "SIGMORPHON  shared task development set", "start_pos": 79, "end_pos": 118, "type": "DATASET", "confidence": 0.6221189975738526}]}]}