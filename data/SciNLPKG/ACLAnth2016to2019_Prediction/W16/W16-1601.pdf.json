{"title": [{"text": "Explaining Predictions of Non-Linear Classifiers in NLP", "labels": [], "entities": [{"text": "Explaining Predictions of Non-Linear Classifiers", "start_pos": 0, "end_pos": 48, "type": "TASK", "confidence": 0.8645778656005859}]}], "abstractContent": [{"text": "Layer-wise relevance propagation (LRP) is a recently proposed technique for explaining predictions of complex non-linear classifiers in terms of input variables.", "labels": [], "entities": [{"text": "Layer-wise relevance propagation (LRP)", "start_pos": 0, "end_pos": 38, "type": "TASK", "confidence": 0.764340395728747}]}, {"text": "In this paper, we apply LRP for the first time to natural language processing (NLP).", "labels": [], "entities": [{"text": "natural language processing (NLP)", "start_pos": 50, "end_pos": 83, "type": "TASK", "confidence": 0.7937565743923187}]}, {"text": "More precisely, we use it to explain the predictions of a convolutional neural network (CNN) trained on a topic categoriza-tion task.", "labels": [], "entities": []}, {"text": "Our analysis highlights which words are relevant fora specific prediction of the CNN.", "labels": [], "entities": []}, {"text": "We compare our technique to standard sensitivity analysis, both qualitatively and quantitatively, using a \"word deleting\" perturbation experiment, a PCA analysis, and various visualizations.", "labels": [], "entities": [{"text": "word deleting\" perturbation", "start_pos": 107, "end_pos": 134, "type": "TASK", "confidence": 0.7593637257814407}]}, {"text": "All experiments validate the suitability of LRP for explaining the CNN predictions, which is also inline with results reported in recent image classification studies.", "labels": [], "entities": [{"text": "CNN predictions", "start_pos": 67, "end_pos": 82, "type": "TASK", "confidence": 0.6857322156429291}, {"text": "image classification", "start_pos": 137, "end_pos": 157, "type": "TASK", "confidence": 0.725295215845108}]}], "introductionContent": [{"text": "Following seminal work by and, the use of deep learning models for natural language processing (NLP) applications received an increasing attention in recent years.", "labels": [], "entities": []}, {"text": "In parallel, initiated by the computer vision domain, there is also a trend toward understanding deep learning models through visualization techniques) or through decision tree extraction).", "labels": [], "entities": [{"text": "decision tree extraction", "start_pos": 163, "end_pos": 187, "type": "TASK", "confidence": 0.7274713118871053}]}, {"text": "Most work dedicated to understanding neural network classifiers for NLP tasks) use gradientbased approaches.", "labels": [], "entities": [{"text": "understanding neural network classifiers for NLP tasks", "start_pos": 23, "end_pos": 77, "type": "TASK", "confidence": 0.6797514004366738}]}, {"text": "Recently, a technique called layer-wise relevance propagation (LRP) ( ) has been shown to produce more meaningful explanations in the context of image classifications ( . In this paper, we apply the same LRP technique to a NLP task, where a neural network maps a sequence of word2vec vectors representing a text document to its category, and evaluate whether similar benefits in terms of explanation quality are observed.", "labels": [], "entities": [{"text": "layer-wise relevance propagation (LRP)", "start_pos": 29, "end_pos": 67, "type": "TASK", "confidence": 0.7395674933989843}, {"text": "image classifications", "start_pos": 145, "end_pos": 166, "type": "TASK", "confidence": 0.7466107904911041}]}, {"text": "In the present work we contribute by (1) applying the LRP method to the NLP domain, (2) proposing a technique for quantitative evaluation of explanation methods for NLP classifiers, and (3) qualitatively and quantitatively comparing two different explanation methods, namely LRP and a gradient-based approach, on a topic categorization task using the 20Newsgroups dataset.", "labels": [], "entities": [{"text": "20Newsgroups dataset", "start_pos": 351, "end_pos": 371, "type": "DATASET", "confidence": 0.947242021560669}]}], "datasetContent": [{"text": "For the following experiments we use the 20news-bydate version of the 20Newsgroups 2 dataset consisting of 11314/7532 train/test documents evenly distributed among twenty fine-grained categories.", "labels": [], "entities": [{"text": "20news-bydate version of the 20Newsgroups 2 dataset", "start_pos": 41, "end_pos": 92, "type": "DATASET", "confidence": 0.722387296812875}]}, {"text": "As pre-processing we remove the document headers, tokenize the text with NLTK 4 , filter out punctuation and numbers 5 , and finally truncate each document to the first 400 tokens.", "labels": [], "entities": []}, {"text": "We train the CNN by stochastic mini-batch gradient descent with momentum (with l 2 -norm penalty and dropout).", "labels": [], "entities": []}, {"text": "Our trained classifier achieves a classification accuracy of 80.19% 6 . Due to our input representation, applying LRP or SA to our neural classifier yields one relevance value per word-embedding dimension.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 49, "end_pos": 57, "type": "METRIC", "confidence": 0.9693687558174133}]}, {"text": "From these single input variable relevances to obtain wordlevel relevances, we sum up the relevances over the word embedding space in case of LRP, and (unless otherwise stated) take the squared l 2 -norm of the corresponding word gradient in case of SA.", "labels": [], "entities": []}, {"text": "More precisely, given an input document d consisting of a sequence (w 1 , w 2 , ..., w N ) of N words, each word being represented by a Ddimensional word embedding, we compute the relevance R(w t ) of the t th word in the input document, through the summation: where R i,t denotes the relevance of the input variable corresponding to the i th dimension of the t th word embedding, obtained by LRP or SA as specified in Sections 2.1 & 2.2.", "labels": [], "entities": []}, {"text": "We employ NLTK's version 3.1 recommended tokenizers sent tokenize and word tokenize, module nltk.tokenize.", "labels": [], "entities": []}, {"text": "We retain only tokens composed of the following characters: alphabetic-character, apostrophe, hyphen and dot, and containing at least one alphabetic-character.", "labels": [], "entities": []}, {"text": "To the best of our knowledge, the best published 20Newsgroups accuracy is 83.0% ().", "labels": [], "entities": [{"text": "20Newsgroups", "start_pos": 49, "end_pos": 61, "type": "DATASET", "confidence": 0.7594894170761108}, {"text": "accuracy", "start_pos": 62, "end_pos": 70, "type": "METRIC", "confidence": 0.9681622385978699}]}, {"text": "However we notice that for simplification we use a fixed-length document representation, and our main focus is on explaining classifier decisions, not on improving the classification state-of-the-art.", "labels": [], "entities": []}, {"text": "In particular, in case of SA, the above word relevance can equivalently be expressed as: where f (d) represents the classifier's prediction for document d.", "labels": [], "entities": []}, {"text": "Note that the resulting LRP word relevance is signed, while the SA word relevance is positive.", "labels": [], "entities": [{"text": "SA word relevance", "start_pos": 64, "end_pos": 81, "type": "METRIC", "confidence": 0.6999062895774841}]}, {"text": "In all experiments, we use the term target class to identify the function f (x) to analyze in the relevance decomposition.", "labels": [], "entities": []}, {"text": "This function maps the neural network input to the neural network output variable corresponding to the target class.", "labels": [], "entities": []}], "tableCaptions": []}