{"title": [{"text": "An Attentive Neural Architecture for Fine-grained Entity Type Classification", "labels": [], "entities": []}], "abstractContent": [{"text": "In this work we propose a novel attention-based neural network model for the task of fine-grained entity type classification that unlike previously proposed models recursively composes representations of entity mention contexts.", "labels": [], "entities": [{"text": "entity type classification", "start_pos": 98, "end_pos": 124, "type": "TASK", "confidence": 0.657246987024943}]}, {"text": "Our model achieves state-of-the-art performance with 74.94% loose micro F1-score on the well-established FIGER dataset, a relative improvement of 2.59%.", "labels": [], "entities": [{"text": "F1-score", "start_pos": 72, "end_pos": 80, "type": "METRIC", "confidence": 0.8466513752937317}, {"text": "FIGER dataset", "start_pos": 105, "end_pos": 118, "type": "DATASET", "confidence": 0.7911173403263092}]}, {"text": "We also investigate the behavior of the attention mechanism of our model and observe that it can learn contextual linguistic expressions that indicate the fine-grained category memberships of an entity.", "labels": [], "entities": []}], "introductionContent": [{"text": "Entity type classification is the task of assigning semantic types to mentions of entities in sentences.", "labels": [], "entities": [{"text": "Entity type classification", "start_pos": 0, "end_pos": 26, "type": "TASK", "confidence": 0.8423423767089844}, {"text": "assigning semantic types to mentions of entities in sentences", "start_pos": 42, "end_pos": 103, "type": "TASK", "confidence": 0.6633925437927246}]}, {"text": "Identifying the types of entities is useful for various natural language processing tasks, such as relation extraction), question answering (), and knowledge base population (.", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 99, "end_pos": 118, "type": "TASK", "confidence": 0.8173794150352478}, {"text": "question answering", "start_pos": 121, "end_pos": 139, "type": "TASK", "confidence": 0.9155982434749603}]}, {"text": "Unfortunately, most entity type classification systems use a relatively small number of types (e.g. person, organization, location, time, and miscellaneous) which maybe too coarse-grained for some NLP applications.", "labels": [], "entities": [{"text": "entity type classification", "start_pos": 20, "end_pos": 46, "type": "TASK", "confidence": 0.6987537940343221}]}, {"text": "To address this shortcoming, a series of recent work has investigated entity type classification with a large set of fine-grained types (Lee et al.,: An illustration of our proposed model predicting finegrained semantic types for the mention \"New York\" in the sentence \"She got a Ph.D from New York in 2006;.", "labels": [], "entities": [{"text": "entity type classification", "start_pos": 70, "end_pos": 96, "type": "TASK", "confidence": 0.750155508518219}]}, {"text": "Existing fine-grained entity type classification systems have used approaches ranging from sparse binary features to dense vector representations of entities to model the entity mention and its context.", "labels": [], "entities": [{"text": "entity type classification", "start_pos": 22, "end_pos": 48, "type": "TASK", "confidence": 0.698995570341746}]}, {"text": "However, no previously proposed system has attempted to learn to recursively compose representations of entity context.", "labels": [], "entities": []}, {"text": "For example, one can see that a phrase \"got a Ph.D. from\" is indicative of the next words being an educational institution, something which would be helpful for fine-grained entity type classification.", "labels": [], "entities": [{"text": "fine-grained entity type classification", "start_pos": 161, "end_pos": 200, "type": "TASK", "confidence": 0.6720132827758789}]}, {"text": "In this work our main contributions are two-fold: 1.", "labels": [], "entities": []}, {"text": "A first model for fine-grained entity type classification that learns to recursively compose representations for the context of each mention and attains state-of-the-art performance on a well-established dataset.", "labels": [], "entities": [{"text": "fine-grained entity type classification", "start_pos": 18, "end_pos": 57, "type": "TASK", "confidence": 0.6452498883008957}]}, {"text": "2. The observation that by incorporating an attention mechanism into our model, we not only achieve better performance, but also are able to observe that the model learns contextual linguistic expressions that indicate fine-grained category memberships of an entity.", "labels": [], "entities": []}], "datasetContent": [{"text": "To train and evaluate our model we use the publicly available FIGER dataset with 112 fine-grained types from.", "labels": [], "entities": [{"text": "FIGER dataset", "start_pos": 62, "end_pos": 75, "type": "DATASET", "confidence": 0.7748417258262634}]}, {"text": "The sizes of our datasets are 2, 600, 000 for training, 90, 000 for development, and 563 for testing.", "labels": [], "entities": []}, {"text": "Note that the train and development sets were created from Wikipedia, whereas the test set is a manually annotated dataset of newspaper articles.", "labels": [], "entities": []}, {"text": "Following, we evaluate the model performances by strict, loose macro, and loose micro measures.", "labels": [], "entities": []}, {"text": "For the i-th instance, let the set of the predicted types b\u00ea Ti , and the set of the true types be Ti . Then the precisions and recall for each measure are computed as follows.", "labels": [], "entities": [{"text": "precisions", "start_pos": 113, "end_pos": 123, "type": "METRIC", "confidence": 0.9985664486885071}, {"text": "recall", "start_pos": 128, "end_pos": 134, "type": "METRIC", "confidence": 0.9989684820175171}]}, {"text": "\u2022 strict \u2022 loose macro \u2022 loose micro Where N is the total number of instances.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Loose Micro Precision (P), Recall (R), and F1-score", "labels": [], "entities": [{"text": "Loose Micro Precision (P)", "start_pos": 10, "end_pos": 35, "type": "METRIC", "confidence": 0.745548889040947}, {"text": "Recall (R)", "start_pos": 37, "end_pos": 47, "type": "METRIC", "confidence": 0.9686131924390793}, {"text": "F1-score", "start_pos": 53, "end_pos": 61, "type": "METRIC", "confidence": 0.9993570446968079}]}, {"text": " Table 2: Strict, Loose Macro and Loose Micro F1-scores", "labels": [], "entities": [{"text": "Loose Micro F1-scores", "start_pos": 34, "end_pos": 55, "type": "METRIC", "confidence": 0.5446315904458364}]}]}