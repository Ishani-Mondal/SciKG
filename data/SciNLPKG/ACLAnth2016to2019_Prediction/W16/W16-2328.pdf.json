{"title": [], "abstractContent": [{"text": "In this paper, we attempt to improve Statistical Machine Translation (SMT) systems between Czech and English.", "labels": [], "entities": [{"text": "Statistical Machine Translation (SMT)", "start_pos": 37, "end_pos": 74, "type": "TASK", "confidence": 0.8459720114866892}]}, {"text": "To accomplish this, we performed translation model training, created adaptations of training settings for each language pair, and obtained comparable corpora for our SMT systems.", "labels": [], "entities": [{"text": "translation model training", "start_pos": 33, "end_pos": 59, "type": "TASK", "confidence": 0.9007837573687235}, {"text": "SMT", "start_pos": 166, "end_pos": 169, "type": "TASK", "confidence": 0.9830507636070251}]}, {"text": "Innovative tools and data adaptation techniques were employed.", "labels": [], "entities": [{"text": "data adaptation", "start_pos": 21, "end_pos": 36, "type": "TASK", "confidence": 0.7652490735054016}]}, {"text": "Only the official parallel text corpora and monolingual models for the WMT 2016 evaluation campaign were used to train language models, and to develop, tune, and test the system.", "labels": [], "entities": [{"text": "WMT 2016 evaluation campaign", "start_pos": 71, "end_pos": 99, "type": "DATASET", "confidence": 0.6750268414616585}]}, {"text": "We explored the use of domain adaptation techniques, symme-trized word alignment models, the unsu-pervised transliteration models and the KenLM language modeling tool.", "labels": [], "entities": [{"text": "domain adaptation", "start_pos": 23, "end_pos": 40, "type": "TASK", "confidence": 0.7447878122329712}, {"text": "symme-trized word alignment", "start_pos": 53, "end_pos": 80, "type": "TASK", "confidence": 0.6064323882261912}, {"text": "KenLM language modeling", "start_pos": 138, "end_pos": 161, "type": "TASK", "confidence": 0.6505759954452515}]}, {"text": "To evaluate the effects of different preparations on translation results, we conducted experiments and used the BLEU, NIST and TER metrics.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 112, "end_pos": 116, "type": "METRIC", "confidence": 0.9984601736068726}, {"text": "NIST", "start_pos": 118, "end_pos": 122, "type": "DATASET", "confidence": 0.8446438312530518}, {"text": "TER", "start_pos": 127, "end_pos": 130, "type": "METRIC", "confidence": 0.9957774877548218}]}, {"text": "Our results indicate that our approach produced a positive impact on SMT quality.", "labels": [], "entities": [{"text": "SMT", "start_pos": 69, "end_pos": 72, "type": "TASK", "confidence": 0.9970695376396179}]}], "introductionContent": [{"text": "Statistical Machine Translation (SMT) must deal with a number of problems to achieve high quality.", "labels": [], "entities": [{"text": "Statistical Machine Translation (SMT", "start_pos": 0, "end_pos": 36, "type": "TASK", "confidence": 0.8518813014030456}]}, {"text": "These problems include the need to align parallel texts in language pairs and cleaning harvested parallel corpora to remove errors.", "labels": [], "entities": []}, {"text": "This is especially true for real-world corpora developed from text harvested from the vast data available on the Internet.", "labels": [], "entities": []}, {"text": "Out-Of-Vocabulary (OOV) words must also be handled, as they are inevitable in real-world texts.", "labels": [], "entities": []}, {"text": "The lack of enough parallel corpora is another significant challenge for SMT.", "labels": [], "entities": [{"text": "SMT", "start_pos": 73, "end_pos": 76, "type": "TASK", "confidence": 0.9959302544593811}]}, {"text": "Since the approach is statistical in nature, a significant amount of quality language pair data is needed to improve translation accuracy.", "labels": [], "entities": [{"text": "translation", "start_pos": 117, "end_pos": 128, "type": "TASK", "confidence": 0.9573338031768799}, {"text": "accuracy", "start_pos": 129, "end_pos": 137, "type": "METRIC", "confidence": 0.7372817397117615}]}, {"text": "In addition, very general translation systems that work in a general text domain have accuracy problems in specific domains.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 86, "end_pos": 94, "type": "METRIC", "confidence": 0.9961583018302917}]}, {"text": "SMT systems are more accurate on corpora from a domain that is not too wide.", "labels": [], "entities": [{"text": "SMT", "start_pos": 0, "end_pos": 3, "type": "TASK", "confidence": 0.9839682579040527}]}, {"text": "This exacerbates the data problem, calling for the enhancement of parallel corpora for particular text domains.", "labels": [], "entities": []}, {"text": "This paper describes SMT research that addresses these problems, particularly domain adaptation within the limits of permissible data for the WMT 2016 campaign.", "labels": [], "entities": [{"text": "SMT", "start_pos": 21, "end_pos": 24, "type": "TASK", "confidence": 0.9965435862541199}, {"text": "domain adaptation", "start_pos": 78, "end_pos": 95, "type": "TASK", "confidence": 0.7416275441646576}, {"text": "WMT 2016 campaign", "start_pos": 142, "end_pos": 159, "type": "TASK", "confidence": 0.6757650772730509}]}, {"text": "To accomplish this, we performed model training, created adaptations of training settings and data for each language pair.", "labels": [], "entities": []}, {"text": "Innovative tools and data adaptation techniques were employed.", "labels": [], "entities": [{"text": "data adaptation", "start_pos": 21, "end_pos": 36, "type": "TASK", "confidence": 0.7652490735054016}]}, {"text": "We explored the use of domain adaptation techniques, symmetrized word alignment models, the unsupervised transliteration models, and the KenLM language modeling tool.", "labels": [], "entities": [{"text": "domain adaptation", "start_pos": 23, "end_pos": 40, "type": "TASK", "confidence": 0.7362408638000488}, {"text": "word alignment", "start_pos": 65, "end_pos": 79, "type": "TASK", "confidence": 0.6853843629360199}, {"text": "KenLM language modeling", "start_pos": 137, "end_pos": 160, "type": "TASK", "confidence": 0.6549652616182963}]}, {"text": "To evaluate the effects of different preparations on translation results, we conducted experiments and evaluated the results using standard SMT metrics (.", "labels": [], "entities": [{"text": "SMT", "start_pos": 140, "end_pos": 143, "type": "TASK", "confidence": 0.9894416332244873}]}, {"text": "The languages translated during this research were: Czech, and English, in both directions.", "labels": [], "entities": []}, {"text": "Czech is found in the Slavic branch of that language family.", "labels": [], "entities": []}, {"text": "English falls in the Western group This paper is structured as follows: Section 2 explains the data preparation.", "labels": [], "entities": []}, {"text": "Section 3 presents experiment setup and the results.", "labels": [], "entities": []}, {"text": "Lastly in Section 4 we summarize the work.", "labels": [], "entities": []}], "datasetContent": [{"text": "Various versions of our SMT systems were evaluated via experimentation.", "labels": [], "entities": [{"text": "SMT", "start_pos": 24, "end_pos": 27, "type": "TASK", "confidence": 0.9912817478179932}]}, {"text": "In preparation for experiments, we processed the corpora.", "labels": [], "entities": []}, {"text": "This involved tokenization, cleaning, factorization, conversion to lowercase, splitting, and final cleaning after splitting.", "labels": [], "entities": []}, {"text": "Language models were developed and tuned using the training data.", "labels": [], "entities": []}, {"text": "The Experiment Management System () from the open source Moses SMT toolkit was used to conduct the experiments.", "labels": [], "entities": []}, {"text": "Training of a 6-gram language model was accomplished our resulting systems using the KenLM Modeling Toolkit instead of 5-gram SRILM) with an interpolated version of Kneser-Key discounting (interpolateunk -kndiscount) that was used in our baseline systems.", "labels": [], "entities": [{"text": "KenLM Modeling Toolkit", "start_pos": 85, "end_pos": 107, "type": "DATASET", "confidence": 0.7286712328592936}]}, {"text": "Word and phrase alignment was performed using SyMGIZA++ (Junczys-Dowmunt and Sza\u0142, 2012) instead of GIZA++.", "labels": [], "entities": [{"text": "Word and phrase alignment", "start_pos": 0, "end_pos": 25, "type": "TASK", "confidence": 0.5629277527332306}]}, {"text": "KenLM was also used, as described earlier, to binarize the language models.", "labels": [], "entities": []}, {"text": "The OOV's were handled by using Unsupervised Transliteration Model.", "labels": [], "entities": []}, {"text": "The results are shown in.", "labels": [], "entities": []}, {"text": "Each language pair was translated in both directions.", "labels": [], "entities": []}, {"text": "\"BASE\" in the tables represents the baseline SMT system.", "labels": [], "entities": [{"text": "BASE", "start_pos": 1, "end_pos": 5, "type": "METRIC", "confidence": 0.9990885257720947}, {"text": "SMT", "start_pos": 45, "end_pos": 48, "type": "TASK", "confidence": 0.9889847040176392}]}, {"text": "\"EXT\" indicates results for the baseline system, using the baseline settings but extended with additional permissible data (limited to parallel Europarl v7, Common Crawl, News Commentary, CzEng and monolingual News Crawl 07-15) with data adaptation.", "labels": [], "entities": [{"text": "EXT", "start_pos": 1, "end_pos": 4, "type": "METRIC", "confidence": 0.914385199546814}, {"text": "Europarl", "start_pos": 144, "end_pos": 152, "type": "DATASET", "confidence": 0.9745622873306274}, {"text": "News Crawl 07-15", "start_pos": 210, "end_pos": 226, "type": "DATASET", "confidence": 0.8280634681383768}, {"text": "data adaptation", "start_pos": 233, "end_pos": 248, "type": "TASK", "confidence": 0.7292452752590179}]}, {"text": "\"BEST\" indicates the results when the new SMT settings were applied and using all permissible data after data adaptation.", "labels": [], "entities": [{"text": "BEST", "start_pos": 1, "end_pos": 5, "type": "METRIC", "confidence": 0.9994440674781799}, {"text": "SMT", "start_pos": 42, "end_pos": 45, "type": "TASK", "confidence": 0.9868038296699524}]}, {"text": "Three well-known metrics were used for scoring the results: Bilingual Evaluation Understudy (BLEU), the US National Institute of Standards and Technology (NIST) metric and Translation Error Rate (TER).", "labels": [], "entities": [{"text": "Bilingual Evaluation Understudy (BLEU)", "start_pos": 60, "end_pos": 98, "type": "METRIC", "confidence": 0.8423967063426971}, {"text": "Translation Error Rate (TER)", "start_pos": 172, "end_pos": 200, "type": "METRIC", "confidence": 0.8944202760855356}]}, {"text": "The results show that the systems performed well on all data sets in comparison to the baseline SMT systems.", "labels": [], "entities": [{"text": "SMT", "start_pos": 96, "end_pos": 99, "type": "TASK", "confidence": 0.986785352230072}]}, {"text": "Application of the new settings and use of all permissible data improved performance even more.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1. Each lan- guage pair was translated in both directions.  \"BASE\" in the tables represents the baseline  SMT system. \"EXT\" indicates results for the  baseline system, using the baseline settings but  extended with additional permissible data (lim- ited to parallel Europarl v7, Common Crawl,", "labels": [], "entities": [{"text": "BASE", "start_pos": 68, "end_pos": 72, "type": "METRIC", "confidence": 0.9993205070495605}, {"text": "SMT", "start_pos": 113, "end_pos": 116, "type": "TASK", "confidence": 0.9688991904258728}, {"text": "EXT", "start_pos": 126, "end_pos": 129, "type": "METRIC", "confidence": 0.9549477696418762}, {"text": "Europarl", "start_pos": 273, "end_pos": 281, "type": "DATASET", "confidence": 0.9544379711151123}, {"text": "Common Crawl", "start_pos": 286, "end_pos": 298, "type": "DATASET", "confidence": 0.8976863920688629}]}, {"text": " Table 1: Progressive Results, 2014 Test Data", "labels": [], "entities": [{"text": "2014 Test Data", "start_pos": 31, "end_pos": 45, "type": "DATASET", "confidence": 0.8466421167055765}]}]}