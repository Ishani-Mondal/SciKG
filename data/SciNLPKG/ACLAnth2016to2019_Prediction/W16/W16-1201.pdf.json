{"title": [{"text": "Learning Cross-lingual Representations with Matrix Factorization", "labels": [], "entities": [{"text": "Cross-lingual Representations", "start_pos": 9, "end_pos": 38, "type": "TASK", "confidence": 0.631711021065712}]}], "abstractContent": [{"text": "We present a matrix factorization model for learning cross-lingual representations.", "labels": [], "entities": []}, {"text": "Using sentence-aligned corpora, the proposed model learns distributed representations by factoring the given data into language-dependent factors and one shared factor.", "labels": [], "entities": []}, {"text": "Moreover, the model can quickly learn shared representations for more than two languages without undermining the quality of the monolingual components.", "labels": [], "entities": []}, {"text": "The model achieves an accuracy of 88% on English to German cross-lingual document classification, and 0.8 Pearson correlation on Spanish-English cross-lingual semantic textual similarity.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 22, "end_pos": 30, "type": "METRIC", "confidence": 0.9995692372322083}, {"text": "English to German cross-lingual document classification", "start_pos": 41, "end_pos": 96, "type": "TASK", "confidence": 0.585503434141477}, {"text": "Pearson correlation", "start_pos": 106, "end_pos": 125, "type": "METRIC", "confidence": 0.9557453989982605}]}, {"text": "While the results do not beat state-of-the-art performance in these tasks, we show that the crosslingual models are at least as good as their monolingual counterparts .", "labels": [], "entities": []}], "introductionContent": [{"text": "A large body of NLP research in recent years has focused on representing natural language words and phrases in high-dimensional continuous vector spaces.", "labels": [], "entities": []}, {"text": "Such representations can be integrated with various NLP applications as they can be easily learned, processed, and compared, often in an unsupervised or semi-supervised manner.", "labels": [], "entities": []}, {"text": "Distributed representations of words, or word embeddings, can be learned using global word co-occurrence statistics as in matrix factorization models), or using local context as in neural probabilistic language models).", "labels": [], "entities": []}, {"text": "Compared to word embeddings, representing variable-length sequences using a vector space model is more challenging since these vectors need to encode complex semantic structures and relationships.", "labels": [], "entities": []}, {"text": "Several models have been proposed for learning phrase and sentence embeddings, either by combining word embeddings () or directly learning the sentence representations ().", "labels": [], "entities": []}, {"text": "In our global world of information, many NLP problems exist in multilingual and cross-lingual settings.", "labels": [], "entities": []}, {"text": "It is often desirable to generalize sentence representations to several languages such that sentences conveying the same meaning in any language are clustered together and potentially mapped to one another in the semantic space.", "labels": [], "entities": []}, {"text": "Such cross-lingual representations can then be used directly in NLP applications such as machine translation and crosslingual question answering.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 89, "end_pos": 108, "type": "TASK", "confidence": 0.8291436731815338}, {"text": "crosslingual question answering", "start_pos": 113, "end_pos": 144, "type": "TASK", "confidence": 0.6654965281486511}]}, {"text": "They can also be used to learn classifiers that generalize to languages beyond the ones used in training.", "labels": [], "entities": []}, {"text": "A number of models have recently been proposed for learning cross-lingual compositional representations (.", "labels": [], "entities": []}, {"text": "We propose a relatively simple and nuanced model inspired by the monolingual weighted matrix factorization (WMF) model proposed in, which we extend to the cross-lingual setting.", "labels": [], "entities": []}, {"text": "The WMF model learns word representations by decomposing a sparse tf-idf matrix into two lowrank factor matrices representing words and sen-1 tences.", "labels": [], "entities": []}, {"text": "The weights are adjusted to reflect the confidence levels in reconstructing observed vs. missing words in the original matrix.", "labels": [], "entities": []}, {"text": "Representations for variable-length sequences can be calculated by minimizing the reconstruction error as described in Section 2.1.", "labels": [], "entities": []}, {"text": "In this paper, we propose to extend this model to the cross-lingual setting by modeling two languages in parallel to obtain shared semantic representations.", "labels": [], "entities": []}, {"text": "The proposed model has a simple loss function and only uses sentence-aligned data for learning the shared representations.", "labels": [], "entities": []}, {"text": "Furthermore, the model can be readily extended to multiple languages without loss of quality.", "labels": [], "entities": []}, {"text": "We describe the model in two variations in Section 2.2.", "labels": [], "entities": []}, {"text": "We evaluate the quality of these representations using the cross-lingual document classification task, where a multi-class perceptron is trained to classify documents into four categories.", "labels": [], "entities": [{"text": "cross-lingual document classification", "start_pos": 59, "end_pos": 96, "type": "TASK", "confidence": 0.6077443957328796}]}, {"text": "Using German and English labeled short documents, the classifier is trained on one language and tested on the other.", "labels": [], "entities": []}, {"text": "Using the compositional representations generated by our model, we achieve an accuracy of 88% in the English\u2192German classification task.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 78, "end_pos": 86, "type": "METRIC", "confidence": 0.9996451139450073}, {"text": "English\u2192German classification", "start_pos": 101, "end_pos": 130, "type": "TASK", "confidence": 0.5071609392762184}]}, {"text": "We also evaluate on the Semeval cross-lingual semantic textual similarity (STS) task, where we assign a similarity score to pairs of English and Spanish sentences.", "labels": [], "entities": [{"text": "Semeval cross-lingual semantic textual similarity (STS)", "start_pos": 24, "end_pos": 79, "type": "TASK", "confidence": 0.7102572843432426}]}, {"text": "Our model yields a performance of 0.8 Pearson correlation in this task.", "labels": [], "entities": [{"text": "Pearson correlation", "start_pos": 38, "end_pos": 57, "type": "METRIC", "confidence": 0.9552444815635681}]}], "datasetContent": [{"text": "We evaluate our crosslingual models in two empirical evaluation settings: Crosslingual Semantic Textual Similarity (STS), and Cross-lingual Document Classification (CLDC).", "labels": [], "entities": [{"text": "Crosslingual Semantic Textual Similarity (STS)", "start_pos": 74, "end_pos": 120, "type": "TASK", "confidence": 0.6772771605423519}, {"text": "Cross-lingual Document Classification (CLDC)", "start_pos": 126, "end_pos": 170, "type": "TASK", "confidence": 0.8086465746164322}]}, {"text": "We evaluate the performance of the monolingual components learned using BMF or CMF models on the Semeval monolingual Spanish semantic textual similarity (STS) task, namely STS 2014 and STS  2015.", "labels": [], "entities": [{"text": "BMF", "start_pos": 72, "end_pos": 75, "type": "METRIC", "confidence": 0.8799208998680115}, {"text": "Semeval monolingual Spanish semantic textual similarity (STS) task", "start_pos": 97, "end_pos": 163, "type": "TASK", "confidence": 0.7918632626533508}]}, {"text": "The objective of this evaluation is to check whether the quality is hurt by forcing the factors into a shared semantic space.", "labels": [], "entities": []}, {"text": "We train two monolingual models: Mono WMF: We train a monolingual Spanish WMF model using the Spanish component of the parallel training set, which consists of 1M sentences.", "labels": [], "entities": []}, {"text": "This is the same set used to train the cross-lingual models, so the results are comparable.", "labels": [], "entities": []}, {"text": "WMF*: We train another Spanish WMF model with a more varied training set, similar in construction to the English monolingual model.", "labels": [], "entities": [{"text": "WMF", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.8690457344055176}]}, {"text": "This training set includes Wikipedia and newswire articles, so it's more similar to the test set.", "labels": [], "entities": []}, {"text": "This set consists of about 400K sentences extracted from the second edition of Spanish Gigawords () and the Spanish Wikipedia Corpus ().", "labels": [], "entities": [{"text": "Spanish Gigawords", "start_pos": 79, "end_pos": 96, "type": "DATASET", "confidence": 0.8788758814334869}, {"text": "Spanish Wikipedia Corpus", "start_pos": 108, "end_pos": 132, "type": "DATASET", "confidence": 0.8893696268399557}]}, {"text": "We use the same values for all the parameters, and we run ALS for 20 iterations.", "labels": [], "entities": [{"text": "ALS", "start_pos": 58, "end_pos": 61, "type": "METRIC", "confidence": 0.7283020615577698}]}, {"text": "shows the results on Semeval Spanish STS 2014 dataset, which includes sentence pairs extracted from Spanish Wikipedia and news articles.", "labels": [], "entities": [{"text": "Semeval Spanish STS 2014 dataset", "start_pos": 21, "end_pos": 53, "type": "DATASET", "confidence": 0.6997770607471466}]}, {"text": "We also show the results on the harder 2015 dataset, which intentionally includes sentence pairs with higher degree of difficulty, such as sentences with shared vocabulary but different compositional meaning.", "labels": [], "entities": [{"text": "harder 2015 dataset", "start_pos": 32, "end_pos": 51, "type": "DATASET", "confidence": 0.7945634722709656}]}, {"text": "The first row depicts the results obtained by the top system participating in the Semeval task, Semeval Best.", "labels": [], "entities": [{"text": "Semeval task", "start_pos": 82, "end_pos": 94, "type": "TASK", "confidence": 0.8770365417003632}]}, {"text": "While none of our models outperforms the official Semeval top ranking system, Semeval Best, we show that the Spanish models trained using the BMF and CMF models actually outperform the monolingual Spanish model (mono-WMF) when we use the same dataset for training.", "labels": [], "entities": [{"text": "Semeval Best", "start_pos": 78, "end_pos": 90, "type": "DATASET", "confidence": 0.8177714049816132}, {"text": "BMF", "start_pos": 142, "end_pos": 145, "type": "DATASET", "confidence": 0.580401599407196}]}, {"text": "The advantage of a monolingual model, however, is that it can be trained using more   varied training data, as evident by the higher performance of WMF * , outperforming our cross-lingual derived models.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Cross-lingual STS EN-SP Test results using Pearson", "labels": [], "entities": [{"text": "Cross-lingual STS EN-SP", "start_pos": 10, "end_pos": 33, "type": "TASK", "confidence": 0.6519847710927328}]}, {"text": " Table 3: Performance on STS 2014 (WK14, NW14) and STS", "labels": [], "entities": [{"text": "WK14, NW14)", "start_pos": 35, "end_pos": 46, "type": "DATASET", "confidence": 0.7913555204868317}, {"text": "STS", "start_pos": 51, "end_pos": 54, "type": "DATASET", "confidence": 0.6241117715835571}]}, {"text": " Table 4: Cross-lingual document classification accuracy", "labels": [], "entities": [{"text": "Cross-lingual document classification", "start_pos": 10, "end_pos": 47, "type": "TASK", "confidence": 0.7369879086812338}]}]}