{"title": [], "abstractContent": [{"text": "The article describes LIMSI's submission to the first WMT'16 shared biomed-ical translation task, focusing on the sole English-French translation direction.", "labels": [], "entities": [{"text": "WMT'16 shared biomed-ical translation task", "start_pos": 54, "end_pos": 96, "type": "TASK", "confidence": 0.7149849534034729}]}, {"text": "Our main submission is the output of a MOSES-based statistical machine translation (SMT) system, rescored with Struc-tured OUtput Layer (SOUL) neural network models.", "labels": [], "entities": [{"text": "MOSES-based statistical machine translation (SMT)", "start_pos": 39, "end_pos": 88, "type": "TASK", "confidence": 0.7432438220296588}]}, {"text": "We also present an attempt to circumvent syntactic complexity: our proposal combines the outputs of PB-SMT systems trained either to translate entire source sentences or specific syntactic constructs extracted from those sentences.", "labels": [], "entities": []}, {"text": "The approach is implemented using Confusion Network (CN) decoding.", "labels": [], "entities": []}, {"text": "The quality of the combined output is comparable to the quality of our main system.", "labels": [], "entities": []}], "introductionContent": [{"text": "The paper provides the details of LIMSI's submission to the first shared biomedical translation task at WMT'16.", "labels": [], "entities": [{"text": "biomedical translation task at WMT'16", "start_pos": 73, "end_pos": 110, "type": "TASK", "confidence": 0.7496885836124421}]}, {"text": "For our main submission we built a phrase-based statistical machine translation (SMT) system using MOSES and attempted to improve the quality of its output by rescoring its n-best list with Structured OUtput Layer (SOUL) neural network models.", "labels": [], "entities": [{"text": "phrase-based statistical machine translation (SMT)", "start_pos": 35, "end_pos": 85, "type": "TASK", "confidence": 0.7314976028033665}, {"text": "MOSES", "start_pos": 99, "end_pos": 104, "type": "DATASET", "confidence": 0.8268445730209351}]}, {"text": "Our secondary submission was designed to mitigate the negative effects of syntactic complexity of sentences.", "labels": [], "entities": []}, {"text": "This complexity creates a challenge for the phrase-based SMT (PBSMT) paradigm that only sees a sentence as a sequential structure.", "labels": [], "entities": [{"text": "SMT (PBSMT) paradigm", "start_pos": 57, "end_pos": 77, "type": "TASK", "confidence": 0.7922960877418518}]}, {"text": "To overcome this problem, the output of PB-SMT systems can be combined with the output of \"syntax-aware\" MT systems).", "labels": [], "entities": []}, {"text": "As the building of the latter type of systems can be costly, we propose a light-weight alternative that combines the outputs of several PBSMT systems trained for the translation of (a) entire sentences, and (b) separate continuous and discontinuous syntactic constructions extracted from those sentences.", "labels": [], "entities": []}, {"text": "The combination is performed using confusion network (CN) decoding.", "labels": [], "entities": []}, {"text": "The quantitative difference with the baseline is rather small, but our comparative analysis of this system allows us to better understand its potential and limitations.", "labels": [], "entities": []}], "datasetContent": [{"text": "BLEU scores () are computed using the cased multi-bleu.perl script and our own tokenizer for reference translations .  The resulting CN-DECODING 300-best lists were compared to the 300-best lists of the baseline system.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 0, "end_pos": 4, "type": "METRIC", "confidence": 0.9859463572502136}]}, {"text": "On average, 11% of unique 1-grams from each CN-DECODING hypothesis search space are new (see), a significant proportion of novelty relative to our baseline system.", "labels": [], "entities": [{"text": "novelty", "start_pos": 123, "end_pos": 130, "type": "METRIC", "confidence": 0.9879125952720642}]}, {"text": "We also compared our approach to the MOSES xml-mode that enables to propose to the decoder alternative partial translations with their proba-: Average % of new unique n-gram per CN-DECODING hypothesis (using 300-best lists) LIMSITEST2-ABS). bility.", "labels": [], "entities": [{"text": "LIMSITEST2-ABS", "start_pos": 224, "end_pos": 238, "type": "METRIC", "confidence": 0.8820550441741943}, {"text": "bility", "start_pos": 241, "end_pos": 247, "type": "METRIC", "confidence": 0.8516483902931213}]}, {"text": "Using 30-best lists of NP-SMT translations reranked by SOUL, we marked the source sentences with possible NP translations which competed with PT choices (inclusive option).", "labels": [], "entities": [{"text": "SOUL", "start_pos": 55, "end_pos": 59, "type": "DATASET", "confidence": 0.762807309627533}, {"text": "PT", "start_pos": 142, "end_pos": 144, "type": "METRIC", "confidence": 0.9306790828704834}]}, {"text": "Each NP translation variant was assigned a probability proportional to the 0<n\u2264lnp P (u n |\u03b5) of the 1-grams u n composing it.", "labels": [], "entities": []}, {"text": "CN-DECODING decoding was performed according to the configuration described in Section 4.1, with the 30-best NP-SMT list reranked by SOUL.", "labels": [], "entities": []}, {"text": "Results in  For the remaining CN-DECODING experiments, the 30-best lists of each system are reranked by SOUL prior to system combination.", "labels": [], "entities": [{"text": "SOUL", "start_pos": 104, "end_pos": 108, "type": "METRIC", "confidence": 0.9829723238945007}]}, {"text": "We noticed that the NP-SMT and NP-Reduced-SMT hypotheses tend to be shorter than the corresponding local translations in the baseline output.", "labels": [], "entities": []}, {"text": "We tried to reduce the negative impact on quality and avoided aligning baseline words to NULL in the CN-DECODING alignment procedure.", "labels": [], "entities": [{"text": "CN-DECODING alignment", "start_pos": 101, "end_pos": 122, "type": "TASK", "confidence": 0.6343021392822266}]}, {"text": "We assigned the rest of the NULL arcs a very low probability of p(N U LL) = 0.001 (compared to the previously assigned average score of all the other arcs between two consecutive nodes).", "labels": [], "entities": []}, {"text": "In this condition, the quality of CN-DECODING output reranked by SOUL shows an insignificant gain over the baseline MOSES + SOUL (+0.18 BLEU for LIMSITEST2-ABS, see).", "labels": [], "entities": [{"text": "MOSES", "start_pos": 116, "end_pos": 121, "type": "METRIC", "confidence": 0.9814301133155823}, {"text": "BLEU", "start_pos": 136, "end_pos": 140, "type": "METRIC", "confidence": 0.9979585409164429}]}, {"text": "It seems that the CN-DECODING procedure allowed our system to locally choose \"good\" translation variants, in spite of the quality decrease that we observed for NP-Reduced-SMT hypotheses (see", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Corpora used for training (left); development and test (right)", "labels": [], "entities": []}, {"text": " Table 2: Results (BLEU) for MOSES and MOSES + SOUL on the in-house test set", "labels": [], "entities": [{"text": "BLEU)", "start_pos": 19, "end_pos": 24, "type": "METRIC", "confidence": 0.9788189232349396}, {"text": "MOSES", "start_pos": 29, "end_pos": 34, "type": "DATASET", "confidence": 0.4678870141506195}]}, {"text": " Table 3: NP-SMT and NP-Reduced-SMT per- formance for LIMSITEST2-ABS.", "labels": [], "entities": []}, {"text": " Table 4: Average % of new unique n-gram per  CN-DECODING hypothesis (using 300-best lists)  LIMSITEST2-ABS).", "labels": [], "entities": [{"text": "LIMSITEST2-ABS", "start_pos": 93, "end_pos": 107, "type": "METRIC", "confidence": 0.9237165451049805}]}, {"text": " Table 5: Results (BLEU) for different strategies  of NP injection.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 19, "end_pos": 23, "type": "METRIC", "confidence": 0.9984751343727112}, {"text": "NP injection", "start_pos": 54, "end_pos": 66, "type": "TASK", "confidence": 0.9592684209346771}]}, {"text": " Table 6: Results (BLEU) for CN-DECODING ex- periments.", "labels": [], "entities": [{"text": "BLEU)", "start_pos": 19, "end_pos": 24, "type": "METRIC", "confidence": 0.9603987038135529}]}]}