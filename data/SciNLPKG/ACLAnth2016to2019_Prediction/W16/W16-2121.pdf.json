{"title": [{"text": "Information-based Modeling of Diachronic Linguistic Change: from Typicality to Productivity", "labels": [], "entities": [{"text": "Information-based Modeling of Diachronic Linguistic Change", "start_pos": 0, "end_pos": 58, "type": "TASK", "confidence": 0.7907711366812388}]}], "abstractContent": [{"text": "We present anew approach for modeling diachronic linguistic change in grammatical usage.", "labels": [], "entities": []}, {"text": "We illustrate the approach on English scientific writing in Late Modern English, focusing on grammatical patterns that are potentially indicative of shifts in register, genre and/or style.", "labels": [], "entities": []}, {"text": "Commonly, diachronic change is characterized by the relative frequency of typical linguistic features overtime.", "labels": [], "entities": []}, {"text": "However, to fully capture changing linguistic usage, feature productivity needs to betaken into account as well.", "labels": [], "entities": []}, {"text": "We introduce a data-driven approach for systematically detecting typical features and assessing their productivity overtime, using information-theoretic measures of entropy and surprisal.", "labels": [], "entities": []}], "introductionContent": [{"text": "The analysis of diachronic corpora is of great interest to linguistics, history and cultural studies alike.", "labels": [], "entities": []}, {"text": "The challenges in dealing with diachronic material are manifold, ranging from corpus compilation and annotation to analysis.", "labels": [], "entities": [{"text": "corpus compilation", "start_pos": 78, "end_pos": 96, "type": "TASK", "confidence": 0.749074250459671}]}, {"text": "Here, we address questions of analysis, notably the data-driven detection and evaluation of linguistic features marking shifts in register, genre and/or style.", "labels": [], "entities": []}, {"text": "Specifically, we focus on the productivity of features overtime, i.e. the property of a grammatical pattern to attract new lexical items and to spread to new contexts (cf.).", "labels": [], "entities": []}, {"text": "In terms of methods, we propose a systematic approach to feature detection and evaluation based on information-theoretic measures such as entropy and surprisal.", "labels": [], "entities": [{"text": "feature detection and evaluation", "start_pos": 57, "end_pos": 89, "type": "TASK", "confidence": 0.8024580627679825}]}, {"text": "These measures are based on probability in context, where that context maybe the ambient context (as in n-gram models) or the extra-linguistic context (here: time, register) (cf. Section 3 for details).", "labels": [], "entities": []}, {"text": "While we investigate diachronic linguistic change in English scientific writing, our methodology can easily be applied to other scenarios analyzing differences/similarities across registers/genres/languages/time and the like in terms of typicality and productivity.", "labels": [], "entities": []}, {"text": "To detect features, we employ relative entropy or Kullback-Leibler Divergence (KLD), a well-known measure of similarity/dissimilarity between probability distributions used in natural language and speech processing and information retrieval (see e.g.;).", "labels": [], "entities": [{"text": "Kullback-Leibler Divergence (KLD)", "start_pos": 50, "end_pos": 83, "type": "METRIC", "confidence": 0.733093512058258}, {"text": "information retrieval", "start_pos": 219, "end_pos": 240, "type": "TASK", "confidence": 0.7666628360748291}]}, {"text": "Using KLD, we compare different time periods and obtain typical features of scientific texts for further analysis.", "labels": [], "entities": [{"text": "KLD", "start_pos": 6, "end_pos": 9, "type": "DATASET", "confidence": 0.7124245166778564}]}, {"text": "As features, here, we use part-of-speech (POS) 3-grams to approximate grammatical patterns.", "labels": [], "entities": []}, {"text": "To capture productivity, we apply the notion of average surprisal (AvS).", "labels": [], "entities": [{"text": "average surprisal (AvS)", "start_pos": 48, "end_pos": 71, "type": "METRIC", "confidence": 0.931575345993042}]}, {"text": "Using surprisal, we compare differences in probabilities for selected units (here: parts-of-speech) and contexts across different time periods and registers (here: scientific vs. \"general\" language), which allows us to evaluate their contribution to change in terms of productivity.", "labels": [], "entities": []}, {"text": "For example, passive voice is considered atypical feature of scientific writing (compared to other registers) (cf.).", "labels": [], "entities": []}, {"text": "Diachronically, its productivity may have been low in the beginning and increasing later on or it may first have been high and then decreasing overtime.", "labels": [], "entities": []}, {"text": "For example, in scientific writing passive may have initially been used with only a few verbs (e.g. BE + made/seen/found) and in few contexts (e.g. as/it maybe seen) and then extended to more verbs (e.g. BE + made/seen/found/observed/determined/produced) and spread to more contexts (e.g. as/it/that may/will/must + VERB), which would indicate a shift from a lower to a higher productivity.", "labels": [], "entities": [{"text": "BE", "start_pos": 100, "end_pos": 102, "type": "METRIC", "confidence": 0.8762183785438538}, {"text": "VERB", "start_pos": 316, "end_pos": 320, "type": "METRIC", "confidence": 0.9649235010147095}]}, {"text": "In the following, we describe related work (Section 2) as well as the data, methods and analytic procedures (Section 3), followed by selected analyses and results (Section 4).", "labels": [], "entities": []}, {"text": "We conclude with a summary and envoi (Section 5).", "labels": [], "entities": [{"text": "envoi", "start_pos": 31, "end_pos": 36, "type": "METRIC", "confidence": 0.9947370886802673}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 2: Gerund verbs in the gerund 3-gram for very low to low AvS (RSC)", "labels": [], "entities": [{"text": "AvS", "start_pos": 64, "end_pos": 67, "type": "METRIC", "confidence": 0.9917768239974976}]}, {"text": " Table 3: Passive verbs in the modal passive 3-gram  for very low to low AvS (RSC)", "labels": [], "entities": [{"text": "AvS", "start_pos": 73, "end_pos": 76, "type": "METRIC", "confidence": 0.992198646068573}]}]}