{"title": [{"text": "Coursebook Texts as a Helping Hand for Classifying Linguistic Complexity in Language Learners' Writings", "labels": [], "entities": [{"text": "Classifying Linguistic Complexity in Language Learners' Writings", "start_pos": 39, "end_pos": 103, "type": "TASK", "confidence": 0.6556909935814994}]}], "abstractContent": [{"text": "We bring together knowledge from two different types of language learning data, texts learners read and texts they write, to improve linguistic complexity classification in the latter.", "labels": [], "entities": [{"text": "linguistic complexity classification", "start_pos": 133, "end_pos": 169, "type": "TASK", "confidence": 0.6611299018065134}]}, {"text": "Linguistic complexity in the foreign and second language learning context can be expressed in terms of proficiency levels.", "labels": [], "entities": []}, {"text": "We show that incorporating features capturing lexical complexity information from reading passages can boost significantly the machine learning based classification of learner-written texts into proficiency levels.", "labels": [], "entities": []}, {"text": "With an F 1 score of .8 our system rivals state-of-the-art results reported for other languages for this task.", "labels": [], "entities": [{"text": "F 1 score", "start_pos": 8, "end_pos": 17, "type": "METRIC", "confidence": 0.9864499568939209}]}, {"text": "Finally, we present a freely available web-based tool for proficiency level classification and lexical complexity visualization for both learner writings and reading texts.", "labels": [], "entities": [{"text": "proficiency level classification", "start_pos": 58, "end_pos": 90, "type": "TASK", "confidence": 0.8159146110216776}]}], "introductionContent": [{"text": "Second or foreign (L2) language learners pass through different development stages commonly referred to as proficiency levels.", "labels": [], "entities": []}, {"text": "A popular scale of such levels is the Common European Framework of Reference for Languages (CEFR)).", "labels": [], "entities": [{"text": "Common European Framework of Reference for Languages (CEFR))", "start_pos": 38, "end_pos": 98, "type": "DATASET", "confidence": 0.7610329180955887}]}, {"text": "As learners advance to higher levels, the complexity of the linguistic input that they are able to comprehend (receptive skills) and the output that they produce (productive skills) increases in terms of both lexical and grammatical patterns.", "labels": [], "entities": []}, {"text": "Although learners' receptive and productive knowledge overlap, they only do so partially, the latter being typically a subset of the former corresponding to a somewhat lower linguistic complexity overall.", "labels": [], "entities": []}, {"text": "In previous work, NLP methods have been successfully applied for assessing separately receptive and productive L2 levels (see section 2).", "labels": [], "entities": []}, {"text": "We, on the other hand, hypothesize that, since a shared linguistic content exists between what L2 learners are exposed to (L2 input texts, e.g. reading passages from coursebooks) and what they produce (L2 output texts, e.g. essays), transferring knowledge from one text type may improve the classification of linguistic complexity levels in the other.", "labels": [], "entities": []}, {"text": "We focus on the automatic prediction of CEFR levels for L2 learner essays fora number of reasons.", "labels": [], "entities": [{"text": "CEFR levels", "start_pos": 40, "end_pos": 51, "type": "METRIC", "confidence": 0.8980700969696045}]}, {"text": "Essay writing is a popular means to assess learners' proficiency level and it is a rather subjective and time-consuming task.", "labels": [], "entities": [{"text": "Essay writing", "start_pos": 0, "end_pos": 13, "type": "TASK", "confidence": 0.900233656167984}]}, {"text": "Moreover, such data is rather scarce and cumbersome to collect . Our target language is Swedish since corpora for both L2 text types are available for this language.", "labels": [], "entities": []}, {"text": "We compare two different strategies aiming at improving L2 essay classification results without additional data of this type: (i) employing a word list based on a coursebook corpus for lexical features, (ii) domain adaptation experiments, i.e. training a machine learning model on L2 input texts and using it to classify the essays.", "labels": [], "entities": [{"text": "L2 essay classification", "start_pos": 56, "end_pos": 79, "type": "TASK", "confidence": 0.7570905486742655}, {"text": "domain adaptation", "start_pos": 208, "end_pos": 225, "type": "TASK", "confidence": 0.6888751685619354}]}, {"text": "We first compare the distribution of words per CEFR levels in the essays using two different word lists and find that a list based on L2 input texts correlates well with the manually assigned CEFR labels of the essays.", "labels": [], "entities": []}, {"text": "Using this list in machine learning experiments produces a significant performance boost which exceeds our domain adaptation attempts and compares well also to previously reported results for this task.", "labels": [], "entities": []}, {"text": "Finally, we present an online tool for assessing linguistic complexity in L2 Swedish input and output texts that performs a machine learning based CEFR level classification and a lexical complexity analysis supported by a color-enhanced visualization of words per level.", "labels": [], "entities": [{"text": "CEFR level classification", "start_pos": 147, "end_pos": 172, "type": "TASK", "confidence": 0.7937431335449219}]}], "datasetContent": [{"text": "We use the sequential minimal optimization algorithm from WEKA () and the feature set mentioned above for all experiments.", "labels": [], "entities": [{"text": "sequential minimal optimization", "start_pos": 11, "end_pos": 42, "type": "TASK", "confidence": 0.6086857517560323}, {"text": "WEKA", "start_pos": 58, "end_pos": 62, "type": "DATASET", "confidence": 0.9240357279777527}]}, {"text": "Results are obtained using 10-fold cross-validation, unless otherwise specified.", "labels": [], "entities": []}, {"text": "Reported measures include F 1 and quadratic weighted kappa (\u03ba 2 ), a distance-based scoring function taking into consideration also the degree of misclassifications.", "labels": [], "entities": [{"text": "F 1", "start_pos": 26, "end_pos": 29, "type": "METRIC", "confidence": 0.9917347133159637}, {"text": "quadratic weighted kappa (\u03ba 2 )", "start_pos": 34, "end_pos": 65, "type": "METRIC", "confidence": 0.9183946847915649}]}, {"text": "Our baselines consist of assigning the most frequent label in the dataset to each instance (MAJORITY) and cross-validated results on the learner essays using KELLY (E-KELLY) for lexical features.", "labels": [], "entities": [{"text": "MAJORITY", "start_pos": 92, "end_pos": 100, "type": "METRIC", "confidence": 0.9883710741996765}]}, {"text": "Domain adaptation We compare these to two models using information from SVALex+ (E-SVALEX+ with SVALex+ instead of KELLY and E-KELLY&SVALEX+ including both lists), as well as to two simple domain adaptation setups inspired by.", "labels": [], "entities": [{"text": "Domain adaptation", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.8079976439476013}]}, {"text": "Ina domain adaptation scenario, data from a source domain is used to predict labels in a different, target domain.", "labels": [], "entities": []}, {"text": "In our SOURCE-ONLY setup, a model trained on coursebook texts is applied to the essays, our target domain.", "labels": [], "entities": []}, {"text": "In +FEATURE the CEFR levels predicted by a model trained on coursebook texts is used as an additional feature when training a classifier for the essays.", "labels": [], "entities": [{"text": "FEATURE", "start_pos": 4, "end_pos": 11, "type": "METRIC", "confidence": 0.9813077449798584}, {"text": "CEFR", "start_pos": 16, "end_pos": 20, "type": "METRIC", "confidence": 0.9607604742050171}]}, {"text": "For both the SOURCE-ONLY and the +FEATURE setup the KELLY list has been used.", "labels": [], "entities": [{"text": "FEATURE", "start_pos": 34, "end_pos": 41, "type": "METRIC", "confidence": 0.9848504066467285}, {"text": "KELLY", "start_pos": 52, "end_pos": 57, "type": "METRIC", "confidence": 0.9961485862731934}]}], "tableCaptions": [{"text": " Table 1: Overview of CEFR-level annotated Swedish datasets.", "labels": [], "entities": [{"text": "CEFR-level annotated Swedish datasets", "start_pos": 22, "end_pos": 59, "type": "DATASET", "confidence": 0.9026454091072083}]}, {"text": " Table 2: Distribution of token CEFR levels (in %) per essay CEFR levels.", "labels": [], "entities": []}, {"text": " Table 3: Results for different classification improvement strategies.", "labels": [], "entities": []}]}