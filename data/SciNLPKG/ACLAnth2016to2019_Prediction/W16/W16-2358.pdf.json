{"title": [], "abstractContent": [{"text": "This paper presents the systems developed by LIUM and CVC for the WMT16 Mul-timodal Machine Translation challenge.", "labels": [], "entities": [{"text": "CVC", "start_pos": 54, "end_pos": 57, "type": "DATASET", "confidence": 0.8540160059928894}, {"text": "WMT16 Mul-timodal Machine Translation challenge", "start_pos": 66, "end_pos": 113, "type": "TASK", "confidence": 0.7224455118179322}]}, {"text": "We explored various comparative methods , namely phrase-based systems and at-tentional recurrent neural networks models trained using monomodal or multi-modal data.", "labels": [], "entities": []}, {"text": "We also performed a human evaluation in order to estimate the usefulness of multimodal data for human machine translation and image description generation.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 102, "end_pos": 121, "type": "TASK", "confidence": 0.6905234605073929}, {"text": "image description generation", "start_pos": 126, "end_pos": 154, "type": "TASK", "confidence": 0.7621945738792419}]}, {"text": "Our systems obtained the best results for both tasks according to the automatic evaluation metrics BLEU and METEOR .", "labels": [], "entities": [{"text": "BLEU", "start_pos": 99, "end_pos": 103, "type": "METRIC", "confidence": 0.9805207252502441}, {"text": "METEOR", "start_pos": 108, "end_pos": 114, "type": "METRIC", "confidence": 0.9806475043296814}]}], "introductionContent": [{"text": "Recently, deep learning has greatly impacted the natural language processing field as well as computer vision.", "labels": [], "entities": [{"text": "computer vision", "start_pos": 94, "end_pos": 109, "type": "TASK", "confidence": 0.7711373269557953}]}, {"text": "Machine translation (MT) with deep neural networks (DNN), proposed by and () competed successfully in the last year's WMT evaluation campaign).", "labels": [], "entities": [{"text": "Machine translation (MT", "start_pos": 0, "end_pos": 23, "type": "TASK", "confidence": 0.8575956225395203}, {"text": "WMT evaluation", "start_pos": 118, "end_pos": 132, "type": "TASK", "confidence": 0.5921475291252136}]}, {"text": "In the same trend, generating descriptions from images using DNNs has been proposed by.", "labels": [], "entities": []}, {"text": "Several attempts have been made to incorporate features from different modalities in order to help the automatic system to better model the task at hand.", "labels": [], "entities": []}, {"text": "This paper describes the systems developed by LIUM and CVC who participated in the two proposed tasks for the WMT 2016 Multimodal Machine Translation evaluation campaign: Multimodal machine translation (Task 1) and multimodal image description (Task 2).", "labels": [], "entities": [{"text": "CVC", "start_pos": 55, "end_pos": 58, "type": "DATASET", "confidence": 0.8763834238052368}, {"text": "WMT 2016 Multimodal Machine Translation evaluation", "start_pos": 110, "end_pos": 160, "type": "TASK", "confidence": 0.7958720624446869}, {"text": "Multimodal machine translation", "start_pos": 171, "end_pos": 201, "type": "TASK", "confidence": 0.6774247586727142}, {"text": "multimodal image description", "start_pos": 215, "end_pos": 243, "type": "TASK", "confidence": 0.62919549147288}]}, {"text": "The remainder of this paper is structured in two parts: The first part (section 2) describes the architecture of the four systems (two monomodal and two multimodal) submitted for Task 1.", "labels": [], "entities": []}, {"text": "The standard phrase-based SMT systems based on Moses are described in section 2.1 while the neural MT systems are described in section 2.2 (monomodal) and section 3.2 (multimodal).", "labels": [], "entities": [{"text": "SMT", "start_pos": 26, "end_pos": 29, "type": "TASK", "confidence": 0.8520254492759705}]}, {"text": "The second part (section 3) contains the description of the two systems submitted for Task 2: The first one is a monomodal neural MT system similar to the one presented in section 2.2, and the second one is a multimodal neural machine translation (MNMT) with shared attention mechanism.", "labels": [], "entities": [{"text": "multimodal neural machine translation (MNMT)", "start_pos": 209, "end_pos": 253, "type": "TASK", "confidence": 0.7841898628643581}]}, {"text": "In order to evaluate the feasibility of the multimodal approach, we also asked humans to perform the two tasks of this evaluation campaign.", "labels": [], "entities": []}, {"text": "Results show that the additional English description sentences improved performance while the straightforward translation of the sentence without the image did not provide as good results.", "labels": [], "entities": []}, {"text": "The results of these experiments are presented in section 4.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 2: BLEU and METEOR scores on detokenized outputs of baseline and submitted Task 1 systems.  The METEOR scores in parenthesis are computed with -norm parameter.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9987829327583313}, {"text": "METEOR", "start_pos": 19, "end_pos": 25, "type": "METRIC", "confidence": 0.9674704074859619}, {"text": "METEOR", "start_pos": 103, "end_pos": 109, "type": "METRIC", "confidence": 0.8205102682113647}]}, {"text": " Table 3: BLEU scores for various deep features  on the image description generation task using the  system of Xu et al. (Xu et al., 2015).", "labels": [], "entities": [{"text": "BLEU", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9992139339447021}, {"text": "image description generation task", "start_pos": 56, "end_pos": 89, "type": "TASK", "confidence": 0.839931458234787}]}, {"text": " Table 5: BLEU and METEOR scores of our NMT  based submissions for Task 2.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9993470311164856}, {"text": "METEOR", "start_pos": 19, "end_pos": 25, "type": "METRIC", "confidence": 0.9969461560249329}]}, {"text": " Table 6: BLEU and METEOR scores for human  translation/description generation experiments.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9992102384567261}, {"text": "METEOR", "start_pos": 19, "end_pos": 25, "type": "METRIC", "confidence": 0.9873472452163696}, {"text": "human  translation/description generation", "start_pos": 37, "end_pos": 78, "type": "TASK", "confidence": 0.7962204694747925}]}]}