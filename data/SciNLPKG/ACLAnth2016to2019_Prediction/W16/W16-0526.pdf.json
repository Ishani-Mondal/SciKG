{"title": [{"text": "Augmenting Course Material with Open Access Textbooks", "labels": [], "entities": [{"text": "Augmenting Course Material", "start_pos": 0, "end_pos": 26, "type": "TASK", "confidence": 0.8870708346366882}]}], "abstractContent": [{"text": "Online, open access, high-quality textbooks are an exciting new resource for improving the online learning experience.", "labels": [], "entities": []}, {"text": "Because textbooks contain carefully crafted material written in a logical order, with terms defined before use and discussed in detail, they can provide foundational material with which to buttress other resources.", "labels": [], "entities": []}, {"text": "As a first step towards this goal, we explore the automated augmentation of a popular online learning resource-Khan Academy video modules-with relevant reference chapters from open access textbooks.", "labels": [], "entities": []}, {"text": "We show results from standard information retrieval weighting and ranking methods as well as an NLP-inspired approach, achieving F1 scores ranging from 0.63, to 0.83 on science topics.", "labels": [], "entities": [{"text": "information retrieval weighting", "start_pos": 30, "end_pos": 61, "type": "TASK", "confidence": 0.7826651533444723}, {"text": "F1 scores", "start_pos": 129, "end_pos": 138, "type": "METRIC", "confidence": 0.9815159738063812}]}, {"text": "Future work includes taking into account the difficulty level and prerequisites of a textbook to select sections that are both relevant and reflect the concepts that the reader has already encountered.", "labels": [], "entities": []}], "introductionContent": [{"text": "A learner who is studying material from an online course, such as a video from a Khan academy physics sequence, may desire additional reading material to supplement the current video or exercise.", "labels": [], "entities": []}, {"text": "It can be distracting to do a web search to find relevant material, and furthermore, the material that is found maybe described at the wrong level or may assume prerequisite knowledge that the learner does not have.", "labels": [], "entities": []}, {"text": "To this point, note that online encyclopedic resources, such as Wikipedia, are not pedagogically organized and tend to have many cyclic dependencies among articles.", "labels": [], "entities": []}, {"text": "Textbooks written for students are specifically designed for learning.", "labels": [], "entities": []}, {"text": "Material is carefully organized to define terms before use or to point the reader to the location in which the material will be discussed in more detail.", "labels": [], "entities": []}, {"text": "Content is described at a consistent reading level and notation and formatting are also consistent.", "labels": [], "entities": []}, {"text": "However, to date, textbooks have not been widely used for automated online recommendations, most likely because they have not been freely available online for many subjects.", "labels": [], "entities": []}, {"text": "This situation is changing with the advent of projects like OpenStax (Pitt, 2015) 1 for which respected educators are writing and vetting free online textbooks in major subject categories.", "labels": [], "entities": [{"text": "OpenStax (Pitt, 2015)", "start_pos": 60, "end_pos": 81, "type": "DATASET", "confidence": 0.6981403032938639}]}, {"text": "In this work we explore the potential of augmenting online course materials -specifically Khan Academy modules 2 -with relevant supplemental reading from textbooks.", "labels": [], "entities": [{"text": "Khan Academy modules 2", "start_pos": 90, "end_pos": 112, "type": "DATASET", "confidence": 0.94674052298069}]}, {"text": "We show that even very simple algorithms can go along way towards making effective recommendations.", "labels": [], "entities": []}], "datasetContent": [{"text": "All tuning of hyperparameters (tf-idf filtering, the minimum frequency of a learning objective term and the threshold fora spike) was done on augmentation of the Khan Academy physics module with the OpenStax physics textbook.", "labels": [], "entities": [{"text": "Khan Academy physics module", "start_pos": 162, "end_pos": 189, "type": "DATASET", "confidence": 0.9287664592266083}, {"text": "OpenStax physics textbook", "start_pos": 199, "end_pos": 224, "type": "DATASET", "confidence": 0.827461302280426}]}, {"text": "For each of the three test modules, we picked a random subset of 10 submodules and split this into two disjoint sets with 5 submodules for each.", "labels": [], "entities": []}, {"text": "We recruited four judges and had two judges label each of these disjoint sets, so in total all submodules were labeled twice.", "labels": [], "entities": []}, {"text": "For every Khan Academy submodule, the judges were told to select any and all chapters in the textbook that explained the same concepts as that submodule.", "labels": [], "entities": [{"text": "Khan Academy submodule", "start_pos": 10, "end_pos": 32, "type": "DATASET", "confidence": 0.8770798643430074}]}, {"text": "A fifth judge (one of the authors) broke ties between any discrepancies in answers from the first two judges.", "labels": [], "entities": []}, {"text": "Precision was calculated as where M is the number of submodules, Ni is the number of chapters that were correctly matched for submodule i, and N is the total number of chapters that were  output.", "labels": [], "entities": [{"text": "Precision", "start_pos": 0, "end_pos": 9, "type": "METRIC", "confidence": 0.9847871661186218}]}, {"text": "Recall was calculated as where K is the total number of gold-standard chapter annotations for the entire module.", "labels": [], "entities": [{"text": "Recall", "start_pos": 0, "end_pos": 6, "type": "METRIC", "confidence": 0.9907246232032776}]}, {"text": "F1 was the harmonic mean of the precision and recall scores.", "labels": [], "entities": [{"text": "F1", "start_pos": 0, "end_pos": 2, "type": "METRIC", "confidence": 0.9952017068862915}, {"text": "precision", "start_pos": 32, "end_pos": 41, "type": "METRIC", "confidence": 0.9994630217552185}, {"text": "recall", "start_pos": 46, "end_pos": 52, "type": "METRIC", "confidence": 0.9959830045700073}]}, {"text": "The results for the three methods are shown in.", "labels": [], "entities": []}, {"text": "The tf-idf document similarity method (Method 1) achieves high precision, but lower recall because it only selects one chapter per module.", "labels": [], "entities": [{"text": "precision", "start_pos": 63, "end_pos": 72, "type": "METRIC", "confidence": 0.9992544054985046}, {"text": "recall", "start_pos": 84, "end_pos": 90, "type": "METRIC", "confidence": 0.9994794726371765}]}, {"text": "Surprisingly the spikes method (Method 3) performed worse than the term frequency method (Method 2).", "labels": [], "entities": []}, {"text": "We believe that this is because there were few occasions in the test set where the chapter with the highest frequency of a term did not correspond to the chapter that a term was explained in.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: The results of the tf-idf (Method 1), Term frequency", "labels": [], "entities": [{"text": "Term frequency", "start_pos": 48, "end_pos": 62, "type": "METRIC", "confidence": 0.9273432195186615}]}]}