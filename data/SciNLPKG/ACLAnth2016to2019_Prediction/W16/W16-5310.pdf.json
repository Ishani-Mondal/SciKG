{"title": [{"text": "CogALex-V Shared Task: LexNET -Integrated Path-based and Distributional Method for the Identification of Semantic Relations", "labels": [], "entities": [{"text": "LexNET", "start_pos": 23, "end_pos": 29, "type": "DATASET", "confidence": 0.8452997803688049}, {"text": "Identification of Semantic Relations", "start_pos": 87, "end_pos": 123, "type": "TASK", "confidence": 0.8078110218048096}]}], "abstractContent": [{"text": "We present a submission to the CogALex 2016 shared task on the corpus-based identification of semantic relations, using LexNET (Shwartz and Dagan, 2016), an integrated path-based and distributional method for semantic relation classification.", "labels": [], "entities": [{"text": "corpus-based identification of semantic relations", "start_pos": 63, "end_pos": 112, "type": "TASK", "confidence": 0.7264181137084961}, {"text": "LexNET", "start_pos": 120, "end_pos": 126, "type": "DATASET", "confidence": 0.9386301636695862}, {"text": "semantic relation classification", "start_pos": 209, "end_pos": 241, "type": "TASK", "confidence": 0.6917813022931417}]}, {"text": "The reported results in the shared task bring this submission to the third place on subtask 1 (word relatedness), and the first place on subtask 2 (semantic relation classification), demonstrating the utility of integrating the complementary path-based and distributional information sources in recognizing concrete semantic relations.", "labels": [], "entities": [{"text": "semantic relation classification)", "start_pos": 148, "end_pos": 181, "type": "TASK", "confidence": 0.7401249408721924}]}, {"text": "Combined with a common similarity measure, LexNET performs fairly good on the word relatedness task (subtask 1).", "labels": [], "entities": [{"text": "LexNET", "start_pos": 43, "end_pos": 49, "type": "DATASET", "confidence": 0.7520952820777893}]}, {"text": "The relatively low performance of LexNET and all other systems on subtask 2, however, confirms the difficulty of the semantic relation classification task, and stresses the need to develop additional methods for this task.", "labels": [], "entities": [{"text": "LexNET", "start_pos": 34, "end_pos": 40, "type": "DATASET", "confidence": 0.9203518629074097}, {"text": "semantic relation classification task", "start_pos": 117, "end_pos": 154, "type": "TASK", "confidence": 0.8133575916290283}]}], "introductionContent": [{"text": "Discovering whether words are semantically related and identifying the specific semantic relation that holds between them is a key component in many NLP applications, such as question answering and recognizing textual entailment (.", "labels": [], "entities": [{"text": "question answering", "start_pos": 175, "end_pos": 193, "type": "TASK", "confidence": 0.8985902965068817}, {"text": "recognizing textual entailment", "start_pos": 198, "end_pos": 228, "type": "TASK", "confidence": 0.8088038365046183}]}, {"text": "Automated methods for semantic relation identification are commonly corpus-based, and mainly rely on the distributional representation of each word.", "labels": [], "entities": [{"text": "semantic relation identification", "start_pos": 22, "end_pos": 54, "type": "TASK", "confidence": 0.8507905006408691}]}, {"text": "The CogALex shared task on the corpus-based identification of semantic relations consists of two subtasks.", "labels": [], "entities": [{"text": "corpus-based identification of semantic relations", "start_pos": 31, "end_pos": 80, "type": "TASK", "confidence": 0.7448849618434906}]}, {"text": "In the first task, the system needs to identify fora word pair whether the words are semantically related or not (e.g. True:(dog, cat), False:(dog, fruit)).", "labels": [], "entities": [{"text": "False", "start_pos": 136, "end_pos": 141, "type": "METRIC", "confidence": 0.9706519246101379}]}, {"text": "In the second task, the goal is to determine the specific semantic relation that holds fora given pair, if any (PART OF:(tail, cat), HYPER:(cat, animal)).", "labels": [], "entities": [{"text": "PART OF", "start_pos": 112, "end_pos": 119, "type": "METRIC", "confidence": 0.8444539904594421}, {"text": "HYPER", "start_pos": 133, "end_pos": 138, "type": "METRIC", "confidence": 0.9912716746330261}]}, {"text": "In this paper we describe our approach and system setup for the shared task.", "labels": [], "entities": []}, {"text": "We use, an integrated path-based and distributional method for semantic relation classification.", "labels": [], "entities": [{"text": "semantic relation classification", "start_pos": 63, "end_pos": 95, "type": "TASK", "confidence": 0.8350206216176351}]}, {"text": "LexNET was the system with the overall best performance on subtask 2, and was ranked third on subtask 1, demonstrating the utility of integrating the complementary path-based and distributional information sources in recognizing semantic relatedness.", "labels": [], "entities": [{"text": "LexNET", "start_pos": 0, "end_pos": 6, "type": "DATASET", "confidence": 0.9710783362388611}]}, {"text": "To aid in recognizing whether a pair of words are related at all (subtask 1), we combine LexNET with a common similarity measure (cosine similarity), achieving fairly good performance, and a slight improvement upon using cosine similarity alone.", "labels": [], "entities": [{"text": "LexNET", "start_pos": 89, "end_pos": 95, "type": "DATASET", "confidence": 0.8640509247779846}, {"text": "cosine similarity)", "start_pos": 130, "end_pos": 148, "type": "METRIC", "confidence": 0.7364239990711212}]}, {"text": "Subtask 2, however, has shown to be extremely difficult, with LexNET and all other systems achieving relatively low F 1 scores.", "labels": [], "entities": [{"text": "LexNET", "start_pos": 62, "end_pos": 68, "type": "DATASET", "confidence": 0.9543004035949707}, {"text": "F 1 scores", "start_pos": 116, "end_pos": 126, "type": "METRIC", "confidence": 0.9879615505536398}]}, {"text": "The conflict between the mediocre performance and the recent success of distributional methods on several other common datasets for semantic relation classification () could be explained by the stricter evaluation setup in this subtask, which is supposed to demonstrate more closely real-world application settings.", "labels": [], "entities": [{"text": "semantic relation classification", "start_pos": 132, "end_pos": 164, "type": "TASK", "confidence": 0.7040046056111654}]}, {"text": "The difficulty of the semantic relation classification task emphasizes the need to develop better methods for this task.", "labels": [], "entities": [{"text": "semantic relation classification task", "start_pos": 22, "end_pos": 59, "type": "TASK", "confidence": 0.8086555898189545}]}], "datasetContent": [{"text": "The shared task organizers provided a dataset extracted from EVALution 1.0 (, which was split into training and test sets.", "labels": [], "entities": []}, {"text": "As instructed, we trained and tuned our method on the training set, and evaluated it once on the test set.", "labels": [], "entities": []}, {"text": "To tune the hyper-parameters, we split the training set to 90% train and 10% validation sets.", "labels": [], "entities": []}, {"text": "Since the dataset contains only 318 different words in the x slot, we performed the split such that the train and the validation contain distinct x words.", "labels": [], "entities": []}, {"text": "LexNET has several tunable hyper-parameters.", "labels": [], "entities": [{"text": "LexNET", "start_pos": 0, "end_pos": 6, "type": "DATASET", "confidence": 0.972156822681427}]}, {"text": "Similarly to , we used the English Wikipedia dump from May 2015 as an underlying corpus (3B tokens), and initialized the network's word embeddings with the 50-dimensional pre-trained GloVe word embeddings (), trained on Wikipedia and Gigaword 5 (6B tokens).", "labels": [], "entities": [{"text": "English Wikipedia dump from May 2015", "start_pos": 27, "end_pos": 63, "type": "DATASET", "confidence": 0.8942394951979319}]}, {"text": "We fixed this hyper-parameter due to computational limitations with higher-dimensional embeddings.", "labels": [], "entities": []}, {"text": "For each subtask, we tuned LexNET's hyper-parameters on the validation set: the number of hidden layers (0 or 1), the number of training epochs, and the word dropout rate (see  for technical details).", "labels": [], "entities": [{"text": "LexNET", "start_pos": 27, "end_pos": 33, "type": "DATASET", "confidence": 0.8793646097183228}, {"text": "word dropout rate", "start_pos": 153, "end_pos": 170, "type": "METRIC", "confidence": 0.7926130294799805}]}, {"text": "displays the best performing hyper-parameters in each subtask, along with the performance on the validation set, which is detailed below.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Performance scores on the validation set along with hyper-parameters and effective corpus size  (#tokens) used by each method. Subtask 2 results refer to the subset of related pairs, as detailed in  \u00a7 4.2.", "labels": [], "entities": []}, {"text": " Table 2: Performance scores on the test set in each subtask, of the selected methods and the baselines.", "labels": [], "entities": []}]}