{"title": [{"text": "Whose Nickname is This? Recognizing Politicians from Their Aliases", "labels": [], "entities": [{"text": "Recognizing Politicians from Their Aliases", "start_pos": 24, "end_pos": 66, "type": "TASK", "confidence": 0.8819837093353271}]}], "abstractContent": [{"text": "Using aliases to refer to public figures is one way to make fun of people, to express sarcasm, or even to sidestep legal issues when expressing opinions on social media.", "labels": [], "entities": []}, {"text": "However, linking an alias back to the real name is difficult, as it entails phonemic, graphemic, and semantic challenges.", "labels": [], "entities": []}, {"text": "In this paper, we propose a phonemic-based approach and inject semantic information to align aliases with politicians' Chinese formal names.", "labels": [], "entities": []}, {"text": "The proposed approach creates an HMM model for each name to model its phonemes and takes into account document-level pairwise mutual information to capture the semantic relations to the alias.", "labels": [], "entities": []}, {"text": "In this work we also introduce two new datasets consisting of 167 phonemic pairs and 279 mixed pairs of aliases and formal names.", "labels": [], "entities": []}, {"text": "Experimental results show that the proposed approach models both phonemic and semantic information and outperforms previous work on both the phonemic and mixed datasets with the best top-1 accuracies of 0.78 and 0.59 respectively.", "labels": [], "entities": []}], "introductionContent": [{"text": "Due to the casual nature of social media, there exist a large number of non-standard words in text expressions which make it substantially different from formal written text.", "labels": [], "entities": []}, {"text": "It is reported in () that more than four million distinct out-of-vocabulary (OOV) tokens occur in the Edinburgh Twitter corpus (.", "labels": [], "entities": [{"text": "Edinburgh Twitter corpus", "start_pos": 102, "end_pos": 126, "type": "DATASET", "confidence": 0.9836616714795431}]}, {"text": "This variation poses challenges for natural language processing (NLP) tasks).", "labels": [], "entities": [{"text": "natural language processing (NLP) tasks", "start_pos": 36, "end_pos": 75, "type": "TASK", "confidence": 0.7581224696976798}]}, {"text": "According to), on encountering the many non-standard words, found actually to be unknown named entities, they were obliged to manually eliminate these while normalizing the dataset.", "labels": [], "entities": []}, {"text": "Thus, we believe that named entity matching (NEM) is an important problem in noisy text analysis.", "labels": [], "entities": [{"text": "named entity matching (NEM)", "start_pos": 22, "end_pos": 49, "type": "TASK", "confidence": 0.793355330824852}, {"text": "noisy text analysis", "start_pos": 77, "end_pos": 96, "type": "TASK", "confidence": 0.6184781094392141}]}, {"text": "NEM is the task of matching the different alias names for entities back to their respective formal names.", "labels": [], "entities": [{"text": "NEM", "start_pos": 0, "end_pos": 3, "type": "TASK", "confidence": 0.8382734060287476}]}, {"text": "Many applications benefit from this technique, including name transliteration (, entity linking (, entity clustering (, and entity identification for paraphrase mining (.", "labels": [], "entities": [{"text": "name transliteration", "start_pos": 57, "end_pos": 77, "type": "TASK", "confidence": 0.8056292533874512}, {"text": "entity linking", "start_pos": 81, "end_pos": 95, "type": "TASK", "confidence": 0.7573719918727875}, {"text": "entity clustering", "start_pos": 99, "end_pos": 116, "type": "TASK", "confidence": 0.7433168292045593}, {"text": "entity identification", "start_pos": 124, "end_pos": 145, "type": "TASK", "confidence": 0.7344464659690857}, {"text": "paraphrase mining", "start_pos": 150, "end_pos": 167, "type": "TASK", "confidence": 0.7679830491542816}]}, {"text": "This task is different from most in noisy text normalization.", "labels": [], "entities": [{"text": "noisy text normalization", "start_pos": 36, "end_pos": 60, "type": "TASK", "confidence": 0.6362727880477905}]}, {"text": "While most work on normalization includes two parts-informal word identification and word recovery-this work is different in two ways.", "labels": [], "entities": [{"text": "word identification", "start_pos": 61, "end_pos": 80, "type": "TASK", "confidence": 0.715059444308281}, {"text": "word recovery-this", "start_pos": 85, "end_pos": 103, "type": "TASK", "confidence": 0.8048273324966431}]}, {"text": "First, we focus on the recovery of informal names of named entities, in contrast to the general typo and abbreviation recovery.", "labels": [], "entities": [{"text": "recovery of informal names of named entities", "start_pos": 23, "end_pos": 67, "type": "TASK", "confidence": 0.7956108961786542}, {"text": "abbreviation recovery", "start_pos": 105, "end_pos": 126, "type": "TASK", "confidence": 0.6923138052225113}]}, {"text": "Second, the identification of these aliases is a named entity recognition (NER) problem, while conventional normalization works search for every OOV words.", "labels": [], "entities": [{"text": "named entity recognition (NER)", "start_pos": 49, "end_pos": 79, "type": "TASK", "confidence": 0.8104670147101084}]}, {"text": "The challenges of NEM lie in variation, which can be attributed to many factors: nicknames, acronyms, and differences in transliteration.", "labels": [], "entities": [{"text": "NEM", "start_pos": 18, "end_pos": 21, "type": "TASK", "confidence": 0.9764916300773621}]}, {"text": "As a result, exact string matching can yield poor results.", "labels": [], "entities": [{"text": "exact string matching", "start_pos": 13, "end_pos": 34, "type": "TASK", "confidence": 0.6036441822846731}]}, {"text": "It is reported () that most tokenization errors are caused by named entities in documents.", "labels": [], "entities": [{"text": "tokenization", "start_pos": 28, "end_pos": 40, "type": "TASK", "confidence": 0.978550910949707}]}, {"text": "It is difficult to utilize analysis tools which depend on tokenized text.", "labels": [], "entities": []}, {"text": "While most normalization can be achieved using features within words, for example, ('u', 'you') and, aliases and formal names may have no graphemic or phonemic connections, for instance,.", "labels": [], "entities": []}, {"text": "In this paper, we propose a novel method to train word models for each named entity with fullconnected hidden Markov models (HMMs).", "labels": [], "entities": []}, {"text": "We create two datasets of aliases and formal name pairs: one similar-phonemic pair only dataset and one mixed dataset including both similar-phonemic and nonsimilar-phonemic pairs.", "labels": [], "entities": []}, {"text": "In both datasets, our method outperforms all of the baselines, including).", "labels": [], "entities": []}, {"text": "In the mixed dataset, some aliases have no connection with the formal name within words.", "labels": [], "entities": []}, {"text": "Combining our model with the statistical PMI measurement improves performance.", "labels": [], "entities": []}, {"text": "Our contributions are as follows.", "labels": [], "entities": []}, {"text": "First, we propose anew method to solve the character sequence disorder problem for the NEM task.", "labels": [], "entities": [{"text": "character sequence disorder", "start_pos": 43, "end_pos": 70, "type": "TASK", "confidence": 0.7146493792533875}, {"text": "NEM task", "start_pos": 87, "end_pos": 95, "type": "TASK", "confidence": 0.9393714070320129}]}, {"text": "Second, we propose anew method for pairs of aliases and formal names which contain no graphemic or phonetic similarity.", "labels": [], "entities": []}, {"text": "Third, in our experiment, our method outperforms other baselines on both datasets.", "labels": [], "entities": []}, {"text": "Below, we describe in Section 2 the related work for the task and in Section 3 the phonetic similarity formula.", "labels": [], "entities": []}, {"text": "The implementation of the word model and the proposed refined version are described in Sections 4 and 5.", "labels": [], "entities": []}, {"text": "The dataset collection, evaluation, and error analysis are in Section 6.", "labels": [], "entities": [{"text": "Section 6", "start_pos": 62, "end_pos": 71, "type": "DATASET", "confidence": 0.9239826500415802}]}], "datasetContent": [{"text": "We describe in Section 6.1 the dataset creation, and then in Section 6.2 describe the experiment settings and in Section 6.3 the evaluation.", "labels": [], "entities": [{"text": "dataset creation", "start_pos": 31, "end_pos": 47, "type": "TASK", "confidence": 0.7182786166667938}]}, {"text": "279 distinct alias and formal name pairs are collected from wikiptt 1 .The size of formal name set, which is taken as the candidates for each alias recovery, is 72.", "labels": [], "entities": []}, {"text": "From the collection of pairs, we created two datasets: a mixed dataset and a similar-phonemic dataset.", "labels": [], "entities": []}, {"text": "To test the power of the phonetic features embedded in our word model, we built a similar-phonemic dataset, a subset of the mixed dataset containing 167 aliases and normal name pairs which were manually identified as bearing phonetic similarity.", "labels": [], "entities": []}, {"text": "The mixed and similar-phonemic datasets are described in: Similar-phonemic and mixed datasets  We evaluated performance on a ranking task (the setting of (Andrews et al., 2012)).", "labels": [], "entities": []}, {"text": "We constructed as the candidates a set of normal names covering all of the entities referred to by aliases.", "labels": [], "entities": []}, {"text": "The task is to identify for each alias the best-matched name entity in the normal name set.", "labels": [], "entities": []}, {"text": "We acquired two sets of prior knowledge as follows.", "labels": [], "entities": []}, {"text": "We collected 114,438 open-source character-to-pinyin mappings from OpenFoundry 2 . The list of possible initials and finals were provided by Weebly 3 , a Chinese online remote learning system.", "labels": [], "entities": []}, {"text": "From PTT we collected 478,579 posts discussing of politicians.", "labels": [], "entities": [{"text": "PTT", "start_pos": 5, "end_pos": 8, "type": "DATASET", "confidence": 0.9443578720092773}]}, {"text": "PTT is a well-known Chineselanguage bulletin board system containing 20,000 boards covering a multitude of topics.", "labels": [], "entities": [{"text": "PTT", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.9566279053688049}]}, {"text": "Users post their opinions on the board.", "labels": [], "entities": []}, {"text": "Under each post, other users can add short comments.", "labels": [], "entities": []}, {"text": "As with most usergenerated text, articles posted on PTT contain extremely short text, out-of-vocabulary tokens, and aliases.", "labels": [], "entities": [{"text": "PTT", "start_pos": 52, "end_pos": 55, "type": "DATASET", "confidence": 0.8458031415939331}]}, {"text": "We calculated the PMI of each alias and formal name pair at the document level, and then ranked candidates according to their PMI value; the inspiration for this comes from entity clustering (, for which related entities tend to be mentioned in the same document.", "labels": [], "entities": [{"text": "PMI", "start_pos": 18, "end_pos": 21, "type": "METRIC", "confidence": 0.9739894866943359}, {"text": "entity clustering", "start_pos": 173, "end_pos": 190, "type": "TASK", "confidence": 0.7191763520240784}]}, {"text": "The experiments were conducted on both the mixed and similar-phonemic datasets.", "labels": [], "entities": []}, {"text": "A baseline (Baseline) was implemented based on a statistical character-level transition model.", "labels": [], "entities": []}, {"text": "We calculated the frequency of character transitions between aliases and formal names in our training set and handled zerocount transitions using add-\u03b1 smoothing.", "labels": [], "entities": []}, {"text": "We use the pre-trained model (Mingpipe) provided by) as a comparable setting.", "labels": [], "entities": []}, {"text": "The Fixed Order HMM setting denotes the basic left-to-right HMM model.", "labels": [], "entities": [{"text": "Fixed Order HMM setting", "start_pos": 4, "end_pos": 27, "type": "DATASET", "confidence": 0.5233988836407661}]}, {"text": "To account for character sequence mismatches between alias and normal name, a simple solution is to rearrange the character order.", "labels": [], "entities": []}, {"text": "Thus the (All sequence baseline) and (All sequence HMM) settings try all possible character sequences for each alias with brute force and report the result of the highest matching sequence.", "labels": [], "entities": []}, {"text": "The (Fully Connected HMM) denotes a trained fully connected HMM model trained with our dataset and the (Fully connected No training) is a non-trained version.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 3: Similar-phonemic and mixed datasets", "labels": [], "entities": []}, {"text": " Table 4: The experiment result with similar-phonemic dataset and mixed dataset", "labels": [], "entities": []}, {"text": " Table 5: Top-N HMM results", "labels": [], "entities": [{"text": "HMM", "start_pos": 16, "end_pos": 19, "type": "TASK", "confidence": 0.6628997325897217}]}]}