{"title": [{"text": "Evaluating vector space models using human semantic priming results", "labels": [], "entities": []}], "abstractContent": [{"text": "Vector space models of word representation are often evaluated using human similarity ratings.", "labels": [], "entities": [{"text": "word representation", "start_pos": 23, "end_pos": 42, "type": "TASK", "confidence": 0.7517095804214478}]}, {"text": "Those ratings are elicited in explicit tasks and have well-known subjective biases.", "labels": [], "entities": []}, {"text": "As an alternative, we propose evaluating vector spaces using implicit cognitive measures.", "labels": [], "entities": []}, {"text": "We focus in particular on semantic priming, exploring the strengths and limitations of existing datasets, and propose ways in which those datasets can be improved.", "labels": [], "entities": [{"text": "semantic priming", "start_pos": 26, "end_pos": 42, "type": "TASK", "confidence": 0.7849432229995728}]}], "introductionContent": [{"text": "Vector space models of meaning (VSMs) represent the words of a vocabulary as points in a multidimensional space.", "labels": [], "entities": []}, {"text": "These models are often evaluated by assessing the extent to which relations between pairs of word vectors mirror relations between the words that correspond to those vectors.", "labels": [], "entities": []}, {"text": "This evaluation method requires us to select a word relation metric that can serve as ground truth, and it requires us to identify the particular types of relations that we would like our models to represent accurately.", "labels": [], "entities": []}, {"text": "Typical approaches to VSM evaluation use human annotations as ground truth: in particular, similarity ratings for pairs of words.", "labels": [], "entities": [{"text": "VSM evaluation", "start_pos": 22, "end_pos": 36, "type": "TASK", "confidence": 0.9758176505565643}]}, {"text": "Some evaluation datasets focus on similarity per se: hotscalding would rate highly, while antonyms like hot-cold and associates like hot-stove would not ().", "labels": [], "entities": [{"text": "similarity", "start_pos": 34, "end_pos": 44, "type": "METRIC", "confidence": 0.9500648379325867}]}, {"text": "Others do not distinguish similarity from other types of relations: synonyms, antonyms and associates can all receive high ratings (.", "labels": [], "entities": []}, {"text": "While the distinction between similarity and relatedness is important, it represents only a preliminary step toward a more precise understanding of what we mean-and what we should mean-when we talk about relations between words.", "labels": [], "entities": []}, {"text": "The notions of \"similarity\" and \"relatedness\" are fairly vaguely defined, and as a result human raters asked to quantify these relations must carryout some interpretations of their own with respect to the task, in order to settle upon a judgment schema and apply that schema to rate word pairs.", "labels": [], "entities": []}, {"text": "The fact that the definition of the relation structure is left to the annotator's judgment introduces interannotator variability as well as potentially undesirable properties of human similarity judgments: for example, the fact that they are not symmetric.", "labels": [], "entities": []}, {"text": "The subjectivity of this task, and the involvement of the conscious reasoning process needed to arrive at a rating (, raise the question: to what extent does the relation structure that emerges from such rating tasks reliably reflect the relation structure that underlies human language understanding?", "labels": [], "entities": []}, {"text": "After all, humans process language effortlessly, and natural language comprehension does not require reasoning about how similar or related words are.", "labels": [], "entities": []}, {"text": "This does not mean that the brain does not perform computations reflecting relations between words-evidence suggests that such computations occur constantly in language processing, but that these computations occur on a subconscious level (.", "labels": [], "entities": []}, {"text": "Fortunately, there are psycholinguistic paradigms that allow us to tap into this level of processing.", "labels": [], "entities": []}, {"text": "If we can make use of these subconscious cognitive measures of relatedness, we maybe able to continue taking advantage of humans as the source of ground truth on word relations-while avoiding the subjectivity and bias introduced by conscious rating tasks.", "labels": [], "entities": []}, {"text": "We propose to evaluate VSMs using semantic priming, a cognitive phenomenon understood to reflect word-level relation structure in the human brain.", "labels": [], "entities": [{"text": "VSMs", "start_pos": 23, "end_pos": 27, "type": "TASK", "confidence": 0.9262951016426086}]}, {"text": "We show some preliminary results exploring the ability of various VSMs to predict this measure, and discuss the potential for finergrained differentiation between specific types of word relations.", "labels": [], "entities": []}, {"text": "Finally, we argue that existing datasets (both explicit similarity judgments and semantic priming) are too small to meaningfully compare VSMs, and propose creating a larger semantic priming resource tailored to the needs of VSM evaluation.", "labels": [], "entities": [{"text": "VSM evaluation", "start_pos": 224, "end_pos": 238, "type": "TASK", "confidence": 0.9151797890663147}]}], "datasetContent": [{"text": "Most previous work has modeled small priming datasets.", "labels": [], "entities": []}, {"text": "By contrast, we follow in taking advantage of the online database of the Semantic Priming Project (SPP), which compiles priming data from 768 subjects for over 6000 word pairs.", "labels": [], "entities": []}, {"text": "This dataset's size alone is advantageous, as it potentially allows us to draw more confident conclusions about differences between models (as discussed below), and it ensures broader coverage in the vocabulary.", "labels": [], "entities": []}, {"text": "The SPP has two additional advantages that are relevant for our purposes.", "labels": [], "entities": [{"text": "SPP", "start_pos": 4, "end_pos": 7, "type": "TASK", "confidence": 0.8638859987258911}]}, {"text": "First, it contains data for four methodological variations on the semantic priming paradigm: all combinations of two tasks, lexical decision and naming, and two stimulus onset asynchronies (SOA), 200 ms and 1200 ms, which represent the amount of time between the start of the prime word and the start of the target word.", "labels": [], "entities": [{"text": "lexical decision and naming", "start_pos": 124, "end_pos": 151, "type": "TASK", "confidence": 0.6427498757839203}, {"text": "stimulus onset asynchronies (SOA)", "start_pos": 161, "end_pos": 194, "type": "METRIC", "confidence": 0.7617890735467275}]}, {"text": "We assess the usefulness of each of the methods for evaluating VSMs, in order to identify the methodological choices that generate optimal data for evaluation.", "labels": [], "entities": [{"text": "VSMs", "start_pos": 63, "end_pos": 67, "type": "TASK", "confidence": 0.8079521656036377}]}, {"text": "A second advantage of the SPP is that it contains annotations of the relation types of the word pairs; this property can allow for finer-grained analyses that focus on relations of particular interest, as we will discuss in greater detail below.", "labels": [], "entities": []}, {"text": "We evaluated the VSMs by fitting linear regression models to the human response times, with cosine similarity between prime and target as the predictor of interest.", "labels": [], "entities": [{"text": "VSMs", "start_pos": 17, "end_pos": 21, "type": "TASK", "confidence": 0.7883053421974182}]}, {"text": "As a simple baseline model, we entered only word frequency as a predictor.", "labels": [], "entities": []}, {"text": "Word frequency is widely recognized as a strong predictor of reaction time in language tasks (.", "labels": [], "entities": []}, {"text": "While it is only one among the factors known to affect the speed of word recognition (, it is by far the most important, and unlike factors such as word length, it is represented in many vector space models (, making it all the more important to control for here.", "labels": [], "entities": [{"text": "word recognition", "start_pos": 68, "end_pos": 84, "type": "TASK", "confidence": 0.8086798191070557}]}, {"text": "Finally, for the sake of comparison with conventional metrics, we include, which shows the same baseline and vector space regression models, assessed as predictors of the ratings in the MEN () and SimLex ( datasets.", "labels": [], "entities": [{"text": "MEN", "start_pos": 186, "end_pos": 189, "type": "DATASET", "confidence": 0.8528649210929871}, {"text": "SimLex ( datasets", "start_pos": 197, "end_pos": 214, "type": "DATASET", "confidence": 0.7790493567784628}]}, {"text": "Frequency appears to be a poorer predictor of explicit similarity ratings than of the implicit cognitive measures.", "labels": [], "entities": [{"text": "Frequency", "start_pos": 0, "end_pos": 9, "type": "METRIC", "confidence": 0.9579683542251587}]}, {"text": "Although there is some variation in performance between the four normally-trained VSMs, it is less straightforward to distinguish between them once we take confidence intervals into account; this issue of overlapping confidence intervals is much more pronounced with smaller datasets such as RG-65 and).", "labels": [], "entities": [{"text": "RG-65", "start_pos": 292, "end_pos": 297, "type": "DATASET", "confidence": 0.9513328075408936}]}], "tableCaptions": []}