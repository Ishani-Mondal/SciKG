{"title": [{"text": "Neural Clinical Paraphrase Generation with Attention", "labels": [], "entities": [{"text": "Neural Clinical Paraphrase Generation", "start_pos": 0, "end_pos": 37, "type": "TASK", "confidence": 0.7646768540143967}]}], "abstractContent": [{"text": "Paraphrase generation is important in various applications such as search, summarization, and question answering due to its ability to generate textual alternatives while keeping the overall meaning intact.", "labels": [], "entities": [{"text": "Paraphrase generation", "start_pos": 0, "end_pos": 21, "type": "TASK", "confidence": 0.9423599243164062}, {"text": "summarization", "start_pos": 75, "end_pos": 88, "type": "TASK", "confidence": 0.9582944512367249}, {"text": "question answering", "start_pos": 94, "end_pos": 112, "type": "TASK", "confidence": 0.8073052763938904}]}, {"text": "Clinical paraphrase generation is especially vital in building patient-centric clinical decision support (CDS) applications where users are able to understand complex clinical jargons via easily comprehensible alternative paraphrases.", "labels": [], "entities": [{"text": "Clinical paraphrase generation", "start_pos": 0, "end_pos": 30, "type": "TASK", "confidence": 0.6236929595470428}]}, {"text": "This paper presents Neural Clinical Paraphrase Generation (NCPG), a novel approach that casts the task as a monolingual neu-ral machine translation (NMT) problem.", "labels": [], "entities": [{"text": "Neural Clinical Paraphrase Generation (NCPG)", "start_pos": 20, "end_pos": 64, "type": "TASK", "confidence": 0.7807455105440957}, {"text": "neu-ral machine translation (NMT)", "start_pos": 120, "end_pos": 153, "type": "TASK", "confidence": 0.7937128841876984}]}, {"text": "We propose an end-to-end neural network built on an attention-based bidirectional Recurrent Neural Network (RNN) architecture with an encoder-decoder framework to perform the task.", "labels": [], "entities": []}, {"text": "Conventional bilingual NMT models mostly rely on word-level modeling and are often limited by out-of-vocabulary (OOV) issues.", "labels": [], "entities": []}, {"text": "In contrast, we represent the source and target paraphrase pairs as character sequences to address this limitation.", "labels": [], "entities": []}, {"text": "To the best of our knowledge, this is the first work that uses attention-based RNNs for clinical paraphrase generation and also proposes an end-to-end character-level modeling for this task.", "labels": [], "entities": [{"text": "paraphrase generation", "start_pos": 97, "end_pos": 118, "type": "TASK", "confidence": 0.8117985725402832}]}, {"text": "Extensive experiments on a large curated clinical paraphrase corpus show that the attention-based NCPG models achieve improvements of up to 5.2 BLEU points and 0.5 METEOR points over a non-attention based strong baseline for word-level modeling, whereas further gains of up to 6.1 BLEU points and 1.3 METEOR points are obtained by the character-level NCPG models over their word-level counterparts.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 144, "end_pos": 148, "type": "METRIC", "confidence": 0.9961138963699341}, {"text": "METEOR", "start_pos": 164, "end_pos": 170, "type": "METRIC", "confidence": 0.9861679673194885}, {"text": "BLEU", "start_pos": 281, "end_pos": 285, "type": "METRIC", "confidence": 0.993976354598999}, {"text": "METEOR", "start_pos": 301, "end_pos": 307, "type": "METRIC", "confidence": 0.9667548537254333}]}, {"text": "Overall, our models demonstrate comparable performance relative to the state-of-the-art phrase-based non-neural models.", "labels": [], "entities": []}], "introductionContent": [{"text": "Paraphrasing, the act of generating the same semantic content as the source in the same language, can help gain performance improvements in many NLP applications.", "labels": [], "entities": []}, {"text": "Examples include generating query variants or pattern alternatives for information retrieval, information extraction or question answering systems, creating reference paraphrases for automatic evaluation of machine translation and document summarization systems, and generating concise or simplified information for sentence compression or sentence simplification systems).", "labels": [], "entities": [{"text": "information retrieval", "start_pos": 71, "end_pos": 92, "type": "TASK", "confidence": 0.758158951997757}, {"text": "information extraction or question answering", "start_pos": 94, "end_pos": 138, "type": "TASK", "confidence": 0.7473385810852051}, {"text": "machine translation and document summarization", "start_pos": 207, "end_pos": 253, "type": "TASK", "confidence": 0.7818543076515198}, {"text": "sentence compression or sentence simplification", "start_pos": 316, "end_pos": 363, "type": "TASK", "confidence": 0.7090405225753784}]}, {"text": "In particular, paraphrase generation has a significant value in developing patient-centric intelligent clinical decision support (CDS) applications where users are able to understand complex clinical jargons via easily comprehensible alternative paraphrases.", "labels": [], "entities": [{"text": "paraphrase generation", "start_pos": 15, "end_pos": 36, "type": "TASK", "confidence": 0.9548880159854889}, {"text": "patient-centric intelligent clinical decision support (CDS)", "start_pos": 75, "end_pos": 134, "type": "TASK", "confidence": 0.6665366590023041}]}, {"text": "For example, the complex clinical term \"nocturnal enuresis\" can be paraphrased as \"nocturnal incontinence of urine\" or \"bedwetting\" to better clarify a well-known condition associated with children.", "labels": [], "entities": []}, {"text": "Traditional paraphrase generation methods exploit hand-crafted rules or automatically learned complex paraphrase patterns (, use thesaurus-based ( or semantic analysis driven natural language generation approaches (, or leverage statistical machine learning theory and principles).", "labels": [], "entities": [{"text": "paraphrase generation", "start_pos": 12, "end_pos": 33, "type": "TASK", "confidence": 0.9347885847091675}, {"text": "semantic analysis driven natural language generation", "start_pos": 150, "end_pos": 202, "type": "TASK", "confidence": 0.7051327526569366}]}, {"text": "In contrast, inspired by the recent success of bilingual neural machine translation (NMT)) that shows promising performance compared to the traditional statistical machine translation (SMT) approaches, we propose neural clinical paraphrase generation (NCPG) by casting the task as a monolingual NMT problem.", "labels": [], "entities": [{"text": "bilingual neural machine translation (NMT))", "start_pos": 47, "end_pos": 90, "type": "TASK", "confidence": 0.7841592005320958}, {"text": "statistical machine translation (SMT)", "start_pos": 152, "end_pos": 189, "type": "TASK", "confidence": 0.834099531173706}, {"text": "neural clinical paraphrase generation (NCPG)", "start_pos": 213, "end_pos": 257, "type": "TASK", "confidence": 0.7476401797362736}]}, {"text": "Unlike bilingual machine translation, monolingual machine translation considers the source language the same as the target language, which allows for its adaptation as a paraphrase generation task.", "labels": [], "entities": [{"text": "bilingual machine translation", "start_pos": 7, "end_pos": 36, "type": "TASK", "confidence": 0.7075790365537008}, {"text": "monolingual machine translation", "start_pos": 38, "end_pos": 69, "type": "TASK", "confidence": 0.6516402165095011}, {"text": "paraphrase generation task", "start_pos": 170, "end_pos": 196, "type": "TASK", "confidence": 0.7822581728299459}]}, {"text": "SMT systems ( use a noisy channel model to identify an optimal target sentence that maximizes its conditional probability given a source sentence.", "labels": [], "entities": [{"text": "SMT", "start_pos": 0, "end_pos": 3, "type": "TASK", "confidence": 0.9787812829017639}]}, {"text": "Ideally, this process uses the Bayes' rule to distinctly maximize the KL-divergence between a language model and a translation model from a monolingual and a parallel corpus, respectively.", "labels": [], "entities": []}, {"text": "However, NMT models are built from training a single end-to-end neural network architecture on a large parallel corpus that can directly optimize the conditional probability of an underlying sentence pair.", "labels": [], "entities": []}, {"text": "Such models typically follow an encoder-decoder approach by building a pair of neural networks, where the first network acts as an encoder to generate a fixed-length vector representation of the source sentence, which is in turn decoded by the second network to form a target sentence).", "labels": [], "entities": []}, {"text": "Recurrent Neural Network (RNN) architectures with Long Short-Term Memory (LSTM) or Gated Recurrent Units (GRU) () are generally utilized to train the end-to-end state-of-the-art NMT systems.", "labels": [], "entities": [{"text": "Long Short-Term Memory (LSTM)", "start_pos": 50, "end_pos": 79, "type": "METRIC", "confidence": 0.8087011228005091}]}, {"text": "Another effective NMT model has been proposed recently, which follows an attention-based soft-search approach to improve the performance of the encoder-decoder architectures (.", "labels": [], "entities": []}, {"text": "We use an attention-based bidirectional RNN architecture) with an encoder-decoder framework to build our NCPG models.", "labels": [], "entities": []}, {"text": "Bidirectional RNNs have been shown to outperform unidirectional RNNs for sequence to sequence learning tasks.", "labels": [], "entities": []}, {"text": "NMT models mostly rely on word-level modeling that often causes an out-of-vocabulary (OOV) issue while predicting a target word given an unknown source word ().", "labels": [], "entities": []}, {"text": "To address this limitation, we represent the source and target paraphrase pairs as character sequences and propose a character-level encoder-decoder framework for clinical paraphrase generation.", "labels": [], "entities": [{"text": "paraphrase generation", "start_pos": 172, "end_pos": 193, "type": "TASK", "confidence": 0.7564058601856232}]}, {"text": "To the best of our knowledge, this work is the first to adapt monolingual NMT for clinical paraphrase generation using an attention-based mechanism and also propose an end-to-end character-level NCPG model.", "labels": [], "entities": [{"text": "paraphrase generation", "start_pos": 91, "end_pos": 112, "type": "TASK", "confidence": 0.7267128229141235}]}, {"text": "Extensive experiments on a large curated clinical paraphrase corpus built on a benchmark parallel paraphrase database, PPDB 2.0 (), along with a comprehensive medical metathesaurus ( show that the proposed attention-based NCPG model can outperform an RNN encoder-decoder based strong baseline for word-level modeling, whereas character-level models can achieve further improvements over their word-level counterparts.", "labels": [], "entities": []}, {"text": "Overall, the proposed models demonstrate comparable performance relative to the state-of-the-art phrase-based conventional machine translation models.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 123, "end_pos": 142, "type": "TASK", "confidence": 0.7483713030815125}]}, {"text": "The main contributions of our paper can be summarized as follows: \u2022 We presented a novel approach for clinical paraphrase generation by casting the task as a monolingual neural machine translation problem.", "labels": [], "entities": [{"text": "paraphrase generation", "start_pos": 111, "end_pos": 132, "type": "TASK", "confidence": 0.8374070227146149}]}, {"text": "We proposed an end-to-end neural network model built on an attention-based bidirectional Recurrent Neural Network (RNN) architecture () with an encoder-decoder framework to perform the task.", "labels": [], "entities": []}, {"text": "\u2022 We also presented a novel character-based neural clinical paraphrase generation approach to overcome the OOV issues encountered by the word-level models.", "labels": [], "entities": [{"text": "character-based neural clinical paraphrase generation", "start_pos": 28, "end_pos": 81, "type": "TASK", "confidence": 0.6191645085811615}, {"text": "OOV", "start_pos": 107, "end_pos": 110, "type": "METRIC", "confidence": 0.6470237970352173}]}, {"text": "\u2022 We built a large curated paraphrase corpus using a benchmark parallel paraphrase database, PPDB 2.0 () along with a comprehensive medical metathesaurus, UMLS (Lindberg et al., 1993) for our experiments.", "labels": [], "entities": [{"text": "UMLS (Lindberg et al., 1993)", "start_pos": 155, "end_pos": 183, "type": "DATASET", "confidence": 0.8287909105420113}]}, {"text": "\u2022 We conducted rigorous automatic and manual evaluations of our models.", "labels": [], "entities": []}, {"text": "Results demonstrated that our proposed attention-based NCPG model can outperform an RNN encoder-decoder based strong baseline for word-level modeling, whereas character-level models can achieve further improvements.", "labels": [], "entities": []}, {"text": "Overall, our models showed comparable performance relative to the state-of-the-art phrase-based non-neural machine translation models.", "labels": [], "entities": [{"text": "phrase-based non-neural machine translation", "start_pos": 83, "end_pos": 126, "type": "TASK", "confidence": 0.5998025983572006}]}], "datasetContent": [{"text": "To quantitatively evaluate the performance of our paraphrase generation models, we use two well-known automatic metrics for machine translation evaluation: BLEU () and METEOR.", "labels": [], "entities": [{"text": "paraphrase generation", "start_pos": 50, "end_pos": 71, "type": "TASK", "confidence": 0.831449568271637}, {"text": "machine translation evaluation", "start_pos": 124, "end_pos": 154, "type": "TASK", "confidence": 0.8615702589352926}, {"text": "BLEU", "start_pos": 156, "end_pos": 160, "type": "METRIC", "confidence": 0.9988679885864258}, {"text": "METEOR", "start_pos": 168, "end_pos": 174, "type": "METRIC", "confidence": 0.926458477973938}]}, {"text": "Previous work has shown that these metrics can perform well for the paraphrase recognition task () and correlate well with human judgments in evaluating generated paraphrases.", "labels": [], "entities": [{"text": "paraphrase recognition task", "start_pos": 68, "end_pos": 95, "type": "TASK", "confidence": 0.9083718458811442}]}, {"text": "BLEU considers exact matching between target paraphrases and system generated paraphrases by considering n-gram overlaps.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 0, "end_pos": 4, "type": "METRIC", "confidence": 0.9119328856468201}]}, {"text": "Meanwhile, METEOR improves upon this measure via stemming and synonymy using WordNet.", "labels": [], "entities": [{"text": "METEOR", "start_pos": 11, "end_pos": 17, "type": "DATASET", "confidence": 0.5575317144393921}, {"text": "WordNet", "start_pos": 77, "end_pos": 84, "type": "DATASET", "confidence": 0.9780557155609131}]}, {"text": "We compute BLEU scores with jBLEU V0.1.1 (an exact reimplementation of NIST's mteval-v13.pl without tokenization) and METEOR scores using METEOR V1.4 with all default settings.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 11, "end_pos": 15, "type": "METRIC", "confidence": 0.9981421232223511}, {"text": "METEOR", "start_pos": 118, "end_pos": 124, "type": "METRIC", "confidence": 0.8793792724609375}]}, {"text": "shows the average BLEU and METEOR scores for the NCPG models considering the source and the target paraphrases as references to the system generated paraphrases.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 18, "end_pos": 22, "type": "METRIC", "confidence": 0.9992648959159851}, {"text": "METEOR", "start_pos": 27, "end_pos": 33, "type": "METRIC", "confidence": 0.9948179125785828}, {"text": "NCPG", "start_pos": 49, "end_pos": 53, "type": "DATASET", "confidence": 0.9710200428962708}]}, {"text": "The input/prediction level for all models are denoted in parenthesis.", "labels": [], "entities": []}, {"text": "Moses is the word-level statistical paraphrase generation model trained using the Moses package.", "labels": [], "entities": [{"text": "word-level statistical paraphrase generation", "start_pos": 13, "end_pos": 57, "type": "TASK", "confidence": 0.5575238689780235}]}, {"text": "Source-Target refers to the scores computed between the source and the target paraphrase pairs of the test set, because the source text is also a paraphrase of the target text.", "labels": [], "entities": []}, {"text": "This can essentially serve as an upper bound of the paraphrasing scores ().", "labels": [], "entities": []}, {"text": "Our results show that all NCPG models perform relatively better than Source-Target in terms of BLEU scores.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 95, "end_pos": 99, "type": "METRIC", "confidence": 0.9992942810058594}]}, {"text": "Similar trend is also seen for METEOR scores.", "labels": [], "entities": [{"text": "METEOR", "start_pos": 31, "end_pos": 37, "type": "METRIC", "confidence": 0.8370773792266846}]}, {"text": "We also observe that Moses obtains the highest scores, which is expected because Moses uses an additional monolingual training corpus of 418M words that was not used to train our NCPG models.", "labels": [], "entities": []}, {"text": "Moreover, as BLEU and METEOR scores consider the number of word/synonym overlaps between the source and target paraphrase pairs, our qualitative evaluation (reported in the next subsection) reveals that Moses often repeats the source text as the generated target paraphrases and achieves higher scores for exact matching.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 13, "end_pos": 17, "type": "METRIC", "confidence": 0.9981326460838318}, {"text": "METEOR", "start_pos": 22, "end_pos": 28, "type": "METRIC", "confidence": 0.9843666553497314}]}, {"text": "This phenomenon is also evident from the Source-Target scores, which denote that models can achieve lower BLEU/METEOR scores even though they generate better quality paraphrases.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 106, "end_pos": 110, "type": "METRIC", "confidence": 0.9987688660621643}, {"text": "METEOR", "start_pos": 111, "end_pos": 117, "type": "METRIC", "confidence": 0.7563186287879944}]}, {"text": "The results also reveal that the attention-based NCPG models mostly outperform the RNN encoderdecoder models, and char-level NCPG models perform considerably better than their word-level counterparts.", "labels": [], "entities": []}, {"text": "Qualitative analysis revealed that word-level NCPG models largely suffered from OOV issues while char-level models could efficiently deal with this problem.", "labels": [], "entities": [{"text": "OOV", "start_pos": 80, "end_pos": 83, "type": "METRIC", "confidence": 0.8855457305908203}]}, {"text": "This is a noteworthy achievement because our character-level models do not require language-dependent grammatical pre-processing and they learn from efficient encoding of character sequences while being tolerant to spelling errors, a very common occurrence in clinical documents.", "labels": [], "entities": []}, {"text": "We hypothesize that the results of the char-level models would further improve if pre-trained character embeddings based on a large background clinical corpus (e.g. biomedical literature corpus such as PubMed Central 3 ) can be used during training.: Automatic evaluation scores for all models.", "labels": [], "entities": [{"text": "PubMed Central 3", "start_pos": 202, "end_pos": 218, "type": "DATASET", "confidence": 0.8859823346138}]}, {"text": "Automatic evaluation of paraphrasing is difficult as BLEU and METEOR can capture the textual similarity while disregarding the novelty of the generated paraphrases.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 53, "end_pos": 57, "type": "METRIC", "confidence": 0.9965081810951233}, {"text": "METEOR", "start_pos": 62, "end_pos": 68, "type": "METRIC", "confidence": 0.79816734790802}]}, {"text": "Hence, we conduct human evaluation to qualitatively evaluate the performance of our NCPG models.", "labels": [], "entities": []}, {"text": "We use a methodology derived from for this purpose.", "labels": [], "entities": []}, {"text": "Five judges (familiar with the clinical domain) evaluated the quality of a randomly selected subset (2%) of the paraphrases from the test set using three criteria: 1) semantic relatedness: whether the overall meaning is preserved in the paraphrase, 2) novelty 4 : if the paraphrase is considerably different from the source text, and 3) grammaticality: if the paraphrase is syntactically correct and fluent.", "labels": [], "entities": [{"text": "novelty", "start_pos": 252, "end_pos": 259, "type": "METRIC", "confidence": 0.9592154622077942}]}, {"text": "The judges were presented with the source and the target text along with the system generated paraphrases.", "labels": [], "entities": []}, {"text": "Note that, the target text is considered as one of many candidate paraphrases of the source text.", "labels": [], "entities": []}, {"text": "For each of the criteria, the judges assigned an integer score between 1 (very poor) and 5 (very good) to each paraphrase.", "labels": [], "entities": []}, {"text": "System settings and model identities were not disclosed to the judges during evaluation.", "labels": [], "entities": []}, {"text": "shows the average quality scores for all models.", "labels": [], "entities": []}, {"text": "These results demonstrate that on average, our attention-based models (NCPG-2) outperform the NCPG-1 models, and char-level models perform better than word-level models in terms of semantic relatedness and grammaticality while underperforming in terms of novelty.", "labels": [], "entities": []}, {"text": "Furthermore, our word-level NCPG models perform better than Moses in terms of novelty (up to 22% improvement) as Moses often generates the same paraphrase as the source sequence.", "labels": [], "entities": [{"text": "novelty", "start_pos": 78, "end_pos": 85, "type": "METRIC", "confidence": 0.9871723055839539}]}, {"text": "These results show that on average, our proposed models perform on par with Moses and Source-Target.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Automatic evaluation scores for all models.", "labels": [], "entities": [{"text": "Automatic", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9272889494895935}]}, {"text": " Table 2: Human evaluation scores for all models.", "labels": [], "entities": []}]}