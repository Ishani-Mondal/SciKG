{"title": [{"text": "Automatic Analysis of Flaws in Pre-Trained NLP Models", "labels": [], "entities": [{"text": "Automatic Analysis of Flaws", "start_pos": 0, "end_pos": 27, "type": "TASK", "confidence": 0.7243163287639618}]}], "abstractContent": [{"text": "Most tools for natural language processing (NLP) today are based on machine learning and come with pre-trained models.", "labels": [], "entities": [{"text": "natural language processing (NLP)", "start_pos": 15, "end_pos": 48, "type": "TASK", "confidence": 0.8206969400246938}]}, {"text": "In addition, third-parties provide pre-trained models for popular NLP tools.", "labels": [], "entities": []}, {"text": "The predictive power and accuracy of these tools depends on the quality of these models.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 25, "end_pos": 33, "type": "METRIC", "confidence": 0.9988768696784973}]}, {"text": "Downstream researchers often base their results on pre-trained models instead of training their own.", "labels": [], "entities": []}, {"text": "Consequently, pre-trained models are an essential resource to our community.", "labels": [], "entities": []}, {"text": "However, to be best of our knowledge, no systematic study of pre-trained models has been conducted so far.", "labels": [], "entities": []}, {"text": "This paper reports on the analysis of 274 pre-models for six NLP tools and four potential causes of problems: encoding, tokenization, normalization, and changeover time.", "labels": [], "entities": []}, {"text": "The analysis is implemented in the open source tool Model Investigator.", "labels": [], "entities": []}, {"text": "Our work 1) allows model consumers to better assess whether a model is suitable for their task, 2) enables tool and model creators to sanity-check their models before distributing them, and 3) enables improvements in tool inter-operability by performing automatic adjustments of normalization or other pre-processing based on the models used.", "labels": [], "entities": []}], "introductionContent": [{"text": "As natural language processing (NLP) has become a pervasive technology in many research and application domains, NLP tools and the pre-trained models that ship with them or that are provided by third parties have become essential resources.", "labels": [], "entities": [{"text": "natural language processing (NLP)", "start_pos": 3, "end_pos": 36, "type": "TASK", "confidence": 0.7951079706350962}]}, {"text": "Often, researchers and other users do not have access to text corpora from which they could train suitable models themselves or simply prefer the convenience of using existing models.", "labels": [], "entities": []}, {"text": "Users of centrally provided NLP infrastructures may not even have the option of using models other that those offered within the platform.", "labels": [], "entities": []}, {"text": "However, this entails that any problems with these models, propagate into subsequent NLP components in a pipeline or into data analytics and negatively influence them.", "labels": [], "entities": []}, {"text": "Worst of all, the consumers of pre-trained models may not even be aware of the problems the models exhibit.", "labels": [], "entities": []}, {"text": "We hope to raise more awareness through this paper by reporting on an analysis of pre-trained models for typical sources of problems: encoding, tokenization, normalization, and changes between different released versions (Section 3).", "labels": [], "entities": []}, {"text": "The analysis is based on a dataset of 274 pre-trained models for six popular NLP tools.", "labels": [], "entities": []}, {"text": "To the best of our knowledge, this is the first systematic analysis of pre-trained models for flaws and other sources of problems.", "labels": [], "entities": []}, {"text": "We have observed that some models have been distributed with serious flaws for years and have informed the model creators of the problems.", "labels": [], "entities": []}, {"text": "The open source tool Model Investigator 1 that was created and used to perform this analysis (Section 2).", "labels": [], "entities": []}, {"text": "It can be used by model creators to perform automatic sanity checks on their models and by model consumers to obtain detailed information about new models as they become available.", "labels": [], "entities": []}, {"text": "The modular tool can easily be extended to support pre-trained models of new NLP tools.", "labels": [], "entities": []}, {"text": "Finally, we investigate the negative impact of flawed models in a case study: models trained with a bad character encoding (Section 4).", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Analyzed tools, series, and models", "labels": [], "entities": []}, {"text": " Table 2: Models with encoding problems (* affected entires for most recent version).", "labels": [], "entities": []}, {"text": " Table 3: Percentage of split lexicon entries for English pre-trained models of six NLP tools", "labels": [], "entities": []}, {"text": " Table 5: Normalization issues (* no 1% cutoff)", "labels": [], "entities": [{"text": "Normalization", "start_pos": 10, "end_pos": 23, "type": "TASK", "confidence": 0.8887120485305786}]}, {"text": " Table 6: Series with lexicon size changes (> 1%)", "labels": [], "entities": []}]}