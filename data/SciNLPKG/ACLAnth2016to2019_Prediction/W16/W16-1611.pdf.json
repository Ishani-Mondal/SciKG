{"title": [], "abstractContent": [{"text": "We introduce an LSTM-based method for dynamically integrating several word-prediction experts to obtain a conditional language model which can be good simultaneously at several subtasks.", "labels": [], "entities": []}, {"text": "We illustrate this general approach with an application to dialogue where we integrate a neural chat model, good at conversational aspects, with a neural question-answering model, good at retrieving precise information from a knowledge-base, and show how the integration combines the strengths of the independent components.", "labels": [], "entities": []}, {"text": "We hope that this focused contribution will attract attention on the benefits of using such mixtures of experts in NLP and dialogue systems specifically.", "labels": [], "entities": []}], "introductionContent": [{"text": "The mainstream architecture for virtual agents in dialogue systems) involves a combination of several components, which require a lot of expertise in the different technologies, considerable development and implementation effort to adapt each component to anew domain, and are only partially trainable (if at all).", "labels": [], "entities": []}, {"text": "Recently,,,  proposed to replace this complex architecture by a single network (such as a Long Short Term Memory (LSTM)) that predicts the agent's response from the dialogue history up to the point where it should be produced: this network can be seen as a form of conditional neural language model (LM), where * Work performed during Phong Le's internship at XRCE in 2015.", "labels": [], "entities": []}, {"text": "the dialogue history provides the context for the production of the next agent's utterance.", "labels": [], "entities": []}, {"text": "Despite several advantages over the traditional architecture (learnability, adaptability, better approximations to human utterances), this approach is inferior in one dimension: it assumes that all the knowledge required for the next agent's utterance has to be implicitly present in the dialogues over which the network is trained, and to then be precisely memorized by the network, while the traditional approach allows this knowledge to be dynamically accessed from external knowledge-base (KB) sources, with guaranteed accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 523, "end_pos": 531, "type": "METRIC", "confidence": 0.995079517364502}]}, {"text": "To address this issue, we propose the following approach.", "labels": [], "entities": []}, {"text": "As in, we first do train a conditional neural LM based on existing dialogues, which we call our chat model; this model can be seen as an \"expert\" about the conversational patterns in the dialogue, but not about its knowledge-intensive aspects.", "labels": [], "entities": []}, {"text": "Besides, we train another model, which this time is an expert about these knowledge aspects, which we call our QA model, due to its connections to Question Answering (QA).", "labels": [], "entities": [{"text": "Question Answering (QA)", "start_pos": 147, "end_pos": 170, "type": "TASK", "confidence": 0.8263882517814636}]}, {"text": "We then combine these two expert models through an LSTM-based integration model, which at each time step, encodes the whole history into a vector and then uses a softmax layer to compute a probability mixture over the two models, from which the next token is then sampled.", "labels": [], "entities": []}, {"text": "While here we combine in this way only two models, this core contribution of our paper is immediately generalizable to several expert models, each competent on a specific task, where the (soft) choice between the models is done through the same kind of contextually-aware \"attention\" mechanism.", "labels": [], "entities": []}, {"text": "Additional smaller contributions consist in the neural regime we adopt for training the QA model, the way in which we reduce the memorization requirements on this model.", "labels": [], "entities": []}, {"text": "It is worth noting that concurrently with our work, have proposed a similar idea focusing only on QA in a traditional set-up.", "labels": [], "entities": []}, {"text": "Our case is more difficult because of the chat interaction; and the integration framework we propose is generally applicable to situations where a pool of word-prediction \"experts\" compete for attention during the generation of text.", "labels": [], "entities": []}, {"text": "Outside of dialogue applications, also independently and even more recently, have proposed a \"Latent Predictor Network for Code Generation\", which has some close similarities to our LSTMbased mixture of experts.", "labels": [], "entities": [{"text": "Code Generation", "start_pos": 123, "end_pos": 138, "type": "TASK", "confidence": 0.7758511900901794}]}], "datasetContent": [{"text": "We implement our models in C++ using CUDA.", "labels": [], "entities": []}, {"text": "Since automatically evaluating a conversation system is still challenging, we, following, use word perplexity only.", "labels": [], "entities": []}, {"text": "In our experiments, every LSTM has 1024 hidden units and 1024 memory cells.", "labels": [], "entities": []}, {"text": "The vocabulary of the chat model has 19.3k words, that of the QA model 12.7k words.", "labels": [], "entities": []}, {"text": "We firstly train the chat model on all chat data with the learning rate 0.01, and continue training it on the device-specification data with the learning rate 0.001.", "labels": [], "entities": []}, {"text": "Using this smaller learning rate we expect that the model will not forget what it has learnt on all the chat corpus.", "labels": [], "entities": []}, {"text": "Next, we train the QA model on the data generated in Section 4.2 with the learning rate 0.01.", "labels": [], "entities": []}, {"text": "Finally, we train the integration model on the device-specification training data also with the learning rate 0.01.", "labels": [], "entities": []}, {"text": "Our initial results are as follows.", "labels": [], "entities": []}, {"text": "The integration slightly increases the perplexity on all tokens (15.4, compared to 14.7 of the chat model), but it does help to significantly decrease perplexity 38% on the numeric tokens (46.8, compared to 75.8 of the chat model).", "labels": [], "entities": []}, {"text": "This decrease is due to the improved ability of the integration model to detect places where a numeric value associated with a device-attribute information request should be inserted and to predict this value.", "labels": [], "entities": []}, {"text": "Not all numeric values are associated with information requests of this type, but the reported perplexities are overall numeric values.", "labels": [], "entities": []}, {"text": "The decrease in perplexity over the numeric values is not enough to decrease overall perplexity because the numeric tokens represent only 6.7% of the tokens, and the integration model wrongly puts some small probability mass on the QA expert also in the case of the many nonnumeric tokens.", "labels": [], "entities": []}, {"text": "However, the fact that the perplexity decreases over the numeric tokens shows that the integration model is useful for predicting correct values, which are informationally much more critical to the user than general words (admittedly, perplexity is here a weak proxy for what a human evaluation of usefulness would provide.) shows a chat example with our integration model.", "labels": [], "entities": []}], "tableCaptions": []}