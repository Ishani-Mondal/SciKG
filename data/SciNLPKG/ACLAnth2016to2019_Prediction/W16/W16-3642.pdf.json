{"title": [{"text": "Reference Resolution in Situated Dialogue with Learned Semantics", "labels": [], "entities": [{"text": "Reference Resolution", "start_pos": 0, "end_pos": 20, "type": "TASK", "confidence": 0.7084351778030396}]}], "abstractContent": [{"text": "Understanding situated dialogue requires identifying referents in the environment to which the dialogue participants refer.", "labels": [], "entities": []}, {"text": "This reference resolution problem, often in a complex environment with high ambiguity , is very challenging.", "labels": [], "entities": [{"text": "reference resolution", "start_pos": 5, "end_pos": 25, "type": "TASK", "confidence": 0.8722665309906006}]}, {"text": "We propose an approach that addresses those challenges by combining learned semantic structure of referring expressions with dialogue history into a ranking-based model.", "labels": [], "entities": []}, {"text": "We evaluate the new technique on a corpus of human-human tutorial dialogues for computer programming.", "labels": [], "entities": []}, {"text": "The experimental results show a substantial performance improvement over two recent state-of-the-art approaches.", "labels": [], "entities": []}, {"text": "The proposed work makes astride toward automated dialogue in complex problem-solving environments.", "labels": [], "entities": []}], "introductionContent": [{"text": "The content of a situated dialogue is very closely related to the environment in which it happens.", "labels": [], "entities": []}, {"text": "As dialogue systems move toward assisting users in increasingly complex tasks, these systems must understand users' language within the environment of the tasks.", "labels": [], "entities": []}, {"text": "To achieve this goal, dialogue systems must perform reference resolution, which involves identifying the referents in the environment that the user refers to (;).", "labels": [], "entities": [{"text": "reference resolution", "start_pos": 52, "end_pos": 72, "type": "TASK", "confidence": 0.7243890017271042}]}, {"text": "Imagine a dialogue system that assists a novice student in solving a programming problem.", "labels": [], "entities": []}, {"text": "To understand a question or statement the student poses, such as, \"Should I use the 2 dimensional array?\", the system must link the referring expression \"the 2 dimensional array\" to an object 1 in the environment.", "labels": [], "entities": []}, {"text": "This process is illustrated in, which shows an excerpt from a corpus of tutorial dialogue situated in an introductory computer programming task in the Java programming language.", "labels": [], "entities": []}, {"text": "The arrows link referring expressions in the situated dialogue to their referents in the environment.", "labels": [], "entities": []}, {"text": "To identify the referent of each referring expression, it is essential to capture the semantic structure of the referring expression of the object it refers to, such as \"the 2 dimensional array\" contains two attributes, \"2 dimensional\" and \"array\".", "labels": [], "entities": []}, {"text": "At the same time, the dialogue history and the history of user task actions (such as editing the code) play a key role.", "labels": [], "entities": []}, {"text": "To disambiguate the referent of \"my array\", temporal information is needed: in this case, the referent is a variable named arra, which is an array that the student has just created.", "labels": [], "entities": []}, {"text": "Reference resolution in situated dialogue is challenging because of the ambiguity inherent within dialogue utterances and the complexity of the environment.", "labels": [], "entities": [{"text": "Reference resolution", "start_pos": 0, "end_pos": 20, "type": "TASK", "confidence": 0.9681093990802765}]}, {"text": "Prior work has leveraged dialogue history and task history information to improve the accuracy of reference resolution).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 86, "end_pos": 94, "type": "METRIC", "confidence": 0.9989207983016968}, {"text": "reference resolution", "start_pos": 98, "end_pos": 118, "type": "TASK", "confidence": 0.7530494332313538}]}, {"text": "However, these prior approaches have employed relatively simple semantic information from the referring expressions, such as a manually created lexicon, or have operated within an environment with a limited set of pre-defined objects.", "labels": [], "entities": []}, {"text": "Besides reference resolution in situated dialogue, there is also a research direction in which machine learning models are used to learn the semantics of noun phrases in order to map noun phrases to objects in a related environment ().", "labels": [], "entities": [{"text": "reference resolution", "start_pos": 8, "end_pos": 28, "type": "TASK", "confidence": 0.7886902093887329}]}, {"text": "However, these prior approaches operated at the granularity of single of the corpus utilized in this work.", "labels": [], "entities": []}, {"text": "However, we follow the standard usage of \"object\" in situated dialogue (, which for programming is any portion of code in the environment.", "labels": [], "entities": []}, {"text": "spoken utterances not contextualized within a dialogue history, and they too focus on environments with a limited number (and a pre-defined set) of objects.", "labels": [], "entities": []}, {"text": "As this paper demonstrates, these prior approaches do not perform well in situated dialogues for complex problem solving, in which the user creates, modifies, and removes objects from the environment in unpredictable ways.", "labels": [], "entities": [{"text": "problem solving", "start_pos": 105, "end_pos": 120, "type": "TASK", "confidence": 0.8358080983161926}]}, {"text": "To tackle the problem of reference resolution in this type of situated dialogue, we propose an approach that combines semantics from a conditional-random-field-based semantic parser along with salient features from dialogue history and task history.", "labels": [], "entities": [{"text": "reference resolution", "start_pos": 25, "end_pos": 45, "type": "TASK", "confidence": 0.7516389489173889}]}, {"text": "We evaluate this approach on the JavaTutor corpus, a corpus of textual tutorial dialogue collected within an online environment for computer programming.", "labels": [], "entities": [{"text": "JavaTutor corpus", "start_pos": 33, "end_pos": 49, "type": "DATASET", "confidence": 0.8494812548160553}]}, {"text": "The results show that our approach achieves substantial improvement over two existing state-of-the-art approaches, with existing approaches achieving 55.2% accuracy at best, and the new approach achieving 68.5% accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 156, "end_pos": 164, "type": "METRIC", "confidence": 0.9987800717353821}, {"text": "accuracy", "start_pos": 211, "end_pos": 219, "type": "METRIC", "confidence": 0.9974169731140137}]}, {"text": "Typos and syntactic errors are shown as they appear in the original corpus.", "labels": [], "entities": [{"text": "Typos", "start_pos": 0, "end_pos": 5, "type": "METRIC", "confidence": 0.7406368255615234}]}], "datasetContent": [{"text": "To evaluate the new approach, we performed a set of experiments that compare our approach with two state-of-the-art approaches.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 3 Reference resolution results.", "labels": [], "entities": [{"text": "resolution", "start_pos": 19, "end_pos": 29, "type": "METRIC", "confidence": 0.8856189846992493}]}, {"text": " Table 4 Reference resolution results with gold se- mantic labels.", "labels": [], "entities": []}]}