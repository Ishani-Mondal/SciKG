{"title": [{"text": "Enriching a Valency Lexicon by Deverbative Nouns", "labels": [], "entities": []}], "abstractContent": [{"text": "In this paper, we present an attempt to automatically identify Czech deverbative nouns using several methods that use large corpora as well as existing lexical resources.", "labels": [], "entities": []}, {"text": "The motivation for the task is to extend a verbal valency (i.e., predicate-argument) lexicon by adding nouns that share the valency properties with the base verb, assuming their properties can be derived (even if not trivially) from the underlying verb by deterministic grammatical rules.", "labels": [], "entities": []}, {"text": "At the same time, even in inflective languages, not all deverbatives are simply created from their underlying base verb by regular lexical derivation processes.", "labels": [], "entities": []}, {"text": "We have thus developed hybrid techniques that use both large parallel corpora and several standard lexical resources.", "labels": [], "entities": []}, {"text": "Thanks to the use of parallel corpora, the resulting sets contain also synonyms, which the lexical derivation rules cannot get.", "labels": [], "entities": []}, {"text": "For evaluation, we have manually created a gold dataset of deverbative nouns linked to 100 frequent Czech verbs since no such dataset was initially available for Czech.", "labels": [], "entities": []}], "introductionContent": [{"text": "Valency is one of the central notions in a \"deep\" syntactic and semantic description of language structure.", "labels": [], "entities": []}, {"text": "In most accounts, verbs are in the focus of any valency (or predicate-argument) theory, even if it is widely acknowledged that nouns, adjectives and even adverbs can have valency properties.", "labels": [], "entities": []}, {"text": "There have been created many lexicons that contain verbs and their predicate-argument structure and/or valency, in some cases also subcategorization information or semantic preferences are included.", "labels": [], "entities": []}, {"text": "Creating such a lexicon is a laborious task.", "labels": [], "entities": []}, {"text": "On top of the sheer volume of such a lexicon (to achieve good coverage of the given language), the biggest difficulty is to keep consistency among entries that describe verbs with the same or very similar behavior.", "labels": [], "entities": [{"text": "consistency", "start_pos": 129, "end_pos": 140, "type": "METRIC", "confidence": 0.9640324115753174}]}, {"text": "The same holds for derivations; inmost cases, no attempt is made to link the derivations to the base verbs in the lexicon (with NomBank () being an exception, linking nouns to base verbs in the English PropBank).", "labels": [], "entities": [{"text": "PropBank", "start_pos": 202, "end_pos": 210, "type": "DATASET", "confidence": 0.6154665946960449}]}, {"text": "Valency information (number and function of the arguments) is shared between the base verb and its deverbatives, undergoing certain transformations in defined cases.", "labels": [], "entities": []}, {"text": "Moreover, especially in richly inflective languages, the subcategorization information (morphosyntactic surface expression of the arguments) can be derived by more or less deterministic rules from the verb, the deverbative relation and the verb's arguments' subcategorization).", "labels": [], "entities": []}, {"text": "These rules, for example, transform the case of Actor (Deep subject) from nominative to genitive as the appropriate subcategorization for the deverbative noun, or delete the Actor altogether from the list of arguments in case of the derivation teach \u2192 teacher (u\u010dit \u2192 u\u010ditel).", "labels": [], "entities": []}, {"text": "It is thus natural to look for ways of organizing the valency or predicate-argument lexicons in such away that they contain the links between the underlying verb and its deverbatives, which is not only natural, but if successful, would help the consistency of the grammatical properties between the verb and its deverbatives.", "labels": [], "entities": []}, {"text": "The goal of this study is to automatically discover deverbative nouns related to (base) verbs, using primarily parallel corpora, but also existing lexicons (mainly as an additional source and for comparison).", "labels": [], "entities": []}, {"text": "The use of a parallel corpus should give us those deverbatives which would otherwise be hard to find using only monolingual resources.", "labels": [], "entities": []}, {"text": "However, it is not our goal hereto fully transfer the valency information from the base verb -as mentioned in the previous paragraph, that work is being done separately and we assume its results (i.e., the transfer rules) can then be applied relatively easily if we are successful in discovering and linking the appropriate nouns to the base verb.", "labels": [], "entities": []}, {"text": "In order to evaluate and compare the resulting automatic systems, evaluation (gold-standard) data had to be developed, due to the lack of such a resource.", "labels": [], "entities": []}, {"text": "The language selected for this project is Czech, a richly inflectional language where derivations can be related to the word from which they are derived by regular changes (stemming with possible phonological changes, suffixing, prefixing) or -as is often the case -by more or less irregular processes.", "labels": [], "entities": []}, {"text": "There are many types (and definitions) of event/deverbative nouns.", "labels": [], "entities": []}, {"text": "We are using the more general term deverbative throughout here, to avoid possible narrow interpretation of \"event\".", "labels": [], "entities": []}, {"text": "For the purpose of our study and experiments, a deverbative noun is defined as a noun which in fact describes a state or event and can be easily paraphrased using its base verb without substantial change in meaning.", "labels": [], "entities": []}, {"text": "For example, Po \u00faderu do jeho hlavy utekl.", "labels": [], "entities": []}, {"text": "(lit. After hitting him in the head he ran away.) can be paraphrased as Pot\u00e9, coho ude\u0159il do hlavy, utekl.", "labels": [], "entities": []}, {"text": "(lit: After he hit him in the head, he ran away.).", "labels": [], "entities": []}, {"text": "The same noun can be used as a deverbative noun or entity-referring (referential) noun in different contexts; in Czech, however, this is rarer as the noun itself would be different for the two cases.", "labels": [], "entities": []}, {"text": "For example, stavba (lit: building) in P\u0159i stavb\u011b domu jim do\u0161ly pen\u00edze.", "labels": [], "entities": []}, {"text": "(lit: During the building of the house, they ran out of money.) is an event noun, while in Tato stavba [= budova] se prodala levn\u011b.", "labels": [], "entities": []}, {"text": "(lit: This building sold cheaply.) it refers to an entity; here, even in Czech the same noun is used.", "labels": [], "entities": []}, {"text": "However, another Czech derivations, stav\u011bn\u00ed (from the same base verb, stav\u011bt) can only be used as event noun, and staven\u00ed only as a referential one.", "labels": [], "entities": []}, {"text": "We also use the term derivation in a very broad sense, not only describing the very regular and productive derivation such as English -ing (Czech: -\u02c7 en\u00ed, -a/\u00e1n\u00ed, -\u00ed/\u00e1v\u00e1n\u00ed, -(u)t\u00ed, ...), but also those which are much less frequent (-ba, -nost, -ota).", "labels": [], "entities": []}], "datasetContent": [{"text": "The measure used has been F-measure (F 1 ), see Eq.", "labels": [], "entities": [{"text": "F-measure (F 1 )", "start_pos": 26, "end_pos": 42, "type": "METRIC", "confidence": 0.8184963762760162}]}, {"text": "1. The design of the experiments has intentionally been wide to assess how either high recall or high precision can be obtained; depending on the use of the resulting sets of deverbatives, one may prefer precision (P) or recall (R); therefore, for all experiments, we report, in addition to the standard F 1 measure, also both P and R.", "labels": [], "entities": [{"text": "recall", "start_pos": 87, "end_pos": 93, "type": "METRIC", "confidence": 0.9958096742630005}, {"text": "precision", "start_pos": 102, "end_pos": 111, "type": "METRIC", "confidence": 0.9913846254348755}, {"text": "precision (P)", "start_pos": 204, "end_pos": 217, "type": "METRIC", "confidence": 0.9311521202325821}, {"text": "recall (R)", "start_pos": 221, "end_pos": 231, "type": "METRIC", "confidence": 0.945095881819725}, {"text": "F 1 measure", "start_pos": 304, "end_pos": 315, "type": "METRIC", "confidence": 0.9528749187787374}]}, {"text": "All experiments have been evaluated on all three versions of the evaluation dataset (see Sect.", "labels": [], "entities": []}, {"text": "4 for more details on the evaluation dataset properties and the preparation process).", "labels": [], "entities": []}, {"text": "We also report results on the development dataset, just as a sanity check.", "labels": [], "entities": []}, {"text": "The results are summarized in  The best F 1 scores are in bold, the best and second best (and close) recall scores are in italics.", "labels": [], "entities": [{"text": "F 1 scores", "start_pos": 40, "end_pos": 50, "type": "METRIC", "confidence": 0.9395122528076172}, {"text": "recall", "start_pos": 101, "end_pos": 107, "type": "METRIC", "confidence": 0.9895769357681274}]}, {"text": "To interpret the table, one has to take into account the ultimate goals for which the discovered deverbatives will be used.", "labels": [], "entities": []}, {"text": "If the goal is to acquire all possible nouns which could possibly be deverbatives, and select and process them manually to extend, say, an existing noun valency / predicate argument lexicon, recall R will be more important than precision or the equal-weighted F 1 score.", "labels": [], "entities": [{"text": "recall", "start_pos": 191, "end_pos": 197, "type": "METRIC", "confidence": 0.9972021579742432}, {"text": "R", "start_pos": 198, "end_pos": 199, "type": "METRIC", "confidence": 0.5089383721351624}, {"text": "precision", "start_pos": 228, "end_pos": 237, "type": "METRIC", "confidence": 0.9997298121452332}, {"text": "F 1 score", "start_pos": 260, "end_pos": 269, "type": "METRIC", "confidence": 0.9459830323855082}]}, {"text": "On the other hand, if the results are to be used, e.g., as features in downstream automatic processing or in NLP machine learning experiments, the F 1 measure, or perhaps precision P, would be preferred as the main selection criterion.", "labels": [], "entities": [{"text": "F 1 measure", "start_pos": 147, "end_pos": 158, "type": "METRIC", "confidence": 0.9787410100301107}, {"text": "precision P", "start_pos": 171, "end_pos": 182, "type": "METRIC", "confidence": 0.9737420976161957}]}, {"text": "It is clear that there are huge differences among the tested extraction methods, and thus all possible needs can be served by selecting the appropriate method.", "labels": [], "entities": []}, {"text": "Regardless of the use of the results, we can see several general trends: \u2022 The baseline method, which used only a limited number of regular derivations of the base verb (cf. Sect.", "labels": [], "entities": []}, {"text": "5) and no additional lexicons or corpora, is actually quite strong and it was surpassed only by the optimized parallel corpus method(s).", "labels": [], "entities": []}, {"text": "\u2022 WordNet does not help much, if at all, both in the basic system where it is only combined with the baseline and in the last two systems when it adds to the results of the optimized systems.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 2, "end_pos": 9, "type": "DATASET", "confidence": 0.9323755502700806}]}, {"text": "The increase in recall -which was the assumed contribution of WordNet -is small and the loss in precision substantial, even as F 1 grows.", "labels": [], "entities": [{"text": "recall", "start_pos": 16, "end_pos": 22, "type": "METRIC", "confidence": 0.9995636343955994}, {"text": "WordNet", "start_pos": 62, "end_pos": 69, "type": "DATASET", "confidence": 0.9518476724624634}, {"text": "precision", "start_pos": 96, "end_pos": 105, "type": "METRIC", "confidence": 0.9990425705909729}, {"text": "F 1", "start_pos": 127, "end_pos": 130, "type": "METRIC", "confidence": 0.9857907593250275}]}, {"text": "\u2022 A manually annotated corpus, not surprisingly, gets much more precise results than a large but only automatically analyzed corpus (PCEDT vs. CzEng).", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Summary of results of all experiments", "labels": [], "entities": [{"text": "Summary", "start_pos": 10, "end_pos": 17, "type": "METRIC", "confidence": 0.6601147055625916}]}]}