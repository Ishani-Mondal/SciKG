{"title": [{"text": "The Physics of Text: Ontological Realism in Information Extraction", "labels": [], "entities": [{"text": "Ontological Realism in Information Extraction", "start_pos": 21, "end_pos": 66, "type": "TASK", "confidence": 0.6529776692390442}]}], "abstractContent": [{"text": "We propose an approach to extracting information from text based on the hypothesis that text sometimes describes the world.", "labels": [], "entities": []}, {"text": "The hypothesis is embodied in a generative probability model that describes (1) possible worlds and the facts they might contain, (2) how an author chooses facts to express, and (3) how those facts are expressed in text.", "labels": [], "entities": []}, {"text": "Given text, information extraction is done by computing a posterior over the worlds that might have generated it.", "labels": [], "entities": [{"text": "information extraction", "start_pos": 12, "end_pos": 34, "type": "TASK", "confidence": 0.8369888961315155}]}, {"text": "As a by-product, this unsupervised learning process discovers new relations and their textual expressions, extracts new facts, disambiguates instances of polysemous expressions , and resolves entity references.", "labels": [], "entities": []}, {"text": "The probability model also explains and improves on Brin's bootstrapping heuristic, which underlies many open information extraction systems.", "labels": [], "entities": [{"text": "information extraction", "start_pos": 110, "end_pos": 132, "type": "TASK", "confidence": 0.7495320439338684}]}, {"text": "Preliminary results on a small corpus of New York Times text suggest that the approach is effective.", "labels": [], "entities": [{"text": "New York Times text", "start_pos": 41, "end_pos": 60, "type": "DATASET", "confidence": 0.7658004462718964}]}], "introductionContent": [{"text": "The purpose of information extraction (IE) is to produce both general knowledge structures and specific facts that will support inference, problem solving, and question answering.", "labels": [], "entities": [{"text": "information extraction (IE)", "start_pos": 15, "end_pos": 42, "type": "TASK", "confidence": 0.8763651251792908}, {"text": "problem solving", "start_pos": 139, "end_pos": 154, "type": "TASK", "confidence": 0.7782596945762634}, {"text": "question answering", "start_pos": 160, "end_pos": 178, "type": "TASK", "confidence": 0.8582853972911835}]}, {"text": "The primary difficulties include (1) the huge variety and ambiguity of linguistic expressions of underlying content; (2) the problem of resolving multiple entity references within and across documents; (3) the complexity of the underlying information itself: its ontology, temporal and causal structure, provenance, etc.", "labels": [], "entities": []}, {"text": "Section 2 describes the major approaches that have been taken and their shortcomings.", "labels": [], "entities": []}, {"text": "Recent developments in probabilistic modeling and inference make it possible to revisit a Bayesian approach to IE championed by, among others.", "labels": [], "entities": [{"text": "IE", "start_pos": 111, "end_pos": 113, "type": "TASK", "confidence": 0.9908527731895447}]}, {"text": "The approach is based on what one might call ontologically realistic generative models: that is, probability models that describe, in a very general sense, both the ways that the real world might be and the ways that world might be described in text.", "labels": [], "entities": []}, {"text": "Such models explain why this text is on the page in the same way that physical theories explain laboratory measurements-that is, by reference to an underlying reality.", "labels": [], "entities": []}, {"text": "Perhaps surprisingly, commonly used generative models of language make no such reference.", "labels": [], "entities": []}, {"text": "A simple, initial model (Section 3) posits a world of facts (binary relations between entities) that are expressed using arbitrary dependency paths connecting named-entity mentions.", "labels": [], "entities": []}, {"text": "Using the machinery of a probabilistic programming language such as BLOG (augmented with anew form of proposal distribution for split-merge MCMC ( ) and a small, preprocessed corpus of New York Times sentences, preliminary results (Section 4) indicate that the approach is surprisingly effective in discovering relations, lexicons, and facts in an unsupervised fashion.", "labels": [], "entities": [{"text": "BLOG", "start_pos": 68, "end_pos": 72, "type": "METRIC", "confidence": 0.508618950843811}]}, {"text": "A key advantage of this vertically integrated generative approach, compared to more classical bottomup pipelines with deterministic stages, is that no hard decisions are made and all available context is ap-plied to reduce uncertainty at every level, resulting in much higher accuracy (.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 276, "end_pos": 284, "type": "METRIC", "confidence": 0.9974991679191589}]}, {"text": "Parsing, entity resolution, event recognition, and extraction emerge from a single, vertically integrated inference process-no special algorithms are needed.", "labels": [], "entities": [{"text": "Parsing", "start_pos": 0, "end_pos": 7, "type": "TASK", "confidence": 0.9624094367027283}, {"text": "entity resolution", "start_pos": 9, "end_pos": 26, "type": "TASK", "confidence": 0.792870044708252}, {"text": "event recognition", "start_pos": 28, "end_pos": 45, "type": "TASK", "confidence": 0.836139440536499}]}], "datasetContent": [{"text": "The model was applied to a small subset (8500 sentences) of an NYT corpus).", "labels": [], "entities": [{"text": "NYT corpus", "start_pos": 63, "end_pos": 73, "type": "DATASET", "confidence": 0.9271985590457916}]}, {"text": "The subset was chosen heuristically to have a relatively small number of distinct entity mentions, so as to increase the number of bootstrapping opportunities.", "labels": [], "entities": []}, {"text": "The sentences contain two named entities connected by a grammatical dependency path, matching our trivial grammatical model.", "labels": [], "entities": []}, {"text": "The inference process discovers (1) roughly 200 relations that underlie the text; (2) the dictionaries describing how each relation is expressed by dependency paths; and (3) the facts belonging to each relation.", "labels": [], "entities": []}, {"text": "We also found 60 facts such as rel 46 (BBDO W orldwide, Omnicom Group) and rel 46 (F ox, N ews Corporation).", "labels": [], "entities": [{"text": "rel 46", "start_pos": 31, "end_pos": 37, "type": "METRIC", "confidence": 0.9214795231819153}, {"text": "BBDO W orldwide, Omnicom Group)", "start_pos": 39, "end_pos": 70, "type": "DATASET", "confidence": 0.8486710446221488}, {"text": "F ox, N ews Corporation)", "start_pos": 83, "end_pos": 107, "type": "DATASET", "confidence": 0.6232288607529232}]}, {"text": "Manual verification of all facts for the most common 20 relations shows roughly 95% precision, with most errors arising from the limitations of the preprocessor and named entity extractor.", "labels": [], "entities": [{"text": "precision", "start_pos": 84, "end_pos": 93, "type": "METRIC", "confidence": 0.9995531439781189}]}, {"text": "Because of the strength and frequency of bootstrapping inferences, it seems likely (although this remains to be verified) that the relation discovery process is more accurate than in other approaches and requires less data.", "labels": [], "entities": [{"text": "relation discovery process", "start_pos": 131, "end_pos": 157, "type": "TASK", "confidence": 0.891991396745046}]}, {"text": "Extensions to the generative model to include entity attributes and a more complete semantic grammar (see Section 5) will automatically resolve entity references and avoid the need for pre-parsing or named-entity recognition.", "labels": [], "entities": [{"text": "named-entity recognition", "start_pos": 200, "end_pos": 224, "type": "TASK", "confidence": 0.7608786523342133}]}, {"text": "The traditional method of evaluation for IE systems relies on the ability to inspect the extracted knowledge base for correctness.", "labels": [], "entities": [{"text": "IE", "start_pos": 41, "end_pos": 43, "type": "TASK", "confidence": 0.9799813628196716}]}, {"text": "As probability models become more sophisticated, this approach will fail, because (1) the knowledge is represented using internal symbols referring to relations and entities the system discovers for itself, that may not correspond to standard concepts in English, and (2) the meaning of a given internal symbol varies across possible worlds in the inference process.", "labels": [], "entities": []}, {"text": "Instead, as with humans, the query interface must, inevitably, be via language itself.", "labels": [], "entities": []}, {"text": "For example, one can ask whether the subjects of sentences 14 (\"Obama roasts WH press\") and 22 (\"President seeks second term\") are the same entity, or ask for x such that \"x is President of South Sudan\" is true.", "labels": [], "entities": []}], "tableCaptions": []}