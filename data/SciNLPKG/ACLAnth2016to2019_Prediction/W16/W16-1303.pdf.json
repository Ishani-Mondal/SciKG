{"title": [{"text": "IKE -An Interactive Tool for Knowledge Extraction", "labels": [], "entities": [{"text": "Knowledge Extraction", "start_pos": 29, "end_pos": 49, "type": "TASK", "confidence": 0.6914727240800858}]}], "abstractContent": [{"text": "Recent work on information extraction has suggested that fast, interactive tools can be highly effective; however, creating a usable system is challenging, and few publi-cally available tools exist.", "labels": [], "entities": [{"text": "information extraction", "start_pos": 15, "end_pos": 37, "type": "TASK", "confidence": 0.8728999197483063}]}, {"text": "In this paper we present IKE, anew extraction tool that performs fast, interactive bootstrapping to develop high-quality extraction patterns for targeted relations.", "labels": [], "entities": []}, {"text": "Central to IKE is the notion that an extraction pattern can be treated as a search query over a corpus.", "labels": [], "entities": [{"text": "IKE", "start_pos": 11, "end_pos": 14, "type": "TASK", "confidence": 0.9396035671234131}]}, {"text": "To oper-ationalize this, IKE uses a novel query language that is expressive, easy to understand, and fast to execute-essential requirements fora practical system.", "labels": [], "entities": []}, {"text": "It is also the first interactive extraction tool to seamlessly integrate symbolic (boolean) and distributional (similarity-based) methods for search.", "labels": [], "entities": []}, {"text": "An initial evaluation suggests that relation tables can be populated substantially faster than by manual pattern authoring while retaining accuracy, and more reliably than fully automated tools, an important step towards practical KB construction.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 139, "end_pos": 147, "type": "METRIC", "confidence": 0.9990262985229492}, {"text": "KB construction", "start_pos": 231, "end_pos": 246, "type": "TASK", "confidence": 0.9739170670509338}]}, {"text": "We are making IKE publically available (http://allenai.org/ software/interactive-knowledge-extraction).", "labels": [], "entities": []}], "introductionContent": [{"text": "Knowledge extraction from text remains a fundamental challenge for any system that works with structured data.", "labels": [], "entities": [{"text": "Knowledge extraction from text", "start_pos": 0, "end_pos": 30, "type": "TASK", "confidence": 0.8366628289222717}]}, {"text": "Automatic extraction algorithms, e.g.,), have proved efficient and scalable, especially when leveraging existing search engine technologies, e.g.,), but typically produce noisy results, e.g., the best F1 score for the KBP slot filling task was 0.28, as reported in (.", "labels": [], "entities": [{"text": "Automatic extraction", "start_pos": 0, "end_pos": 20, "type": "TASK", "confidence": 0.7263002097606659}, {"text": "F1 score", "start_pos": 201, "end_pos": 209, "type": "METRIC", "confidence": 0.9809798300266266}, {"text": "KBP slot filling task", "start_pos": 218, "end_pos": 239, "type": "TASK", "confidence": 0.7478070929646492}]}, {"text": "Weakly supervised automatic bootstrapping methods () are more precise in the initial bootstrapping iterations, but digress in later iterations, a problem generally referred to as semantic drift.", "labels": [], "entities": []}, {"text": "More recently there has been work on more interactive methods, which can be seen as a \"machine teaching\" approach to KB construction ().", "labels": [], "entities": [{"text": "KB construction", "start_pos": 117, "end_pos": 132, "type": "TASK", "confidence": 0.9393907189369202}]}, {"text": "For example, showed that users can be surprisingly effective at authoring and refining extraction rules fora slot filling task, and) demonstrated that a combination of machine learning and user authoring produced high quality results.", "labels": [], "entities": [{"text": "authoring and refining extraction rules fora slot filling task", "start_pos": 64, "end_pos": 126, "type": "TASK", "confidence": 0.7302791873613993}]}, {"text": "However, none of these approaches have evolved into publically available tools.", "labels": [], "entities": []}, {"text": "In this paper we present IKE, a usable, generalpurpose tool for interactive extraction.", "labels": [], "entities": [{"text": "interactive extraction", "start_pos": 64, "end_pos": 86, "type": "TASK", "confidence": 0.6889855563640594}]}, {"text": "Central to IKE is the notion that an extraction pattern can be treated as a search query over a corpus, building on earlier work by).", "labels": [], "entities": [{"text": "IKE", "start_pos": 11, "end_pos": 14, "type": "TASK", "confidence": 0.907213032245636}]}, {"text": "It addresses the resulting requirements of expressiveness, comprehensibility, and speed with a novel query language based on chunking rather than parsing, and is the first tool to seamlessly integrate symbolic (boolean) and distributional (similarity-based) methods for search.", "labels": [], "entities": [{"text": "speed", "start_pos": 82, "end_pos": 87, "type": "METRIC", "confidence": 0.9776939153671265}]}, {"text": "It also includes a machine learning component for suggesting new queries to the user.", "labels": [], "entities": []}, {"text": "A preliminary evaluation suggests that relation tables can be populated substantially faster with IKE than by manual pattern authoring (and more reliably than fully automated tools), while retaining accu-racy, suggesting IKE has utility for KB construction.", "labels": [], "entities": [{"text": "KB construction", "start_pos": 241, "end_pos": 256, "type": "TASK", "confidence": 0.9063216149806976}]}], "datasetContent": [{"text": "Although IKE is still underdevelopment, we have conducted a preliminary evaluation, comparing it with two other methods for populating relation tables.", "labels": [], "entities": [{"text": "IKE", "start_pos": 9, "end_pos": 12, "type": "TASK", "confidence": 0.6024451851844788}]}, {"text": "Our interest is in how these different methods compare in terms of precision, yield and time: \u2022 Manual: The user manually authors and refines patterns (without any automatic assistance) to populate a table.", "labels": [], "entities": [{"text": "precision", "start_pos": 67, "end_pos": 76, "type": "METRIC", "confidence": 0.9992408752441406}, {"text": "yield", "start_pos": 78, "end_pos": 83, "type": "METRIC", "confidence": 0.9725810885429382}]}, {"text": "\u2022 Automatic: The user provides an initial table with a few entries, and then lets the system bootstrap on its own, without any further interaction.", "labels": [], "entities": []}, {"text": "\u2022 Interactive (IKE): Interactive bootstrapping, as described earlier.", "labels": [], "entities": []}, {"text": "The manual system was implemented in IKE by disabling the embedding-based set expansion and MLbased query suggestion features.", "labels": [], "entities": [{"text": "IKE", "start_pos": 37, "end_pos": 40, "type": "DATASET", "confidence": 0.7554486393928528}]}, {"text": "The automatic approach was simulated in IKE by removing both user annotation steps in, and instead adding all machine-learned patterns suggested by the Query Suggestor (Section 2.2) and instances that occur at least k times in the corpus (using k = 2).", "labels": [], "entities": []}, {"text": "This is a simple baseline method of bootstrapping, compared with more sophisticated methods such as co-training).", "labels": [], "entities": []}, {"text": "For a fair comparison, we compared results after 3 bootstrapping iterations (for Automatic, IKE) and a similar amount of user time (\u223c30 mins, for Manual and IKE).", "labels": [], "entities": []}, {"text": "The number of iterations were limited to 3 to keep the annotation time within reasonable limits.", "labels": [], "entities": []}, {"text": "We compared these methods to define and populate two target relations: conducts(material,energy), and has-part(animal,bodypart).", "labels": [], "entities": []}, {"text": "All methods extract knowledge from the same corpora of science text, consisting of \u223c1.5M sentences (largely) about elementary science drawn from science textbooks, Simple Wikipedia, and the Web.", "labels": [], "entities": [{"text": "Simple Wikipedia", "start_pos": 164, "end_pos": 180, "type": "DATASET", "confidence": 0.8795982301235199}]}, {"text": "For each relation, two (different) users familiar with IKE were asked to construct these tables.", "labels": [], "entities": []}, {"text": "The numbers presented in are averaged over these two users.", "labels": [], "entities": []}, {"text": "Although this study is small, it provides helpful indicators about IKE's utility.", "labels": [], "entities": [{"text": "IKE", "start_pos": 67, "end_pos": 70, "type": "TASK", "confidence": 0.9549642205238342}]}], "tableCaptions": [{"text": " Table 3: conducts(material,energy) table after 3 iterations or", "labels": [], "entities": []}, {"text": " Table 4: has-part(organism,bodypart) table after 3 iterations", "labels": [], "entities": []}]}