{"title": [{"text": "CaTeRS: Causal and Temporal Relation Scheme for Semantic Annotation of Event Structures", "labels": [], "entities": [{"text": "Causal and Temporal Relation", "start_pos": 8, "end_pos": 36, "type": "TASK", "confidence": 0.6373201310634613}, {"text": "Semantic Annotation of Event Structures", "start_pos": 48, "end_pos": 87, "type": "TASK", "confidence": 0.7514859855175018}]}], "abstractContent": [{"text": "Learning commonsense causal and temporal relation between events is one of the major steps towards deeper language understanding.", "labels": [], "entities": []}, {"text": "This is even more crucial for understanding stories and script learning.", "labels": [], "entities": [{"text": "understanding stories", "start_pos": 30, "end_pos": 51, "type": "TASK", "confidence": 0.9045858681201935}, {"text": "script learning", "start_pos": 56, "end_pos": 71, "type": "TASK", "confidence": 0.9245027005672455}]}, {"text": "A prerequisite for learning scripts is a semantic framework which enables capturing rich event structures.", "labels": [], "entities": []}, {"text": "In this paper we introduce a novel semantic annotation framework, called Causal and Temporal Relation Scheme (CaTeRS), which is unique in simultaneously capturing a comprehensive set of temporal and causal relations between events.", "labels": [], "entities": []}, {"text": "By annotating a total of 1,600 sentences in the context of 320 five-sentence short stories sampled from ROCStories corpus , we demonstrate that these stories are indeed full of causal and temporal relations.", "labels": [], "entities": [{"text": "ROCStories corpus", "start_pos": 104, "end_pos": 121, "type": "DATASET", "confidence": 0.9371517896652222}]}, {"text": "Furthermore, we show that the CaTeRS annotation scheme enables high inter-annotator agreement for broad-coverage event entity annotation and moderate agreement on semantic link annotation.", "labels": [], "entities": [{"text": "broad-coverage event entity annotation", "start_pos": 98, "end_pos": 136, "type": "TASK", "confidence": 0.6612738817930222}]}], "introductionContent": [{"text": "Understanding events and their relations in natural language has become increasingly important for various NLP tasks.", "labels": [], "entities": [{"text": "Understanding events and their relations in natural language", "start_pos": 0, "end_pos": 60, "type": "TASK", "confidence": 0.7519083172082901}]}, {"text": "Most notably, story understanding) which is an extremely challenging task in natural language understanding, is highly dependent on understanding events and their relations.", "labels": [], "entities": [{"text": "story understanding", "start_pos": 14, "end_pos": 33, "type": "TASK", "confidence": 0.876754641532898}, {"text": "natural language understanding", "start_pos": 77, "end_pos": 107, "type": "TASK", "confidence": 0.6563294033209482}]}, {"text": "Recently, we have witnessed a renewed interest in story and narrative understanding based on the progress made in core NLP tasks.", "labels": [], "entities": [{"text": "story and narrative understanding", "start_pos": 50, "end_pos": 83, "type": "TASK", "confidence": 0.6839511469006538}]}, {"text": "Perhaps the biggest challenge of story understanding (and story generation) is having commonsense knowledge for the interpretation of narrative events.", "labels": [], "entities": [{"text": "story understanding", "start_pos": 33, "end_pos": 52, "type": "TASK", "confidence": 0.8257360458374023}, {"text": "story generation", "start_pos": 58, "end_pos": 74, "type": "TASK", "confidence": 0.7341886013746262}]}, {"text": "This commonsense knowledge can be best represented as scripts.", "labels": [], "entities": []}, {"text": "Scripts present structured knowledge about stereotypical event sequences together with their participants.", "labels": [], "entities": []}, {"text": "A well known script is the Restaurant Script, which includes the events {Entering, Sitting down, Asking for menus, Choosing meals, etc.}, and the participants {Customer, Waiter, Chef, Tables, etc.}.", "labels": [], "entities": []}, {"text": "A large body of work in story understanding has focused on learning scripts (.", "labels": [], "entities": [{"text": "story understanding", "start_pos": 24, "end_pos": 43, "type": "TASK", "confidence": 0.8976229429244995}]}, {"text": "Given that developing hand-built scripts is extremely time-consuming, there is a serious need for automatically induced scripts.", "labels": [], "entities": []}, {"text": "It is evident that various NLU applications (text summarization, co-reference resolution and question answering, among others) can benefit from the rich inferential capabilities that structured knowledge about events can provide.", "labels": [], "entities": [{"text": "text summarization", "start_pos": 45, "end_pos": 63, "type": "TASK", "confidence": 0.7184880375862122}, {"text": "co-reference resolution", "start_pos": 65, "end_pos": 88, "type": "TASK", "confidence": 0.7132322490215302}, {"text": "question answering", "start_pos": 93, "end_pos": 111, "type": "TASK", "confidence": 0.8485537171363831}]}, {"text": "The first step for any script learner is to decide on a corpus to drive the learning process.", "labels": [], "entities": []}, {"text": "The most recent resource for this purpose is a corpus of short commonsense stories, called ROCStories (, which is a corpus of 40,000 short commonsense everyday stories . This corpus contains high quality 2 five-sentence stories that are full of stereotypical causal and temporal relations between events, making them a perfect resource for learning narrative schemas.", "labels": [], "entities": [{"text": "ROCStories", "start_pos": 91, "end_pos": 101, "type": "METRIC", "confidence": 0.5398344993591309}]}, {"text": "One of the prerequisites for learning scripts from these stories is to extract events and find inter-event semantic relations.", "labels": [], "entities": []}, {"text": "Earlier work) defines verbs as events and uses TimeML-based) learning for temporal ordering of events.", "labels": [], "entities": []}, {"text": "This clearly has many shortcomings, including, but not limited to (1) not capturing a wide range of non-verbal events such as 'earthquake', (2) not capturing a more comprehensive set of semantic relations between events such as causality, which is a core relation in stories.", "labels": [], "entities": []}, {"text": "In this paper we formally define anew comprehensive semantic framework for capturing stereotypical event-event temporal and causal relations in commonsense stories, the details of which can be found in Sections 2-4.", "labels": [], "entities": []}, {"text": "Using this semantic framework we annotated 320 stories sampled from ROCStories to extract inter-event semantic structures.", "labels": [], "entities": []}, {"text": "Our inter-annotator agreement analysis, presented in Section 5 shows that this framework enables high event entity annotation agreement and promising inter-event relation annotation agreement.", "labels": [], "entities": []}, {"text": "We believe that our semantic framework better suits the goals of the task of script learning and story understanding, which can potentially enable learning richer and more accurate scripts.", "labels": [], "entities": [{"text": "script learning", "start_pos": 77, "end_pos": 92, "type": "TASK", "confidence": 0.7970905900001526}, {"text": "story understanding", "start_pos": 97, "end_pos": 116, "type": "TASK", "confidence": 0.7513553202152252}]}, {"text": "Although this work focuses on stories, the CaTeRS annotation framework for capturing inter-event relations can be applied to other genres.", "labels": [], "entities": []}], "datasetContent": [{"text": "We randomly sampled 320 stories (1,600 sentences) from the ROCStories Corpus.", "labels": [], "entities": [{"text": "ROCStories Corpus", "start_pos": 59, "end_pos": 76, "type": "DATASET", "confidence": 0.958217054605484}]}, {"text": "This set covers a variety of everyday stories, with titles ranging from 'got anew phone' to 'Left at the altar'.", "labels": [], "entities": []}, {"text": "We provided our main expert annotator with the annotation guidelines, with the task of annotating each of the 320 stories at story level.", "labels": [], "entities": []}, {"text": "The annotation task was setup on Brat tool 8 . On average, annotation time per story was 11 minutes.", "labels": [], "entities": [{"text": "Brat tool 8", "start_pos": 33, "end_pos": 44, "type": "DATASET", "confidence": 0.9195394118626913}]}, {"text": "These annotations can be found through http://cs.rochester.", "labels": [], "entities": []}, {"text": "edu/nlp/rocstories/CaTeRS/.", "labels": [], "entities": []}], "tableCaptions": []}