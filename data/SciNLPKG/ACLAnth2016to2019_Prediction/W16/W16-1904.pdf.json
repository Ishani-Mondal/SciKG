{"title": [{"text": "Leveraging Annotators' Gaze Behaviour for Coreference Resolution", "labels": [], "entities": [{"text": "Coreference Resolution", "start_pos": 42, "end_pos": 64, "type": "TASK", "confidence": 0.965658038854599}]}], "abstractContent": [{"text": "This paper aims at utilizing cognitive information obtained from the eye movements behavior of annotators for automatic coreference resolution.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 120, "end_pos": 142, "type": "TASK", "confidence": 0.9487494826316833}]}, {"text": "We first record eye-movement behavior of multiple annotators resolving coreferences in 22 documents selected from MUC dataset.", "labels": [], "entities": [{"text": "MUC dataset", "start_pos": 114, "end_pos": 125, "type": "DATASET", "confidence": 0.9724491834640503}]}, {"text": "By inspecting the gaze-regression profiles of our participants, we observe how regressive saccades account for selection of potential antecedents fora certain anaphoric mention.", "labels": [], "entities": []}, {"text": "Based on this observation, we then propose a heuris-tic to utilize gaze data to prune mention pairs in mention-pair model, a popular paradigm for automatic coreference resolution.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 156, "end_pos": 178, "type": "TASK", "confidence": 0.8660008609294891}]}, {"text": "Consistent improvement inaccuracy across several classifiers is observed with our heuristic, demonstrating why cognitive data can be useful fora difficult task like coreference resolution.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 165, "end_pos": 187, "type": "TASK", "confidence": 0.9585978388786316}]}], "introductionContent": [{"text": "Coreference resolution deals with identifying the expressions in a discourse referring to the same entity.", "labels": [], "entities": [{"text": "Coreference resolution", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.9065550863742828}]}, {"text": "It is crucial to many information retrieval tasks (.", "labels": [], "entities": [{"text": "information retrieval", "start_pos": 22, "end_pos": 43, "type": "TASK", "confidence": 0.7779744863510132}]}, {"text": "One of its main objectives of is to resolve the noun phrases to the entities they refer to.", "labels": [], "entities": []}, {"text": "Though there exist many rule based ( and machine learning based () approaches to coreference resolution, they are way behind imitating the human process of coreference resolution.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 81, "end_pos": 103, "type": "TASK", "confidence": 0.9514883756637573}, {"text": "coreference resolution", "start_pos": 156, "end_pos": 178, "type": "TASK", "confidence": 0.9125894606113434}]}, {"text": "Comparing the performance of different existing systems on a standard dataset, Ontonotes, released for CoNLL-2012 shared task (, it is quite evident that the recent systems do not have much improvement inaccuracy over the earlier systems.", "labels": [], "entities": [{"text": "Ontonotes", "start_pos": 79, "end_pos": 88, "type": "DATASET", "confidence": 0.8726854920387268}]}, {"text": "This paper attempts to gain insight into the cognitive aspects of coreference resolution to improve mention-pair model, a well-known supervised coreference resolution paradigm.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 66, "end_pos": 88, "type": "TASK", "confidence": 0.9569161832332611}, {"text": "coreference resolution", "start_pos": 144, "end_pos": 166, "type": "TASK", "confidence": 0.7600821256637573}]}, {"text": "For this we employ eye-tracking technology that has been quite effective in the field of psycholinguistics to study language comprehension, lexical and syntactic processing(von der.", "labels": [], "entities": [{"text": "syntactic processing", "start_pos": 152, "end_pos": 172, "type": "TASK", "confidence": 0.7115855067968369}]}, {"text": "Recently, eye-tracking studies have been conducted for various language processing tasks like Sentiment Analysis, Translation and Word Sense Disambiguation.", "labels": [], "entities": [{"text": "Sentiment Analysis", "start_pos": 94, "end_pos": 112, "type": "TASK", "confidence": 0.8595582246780396}, {"text": "Translation", "start_pos": 114, "end_pos": 125, "type": "TASK", "confidence": 0.9700316786766052}, {"text": "Word Sense Disambiguation", "start_pos": 130, "end_pos": 155, "type": "TASK", "confidence": 0.7220927675565084}]}, {"text": "develop a method to measure the sentiment annotation complexity using cognitive evidence from eye-tracking.", "labels": [], "entities": [{"text": "sentiment annotation", "start_pos": 32, "end_pos": 52, "type": "TASK", "confidence": 0.9221033751964569}]}, {"text": "measure complexity in text to be translated based on gaze input of translators which is used to label training data.", "labels": [], "entities": []}, {"text": "propose a studied the cognitive aspects if Word Sense Disambiguation (WSD) through eye-tracking.", "labels": [], "entities": [{"text": "Word Sense Disambiguation (WSD)", "start_pos": 43, "end_pos": 74, "type": "TASK", "confidence": 0.7614980787038803}]}, {"text": "Eye-tracking studies have also been conducted for the task of coreference resolution.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 62, "end_pos": 84, "type": "TASK", "confidence": 0.9822963178157806}]}, {"text": "check for whether the syntax or discourse representation has better role in pronoun interpretation.", "labels": [], "entities": [{"text": "pronoun interpretation", "start_pos": 76, "end_pos": 98, "type": "TASK", "confidence": 0.7319916635751724}]}, {"text": "examine the effect of gender information and accessibility to pronoun interpretation.", "labels": [], "entities": [{"text": "pronoun interpretation", "start_pos": 62, "end_pos": 84, "type": "TASK", "confidence": 0.7608617842197418}]}, {"text": "studies the fixation patterns on pronoun and associated verb phrases to explain comprehension of pronouns.", "labels": [], "entities": []}, {"text": "We perform yet another eye-tracking study to understand certain facets of human process involved in coreference resolution that eventually can help automatic coreference resolution.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 100, "end_pos": 122, "type": "TASK", "confidence": 0.9583845734596252}, {"text": "coreference resolution", "start_pos": 158, "end_pos": 180, "type": "TASK", "confidence": 0.8843761384487152}]}, {"text": "Our participants are given a set of documents to perform coreference annotation and the eye movements during the exercise are recorded.", "labels": [], "entities": [{"text": "coreference annotation", "start_pos": 57, "end_pos": 79, "type": "TASK", "confidence": 0.9116305112838745}]}, {"text": "Eyemovement patterns are characterized by two basic attributes: (1) Fixations, corresponding to a longer stay of gaze on a visual object (like charac-ters, words etc.", "labels": [], "entities": [{"text": "Fixations", "start_pos": 68, "end_pos": 77, "type": "METRIC", "confidence": 0.996222734451294}]}, {"text": "in text) (2) Saccades, corresponding to the transition of eyes between two fixations.", "labels": [], "entities": []}, {"text": "Moreover, a saccade is called a Regressive Saccade or simply, Regression if it represents a phenomenon of going back to a pre-visited segment.", "labels": [], "entities": [{"text": "Regression", "start_pos": 62, "end_pos": 72, "type": "METRIC", "confidence": 0.910636842250824}]}, {"text": "While analyzing these attributes in our dataset, we observe a correlation between the Total Regression Count and the complexity of a mention being resolved.", "labels": [], "entities": [{"text": "Total Regression Count", "start_pos": 86, "end_pos": 108, "type": "METRIC", "confidence": 0.9255438844362894}, {"text": "complexity", "start_pos": 117, "end_pos": 127, "type": "METRIC", "confidence": 0.9674753546714783}]}, {"text": "Additionally, Mention Regression Count, i.e., the count of a previous mention getting visited while resolving for an anaphoric mention, proves to be a measure of relevance of that particular mention as antecedent to the anaphoric mention.", "labels": [], "entities": [{"text": "Mention Regression Count", "start_pos": 14, "end_pos": 38, "type": "METRIC", "confidence": 0.9239854216575623}]}, {"text": "Following the insights, we try to enrich mention-pair model, a popular paradigm in automatic coreference resolution by performing mention pair pruning prior to classification using mention regression data.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 93, "end_pos": 115, "type": "TASK", "confidence": 0.8095610439777374}]}], "datasetContent": [{"text": "Eye movement data driven mention pair pruning, as discussed above, is experimented across different classifiers, viz., Support Vector Machine (SVM), Naive Bayes, and Multi-layered FeedForward Neural Network (Neural Net).", "labels": [], "entities": []}, {"text": "We use libsvm for SVM implementation and ScikitLearn   Since the main aspect of our work is mention pair pruning, we first check the mention pair pruning accuracy.", "labels": [], "entities": [{"text": "SVM implementation", "start_pos": 18, "end_pos": 36, "type": "TASK", "confidence": 0.8376147449016571}, {"text": "accuracy", "start_pos": 154, "end_pos": 162, "type": "METRIC", "confidence": 0.9744547009468079}]}, {"text": "We find that mention pair pruning has a precision of 87.24%.", "labels": [], "entities": [{"text": "precision", "start_pos": 40, "end_pos": 49, "type": "METRIC", "confidence": 0.9991818070411682}]}, {"text": "Pruning errors maybe attributed to increased number of regressions happening to mentions towards the end of the documents (refer section 3).", "labels": [], "entities": [{"text": "Pruning", "start_pos": 0, "end_pos": 7, "type": "METRIC", "confidence": 0.9441969990730286}]}, {"text": "Performance of the system is evaluated using MUC, B and CEAFe metrics.", "labels": [], "entities": [{"text": "MUC", "start_pos": 45, "end_pos": 48, "type": "DATASET", "confidence": 0.5829281806945801}, {"text": "B", "start_pos": 50, "end_pos": 51, "type": "METRIC", "confidence": 0.9921109676361084}, {"text": "CEAFe", "start_pos": 56, "end_pos": 61, "type": "METRIC", "confidence": 0.46556609869003296}]}, {"text": "CoNLL score is computed as the average of F1s of all the mentioned metrics.", "labels": [], "entities": [{"text": "CoNLL score", "start_pos": 0, "end_pos": 11, "type": "METRIC", "confidence": 0.7194355130195618}, {"text": "F1s", "start_pos": 42, "end_pos": 45, "type": "METRIC", "confidence": 0.9992246627807617}]}, {"text": "shows the results across different classifiers with and without mention pair pruning.", "labels": [], "entities": []}, {"text": "Considering the CoNLL score, there is an improvement in performance across all classifiers.", "labels": [], "entities": [{"text": "CoNLL score", "start_pos": 16, "end_pos": 27, "type": "METRIC", "confidence": 0.6991944313049316}]}, {"text": "This improvement is contributed by the increase in precision , despite the fall in recall.", "labels": [], "entities": [{"text": "precision", "start_pos": 51, "end_pos": 60, "type": "METRIC", "confidence": 0.9997075200080872}, {"text": "recall", "start_pos": 83, "end_pos": 89, "type": "METRIC", "confidence": 0.9993717074394226}]}, {"text": "shows a few instances of non-coreferent antecedent-anaphora pairs which are correctly predicted as non-coreferent because of pruning.", "labels": [], "entities": []}, {"text": "Among all the classifiers neural network gives better accuracy, but the effective performance gain is higher with classifiers with lesser accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 54, "end_pos": 62, "type": "METRIC", "confidence": 0.998946487903595}, {"text": "accuracy", "start_pos": 138, "end_pos": 146, "type": "METRIC", "confidence": 0.9878630638122559}]}, {"text": "Naive Bayes giving the least accuracy, gives http://keras.io/ the best accuracy improvement of 2.04% with mention-pair pruning.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 29, "end_pos": 37, "type": "METRIC", "confidence": 0.999626636505127}, {"text": "accuracy", "start_pos": 71, "end_pos": 79, "type": "METRIC", "confidence": 0.9995397329330444}]}, {"text": "This gives the impression that systems with lower performance, are likely to benefit from the eye movement based heuristics.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Results with different classifiers and Berkeley coreference system with and without pruning of  candidate mention pairs (P,R,F)\u2192 (Precision, R:Recall, F:F-measure), CoNLL:CoNLL Score", "labels": [], "entities": [{"text": "CoNLL:CoNLL Score", "start_pos": 175, "end_pos": 192, "type": "METRIC", "confidence": 0.4434809163212776}]}]}