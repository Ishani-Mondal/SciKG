{"title": [{"text": "Language and Dialect Discrimination Using Compression-Inspired Language Models", "labels": [], "entities": [{"text": "Language and Dialect Discrimination", "start_pos": 0, "end_pos": 35, "type": "TASK", "confidence": 0.5872160792350769}]}], "abstractContent": [{"text": "The DSL 2016 shared task continued previous evaluations from 2014 and 2015 that facilitated the study of automated language and dialect identification.", "labels": [], "entities": [{"text": "automated language and dialect identification", "start_pos": 105, "end_pos": 150, "type": "TASK", "confidence": 0.5855997204780579}]}, {"text": "This paper describes results for this year's shared task and from several related experiments conducted at the Johns Hopkins University Human Language Technology Center of Excellence (JHU HLTCOE).", "labels": [], "entities": [{"text": "Johns Hopkins University Human Language Technology Center of Excellence (JHU HLTCOE)", "start_pos": 111, "end_pos": 195, "type": "DATASET", "confidence": 0.7576514620047349}]}, {"text": "Previously the HLTCOE has explored the use of compression-inspired language modeling for language and dialect identification , using news, Wikipedia, blog, and Twitter corpora.", "labels": [], "entities": [{"text": "language and dialect identification", "start_pos": 89, "end_pos": 124, "type": "TASK", "confidence": 0.6487691476941109}]}, {"text": "The technique we have relied upon is based on prediction by partial matching (PPM), a state of the art text compression technique.", "labels": [], "entities": [{"text": "prediction by partial matching (PPM)", "start_pos": 46, "end_pos": 82, "type": "TASK", "confidence": 0.7560807296207973}, {"text": "text compression", "start_pos": 103, "end_pos": 119, "type": "TASK", "confidence": 0.706172451376915}]}, {"text": "Due to the close relationship between adaptive compression and language modeling, such compression techniques can also be applied to multi-way text classification problems, and previous studies have examined tasks such as authorship attribution, email spam detection, and topical classification.", "labels": [], "entities": [{"text": "language modeling", "start_pos": 63, "end_pos": 80, "type": "TASK", "confidence": 0.7184963524341583}, {"text": "text classification", "start_pos": 143, "end_pos": 162, "type": "TASK", "confidence": 0.7034275829792023}, {"text": "authorship attribution", "start_pos": 222, "end_pos": 244, "type": "TASK", "confidence": 0.7531184256076813}, {"text": "email spam detection", "start_pos": 246, "end_pos": 266, "type": "TASK", "confidence": 0.6722666223843893}, {"text": "topical classification", "start_pos": 272, "end_pos": 294, "type": "TASK", "confidence": 0.8434662520885468}]}, {"text": "We applied our approach to the multi-class decision that considered each dialect or language as a possibility for the given shared task input line.", "labels": [], "entities": []}, {"text": "Results for testset A were in accord with our expectations, however results for testsets B and C were notably worse.", "labels": [], "entities": []}], "introductionContent": [{"text": "Automated language identification (LID) can be defined as the task of predicting the dominant language being used by the author of a text.", "labels": [], "entities": [{"text": "Automated language identification (LID)", "start_pos": 0, "end_pos": 39, "type": "TASK", "confidence": 0.7522356460491816}, {"text": "predicting the dominant language being used by the author of a text", "start_pos": 70, "end_pos": 137, "type": "TASK", "confidence": 0.6852416346470515}]}, {"text": "Often the decision task is formulated as selecting one language from a fixed inventory of languages, although it is not uncommon to extend the problem to indicating \"none of the above\" when it is believed that the text is not written in one of the listed languages.", "labels": [], "entities": []}, {"text": "For comparatively large input texts (i.e., texts longer than a sentence or two), choosing between only a few languages, or when it is diverse languages that are being considered, high levels of accuracy can be achieved (i.e., over 99%).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 194, "end_pos": 202, "type": "METRIC", "confidence": 0.9987258315086365}]}, {"text": "The Discriminating between Similar Languages (DSL) shared task was started in 2014 and it is now in its third year.", "labels": [], "entities": [{"text": "Discriminating between Similar Languages (DSL) shared task", "start_pos": 4, "end_pos": 62, "type": "TASK", "confidence": 0.7334524525536431}]}, {"text": "The DSL'16 task () is focused on distinguishing between highly related languages, which is a more challenging problem than the general case.", "labels": [], "entities": []}, {"text": "Examples include distinguishing between mutually-intelligible variants of a regional language (e.g., Bosnian, Croatian, and Serbian variants of Serbo-Croatian) or among dialects of imperial languages (e.g., between African, European, and South American Portuguese).", "labels": [], "entities": []}, {"text": "A variety of approaches have been used for language identification since the increased availability of multilingual corpora in the early 1990s.", "labels": [], "entities": [{"text": "language identification", "start_pos": 43, "end_pos": 66, "type": "TASK", "confidence": 0.7210957705974579}]}, {"text": "These include vector comparisons (e.g., cosine similarity), language modeling, and supervised machine learning (.", "labels": [], "entities": [{"text": "language modeling", "start_pos": 60, "end_pos": 77, "type": "TASK", "confidence": 0.7701016068458557}]}, {"text": "In recent years, there has been increased interest in LID due to the the growth of international (i.e., multilingual) social media platforms.", "labels": [], "entities": []}, {"text": "Such user-generated texts tend to be short, less grammatical, and contain highly variable spellings and the frequent use of abbreviations, shorthands, emoticons, and other confounding phenomena which can complicate language identification.", "labels": [], "entities": [{"text": "language identification", "start_pos": 215, "end_pos": 238, "type": "TASK", "confidence": 0.7175125181674957}]}, {"text": "In this paper we discuss the use of compression-inspired language models for predicting the language of texts.", "labels": [], "entities": [{"text": "predicting the language of texts", "start_pos": 77, "end_pos": 109, "type": "TASK", "confidence": 0.8359166264533997}]}, {"text": "In Section 2 we describe classification using the prediction by partial matching algorithm.", "labels": [], "entities": [{"text": "classification", "start_pos": 25, "end_pos": 39, "type": "TASK", "confidence": 0.9688763618469238}]}, {"text": "In Section 3 we report experiments on language identification.", "labels": [], "entities": [{"text": "language identification", "start_pos": 38, "end_pos": 61, "type": "TASK", "confidence": 0.7968705594539642}]}, {"text": "In Section 4 we discuss our participation in the DSL'16 challenge and briefly summarize results.", "labels": [], "entities": []}, {"text": "Section 5 briefly mentions a few related studies.", "labels": [], "entities": []}], "datasetContent": [{"text": "In these experiments we use PPM-A, a decision that was undertaken based on the fact our existing software () relies on hash-tables to store frequency counts.", "labels": [], "entities": []}, {"text": "Refactoring the source code to use suffix trees would make it easier to adopt the parameter estimate techniques in PPM-C, but we did not have time before this year's evaluation to consider such a change.", "labels": [], "entities": []}, {"text": "It also came as a last-minute surprise to find that the dialectal Arabic dataset was phonetically encoded and not expressed in native orthography.", "labels": [], "entities": []}, {"text": "We had previously worked with written dialect identification using the test sets produced by.", "labels": [], "entities": [{"text": "written dialect identification", "start_pos": 30, "end_pos": 60, "type": "TASK", "confidence": 0.6339803238709768}]}, {"text": "Working with automatically produced phonetic representations is undoubtably a more challenging task, but not one that we were prepared for.", "labels": [], "entities": []}, {"text": "In hindsight, it would have been worthwhile to examine the training data beforehand.", "labels": [], "entities": []}, {"text": "Our runs were ranked 15th of 18 systems.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Comparison of PPM order and direction of processing.", "labels": [], "entities": []}, {"text": " Table 2: Comparison of PPM order and case-folding. Performance drops without case information.", "labels": [], "entities": []}, {"text": " Table 3: Use of case preservation, digit conflation, and combination of directionality. Our best results  for the DSL'15 dataset.", "labels": [], "entities": [{"text": "case preservation", "start_pos": 17, "end_pos": 34, "type": "TASK", "confidence": 0.7256935387849808}, {"text": "DSL'15 dataset", "start_pos": 115, "end_pos": 129, "type": "DATASET", "confidence": 0.9726212024688721}]}, {"text": " Table 4: Augmenting training data using external corpora -compare results to", "labels": [], "entities": [{"text": "Augmenting training", "start_pos": 10, "end_pos": 29, "type": "TASK", "confidence": 0.876692920923233}]}, {"text": " Table 3. The use of  additional data degrades performance.", "labels": [], "entities": []}, {"text": " Table 6: Results for all hltcoe runs.", "labels": [], "entities": []}, {"text": " Table 7: Confusion maxtrix for hltcoe run 1 (test set A -closed training).", "labels": [], "entities": [{"text": "Confusion maxtrix", "start_pos": 10, "end_pos": 27, "type": "METRIC", "confidence": 0.9016942381858826}]}]}