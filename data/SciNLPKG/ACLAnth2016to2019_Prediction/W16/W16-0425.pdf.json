{"title": [], "abstractContent": [{"text": "Precise semantic representation of a sentence and definitive information extraction are key steps in the accurate processing of sentence meaning, especially for figurative phenomena such as sarcasm, Irony, and metaphor cause literal meanings to be discounted and secondary or extended meanings to be intentionally profiled.", "labels": [], "entities": [{"text": "definitive information extraction", "start_pos": 50, "end_pos": 83, "type": "TASK", "confidence": 0.6662128269672394}]}, {"text": "Semantic modelling faces anew challenge in social media, because grammatical inaccuracy is commonplace yet many previous state-of-the-art methods exploit grammatical structure.", "labels": [], "entities": [{"text": "Semantic modelling", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.8583079874515533}]}, {"text": "For sarcasm detection over social media content, researchers so far have counted on Bag-of-Words(BOW), N-grams etc.", "labels": [], "entities": [{"text": "sarcasm detection", "start_pos": 4, "end_pos": 21, "type": "TASK", "confidence": 0.928216964006424}, {"text": "Bag-of-Words(BOW)", "start_pos": 84, "end_pos": 101, "type": "METRIC", "confidence": 0.8717592656612396}]}, {"text": "In this paper, we propose a neural network semantic model for the task of sarcasm detection.", "labels": [], "entities": [{"text": "sarcasm detection", "start_pos": 74, "end_pos": 91, "type": "TASK", "confidence": 0.9211567938327789}]}, {"text": "We also review semantic modelling using Support Vector Machine (SVM) that employs constituency parse-trees fed and labeled with syntactic and semantic information.", "labels": [], "entities": [{"text": "semantic modelling", "start_pos": 15, "end_pos": 33, "type": "TASK", "confidence": 0.8817871809005737}]}, {"text": "The proposed neural network model composed of Convolution Neu-ral Network(CNN) and followed by a Long short term memory (LSTM) network and finally a Deep neural network(DNN).", "labels": [], "entities": []}, {"text": "The proposed model outperforms state-of-the-art text-based methods for sarcasm detection, yielding an F-score of .92.", "labels": [], "entities": [{"text": "sarcasm detection", "start_pos": 71, "end_pos": 88, "type": "TASK", "confidence": 0.9515069425106049}, {"text": "F-score", "start_pos": 102, "end_pos": 109, "type": "METRIC", "confidence": 0.9994674324989319}]}], "introductionContent": [{"text": "Figurative language, such as metaphor, irony and sarcasm, is a ubiquitous aspect of human communication from ancient religious texts to modern microtexts.", "labels": [], "entities": []}, {"text": "Sarcasm detection, despite being a wellstudied phenomenon in cognitive science and linguistics (, is still at its infancy as a computational task.", "labels": [], "entities": [{"text": "Sarcasm detection", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.9316074252128601}]}, {"text": "Detection is difficult because literal meaning is discounted and secondary or extended meanings are instead intentionally profiled.", "labels": [], "entities": [{"text": "Detection", "start_pos": 0, "end_pos": 9, "type": "TASK", "confidence": 0.9714899659156799}]}, {"text": "In social contexts, one's ability to detect sarcasm relies heavily on social cues such as sentiment, belief, and speaker's intention.", "labels": [], "entities": []}, {"text": "Sarcasm is mocking and often involves harsh delivery to achieve savage putdowns, even though it can be also crafted more gently as the accretion of politeness and the abatement of hostility around a criticism.", "labels": [], "entities": [{"text": "Sarcasm", "start_pos": 0, "end_pos": 7, "type": "TASK", "confidence": 0.9523858428001404}]}, {"text": "Moreover, sarcasm often couches criticism within a humorous atmosphere.", "labels": [], "entities": []}, {"text": "() addressed one common form of sarcasm as the juxtaposition of a positive sentiment attached to a negative situation, or vice versa.", "labels": [], "entities": []}, {"text": "( ) modeled sarcasm via a composition of linguistic elements, such as specific surface features about a product, frequent words, and punctuation marks.", "labels": [], "entities": []}, {"text": "() views sarcasm as a conformation of lexical and pragmatic factors such as emoticons and profile references in social media.", "labels": [], "entities": []}, {"text": "Most research approaches toward the automatic detection of sarcasm are text-based and consider sarcasm to be as a function of contrasting conditions or lexical clues.", "labels": [], "entities": [{"text": "automatic detection of sarcasm", "start_pos": 36, "end_pos": 66, "type": "TASK", "confidence": 0.8102232068777084}]}, {"text": "Such approaches extract definitive lexical cues as features, where the linguistic scale of features is stretched from words to phrases to provide richer contexts for analysis.", "labels": [], "entities": []}, {"text": "Lexical feature cues may yield good results, yet without a precise semantic representation of a sentence, which is key for determining the intended gist of a sentence, robust automatic sarcasm detection will remain a difficult challenge to realize.", "labels": [], "entities": [{"text": "automatic sarcasm detection", "start_pos": 175, "end_pos": 202, "type": "TASK", "confidence": 0.6611924171447754}]}, {"text": "Accurate semantic modelling of context becomes obligatory for automatic sarcasm detection if social cues and extended meaning are to be grasped.", "labels": [], "entities": [{"text": "sarcasm detection", "start_pos": 72, "end_pos": 89, "type": "TASK", "confidence": 0.8259375095367432}]}, {"text": "Encouraging an immediate and very social use of language, social media platforms such as Twitter 1 are rich sources of texts for Natural Language Processing (NLP).", "labels": [], "entities": [{"text": "Natural Language Processing (NLP)", "start_pos": 129, "end_pos": 162, "type": "TASK", "confidence": 0.6875665585199991}]}, {"text": "Social micro-texts are dense in figurative language, and are useful for figurative analysis because of their topicality, ease of access, and the use of self-annotation via hashtag.", "labels": [], "entities": [{"text": "figurative analysis", "start_pos": 72, "end_pos": 91, "type": "TASK", "confidence": 0.7988927364349365}]}, {"text": "In Twitter, language is distorted, often plumbing the depths of bad language).", "labels": [], "entities": []}, {"text": "Yet due to the presence of grammatical errors liberally mixed with social media markers (hashtags, emoticons, profiles), abbreviations, and code switching, these micro-texts are harder to parse, and parsing is the most commonly used method to obtain a semantic representation of a sentence.", "labels": [], "entities": []}, {"text": "The accuracy of state-of-theart constituency parsers over tweets can be significantly lower than that for normal texts, so social media researchers still largely rely on surface level features.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 4, "end_pos": 12, "type": "METRIC", "confidence": 0.9985339641571045}]}, {"text": "With the recent move to artificial neural networks in NLP, ANNs provide an alternative basis for semantic modelling.", "labels": [], "entities": [{"text": "semantic modelling", "start_pos": 97, "end_pos": 115, "type": "TASK", "confidence": 0.91192227602005}]}, {"text": "In this paper, we perform semantic modelling of sentences using neural networks for the task of sarcasm detection.", "labels": [], "entities": [{"text": "semantic modelling of sentences", "start_pos": 26, "end_pos": 57, "type": "TASK", "confidence": 0.8378224521875381}, {"text": "sarcasm detection", "start_pos": 96, "end_pos": 113, "type": "TASK", "confidence": 0.9294540286064148}]}, {"text": "The paper is organized as follows.", "labels": [], "entities": []}, {"text": "Section 2 surveys related works, section 3 outlines methods of data collection and data processing, section 4 describes the recursive SVM model, section 5 describes the neural network model, section 6 & 7 outline our experimental setup and experimental analysis respectively, while section 8 presents a simple sarcastic Twitter bot.", "labels": [], "entities": [{"text": "data collection", "start_pos": 63, "end_pos": 78, "type": "TASK", "confidence": 0.7719510495662689}]}, {"text": "Finally, section 9 concludes with a short discussion of future work.", "labels": [], "entities": []}], "datasetContent": [{"text": "Twitter provides functionality to users to summarize their intention via hashtags.", "labels": [], "entities": [{"text": "summarize their intention", "start_pos": 43, "end_pos": 68, "type": "TASK", "confidence": 0.8957551717758179}]}, {"text": "Using a user's self-declaration of sarcasm as a retrieval cue, #sar-casm, we have crawled the Twittersphere.", "labels": [], "entities": []}, {"text": "Since this simple heuristic misses those uses of sarcasm that lack an explicit mention of #sarcasm, we used LSA-based approach to extend the list of indicative hashtags (e.g.to include #sarcastic, #yeahright etc.).", "labels": [], "entities": []}, {"text": "We also harvested tweets from user profiles with a strong bias toward sincerity or (for professional wits) sarcasm.", "labels": [], "entities": []}, {"text": "To build our sarcastic data set we aggregated all tweets containing one or more positive markers of sarcasm, but removed such markers from the tweets, while tweets which did not contain any positive markers of sarcasm were considered non-sarcastic.", "labels": [], "entities": []}, {"text": "The training dataset of 39K tweets is evenly balanced containing 18k sarcastic data and 21K non-sarcastic data.", "labels": [], "entities": []}, {"text": "As a test set, we have created a dataset of 2000 tweets annotated by an internal team of researchers.", "labels": [], "entities": []}, {"text": "For purposes of comparison, we also used two different publicly available sarcasm datasets.", "labels": [], "entities": []}, {"text": "Social media contains many interesting elements such as hashtags, profile references and emoticons.", "labels": [], "entities": []}, {"text": "Due to the size limitation of tweets, users exploit these elements to provide contextual information.", "labels": [], "entities": []}, {"text": "To tightly focus our research question, we did not include sarcasm from the larger conversational context and thus dropped all profile information from the input text.", "labels": [], "entities": []}, {"text": "As users often use multi-worded hashtags to add an additional sarcastic dimension to a tweet.", "labels": [], "entities": []}, {"text": "we used a hashtag splitter to split these phrasal tags and appended their words to the text.", "labels": [], "entities": []}, {"text": "For the recursive-SVM, we used the Stanford constituency parser for parsing tweets.", "labels": [], "entities": [{"text": "parsing tweets", "start_pos": 68, "end_pos": 82, "type": "TASK", "confidence": 0.8889519572257996}]}, {"text": "In order to ex-3 http://nlp.stanford.edu/software/lex-parser.shtml tract maximum information from the parse tree, we used both a pre-processing and a post-processing method which are described below.", "labels": [], "entities": []}, {"text": "To evaluate both models, we have tested rigorously with different experimental setups.", "labels": [], "entities": []}, {"text": "For the recursive SVM, we employed different sets of feature combinations mentioned in table 1.", "labels": [], "entities": []}, {"text": "In the neural network model, we opted fora word embedding dimension set to 256.", "labels": [], "entities": []}, {"text": "We tested our model with different settings of the hyperparameters for CNN (number of filter, filter size), LSTM (hidden memory dimension, dropout ratio), and DNN (number of hidden memory units (HMU)).", "labels": [], "entities": [{"text": "CNN", "start_pos": 71, "end_pos": 74, "type": "METRIC", "confidence": 0.9380881786346436}, {"text": "LSTM", "start_pos": 108, "end_pos": 112, "type": "METRIC", "confidence": 0.9643667936325073}]}, {"text": "Initially we passed the output of CNN via a maxdropout layer, with maxpooling size 2 and 3, to the LSTM, but later we dropped the maxpooling layer, which improved the performance by 2%.", "labels": [], "entities": [{"text": "LSTM", "start_pos": 99, "end_pos": 103, "type": "DATASET", "confidence": 0.8094462752342224}]}, {"text": "In our experiment, apart from the combination of CNN, LSTM, and DNN, we observed the performance for each of the neural networks individually.", "labels": [], "entities": []}, {"text": "The CNN network is investigated by varying the number of filters and the filter widths, set to 64, 128, 256 and 2, 3 respectively.", "labels": [], "entities": []}, {"text": "For the LSTM network, the number of memory units is varied from 64 to 256.", "labels": [], "entities": []}, {"text": "Sigmoid is chosen as activation function for both networks.", "labels": [], "entities": []}, {"text": "We used Gaussian initialization scaled by the fan-in and the fan-out for the embedding layer and Gaussian initialization scaled by the fan-in for the CNN, the LSTM, and the DNN layer as initial probability distribution.", "labels": [], "entities": []}, {"text": "The code was implemented using keras 4 library.", "labels": [], "entities": []}, {"text": "In the neural network, success depends on the apt input and the selection of hyperparameters.", "labels": [], "entities": []}, {"text": "As we observed that the inclusion of hashtag information in the recursive-SVM method gained a better F-score, we pertained the same input structure for the neural network.", "labels": [], "entities": [{"text": "F-score", "start_pos": 101, "end_pos": 108, "type": "METRIC", "confidence": 0.998801589012146}]}, {"text": "Apart from difficulties in training a neural network, enormous training time is another passive obstacle.", "labels": [], "entities": []}, {"text": "We observed that compared to stacked LSTM network, the CNN-LSTM network converges faster as CNN reduces frequency variation and produces better composite representation of the input to the LSTM network.", "labels": [], "entities": []}, {"text": "Sarcasm detection is considered a complex task, as very subtle contextual information often triggers the sarcastic notion.", "labels": [], "entities": [{"text": "Sarcasm detection", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.972359836101532}]}, {"text": "Thus we noticed that the inclusion of a dropout layer on top of the CNN layer, our model suffered a decrease in performance.", "labels": [], "entities": []}, {"text": "In the testing dataset, we observed an interesting example.", "labels": [], "entities": []}, {"text": "I don't know about you man but I love the history homework.", "labels": [], "entities": []}, {"text": "With the dropout layer, model identified above mentioned example as non-sarcastic, yet without the dropout layer, our model labeled it as sarcastic.", "labels": [], "entities": []}, {"text": "This indicates that the word \"man\", which functions as an intensifier of sarcasm in this context, was dropped out from the output of the CNN layer.", "labels": [], "entities": []}, {"text": "Also we observed that incrementing the filter width of the CNN layer boosted the performance of our model by a small margin.", "labels": [], "entities": []}, {"text": "To obtain the apt network size, we have also trained with bigger network sizes and larger filter widths, but no improvement has been observed.", "labels": [], "entities": []}, {"text": "contains the experimental results over our dataset.", "labels": [], "entities": []}, {"text": "Sarcasm is a very subjective phenomenon.", "labels": [], "entities": [{"text": "Sarcasm", "start_pos": 0, "end_pos": 7, "type": "TASK", "confidence": 0.9222849011421204}]}, {"text": "Even for the human annotators, it was quite hard to decide if the speaker was sarcastic or not.", "labels": [], "entities": []}, {"text": "It was interesting to observe the performance of our model when human annotators interpreted differently.", "labels": [], "entities": []}, {"text": "Since our   We evaluated our system with two publicly available datasets).", "labels": [], "entities": []}, {"text": "The results are mentioned in table 3.", "labels": [], "entities": []}, {"text": "We observed 167 that our model has performed with a better f-score than both of the systems, but it has a lower precision value than SASI ( ).", "labels": [], "entities": [{"text": "f-score", "start_pos": 59, "end_pos": 66, "type": "METRIC", "confidence": 0.9751313328742981}, {"text": "precision", "start_pos": 112, "end_pos": 121, "type": "METRIC", "confidence": 0.9987462759017944}, {"text": "SASI", "start_pos": 133, "end_pos": 137, "type": "METRIC", "confidence": 0.8672332167625427}]}], "tableCaptions": [{"text": " Table 3: Comparison with other datasets", "labels": [], "entities": []}]}