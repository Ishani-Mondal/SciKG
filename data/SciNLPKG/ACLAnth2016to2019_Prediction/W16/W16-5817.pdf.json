{"title": [{"text": "Language Identification in Code-Switched Text Using Conditional Random Fields and Babelnet", "labels": [], "entities": [{"text": "Language Identification", "start_pos": 0, "end_pos": 23, "type": "TASK", "confidence": 0.6681681722402573}]}], "abstractContent": [{"text": "The paper outlines a supervised approach to language identification in code-switched data, framing this as a sequence labeling task where the label of each token is identified using a classifier based on Conditional Random Fields and trained on a range of different features, extracted both from the training data and by using information from Babelnet and Babelfy.", "labels": [], "entities": [{"text": "language identification", "start_pos": 44, "end_pos": 67, "type": "TASK", "confidence": 0.7484561204910278}]}, {"text": "The method was tested on the development dataset provided by organizers of the shared task on language identification in code-switched data, obtaining tweet level monolin-gual, code-switched and weighted F1-scores of 94%, 85% and 91%, respectively, with a token level accuracy of 95.8%.", "labels": [], "entities": [{"text": "language identification", "start_pos": 94, "end_pos": 117, "type": "TASK", "confidence": 0.7358440309762955}, {"text": "F1-scores", "start_pos": 204, "end_pos": 213, "type": "METRIC", "confidence": 0.9678614139556885}, {"text": "accuracy", "start_pos": 268, "end_pos": 276, "type": "METRIC", "confidence": 0.5867395997047424}]}, {"text": "When evaluated on the unseen test data, the system achieved 90%, 85% and 87.4% monolingual, code-switched and weighted tweet level F1-scores, and a token level accuracy of 95.7%.", "labels": [], "entities": [{"text": "F1-scores", "start_pos": 131, "end_pos": 140, "type": "METRIC", "confidence": 0.6549497842788696}, {"text": "accuracy", "start_pos": 160, "end_pos": 168, "type": "METRIC", "confidence": 0.8070756793022156}]}], "introductionContent": [{"text": "Today many short messages contain words from different languages and it is a challenging task to identify which languages the different words are written in.", "labels": [], "entities": []}, {"text": "Often the messages contain text snippets from several languages, that is, showing code-switching.", "labels": [], "entities": []}, {"text": "Sometimes the messages even contain code-mixing, where there is a mix of the languages inside a single utterance or even inside a token itself.", "labels": [], "entities": []}, {"text": "The first code-switching data challenge was organized at EMNLP 2014 ().", "labels": [], "entities": [{"text": "EMNLP 2014", "start_pos": 57, "end_pos": 67, "type": "DATASET", "confidence": 0.8884201347827911}]}, {"text": "The task was to identify the language for each word in a text, classifying the words according to six labels: 'Lang1', 'Lang2', 'Mixed', 'NE', 'Other', and 'Ambiguous'.", "labels": [], "entities": []}, {"text": "The first two labels identify tokens from the main languages that are mixed in the text, while the third is for tokens with word-internal mixing between these languages; 'NE' for named entities; 'Other' for language independent tokens (punctuation, numbers, etc.) and tokens from other languages, and 'Ambiguous' denotes tokens that cannot safely be assigned any (or only one) of the other labels.", "labels": [], "entities": []}, {"text": "This shared task was organized again this year (, with new datasets and slightly different labels, adding 'Unk' for unknown tokens.", "labels": [], "entities": []}, {"text": "Work on developing tools for automatic language identification was initiated already in the 1960s, and although analysing codeswitched text is a research area which has started to achieve wide-spread attention only in recent years, the first work in the field was carried out over thirty years ago by, examined the syntax of the intra-sentential code-switching between Arabic and French.", "labels": [], "entities": [{"text": "automatic language identification", "start_pos": 29, "end_pos": 62, "type": "TASK", "confidence": 0.6442191004753113}]}, {"text": "They claimed that Arabic-French codeswitching was possible at all syntactic boundaries above the word level.", "labels": [], "entities": []}, {"text": "give a comprehensive overview of the work on code-switching until 2015.", "labels": [], "entities": []}, {"text": "Notably, Solorio and Liu (2008) trained classifiers to predict code-switching points in Spanish and English, using different learning algorithms and transcriptions of code-switched discourse, while Nguyen and Do\u02d8 gru\u00f6z (2013) focused on wordlevel language identification (in Dutch-Turkish news commentary).", "labels": [], "entities": [{"text": "wordlevel language identification", "start_pos": 237, "end_pos": 270, "type": "TASK", "confidence": 0.736703077952067}]}, {"text": "Nguyen and Cornips (2016) describe work on analyzing and detecting intra-word codemixing by first segmenting words into smaller units and later identifying words composed of sequences of subunits associated with different languages in tweets (posts on the Twitter social-media site).", "labels": [], "entities": []}, {"text": "The paper is organized as follows: Section 2 provides a description of the language identification method, whereby a supervised model was built using Conditional Random Fields to classify each token in a tweet into one of the seven categories based on different features, most of which are extracted from the training data, as described in Section 3.", "labels": [], "entities": [{"text": "language identification", "start_pos": 75, "end_pos": 98, "type": "TASK", "confidence": 0.7401214838027954}]}, {"text": "Results are then presented and discussed in Section 4, while Section 5 addresses future work and concludes.", "labels": [], "entities": []}], "datasetContent": [{"text": "We used the datasets provided by the organizers of the EMNLP 2016 code-switching workshop shared task on language identification in code-switched data ().", "labels": [], "entities": [{"text": "EMNLP 2016 code-switching workshop", "start_pos": 55, "end_pos": 89, "type": "DATASET", "confidence": 0.8227466642856598}, {"text": "language identification", "start_pos": 105, "end_pos": 128, "type": "TASK", "confidence": 0.6866061985492706}]}, {"text": "Three types of data were provided: training, development and test.", "labels": [], "entities": []}, {"text": "In the training and development datasets, the total number of tweets are 11,400 and 3,014, respectively, with language identification offsets given for each category.", "labels": [], "entities": []}, {"text": "In the test data, the total number of tweets is 18,237 without annotations.", "labels": [], "entities": []}, {"text": "The number of tweets and the number of tokens in each of the three datasets are given in.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Statistics of the tweet datasets", "labels": [], "entities": []}, {"text": " Table 2: System performance on the development data, with and without the external resources (Babelnet and Babelfy)", "labels": [], "entities": []}, {"text": " Table 3: Token level accuracy (left) and tweet level F1 scores (right) on the test data for all participating systems", "labels": [], "entities": [{"text": "accuracy", "start_pos": 22, "end_pos": 30, "type": "METRIC", "confidence": 0.7835732698440552}, {"text": "tweet level F1 scores", "start_pos": 42, "end_pos": 63, "type": "METRIC", "confidence": 0.788616880774498}]}]}