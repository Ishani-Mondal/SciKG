{"title": [{"text": "Active learning for detection of stance components", "labels": [], "entities": [{"text": "detection of stance", "start_pos": 20, "end_pos": 39, "type": "TASK", "confidence": 0.8445800940195719}]}], "abstractContent": [{"text": "Automatic detection of five language components, which are all relevant for expressing opinions and for stance taking, was studied: positive sentiment, negative sentiment, speculation, contrast and condition.", "labels": [], "entities": [{"text": "stance taking", "start_pos": 104, "end_pos": 117, "type": "TASK", "confidence": 0.973179966211319}, {"text": "contrast", "start_pos": 185, "end_pos": 193, "type": "METRIC", "confidence": 0.9852584600448608}]}, {"text": "A resource-aware approach was taken, which included manual annotation of 500 training samples and the use of limited lexical resources.", "labels": [], "entities": []}, {"text": "Active learning was compared to random selection of training data, as well as to a lexicon-based method.", "labels": [], "entities": []}, {"text": "Active learning was successful for the categories speculation, contrast and condition, but not for the two sentiment categories, for which results achieved when using active learning were similar to those achieved when applying a random selection of training data.", "labels": [], "entities": []}, {"text": "This difference is likely due to a larger variation in how sentiment is expressed than in how speakers express the other three categories.", "labels": [], "entities": []}, {"text": "This larger variation was also shown by the lower recall results achieved by the lexicon-based approach for sentiment than for the categories speculation, contrast and condition.", "labels": [], "entities": [{"text": "recall", "start_pos": 50, "end_pos": 56, "type": "METRIC", "confidence": 0.999261200428009}]}], "introductionContent": [{"text": "In studies of automatic detection of opinions, it is typically assumed that there are substantial resources available in the form of annotated text corpora (.", "labels": [], "entities": [{"text": "automatic detection of opinions", "start_pos": 14, "end_pos": 45, "type": "TASK", "confidence": 0.7917194738984108}]}, {"text": "However, such large resources of annotated data cannot always be obtained, e.g., when crowd-sourced or community annotations are not possible or not desirable.", "labels": [], "entities": []}, {"text": "The aim of this study is, therefore, to explore the possibility to detect language components that are relevant for opinion mining and stance detection, when using very limited resources of manually annotated data.", "labels": [], "entities": [{"text": "opinion mining", "start_pos": 116, "end_pos": 130, "type": "TASK", "confidence": 0.9050224423408508}, {"text": "stance detection", "start_pos": 135, "end_pos": 151, "type": "TASK", "confidence": 0.9693445861339569}]}, {"text": "Five language components, which are relevant as topic-independent components for expressing opinions and for stance taking, were investigated: positive and negative sentiment, speculation, contrast and condition.", "labels": [], "entities": [{"text": "stance taking", "start_pos": 109, "end_pos": 122, "type": "TASK", "confidence": 0.9757027328014374}, {"text": "contrast", "start_pos": 189, "end_pos": 197, "type": "METRIC", "confidence": 0.9537515044212341}]}, {"text": "Sentiment analysis is an important component of stance detection, as knowledge of whether positive or negative sentiment is expressed towards a target of interest has been shown useful for the task of binary stance detection, i.e., stance taking for or against a certain target (.", "labels": [], "entities": [{"text": "Sentiment analysis", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.9180712997913361}, {"text": "stance detection", "start_pos": 48, "end_pos": 64, "type": "TASK", "confidence": 0.9534415602684021}, {"text": "binary stance detection", "start_pos": 201, "end_pos": 224, "type": "TASK", "confidence": 0.6510939796765646}, {"text": "stance taking", "start_pos": 232, "end_pos": 245, "type": "TASK", "confidence": 0.804789274930954}]}, {"text": "Speculation, contrast and condition were assessed as important components for stance taking, as they can all be used as modifications of opinions.", "labels": [], "entities": [{"text": "Speculation", "start_pos": 0, "end_pos": 11, "type": "METRIC", "confidence": 0.9292089939117432}, {"text": "contrast", "start_pos": 13, "end_pos": 21, "type": "METRIC", "confidence": 0.9815422892570496}, {"text": "stance taking", "start_pos": 78, "end_pos": 91, "type": "TASK", "confidence": 0.9774964153766632}]}, {"text": "For instance, an expression of contrast could indicate that opinions of different polarities are expressed, e.g., \"I did enjoy reading some of this book, but the two tales in the middle dragged too much for me to be able to really recommend this book\".", "labels": [], "entities": []}, {"text": "A positive opinion that is expressed with speculation might be less positive, e.g., \"His description of the 50's seems accurate and readers might enjoy the trip back in time\".", "labels": [], "entities": []}, {"text": "Finally, when a positive opinion is expressed in the context of a condition, it is not necessarily positive anymore, e.g., \"If the plot had been more gripping, more intense, this would have worked perfectly\".", "labels": [], "entities": []}, {"text": "Stanford Sentiment Treebank into the categories positive and negative sentiment.", "labels": [], "entities": [{"text": "Stanford Sentiment Treebank", "start_pos": 0, "end_pos": 27, "type": "DATASET", "confidence": 0.7874046166737875}]}, {"text": "When the sentences were classified into a five-level scale of sentiment, with the category neutral included (, an accuracy of 0.81 was achieved.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 114, "end_pos": 122, "type": "METRIC", "confidence": 0.999602735042572}]}, {"text": "The three opinion modifying categories have all been defined in previous research.", "labels": [], "entities": [{"text": "opinion modifying", "start_pos": 10, "end_pos": 27, "type": "TASK", "confidence": 0.774962306022644}]}, {"text": "Speculation has, for instance, been defined as \"the possible existence of a thing is claimed -neither its existence nor its non-existence is known for sure\".", "labels": [], "entities": []}, {"text": "Contrast has been defined as \"Contrast(\u03b1,\u03b2) holds when \u03b1 and \u03b2 have similar semantic structures, but contrasting themes, i.e. sentence topics, or when one constituent negates a default consequence of the other\" (.", "labels": [], "entities": []}, {"text": "Finally, the category condition is defined within in Rhetorical Structure Theory as something which \"presents a hypothetical, future, or otherwise unrealized situation\".", "labels": [], "entities": [{"text": "Rhetorical Structure Theory", "start_pos": 53, "end_pos": 80, "type": "TASK", "confidence": 0.824053684870402}]}, {"text": "There are several studies on speculation/uncertainty detection ().", "labels": [], "entities": [{"text": "speculation/uncertainty detection", "start_pos": 29, "end_pos": 62, "type": "TASK", "confidence": 0.8456082791090012}]}, {"text": "On the SFU Review corpus, which consists of English consumer generated reviews of books, movies, music, cars, computers, cookware and hotels (), speculation cues, together with their scopes, have been annotated).", "labels": [], "entities": [{"text": "SFU Review corpus", "start_pos": 7, "end_pos": 24, "type": "DATASET", "confidence": 0.9698482553164164}]}, {"text": "An F-score of 0.92 () was achieved when training a support vector machine to automatically detect the annotated cues.", "labels": [], "entities": [{"text": "F-score", "start_pos": 3, "end_pos": 10, "type": "METRIC", "confidence": 0.9996347427368164}]}, {"text": "The SFU Review corpus has also been annotated for contrasts and conditions.", "labels": [], "entities": [{"text": "SFU Review corpus", "start_pos": 4, "end_pos": 21, "type": "DATASET", "confidence": 0.9665128191312155}]}, {"text": "Experiments have been carried out on the task of determining whether a sentence in this corpus contains an expression of speculation, contrast or condition.", "labels": [], "entities": []}, {"text": "A classifier F-score of around 0.90 was achieved for speculation, around 0.60 for contrast and around 0.70 for condition, when using around 3,000 training samples (.", "labels": [], "entities": [{"text": "F-score", "start_pos": 13, "end_pos": 20, "type": "METRIC", "confidence": 0.8630894422531128}, {"text": "contrast", "start_pos": 82, "end_pos": 90, "type": "METRIC", "confidence": 0.9852997064590454}]}, {"text": "The standard method to randomly select samples for training the machine learning models were used in all studies described above.", "labels": [], "entities": []}, {"text": "However, instead of a random selection, it is possible to use an active selection of useful training data.", "labels": [], "entities": []}, {"text": "Although there are some studies on the use of such active learning techniques for sentiment analysis (, few studies measure results for resource-aware approaches when using a very limited amount of manually annotated data.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 82, "end_pos": 100, "type": "TASK", "confidence": 0.9786827862262726}]}, {"text": "The usefulness of active learning for sentence-level detection of language components relevant when expressing stance, and when using a very limited amount of training data, is, therefore, the focus of this study.", "labels": [], "entities": [{"text": "sentence-level detection", "start_pos": 38, "end_pos": 62, "type": "TASK", "confidence": 0.672920897603035}]}], "datasetContent": [{"text": "A total of five different approaches for detecting the categories investigated were compared, three methods based on active learning, one based on random sampling and one lexicon-matching approach: (1) The lexicon-matching was the most basic approach.", "labels": [], "entities": []}, {"text": "Sentences that contained a marker in any of the five compiled lexicons were classified as belonging to the category for which the lexicon was compiled.", "labels": [], "entities": []}, {"text": "A situation was simulated in which limited resources would be available to create an annotated corpus, and thereby a maximum of 500 annotated sentences would be available for training a classifier.", "labels": [], "entities": []}, {"text": "Given a hypothetical annotation speed of 50 sentences per hour, it would be possible to construct such an annotated corpus in ten working hours.", "labels": [], "entities": []}, {"text": "The five stance categories were evaluated separately, and separate binary classifiers were trained for each of the categories.", "labels": [], "entities": []}, {"text": "The work of the manual annotator was simulated by using the annotations in the corpora described above.", "labels": [], "entities": []}, {"text": "Each corpus was split into two equally large sets: an evaluation set and a set to use as the pool of data from which training samples were to be selected.", "labels": [], "entities": []}, {"text": "The pool of data from which samples were selected was thus used as simulated unlabelled data, and manual annotation of the selected samples was simulated by using the labelling available in the annotated corpus.", "labels": [], "entities": []}, {"text": "The same randomly selected seed set of 30 training samples was used for all machine learning approaches, except for approach number five, for which the lexicons were used for selecting samples.", "labels": [], "entities": []}, {"text": "There is a large difference between the proportion of samples belonging to the minority category for the different categories.", "labels": [], "entities": []}, {"text": "That is, a proportion of 24% for speculation, 8% for contrast and 4% for condition, compared to a proportion of 42% and 39% for positive and negative sentiment, respectively.", "labels": [], "entities": []}, {"text": "In order to investigate whether potential differences between categories depend on these proportion differences, rather than on differences between how the categories are expressed, additional experiments were performed for modified versions of the positive and negative sentiment corpora.", "labels": [], "entities": []}, {"text": "The original training data for the sentiment classifiers was modified to instead contain a 24% proportion of the minority category, i.e., the same proportion of minority category samples as the speculation category.", "labels": [], "entities": [{"text": "sentiment classifiers", "start_pos": 35, "end_pos": 56, "type": "TASK", "confidence": 0.8823600709438324}]}, {"text": "This was achieved by removing a randomly selected set of instances that belonged to the minority category from the training data.", "labels": [], "entities": []}, {"text": "That is, the instances classified as positive when investigating positive sentiment, and the instances classified as negative for negative sentiment.", "labels": [], "entities": []}, {"text": "For each of the seven data sets (five with original minority category frequencies and two with modified frequencies), the experiments were repeated 60 times, with anew random split into an evaluation set and into a pool of data from which to select training samples.", "labels": [], "entities": []}, {"text": "For each of the 60 folds, anew randomly selected seed set (or a seed set selected based on the lexicon for approach number five) was used.", "labels": [], "entities": []}, {"text": "Average precision, recall and F-score between the 60 folds were measured.", "labels": [], "entities": [{"text": "precision", "start_pos": 8, "end_pos": 17, "type": "METRIC", "confidence": 0.9997499585151672}, {"text": "recall", "start_pos": 19, "end_pos": 25, "type": "METRIC", "confidence": 0.9997736811637878}, {"text": "F-score", "start_pos": 30, "end_pos": 37, "type": "METRIC", "confidence": 0.9994843006134033}]}], "tableCaptions": []}