{"title": [], "abstractContent": [{"text": "We explore a large number of features for cross-lingual pronoun prediction for translation between English and Ger-man/French.", "labels": [], "entities": [{"text": "cross-lingual pronoun prediction", "start_pos": 42, "end_pos": 74, "type": "TASK", "confidence": 0.7159709930419922}, {"text": "translation between English and Ger-man/French", "start_pos": 79, "end_pos": 125, "type": "TASK", "confidence": 0.6704288635935102}]}, {"text": "We find that features related to German/French are more informative than features related to English, regardless of the translation direction.", "labels": [], "entities": []}, {"text": "Our most useful features are local context, dependency head features, and source pronouns.", "labels": [], "entities": []}, {"text": "We also find that it is sometimes more successful to employ a 2-step procedure that first makes a binary choice between pronouns and other, then classifies pronouns.", "labels": [], "entities": []}, {"text": "For the pronoun/other distinction POS n-grams were very useful.", "labels": [], "entities": []}], "introductionContent": [{"text": "This paper reports results for the UU-Stymne system on the WMT 2016 pronoun prediction shared task.", "labels": [], "entities": [{"text": "WMT 2016 pronoun prediction shared task", "start_pos": 59, "end_pos": 98, "type": "TASK", "confidence": 0.7692586332559586}]}, {"text": "The task entails classifying which among a set of target pronouns, or other is the correct translation of a given source pronoun.", "labels": [], "entities": []}, {"text": "There are tasks for two language pairs, English and German/French, in both directions.", "labels": [], "entities": []}, {"text": "An example is shown in (1), where we need to predict which German pronoun should be the translation of It, which in this case should beer since it refers to the masculine word Saal (room) in the previous sentence.", "labels": [], "entities": []}, {"text": "Had the antecedent instead been the neuter Zimmer, the correct pronoun would have been es.", "labels": [], "entities": []}, {"text": "The target words are lemmatized with coarse POS-tags, to better mimic the SMT task, in contrast to previous versions of this task where full forms were used.", "labels": [], "entities": [{"text": "SMT task", "start_pos": 74, "end_pos": 82, "type": "TASK", "confidence": 0.9207651913166046}]}, {"text": "For full details of the task and training data, seethe task overview paper ().", "labels": [], "entities": []}, {"text": "(1) It 's smaller than this . REPLACE 0 sein|VERB klein|ADJ als|CONJ dies|PRON hier|ADV .|.", "labels": [], "entities": [{"text": "REPLACE", "start_pos": 30, "end_pos": 37, "type": "METRIC", "confidence": 0.9938720464706421}, {"text": "VERB", "start_pos": 45, "end_pos": 49, "type": "METRIC", "confidence": 0.9722967743873596}, {"text": "CONJ", "start_pos": 64, "end_pos": 68, "type": "METRIC", "confidence": 0.659691333770752}, {"text": "ADV", "start_pos": 84, "end_pos": 87, "type": "DATASET", "confidence": 0.8149730563163757}]}, {"text": "We set out to establish the usefulness of a large number of features for this task in all translation directions, without any explicit use of anaphora resolution.", "labels": [], "entities": [{"text": "anaphora resolution", "start_pos": 142, "end_pos": 161, "type": "TASK", "confidence": 0.7368533313274384}]}, {"text": "We also investigate a 2-step classification procedure.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Macro-R for workshop baseline.", "labels": [], "entities": []}, {"text": " Table 2: Macro-R for individual feature groups  and source and target features", "labels": [], "entities": []}, {"text": " Table 3: Feature ablation study. Macro-R with in- dividual feature groups removed.", "labels": [], "entities": []}, {"text": " Table 4: Macro-R with different local context, and  the best window sizes", "labels": [], "entities": []}, {"text": " Table 5: Macro-R for systems with removed sets  of feature groups", "labels": [], "entities": []}, {"text": " Table 6: Macro-R with different combinations of  training data with the feature set from the sub- mitted system (I=IWSLT, N=News, E=Europarl),  \u221216 means filtering away features occurring less  than 16 times in the training data. (D) is for results  on the DiscoMT15 set. The training data used in  the submitted 1-step systems are marked in bold.", "labels": [], "entities": [{"text": "IWSLT", "start_pos": 116, "end_pos": 121, "type": "METRIC", "confidence": 0.47572147846221924}, {"text": "Europarl", "start_pos": 133, "end_pos": 141, "type": "DATASET", "confidence": 0.899110734462738}, {"text": "DiscoMT15 set", "start_pos": 258, "end_pos": 271, "type": "DATASET", "confidence": 0.9602594971656799}]}, {"text": " Table 7: Macro-R for submitted system, and best systems trained after submission time,using IWSLT  and all data for training.", "labels": [], "entities": [{"text": "IWSLT", "start_pos": 93, "end_pos": 98, "type": "DATASET", "confidence": 0.7861076593399048}]}]}