{"title": [], "abstractContent": [{"text": "In this paper we describe a method for selecting pairs of parallel documents (docu-ments that area translation of each other) from a large collection of documents obtained from the web.", "labels": [], "entities": []}, {"text": "Our approach is based on a coverage score that reflects the number of distinct bilingual phrase pairs found in each pair of documents, normalized by the total number of unique phrases found in them.", "labels": [], "entities": [{"text": "coverage score", "start_pos": 27, "end_pos": 41, "type": "METRIC", "confidence": 0.9526301920413971}]}, {"text": "Since parallel documents tend to share more bilingual phrase pairs than non-parallel documents, our alignment algorithm selects pairs of documents with the maximum coverage score from all possible pairings involving either one of the two documents.", "labels": [], "entities": [{"text": "coverage", "start_pos": 164, "end_pos": 172, "type": "METRIC", "confidence": 0.9659152626991272}]}], "introductionContent": [{"text": "In this paper we describe our algorithm for bilingual document alignment, which is based on a coverage scoring function that reflects the ratio of unique bilingual phrase pairs from a Moses phrase table () that are found in each bilingual pair of documents . Basically, we exploit the fact that (parallel) phrase pairs are more likely to co-occur in parallel documents than in non-parallel ones.", "labels": [], "entities": [{"text": "bilingual document alignment", "start_pos": 44, "end_pos": 72, "type": "TASK", "confidence": 0.6884679694970449}]}, {"text": "This insight came to our mind when we learned about the MT-based approach proposed by to the closely related sentence alignment problem, which is to align parallel sentences within a pair of parallel documents.", "labels": [], "entities": [{"text": "MT-based", "start_pos": 56, "end_pos": 64, "type": "TASK", "confidence": 0.9846991896629333}, {"text": "sentence alignment problem", "start_pos": 109, "end_pos": 135, "type": "TASK", "confidence": 0.7955586413542429}]}, {"text": "The MT-based approach to sentence alignment uses the BLEU score between sentences of one document and machine translated sentences of the other, as an indicator of parallelism between sentences.", "labels": [], "entities": [{"text": "MT-based", "start_pos": 4, "end_pos": 12, "type": "TASK", "confidence": 0.9637567400932312}, {"text": "sentence alignment", "start_pos": 25, "end_pos": 43, "type": "TASK", "confidence": 0.7817738950252533}, {"text": "BLEU score", "start_pos": 53, "end_pos": 63, "type": "METRIC", "confidence": 0.9846906661987305}]}, {"text": "By using a phrase table directly we circumvent the decoding process which inevitably makes translation hereafter we will avoid repeating the word bilingual whenever we mention pairs of documents or phrases choices (and sometimes errors) that differ from the ones made by the human translators.", "labels": [], "entities": []}, {"text": "One may argue that using a decoder would have the advantage of avoiding \"noisy\" phrase pairs from the phrase table.", "labels": [], "entities": []}, {"text": "However, we observed that most of the \"noisy\" phrase pairs in the phrase table are not completely unrelated.", "labels": [], "entities": []}, {"text": "Instead, they sometimes miss a word or two on one of the sides, but are otherwise parallel to some extent.", "labels": [], "entities": []}, {"text": "Nevertheless, since we employ uniform weighting for all phrase pairs (we treat them as binary features; either they are present in a document or not), the effect of noisy entries becomes diluted in a large number of features.", "labels": [], "entities": []}, {"text": "For the most sceptical amongst us, please consider that even if the phrase table was created by a random aligner, the mere fact that the phrase pairs were sampled from parallel sentences, would cause parallel documents to statistically share more of such phrase pairs than non-parallel documents.", "labels": [], "entities": []}, {"text": "Our earlier successful application of coveragebased scores to the problem of sentence alignment prompted us to develop a similar solution to the document alignment problem.", "labels": [], "entities": [{"text": "sentence alignment", "start_pos": 77, "end_pos": 95, "type": "TASK", "confidence": 0.7285416275262833}, {"text": "document alignment", "start_pos": 145, "end_pos": 163, "type": "TASK", "confidence": 0.719950944185257}]}], "datasetContent": [{"text": "The evaluation in this shared task is based on recall, i.e. the ratio of URL pairs from the testset that are correctly identified by the aligner.", "labels": [], "entities": [{"text": "recall", "start_pos": 47, "end_pos": 53, "type": "METRIC", "confidence": 0.999303936958313}]}, {"text": "A oneto-one rule is enforced, which allows each English URL to be aligned with at most one French URL and vice versa.", "labels": [], "entities": []}, {"text": "Despite the merits of a pure content-based approach, which is applicable in scenarios where URLs and other metadata are not available, we acknowledge that for the present task we may obtain better results if we take advantage of all information available (page URL and HTML structure) besides the plain text content.", "labels": [], "entities": []}, {"text": "Therefore, besides evaluating our content-based method on its own, we submitted two additional extended sets of results obtained by trivial combinations of our content-based method with the metadata-based (URL-based) baseline method.", "labels": [], "entities": []}, {"text": "The first extended set, called coverage/url, gives priority to predictions of the coverage-based method, adding only URL-predicted pairs for URLs that were not aligned by the coverage-based method.", "labels": [], "entities": []}, {"text": "Conversely, the second extended set, called url/coverage, gives priority to the predictions of the URL-based aligner.", "labels": [], "entities": []}, {"text": "The results obtained with our coverage-based aligner and the two trivial combinations with the baseline aligner for the development and test sets are summarized in: Evaluation results on the final test set.", "labels": [], "entities": []}, {"text": "The coverage-based aligner, alone, improves 5% over the baseline on the development set and 33% on the test set.", "labels": [], "entities": []}, {"text": "But when combined with the baseline aligner, the recall is boosted up to 23% above the baseline on the development set and up to 42% on the test set.", "labels": [], "entities": [{"text": "recall", "start_pos": 49, "end_pos": 55, "type": "METRIC", "confidence": 0.9991626739501953}]}, {"text": "A possible explanation for the boosted recall is that since the methods rely on completely different feature sets, their predictions are to some degree complementary.", "labels": [], "entities": [{"text": "recall", "start_pos": 39, "end_pos": 45, "type": "METRIC", "confidence": 0.9969550371170044}]}, {"text": "We would like to point out that the coveragebased aligner made substantially fewer predictions than the baseline (52.7%) in the development set, and still yielded higher recall (+4.86%).", "labels": [], "entities": [{"text": "recall", "start_pos": 170, "end_pos": 176, "type": "METRIC", "confidence": 0.9997329115867615}]}, {"text": "This allows us to speculate that the precision of the coverage-based alignment is likely to be higher than the precision of the baseline.", "labels": [], "entities": [{"text": "precision", "start_pos": 37, "end_pos": 46, "type": "METRIC", "confidence": 0.9993859529495239}, {"text": "precision", "start_pos": 111, "end_pos": 120, "type": "METRIC", "confidence": 0.9984983205795288}]}], "tableCaptions": [{"text": " Table 1: Evaluation results on the development  set.", "labels": [], "entities": []}, {"text": " Table 2: Evaluation results on the final test set.", "labels": [], "entities": []}]}