{"title": [], "abstractContent": [{"text": "We introduce a bootstrapping algorithm for regression that exploits word embedding models.", "labels": [], "entities": []}, {"text": "We use it to infer four psycholinguis-tic properties of words: Familiarity, Age of Acquisition, Concreteness and Imagery and further populate the MRC Psycholinguistic Database with these properties.", "labels": [], "entities": [{"text": "Familiarity", "start_pos": 63, "end_pos": 74, "type": "METRIC", "confidence": 0.927208662033081}, {"text": "MRC Psycholinguistic Database", "start_pos": 146, "end_pos": 175, "type": "DATASET", "confidence": 0.9146829048792521}]}, {"text": "The approach achieves 0.88 correlation with human-produced values and the inferred psycholin-guistic features lead to state-of-the-art results when used in a Lexical Simplification task.", "labels": [], "entities": [{"text": "Lexical Simplification task", "start_pos": 158, "end_pos": 185, "type": "TASK", "confidence": 0.9146959185600281}]}], "introductionContent": [{"text": "Throughout the last three decades, much has been found on how the psycholinguistic properties of words influence cognitive processes in the human brain when a subject is presented with either written or spoken forms.", "labels": [], "entities": []}, {"text": "A word's Age of Acquisition is an example.", "labels": [], "entities": []}, {"text": "The findings in reveal that objects whose names are learned earlier in life can be named faster in later stages of life.", "labels": [], "entities": []}, {"text": "show that words learned in early ages are orthographically or phonologically very distinct from those learned in adult life.", "labels": [], "entities": []}, {"text": "Other examples of psycholinguistic properties, such as Familiarity and Concreteness, influence one's proficiency in word recognition and text comprehension.", "labels": [], "entities": [{"text": "Familiarity", "start_pos": 55, "end_pos": 66, "type": "METRIC", "confidence": 0.9874076843261719}, {"text": "word recognition", "start_pos": 116, "end_pos": 132, "type": "TASK", "confidence": 0.7736748456954956}]}, {"text": "The experiments in ( show that words with high Familiarity yield lower reaction times in both visual and auditory lexical decision, and require less hand gesticulation in order to be described.", "labels": [], "entities": [{"text": "Familiarity", "start_pos": 47, "end_pos": 58, "type": "METRIC", "confidence": 0.9983568787574768}]}, {"text": "found that humans are less sensitive to changes in wording made to sentences with high Concreteness words.", "labels": [], "entities": []}, {"text": "When quantified, these aspects can be used as features for various Natural Language Processing (NLP) tasks.", "labels": [], "entities": []}, {"text": "The Lexical Simplification approach in ) is an example.", "labels": [], "entities": [{"text": "Lexical Simplification", "start_pos": 4, "end_pos": 26, "type": "TASK", "confidence": 0.8113060891628265}]}, {"text": "By combining various collocational features and psycholinguistic measures extracted from the MRC Psycholinguistic Database, they trained a ranker) that reached first place in the English Lexical Simplification task at SemEval 2012.", "labels": [], "entities": [{"text": "MRC Psycholinguistic Database", "start_pos": 93, "end_pos": 122, "type": "DATASET", "confidence": 0.8978215853373209}, {"text": "English Lexical Simplification task at SemEval 2012", "start_pos": 179, "end_pos": 230, "type": "TASK", "confidence": 0.713257589510509}]}, {"text": "Semantic Classification tasks have also benefited from the use of such features: by combining Concreteness with other features, () reached the state-of-theart performance in Semantic Composition (denotative/connotative) and Semantic Modification (intersective/subsective) prediction.", "labels": [], "entities": [{"text": "Semantic Classification tasks", "start_pos": 0, "end_pos": 29, "type": "TASK", "confidence": 0.9090707302093506}, {"text": "Semantic Modification (intersective/subsective) prediction", "start_pos": 224, "end_pos": 282, "type": "TASK", "confidence": 0.6212130263447762}]}, {"text": "Despite the evident usefulness of psycholinguistic properties of words, resources describing such properties are rare.", "labels": [], "entities": []}, {"text": "The most extensively developed resource for English is the MRC Psycholinguistic Database (Section 2).", "labels": [], "entities": [{"text": "MRC Psycholinguistic Database", "start_pos": 59, "end_pos": 88, "type": "DATASET", "confidence": 0.8584505120913187}]}, {"text": "However, it is far from complete, most likely due to the inherent cost of manually entering such properties.", "labels": [], "entities": []}, {"text": "In this paper we propose a method to automatically infer these missing properties.", "labels": [], "entities": []}, {"text": "We train regressors by performing bootstrapping over the existing features in the MRC database, exploiting word embedding models and other linguistic resources for that (Section 3).", "labels": [], "entities": [{"text": "MRC database", "start_pos": 82, "end_pos": 94, "type": "DATASET", "confidence": 0.8387247323989868}]}, {"text": "This approach outperform various strong baselines (Section 4) and the resulting properties lead to significant improvements when used in Lexical Simplification models (Section 5).", "labels": [], "entities": [{"text": "Lexical Simplification", "start_pos": 137, "end_pos": 159, "type": "TASK", "confidence": 0.8594038188457489}]}], "datasetContent": [{"text": "Since we were notable to find previous work for this task, in these experiments, we compare the performance of our bootstrapping strategy to various baselines.", "labels": [], "entities": []}, {"text": "For training, we use the Ridge regression algorithm.", "labels": [], "entities": []}, {"text": "As features, our regressor uses the word's raw embedding values, along with the following 15 lexical features: \u2022 Word's length and number of syllables, as determined by the Morph Adorner module of LEXenstein ().", "labels": [], "entities": []}, {"text": "\u2022 Word's frequency in the Brown (, SUBTLEX (Brysbaert and New, 2009), SubIMDB (Paetzold and Specia, 2016), Wikipedia and Simple Wikipedia corpora.", "labels": [], "entities": [{"text": "Wikipedia", "start_pos": 107, "end_pos": 116, "type": "DATASET", "confidence": 0.9714323878288269}, {"text": "Simple Wikipedia corpora", "start_pos": 121, "end_pos": 145, "type": "DATASET", "confidence": 0.7950266202290853}]}, {"text": "\u2022 Number of senses, synonyms, hypernyms and hyponyms for word in WordNet).", "labels": [], "entities": [{"text": "WordNet", "start_pos": 65, "end_pos": 72, "type": "DATASET", "confidence": 0.9304091334342957}]}, {"text": "\u2022 Minimum, maximum and average distance between the word's senses in WordNet and the thesaurus' root sense.", "labels": [], "entities": [{"text": "Minimum", "start_pos": 2, "end_pos": 9, "type": "METRIC", "confidence": 0.9946787357330322}, {"text": "WordNet", "start_pos": 69, "end_pos": 76, "type": "DATASET", "confidence": 0.9794589877128601}]}, {"text": "\u2022 Number of images found for word in the Getty Images database 1 . We train our embedding models using word2vec () over a corpus of 7 billion words composed by the SubIMDB corpus, UMBC webbase 2 , News Crawl 3 , SUBTLEX (Brysbaert and New, 2009), Wikipedia and Simple Wikipedia.", "labels": [], "entities": [{"text": "Getty Images database", "start_pos": 41, "end_pos": 62, "type": "DATASET", "confidence": 0.895682156085968}, {"text": "SubIMDB corpus", "start_pos": 164, "end_pos": 178, "type": "DATASET", "confidence": 0.7540185451507568}, {"text": "UMBC webbase", "start_pos": 180, "end_pos": 192, "type": "DATASET", "confidence": 0.9243917763233185}, {"text": "Wikipedia", "start_pos": 247, "end_pos": 256, "type": "DATASET", "confidence": 0.9781187772750854}, {"text": "Simple Wikipedia", "start_pos": 261, "end_pos": 277, "type": "DATASET", "confidence": 0.8032378554344177}]}, {"text": "We use 5-fold cross-validation to optimise parameters: \u03b6, embeddings model architecture (CBOW or Skip-Gram), and word vector size (from 300 to 2,500 in intervals of 200).", "labels": [], "entities": []}, {"text": "We include four strong baseline systems in the comparison: \u2022 Max.", "labels": [], "entities": []}, {"text": "Similarity: Test word is assigned the property value of the closest word in the training set, i.e. the word with the highest cosine similarity according to the word embeddings model.", "labels": [], "entities": []}, {"text": "Similarity: Test word is assigned the average property value of then closest words in the training set, i.e. the words with the highest cosine similarity according to the word embeddings model.", "labels": [], "entities": []}, {"text": "The value of n is decided through 5-fold cross validation.", "labels": [], "entities": []}, {"text": "\u2022 Simple SVM: Test word is assigned the property value as predicted by an SVM regressor) with a polynomial kernel trained with the 15 aforementioned lexical features.", "labels": [], "entities": []}, {"text": "\u2022 Simple Ridge: Test word is assigned the property value as predicted by a Ridge regressor trained with the 15 aforementioned lexical features.", "labels": [], "entities": []}, {"text": "\u2022 Super Ridge: Identical to Simple Ridge, the only difference being that it also includes the words embeddings in the feature set.", "labels": [], "entities": []}, {"text": "We note that this baseline uses the exact same features and regression algorithm as our bootstrapped regressors.", "labels": [], "entities": []}, {"text": "The parameters of all baseline systems are optimised following the same method as with our approach.", "labels": [], "entities": []}, {"text": "We also measure the correlation between each of the aforementioned lexical features and the psycholinguistic properties.", "labels": [], "entities": []}, {"text": "For each psycholinguistic property, we create a training and a test set by splitting the labelled instances available in the MRC Database in two equally sized portions.", "labels": [], "entities": [{"text": "MRC Database", "start_pos": 125, "end_pos": 137, "type": "DATASET", "confidence": 0.9062107503414154}]}, {"text": "All training instances are used as seeds in our approach.", "labels": [], "entities": []}, {"text": "As evaluation metrics, we use Spearman's (\u03c1) and Pearson's (r) correlation.", "labels": [], "entities": [{"text": "Spearman's (\u03c1)", "start_pos": 30, "end_pos": 44, "type": "METRIC", "confidence": 0.7916893005371094}, {"text": "Pearson's (r) correlation", "start_pos": 49, "end_pos": 74, "type": "METRIC", "confidence": 0.9386680920918783}]}, {"text": "Pearson's correlation is the most important indicator of performance: an effective regressor would predict values that change linearly with a given psycholinguistic property.", "labels": [], "entities": [{"text": "Pearson's correlation", "start_pos": 0, "end_pos": 21, "type": "METRIC", "confidence": 0.586252748966217}]}, {"text": "The results are illustrated in.", "labels": [], "entities": []}, {"text": "While the similarity-based approaches tend to perform well for Concreteness and Imagery, typical regressors capture Familiarity and Age of Acquisition more effectively.", "labels": [], "entities": []}, {"text": "Our approach, on the other hand, is consistently superior for all psycholinguistic properties, with both Spearman's and Pearson's correlation scores varying between 0.82 and 0.88.", "labels": [], "entities": [{"text": "Pearson's correlation", "start_pos": 120, "end_pos": 141, "type": "METRIC", "confidence": 0.811260998249054}]}, {"text": "The difference in performance between the Super Ridge baseline and our approach confirm that our bootstrapping algorithm can in fact improve on the performance of a regressor.", "labels": [], "entities": [{"text": "Super Ridge baseline", "start_pos": 42, "end_pos": 62, "type": "DATASET", "confidence": 0.709689329067866}]}, {"text": "The parameters used by our bootstrappers, which are reported below, highlight the importance of parameter optimization in out bootstrapping strategy: its performance peaked with very different configurations for most psycholinguistic properties: \u2022 Familiarity: 300 word vector dimensions with a Skip-Gram model, and \u03b6 = 0.9.", "labels": [], "entities": []}, {"text": "\u2022 Age of Acquisition: 700 word vector dimensions with a CBOW model, and \u03b6 = 0.7.", "labels": [], "entities": []}, {"text": "\u2022 Concreteness: 1,100 word vector dimensions with a Skip-Gram model, and \u03b6 = 0.7.", "labels": [], "entities": []}, {"text": "\u2022 Imagery: 1,100 word vector dimensions with a Skip-Gram model, and \u03b6 = 0.7.", "labels": [], "entities": []}, {"text": "Interestingly, frequency in the SubIMDB corpus 4 , composed of over 7 million sentences extracted from subtitles of \"family\" movies and series, has good linear correlation with Familiarity and Age of Acquisition, much higher than any other feature.", "labels": [], "entities": [{"text": "frequency", "start_pos": 15, "end_pos": 24, "type": "METRIC", "confidence": 0.991085946559906}, {"text": "SubIMDB corpus 4", "start_pos": 32, "end_pos": 48, "type": "DATASET", "confidence": 0.8061839640140533}, {"text": "Familiarity", "start_pos": 177, "end_pos": 188, "type": "METRIC", "confidence": 0.9300406575202942}]}, {"text": "For Concreteness and Imagery, on the other hand, the results suggest something different: the further a word is from the root of a thesaurus, the most likely it is to refer to a physical objector entity.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Results on SemEval 2012 LS task dataset", "labels": [], "entities": [{"text": "SemEval 2012 LS task dataset", "start_pos": 21, "end_pos": 49, "type": "DATASET", "confidence": 0.859277868270874}]}]}