{"title": [{"text": "An Empirical Study of Automatic Chinese Word Segmentation for Spoken Language Understanding and Named Entity Recognition", "labels": [], "entities": [{"text": "Automatic Chinese Word Segmentation", "start_pos": 22, "end_pos": 57, "type": "TASK", "confidence": 0.5970185771584511}, {"text": "Spoken Language Understanding", "start_pos": 62, "end_pos": 91, "type": "TASK", "confidence": 0.8570642669995626}, {"text": "Named Entity Recognition", "start_pos": 96, "end_pos": 120, "type": "TASK", "confidence": 0.7709077000617981}]}], "abstractContent": [{"text": "Word segmentation is usually recognized as the first step for many Chinese natural language processing tasks, yet its impact on these subsequent tasks is relatively under-studied.", "labels": [], "entities": [{"text": "Word segmentation", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.709303230047226}, {"text": "Chinese natural language processing tasks", "start_pos": 67, "end_pos": 108, "type": "TASK", "confidence": 0.6788059771060944}]}, {"text": "For example, how to solve the mismatch problem when applying an existing word seg-menter to new data?", "labels": [], "entities": []}, {"text": "Does a better word seg-menter yield a better subsequent NLP task per-formance?", "labels": [], "entities": []}, {"text": "In this work, we conduct an initial attempt to answer these questions on two related subsequent tasks: semantic slot filling in spoken language understanding and named entity recognition.", "labels": [], "entities": [{"text": "semantic slot filling in spoken language understanding", "start_pos": 103, "end_pos": 157, "type": "TASK", "confidence": 0.7897877182279315}, {"text": "named entity recognition", "start_pos": 162, "end_pos": 186, "type": "TASK", "confidence": 0.6566700637340546}]}, {"text": "We propose three techniques to solve the mismatch problem: using word segmentation outputs as additional features, adaptation with partial-learning and taking advantage of n-best word segmentation list.", "labels": [], "entities": []}, {"text": "Experimental results demonstrate the effectiveness of these techniques for both tasks and we achieve an error reduction of about 11% for spoken language understanding and 24% for named entity recognition over the baseline systems.", "labels": [], "entities": [{"text": "error reduction", "start_pos": 104, "end_pos": 119, "type": "METRIC", "confidence": 0.9781276285648346}, {"text": "spoken language understanding", "start_pos": 137, "end_pos": 166, "type": "TASK", "confidence": 0.6854841311772665}, {"text": "named entity recognition", "start_pos": 179, "end_pos": 203, "type": "TASK", "confidence": 0.6292796432971954}]}], "introductionContent": [{"text": "Unlike English text in which sentences are sequences of words separated by white spaces, in Chinese text (as are some other languages including Arabic, Japanese, etc.), sentences are represented as strings of characters without similar natural delimiters.", "labels": [], "entities": []}, {"text": "Therefore, it is generally claimed that the first step in a Chinese language processing task is to identify the sequence of words in a sentence and mark * Work done at Nuance during an internship.", "labels": [], "entities": [{"text": "Chinese language processing task", "start_pos": 60, "end_pos": 92, "type": "TASK", "confidence": 0.6748052686452866}]}, {"text": "boundaries inappropriate places, which is refereed to as the task of Chinese Word Segmentation (CWS).", "labels": [], "entities": [{"text": "Chinese Word Segmentation (CWS)", "start_pos": 69, "end_pos": 100, "type": "TASK", "confidence": 0.7500250538190206}]}, {"text": "(1) Input: \u80fd\u7a7f\u591a\u5c11\u7a7f\u591a\u5c11 CWS 1: \u80fd|\u7a7f|\u591a \u591a \u591a\u5c11 \u5c11 \u5c11|\u7a7f|\u591a\u5c11 1 (Put on as much clothes as possible.)", "labels": [], "entities": [{"text": "Input", "start_pos": 4, "end_pos": 9, "type": "METRIC", "confidence": 0.969866156578064}]}], "datasetContent": [{"text": "As described above, intent recognition is the first step in SLU, and the availability of which is assumed in this research  For NER experiments, we use the benchmark NER data from the third SIGHAN Chinese language processing Bakeoff ().", "labels": [], "entities": [{"text": "intent recognition", "start_pos": 20, "end_pos": 38, "type": "TASK", "confidence": 0.8202217221260071}, {"text": "SLU", "start_pos": 60, "end_pos": 63, "type": "TASK", "confidence": 0.9603282809257507}, {"text": "NER", "start_pos": 128, "end_pos": 131, "type": "TASK", "confidence": 0.9516845345497131}, {"text": "SIGHAN Chinese language processing Bakeoff", "start_pos": 190, "end_pos": 232, "type": "DATASET", "confidence": 0.6526943862438201}]}, {"text": "It consists of 46,364 sentences in the training set and 4,365 sentences in the testing set.", "labels": [], "entities": []}, {"text": "These data are annotated with both word boundaries and NER information.", "labels": [], "entities": []}, {"text": "In the closed track evaluation of), participants could only use the information found in the provided training data.", "labels": [], "entities": []}, {"text": "Our best model (NER 3-fold) belongs to this track since it uses only the word segmentation annotation in the training data set.", "labels": [], "entities": [{"text": "word segmentation annotation", "start_pos": 73, "end_pos": 101, "type": "TASK", "confidence": 0.755998452504476}]}, {"text": "Our model outperforms all the submissions as shown in.", "labels": [], "entities": []}, {"text": "Furthermore, even if manual word segmentation does not exist in the data, the model CTB6 N-best and PKU N-best which using existing word segmenters trained from publiclyavailable data can still outperform all the submissions in SIGHAN-3.", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 28, "end_pos": 45, "type": "TASK", "confidence": 0.7569559514522552}]}, {"text": "Note that, these models use only character and word segmentation features without requiring additional name lists, part-of-speech taggers, etc.", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 47, "end_pos": 64, "type": "TASK", "confidence": 0.6995294988155365}]}], "tableCaptions": [{"text": " Table 1: Statistics of two publicly-available corpus for CWS", "labels": [], "entities": [{"text": "CWS", "start_pos": 58, "end_pos": 61, "type": "TASK", "confidence": 0.7209856510162354}]}, {"text": " Table 2: SLU Results in Recall (R), Precision (P), and F-measure (F).  *  means it is statistically significant better than Baseline", "labels": [], "entities": [{"text": "Recall (R)", "start_pos": 25, "end_pos": 35, "type": "METRIC", "confidence": 0.9400850087404251}, {"text": "Precision (P)", "start_pos": 37, "end_pos": 50, "type": "METRIC", "confidence": 0.9552987813949585}, {"text": "F-measure (F)", "start_pos": 56, "end_pos": 69, "type": "METRIC", "confidence": 0.958398774266243}]}, {"text": " Table 3: CWS and NER Results in F-measure. CWS F (Train) and CWS F (Test) are the word segmentation F-measure in the", "labels": [], "entities": [{"text": "F-measure", "start_pos": 33, "end_pos": 42, "type": "METRIC", "confidence": 0.9219667911529541}, {"text": "CWS F (Test)", "start_pos": 62, "end_pos": 74, "type": "METRIC", "confidence": 0.7611392855644226}, {"text": "word segmentation F-measure", "start_pos": 83, "end_pos": 110, "type": "TASK", "confidence": 0.7412803967793783}]}, {"text": " Table 3. This verifies our hypothesis that 1-best  CWS is not sufficient.", "labels": [], "entities": []}]}