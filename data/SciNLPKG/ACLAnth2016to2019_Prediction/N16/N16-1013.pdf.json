{"title": [{"text": "Integer Linear Programming for Discourse Parsing", "labels": [], "entities": []}], "abstractContent": [{"text": "In this paper we present the first, to the best of our knowledge, discourse parser that is able to predict non-tree DAG structures.", "labels": [], "entities": [{"text": "discourse parser", "start_pos": 66, "end_pos": 82, "type": "TASK", "confidence": 0.7149939388036728}]}, {"text": "We use Integer Linear Programming (ILP) to encode both the objective function and the constraints as global decoding over local scores.", "labels": [], "entities": []}, {"text": "Our underlying data come from multi-party chat dialogues , which require the prediction of DAGs.", "labels": [], "entities": []}, {"text": "We use the dependency parsing paradigm, as has been done in the past (Muller et al., 2012; Li et al., 2014; Afantenos et al., 2015), but we use the underlying formal framework of SDRT and exploit SDRT's notions of left and right distributive relations.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 11, "end_pos": 29, "type": "TASK", "confidence": 0.847241073846817}]}, {"text": "We achieve an F-measure of 0.531 for fully labeled structures which beats the previous state of the art.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 14, "end_pos": 23, "type": "METRIC", "confidence": 0.9990386962890625}]}], "introductionContent": [{"text": "Multi-party dialogue parsing, in which complete discourse structures for multi-party dialogue or its close cousin, multi-party chat, are automatically constructed, is still in its infancy.", "labels": [], "entities": [{"text": "Multi-party dialogue parsing", "start_pos": 0, "end_pos": 28, "type": "TASK", "confidence": 0.813068171342214}]}, {"text": "Nevertheless, these are now very common forms of communication on the Web.", "labels": [], "entities": []}, {"text": "Dialogue appears also importantly different from monologue.", "labels": [], "entities": []}, {"text": "point out that forcing discourse structures to be trees will perforce miss 9% of the links in their corpus, because a significant number of discourse structures in the corpus are not trees.", "labels": [], "entities": []}, {"text": "Although is the only prior paper we know of that studies dialogue parsing on multi-party dialogue, and that work relied on methods adapted to treelike structures, we think the area of multi-party dialogue and non-treelike discourse structures is ripe for investigation and potentially important for other genres like the discourse analysis of fora (, for example).", "labels": [], "entities": [{"text": "dialogue parsing", "start_pos": 57, "end_pos": 73, "type": "TASK", "confidence": 0.7128706574440002}, {"text": "discourse analysis of fora", "start_pos": 321, "end_pos": 347, "type": "TASK", "confidence": 0.8085660934448242}]}, {"text": "This paper proposes a method based on constraints using Integer Linear Programming decoding over local probability distributions to investigate both treelike and non-treelike, full discourse structures for multi-party dialogue.", "labels": [], "entities": []}, {"text": "We show that our method outperforms that of on the corpus they developed.", "labels": [], "entities": []}, {"text": "Discourse parsing involves at least three main steps: the segmentation of a text into elementary discourse units (EDUs), the basic building blocks for discourse structures, the attachment of EDUs together into connected structures for texts, and finally the labelling of the links between discourse units with discourse relations.", "labels": [], "entities": [{"text": "Discourse parsing", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.8326291143894196}]}, {"text": "Much current work in discourse parsing focuses on the labelling of discourse relations, using data from the Penn Discourse Treebank (PDTB) (.", "labels": [], "entities": [{"text": "discourse parsing", "start_pos": 21, "end_pos": 38, "type": "TASK", "confidence": 0.7025310844182968}, {"text": "Penn Discourse Treebank (PDTB)", "start_pos": 108, "end_pos": 138, "type": "DATASET", "confidence": 0.9555708368619283}]}, {"text": "This work has availed itself of increasingly sophisticated features of the semantics of the units to be related; but as the PDTB does not provide full discourse structures for texts, it is not relevant to our concerns here.", "labels": [], "entities": []}, {"text": "Rhetorical Structure Theory (RST) () does take into account the global structure of the document, and the RST Discourse Tree Bank has texts annotated according to RST with full discourse structures.", "labels": [], "entities": [{"text": "Rhetorical Structure Theory (RST)", "start_pos": 0, "end_pos": 33, "type": "TASK", "confidence": 0.8082852611939112}, {"text": "RST Discourse Tree Bank", "start_pos": 106, "end_pos": 129, "type": "DATASET", "confidence": 0.8183726519346237}]}, {"text": "This has guided most work in recent discourse parsing of multi-sentence text).", "labels": [], "entities": [{"text": "discourse parsing", "start_pos": 36, "end_pos": 53, "type": "TASK", "confidence": 0.716865599155426}]}, {"text": "But RST requires that discourse structures be projective trees.", "labels": [], "entities": [{"text": "RST", "start_pos": 4, "end_pos": 7, "type": "TASK", "confidence": 0.9808339476585388}]}, {"text": "While projective trees are arguably a contender for representing the discourse structure of monologue text, multi-party chat dialogues exhibit crossing dependencies.", "labels": [], "entities": []}, {"text": "This rules out using a theory like RST as a basis either for an annotation model or as a guide to learning discourse structure.", "labels": [], "entities": [{"text": "RST", "start_pos": 35, "end_pos": 38, "type": "TASK", "confidence": 0.9046651721000671}]}, {"text": "Several subgroups of interlocutors can momentarily form and carry on a discussion amongst themselves, forming thus multiple concurrent discussion threads.", "labels": [], "entities": []}, {"text": "Furthermore, participants of one thread may reply or comment to something said to another thread.", "labels": [], "entities": []}, {"text": "One might conclude from the presence of multiple threads in dialogue that we should use non-projective trees to guide discourse parsing.", "labels": [], "entities": [{"text": "discourse parsing", "start_pos": 118, "end_pos": 135, "type": "TASK", "confidence": 0.7457118034362793}]}, {"text": "But non-projective trees cannot always reflect the structure of a discourse either, as argue on theoretical grounds.", "labels": [], "entities": []}, {"text": "provide examples in which a question or a comment by speaker S that is addressed to all the engaged parties in the conversation receives an answer from all the other participants, all of which are then acknowledged by S with a simple OK or No worries, thus creating an intuitive, \"lozenge\" like structure, in which the acknowledgment has several incoming links representing discourse dependencies.", "labels": [], "entities": []}, {"text": "A final, important organizing element of the discourse structure for text and dialogue is the presence of clusters of EDUs that can act together as an argument to other discourse relations.", "labels": [], "entities": []}, {"text": "This means that subgraphs of the entire discourse graph act as elements or nodes in the full discourse structure.", "labels": [], "entities": []}, {"text": "These subgraphs are complex discourse units or CDUs.", "labels": [], "entities": []}, {"text": "Here is an example from the Settlers corpus: Thomas's response to gotwoodforsheep spans two turns in the corpus.", "labels": [], "entities": [{"text": "Settlers corpus", "start_pos": 28, "end_pos": 43, "type": "DATASET", "confidence": 0.8214326202869415}]}, {"text": "More interestingly, the response is a conditional \"yes\" in which EDUs (c) and (d) jointly specify the antecedent of the discourse relation that links both to the EDU I do.", "labels": [], "entities": []}, {"text": "CDUs have been claimed to bean important organizing principle of discourse structure and important for the analysis of anaphora and ellipsis for over 20 years).", "labels": [], "entities": [{"text": "CDUs", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.8157557249069214}]}, {"text": "Yet the computational community has ignored them; when they are present in annotated corpora, they have been eliminated.", "labels": [], "entities": []}, {"text": "This attitude is understandable, because CDUs, as they stand, are not representable as trees in any straightforward way.", "labels": [], "entities": []}, {"text": "But given that our method can produce non-treelike graphs, we take a first step towards the prediction of CDUs as part of discourse structure by encoding them in a hypergraph-like framework.", "labels": [], "entities": []}, {"text": "In particular, we will transform our corpus by distributing relations on CDUs overall their constituents as we describe in section 3.", "labels": [], "entities": []}, {"text": "Our paper is organized as follows.", "labels": [], "entities": []}, {"text": "The data that we have used are described in more detail in the following section, while the underlying linguistic theory that we are using is described in section 3.", "labels": [], "entities": []}, {"text": "In section 4 we present in detail the model that we have used, in particular the ILP decoder and the constraints and objective function it exploits.", "labels": [], "entities": [{"text": "ILP decoder", "start_pos": 81, "end_pos": 92, "type": "DATASET", "confidence": 0.8453324735164642}]}, {"text": "We report our results in section 5.", "labels": [], "entities": []}, {"text": "Section 6 provides the related work while section 7 concludes this paper.", "labels": [], "entities": []}], "datasetContent": [{"text": "Features for training the local model and getting scores for the decoders were extracted for every pair of EDUs.", "labels": [], "entities": []}, {"text": "Features concerned each EDU individually as well as the pair itself.", "labels": [], "entities": []}, {"text": "We used obvious, surface features such as: the position of EDUs in the dialogue, who their speakers are, whether two EDUs have the same speaker, the distance between EDUs, the presence of mood indicators ('?', '!')", "labels": [], "entities": []}, {"text": "in the EDU, lexical features of the EDU (e.g., does a verb signifying an exchange occur in the EDU), and first and last words of the EDU.", "labels": [], "entities": [{"text": "EDU", "start_pos": 7, "end_pos": 10, "type": "DATASET", "confidence": 0.9017755389213562}, {"text": "EDU", "start_pos": 133, "end_pos": 136, "type": "DATASET", "confidence": 0.9264096617698669}]}, {"text": "We also used the structures and Subject lemmas given by syntactic dependency parsing, provided by the Stanford CoreNLP pipeline ().", "labels": [], "entities": [{"text": "syntactic dependency parsing", "start_pos": 56, "end_pos": 84, "type": "TASK", "confidence": 0.6220978498458862}, {"text": "Stanford CoreNLP pipeline", "start_pos": 102, "end_pos": 127, "type": "DATASET", "confidence": 0.9263101816177368}]}, {"text": "Finally we used's method for classifying EDUs with respect to whether they involved an offer, a counteroffer, or were other.", "labels": [], "entities": []}, {"text": "As mentioned earlier, in addition to the ILP and MST decoders we used two baseline decoders, LAST and LOCAL.", "labels": [], "entities": [{"text": "MST decoders", "start_pos": 49, "end_pos": 61, "type": "DATASET", "confidence": 0.8444762229919434}, {"text": "LOCAL", "start_pos": 102, "end_pos": 107, "type": "METRIC", "confidence": 0.8959234952926636}]}, {"text": "The LAST decoder simply selects the previous EDU for attachment no matter what the underlying probability distribution is.", "labels": [], "entities": []}, {"text": "This has proved a very hard baseline to beat in discourse.", "labels": [], "entities": []}, {"text": "The LOCAL decoder is a naive decoder which in the case of attachment returns \"attached\" if the probability of attachment between EDUs i and j is higher than .5 and \"non-attached\" in the opposite case.", "labels": [], "entities": []}, {"text": "Each of the three distribution methods described in Section 3 (Head, Partial and Full Distribution) yielded different dependency graphs for our input documents, which formed three distinct corpora on which we trained and tested separately.", "labels": [], "entities": []}, {"text": "For each of them, our training set represented 90% of the dependency graphs from the initial corpus, chosen at random; the test set representing the remaining 10%.", "labels": [], "entities": []}, {"text": "shows our evaluation results, comparing decoders and baselines for each of the distribution strategies.", "labels": [], "entities": []}, {"text": "As can be seen, our ILP decoder consistently performs significantly better than the baselines as well as the MST decoder, which was the previous state of the art ( even when restricted to tree structures and HR (setting the hyper-parameter \u03b4 = 1).", "labels": [], "entities": [{"text": "MST decoder", "start_pos": 109, "end_pos": 120, "type": "DATASET", "confidence": 0.8167130351066589}]}, {"text": "This prompted us to investigate how our objective function compared to MST's.", "labels": [], "entities": []}, {"text": "We eliminated all constraints in ILP except acyclicity, connectedness, turn constraint and eliminating any constraint on outgoing edges (setting \u03b4 = \u221e); in this case, ILP's objective function performed better on the full structure prediction (.531 F1) than MST with attachment and labelling jointly maximized (.516 F1).", "labels": [], "entities": [{"text": "F1", "start_pos": 248, "end_pos": 250, "type": "METRIC", "confidence": 0.9824621677398682}, {"text": "F1", "start_pos": 315, "end_pos": 317, "type": "METRIC", "confidence": 0.9680609107017517}]}, {"text": "This means that our objective function, although it maximizes scores and not probabilities, produces an ordering over outputs that outperforms classic MST.", "labels": [], "entities": []}, {"text": "Our analysis showed further that the constraints on outgoing edges (the tuning of the hyperparameter e o = 6) were very important for our corpus and our (admittedly flawed) local model; in other words, an ILP constrained tree for this corpus was a better predictor of the data with our local model than an unrestrained MST tree decoding.", "labels": [], "entities": []}, {"text": "We also note that our scores dropped in distributive settings but that ILP performed considerably better than the alternatives and better than the previous state of the art on dependency trees using HR on the gold and MST decoding.", "labels": [], "entities": []}, {"text": "We need to investigate further constraints, and to refine and improve our features to get a better local model.", "labels": [], "entities": []}, {"text": "Our local model will eventually need to be replaced by one that takes into account more of the surrounding structure when it assigns scores to attachments and labels.", "labels": [], "entities": []}, {"text": "We also plan to investigate the use of recurrent neural networks in order to improve our local model.", "labels": [], "entities": []}], "tableCaptions": []}