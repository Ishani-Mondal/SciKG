{"title": [{"text": "Speed-Constrained Tuning for Statistical Machine Translation Using Bayesian Optimization", "labels": [], "entities": [{"text": "Statistical Machine Translation", "start_pos": 29, "end_pos": 60, "type": "TASK", "confidence": 0.8360337615013123}]}], "abstractContent": [{"text": "We address the problem of automatically finding the parameters of a statistical machine translation system that maximize BLEU scores while ensuring that decoding speed exceeds a minimum value.", "labels": [], "entities": [{"text": "statistical machine translation", "start_pos": 68, "end_pos": 99, "type": "TASK", "confidence": 0.6119299928347269}, {"text": "BLEU", "start_pos": 121, "end_pos": 125, "type": "METRIC", "confidence": 0.9920499920845032}]}, {"text": "We propose the use of Bayesian Optimization to efficiently tune the speed-related decoding parameters by easily incorporating speed as a noisy constraint function.", "labels": [], "entities": []}, {"text": "The obtained parameter values are guaranteed to satisfy the speed constraint with an associated confidence margin.", "labels": [], "entities": [{"text": "speed constraint", "start_pos": 60, "end_pos": 76, "type": "METRIC", "confidence": 0.9778245985507965}]}, {"text": "Across three language pairs and two speed constraint values , we report overall optimization time reduction compared to grid and random search.", "labels": [], "entities": []}, {"text": "We also show that Bayesian Optimization can decouple speed and BLEU measurements, resulting in a further reduction of overall optimization time as speed is measured over a small subset of sentences.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 63, "end_pos": 67, "type": "METRIC", "confidence": 0.9968337416648865}]}], "introductionContent": [{"text": "Research in Statistical Machine Translation (SMT) aims to improve translation quality, typically measured by BLEU scores (), over a baseline system.", "labels": [], "entities": [{"text": "Statistical Machine Translation (SMT)", "start_pos": 12, "end_pos": 49, "type": "TASK", "confidence": 0.8030186494191488}, {"text": "BLEU", "start_pos": 109, "end_pos": 113, "type": "METRIC", "confidence": 0.9986269474029541}]}, {"text": "Given a task defined by a language pair and its corpora, the quality of a system is assessed by contrasting choices made in rule/phrase extraction criteria, feature functions, decoding algorithms and parameter optimization techniques.", "labels": [], "entities": [{"text": "rule/phrase extraction criteria", "start_pos": 124, "end_pos": 155, "type": "TASK", "confidence": 0.7131268620491028}]}, {"text": "Some of these choices result in systems with significant differences in performance.", "labels": [], "entities": []}, {"text": "For example, in phrase-based translation (PBMT) (Koehn et al., * This work was done during an internship of the first author at SDL Research, 2003), decoder parameters such as pruning thresholds and reordering constraints can have a dramatic impact on both BLEU and decoding speed.", "labels": [], "entities": [{"text": "phrase-based translation (PBMT)", "start_pos": 16, "end_pos": 47, "type": "TASK", "confidence": 0.8327191233634949}, {"text": "BLEU", "start_pos": 257, "end_pos": 261, "type": "METRIC", "confidence": 0.9935702085494995}]}, {"text": "However, unlike feature weights, which can be optimized by MERT (), it is difficult to optimize decoder parameters either for speed or for BLEU.", "labels": [], "entities": [{"text": "MERT", "start_pos": 59, "end_pos": 63, "type": "METRIC", "confidence": 0.8972532153129578}, {"text": "BLEU", "start_pos": 139, "end_pos": 143, "type": "METRIC", "confidence": 0.9920795559883118}]}, {"text": "We are interested in the problem of automatically finding the decoder parameters and feature weights that yield the best BLEU at a specified minimum decoding speed.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 121, "end_pos": 125, "type": "METRIC", "confidence": 0.9968882203102112}]}, {"text": "This is potentially very expensive because each change in a decoder parameter requires re-decoding to assess both BLEU and translation speed.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 114, "end_pos": 118, "type": "METRIC", "confidence": 0.9978043437004089}]}, {"text": "This is under-studied in the literature, despite its importance for real-life commercial SMT engines whose speed and latency can be as significant for user satisfaction as overall translation quality.", "labels": [], "entities": [{"text": "SMT", "start_pos": 89, "end_pos": 92, "type": "TASK", "confidence": 0.9851630330085754}]}, {"text": "We propose to use Bayesian Optimization () for this constrained optimization task.", "labels": [], "entities": []}, {"text": "By using prior knowledge of the function to be optimized and by exploring the most uncertain and the most promising regions of the parameter space, Bayesian Optimization (BO) is able to quickly find optimal parameter values.", "labels": [], "entities": []}, {"text": "It is particularly well-suited to optimize expensive and non-differentiable functions such as the BLEU score of a decoder on a tuning set.", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 98, "end_pos": 108, "type": "METRIC", "confidence": 0.9847511053085327}]}, {"text": "The BO framework can also incorporate noisy constraints, such as decoder speed measurements, yielding parameters that satisfy these constraints with quantifiable confidence values.", "labels": [], "entities": []}, {"text": "For a set of fixed feature weights, we use BO to optimize phrase-based decoder parameters for speed and BLEU.", "labels": [], "entities": [{"text": "BO", "start_pos": 43, "end_pos": 45, "type": "METRIC", "confidence": 0.9961811304092407}, {"text": "speed", "start_pos": 94, "end_pos": 99, "type": "METRIC", "confidence": 0.9850045442581177}, {"text": "BLEU", "start_pos": 104, "end_pos": 108, "type": "METRIC", "confidence": 0.997785210609436}]}, {"text": "We show across 3 different language pairs that BO can find fast configurations with high BLEU scores much more efficiently than other tuning techniques such as grid or random search.", "labels": [], "entities": [{"text": "BO", "start_pos": 47, "end_pos": 49, "type": "METRIC", "confidence": 0.868368923664093}, {"text": "BLEU", "start_pos": 89, "end_pos": 93, "type": "METRIC", "confidence": 0.9983435869216919}]}, {"text": "We also show that BLEU and decoding speed can be treated as decoupled measurements by BO.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 18, "end_pos": 22, "type": "METRIC", "confidence": 0.9987911581993103}, {"text": "BO", "start_pos": 86, "end_pos": 88, "type": "METRIC", "confidence": 0.9935359954833984}]}, {"text": "This results in a further reduction of overall optimization time, since speed can be measured over a smaller set of sentences than is needed for BLEU.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 145, "end_pos": 149, "type": "METRIC", "confidence": 0.9135711193084717}]}, {"text": "Finally, we discuss the effects of feature weights reoptimization after speed tuning, where we show that further improvements in BLEU can be obtained.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 129, "end_pos": 133, "type": "METRIC", "confidence": 0.998046875}]}, {"text": "Although our analysis is done on a phrase-based system with standard decoder parameters (decoding stack size, distortion limit, and maximum number of translations per source phrase), BO could be applied to other decoding paradigms and parameters.", "labels": [], "entities": [{"text": "BO", "start_pos": 183, "end_pos": 185, "type": "METRIC", "confidence": 0.9816805124282837}]}, {"text": "The paper is organized as follows.", "labels": [], "entities": []}, {"text": "Section 2 gives a brief overview of Bayesian Optimization and describes how it can be applied to our problem, Section 3 reports our speed-constrained tuning experiments, Section 4 reviews related work, and Section 5 concludes.", "labels": [], "entities": [{"text": "Bayesian Optimization", "start_pos": 36, "end_pos": 57, "type": "TASK", "confidence": 0.6786261796951294}]}], "datasetContent": [{"text": "We report translation results in three language pairs, chosen for the different challenges they pose for SMT systems: Spanish-to-English, English-toGerman and Chinese-to-English.", "labels": [], "entities": [{"text": "SMT", "start_pos": 105, "end_pos": 108, "type": "TASK", "confidence": 0.9889246821403503}]}, {"text": "For each language pair, we use generic parallel data extracted from the web.", "labels": [], "entities": []}, {"text": "The data sizes are 1.7, 1.1 and 0.3 billion words, respectively.", "labels": [], "entities": []}, {"text": "For Spanish-to-English and English-to-German we use mixed-domain tuning/test sets, which have about 1K sentences each and were created to evenly represent different domains, including world news, health, sport, science and others.", "labels": [], "entities": []}, {"text": "For Chinese-toEnglish we use in-domain sets (2K sentences) created by randomly extracting unique parallel sentences from in-house parallel text collections; this in-domain data leads to higher BLEU scores than in the other tasks, as will be reported later.", "labels": [], "entities": [{"text": "BLEU scores", "start_pos": 193, "end_pos": 204, "type": "METRIC", "confidence": 0.9792313575744629}]}, {"text": "In all cases we have one reference translation.", "labels": [], "entities": []}, {"text": "We use an in-house implementation of a phrase-based decoder with lexicalized reordering model (.", "labels": [], "entities": []}, {"text": "The system uses 21 features, whose weights are optimized for BLEU via MERT () at very slow decoder parameter settings in order to minimize search errors in tuning.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 61, "end_pos": 65, "type": "METRIC", "confidence": 0.9945414662361145}, {"text": "MERT", "start_pos": 70, "end_pos": 74, "type": "METRIC", "confidence": 0.9788472056388855}]}, {"text": "The feature weights remain fixed during the speed tuning process.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Speed means and standard deviations in words per", "labels": [], "entities": [{"text": "Speed means", "start_pos": 10, "end_pos": 21, "type": "METRIC", "confidence": 0.9741349220275879}]}, {"text": " Table 2: Results obtained after reaching the full evaluation bud-", "labels": [], "entities": []}, {"text": " Table 3: Results obtained after reaching the full evaluation bud-", "labels": [], "entities": []}, {"text": " Table 4: Chinese-to-English results of re-running MERT using", "labels": [], "entities": [{"text": "MERT", "start_pos": 51, "end_pos": 55, "type": "TASK", "confidence": 0.5760796666145325}]}]}