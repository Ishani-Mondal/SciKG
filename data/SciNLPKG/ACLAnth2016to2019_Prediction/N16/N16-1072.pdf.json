{"title": [], "abstractContent": [{"text": "Cross-lingual Wikification is the task of grounding mentions written in non-English documents to entries in the English Wikipedia.", "labels": [], "entities": []}, {"text": "This task involves the problem of comparing textual clues across languages, which requires developing a notion of similarity between text snippets across languages.", "labels": [], "entities": []}, {"text": "In this paper, we address this problem by jointly training multilingual embeddings for words and Wikipedia titles.", "labels": [], "entities": []}, {"text": "The proposed method can be applied to all languages represented in Wikipedia, including those for which no machine translation technology is available.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 107, "end_pos": 126, "type": "TASK", "confidence": 0.7650142014026642}]}, {"text": "We create a challenging dataset in 12 languages and show that our proposed approach outperforms various baselines.", "labels": [], "entities": []}, {"text": "Moreover, our model compares favorably with the best systems on the TAC KBP2015 Entity Linking task including those that relied on the availability of translation from the target language to English.", "labels": [], "entities": [{"text": "TAC KBP2015 Entity Linking task", "start_pos": 68, "end_pos": 99, "type": "TASK", "confidence": 0.7699505686759949}]}], "introductionContent": [{"text": "Wikipedia has become an indispensable resource in knowledge acquisition and text understanding for both human beings and computers.", "labels": [], "entities": [{"text": "knowledge acquisition", "start_pos": 50, "end_pos": 71, "type": "TASK", "confidence": 0.7203827649354935}, {"text": "text understanding", "start_pos": 76, "end_pos": 94, "type": "TASK", "confidence": 0.7735222578048706}]}, {"text": "The task of Wikification or Entity Linking aims at disambiguating mentions (sub-strings) in text to the corresponding titles (entries) in Wikipedia or other Knowledge Bases, such as FreeBase.", "labels": [], "entities": [{"text": "Entity Linking", "start_pos": 28, "end_pos": 42, "type": "TASK", "confidence": 0.6657989025115967}]}, {"text": "For English text, this problem has been studied extensively (.", "labels": [], "entities": []}, {"text": "It also has been shown to be a valuable component of several natural language processing and information extraction tasks across different domains.", "labels": [], "entities": [{"text": "natural language processing and information extraction", "start_pos": 61, "end_pos": 115, "type": "TASK", "confidence": 0.6543786724408468}]}, {"text": "Recently, there has also been interest in the crosslingual setting of Wikification: given a mention from a document written in a foreign language, the goal is to find the corresponding title in the English Wikipedia.", "labels": [], "entities": []}, {"text": "This task is driven partly by the fact that a lot of information around the world maybe written in a foreign language for which there are limited linguistic resources and, specifically, no English translation technology.", "labels": [], "entities": [{"text": "English translation", "start_pos": 189, "end_pos": 208, "type": "TASK", "confidence": 0.7166073620319366}]}, {"text": "Instead of translating the whole document to English, grounding the important entity mentions in the English Wikipedia maybe a good solution that could better capture the key message of the text, especially if it can be reliably achieved with fewer resources than those needed to develop a translation system.", "labels": [], "entities": []}, {"text": "This task is mainly driven by the Text Analysis Conference (TAC) Knowledge Base Population (KBP) Entity Linking Tracks (, where the target languages are In this paper, we develop a general technique which can be applied to all languages in Wikipedia even when no machine translation technology is available for them.", "labels": [], "entities": [{"text": "Text Analysis Conference (TAC) Knowledge Base Population (KBP) Entity Linking", "start_pos": 34, "end_pos": 111, "type": "TASK", "confidence": 0.7744705293859754}]}, {"text": "The challenges in Wikification are due both to ambiguity and variability in expressing entities and concepts: a given mention in text, e.g., Chicago, may refer to different titles in Wikipedia (Chicago Bulls, the City, Chicago Bears, the band, etc.), and a title can be expressed in the text in multiple ways, such as synonyms and nicknames.", "labels": [], "entities": []}, {"text": "These challenges are usually resolved by calculating some similarity between the representation of the mention and candidate titles.", "labels": [], "entities": []}, {"text": "For instance, the mention could be represented using its neighboring words, whereas a ti-589 tle is usually represented by the words and entities in the document which introduces the title.", "labels": [], "entities": []}, {"text": "In the cross-lingual setting, an additional challenge arises from the need to match words in a foreign language to an English title.", "labels": [], "entities": []}, {"text": "In this paper, we address this problem by using multilingual title and word embeddings.", "labels": [], "entities": []}, {"text": "We represent words and Wikipedia titles in both the foreign language and in English in the same continuous vector space, which allows us to compute meaningful similarity between mentions in the foreign language and titles in English.", "labels": [], "entities": []}, {"text": "We show that learning these embeddings only requires Wikipedia documents and language links between the titles across different languages, which are quite common in Wikipedia.", "labels": [], "entities": []}, {"text": "Therefore, we can learn embeddings for all languages in Wikipedia without any additional annotation or supervision.", "labels": [], "entities": []}, {"text": "Another notable challenge for the cross-lingual setting that we do not address in this paper is that of generating English candidate titles given a foreign mention when there is no corresponding title in the foreign language Wikipedia.", "labels": [], "entities": []}, {"text": "If a title exists in both the English and the foreign language Wikipedia, there could be examples of using this title in the foreign language Wikipedia text, and this information could help us determine the possible English titles.", "labels": [], "entities": []}, {"text": "For example, Vladimir N. Vapnik exists in both the English Wikipedia (en/Vladimir Vapnik) 1 and the Chinese Wikipedia (zh/\u232b\u2026\u02d9s\u00b7\u2325n< K).", "labels": [], "entities": [{"text": "English Wikipedia (en/Vladimir Vapnik) 1", "start_pos": 51, "end_pos": 91, "type": "DATASET", "confidence": 0.8273206022050645}]}, {"text": "In the Chinese Wikipedia, we may seethe use of the mention ,n<K as a reference, that is, ,n< K is linked to the title zh/\u232b\u2026\u02d9s\u00b7\u2325n<K.", "labels": [], "entities": []}, {"text": "Following the inter-language links in Wikipedia, we can reach the English title en/Vladimir Vapnik.", "labels": [], "entities": []}, {"text": "On the other hand, Dan Roth does not have a page in the Chinese Wikipedia, it would have been harder to get to en/Dan Roth from the Chinese mention.", "labels": [], "entities": []}, {"text": "In this case, a transliteration model maybe needed.", "labels": [], "entities": []}, {"text": "Note that the difference between these two cases is only in generating English title candidates from the given foreign mention.", "labels": [], "entities": []}, {"text": "The disambiguation method which identifies the most probable title is conceptually the same, so our method could generalize as is to this case.", "labels": [], "entities": []}, {"text": "For evaluation purposes, we focus in this paper on mentions that have corresponding titles in both the English and the foreign language Wikipedia, and concentrate on disambiguating titles across languages.", "labels": [], "entities": []}, {"text": "This allows us to evaluate on a large number of Wikipedia documents.", "labels": [], "entities": []}, {"text": "Note that under this setting, a natural approach is to do wikification on the foreign language and then follow the language links to obtain the corresponding English titles.", "labels": [], "entities": []}, {"text": "However, this approach requires developing a separate wikifier for each foreign language if it uses languagespecific features, while our approach is generic and only requires using the appropriate embeddings.", "labels": [], "entities": []}, {"text": "Importantly, the aforementioned approach will also not generalize to the cases where the target titles only exist in the English Wikipedia while ours does.", "labels": [], "entities": []}, {"text": "We create a challenging Wikipedia dataset for 12 foreign languages and show that the proposed approach, WikiME (Wikification using Multilingual Embeddings), consistently outperforms various baselines.", "labels": [], "entities": [{"text": "Wikipedia dataset", "start_pos": 24, "end_pos": 41, "type": "DATASET", "confidence": 0.8894712924957275}]}, {"text": "Moreover, the results on the TAC KBP2015 Entity Linking dataset show that our approach compares favorably with the best Spanish system and the best Chinese system despite using significantly weaker resources (no need for translation).", "labels": [], "entities": [{"text": "TAC KBP2015 Entity Linking dataset", "start_pos": 29, "end_pos": 63, "type": "DATASET", "confidence": 0.8169895887374878}]}, {"text": "We note that the need for translation would have prevented the wikification of 12 languages used in this paper.", "labels": [], "entities": []}], "datasetContent": [{"text": "We evaluate the proposed method on the Wikipedia dataset of 12 langugaes and the TAC'15 Entity Linking dataset.", "labels": [], "entities": [{"text": "Wikipedia dataset of 12 langugaes", "start_pos": 39, "end_pos": 72, "type": "DATASET", "confidence": 0.9662479639053345}, {"text": "TAC'15 Entity Linking dataset", "start_pos": 81, "end_pos": 110, "type": "DATASET", "confidence": 0.8181350380182266}]}, {"text": "For all experiments, we use the Word2Vec implementation in Gensim 2 to learn the skip-gram model with dimensionality 500 for each language.", "labels": [], "entities": []}, {"text": "The CCA code for projecting mono-lingual embeddings is from in which the ratio parameter is set to 0.5 (i.e., the resulting multilingual embeddings have dimensionality 250).", "labels": [], "entities": []}, {"text": "We  tokenization is based on whitespaces.", "labels": [], "entities": [{"text": "We  tokenization", "start_pos": 0, "end_pos": 16, "type": "TASK", "confidence": 0.5575670003890991}]}, {"text": "The number of tokens we use to learn the skip-gram model and the number of title alignments used by the CCA are given in.", "labels": [], "entities": []}, {"text": "For learning the weights in Eq., we use the implementation of linear ranking SVM in.", "labels": [], "entities": []}, {"text": "Parameter selection and feature engineering are done by conducting cross-validation on the training data of Spanish Wikipedia dataset.", "labels": [], "entities": [{"text": "Parameter selection", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.7383726388216019}, {"text": "feature engineering", "start_pos": 24, "end_pos": 43, "type": "TASK", "confidence": 0.7568082213401794}, {"text": "Spanish Wikipedia dataset", "start_pos": 108, "end_pos": 133, "type": "DATASET", "confidence": 0.8997817238171896}]}, {"text": "We create this dataset from the documents in Wikipedia by taking the anchors (hyperlinked texts) as the query mentions and the corresponding English Wikipedia titles as the answers.", "labels": [], "entities": []}, {"text": "Note that we only keep the mentions for which we can get the corresponding English Wikipedia titles by the language links.", "labels": [], "entities": []}, {"text": "As observed in previous work), most of the mentions in Wikipedia documents are easy, that is, the baseline of simply choosing the title that maximizes P r(title|mention), the most frequent title given the mention surface string, performs quite well.", "labels": [], "entities": []}, {"text": "In order to create a more challenging dataset, we randomly select mentions such that the number of easy mentions is about twice the number of hard mentions (those mentions for which the most common title is not the correct title  test documents, many mentions and titles actually overlap.", "labels": [], "entities": []}, {"text": "To test that the algorithms really generalize from training examples, we ensure that no (mention, title) pair in the test set appear in the training set.", "labels": [], "entities": []}, {"text": "shows the number of training mentions, test mentions, and hard mentions in the test set of each language.", "labels": [], "entities": []}, {"text": "This dataset is publicly available at http://bilbo.cs.illinois.edu/ \u02dc ctsai12/xlwikifier-wikidata.zip.", "labels": [], "entities": []}, {"text": "The performance of the proposed method (WikiME) is shown in along with the following approaches: MonoEmb: In this method, we use the monolingual embeddings before applying CCA while all the other settings are the same as in WikiME.", "labels": [], "entities": []}, {"text": "Since the monolingual embeddings are learnt separately for each language, calculating the cosine similarity of the word embedding in the foreign language and an English title embedding does not produce a good similarity function.", "labels": [], "entities": []}, {"text": "The ranker, though, learns that the most important feature is P r(title|mention), and, consequently, performs well on easy mentions but has poor performance on hard mentions.", "labels": [], "entities": []}, {"text": "WordAlign: Instead of using the aligned Wikipedia titles in generating multilingual embeddings, the CCA model operates on the word alignments as originally proposed in.", "labels": [], "entities": [{"text": "WordAlign", "start_pos": 0, "end_pos": 9, "type": "DATASET", "confidence": 0.9635677337646484}]}, {"text": "We use the word alignments provided by, which are obtained  we pick the most common title given the mention.", "labels": [], "entities": []}, {"text": "Bold signifies highest score for each column. from the parallel news commentary corpora combined with the Europarl corpus for English to German, France, and Spanish.", "labels": [], "entities": [{"text": "Europarl corpus", "start_pos": 106, "end_pos": 121, "type": "DATASET", "confidence": 0.9886857867240906}]}, {"text": "The number of aligned words for German, France, and Spanish are 37,484, 37,582, and 37,554 respectively.", "labels": [], "entities": []}, {"text": "WikiME performs statistically significantly better than WordAlign on all three languages.", "labels": [], "entities": [{"text": "WordAlign", "start_pos": 56, "end_pos": 65, "type": "DATASET", "confidence": 0.9499331712722778}]}, {"text": "EsWikifier: We use Illinois Wikifier) on a Spanish Wikipedia dump and train its ranker on the same set of documents that are used in WikiME.", "labels": [], "entities": []}, {"text": "Ceiling: These rows show the performance of title candidate generation.", "labels": [], "entities": []}, {"text": "That is, the numbers indicate the percentage of mentions that have the gold title in its candidate set, therefore upper-bounds the ranking performance.", "labels": [], "entities": []}, {"text": "In sum, WikiME can disambiguate the hard mentions much better than other methods without sacrificing the performance on the easy mentions much.", "labels": [], "entities": []}, {"text": "Comparing across different languages, it is important to note that languages which have a smaller size Wikipedia tend to have better performance, despite the degradation in the quality of the embeddings (see below).", "labels": [], "entities": []}, {"text": "This is due to the difficulty of the datasets.", "labels": [], "entities": []}, {"text": "That is, there is less ambiguity because the number of articles in the corresponding Wikipedia is small.", "labels": [], "entities": [{"text": "ambiguity", "start_pos": 23, "end_pos": 32, "type": "METRIC", "confidence": 0.9756121635437012}]}, {"text": "shows the feature ablation study of WikiME.", "labels": [], "entities": [{"text": "WikiME", "start_pos": 36, "end_pos": 42, "type": "DATASET", "confidence": 0.9320687055587769}]}, {"text": "For each language, we show results on hard mentions (the left bar) and all mentions (the right bar).", "labels": [], "entities": []}, {"text": "We do not show the performance on easy mentions since it always stays high and does not change much.", "labels": [], "entities": []}, {"text": "We can see that Local Context and Other Mentions are very effective for most of the languages.", "labels": [], "entities": []}, {"text": "In particular, on hard mentions, the performance gain of the three feature groups is from almost 0 to around 50.", "labels": [], "entities": []}, {"text": "For the easier dataset such as Urdu, Basic features alone work quite well.", "labels": [], "entities": []}, {"text": "shows the performance of WikiME when we vary the number of aligned titles in generating multilingual embeddings.", "labels": [], "entities": []}, {"text": "The performance drops a lot when there are only few aligned titles, especially for Spanish and French, where the results are even worse than MonoEmb when only 2000 titles are aligned.", "labels": [], "entities": []}, {"text": "This indicates that the CCA method needs enough aligned pairs in order to produce good embeddings.", "labels": [], "entities": []}, {"text": "The performance does not change much when there are more than 16,000 aligned titles.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1. We train a linear ranking SVM model  with the proposed features to obtain the weights, w i ,  in Eq. (1). Finally, the title which has the highest  relevant score is chosen as the answer to m.", "labels": [], "entities": []}, {"text": " Table 2. For learning the weights in Eq.", "labels": [], "entities": [{"text": "Eq", "start_pos": 38, "end_pos": 40, "type": "DATASET", "confidence": 0.9162110090255737}]}, {"text": " Table 3: The number of training and test mentions of the", "labels": [], "entities": []}, {"text": " Table 4: Ranking performance (Precision@1) of different ap-", "labels": [], "entities": [{"text": "Precision@1)", "start_pos": 31, "end_pos": 43, "type": "METRIC", "confidence": 0.9522082507610321}]}, {"text": " Table 5: TAC KBP2015 Entity Linking dataset. All results use", "labels": [], "entities": [{"text": "TAC KBP2015 Entity Linking dataset", "start_pos": 10, "end_pos": 44, "type": "DATASET", "confidence": 0.7894008874893188}]}]}