{"title": [{"text": "Using Related Languages to Enhance Statistical Language Models", "labels": [], "entities": []}], "abstractContent": [{"text": "The success of many language modeling methods and applications relies heavily on the amount of data available.", "labels": [], "entities": []}, {"text": "This problem is further exacerbated in statistical machine translation , where parallel data in the source and target languages is required.", "labels": [], "entities": [{"text": "statistical machine translation", "start_pos": 39, "end_pos": 70, "type": "TASK", "confidence": 0.6741306881109873}]}, {"text": "However, large amounts of data are only available fora small number of languages; as a result, many language modeling techniques are inadequate for the vast majority of languages.", "labels": [], "entities": [{"text": "language modeling", "start_pos": 100, "end_pos": 117, "type": "TASK", "confidence": 0.7328436970710754}]}, {"text": "In this paper, we attempt to lessen the problem of alack of training data for low-resource languages by adding data from related high-resource languages in three experiments.", "labels": [], "entities": []}, {"text": "First, we interpolate language models trained on the target language and on the related language.", "labels": [], "entities": []}, {"text": "In our second experiment, we select the sentences most similar to the target language and add them to our training corpus.", "labels": [], "entities": []}, {"text": "Finally, we integrate data from the related language into a translation model fora statistical machine translation application.", "labels": [], "entities": [{"text": "statistical machine translation", "start_pos": 83, "end_pos": 114, "type": "TASK", "confidence": 0.6175077160199484}]}, {"text": "Although we do not see many significant improvements over baselines trained on a small amount of data in the target language , we discuss some further experiments that could be attempted in order to augment language models and translation models with data from related languages.", "labels": [], "entities": []}], "introductionContent": [{"text": "Statistical language modeling methods are an essential part of many language processing applications, including automatic speech recognition, machine translation (, and information retrieval ().", "labels": [], "entities": [{"text": "Statistical language modeling", "start_pos": 0, "end_pos": 29, "type": "TASK", "confidence": 0.7726036906242371}, {"text": "automatic speech recognition", "start_pos": 112, "end_pos": 140, "type": "TASK", "confidence": 0.6503413021564484}, {"text": "machine translation", "start_pos": 142, "end_pos": 161, "type": "TASK", "confidence": 0.8228164911270142}, {"text": "information retrieval", "start_pos": 169, "end_pos": 190, "type": "TASK", "confidence": 0.815688967704773}]}, {"text": "However, their success is heavily dependent on the availability of suitably large text resources for training.", "labels": [], "entities": []}, {"text": "Such data can be hard to obtain, especially for low-resource languages.", "labels": [], "entities": []}, {"text": "This problem is especially acute when language modeling is used in statistical machine translation, where alack of parallel resources fora language pair can be a significant detriment to quality.", "labels": [], "entities": [{"text": "language modeling", "start_pos": 38, "end_pos": 55, "type": "TASK", "confidence": 0.7212212085723877}, {"text": "statistical machine translation", "start_pos": 67, "end_pos": 98, "type": "TASK", "confidence": 0.660782148440679}]}, {"text": "Our goal is to exploit a high-resource language to improve modeling of a related low-resource language, which is applicable to cases where the target language is closely related to a language with a large amount of text data available.", "labels": [], "entities": []}, {"text": "For example, languages that are not represented in the European Parliament, such as Catalan, can be aided by related languages that are, such as Spanish.", "labels": [], "entities": []}, {"text": "The data available from the related high-resource language can be adapted in order to add to the translation model or the language model of the target language.", "labels": [], "entities": []}, {"text": "This paper is an initial attempt at using minimally transformed data from a related language to enhance language models and increase parallel data for SMT.", "labels": [], "entities": [{"text": "SMT", "start_pos": 151, "end_pos": 154, "type": "TASK", "confidence": 0.9947054982185364}]}], "datasetContent": [{"text": "Our first experiment attempted to use language models trained on the transliterated data to increase the coverage of a language model based on Spanish data; this was modeled after.", "labels": [], "entities": []}, {"text": "The language models in this experiment were trigram models with Good-Turing smoothing built using SRILM).", "labels": [], "entities": [{"text": "SRILM", "start_pos": 98, "end_pos": 103, "type": "DATASET", "confidence": 0.7735809087753296}]}, {"text": "As baselines, we trained Spanish (es) LMs on a small amount (30K sentences) and a large amount (1.5M sentences) of data.", "labels": [], "entities": []}, {"text": "We also trained language models based on 30K transliterated and standard Italian (it) and Portuguese (pt) sentences.", "labels": [], "entities": []}, {"text": "All were tested on the Spanish test set.", "labels": [], "entities": [{"text": "Spanish test set", "start_pos": 23, "end_pos": 39, "type": "DATASET", "confidence": 0.9786249995231628}]}, {"text": "shows the perplexity for each of the baselines.", "labels": [], "entities": []}, {"text": "As expected, more Spanish training data led to a lower perplexity.", "labels": [], "entities": []}, {"text": "However, the transliterated Italian and Portuguese baselines yielded better perplexity with less data.", "labels": [], "entities": []}, {"text": "Note also the strong effect of transliteration.", "labels": [], "entities": []}, {"text": "In the experiment, we interpolated LMs trained on different amounts of transliterated data with the LM trained on 30K Spanish sentences.", "labels": [], "entities": []}, {"text": "We used SRILM's compute-best-mix tool to determine the interpolation weights of the models.", "labels": [], "entities": [{"text": "SRILM", "start_pos": 8, "end_pos": 13, "type": "DATASET", "confidence": 0.8082535862922668}]}, {"text": "This parameter was trained on the Spanish development set.", "labels": [], "entities": [{"text": "Spanish development set", "start_pos": 34, "end_pos": 57, "type": "DATASET", "confidence": 0.9297695954640707}]}, {"text": "shows the results for the interpolation of the Spanish LM with Italian and Portuguese, both separately and simultaneously.", "labels": [], "entities": [{"text": "Spanish LM", "start_pos": 47, "end_pos": 57, "type": "DATASET", "confidence": 0.8448516130447388}]}, {"text": "The lambda values are the weights given to each of the language models.", "labels": [], "entities": []}, {"text": "None of the interpolated combinations improves on the perplexity of the smallest Spanish baseline.", "labels": [], "entities": []}, {"text": "The best results for interpolated language models are achieved when combining the 30K-sentence Spanish model with the 1.5M-sentence Portuguese model, which almost reaches the perplexity level of the Spanish-only model.", "labels": [], "entities": []}, {"text": "As a comparison, we also interpolated two separate language models, each trained on 30K Spanish sentences; the weight for these models was close to 0.5.", "labels": [], "entities": []}, {"text": "In the best-performing language model mix that used all three languages, Portuguese was weighted with a lambda of about 0.17, whereas Italian was only weighted with 0.016.", "labels": [], "entities": []}, {"text": "That shows that Portuguese, in this setup, is a better model of Spanish.", "labels": [], "entities": []}, {"text": "An open question has to do with the performance of the Portuguese language model in the experiment compared to the baselines.", "labels": [], "entities": []}, {"text": "In, we see that the language model does significantly worse when trained on more Portuguese data.", "labels": [], "entities": []}, {"text": "However, the interpolation of the Spanish and Portuguese language models yields a lower perplexity when trained on a large amount of Portuguese data.", "labels": [], "entities": []}, {"text": "Since the data was identical in the baselines and experiments, further exploration is needed to understand this behavior.", "labels": [], "entities": []}, {"text": "For our second experiment, our goal was to select the most \"Spanish-like\" data from our Italian and Portuguese corpora.", "labels": [], "entities": []}, {"text": "We concatenated this data with the Spanish sentences in order to increase the amount of training data for the language model.", "labels": [], "entities": []}, {"text": "This is similar to what was done by.", "labels": [], "entities": []}, {"text": "First, we trained a language model on our small Spanish corpus.", "labels": [], "entities": []}, {"text": "This language model was then queried on a concatenation of the transliterated Italian and Portuguese data.", "labels": [], "entities": []}, {"text": "The sentences in this corpus were ranked according to their perplexity in the Spanish LM.", "labels": [], "entities": [{"text": "Spanish LM", "start_pos": 78, "end_pos": 88, "type": "DATASET", "confidence": 0.9625043272972107}]}, {"text": "We selected the best 30K and 5K sentences, which were then concatenated with the Spanish data to form a larger corpus.", "labels": [], "entities": []}, {"text": "Finally, we used to create a trigram language model with Kneser-Ney smoothing on that data.", "labels": [], "entities": []}, {"text": "We also ran the same experiment on Italian and Portuguese separately.", "labels": [], "entities": []}, {"text": "gives the results from these experiments.", "labels": [], "entities": []}, {"text": "This table shows that the mixed-language models for each language performed better when they had a lower amount of non-Spanish data.", "labels": [], "entities": []}, {"text": "This indicates that it is better to simply use a small amount of data in the low-resource language, rather than trying to augment it with the transliterated data from related languages.", "labels": [], "entities": []}, {"text": "Using a smaller amount of the Spanish data, having a different strategy for selecting the non-Spanish data, using a different transliteration method, or using Italian and Portuguese data that was not a direct translation of the Spanish data may have all led to improvements.", "labels": [], "entities": []}, {"text": "It is also interesting to note that the language models based on the corpus containing only Portuguese performed almost as well as those based on the corpus containing Portuguese and Italian.", "labels": [], "entities": []}, {"text": "This indicates that the Portuguese data likely had more Spanish-like sentences than the Italian data.", "labels": [], "entities": [{"text": "Portuguese data", "start_pos": 24, "end_pos": 39, "type": "DATASET", "confidence": 0.733891099691391}]}, {"text": "As mentioned in section 3.1, Portuguese is more similar to Spanish, so this makes intuitive sense.", "labels": [], "entities": []}, {"text": "However, it is surprising given the results in table 4, which shows that the Italian-only language models performed better on Spanish data than the Portuguese-only language models.", "labels": [], "entities": []}, {"text": "Lastly, we experimented with translation models in order to see if our approach yielded similar results.", "labels": [], "entities": [{"text": "translation", "start_pos": 29, "end_pos": 40, "type": "TASK", "confidence": 0.967391848564148}]}, {"text": "For our baseline, we used a small parallel corpus of 30K English-Spanish (en-es) sentences from the Europarl corpus ().", "labels": [], "entities": [{"text": "Europarl corpus", "start_pos": 100, "end_pos": 115, "type": "DATASET", "confidence": 0.9883421957492828}]}, {"text": "The data was preprocessed as described in section 3.2.", "labels": [], "entities": []}, {"text": "Since SMT systems are often trained on large amounts of data, we expected poor coverage with this dataset.", "labels": [], "entities": [{"text": "SMT", "start_pos": 6, "end_pos": 9, "type": "TASK", "confidence": 0.9920849204063416}, {"text": "coverage", "start_pos": 79, "end_pos": 87, "type": "METRIC", "confidence": 0.9707659482955933}]}, {"text": "However, this size would be representative of the amount of data available for low-resource languages.", "labels": [], "entities": []}, {"text": "We used Moses ( ) to train our phrase-based SMT system on the above mentioned parallel corpus (en-es).", "labels": [], "entities": [{"text": "SMT", "start_pos": 44, "end_pos": 47, "type": "TASK", "confidence": 0.8984646797180176}]}, {"text": "We also trained a language model of 5M words of Spanish data from the same source, making sure that this data was strictly distinct from our parallel data.", "labels": [], "entities": []}, {"text": "The language model was trained using KenLM   weights were set by optimizing BLEU using MERT on a separate development set of 2,000 sentences (English-Spanish).", "labels": [], "entities": [{"text": "BLEU", "start_pos": 76, "end_pos": 80, "type": "METRIC", "confidence": 0.9967082738876343}, {"text": "MERT", "start_pos": 87, "end_pos": 91, "type": "METRIC", "confidence": 0.8907511234283447}]}, {"text": "After decoding, we detokenized and evaluated the output.", "labels": [], "entities": []}, {"text": "For the evaluation, we used a clean Spanish test set of 2,000 sentences from the same source.", "labels": [], "entities": [{"text": "Spanish test set", "start_pos": 36, "end_pos": 52, "type": "DATASET", "confidence": 0.7417316933472952}]}, {"text": "As an automatic evaluation measure, we used BLEU () for quantitative evaluation.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 44, "end_pos": 48, "type": "METRIC", "confidence": 0.9986730813980103}]}, {"text": "For our experiments, we used Italian and Portuguese as auxiliary languages.", "labels": [], "entities": []}, {"text": "We created two corpora of 30K sentences each from the Europarl corpus, en-it and en-pt.", "labels": [], "entities": [{"text": "Europarl corpus", "start_pos": 54, "end_pos": 69, "type": "DATASET", "confidence": 0.9915359020233154}]}, {"text": "We first tokenized and transliterated the training corpus of the related language as described in section 3.3.", "labels": [], "entities": []}, {"text": "Then, we concatenated the resulting corpora with our baseline corpus and trained our model.", "labels": [], "entities": []}, {"text": "This is similar to what was done by , although we attempt to translate into the low-resource language.", "labels": [], "entities": []}, {"text": "We first experimented with each auxiliary language independently and then with both languages.", "labels": [], "entities": []}, {"text": "In total we conducted the following experiments: \u2022 English-Spanish (en-es) + English-Italian transliterated (en-es it ) \u2022 English-Spanish (en-es) + English-Portuguese transliterated (en-es pt ) \u2022 English-Spanish (en-es) + English-Italian transliterated (en-es it ) + English-Portuguese transliterated (en-es pt ) In this experiment, we expected to observe some improvements compared to the language modeling experiments, as the mistakes in the transliterated output could be filtered out by the language model containing clean Spanish data.", "labels": [], "entities": []}, {"text": "Moreover, we examined whether it is possible to have gains from using multiple related languages simultaneously.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 4: Baseline results for experiment 1.", "labels": [], "entities": []}, {"text": " Table 5: Results of interpolated language models and optimal lambda values.", "labels": [], "entities": []}, {"text": " Table 7: BLEU scores obtained for the different training sets", "labels": [], "entities": [{"text": "BLEU", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9991154074668884}]}]}