{"title": [{"text": "An Empirical Evaluation of Noise Contrastive Estimation for the Neural Network Joint Model of Translation", "labels": [], "entities": [{"text": "Noise Contrastive Estimation", "start_pos": 27, "end_pos": 55, "type": "TASK", "confidence": 0.6665236949920654}, {"text": "Neural Network Joint Model of Translation", "start_pos": 64, "end_pos": 105, "type": "TASK", "confidence": 0.5297918220361074}]}], "abstractContent": [{"text": "The neural network joint model of translation or NNJM (Devlin et al., 2014) combines source and target context to produce a powerful translation feature.", "labels": [], "entities": []}, {"text": "However, its softmax layer necessitates a sum over the entire output vocabulary, which results in very slow maximum likelihood (MLE) training.", "labels": [], "entities": []}, {"text": "This has led some groups to train using Noise Con-trastive Estimation (NCE), which side-steps this sum.", "labels": [], "entities": [{"text": "Noise Con-trastive Estimation (NCE)", "start_pos": 40, "end_pos": 75, "type": "METRIC", "confidence": 0.7710117548704147}]}, {"text": "We carryout the first direct comparison of MLE and NCE training objectives for the NNJM, showing that NCE is significantly outperformed by MLE on large-scale Arabic-English and Chinese-English translation tasks.", "labels": [], "entities": [{"text": "NNJM", "start_pos": 83, "end_pos": 87, "type": "DATASET", "confidence": 0.9645028114318848}, {"text": "Chinese-English translation tasks", "start_pos": 177, "end_pos": 210, "type": "TASK", "confidence": 0.7635675668716431}]}, {"text": "We also show that this drop can be avoided by using a recently proposed translation noise distribution.", "labels": [], "entities": []}], "introductionContent": [{"text": "The Neural Network Joint Model of Translation, or NNJM (, is a strong feature for statistical machine translation.", "labels": [], "entities": [{"text": "Neural Network Joint Model of Translation", "start_pos": 4, "end_pos": 45, "type": "TASK", "confidence": 0.5757467051347097}, {"text": "statistical machine translation", "start_pos": 82, "end_pos": 113, "type": "TASK", "confidence": 0.68980606396993}]}, {"text": "The NNJM uses both target and source tokens as context fora feedforward neural network language model (LM).", "labels": [], "entities": [{"text": "NNJM", "start_pos": 4, "end_pos": 8, "type": "DATASET", "confidence": 0.9437178373336792}]}, {"text": "Unfortunately, its softmax layer requires a sum over the entire output vocabulary, which slows the calculation of LM probabilities and the maximum likelihood estimation (MLE) of model parameters.", "labels": [], "entities": [{"text": "maximum likelihood estimation (MLE)", "start_pos": 139, "end_pos": 174, "type": "METRIC", "confidence": 0.7653794586658478}]}, {"text": "address this problem at runtime only with a self-normalized MLE objective.", "labels": [], "entities": [{"text": "MLE", "start_pos": 60, "end_pos": 63, "type": "METRIC", "confidence": 0.74054354429245}]}, {"text": "Others advocate the use of Noise Contrastive Estimation (NCE) to train NNJMs and similar monolingual LMs;.", "labels": [], "entities": [{"text": "Noise Contrastive Estimation (NCE)", "start_pos": 27, "end_pos": 61, "type": "METRIC", "confidence": 0.65381920337677}]}, {"text": "NCE avoids the sum over the output vocabulary at both train-and run-time by wrapping the NNJM inside a classifier that attempts to separate real data from sampled noise, greatly improving training speed.", "labels": [], "entities": [{"text": "NCE", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.8664360642433167}]}, {"text": "The training efficiency of NCE is well-documented, and will not be evaluated here.", "labels": [], "entities": [{"text": "NCE", "start_pos": 27, "end_pos": 30, "type": "DATASET", "confidence": 0.7492067217826843}]}, {"text": "However, the experimental evidence that NCE matches MLE in terms of resulting model quality is all on monolingual language modeling tasks.", "labels": [], "entities": []}, {"text": "Since cross-lingual contexts provide substantially stronger signals than monolingual ones, there is reason to suspect these results may not carryover to NNJMs.", "labels": [], "entities": []}, {"text": "To our knowledge there is no published work that directly compares MLE and NCE in the context of an NNJM; this paper fills that gap as its primary contribution.", "labels": [], "entities": [{"text": "MLE", "start_pos": 67, "end_pos": 70, "type": "TASK", "confidence": 0.7720639109611511}, {"text": "NNJM", "start_pos": 100, "end_pos": 104, "type": "DATASET", "confidence": 0.9144169688224792}]}, {"text": "We measure model likelihood and translation quality in large-scale Arabic-to-English and Chinese-to-English translation tasks.", "labels": [], "entities": [{"text": "translation", "start_pos": 32, "end_pos": 43, "type": "TASK", "confidence": 0.9572970271110535}, {"text": "Chinese-to-English translation tasks", "start_pos": 89, "end_pos": 125, "type": "TASK", "confidence": 0.7472129861513773}]}, {"text": "We also test a recently-proposed translation noise distribution for NCE (, along with a mixture of noise distributions.", "labels": [], "entities": [{"text": "NCE", "start_pos": 68, "end_pos": 71, "type": "DATASET", "confidence": 0.881601095199585}]}, {"text": "Finally, we test a widely known, but apparently undocumented, technique for domain adaptation of NNJMs, demonstrating its utility, as well as its impact on the MLE-NCE comparison.", "labels": [], "entities": [{"text": "domain adaptation of NNJMs", "start_pos": 76, "end_pos": 102, "type": "TASK", "confidence": 0.7504388988018036}, {"text": "MLE-NCE comparison", "start_pos": 160, "end_pos": 178, "type": "TASK", "confidence": 0.6846695840358734}]}], "datasetContent": [{"text": "We test two translation scenarios drawn from the recent BOLT evaluations: Arabic-to-English and Chinese-to-English.", "labels": [], "entities": [{"text": "BOLT", "start_pos": 56, "end_pos": 60, "type": "METRIC", "confidence": 0.44955119490623474}]}, {"text": "The vital statistics for our corpora are given in NIST data with BOLT-specific informal genres.", "labels": [], "entities": [{"text": "NIST data", "start_pos": 50, "end_pos": 59, "type": "DATASET", "confidence": 0.9420233964920044}]}, {"text": "The development and test sets are focused specifically on the web-forum genre, as is the in-domain subset of the training data (In-dom).", "labels": [], "entities": []}, {"text": "The Arabic was segmented with MADA-ARZ (, while the Chinese was segmented with a lexiconbased approach.", "labels": [], "entities": [{"text": "MADA-ARZ", "start_pos": 30, "end_pos": 38, "type": "METRIC", "confidence": 0.6392966508865356}]}, {"text": "All data was word-aligned with IBM-4 in GIZA++ (, with growdiag-final-and symmetrization ().", "labels": [], "entities": [{"text": "IBM-4", "start_pos": 31, "end_pos": 36, "type": "DATASET", "confidence": 0.9006326794624329}]}], "tableCaptions": [{"text": " Table 2: Comparing various NNJM training objectives on two translation scenarios. BLEU results that are statistically better than", "labels": [], "entities": [{"text": "BLEU", "start_pos": 83, "end_pos": 87, "type": "METRIC", "confidence": 0.9990553259849548}]}, {"text": " Table 3: Comparing NNJM training objectives with and with-", "labels": [], "entities": [{"text": "Comparing NNJM training", "start_pos": 10, "end_pos": 33, "type": "TASK", "confidence": 0.4810984929402669}]}]}