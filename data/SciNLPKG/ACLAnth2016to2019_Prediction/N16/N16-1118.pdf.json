{"title": [{"text": "The Role of Context Types and Dimensionality in Learning Word Embeddings", "labels": [], "entities": []}], "abstractContent": [{"text": "We provide the first extensive evaluation of how using different types of context to learn skip-gram word embeddings affects performance on a wide range of intrinsic and ex-trinsic NLP tasks.", "labels": [], "entities": []}, {"text": "Our results suggest that while intrinsic tasks tend to exhibit a clear preference to particular types of contexts and higher dimensionality, more careful tuning is required for finding the optimal settings for most of the extrinsic tasks that we considered.", "labels": [], "entities": []}, {"text": "Furthermore, for these extrinsic tasks, we find that once the benefit from increasing the embedding dimensionality is mostly exhausted, simple concatenation of word em-beddings, learned with different context types, can yield further performance gains.", "labels": [], "entities": []}, {"text": "As an additional contribution, we propose anew variant of the skip-gram model that learns word embeddings from weighted contexts of substitute words.", "labels": [], "entities": []}], "introductionContent": [{"text": "Word embeddings have become increasingly popular lately, proving to be valuable as a source of features in abroad range of NLP tasks with limited supervision).", "labels": [], "entities": []}, {"text": "word2vec 1 skip-gram () * Majority of work performed while at IBM Watson.", "labels": [], "entities": []}, {"text": "1 http://code.google.com/p/word2vec/ and GloVe 2 () are among the most widely used word embedding models today.", "labels": [], "entities": []}, {"text": "Their success is largely due to an efficient and user-friendly implementation that learns highquality word embeddings from very large corpora.", "labels": [], "entities": []}, {"text": "Both word2vec and GloVe learn lowdimensional continuous vector representations for words by considering window-based contexts, i.e., context words within some fixed distance of each side of the target word.", "labels": [], "entities": []}, {"text": "However, the underlying models are equally applicable to different choices of context types.", "labels": [], "entities": []}, {"text": "For example, and showed that using syntactic contexts rather than window contexts in word2vec captures functional similarity (as in lion:cat) rather than topical similarity or relatedness (as in lion:zoo).", "labels": [], "entities": []}, {"text": "Further, and showed the benefits of such modified-context embeddings in dependency parsing and lexical substitution tasks.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 72, "end_pos": 90, "type": "TASK", "confidence": 0.807195633649826}]}, {"text": "However, to the best of our knowledge, there has not been an extensive evaluation of the effect of multiple, diverse context types on a wide range of NLP tasks.", "labels": [], "entities": []}, {"text": "Word embeddings are typically evaluated on intrinsic and extrinsic tasks.", "labels": [], "entities": []}, {"text": "Intrinsic tasks mostly include predicting human judgments of semantic relations between words, e.g., as in WordSim-353 (), while extrinsic tasks include various 'real' downstream NLP tasks, such as coreference resolution and sentiment analysis.", "labels": [], "entities": [{"text": "predicting human judgments of semantic relations between words", "start_pos": 31, "end_pos": 93, "type": "TASK", "confidence": 0.9110702574253082}, {"text": "WordSim-353", "start_pos": 107, "end_pos": 118, "type": "DATASET", "confidence": 0.958461582660675}, {"text": "coreference resolution", "start_pos": 198, "end_pos": 220, "type": "TASK", "confidence": 0.958183079957962}, {"text": "sentiment analysis", "start_pos": 225, "end_pos": 243, "type": "TASK", "confidence": 0.9542941749095917}]}, {"text": "Re-cent works have shown that while intrinsic evaluations are easier to perform, their correlation with results on extrinsic evaluations is not very reliable (, stressing the importance of the latter.", "labels": [], "entities": []}, {"text": "In this work, we provide the first extensive evaluation of word embeddings learned with different types of context, on a wide range of intrinsic similarity and relatedness tasks, and extrinsic NLP tasks, namely dependency parsing, named entity recognition, coreference resolution, and sentiment analysis.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 211, "end_pos": 229, "type": "TASK", "confidence": 0.748952716588974}, {"text": "named entity recognition", "start_pos": 231, "end_pos": 255, "type": "TASK", "confidence": 0.631915956735611}, {"text": "coreference resolution", "start_pos": 257, "end_pos": 279, "type": "TASK", "confidence": 0.949813574552536}, {"text": "sentiment analysis", "start_pos": 285, "end_pos": 303, "type": "TASK", "confidence": 0.9535473585128784}]}, {"text": "We employ contexts based of different word window sizes, syntactic dependencies, and a lesserknown substitute words approach ().", "labels": [], "entities": []}, {"text": "Finally, we experiment with combinations of the above word embeddings, comparing two approaches: (1) simple vector concatenation that offers a wider variety of features fora classifier to choose and learn weighted combinations from, and (2) dimensionality reduction via either Singular Value Decomposition or Canonical Correlation Analysis, which tries to find a smaller subset of features.", "labels": [], "entities": []}, {"text": "Our results suggest that it is worthwhile to carefully choose the right type of word embeddings for an extrinsic NLP task, rather than rely on intrinsic benchmark results.", "labels": [], "entities": []}, {"text": "Specifically, picking the optimal context type and dimensionality is critical.", "labels": [], "entities": []}, {"text": "Furthermore, once the benefit from increasing the embedding dimensionality is mostly exhausted, concatenation of word embeddings learned with different context types can yield further performance gains.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 2: NER MUC out-of-domain results for dif- ferent embeddings with dimensionality = 25.", "labels": [], "entities": [{"text": "NER MUC", "start_pos": 10, "end_pos": 17, "type": "TASK", "confidence": 0.6198450326919556}]}, {"text": " Table 2. In this out-of-domain setting,  all types of contexts achieve at least five points im- provement over the baseline. Presumably, this is be- cause continuous word embedding features are more  robust to differences between train and test data,  such as the typical vocabulary used. However, a de- tailed investigation of out-of-domain settings is out  of scope for this paper and left for future work.", "labels": [], "entities": []}, {"text": " Table 3. To control for dimen- sionality, concats are always compared against sin-", "labels": [], "entities": []}, {"text": " Table 3: Extrinsic tasks development set results obtained with word embeddings concatenations. 'best'  and 'best+' are the best results achieved across all single context types and context concatenations, respec- tively (best performing embedding indicated in parenthesis). 'mean' and 'mean+' are the mean results for  the same. Due to computational limitations of the employed systems, some of the evaluations were not  performed.", "labels": [], "entities": []}]}