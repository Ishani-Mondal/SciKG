{"title": [{"text": "Cross-Domain Mining of Argumentative Text through Distant Supervision", "labels": [], "entities": [{"text": "Cross-Domain Mining of Argumentative Text", "start_pos": 0, "end_pos": 41, "type": "TASK", "confidence": 0.8454018354415893}]}], "abstractContent": [{"text": "Argumentation mining is considered as a key technology for future search engines and automated decision making.", "labels": [], "entities": [{"text": "Argumentation mining", "start_pos": 0, "end_pos": 20, "type": "TASK", "confidence": 0.861200749874115}, {"text": "decision making", "start_pos": 95, "end_pos": 110, "type": "TASK", "confidence": 0.7044935673475266}]}, {"text": "In such applications , argumentative text segments have to be mined from large and diverse document collections.", "labels": [], "entities": []}, {"text": "However, most existing argumenta-tion mining approaches tackle the classification of argumentativeness only fora few manually annotated documents from narrow domains and registers.", "labels": [], "entities": [{"text": "argumenta-tion mining", "start_pos": 23, "end_pos": 44, "type": "TASK", "confidence": 0.7256827056407928}]}, {"text": "This limits their practical applicability.", "labels": [], "entities": []}, {"text": "We hence propose a distant supervision approach that acquires argumentative text segments automatically from online debate portals.", "labels": [], "entities": []}, {"text": "Experiments across domains and registers show that training on such a corpus improves the effectiveness and robustness of mining argumentative text.", "labels": [], "entities": []}, {"text": "We freely provide the underlying corpus for research.", "labels": [], "entities": []}], "introductionContent": [{"text": "Argumentation mining attracts much attention recently: it is an important building block of applications like automated decision making) or pro-and-con search engines).", "labels": [], "entities": [{"text": "Argumentation mining", "start_pos": 0, "end_pos": 20, "type": "TASK", "confidence": 0.9004948735237122}, {"text": "decision making", "start_pos": 120, "end_pos": 135, "type": "TASK", "confidence": 0.696460634469986}]}, {"text": "In such applications, argumentation mining usually consists of solving three tasks for each document: (1) Identifying all argumentative text segments in the document, (2) classifying the type of each segment, and (3) classifying relations between the segments.", "labels": [], "entities": [{"text": "argumentation mining", "start_pos": 22, "end_pos": 42, "type": "TASK", "confidence": 0.9393969476222992}, {"text": "Identifying all argumentative text segments in the document", "start_pos": 106, "end_pos": 165, "type": "TASK", "confidence": 0.8264982029795647}]}, {"text": "In this paper we focus on the first task taking on the retrieval perspective of a search engine: Given a large-scale collection of documents (e.g., the web) and a query on some topic, return all argumentative text segments relevant to the topic.", "labels": [], "entities": []}, {"text": "Among others, a classifier is needed for this task that can distinguish argumentative from non-argumentative segments.", "labels": [], "entities": []}, {"text": "Since we cannot presuppose a specific domain or register within a general retrieval scenario, the classifier needs to robustly deal with documents from diverse domains and registers.", "labels": [], "entities": []}, {"text": "In this regard the following two key issues arise.", "labels": [], "entities": []}, {"text": "First, existing approaches to classifying argumentativeness usually focus on specific text domains (e.g., education) and registers (e.g., student essays).", "labels": [], "entities": [{"text": "classifying argumentativeness", "start_pos": 30, "end_pos": 59, "type": "TASK", "confidence": 0.8630075752735138}]}, {"text": "Therefore, many used features capture not only local linguistic properties of a text segment, but also global document properties (e.g., that a segment is part of the introduction).", "labels": [], "entities": []}, {"text": "Such kinds of features tend to be effective only within a certain domain or a particular register while often failing for others.", "labels": [], "entities": []}, {"text": "Second, all major existing approaches follow a supervised learning scheme based on manual annotation of argumentative text segments.", "labels": [], "entities": []}, {"text": "However, the annotation of arguments is particularly intricate and thus expensive due to the complex linguistic structure and the partly subjective interpretation of argumentativeness.", "labels": [], "entities": []}, {"text": "Different types of argumentative and non-argumentative segments may come in any order, segment boundaries are not always unambiguous, and parts of an argument maybe implicit.", "labels": [], "entities": []}, {"text": "Studies reveal that annotators need multiple training sessions to identify and classify argumentative segments with moderate inter-annotator agreement, and crowdsourcing-based annotation does not help notably ().", "labels": [], "entities": []}, {"text": "I.e., a high-quality manual annotation will not scale to large numbers of documents from diverse domains and registers.", "labels": [], "entities": []}, {"text": "We propose a solution to the outlined issues.", "labels": [], "entities": []}, {"text": "In particular, we follow the idea of distant supervision to construct a large-scale corpus of text segments from diverse domains and registers annotated with respect to argumentativeness.", "labels": [], "entities": []}, {"text": "Distant supervision is a well-known idea for training robust statistical classifiers.", "labels": [], "entities": []}, {"text": "Here, we exploit online debate portals that (1) contain argumentative and non-argumentative text segments for several controversial topics, and that (2) are organized in a semi-structured form, allowing to derive annotations from it.", "labels": [], "entities": []}, {"text": "In several experiments we compare classifiers trained on the constructed corpus to those trained on existing corpora for argumentation mining.", "labels": [], "entities": [{"text": "argumentation mining", "start_pos": 121, "end_pos": 141, "type": "TASK", "confidence": 0.936212807893753}]}, {"text": "We classify argumentativeness using a rich set of lexical, syntax, and indicator feature types.", "labels": [], "entities": []}, {"text": "Our results suggest that the new corpus is the most robust resource for classifying argumentative text segments across domains and registers.", "labels": [], "entities": []}, {"text": "In addition, we observe that n-grams seem to be most domain-dependent, while syntax features turnout to be more robust.", "labels": [], "entities": []}, {"text": "The contribution of this paper is three-fold: First, through distant supervision we acquire a large corpus with 28,689 argumentative text segments from the online debate portal idebate.org.", "labels": [], "entities": []}, {"text": "The corpus covers 14 separate domains with strongly varying feature distributions.", "labels": [], "entities": []}, {"text": "It will be made freely available to other researchers.", "labels": [], "entities": []}, {"text": "1 Second, we obtain a robust classifier for argumentativeness, providing evidence that distant supervision does not only save money and time, but also benefits the effectiveness of cross-domain and cross-register argumentation mining.", "labels": [], "entities": [{"text": "cross-register argumentation mining", "start_pos": 198, "end_pos": 233, "type": "TASK", "confidence": 0.7251192331314087}]}, {"text": "Third, we evaluate-for the first timethe robustness of several features in classifying argumentativeness across domains and registers.", "labels": [], "entities": []}, {"text": "Altogether, the paper serves as a starting point for bringing argumentation mining to practice.", "labels": [], "entities": [{"text": "argumentation mining", "start_pos": 62, "end_pos": 82, "type": "TASK", "confidence": 0.9498544335365295}]}, {"text": "We expect that a robust identification of arguments will be a core module of future search engines, as it allows to provide rationales for retrieved documents.", "labels": [], "entities": []}, {"text": "To this end, the search engines also need to identify the most relevant arguments fora given topic.", "labels": [], "entities": []}, {"text": "The paper concludes with ideas on how to assess argument relevance with resources that are obtained through applying our proposed distant supervision technique to other datasets.", "labels": [], "entities": [{"text": "argument relevance", "start_pos": 48, "end_pos": 66, "type": "TASK", "confidence": 0.7310170829296112}]}, {"text": "1 http://www.uni-weimar.de/medien/webis/corpora", "labels": [], "entities": []}], "datasetContent": [{"text": "To evaluate the effect of using the Webis-Debate-16 corpus for training, appropriate argumentation corpora are needed for comparison.", "labels": [], "entities": [{"text": "Webis-Debate-16 corpus", "start_pos": 36, "end_pos": 58, "type": "DATASET", "confidence": 0.9600225985050201}]}, {"text": "We consider an available corpus as appropriate if (1) the corpus is annotated in away that allows the distinction of argumentative from non-argumentative text segments, and if (2) the corpus comes with clear annotation guidelines and reported inter-annotator agreement.", "labels": [], "entities": []}, {"text": "In addition, we aim at corpora that differ in terms of the covered domains and registers to provide an adequate cross-domain setting.", "labels": [], "entities": []}, {"text": "While the Araucaria corpus does not meet the second requirement (), two recently published corpora fulfill both; we refer to them as the Essays corpus and the Web discourse corpus.", "labels": [], "entities": [{"text": "Araucaria corpus", "start_pos": 10, "end_pos": 26, "type": "DATASET", "confidence": 0.7979088127613068}, {"text": "Web discourse corpus", "start_pos": 159, "end_pos": 179, "type": "DATASET", "confidence": 0.7945270339647929}]}, {"text": "Essays: The Argument Annotated Essays corpus of consists of 90 manually annotated persuasive student essays from the education domain.", "labels": [], "entities": []}, {"text": "Argumentative text segments are assigned with their type (major claim, claim, or premise).", "labels": [], "entities": []}, {"text": "Following, we consider all sentences that do not have an annotation as being non-argumentative, and the annotated segments as argumentative.", "labels": [], "entities": []}, {"text": "Web discourse: The Argument Annotated Usergenerated Web Discourse corpus of consists of 340 documents from six different topics and four registers.", "labels": [], "entities": [{"text": "Usergenerated Web Discourse corpus", "start_pos": 38, "end_pos": 72, "type": "DATASET", "confidence": 0.5163199082016945}]}, {"text": "The annotation of arguments is conducted based on the argument model of Toulmin (1958) using five types (claim, premise, backing, rebuttal, and refutation).", "labels": [], "entities": []}, {"text": "Again, we consider all annotated text segments as being argumentative and sentences without annotation as being non-argumentative.", "labels": [], "entities": []}, {"text": "Only in case of the Essays corpus, the authors already provide a split into a training and a test set (72 essays for training and 18 for testing).", "labels": [], "entities": []}, {"text": "For both the Web discourse corpus and our corpus, we randomly split the document set into 80% for training and 20% for testing.", "labels": [], "entities": [{"text": "Web discourse corpus", "start_pos": 13, "end_pos": 33, "type": "DATASET", "confidence": 0.6865579883257548}]}, {"text": "As a result, the training set of the Web discourse corpus consists of 272 documents, and its test set of 68 documents, while the training and test sets of our corpus consist of 356 and 89 documents, respectively.", "labels": [], "entities": [{"text": "Web discourse corpus", "start_pos": 37, "end_pos": 57, "type": "DATASET", "confidence": 0.7996795972188314}]}, {"text": "We train classifiers for each of the above feature types and for the full feature set on the training set of each corpus using the default configuration of the naive Bayes implementation of Weka (.", "labels": [], "entities": []}, {"text": "Since all corpora are imbalanced in terms of the number of argumentative and non-argumentative text segments, we perform undersampling for all training sets-an effective technique for largely imbalanced datasets).", "labels": [], "entities": []}, {"text": "All feature values are computed based on the output of the StanfordNLP library (.", "labels": [], "entities": [{"text": "StanfordNLP library", "start_pos": 59, "end_pos": 78, "type": "DATASET", "confidence": 0.9845010936260223}]}, {"text": "For the different classifiers, we measure the resulting classification performance on all three test sets in terms of accuracy and F 1 -score.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 118, "end_pos": 126, "type": "METRIC", "confidence": 0.9996885061264038}, {"text": "F 1 -score", "start_pos": 131, "end_pos": 141, "type": "METRIC", "confidence": 0.987753614783287}]}, {"text": "shows the results of the in-domain experiments.", "labels": [], "entities": []}, {"text": "For the full feature set, the achieved F 1 -score.", "labels": [], "entities": [{"text": "F 1 -score", "start_pos": 39, "end_pos": 49, "type": "METRIC", "confidence": 0.9906212389469147}]}, {"text": "The results of all in-domain experiments on the three corpora for each feature type and the full feature set.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2. Number of documents, argumentative segments,  and non-argumentative segments in each domain of our  Webis-Debate-16 corpus. Domains correspond to themes  from idebate.org.", "labels": [], "entities": []}, {"text": " Table 4. The results of all in-domain experiments on the three corpora for each feature type and the full feature set.", "labels": [], "entities": []}, {"text": " Table 5. The results of all cross-domain experiments on the three corpora for each feature type and the full feature set.", "labels": [], "entities": []}]}