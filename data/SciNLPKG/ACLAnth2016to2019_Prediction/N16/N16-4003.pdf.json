{"title": [{"text": "Question Answering with Knowledge Base, Web and Beyond", "labels": [], "entities": [{"text": "Question Answering", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.8392727077007294}]}], "abstractContent": [], "introductionContent": [{"text": "Developing a Question Answering (QA) system to automatically answer naturallanguage questions has been a long-standing research problem since the dawn of AI, for its clear practical and scientific value.", "labels": [], "entities": [{"text": "Question Answering (QA)", "start_pos": 13, "end_pos": 36, "type": "TASK", "confidence": 0.8398155450820923}]}, {"text": "For instance, whether a system can answer questions correctly is a natural way to evaluate a machine's understanding of a domain.", "labels": [], "entities": []}, {"text": "Providing succinct and precise answers to informational queries is also the direction pursued by the next generation of search engines that aim to incorporate more \"semantics\", as well as the basic function in digital assistants like In this tutorial, we aim to give the audience a coherent overview of the research of question answering.", "labels": [], "entities": [{"text": "question answering", "start_pos": 319, "end_pos": 337, "type": "TASK", "confidence": 0.7919349372386932}]}, {"text": "We will first introduce a variety of QA problems proposed by pioneer researchers and briefly describe the early efforts.", "labels": [], "entities": [{"text": "QA", "start_pos": 37, "end_pos": 39, "type": "TASK", "confidence": 0.9358997344970703}]}, {"text": "By contrasting with the current research trend in this domain, the audience can easily comprehend what technical problems remain challenging and what the main breakthroughs and opportunities are during the past half century.", "labels": [], "entities": []}, {"text": "For the rest of the tutorial, we select three categories of the QA problems that have recently attracted a great deal of attention in the research community, and will present the tasks with the latest technical survey.", "labels": [], "entities": []}, {"text": "The first two categories regard answering factoid questions, where the main difference of the problem settings is the information source used for extracting answers.", "labels": [], "entities": [{"text": "answering factoid questions", "start_pos": 32, "end_pos": 59, "type": "TASK", "confidence": 0.8920503457387289}]}, {"text": "QA with knowledge base aims to answer natural language questions using real-world facts stored in an existing, large-scale database.", "labels": [], "entities": []}, {"text": "The representative approach for this task is to develop a semantic parser (of questions), which will be the main focus.", "labels": [], "entities": []}, {"text": "Other approaches like text matching in the embedding space and those driven by information extraction will also be discussed.", "labels": [], "entities": [{"text": "text matching", "start_pos": 22, "end_pos": 35, "type": "TASK", "confidence": 0.7977972030639648}, {"text": "information extraction", "start_pos": 79, "end_pos": 101, "type": "TASK", "confidence": 0.785522073507309}]}, {"text": "The other category, QA with the Web, targets answering questions using mainly from the facts extracted from general text corpora derived from the Web.", "labels": [], "entities": [{"text": "QA with the Web", "start_pos": 20, "end_pos": 35, "type": "TASK", "confidence": 0.8082690984010696}]}, {"text": "In addition to the common components and techniques used in this setting, including passage retrieval, entity recognition and question analysis, we will also introduce latest work on how to leverage and incorporate additional structured and semi-structured data to improve the performance.", "labels": [], "entities": [{"text": "passage retrieval", "start_pos": 84, "end_pos": 101, "type": "TASK", "confidence": 0.9306898713111877}, {"text": "entity recognition", "start_pos": 103, "end_pos": 121, "type": "TASK", "confidence": 0.8840476274490356}, {"text": "question analysis", "start_pos": 126, "end_pos": 143, "type": "TASK", "confidence": 0.8005335330963135}]}, {"text": "The third category of the QA problems that we will highlight is the non-factoid questions.", "labels": [], "entities": []}, {"text": "Due to its broad coverage, we will briefly cover three exemplary topics: story comprehension, reasoning questions and paragraph QA.", "labels": [], "entities": [{"text": "paragraph QA", "start_pos": 118, "end_pos": 130, "type": "TASK", "confidence": 0.5782737731933594}]}, {"text": "The tutorial will conclude by summarizing a whole area of exciting and dynamic research that is worthy of more detailed investigation for many years to come.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": []}