{"title": [{"text": "Separating Actor-View from Speaker-View Opinion Expressions using Linguistic Features", "labels": [], "entities": [{"text": "Separating Actor-View from Speaker-View Opinion Expressions", "start_pos": 0, "end_pos": 59, "type": "TASK", "confidence": 0.8228252728780111}]}], "abstractContent": [{"text": "We examine different features and classifiers for the categorization of opinion words into actor and speaker view.", "labels": [], "entities": []}, {"text": "To our knowledge, this is the first comprehensive work to address sentiment views on the word level taking into consideration opinion verbs, nouns and adjectives.", "labels": [], "entities": []}, {"text": "We consider many high-level features requiring only few labeled training data.", "labels": [], "entities": []}, {"text": "A detailed feature analysis produces linguistic insights into the nature of sentiment views.", "labels": [], "entities": []}, {"text": "We also examine how far global constraints between different opinion words help to increase classification performance.", "labels": [], "entities": []}, {"text": "Finally, we show that our (prior) word-level annotation correlates with contextual sentiment views.", "labels": [], "entities": []}], "introductionContent": [{"text": "While there has been much research in sentiment analysis on the tasks of subjectivity detection and polarity classification, there has been less work on other types of categorizations that can be imposed upon subjective expressions.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 38, "end_pos": 56, "type": "TASK", "confidence": 0.9628446698188782}, {"text": "subjectivity detection", "start_pos": 73, "end_pos": 95, "type": "TASK", "confidence": 0.7523876130580902}, {"text": "polarity classification", "start_pos": 100, "end_pos": 123, "type": "TASK", "confidence": 0.7320904582738876}]}, {"text": "In this paper, we focus on the views that an opinion expression evokes.", "labels": [], "entities": []}, {"text": "By views, we understand the perspective of the holder of some opinion.", "labels": [], "entities": []}, {"text": "We distinguish between the two most common types: expressions conveying sentiment of the entities participating in the event denoted by the opinion word, referred to as actor views (e.g. disappointed in (1) or praised in (2)), and expressions conveying sentiment of the speaker of the utterance, referred to as speaker views (e.g. excelled in (3) or wasted in (4)).", "labels": [], "entities": []}, {"text": "(1) Party members were disappointedactor at the election outcome.", "labels": [], "entities": []}, {"text": "The distinction between those categories is relevant for related tasks in sentiment analysis, most importantly, opinion holder and target extraction.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 74, "end_pos": 92, "type": "TASK", "confidence": 0.9553533494472504}, {"text": "opinion holder", "start_pos": 112, "end_pos": 126, "type": "TASK", "confidence": 0.6861978471279144}, {"text": "target extraction", "start_pos": 131, "end_pos": 148, "type": "TASK", "confidence": 0.7325377911329269}]}, {"text": "This has already been demonstrated for verbs.", "labels": [], "entities": []}, {"text": "For example, even though the noun Peter has the same grammatical relation to the opinion verb in (5) & (6), in the former sentence it is a holder but in the latter it is a target.", "labels": [], "entities": []}, {"text": "Similar cases can be observed for opinion nouns  While the distinction of sentiment views is not new, we put a different emphasis on this task.", "labels": [], "entities": []}, {"text": "Our focus is on the prior meaning that opinion words evoke.", "labels": [], "entities": []}, {"text": "Hence we consider this as a word-level task.", "labels": [], "entities": []}, {"text": "Every opinion word from a sentiment lexicon is to be categorized as conveying either an actor or a speaker view.", "labels": [], "entities": []}, {"text": "Our aim is to find comprehensive methods to automatically categorize opinion words of various parts of speech (verbs, nouns, adjectives).", "labels": [], "entities": []}, {"text": "The resulting lexical resources are indispensable for opendomain categorization.", "labels": [], "entities": []}, {"text": "Previous work focused on contextual classification of sentiment views.", "labels": [], "entities": [{"text": "contextual classification of sentiment views", "start_pos": 25, "end_pos": 69, "type": "TASK", "confidence": 0.8134249746799469}]}, {"text": "showed that while prior lexical knowledge of sentiment views is effective in transferring opinion role extractors to other domains, this does not apply to contextual classifiers.", "labels": [], "entities": [{"text": "opinion role extractors", "start_pos": 90, "end_pos": 113, "type": "TASK", "confidence": 0.6912570794423422}]}, {"text": "In this work, we focus on linguistic properties for predicting sentiment views.", "labels": [], "entities": [{"text": "predicting sentiment views", "start_pos": 52, "end_pos": 78, "type": "TASK", "confidence": 0.9469947616259257}]}, {"text": "We examine in how far morphological information can be used.", "labels": [], "entities": []}, {"text": "Distributional and syntactic information is also considered.", "labels": [], "entities": []}, {"text": "In terms of lexical resources, we examine WordNet and FrameNet.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 42, "end_pos": 49, "type": "DATASET", "confidence": 0.963204562664032}]}, {"text": "We show that information from a sentiment lexicon can give some additional clues.", "labels": [], "entities": []}, {"text": "In order to combine the different features to predict the sentiment views evoked by opinion words we employ supervised classification.", "labels": [], "entities": []}, {"text": "As a classifier, we use Markov Logic Networks () since they do not only allow us to define features for instances (i.e. opinion words) but also to formulate global constraints between different instances.", "labels": [], "entities": []}, {"text": "The latter cannot be expressed by traditional classifiers (e.g. SVM).", "labels": [], "entities": []}, {"text": "We examine two types of constraints: consistency between instances that are distributionally similar and consistency between morphologically related instances.", "labels": [], "entities": [{"text": "consistency", "start_pos": 37, "end_pos": 48, "type": "METRIC", "confidence": 0.9725931286811829}]}, {"text": "Finally, we also examine the relationship between prior lexical information (i.e. our approach) and contextual annotation in the MPQA corpus.", "labels": [], "entities": [{"text": "MPQA corpus", "start_pos": 129, "end_pos": 140, "type": "DATASET", "confidence": 0.9222977459430695}]}], "datasetContent": [{"text": "For our evaluation of supervised classification, we focus on a setting in which only few labeled training data are available.", "labels": [], "entities": [{"text": "supervised classification", "start_pos": 22, "end_pos": 47, "type": "TASK", "confidence": 0.6810029149055481}]}, {"text": "We sampled from our gold standard 20% of the labeled training data.", "labels": [], "entities": []}, {"text": "The remaining 80% are used as test data.", "labels": [], "entities": []}, {"text": "This process was repeated five times.", "labels": [], "entities": []}, {"text": "We report performance averaged over these five (test) samples.", "labels": [], "entities": []}, {"text": "We focus on small training sizes since we think that for the given lexicon induction task, we should pursue an approach that requires little human annotation.", "labels": [], "entities": []}, {"text": "Moreover, we show that our approach yields good results despite the absence of large amounts of training data.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Distribution of the different sentiment views.", "labels": [], "entities": [{"text": "Distribution", "start_pos": 10, "end_pos": 22, "type": "TASK", "confidence": 0.9687415361404419}]}, {"text": " Table 4: High-precision features (minimal frequency > 10).", "labels": [], "entities": []}, {"text": " Table 7: Comparison of prior labels and context labels.", "labels": [], "entities": []}, {"text": " Table 6: Comparison of different classifiers (for training, 20% of the labeled data were sampled; the test data are the remaining", "labels": [], "entities": []}, {"text": " Table 9: Contextual classification of opinion nouns with a prior", "labels": [], "entities": [{"text": "Contextual classification of opinion nouns with a prior", "start_pos": 10, "end_pos": 65, "type": "TASK", "confidence": 0.8460418358445168}]}]}