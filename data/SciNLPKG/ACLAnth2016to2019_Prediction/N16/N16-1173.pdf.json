{"title": [{"text": "Unsupervised Learning of Prototypical Fillers for Implicit Semantic Role Labeling", "labels": [], "entities": [{"text": "Implicit Semantic Role Labeling", "start_pos": 50, "end_pos": 81, "type": "TASK", "confidence": 0.5974232107400894}]}], "abstractContent": [{"text": "Gold annotations for supervised implicit semantic role labeling are extremely sparse and costly.", "labels": [], "entities": [{"text": "supervised implicit semantic role labeling", "start_pos": 21, "end_pos": 63, "type": "TASK", "confidence": 0.5712864816188812}]}, {"text": "As a lightweight alternative, this paper describes an approach based on unsupervised parsing which can do without iSRL-specific training data: We induce prototypical roles from large amounts of explicit SRL annotations paired with their distributed word representations.", "labels": [], "entities": []}, {"text": "An evaluation shows competitive performance with supervised methods on the SemEval 2010 data, and our method can easily be applied to predicates (or languages) for which no training annotations are available.", "labels": [], "entities": [{"text": "SemEval 2010 data", "start_pos": 75, "end_pos": 92, "type": "DATASET", "confidence": 0.8256672620773315}]}], "introductionContent": [{"text": "Semantic role labeling (SRL) () has become a well-established and highly important NLP component which directly benefits various downstream applications, such as text summarization (Trandab\u02d8 at\u00b8,at\u00b8, 2011), recognizing textual entailment ( or QA systems).", "labels": [], "entities": [{"text": "Semantic role labeling (SRL)", "start_pos": 0, "end_pos": 28, "type": "TASK", "confidence": 0.8251634935537974}, {"text": "text summarization", "start_pos": 162, "end_pos": 180, "type": "TASK", "confidence": 0.7593645453453064}, {"text": "recognizing textual entailment", "start_pos": 207, "end_pos": 237, "type": "TASK", "confidence": 0.8278912901878357}]}, {"text": "Its goal is to detect verbal or nominal predicates, together with their associated arguments and semantic roles, either by PropBank/Nombank () or FrameNet ( analysis.", "labels": [], "entities": []}, {"text": "In its traditional form, however, SRL is restricted to the local syntactic context of the predicate as in the following example from: [ GOAL/NI In the centre of this room] there was an upright beam, [ THEME which] had been placed [ TIME at some period] as a support for the old worm-eaten baulk of timber which spanned the roof.", "labels": [], "entities": [{"text": "SRL", "start_pos": 34, "end_pos": 37, "type": "TASK", "confidence": 0.9347993731498718}, {"text": "GOAL/NI", "start_pos": 136, "end_pos": 143, "type": "METRIC", "confidence": 0.8856485486030579}, {"text": "THEME", "start_pos": 201, "end_pos": 206, "type": "METRIC", "confidence": 0.993198037147522}, {"text": "TIME", "start_pos": 232, "end_pos": 236, "type": "METRIC", "confidence": 0.8043648600578308}]}, {"text": "Ina FrameNet-style analysis of the sentence, the predicate place evokes the PLACING frame, with two frame elements (roles) overtly expressed (THEME and TIME) but with one role -GOAL -beyond the embedded relative clause and thus beyond the scope of the SRL parser.", "labels": [], "entities": [{"text": "THEME", "start_pos": 142, "end_pos": 147, "type": "METRIC", "confidence": 0.9396635890007019}, {"text": "TIME", "start_pos": 152, "end_pos": 156, "type": "METRIC", "confidence": 0.9207137227058411}, {"text": "GOAL", "start_pos": 177, "end_pos": 181, "type": "METRIC", "confidence": 0.9911494255065918}]}, {"text": "Such implicit roles, or null instantiations (NIs)) are much harder to detect automatically, as they require to broaden the analysis to the surrounding discourse, commonly also to preceding (or following) sentences.", "labels": [], "entities": []}, {"text": "State-of-the-art approaches to implicit SRL (iSRL) are supervised and need a groundwork of hand-annotated training data -which is costly, extremely sparse, limited to only a handful of predicates, and requires careful feature engineering.", "labels": [], "entities": [{"text": "SRL (iSRL)", "start_pos": 40, "end_pos": 50, "type": "TASK", "confidence": 0.776914969086647}]}, {"text": "A first attempt has been made to combine the scarce resources available, but given the great diversity of predicatespecific roles and enormous complexity of the task, the main issues remain.", "labels": [], "entities": []}, {"text": "A promising exploratory effort recently made by aims to overcome the annotation bottleneck by using distributional methods to infer evidence for elements filling null instantiated roles.", "labels": [], "entities": []}, {"text": "The authors do not rely on gold annotations but instead learn distributional properties of fillers induced from a large corpus.", "labels": [], "entities": []}, {"text": "Our Contribution: We propose an extension of the distributional idea for unsupervised iSRL to loosen the need for annotated training data.", "labels": [], "entities": []}, {"text": "Specifically, we propose to induce predicate and role-specific prototypical fillers from large amounts of SRL annotated texts in order to resolve null instantiations as (semantically and syntactically) similar elements found in the context.", "labels": [], "entities": [{"text": "SRL annotated texts", "start_pos": 106, "end_pos": 125, "type": "TASK", "confidence": 0.768762211004893}]}, {"text": "Parts of our approach have been successfully applied in traditional SRL (), but not yet to implicit roles.", "labels": [], "entities": [{"text": "SRL", "start_pos": 68, "end_pos": 71, "type": "TASK", "confidence": 0.9778669476509094}]}, {"text": "Our work differs from in that we extend discrete context vectors to SRL-guided embeddings and experiment with a variety of different configurations.", "labels": [], "entities": [{"text": "SRL-guided embeddings", "start_pos": 68, "end_pos": 89, "type": "TASK", "confidence": 0.8254643678665161}]}, {"text": "We intend not to set anew benchmark beating the current state-of-the-art for supervised iSRL, but rather provide a simple and alternative strategy which does not rely on manually annotated gold data.", "labels": [], "entities": []}, {"text": "Still, we demonstrate that our method is highly competitive with supervised methods on one out of two standard evaluation sets and that it can easily be extended to other predicates for which no implicit gold annotations are available.", "labels": [], "entities": []}], "datasetContent": [{"text": "In order to assess the usefulness of our approach, a quantitative evaluation has been conducted on two iSRL test sets which have become a de facto standard in this domain: a collection of fiction novels from the SemEval 2010 Shared Task with manual annotations of null instantiations, and Gerber and Chai (2010)'s augmented NomBank data set.", "labels": [], "entities": [{"text": "iSRL test sets", "start_pos": 103, "end_pos": 117, "type": "DATASET", "confidence": 0.9121732910474142}, {"text": "SemEval 2010 Shared Task", "start_pos": 212, "end_pos": 236, "type": "TASK", "confidence": 0.7630537450313568}, {"text": "NomBank data set", "start_pos": 324, "end_pos": 340, "type": "DATASET", "confidence": 0.8573363224665324}]}, {"text": "shows some general statistics on the number of implicit roles and candidate phrases involved in our experiments.", "labels": [], "entities": []}, {"text": "As to have a comparison with the supervised approaches referred to in this study, we also provide the size of the training data.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Statistics on the number of explicit fillers used for", "labels": [], "entities": []}, {"text": " Table 2: Statistics on implicit arguments and candidate phrases", "labels": [], "entities": []}, {"text": " Table 4: NI linking performance on the SemEval test data.", "labels": [], "entities": [{"text": "SemEval test data", "start_pos": 40, "end_pos": 57, "type": "DATASET", "confidence": 0.8323697249094645}]}, {"text": " Table 3: Classification scores for implicit argument labeling on the NomBank test section. Baseline B from Gerber & Chai (2010):", "labels": [], "entities": [{"text": "implicit argument labeling", "start_pos": 36, "end_pos": 62, "type": "TASK", "confidence": 0.6481658120950063}, {"text": "NomBank test section", "start_pos": 70, "end_pos": 90, "type": "DATASET", "confidence": 0.9063867330551147}]}]}