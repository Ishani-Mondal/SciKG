{"title": [{"text": "Improved Neural Network-based Multi-label Classification with Better Initialization Leveraging Label Co-occurrence", "labels": [], "entities": [{"text": "Improved Neural Network-based Multi-label Classification", "start_pos": 0, "end_pos": 56, "type": "TASK", "confidence": 0.5678942680358887}]}], "abstractContent": [{"text": "Ina multi-label text classification task, in which multiple labels can be assigned to one text, label co-occurrence itself is informative.", "labels": [], "entities": [{"text": "multi-label text classification task", "start_pos": 4, "end_pos": 40, "type": "TASK", "confidence": 0.7030094191431999}]}, {"text": "We propose a novel neural network initializa-tion method to treat some of the neurons in the final hidden layer as dedicated neurons for each pattern of label co-occurrence.", "labels": [], "entities": []}, {"text": "These dedicated neurons are initialized to connect to the corresponding co-occurring labels with stronger weights than to others.", "labels": [], "entities": []}, {"text": "In experiments with a natural language query classification task, which requires multi-label classification , our initialization method improved classification accuracy without any computational overhead in training and evaluation.", "labels": [], "entities": [{"text": "natural language query classification task", "start_pos": 22, "end_pos": 64, "type": "TASK", "confidence": 0.6833130359649658}, {"text": "accuracy", "start_pos": 160, "end_pos": 168, "type": "METRIC", "confidence": 0.9088022112846375}]}], "introductionContent": [{"text": "In multi-label text classification, one text can be associated with multiple labels (label cooccurrence)).", "labels": [], "entities": [{"text": "multi-label text classification", "start_pos": 3, "end_pos": 34, "type": "TASK", "confidence": 0.6475393374760946}]}, {"text": "Since label co-occurrence itself contains information, we would like to leverage the label co-occurrence to improve multi-label classification using a neural network (NN).", "labels": [], "entities": [{"text": "multi-label classification", "start_pos": 116, "end_pos": 142, "type": "TASK", "confidence": 0.7966789305210114}]}, {"text": "We propose a novel NN initialization method that treats some of the neurons in the final hidden layer as dedicated neurons for each pattern of label co-occurrence.", "labels": [], "entities": [{"text": "NN initialization", "start_pos": 19, "end_pos": 36, "type": "TASK", "confidence": 0.7204170823097229}]}, {"text": "These dedicated neurons are initialized to connect to the corresponding cooccurring labels with stronger weights than to others.", "labels": [], "entities": []}, {"text": "While initialization of an NN is an important research topic, to the best of our knowledge, there has been no attempt to leverage label cooccurrence for NN initialization.", "labels": [], "entities": [{"text": "initialization of an NN", "start_pos": 6, "end_pos": 29, "type": "TASK", "confidence": 0.8892792165279388}, {"text": "NN initialization", "start_pos": 153, "end_pos": 170, "type": "TASK", "confidence": 0.7825442552566528}]}, {"text": "To validate our proposed method, we focus on multi-label Natural Language Query (NLQ) classification in a document retrieval system in which users input queries in natural language and the system returns documents that contain answers to the queries.", "labels": [], "entities": [{"text": "multi-label Natural Language Query (NLQ) classification", "start_pos": 45, "end_pos": 100, "type": "TASK", "confidence": 0.6823033839464188}]}, {"text": "For NLQ classification, we first train a model from training data that contains pairs of queries and corresponding one or more than one document labels, and then predict the appropriate document labels for new queries with the trained model.", "labels": [], "entities": [{"text": "NLQ classification", "start_pos": 4, "end_pos": 22, "type": "TASK", "confidence": 0.889636367559433}]}, {"text": "Through experiments with a real-world document retrieval system and publicly available multi-label data set, simply and directly embedding label cooccurrence information into an NN with our proposed method improved accuracy of NLQ classification.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 215, "end_pos": 223, "type": "METRIC", "confidence": 0.9992997646331787}, {"text": "NLQ classification", "start_pos": 227, "end_pos": 245, "type": "TASK", "confidence": 0.781198114156723}]}], "datasetContent": [{"text": "We conducted experiments with the real-world NLQ classification data and the publicly available data to confirm the advantage of the proposed method.", "labels": [], "entities": [{"text": "NLQ classification", "start_pos": 45, "end_pos": 63, "type": "TASK", "confidence": 0.731404185295105}]}], "tableCaptions": [{"text": " Table 1: 1-best accuracy, recall@5, and full accuracy for evaluation data using different loss functions (Random initialization \u2192", "labels": [], "entities": [{"text": "accuracy", "start_pos": 17, "end_pos": 25, "type": "METRIC", "confidence": 0.9990097284317017}, {"text": "recall@5", "start_pos": 27, "end_pos": 35, "type": "METRIC", "confidence": 0.9517436623573303}, {"text": "accuracy", "start_pos": 46, "end_pos": 54, "type": "METRIC", "confidence": 0.9989826083183289}]}, {"text": " Table 2: 1-best accuracy, recall@5, and full accuracy for eval-", "labels": [], "entities": [{"text": "accuracy", "start_pos": 17, "end_pos": 25, "type": "METRIC", "confidence": 0.9993231296539307}, {"text": "recall@5", "start_pos": 27, "end_pos": 35, "type": "METRIC", "confidence": 0.9629475275675455}, {"text": "accuracy", "start_pos": 46, "end_pos": 54, "type": "METRIC", "confidence": 0.9919193983078003}]}, {"text": " Table 3: Investigation of neural network after back-propagation training.", "labels": [], "entities": []}]}