{"title": [], "abstractContent": [{"text": "In this paper we present new state-of-the-art performance on CCG supertagging and parsing.", "labels": [], "entities": [{"text": "parsing", "start_pos": 82, "end_pos": 89, "type": "TASK", "confidence": 0.8829357028007507}]}, {"text": "Our model outperforms existing approaches by an absolute gain of 1.5%.", "labels": [], "entities": []}, {"text": "We analyze the performance of several neural models and demonstrate that while feed-forward architectures can compete with bidirectional LSTMs on POS tagging, models that encode the complete sentence are necessary for the long range syntactic information encoded in supertags.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 146, "end_pos": 157, "type": "TASK", "confidence": 0.6847814470529556}]}], "introductionContent": [{"text": "Morphosyntactic labels for words are commonly used in a variety of NLP applications.", "labels": [], "entities": []}, {"text": "For this reason, part-of-speech (POS) tagging and supertagging have drawn significant attention from the community.", "labels": [], "entities": [{"text": "part-of-speech (POS) tagging", "start_pos": 17, "end_pos": 45, "type": "TASK", "confidence": 0.6086151719093322}]}, {"text": "Combinatory Categorial Grammar is a lexicalized grammar formalism that is widely used for syntactic and semantic parsing.", "labels": [], "entities": [{"text": "Combinatory Categorial Grammar", "start_pos": 0, "end_pos": 30, "type": "TASK", "confidence": 0.6862989763418833}, {"text": "syntactic and semantic parsing", "start_pos": 90, "end_pos": 120, "type": "TASK", "confidence": 0.6356362700462341}]}, {"text": "Supertagging) assigns complex syntactic labels to words to enable fast and accurate parsing.", "labels": [], "entities": []}, {"text": "The disambiguation of correctly labeling a word with one of over 1,200 CCG labels is difficult compared to choosing on of the 45 POS labels in the Penn Treebank (.", "labels": [], "entities": [{"text": "Penn Treebank", "start_pos": 147, "end_pos": 160, "type": "DATASET", "confidence": 0.9930636882781982}]}, {"text": "In addition to the large label space of CCG supertags, labeling a word correctly depends on knowledge of syntactic phenomena arbitrarily far in the sentence.", "labels": [], "entities": []}, {"text": "This is because supertags encode highly specific syntactic information (e.g. types and locations of arguments) about a word's usage in a sentence.", "labels": [], "entities": []}, {"text": "In this paper, we show that Bidirectional Long Short-Term Memory recurrent neural networks (biLSTMs)), which can use information from the entire sentence, area natural and powerful architecture for CCG supertagging.", "labels": [], "entities": []}, {"text": "In addition to the bi-LSTM, we create a simple yet novel model that outperforms the previous state-of-the-art RNN model that uses handcrafted features ( ) by 1.5%.", "labels": [], "entities": []}, {"text": "Concurrent to this work () introduced a different training methodology for bi-LSTM for supertagging.", "labels": [], "entities": []}, {"text": "We provide a detailed analysis of the quality of various LSTM architectures, forward, backward, and bi-directional, shedding light over the ability of the bi-LSTM to exploit rich sentential context necessary for performing supertagging.", "labels": [], "entities": []}, {"text": "We also show that a baseline feed-forward neural network (NN) architecture significantly outperforms previous feed-forward NN baselines, with slightly fewer features, achieving better accuracy than the RNN model from ( . Recently, bi-LSTMs have achieved high accuracies in a simpler sequence labeling task: partof-speech tagging () on the Penn treebank, with small improvements over local models.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 184, "end_pos": 192, "type": "METRIC", "confidence": 0.998676598072052}, {"text": "sequence labeling", "start_pos": 283, "end_pos": 300, "type": "TASK", "confidence": 0.6097369492053986}, {"text": "partof-speech tagging", "start_pos": 307, "end_pos": 328, "type": "TASK", "confidence": 0.8543110489845276}, {"text": "Penn treebank", "start_pos": 339, "end_pos": 352, "type": "DATASET", "confidence": 0.993850976228714}]}, {"text": "However, we achieve strong accuracies compared to () using feed-forward neural network model trained on local context, showing that this task does not require bi-LSTMs.", "labels": [], "entities": []}, {"text": "Our strong feed-forward NN baselines show the power of feed-forward NNs for some tasks.", "labels": [], "entities": []}, {"text": "Our main contributions are the introduction of anew bi-LSTM model for CCG supertagging that achieves state-of-the-art, on both CCG supertagging and parsing, and a detailed analysis of our results, including a comparison of bi-LSTMs and simpler feed forward NN models for supertagging and POS tagging, which suggests that the added complexity of bi-LSTMs may not be necessary for POS tagging, where local contexts suffice to a much greater extent than in supertagging.", "labels": [], "entities": [{"text": "parsing", "start_pos": 148, "end_pos": 155, "type": "TASK", "confidence": 0.9672736525535583}, {"text": "POS tagging", "start_pos": 288, "end_pos": 299, "type": "TASK", "confidence": 0.7997544705867767}, {"text": "POS tagging", "start_pos": 379, "end_pos": 390, "type": "TASK", "confidence": 0.9226638078689575}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Accuracies on the development section. The language", "labels": [], "entities": [{"text": "Accuracies", "start_pos": 10, "end_pos": 20, "type": "METRIC", "confidence": 0.9946081638336182}]}, {"text": " Table 2: Prediction accuracy for our models on several common and difficult supertags.", "labels": [], "entities": [{"text": "Prediction", "start_pos": 10, "end_pos": 20, "type": "METRIC", "confidence": 0.9322795867919922}, {"text": "accuracy", "start_pos": 21, "end_pos": 29, "type": "METRIC", "confidence": 0.9512327909469604}]}, {"text": " Table 3: Our new POS tagging results show a strong Feed-", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 18, "end_pos": 29, "type": "TASK", "confidence": 0.7864697277545929}]}]}