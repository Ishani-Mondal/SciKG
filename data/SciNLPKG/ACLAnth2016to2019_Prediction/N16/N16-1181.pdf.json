{"title": [{"text": "Learning to Compose Neural Networks for Question Answering", "labels": [], "entities": [{"text": "Question Answering", "start_pos": 40, "end_pos": 58, "type": "TASK", "confidence": 0.7572470903396606}]}], "abstractContent": [{"text": "We describe a question answering model that applies to both images and structured knowledge bases.", "labels": [], "entities": [{"text": "question answering", "start_pos": 14, "end_pos": 32, "type": "TASK", "confidence": 0.753825306892395}]}, {"text": "The model uses natural language strings to automatically assemble neu-ral networks from a collection of composable modules.", "labels": [], "entities": []}, {"text": "Parameters for these modules are learned jointly with network-assembly parameters via reinforcement learning, with only (world, question, answer) triples as supervision.", "labels": [], "entities": []}, {"text": "Our approach, which we term a dynamic neural module network, achieves state-of-the-art results on benchmark datasets in both visual and structured domains.", "labels": [], "entities": []}], "introductionContent": [{"text": "This paper presents a compositional, attentional model for answering questions about a variety of world representations, including images and structured knowledge bases.", "labels": [], "entities": []}, {"text": "The model translates from questions to dynamically assembled neural networks, then applies these networks to world representations (images or knowledge bases) to produce answers.", "labels": [], "entities": []}, {"text": "We take advantage of two largely independent lines of work: on one hand, an extensive literature on answering questions by mapping from strings to logical representations of meaning; on the other, a series of recent successes in deep neural models for image recognition and captioning.", "labels": [], "entities": [{"text": "image recognition and captioning", "start_pos": 252, "end_pos": 284, "type": "TASK", "confidence": 0.6609271764755249}]}, {"text": "By constructing neural networks instead of logical forms, our model leverages the best aspects of both linguistic compositionality and continuous representations.", "labels": [], "entities": []}, {"text": "Our model has two components, trained jointly: first, a collection of neural \"modules\" that can be freely composed (; second, a network layout predictor that assembles modules into complete deep networks tailored to each question ().", "labels": [], "entities": []}, {"text": "lookup relate and Previous work has used manually-specified modular structures for visual learning ().", "labels": [], "entities": []}, {"text": "Here we: \u2022 learn a network structure predictor jointly with module parameters themselves \u2022 extend visual primitives from previous work to reason over structured world representations Training data consists of (world, question, answer) triples: our approach requires no supervision of network layouts.", "labels": [], "entities": []}, {"text": "We achieve state-of-the-art performance on two markedly different question answering tasks: one with questions about natural images, and another with more compositional questions about United States geography.", "labels": [], "entities": [{"text": "question answering", "start_pos": 66, "end_pos": 84, "type": "TASK", "confidence": 0.8049724996089935}]}], "datasetContent": [{"text": "The framework described in this paper is general, and we are interested in how well it performs on datasets of varying domain, size and linguistic complexity.", "labels": [], "entities": []}, {"text": "To that end, we evaluate our model on tasks at opposite extremes of both these criteria: a large visual question answering dataset, and a small collection of more structured geography questions.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Results on the VQA test server. NMN is the  parameter-tying model from Andreas et al. (2015), while  NMN* is a reimplementation using the same image processing  pipeline as D-NMN. The model with dynamic network structure  prediction achieves the best published results on this task.", "labels": [], "entities": [{"text": "VQA test server", "start_pos": 25, "end_pos": 40, "type": "DATASET", "confidence": 0.9587837258974711}, {"text": "dynamic network structure  prediction", "start_pos": 205, "end_pos": 242, "type": "TASK", "confidence": 0.6564800813794136}]}, {"text": " Table 2: Results on the GeoQA dataset, and the GeoQA  dataset with quantification. Our approach outperforms both a  purely logical model (LSP-F) and a model with learned percep- tual predicates (LSP-W) on the original dataset, and a fixed- structure NMN under both evaluation conditions.", "labels": [], "entities": [{"text": "GeoQA dataset", "start_pos": 25, "end_pos": 38, "type": "DATASET", "confidence": 0.9501370191574097}, {"text": "GeoQA  dataset", "start_pos": 48, "end_pos": 62, "type": "DATASET", "confidence": 0.9690123796463013}]}]}