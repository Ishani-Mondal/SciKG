{"title": [{"text": "Extraction of Bilingual Technical Terms for Chinese-Japanese Patent Translation", "labels": [], "entities": [{"text": "Extraction of Bilingual Technical Terms", "start_pos": 0, "end_pos": 39, "type": "TASK", "confidence": 0.8434758901596069}, {"text": "Chinese-Japanese Patent Translation", "start_pos": 44, "end_pos": 79, "type": "TASK", "confidence": 0.599205364783605}]}], "abstractContent": [{"text": "The translation of patents or scientific papers is a key issue that should be helped by the use of statistical machine translation (SMT).", "labels": [], "entities": [{"text": "translation of patents or scientific papers", "start_pos": 4, "end_pos": 47, "type": "TASK", "confidence": 0.8883446554342905}, {"text": "statistical machine translation (SMT)", "start_pos": 99, "end_pos": 136, "type": "TASK", "confidence": 0.7759085943301519}]}, {"text": "In this paper, we propose a method to improve Chinese-Japanese patent SMT by pre-marking the training corpus with aligned bilingual multi-word terms.", "labels": [], "entities": [{"text": "Chinese-Japanese patent SMT", "start_pos": 46, "end_pos": 73, "type": "TASK", "confidence": 0.4970344305038452}]}, {"text": "We automatically extract multi-word terms from monolingual corpora by combining statistical and linguistic filtering methods.", "labels": [], "entities": []}, {"text": "We use the sampling-based alignment method to identify aligned terms and set some threshold on translation probabilities to select the most promising bilingual multi-word terms.", "labels": [], "entities": []}, {"text": "We pre-mark a Chinese-Japanese training corpus with such selected aligned bilingual multi-word terms.", "labels": [], "entities": []}, {"text": "We obtain the performance of over 70% precision in bilingual term extraction and a significant improvement of BLEU scores in our experiments on a Chinese-Japanese patent parallel corpus.", "labels": [], "entities": [{"text": "precision", "start_pos": 38, "end_pos": 47, "type": "METRIC", "confidence": 0.9987165927886963}, {"text": "bilingual term extraction", "start_pos": 51, "end_pos": 76, "type": "TASK", "confidence": 0.6040136019388834}, {"text": "BLEU", "start_pos": 110, "end_pos": 114, "type": "METRIC", "confidence": 0.9996310472488403}, {"text": "Chinese-Japanese patent parallel corpus", "start_pos": 146, "end_pos": 185, "type": "DATASET", "confidence": 0.6582865566015244}]}], "introductionContent": [{"text": "China and Japan are producing a large amount of scientific journals and patents in their respective languages.", "labels": [], "entities": []}, {"text": "The World Intellectual Property Organization (WIPO) Indicators show that China was the first country for patent applications in 2013.", "labels": [], "entities": [{"text": "World Intellectual Property Organization (WIPO) Indicators", "start_pos": 4, "end_pos": 62, "type": "DATASET", "confidence": 0.642070971429348}]}, {"text": "Japan was the first country for patent grants in 2013.", "labels": [], "entities": []}, {"text": "Much of current scientific development in China or Japan is not readily available to non-Chinese or nonJapanese speaking scientists.", "labels": [], "entities": []}, {"text": "Additionally, China and Japan are more efficient at converting research and development dollars into patents than the U.S. or the European countries 2 . Making Chinese patents available in Japanese, and Japanese patents available and in Chinese is a key issue for increased economical development in Asia.", "labels": [], "entities": []}, {"text": "In recent years, Chinese-Japanese machine translation of patents or scientific papers has made rapid progress with the large quantities of parallel corpora provided by the organizers of the Workshop on Asian Translation (WAT) 3 4 . In the \"patents subtask\" of, a Chinese to Japanese translation system is described that achieves higher BLEU scores by combination of results between Statistical Post Editing (SPE) based on their rule-based translation system and SMT system equipped with a recurrent neural language model (RNNLM).", "labels": [], "entities": [{"text": "machine translation of patents or scientific papers", "start_pos": 34, "end_pos": 85, "type": "TASK", "confidence": 0.8397179160799298}, {"text": "Asian Translation (WAT)", "start_pos": 202, "end_pos": 225, "type": "TASK", "confidence": 0.8333559274673462}, {"text": "BLEU", "start_pos": 336, "end_pos": 340, "type": "METRIC", "confidence": 0.9993157386779785}, {"text": "SMT", "start_pos": 462, "end_pos": 465, "type": "TASK", "confidence": 0.9784720540046692}]}, {"text": "In the research by, they improved a Chinese-to-Japanese patent translation system by using English as a pivot language for three different purposes: corpus enrichment, sentence pivot translation and phrase pivot translation.", "labels": [], "entities": [{"text": "Chinese-to-Japanese patent translation", "start_pos": 36, "end_pos": 74, "type": "TASK", "confidence": 0.7025986115137736}, {"text": "corpus enrichment", "start_pos": 149, "end_pos": 166, "type": "TASK", "confidence": 0.7012805491685867}, {"text": "sentence pivot translation", "start_pos": 168, "end_pos": 194, "type": "TASK", "confidence": 0.6383860409259796}, {"text": "phrase pivot translation", "start_pos": 199, "end_pos": 223, "type": "TASK", "confidence": 0.6708421111106873}]}, {"text": "Still, the availability of patent bilingual corpora between Chinese and Japanese in certain domains is a problem.", "labels": [], "entities": []}, {"text": "In this paper, we propose a simpler way to improve Chinese to Japanese phrase-based machine translation quality based on a small size of available bilingual patent corpus, without exploiting extra bilingual data, or using a third language, with no complex approach.", "labels": [], "entities": [{"text": "Chinese to Japanese phrase-based machine translation", "start_pos": 51, "end_pos": 103, "type": "TASK", "confidence": 0.5654902507861456}]}, {"text": "Patents or scientific papers contain large amounts of domain-specific terms in words or multi-word expressions.", "labels": [], "entities": []}, {"text": "Monolingual or bilingual term extraction is an important task for the fields of information retrieval, text categorization, clustering, machine translation, etc.", "labels": [], "entities": [{"text": "Monolingual or bilingual term extraction", "start_pos": 0, "end_pos": 40, "type": "TASK", "confidence": 0.6017390489578247}, {"text": "information retrieval", "start_pos": 80, "end_pos": 101, "type": "TASK", "confidence": 0.7599507570266724}, {"text": "text categorization", "start_pos": 103, "end_pos": 122, "type": "TASK", "confidence": 0.7574423849582672}, {"text": "machine translation", "start_pos": 136, "end_pos": 155, "type": "TASK", "confidence": 0.774173229932785}]}, {"text": "There exist work on monolingual or bilingual term extraction in different languages.", "labels": [], "entities": [{"text": "monolingual or bilingual term extraction", "start_pos": 20, "end_pos": 60, "type": "TASK", "confidence": 0.6309787571430207}]}, {"text": "In (, multi-word terms in Chinese in the information technology (IT) domain and the medicine domain are extracted based on the integration of Web information and termhood estimation.", "labels": [], "entities": []}, {"text": "describes a combination of linguistic and statistical information method (C-value/NC-value) for the automatic extraction of multi-word terms from English corpora.", "labels": [], "entities": [{"text": "automatic extraction of multi-word terms from English corpora", "start_pos": 100, "end_pos": 161, "type": "TASK", "confidence": 0.8288596123456955}]}, {"text": "In), it was showed that the C-/NC-value method is an efficient domain-independent multi-word term recognition not only in English but in Japanese as well.", "labels": [], "entities": [{"text": "domain-independent multi-word term recognition", "start_pos": 63, "end_pos": 109, "type": "TASK", "confidence": 0.6517253667116165}]}, {"text": "Some work consider the case of bilingual term extraction.", "labels": [], "entities": [{"text": "bilingual term extraction", "start_pos": 31, "end_pos": 56, "type": "TASK", "confidence": 0.6313078800837199}]}, {"text": "In, Chinese-Japanese multi-word terms are extracted by re-segmenting the Chinese and Japanese bi-corpus and combining multi-word terms as one single word based on extracted monolingual terms.", "labels": [], "entities": []}, {"text": "The word alignments containing terms are smoothed by computing the associations between pairs of bilingual term candidates.", "labels": [], "entities": []}, {"text": "In this paper, we propose a method to extract Chinese-Japanese bilingual multi-word terms by extracting Chinese and Japanese monolingual multi-word terms using a linguistic and statistical technique (C-value) () and the sampling-based alignment method) for bilingual multi-word term alignment.", "labels": [], "entities": [{"text": "bilingual multi-word term alignment", "start_pos": 257, "end_pos": 292, "type": "TASK", "confidence": 0.5756230801343918}]}, {"text": "We filter the aligned candidate terms by setting thresholds on translation probabilities.", "labels": [], "entities": []}, {"text": "We perform experiments on the Chinese-Japanese JPO patent corpus of WAT 2015.", "labels": [], "entities": [{"text": "JPO patent corpus of WAT 2015", "start_pos": 47, "end_pos": 76, "type": "DATASET", "confidence": 0.8892329037189484}]}, {"text": "We pre-mark the extracted bilingual terms in the Chinese-Japanese training corpus of an SMT system.", "labels": [], "entities": [{"text": "SMT", "start_pos": 88, "end_pos": 91, "type": "TASK", "confidence": 0.9910365343093872}]}, {"text": "We compare the translation system which uses our proposed method with a baseline system.", "labels": [], "entities": []}, {"text": "We obtain a significant improvement in translation accuracy as evaluated by BLEU ().", "labels": [], "entities": [{"text": "translation", "start_pos": 39, "end_pos": 50, "type": "TASK", "confidence": 0.9248771667480469}, {"text": "accuracy", "start_pos": 51, "end_pos": 59, "type": "METRIC", "confidence": 0.9394234418869019}, {"text": "BLEU", "start_pos": 76, "end_pos": 80, "type": "METRIC", "confidence": 0.9978007674217224}]}, {"text": "The paper is organized as follows: in Section 2, we introduce the experimental data sets used in our experiments.", "labels": [], "entities": []}, {"text": "Section 3 gives our proposed method to extract Chinese-Japanese bilingual multi-word terms using the C-value and the sampling-based alignment method.", "labels": [], "entities": []}, {"text": "In Section 4, we describe our experiments and their results based on the data introduced in Section 2, and an analysis of the experimental results.", "labels": [], "entities": []}, {"text": "Section 5 gives the conclusion and discusses future directions.", "labels": [], "entities": []}], "datasetContent": [{"text": "We train the Chinese-Japanese translation models on the training parallel pre-marked corpus with the extracted filtered aligned bilingual multi-word terms.", "labels": [], "entities": []}, {"text": "A language model is trained with the original Japanese corpus without pre-marking annotation.", "labels": [], "entities": []}, {"text": "We remove the markers from obtained phrase tables before performing tuning and decoding processes.", "labels": [], "entities": []}, {"text": "We compare such a systems with a standard baseline system.", "labels": [], "entities": []}, {"text": "We extract monolingual multi-word terms from a Chinese-Japanese training corpus of 100,000 lines as indicated in (Section 2).", "labels": [], "entities": []}, {"text": "shows the number of monolingual multi-word terms extracted in Chinese and Japanese respectively using C-value and the linguistic pattern given in Section 3.1.", "labels": [], "entities": []}, {"text": "The extracted monolingual multi-word terms were ranked by decreasing order of C-values.", "labels": [], "entities": []}, {"text": "We mark the training corpus with the same size of Chinese and Japanese monolingual multi-word terms.", "labels": [], "entities": []}, {"text": "They are the first 80,000 monolingual multi-word terms with higher C-value in both languages.", "labels": [], "entities": []}, {"text": "Follow the description given in Section 3.2.", "labels": [], "entities": []}, {"text": "Table 4 gives the number of bilingual multi-word terms obtained for different thresholds from the marked 100,000 training corpus.", "labels": [], "entities": []}, {"text": "We randomly extract 100 bilingual multi-word terms respectively and roughly   check how well they correspond/match manually.", "labels": [], "entities": []}, {"text": "The precision (good match) of the extracted bilingual multi-word terms is over 70%, while threshold becomes greater than 0.4.", "labels": [], "entities": [{"text": "precision", "start_pos": 4, "end_pos": 13, "type": "METRIC", "confidence": 0.9994589686393738}, {"text": "threshold", "start_pos": 90, "end_pos": 99, "type": "METRIC", "confidence": 0.987998366355896}]}, {"text": "shows sample of bilingual multi-word terms we extracted.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Statistics on our experimental data sets (after tokeniz-", "labels": [], "entities": []}, {"text": " Table 4: Evaluation results in BLEU for Chinese to Japanese translation based on pre-marked training corpus with bilingual", "labels": [], "entities": [{"text": "BLEU", "start_pos": 32, "end_pos": 36, "type": "METRIC", "confidence": 0.9965664148330688}, {"text": "Chinese to Japanese translation", "start_pos": 41, "end_pos": 72, "type": "TASK", "confidence": 0.640341728925705}]}, {"text": " Table 7: Distribution of the reduced phrase table of baseline system based on GIZA++/Moses 2.1.1.", "labels": [], "entities": [{"text": "GIZA++/Moses 2.1.1", "start_pos": 79, "end_pos": 97, "type": "DATASET", "confidence": 0.8819558173418045}]}]}