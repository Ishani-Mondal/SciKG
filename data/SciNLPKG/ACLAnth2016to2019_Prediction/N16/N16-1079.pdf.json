{"title": [], "abstractContent": [{"text": "Many puns create humor through the relationship between a pun and its phonologically similar target.", "labels": [], "entities": []}, {"text": "For example, in \"Don't take geologists for granite\" the word \"granite\" is a pun with the target \"granted\".", "labels": [], "entities": []}, {"text": "The recovery of the target in the mind of the listener is essential to the success of the pun.", "labels": [], "entities": []}, {"text": "This work introduces anew model for automatic target recovery and provides the first empirical test for this task.", "labels": [], "entities": [{"text": "automatic target recovery", "start_pos": 36, "end_pos": 61, "type": "TASK", "confidence": 0.6038741370042165}]}, {"text": "The model draws upon techniques for automatic speech recognition using weighted finite-state transducers, and leverages automatically learned phone edit probabilities that give insight into how people perceive sounds and into what makes a good pun.", "labels": [], "entities": [{"text": "automatic speech recognition", "start_pos": 36, "end_pos": 64, "type": "TASK", "confidence": 0.6716464261213938}]}, {"text": "The model is evaluated on a small corpus where it is able to automatically recover a large fraction of the pun targets.", "labels": [], "entities": []}], "introductionContent": [{"text": "From the high culture of Shakespeare's plays, to the depths of the YouTube comments section, from advertising slogans to conversations with nerdy parents, puns area versatile rhetorical device and their understanding is essential to any comprehensive approach to computational humor.", "labels": [], "entities": []}, {"text": "Humor has been described as \"one of the most interesting and puzzling research areas in the field of natural language understanding\" (.", "labels": [], "entities": [{"text": "Humor", "start_pos": 0, "end_pos": 5, "type": "TASK", "confidence": 0.9507414102554321}, {"text": "natural language understanding", "start_pos": 101, "end_pos": 131, "type": "TASK", "confidence": 0.656322052081426}]}, {"text": "Puns, in particular, offer an interesting subject for study since their humor derives from wordplay and double-meaning.", "labels": [], "entities": []}, {"text": "An important class of puns, known as paronomasic puns, are those where one entity, the pun, is phonologically similar to another, the target.", "labels": [], "entities": []}, {"text": "Consider an example from: \"Sign by gate to nudist colony: Come in.", "labels": [], "entities": []}, {"text": "We are Never Clothed.\"", "labels": [], "entities": [{"text": "Never Clothed", "start_pos": 7, "end_pos": 20, "type": "DATASET", "confidence": 0.883334219455719}]}, {"text": "Here, \"clothed\" is the pun and \"closed\" is the target.", "labels": [], "entities": []}, {"text": "Paronomasic puns are distinguished from homographic puns such as \"Two silkworms had a race.", "labels": [], "entities": []}, {"text": "They ended up in a tie.\" which puns on the two definitions of the word \"tie\".", "labels": [], "entities": []}, {"text": "When the pun and target are homophonic this is called a perfect pun, and when nearly homophonic an imperfect pun ( (or a heterophonic pun).", "labels": [], "entities": []}, {"text": "The focus of this work is to propose and evaluate a model for target recovery of both perfect and imperfect paronomasic puns, assuming that the location of the pun word or word sequence.", "labels": [], "entities": []}, {"text": "classifies puns in terms of whether they are self-contained, i.e., based on general knowledge and humorous in a variety of circumstances, or contextually integrated, i.e. relying on a specific context such as a visual context, knowledge of a recent event or discussion.", "labels": [], "entities": []}, {"text": "Many puns of this type are associated with cartoons or images, e.g. a cartoon with pies and cakes in the street having the caption \"The streets were oddly desserted\" (desserted/deserted).", "labels": [], "entities": []}, {"text": "Contextually integrated puns lose their humor out of context because the pun is difficult to detect.", "labels": [], "entities": []}, {"text": "However, target recovery is often still possible, and thus this distinction does not play a major role in the current study.", "labels": [], "entities": []}, {"text": "If a listener fails to recover the target of the pun then the statement fails in its humor.", "labels": [], "entities": []}, {"text": "The two chief clues that the listener must rely onto perform target recovery are the phonetic information and language context.", "labels": [], "entities": [{"text": "target recovery", "start_pos": 61, "end_pos": 76, "type": "TASK", "confidence": 0.7217641025781631}]}, {"text": "This is analogous to the way in which someone listening to speech uses the acoustic information and language context to recover a sequence of words from an audio source.", "labels": [], "entities": []}, {"text": "In the words of, \"the recovery of the target in heterophonic puns is just a specific case of the complex task of hearing.\"", "labels": [], "entities": []}, {"text": "The similarity between hearing and target recovery suggests the use of methods from automatic speech recognition in building a model for automatic target recovery.", "labels": [], "entities": [{"text": "target recovery", "start_pos": 35, "end_pos": 50, "type": "TASK", "confidence": 0.7199841886758804}, {"text": "automatic target recovery", "start_pos": 137, "end_pos": 162, "type": "TASK", "confidence": 0.6394166052341461}]}, {"text": "The goal of this paper is to develop and test a computational model for target recovery in puns.", "labels": [], "entities": [{"text": "target recovery in puns", "start_pos": 72, "end_pos": 95, "type": "TASK", "confidence": 0.8116617724299431}]}, {"text": "Sentences with the position of the pun marked are given as input and the model must output the target word sequence.", "labels": [], "entities": []}, {"text": "As the focus is on paronomasic puns, the relationship between the pun and the target is primarily phonological, but surrounding language context is also important for recovering the target.", "labels": [], "entities": []}, {"text": "This work has applications in natural language understanding of texts that contain humor.", "labels": [], "entities": [{"text": "natural language understanding of texts that contain humor", "start_pos": 30, "end_pos": 88, "type": "TASK", "confidence": 0.7932705096900463}]}, {"text": "Furthermore, the insights gained from our model are useful for improving pun generation in computational humor systems.", "labels": [], "entities": [{"text": "pun generation", "start_pos": 73, "end_pos": 87, "type": "TASK", "confidence": 0.8881228566169739}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Accuracy and mean reciprocal rank (MRR) for target recovery", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9993698000907898}, {"text": "mean reciprocal rank (MRR)", "start_pos": 23, "end_pos": 49, "type": "METRIC", "confidence": 0.9308376510938009}]}, {"text": " Table 2: Top ranked target LM + PEM hypotheses for the pun \"A book fell on my head. I've only got my shelf to blame.\"", "labels": [], "entities": [{"text": "PEM", "start_pos": 33, "end_pos": 36, "type": "METRIC", "confidence": 0.7715707421302795}]}]}