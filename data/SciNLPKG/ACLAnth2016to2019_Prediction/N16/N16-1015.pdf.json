{"title": [{"text": "Multi-domain Neural Network Language Generation for Spoken Dialogue Systems", "labels": [], "entities": [{"text": "Multi-domain Neural Network Language Generation", "start_pos": 0, "end_pos": 47, "type": "TASK", "confidence": 0.5962385356426239}]}], "abstractContent": [{"text": "Moving from limited-domain natural language generation (NLG) to open domain is difficult because the number of semantic input combinations grows exponentially with the number of domains.", "labels": [], "entities": [{"text": "limited-domain natural language generation (NLG)", "start_pos": 12, "end_pos": 60, "type": "TASK", "confidence": 0.8167278681482587}]}, {"text": "Therefore, it is important to leverage existing resources and exploit similarities between domains to facilitate domain adaptation.", "labels": [], "entities": [{"text": "domain adaptation", "start_pos": 113, "end_pos": 130, "type": "TASK", "confidence": 0.7209122478961945}]}, {"text": "In this paper, we propose a procedure to train multi-domain, Recurrent Neural Network-based (RNN) language generators via multiple adaptation steps.", "labels": [], "entities": []}, {"text": "In this procedure, a model is first trained on counterfeited data synthesised from an out-of-domain dataset, and then fine tuned on a small set of in-domain utterances with a discriminative objective function.", "labels": [], "entities": []}, {"text": "Corpus-based evaluation results show that the proposed procedure can achieve competitive performance in terms of BLEU score and slot error rate while significantly reducing the data needed to train generators in new, unseen domains.", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 113, "end_pos": 123, "type": "METRIC", "confidence": 0.9801517426967621}, {"text": "slot error rate", "start_pos": 128, "end_pos": 143, "type": "METRIC", "confidence": 0.891382892926534}]}, {"text": "In subjective testing, human judges confirm that the procedure greatly improves generator performance when only a small amount of data is available in the domain.", "labels": [], "entities": []}], "introductionContent": [{"text": "Modern Spoken Dialogue Systems (SDS) are typically developed according to a well-defined ontology, which provides a structured representation of the domain data that the dialogue system can talk about, such as searching fora restaurant or shopping fora laptop.", "labels": [], "entities": [{"text": "Spoken Dialogue Systems (SDS)", "start_pos": 7, "end_pos": 36, "type": "TASK", "confidence": 0.6712633669376373}]}, {"text": "Unlike conventional approaches employing a substantial amount of handcrafting for each individual processing component, statistical approaches to SDS promise a domain-scalable framework which requires a minimal amount of human intervention (.", "labels": [], "entities": [{"text": "SDS", "start_pos": 146, "end_pos": 149, "type": "TASK", "confidence": 0.9715195894241333}]}, {"text": "Mrk\u0161i\u00b4  showed improved performance in belief tracking by training a general model and adapting it to specific domains.", "labels": [], "entities": [{"text": "belief tracking", "start_pos": 39, "end_pos": 54, "type": "TASK", "confidence": 0.9378309845924377}]}, {"text": "Similar benefit can be observed in Ga\u0161i\u00b4 , in which a Bayesian committee machine) was used to model policy learning in a multi-domain SDS regime.", "labels": [], "entities": [{"text": "policy learning", "start_pos": 100, "end_pos": 115, "type": "TASK", "confidence": 0.812787264585495}]}, {"text": "In past decades, adaptive NLG has been studied from linguistic perspectives, such as systems that learn to tailor user preferences (, convey a specific personality trait (), or align with their conversational partner ().", "labels": [], "entities": []}, {"text": "Domain adaptation was first addressed by using a generator based on the Lexical Functional Grammar (LFG) fstructures.", "labels": [], "entities": [{"text": "Domain adaptation", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.813184916973114}]}, {"text": "Although these approaches can model rich linguistic phenomenon, they are not readily adaptable to data since they still require many handcrafted rules to define the search space.", "labels": [], "entities": []}, {"text": "Recently, RNN-based language generation has been introduced ().", "labels": [], "entities": [{"text": "RNN-based language generation", "start_pos": 10, "end_pos": 39, "type": "TASK", "confidence": 0.8020490209261576}]}, {"text": "This class of statistical generators can learn generation decisions directly from dialogue act (DA)-utterance pairs without any semantic annotations ( or hand-coded grammars).", "labels": [], "entities": []}, {"text": "Many existing adaptation approaches can be directly applied due to the flexibility of the underlying RNN language model (RNNLM) architecture.", "labels": [], "entities": []}, {"text": "Discriminative training (DT) has been successfully used to train RNNs for various tasks.", "labels": [], "entities": [{"text": "Discriminative training (DT)", "start_pos": 0, "end_pos": 28, "type": "TASK", "confidence": 0.6896087467670441}]}, {"text": "By optimising directly against the desired objective function such as BLEU score  or Word Error Rate (), the model can explore its output space and learn to discriminate between good and bad hypotheses.", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 70, "end_pos": 80, "type": "METRIC", "confidence": 0.9892827570438385}, {"text": "Word Error Rate", "start_pos": 85, "end_pos": 100, "type": "METRIC", "confidence": 0.7099313040574392}]}, {"text": "In this paper we show that DT can enable a generator to learn more efficiently when in-domain data is scarce.", "labels": [], "entities": [{"text": "DT", "start_pos": 27, "end_pos": 29, "type": "TASK", "confidence": 0.8778572082519531}]}, {"text": "The paper presents an incremental recipe for training multi-domain language generators based on a purely data-driven, RNN-based generation model.", "labels": [], "entities": []}, {"text": "Following a review of related work in section 2, section 3 describes the detailed RNN generator architecture.", "labels": [], "entities": [{"text": "RNN generator", "start_pos": 82, "end_pos": 95, "type": "TASK", "confidence": 0.5853806734085083}]}, {"text": "The data counterfeiting approach for synthesising an in-domain dataset is introduced in section 4, where it is compared to the simple model fine-tuning approach.", "labels": [], "entities": []}, {"text": "In section 5, we describe our proposed DT procedure for training natural language generators.", "labels": [], "entities": [{"text": "DT", "start_pos": 39, "end_pos": 41, "type": "TASK", "confidence": 0.9700344800949097}, {"text": "training natural language generators", "start_pos": 56, "end_pos": 92, "type": "TASK", "confidence": 0.6385071948170662}]}, {"text": "Following a brief review of the data sets used in section 6, corpus-based evaluation results are presented in section 7.", "labels": [], "entities": []}, {"text": "In order to assess the subjective performance of our system, a quality test and a pairwise preference test are presented in section 8.", "labels": [], "entities": []}, {"text": "The results show that the proposed adaptation recipe improves not only the objective scores but also the user's perceived quality of the system.", "labels": [], "entities": []}, {"text": "We conclude with a brief summary in section 9.", "labels": [], "entities": []}], "datasetContent": [{"text": "In order to test our proposed recipe for training multi-domain language generators, we conducted experiments using four different domains: finding a restaurant, finding a hotel, buying a laptop, and buying a television.", "labels": [], "entities": []}, {"text": "Datasets for the restaurant and hotel domains have been previously released by.", "labels": [], "entities": []}, {"text": "These were created by workers recruited by Amazon Mechanical Turk (AMT) by asking them to propose an appropriate natural language realisation corresponding to each system dialogue act actually generated by a dialogue system.", "labels": [], "entities": [{"text": "Amazon Mechanical Turk (AMT)", "start_pos": 43, "end_pos": 71, "type": "DATASET", "confidence": 0.9292619427045187}]}, {"text": "However, the number of actually occurring DA combinations in the restaurant and hotel domains were rather limited (\u223c200) and since multiple references were collected for each DA, the resulting datasets are not sufficiently diverse to enable the assessment of the generalisation capability of the different training methods over unseen semantic inputs.", "labels": [], "entities": []}, {"text": "In order to create more diverse datasets for the laptop and TV domains, we enumerated all possible combinations of dialogue act types and slots based on the ontology shown in.", "labels": [], "entities": []}, {"text": "This yielded  about 13K distinct DAs in the laptop domain and 7K distinct DAs in the TV domain.", "labels": [], "entities": []}, {"text": "We then used AMT workers to collect just one realisation for each DA.", "labels": [], "entities": [{"text": "DA", "start_pos": 66, "end_pos": 68, "type": "DATASET", "confidence": 0.6043862700462341}]}, {"text": "Since the resulting datasets have a much larger input space but only one training example for each DA, the system must learn partial realisations of concepts and be able to recombine and apply them to unseen DAs.", "labels": [], "entities": []}, {"text": "Also note that the number of act types and slots of the new ontology is larger, which makes NLG in both laptop and TV domains much harder.", "labels": [], "entities": []}, {"text": "We first assess generator performance using two objective evaluation metrics, the BLEU-4 score) and slot error rate ERR ().", "labels": [], "entities": [{"text": "BLEU-4 score", "start_pos": 82, "end_pos": 94, "type": "METRIC", "confidence": 0.9749607741832733}, {"text": "slot error rate ERR", "start_pos": 100, "end_pos": 119, "type": "METRIC", "confidence": 0.9151506274938583}]}, {"text": "Slot error rates were calculated by averaging slot errors over each of the top 5 realisations in the entire corpus.", "labels": [], "entities": [{"text": "Slot error", "start_pos": 0, "end_pos": 10, "type": "METRIC", "confidence": 0.5476335734128952}, {"text": "slot errors", "start_pos": 46, "end_pos": 57, "type": "METRIC", "confidence": 0.9523970782756805}]}, {"text": "We used multiple references to compute the BLEU scores when available (i.e. for the restaurant and hotel domains).", "labels": [], "entities": [{"text": "BLEU", "start_pos": 43, "end_pos": 47, "type": "METRIC", "confidence": 0.9985966086387634}]}, {"text": "In order to better compare results across different methods, we plotted the BLEU and slot error rate curves against different amounts of adaptation data.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 76, "end_pos": 80, "type": "METRIC", "confidence": 0.9990614056587219}, {"text": "slot error rate", "start_pos": 85, "end_pos": 100, "type": "METRIC", "confidence": 0.9126099149386088}]}, {"text": "Note that in the graphs the x-axis is presented on a log-scale.", "labels": [], "entities": []}, {"text": "The generators were implemented using the Theano library (, and trained by partitioning each of the collected corpora into a training, validation, and testing set in the ratio 3:1:1.", "labels": [], "entities": [{"text": "Theano library", "start_pos": 42, "end_pos": 56, "type": "DATASET", "confidence": 0.9693429172039032}]}, {"text": "All the generators were trained by treating each sentence as a mini-batch.", "labels": [], "entities": []}, {"text": "An l 2 regularisation term was added to the objective function for every 10 training examples.", "labels": [], "entities": []}, {"text": "The hidden layer size was set to be 100 for all cases.", "labels": [], "entities": []}, {"text": "Stochastic gradient descent and back propagation through time were used to optimise the parameters.", "labels": [], "entities": []}, {"text": "In order to prevent overfitting, early stopping was implemented using the validation set.", "labels": [], "entities": []}, {"text": "During decoding, we over-generated 20 utterances and selected the top 5 realisations for each DA according to the following reranking criteria, where \u03bb is a tradeoff constant, F (\u03b8) is the cost generated by network parameters \u03b8, and the slot error rate ERR is computed by exact matching of the slot tokens in the candidate utterances.", "labels": [], "entities": [{"text": "F (\u03b8)", "start_pos": 176, "end_pos": 181, "type": "METRIC", "confidence": 0.9437283128499985}, {"text": "slot error rate ERR", "start_pos": 237, "end_pos": 256, "type": "METRIC", "confidence": 0.796522781252861}]}, {"text": "\u03bb is set to a large value (10) in order to severely penalise nonsensical outputs.", "labels": [], "entities": []}, {"text": "Since our generator works stochastically and the trained networks can differ depending on the initialisation, all the results shown below were averaged over 5 randomly initialised networks.", "labels": [], "entities": []}, {"text": "Since automatic metrics may not consistently agree with human perception), human testing is needed to assess subjective quality.", "labels": [], "entities": []}, {"text": "To do: Human evaluation for utterance quality in two domains.", "labels": [], "entities": []}, {"text": "Results are shown in two metrics (rating out of 3).", "labels": [], "entities": []}, {"text": "Statistical significance was computed using a two-tailed Student's t-test, between the model trained with full data (scrALL) and all others.", "labels": [], "entities": [{"text": "significance", "start_pos": 12, "end_pos": 24, "type": "METRIC", "confidence": 0.6829342842102051}]}, {"text": "this, a set of judges were recruited using AMT.", "labels": [], "entities": [{"text": "AMT", "start_pos": 43, "end_pos": 46, "type": "DATASET", "confidence": 0.8160105347633362}]}, {"text": "We tested our models on two adaptation scenarios: laptop to TV and TV to laptop.", "labels": [], "entities": []}, {"text": "For each task, two systems among the four were compared: training from scratch using full dataset (scrALL), adapting with DT training but only 10% of target domain data (DT-10%), adapting with ML training but only 10% of target domain data (ML-10%), and training from scratch using only 10% of target domain data (scr-10%).", "labels": [], "entities": []}, {"text": "In order to evaluate system performance in the presence of language variation, each system generated 5 different surface realisations for each input DA and the human judges were asked to score each of them in terms of informativeness and naturalness (rating out of 3), and also asked to state a preference between the two.", "labels": [], "entities": []}, {"text": "Here informativeness is defined as whether the utterance contains all the information specified in the DA, and naturalness is defined as whether the utterance could plausibly have been produced by a human.", "labels": [], "entities": []}, {"text": "In order to decrease the amount of information presented to the judges, utterances that appeared identically in both systems were filtered out.", "labels": [], "entities": []}, {"text": "We tested about 2000 DAs for each scenario distributed uniformly between contrasts except that allowed 50% more comparisons between ML-10% and DT-10% because they were close.", "labels": [], "entities": [{"text": "ML-10", "start_pos": 132, "end_pos": 137, "type": "METRIC", "confidence": 0.7543262243270874}]}, {"text": "shows the subjective quality assessments which exhibit the same general trend as the objective results.", "labels": [], "entities": []}, {"text": "If a large amount of target domain data is available, training everything from scratch (scrALL) achieves a very good performance and adaptation is not necessary.", "labels": [], "entities": []}, {"text": "However, if only a limited amount of in-domain data is available, efficient adaptation is critical (DT-10% & ML-10% > scr-10%).", "labels": [], "entities": [{"text": "DT-10", "start_pos": 100, "end_pos": 105, "type": "METRIC", "confidence": 0.8647244572639465}, {"text": "ML-10", "start_pos": 109, "end_pos": 114, "type": "METRIC", "confidence": 0.803508460521698}]}, {"text": "More-: Pairwise preference test among four approaches in two domains.", "labels": [], "entities": []}, {"text": "Statistical significance was computed using two-tailed binomial test.", "labels": [], "entities": [{"text": "significance", "start_pos": 12, "end_pos": 24, "type": "METRIC", "confidence": 0.6191837191581726}]}, {"text": "over, judges also preferred the DT trained generator (DT-10%) compared to the ML trained generator (ML-10%), especially for informativeness.", "labels": [], "entities": []}, {"text": "In the laptop to TV scenario, the informativeness score of DT method (DT-10%) was considered indistinguishable when comparing to the method trained with full training set (scrALL).", "labels": [], "entities": []}, {"text": "The preference test results are shown in.", "labels": [], "entities": []}, {"text": "Again, adaptation methods (DT-10% & ML-10%) are crucial to bridge the gap between domains when the target domain data is scarce (DT-10% & ML-10% > scr-10%).", "labels": [], "entities": []}, {"text": "The results also suggest that the DT training approach (DT-10%) was preferred compared to ML training (ML-10%), even though the preference in this case was not statistically significant.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Human evaluation for utterance quality in  two domains. Results are shown in two metrics  (rating out of 3). Statistical significance was com- puted using a two-tailed Student's t-test, between the  model trained with full data (scrALL) and all others.", "labels": [], "entities": [{"text": "Statistical significance", "start_pos": 119, "end_pos": 143, "type": "METRIC", "confidence": 0.7703395187854767}]}, {"text": " Table 3: Pairwise preference test among four ap- proaches in two domains. Statistical significance  was computed using two-tailed binomial test.", "labels": [], "entities": [{"text": "Statistical significance", "start_pos": 75, "end_pos": 99, "type": "METRIC", "confidence": 0.8565855324268341}]}]}