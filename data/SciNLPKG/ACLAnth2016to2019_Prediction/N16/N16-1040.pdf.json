{"title": [], "abstractContent": [{"text": "Idioms pose a great challenge to natural language understanding.", "labels": [], "entities": [{"text": "natural language understanding", "start_pos": 33, "end_pos": 63, "type": "TASK", "confidence": 0.6741026739279429}]}, {"text": "A system that can automatically paraphrase idioms in context has applications in many NLP tasks.", "labels": [], "entities": []}, {"text": "This paper proposes a phrasal substitution method to replace idioms with their figurative meanings in literal English.", "labels": [], "entities": []}, {"text": "Our approach identifies relevant replacement phrases from an idiom's dictionary definition and performs appropriate grammatical and referential transformations to ensure that the idiom substitution fits seamlessly into the original context.", "labels": [], "entities": []}, {"text": "The proposed method has been evaluated both by automatic metrics and human judgments.", "labels": [], "entities": []}, {"text": "Results suggest that high quality paraphrases of idiomatic expressions can be achieved.", "labels": [], "entities": []}], "introductionContent": [{"text": "An idiom is a combination of words that has a figurative meaning which differs from its literal meaning.", "labels": [], "entities": []}, {"text": "Idioms pose a great challenge to many NLP tasks, such as machine translation, word sense disambiguation, and sentiment analysis.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 57, "end_pos": 76, "type": "TASK", "confidence": 0.8144445717334747}, {"text": "word sense disambiguation", "start_pos": 78, "end_pos": 103, "type": "TASK", "confidence": 0.7190687656402588}, {"text": "sentiment analysis", "start_pos": 109, "end_pos": 127, "type": "TASK", "confidence": 0.9592244923114777}]}, {"text": "Previous work () has shown that atypical statistical machine translation system might achieve only half of the BLEU score () on sentences that contain idiomatic expressions than on those that do not.", "labels": [], "entities": [{"text": "statistical machine translation", "start_pos": 41, "end_pos": 72, "type": "TASK", "confidence": 0.6322081784407297}, {"text": "BLEU score", "start_pos": 111, "end_pos": 121, "type": "METRIC", "confidence": 0.9905690550804138}]}, {"text": "Idioms are also problematic for second language learners.", "labels": [], "entities": []}, {"text": "Ina pilot study we have surveyed seven non-native speakers on 100 Tweets containing idioms; we have found that, on average, the participants had trouble understanding 70% of them due to the inclusion of idioms.", "labels": [], "entities": []}, {"text": "This work explores the possibility of automatically replacing idiomatic expressions in sentences.", "labels": [], "entities": []}, {"text": "The full pipeline of a successful system has to solve many problems.", "labels": [], "entities": []}, {"text": "First, it has to determine that an expression is, in fact, being used as an idiom in a sentence.", "labels": [], "entities": []}, {"text": "Moreover, the system has to sense disambiguate the idiom -it has to pick the correct interpretation when more than one is possible.", "labels": [], "entities": []}, {"text": "Second, it has to generate an appropriate phrasal replacement for the idiom using literal English.", "labels": [], "entities": []}, {"text": "Third, it has to ensure that the replacement phrase will fit seamlessly back into the original sentence.", "labels": [], "entities": []}, {"text": "This paper focuses on the second and third problem, which have not been studied as extensively in previous works.", "labels": [], "entities": []}, {"text": "We propose to extract the phrasal replacement for an idiom from its definition, assuming the existence of an up-to-date dictionary of broad coverage and high quality.", "labels": [], "entities": []}, {"text": "Because atypical definition is quite long, it cannot directly serve as a replacement for the idiom.", "labels": [], "entities": []}, {"text": "A major challenge of our work is in identifying the right nugget to extract from the definition.", "labels": [], "entities": []}, {"text": "Another major challenge is the smooth integration of the substitution phrase into the sentence.", "labels": [], "entities": []}, {"text": "We consider both grammatical fluency as well as references resolution in our automatic Post-Editing technique.", "labels": [], "entities": [{"text": "references resolution", "start_pos": 48, "end_pos": 69, "type": "TASK", "confidence": 0.793439656496048}]}, {"text": "These phrasal challenges set our goals apart from related work on lexical simplification and substitution () and from general sentence simplification) methods.", "labels": [], "entities": []}, {"text": "We validate the plausibility of the proposed methods with empirical experiments on a manually annotated corpus.", "labels": [], "entities": []}, {"text": "Results from both automatic evaluations and user studies show that the proposed approach can generate high-quality paraphrases of sentences containing idiomatic expressions.", "labels": [], "entities": []}, {"text": "A successful idiom paraphrase generator may not only benefit non-native speakers, but may also facilitate other NLP applications.", "labels": [], "entities": []}], "datasetContent": [{"text": "To determine the performance of the definition shortening methods and post editing operations, we have carried out two experiments.", "labels": [], "entities": [{"text": "definition shortening", "start_pos": 36, "end_pos": 57, "type": "TASK", "confidence": 0.821895182132721}]}, {"text": "The first (Section 4.2) evaluates the quality of the substitution generation methods; we also argument the evaluation with statistical analysis of post-editing as a reference for future work.", "labels": [], "entities": [{"text": "substitution generation", "start_pos": 53, "end_pos": 76, "type": "TASK", "confidence": 0.8906430900096893}]}, {"text": "The second (Section 4.3) evaluates whether the resulting paraphrased sentence is grammatical and preserves the original meaning.", "labels": [], "entities": []}, {"text": "In this experiment, we compare different approaches for substitution generation using automatic metrics.", "labels": [], "entities": [{"text": "substitution generation", "start_pos": 56, "end_pos": 79, "type": "TASK", "confidence": 0.9532963037490845}]}, {"text": "We wish to determine: 1) How well does each method replicate human annotators' phrasal extractions?", "labels": [], "entities": [{"text": "replicate human annotators' phrasal extractions", "start_pos": 51, "end_pos": 98, "type": "TASK", "confidence": 0.7454815864562988}]}, {"text": "2) Do we need specialized methods for extracting core meanings from idiom definitions?", "labels": [], "entities": [{"text": "extracting core meanings from idiom definitions", "start_pos": 38, "end_pos": 85, "type": "TASK", "confidence": 0.8103009959061941}]}, {"text": "3) Is the ML-based method more general and flexible?", "labels": [], "entities": []}, {"text": "The training data contains 88 definitions fora total of 645 chunks that have been labeled as \"keep\" or \"discard\" according to the gold standards.", "labels": [], "entities": []}, {"text": "The test data consists of 84 unique idioms used in tweets.", "labels": [], "entities": []}, {"text": "The evaluation metric is the minimum edit distance of each proposed substitution from the gold standard.", "labels": [], "entities": [{"text": "edit distance", "start_pos": 37, "end_pos": 50, "type": "METRIC", "confidence": 0.9670099020004272}]}, {"text": "We also calculate the compression rate, the ratio between numbers of tokens kept with total numbers of tokens in original sentence.", "labels": [], "entities": [{"text": "compression rate", "start_pos": 22, "end_pos": 38, "type": "METRIC", "confidence": 0.9642945230007172}]}, {"text": "We compare our proposed methods with McDonald (2006).", "labels": [], "entities": []}, {"text": "Specifically we use an adapted version described in.", "labels": [], "entities": []}, {"text": "We also implemented two simpler baselines: Equal-POS: Extract those words from the definition that have the same POS tags as the idiom.", "labels": [], "entities": []}, {"text": "For example, if the idiom consists of a VB and an NN, then the first two words tagged as VB and NN in the definition are returned as the substitution.", "labels": [], "entities": []}, {"text": "When POS matching fails, the whole definition is returned.", "labels": [], "entities": [{"text": "POS matching", "start_pos": 5, "end_pos": 17, "type": "TASK", "confidence": 0.786153644323349}]}, {"text": "First-Six: Always return the first six words.", "labels": [], "entities": []}, {"text": "We choose six because the average length of the gold standard extractions from the training set is six words long.", "labels": [], "entities": []}, {"text": "From the results presented in, we see that the problem of extracting the core explanation from along definition is not trivial.", "labels": [], "entities": []}, {"text": "The average minimum edit distances from the gold standard are high for the two simple baselines (6.29 for First-Six, 4.92 for Equal-POS).", "labels": [], "entities": [{"text": "edit distances", "start_pos": 20, "end_pos": 34, "type": "METRIC", "confidence": 0.9651257991790771}, {"text": "Equal-POS", "start_pos": 126, "end_pos": 135, "type": "METRIC", "confidence": 0.9542843699455261}]}, {"text": "The text compression baseline, McDonald, is only a little better, at 4.86.", "labels": [], "entities": []}, {"text": "Because the proposed methods are developed especially for idiom definitions, they are closer to the gold standard.", "labels": [], "entities": [{"text": "idiom definitions", "start_pos": 58, "end_pos": 75, "type": "TASK", "confidence": 0.7271369993686676}]}, {"text": "Considering the inter-annotator agreement as an upper-bound (with an average minimum edit distance of 2.15 for the test set), the ML-based approach comes the closest to the upper-bound (with an average distance of 2.75).: A comparison of different substitution generation methods with gold standard.", "labels": [], "entities": [{"text": "substitution generation", "start_pos": 248, "end_pos": 271, "type": "TASK", "confidence": 0.8566153943538666}]}, {"text": "M EDavg denotes the average minimum edit distance of the method's extraction from the gold standard.", "labels": [], "entities": [{"text": "M EDavg", "start_pos": 0, "end_pos": 7, "type": "METRIC", "confidence": 0.8215038180351257}, {"text": "edit distance", "start_pos": 36, "end_pos": 49, "type": "METRIC", "confidence": 0.9361429512500763}]}, {"text": "Figure 1 plots a distribution of each method's minimum edit distances for the instances in the test set.", "labels": [], "entities": []}, {"text": "While the rule-based approach has a similar distribution as the trained classifier, it is almost always slightly worse.", "labels": [], "entities": []}, {"text": "We see that half of the extractions based on the keep/discard classification are within a one word difference from the gold standard, and there are fewer than five instances for which the edit distance is at least 10; in contrast, the rule-based approach has fewer cases of (nearly) perfect matches and more cases of large mismatches (with the exception of an edit distance of 9).", "labels": [], "entities": []}, {"text": "These results suggest that specialized methods are necessary for processing idiom definitions and that an ML-based approach is more general and flexible.", "labels": [], "entities": [{"text": "processing idiom definitions", "start_pos": 65, "end_pos": 93, "type": "TASK", "confidence": 0.7584276795387268}]}, {"text": "Minimum edit distance to the gold standard cannot fully indicate the grammaticality and meaning preservation of the extracted phrase.", "labels": [], "entities": []}, {"text": "In this experiment, we follow standard human evaluation procedures) to verify our findings from the first experiment.", "labels": [], "entities": []}, {"text": "The results will answer two questions: 1) Are the shortened definitions grammatical and are they representative of the core meanings?", "labels": [], "entities": []}, {"text": "2) Are the final paraphrased sentences grammatical and do they retain their original meanings?", "labels": [], "entities": []}, {"text": "We used the same 84 idioms which were the test set in the automatic evaluation.", "labels": [], "entities": []}, {"text": "Four native speakers were recruited to evaluate the grammaticality and meaning of the shortened definitions and paraphrased sentences on a five-point scale.", "labels": [], "entities": []}, {"text": "Each person took approximately 90 minutes to finish the study.", "labels": [], "entities": []}, {"text": "We did not evaluate the simple baselines (First-Six and Equal-POS) because their qualities were obvi-ously low; including them may bias the human subjects to give inflated scores to the better methods.", "labels": [], "entities": [{"text": "Equal-POS", "start_pos": 56, "end_pos": 65, "type": "METRIC", "confidence": 0.9802700281143188}]}, {"text": "The results are presented in.", "labels": [], "entities": []}, {"text": "In terms of shortening the definition, the rulebased method obtains the highest scores in both grammaticality and meaning; this is because it tends to be relatively conservative.", "labels": [], "entities": []}, {"text": "The compression rate is 59%, while the ML-based method is 51%.", "labels": [], "entities": [{"text": "compression rate", "start_pos": 4, "end_pos": 20, "type": "METRIC", "confidence": 0.9603721499443054}]}, {"text": "Keeping more words in the definition reduces the chance of introducing grammar error and meaning loss; however, a longer definition makes poorer substitution in the full sentence because it introduces redundancy and thwarts post-editing efforts.", "labels": [], "entities": []}, {"text": "This is validated in our experimental results -in terms of the paraphrased sentences, the rule-based method is outperformed by the ML-based method, which achieves the best result, with 4.61 in grammaticality and 4.64 in meaning.", "labels": [], "entities": []}, {"text": "shows some typical examples of the paraphrases produced using substitution generation from the ML-based method, the rule-based method, and the McDonald method followed by processing with the proposed post-editing techniques.", "labels": [], "entities": [{"text": "substitution generation", "start_pos": 62, "end_pos": 85, "type": "TASK", "confidence": 0.7174848914146423}]}, {"text": "The first example features the effect of boundary smoothing.", "labels": [], "entities": [{"text": "boundary smoothing", "start_pos": 41, "end_pos": 59, "type": "TASK", "confidence": 0.7347172796726227}]}, {"text": "The shortened definition from the ML-based method is work together to.", "labels": [], "entities": []}, {"text": "Direct replacement into the original sentence creates a disfluent bigram \"working work\", which has a probability of 0; thus the first word in the shortened definition (work) is deleted automatically.", "labels": [], "entities": []}, {"text": "Similarly, the word to is deleted for the right boundary.", "labels": [], "entities": []}, {"text": "In the third example, an automatic grammar adjustment is applied during substitution: a temporary solution is converted to Temporary solutions to keep the number consistent.", "labels": [], "entities": []}, {"text": "In the forth example, the reference they is successfully resolved to you in the definition.", "labels": [], "entities": []}, {"text": "The fifth example features a challenging rare case that results in a failed reference resolution.", "labels": [], "entities": [{"text": "reference resolution", "start_pos": 76, "end_pos": 96, "type": "TASK", "confidence": 0.7511110901832581}]}, {"text": "Shortening the definition is a trade off between length and meaning.", "labels": [], "entities": [{"text": "length", "start_pos": 49, "end_pos": 55, "type": "METRIC", "confidence": 0.9577960968017578}]}, {"text": "In these examples, the rulebased method keeps as many words as possible from the definition and leads to redundancy in the final output.", "labels": [], "entities": []}, {"text": "It has a negative impact on the readability of the paraphrase.", "labels": [], "entities": []}, {"text": "The McDonald method is too aggressive for short text such as definition, so the outputs are often discontinuous.", "labels": [], "entities": []}, {"text": "The ML-based method offers a reasonable balance between length and meaning, and produces paraphrases that people seem to prefer.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 3: Agreement between the two annotators. MEDavg rep-", "labels": [], "entities": [{"text": "MEDavg rep", "start_pos": 48, "end_pos": 58, "type": "DATASET", "confidence": 0.868595689535141}]}, {"text": " Table 4: A comparison of different substitution generation methods with gold standard. M EDavg denotes the average minimum", "labels": [], "entities": [{"text": "substitution generation", "start_pos": 36, "end_pos": 59, "type": "TASK", "confidence": 0.8912884593009949}, {"text": "M EDavg", "start_pos": 88, "end_pos": 95, "type": "METRIC", "confidence": 0.7907693386077881}]}]}