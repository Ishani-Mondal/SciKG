{"title": [{"text": "Multilingual Relation Extraction using Compositional Universal Schema", "labels": [], "entities": [{"text": "Multilingual Relation Extraction", "start_pos": 0, "end_pos": 32, "type": "TASK", "confidence": 0.852492113908132}]}], "abstractContent": [{"text": "Universal schema builds a knowledge base (KB) of entities and relations by jointly embedding all relation types from input KBs as well as textual patterns observed in raw text.", "labels": [], "entities": []}, {"text": "In most previous applications of universal schema, each textual pattern is represented as a single embedding, preventing generalization to unseen patterns.", "labels": [], "entities": []}, {"text": "Recent work employs a neural network to capture patterns' compositional semantics, providing generalization to all possible input text.", "labels": [], "entities": []}, {"text": "In response, this paper introduces significant further improvements to the coverage and flexibility of universal schema relation extraction: predictions for entities unseen in training and multilingual transfer learning to domains with no annotation.", "labels": [], "entities": [{"text": "universal schema relation extraction", "start_pos": 103, "end_pos": 139, "type": "TASK", "confidence": 0.6261420026421547}]}, {"text": "We evaluate our model through extensive experiments on the English and Spanish TAC KBP benchmark, outperforming the top system from TAC 2013 slot-filling using no handwritten patterns or additional annotation.", "labels": [], "entities": [{"text": "English and Spanish TAC KBP benchmark", "start_pos": 59, "end_pos": 96, "type": "DATASET", "confidence": 0.6466451833645502}, {"text": "TAC 2013 slot-filling", "start_pos": 132, "end_pos": 153, "type": "DATASET", "confidence": 0.8309668302536011}]}, {"text": "We also consider a multilingual setting in which English training data entities overlap with the seed KB, but Spanish text does not.", "labels": [], "entities": []}, {"text": "Despite having no annotation for Spanish data, we train an accurate predictor, with additional improvements obtained by tying word embeddings across languages.", "labels": [], "entities": []}, {"text": "Furthermore, we find that multilingual training improves English relation extraction accuracy.", "labels": [], "entities": [{"text": "English relation extraction", "start_pos": 57, "end_pos": 84, "type": "TASK", "confidence": 0.6835059920946757}, {"text": "accuracy", "start_pos": 85, "end_pos": 93, "type": "METRIC", "confidence": 0.8833996653556824}]}, {"text": "Our approach is thus suited to broad-coverage automated knowledge base construction in a variety of languages and domains.", "labels": [], "entities": [{"text": "broad-coverage automated knowledge base construction", "start_pos": 31, "end_pos": 83, "type": "TASK", "confidence": 0.5620762646198273}]}], "introductionContent": [{"text": "The goal of automatic knowledge base construction (AKBC) is to build a structured knowledge base (KB) of facts using a noisy corpus of raw text evidence, and perhaps an initial seed KB to be augmented.", "labels": [], "entities": [{"text": "automatic knowledge base construction (AKBC)", "start_pos": 12, "end_pos": 56, "type": "TASK", "confidence": 0.7866238355636597}]}, {"text": "AKBC supports downstream reasoning at a high level about extracted entities and their relations, and thus has broad-reaching applications to a variety of domains.", "labels": [], "entities": [{"text": "AKBC", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.9149527549743652}]}, {"text": "One challenge in AKBC is aligning knowledge from a structured KB with a text corpus in order to perform supervised learning through distant supervision.", "labels": [], "entities": []}, {"text": "Universal schema ( ) along with its extensions (, avoids alignment by jointly embedding KB relations, entities, and surface text patterns.", "labels": [], "entities": []}, {"text": "This propagates information between KB annotation and corresponding textual evidence.", "labels": [], "entities": []}, {"text": "The above applications of universal schema express each text relation as a distinct item to be embedded.", "labels": [], "entities": []}, {"text": "This harms its ability to generalize to inputs not precisely seen at training time.", "labels": [], "entities": []}, {"text": "Recently, addressed this issue by embedding text patterns using a deep sentence encoder, which captures the compositional semantics of textual relations and allows for prediction on inputs never seen before.", "labels": [], "entities": []}, {"text": "This paper further expands the coverage abilities of universal schema relation extraction by introducing techniques for forming predictions for new entities unseen in training and even for new domains with no associated annotation.", "labels": [], "entities": [{"text": "universal schema relation extraction", "start_pos": 53, "end_pos": 89, "type": "TASK", "confidence": 0.6718038693070412}]}, {"text": "In the extreme example of domain adaptation to a completely new language, we may have limited linguistic resources or labeled data such as treebanks, and only rarely a KB with adequate coverage.", "labels": [], "entities": [{"text": "domain adaptation", "start_pos": 26, "end_pos": 43, "type": "TASK", "confidence": 0.7345489263534546}]}, {"text": "Our method performs multilingual transfer learning, providing a predictive model fora language with no coverage in an existing KB, by leveraging common representations for shared entities across text corpora.", "labels": [], "entities": [{"text": "multilingual transfer learning", "start_pos": 20, "end_pos": 50, "type": "TASK", "confidence": 0.7586433986822764}]}, {"text": "As depicted in, we simply require that one language have an available KB of seed facts.", "labels": [], "entities": []}, {"text": "We can further improve our models by tying a small set of word embeddings across languages using only simple knowledge about word-level translations, learning to embed semantically similar textual patterns from different languages into the same latent space.", "labels": [], "entities": []}, {"text": "In extensive experiments on the TAC Knowledge Base Population (KBP) slot-filling benchmark we outperform the top 2013 system with an F1 score of 40.7 and perform relation extraction in Spanish with no labeled data or direct overlap between the Spanish training corpus and the training KB, demonstrating that our approach is wellsuited for broad-coverage AKBC in low-resource languages and domains.", "labels": [], "entities": [{"text": "TAC Knowledge Base Population (KBP) slot-filling benchmark", "start_pos": 32, "end_pos": 90, "type": "DATASET", "confidence": 0.8051679399278429}, {"text": "F1 score", "start_pos": 133, "end_pos": 141, "type": "METRIC", "confidence": 0.979752242565155}, {"text": "relation extraction", "start_pos": 162, "end_pos": 181, "type": "TASK", "confidence": 0.8525211215019226}]}, {"text": "Interestingly, joint training with Spanish improves English accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 60, "end_pos": 68, "type": "METRIC", "confidence": 0.9847522377967834}]}, {"text": "English Low-resource in KB not in KB: Splitting the entities in a multilingual AKBC training set into parts.", "labels": [], "entities": [{"text": "AKBC training set", "start_pos": 79, "end_pos": 96, "type": "DATASET", "confidence": 0.6911133130391439}]}, {"text": "We only require that entities in the two corpora overlap.", "labels": [], "entities": []}, {"text": "Remarkably, we can train a model for the low-resource language even if entities in the lowresource language do not occur in the KB.", "labels": [], "entities": []}], "datasetContent": [{"text": "In experiments on the English and Spanish TAC KBC slot-filling tasks, we find that both USchema and LSTM models outperform the CNN across languages, and that the LSTM tends to perform slightly better than USchema as the only model.", "labels": [], "entities": [{"text": "USchema", "start_pos": 88, "end_pos": 95, "type": "DATASET", "confidence": 0.8969146609306335}, {"text": "USchema", "start_pos": 205, "end_pos": 212, "type": "DATASET", "confidence": 0.9378010630607605}]}, {"text": "Ensembling the LSTM and USchema models further increases final F1 scores in all experiments, suggesting that the two different types of model compliment each other well.", "labels": [], "entities": [{"text": "USchema", "start_pos": 24, "end_pos": 31, "type": "DATASET", "confidence": 0.8386648893356323}, {"text": "F1 scores", "start_pos": 63, "end_pos": 72, "type": "METRIC", "confidence": 0.8772366046905518}]}, {"text": "Indeed, in Section 5.3 we present quantitative and qualitative analysis of our results which further confirms this hypothesis: the LSTM and USchema models each perform better on different pattern lengths and are characterized by different precision-recall tradeoffs.", "labels": [], "entities": [{"text": "USchema", "start_pos": 140, "end_pos": 147, "type": "DATASET", "confidence": 0.877245306968689}]}, {"text": "We also demonstrate the effect of jointly learning English and Spanish models on English slot-filling performance.", "labels": [], "entities": []}, {"text": "Adding Spanish data improves our F1 scores by 1.5 points on 2013 and 1.1 on 2014 over using English alone.", "labels": [], "entities": [{"text": "F1 scores", "start_pos": 33, "end_pos": 42, "type": "METRIC", "confidence": 0.9797661304473877}]}, {"text": "This places are system higher than the top performer at the 2013 TAC slot-filling task even though our system uses no hand-written rules.", "labels": [], "entities": [{"text": "2013 TAC slot-filling task", "start_pos": 60, "end_pos": 86, "type": "DATASET", "confidence": 0.6004342511296272}]}], "tableCaptions": [{"text": " Table 2: Precision, recall and F1 on the English TAC  2013 slot-filling task. AN refers to alternative names  heuristic and Es refers to the addition of Spanish text at  train time. LSTM+USchema ensemble outperforms any  single model, including the highly-tuned top 2013 sys- tem of Roth et al. (2014), despite using no handwritten  patterns.", "labels": [], "entities": [{"text": "Precision", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9941704273223877}, {"text": "recall", "start_pos": 21, "end_pos": 27, "type": "METRIC", "confidence": 0.9985798597335815}, {"text": "F1", "start_pos": 32, "end_pos": 34, "type": "METRIC", "confidence": 0.999451220035553}, {"text": "English TAC  2013 slot-filling task", "start_pos": 42, "end_pos": 77, "type": "DATASET", "confidence": 0.7264128923416138}, {"text": "AN", "start_pos": 79, "end_pos": 81, "type": "METRIC", "confidence": 0.9983434677124023}, {"text": "Es", "start_pos": 125, "end_pos": 127, "type": "METRIC", "confidence": 0.9526692628860474}]}, {"text": " Table 3: Precision, recall and F1 on the English TAC  2014 slot-filling task. Es refers to the addition of Span- ish text at train time. The AN heuristic is ineffective on  2014 adding only 0.2 to F1. Our system would rank 4/18  in the official TAC 2014 competition behind systems that  use hand-written patterns and active learning despite our  system using neither of these additional annotations (Sur- deanu and Ji., 2014).", "labels": [], "entities": [{"text": "Precision", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9912200570106506}, {"text": "recall", "start_pos": 21, "end_pos": 27, "type": "METRIC", "confidence": 0.9984661340713501}, {"text": "F1", "start_pos": 32, "end_pos": 34, "type": "METRIC", "confidence": 0.9996469020843506}, {"text": "English TAC  2014 slot-filling task", "start_pos": 42, "end_pos": 77, "type": "DATASET", "confidence": 0.736791443824768}, {"text": "Es", "start_pos": 79, "end_pos": 81, "type": "METRIC", "confidence": 0.9907367825508118}, {"text": "AN", "start_pos": 142, "end_pos": 144, "type": "METRIC", "confidence": 0.991138756275177}, {"text": "F1", "start_pos": 198, "end_pos": 200, "type": "METRIC", "confidence": 0.9921467900276184}]}, {"text": " Table 4: Zero-annotation transfer learning F1 scores on  2012 Spanish TAC KBP slot-filling task. Adding a trans- lation dictionary improves all encoder-based models. En- sembling LSTM and USchema models performs the best.", "labels": [], "entities": [{"text": "Zero-annotation transfer learning", "start_pos": 10, "end_pos": 43, "type": "TASK", "confidence": 0.7705082893371582}, {"text": "F1", "start_pos": 44, "end_pos": 46, "type": "METRIC", "confidence": 0.8304249048233032}, {"text": "2012 Spanish TAC KBP slot-filling task", "start_pos": 58, "end_pos": 96, "type": "DATASET", "confidence": 0.8763469556967417}, {"text": "USchema", "start_pos": 189, "end_pos": 196, "type": "DATASET", "confidence": 0.8801318407058716}]}, {"text": " Table 5: Example English query words (not in translation  dictionary) in bold with their top nearest neighbors by co- sine similarity listed for the dictionary and no ties LSTM  variants. Dictionary-tied nearest neighbors are consis- tently more relevant to the query word than untied.", "labels": [], "entities": [{"text": "LSTM", "start_pos": 173, "end_pos": 177, "type": "METRIC", "confidence": 0.8474456071853638}]}]}