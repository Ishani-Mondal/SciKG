{"title": [{"text": "What to talk about and how? Selective Generation using LSTMs with Coarse-to-Fine Alignment", "labels": [], "entities": [{"text": "Selective Generation", "start_pos": 28, "end_pos": 48, "type": "TASK", "confidence": 0.9150485694408417}]}], "abstractContent": [{"text": "We propose an end-to-end, domain-independent neural encoder-aligner-decoder model for selective generation, i.e., the joint task of content selection and surface realization.", "labels": [], "entities": [{"text": "surface realization", "start_pos": 154, "end_pos": 173, "type": "TASK", "confidence": 0.7500170767307281}]}, {"text": "Our model first encodes a full set of over-determined database event records via an LSTM-based recurrent neural network, then utilizes a novel coarse-to-fine aligner to identify the small subset of salient records to talk about, and finally employs a decoder to generate free-form descriptions of the aligned, selected records.", "labels": [], "entities": []}, {"text": "Our model achieves the best selection and generation results reported to-date (with 59% relative improvement in generation) on the benchmark WEATHER-GOV dataset, despite using no specialized features or linguistic resources.", "labels": [], "entities": [{"text": "WEATHER-GOV dataset", "start_pos": 141, "end_pos": 160, "type": "DATASET", "confidence": 0.9502076506614685}]}, {"text": "Using an improved k-nearest neighbor beam filter helps further.", "labels": [], "entities": []}, {"text": "We also perform a series of ablations and visualizations to elucidate the contributions of our key model components.", "labels": [], "entities": []}, {"text": "Lastly, we evaluate the generalizability of our model on the ROBOCUP dataset, and get results that are competitive with or better than the state-of-the-art, despite being severely data-starved.", "labels": [], "entities": [{"text": "ROBOCUP dataset", "start_pos": 61, "end_pos": 76, "type": "DATASET", "confidence": 0.859992653131485}]}], "introductionContent": [{"text": "We consider the important task of producing a natural language description of a rich world state represented as an over-determined database of event records.", "labels": [], "entities": []}, {"text": "This task, which we refer to as selective generation, is often formulated as two subproblems: content selection, which involves choosing a subset of relevant records to talk about from the exhaustive database, and surface realization, which is concerned with generating natural language descriptions for this subset.", "labels": [], "entities": [{"text": "selective generation", "start_pos": 32, "end_pos": 52, "type": "TASK", "confidence": 0.7919802963733673}, {"text": "content selection", "start_pos": 94, "end_pos": 111, "type": "TASK", "confidence": 0.6855230927467346}, {"text": "surface realization", "start_pos": 214, "end_pos": 233, "type": "TASK", "confidence": 0.750685840845108}]}, {"text": "Learning to perform these tasks jointly is challenging due to the uncertainty in deciding which records are relevant, the complex dependencies between selected records, and the multiple ways in which these records can be described.", "labels": [], "entities": []}, {"text": "Previous work has made significant progress on this task).", "labels": [], "entities": []}, {"text": "However, most approaches solve the two content selection and surface realization subtasks separately, use manual domain-dependent resources (e.g., semantic parsers) and features, or employ template-based generation.", "labels": [], "entities": [{"text": "content selection and surface realization subtasks", "start_pos": 39, "end_pos": 89, "type": "TASK", "confidence": 0.6820839842160543}]}, {"text": "This limits domain adaptability and reduces coherence.", "labels": [], "entities": []}, {"text": "We take an alternative, neural encoder-aligner-decoder approach to free-form selective generation that jointly performs content selection and surface realization, without using any specialized features, resources, or generation templates.", "labels": [], "entities": [{"text": "free-form selective generation", "start_pos": 67, "end_pos": 97, "type": "TASK", "confidence": 0.7107201814651489}, {"text": "surface realization", "start_pos": 142, "end_pos": 161, "type": "TASK", "confidence": 0.7878629565238953}]}, {"text": "This enables our approach to generalize to new domains.", "labels": [], "entities": []}, {"text": "Further, our memorybased model captures the long-range contextual dependencies among records and descriptions, which are integral to this task (.", "labels": [], "entities": []}, {"text": "We formulate our model as an encoder-alignerdecoder framework that uses recurrent neural networks with long short-term memory units (LSTMRNNs)) together with a coarse-to-fine aligner to select and \"translate\" the rich world state into a natural language description.", "labels": [], "entities": []}, {"text": "Our model first encodes the full set of over-determined 1 event records using a bidirectional LSTM-RNN.", "labels": [], "entities": []}, {"text": "A novel coarse-to-fine aligner then reasons over multiple abstractions of the input to decide which of the records to discuss.", "labels": [], "entities": []}, {"text": "The model next employs an LSTM decoder to gen-erate natural language descriptions of the selected records.", "labels": [], "entities": []}, {"text": "The use of LSTMs, which have proven effective for similar long-range generation tasks), allows our model to capture the longrange contextual dependencies that exist in selective generation.", "labels": [], "entities": []}, {"text": "Further, the introduction of our proposed variation on alignment-based LSTMs () enables our model to learn to perform content selection and surface realization jointly, by aligning each generated word to an event record during decoding.", "labels": [], "entities": [{"text": "surface realization", "start_pos": 140, "end_pos": 159, "type": "TASK", "confidence": 0.7346298694610596}]}, {"text": "Our novel coarse-to-fine aligner avoids searching over the full set of over-determined records by employing two stages of increasing complexity: a pre-selector and a refiner acting on multiple abstractions (low-and high-level) of the record input.", "labels": [], "entities": []}, {"text": "The end-to-end nature of our framework has the advantage that it can be trained directly on corpora of record sets paired with natural language descriptions, without the need for ground-truth content selection.", "labels": [], "entities": []}, {"text": "We evaluate our model on a benchmark weather forecasting dataset (WEATHERGOV) and achieve the best results reported to-date on content selection (12% relative improvement in F-1) and language generation (59% relative improvement in BLEU), despite using no domain-specific resources.", "labels": [], "entities": [{"text": "language generation", "start_pos": 183, "end_pos": 202, "type": "TASK", "confidence": 0.7596397995948792}, {"text": "BLEU", "start_pos": 232, "end_pos": 236, "type": "METRIC", "confidence": 0.997344434261322}]}, {"text": "We also perform a series of ablations and visualizations to elucidate the contributions of the primary model components, and also show improvements with a simple, k-nearest neighbor beam filter approach.", "labels": [], "entities": []}, {"text": "Finally, we demonstrate the generalizability of our model by directly applying it to a benchmark sportscasting dataset (ROBOCUP), where we get results competitive with or better than state-of-the-art, despite being extremely data-starved.", "labels": [], "entities": []}], "datasetContent": [{"text": "Datasets We analyze our model on the benchmark WEATHERGOV dataset, and use the data-starved ROBOCUP dataset to demonstrate the model's generalizability.", "labels": [], "entities": [{"text": "WEATHERGOV dataset", "start_pos": 47, "end_pos": 65, "type": "DATASET", "confidence": 0.9459239840507507}, {"text": "ROBOCUP dataset", "start_pos": 92, "end_pos": 107, "type": "DATASET", "confidence": 0.7058371603488922}]}, {"text": "Following, we use WEATHERGOV training, development, and test splits of size 25000, 1000, and 3528, respectively.", "labels": [], "entities": []}, {"text": "For ROBOCUP, we follow the evaluation methodology of previous work, performing three-fold cross-validation whereby we train on three games (approximately 1000 scenarios) and test on the fourth.", "labels": [], "entities": [{"text": "ROBOCUP", "start_pos": 4, "end_pos": 11, "type": "TASK", "confidence": 0.5486443638801575}]}, {"text": "Within each split, we holdout 10% of the training data as the development set to tune the early-stopping criterion and \u03b3.", "labels": [], "entities": []}, {"text": "We then report the standard average performance (weighted by the number of scenarios) over these four splits.", "labels": [], "entities": []}, {"text": "Dataset Processing In this section, we present the implementation details regarding our data preprocessing.", "labels": [], "entities": [{"text": "Dataset Processing", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.7167490422725677}]}, {"text": "We use WEATHERGOV as an example here, since it is our primary dataset, and the same recipe is followed for ROBOCUP.", "labels": [], "entities": []}, {"text": "For tokenization of the textual descriptions, we simply treat as token each string unit delimited by a space, which includes regular words (\"sunny\"), punctuation (\",\"), and numerical values.", "labels": [], "entities": []}, {"text": "A special token is added to represent the beginning and end of the entire textual description.", "labels": [], "entities": []}, {"text": "This operation results in a vocabulary of size 338, and we did not filter out any rare tokens.", "labels": [], "entities": []}, {"text": "Moreover, in this setup, numerical values are also generated as any other token during decoding period.", "labels": [], "entities": []}, {"text": "For event record representation, we represent each event as a fixed-length vector, concatenated by multiple \"attribute (field) vectors\".", "labels": [], "entities": [{"text": "event record representation", "start_pos": 4, "end_pos": 31, "type": "TASK", "confidence": 0.6333077649275461}]}, {"text": "Each attribute vector represents either a 1) record type (e.g., \"rainChance\") with a one-hot vector, 2) record time slot (e.g., \"06:00-21:00\") with a one-hot vector, 3) record mode (e.g., \"SSE\") with a one-hot vector, or, 4) record value (e.g., \"20\") with a 0-1 vector.", "labels": [], "entities": []}, {"text": "The 0-1 vector for record value is simply the signed binary representation of this number.", "labels": [], "entities": []}, {"text": "We choose the usage of 0-1 binary representation vectors for numbers because it allows us to share binning-style information between nearby numbers (whereas a one-hot vector is sparse).", "labels": [], "entities": []}, {"text": "Training Details On WEATHERGOV, we lightly tune the number of hidden units and \u03b3 on the development set according to the generation metric (BLEU), and choose 500 units from {250, 500, 750} and \u03b3 = 8.5 from {6.5, 7.5, 8.5, 10.5, 12.5}.", "labels": [], "entities": [{"text": "WEATHERGOV", "start_pos": 20, "end_pos": 30, "type": "DATASET", "confidence": 0.8051132559776306}, {"text": "BLEU)", "start_pos": 140, "end_pos": 145, "type": "METRIC", "confidence": 0.9539315402507782}]}, {"text": "For ROBOCUP, we only tune \u03b3 on the development set and choose \u03b3 = 5.0 from the set {1.0, 2.0, . .", "labels": [], "entities": []}, {"text": "However, we do not retune the number of hidden units on ROBOCUP.", "labels": [], "entities": [{"text": "ROBOCUP", "start_pos": 56, "end_pos": 63, "type": "DATASET", "confidence": 0.82140052318573}]}, {"text": "For each iteration, we randomly sample a mini-batch of 100 scenarios during back-propagation and use Adam () for optimization.", "labels": [], "entities": []}, {"text": "Training typically converges within 30 epochs.", "labels": [], "entities": []}, {"text": "We select the model according to the BLEU score on the development set.", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 37, "end_pos": 47, "type": "METRIC", "confidence": 0.966009110212326}]}, {"text": "Evaluation Metrics We consider two metrics as a means of evaluating the effectiveness of our model on the two selective generation subproblems.", "labels": [], "entities": []}, {"text": "For content selection, we use the F-1 score of the set of selected records as defined by the harmonic mean of precision and recall with respect to the ground-truth selection record set.", "labels": [], "entities": [{"text": "content selection", "start_pos": 4, "end_pos": 21, "type": "TASK", "confidence": 0.8429180383682251}, {"text": "F-1 score", "start_pos": 34, "end_pos": 43, "type": "METRIC", "confidence": 0.9807110130786896}, {"text": "precision", "start_pos": 110, "end_pos": 119, "type": "METRIC", "confidence": 0.999186098575592}, {"text": "recall", "start_pos": 124, "end_pos": 130, "type": "METRIC", "confidence": 0.9985591769218445}]}, {"text": "We define the set of selected records as consisting of the record with the largest selection weight \u03b1 ti computed by our aligner at each decoding step t.", "labels": [], "entities": []}, {"text": "We evaluate the quality of surface realization using the BLEU score 6 (a 4-gram matching-based precision) () of the generated description with respect to the human-created reference.", "labels": [], "entities": [{"text": "surface realization", "start_pos": 27, "end_pos": 46, "type": "TASK", "confidence": 0.7614643573760986}, {"text": "BLEU score 6", "start_pos": 57, "end_pos": 69, "type": "METRIC", "confidence": 0.9700201948483785}]}, {"text": "To be comparable to previous results on WEATHERGOV, we also consider a modified BLEU score (cBLEU) that does not penalize numerical deviations of at most five () (i.e., to not penalize \"low around 58\" compared to a reference \"low around 60\").", "labels": [], "entities": [{"text": "WEATHERGOV", "start_pos": 40, "end_pos": 50, "type": "DATASET", "confidence": 0.8465555906295776}, {"text": "BLEU score (cBLEU)", "start_pos": 80, "end_pos": 98, "type": "METRIC", "confidence": 0.9439010977745056}]}, {"text": "On ROBOCUP, we also evaluate the BLEU score in the case that groundtruth content selection is known (sBLEU G ), to be comparable to previous work.", "labels": [], "entities": [{"text": "ROBOCUP", "start_pos": 3, "end_pos": 10, "type": "METRIC", "confidence": 0.4628332853317261}, {"text": "BLEU score", "start_pos": 33, "end_pos": 43, "type": "METRIC", "confidence": 0.9790922403335571}, {"text": "sBLEU G )", "start_pos": 101, "end_pos": 110, "type": "METRIC", "confidence": 0.9048665165901184}]}], "tableCaptions": [{"text": " Table 1: Primary WEATHERGOV results", "labels": [], "entities": [{"text": "WEATHERGOV", "start_pos": 18, "end_pos": 28, "type": "METRIC", "confidence": 0.5902679562568665}]}, {"text": " Table 2: Effect of beam width", "labels": [], "entities": []}, {"text": " Table 3: k-NN beam filter (dev set)", "labels": [], "entities": []}, {"text": " Table 4: k-NN beam filter (test set)", "labels": [], "entities": []}, {"text": " Table 5: Coarse-to-fine aligner ablation (dev set)", "labels": [], "entities": []}, {"text": " Table 6: Encoder ablation (dev set)", "labels": [], "entities": []}]}