{"title": [{"text": "Discriminative Reranking for Grammatical Error Correction with Statistical Machine Translation", "labels": [], "entities": [{"text": "Discriminative Reranking", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.608262687921524}, {"text": "Statistical Machine Translation", "start_pos": 63, "end_pos": 94, "type": "TASK", "confidence": 0.5864604115486145}]}], "abstractContent": [{"text": "Research on grammatical error correction has received considerable attention.", "labels": [], "entities": [{"text": "grammatical error correction", "start_pos": 12, "end_pos": 40, "type": "TASK", "confidence": 0.6689819395542145}]}, {"text": "For dealing with all types of errors, grammatical error correction methods that employ statistical machine translation (SMT) have been proposed in recent years.", "labels": [], "entities": [{"text": "grammatical error correction", "start_pos": 38, "end_pos": 66, "type": "TASK", "confidence": 0.6281264026959738}, {"text": "statistical machine translation (SMT)", "start_pos": 87, "end_pos": 124, "type": "TASK", "confidence": 0.7373227179050446}]}, {"text": "An SMT system generates candidates with scores for all candidates and selects the sentence with the highest score as the correction result.", "labels": [], "entities": [{"text": "SMT", "start_pos": 3, "end_pos": 6, "type": "TASK", "confidence": 0.9899375438690186}]}, {"text": "However, the 1-best result of an SMT system is not always the best result.", "labels": [], "entities": [{"text": "SMT", "start_pos": 33, "end_pos": 36, "type": "TASK", "confidence": 0.9917383790016174}]}, {"text": "Thus, we propose a reranking approach for grammatical error correction.", "labels": [], "entities": [{"text": "grammatical error correction", "start_pos": 42, "end_pos": 70, "type": "TASK", "confidence": 0.6236019929250082}]}, {"text": "The rerank-ing approach is used to re-score N-best results of the SMT and reorder the results.", "labels": [], "entities": [{"text": "SMT", "start_pos": 66, "end_pos": 69, "type": "TASK", "confidence": 0.9833184480667114}]}, {"text": "Our experiments show that our reranking system using parts of speech and syntactic features improves performance and achieves state-of-the-art quality, with an F 0.5 score of 40.0.", "labels": [], "entities": [{"text": "F 0.5 score", "start_pos": 160, "end_pos": 171, "type": "METRIC", "confidence": 0.984159251054128}]}], "introductionContent": [{"text": "Research on assisting second language learners has received considerable attention, especially regarding grammatical error correction of essays written by English as a Second Language (ESL) learners.", "labels": [], "entities": [{"text": "grammatical error correction of essays written by English as a Second Language (ESL) learners", "start_pos": 105, "end_pos": 198, "type": "TASK", "confidence": 0.8367412481456995}]}, {"text": "To address all types of errors, grammatical error correction methods that use statistical machine translation (SMT) have been proposed).", "labels": [], "entities": [{"text": "grammatical error correction", "start_pos": 32, "end_pos": 60, "type": "TASK", "confidence": 0.6322964529196421}, {"text": "statistical machine translation (SMT)", "start_pos": 78, "end_pos": 115, "type": "TASK", "confidence": 0.7606742779413859}]}, {"text": "SMTbased error correction systems have achieved rankings first and third in the CoNLL2014 Shared Task ( ).", "labels": [], "entities": [{"text": "SMTbased error correction", "start_pos": 0, "end_pos": 25, "type": "TASK", "confidence": 0.8674401044845581}, {"text": "CoNLL2014 Shared Task", "start_pos": 80, "end_pos": 101, "type": "DATASET", "confidence": 0.7530370155970255}]}, {"text": "SMT systems generate many candidates of translation.", "labels": [], "entities": [{"text": "SMT", "start_pos": 0, "end_pos": 3, "type": "TASK", "confidence": 0.9810024499893188}, {"text": "translation", "start_pos": 40, "end_pos": 51, "type": "TASK", "confidence": 0.965914249420166}]}, {"text": "SMT systems generate scored candidates and select a sentence having the highest score as the translation result.", "labels": [], "entities": [{"text": "SMT", "start_pos": 0, "end_pos": 3, "type": "TASK", "confidence": 0.9732708930969238}]}, {"text": "However, the 1-best result of SMT system is not always the best result because the scoring is conducted only with local features.", "labels": [], "entities": [{"text": "SMT", "start_pos": 30, "end_pos": 33, "type": "TASK", "confidence": 0.9794955849647522}]}, {"text": "In other words, N-best (N > 1) results maybe better than the 1-best result.", "labels": [], "entities": []}, {"text": "Reranking approaches have been devised to solve the scoring problem.", "labels": [], "entities": [{"text": "scoring problem", "start_pos": 52, "end_pos": 67, "type": "TASK", "confidence": 0.9069430828094482}]}, {"text": "Reranking is a method that re-scores N-best candidates of SMT and reorders the candidates by score.", "labels": [], "entities": [{"text": "Reranking", "start_pos": 0, "end_pos": 9, "type": "METRIC", "confidence": 0.6595947742462158}, {"text": "SMT", "start_pos": 58, "end_pos": 61, "type": "TASK", "confidence": 0.9845041036605835}]}, {"text": "shows a flow of reranking.", "labels": [], "entities": []}, {"text": "First, N-best results are obtained by a grammatical error correction system using SMT fora learner sentence (A in.", "labels": [], "entities": [{"text": "SMT", "start_pos": 82, "end_pos": 85, "type": "TASK", "confidence": 0.8641382455825806}]}, {"text": "A reranking sys-tem then re-scores the N-best results and reorders them (B in.", "labels": [], "entities": []}, {"text": "In this study, we apply a discriminative reranking method to the task of grammatical error correction.", "labels": [], "entities": [{"text": "grammatical error correction", "start_pos": 73, "end_pos": 101, "type": "TASK", "confidence": 0.5803449253241221}]}, {"text": "Syntactic information is not considered in the phrase-based SMT.", "labels": [], "entities": [{"text": "SMT", "start_pos": 60, "end_pos": 63, "type": "TASK", "confidence": 0.7753968238830566}]}, {"text": "We show that using syntactic features in the reranking system can improve error correction performance.", "labels": [], "entities": [{"text": "error correction", "start_pos": 74, "end_pos": 90, "type": "TASK", "confidence": 0.7465905845165253}]}, {"text": "Although reranking using only surface features ) is not effective for grammatical error correction, reranking using syntactic features improves the F 0.5 score.", "labels": [], "entities": [{"text": "grammatical error correction", "start_pos": 70, "end_pos": 98, "type": "TASK", "confidence": 0.5897603134314219}, {"text": "F 0.5 score", "start_pos": 148, "end_pos": 159, "type": "METRIC", "confidence": 0.98271510998408}]}], "datasetContent": [{"text": "We conducted experiments on grammatical error correction to observe the effect of discriminative reranking and our syntactic features.", "labels": [], "entities": [{"text": "grammatical error correction", "start_pos": 28, "end_pos": 56, "type": "TASK", "confidence": 0.5603900949160258}]}, {"text": "We used phrase-based SMT which many previous studies used for grammatical error correction fora baseline system.", "labels": [], "entities": [{"text": "phrase-based SMT", "start_pos": 8, "end_pos": 24, "type": "TASK", "confidence": 0.5228196382522583}, {"text": "grammatical error correction", "start_pos": 62, "end_pos": 90, "type": "TASK", "confidence": 0.6546178956826528}]}, {"text": "We used cicada 0.3.5 2 for the machine translation tool and KenLM 3 as the language modeling tool.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 31, "end_pos": 50, "type": "TASK", "confidence": 0.7751939594745636}]}, {"text": "We used ZMERT 4 as the parameter tuning tool and implemented the averaged perceptron for reranking.", "labels": [], "entities": []}, {"text": "The translation model was trained on the Lang-8 Learner Corpora v2.0.", "labels": [], "entities": [{"text": "translation", "start_pos": 4, "end_pos": 15, "type": "TASK", "confidence": 0.9701359868049622}, {"text": "Lang-8 Learner Corpora v2.0", "start_pos": 41, "end_pos": 68, "type": "DATASET", "confidence": 0.9443332105875015}]}, {"text": "We extracted English essays that were written by ESL learners and cleaned noise with the method proposed in.", "labels": [], "entities": []}, {"text": "From the results, we obtained 1,069,127 sentence pairs.", "labels": [], "entities": []}, {"text": "We used a 5-gram language model built on the \"Associated Press Worldstream English Service\" from English Gigaword corpus and NU-CLE 3.2 (.", "labels": [], "entities": [{"text": "Associated Press Worldstream English Service\" from English Gigaword corpus", "start_pos": 46, "end_pos": 120, "type": "DATASET", "confidence": 0.9301182925701141}, {"text": "NU-CLE 3.2", "start_pos": 125, "end_pos": 135, "type": "DATASET", "confidence": 0.8633475303649902}]}, {"text": "We used these two language models as separate feature functions in the SMT system.", "labels": [], "entities": [{"text": "SMT", "start_pos": 71, "end_pos": 74, "type": "TASK", "confidence": 0.9904575347900391}]}, {"text": "For training data of reranking, Lang-8 Learner Corpora was split into 10 parts and each part was corrected by a grammatical error correction system trained on the other nine parts.", "labels": [], "entities": [{"text": "Lang-8 Learner Corpora", "start_pos": 32, "end_pos": 54, "type": "DATASET", "confidence": 0.9390547275543213}]}, {"text": "We selected 10 as N for N-best reranking.", "labels": [], "entities": []}, {"text": "PukWaC corpus () was used for constructing our \"Web dependency N-gram\" feature.", "labels": [], "entities": [{"text": "PukWaC corpus", "start_pos": 0, "end_pos": 13, "type": "DATASET", "confidence": 0.9431964159011841}]}, {"text": "We use Stanford Parser 3.2.0 5 as a dependency parser.", "labels": [], "entities": [{"text": "Stanford Parser 3.2.0 5", "start_pos": 7, "end_pos": 30, "type": "DATASET", "confidence": 0.8925260752439499}]}, {"text": "CoNLL-2013 test set were split into 700 sentences for parameter tuning of SMT and 681 sentences for tuning parameter beta.", "labels": [], "entities": [{"text": "CoNLL-2013 test set", "start_pos": 0, "end_pos": 19, "type": "DATASET", "confidence": 0.9811179637908936}, {"text": "SMT", "start_pos": 74, "end_pos": 77, "type": "TASK", "confidence": 0.8751085996627808}]}, {"text": "CoNLL-2014 test set, 1,312 sentences were used for evaluation.", "labels": [], "entities": [{"text": "CoNLL-2014 test set", "start_pos": 0, "end_pos": 19, "type": "DATASET", "confidence": 0.9785975217819214}]}, {"text": "We used M2 Scorer as an evaluation tool . This scorer calculates precision, recall, and F 0.5 scores.", "labels": [], "entities": [{"text": "M2 Scorer", "start_pos": 8, "end_pos": 17, "type": "DATASET", "confidence": 0.7101731300354004}, {"text": "precision", "start_pos": 65, "end_pos": 74, "type": "METRIC", "confidence": 0.9989390969276428}, {"text": "recall", "start_pos": 76, "end_pos": 82, "type": "METRIC", "confidence": 0.9994515776634216}, {"text": "F 0.5 scores", "start_pos": 88, "end_pos": 100, "type": "METRIC", "confidence": 0.9779608448346456}]}, {"text": "We used F 0.5 as a tuning metric.", "labels": [], "entities": [{"text": "F", "start_pos": 8, "end_pos": 9, "type": "METRIC", "confidence": 0.955272912979126}]}, {"text": "In addition, we used GLEU ( as evaluation metrics.", "labels": [], "entities": [{"text": "GLEU", "start_pos": 21, "end_pos": 25, "type": "METRIC", "confidence": 0.9958937168121338}]}, {"text": "We used the 1-best result of the SMT correction system and reranking by probability of the large N-gram language model) as baseline systems.", "labels": [], "entities": [{"text": "SMT correction", "start_pos": 33, "end_pos": 47, "type": "TASK", "confidence": 0.9641565084457397}]}, {"text": "In addition, we compared the systems that are ranked first (CAMB) and second (CUUI)) in CoNLL2014 Shared Task.", "labels": [], "entities": []}, {"text": "The discriminative reranking system with our features achieved the best F 0.5 score.", "labels": [], "entities": [{"text": "F 0.5 score", "start_pos": 72, "end_pos": 83, "type": "METRIC", "confidence": 0.9817044933636984}]}, {"text": "The difference between the results of baseline and reranking using our features was statistically significant (p < 0.01).", "labels": [], "entities": []}, {"text": "Because a large N-gram language model was adopted for reranking, recall increased considerably but precision declined.", "labels": [], "entities": [{"text": "recall", "start_pos": 65, "end_pos": 71, "type": "METRIC", "confidence": 0.9996501207351685}, {"text": "precision", "start_pos": 99, "end_pos": 108, "type": "METRIC", "confidence": 0.9994427561759949}]}, {"text": "This result is extremely similar to that of the CAMB system, which is an SMT-based error correction system that reranks by using a large N-gram language model.", "labels": [], "entities": [{"text": "SMT-based error correction", "start_pos": 73, "end_pos": 99, "type": "TASK", "confidence": 0.9003998835881551}]}, {"text": "When we compare the reranking system using our features to CUUI, our system is better in all metrics.", "labels": [], "entities": [{"text": "CUUI", "start_pos": 59, "end_pos": 63, "type": "DATASET", "confidence": 0.9100393652915955}]}, {"text": "When we use the discriminative reranking with our features, both precision and recall increase.", "labels": [], "entities": [{"text": "precision", "start_pos": 65, "end_pos": 74, "type": "METRIC", "confidence": 0.9997339844703674}, {"text": "recall", "start_pos": 79, "end_pos": 85, "type": "METRIC", "confidence": 0.9996790885925293}]}, {"text": "In the experimental results of system combination (), recall increases but precision declines with respect to original SMT results.", "labels": [], "entities": [{"text": "recall", "start_pos": 54, "end_pos": 60, "type": "METRIC", "confidence": 0.9996688365936279}, {"text": "precision", "start_pos": 75, "end_pos": 84, "type": "METRIC", "confidence": 0.9995057582855225}, {"text": "SMT", "start_pos": 119, "end_pos": 122, "type": "TASK", "confidence": 0.985325813293457}]}, {"text": "In addition, precision increases but recall declines with respect to pipeline results.", "labels": [], "entities": [{"text": "precision", "start_pos": 13, "end_pos": 22, "type": "METRIC", "confidence": 0.999729573726654}, {"text": "recall", "start_pos": 37, "end_pos": 43, "type": "METRIC", "confidence": 0.9996172189712524}]}, {"text": "The reranking that employed all features generated a lower F 0.5 score than when only our features were used.", "labels": [], "entities": [{"text": "F 0.5 score", "start_pos": 59, "end_pos": 70, "type": "METRIC", "confidence": 0.9867165088653564}]}, {"text": "One reason for this is that the roles of features overlap.", "labels": [], "entities": []}, {"text": "These experiments revealed that reranking is effective in grammatical error correction tasks and that POS and syntactic features are important.", "labels": [], "entities": [{"text": "grammatical error correction tasks", "start_pos": 58, "end_pos": 92, "type": "TASK", "confidence": 0.6874588206410408}, {"text": "POS", "start_pos": 102, "end_pos": 105, "type": "METRIC", "confidence": 0.7769895195960999}]}], "tableCaptions": [{"text": " Table 1: Oracle score of grammatical error correction", "labels": [], "entities": [{"text": "Oracle score", "start_pos": 10, "end_pos": 22, "type": "METRIC", "confidence": 0.8858169615268707}, {"text": "grammatical error correction", "start_pos": 26, "end_pos": 54, "type": "TASK", "confidence": 0.5251243909200033}]}, {"text": " Table 3: Experimental results. TP, FN, and FP denote true positive, false negative, and false positive, respectively.Asterisks indicate", "labels": [], "entities": [{"text": "TP", "start_pos": 32, "end_pos": 34, "type": "METRIC", "confidence": 0.9746636152267456}, {"text": "FN", "start_pos": 36, "end_pos": 38, "type": "METRIC", "confidence": 0.9501954913139343}, {"text": "FP", "start_pos": 44, "end_pos": 46, "type": "METRIC", "confidence": 0.9969858527183533}]}]}