{"title": [{"text": "Making Dependency Labeling Simple, Fast and Accurate", "labels": [], "entities": [{"text": "Dependency Labeling", "start_pos": 7, "end_pos": 26, "type": "TASK", "confidence": 0.8245704174041748}, {"text": "Accurate", "start_pos": 44, "end_pos": 52, "type": "METRIC", "confidence": 0.9919860363006592}]}], "abstractContent": [{"text": "This work addresses the task of dependency labeling-assigning labels to an (unlabeled) dependency tree.", "labels": [], "entities": [{"text": "dependency labeling-assigning labels to an (unlabeled) dependency tree", "start_pos": 32, "end_pos": 102, "type": "TASK", "confidence": 0.8042886137962342}]}, {"text": "We employ and extend a feature representation learning approach, optimizing it for both high speed and accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 103, "end_pos": 111, "type": "METRIC", "confidence": 0.99277263879776}]}, {"text": "We apply our labeling model on top of state-of-the-art parsers and evaluate its performance on standard benchmarks including the CoNLL-2009 and the English PTB datasets.", "labels": [], "entities": [{"text": "CoNLL-2009", "start_pos": 129, "end_pos": 139, "type": "DATASET", "confidence": 0.9604780673980713}, {"text": "English PTB datasets", "start_pos": 148, "end_pos": 168, "type": "DATASET", "confidence": 0.923724889755249}]}, {"text": "Our model processes over 1,700 English sentences per second, which is 30 times faster than the sparse-feature method.", "labels": [], "entities": []}, {"text": "It improves labeling accuracy over the outputs of top parsers, achieving the best LAS on 5 out of 7 datasets 1 .", "labels": [], "entities": [{"text": "labeling", "start_pos": 12, "end_pos": 20, "type": "TASK", "confidence": 0.9213926196098328}, {"text": "accuracy", "start_pos": 21, "end_pos": 29, "type": "METRIC", "confidence": 0.944477379322052}, {"text": "LAS", "start_pos": 82, "end_pos": 85, "type": "METRIC", "confidence": 0.9768573045730591}]}], "introductionContent": [{"text": "Traditionally in dependency parsing, the tasks of finding the tree structure and labeling the dependency arcs are coupled in a joint achitecture.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 17, "end_pos": 35, "type": "TASK", "confidence": 0.8577538430690765}]}, {"text": "While it has potential to eliminate errors propogated through a separated procedure, joint decoding introduces other sources of issues that can also lead to non-optimal labeling assignments.", "labels": [], "entities": []}, {"text": "One of the issues arises from inexact algorithms adopted in order to solve the hard joint search problem.", "labels": [], "entities": [{"text": "hard joint search problem", "start_pos": 79, "end_pos": 104, "type": "TASK", "confidence": 0.6960471719503403}]}, {"text": "For instance, many parsers () adopt greedy decoding such as beam search, which may prune away the correct labeling hypothesis in an early decoding stage.", "labels": [], "entities": [{"text": "beam search", "start_pos": 60, "end_pos": 71, "type": "TASK", "confidence": 0.7787698209285736}]}, {"text": "Another issue is caused by the absence of rich label features.", "labels": [], "entities": []}, {"text": "Adding dependency labels to the combinatorial space significantly slows down the search procedure.", "labels": [], "entities": []}, {"text": "As a trade-off, many parsers such as MSTParser,) incorporate only single-arc label features to reduce the processing time.", "labels": [], "entities": [{"text": "MSTParser", "start_pos": 37, "end_pos": 46, "type": "DATASET", "confidence": 0.855968713760376}]}, {"text": "This restriction greatly limits the labeling accuracy.", "labels": [], "entities": [{"text": "labeling", "start_pos": 36, "end_pos": 44, "type": "TASK", "confidence": 0.9626938700675964}, {"text": "accuracy", "start_pos": 45, "end_pos": 53, "type": "METRIC", "confidence": 0.9620497226715088}]}, {"text": "In this work, we explore an alternative approach where the dependency labeling is applied as a separate procedure, alleviating the issues described above.", "labels": [], "entities": [{"text": "dependency labeling", "start_pos": 59, "end_pos": 78, "type": "TASK", "confidence": 0.7809384763240814}]}, {"text": "The potential of this approach has been explored in early work.", "labels": [], "entities": []}, {"text": "For instance, applied a separate labeling step on top of the first-order MSTParser.", "labels": [], "entities": [{"text": "MSTParser", "start_pos": 73, "end_pos": 82, "type": "DATASET", "confidence": 0.8858112096786499}]}, {"text": "The benefit of such approach is two-fold.", "labels": [], "entities": []}, {"text": "First, finding the optimal labeling assignment (once the tree structure is produced) can be solved via an exact dynamic programming algorithm.", "labels": [], "entities": []}, {"text": "Second, it becomes relatively cheap to add rich label features given a fixed tree, and the exact algorithm still applies when high-order label features are included.", "labels": [], "entities": []}, {"text": "However, due to performance issues, such approach has not been adopted by the top performing parsers.", "labels": [], "entities": []}, {"text": "In this work, we show that the labeling procedure, when optimized with recent advanced techniques in parsing, can achieve very high speed and accuracy.", "labels": [], "entities": [{"text": "labeling", "start_pos": 31, "end_pos": 39, "type": "TASK", "confidence": 0.9810857772827148}, {"text": "parsing", "start_pos": 101, "end_pos": 108, "type": "TASK", "confidence": 0.9765442609786987}, {"text": "speed", "start_pos": 132, "end_pos": 137, "type": "METRIC", "confidence": 0.9946075677871704}, {"text": "accuracy", "start_pos": 142, "end_pos": 150, "type": "METRIC", "confidence": 0.9914608001708984}]}, {"text": "Specifically, our approach employs the recent distributional representation learning technique for parsing.", "labels": [], "entities": [{"text": "parsing", "start_pos": 99, "end_pos": 106, "type": "TASK", "confidence": 0.9727501273155212}]}, {"text": "We apply and extend the low-rank tensor factorization method ( ) to the second-order case to learn a joint scoring function over grand-head, head, modifier and their labels.", "labels": [], "entities": []}, {"text": "Unlike the prior work which additionally requires traditional sparse features to achieve state-of-the-art performance, our extention alone delivers the same level of accuracy, while being substantially faster.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 166, "end_pos": 174, "type": "METRIC", "confidence": 0.9989411234855652}]}, {"text": "As a consequence, the labeling model can be applied either as a refinement (re-labeling) step on top of existing parsers with negligible cost of computation, or as apart of a decoupled procedure to simplify and speedup the dependency parsing decoding.", "labels": [], "entities": [{"text": "dependency parsing decoding", "start_pos": 223, "end_pos": 250, "type": "TASK", "confidence": 0.7601291735967001}]}, {"text": "We evaluate on all datasets in the CoNLL-2009 shared task as well as the English Penn Treebank dataset, applying our labeling model on top of stateof-the-art dependency parsers.", "labels": [], "entities": [{"text": "CoNLL-2009 shared task", "start_pos": 35, "end_pos": 57, "type": "DATASET", "confidence": 0.8596444129943848}, {"text": "English Penn Treebank dataset", "start_pos": 73, "end_pos": 102, "type": "DATASET", "confidence": 0.9475269019603729}]}, {"text": "Our labeling model processes over 1,700 English sentences per second, which is 30 times faster than the sparse-feature method.", "labels": [], "entities": []}, {"text": "As a refinement (re-labeling) model, it achieves the best LAS on 5 out of 7 datasets.", "labels": [], "entities": [{"text": "LAS", "start_pos": 58, "end_pos": 61, "type": "METRIC", "confidence": 0.8816226720809937}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 2: Pipelined Results on CoNLL-2009.", "labels": [], "entities": [{"text": "CoNLL-2009", "start_pos": 31, "end_pos": 41, "type": "DATASET", "confidence": 0.9060168266296387}]}, {"text": " Table 3: LAS and parsing speed (sentence per second) based  on unlabeled golden trees.", "labels": [], "entities": [{"text": "LAS", "start_pos": 10, "end_pos": 13, "type": "METRIC", "confidence": 0.6471712589263916}, {"text": "parsing", "start_pos": 18, "end_pos": 25, "type": "TASK", "confidence": 0.9660183787345886}]}, {"text": " Table 4: Joint vs. Separate analysis on PTB.", "labels": [], "entities": [{"text": "PTB", "start_pos": 41, "end_pos": 44, "type": "DATASET", "confidence": 0.5731497406959534}]}]}