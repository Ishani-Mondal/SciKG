{"title": [{"text": "Recurrent Support Vector Machines For Slot Tagging In Spoken Language Understanding", "labels": [], "entities": [{"text": "Slot Tagging", "start_pos": 38, "end_pos": 50, "type": "TASK", "confidence": 0.9518866837024689}]}], "abstractContent": [{"text": "We propose recurrent support vector machine (RSVM) for slot tagging.", "labels": [], "entities": [{"text": "slot tagging", "start_pos": 55, "end_pos": 67, "type": "TASK", "confidence": 0.8447990715503693}]}, {"text": "This model is a combination of the recurrent neural network (RNN) and the structured support vector machine.", "labels": [], "entities": []}, {"text": "RNN extracts features from the input sequence.", "labels": [], "entities": []}, {"text": "The structured support vector machine uses a sequence-level dis-criminative objective function.", "labels": [], "entities": []}, {"text": "The proposed model therefore combines the sequence representation capability of an RNN with the sequence-level discrim-inative objective.", "labels": [], "entities": []}, {"text": "We have observed new state-of-the-art results on two benchmark datasets and one private dataset.", "labels": [], "entities": []}, {"text": "RSVM obtained statistical significant 4% and 2% relative average F1 score improvement on ATIS dataset and Chunking dataset, respectively.", "labels": [], "entities": [{"text": "RSVM", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.9225925207138062}, {"text": "F1 score", "start_pos": 65, "end_pos": 73, "type": "METRIC", "confidence": 0.9816367328166962}, {"text": "ATIS dataset", "start_pos": 89, "end_pos": 101, "type": "DATASET", "confidence": 0.94675612449646}, {"text": "Chunking dataset", "start_pos": 106, "end_pos": 122, "type": "DATASET", "confidence": 0.9750367999076843}]}, {"text": "Out of eight domains in Cortana live log dataset, RSVM achieved F1 score improvement on seven domains.", "labels": [], "entities": [{"text": "Cortana live log dataset", "start_pos": 24, "end_pos": 48, "type": "DATASET", "confidence": 0.9656755775213242}, {"text": "F1 score", "start_pos": 64, "end_pos": 72, "type": "METRIC", "confidence": 0.9797837138175964}]}, {"text": "Experiments also show that RSVM significantly speeds up the model training by skipping the weight updating for non-support vector training samples, compared against training using RNN with CRF or minimum cross-entropy objectives.", "labels": [], "entities": []}], "introductionContent": [{"text": "One of the key tasks in natural language understanding () is slot tagging that labels user queries with semantic tags.", "labels": [], "entities": [{"text": "natural language understanding", "start_pos": 24, "end_pos": 54, "type": "TASK", "confidence": 0.6395210425059}, {"text": "slot tagging", "start_pos": 61, "end_pos": 73, "type": "TASK", "confidence": 0.8086690306663513}]}, {"text": "It is a sequence labeling problem that transcribes a sequence of observations X = [x(1), x(2), ..., x(M)] to a sequence of discrete labels Y = [y(1), y(2), ..., y(M)].", "labels": [], "entities": [{"text": "sequence labeling", "start_pos": 8, "end_pos": 25, "type": "TASK", "confidence": 0.635683000087738}]}, {"text": "For example, in the query \"show me flights from Seattle to Boston\", the words \"Seattle\" and \"Boston\" should be labeled, respectively, as the from-city-name slot and the to-city-name slot.", "labels": [], "entities": []}, {"text": "Recently recurrent neural networks (RNNs) and their variants achieved state-of-the-art performances on slot tagging tasks (.", "labels": [], "entities": [{"text": "slot tagging tasks", "start_pos": 103, "end_pos": 121, "type": "TASK", "confidence": 0.8357722759246826}]}, {"text": "One direction to improve the sequence labeling is to strengthen the model memorization capability by designing dedicated special structures, for example, using long-short-term-memory (LSTM) networks, gated RNN and RNN with external memory (RNN-em) . The other direction is to optimize the sequence-level discrimination criterion.", "labels": [], "entities": [{"text": "sequence labeling", "start_pos": 29, "end_pos": 46, "type": "TASK", "confidence": 0.6641172468662262}, {"text": "model memorization", "start_pos": 68, "end_pos": 86, "type": "TASK", "confidence": 0.6918403506278992}]}, {"text": "For example, recurrent conditional random fields (RCRFs) () is trained to optimize the sequence conditional likelihood rather than minimizing frame level cross-entropy applied in conventional RNN based sequence labeling (.", "labels": [], "entities": [{"text": "RNN based sequence labeling", "start_pos": 192, "end_pos": 219, "type": "TASK", "confidence": 0.5877358689904213}]}, {"text": "In this paper, we propose recurrent support vector machines (RSVMs) to improve the discrimination ability of RNNs.", "labels": [], "entities": []}, {"text": "Different from RCRFs and conventional RNNs that in essence apply the multinomial logistic regression on the output layer, RSVMs optimize the sequence-level max-margin training criterion used by structured support vector machines () on the output layer of RNNs.", "labels": [], "entities": []}, {"text": "There are several advantages of using sequence-level max-margin training over maximum likelihood or minimum cross-entropy.", "labels": [], "entities": []}, {"text": "Firstly, the sequencelevel max-margin criterion is a global un-normalized criterion in which there is no computation cost for normalization.", "labels": [], "entities": []}, {"text": "Secondly, using max-margin training, only training samples from support vectors generate nonzero errors.", "labels": [], "entities": []}, {"text": "In other words, model training can be sped up by skipping the weight updating for non-support vector training samples.", "labels": [], "entities": []}, {"text": "Finally, as proven in, margin maximization is equivalent to minimization of an upper bound on the generalization errors.", "labels": [], "entities": []}, {"text": "Max-margin training has no assumption about the model distribution.", "labels": [], "entities": []}, {"text": "To use maximum likelihood or minimum cross-entropy, it assumes that the model distribution is peaked.", "labels": [], "entities": []}, {"text": "However, especially in natural language processing where the ambiguity is ubiquitous, this assumption does not hold.", "labels": [], "entities": []}, {"text": "For example, \"seven eleven\" can be labeled as time tag or place name (super market name) tag.", "labels": [], "entities": []}, {"text": "The conditional probability of tag given \"seven eleven\" should not be sharp for time or place name.", "labels": [], "entities": []}, {"text": "Recently, SVM is also applied on top of a deep neural network for speech recognition (.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 66, "end_pos": 84, "type": "TASK", "confidence": 0.8249471187591553}]}, {"text": "In their work, a cutting-plane algorithm) is used, which is computationally expensive for speech recognition tasks.", "labels": [], "entities": [{"text": "speech recognition tasks", "start_pos": 90, "end_pos": 114, "type": "TASK", "confidence": 0.8982887069384257}]}, {"text": "In this paper, we use the stochastic gradient descent algorithm (SGD)) for model training.", "labels": [], "entities": [{"text": "model training", "start_pos": 75, "end_pos": 89, "type": "TASK", "confidence": 0.7850931584835052}]}, {"text": "The loss function is critical to the sequence level max-margin training criterion, which defines the margin.", "labels": [], "entities": [{"text": "sequence level max-margin training criterion", "start_pos": 37, "end_pos": 81, "type": "METRIC", "confidence": 0.7814232349395752}]}, {"text": "In this paper, we apply the sequence level hard loss function rather than traditional Hamming loss function.", "labels": [], "entities": [{"text": "sequence level hard loss function", "start_pos": 28, "end_pos": 61, "type": "METRIC", "confidence": 0.8609638333320617}]}, {"text": "In sequence level hard loss function, the wrong sequence is assigned loss one without considering the number of wrong slot labels in the sequence.", "labels": [], "entities": []}, {"text": "In the experiments on two benchmark datasets, namely the ATIS (Airline Travel Information Systems) dataset () and the CoNLL 2000 Chunking dataset 1 , and private Cortana live log dataset, RSVMs outperformed previous results.", "labels": [], "entities": [{"text": "ATIS (Airline Travel Information Systems) dataset", "start_pos": 57, "end_pos": 106, "type": "DATASET", "confidence": 0.6977714039385319}, {"text": "CoNLL 2000 Chunking dataset 1", "start_pos": 118, "end_pos": 147, "type": "DATASET", "confidence": 0.9598882794380188}, {"text": "Cortana live log dataset", "start_pos": 162, "end_pos": 186, "type": "DATASET", "confidence": 0.7815702110528946}]}], "datasetContent": [{"text": "In this section, we compare different slot models on different domains based on Cortana live log data.).", "labels": [], "entities": [{"text": "Cortana live log data.", "start_pos": 80, "end_pos": 102, "type": "DATASET", "confidence": 0.9360974729061127}]}, {"text": "\"RCRF\" represents the RCRF slot tagging models that use the same feature as \"RNN\" ().", "labels": [], "entities": []}, {"text": "\"joint-RNN\" ) also uses the same features as \"RNN\" and \"RCRF\".", "labels": [], "entities": []}, {"text": "However, \"joint-RNN\" implicitly makes use of query domain, intent and slot information by training the domain classifier, intent classifier and slot labeling jointly via multi-task learning.", "labels": [], "entities": []}, {"text": "Overall, the proposed RSVM obtains significant improvement over CRF, RNN,RCRF and joint-RNN on alarm, communication, note and reminder (z-test p \u2212 value < 5E \u2212 5).", "labels": [], "entities": []}, {"text": "On the calendar, places and weather, RSVM achieves similar performance as joint-RNN.", "labels": [], "entities": [{"text": "RSVM", "start_pos": 37, "end_pos": 41, "type": "DATASET", "confidence": 0.6235390305519104}]}, {"text": "Even joint-RNN is built on the basis of conventional RNN using local normalization, it actually takes the sequence representation information implicitly from domain and intent classification.", "labels": [], "entities": []}, {"text": "However, in ondevice domain, RCRF performs the best and the proposed RSVM model performs even worse than CRF.", "labels": [], "entities": []}, {"text": "We notice that, in ondevice model, user queries tend to be short, with on average 2.4 words in a query, shown in 1.", "labels": [], "entities": []}, {"text": "Also the loss function in the proposed model only uses the top and the second most hypothesis, which maybe less informative, especially with short sentences, as compared to using all hypothesis in gives the overall performance comparison of different models in internal live log dataset using the weighted average F1 score overall domains.", "labels": [], "entities": [{"text": "F1", "start_pos": 314, "end_pos": 316, "type": "METRIC", "confidence": 0.9837856888771057}]}, {"text": "In this table, we can find that the proposed RSVM on average can achieve 0.6% and 0.7% F1 score improvement over joint-RNN and RCRF, respectively.", "labels": [], "entities": [{"text": "F1 score improvement", "start_pos": 87, "end_pos": 107, "type": "METRIC", "confidence": 0.9717823266983032}]}], "tableCaptions": [{"text": " Table. 1 shows the average query length (the  number of words in one query) on different domains.", "labels": [], "entities": []}, {"text": " Table 2: F1 score (in %) for slot tagging on ATIS achieved by different", "labels": [], "entities": [{"text": "F1 score", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9730607867240906}, {"text": "slot tagging", "start_pos": 30, "end_pos": 42, "type": "TASK", "confidence": 0.9104691445827484}, {"text": "ATIS", "start_pos": 46, "end_pos": 50, "type": "DATASET", "confidence": 0.9212546944618225}]}, {"text": " Table 3: F1 score (in %) for chunking on CoNLL 2000 shared task", "labels": [], "entities": [{"text": "F1 score", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9787817597389221}, {"text": "chunking", "start_pos": 30, "end_pos": 38, "type": "TASK", "confidence": 0.9855918884277344}, {"text": "CoNLL 2000 shared task", "start_pos": 42, "end_pos": 64, "type": "DATASET", "confidence": 0.940726712346077}]}, {"text": " Table 4: F1 score comparison on different slot tagging models on", "labels": [], "entities": [{"text": "F1 score", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9744010865688324}, {"text": "slot tagging", "start_pos": 43, "end_pos": 55, "type": "TASK", "confidence": 0.748839795589447}]}, {"text": " Table 5: F1 score comparison on different slot tagging models on on- device, places, reminder and weather.", "labels": [], "entities": [{"text": "F1 score", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.973641037940979}, {"text": "slot tagging", "start_pos": 43, "end_pos": 55, "type": "TASK", "confidence": 0.6833414882421494}]}, {"text": " Table 6: The weighted average F1 score of different slot tagging models", "labels": [], "entities": [{"text": "F1 score", "start_pos": 31, "end_pos": 39, "type": "METRIC", "confidence": 0.9543077647686005}, {"text": "slot tagging", "start_pos": 53, "end_pos": 65, "type": "TASK", "confidence": 0.8492903709411621}]}]}