{"title": [{"text": "This is how we do it: Answer Reranking for Open-domain How Questions with Paragraph Vectors and Minimal Feature Engineering", "labels": [], "entities": [{"text": "Answer Reranking", "start_pos": 22, "end_pos": 38, "type": "TASK", "confidence": 0.9819761216640472}]}], "abstractContent": [{"text": "We present a simple yet powerful approach to non-factoid answer reranking whereby question-answer pairs are represented by con-catenated distributed representation vectors and a multilayer perceptron is used to compute the score for an answer.", "labels": [], "entities": [{"text": "non-factoid answer reranking", "start_pos": 45, "end_pos": 73, "type": "TASK", "confidence": 0.6211816370487213}]}, {"text": "Despite its simplicity, our approach achieves state-of-the-art performance on a public dataset of How questions, outperforming systems which employ sophisticated feature sets.", "labels": [], "entities": []}, {"text": "We attribute this good performance to the use of paragraph instead of word vector representations and to the use of suitable data for training these representations.", "labels": [], "entities": []}], "introductionContent": [{"text": "In contrast to factoid question answering (QA), nonfactoid QA is concerned with questions whose answer is not easily expressed as an entity or list of entities and can instead be quite complex -compare, for example, the factoid question Who is the secretary general of the UN? with the non-factoid manner question How is the secretary general of the UN chosen?", "labels": [], "entities": [{"text": "factoid question answering (QA)", "start_pos": 15, "end_pos": 46, "type": "TASK", "confidence": 0.8001860777537028}]}, {"text": "A significant amount of research has been carried out on factoid QA, with non-factoid questions receiving less attention.", "labels": [], "entities": [{"text": "factoid QA", "start_pos": 57, "end_pos": 67, "type": "TASK", "confidence": 0.8502647578716278}]}, {"text": "This is changing, however, with the popularity of community-based question answering (CQA) sites such as Yahoo!", "labels": [], "entities": [{"text": "question answering (CQA)", "start_pos": 66, "end_pos": 90, "type": "TASK", "confidence": 0.8256731152534484}]}, {"text": "Answers 1 , Quora 2 and the StackExchange 3 family of forums.", "labels": [], "entities": []}, {"text": "The ability of users to vote for their favourite answer makes these sites a valuable source of training data for open-domain non-factoid QA systems.", "labels": [], "entities": []}, {"text": "In this paper, we present a neural approach to open-domain non-factoid QA, focusing on the subtask of answer reranking, i.e. given a list of candidate answers to a question, order the answers according to their relevance to the question.", "labels": [], "entities": []}, {"text": "We test our approach on the Yahoo!", "labels": [], "entities": [{"text": "Yahoo!", "start_pos": 28, "end_pos": 34, "type": "DATASET", "confidence": 0.9042912423610687}]}, {"text": "Answers dataset of manner or How questions introduced by, who describe answer reranking experiments on this dataset using a diverse range of features incorporating syntax, lexical semantics and discourse.", "labels": [], "entities": []}, {"text": "In particular, they show how discourse information (obtained either via a discourse parser or using shallow techniques based on discourse markers) can complement distributed lexical semantic information.", "labels": [], "entities": []}, {"text": "show how discourse structure can be used to generate artificial questionanswer training pairs from documents, and test their approach on the same dataset.", "labels": [], "entities": []}, {"text": "The best performance on this dataset -33.01 P@1 and 53.96 MRR -is reported by who improve on the lexical semantic models of by exploiting indirect associations between words using higher-order models.", "labels": [], "entities": [{"text": "P", "start_pos": 44, "end_pos": 45, "type": "METRIC", "confidence": 0.9656438231468201}, {"text": "MRR", "start_pos": 58, "end_pos": 61, "type": "METRIC", "confidence": 0.9985712766647339}]}, {"text": "In contrast, our approach is very simple and requires no feature engineering.", "labels": [], "entities": []}, {"text": "Question-answer pairs are represented by concatenated distributed representation vectors and a multilayer perceptron is used to compute the score for an answer (the probability of an answer being the best answer to the question).", "labels": [], "entities": []}, {"text": "Despite its simplicity, we achieve state-of-theart performance on this dataset -37.17 P@1 and 56.82 MRR.", "labels": [], "entities": [{"text": "MRR", "start_pos": 100, "end_pos": 103, "type": "METRIC", "confidence": 0.9703072309494019}]}, {"text": "We attribute this improved performance to the use of paragraph vector representations () instead of averaging over word vectors, and to the use of suitable data for training these representations.", "labels": [], "entities": []}], "datasetContent": [{"text": "To mentations of the P@1 and mean reciprocal rank (MRR) evaluation metrics.", "labels": [], "entities": [{"text": "mean reciprocal rank (MRR)", "start_pos": 29, "end_pos": 55, "type": "METRIC", "confidence": 0.9128835002581278}]}, {"text": "To evaluate whether the difference between two models is statistically significant, statistical significance testing is performed using one-tailed bootstrap resampling with 10,000 iterations.", "labels": [], "entities": []}, {"text": "Improvements are considered to be statistically significant at the 5% confidence level (p < 0.05).", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Development P@1 and MRR for different vectors", "labels": [], "entities": [{"text": "Development P@1", "start_pos": 10, "end_pos": 25, "type": "METRIC", "confidence": 0.8396915942430496}, {"text": "MRR", "start_pos": 30, "end_pos": 33, "type": "METRIC", "confidence": 0.9444198608398438}]}, {"text": " Table 2: Test P@1 and MRR. * indicates that improvements", "labels": [], "entities": [{"text": "Test P@1", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.8088840693235397}, {"text": "MRR", "start_pos": 23, "end_pos": 26, "type": "METRIC", "confidence": 0.9971446394920349}]}]}