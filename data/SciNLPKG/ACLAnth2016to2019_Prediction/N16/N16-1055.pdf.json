{"title": [{"text": "An Unsupervised Model of Orthographic Variation for Historical Document Transcription", "labels": [], "entities": [{"text": "Historical Document Transcription", "start_pos": 52, "end_pos": 85, "type": "TASK", "confidence": 0.8239989876747131}]}], "abstractContent": [{"text": "Historical documents frequently exhibit extensive orthographic variation, including archaic spellings and obsolete shorthand.", "labels": [], "entities": []}, {"text": "OCR tools typically seek to produce so-called diplomatic transcriptions that preserve these variants , but many end tasks require transcriptions with normalized orthography.", "labels": [], "entities": []}, {"text": "In this paper, we present a novel joint transcription model that learns, unsupervised, a probabilistic mapping between modern orthography and that used in the document.", "labels": [], "entities": []}, {"text": "Our system thus produces dual diplomatic and normalized transcriptions simultaneously, and achieves a 35% relative error reduction over a state-of-the-art OCR model on diplomatic transcription, and a 46% reduction on normalized transcription.", "labels": [], "entities": [{"text": "relative error reduction", "start_pos": 106, "end_pos": 130, "type": "METRIC", "confidence": 0.8010080854098002}]}], "introductionContent": [{"text": "Optical Character Recognition (OCR) for historical texts, a challenging problem due to unknown fonts and deteriorating documents, is made even more difficult by the fact that orthographic conventions including spelling, accent usage, and shorthands have not been consistent across the history of printing.", "labels": [], "entities": [{"text": "Optical Character Recognition (OCR)", "start_pos": 0, "end_pos": 35, "type": "TASK", "confidence": 0.839239627122879}]}, {"text": "For this reason, modern language models (LMs) yield poor performance when trying to recognize characters on the pages of these documents.", "labels": [], "entities": []}, {"text": "Furthermore, transcription of the actual printed characters may not always be the most desirable output.", "labels": [], "entities": [{"text": "transcription of the actual printed characters", "start_pos": 13, "end_pos": 59, "type": "TASK", "confidence": 0.7748492161432902}]}, {"text": "describes two types of transcription: one that preserves variants and typographical errors, and another that records the substantive content, with this noise removed.", "labels": [], "entities": []}, {"text": "Though in 1950 the substantive version was the norm, today these have become two distinct but equally valid tasks.", "labels": [], "entities": []}, {"text": "Diplomatic transcription, the standard in contemporary OCR, preserves the variants of the document valuable to book historians and linguists.", "labels": [], "entities": [{"text": "Diplomatic transcription", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.769987553358078}, {"text": "OCR", "start_pos": 55, "end_pos": 58, "type": "TASK", "confidence": 0.6161032319068909}]}, {"text": "Normalized or modernized transcription recovers the substantive content, producing a text that adheres to modern standards.", "labels": [], "entities": []}, {"text": "Normalized transcriptions are easier for users to read, and make large collections of historical texts indexable and searchable).", "labels": [], "entities": []}, {"text": "The current ideal for digital editions of historical texts has been described as a combination of diplomatic and normalized transcription.", "labels": [], "entities": []}, {"text": "This is generally achieved with a pipeline: first OCR is used to transcribe the document, then an (often manual) post-hoc normalization is performed.", "labels": [], "entities": []}, {"text": "However, such a pipeline will result in cascading errors from OCR mistakes, and fails to make use of knowledge about modern language during the initial transcription.", "labels": [], "entities": []}, {"text": "Additionally, post-processing tools are typically cumbersome language-specific, handbuilt systems ( In this work, we introduce a novel OCR model designed to jointly produce both diplomatic and normalized transcriptions.", "labels": [], "entities": []}, {"text": "The model is an extension of Ocular, the state of the art in historical OCR.", "labels": [], "entities": []}, {"text": "Ocular's innovative ability to handle the material challenges of OCR (unknown fonts, uneven inking, etc.) depends on its use of a character n-gram LM.", "labels": [], "entities": [{"text": "Ocular", "start_pos": 0, "end_pos": 6, "type": "DATASET", "confidence": 0.8795091509819031}]}, {"text": "Our model improves the quality of Ocular's transcriptions by automatically learning a probabilistic mapping between the LM, which is trained on modern text, and the unique orthography of the document.", "labels": [], "entities": [{"text": "Ocular's transcriptions", "start_pos": 34, "end_pos": 57, "type": "TASK", "confidence": 0.5851077338059744}]}, {"text": "This results in both an improved orthographically-correct diplomatic transcription and a modern-style normalized transcription.", "labels": [], "entities": []}, {"text": "To our knowledge, this represents the first OCR system that jointly produces both diplomatic and normalized transcriptions.", "labels": [], "entities": []}, {"text": "We evaluate our model on a multilingual collection of books exemplifying a high degree of orthographic variation.", "labels": [], "entities": []}, {"text": "For diplomatic transcription, our unsupervised joint model achieves an error reduction of 35% over the baseline Ocular system without support for orthographic variation, and nearly matches the error rate of an approach proposed by earlier work that uses a hand-constructed ruleset of orthographic rewrites.", "labels": [], "entities": [{"text": "diplomatic transcription", "start_pos": 4, "end_pos": 28, "type": "TASK", "confidence": 0.8591343462467194}, {"text": "error reduction", "start_pos": 71, "end_pos": 86, "type": "METRIC", "confidence": 0.9631241261959076}]}, {"text": "However, for the new task of normalized transcription, we achieve a 46% error reduction over the baseline, as well as a 28% reduction over the hand-built ruleset approach.", "labels": [], "entities": [{"text": "normalized transcription", "start_pos": 29, "end_pos": 53, "type": "TASK", "confidence": 0.9324004650115967}, {"text": "error reduction", "start_pos": 72, "end_pos": 87, "type": "METRIC", "confidence": 0.9813657701015472}]}], "datasetContent": [{"text": "As a first baseline, we compare against Ocular with no orthographic variation handling, in which characters generated by the LM are rendered directly.", "labels": [], "entities": []}, {"text": "As a second baseline, we compare to our previous work, which improved Ocular's diplomatic transcription accuracy by introducing orthographic variation directly into the LM with hand-constructed language-specific orthographic rules to rewrite the LM training data prior to n-gram estimation (.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 104, "end_pos": 112, "type": "METRIC", "confidence": 0.8093835115432739}]}, {"text": "However, this rule-based preprocessing approach is inadequate in many ways.", "labels": [], "entities": []}, {"text": "First, annotators do not know the full range of orthographic variations, or their frequencies, in each document, and it is impossible to write rules to handle typos.", "labels": [], "entities": []}, {"text": "Furthermore, a highly language-proficient   annotator is required, which is not always feasible with, e.g, rare indigenous languages.", "labels": [], "entities": []}, {"text": "Each baseline model has a single output, evaluated against both diplomatic and normalized gold.", "labels": [], "entities": []}, {"text": "Our source code and evaluation data are freely available at https://github.com/tberg12/ocular and https://github.com/dhgarrette/ocr-evaluation-data.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 3: Experimental results for both Diplomatic  (preserving variation) and Normalized (modern or- thography) transcription tasks. Results given as both  character error rate (CER, including punctuation)  and word error rate (WER, without punctuation).", "labels": [], "entities": [{"text": "character error rate (CER", "start_pos": 157, "end_pos": 182, "type": "METRIC", "confidence": 0.8614157676696778}, {"text": "word error rate", "start_pos": 212, "end_pos": 227, "type": "METRIC", "confidence": 0.8276041746139526}, {"text": "WER", "start_pos": 229, "end_pos": 232, "type": "METRIC", "confidence": 0.5009195804595947}]}, {"text": " Table 4: A sample of high-probability Spanish sub- stitution rules learned by our unsupervised model.", "labels": [], "entities": []}]}