{"title": [{"text": "Probabilistic Models for Learning a Semantic Parser Lexicon", "labels": [], "entities": []}], "abstractContent": [{"text": "We introduce several probabilistic models for learning the lexicon of a semantic parser.", "labels": [], "entities": [{"text": "learning the lexicon of a semantic parser", "start_pos": 46, "end_pos": 87, "type": "TASK", "confidence": 0.6228879136698586}]}, {"text": "Lexicon learning is the first step of training a semantic parser fora new application domain and the quality of the learned lexicon significantly affects both the accuracy and efficiency of the final semantic parser.", "labels": [], "entities": [{"text": "Lexicon learning", "start_pos": 0, "end_pos": 16, "type": "TASK", "confidence": 0.8415104746818542}, {"text": "accuracy", "start_pos": 163, "end_pos": 171, "type": "METRIC", "confidence": 0.998127281665802}]}, {"text": "Existing work on lexicon learning has focused on heuris-tic methods that lack convergence guarantees and require significant human input in the form of lexicon templates or annotated logical forms.", "labels": [], "entities": []}, {"text": "In contrast, our probabilistic models are trained directly from question/answer pairs using EM and our simplest model has a concave objective that guarantees convergence to a global optimum.", "labels": [], "entities": []}, {"text": "An experimental evaluation on a set of 4th grade science questions demonstrates that our models improve semantic parser accuracy (35-70% error reduction) and efficiency (4-25x more sentences per second) relative to prior work despite using less human input.", "labels": [], "entities": [{"text": "semantic parser", "start_pos": 104, "end_pos": 119, "type": "TASK", "confidence": 0.7032659649848938}, {"text": "accuracy", "start_pos": 120, "end_pos": 128, "type": "METRIC", "confidence": 0.8566556572914124}]}, {"text": "Our models also obtain competitive results on GEO880 without any dataset-specific engineering.", "labels": [], "entities": [{"text": "GEO880", "start_pos": 46, "end_pos": 52, "type": "DATASET", "confidence": 0.9791864156723022}]}], "introductionContent": [{"text": "Semantic parsing has recently gained popularity as a technique for mapping from natural language to a formal meaning representation language, e.g., in order to answer questions against a database).", "labels": [], "entities": [{"text": "Semantic parsing", "start_pos": 0, "end_pos": 16, "type": "TASK", "confidence": 0.8445350825786591}]}, {"text": "In order to train a semantic parser, one must first provide a lexicon, which is a mapping from words in the language to statements in the meaning representation language.", "labels": [], "entities": []}, {"text": "This mapping defines the grammar of the parser and thereby determines the set of meaning representations that can be produced for any given sentence.", "labels": [], "entities": []}, {"text": "Therefore, a good lexicon is necessary to achieve both high accuracy and parsing speed.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 60, "end_pos": 68, "type": "METRIC", "confidence": 0.9979907274246216}, {"text": "parsing", "start_pos": 73, "end_pos": 80, "type": "TASK", "confidence": 0.9568941593170166}]}, {"text": "However, the lexicon is unobserved in real semantic parsing applications, leading us to ask: how do we learn a lexicon fora semantic parser?", "labels": [], "entities": [{"text": "semantic parsing", "start_pos": 43, "end_pos": 59, "type": "TASK", "confidence": 0.7899452149868011}]}, {"text": "This paper presents several novel probabilistic models for learning a semantic parser lexicon.", "labels": [], "entities": []}, {"text": "Existing lexicon learning algorithms are heuristic in nature and require either annotated logical forms or manually-specified lexicon entry templates during training.", "labels": [], "entities": []}, {"text": "In contrast, our models do not require such templates and can be trained from question/answer pairs and other forms of weak supervision.", "labels": [], "entities": []}, {"text": "Training consists of optimizing an objective function with Expectation Maximization (EM), thereby guaran-teeing convergence to a local optimum.", "labels": [], "entities": [{"text": "Expectation Maximization (EM)", "start_pos": 59, "end_pos": 88, "type": "METRIC", "confidence": 0.8309657335281372}]}, {"text": "Furthermore, the objective function for our simplest model is concave, guaranteeing convergence to a global optimum.", "labels": [], "entities": []}, {"text": "Our approach generates a probabilistic context-free grammar that represents the space of correct semantic parses for each question; once trained, our approach derives lexicon entries from the most likely parse of each question).", "labels": [], "entities": []}, {"text": "We present an experimental evaluation of our lexicon learning models on a data set of food chain questions from a 4th grade science domain.", "labels": [], "entities": []}, {"text": "These questions concern relations between organisms in an ecosystem and have challenging lexical diversity and question length.", "labels": [], "entities": [{"text": "question length", "start_pos": 111, "end_pos": 126, "type": "TASK", "confidence": 0.513191431760788}]}, {"text": "Our models improve semantic parser accuracy (35-70% error reduction) over prior work despite using less human input.", "labels": [], "entities": [{"text": "semantic parser", "start_pos": 19, "end_pos": 34, "type": "TASK", "confidence": 0.8084510862827301}, {"text": "accuracy", "start_pos": 35, "end_pos": 43, "type": "METRIC", "confidence": 0.9276630878448486}, {"text": "error reduction", "start_pos": 52, "end_pos": 67, "type": "METRIC", "confidence": 0.9272025227546692}]}, {"text": "Furthermore, our best model produces a lexicon that contains 40x fewer entries than the most accurate baseline, resulting in a semantic parser that is 4x faster.", "labels": [], "entities": []}, {"text": "Our models also obtain competitive results on GEO880 without any dataset-specific engineering.", "labels": [], "entities": [{"text": "GEO880", "start_pos": 46, "end_pos": 52, "type": "DATASET", "confidence": 0.9791864156723022}]}], "datasetContent": [{"text": "We compare our lexicon learning models against several baselines on two data sets: FOODCHAINS, containing 4th grade science food chain questions, and GEO880, containing geography questions.", "labels": [], "entities": [{"text": "FOODCHAINS", "start_pos": 83, "end_pos": 93, "type": "METRIC", "confidence": 0.9829246401786804}, {"text": "GEO880", "start_pos": 150, "end_pos": 156, "type": "DATASET", "confidence": 0.8979846239089966}]}, {"text": "These data sets each present different challenges for lexicon learning: FOODCHAINS has more difficult language -long questions and more lexical variation -while  We performed an additional evaluation on GEO880 to demonstrate that our models can work with more complex logical forms.", "labels": [], "entities": [{"text": "FOODCHAINS", "start_pos": 72, "end_pos": 82, "type": "METRIC", "confidence": 0.8886415362358093}, {"text": "GEO880", "start_pos": 203, "end_pos": 209, "type": "DATASET", "confidence": 0.9875460267066956}]}, {"text": "GEO880 is a good data set for this evaluation because its logical forms contain, on average, about twice as many constants as FOOD-CHAINS.", "labels": [], "entities": [{"text": "GEO880", "start_pos": 0, "end_pos": 6, "type": "DATASET", "confidence": 0.9779386520385742}, {"text": "FOOD-CHAINS", "start_pos": 126, "end_pos": 137, "type": "METRIC", "confidence": 0.913709282875061}]}, {"text": "We applied PAL to generate a lexicon for this data set using its included logical form labels, then trained a CCG semantic parser with this lexicon.", "labels": [], "entities": []}, {"text": "compares the accuracy of this parser with previous CCG lexicon learning results on this data set using the standard 600/280 train/test split.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 13, "end_pos": 21, "type": "METRIC", "confidence": 0.9994968175888062}]}, {"text": "The comparison to PAL is inexact because both prior systems use CCG parsers with special extensions that improve performance on this data set.", "labels": [], "entities": []}, {"text": "UBL uses factored lexicon entries that generalize better to certain infrequent entries, and ZC2007 includes relaxed parsing operators that fix common parsing errors.", "labels": [], "entities": [{"text": "UBL", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.9626369476318359}, {"text": "ZC2007", "start_pos": 92, "end_pos": 98, "type": "DATASET", "confidence": 0.9276815056800842}]}, {"text": "Examining the errors made by our parser, we found many cases where these extensions would help.", "labels": [], "entities": []}, {"text": "We therefore trained another CCG parser using a lexicon generated by postprocessing PAL's lexicon to include factored lexicon entries.", "labels": [], "entities": []}, {"text": "This parser achieves an accuracy close to previous work.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 24, "end_pos": 32, "type": "METRIC", "confidence": 0.9993488192558289}]}], "tableCaptions": [{"text": " Table 1: Data statistics for FOODCHAINS and GEO880.", "labels": [], "entities": [{"text": "FOODCHAINS", "start_pos": 30, "end_pos": 40, "type": "DATASET", "confidence": 0.5917680263519287}, {"text": "GEO880", "start_pos": 45, "end_pos": 51, "type": "DATASET", "confidence": 0.957470178604126}]}, {"text": " Table 2: Comparison of semantic parser accuracy on FOOD-", "labels": [], "entities": [{"text": "accuracy", "start_pos": 40, "end_pos": 48, "type": "METRIC", "confidence": 0.6785536408424377}, {"text": "FOOD", "start_pos": 52, "end_pos": 56, "type": "DATASET", "confidence": 0.6803799271583557}]}, {"text": " Table 3: Semantic parser accuracy comparison for several lex-", "labels": [], "entities": [{"text": "accuracy", "start_pos": 26, "end_pos": 34, "type": "METRIC", "confidence": 0.9026113152503967}]}, {"text": " Table 4: Lexicon size excluding entity names and parse time", "labels": [], "entities": []}, {"text": " Table 5: Logical form accuracy on GEO880 compared to previ-", "labels": [], "entities": [{"text": "accuracy", "start_pos": 23, "end_pos": 31, "type": "METRIC", "confidence": 0.7302587628364563}, {"text": "GEO880", "start_pos": 35, "end_pos": 41, "type": "DATASET", "confidence": 0.9664832949638367}]}]}