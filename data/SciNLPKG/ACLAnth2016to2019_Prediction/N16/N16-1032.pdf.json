{"title": [{"text": "Drop-out Conditional Random Fields for Twitter with Huge Mined Gazetteer", "labels": [], "entities": [{"text": "Huge Mined Gazetteer", "start_pos": 52, "end_pos": 72, "type": "DATASET", "confidence": 0.7584638794263204}]}], "abstractContent": [{"text": "In named entity recognition task especially for massive data like Twitter, having a large amount of high quality gazetteers can alleviate the problem of training data scarcity.", "labels": [], "entities": [{"text": "named entity recognition", "start_pos": 3, "end_pos": 27, "type": "TASK", "confidence": 0.6158961256345113}]}, {"text": "One could collect large gazetteers from knowledge graph and phrase embeddings to obtain high coverage of gazetteers.", "labels": [], "entities": []}, {"text": "However, large gazetteers cause a side-effect called \"feature under-training\", where the gazetteer features overwhelm the context features.", "labels": [], "entities": []}, {"text": "To resolve this problem, we propose the dropout conditional random fields, which decrease the influence of gazetteer features with a high weight.", "labels": [], "entities": []}, {"text": "Our experiments on named entity recognition with Twitter data lead to higher F1 score of 69.38%, about 4% better than the strong base-line presented in Smith and Osborne (2006).", "labels": [], "entities": [{"text": "named entity recognition", "start_pos": 19, "end_pos": 43, "type": "TASK", "confidence": 0.6296684841314951}, {"text": "F1 score", "start_pos": 77, "end_pos": 85, "type": "METRIC", "confidence": 0.9742803573608398}]}], "introductionContent": [{"text": "Nowadays, people are generating tremendous amount of information on social websites.", "labels": [], "entities": []}, {"text": "For example, more than 200 million tweets are generated everyday on Twitter ().", "labels": [], "entities": []}, {"text": "Twitter has become a key news source, in addition to standard news channels.", "labels": [], "entities": []}, {"text": "As such, social scientists are starting to pay attention to it in recent years).", "labels": [], "entities": []}, {"text": "The traditional machine learned modeling approaches trained with small and clean general text, such as news articles, perform poorly when applied to tweets, because tweets are structurally very different from general text.", "labels": [], "entities": []}, {"text": "Thus, it \u00a7 Both authors contributed equally. is necessary to build new models for Twitter.", "labels": [], "entities": []}, {"text": "One could label a reasonable size of tweets to train a model fora natural language processing (NLP) application.", "labels": [], "entities": []}, {"text": "The problem is that it is very expensive to refresh the annotated data to keep the model upto-date, because users generate tweets in a unprecedented rate).", "labels": [], "entities": []}, {"text": "An obvious solution to the problem is to develop methods of utilizing a large amount of unlabeled data.", "labels": [], "entities": []}, {"text": "One way is to induce word embeddings in a real-valued vector space from a large number of tweets ().", "labels": [], "entities": []}, {"text": "It is shown that the task-specific embeddings induced on tweets provide more powerful than those created from out-ofdomain texts ().", "labels": [], "entities": []}, {"text": "Another method is to build the task-specific gazetteers.", "labels": [], "entities": []}, {"text": "Task-specific gazetteers make the models more general and increase their coverage for unseen events.", "labels": [], "entities": []}, {"text": "They have been proven to be useful on a number of tasks ().", "labels": [], "entities": []}, {"text": "Since gazetteers can improve modeling performance, here we more focus on how to use gazetteer more effectively.", "labels": [], "entities": []}, {"text": "To build gazetteers with sufficient coverage for our task, we first expand gazetteers from knowledge graph and phrase embeddings.", "labels": [], "entities": []}, {"text": "However, since the expanded gazetteers cover significant proportions of the entities in the training data, the weight of gazetteers features are easily inflated and thus the model tends to rely too much on lexical features extracted from the gazetteers fea-tures to assign a tag rather than the contextual features such as n-gram, a phenomenon called \"feature under-training\".", "labels": [], "entities": []}, {"text": "As a result, we often observe noticeable performance degradation attest time when the entity value does not exist in the training set or the entity dictionary.", "labels": [], "entities": []}, {"text": "To solve this problem, we introduce a model called dropout CRFs 1 and compare to the combination model proposed by.", "labels": [], "entities": []}, {"text": "In our experiments, we show that the proposed method significantly improves the F1 score from 65.54% to 69.38%, compared to the baseline.", "labels": [], "entities": [{"text": "F1 score", "start_pos": 80, "end_pos": 88, "type": "METRIC", "confidence": 0.9814399778842926}]}], "datasetContent": [{"text": "To demonstrate the effectiveness of the dropout CRFs, we run experiments on named entity recognition task on the Twitter dataset of.", "labels": [], "entities": [{"text": "named entity recognition", "start_pos": 76, "end_pos": 100, "type": "TASK", "confidence": 0.6106112202008566}, {"text": "Twitter dataset", "start_pos": 113, "end_pos": 128, "type": "DATASET", "confidence": 0.7994459867477417}]}, {"text": "We refer the readers to for the details of the dataset.", "labels": [], "entities": []}, {"text": "We split the data into 70% for training, 10% for tuning, and 20% for testing.", "labels": [], "entities": []}, {"text": "For all the experiments presented in this section, both CRFs and dropout CRFs are trained using the L-BFGS (.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Comparison of models with or without dropout.", "labels": [], "entities": []}, {"text": " Table 3: Comparison of vanilla CRF model and dropout model", "labels": [], "entities": []}]}