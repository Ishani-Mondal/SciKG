{"title": [{"text": "Instant Feedback for Increasing the Presence of Solutions in Peer Reviews", "labels": [], "entities": []}], "abstractContent": [{"text": "We present the design and evaluation of a web-based peer review system that uses natural language processing to automatically evaluate and provide instant feedback regarding the presence of solutions in peer reviews.", "labels": [], "entities": []}, {"text": "Student reviewers can then choose to either revise their reviews to address the system's feedback, or ignore the feedback and submit their original reviews.", "labels": [], "entities": []}, {"text": "A system deployment in multiple high school classrooms shows that our solution prediction model triggers instant feedback with high precision, and that the feedback is successful in increasing the number of peer reviews with solutions.", "labels": [], "entities": [{"text": "solution prediction", "start_pos": 70, "end_pos": 89, "type": "TASK", "confidence": 0.8417830467224121}, {"text": "precision", "start_pos": 132, "end_pos": 141, "type": "METRIC", "confidence": 0.9883149862289429}]}], "introductionContent": [{"text": "Peer review provides learning opportunities for students in their roles as both author and reviewer, and is a promising approach for helping students improve their writing).", "labels": [], "entities": [{"text": "Peer review", "start_pos": 0, "end_pos": 11, "type": "TASK", "confidence": 0.7442775368690491}]}, {"text": "However, one limitation of peer review is that student reviewers are generally novices in their disciplines and typically inexperienced in constructing helpful textual reviews.", "labels": [], "entities": []}, {"text": "Research in the learning sciences has identified properties of helpful comments in textual reviews, e.g., localizing where problems occur in a paper and suggesting solutions to problems, or providing review justifications such as explanations of judgments (.", "labels": [], "entities": []}, {"text": "Research in computer science, in turn, has used natural language processing and machine learning to build models for automatically identifying helpful review properties, including localization and solution (, as well as quality and tone.", "labels": [], "entities": []}, {"text": "While such prediction models have been evaluated intrinsically (i.e., with respect to predicting gold-standard labels), few have actually been incorporated into working peer review systems and evaluated extrinsically).", "labels": [], "entities": [{"text": "predicting gold-standard labels", "start_pos": 86, "end_pos": 117, "type": "TASK", "confidence": 0.8638165791829427}]}, {"text": "The SWoRD research project 1 involves different active research threads for improving the utility of an existing web-based peer review system.", "labels": [], "entities": [{"text": "SWoRD research project", "start_pos": 4, "end_pos": 26, "type": "DATASET", "confidence": 0.7787326176961263}]}, {"text": "Our research in the SWoRD project aims at building instant feedback components for improving the quality of textual peer reviews.", "labels": [], "entities": []}, {"text": "Our initial work focused on improving review localization (", "labels": [], "entities": []}], "datasetContent": [{"text": "In Spring 2015, SWoRD with instant-feedback was deployed in 9 high-school Advanced Placement (AP) classes.", "labels": [], "entities": []}, {"text": "We conducted preliminary evaluations to answer two research questions: (1) How precisely does the system predict peer review solution and trigger the instant feedback?", "labels": [], "entities": []}, {"text": "(2) How does the instant feedback impact review revisions?", "labels": [], "entities": []}, {"text": "We collected peer review submissions which were intervened by Instant-feedback SWoRD (i.e., triggered instant feedback), and their immediately subsequent resubmissions (if any), then had an expert manually code the collected comments for their feedback types: solution, problem-only, non-criticism (double-coded data had inter-rater \u03ba 0.87).", "labels": [], "entities": [{"text": "Instant-feedback", "start_pos": 62, "end_pos": 78, "type": "METRIC", "confidence": 0.9580388069152832}]}, {"text": "Only intervened reviews were used to evaluate model performance because subsequent resubmissions were not predicted.", "labels": [], "entities": []}, {"text": "In our deployment, 134 of 1428 reviews were intervened, containing 891 comments: 223 Solution, 340 Problem-only, and 328 Non-criticism.", "labels": [], "entities": []}, {"text": "shows that our deployed model outperforms a Bag-of-Words (BoW) baseline 6 in 3-way classification.", "labels": [], "entities": []}, {"text": "Given that the AP data was never used for model training, the obtained performance is promising and encourages us to improve the model with more data.", "labels": [], "entities": [{"text": "AP data", "start_pos": 15, "end_pos": 22, "type": "DATASET", "confidence": 0.6588517427444458}]}, {"text": "Regarding instant feedback precision, we calculated the true S-RATIO for each intervened review (using gold standard labels).", "labels": [], "entities": [{"text": "precision", "start_pos": 27, "end_pos": 36, "type": "METRIC", "confidence": 0.8958775997161865}, {"text": "S-RATIO", "start_pos": 61, "end_pos": 68, "type": "METRIC", "confidence": 0.9700765609741211}]}, {"text": "shows that given the 0.7 threshold used for this deployment, Instant-feedback SWoRD incorrectly triggered instant feedback for 24 submissions (column 3) out of 134, yielding a precision 0.82.", "labels": [], "entities": [{"text": "precision", "start_pos": 176, "end_pos": 185, "type": "METRIC", "confidence": 0.9805747270584106}]}, {"text": "Because Instantfeedback SWoRD does not let student reviewers know the S-RATIO threshold, students should only think that the instant feedback was incorrect when Used 1,2,3-grams as features.", "labels": [], "entities": [{"text": "S-RATIO threshold", "start_pos": 70, "end_pos": 87, "type": "METRIC", "confidence": 0.9444279968738556}]}, {"text": "True S-RATIO \u2264 1.0 > 0.7 = 1.0 #intervened 134 24 (18%) 16 (12%): True S-RATIO of intervened submission they provided solutions for all mentioned problems (true S-RATIO = 1).", "labels": [], "entities": []}, {"text": "From this student perspective, Instant-feedback SWoRD had 16 incorrect triggers (column 4), achieving a precision 0.88.", "labels": [], "entities": [{"text": "precision", "start_pos": 104, "end_pos": 113, "type": "METRIC", "confidence": 0.9963265061378479}]}, {"text": "Finally, to evaluate the impact of instant feedback on review revision, we considered the 74 subsequent resubmissions.", "labels": [], "entities": [{"text": "review revision", "start_pos": 55, "end_pos": 70, "type": "TASK", "confidence": 0.4468786120414734}]}, {"text": "We collected comments that were revised or newly-added to the resubmissions (no comment was deleted), and obtained 115 comments.", "labels": [], "entities": []}, {"text": "Pairing 111 revised comments with their original versions, we observed that 73 (66%) comments were fixed from problem-only to solution, 3 (3%) from non-criticism to solution, only 1 comment (0.9%) was edited from solution to non-criticism, and none from solution to problem-only.", "labels": [], "entities": []}, {"text": "All of the 4 newly-added comments mentioned problems and provided solutions.", "labels": [], "entities": []}, {"text": "These results suggest that Instant-feedback SWoRD does indeed help reviewers revise their comments to include more solutions.", "labels": [], "entities": [{"text": "Instant-feedback SWoRD", "start_pos": 27, "end_pos": 49, "type": "TASK", "confidence": 0.45916683971881866}]}], "tableCaptions": [{"text": " Table 1: Comment-level solution prediction performance. Acc:", "labels": [], "entities": [{"text": "Comment-level solution prediction", "start_pos": 10, "end_pos": 43, "type": "TASK", "confidence": 0.59876216451327}, {"text": "Acc", "start_pos": 57, "end_pos": 60, "type": "METRIC", "confidence": 0.8847499489784241}]}]}