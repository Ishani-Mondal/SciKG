{"title": [], "abstractContent": [{"text": "Automatically generated databases of English paraphrases have the drawback that they return a single list of paraphrases for an input word or phrase.", "labels": [], "entities": []}, {"text": "This means that all senses of polysemous words are grouped together, unlike WordNet which partitions different senses into separate synsets.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 76, "end_pos": 83, "type": "DATASET", "confidence": 0.939494252204895}]}, {"text": "We present anew method for clustering paraphrases byword sense, and apply it to the Paraphrase Database (PPDB).", "labels": [], "entities": [{"text": "clustering paraphrases byword sense", "start_pos": 27, "end_pos": 62, "type": "TASK", "confidence": 0.8187300115823746}, {"text": "Paraphrase Database (PPDB)", "start_pos": 84, "end_pos": 110, "type": "DATASET", "confidence": 0.7685154616832733}]}, {"text": "We investigate the performance of hierarchical and spectral clustering algorithms, and systematically explore different ways of defining the similarity matrix that they use as input.", "labels": [], "entities": []}, {"text": "Our method produces sense clusters that are qualitatively and quantitatively good, and that represent a substantial improvement to the PPDB resource.", "labels": [], "entities": [{"text": "PPDB resource", "start_pos": 135, "end_pos": 148, "type": "DATASET", "confidence": 0.8509349226951599}]}], "introductionContent": [{"text": "Many natural language processing tasks rely on the ability to identify words and phrases with equivalent meaning but different wording.", "labels": [], "entities": [{"text": "natural language processing", "start_pos": 5, "end_pos": 32, "type": "TASK", "confidence": 0.6631468931833903}]}, {"text": "These alternative ways of expressing the same information are called paraphrases.", "labels": [], "entities": []}, {"text": "Several research efforts have produced automatically generated databases of English paraphrases, including DIRT (), the Microsoft Research Paraphrase Phrase Tables (), and the Paraphrase Database (.", "labels": [], "entities": [{"text": "DIRT", "start_pos": 107, "end_pos": 111, "type": "DATASET", "confidence": 0.7648895978927612}, {"text": "Microsoft Research Paraphrase Phrase Tables", "start_pos": 120, "end_pos": 163, "type": "DATASET", "confidence": 0.7600238919258118}]}, {"text": "A primary benefit of these automatically generated resources is their enormous scale, which provides superior coverage compared to manually compiled resources like WordNet.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 164, "end_pos": 171, "type": "DATASET", "confidence": 0.966060996055603}]}, {"text": "But automatically generated paraphrase resources currently have the drawback that they group all senses of polysemous words together, and do not partition paraphrases into groups like WordNet does Figure 1: Our goal is to partition paraphrases of an input word like bug into clusters representing its distinct senses. with its synsets.", "labels": [], "entities": []}, {"text": "Thus a search for paraphrases of the noun bug would yield a single list of paraphrases that includes insect, glitch, beetle, error, microbe, wire, cockroach, malfunction, microphone, mosquito, virus, tracker, pest, informer, snitch, parasite, bacterium, fault, mistake, failure and many others.", "labels": [], "entities": [{"text": "error, microbe, wire, cockroach, malfunction, microphone, mosquito, virus, tracker, pest, informer, snitch, parasite, bacterium, fault, mistake,", "start_pos": 125, "end_pos": 269, "type": "Description", "confidence": 0.7720030834898353}]}, {"text": "The goal of this work is to group these paraphrases into clusters that denote the distinct senses of the input word or phrase, as shown in.", "labels": [], "entities": []}, {"text": "We develop a method for clustering the paraphrases from the Paraphrase Database (PPDB).", "labels": [], "entities": [{"text": "Paraphrase Database (PPDB)", "start_pos": 60, "end_pos": 86, "type": "DATASET", "confidence": 0.8162499904632569}]}, {"text": "PPDB contains over 100 million paraphrases generated using the bilingual pivoting method), which posits that two English words are potential paraphrases of each other if they share one or more foreign translations.", "labels": [], "entities": [{"text": "PPDB", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.9106318950653076}]}, {"text": "We apply two clustering algorithms, Hierarchical Graph Factorization Clustering () and Self-Tuning Spectral Clustering (, and systematically explore different ways of defining the similarity matrix that they use as input.", "labels": [], "entities": []}, {"text": "We exploit a variety of features from PPDB to cluster its paraphrases by sense, including its im- plicit graph structure, aligned foreign words, paraphrase scores, predicted entailment relations, and monolingual distributional similarity scores.", "labels": [], "entities": []}, {"text": "Our goal is to determine which algorithm and features are the most effective for clustering paraphrases by sense.", "labels": [], "entities": []}, {"text": "We address three research questions: \u2022 Which similarity metric is best for sense clustering?", "labels": [], "entities": [{"text": "sense clustering", "start_pos": 75, "end_pos": 91, "type": "TASK", "confidence": 0.8185039460659027}]}, {"text": "We systematically compare different ways of defining matrices that specify the similarity between pairs of paraphrases.", "labels": [], "entities": []}, {"text": "\u2022 Are better clusters produced by comparing second-order paraphrases?", "labels": [], "entities": []}, {"text": "We use PPDB's graph structure to decide whether mosquito and pest belong to the same sense cluster by comparing lists of paraphrases for the two words.", "labels": [], "entities": []}, {"text": "\u2022 Can entailment relations inform sense clustering?", "labels": [], "entities": [{"text": "sense clustering", "start_pos": 34, "end_pos": 50, "type": "TASK", "confidence": 0.7022481709718704}]}, {"text": "We exploit knowledge like beetle is-an insect, and that there is no entailment between malfunction and microbe.", "labels": [], "entities": []}, {"text": "Our method produces sense clusters that are qualitatively and quantitatively good, and that represent a substantial improvement to the PPDB resource.", "labels": [], "entities": [{"text": "PPDB resource", "start_pos": 135, "end_pos": 148, "type": "DATASET", "confidence": 0.8509349226951599}]}], "datasetContent": [{"text": "We follow the experimental setup of.", "labels": [], "entities": []}, {"text": "We focus our evaluation on a set of query words drawn from the LexSub test data, plus 16 additional handpicked polysemous words.", "labels": [], "entities": [{"text": "LexSub test data", "start_pos": 63, "end_pos": 79, "type": "DATASET", "confidence": 0.9890337387720743}]}, {"text": "We evaluate our method using two standard metrics: the paired F-Score and V-Measure.", "labels": [], "entities": [{"text": "F-Score", "start_pos": 62, "end_pos": 69, "type": "METRIC", "confidence": 0.9560469388961792}]}, {"text": "Both were used in the 2010 SemEval Word Sense Induction Task ( and by.", "labels": [], "entities": [{"text": "SemEval Word Sense Induction Task", "start_pos": 27, "end_pos": 60, "type": "TASK", "confidence": 0.7882016897201538}]}, {"text": "We give our results in terms of weighted average performance on these metrics, where the score for each individual paraphrase set is weighted by the number of reference clusters for that query word.", "labels": [], "entities": []}, {"text": "Paired F-Score frames the clustering problem as a classification task (.", "labels": [], "entities": [{"text": "F-Score", "start_pos": 7, "end_pos": 14, "type": "METRIC", "confidence": 0.8229230046272278}, {"text": "clustering problem", "start_pos": 26, "end_pos": 44, "type": "TASK", "confidence": 0.9013777077198029}]}, {"text": "It gen-erates the set of all word pairs belonging to the same reference cluster, F (S), and the set of all word pairs belonging to the same automatically-generated cluster, F (K).", "labels": [], "entities": []}, {"text": "Precision, recall, and F-score can then be calculated in the usual way, i.e. P = F (K)\u2229F (S) , and F = 2\u00b7P \u00b7R P +R . V-Measure assesses the quality of a clustering solution against reference clusters in terms of clustering homogeneity and completeness.", "labels": [], "entities": [{"text": "Precision", "start_pos": 0, "end_pos": 9, "type": "METRIC", "confidence": 0.9952632188796997}, {"text": "recall", "start_pos": 11, "end_pos": 17, "type": "METRIC", "confidence": 0.9986214637756348}, {"text": "F-score", "start_pos": 23, "end_pos": 30, "type": "METRIC", "confidence": 0.996207594871521}]}, {"text": "Homogeneity describes the extent to which each cluster is composed of paraphrases belonging to the same reference cluster, and completeness refers to the extent to which points in a reference cluster are assigned to a single cluster.", "labels": [], "entities": [{"text": "completeness", "start_pos": 127, "end_pos": 139, "type": "METRIC", "confidence": 0.9488184452056885}]}, {"text": "Both are defined in terms of conditional entropy.", "labels": [], "entities": []}, {"text": "VMeasure is the harmonic mean of homogeneity hand completeness c; V-Measure = 2\u00b7h\u00b7c h+c .", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Average performance and number of clus- ters produced by our different similarity methods.", "labels": [], "entities": []}]}