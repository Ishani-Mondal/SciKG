{"title": [], "abstractContent": [{"text": "Word clusters improve performance in many NLP tasks including training neural network language models, but current increases in datasets are outpacing the ability of word clusterers to handle them.", "labels": [], "entities": []}, {"text": "In this paper we present a novel bidirectional, interpolated, refining , and alternating (BIRA) predictive exchange algorithm and introduce ClusterCat, a clusterer based on this algorithm.", "labels": [], "entities": [{"text": "alternating (BIRA", "start_pos": 77, "end_pos": 94, "type": "METRIC", "confidence": 0.8141910433769226}]}, {"text": "We show that ClusterCat is 3-85 times faster than four other well-known clusterers, while also improving upon the predictive exchange algo-rithm's perplexity by up to 18%.", "labels": [], "entities": []}, {"text": "Notably, ClusterCat clusters a 2.5 billion token English News Crawl corpus in 3 hours.", "labels": [], "entities": [{"text": "English News Crawl corpus", "start_pos": 49, "end_pos": 74, "type": "DATASET", "confidence": 0.7740640863776207}]}, {"text": "We also evaluate in a machine translation setting, resulting in shorter training times achieving the same translation quality measured in BLEU scores.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 22, "end_pos": 41, "type": "TASK", "confidence": 0.7857706844806671}, {"text": "BLEU", "start_pos": 138, "end_pos": 142, "type": "METRIC", "confidence": 0.997734785079956}]}, {"text": "ClusterCat is portable and freely available.", "labels": [], "entities": [{"text": "ClusterCat", "start_pos": 0, "end_pos": 10, "type": "DATASET", "confidence": 0.8759677410125732}]}], "introductionContent": [{"text": "Words can be grouped into equivalence classes to reduce data sparsity and generalize data.", "labels": [], "entities": []}, {"text": "Word clusters are useful in many NLP applications.", "labels": [], "entities": []}, {"text": "Within machine translation, word classes are used in word alignment (), translation models (, reordering, preordering, SAMT (), and OSM (.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 7, "end_pos": 26, "type": "TASK", "confidence": 0.7306662797927856}, {"text": "word alignment", "start_pos": 53, "end_pos": 67, "type": "TASK", "confidence": 0.7598508894443512}]}, {"text": "Word clusterings have also found utility in parsing (), chunking, and NER (), among many others.", "labels": [], "entities": [{"text": "Word clusterings", "start_pos": 0, "end_pos": 16, "type": "TASK", "confidence": 0.6119607090950012}, {"text": "parsing", "start_pos": 44, "end_pos": 51, "type": "TASK", "confidence": 0.9781808257102966}, {"text": "chunking", "start_pos": 56, "end_pos": 64, "type": "TASK", "confidence": 0.9544870853424072}]}, {"text": "Word clusters also speedup normalization in training neural network and MaxEnt language models, via class-based decomposition.", "labels": [], "entities": []}, {"text": "This reduces the normalization time from O(|V |) (the vocabulary size) to \u2248 O( |V |) .", "labels": [], "entities": [{"text": "O", "start_pos": 41, "end_pos": 42, "type": "METRIC", "confidence": 0.971479594707489}]}], "datasetContent": [{"text": "For the two-sided class-based LM task we used 800 and 1200 classes for English, and 800 classes for Russian.", "labels": [], "entities": []}, {"text": "The clusterers (cf. Sec.", "labels": [], "entities": []}, {"text": "2) are Browncluster (, ClusterCat (introduced in Section 3), mkcls (Och, 1995), Phrasal's clusterer (, and word2vec's clustering feature ().", "labels": [], "entities": [{"text": "Browncluster", "start_pos": 7, "end_pos": 19, "type": "DATASET", "confidence": 0.9071692824363708}]}, {"text": "The data comes from the 2011-2013 News Crawl monolingual data of the WMT task.", "labels": [], "entities": [{"text": "News Crawl monolingual data", "start_pos": 34, "end_pos": 61, "type": "DATASET", "confidence": 0.8967197835445404}, {"text": "WMT task", "start_pos": 69, "end_pos": 77, "type": "TASK", "confidence": 0.5426097512245178}]}, {"text": "3 For these experiments the data was deduplicated, shuffled, tokenized, digit-conflated, and lowercased.", "labels": [], "entities": []}, {"text": "In order to have a large test set, one line per 100 of the resulting corpus was separated into the test set.", "labels": [], "entities": []}, {"text": "For English this gave 1B training tokens, 2M training types, and 12M test tokens.", "labels": [], "entities": []}, {"text": "For Russian, 550M training tokens, 2.7M training types, and 6M test tokens.", "labels": [], "entities": []}, {"text": "All clusterers had a minimum count threshold of 3 occurrences in the training set.", "labels": [], "entities": []}, {"text": "All used 12 threads and 15 iterations, except single-threaded mkcls which used the default one iteration.", "labels": [], "entities": []}, {"text": "Clusterings were performed on a 2.4 GHz Opteron 8378 machine featuring 16 threads and 64 GB of RAM.", "labels": [], "entities": [{"text": "Opteron 8378 machine", "start_pos": 40, "end_pos": 60, "type": "DATASET", "confidence": 0.9384475151697794}]}, {"text": "The predictive exchange-based clusterers (ClusterCat and Phrasal) exhibit slow time growth as |C| increases, while the other three (Brown, mkcls, and word2vec) are much more sensitive to |C| . ClusterCat is three times faster than Phrasal for all sets.", "labels": [], "entities": [{"text": "Phrasal", "start_pos": 57, "end_pos": 64, "type": "DATASET", "confidence": 0.9338245987892151}]}, {"text": "For both English and Russian we observe prohibitive growth for mkcls, with the full Russian training set taking over 3 days, compared to 1.5 hours for ClusterCat.", "labels": [], "entities": []}, {"text": "We performed an additional experiment on ClusterCat, adding more training data.", "labels": [], "entities": [{"text": "ClusterCat", "start_pos": 41, "end_pos": 51, "type": "DATASET", "confidence": 0.9261007905006409}]}, {"text": "3.0 hours to cluster 2.5 billion training tokens, using 40 GB of memory for |C| = 800.", "labels": [], "entities": []}, {"text": "When the number of clusters was tripled to |C| = 2400 , the same 2.5B corpus was clustered in under 8 hours.", "labels": [], "entities": []}, {"text": "The clusterings are also evaluated on the perplexity (PP) of an external 5-gram two-sided class-based LM.", "labels": [], "entities": [{"text": "perplexity (PP)", "start_pos": 42, "end_pos": 57, "type": "METRIC", "confidence": 0.71534064412117}]}, {"text": "found that the two-sided model (which mkcls uses) tends to give better PP in two-sided class-based LM experiments, but the onesided model of the predictive exchange that we employed produces better PP for training LSTM LMs.", "labels": [], "entities": []}, {"text": "shows perplexity results using a varying number of classes.", "labels": [], "entities": []}, {"text": "As word2vec is the only clusterer not optimized on log-likelihood, its perplexity is quite high, and remains high as more training data is added.", "labels": [], "entities": []}, {"text": "On the other hand, mkcls gives the lowest perplexity, although this is an artefact of the twosided evaluation.", "labels": [], "entities": []}, {"text": "ClusterCat gives lower perplexity than the original predictive exchange algorithm (in Phrasal) and Brown clustering.", "labels": [], "entities": [{"text": "Phrasal", "start_pos": 86, "end_pos": 93, "type": "DATASET", "confidence": 0.890388011932373}]}, {"text": "The Russian experiments yielded higher PP for all clusterings, but otherwise the same comparative results.", "labels": [], "entities": [{"text": "PP", "start_pos": 39, "end_pos": 41, "type": "METRIC", "confidence": 0.9977198243141174}]}, {"text": "The metaheuristic techniques used in mkcls can be applied to other exchange-based clusterers-including ours-for further improvements.", "labels": [], "entities": []}, {"text": "It is also interesting to look at time-sensitive clustering.", "labels": [], "entities": []}, {"text": "shows what perplexity can be obtained within a given training time frame.", "labels": [], "entities": []}, {"text": "For each clusterer, each successive rightward point in the figure represents an order of magnitude more training data, from 10 6 to 10 9 tokens.", "labels": [], "entities": []}, {"text": "ClusterCat can train on 10 times more data than either mkcls or Browncluster and produces better perplexity than either, within a given amount of time.", "labels": [], "entities": [{"text": "Browncluster", "start_pos": 64, "end_pos": 76, "type": "DATASET", "confidence": 0.9540424346923828}]}, {"text": "This training set was too large for the external class-based LM to fit into memory, so no perplexity evaluation of this clustering was possible.", "labels": [], "entities": []}, {"text": "The skip-gram model within word2vec resulted in even higher PP at almost three times the clustering time, relative to the CBOW model that we used.", "labels": [], "entities": [{"text": "PP", "start_pos": 60, "end_pos": 62, "type": "METRIC", "confidence": 0.9713456630706787}]}, {"text": "Using hierarchical softmax with a window of one word on either side gave no appreciable difference in perplexity, while also increasing training time.", "labels": [], "entities": []}, {"text": "We also evaluated mkcls and ClusterCat extrinsically in machine translation, for word alignment.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 56, "end_pos": 75, "type": "TASK", "confidence": 0.7150700688362122}, {"text": "word alignment", "start_pos": 81, "end_pos": 95, "type": "TASK", "confidence": 0.7917051613330841}]}, {"text": "As training sets get larger every year, mkcls struggles to keep pace, and is a substantial time bottleneck in MT pipelines.", "labels": [], "entities": [{"text": "MT", "start_pos": 110, "end_pos": 112, "type": "TASK", "confidence": 0.9818850159645081}]}, {"text": "We compare time and BLEU scores of using either mkcls or ClusterCat for Russian\u2194English translation.", "labels": [], "entities": [{"text": "time", "start_pos": 11, "end_pos": 15, "type": "METRIC", "confidence": 0.9880468845367432}, {"text": "BLEU", "start_pos": 20, "end_pos": 24, "type": "METRIC", "confidence": 0.9989321827888489}, {"text": "Russian\u2194English translation", "start_pos": 72, "end_pos": 99, "type": "TASK", "confidence": 0.5433503240346909}]}, {"text": "The parallel data comes from the WMT-2015 Common Crawl Corpus, News Commentary, Yandex 1M Corpus, and the Wiki Headlines Corpus.", "labels": [], "entities": [{"text": "WMT-2015 Common Crawl Corpus", "start_pos": 33, "end_pos": 61, "type": "DATASET", "confidence": 0.9042052924633026}, {"text": "Yandex 1M Corpus", "start_pos": 80, "end_pos": 96, "type": "DATASET", "confidence": 0.9093744357426962}, {"text": "Wiki Headlines Corpus", "start_pos": 106, "end_pos": 127, "type": "DATASET", "confidence": 0.907017449537913}]}, {"text": "The monolingual data consists of 2007-2014 News Commentary and News Crawl articles.", "labels": [], "entities": []}, {"text": "The dev and test sets contain 3000 sentences from EN\u2192RU manually translated news articles.", "labels": [], "entities": [{"text": "EN\u2192RU manually translated news articles", "start_pos": 50, "end_pos": 89, "type": "TASK", "confidence": 0.5356936965669904}]}, {"text": "We used standard configurations, like truecasing, MGIZA alignment, GDFA phrase extraction, phrase-based Moses, quantized KenLM 5-gram MKN LMs, and MERT tuning.", "labels": [], "entities": [{"text": "MGIZA alignment", "start_pos": 50, "end_pos": 65, "type": "TASK", "confidence": 0.6902632415294647}, {"text": "GDFA phrase extraction", "start_pos": 67, "end_pos": 89, "type": "TASK", "confidence": 0.5864447752634684}]}, {"text": "presents the BLEU score changes across varying cluster sizes.", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 13, "end_pos": 23, "type": "METRIC", "confidence": 0.9760175943374634}]}, {"text": "The BLEU score differences between using mkcls and ClusterCat are minimal but there area few statistically significant changes, using bootstrap resampling).", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 4, "end_pos": 14, "type": "METRIC", "confidence": 0.9726751446723938}]}, {"text": "Figure 3 shows translation model training times, before MERT.", "labels": [], "entities": [{"text": "translation model training", "start_pos": 15, "end_pos": 41, "type": "TASK", "confidence": 0.8524864315986633}, {"text": "MERT", "start_pos": 56, "end_pos": 60, "type": "METRIC", "confidence": 0.7953469157218933}]}, {"text": "Using ClusterCat reduces the translation model training time with 500 clusters from 20 hours using mkcls (of which 60% of the time is spent on clustering) to just 8 hours (of which 5% is spent on clustering).", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Clustering times (hours) of full training sets. For En-", "labels": [], "entities": []}, {"text": " Table 2: 5-gram two-sided class-based LM PP using 10 9 En-", "labels": [], "entities": []}, {"text": " Table 3: BLEU score changes and significance across", "labels": [], "entities": [{"text": "BLEU score changes", "start_pos": 10, "end_pos": 28, "type": "METRIC", "confidence": 0.9582632978757223}, {"text": "significance", "start_pos": 33, "end_pos": 45, "type": "METRIC", "confidence": 0.9136340022087097}]}]}