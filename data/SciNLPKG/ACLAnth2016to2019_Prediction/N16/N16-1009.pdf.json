{"title": [{"text": "Entity-balanced Gaussian pLSA for Automated Comparison", "labels": [], "entities": [{"text": "pLSA", "start_pos": 25, "end_pos": 29, "type": "METRIC", "confidence": 0.8710027933120728}]}], "abstractContent": [{"text": "Community created content (e.g., product descriptions , reviews) typically discusses one entity at a time and it can be hard as well as time consuming fora user to compare two or more entities.", "labels": [], "entities": []}, {"text": "In response, we define a novel task of automatically generating entity comparisons from text.", "labels": [], "entities": []}, {"text": "Our output is a table that semantically clusters descriptive phrases about entities.", "labels": [], "entities": []}, {"text": "Our clustering algorithm is a Gaussian extension of probabilis-tic latent semantic analysis (pLSA), in which each phrase is represented in word vector embedding space.", "labels": [], "entities": [{"text": "probabilis-tic latent semantic analysis (pLSA)", "start_pos": 52, "end_pos": 98, "type": "TASK", "confidence": 0.6950606448309762}]}, {"text": "In addition, our algorithm attempts to balance information about entities in each cluster to generate meaningful comparison tables, where possible.", "labels": [], "entities": []}, {"text": "We test our sys-tem's effectiveness on two domains, travel articles and movie reviews, and find that entity-balanced clusters are strongly preferred by users.", "labels": [], "entities": []}], "introductionContent": [{"text": "The proliferation of Web 2.0 has enabled ready access to large amounts of community created content, such as status messages, blogs, wikis, and reviews.", "labels": [], "entities": []}, {"text": "These form an important source of knowledge in our day today decision making, such as deciding which restaurant to try, or which movie to watch, or which city to visit etc.", "labels": [], "entities": [{"text": "decision making", "start_pos": 61, "end_pos": 76, "type": "TASK", "confidence": 0.735017716884613}]}, {"text": "Unfortunately, such content typically focuses on one real world entity at a time, whereas, a user deciding between alternatives is most interested in a comparative analysis of strengths and weaknesses of each.", "labels": [], "entities": []}, {"text": "* This work was carried out as part of PhD research at IIT Delhi.", "labels": [], "entities": [{"text": "IIT Delhi", "start_pos": 55, "end_pos": 64, "type": "DATASET", "confidence": 0.6832037270069122}]}, {"text": "The author is also a regular employee at IBM Research.", "labels": [], "entities": [{"text": "IBM Research", "start_pos": 41, "end_pos": 53, "type": "DATASET", "confidence": 0.7977703809738159}]}, {"text": "There have been some recent attempts to create comparisons using expert knowledge, but generating such comparisons manually does not scaleeven pairwise comparisons are quadratic in the number of entities.", "labels": [], "entities": []}, {"text": "Few automated comparisons for specific products with pre-defined attributes (e.g., laptops, cameras) exist; they are typically powered by existing structured knowledge bases.", "labels": [], "entities": []}, {"text": "To the best of our knowledge, prior work on automatically generating comparisons for arbitrary domains from unstructured text, does not exist.", "labels": [], "entities": []}, {"text": "We define a novel task of generating entity comparisons from textual corpora in which each document describes one entity at a time.", "labels": [], "entities": []}, {"text": "For broad applicability, we do not restrict ourselves to a pre-defined ontology; instead, we use textual phrases that describe entities as our unit of information.", "labels": [], "entities": []}, {"text": "We call these descriptive phrases -they encompass general attribute-value phrases, opinion phrases, and other descriptions of the facets of an entity.", "labels": [], "entities": []}, {"text": "We generate entity comparisons in a tabular form where the phrases are organized semantically, thus, allowing for direct comparisons.", "labels": [], "entities": []}, {"text": "shows a sample city comparison generated by our system for tourism.", "labels": [], "entities": []}, {"text": "Our comparison generation algorithm extracts descriptive phrases per entity and clusters them into semantic groups.", "labels": [], "entities": [{"text": "comparison generation", "start_pos": 4, "end_pos": 25, "type": "TASK", "confidence": 0.7844943702220917}]}, {"text": "We perform clustering via a topic model, where phrases from an entity are combined into one document.", "labels": [], "entities": []}, {"text": "The topics identify prominent facets of the entities.", "labels": [], "entities": []}, {"text": "Unfortunately, since the number of entities being compared is usually small, just statistical co-occurrence of words and phrases is not sufficient to identify good topics.", "labels": [], "entities": []}, {"text": "In response, we use vector embeddings of descriptive phrases and employ a Gaussian extension of probabilistic latent semantic analysis (pLSA) over these vectors.", "labels": [], "entities": []}, {"text": "We also modify Gaussian pLSA to additionally incorporate an entity-balance term, preferring topics in which phrases from the entities are represented in a proportionate measure.", "labels": [], "entities": []}, {"text": "The balance term trades off the discovery of unique facets for each entity with that of common facets.", "labels": [], "entities": []}, {"text": "This enables direct comparison between entities leading to an overall improved comparison table.", "labels": [], "entities": []}, {"text": "Since the balance term is only a preference (not a constraint), it still allows the algorithm to exhibit clusters which maybe sparsely represented (or not represented at all) in one of the entities.", "labels": [], "entities": []}, {"text": "We demonstrate the usefulness of our ideas on two domains -tourism and movies.", "labels": [], "entities": []}, {"text": "Based on user experiments, we find that the entity-balanced model outputs much better comparisons as compared to an entity-oblivious model such as GMM.", "labels": [], "entities": [{"text": "GMM", "start_pos": 147, "end_pos": 150, "type": "DATASET", "confidence": 0.9347819685935974}]}, {"text": "In summary, our paper makes the following contributions: \u2022 We define a novel task of generating entity comparisons from a corpus that describes entities individually.", "labels": [], "entities": []}, {"text": "\u2022 We present the first system to output such a comparison.", "labels": [], "entities": []}, {"text": "Our system runs Gaussian pLSA over the vector embeddings of extracted phrases, and preferentially tries to balance the entities in each topic.", "labels": [], "entities": []}, {"text": "\u2022 Human subject evaluations using Amazon Mechanical Turk (AMT) demonstrate that AMT workers overwhelmingly prefer comparisons generated using entity-balanced Gaussian pLSA compared to entity-oblivious clustering.", "labels": [], "entities": [{"text": "Amazon Mechanical Turk (AMT)", "start_pos": 34, "end_pos": 62, "type": "DATASET", "confidence": 0.8386325041453043}]}], "datasetContent": [{"text": "We chose various parameters in our IE systems so that our precision never drops below 0.70.", "labels": [], "entities": [{"text": "precision", "start_pos": 58, "end_pos": 67, "type": "METRIC", "confidence": 0.999007523059845}]}, {"text": "For example, we used K=15 for choosing the top words from LDA into seed list.", "labels": [], "entities": []}, {"text": "We use this target precision, because we believe that for any human-facing system the precision needs to be high for it to be considered acceptable by people.", "labels": [], "entities": [{"text": "precision", "start_pos": 19, "end_pos": 28, "type": "METRIC", "confidence": 0.8440259695053101}, {"text": "precision", "start_pos": 86, "end_pos": 95, "type": "METRIC", "confidence": 0.9977777600288391}]}, {"text": "compares the performance of the various IE methods.", "labels": [], "entities": [{"text": "IE", "start_pos": 40, "end_pos": 42, "type": "TASK", "confidence": 0.959801197052002}]}, {"text": "Not surprisingly, we find that manual seed lists obtain a much higher recall as compared to LDA seeds, at approximately the same level of precision.", "labels": [], "entities": [{"text": "recall", "start_pos": 70, "end_pos": 76, "type": "METRIC", "confidence": 0.999460756778717}, {"text": "precision", "start_pos": 138, "end_pos": 147, "type": "METRIC", "confidence": 0.9985815286636353}]}, {"text": "Both Wordnet and word-vector improve the recall substantially, though vectors are more effective.", "labels": [], "entities": [{"text": "Wordnet", "start_pos": 5, "end_pos": 12, "type": "DATASET", "confidence": 0.9629996418952942}, {"text": "recall", "start_pos": 41, "end_pos": 47, "type": "METRIC", "confidence": 0.9989498257637024}]}, {"text": "The recall of all nouns is only 0.67 because a large number of descriptive phrases were larger ngrams (not just adjective-noun bigrams) and were missed due to chunking errors.", "labels": [], "entities": [{"text": "recall", "start_pos": 4, "end_pos": 10, "type": "METRIC", "confidence": 0.9993151426315308}]}, {"text": "In order to evaluate the usefulness of our system we conducted extensive experiments on Amazon Mechanical Turk (AMT).", "labels": [], "entities": [{"text": "Amazon Mechanical Turk (AMT)", "start_pos": 88, "end_pos": 116, "type": "DATASET", "confidence": 0.9420766333738962}]}, {"text": "Our experiments answer the following questions.", "labels": [], "entities": []}, {"text": "(1) Are comparisons generated using our clustering methods G-pLSA and EB GpLSA preferred by users against the entity oblivious baseline of GMM?", "labels": [], "entities": []}, {"text": "(2) Are our system-generated comparison tables helpful to people for the task of entity comparison?", "labels": [], "entities": [{"text": "entity comparison", "start_pos": 81, "end_pos": 98, "type": "TASK", "confidence": 0.7386116981506348}]}, {"text": "Datasets & System Settings: We experiment 6 on two datasets -tourism and movies.", "labels": [], "entities": []}, {"text": "For tourism, we downloaded a collection of 16,785 travel articles from WikiTravel.", "labels": [], "entities": []}, {"text": "The website contains articles that have been collaboratively written by Web users.", "labels": [], "entities": []}, {"text": "Each article describes a city or a larger geographic area that is of interest to tourists.", "labels": [], "entities": []}, {"text": "In addition, all articles contain sections 7 describing different aspects of a city from a tourism point of view (e.g., places to see, transportation, shopping and eating).", "labels": [], "entities": []}, {"text": "For our proof of concept, we performed IE only on the 'places to see' sections.", "labels": [], "entities": [{"text": "IE", "start_pos": 39, "end_pos": 41, "type": "TASK", "confidence": 0.8858487606048584}]}, {"text": "For Movies dataset, we used the Amazon review data set (.", "labels": [], "entities": [{"text": "Movies dataset", "start_pos": 4, "end_pos": 18, "type": "DATASET", "confidence": 0.974815160036087}, {"text": "Amazon review data set", "start_pos": 32, "end_pos": 54, "type": "DATASET", "confidence": 0.94752998650074}]}, {"text": "It has over 7.9 million reviews for 250,000 movies.", "labels": [], "entities": []}, {"text": "We combined all the reviews fora movie, thus, generating a large Code and data available on request 7 http://wikitravel.org/en/Wikitravel:Article templates/Sections review document per movie.", "labels": [], "entities": []}, {"text": "This dataset is much noisier compared to WikiTravel due to presence of slang, incorrect grammar, sarcasm, etc.", "labels": [], "entities": []}, {"text": "In addition, users also tend to compare and contrast while reviewing movies so there are even references to other movies.", "labels": [], "entities": []}, {"text": "As a result, the descriptive phrases extracted were much more noisy.", "labels": [], "entities": []}, {"text": "For the time consuming manual seed list setting of our IE system, we only use the tourism dataset.", "labels": [], "entities": [{"text": "IE", "start_pos": 55, "end_pos": 57, "type": "TASK", "confidence": 0.8857690095901489}, {"text": "tourism dataset", "start_pos": 82, "end_pos": 97, "type": "DATASET", "confidence": 0.7068003714084625}]}, {"text": "For movies, we generate seeds using annotation over LDA topics only.", "labels": [], "entities": []}, {"text": "For all systems we use wordvectors to expand the seed list.", "labels": [], "entities": []}, {"text": "For each table, we generated k clusters where k was determined using a heuristic 8 (, and we displayed at most 30 phrases per cluster.", "labels": [], "entities": []}, {"text": "We did not display any cluster that had less than 4 phrases.", "labels": [], "entities": []}, {"text": "In order to examine whether clustering using EB G-pLSA indeed produces best comparison tables, we conducted a human evaluation task on Amazon Mechanical Turk (AMT) where users of our system were asked to indicate their preference between two comparison tables.", "labels": [], "entities": [{"text": "Amazon Mechanical Turk (AMT)", "start_pos": 135, "end_pos": 163, "type": "DATASET", "confidence": 0.9205919901529948}]}, {"text": "Since we have three systems we performed this pairwise study thrice.", "labels": [], "entities": []}, {"text": "In each study, two comparison tables were generated from different systems.", "labels": [], "entities": []}, {"text": "For each entity-pair we asked four workers each to select which comparison table they preferred.", "labels": [], "entities": []}, {"text": "The order of the tables was randomized to remove any biasing effect.", "labels": [], "entities": []}, {"text": "We paid $0.3 for each table comparison.", "labels": [], "entities": []}, {"text": "reports the results for both domains where descriptive phrases were generated using LDA+WV.", "labels": [], "entities": []}, {"text": "On 30 city-pairs in the Tourism domain, workers preferred the comparison tables generated using EB G-pLSA 53% of the time and GMM was preferred only 13% (the rest were ties).", "labels": [], "entities": [{"text": "Tourism domain", "start_pos": 24, "end_pos": 38, "type": "DATASET", "confidence": 0.902958333492279}, {"text": "GMM", "start_pos": 126, "end_pos": 129, "type": "DATASET", "confidence": 0.6979901790618896}]}, {"text": "It is worthwhile to note that whereas in 20% of the comparisons, EB G-pLSA had a clear 4-0 margin, there was no such comparison where all the workers preferred the GMM model.", "labels": [], "entities": [{"text": "GMM", "start_pos": 164, "end_pos": 167, "type": "DATASET", "confidence": 0.9027748107910156}]}, {"text": "We also requested users to provide the reasons for their preferences.", "labels": [], "entities": []}, {"text": "While most users specified a non-informative reason such as \"like it better\", some users gave specific reasons such as \"subdivides the parts I find useful into more specific Domain Total pairs EB G-pLSA Win GMM Win EB G-pLSA Win G-pLSA Win G-pLSA Win GMM Win: User preference win-loss statistics for different clustering methods on both city and movie comparison task using the same IE system.", "labels": [], "entities": []}, {"text": "Both EB G-pLSA and G-pLSA significantly outperform the baseline GMM model.", "labels": [], "entities": []}, {"text": "EB G-pLSA has some edge over the G-pLSA model.", "labels": [], "entities": [{"text": "EB", "start_pos": 0, "end_pos": 2, "type": "DATASET", "confidence": 0.8991597890853882}]}, {"text": "Note: Ties have not been shown in the table.", "labels": [], "entities": []}, {"text": "categories\" and \"easy to understand and more specific points of comparison\".", "labels": [], "entities": []}, {"text": "Our results also show that G-pLSA is a distinct improvement over GMM (44% vs. 16%).", "labels": [], "entities": [{"text": "G-pLSA", "start_pos": 27, "end_pos": 33, "type": "METRIC", "confidence": 0.9339307546615601}, {"text": "GMM", "start_pos": 65, "end_pos": 68, "type": "DATASET", "confidence": 0.6474707126617432}]}, {"text": "EB G-pLSA had a marginal edge over G-pLSA (43% vs. 30%).", "labels": [], "entities": [{"text": "EB", "start_pos": 0, "end_pos": 2, "type": "DATASET", "confidence": 0.8412084579467773}]}, {"text": "On movies domain, we report results on 20 movie-pairs and we again found an overwhelming preference for the system using EB G-pLSA for clustering.", "labels": [], "entities": []}, {"text": "55% of the time, the output of EB GpLSA was preferred over GMM's 10%.", "labels": [], "entities": [{"text": "EB GpLSA", "start_pos": 31, "end_pos": 39, "type": "METRIC", "confidence": 0.6446090340614319}, {"text": "GMM", "start_pos": 59, "end_pos": 62, "type": "DATASET", "confidence": 0.9606321454048157}]}, {"text": "Other comparisons between G-pLSA and GMM, and between our G-pLSA and EB G-pLSA systems also follow trends similar to tourism domain.", "labels": [], "entities": [{"text": "GMM", "start_pos": 37, "end_pos": 40, "type": "DATASET", "confidence": 0.9116640090942383}]}, {"text": "The performance of EB G-pLSA is statistically significantly better than GMM for both the tourism and the movie datasets, with p values being less than 0.00004 and 0.002, respectively, using a one-sided students t-test.", "labels": [], "entities": [{"text": "GMM", "start_pos": 72, "end_pos": 75, "type": "METRIC", "confidence": 0.6379808187484741}]}, {"text": "This strong preference suggests that the clustering induced by incorporating entity balance in the clusters produces much better comparison tables.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Quality of extracted descriptive phrases on a devset", "labels": [], "entities": [{"text": "Quality", "start_pos": 10, "end_pos": 17, "type": "METRIC", "confidence": 0.9701112508773804}]}, {"text": " Table 3: User preference win-loss statistics for different clustering methods on both city and movie comparison task using the same", "labels": [], "entities": []}]}