{"title": [{"text": "Shift-Reduce CCG Parsing using Neural Network Models", "labels": [], "entities": [{"text": "Shift-Reduce CCG Parsing", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.8270032604535421}]}], "abstractContent": [{"text": "We present a neural network based shift-reduce CCG parser, the first neural-network based parser for CCG.", "labels": [], "entities": []}, {"text": "We also study the impact of neural network based tagging models , and greedy versus beam-search parsing, by using a structured neural network model.", "labels": [], "entities": [{"text": "beam-search parsing", "start_pos": 84, "end_pos": 103, "type": "TASK", "confidence": 0.7177588939666748}]}, {"text": "Our greedy parser obtains a labeled F-score of 83.27%, the best reported result for greedy CCG parsing in the literature (an improvement of 2.5% over a perceptron based greedy parser) and is more than three times faster.", "labels": [], "entities": [{"text": "F-score", "start_pos": 36, "end_pos": 43, "type": "METRIC", "confidence": 0.9371069073677063}, {"text": "CCG parsing", "start_pos": 91, "end_pos": 102, "type": "TASK", "confidence": 0.6349494755268097}]}, {"text": "With abeam, our structured neural network model gives a labeled F-score of 85.57% which is 0.6% better than the perceptron based counterpart.", "labels": [], "entities": [{"text": "F-score", "start_pos": 64, "end_pos": 71, "type": "METRIC", "confidence": 0.9798074960708618}]}], "introductionContent": [{"text": "Shift-reduce parsing is interesting for practical realworld applications like parsing the web, since parsing can be achieved in linear time.", "labels": [], "entities": [{"text": "Shift-reduce parsing", "start_pos": 0, "end_pos": 20, "type": "TASK", "confidence": 0.7965423166751862}, {"text": "parsing the web", "start_pos": 78, "end_pos": 93, "type": "TASK", "confidence": 0.9074397683143616}]}, {"text": "Although greedy parsers are fast, accuracies of these parsers are typically much lower than graph-based parsers.", "labels": [], "entities": [{"text": "accuracies", "start_pos": 34, "end_pos": 44, "type": "METRIC", "confidence": 0.9912978410720825}]}, {"text": "Conversely, beam-search parsers achieve accuracies comparable to graph-based parsers (Zhang and Nivre, 2011) but are much slower than their greedy counterparts.", "labels": [], "entities": [{"text": "beam-search parsers", "start_pos": 12, "end_pos": 31, "type": "TASK", "confidence": 0.7444623112678528}]}, {"text": "Recently, have showed that fast and accurate parsing can be achieved using neural network based parsers.", "labels": [], "entities": [{"text": "parsing", "start_pos": 45, "end_pos": 52, "type": "TASK", "confidence": 0.9686517119407654}]}, {"text": "Improving their work,  presented a structured neural network model which gave stateof-the-art results for English dependency parsing.", "labels": [], "entities": [{"text": "English dependency parsing", "start_pos": 106, "end_pos": 132, "type": "TASK", "confidence": 0.644800086816152}]}, {"text": "There has been increasing interest in Combinatory Categorial Grammar (CCG)) parsing due to the simplicity of its interface between syntax and semantics.", "labels": [], "entities": [{"text": "Combinatory Categorial Grammar (CCG)) parsing", "start_pos": 38, "end_pos": 83, "type": "TASK", "confidence": 0.7269822444234576}]}, {"text": "In addition to predicateargument structure, CCG captures the unbounded dependencies found in grammatical constructions like relativization, coordination, etc.", "labels": [], "entities": []}, {"text": "We present a neural network based shift-reduce CCG parser, the first neural network based parser for CCG.", "labels": [], "entities": []}, {"text": "We first adapt's shift-reduce dependency parser for CCG parsing.", "labels": [], "entities": [{"text": "CCG parsing", "start_pos": 52, "end_pos": 63, "type": "TASK", "confidence": 0.6749247610569}]}, {"text": "We then develop a structured neural network model based on , in order to explore the impact of a beamsearch on the parser.", "labels": [], "entities": []}, {"text": "We also analyze the impact of neural network taggers (for both POS-tagging and CCG supertagging) as compared to maximum entropy taggers.", "labels": [], "entities": []}, {"text": "Our greedy neural network parser achieves unlabeled and labeled F-scores of 89.78% and 83.27% respectively, an improvement of around 2.5% over a perceptron based greedy parser, and is more than three times faster.", "labels": [], "entities": [{"text": "F-scores", "start_pos": 64, "end_pos": 72, "type": "METRIC", "confidence": 0.9577317833900452}]}, {"text": "Due to its relevance for large-scale parsing, we make this parser available for public usage.", "labels": [], "entities": []}, {"text": "By using abeam search, our structured neural network model gave even better results of 91.95% and 85.57% unlabeled and labeled F-scores respectively.", "labels": [], "entities": [{"text": "F-scores", "start_pos": 127, "end_pos": 135, "type": "METRIC", "confidence": 0.9091629981994629}]}, {"text": "To the best of our knowledge, ours is the first neural network based parser for CCG and also the first work on exploring neural network taggers for shift-reduce CCG parsing.", "labels": [], "entities": [{"text": "CCG parsing", "start_pos": 161, "end_pos": 172, "type": "TASK", "confidence": 0.6595906019210815}]}], "datasetContent": [{"text": "We first compare our neural network parser (NNPar) 2 with a perceptron based parser in the greedy settings.", "labels": [], "entities": []}, {"text": "Then we analyze the impact of beam using neural network (NNPar) and structured neural network (Structured NNPar) models.", "labels": [], "entities": []}, {"text": "The perceptron based parser is a reimplementation of Zhang and Clark (2011)'s parser (Z&C*).", "labels": [], "entities": []}, {"text": "A global linear model trained with the averaged perceptron) is used for this parser and an early-update () strategy is used during training.", "labels": [], "entities": []}, {"text": "In the greedy setting (beam=1), when the predicted action differs from the gold action, decoding stops and weights are updated accordingly.", "labels": [], "entities": []}, {"text": "When abeam is used (beam=16), weights are updated when the gold parse configuration falls out of the beam.", "labels": [], "entities": []}, {"text": "For Z&C*, the feature set of, which comprises of 64 feature templates is used.", "labels": [], "entities": []}, {"text": "For NNPar, the 34 feature templates described in section 3.2 are used.", "labels": [], "entities": []}, {"text": "We employ an arc-standard style shift-reduce algorithm for CCG parsing, similar to, for all our experiments.", "labels": [], "entities": [{"text": "CCG parsing", "start_pos": 59, "end_pos": 70, "type": "TASK", "confidence": 0.7428281307220459}]}], "tableCaptions": [{"text": " Table 1: Performance of greedy CCG parsers on  CCGbank development data (Sec. 00).", "labels": [], "entities": [{"text": "CCGbank development data", "start_pos": 48, "end_pos": 72, "type": "DATASET", "confidence": 0.8341894944508871}]}, {"text": " Table 3: Results on CCGbank test data (Sec. 23).", "labels": [], "entities": [{"text": "CCGbank test data", "start_pos": 21, "end_pos": 38, "type": "DATASET", "confidence": 0.9678358236948649}]}, {"text": " Table 2: Impact of the beam on CCGbank develop- ment data (Sec. 00).", "labels": [], "entities": [{"text": "CCGbank develop- ment data (Sec. 00)", "start_pos": 32, "end_pos": 68, "type": "DATASET", "confidence": 0.759159631199307}]}, {"text": " Table 4: Speed comparison of perceptron and neural  network based greedy parsers.", "labels": [], "entities": []}]}