{"title": [{"text": "Phylogenetic simulations over constraint-based grammar formalisms", "labels": [], "entities": []}], "abstractContent": [{"text": "Computational phylogenetics has been shown to be effective over grammatical characteristics.", "labels": [], "entities": [{"text": "Computational phylogenetics", "start_pos": 0, "end_pos": 27, "type": "TASK", "confidence": 0.7227330505847931}]}, {"text": "Recent work suggests that constraint-based formalisms are compatible with such an approach (Eden, 2013).", "labels": [], "entities": []}, {"text": "In this paper, we report on simulations to determine how useful constraint-based formalisms are in phyloge-netic research and under what conditions.", "labels": [], "entities": []}], "introductionContent": [{"text": "Popular computational methods for phylogenetic research (estimating the evolutionary histories of languages) primarily involve comparisons over cognate sets.", "labels": [], "entities": []}, {"text": "Recent works ( indicate that comparing sets of grammatical parameters can be effective as well.", "labels": [], "entities": []}, {"text": "However, generating a large number of meaningful parameters remains a formal obstacle.", "labels": [], "entities": []}, {"text": "In this paper we argue that constraint-based grammar formalisms maybe exploited for parameter generation, and explore to what extent such research is feasible.", "labels": [], "entities": [{"text": "parameter generation", "start_pos": 84, "end_pos": 104, "type": "TASK", "confidence": 0.7522486746311188}]}, {"text": "Because the use of constraint-based grammars in phylogenetics is relatively novel, we do not know a posteriori how many constraints and how many languages must be considered fora computational approach to be successful.", "labels": [], "entities": []}, {"text": "If a minimum threshold is established that is methodologically prohibitive (e.g. if such systems were only accurate given a set of 1,000 languages), we can abandon this approach as infeasible.", "labels": [], "entities": []}, {"text": "By initially experimenting with simulated data, we establish a footing for future empirical studies.", "labels": [], "entities": []}, {"text": "In this paper, we report on simulations which consistently outperform two baseline models.", "labels": [], "entities": []}, {"text": "Significantly, these results obtained with a modest number of constraints c \u2265 4 and languages l \u2265 4.", "labels": [], "entities": []}], "datasetContent": [{"text": "Because we have access to T , the gold standard tree, we diverge from the partially qualitative evaluations of and and adopt a purely quantative evaluation metric based on precision and recall).", "labels": [], "entities": [{"text": "precision", "start_pos": 172, "end_pos": 181, "type": "METRIC", "confidence": 0.9989093542098999}, {"text": "recall", "start_pos": 186, "end_pos": 192, "type": "METRIC", "confidence": 0.991472601890564}]}, {"text": "As in standard precision and recall, we measure the proportion of correct items relative to T and T respectively.", "labels": [], "entities": [{"text": "precision", "start_pos": 15, "end_pos": 24, "type": "METRIC", "confidence": 0.9806215167045593}, {"text": "recall", "start_pos": 29, "end_pos": 35, "type": "METRIC", "confidence": 0.998603880405426}]}, {"text": "We define correct items to be matching subtrees rooted by internal nodes as shown in.", "labels": [], "entities": []}, {"text": "Two subtrees are counted as matching if they dominate the same set of leaves.", "labels": [], "entities": []}, {"text": "Figure 2: Subtree a in A matches subtree bin B.", "labels": [], "entities": []}, {"text": "T is then compared against two null hypothesis baseline trees, BF and BR.", "labels": [], "entities": [{"text": "T", "start_pos": 0, "end_pos": 1, "type": "METRIC", "confidence": 0.8964674472808838}, {"text": "BF", "start_pos": 63, "end_pos": 65, "type": "METRIC", "confidence": 0.9887394905090332}, {"text": "BR", "start_pos": 70, "end_pos": 72, "type": "METRIC", "confidence": 0.9115987420082092}]}, {"text": "BF is a flat tree composed of a single internal node dominating the entire set of languages S as in.", "labels": [], "entities": [{"text": "BF", "start_pos": 0, "end_pos": 2, "type": "METRIC", "confidence": 0.8565436005592346}]}, {"text": "BF encodes the empirical null hypothesis that S contains no subgroups.: A random baseline tree BF with n leaves BR is a randomly constructed binary tree encoding the null hypothesis that the phylogeny estimation procedure does not outperform chance groupings.", "labels": [], "entities": [{"text": "BF", "start_pos": 0, "end_pos": 2, "type": "METRIC", "confidence": 0.9060718417167664}]}, {"text": "Precision and recall are calculated between T and the three test trees.", "labels": [], "entities": [{"text": "Precision", "start_pos": 0, "end_pos": 9, "type": "METRIC", "confidence": 0.9943481087684631}, {"text": "recall", "start_pos": 14, "end_pos": 20, "type": "METRIC", "confidence": 0.99921715259552}]}, {"text": "We consider an experiment successful when T is more accurate than BF and BR.", "labels": [], "entities": [{"text": "BF", "start_pos": 66, "end_pos": 68, "type": "METRIC", "confidence": 0.9894915819168091}, {"text": "BR", "start_pos": 73, "end_pos": 75, "type": "METRIC", "confidence": 0.9676536917686462}]}], "tableCaptions": []}