{"title": [{"text": "Symmetric Patterns and Coordinations: Fast and Enhanced Representations of Verbs and Adjectives", "labels": [], "entities": []}], "abstractContent": [{"text": "State-of-the-art word embeddings, which are often trained on bag-of-words (BOW) contexts , provide a high quality representation of aspects of the semantics of nouns.", "labels": [], "entities": []}, {"text": "However, their quality decreases substantially for the task of verb similarity prediction.", "labels": [], "entities": [{"text": "verb similarity prediction", "start_pos": 63, "end_pos": 89, "type": "TASK", "confidence": 0.7734490831693014}]}, {"text": "In this paper we show that using symmetric pattern contexts (SPs, e.g., \"X and Y\") improves word2vec verb similarity performance by up to 15% and is also instrumental in adjective similarity prediction.", "labels": [], "entities": [{"text": "word2vec verb similarity", "start_pos": 92, "end_pos": 116, "type": "TASK", "confidence": 0.5524009466171265}, {"text": "adjective similarity prediction", "start_pos": 170, "end_pos": 201, "type": "TASK", "confidence": 0.8521068493525187}]}, {"text": "The unsupervised SP contexts are even superior to a variety of dependency contexts extracted using a supervised dependency parser.", "labels": [], "entities": []}, {"text": "Moreover, we observe that SPs and dependency coordination contexts (Coor) capture a similar type of information, and demonstrate that Coor contexts are superior to other dependency contexts including the set of all dependency contexts, although they are still inferior to SPs.", "labels": [], "entities": []}, {"text": "Finally, there are substantially fewer SP contexts compared to alternative representations , leading to a massive reduction in training time.", "labels": [], "entities": []}, {"text": "On an 8G words corpus and a 32 core machine, the SP model trains in 11 minutes , compared to 5 and 11 hours with BOW and all dependency contexts, respectively.", "labels": [], "entities": []}], "introductionContent": [{"text": "In recent years, vector space models (VSMs) have become prominent in NLP.", "labels": [], "entities": []}, {"text": "VSMs are often evaluated by measuring their ability to predict human judgments of lexical semantic relations between pairs of words, mostly association or similarity.", "labels": [], "entities": [{"text": "VSMs", "start_pos": 0, "end_pos": 4, "type": "TASK", "confidence": 0.7995262145996094}, {"text": "predict human judgments of lexical semantic relations between pairs of words", "start_pos": 55, "end_pos": 131, "type": "TASK", "confidence": 0.7495217296210203}]}, {"text": "While many datasets for these tasks are limited to pairs of nouns, the recent SimLex999 word similarity dataset () also consists of similarity scores for verb and adjective pairs.", "labels": [], "entities": [{"text": "SimLex999 word similarity dataset", "start_pos": 78, "end_pos": 111, "type": "DATASET", "confidence": 0.6189500167965889}]}, {"text": "State-ofthe-art VSMs such as word2vec skip-gram () and GloVe () excel at noun-related tasks.", "labels": [], "entities": []}, {"text": "However, their performance substantially decreases on verb similarity prediction in SimLex999, and their adjective representations have rarely been evaluated (Section 2).", "labels": [], "entities": [{"text": "verb similarity prediction", "start_pos": 54, "end_pos": 80, "type": "TASK", "confidence": 0.7120241125424703}]}, {"text": "In this paper we show that a key factor in the reduced performance of the w2v-SG model on verb representation is its reliance on bag-of-words (BOW) contexts: contexts of the represented words that consist of words in their physical proximity.", "labels": [], "entities": [{"text": "verb representation", "start_pos": 90, "end_pos": 109, "type": "TASK", "confidence": 0.7107747197151184}]}, {"text": "We investigate a number of alternative contexts for this model, including various dependency contexts, and show that simple, automatically acquired symmetric patterns (SPs, e.g., \"X or Y\",)) are the most useful contexts for the representation of verbs and also adjectives.", "labels": [], "entities": []}, {"text": "Moreover, the SP-based model is much more compact than the alternatives, making its training an order of magnitude faster.", "labels": [], "entities": []}, {"text": "In particular, we train several versions of the w2v-SG model, each with a different context type, and evaluate the resulting word embeddings on the task of predicting the similarity scores of the verb and adjective portions of SimLex999.", "labels": [], "entities": []}, {"text": "Our results show that SP contexts (SG-SP) obtain the best results on both tasks: Spearman's \u03c1 scores of 0.459 on verbs and 0.651 on adjectives.", "labels": [], "entities": [{"text": "Spearman's \u03c1 scores", "start_pos": 81, "end_pos": 100, "type": "METRIC", "confidence": 0.6489144787192345}]}, {"text": "These results are 15.2% and 4.7% better than BOW contexts and 7.3% and 6.5% better than all dependency contexts (DepAll).", "labels": [], "entities": []}, {"text": "Moreover, the number of SP contexts is substantially smaller than the alternatives, making it extremely fast to train: 11 minutes only on an 8G word corpus using a 32 CPU core machine, compared to 5 and 11 hours for BOW and DepAll, respectively.", "labels": [], "entities": [{"text": "SP contexts", "start_pos": 24, "end_pos": 35, "type": "TASK", "confidence": 0.8972502648830414}, {"text": "DepAll", "start_pos": 224, "end_pos": 230, "type": "DATASET", "confidence": 0.770824670791626}]}, {"text": "Recently,  presented a count-based VSM that utilizes SP contexts (SRR15).", "labels": [], "entities": [{"text": "VSM", "start_pos": 35, "end_pos": 38, "type": "TASK", "confidence": 0.8526367545127869}]}, {"text": "This model excels on verb similarity, outperforming VSMs that use other contexts (e.g., BOW and DepAll) by more than 20%.", "labels": [], "entities": []}, {"text": "In this paper we show that apart from its SP contexts, the success of SRR15 is attributed in large to its explicit representation of antonyms (live/die); turning this feature off reduces its performance to be on par with SG-SP.", "labels": [], "entities": [{"text": "SRR15", "start_pos": 70, "end_pos": 75, "type": "DATASET", "confidence": 0.5754923820495605}]}, {"text": "As opposed to , we keep our VSM fixed across experiments (w2v-SG), changing only the context type.", "labels": [], "entities": []}, {"text": "This allows us to attribute our improved results to one factor: SP contexts.", "labels": [], "entities": []}, {"text": "We further observe that SP contexts are tightly connected to syntactic coordination contexts (Coor, Section 3).", "labels": [], "entities": [{"text": "SP contexts", "start_pos": 24, "end_pos": 35, "type": "TASK", "confidence": 0.8895022869110107}]}, {"text": "Following this observation, we compare the w2v-SG model with three dependency-based context types: (a) Coor contexts; (b) all dependency links (DepAll); and (c) all dependency links excluding Coor links (Coor C ).", "labels": [], "entities": []}, {"text": "Our results show that training with Coor contexts is superior to training with the other context types, leading to improved similarity prediction of 2.7-4.1% and 4.3-6.9% on verbs and adjectives respectively.", "labels": [], "entities": [{"text": "similarity prediction", "start_pos": 124, "end_pos": 145, "type": "METRIC", "confidence": 0.845006674528122}]}, {"text": "These results demonstrate the prominence of Coor contexts in verb and adjective representation: these contexts are even better than their combination with the rest of the dependency-based contexts (the DepAll contexts).", "labels": [], "entities": [{"text": "verb and adjective representation", "start_pos": 61, "end_pos": 94, "type": "TASK", "confidence": 0.6973706036806107}, {"text": "DepAll contexts", "start_pos": 202, "end_pos": 217, "type": "DATASET", "confidence": 0.907288521528244}]}, {"text": "Nonetheless, although Coor contexts are extracted using a supervised dependency parser, they are still inferior to SP contexts, extracted automatically from plain text (Section 3), by 4.6% and 2.2% for verb and adjective pairs.", "labels": [], "entities": []}], "datasetContent": [{"text": "We keep the VSM fixed throughout our experiments, changing only the context type.", "labels": [], "entities": [{"text": "VSM fixed", "start_pos": 12, "end_pos": 21, "type": "TASK", "confidence": 0.7454463541507721}]}, {"text": "This methodology allows us to evaluate the impact of different contexts on the VSM performance, as context choice is the only modeling decision that changes across experimental conditions.", "labels": [], "entities": [{"text": "VSM", "start_pos": 79, "end_pos": 82, "type": "TASK", "confidence": 0.9671593308448792}]}, {"text": "Our VSM is the word2vec skip-gram model (), which obtains state-ofthe-art results on a variety of NLP tasks ( ).", "labels": [], "entities": []}, {"text": "We employ the word2vec toolkit.", "labels": [], "entities": []}, {"text": "For all context types other than BOW we use the word2vec package of (), 5 which augments the standard word2vec toolkit with code that allows arbitrary context definition.", "labels": [], "entities": []}, {"text": "We experiment with the verb pair (222 pairs) and adjective pair (111 pairs) portions of SimLex999 ().", "labels": [], "entities": []}, {"text": "We report the Spearman \u03c1 correlation between the ranks derived from the scores of the evaluated models and the human scores provided in SimLex999.", "labels": [], "entities": [{"text": "Spearman \u03c1 correlation", "start_pos": 14, "end_pos": 36, "type": "METRIC", "confidence": 0.936200221379598}, {"text": "SimLex999", "start_pos": 136, "end_pos": 145, "type": "DATASET", "confidence": 0.9087686538696289}]}, {"text": "We train the w2v-SG model with five different context types: (a) BOW contexts (SG-BOW); (b) all dependency links (SG-DepAll) (c) dependencybased coordination contexts (i.e., those labeled with conj, SG-Coor); (d) all dependency links except for coordinations (SG-Coor C ); and (e) SP contexts.", "labels": [], "entities": []}, {"text": "Our training corpus is the 8G words corpus gener- Spearman's \u03c1 scores on the different portions of SimLex999.", "labels": [], "entities": []}, {"text": "The top part presents results for the word2vec skip-gram model (w2v-SG) with various context types (see text).", "labels": [], "entities": []}, {"text": "The bottom lines present the results of the count SP-based model of , with (SRR15) and without (SRR15 \u2212 ) its antonym detection method.", "labels": [], "entities": []}, {"text": "The two rightmost columns present the run time of the w2v-SG models in minutes (Time) and the number of context instances used by the model (#Cont.).", "labels": [], "entities": []}, {"text": "For each SimLex999 portion, the score of the best w2v-SG model across context types is highlighted in bold font.", "labels": [], "entities": []}, {"text": "ated by the word2vec script.", "labels": [], "entities": []}, {"text": "7 Models (b)-(d) require the dependency parse trees of the corpus as input.", "labels": [], "entities": []}, {"text": "To generate these trees, we employ the Stanford POS Tagger ( and the stack version of the MALT parser ().", "labels": [], "entities": [{"text": "Stanford POS Tagger", "start_pos": 39, "end_pos": 58, "type": "DATASET", "confidence": 0.8249677618344625}]}, {"text": "The SP contexts are generated using the SPs extracted by the DR06 algorithm from our training corpus (see Section 3).", "labels": [], "entities": []}, {"text": "For BOW contexts, we experiment with three window sizes (2, 5 and 10) and report the best results (window size of 2 across conditions).", "labels": [], "entities": []}, {"text": "For dependency based contexts we follow the standard convention in the literature: we consider the immediate heads and modifiers of the represented word.", "labels": [], "entities": []}, {"text": "All models are trained with 500 dimensions, the default value of the word2vec script.", "labels": [], "entities": []}, {"text": "Other hyperparameters were also set to the default values of the code packages.", "labels": [], "entities": []}, {"text": "The SG-SP model provides the most useful verb and adjective representations among the w2v-SG models.", "labels": [], "entities": []}, {"text": "Compared to BOW (SG-BOW), the most commonly used context type, SG-SP results are 15.2% and 4.7% higher on verbs and adjectives respectively.", "labels": [], "entities": [{"text": "BOW", "start_pos": 12, "end_pos": 15, "type": "METRIC", "confidence": 0.9931123852729797}]}, {"text": "Compared to dependency links (SG-DepAll), the improvements are 7.3% and 6.5%.", "labels": [], "entities": []}, {"text": "For completeness, we compare the models on the noun pairs portion, observing that SG-BOW and SG-DepAll are \u223c8.5% better than SG-SP.", "labels": [], "entities": [{"text": "completeness", "start_pos": 4, "end_pos": 16, "type": "METRIC", "confidence": 0.9202545285224915}]}, {"text": "This indicates that different word classes require different representations.", "labels": [], "entities": []}, {"text": "The results for SG-Coor, which is trained with syntactic coordination (Coor) contexts, show that these contexts are superior to all the other dependency links (SG-Coor C ) by 4.1% and 6.9% on verbs and adjectives.", "labels": [], "entities": []}, {"text": "Importantly, comparing the SGCoor model to the SG-DepAll model, which augments the Coor contexts with the other syntactic dependency contexts, reveals that SG-DepAll is actually inferior by 2.7% and 4.3% in Spearman \u03c1 on verbs and adjectives respectively.", "labels": [], "entities": []}, {"text": "Interestingly, Coor contexts, which are extracted using a supervised parser, are still inferior by 4.6% and 2.2% to SPs, which capture similar contexts but are extracted from plain text.", "labels": [], "entities": []}, {"text": "also shows the training times of the various w2v-SG models on a 32G memory, 32 CPU core machine.", "labels": [], "entities": []}, {"text": "SG-SP and SG-Coor, which take 11 minutes and 23 minutes respectively to train, are substantially faster than the other w2v-SG models.", "labels": [], "entities": []}, {"text": "For example, they are more than an order of magnitude faster than SG-BOW (320 minutes) and SG-Coor C (677 minutes).", "labels": [], "entities": []}, {"text": "This is not surprising, as there are far fewer SP contexts (270M) and Coor contexts (550M) than BOW contexts (13G) and Coor C contexts (14G) (#Cont. column).", "labels": [], "entities": []}, {"text": "Finally, the performance of the SG-SP model is still substantially inferior to the SRR15 SP-based model ( . As both models use the same SP contexts, this result indicates that other modeling decisions in SRR15 lead to its superior performance.", "labels": [], "entities": [{"text": "SRR15", "start_pos": 204, "end_pos": 209, "type": "DATASET", "confidence": 0.8539592027664185}]}, {"text": "We show that this difference is mostly attributed to one feature of SRR15: its method for detecting antonym pairs (good/bad).", "labels": [], "entities": [{"text": "SRR15", "start_pos": 68, "end_pos": 73, "type": "DATASET", "confidence": 0.7750307321548462}]}, {"text": "Indeed, the SRR15 model without its antonym detection method (SRR15 \u2212 ) obtains a Spearman \u03c1 of 0.441, compared to 0.459 of SG-SP on verb pairs.", "labels": [], "entities": [{"text": "Spearman \u03c1", "start_pos": 82, "end_pos": 92, "type": "METRIC", "confidence": 0.9868403971195221}]}, {"text": "For adjectives, however, SRR15 \u2212 is 1.7% better than SRR15, in- We compare the w2v-SG models training time only.", "labels": [], "entities": [{"text": "SRR15", "start_pos": 25, "end_pos": 30, "type": "METRIC", "confidence": 0.9460724592208862}, {"text": "SRR15", "start_pos": 53, "end_pos": 58, "type": "METRIC", "confidence": 0.6644371747970581}]}, {"text": "SRR15 and SRR15 \u2212 are count-based models and have no training step.", "labels": [], "entities": [{"text": "SRR15", "start_pos": 0, "end_pos": 5, "type": "DATASET", "confidence": 0.8214739561080933}, {"text": "SRR15", "start_pos": 10, "end_pos": 15, "type": "DATASET", "confidence": 0.6721206307411194}]}, {"text": "creasing the difference from SG-SP to 2.9%.", "labels": [], "entities": [{"text": "SG-SP", "start_pos": 29, "end_pos": 34, "type": "METRIC", "confidence": 0.7410527467727661}]}], "tableCaptions": []}