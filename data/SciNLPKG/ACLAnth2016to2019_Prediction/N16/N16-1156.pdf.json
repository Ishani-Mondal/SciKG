{"title": [{"text": "Ten Pairs to Tag -Multilingual POS Tagging via Coarse Mapping between Embeddings", "labels": [], "entities": [{"text": "POS Tagging", "start_pos": 31, "end_pos": 42, "type": "TASK", "confidence": 0.5445087850093842}]}], "abstractContent": [{"text": "In the absence of annotations in the target language , multilingual models typically draw on extensive parallel resources.", "labels": [], "entities": []}, {"text": "In this paper, we demonstrate that accurate multilingual part-of-speech (POS) tagging can be done with just a few (e.g., ten) word translation pairs.", "labels": [], "entities": [{"text": "multilingual part-of-speech (POS) tagging", "start_pos": 44, "end_pos": 85, "type": "TASK", "confidence": 0.6379252175490061}]}, {"text": "We use the translation pairs to establish a coarse linear isometric (orthonormal) mapping between monolingual embeddings.", "labels": [], "entities": []}, {"text": "This enables the supervised source model expressed in terms of embeddings to be used directly on the target language.", "labels": [], "entities": []}, {"text": "We further refine the model in an unsupervised manner by initializing and regularizing it to be close to the direct transfer model.", "labels": [], "entities": []}, {"text": "Averaged across six languages , our model yields a 37.5% absolute improvement over the monolingual prototype-driven method (Haghighi and Klein, 2006) when using a comparable amount of supervision.", "labels": [], "entities": []}, {"text": "Moreover, to highlight key linguistic characteristics of the generated tags, we use them to predict typological properties of languages , obtaining a 50% error reduction relative to the prototype model.", "labels": [], "entities": []}], "introductionContent": [{"text": "After two decades of study, the best performing multilingual methods can in some cases approach their supervised monolingual analogues.", "labels": [], "entities": []}, {"text": "To reach this level of performance, however, multilingual methods typically make use of significant parallel resources such as parallel translations or bilingual dic-tionaries.", "labels": [], "entities": []}, {"text": "These resources act as substitutes for explicit annotations available in the target language for supervised methods.", "labels": [], "entities": []}, {"text": "It is less clear what can be done without extensive parallel resources.", "labels": [], "entities": []}, {"text": "Indeed, the motivation for our paper comes from trying to understand how little parallel data is necessary for effective multilingual transfer.", "labels": [], "entities": [{"text": "multilingual transfer", "start_pos": 121, "end_pos": 142, "type": "TASK", "confidence": 0.7057944238185883}]}, {"text": "In this paper, we demonstrate that only ten word translation pairs suffice for effective multilingual transfer of part-of-speech (POS) tagging.", "labels": [], "entities": [{"text": "multilingual transfer of part-of-speech (POS) tagging", "start_pos": 89, "end_pos": 142, "type": "TASK", "confidence": 0.769485242664814}]}, {"text": "To achieve this we make use of and integrate two sources of statistical signal.", "labels": [], "entities": []}, {"text": "First, we enable transfer of information from the source to target languages by establishing a coarse mapping between word embeddings in two languages on the basis of the few available translation pairs.", "labels": [], "entities": []}, {"text": "The mapping is useful because of significant structural similarity of embedding spaces across languages.", "labels": [], "entities": []}, {"text": "Second, we leverage the potential of unsupervised monolingual models to capture language-specific syntactic properties.", "labels": [], "entities": []}, {"text": "The two sources of signals are largely complementary.", "labels": [], "entities": []}, {"text": "Embeddings provide a coarse alignment between languages while unsupervised methods fine tune the correspondences in service of the task at hand.", "labels": [], "entities": []}, {"text": "While unsupervised methods are fragile and challenging to estimate in general, they can be helpful if initialized and regularized properly, which is our focus.", "labels": [], "entities": []}, {"text": "In order to transfer annotations, we align monolingual embeddings between languages.", "labels": [], "entities": []}, {"text": "However, a full fine-grained alignment is not possible with only ten translation pairs due to differences between the languages and variations across raw corpora from which the embeddings are derived.", "labels": [], "entities": []}, {"text": "Instead, we re-strict the initial coarse mapping to be linear and isometric (orthonormal) so as to leave lengths and angles between the word vectors invariant.", "labels": [], "entities": []}, {"text": "One advantage is that this preserves cosine similarity between vectors, which is viewed as a proxy for syntactic/semantic similarity (.", "labels": [], "entities": []}, {"text": "The resulting coarse alignment is then used to initialize and guide an unsupervised model over the target language.", "labels": [], "entities": []}, {"text": "Our unsupervised model is a feature-based hidden Markov model (HMM) expressed in terms of word embeddings.", "labels": [], "entities": []}, {"text": "By establishing a common multilingual embedding space, we can map the source HMM estimated from supervised annotations directly to the target.", "labels": [], "entities": []}, {"text": "The resulting \"direct transfer\" model should be further adjusted as languages differ, and the initial alignment obtained based on embeddings is imperfect.", "labels": [], "entities": []}, {"text": "For this reason we cast the direct transfer model as a regularizer for the target HMM, and permit the HMM to further adjust the embedding transformations and relations of embeddings to the tags both globally (overall rotation and scaling) and locally (introducing small corrections).", "labels": [], "entities": []}, {"text": "Our two phase approach is simple to implement, performs well, and can be adapted to other NLP tasks.", "labels": [], "entities": []}, {"text": "We evaluate our approach on POS tagging using the multilingual universal dependency treebanks ().", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 28, "end_pos": 39, "type": "TASK", "confidence": 0.8986346125602722}]}, {"text": "Specifically, we use English as the source language and test on three IndoEuropean languages (Danish, German and Spanish) and three non-Indo-European-languages (Finnish, Hungarian and Indonesian).", "labels": [], "entities": []}, {"text": "Experimental results show that our method consistently outperforms various baselines across languages.", "labels": [], "entities": []}, {"text": "On average, our full model achieves 8% absolute improvement over the direct transfer counterpart.", "labels": [], "entities": []}, {"text": "We also compare against a prototype-driven tagger) using 14 prototypes as supervision.", "labels": [], "entities": []}, {"text": "Our model significantly outperforms's model by 37.5% (67.5% vs 30%).", "labels": [], "entities": []}, {"text": "We also introduce a novel task-based evaluation of automatic POS taggers, where tagger predictions are used to determine typological properties of the target language.", "labels": [], "entities": [{"text": "POS taggers", "start_pos": 61, "end_pos": 72, "type": "TASK", "confidence": 0.8327021300792694}]}, {"text": "This evaluation highlights key linguistic features of the generated tags.", "labels": [], "entities": []}, {"text": "On this task, our model achieves 80% accuracy, yielding 50% error reduction relative to the prototype model.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 37, "end_pos": 45, "type": "METRIC", "confidence": 0.9994402527809143}, {"text": "error reduction", "start_pos": 60, "end_pos": 75, "type": "METRIC", "confidence": 0.9779166877269745}]}], "datasetContent": [{"text": "Dataset We evaluate our method on the latest Version 1  While Wikipedia texts may contain parallel articles, we show in that the amount of text varies significantly across languages.", "labels": [], "entities": []}, {"text": "also demonstrated that parallel information in Wikipedia is very noisy.", "labels": [], "entities": []}, {"text": "Therefore, direct translations are difficult to get from these texts.", "labels": [], "entities": []}, {"text": "We use the word2vec tool with the skip-gram learning scheme ().", "labels": [], "entities": []}, {"text": "In our experiments we used = 20 for the dimension of word embeddings and w = 1 for the context window size of the skip-gram, which yields the best overall performance for our model.", "labels": [], "entities": []}, {"text": "In our analysis, we also explore the impact of embedding dimension and window size.", "labels": [], "entities": []}, {"text": "Word Translation Pairs For each target language, we collect English translations for the top ten most frequent words in the training corpus.", "labels": [], "entities": [{"text": "Word Translation Pairs", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.7454825639724731}]}, {"text": "Our preliminary experiments show that this selection method performs the best.", "labels": [], "entities": []}, {"text": "The selected words are typically from closed classes, such as punctuation marks, determiners and prepositions.", "labels": [], "entities": []}, {"text": "We find translations using Wiktionary.", "labels": [], "entities": []}, {"text": "Model Variants Our model varies along two dimensions.", "labels": [], "entities": []}, {"text": "On one dimension, we use two different methods for inducing multilingual word embeddings: Pseudoinverse and Isometric alignment as described in Section 3.1.", "labels": [], "entities": [{"text": "Pseudoinverse", "start_pos": 90, "end_pos": 103, "type": "METRIC", "confidence": 0.9757640957832336}, {"text": "Isometric alignment", "start_pos": 108, "end_pos": 127, "type": "TASK", "confidence": 0.8543158173561096}]}, {"text": "On the other dimension, we experiment with two different multilingual transfer models.", "labels": [], "entities": []}, {"text": "We use Direct Transfer to denote our direct transfer model, and Transfer+EM for our unsupervised model trained in the target language.", "labels": [], "entities": []}, {"text": "Baselines We also compare against the prototypedriven method of.", "labels": [], "entities": []}, {"text": "Specifically, we use the publicly available implementation provided by the authors.", "labels": [], "entities": []}, {"text": "5 Note that their model requires at least one prototype for each POS category.", "labels": [], "entities": []}, {"text": "Therefore, we select 14 prototypes (the most frequent word from each category) for the baseline, while our method only uses ten translation pairs.", "labels": [], "entities": []}, {"text": "Evaluation Unlike other unsupervised methods, all models in our experiments can identify the label for each POS tag because of knowledge from either the source languages or prototypes.", "labels": [], "entities": []}, {"text": "Therefore, we directly report the token-level POS accuracy for all experiments.", "labels": [], "entities": [{"text": "POS", "start_pos": 46, "end_pos": 49, "type": "METRIC", "confidence": 0.7473280429840088}, {"text": "accuracy", "start_pos": 50, "end_pos": 58, "type": "METRIC", "confidence": 0.5874923467636108}]}, {"text": "Other Details For all experiments, we use the following regularization weights: \u03b3 = 0.001 for supervised models learned on the source language and \u03b2 = 0.01 for unsupervised models learned on the target language.", "labels": [], "entities": []}, {"text": "During training, we also normalize the log-likelihood of labeled or unlabeled data by the total number of tokens.", "labels": [], "entities": []}, {"text": "As a result, the magnitude of the objective value is independent of the corpus size, hence we do not need to tune the regularization weight for each target language.", "labels": [], "entities": []}, {"text": "We run ten iterations of the EM algorithm.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Number of tokens of the Wikipedia dumps used for inducing word embeddings.", "labels": [], "entities": []}, {"text": " Table 2: Token-level POS tagging accuracy (%) for different variants of our transfer model. We always use English as the source", "labels": [], "entities": [{"text": "Token-level POS tagging", "start_pos": 10, "end_pos": 33, "type": "TASK", "confidence": 0.6579159200191498}, {"text": "accuracy", "start_pos": 34, "end_pos": 42, "type": "METRIC", "confidence": 0.8983030319213867}]}, {"text": " Table 3: The accuracy (%) of typological properties prediction", "labels": [], "entities": [{"text": "accuracy", "start_pos": 14, "end_pos": 22, "type": "METRIC", "confidence": 0.9996505975723267}]}, {"text": " Table 4: The accuracy (%) of our best Transfer+EM model with different feature sets, removing either indicator features or", "labels": [], "entities": [{"text": "accuracy", "start_pos": 14, "end_pos": 22, "type": "METRIC", "confidence": 0.999658465385437}]}]}