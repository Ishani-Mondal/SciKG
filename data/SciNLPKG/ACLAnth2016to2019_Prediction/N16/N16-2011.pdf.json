{"title": [{"text": "Exploring Fine-Grained Emotion Detection in Tweets", "labels": [], "entities": [{"text": "Exploring Fine-Grained Emotion Detection in Tweets", "start_pos": 0, "end_pos": 50, "type": "TASK", "confidence": 0.6994446665048599}]}], "abstractContent": [{"text": "We examine if common machine learning techniques known to perform well in coarse-grained emotion and sentiment classification can also be applied successfully on a set of fine -grained emotion categories.", "labels": [], "entities": [{"text": "sentiment classification", "start_pos": 101, "end_pos": 125, "type": "TASK", "confidence": 0.8795973658561707}]}, {"text": "We first describe the grounded theory approach used to develop a corpus of 5,553 tweets manually annotated with 28 emotion categories.", "labels": [], "entities": []}, {"text": "From our preliminary experiments, we have identified two machine learning algorithms that perform well in this emotion classification task and demonstrated that it is feasible to train classifiers to detect 28 emotion categories without a huge drop in performance compared to coarser-grained classification schemes.", "labels": [], "entities": [{"text": "emotion classification task", "start_pos": 111, "end_pos": 138, "type": "TASK", "confidence": 0.7874035934607188}]}], "introductionContent": [{"text": "In sentiment analysis, emotion provides a promising direction for fine-grained analysis of subjective content.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 3, "end_pos": 21, "type": "TASK", "confidence": 0.9585609138011932}, {"text": "fine-grained analysis of subjective content", "start_pos": 66, "end_pos": 109, "type": "TASK", "confidence": 0.7379435062408447}]}, {"text": "Sentiment analysis is mainly focused on detecting the subjectivity (objective or subjective) () or semantic orientation (positive or negative)) of a unit of text (i.e., coarse-grained classification schemes) rather than a specific emotion.", "labels": [], "entities": [{"text": "Sentiment analysis", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.9481298923492432}]}, {"text": "Often times, knowing exactly how one reacts emotionally towards a particular entity, topic or event does matter ( ).", "labels": [], "entities": []}, {"text": "For example, while anger and sadness are both negative emotions, distinguishing between them can be important so businesses can filter out angry customers and respond to them effectively.", "labels": [], "entities": []}, {"text": "Automatic emotion detection on Twitter presents a different set of challenges because tweets exhibit a unique set of characteristics that are not shared by other types of text.", "labels": [], "entities": [{"text": "Automatic emotion detection", "start_pos": 0, "end_pos": 27, "type": "TASK", "confidence": 0.6518612404664358}]}, {"text": "Unlike traditional text, tweets consist of short messages expressed within the limit of 140 characters.", "labels": [], "entities": []}, {"text": "Due to the length limitation, language used to express emotions in tweets differs significantly from that found in longer documents (e.g., blogs, news, and stories).", "labels": [], "entities": []}, {"text": "Language use on Twitter is also typically informal.", "labels": [], "entities": []}, {"text": "It is common for abbreviations, acronyms, emoticons, unusual orthographic elements, slang, and misspellings to occur in these short messages.", "labels": [], "entities": []}, {"text": "On top of that, retweets (i.e., propagating messages of other users), referring to @username when responding to another user's tweet, and using #hashtags to represent topics are prevalent in tweets.", "labels": [], "entities": []}, {"text": "Even though users are restricted to post only 140 characters per tweet, it is not uncommon to find a tweet containing more than one emotion.", "labels": [], "entities": []}, {"text": "Emotion cues are not limited to only emotion words such as happy, amused, sad, miserable, scared, etc.", "labels": [], "entities": []}, {"text": "People use a variety of ways to express a wide range of emotions.", "labels": [], "entities": []}, {"text": "For instance, a person expressing happiness may use the emotion word \"happy\" (Example 1), the interjection \"woop\" (Example 2), the emoticon \":)\" (Example 3) or the emoji \"\u00ed \u00bd\u00ed\u00b8\u0081\" (Example 4).", "labels": [], "entities": []}, {"text": "Example 1: \"I can now finally say I am at a place in my life where I am happy with who am and the stuff I have coming for me in the future #blessed\" [Happiness] Example 2: \"its midnight and i am eating a lion bar woop\" [Happiness] Example 3: \"Enjoying a night of #Dexter with @DomoniqueP07 :)\" [Happiness] Example 4: \"The wait is almost over LA, will be out in just a little!", "labels": [], "entities": []}, {"text": "\u00ed \u00bd\u00ed\u00b8\u0081\u00ed \u00bd\u00ed\u00b8\u0081\u00ed \u00bd\u00ed\u00b8\u0081\u00ed \u00bd\u00ed\u00b8\u0081\" In addition to explicit expressions of emotion, users on Twitter also express their emotions in figurative forms through the use of idiomatic expressions (Example 5), similes (Example 6), metaphors (Example 7) or other descriptors (Example 8).", "labels": [], "entities": []}, {"text": "In these figurative expressions of emotion, each word if treated individually does not directly convey any emotion.", "labels": [], "entities": []}, {"text": "When combined together and, depending on the context of use, they act as implicit indicators of emotion.", "labels": [], "entities": []}, {"text": "Automatic emotion detectors that rely solely on the recognition of emotion words will likely fail to recognize the emotions conveyed in these examples.", "labels": [], "entities": []}, {"text": "Example 5: \"@ter2459 it was!!!", "labels": [], "entities": []}, {"text": "I am still on cloud nine!", "labels": [], "entities": []}, {"text": "I say and watched them for over two hours.", "labels": [], "entities": []}, {"text": "[Happiness] Example 6: \"Getting one of these bad boys in your cereal box and feeling like your day simply couldn't get any better http://t.co/Fae9EjyN61\" The occurrence of an emotion word in a tweet does not always indicate the tweeter's emotion.", "labels": [], "entities": []}, {"text": "The emotion word \"happy\" in Example 9 is not used to describe how the tweeter feels about the tune but is instead used to characterize the affective quality or affective property of the tune.", "labels": [], "entities": []}, {"text": "The tweeter attributes a happy quality to the tune but is in fact expressing anger towards the \"happy\" tune.", "labels": [], "entities": []}, {"text": "Similarly, #Hap-piness in Example 10 is part of a book's title so the emotion word hashtag functions as a topic more than an expression or description of an individual's emotion.", "labels": [], "entities": []}, {"text": "The common practice of using emotion word hashtags to retrieve self-annotated examples as ground truth to build emotion classifiers, a method known as \"distant supervision\", is susceptible to this weakness.", "labels": [], "entities": []}, {"text": "Example 9: \"@Anjijade I was at this party on the weekend, that happy tune was played endlessly, really not my stuff, it was like the cure's torture ha\" These challenges associated with detecting finegrained emotion expressions in tweets remain a virgin territory that has not been thoroughly explored.", "labels": [], "entities": []}, {"text": "To start addressing some off these challenges, we present a manually-annotated tweet corpus that captures a diversity of emotion expressions at a fine-grained level.", "labels": [], "entities": []}, {"text": "We describe the grounded theory approach used to develop a corpus of 5,553 tweets manually annotated with 28 emotion categories.", "labels": [], "entities": []}, {"text": "The corpus captures a variety of explicit and implicit emotion expressions for these 28 emotion categories, including the examples described above.", "labels": [], "entities": []}, {"text": "Using this carefully curated gold standard corpus, we report our preliminary efforts to train and evaluate machine learning models for emotion classification.", "labels": [], "entities": [{"text": "emotion classification", "start_pos": 135, "end_pos": 157, "type": "TASK", "confidence": 0.7608523368835449}]}, {"text": "We examine if common machine learning techniques known to perform well in coarse-grained emotion and sentiment classification can also be applied successfully on this set of fine-grained emotion categories.", "labels": [], "entities": [{"text": "sentiment classification", "start_pos": 101, "end_pos": 125, "type": "TASK", "confidence": 0.8849141001701355}]}, {"text": "The contributions of this paper are two-fold: a) Identifying machine learning algorithms that generally perform well at classifying the 28 emotion categories in the corpus and comparing them to baselines b) Comparing the machine learning performance of fine-grained to coarse-grained emotion classification", "labels": [], "entities": [{"text": "Identifying machine learning", "start_pos": 49, "end_pos": 77, "type": "TASK", "confidence": 0.8916757901509603}]}], "datasetContent": [{"text": "We ran a series of experiments to identify a set of machine learning algorithms that generally perform well for this task.", "labels": [], "entities": []}, {"text": "Four machine learning algorithms were found to perform well in this problem space: support vector machines (SVM)), Bayesian networks (, decision trees ( ), and k-nearest neighbor (KNN) (.", "labels": [], "entities": []}, {"text": "The features were held constant across different classifiers in the candidate set.", "labels": [], "entities": []}, {"text": "As a starting point, a unigram (i.e., bag-of-words) model, which has been shown to work reasonably well for text classification in sentiment analysis (), was chosen.", "labels": [], "entities": [{"text": "text classification", "start_pos": 108, "end_pos": 127, "type": "TASK", "confidence": 0.7225168943405151}, {"text": "sentiment analysis", "start_pos": 131, "end_pos": 149, "type": "TASK", "confidence": 0.8498584926128387}]}, {"text": "Although limited, the unigram bag-of-words features captures not only emotion words but all words in a tweet, thus increasing the likelihood of the classifiers to handle the figurative expressions of emotion.", "labels": [], "entities": []}, {"text": "We tokenized the text in the corpus and extracted all unique terms as features.", "labels": [], "entities": []}, {"text": "We created a custom tokenizer to better handle elements that are common in tweets.", "labels": [], "entities": []}, {"text": "In particular, the tokenizer recognizes emoticons, emojis, URLs and HTML encoding.", "labels": [], "entities": []}, {"text": "The tokenizer also handles common abbreviations and contractions.", "labels": [], "entities": []}, {"text": "Text was encoded in UTF-8 in order to preserve the emojis.", "labels": [], "entities": [{"text": "UTF-8", "start_pos": 20, "end_pos": 25, "type": "DATASET", "confidence": 0.8657371997833252}]}, {"text": "We then evaluated the effect of case normalization (i.e, lowercasing), stemming, and a minimum word frequency threshold (f = 1, 3, 5 and 10) as a means to reduce the number of features.", "labels": [], "entities": []}, {"text": "Classifiers were evaluated using 10-fold cross validation.", "labels": [], "entities": []}, {"text": "To make experiments more manageable, we frame the problem as a multi-class classification task.", "labels": [], "entities": [{"text": "multi-class classification task", "start_pos": 63, "end_pos": 94, "type": "TASK", "confidence": 0.7528627713521322}]}, {"text": "Each tweet was assigned to only one emotion label.", "labels": [], "entities": []}, {"text": "For tweets with multiple labels, only the primary label (i.e., first label) was assigned to the tweet, and the other labels were ignored.", "labels": [], "entities": []}, {"text": "We carried out two sets of experiments.", "labels": [], "entities": []}, {"text": "First, we created one single classifier (multi-class-single: one versus one) to distinguish between 29 classes (i.e., 28 emotion categories and no emotion).", "labels": [], "entities": []}, {"text": "Second, we ran experiments using Weka's MultiClassClassifier, a meta-classifier that mapped a multi-class dataset into multiple two-class classifiers (multiclass-binary: one versus all), one for each emotion and one for no emotion, thus resulting in a setup with 29 binary classifiers in total.", "labels": [], "entities": []}, {"text": "Unfortunately, the multi-class-binary setup was not designed to handle instances with multiple labels but it offered a straightforward implementation of multiple binary classifications for preliminary analysis.", "labels": [], "entities": []}, {"text": "About 92% of the corpus contained instances with only a single label so overall classification performance is expected to be close to that of a multi-label classifier.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Distribution of tweets with emotion and non-emotion", "labels": [], "entities": []}, {"text": " Table 2: Distribution of tweets for emotion valence", "labels": [], "entities": [{"text": "emotion valence", "start_pos": 37, "end_pos": 52, "type": "TASK", "confidence": 0.6896296143531799}]}, {"text": " Table 3: Distribution of tweets for 28 emotion categories", "labels": [], "entities": [{"text": "Distribution of tweets", "start_pos": 10, "end_pos": 32, "type": "TASK", "confidence": 0.87419193983078}]}, {"text": " Table 4: Micro-averaged F1 for multi-class-single (MCS) and  multi-class-binary (MCB)", "labels": [], "entities": [{"text": "F1", "start_pos": 25, "end_pos": 27, "type": "METRIC", "confidence": 0.7837870717048645}]}, {"text": " Table 5: Comparison between best performing models and  baselines (A: Accuracy, P: Precision, R: Recall)", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 71, "end_pos": 79, "type": "METRIC", "confidence": 0.9457541108131409}, {"text": "Precision", "start_pos": 84, "end_pos": 93, "type": "METRIC", "confidence": 0.9309614896774292}, {"text": "Recall", "start_pos": 98, "end_pos": 104, "type": "METRIC", "confidence": 0.9203705787658691}]}, {"text": " Table 5. In terms  of accuracy, SVM and BayesNet outperform the  majority-class and random baselines in both multi- class-single and multi-class-binary. BayesNet cor- rectly predicts roughly 60% of the instances while  SVM correctly predicts roughly 50%. In terms of  F1, SVM and BayesNet exceed the performance of  all the three baselines.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 23, "end_pos": 31, "type": "METRIC", "confidence": 0.9993460774421692}, {"text": "F1", "start_pos": 269, "end_pos": 271, "type": "METRIC", "confidence": 0.9994776844978333}]}, {"text": " Table 6: Accuracy (A), precision (P), recall (R) and F1 across classification schemes with different levels of granularity", "labels": [], "entities": [{"text": "Accuracy (A)", "start_pos": 10, "end_pos": 22, "type": "METRIC", "confidence": 0.9015707969665527}, {"text": "precision (P)", "start_pos": 24, "end_pos": 37, "type": "METRIC", "confidence": 0.9444455206394196}, {"text": "recall (R)", "start_pos": 39, "end_pos": 49, "type": "METRIC", "confidence": 0.9602228105068207}, {"text": "F1", "start_pos": 54, "end_pos": 56, "type": "METRIC", "confidence": 0.9990468621253967}]}]}