{"title": [{"text": "Capturing Reliable Fine-Grained Sentiment Associations by Crowdsourcing and Best-Worst Scaling", "labels": [], "entities": [{"text": "Capturing Reliable Fine-Grained Sentiment Associations", "start_pos": 0, "end_pos": 54, "type": "TASK", "confidence": 0.8499523162841797}]}], "abstractContent": [{"text": "Access to word-sentiment associations is useful for many applications, including sentiment analysis, stance detection, and linguistic analysis.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 81, "end_pos": 99, "type": "TASK", "confidence": 0.9683502614498138}, {"text": "stance detection", "start_pos": 101, "end_pos": 117, "type": "TASK", "confidence": 0.9613760709762573}, {"text": "linguistic analysis", "start_pos": 123, "end_pos": 142, "type": "TASK", "confidence": 0.7443438768386841}]}, {"text": "However, manually assigning fine-grained sentiment association scores to words has many challenges with respect to keeping annotations consistent.", "labels": [], "entities": []}, {"text": "We apply the annotation technique of Best-Worst Scaling to obtain real-valued sentiment association scores for words and phrases in three different domains: general English, English Twitter, and Arabic Twitter.", "labels": [], "entities": []}, {"text": "We show that on all three domains the ranking of words by sentiment remains remarkably consistent even when the annotation process is repeated with a different set of annotators.", "labels": [], "entities": []}, {"text": "We also, for the first time, determine the minimum difference in sentiment association that is perceptible to native speakers of a language.", "labels": [], "entities": []}], "introductionContent": [{"text": "Word-sentiment associations, commonly captured in sentiment lexicons, are useful in automatic sentiment prediction (), stance detection (), literary analysis, detecting personality traits (, and other applications.", "labels": [], "entities": [{"text": "automatic sentiment prediction", "start_pos": 84, "end_pos": 114, "type": "TASK", "confidence": 0.6176350812117258}, {"text": "stance detection", "start_pos": 119, "end_pos": 135, "type": "TASK", "confidence": 0.9036234319210052}, {"text": "literary analysis", "start_pos": 140, "end_pos": 157, "type": "TASK", "confidence": 0.7956986427307129}]}, {"text": "Manually created sentiment lexicons are especially useful because they tend to be more accurate than automatically generated lexicons; they can be used to automatically generate large-scale lexicons (); they can be used to evaluate different methods of automatically creating sentiment lexicons; and they can be used for linguistic analyses such as examining how sentiment is composed in phrases and sentences.", "labels": [], "entities": []}, {"text": "The sentiment of a phrase can differ significantly from the sentiment of its constituent words.", "labels": [], "entities": []}, {"text": "Sentiment composition is the determining of sentiment of a multi-word linguistic unit, such as a phrase or a sentence, from its constituents.", "labels": [], "entities": [{"text": "Sentiment composition", "start_pos": 0, "end_pos": 21, "type": "TASK", "confidence": 0.9510596692562103}, {"text": "determining of sentiment of a multi-word linguistic unit, such as a phrase or a sentence", "start_pos": 29, "end_pos": 117, "type": "TASK", "confidence": 0.6285516619682312}]}, {"text": "Lexicons that include sentiment associations for phrases as well as for their constituent words are useful in studying sentiment composition.", "labels": [], "entities": [{"text": "sentiment composition", "start_pos": 119, "end_pos": 140, "type": "TASK", "confidence": 0.9081460535526276}]}, {"text": "We refer to them as sentiment composition lexicons (SCLs).", "labels": [], "entities": [{"text": "sentiment composition lexicons (SCLs)", "start_pos": 20, "end_pos": 57, "type": "TASK", "confidence": 0.8004821886618932}]}, {"text": "We created SCLs for three domains, and all three were used in recent SemEval shared tasks.", "labels": [], "entities": [{"text": "SemEval shared tasks", "start_pos": 69, "end_pos": 89, "type": "TASK", "confidence": 0.9058767159779867}]}, {"text": "We refer to the lexicon created for the English Twitter domain as the SemEval-2015 English Twitter Sentiment Lexicon; for the general English domain as the SemEval-2016 General English Sentiment Modifiers Lexicon; and for the Arabic Twitter domain as the SemEval-2016 Arabic Twitter Sentiment Lexicon.", "labels": [], "entities": [{"text": "SemEval-2016 General English Sentiment Modifiers Lexicon", "start_pos": 156, "end_pos": 212, "type": "TASK", "confidence": 0.4894484579563141}, {"text": "SemEval-2016 Arabic Twitter Sentiment Lexicon", "start_pos": 255, "end_pos": 300, "type": "TASK", "confidence": 0.47802152633666994}]}, {"text": "Note that the English Twitter lexicon was first described in (), whereas the other two are novel contributions presented in this paper.", "labels": [], "entities": []}, {"text": "Most existing manually created sentiment lexicons tend to provide only lists of positive and negative words with very coarse levels of sentiment (.", "labels": [], "entities": []}, {"text": "The coarse-grained distinctions maybe less useful in downstream applications than having access to fine-grained (real-valued) sentiment association scores.", "labels": [], "entities": []}, {"text": "Only a small number of manual lexicons capture sentiment associations at a fine-grained level).", "labels": [], "entities": []}, {"text": "This is not surprising because obtaining real-valued sentiment annotations has several challenges.", "labels": [], "entities": []}, {"text": "Respondents are faced with a higher cognitive load when asked for real-valued sentiment scores for terms as opposed to simply classifying terms as either positive or negative.", "labels": [], "entities": []}, {"text": "Besides, it is difficult for an annotator to remain consistent with his/her annotations.", "labels": [], "entities": []}, {"text": "Further, the same sentiment association may map to different sentiment scores in the minds of different annotators; for example, one annotator may assign a score of 0.6 and another 0.8 for the same degree of positive association.", "labels": [], "entities": []}, {"text": "One could overcome these problems by providing annotators with pairs of terms and asking which is more positive (a comparative approach), however that requires a much larger set of annotations (order N 2 , where N is the number of terms to be annotated).", "labels": [], "entities": []}, {"text": "Best-Worst Scaling (BWS) is an annotation technique, commonly used in marketing research, that exploits the comparative approach to annotation while keeping the number of required annotations small.", "labels": [], "entities": [{"text": "Best-Worst Scaling (BWS)", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.7099046349525452}]}, {"text": "In this work, we investigate the applicability and reliability of the Best-Worst Scaling annotation technique in capturing word-sentiment associations via crowdsourcing.", "labels": [], "entities": []}, {"text": "Our main contributions are as follows: 1.", "labels": [], "entities": []}, {"text": "We create fine-grained sentiment composition lexicons for Arabic Twitter and general English (in addition to our earlier work on English Twitter) using Best-Worst Scaling.", "labels": [], "entities": [{"text": "sentiment composition lexicons", "start_pos": 23, "end_pos": 53, "type": "TASK", "confidence": 0.7722576856613159}]}, {"text": "The lexicons include entries for single words as well as multiword phrases.", "labels": [], "entities": []}, {"text": "The sentiment scores are real values between -1 (most negative) and +1 (most positive).", "labels": [], "entities": []}, {"text": "2. We show that the annotations on all three domains are reliable; re-doing the annotation with different sets of annotators produces a very similar order of terms-an average Spearman rank correlation of 0.98.", "labels": [], "entities": [{"text": "Spearman rank correlation", "start_pos": 175, "end_pos": 200, "type": "METRIC", "confidence": 0.7328846553961436}]}, {"text": "Furthermore, we show that reliable rankings can be obtained with just two or three annotations per BWS question.", "labels": [], "entities": [{"text": "BWS question", "start_pos": 99, "end_pos": 111, "type": "DATASET", "confidence": 0.7542564272880554}]}, {"text": "( and have shown that conventional rating-scale methods require a much higher number of responses).", "labels": [], "entities": []}, {"text": "3. We examine the relationship between 'difference in the sentiment scores between two terms' and 'agreement amongst annotators' when asked which term is more positive.", "labels": [], "entities": []}, {"text": "We show that agreement grows rapidly and reaches 90% when the difference in sentiment scores is about 0.4 (20% of interval between -1 and 1).", "labels": [], "entities": [{"text": "agreement", "start_pos": 13, "end_pos": 22, "type": "METRIC", "confidence": 0.9878359436988831}]}, {"text": "4. We calculate the minimum difference in sentiment scores of two terms that is perceptible to native speakers of a language.", "labels": [], "entities": []}, {"text": "For sentiment scores between -1 (most negative) and 1 (most positive), we show that the perceptible difference is about 0.08 for English and Arabic speakers.", "labels": [], "entities": []}, {"text": "Knowing the least perceptible difference helps researchers better understand sentiment composition.", "labels": [], "entities": [{"text": "sentiment composition", "start_pos": 77, "end_pos": 98, "type": "TASK", "confidence": 0.9046489894390106}]}, {"text": "For example, consider the task of determining whether an adjective significantly impacts the sentiment of the noun it qualifies.", "labels": [], "entities": []}, {"text": "This can be accomplished by determining whether the difference in sentiment scores between the combined phrase and the constituent noun alone is greater than the least perceptible difference.", "labels": [], "entities": []}, {"text": "The data and code created as part of this project (the lexicons, the annotation questionnaire, and the code to generate BWS questions) are made available.", "labels": [], "entities": [{"text": "BWS", "start_pos": 120, "end_pos": 123, "type": "DATASET", "confidence": 0.6644553542137146}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Example entries from the three lexicons.", "labels": [], "entities": []}]}