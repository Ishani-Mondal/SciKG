{"title": [{"text": "BIRA: Improved Predictive Exchange Word Clustering", "labels": [], "entities": [{"text": "BIRA", "start_pos": 0, "end_pos": 4, "type": "METRIC", "confidence": 0.969963014125824}, {"text": "Improved Predictive Exchange Word Clustering", "start_pos": 6, "end_pos": 50, "type": "TASK", "confidence": 0.5497559428215026}]}], "abstractContent": [{"text": "Word clusters are useful for many NLP tasks including training neural network language models, but current increases in datasets are outpacing the ability of word clusterers to handle them.", "labels": [], "entities": []}, {"text": "Little attention has been paid thus far on inducing high-quality word clusters at a large scale.", "labels": [], "entities": []}, {"text": "The predictive exchange algorithm is quite scalable, but sometimes does not provide as good perplexity as other slower clustering algorithms.", "labels": [], "entities": [{"text": "predictive exchange", "start_pos": 4, "end_pos": 23, "type": "TASK", "confidence": 0.8993222117424011}]}, {"text": "We introduce the bidirectional, interpolated, refining, and alternating (BIRA) predictive exchange algorithm.", "labels": [], "entities": [{"text": "alternating (BIRA)", "start_pos": 60, "end_pos": 78, "type": "METRIC", "confidence": 0.8265013545751572}, {"text": "predictive exchange", "start_pos": 79, "end_pos": 98, "type": "TASK", "confidence": 0.5982785820960999}]}, {"text": "It improves upon the pre-dictive exchange algorithm's perplexity by up to 18%, giving it perplexities comparable to the slower two-sided exchange algorithm, and better perplexities than the slower Brown clustering algorithm.", "labels": [], "entities": []}, {"text": "Our BIRA implementation is fast, clustering a 2.5 billion token English News Crawl corpus in 3 hours.", "labels": [], "entities": [{"text": "BIRA", "start_pos": 4, "end_pos": 8, "type": "DATASET", "confidence": 0.532390832901001}, {"text": "English News Crawl corpus", "start_pos": 64, "end_pos": 89, "type": "DATASET", "confidence": 0.7000161558389664}]}, {"text": "It also reduces machine translation training time while preserving translation quality.", "labels": [], "entities": [{"text": "machine translation training", "start_pos": 16, "end_pos": 44, "type": "TASK", "confidence": 0.8658996224403381}]}, {"text": "Our implementation is portable and freely available.", "labels": [], "entities": []}], "introductionContent": [{"text": "Words can be grouped together into equivalence classes to help reduce data sparsity and better generalize data.", "labels": [], "entities": []}, {"text": "Word clusters are useful in many NLP applications.", "labels": [], "entities": []}, {"text": "Within machine translation word classes are used in word alignment (), translation models (, reordering, preordering, targetside inflection (), SAMT (, and OSM (), among many others.", "labels": [], "entities": [{"text": "word alignment", "start_pos": 52, "end_pos": 66, "type": "TASK", "confidence": 0.7357485592365265}, {"text": "SAMT", "start_pos": 144, "end_pos": 148, "type": "TASK", "confidence": 0.7015524506568909}]}, {"text": "Word clusterings have also found utility in parsing (), chunking), NER (), structure transfer, and discourse relation discovery.", "labels": [], "entities": [{"text": "Word clusterings", "start_pos": 0, "end_pos": 16, "type": "TASK", "confidence": 0.652391329407692}, {"text": "parsing", "start_pos": 44, "end_pos": 51, "type": "TASK", "confidence": 0.9722762703895569}, {"text": "structure transfer", "start_pos": 75, "end_pos": 93, "type": "TASK", "confidence": 0.7367115169763565}, {"text": "discourse relation discovery", "start_pos": 99, "end_pos": 127, "type": "TASK", "confidence": 0.670412689447403}]}, {"text": "Word clusters also speedup normalization in training neural network and MaxEnt language models, via class-based decomposition.", "labels": [], "entities": []}, {"text": "This reduces the normalization time from O(|V |) (the vocabulary size) to \u2248 O( |V |) . More improvements to O(log(|V |)) are found using hierarchical softmax) .", "labels": [], "entities": []}], "datasetContent": [{"text": "Our experiments consist of both intrinsic and extrinsic evaluations.", "labels": [], "entities": []}, {"text": "The intrinsic evaluation measures the perplexity (PP) of two-sided class-based models for English and Russian, and the extrinsic evaluation measures BLEU scores of phrase-based MT of Russian\u2194English and Japanese\u2194English texts.", "labels": [], "entities": [{"text": "perplexity (PP)", "start_pos": 38, "end_pos": 53, "type": "METRIC", "confidence": 0.7091361582279205}, {"text": "BLEU", "start_pos": 149, "end_pos": 153, "type": "METRIC", "confidence": 0.9992522597312927}, {"text": "MT", "start_pos": 177, "end_pos": 179, "type": "TASK", "confidence": 0.7857195734977722}]}, {"text": "In this task we used 400, 800, and 1200 classes for English, and 800 classes for Russian.", "labels": [], "entities": []}, {"text": "The data comes from the 2011-2013 News Crawl monolingual data of the WMT task.", "labels": [], "entities": [{"text": "News Crawl monolingual data", "start_pos": 34, "end_pos": 61, "type": "DATASET", "confidence": 0.8967197835445404}, {"text": "WMT task", "start_pos": 69, "end_pos": 77, "type": "TASK", "confidence": 0.5426097512245178}]}, {"text": "For these experiments the data was deduplicated, shuffled, tokenized, digitconflated, and lowercased.", "labels": [], "entities": []}, {"text": "In order to have a large test set, one line per 100 of the resulting (shuffled) corpus was separated into the test set.", "labels": [], "entities": []}, {"text": "The minimum count threshold was set to 3 occurrences in the training set.", "labels": [], "entities": [{"text": "minimum count threshold", "start_pos": 4, "end_pos": 27, "type": "METRIC", "confidence": 0.7225345770517985}, {"text": "occurrences", "start_pos": 41, "end_pos": 52, "type": "METRIC", "confidence": 0.9712499380111694}]}, {"text": "The clusterings are evaluated on the PP of an external 5-gram unidirectional two-sided class-based language model (LM).", "labels": [], "entities": []}, {"text": "The n-gram-order interpolation weights are tuned using a distinct development set of comparable size and quality as the test set. and show perplexity results using a varying number of classes.", "labels": [], "entities": []}, {"text": "Two-sided exchange gives the lowest perplexity across the board, although this is within a two-sided LM evaluation. of a given word followed by a given class.", "labels": [], "entities": []}, {"text": "8 This was independently discovered in. http://www.statmt.org/wmt15/ translation-task.html The data setup script is at http://www.dfki.de/ \u02dc jode03/naacl2016.sh . We also evaluated clusters derived from word2vec () using various configurations , and all gave poor perplexities.", "labels": [], "entities": []}, {"text": "BIRA gives better perplexities than both the original predictive exchange algorithm and Brown clusters.", "labels": [], "entities": [{"text": "BIRA", "start_pos": 0, "end_pos": 4, "type": "METRIC", "confidence": 0.9665318131446838}]}, {"text": "The Russian experiments yielded higher perplexities for all clusterings, but otherwise the same comparative results.", "labels": [], "entities": []}, {"text": "In general Brown clusters give slightly worse results relative to exchange-based clusters, since Brown clustering requires an early, permanent placement of frequent words, with further restrictions imposed on the |C|-most frequent words (.", "labels": [], "entities": []}, {"text": "Liang-style Brown clustering is only efficient on a small number of clusters, since there is a |C| 2 term in its time complexity.", "labels": [], "entities": []}, {"text": "Negative sampling & hierarchical softmax; CBOW & skipgram; various window sizes; various dimensionalities.", "labels": [], "entities": []}, {"text": "For the two-sided exchange we used mkcls; for the original pred.", "labels": [], "entities": []}, {"text": "exchange we used Phrasal's clusterer; for Brown clustering we used Percy Liang's brown-cluster (329dc).", "labels": [], "entities": []}, {"text": "All had min-count=3, and all but mkcls (which is not multithreaded) had threads=12, iterations=15.", "labels": [], "entities": []}, {"text": "The original predictive exchange algorithm has a more fractionated history than the two-sided exchange algorithm.", "labels": [], "entities": []}, {"text": "Interestingly, increasing the number of clusters causes a convergence in the word clusterings themselves, while also causing a divergence in the time complexities of these two varieties of the exchange algorithm.", "labels": [], "entities": []}, {"text": "The metaheuristic techniques employed by the twosided clusterer mkcls can be applied to other exchange-based clusterers-including ours-for further improvements.", "labels": [], "entities": []}, {"text": "presents wall clock times using the full training set, varying the number of word classes |C| (for English).", "labels": [], "entities": []}, {"text": "The predictive exchange-based clusterers (BIRA and Phrasal) exhibit slow increases in time as the number of classes increases, while the others (Brown and mkcls) are much more sensitive to |C| . Our BIRA-based clusterer is three times faster than Phrasal for all these sets.", "labels": [], "entities": [{"text": "BIRA", "start_pos": 42, "end_pos": 46, "type": "METRIC", "confidence": 0.8561803698539734}]}, {"text": "We performed an additional experiment, adding more English News Crawl training data.", "labels": [], "entities": [{"text": "English News Crawl training data", "start_pos": 51, "end_pos": 83, "type": "DATASET", "confidence": 0.8582982301712037}]}, {"text": "Our implementation took 3.0 hours to cluster 2.5 billion training tokens, with |C| = 800 using modest hardware.", "labels": [], "entities": []}, {"text": "We also evaluated the BIRA predictive exchange algorithm extrinsically in machine translation.", "labels": [], "entities": [{"text": "BIRA", "start_pos": 22, "end_pos": 26, "type": "METRIC", "confidence": 0.9288210272789001}, {"text": "machine translation", "start_pos": 74, "end_pos": 93, "type": "TASK", "confidence": 0.665501058101654}]}, {"text": "As discussed in Section 1, word clusters are employed in a variety of ways within machine translation systems, the most common of which is in word alignment where mkcls is widely used.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 82, "end_pos": 101, "type": "TASK", "confidence": 0.7138710021972656}, {"text": "word alignment", "start_pos": 142, "end_pos": 156, "type": "TASK", "confidence": 0.7623156607151031}]}, {"text": "As training sets get larger every year, mkcls struggles to keep pace, and is a substantial time bottleneck in MT pipelines with large datasets.", "labels": [], "entities": [{"text": "MT", "start_pos": 110, "end_pos": 112, "type": "TASK", "confidence": 0.9839582443237305}]}, {"text": "We used data from the Workshop on Machine Translation 2015 (WMT15) Russian\u2194English dataset and the Workshop on Asian Translation 2014 (WAT14) Japanese\u2194English dataset ().", "labels": [], "entities": [{"text": "Machine Translation 2015", "start_pos": 34, "end_pos": 58, "type": "TASK", "confidence": 0.7790229419867197}, {"text": "WMT15) Russian\u2194English dataset", "start_pos": 60, "end_pos": 90, "type": "DATASET", "confidence": 0.8089571495850881}, {"text": "Asian Translation 2014 (WAT14) Japanese\u2194English dataset", "start_pos": 111, "end_pos": 166, "type": "DATASET", "confidence": 0.8103344202041626}]}, {"text": "Both pairs used standard configurations, like truecasing, MeCab segmentation for Japanese, MGIZA alignment, grow-diag-final-and phrase extraction, phrase-based Moses, quantized   The BLEU score differences between using mkcls and our BIRA implementation are small but there area few statistically significant changes, using bootstrap resampling).", "labels": [], "entities": [{"text": "MeCab segmentation", "start_pos": 58, "end_pos": 76, "type": "TASK", "confidence": 0.7448521554470062}, {"text": "MGIZA alignment", "start_pos": 91, "end_pos": 106, "type": "TASK", "confidence": 0.6159703135490417}, {"text": "phrase extraction", "start_pos": 128, "end_pos": 145, "type": "TASK", "confidence": 0.6795644909143448}, {"text": "BLEU score", "start_pos": 183, "end_pos": 193, "type": "METRIC", "confidence": 0.9779656231403351}]}, {"text": "presents the BLEU score changes across varying cluster sizes (*: p-value < 0.05, **: p-value < 0.01).", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 13, "end_pos": 23, "type": "METRIC", "confidence": 0.9769751131534576}]}, {"text": "MERT tuning is quite erratic, and some of the BLEU differences could be affected by noise in the tuning process in obtaining quality weight values.", "labels": [], "entities": [{"text": "MERT tuning", "start_pos": 0, "end_pos": 11, "type": "TASK", "confidence": 0.4485352635383606}, {"text": "BLEU", "start_pos": 46, "end_pos": 50, "type": "METRIC", "confidence": 0.99925297498703}]}, {"text": "Using our BIRA implementation reduces the translation model training time with 500 clusters from 20 hours using mkcls (of which 60% of the time is spent on clustering) to just 8 hours (of which 5% is spent on clustering).", "labels": [], "entities": [{"text": "translation model training", "start_pos": 42, "end_pos": 68, "type": "TASK", "confidence": 0.854527751604716}]}], "tableCaptions": [{"text": " Table 2: 5-gram two-sided class-based LM perplexities.", "labels": [], "entities": []}, {"text": " Table 3: Clustering times (hours) of full training sets. Mkcls", "labels": [], "entities": [{"text": "Mkcls", "start_pos": 58, "end_pos": 63, "type": "DATASET", "confidence": 0.6435820460319519}]}, {"text": " Table 4: BLEU scores (mkcls\u2192BIRA) and significance across", "labels": [], "entities": [{"text": "BLEU scores", "start_pos": 10, "end_pos": 21, "type": "METRIC", "confidence": 0.9677179157733917}, {"text": "BIRA", "start_pos": 29, "end_pos": 33, "type": "METRIC", "confidence": 0.973451554775238}, {"text": "significance", "start_pos": 39, "end_pos": 51, "type": "METRIC", "confidence": 0.991229772567749}]}]}