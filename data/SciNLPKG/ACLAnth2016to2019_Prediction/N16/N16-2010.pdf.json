{"title": [{"text": "Explicit Argument Identification for Discourse Parsing In Hindi: A Hybrid Pipeline", "labels": [], "entities": [{"text": "Explicit Argument Identification", "start_pos": 0, "end_pos": 32, "type": "TASK", "confidence": 0.7121630311012268}, {"text": "Discourse Parsing", "start_pos": 37, "end_pos": 54, "type": "TASK", "confidence": 0.6673586517572403}]}], "abstractContent": [{"text": "Shallow discourse parsing enables us to study discourse as a coherent piece of information rather than a sequence of clauses, sentences and paragraphs.", "labels": [], "entities": [{"text": "discourse parsing", "start_pos": 8, "end_pos": 25, "type": "TASK", "confidence": 0.7640992999076843}]}, {"text": "In this paper, we identify arguments of explicit discourse relations in Hindi.", "labels": [], "entities": []}, {"text": "This is the first such work carried out for Hindi.", "labels": [], "entities": []}, {"text": "Building upon previous work carried out on discourse connective identification in Hindi, we propose a hybrid pipeline which makes use of both sub-tree extraction and linear tagging approaches.", "labels": [], "entities": [{"text": "discourse connective identification", "start_pos": 43, "end_pos": 78, "type": "TASK", "confidence": 0.7085024118423462}, {"text": "sub-tree extraction", "start_pos": 142, "end_pos": 161, "type": "TASK", "confidence": 0.7572081983089447}]}, {"text": "We report state-of-the-art performance for this task.", "labels": [], "entities": []}], "introductionContent": [{"text": "Units within apiece of text are not meant to be understood independently but understood by linking them with other units in the text.", "labels": [], "entities": []}, {"text": "These units maybe clauses, sentences or even complete paragraphs.", "labels": [], "entities": []}, {"text": "Establishing relations between units present in a text allows the text to be semantically well structured and understandable.", "labels": [], "entities": []}, {"text": "Understanding the internal structure of text and the identification of discourse relations is called discourse analysis.", "labels": [], "entities": [{"text": "identification of discourse relations", "start_pos": 53, "end_pos": 90, "type": "TASK", "confidence": 0.8332103192806244}, {"text": "discourse analysis", "start_pos": 101, "end_pos": 119, "type": "TASK", "confidence": 0.7407159060239792}]}, {"text": "A fully automated shallow discourse parser would greatly aid in discourse analysis and improve the performance of Text summarization and Question answering systems.", "labels": [], "entities": [{"text": "shallow discourse parser", "start_pos": 18, "end_pos": 42, "type": "TASK", "confidence": 0.7390333414077759}, {"text": "discourse analysis", "start_pos": 64, "end_pos": 82, "type": "TASK", "confidence": 0.740083858370781}, {"text": "Text summarization", "start_pos": 114, "end_pos": 132, "type": "TASK", "confidence": 0.8283157050609589}, {"text": "Question answering", "start_pos": 137, "end_pos": 155, "type": "TASK", "confidence": 0.8735413551330566}]}, {"text": "Given a text, a shallow discourse parser would identify discourse relations, consisting of two spans of text exhibiting some kind of relationship between each other.", "labels": [], "entities": []}, {"text": "Discourse relations whose presence is marked explicitly by discourse connectives are called Explicit discourse relations and those which are not are called Implicit discourse relations.", "labels": [], "entities": []}, {"text": "At present, complete shallow discourse parsers are only available for English (.", "labels": [], "entities": []}, {"text": "The ongoing CoNLL 2016 shared task on Shallow Discourse Parsing has included Chinese as well.", "labels": [], "entities": [{"text": "CoNLL 2016 shared task", "start_pos": 12, "end_pos": 34, "type": "DATASET", "confidence": 0.8240050226449966}, {"text": "Shallow Discourse Parsing", "start_pos": 38, "end_pos": 63, "type": "TASK", "confidence": 0.6246053775151571}]}, {"text": "Work towards a complete shallow discourse parser in Hindi has also begun.", "labels": [], "entities": [{"text": "shallow discourse parser", "start_pos": 24, "end_pos": 48, "type": "TASK", "confidence": 0.6987118124961853}]}, {"text": "reported state-of-theart results for discourse connective identification in Hindi.", "labels": [], "entities": [{"text": "discourse connective identification", "start_pos": 37, "end_pos": 72, "type": "TASK", "confidence": 0.7188720305760702}]}, {"text": "Our work focuses on the next part towards a shallow discourse parser for Hindi i.e. argument identification for Explicit discourse relations.", "labels": [], "entities": [{"text": "argument identification", "start_pos": 84, "end_pos": 107, "type": "TASK", "confidence": 0.7147806286811829}]}, {"text": "In this paper, we discuss current approaches for this task and also propose a hybrid pipeline incorporating many of these approaches.", "labels": [], "entities": []}, {"text": "We report high accuracies of 93.28% for Arg2 identification, 71.09% for Arg1 identification and 66.3% for Arg1-Arg2 identification.", "labels": [], "entities": [{"text": "accuracies", "start_pos": 15, "end_pos": 25, "type": "METRIC", "confidence": 0.9990662932395935}, {"text": "Arg2", "start_pos": 40, "end_pos": 44, "type": "METRIC", "confidence": 0.9504163861274719}, {"text": "Arg1", "start_pos": 72, "end_pos": 76, "type": "METRIC", "confidence": 0.9530933499336243}, {"text": "Arg1-Arg2 identification", "start_pos": 106, "end_pos": 130, "type": "TASK", "confidence": 0.7295638024806976}]}, {"text": "The rest of the paper is organized as follows.", "labels": [], "entities": []}, {"text": "Section 2 briefly introduces the Hindi Discourse Relations Bank(HDRB).", "labels": [], "entities": [{"text": "Hindi Discourse Relations Bank(HDRB)", "start_pos": 33, "end_pos": 69, "type": "DATASET", "confidence": 0.6930292248725891}]}, {"text": "Related work carried out in English is discussed in Section 3.", "labels": [], "entities": []}, {"text": "In section 4, we describe in detail our approach to argument identification of Explicit discourse relations.", "labels": [], "entities": [{"text": "argument identification of Explicit discourse relations", "start_pos": 52, "end_pos": 107, "type": "TASK", "confidence": 0.6978549162546793}]}, {"text": "Section 5 discusses the performance of the proposed pipeline and we conclude in Section 6.", "labels": [], "entities": []}], "datasetContent": [{"text": "Maximum Entropy) for classifier based steps and Conditional Random Fields () for linear tagging based steps were our choice of algorithms.", "labels": [], "entities": []}, {"text": "L2 regularized Stochastic Gradient Descent (SGD) was used while training the CRF model and LibLinear solver) with L2 penalties was used to train the Maximum Entropy model.", "labels": [], "entities": []}, {"text": "Maximum Entropy was implemented using Nltk toolkit 1 and Sklearn 2 whereas Conditional Random Fields was implemented using a CRFsuite 3.We used 5-fold cross validation to arrive at the results.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Arg2 identification results", "labels": [], "entities": [{"text": "Arg2 identification", "start_pos": 10, "end_pos": 29, "type": "TASK", "confidence": 0.8677206337451935}]}, {"text": " Table 3: Arg1(SS) identification results", "labels": [], "entities": [{"text": "Arg1", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9760885238647461}, {"text": "SS) identification", "start_pos": 15, "end_pos": 33, "type": "TASK", "confidence": 0.7372924486796061}]}]}