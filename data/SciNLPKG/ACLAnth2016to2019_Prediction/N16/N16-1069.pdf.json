{"title": [{"text": "Large-scale Multitask Learning for Machine Translation Quality Estimation", "labels": [], "entities": [{"text": "Machine Translation Quality Estimation", "start_pos": 35, "end_pos": 73, "type": "TASK", "confidence": 0.8579713851213455}]}], "abstractContent": [{"text": "Multitask learning has been proven a useful technique in a number of Natural Language Processing applications where data is scarce and naturally diverse.", "labels": [], "entities": [{"text": "Multitask learning", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.8095405399799347}]}, {"text": "Examples include learning from data of different domains and learning from labels provided by multiple annota-tors.", "labels": [], "entities": []}, {"text": "Tasks in these scenarios would be the domains or the annotators.", "labels": [], "entities": []}, {"text": "When faced with limited data for each task, a framework for the learning of tasks in parallel while using a shared representation is clearly helpful: what is learned fora given task can be transferred to other tasks while the peculiarities of each task are still modelled.", "labels": [], "entities": []}, {"text": "Focusing on machine translation quality estimation as application, in this paper we show that multitask learning is also useful in cases where data is abundant.", "labels": [], "entities": [{"text": "machine translation quality estimation", "start_pos": 12, "end_pos": 50, "type": "TASK", "confidence": 0.8583609610795975}, {"text": "multitask learning", "start_pos": 94, "end_pos": 112, "type": "TASK", "confidence": 0.8471404314041138}]}, {"text": "Based on two large-scale datasets, we explore models with multiple annotators and multiple languages and show that state-of-the-art mul-titask learning algorithms lead to improved results in all settings.", "labels": [], "entities": []}], "introductionContent": [{"text": "Quality Estimation (QE) models predict the quality of Machine Translation (MT) output based on the source and target texts only, without reference translations.", "labels": [], "entities": [{"text": "Machine Translation (MT) output", "start_pos": 54, "end_pos": 85, "type": "TASK", "confidence": 0.8699045777320862}]}, {"text": "This task is often framed as a supervised machine learning problem using various features indicating fluency, adequacy and complexity of the source-target text pair, and annotations on translation quality given by human translators.", "labels": [], "entities": []}, {"text": "Various kernel-based regression and classification algorithms have been explored to learn prediction models.", "labels": [], "entities": []}, {"text": "The application of QE we focus on here is that of guiding professional translators during the postediting of MT output.", "labels": [], "entities": [{"text": "MT output", "start_pos": 109, "end_pos": 118, "type": "TASK", "confidence": 0.8347609341144562}]}, {"text": "QE models can provide translators with information on how much editing/time will be necessary to fix a given segment, or on whether it is worth editing it at all, as opposed to translating it from scratch.", "labels": [], "entities": []}, {"text": "For this application, models are learnt from quality annotations that reflect post-editing effort, for instance, 1-5 judgements on estimated post-editing effort) or actual post-editing effort measured as post-editing time or edit distance between the MT output and its post-edited version).", "labels": [], "entities": []}, {"text": "One of the biggest challenges in this field is to deal with the inherent subjectivity of quality labels given by humans.", "labels": [], "entities": []}, {"text": "Explicit judgements (e.g. the 1-5 point scale) are affected the most, with previous work showing that translators' perception of post-editing effort differs from actual effort).", "labels": [], "entities": []}, {"text": "However, even objective annotations of actual post-editing effort are subject to natural variance.", "labels": [], "entities": []}, {"text": "Take, for example, post-editing time as a label: Different annotators have different typing speeds and may require more or less time to deal with the same edits depending on their level of experience, familiarity with the domain, etc.", "labels": [], "entities": []}, {"text": "Post-editing distance also varies across translators as there are often multiple ways of producing a good quality translation from an MT output, even when strict guidelines are given.", "labels": [], "entities": []}, {"text": "In order to address variance among multiple translators, three strategies have been applied: (i) models are built by averaging annotations from multiple translators on the same data points, as was done in the first shared task on the topic); (ii) models are built for individual translators by collecting labelled data for each translator; and (iii) models are built using multitask learning techniques to put together annotations from multiple translators while keeping track of the translators' identification to account for their individual biases.", "labels": [], "entities": []}, {"text": "The first approach is sensible because, in the limit, the models built should reflect the \"average\" strategies/preferences of translators.", "labels": [], "entities": []}, {"text": "However, its cost makes it prohibitive.", "labels": [], "entities": []}, {"text": "The second approach can lead to very accurate models but it requires sufficient training data for each translator, and that all translators are known at model building time.", "labels": [], "entities": []}, {"text": "The last approach is very attractive.", "labels": [], "entities": []}, {"text": "It is a transfer learning (a.k.a. domain-adaptation) approach that allows the modelling of data from each individual translator while also modelling correlations between translators such that \"similar\" translators can mutually inform one another.", "labels": [], "entities": [{"text": "transfer learning (a.k.a. domain-adaptation)", "start_pos": 8, "end_pos": 52, "type": "TASK", "confidence": 0.7945769429206848}]}, {"text": "As such, it does not require multiple annotations of the same data points and can be effective even if only a few data points are available for each translator.", "labels": [], "entities": []}, {"text": "In fact, previous work on multitask learning for quality estimation has concentrated on the problem of learning prediction models from little data provided by different annotators.", "labels": [], "entities": [{"text": "quality estimation", "start_pos": 49, "end_pos": 67, "type": "TASK", "confidence": 0.6841002255678177}]}, {"text": "In this paper we take a step further to investigate multitask learning for quality estimation in settings where data maybe abundant for some or most annotators.", "labels": [], "entities": [{"text": "quality estimation", "start_pos": 75, "end_pos": 93, "type": "TASK", "confidence": 0.6315749436616898}]}, {"text": "We explore a multitask learning approach that provides a general, scalable and robust solution regardless of the amount of data available.", "labels": [], "entities": []}, {"text": "By testing models on single translator data, we show that while building models for individual translators is a sensible decision when large amounts of data are available, the multitask learning approach can outperform these models by learning from data by multiple annotators.", "labels": [], "entities": []}, {"text": "Additionally, besides having translators as \"tasks\", we address the problem of learning from data for multiple language pairs.", "labels": [], "entities": []}, {"text": "We devise our multitaslk approach within the Bayesian non-parametric machine learning framework of Gaussian Processes).", "labels": [], "entities": []}, {"text": "Gaussian Processes have shown very good results for quality estimation in previous work.", "labels": [], "entities": [{"text": "quality estimation", "start_pos": 52, "end_pos": 70, "type": "TASK", "confidence": 0.6141541600227356}]}, {"text": "Our datasets -annotated for postediting distance -contain nearly 100K data points, two orders of magnitude larger than those used in previous work.", "labels": [], "entities": [{"text": "postediting distance", "start_pos": 28, "end_pos": 48, "type": "TASK", "confidence": 0.7546463012695312}]}, {"text": "To cope with scalability issues resulting from the size of these datasets, we apply a sparse version of Gaussian Processes.", "labels": [], "entities": []}, {"text": "We perform extensive experiments on this large-scale data aiming to answer the following research questions: \u2022 What is the best approach to build models to be used by individual translators?", "labels": [], "entities": []}, {"text": "How much data is necessary to build independent models (one per translator) that can be as accurate as (or better than) models using data from multiple translators?", "labels": [], "entities": []}, {"text": "\u2022 When large amounts of data are available, can we still improve over independent and pooled models by learning from metadata to exploit transfer across translators?", "labels": [], "entities": []}, {"text": "\u2022 Can crosslingual data help improve model performance by exploiting transfer across language pairs?", "labels": [], "entities": []}, {"text": "In the remainder of the paper we start with an overview on related work in the area of multitask learning for quality estimation (Section 2), to then describe our approach to multitask learning in the context of Gaussian Processes (Section 3).", "labels": [], "entities": []}, {"text": "In Section 4 we introduce our data and experimental settings.", "labels": [], "entities": []}, {"text": "Finally in Sections 5 and 6 we present the results of our experiments to answer the above mentioned questions for cross-annotator and crosslingual transfer, respectively.", "labels": [], "entities": [{"text": "crosslingual transfer", "start_pos": 134, "end_pos": 155, "type": "TASK", "confidence": 0.7784216105937958}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Number of en-es and en-fr segments", "labels": [], "entities": [{"text": "Number", "start_pos": 10, "end_pos": 16, "type": "METRIC", "confidence": 0.9579839110374451}]}]}