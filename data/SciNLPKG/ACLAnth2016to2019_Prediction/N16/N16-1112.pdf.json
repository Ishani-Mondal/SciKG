{"title": [{"text": "LSTM Neural Reordering Feature for Statistical Machine Translation", "labels": [], "entities": [{"text": "LSTM Neural Reordering", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.599706103404363}, {"text": "Statistical Machine Translation", "start_pos": 35, "end_pos": 66, "type": "TASK", "confidence": 0.8138867020606995}]}], "abstractContent": [{"text": "Artificial neural networks are powerful models , which have been widely applied into many aspects of machine translation, such as language modeling and translation mod-eling.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 101, "end_pos": 120, "type": "TASK", "confidence": 0.7471089065074921}, {"text": "language modeling", "start_pos": 130, "end_pos": 147, "type": "TASK", "confidence": 0.7570978701114655}]}, {"text": "Though notable improvements have been made in these areas, the reordering problem still remains a challenge in statistical machine translations.", "labels": [], "entities": [{"text": "statistical machine translations", "start_pos": 111, "end_pos": 143, "type": "TASK", "confidence": 0.6906275749206543}]}, {"text": "In this paper, we present a novel neural reordering model that directly models word pairs and their alignment.", "labels": [], "entities": []}, {"text": "Further by utilizing LSTM recurrent neural networks , much longer context could be learned for reordering prediction.", "labels": [], "entities": [{"text": "reordering prediction", "start_pos": 95, "end_pos": 116, "type": "TASK", "confidence": 0.6155137419700623}]}, {"text": "Experimental results on NIST OpenMT12 Arabic-English and Chinese-English 1000-best rescoring task show that our LSTM neural reordering feature is robust, and achieves significant improvements over various baseline systems.", "labels": [], "entities": [{"text": "NIST OpenMT12 Arabic-English", "start_pos": 24, "end_pos": 52, "type": "DATASET", "confidence": 0.8362048069636027}, {"text": "LSTM neural reordering", "start_pos": 112, "end_pos": 134, "type": "TASK", "confidence": 0.7245654265085856}]}], "introductionContent": [{"text": "In statistical machine translation, the language model, translation model, and reordering model are the three most important components.", "labels": [], "entities": [{"text": "statistical machine translation", "start_pos": 3, "end_pos": 34, "type": "TASK", "confidence": 0.654930979013443}]}, {"text": "Among these models, the reordering model plays an important role in phrase-based machine translation (, and it still remains a major challenge in current study.", "labels": [], "entities": [{"text": "phrase-based machine translation", "start_pos": 68, "end_pos": 100, "type": "TASK", "confidence": 0.7162391344706217}]}, {"text": "In recent years, various phrase reordering methods have been proposed for phrase-based SMT systems, which can be classified into two broad categories: (1) Distance-based RM: Penalize phrase displacements with respect to the degree of nonmonotonicity ( ).", "labels": [], "entities": [{"text": "phrase reordering", "start_pos": 25, "end_pos": 42, "type": "TASK", "confidence": 0.7685379683971405}, {"text": "SMT", "start_pos": 87, "end_pos": 90, "type": "TASK", "confidence": 0.8740739822387695}, {"text": "Penalize phrase displacements", "start_pos": 174, "end_pos": 203, "type": "TASK", "confidence": 0.6203888853391012}]}, {"text": "(2) Lexicalized RM: Conditions reordering probabilities on current phrase pairs.", "labels": [], "entities": [{"text": "Lexicalized RM", "start_pos": 4, "end_pos": 18, "type": "TASK", "confidence": 0.7131322026252747}]}, {"text": "According to the orientation determinants, lexicalized reordering model can further be classified into word-based RM), phrase-based RM (, and hierarchical phrase-based RM ().", "labels": [], "entities": []}, {"text": "Furthermore, some researchers proposed a reordering model that conditions both current and previous phrase pairs by utilizing recursive autoencoders (.", "labels": [], "entities": []}, {"text": "In this paper, we propose a novel neural reordering feature by including longer context for predicting orientations.", "labels": [], "entities": [{"text": "predicting orientations", "start_pos": 92, "end_pos": 115, "type": "TASK", "confidence": 0.8789959251880646}]}, {"text": "We utilize along short-term memory recurrent neural network (LSTM-RNN), and directly models word pairs to predict its most probable orientation.", "labels": [], "entities": []}, {"text": "Experimental results on NIST OpenMT12 Arabic-English and Chinese-English translation show that our neural reordering model achieves significant improvements over various baselines in 1000-best rescoring task.", "labels": [], "entities": [{"text": "NIST OpenMT12 Arabic-English", "start_pos": 24, "end_pos": 52, "type": "DATASET", "confidence": 0.8433826367060343}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 2: LSTM reordering model with different orientation", "labels": [], "entities": [{"text": "LSTM reordering", "start_pos": 10, "end_pos": 25, "type": "TASK", "confidence": 0.7081064879894257}]}, {"text": " Table 3: LSTM reordering model with different orientation", "labels": [], "entities": [{"text": "LSTM reordering", "start_pos": 10, "end_pos": 25, "type": "TASK", "confidence": 0.7115457355976105}]}, {"text": " Table 4: Results on various baselines for Arabic-English and", "labels": [], "entities": []}]}