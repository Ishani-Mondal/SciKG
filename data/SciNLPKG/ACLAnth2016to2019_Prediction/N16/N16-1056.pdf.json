{"title": [{"text": "Bidirectional RNN for Medical Event Detection in Electronic Health Records", "labels": [], "entities": [{"text": "Bidirectional RNN", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.5465832054615021}, {"text": "Medical Event Detection", "start_pos": 22, "end_pos": 45, "type": "TASK", "confidence": 0.5856100022792816}]}], "abstractContent": [{"text": "Sequence labeling for extraction of medical events and their attributes from unstructured text in Electronic Health Record (EHR) notes is a key step towards semantic understanding of EHRs.", "labels": [], "entities": [{"text": "Sequence labeling", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.8898135423660278}, {"text": "extraction of medical events and their attributes from unstructured text in Electronic Health Record (EHR)", "start_pos": 22, "end_pos": 128, "type": "TASK", "confidence": 0.7860033512115479}]}, {"text": "It has important applications in health informatics including pharmacovig-ilance and drug surveillance.", "labels": [], "entities": [{"text": "drug surveillance", "start_pos": 85, "end_pos": 102, "type": "TASK", "confidence": 0.6991725414991379}]}, {"text": "The state of the art supervised machine learning models in this domain are based on Conditional Random Fields (CRFs) with features calculated from fixed context windows.", "labels": [], "entities": []}, {"text": "In this application, we explored recurrent neural network frameworks and show that they significantly outperformed the CRF models.", "labels": [], "entities": []}], "introductionContent": [{"text": "EHRs report patient's health, medical history and treatments compiled by medical staff at hospitals.", "labels": [], "entities": []}, {"text": "It is well known that EHR notes contain information about medical events including medication, diagnosis (or Indication), and adverse drug events (ADEs) etc.", "labels": [], "entities": [{"text": "Indication", "start_pos": 109, "end_pos": 119, "type": "METRIC", "confidence": 0.960857629776001}]}, {"text": "A medical event in this context can be described as a change in patient's medical status.", "labels": [], "entities": []}, {"text": "Identifying these events in a structured manner has many important clinical applications such as discovery of abnormally high rate of adverse reaction events to a particular drug, surveillance of drug efficacy, etc.", "labels": [], "entities": []}, {"text": "In this paper we treat EHR clinical event detection as a task of sequence labeling.", "labels": [], "entities": [{"text": "EHR clinical event detection", "start_pos": 23, "end_pos": 51, "type": "TASK", "confidence": 0.862152174115181}]}, {"text": "Sequence labeling in the context of machine learning refers to the task of learning to predict a label for each data-point in a sequence of data-points.", "labels": [], "entities": [{"text": "Sequence labeling", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.9117379784584045}]}, {"text": "This learning framework has wide applications in many disciplines such as genomics, intrusion detection, natural language processing, speech recognition etc.", "labels": [], "entities": [{"text": "intrusion detection", "start_pos": 84, "end_pos": 103, "type": "TASK", "confidence": 0.742069885134697}, {"text": "speech recognition", "start_pos": 134, "end_pos": 152, "type": "TASK", "confidence": 0.8051110506057739}]}, {"text": "However, sequence labeling in EHRs is a challenging task.", "labels": [], "entities": [{"text": "sequence labeling", "start_pos": 9, "end_pos": 26, "type": "TASK", "confidence": 0.6563320904970169}]}, {"text": "Unlike text in the open domain, EHR notes are frequently noisy, containing incomplete sentences, phrases and irregular use of language.", "labels": [], "entities": []}, {"text": "In addition, EHR notes incorporate abundant abbreviations, rich medical jargons, and their variations, which make recognizing semantically similar patterns in EHR notes difficult.", "labels": [], "entities": [{"text": "EHR notes", "start_pos": 13, "end_pos": 22, "type": "DATASET", "confidence": 0.8753751218318939}]}, {"text": "Additionally, different events exhibit different patterns and possess different prevalences.", "labels": [], "entities": [{"text": "prevalences", "start_pos": 80, "end_pos": 91, "type": "METRIC", "confidence": 0.9526163339614868}]}, {"text": "For example, while a medication comprises of at most a few words of a noun, an ADE (e.g., \"has not felt back to his normal self\") may vary to comprise of a significant part of a sentence.", "labels": [], "entities": [{"text": "ADE", "start_pos": 79, "end_pos": 82, "type": "METRIC", "confidence": 0.9883496761322021}]}, {"text": "While medication information is frequently described in EHRs, ADEs are typically rare events.", "labels": [], "entities": []}, {"text": "Rule-based and learning-based approaches have been developed to identify and extract information from EHR notes (, (,,,.", "labels": [], "entities": []}, {"text": "Learningbased approaches use sequence labeling algorithms like Conditional Random Fields (), Hidden Markov Models (), and Max-entropy Markov Models).", "labels": [], "entities": []}, {"text": "One major drawback of these graphical models is that the label prediction at anytime point only depends on its data instance and the immediate neighboring labels.", "labels": [], "entities": [{"text": "label prediction", "start_pos": 57, "end_pos": 73, "type": "TASK", "confidence": 0.6897442042827606}]}, {"text": "While this approach performs well in learning the distribution of the output labels, it has some limitations.", "labels": [], "entities": []}, {"text": "One major limitation is that it is not designed to learn from dependencies which lie in the surrounding but not quite immediate neighborhood.", "labels": [], "entities": []}, {"text": "Therefore, the feature vectors have to be explicitly modeled to include the surrounding contextual information.", "labels": [], "entities": []}, {"text": "Traditionally, bag of words representation of surrounding context has shown reasonably good performance.", "labels": [], "entities": [{"text": "bag of words representation of surrounding context", "start_pos": 15, "end_pos": 65, "type": "TASK", "confidence": 0.7324929194790977}]}, {"text": "However, the information contained in the bag of words vector is very sensitive to context window size.", "labels": [], "entities": []}, {"text": "If the context window is too short, it will not include all the information.", "labels": [], "entities": []}, {"text": "On the other hand if the context window is too large, it will compress the vital information with other irrelevant words.", "labels": [], "entities": []}, {"text": "Usually away to tackle this problem is to try different context window sizes and use the one that gives the highest validation performance.", "labels": [], "entities": []}, {"text": "However, this method cannot be easily applied to our task, because different medical events like medication, diagnosis or adverse drug reaction require different context window sizes.", "labels": [], "entities": []}, {"text": "For example, while a medication can be determined by a context of two or three words containing the drug name, an adverse drug reaction would require the context of the entire sentence.", "labels": [], "entities": []}, {"text": "As an example, this is a sentence from one of the EHRs, \"The follow-up needle biopsy results were consistent with bronchiolitis obliterans, which was likely due to the Bleomycin component of his ABVD chemo\".", "labels": [], "entities": [{"text": "EHRs", "start_pos": 50, "end_pos": 54, "type": "DATASET", "confidence": 0.9431256055831909}, {"text": "Bleomycin", "start_pos": 168, "end_pos": 177, "type": "METRIC", "confidence": 0.9805638194084167}]}, {"text": "In this sentence, the true labels are Adverse Drug Event(ADE) for \"bronchiolitis obliterans\" and Drugname for \"ABVD chemo\".", "labels": [], "entities": [{"text": "Adverse Drug Event(ADE)", "start_pos": 38, "end_pos": 61, "type": "METRIC", "confidence": 0.8422633707523346}]}, {"text": "However the ADE , \"bronchiolitis obliterans\" could be misslabeled as just another disease or symptom, if the entire sentence is not taken into context.", "labels": [], "entities": [{"text": "ADE", "start_pos": 12, "end_pos": 15, "type": "METRIC", "confidence": 0.8933597803115845}]}, {"text": "Recent advancements in Recurrent Neural Networks (RNNs) have opened up new avenues of research in sequence labeling.", "labels": [], "entities": [{"text": "Recurrent Neural Networks (RNNs)", "start_pos": 23, "end_pos": 55, "type": "TASK", "confidence": 0.5881346116463343}, {"text": "sequence labeling", "start_pos": 98, "end_pos": 115, "type": "TASK", "confidence": 0.630128413438797}]}, {"text": "Traditionally, recurrent neural networks have been hard to train through Back-Propagation, because learning long term dependencies using simple recurrent neurons lead to problems like exploding or vanishing gradients (,).", "labels": [], "entities": []}, {"text": "Recent approaches have modified the simple neuron structure in order to learn dependencies over longer intervals more efficiently.", "labels": [], "entities": []}, {"text": "In this study, we evaluate the performance of two such neural networks, namely, Long Short Term Memory (LSTM) and Gated Recurrent Units (GRU).", "labels": [], "entities": []}, {"text": "Timely identification of new drug toxicities is an unresolved clinical and public health problem, costing people's lives and billions of US dollars.", "labels": [], "entities": [{"text": "identification of new drug toxicities", "start_pos": 7, "end_pos": 44, "type": "TASK", "confidence": 0.842239785194397}]}, {"text": "In this study, we empirically evaluated LSTM and GRU on EHR notes, focusing on the clinically important task of detecting medication, diagnosis, and adverse drug event.", "labels": [], "entities": [{"text": "GRU", "start_pos": 49, "end_pos": 52, "type": "METRIC", "confidence": 0.9348477125167847}, {"text": "EHR", "start_pos": 56, "end_pos": 59, "type": "METRIC", "confidence": 0.6974743008613586}]}, {"text": "To our knowledge, we are the first group reporting the uses of RNN frameworks for information extraction in EHR notes.", "labels": [], "entities": [{"text": "information extraction", "start_pos": 82, "end_pos": 104, "type": "TASK", "confidence": 0.7996462285518646}, {"text": "EHR notes", "start_pos": 108, "end_pos": 117, "type": "DATASET", "confidence": 0.6977834403514862}]}], "datasetContent": [{"text": "The annotated corpus contains 780 English EHR notes or 613,593 word tokens (an average of 786 words per note) from cancer patients who have been diagnosed with hematological malignancy.", "labels": [], "entities": [{"text": "English EHR notes", "start_pos": 34, "end_pos": 51, "type": "DATASET", "confidence": 0.770364244778951}]}, {"text": "Each note was annotated by at least two annotators with inter-annotator agreement of 0.93 kappa.", "labels": [], "entities": []}, {"text": "The annotated events and attributes and their instances in the annotated corpus are shown in.", "labels": [], "entities": []}, {"text": "The annotated events can be broadly divided into two groups, Medication, and Disease.", "labels": [], "entities": [{"text": "Medication", "start_pos": 61, "end_pos": 71, "type": "TASK", "confidence": 0.8853099942207336}]}, {"text": "The Medication group contains Drugname, Dosage, Frequency, Duration and Route.", "labels": [], "entities": [{"text": "Medication", "start_pos": 4, "end_pos": 14, "type": "TASK", "confidence": 0.8379809856414795}, {"text": "Frequency", "start_pos": 48, "end_pos": 57, "type": "METRIC", "confidence": 0.956436276435852}, {"text": "Duration", "start_pos": 59, "end_pos": 67, "type": "METRIC", "confidence": 0.9677712321281433}, {"text": "Route", "start_pos": 72, "end_pos": 77, "type": "METRIC", "confidence": 0.9774903655052185}]}, {"text": "It corresponds to information about medication events and their attributes.", "labels": [], "entities": []}, {"text": "The attributes (Route, Frequency, Dosage, and Duration) of a medication (Drug name) occur less frequently than the Drugname tag itself, because few EHRs report complete attributes of an event.", "labels": [], "entities": [{"text": "Route", "start_pos": 16, "end_pos": 21, "type": "METRIC", "confidence": 0.9666897654533386}, {"text": "Frequency", "start_pos": 23, "end_pos": 32, "type": "METRIC", "confidence": 0.9081504344940186}, {"text": "Dosage", "start_pos": 34, "end_pos": 40, "type": "METRIC", "confidence": 0.9059706926345825}, {"text": "Duration", "start_pos": 46, "end_pos": 54, "type": "METRIC", "confidence": 0.9505605101585388}]}, {"text": "The Disease group contains events related to diseases (ADE, Indication, Other SSD) and their attributes (Severity).", "labels": [], "entities": [{"text": "Indication", "start_pos": 60, "end_pos": 70, "type": "METRIC", "confidence": 0.9405688643455505}]}, {"text": "An injury or disease can be labeled as ADE, Indication, or Other SSD depending on the semantic context.", "labels": [], "entities": [{"text": "ADE", "start_pos": 39, "end_pos": 42, "type": "METRIC", "confidence": 0.7950873970985413}, {"text": "Indication", "start_pos": 44, "end_pos": 54, "type": "METRIC", "confidence": 0.9775357842445374}]}, {"text": "It is marked as ADE if it is the side effect of a drug.", "labels": [], "entities": [{"text": "ADE", "start_pos": 16, "end_pos": 19, "type": "METRIC", "confidence": 0.9855459332466125}]}, {"text": "It is marked as Indication if it is being diagnosed currently by the doctor and a medication has been prescribed for it.", "labels": [], "entities": [{"text": "Indication", "start_pos": 16, "end_pos": 26, "type": "METRIC", "confidence": 0.9989629983901978}]}, {"text": "Any sign, symptom or disease that does not fall into the aforementioned two categories is labeled as Other SSD.", "labels": [], "entities": []}, {"text": "Other SSD is the most common label in our corpus, because it is frequently used to label conditions in the past history of the patient.", "labels": [], "entities": []}, {"text": "For each note, we removed special characters that do not serve as punctuation and then split the note into sentences using regular expressions.", "labels": [], "entities": []}, {"text": "For each word, the models were trained to predict either one of the nine medically relevant tags described in section 3, or the Outside label.", "labels": [], "entities": []}, {"text": "The CRF tagger was run in two modes.", "labels": [], "entities": [{"text": "CRF tagger", "start_pos": 4, "end_pos": 14, "type": "TASK", "confidence": 0.7979834675788879}]}, {"text": "The first mode (CRFnocontext) used only the current word and its corresponding skip-gram representation.", "labels": [], "entities": []}, {"text": "The second mode (CRF-context) used the extra context feature described in section 4.3.", "labels": [], "entities": []}, {"text": "The extra features are basically the bag of words representation of the preceding and following sections of the sentence.", "labels": [], "entities": []}, {"text": "The first mode was used to compare the performance of CRF and RNN models when using the same input data.", "labels": [], "entities": []}, {"text": "It also serves as a method of contrasting with CRF's performance when context features are explicitly added.", "labels": [], "entities": []}, {"text": "CRF Tagger uses L-BFGS optimizer with L2-regularization.", "labels": [], "entities": [{"text": "CRF Tagger", "start_pos": 0, "end_pos": 10, "type": "DATASET", "confidence": 0.9587286114692688}]}, {"text": "The RNN frameworks are trained on sentence level and document level.", "labels": [], "entities": []}, {"text": "The sentence level neural networks are fed only one sentence at a time.", "labels": [], "entities": []}, {"text": "This means that the LSTM and GRU states are only preserved and propagated within a sentence.", "labels": [], "entities": []}, {"text": "The networks cell states are re-initialized before each sentence.", "labels": [], "entities": []}, {"text": "The document level neural networks are fed one document at a time, so they can learn context cues that reside outside of the sentence boundary.", "labels": [], "entities": []}, {"text": "We use 100 dimensional hidden layer for each directional RNN chain.", "labels": [], "entities": []}, {"text": "Since we use bi-directional LSTMs and GRUs, this essentially amounts to a 200 dimensional recurrent hidden layer.", "labels": [], "entities": []}, {"text": "The hidden layer activation functions for both RNN models are tanh.", "labels": [], "entities": []}, {"text": "Output of this hidden layer is fed into a Softmax output layer which emits probabilities for each of the nine medical labels and the Outside label.", "labels": [], "entities": []}, {"text": "We use categorical cross entropy as the objective function.", "labels": [], "entities": []}, {"text": "Similar to the CRF implementation, the Neural Net cost function also contains an L2-regularization component.", "labels": [], "entities": []}, {"text": "We also use dropout () as an additional measure to avoid over-fitting.", "labels": [], "entities": []}, {"text": "Fifty percent dropout is used to manipulate the inputs to the RNN and the Softmax layer.", "labels": [], "entities": [{"text": "RNN", "start_pos": 62, "end_pos": 65, "type": "DATASET", "confidence": 0.8574838638305664}]}, {"text": "We use AdaGrad () to optimize the network cost.", "labels": [], "entities": []}, {"text": "We use ten-fold cross validation to calculate the performance metric for each model.", "labels": [], "entities": []}, {"text": "The dataset is divided at the note level.", "labels": [], "entities": []}, {"text": "We separate out 10 % of the training set to form the validation set.", "labels": [], "entities": []}, {"text": "This validation set is used to evaluate the different parameter combinations for CRF and RNN models.", "labels": [], "entities": []}, {"text": "We employ early stopping to terminate the training run if the validation error increases consistently.", "labels": [], "entities": []}, {"text": "We use a maximum of 40 epochs to train each network.", "labels": [], "entities": []}, {"text": "The batch sizes used were kept constant at 128 for sentence level RNNs and 16 for document level RNNs.", "labels": [], "entities": []}, {"text": "We report micro-averaged recall, precision and fscore.", "labels": [], "entities": [{"text": "recall", "start_pos": 25, "end_pos": 31, "type": "METRIC", "confidence": 0.9769240021705627}, {"text": "precision", "start_pos": 33, "end_pos": 42, "type": "METRIC", "confidence": 0.9997239708900452}, {"text": "fscore", "start_pos": 47, "end_pos": 53, "type": "METRIC", "confidence": 0.9962843060493469}]}, {"text": "We use exact phrase matching to calculate the evaluation score for our experiments.", "labels": [], "entities": [{"text": "phrase matching", "start_pos": 13, "end_pos": 28, "type": "TASK", "confidence": 0.6816565543413162}]}, {"text": "Each phrase labeled by the learned models is considered a true positive only if it matches the exact true boundary of the phrase and correctly labels all the words in the phrase.", "labels": [], "entities": []}, {"text": "We use CRFsuite for implementing the CRF tagger.", "labels": [], "entities": []}, {"text": "We use Lasagne to setup the Neural Net framework.", "labels": [], "entities": [{"text": "Neural Net framework", "start_pos": 28, "end_pos": 48, "type": "DATASET", "confidence": 0.7118258476257324}]}, {"text": "Lasagne 1 is a machine learning library focused towards neural networks that is build on top of Theano ().", "labels": [], "entities": [{"text": "Theano", "start_pos": 96, "end_pos": 102, "type": "DATASET", "confidence": 0.9111550450325012}]}, {"text": "shows the micro averaged scores for each method.", "labels": [], "entities": []}, {"text": "All RNN models significantly outperform the baseline (CRF-context).", "labels": [], "entities": []}, {"text": "Compared to the baseline system, our best system (GRU-document) improved the recall (0.8126), precision (0.7938) and Fscore (0.8031) by 19% , 2% and 11 % respectively.", "labels": [], "entities": [{"text": "GRU-document", "start_pos": 50, "end_pos": 62, "type": "METRIC", "confidence": 0.6105265617370605}, {"text": "recall", "start_pos": 77, "end_pos": 83, "type": "METRIC", "confidence": 0.9997966885566711}, {"text": "precision", "start_pos": 94, "end_pos": 103, "type": "METRIC", "confidence": 0.9988449811935425}, {"text": "Fscore (0.8031)", "start_pos": 117, "end_pos": 132, "type": "METRIC", "confidence": 0.9579479098320007}]}, {"text": "Clearly the improvement in recall contributes more to the overall increase in system performance.", "labels": [], "entities": [{"text": "recall", "start_pos": 27, "end_pos": 33, "type": "METRIC", "confidence": 0.99965500831604}]}, {"text": "The performance of different RNN models is almost similar, except for the GRU model which exhibits an Fscore improvement of at least one percentage point over the rest.", "labels": [], "entities": [{"text": "GRU", "start_pos": 74, "end_pos": 77, "type": "DATASET", "confidence": 0.7617520093917847}, {"text": "Fscore", "start_pos": 102, "end_pos": 108, "type": "METRIC", "confidence": 0.9996850490570068}]}], "tableCaptions": [{"text": " Table 1: Annotation statistics for the corpus.", "labels": [], "entities": []}, {"text": " Table 2: Cross validated micro-average of Precision, Recall and", "labels": [], "entities": [{"text": "Precision", "start_pos": 43, "end_pos": 52, "type": "METRIC", "confidence": 0.9873623847961426}, {"text": "Recall", "start_pos": 54, "end_pos": 60, "type": "METRIC", "confidence": 0.9924057126045227}]}]}