{"title": [{"text": "Black Holes and White Rabbits: Metaphor Identification with Visual Features", "labels": [], "entities": [{"text": "Metaphor Identification", "start_pos": 31, "end_pos": 54, "type": "TASK", "confidence": 0.6793172806501389}]}], "abstractContent": [{"text": "Metaphor is pervasive in our communication, which makes it an important problem for natural language processing (NLP).", "labels": [], "entities": [{"text": "natural language processing (NLP)", "start_pos": 84, "end_pos": 117, "type": "TASK", "confidence": 0.8051880896091461}]}, {"text": "Numerous approaches to metaphor processing have thus been proposed, all of which relied on linguistic features and textual data to construct their models.", "labels": [], "entities": [{"text": "metaphor processing", "start_pos": 23, "end_pos": 42, "type": "TASK", "confidence": 0.9448258578777313}]}, {"text": "Human metaphor comprehension is, however, known to rely on both our linguistic and perceptual experience, and vision can play a particularly important role when metaphorically projecting imagery across domains.", "labels": [], "entities": []}, {"text": "In this paper, we present the first metaphor identification method that simultaneously draws knowledge from linguistic and visual data.", "labels": [], "entities": [{"text": "metaphor identification", "start_pos": 36, "end_pos": 59, "type": "TASK", "confidence": 0.7786220610141754}]}, {"text": "Our results demonstrate that it outperforms linguistic and visual models in isolation, as well as being competitive with the best-performing metaphor identification methods, that rely on hand-crafted knowledge about domains and perception.", "labels": [], "entities": [{"text": "metaphor identification", "start_pos": 141, "end_pos": 164, "type": "TASK", "confidence": 0.7772904634475708}]}], "introductionContent": [{"text": "Metaphor lends vividness, sophistication and clarity to our thought and communication.", "labels": [], "entities": [{"text": "clarity", "start_pos": 45, "end_pos": 52, "type": "METRIC", "confidence": 0.9810075163841248}]}, {"text": "At the same time, it plays a fundamental structural role in our cognition, helping us to organise and project knowledge ().", "labels": [], "entities": []}, {"text": "Metaphors arise due to systematic associations between distinct, and seemingly unrelated, concepts.", "labels": [], "entities": []}, {"text": "For instance, when we talk about \"the turning wheels of apolitical regime\", \"rebuilding the campaign machinery\" or \"mending foreign policy\", we view politics and political systems in terms of mechanisms, they can function, break, be mended etc.", "labels": [], "entities": []}, {"text": "The existence of this association allows us to transfer knowledge and imagery from the domain of mechanisms (the source domain) to that of political systems (the target domain).", "labels": [], "entities": []}, {"text": "According to, such metaphorical mappings, or conceptual metaphors, form the basis of metaphorical language.", "labels": [], "entities": []}, {"text": "Metaphor is pervasive in our communication, which makes it important for NLP applications dealing with real-world text.", "labels": [], "entities": []}, {"text": "A number of approaches to metaphor processing have thus been proposed, using supervised classification), clustering, vector space models (), lexical resources () and web search with lexicosyntactic patterns.", "labels": [], "entities": [{"text": "metaphor processing", "start_pos": 26, "end_pos": 45, "type": "TASK", "confidence": 0.9238544404506683}]}, {"text": "So far, these and other metaphor processing works relied on textual data to construct their models.", "labels": [], "entities": []}, {"text": "Yet, several experiments indicated that perceptual properties of concepts, such as concreteness and imageability, are important features for metaphor identification).", "labels": [], "entities": [{"text": "metaphor identification", "start_pos": 141, "end_pos": 164, "type": "TASK", "confidence": 0.8495332300662994}]}, {"text": "However, all of these methods used manually-annotated linguistic resources to determine these properties (such as the MRC concreteness database).", "labels": [], "entities": [{"text": "MRC concreteness", "start_pos": 118, "end_pos": 134, "type": "TASK", "confidence": 0.7449574172496796}]}, {"text": "To the best of our knowledge, there has not yet been a metaphor processing method that employed information learned from both linguistic and visual data.", "labels": [], "entities": [{"text": "metaphor processing", "start_pos": 55, "end_pos": 74, "type": "TASK", "confidence": 0.8678265511989594}]}, {"text": "Ample re-search in cognitive science suggests that human meaning representations are not merely a product of our linguistic exposure, but are also grounded in our perceptual system and sensori-motor experience (.", "labels": [], "entities": []}, {"text": "Semantic models integrating information from multiple modalities have been shown successful in tasks such as modeling semantic similarity and relatedness), lexical entailment (), compositionality) and bilingual lexicon induction ().", "labels": [], "entities": [{"text": "bilingual lexicon induction", "start_pos": 201, "end_pos": 228, "type": "TASK", "confidence": 0.6706378857294718}]}, {"text": "Using visual information is particularly relevant to modelling metaphor, where imagery is ported across domains.", "labels": [], "entities": [{"text": "modelling metaphor", "start_pos": 53, "end_pos": 71, "type": "TASK", "confidence": 0.9425551891326904}]}, {"text": "In this paper, we present the first metaphor identification method integrating meaning representations learned from linguistic and visual data.", "labels": [], "entities": [{"text": "metaphor identification", "start_pos": 36, "end_pos": 59, "type": "TASK", "confidence": 0.7605573832988739}]}, {"text": "We construct our representations using a skip-gram model of trained on textual data to obtain linguistic embeddings and a deep convolutional neural network) trained on image data to obtain visual embeddings.", "labels": [], "entities": []}, {"text": "Linguistic word embeddings have been previously successfully used to answer analogy questions (.", "labels": [], "entities": []}, {"text": "These works have shown that such representations capture the nuances of word meaning needed to recognise relational similarity (e.g. between pairs \"king : queen\" and \"man : woman\"), quantified by the respective vector offsets (king -queen \u2248 man -woman).", "labels": [], "entities": []}, {"text": "In our experiments, we investigate how well these representations can capture information about source and target domains and their interaction in a metaphor.", "labels": [], "entities": []}, {"text": "We then enrich these representations with visual information.", "labels": [], "entities": []}, {"text": "We first acquire linguistic and visual embeddings for individual words and then extend the methods to learn embeddings for longer phrases.", "labels": [], "entities": []}, {"text": "The focus of our experiments is on metaphorical expressions in verb-subject, verb-direct object and adjectival modifier-noun constructions.", "labels": [], "entities": []}, {"text": "We thus learn embeddings for verbs, adjectives, nouns, as well as verb-noun and adjective-noun phrases.", "labels": [], "entities": []}, {"text": "We then use a set of arithmetic operations on word and phrase embedding vectors to classify phrases as literal or metaphorical.", "labels": [], "entities": []}, {"text": "To the best of our knowledge, our approach is also the first one to apply word or phrase embeddings to the task of metaphor identification.", "labels": [], "entities": [{"text": "metaphor identification", "start_pos": 115, "end_pos": 138, "type": "TASK", "confidence": 0.8514893651008606}]}, {"text": "Our results demonstrate that the joint model incorporating linguistic and visual representations outperforms the linguistic model in isolation, as well as being competitive with the best-performing metaphor identification methods that rely on hand-crafted information about domains, concreteness and imageability. is notable as they focused on compositional rather than categorical features.", "labels": [], "entities": []}, {"text": "They trained an SVM with dependency-tree kernels to capture compositional information, using lexical, part-of-speech tag and WordNet supersense representations of sentence trees.", "labels": [], "entities": []}, {"text": "aimed at modelling conceptual information.", "labels": [], "entities": []}, {"text": "They derived semantic signatures of texts as sets of highly-related and interlinked WordNet synsets.", "labels": [], "entities": []}, {"text": "The semantic signatures served as features to train a set of classifiers (maximum entropy, decision trees, SVM, random forest) that map new metaphors to the semantic signatures of the known ones.", "labels": [], "entities": []}, {"text": "hypothesized that metaphor is commonly used to describe abstract concepts in terms of more concrete or physical experiences.", "labels": [], "entities": []}, {"text": "Thus, Turney and colleagues expected that there would be some discrepancy in the level of concrete-ness of source and target terms in the metaphor.", "labels": [], "entities": []}, {"text": "They developed a method to automatically measure concreteness of words and applied it to identify verbal and adjectival metaphors. and followed in Turney's steps, extending the models by incorporating information about selectional preferences. and focused on modeling topical structure of text to identify metaphor.", "labels": [], "entities": []}, {"text": "Their main hypothesis was that metaphorical language (coming from a different domain) would represent atypical vocabulary within the topical structure of the text.", "labels": [], "entities": []}, {"text": "acquired a set of topic chains by linking semantically related words in a given text.", "labels": [], "entities": []}, {"text": "They then looked for vocabulary outside the topic chain and yet connected to topic chain words via syntactic dependencies and exhibiting high imageability.", "labels": [], "entities": []}, {"text": "used LDA topic modelling to identify sets of source and target domain vocabulary.", "labels": [], "entities": [{"text": "LDA topic modelling", "start_pos": 5, "end_pos": 24, "type": "TASK", "confidence": 0.6436959107716879}]}, {"text": "In their system, the acquired topics represented source and target domains, and sentences containing vocabulary from both were tagged as metaphorical.", "labels": [], "entities": []}], "datasetContent": [{"text": "We evaluate our method using two datasets manually annotated for metaphoricity: created a large dataset of adjective-noun pairs that they annotated for metaphoricity.", "labels": [], "entities": []}, {"text": "Starting with a 1000 frequent adjectives, they extracted nouns they co-occur within TenTen Web Corpus 4 using SketchEngine and in collections of metaphor on the Web.", "labels": [], "entities": [{"text": "TenTen Web Corpus 4", "start_pos": 84, "end_pos": 103, "type": "DATASET", "confidence": 0.9475888758897781}]}, {"text": "Tsvetkov et al. divided the data into a training set (containing 884 literal and 884 metaphorical pairs) and test set (111 literal and 111 metaphorical pairs).", "labels": [], "entities": []}, {"text": "We will refer to their training set as TSV-TRAIN and to the test set as TSV-TEST.", "labels": [], "entities": [{"text": "TSV-TRAIN", "start_pos": 39, "end_pos": 48, "type": "METRIC", "confidence": 0.7767757773399353}, {"text": "TSV-TEST", "start_pos": 72, "end_pos": 80, "type": "DATASET", "confidence": 0.49327099323272705}]}, {"text": "The test set was annotated for metaphoricity by 5 annotators with an inter-annotator agreement of \u03ba = 0.76.", "labels": [], "entities": []}, {"text": "shows a portion of the anno-  tated test set.", "labels": [], "entities": [{"text": "anno-  tated test set", "start_pos": 23, "end_pos": 44, "type": "DATASET", "confidence": 0.5804541885852814}]}, {"text": "Metaphorical phrases that depend on wider context for their interpretation (e.g. drowning students) were removed.", "labels": [], "entities": []}, {"text": "The training set was annotated by one annotator only, and it is thus likely that the annotations are less reliable than those in the test set.", "labels": [], "entities": []}, {"text": "We thus evaluate our methods on Tsvetkov et al.'s test set (TSV-TEST).", "labels": [], "entities": [{"text": "Tsvetkov et al.'s test set", "start_pos": 32, "end_pos": 58, "type": "DATASET", "confidence": 0.681202096598489}, {"text": "TSV-TEST", "start_pos": 60, "end_pos": 68, "type": "METRIC", "confidence": 0.4066920578479767}]}, {"text": "However, we will also report results on TSV-TRAIN to confirm whether the observed trends hold in a larger, though likely noisier, dataset.", "labels": [], "entities": [{"text": "TSV-TRAIN", "start_pos": 40, "end_pos": 49, "type": "DATASET", "confidence": 0.46544551849365234}]}, {"text": "We selected the above two datasets since they include examples for different senses (both metaphorical and literal) of the same verbs or adjectives.", "labels": [], "entities": []}, {"text": "This allows us to test the extent to which our model is able to discriminate between different word senses, as opposed to merely selecting the most frequent class fora given word.", "labels": [], "entities": []}, {"text": "We divided the verb-and adjective-noun datasets into development and test sets.", "labels": [], "entities": []}, {"text": "The verb-noun development set contained 80 instances from MOH (40 literal and 40 metaphorical), leaving us with the test set of 567 verb-noun pairs from MOH.", "labels": [], "entities": [{"text": "MOH", "start_pos": 58, "end_pos": 61, "type": "DATASET", "confidence": 0.9313674569129944}, {"text": "MOH", "start_pos": 153, "end_pos": 156, "type": "DATASET", "confidence": 0.9221326112747192}]}, {"text": "We created the adjective-noun development set using 80 adjective-noun pairs (40 literal and 40 metaphorical) from TSV-TRAIN, leaving all of the 222 adjectivenoun pairs in TSV-TEST for evaluation.", "labels": [], "entities": [{"text": "TSV-TRAIN", "start_pos": 114, "end_pos": 123, "type": "DATASET", "confidence": 0.8506230711936951}, {"text": "TSV-TEST", "start_pos": 171, "end_pos": 179, "type": "DATASET", "confidence": 0.8569439649581909}]}, {"text": "Ina separate experiment, we also applied our methods to the remainder of TSV-TRAIN (1688 adjective-noun pairs) to evaluate our system on a larger adjective dataset.", "labels": [], "entities": [{"text": "TSV-TRAIN", "start_pos": 73, "end_pos": 82, "type": "DATASET", "confidence": 0.6194243431091309}]}, {"text": "We used the development sets to determine an op- timal threshold value for each of our scoring methods.", "labels": [], "entities": []}, {"text": "The thresholds for verb-noun and adjectivenoun phrases were optimized independently using the corresponding development sets.", "labels": [], "entities": []}, {"text": "We experimented with the three phrase-level scoring methods on the development sets, and found that PHRAS-COS1 consistently outperformed PHRASCOS2 and PHRASCOS3 for both verb-noun and adjectivenoun phrases.", "labels": [], "entities": [{"text": "PHRAS-COS1", "start_pos": 100, "end_pos": 110, "type": "METRIC", "confidence": 0.8038765788078308}]}, {"text": "We thus report results for PHRAS-COS1 on our test sets.", "labels": [], "entities": [{"text": "PHRAS-COS1", "start_pos": 27, "end_pos": 37, "type": "DATASET", "confidence": 0.627221405506134}]}, {"text": "We first evaluated the performance of WORDCOS and PHRASCOS1 using linguistic and visual representations in isolation, and then evaluated the multimodal models using middle and late fusion strategies.", "labels": [], "entities": []}, {"text": "In middle fusion, we concatenated the linguistic and visual vectors, and then applied WORDCOS and PHRASCOS1 methods to the resulting multimodal vectors.", "labels": [], "entities": [{"text": "WORDCOS", "start_pos": 86, "end_pos": 93, "type": "METRIC", "confidence": 0.896312952041626}, {"text": "PHRASCOS1", "start_pos": 98, "end_pos": 107, "type": "METRIC", "confidence": 0.9555650949478149}]}, {"text": "We will refer to these methods as WORDMID and PHRASMID respectively.", "labels": [], "entities": [{"text": "WORDMID", "start_pos": 34, "end_pos": 41, "type": "METRIC", "confidence": 0.7857113480567932}, {"text": "PHRASMID", "start_pos": 46, "end_pos": 54, "type": "METRIC", "confidence": 0.9532181024551392}]}, {"text": "In late fusion, we used an average of linguistic and visual scores to determine metaphoricity.", "labels": [], "entities": []}, {"text": "We experimented with three different scoring methods: (1) WORDLATE, where linguistic and visual WORD-COS scores were combined; (2) PHRASLATE, where linguistic and visual PHRASCOS1 scores were combined; and (3) MIXLATE, where linguistic and WORDCOS and visual PHRASCOS1 scores were combined.", "labels": [], "entities": [{"text": "PHRASLATE", "start_pos": 131, "end_pos": 140, "type": "METRIC", "confidence": 0.9716169238090515}, {"text": "MIXLATE", "start_pos": 210, "end_pos": 217, "type": "METRIC", "confidence": 0.571912407875061}]}], "tableCaptions": [{"text": " Table 1: System performance on Mohammad et al. dataset", "labels": [], "entities": [{"text": "Mohammad et al. dataset", "start_pos": 32, "end_pos": 55, "type": "DATASET", "confidence": 0.8730473220348358}]}, {"text": " Table 2: System performance on Tsvetkov et al. test set (TSV-", "labels": [], "entities": [{"text": "Tsvetkov et al. test set", "start_pos": 32, "end_pos": 56, "type": "DATASET", "confidence": 0.6641647815704346}]}]}