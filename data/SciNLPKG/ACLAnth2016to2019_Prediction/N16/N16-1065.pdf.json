{"title": [{"text": "Combining Recurrent and Convolutional Neural Networks for Relation Classification", "labels": [], "entities": []}], "abstractContent": [{"text": "This paper investigates two different neural architectures for the task of relation classification: convolutional neural networks and recurrent neural networks.", "labels": [], "entities": [{"text": "relation classification", "start_pos": 75, "end_pos": 98, "type": "TASK", "confidence": 0.9034222364425659}]}, {"text": "For both models , we demonstrate the effect of different architectural choices.", "labels": [], "entities": []}, {"text": "We present anew context representation for convolutional neural networks for relation classification (extended middle context).", "labels": [], "entities": [{"text": "relation classification", "start_pos": 77, "end_pos": 100, "type": "TASK", "confidence": 0.874941498041153}]}, {"text": "Furthermore, we propose connectionist bi-directional recurrent neural networks and introduce ranking loss for their optimization.", "labels": [], "entities": []}, {"text": "Finally, we show that combining convolutional and recurrent neural networks using a simple voting scheme is accurate enough to improve results.", "labels": [], "entities": []}, {"text": "Our neural models achieve state-of-the-art results on the SemEval 2010 relation classification task.", "labels": [], "entities": [{"text": "SemEval 2010 relation classification task", "start_pos": 58, "end_pos": 99, "type": "TASK", "confidence": 0.8317848443984985}]}], "introductionContent": [{"text": "Relation classification is the task of assigning sentences with two marked entities to a predefined set of relations.", "labels": [], "entities": [{"text": "Relation classification", "start_pos": 0, "end_pos": 23, "type": "TASK", "confidence": 0.9681271314620972}]}, {"text": "The sentence \"We poured the <e1>milk</e1> into the <e2>pumpkin mixture</e2>.\", for example, expresses the relation Entity-Destination(e1,e2).", "labels": [], "entities": []}, {"text": "While early research mostly focused on support vector machines or maximum entropy classifiers (, recent research showed performance improvements by applying neural networks (NNs)) on the benchmark data from SemEval 2010 shared task 8 () . This study investigates two different types of NNs: recurrent neural networks (RNNs) and convolutional neural networks (CNNs) as well as their combination.", "labels": [], "entities": [{"text": "SemEval 2010 shared task 8", "start_pos": 207, "end_pos": 233, "type": "TASK", "confidence": 0.5306042850017547}]}, {"text": "We make the following contributions: (1) We propose extended middle context, anew context representation for CNNs for relation classification.", "labels": [], "entities": [{"text": "relation classification", "start_pos": 118, "end_pos": 141, "type": "TASK", "confidence": 0.9005080759525299}]}, {"text": "The extended middle context uses all parts of the sentence (the relation arguments, left of the relation arguments, between the arguments, right of the arguments) and pays special attention to the middle part.", "labels": [], "entities": []}, {"text": "(2) We present connectionist bi-directional RNN models which are especially suited for sentence classification tasks since they combine all intermediate hidden layers for their final decision.", "labels": [], "entities": [{"text": "sentence classification tasks", "start_pos": 87, "end_pos": 116, "type": "TASK", "confidence": 0.8277607361475626}]}, {"text": "Furthermore, the ranking loss function is introduced for the RNN model optimization which has not been investigated in the literature for relation classification before.", "labels": [], "entities": [{"text": "RNN model optimization", "start_pos": 61, "end_pos": 83, "type": "TASK", "confidence": 0.7477384606997172}, {"text": "relation classification", "start_pos": 138, "end_pos": 161, "type": "TASK", "confidence": 0.9560433030128479}]}, {"text": "(3) Finally, we combine CNNs and RNNs using a simple voting scheme and achieve new state-of-theart results on the SemEval 2010 benchmark dataset.", "labels": [], "entities": [{"text": "SemEval 2010 benchmark dataset", "start_pos": 114, "end_pos": 144, "type": "DATASET", "confidence": 0.8690398186445236}]}], "datasetContent": [{"text": "We used the relation classification dataset of the SemEval 2010 task 8 (.", "labels": [], "entities": [{"text": "relation classification", "start_pos": 12, "end_pos": 35, "type": "TASK", "confidence": 0.8427076041698456}, {"text": "SemEval 2010 task 8", "start_pos": 51, "end_pos": 70, "type": "TASK", "confidence": 0.7081969827413559}]}, {"text": "It consists of sentences which have been manually labeled with 19 relations (9 directed relations and one artificial class Other).", "labels": [], "entities": []}, {"text": "8,000 sentences have been distributed as training set and 2,717 sentences served as test set.", "labels": [], "entities": []}, {"text": "For evaluation, we applied the official scoring script and report the macro F1 score which also served as the official result of the shared task.", "labels": [], "entities": [{"text": "F1 score", "start_pos": 76, "end_pos": 84, "type": "METRIC", "confidence": 0.9277690052986145}]}, {"text": "RNN and CNN models were implemented with theano (.", "labels": [], "entities": [{"text": "RNN", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.886656641960144}]}, {"text": "For all our models, we use L2 regularization with a weight of 0.0001.", "labels": [], "entities": []}, {"text": "For CNN training, we use mini batches of 25 training examples while we perform stochastic gradient descent for the RNN.", "labels": [], "entities": [{"text": "CNN training", "start_pos": 4, "end_pos": 16, "type": "TASK", "confidence": 0.9057006239891052}, {"text": "RNN", "start_pos": 115, "end_pos": 118, "type": "DATASET", "confidence": 0.8053778409957886}]}, {"text": "The initial learning rates are 0.2 for the CNN and 0.01 for the RNN.", "labels": [], "entities": [{"text": "CNN", "start_pos": 43, "end_pos": 46, "type": "DATASET", "confidence": 0.913783073425293}, {"text": "RNN", "start_pos": 64, "end_pos": 67, "type": "DATASET", "confidence": 0.8994481563568115}]}, {"text": "We train the models for 10 (CNN) and 50 (RNN) epochs without early stopping.", "labels": [], "entities": [{"text": "RNN) epochs", "start_pos": 41, "end_pos": 52, "type": "DATASET", "confidence": 0.7676241795221964}]}, {"text": "As activation function, we apply tanh for the CNN and capped ReLU for the RNN.", "labels": [], "entities": [{"text": "ReLU", "start_pos": 61, "end_pos": 65, "type": "METRIC", "confidence": 0.9461279511451721}, {"text": "RNN", "start_pos": 74, "end_pos": 77, "type": "DATASET", "confidence": 0.8790216445922852}]}, {"text": "For tuning the hyperparameters, we split the training data into two parts: 6.5k (training) and 1.5k (development) sentences.", "labels": [], "entities": []}, {"text": "We also tuned the learning rate schedule on dev.", "labels": [], "entities": []}, {"text": "Beside of training single models, we also report ensemble results for which we combined the presented single models with a voting process.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: F1 score of CNN and its components, * indicates", "labels": [], "entities": [{"text": "F1 score", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9770035743713379}]}, {"text": " Table 2: F1 score of RNN and its components, * indicates", "labels": [], "entities": [{"text": "F1 score", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.976702094078064}, {"text": "RNN", "start_pos": 22, "end_pos": 25, "type": "DATASET", "confidence": 0.8583422303199768}]}, {"text": " Table 3: State-of-the-art results for relation classification", "labels": [], "entities": [{"text": "relation classification", "start_pos": 39, "end_pos": 62, "type": "TASK", "confidence": 0.9806367456912994}]}]}