{"title": [{"text": "The Instantiation Discourse Relation: A Corpus Analysis of Its Properties and Improved Detection", "labels": [], "entities": [{"text": "Instantiation Discourse Relation", "start_pos": 4, "end_pos": 36, "type": "TASK", "confidence": 0.6518485645453135}]}], "abstractContent": [{"text": "INSTANTIATION is a fairly common discourse relation and past work has suggested that it plays special roles in local coherence, in sentiment expression and in content selection in summarization.", "labels": [], "entities": [{"text": "INSTANTIATION", "start_pos": 0, "end_pos": 13, "type": "METRIC", "confidence": 0.47648581862449646}, {"text": "sentiment expression", "start_pos": 131, "end_pos": 151, "type": "TASK", "confidence": 0.8171816766262054}, {"text": "summarization", "start_pos": 180, "end_pos": 193, "type": "TASK", "confidence": 0.9256372451782227}]}, {"text": "In this paper we provide the first systematic corpus analysis of the relation and show that relation-specific features can improve considerably the detection of the relation.", "labels": [], "entities": []}, {"text": "We show that sentences involved in INSTANTIATION are set apart from other sentences by the use of gradable (subjec-tive) adjectives, the occurrence of rare words and by different patterns in part-of-speech usage.", "labels": [], "entities": [{"text": "INSTANTIATION", "start_pos": 35, "end_pos": 48, "type": "TASK", "confidence": 0.8835437297821045}]}, {"text": "Words across arguments of INSTANTI-ATION are connected through hypernym and meronym relations significantly more often than in other sentences and that they standout in context by being significantly less similar to each other than other adjacent sentence pairs.", "labels": [], "entities": []}, {"text": "These factors provide substantial pre-dictive power that improves the identification of implicit INSTANTIATION relation by more than 5% F-measure.", "labels": [], "entities": [{"text": "INSTANTIATION", "start_pos": 97, "end_pos": 110, "type": "METRIC", "confidence": 0.6436638236045837}, {"text": "F-measure", "start_pos": 136, "end_pos": 145, "type": "METRIC", "confidence": 0.9950460195541382}]}], "introductionContent": [{"text": "In an INSTANTIATION relation, one text span explains in further detail the events, reasons, behaviors and attitudes mentioned in the other ( , as illustrated by the segments below: [a] Other fundamental \"reforms\" of the 1986 act have been threatened as well.", "labels": [], "entities": [{"text": "INSTANTIATION", "start_pos": 6, "end_pos": 19, "type": "METRIC", "confidence": 0.7523376941680908}]}, {"text": "[b] The House seriously considered raising the top tax rate paid by individuals with the highest incomes.", "labels": [], "entities": []}, {"text": "Sentence mentions \"other reforms\" and a threat to them, but leaves unspecified what are the reforms or how they are threatened.", "labels": [], "entities": []}, {"text": "provides sufficient detail for the reader to infer more concretely what has happened.", "labels": [], "entities": [{"text": "detail", "start_pos": 20, "end_pos": 26, "type": "METRIC", "confidence": 0.965293824672699}]}, {"text": "The INSTANTIATION relation has some special properties.", "labels": [], "entities": [{"text": "INSTANTIATION", "start_pos": 4, "end_pos": 17, "type": "METRIC", "confidence": 0.5087693929672241}]}, {"text": "A study of discourse relations as indicators for content selection in single document summarization revealed that the first sentences from INSTANTIATION pairs are included inhuman summaries significantly more often than other sentences (  and that being a first sentence in an INSTANTIATION relation is the most powerful indicator for content selection related to discourse relation sense.", "labels": [], "entities": [{"text": "content selection in single document summarization", "start_pos": 49, "end_pos": 99, "type": "TASK", "confidence": 0.6086792896191279}]}, {"text": "The sentences between which the relation holds also contain more sentiment expressions than other sentences (, making it a special target for sentiment analysis applications.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 142, "end_pos": 160, "type": "TASK", "confidence": 0.928943008184433}]}, {"text": "Moreover, INSTANTIATION relations appear to play a special role in local coherence , as the flow between IN-STANTIATION sentences is not explained by the major coherence theories).", "labels": [], "entities": []}, {"text": "Many of the sentences in INSTANTIATION relation contain entity instantiations (complex examples of set-instance anaphora), such as \"several EU countries\"-\"the UK\", \"footballers\"-\"Wayne Rooney\" and \"most cosmetic purchase\"-\"lipstick\" (, raising further questions about the relationship between INSTANTIA-TIONS and key discourse phenomena.", "labels": [], "entities": [{"text": "INSTANTIATION relation contain entity instantiations", "start_pos": 25, "end_pos": 77, "type": "TASK", "confidence": 0.6390557527542114}]}, {"text": "Detecting an INSTANTIATION, however, is hard.", "labels": [], "entities": [{"text": "Detecting", "start_pos": 0, "end_pos": 9, "type": "TASK", "confidence": 0.9623973965644836}, {"text": "INSTANTIATION", "start_pos": 13, "end_pos": 26, "type": "METRIC", "confidence": 0.6644474864006042}]}, {"text": "In the Penn Discourse Treebank (PDTB) (, INSTANTIATION is one of the few relations that are more often implicit, i.e., expressed without a discourse marker such as \"for exam-ple\".", "labels": [], "entities": [{"text": "Penn Discourse Treebank (PDTB)", "start_pos": 7, "end_pos": 37, "type": "DATASET", "confidence": 0.9556555449962616}, {"text": "INSTANTIATION", "start_pos": 41, "end_pos": 54, "type": "METRIC", "confidence": 0.9943104982376099}]}, {"text": "Identifying implicit discourse relation is an acknowledged difficult task (), but the challenge is exacerbated due to the lack of explicit INSTANTIATIONs: explicit relations are shown to improve their implicit counterparts using data source expansion.", "labels": [], "entities": []}, {"text": "Moreover, detecting INSTANTIATION also involves the skewed class distribution problem ( because although it is one of the largest class of implicit relations, it constitutes less than 10% of all the implicit relations annotated in the PDTB.", "labels": [], "entities": [{"text": "detecting INSTANTIATION", "start_pos": 10, "end_pos": 33, "type": "TASK", "confidence": 0.7413504719734192}, {"text": "PDTB", "start_pos": 235, "end_pos": 239, "type": "DATASET", "confidence": 0.950306236743927}]}, {"text": "In this work, we identify a rich set of factors that sets apart each sentence in an implicit INSTAN-TIATION and the pair as a whole.", "labels": [], "entities": []}, {"text": "We show that these factors improve the identification of implicit INSTANTIATION by at least 5% in F-measure and 8% in balanced accuracy compared to prior systems.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 98, "end_pos": 107, "type": "METRIC", "confidence": 0.989531397819519}, {"text": "accuracy", "start_pos": 127, "end_pos": 135, "type": "METRIC", "confidence": 0.9343620538711548}]}], "datasetContent": [{"text": "In this section, we demonstrate the benefit of exploiting INSTANTIATION characteristics in the identification of the relation.", "labels": [], "entities": [{"text": "INSTANTIATION", "start_pos": 58, "end_pos": 71, "type": "METRIC", "confidence": 0.824354887008667}]}, {"text": "Following prior work that identifies the more detailed (second-level) relations in the PDTB (), we use sections 2-21 as training, section 23 as testing.", "labels": [], "entities": [{"text": "PDTB", "start_pos": 87, "end_pos": 91, "type": "DATASET", "confidence": 0.8871338367462158}]}, {"text": "The rest of the corpus is used for development.", "labels": [], "entities": []}, {"text": "The task is to predict if an implicit INSTANTIATION relation holds between pairs of adjacent sentences in the same paragraph.", "labels": [], "entities": []}, {"text": "Sentence pairs with INSTANTI-ATION relation constitute the positive class; all other non-explicit relations 3 constitute the negative class.", "labels": [], "entities": [{"text": "INSTANTI-ATION", "start_pos": 20, "end_pos": 34, "type": "METRIC", "confidence": 0.8748658299446106}]}, {"text": "We use Logistic Regression with class weights inversely proportional to the size of each class.", "labels": [], "entities": [{"text": "Regression", "start_pos": 16, "end_pos": 26, "type": "METRIC", "confidence": 0.5740611553192139}]}, {"text": "The factors discussed in \u00a7 3 are adopted as the only features in the classifier.", "labels": [], "entities": []}, {"text": "We use the average values of s 1 and s 2 and their difference for: the number of words, difference in number of words compared to the sentence before s 1 , the percentage of OOVs, gradable adjectives, POS tags and Jaccard similarity to immediate context.", "labels": [], "entities": [{"text": "OOVs", "start_pos": 174, "end_pos": 178, "type": "METRIC", "confidence": 0.8450905680656433}]}, {"text": "We use the minimum, maximum and average differences in wordpair unigram log probability, and average Jaccard similarity across sentence pairs.", "labels": [], "entities": [{"text": "wordpair unigram log probability", "start_pos": 55, "end_pos": 87, "type": "METRIC", "confidence": 0.5820350870490074}]}, {"text": "For Wordnet relations, we use binary features indicating the presence of a relation.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Average # words. [ * ]: significant (p < 0.05) com-", "labels": [], "entities": []}, {"text": " Table 2: Average % of rare words per sentence. [ * ]: significant", "labels": [], "entities": []}, {"text": " Table 3: Average % of gradable adjectives per sentence. [ * ]:", "labels": [], "entities": []}, {"text": " Table 4: POS tags significantly different in percentage com-", "labels": [], "entities": []}, {"text": " Table 5: Percentage of sentence pairs with Wordnet relation-", "labels": [], "entities": []}, {"text": " Table 6: Average Jaccard similarity of an adjacent sentence pair", "labels": [], "entities": [{"text": "Average Jaccard similarity", "start_pos": 10, "end_pos": 36, "type": "METRIC", "confidence": 0.8440067370732626}]}, {"text": " Table 7: Precision, recall, F-measure and balanced accuracy of", "labels": [], "entities": [{"text": "Precision", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9984890222549438}, {"text": "recall", "start_pos": 21, "end_pos": 27, "type": "METRIC", "confidence": 0.9997206330299377}, {"text": "F-measure", "start_pos": 29, "end_pos": 38, "type": "METRIC", "confidence": 0.9989169836044312}, {"text": "accuracy", "start_pos": 52, "end_pos": 60, "type": "METRIC", "confidence": 0.9677541255950928}]}, {"text": " Table 8: Relations involved in false positives, \u2265 10% for least", "labels": [], "entities": []}]}