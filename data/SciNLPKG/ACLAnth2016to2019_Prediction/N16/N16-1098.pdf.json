{"title": [{"text": "A Corpus and Cloze Evaluation for Deeper Understanding of Commonsense Stories", "labels": [], "entities": []}], "abstractContent": [{"text": "Representation and learning of commonsense knowledge is one of the foundational problems in the quest to enable deep language understanding.", "labels": [], "entities": [{"text": "deep language understanding", "start_pos": 112, "end_pos": 139, "type": "TASK", "confidence": 0.6594063937664032}]}, {"text": "This issue is particularly challenging for understanding casual and corre-lational relationships between events.", "labels": [], "entities": []}, {"text": "While this topic has received a lot of interest in the NLP community, research has been hindered by the lack of a proper evaluation framework.", "labels": [], "entities": []}, {"text": "This paper attempts to address this problem with anew framework for evaluating story understanding and script learning: the 'Story Cloze Test'.", "labels": [], "entities": [{"text": "story understanding", "start_pos": 79, "end_pos": 98, "type": "TASK", "confidence": 0.8305636644363403}, {"text": "script learning", "start_pos": 103, "end_pos": 118, "type": "TASK", "confidence": 0.8043093681335449}]}, {"text": "This test requires a system to choose the correct ending to a four-sentence story.", "labels": [], "entities": []}, {"text": "We created anew corpus of 50k five-sentence commonsense stories, ROCSto-ries, to enable this evaluation.", "labels": [], "entities": []}, {"text": "This corpus is unique in two ways: (1) it captures a rich set of causal and temporal commonsense relations between daily events, and (2) it is a high quality collection of everyday life stories that can also be used for story generation.", "labels": [], "entities": [{"text": "story generation", "start_pos": 220, "end_pos": 236, "type": "TASK", "confidence": 0.7809901237487793}]}, {"text": "Experimental evaluation shows that a host of baselines and state-of-the-art models based on shallow language understanding struggle to achieve a high score on the Story Cloze Test.", "labels": [], "entities": [{"text": "Story Cloze Test", "start_pos": 163, "end_pos": 179, "type": "DATASET", "confidence": 0.8807554046312968}]}, {"text": "We discuss these implications for script and story learning , and offer suggestions for deeper language understanding.", "labels": [], "entities": [{"text": "script and story learning", "start_pos": 34, "end_pos": 59, "type": "TASK", "confidence": 0.7690990120172501}]}], "introductionContent": [{"text": "Story understanding is an extremely challenging task in natural language understanding with a longrunning history in AI).", "labels": [], "entities": [{"text": "Story understanding", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.8443381190299988}, {"text": "natural language understanding", "start_pos": 56, "end_pos": 86, "type": "TASK", "confidence": 0.6448114315668741}]}, {"text": "Recently, there has been a renewed interest in story and narrative understanding based on progress made in core NLP tasks.", "labels": [], "entities": [{"text": "story and narrative understanding", "start_pos": 47, "end_pos": 80, "type": "TASK", "confidence": 0.6843841001391411}]}, {"text": "This ranges from generic storytelling models to building systems which can compose meaningful stories in collaboration with humans . Perhaps the biggest challenge of story understanding (and story generation) is having commonsense knowledge for the interpretation of narrative events.", "labels": [], "entities": [{"text": "story understanding", "start_pos": 166, "end_pos": 185, "type": "TASK", "confidence": 0.7135975062847137}, {"text": "story generation", "start_pos": 191, "end_pos": 207, "type": "TASK", "confidence": 0.7462309896945953}]}, {"text": "The question is how to provide commonsense knowledge regarding daily events to machines.", "labels": [], "entities": []}, {"text": "A large body of work in story understanding has focused on learning scripts.", "labels": [], "entities": [{"text": "story understanding", "start_pos": 24, "end_pos": 43, "type": "TASK", "confidence": 0.9047922492027283}]}, {"text": "Scripts represent structured knowledge about stereotypical event sequences together with their participants.", "labels": [], "entities": []}, {"text": "It is evident that various NLP applications (text summarization, co-reference resolution, question answering, etc.) can hugely benefit from the rich inferential capabilities that structured knowledge about events can provide.", "labels": [], "entities": [{"text": "text summarization", "start_pos": 45, "end_pos": 63, "type": "TASK", "confidence": 0.7108705341815948}, {"text": "co-reference resolution", "start_pos": 65, "end_pos": 88, "type": "TASK", "confidence": 0.7188379615545273}, {"text": "question answering", "start_pos": 90, "end_pos": 108, "type": "TASK", "confidence": 0.8432939648628235}]}, {"text": "Given that developing hand-built scripts is extremely timeconsuming, there is a serious need for automatically induced scripts.", "labels": [], "entities": []}, {"text": "Most relevant to this issue is work on unsupervised learning of 'narrative chains' and event schemas.", "labels": [], "entities": []}, {"text": "The first requirement of any learner is to decide on a corpus to drive the learning process.", "labels": [], "entities": []}, {"text": "We are foremost interested in a resource that is full of temporal and causal relations between events because causality is a central component of coherency.", "labels": [], "entities": []}, {"text": "Personal stories from daily weblogs are good sources of commonsense causal information), but teasing out useful information from noisy blog entries is a problem of its own.", "labels": [], "entities": []}, {"text": "Consider the following snippet from ICWSM 2011 Spinn3r Dataset of Weblog entries ( \"I had an interesting day in the studio today.", "labels": [], "entities": [{"text": "ICWSM 2011 Spinn3r Dataset of Weblog entries", "start_pos": 36, "end_pos": 80, "type": "DATASET", "confidence": 0.9300951957702637}]}, {"text": "It was so interesting that I took pictures along the way to describe it to you.", "labels": [], "entities": []}, {"text": "Sometimes I like to read an autobiography/biography to discover how someone got from thereto here.....how they started, how they traveled in mind and spirit, what made them who they are now.", "labels": [], "entities": []}, {"text": "Well, today, my work was a little like that.\"", "labels": [], "entities": []}, {"text": "This text is full of discourse complexities.", "labels": [], "entities": []}, {"text": "A host of challenging language understanding tasks are required to get at the commonsense knowledge embedded within such text snippets.", "labels": [], "entities": [{"text": "language understanding", "start_pos": 22, "end_pos": 44, "type": "TASK", "confidence": 0.726771891117096}]}, {"text": "What is needed is a simplified version of these narratives.", "labels": [], "entities": []}, {"text": "This paper introduces anew corpus of such short commonsense stories.", "labels": [], "entities": []}, {"text": "With careful prompt design and multiple phases of quality control, we collected 50k high quality five-sentence stories that are full of stereotypical causal and temporal relations between events.", "labels": [], "entities": []}, {"text": "The corpus not only serves as a resource for learning commonsense narrative schemas, but is also suitable for training story generation models.", "labels": [], "entities": [{"text": "story generation", "start_pos": 119, "end_pos": 135, "type": "TASK", "confidence": 0.714085727930069}]}, {"text": "We describe this corpus in detail in Section 3.", "labels": [], "entities": []}, {"text": "This new corpus also addresses a problem facing script learning over the past few years.", "labels": [], "entities": []}, {"text": "Despite the attention scripts have received, progress has been inhibited by the lack of a systematic evaluation framework.", "labels": [], "entities": []}, {"text": "A commonly used evaluation is the 'Narrative Cloze Test) in which a system predicts a held-out event (a verb and its arguments) given a set of observed events.", "labels": [], "entities": []}, {"text": "For example, the following is one such test with a missing event: {X threw, pulled X, told X, ???, X completed} 1 . As is often the case, several works now optimize to this specific test, achieving higher scores with shallow techniques.", "labels": [], "entities": []}, {"text": "This is problematic because the models often are not learning commonsense knowledge, but rather how to beat the shallow test.", "labels": [], "entities": []}, {"text": "This paper thus introduces anew evaluation framework called the Story Cloze Test.", "labels": [], "entities": [{"text": "Story Cloze Test", "start_pos": 64, "end_pos": 80, "type": "DATASET", "confidence": 0.7720905145009359}]}, {"text": "Instead of predicting an event, the system is tasked with choosing an entire sentence to complete the given story.", "labels": [], "entities": []}, {"text": "Narrative cloze tests were not meant to be human solvable.", "labels": [], "entities": []}, {"text": "We collected 3,742 doubly verified Story Cloze Test cases.", "labels": [], "entities": [{"text": "Story Cloze Test cases", "start_pos": 35, "end_pos": 57, "type": "DATASET", "confidence": 0.9639912396669388}]}, {"text": "The testis described in detail in Section 4.", "labels": [], "entities": []}, {"text": "Finally, this paper proposes several models, including the most recent state-of-the-art approaches for the narrative cloze test, for tackling the Story Cloze Test.", "labels": [], "entities": [{"text": "Story Cloze Test", "start_pos": 146, "end_pos": 162, "type": "DATASET", "confidence": 0.8571205536524454}]}, {"text": "The results strongly suggest that achieving better than random or constant-choose performance requires richer semantic representation of events together with deeper levels of modeling the semantic space of stories.", "labels": [], "entities": []}, {"text": "We believe that switching to the Story Cloze Test as the empirical evaluation framework for story understanding and script learning can help direct the field to anew direction of deeper language understanding.", "labels": [], "entities": [{"text": "Story Cloze Test", "start_pos": 33, "end_pos": 49, "type": "DATASET", "confidence": 0.7291314601898193}, {"text": "story understanding", "start_pos": 92, "end_pos": 111, "type": "TASK", "confidence": 0.8169240653514862}, {"text": "script learning", "start_pos": 116, "end_pos": 131, "type": "TASK", "confidence": 0.8288584351539612}]}], "datasetContent": [{"text": "As described earlier in the introduction, the common evaluation framework for script learning is the 'Narrative Cloze Test', where a system generates a ranked list of guesses fora missing event, given some observed events.", "labels": [], "entities": [{"text": "script learning", "start_pos": 78, "end_pos": 93, "type": "TASK", "confidence": 0.8684984743595123}]}, {"text": "The original goal of this test was to provide a comparative measure to evaluate narrative knowledge.", "labels": [], "entities": []}, {"text": "However, gradually, the community started optimizing towards the performance on the test itself, achieving higher scores without demonstrating narrative knowledge learning.", "labels": [], "entities": []}, {"text": "For instance, generating the ranked list according to the event's corpus frequency (e.g., always predicting 'X said') was shown to bean extremely strong baseline.", "labels": [], "entities": []}, {"text": "Originally, narrative cloze test chains were extracted by hand and verified as gold chains.", "labels": [], "entities": []}, {"text": "However, the cloze test chains used in all of the most recent works are not human verified as gold.", "labels": [], "entities": []}, {"text": "It is evident that there is a need fora more systematic automatic evaluation framework which is more inline with the original deeper script/story understanding goals.", "labels": [], "entities": []}, {"text": "It is important to note that reordering of temporally shuffled stories (Section 3.3) can serve as a framework to evaluate a system's story understanding.", "labels": [], "entities": []}, {"text": "However, reordering can be achieved to a degree by using various surface features such as adverbials, so this cannot be a foolproof story understanding evaluation framework.", "labels": [], "entities": [{"text": "foolproof story understanding evaluation", "start_pos": 122, "end_pos": 162, "type": "TASK", "confidence": 0.6942943930625916}]}, {"text": "Our ROCStories corpus enables a brand new framework for evaluating story understanding, called the 'Story Cloze Test'.", "labels": [], "entities": [{"text": "ROCStories corpus", "start_pos": 4, "end_pos": 21, "type": "DATASET", "confidence": 0.8097093105316162}, {"text": "story understanding", "start_pos": 67, "end_pos": 86, "type": "TASK", "confidence": 0.7021081000566483}]}], "tableCaptions": [{"text": " Table 2: Crowdsourcing worker statistics.", "labels": [], "entities": []}, {"text": " Table 3: Results from the human temporal shuffling experiment.", "labels": [], "entities": []}, {"text": " Table 5: Statistics for crowd-sourcing Story Cloze  Test instances.", "labels": [], "entities": []}, {"text": " Table 6: The accuracy of various models on The Story Cloze validation and test sets.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 14, "end_pos": 22, "type": "METRIC", "confidence": 0.9996775388717651}, {"text": "The Story Cloze validation and test sets", "start_pos": 44, "end_pos": 84, "type": "DATASET", "confidence": 0.8272018432617188}]}]}