{"title": [{"text": "Automatic tagging and retrieval of E-Commerce products based on visual features", "labels": [], "entities": []}], "abstractContent": [{"text": "This paper proposes an automatic tag assignment approach to various e-commerce products where tag allotment is done solely based on the visual features in the image.", "labels": [], "entities": [{"text": "tag assignment", "start_pos": 33, "end_pos": 47, "type": "TASK", "confidence": 0.6780574172735214}]}, {"text": "It then builds a tag based product retrieval system upon these allotted tags.", "labels": [], "entities": []}, {"text": "The explosive growth of e-commerce products being sold online has made manual annotation infeasible.", "labels": [], "entities": []}, {"text": "Without such tags it's impossible for customers to be able to find these products.", "labels": [], "entities": []}, {"text": "Hence a scalable approach catering to such large number of product images and allocating meaningful tags is essential and could be used to make an efficient tag based product retrieval system.", "labels": [], "entities": []}, {"text": "In this paper we propose one such approach based on feature extraction using Deep Convolutional Neural Networks to learn descriptive semantic features from product images.", "labels": [], "entities": [{"text": "feature extraction", "start_pos": 52, "end_pos": 70, "type": "TASK", "confidence": 0.7629232108592987}]}, {"text": "Then we use inverse distance weighted K-nearest neighbours classifiers along with several other multi-label classification approaches to assign appropriate tags to our images.", "labels": [], "entities": []}, {"text": "We demonstrate the functioning of our algorithm for the Amazon product dataset for various categories of products like clothing and apparel, electronics, sports equipment etc.", "labels": [], "entities": [{"text": "Amazon product dataset", "start_pos": 56, "end_pos": 78, "type": "DATASET", "confidence": 0.8725997805595398}]}], "introductionContent": [{"text": "In the present day world of mass internet penetration and the advent of the e-commerce era the number of products being bought and sold online has increased exponentially in the past few years.", "labels": [], "entities": []}, {"text": "In 2012, Business to Consumer (B2C) e-commerce sales grew 21.1% to top $1 trillion for the first time . This is expected to grow steadily at the rate of around 20% and is estimated to hit $2.5 trillion by 2018 2 . Given the explosive growth in the number of products being sold online and the relative heterogeneity in the categories these products could be allotted to, it has become physically impossible and infeasible to manually tag these products.", "labels": [], "entities": []}, {"text": "Besides not everyone will tag the same images with the same tags.", "labels": [], "entities": []}, {"text": "This leads to discrepancy in the kinds of tags allotted to the products.", "labels": [], "entities": []}, {"text": "Search engines looking for products based on customers query heavily rely on these tags allotted to each image to return accurate and meaningful results to customers queries but mainly only the product images are available which is impossible for the search engine to make sense of.", "labels": [], "entities": []}, {"text": "Besides the discrepancy in tagging leads to a lot of useful search results to get excluded.", "labels": [], "entities": []}, {"text": "An automatic tagging system can help take care of both of these problems and will be able to build an efficient product database querying system even if the database consists solely of visual information about the products.", "labels": [], "entities": []}, {"text": "Such an automated systems will bring about tagging homogeneity so that similar products are tagged with the same tags.", "labels": [], "entities": [{"text": "tagging homogeneity", "start_pos": 43, "end_pos": 62, "type": "TASK", "confidence": 0.8755235970020294}]}, {"text": "This will also eliminate the need for the laborious process of manually tagging such products.", "labels": [], "entities": []}, {"text": "The e-commerce marketplace is a truly multimodal space with visual features co-existing with product descriptions and feature specifications.", "labels": [], "entities": []}, {"text": "To be truly effective, such a marketplace must allow the user to be able to find products based on it's visual features as well as product descriptions.", "labels": [], "entities": []}, {"text": "This paper proposes an efficient approach to create such a Multi-Modal visual feature based product information retrieval system.", "labels": [], "entities": [{"text": "Multi-Modal visual feature based product information retrieval", "start_pos": 59, "end_pos": 121, "type": "TASK", "confidence": 0.5416414397103446}]}, {"text": "This is achieved in a 2 step process: 1.", "labels": [], "entities": []}, {"text": "(Image to Tags) Visual features are extracted from product images and are used to automatically annotate these product images with meaningful tags.", "labels": [], "entities": []}, {"text": "2. (Tags to Images) Now these tags are used to query a hash table indexed on these tags and used to retrieve all images corresponding to this tag.", "labels": [], "entities": []}, {"text": "The rest of the paper is organized as follows.", "labels": [], "entities": []}, {"text": "Related literature is reviewed in Section 2.", "labels": [], "entities": [{"text": "Related literature", "start_pos": 0, "end_pos": 18, "type": "DATASET", "confidence": 0.7201258540153503}]}, {"text": "Section 3 presents our proposed approach along with details of techniques used.", "labels": [], "entities": []}, {"text": "Sections 4 presents a detailed description of obtained results for various datasets.", "labels": [], "entities": []}, {"text": "Section 5 and 6 present Conclusion and Future Work respectively.", "labels": [], "entities": [{"text": "Conclusion", "start_pos": 24, "end_pos": 34, "type": "TASK", "confidence": 0.702623724937439}]}], "datasetContent": [{"text": "Lack of open availability of a dataset is one of the biggest problems which hinders the development of effective automatic tagging systems for e-commerce products.", "labels": [], "entities": []}, {"text": "Most of the data present on the web is highly unstructured and lacks proper labels and hence cant be effectively used.", "labels": [], "entities": []}, {"text": "Even when the labels are there, they are extremely noisy and cant be relied upon.", "labels": [], "entities": []}, {"text": "In our paper we present the results on the Amazon e-commerce product dataset, which contains images of various product categories and their metadata which we parse to obtain the tags associated with each image.", "labels": [], "entities": [{"text": "Amazon e-commerce product dataset", "start_pos": 43, "end_pos": 76, "type": "DATASET", "confidence": 0.883538231253624}]}, {"text": "For this paper we demonstrate our approach for apparels and clothing, electronics and sports equipment categories and show that the approach scales up to large number of tags and performs well on a wide category of products.", "labels": [], "entities": []}, {"text": "Images of these categories are tagged with a total of 1664, 886 and 2224 possible tags respectively.", "labels": [], "entities": []}, {"text": "to train it on our Amazon product dataset next.", "labels": [], "entities": [{"text": "Amazon product dataset", "start_pos": 19, "end_pos": 41, "type": "DATASET", "confidence": 0.9644309282302856}]}, {"text": "We also experiment with the VGG-16 and Googlenet networks, but VGG-19 features give us the best performance and hence we use them for our paper.", "labels": [], "entities": [{"text": "VGG-16", "start_pos": 28, "end_pos": 34, "type": "DATASET", "confidence": 0.9728997349739075}, {"text": "VGG-19", "start_pos": 63, "end_pos": 69, "type": "DATASET", "confidence": 0.954761803150177}]}, {"text": "The network structure is presented in Image 1.", "labels": [], "entities": []}, {"text": "It is observed that Deep Convolutional Neural networks have the ability to learn useful feature representations by non-linearly projecting the input images into a discriminative subspace where similar images tend to have similar intermediate feature representations while non-similar images are projected far from each other.", "labels": [], "entities": []}, {"text": "This trend is independent of the dataset it is trained on and hence a network trained on Imagenet network too is able to learn useful feature representations for the Amazon product dataset when trained on it., Bengio (2012) Hence we could use VGG-19 models pre-trained on Imagenet and then adapt them for our dataset.", "labels": [], "entities": [{"text": "Imagenet network", "start_pos": 89, "end_pos": 105, "type": "DATASET", "confidence": 0.9462961554527283}, {"text": "Amazon product dataset", "start_pos": 166, "end_pos": 188, "type": "DATASET", "confidence": 0.8767813444137573}]}, {"text": "This cuts down our training time tremendously as training Deep CNN models from scratch is computationally very expensive.", "labels": [], "entities": []}, {"text": "We use the 4096 Dimensional features from the last fully connected hidden layer of the VGG net as features to represent a given visual image.", "labels": [], "entities": [{"text": "VGG net", "start_pos": 87, "end_pos": 94, "type": "DATASET", "confidence": 0.9781288802623749}]}], "tableCaptions": [{"text": " Table 1: Tag Annotation results", "labels": [], "entities": [{"text": "Tag Annotation", "start_pos": 10, "end_pos": 24, "type": "TASK", "confidence": 0.45299825072288513}]}, {"text": " Table 2: Performance of the Content Based Image  Retrieval System for a list of 1000 query tags", "labels": [], "entities": [{"text": "Content Based Image  Retrieval", "start_pos": 29, "end_pos": 59, "type": "TASK", "confidence": 0.5715378299355507}]}]}