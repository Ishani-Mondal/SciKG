{"title": [{"text": "Dependency Based Embeddings for Sentence Classification Tasks", "labels": [], "entities": [{"text": "Sentence Classification Tasks", "start_pos": 32, "end_pos": 61, "type": "TASK", "confidence": 0.9434823989868164}]}], "abstractContent": [{"text": "We compare different word embeddings from a standard window based skipgram model, a skipgram model trained using dependency context features and a novel skipgram variant that utilizes additional information from dependency graphs.", "labels": [], "entities": []}, {"text": "We explore the effectiveness of the different types of word embeddings for word similarity and sentence classification tasks.", "labels": [], "entities": [{"text": "word similarity", "start_pos": 75, "end_pos": 90, "type": "TASK", "confidence": 0.7322242558002472}, {"text": "sentence classification tasks", "start_pos": 95, "end_pos": 124, "type": "TASK", "confidence": 0.789688766002655}]}, {"text": "We consider three common sentence classification tasks: question type classification on the TREC dataset, binary sentiment classification on Stanford's Sentiment Treebank and semantic relation classification on the SemEval 2010 dataset.", "labels": [], "entities": [{"text": "sentence classification", "start_pos": 25, "end_pos": 48, "type": "TASK", "confidence": 0.7564430236816406}, {"text": "question type classification", "start_pos": 56, "end_pos": 84, "type": "TASK", "confidence": 0.7517977555592855}, {"text": "TREC dataset", "start_pos": 92, "end_pos": 104, "type": "DATASET", "confidence": 0.9623786211013794}, {"text": "binary sentiment classification", "start_pos": 106, "end_pos": 137, "type": "TASK", "confidence": 0.659743865331014}, {"text": "Stanford's Sentiment Treebank", "start_pos": 141, "end_pos": 170, "type": "DATASET", "confidence": 0.49246876686811447}, {"text": "semantic relation classification", "start_pos": 175, "end_pos": 207, "type": "TASK", "confidence": 0.6409132679303488}, {"text": "SemEval 2010 dataset", "start_pos": 215, "end_pos": 235, "type": "DATASET", "confidence": 0.6782989700635275}]}, {"text": "For each task we use three different classification methods: a Support Vector Machine, a Convolutional Neural Network and a Long Short Term Memory Network.", "labels": [], "entities": []}, {"text": "Our experiments show that dependency based embeddings outperform standard window based embeddings inmost of the settings, while using dependency context embeddings as additional features improves performance in all tasks regardless of the classification method.", "labels": [], "entities": []}, {"text": "Our embeddings and code are available at", "labels": [], "entities": []}], "introductionContent": [{"text": "Representing words as low dimensional vectors (also known as word embeddings) has been a widely adopted technique in NLP.", "labels": [], "entities": []}, {"text": "Word representations can be used as features for classification tasks such as named entity recognition or chunking (, and as a pretraining method for initializing deep neural network representations.", "labels": [], "entities": [{"text": "named entity recognition", "start_pos": 78, "end_pos": 102, "type": "TASK", "confidence": 0.5844327112038931}, {"text": "initializing deep neural network representations", "start_pos": 150, "end_pos": 198, "type": "TASK", "confidence": 0.866628909111023}]}, {"text": "Word embeddings provide better generalization to unseen examples since they can capture general semantic and syntactic properties of words.", "labels": [], "entities": []}, {"text": "One of the most popular methods of learning word embeddings is the skipgram model of) where embeddings are trained by making predictions of context words appearing in a window around a target word.", "labels": [], "entities": []}, {"text": "The standard skipgram model ignores syntax and only partially takes into consideration the sequential structure of text, but still captures certain syntactic properties of words.", "labels": [], "entities": []}, {"text": "A significant amount of previous research has explored methods for directly taking syntax into account for word embedding learning.", "labels": [], "entities": [{"text": "word embedding learning", "start_pos": 107, "end_pos": 130, "type": "TASK", "confidence": 0.7146664063135783}]}, {"text": "One simple method is based on traditional count-based distributional semantic spaces and utilizes words with syntactic types from a dependency parse graph as context features.", "labels": [], "entities": []}, {"text": "This method has also been applied to skipgram models, where word embeddings are optimized to predict dependency context features instead of other words ().", "labels": [], "entities": []}, {"text": "Syntax-based embeddings have been shown to have different properties in word similarity evaluations than their window based counterparts, better capturing the functional properties of words.", "labels": [], "entities": [{"text": "word similarity evaluations", "start_pos": 72, "end_pos": 99, "type": "TASK", "confidence": 0.7329410513242086}]}, {"text": "However, it is not clear if they provide any advantage for NLP tasks.", "labels": [], "entities": []}, {"text": "We show that using dependency context features can be a general method of providing syntactic information for several sentence classification tasks.", "labels": [], "entities": [{"text": "sentence classification tasks", "start_pos": 118, "end_pos": 147, "type": "TASK", "confidence": 0.787166545788447}]}, {"text": "Furthermore, the dependency context embeddings improve performance with all classifiers we tested.", "labels": [], "entities": []}, {"text": "We consider the usage of word and dependency context features for three common sentence classification tasks: TREC question type classification, binary sentiment prediction on Stanford Sentiment Treebank, and SemEval 2010 relation identification.", "labels": [], "entities": [{"text": "sentence classification", "start_pos": 79, "end_pos": 102, "type": "TASK", "confidence": 0.7878062129020691}, {"text": "TREC question type classification", "start_pos": 110, "end_pos": 143, "type": "TASK", "confidence": 0.82896289229393}, {"text": "binary sentiment prediction", "start_pos": 145, "end_pos": 172, "type": "TASK", "confidence": 0.6359360118707021}, {"text": "Stanford Sentiment Treebank", "start_pos": 176, "end_pos": 203, "type": "DATASET", "confidence": 0.8701021671295166}, {"text": "SemEval 2010 relation identification", "start_pos": 209, "end_pos": 245, "type": "TASK", "confidence": 0.8406288027763367}]}, {"text": "We evaluate different methods of using the dependency context embeddings as extra features besides word embeddings to inject information into sentence classifiers about the syntactic structure of a sentence.", "labels": [], "entities": []}, {"text": "The advantage of such a method is that it can be applied to any classifier that utilizes standard word embeddings.", "labels": [], "entities": []}, {"text": "We evaluate the usefulness of syntaxbased word embeddings and dependency context embeddings with three different sentence classification methods: a Support Vector Machine (SVM), a Convolutional Neural Network (CNN) and a Long Short Term Memory network (LSTM).", "labels": [], "entities": []}, {"text": "In order to better utilize the structure of dependency graphs, we propose an extended version of the simple dependency based skipgram of.", "labels": [], "entities": []}, {"text": "This extended version considers cooccurrences in a dependency graph between pairs of words, words and dependency context features, and between different dependency context features.", "labels": [], "entities": []}, {"text": "This scheme results in word embeddings that share properties between window based models and dependency graph based ones.", "labels": [], "entities": []}, {"text": "More importantly, it provides additional structural information for the dependency context feature embeddings making them more effective when used in sentence classification tasks.", "labels": [], "entities": [{"text": "sentence classification tasks", "start_pos": 150, "end_pos": 179, "type": "TASK", "confidence": 0.8104595144589742}]}, {"text": "Our evaluation provides several insights on the role of syntax for embeddings and how they can be used for sentence classification.", "labels": [], "entities": [{"text": "sentence classification", "start_pos": 107, "end_pos": 130, "type": "TASK", "confidence": 0.7498665153980255}]}, {"text": "First, we confirm past claims about the different properties between dependency and window based skipgram embeddings in word similarity tasks.", "labels": [], "entities": [{"text": "word similarity tasks", "start_pos": 120, "end_pos": 141, "type": "TASK", "confidence": 0.7862478395303091}]}, {"text": "Second, we show that dependency based embeddings perform better in question classification and relation identification than window based ones.", "labels": [], "entities": [{"text": "question classification", "start_pos": 67, "end_pos": 90, "type": "TASK", "confidence": 0.7859868109226227}, {"text": "relation identification", "start_pos": 95, "end_pos": 118, "type": "TASK", "confidence": 0.829874724149704}]}, {"text": "These results are robust across multiple classification methods.", "labels": [], "entities": []}, {"text": "We show that combining dependency context feature embeddings together with word embeddings provide a simple and effective way to improve sentence classification performance.", "labels": [], "entities": [{"text": "sentence classification", "start_pos": 137, "end_pos": 160, "type": "TASK", "confidence": 0.7301117777824402}]}, {"text": "Finally, the performance gain is higher for the extended dependency based skipgram developed in this paper.", "labels": [], "entities": []}], "datasetContent": [{"text": "We evaluate the effect of the different contextual features for skipgram word embeddings in two word similarity datasets: WordSim-353 () and SimLex-999 ().", "labels": [], "entities": [{"text": "WordSim-353", "start_pos": 122, "end_pos": 133, "type": "DATASET", "confidence": 0.9609444737434387}]}, {"text": "For both datasets, we compare the cosine similarity of word embeddings fora pair of words to human judgements and report Spearman's correlation in Table 1.", "labels": [], "entities": [{"text": "Spearman's correlation", "start_pos": 121, "end_pos": 143, "type": "METRIC", "confidence": 0.6098685562610626}]}, {"text": "The two datasets use a different notion of word similarity for scoring.", "labels": [], "entities": []}, {"text": "Wordsim-353 mostly captures topical similarity (or relatedness), giving high similarity to pair of words like clothes-closet.", "labels": [], "entities": []}, {"text": "SimLex-999 uses a more strict version of similarity, often called substitutional similarity, where the pair clothes-closet has a low similarity score and pairs like shore-coast have high similarity.", "labels": [], "entities": [{"text": "SimLex-999", "start_pos": 0, "end_pos": 10, "type": "DATASET", "confidence": 0.9297410249710083}, {"text": "similarity", "start_pos": 41, "end_pos": 51, "type": "METRIC", "confidence": 0.9475754499435425}, {"text": "similarity score", "start_pos": 133, "end_pos": 149, "type": "METRIC", "confidence": 0.9400568306446075}]}, {"text": "Win5 skipgram version achieves a higher correlation for WordSim-353 compared to LG, but the results are reversed for SimLex-999.", "labels": [], "entities": [{"text": "WordSim-353", "start_pos": 56, "end_pos": 67, "type": "DATASET", "confidence": 0.9680124521255493}]}, {"text": "This agrees with previous research that shows that syntactic contexts correlate better with substitutional similarity judgements than using words in a window as contexts (", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Spearman correlation for the 3 skipgram variants", "labels": [], "entities": [{"text": "Spearman correlation", "start_pos": 10, "end_pos": 30, "type": "METRIC", "confidence": 0.7020705044269562}]}, {"text": " Table 2: Accuracy on 6-way TREC question classification", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9988301396369934}, {"text": "TREC question classification", "start_pos": 28, "end_pos": 56, "type": "TASK", "confidence": 0.6775984168052673}]}, {"text": " Table 3.  The state of the art for this dataset comes from Kim  (2014) using the same convolutional neural network  as we do, but also utilizing the phrasal level anno- tations which provide about an order of magnitude  larger training set. In addition, this specific configu- ration of the network (multichannel) uses two chan- nels at the input layer, one updating the word embed- dings during training and one that keeps them static  as we do in our experiments.", "labels": [], "entities": []}, {"text": " Table 3: Accuracy on Stanford Sentiment Treebank binary", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9932838678359985}, {"text": "Stanford Sentiment Treebank", "start_pos": 22, "end_pos": 49, "type": "DATASET", "confidence": 0.8717193007469177}]}, {"text": " Table 4: F1 score for SemEval 2010 Relation Identification", "labels": [], "entities": [{"text": "F1 score", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9725397825241089}, {"text": "SemEval 2010 Relation Identification", "start_pos": 23, "end_pos": 59, "type": "TASK", "confidence": 0.8925976306200027}]}]}