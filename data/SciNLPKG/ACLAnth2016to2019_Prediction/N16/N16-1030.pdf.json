{"title": [{"text": "Neural Architectures for Named Entity Recognition", "labels": [], "entities": [{"text": "Neural Architectures", "start_pos": 0, "end_pos": 20, "type": "TASK", "confidence": 0.7366280257701874}, {"text": "Named Entity Recognition", "start_pos": 25, "end_pos": 49, "type": "TASK", "confidence": 0.6957458058993021}]}], "abstractContent": [{"text": "State-of-the-art named entity recognition systems rely heavily on hand-crafted features and domain-specific knowledge in order to learn effectively from the small, supervised training corpora that are available.", "labels": [], "entities": [{"text": "named entity recognition", "start_pos": 17, "end_pos": 41, "type": "TASK", "confidence": 0.6007203062375387}]}, {"text": "In this paper, we introduce two new neural architectures-one based on bidirectional LSTMs and conditional random fields, and the other that constructs and labels segments using a transition-based approach inspired by shift-reduce parsers.", "labels": [], "entities": []}, {"text": "Our models rely on two sources of information about words: character-based word representations learned from the supervised corpus and unsupervised word representations learned from unannotated corpora.", "labels": [], "entities": []}, {"text": "Our models obtain state-of-the-art performance in NER in four languages without resorting to any language-specific knowledge or resources such as gazetteers.", "labels": [], "entities": []}], "introductionContent": [{"text": "Named entity recognition (NER) is a challenging learning problem.", "labels": [], "entities": [{"text": "Named entity recognition (NER)", "start_pos": 0, "end_pos": 30, "type": "TASK", "confidence": 0.8101393083731333}]}, {"text": "One the one hand, inmost languages and domains, there is only a very small amount of supervised training data available.", "labels": [], "entities": []}, {"text": "On the other, there are few constraints on the kinds of words that can be names, so generalizing from this small sample of data is difficult.", "labels": [], "entities": []}, {"text": "As a result, carefully constructed orthographic features and language-specific knowledge resources, such as gazetteers, are widely used for solving this task.", "labels": [], "entities": []}, {"text": "Unfortunately, languagespecific resources and features are costly to develop in new languages and new domains, making NER a challenge to adapt.", "labels": [], "entities": []}, {"text": "Unsupervised learning from unannotated corpora offers an alternative strategy for obtaining better generalization from small amounts of supervision.", "labels": [], "entities": []}, {"text": "However, even systems that have relied extensively on unsupervised features have used these to augment, rather than replace, hand-engineered features (e.g., knowledge about capitalization patterns and character classes in a particular language) and specialized knowledge resources (e.g., gazetteers).", "labels": [], "entities": []}, {"text": "In this paper, we present neural architectures for NER that use no language-specific resources or features beyond a small amount of supervised training data and unlabeled corpora.", "labels": [], "entities": [{"text": "NER", "start_pos": 51, "end_pos": 54, "type": "TASK", "confidence": 0.9391663074493408}]}, {"text": "Our models are designed to capture two intuitions.", "labels": [], "entities": []}, {"text": "First, since names often consist of multiple tokens, reasoning jointly over tagging decisions for each token is important.", "labels": [], "entities": []}, {"text": "We compare two models here, (i) a bidirectional LSTM with a sequential conditional random layer above it (LSTM-CRF; \u00a72), and (ii) anew model that constructs and labels chunks of input sentences using an algorithm inspired by transition-based parsing with states represented by stack LSTMs (S-LSTM; \u00a73).", "labels": [], "entities": []}, {"text": "Second, token-level evidence for \"being a name\" includes both orthographic evidence (what does the word being tagged as a name look like?) and distributional evidence (where does the word being tagged tend to occur in a corpus?).", "labels": [], "entities": []}, {"text": "To capture orthographic sensitivity, we use character-based word representation model () to capture distributional sensitivity, we combine these representations with distributional representations ().", "labels": [], "entities": []}, {"text": "Our word representations combine both of these, and dropout training is used to encourage the model to learn to trust both sources of evidence ( \u00a74).", "labels": [], "entities": []}, {"text": "Experiments in English, Dutch, German, and Spanish show that we are able to obtain state-of-the-art NER performance with the LSTM-CRF model in Dutch, German, and Spanish, and very near the state-of-the-art in English without any hand-engineered features or gazetteers ( \u00a75).", "labels": [], "entities": [{"text": "NER performance", "start_pos": 100, "end_pos": 115, "type": "TASK", "confidence": 0.885416716337204}]}, {"text": "The transition-based algorithm likewise surpasses the best previously published results in several languages, although it performs less well than the LSTM-CRF model.", "labels": [], "entities": []}], "datasetContent": [{"text": "This section presents the methods we use to train our models, the results we obtained on various tasks and the impact of our networks' configuration on model performance.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: English NER results (CoNLL-2003 test set). * indi-", "labels": [], "entities": [{"text": "NER", "start_pos": 18, "end_pos": 21, "type": "TASK", "confidence": 0.4983798563480377}, {"text": "CoNLL-2003 test set", "start_pos": 31, "end_pos": 50, "type": "DATASET", "confidence": 0.9611092408498129}]}, {"text": " Table 2: German NER results (CoNLL-2003 test set). * indi-", "labels": [], "entities": [{"text": "German NER results", "start_pos": 10, "end_pos": 28, "type": "DATASET", "confidence": 0.8049426277478536}, {"text": "CoNLL-2003 test set)", "start_pos": 30, "end_pos": 50, "type": "DATASET", "confidence": 0.9260575771331787}]}, {"text": " Table 3: Dutch NER (CoNLL-2002 test set). * indicates mod-", "labels": [], "entities": [{"text": "Dutch NER (CoNLL-2002 test set)", "start_pos": 10, "end_pos": 41, "type": "DATASET", "confidence": 0.9244093554360526}]}, {"text": " Table 4: Spanish NER (CoNLL-2002 test set). * indicates mod-", "labels": [], "entities": [{"text": "Spanish NER (CoNLL-2002 test set)", "start_pos": 10, "end_pos": 43, "type": "DATASET", "confidence": 0.8693152155194964}]}]}