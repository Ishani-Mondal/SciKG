{"title": [{"text": "Polyglot Neural Language Models: A Case Study in Cross-Lingual Phonetic Representation Learning", "labels": [], "entities": [{"text": "Cross-Lingual Phonetic Representation Learning", "start_pos": 49, "end_pos": 95, "type": "TASK", "confidence": 0.8144707679748535}]}], "abstractContent": [{"text": "We introduce polyglot language models, recurrent neural network models trained to predict symbol sequences in many different languages using shared representations of symbols and conditioning on typological information about the language to be predicted.", "labels": [], "entities": []}, {"text": "We apply these to the problem of modeling phone sequences-a domain in which universal symbol inventories and cross-linguistically shared feature representations area natural fit.", "labels": [], "entities": []}, {"text": "Intrinsic evaluation on held-out perplexity, qualitative analysis of the learned representations , and extrinsic evaluation in two downstream applications that make use of phonetic features show (i) that polyglot models better generalize to held-out data than comparable monolingual models and (ii) that polyglot phonetic feature representations are of higher quality than those learned monolingually.", "labels": [], "entities": []}], "introductionContent": [{"text": "Nearly all existing language model (LM) architectures are designed to model one language at a time.", "labels": [], "entities": []}, {"text": "This is unsurprising considering the historical importance of count-based models in which every surface form of a word is a separately modeled entity (English cat and Spanish gato would not likely benefit from sharing counts).", "labels": [], "entities": []}, {"text": "However, recent models that use distributed representations-in particular models that share representations across languages (, inter alia)-suggest universal models applicable to multiple languages area possibility.", "labels": [], "entities": []}, {"text": "This paper takes a step in this direction.", "labels": [], "entities": []}, {"text": "We introduce polyglot language models: neural network language models that are trained on and applied to any number of languages.", "labels": [], "entities": []}, {"text": "Our goals with these models are the following.", "labels": [], "entities": []}, {"text": "First, to facilitate data and parameter sharing, providing more training resources to languages, which is especially valuable in low-resource settings.", "labels": [], "entities": []}, {"text": "Second, models trained on diverse languages with diverse linguistic properties will better be able to learn naturalistic representations that are less likely to \"overfit\" to a single linguistic outlier.", "labels": [], "entities": []}, {"text": "Finally, polyglot models offer convenience in a multilingual world: a single model replaces dozens of different models.", "labels": [], "entities": []}, {"text": "Exploration of polyglot language models at the sentence level-the traditional domain of language modeling-requires dealing with a massive event space (i.e., the union of words across many languages).", "labels": [], "entities": []}, {"text": "To work in a more tractable domain, we evaluate our model on phone-based language modeling, the modeling sequences of sounds, rather than words.", "labels": [], "entities": []}, {"text": "We choose this domain since a common assumption of many theories of phonology is that all spoken languages construct words from a finite inventory of phonetic symbols (represented conveniently as the elements of the the International Phonetic Alphabet; IPA) which are distinguished by language-universal features (e.g., place and manner of articulation, voicing status, etc.).", "labels": [], "entities": []}, {"text": "Although our focus is on sound sequences, our solution can be ported to the semantic/syntactic problem as resulting from adaptation to constraints on semantic/syntactic structure.", "labels": [], "entities": []}, {"text": "This paper makes two primary contributions: in modeling and in applications.", "labels": [], "entities": []}, {"text": "In \u00a72, we introduce a novel polyglot neural language model (NLM) architecture.", "labels": [], "entities": []}, {"text": "Despite being trained on multiple languages, the multilingual model is more effective (9.5% lower perplexity) than individual models, and substantially more effective than naive baselines (over 25% lower perplexity).", "labels": [], "entities": []}, {"text": "Our most effective polyglot architecture conditions not only on the identity of the language being predicted in each sequence, but also on a vector representation of its phono-typological properties.", "labels": [], "entities": []}, {"text": "In addition to learning representations of phones as part of the polyglot language modeling objective, the model incorporates features about linguistic typology to improve generalization performance ( \u00a73).", "labels": [], "entities": []}, {"text": "Our second primary contribution is to show that downstream applications are improved by using polyglotlearned phone representations.", "labels": [], "entities": []}, {"text": "We focus on two tasks: predicting adapted word forms in models of cross-lingual lexical borrowing and speech synthesis ( \u00a74).", "labels": [], "entities": [{"text": "predicting adapted word forms", "start_pos": 23, "end_pos": 52, "type": "TASK", "confidence": 0.8969647586345673}, {"text": "cross-lingual lexical borrowing", "start_pos": 66, "end_pos": 97, "type": "TASK", "confidence": 0.6318168441454569}, {"text": "speech synthesis", "start_pos": 102, "end_pos": 118, "type": "TASK", "confidence": 0.7217903584241867}]}, {"text": "Our experimental results ( \u00a75) show that in borrowing, we improve over the current stateof-the-art, and in speech synthesis, our features are more effective than manually-designed phonetic features.", "labels": [], "entities": [{"text": "borrowing", "start_pos": 44, "end_pos": 53, "type": "TASK", "confidence": 0.9646444320678711}, {"text": "speech synthesis", "start_pos": 107, "end_pos": 123, "type": "TASK", "confidence": 0.7154831737279892}]}, {"text": "Finally, we analyze the phonological content of learned representations, finding that our polyglot models discover standard phonological categories such as length and nasalization, and that these are grouped correctly across languages with different phonetic inventories and contrastive features.", "labels": [], "entities": []}], "datasetContent": [{"text": "Our experimental evaluation of our proposed polyglot models consists of two parts: (i) an intrinsic evaluation where phone sequences are modeled with independent models and (ii) an extrinsic evaluation of the learned phonetic representations.", "labels": [], "entities": []}, {"text": "Before discussing these results, we provide details of the data resources we used.", "labels": [], "entities": []}, {"text": "We experiment with the following languages: Arabic (AR), French (FR), Hindi (HI), Italian (IT), Maltese (MT), Romanian (RO), Swahili (SW), Tamil (TA), and Telugu (TE).", "labels": [], "entities": []}, {"text": "In our language modeling experiments, two main sources of data are pronunciation dictionaries and typological features described in \u00a73.", "labels": [], "entities": []}, {"text": "The dictionaries for AR, FR, HI, TA, and TE are taken from in-house speech recognition/synthesis systems.", "labels": [], "entities": [{"text": "AR", "start_pos": 21, "end_pos": 23, "type": "METRIC", "confidence": 0.9014071226119995}, {"text": "FR", "start_pos": 25, "end_pos": 27, "type": "METRIC", "confidence": 0.8601409196853638}, {"text": "TA", "start_pos": 33, "end_pos": 35, "type": "METRIC", "confidence": 0.8490095138549805}, {"text": "TE", "start_pos": 41, "end_pos": 43, "type": "METRIC", "confidence": 0.9914484620094299}, {"text": "speech recognition/synthesis", "start_pos": 68, "end_pos": 96, "type": "TASK", "confidence": 0.8013485223054886}]}, {"text": "For remaining languages, the dictionaries are automatically constructed using the Omniglot grapheme-to-IPA conversion rules.", "labels": [], "entities": []}, {"text": "We use two types of pronunciation dictionaries: (1) AR, FR, HI, IT, MT, RO, and SW dictionaries used in experiments with lexical borrowing; and (2) EN, HI, TA, and TE dictionaries used in experiments with speech synthesis.", "labels": [], "entities": [{"text": "FR", "start_pos": 56, "end_pos": 58, "type": "METRIC", "confidence": 0.8248820900917053}, {"text": "speech synthesis", "start_pos": 205, "end_pos": 221, "type": "TASK", "confidence": 0.7288471311330795}]}, {"text": "The former are mapped to IPA, with the resulting phone vocabulary size-the number of distinct phones across IPA dictionaries-of 127 phones.", "labels": [], "entities": []}, {"text": "The latter are encoded using the UniTran universal transliteration resource (, with a vocabulary of 79 phone types.", "labels": [], "entities": []}, {"text": "From the (word-type) pronunciation dictionaries, we remove 15% of the words for development, and a further 10% for testing; the rest of the data is   used to train the models.", "labels": [], "entities": []}, {"text": "In tables 1 and 2 we list-for both types of pronunciation dictionariestrain/dev/test data statistics for words (phone sequences) and phone tokens.", "labels": [], "entities": []}, {"text": "We concatenate each phone sequence with beginning and end symbols (<s>, </s>).", "labels": [], "entities": []}, {"text": "We used the following network architecture: 100-dimensional phone vectors, with hidden local-context and LSTM layers of size 100, and hidden language layer of size 20.", "labels": [], "entities": []}, {"text": "All language models were trained using the left context of 3 phones (4-gram LMs).", "labels": [], "entities": []}, {"text": "Across all language modeling experiments, parameter optimization was performed on the dev set using the Adam algorithm () with mini-batches of size 100 to train the models for 5 epochs.", "labels": [], "entities": []}, {"text": "Perplexity is the standard evaluation measure for language models, which has been shown to correlate strongly with error rates in downstream applications ().", "labels": [], "entities": [{"text": "Perplexity", "start_pos": 0, "end_pos": 10, "type": "METRIC", "confidence": 0.9111741185188293}]}, {"text": "We evaluated perplexities across several architectures, and several monolingual and multilingual setups.", "labels": [], "entities": []}, {"text": "We kept the same hyper-parameters across all setups, as detailed in \u00a75.", "labels": [], "entities": []}, {"text": "Perplexities of LMs trained on the two types of pronunciation dictionaries were evaluated separately;   We see several patterns of results.", "labels": [], "entities": []}, {"text": "First, polyglot models require, unsurprisingly, information about what language they are predicting to obtain good modeling performance.", "labels": [], "entities": []}, {"text": "Second, typological information is more valuable than letting the model learn representations of the language along with the characters.", "labels": [], "entities": []}, {"text": "Finally, typology-augmented polyglot models outperform their monolingual baseline, providing evidence in support of the hypothesis that cross-lingual evidence is useful not only for learning cross-lingual representations and models, but monolingual ones as well.", "labels": [], "entities": []}, {"text": "We fully reproduced lexical borrowing models described in) for three language pairs: AR-SW, FR-RO, and IT-MT.", "labels": [], "entities": [{"text": "FR-RO", "start_pos": 92, "end_pos": 97, "type": "METRIC", "confidence": 0.944041907787323}]}, {"text": "Train and test corpora are donor-loanword pairs in the language pairs.", "labels": [], "entities": []}, {"text": "Corpora statistics are given in table 5 (note that these are extremely small data sets; thus small numbers of highly informative features a necessary for good generalization).", "labels": [], "entities": []}, {"text": "We use the reproduced systems as the baselines, and compare these to the corresponding systems augmented with phone vectors, as described in \u00a74.1.", "labels": [], "entities": []}, {"text": "Integrated vectors were obtained from a single polyglot model with typology, trained on all languages with IPA dictionaries.", "labels": [], "entities": []}, {"text": "For comparison with the results in table 3, perplexity of the model on the IT dataset (used for evaluation is \u00a75.2) is 4.16, even lower than in the model trained on four languages.", "labels": [], "entities": [{"text": "IT dataset", "start_pos": 75, "end_pos": 85, "type": "DATASET", "confidence": 0.8773805201053619}]}, {"text": "To retrain the high-level conceptual linguistic features learned by the borrowing models, we initialized the augmented systems with feature weights learned by the baselines, and retrained.", "labels": [], "entities": []}, {"text": "Final weights were established using cross-validation.", "labels": [], "entities": []}, {"text": "Then, we evaluated the accuracy of the augmented borrowing systems on the held-out test data.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 23, "end_pos": 31, "type": "METRIC", "confidence": 0.9995219707489014}]}, {"text": "Accuracies are shown in table 6.", "labels": [], "entities": [{"text": "Accuracies", "start_pos": 0, "end_pos": 10, "type": "METRIC", "confidence": 0.9846609234809875}]}, {"text": "We observe improvements of up to 5% in accuracies of FR-RO and IT-MT pairs.", "labels": [], "entities": [{"text": "accuracies", "start_pos": 39, "end_pos": 49, "type": "METRIC", "confidence": 0.9974164962768555}, {"text": "FR-RO", "start_pos": 53, "end_pos": 58, "type": "METRIC", "confidence": 0.9512474536895752}]}, {"text": "Effectiveness of the same polyglot model trained on multiple languages and integrated in different downstream systems supports our assumption that the model remains stable and effective with addition of languages.", "labels": [], "entities": []}, {"text": "Our model is less effective for the AR-SW language pair.", "labels": [], "entities": []}, {"text": "We speculate that the results are worse, because this is a pair of (typologically) more distant languages; consequently, the phonological adaptation processes that happen in loanword assimilation are more complex than mere substitutions of similar phones that we are targeting via the integration of phone vectors.", "labels": [], "entities": []}, {"text": "A popular objective metric for measuring the quality of synthetic speech is the Mel Cepstral Distortion (MCD) (.", "labels": [], "entities": [{"text": "Mel Cepstral Distortion (MCD)", "start_pos": 80, "end_pos": 109, "type": "METRIC", "confidence": 0.8156873484452566}]}, {"text": "The MCD metric calculates an L2 norm of the Mel Frequency Cepstral Coefficients (MFCCs) of natural speech from a held out test set, and synthetic speech generated from the same test set.", "labels": [], "entities": []}, {"text": "Since this is a distance metric, a lower value of MCD suggests better synthesis.", "labels": [], "entities": [{"text": "MCD", "start_pos": 50, "end_pos": 53, "type": "METRIC", "confidence": 0.5840623378753662}]}, {"text": "The MCD is a database-specific metric, but experiments by have shown that a decrease in MCD of 0.08 is perceptually significant, and a decrease of 0.12 is equivalent to doubling the size of the TTS database.", "labels": [], "entities": [{"text": "MCD", "start_pos": 88, "end_pos": 91, "type": "METRIC", "confidence": 0.9198849201202393}, {"text": "TTS database", "start_pos": 194, "end_pos": 206, "type": "DATASET", "confidence": 0.8374181389808655}]}, {"text": "In our experiments, we use MCD to measure the relative improvement obtained by our techniques.", "labels": [], "entities": []}, {"text": "We conducted experiments on the IIIT-H Hindi voice database (), a 2 hour single speaker database recorded by a professional male speaker.", "labels": [], "entities": [{"text": "IIIT-H Hindi voice database", "start_pos": 32, "end_pos": 59, "type": "DATASET", "confidence": 0.7695509940385818}]}, {"text": "We used the same front end (UniTran) to build all the Hindi TTS systems, with the only difference between the systems being the presence or absence of phonetic features and our vectors.", "labels": [], "entities": []}, {"text": "For all our voice-based experiments, we built CLUSTER-GEN Statistical Parametric Synthesis voices) using the Festvox voice building tools and the Festival speech synthesis engine).", "labels": [], "entities": [{"text": "Festvox", "start_pos": 109, "end_pos": 116, "type": "DATASET", "confidence": 0.9410497546195984}]}, {"text": "The baseline TTS system was built using no phonetic features.", "labels": [], "entities": [{"text": "TTS", "start_pos": 13, "end_pos": 16, "type": "TASK", "confidence": 0.5735081434249878}]}, {"text": "We also built a TTS system with standard hand-crafted phonetic features.", "labels": [], "entities": [{"text": "TTS", "start_pos": 16, "end_pos": 19, "type": "TASK", "confidence": 0.8046849370002747}]}, {"text": "Our multilingual vectors outperform the baseline, with a significant decrease of 0.19 in MCD.", "labels": [], "entities": [{"text": "MCD", "start_pos": 89, "end_pos": 92, "type": "DATASET", "confidence": 0.492818683385849}]}, {"text": "Crucially, TTS systems augmented with the Polyglot LM phone vectors outperform also the standard TTS with hand-crafted features.", "labels": [], "entities": [{"text": "Polyglot LM phone vectors", "start_pos": 42, "end_pos": 67, "type": "DATASET", "confidence": 0.9608254432678223}]}, {"text": "We found that using both feature sets added no value, suggesting that learned phone vectors are capturing information that is equivalent to the hand-engineered vectors.", "labels": [], "entities": []}, {"text": "We constructed a phonological matrix in which 5,059 rows are IPA phones and 21 columns are boolean indicators of universal phonological properties, e.g. consonant, voiced, labial.", "labels": [], "entities": []}, {"text": "We the projected annotations from the linguistic matrix and manually examined aligned dimensions in the phone vectors from \u00a75.3 (trained on six languages).", "labels": [], "entities": []}, {"text": "In the maximally-correlated columns-corresponding to linguistic features long, consonant, nasalized-we examined phones with highest coefficients.", "labels": [], "entities": []}, {"text": "These were: [5:, U:, i:, O:, E:] for long; [v, \u00f1, > dZ, d, f, j, > ts, N] for consonant; and [\u02dc O, \u02dc E, \u02dc A, \u02dc oe] for nasalized.", "labels": [], "entities": []}, {"text": "Clearly, the learned representation discover standard phonological features.", "labels": [], "entities": []}, {"text": "Moreover, these top-ranked sounds are not grouped by a single language, e.g., / > dZ/ is present in Arabic but not in French, and /\u00f1, N/ are present in French but not in Arabic.", "labels": [], "entities": []}, {"text": "From this analysis, we conclude that (1) the model discovers linguistically meaningful phonetic features; (2) the model induces meaningful related groupings across languages.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Train/dev/test counts for IPA pronunciation dictionaries for words (phone sequences) and phone tokens, in thousands:", "labels": [], "entities": []}, {"text": " Table 2: Train/dev/test statistics for UniTran pronunciation dic-", "labels": [], "entities": []}, {"text": " Table 3: Perplexity experiments with IT as test language. Train-", "labels": [], "entities": []}, {"text": " Table 4: Perplexity experiments with HI as test language.", "labels": [], "entities": []}, {"text": " Table 5: Number of training and test pairs the the borrowing", "labels": [], "entities": [{"text": "borrowing", "start_pos": 52, "end_pos": 61, "type": "TASK", "confidence": 0.8846285343170166}]}, {"text": " Table 6: Accuracies of the baseline models of lexical borrow-", "labels": [], "entities": [{"text": "Accuracies", "start_pos": 10, "end_pos": 20, "type": "METRIC", "confidence": 0.9883289337158203}]}, {"text": " Table 7: MCD for the HI TTS systems. Polyglot LM training", "labels": [], "entities": [{"text": "HI TTS", "start_pos": 22, "end_pos": 28, "type": "DATASET", "confidence": 0.6551560759544373}]}]}