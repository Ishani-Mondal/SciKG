{"title": [{"text": "PIC a Different Word: A Simple Model for Lexical Substitution in Context", "labels": [], "entities": [{"text": "Lexical Substitution in Context", "start_pos": 41, "end_pos": 72, "type": "TASK", "confidence": 0.7881850004196167}]}], "abstractContent": [{"text": "The Lexical Substitution task involves selecting and ranking lexical paraphrases fora target word in a given sentential context.", "labels": [], "entities": [{"text": "Lexical Substitution task", "start_pos": 4, "end_pos": 29, "type": "TASK", "confidence": 0.8442862033843994}]}, {"text": "We present PIC, a simple measure for estimating the ap-propriateness of substitutes in a given context.", "labels": [], "entities": [{"text": "PIC", "start_pos": 11, "end_pos": 14, "type": "METRIC", "confidence": 0.982337236404419}]}, {"text": "PIC outperforms another simple, comparable model proposed in recent work, especially when selecting substitutes from the entire vocabulary.", "labels": [], "entities": [{"text": "PIC", "start_pos": 0, "end_pos": 3, "type": "METRIC", "confidence": 0.5521184802055359}]}, {"text": "Analysis shows that PIC improves over baselines by incorporating frequency biases into predictions.", "labels": [], "entities": [{"text": "PIC", "start_pos": 20, "end_pos": 23, "type": "TASK", "confidence": 0.4612860679626465}]}], "introductionContent": [{"text": "Lexical substitution) is a task in which word meaning in context is described not through dictionary senses but through substitutes (paraphrases) chosen by annotators.", "labels": [], "entities": [{"text": "Lexical substitution)", "start_pos": 0, "end_pos": 21, "type": "TASK", "confidence": 0.8913976748784384}]}, {"text": "For example, consider the following usage of the adjective bright: \"The bright girl was reading a book.\"", "labels": [], "entities": []}, {"text": "Valid lexical substitutions for bright include adjectives like smart and intelligent, but not words like luminous or colorful.", "labels": [], "entities": []}, {"text": "Originally introduced as a SemEval task in 2007, lexical substitution has often been used to evaluate the ability of distributional models to handle polysemy; Van de Cruys et al.,.", "labels": [], "entities": []}, {"text": "Recent models include a simple but high-performing method by, which uses the Skip-gram model of) to compute the probability of a substitute given a sentence context, and integrates it with the probability of the substitute given the target.", "labels": [], "entities": []}, {"text": "The current state of the art is held by another model of Melamud (), which uses a more complex architecture.", "labels": [], "entities": [{"text": "Melamud", "start_pos": 57, "end_pos": 64, "type": "DATASET", "confidence": 0.938165545463562}]}, {"text": "In this paper we build on the simple model of, as simpler methods are easier to recreate and integrate into larger pipelines.", "labels": [], "entities": []}, {"text": "We explore a weak form of supervision that recently has proved beneficial on many NLP tasks: using a language modeling task on unannotated data.", "labels": [], "entities": []}, {"text": "We find a strong improvement over Melamud's simple measure, particularly on the all-words ranking task.", "labels": [], "entities": []}, {"text": "Interestingly, analysis of PIC shows it improves over baselines by incorporating frequency biases into predictions.", "labels": [], "entities": []}], "datasetContent": [{"text": "We compare our proposed measures to three baselines: OOC, the Out-of-Context cosine similarity between the word and target (cos(s, t)), and the addCos and balAddCos measures.", "labels": [], "entities": [{"text": "OOC", "start_pos": 53, "end_pos": 56, "type": "METRIC", "confidence": 0.9367298483848572}, {"text": "balAddCos", "start_pos": 155, "end_pos": 164, "type": "METRIC", "confidence": 0.9107141494750977}]}, {"text": "It is important to note that existing papers on Lexical Substitution all contain subtle differences in experimental setup (vocabulary coverage, candidate pooling, etc.).", "labels": [], "entities": [{"text": "Lexical Substitution", "start_pos": 48, "end_pos": 68, "type": "TASK", "confidence": 0.862884134054184}]}, {"text": "We compare to our own re-implementation of the baselines, so our numbers differ slightly from those in the literature.", "labels": [], "entities": []}, {"text": "We compare models on two variations of the lexical substitution task: candidate ranking and all-words ranking.", "labels": [], "entities": []}, {"text": "In the candidate ranking task, the model is given a list of candidates and must select which are most appropriate for the given target.", "labels": [], "entities": []}, {"text": "We follow prior work in pooling candidates from all substitutions fora given lemma and POS overall contexts, and measure performance using Generalized Average Precision (GAP).", "labels": [], "entities": [{"text": "Generalized Average Precision (GAP)", "start_pos": 139, "end_pos": 174, "type": "METRIC", "confidence": 0.8654555082321167}]}, {"text": "GAP is similar to Mean Average Precision, but weighted by the number of times a substitute was given by annotators.", "labels": [], "entities": [{"text": "GAP", "start_pos": 0, "end_pos": 3, "type": "METRIC", "confidence": 0.889291524887085}, {"text": "Mean Average Precision", "start_pos": 18, "end_pos": 40, "type": "METRIC", "confidence": 0.9281515876452128}]}, {"text": "See for full details of the candidate ranking task.", "labels": [], "entities": []}, {"text": "The second task is the much more difficult task of all-words ranking.", "labels": [], "entities": [{"text": "all-words ranking", "start_pos": 51, "end_pos": 68, "type": "TASK", "confidence": 0.7036063969135284}]}, {"text": "In this task, the model is not provided any gold list of candidates, but must select possible substitutes from the entire vocabulary.", "labels": [], "entities": []}, {"text": "We measure performance by (micro) mean Precision@1 and P@3: that is, of a system's top one/three guesses, the percentage also given by human annotators.", "labels": [], "entities": [{"text": "Precision@1", "start_pos": 39, "end_pos": 50, "type": "METRIC", "confidence": 0.9539194703102112}, {"text": "P", "start_pos": 55, "end_pos": 56, "type": "METRIC", "confidence": 0.968795657157898}]}, {"text": "These evaluation metrics are similar to the best and oot metrics reported in the literature, but we find P@1 and P@3 easier to interpret and analyze.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Lexical Substitution results for candidate ranking", "labels": [], "entities": [{"text": "Lexical Substitution", "start_pos": 10, "end_pos": 30, "type": "TASK", "confidence": 0.7896012365818024}]}]}