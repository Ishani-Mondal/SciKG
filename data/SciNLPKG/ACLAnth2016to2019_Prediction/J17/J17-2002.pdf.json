{"title": [{"text": "Greedy Transition-Based Dependency Parsing with Stack LSTMs under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International (CC BY-NC-ND 4.0) license", "labels": [], "entities": [{"text": "Greedy Transition-Based Dependency Parsing", "start_pos": 0, "end_pos": 42, "type": "TASK", "confidence": 0.5898354947566986}]}], "abstractContent": [{"text": "We introduce a greedy transition-based parser that learns to represent parser states using recurrent neural networks.", "labels": [], "entities": []}, {"text": "Our primary innovation that enables us to do this efficiently is anew control structure for sequential neural networks-the stack long short-term memory unit (LSTM).", "labels": [], "entities": []}, {"text": "Like the conventional stack data structures used in transition-based parsers, elements can be pushed to or popped from the top of the stack inconstant time, but, in addition, an LSTM maintains a continuous space embedding of the stack contents.", "labels": [], "entities": []}, {"text": "Our model captures three facets of the parser's state: (i) unbounded look-ahead into the buffer of incoming words, (ii) the complete history of transition actions taken by the parser, and (iii) the complete contents of the stack of partially built tree fragments, including their internal structures.", "labels": [], "entities": []}, {"text": "In addition, we compare two different word representations: (i) standard word vectors based on look-up tables and (ii) character-based models of words.", "labels": [], "entities": []}, {"text": "Although standard word embedding models work well in all languages, the character-based models improve the handling of out-of-vocabulary words, particularly in morphologically rich languages.", "labels": [], "entities": []}, {"text": "Finally, we discuss the use of dynamic oracles in training the parser.", "labels": [], "entities": []}, {"text": "During training, dynamic oracles alternate between sampling parser states from the training data and from the model as it is being learned, making the model more robust to the kinds of errors that will be made attest time.", "labels": [], "entities": []}, {"text": "Training our model with dynamic oracles yields a linear-time greedy parser with very competitive performance.", "labels": [], "entities": []}], "introductionContent": [{"text": "Natural language parsing can be formulated as a series of decisions that read words in sequence and incrementally combine them to form syntactic structures; this formulation is known as transition-based parsing, and is often coupled with a greedy inference procedure (.", "labels": [], "entities": [{"text": "Natural language parsing", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.6476069688796997}, {"text": "transition-based parsing", "start_pos": 186, "end_pos": 210, "type": "TASK", "confidence": 0.7105650305747986}]}, {"text": "Greedy transitionbased parsing is attractive because the number of operations required to build any projective parse tree is linear in the length of the sentence, making greedy versions of transition-based parsing computationally efficient relative to graph-and grammarbased alternative formalisms, which usually require solving superlinear search problems.", "labels": [], "entities": []}, {"text": "The challenge in transition-based parsing is modeling which action should betaken in each of the states encountered as the parsing algorithm progresses.", "labels": [], "entities": []}, {"text": "Because the parser state involves the complete sentence-which is unbounded in length-the representational challenge faced by the modeler is to find a finite encoding of an infinite space.", "labels": [], "entities": []}, {"text": "This challenge is usually dealt with by making assumptions about state equivalence by selecting features of the state believed by the model-builder to be most informative (e.g., the next three words in the sequence, the roots of the two most recently built subtrees and their left-and right-most children, and so on).", "labels": [], "entities": []}, {"text": "In this article, we advocate a recursive approach, in which complex parser states are represented as the composition of simpler ones, and these are constructed incrementally as parsing proceeds.", "labels": [], "entities": []}, {"text": "Thus, we operate in a paradigm in which the model builder designs recursive architectures that automatically discover effective views of the complete parser's evolving state rather than explicitly engineering which features of the state to focus on.", "labels": [], "entities": []}, {"text": "This construction enables us to avoid making explicit state-equivalence assumptions.", "labels": [], "entities": []}, {"text": "We present one such architecture based on advances in recursively defined neural networks.", "labels": [], "entities": []}, {"text": "Our state representation integrates information from a wide range of sources: r the complete remaining unprocessed words in the input buffer, r the complete history of parser transition actions on this sequence, and r the complete contents of the stack of partially constructed syntactic structures.", "labels": [], "entities": []}, {"text": "This global sensitivity of the state representation contrasts with most previous work in transition-based parsing that considers only a \"narrow view\" of the parser state when extracting features used to predict actions.", "labels": [], "entities": [{"text": "transition-based parsing", "start_pos": 89, "end_pos": 113, "type": "TASK", "confidence": 0.5912817120552063}]}, {"text": "Our work is complementary to previous approaches that develop alternative transition operations to simplify the modeling problem and enable better attachment decisions and to feature engineering (Zhang and Nivre 2011;.", "labels": [], "entities": [{"text": "feature engineering", "start_pos": 175, "end_pos": 194, "type": "TASK", "confidence": 0.7650994658470154}]}, {"text": "Our model is related to recent work that uses neural networks in dependency parsing;).", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 65, "end_pos": 83, "type": "TASK", "confidence": 0.8502833545207977}]}, {"text": "That work can broadly be understood as replacing a conventional linear classifier with a neural network classifier but still only considering a \"narrow view\" of the parser state, whereas our work uses recursively defined networks to incorporate sensitivity to the complete parser state.", "labels": [], "entities": []}, {"text": "Using recursive/recurrent neural networks to compute representations of unboundedly large histories has been proposed previously.", "labels": [], "entities": []}, {"text": "Our innovation is to make the architecture of the neural network identical with the structure of stack data structures used to store the parser state.", "labels": [], "entities": []}, {"text": "To do so, the technical challenge we must solve is being able to access, inconstant time, a fixed-size representation of a stack as it evolves during the course of parsing.", "labels": [], "entities": []}, {"text": "The technical innovation that lets us do this is a variation of recurrent neural networks with long short-term memory units (LSTMs), which we call stack LSTMs (Section 2).", "labels": [], "entities": []}, {"text": "These can be understood as LSTMs augmented with a stack pointer that is manipulated by push and pop operations (in contrast to classic LSTMs that only ever read inputs sequentially).", "labels": [], "entities": []}, {"text": "Our parsing model uses three stack LSTMs to construct the parser state representation: one containing the unprocessed input tokens, one containing the stack of partial syntactic trees, and one containing the history of parse actions (Section 3).", "labels": [], "entities": []}, {"text": "Because the stack of partial syntactic trees may contain both individual tokens and partial syntactic structures, representations of individual tree fragments are computed compositionally with recursive neural networks, similar to.", "labels": [], "entities": []}, {"text": "The parser depends on vector representations of word tokens.", "labels": [], "entities": []}, {"text": "Such representations are most commonly learned as a dictionary lookup function (i.e., a map of each word type to a vector), but they can take a parameterized form that is, for example, sensitive to orthographic or morphological properties of a word's surface form (.", "labels": [], "entities": []}, {"text": "For languages with rich inflective morphology, surface clues can be quite helpful for parsing.", "labels": [], "entities": [{"text": "parsing", "start_pos": 86, "end_pos": 93, "type": "TASK", "confidence": 0.9649102091789246}]}, {"text": "In Section 4, we compare the classical lookup-table approach to a recently proposed model that combines representations of individual characters (using sequential LSTMs) to obtain a representation of the word.", "labels": [], "entities": []}, {"text": "With no explicit morphological annotation, we find that the latter representation gives a large performance increase when parsing Statistical Parsing of Morphologically Rich Languages (SPMRL) data sets in languages with agglutinative morphology or extensive case systems (, and performs as well as the table method in analytic languages.", "labels": [], "entities": [{"text": "parsing Statistical Parsing of Morphologically Rich Languages (SPMRL)", "start_pos": 122, "end_pos": 191, "type": "TASK", "confidence": 0.8705918669700623}]}, {"text": "We further find that, without part-ofspeech tags, this technique benefits all languages, and that in some cases this approach obviates the need for explicit part-of-speech information.", "labels": [], "entities": []}, {"text": "This article also explores two different approaches to training.", "labels": [], "entities": []}, {"text": "Transition-based parsers are trained to optimize the score of the correct parsing action, given a parser state.", "labels": [], "entities": []}, {"text": "The simplest strategy for choosing pairs of states and actions for training is one that follows a deterministic static oracle that maps each dependency tree from a treebank into a sequence of states and actions.", "labels": [], "entities": []}, {"text": "However, this strategy only generates states that result from a history of correct parsing actions.", "labels": [], "entities": []}, {"text": "As a result, models learned with this kind of training may not be robust to errors made attest time.", "labels": [], "entities": []}, {"text": "We therefore also investigate a training procedure that also aims to teach the parser to make good predictions in sub-optimal states, facilitated by the use of dynamic oracles.", "labels": [], "entities": []}, {"text": "The experiments in this article demonstrate that by coupling stack LSTM-based global state representations with dynamic oracle training, parsing with greedy decoding can achieve state-of-the-art parsing accuracies, rivaling the accuracies of previous parsers that rely on exhaustive search procedures.", "labels": [], "entities": []}], "datasetContent": [{"text": "After describing the implementation details of our optimization procedure (Section 6.1) and the data used in our experiments (Section 6.2), we turn to four sets of experiments: 1.", "labels": [], "entities": []}, {"text": "First, we assess the quality of our greedy, global-state stack LSTM parsers on a wide range of data sets, showing that it is highly competitive with the state of the art (Section 6.3).", "labels": [], "entities": []}, {"text": "We report results on five experimental configurations per language, as well as the Chen and Manning (2014) baseline.", "labels": [], "entities": []}, {"text": "These are: the full stack LSTM parsing model (S-LSTM), the stack LSTM parsing model without POS tags (\u2212POS), the stack LSTM parsing model without pretrained language model embeddings (\u2212pretraining), the  stack LSTM parsing model that uses just head words on the stack instead of composed representations (\u2212composition), and the full parsing model where rather than an LSTM, a simple recurrent neural network in which normal sigmoidal hidden units are used instead of the LSTM, but augmented with a stack pointer (S-RNN).", "labels": [], "entities": []}, {"text": "Following Chen and Manning (2014), we exclude punctuation symbols for evaluation.", "labels": [], "entities": []}, {"text": "shows parsing scores comparable to, and we show that our model is better than their model on both the development set and the test set.", "labels": [], "entities": []}, {"text": "Overall, our parser substantially outperforms the baseline neural network parser of, both in the full configuration and in the various ablated conditions we report.", "labels": [], "entities": []}, {"text": "The one exception to this is the \u2212POS condition for the Chinese parsing task, in which we underperform their baseline (which used gold POS tags), although we do still obtain reasonable parsing performance in this limited case.", "labels": [], "entities": [{"text": "POS", "start_pos": 34, "end_pos": 37, "type": "METRIC", "confidence": 0.9391191005706787}, {"text": "Chinese parsing task", "start_pos": 56, "end_pos": 76, "type": "TASK", "confidence": 0.6309807002544403}]}, {"text": "We note that predicted POS tags in English add very little value-suggesting that we can think of parsing sentences directly without first tagging them.", "labels": [], "entities": []}, {"text": "We also find that using composed representations of dependency tree fragments outperforms using representations of head words alone.", "labels": [], "entities": []}, {"text": "Finally, we find that whereas LSTMs outperform classical RNNs, the latter are still quite capable of learning good representations.", "labels": [], "entities": []}, {"text": "Training is performed with mini-batches and requires around 20 hours to achieve convergence in the English data set although it depends on the effect of initialization; the parser achieves an end-to-end runtime of 40,539.8 milliseconds to parse the entire English test data (2.4k sentences) on a single CPU core.", "labels": [], "entities": [{"text": "English data set", "start_pos": 99, "end_pos": 115, "type": "DATASET", "confidence": 0.787580410639445}]}, {"text": "Other data sets require similar runtime per sentence.", "labels": [], "entities": []}, {"text": "The parser uses random seeds to create the mini-batches that it uses to train the model, which has an effect on the parsing results.", "labels": [], "entities": []}, {"text": "In order to seethe effect of initialization, we trained the whole S-LSTM parser with POS tags, pretrained word embeddings, and composition functions on the English SD data set, for the same amount of time (around 20 hours) using different random seeds.", "labels": [], "entities": [{"text": "English SD data set", "start_pos": 156, "end_pos": 175, "type": "DATASET", "confidence": 0.8720086812973022}]}, {"text": "shows the variation due to initialization for 100 different random seeds and their results on the English test set.", "labels": [], "entities": [{"text": "English test set", "start_pos": 98, "end_pos": 114, "type": "DATASET", "confidence": 0.9159613450368246}]}, {"text": "We observe that even though the results are very similar with a minimum of 92.3 and a maximum of 93.1, there are differences.", "labels": [], "entities": []}, {"text": "The modal result is 92.8.", "labels": [], "entities": []}, {"text": "Beam search was determined to have minimal impact on scores (absolute improvements of \u2264 0.3% were observed with small beams).", "labels": [], "entities": []}, {"text": "Therefore, all results we report used greedy decoding-Chen and Manning (2014) likewise only report results with greedy decoding.", "labels": [], "entities": []}, {"text": "This finding is inline with previous work that generates sequences from recurrent networks (), although,, and did report much more substantial improvements with beam search on their parsers.", "labels": [], "entities": []}, {"text": "In order to isolate the improvements provided by the LSTM encodings of characters described in Section 4.2, we run the stack LSTM parser in the following configurations: r Words + POS: words and POS tags (Section 4.1) The results shown in for the whole S-LSTM parser and English-SD are the best results for the development set, even though the histogram in shows a couple of models with better results on the test set.", "labels": [], "entities": []}, {"text": "19 Although superficially similar to ours, is a phrase-structure parser and adaptation to the dependency parsing scenario would have been nontrivial.", "labels": [], "entities": [{"text": "phrase-structure parser", "start_pos": 48, "end_pos": 71, "type": "TASK", "confidence": 0.7000694274902344}, {"text": "dependency parsing", "start_pos": 94, "end_pos": 112, "type": "TASK", "confidence": 0.8319687843322754}]}, {"text": "We discuss their work in Section 7.", "labels": [], "entities": [{"text": "Section 7", "start_pos": 25, "end_pos": 34, "type": "TASK", "confidence": 0.5632455050945282}]}, {"text": "None of the experimental configurations include pretrained word-embeddings or any additional data resources.", "labels": [], "entities": []}, {"text": "All experiments include SWAP transition, meaning that nonprojective trees could be produced in any language.", "labels": [], "entities": [{"text": "SWAP transition", "start_pos": 24, "end_pos": 39, "type": "TASK", "confidence": 0.6928853094577789}]}, {"text": "Finally, in addition to the dimensionality described in Section 6.1, the character-based representations of words have 100 dimensions.", "labels": [], "entities": []}, {"text": "show the results of the parsers for the development sets and the final test sets, respectively.", "labels": [], "entities": []}, {"text": "Most notable are improvements for agglutinative languages-Basque, Hungarian, Korean, and Turkish-both when POS tags are included and when they are not.", "labels": [], "entities": []}, {"text": "Consistently, across all languages, Chars outperforms Words, suggesting that the character-level LSTMs are learning representations that capture similar information to parts of speech.", "labels": [], "entities": []}, {"text": "On average, Chars is on par with Words + POS, and the best average of labeled attachment scores is achieved with Chars + POS.", "labels": [], "entities": [{"text": "labeled attachment scores", "start_pos": 70, "end_pos": 95, "type": "METRIC", "confidence": 0.7032362421353658}]}, {"text": "The results achieved by the dynamic oracle for English are actually one of the best results ever reported in this data set, achieving 93.56 unlabeled attachment score.", "labels": [], "entities": []}, {"text": "This is remarkable given that the parser uses a completely greedy inference procedure.", "labels": [], "entities": []}, {"text": "Moreover, the Chinese numbers establish the state-of-the-art by using the same settings as in.", "labels": [], "entities": []}, {"text": "The error-exploring dynamic-oracle training always improves above static oracle training using the same transition system, but the arc-hybrid system slightly underperforms the arc-standard system when trained with static oracle.", "labels": [], "entities": []}, {"text": "Transforming the sampling distribution towards preferring less probable events (\u03b1 = 0.75) is especially beneficial when training with pretrained word embeddings.", "labels": [], "entities": []}, {"text": "Unlabeled attachment scores and labeled attachment scores on the development sets (top) and the final test sets (bottom) for Chinese and English (SD).", "labels": [], "entities": []}, {"text": "The columns marked with \"Arc-std.\" show the results of the parser arc-standard oracle, which are the same numbers as in.", "labels": [], "entities": []}, {"text": "The columns marked with \"Arc-hybrid\" show the results of the parser with the arc-hybrid oracle.", "labels": [], "entities": []}, {"text": "The columns marked with \"static\" (\"dynamic\") show the results of the parser with static (dynamic) oracles.", "labels": [], "entities": []}, {"text": "In order to be able to compare with similar greedy parsers) we report the performance of the parser on the multilingual treebanks of the).", "labels": [], "entities": []}, {"text": "Because some of the treebanks contain nonprojective sentences and arc-hybrid does not allow nonprojective trees, we use the pseudo-projective approach.", "labels": [], "entities": []}, {"text": "For all the experiments presented in this section we used the predicted part-of-speech tags provided by the CoNLL 2009 shared task organizers.", "labels": [], "entities": [{"text": "CoNLL 2009 shared task organizers", "start_pos": 108, "end_pos": 141, "type": "DATASET", "confidence": 0.9531874775886535}]}, {"text": "In order to see if the pretrained word embeddings are useful for other languages we also include results with pretrained word embeddings for English, Chinese, German, and Spanish following the same training set-up as in Section 4; for English and Chinese we used the same pretrained word embeddings as in previous experiments, for German we pretrained embeddings using the monolingual training data from the WMT 2015 data set , and for Spanish we used the Spanish Gigaword version 3.", "labels": [], "entities": [{"text": "WMT 2015 data set", "start_pos": 408, "end_pos": 425, "type": "DATASET", "confidence": 0.941266804933548}]}, {"text": "The results for the parser with character-based representations on these data sets (last line of the table) were published by.", "labels": [], "entities": []}, {"text": "In Zhang and Weiss (2016), it is also possible to find results of the same version of the parser on the Universal Dependency treebanks ().", "labels": [], "entities": [{"text": "Universal Dependency treebanks", "start_pos": 104, "end_pos": 134, "type": "DATASET", "confidence": 0.6733763515949249}]}], "tableCaptions": [{"text": " Table 1  Unlabeled attachment scores and labeled attachment scores on the development sets (top) and  the final test sets (bottom) for Chinese and English (SD). The columns marked with S-LSTM  show the results of the parser with the whole S-LSTM model. The columns marked with \u2212POS  show the results of the parser without POS tags. The columns marked with \u2212pretraining show  the results of the parser without pretraining. The columns marked with S-RNN show the results  of the parser in which the S-LSTM is replaced by a recurrent neural network. The columns  marked with C&M (2014) show the results of Chen and Manning (2014).", "labels": [], "entities": [{"text": "C&M (2014)", "start_pos": 573, "end_pos": 583, "type": "DATASET", "confidence": 0.8581419487794241}]}, {"text": " Table 2  Unlabeled attachment scores (top) and labeled attachment scores (bottom) on the development  sets (not a standard development set for Turkish). In each table, the first two columns show the  results of the parser with word lookup (Words) vs. character-based (Chars) representations.  Boldface shows the better result comparing Words vs. Chars, comparing Words + POS vs. Chars  + POS, and comparing Words + POS + Morph vs. Chars + POS + Morph.", "labels": [], "entities": []}, {"text": " Table 3  Unlabeled attachment scores (top) and labeled attachment scores (bottom) on the test sets.  In each table, the first two columns show the results of the parser with word lookup  (Words) vs. character-based (Chars) representations. Boldface shows the better result  comparing Words vs. Chars, comparing Words + POS vs. Chars + POS, and comparing  Words + POS + Morph vs. Chars + POS + Morph.", "labels": [], "entities": []}, {"text": " Table 5  Test-set performance of our best results (according to UAS or LAS, whichever has the larger  difference), compared with state-of-the-art greedy transition-based parsers (\"Best Greedy  Result\") and best results reported (\"Best Published Result\"). Note that B+'13 and B+'14 are a  combination of parsers and use unlabeled data; our models do not. We only use unlabeled data  for the pretrained word embeddings of DWPP. W refers to Words; C refers to Chars; WP refers  to Words + Pos; WPM refers to Words + Pos + Morph; CP refers to Chars + Pos; CPM refers to  Chars + Pos + Morph; B'13 is (Ballesteros 2013); N+'06a is (", "labels": [], "entities": [{"text": "UAS", "start_pos": 65, "end_pos": 68, "type": "DATASET", "confidence": 0.8868335485458374}]}, {"text": " Table 1. The  columns marked with \"Arc-hybrid\" show the results of the parser with the arc-hybrid oracle.  The columns marked with \"static\" (\"dynamic\") show the results of the parser with static  (dynamic) oracles.", "labels": [], "entities": []}]}