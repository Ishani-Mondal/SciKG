{"title": [{"text": "A Statistical, Grammar-Based Approach to Microplanning", "labels": [], "entities": [{"text": "Microplanning", "start_pos": 41, "end_pos": 54, "type": "TASK", "confidence": 0.5808608531951904}]}], "abstractContent": [{"text": "Although there has been much work in recent years on data-driven natural language generation, little attention has been paid to the fine-grained interactions that arise during microplanning between aggregation, surface realization, and sentence segmentation.", "labels": [], "entities": [{"text": "natural language generation", "start_pos": 65, "end_pos": 92, "type": "TASK", "confidence": 0.7323068380355835}, {"text": "surface realization", "start_pos": 211, "end_pos": 230, "type": "TASK", "confidence": 0.7846786677837372}, {"text": "sentence segmentation", "start_pos": 236, "end_pos": 257, "type": "TASK", "confidence": 0.727420836687088}]}, {"text": "In this article, we propose a hybrid symbolic/statistical approach to jointly model the constraints regulating these interactions.", "labels": [], "entities": []}, {"text": "Our approach integrates a small handwritten grammar, a statistical hypertagger, and a surface realization algorithm.", "labels": [], "entities": [{"text": "surface realization", "start_pos": 86, "end_pos": 105, "type": "TASK", "confidence": 0.7579962611198425}]}, {"text": "It is applied to the verbalization of knowledge base queries and tested on 13 knowledge bases to demonstrate domain independence.", "labels": [], "entities": []}, {"text": "We evaluate our approach in several ways.", "labels": [], "entities": []}, {"text": "A quantitative analysis shows that the hybrid approach outperforms a purely symbolic approach in terms of both speed and coverage.", "labels": [], "entities": [{"text": "speed", "start_pos": 111, "end_pos": 116, "type": "METRIC", "confidence": 0.9948189854621887}, {"text": "coverage", "start_pos": 121, "end_pos": 129, "type": "METRIC", "confidence": 0.803655207157135}]}, {"text": "Results from a human study indicate that users find the output of this hybrid statistic/symbolic system more fluent than both a template-based and a purely symbolic grammar-based approach.", "labels": [], "entities": []}, {"text": "Finally, we illustrate by means of examples that our approach can account for various factors impacting aggregation, sentence segmentation, and surface realization.", "labels": [], "entities": [{"text": "sentence segmentation", "start_pos": 117, "end_pos": 138, "type": "TASK", "confidence": 0.7528213262557983}, {"text": "surface realization", "start_pos": 144, "end_pos": 163, "type": "TASK", "confidence": 0.7921240031719208}]}], "introductionContent": [{"text": "When generating a text, many choices must be made.", "labels": [], "entities": []}, {"text": "The content to be expressed must be selected (content selection) and structured (document planning).", "labels": [], "entities": []}, {"text": "Content must be distributed into sentences (sentence segmentation).", "labels": [], "entities": [{"text": "sentence segmentation)", "start_pos": 44, "end_pos": 66, "type": "TASK", "confidence": 0.8156611323356628}]}, {"text": "Words (lexicalization) and syntactic structures (surface realization) must be chosen.", "labels": [], "entities": []}, {"text": "Appropriate referring expressions must be identified to describe entities (referring expression generation).", "labels": [], "entities": [{"text": "referring expression generation", "start_pos": 75, "end_pos": 106, "type": "TASK", "confidence": 0.6931147774060568}]}, {"text": "Coordinated and elliptical constructs maybe exploited to omit repeated information (Aggregation).", "labels": [], "entities": [{"text": "Aggregation", "start_pos": 84, "end_pos": 95, "type": "METRIC", "confidence": 0.9897145628929138}]}, {"text": "These decisions interact and are subject to various constraints.", "labels": [], "entities": []}, {"text": "Consider for instance the content sketched in Example (1).", "labels": [], "entities": []}, {"text": "There are many ways of verbalizing this content 1 but the appropriate choice depends on the context.", "labels": [], "entities": []}, {"text": "For instance, the elision form (1l-m) is only appropriate in a context where another sell literal is present (e.g., car(x) sell(x,y) sportsCar(y) sell(x,z) trucks(z)).", "labels": [], "entities": []}, {"text": "In this case, the repeated sell predicate can be elided (A car dealer selling sports cars and trucks).", "labels": [], "entities": []}, {"text": "There are both soft and hard constraints regulating the choice of a given verbalization.", "labels": [], "entities": []}, {"text": "A clause starting with a comma must be complemented by one starting with a coordination (Examples (2)a-b) and an elided clause must follow its source clause (Examples (2)c-d).", "labels": [], "entities": []}, {"text": "These are hard, grammatical, constraints in that violating them yields sub-standard text.", "labels": [], "entities": []}, {"text": "On the other hand, many syntactic and linear ordering choices are regulated by soft constraints-that is, yield text of variable acceptability.", "labels": [], "entities": []}, {"text": "Thus, although both sentences in Example (3) are grammatical, Example (3a) is arguably better English than Example (3b).", "labels": [], "entities": []}, {"text": "I am looking fora teaching assistant who is employed by the University, who teaches English, and who has a PhD", "labels": [], "entities": [{"text": "University", "start_pos": 60, "end_pos": 70, "type": "DATASET", "confidence": 0.96465665102005}]}], "datasetContent": [{"text": "We developed and tested the generation approach described in the preceding section on 13 knowledge bases-namely, two ontologies on cars and on Master courses developed by the Quelo consortium and 11 ontologies available on the Web, including the Aquatic Resource Observation ontology, the GoodRelations ontology, Wines, QALL-ME (), Adolena Ontology (), Movies, The Air System Ontology (TONES repository), Camera OWL Ontology and Travel (Prot\u00e9g\u00e9 repository), The Photography Ontology, and The Bibliographic Ontology.", "labels": [], "entities": []}, {"text": "This involved automatically acquiring lexicons from these knowledge bases; manually specifying a FB-LTAG describing the morpho-syntax, the syntax, and the semantics of KB queries; developing a parallel corpus of formal and natural language KB queries to train the hypertagger model; training the hypertagger model on that corpus; and integrating this hypertagger with the surface realization algorithm described in PerezBeltrachini, Gardent, and Franconi (2014).", "labels": [], "entities": []}, {"text": "In this section, we start by evaluating the impact of the hypertagging module in terms of both speed and coverage.", "labels": [], "entities": [{"text": "speed", "start_pos": 95, "end_pos": 100, "type": "METRIC", "confidence": 0.9945594668388367}, {"text": "coverage", "start_pos": 105, "end_pos": 113, "type": "METRIC", "confidence": 0.9884791970252991}]}, {"text": "We then goon to evaluate the quality of the generator output when compared with both a template-and a grammar-based approach, using both quantitative metrics (BLEU) and a human-based evaluation.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 159, "end_pos": 163, "type": "METRIC", "confidence": 0.7673780918121338}]}, {"text": "In Section 6, we will also show that our approach can account for various factors impacting aggregation, sentence segmentation, and the choice of contextually appropriate syntactic structures.", "labels": [], "entities": [{"text": "sentence segmentation", "start_pos": 105, "end_pos": 126, "type": "TASK", "confidence": 0.7447201311588287}]}], "tableCaptions": [{"text": " Table 3  Hypertagger accuracy (percent). n is the number of best sequences considered.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 22, "end_pos": 30, "type": "METRIC", "confidence": 0.9526661038398743}]}, {"text": " Table 5  Output quality: The differences between the systems Symb/Hyb and the systems Temp/Hyb for  both Fluency and Clarity categories are statistically significant. Fisher's exact test gives a  two-tailed p-value < 0.0001 in all the cases.", "labels": [], "entities": [{"text": "Output quality", "start_pos": 10, "end_pos": 24, "type": "METRIC", "confidence": 0.9635052382946014}, {"text": "Fluency", "start_pos": 106, "end_pos": 113, "type": "METRIC", "confidence": 0.9280972480773926}]}]}