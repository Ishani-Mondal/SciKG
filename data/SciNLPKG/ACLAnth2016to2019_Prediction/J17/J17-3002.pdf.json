{"title": [{"text": "Translation Divergences in Chinese-English Machine Translation: An Empirical Investigation under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International (CC BY-NC-ND 4.0) license", "labels": [], "entities": [{"text": "Translation Divergences in Chinese-English Machine Translation", "start_pos": 0, "end_pos": 62, "type": "TASK", "confidence": 0.6694386055072149}]}], "abstractContent": [{"text": "In this article, we conduct an empirical investigation of translation divergences between Chinese and English relying on a parallel treebank.", "labels": [], "entities": [{"text": "translation divergences", "start_pos": 58, "end_pos": 81, "type": "TASK", "confidence": 0.9758214354515076}]}, {"text": "To do this, we first devise a hierarchical alignment scheme where Chinese and English parse trees are aligned in away that eliminates conflicts and redundancies between word alignments and syntactic parses to prevent the generation of spurious translation divergences.", "labels": [], "entities": [{"text": "word alignments and syntactic parses", "start_pos": 169, "end_pos": 205, "type": "TASK", "confidence": 0.6901804208755493}]}, {"text": "Using this Hierarchically Aligned Chinese-English Parallel Treebank (HACEPT), we are able to semi-automatically identify and categorize the translation divergences between the two languages and quantify each type of translation divergence.", "labels": [], "entities": []}, {"text": "Our results show that the translation divergences are much broader than described in previous studies that are largely based on anecdotal evidence and linguistic knowledge.", "labels": [], "entities": [{"text": "translation divergences", "start_pos": 26, "end_pos": 49, "type": "TASK", "confidence": 0.9689987897872925}]}, {"text": "The distribution of the translation divergences also shows that some high-profile translation divergences that motivate previous research are actually very rare in our data, whereas other translation divergences that have previously received little attention actually exist in large quantities.", "labels": [], "entities": [{"text": "translation divergences", "start_pos": 24, "end_pos": 47, "type": "TASK", "confidence": 0.8633134663105011}]}, {"text": "We also show that HACEPT allows the extraction of syntax-based translation rules, most of which are expressive enough to capture the translation divergences, and point out that the syntactic annotation in existing treebanks is not optimal for extracting such translation rules.", "labels": [], "entities": [{"text": "extraction of syntax-based translation", "start_pos": 36, "end_pos": 74, "type": "TASK", "confidence": 0.6244824305176735}]}, {"text": "We also discuss the implications of our study for attempts to bridge translation divergences by devising shared semantic representations across languages.", "labels": [], "entities": [{"text": "translation divergences", "start_pos": 69, "end_pos": 92, "type": "TASK", "confidence": 0.9339203238487244}]}, {"text": "Our quantitative results lend further support to the observation that although it is possible to bridge some translation divergences with semantic representations, other translation divergences are open-ended, thus building a semantic representation that captures all possible translation divergences maybe impractical.", "labels": [], "entities": []}, {"text": "Note: Part of Section 2 of this paper has appeared in Deng and Xue (2014c).", "labels": [], "entities": [{"text": "Deng and Xue (2014c)", "start_pos": 54, "end_pos": 74, "type": "DATASET", "confidence": 0.8290017346541086}]}, {"text": "All the other contents are new.", "labels": [], "entities": []}], "introductionContent": [{"text": "Statistical machine translation (SMT), currently the dominant approach to machine translation (MT), relies on large amounts of parallel text called bitext to learn translation patterns that can be used to translate new text.", "labels": [], "entities": [{"text": "Statistical machine translation (SMT)", "start_pos": 0, "end_pos": 37, "type": "TASK", "confidence": 0.8248344361782074}, {"text": "machine translation (MT)", "start_pos": 74, "end_pos": 98, "type": "TASK", "confidence": 0.8583593487739563}]}, {"text": "The statistical paradigm of MT started over two decades ago with word-based models described in the seminal work of, where an MT system automatically learns translation correspondence between word-aligned sentence pairs and selects the most plausible translation fora source language sentence using the language model trained on monolingual data in the target language.", "labels": [], "entities": [{"text": "MT", "start_pos": 28, "end_pos": 30, "type": "TASK", "confidence": 0.9952046871185303}, {"text": "MT", "start_pos": 126, "end_pos": 128, "type": "TASK", "confidence": 0.9689440727233887}]}, {"text": "Although this general paradigm has not changed, SMT approaches have evolved since then.", "labels": [], "entities": [{"text": "SMT", "start_pos": 48, "end_pos": 51, "type": "TASK", "confidence": 0.9952303171157837}]}, {"text": "Only several years after the introduction of word-based models, phrase-based models were proposed that better use local context and handle the translation of non-compositional phrases to yield superior translation accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 214, "end_pos": 222, "type": "METRIC", "confidence": 0.8996956944465637}]}, {"text": "Hierarchical phrase-based models further advanced the state of the art by allowing non-terminals in phrase-based translation rules called hierarchical phrase pairs, which effectively capture long-distance lexical dependencies because the yields of the non-terminals are of variable lengths and can be arbitrarily long (.", "labels": [], "entities": []}, {"text": "Along this main thread, in the last decade there has been intensive research on incorporating syntactic trees produced by syntactic parsers trained on human-annotated treebanks into an SMT model.", "labels": [], "entities": [{"text": "SMT", "start_pos": 185, "end_pos": 188, "type": "TASK", "confidence": 0.9878318905830383}]}, {"text": "The attempt to provide syntactic information for SMT models is driven by the widely accepted assumption that word order varies in systematic ways among languages and reordering in a sentence pair often involves syntactic constituents rather than individual words.", "labels": [], "entities": [{"text": "SMT", "start_pos": 49, "end_pos": 52, "type": "TASK", "confidence": 0.994526207447052}]}, {"text": "It is natural then to expect that incorporating syntactic structures into SMT models would lead to improved MT accuracy.", "labels": [], "entities": [{"text": "SMT", "start_pos": 74, "end_pos": 77, "type": "TASK", "confidence": 0.9873145818710327}, {"text": "MT", "start_pos": 108, "end_pos": 110, "type": "TASK", "confidence": 0.9919449687004089}, {"text": "accuracy", "start_pos": 111, "end_pos": 119, "type": "METRIC", "confidence": 0.9349420666694641}]}, {"text": "Various approaches have been proposed to incorporate syntactic structures, and their differences can be described along two dimensions: whether they use syntactic structures on the source side or the target side or both, and whether they use phrase structures or dependency structures.", "labels": [], "entities": []}, {"text": "String-to-tree systems model the syntactic structures of target language sentences () and tree-to-string systems model the syntactic structures of source language sentences; Liu, Liu, and Lin 2006;.", "labels": [], "entities": []}, {"text": "Tree-to-tree systems model the syntactic structures of both source and target language sentences; Liu, L \u00a8 u, and Liu 2009).", "labels": [], "entities": []}, {"text": "Early syntax-based models generally use phrase structure (or constituent structure) trees and later syntax-based systems also use dependency trees.", "labels": [], "entities": []}, {"text": "The general observation about syntax-based models is that although incorporating syntactic structures has led to solid gains, there are also challenges that have prevented syntax-based systems from realizing their full potential.", "labels": [], "entities": []}, {"text": "The first challenge is the inevitable errors acquired in automatic syntactic parsing.", "labels": [], "entities": [{"text": "syntactic parsing", "start_pos": 67, "end_pos": 84, "type": "TASK", "confidence": 0.6429990082979202}]}, {"text": "Syntax-based systems rely on syntactic parsers trained on manually annotated treebanks to automatically parse large quantities of parallel text in order to extract translation rules.", "labels": [], "entities": []}, {"text": "Even though state-of-the-art parsers can parse English text at over 90% accuracy when evaluated against standard benchmarks such as the Penn TreeBank, syntactic parsing accuracy for other languages is considerably lower (.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 72, "end_pos": 80, "type": "METRIC", "confidence": 0.9963846206665039}, {"text": "Penn TreeBank", "start_pos": 136, "end_pos": 149, "type": "DATASET", "confidence": 0.9909019470214844}, {"text": "syntactic parsing", "start_pos": 151, "end_pos": 168, "type": "TASK", "confidence": 0.6778950393199921}, {"text": "accuracy", "start_pos": 169, "end_pos": 177, "type": "METRIC", "confidence": 0.7805889844894409}]}, {"text": "In addition, even for English, there is considerable performance degradation when the data that needs to be parsed is different from the Wall Street Journal newswire articles that the parsers are generally trained on.", "labels": [], "entities": [{"text": "Wall Street Journal newswire articles", "start_pos": 137, "end_pos": 174, "type": "DATASET", "confidence": 0.9051058650016784}]}, {"text": "Syntax-based SMT systems are only competitive when used in conjunction with techniques such as packed forests, which relax the need to use one-best parses.", "labels": [], "entities": [{"text": "SMT", "start_pos": 13, "end_pos": 16, "type": "TASK", "confidence": 0.9126086831092834}]}, {"text": "The second challenge is that the constraints imposed by the syntactic structures have been shown to be too stringent, and prevent useful syntaxbased translation rules that do not obey syntactic constituent boundaries from being used in SMT models and hurt MT performance.", "labels": [], "entities": [{"text": "SMT", "start_pos": 236, "end_pos": 239, "type": "TASK", "confidence": 0.9901064038276672}, {"text": "MT", "start_pos": 256, "end_pos": 258, "type": "TASK", "confidence": 0.9863941073417664}]}, {"text": "Effective techniques have been developed to address this issue by identifying heuristics to relax the constraints of syntactic structures when extracting translation rules (.", "labels": [], "entities": []}, {"text": "As the gain of incorporating syntactic information has plateaued, the field is poised to climb up the Vauquois Pyramid and start exploring the utility of semantic representations for SMT systems, mirroring the progression of earlier rule-based approaches in the previous incarnation of MT research.", "labels": [], "entities": [{"text": "SMT", "start_pos": 183, "end_pos": 186, "type": "TASK", "confidence": 0.9948439598083496}, {"text": "MT", "start_pos": 286, "end_pos": 288, "type": "TASK", "confidence": 0.9858027696609497}]}, {"text": "The hope is that more abstract semantic representations can better address translation divergences than syntactic structures, and this advantage will hopefully offset the potential harm caused by the expected drop in the accuracy of semantic analyzers that are more difficult to develop than syntactic parsers.", "labels": [], "entities": [{"text": "translation divergences", "start_pos": 75, "end_pos": 98, "type": "TASK", "confidence": 0.9022822678089142}, {"text": "accuracy", "start_pos": 221, "end_pos": 229, "type": "METRIC", "confidence": 0.9981154203414917}]}, {"text": "The development of the AMR Bank () is the latest attempt in that direction, although it is important to point out that the significance of such semantically annotated corpora goes far beyond the narrow purpose of MT, and that the AMR Bank is neither the first nor the only attempt to develop semantically annotated resources that can be used for MT purposes.", "labels": [], "entities": [{"text": "AMR Bank", "start_pos": 23, "end_pos": 31, "type": "DATASET", "confidence": 0.9481039345264435}, {"text": "MT", "start_pos": 213, "end_pos": 215, "type": "TASK", "confidence": 0.9816265106201172}, {"text": "AMR Bank", "start_pos": 230, "end_pos": 238, "type": "DATASET", "confidence": 0.9242716431617737}, {"text": "MT", "start_pos": 346, "end_pos": 348, "type": "TASK", "confidence": 0.9935219883918762}]}, {"text": "Similar efforts include a series of head-driven phrase structure grammarbased resources (e.g., LingGO Redwoods Treebank and the DeepBank) (, the semantic layers of which are based on Minimal Recursion Semantics (MRS) (), a semantic representation framework that has been adopted in modern semantic transfer-based MT systems ().", "labels": [], "entities": [{"text": "LingGO Redwoods Treebank", "start_pos": 95, "end_pos": 119, "type": "DATASET", "confidence": 0.9693692922592163}, {"text": "semantic transfer-based MT", "start_pos": 289, "end_pos": 315, "type": "TASK", "confidence": 0.5833262999852499}]}, {"text": "As the field prepares to take this next step of incorporating semantic representation into the SMT paradigm, it is worth asking: i) Are translation divergences properly represented by the kind of syntax-based translation rules such as hierarchical phrase pairs used in current systems?", "labels": [], "entities": [{"text": "SMT paradigm", "start_pos": 95, "end_pos": 107, "type": "TASK", "confidence": 0.9377321898937225}, {"text": "translation divergences", "start_pos": 136, "end_pos": 159, "type": "TASK", "confidence": 0.9192123711109161}]}, {"text": "ii) Can these rules be properly extracted from existing syntactically annotated parallel treebanks?", "labels": [], "entities": []}, {"text": "iii) What are the advantages and challenges in building semantic representations that can bridge translation divergences?", "labels": [], "entities": [{"text": "translation divergences", "start_pos": 97, "end_pos": 120, "type": "TASK", "confidence": 0.8454917073249817}]}, {"text": "We try to answer these questions by identifying and categorizing actual translation divergences in a parallel treebank, and extracting (an enhanced form of ) hierarchical phrase pairs to see if the translation divergences can be captured by these hierarchical phrase pairs.", "labels": [], "entities": []}, {"text": "We then look into whether the translation divergences pose any challenge for attempts at devising semantic representations that are supposed to bridge the divergences.", "labels": [], "entities": []}, {"text": "To do this, we first manually align about 10,000 ChineseEnglish sentence pairs that have been manually parsed syntactically on both sides, and then semi-automatically extract and categorize translation divergences between the two languages.", "labels": [], "entities": [{"text": "translation divergences", "start_pos": 190, "end_pos": 213, "type": "TASK", "confidence": 0.8523089289665222}]}, {"text": "The manual alignment is hierarchical in that it is performed at both the word level (between terminal nodes) and the constituent level (between non-terminal nodes), and is done in away that eliminates conflicts and redundancies between word alignments and syntactic trees.", "labels": [], "entities": []}, {"text": "This is necessary in order not to generate spurious translation divergences.", "labels": [], "entities": []}, {"text": "The Chinese-English language pair is chosen for this study because parallel treebanks for these two languages can be readily found.", "labels": [], "entities": []}, {"text": "Manually constructed rather than automatically produced parse trees are used because we want to isolate genuine translation divergences resulting from different syntactic implications of our research for efforts to bridge translation divergences by devising semantic representations that are shared across languages.", "labels": [], "entities": []}, {"text": "We discuss related work in Section 6 and conclude the paper in Section 7.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1  Statistics of IAA.", "labels": [], "entities": [{"text": "IAA", "start_pos": 24, "end_pos": 27, "type": "TASK", "confidence": 0.4600261449813843}]}, {"text": " Table 2  Proportion of the TD types.", "labels": [], "entities": []}, {"text": " Table 3  TD instances with only one feature.", "labels": [], "entities": []}, {"text": " Table 4  Co-occurrence of TD features.", "labels": [], "entities": []}, {"text": " Table 5  TD instances with the AFW feature.", "labels": [], "entities": [{"text": "AFW", "start_pos": 32, "end_pos": 35, "type": "METRIC", "confidence": 0.7623953819274902}]}, {"text": " Table 7  Distribution of terminal nodes in rules.", "labels": [], "entities": []}]}