{"title": [{"text": "Hybrid Grammars for Parsing of Discontinuous Phrase Structures and Non-Projective Dependency Structures", "labels": [], "entities": [{"text": "Parsing of Discontinuous Phrase Structures", "start_pos": 20, "end_pos": 62, "type": "TASK", "confidence": 0.8278475642204285}]}], "abstractContent": [{"text": "We explore the concept of hybrid grammars, which formalize and generalize a range of existing frameworks for dealing with discontinuous syntactic structures.", "labels": [], "entities": []}, {"text": "Covered are both discontinuous phrase structures and non-projective dependency structures.", "labels": [], "entities": []}, {"text": "Technically, hybrid grammars are related to synchronous grammars, where one grammar component generates linear structures and another generates hierarchical structures.", "labels": [], "entities": []}, {"text": "By coupling lexical elements of both components together, discontinuous structures result.", "labels": [], "entities": []}, {"text": "Several types of hybrid grammars are characterized.", "labels": [], "entities": []}, {"text": "We also discuss grammar induction from treebanks.", "labels": [], "entities": [{"text": "grammar induction", "start_pos": 16, "end_pos": 33, "type": "TASK", "confidence": 0.8106503486633301}]}, {"text": "The main advantage over existing frameworks is the ability of hybrid grammars to separate discontinuity of the desired structures from time complexity of parsing.", "labels": [], "entities": []}, {"text": "This permits exploration of a large variety of parsing algorithms for discontinuous structures, with different properties.", "labels": [], "entities": []}, {"text": "This is confirmed by the reported experimental results, which show a wide variety of running time, accuracy, and frequency of parse failures.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 99, "end_pos": 107, "type": "METRIC", "confidence": 0.9987642765045166}]}], "introductionContent": [{"text": "Much of the theory of parsing assumes syntactic structures that are trees, formalized such that the children of each node are ordered, and the yield of a tree, that is, the leaves read from left to right, is the sentence.", "labels": [], "entities": []}, {"text": "In different terms, each node in the hierarchical syntactic structure of a sentence corresponds to a phrase that is a list of adjacent words, without any gaps.", "labels": [], "entities": []}, {"text": "Such a structure is easy to represent in terms of bracketed notation, which is used, for instance, in the Penn Treebank.", "labels": [], "entities": [{"text": "Penn Treebank", "start_pos": 106, "end_pos": 119, "type": "DATASET", "confidence": 0.9945179522037506}]}, {"text": "Describing syntax in terms of such narrowly defined trees seems most appropriate for relatively rigid word-order languages such as English.", "labels": [], "entities": []}, {"text": "Nonetheless, the aforementioned Penn Treebank of English contains traces and other elements that encode additional structure next to the pure tree structure as indicated by the brackets.", "labels": [], "entities": [{"text": "Penn Treebank of English", "start_pos": 32, "end_pos": 56, "type": "DATASET", "confidence": 0.9880792200565338}]}, {"text": "This is in keeping with observations that even English cannot be described adequately without a more general form of trees, allowing for so-called discontinuity.", "labels": [], "entities": []}, {"text": "Ina discontinuous structure, the set of leaves dominated by anode of the tree need not form a contiguous sequence of words, but may comprise one or more gaps.", "labels": [], "entities": []}, {"text": "The need for discontinuous structures tends to be even greater for languages with relatively free word order ().", "labels": [], "entities": []}, {"text": "In the context of dependency parsing, the more specific term non-projectivity is used instead of, or next to, discontinuity.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 18, "end_pos": 36, "type": "TASK", "confidence": 0.8357320427894592}]}, {"text": "See Rambow (2010) fora discussion of the relation between constituent and dependency structures and see fora comparison of discontinuity and nonprojectivity.", "labels": [], "entities": [{"text": "Rambow (2010)", "start_pos": 4, "end_pos": 17, "type": "DATASET", "confidence": 0.879747062921524}]}, {"text": "As shown by, for example, and, discontinuity encoded using traces in the Penn Treebank can be rendered in alternative, and arguably more explicit, forms.", "labels": [], "entities": [{"text": "Penn Treebank", "start_pos": 73, "end_pos": 86, "type": "DATASET", "confidence": 0.996178150177002}]}, {"text": "In many modern treebanks, discontinuous structures have been given a prominent status (e.g.,.", "labels": [], "entities": []}, {"text": "shows an example of a non-projective dependency structure.", "labels": [], "entities": []}, {"text": "The most established parsing algorithms are compiled out of context-free grammars (CFGs), or closely related formalisms such as tree substitution grammars or regular tree grammars.", "labels": [], "entities": []}, {"text": "These parsers, which have a time complexity of O(n 3 ) for n being the length of the input string, operate by composing adjacent substrings of the input sentence into longer substrings.", "labels": [], "entities": [{"text": "O", "start_pos": 47, "end_pos": 48, "type": "METRIC", "confidence": 0.9897537231445312}]}, {"text": "As a result, the structures they can build directly do not involve any discontinuity.", "labels": [], "entities": []}, {"text": "The need for discontinuous syntactic structures thus poses a challenge to traditional parsing algorithms.", "labels": [], "entities": []}, {"text": "One possible solution is commonly referred to as pseudo-projectivity in the literature on dependency parsing.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 90, "end_pos": 108, "type": "TASK", "confidence": 0.8344722390174866}]}, {"text": "A standard parsing system is trained on a corpus of projective dependency structures that was obtained by applying a lifting operation to non-projective structures.", "labels": [], "entities": []}, {"text": "Ina first pass, this system is applied to unlabeled sentences and produces projective dependencies.", "labels": [], "entities": []}, {"text": "Ina second pass, the lifting operation is reversed to introduce non-projectivity.", "labels": [], "entities": []}, {"text": "A related idea for discontinuous phrase structures is the reversible splitting conversion of.,, and.", "labels": [], "entities": []}, {"text": "The two passes of pseudo-projective dependency parsing need not be strictly separated in time.", "labels": [], "entities": [{"text": "pseudo-projective dependency parsing", "start_pos": 18, "end_pos": 54, "type": "TASK", "confidence": 0.6942114432652792}]}, {"text": "For example, one way to characterize the algorithm by  is that it combines the first pass with the second.", "labels": [], "entities": []}, {"text": "Here the usual one-way input tape is replaced by a buffer.", "labels": [], "entities": []}, {"text": "A non-topmost element from the parsing stack, which holds a word previously read from the input sentence, can be transferred back to the buffer, and 0 ROOT 1 A 2 hearing 3 is 4 scheduled 5 on 6 the 7 issue 8 today thereby input positions can be effectively swapped.", "labels": [], "entities": [{"text": "ROOT 1 A 2 hearing 3", "start_pos": 151, "end_pos": 171, "type": "METRIC", "confidence": 0.9195432563622793}]}, {"text": "This then results in a non-projective dependency structure.", "labels": [], "entities": []}, {"text": "A second potential solution to obtain syntactic structures that go beyond context-free power is to use more expressive grammatical formalisms.", "labels": [], "entities": []}, {"text": "One approach proposed by is to separate linear order from the parent-child relation in syntactic structure, and to allow shuffling of the order of descendants of anode, which need not be its direct children.", "labels": [], "entities": []}, {"text": "The set of possible orders is restricted by linear precedence constraints.", "labels": [], "entities": []}, {"text": "A further restriction maybe imposed by compaction (.", "labels": [], "entities": []}, {"text": "As discussed by and, this may lead to exponential parsing complexity; see also.", "labels": [], "entities": []}, {"text": "Separating linear order from the parent-child relation is in the tradition of headdriven phrase structure grammar (HPSG), where grammars are commonly hand-written.", "labels": [], "entities": [{"text": "Separating linear order", "start_pos": 0, "end_pos": 23, "type": "TASK", "confidence": 0.8665456970532736}, {"text": "headdriven phrase structure grammar (HPSG)", "start_pos": 78, "end_pos": 120, "type": "TASK", "confidence": 0.7767173945903778}]}, {"text": "This differs from our objectives to induce grammars automatically from training data, as will become clear in the following sections.", "labels": [], "entities": []}, {"text": "To stay within a polynomial time complexity, one may also consider tree adjoining grammars (TAGs), which can describe strictly larger classes of word order phenomena than.", "labels": [], "entities": []}, {"text": "The resulting parsers have a time complexity of O(n 6 ).", "labels": [], "entities": [{"text": "O", "start_pos": 48, "end_pos": 49, "type": "METRIC", "confidence": 0.9601294994354248}]}, {"text": "However, the derived trees they generate are still continuous.", "labels": [], "entities": []}, {"text": "Although their derivation trees maybe argued to be discontinuous, these by themselves are not normally the desired syntactic structures.", "labels": [], "entities": []}, {"text": "Moreover, it was argued by that further additions to TAGs are needed to obtain adequate descriptions of certain non-context-free phenomena.", "labels": [], "entities": [{"text": "TAGs", "start_pos": 53, "end_pos": 57, "type": "TASK", "confidence": 0.828628420829773}]}, {"text": "These additions further increase the time complexity.", "labels": [], "entities": []}, {"text": "In order to obtain desired syntactic structures, one may combine TAG parsing with an idea that is related to that of pseudo-projectivity.", "labels": [], "entities": [{"text": "TAG parsing", "start_pos": 65, "end_pos": 76, "type": "TASK", "confidence": 0.8744779825210571}]}, {"text": "For example, propose a transformation that turns a derivation tree of a (lexicalized) TAG into a non-projective dependency structure.", "labels": [], "entities": []}, {"text": "The same idea has been applied to derivation trees of other formalisms, in particular (lexicalized) linear context-free rewriting systems (LCFRSs)), whose weak generative power subsumes that of TAGs.", "labels": [], "entities": []}, {"text": "Parsers more powerful than those for CFGs often incur high time costs.", "labels": [], "entities": []}, {"text": "In particular, LCFRS parsers have a time complexity that is polynomial in the sentence length, but with a degree that is determined by properties of the grammar.", "labels": [], "entities": [{"text": "LCFRS parsers", "start_pos": 15, "end_pos": 28, "type": "TASK", "confidence": 0.6328702419996262}]}, {"text": "This degree typically increases with the amount of discontinuity in the desired structures.", "labels": [], "entities": []}, {"text": "Difficulties in running LCFRS parsers for natural languages are described, for example, by.", "labels": [], "entities": []}, {"text": "In the architectures we have discussed, the common elements are: r a grammar, in some fixed formalism, that determines the set of sentences that are accepted, and r a procedure to build (discontinuous) structures, guided by the derivation of input sentences.", "labels": [], "entities": []}, {"text": "The purpose of this article is to explore a theoretical framework that allows us to capture a wide range of parsing architectures that all share these two common elements.", "labels": [], "entities": []}, {"text": "At the core of this framework lies a formalism called hybrid grammar, introduced in.", "labels": [], "entities": []}, {"text": "Such a grammar consists of a string grammar and a tree grammar.", "labels": [], "entities": []}, {"text": "Derivations are coupled, as in synchronous grammars.", "labels": [], "entities": []}, {"text": "In addition, each occurrence of a terminal symbol in the string grammar is coupled to an occurrence of a terminal symbol in the tree grammar.", "labels": [], "entities": []}, {"text": "The string grammar defines the set of accepted sentences.", "labels": [], "entities": []}, {"text": "The tree grammar, whose rules are tied to the rules of the string grammar for synchronous rewriting, determines the resulting syntactic structures, which maybe discontinuous.", "labels": [], "entities": []}, {"text": "The way the syntactic structures are obtained critically relies on the coupling of terminal symbols in the two component grammars, which is where our theory departs from that of synchronous grammars.", "labels": [], "entities": []}, {"text": "A hybrid grammar generates a set of hybrid trees; 1 shows an example of a hybrid tree, which corresponds to the non-projective dependency structure of.", "labels": [], "entities": []}, {"text": "The general concept of hybrid grammars leaves open the choice of the string grammar formalism and that of the tree grammar formalism.", "labels": [], "entities": []}, {"text": "In this article we consider simple macro grammars and LCFRSs as string grammar formalisms.", "labels": [], "entities": []}, {"text": "The tree grammar formalisms we consider are simple context-free tree grammars and simple definite clause programs (sDCP), inspired by.", "labels": [], "entities": []}, {"text": "This gives four combinations, each leading to one class of hybrid grammars.", "labels": [], "entities": []}, {"text": "In addition, more fine-grained subclasses can be defined by placing further syntactic restrictions on the string and tree formalisms.", "labels": [], "entities": []}, {"text": "To place hybrid grammars in the context of existing parsing architectures, let us consider classical grammar induction from a treebank, for example, for context-free grammars or for LCFRSs.", "labels": [], "entities": []}, {"text": "Rules are extracted directly from the trees in the training set, and unseen input strings are consequently parsed according to these structures.", "labels": [], "entities": []}, {"text": "Grammars induced in this way can be seen as restricted hybrid grammars, in which no freedom exists in the relation between the string component and the tree component.", "labels": [], "entities": []}, {"text": "In particular, the presence of discontinuous structures generally leads to high time complexity of string parsing.", "labels": [], "entities": [{"text": "string parsing", "start_pos": 99, "end_pos": 113, "type": "TASK", "confidence": 0.6798205524682999}]}, {"text": "In contrast, the framework in this article detaches the string component of the grammar from the tree component.", "labels": [], "entities": []}, {"text": "Thereby the parsing process of input strings is no longer bound to follow the tree structures, while the same tree structures as before can still be produced, provided the tree component is suitably chosen.", "labels": [], "entities": []}, {"text": "This allows string parsing with low time complexity in combination with production of discontinuous trees.", "labels": [], "entities": [{"text": "string parsing", "start_pos": 12, "end_pos": 26, "type": "TASK", "confidence": 0.6564620435237885}]}, {"text": "presented experiments with various subclasses of hybrid grammars for the purpose of constituent parsing.", "labels": [], "entities": [{"text": "constituent parsing", "start_pos": 84, "end_pos": 103, "type": "TASK", "confidence": 0.6912777423858643}]}, {"text": "Trade-offs between speed and accuracy were identified.", "labels": [], "entities": [{"text": "speed", "start_pos": 19, "end_pos": 24, "type": "METRIC", "confidence": 0.9965619444847107}, {"text": "accuracy", "start_pos": 29, "end_pos": 37, "type": "METRIC", "confidence": 0.9991884827613831}]}, {"text": "In the present article, we extend our investigation to dependency parsing.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 55, "end_pos": 73, "type": "TASK", "confidence": 0.900288850069046}]}, {"text": "This includes induction of a hybrid grammar from a dependency treebank.", "labels": [], "entities": []}, {"text": "Before turning to the experiments, we present several completeness results about existence of hybrid grammars generating non-projective dependency structures.", "labels": [], "entities": []}, {"text": "This article is organized as follows.", "labels": [], "entities": []}, {"text": "After preliminaries in Section 2, Section 3 defines hybrid trees.", "labels": [], "entities": []}, {"text": "These are able to capture both discontinuous phrase structures and nonprojective dependency structures.", "labels": [], "entities": []}, {"text": "Thanks to the concept of hybrid trees, there will be no need, later in the article, to distinguish between hybrid grammars for constituent parsing and hybrid grammars for dependency parsing.", "labels": [], "entities": [{"text": "constituent parsing", "start_pos": 127, "end_pos": 146, "type": "TASK", "confidence": 0.7068287134170532}, {"text": "dependency parsing", "start_pos": 171, "end_pos": 189, "type": "TASK", "confidence": 0.7997167408466339}]}, {"text": "To make this article self-contained, we define two existing string grammar formalisms and two tree grammar formalisms in Section 4.", "labels": [], "entities": []}, {"text": "The four classes of hybrid grammars that result by combining these formalisms are presented in Section 5, which also discusses how to use them for parsing.", "labels": [], "entities": []}, {"text": "How to induce hybrid grammars from treebanks is discussed in Section 6.", "labels": [], "entities": []}, {"text": "Section 7 reports on experiments that provide proof of concept.", "labels": [], "entities": []}, {"text": "In particular, LCFRS/sDCP-hybrid grammars are induced from corpora of dependency structures and phrase structures and employed to predict the syntactic structure of unlabeled sentences.", "labels": [], "entities": []}, {"text": "It is demonstrated that hybrid grammars allow a wide variety of results, in terms of time complexity, accuracy, and frequency of parse failures.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 102, "end_pos": 110, "type": "METRIC", "confidence": 0.9992126226425171}]}, {"text": "How hybrid grammars relate to existing ideas is discussed in Section 8.", "labels": [], "entities": []}, {"text": "The text refers to a number of theoretical results that are not central to the main content of this article.", "labels": [], "entities": []}, {"text": "In order to preserve the continuity of the discussion, we have deferred their proofs to appendices.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section, we present the first experimental results on induction of LCFRS/sDCP hybrid grammars from dependency structures and their application to parsing.", "labels": [], "entities": []}, {"text": "We further present experiments on constituent parsing similar to those of, but now with a larger portion of the TIGER corpus ().", "labels": [], "entities": [{"text": "constituent parsing", "start_pos": 34, "end_pos": 53, "type": "TASK", "confidence": 0.6617295742034912}, {"text": "TIGER corpus", "start_pos": 112, "end_pos": 124, "type": "DATASET", "confidence": 0.7968228161334991}]}, {"text": "The purpose of the experiments is threefold: (i) A proof-of-concept for the induction techniques developed in Section 6 is provided.", "labels": [], "entities": []}, {"text": "(ii) The influence of the strategy of recursive partitioning is evaluated empirically, as is the influence of the nonterminal naming scheme.", "labels": [], "entities": []}, {"text": "We are particularly interested in how the strategy of recursive partitioning affects the size, parse time, accuracy, and robustness of the induced hybrid grammars.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 107, "end_pos": 115, "type": "METRIC", "confidence": 0.9965057373046875}]}, {"text": "(iii) The performance of our architecture for syntactic parsing based on LCFRS/sDCP hybrid grammar is compared with two existing parsing architectures.", "labels": [], "entities": [{"text": "syntactic parsing", "start_pos": 46, "end_pos": 63, "type": "TASK", "confidence": 0.6858827471733093}]}, {"text": "For all experiments, a corpus is split into a training set and a test set.", "labels": [], "entities": []}, {"text": "A LCFRS/sDCP hybrid grammar is induced from the training set.", "labels": [], "entities": []}, {"text": "Probabilities of rules are determined by relative frequency estimation.", "labels": [], "entities": []}, {"text": "The induced grammar is then applied on each sentence of the test set (see Section 5.3), and the parse obtained from the most probable derivation is compared with the gold standard, resulting in a score for each sentence.", "labels": [], "entities": []}, {"text": "The average of these scores for all test sentences is computed, weighted by sentence length.", "labels": [], "entities": []}, {"text": "All algorithms are implemented in Python and experiments are run on a server with two 2.6-GHz Intel Xeon E5-2630 v2 CPUs and 64 GB of RAM.", "labels": [], "entities": []}, {"text": "Each experiment uses a single thread; the measured running time might be slightly distorted because of the usual load jitter.", "labels": [], "entities": []}, {"text": "For probabilistic LCFRS parsing we use two off-the-shelf systems: If the induced grammar's first component is equivalent to a FA, then we use the OpenFST () framework with the Python bindings of.", "labels": [], "entities": [{"text": "LCFRS parsing", "start_pos": 18, "end_pos": 31, "type": "TASK", "confidence": 0.8233267962932587}, {"text": "FA", "start_pos": 126, "end_pos": 128, "type": "METRIC", "confidence": 0.9724858999252319}]}, {"text": "Otherwise, we utilize the LCFRS parser of, which is part of the runtime system of the Grammatical Framework (Ranta 2011).", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2  Experiments with dependency parsing (TIGER in CoNLL 2006 shared task): method of recursive  partitioning for extraction, argument label, number of nonterminals and rules, maximum and  average fanout, number of parse failures, unlabeled attachment score, labeled attachment score,  label accuracy, and parse time in seconds.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 27, "end_pos": 45, "type": "TASK", "confidence": 0.7632416188716888}, {"text": "TIGER in CoNLL 2006 shared task)", "start_pos": 47, "end_pos": 79, "type": "DATASET", "confidence": 0.773727297782898}, {"text": "accuracy", "start_pos": 297, "end_pos": 305, "type": "METRIC", "confidence": 0.7573064565658569}]}, {"text": " Table 3  Experiments with dependency parsing (NEGRA). From the sentences with length \u2264 25, the first  14,858 make up the training corpus and the remaining 1,651 the test corpus. Additionally to the  columns in", "labels": [], "entities": [{"text": "dependency parsing (NEGRA)", "start_pos": 27, "end_pos": 53, "type": "TASK", "confidence": 0.732798957824707}]}, {"text": " Table 4  Experiments for constituent parsing (TIGER). Number of nonterminals, rules, and parse failures,  recall, precision, F-measure, average number of gaps per constituent, and parse time in seconds.", "labels": [], "entities": [{"text": "constituent parsing (TIGER)", "start_pos": 26, "end_pos": 53, "type": "TASK", "confidence": 0.7381510496139526}, {"text": "recall", "start_pos": 107, "end_pos": 113, "type": "METRIC", "confidence": 0.9990450739860535}, {"text": "precision", "start_pos": 115, "end_pos": 124, "type": "METRIC", "confidence": 0.9994693398475647}, {"text": "F-measure", "start_pos": 126, "end_pos": 135, "type": "METRIC", "confidence": 0.9966866374015808}]}]}