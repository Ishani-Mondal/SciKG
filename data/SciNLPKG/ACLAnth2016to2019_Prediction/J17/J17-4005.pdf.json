{"title": [{"text": "Multiword Expression Processing: A Survey under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International (CC BY-NC-ND 4.0) license Computational Linguistics", "labels": [], "entities": [{"text": "Multiword Expression Processing", "start_pos": 0, "end_pos": 31, "type": "TASK", "confidence": 0.8702937364578247}]}], "abstractContent": [{"text": "Multiword expressions (MWEs) area class of linguistic forms spanning conventional word boundaries that are both idiosyncratic and pervasive across different languages.", "labels": [], "entities": []}, {"text": "The structure of linguistic processing that depends on the clear distinction between words and phrases has to be rethought to accommodate MWEs.", "labels": [], "entities": []}, {"text": "The issue of MWE handling is crucial for NLP applications, where it raises a number of challenges.", "labels": [], "entities": [{"text": "MWE handling", "start_pos": 13, "end_pos": 25, "type": "TASK", "confidence": 0.988004207611084}]}, {"text": "The emergence of solutions in the absence of guiding principles motivates this survey, whose aim is not only to provide a focused review Volume 43, Number 4 of MWE processing, but also to clarify the nature of interactions between MWE processing and downstream applications.", "labels": [], "entities": [{"text": "MWE processing", "start_pos": 160, "end_pos": 174, "type": "TASK", "confidence": 0.926166296005249}, {"text": "MWE processing", "start_pos": 231, "end_pos": 245, "type": "TASK", "confidence": 0.8667756915092468}]}, {"text": "We propose a conceptual framework within which challenges and research contributions can be positioned.", "labels": [], "entities": []}, {"text": "It offers a shared understanding of what is meant by \"MWE processing,\" distinguishing the subtasks of MWE discovery and identification.", "labels": [], "entities": [{"text": "MWE processing", "start_pos": 54, "end_pos": 68, "type": "TASK", "confidence": 0.9546233415603638}, {"text": "MWE discovery and identification", "start_pos": 102, "end_pos": 134, "type": "TASK", "confidence": 0.8858395367860794}]}, {"text": "It also elucidates the interactions between MWE processing and two use cases: Parsing and machine translation.", "labels": [], "entities": [{"text": "MWE processing", "start_pos": 44, "end_pos": 58, "type": "TASK", "confidence": 0.9736811518669128}, {"text": "Parsing", "start_pos": 78, "end_pos": 85, "type": "TASK", "confidence": 0.9726961255073547}, {"text": "machine translation", "start_pos": 90, "end_pos": 109, "type": "TASK", "confidence": 0.7789692282676697}]}, {"text": "Many of the approaches in the literature can be differentiated according to how MWE processing is timed with respect to underlying use cases.", "labels": [], "entities": [{"text": "MWE processing", "start_pos": 80, "end_pos": 94, "type": "TASK", "confidence": 0.9645850360393524}]}, {"text": "We discuss how such orchestration choices affect the scope of MWE-aware systems.", "labels": [], "entities": [{"text": "MWE-aware", "start_pos": 62, "end_pos": 71, "type": "TASK", "confidence": 0.8796115517616272}]}, {"text": "For each of the two MWE processing subtasks and for each of the two use cases, we conclude on open issues and research perspectives.", "labels": [], "entities": [{"text": "MWE processing subtasks", "start_pos": 20, "end_pos": 43, "type": "TASK", "confidence": 0.871548593044281}]}], "introductionContent": [{"text": "Traditional formal descriptions of individual human languages typically divide labor between a repository of words and their properties, called a lexicon, and a description of how such words combine to form larger units, called a grammar.", "labels": [], "entities": []}, {"text": "These two elements provide a systematic but finite basis for computing the properties of any syntactically legitimate sentence.", "labels": [], "entities": []}, {"text": "Although grammatical theories differ about the nature of lexical versus grammatical information and their manner of interaction, a particular theory must establish what counts as a word in order to pin down what the lexicon should contain.", "labels": [], "entities": []}, {"text": "As, among others, have pointed out, the question of what constitutes a word is surprisingly complex, and one reason for this is the predominance in everyday language of elements known as multiword expressions.", "labels": [], "entities": []}, {"text": "MWEs consist of several words (in the conventionally understood sense) but behave as single words to some extent.", "labels": [], "entities": []}, {"text": "This is well illustrated by an expression like by and large, which any English speaker knows can have roughly equivalent meaning and syntactic function to mostly, an adverb.", "labels": [], "entities": []}, {"text": "Among the problematic characteristics of this expression are (1) syntactic anomaly of the part-of-speech (POS) sequence preposition + conjunction + adjective, (2) non-compositionality: semantics of the whole that is unrelated to the individual pieces, (3) non-substitutability of synonym words (e.g., by and big), and (4) ambiguity between MWE and non-MWE readings of a substring by and large (e.g., by and large we agree versus he walked by and large tractors passed him).", "labels": [], "entities": []}, {"text": "Although these characteristics by no means exhaust the list of peculiarities, the idiosyncratic nature of the expression is plain, leading us to ask where its pertinent characteristics should be stored.", "labels": [], "entities": []}, {"text": "The traditional division of labor gives us two optionsthe lexicon or the grammar-but MWEs disrupt the tradition precisely because they are more than one word long (.", "labels": [], "entities": []}, {"text": "Their idiosyncrasy suggests that they belong in the lexicon, yet, being constructed out of more than one word, they would also fall within the traditional scope of grammar, even if constituted (cf. by and large) from non-standard sequences of syntactic categories.", "labels": [], "entities": []}, {"text": "As we shall soon see, the glue that can hold an MWE together often involves grammatical relations between the subparts, so that the structure of linguistic processing tasks such as parsing and machine translation (MT), which depends on a normally clear distinction between word tokens and phrases, has to be re-thought to accommodate MWEs.", "labels": [], "entities": [{"text": "parsing and machine translation (MT)", "start_pos": 181, "end_pos": 217, "type": "TASK", "confidence": 0.7506838398320335}]}, {"text": "The issue of MWE handling goes to the heart of natural language processing (NLP) where it raises a number of MWE Processing: A Survey fundamental problems with a frequency that cannot be ignored.", "labels": [], "entities": [{"text": "MWE handling", "start_pos": 13, "end_pos": 25, "type": "TASK", "confidence": 0.9841641187667847}, {"text": "natural language processing (NLP)", "start_pos": 47, "end_pos": 80, "type": "TASK", "confidence": 0.7469744185606638}, {"text": "MWE Processing", "start_pos": 109, "end_pos": 123, "type": "TASK", "confidence": 0.9157026708126068}]}, {"text": "Not surprisingly, it has been and still is a main item on the agenda of several working groups such as the PARSEME network, of which the authors of this article are members.", "labels": [], "entities": [{"text": "PARSEME network", "start_pos": 107, "end_pos": 122, "type": "DATASET", "confidence": 0.7989121973514557}]}, {"text": "The main aim of this survey is to shed light on how MWEs are handled in NLP applications.", "labels": [], "entities": [{"text": "MWEs", "start_pos": 52, "end_pos": 56, "type": "TASK", "confidence": 0.9632092714309692}]}, {"text": "More particularly, it tries to clarify the nature of interactions between MWE processing and downstream applications such as MWE-aware parsing and MT.", "labels": [], "entities": [{"text": "MWE processing", "start_pos": 74, "end_pos": 88, "type": "TASK", "confidence": 0.8410334587097168}, {"text": "MWE-aware parsing", "start_pos": 125, "end_pos": 142, "type": "TASK", "confidence": 0.7885370850563049}, {"text": "MT", "start_pos": 147, "end_pos": 149, "type": "TASK", "confidence": 0.94317626953125}]}, {"text": "There is no shortage of proposed approaches for MWE processing and MWE-aware NLP applications.", "labels": [], "entities": [{"text": "MWE processing", "start_pos": 48, "end_pos": 62, "type": "TASK", "confidence": 0.9677854180335999}, {"text": "MWE-aware NLP", "start_pos": 67, "end_pos": 80, "type": "TASK", "confidence": 0.7592177391052246}]}, {"text": "In fact, it is the emergence of approaches in the absence of guiding principles that motivates this article.", "labels": [], "entities": []}, {"text": "There have been other surveys and reviews about MWEs with different scopes.", "labels": [], "entities": []}, {"text": "Some concentrate primarily on their linguistic characteristics.", "labels": [], "entities": []}, {"text": "Although this is a valid area of linguistic research, it is not of primary interest to researchers who are addressing the design of computational solutions to the spectrum of problems that MWEs bring into focus.", "labels": [], "entities": []}, {"text": "Others are bibliographical reviews/state-of-the-art overviews done in the context of Ph.D. theses) or book chapters, with a narrow scope focusing only on a specific part of MWE processing.", "labels": [], "entities": [{"text": "MWE processing", "start_pos": 173, "end_pos": 187, "type": "TASK", "confidence": 0.9378543496131897}]}, {"text": "In these studies, the subject area is relevant, but the work surveyed tends to be on the micro scale and misses the higher-level insights that one hopes might emerge from the study of such a pervasive phenomenon.", "labels": [], "entities": []}, {"text": "Several journal special issues on MWEs ( area showcase for outstanding research in the field, but do not provide abroad overview.", "labels": [], "entities": []}, {"text": "In short, a big picture is missing from existing reviews and without one it is difficult to compare individual solutions or to reveal that ostensibly different solutions might actually share similar characteristics.", "labels": [], "entities": []}, {"text": "To overcome these shortcomings we felt that it was necessary to create a conceptual framework within which both the problems and the different research contributions could be positioned.", "labels": [], "entities": []}, {"text": "The goals of this survey are the following: r Provide a focused overview of how MWEs are handled in NLP applications, thereby focusing on MWE processing rather than MWEs as a linguistic phenomenon, and their surprising frequency.", "labels": [], "entities": [{"text": "MWE processing", "start_pos": 138, "end_pos": 152, "type": "TASK", "confidence": 0.8877366185188293}]}, {"text": "The awkwardness arises from the way in which they transcend boundaries imposed by the different subfields of morphology, lexicology, syntax, and semantics.", "labels": [], "entities": []}, {"text": "Their lack of homogeneity has led to various categorization schemes that we discuss further subsequently.", "labels": [], "entities": []}, {"text": "Definitions observed in the literature are not exactly in disagreement, but tend to stress different aspects according to the identified MWE categories under consideration.", "labels": [], "entities": []}, {"text": "Here is an illustrative selection: r \"a multiword unit or a collocation of words that co-occur together statistically more than chance\" r \"a sequence of words that acts as a single unit at some level of linguistic analysis\" ( r \"idiosyncratic interpretations that crossword boundaries\" ( r \"lexical items that: (a) can be decomposed into multiple lexemes; and (b) display lexical, syntactic, semantic, pragmatic and/or statistical idiomaticity\" ( The first two focus mainly on the essential structural aspects of MWEs evidenced by the unusual co-occurrence of two or more elements within a template of some kind.", "labels": [], "entities": []}, {"text": "The complexity of the template can vary widely, from a simple sequence of two fixed words, to longer sequences of less tightly specified elements (e.g., lexemes) constrained by syntactic and/or semantic relationships, with the possibility of intervening gaps.", "labels": [], "entities": []}, {"text": "The third definition emphasizes the essentially idiosyncratic semantic aspect of MWEs, evidenced by degrees of non-compositionality in arriving at the interpretation of the whole from the several parts.", "labels": [], "entities": []}, {"text": "In this article we subscribe to the fourth definition, by, which captures both of these aspects-that is, outstanding co-occurrence (i.e., collocation or statistical idiomaticity) and generalized non-compositionality (i.e., lexical, syntactic, semantic, and pragmatic idiomaticity).", "labels": [], "entities": []}, {"text": "This definition also emphasizes that the anomalies of MWEs are manifest over different linguistic levels.", "labels": [], "entities": []}, {"text": "As mentioned earlier, MWEs are not homogeneous and have been categorized using different schemes.", "labels": [], "entities": []}, {"text": "The following list defines categories of MWEs commonly seen in the literature.", "labels": [], "entities": []}, {"text": "These categories are non-exhaustive and can overlap.", "labels": [], "entities": []}, {"text": "They cover the examples mentioned in this article: r An idiom is a group of lexemes whose meaning is established by convention and cannot be deduced from the individual lexemes composing the expression (e.g., to kick the bucket).", "labels": [], "entities": []}, {"text": "r A light-verb construction is formed by ahead verb with light semantics that becomes fully specified when combined with a (directly or indirectly) dependent predicative noun (e.g., to take a shower).", "labels": [], "entities": []}, {"text": "2 r A verb-particle construction comprises a verb and a particle, usually a preposition or adverb, which modifies the meaning of the verb and which needs not be immediately adjacent to it (e.g., to give up).", "labels": [], "entities": []}, {"text": "Verb-particle it is easy to capture using statistical association measures (Section 2.2.1).", "labels": [], "entities": []}, {"text": "Conversely, prominent co-occurrence is problematic for MT, because word-for-word translation might lead to translations of words that are suitable individually, but that yield nonfluent or ambiguous translations of MWEs.", "labels": [], "entities": [{"text": "MT", "start_pos": 55, "end_pos": 57, "type": "TASK", "confidence": 0.9920463562011719}]}, {"text": "For instance, the Italian expression compilare un modulo has to be translated into English as to fill in a form rather than the word-forword translation to compile a module.", "labels": [], "entities": []}, {"text": "Discontiguity, whereby alien elements can intervene between core MWE components, is a challenge for MWE processing.", "labels": [], "entities": [{"text": "MWE processing", "start_pos": 100, "end_pos": 114, "type": "TASK", "confidence": 0.9727339744567871}]}, {"text": "For instance, the Portuguese expression levar em conta (to take into account) licenses a direct object that can either appear after the idiom, like in ele levou em conta minha opini\u00e3o (he took into account my opinion) or between the verb and the fixed prepositional complement, like in ele levou minh\u00e3o opini\u00e3o em conta (he took my opinion into account).", "labels": [], "entities": []}, {"text": "Discriminating the intervening words from the core can be non-trivial but if they form a single syntactic constituent, as in the example, the task can be facilitated by syntactic analysis, thus creating an opportunity for parsing.", "labels": [], "entities": []}, {"text": "Non-compositionality is prototypical in idioms such as the French nominal compound fleur bleue (lit. blue flower).", "labels": [], "entities": []}, {"text": "This expression is used to characterize a sentimental and often naive person, so its meaning is completely opaque to speakers who only know the meanings of the individual words.", "labels": [], "entities": []}, {"text": "This property is a challenge for MT because translating non-compositional MWEs through the individual words or structures will very often yield an inappropriate translation.", "labels": [], "entities": [{"text": "MT", "start_pos": 33, "end_pos": 35, "type": "TASK", "confidence": 0.9941293001174927}]}, {"text": "The problem of non-compositionality of MWEs requires a strategy aiming to correctly identify the borders of MWEs and to find the associated sense of the expression.", "labels": [], "entities": []}, {"text": "For example, the Romanian idiom a i-o coace cuiva (lit.", "labels": [], "entities": []}, {"text": "to bake it for someone) should be translated in English as to prepare a trap/prank/ambush.", "labels": [], "entities": []}, {"text": "Several strategies use external resources, often the fruits of MWE discovery, to identify MWEs and their equivalents.", "labels": [], "entities": [{"text": "MWE discovery", "start_pos": 63, "end_pos": 76, "type": "TASK", "confidence": 0.9461165368556976}]}, {"text": "Conversely, non-literal translations can serve as a cue for ranking non-compositional MWEs such as idioms during MWE discovery.", "labels": [], "entities": [{"text": "MWE discovery", "start_pos": 113, "end_pos": 126, "type": "TASK", "confidence": 0.9342555105686188}]}, {"text": "Ambiguity is a challenge for many NLP tasks.", "labels": [], "entities": []}, {"text": "The type of ambiguity that impacts MWE processing the most is the choice between a compositional and an MWE reading of a sequence of words, as illustrated by the sentence I am struck by the way the rest of the world is confident of a better future.", "labels": [], "entities": [{"text": "MWE processing", "start_pos": 35, "end_pos": 49, "type": "TASK", "confidence": 0.9582479298114777}, {"text": "MWE reading of a sequence of words", "start_pos": 104, "end_pos": 138, "type": "TASK", "confidence": 0.7206180351121085}]}, {"text": "In most cases the sequence of words by the way is an MWE with the approximate meaning of incidentally.", "labels": [], "entities": []}, {"text": "However, in the example it is a regular prepositional complement of the verb struck.", "labels": [], "entities": []}, {"text": "In some cases, syntactic analysis can aid in determining whether the sequence of words should be recognized as an MWE.", "labels": [], "entities": []}, {"text": "An analysis that takes by the way to bean MWE and thus an adverb in this case, will yield an ungrammatical sentence (which becomes clear when we replace by the way with incidentally: I am struck incidentally the rest of the world . .", "labels": [], "entities": []}, {"text": "). Parsing can help reveal the relevant subcategorization frame that includes the preposition selected by the verb.", "labels": [], "entities": []}, {"text": "Variability, that is, the fact that MWEs allow for varying degrees of flexibility in their formation, poses great challenges for their identification.", "labels": [], "entities": []}, {"text": "Searching for fixed forms only will lead to low recall, because the fixed form will fail to match all possible variations.", "labels": [], "entities": [{"text": "recall", "start_pos": 48, "end_pos": 54, "type": "METRIC", "confidence": 0.9996053576469421}]}, {"text": "For example, een graantje meepikken (lit. to pick a grain with the others) is a Dutch MWE meaning to benefit from something as aside effect.", "labels": [], "entities": []}, {"text": "Just searching for the fixed string graantje meepikken will not identify Zij pikken er hun graantje van mee (lit.", "labels": [], "entities": []}, {"text": "they pick their grain of something with the others), meaning that they are benefiting from something as aside effect.", "labels": [], "entities": []}, {"text": "However, syntactic analysis can help us identify the parts of this MWE that allow for variation, here the determiner that can be changed into a possessive pronoun.", "labels": [], "entities": []}, {"text": "The problem becomes more serious in morphologically rich languages where words may take hundreds of different surface forms.", "labels": [], "entities": []}, {"text": "For example, the Turkish MWE kafa \u00e7ekmek (lit. to pull head), referring to consuming alcohol, may appear in 842 MWE Processing: A Survey many different surface forms such as kafalar\u0131 \u00e7ekelim (lit. let's pull the heads), kafay\u0131 \u00e7ektim (lit. I pulled the head), kafay\u0131 \u00e7ektin (lit. You pulled the head), kafalar\u0131 \u00e7ekecekler (lit.", "labels": [], "entities": [{"text": "Turkish MWE kafa \u00e7ekmek (lit. to pull head)", "start_pos": 17, "end_pos": 60, "type": "TASK", "confidence": 0.5805282145738602}]}, {"text": "They will pull the heads), among many more under different number and person agreements and tenses.", "labels": [], "entities": []}], "datasetContent": [{"text": "The application of MWE identification in parsing and MT opens up possibilities for extrinsic evaluation of the former.", "labels": [], "entities": [{"text": "MWE identification", "start_pos": 19, "end_pos": 37, "type": "TASK", "confidence": 0.9655620157718658}, {"text": "parsing", "start_pos": 41, "end_pos": 48, "type": "TASK", "confidence": 0.978789746761322}, {"text": "MT", "start_pos": 53, "end_pos": 55, "type": "TASK", "confidence": 0.9911200404167175}]}, {"text": "By assessing the quality of parsers and MT systems that incorporate various automatic MWE identification methods, and comparing results, the contribution of individual MWE identification methods can be estimated.", "labels": [], "entities": [{"text": "MT", "start_pos": 40, "end_pos": 42, "type": "TASK", "confidence": 0.9481989741325378}, {"text": "MWE identification", "start_pos": 86, "end_pos": 104, "type": "TASK", "confidence": 0.9433146119117737}, {"text": "MWE identification", "start_pos": 168, "end_pos": 186, "type": "TASK", "confidence": 0.8909641206264496}]}, {"text": "Similarly, MWE discovery can be evaluated extrinsically by testing the usefulness of (semi-)automatically created MWE lists for identification.", "labels": [], "entities": [{"text": "MWE discovery", "start_pos": 11, "end_pos": 24, "type": "TASK", "confidence": 0.9708728194236755}]}, {"text": "The intrinsic evaluation of MWE discovery and MWE identification, on which more details can be found in Sections 2 and 3, is non-trivial, among other things because of the lack of available test data.", "labels": [], "entities": [{"text": "MWE discovery", "start_pos": 28, "end_pos": 41, "type": "TASK", "confidence": 0.9901801645755768}, {"text": "MWE identification", "start_pos": 46, "end_pos": 64, "type": "TASK", "confidence": 0.9743227362632751}]}, {"text": "Evaluating MWE processing extrinsically through the use cases of parsing and MT is an attractive alternative.", "labels": [], "entities": [{"text": "MWE processing", "start_pos": 11, "end_pos": 25, "type": "TASK", "confidence": 0.9591255486011505}, {"text": "parsing", "start_pos": 65, "end_pos": 72, "type": "TASK", "confidence": 0.9803358316421509}, {"text": "MT", "start_pos": 77, "end_pos": 79, "type": "TASK", "confidence": 0.939426839351654}]}, {"text": "However, as Sections 4 and 5 will further specify, caution is needed when measuring the impact of MWE identification on, for example, parsing quality.", "labels": [], "entities": [{"text": "MWE identification", "start_pos": 98, "end_pos": 116, "type": "TASK", "confidence": 0.9654126465320587}, {"text": "parsing", "start_pos": 134, "end_pos": 141, "type": "TASK", "confidence": 0.9877620935440063}]}, {"text": "Depending on the type of orchestration at hand, different evaluation strategies should be adopted in order to avoid misleading conclusions.", "labels": [], "entities": []}, {"text": "Discovery is a process whose goal is to find new lexical entries.", "labels": [], "entities": []}, {"text": "Its evaluation is tricky because the utility and relevance of these entries is hard to assess.", "labels": [], "entities": []}, {"text": "Most discovery methods output ranked MWE lists, which can be evaluated as follows: r Post hoc human judgments: Given the top n MWEs retrieved by a method, experts select the relevant ones.", "labels": [], "entities": []}, {"text": "The proportion of positive entries found is used to evaluate the method (da r Dictionaries: The returned list can be automatically evaluated by checking the entries already present in a gold standard dictionary.", "labels": [], "entities": []}, {"text": "This assumes that entries absent from the dictionary are wrong (Ramisch, De Araujo, and Villavicencio 2012; r Dedicated data sets: Given a list of known positive and negative MWE examples, true MWEs should be ranked first.", "labels": [], "entities": []}, {"text": "This can be seen as an information retrieval problem, and measures like average precision, precision at k, recall, and F1 can be used to evaluate the discovery method.", "labels": [], "entities": [{"text": "information retrieval", "start_pos": 23, "end_pos": 44, "type": "TASK", "confidence": 0.7491834163665771}, {"text": "precision", "start_pos": 80, "end_pos": 89, "type": "METRIC", "confidence": 0.7972545623779297}, {"text": "precision", "start_pos": 91, "end_pos": 100, "type": "METRIC", "confidence": 0.9989883303642273}, {"text": "recall", "start_pos": 107, "end_pos": 113, "type": "METRIC", "confidence": 0.9990857839584351}, {"text": "F1", "start_pos": 119, "end_pos": 121, "type": "METRIC", "confidence": 0.9997233748435974}]}, {"text": "The evaluation of MWE identification must take all the challenges mentioned in Section 3.1 into account.", "labels": [], "entities": [{"text": "MWE identification", "start_pos": 18, "end_pos": 36, "type": "TASK", "confidence": 0.9856227040290833}]}, {"text": "Automatic evaluation is possible if we compare the output of the MWE tagger with manually annotated sentences on a given test set using traditional measures such as precision, recall, and F-measure.", "labels": [], "entities": [{"text": "MWE tagger", "start_pos": 65, "end_pos": 75, "type": "TASK", "confidence": 0.6039243638515472}, {"text": "precision", "start_pos": 165, "end_pos": 174, "type": "METRIC", "confidence": 0.9994379878044128}, {"text": "recall", "start_pos": 176, "end_pos": 182, "type": "METRIC", "confidence": 0.9971543550491333}, {"text": "F-measure", "start_pos": 188, "end_pos": 197, "type": "METRIC", "confidence": 0.9963740706443787}]}, {"text": "However, these measures are based on full-MWE comparison and ignore partial matches (Constant, Sigogne, and Watrin 2012).", "labels": [], "entities": []}, {"text": "Link-based precision and recall, inspired by the Message Understanding Conference criterion for coreference resolution, can be used to distinguish taggers that can identify only part of an MWE from systems that do not recognize it at all ().", "labels": [], "entities": [{"text": "precision", "start_pos": 11, "end_pos": 20, "type": "METRIC", "confidence": 0.981928825378418}, {"text": "recall", "start_pos": 25, "end_pos": 31, "type": "METRIC", "confidence": 0.9987015724182129}, {"text": "coreference resolution", "start_pos": 96, "end_pos": 118, "type": "TASK", "confidence": 0.9560237228870392}]}, {"text": "It is also possible to consider partial matches on MWEs by taking the maximum precision and recall among all possible token alignments between the prediction and the gold standard ().", "labels": [], "entities": [{"text": "precision", "start_pos": 78, "end_pos": 87, "type": "METRIC", "confidence": 0.9982370138168335}, {"text": "recall", "start_pos": 92, "end_pos": 98, "type": "METRIC", "confidence": 0.9991175532341003}]}, {"text": "It is worth noting that current partial matching evaluation metrics are not completely satisfactory and should be further investigated.", "labels": [], "entities": [{"text": "partial matching evaluation", "start_pos": 32, "end_pos": 59, "type": "TASK", "confidence": 0.7658286492029825}]}, {"text": "Indeed, these metrics do not take into account the \"importance\" of tokens within the whole expression.", "labels": [], "entities": []}, {"text": "For instance, if the tagger identifies into account instead of the whole expression take into account, which is partially correct, it misses the syntactic head of the expression and this will cause a downstream semantic parser to fail.", "labels": [], "entities": []}, {"text": "We could therefore assume that partial matching evaluation metrics should strongly penalize the system in that case.", "labels": [], "entities": []}, {"text": "In the other extreme case, sometimes missing some tokens or identifying additional tokens might not harm semantic analysis.", "labels": [], "entities": [{"text": "semantic analysis", "start_pos": 105, "end_pos": 122, "type": "TASK", "confidence": 0.8724303245544434}]}, {"text": "For instance, in the sentence John had a bath, the inclusion of the determiner a as a lexicalized element of the light-verb construction have_bath is questionable and a tagging error on this element should not be strongly penalized.", "labels": [], "entities": []}, {"text": "The other way around, missing had and bath, which are obligatory elements, should be strongly penalized.", "labels": [], "entities": []}, {"text": "Evaluation metrics using weighting schemes that assess partial matches by the \"importance\" of the tokens should be developed in the future.", "labels": [], "entities": []}, {"text": "Many advances in the development of better evaluation metrics area by-product of shared tasks on MWE identification.", "labels": [], "entities": [{"text": "MWE identification", "start_pos": 97, "end_pos": 115, "type": "TASK", "confidence": 0.969836562871933}]}, {"text": "The DiMSUM shared task for joint identification and supersense tagging of MWEs in English has put identification in focus ().", "labels": [], "entities": [{"text": "supersense tagging of MWEs", "start_pos": 52, "end_pos": 78, "type": "TASK", "confidence": 0.8144824802875519}]}, {"text": "Among the proposed systems, sequence taggers and the use of clustering methods for generalization seem to bring good results.", "labels": [], "entities": [{"text": "sequence taggers", "start_pos": 28, "end_pos": 44, "type": "TASK", "confidence": 0.7802852690219879}]}, {"text": "The results of the PARSEME shared task on verbal MWE identification () confirm that sequence taggers can perform as well as parsing-based approaches, depending on the language and on the proportion of discontiguous MWEs.", "labels": [], "entities": [{"text": "PARSEME shared task", "start_pos": 19, "end_pos": 38, "type": "TASK", "confidence": 0.48465631405512494}, {"text": "MWE identification", "start_pos": 49, "end_pos": 67, "type": "TASK", "confidence": 0.9108601212501526}]}, {"text": "Extrinsic evaluation of MWE identification has also been performed.", "labels": [], "entities": [{"text": "MWE identification", "start_pos": 24, "end_pos": 42, "type": "TASK", "confidence": 0.987626314163208}]}, {"text": "Identifying (discontiguous) MWEs influences the performance of information retrieval (Doucet and Ahonen-Myka 2004) and word sense disambiguation (.", "labels": [], "entities": [{"text": "Identifying (discontiguous) MWEs", "start_pos": 0, "end_pos": 32, "type": "TASK", "confidence": 0.6403073012828827}, {"text": "information retrieval", "start_pos": 63, "end_pos": 84, "type": "TASK", "confidence": 0.7154584228992462}, {"text": "word sense disambiguation", "start_pos": 119, "end_pos": 144, "type": "TASK", "confidence": 0.7040048042933146}]}, {"text": "Evaluation of identification when performed before parsing (Section 4.2) or before MT (Section 5.2) is detailed in the corresponding sections.", "labels": [], "entities": [{"text": "parsing", "start_pos": 51, "end_pos": 58, "type": "TASK", "confidence": 0.9529776573181152}, {"text": "MT", "start_pos": 83, "end_pos": 85, "type": "TASK", "confidence": 0.8692480325698853}]}, {"text": "Evaluating a syntactic parser generally consists of comparing the output to reference (gold standard) parses from a manually labeled treebank.", "labels": [], "entities": [{"text": "Evaluating a syntactic parser", "start_pos": 0, "end_pos": 29, "type": "TASK", "confidence": 0.6627066880464554}]}, {"text": "In the case of constituency parsing, a constituent is treated as correct if there exists a constituent in the gold standard parse with the same labels and starting and ending points.", "labels": [], "entities": [{"text": "constituency parsing", "start_pos": 15, "end_pos": 35, "type": "TASK", "confidence": 0.7897912561893463}]}, {"text": "These parsers are traditionally evaluated through precision, recall, and F-measure metrics.", "labels": [], "entities": [{"text": "precision", "start_pos": 50, "end_pos": 59, "type": "METRIC", "confidence": 0.9992697834968567}, {"text": "recall", "start_pos": 61, "end_pos": 67, "type": "METRIC", "confidence": 0.9976038336753845}, {"text": "F-measure", "start_pos": 73, "end_pos": 82, "type": "METRIC", "confidence": 0.9876267313957214}]}, {"text": "In standard dependency parsing with the single-head constraint, the number of dependencies produced by the parser should be equal to the number of total dependencies in the gold-standard parse tree.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 12, "end_pos": 30, "type": "TASK", "confidence": 0.6594062596559525}]}, {"text": "Common metrics to evaluate these parsers include the percentage of tokens with correct head, called unlabeled attachment score (UAS), and the percentage of tokens with correct head and dependency label, called labeled attachment score (LAS).", "labels": [], "entities": [{"text": "unlabeled attachment score (UAS)", "start_pos": 100, "end_pos": 132, "type": "METRIC", "confidence": 0.8157838135957718}, {"text": "labeled attachment score (LAS)", "start_pos": 210, "end_pos": 240, "type": "METRIC", "confidence": 0.811071515083313}]}, {"text": "The evaluation of identification and discovery has been discussed in previous sections.", "labels": [], "entities": [{"text": "identification and discovery", "start_pos": 18, "end_pos": 46, "type": "TASK", "confidence": 0.6526607771714529}]}, {"text": "However, evaluation of MWE-aware parsers and of whether or not MWE identification helps to improve the parsing quality requires some additional care.", "labels": [], "entities": [{"text": "MWE-aware parsers", "start_pos": 23, "end_pos": 40, "type": "TASK", "confidence": 0.868494987487793}, {"text": "MWE identification", "start_pos": 63, "end_pos": 81, "type": "TASK", "confidence": 0.9026193618774414}]}, {"text": "In most work where MWE identification is realized before parsing, the MWEs are merged into single tokens (Section 4.2.2).", "labels": [], "entities": [{"text": "MWE identification", "start_pos": 19, "end_pos": 37, "type": "TASK", "confidence": 0.9708826541900635}]}, {"text": "As a result, the common metrics for parsing evaluation given above become problematic for measuring the impact of MWE identification on parsing performance (Eryi \u02d8 git, \u02d9 Ilbay, and Can 2011).", "labels": [], "entities": [{"text": "parsing evaluation", "start_pos": 36, "end_pos": 54, "type": "TASK", "confidence": 0.9275871813297272}, {"text": "MWE identification", "start_pos": 114, "end_pos": 132, "type": "TASK", "confidence": 0.9691376984119415}]}, {"text": "For example, in dependency parsing, the concatenation of MWEs into single units decrements the total number of evaluated dependencies.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 16, "end_pos": 34, "type": "TASK", "confidence": 0.8725335001945496}]}, {"text": "It is thus possible to obtain different scores without actually changing the quality of the parser, but simply the representation of the results.", "labels": [], "entities": []}, {"text": "Instead of UAS and LAS metrics, the attachment scores on the surrounding structures, namely, UAS surr and LAS surr (i.e., the accuracies on the dependency relations excluding the ones between MWE elements) are more appropriate for the extrinsic evaluation of the impact of MWE identification on parsing.", "labels": [], "entities": [{"text": "UAS surr", "start_pos": 93, "end_pos": 101, "type": "METRIC", "confidence": 0.7914964556694031}, {"text": "LAS surr", "start_pos": 106, "end_pos": 114, "type": "METRIC", "confidence": 0.9080680310726166}, {"text": "MWE identification", "start_pos": 273, "end_pos": 291, "type": "TASK", "confidence": 0.9665871262550354}]}, {"text": "Similar considerations apply to constituency parsing.", "labels": [], "entities": [{"text": "constituency parsing", "start_pos": 32, "end_pos": 52, "type": "TASK", "confidence": 0.8949756026268005}]}, {"text": "Although UAS surr and LAS surr are valuable metrics for measuring the impact of different MWE categories on parsing, they are troublesome with automatic MWE identification when gold-standard MWE segmentation is not available, because erroneously identified MWEs would degrade parsing scores on the surrounding dependencies.", "labels": [], "entities": [{"text": "parsing", "start_pos": 108, "end_pos": 115, "type": "TASK", "confidence": 0.9590849876403809}, {"text": "MWE identification", "start_pos": 153, "end_pos": 171, "type": "TASK", "confidence": 0.9151056706905365}]}, {"text": "An alternative solution is to detach the concatenated MWE components (if any) into a dependency or constituency subtree (Candito and Constant 2014; Eryi \u02d8 git, \u02d9 Ilbay, and Can 2011).", "labels": [], "entities": []}, {"text": "In this way, the standard evaluation metrics are still applicable in all different orchestration scenarios and work on both contiguous and non-contiguous cases, thus providing a means to assess the performance of joint syntactic parsing and MWE identification as a whole.", "labels": [], "entities": [{"text": "joint syntactic parsing", "start_pos": 213, "end_pos": 236, "type": "TASK", "confidence": 0.6073471307754517}, {"text": "MWE identification", "start_pos": 241, "end_pos": 259, "type": "TASK", "confidence": 0.9781033098697662}]}, {"text": "The evaluation of MWEs translation quality remains an open challenge, whatever MT paradigm is adopted (), because of alack of shared assessment methodologies, benchmarking resources, and annotation guidelines.", "labels": [], "entities": [{"text": "MWEs translation", "start_pos": 18, "end_pos": 34, "type": "TASK", "confidence": 0.8860030174255371}]}, {"text": "With reference to the assessment methodologies, automatic evaluation metrics such as BLEU ( do not specifically take MWE translation quality into account.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 85, "end_pos": 89, "type": "METRIC", "confidence": 0.9972021579742432}, {"text": "MWE translation", "start_pos": 117, "end_pos": 132, "type": "TASK", "confidence": 0.9048294126987457}]}, {"text": "For instance, BLEU is based on shared words between the candidate and the reference translation, and gives only a very general indication about quality.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 14, "end_pos": 18, "type": "METRIC", "confidence": 0.9980767965316772}]}, {"text": "Thus, it cannot be considered as a suitable metric for the kind of more differentiated analysis required to identify specific gaps in the coverage of the system, as is needed for MWEs.", "labels": [], "entities": [{"text": "MWEs", "start_pos": 179, "end_pos": 183, "type": "TASK", "confidence": 0.8684035539627075}]}, {"text": "There have been a few attempts to adapt automatic evaluation metrics towards a more fine-grained MT error analysis ().", "labels": [], "entities": [{"text": "MT error analysis", "start_pos": 97, "end_pos": 114, "type": "TASK", "confidence": 0.7508720358212789}]}, {"text": "Extrinsic evaluations in MT have also been performed, mainly for SMT.", "labels": [], "entities": [{"text": "MT", "start_pos": 25, "end_pos": 27, "type": "TASK", "confidence": 0.9932627081871033}, {"text": "SMT", "start_pos": 65, "end_pos": 68, "type": "TASK", "confidence": 0.9944283962249756}]}, {"text": "For instance, Carpuat and Diab (2010) conducted a pilot study fora task-oriented evaluation of MWE translation in SMT, whereas Bouamor, Semmar, and Zweigenbaum (2012a) consider SMT as an extrinsic evaluation of the usefulness of automatically discovered MWEs and explore strategies for integrating them in a SMT system, aiming at a more thorough error analysis of MWE translation.", "labels": [], "entities": [{"text": "MWE translation", "start_pos": 95, "end_pos": 110, "type": "TASK", "confidence": 0.9775230884552002}, {"text": "SMT", "start_pos": 114, "end_pos": 117, "type": "TASK", "confidence": 0.9334461688995361}, {"text": "SMT", "start_pos": 177, "end_pos": 180, "type": "TASK", "confidence": 0.9737679958343506}, {"text": "SMT", "start_pos": 308, "end_pos": 311, "type": "TASK", "confidence": 0.969844400882721}, {"text": "MWE translation", "start_pos": 364, "end_pos": 379, "type": "TASK", "confidence": 0.9428099393844604}]}, {"text": "Another important drawback in this field is represented by the fact that parallel corpora annotated with MWEs, which are important and necessary gold standard resources for the evaluation of MT translation quality, are very scarce.", "labels": [], "entities": [{"text": "MT translation", "start_pos": 191, "end_pos": 205, "type": "TASK", "confidence": 0.9535547494888306}]}, {"text": "MWE annotation is indeed a complex and time-consuming task.", "labels": [], "entities": [{"text": "MWE annotation", "start_pos": 0, "end_pos": 14, "type": "TASK", "confidence": 0.9033285677433014}]}, {"text": "Annotated resources are usually produced manually and require a large number of experts.", "labels": [], "entities": []}, {"text": "In addition, annotating MWEs in parallel corpora requires the correct delimitation of MWEs (contiguous vs. discontiguous expressions) to classify and to disambiguate them and to handle not only the multilingual dimension, but also translation asymmetries between languages (Section 5.1).", "labels": [], "entities": []}, {"text": "Moreover, each category of MWEs has its own set of properties.", "labels": [], "entities": []}, {"text": "MWE-annotated benchmarking resources useful for translation quality evaluation are usually available for (1) specific MWE categories, (2) specific language pairs, (3) a specific MWE alignment tool or integration strategy in MT systems, or (4) specific approaches to handling MWEs in MT.", "labels": [], "entities": [{"text": "translation quality evaluation", "start_pos": 48, "end_pos": 78, "type": "TASK", "confidence": 0.9180623094240824}, {"text": "MWE alignment", "start_pos": 178, "end_pos": 191, "type": "TASK", "confidence": 0.8634859025478363}, {"text": "MT", "start_pos": 224, "end_pos": 226, "type": "TASK", "confidence": 0.9391129016876221}]}, {"text": "Evaluation data consist mainly of small parallel corpora, manually built by carefully selecting sentences containing specific categories of MWE to avoid data sparseness, aligned either with human translations collected from the Web or generated by commercial MT systems (Google Translate, Bing, OpenLogos).", "labels": [], "entities": []}, {"text": "Previous work that makes use of such resources includes Ramisch, Besacier, and Kobzar (2013) for verb-particle constructions in English and French; for different categories of MWE in language pairs involving English to for French-Romanian verb-noun idioms and collocations; for compositional noun compounds, compositional verb compounds, and a set of non-compositional compounds in German-English; for light-verb constructions in English to for verb-particle constructions in the German-English language pair.", "labels": [], "entities": []}, {"text": "In addition, these linguistic resources are annotated only with a limited set of MWE categories such as, for instance, light-verb constructions.", "labels": [], "entities": []}, {"text": "They are of variable granularity, so some annotation schemes consider only MWE categories, whereas others include additional information such as POS and degree of fixedness.", "labels": [], "entities": [{"text": "POS", "start_pos": 145, "end_pos": 148, "type": "METRIC", "confidence": 0.9973612427711487}]}, {"text": "There are only very few instances of parallel corpora annotated with several categories of MWEs and with different types of correspondences (many-to-one, one-tomany, and many-to-many translations), such as those created by,.", "labels": [], "entities": []}, {"text": "Moreover, the lack of homogeneity represents areal obstacle to the effective reuse of existing annotated data.", "labels": [], "entities": []}, {"text": "Concerning MWE annotation guidelines, only very few papers describe the procedures adopted during resource development.", "labels": [], "entities": [{"text": "MWE annotation", "start_pos": 11, "end_pos": 25, "type": "TASK", "confidence": 0.9101023077964783}]}, {"text": "Comprehensive approaches to MWE annotation in parallel corpora, that is, which take into account a large inventory of MWE categories, include, who developed a parallel English-Italian corpus, and, who worked on the French part of a parallel French-English corpus.", "labels": [], "entities": [{"text": "MWE annotation", "start_pos": 28, "end_pos": 42, "type": "TASK", "confidence": 0.9677678644657135}]}, {"text": "In conclusion, the evaluation of MWE processing in MT is still an open issue, as we will discuss in the next section.", "labels": [], "entities": [{"text": "MWE processing", "start_pos": 33, "end_pos": 47, "type": "TASK", "confidence": 0.9704644680023193}, {"text": "MT", "start_pos": 51, "end_pos": 53, "type": "TASK", "confidence": 0.9186274409294128}]}], "tableCaptions": []}