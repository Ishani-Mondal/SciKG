{"title": [{"text": "Mapping to Declarative Knowledge for Word Problem Solving", "labels": [], "entities": [{"text": "Word Problem Solving", "start_pos": 37, "end_pos": 57, "type": "TASK", "confidence": 0.8249038060506185}]}], "abstractContent": [{"text": "Math word problems form a natural abstraction to a range of quantitative reasoning problems , such as understanding financial news, sports results, and casualties of war.", "labels": [], "entities": []}, {"text": "Solving such problems requires the understanding of several mathematical concepts such as dimensional analysis, subset relationships, etc.", "labels": [], "entities": []}, {"text": "In this paper, we develop declarative rules which govern the translation of natural language description of these concepts to math expressions.", "labels": [], "entities": []}, {"text": "We then present a framework for incorporating such declarative knowledge into word problem solving.", "labels": [], "entities": [{"text": "word problem solving", "start_pos": 78, "end_pos": 98, "type": "TASK", "confidence": 0.8308809200922648}]}, {"text": "Our method learns to map arithmetic word problem text to math expressions , by learning to select the relevant declarative knowledge for each operation of the solution expression.", "labels": [], "entities": []}, {"text": "This provides away to handle multiple concepts in the same problem while, at the same time, supporting in-terpretability of the answer expression.", "labels": [], "entities": []}, {"text": "Our method models the mapping to declarative knowledge as a latent variable, thus removing the need for expensive annotations.", "labels": [], "entities": []}, {"text": "Experimental evaluation suggests that our domain knowledge based solver outperforms all other systems, and that it generalizes better in the realistic case where the training data it is exposed to is biased in a different way than the test data.", "labels": [], "entities": []}], "introductionContent": [{"text": "Many natural language understanding situations require reasoning with respect to numbers or quanti- * Most of the work was done when the authors were at the University of Illinois, Urbana Champaign.", "labels": [], "entities": [{"text": "natural language understanding", "start_pos": 5, "end_pos": 35, "type": "TASK", "confidence": 0.6532014409701029}]}, {"text": "ties -understanding financial news, sports results, or the number of casualties in a bombing.", "labels": [], "entities": [{"text": "understanding financial news", "start_pos": 6, "end_pos": 34, "type": "TASK", "confidence": 0.8530705173810323}]}, {"text": "Math word problems form a natural abstraction to a lot of these quantitative reasoning problems.", "labels": [], "entities": []}, {"text": "Consequently, there has been a growing interest in developing automated methods to solve math word problems (.", "labels": [], "entities": []}, {"text": "To solve the problem, one needs to understand that \"apple pies\" and \"pecan pies\" are kinds of \"pies\", and hence, the number of apple pies and pecan pies needs to be summed up to get the total number of pies.", "labels": [], "entities": []}, {"text": "Similarly, detecting that \"5\" represents \"the number of pies per row\" and applying dimensional analysis or unit compatibility knowledge, helps us infer that the total number of pies needs to be divided by 5 to get the answer.", "labels": [], "entities": []}, {"text": "Besides part-whole relationship and dimensional analysis, there are several other concepts that are needed to support reasoning in math word problems.", "labels": [], "entities": []}, {"text": "Some of these involve understanding comparisons, transactions, and the application of math or physics formulas.", "labels": [], "entities": [{"text": "understanding comparisons", "start_pos": 22, "end_pos": 47, "type": "TASK", "confidence": 0.8086369037628174}]}, {"text": "Most of this knowledge can be encoded as declarative rules, as illustrated in this paper.", "labels": [], "entities": []}, {"text": "This paper introduces a framework for incorporating this \"declarative knowledge\" into word problem solving.", "labels": [], "entities": [{"text": "word problem solving", "start_pos": 86, "end_pos": 106, "type": "TASK", "confidence": 0.825629452864329}]}, {"text": "We focus on arithmetic word problems, whose solution can be obtained by combining the numbers in the problem with basic operations (addition, subtraction, multiplication or division).", "labels": [], "entities": []}, {"text": "For combining a pair of numbers or math subexpressions, our method first predicts the math concept that is needed for it (e.g., subset relationship, dimensional analysis, etc.), and then predicts a declarative rule under that concept to infer the mathematical operation.", "labels": [], "entities": []}, {"text": "We model the selection of declarative rules as a latent variable, which removes the need for expensive annotations for the intermediate steps.", "labels": [], "entities": []}, {"text": "The proposed approach has some clear advantages compared to existing work on word problem solving.", "labels": [], "entities": [{"text": "word problem solving", "start_pos": 77, "end_pos": 97, "type": "TASK", "confidence": 0.8528716762860616}]}, {"text": "First, it provides interpretability of the solution, without expensive annotations.", "labels": [], "entities": []}, {"text": "Our method selects a declarative knowledge based inference rule for each operation needed in the solution.", "labels": [], "entities": []}, {"text": "These rules provide an explanation for the operations performed.", "labels": [], "entities": []}, {"text": "In particular, it learns to select relevant rules without explicit annotations for them.", "labels": [], "entities": []}, {"text": "Second, each individual operation in the solution expression can be generated independently by a separate mathematical concept.", "labels": [], "entities": []}, {"text": "This allows our method to handle multiple concepts in the same problem.", "labels": [], "entities": []}, {"text": "We show that existing datasets of arithmetic word problems suffer from significant vocabulary biases and, consequently, existing solvers do not do well on conceptually similar problems that are not biased in the same way.", "labels": [], "entities": []}, {"text": "Our method, on the other hand, learns the right abstractions even in the presence of biases in the data.", "labels": [], "entities": []}, {"text": "We also introduce a novel approach to gather word problems without these biases, creating anew dataset of 1492 problems.", "labels": [], "entities": []}, {"text": "The next section discusses related work.", "labels": [], "entities": []}, {"text": "We next introduce the mathematical concepts required for arithmetic word problems, as well as the declarative rules for each concept.", "labels": [], "entities": []}, {"text": "Section 4 describes our model -how we predict answers using declarative knowledge -and provides the details of our training paradigm.", "labels": [], "entities": []}, {"text": "Finally, we provide an experimental evaluation of our proposed method in Section 6, and then conclude with a discussion of future work.", "labels": [], "entities": []}], "datasetContent": [{"text": "We first evaluate our approach on the existing datasets of AllArith, AllArithLex, and AllArithTmpl (.", "labels": [], "entities": [{"text": "AllArith", "start_pos": 59, "end_pos": 67, "type": "DATASET", "confidence": 0.9712991714477539}, {"text": "AllArithLex", "start_pos": 69, "end_pos": 80, "type": "DATASET", "confidence": 0.9276987910270691}, {"text": "AllArithTmpl", "start_pos": 86, "end_pos": 98, "type": "DATASET", "confidence": 0.9523007869720459}]}, {"text": "AllArithLex and AllArithTmpl are subsets of the AllArith dataset, created to test the robustness to new vocabulary, and new equation forms respectively.", "labels": [], "entities": [{"text": "AllArithLex", "start_pos": 0, "end_pos": 11, "type": "DATASET", "confidence": 0.9155530333518982}, {"text": "AllArithTmpl", "start_pos": 16, "end_pos": 28, "type": "DATASET", "confidence": 0.8555570244789124}, {"text": "AllArith dataset", "start_pos": 48, "end_pos": 64, "type": "DATASET", "confidence": 0.9744115769863129}]}, {"text": "We compare to the top performing systems for arithmetic word problems.", "labels": [], "entities": []}, {"text": "They are as follows: 3.", "labels": [], "entities": []}, {"text": "UNITDEP: Unit dependency graph based solver of.", "labels": [], "entities": [{"text": "UNITDEP", "start_pos": 0, "end_pos": 7, "type": "DATASET", "confidence": 0.9259518384933472}]}, {"text": "We refer to our approach as KNOWLEDGE.", "labels": [], "entities": [{"text": "KNOWLEDGE", "start_pos": 28, "end_pos": 37, "type": "METRIC", "confidence": 0.9166610240936279}]}, {"text": "For all solvers, we use the system released by the respective authors.", "labels": [], "entities": [{"text": "solvers", "start_pos": 8, "end_pos": 15, "type": "TASK", "confidence": 0.9819498658180237}]}, {"text": "The system of TEMPLATE expects an equation as the answer, whereas our dataset contains only math expressions.", "labels": [], "entities": []}, {"text": "We converted expressions to equations by introducing a single variable and assigning the math expression to it.", "labels": [], "entities": []}, {"text": "For example, an expression \"(2 + 3)\" gets converted to \"X = (2 + 3)\".", "labels": [], "entities": []}, {"text": "The first few columns of shows the performance of the systems on the aforementioned datasets 1 . The performance of KNOWLEDGE is on par or lower than some of the existing systems.", "labels": [], "entities": [{"text": "KNOWLEDGE", "start_pos": 116, "end_pos": 125, "type": "METRIC", "confidence": 0.6668933033943176}]}, {"text": "We analyzed the systems, and found most of them to not be robust to perturbations of the problem text; shows a few examples.", "labels": [], "entities": []}, {"text": "We further analyzed the datasets, and identified several biases in the problems (in both train and test).", "labels": [], "entities": []}, {"text": "Systems which remember these biases get an undue advantage in evaluation.", "labels": [], "entities": []}, {"text": "For example, the verb \"give\" only appears with subtraction, and hence the models are   learning an erroneous correlation of \"give\" with subtraction.", "labels": [], "entities": []}, {"text": "Since the test also exhibits the same bias, these systems get all the \"give\"-related questions correct.", "labels": [], "entities": []}, {"text": "However, they fail to solve the problem in, where \"give\" results in addition.", "labels": [], "entities": []}, {"text": "We also tested KNOWLEDGE on the addition subtraction problems dataset released by.", "labels": [], "entities": [{"text": "KNOWLEDGE", "start_pos": 15, "end_pos": 24, "type": "METRIC", "confidence": 0.9899914264678955}]}, {"text": "It achieved across validation accuracy of 77.19%, which is competitive with the state of the art accuracy of 78% achieved with the same level of supervision.", "labels": [], "entities": [{"text": "validation", "start_pos": 19, "end_pos": 29, "type": "TASK", "confidence": 0.8809444904327393}, {"text": "accuracy", "start_pos": 30, "end_pos": 38, "type": "METRIC", "confidence": 0.9371585249900818}, {"text": "accuracy", "start_pos": 97, "end_pos": 105, "type": "METRIC", "confidence": 0.9948468208312988}]}, {"text": "The system of Mitra and Baral (2016) achieved 86.07% accuracy on this dataset, but requires rich annotations for formulas and alignment of numbers to formulas.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 53, "end_pos": 61, "type": "METRIC", "confidence": 0.9995498061180115}]}, {"text": "In order to remove the aforementioned biases from the dataset, we augment it with new word problems collected via a crowdsourcing platform.", "labels": [], "entities": []}, {"text": "These new word problems are created by perturbing the original problems minimally, such that the answer is different from the original problem.", "labels": [], "entities": []}, {"text": "For each word problem p with an answer expression a in our original dataset AllArith, we replace one operation in a to create anew math expression a . We ask annotators to modify problem p minimally, such that a is now the solution to the modified word problem.", "labels": [], "entities": [{"text": "AllArith", "start_pos": 76, "end_pos": 84, "type": "DATASET", "confidence": 0.8862404823303223}]}, {"text": "We create a from a either by replacing an addition with subtraction or vice versa, or by replacing multiplication with division or vice versa.", "labels": [], "entities": []}, {"text": "We do not replace addition and subtraction with multiplication or division, since there might not bean easy perturbation that supports this conversion.", "labels": [], "entities": []}, {"text": "We only allowed perturbed expressions which evaluate to values greater than 1.", "labels": [], "entities": []}, {"text": "For example, we generate the expression \"(3+2)\" from \"(3-2)\"; we generated expressions \"(10+2)/4\" and \"(10-2)*4\" for the expression \"(10-2)/4\".", "labels": [], "entities": []}, {"text": "We generate all possible perturbed expressions fora given answer expression, and ask for problem text modification for each one of them.", "labels": [], "entities": []}, {"text": "We show the annotators the original problem text p paired with a perturbed answer a . The instructions advised them to copy over the given problem text, and modify it as little as possible so that the given math expression is now the solution to this modified problem.", "labels": [], "entities": []}, {"text": "They were also instructed not to add or delete the numbers mentioned in the problem.", "labels": [], "entities": []}, {"text": "If the original problem mentions two \"3\"s and one \"2\", the modified problem should also contain two \"3\"s and one \"2\".", "labels": [], "entities": []}, {"text": "We manually pruned problems which did not yield the desired solution a \ud97b\udf59 , or were too different from the input problem p.", "labels": [], "entities": []}, {"text": "This procedure gave us a set of 661 new word problems, which we refer to as Perturb.", "labels": [], "entities": [{"text": "Perturb", "start_pos": 76, "end_pos": 83, "type": "METRIC", "confidence": 0.9076961874961853}]}, {"text": "Finally we augment AllArith with the problems of Perturb, and call this new dataset Aggregate.", "labels": [], "entities": [{"text": "Perturb", "start_pos": 49, "end_pos": 56, "type": "DATASET", "confidence": 0.5906503796577454}, {"text": "Aggregate", "start_pos": 84, "end_pos": 93, "type": "DATASET", "confidence": 0.7980499863624573}]}, {"text": "Aggregate has a total of 1492 problems.", "labels": [], "entities": [{"text": "Aggregate", "start_pos": 0, "end_pos": 9, "type": "DATASET", "confidence": 0.6107650995254517}]}, {"text": "The addition of the Perturb problems ensures that the dataset now has problems with similar lexical items generating different answers.", "labels": [], "entities": [{"text": "Perturb", "start_pos": 20, "end_pos": 27, "type": "METRIC", "confidence": 0.7090162038803101}]}, {"text": "This minimizes the bias that we discussed in subsection 6.1.", "labels": [], "entities": []}, {"text": "To quantify this, consider the probability distribution over operations fora quantity q, given that word w is present in the neighborhood of q.", "labels": [], "entities": []}, {"text": "For an unbiased dataset, you will expect the entropy of this distribution to be high, since the presence of a single word in a number neighborhood will seldom be completely informative for the operation.", "labels": [], "entities": []}, {"text": "We compute the average of this entropy value overall numbers and neighborhood words in our dataset.", "labels": [], "entities": []}, {"text": "AllArith and Perturb have an average entropy of 0.34 and 0.32 respectively, whereas Aggregate's average entropy is 0.54, indicating that, indeed, the complete data set is significantly less biased.", "labels": [], "entities": []}, {"text": "First, we evaluate the ability of systems to generalize from biased datasets.", "labels": [], "entities": []}, {"text": "We train all systems on AllArith, and test them on Perturb (which was created by perturbing AllArith problems).", "labels": [], "entities": [{"text": "AllArith", "start_pos": 24, "end_pos": 32, "type": "DATASET", "confidence": 0.9634571075439453}, {"text": "Perturb", "start_pos": 51, "end_pos": 58, "type": "DATASET", "confidence": 0.6257216930389404}, {"text": "AllArith", "start_pos": 92, "end_pos": 100, "type": "DATASET", "confidence": 0.8875064253807068}]}, {"text": "The last column of shows the performance of systems in this setting.", "labels": [], "entities": []}, {"text": "KNOWLEDGE outperforms all other systems in this setting with around 19% absolute improvement over UNITDEP.", "labels": [], "entities": [{"text": "KNOWLEDGE", "start_pos": 0, "end_pos": 9, "type": "METRIC", "confidence": 0.8090143799781799}, {"text": "absolute", "start_pos": 72, "end_pos": 80, "type": "METRIC", "confidence": 0.9893514513969421}, {"text": "UNITDEP", "start_pos": 98, "end_pos": 105, "type": "DATASET", "confidence": 0.7667504549026489}]}, {"text": "This shows that declarative knowledge allows the system to learn the correct abstractions, even from biased datasets.", "labels": [], "entities": []}, {"text": "Finally, we evaluate the systems on the Aggregate dataset.", "labels": [], "entities": [{"text": "Aggregate dataset", "start_pos": 40, "end_pos": 57, "type": "DATASET", "confidence": 0.9634933769702911}]}, {"text": "Following previous work, we compute two subsets of Aggregate comprising 756 problems each, using the MAWPS () system.", "labels": [], "entities": []}, {"text": "The first, called AggregateLex, is one with low lexical repetitions, and the second called AggregateTmpl is one with low repetitions of equation forms.", "labels": [], "entities": []}, {"text": "We also evaluate on these two subsets on a 5-fold cross validation.", "labels": [], "entities": []}, {"text": "Columns 4-6 of show the performance of systems on this setting.", "labels": [], "entities": []}, {"text": "KNOWLEDGE significantly o utperforms other s ystems on Aggregate and AggregateLex, and is similar to UNITDEP on AggregateTmpl.", "labels": [], "entities": [{"text": "KNOWLEDGE", "start_pos": 0, "end_pos": 9, "type": "METRIC", "confidence": 0.767148494720459}, {"text": "Aggregate", "start_pos": 55, "end_pos": 64, "type": "DATASET", "confidence": 0.9577714800834656}, {"text": "AggregateLex", "start_pos": 69, "end_pos": 81, "type": "DATASET", "confidence": 0.8555655479431152}]}, {"text": "There is a 9% absolute improvement on AggregateLex, showing that KNOWLEDGE is significantly more robust to low lexical overlap between train and test.", "labels": [], "entities": [{"text": "AggregateLex", "start_pos": 38, "end_pos": 50, "type": "METRIC", "confidence": 0.5761035084724426}, {"text": "KNOWLEDGE", "start_pos": 65, "end_pos": 74, "type": "METRIC", "confidence": 0.9248433113098145}]}, {"text": "The last column of also shows that the other systems do not learn the right abstraction, even when trained on Aggregate.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 3: Accuracy in solving arithmetic word problems. All columns except the last report 5-fold cross validation", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9914382696151733}]}]}