{"title": [{"text": "Event Time Extraction with a Decision Tree of Neural Classifiers", "labels": [], "entities": [{"text": "Event Time Extraction", "start_pos": 0, "end_pos": 21, "type": "TASK", "confidence": 0.5716610054175059}]}], "abstractContent": [{"text": "Extracting the information from text when an event happened is challenging.", "labels": [], "entities": [{"text": "Extracting the information from text when an event happened", "start_pos": 0, "end_pos": 59, "type": "TASK", "confidence": 0.8119390606880188}]}, {"text": "Documents do not only report on current events, but also on past events as well as on future events.", "labels": [], "entities": []}, {"text": "Often, the relevant time information for an event is scattered across the document.", "labels": [], "entities": []}, {"text": "In this paper we present a novel method to automatically anchor events in time.", "labels": [], "entities": []}, {"text": "To our knowledge it is the first approach that takes temporal information from the complete document into account.", "labels": [], "entities": []}, {"text": "We created a decision tree that applies neural network based classifiers at its nodes.", "labels": [], "entities": []}, {"text": "We use this tree to incrementally infer, in a stepwise manner, at which time frame an event happened.", "labels": [], "entities": []}, {"text": "We evaluate the approach on the TimeBank-EventTime Corpus (Reimers et al., 2016) achieving an accuracy of 42.0% compared to an inter-annotator agreement (IAA) of 56.7%.", "labels": [], "entities": [{"text": "TimeBank-EventTime Corpus", "start_pos": 32, "end_pos": 57, "type": "DATASET", "confidence": 0.9255848526954651}, {"text": "accuracy", "start_pos": 94, "end_pos": 102, "type": "METRIC", "confidence": 0.9990189075469971}, {"text": "inter-annotator agreement (IAA)", "start_pos": 127, "end_pos": 158, "type": "METRIC", "confidence": 0.7027144491672516}]}, {"text": "For events that span over a single day we observe an accuracy improvement of 33.1 points compared to the state-of-the-art CAEVO system (Chambers et al., 2014).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 53, "end_pos": 61, "type": "METRIC", "confidence": 0.9996028542518616}, {"text": "CAEVO", "start_pos": 122, "end_pos": 127, "type": "METRIC", "confidence": 0.8909051418304443}]}, {"text": "Without retraining , we apply this model to the SemEval-2015 Task 4 on automatic timeline generation and achieve an improvement of 4.01 points F 1-score compared to the state-of-the-art.", "labels": [], "entities": [{"text": "timeline generation", "start_pos": 81, "end_pos": 100, "type": "TASK", "confidence": 0.6941457092761993}]}, {"text": "Our code is publically available.", "labels": [], "entities": []}], "introductionContent": [{"text": "Knowing when an event happened is useful fora lot of use cases.", "labels": [], "entities": [{"text": "Knowing when an event happened", "start_pos": 0, "end_pos": 30, "type": "TASK", "confidence": 0.8668426156044007}]}, {"text": "Examples are in the fields of time-aware information retrieval, text summarization, automated timeline generation, and automatic knowledge base population.", "labels": [], "entities": [{"text": "time-aware information retrieval", "start_pos": 30, "end_pos": 62, "type": "TASK", "confidence": 0.5936669707298279}, {"text": "text summarization", "start_pos": 64, "end_pos": 82, "type": "TASK", "confidence": 0.7850866913795471}, {"text": "automated timeline generation", "start_pos": 84, "end_pos": 113, "type": "TASK", "confidence": 0.593948096036911}]}, {"text": "Many facts in a knowledge base are * During author's internship in the research training group AIPHES at UKP Lab, TU Darmstadt.", "labels": [], "entities": [{"text": "UKP Lab", "start_pos": 105, "end_pos": 112, "type": "DATASET", "confidence": 0.9545391201972961}]}, {"text": "1 https://github.com/ukplab/ tacl2017-event-time-extraction only true fora certain time period, for example the presidency of a person.", "labels": [], "entities": []}, {"text": "Hence, the population of a knowledge base can highly benefit from high quality event and event time 2 extraction.", "labels": [], "entities": []}, {"text": "Inherent to events is the connection to time.", "labels": [], "entities": []}, {"text": "defines an event as \"something that happens at some specific time and place\".", "labels": [], "entities": []}, {"text": "The challenges for automatic event time extraction are manifold.", "labels": [], "entities": [{"text": "automatic event time extraction", "start_pos": 19, "end_pos": 50, "type": "TASK", "confidence": 0.5552748367190361}]}, {"text": "The temporal information in news articles which states when an event happened is, inmost cases, not in the same or in neighboring sentences with the event (.", "labels": [], "entities": []}, {"text": "It can be mentioned far before the event or far after the event.", "labels": [], "entities": []}, {"text": "Even worse, for more than 60% of events, the specific day at which the event happened is not mentioned.", "labels": [], "entities": []}, {"text": "However, from the world knowledge and causal relations, the reader can infer a lot of temporal information about those events and can often infer that the event happened before or after some specific point in time.", "labels": [], "entities": []}, {"text": "In this paper we describe anew classifier for automatic event time extraction.", "labels": [], "entities": [{"text": "automatic event time extraction", "start_pos": 46, "end_pos": 77, "type": "TASK", "confidence": 0.5633354187011719}]}, {"text": "We use the TimeBankEventTime Corpus () to train and evaluate our proposed architecture.", "labels": [], "entities": [{"text": "TimeBankEventTime Corpus", "start_pos": 11, "end_pos": 35, "type": "DATASET", "confidence": 0.9358311891555786}]}, {"text": "In contrast to other corpora on temporal relations, the annotation of the TimeBank-EventTime Corpus does not make restrictions where, and in which form, temporal information for an event must be provided.", "labels": [], "entities": [{"text": "TimeBank-EventTime Corpus", "start_pos": 74, "end_pos": 99, "type": "DATASET", "confidence": 0.9334801137447357}]}, {"text": "The annotators were allowed to take the whole document into account and were asked to answer, to the best of their ability, the question at which date or time period the event happened.", "labels": [], "entities": []}, {"text": "The event time annotation for some sample events is shown in the following: \u2022 He was 1980-05-26 into space on May 26, We will refer to the temporal information when an event happened as event time.", "labels": [], "entities": []}, {"text": "2. Due to the diverse types of events and due to varying temporal information for events, the structure of the labels varies.", "labels": [], "entities": []}, {"text": "3. Temporal information from the whole document must betaken into account.", "labels": [], "entities": []}, {"text": "4. For 12.6% of the events, the event time label is a combination of several temporal clues.", "labels": [], "entities": []}, {"text": "An example could be that the annotator combined that the person went missing on the 15th and that the person went missing in the month of August.", "labels": [], "entities": []}, {"text": "However, nowhere in text is the 15th of August explicitly mentioned.", "labels": [], "entities": [{"text": "15th of August", "start_pos": 32, "end_pos": 46, "type": "DATASET", "confidence": 0.7454239726066589}]}, {"text": "The main contribution of this paper is the proposal of a novel combination of a decision tree combined with neural network classifiers for the nodes to solve the afore-mentioned challenges.", "labels": [], "entities": []}, {"text": "To our knowledge, this is the first system that works on the complete document and can extract long-range relations between events and temporal expressions.", "labels": [], "entities": []}, {"text": "Further, it is the first system that focuses on extracting begin and end points for events that span over multiple days.", "labels": [], "entities": []}, {"text": "Evaluated on the TimeBank-EventTime Corpus (, it achieves an accuracy of 42.0% compared to an inter-annotator agreement (IAA) of 56.7%.", "labels": [], "entities": [{"text": "TimeBank-EventTime Corpus", "start_pos": 17, "end_pos": 42, "type": "DATASET", "confidence": 0.9363915324211121}, {"text": "accuracy", "start_pos": 61, "end_pos": 69, "type": "METRIC", "confidence": 0.9993107318878174}, {"text": "inter-annotator agreement (IAA)", "start_pos": 94, "end_pos": 125, "type": "METRIC", "confidence": 0.7171344876289367}]}, {"text": "Compared to the state-of-the-art CAEVO system ( ), we observe a substantial improvement inaccuracy of 33.7 percentage points for events that happened on a single day.", "labels": [], "entities": [{"text": "CAEVO", "start_pos": 33, "end_pos": 38, "type": "METRIC", "confidence": 0.7688307166099548}]}, {"text": "For Multi-Day Events, we observe an accuracy of 24.3% using a strict metric.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 36, "end_pos": 44, "type": "METRIC", "confidence": 0.9995176792144775}]}, {"text": "We show that the proposed model generalizes well to new tasks and textual domains.", "labels": [], "entities": []}, {"text": "We applied it without re-training to the SemEval-2015 Task 4 on automatic timeline generation.", "labels": [], "entities": [{"text": "SemEval-2015 Task 4", "start_pos": 41, "end_pos": 60, "type": "TASK", "confidence": 0.7441470424334208}, {"text": "automatic timeline generation", "start_pos": 64, "end_pos": 93, "type": "TASK", "confidence": 0.5642400979995728}]}, {"text": "There, it achieves an improvement of 4.01 points F 1 -score compared to the state-of-the-art.", "labels": [], "entities": [{"text": "F 1 -score", "start_pos": 49, "end_pos": 59, "type": "METRIC", "confidence": 0.7768310457468033}]}], "datasetContent": [{"text": "We conduct our experiments on the TimeBankEventTime Corpus (.", "labels": [], "entities": [{"text": "TimeBankEventTime Corpus", "start_pos": 34, "end_pos": 58, "type": "DATASET", "confidence": 0.9572158455848694}]}, {"text": "The corpus is comprised of 36 documents and 1498 annotated events.", "labels": [], "entities": []}, {"text": "We use the same split into training, development, and test set as  resulting in 22 documents for training, 5 documents for hyperparameter optimization, and 9 documents for the final evaluation.", "labels": [], "entities": [{"text": "hyperparameter optimization", "start_pos": 123, "end_pos": 150, "type": "TASK", "confidence": 0.6608078628778458}]}, {"text": "Using this split allows a fair comparison to the CAEVO system.", "labels": [], "entities": [{"text": "CAEVO", "start_pos": 49, "end_pos": 54, "type": "DATASET", "confidence": 0.798976480960846}]}, {"text": "Hyperparameters for the individual local classifiers were chosen using random search) with at least 1000 iterations per local classifier.", "labels": [], "entities": []}, {"text": "We evaluate our system using two different metrics.", "labels": [], "entities": []}, {"text": "The strict metric requires an exact match between the predicted label and the gold label.", "labels": [], "entities": []}, {"text": "A disadvantage of this metric is that it does not allow partial agreement.", "labels": [], "entities": []}, {"text": "The strict agreement between two annotators is fairly low for events where the exact date of the event was not mentioned.", "labels": [], "entities": []}, {"text": "In order to allow partial matches, we will also use a relaxed metric, which will judge two different labels only as an error, if those are mutually exclusive.", "labels": [], "entities": []}, {"text": "Two labels are mutually exclusive, if there is no event date which could satisfy both labels at the same time.", "labels": [], "entities": []}, {"text": "If the event happened on August 5th, 1998, the two annotations before 1998-08-31 and after 1998-08-01 before 1998-08-31 would both be satisfied.", "labels": [], "entities": []}, {"text": "Therefore, these two different labels would be considered as correct.", "labels": [], "entities": []}, {"text": "In contrast, the two annotations after 1998-02-01 and before 1997-12-31 can never be satisfied at the same time and are therefore mutually exclusive.", "labels": [], "entities": []}, {"text": "The score of the relaxed metric must be seen in combination with the strict metric.", "labels": [], "entities": []}, {"text": "A system could trick the relaxed metric by returning a before date that is far in the future which results in a high relaxed score but a negligible strict score.", "labels": [], "entities": []}, {"text": "Future research is necessary to judge the quality of different kind of partial matches and to design an appropriate metric.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Distribution of the retrieved labels for the pro- posed system and for the baseline. Less precise are labels  where the time frame when the event has happened is  larger than for the gold label. Wrong label are labels  which are in clear contradiction to the gold standard.", "labels": [], "entities": []}, {"text": " Table 3: Comparison of the accuracy (strict metric) for  Single Day Events (SD), Multi-Day Events (MD) and  overall. Reduced tree uses only the local classifiers 1, 2.1  and 3.2.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 28, "end_pos": 36, "type": "METRIC", "confidence": 0.9994565844535828}]}, {"text": " Table 4: Accuracy for the different local classifiers vs. a  Majority Vote baseline. Local classifiers are numbered as  depicted in", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9964620471000671}]}, {"text": " Table 7: Performance of our system on the SemEval-2015  Task 4 Track B for the topics Airbus, General Motors, and  stock market.", "labels": [], "entities": []}]}