{"title": [], "abstractContent": [{"text": "We propose anew generative language model for sentences that first samples a prototype sentence from the training corpus and then edits it into anew sentence.", "labels": [], "entities": []}, {"text": "Compared to traditional language models that generate from scratch either left-to-right or by first sampling a latent sentence vector, our prototype-then-edit model improves perplexity on language modeling and generates higher quality outputs according to human evaluation.", "labels": [], "entities": []}, {"text": "Furthermore, the model gives rise to a latent edit vector that captures interpretable semantics such as sentence similarity and sentence-level analogies.", "labels": [], "entities": []}], "introductionContent": [{"text": "The ability to generate sentences is core to many NLP tasks, including machine translation, summarization, speech recognition, and dialogue.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 71, "end_pos": 90, "type": "TASK", "confidence": 0.792413741350174}, {"text": "summarization", "start_pos": 92, "end_pos": 105, "type": "TASK", "confidence": 0.9799044132232666}, {"text": "speech recognition", "start_pos": 107, "end_pos": 125, "type": "TASK", "confidence": 0.7176778465509415}]}, {"text": "Most neural models for these tasks are based on recurrent neural language models (NLMs), which generate sentences from scratch, often in a left-to-right manner (.", "labels": [], "entities": []}, {"text": "It is often observed that such NLMs suffer from the problem of favoring generic utterances such as \"I don't know\" ( . At the same time, naive strategies to increase diversity have been shown to compromise grammaticality (, suggesting that current NLMs may lack the inductive bias to faithfully represent the full diversity of complex utterances.", "labels": [], "entities": []}, {"text": "Indeed, it is difficult even for humans to write complex text from scratch in a single pass; we often create an initial draft and incrementally revise it.", "labels": [], "entities": []}, {"text": "Inspired by this process,: The prototype-then-edit model generates a sentence by sampling a random example from the training set and then editing it using a randomly sampled edit vector.", "labels": [], "entities": []}, {"text": "we propose anew unconditional generative model of text which we call the prototype-then-edit model, illustrated in.", "labels": [], "entities": []}, {"text": "It first samples a random prototype sentence from the training corpus, and then invokes a neural editor, which draws a random \"edit vector\" and generates anew sentence by attending to the prototype while conditioning on the edit vector.", "labels": [], "entities": []}, {"text": "The motivation is that sentences from the corpus provide a high quality starting point: they are grammatical, naturally diverse, and exhibit no bias towards shortness or vagueness.", "labels": [], "entities": []}, {"text": "The attention mechanism ( of the neural editor strongly biases the generation towards the prototype, and therefore it needs to solve a much easier problem than generating from scratch.", "labels": [], "entities": []}, {"text": "We train the neural editor by maximizing an approximation to the generative model's loglikelihood.", "labels": [], "entities": []}, {"text": "This objective is a sum over lexically-similar sentence pairs in the training set, which we can scalably approximate using locality sensitive hashing.", "labels": [], "entities": []}, {"text": "We also show empirically that most lexically similar sentences are also semantically similar, thereby endowing the neural editor with additional semantic structure.", "labels": [], "entities": []}, {"text": "For example, we can use the neural editor to perform a random walk from a seed sentence to traverse semantic space.", "labels": [], "entities": []}, {"text": "We compare our prototype-then-edit model to approaches that generate from scratch on both language generation quality and semantic properties.", "labels": [], "entities": []}, {"text": "For the former, our model generates higher quality generations according to human evaluations, and improves perplexity by 13 points on the Yelp corpus and 7 points on the One Billion Word Benchmark.", "labels": [], "entities": [{"text": "Yelp corpus", "start_pos": 139, "end_pos": 150, "type": "DATASET", "confidence": 0.9725366830825806}]}, {"text": "For the latter, we show that latent edit vectors outperform standard sentence variational autoencoders () on semantic similarity, locally-controlled text generation, and a sentence analogy task.", "labels": [], "entities": [{"text": "text generation", "start_pos": 149, "end_pos": 164, "type": "TASK", "confidence": 0.7401373535394669}, {"text": "sentence analogy task", "start_pos": 172, "end_pos": 193, "type": "TASK", "confidence": 0.8016672730445862}]}], "datasetContent": [{"text": "We divide our experimental results into two parts.", "labels": [], "entities": []}, {"text": "In Section 4.2, we evaluate the merits of the prototypethen-edit model as a generative modeling strategy, measuring its improvements on language modeling (perplexity) and generation quality (human evaluations of diversity and plausibility).", "labels": [], "entities": [{"text": "generative modeling", "start_pos": 76, "end_pos": 95, "type": "TASK", "confidence": 0.9596921801567078}]}, {"text": "In Section 4.3, we focus on the semantics learned by the model and its latent edit vector space.", "labels": [], "entities": []}, {"text": "We demonstrate that it possesses interpretable semantics, enabling us to smoothly control the magnitude of edits, incrementally optimize sentences for target properties, and perform analogy-style sentence transformations.", "labels": [], "entities": [{"text": "analogy-style sentence transformations", "start_pos": 182, "end_pos": 220, "type": "TASK", "confidence": 0.6311171452204386}]}, {"text": "We evaluate perplexity on the Yelp review corpus) and the One Billion Word Language Model Benchmark (BILLIONWORD,).", "labels": [], "entities": [{"text": "Yelp review corpus", "start_pos": 30, "end_pos": 48, "type": "DATASET", "confidence": 0.9347901344299316}, {"text": "BILLIONWORD", "start_pos": 101, "end_pos": 112, "type": "METRIC", "confidence": 0.9649720191955566}]}, {"text": "For qualitative evaluations of generation quality and semantics, we focus on YELP as our primary test case, as we found that human judgments of semantic similarity were much better calibrated in this focused setting.", "labels": [], "entities": [{"text": "YELP", "start_pos": 77, "end_pos": 81, "type": "METRIC", "confidence": 0.8999677896499634}]}, {"text": "For both corpora, we used the named-entity recognizer (NER) in spaCy 2 to replace named entities with their NER categories.", "labels": [], "entities": []}, {"text": "We replaced tokens outside the top 10,000 most frequent tokens with an \"out-of-vocabulary\" token.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Perplexity of NEURALEDITOR with the two  VAE parameters \u03ba outperform all methods on YELP and  all non-ensemble methods on BILLIONWORD.", "labels": [], "entities": [{"text": "NEURALEDITOR", "start_pos": 24, "end_pos": 36, "type": "METRIC", "confidence": 0.6028229594230652}, {"text": "VAE", "start_pos": 51, "end_pos": 54, "type": "METRIC", "confidence": 0.9946033358573914}, {"text": "YELP", "start_pos": 94, "end_pos": 98, "type": "METRIC", "confidence": 0.6543469429016113}, {"text": "BILLIONWORD", "start_pos": 132, "end_pos": 143, "type": "METRIC", "confidence": 0.9153069853782654}]}, {"text": " Table 6: Edit vectors capture one-word sentence analogies with performance close to lexical analogies.", "labels": [], "entities": []}]}