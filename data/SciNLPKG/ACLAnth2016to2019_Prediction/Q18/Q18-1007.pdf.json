{"title": [{"text": "Towards Evaluating Narrative Quality In Student Writing", "labels": [], "entities": []}], "abstractContent": [{"text": "This work lays the foundation for automated assessments of narrative quality in student writing.", "labels": [], "entities": []}, {"text": "We first manually score essays for narrative-relevant traits and sub-traits, and measure inter-annotator agreement.", "labels": [], "entities": []}, {"text": "We then explore linguistic features that are indicative of good narrative writing and use them to build an automated scoring system.", "labels": [], "entities": []}, {"text": "Experiments show that our features are more effective in scoring specific aspects of narrative quality than a state-of-the-art feature set.", "labels": [], "entities": []}], "introductionContent": [{"text": "Narrative, which includes personal experiences and stories, real or imagined, is a medium of expression that is used from the very early stages of a child's life.", "labels": [], "entities": []}, {"text": "Narratives are also employed in various capacities in school instruction and assessment.", "labels": [], "entities": []}, {"text": "For example, the Common Core State Standards, an educational initiative in the United States that details requirements for student knowledge in grades K-12, employs literature/narratives as one of its three language arts genres.", "labels": [], "entities": [{"text": "Common Core State Standards", "start_pos": 17, "end_pos": 44, "type": "DATASET", "confidence": 0.9473646283149719}]}, {"text": "With the increased focus on automated evaluation of student writing in educational settings, automated methods for evaluating narrative essays at scale are becoming increasingly important.", "labels": [], "entities": []}, {"text": "Automated scoring of narrative essays is a challenging area, and one that has not been explored extensively in NLP research.", "labels": [], "entities": [{"text": "Automated scoring of narrative essays", "start_pos": 0, "end_pos": 37, "type": "TASK", "confidence": 0.8456275343894959}]}, {"text": "Previous work on automated essay scoring has focused on informational, argumentative, persuasive and source-based writing constructs (.", "labels": [], "entities": [{"text": "essay scoring", "start_pos": 27, "end_pos": 40, "type": "TASK", "confidence": 0.7106758058071136}]}, {"text": "Similarly, operational essay scoring engines ( are geared towards evaluating language proficiency in general.", "labels": [], "entities": [{"text": "operational essay scoring", "start_pos": 11, "end_pos": 36, "type": "TASK", "confidence": 0.6560770173867544}]}, {"text": "In this work, we lay the groundwork and present the first results for automated scoring of narrative essays, focusing on narrative quality.", "labels": [], "entities": [{"text": "automated scoring of narrative essays", "start_pos": 70, "end_pos": 107, "type": "TASK", "confidence": 0.6853146493434906}]}, {"text": "One of the challenges in narrative quality analysis is the scarcity of scored essays in this genre.", "labels": [], "entities": [{"text": "narrative quality analysis", "start_pos": 25, "end_pos": 51, "type": "TASK", "confidence": 0.6921145419279734}]}, {"text": "We describe a detailed manual annotation study on scoring student essays along multiple dimensions of narrative quality, such as narrative development and narrative organization.", "labels": [], "entities": [{"text": "narrative development", "start_pos": 129, "end_pos": 150, "type": "TASK", "confidence": 0.6980306655168533}]}, {"text": "Using a scoring rubric adapted from the U.S. Common Core State Standards, we annotated 942 essays written for 18 different essay-prompts by students from three different grade levels.", "labels": [], "entities": [{"text": "U.S. Common Core State Standards", "start_pos": 40, "end_pos": 72, "type": "DATASET", "confidence": 0.7615400671958923}]}, {"text": "This data set provides a variety of story types and language proficiency levels.", "labels": [], "entities": []}, {"text": "We measured inter-annotator agreement to understand reliability of scoring stories for traits (e.g., development) as well as sub-traits (e.g., plot development and the use of narrative techniques).", "labels": [], "entities": [{"text": "plot development", "start_pos": 143, "end_pos": 159, "type": "TASK", "confidence": 0.7267761081457138}]}, {"text": "A number of techniques for writing good stories are targeted by the scoring rubrics.", "labels": [], "entities": []}, {"text": "We implemented a system for automatically scoring different traits of narratives, using linguistic features that capture some of those techniques.", "labels": [], "entities": []}, {"text": "We investigated the effectiveness of each feature for scoring narrative traits and analyzed the results to identify sources of errors.", "labels": [], "entities": []}, {"text": "The main contributions of this work are as follows: (1) To the best of our knowledge, this is the first detailed annotation study on scoring narrative essays for different aspects of narrative quality.", "labels": [], "entities": []}], "datasetContent": [{"text": "Our experiments investigate the following questions: (1) Is it possible to score narrative quality traits in essays using automated methods?", "labels": [], "entities": []}, {"text": "(2) Which of our feature sets are effective for scoring narrative quality traits?", "labels": [], "entities": []}, {"text": "(3) How do our narrative-inspired features perform as compared to a baseline that is competitive but does not specifically address the narrative construct?", "labels": [], "entities": []}, {"text": "(4) How does overall scoring of narrative essays differ from trait scoring?", "labels": [], "entities": []}, {"text": "(5) What are the best feature combinations for narrative scoring?", "labels": [], "entities": [{"text": "narrative scoring", "start_pos": 47, "end_pos": 64, "type": "TASK", "confidence": 0.8690333366394043}]}, {"text": "To answer these questions, we built and evaluated scoring systems for each trait, overall Narrative and Total scores.", "labels": [], "entities": [{"text": "Total scores", "start_pos": 104, "end_pos": 116, "type": "METRIC", "confidence": 0.941448450088501}]}, {"text": "In each case, we performed detailed ablation studies at the feature-set level.", "labels": [], "entities": []}, {"text": "We have 10 features sets (9 feature sets described above plus a baseline feature set); thus 1024 feature set combinations were investigated.", "labels": [], "entities": []}, {"text": "As our traits are highly correlated, we used all of our features for building systems for each trait, leaving it to the ablation process to reveal the most promising feature set combination.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Score distributions for traits", "labels": [], "entities": []}, {"text": " Table 2. The  three main traits are shown in bold, the sub-traits are  prefixed with a \":\", and the composite traits (Narra- tive and Total) are shown in italics.", "labels": [], "entities": [{"text": "Total", "start_pos": 135, "end_pos": 140, "type": "METRIC", "confidence": 0.9655912518501282}]}, {"text": " Table 4: Performance (QWK) on predicting traits and Narrative and Total scores; Best feature combinations:  *For Organization: Details+ Modal+ Pronoun+ Content+ Graph+ Subjectivity+ Transition;  *For Development: Details+ Modal+ Content+ Graph+ Statives+ Transition;  *For Conventions: Baseline + Details + Graph;  *For Narrative: Baseline+ Details+ Modal+ Pronoun+ Content+ Graph+ Statives+ Subjectivity+ Transition;  *For Total: Details+ Baseline+ Modal+ Content+ Graph+ Subjectivity+ Transition", "labels": [], "entities": [{"text": "predicting traits", "start_pos": 31, "end_pos": 48, "type": "TASK", "confidence": 0.8713635504245758}]}, {"text": " Table 6: Human-machine confusion matrix for Develop- ment traits scores", "labels": [], "entities": []}]}