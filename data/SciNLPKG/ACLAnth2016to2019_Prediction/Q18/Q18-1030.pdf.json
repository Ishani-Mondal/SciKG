{"title": [{"text": "Universal Word Segmentation: Implementation and Interpretation", "labels": [], "entities": [{"text": "Universal Word Segmentation", "start_pos": 0, "end_pos": 27, "type": "TASK", "confidence": 0.624598870674769}]}], "abstractContent": [{"text": "Word segmentation is a low-level NLP task that is non-trivial fora considerable number of languages.", "labels": [], "entities": [{"text": "Word segmentation", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.7394377440214157}]}, {"text": "In this paper, we present a sequence tagging framework and apply it to word segmentation fora wide range of languages with different writing systems and ty-pological characteristics.", "labels": [], "entities": [{"text": "sequence tagging", "start_pos": 28, "end_pos": 44, "type": "TASK", "confidence": 0.7108755707740784}, {"text": "word segmentation", "start_pos": 71, "end_pos": 88, "type": "TASK", "confidence": 0.7414650917053223}]}, {"text": "Additionally, we investigate the correlations between various ty-pological factors and word segmentation accuracy.", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 87, "end_pos": 104, "type": "TASK", "confidence": 0.7435424327850342}, {"text": "accuracy", "start_pos": 105, "end_pos": 113, "type": "METRIC", "confidence": 0.8237142562866211}]}, {"text": "The experimental results indicate that segmentation accuracy is positively related to word boundary markers and negatively to the number of unique non-segmental terms.", "labels": [], "entities": [{"text": "segmentation", "start_pos": 39, "end_pos": 51, "type": "TASK", "confidence": 0.9445408582687378}, {"text": "accuracy", "start_pos": 52, "end_pos": 60, "type": "METRIC", "confidence": 0.9023540616035461}]}, {"text": "Based on the analysis, we design a small set of language-specific settings and extensively evaluate the segmentation system on the Universal Dependencies datasets.", "labels": [], "entities": [{"text": "segmentation", "start_pos": 104, "end_pos": 116, "type": "TASK", "confidence": 0.9685059785842896}, {"text": "Universal Dependencies datasets", "start_pos": 131, "end_pos": 162, "type": "DATASET", "confidence": 0.8546073834101359}]}, {"text": "Our model obtains state-of-the-art accuracies on all the UD languages.", "labels": [], "entities": []}, {"text": "It performs substantially better on languages that are non-trivial to segment, such as Chinese, Japanese, Arabic and He-brew, when compared to previous work.", "labels": [], "entities": []}], "introductionContent": [{"text": "Word segmentation is the initial step for most higher level natural language processing tasks, such as part-of-speech tagging (POS), parsing and machine translation.", "labels": [], "entities": [{"text": "Word segmentation", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.7016475945711136}, {"text": "part-of-speech tagging (POS)", "start_pos": 103, "end_pos": 131, "type": "TASK", "confidence": 0.8349897682666778}, {"text": "parsing", "start_pos": 133, "end_pos": 140, "type": "TASK", "confidence": 0.9533393979072571}, {"text": "machine translation", "start_pos": 145, "end_pos": 164, "type": "TASK", "confidence": 0.7786417305469513}]}, {"text": "It can be regarded as the problem of correctly identifying word forms from a character string.", "labels": [], "entities": []}, {"text": "Word segmentation can be very challenging, especially for languages without explicit word boundary delimiters, such as Chinese, Japanese and Vietnamese.", "labels": [], "entities": [{"text": "Word segmentation", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.7069379389286041}]}, {"text": "Even for space-delimited languages like English or Russian, relying on white space alone generally does not result in adequate segmentation as at least punctuation should usually be separated from the attached words.", "labels": [], "entities": []}, {"text": "For some languages, the space-delimited units in the surface form are too coarse-grained and therefore often further analysed, as in the cases of Arabic and Hebrew.", "labels": [], "entities": []}, {"text": "Even though language-specific word segmentation systems are near-perfect for some languages, it is still useful to have a single system that performs reasonably with no or minimum language-specific adaptations.", "labels": [], "entities": [{"text": "language-specific word segmentation", "start_pos": 12, "end_pos": 47, "type": "TASK", "confidence": 0.6153648495674133}]}, {"text": "Word segmentation standards vary substantially with different definitions of the concept of a word.", "labels": [], "entities": [{"text": "Word segmentation", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.6690755933523178}]}, {"text": "In this paper, we will follow the teminologies of Universal Dependencies (UD), where words are defined as basic syntactic units that do not always coincide with phonological or orthographic words.", "labels": [], "entities": [{"text": "Universal Dependencies (UD)", "start_pos": 50, "end_pos": 77, "type": "TASK", "confidence": 0.685686981678009}]}, {"text": "Some orthographic tokens, known in UD as multiword tokens, therefore need to be broken into smaller units that cannot always be obtained by splitting the input character sequence.", "labels": [], "entities": []}, {"text": "To perform word segmentation in the UD framework, neither rule-based tokenisers that rely on white space nor the naive character-level sequence tagging model proposed previously are ideal.", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 11, "end_pos": 28, "type": "TASK", "confidence": 0.7679922878742218}, {"text": "character-level sequence tagging", "start_pos": 119, "end_pos": 151, "type": "TASK", "confidence": 0.650534470876058}]}, {"text": "In this paper, we present an enriched sequence labelling model for universal word segmentation.", "labels": [], "entities": [{"text": "universal word segmentation", "start_pos": 67, "end_pos": 94, "type": "TASK", "confidence": 0.6926185588041941}]}, {"text": "It is capable of segmenting languages in very diverse written forms.", "labels": [], "entities": []}, {"text": "Furthermore, it simultaneously identifies the multiword tokens defined by the UD framework that cannot be resolved simply by splitting Note that this notion of multiword token has nothing to do with the notion of multiword expression (MWE) as discussed, for example, in. the input character sequence.", "labels": [], "entities": []}, {"text": "We adapt a regular sequence tagging model, namely the bidirectional recurrent neural networks with conditional random fields (CRF) () interface as the fundamental framework (BiRNN-CRF) ) for word segmentation.", "labels": [], "entities": [{"text": "BiRNN-CRF", "start_pos": 174, "end_pos": 183, "type": "METRIC", "confidence": 0.8658924102783203}, {"text": "word segmentation", "start_pos": 191, "end_pos": 208, "type": "TASK", "confidence": 0.7874433398246765}]}, {"text": "The main contributions of this work include: 1.", "labels": [], "entities": []}, {"text": "We propose a sequence tagging model for word segmentation, both for general purposes (mere splitting) and full UD processing (splitting plus occasional transduction).", "labels": [], "entities": [{"text": "sequence tagging", "start_pos": 13, "end_pos": 29, "type": "TASK", "confidence": 0.6948526799678802}, {"text": "word segmentation", "start_pos": 40, "end_pos": 57, "type": "TASK", "confidence": 0.7881365120410919}, {"text": "UD processing", "start_pos": 111, "end_pos": 124, "type": "TASK", "confidence": 0.9529887437820435}]}, {"text": "2. We investigate the correlation between segmentation accuracy and properties of languages and writing systems, which is helpful in interpreting the gaps between segmentation accuracies across different languages as well as selecting language-specific settings for the model.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 55, "end_pos": 63, "type": "METRIC", "confidence": 0.7721174955368042}]}, {"text": "3. Our segmentation system achieves state-of-theart accuracy on the UD datasets and improves on previous work especially for the most challenging languages.", "labels": [], "entities": [{"text": "segmentation", "start_pos": 7, "end_pos": 19, "type": "TASK", "confidence": 0.9740496277809143}, {"text": "accuracy", "start_pos": 52, "end_pos": 60, "type": "METRIC", "confidence": 0.9928879141807556}, {"text": "UD datasets", "start_pos": 68, "end_pos": 79, "type": "DATASET", "confidence": 0.7810289859771729}]}, {"text": "4. We provide an open source implementation.", "labels": [], "entities": []}], "datasetContent": [{"text": "Datasets from Universal Dependencies 2.0 ( are used for all the word segmentation experiments.", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 64, "end_pos": 81, "type": "TASK", "confidence": 0.748193234205246}]}, {"text": "In total, there are 81 datasets in 49 languages that vary substantially in size.", "labels": [], "entities": []}, {"text": "The training sets are available in 45 languages.", "labels": [], "entities": []}, {"text": "We follow the standard splits of the datasets.", "labels": [], "entities": []}, {"text": "If no development set is available, 10% of the training set is subtracted.", "labels": [], "entities": []}, {"text": "We adopt word-level precision, recall and F1-score as the evaluation metrics.", "labels": [], "entities": [{"text": "precision", "start_pos": 20, "end_pos": 29, "type": "METRIC", "confidence": 0.8756492137908936}, {"text": "recall", "start_pos": 31, "end_pos": 37, "type": "METRIC", "confidence": 0.9993669390678406}, {"text": "F1-score", "start_pos": 42, "end_pos": 50, "type": "METRIC", "confidence": 0.9988561868667603}]}, {"text": "The candidate and the reference word sequences in our experiments may not share the same underlying characters due to the transduction of non-segmental multiword tokens.", "labels": [], "entities": []}, {"text": "The alignment between the candidate words and the references becomes unclear and therefore it is difficult to compute the associated scores.", "labels": [], "entities": []}, {"text": "To resolve this issue, we use the longest common subsequence algorithm to align the candidate and the reference words.", "labels": [], "entities": []}, {"text": "The matched words are compared and the evaluation scores are computed accordingly: where c and r denote the sequences of candidate words and reference words, and |c|, |r| are their  lengths.", "labels": [], "entities": []}, {"text": "|c\u2229r| is the number of candidate words that are aligned to reference words by the longest common subsequence algorithm.", "labels": [], "entities": []}, {"text": "The word-level evaluation metrics adopted in this paper are different from the boundary-based alternatives).", "labels": [], "entities": []}, {"text": "We adapt the evaluation script from the CoNLL 2017 shared task () to calculate the scores.", "labels": [], "entities": [{"text": "CoNLL 2017 shared task", "start_pos": 40, "end_pos": 62, "type": "DATASET", "confidence": 0.9203813821077347}]}, {"text": "In the following experiments, we only report the F1-score.", "labels": [], "entities": [{"text": "F1-score", "start_pos": 49, "end_pos": 57, "type": "METRIC", "confidence": 0.999457061290741}]}, {"text": "In the following sections, we thoroughly investigate correlations between several language-specific characteristics and segmentation accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 133, "end_pos": 141, "type": "METRIC", "confidence": 0.9787774085998535}]}, {"text": "All the experimental results in Section 6.2 are obtained on the development sets.", "labels": [], "entities": []}, {"text": "The test sets are reserved for final evaluation, reported in Section 6.3.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Pearson product-moment correlation coeffi- cients between dataset size and the statistical factors.", "labels": [], "entities": []}, {"text": " Table 2: Different UD datasets in same languages  and the statistical factors.", "labels": [], "entities": [{"text": "UD datasets", "start_pos": 20, "end_pos": 31, "type": "DATASET", "confidence": 0.8264705240726471}]}, {"text": " Table 4: Hyper-parameters for segmentation.", "labels": [], "entities": [{"text": "segmentation", "start_pos": 31, "end_pos": 43, "type": "TASK", "confidence": 0.9797699451446533}]}, {"text": " Table 5: Different segmentation units employed for  word segmentation on Vietnamese. Concatenated 3- gram is not used.", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 53, "end_pos": 70, "type": "TASK", "confidence": 0.7584003806114197}]}, {"text": " Table 6: Accuracy of the seq2seq transducer on Ara- bic and Hebrew.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9970303773880005}]}, {"text": " Table 7: Segmentation accuracies on Arabic and  Hebrew with different ways of transducing non- segmental multiword tokens.", "labels": [], "entities": [{"text": "transducing non- segmental multiword tokens", "start_pos": 79, "end_pos": 122, "type": "TASK", "confidence": 0.8381195763746897}]}, {"text": " Table 8: Average evaluation scores on UD lan- guages, excluding Chinese, Japanese, Vietnamese,  Arabic and Hebrew.", "labels": [], "entities": [{"text": "UD lan- guages", "start_pos": 39, "end_pos": 53, "type": "DATASET", "confidence": 0.7747451961040497}]}, {"text": " Table 9: Evaluation results on the UD test sets in F1-scores. The datasets are represented in the correspond- ing treebank codes. PUD suffix indicates the parallel test data. Two shades of green/red are used for better  visualisation, with brighter colours for larger differences. Green represents that our system is better than  UDPipe and red is used otherwise.", "labels": [], "entities": [{"text": "UD test sets", "start_pos": 36, "end_pos": 48, "type": "DATASET", "confidence": 0.8266913294792175}, {"text": "F1-scores", "start_pos": 52, "end_pos": 61, "type": "METRIC", "confidence": 0.9710487127304077}, {"text": "PUD suffix", "start_pos": 131, "end_pos": 141, "type": "METRIC", "confidence": 0.896996408700943}, {"text": "UDPipe", "start_pos": 331, "end_pos": 337, "type": "DATASET", "confidence": 0.9259495139122009}]}, {"text": " Table 10: Comparison between the binary tags (BT)  and the fine-grained tags (FT) as well as the effec- tiveness of the CRF interface on the development  sets.", "labels": [], "entities": [{"text": "fine-grained tags (FT)", "start_pos": 60, "end_pos": 82, "type": "METRIC", "confidence": 0.6537044227123261}]}, {"text": " Table 12: Extrinsic evaluations with dependency parsing on the test sets. The parsing accuracies are reported  in unlabelled attachment score (UAS) and labelled attachment score (LAS).", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 38, "end_pos": 56, "type": "TASK", "confidence": 0.7084701806306839}, {"text": "unlabelled attachment score (UAS)", "start_pos": 115, "end_pos": 148, "type": "METRIC", "confidence": 0.7845883866151174}, {"text": "labelled attachment score (LAS)", "start_pos": 153, "end_pos": 184, "type": "METRIC", "confidence": 0.879499355951945}]}, {"text": " Table 13: Evaluation on the surprise languages.", "labels": [], "entities": []}, {"text": " Table 14: Comparison between the universal model  and the language-specific models.", "labels": [], "entities": []}]}