{"title": [{"text": "Mind the GAP: A Balanced Corpus of Gendered Ambiguous Pronouns", "labels": [], "entities": []}], "abstractContent": [{"text": "Coreference resolution is an important task for natural language understanding, and the resolution of ambiguous pronouns a longstanding challenge.", "labels": [], "entities": [{"text": "Coreference resolution", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.934066891670227}, {"text": "natural language understanding", "start_pos": 48, "end_pos": 78, "type": "TASK", "confidence": 0.6552747686704}, {"text": "resolution of ambiguous pronouns", "start_pos": 88, "end_pos": 120, "type": "TASK", "confidence": 0.8266272842884064}]}, {"text": "Nonetheless, existing corpora do not capture ambiguous pronouns in sufficient volume or diversity to accurately indicate the practical utility of models.", "labels": [], "entities": []}, {"text": "Furthermore, we find gender bias in existing corpora and systems favoring masculine entities.", "labels": [], "entities": []}, {"text": "To address this, we present and release GAP, a gender-balanced labeled corpus of 8,908 ambiguous pronoun-name pairs sampled to provide diverse coverage of challenges posed by real-world text.", "labels": [], "entities": []}, {"text": "We explore a range of baselines that demonstrate the complexity of the challenge, the best achieving just 66.9% F1.", "labels": [], "entities": [{"text": "F1", "start_pos": 112, "end_pos": 114, "type": "METRIC", "confidence": 0.9996185302734375}]}, {"text": "We show that syntactic structure and continuous neural models provide promising, complementary cues for approaching the challenge.", "labels": [], "entities": []}], "introductionContent": [{"text": "Coreference resolution involves linking referring expressions that evoke the same discourse entity, as defined in shared tasks such as) and MUC (.", "labels": [], "entities": [{"text": "Coreference resolution", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.9194991290569305}, {"text": "MUC", "start_pos": 140, "end_pos": 143, "type": "DATASET", "confidence": 0.7238101959228516}]}, {"text": "Unfortunately, high scores on these tasks do not necessarily translate into acceptable performance for downstream applications such as machine translation and fact extraction.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 135, "end_pos": 154, "type": "TASK", "confidence": 0.8410024642944336}, {"text": "fact extraction", "start_pos": 159, "end_pos": 174, "type": "TASK", "confidence": 0.7892171144485474}]}, {"text": "In particular, high-scoring systems successfully identify coreference relationships between string-matching proper names, but fare worse on anaphoric mentions such as pronouns and common noun phrases (.", "labels": [], "entities": []}, {"text": "We consider the problem of resolving gendered ambiguous pronouns in English, such as she 1 in: (1) In May, Fujisawa joined Mari Motohashi's rink as the team's skip, moving back from Karuizawa to Kitami where she had spent her junior days.", "labels": [], "entities": [{"text": "Fujisawa", "start_pos": 107, "end_pos": 115, "type": "METRIC", "confidence": 0.9657679200172424}]}, {"text": "With this scope, we make three key contributions: \u2022 We design an extensible, language-independent mechanism for extracting challenging ambiguous pronouns from text.", "labels": [], "entities": [{"text": "extracting challenging ambiguous pronouns from text", "start_pos": 112, "end_pos": 163, "type": "TASK", "confidence": 0.8199486831823984}]}, {"text": "\u2022 We build and release GAP, a human-labeled corpus of 8,908 ambiguous pronoun-name pairs derived from Wikipedia.", "labels": [], "entities": []}, {"text": "This data set targets the challenges of resolving naturally occurring ambiguous pronouns and rewards systems that are gender-fair.", "labels": [], "entities": []}, {"text": "\u2022 We run four state-of-the-art coreference resolvers and several competitive simple baselines on GAP to understand limitations in current modeling, including gender bias.", "labels": [], "entities": [{"text": "coreference resolvers", "start_pos": 31, "end_pos": 52, "type": "TASK", "confidence": 0.9105472564697266}]}, {"text": "We find that syntactic structure and transformer models () provide promising, complementary cues for approaching GAP.", "labels": [], "entities": [{"text": "GAP", "start_pos": 113, "end_pos": 116, "type": "TASK", "confidence": 0.9426472783088684}]}, {"text": "Coreference resolution decisions can drastically alter how automatic systems process text.", "labels": [], "entities": [{"text": "Coreference resolution", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.9196518063545227}]}, {"text": "Biases in automatic systems have caused a wide range of underrepresented groups to be served in an inequitable way by downstream applications.", "labels": [], "entities": []}, {"text": "We take the construction of the new GAP corpus as an opportunity to reduce gender bias in coreference data sets; in this way, GAP can promote equitable modeling of reference phenomena complementary to the recent work of and.", "labels": [], "entities": [{"text": "GAP corpus", "start_pos": 36, "end_pos": 46, "type": "DATASET", "confidence": 0.7855595052242279}]}, {"text": "The examples throughout the paper highlight the ambiguous pronoun in bold, the two potential coreferent names in italics, and the correct one also underlined.", "labels": [], "entities": []}, {"text": "2 http://goo.gl/language/gap-coreference.", "labels": [], "entities": []}, {"text": "Such approaches promise to improve equity of downstream models, such as triple extraction for knowledge-base populations.", "labels": [], "entities": [{"text": "triple extraction", "start_pos": 72, "end_pos": 89, "type": "TASK", "confidence": 0.7444723546504974}]}], "datasetContent": [{"text": "We setup the GAP challenge and analyze the applicability of a range of off-the-shelf tools.", "labels": [], "entities": [{"text": "GAP challenge", "start_pos": 13, "end_pos": 26, "type": "TASK", "confidence": 0.9262497425079346}]}, {"text": "We find that existing resolvers do not perform well and are biased to favor better resolution of masculine pronouns.", "labels": [], "entities": []}, {"text": "We empirically validate the observation that Transformer models ( encode coreference relationships, adding to the results by Furthermore, we show they complement traditional linguistic cues such as syntactic distance and parallelism.", "labels": [], "entities": []}, {"text": "All experiments use the Google Cloud NL API 7 for pre-processing, unless otherwise noted.", "labels": [], "entities": [{"text": "Google Cloud NL API 7", "start_pos": 24, "end_pos": 45, "type": "DATASET", "confidence": 0.8493843793869018}]}], "tableCaptions": [{"text": " Table 3: Consensus label counts for the extracted  examples (Raw) and after further filtering (Final).", "labels": [], "entities": []}, {"text": " Table 4: Performance of off-the-shelf resolvers on  the GAP development set, split by Masculine and  Feminine (Bias shows F/M), and Overall. Bold indi- cates best performance.", "labels": [], "entities": [{"text": "GAP development set", "start_pos": 57, "end_pos": 76, "type": "DATASET", "confidence": 0.7170023918151855}, {"text": "Masculine", "start_pos": 87, "end_pos": 96, "type": "METRIC", "confidence": 0.9735735058784485}]}, {"text": " Table 5: Pronoun-name F1 score, by gender, of off- the-shelf systems on the OntoNotes test set. Scores  based on 2,091 masculine pronoun-named entity pairs  (in 403 clusters) and 1,095 feminine pairs (in 104 clus- ters). Bold indicates best performance.", "labels": [], "entities": [{"text": "F1 score", "start_pos": 23, "end_pos": 31, "type": "METRIC", "confidence": 0.8940803110599518}, {"text": "OntoNotes test set", "start_pos": 77, "end_pos": 95, "type": "DATASET", "confidence": 0.9460252324740092}]}, {"text": " Table 6: Performance of our baselines on the devel- opment set. Parallelism+URL tests the page-context  setting; all other test the snippet-context setting. Bold  indicates best performance in each setting.", "labels": [], "entities": []}, {"text": " Table 8: Coreference signal of a Transformer model on  the validation dataset, by encoder attention layer and  head.", "labels": [], "entities": []}, {"text": " Table 9: Comparison of the predictions of the PARAL- LELISM and TRANSFORMER-SINGLE heuristics over  the GAP development dataset.", "labels": [], "entities": [{"text": "PARAL- LELISM", "start_pos": 47, "end_pos": 60, "type": "METRIC", "confidence": 0.8835922479629517}, {"text": "GAP development dataset", "start_pos": 105, "end_pos": 128, "type": "DATASET", "confidence": 0.6497802436351776}]}, {"text": " Table 10: Baselines on the GAP challenge test set.", "labels": [], "entities": [{"text": "GAP challenge test set", "start_pos": 28, "end_pos": 50, "type": "DATASET", "confidence": 0.8428167849779129}]}]}