{"title": [{"text": "Bootstrap Domain-Specific Sentiment Classifiers from Unlabeled Corpora", "labels": [], "entities": []}], "abstractContent": [{"text": "There is often the need to perform sentiment classification in a particular domain where no labeled document is available.", "labels": [], "entities": [{"text": "sentiment classification", "start_pos": 35, "end_pos": 59, "type": "TASK", "confidence": 0.9611328542232513}]}, {"text": "Although we could make use of a general-purpose off-the-shelf sentiment classifier or a pre-built one fora different domain, the effectiveness would be inferior.", "labels": [], "entities": []}, {"text": "In this paper, we explore the possibility of building domain-specific sentiment clas-sifiers with u nlabeled d ocuments o nly.", "labels": [], "entities": []}, {"text": "Our investigation indicates that in the word em-beddings learned from the unlabeled corpus of a given domain, the distributed word representations (vectors) for opposite sentiments form distinct clusters, though those clusters are not transferable across domains.", "labels": [], "entities": []}, {"text": "Exploiting such a clustering structure, we are able to utilize machine learning algorithms to induce a quality domain-specific sentiment lexicon from just a few typical sentiment words (\"seeds\").", "labels": [], "entities": []}, {"text": "An important finding is that simple linear model based supervised learning algorithms (such as linear SVM) can actually work better than more sophisticated semi-supervised/transductive learning algorithms which represent the state-of-the-art technique for sentiment lexicon induction.", "labels": [], "entities": [{"text": "sentiment lexicon induction", "start_pos": 256, "end_pos": 283, "type": "TASK", "confidence": 0.9680364727973938}]}, {"text": "The induced lexicon could be applied directly in a lexicon-based method for sentiment classification , but ah igher performance could be achieved through a two-phase bootstrapping method which uses the induced lexicon to assign positive/negative sentiment scores to un-labeled documents first, and then u ses those documents found to have clear sentiment signals as pseudo-labeled examples to train a document sentiment classifier via supervised learning algorithms (such as LSTM).", "labels": [], "entities": [{"text": "sentiment classification", "start_pos": 76, "end_pos": 100, "type": "TASK", "confidence": 0.9030840992927551}]}, {"text": "On several benchmark datasets for document sentiment classification, our end-to-end pipelined approach which is overall unsupervised (ex-cept fora tiny set of seed words) outper-forms existing unsupervised approaches and achieves an accuracy comparable to that of fully supervised approaches.", "labels": [], "entities": [{"text": "document sentiment classification", "start_pos": 34, "end_pos": 67, "type": "TASK", "confidence": 0.805417795976003}, {"text": "accuracy", "start_pos": 233, "end_pos": 241, "type": "METRIC", "confidence": 0.9988415837287903}]}], "introductionContent": [{"text": "Sentiment analysis) is a popular research topic which has a wide range of applications, such as summarizing customer reviews, monitoring social media, and predicting stock market trends.", "labels": [], "entities": [{"text": "Sentiment analysis", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.8636192083358765}, {"text": "summarizing customer reviews", "start_pos": 96, "end_pos": 124, "type": "TASK", "confidence": 0.8857476909955343}, {"text": "predicting stock market", "start_pos": 155, "end_pos": 178, "type": "TASK", "confidence": 0.8722769816716512}]}, {"text": "A basic task in sentiment analysis is to classify the sentiment polarity of a given piece of text (document), i.e., whether the opinion expressed in the text is positive or negative (), which is the focus of this paper.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 16, "end_pos": 34, "type": "TASK", "confidence": 0.9487409293651581}]}, {"text": "There are many different approaches to sentiment classification in the Natural Language Processing (NLP) literature -from simple lexicon-based methods () to learning-based approaches (, and also hybrid methods in between.", "labels": [], "entities": [{"text": "sentiment classification", "start_pos": 39, "end_pos": 63, "type": "TASK", "confidence": 0.9552184641361237}]}, {"text": "No matter which approach is taken, a sentiment classifier built for its target domain would work well only within that specific domain, but suffer a serious performance loss once the domain boundary is crossed.", "labels": [], "entities": []}, {"text": "The same word could drastically change its sentiment polarity (and/or strength) if it is used in a different domain.", "labels": [], "entities": []}, {"text": "For example, being \"small\" is likely to be negative fora hotel room but positive fora digital camcorder, being \"unexpected\" maybe a good thing for the ending of a movie but not for the engine of a car, and we will probably enjoy \"interesting\" books but not necessarily \"interesting\" food.", "labels": [], "entities": []}, {"text": "Here, the domain could be defined not by the topic of the documents but by the style of writing.", "labels": [], "entities": []}, {"text": "For example, the meanings of words like \"gay\" and \"terrific\" would depend on whether the text was written in a historical era or modern times.", "labels": [], "entities": []}, {"text": "When we need to perform sentiment classification in anew domain unseen before, there are usually neither labeled dictionary available to employ lexicon-based sentiment classifiers nor labeled corpus available to train learning-based sentiment classifiers.", "labels": [], "entities": [{"text": "sentiment classification", "start_pos": 24, "end_pos": 48, "type": "TASK", "confidence": 0.906918853521347}]}, {"text": "It is, of course, possible to resort to a generalpurpose off-the-shelf sentiment classifier, or a prebuilt one fora different domain.", "labels": [], "entities": [{"text": "generalpurpose off-the-shelf sentiment classifier", "start_pos": 42, "end_pos": 91, "type": "TASK", "confidence": 0.6216164007782936}]}, {"text": "However, the effectiveness would often be unsatisfactory because of the reasons mentioned above.", "labels": [], "entities": []}, {"text": "There have been some studies on domain adaptation or transfer learning for sentiment classification), but they still require a large amount of labeled training data from a fairly similar source domain, which is not always feasible.", "labels": [], "entities": [{"text": "domain adaptation", "start_pos": 32, "end_pos": 49, "type": "TASK", "confidence": 0.7566133141517639}, {"text": "sentiment classification", "start_pos": 75, "end_pos": 99, "type": "TASK", "confidence": 0.9746344983577728}]}, {"text": "Those algorithms also tend to be computational-expensive and time-consuming.", "labels": [], "entities": []}, {"text": "In this paper, we propose an end-to-end pipelined nearly-unsupervised approach to domain-specific sentiment classification of documents fora new domain based on distributed word representations (vectors).", "labels": [], "entities": [{"text": "domain-specific sentiment classification of documents", "start_pos": 82, "end_pos": 135, "type": "TASK", "confidence": 0.7834735751152039}]}, {"text": "As shown in, the proposed approach consists of three main stages (components): (1) domain-specific sentiment word embedding, (2) domain-specific sentiment lexicon induction, (3) domain-specific sentiment classification of documents.", "labels": [], "entities": [{"text": "domain-specific sentiment word embedding", "start_pos": 83, "end_pos": 123, "type": "TASK", "confidence": 0.6168603226542473}, {"text": "domain-specific sentiment lexicon induction", "start_pos": 129, "end_pos": 172, "type": "TASK", "confidence": 0.6741952151060104}, {"text": "domain-specific sentiment classification of documents", "start_pos": 178, "end_pos": 231, "type": "TASK", "confidence": 0.7619530975818634}]}, {"text": "Briefly speaking, given a large unlabeled corpus fora new domain, we would first setup the vector space for that domain via word embedding, then induce a sentiment lexicon in the discovered vector space from a very small set of seed words as well as a general-purpose lexicon, and finally exploit the induced lexicon in a lexicon-based document sentiment classifier to bootstrap a more effective learning-based document sentiment classifier for that domain.", "labels": [], "entities": []}, {"text": "The second stage of our approach outperforms the state-of-the-art unsupervised method for sentiment lexicon induction (, which is the most closely related work (see Section 2).", "labels": [], "entities": [{"text": "sentiment lexicon induction", "start_pos": 90, "end_pos": 117, "type": "TASK", "confidence": 0.9550402760505676}]}, {"text": "The key to the superior performance of our method compared with theirs is the insight gained from our first stage that positive and negative sentiment words are largely clustered in the domain-specific vector space but these two clusters have a non-negligible overlap, therefore semisupervised/transductive learning algorithms could be easily misled by the examples in the overlap and would actually notwork as well as simple supervised classification algorithms.", "labels": [], "entities": []}, {"text": "Overall, the document sentiment classifier resulting from our nearlyunsupervised approach does not require any labeled document to be trained, and it can outperform the state-of-the-art unsupervised method for document sentiment classification.", "labels": [], "entities": [{"text": "document sentiment classifier", "start_pos": 13, "end_pos": 42, "type": "TASK", "confidence": 0.7695257663726807}, {"text": "document sentiment classification", "start_pos": 210, "end_pos": 243, "type": "TASK", "confidence": 0.8016410569349924}]}, {"text": "The source code for our implemented system and the datasets for our experiments are open to the research community . The rest of this paper is organized as follows.", "labels": [], "entities": []}, {"text": "In Section 2, we review previous studies on this topic.", "labels": [], "entities": []}, {"text": "In Sections 3 to 5, we describe the three main stages of our approach respectively.", "labels": [], "entities": []}, {"text": "In Section 6, we draw conclusions and discuss future work.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 2: Comparing the induced lexicons with their corresponding known lexicons (ground-truth) according  to the ranking of sentiment words measured by AU C and Kendall's \u03c4 .", "labels": [], "entities": []}, {"text": " Table 3: Lexicon-based sentiment classification of Amazon Kitchen product reviews.", "labels": [], "entities": [{"text": "Lexicon-based sentiment classification", "start_pos": 10, "end_pos": 48, "type": "TASK", "confidence": 0.6748132606347402}, {"text": "Amazon Kitchen product reviews", "start_pos": 52, "end_pos": 82, "type": "DATASET", "confidence": 0.7848191112279892}]}, {"text": " Table 4: Sentiment classification of long texts.", "labels": [], "entities": [{"text": "Sentiment classification of long texts", "start_pos": 10, "end_pos": 48, "type": "TASK", "confidence": 0.9306395769119262}]}, {"text": " Table 5: Sentiment classification of short texts into  two categories -SemEval-2017 Task 4B.", "labels": [], "entities": [{"text": "Sentiment classification of short texts", "start_pos": 10, "end_pos": 49, "type": "TASK", "confidence": 0.9443901777267456}]}, {"text": " Table 6: Sentiment classification of short texts on a five-point scale -SemEval-2017 Task 4C.", "labels": [], "entities": [{"text": "Sentiment classification of short texts", "start_pos": 10, "end_pos": 49, "type": "TASK", "confidence": 0.9446614503860473}]}]}