{"title": [{"text": "Learning Typed Entailment Graphs with Global Soft Constraints", "labels": [], "entities": []}], "abstractContent": [{"text": "This paper presents anew method for learning typed entailment graphs from text.", "labels": [], "entities": []}, {"text": "We extract predicate-argument structures from multiple-source news corpora, and compute local distributional similarity scores to learn entailments between predicates with typed arguments (e.g., person contracted disease).", "labels": [], "entities": [{"text": "distributional similarity scores", "start_pos": 94, "end_pos": 126, "type": "METRIC", "confidence": 0.638761838277181}]}, {"text": "Previous work has used transitivity constraints to improve local decisions, but these constraints are intractable on large graphs.", "labels": [], "entities": []}, {"text": "We instead propose a scalable method that learns globally consistent similarity scores based on new soft constraints that consider both the structures across typed entailment graphs and inside each graph.", "labels": [], "entities": []}, {"text": "Learning takes only a few hours to run over 100K predicates, and our results show large improvements over local similarity scores on two entailment data sets.", "labels": [], "entities": []}, {"text": "We further show improvements over paraphrases and entailments from the Paraphrase Database and prior state-of-the-art entailment graphs.", "labels": [], "entities": [{"text": "Paraphrase Database", "start_pos": 71, "end_pos": 90, "type": "DATASET", "confidence": 0.940832108259201}]}, {"text": "We show that the entailment graphs improve performance in a downstream task.", "labels": [], "entities": []}], "introductionContent": [{"text": "Recognizing textual entailment and paraphrasing is critical to many core natural language processing applications such as question answering and semantic parsing.", "labels": [], "entities": [{"text": "question answering", "start_pos": 122, "end_pos": 140, "type": "TASK", "confidence": 0.9175736308097839}, {"text": "semantic parsing", "start_pos": 145, "end_pos": 161, "type": "TASK", "confidence": 0.7029548734426498}]}, {"text": "The surface form of a sentence that answers a question such as \"Does Verizon own Yahoo?\" frequently does not directly correspond to the form of the question, but is rather a paraphrase or an expression such as \"Verizon bought Yahoo,\" that entails the answer.", "labels": [], "entities": []}, {"text": "The lack of a well-established form-independent semantic representation for natural language is the most important single obstacle to bridging the gap between queries and text resources.", "labels": [], "entities": []}, {"text": "This paper seeks to learn meaning postulates (e.g., buying entails owning) that can be used to augment the standard form-dependent semantics.", "labels": [], "entities": []}, {"text": "Our immediate goal is to learn entailment rules between typed predicates with two arguments, where the type of each predicate is determined by the types of its arguments.", "labels": [], "entities": []}, {"text": "We construct typed entailment graphs, with typed predicates as nodes and entailment rules as edges.", "labels": [], "entities": []}, {"text": "shows simple examples of such graphs with arguments of types company,company and person,location.", "labels": [], "entities": []}, {"text": "Entailment relations are detected computing a similarity score between the typed predicates based on the distributional inclusion hypothesis, which states that a word (predicate) u entails another word (predicate) v if in any context that u can be used, v can be used in its place ().", "labels": [], "entities": [{"text": "similarity score", "start_pos": 46, "end_pos": 62, "type": "METRIC", "confidence": 0.9444583058357239}]}, {"text": "Most previous work has taken a \"local learning\" approach, namely, learning entailment rules independently from each other.", "labels": [], "entities": []}, {"text": "One problem facing local learning approaches is that many correct edges are not identified because of data sparsity and many wrong edges are spuriously identified as valid entailments.", "labels": [], "entities": []}, {"text": "A \"global learning\" approach, where dependencies between entailment rules are taken into account, can improve the local decisions significantly.", "labels": [], "entities": []}, {"text": "imposed transitivity constraints on the entailments, such that the inclusion of rules i\u2192j and j\u2192k implies that of i\u2192k.", "labels": [], "entities": []}, {"text": "Although they showed transitivity constraints to be effective in learning entailment graphs, the Integer Linear Programming (ILP) solution of Berant et al. is not scalable beyond a few hundred nodes.", "labels": [], "entities": []}, {"text": "In fact, the problem of finding a maximally weighted transitive subgraph of a graph with arbitrary edge weights is NP-hard).", "labels": [], "entities": []}, {"text": "This paper instead proposes a scalable solution that does not rely on transitivity closure, but instead uses two global soft constraints that maintain structural similarity both across and within each typed entailment graph ().", "labels": [], "entities": [{"text": "transitivity closure", "start_pos": 70, "end_pos": 90, "type": "TASK", "confidence": 0.6957866698503494}]}, {"text": "We introduce an unsupervised framework to learn globally consistent similarity scores given local similarity scores ( \u00a74).", "labels": [], "entities": []}, {"text": "Our method is highly parallelizable and takes only a few hours to apply to more than 100K predicates.", "labels": [], "entities": []}, {"text": "Our experiments ( \u00a76) show that the global scores improve significantly over local scores and outperform state-of-the-art entailment graphs on two standard entailment rule data sets.", "labels": [], "entities": []}, {"text": "We ultimately intend the typed entailment graphs to provide a resource for entailment and paraphrase rules for use in semantic parsing and open domain question answering, as has been done for similar resources such as the Paraphrase Database (PPDB;) in and.", "labels": [], "entities": [{"text": "semantic parsing", "start_pos": 118, "end_pos": 134, "type": "TASK", "confidence": 0.7263737469911575}, {"text": "open domain question answering", "start_pos": 139, "end_pos": 169, "type": "TASK", "confidence": 0.5790800228714943}]}, {"text": "With that end in view, we have included a comparison with PPDB in our evaluation on the entailment data sets.", "labels": [], "entities": [{"text": "PPDB", "start_pos": 58, "end_pos": 62, "type": "DATASET", "confidence": 0.8853923082351685}, {"text": "entailment data sets", "start_pos": 88, "end_pos": 108, "type": "DATASET", "confidence": 0.7668861548105875}]}, {"text": "We also show that the learned entailment rules improve performance on a question-answering task ( \u00a77) with no tuning or prior knowledge of the task.", "labels": [], "entities": []}], "datasetContent": [{"text": "We extract binary relations from a multiple-source news corpus ( \u00a75.1) and compute local and global scores.", "labels": [], "entities": []}, {"text": "We form entailment graphs based on the similarity scores and test our model on two entailment rules data sets ( \u00a75.2).", "labels": [], "entities": []}, {"text": "We then discuss parameter tuning ( \u00a75.3) and baseline systems ( \u00a75.4).", "labels": [], "entities": [{"text": "parameter tuning", "start_pos": 16, "end_pos": 32, "type": "TASK", "confidence": 0.6934912353754044}]}, {"text": "Levy/Holt's Entailment Data Set proposed anew annotation method (and anew data set) for collecting relational inference data in context.", "labels": [], "entities": [{"text": "Entailment Data Set", "start_pos": 12, "end_pos": 31, "type": "DATASET", "confidence": 0.7346226374308268}]}, {"text": "Their method removes a major bias in other inference data sets such as Zeichner's (, where candidate entailments were selected using a directional similarity measure.", "labels": [], "entities": []}, {"text": "Levy and Dagan form questions of the type which city (q type ), is located near (q rel ), mountains (q arg )? and provide possible answers of the form Kyoto (a answer ), is surrounded by (a rel ), mountains (a arg ).", "labels": [], "entities": []}, {"text": "Annotators are shown a question with multiple possible answers, where a answer is masked by q type to reduce the bias towards world knowledge.", "labels": [], "entities": []}, {"text": "If the annotator indicates the answer as True (False), it is interpreted that the predicate in the answer entails (does not entail) the predicate in the question.", "labels": [], "entities": [{"text": "False", "start_pos": 47, "end_pos": 52, "type": "METRIC", "confidence": 0.7683253884315491}]}, {"text": "Whereas the Levy and Dagan entailment data set removes bias, a recent evaluation identified a high labeling error rate for entailments that hold only in one direction.", "labels": [], "entities": [{"text": "Dagan entailment data set", "start_pos": 21, "end_pos": 46, "type": "DATASET", "confidence": 0.9156314134597778}]}, {"text": "Holt analyzed 150 positive examples and showed that 33% of the claimed entailments are correct only in the opposite direction, and 15% do not entail in any direction.", "labels": [], "entities": []}, {"text": "Holt (2018) designed a task to crowdannotate the data set by a) adding the reverse entailment (q\u2192a) for each original positive entailment (a\u2192q) in Levy and Dagan's data set; and b) directly asking the annotators if a positive example (or its reverse) is an entailment or not (as opposed to relying on a factoid question).", "labels": [], "entities": [{"text": "Dagan's data set", "start_pos": 156, "end_pos": 172, "type": "DATASET", "confidence": 0.7789116203784943}]}, {"text": "We test our method on this re-annotated data set of 18,407 examples (3,916 positive and 14,491 negative), which we refer to as Levy/Holt.", "labels": [], "entities": []}, {"text": "We run our CCG-based binary relation extraction on the examples and perform our typing procedure ( \u00a73.2) on a answer (e.g., Kyoto) and a arg (e.g., mountains) to find the types of the arguments.", "labels": [], "entities": [{"text": "CCG-based binary relation extraction", "start_pos": 11, "end_pos": 47, "type": "TASK", "confidence": 0.6309081614017487}]}, {"text": "We split the reannotated data set into dev (30%) and test (70%) such that all the examples with the same q type and q rel are assigned to only one of the sets.", "labels": [], "entities": []}, {"text": "Berant's Entailment Data Set Berant et al.", "labels": [], "entities": [{"text": "Berant's Entailment Data Set Berant et al.", "start_pos": 0, "end_pos": 42, "type": "DATASET", "confidence": 0.916739390956031}]}, {"text": "(2011) annotated all the edges of 10 typed entail-ment graphs based on the predicates in their corpus.", "labels": [], "entities": []}, {"text": "The data set contains 3,427 edges (positive), and 35,585 non-edges (negative).", "labels": [], "entities": []}, {"text": "We evaluate our method on all the examples of Berant's entailment data set.", "labels": [], "entities": [{"text": "Berant's entailment data set", "start_pos": 46, "end_pos": 74, "type": "DATASET", "confidence": 0.8278911232948303}]}, {"text": "The types of this data set do not match with FIGER types, but we perform a simple handmapping between their types and FIGER types.", "labels": [], "entities": []}, {"text": "To further test the utility of explicit entailment rules, we evaluate the learned rules on an extrinsic task: answer selection for machine reading comprehension on NewsQA, a data set that 712 The board hailed Romney for his solid credentials.", "labels": [], "entities": [{"text": "answer selection", "start_pos": 110, "end_pos": 126, "type": "TASK", "confidence": 0.8228125274181366}, {"text": "NewsQA", "start_pos": 164, "end_pos": 170, "type": "DATASET", "confidence": 0.9794436693191528}]}, {"text": "Who praised Mitt Romney's credentials?", "labels": [], "entities": []}, {"text": "Researchers announced this week that they've found anew gene, ALS6, which is responsible for . .", "labels": [], "entities": []}, {"text": "Which gene did the ALS association discover ? One out of every 17 children under 3 years old in America has a food allergy, and some will outgrow their sensitivities.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Area under the precision-recall curve (for", "labels": [], "entities": [{"text": "precision-recall curve", "start_pos": 25, "end_pos": 47, "type": "METRIC", "confidence": 0.9625668823719025}]}, {"text": " Table 3: Examples where explicit entailment relations improve the rankings. The related words are boldfaced.", "labels": [], "entities": []}, {"text": " Table 4: Results (in percentage) for answer selection", "labels": [], "entities": [{"text": "answer selection", "start_pos": 38, "end_pos": 54, "type": "TASK", "confidence": 0.982476145029068}]}]}