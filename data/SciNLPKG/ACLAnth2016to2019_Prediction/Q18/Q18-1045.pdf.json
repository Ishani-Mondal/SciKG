{"title": [{"text": "Recurrent Neural Networks in Linguistic Theory: Revisiting Pinker and Prince (1988) and the Past Tense Debate", "labels": [], "entities": [{"text": "Recurrent Neural Networks in Linguistic Theory: Revisiting Pinker and Prince (1988)", "start_pos": 0, "end_pos": 83, "type": "TASK", "confidence": 0.7550638828958783}, {"text": "Past Tense Debate", "start_pos": 92, "end_pos": 109, "type": "TASK", "confidence": 0.5888516505559286}]}], "abstractContent": [{"text": "Can advances in NLP help advance cog-nitive modeling?", "labels": [], "entities": [{"text": "cog-nitive modeling", "start_pos": 33, "end_pos": 52, "type": "TASK", "confidence": 0.8036481440067291}]}, {"text": "We examine the role of artificial neural networks, the current state of the art in many common NLP tasks, by returning to a classic case study.", "labels": [], "entities": []}, {"text": "In 1986, Rumelhart and McClelland famously introduced a neural architecture that learned to transduce English verb stems to their past tense forms.", "labels": [], "entities": []}, {"text": "Shortly thereafter, in 1988, Pinker and Prince presented a comprehensive rebuttal of many of Rumelhart and McClelland's claims.", "labels": [], "entities": []}, {"text": "Much of the force of their attack centered on the empirical inadequacy of the Rumelhart and McClelland model.", "labels": [], "entities": []}, {"text": "Today, however, that model is severely outmoded.", "labels": [], "entities": []}, {"text": "We show that the Encoder-Decoder network architectures used in modern NLP systems obviate most of Pinker and Prince's criticisms without requiring any simplification of the past tense mapping problem.", "labels": [], "entities": [{"text": "past tense mapping", "start_pos": 173, "end_pos": 191, "type": "TASK", "confidence": 0.6080957253774008}]}, {"text": "We suggest that the empirical performance of modern networks warrants a reexamination of their utility in linguistic and cognitive modeling.", "labels": [], "entities": []}], "introductionContent": [{"text": "In their famous 1986 opus, Rumelhart and McClelland (R&M) describe a neural network capable of transducing English verb stems to their past tense.", "labels": [], "entities": [{"text": "transducing English verb stems to their past tense", "start_pos": 95, "end_pos": 145, "type": "TASK", "confidence": 0.762184876948595}]}, {"text": "The strong cognitive claims in the article fomented a veritable brouhaha in the linguistics community and eventually led to the highly influential rebuttal of.", "labels": [], "entities": []}, {"text": "P&P highlighted the extremely poor empirical performance of the R&M model, and pointed out a number of theoretical issues with the model, which they suggested would apply to any neural network, contemporarily branded connectionist approaches.", "labels": [], "entities": [{"text": "P&P", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.9282329082489014}]}, {"text": "Their critique was so successful that many linguists and cognitive scientists to this day do not consider neural networks a viable approach to modeling linguistic data and human cognition.", "labels": [], "entities": []}, {"text": "In the field of natural language processing (NLP), however, neural networks have experienced a renaissance.", "labels": [], "entities": [{"text": "natural language processing (NLP)", "start_pos": 16, "end_pos": 49, "type": "TASK", "confidence": 0.8328034480412801}]}, {"text": "With novel architectures, large new data sets available for training, and access to extensive computational resources, neural networks now constitute the state of the art in many NLP tasks.", "labels": [], "entities": []}, {"text": "However, NLP as a discipline has a distinct practical bent and more often concerns itself with the large-scale engineering applications of language technologies.", "labels": [], "entities": []}, {"text": "As such, the field's findings are not always considered relevant to the scientific study of language (i.e., the field of linguistics).", "labels": [], "entities": []}, {"text": "Recent work, however, has indicated that this perception is changing, with researchers, for example, probing the ability of neural networks to learn syntactic dependencies like subject-verb agreement (.", "labels": [], "entities": []}, {"text": "Moreover, in the domains of morphology and phonology, both NLP practitioners and linguists have considered virtually identical problems, seemingly unbeknownst to each other.", "labels": [], "entities": []}, {"text": "For example, both computational and theoretical morphologists are concerned with how different inflected forms in the lexicon are related and how one can learn to generate such inflections from data.", "labels": [], "entities": []}, {"text": "Indeed, the original R&M network focuses on such a generation task, namely, generating English past tense forms from their stems.", "labels": [], "entities": []}, {"text": "R&M's network, however, was severely limited and did not generalize correctly to held-out data.", "labels": [], "entities": [{"text": "R&M's network", "start_pos": 0, "end_pos": 13, "type": "DATASET", "confidence": 0.8953114986419678}]}, {"text": "In contrast, state-of-the art morphological generation networks used in NLP, built from the modern evolution of recurrent neural networks (RNNs) explored by and others, solve the same problem almost perfectly (.", "labels": [], "entities": []}, {"text": "This level of performance on a cognitively relevant problem suggests that it is time to consider further incorporating network modeling into the study of linguistics and cognitive science.", "labels": [], "entities": []}, {"text": "Crucially, we wish to sidestep one of the issues that framed the original debate between P&P and R&M-whether or not neural models learn and use \"rules.\"", "labels": [], "entities": []}, {"text": "From our perspective, any system that picks up systematic, predictable patterns in data maybe referred to as rule-governed.", "labels": [], "entities": []}, {"text": "We focus instead on an empirical assessment of the ability of a modern state-of-the-art neural architecture to learn linguistic patterns, asking the following questions: (i) Does the learner induce the full set of correct generalizations about the data?", "labels": [], "entities": []}, {"text": "Given a range of novel inputs, to what extent does it apply the correct transformations to them?", "labels": [], "entities": []}, {"text": "(ii) Does the behavior of the learner mimic humans?", "labels": [], "entities": []}, {"text": "In this work, we run new experiments examining the ability of the Encoder-Decoder architecture developed for machine translation () to learn the English past tense.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 109, "end_pos": 128, "type": "TASK", "confidence": 0.7070343494415283}]}, {"text": "The results suggest that modern nets absolutely meet the first criterion, and often meet the second.", "labels": [], "entities": []}, {"text": "Furthermore, they do this given limited prior knowledge of linguistic structure: The networks we consider do not have phonological features built into them and must instead learn their own representations for input phonemes.", "labels": [], "entities": []}, {"text": "The design and performance of these networks invalidate many of the criticisms in.", "labels": [], "entities": []}, {"text": "We contend that, given the gains displayed in this case study, which is characteristic of problems in the morpho-phonological domain, researchers across linguistics and cognitive science should consider evaluating modern neural architectures as part of their modeling toolbox.", "labels": [], "entities": []}, {"text": "This paper is structured as follows.", "labels": [], "entities": []}, {"text": "Section 2 describes the problem under consideration, the English past tense.", "labels": [], "entities": []}, {"text": "Section 3 lays out the original Rumelhart and McClelland model from 1986 in modern machine-learning parlance, and compares it to a state-of-the-art Encoder-Decoder architecture.", "labels": [], "entities": []}, {"text": "A historical perspective on alternative approaches to modeling, both neural and nonneural, is provided in Section 4.", "labels": [], "entities": []}, {"text": "The empirical performance of the Encoder-Decoder architecture is evaluated in Section 5.", "labels": [], "entities": []}, {"text": "Section 6 provides a summary of which of Pinker and Prince's original criticisms have effectively been resolved, and which ones still require further consideration.", "labels": [], "entities": []}], "datasetContent": [{"text": "We evaluate the performance of the ED architecture in light of the criticisms P&P levied against the original R&M model.", "labels": [], "entities": []}, {"text": "We show that, inmost cases, these criticisms no longer apply.", "labels": [], "entities": []}, {"text": "The most potent line of attack P&P use against the R&M model is that it simply does not learn the English past tense very well.", "labels": [], "entities": [{"text": "R&M", "start_pos": 51, "end_pos": 54, "type": "DATASET", "confidence": 0.6659684181213379}]}, {"text": "Although the nondeterministic, manual, and non-precise decoding procedure used by R&M makes it difficult to obtain exact accuracy numbers, P&P estimate that the model only prefers the correct past tense form for about 67% of English verb stems.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 121, "end_pos": 129, "type": "METRIC", "confidence": 0.9655978083610535}]}, {"text": "Furthermore, many of the errors made by the R&M network are unattested inhuman performance.", "labels": [], "entities": [{"text": "R&M network", "start_pos": 44, "end_pos": 55, "type": "DATASET", "confidence": 0.5717238634824753}]}, {"text": "For example, the model produces blends of regular and irregular past-tense formation (e.g., eat \u2192 ated) that children do not produce unless they mistake ate fora present stem).", "labels": [], "entities": []}, {"text": "Furthermore, the R&M model frequently produces irregular past tense forms when a regular formation is expected (e.g., ping \u2192 pang).", "labels": [], "entities": []}, {"text": "Humans are more likely to overregularize.", "labels": [], "entities": []}, {"text": "These behaviors suggest that the R&M model learns the wrong kind of generalizations.", "labels": [], "entities": [{"text": "R&M", "start_pos": 33, "end_pos": 36, "type": "TASK", "confidence": 0.807244877020518}]}, {"text": "As shown subsequently, the ED architecture seems to avoid these pitfalls, while outperforming a P&P-style non-neural baseline.", "labels": [], "entities": []}, {"text": "In the first experiment, we seek to show: (i) the ED model successfully learns to conjugate both regular and irregular verbs in the training data, and generalizes to held-out data at convergence and (ii) the pattern of errors the model exhibits is compatible with attested speech errors.", "labels": [], "entities": []}, {"text": "Our base data set consists of 4,039 verb types in the CELEX database (.", "labels": [], "entities": [{"text": "CELEX database", "start_pos": 54, "end_pos": 68, "type": "DATASET", "confidence": 0.9786299169063568}]}, {"text": "Each verb is associated with a present tense form (stem) and past tense form, both in IPA.", "labels": [], "entities": []}, {"text": "Each verb is also marked as regular or irregular.", "labels": [], "entities": []}, {"text": "A total of 168 of the 4,039 verb types were marked as irregular.", "labels": [], "entities": []}, {"text": "We assigned verbs to train, development, and test sets according to a random 80-10-10 split.", "labels": [], "entities": []}, {"text": "Each verb appears in exactly one of these sets once.", "labels": [], "entities": []}, {"text": "This corresponds to a uniform distribution over types because every verb has an effective frequency of 1.", "labels": [], "entities": []}, {"text": "In contrast, the original R&M model was trained and tested (data was not held out) on a set of 506 stem/past pairs derived from.", "labels": [], "entities": []}, {"text": "A total of 98 of the 506 verb types were marked as irregular.", "labels": [], "entities": []}, {"text": "In real human communication, words follow a Zipfian distribution, with many irregular verbs being exponentially more common than regular verbs.", "labels": [], "entities": []}, {"text": "Although this condition is more true to the external environment of language learning, it may not accurately represent the psychological reality of how that environment is processed.", "labels": [], "entities": []}, {"text": "A body of psycholinguistic evidence suggests that human learners generalize phonological patterns based on the count of word types they appear in, ignoring the token frequency of those types.", "labels": [], "entities": []}, {"text": "Thus, we chose to weigh all verb types equally for training, effecting a uniform distribution over types as described above.", "labels": [], "entities": []}, {"text": "Our architecture is nearly identical to that used in, with hyperparameters set following.", "labels": [], "entities": []}, {"text": "Each input character has an embedding size of 300 units.", "labels": [], "entities": []}, {"text": "The encoder consists of a bidirectional LSTM) with two layers.", "labels": [], "entities": []}, {"text": "There is a dropout value of 0.3 between the layers.", "labels": [], "entities": []}, {"text": "The decoder is a unidirectional LSTM with two layers.", "labels": [], "entities": []}, {"text": "Both the encoder and decoder have 100 hidden units.", "labels": [], "entities": []}, {"text": "Training was done using the Adadelta procedure) with a learning rate of 1.0 and a minibatch size of 20.", "labels": [], "entities": [{"text": "learning rate", "start_pos": 55, "end_pos": 68, "type": "METRIC", "confidence": 0.9746150076389313}]}, {"text": "We train for 100 epochs to ensure that all verb forms in the training data are adequately learned.", "labels": [], "entities": []}, {"text": "We decode the model with beam search (k = 12).", "labels": [], "entities": []}, {"text": "The code for our experiments is derived from the OpenNMT package ().", "labels": [], "entities": [{"text": "OpenNMT package", "start_pos": 49, "end_pos": 64, "type": "DATASET", "confidence": 0.9502487182617188}]}, {"text": "We use accuracy as our metric of performance.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 7, "end_pos": 15, "type": "METRIC", "confidence": 0.9993003606796265}]}, {"text": "We train the MGL as a non-neural baseline, using the code distributed with Albright and Hayes (2003) with default settings.", "labels": [], "entities": []}, {"text": "The non-neural MGL baseline unsurprisingly learns the regular pasttense pattern nearly perfectly, given that it is imbued with knowledge of phonological features as well as a list of phonologically illegal phoneme sequences to avoid in its output.", "labels": [], "entities": []}, {"text": "However, in our testing of the MGL, the preferred past-tense output for all verbs was never an irregular formulation.", "labels": [], "entities": [{"text": "MGL", "start_pos": 31, "end_pos": 34, "type": "DATASET", "confidence": 0.6339729428291321}]}, {"text": "This was true even for irregular verbs that were observed by the learner in the training set.", "labels": [], "entities": []}, {"text": "One might say that the MGL is only intended to account for the regular route of a dual route system.", "labels": [], "entities": [{"text": "MGL", "start_pos": 23, "end_pos": 26, "type": "DATASET", "confidence": 0.6823267936706543}]}, {"text": "However, the intended scope of the MGL seems to be wider.", "labels": [], "entities": [{"text": "MGL", "start_pos": 35, "end_pos": 38, "type": "DATASET", "confidence": 0.5150789022445679}]}, {"text": "The model is billed as accurately learning \"islands of subregularity\" within the past tense system, and Albright and Hayes use the model to make predictions about which irregular forms of novel verb stems are preferable to human speakers (see the subsequent discussion of wugs).: Results on held-out data in English past tense prediction for single-and multi-task scenarios.", "labels": [], "entities": [{"text": "English past tense prediction", "start_pos": 308, "end_pos": 337, "type": "TASK", "confidence": 0.6084664165973663}]}, {"text": "The MGL achieves perfect accuracy on regular verbs, and 0 accuracy on irregular verbs.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 25, "end_pos": 33, "type": "METRIC", "confidence": 0.9973747730255127}, {"text": "accuracy", "start_pos": 58, "end_pos": 66, "type": "METRIC", "confidence": 0.9674357175827026}]}, {"text": "\u2020 indicates that a neural model's performance was found to be significantly different (p < 0.05) from the MGL.", "labels": [], "entities": []}, {"text": "In contrast, the ED model, despite no builtin knowledge of phonology, successfully learns to conjugate nearly all the verbs in the training data, including irregulars-no reduction in scope is needed.", "labels": [], "entities": []}, {"text": "This capacity to account for specific exceptions to the regular rule does not result in overfitting.", "labels": [], "entities": []}, {"text": "We note similarly high accuracy on held-out regular data-98.9% to 99.2% at convergence depending on the condition.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 23, "end_pos": 31, "type": "METRIC", "confidence": 0.9995889067649841}, {"text": "convergence", "start_pos": 75, "end_pos": 86, "type": "METRIC", "confidence": 0.9480950236320496}]}, {"text": "We report the full accuracy in all conditions in.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 19, "end_pos": 27, "type": "METRIC", "confidence": 0.9996408224105835}]}, {"text": "The \u2020 indicates when a neural model's performance was found to be significantly different (p < 0.05) from the MGL according to a \u03c7 2 test.", "labels": [], "entities": [{"text": "\u2020", "start_pos": 4, "end_pos": 5, "type": "METRIC", "confidence": 0.9622639417648315}]}, {"text": "The ED model achieves near-perfect accuracy on regular verbs, and irregular verbs seen during training, as well as substantial accuracy on irregular verbs in the dev and test sets.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 35, "end_pos": 43, "type": "METRIC", "confidence": 0.9985731840133667}, {"text": "accuracy", "start_pos": 127, "end_pos": 135, "type": "METRIC", "confidence": 0.9985647797584534}]}, {"text": "This behavior jointly results in better overall performance for the ED model when all verbs are considered.", "labels": [], "entities": []}, {"text": "shows learning curves for regular and irregular verbs types in different conditions.", "labels": [], "entities": []}, {"text": "An error analysis of held-out data shows that the errors made by this network do not show any of the problems of the R&M architecture.", "labels": [], "entities": [{"text": "R&M", "start_pos": 117, "end_pos": 120, "type": "TASK", "confidence": 0.5704314708709717}]}, {"text": "There are no blend errors of the eat \u2192 ated variety.", "labels": [], "entities": []}, {"text": "Indeed, the only error the network makes on irregulars is overregularization (e.g., throw \u2192 throwed).", "labels": [], "entities": []}, {"text": "In fact, the overregularization-caused lower accuracy that we observe for irregular verbs in development and testis expected and desirable; it matches the human tendency to treat novel words as regular, lacking knowledge of irregularity.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 45, "end_pos": 53, "type": "METRIC", "confidence": 0.9991663694381714}]}, {"text": "Although most held-out irregulars are regularized, as expected, the ED model does, perhaps surprisingly, correctly conjugate a handful of irregular forms it has not seen during training-five in the test set.", "labels": [], "entities": []}, {"text": "However, three of these are prefixed versions of irregulars that exist in the training set (retell \u2192 retold, partake \u2192 partook, withdraw \u2192 withdrew).", "labels": [], "entities": []}, {"text": "One (sling \u2192 slung) is an analogy to similar training words (fling, cling).", "labels": [], "entities": []}, {"text": "The final conjugation, forsake \u2192 forsook, is an interesting combination, with the prefix \"for,\" but an unattested base form \"sake\" that is similar to \"take.\"", "labels": [], "entities": []}, {"text": "From the training data, the only regular verb with an error is compartmentalized, whose past tense is predicted to be \"compartmentalized,\" with a spurious vowel change that would likely be ironed outwith additional training.", "labels": [], "entities": []}, {"text": "Among the regular verbs in the development and test sets, the errors also consisted of single vowel changes (the full set of these errors was \"thin\" \u2192 \"thun,\" \"try\" \u2192 \"traud,\" \"institutionalize\" \u2192 \"instititionalized,\" and \"drawl\" \u2192 \"drooled\").", "labels": [], "entities": []}, {"text": "Overall then, the ED model performs extremely well, afar cry from the \u224867% accuracy of the R&M model.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 75, "end_pos": 83, "type": "METRIC", "confidence": 0.9993334412574768}, {"text": "R&M model", "start_pos": 91, "end_pos": 100, "type": "DATASET", "confidence": 0.7651377320289612}]}, {"text": "It exceeds any reasonable standard of empirical adequacy, and shows human-like error behavior.", "labels": [], "entities": []}, {"text": "R&M made several claims that their architecture modeled the detailed acquisition of the English past tense by children.", "labels": [], "entities": [{"text": "R&M", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.8932462334632874}]}, {"text": "The core claim was that their model exhibited a macro U-shaped learning curve as in \u00a72.", "labels": [], "entities": []}, {"text": "Irregulars were initially produced correctly, followed by a period of overregularization preceding a final correct stage.", "labels": [], "entities": []}, {"text": "However, P&P point out that R&M only achieve this pattern by manipulating the input distribution fed into their network.", "labels": [], "entities": []}, {"text": "They trained only on irregulars fora number of epochs,: Here we evince the oscillating development of single words in our corpus.", "labels": [], "entities": []}, {"text": "For each stem, e.g., CLING, we show the past form that produced at change points to show the diversity of alternation.", "labels": [], "entities": []}, {"text": "Beyond the last epoch displayed, each verb was produced correctly.", "labels": [], "entities": []}, {"text": "before flooding the network with regular verb forms.", "labels": [], "entities": []}, {"text": "R&M justify this by claiming that young children's vocabulary consists disproportionately of irregular verbs early on, but P&P cite contrary evidence.", "labels": [], "entities": [{"text": "R&M", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.952374001344045}, {"text": "P&P", "start_pos": 123, "end_pos": 126, "type": "DATASET", "confidence": 0.9219896594683329}]}, {"text": "A survey of child-directed speech shows that the ratio of regular to irregular verbs a child hears is constant while they are learning their language.", "labels": [], "entities": []}, {"text": "Furthermore, psycholinguistic results suggest that there is no early skew towards irregular verbs in the vocabulary children understand or use.", "labels": [], "entities": []}, {"text": "Although we do not wish to make a strong claim that the ED architecture accurately mirrors children's acquisition, only that it ultimately learns the correct generalizations, we wanted to see if it would display a child-like learning pattern without changing the training inputs fed into the network over time-that is, in all of our experiments, the data sets remained fixed for all epochs, unlike in R&M.", "labels": [], "entities": []}, {"text": "We do not clearly see a macro U-shape, but we do observe Plukett and Marchman's predicted oscillations for irregular learning-the so-called micro U-shaped pattern.", "labels": [], "entities": []}, {"text": "As shown in, individual verbs oscillate between correct production and overregularization before they are fully mastered.", "labels": [], "entities": []}, {"text": "As a further test of the MGL as a cognitive model, Albright and Hayes created a set of 74 nonce English verb stems with varying levels of similarity to both regular and irregular verbs.", "labels": [], "entities": [{"text": "MGL", "start_pos": 25, "end_pos": 28, "type": "TASK", "confidence": 0.8284305334091187}]}, {"text": "For each stem (e.g., rife), they picked one regular output form (rifed), and one irregular output form (rofe).", "labels": [], "entities": []}, {"text": "They used these stems and potential past-tense variants to perform a wug test with human participants.", "labels": [], "entities": []}, {"text": "For each stem, they had 24 participants freely attempt to produce a past  Another objection levied by P&P is R&M's focus on learning a single morphological transduction: stem to past tense.", "labels": [], "entities": []}, {"text": "Many phonological patterns in a language, however, are not restricted to a single transduction-they makeup a core part of the phonological system and take part in many different processes.", "labels": [], "entities": []}, {"text": "For instance, the voicing assimilation patterns found in the past tense also apply to the third person singular: we seethe affix -s rendered as [-s] after voiceless consonants and [-z] after voiced consonants and vowels.", "labels": [], "entities": []}, {"text": "P&P argue that the R&M model would not be able to take advantage of these shared generalizations.", "labels": [], "entities": []}, {"text": "Assuming a different network would need to be trained for each transduction (e.g., stem to gerund and stem to past participle), it would be impossible to learn that they have any patterns in common.", "labels": [], "entities": []}, {"text": "However, as discussed in \u00a73.2, a single ED model can learn multiple types of mapping, simply by tagging each input-output pair in the training set with the transduction it represents.", "labels": [], "entities": []}, {"text": "A network trained in such away shares the same weights and phoneme embeddings across tasks, and thus has the capacity to generalize patterns across all transductions, naturally capturing the overall phonology of the language.", "labels": [], "entities": []}, {"text": "Because different transductions mutually constrain each other (e.g., English in general does not allow sequences of identical vowels), we actually expect faster learning of each individual pattern, which we test in the following experiment.", "labels": [], "entities": []}, {"text": "We trained a model with an architecture identical to that used in Experiment 1, but this time to jointly predict four mappings associated with English verbs (past, gerund, past participle, thirdperson singular).", "labels": [], "entities": []}, {"text": "For each of the verb types in our base training set from Experiment 1, we added the three remaining mappings.", "labels": [], "entities": []}, {"text": "The gerund, past-participle, and third-person singular forms were identified in CELEX according to their labels in Wiktionary.", "labels": [], "entities": [{"text": "CELEX", "start_pos": 80, "end_pos": 85, "type": "DATASET", "confidence": 0.9448907971382141}]}, {"text": "The network was trained on all individual stem \u2192 inflection pairs in the new training set, with each input string modified with additional characters representing the current transduction: take <PST> \u2192 took, but take <PTCP> \u2192 taken.", "labels": [], "entities": []}, {"text": "7 Results. and show the results.", "labels": [], "entities": []}, {"text": "Overall, accuracy is >99% after convergence on train.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 9, "end_pos": 17, "type": "METRIC", "confidence": 0.999792754650116}]}, {"text": "Although the difference in final performance is never statistically significant compared to singletask learning, the learning curves are much steeper, so this level of performance is achieved much more quickly.", "labels": [], "entities": []}, {"text": "This provides evidence for our intuition that cross-task generalization facilitates individual task learning due to shared phonological patterning (i.e., jointly generating the gerund hastens pasttense learning).", "labels": [], "entities": [{"text": "cross-task generalization", "start_pos": 46, "end_pos": 71, "type": "TASK", "confidence": 0.7681892514228821}]}], "tableCaptions": [{"text": " Table 3: Results on held-out data in English past tense  prediction for single-and multi-task scenarios. The  MGL achieves perfect accuracy on regular verbs, and  0 accuracy on irregular verbs.  \u2020 indicates that a neu- ral model's performance was found to be significantly  different (p < 0.05) from the MGL.", "labels": [], "entities": [{"text": "English past tense  prediction", "start_pos": 38, "end_pos": 68, "type": "TASK", "confidence": 0.6240712553262711}, {"text": "accuracy", "start_pos": 132, "end_pos": 140, "type": "METRIC", "confidence": 0.9984373450279236}, {"text": "accuracy", "start_pos": 166, "end_pos": 174, "type": "METRIC", "confidence": 0.9780415892601013}]}]}