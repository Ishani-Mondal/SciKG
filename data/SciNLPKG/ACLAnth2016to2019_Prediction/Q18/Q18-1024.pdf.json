{"title": [{"text": "Native Language Cognate Effects on Second Language Lexical Choice", "labels": [], "entities": [{"text": "Second Language Lexical Choice", "start_pos": 35, "end_pos": 65, "type": "TASK", "confidence": 0.6894886791706085}]}], "abstractContent": [{"text": "We present a computational analysis of cog-nate effects on the spontaneous linguistic productions of advanced non-native speakers.", "labels": [], "entities": []}, {"text": "Introducing a large corpus of highly competent non-native English speakers, and using a set of carefully selected lexical items, we show that the lexical choices of non-natives are affected by cognates in their native language.", "labels": [], "entities": []}, {"text": "This effect is so powerful that we are able to reconstruct the phylogenetic language tree of the Indo-European language family solely from the frequencies of specific lexical items in the English of authors with various native languages.", "labels": [], "entities": []}, {"text": "We quantitatively analyze non-native lexical choice, highlighting cognate facilitation as one of the important phenomena shaping the language of non-native speakers.", "labels": [], "entities": []}], "introductionContent": [{"text": "Acquisition of vocabulary and semantic knowledge of a second language, including appropriate word choice and awareness of subtle word meaning contours, are recognized as a notoriously hard task, even for advanced non-native speakers.", "labels": [], "entities": []}, {"text": "When nonnative authors produce utterances in a foreign language (L2), these utterances are marked by traces of their native language (L1).", "labels": [], "entities": []}, {"text": "Such traces are known as transfer effects, and they can be phonological (a foreign accent), morphological, lexical, or syntactic.", "labels": [], "entities": []}, {"text": "Specifically, psycholinguistic research has shown that the choice of lexical items is influenced by the author's L1, and that non-native speakers tend to choose words that happen to have cognates in their native language.", "labels": [], "entities": []}, {"text": "Cognates are words in two languages that share both a similar meaning and a similar phonetic (and, sometimes, also orthographic) form, due to a common ancestor in some protolanguage.", "labels": [], "entities": []}, {"text": "The definition is sometimes also extended to words that have similar forms and meanings due to borrowing.", "labels": [], "entities": []}, {"text": "Most studies on cognate facilitation have been conducted with few human subjects, focusing on few words, and the experimental setup was such that participants were asked to produce lexical choices in an artificial setting.", "labels": [], "entities": []}, {"text": "We demonstrate that cognates affect lexical choice in L2 spontaneous production on a much larger scale.", "labels": [], "entities": []}, {"text": "Using anew and unique large corpus of nonnative English that we introduce as part of this work, we identify a focus set of over 1000 words, and show that they are distributed very differently across the \"Englishes\" of authors with various L1s.", "labels": [], "entities": []}, {"text": "Importantly, we go to great lengths to guarantee that these words do not reflect specific properties of the various native languages, the cultures associated with them, or the topics that maybe relevant for particular geographic regions.", "labels": [], "entities": []}, {"text": "Rather, these are \"ordinary\" words, with very little culture-specific weight, that happen to have synonyms in English that may reflect cognates in some L1s, but not all of them.", "labels": [], "entities": []}, {"text": "Consequently, they are used differently by authors with different linguistic backgrounds, to the extent that the authors' L1s can be identified through their use of the words in the focus set.", "labels": [], "entities": []}, {"text": "The signal of L1 is so powerful, that we are able to reconstruct a linguistic typology tree from the distribution of these words in the Englishes witnessed in the corpus.", "labels": [], "entities": []}, {"text": "We propose a methodology for creating a focus set of highly frequent, unbiased words that we expect to be distributed differently across different Englishes simply because they happen to have synonyms with different etymologies, even though they carry very limited cultural weight.", "labels": [], "entities": []}, {"text": "Then, we show that simple lexical semantic features (based on the focus set of words) suffice for clustering together English texts authored by speakers of \"closer\" languages; we generate a phylogenetic tree of 31 languages solely by looking at lexical semantic properties of the English spoken by non-native speakers from 31 countries.", "labels": [], "entities": []}, {"text": "The contribution of this work is twofold.", "labels": [], "entities": []}, {"text": "First, we introduce the L2-Reddit corpus: a large corpus of highly-advanced, fluent, diverse, non-native English, with sentence-level annotations of the native language of each author.", "labels": [], "entities": []}, {"text": "Second, we layout sound empirical foundations for the theoretical hypothesis on the cognate effect in L2 of non-native English speakers, highlighting the cognate facilitation phenomenon as one of the important factors shaping the language of non-native speakers.", "labels": [], "entities": []}, {"text": "After discussing related work in Section 2, we describe the L2-Reddit corpus in Section 3.", "labels": [], "entities": [{"text": "L2-Reddit corpus", "start_pos": 60, "end_pos": 76, "type": "DATASET", "confidence": 0.6985939890146255}]}, {"text": "Section 4 details the methodology we use and our results.", "labels": [], "entities": []}, {"text": "We analyze these results in Section 5, and conclude with suggestions for future research.", "labels": [], "entities": []}], "datasetContent": [{"text": "Unlike most corpora of non-native speakers, which focus on learners (e.g., ICLE, EF-CAMDAT (, or the TOEFL dataset ( ), our corpus is unique in that it is composed by fluent, advanced non-native speakers of English.", "labels": [], "entities": [{"text": "ICLE", "start_pos": 75, "end_pos": 79, "type": "METRIC", "confidence": 0.6901581287384033}, {"text": "TOEFL dataset", "start_pos": 101, "end_pos": 114, "type": "DATASET", "confidence": 0.867875337600708}]}, {"text": "We verified that, on average, Reddit users possess excellent, near-native command of English by comparing three distinct populations: (i) Reddit native English authors, defined as those tagged for one of the English-speaking countries: Australia, Canada, Ireland, New Zealand, and the UK.", "labels": [], "entities": []}, {"text": "We excluded texts produced by US authors due to the high ratio of the US immigrant population; (ii) Reddit non-native English authors; and (iii) A population of English learners, using the TOEFL dataset ( ; here, the proficiency of authors is classified as low, intermediate, or high.", "labels": [], "entities": [{"text": "TOEFL dataset", "start_pos": 189, "end_pos": 202, "type": "DATASET", "confidence": 0.9493178427219391}]}, {"text": "We compared these populations across various indices, assessing their proficiency with several commonly accepted lexical and syntactic complexity measures (.", "labels": [], "entities": []}, {"text": "Lexical richness was evaluated through typeto-token ratio (TTR), average age-of-acquisition (in years) of lexical items (, and mean word rank, where the rank was retrieved from a list of the entire Reddit dataset vocabulary, sorted byword frequency in the corpus.", "labels": [], "entities": [{"text": "typeto-token ratio (TTR)", "start_pos": 39, "end_pos": 63, "type": "METRIC", "confidence": 0.8467268109321594}, {"text": "mean word rank", "start_pos": 127, "end_pos": 141, "type": "METRIC", "confidence": 0.7808045148849487}, {"text": "Reddit dataset vocabulary", "start_pos": 198, "end_pos": 223, "type": "DATASET", "confidence": 0.8568147619565328}]}, {"text": "Syntactic com-plexity was assessed using mean length of T-units (TU; the minimal terminable unit of language that can be considered a grammatical sentence), and the ratio of complex T-units (those containing a dependent clause) to all T-units in a sentence.", "labels": [], "entities": [{"text": "mean length of T-units", "start_pos": 41, "end_pos": 63, "type": "METRIC", "confidence": 0.852540448307991}]}, {"text": "Across almost all indices, the level of Reddit non-natives is much higher than even the advanced TOEFL learners, and almost on par with Reddit natives.", "labels": [], "entities": []}, {"text": "To better assess the quality of the reconstructed trees we now provide a quantitative evaluation of the language typologies obtained by the various experiments.", "labels": [], "entities": []}, {"text": "We adopt the evaluation approach of, who introduced a distance metric between two trees, defined as the sum of the square differences between all leaf-pair distances in the two trees.", "labels": [], "entities": []}, {"text": "More specifically, given a tree of N leaves, l i , i \u2208 [1..N ], the distance between two leaves l i , l j in a tree \u03c4 , denoted D \u03c4 (l i , l j ), is defined as the length of the shortest path between l i and l j . The distance Dist(\u03c4, g) between a generated tree \u03c4 and the gold tree g is then calculated by summing the square differences between all leaf-pair distances in the two trees: We used the Indo-European tree in Glottolog 13 as our gold standard, pruning it to contain the set of 31 languages considered in this work.", "labels": [], "entities": [{"text": "Dist", "start_pos": 227, "end_pos": 231, "type": "METRIC", "confidence": 0.9474512338638306}]}, {"text": "For the sake of comparison, we also present the distance obtained fora completely random tree, generated by sampling a random distance matrix from the uniform (0, 1) distribution.", "labels": [], "entities": []}, {"text": "The reported random tree evaluation score is averaged over 100 experiments.", "labels": [], "entities": []}, {"text": "All distances are normalized to a zero-one scale, where the bounds, zero and one, represent the identical and the most distant tree with respect to the gold standard, respectively.", "labels": [], "entities": []}, {"text": "Much expectedly, the random tree is the worst one, followed closely by the tree reconstructed from a random sample of over 1000 words sampled from the corpus.", "labels": [], "entities": []}, {"text": "The best result is obtained by considering both word frequencies and representations, being only slightly superior to the tree reconstructed using word frequencies alone.", "labels": [], "entities": []}, {"text": "The latter result corroborates the aforementioned observation (Section 4.3.2) and further posits word frequencies as the major factor affecting the shape of the obtained phylogeny.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Evaluation of the English proficiency of non-native Reddit users.", "labels": [], "entities": []}, {"text": " Table 3: Normalized distance between a reconstructed  and the gold tree; lower distances indicate better result.", "labels": [], "entities": []}]}