{"title": [{"text": "Data Statements for Natural Language Processing: Toward Mitigating System Bias and Enabling Better Science", "labels": [], "entities": [{"text": "Natural Language Processing", "start_pos": 20, "end_pos": 47, "type": "TASK", "confidence": 0.6848088701566061}, {"text": "Mitigating System Bias", "start_pos": 56, "end_pos": 78, "type": "TASK", "confidence": 0.9311412572860718}]}], "abstractContent": [{"text": "In this paper, we propose data statements as a design solution and professional practice for natural language processing technologists , in both research and development.", "labels": [], "entities": []}, {"text": "Through the adoption and widespread use of data statements, the field can begin to address critical scientific and ethical issues that result from the use of data from certain populations in the development of technology for other populations.", "labels": [], "entities": []}, {"text": "We present a form that data statements can take and explore the implications of adopting them as part of regular practice.", "labels": [], "entities": []}, {"text": "We argue that data statements will help alleviate issues related to exclusion and bias in language technology, lead to better precision in claims about how natural language processing research can generalize and thus better engineering results , protect companies from public embarrassment , and ultimately lead to language technology that meets its users in their own preferred linguistic style and furthermore does not misrepresent them to others.", "labels": [], "entities": [{"text": "precision", "start_pos": 126, "end_pos": 135, "type": "METRIC", "confidence": 0.9964879751205444}]}], "introductionContent": [{"text": "As technology enters widespread societal use it is important that we, as technologists, think critically about how the design decisions we make and systems we build impact people-including not only users of the systems but also other people who will be affected by the systems without directly interacting with them.", "labels": [], "entities": []}, {"text": "For this paper, we focus on natural language processing (NLP) technology.", "labels": [], "entities": [{"text": "natural language processing (NLP)", "start_pos": 28, "end_pos": 61, "type": "TASK", "confidence": 0.7745531896750132}]}, {"text": "Potential adverse impacts include NLP systems that fail to work for specific subpopulations (e.g., children or speakers of language varieties that are not supported by training or test data) or systems that reify and reinforce biases present in training data (e.g., a resume-review system that ranks female candidates as less qualified for computer programming jobs because of biases present in training text).", "labels": [], "entities": []}, {"text": "There are both scientific and ethical reasons to be concerned.", "labels": [], "entities": []}, {"text": "Scientifically, there is the issue of generalizability of results; ethically, the potential for significant real-world harms.", "labels": [], "entities": []}, {"text": "Although there is increasing interest in ethics in NLP, there remains the open and urgent question of how we integrate ethical considerations into the everyday practice of our field.", "labels": [], "entities": []}, {"text": "This question has no simple answer, but rather will require a constellation of multi-faceted solutions.", "labels": [], "entities": []}, {"text": "Toward that end, and drawing on value sensitive design), this paper contributes one new professional practice-called data statements-which we argue will bring about improvements in engineering and scientific outcomes while also enabling more ethically responsive NLP technology.", "labels": [], "entities": []}, {"text": "A data statement is a characterization of a dataset that provides context to allow developers and users to better understand how experimental results might generalize, how software might be appropriately deployed, and what biases might be reflected in systems built on the software.", "labels": [], "entities": []}, {"text": "In developing this practice, we draw on analogous practices from the fields of psychology and medicine that require some standardized information about the populations studied (e.g.,.", "labels": [], "entities": []}, {"text": "Though the construct of data statements applies more broadly, in this paper we focus specifically on data statements for NLP systems.", "labels": [], "entities": []}, {"text": "Data statements should be included inmost writing on NLP including: papers presenting new datasets, papers reporting experimental work with datasets, and documentation for NLP systems.", "labels": [], "entities": []}, {"text": "Data statements should help us as afield engage with the ethical issues of exclusion, overgeneralization, and underexposure.", "labels": [], "entities": []}, {"text": "Furthermore, as data statements bring our datasets and their represented populations into better focus, they should also help us as afield deal with scientific issues of generalizability and reproducibility.", "labels": [], "entities": []}, {"text": "Adopting this practice will position us to better understand and describe our results and, ultimately, do better and more ethical science and engineering.", "labels": [], "entities": []}, {"text": "We begin by defining terms ( \u00a72), discuss why NLP needs data statements ( \u00a73), and relate our proposal to current practice ( \u00a74).", "labels": [], "entities": []}, {"text": "Next is the substance of our contribution: a detailed proposal for data statements for NLP ( \u00a75), illustrated with two case studies ( \u00a76).", "labels": [], "entities": []}, {"text": "In \u00a77 we discuss how data statements can mitigate bias and use the technique of \"value scenarios\" to envision potential effects of their adoption.", "labels": [], "entities": []}, {"text": "Finally, we relate data statements to similar emerging proposals ( \u00a78), make recommendations for how to implement and promote the uptake of data statements ( \u00a79), and layout considerations for tech policy ( \u00a710).", "labels": [], "entities": []}], "datasetContent": [{"text": "An NLP dataset is a collection of speech or writing possibly combined with annotations.", "labels": [], "entities": [{"text": "NLP dataset", "start_pos": 3, "end_pos": 14, "type": "DATASET", "confidence": 0.7187233865261078}]}, {"text": "Annotations include indications of linguistic structure like part of speech tags or syntactic parse trees, as well as labels classifying aspects of what the speakers were attempting to accomplish with their utterances.", "labels": [], "entities": []}, {"text": "The latter includes annotations for sentiment (Liu, 2012) and for figurative language or sarcasm (e.g.,).", "labels": [], "entities": []}, {"text": "Labels can be naturally occurring, such as star ratings in reviews taken as indications of the overall sentiment of By arguing here that data statements promote both ethical practice and sound science, we do not mean to suggest that these two can be conflated.", "labels": [], "entities": []}, {"text": "A system can give accurate responses as measured by some test set (scientific soundness) and yet lead to real-world harms (ethical issues).", "labels": [], "entities": []}, {"text": "Accordingly, it is up to researchers and research communities to engage with both scientific and ethical ideals.", "labels": [], "entities": []}, {"text": "Multi-modal datasets combine language and video or other additional signals.", "labels": [], "entities": []}, {"text": "Here, our focus is on linguistic data.", "labels": [], "entities": []}, {"text": "the review (e.g.,) or the hashtag #sarcasm used to identify sarcastic language (e.g.,.", "labels": [], "entities": []}, {"text": "Speaker We use the term speaker to refer to the individual who produced some segment of linguistic behavior included in the dataset, even if the linguistic behavior is originally written.", "labels": [], "entities": []}, {"text": "Annotator The term annotator refers to people who assign annotations to the raw data, including transcribers of spoken data.", "labels": [], "entities": []}, {"text": "Annotators maybe crowdworkers or highly trained researchers, sometimes involved in the creation of the annotation guidelines.", "labels": [], "entities": []}, {"text": "Annotation is often done semiautomatically, with NLP tools being used to create a first pass that is corrected or augmented by human annotators.", "labels": [], "entities": []}, {"text": "Curator A third role in dataset creation, less commonly discussed, is the curator.", "labels": [], "entities": [{"text": "dataset creation", "start_pos": 24, "end_pos": 40, "type": "TASK", "confidence": 0.7480224967002869}]}, {"text": "Curators are involved in the selection of which data to include, by selecting individual documents, by creating search terms that generate sets of documents, by selecting speakers to interview and designing interview questions, and so forth.", "labels": [], "entities": []}, {"text": "Stakeholders Stakeholders are people impacted directly or indirectly by a system.", "labels": [], "entities": []}, {"text": "Direct stakeholders include those who interact with the system, either by participating in system creation (developers, speakers, annotators and curators) or by using it.", "labels": [], "entities": []}, {"text": "Indirect stakeholders do not use the system but are nonetheless impacted by it.", "labels": [], "entities": []}, {"text": "For example, people whose Web content is displayed or rendered invisible by search engine algorithms are indirect stakeholders with respect to those systems.", "labels": [], "entities": []}, {"text": "Algorithm We use the term algorithm to encompass both rule-based and machine learning approaches to NLP.", "labels": [], "entities": []}, {"text": "Some algorithms (typically rule-based ones) are tightly connected to the datasets they are developed against.", "labels": [], "entities": []}, {"text": "Other algorithms can be easily ported to different datasets.", "labels": [], "entities": []}, {"text": "System We use the term NLP system to refer to apiece of software that does some kind of natural language processing, typically involving algorithms trained on particular datasets.", "labels": [], "entities": []}, {"text": "We use this term to refer to both components focused on specific tasks (e.g., the Stanford parser] trained on the Penn Treebank to do English parsing) and user-facing products such as Amazon's Alexa or Google Home.", "labels": [], "entities": [{"text": "Penn Treebank", "start_pos": 114, "end_pos": 127, "type": "DATASET", "confidence": 0.9830605387687683}, {"text": "English parsing", "start_pos": 134, "end_pos": 149, "type": "TASK", "confidence": 0.44019514322280884}]}, {"text": "Bias We use the term bias to refer to cases where computer systems \"systematically and unfairly discriminate against certain individuals or groups of individuals in favor of others\".", "labels": [], "entities": []}, {"text": "To be clear: (i) unfair discrimination does not give rise to bias unless it occurs systematically and (ii) systematic discrimination does not give rise to bias unless it results in an unfair outcome.", "labels": [], "entities": []}, {"text": "show that in some cases, system bias reflects biases in society; these are pre-existing biases with roots in social institutions, practices and attitudes.", "labels": [], "entities": []}, {"text": "In other cases, reasonable, seemingly neutral, technical elements (e.g., the order in which an algorithm processes data) can result in bias when used in real world contexts; these technical biases stem from technical constraints and decisions.", "labels": [], "entities": []}, {"text": "A third source of bias, emergent bias, occurs when a system designed for one context is applied in another (e.g., with a different population).", "labels": [], "entities": []}], "tableCaptions": []}