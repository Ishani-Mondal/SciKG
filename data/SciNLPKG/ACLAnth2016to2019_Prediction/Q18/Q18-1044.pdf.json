{"title": [{"text": "Integrating Weakly Supervised Word Sense Disambiguation into Neural Machine Translation", "labels": [], "entities": [{"text": "Integrating Weakly Supervised Word Sense Disambiguation", "start_pos": 0, "end_pos": 55, "type": "TASK", "confidence": 0.8451576232910156}, {"text": "Neural Machine Translation", "start_pos": 61, "end_pos": 87, "type": "TASK", "confidence": 0.6876667141914368}]}], "abstractContent": [{"text": "This paper demonstrates that word sense disambiguation (WSD) can improve neural machine translation (NMT) by widening the source context considered when modeling the senses of potentially ambiguous words.", "labels": [], "entities": [{"text": "word sense disambiguation (WSD", "start_pos": 29, "end_pos": 59, "type": "TASK", "confidence": 0.7715230643749237}, {"text": "neural machine translation (NMT)", "start_pos": 73, "end_pos": 105, "type": "TASK", "confidence": 0.7677471538384756}]}, {"text": "We first introduce three adaptive clustering algorithms for WSD, based on k-means, Chinese restaurant processes, and random walks, which are then applied to large word contexts represented in a low-rank space and evaluated on SemEval shared-task data.", "labels": [], "entities": [{"text": "WSD", "start_pos": 60, "end_pos": 63, "type": "TASK", "confidence": 0.9415897727012634}]}, {"text": "We then learn word vectors jointly with sense vectors defined by our best WSD method, within a state-of-the-art NMT system.", "labels": [], "entities": []}, {"text": "We show that the concatenation of these vectors, and the use of a sense selection mechanism based on the weighted average of sense vectors, outperforms several baselines including sense-aware ones.", "labels": [], "entities": []}, {"text": "This is demonstrated by translation on five language pairs.", "labels": [], "entities": []}, {"text": "The improvements are more than 1 BLEU point over strong NMT base-lines, +4% accuracy overall ambiguous nouns and verbs, or +20% when scored manually over several challenging words.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 33, "end_pos": 37, "type": "METRIC", "confidence": 0.9993365406990051}, {"text": "accuracy", "start_pos": 76, "end_pos": 84, "type": "METRIC", "confidence": 0.9993724226951599}]}], "introductionContent": [{"text": "The correct translation of polysemous words remains a challenge for machine translation.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 68, "end_pos": 87, "type": "TASK", "confidence": 0.7601545453071594}]}, {"text": "Although some translation options maybe interchangeable, substantially different senses of * Work conducted while at the Idiap Research Institute.", "labels": [], "entities": [{"text": "Idiap Research Institute", "start_pos": 121, "end_pos": 145, "type": "DATASET", "confidence": 0.9348469773928324}]}, {"text": "source words must generally be rendered by different words in the target language.", "labels": [], "entities": []}, {"text": "Hence, an MT system should identify-implicitly or explicitlythe correct sense conveyed by each occurrence in order to generate an appropriate translation.", "labels": [], "entities": [{"text": "MT", "start_pos": 10, "end_pos": 12, "type": "TASK", "confidence": 0.9904899597167969}]}, {"text": "For instance, in the following sentence from Europarl, the translation of \"deal\" should convey the sense \"to handle\" (in French traiter) and not \"to cope\" (in French rem\u00e9dier, which is wrong): Source: How can we guarantee the system of prior notification for high-risk products at ports that have the necessary facilities to deal with them?", "labels": [], "entities": [{"text": "Europarl", "start_pos": 45, "end_pos": 53, "type": "DATASET", "confidence": 0.9766075015068054}]}, {"text": "Reference translation: Comment pouvons-nous garantir le syst\u00e8me de notification pr\u00e9alable pour les produits pr\u00e9sentant un risque \u00e9lev\u00e9 dans les ports qui disposent des installations n\u00e9cessaires pour traiter ces produits ? Baseline neural MT: [.", "labels": [], "entities": [{"text": "Baseline neural MT", "start_pos": 222, "end_pos": 240, "type": "TASK", "confidence": 0.49899686376253766}]}, {"text": ".] les ports qui disposent des moyens n\u00e9cessaires pour y rem\u00e9dier ? Sense-aware neural MT: [.", "labels": [], "entities": []}, {"text": ".] les ports qui disposent des installations n\u00e9cessaires pour les traiter ? Current MT systems perform word sense disambiguation implicitly, based on co-occurring words in a rather limited context.", "labels": [], "entities": [{"text": "MT", "start_pos": 84, "end_pos": 86, "type": "TASK", "confidence": 0.9767778515815735}, {"text": "word sense disambiguation", "start_pos": 103, "end_pos": 128, "type": "TASK", "confidence": 0.7516922056674957}]}, {"text": "In phrase-based statistical MT, the context size is related to the order of the language model (often between 3 and 5) and to the length of n-grams in the phrase table (seldom above 5).", "labels": [], "entities": [{"text": "phrase-based statistical MT", "start_pos": 3, "end_pos": 30, "type": "TASK", "confidence": 0.5494743486245474}]}, {"text": "In attention-based neural MT (NMT), the context extends to the entire sentence, but multiple word senses are not modeled explicitly.", "labels": [], "entities": [{"text": "attention-based neural MT (NMT)", "start_pos": 3, "end_pos": 34, "type": "TASK", "confidence": 0.7517633438110352}]}, {"text": "The implicit sense information captured byword representations used in NMT leads to a bias in the attention mechanism towards dominant senses.", "labels": [], "entities": []}, {"text": "Therefore, the NMT decoders cannot clearly identify the contexts in which one word sense should be used rather than another one.", "labels": [], "entities": []}, {"text": "Hence, although NMT can use local constraints to translate \"great rock band\" into French as superbe groupe de rock rather than grande bande de pierre-thus correctly assigning the musical rather than geological sense to \"rock\"-it fails to do so for word senses that require larger contexts.", "labels": [], "entities": [{"text": "NMT", "start_pos": 16, "end_pos": 19, "type": "DATASET", "confidence": 0.8743329048156738}]}, {"text": "In this paper, we demonstrate that the explicit modeling of word senses can be helpful to NMT by using combined vector representations of word types and senses, which are inferred from contexts that are larger than that of state-of-the-art NMT systems.", "labels": [], "entities": [{"text": "NMT", "start_pos": 90, "end_pos": 93, "type": "TASK", "confidence": 0.9265037178993225}]}, {"text": "We make the following contributions: \u2022 Weakly supervised word sense disambiguation (WSD) approaches integrated into NMT, based on three adaptive clustering methods and operating on large word contexts.", "labels": [], "entities": [{"text": "Weakly supervised word sense disambiguation (WSD)", "start_pos": 39, "end_pos": 88, "type": "TASK", "confidence": 0.7036579288542271}]}, {"text": "\u2022 Three sense selection mechanisms for integrating WSD into NMT, respectively based on top, average, and weighted average (i.e., attention) of word senses.", "labels": [], "entities": [{"text": "WSD", "start_pos": 51, "end_pos": 54, "type": "TASK", "confidence": 0.9204586148262024}]}, {"text": "\u2022 Consistent improvements against baseline NMT on five language pairs: from English (EN) into Chinese (ZH), Dutch (NL), French (FR), German (DE), and Spanish (ES).", "labels": [], "entities": []}, {"text": "The paper is organized as follows.", "labels": [], "entities": []}, {"text": "In \u00a72, we present three adaptive WSD methods based on k-means clustering, the Chinese restaurant process, and random walks.", "labels": [], "entities": [{"text": "WSD", "start_pos": 33, "end_pos": 36, "type": "TASK", "confidence": 0.9515383839607239}]}, {"text": "In \u00a73, we present three sense selection mechanisms that integrate the word senses into NMT.", "labels": [], "entities": []}, {"text": "The experimental details appear in \u00a74, and the results concerning the optimal parameter settings are presented in \u00a75, where we also show that our WSD component is competitive on the SemEval 2010 shared task.", "labels": [], "entities": [{"text": "SemEval 2010 shared task", "start_pos": 182, "end_pos": 206, "type": "TASK", "confidence": 0.6403674185276031}]}, {"text": "\u00a76 presents our results: The BLEU scores increase by about 1 point with respect to a strong NMT baseline, and the accuracy of ambiguous noun and verb translation improves by about 4%, while a manual evaluation of several challenging and frequent words shows an improvement of about 20%.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 29, "end_pos": 33, "type": "METRIC", "confidence": 0.9992710947990417}, {"text": "accuracy", "start_pos": 114, "end_pos": 122, "type": "METRIC", "confidence": 0.999188244342804}, {"text": "noun and verb translation", "start_pos": 136, "end_pos": 161, "type": "TASK", "confidence": 0.5898263528943062}]}, {"text": "A discussion of related work appears finally in \u00a77.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 2: Performance of the WSD+SMT factored system for two language pairs from WIT3, with three clustering  methods and two initializations.", "labels": [], "entities": [{"text": "WSD+SMT factored", "start_pos": 29, "end_pos": 45, "type": "TASK", "confidence": 0.6320444047451019}, {"text": "WIT3", "start_pos": 81, "end_pos": 85, "type": "DATASET", "confidence": 0.9452236890792847}]}, {"text": " Table 3: WSD results from three SemEval 2010 systems and our six systems, in terms of V -score, F 1 score, and  their average. C = the average number of clusters. The adaptive k-means using definitions outperforms the others  on the average of V and F 1 , when considering both nouns and verbs, or nouns only. The SemEval systems are UoY  (Korkontzelos and Manandhar, 2010); KCDC-GD (Kern et al., 2010); and Duluth-Mix-Gap (Pedersen, 2010).", "labels": [], "entities": [{"text": "WSD", "start_pos": 10, "end_pos": 13, "type": "TASK", "confidence": 0.8053886890411377}, {"text": "V -score", "start_pos": 87, "end_pos": 95, "type": "METRIC", "confidence": 0.8752944668134054}, {"text": "F 1 score", "start_pos": 97, "end_pos": 106, "type": "METRIC", "confidence": 0.9735578298568726}]}, {"text": " Table 5: BLEU scores of our sense-aware NMT systems over five language pairs: ATT ini is the best one among  SMT and NMT systems. Significance testing is indicated by  \u2020 for p < 0.05 and  \u2021 for p < 0.01.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.999363362789154}, {"text": "ATT", "start_pos": 79, "end_pos": 82, "type": "METRIC", "confidence": 0.925387978553772}]}, {"text": " Table 6: Confusion matrix for our WSD+NMT  (ATT ini ) system and our WSD+SMT system against  their respective baselines (NMT and SMT), over the  Europarl test data, for two language pairs.", "labels": [], "entities": [{"text": "WSD+SMT", "start_pos": 70, "end_pos": 77, "type": "TASK", "confidence": 0.5492485364278158}, {"text": "Europarl test data", "start_pos": 146, "end_pos": 164, "type": "DATASET", "confidence": 0.9925617774327596}]}, {"text": " Table 7: BLEU scores on WMT NewsTest 2012 and 2013 (NT) test sets for two language pairs. Significance  testing is indicated by  \u2020 for p < 0.05 and  \u2021 for p < 0.01.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9994350075721741}, {"text": "WMT NewsTest 2012 and 2013 (NT) test sets", "start_pos": 25, "end_pos": 66, "type": "DATASET", "confidence": 0.9426459968090057}]}, {"text": " Table 8: BLEU score on English-to-German translation over the WMT NewsTest (NT) 2014 and 2015 test sets.  Significance testing is indicated by  \u2020 for p < 0.05 and  \u2021 for p < 0.01. The highest score per column is in bold.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9996334314346313}, {"text": "WMT NewsTest (NT) 2014 and 2015 test sets", "start_pos": 63, "end_pos": 104, "type": "DATASET", "confidence": 0.950114643573761}]}]}