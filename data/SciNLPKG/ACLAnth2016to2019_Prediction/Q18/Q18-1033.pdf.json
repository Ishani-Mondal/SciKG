{"title": [{"text": "Detecting Institutional Dialog Acts in Police Traffic Stops", "labels": [], "entities": [{"text": "Detecting Institutional Dialog Acts in Police Traffic Stops", "start_pos": 0, "end_pos": 59, "type": "TASK", "confidence": 0.7920984774827957}]}], "abstractContent": [{"text": "We apply computational dialog methods to police body-worn camera footage to model conversations between police officers and community members in traffic stops.", "labels": [], "entities": []}, {"text": "Relying on the theory of institutional talk, we develop a labeling scheme for police speech during traffic stops, and a tagger to detect institutional dialog acts (Reasons, Searches, Offering Help) from transcribed text at the turn (78% F-score) and stop (89% F-score) level.", "labels": [], "entities": [{"text": "F-score", "start_pos": 237, "end_pos": 244, "type": "METRIC", "confidence": 0.9909975528717041}, {"text": "F-score) level", "start_pos": 260, "end_pos": 274, "type": "METRIC", "confidence": 0.916701594988505}]}, {"text": "We then develop speech recognition and seg-mentation algorithms to detect these acts at the stop level from raw camera audio (81% F-score, with even higher accuracy for crucial acts like conveying the reason for the stop).", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 16, "end_pos": 34, "type": "TASK", "confidence": 0.7096600979566574}, {"text": "F-score", "start_pos": 130, "end_pos": 137, "type": "METRIC", "confidence": 0.9986016154289246}, {"text": "accuracy", "start_pos": 156, "end_pos": 164, "type": "METRIC", "confidence": 0.9957085847854614}, {"text": "conveying the reason for the stop", "start_pos": 187, "end_pos": 220, "type": "TASK", "confidence": 0.8248862226804098}]}, {"text": "We demonstrate that the dialog structures produced by our tagger could reveal whether officers follow law enforcement norms like introducing themselves, explaining the reason for the stop, and asking permission for searches.", "labels": [], "entities": []}, {"text": "This work may therefore inform and aid efforts to ensure the procedural justice of police-community interactions.", "labels": [], "entities": []}], "introductionContent": [{"text": "Improving the relationship between police officers and the communities they serve is a critical societal goal.", "labels": [], "entities": []}, {"text": "We propose to study this relationship by applying NLP techniques to conversations between officers and community members in traffic stops.", "labels": [], "entities": []}, {"text": "Traffic stops are one of the most common forms of police contact with community members, with 10% of U.S. adults pulled over every year).", "labels": [], "entities": []}, {"text": "Yet past research on what people experience during these traffic stops has mainly been limited to self-reported behavior and post-hoc narratives).", "labels": [], "entities": []}, {"text": "The rapid adoption of body-worn cameras by police departments in the U.S. (laws in 60% of states in the U.S. encourage the use of body cameras) and across the world has provided unprecedented insight into traffic stops.", "labels": [], "entities": []}, {"text": "1 While footage from these cameras is used as evidence in contentious cases, the unstructured nature and immense volume of video data means that most of this footage is untapped.", "labels": [], "entities": []}, {"text": "Recent work by demonstrated that body-worn camera footage could be used not just as evidence in court, but as data.", "labels": [], "entities": []}, {"text": "They developed algorithms to automatically detect the degree of respect that officers communicated to drivers in close to 1,000 routine traffic stops captured on camera.", "labels": [], "entities": []}, {"text": "It was the first study to use machine learning techniques to extract insights from this footage.", "labels": [], "entities": []}, {"text": "This footage can be further used to unearth the structure of police-community interactions and gain a more comprehensive picture of the traffic stop as an everyday institutional practice.", "labels": [], "entities": []}, {"text": "For instance, knowing which requests the officer makes, whether and when they introduce themselves or explain the reason for the stop is a novel way to measure procedural justice; a set of fairness principles recommended by the President's Task Force on 21st Century Policing, and endorsed by police departments across the U.S. We propose automatically extracting dialog structure from body camera footage to contribute to our understanding of police-community interactions.", "labels": [], "entities": [{"text": "knowing which requests the officer makes, whether and when they introduce themselves or explain the reason for the stop", "start_pos": 14, "end_pos": 133, "type": "Description", "confidence": 0.7007892012596131}]}, {"text": "We rely on the notion of institutional talk, which posits that dialog acts, topics, and narrative are heavily defined by the institutional context.", "labels": [], "entities": []}, {"text": "Traffic stops area kind of institutional talk; as are, for example, doctor-patient interactions, counseling conversations, and citizen calls for help from police.", "labels": [], "entities": []}, {"text": "We introduce a model of institutional acts for traffic stop conversations.", "labels": [], "entities": [{"text": "traffic stop conversations", "start_pos": 47, "end_pos": 73, "type": "TASK", "confidence": 0.74153733253479}]}, {"text": "Since the officer holds a position of power within this institutional context, their dialog behavior has a greater influence in shaping the conversation; hence, we focus on the institutional acts performed by the officer in this paper.", "labels": [], "entities": []}, {"text": "Contributions of our paper: 1) A typology of institutional dialog acts to model the structure of police-driver interactions during traffic stops.", "labels": [], "entities": []}, {"text": "2) An institutional act tagger that works from transcribed words (78% F-score) or from raw audio (60% Fscore).", "labels": [], "entities": [{"text": "institutional act tagger", "start_pos": 6, "end_pos": 30, "type": "TASK", "confidence": 0.6685052514076233}, {"text": "F-score", "start_pos": 70, "end_pos": 77, "type": "METRIC", "confidence": 0.9955470561981201}, {"text": "Fscore", "start_pos": 102, "end_pos": 108, "type": "METRIC", "confidence": 0.9929306507110596}]}, {"text": "3) A classifier that uses this dialog structure to detect acts at the stop level (e.g., \"Does this stop contain a Reason?\")", "labels": [], "entities": []}, {"text": "(81% F-score from raw audio).", "labels": [], "entities": [{"text": "F-score", "start_pos": 5, "end_pos": 12, "type": "METRIC", "confidence": 0.9952185750007629}]}, {"text": "4) An analysis of salient dialog structure patterns in traffic stops; demonstrating its potential as a tool for police departments to assess and improve police community interactions.", "labels": [], "entities": []}], "datasetContent": [{"text": "Table 3 presents micro-averaged (i.e., weighted average of each class) precision, recall and F-measure obtained on 10-fold cross validation.", "labels": [], "entities": [{"text": "precision", "start_pos": 71, "end_pos": 80, "type": "METRIC", "confidence": 0.9975475668907166}, {"text": "recall", "start_pos": 82, "end_pos": 88, "type": "METRIC", "confidence": 0.9995573163032532}, {"text": "F-measure", "start_pos": 93, "end_pos": 102, "type": "METRIC", "confidence": 0.9993446469306946}]}, {"text": "While ERT posted the highest precision of 80.9% at a low recall of 63.6%, SVM reported the highest recall of 76.2% without a huge dentin precision.", "labels": [], "entities": [{"text": "ERT", "start_pos": 6, "end_pos": 9, "type": "DATASET", "confidence": 0.5080864429473877}, {"text": "precision", "start_pos": 29, "end_pos": 38, "type": "METRIC", "confidence": 0.9989739656448364}, {"text": "recall", "start_pos": 57, "end_pos": 63, "type": "METRIC", "confidence": 0.9985353946685791}, {"text": "SVM", "start_pos": 74, "end_pos": 77, "type": "DATASET", "confidence": 0.7056382298469543}, {"text": "recall", "start_pos": 99, "end_pos": 105, "type": "METRIC", "confidence": 0.9990025162696838}]}, {"text": "Overall, we obtain the best micro-averaged F-score of 77.5% using SVM.", "labels": [], "entities": [{"text": "F-score", "start_pos": 43, "end_pos": 50, "type": "METRIC", "confidence": 0.934769332408905}, {"text": "SVM", "start_pos": 66, "end_pos": 69, "type": "DATASET", "confidence": 0.7533197999000549}]}, {"text": "CNN performed worse than both ERT and SVM.", "labels": [], "entities": [{"text": "CNN", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.9468672871589661}, {"text": "ERT", "start_pos": 30, "end_pos": 33, "type": "DATASET", "confidence": 0.5413325428962708}, {"text": "SVM", "start_pos": 38, "end_pos": 41, "type": "DATASET", "confidence": 0.8844137787818909}]}, {"text": "We also performed an ablation study to seethe relative importance of features in the SVM 7 CNN: batch size of 10, dropout of 0.3, adam, 10 epochs.", "labels": [], "entities": [{"text": "SVM 7 CNN", "start_pos": 85, "end_pos": 94, "type": "DATASET", "confidence": 0.8964957992235819}]}, {"text": "SVM: C=1, linear kernel.", "labels": [], "entities": [{"text": "SVM", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.9026128649711609}]}, {"text": "ERT: 100 estimators, max tree depth 75, # of features capped at 20% of all features.", "labels": [], "entities": [{"text": "ERT", "start_pos": 0, "end_pos": 3, "type": "METRIC", "confidence": 0.8022299408912659}, {"text": "max tree depth", "start_pos": 21, "end_pos": 35, "type": "METRIC", "confidence": 0.9237718184789022}]}, {"text": "Parameter values obtained using grid-search within the training set for each fold.", "labels": [], "entities": []}, {"text": "8 Since CNN performed much worse than SVM with lexical features alone (last row), presumably because of the small amount of data, we did not perform more CNN experiments.", "labels": [], "entities": []}, {"text": "We inspected the weights assigned to the features by a model trained on the entire dataset.", "labels": [], "entities": []}, {"text": "The models created for each institutional act had at least one pattern or structure feature in the top twenty five features.", "labels": [], "entities": []}, {"text": "shows the feature weights assigned to the model detecting GREETING.", "labels": [], "entities": [{"text": "GREETING", "start_pos": 58, "end_pos": 66, "type": "METRIC", "confidence": 0.931738555431366}]}, {"text": "The model up-weighted utterances with greeting patterns (GREETINGS), first utterances (FIRST), and utterances in the first quarter (FIRSTQUART), while down-weighting longer utterances and those that mention lenience (LENIENCE).", "labels": [], "entities": [{"text": "GREETINGS", "start_pos": 57, "end_pos": 66, "type": "METRIC", "confidence": 0.9405549168586731}, {"text": "FIRST", "start_pos": 87, "end_pos": 92, "type": "METRIC", "confidence": 0.8749058842658997}, {"text": "FIRSTQUART", "start_pos": 132, "end_pos": 142, "type": "METRIC", "confidence": 0.9671189785003662}, {"text": "LENIENCE", "start_pos": 217, "end_pos": 225, "type": "METRIC", "confidence": 0.9552934765815735}]}, {"text": "We now present experiments using the automatically identified officer speech segments.", "labels": [], "entities": []}, {"text": "At training time, we use the ASR generated text using gold segments; Patch of 210ms with astride of 50ms.", "labels": [], "entities": []}, {"text": "Audio was downsampled to 16kHz, and converted to 21-dimensional magnitude mel-filterbank representation covering frequencies from 0-8 kHz.", "labels": [], "entities": []}, {"text": "FFT size was 512 with 10ms hop and 30ms frame size.", "labels": [], "entities": [{"text": "FFT size", "start_pos": 0, "end_pos": 8, "type": "METRIC", "confidence": 0.5473580062389374}]}, {"text": "attest time, we use the same ASR model to generate text for the predicted segments.", "labels": [], "entities": [{"text": "ASR", "start_pos": 29, "end_pos": 32, "type": "TASK", "confidence": 0.7092614769935608}]}, {"text": "Since the predicted segments do not exactly match gold segments, we use a fuzzy-matching approach for evaluation.", "labels": [], "entities": []}, {"text": "If a gold segment contains an act and an overlapping predicted segment has the same act, we consider it a true positive.", "labels": [], "entities": []}, {"text": "If a gold segment contains an act, but none of the overlapping predicted segments have that act, it is counted as a false negative.", "labels": [], "entities": []}, {"text": "If an act is identified in one of the predicted segments, without any of the overlapping gold segments having it, then we consider it a false positive.", "labels": [], "entities": []}, {"text": "presents results using this evaluation scheme.", "labels": [], "entities": []}, {"text": "Again, BLSTM using the 10Best strategy obtained the best F-score of 59.8%.", "labels": [], "entities": [{"text": "BLSTM", "start_pos": 7, "end_pos": 12, "type": "DATASET", "confidence": 0.6188622117042542}, {"text": "F-score", "start_pos": 57, "end_pos": 64, "type": "METRIC", "confidence": 0.9995619654655457}]}, {"text": "Both BLSTM and DNN benefited significantly from using the 10Best likely predictions.", "labels": [], "entities": [{"text": "BLSTM", "start_pos": 5, "end_pos": 10, "type": "METRIC", "confidence": 0.6091815829277039}, {"text": "DNN", "start_pos": 15, "end_pos": 18, "type": "DATASET", "confidence": 0.9268519282341003}, {"text": "10Best likely predictions", "start_pos": 58, "end_pos": 83, "type": "DATASET", "confidence": 0.851885994275411}]}, {"text": "As in the ASR experiments, the DNN substantially closes the gap in performance by using the 10Best strategy.", "labels": [], "entities": [{"text": "ASR", "start_pos": 10, "end_pos": 13, "type": "TASK", "confidence": 0.9590691924095154}]}], "tableCaptions": [{"text": " Table 3: Micro-averaged precision (P), recall (R) and F- score (F) for experiments using manual transcripts.", "labels": [], "entities": [{"text": "Micro-averaged precision (P)", "start_pos": 10, "end_pos": 38, "type": "METRIC", "confidence": 0.880447793006897}, {"text": "recall (R)", "start_pos": 40, "end_pos": 50, "type": "METRIC", "confidence": 0.9692505598068237}, {"text": "F- score (F)", "start_pos": 55, "end_pos": 67, "type": "METRIC", "confidence": 0.9876692593097687}]}, {"text": " Table 4: Data used to build the ASR models.", "labels": [], "entities": [{"text": "ASR", "start_pos": 33, "end_pos": 36, "type": "TASK", "confidence": 0.9660595655441284}]}, {"text": " Table 5: Language model perplexity on Dev set.", "labels": [], "entities": []}, {"text": " Table 6: Word error rate for different ASR models.", "labels": [], "entities": [{"text": "Word error rate", "start_pos": 10, "end_pos": 25, "type": "METRIC", "confidence": 0.7906872232755026}, {"text": "ASR", "start_pos": 40, "end_pos": 43, "type": "TASK", "confidence": 0.988125205039978}]}, {"text": " Table 7: Micro-averaged F-scores on institutional act pre- diction using different ASR sources.", "labels": [], "entities": [{"text": "F-scores", "start_pos": 25, "end_pos": 33, "type": "METRIC", "confidence": 0.7990961074829102}, {"text": "ASR", "start_pos": 84, "end_pos": 87, "type": "TASK", "confidence": 0.9030124545097351}]}, {"text": " Table 8: Micro-averaged F-scores on institutional act pre- diction from raw audio using different ASR sources.", "labels": [], "entities": [{"text": "F-scores", "start_pos": 25, "end_pos": 33, "type": "METRIC", "confidence": 0.8134565353393555}]}, {"text": " Table 9: Stop level institutional act presence detection results (for each label).", "labels": [], "entities": [{"text": "Stop level institutional act presence detection", "start_pos": 10, "end_pos": 57, "type": "TASK", "confidence": 0.7755910158157349}]}, {"text": " Table 10: Stop level institutional act detection using our  tagger, compared to a lexical baseline model trained on  all the words spoken by the officer, without accounting  for the dialog structure.", "labels": [], "entities": [{"text": "Stop level institutional act detection", "start_pos": 11, "end_pos": 49, "type": "TASK", "confidence": 0.76354079246521}]}, {"text": " Table 11: Summary: Micro-averaged F-scores across dif- ferent text/segmentation sources.", "labels": [], "entities": [{"text": "F-scores", "start_pos": 35, "end_pos": 43, "type": "METRIC", "confidence": 0.699808657169342}]}]}