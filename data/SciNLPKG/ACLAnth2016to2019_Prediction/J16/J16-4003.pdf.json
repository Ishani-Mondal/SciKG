{"title": [{"text": "There Is No Logical Negation Here, But There Are Alternatives: Modeling Conversational Negation with Distributional Semantics", "labels": [], "entities": []}], "abstractContent": [{"text": "Logical negation is a challenge for distributional semantics, because predicates and their negations tend to occur in very similar contexts, and consequently their distributional vectors are very similar.", "labels": [], "entities": [{"text": "Logical negation", "start_pos": 0, "end_pos": 16, "type": "TASK", "confidence": 0.7992642223834991}]}, {"text": "Indeed, it is not even clear what properties a \"negated\" distributional vector should possess.", "labels": [], "entities": []}, {"text": "However, when linguistic negation is considered in its actual discourse usage, it often performs a role that is quite different from straightforward logical negation.", "labels": [], "entities": []}, {"text": "If someone states, in the middle of a conversation, that \"This is not a dog,\" the negation strongly suggests a restricted set of alternative predicates that might hold true of the object being talked about.", "labels": [], "entities": []}, {"text": "In particular, other canids and middle-sized mammals are plausible alternatives, birds are less likely, skyscrapers and other large buildings virtually impossible.", "labels": [], "entities": []}, {"text": "Conversational negation acts like a graded similarity function, of the sort that distributional semantics might be good at capturing.", "labels": [], "entities": []}, {"text": "In this article, we introduce a large data set of alternative plausibility ratings for conversationally negated nominal predicates, and we show that simple similarity in distri-butional semantic space provides an excellent fit to subject data.", "labels": [], "entities": [{"text": "conversationally negated nominal predicates", "start_pos": 87, "end_pos": 130, "type": "TASK", "confidence": 0.6290845721960068}]}, {"text": "On the one hand, this fills a gap in the literature on conversational negation, proposing distributional semantics as the right tool to make explicit predictions about potential alternatives of negated predicates.", "labels": [], "entities": []}, {"text": "On Computational Linguistics Volume 42, Number 4 the other hand, the results suggest that negation, when addressed from a broader pragmatic perspective, far from being a nuisance, is an ideal application domain for distributional semantic methods.", "labels": [], "entities": []}], "introductionContent": [{"text": "Distributional semantics (DS) derives vector-based representations of the meaning of words and other linguistic expressions by generalizing over the contexts in which such expressions occur in large text corpora.", "labels": [], "entities": [{"text": "Distributional semantics (DS)", "start_pos": 0, "end_pos": 29, "type": "TASK", "confidence": 0.8045806884765625}]}, {"text": "By exploiting the rich commonsense knowledge encoded in corpora and a continuous notion of relatedness that is well-suited to capture the fuzzy nature of content-word semantics, DS representations can successfully model lexical aspects of meaning such as synonymy, word analogy, selectional preferences, and, to a certain extent, hypernymy.", "labels": [], "entities": [{"text": "word analogy", "start_pos": 265, "end_pos": 277, "type": "TASK", "confidence": 0.7587498724460602}]}, {"text": "There is, however, virtually no evidence that DS can capture the semantic properties of grammatical terms such as conjunctions, determiners, or adverbial particles.", "labels": [], "entities": []}, {"text": "The very notion of continuous similarity that is so powerful in modeling lexical phenomena is problematic when it comes to capturing the discrete logical operations that are typically associated with the meaning of grammatical terms.", "labels": [], "entities": []}, {"text": "Adverbs and determiners expressing negation, such as English no and not, receive a very elegant treatment in logic-based approaches: if dog denotes the (appropriately indexed) set of all dogs, then no dog denotes the complement of the set.", "labels": [], "entities": []}, {"text": "However, there is no straightforward \"negation\" operation that, when applied to the DS vector of dog, would derive a no dog vector capturing the same complement intuition in vector space.", "labels": [], "entities": []}, {"text": "Moreover, negated elements tend to occur in the same contexts of their affirmative counterparts (cf.: A dog was barking, No dog was barking).", "labels": [], "entities": []}, {"text": "Consequently, corpus-induced vectors of predicates and their negations are very similar.", "labels": [], "entities": []}, {"text": "This \"contextual invariance\" of negation is indeed a well-known problem also in lexical semantics, where it has been observed that vectors of words and their (lexicalized) opposites tend to be extremely similar ().", "labels": [], "entities": []}, {"text": "In this article, we argue that the problems with negation in DS arise because we are trying to capture a purely logical kind of negation that is neither well-suited to DS nor particularly useful for modeling real-life language usage.", "labels": [], "entities": []}, {"text": "If we isolate dogs and nondogs in the lab, the logical approach is very appealing: non-dogs include anything that is not a dog.", "labels": [], "entities": []}, {"text": "However, consider which of the following two sentences is more likely to be uttered in a natural conversational context: a.", "labels": [], "entities": []}, {"text": "This is not a dog.", "labels": [], "entities": []}, {"text": "it is a wolf. b. This is not a dog.", "labels": [], "entities": []}, {"text": "If the negation of a predicate is just the complement of the corresponding set, then Examples (1a) and (1b) should be equally plausible.", "labels": [], "entities": []}, {"text": "However, Example (1a) is clearly more natural than (1b).", "labels": [], "entities": []}, {"text": "Looking beyond the purely logical aspects of negation, along tradition informal semantics, pragmatics and psycholinguistics has stressed that, in actual conversational contexts, negation is not just excluding possible denotata of the predicates it takes scope over, but also suggesting the truth of an alternative assertion.", "labels": [], "entities": []}, {"text": "Alternativehood (the possibility of an expression to constitute an alternative to a negated item) seems very well-suited to be modeled in DS.", "labels": [], "entities": []}, {"text": "It is, more specifically, tied to a contextual notion of similarity: We expect plausible alternatives to be objects or events that tend to occur in contexts that are typical of the negated ones.", "labels": [], "entities": []}, {"text": "Finally, alternativehood, just like many lexical properties successfully modeled in DS, is an inherently graded property.", "labels": [], "entities": []}, {"text": "This is not a dog.", "labels": [], "entities": []}, {"text": "it is a tarantula. b. This is not a dog.", "labels": [], "entities": []}, {"text": "it is a conference call.", "labels": [], "entities": []}, {"text": "Sentence (2a) is more surprising than (1a), but arguably less so than (1b).", "labels": [], "entities": [{"text": "Sentence", "start_pos": 0, "end_pos": 8, "type": "METRIC", "confidence": 0.7577767968177795}]}, {"text": "In turn, the contingencies in which the latter might be uttered, although undoubtedly bizarre, are still easier to conceive than those that would justify uttering Example (2b).", "labels": [], "entities": [{"text": "Example", "start_pos": 163, "end_pos": 170, "type": "DATASET", "confidence": 0.8690860271453857}]}, {"text": "The first goal of the current article is then to introduce the computational linguistics community to the pragmatic, alternative-licensing view of negation, that we will call conversational negation.", "labels": [], "entities": []}, {"text": "Second, we illustrate how DS can contribute, from anew angle, to the literature on alternativehood under conversational negation.", "labels": [], "entities": []}, {"text": "Thanks to its ability to automatically identify potential alternatives in a large vocabulary of linguistic expressions, DS allows us to make predictions about which elements fall into the (fuzzy) alternative set of a negated expression.", "labels": [], "entities": []}, {"text": "This is anew contribution to studies on the semantics of alternatives (in negation or other domains), where authors rely instead on their intuition to pick a small number of candidate alternatives.", "labels": [], "entities": []}, {"text": "Our main empirical contributions are to provide a set of subject-rated negatedpredicate/alternative statements, and to predict these ratings with DS.", "labels": [], "entities": [{"text": "DS", "start_pos": 146, "end_pos": 148, "type": "METRIC", "confidence": 0.9260523319244385}]}, {"text": "We collect alternativehood judgments in two (minimal) sentential contexts, and study how both sentential context and the negated-item/alternative relation affect the judgments.", "labels": [], "entities": []}, {"text": "The most striking result of the computational simulations is how good simple distributional similarity is at predicting the plausibility of an alternative.", "labels": [], "entities": []}, {"text": "This measure comes so close to an estimated upper bound that we can only improve over it by a small margin when we use compositional methods and supervision to take sentential context and the specifics of negation into account.", "labels": [], "entities": []}, {"text": "Finally, we present some conjectures on what a DS-based theory accounting for conversational negation could look like.", "labels": [], "entities": [{"text": "conversational negation", "start_pos": 78, "end_pos": 101, "type": "TASK", "confidence": 0.734268993139267}]}, {"text": "We argue that negation should not be modeled as part of the static distributional representation of a single statement, but as a function that, given the negated predicate, produces a probability distribution over the predicates that are most likely to follow.", "labels": [], "entities": [{"text": "negation", "start_pos": 14, "end_pos": 22, "type": "TASK", "confidence": 0.9805008172988892}]}, {"text": "This approach suggests, more generally, adopting a dynamic view of DS, not unlike the one that has been prominent for decades in other areas of semantics.", "labels": [], "entities": []}, {"text": "The rest of this article is structured as follows.", "labels": [], "entities": []}, {"text": "Section 2 reviews attempts to model (logical) negation in DS.", "labels": [], "entities": []}, {"text": "Section 3 surveys the literature on alternative-licensing conversational negation.", "labels": [], "entities": [{"text": "alternative-licensing conversational negation", "start_pos": 36, "end_pos": 81, "type": "TASK", "confidence": 0.6176849007606506}]}, {"text": "Our data set containing subject plausibility ratings for negateditem/alternative pairs is introduced and analyzed in Section 4.", "labels": [], "entities": []}, {"text": "In Section 5, we use DS to model the ratings in the data set.", "labels": [], "entities": [{"text": "DS", "start_pos": 21, "end_pos": 23, "type": "METRIC", "confidence": 0.8838787078857422}]}, {"text": "We conclude in Section 6 by looking at the theoretical implications of our work, as well as suggesting directions for further study.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 3  Summary of alternative plausibility distributions: Number of reliably rated pairs, medians of  mean pair rating, and pair rating variance.", "labels": [], "entities": [{"text": "pair rating variance", "start_pos": 127, "end_pos": 147, "type": "METRIC", "confidence": 0.665920078754425}]}, {"text": " Table 4  Percentage Pearson correlations between model-produced scores and mean human ratings of  test set pairs.", "labels": [], "entities": []}]}