{"title": [{"text": "Source Language Adaptation Approaches for Resource-Poor Machine Translation", "labels": [], "entities": [{"text": "Source Language Adaptation Approaches", "start_pos": 0, "end_pos": 37, "type": "TASK", "confidence": 0.6626780182123184}, {"text": "Machine Translation", "start_pos": 56, "end_pos": 75, "type": "TASK", "confidence": 0.7173194587230682}]}], "abstractContent": [{"text": "Most of the world languages are resource-poor for statistical machine translation; still, many of them are actually related to some resource-rich language.", "labels": [], "entities": [{"text": "statistical machine translation", "start_pos": 50, "end_pos": 81, "type": "TASK", "confidence": 0.7383936047554016}]}, {"text": "Thus, we propose three novel, language-independent approaches to source language adaptation for resource-poor statistical machine translation.", "labels": [], "entities": [{"text": "source language adaptation", "start_pos": 65, "end_pos": 91, "type": "TASK", "confidence": 0.6368978420893351}, {"text": "statistical machine translation", "start_pos": 110, "end_pos": 141, "type": "TASK", "confidence": 0.625752846399943}]}, {"text": "Specifically, we build improved statistical machine translation models from a resource-poor language POOR into a target language TGT by adapting and using a large bitext fora related resource-rich language RICH and the same target language TGT.", "labels": [], "entities": [{"text": "statistical machine translation", "start_pos": 32, "end_pos": 63, "type": "TASK", "confidence": 0.6249465644359589}]}, {"text": "We assume a small POOR-TGT bitext from which we learn word-level and phrase-level paraphrases and cross-lingual morphological variants between the resource-rich and the resource-poor language.", "labels": [], "entities": [{"text": "POOR-TGT bitext", "start_pos": 18, "end_pos": 33, "type": "METRIC", "confidence": 0.6647346317768097}]}, {"text": "Our work is of importance for resource-poor machine translation because it can provide a useful guideline for people building machine translation systems for resource-poor languages.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 44, "end_pos": 63, "type": "TASK", "confidence": 0.7169196456670761}, {"text": "machine translation", "start_pos": 126, "end_pos": 145, "type": "TASK", "confidence": 0.7394050359725952}]}, {"text": "Our experiments for Indonesian/Malay-English translation show that using the large adapted resource-rich bitext yields 7.26 BLEU points of improvement over the unadapted one and 3.09 BLEU points over the original small bitext.", "labels": [], "entities": [{"text": "Indonesian/Malay-English translation", "start_pos": 20, "end_pos": 56, "type": "TASK", "confidence": 0.56362584233284}, {"text": "BLEU", "start_pos": 124, "end_pos": 128, "type": "METRIC", "confidence": 0.9993422627449036}, {"text": "BLEU", "start_pos": 183, "end_pos": 187, "type": "METRIC", "confidence": 0.9986949563026428}]}, {"text": "Moreover, combining the small POOR-TGT bitext with the adapted bitext outperforms the corresponding combinations with the unadapted bitext by 1.93-3.25 BLEU points.", "labels": [], "entities": [{"text": "POOR-TGT", "start_pos": 30, "end_pos": 38, "type": "METRIC", "confidence": 0.8917748928070068}, {"text": "BLEU", "start_pos": 152, "end_pos": 156, "type": "METRIC", "confidence": 0.9990890026092529}]}, {"text": "We also demonstrate the applicability of our approaches to other languages and domains.", "labels": [], "entities": []}], "introductionContent": [{"text": "Contemporary statistical machine translation (SMT) systems learn how to translate from large sentence-aligned bilingual corpora of human-generated translations, called translation but rather adaptation (since our ultimate goal is to translate into a third language X).", "labels": [], "entities": [{"text": "statistical machine translation (SMT)", "start_pos": 13, "end_pos": 50, "type": "TASK", "confidence": 0.7795383781194687}]}, {"text": "A special case of this same line of research is the translation between dialects of the same language, for example, between Cantonese and Mandarin, or between a dialect of a language and a standard version of that language, for example, between some Arabic dialect (e.g., Egyptian) and Modern Standard Arabic.", "labels": [], "entities": []}, {"text": "Here again, manual rules and/or language-specific tools and resources are typically used.", "labels": [], "entities": []}, {"text": "In the case of Arabic dialects, a further complication arises due to the informal status of the dialects, which are not standardized and not used informal contexts but rather only in informal online media such as social networks, chats, forums, Twitter, and SMS messages, though the Egyptian Wikipedia is one notable exception.", "labels": [], "entities": []}, {"text": "This causes further mismatch in domain and genre.", "labels": [], "entities": []}, {"text": "Thus, translating from Arabic dialects to Modern Standard Arabic requires, among other things, normalizing informal text to a formal form.", "labels": [], "entities": []}, {"text": "first normalized a dialectal Egyptian Arabic to look like Modern Standard Arabic, and then translated the transformed text to English.", "labels": [], "entities": []}, {"text": "In fact, this is a more general problem, which arises with informal sources such as SMS messages and Tweets for just any language (; Han and Baldwin 2011;.", "labels": [], "entities": []}, {"text": "Here the main focus is on coping with spelling errors, abbreviations, and slang, which are typically addressed using string edit distance, while also taking pronunciation into account.", "labels": [], "entities": []}, {"text": "This is different from our task, where we try to adapt good, formal text from one language to another.", "labels": [], "entities": []}, {"text": "A second relevant line of research is on language adaptation and normalization, when done specifically for improving SMT into another language.", "labels": [], "entities": [{"text": "language adaptation", "start_pos": 41, "end_pos": 60, "type": "TASK", "confidence": 0.7519087195396423}, {"text": "SMT", "start_pos": 117, "end_pos": 120, "type": "TASK", "confidence": 0.9935848116874695}]}, {"text": "For example, Marujo et al.", "labels": [], "entities": []}, {"text": "(2011) described a rule-based system for adapting Brazilian Portuguese (BP) to European Portuguese (EP), which they used to adapt BP-English bitexts to EP-English.", "labels": [], "entities": [{"text": "adapting Brazilian Portuguese (BP) to European Portuguese (EP)", "start_pos": 41, "end_pos": 103, "type": "TASK", "confidence": 0.578917587796847}]}, {"text": "They report small improvements in BLEU for EP-English translation when training on the adapted \"EP\"-English bitext compared with using the unadapted BP-English, or when an EP-English bitext is used in addition to the adapted/unadapted one (41.07 vs. 40.91 BLEU points).", "labels": [], "entities": [{"text": "BLEU", "start_pos": 34, "end_pos": 38, "type": "METRIC", "confidence": 0.9992986917495728}, {"text": "EP-English translation", "start_pos": 43, "end_pos": 65, "type": "TASK", "confidence": 0.6657818406820297}, {"text": "BLEU", "start_pos": 256, "end_pos": 260, "type": "METRIC", "confidence": 0.996604323387146}]}, {"text": "Unlike that work, which heavily relied on language-specific rules, our approach is statistical, and largely languageindependent; moreover, our improvements are much more sizable.", "labels": [], "entities": []}, {"text": "A third relevant line of research is on reusing bitexts between related languages without or with very little adaptation, which works well for very closely related languages.", "labels": [], "entities": []}, {"text": "For example, our previous work) experimented with various techniques for combining a small bitext fora resource-poor language (Indonesian or Spanish) with a much larger bitext fora related resource-rich language (Malay or Portuguese), pretending that Spanish is resource-poor; the target language of all bitexts was English.", "labels": [], "entities": []}, {"text": "However, that work did not attempt language adaptation, except for very simple transliteration for Portuguese-Spanish that ignored context entirely; because it does not substitute a word with a completely different word, transliteration did not help much for Malay-Indonesian, which use unified spelling.", "labels": [], "entities": [{"text": "language adaptation", "start_pos": 35, "end_pos": 54, "type": "TASK", "confidence": 0.7388493120670319}]}, {"text": "Still, once we have language-adapted the large bitext, it makes sense to try to combine it further with the small bitext; thus, in the following we will directly compare and combine these two approaches.", "labels": [], "entities": []}, {"text": "One alternative, which we do not explore in this work, is to use cascaded translation using a pivot language.", "labels": [], "entities": []}, {"text": "Unfortunately, using the resource-rich language as a pivot (poor\u2192rich\u2192X) would require an additional parallel poor-rich bitext, which we do not have.", "labels": [], "entities": []}, {"text": "Pivoting over the target X (rich\u2192X\u2192poor) for the purpose of language adaptation, on the other hand, would miss the opportunity to exploit the relationship between the resource-poor and the resource-rich language; this would also be circular since the first step would ask an SMT system to translate its own training data (we only have one rich-X bitext).", "labels": [], "entities": [{"text": "language adaptation", "start_pos": 60, "end_pos": 79, "type": "TASK", "confidence": 0.7261809259653091}, {"text": "SMT", "start_pos": 275, "end_pos": 278, "type": "TASK", "confidence": 0.9755535125732422}]}, {"text": "Yet another alternative approach for improving resource-poor MT is to mine translation bitexts from comparable corpora.", "labels": [], "entities": [{"text": "MT", "start_pos": 61, "end_pos": 63, "type": "TASK", "confidence": 0.9923451542854309}]}, {"text": "This is orthogonal to our efforts here, as our focus is on adapting resources fora related resource-rich language, rather than directly mining source-target translation pairs from comparable corpora.", "labels": [], "entities": []}], "datasetContent": [{"text": "With a small Indonesian-English bitext and a larger Malay-English bitext, we use three approaches for source language adaptation to adapt the Malay side of the MalayEnglish bitext to look like Indonesian, thus obtaining a synthetic \"Indonesian\"-English bitext.", "labels": [], "entities": [{"text": "source language adaptation", "start_pos": 102, "end_pos": 128, "type": "TASK", "confidence": 0.638391892115275}]}, {"text": "With the synthetic bitext, we run two kinds of experiments: r isolated, where we train an SMT system on the synthetic \"Indonesian\"-English bitext only r combined, where we combine the synthetic bitext with the original   We can see that for the word-level paraphrasing experiments (CN:*), all combinations except CN:word perform significantly better than their corresponding baselines, but the improvements are most sizeable for simple concatenation.", "labels": [], "entities": [{"text": "SMT", "start_pos": 90, "end_pos": 93, "type": "TASK", "confidence": 0.9850085973739624}]}, {"text": "Note that whereas there is a difference of 0.31 BLEU points between the balanced concatenation and the sophisticated combination for the original ML2EN, they differ little for the adapted versions.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 48, "end_pos": 52, "type": "METRIC", "confidence": 0.9992190599441528}, {"text": "ML2EN", "start_pos": 146, "end_pos": 151, "type": "DATASET", "confidence": 0.8698804974555969}]}, {"text": "This is probably due to the sophisticated combination assuming that the second bitext is worse than the first one, which is not really the case for the adapted versions: As shows, they all outperform IN2EN.", "labels": [], "entities": [{"text": "IN2EN", "start_pos": 200, "end_pos": 205, "type": "DATASET", "confidence": 0.6750814914703369}]}, {"text": "Overall, phrase-level paraphrasing (PPT:*) performs a bit better than word-level paraphrasing, and they are both outperformed by the text rewriting decoder (DD:*).", "labels": [], "entities": []}, {"text": "Finally, system combination with MEMT yields even further gains.", "labels": [], "entities": [{"text": "MEMT", "start_pos": 33, "end_pos": 37, "type": "DATASET", "confidence": 0.564584493637085}]}, {"text": "These results are consistent with those for the isolated experiments.", "labels": [], "entities": []}, {"text": "The results for the baseline systems are shown in.", "labels": [], "entities": []}, {"text": "We can see that training on ML2EN instead of IN2EN yields over 4 points absolute drop in BLEU (Papineni et al.", "labels": [], "entities": [{"text": "IN2EN", "start_pos": 45, "end_pos": 50, "type": "METRIC", "confidence": 0.8765925765037537}, {"text": "BLEU", "start_pos": 89, "end_pos": 93, "type": "METRIC", "confidence": 0.9983162879943848}]}, {"text": "2002) score, even though ML2EN is about 10 times larger than IN2EN and both bitexts are from the same domain.", "labels": [], "entities": []}, {"text": "This confirms the existence of important differences between Malay and Indonesian.", "labels": [], "entities": []}, {"text": "Simple concatenation does not help, but balanced concatenation with repetitions improves by 1.12 BLEU points over IN2EN, which shows the importance of giving IN2EN a proper weight in the combined bitext.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 97, "end_pos": 101, "type": "METRIC", "confidence": 0.9996218681335449}, {"text": "IN2EN", "start_pos": 114, "end_pos": 119, "type": "METRIC", "confidence": 0.8625377416610718}]}, {"text": "This is further reconfirmed by the sophisticated phrase table combination, which yields an additional absolute gain of 0.31 BLEU points.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 124, "end_pos": 128, "type": "METRIC", "confidence": 0.9990847110748291}]}, {"text": "shows the results for the isolated experiments.", "labels": [], "entities": []}, {"text": "We can see that word-level paraphrasing (CN:*) improves by up to 5.56 and 1.39 BLEU points over the two baselines.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 79, "end_pos": 83, "type": "METRIC", "confidence": 0.9981374740600586}]}, {"text": "further shows that the optimal parameters for the word-level systems involve a very low probability cut-off, and a high number of n-best sentences.", "labels": [], "entities": []}, {"text": "This indicates that they are robust to noise, probably because bad source-side phrases are Isolated experiments.", "labels": [], "entities": []}, {"text": "The subscript shows the parameters found on IN2EN-dev and used for IN2EN-test.", "labels": [], "entities": [{"text": "IN2EN-dev", "start_pos": 44, "end_pos": 53, "type": "DATASET", "confidence": 0.933023989200592}, {"text": "IN2EN-test", "start_pos": 67, "end_pos": 77, "type": "DATASET", "confidence": 0.8872668147087097}]}, {"text": "The superscript shows the absolute test improvement over the ML2EN and the IN2EN baselines.", "labels": [], "entities": [{"text": "absolute test", "start_pos": 26, "end_pos": 39, "type": "METRIC", "confidence": 0.9620432257652283}, {"text": "ML2EN", "start_pos": 61, "end_pos": 66, "type": "DATASET", "confidence": 0.8237842321395874}]}, {"text": "Scores that are statistically significantly better than ML2EN and IN2EN (p < 0.01, Collins' sign test) are shown in bold and are underlined, respectively.", "labels": [], "entities": [{"text": "ML2EN", "start_pos": 56, "end_pos": 61, "type": "DATASET", "confidence": 0.5521222949028015}, {"text": "IN2EN", "start_pos": 66, "end_pos": 71, "type": "METRIC", "confidence": 0.9731926321983337}, {"text": "Collins' sign test)", "start_pos": 83, "end_pos": 102, "type": "METRIC", "confidence": 0.7065356373786926}]}, {"text": "The last line shows system combination results using MEMT.", "labels": [], "entities": [{"text": "MEMT", "start_pos": 53, "end_pos": 57, "type": "DATASET", "confidence": 0.7969709038734436}]}, {"text": "We asked a native Indonesian speaker who does not speak Malay to judge whether our \"Indonesian\" adaptations are more understandable to him than the original Malay input for 100 random sentences.", "labels": [], "entities": []}, {"text": "We used two extremes: the conservative CN:word,t=0 vs. CN:word +morph.", "labels": [], "entities": []}, {"text": "Because the latter is noisy, the top three choices were judged for it. shows that CN:word,t=0 is better/equal to the original 53%/31% of the time.", "labels": [], "entities": []}, {"text": "Thus, it is a very good step in the direction of turning Malay into Indonesian.", "labels": [], "entities": []}, {"text": "In contrast, CN:word +morph is typically worse than the original; moreover, those at rank 2 area bit better than those at rank 1; even compared to the best in top 3, the better:worse ratio is 45%:43%.", "labels": [], "entities": []}, {"text": "Still, this latter model works better, which means that phrase-based SMT systems are robust to noise and prefer more variety rather than better translations in the training bitext.", "labels": [], "entities": [{"text": "SMT", "start_pos": 69, "end_pos": 72, "type": "TASK", "confidence": 0.8050075173377991}]}, {"text": "That is, humans usually like high precision, whereas what the downstream SMT system really needs should be high recall.", "labels": [], "entities": [{"text": "precision", "start_pos": 34, "end_pos": 43, "type": "METRIC", "confidence": 0.9968910813331604}, {"text": "SMT", "start_pos": 73, "end_pos": 76, "type": "TASK", "confidence": 0.9832069873809814}, {"text": "recall", "start_pos": 112, "end_pos": 118, "type": "METRIC", "confidence": 0.9987180233001709}]}, {"text": "Note also that the judgments were at the sentence level, although phrases are sub-sentential, that is, there can be many good phrases to be extracted from a \"bad\" sentence.", "labels": [], "entities": []}, {"text": "For example, CN:word +morph adapted perisian navigasi kereta 3D di pasaran Malaysia menjelang akhir tahun ('3D car navigation software hits Malaysia by year-end') to the following three versions (changes are underlined): r pertama kali mobil 3D di pasar Malaysia pada akhir tahun r lunak navigasi mobil 3D di pasar Malaysia pada akhir tahun r perangkat navigasi mobil 3D di pasar Malaysia pada akhir tahun All three converted manjelang ('by') to pada ('at'), which is not needed, as manjelang is also an Indonesian word.", "labels": [], "entities": [{"text": "3D car navigation software", "start_pos": 108, "end_pos": 134, "type": "TASK", "confidence": 0.8006100207567215}]}, {"text": "Our human translator did not like the first two versions, but liked the last one better, compared to the original Malay sentence.", "labels": [], "entities": []}, {"text": "The first two versions did not adapt perisian ('software') correctly, but all three successfully adapted kereta to mobil ('car'), and also pasaran to pasar ('market'), which would encourage good phrase pairs in the phrase table extracted from the adapted bitext.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1  Cosine similarities between some pairs of languages, calculated on the Universal Declaration of  Human Rights using tokens and filtering out punctuation symbols.", "labels": [], "entities": [{"text": "Universal Declaration of  Human Rights", "start_pos": 81, "end_pos": 119, "type": "DATASET", "confidence": 0.9555231928825378}]}, {"text": " Table 3  The five baselines. The subscript indicates the parameters found on IN2EN-dev and used  for IN2EN-test. The scores that are statistically significantly better than ML2EN and IN2EN  (p < 0.01, Collins' sign test) are shown in bold and are underlined, respectively.", "labels": [], "entities": [{"text": "IN2EN-dev", "start_pos": 78, "end_pos": 87, "type": "DATASET", "confidence": 0.9231985807418823}, {"text": "Collins' sign test)", "start_pos": 202, "end_pos": 221, "type": "METRIC", "confidence": 0.6105468422174454}]}, {"text": " Table 4  Isolated experiments. The subscript shows the parameters found on IN2EN-dev and used for  IN2EN-test. The superscript shows the absolute test improvement over the ML2EN and the  IN2EN baselines. Scores that are statistically significantly better than ML2EN and IN2EN  (p < 0.01, Collins' sign test) are shown in bold and are underlined, respectively. The last line  shows system combination results using MEMT.", "labels": [], "entities": [{"text": "MEMT", "start_pos": 415, "end_pos": 419, "type": "DATASET", "confidence": 0.6607812643051147}]}, {"text": " Table 6  Paraphrasing non-Indonesian words only: those appearing at most t times in IN-LM.  The subscript indicates the parameters found on IN2EN-dev and used for IN2EN-test.", "labels": [], "entities": [{"text": "IN2EN-dev", "start_pos": 141, "end_pos": 150, "type": "DATASET", "confidence": 0.8974654078483582}]}, {"text": " Table 7  Human judgments: Malay versus adapted \"Indonesian.\" A subscript shows the ranking of the  sentences, and the parameter values are those from Tables 4 and 6.", "labels": [], "entities": []}, {"text": " Table 9  Improving Macedonian-English SMT by adapting Bulgarian to Macedonian. The BLEU scores  that are significantly better (p < 0.01) than BG2EN and MK2EN are in bold and underlined,  respectively. The last line shows system combination results using MEMT.", "labels": [], "entities": [{"text": "SMT", "start_pos": 39, "end_pos": 42, "type": "TASK", "confidence": 0.7587890028953552}, {"text": "BLEU", "start_pos": 84, "end_pos": 88, "type": "METRIC", "confidence": 0.9993963241577148}, {"text": "BG2EN", "start_pos": 143, "end_pos": 148, "type": "METRIC", "confidence": 0.9413544535636902}]}, {"text": " Table 10  Isolated experiments with readability features, TTR and OVIX. The subscript indicates the  parameters found on IN2EN-dev and used for IN2EN-test. The scores that are statistically  significantly better than ML2EN and IN2EN (p < 0.01, Collins' sign test) are shown in bold and  are underlined, respectively.", "labels": [], "entities": [{"text": "TTR", "start_pos": 59, "end_pos": 62, "type": "METRIC", "confidence": 0.8832768201828003}, {"text": "OVIX", "start_pos": 67, "end_pos": 71, "type": "METRIC", "confidence": 0.7653969526290894}, {"text": "Collins' sign test", "start_pos": 245, "end_pos": 263, "type": "DATASET", "confidence": 0.66898845632871}]}, {"text": " Table 4. The results are shown in", "labels": [], "entities": []}]}