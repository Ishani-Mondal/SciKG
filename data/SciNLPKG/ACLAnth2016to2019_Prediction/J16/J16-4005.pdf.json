{"title": [{"text": "Integrating Type Theory and Distributional Semantics: A Case Study on Adjective-Noun Compositions", "labels": [], "entities": [{"text": "Integrating Type Theory", "start_pos": 0, "end_pos": 23, "type": "TASK", "confidence": 0.7489351232846578}, {"text": "Adjective-Noun Compositions", "start_pos": 70, "end_pos": 97, "type": "TASK", "confidence": 0.7278642058372498}]}], "abstractContent": [{"text": "CNRS In this article, we explore an integration of a formal semantic approach to lexical meaning and an approach based on distributional methods.", "labels": [], "entities": [{"text": "CNRS", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.9766518473625183}]}, {"text": "First, we outline a formal semantic theory that aims to combine the virtues of both formal and distributional frameworks.", "labels": [], "entities": []}, {"text": "We then proceed to develop an algebraic interpretation of that formal semantic theory and show how at least two kinds of distributional models make this interpretation concrete.", "labels": [], "entities": []}, {"text": "Focusing on the case of adjective-noun composition, we compare several distributional models with respect to the semantic information that a formal semantic theory would need, and we show how to integrate the information provided by distributional models back into the formal semantic framework.", "labels": [], "entities": []}], "introductionContent": [{"text": "Formal semantics (FS) has provided insightful models of composition and recently has addressed issues of how composition may in turn affect the original meanings of lexical items).", "labels": [], "entities": [{"text": "Formal semantics (FS)", "start_pos": 0, "end_pos": 21, "type": "TASK", "confidence": 0.7321952700614929}]}, {"text": "Type Composition Logic (TCL; Asher 2011) provides a detailed formal model of the interaction between composition and lexical meaning in which the composition of two words wand w \ud97b\udf59 may shift the original meanings of wand w \ud97b\udf59 . For example, consider the case of an adjective like heavy and a noun like traffic.", "labels": [], "entities": [{"text": "Type Composition Logic (TCL; Asher 2011", "start_pos": 0, "end_pos": 39, "type": "TASK", "confidence": 0.7904358319938183}]}, {"text": "TCL assigns a logical form to the adjective-noun combination heavy traffic, \u03bbx.(O(heavy)(x) \u2227 M(traffic)(x)), where O is a functor induced by the noun that outputs a meaning paraphrased as heavy for traffic.", "labels": [], "entities": []}, {"text": "The M functor does something similar for the noun.", "labels": [], "entities": []}, {"text": "Different types of adjectives will interact differently with the meaning of the noun; for example, non-subsective adjectives like fake in fake dollar bill output a meaning whose denotation has an empty intersection with the denotation of the original noun but shares surface properties with things that are (e.g., dollar bills).", "labels": [], "entities": []}, {"text": "TCL thus decomposes an adjective-noun combination into a conjunction of two properties representing the contextual contributions of the noun and adjective.", "labels": [], "entities": []}, {"text": "This decomposition property allows TCL to predict non-trivial logical entailments just from the form of adjective-noun compositions (in contrast to Montague's higher order approach, which requires meaning postulates), while also capturing the shiftiness of lexical meaning, something that most formal semantic theories do not consider.", "labels": [], "entities": [{"text": "TCL", "start_pos": 35, "end_pos": 38, "type": "TASK", "confidence": 0.9152601361274719}]}, {"text": "However, neither TCL nor the other FS theories mentioned provide a method for constructing such functors or lexical meanings.", "labels": [], "entities": []}, {"text": "In this article we develop two distributional semantic (DS) models able to provide such a method, in virtue of (i) TCL's distinction between internal or conceptual content and external or referential content and (ii) the close correspondence between the way TCL and these models treat compositionin particular, the fact that these models share with TCL the decomposition property we just mentioned.", "labels": [], "entities": []}, {"text": "We show that such methods can furnish the appropriate TCL functors, provided we take one big step: We identify TCL's internal content with vectors, which distributional methods use to represent word meaning.", "labels": [], "entities": []}, {"text": "Functors introduced by TCL for composition then correspond to vector transformations within distributional models.", "labels": [], "entities": []}, {"text": "We also show how to translate the results of these transformations back into TCL logical forms.", "labels": [], "entities": []}, {"text": "TCL logical forms will then entail non-trivial inferences based on DS lexical information, while keeping the structural and conceptual advantages of a FS based logical form.", "labels": [], "entities": []}, {"text": "We illustrate our approach with adjective-noun compositions because they are simpler and better understood than other compositions.", "labels": [], "entities": []}, {"text": "Such compositions do not typically introduce scope-bearing elements like quantifiers, unlike the construction of verb phrases, for instance.", "labels": [], "entities": []}, {"text": "Also, the range of variation in adjective-noun composition is better understood, than, say, the effects of composition in verbal predications, which also involve more parameters that can potentially affect the composition.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1  Accuracy results for subsectivity and intersectivity.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.998237133026123}]}, {"text": " Table 2  Accuracy results for entailment. ent 1 looks at the top most similar word, and ent 10 looks at the  top 10 most similar words.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9968942403793335}]}, {"text": " Table 3  Accuracy results for semantic relations (sr) and entailment. Results are presented for both the  top most similar word, and the top 10 most similar words. ent+sr combines both entailments  and semantically related words.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9973406195640564}]}]}