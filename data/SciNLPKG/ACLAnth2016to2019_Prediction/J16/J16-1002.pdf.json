{"title": [{"text": "Integrating Selectional Constraints and Subcategorization Frames in a Dependency Parser", "labels": [], "entities": []}], "abstractContent": [{"text": "Statistical parsers are trained on treebanks that are composed of a few thousand sentences.", "labels": [], "entities": []}, {"text": "In order to prevent data sparseness and computational complexity, such parsers make strong independence hypotheses on the decisions that are made to build a syntactic tree.", "labels": [], "entities": []}, {"text": "These independence hypotheses yield a decomposition of the syntactic structures into small pieces, which in turn prevent the parser from adequately modeling many lexico-syntactic phenomena like selectional constraints and subcategorization frames.", "labels": [], "entities": []}, {"text": "Additionally, treebanks are several orders of magnitude too small to observe many lexico-syntactic regularities, such as selectional constraints and subcategorization frames.", "labels": [], "entities": []}, {"text": "In this article, we propose a solution to both problems: how to account for patterns that exceed the size of the pieces that are modeled in the parser and how to obtain subcategorization frames and selectional constraints from raw corpora and incorporate them in the parsing process.", "labels": [], "entities": []}, {"text": "The method proposed was evaluated on French and on English.", "labels": [], "entities": []}, {"text": "The experiments on French showed a decrease of 41.6% of selectional constraint violations and a decrease of 22% of erroneous subcategorization frame assignment.", "labels": [], "entities": []}, {"text": "These figures are lower for English: 16.21% in the first case and 8.83% in the second.", "labels": [], "entities": []}], "introductionContent": [{"text": "The fundamental problem we address in this article was formulated by as the following question: How much context-sensitivity is required to provide reasonable structural descriptions?", "labels": [], "entities": []}, {"text": "His answer to this question was the extended domain of locality principle of Tree Adjoining Grammars, which allows us to represent in a single structure (an elementary tree 1 ) a predicate and its arguments.", "labels": [], "entities": []}, {"text": "Context sensitivity and the correct size of domain of locality fora reasonable structural description has always been a major issue for syntactic formalisms and parsers.", "labels": [], "entities": [{"text": "Context sensitivity", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.6949836164712906}]}, {"text": "Giving an overview of the different solutions that have been proposed to answer this question is clearly beyond the scope of this article.", "labels": [], "entities": []}, {"text": "We will limit our discussion to the framework of graph-based dependency parsing), in which our study takes place.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 61, "end_pos": 79, "type": "TASK", "confidence": 0.7056086957454681}]}, {"text": "The basic first-order model makes an extreme choice with respect to the domain of locality by limiting it to one dependency (the score of a tree is the sum of the scores of its dependencies).", "labels": [], "entities": []}, {"text": "Second-order models slightly extend the factor sizes to second-order patterns that include a dependency adjacent to the target dependency.", "labels": [], "entities": []}, {"text": "It has been shown experimentally that second-order models perform better than first-order ones, which tends to prove that second-order factors do capture important syntactic regularities.", "labels": [], "entities": []}, {"text": "More recently, proposed extending factor size to three dependencies and showed that such models yield better accuracy than second-order models on the same data.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 109, "end_pos": 117, "type": "METRIC", "confidence": 0.9979971051216125}]}, {"text": "However, extending the order of the models has a high computational cost because the number of factors to be considered in a sentence grows exponentially with the order of the model.", "labels": [], "entities": []}, {"text": "Using such models in a Dynamic Programming framework, such as, becomes quickly intractable in terms of processing time and memory requirements.", "labels": [], "entities": []}, {"text": "Additionally, by reliably estimating the scores of such factors we are quickly confronted with the problem of data sparseness.", "labels": [], "entities": []}, {"text": "One can also note that high-order factors are not needed for all syntactic phenomena.", "labels": [], "entities": []}, {"text": "In fact, most syntactic attachments can be accurately described with first-and second-order models.", "labels": [], "entities": [{"text": "syntactic attachments", "start_pos": 14, "end_pos": 35, "type": "TASK", "confidence": 0.7354077696800232}]}, {"text": "This is why first-and second-order models perform quite well: They reach a labeled accuracy score of 85.36% and 88.88% for first-and second-order models, respectively, on the French Treebank.", "labels": [], "entities": [{"text": "labeled", "start_pos": 75, "end_pos": 82, "type": "METRIC", "confidence": 0.96714848279953}, {"text": "accuracy score", "start_pos": 83, "end_pos": 97, "type": "METRIC", "confidence": 0.9178215265274048}, {"text": "French Treebank", "start_pos": 175, "end_pos": 190, "type": "DATASET", "confidence": 0.9878821671009064}]}, {"text": "The same models trained on the Penn Treebank (Marcus, Marcinkiewicz, and Santorini 1993) reach 88.57% and 91.76% labeled accuracy score, respectively.", "labels": [], "entities": [{"text": "Penn Treebank", "start_pos": 31, "end_pos": 44, "type": "DATASET", "confidence": 0.9909481406211853}, {"text": "labeled", "start_pos": 113, "end_pos": 120, "type": "METRIC", "confidence": 0.9124357104301453}, {"text": "accuracy score", "start_pos": 121, "end_pos": 135, "type": "METRIC", "confidence": 0.930772066116333}]}, {"text": "The extension of the domain of locality can therefore be limited to some syntactic phenomena.", "labels": [], "entities": []}, {"text": "This is the casein Tree Adjoining Grammars for which the extended domain of locality only concerned some aspects of syntax, namely, subcategorization.", "labels": [], "entities": []}, {"text": "The solution we explore in this article, in order to take high-order factors into account in a parser, is to decompose the parsing process into two sub-processes.", "labels": [], "entities": []}, {"text": "One of them is in charge of local syntactic phenomena and does not need a highorder model and the other takes care of syntactic phenomena that are beyond the scope of the first one.", "labels": [], "entities": []}, {"text": "We will call the first one parsing and the second one patching.", "labels": [], "entities": [{"text": "parsing", "start_pos": 27, "end_pos": 34, "type": "TASK", "confidence": 0.974636435508728}]}, {"text": "The patching process is responsible for modeling two important aspects of syntax, Selectional Constraints (SCs) and Subcategorization Frames (SFs), which are usually poorly modeled in parsers, as we will show in Sections 7 and 8.", "labels": [], "entities": []}, {"text": "Parsing and patching differ in two important aspects.", "labels": [], "entities": [{"text": "Parsing", "start_pos": 0, "end_pos": 7, "type": "TASK", "confidence": 0.9472434520721436}, {"text": "patching", "start_pos": 12, "end_pos": 20, "type": "TASK", "confidence": 0.7575204372406006}]}, {"text": "First, they rely on different search algorithms.", "labels": [], "entities": []}, {"text": "The first one is based on Dynamic Programming and the other one uses Integer Linear Programming (ILP).", "labels": [], "entities": []}, {"text": "Second, they rely on different data sets.", "labels": [], "entities": []}, {"text": "The first uses a standard treebank whereas the second uses much larger unannotated corpora.", "labels": [], "entities": []}, {"text": "The reason for the first difference comes from the different nature of these two processes.", "labels": [], "entities": []}, {"text": "As already mentioned, high-order factors are needed to model some specific syntactic phenomena and we do not want to systematically increase the order of the model in order to take them into account.", "labels": [], "entities": []}, {"text": "Using factors of different sizes in a Dynamic Programming parser is not practical and leads toad hoc adaptation of the parser.", "labels": [], "entities": []}, {"text": "This is the reason why patching is based on ILP, which can accommodate more naturally for constraints defined on structures of different sizes.", "labels": [], "entities": []}, {"text": "The second difference between parsing and patching is the data sets that were used to train them.", "labels": [], "entities": [{"text": "parsing", "start_pos": 30, "end_pos": 37, "type": "TASK", "confidence": 0.9700405597686768}]}, {"text": "The parser is trained on a standard treebank whereas the patching model is trained on a raw corpus that is several orders of magnitude larger.", "labels": [], "entities": []}, {"text": "The reason for this difference comes from the fact that high-order factors used to model SFs and SCs contain up to three lexical elements and cannot be accurately modeled using available treebanks.", "labels": [], "entities": []}, {"text": "It has been shown by and that bilexical dependencies of the Collins parser) have a very limited impact on the performances of the parser, although they were supposed to play a key role for some important ambiguous syntactic attachments.", "labels": [], "entities": [{"text": "Collins", "start_pos": 60, "end_pos": 67, "type": "DATASET", "confidence": 0.9403952956199646}]}, {"text": "The reason for this is that treebanks are not large enough to correctly model bilexical dependencies.", "labels": [], "entities": []}, {"text": "We show in Sections 7.2 and 8.2 that current treebanks are much too limited in size to accurately model SCs and SFs.", "labels": [], "entities": []}, {"text": "Other solutions have been proposed in the literature in order to combine local and global syntactic phenomena in a parser.", "labels": [], "entities": []}, {"text": "Parse reranking is one of them.", "labels": [], "entities": [{"text": "Parse reranking", "start_pos": 0, "end_pos": 15, "type": "TASK", "confidence": 0.8708760142326355}]}, {"text": "The idea is to produce the n-best parses fora sentence and rerank them using higher order features, such as in Collins and and.", "labels": [], "entities": [{"text": "Collins", "start_pos": 111, "end_pos": 118, "type": "DATASET", "confidence": 0.9514179229736328}]}, {"text": "This solution has the advantage of drastically limiting the search space of the high-order search algorithm to the k best parses.", "labels": [], "entities": []}, {"text": "Although the parsing architecture we propose in this article does use k-best parse lists, our solution allows us to combine dependencies that appear in any of the parses of the list.", "labels": [], "entities": []}, {"text": "We show in Section 6.3 that combining dependencies that appear in any parse of a k-best list can yield parses that are more accurate than the best parse of this k-best list.", "labels": [], "entities": []}, {"text": "Our method is closer to forest rescoring ( or forest reranking.", "labels": [], "entities": []}, {"text": "Another solution to combine local and global decisions is to represent the local and the global constraints as a single ILP program.", "labels": [], "entities": []}, {"text": "This solution is possible because dependency parsing can be framed as an ILP program.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 34, "end_pos": 52, "type": "TASK", "confidence": 0.8405857980251312}]}, {"text": "propose a formulation of nonprojective dependency parsing as an ILP program.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 39, "end_pos": 57, "type": "TASK", "confidence": 0.6991226375102997}]}, {"text": "This program, however, requires an exponential number of variables.", "labels": [], "entities": []}, {"text": "propose a more concise formulation that only requires a polynomial number of variables and constraints.", "labels": [], "entities": []}, {"text": "propose extending the model to third-order factors and using dual decomposition.", "labels": [], "entities": []}, {"text": "All these approaches have in common their ability to produce nonprojective structures.", "labels": [], "entities": []}, {"text": "Our work departs from these approaches in that it uses a dynamic programming parser combined with an ILP solver.", "labels": [], "entities": []}, {"text": "Additionally, we do not take nonprojective structures into account.", "labels": [], "entities": []}, {"text": "The structure of this article is as follows.", "labels": [], "entities": []}, {"text": "In Section 2 we describe the type of parser used in this work.", "labels": [], "entities": []}, {"text": "Section 3 describes the patching process that detects, in a given sentence, a set of optimal SFs and SCs, using ILP.", "labels": [], "entities": []}, {"text": "The exact nature of SFs and SCs is described in that section.", "labels": [], "entities": []}, {"text": "Section 4 proposes away to combine the solutions produced by the two methods using constrained parsing.", "labels": [], "entities": []}, {"text": "In Section 5, we justify the use of ILP by showing that the patching process is actually NP-complete.", "labels": [], "entities": []}, {"text": "Sections 6, 7, and 8 constitute the experimental part of this work.", "labels": [], "entities": []}, {"text": "Section 6 describes the experimental set-up, and Sections 7 and 8, respectively, give results obtained on French and English.", "labels": [], "entities": []}, {"text": "Section 9 concludes the article.", "labels": [], "entities": []}, {"text": "The material presented in this article has been partially published in and, a method for taking into account selectional constraints in a parser is presented, and in a method of introducing subcategorization frames in the parser is described.", "labels": [], "entities": []}, {"text": "This paper proposes a general framework for dealing with these two problems, both separately and jointly, using Integer Linear Programming, whereas the two previous techniques used ad hoc adaptations and could not treat the two problems jointly.", "labels": [], "entities": []}, {"text": "Additionally, we extended the experimental part of our work to English, whereas previous work only concerned French.", "labels": [], "entities": []}], "datasetContent": [{"text": "We describe in this section and the two following ones the experimental part of this work.", "labels": [], "entities": []}, {"text": "This section concerns language-independent aspects of the experimental set-up and Sections 7 and 8 describe the experiments and results obtained, respectively, on French and English data.", "labels": [], "entities": []}, {"text": "The complete experiments involve two offline and three online processes.", "labels": [], "entities": []}, {"text": "The offline processes are:  We describe in this section the experiments performed on French and the results obtained.", "labels": [], "entities": [{"text": "French", "start_pos": 85, "end_pos": 91, "type": "DATASET", "confidence": 0.9505172967910767}]}, {"text": "We start, in Section 7.1, with the description of the data used to train the parser and give an overview of the errors made by the parser.", "labels": [], "entities": []}, {"text": "The extraction of SCs and SFs from raw corpora is described in Section 7.2, which starts with the description of the corpora that were used, then gives general statistics and coverage results for the extracted data.", "labels": [], "entities": [{"text": "coverage", "start_pos": 175, "end_pos": 183, "type": "METRIC", "confidence": 0.9776736497879028}]}, {"text": "The results of patching and parsing are given in Section 7.3 and an analysis of the errors is presented in Section 7.4.", "labels": [], "entities": [{"text": "parsing", "start_pos": 28, "end_pos": 35, "type": "TASK", "confidence": 0.9613176584243774}]}, {"text": "Section 7.5 analyzes the runtime performances.", "labels": [], "entities": []}, {"text": "A second series of experiments was performed on English.", "labels": [], "entities": [{"text": "English", "start_pos": 48, "end_pos": 55, "type": "DATASET", "confidence": 0.949717104434967}]}, {"text": "Although the setting used is almost the same as for French, there are some notable differences between the two series of experiments with respect to the data used: r The treebank used for training the parser is significantly larger.", "labels": [], "entities": []}, {"text": "r The definition of SC and SF patterns is different.", "labels": [], "entities": []}, {"text": "r The raw corpus used to extract ISCs and ISFs is one order of magnitude larger.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1  Decomposition of the French Treebank into training, development, and test sets.", "labels": [], "entities": [{"text": "French Treebank", "start_pos": 31, "end_pos": 46, "type": "DATASET", "confidence": 0.9934345781803131}]}, {"text": " Table 3.  The raw corpora were first tokenized, POS-tagged, and lemmatized with the  MACAON tool suite (", "labels": [], "entities": []}, {"text": " Table 3  Some statistics computed on the corpora used to collect Subcategorization Frames and  Selectional Constraints.", "labels": [], "entities": []}, {"text": " Table 4  Number of verbal lemmas, SFs, and average number of SFs per verb for three levels of  thresholding (0, 5, and 10).", "labels": [], "entities": [{"text": "SFs", "start_pos": 35, "end_pos": 38, "type": "METRIC", "confidence": 0.9101452827453613}, {"text": "average number of SFs", "start_pos": 44, "end_pos": 65, "type": "METRIC", "confidence": 0.9287616461515427}]}, {"text": " Table 5  Lexical and syntactic coverage on FTB DEV of the extracted SFs. Coverage is computed for three  thresholding levels of the automatically generated resource (A 0 , A 5 , and A 10 ) and FTB TRAIN (T).", "labels": [], "entities": [{"text": "FTB DEV", "start_pos": 44, "end_pos": 51, "type": "DATASET", "confidence": 0.9156879484653473}, {"text": "Coverage", "start_pos": 74, "end_pos": 82, "type": "METRIC", "confidence": 0.9331145882606506}, {"text": "FTB", "start_pos": 194, "end_pos": 197, "type": "DATASET", "confidence": 0.7623404264450073}, {"text": "TRAIN", "start_pos": 198, "end_pos": 203, "type": "METRIC", "confidence": 0.908222496509552}]}, {"text": " Table 6  Number of occurrences of the four SC patterns (OBJ, SBJ, VdeN, and VaN) in raw corpora with  three levels of thresholding (0, 5, and 10).", "labels": [], "entities": []}, {"text": " Table 7  Coverage for the four SC configurations (OBJ, SBJ, VdeN, VaN). Coverage is computed for three  thresholding levels of the automatically generated resource (A 0 , A 5 , and A 10 ) and FTB TRAIN (T).", "labels": [], "entities": [{"text": "FTB TRAIN (T)", "start_pos": 193, "end_pos": 206, "type": "METRIC", "confidence": 0.8597161650657654}]}, {"text": " Table 8  Four measures of accuracy on FTB TEST for four settings: Baseline second-order parser, patching  with confidence measure, patching with SF only, patching with SCs only, and patching with SFs  and SCs.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 27, "end_pos": 35, "type": "METRIC", "confidence": 0.9991804957389832}, {"text": "FTB TEST", "start_pos": 39, "end_pos": 47, "type": "DATASET", "confidence": 0.7944979667663574}]}, {"text": " Table 9  Raw number of errors, error decrease, and error distribution for each SC pattern, average of SC  patterns, and SFs.", "labels": [], "entities": [{"text": "Raw number of errors", "start_pos": 10, "end_pos": 30, "type": "METRIC", "confidence": 0.9248479008674622}, {"text": "error decrease", "start_pos": 32, "end_pos": 46, "type": "METRIC", "confidence": 0.8893891274929047}, {"text": "error distribution", "start_pos": 52, "end_pos": 70, "type": "METRIC", "confidence": 0.8964568078517914}, {"text": "SFs", "start_pos": 121, "end_pos": 124, "type": "METRIC", "confidence": 0.9769312739372253}]}, {"text": " Table 10  Decomposition of the Penn Treebank into training, development, and test sets.", "labels": [], "entities": [{"text": "Penn Treebank", "start_pos": 32, "end_pos": 45, "type": "DATASET", "confidence": 0.9951966404914856}]}, {"text": " Table 10. The main  difference with respect to French comes from the training set, which is 2.44 times larger.  As could be expected, the parser trained and evaluated on the Penn Treebank yields  better results than the same parser trained on the French Treebank. The LAS is 91.76 and  UAS is 93.75, a relative increase of 3.24% and 3.35% with respect to French.", "labels": [], "entities": [{"text": "Penn Treebank", "start_pos": 175, "end_pos": 188, "type": "DATASET", "confidence": 0.9955137073993683}, {"text": "French Treebank", "start_pos": 248, "end_pos": 263, "type": "DATASET", "confidence": 0.9884184896945953}, {"text": "LAS", "start_pos": 269, "end_pos": 272, "type": "METRIC", "confidence": 0.9979948997497559}, {"text": "UAS", "start_pos": 287, "end_pos": 290, "type": "METRIC", "confidence": 0.9761233925819397}]}, {"text": " Table 11  Contribution of the 20 SC patterns to the errors made by the parser. For each pattern, we  displayed its frequency, the parser accuracy, and the impact on global errors.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 138, "end_pos": 146, "type": "METRIC", "confidence": 0.9926797151565552}]}, {"text": " Table 12  Some statistics computed on the corpora used to collect Subcategorization Frames and  Selectional Constraints.", "labels": [], "entities": []}, {"text": " Table 13  Number of occurrences of the 20 SC patterns in the GIGA corpus with three levels of  thresholding (0, 5, and 10).", "labels": [], "entities": [{"text": "GIGA corpus", "start_pos": 62, "end_pos": 73, "type": "DATASET", "confidence": 0.9445509910583496}]}, {"text": " Table 14  Number of verbal lemmas, SFs, and average number of SFs per verb for three levels of  thresholding (0, 5, and 10).", "labels": [], "entities": [{"text": "SFs", "start_pos": 36, "end_pos": 39, "type": "METRIC", "confidence": 0.9100651144981384}, {"text": "average number of SFs", "start_pos": 45, "end_pos": 66, "type": "METRIC", "confidence": 0.9322540163993835}]}, {"text": " Table 15  Coverage for the 20 SC patterns on PTB DEV. Coverage is computed for three thresholding levels  of the automatically generated resource (A 0 , A 5 , and A 10 ) and PTB TRAIN (T).", "labels": [], "entities": [{"text": "PTB DEV", "start_pos": 46, "end_pos": 53, "type": "DATASET", "confidence": 0.9409474730491638}, {"text": "PTB", "start_pos": 175, "end_pos": 178, "type": "DATASET", "confidence": 0.811765193939209}, {"text": "TRAIN", "start_pos": 179, "end_pos": 184, "type": "METRIC", "confidence": 0.7693862318992615}]}, {"text": " Table 17. The table shows that the Oracle accuracy of 100 best parses for a first-order  parser is often below the accuracy of the first-best parse for a second-order parser. The  situation is slightly more favorable for k = 200 but is still dominated for some SCs by  the first-best second-order accuracy. This is the reason why we decided to use a second- order parser in the candidate generation step. The rest of the process is unchanged.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 43, "end_pos": 51, "type": "METRIC", "confidence": 0.8496934771537781}, {"text": "accuracy", "start_pos": 116, "end_pos": 124, "type": "METRIC", "confidence": 0.9821121692657471}]}, {"text": " Table 19  Raw number of errors, error decrease, and error distribution for each SC pattern, average of SC  patterns, and SF.", "labels": [], "entities": [{"text": "Raw number of errors", "start_pos": 11, "end_pos": 31, "type": "METRIC", "confidence": 0.9390999376773834}, {"text": "error decrease", "start_pos": 33, "end_pos": 47, "type": "METRIC", "confidence": 0.8917818069458008}, {"text": "error distribution", "start_pos": 53, "end_pos": 71, "type": "METRIC", "confidence": 0.8972298204898834}, {"text": "SF", "start_pos": 122, "end_pos": 124, "type": "METRIC", "confidence": 0.9985584616661072}]}]}