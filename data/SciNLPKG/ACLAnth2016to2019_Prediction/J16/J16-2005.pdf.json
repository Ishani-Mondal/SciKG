{"title": [{"text": "Mining Parallel Corpora from Sina Weibo and Twitter", "labels": [], "entities": [{"text": "Mining Parallel Corpora from Sina Weibo", "start_pos": 0, "end_pos": 39, "type": "DATASET", "confidence": 0.8583111464977264}]}], "abstractContent": [{"text": "Microblogs such as Twitter, Facebook, and Sina Weibo (China's equivalent of Twitter) area remarkable linguistic resource.", "labels": [], "entities": []}, {"text": "In contrast to content from edited genres such as newswire, microblogs contain discussions of virtually every topic by numerous individuals in different languages and dialects and in different styles.", "labels": [], "entities": []}, {"text": "In this work, we show that some microblog users post \"self-translated\" messages targeting audiences who speak different languages, either by writing the same message in multiple languages or by retweeting translations of their original posts in a second language.", "labels": [], "entities": []}, {"text": "We introduce a method for finding and extracting this naturally occurring parallel data.", "labels": [], "entities": []}, {"text": "Identifying the parallel content requires solving an alignment problem, and we give an optimally efficient dynamic programming algorithm for this.", "labels": [], "entities": []}, {"text": "Using our method, we extract nearly 3M Chinese-English parallel segments from Sina Weibo using a targeted crawl of Weibo users who post in multiple languages.", "labels": [], "entities": [{"text": "Chinese-English parallel segments from Sina Weibo", "start_pos": 39, "end_pos": 88, "type": "DATASET", "confidence": 0.6449078768491745}]}, {"text": "Additionally, from a random sample of Twitter, we obtain substantial amounts of parallel data in multiple language pairs.", "labels": [], "entities": []}, {"text": "Evaluation is performed by assessing the accuracy of our extraction approach relative to a manual annotation as well as *", "labels": [], "entities": [{"text": "accuracy", "start_pos": 41, "end_pos": 49, "type": "METRIC", "confidence": 0.9995139837265015}]}], "introductionContent": [], "datasetContent": [{"text": "The goal of the IDA model is to find the most likely parallel segments[u, v], their languages l, r, and the alignments a.", "labels": [], "entities": []}, {"text": "We also define an evaluation metric that compares the predictions of our model with those obtained by manual annotation.", "labels": [], "entities": []}, {"text": "\u222a. The intersection between two segments \u2229, namely and, computes the number of tokens within the intersection of the intervals, as given by [max(a, a ), min(b, b )].", "labels": [], "entities": []}, {"text": "Similarly, the union between two segments ( \u222a) computes the number of tokens within the union of the intervals, given by [min(a, a ), max(b, b )].", "labels": [], "entities": []}, {"text": "One important aspect to consider is that the segments can span half words, which can happen if there is a missing space between a sentence pair boundary, such as uneasyBom, which contains the English word uneasy and the Portuguese word Bom.", "labels": [], "entities": []}, {"text": "To cope with this, we add the fractional count as the ratio between the number of characters that is included in the interval and total number of characters in the token.", "labels": [], "entities": []}, {"text": "Thus, the segment corresponding to uneasy in uneasyBom would correspond to two-thirds of a single word.", "labels": [], "entities": [{"text": "uneasyBom", "start_pos": 45, "end_pos": 54, "type": "DATASET", "confidence": 0.9414558410644531}]}, {"text": "A hypothetical segment [a h , b h ] with language l h is scored against the reference [a h , b h ] with language l r as: This score penalizes the hypothesis segment for each extra token not in the reference, as well as each token in the reference that is not in the hypothesis.", "labels": [], "entities": []}, {"text": "Furthermore, segments that differ in language will have a zero score.", "labels": [], "entities": []}, {"text": "Unlike our previous work, we decided not to evaluate the language pair detection as a separate task, as only a negligible number of spurious parallel sentences (less than 0.1%) are caused by a incorrect detection of the language pair.", "labels": [], "entities": [{"text": "language pair detection", "start_pos": 57, "end_pos": 80, "type": "TASK", "confidence": 0.650513768196106}]}, {"text": "The final score S IDA is computed as the harmonic mean between the segment scores of the parallel segments: We opt to compute the harmonic mean (as opposed to a arithmetic mean) because it emphasizes that both parallel segments must be accurate to obtain a high score.", "labels": [], "entities": []}, {"text": "This is because parallel segments are only useful when both sides are accurate on the span and language.", "labels": [], "entities": []}, {"text": "In this section, we describe the experiments performed to show the effectiveness of our proposed algorithm and the value of the data obtained.", "labels": [], "entities": []}, {"text": "There are three sets of experiments that are performed.", "labels": [], "entities": []}, {"text": "We evaluate the parallel data extraction process intrinsically by testing each of the three steps described in Section 4, and extrinsically by testing its utility when used as training data for MT systems.", "labels": [], "entities": [{"text": "data extraction", "start_pos": 25, "end_pos": 40, "type": "TASK", "confidence": 0.7583933770656586}, {"text": "MT", "start_pos": 194, "end_pos": 196, "type": "TASK", "confidence": 0.9871659874916077}]}, {"text": "We report on the experiments performed in each of the stages of the parallel data extraction process described in Section 4. 7.3.1 Filtering.", "labels": [], "entities": [{"text": "data extraction", "start_pos": 77, "end_pos": 92, "type": "TASK", "confidence": 0.7216404527425766}]}, {"text": "The filtering step (described in Section 4.1) attempts to filter out monolingual tweets, because these are sure to not contain parallel data.", "labels": [], "entities": []}, {"text": "Ideally, we would uniformly sample tweets and annotate them on whether they are multilingual.", "labels": [], "entities": []}, {"text": "However, this would require an extraordinary amount of effort to obtain a sample with a large number of multilingual tweets, as most tweets are monolingual.", "labels": [], "entities": []}, {"text": "Thus, we use a preexisting annotated data set from Twitter, where each word in the tweet was annotated with its language.", "labels": [], "entities": []}, {"text": "In this data set, there are 773 annotated samples from Twitter.", "labels": [], "entities": []}, {"text": "We filter these so that all tweets contain words in at least two different languages, resulting in 554 multilingual tweets.", "labels": [], "entities": []}, {"text": "From this data set, we define two splits.", "labels": [], "entities": []}, {"text": "The first one contains only the language pairs that we are extracting parallel data from in this work, which allows us to estimate the degree our algorithm is spuriously removing multilingual tweets in the filtering step.", "labels": [], "entities": []}, {"text": "In all, 291 tweets from the 554 were obtained according to this criteria.", "labels": [], "entities": []}, {"text": "The second subset is restricted to languages that use the Latin alphabet as these are more difficult to label correctly.", "labels": [], "entities": []}, {"text": "This subset contains 222 tweets.", "labels": [], "entities": []}, {"text": "Finally, to build a data set of monolingual tweets, we sample tweets from Twitter uniformly until we find 2,000 tweets that are monolingual.", "labels": [], "entities": []}, {"text": "These are then injected into the Twitter data set, and we compute the percentage of tweets that were labelled correctly from the different sets, using different thresholds for Equation.", "labels": [], "entities": [{"text": "Twitter data set", "start_pos": 33, "end_pos": 49, "type": "DATASET", "confidence": 0.8699731628100077}, {"text": "Equation", "start_pos": 176, "end_pos": 184, "type": "METRIC", "confidence": 0.9973132014274597}]}, {"text": "Results are shown in, where the plot line Multilingual represents the percentage of multilingual tweets from the full set of 554 tweets that were correctly labelled (y-axis) for different values for different thresholds (x-axis).", "labels": [], "entities": []}, {"text": "Plot lines Multilingual (Used Languages) and Multilingual (Latin) denote that percentage of correctly labelled multilingual tweets from the subsets created by restricting the 554 tweets to the used languages in this work for parallel data extraction and the set consisting of Latin languages, respectively.", "labels": [], "entities": [{"text": "parallel data extraction", "start_pos": 225, "end_pos": 249, "type": "TASK", "confidence": 0.6667224764823914}]}, {"text": "Finally, the plot line Monolingual represents the set of monolingual tweets that were correctly labelled.", "labels": [], "entities": []}, {"text": "We can observe that by simply removing the top 90% of word pairs, we can remove 67.8% of the monolingual tweets at the cost of losing 10-15% of the multilingual tweets at threshold 0.", "labels": [], "entities": []}, {"text": "When we start increasing the threshold, we observe a substancial improvement for the detection of monolingual tweets, at the cost of mislabelling multilingual tweets.", "labels": [], "entities": []}, {"text": "As expected,  In order to measure the impact of the extracted corpora, we perform an extrinsic experiment where we use the extracted data as training parallel sentences for existing MT systems.", "labels": [], "entities": [{"text": "MT", "start_pos": 182, "end_pos": 184, "type": "TASK", "confidence": 0.9730932712554932}]}, {"text": "We first perform an extensive test on the English-Chinese language pair, where we show that the extracted corpus contributes to improve the state-of-the-art Most probable words inferred using LDA in several topics from the parallel data extracted from Weibo.", "labels": [], "entities": []}, {"text": "Topic labels (in parentheses) were created manually for illustration purposes.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2  Description of the annotated data.", "labels": [], "entities": []}, {"text": " Table 3  Results for the location of the parallel segments over different data sets. The English Overlap and  Foreign Overlap columns illustrate the average of the overlaps of the automatically extracted  segments for the English and Foreign segments, respectively. The final score is computed as the  harmonic mean between the two previous overlaps, which is shown in the S IDA column.", "labels": [], "entities": []}, {"text": " Table 4  Results for the parallel data identification task over different data sets. The columns present the  identification results using an incremental set of features. Each cell contains the F-measure using  a given data set and set of features.", "labels": [], "entities": [{"text": "parallel data identification task", "start_pos": 26, "end_pos": 59, "type": "TASK", "confidence": 0.7439102381467819}, {"text": "F-measure", "start_pos": 195, "end_pos": 204, "type": "METRIC", "confidence": 0.9116819500923157}]}, {"text": " Table 6  BLEU scores for different data sets in different translation directions (left to right), broken out  with different training corpora (top to bottom).", "labels": [], "entities": [{"text": "BLEU", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9985490441322327}]}, {"text": " Table 8  Translation experiment results for different language pairs on the Twitter data. Each column  shows the MT results for a given source language into English. The Out-of-domain size and  In-domain size rows represent the number of sentence pairs in the in-domain and out-of-domain  training sets. The Out-of-domain and +In-domain rows show the BLEU scores for a set-up where  only the out-of-domain data was used and the same set-up after adding the in-domain data set,  respectively.", "labels": [], "entities": [{"text": "Twitter data", "start_pos": 77, "end_pos": 89, "type": "DATASET", "confidence": 0.7701492607593536}, {"text": "MT", "start_pos": 114, "end_pos": 116, "type": "TASK", "confidence": 0.9443449974060059}, {"text": "BLEU", "start_pos": 352, "end_pos": 356, "type": "METRIC", "confidence": 0.9993916749954224}]}]}