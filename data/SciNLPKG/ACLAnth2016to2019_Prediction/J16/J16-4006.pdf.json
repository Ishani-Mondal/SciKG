{"title": [{"text": "Aligning Packed Dependency Trees: A Theory of Composition for Distributional Semantics", "labels": [], "entities": [{"text": "Aligning Packed Dependency Trees", "start_pos": 0, "end_pos": 32, "type": "TASK", "confidence": 0.8842448741197586}]}], "abstractContent": [{"text": "We present anew framework for compositional distributional semantics in which the distribu-tional contexts of lexemes are expressed in terms of anchored packed dependency trees.", "labels": [], "entities": []}, {"text": "We show that these structures have the potential to capture the full sentential contexts of a lexeme and provide a uniform basis for the composition of distributional knowledge in away that captures both mutual disambiguation and generalization.", "labels": [], "entities": []}], "introductionContent": [{"text": "This article addresses a central unresolved issue in distributional semantics: how to model semantic composition.", "labels": [], "entities": []}, {"text": "Although there has recently been considerable interest in this problem, it remains unclear what distributional composition actually means.", "labels": [], "entities": []}, {"text": "Our view is that distributional composition is a matter of contextualizing the lexemes being composed.", "labels": [], "entities": []}, {"text": "This goes well beyond traditional word sense disambiguation, where each lexeme is assigned one of a fixed number of senses.", "labels": [], "entities": [{"text": "word sense disambiguation", "start_pos": 34, "end_pos": 59, "type": "TASK", "confidence": 0.6472268203894297}]}, {"text": "Our proposal is that composition involves deriving a fine-grained characterization of the distributional meaning of each lexeme in the phrase, where the meaning that is associated with each lexeme is bespoke to that particular context.", "labels": [], "entities": []}, {"text": "Distributional composition is, therefore, a matter of integrating the meaning of each of the lexemes in the phrase.", "labels": [], "entities": []}, {"text": "To achieve this we need a structure within which all of the lexemes' semantics can be overlaid.", "labels": [], "entities": []}, {"text": "Once this is done, the lexemes can collectively agree on the semantics of the phrase, and in so doing, determine the semantics that they have in the context of that phrase.", "labels": [], "entities": []}, {"text": "Our process of composition thus creates a single structure that encodes contextualized representations of every lexeme in the phrase.", "labels": [], "entities": []}, {"text": "The (uncontextualized) distributional knowledge of a lexeme is typically formed by aggregating distributional features across all uses of the lexeme found within the corpus, where distributional features arise from co-occurrences found in the corpus.", "labels": [], "entities": []}, {"text": "The distributional features of a lexeme are associated with weights that encode the strength of that feature.", "labels": [], "entities": []}, {"text": "Contextualization involves inferring adjustments to these weights to reflect the context in which the lexeme is being used.", "labels": [], "entities": []}, {"text": "The weights of distributional features that don't fit the context are reduced, while the weight of those features that are compatible with the context can be boosted.", "labels": [], "entities": []}, {"text": "As an example, consider how we contextualize the distributional features of the word wooden in the context of the phrase wooden floor.", "labels": [], "entities": []}, {"text": "The uncontextualized representation of wooden presumably includes distributional features associated with different uses, for example, The director fired the wooden actor and I sat on the wooden chair.", "labels": [], "entities": []}, {"text": "So, although we may have observed in a corpus that it is plausible for the adjective wooden to modify floor, table, toy, actor, and voice, in the specific context of the phrase wooden floor, we need to find away to down-weight the distributional features of being something that can modify actor and voice, while up-weighting the distributional features of being something that can modify table and toy.", "labels": [], "entities": []}, {"text": "In this example we considered so-called first-order distributional features; these involve a single dependency relation (e.g., an adjective modifying a noun).", "labels": [], "entities": []}, {"text": "Similar inferences can also be made with respect to distributional features that involve higherorder grammatical dependencies.", "labels": [], "entities": []}, {"text": "For example, suppose that we have observed that a noun that wooden modifies (e.g., actor) can be the direct object of the verb fired, as in The director fired the wooden actor.", "labels": [], "entities": []}, {"text": "We want this distributional feature of wooden to be downweighted in the distributional representation of wooden in the context of wooden table, since things made of wood do not typically lose their job.", "labels": [], "entities": []}, {"text": "In addition to specializing the distributional representation of wood to reflect the context wooden floor, the distributional representation of floor should also be refined, down-weighting distributional features arising in contexts such as Prices fell through the floor, while up-weighting distributional features arising in contexts such as I polished the concrete floor.", "labels": [], "entities": []}, {"text": "In our example, some of the distributional features of wooden-in particular, those to do with the noun that this sense of wooden could modify-are internal to the phrase wooden floor in the sense that they are alternatives to one of the words in the phrase.", "labels": [], "entities": []}, {"text": "Although it is specifically a floor that is wooden, our proposal is that the contextualized representation of wooden should recognize that it is plausible that nouns such as chair and toy could be modified by the particular sense of wooden that is being used.", "labels": [], "entities": []}, {"text": "The remaining distributional features are external to the phrase.", "labels": [], "entities": []}, {"text": "For example, the verb mop could bean external feature, because things that can be modified by wooden can be the direct object of mop.", "labels": [], "entities": []}, {"text": "The external features of wooden and floor with respect to the phrase wooden floor provide something akin to the traditional interpretation of the distributional semantics of the phrase, namely, a representation of those (external) contexts in which this phrase can occur.", "labels": [], "entities": []}, {"text": "Although internal features are, in a sense, inconsistent with the specific semantics of the phrase, they provide away to embellish the characterization of the distributional meaning of the lexemes in the phrase.", "labels": [], "entities": []}, {"text": "Recall that our goal is to infer a rich and finegrained representation of the contextualized distributional meaning of each of the lexemes in the phrase.", "labels": [], "entities": []}, {"text": "Having introduced the proposal that distributional composition should be viewed as a matter of contextualization, the question arises as to how to realize this conception.", "labels": [], "entities": []}, {"text": "Because each lexeme in the phrase needs to be able to contribute to the contextualization of the other lexemes in the phrase, we need to be able to align what we know about each of the lexeme's distributional features so that this can be achieved.", "labels": [], "entities": []}, {"text": "The problem is that the uncontextualized distributional knowledge associated with the different lexemes in the phrase take a different perspective on the feature space.", "labels": [], "entities": []}, {"text": "To overcome this we need to: (a) provide away of structuring the distributional feature space, which we do by typing distributional features with dependency paths; and (b) find away to systematically modify the perspective that each lexeme has on this structured feature space in such away that they are all aligned with one another.", "labels": [], "entities": []}, {"text": "Following, we use typed dependency relations as the bases for our distributional features, and following, we include higher-order dependency relations in this space.", "labels": [], "entities": []}, {"text": "However, in contrast to previous proposals, the higher-order dependency relations provides structure to the space that is crucial to our definition of composition.", "labels": [], "entities": []}, {"text": "Each co-occurrence associated with a lexeme such as wooden is typed by the path in the dependency tree that connects the lexeme wooden with the co-occurring lexeme (e.g., fired).", "labels": [], "entities": []}, {"text": "This allows us to encode a lexeme's distributional knowledge with a hierarchical structure that we call an Anchored Packed Dependency Tree (APT).", "labels": [], "entities": []}, {"text": "As we show, this data structure provides away for us to align the distributional knowledge of the lexemes that are being composed in such away that the inferences needed to achieve contextualization can be implemented.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section we consider some empirical evidence in support of APTs.", "labels": [], "entities": [{"text": "APTs", "start_pos": 66, "end_pos": 70, "type": "TASK", "confidence": 0.9785920977592468}]}, {"text": "First, we consider some of the different ways in which APTs can be instantiated.", "labels": [], "entities": [{"text": "APTs", "start_pos": 55, "end_pos": 59, "type": "TASK", "confidence": 0.9880330562591553}]}, {"text": "Second, we present a number of case studies showing the disambiguating effect of APT composition in adjective-noun composition.", "labels": [], "entities": [{"text": "APT composition", "start_pos": 81, "end_pos": 96, "type": "TASK", "confidence": 0.889962375164032}]}, {"text": "Finally, we evaluate the model using the phrase-based compositionality benchmarks of.", "labels": [], "entities": [{"text": "phrase-based compositionality", "start_pos": 41, "end_pos": 70, "type": "TASK", "confidence": 0.6374323815107346}]}, {"text": "The M&L2008 Data Set.", "labels": [], "entities": [{"text": "M&L2008 Data Set", "start_pos": 4, "end_pos": 20, "type": "DATASET", "confidence": 0.9650294065475464}]}, {"text": "The second experiment uses the M&L2008 data set, introduced by, which contains pairs of intransitive sensitives together with human judgments of similarity.", "labels": [], "entities": [{"text": "M&L2008 data set", "start_pos": 31, "end_pos": 47, "type": "DATASET", "confidence": 0.8630164265632629}]}, {"text": "The data set contains 120 unique subject, verb, landmark triples with a varying number of human judgments per item.", "labels": [], "entities": []}, {"text": "On average each triple is rated by 30 participants.", "labels": [], "entities": []}, {"text": "The task is to rate the similarity of the verb and the landmark given the potentially disambiguating context of the subject.", "labels": [], "entities": [{"text": "similarity", "start_pos": 24, "end_pos": 34, "type": "METRIC", "confidence": 0.9620891213417053}]}, {"text": "For example, in the context of the subject fire one might expect glowed to be close to burned but not close to beamed.", "labels": [], "entities": []}, {"text": "Conversely, in the context of the subject face one might expect glowed to be close to beamed and not close to burned.", "labels": [], "entities": []}, {"text": "This data set was used in the evaluations carried out by and.", "labels": [], "entities": []}, {"text": "These evaluations clearly follow the experimental procedure of Mitchell and Lapata and do not evaluate against mean scores.", "labels": [], "entities": []}, {"text": "Instead, separate points are created for each human annotator, as discussed in Section 5.3.1.", "labels": [], "entities": []}, {"text": "The multi-step regression algorithm of achieved \u03c1 = 0.23 on this data set.", "labels": [], "entities": [{"text": "\u03c1", "start_pos": 48, "end_pos": 49, "type": "METRIC", "confidence": 0.9519240856170654}]}, {"text": "In the evaluation of, the lexical function algorithm, which learns a matrix representation for each functor and defines composition as matrix-vector multiplication, was the best-performing compositional algorithm at this task.", "labels": [], "entities": []}, {"text": "With optimal parameter settings, it achieved around \u03c1 = 0.26.", "labels": [], "entities": [{"text": "\u03c1", "start_pos": 52, "end_pos": 53, "type": "METRIC", "confidence": 0.9897176027297974}]}, {"text": "In this evaluation, the full additive model of Guevara (2010) achieved \u03c1 < 0.05.", "labels": [], "entities": [{"text": "\u03c1", "start_pos": 71, "end_pos": 72, "type": "METRIC", "confidence": 0.9896837472915649}]}, {"text": "In order to make our results directly comparable with these previous evaluations, we used the same corpus to construct our APT lexicons, namely, the concat corpus described in Section 5.1.", "labels": [], "entities": []}, {"text": "Otherwise, the APT lexicon was constructed as described in Section 5.3.1.", "labels": [], "entities": [{"text": "APT lexicon", "start_pos": 15, "end_pos": 26, "type": "TASK", "confidence": 0.6520948708057404}]}, {"text": "As before, note that k = 1 in shifted PPMI is equivalent to not shifting PPMI.", "labels": [], "entities": []}, {"text": "We see that UNI is highly competitive with the optimized lexical function model that was the best performing model in the evaluation of.", "labels": [], "entities": [{"text": "UNI", "start_pos": 12, "end_pos": 15, "type": "DATASET", "confidence": 0.843695342540741}]}, {"text": "In that evaluation, the lexical function model achieved between 0.23 and 0.26, depending on the parameters used in dimensionality reduction.", "labels": [], "entities": []}, {"text": "Using vanilla PPMI, without any context distribution smoothing or shifting, UNI achieves \u03c1 = 0.20, which is less than INT . However, when using shifted PPMI as weights, the best result is 0.26.", "labels": [], "entities": [{"text": "INT", "start_pos": 118, "end_pos": 121, "type": "METRIC", "confidence": 0.933434009552002}]}, {"text": "The shifting of PPMI means that contexts need to be more surprising in order to be considered as features.", "labels": [], "entities": []}, {"text": "This makes sense when using an additive model such as UNI . We also see that at this task and using this corpus, INT performs relatively well.", "labels": [], "entities": [{"text": "INT", "start_pos": 113, "end_pos": 116, "type": "TASK", "confidence": 0.8859930634498596}]}, {"text": "Using vanilla PPMI, without any context distribution smoothing or shifting, it achieves \u03c1 = 0.23, which equals the performance of the multi-step regression algorithm of.", "labels": [], "entities": [{"text": "context distribution smoothing or shifting", "start_pos": 32, "end_pos": 74, "type": "TASK", "confidence": 0.6627936840057373}]}, {"text": "Here, however, shifting PPMI has a negative impact on performance.", "labels": [], "entities": []}, {"text": "This is largely because of the intersective nature of the composition Results on the M&L2008 data set.", "labels": [], "entities": [{"text": "M&L2008 data set", "start_pos": 85, "end_pos": 101, "type": "DATASET", "confidence": 0.9724085569381714}]}, {"text": "Values shown are Spearman's \u03c1. humans 0.40 operation-if shifting PPMI removes a feature from one of the unigram representations, it cannot be recovered during composition.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 5  Results on the M&L2010 data set using the M&L method of evaluation. Values shown are  Spearman's \u03c1.", "labels": [], "entities": [{"text": "M&L2010 data set", "start_pos": 25, "end_pos": 41, "type": "DATASET", "confidence": 0.9600917935371399}, {"text": "M&L", "start_pos": 52, "end_pos": 55, "type": "DATASET", "confidence": 0.84090789159139}, {"text": "Spearman's \u03c1", "start_pos": 96, "end_pos": 108, "type": "METRIC", "confidence": 0.7667724092801412}]}, {"text": " Table 6  Results on the M&L2008 data set. Values shown are Spearman's \u03c1.", "labels": [], "entities": [{"text": "M&L2008 data set", "start_pos": 25, "end_pos": 41, "type": "DATASET", "confidence": 0.9240304589271545}, {"text": "Spearman's \u03c1", "start_pos": 60, "end_pos": 72, "type": "METRIC", "confidence": 0.7411982814470927}]}]}