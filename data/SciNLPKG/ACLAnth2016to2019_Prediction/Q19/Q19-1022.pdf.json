{"title": [{"text": "Syntax-aware Semantic Role Labeling without Parsing", "labels": [], "entities": [{"text": "Syntax-aware Semantic Role Labeling", "start_pos": 0, "end_pos": 35, "type": "TASK", "confidence": 0.6815738081932068}, {"text": "Parsing", "start_pos": 44, "end_pos": 51, "type": "TASK", "confidence": 0.6550061702728271}]}], "abstractContent": [{"text": "In this paper we focus on learning dependency aware representations for semantic role labeling without recourse to an external parser.", "labels": [], "entities": [{"text": "semantic role labeling", "start_pos": 72, "end_pos": 94, "type": "TASK", "confidence": 0.6851622859636942}]}, {"text": "The backbone of our model is an LSTM-based semantic role labeler jointly trained with two auxiliary tasks: predicting the dependency label of a word and whether there exists an arc linking it to the predicate.", "labels": [], "entities": [{"text": "LSTM-based semantic role labeler", "start_pos": 32, "end_pos": 64, "type": "TASK", "confidence": 0.7199323624372482}, {"text": "predicting the dependency label of a word", "start_pos": 107, "end_pos": 148, "type": "TASK", "confidence": 0.869272129876273}]}, {"text": "The auxiliary tasks provide syntactic information that is specific to semantic role labeling and are learned from training data (dependency annotations) without relying on existing dependency parsers, which can be noisy (e.g., on out-of-domain data or infrequent constructions).", "labels": [], "entities": [{"text": "semantic role labeling", "start_pos": 70, "end_pos": 92, "type": "TASK", "confidence": 0.6358825067679087}]}, {"text": "Experimental results on the CoNLL-2009 benchmark dataset show that our model outperforms the state of the art in English, and consistently improves performance in other languages, including Chinese, German, and Spanish.", "labels": [], "entities": [{"text": "CoNLL-2009 benchmark dataset", "start_pos": 28, "end_pos": 56, "type": "DATASET", "confidence": 0.9459396004676819}]}], "introductionContent": [{"text": "Semantic role labeling (SRL) aims to identify the arguments of semantic predicates in a sentence and label them with a set of predefined relations (e.g.,.", "labels": [], "entities": [{"text": "Semantic role labeling (SRL)", "start_pos": 0, "end_pos": 28, "type": "TASK", "confidence": 0.8575320243835449}]}, {"text": "Semantic roles capture basic predicate-argument structure while abstracting over surface syntactic configurations and have been shown to benefit a wide spectrum of applications ranging from machine translation) to information extraction) and summarization (.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 190, "end_pos": 209, "type": "TASK", "confidence": 0.7546698153018951}, {"text": "information extraction", "start_pos": 214, "end_pos": 236, "type": "TASK", "confidence": 0.8355344235897064}, {"text": "summarization", "start_pos": 242, "end_pos": 255, "type": "TASK", "confidence": 0.9943641424179077}]}, {"text": "The successful application of neural networks to a variety of NLP tasks () has provided strong impetus to develop deep end-to-end models for SRL that forego the need for extensive feature engineering.", "labels": [], "entities": [{"text": "SRL", "start_pos": 141, "end_pos": 144, "type": "TASK", "confidence": 0.9801222085952759}]}, {"text": "Recently proposed models () largely rely on bi-directional recurrent neural networks) and predict semantic roles from textual input.", "labels": [], "entities": []}, {"text": "They achieve competitive results while being syntax agnostic, thereby challenging conventional wisdom that parse trees provide a better form of representation for assigning semantic role labels.", "labels": [], "entities": [{"text": "assigning semantic role labels", "start_pos": 163, "end_pos": 193, "type": "TASK", "confidence": 0.7677945345640182}]}, {"text": "There are, however, good reasons why syntax ought to help semantic role labeling.", "labels": [], "entities": [{"text": "semantic role labeling", "start_pos": 58, "end_pos": 80, "type": "TASK", "confidence": 0.736333429813385}]}, {"text": "First and foremost, SRL systems are trained on datasets whose semantic role annotations have been produced on top of treebanked corpora, and as a result are closely tied to syntactic information.", "labels": [], "entities": [{"text": "SRL", "start_pos": 20, "end_pos": 23, "type": "TASK", "confidence": 0.9846435785293579}]}, {"text": "An example sentence with roles labeled in the style of) is shown in.", "labels": [], "entities": []}, {"text": "Here, many arcs in the syntactic dependency graph are mirrored in the semantic dependency graph, suggesting that syntactic dependencies could provide useful information to the SRL task.", "labels": [], "entities": [{"text": "SRL task", "start_pos": 176, "end_pos": 184, "type": "TASK", "confidence": 0.9406790733337402}]}, {"text": "Secondly, predicates are typically associated with a standard linking, that is, a deterministic mapping from syntactic roles to semantic ones (.", "labels": [], "entities": []}, {"text": "For example, subject (SBJ) is commonly mapped onto A0, whereas A1 is often realized as object (OBJ).", "labels": [], "entities": []}, {"text": "Even in cases where there is no canonical mapping, dependency labels are still closely related to certain semantic roles, like the syntactic function TMP and the semantic role AM-TMP.", "labels": [], "entities": []}, {"text": "The question of how to effectively incorporate syntactic information into sequential neural network models has met with different answers in the literature.", "labels": [], "entities": []}, {"text": "make use of graph convolutional networks (GCNs; as a means to represent syntax in neural models.", "labels": [], "entities": []}, {"text": "GCNs are used to encode syntactic dependency trees in combination with encoders based on long short-term memory units (LSTMs).", "labels": [], "entities": []}, {"text": "emphasize the role of syntax in argument identification rather than role labeling.", "labels": [], "entities": [{"text": "argument identification", "start_pos": 32, "end_pos": 55, "type": "TASK", "confidence": 0.7601357400417328}, {"text": "role labeling", "start_pos": 68, "end_pos": 81, "type": "TASK", "confidence": 0.7443397641181946}]}, {"text": "Specifically, they develop an argument pruning algorithm that operates over dependency structures and selects argument candidates subject to a parameter determining their distance from the predicate.", "labels": [], "entities": []}, {"text": "The predicate and its arguments are then encoded with an LSTM similar to . incorporate syntax at decoding time, in the form of constraints on the output structure (e.g., consistency with a parse tree is enforced by rejecting or penalizing arguments that are not constituents), whereas incorporate syntactic information in a multi-task neural network model that simultaneously performs part-of-speech tagging, dependency parsing, predicate detection, and SRL.", "labels": [], "entities": [{"text": "part-of-speech tagging", "start_pos": 385, "end_pos": 407, "type": "TASK", "confidence": 0.711519330739975}, {"text": "dependency parsing", "start_pos": 409, "end_pos": 427, "type": "TASK", "confidence": 0.7832759320735931}, {"text": "predicate detection", "start_pos": 429, "end_pos": 448, "type": "TASK", "confidence": 0.9042688310146332}, {"text": "SRL", "start_pos": 454, "end_pos": 457, "type": "TASK", "confidence": 0.9819487929344177}]}, {"text": "In this paper we argue that syntactic information is important for semantic role labeling and syntactic parsing is not.", "labels": [], "entities": [{"text": "semantic role labeling", "start_pos": 67, "end_pos": 89, "type": "TASK", "confidence": 0.694160521030426}, {"text": "syntactic parsing", "start_pos": 94, "end_pos": 111, "type": "TASK", "confidence": 0.8040904700756073}]}, {"text": "Despite recent advances in dependency parsing, the use of an external parser often leads to pipeline-style architectures where errors propagate to later processing stages, affecting model performance.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 27, "end_pos": 45, "type": "TASK", "confidence": 0.8030783832073212}]}, {"text": "To mitigate such errors, Marcheggiani and Titov (2017) calculate a scalar gate for each edge in the dependency tree.", "labels": [], "entities": []}, {"text": "And perhaps unsurprisingly, the performance of their system decreases when more than one GCN layer is stacked, as the effect of noisy information is amplified.", "labels": [], "entities": []}, {"text": "Our key insight is to focus on dependency labels, which provide important information for semantic roles without requiring access to a full-blown syntactic representation of the sentence.", "labels": [], "entities": []}, {"text": "Our model concentrates on the dependency structures pertaining to the predicate in a given sentence rather than capturing information relating to every arc in the dependency tree.", "labels": [], "entities": []}, {"text": "The majority of arguments (approximately 68%) in the CoNLL-2009 English development set are directly linked to the predicate or are predicates themselves.", "labels": [], "entities": [{"text": "CoNLL-2009 English development set", "start_pos": 53, "end_pos": 87, "type": "DATASET", "confidence": 0.9357367604970932}]}, {"text": "Our work focuses on learning dependencyaware representations without recourse to an external parser.", "labels": [], "entities": []}, {"text": "The backbone of our model is a semantic role labeler jointly trained with a dependency information extractor with two auxiliary tasks: predicting the dependency label of a word and whether there exists an arc linking it to the predicate.", "labels": [], "entities": [{"text": "predicting the dependency label of a word", "start_pos": 135, "end_pos": 176, "type": "TASK", "confidence": 0.877378625529153}]}, {"text": "The two auxiliary tasks provide dependency information that is specific to the SRL task and is learned from training data (dependency annotations) without ever utilizing an external parser.", "labels": [], "entities": [{"text": "SRL task", "start_pos": 79, "end_pos": 87, "type": "TASK", "confidence": 0.9229584336280823}]}, {"text": "Our model falls under the general paradigm of multi-task learning which aims to improve a main task by jointly learning one or more related auxiliary tasks.", "labels": [], "entities": []}, {"text": "Multi-task learning has been successfully applied to various sequence-prediction tasks including chunking, tagging, name error detection (, machine translation (, supersense tagging (, entailment (, and semantic role labeling.", "labels": [], "entities": [{"text": "tagging", "start_pos": 107, "end_pos": 114, "type": "TASK", "confidence": 0.9666323065757751}, {"text": "name error detection", "start_pos": 116, "end_pos": 136, "type": "TASK", "confidence": 0.7043153047561646}, {"text": "machine translation", "start_pos": 140, "end_pos": 159, "type": "TASK", "confidence": 0.7462490200996399}, {"text": "semantic role labeling", "start_pos": 203, "end_pos": 225, "type": "TASK", "confidence": 0.6560010413328806}]}, {"text": "Experimental results on the CoNLL-2009 benchmark dataset show that our model is able to outperform the state of the art in English, and to improve SRL performance in other languages, including Chinese, German, and Spanish.", "labels": [], "entities": [{"text": "CoNLL-2009 benchmark dataset", "start_pos": 28, "end_pos": 56, "type": "DATASET", "confidence": 0.9662237366040548}, {"text": "SRL", "start_pos": 147, "end_pos": 150, "type": "TASK", "confidence": 0.984043300151825}]}], "datasetContent": [{"text": "We implemented our model in PyTorch: Hyperparameter values.", "labels": [], "entities": [{"text": "PyTorch", "start_pos": 28, "end_pos": 35, "type": "DATASET", "confidence": 0.8851481080055237}]}, {"text": "to Hajic et al. for details on individual languages and their annotations).", "labels": [], "entities": []}, {"text": "For experiments on English, we used the embeddings of, which were learned using the structured skip n-gram approach of.", "labels": [], "entities": []}, {"text": "Ina few experiments we also used English character embeddings following.", "labels": [], "entities": []}, {"text": "These were pre-trained with a CNN-BiLSTM model ( on the 1 Billion Word Benchmark, 2 which is publicly released as part of the AllenNLP toolkit.", "labels": [], "entities": [{"text": "AllenNLP toolkit", "start_pos": 126, "end_pos": 142, "type": "DATASET", "confidence": 0.9644185602664948}]}, {"text": "Embeddings 4 for Chinese, Spanish, and German were pre-trained on Wikipedia using fastText (.", "labels": [], "entities": []}, {"text": "The dropout mechanism was applied to the input layer and the top hidden layer of the BiLSTM encoders.", "labels": [], "entities": [{"text": "BiLSTM encoders", "start_pos": 85, "end_pos": 100, "type": "DATASET", "confidence": 0.9069382846355438}]}, {"text": "We used the Adam optimizer) to train our models.", "labels": [], "entities": []}, {"text": "We performed hyperparameter tuning and model selection on the English development set; optimal hyperparameter values (for all languages) are shown in  as in which uses a pipeline of mate-tools).", "labels": [], "entities": [{"text": "hyperparameter tuning", "start_pos": 13, "end_pos": 34, "type": "TASK", "confidence": 0.7177259624004364}, {"text": "English development set", "start_pos": 62, "end_pos": 85, "type": "DATASET", "confidence": 0.8431617816289266}]}], "tableCaptions": [{"text": " Table 2: English results on the CoNLL-2009  in-domain (WSJ) test set.", "labels": [], "entities": [{"text": "CoNLL-2009  in-domain (WSJ) test set", "start_pos": 33, "end_pos": 69, "type": "DATASET", "confidence": 0.840498149394989}]}, {"text": " Table 3: English results on the CoNLL-2009  out-of domain (Brown) test set.", "labels": [], "entities": [{"text": "CoNLL-2009  out-of domain (Brown) test set", "start_pos": 33, "end_pos": 75, "type": "DATASET", "confidence": 0.8866268321871758}]}, {"text": " Table 4: Results on the CoNLL-2009 test sets for  Chinese, German, and Spanish.", "labels": [], "entities": [{"text": "CoNLL-2009 test sets", "start_pos": 25, "end_pos": 45, "type": "DATASET", "confidence": 0.9430719017982483}]}, {"text": " Table 5: Ablation results on the CoNLL-2009  English development set.", "labels": [], "entities": [{"text": "Ablation", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.995812714099884}, {"text": "CoNLL-2009  English development set", "start_pos": 34, "end_pos": 69, "type": "DATASET", "confidence": 0.9602219313383102}]}, {"text": " Table 6: F 1 results on the English test set broken  down into verbal and nominal predicates.", "labels": [], "entities": [{"text": "F 1", "start_pos": 10, "end_pos": 13, "type": "METRIC", "confidence": 0.955573171377182}, {"text": "English test set", "start_pos": 29, "end_pos": 45, "type": "DATASET", "confidence": 0.8163809776306152}]}]}