{"title": [{"text": "DREAM: A Challenge Data Set and Models for Dialogue-Based Reading Comprehension", "labels": [], "entities": [{"text": "Dialogue-Based Reading Comprehension", "start_pos": 43, "end_pos": 79, "type": "TASK", "confidence": 0.6279051502545675}]}], "abstractContent": [{"text": "We present DREAM, the first dialogue-based multiple-choice reading comprehension data set.", "labels": [], "entities": []}, {"text": "Collected from English as a Foreign Language examinations designed by human experts to evaluate the comprehension level of Chinese learners of English, our data set contains 10,197 multiple-choice questions for 6,444 dialogues.", "labels": [], "entities": []}, {"text": "In contrast to existing reading comprehension data sets, DREAM is the first to focus on in-depth multi-turn multi-party dialogue understanding.", "labels": [], "entities": [{"text": "multi-party dialogue understanding", "start_pos": 108, "end_pos": 142, "type": "TASK", "confidence": 0.6157631973425547}]}, {"text": "DREAM is likely to present significant challenges for existing reading comprehension systems: 84% of answers are non-extractive, 85% of questions require reasoning beyond a single sentence, and 34% of questions also involve common-sense knowledge.", "labels": [], "entities": []}, {"text": "We apply several popular neural reading comprehension models that primarily exploit surface information within the text and find them to, at best, just barely outperform a rule-based approach.", "labels": [], "entities": []}, {"text": "We next investigate the effects of incorporating dialogue structure and different kinds of general world knowledge into both rule-based and (neural and non-neural) machine learning-based reading comprehension models.", "labels": [], "entities": []}, {"text": "Experimental results on the DREAM data set show the effectiveness of dialogue structure and general world knowledge.", "labels": [], "entities": [{"text": "DREAM data set", "start_pos": 28, "end_pos": 42, "type": "DATASET", "confidence": 0.9185925722122192}]}, {"text": "DREAM is available at https://dataset.", "labels": [], "entities": [{"text": "DREAM", "start_pos": 0, "end_pos": 5, "type": "DATASET", "confidence": 0.7836158871650696}]}], "introductionContent": [{"text": "Recently a significant amount of research has focused on the construction of large-scale multiple- * This work was done when K.", "labels": [], "entities": []}, {"text": "S. was an intern at the Tencent AI Lab, Bellevue, WA.", "labels": [], "entities": []}, {"text": "choice () and extractive () reading comprehension data sets (Section 2).", "labels": [], "entities": []}, {"text": "Source documents in these data sets have generally been drawn from formal written texts such as news, fiction, and Wikipedia articles, which are commonly considered wellwritten, accurate, and neutral.", "labels": [], "entities": []}, {"text": "With the goal of advancing research in machine reading comprehension and facilitating dialogue understanding, we construct and present DREAM -the first multiple-choice Dialoguebased REAding comprehension exaMination data set.", "labels": [], "entities": [{"text": "dialogue understanding", "start_pos": 86, "end_pos": 108, "type": "TASK", "confidence": 0.8606772124767303}]}, {"text": "We collect 10,197 questions for 6,444 multiturn multi-party dialogues from English language exams, which are carefully designed by educational experts (e.g., English teachers) to assess the comprehension level of Chinese learners of English.", "labels": [], "entities": []}, {"text": "Each question is associated with three answer options, exactly one of which is correct.", "labels": [], "entities": []}, {"text": "(See for an example.)", "labels": [], "entities": []}, {"text": "DREAM covers a variety of topics and scenarios in daily life such as conversations on the street, on the phone, in a classroom or library, at the airport or the office or a shop.", "labels": [], "entities": []}, {"text": "Based on our analysis of DREAM, we argue that dialogue-based reading comprehension is at least as difficult as existing non-conversational counterparts.", "labels": [], "entities": []}, {"text": "In particular, answering 34% of DREAM questions requires unspoken commonsense knowledge, for example, unspoken scene information.", "labels": [], "entities": []}, {"text": "This might be due to the nature of dialogues: For efficient oral communication, people rarely state obvious explicit world knowledge () such as ''Christmas Day is celebrated on December 25th.''Understanding W: Tom, look at your shoes.", "labels": [], "entities": []}, {"text": "M: Oh, mum, I just cleaned them yesterday.", "labels": [], "entities": []}, {"text": "W: They are dirty now.", "labels": [], "entities": []}, {"text": "You must clean them again.", "labels": [], "entities": []}, {"text": "M: I do not want to clean them today.", "labels": [], "entities": []}, {"text": "Even if I clean them today, they will get dirty again tomorrow.", "labels": [], "entities": []}, {"text": "W: All right, then.", "labels": [], "entities": []}, {"text": "M: Mum, give me something to eat, please.", "labels": [], "entities": [{"text": "Mum", "start_pos": 3, "end_pos": 6, "type": "DATASET", "confidence": 0.5830237865447998}]}, {"text": "W: You had your breakfast in the morning, Tom, and you had lunch at school.", "labels": [], "entities": []}, {"text": "M: I am hungry again.", "labels": [], "entities": [{"text": "M", "start_pos": 0, "end_pos": 1, "type": "METRIC", "confidence": 0.7613492012023926}]}, {"text": "W: Oh, hungry?", "labels": [], "entities": []}, {"text": "But if I give you something to eat today, you will be hungry again tomorrow.", "labels": [], "entities": []}, {"text": "Q1 Why did the woman say that she wouldn't give him anything to eat?", "labels": [], "entities": []}, {"text": "A. Because his mother wants to correct his bad habit.\ud97b\udf59 B.", "labels": [], "entities": [{"text": "\ud97b\udf59", "start_pos": 53, "end_pos": 54, "type": "METRIC", "confidence": 0.9840699434280396}, {"text": "B", "start_pos": 55, "end_pos": 56, "type": "METRIC", "confidence": 0.6102495193481445}]}, {"text": "Because he had lunch at school.", "labels": [], "entities": []}, {"text": "C. Because his mother wants to leave him hungry.", "labels": [], "entities": []}, {"text": "the social implications of an utterance as well as inferring a speaker's intentions is also regularly required for answering dialogue-based questions.", "labels": [], "entities": []}, {"text": "The dialogue content in, for example, is itself insufficient for readers to recognize the intention of the female speaker (W) in the first question (Q1).", "labels": [], "entities": []}, {"text": "However, world knowledge is rarely considered in state-of-the-art reading comprehension models ().", "labels": [], "entities": []}, {"text": "Moreover, dialogue-based questions can cover information imparted across multiple turns involving multiple speakers.", "labels": [], "entities": []}, {"text": "In DREAM, approximately 85% of questions can only be answered by considering the information from multiple sentences.", "labels": [], "entities": []}, {"text": "For example, to answer Q1 in later in the paper regarding the date of birth of the male speaker (M), the supporting sentences (in bold) include ''You know, tomorrow is Christmas Day'' from the female speaker and ''.", "labels": [], "entities": [{"text": "Q1", "start_pos": 23, "end_pos": 25, "type": "METRIC", "confidence": 0.9493114948272705}]}, {"text": "I am more than excited about my birthday, which will come in two days'' from the male speaker.", "labels": [], "entities": []}, {"text": "Compared with ''multiple-sentence questions'' in traditional reading comprehension data sets, DREAM further requires an understanding of the turn-based structure of dialogue-for example, for aligning utterances with their corresponding speakers.", "labels": [], "entities": []}, {"text": "As only 16% of correct answer options are text spans from the source documents, we primarily explore rule-based methods and state-of-theart neural models designed for multiple-choice reading comprehension (Section 4).", "labels": [], "entities": []}, {"text": "We find first that neural models designed for non-dialoguebased reading comprehension) do not fare well: The highest achieved accuracy is 45.5%, only slightly better than the accuracy (44.6%) of a simple lexical baseline (.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 126, "end_pos": 134, "type": "METRIC", "confidence": 0.9982423782348633}, {"text": "accuracy", "start_pos": 175, "end_pos": 183, "type": "METRIC", "confidence": 0.9989173412322998}]}, {"text": "For the most part, these models fundamentally exploit only surface-level information from the source documents.", "labels": [], "entities": []}, {"text": "Considering the abovementioned challenges, however, we hypothesize that incorporating general world knowledge and aspects of the dialogue structure would allow a better understanding of the dialogues.", "labels": [], "entities": []}, {"text": "As a result, we modify our baseline systems to include (1) general world knowledge in the form of such as ConceptNet relations) and a pre-trained language model (, and (2) speaker information for each utterance.", "labels": [], "entities": []}, {"text": "Experiments show the effectiveness of these factors on the lexical baselines as well as neural and non-neural machine learning approaches: We acquire up to 11.9% absolute gain inaccuracy compared with the highest performance achieved by the state-of-the-art reading comprehension model (), which mainly relies on explicit surface-level information in the text (Section 5).", "labels": [], "entities": [{"text": "absolute gain inaccuracy", "start_pos": 162, "end_pos": 186, "type": "METRIC", "confidence": 0.8891747196515402}]}, {"text": "Finally, we see a significant gap between the best automated approach (59.5%) and human ceiling performance (98.6%) on the DREAM data set.", "labels": [], "entities": [{"text": "DREAM data set", "start_pos": 123, "end_pos": 137, "type": "DATASET", "confidence": 0.9328792889912924}]}, {"text": "This provides yet additional evidence that dialogue-based reading comprehension is a very challenging task.", "labels": [], "entities": [{"text": "dialogue-based reading comprehension", "start_pos": 43, "end_pos": 79, "type": "TASK", "confidence": 0.6981042424837748}]}, {"text": "We hope that it also inspires the research community to develop methods for the dialogue-based reading comprehension task.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 2: Distribution of answer (or correct answer option) types in three kinds of reading comprehension data sets.  Statistics of other data sets come from Reddy et al. (2018), Ko\u010disk`Ko\u010disk`y et al. (2018), and Lai et al. (2017).", "labels": [], "entities": []}, {"text": " Table 4: The overall statistics of DREAM. A turn is  defined as an uninterrupted stream of speech from one  speaker in a dialogue.", "labels": [], "entities": [{"text": "DREAM", "start_pos": 36, "end_pos": 41, "type": "TASK", "confidence": 0.8708289265632629}]}, {"text": " Table 5: The separation of the training, development,  and test sets in DREAM.", "labels": [], "entities": []}, {"text": " Table 6: Distribution (%) of question types.", "labels": [], "entities": []}, {"text": " Table 7: Comparison of the quality of dialogues from  DREAM and Friends (a TV show).", "labels": [], "entities": [{"text": "DREAM and Friends (a TV show)", "start_pos": 55, "end_pos": 84, "type": "DATASET", "confidence": 0.8669734224677086}]}, {"text": " Table 8: Performance in accuracy (%) on the DREAM data set. Performance marked by \ud97b\udf59 is reported based on  25% annotated questions from the development and test sets.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 25, "end_pos": 33, "type": "METRIC", "confidence": 0.999515175819397}, {"text": "DREAM data set", "start_pos": 45, "end_pos": 59, "type": "DATASET", "confidence": 0.9594929218292236}]}]}