{"title": [{"text": "Complex Program Induction for Querying Knowledge Bases in the Absence of Gold Programs", "labels": [], "entities": []}], "abstractContent": [{"text": "Recent years have seen increasingly complex question-answering on knowledge bases (KBQA) involving logical, quantitative, and comparative reasoning over KB subgraphs.", "labels": [], "entities": []}, {"text": "Neural Program Induction (NPI) is a pragmatic approach toward modularizing the reasoning process by translating a complex natural language query into a multi-step executable program.", "labels": [], "entities": [{"text": "Neural Program Induction (NPI)", "start_pos": 0, "end_pos": 30, "type": "TASK", "confidence": 0.7597681929667791}, {"text": "modularizing the reasoning process", "start_pos": 62, "end_pos": 96, "type": "TASK", "confidence": 0.751284196972847}]}, {"text": "While NPI has been commonly trained with the ''gold'' program or its sketch, for realistic KBQA applications such gold programs are expensive to obtain.", "labels": [], "entities": [{"text": "NPI", "start_pos": 6, "end_pos": 9, "type": "DATASET", "confidence": 0.897815465927124}]}, {"text": "There, practically only natural language queries and the corresponding answers can be provided for training.", "labels": [], "entities": []}, {"text": "The resulting combinatorial explosion in program space, along with extremely sparse rewards, makes NPI for KBQA ambitious and challenging.", "labels": [], "entities": []}, {"text": "We present Complex Imperative Program Induction from Terminal Rewards (CIPITR), an advanced neural programmer that mitigates reward sparsity with auxiliary rewards, and restricts the program space to semantically correct programs using high-level constraints, KB schema, and inferred answer type.", "labels": [], "entities": [{"text": "Complex Imperative Program Induction from Terminal Rewards", "start_pos": 11, "end_pos": 69, "type": "TASK", "confidence": 0.7080540359020233}]}, {"text": "CIPITR solves complex KBQA considerably more accurately than key-value memory networks and neural symbolic machines (NSM).", "labels": [], "entities": []}, {"text": "For moderately complex queries requiring 2-to 5-step programs, CIPITR scores at least 3\u00d7 higher F1 than the competing systems.", "labels": [], "entities": [{"text": "F1", "start_pos": 96, "end_pos": 98, "type": "METRIC", "confidence": 0.9988716244697571}]}, {"text": "On one of the hardest class of programs (comparative reasoning) with 5-10 steps, CIPITR outperforms NSM by a factor of 89 and memory networks by 9 times.", "labels": [], "entities": [{"text": "comparative reasoning", "start_pos": 41, "end_pos": 62, "type": "TASK", "confidence": 0.8182136118412018}]}], "introductionContent": [{"text": "Structured knowledge bases (KB) like Wikidata and Freebase can support answering questions (KBQA) over a diverse spectrum of structural complexity.", "labels": [], "entities": [{"text": "Freebase", "start_pos": 50, "end_pos": 58, "type": "DATASET", "confidence": 0.9231564402580261}, {"text": "answering questions (KBQA)", "start_pos": 71, "end_pos": 97, "type": "TASK", "confidence": 0.8208026051521301}]}, {"text": "This includes queries with single-hop (Obama's birthplace), or multi-hop (who voiced Meg in Family Guy), or complex queries such as ''how many countries have more rivers and lakes than.", "labels": [], "entities": []}, {"text": "Complex queries require a proper assembly of selected operators from a library of graph, set, logical, and arithmetic operations into a complex procedure, and is the subject of this paper.", "labels": [], "entities": []}, {"text": "Relatively simple query classes, in particular, in which answers are KB entities, can be served with feed-forward () and seq2seq  networks.", "labels": [], "entities": []}, {"text": "However, such systems show copying or rote learning behavior when Boolean or open numeric domains are involved.", "labels": [], "entities": [{"text": "copying", "start_pos": 27, "end_pos": 34, "type": "TASK", "confidence": 0.9676182866096497}]}, {"text": "More complex queries need to be evaluated as an acyclic expression graph over nodes representing KB access, set, logical, and arithmetic operators (.", "labels": [], "entities": []}, {"text": "A practical alternative to inferring a stateless expression graph is to generate an imperative sequential program to solve the query.", "labels": [], "entities": []}, {"text": "Each step of the program selects anatomic operator and a set of previously defined variables as arguments and writes the result to scratch memory, which can then be used in subsequent steps.", "labels": [], "entities": []}, {"text": "Such imperative programs are preferable to opaque, monolithic networks for their interpretability and generalization to diverse domains.", "labels": [], "entities": []}, {"text": "Another motivation behind opting for the program induction paradigm for solving complex tasks, such as complex question answering, is modularizing the end-to-end complex reasoning process.", "labels": [], "entities": [{"text": "complex question answering", "start_pos": 103, "end_pos": 129, "type": "TASK", "confidence": 0.628546396891276}]}, {"text": "With this approach it is now possible to first train separate modules for each of the atomic operations involved and then train a program induction model that learns to use these separately trained models and invoke the sub-modules in the correct fashion to solve the task.", "labels": [], "entities": []}, {"text": "These sub-modules can even be task-agnostic generic models that can be pretrained with much more extensive training data, while the program induction model learns from examples pertaining to the specific task.", "labels": [], "entities": []}, {"text": "This paradigm of program induction has been used for decades, with rule induction and probabilistic program induction techniques in and by constructing algorithms utilizing formal theorem-proving techniques in.", "labels": [], "entities": [{"text": "program induction", "start_pos": 17, "end_pos": 34, "type": "TASK", "confidence": 0.8181622922420502}, {"text": "rule induction", "start_pos": 67, "end_pos": 81, "type": "TASK", "confidence": 0.7956498563289642}]}, {"text": "These traditional approaches (e.g., incorporated domain specific knowledge about programming languages instead of applying learning techniques.", "labels": [], "entities": []}, {"text": "More recently, to promote generalizability and reduce dependecy on domain specific knowledge, neural approaches have been applied to problems like addition, sorting, and word algebra problems (Reed and as well as for manipulating a physical environment (.", "labels": [], "entities": [{"text": "addition, sorting", "start_pos": 147, "end_pos": 164, "type": "TASK", "confidence": 0.7642700870831808}, {"text": "word algebra", "start_pos": 170, "end_pos": 182, "type": "TASK", "confidence": 0.6119110733270645}]}, {"text": "Program Induction has also seen initial promise in translating simple natural language queries into programs executable in one or two hops over a KB to obtain answers (.", "labels": [], "entities": [{"text": "Program Induction", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.7187494039535522}]}, {"text": "In contrast, many of the complex queries from, such as the one in, require up to 10-step programs involving multiple relations and several arithmetic and logical operations.", "labels": [], "entities": []}, {"text": "Sample operations include gen \u2212 set: collecting {t : (h, r, t) \u2208 KB}, computing set \u2212 union, counting set sizes (set \u2212 count), comparing numbers or sets, and so forth.", "labels": [], "entities": []}, {"text": "These operations need to be executed in the correct order, with correct parameters, sharing information via intermediate results to arrive at the correct answer.", "labels": [], "entities": []}, {"text": "Note also that the actual gold program is not available for supervision and therefore the large space of possible translation actions at each step, coupled with a large number of steps needed to get any payoff, makes the reward very sparse.", "labels": [], "entities": []}, {"text": "This renders complex KBQA in the absence of gold programs extremely challenging.", "labels": [], "entities": []}, {"text": "The CIPITR framework reads a natural language query and writes a program as a sequence of actions, guided at every step by constraints posed by the KB and the answer-type.", "labels": [], "entities": []}, {"text": "Because the space of actions is discrete, REINFORCE is used to learn the action selection by computing the reward from the output answer obtained by executing the program and the target answer, which is the only source of supervision.", "labels": [], "entities": [{"text": "REINFORCE", "start_pos": 42, "end_pos": 51, "type": "METRIC", "confidence": 0.993240237236023}]}], "datasetContent": [{"text": "We compare CIPITR against baselines) on complex KBQA and further identify the contributions of the ideas presented in Section 5 via ablation studies.", "labels": [], "entities": [{"text": "CIPITR", "start_pos": 11, "end_pos": 17, "type": "METRIC", "confidence": 0.8688873648643494}]}, {"text": "For this work, we limit our effort on KBQA to the setting where the query is annotated with the gold KB-artifacts, which standardizes the input to the program induction for the competing models.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: F1 scores(%) of CIPITR and rule-based model(as in Sec.6.2.1) on WebQuestionsSP test set having  1,639 queries.", "labels": [], "entities": [{"text": "F1", "start_pos": 10, "end_pos": 12, "type": "METRIC", "confidence": 0.9996745586395264}, {"text": "CIPITR", "start_pos": 26, "end_pos": 32, "type": "DATASET", "confidence": 0.7923876643180847}, {"text": "WebQuestionsSP test set", "start_pos": 74, "end_pos": 97, "type": "DATASET", "confidence": 0.9430491129557291}]}, {"text": " Table 3: F1 score (%) of KVMnet and NSM, and CIPITR. Bold numbers indicate the best among KVMnet and  top beam score of NSM and CIPITR.", "labels": [], "entities": [{"text": "F1 score", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9823226928710938}]}, {"text": " Table 4: Ablation testing on comparative questions:  Top beam's F1 score obtained by omitting each of the  above features from CIPITR, originally having F1 of  15.123%.", "labels": [], "entities": [{"text": "Ablation", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.985079824924469}, {"text": "F1 score", "start_pos": 65, "end_pos": 73, "type": "METRIC", "confidence": 0.9836692810058594}, {"text": "CIPITR", "start_pos": 128, "end_pos": 134, "type": "DATASET", "confidence": 0.9602584838867188}, {"text": "F1", "start_pos": 154, "end_pos": 156, "type": "METRIC", "confidence": 0.998915433883667}]}]}