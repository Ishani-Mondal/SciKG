{"title": [{"text": "Grammar Error Correction in Morphologically Rich Languages: The Case of Russian", "labels": [], "entities": []}], "abstractContent": [{"text": "Until now, most of the research in grammar error correction focused on English, and the problem has hardly been explored for other languages.", "labels": [], "entities": [{"text": "grammar error correction", "start_pos": 35, "end_pos": 59, "type": "TASK", "confidence": 0.5959065953890482}]}, {"text": "We address the task of correcting writing mistakes in morphologically rich languages , with a focus on Russian.", "labels": [], "entities": []}, {"text": "We present a corrected and error-tagged corpus of Russian learner writing and develop models that make use of existing state-of-the-art methods that have been well studied for English.", "labels": [], "entities": []}, {"text": "Although impressive results have recently been achieved for grammar error correction of non-native English writing, these results are limited to domains where plentiful training data are available.", "labels": [], "entities": [{"text": "grammar error correction of non-native English writing", "start_pos": 60, "end_pos": 114, "type": "TASK", "confidence": 0.7447145581245422}]}, {"text": "Because annotation is extremely costly, these approaches are not suitable for the majority of domains and languages.", "labels": [], "entities": []}, {"text": "We thus focus on methods that use ''minimal super-vision''; that is, those that do not rely on large amounts of annotated training data, and show how existing minimal-supervision approaches extend to a highly inflectional language such as Russian.", "labels": [], "entities": []}, {"text": "The results demonstrate that these methods are particularly useful for correcting mistakes in grammatical phenomena that involve rich morphology.", "labels": [], "entities": []}], "introductionContent": [{"text": "This paper addresses the task of correcting errors in text.", "labels": [], "entities": [{"text": "correcting errors in text", "start_pos": 33, "end_pos": 58, "type": "TASK", "confidence": 0.8626250177621841}]}, {"text": "Most of the research in the area of grammar error correction (GEC) focused on correcting mistakes made by English language learners.", "labels": [], "entities": [{"text": "grammar error correction (GEC)", "start_pos": 36, "end_pos": 66, "type": "TASK", "confidence": 0.7567985355854034}, {"text": "correcting mistakes made by English language learners", "start_pos": 78, "end_pos": 131, "type": "TASK", "confidence": 0.7218242628233773}]}, {"text": "One standard approach to dealing with these errors, which proved highly successful in text correction competitions (, makes use of a machinelearning classifier paradigm and is based on the methodology for correcting context-sensitive spelling mistakes).", "labels": [], "entities": [{"text": "text correction competitions", "start_pos": 86, "end_pos": 114, "type": "TASK", "confidence": 0.8685915271441141}]}, {"text": "In this approach, classifiers are trained fora particular mistake type: for example, preposition, article, or noun number.", "labels": [], "entities": []}, {"text": "Originally, classifiers were trained on native English data.", "labels": [], "entities": []}, {"text": "As several annotated learner datasets became available, models were also trained on annotated learner data.", "labels": [], "entities": []}, {"text": "More recently, the statistical machine translation (MT) methods, including neural MT, have gained considerable popularity thanks to the availability of large annotated corpora of learner writing (e.g.,.", "labels": [], "entities": [{"text": "statistical machine translation (MT)", "start_pos": 19, "end_pos": 55, "type": "TASK", "confidence": 0.7798198759555817}]}, {"text": "Classification methods work very well on well-defined types of errors, whereas MT is good at correcting interacting and complex types of mistakes, which makes these approaches complementary in some respects.", "labels": [], "entities": [{"text": "MT", "start_pos": 79, "end_pos": 81, "type": "TASK", "confidence": 0.9507327675819397}]}, {"text": "Thanks to the availability of large (in-domain) datasets, substantial gains in performance have been made in English grammar correction.", "labels": [], "entities": [{"text": "English grammar correction", "start_pos": 109, "end_pos": 135, "type": "TASK", "confidence": 0.6996527910232544}]}, {"text": "Unfortunately, research on other languages has been scarce.", "labels": [], "entities": []}, {"text": "Previous work includes efforts to create annotated learner corpora for Arabic ( ), Japanese (Mizumoto et al., 2011), and Chinese (, and shared tasks on Arabic ( and Chinese error detection (.", "labels": [], "entities": [{"text": "Chinese error detection", "start_pos": 165, "end_pos": 188, "type": "TASK", "confidence": 0.6584095160166422}]}, {"text": "However, building robust models in other languages has been a challenge, since an approach that relies on heavy supervision is not viable across languages, genres, and learner backgrounds.", "labels": [], "entities": []}, {"text": "Moreover, for languages that are complex morphologically, we may need more data to address the lexical sparsity.", "labels": [], "entities": []}, {"text": "This work focuses on Russian, a highly inflectional language from the Slavic group.", "labels": [], "entities": []}, {"text": "Russian has over 260M speakers, for 47% of whom Russian is not their native language.", "labels": [], "entities": []}, {"text": "We corrected and error-tagged over 200K words of non-native Russian texts.", "labels": [], "entities": []}, {"text": "We use this dataset to build several grammar correction systems that draw on and extend the methods that showed state-of-theart performance on English grammar correction.", "labels": [], "entities": [{"text": "grammar correction", "start_pos": 37, "end_pos": 55, "type": "TASK", "confidence": 0.7128992825746536}, {"text": "English grammar correction", "start_pos": 143, "end_pos": 169, "type": "TASK", "confidence": 0.5915344854195913}]}, {"text": "Because the size of our annotation is limited, compared with what is used for English, one of the goals of our work is to quantify the effect of having limited annotation on existing approaches.", "labels": [], "entities": []}, {"text": "We evaluate both the MT paradigm, which requires large amounts of annotated learner data, and the classification approaches that can work with any amount of supervision.", "labels": [], "entities": [{"text": "MT", "start_pos": 21, "end_pos": 23, "type": "TASK", "confidence": 0.9871593713760376}]}, {"text": "Overall, the results obtained for Russian are much lower than those reported for English.", "labels": [], "entities": []}, {"text": "We further find that the minimal-supervision classification methods that can combine large amounts of native data with a small annotated learner sample give the best results on a language with rich morphology and with limited annotation.", "labels": [], "entities": []}, {"text": "The system that uses classifiers with minimal supervision achieves an F 0.5 score of 21.0, 2 whereas the MT system trained on the same data achieves a score of only 10.6.", "labels": [], "entities": [{"text": "F 0.5 score", "start_pos": 70, "end_pos": 81, "type": "METRIC", "confidence": 0.9870165387789408}, {"text": "MT", "start_pos": 105, "end_pos": 107, "type": "TASK", "confidence": 0.8594314455986023}]}, {"text": "This paper makes the following contributions: (1) We describe an error classification schema for Russian learner errors, and present an error-tagged Russian learner corpus.", "labels": [], "entities": []}, {"text": "The dataset is available for research and can serve as a benchmark dataset for Russian, which should facilitate progress on grammar correction research, especially for languages other than English.", "labels": [], "entities": [{"text": "grammar correction research", "start_pos": 124, "end_pos": 151, "type": "TASK", "confidence": 0.7869462668895721}]}, {"text": "(2) We present an analysis of the annotated data, in terms of error rates, error distributions by learner type (foreign and heritage), as well as comparison to learner corpora in other languages.", "labels": [], "entities": []}, {"text": "(3) We extend stateof-the-art grammar correction methods to a morphologically rich language and, in particular, identify classifiers needed to address mistakes 1 https://en.wikipedia.org/wiki/Russian language.", "labels": [], "entities": [{"text": "stateof-the-art grammar correction", "start_pos": 14, "end_pos": 48, "type": "TASK", "confidence": 0.6388170421123505}]}, {"text": "2 This is a standard metric used in grammar correction since the CoNLL shared tasks.", "labels": [], "entities": [{"text": "grammar correction", "start_pos": 36, "end_pos": 54, "type": "TASK", "confidence": 0.8484135270118713}, {"text": "CoNLL shared tasks", "start_pos": 65, "end_pos": 83, "type": "DATASET", "confidence": 0.8417621453603109}]}, {"text": "Because precision is more important than recall in grammar correction, it is weighed twice as high, and is denoted as F 0.5 . Other metrics have been proposed recently).", "labels": [], "entities": [{"text": "precision", "start_pos": 8, "end_pos": 17, "type": "METRIC", "confidence": 0.9991645812988281}, {"text": "recall", "start_pos": 41, "end_pos": 47, "type": "METRIC", "confidence": 0.9980091452598572}, {"text": "grammar correction", "start_pos": 51, "end_pos": 69, "type": "TASK", "confidence": 0.8170210123062134}, {"text": "F", "start_pos": 118, "end_pos": 119, "type": "METRIC", "confidence": 0.9947552680969238}]}, {"text": "3 https://github.com/arozovskaya/RULEC-GEC. that are specific to these languages.", "labels": [], "entities": [{"text": "RULEC-GEC.", "start_pos": 33, "end_pos": 43, "type": "METRIC", "confidence": 0.990225613117218}]}, {"text": "(4) We demonstrate that the classification framework with minimal supervision is particularly useful for morphologically rich languages; they can benefit from large amounts of native data, due to a large variability of word forms, and small amounts of annotation provide good estimates of typical learner errors.", "labels": [], "entities": []}, {"text": "We present an error analysis that provides further insight into the behavior of the models on a morphologically rich language.", "labels": [], "entities": []}, {"text": "Section 2 presents related work.", "labels": [], "entities": []}, {"text": "Section 3 describes the corpus.", "labels": [], "entities": []}, {"text": "Experiments are described in Section 4, and the results are presented in Section 5.", "labels": [], "entities": []}, {"text": "We present an error analysis in Section 6 and conclude in Section 7.", "labels": [], "entities": [{"text": "error", "start_pos": 14, "end_pos": 19, "type": "METRIC", "confidence": 0.9584267139434814}]}], "datasetContent": [{"text": "The experiments investigate the following: 1.", "labels": [], "entities": []}, {"text": "How do the two state-of-the-art methods compare under the conditions that we have for Russian (rich morphology and limited annotations)?", "labels": [], "entities": []}, {"text": "2. What is the performance on individual errors and the overall performance compared with results obtained for English grammar correction?", "labels": [], "entities": [{"text": "English grammar correction", "start_pos": 111, "end_pos": 137, "type": "TASK", "confidence": 0.6698301136493683}]}, {"text": "3. How well do the classifiers within the minimal supervision framework perform in morphologically rich languages, on grammatical phenomena that are common in highly inflectional languages such as Russian, as well as on phenomena that also occur in English?", "labels": [], "entities": []}, {"text": "To answer these questions, the following three approaches are implemented: \u2022 Learner-trained classifiers: Error-specific classifiers trained on learner data \u2022 Minimal-supervision classifiers: Error-specific classifiers trained on learner and native data with minimal supervision (see Section 2.2) \u2022 Phrase-based machine translation system Data We split the annotated data into training (4,980 sentences, 83,410 words), development (2,500 sentences, 41,163 words), and test (5,000 sentences, 81,693 words).", "labels": [], "entities": [{"text": "Phrase-based machine translation", "start_pos": 299, "end_pos": 331, "type": "TASK", "confidence": 0.7056375642617544}]}, {"text": "For the native data, we use the Yandex corpus), a diverse corpus of newswire, fiction, and other genres (18M words).", "labels": [], "entities": [{"text": "Yandex corpus", "start_pos": 32, "end_pos": 45, "type": "DATASET", "confidence": 0.9707260131835938}]}, {"text": "All the data was preprocessed with the the Mystem morphological analyzer) and a part-of-speech tagger (Schmid, 1995).", "labels": [], "entities": [{"text": "Mystem morphological analyzer", "start_pos": 43, "end_pos": 72, "type": "DATASET", "confidence": 0.8047503630320231}]}], "tableCaptions": [{"text": " Table 2: Statistics for the annotated data in RULEC- GEC.", "labels": [], "entities": [{"text": "RULEC- GEC", "start_pos": 47, "end_pos": 57, "type": "DATASET", "confidence": 0.8072395722071329}]}, {"text": " Table 3: Distribution by error type. Total number  of categories is 23. The top 13 are shown. Replace  includes phenomena not covered by other categories,  e.g., additional morphological phenomena, replacing  multi-word expressions, and word order.", "labels": [], "entities": [{"text": "Replace", "start_pos": 95, "end_pos": 102, "type": "METRIC", "confidence": 0.8797882199287415}, {"text": "word order", "start_pos": 238, "end_pos": 248, "type": "TASK", "confidence": 0.7266190648078918}]}, {"text": " Table 4: Inter-annotator agreement. Error rates based  on the corrections on the second pass. Judged correct  denotes the percentage of sentences that the second  rater did not change.", "labels": [], "entities": [{"text": "Error", "start_pos": 37, "end_pos": 42, "type": "METRIC", "confidence": 0.99727863073349}]}, {"text": " Table 5: Error rates in various learner corpora. The  CoNLL and JFLEG have two and four reference  annotations, respectively. Numbers shown for each.", "labels": [], "entities": [{"text": "Error", "start_pos": 10, "end_pos": 15, "type": "METRIC", "confidence": 0.9641643762588501}, {"text": "CoNLL", "start_pos": 55, "end_pos": 60, "type": "DATASET", "confidence": 0.8966236114501953}, {"text": "JFLEG", "start_pos": 65, "end_pos": 70, "type": "DATASET", "confidence": 0.8156300783157349}]}, {"text": " Table 6: Comparison statistics for Russian and English learner corpora. The CoNLL-test was annotated by two  annotators; numbers shown for each.", "labels": [], "entities": []}, {"text": " Table 7: Most common errors for foreign and heritage Russian speakers.", "labels": [], "entities": [{"text": "errors", "start_pos": 22, "end_pos": 28, "type": "METRIC", "confidence": 0.9209781885147095}]}, {"text": " Table 9: Confusion matrix for noun case errors based on the training and development data from the RULEC-GEC  corpus. The left column shows the correct case. Each row shows the author's case choices for that label and  P rob(source|label).", "labels": [], "entities": [{"text": "RULEC-GEC  corpus", "start_pos": 100, "end_pos": 117, "type": "DATASET", "confidence": 0.931915670633316}]}, {"text": " Table 10: Comparison of classifiers trained on (1) learner data and", "labels": [], "entities": []}, {"text": " Table 11: Performance of the three systems.", "labels": [], "entities": []}, {"text": " Table 12: Performance of minimal-supervision classifiers before and after false positive analysis.", "labels": [], "entities": []}]}