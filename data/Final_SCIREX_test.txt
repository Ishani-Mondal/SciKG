document	O
:	O
Deep	B-Method
Label	I-Method
Distribution	I-Method
Learning	I-Method
With	O
Label	B-Task
Ambiguity	I-Task
	
Convolutional	B-Method
Neural	I-Method
Networks	I-Method
(	O
ConvNets	B-Method
)	O
have	O
achieved	O
excellent	O
recognition	B-Task
performance	O
in	O
various	O
visual	B-Task
recognition	I-Task
tasks	I-Task
.	O
	
A	O
large	O
labeled	O
training	O
set	O
is	O
one	O
of	O
the	O
most	O
important	O
factors	O
for	O
its	O
success	O
.	O
	
However	O
,	O
it	O
is	O
difficult	O
to	O
collect	O
sufficient	O
training	O
images	O
with	O
precise	O
labels	O
in	O
some	O
domains	O
such	O
as	O
apparent	O
age	B-Task
estimation	I-Task
,	O
head	B-Task
pose	I-Task
estimation	I-Task
,	O
multi	B-Task
-	I-Task
label	I-Task
classification	I-Task
and	O
semantic	B-Task
segmentation	I-Task
.	O
	
Fortunately	O
,	O
there	O
is	O
ambiguous	O
information	O
among	O
labels	O
,	O
which	O
makes	O
these	O
tasks	O
different	O
from	O
traditional	O
classification	B-Task
.	O
	
Based	O
on	O
this	O
observation	O
,	O
we	O
convert	O
the	O
label	O
of	O
each	O
image	O
into	O
a	O
discrete	O
label	O
distribution	O
,	O
and	O
learn	O
the	O
label	O
distribution	O
by	O
minimizing	O
a	O
Kullback	O
-	O
Leibler	O
divergence	O
between	O
the	O
predicted	O
and	O
ground	O
-	O
truth	O
label	O
distributions	O
using	O
deep	B-Method
ConvNets	I-Method
.	O
	
The	O
proposed	O
DLDL	B-Method
(	O
Deep	B-Method
Label	I-Method
Distribution	I-Method
Learning	I-Method
)	O
method	O
effectively	O
utilizes	O
the	O
label	O
ambiguity	O
in	O
both	O
feature	B-Method
learning	I-Method
and	O
classifier	B-Method
learning	I-Method
,	O
which	O
help	O
prevent	O
the	O
network	O
from	O
over	O
-	O
fitting	O
even	O
when	O
the	O
training	O
set	O
is	O
small	O
.	O
	
Experimental	O
results	O
show	O
that	O
the	O
proposed	O
approach	O
produces	O
significantly	O
better	O
results	O
than	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
methods	O
for	O
age	B-Task
estimation	I-Task
and	O
head	B-Task
pose	I-Task
estimation	I-Task
.	O
	
At	O
the	O
same	O
time	O
,	O
it	O
also	O
improves	O
recognition	B-Task
performance	O
for	O
multi	B-Task
-	I-Task
label	I-Task
classification	I-Task
and	I-Task
semantic	I-Task
segmentation	I-Task
tasks	I-Task
.	O
	
Label	B-Task
distribution	I-Task
,	O
deep	B-Task
learning	I-Task
,	O
age	B-Task
estimation	I-Task
,	O
head	B-Task
pose	I-Task
estimation	I-Task
,	O
semantic	B-Task
segmentation	I-Task
.	O
	
section	O
:	O
Introduction	O
	
Convolutional	B-Method
Neural	I-Method
Networks	I-Method
(	O
ConvNets	B-Method
)	O
have	O
achieved	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
performance	O
on	O
various	O
visual	B-Task
recognition	I-Task
tasks	I-Task
such	O
as	O
image	B-Task
classification	I-Task
,	O
object	O
detection	B-Task
and	O
semantic	B-Task
segmentation	I-Task
.	O
	
The	O
availability	O
of	O
a	O
huge	O
set	O
of	O
training	O
images	O
is	O
one	O
of	O
the	O
most	O
important	O
factors	O
for	O
their	O
success	O
.	O
	
However	O
,	O
it	O
is	O
difficult	O
to	O
collect	O
sufficient	O
training	O
images	O
with	O
unambiguous	O
labels	O
in	O
domains	O
such	O
as	O
age	B-Task
estimation	I-Task
,	O
head	B-Task
pose	I-Task
estimation	I-Task
,	O
multi	B-Task
-	I-Task
label	I-Task
classification	I-Task
and	O
semantic	B-Task
segmentation	I-Task
.	O
	
Therefore	O
,	O
exploiting	O
deep	B-Method
learning	I-Method
methods	I-Method
with	O
limited	O
samples	O
and	O
ambiguous	O
labels	O
has	O
become	O
an	O
attractive	O
yet	O
challenging	O
topic	O
.	O
	
Why	O
is	O
it	O
difficult	O
to	O
collect	O
a	O
large	O
and	O
accurately	O
labeled	O
training	O
set	O
?	O
	
Firstly	O
,	O
it	O
is	O
difficult	O
(	O
even	O
for	O
domain	O
experts	O
)	O
to	O
provide	O
exact	O
labels	O
to	O
some	O
tasks	O
.	O
	
For	O
example	O
,	O
the	O
pixels	O
close	O
to	O
object	O
boundaries	O
are	O
very	O
difficult	O
to	O
label	O
for	O
annotators	B-Task
in	O
semantic	B-Task
segmentation	I-Task
.	O
	
In	O
addition	O
,	O
pixel	B-Task
labeling	I-Task
is	O
a	O
time	O
-	O
consuming	O
task	O
that	O
may	O
limit	O
the	O
amount	O
of	O
training	O
samples	O
.	O
	
Another	O
example	O
is	O
that	O
people	O
’s	O
apparent	O
age	B-Task
and	O
head	O
pose	O
is	O
difficult	O
to	O
describe	O
with	O
an	O
accurate	O
number	O
.	O
	
Secondly	O
,	O
it	O
is	O
very	O
hard	O
to	O
gather	O
complete	O
and	O
sufficient	O
data	O
.	O
	
For	O
example	O
,	O
it	O
is	O
difficult	O
to	O
build	O
an	O
age	B-Task
dataset	O
covering	O
people	O
from	O
1	O
to	O
85	O
years	O
old	O
,	O
and	O
ensure	O
that	O
every	O
age	B-Task
in	O
this	O
range	O
has	O
enough	O
associated	O
images	O
.	O
	
Similar	O
difficulties	O
arise	O
in	O
head	B-Task
pose	I-Task
estimation	I-Task
,	O
where	O
head	O
poses	O
are	O
usually	O
collected	O
at	O
a	O
small	O
set	O
of	O
angles	O
with	O
a	O
10	O
or	O
15	O
increment	O
.	O
	
Thus	O
,	O
the	O
publicly	O
available	O
age	B-Task
,	O
head	O
pose	O
and	O
semantic	O
segmentation	O
datasets	O
are	O
small	O
scale	O
compared	O
to	O
those	O
in	O
image	B-Task
classification	I-Task
tasks	I-Task
.	O
	
These	O
aforementioned	O
small	O
datasets	O
have	O
a	O
common	O
characteristic	O
,	O
i.e.	O
,	O
label	B-Task
ambiguity	I-Task
,	O
which	O
refers	O
to	O
the	O
uncertainty	O
among	O
the	O
ground	O
-	O
truth	O
labels	O
.	O
	
On	O
one	O
hand	O
,	O
label	O
ambiguity	O
is	O
unavoidable	O
in	O
some	O
applications	O
.	O
	
We	O
usually	O
predict	O
another	O
person	O
’s	O
age	B-Task
in	O
a	O
way	O
like	O
“	O
around	O
25	O
”	O
,	O
which	O
indicates	O
using	O
not	O
only	O
25	O
,	O
but	O
also	O
neighboring	O
ages	O
to	O
describe	O
the	O
face	O
.	O
	
And	O
,	O
different	O
people	O
may	O
have	O
different	O
guesses	O
towards	O
the	O
same	O
face	O
.	O
	
Similar	O
situations	O
also	O
hold	O
for	O
other	O
types	O
of	O
tasks	O
.	O
	
The	O
labels	O
of	O
pixels	O
at	O
object	O
boundaries	O
are	O
difficult	O
to	O
annotate	O
because	O
of	O
the	O
inherent	O
ambiguity	O
of	O
these	O
pixels	O
in	O
semantic	B-Task
segmentation	I-Task
.	O
	
On	O
the	O
other	O
hand	O
,	O
label	B-Task
ambiguity	I-Task
can	O
also	O
happen	O
if	O
we	O
are	O
not	O
confident	O
in	O
the	O
labels	O
we	O
provide	O
for	O
an	O
image	O
.	O
	
In	O
the	O
multi	B-Task
-	I-Task
label	I-Task
classification	I-Task
task	I-Task
,	O
some	O
objects	O
are	O
clearly	O
visible	O
but	O
difficult	O
to	O
recognize	O
.	O
	
This	O
type	O
of	O
objects	O
are	O
annotated	O
as	O
Difficult	O
in	O
the	O
PASCAL	B-Task
Visual	I-Task
Object	I-Task
Classes	I-Task
(	I-Task
VOC	I-Task
)	I-Task
classification	I-Task
challenge	I-Task
,	O
e.g.	O
,	O
the	O
chair	O
in	O
the	O
third	O
image	O
of	O
the	O
first	O
row	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
.	O
	
[	O
Age	O
estimation	B-Task
]	O
	
[	O
Head	B-Task
pose	I-Task
estimation	I-Task
]	O
	
[	O
Multi	B-Task
-	I-Task
label	I-Task
classification	I-Task
]	O
	
[	O
Semantic	B-Task
segmentation	I-Task
]	O
	
There	O
are	O
two	O
main	O
types	O
of	O
labeling	B-Method
methods	I-Method
:	O
single	B-Method
-	I-Method
label	I-Method
recognition	I-Method
(	O
SLR	B-Method
)	O
and	O
multi	B-Method
-	I-Method
label	I-Method
recognition	I-Method
(	O
MLR	B-Method
)	O
.	O
	
SLR	B-Method
assumes	O
one	O
image	O
or	O
pixel	O
	
has	O
one	O
label	O
and	O
MLR	B-Method
assumes	O
that	O
one	O
image	O
or	O
pixel	O
may	O
be	O
assigned	O
multiple	O
labels	O
.	O
	
Both	O
SLR	B-Method
and	O
MLR	B-Method
aim	O
to	O
answer	O
the	O
question	O
of	O
which	O
labels	O
can	O
be	O
used	O
to	O
describe	O
an	O
image	O
or	O
pixel	O
,	O
but	O
they	O
can	O
not	O
describe	O
the	O
label	O
ambiguity	O
associated	O
with	O
it	O
.	O
	
Label	B-Task
ambiguity	I-Task
will	O
help	O
improve	O
recognition	B-Task
performance	O
if	O
it	O
can	O
be	O
reasonably	O
exploited	O
.	O
	
In	O
order	O
to	O
utilize	O
label	O
correlation	O
(	O
which	O
may	O
be	O
considered	O
as	O
a	O
consequence	O
of	O
label	O
ambiguity	O
in	O
some	O
applications	O
)	O
,	O
Geng	O
et	O
al	O
.	O
proposed	O
a	O
label	B-Method
distribution	I-Method
learning	I-Method
(	I-Method
LDL	I-Method
)	I-Method
approach	I-Method
for	O
age	B-Task
estimation	I-Task
and	O
head	B-Task
pose	I-Task
estimation	I-Task
.	O
	
Recently	O
,	O
some	O
improvements	O
of	O
LDL	B-Method
have	O
been	O
proposed	O
.	O
	
Xing	O
et	O
al	O
.	O
	
proposed	O
two	O
algorithms	O
named	O
LDLogitBoost	B-Method
and	O
AOSO	B-Method
-	I-Method
LDLogitBoost	I-Method
to	O
learn	O
general	B-Method
models	I-Method
to	O
relax	O
the	O
maximum	B-Method
entropy	I-Method
model	I-Method
in	O
traditional	O
LDL	B-Method
methods	O
.	O
	
Furthermore	O
,	O
He	O
et	O
al	O
.	O
generated	O
age	B-Task
label	O
distributions	O
through	O
weighted	B-Method
linear	I-Method
combination	I-Method
of	O
the	O
input	O
image	O
’s	O
label	O
and	O
its	O
context	O
-	O
neighboring	O
samples	O
.	O
	
However	O
,	O
these	O
methods	O
are	O
suboptimal	O
because	O
they	O
only	O
utilize	O
the	O
correlation	O
of	O
neighboring	O
labels	O
in	O
classifier	B-Task
learning	I-Task
,	O
but	O
not	O
in	O
learning	O
the	O
visual	B-Task
representations	I-Task
.	O
	
Deep	B-Method
ConvNets	I-Method
have	O
natural	O
advantages	O
in	O
feature	B-Task
learning	I-Task
.	O
	
Existing	O
ConvNet	B-Method
frameworks	I-Method
can	O
be	O
viewed	O
as	O
classification	B-Method
and	I-Method
regression	I-Method
models	I-Method
based	O
on	O
different	O
optimization	B-Metric
objective	I-Metric
functions	I-Metric
.	O
	
In	O
many	O
cases	O
,	O
the	O
softmax	O
loss	O
and	O
loss	B-Method
are	O
used	O
in	O
deep	B-Method
ConvNet	I-Method
models	I-Method
for	O
classification	B-Task
and	I-Task
regression	I-Task
problems	I-Task
,	O
respectively	O
.	O
	
The	O
softmax	O
loss	O
maximizes	O
the	O
estimated	O
probability	O
of	O
the	O
ground	O
-	O
truth	O
class	O
without	O
considering	O
other	O
classes	O
,	O
and	O
the	O
loss	O
minimizes	O
the	O
squared	O
difference	O
between	O
the	O
estimated	O
values	O
of	O
the	O
network	O
and	O
the	O
ground	O
-	O
truth	O
.	O
	
These	O
methods	O
have	O
achieved	O
satisfactory	O
performance	O
in	O
some	O
domains	O
such	O
as	O
image	B-Task
classification	I-Task
,	O
human	B-Task
pose	I-Task
estimation	I-Task
and	O
object	O
detection	B-Task
.	O
	
However	O
,	O
existing	O
deep	B-Method
learning	I-Method
methods	I-Method
can	O
not	O
utilize	O
the	O
label	O
ambiguity	O
information	O
.	O
	
Moreover	O
,	O
a	O
well	O
-	O
known	O
fact	O
is	O
that	O
learning	O
a	O
good	O
ConvNet	B-Method
requires	O
a	O
lot	O
of	O
images	O
.	O
	
In	O
order	O
to	O
solve	O
the	O
issues	O
mentioned	O
above	O
,	O
we	O
convert	O
both	O
traditional	O
SLR	B-Method
and	O
MLR	B-Task
problems	I-Task
to	O
label	B-Task
distribution	I-Task
learning	I-Task
problems	I-Task
.	O
	
Every	O
instance	O
is	O
assigned	O
a	O
discrete	O
label	O
distribution	O
according	O
to	O
its	O
ground	O
-	O
truth	O
.	O
	
The	O
label	O
distribution	O
can	O
naturally	O
describe	O
the	O
ambiguous	O
information	O
among	O
all	O
possible	O
labels	O
.	O
	
Through	O
deep	B-Method
label	I-Method
distribution	I-Method
learning	I-Method
,	O
the	O
training	O
instances	O
associated	O
with	O
each	O
class	O
label	O
is	O
significantly	O
increased	O
without	O
actually	O
increase	O
the	O
number	O
of	O
the	O
total	O
training	O
examples	O
.	O
	
Fig	O
.	O
	
[	O
reference	O
]	O
intuitively	O
shows	O
four	O
examples	O
of	O
label	B-Task
distribution	I-Task
for	O
different	O
recognition	B-Task
tasks	I-Task
.	O
	
Then	O
,	O
we	O
utilize	O
a	O
deep	B-Method
ConvNet	I-Method
to	O
learn	O
the	O
label	O
distribution	O
in	O
both	O
feature	B-Task
learning	I-Task
and	O
classifier	B-Task
learning	I-Task
.	O
	
Since	O
we	O
learn	O
label	B-Task
distribution	I-Task
with	O
deep	B-Method
ConvNets	I-Method
,	O
we	O
call	O
our	O
method	O
DLDL	B-Method
:	O
Deep	B-Method
Label	I-Method
Distribution	I-Method
Learning	I-Method
.	O
	
The	O
benefits	O
of	O
DLDL	B-Method
are	O
summarized	O
as	O
follows	O
:	O
DLDL	B-Method
is	O
an	O
end	B-Method
-	I-Method
to	I-Method
-	I-Method
end	I-Method
learning	I-Method
framework	I-Method
which	O
utilizes	O
the	O
label	O
ambiguity	O
in	O
both	O
feature	B-Method
learning	I-Method
and	O
classifier	B-Method
learning	I-Method
;	O
DLDL	B-Method
not	O
only	O
achieves	O
more	O
robust	O
performance	O
than	O
existing	O
classification	B-Method
and	I-Method
regression	I-Method
methods	I-Method
,	O
but	O
also	O
effectively	O
relaxes	O
the	O
requirement	O
for	O
large	O
amount	O
of	O
training	O
images	O
,	O
e.g.	O
,	O
a	O
training	O
face	O
image	O
with	O
ground	O
-	O
truth	O
label	O
	
25	O
is	O
also	O
useful	O
for	O
predicting	B-Task
faces	I-Task
at	O
age	B-Task
24	O
or	O
26	O
;	O
DLDL	B-Method
(	O
only	O
single	B-Method
model	I-Method
without	O
ensemble	B-Method
)	O
achieves	O
better	O
performance	O
than	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
methods	O
on	O
age	B-Task
and	O
head	B-Task
pose	I-Task
estimation	I-Task
tasks	I-Task
.	O
	
DLDL	B-Method
also	O
improves	O
the	O
performance	O
for	O
multi	B-Task
-	I-Task
label	I-Task
classification	I-Task
and	I-Task
semantic	I-Task
segmentation	I-Task
.	O
	
The	O
rest	O
of	O
this	O
paper	O
is	O
organized	O
as	O
follows	O
.	O
	
We	O
first	O
review	O
the	O
related	O
work	O
in	O
Section	O
[	O
reference	O
]	O
.	O
	
Then	O
,	O
Section	O
[	O
reference	O
]	O
proposes	O
the	O
DLDL	B-Method
framework	O
,	O
including	O
the	O
DLDL	B-Method
problem	O
definition	O
,	O
DLDL	B-Method
theory	O
,	O
label	B-Method
distribution	I-Method
construction	I-Method
and	O
training	O
details	O
.	O
	
After	O
that	O
,	O
the	O
experiments	O
are	O
reported	O
in	O
Section	O
[	O
reference	O
]	O
.	O
	
Finally	O
,	O
Section	O
[	O
reference	O
]	O
presents	O
discussions	O
and	O
the	O
conclusion	O
is	O
given	O
in	O
Section	O
[	O
reference	O
]	O
.	O
	
section	O
:	O
Related	O
Work	O
	
In	O
the	O
past	O
two	O
decades	O
,	O
many	O
efforts	O
have	O
been	O
devoted	O
to	O
visual	B-Task
recognition	I-Task
,	O
including	O
at	O
least	O
image	B-Task
classification	I-Task
,	O
object	O
detection	B-Task
,	O
semantic	B-Task
segmentation	I-Task
,	O
and	O
facial	B-Task
attribute	I-Task
(	O
apparent	O
age	B-Task
and	O
head	O
pose	O
)	O
estimation	B-Task
.	O
	
These	O
works	O
can	O
be	O
divided	O
into	O
two	O
streams	O
.	O
	
Earlier	O
research	O
was	O
mainly	O
based	O
on	O
hand	O
-	O
crafted	O
features	O
,	O
while	O
more	O
recent	O
ones	O
are	O
usually	O
deep	B-Method
learning	I-Method
methods	I-Method
.	O
	
In	O
this	O
section	O
,	O
we	O
briefly	O
review	O
these	O
related	O
approaches	O
.	O
	
Methods	O
based	O
on	O
hand	O
-	O
crafted	O
features	O
usually	O
include	O
two	O
stages	O
.	O
	
The	O
first	O
stage	O
is	O
feature	B-Task
extraction	I-Task
.	O
	
The	O
second	O
stage	O
learns	O
models	O
for	O
recognition	B-Task
,	O
detection	B-Task
or	O
estimation	B-Task
using	O
these	O
features	O
.	O
	
SVM	B-Method
,	O
random	B-Method
forest	I-Method
and	O
neural	B-Method
networks	I-Method
have	O
commonly	O
been	O
used	O
during	O
the	O
learning	B-Task
stage	I-Task
.	O
	
In	O
addition	O
,	O
Geng	O
et	O
al	O
.	O
proposed	O
the	O
label	B-Method
distribution	I-Method
learning	I-Method
approach	I-Method
to	O
utilize	O
the	O
correlation	O
among	O
adjacent	O
labels	O
,	O
which	O
further	O
improved	O
performance	O
on	O
age	B-Task
estimation	I-Task
and	O
head	B-Task
pose	I-Task
estimation	I-Task
.	O
	
Although	O
important	O
progresses	O
have	O
been	O
made	O
with	O
these	O
features	O
,	O
the	O
hand	B-Method
-	I-Method
crafted	I-Method
features	I-Method
render	O
them	O
suboptimal	O
for	O
particular	O
tasks	O
such	O
as	O
age	B-Task
or	O
head	B-Task
pose	I-Task
estimation	I-Task
.	O
	
More	O
recently	O
,	O
learning	B-Method
feature	I-Method
representation	I-Method
has	O
shown	O
great	O
advantages	O
.	O
	
For	O
example	O
,	O
Lu	O
et	O
al	O
.	O
tried	O
to	O
learn	O
cost	O
-	O
sensitive	O
local	O
binary	O
features	O
for	O
age	B-Task
estimation	I-Task
.	O
	
Deep	B-Method
learning	I-Method
has	O
substantially	O
improved	O
upon	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
in	O
image	B-Task
classification	I-Task
,	O
object	O
detection	B-Task
,	O
semantic	B-Task
segmentation	I-Task
and	O
many	O
other	O
vision	B-Task
tasks	I-Task
.	O
	
In	O
many	O
cases	O
,	O
the	O
softmax	O
loss	O
is	O
used	O
in	O
deep	B-Method
models	I-Method
for	O
classification	B-Task
.	O
	
Besides	O
classification	B-Task
,	O
deep	B-Method
ConvNets	I-Method
have	O
also	O
been	O
trained	O
for	O
regression	B-Task
tasks	I-Task
such	O
as	O
head	B-Task
pose	I-Task
estimation	I-Task
and	O
facial	O
landmark	O
detection	B-Task
.	O
	
In	O
regression	B-Task
problems	I-Task
,	O
the	O
training	B-Method
procedure	I-Method
usually	O
optimizes	O
a	O
squared	O
loss	O
function	O
.	O
	
Satisfactory	O
performance	O
has	O
also	O
been	O
obtained	O
by	O
using	O
Tukey	B-Method
’s	I-Method
biweight	I-Method
function	I-Method
in	O
human	B-Task
pose	I-Task
estimation	I-Task
.	O
	
In	O
terms	O
of	O
model	B-Method
architecture	I-Method
,	O
deep	B-Method
ConvNet	I-Method
models	I-Method
which	O
use	O
deeper	B-Method
architecture	I-Method
and	O
smaller	O
convolution	B-Method
filters	I-Method
(	O
e.g.	O
,	O
VGG	B-Method
-	I-Method
Nets	I-Method
and	O
VGG	B-Method
-	I-Method
Face	I-Method
)	O
are	O
very	O
powerful	O
.	O
	
Nevertheless	O
,	O
these	O
deep	B-Method
learning	I-Method
methods	I-Method
do	O
not	O
make	O
use	O
of	O
the	O
presence	O
of	O
label	O
ambiguity	O
in	O
the	O
training	O
set	O
,	O
and	O
usually	O
require	O
a	O
large	O
amount	O
of	O
training	O
data	O
.	O
	
A	O
latest	O
approach	O
,	O
in	O
Inception	O
-	O
v3	O
,	O
is	O
based	O
on	O
label	B-Method
smoothing	I-Method
(	O
LS	B-Method
)	O
.	O
	
Instead	O
of	O
only	O
using	O
the	O
ground	O
-	O
truth	O
label	O
,	O
they	O
utilize	O
a	O
mixture	O
of	O
the	O
ground	O
-	O
truth	O
label	O
and	O
a	O
uniform	O
distribution	O
to	O
regularize	O
the	O
classifier	B-Method
.	O
	
However	O
,	O
LS	B-Method
is	O
limited	O
to	O
the	O
uniform	O
distribution	O
among	O
labels	O
rather	O
than	O
mining	O
labels	O
’	O
ambiguous	O
information	O
.	O
	
We	O
believe	O
that	O
label	O
ambiguity	O
is	O
too	O
important	O
to	O
ignore	O
.	O
	
If	O
we	O
make	O
good	O
use	O
of	O
the	O
ambiguity	O
,	O
we	O
expect	O
the	O
required	O
number	O
of	O
training	O
images	O
for	O
some	O
tasks	O
could	O
be	O
effectively	O
reduced	O
.	O
	
In	O
this	O
paper	O
,	O
we	O
focus	O
on	O
how	O
to	O
exploit	O
the	O
label	O
ambiguity	O
in	O
deep	B-Task
ConvNets	I-Task
.	O
	
Age	B-Task
and	O
head	B-Task
pose	I-Task
estimation	I-Task
from	O
still	O
face	O
images	O
are	O
suitable	O
applications	O
of	O
the	O
proposed	O
research	O
.	O
	
In	O
addition	O
,	O
we	O
also	O
extend	O
our	O
works	O
to	O
multi	B-Task
-	I-Task
label	I-Task
classification	I-Task
and	O
semantic	B-Task
segmentation	I-Task
.	O
	
section	O
:	O
The	O
Proposed	O
DLDL	B-Method
Approach	O
	
In	O
this	O
section	O
,	O
we	O
firstly	O
give	O
the	O
definition	O
of	O
the	O
DLDL	B-Method
problem	O
.	O
	
Then	O
,	O
we	O
present	O
the	O
DLDL	B-Method
theory	O
.	O
	
Next	O
,	O
we	O
propose	O
the	O
construction	B-Method
methods	I-Method
of	O
label	B-Task
distribution	I-Task
for	O
different	O
recognition	B-Task
tasks	I-Task
.	O
	
Finally	O
,	O
we	O
briefly	O
introduce	O
the	O
DLDL	B-Method
architecture	O
and	O
training	O
details	O
.	O
	
subsection	O
:	O
The	O
deep	B-Method
label	I-Method
distribution	I-Method
learning	I-Method
problem	I-Method
	
Given	O
an	O
input	O
image	O
,	O
we	O
are	O
interested	O
in	O
estimating	O
a	O
category	O
output	O
(	O
e.g.	O
,	O
age	B-Task
or	O
head	O
pose	O
angles	O
)	O
.	O
	
For	O
two	O
input	O
images	O
and	O
with	O
ground	O
-	O
truth	O
labels	O
and	O
,	O
and	O
are	O
supposed	O
to	O
be	O
similar	O
to	O
each	O
other	O
if	O
the	O
correlation	O
of	O
and	O
is	O
strong	O
,	O
and	O
vice	O
versa	O
.	O
	
For	O
example	O
,	O
the	O
correlation	O
between	O
faces	O
aged	O
32	O
and	O
33	O
should	O
be	O
stronger	O
than	O
that	O
between	O
faces	O
aged	O
32	O
and	O
64	O
,	O
in	O
terms	O
of	O
facial	O
details	O
that	O
reflect	O
the	O
age	B-Task
(	O
e.g.	O
,	O
skin	O
smoothness	O
)	O
.	O
	
In	O
other	O
words	O
,	O
we	O
expect	O
high	O
correlation	O
among	O
input	O
images	O
with	O
similar	O
outputs	O
.	O
	
The	O
label	B-Method
distribution	I-Method
learning	I-Method
approach	I-Method
exploited	O
such	O
correlations	O
in	O
the	O
machine	B-Task
learning	I-Task
phase	I-Task
,	O
but	O
used	O
features	O
that	O
are	O
extracted	O
ignoring	O
these	O
correlations	O
.	O
	
The	O
proposed	O
DLDL	B-Method
approach	O
,	O
however	O
,	O
is	O
an	O
end	O
-	O
to	O
-	O
end	B-Method
deep	I-Method
learning	I-Method
method	I-Method
which	O
utilizes	O
such	O
correlation	O
information	O
in	O
both	O
feature	B-Method
learning	I-Method
and	O
classifier	B-Method
learning	I-Method
.	O
	
We	O
will	O
also	O
extend	O
DLDL	B-Method
to	O
handle	O
other	O
types	O
of	O
label	O
ambiguity	O
beyond	O
correlation	O
.	O
	
To	O
fulfill	O
this	O
goal	O
,	O
instead	O
of	O
outputting	O
a	O
single	O
value	O
for	O
an	O
input	O
,	O
DLDL	B-Method
quantizes	O
the	O
range	O
of	O
possible	O
values	O
into	O
several	O
labels	O
.	O
	
For	O
example	O
,	O
in	O
age	B-Task
estimation	I-Task
,	O
it	O
is	O
reasonable	O
to	O
assume	O
that	O
,	O
and	O
it	O
is	O
a	O
common	O
practice	O
to	O
estimate	O
integer	O
values	O
for	O
ages	O
.	O
	
Thus	O
,	O
we	O
can	O
define	O
the	O
set	O
as	O
the	O
ordered	O
label	O
set	O
for	O
age	B-Task
estimation	I-Task
.	O
	
The	O
task	O
of	O
DLDL	B-Method
is	O
then	O
to	O
predict	O
a	O
label	B-Task
distribution	I-Task
,	O
where	O
is	O
the	O
estimated	O
probability	O
that	O
should	O
be	O
predicted	O
to	O
be	O
years	O
old	O
.	O
	
By	O
estimating	O
an	O
entire	O
label	B-Task
distribution	I-Task
,	O
the	O
deep	B-Method
learning	I-Method
machine	I-Method
is	O
forced	O
to	O
take	O
care	O
of	O
the	O
ambiguity	O
among	O
labels	O
.	O
	
Specifically	O
,	O
the	O
input	O
space	O
of	O
our	O
framework	O
is	O
,	O
where	O
,	O
and	O
are	O
the	O
height	O
,	O
width	O
,	O
and	O
number	O
of	O
channels	O
of	O
the	O
input	O
image	O
,	O
respectively	O
.	O
	
DLDL	B-Method
predicts	O
a	O
label	O
distribution	O
vector	O
,	O
where	O
is	O
the	O
label	O
set	O
defined	O
for	O
a	O
specific	O
task	O
(	O
e.g.	O
,	O
the	O
above	O
)	O
.	O
	
We	O
assume	O
is	O
complete	O
,	O
i.e.	O
,	O
any	O
possible	O
value	O
has	O
a	O
corresponding	O
member	O
in	O
.	O
	
A	O
training	O
data	O
set	O
with	O
instances	O
is	O
then	O
denoted	O
as	O
.	O
	
We	O
use	O
boldface	O
lowercase	O
letters	O
like	O
to	O
denote	O
vectors	O
,	O
and	O
the	O
-	O
th	O
element	O
of	O
is	O
denoted	O
as	O
.	O
	
The	O
goal	O
of	O
DLDL	B-Method
is	O
to	O
directly	O
learn	O
a	O
conditional	O
probability	O
mass	O
function	O
from	O
,	O
where	O
is	O
the	O
parameters	O
in	O
the	O
framework	O
.	O
	
subsection	O
:	O
Deep	B-Method
label	I-Method
distribution	I-Method
learning	I-Method
	
Given	O
an	O
instance	O
with	O
label	O
distribution	O
,	O
we	O
assume	O
that	O
is	O
the	O
activation	O
of	O
the	O
last	O
fully	B-Method
connected	I-Method
layer	I-Method
in	O
a	O
deep	B-Method
ConvNet	I-Method
.	O
	
We	O
use	O
a	O
softmax	O
function	O
to	O
turn	O
these	O
activations	O
into	O
a	O
probability	O
distribution	O
,	O
that	O
is	O
,	O
Given	O
a	O
training	O
data	O
set	O
,	O
the	O
goal	O
of	O
DLDL	B-Method
is	O
to	O
find	O
to	O
generate	O
a	O
distribution	O
that	O
is	O
similar	O
to	O
.	O
	
There	O
are	O
different	O
criteria	O
to	O
measure	O
the	O
similarity	O
or	O
distance	O
between	O
two	O
distributions	O
.	O
	
For	O
example	O
,	O
if	O
the	O
Kullback	O
-	O
Leibler	O
(	O
KL	B-Metric
)	I-Metric
divergence	I-Metric
is	O
used	O
as	O
the	O
measurement	O
of	O
the	O
similarity	O
between	O
the	O
ground	O
-	O
truth	O
and	O
predicted	O
label	O
distribution	O
,	O
then	O
the	O
best	O
parameter	O
is	O
determined	O
by	O
Thus	O
,	O
we	O
can	O
define	O
the	O
loss	O
function	O
as	O
:	O
Stochastic	B-Method
gradient	I-Method
descent	I-Method
is	O
used	O
to	O
minimize	O
the	O
objective	O
function	O
Eq	O
.	O
	
[	O
reference	O
]	O
.	O
	
For	O
any	O
and	O
,	O
and	O
the	O
derivative	O
of	O
softmax	O
(	O
Eq	O
.	O
	
[	O
reference	O
]	O
)	O
is	O
well	O
known	O
,	O
as	O
where	O
is	O
1	O
if	O
,	O
and	O
0	O
otherwise	O
.	O
	
According	O
to	O
the	O
chain	O
rule	O
,	O
for	O
any	O
fixed	O
,	O
we	O
have	O
	
Thus	O
,	O
the	O
derivative	O
of	O
with	O
respect	O
to	O
is	O
Once	O
is	O
learned	O
,	O
the	O
label	O
distribution	O
of	O
any	O
new	O
instance	O
can	O
be	O
generated	O
by	O
a	O
forward	B-Method
run	I-Method
of	O
the	O
network	O
.	O
	
If	O
the	O
expected	O
class	O
label	O
is	O
a	O
single	O
one	O
,	O
DLDL	B-Method
outputs	O
,	O
where	O
Prediction	B-Task
with	O
multiple	O
labels	O
is	O
also	O
allowed	O
,	O
which	O
could	O
be	O
a	O
set	O
where	O
is	O
a	O
predefined	O
threshold	O
.	O
	
If	O
the	O
expected	O
output	O
is	O
a	O
real	O
number	O
,	O
DLDL	B-Method
predicts	O
the	O
expectation	O
of	O
,	O
as	O
where	O
.	O
	
This	O
indicates	O
that	O
DLDL	B-Method
is	O
suitable	O
for	O
both	O
classification	B-Task
and	I-Task
regression	I-Task
tasks	I-Task
.	O
	
subsection	O
:	O
Label	B-Method
distribution	I-Method
construction	I-Method
	
The	O
ground	O
-	O
truth	O
label	O
distribution	O
is	O
not	O
available	O
in	O
most	O
existing	O
datasets	O
,	O
which	O
must	O
be	O
generated	O
under	O
proper	O
assumptions	O
.	O
	
A	O
desirable	O
label	B-Method
distribution	I-Method
must	O
satisfy	O
some	O
basic	O
principles	O
:	O
(	O
1	O
)	O
should	O
be	O
a	O
probability	B-Method
distribution	I-Method
.	O
	
Thus	O
,	O
we	O
have	O
and	O
.	O
	
(	O
2	O
)	O
	
The	O
probability	O
values	O
should	O
have	O
difference	O
among	O
all	O
possible	O
labels	O
associated	O
with	O
an	O
image	O
.	O
	
In	O
other	O
words	O
,	O
a	O
less	O
ambiguous	O
category	O
must	O
be	O
assigned	O
high	O
probability	O
and	O
those	O
more	O
ambiguous	O
labels	O
must	O
have	O
low	O
probabilities	O
.	O
	
In	O
this	O
section	O
,	O
we	O
propose	O
the	O
way	O
to	O
construct	O
label	O
distributions	O
for	O
age	B-Task
estimation	I-Task
,	O
head	B-Task
pose	I-Task
estimation	I-Task
,	O
multi	B-Task
-	I-Task
label	I-Task
classification	I-Task
and	O
semantic	B-Task
segmentation	I-Task
.	O
	
For	O
age	B-Task
estimation	I-Task
,	O
we	O
assume	O
that	O
the	O
probabilities	O
should	O
concentrate	O
around	O
the	O
ground	O
-	O
truth	O
age	B-Task
.	O
	
Thus	O
,	O
we	O
quantize	O
to	O
get	O
using	O
a	O
normal	B-Method
distribution	I-Method
.	O
	
For	O
example	O
,	O
the	O
apparent	O
age	B-Task
of	O
a	O
face	O
is	O
labeled	O
by	O
hundreds	O
of	O
users	O
.	O
	
The	O
ground	O
-	O
truth	O
(	O
including	O
a	O
mean	O
and	O
a	O
standard	O
deviation	O
)	O
is	O
calculated	O
from	O
all	O
the	O
votes	O
.	O
	
For	O
this	O
problem	O
,	O
we	O
find	O
the	O
range	O
of	O
the	O
target	O
(	O
e.g.	O
,	O
)	O
,	O
quantize	O
it	O
into	O
a	O
complete	O
and	O
ordered	O
label	O
set	O
,	O
where	O
is	O
the	O
label	O
set	O
size	O
and	O
are	O
all	O
possible	O
predictions	O
for	O
.	O
	
A	O
label	B-Method
distribution	I-Method
is	O
then	O
,	O
where	O
is	O
the	O
probability	O
that	O
(	O
i.e.	O
,	O
for	O
)	O
.	O
	
Since	O
we	O
use	O
equal	O
step	O
size	O
in	O
quantizing	B-Task
,	O
the	O
normal	B-Method
p.d.f	I-Method
.	O
	
(	O
probability	B-Method
density	I-Method
function	I-Method
)	O
is	O
a	O
natural	O
choice	O
to	O
generate	O
the	O
ground	O
-	O
truth	O
from	O
and	O
:	O
where	O
.	O
	
Fig	O
.	O
	
[	O
reference	O
]	O
shows	O
a	O
face	O
and	O
its	O
corresponding	O
label	O
distribution	O
.	O
	
For	O
problems	O
where	O
is	O
unknown	O
,	O
we	O
will	O
show	O
that	O
a	O
reasonably	O
chosen	O
also	O
works	O
well	O
in	O
DLDL	B-Method
.	O
	
For	O
head	B-Task
pose	I-Task
estimation	I-Task
,	O
we	O
need	O
to	O
jointly	O
estimate	O
pitch	O
and	O
yaw	O
angles	O
.	O
	
Thus	O
,	O
learning	B-Task
joint	I-Task
distribution	I-Task
is	O
also	O
necessary	O
in	O
DLDL	B-Method
.	O
	
Suppose	O
the	O
label	O
set	O
is	O
,	O
where	O
is	O
a	O
pair	O
of	O
values	O
.	O
	
That	O
is	O
,	O
we	O
want	O
to	O
learn	O
the	O
joint	O
distribution	O
of	O
two	O
variables	O
.	O
	
Then	O
,	O
the	O
label	O
distribution	O
can	O
be	O
represented	O
by	O
an	O
matrix	O
,	O
whose	O
-	O
th	O
element	O
is	O
.	O
	
For	O
example	O
,	O
when	O
we	O
use	O
two	O
angles	O
(	O
pitch	O
and	O
yaw	O
)	O
to	O
describe	O
a	O
head	O
pose	O
,	O
is	O
a	O
pair	O
of	O
pitch	O
and	O
yaw	O
angles	O
.	O
	
Given	O
an	O
instance	O
with	O
ground	O
-	O
truth	O
mean	O
and	O
covariance	O
matrix	O
,	O
we	O
calculate	O
its	O
label	B-Method
distribution	I-Method
as	O
where	O
.	O
	
In	O
the	O
above	O
,	O
we	O
assume	O
,	O
that	O
is	O
,	O
the	O
covariance	O
matrix	O
is	O
diagonal	O
.	O
	
Fig	O
.	O
	
[	O
reference	O
]	O
shows	O
a	O
joint	O
label	O
distribution	O
with	O
head	O
pose	O
and	O
.	O
	
For	O
multi	B-Task
-	I-Task
label	I-Task
classification	I-Task
,	O
a	O
multi	O
-	O
label	O
image	O
always	O
contains	O
at	O
least	O
one	O
object	O
of	O
the	O
class	O
of	O
interest	O
.	O
	
There	O
are	O
usually	O
multiple	O
labels	O
for	O
an	O
image	O
.	O
	
These	O
labels	O
are	O
grouped	O
into	O
three	O
different	O
levels	O
,	O
including	O
Positive	O
,	O
Negative	O
and	O
Difficult	O
in	O
the	O
PASCAL	O
VOC	O
dataset	O
.	O
	
A	O
label	O
is	O
Positive	O
means	O
an	O
image	O
contains	O
objects	O
from	O
that	O
category	O
,	O
and	O
	
Negative	O
otherwise	O
.	O
	
Difficult	O
indicates	O
that	O
an	O
object	O
is	O
clearly	O
visible	O
but	O
difficult	O
to	O
recognize	O
.	O
	
Existing	O
multi	B-Method
-	I-Method
label	I-Method
methods	I-Method
often	O
view	O
Difficult	O
as	O
Negative	O
,	O
which	O
leads	O
to	O
the	O
loss	O
of	O
useful	O
information	O
.	O
	
It	O
is	O
not	O
reasonable	O
either	O
if	O
we	O
simply	O
treat	O
Difficult	O
as	O
Positive	O
.	O
	
Therefore	O
,	O
a	O
nature	O
choice	O
is	O
to	O
use	O
label	O
ambiguity	O
.	O
	
We	O
define	O
different	O
probabilities	O
for	O
different	O
types	O
of	O
labels	O
,	O
as	O
for	O
Positive	O
,	O
Difficult	O
and	O
Negative	O
labels	O
,	O
respectively	O
.	O
	
Furthermore	O
,	O
an	O
normalization	B-Method
is	O
applied	O
to	O
ensure	O
:	O
where	O
equals	O
,	O
or	O
if	O
the	O
label	O
is	O
Positive	O
,	O
Difficult	O
or	O
Negative	O
,	O
respectively	O
.	O
	
The	O
label	B-Task
distribution	I-Task
is	O
shown	O
for	O
a	O
multi	O
-	O
label	O
image	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
.	O
	
For	O
semantic	B-Task
segmentation	I-Task
,	O
we	O
need	O
to	O
label	O
a	O
pixel	O
as	O
belonging	O
to	O
one	O
class	O
if	O
it	O
is	O
a	O
pixel	O
inside	O
an	O
object	O
of	O
that	O
class	O
,	O
or	O
as	O
the	O
background	O
otherwise	O
.	O
	
Let	O
denote	O
the	O
annotation	O
of	O
the	O
-	O
th	O
pixel	O
,	O
where	O
(	O
assuming	O
there	O
are	O
categories	O
and	O
0	O
for	O
background	O
)	O
.	O
	
Fully	B-Method
Convolutional	I-Method
Networks	I-Method
(	O
FCN	B-Method
)	O
have	O
been	O
an	O
effective	O
solution	O
to	O
this	O
task	O
.	O
	
In	O
FCN	B-Method
,	O
a	O
ground	O
-	O
truth	O
label	O
means	O
that	O
and	O
for	O
all	O
.	O
	
However	O
,	O
it	O
is	O
very	O
difficult	O
to	O
specify	O
ground	O
-	O
truth	O
labels	O
for	O
pixels	O
close	O
to	O
object	O
boundaries	O
,	O
because	O
labels	O
of	O
these	O
pixels	O
are	O
inherently	O
ambiguous	O
.	O
	
We	O
propose	O
a	O
mechanism	O
to	O
describe	O
the	O
label	O
ambiguity	O
in	O
the	O
boundaries	O
.	O
	
Considering	O
a	O
Gaussian	B-Method
kernel	I-Method
matrix	I-Method
,	O
we	O
replace	O
the	O
original	O
label	O
distribution	O
with	O
,	O
as	O
where	O
,	O
,	O
is	O
the	O
kernel	O
size	O
,	O
and	O
are	O
padding	O
and	O
stride	O
sizes	O
.	O
	
In	O
our	O
experiment	O
,	O
we	O
set	O
,	O
and	O
,	O
and	O
the	O
generated	O
label	O
distribution	O
is	O
Fig	O
.	O
	
[	O
reference	O
]	O
gives	O
the	O
semantic	O
label	O
distribution	O
for	O
a	O
bird	O
image	O
which	O
shows	O
that	O
the	O
ambiguity	O
is	O
encoded	O
in	O
the	O
label	O
distributions	O
.	O
	
subsection	O
:	O
The	O
DLDL	B-Method
architecture	O
and	O
training	O
details	O
	
We	O
use	O
a	O
deep	B-Method
ConvNet	I-Method
and	O
a	O
training	O
set	O
to	O
learn	O
a	O
as	O
the	O
estimation	B-Task
of	O
.	O
	
The	O
structure	O
of	O
our	O
network	O
is	O
based	O
on	O
popular	O
deep	B-Method
models	I-Method
such	O
as	O
ZF	B-Method
-	I-Method
Net	I-Method
and	O
VGG	B-Method
-	I-Method
Nets	I-Method
.	O
	
The	O
ZF	B-Method
-	I-Method
Net	I-Method
consists	O
five	O
convolution	B-Method
layers	I-Method
,	O
followed	O
by	O
three	O
fully	B-Method
connected	I-Method
layers	I-Method
.	O
	
The	O
VGG	B-Method
-	I-Method
Nets	I-Method
architecture	I-Method
includes	O
16	O
or	O
19	O
layers	O
.	O
	
We	O
modify	O
the	O
last	O
fully	O
connected	O
layer	O
’s	O
output	O
based	O
on	O
the	O
task	O
and	O
replace	O
the	O
original	O
softmax	O
loss	O
function	O
with	O
the	O
KL	B-Method
loss	I-Method
function	I-Method
.	O
	
In	O
addition	O
,	O
we	O
use	O
the	O
parameter	O
ReLU	B-Method
for	O
ZF	B-Task
-	I-Task
Net	I-Task
.	O
	
In	O
our	O
network	O
,	O
the	O
input	O
is	O
an	O
order	O
three	O
tensor	O
and	O
the	O
output	O
may	O
be	O
a	O
vector	O
(	O
age	B-Task
estimation	I-Task
and	O
multi	B-Task
-	I-Task
label	I-Task
classification	I-Task
)	O
,	O
a	O
matrix	O
(	O
head	B-Task
pose	I-Task
estimation	I-Task
)	O
or	O
a	O
tensor	B-Method
(	O
semantic	B-Task
segmentation	I-Task
)	O
.	O
	
In	O
this	O
paper	O
,	O
we	O
train	O
the	O
deep	B-Method
models	I-Method
in	O
two	O
ways	O
:	O
	
Training	O
from	O
scratch	O
.	O
	
For	O
ZF	B-Task
-	I-Task
Net	I-Task
,	O
the	O
initialization	O
is	O
performed	O
randomly	O
,	O
based	O
on	O
a	O
Gaussian	B-Method
distribution	I-Method
with	O
zero	O
mean	O
and	O
0.01	O
standard	O
deviation	O
,	O
and	O
biases	O
are	O
initialized	O
to	O
zero	O
.	O
	
The	O
coefficient	O
of	O
the	O
parameter	O
	
ReLU	B-Method
is	O
initialized	O
to	O
0.25	O
.	O
	
The	O
dropout	B-Method
is	O
applied	O
to	O
the	O
last	O
two	O
fully	O
connected	O
layers	O
with	O
rate	O
0.5	O
.	O
	
The	O
coefficient	O
of	O
weight	O
decay	O
is	O
set	O
to	O
.	O
	
Optimization	B-Task
is	O
done	O
by	O
Stochastic	B-Method
Gradient	I-Method
Descent	I-Method
(	O
SGD	B-Method
)	O
using	O
mini	O
-	O
batches	O
of	O
128	O
and	O
the	O
momentum	O
coefficient	O
is	O
0.9	O
.	O
	
The	O
initial	O
learning	B-Metric
rate	I-Metric
is	O
set	O
to	O
0.01	O
.	O
	
The	O
total	O
number	O
of	O
epochs	O
is	O
about	O
20	O
.	O
	
Fine	B-Task
-	I-Task
tuning	I-Task
.	O
	
Three	O
pre	B-Method
-	I-Method
trained	I-Method
models	I-Method
including	O
VGG	B-Method
-	I-Method
Nets	I-Method
(	O
16	B-Method
-	I-Method
layers	I-Method
and	O
19	O
-	O
layers	O
)	O
and	O
VGG	B-Method
-	I-Method
Face	I-Method
(	O
16	B-Method
-	I-Method
layers	I-Method
)	O
are	O
used	O
to	O
fine	O
-	O
tune	O
for	O
different	O
tasks	O
.	O
	
We	O
remove	O
these	O
pre	O
-	O
trained	O
models	O
’	O
classification	B-Method
layer	I-Method
and	O
loss	B-Method
layer	I-Method
,	O
and	O
put	O
in	O
our	O
label	B-Method
distribution	I-Method
layer	I-Method
which	O
is	O
initialized	O
by	O
the	O
Gaussian	B-Method
distribution	I-Method
and	O
the	O
KL	B-Method
loss	I-Method
layer	I-Method
.	O
	
The	O
learning	B-Metric
rates	I-Metric
of	O
the	O
convolutional	B-Method
layers	I-Method
,	O
the	O
first	O
two	O
fully	B-Method
-	I-Method
connected	I-Method
layers	I-Method
and	O
the	O
label	B-Method
distribution	I-Method
layer	I-Method
are	O
initialized	O
as	O
0.001	O
,	O
0.001	O
and	O
0.01	O
,	O
respectively	O
.	O
	
We	O
fine	O
-	O
tune	O
all	O
layers	O
by	O
back	B-Method
propagation	I-Method
through	O
the	O
whole	O
net	O
using	O
mini	O
-	O
batches	O
of	O
32	O
.	O
	
The	O
total	O
number	O
of	O
epochs	O
is	O
about	O
10	O
for	O
age	B-Task
estimation	I-Task
and	O
20	O
for	O
multi	B-Task
-	I-Task
label	I-Task
classification	I-Task
.	O
	
section	O
:	O
Experiments	O
	
We	O
evaluate	O
DLDL	B-Method
on	O
four	O
tasks	O
,	O
i.e.	O
,	O
age	B-Task
estimation	I-Task
,	O
head	B-Task
pose	I-Task
estimation	I-Task
,	O
multi	B-Task
-	I-Task
label	I-Task
classification	I-Task
and	O
semantic	B-Task
segmentation	I-Task
.	O
	
Our	O
implementation	O
is	O
based	O
on	O
MatConvNet	B-Method
.	O
	
All	O
our	O
experiments	O
are	O
carried	O
out	O
on	O
a	O
NVIDIA	B-Method
K40	I-Method
GPU	I-Method
with	O
12	O
GB	O
of	O
onboard	O
memory	O
.	O
	
subsection	O
:	O
Age	O
estimation	B-Task
	
Datasets	O
.	O
	
Two	O
age	B-Task
estimation	I-Task
datasets	O
are	O
used	O
in	O
our	O
experiments	O
.	O
	
The	O
first	O
is	O
Morph	B-Material
,	O
which	O
is	O
one	O
of	O
the	O
largest	O
publicly	O
available	O
age	B-Task
datasets	O
.	O
	
There	O
are	O
55	O
,	O
134	O
face	O
images	O
from	O
more	O
than	O
13	O
,	O
000	O
subjects	O
.	O
	
Ages	O
range	O
from	O
16	O
to	O
77	O
.	O
	
Since	O
no	O
TRAIN	O
/	O
TEST	O
split	O
is	O
provided	O
,	O
10	B-Method
-	I-Method
fold	I-Method
cross	I-Method
-	I-Method
validation	I-Method
is	O
used	O
for	O
Morph	B-Material
.	O
	
The	O
second	O
dataset	O
is	O
from	O
the	O
apparent	O
age	B-Task
estimation	I-Task
competition	O
,	O
the	O
first	O
competition	O
track	O
of	O
the	O
ICCV	O
ChaLearn	B-Material
LAP	I-Material
2015	I-Material
workshop	O
.	O
	
Compared	O
with	O
Morph	B-Material
,	O
this	O
dataset	O
(	O
ChaLearn	B-Material
)	O
consists	O
of	O
images	O
collected	O
in	O
the	O
wild	O
,	O
without	O
any	O
position	O
,	O
illumination	O
or	O
quality	O
restriction	O
.	O
	
The	O
only	O
condition	O
is	O
that	O
each	O
image	O
contains	O
only	O
one	O
face	O
.	O
	
The	O
dataset	O
has	O
4	O
,	O
699	O
images	O
,	O
and	O
is	O
split	O
into	O
2	O
,	O
476	O
training	O
(	O
TRAIN	O
)	O
,	O
1	O
,	O
136	O
validation	O
(	O
VAL	O
)	O
and	O
1	O
,	O
087	O
testing	O
(	O
TEST	O
)	O
images	O
.	O
	
The	O
apparent	O
age	B-Task
(	O
i.e.	O
,	O
how	O
old	O
does	O
this	O
person	O
look	O
like	O
)	O
of	O
each	O
image	O
is	O
labeled	O
by	O
multiple	O
individuals	O
.	O
	
The	O
age	B-Task
of	O
face	O
images	O
range	O
from	O
3	O
to	O
85	O
.	O
	
For	O
each	O
image	O
,	O
its	O
mean	O
age	B-Task
and	O
the	O
corresponding	O
standard	O
deviation	O
are	O
given	O
.	O
	
Since	O
the	O
ground	O
-	O
truth	O
for	O
TEST	O
images	O
are	O
not	O
published	O
,	O
we	O
train	O
on	O
the	O
TRAIN	O
split	O
and	O
evaluate	O
on	O
the	O
VAL	O
split	O
of	O
ChaLearn	B-Material
images	O
.	O
	
Baselines	O
.	O
	
To	O
demonstrate	O
the	O
effectiveness	O
of	O
DLDL	B-Method
,	O
we	O
firstly	O
consider	O
two	O
related	O
methods	O
as	O
baselines	O
:	O
ConvNet	B-Method
+	I-Method
LS	I-Method
(	I-Method
KL	I-Method
)	O
and	O
ConvNet	O
+	O
LD	B-Method
(	O
-	O
div	O
)	O
.	O
	
The	O
former	O
uses	O
label	B-Method
smoothing	I-Method
(	O
LS	B-Method
)	O
as	O
ground	O
-	O
truth	O
and	O
KL	O
divergence	O
as	O
loss	O
function	O
.	O
	
The	O
latter	O
uses	O
label	O
distribution	O
(	O
LD	B-Method
)	O
as	O
ground	O
-	O
truth	O
and	O
divergence	O
as	O
loss	O
function	O
,	O
which	O
is	O
In	O
addition	O
,	O
we	O
also	O
compare	O
DLDL	B-Method
with	O
the	O
following	O
baseline	O
methods	O
:	O
	
BFGS	B-Method
-	O
LDL	B-Method
Geng	O
et	O
al	O
.	O
proposed	O
the	O
label	B-Method
distribution	I-Method
learning	I-Method
approach	I-Method
(	O
IIS	B-Method
-	I-Method
LLD	I-Method
)	O
for	O
age	B-Task
and	O
head	B-Task
pose	I-Task
estimation	I-Task
.	O
	
They	O
used	O
traditional	O
image	O
features	O
.	O
	
To	O
further	O
improve	O
IIS	B-Method
-	I-Method
LLD	I-Method
,	O
Geng	O
et	O
al	O
.	O
proposed	O
a	O
BFGS	O
-	O
LDL	B-Method
algorithm	O
by	O
using	O
the	O
effective	O
quasi	B-Method
-	I-Method
Newton	I-Method
optimization	I-Method
method	I-Method
BFGS	I-Method
.	O
	
C	B-Method
-	I-Method
ConvNet	I-Method
Classification	I-Method
ConvNets	I-Method
have	O
obtained	O
very	O
competitive	O
performance	O
in	O
various	O
computer	B-Task
vision	I-Task
tasks	I-Task
.	O
	
ZF	B-Method
-	I-Method
Net	I-Method
and	O
VGG	B-Method
-	I-Method
Net	I-Method
are	O
popular	O
models	O
which	O
use	O
the	O
softmax	O
loss	O
.	O
	
We	O
replace	O
the	O
ImageNet	B-Method
-	I-Method
specific	I-Method
1000	I-Method
-	I-Method
way	I-Method
classification	I-Method
in	O
these	O
modes	O
with	O
the	O
label	O
set	O
.	O
	
R	B-Method
-	I-Method
ConvNet	I-Method
ConvNets	I-Method
are	O
also	O
successively	O
trained	O
for	O
regression	B-Task
tasks	I-Task
.	O
	
In	O
R	B-Task
-	I-Task
ConvNet	I-Task
,	O
the	O
ground	O
-	O
truth	O
label	O
(	O
age	B-Task
and	O
pose	O
angle	O
)	O
is	O
projected	O
into	O
the	O
range	O
by	O
the	O
mapping	O
,	O
where	O
and	O
are	O
the	O
maximum	O
and	O
minimum	O
values	O
in	O
the	O
training	O
label	O
set	O
.	O
	
During	O
prediction	B-Task
,	O
the	O
R	O
-	O
ConvNet	O
regression	O
result	O
is	O
reverse	O
mapped	O
to	O
get	O
.	O
	
To	O
speed	O
up	O
convergence	O
,	O
the	O
last	O
fully	B-Method
connected	I-Method
layer	I-Method
is	O
followed	O
a	O
hyperbolic	O
tangent	O
activation	O
function	O
,	O
which	O
maps	O
to	O
.	O
	
The	O
squared	O
,	O
and	O
-	O
ins	O
loss	O
functions	O
are	O
used	O
in	O
R	B-Method
-	I-Method
ConvNet	I-Method
.	O
	
Implementation	O
details	O
.	O
	
We	O
use	O
the	O
same	O
preprocessing	B-Method
pipeline	I-Method
for	O
all	O
compared	O
methods	O
,	O
including	O
face	O
detection	B-Task
,	O
facial	O
key	O
points	O
detection	B-Task
and	O
face	B-Task
alignment	I-Task
,	O
as	O
shown	O
in	O
Fig	O
[	O
reference	O
]	O
.	O
	
We	O
employ	O
the	O
DPM	B-Method
model	I-Method
to	O
detect	O
the	O
main	O
facial	O
region	O
.	O
	
Then	O
,	O
the	O
detected	O
face	O
is	O
fed	O
into	O
cascaded	B-Method
convolution	I-Method
networks	I-Method
to	O
get	O
the	O
five	O
facial	O
key	O
points	O
,	O
including	O
the	O
left	O
/	O
right	O
eye	O
centers	O
,	O
nose	O
tip	O
and	O
left	O
/	O
right	O
mouth	O
corners	O
.	O
	
Finally	O
,	O
based	O
on	O
these	O
facial	O
points	O
,	O
we	O
align	O
the	O
face	O
to	O
the	O
upright	O
pose	O
.	O
	
Data	B-Task
augmentation	I-Task
are	O
only	O
applied	O
to	O
the	O
training	O
images	O
for	O
ChaLearn	B-Material
.	O
	
For	O
one	O
color	O
input	O
training	O
image	O
,	O
we	O
generate	O
its	O
gray	B-Method
-	I-Method
scale	I-Method
version	I-Method
,	O
and	O
left	O
-	O
right	O
flip	O
both	O
color	O
and	O
gray	O
-	O
scale	O
versions	O
.	O
	
Thus	O
,	O
every	O
training	O
image	O
turns	O
into	O
4	O
images	O
.	O
	
[	O
Input	O
]	O
[	O
Detection	O
]	O
	
[	O
Facial	O
points	O
]	O
	
[	O
Alignment	O
]	O
We	O
define	O
for	O
both	O
datasets	O
.	O
	
The	O
label	O
distribution	O
of	O
each	O
image	O
is	O
generated	O
using	O
Eq	O
.	O
	
[	O
reference	O
]	O
.	O
	
The	O
mean	O
is	O
provided	O
in	O
both	O
Morph	B-Material
and	O
ChaLearn	B-Material
.	O
	
The	O
standard	O
deviation	O
,	O
however	O
,	O
is	O
provided	O
in	O
ChaLearn	B-Material
but	O
not	O
in	O
Morph	B-Material
.	O
	
We	O
simply	O
set	O
in	O
Morph	B-Material
.	O
	
Experiments	O
for	O
different	O
methods	O
are	O
conducted	O
under	O
the	O
same	O
data	O
splits	O
.	O
	
1	O
Used	O
80	O
%	O
of	O
Morph	B-Material
images	O
for	O
training	O
and	O
20	O
%	O
for	O
evaluation	O
;	O
2	O
Used	O
additional	O
external	O
face	O
images	O
(	O
i.e.	O
,	O
IMDB	O
-	O
WIKI	O
)	O
;	O
3	O
Used	O
pre	O
-	O
trained	O
model	O
(	O
i.e.	O
,	O
VGG	B-Method
-	I-Method
Nets	I-Method
or	O
VGG	B-Method
-	I-Method
Face	I-Method
)	O
.	O
	
Evaluation	B-Metric
criteria	I-Metric
.	O
	
Mean	B-Metric
Absolute	I-Metric
Error	I-Metric
(	O
MAE	B-Metric
)	O
and	O
Cumulative	B-Metric
Score	I-Metric
(	I-Metric
CS	I-Metric
)	O
are	O
used	O
to	O
evaluate	O
the	O
performance	O
of	O
age	B-Task
estimation	I-Task
.	O
	
MAE	B-Metric
is	O
the	O
average	O
difference	O
between	O
the	O
predicted	O
and	O
the	O
real	O
age	B-Task
:	O
where	O
and	O
are	O
the	O
estimated	O
and	O
ground	O
-	O
truth	O
age	B-Task
of	O
the	O
-	O
th	O
testing	O
image	O
,	O
respectively	O
.	O
	
CS	B-Method
is	O
defined	O
as	O
the	O
accuracy	O
rate	O
of	O
correct	O
estimation	B-Task
:	O
where	O
is	O
the	O
number	O
of	O
correct	O
estimation	B-Task
,	O
i.e.	O
,	O
testing	O
images	O
that	O
satisfy	O
.	O
	
In	O
our	O
experiment	O
,	O
.	O
	
In	O
addition	O
,	O
a	O
special	O
measurement	O
(	O
named	O
-	O
error	O
)	O
is	O
defined	O
by	O
the	O
ChaLearn	B-Material
competition	O
,	O
computed	O
as	O
Results	O
.	O
	
Table	O
[	O
reference	O
]	O
lists	O
results	O
on	O
both	O
datasets	O
.	O
	
The	O
upper	O
part	O
shows	O
results	O
in	O
the	O
literature	O
.	O
	
The	O
middle	O
part	O
shows	O
the	O
baseline	O
results	O
.	O
	
The	O
lower	O
part	O
shows	O
the	O
results	O
of	O
the	O
proposed	O
approach	O
.	O
	
The	O
first	O
term	O
in	O
the	O
parenthesis	O
behind	O
each	O
method	O
is	O
the	O
loss	O
function	O
corresponding	O
to	O
the	O
method	O
.	O
	
Max	O
or	O
Exp	O
represent	O
predicting	O
according	O
to	O
Eq	O
.	O
	
[	O
reference	O
]	O
or	O
[	O
reference	O
]	O
,	O
respectively	O
.	O
	
Since	O
cross	B-Method
-	I-Method
validation	I-Method
is	O
used	O
in	O
Morph	B-Material
,	O
we	O
also	O
provide	O
its	O
standard	O
deviations	O
.	O
	
[	O
ChaLearn	B-Material
]	O
	
[	O
Morph	B-Material
]	O
	
[	O
AFLW	O
]	O
[	O
	
subfigure	O
]	O
labelformat	O
=	O
empty	O
[	O
40	O
]	O
	
[	O
19	O
]	O
[	O
62	O
]	O
	
[	O
23	O
]	O
	
[	O
38	O
]	O
	
[	O
24	O
]	O
	
[	O
26	O
]	O
	
[	O
66	O
]	O
	
[	O
52	O
]	O
[	O
22	O
]	O
	
[	O
red39.69	O
]	O
	
[	O
red19.29	O
]	O
	
[	O
red61.61	O
]	O
	
[	O
red22.94	O
]	O
	
[	O
red37.87	O
]	O
	
[	O
red24.27	O
]	O
	
[	O
red25.40	O
]	O
[	O
blue60.17	O
]	O
	
[	O
blue35.06	O
]	O
[	O
blue28.55	O
]	O
From	O
Table	O
[	O
reference	O
]	O
,	O
we	O
can	O
see	O
that	O
DLDL	B-Method
consistently	O
outperforms	O
baselines	O
and	O
other	O
published	O
methods	O
.	O
	
The	O
difference	O
between	O
DLDL	B-Method
(	O
KL	O
,	O
Max	O
)	O
and	O
its	O
competitor	O
C	B-Method
-	I-Method
ConvNet	I-Method
(	O
softmax	B-Method
,	O
Max	O
)	O
is	O
0.51	O
on	O
Morph	B-Material
.	O
	
This	O
gap	O
is	O
more	O
than	O
6	O
times	O
the	O
sum	O
of	O
their	O
standard	O
deviations	O
(	O
0.03	O
+	O
0.05	O
)	O
,	O
showing	O
statistically	O
significant	O
differences	O
.	O
	
The	O
advantage	O
of	O
DLDL	B-Method
over	O
R	B-Method
-	I-Method
ConvNet	I-Method
,	O
C	B-Method
-	I-Method
ConvNet	I-Method
and	O
ConvNet	B-Method
+	I-Method
LS	I-Method
suggests	O
that	O
learning	B-Task
label	I-Task
distribution	I-Task
is	O
advantageous	O
in	O
deep	B-Task
end	I-Task
-	I-Task
to	I-Task
-	I-Task
end	I-Task
models	I-Task
.	O
	
DLDL	B-Method
has	O
much	O
better	O
results	O
than	O
BFGS	O
-	O
LDL	B-Method
,	O
which	O
shows	O
that	O
the	O
learned	O
deep	O
features	O
are	O
more	O
powerful	O
than	O
manually	O
designed	O
ones	O
.	O
	
Compared	O
to	O
ConvNet	O
+	O
LD	B-Method
(	O
-	O
div	O
)	O
,	O
DLDL	B-Method
(	O
KL	O
)	O
achieves	O
lower	O
MAE	B-Metric
on	O
both	O
datasets	O
.	O
	
It	O
indicates	O
that	O
KL	B-Metric
-	I-Metric
divergence	I-Metric
is	O
better	O
than	O
-	O
divergence	O
for	O
measuring	O
the	O
similarity	B-Task
of	I-Task
two	I-Task
distributions	I-Task
in	O
this	O
context	O
.	O
	
We	O
find	O
that	O
C	B-Method
-	I-Method
ConvNet	I-Method
and	O
R	B-Method
-	I-Method
ConvNet	I-Method
are	O
not	O
stable	O
.	O
	
The	O
R	B-Method
-	I-Method
ConvNet	I-Method
(	I-Method
)	I-Method
method	I-Method
,	O
although	O
being	O
the	O
second	O
best	O
method	O
for	O
ChaLearn	B-Material
,	O
is	O
inferior	O
to	O
C	B-Method
-	I-Method
ConvNet	I-Method
(	O
softmax	B-Method
,	O
Exp	B-Method
)	O
for	O
Morph	B-Material
.	O
	
In	O
addition	O
,	O
we	O
also	O
find	O
that	O
Eq	O
.	O
	
[	O
reference	O
]	O
is	O
better	O
than	O
Eq	O
.	O
	
[	O
reference	O
]	O
in	O
many	O
cases	O
,	O
which	O
suggests	O
that	O
Eq	O
.	O
	
[	O
reference	O
]	O
is	O
more	O
suitable	O
than	O
Eq	O
.	O
	
[	O
reference	O
]	O
for	O
age	B-Task
estimation	I-Task
.	O
	
Fine	O
-	O
tuning	O
DLDL	B-Method
.	O
	
Instead	O
of	O
training	O
DLDL	B-Method
from	O
scratch	O
,	O
we	O
also	O
fine	O
-	O
tune	O
the	O
network	B-Method
of	I-Method
VGG	I-Method
-	I-Method
Face	I-Method
.	O
	
On	O
the	O
small	O
scale	O
ChaLearn	B-Material
dataset	O
,	O
the	O
MAE	B-Metric
of	O
DLDL	B-Method
is	O
reduced	O
from	O
5.34	O
to	O
3.51	O
,	O
yielding	O
a	O
significant	O
improvement	O
.	O
	
The	O
-	O
error	O
of	O
DLDL	B-Method
is	O
reduced	O
from	O
0.44	O
to	O
0.31	O
,	O
which	O
is	O
close	O
to	O
the	O
best	O
competition	O
result	O
0.28	O
on	O
the	O
validation	O
set	O
.	O
	
In	O
,	O
external	O
training	O
images	O
(	O
260	O
,	O
282	O
additional	O
external	O
training	O
images	O
with	O
real	O
age	B-Task
annotation	O
)	O
were	O
used	O
.	O
	
DLDL	B-Method
only	O
uses	O
the	O
ChaLearn	B-Material
dataset	O
	
’s	O
2	O
,	O
476	O
training	O
images	O
and	O
is	O
the	O
best	O
among	O
ChaLearn	B-Material
teams	O
that	O
do	O
not	O
use	O
external	O
data	O
.	O
	
In	O
the	O
competition	O
,	O
the	O
best	O
external	O
-	O
data	O
-	O
free	O
-	O
error	O
is	O
0.48	O
,	O
which	O
is	O
worse	O
than	O
DLDL	B-Method
’s	O
.	O
	
However	O
,	O
the	O
idea	O
in	O
to	O
use	O
external	O
data	O
is	O
useful	O
for	O
further	O
reducing	O
DLDL	B-Method
’s	O
estimation	B-Task
error	O
.	O
	
Fig	O
.	O
	
[	O
reference	O
]	O
and	O
Fig	O
.	O
	
[	O
reference	O
]	O
show	O
the	O
CS	O
curves	O
on	O
ChaLearn	B-Material
and	O
Morph	B-Material
datasets	O
.	O
	
At	O
every	O
error	O
level	O
,	O
our	O
DLDL	B-Method
fine	O
-	O
tuned	O
VGG	O
-	O
Face	O
always	O
achieves	O
the	O
best	O
accuracy	B-Metric
among	O
all	O
methods	O
.	O
	
It	O
is	O
noteworthy	O
that	O
the	O
CS	B-Metric
curves	O
of	O
DLDL	B-Method
(	O
KL	O
,	O
Max	O
)	O
and	O
ConvNet	B-Method
(	O
-	O
div	O
,	O
Max	O
)	O
are	O
very	O
close	O
to	O
that	O
of	O
the	O
DLDL	B-Method
+	O
VGG	O
-	O
Face	O
(	O
KL	O
,	O
Max	O
)	O
on	O
Morph	B-Material
even	O
without	O
lots	O
of	O
external	O
data	O
and	O
very	O
deep	B-Method
model	I-Method
.	O
	
This	O
observation	O
supports	O
the	O
idea	O
that	O
using	O
DLDL	B-Method
can	O
achieve	O
competitive	O
performance	O
even	O
with	O
limited	O
training	O
samples	O
.	O
	
In	O
Fig	O
.	O
	
[	O
reference	O
]	O
	
,	O
we	O
show	O
some	O
examples	O
of	O
face	O
images	O
from	O
the	O
ChaLearn	B-Material
validation	O
set	O
and	O
predicted	O
label	O
distributions	O
by	O
DLDL	B-Method
(	O
KL	O
,	O
Exp	O
)	O
.	O
	
In	O
many	O
cases	O
,	O
our	O
solution	O
is	O
able	O
to	O
accurately	O
predict	O
the	O
apparent	O
age	B-Task
of	O
faces	O
.	O
	
Failures	O
may	O
come	O
from	O
two	O
causes	O
.	O
	
The	O
first	O
is	O
the	O
failure	O
to	O
detect	O
or	O
align	O
the	O
face	O
.	O
	
The	O
second	O
is	O
some	O
extreme	O
conditions	O
of	O
face	O
images	O
such	O
as	O
occlusion	O
,	O
low	O
resolution	O
,	O
heavy	O
makeup	O
and	O
old	O
photos	O
.	O
	
subsection	O
:	O
Head	B-Task
pose	I-Task
estimation	I-Task
	
Datasets	O
.	O
	
We	O
use	O
three	O
datasets	O
in	O
head	B-Task
pose	I-Task
estimation	I-Task
:	O
Pointing’04	O
,	O
BJUT	O
-	O
3D	O
and	O
Annotated	O
Facial	O
Landmarks	O
in	O
the	O
Wild	O
(	O
AFLW	O
)	O
.	O
	
In	O
them	O
,	O
head	O
pose	O
is	O
determined	O
by	O
two	O
angles	O
:	O
pitch	O
and	O
yaw	O
.	O
	
Pointing’04	O
discretizes	O
the	O
pitch	O
into	O
9	O
angles	O
and	O
the	O
yaw	O
into	O
13	O
angles	O
.	O
	
When	O
the	O
pitch	O
angel	O
is	O
or	O
,	O
the	O
yaw	O
angle	O
is	O
always	O
set	O
to	O
.	O
	
Thus	O
,	O
there	O
are	O
93	O
poses	O
in	O
total	O
.	O
	
The	O
head	O
images	O
are	O
taken	O
from	O
15	O
different	O
human	O
subjects	O
in	O
two	O
different	O
time	O
periods	O
,	O
resulting	O
in	O
images	O
.	O
	
BJUT	O
-	O
3D	O
contains	O
500	O
3D	O
faces	O
(	O
250	O
male	O
and	O
250	O
female	O
people	O
)	O
,	O
acquired	O
by	O
a	O
CyberWare	B-Method
Laser	I-Method
Scanner	I-Method
in	O
an	O
engineered	O
environment	O
.	O
	
9	O
pitch	O
angles	O
and	O
13	O
yaw	O
angles	O
are	O
used	O
.	O
	
There	O
are	O
in	O
total	O
93	O
poses	O
in	O
this	O
dataset	O
,	O
similar	O
to	O
that	O
in	O
Pointing’04	B-Task
.	O
	
Therefore	O
,	O
face	O
images	O
are	O
obtained	O
.	O
	
Unlike	O
Pointing’04	B-Method
and	O
BJUT	B-Method
-	I-Method
3D	I-Method
,	O
the	O
AFLW	B-Method
is	O
a	O
real	O
-	O
world	O
face	O
database	O
.	O
	
Head	O
pose	O
is	O
coarsely	O
obtained	O
by	O
fitting	O
a	O
mean	B-Method
3D	I-Method
face	I-Method
with	O
the	O
POSIT	B-Method
algorithm	I-Method
.	O
	
The	O
dataset	O
contains	O
about	O
24k	O
faces	O
in	O
real	O
-	O
world	O
images	O
.	O
	
We	O
select	O
23	O
,	O
409	O
faces	O
to	O
ensure	O
pitch	O
and	O
yaw	O
angles	O
within	O
.	O
	
Implementation	O
details	O
.	O
	
The	O
head	O
region	O
is	O
provided	O
by	O
bounding	O
box	O
annotations	O
in	O
Pointing’04	O
and	O
AFLW	O
.	O
	
The	O
BJUT	O
-	O
3D	O
does	O
not	O
contain	O
background	O
regions	O
.	O
	
Therefore	O
,	O
we	O
will	O
not	O
perform	O
any	O
preprocessing	O
.	O
	
In	O
DLDL	B-Method
,	O
we	O
set	O
in	O
Pointing’04	O
and	O
in	O
BJUT	O
-	O
3D	O
for	O
constructing	O
label	B-Task
distributions	I-Task
.	O
	
For	O
AFLW	O
,	O
ground	O
-	O
truth	O
of	O
head	O
pose	O
angles	O
are	O
given	O
as	O
real	O
numbers	O
.	O
	
Ground	O
-	O
truth	O
(	O
pitch	O
and	O
yaw	O
)	O
angles	O
are	O
divided	O
from	O
to	O
in	O
steps	O
of	O
,	O
so	O
we	O
get	O
(	O
pitch	O
,	O
yaw	O
)	O
pair	O
category	O
labels	O
.	O
	
We	O
set	O
for	O
AFLW	O
.	O
	
Since	O
the	O
discrete	O
Jeffrey	O
’s	O
divergence	O
is	O
used	O
in	O
LDL	B-Method
,	O
we	O
implement	O
BFGS	O
-	O
LDL	B-Method
with	O
the	O
Kullback	B-Method
-	I-Method
Leibler	I-Method
divergence	I-Method
.	O
	
All	O
experiments	O
are	O
performed	O
under	O
the	O
same	O
setting	O
,	O
including	O
data	O
splits	O
,	O
input	O
size	O
and	O
network	B-Method
architecture	I-Method
.	O
	
To	O
validate	O
the	O
effectiveness	O
of	O
DLDL	B-Method
for	O
head	B-Task
pose	I-Task
estimation	I-Task
,	O
we	O
use	O
the	O
same	O
baselines	O
as	O
age	B-Task
estimation	I-Task
.	O
	
Our	O
experiments	O
show	O
that	O
Eq	O
.	O
	
[	O
reference	O
]	O
has	O
lower	O
accuracy	B-Metric
than	O
Eq	O
.	O
	
[	O
reference	O
]	O
.	O
	
Hence	O
,	O
we	O
use	O
Eq	O
.	O
	
[	O
reference	O
]	O
in	O
this	O
section	O
.	O
	
Evaluation	B-Metric
criteria	I-Metric
.	O
	
Three	O
types	O
of	O
prediction	B-Metric
values	I-Metric
are	O
evaluated	O
:	O
pitch	O
,	O
yaw	O
,	O
and	O
pitch	O
+	O
yaw	O
,	O
where	O
pitch	O
+	O
yaw	O
jointly	O
estimates	O
the	O
pitch	O
and	O
yaw	O
angles	O
.	O
	
Two	O
different	O
measurements	O
are	O
used	O
,	O
which	O
is	O
MAE	B-Metric
(	O
Eq	O
.	O
	
[	O
reference	O
]	O
)	O
and	O
classification	B-Metric
accuracy	I-Metric
(	O
Acc	B-Metric
)	O
.	O
	
When	O
we	O
treat	O
different	O
poses	O
as	O
different	O
classes	O
,	O
Acc	B-Metric
measures	O
the	O
pose	B-Metric
class	I-Metric
classification	I-Metric
accuracy	I-Metric
.	O
	
In	O
particular	O
,	O
the	O
MAE	B-Metric
of	O
pitch	O
+	O
yaw	O
is	O
calculated	O
as	O
the	O
Euclidean	O
distance	O
between	O
the	O
predicted	O
(	O
pitch	O
,	O
yaw	O
)	O
pair	O
and	O
the	O
ground	O
-	O
truth	O
pair	O
;	O
the	O
Acc	B-Metric
of	O
pitch	O
+	O
yaw	O
is	O
calculated	O
by	O
regarding	O
each	O
(	O
pitch	O
,	O
yaw	O
)	O
pair	O
as	O
a	O
class	O
.	O
	
For	O
R	B-Task
-	I-Task
ConvNet	I-Task
,	O
we	O
only	O
report	O
its	O
MAE	B-Metric
but	O
not	O
Acc	B-Metric
,	O
because	O
its	O
predicted	O
value	O
are	O
continuous	O
real	O
numbers	O
.	O
	
All	O
methods	O
are	O
tested	O
with	O
5	B-Method
-	I-Method
fold	I-Method
cross	I-Method
validation	I-Method
for	O
Pointing’04	B-Task
and	O
BJUT	B-Task
-	I-Task
3D	I-Task
following	I-Task
.	O
	
For	O
AFLW	B-Method
,	O
15	O
,	O
561	O
face	O
images	O
are	O
randomly	O
chosen	O
for	O
training	O
,	O
and	O
the	O
remaining	O
7	O
,	O
848	O
for	O
evaluation	O
.	O
	
The	O
setup	O
is	O
similar	O
to	O
the	O
recent	O
literature	O
(	O
14	O
,	O
000	O
images	O
for	O
training	O
and	O
the	O
rest	O
7	O
,	O
041	O
images	O
for	O
testing	O
)	O
.	O
	
[	O
subfigure	O
]	O
labelformat	O
=	O
empty	O
[	O
(	O
+	O
77	O
,	O
-	O
4	O
)	O
]	O
	
[	O
(	O
-	O
16	O
,	O
-	O
1	O
)	O
]	O
	
[	O
(	O
-	O
1	O
,	O
-	O
30	O
)	O
]	O
	
[	O
(	O
+	O
30	O
,	O
+	O
8	O
)	O
]	O
	
[	O
(	O
+	O
4	O
,	O
-	O
4	O
)	O
]	O
[	O
(	O
-	O
36	O
,	O
+	O
13	O
)	O
]	O
	
[	O
(	O
-	O
87	O
,	O
-	O
3	O
)	O
]	O
	
[	O
(	O
-	O
61	O
,	O
-	O
58	O
)	O
]	O
	
[	O
(	O
+	O
63	O
,	O
+	O
12	O
)	O
]	O
	
[	O
(	O
+	O
80	O
,	O
-	O
27	O
)	O
]	O
	
[	O
red	O
(+	O
75	O
,	O
-	O
3	O
)	O
]	O
	
[	O
red	O
(-	O
15	O
,	O
0	O
)	O
]	O
	
[	O
red	O
(-	O
3	O
,	O
-	O
27	O
)	O
]	O
	
[	O
red	O
(+	O
27	O
,	O
+	O
6	O
)	O
]	O
	
[	O
red	O
(+	O
6	O
,	O
-	O
3	O
]	O
	
[	O
red	O
(-	O
39	O
,	O
+	O
15	O
]	O
	
[	O
red	O
(-	O
87	O
,	O
0	O
)	O
]	O
	
[	O
blue	O
(-	O
3	O
,	O
-	O
12	O
)	O
]	O
	
[	O
blue	O
(+	O
21	O
,	O
+	O
18	O
]	O
	
[	O
blue	O
(+	O
45	O
,	O
-	O
15	O
)	O
]	O
	
Results	O
.	O
	
Tables	O
[	O
reference	O
]	O
,	O
[	O
reference	O
]	O
and	O
[	O
reference	O
]	O
show	O
results	O
on	O
Pointing’04	O
,	O
BJUT	O
-	O
3D	O
and	O
AFLW	O
,	O
respectively	O
.	O
	
Pointing’04	B-Task
is	O
small	O
scale	O
with	O
only	O
2	O
,	O
790	O
images	O
.	O
	
We	O
observe	O
that	O
BFGS	O
-	O
LDL	B-Method
(	O
with	O
hand	O
-	O
crafted	O
features	O
)	O
has	O
much	O
lower	O
MAE	B-Metric
and	O
much	O
higher	O
accuracy	B-Metric
than	O
deep	B-Method
learning	I-Method
methods	I-Method
C	I-Method
-	I-Method
ConvNet	I-Method
,	O
R	B-Method
-	I-Method
ConvNet	I-Method
and	O
ConvNet	B-Method
+	I-Method
LS	I-Method
.	O
	
One	O
reasonable	O
conjecture	O
is	O
that	O
C	B-Method
-	I-Method
ConvNet	I-Method
,	O
R	B-Method
-	I-Method
ConvNet	I-Method
and	O
ConvNet	B-Method
+	I-Method
LS	I-Method
are	O
not	O
well	O
-	O
learned	O
with	O
only	O
small	O
number	O
of	O
training	O
images	O
.	O
	
DLDL	B-Method
,	O
however	O
,	O
successfully	O
learns	O
the	O
head	O
pose	O
.	O
	
For	O
example	O
,	O
its	O
accuracy	B-Metric
for	O
pitch	B-Task
+	I-Task
yaw	I-Task
is	O
73.15	O
(	O
and	O
C	B-Method
-	I-Method
ConvNet	I-Method
is	O
only	O
42.97	O
)	O
.	O
	
That	O
is	O
,	O
DLDL	B-Method
is	O
able	O
to	O
perform	O
deep	B-Task
learning	I-Task
with	O
few	O
training	O
images	O
,	O
while	O
C	B-Method
-	I-Method
ConvNet	I-Method
R	I-Method
-	I-Method
ConvNet	I-Method
and	O
ConvNet	B-Method
+	I-Method
LS	I-Method
have	O
failed	O
for	O
this	O
task	O
.	O
	
On	O
BJUT	O
-	O
3D	O
and	O
AFLW	O
which	O
have	O
enough	O
training	O
data	O
,	O
we	O
observe	O
that	O
many	O
deep	B-Method
learning	I-Method
methods	I-Method
show	O
higher	O
performance	O
than	O
BFGS	O
-	O
LDL	B-Method
.	O
	
DLDL	B-Method
achieves	O
the	O
best	O
performance	O
:	O
it	O
has	O
much	O
lower	O
MAE	B-Metric
and	O
higher	O
accuracy	B-Metric
than	O
other	O
methods	O
.	O
	
Another	O
observation	O
is	O
also	O
worth	O
mentioning	O
.	O
	
Although	O
R	B-Method
-	I-Method
ConvNet	I-Method
is	O
better	O
than	O
C	B-Method
-	I-Method
ConvNet	I-Method
when	O
label	O
is	O
dense	O
such	O
as	O
age	B-Task
estimation	I-Task
and	O
head	B-Task
pose	I-Task
estimation	I-Task
on	O
AFLW	B-Task
,	O
it	O
is	O
obviously	O
worse	O
than	O
C	B-Method
-	I-Method
ConvNet	I-Method
on	O
BJUT	B-Method
-	I-Method
3D	I-Method
and	O
pointing’04	B-Method
for	O
head	B-Task
pose	I-Task
estimation	I-Task
which	O
have	O
sparse	O
labels	O
.	O
	
In	O
other	O
words	O
,	O
the	O
performance	O
of	O
C	B-Method
-	I-Method
ConvNet	I-Method
and	O
R	B-Method
-	I-Method
ConvNet	I-Method
are	O
not	O
very	O
robust	O
,	O
while	O
the	O
proposed	O
method	O
consistently	O
achieves	O
excellent	O
performance	O
.	O
	
Fig	O
.	O
	
[	O
reference	O
]	O
shows	O
the	O
pitch	O
+	O
yaw	O
CS	O
curves	O
on	O
the	O
AFLW	O
dataset	O
.	O
	
There	O
is	O
an	O
obvious	O
gap	O
between	O
DLDL	B-Method
and	O
baseline	O
methods	O
at	O
every	O
error	O
level	O
.	O
	
Fig	O
.	O
	
[	O
reference	O
]	O
shows	O
the	O
predicted	O
label	O
distributions	O
for	O
different	O
head	O
poses	O
on	O
the	O
AFLW	O
testing	O
set	O
using	O
the	O
DLDL	B-Method
model	O
.	O
	
Our	O
approach	O
can	O
estimate	O
head	O
pose	O
with	O
low	O
errors	O
but	O
may	O
fail	O
under	O
some	O
extreme	O
conditions	O
.	O
	
It	O
is	O
noteworthy	O
that	O
DLDL	B-Method
may	O
produce	O
more	O
incorrect	O
estimations	O
when	O
both	O
yaw	O
and	O
pitch	O
are	O
large	O
(	O
e.g.	O
,	O
)	O
.	O
	
The	O
reason	O
might	O
be	O
that	O
there	O
are	O
much	O
fewer	O
training	O
examples	O
for	O
large	O
angles	O
than	O
for	O
other	O
angles	O
.	O
	
subsection	O
:	O
Multi	B-Task
-	I-Task
label	I-Task
classification	I-Task
	
Datasets	O
.	O
	
We	O
evaluate	O
our	O
approach	O
for	O
multi	B-Task
-	I-Task
label	I-Task
classification	I-Task
on	O
the	O
PASCAL	O
VOC	O
dataset	O
:	O
PASCAL	O
VOC2007	O
and	O
VOC2012	O
.	O
	
There	O
are	O
9	O
,	O
963	O
and	O
22	O
,	O
531	O
images	O
in	O
them	O
,	O
respectively	O
.	O
	
Each	O
image	O
is	O
annotated	O
with	O
one	O
or	O
several	O
labels	O
,	O
corresponding	O
to	O
20	O
object	O
categories	O
.	O
	
These	O
images	O
are	O
divided	O
into	O
three	O
subsets	O
including	O
TRAIN	O
,	O
VAL	O
and	O
TEST	O
sets	O
.	O
	
We	O
train	O
on	O
the	O
TRAINVAL	O
set	O
and	O
evaluate	O
on	O
the	O
TEST	O
set	O
.	O
	
The	O
evaluation	B-Metric
metric	I-Metric
is	O
average	B-Metric
precision	I-Metric
(	O
AP	B-Metric
)	O
and	O
mean	O
average	O
precision	O
(	O
mAP	B-Metric
)	O
,	O
complying	O
with	O
the	O
PASCAL	O
challenge	O
protocols	O
.	O
	
We	O
denote	O
our	O
methods	O
as	O
Images	B-Method
-	I-Method
Fine	I-Method
-	I-Method
tuning	I-Method
-	I-Method
DLDL	I-Method
(	O
IF	B-Method
-	I-Method
DLDL	I-Method
)	O
and	O
Proposals	B-Method
-	I-Method
Fine	I-Method
-	I-Method
tuning	I-Method
-	I-Method
DLDL	I-Method
(	O
PF	B-Method
-	I-Method
DLDL	I-Method
)	O
when	O
ConvNets	B-Method
are	O
fine	O
-	O
tuned	O
by	O
images	O
and	O
proposals	O
of	O
images	O
,	O
respectively	O
.	O
	
Details	O
of	O
these	O
two	O
variants	O
are	O
explained	O
later	O
in	O
this	O
section	O
.	O
	
We	O
compare	O
the	O
proposed	O
approaches	O
with	O
the	O
following	O
methods	O
:	O
VGG	B-Method
+	I-Method
SVM	I-Method
[	O
]	O
.	O
	
This	O
method	O
densely	O
extracted	O
4	O
,	O
096	O
dimensional	O
ConvNet	O
features	O
at	O
the	O
penultimate	B-Method
layer	I-Method
of	O
VGG	B-Method
-	I-Method
Nets	I-Method
pre	O
-	O
trained	O
on	O
ImageNet	O
.	O
	
These	O
features	O
from	O
different	O
scales	O
(	O
smallest	O
image	O
side	O
)	O
were	O
aggregated	O
by	O
average	B-Method
pooling	I-Method
.	O
	
Then	O
,	O
these	O
averaged	O
features	O
from	O
two	O
networks	O
(	O
“	O
Net	B-Method
-	I-Method
D	I-Method
”	I-Method
containing	O
16	O
layers	O
and	O
“	O
Net	O
-	O
E	O
”	O
containing	O
19	O
layers	O
)	O
were	O
further	O
fused	O
by	O
stacking	B-Method
.	O
	
Finally	O
,	O
normalized	O
the	O
resulting	O
image	O
features	O
and	O
used	O
these	O
features	O
to	O
train	O
a	O
linear	B-Method
SVM	I-Method
classifier	I-Method
for	O
multi	B-Task
-	I-Task
label	I-Task
classification	I-Task
.	O
	
HCP	B-Method
[	O
]	O
.	O
	
HCP	B-Method
proposed	O
to	O
solve	O
the	O
multi	B-Task
-	I-Task
label	I-Task
object	I-Task
recognition	I-Task
task	I-Task
by	O
extracting	O
object	O
proposals	O
from	O
the	O
images	O
.	O
	
The	O
method	O
used	O
image	O
label	O
and	O
square	O
loss	O
to	O
fine	O
-	O
tune	O
a	O
pre	B-Method
-	I-Method
trained	I-Method
ConvNet	I-Method
.	O
	
Then	O
,	O
BING	O
or	O
EdgeBoxes	O
was	O
used	O
to	O
extract	O
object	O
proposals	O
,	O
which	O
were	O
used	O
to	O
fine	O
-	O
tune	O
the	O
ConvNet	B-Method
again	O
.	O
	
Finally	O
,	O
scores	O
of	O
these	O
proposals	O
were	O
max	O
-	O
pooled	O
to	O
obtain	O
the	O
prediction	B-Task
.	O
	
Fev	O
+	O
Lv	O
[	O
]	O
.	O
	
This	O
approach	O
transformed	O
the	O
multi	B-Task
-	I-Task
label	I-Task
object	I-Task
recognition	I-Task
problem	I-Task
into	O
a	O
multi	B-Task
-	I-Task
class	I-Task
multi	I-Task
-	I-Task
instance	I-Task
learning	I-Task
problem	I-Task
.	O
	
Two	O
views	O
(	O
label	O
view	O
and	O
feature	O
view	O
)	O
were	O
extracted	O
for	O
each	O
proposal	O
of	O
images	O
.	O
	
Then	O
,	O
these	O
two	O
views	O
were	O
encoded	O
by	O
a	O
Fisher	O
vector	O
for	O
each	O
image	O
.	O
	
IF	O
-	O
VGG	O
-	O
ℓ2	O
	
and	O
IF	B-Method
-	I-Method
VGG	I-Method
-	I-Method
KL	I-Method
.	O
	
We	O
fine	O
-	O
tune	O
	
the	O
VGG	B-Method
-	I-Method
Nets	I-Method
with	O
square	B-Method
loss	I-Method
and	O
multi	B-Method
-	I-Method
label	I-Method
cross	I-Method
-	I-Method
entropy	I-Method
loss	I-Method
and	O
use	O
them	O
as	O
our	O
IF	B-Method
-	I-Method
DLDL	I-Method
’s	I-Method
baselines	I-Method
.	O
	
They	O
are	O
trained	O
using	O
the	O
same	O
setting	O
.	O
	
Implementation	O
details	O
.	O
	
According	O
to	O
the	O
ground	O
-	O
truth	O
labels	O
,	O
we	O
set	O
different	O
probabilities	O
for	O
all	O
possible	O
labels	O
on	O
PASCAL	O
VOC	O
dataset	O
.	O
	
In	O
our	O
experiments	O
,	O
,	O
,	O
.	O
	
Finally	O
,	O
similar	O
to	O
label	B-Method
smoothing	I-Method
,	O
a	O
uniform	O
distribution	O
is	O
added	O
to	O
,	O
where	O
.	O
	
IF	B-Method
-	I-Method
DLDL	I-Method
.	O
	
Following	O
,	O
each	O
training	O
image	O
is	O
individually	O
rescaled	O
by	O
randomly	O
sampling	O
in	O
the	O
range	O
[	O
256	O
,	O
512	O
]	O
.	O
	
We	O
randomly	O
crop	O
patches	O
from	O
these	O
resized	O
images	O
.	O
	
We	O
also	O
adjust	O
the	O
pooling	O
kernel	O
in	O
the	O
pool5	O
layer	O
from	O
to	O
.	O
	
Max	B-Method
-	I-Method
pooling	I-Method
and	O
Avg	B-Method
-	I-Method
pooling	I-Method
are	O
used	O
at	O
pool5	O
to	O
train	O
two	O
ConvNets	B-Method
.	O
	
We	O
obtain	O
four	O
ConvNet	B-Method
models	I-Method
thought	O
	
fine	O
-	O
tuning	O
“	O
Net	B-Method
-	I-Method
D	I-Method
”	I-Method
and	O
“	O
Net	O
-	O
E	O
”	O
.	O
	
At	O
the	O
prediction	B-Task
stage	I-Task
,	O
the	O
smaller	O
side	O
of	O
each	O
image	O
is	O
scaled	O
to	O
a	O
fixed	O
length	O
.	O
	
Each	O
scaled	O
image	O
is	O
fed	O
to	O
the	O
fine	B-Method
-	I-Method
tuned	I-Method
ConvNets	I-Method
to	O
obtain	O
the	O
20	O
-	O
dim	O
probability	O
outputs	O
.	O
	
These	O
probability	O
outputs	O
from	O
different	O
scales	O
and	O
different	O
models	O
are	O
averaged	O
to	O
form	O
the	O
final	O
prediction	O
.	O
	
PF	B-Method
-	I-Method
DLDL	I-Method
.	O
	
Following	O
,	O
we	O
further	O
fine	O
-	O
tune	O
IF	B-Method
-	I-Method
DLDL	I-Method
models	I-Method
with	O
proposals	O
of	O
images	O
to	O
boost	O
performance	O
.	O
	
For	O
each	O
training	O
image	O
,	O
we	O
employ	O
EdgeBoxes	O
to	O
produce	O
a	O
set	O
of	O
proposal	O
bounding	O
boxes	O
which	O
are	O
grouped	O
into	O
clusters	O
by	O
the	O
normalized	B-Method
cut	I-Method
algorithm	I-Method
.	O
	
For	O
each	O
cluster	O
,	O
the	O
top	O
proposals	O
with	O
higher	O
predictive	O
scores	O
generated	O
by	O
EdgeBoxes	O
are	O
resized	O
into	O
square	O
shapes	O
(	O
i.e.	O
,	O
)	O
.	O
	
As	O
a	O
result	O
,	O
we	O
can	O
obtain	O
proposals	O
for	O
an	O
image	O
.	O
	
Finally	O
,	O
these	O
resized	O
proposals	O
are	O
fed	O
into	O
a	O
fine	B-Method
-	I-Method
tuned	I-Method
IF	I-Method
-	I-Method
DLDL	I-Method
model	I-Method
to	O
obtain	O
prediction	B-Metric
scores	I-Metric
and	O
these	O
scores	O
are	O
fused	O
by	O
max	B-Method
-	I-Method
pooling	I-Method
to	O
form	O
the	O
prediction	O
distribution	O
of	O
the	O
image	O
.	O
	
This	O
process	O
can	O
be	O
learned	O
by	O
using	O
an	O
end	O
-	O
to	O
-	O
end	O
way	O
.	O
	
In	O
our	O
implementation	O
,	O
we	O
set	O
and	O
at	O
the	O
training	O
and	O
the	O
prediction	B-Task
stage	I-Task
,	O
respectively	O
.	O
	
Similar	O
to	O
IF	B-Method
-	I-Method
DLDL	I-Method
,	O
we	O
also	O
average	O
fuse	B-Metric
prediction	I-Metric
scores	I-Metric
of	O
different	O
models	O
to	O
generate	O
the	O
final	O
prediction	O
.	O
	
Results	O
.	O
	
In	O
Table	O
[	O
reference	O
]	O
,	O
we	O
compare	O
single	O
model	O
results	O
(	O
average	O
AP	B-Metric
of	O
all	O
classes	O
)	O
on	O
VOC2007	O
.	O
	
Our	O
PF	B-Method
-	I-Method
DLDL	I-Method
defeats	O
all	O
the	O
other	O
methods	O
.	O
	
Compared	O
with	O
Fev	B-Method
+	I-Method
Lv	I-Method
,	O
1.7	O
%	O
improvement	O
can	O
be	O
achieved	O
by	O
PF	B-Method
-	I-Method
DLDL	I-Method
even	O
without	O
using	O
the	O
bounding	B-Method
box	I-Method
annotation	I-Method
.	O
	
Compared	O
with	O
HCP	B-Method
-	I-Method
VGG	I-Method
,	O
our	O
PF	B-Method
-	I-Method
DLDL	I-Method
can	O
achieve	O
92.3	O
%	O
mAP	B-Metric
,	O
which	O
is	O
significantly	O
higher	O
than	O
their	O
90.9	O
%	O
.	O
	
This	O
further	O
indicates	O
that	O
it	O
is	O
very	O
important	O
to	O
learn	O
a	O
label	O
distribution	O
.	O
	
Table	O
[	O
reference	O
]	O
and	O
[	O
reference	O
]	O
report	O
details	O
of	O
all	O
experimental	O
results	O
on	O
VOC2007	O
and	O
VOC2012	O
,	O
respectively	O
.	O
	
It	O
can	O
be	O
seen	O
that	O
IF	B-Method
-	I-Method
DLDL	I-Method
outperforms	O
IF	B-Method
-	I-Method
VGG	I-Method
-	I-Method
by	O
1.1	O
%	O
for	O
VOC2007	O
and	O
1.3	O
%	O
for	O
VOC2012	O
,	O
which	O
indicates	O
that	O
the	O
KL	B-Method
loss	I-Method
function	I-Method
is	O
more	O
suitable	O
than	O
loss	O
for	O
measuring	O
the	O
similarity	O
of	O
two	O
label	O
distributions	O
.	O
	
Furthermore	O
,	O
IF	B-Method
-	I-Method
DLDL	I-Method
improves	O
IF	B-Method
-	I-Method
VGG	I-Method
-	I-Method
KL	I-Method
for	O
about	O
0.2–0.3	O
points	O
in	O
mAP	B-Metric
,	O
which	O
suggests	O
that	O
learning	O
a	O
label	O
distribution	O
is	O
beneficial	O
.	O
	
More	O
importantly	O
,	O
PF	B-Method
-	I-Method
DLDL	I-Method
can	O
achieve	O
93.4	O
%	O
for	O
VOC2007	O
and	O
92.4	O
%	O
for	O
VOC2012	O
in	O
mAP	B-Metric
when	O
we	O
average	O
fuse	B-Metric
output	I-Metric
scores	I-Metric
of	O
four	O
PF	B-Method
-	I-Method
DLDL	I-Method
models	I-Method
.	O
	
Our	O
framework	O
shows	O
good	O
performance	O
especially	O
for	O
scene	O
categories	O
such	O
as	O
“	O
chair	O
”	O
,	O
‘	O
table	O
”	O
and	O
“	O
sofa	O
”	O
.	O
	
Although	O
PF	B-Method
-	I-Method
DLDL	I-Method
significantly	O
outperforms	O
IF	B-Method
-	I-Method
DLDL	I-Method
in	O
mAP	B-Metric
,	O
PF	B-Method
-	I-Method
DLDL	I-Method
has	O
higher	O
computational	B-Metric
cost	I-Metric
than	O
IF	B-Method
-	I-Method
DLDL	I-Method
on	O
both	O
training	B-Task
and	I-Task
testing	I-Task
stages	I-Task
.	O
	
Since	O
IF	B-Method
-	I-Method
DLDL	I-Method
does	O
not	O
need	O
region	O
proposals	O
or	O
bounding	O
box	O
information	O
,	O
it	O
may	O
be	O
effectively	O
and	O
efficiently	O
implemented	O
for	O
practical	O
multi	B-Task
-	I-Task
label	I-Task
application	I-Task
such	O
as	O
multi	B-Task
-	I-Task
label	I-Task
image	I-Task
retrieval	I-Task
.	O
	
It	O
is	O
also	O
possible	O
that	O
by	O
adopting	O
new	O
techniques	O
(	O
such	O
as	O
the	O
region	B-Method
proposal	I-Method
method	I-Method
using	O
gated	B-Method
unit	I-Method
in	I-Method
,	O
which	O
has	O
higher	O
accuracy	B-Metric
that	O
ours	O
on	O
VOC	B-Task
tasks	I-Task
)	O
,	O
the	O
accuracy	B-Metric
of	O
our	O
DLDL	B-Method
methods	O
can	O
be	O
further	O
improved	O
.	O
	
[	O
ChaLearn	B-Material
]	O
	
[	O
Morph	B-Material
]	O
	
[	O
Pointing’04	O
]	O
	
[	O
AFLW	O
pitch	O
]	O
[	O
AFLW	O
yaw	O
]	O
BFGS	B-Method
-	I-Method
LDL	I-Method
DLDL	I-Method
	
subsection	O
:	O
Semantic	B-Task
segmentation	I-Task
	
Datasets	O
.	O
	
We	O
employ	O
the	O
PASCAL	O
VOC2011	O
segmentation	O
dataset	O
and	O
the	O
Semantic	O
Boundaries	O
Dataset	O
(	O
SBD	O
)	O
for	O
training	O
the	O
proposed	O
DLDL	B-Method
.	O
	
There	O
are	O
2	O
,	O
224	O
images	O
(	O
1	O
,	O
112	O
for	O
training	O
and	O
1	O
,	O
112	O
for	O
testing	O
)	O
with	O
pixel	O
labels	O
for	O
20	O
semantic	O
categories	O
in	O
VOC2011	O
.	O
	
SBD	O
contains	O
11	O
,	O
355	O
annotated	O
images	O
(	O
8	O
,	O
984	O
for	O
training	O
and	O
2	O
,	O
371	O
for	O
testing	O
)	O
from	O
Hariharan	O
et	O
al	O
.	O
.	O
	
Following	O
FCN	B-Method
,	O
we	O
train	O
DLDL	B-Method
using	O
the	O
union	O
set	O
(	O
8	O
,	O
825	O
images	O
)	O
of	O
SBD	O
and	O
VOC2011	O
training	O
images	O
.	O
	
We	O
evaluate	O
the	O
proposed	O
approach	O
on	O
VOC2011	O
(	O
1	O
,	O
112	O
)	O
and	O
VOC2012	O
(	O
1	O
,	O
456	O
)	O
test	O
images	O
.	O
	
Evaluation	B-Metric
criteria	I-Metric
.	O
	
The	O
performance	O
is	O
measured	O
in	O
terms	O
of	O
mean	B-Metric
IU	I-Metric
(	O
intersection	B-Metric
over	I-Metric
union	I-Metric
)	O
,	O
which	O
is	O
the	O
most	O
widely	O
used	O
metric	O
in	O
semantic	B-Task
segmentation	I-Task
.	O
	
We	O
keep	O
the	O
same	O
settings	O
as	O
FCN	B-Method
including	O
training	O
images	O
and	O
model	O
structure	O
.	O
	
The	O
main	O
change	O
is	O
that	O
we	O
employ	O
KL	O
divergence	O
as	O
the	O
loss	O
function	O
based	O
on	O
label	O
distribution	O
(	O
Eq	O
.	O
	
[	O
reference	O
]	O
)	O
.	O
	
Note	O
that	O
although	O
we	O
transform	O
the	O
ground	O
-	O
truth	O
to	O
label	O
distribution	O
in	O
the	O
training	B-Task
process	I-Task
,	O
our	O
evaluation	O
rely	O
only	O
on	O
ground	O
-	O
truth	O
label	O
.	O
	
Recently	O
,	O
Conditional	B-Method
Random	I-Method
Field	I-Method
(	I-Method
CRF	I-Method
)	I-Method
has	O
been	O
broadly	O
used	O
in	O
many	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
semantic	B-Task
segmentation	I-Task
systems	I-Task
.	O
	
We	O
optionally	O
employ	O
a	O
fully	B-Method
connected	I-Method
CRF	I-Method
to	O
refine	O
the	O
predicted	O
category	O
score	O
maps	O
using	O
the	O
default	O
parameters	O
of	O
.	O
	
Results	O
.	O
	
Table	O
[	O
reference	O
]	O
gives	O
the	O
performance	O
of	O
DLDL	B-Method
-	I-Method
8s	I-Method
and	O
DLDL	B-Method
-	I-Method
8s	I-Method
-	I-Method
CRF	I-Method
on	O
the	O
test	O
images	O
of	O
VOC2011	O
and	O
VOC2012	O
and	O
compares	O
it	O
to	O
the	O
well	O
-	O
known	O
FCN	B-Method
-	I-Method
8s	I-Method
.	O
	
DLDL	B-Method
-	I-Method
8s	I-Method
improves	O
the	O
mean	B-Metric
IU	I-Metric
of	O
FCN	O
-	O
8s	O
form	O
62.7	O
%	O
to	O
64.9	O
%	O
on	O
VOC2011	O
.	O
	
On	O
VOC2012	O
,	O
DLDL	B-Method
-	I-Method
8s	I-Method
leads	O
to	O
an	O
improvement	O
of	O
2.3	O
points	O
in	O
mean	B-Metric
IU	I-Metric
.	O
	
DLDL	B-Method
achieves	O
better	O
results	O
than	O
FCN	B-Method
,	O
which	O
suggests	O
it	O
is	O
important	O
to	O
improve	O
the	O
segmentation	B-Task
performance	O
using	O
label	O
ambiguity	O
.	O
	
In	O
addition	O
,	O
the	O
CRF	B-Method
further	O
improve	O
performance	O
of	O
DLDL	B-Method
-	I-Method
8s	I-Method
,	O
offering	O
a	O
2.6	O
%	O
absolute	O
increase	O
in	O
mean	B-Metric
IU	I-Metric
both	O
on	O
VOC2011	O
and	O
VOC2012	O
.	O
	
Fig	O
.	O
	
[	O
reference	O
]	O
shows	O
four	O
semantic	B-Task
segmentation	I-Task
examples	O
from	O
the	O
VOC2011	O
validation	O
images	O
using	O
FCN	B-Method
-	I-Method
8s	I-Method
,	O
DLDL	B-Method
-	I-Method
8s	I-Method
and	O
DLDL	B-Method
-	I-Method
8s	I-Method
-	I-Method
CRF	I-Method
.	O
	
We	O
can	O
see	O
that	O
DLDL	B-Method
-	I-Method
8s	I-Method
can	O
successfully	O
segment	O
some	O
small	O
objects	O
(	O
e.g.	O
,	O
car	O
and	O
bicycle	O
)	O
and	O
particularly	O
improve	O
the	O
segmentation	B-Task
of	I-Task
object	I-Task
boundaries	I-Task
	
(	O
e.g.	O
,	O
horse	O
’s	O
leg	O
and	O
plant	O
’s	O
leaves	O
)	O
,	O
but	O
FCN	B-Method
-	I-Method
8s	I-Method
	
does	O
not	O
.	O
	
DLDL	B-Method
-	I-Method
8s	I-Method
may	O
fail	O
,	O
e.g.	O
,	O
it	O
sees	O
a	O
flowerpot	O
as	O
a	O
potted	O
plant	O
in	O
the	O
fourth	O
row	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
.	O
	
Furthermore	O
,	O
compared	O
to	O
DLDL	B-Method
-	I-Method
8s	I-Method
,	O
DLDL	B-Method
-	I-Method
8s	I-Method
-	I-Method
CRF	I-Method
is	O
able	O
to	O
refine	O
coarse	O
pixel	O
-	O
level	O
label	O
predictions	O
to	O
produce	O
sharp	O
boundaries	O
and	O
fine	B-Task
-	I-Task
grained	I-Task
segmentations	I-Task
(	O
e.g.	O
,	O
plant	O
’s	O
leaves	O
)	O
.	O
	
[	O
subfloat	O
]	O
labelformat	O
=	O
empty	O
position	O
=	O
top	O
	
[	O
Image	O
]	O
	
[	O
FCN	B-Method
-	I-Method
8s	I-Method
]	O
	
[	O
DLDL	B-Method
-	I-Method
8s	I-Method
]	O
	
[	O
DLDL	B-Method
-	I-Method
8s	I-Method
+	I-Method
CRF	I-Method
]	O
	
[	O
Ground	O
-	O
truth	O
]	O
	
[	O
ChaLearn	B-Material
]	O
	
[	O
Morph	B-Material
]	O
	
[	O
BJUT	O
-	O
3D	O
]	O
	
[	O
AFLW	O
]	O
	
section	O
:	O
Discussions	O
	
In	O
this	O
section	O
,	O
we	O
try	O
to	O
understand	O
the	O
generalization	B-Metric
performance	I-Metric
of	O
DLDL	B-Method
through	O
feature	B-Method
visualization	I-Method
,	O
and	O
to	O
analyze	O
why	O
DLDL	B-Method
can	O
achieve	O
high	O
accuracy	B-Metric
with	O
limited	O
training	O
data	O
.	O
	
In	O
addition	O
,	O
a	O
study	O
of	O
the	O
hyper	O
-	O
parameter	O
is	O
also	O
provided	O
.	O
	
Feature	B-Task
visualization	I-Task
.	O
	
We	O
visualize	O
the	O
model	O
features	O
in	O
a	O
low	O
-	O
dimensional	O
space	O
.	O
	
Early	O
layers	O
learn	O
low	O
-	O
level	O
features	O
(	O
e.g.	O
,	O
edge	O
and	O
corner	O
)	O
and	O
latter	O
layers	O
learn	O
high	O
level	O
features	O
(	O
e.g.	O
,	O
shapes	O
and	O
objects	O
)	O
in	O
a	O
deep	B-Method
ConvNet	I-Method
.	O
	
Hence	O
,	O
we	O
extract	O
the	O
penultimate	O
layer	O
features	O
(	O
4	O
,	O
096	O
-	O
dimensional	O
)	O
on	O
Morph	B-Material
,	O
ChaLearn	B-Material
,	O
Pointing’04	O
and	O
AFLW	O
validation	O
sets	O
.	O
	
To	O
obtain	O
the	O
2	O
-	O
dimensional	O
embeddings	O
of	O
the	O
extracted	O
high	O
dimensional	O
features	O
,	O
we	O
employ	O
a	O
popular	O
dimension	B-Method
reduction	I-Method
algorithm	I-Method
t	I-Method
-	I-Method
SNE	I-Method
.	O
	
The	O
low	B-Method
-	I-Method
dimensional	I-Method
embeddings	I-Method
of	O
validation	O
images	O
from	O
the	O
above	O
four	O
datasets	O
are	O
shown	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
.	O
	
The	O
first	O
row	O
shows	O
the	O
2	O
-	O
dim	O
embeddings	O
of	O
hand	O
-	O
crafted	O
features	O
(	O
BIF	O
for	O
Morph	B-Material
and	O
Chalearn	B-Material
,	O
HOG	O
for	O
Pointing’04	B-Task
and	O
AFLW	O
)	O
and	O
the	O
second	O
row	O
shows	O
that	O
of	O
the	O
DLDL	B-Method
features	O
.	O
	
These	O
figures	O
are	O
colored	O
by	O
their	O
semantic	O
category	O
.	O
	
It	O
can	O
be	O
observed	O
that	O
clear	O
semantic	O
clusterings	O
(	O
old	O
or	O
young	O
for	O
age	B-Task
datasets	O
,	O
left	O
or	O
right	O
,	O
up	O
or	O
down	O
for	O
head	O
pose	O
datasets	O
)	O
appear	O
in	O
deep	O
features	O
but	O
do	O
not	O
in	O
hand	O
-	O
crafted	O
features	O
.	O
	
Reduce	O
over	B-Task
-	I-Task
fitting	I-Task
.	O
	
DLDL	B-Method
can	O
effectively	O
reduce	O
over	B-Task
-	I-Task
fitting	I-Task
when	O
the	O
training	O
set	O
is	O
small	O
.	O
	
This	O
effect	O
can	O
be	O
explained	O
by	O
the	O
label	O
ambiguity	O
.	O
	
Considering	O
an	O
input	O
sample	O
with	O
one	O
single	O
label	O
.	O
	
In	O
traditional	O
deep	B-Method
ConvNet	I-Method
,	O
and	O
for	O
all	O
.	O
	
In	O
DLDL	B-Method
,	O
the	O
label	O
distribution	O
contains	O
many	O
non	O
zeros	O
elements	O
.	O
	
The	O
diversity	O
of	O
labels	O
helps	O
reduce	O
over	B-Task
-	I-Task
fitting	I-Task
.	O
	
Moreover	O
,	O
the	O
objective	O
function	O
(	O
Eq	O
.	O
	
[	O
reference	O
]	O
)	O
of	O
DLDL	B-Method
can	O
be	O
rewritten	O
as	O
In	O
Eq	O
.	O
	
[	O
reference	O
]	O
,	O
the	O
first	O
term	O
is	O
the	O
tradition	B-Method
ConvNet	I-Method
loss	I-Method
function	I-Method
.	O
	
The	O
second	O
term	O
maximize	O
the	O
log	O
-	O
likelihood	O
of	O
the	O
ambiguous	O
labels	O
.	O
	
Unlike	O
existing	O
data	B-Method
augmentation	I-Method
techniques	I-Method
such	O
as	O
random	B-Method
cropping	I-Method
on	O
the	O
images	O
,	O
DLDL	B-Method
augments	O
data	O
on	O
the	O
label	O
side	O
.	O
	
In	O
Fig	O
.	O
	
[	O
reference	O
]	O
,	O
MAE	B-Metric
is	O
shown	O
as	O
a	O
function	O
of	O
the	O
number	O
of	O
epochs	O
on	O
two	O
age	B-Task
datasets	O
(	O
ChaLearn	B-Material
and	O
Morph	B-Material
)	O
and	O
two	O
head	O
pose	O
datasets	O
(	O
BJUT	O
-	O
3D	O
and	O
AFLW	O
)	O
.	O
	
On	O
ChaLearn	B-Material
and	O
AFLW	O
,	O
C	B-Method
-	I-Method
ConveNet	I-Method
(	I-Method
softmax	I-Method
)	I-Method
achieves	O
the	O
lowest	O
training	O
MAE	B-Metric
,	O
but	O
produces	O
the	O
highest	O
validation	O
MAE	B-Metric
.	O
	
In	O
particular	O
,	O
the	O
validation	O
MAE	B-Metric
increases	O
after	O
the	O
8th	O
epoch	O
on	O
ChaLearn	B-Material
.	O
	
Similar	O
phenomenon	O
is	O
observed	O
on	O
AFLW	B-Method
.	O
	
This	O
fact	O
shows	O
that	O
over	B-Task
-	I-Task
fitting	I-Task
happens	O
in	O
C	B-Method
-	I-Method
ConvNet	I-Method
when	O
the	O
number	O
of	O
training	O
images	O
is	O
small	O
.	O
	
Although	O
there	O
are	O
15	O
,	O
561	O
training	O
images	O
in	O
AFLW	O
,	O
each	O
category	O
contains	O
on	O
averagely	O
4	O
training	O
images	O
since	O
there	O
are	O
3	O
,	O
721	O
categories	O
.	O
	
Accelerate	B-Task
convergence	I-Task
.	O
	
We	O
further	O
analyze	O
the	O
convergence	B-Metric
performance	I-Metric
of	O
DLDL	B-Method
,	O
C	B-Method
-	I-Method
ConvNet	I-Method
and	O
R	B-Method
-	I-Method
ConvNet	I-Method
.	O
	
We	O
can	O
observe	O
that	O
the	O
training	O
MAE	B-Metric
is	O
reduced	O
very	O
slowly	O
at	O
the	O
beginning	O
of	O
training	O
using	O
C	B-Method
-	I-Method
ConvNet	I-Method
and	O
R	B-Method
-	I-Method
ConveNet	I-Method
in	O
many	O
cases	O
as	O
shown	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
.	O
	
On	O
the	O
contrary	O
,	O
the	O
MAE	B-Metric
of	O
DLDL	B-Method
reduces	O
quickly	O
.	O
	
Robust	O
performance	O
.	O
	
One	O
notable	O
observation	O
is	O
that	O
C	O
-	O
ConvNet	B-Method
and	O
R	B-Method
-	I-Method
ConveNet	I-Method
is	O
unstable	O
.	O
	
Fig	O
.	O
	
[	O
reference	O
]	O
shows	O
the	O
MAE	B-Metric
for	O
pitch	B-Task
+	I-Task
yaw	I-Task
,	O
a	O
complicated	O
estimation	B-Task
of	O
the	O
joint	B-Method
distribution	I-Method
.	O
	
This	O
is	O
a	O
very	O
sparse	O
label	O
set	O
because	O
the	O
interval	O
of	O
adjacent	O
class	O
(	O
pitch	O
or	O
yaw	O
)	O
is	O
.	O
	
R	B-Method
-	I-Method
ConvNet	I-Method
has	O
difficulty	O
in	O
estimating	O
this	O
output	O
,	O
yielding	O
errors	O
that	O
are	O
roughly	O
20	O
times	O
higher	O
than	O
DLDL	B-Method
and	O
C	O
-	O
ConvNet	O
.	O
	
On	O
the	O
other	O
hand	O
,	O
C	B-Method
-	I-Method
ConvNet	I-Method
easily	O
fall	O
into	O
over	O
-	O
fitting	O
when	O
there	O
are	O
not	O
enough	O
training	O
data	O
(	O
e.g	O
,	O
Fig	O
.	O
	
[	O
reference	O
]	O
and	O
Fig	O
.	O
	
[	O
reference	O
]	O
)	O
.	O
	
The	O
proposed	O
DLDL	B-Method
is	O
more	O
amenable	O
to	O
small	O
datasets	O
or	O
sparse	O
labels	O
than	O
C	B-Method
-	I-Method
ConvNet	I-Method
and	O
R	B-Method
-	I-Method
ConvNet	I-Method
.	O
	
Analyze	O
the	O
hyper	O
-	O
parameter	O
.	O
	
DLDL	B-Method
’s	O
performance	O
may	O
be	O
affected	O
by	O
the	O
label	O
distribution	O
.	O
	
Here	O
,	O
we	O
take	O
age	B-Task
estimation	I-Task
(	O
Morph	B-Material
)	O
and	O
head	B-Task
pose	I-Task
estimation	I-Task
(	O
Pointing’04	B-Task
)	O
for	O
examples	O
.	O
	
is	O
a	O
common	O
hyper	O
-	O
parameter	O
in	O
these	O
tasks	O
if	O
it	O
is	O
not	O
provided	O
in	O
the	O
ground	O
-	O
truth	O
.	O
	
We	O
have	O
empirically	O
set	O
in	O
Morph	B-Material
,	O
and	O
in	O
Pointing’04	O
in	O
our	O
experiments	O
.	O
	
In	O
order	O
to	O
study	O
the	O
impact	O
of	O
,	O
we	O
test	O
DLDL	B-Method
with	O
different	O
values	O
,	O
changing	O
from	O
0	O
to	O
3	O
with	O
0.5	O
interval	O
.	O
	
Fig	O
.	O
	
[	O
reference	O
]	O
shows	O
the	O
MAE	B-Metric
performance	O
on	O
Morph	B-Material
and	O
Pointing’04	B-Task
with	O
different	O
.	O
	
We	O
can	O
see	O
that	O
a	O
proper	O
is	O
important	O
for	O
low	O
MAE	B-Metric
.	O
	
But	O
generally	O
speaking	O
,	O
a	O
value	O
that	O
is	O
close	O
to	O
the	O
interval	O
between	O
neighboring	O
labels	O
is	O
a	O
good	O
choice	O
.	O
	
Because	O
the	O
shape	O
of	O
all	O
curves	O
are	O
V	O
-	O
shape	O
like	O
,	O
it	O
is	O
also	O
very	O
convenient	O
to	O
find	O
an	O
optimal	O
value	O
using	O
the	O
cross	B-Method
-	I-Method
validation	I-Method
strategy	I-Method
.	O
	
section	O
:	O
Conclusion	O
	
We	O
observe	O
that	O
current	O
deep	B-Method
ConvNets	I-Method
can	O
not	O
successfully	O
learn	O
good	O
models	O
when	O
there	O
are	O
not	O
enough	O
training	O
data	O
and	O
/	O
or	O
the	O
labels	O
are	O
ambiguous	O
.	O
	
We	O
propose	O
DLDL	B-Method
,	O
a	O
deep	B-Method
label	I-Method
distribution	I-Method
learning	I-Method
framework	I-Method
to	O
solve	O
this	O
issue	O
by	O
exploiting	O
label	O
ambiguity	O
.	O
	
In	O
DLDL	B-Method
,	O
each	O
image	O
is	O
labeled	O
by	O
a	O
label	O
distribution	O
,	O
which	O
can	O
utilize	O
label	O
ambiguity	O
in	O
both	O
feature	B-Task
learning	I-Task
and	O
classifier	B-Task
learning	I-Task
.	O
	
DLDL	B-Method
consistently	O
improves	O
the	O
network	B-Task
training	I-Task
process	I-Task
in	O
our	O
experiments	O
,	O
by	O
preventing	O
it	O
from	O
over	B-Task
-	I-Task
fitting	I-Task
when	O
the	O
training	O
set	O
is	O
small	O
.	O
	
We	O
empirically	O
showed	O
that	O
DLDL	B-Method
produces	O
robust	O
and	O
competitive	O
performances	O
than	O
traditional	O
classification	B-Method
or	I-Method
regression	I-Method
deep	I-Method
models	I-Method
on	O
several	O
popular	O
visual	B-Task
recognition	I-Task
tasks	I-Task
.	O
	
However	O
,	O
constructing	O
a	O
reasonable	O
label	O
distribution	O
is	O
still	O
challenging	O
due	O
to	O
the	O
diversity	O
of	O
label	O
space	O
for	O
different	O
recognition	B-Task
tasks	I-Task
.	O
	
It	O
is	O
an	O
interesting	O
direction	O
to	O
extend	O
DLDL	B-Method
to	O
more	O
recognition	B-Task
problems	I-Task
by	O
constructing	O
different	O
label	O
distributions	O
.	O
	
bibliography	O
:	O
References	O
	
[	O
]	O
Bin	O
-	O
Bin	O
Gao	O
received	O
the	O
B.S.	O
and	O
M.S.	O
degrees	O
in	O
applied	O
mathematics	O
in	O
2010	O
and	O
2013	O
,	O
respectively	O
.	O
	
He	O
is	O
currently	O
pursuing	O
the	O
Ph.D.	O
degree	O
in	O
the	O
Department	O
of	O
Computer	O
Science	O
and	O
Technology	O
,	O
Nanjing	O
University	O
,	O
China	O
.	O
	
His	O
research	O
interests	O
include	O
computer	B-Task
vision	I-Task
and	O
machine	B-Task
learning	I-Task
.	O
	
{	O
IEEEbiography}	O
[]	O
Chao	O
Xing	O
received	O
the	O
B.S.	O
degree	O
in	O
software	O
engineering	O
from	O
Southeast	O
University	O
,	O
China	O
,	O
in	O
2014	O
.	O
	
He	O
is	O
currently	O
a	O
postgraduate	O
student	O
in	O
the	O
School	O
of	O
Computer	O
Science	O
and	O
Engineering	O
at	O
Southeast	O
University	O
,	O
China	O
.	O
	
His	O
research	O
interests	O
include	O
pattern	B-Task
recognition	I-Task
,	O
machine	B-Task
learning	I-Task
,	O
and	O
data	B-Task
mining	I-Task
.	O
	
{	O
IEEEbiography}	O
[]	O
Chen	O
-	O
Wei	O
Xie	O
received	O
his	O
B.S.	O
degree	O
from	O
Southeast	O
University	O
,	O
China	O
,	O
in	O
2015	O
.	O
	
He	O
is	O
currently	O
a	O
postgraduate	O
student	O
in	O
the	O
Department	O
of	O
Computer	O
Science	O
and	O
Technology	O
,	O
Nanjing	O
University	O
,	O
China	O
.	O
	
His	O
research	O
interests	O
include	O
computer	B-Task
vision	I-Task
and	O
machine	B-Task
learning	I-Task
.	O
	
{	O
	
IEEEbiography}	O
[]	O
Jianxin	O
Wu	O
(	O
M’09	O
)	O
received	O
the	O
B.S.	O
and	O
M.S.	O
degrees	O
in	O
computer	O
science	O
from	O
Nanjing	O
University	O
,	O
and	O
the	O
Ph.D.	O
degree	O
in	O
computer	O
science	O
from	O
the	O
Georgia	O
Institute	O
of	O
Technology	O
.	O
	
He	O
was	O
an	O
Assistant	O
Professor	O
with	O
the	O
Nanyang	O
Technological	O
University	O
,	O
Singapore	O
.	O
	
He	O
is	O
currently	O
a	O
Professor	O
with	O
the	O
Department	O
of	O
Computer	O
Science	O
and	O
Technology	O
,	O
Nanjing	O
University	O
,	O
China	O
,	O
and	O
is	O
associated	O
with	O
the	O
National	O
Key	O
Laboratory	O
for	O
Novel	O
Software	O
Technology	O
,	O
China	O
.	O
	
His	O
current	O
research	O
interests	O
include	O
computer	B-Task
vision	I-Task
and	O
machine	B-Task
learning	I-Task
.	O
	
He	O
has	O
served	O
as	O
an	O
Area	O
Chair	O
for	O
CVPR	O
2017	O
and	O
ICCV	O
2015	O
,	O
	
a	O
Senior	O
PC	O
Member	O
for	O
AAAI	O
2017	O
and	O
AAAI	O
2016	O
,	O
and	O
an	O
Associate	O
Editor	O
of	O
Pattern	O
Recognition	O
Journal	O
.	O
	
{	O
IEEEbiography}	O
[]	O
Xin	O
Geng	O
(	O
M’13	O
)	O
received	O
the	O
B.S.	O
and	O
M.S.	O
degrees	O
in	O
computer	O
science	O
from	O
Nanjing	O
University	O
,	O
China	O
,	O
in	O
2001	O
and	O
2004	O
,	O
respectively	O
,	O
and	O
the	O
Ph	O
.	O
	
D	O
degree	O
from	O
Deakin	O
University	O
,	O
Australia	O
in	O
2008	O
.	O
	
He	O
joined	O
the	O
School	O
of	O
Computer	O
Science	O
and	O
Engineering	O
at	O
Southeast	O
University	O
,	O
China	O
,	O
in	O
2008	O
,	O
and	O
is	O
currently	O
a	O
professor	O
and	O
vice	O
dean	O
of	O
the	O
school	O
.	O
	
He	O
has	O
authored	O
over	O
50	O
refereed	O
papers	O
,	O
and	O
he	O
holds	O
five	O
patents	O
in	O
these	O
areas	O
.	O
	
His	O
research	O
interests	O
include	O
pattern	B-Task
recognition	I-Task
,	O
machine	B-Task
learning	I-Task
,	O
and	O
computer	B-Task
vision	I-Task
.	O
	
In	O
this	O
work	O
we	O
explore	O
recent	O
advances	O
in	O
Recurrent	B-Method
Neural	I-Method
Networks	I-Method
for	O
large	O
scale	O
Language	B-Task
Modeling	I-Task
,	O
a	O
task	O
central	O
to	O
language	B-Task
understanding	I-Task
.	O
	
We	O
extend	O
current	O
models	O
to	O
deal	O
with	O
two	O
key	O
challenges	O
present	O
in	O
this	O
task	O
:	O
corpora	O
and	O
vocabulary	O
sizes	O
,	O
and	O
complex	O
,	O
long	O
term	O
structure	O
of	O
language	O
.	O
	
We	O
perform	O
an	O
exhaustive	O
study	O
on	O
techniques	O
such	O
as	O
character	B-Method
Convolutional	I-Method
Neural	I-Method
Networks	I-Method
or	O
Long	B-Method
-	I-Method
Short	I-Method
Term	I-Method
Memory	I-Method
,	O
on	O
the	O
One	B-Material
Billion	I-Material
Word	I-Material
Benchmark	I-Material
.	O
	
Our	O
best	O
single	O
model	O
significantly	O
improves	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
perplexity	B-Metric
from	O
51.3	O
down	O
to	O
30.0	O
(	O
whilst	O
reducing	O
the	O
number	O
of	O
parameters	O
by	O
a	O
factor	O
of	O
20	O
)	O
,	O
while	O
an	O
ensemble	B-Method
of	I-Method
models	I-Method
sets	O
a	O
new	O
record	O
by	O
improving	O
perplexity	B-Metric
from	O
41.0	O
down	O
to	O
23.7	O
.	O
	
We	O
also	O
release	O
these	O
models	O
for	O
the	O
NLP	B-Task
and	I-Task
ML	I-Task
community	I-Task
to	O
study	O
and	O
improve	O
upon	O
.	O
	
ExploringtheLimitsofLanguageModeling	O
	
section	O
:	O
Introduction	O
	
Language	B-Task
Modeling	I-Task
(	O
LM	B-Task
)	I-Task
is	O
a	O
task	O
central	O
to	O
Natural	B-Task
Language	I-Task
Processing	I-Task
(	I-Task
NLP	I-Task
)	I-Task
and	O
Language	B-Task
Understanding	I-Task
.	O
	
Models	O
which	O
can	O
accurately	O
place	O
distributions	O
over	O
sentences	O
not	O
only	O
encode	O
complexities	O
of	O
language	O
such	O
as	O
grammatical	O
structure	O
,	O
but	O
also	O
distill	O
a	O
fair	O
amount	O
of	O
information	O
about	O
the	O
knowledge	O
that	O
a	O
corpora	O
may	O
contain	O
.	O
	
Indeed	O
,	O
models	O
that	O
are	O
able	O
to	O
assign	O
a	O
low	O
probability	O
to	O
sentences	O
that	O
are	O
grammatically	O
correct	O
but	O
unlikely	O
	
may	O
help	O
other	O
tasks	O
in	O
fundamental	B-Task
language	I-Task
understanding	I-Task
like	O
question	B-Task
answering	I-Task
,	O
machine	B-Task
translation	I-Task
,	O
or	O
text	B-Task
summarization	I-Task
.	O
	
LMs	B-Task
have	O
played	O
a	O
key	O
role	O
in	O
traditional	O
NLP	B-Task
tasks	I-Task
such	O
as	O
speech	B-Task
recognition	I-Task
,	O
machine	B-Task
translation	I-Task
,	O
or	O
text	B-Task
summarization	I-Task
.	O
	
Often	O
(	O
although	O
not	O
always	O
)	O
,	O
training	O
better	O
language	B-Method
models	I-Method
improves	O
the	O
underlying	O
metrics	B-Metric
of	O
the	O
downstream	B-Task
task	I-Task
(	O
such	O
as	O
word	B-Metric
error	I-Metric
rate	I-Metric
for	O
speech	B-Task
recognition	I-Task
,	O
or	O
BLEU	B-Metric
score	I-Metric
for	O
translation	B-Task
)	O
,	O
which	O
makes	O
the	O
task	O
of	O
training	O
better	O
LMs	B-Task
valuable	O
by	O
itself	O
.	O
	
Further	O
,	O
when	O
trained	O
on	O
vast	O
amounts	O
of	O
data	O
,	O
language	B-Task
models	I-Task
compactly	O
extract	O
knowledge	O
encoded	O
in	O
the	O
training	O
data	O
.	O
	
For	O
example	O
,	O
when	O
trained	O
on	O
movie	O
subtitles	O
,	O
these	O
language	B-Method
models	I-Method
are	O
able	O
to	O
generate	O
basic	O
answers	O
to	O
questions	O
about	O
object	O
colors	O
,	O
facts	O
about	O
people	O
,	O
etc	O
.	O
	
Lastly	O
,	O
recently	O
proposed	O
sequence	B-Method
-	I-Method
to	I-Method
-	I-Method
sequence	I-Method
models	I-Method
employ	O
conditional	B-Method
language	I-Method
models	I-Method
as	O
their	O
key	O
component	O
to	O
solve	O
diverse	O
tasks	O
like	O
machine	B-Task
translation	I-Task
or	O
video	B-Task
generation	I-Task
.	O
	
Deep	B-Method
Learning	I-Method
and	O
Recurrent	B-Method
Neural	I-Method
Networks	I-Method
(	O
RNNs	B-Method
)	O
have	O
fueled	O
language	B-Task
modeling	I-Task
research	O
in	O
the	O
past	O
years	O
as	O
it	O
allowed	O
researchers	O
to	O
explore	O
many	O
tasks	O
for	O
which	O
the	O
strong	O
conditional	O
independence	O
assumptions	O
are	O
unrealistic	O
.	O
	
Despite	O
the	O
fact	O
that	O
simpler	O
models	O
,	O
such	O
as	O
N	B-Method
-	I-Method
grams	I-Method
,	O
only	O
use	O
a	O
short	O
history	O
of	O
previous	O
words	O
to	O
predict	O
the	O
next	O
word	O
,	O
they	O
are	O
still	O
a	O
key	O
component	O
to	O
high	O
quality	O
,	O
low	B-Metric
perplexity	I-Metric
LMs	I-Metric
.	O
	
Indeed	O
,	O
most	O
recent	O
work	O
on	O
large	B-Task
scale	I-Task
LM	I-Task
has	O
shown	O
that	O
RNNs	B-Method
are	O
great	O
in	O
combination	O
with	O
N	B-Method
-	I-Method
grams	I-Method
,	O
as	O
they	O
may	O
have	O
different	O
strengths	O
that	O
complement	O
N	B-Method
-	I-Method
gram	I-Method
models	I-Method
,	O
but	O
worse	O
when	O
considered	O
in	O
isolation	O
.	O
	
We	O
believe	O
that	O
,	O
despite	O
much	O
work	O
being	O
devoted	O
to	O
small	O
data	O
sets	O
like	O
the	O
Penn	O
Tree	O
Bank	O
(	O
PTB	O
)	O
,	O
research	O
on	O
larger	O
tasks	O
is	O
very	O
relevant	O
as	O
overfitting	O
is	O
not	O
the	O
main	O
limitation	O
in	O
current	O
language	B-Task
modeling	I-Task
,	O
but	O
is	O
the	O
main	O
characteristic	O
of	O
the	O
PTB	B-Task
task	I-Task
.	O
	
Results	O
on	O
larger	O
corpora	O
usually	O
show	O
better	O
what	O
matters	O
as	O
many	O
ideas	O
work	O
well	O
on	O
small	O
data	O
sets	O
but	O
fail	O
to	O
improve	O
on	O
larger	O
data	O
sets	O
.	O
	
Further	O
,	O
given	O
current	O
hardware	O
trends	O
and	O
vast	O
amounts	O
of	O
text	O
available	O
on	O
the	O
Web	O
,	O
it	O
is	O
much	O
more	O
straightforward	O
to	O
tackle	O
large	B-Task
scale	I-Task
modeling	I-Task
than	O
it	O
used	O
to	O
be	O
.	O
	
Thus	O
,	O
we	O
hope	O
that	O
our	O
work	O
will	O
help	O
and	O
motivate	O
researchers	O
to	O
work	O
on	O
traditional	O
LM	B-Task
beyond	O
PTB	B-Method
–	O
for	O
this	O
purpose	O
,	O
we	O
will	O
open	O
-	O
source	O
our	O
models	O
and	O
training	B-Method
recipes	I-Method
.	O
	
We	O
focused	O
on	O
a	O
well	O
known	O
,	O
large	B-Task
scale	I-Task
LM	I-Task
benchmark	O
:	O
the	O
One	B-Material
Billion	I-Material
Word	I-Material
Benchmark	I-Material
data	O
set	O
.	O
	
This	O
data	O
set	O
is	O
much	O
larger	O
than	O
PTB	B-Method
(	O
one	O
thousand	O
fold	O
,	O
800k	O
word	O
vocabulary	O
and	O
1B	B-Material
words	I-Material
training	I-Material
data	I-Material
)	O
and	O
far	O
more	O
challenging	O
.	O
	
Similar	O
to	O
Imagenet	O
,	O
which	O
helped	O
advance	O
computer	B-Task
vision	I-Task
,	O
we	O
believe	O
that	O
releasing	O
and	O
working	O
on	O
large	O
data	O
sets	O
and	O
models	O
with	O
clear	O
benchmarks	O
will	O
help	O
advance	O
Language	B-Task
Modeling	I-Task
.	O
	
The	O
contributions	O
of	O
our	O
work	O
are	O
as	O
follows	O
:	O
We	O
explored	O
,	O
extended	O
and	O
tried	O
to	O
unify	O
some	O
of	O
the	O
current	O
research	O
on	O
large	B-Task
scale	I-Task
LM	I-Task
.	O
	
Specifically	O
,	O
we	O
designed	O
a	O
Softmax	B-Method
loss	I-Method
which	O
is	O
based	O
on	O
character	B-Method
level	I-Method
CNNs	I-Method
,	O
is	O
efficient	O
to	O
train	O
,	O
and	O
is	O
as	O
precise	O
as	O
a	O
full	B-Method
Softmax	I-Method
which	O
has	O
orders	O
of	O
magnitude	O
more	O
parameters	O
.	O
	
Our	O
study	O
yielded	O
significant	O
improvements	O
to	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
on	O
a	O
well	O
known	O
,	O
large	B-Task
scale	I-Task
LM	I-Task
task	O
:	O
from	O
51.3	O
down	O
to	O
30.0	O
perplexity	B-Metric
for	O
single	O
models	O
whilst	O
reducing	O
the	O
number	O
of	O
parameters	O
by	O
a	O
factor	O
of	O
20	O
.	O
	
We	O
show	O
that	O
an	O
ensemble	O
of	O
a	O
number	O
of	O
different	O
models	O
can	O
bring	O
down	O
perplexity	B-Metric
on	O
this	O
task	O
to	O
23.7	O
,	O
a	O
large	O
improvement	O
compared	O
to	O
current	O
state	O
-	O
of	O
-	O
art	O
.	O
	
We	O
share	O
the	O
model	O
and	O
recipes	O
in	O
order	O
to	O
help	O
and	O
motivate	O
further	O
research	O
in	O
this	O
area	O
.	O
	
In	O
Section	O
[	O
reference	O
]	O
we	O
review	O
important	O
concepts	O
and	O
previous	O
work	O
on	O
language	B-Task
modeling	I-Task
.	O
	
Section	O
[	O
reference	O
]	O
presents	O
our	O
contributions	O
to	O
the	O
field	O
of	O
neural	O
language	B-Task
modeling	I-Task
,	O
emphasizing	O
large	B-Method
scale	I-Method
recurrent	I-Method
neural	I-Method
network	I-Method
training	I-Method
.	O
	
Sections	O
[	O
reference	O
]	O
and	O
[	O
reference	O
]	O
aim	O
at	O
exhaustively	O
describing	O
our	O
experience	O
and	O
understanding	O
throughout	O
the	O
project	O
,	O
as	O
well	O
as	O
emplacing	O
our	O
work	O
relative	O
to	O
other	O
known	O
approaches	O
.	O
	
section	O
:	O
Related	O
Work	O
	
In	O
this	O
section	O
we	O
describe	O
previous	O
work	O
relevant	O
to	O
the	O
approaches	O
discussed	O
in	O
this	O
paper	O
.	O
	
A	O
more	O
detailed	O
discussion	O
on	O
language	B-Task
modeling	I-Task
research	O
is	O
provided	O
in	O
.	O
	
subsection	O
:	O
Language	B-Task
Models	I-Task
	
Language	B-Task
Modeling	I-Task
(	O
LM	B-Task
)	I-Task
has	O
been	O
a	O
central	O
task	O
in	O
NLP	B-Task
.	O
	
The	O
goal	O
of	O
LM	B-Task
is	O
to	O
learn	O
a	O
probability	O
distribution	O
over	O
sequences	O
of	O
symbols	O
pertaining	O
to	O
a	O
language	O
.	O
	
Much	O
work	O
has	O
been	O
done	O
on	O
both	O
parametric	O
(	O
e.g.	O
,	O
log	B-Method
-	I-Method
linear	I-Method
models	I-Method
)	O
and	O
non	B-Method
-	I-Method
parametric	I-Method
approaches	I-Method
(	O
e.g.	O
,	O
count	O
-	O
based	O
LMs	B-Task
)	O
.	O
	
Count	B-Method
-	I-Method
based	I-Method
approaches	I-Method
(	O
based	O
on	O
statistics	B-Method
of	I-Method
N	I-Method
-	I-Method
grams	I-Method
)	O
typically	O
add	O
smoothing	B-Method
which	O
account	O
for	O
unseen	O
(	O
yet	O
possible	O
)	O
sequences	O
,	O
and	O
have	O
been	O
quite	O
successful	O
.	O
	
To	O
this	O
extent	O
,	O
Kneser	B-Method
-	I-Method
Ney	I-Method
smoothed	I-Method
5	I-Method
-	I-Method
gram	I-Method
models	I-Method
are	O
a	O
fairly	O
strong	O
baseline	O
which	O
,	O
for	O
large	O
amounts	O
of	O
training	O
data	O
,	O
have	O
challenged	O
other	O
parametric	B-Method
approaches	I-Method
based	O
on	O
Neural	B-Method
Networks	I-Method
.	O
	
Most	O
of	O
our	O
work	O
is	O
based	O
on	O
Recurrent	B-Method
Neural	I-Method
Networks	I-Method
(	I-Method
RNN	I-Method
)	I-Method
models	I-Method
which	O
retain	O
long	O
term	O
dependencies	O
.	O
	
To	O
this	O
extent	O
,	O
we	O
used	O
the	O
Long	B-Method
-	I-Method
Short	I-Method
Term	I-Method
Memory	I-Method
model	I-Method
which	O
uses	O
a	O
gating	B-Method
mechanism	I-Method
to	O
ensure	O
proper	O
propagation	O
of	O
information	O
through	O
many	O
time	O
steps	O
.	O
	
Much	O
work	O
has	O
been	O
done	O
on	O
small	O
and	O
large	O
scale	O
RNN	O
-	O
based	O
LMs	B-Task
.	O
	
The	O
architectures	O
that	O
we	O
considered	O
in	O
this	O
paper	O
are	O
represented	O
in	O
Figure	O
[	O
reference	O
]	O
.	O
	
In	O
our	O
work	O
,	O
we	O
train	O
models	O
on	O
the	O
popular	O
One	B-Material
Billion	I-Material
Word	I-Material
Benchmark	I-Material
,	O
which	O
can	O
be	O
considered	O
to	O
be	O
a	O
medium	O
-	O
sized	O
data	O
set	O
for	O
count	O
-	O
based	O
LMs	B-Task
but	O
a	O
very	O
large	O
data	O
set	O
for	O
NN	O
-	O
based	O
LMs	B-Task
.	O
	
This	O
regime	O
is	O
most	O
interesting	O
to	O
us	O
as	O
we	O
believe	O
learning	O
a	O
very	O
good	O
model	O
of	O
human	B-Task
language	I-Task
is	O
a	O
complex	O
task	O
which	O
will	O
require	O
large	O
models	O
,	O
and	O
thus	O
large	O
amounts	O
of	O
data	O
.	O
	
Further	O
advances	O
in	O
data	O
availability	O
and	O
computational	O
resources	O
helped	O
our	O
study	O
.	O
	
We	O
argue	O
this	O
leap	O
in	O
scale	O
enabled	O
tremendous	O
advances	O
in	O
deep	B-Task
learning	I-Task
.	O
	
A	O
clear	O
example	O
found	O
in	O
computer	B-Task
vision	I-Task
is	O
Imagenet	O
,	O
which	O
enabled	O
learning	O
complex	O
vision	B-Method
models	I-Method
from	O
large	O
amounts	O
of	O
data	O
.	O
	
A	O
crucial	O
aspect	O
which	O
we	O
discuss	O
in	O
detail	O
in	O
later	O
sections	O
is	O
the	O
size	O
of	O
our	O
models	O
.	O
	
Despite	O
the	O
large	O
number	O
of	O
parameters	O
,	O
we	O
try	O
to	O
minimize	O
computation	O
as	O
much	O
as	O
possible	O
by	O
adopting	O
a	O
strategy	O
proposed	O
in	O
of	O
projecting	O
a	O
relatively	O
big	O
recurrent	O
state	O
space	O
down	O
so	O
that	O
the	O
matrices	O
involved	O
remain	O
relatively	O
small	O
,	O
yet	O
the	O
model	O
has	O
large	O
memory	O
capacity	O
.	O
	
subsection	O
:	O
Convolutional	B-Method
Embedding	I-Method
Models	I-Method
	
There	O
is	O
an	O
increased	O
interest	O
in	O
incorporating	O
character	O
-	O
level	O
inputs	O
to	O
build	O
word	B-Method
embeddings	I-Method
for	O
various	O
NLP	B-Task
problems	I-Task
,	O
including	O
part	B-Task
-	I-Task
of	I-Task
-	I-Task
speech	I-Task
tagging	I-Task
,	O
parsing	B-Task
and	O
language	B-Task
modeling	I-Task
.	O
	
The	O
additional	O
character	O
information	O
has	O
been	O
shown	O
useful	O
on	O
relatively	O
small	O
benchmark	O
data	O
sets	O
.	O
	
The	O
approach	O
proposed	O
in	O
builds	O
word	B-Task
embeddings	I-Task
using	O
bidirectional	O
LSTMs	B-Method
over	O
the	O
characters	O
.	O
	
The	O
recurrent	B-Method
networks	I-Method
process	O
sequences	O
of	O
characters	O
from	O
both	O
sides	O
and	O
their	O
final	O
state	O
vectors	O
are	O
concatenated	O
.	O
	
The	O
resulting	O
representation	O
is	O
then	O
fed	O
to	O
a	O
Neural	B-Method
Network	I-Method
.	O
	
This	O
model	O
achieved	O
very	O
good	O
results	O
on	O
a	O
part	B-Task
-	I-Task
of	I-Task
-	I-Task
speech	I-Task
tagging	I-Task
task	I-Task
.	O
	
In	O
,	O
the	O
words	O
characters	O
are	O
processed	O
by	O
a	O
1	B-Method
-	I-Method
d	I-Method
CNN	I-Method
with	O
max	B-Method
-	I-Method
pooling	I-Method
across	O
the	O
sequence	O
for	O
each	O
convolutional	O
feature	O
.	O
	
The	O
resulting	O
features	O
are	O
fed	O
to	O
a	O
2	B-Method
-	I-Method
layer	I-Method
highway	I-Method
network	I-Method
,	O
which	O
allows	O
the	O
embedding	B-Method
to	O
learn	O
semantic	B-Method
representations	I-Method
.	O
	
The	O
model	O
was	O
evaluated	O
on	O
small	O
-	O
scale	O
language	B-Task
modeling	I-Task
experiments	O
for	O
various	O
languages	O
and	O
matched	O
the	O
best	O
results	O
on	O
the	O
PTB	O
data	O
set	O
despite	O
having	O
60	O
%	O
fewer	O
parameters	O
.	O
	
subsection	O
:	O
Softmax	B-Method
Over	O
Large	O
Vocabularies	O
	
Assigning	O
probability	O
distributions	O
over	O
large	O
vocabularies	O
is	O
computationally	O
challenging	O
.	O
	
For	O
modeling	B-Task
language	I-Task
,	O
maximizing	O
log	O
-	O
likelihood	O
of	O
a	O
given	O
word	O
sequence	O
leads	O
to	O
optimizing	O
cross	O
-	O
entropy	O
between	O
the	O
target	O
probability	O
distribution	O
(	O
e.g.	O
,	O
the	O
target	O
word	O
we	O
should	O
be	O
predicting	O
)	O
,	O
and	O
our	O
model	O
predictions	O
.	O
	
Generally	O
,	O
predictions	O
come	O
from	O
a	O
linear	B-Method
layer	I-Method
followed	O
by	O
a	O
Softmax	B-Method
non	I-Method
-	I-Method
linearity	I-Method
:	O
where	O
is	O
the	O
logit	O
corresponding	O
to	O
a	O
word	O
.	O
	
The	O
logit	B-Method
is	O
generally	O
computed	O
as	O
an	O
inner	B-Method
product	I-Method
where	O
is	O
a	O
context	O
vector	O
and	O
is	O
a	O
“	O
word	O
embedding	O
”	O
for	O
.	O
	
The	O
main	O
challenge	O
when	O
is	O
very	O
large	O
(	O
in	O
the	O
order	O
of	O
one	O
million	O
in	O
this	O
paper	O
)	O
is	O
the	O
fact	O
that	O
computing	O
all	O
inner	O
products	O
between	O
and	O
all	O
embeddings	O
becomes	O
prohibitively	O
slow	O
during	O
training	B-Task
(	O
even	O
when	O
exploiting	O
matrix	B-Method
-	I-Method
matrix	I-Method
multiplications	I-Method
and	O
modern	O
GPUs	B-Method
)	O
.	O
	
Several	O
approaches	O
have	O
been	O
proposed	O
to	O
cope	O
with	O
the	O
scaling	B-Task
issue	I-Task
:	O
importance	B-Method
sampling	I-Method
,	O
Noise	B-Method
Contrastive	I-Method
Estimation	I-Method
(	O
NCE	B-Method
)	O
,	O
self	B-Method
normalizing	I-Method
partition	I-Method
functions	I-Method
or	O
Hierarchical	B-Method
Softmax	I-Method
–	O
	
they	O
all	O
offer	O
good	O
solutions	O
to	O
this	O
problem	O
.	O
	
We	O
found	O
importance	B-Method
sampling	I-Method
to	O
be	O
quite	O
effective	O
on	O
this	O
task	O
,	O
and	O
explain	O
the	O
connection	O
between	O
it	O
and	O
NCE	B-Method
in	O
the	O
following	O
section	O
,	O
as	O
they	O
are	O
closely	O
related	O
.	O
	
section	O
:	O
Language	B-Task
Modeling	I-Task
Improvements	O
	
Recurrent	O
Neural	O
Networks	O
based	O
LMs	B-Task
employ	O
the	O
chain	B-Method
rule	I-Method
to	O
model	O
joint	O
probabilities	O
over	O
word	O
sequences	O
:	O
where	O
the	O
context	O
of	O
all	O
previous	O
words	O
is	O
encoded	O
with	O
an	O
LSTM	B-Method
,	O
and	O
the	O
probability	O
over	O
words	O
uses	O
a	O
Softmax	O
(	O
see	O
Figure	O
[	O
reference	O
]	O
	
(	O
a	O
)	O
)	O
.	O
	
subsection	O
:	O
Relationship	O
between	O
Noise	B-Method
Contrastive	I-Method
Estimation	I-Method
and	O
Importance	B-Method
Sampling	I-Method
	
As	O
discussed	O
in	O
Section	O
[	O
reference	O
]	O
,	O
a	O
large	O
scale	O
Softmax	B-Method
is	O
necessary	O
for	O
training	O
good	O
LMs	B-Task
because	O
of	O
the	O
vocabulary	O
size	O
.	O
	
A	O
Hierarchical	B-Method
Softmax	I-Method
employs	O
a	O
tree	O
in	O
which	O
the	O
probability	O
distribution	O
over	O
words	O
is	O
decomposed	O
into	O
a	O
product	O
of	O
two	O
probabilities	O
for	O
each	O
word	O
,	O
greatly	O
reducing	O
training	B-Task
and	I-Task
inference	I-Task
time	I-Task
as	O
only	O
the	O
path	O
specified	O
by	O
the	O
hierarchy	O
needs	O
to	O
be	O
computed	O
and	O
updated	O
.	O
	
Choosing	O
a	O
good	O
hierarchy	O
is	O
important	O
for	O
obtaining	O
good	O
results	O
and	O
we	O
did	O
not	O
explore	O
this	O
approach	O
further	O
for	O
this	O
paper	O
as	O
sampling	B-Method
methods	I-Method
worked	O
well	O
for	O
our	O
setup	O
.	O
	
Sampling	B-Method
approaches	I-Method
are	O
only	O
useful	O
during	O
training	B-Task
,	O
as	O
they	O
propose	O
an	O
approximation	O
to	O
the	O
loss	O
which	O
is	O
cheap	O
to	O
compute	O
(	O
also	O
in	O
a	O
distributed	B-Task
setting	I-Task
)	O
	
–	O
however	O
,	O
at	O
inference	O
time	O
one	O
still	O
has	O
to	O
compute	O
the	O
normalization	O
term	O
over	O
all	O
words	O
.	O
	
Noise	B-Method
Contrastive	I-Method
Estimation	I-Method
(	O
NCE	B-Method
)	O
proposes	O
to	O
consider	O
a	O
surrogate	B-Task
binary	I-Task
classification	I-Task
task	I-Task
in	O
which	O
a	O
classifier	B-Method
is	O
trained	O
to	O
discriminate	O
between	O
true	O
data	O
,	O
or	O
samples	O
coming	O
from	O
some	O
arbitrary	O
distribution	O
.	O
	
If	O
both	O
the	O
noise	O
and	O
data	O
distributions	O
were	O
known	O
,	O
the	O
optimal	O
classifier	B-Method
would	O
be	O
:	O
where	O
is	O
the	O
binary	O
random	O
variable	O
indicating	O
whether	O
comes	O
from	O
the	O
true	O
data	O
distribution	O
,	O
is	O
the	O
number	O
of	O
negative	O
samples	O
per	O
positive	O
word	O
,	O
and	O
and	O
are	O
the	O
data	O
and	O
noise	O
distribution	O
respectively	O
	
(	O
we	O
dropped	O
any	O
dependency	O
on	O
previous	O
words	O
for	O
notational	O
simplicity	O
)	O
.	O
	
It	O
is	O
easy	O
to	O
show	O
that	O
if	O
we	O
train	O
a	O
logistic	B-Method
classifier	I-Method
where	O
is	O
the	O
logistic	O
function	O
,	O
then	O
,	O
is	O
a	O
good	O
approximation	O
of	O
(	O
is	O
a	O
logit	O
which	O
e.g.	O
an	O
LSTM	B-Method
LM	I-Method
computes	O
)	O
.	O
	
The	O
other	O
technique	O
,	O
which	O
is	O
based	O
on	O
importance	B-Method
sampling	I-Method
(	O
IS	B-Method
)	O
,	O
proposes	O
to	O
directly	O
approximate	O
the	O
partition	O
function	O
(	O
which	O
comprises	O
a	O
sum	O
over	O
all	O
words	O
)	O
with	O
an	O
estimate	O
of	O
it	O
through	O
importance	B-Method
sampling	I-Method
.	O
	
Though	O
the	O
methods	O
look	O
superficially	O
similar	O
,	O
we	O
will	O
derive	O
a	O
similar	O
surrogate	B-Task
classification	I-Task
task	I-Task
akin	O
to	O
NCE	B-Method
which	O
arrives	O
at	O
IS	O
,	O
showing	O
a	O
strong	O
connection	O
between	O
the	O
two	O
.	O
	
Suppose	O
that	O
,	O
instead	O
of	O
having	O
a	O
binary	B-Task
task	I-Task
to	O
decide	O
if	O
a	O
word	O
comes	O
from	O
the	O
data	O
or	O
from	O
the	O
noise	O
distribution	O
,	O
we	O
want	O
to	O
identify	O
the	O
words	O
coming	O
from	O
the	O
true	O
data	O
distribution	O
in	O
a	O
set	O
,	O
comprised	O
of	O
noise	O
samples	O
and	O
one	O
data	O
distribution	O
sample	O
.	O
	
Thus	O
,	O
we	O
can	O
train	O
a	O
multiclass	B-Method
loss	I-Method
over	O
a	O
multinomial	O
random	O
variable	O
which	O
maximizes	O
,	O
assuming	O
w.l.o.g	O
.	O
	
that	O
is	O
always	O
the	O
word	O
coming	O
from	O
true	O
data	O
.	O
	
By	O
Bayes	B-Method
rule	I-Method
,	O
and	O
ignoring	O
terms	O
that	O
are	O
constant	O
with	O
respect	O
to	O
,	O
we	O
can	O
write	O
:	O
and	O
,	O
following	O
a	O
similar	O
argument	O
than	O
for	O
NCE	B-Method
,	O
if	O
we	O
define	O
then	O
is	O
a	O
good	O
approximation	O
of	O
.	O
	
Note	O
that	O
the	O
only	O
difference	O
between	O
NCE	B-Method
and	O
IS	O
is	O
that	O
,	O
in	O
NCE	B-Method
,	O
we	O
define	O
a	O
binary	B-Task
classification	I-Task
task	I-Task
between	O
true	O
or	O
noise	O
words	O
with	O
a	O
logistic	B-Method
loss	I-Method
,	O
whereas	O
in	O
IS	O
we	O
define	O
a	O
multiclass	B-Task
classification	I-Task
problem	I-Task
with	O
a	O
Softmax	B-Method
and	I-Method
cross	I-Method
entropy	I-Method
loss	I-Method
.	O
	
We	O
hope	O
that	O
our	O
derivation	O
helps	O
clarify	O
the	O
similarities	O
and	O
differences	O
between	O
the	O
two	O
.	O
	
In	O
particular	O
,	O
we	O
observe	O
that	O
IS	O
,	O
as	O
it	O
optimizes	O
a	O
multiclass	B-Task
classification	I-Task
task	I-Task
(	O
in	O
contrast	O
to	O
solving	O
a	O
binary	B-Task
task	I-Task
)	O
,	O
may	O
be	O
a	O
better	O
choice	O
.	O
	
Indeed	O
,	O
the	O
updates	O
to	O
the	O
logits	O
with	O
IS	O
are	O
tied	O
whereas	O
in	O
NCE	O
they	O
are	O
independent	O
.	O
	
subsection	O
:	O
CNN	B-Method
Softmax	I-Method
	
The	O
character	O
-	O
level	O
features	O
allow	O
for	O
a	O
smoother	O
and	O
compact	O
parametrization	O
of	O
the	O
word	B-Method
embeddings	I-Method
.	O
	
Recent	O
efforts	O
on	O
small	O
scale	O
language	B-Task
modeling	I-Task
have	O
used	O
CNN	B-Method
character	I-Method
embeddings	I-Method
for	O
the	O
input	O
embeddings	O
.	O
	
Although	O
not	O
as	O
straightforward	O
,	O
we	O
propose	O
an	O
extension	O
to	O
this	O
idea	O
to	O
also	O
reduce	O
the	O
number	O
of	O
parameters	O
of	O
the	O
Softmax	B-Method
layer	I-Method
.	O
	
Recall	O
from	O
Section	O
[	O
reference	O
]	O
that	O
the	O
Softmax	B-Method
computes	O
a	O
logit	O
as	O
where	O
is	O
a	O
context	O
vector	O
and	O
the	O
word	B-Method
embedding	I-Method
.	O
	
Instead	O
of	O
building	O
a	O
matrix	O
of	O
(	O
whose	O
rows	O
correspond	O
to	O
)	O
,	O
we	O
produce	O
with	O
a	O
CNN	B-Method
over	O
the	O
characters	O
of	O
as	O
–	O
	
we	O
call	O
this	O
a	O
CNN	B-Method
Softmax	I-Method
.	O
	
We	O
used	O
the	O
same	O
network	B-Method
architecture	I-Method
to	O
dynamically	O
generate	O
the	O
Softmax	O
word	O
embeddings	O
without	O
sharing	O
the	O
parameters	O
with	O
the	O
input	O
word	B-Method
-	I-Method
embedding	I-Method
sub	I-Method
-	I-Method
network	I-Method
.	O
	
For	O
inference	B-Task
,	O
the	O
vectors	O
can	O
be	O
precomputed	O
,	O
so	O
there	O
is	O
no	O
computational	B-Metric
complexity	I-Metric
increase	O
w.r.t	O
.	O
	
the	O
regular	B-Method
Softmax	I-Method
.	O
	
We	O
note	O
that	O
,	O
when	O
using	O
an	O
importance	B-Method
sampling	I-Method
loss	I-Method
such	O
as	O
the	O
one	O
described	O
in	O
Section	O
[	O
reference	O
]	O
,	O
only	O
a	O
few	O
logits	O
have	O
non	O
-	O
zero	O
gradient	O
(	O
those	O
corresponding	O
to	O
the	O
true	O
and	O
sampled	O
words	O
)	O
.	O
	
With	O
a	O
Softmax	B-Method
where	O
are	O
independently	O
learned	O
word	O
embeddings	O
,	O
this	O
is	O
not	O
a	O
problem	O
.	O
	
But	O
we	O
observed	O
that	O
,	O
when	O
using	O
a	O
CNN	B-Method
,	O
all	O
the	O
logits	O
become	O
tied	O
as	O
the	O
function	O
mapping	O
from	O
to	O
is	O
quite	O
smooth	O
.	O
	
As	O
a	O
result	O
,	O
a	O
much	O
smaller	O
learning	B-Metric
rate	I-Metric
had	O
to	O
be	O
used	O
.	O
	
Even	O
with	O
this	O
,	O
the	O
model	O
lacks	O
capacity	O
to	O
differentiate	O
between	O
words	O
that	O
have	O
very	O
different	O
meanings	O
but	O
that	O
are	O
spelled	O
similarly	O
.	O
	
Thus	O
,	O
a	O
reasonable	O
compromise	O
was	O
to	O
add	O
a	O
small	O
correction	O
factor	O
which	O
is	O
learned	O
per	O
word	O
,	O
such	O
that	O
:	O
where	O
is	O
a	O
matrix	O
projecting	O
a	O
low	O
-	O
dimensional	O
embedding	O
vector	O
back	O
up	O
to	O
the	O
dimensionality	O
of	O
the	O
projected	O
LSTM	B-Method
hidden	O
state	O
of	O
.	O
	
This	O
amounts	O
to	O
adding	O
a	O
bottleneck	B-Method
linear	I-Method
layer	I-Method
,	O
and	O
brings	O
the	O
CNN	B-Method
Softmax	I-Method
much	O
closer	O
to	O
our	O
best	O
result	O
,	O
as	O
can	O
be	O
seen	O
in	O
Table	O
[	O
reference	O
]	O
,	O
where	O
adding	O
a	O
128	O
-	O
dim	O
correction	O
halves	O
the	O
gap	O
between	O
regular	B-Method
and	O
the	O
CNN	B-Method
Softmax	I-Method
.	O
	
Aside	O
from	O
a	O
big	O
reduction	O
in	O
the	O
number	O
of	O
parameters	O
and	O
incorporating	O
morphological	O
knowledge	O
from	O
words	O
,	O
the	O
other	O
benefit	O
of	O
this	O
approach	O
is	O
that	O
out	O
-	O
of	O
-	O
vocabulary	O
(	O
OOV	O
)	O
words	O
can	O
easily	O
be	O
scored	O
.	O
	
This	O
may	O
be	O
useful	O
for	O
other	O
problems	O
such	O
as	O
Machine	B-Task
Translation	I-Task
where	O
handling	B-Task
out	I-Task
-	I-Task
of	I-Task
-	I-Task
vocabulary	I-Task
words	I-Task
is	O
very	O
important	O
.	O
	
This	O
approach	O
also	O
allows	O
parallel	B-Task
training	I-Task
over	O
various	O
data	O
sets	O
since	O
the	O
model	O
is	O
no	O
longer	O
explicitly	O
parametrized	O
by	O
the	O
vocabulary	O
size	O
–	O
or	O
the	O
language	O
.	O
	
This	O
has	O
shown	O
to	O
help	O
when	O
using	O
byte	B-Method
-	I-Method
level	I-Method
input	I-Method
embeddings	I-Method
for	O
named	B-Task
entity	I-Task
recognition	I-Task
,	O
and	O
we	O
hope	O
it	O
will	O
enable	O
similar	O
gains	O
when	O
used	O
to	O
map	O
onto	O
words	O
.	O
	
subsection	O
:	O
Char	O
LSTM	B-Method
Predictions	I-Method
	
The	O
CNN	B-Method
Softmax	I-Method
layer	I-Method
can	O
handle	O
arbitrary	O
words	O
and	O
is	O
much	O
more	O
efficient	O
in	O
terms	O
of	O
number	O
of	O
parameters	O
than	O
the	O
full	O
Softmax	O
matrix	O
.	O
	
It	O
is	O
,	O
though	O
,	O
still	O
considerably	O
slow	O
,	O
as	O
to	O
evaluate	O
perplexities	B-Task
we	O
need	O
to	O
compute	O
the	O
partition	O
function	O
.	O
	
A	O
class	O
of	O
models	O
that	O
solve	O
this	O
problem	O
more	O
efficiently	O
are	O
character	O
-	O
level	O
LSTMs	B-Method
.	O
	
They	O
make	O
predictions	O
one	O
character	O
at	O
a	O
time	O
,	O
thus	O
allowing	O
to	O
compute	O
probabilities	O
over	O
a	O
much	O
smaller	O
vocabulary	O
.	O
	
On	O
the	O
other	O
hand	O
,	O
these	O
models	O
are	O
more	O
difficult	O
to	O
train	O
and	O
seem	O
to	O
perform	O
worse	O
even	O
in	O
small	O
tasks	O
like	O
PTB	B-Task
.	O
	
Most	O
likely	O
this	O
is	O
due	O
to	O
the	O
sequences	O
becoming	O
much	O
longer	O
on	O
average	O
as	O
the	O
LSTM	B-Method
reads	O
the	O
input	O
character	O
by	O
character	O
instead	O
of	O
word	O
by	O
word	O
.	O
	
Thus	O
,	O
we	O
combine	O
the	O
word	B-Method
and	I-Method
character	I-Method
-	I-Method
level	I-Method
models	I-Method
by	O
feeding	O
a	O
word	B-Method
-	I-Method
level	I-Method
LSTM	I-Method
hidden	I-Method
state	I-Method
into	O
a	O
small	O
LSTM	B-Method
that	O
predicts	O
the	O
target	O
word	O
one	O
character	O
at	O
a	O
time	O
(	O
see	O
Figure	O
[	O
reference	O
]	O
	
(	O
c	O
)	O
)	O
.	O
	
In	O
order	O
to	O
make	O
the	O
whole	O
process	O
reasonably	O
efficient	O
,	O
we	O
train	O
the	O
standard	O
LSTM	B-Method
model	I-Method
until	O
convergence	O
,	O
freeze	O
its	O
weights	O
,	O
and	O
replace	O
the	O
standard	O
word	B-Method
-	I-Method
level	I-Method
Softmax	I-Method
layer	I-Method
with	O
the	O
aforementioned	O
character	B-Method
-	I-Method
level	I-Method
LSTM	I-Method
.	O
	
The	O
resulting	O
model	O
scales	O
independently	O
of	O
vocabulary	O
size	O
–	O
both	O
for	O
training	B-Task
and	O
inference	B-Task
.	O
	
However	O
,	O
it	O
does	O
seem	O
to	O
be	O
worse	O
than	O
regular	B-Method
and	I-Method
CNN	I-Method
Softmax	I-Method
	
–	O
	
we	O
are	O
hopeful	O
that	O
further	O
research	O
will	O
enable	O
these	O
models	O
to	O
replace	O
fixed	B-Method
vocabulary	I-Method
models	I-Method
whilst	O
being	O
computationally	O
attractive	O
.	O
	
section	O
:	O
Experiments	O
	
All	O
experiments	O
were	O
run	O
using	O
the	O
TensorFlow	B-Method
system	I-Method
,	O
with	O
the	O
exception	O
of	O
some	O
older	O
models	O
which	O
were	O
used	O
in	O
the	O
ensemble	O
.	O
	
subsection	O
:	O
Data	O
Set	O
	
The	O
experiments	O
are	O
performed	O
on	O
the	O
1B	B-Material
Word	I-Material
Benchmark	I-Material
data	I-Material
set	I-Material
introduced	O
by	O
,	O
which	O
is	O
a	O
publicly	O
available	O
benchmark	O
for	O
measuring	O
progress	O
of	O
statistical	O
language	B-Task
modeling	I-Task
.	O
	
The	O
data	O
set	O
contains	O
about	O
0.8B	O
words	O
with	O
a	O
vocabulary	O
of	O
793471	O
words	O
,	O
including	O
sentence	O
boundary	O
markers	O
.	O
	
All	O
the	O
sentences	O
are	O
shuffled	O
and	O
the	O
duplicates	O
are	O
removed	O
.	O
	
The	O
words	O
that	O
are	O
out	O
of	O
vocabulary	O
(	O
OOV	O
)	O
are	O
marked	O
with	O
a	O
special	O
UNK	O
token	O
(	O
there	O
are	O
approximately	O
0.3	O
%	O
such	O
words	O
)	O
.	O
	
subsection	O
:	O
Model	O
Setup	O
	
The	O
typical	O
measure	O
used	O
for	O
reporting	O
progress	O
in	O
language	B-Task
modeling	I-Task
is	O
perplexity	B-Task
,	O
which	O
is	O
the	O
average	B-Metric
per	I-Metric
-	I-Metric
word	I-Metric
log	I-Metric
-	I-Metric
probability	I-Metric
on	O
the	O
holdout	O
data	O
set	O
:	O
.	O
	
We	O
follow	O
the	O
standard	O
procedure	O
and	O
sum	O
over	O
all	O
the	O
words	O
(	O
including	O
the	O
end	O
of	O
sentence	O
symbol	O
)	O
.	O
	
We	O
used	O
the	O
1B	B-Material
Word	I-Material
Benchmark	I-Material
data	I-Material
set	I-Material
without	O
any	O
pre	O
-	O
processing	O
.	O
	
Given	O
the	O
shuffled	O
sentences	O
,	O
they	O
are	O
input	O
to	O
the	O
network	O
as	O
a	O
batch	O
of	O
independent	O
streams	O
of	O
words	O
.	O
	
Whenever	O
a	O
sentence	O
ends	O
,	O
a	O
new	O
one	O
starts	O
without	O
any	O
padding	O
(	O
thus	O
maximizing	O
the	O
occupancy	O
per	O
batch	O
)	O
.	O
	
For	O
the	O
models	O
that	O
consume	O
characters	O
as	O
inputs	O
or	O
as	O
targets	O
,	O
each	O
word	O
is	O
fed	O
to	O
the	O
model	O
as	O
a	O
sequence	O
of	O
character	O
IDs	O
of	O
preespecified	O
length	O
(	O
see	O
Figure	O
[	O
reference	O
]	O
	
(	O
b	O
)	O
)	O
.	O
	
The	O
words	O
were	O
processed	O
to	O
include	O
special	O
begin	O
and	O
end	O
of	O
word	O
tokens	O
and	O
were	O
padded	O
to	O
reach	O
the	O
expected	O
length	O
.	O
	
I.e.	O
if	O
the	O
maximum	O
word	O
length	O
was	O
10	O
,	O
the	O
word	O
	
“	O
cat	O
”	O
would	O
be	O
transformed	O
to	O
“	O
$	O
cat^	O
”	O
due	O
to	O
the	O
CNN	B-Method
model	I-Method
.	O
	
In	O
our	O
experiments	O
we	O
found	O
that	O
limiting	O
the	O
maximum	O
word	O
length	O
in	O
training	O
to	O
50	O
was	O
sufficient	O
to	O
reach	O
very	O
good	O
results	O
while	O
32	O
was	O
clearly	O
insufficient	O
.	O
	
We	O
used	O
256	O
characters	O
in	O
our	O
vocabulary	O
and	O
the	O
non	O
-	O
ascii	O
symbols	O
were	O
represented	O
as	O
a	O
sequence	O
of	O
bytes	O
.	O
	
subsection	O
:	O
Model	O
Architecture	O
	
We	O
evaluated	O
many	O
variations	O
of	O
RNN	B-Method
LM	I-Method
architectures	I-Method
.	O
	
These	O
include	O
the	O
dimensionalities	O
of	O
the	O
embedding	O
layers	O
,	O
the	O
state	O
,	O
projection	O
sizes	O
,	O
and	O
number	O
of	O
LSTM	B-Method
layers	O
to	O
use	O
.	O
	
Exhaustively	O
trying	O
all	O
combinations	O
would	O
be	O
extremely	O
time	O
consuming	O
for	O
such	O
a	O
large	O
data	O
set	O
,	O
but	O
our	O
findings	O
suggest	O
that	O
LSTMs	B-Method
with	O
a	O
projection	B-Method
layer	I-Method
(	O
i.e.	O
,	O
a	O
bottleneck	O
between	O
hidden	O
states	O
as	O
in	O
)	O
trained	O
with	O
truncated	B-Method
BPTT	I-Method
for	O
20	O
steps	O
performed	O
well	O
.	O
	
Following	O
we	O
use	O
dropout	O
before	O
and	O
after	O
every	O
LSTM	B-Method
layer	I-Method
.	O
	
The	O
biases	O
of	O
LSTM	B-Method
forget	I-Method
gate	I-Method
were	O
initialized	O
to	O
1.0	O
.	O
	
The	O
size	O
of	O
the	O
models	O
will	O
be	O
described	O
in	O
more	O
detail	O
in	O
the	O
following	O
sections	O
,	O
and	O
the	O
choices	O
of	O
hyper	O
-	O
parameters	O
will	O
be	O
released	O
as	O
open	O
source	O
upon	O
publication	O
.	O
	
For	O
any	O
model	O
using	O
character	B-Method
embedding	I-Method
CNNs	I-Method
,	O
we	O
closely	O
follow	O
the	O
architecture	O
from	O
.	O
	
The	O
only	O
important	O
difference	O
is	O
that	O
we	O
use	O
a	O
larger	O
number	O
of	O
convolutional	O
features	O
of	O
4096	O
to	O
give	O
enough	O
capacity	O
to	O
the	O
model	O
.	O
	
The	O
resulting	O
embedding	O
is	O
then	O
linearly	O
transformed	O
to	O
match	O
the	O
LSTM	B-Method
projection	O
sizes	O
.	O
	
This	O
allows	O
it	O
to	O
match	O
the	O
performance	O
of	O
regular	B-Method
word	I-Method
embeddings	I-Method
but	O
only	O
uses	O
a	O
small	O
fraction	O
of	O
parameters	O
.	O
	
subsection	O
:	O
Training	O
Procedure	O
	
The	O
models	O
were	O
trained	O
until	O
convergence	O
with	O
an	O
AdaGrad	B-Method
optimizer	I-Method
using	O
a	O
learning	B-Metric
rate	I-Metric
of	O
0.2	O
.	O
	
In	O
all	O
the	O
experiments	O
the	O
RNNs	B-Method
were	O
unrolled	O
for	O
20	O
steps	O
without	O
ever	O
resetting	O
the	O
LSTM	B-Method
states	O
.	O
	
We	O
used	O
a	O
batch	O
size	O
of	O
128	O
.	O
	
We	O
clip	O
the	O
gradients	O
of	O
the	O
LSTM	B-Method
weights	O
such	O
that	O
their	O
norm	O
is	O
bounded	O
by	O
1.0	O
.	O
	
Using	O
these	O
hyper	O
-	O
parameters	O
we	O
found	O
large	O
LSTMs	B-Method
to	O
be	O
relatively	O
easy	O
to	O
train	O
.	O
	
The	O
same	O
learning	B-Metric
rate	I-Metric
was	O
used	O
in	O
almost	O
all	O
of	O
the	O
experiments	O
.	O
	
In	O
a	O
few	O
cases	O
we	O
had	O
to	O
reduce	O
it	O
by	O
an	O
order	O
of	O
magnitude	O
.	O
	
Unless	O
otherwise	O
stated	O
,	O
the	O
experiments	O
were	O
performed	O
with	O
32	O
GPU	O
workers	O
and	O
asynchronous	B-Method
gradient	I-Method
updates	I-Method
.	O
	
Further	O
details	O
will	O
be	O
fully	O
specified	O
with	O
the	O
code	O
upon	O
publication	O
.	O
	
Training	O
a	O
model	O
for	O
such	O
large	O
target	O
vocabulary	O
(	O
793471	O
words	O
)	O
required	O
to	O
be	O
careful	O
with	O
some	O
details	O
about	O
the	O
approximation	O
to	O
full	B-Task
Softmax	I-Task
using	O
importance	B-Method
sampling	I-Method
.	O
	
We	O
used	O
a	O
large	O
number	O
of	O
negative	O
(	O
or	O
noise	O
)	O
samples	O
:	O
8192	O
such	O
samples	O
were	O
drawn	O
per	O
step	O
,	O
but	O
were	O
shared	O
across	O
all	O
the	O
target	O
words	O
in	O
the	O
batch	O
(	O
2560	O
total	O
,	O
i.e.	O
128	O
times	O
20	O
unrolled	O
steps	O
)	O
.	O
	
This	O
results	O
in	O
multiplying	O
(	O
2560	O
x	O
1024	O
)	O
times	O
(	O
1024	O
x	O
(	O
8192	O
+	O
1	O
)	O
)	O
	
(	O
instead	O
of	O
(	O
2560	O
x	O
1024	O
)	O
times	O
(	O
1024	O
x	O
793471	O
)	O
)	O
,	O
i.e.	O
about	O
100	O
-	O
fold	O
less	O
computation	O
.	O
	
section	O
:	O
Results	O
and	O
Analysis	O
	
In	O
this	O
section	O
we	O
summarize	O
the	O
results	O
of	O
our	O
experiments	O
and	O
do	O
an	O
in	O
-	O
depth	O
analysis	O
.	O
	
Table	O
[	O
reference	O
]	O
contains	O
all	O
results	O
for	O
our	O
models	O
compared	O
to	O
previously	O
published	O
work	O
.	O
	
Table	O
[	O
reference	O
]	O
shows	O
previous	O
and	O
our	O
own	O
work	O
on	O
ensembles	O
of	O
models	O
.	O
	
We	O
hope	O
that	O
our	O
encouraging	O
results	O
,	O
which	O
improved	O
the	O
best	O
perplexity	O
of	O
a	O
single	O
model	O
from	O
51.3	O
to	O
30.0	O
(	O
whilst	O
reducing	O
the	O
model	O
size	O
considerably	O
)	O
,	O
and	O
set	O
a	O
new	O
record	O
with	O
ensembles	O
at	O
23.7	O
,	O
will	O
enable	O
rapid	O
research	O
and	O
progress	O
to	O
advance	O
Language	B-Task
Modeling	I-Task
.	O
	
For	O
this	O
purpose	O
,	O
we	O
will	O
release	O
the	O
model	O
weights	O
and	O
recipes	O
upon	O
publication	O
.	O
	
subsection	O
:	O
Size	O
Matters	O
	
Unsurprisingly	O
,	O
size	O
matters	O
:	O
when	O
training	O
on	O
a	O
very	O
large	O
and	O
complex	O
data	O
set	O
,	O
fitting	O
the	O
training	O
data	O
with	O
an	O
LSTM	B-Method
is	O
fairly	O
challenging	O
.	O
	
Thus	O
,	O
the	O
size	O
of	O
the	O
LSTM	B-Method
layer	I-Method
is	O
a	O
very	O
important	O
factor	O
that	O
influences	O
the	O
results	O
,	O
as	O
seen	O
in	O
Table	O
[	O
reference	O
]	O
.	O
	
The	O
best	O
models	O
are	O
the	O
largest	O
we	O
were	O
able	O
to	O
fit	O
into	O
a	O
GPU	O
memory	O
.	O
	
Our	O
largest	O
model	O
was	O
a	O
2	B-Method
-	I-Method
layer	I-Method
LSTM	I-Method
with	O
8192	O
+	O
1024	O
dimensional	O
recurrent	O
state	O
in	O
each	O
of	O
the	O
layers	O
.	O
	
Increasing	O
the	O
embedding	O
and	O
projection	O
size	O
also	O
helps	O
but	O
causes	O
a	O
large	O
increase	O
in	O
the	O
number	O
of	O
parameters	O
,	O
which	O
is	O
less	O
desirable	O
.	O
	
Lastly	O
,	O
training	O
an	O
RNN	B-Method
instead	O
of	O
an	O
LSTM	B-Method
yields	O
poorer	O
results	O
(	O
about	O
5	O
perplexity	O
worse	O
)	O
for	O
a	O
comparable	O
model	B-Metric
size	I-Metric
.	O
	
subsection	O
:	O
Regularization	O
Importance	O
	
As	O
shown	O
in	O
Table	O
[	O
reference	O
]	O
,	O
using	O
dropout	B-Method
improves	O
the	O
results	O
.	O
	
To	O
our	O
surprise	O
,	O
even	O
relatively	O
small	O
models	O
(	O
e.g.	O
,	O
single	B-Method
layer	I-Method
LSTM	I-Method
with	O
2048	O
units	O
projected	O
to	O
512	O
dimensional	O
outputs	O
)	O
	
can	O
over	O
-	O
fit	O
the	O
training	O
set	O
if	O
trained	O
long	O
enough	O
,	O
eventually	O
yielding	O
holdout	O
set	O
degradation	O
.	O
	
Using	O
dropout	B-Method
on	O
non	O
-	O
recurrent	O
connections	O
largely	O
mitigates	O
these	O
issues	O
.	O
	
While	O
over	O
-	O
fitting	O
still	O
occurs	O
,	O
there	O
is	O
no	O
more	O
need	O
for	O
early	O
stopping	O
.	O
	
For	O
models	O
that	O
had	O
4096	O
or	O
less	O
units	O
in	O
the	O
LSTM	B-Method
layer	I-Method
,	O
we	O
used	O
10	O
%	O
dropout	O
probability	O
.	O
	
For	O
larger	O
models	O
,	O
25	O
%	O
was	O
significantly	O
better	O
.	O
	
Even	O
with	O
such	O
regularization	B-Method
,	O
perplexities	O
on	O
the	O
training	O
set	O
can	O
be	O
as	O
much	O
as	O
6	O
points	O
below	O
test	O
.	O
	
In	O
one	O
experiment	O
we	O
tried	O
to	O
use	O
a	O
smaller	O
vocabulary	O
comprising	O
of	O
the	O
100	O
,	O
000	O
most	O
frequent	O
words	O
and	O
found	O
the	O
difference	O
between	O
train	O
and	O
test	O
to	O
be	O
smaller	O
–	O
	
which	O
suggests	O
that	O
too	O
much	O
capacity	O
is	O
given	O
to	O
rare	O
words	O
.	O
	
This	O
is	O
less	O
of	O
an	O
issue	O
with	O
character	B-Method
CNN	I-Method
embedding	I-Method
models	I-Method
as	O
the	O
embeddings	O
are	O
shared	O
across	O
all	O
words	O
.	O
	
subsection	O
:	O
Importance	B-Method
Sampling	I-Method
is	O
Data	O
Efficient	O
	
Table	O
[	O
reference	O
]	O
shows	O
the	O
test	O
perplexities	O
of	O
NCE	O
vs	O
IS	O
loss	O
after	O
a	O
few	O
epochs	O
of	O
2048	B-Method
unit	I-Method
LSTM	I-Method
with	O
512	O
projection	O
.	O
	
The	O
IS	O
objective	O
significantly	O
improves	O
the	O
speed	O
and	O
the	O
overall	O
performance	O
of	O
the	O
model	O
when	O
compared	O
to	O
NCE	B-Method
.	O
	
subsection	O
:	O
Word	B-Method
Embeddings	I-Method
vs	O
Character	B-Method
CNN	I-Method
	
Replacing	O
the	O
embedding	B-Method
layer	I-Method
with	O
a	O
parametrized	B-Method
neural	I-Method
network	I-Method
that	O
process	O
characters	O
of	O
a	O
given	O
word	O
allows	O
the	O
model	O
to	O
consume	O
arbitrary	O
words	O
and	O
is	O
not	O
restricted	O
to	O
a	O
fixed	O
vocabulary	O
.	O
	
This	O
property	O
is	O
useful	O
for	O
data	O
sets	O
with	O
conversational	O
or	O
informal	O
text	O
as	O
well	O
as	O
for	O
morphologically	O
rich	O
languages	O
.	O
	
Our	O
experiments	O
show	O
that	O
using	O
character	B-Method
-	I-Method
level	I-Method
embeddings	I-Method
is	O
feasible	O
and	O
does	O
not	O
degrade	O
performance	O
–	O
in	O
fact	O
,	O
our	O
best	O
single	O
model	O
uses	O
a	O
Character	B-Method
CNN	I-Method
embedding	I-Method
.	O
	
An	O
additional	O
advantage	O
is	O
that	O
the	O
number	O
of	O
parameters	O
of	O
the	O
input	O
layer	O
is	O
reduced	O
by	O
a	O
factor	O
of	O
11	O
(	O
though	O
training	B-Metric
speed	I-Metric
is	O
slightly	O
worse	O
)	O
.	O
	
For	O
inference	B-Task
,	O
the	O
embeddings	O
can	O
be	O
precomputed	O
so	O
there	O
is	O
no	O
speed	O
penalty	O
.	O
	
Overall	O
,	O
the	O
embedding	O
of	O
the	O
best	O
model	O
is	O
parametrized	O
by	O
72	O
M	O
weights	O
(	O
down	O
from	O
820	O
M	O
weights	O
)	O
.	O
	
Table	O
[	O
reference	O
]	O
shows	O
a	O
few	O
examples	O
of	O
nearest	B-Method
neighbor	I-Method
embeddings	I-Method
for	O
some	O
out	O
-	O
of	O
-	O
vocabulary	O
words	O
when	O
character	B-Method
CNNs	I-Method
are	O
used	O
.	O
	
subsection	O
:	O
Smaller	B-Method
Models	I-Method
with	O
CNN	B-Method
Softmax	I-Method
	
Even	O
with	O
character	B-Method
-	I-Method
level	I-Method
embeddings	I-Method
,	O
the	O
model	O
is	O
still	O
fairly	O
large	O
(	O
though	O
much	O
smaller	O
than	O
the	O
best	O
competing	O
models	O
from	O
previous	O
work	O
)	O
.	O
	
Most	O
of	O
the	O
parameters	O
are	O
in	O
the	O
linear	O
layer	O
before	O
the	O
Softmax	B-Method
:	O
	
820	O
M	O
versus	O
a	O
total	O
of	O
1.04B	O
parameters	O
.	O
	
In	O
one	O
of	O
the	O
experiments	O
we	O
froze	O
the	O
word	B-Method
-	I-Method
LSTM	I-Method
after	O
convergence	O
and	O
replaced	O
the	O
Softmax	B-Method
layer	I-Method
with	O
the	O
CNN	B-Method
Softmax	I-Method
sub	I-Method
-	I-Method
network	I-Method
.	O
	
Without	O
any	O
fine	B-Method
-	I-Method
tuning	I-Method
that	O
model	O
was	O
able	O
to	O
reach	O
39.8	O
perplexity	O
with	O
only	O
293	O
M	O
weights	O
(	O
as	O
seen	O
in	O
Table	O
[	O
reference	O
]	O
)	O
.	O
	
As	O
described	O
in	O
Section	O
[	O
reference	O
]	O
,	O
adding	O
a	O
“	O
correction	O
”	O
word	O
embedding	O
term	O
alleviates	O
the	O
gap	O
between	O
regular	B-Method
and	I-Method
CNN	I-Method
Softmax	I-Method
.	O
	
Indeed	O
,	O
we	O
can	O
trade	O
-	O
off	O
model	B-Metric
size	I-Metric
versus	O
perplexity	O
.	O
	
For	O
instance	O
,	O
by	O
adding	O
100	O
M	O
weights	O
(	O
through	O
a	O
128	B-Method
dimensional	I-Method
bottleneck	I-Method
embedding	I-Method
)	O
we	O
achieve	O
35.8	O
perplexity	O
(	O
see	O
Table	O
[	O
reference	O
]	O
)	O
.	O
	
To	O
contrast	O
with	O
the	O
CNN	B-Method
Softmax	I-Method
,	O
we	O
also	O
evaluated	O
a	O
model	O
that	O
replaces	O
the	O
Softmax	B-Method
layer	I-Method
with	O
a	O
smaller	O
LSTM	B-Method
that	O
predicts	O
one	O
character	O
at	O
a	O
time	O
(	O
see	O
Section	O
[	O
reference	O
]	O
)	O
.	O
	
Such	O
a	O
model	O
does	O
not	O
have	O
to	O
learn	O
long	O
dependencies	O
because	O
the	O
base	O
LSTM	B-Method
still	O
operates	O
at	O
the	O
word	O
-	O
level	O
(	O
see	O
Figure	O
[	O
reference	O
]	O
	
(	O
c	O
)	O
)	O
.	O
	
With	O
a	O
single	B-Method
-	I-Method
layer	I-Method
LSTM	I-Method
of	I-Method
1024	I-Method
units	I-Method
we	O
reached	O
49.0	O
test	O
perplexity	O
,	O
far	O
below	O
the	O
best	O
model	O
.	O
	
In	O
order	O
to	O
make	O
the	O
comparisons	O
more	O
fair	O
,	O
we	O
performed	O
a	O
very	O
expensive	O
marginalization	O
over	O
the	O
words	O
in	O
the	O
vocabulary	O
(	O
to	O
rule	O
out	O
words	O
not	O
in	O
the	O
dictionary	O
which	O
the	O
character	B-Method
LSTM	I-Method
would	O
assign	O
some	O
probability	O
)	O
.	O
	
When	O
doing	O
this	O
marginalization	O
,	O
the	O
perplexity	O
improved	O
a	O
bit	O
down	O
to	O
47.9	O
.	O
	
subsection	O
:	O
Training	B-Metric
Speed	I-Metric
	
We	O
used	O
32	O
Tesla	B-Method
K40	I-Method
GPUs	I-Method
to	O
train	O
our	O
models	O
.	O
	
The	O
smaller	O
version	O
of	O
the	O
LSTM	B-Method
model	I-Method
with	O
2048	B-Method
units	I-Method
and	O
512	O
projections	O
needs	O
less	O
than	O
10	O
hours	O
to	O
reach	O
below	O
45	O
perplexity	O
and	O
after	O
only	O
2	O
hours	O
of	O
training	O
the	O
model	O
beats	O
previous	O
state	O
-	O
of	O
-	O
the	O
art	O
on	O
this	O
data	O
set	O
.	O
	
The	O
best	O
model	O
needs	O
about	O
5	O
days	O
to	O
get	O
to	O
35	O
perplexity	O
and	O
10	O
days	O
to	O
32.5	O
.	O
	
The	O
best	O
results	O
were	O
achieved	O
after	O
3	O
weeks	O
of	O
training	O
.	O
	
See	O
Table	O
[	O
reference	O
]	O
for	O
more	O
details	O
.	O
	
subsection	O
:	O
Ensembles	O
	
We	O
averaged	O
several	O
of	O
our	O
best	O
models	O
and	O
we	O
were	O
able	O
to	O
reach	O
23.7	O
test	O
perplexity	O
(	O
more	O
details	O
and	O
results	O
can	O
be	O
seen	O
in	O
Table	O
[	O
reference	O
]	O
)	O
,	O
which	O
is	O
more	O
than	O
40	O
%	O
improvement	O
over	O
previous	O
work	O
.	O
	
Interestingly	O
,	O
including	O
the	O
best	O
N	B-Method
-	I-Method
gram	I-Method
model	I-Method
reduces	O
the	O
perplexity	O
by	O
1.2	O
point	O
even	O
though	O
the	O
model	O
is	O
rather	O
weak	O
on	O
its	O
own	O
(	O
67.6	O
perplexity	O
)	O
.	O
	
Most	O
previous	O
work	O
had	O
to	O
either	O
ensemble	O
with	O
the	O
best	O
N	B-Method
-	I-Method
gram	I-Method
model	I-Method
(	O
as	O
their	O
RNN	B-Method
only	O
used	O
a	O
limited	O
output	O
vocabulary	O
of	O
a	O
few	O
thousand	O
words	O
)	O
,	O
or	O
use	O
N	O
-	O
gram	O
features	O
as	O
additional	O
input	O
to	O
the	O
RNN	B-Method
.	O
	
Our	O
results	O
,	O
on	O
the	O
contrary	O
,	O
suggest	O
that	O
N	O
-	O
grams	O
are	O
of	O
limited	O
benefit	O
,	O
and	O
suggest	O
that	O
a	O
carefully	O
trained	O
LSTM	B-Method
LM	I-Method
is	O
the	O
most	O
competitive	O
model	O
.	O
	
subsection	O
:	O
LSTMs	B-Method
are	O
best	O
on	O
the	O
tail	O
words	O
	
Figure	O
[	O
reference	O
]	O
shows	O
the	O
difference	O
in	O
log	O
probabilities	O
between	O
our	O
best	O
model	O
(	O
at	O
30.0	O
perplexity	B-Metric
)	O
and	O
the	O
KN	B-Method
-	I-Method
5	I-Method
.	O
	
As	O
can	O
be	O
seen	O
from	O
the	O
plot	O
,	O
the	O
LSTM	B-Method
is	O
better	O
across	O
all	O
the	O
buckets	O
and	O
significantly	O
outperforms	O
KN	B-Method
-	I-Method
5	I-Method
on	O
the	O
rare	O
words	O
.	O
	
This	O
is	O
encouraging	O
as	O
it	O
seems	O
to	O
suggest	O
that	O
LSTM	B-Method
LMs	I-Method
may	O
fare	O
even	O
better	O
for	O
languages	O
or	O
data	O
sets	O
where	O
the	O
number	O
of	O
rare	O
words	O
is	O
larger	O
than	O
traditional	O
N	B-Method
-	I-Method
gram	I-Method
models	I-Method
.	O
	
subsection	O
:	O
Samples	O
from	O
the	O
model	O
	
To	O
qualitatively	O
evaluate	O
the	O
model	O
,	O
we	O
sampled	O
many	O
sentences	O
.	O
	
We	O
discarded	O
short	O
and	O
politically	O
incorrect	O
ones	O
,	O
but	O
the	O
sample	O
shown	O
below	O
is	O
otherwise	O
“	O
raw	O
”	O
(	O
i.e.	O
,	O
not	O
hand	O
picked	O
)	O
.	O
	
The	O
samples	O
are	O
of	O
high	O
quality	O
–	O
which	O
is	O
not	O
a	O
surprise	O
,	O
given	O
the	O
perplexities	O
attained	O
–	O
but	O
there	O
are	O
still	O
some	O
occasional	O
mistakes	O
.	O
	
Sentences	O
generated	O
by	O
the	O
ensemble	O
(	O
about	O
26	O
perplexity	O
)	O
:	O
With	O
even	O
more	O
new	O
technologies	O
coming	O
onto	O
the	O
market	O
quickly	O
during	O
the	O
past	O
three	O
years	O
,	O
an	O
increasing	O
number	O
of	O
companies	O
now	O
must	O
tackle	O
the	O
ever	O
-	O
changing	O
and	O
ever	O
-	O
changing	O
environmental	O
challenges	O
online	O
.	O
	
<	O
S	O
>	O
Check	O
back	O
for	O
updates	O
on	O
this	O
breaking	O
news	O
story	O
.	O
	
<	O
S	O
>	O
	
About	O
800	O
people	O
gathered	O
at	O
Hever	O
Castle	O
on	O
Long	O
Beach	O
from	O
noon	O
to	O
2	O
pm	O
,	O
three	O
to	O
four	O
times	O
that	O
of	O
the	O
funeral	O
cortège	O
.	O
	
<	O
S	O
>	O
	
We	O
are	O
aware	O
of	O
written	O
instructions	O
from	O
the	O
copyright	O
holder	O
not	O
to	O
,	O
in	O
any	O
way	O
,	O
mention	O
Rosenberg	O
’s	O
negative	O
comments	O
if	O
they	O
are	O
relevant	O
as	O
indicated	O
in	O
the	O
documents	O
,	O
”	O
eBay	O
said	O
in	O
a	O
statement	O
.	O
	
<	O
S	O
>	O
	
It	O
is	O
now	O
known	O
that	O
coffee	O
and	O
cacao	O
products	O
can	O
do	O
no	O
harm	O
on	O
the	O
body	O
.	O
	
<	O
S	O
	
>	O
	
Yuri	O
Zhirkov	O
was	O
in	O
attendance	O
at	O
the	O
Stamford	O
Bridge	O
at	O
the	O
start	O
of	O
the	O
second	O
half	O
but	O
neither	O
Drogba	O
nor	O
Malouda	O
was	O
able	O
to	O
push	O
on	O
through	O
the	O
Barcelona	O
defence	O
.	O
	
section	O
:	O
Discussion	O
and	O
Conclusions	O
	
In	O
this	O
paper	O
we	O
have	O
shown	O
that	O
RNN	O
LMs	B-Task
can	O
be	O
trained	O
on	O
large	O
amounts	O
of	O
data	O
,	O
and	O
outperform	O
competing	O
models	O
including	O
carefully	O
tuned	O
N	B-Method
-	I-Method
grams	I-Method
.	O
	
The	O
reduction	O
in	O
perplexity	B-Metric
from	O
51.3	O
to	O
30.0	O
is	O
due	O
to	O
several	O
key	O
components	O
which	O
we	O
studied	O
in	O
this	O
paper	O
.	O
	
Thus	O
,	O
a	O
large	O
,	O
regularized	B-Method
LSTM	I-Method
LM	I-Method
,	O
with	O
projection	B-Method
layers	I-Method
and	O
trained	O
with	O
an	O
approximation	O
to	O
the	O
true	O
Softmax	B-Method
with	O
importance	B-Method
sampling	I-Method
performs	O
much	O
better	O
than	O
N	B-Method
-	I-Method
grams	I-Method
.	O
	
Unlike	O
previous	O
work	O
,	O
we	O
do	O
not	O
require	O
to	O
interpolate	O
both	O
the	O
RNN	B-Method
LM	I-Method
and	O
the	O
N	B-Method
-	I-Method
gram	I-Method
,	O
and	O
the	O
gains	O
of	O
doing	O
so	O
are	O
rather	O
marginal	O
.	O
	
By	O
exploring	O
recent	O
advances	O
in	O
model	B-Method
architectures	I-Method
(	O
e.g.	O
LSTMs	B-Method
)	O
,	O
exploiting	O
small	B-Method
character	I-Method
CNNs	I-Method
,	O
and	O
by	O
sharing	O
our	O
findings	O
in	O
this	O
paper	O
and	O
accompanying	O
code	O
and	O
models	O
(	O
to	O
be	O
released	O
upon	O
publication	O
)	O
,	O
we	O
hope	O
to	O
inspire	O
research	O
on	O
large	O
scale	O
Language	B-Task
Modeling	I-Task
,	O
a	O
problem	O
we	O
consider	O
crucial	O
towards	O
language	B-Task
understanding	I-Task
.	O
	
We	O
hope	O
for	O
future	O
research	O
to	O
focus	O
on	O
reasonably	O
sized	O
datasets	O
taking	O
inspiration	O
from	O
recent	O
advances	O
seen	O
in	O
the	O
computer	B-Task
vision	I-Task
community	I-Task
thanks	O
to	O
efforts	O
such	O
as	O
Imagenet	O
.	O
	
section	O
:	O
Acknowledgements	O
	
We	O
thank	O
Ciprian	O
Chelba	O
,	O
Ilya	O
Sutskever	O
,	O
and	O
the	O
Google	O
Brain	O
Team	O
for	O
their	O
help	O
and	O
discussions	O
.	O
	
We	O
also	O
thank	O
Koray	O
Kavukcuoglu	O
for	O
his	O
help	O
with	O
the	O
manuscript	O
.	O
	
bibliography	O
:	O
References	O
	
Bridging	B-Task
Saliency	I-Task
Detection	I-Task
to	O
Weakly	B-Task
Supervised	I-Task
Object	I-Task
Detection	I-Task
Based	O
on	O
Self	B-Method
-	I-Method
paced	I-Method
Curriculum	I-Method
Learning	I-Method
	
section	O
:	O
Abstract	O
	
Weakly	B-Task
-	I-Task
supervised	I-Task
object	I-Task
detection	I-Task
(	O
WOD	B-Task
)	O
is	O
a	O
challenging	O
problems	O
in	O
computer	B-Task
vision	I-Task
.	O
	
The	O
key	O
problem	O
is	O
to	O
simultaneously	O
infer	O
the	O
exact	O
object	O
locations	O
in	O
the	O
training	O
images	O
and	O
train	O
the	O
object	B-Method
detectors	I-Method
,	O
given	O
only	O
the	O
training	O
images	O
with	O
weak	O
image	O
-	O
level	O
labels	O
.	O
	
Intuitively	O
,	O
by	O
simulating	O
the	O
selective	B-Method
attention	I-Method
mechanism	I-Method
of	O
human	B-Method
visual	I-Method
system	I-Method
,	O
saliency	B-Task
detection	I-Task
technique	O
can	O
select	O
attractive	O
objects	O
in	O
scenes	O
and	O
thus	O
is	O
a	O
potential	O
way	O
to	O
provide	O
useful	O
priors	O
for	O
WOD	B-Task
.	O
	
However	O
,	O
the	O
way	O
to	O
adopt	O
saliency	B-Task
detection	I-Task
in	O
WOD	B-Task
is	O
not	O
trivial	O
since	O
the	O
detected	O
saliency	O
region	O
might	O
be	O
possibly	O
highly	O
ambiguous	O
in	O
complex	O
cases	O
.	O
	
To	O
this	O
end	O
,	O
this	O
paper	O
first	O
comprehensively	O
analyzes	O
the	O
challenges	O
in	O
applying	O
saliency	B-Task
detection	I-Task
to	O
WOD	B-Task
.	O
	
Then	O
,	O
we	O
make	O
one	O
of	O
the	O
earliest	O
efforts	O
to	O
bridge	O
saliency	B-Task
detection	I-Task
to	O
WOD	B-Task
via	O
the	O
self	B-Method
-	I-Method
paced	I-Method
curriculum	I-Method
learning	I-Method
,	O
which	O
can	O
guide	O
the	O
learning	O
procedure	O
to	O
gradually	O
achieve	O
faithful	O
knowledge	O
of	O
multi	O
-	O
class	O
objects	O
from	O
easy	O
to	O
hard	O
.	O
	
The	O
experimental	O
results	O
demonstrate	O
that	O
the	O
proposed	O
approach	O
can	O
successfully	O
bridge	O
saliency	B-Task
detection	I-Task
and	O
WOD	B-Task
tasks	I-Task
and	O
achieve	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
object	B-Task
detection	I-Task
results	O
under	O
the	O
weak	O
supervision	O
.	O
	
section	O
:	O
Introduction	O
1	O
	
Object	B-Task
detection	I-Task
is	O
one	O
of	O
the	O
most	O
fundamental	O
yetchallenging	O
problems	O
in	O
computer	B-Task
vision	I-Task
community	I-Task
.	O
	
The	O
most	O
recent	O
breakthrough	O
was	O
achieved	O
by	O
Girshick	O
et	O
al	O
.	O
,	O
who	O
trained	O
the	O
Convolutional	B-Method
Neural	I-Method
Network	I-Method
(	I-Method
CNN	I-Method
)	I-Method
by	O
using	O
large	O
amount	O
of	O
human	O
labelled	O
bounding	O
boxes	O
to	O
learn	O
the	O
powerful	O
feature	B-Method
representations	I-Method
and	O
object	B-Method
classifiers	I-Method
.	O
	
Despite	O
their	O
success	O
,	O
the	O
problem	O
of	O
object	B-Task
detection	I-Task
is	O
still	O
under	O
-	O
addressed	O
in	O
practice	O
due	O
to	O
the	O
heavy	O
burden	O
of	O
labeling	O
the	O
training	O
samples	O
.	O
	
Essentially	O
,	O
in	O
this	O
big	O
data	O
era	O
,	O
humans	O
more	O
desire	O
intelligent	B-Method
machines	I-Method
which	O
are	O
capable	O
of	O
automatically	O
discovering	O
the	O
intrinsic	O
patterns	O
from	O
the	O
cheaply	O
and	O
massively	O
collected	O
weakly	O
	
*	O
The	O
corresponding	O
author	O
labeled	O
images	O
.	O
	
Thus	O
weakly	B-Task
supervised	I-Task
object	I-Task
detection	I-Task
(	O
WOD	B-Task
)	O
systems	O
have	O
been	O
gaining	O
more	O
interests	O
recently	O
.	O
	
The	O
key	O
problem	O
in	O
WOD	B-Task
is	O
how	O
to	O
extract	O
the	O
exact	O
object	B-Task
localizations	I-Task
and	O
train	O
the	O
corresponding	O
object	B-Method
detectors	I-Method
from	O
the	O
weakly	O
labelled	O
training	O
images	O
.	O
	
In	O
such	O
chicken	B-Task
-	I-Task
egg	I-Task
problem	I-Task
,	O
most	O
methods	O
(	O
including	O
the	O
proposed	O
one	O
)	O
usually	O
use	O
the	O
alternative	O
learning	B-Method
strategy	I-Method
that	O
first	O
provides	O
some	O
coarse	B-Task
estimation	I-Task
to	O
initialize	O
the	O
potential	O
object	O
locations	O
and	O
then	O
gradually	O
train	O
the	O
object	B-Method
detectors	I-Method
and	O
update	O
object	O
locations	O
jointly	O
.	O
	
In	O
this	O
paper	O
,	O
we	O
leverage	O
saliency	B-Task
detection	I-Task
to	O
initialize	O
the	O
potential	O
object	O
locations	O
due	O
to	O
the	O
following	O
reasons	O
:	O
1	O
)	O
Saliency	B-Task
detection	I-Task
;	O
[	O
reference	O
][	O
reference	O
]	O
aims	O
at	O
simulating	O
the	O
selective	B-Method
attention	I-Method
mechanism	I-Method
of	O
human	B-Method
visual	I-Method
system	I-Method
to	O
automatically	O
select	O
sub	O
-	O
regions	O
(	O
usually	O
the	O
regions	O
containing	O
objects	O
of	O
interest	O
)	O
in	O
image	O
scenes	O
.	O
	
Thus	O
,	O
it	O
can	O
be	O
readily	O
utilized	O
to	O
provide	O
useful	O
priors	O
to	O
estimate	O
the	O
potential	B-Task
object	I-Task
localizations	I-Task
and	O
fit	O
well	O
to	O
the	O
investigated	O
task	O
.	O
	
2	O
)	O
	
Some	O
recent	O
saliency	B-Task
detection	I-Task
methods	O
such	O
as	O
[	O
reference	O
]	O
and	O
[	O
reference	O
]	O
can	O
process	O
much	O
faster	O
than	O
the	O
priors	O
,	O
e.g.	O
,	O
intra	O
-	O
class	O
similarity	O
[	O
reference	O
]	O
,	O
inter	O
-	O
class	O
variance	O
[	O
reference	O
]	O
,	O
and	O
distance	O
mapping	O
relation	O
[	O
reference	O
]	O
,	O
adopted	O
in	O
the	O
existing	O
WOD	B-Task
systems	I-Task
.	O
	
3	O
)	O
	
Several	O
existing	O
works	O
,	O
e.g.	O
,	O
,	O
have	O
attempted	O
to	O
apply	O
saliency	B-Task
detection	I-Task
techniques	O
to	O
WOD	B-Task
.	O
	
However	O
they	O
still	O
have	O
not	O
sufficiently	O
explore	O
the	O
intrinsic	O
bridge	O
between	O
these	O
two	O
tasks	O
,	O
which	O
motivates	O
us	O
to	O
clarify	O
the	O
insightful	O
relationship	O
between	O
these	O
two	O
tasks	O
and	O
further	O
develop	O
powerful	O
learning	B-Method
regime	I-Method
to	O
bridge	O
them	O
.	O
	
Essentially	O
,	O
although	O
it	O
sounds	O
reasonable	O
to	O
apply	O
saliency	B-Task
detection	I-Task
to	O
WOD	B-Task
,	O
the	O
way	O
to	O
bridge	O
these	O
two	O
tasks	O
is	O
not	O
trivial	O
.	O
	
The	O
main	O
problem	O
is	O
that	O
saliency	B-Task
detection	I-Task
is	O
formulated	O
as	O
category	B-Method
-	I-Method
free	I-Method
models	I-Method
which	O
only	O
distinguish	O
attractive	O
regions	O
from	O
the	O
image	O
background	O
while	O
irrelevant	O
to	O
the	O
concrete	O
object	O
category	O
.	O
	
Thus	O
,	O
as	O
shown	O
in	O
Fig	O
.	O
1	O
,	O
in	O
the	O
images	O
only	O
containing	O
one	O
category	O
of	O
objects	O
(	O
considered	O
as	O
"	O
easy	O
"	O
images	O
)	O
,	O
the	O
objects	O
can	O
be	O
captured	O
by	O
saliency	B-Task
detection	I-Task
methods	O
easily	O
and	O
associated	O
with	O
the	O
corresponding	O
image	O
label	O
properly	O
.	O
	
Whereas	O
in	O
the	O
images	O
weakly	O
labelled	O
as	O
containing	O
multiple	O
categories	O
of	O
objects	O
(	O
considered	O
as	O
"	O
hard	O
"	O
images	O
)	O
,	O
objects	O
in	O
all	O
of	O
categories	O
will	O
have	O
the	O
probabilities	O
to	O
attract	O
the	O
human	O
attention	O
and	O
their	O
corresponding	O
locations	O
are	O
also	O
hard	O
for	O
saliency	B-Method
models	I-Method
to	O
identify	O
,	O
which	O
largely	O
increases	O
the	O
ambiguity	O
when	O
considering	O
to	O
apply	O
the	O
obtained	O
salient	B-Task
detection	I-Task
results	O
to	O
initializing	O
the	O
training	O
samples	O
for	O
WOD	B-Task
.	O
	
Thus	O
,	O
it	O
is	O
unreliable	O
to	O
directly	O
apply	O
saliency	B-Task
detection	I-Task
to	O
WOD	B-Task
.	O
	
To	O
alleviate	O
this	O
problem	O
,	O
we	O
propose	O
to	O
bridge	O
saliency	B-Task
detection	I-Task
to	O
WOD	B-Task
via	O
a	O
self	B-Method
-	I-Method
paced	I-Method
curriculum	I-Method
learning	I-Method
(	O
SPCL	B-Method
)	O
regime	O
.	O
	
SPCL	B-Method
was	O
proposed	O
in	O
as	O
a	O
general	O
learning	B-Method
framework	I-Method
including	O
both	O
the	O
curriculum	B-Method
learning	I-Method
(	O
CL	B-Method
)	O
and	O
self	B-Method
-	I-Method
paced	I-Method
learning	I-Method
(	O
SPL	B-Method
)	O
components	O
.	O
	
To	O
the	O
best	O
of	O
our	O
knowledge	O
,	O
both	O
of	O
these	O
two	O
learning	B-Method
components	I-Method
are	O
critical	O
in	O
successfully	O
bridging	O
saliency	B-Task
detection	I-Task
to	O
WOD	B-Task
,	O
whereas	O
none	O
of	O
the	O
existing	O
literature	O
has	O
explored	O
them	O
before	O
.	O
	
Specifically	O
,	O
CL	B-Method
was	O
proposed	O
by	O
[	O
reference	O
]	O
,	O
which	O
is	O
usually	O
learned	O
based	O
on	O
the	O
learning	O
priorities	O
derived	O
by	O
predetermined	B-Method
heuristics	I-Method
for	O
particular	O
problems	O
.	O
	
SPL	B-Method
was	O
proposed	O
by	O
[	O
reference	O
]	O
,	O
where	O
the	O
learning	O
pace	O
is	O
dynamically	O
generated	O
by	O
the	O
learner	O
itself	O
,	O
according	O
to	O
which	O
the	O
learner	O
has	O
already	O
learned	O
from	O
the	O
data	O
.	O
	
Thus	O
,	O
the	O
CL	B-Method
and	O
SPL	B-Method
components	O
in	O
SPCL	B-Method
can	O
be	O
correspondingly	O
used	O
to	O
solve	O
the	O
training	B-Task
sample	I-Task
initialization	I-Task
and	O
object	B-Task
detector	I-Task
updating	I-Task
problems	I-Task
in	O
the	O
proposed	O
saliency	B-Task
-	I-Task
guided	I-Task
WOD	I-Task
.	O
	
To	O
implement	O
SPCL	B-Method
for	O
our	O
task	O
,	O
we	O
first	O
design	O
a	O
task	O
-	O
specific	O
curriculum	O
to	O
assign	O
the	O
"	O
easy	O
"	O
images	O
with	O
larger	O
priority	O
than	O
the	O
"	O
hard	O
"	O
images	O
during	O
the	O
learning	B-Task
procedure	I-Task
,	O
which	O
indicates	O
that	O
only	O
the	O
salient	O
object	O
hypotheses	O
in	O
the	O
"	O
easy	O
"	O
images	O
are	O
selected	O
as	O
the	O
initial	O
training	O
samples	O
,	O
while	O
the	O
object	O
hypotheses	O
in	O
the	O
"	O
hard	O
"	O
images	O
will	O
be	O
gradually	O
involved	O
in	O
the	O
subsequent	O
learning	O
iterations	O
.	O
	
To	O
guide	O
the	O
learner	O
to	O
gradually	O
learn	O
faithful	O
knowledge	O
of	O
multi	O
-	O
class	O
objects	O
from	O
the	O
"	O
easy	O
"	O
(	O
high	O
-	O
confidence	O
)	O
images	O
to	O
the	O
"	O
hard	O
"	O
(	O
high	O
-	O
ambiguity	O
)	O
ones	O
,	O
a	O
novel	O
self	B-Method
-	I-Method
paced	I-Method
learning	I-Method
regularizer	O
is	O
proposed	O
to	O
enforce	O
the	O
learner	O
to	O
select	O
confident	O
and	O
diverse	O
training	O
hypotheses	O
in	O
each	O
iteration	O
and	O
learn	O
the	O
object	B-Method
detectors	I-Method
of	O
multiple	O
categories	O
simultaneously	O
.	O
	
Finally	O
,	O
the	O
proposed	O
SPCL	B-Method
regime	I-Method
can	O
fit	O
well	O
to	O
solve	O
the	O
problems	O
in	O
this	O
paper	O
.	O
	
Compared	O
with	O
the	O
SPCL	B-Method
model	I-Method
in	O
,	O
the	O
learning	B-Method
regime	I-Method
proposed	O
in	O
this	O
paper	O
mainly	O
has	O
three	O
differences	O
:	O
1	O
)	O
We	O
design	O
a	O
task	B-Method
-	I-Method
specific	I-Method
learning	I-Method
curriculum	I-Method
for	O
bridging	O
saliency	B-Task
detection	I-Task
and	O
WOD	B-Task
effectively	O
.	O
	
2	O
)	O
	
We	O
introduce	O
an	O
additional	O
term	O
,	O
the	O
sample	O
diversity	O
term	O
,	O
in	O
the	O
self	B-Method
-	I-Method
paced	I-Method
regularizer	I-Method
to	O
prevent	O
the	O
selected	O
training	O
hypotheses	O
from	O
drifting	O
to	O
a	O
small	O
collection	O
of	O
training	O
images	O
.	O
	
3	O
)	O
	
Considering	O
the	O
latent	O
relationship	O
among	O
the	O
multiple	O
categories	O
of	O
co	O
-	O
occurring	O
objects	O
,	O
we	O
further	O
generalize	O
the	O
SPL	B-Method
regime	O
into	O
multi	B-Method
-	I-Method
class	I-Method
formulation	I-Method
,	O
which	O
facilitates	O
the	O
learning	B-Method
system	I-Method
to	O
penalize	O
indiscriminative	O
object	O
hypotheses	O
predicted	O
as	O
belonging	O
to	O
multiple	O
object	O
categories	O
at	O
the	O
same	O
time	O
.	O
	
To	O
sum	O
up	O
,	O
there	O
are	O
three	O
-	O
fold	O
contributions	O
in	O
this	O
paper	O
:	O
	
	O
We	O
comprehensively	O
analyze	O
the	O
prospect	O
and	O
challenges	O
in	O
the	O
idea	O
of	O
bridging	O
saliency	B-Task
detection	I-Task
to	O
WOD	B-Task
and	O
propose	O
an	O
effective	O
way	O
to	O
alleviate	O
the	O
problem	O
,	O
which	O
achieves	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
detection	B-Metric
performance	I-Metric
under	O
the	O
weak	O
supervision	O
.	O
	
	O
We	O
establish	O
a	O
novel	O
SPCL	B-Method
regime	I-Method
containing	O
both	O
the	O
task	B-Method
-	I-Method
specific	I-Method
learning	I-Method
curriculum	I-Method
and	O
the	O
data	B-Method
-	I-Method
driven	I-Method
self	I-Method
-	I-Method
learning	I-Method
pace	I-Method
.	O
	
The	O
regime	O
is	O
well	O
formulated	O
as	O
a	O
concise	O
optimization	B-Method
model	I-Method
.	O
	
	O
We	O
incorporate	O
SPCL	B-Method
with	O
a	O
sample	O
diversity	O
term	O
and	O
further	O
generalize	O
it	O
to	O
work	O
in	O
multi	B-Task
-	I-Task
class	I-Task
scenario	I-Task
.	O
	
section	O
:	O
Related	O
Works	O
	
Saliency	B-Task
detection	I-Task
:	O
	
Most	O
saliency	B-Task
detection	I-Task
methods	O
highlight	O
the	O
attractive	O
image	O
regions	O
by	O
exploring	O
some	O
bottom	O
-	O
up	O
cues	O
.	O
	
As	O
one	O
frequently	O
explored	O
cue	O
,	O
local	O
contrast	O
[	O
reference	O
][	O
reference	O
]	O
is	O
usually	O
used	O
in	O
the	O
saliency	B-Task
detection	I-Task
models	O
to	O
highlight	O
the	O
image	O
regions	O
appearing	O
differently	O
with	O
their	O
spatially	O
neighbor	O
regions	O
.	O
	
Another	O
widely	O
used	O
bottom	O
-	O
up	O
cue	O
is	O
the	O
global	O
contrast	O
.	O
	
Being	O
different	O
from	O
local	O
contrast	O
,	O
global	O
contrast	O
[	O
reference	O
][	O
reference	O
]	O
is	O
used	O
to	O
discover	O
image	O
regions	O
which	O
are	O
unique	O
in	O
the	O
entire	O
image	O
context	O
.	O
	
More	O
recently	O
,	O
background	O
prior	O
becomes	O
another	O
important	O
cue	O
for	O
saliency	B-Task
detection	I-Task
.	O
	
This	O
kind	O
of	O
methods	O
,	O
e.g.	O
,	O
,	O
assume	O
that	O
regions	O
near	O
image	O
boundaries	O
are	O
probably	O
backgrounds	O
and	O
detect	O
salient	O
regions	O
as	O
Figure	O
1	O
:	O
This	O
figure	O
illustrates	O
the	O
main	O
idea	O
of	O
this	O
paper	O
.	O
	
As	O
can	O
be	O
seen	O
,	O
in	O
the	O
training	O
images	O
with	O
weak	O
labels	O
,	O
some	O
of	O
them	O
(	O
in	O
blue	O
frame	O
)	O
are	O
labelled	O
only	O
containing	O
one	O
object	O
category	O
,	O
which	O
are	O
considered	O
as	O
"	O
easy	O
"	O
images	O
for	O
the	O
saliency	B-Task
detection	I-Task
methods	O
.	O
	
While	O
others	O
(	O
in	O
pink	O
frame	O
)	O
labelled	O
as	O
containing	O
multiple	O
object	O
categories	O
are	O
considered	O
as	O
"	O
hard	O
"	O
images	O
.	O
	
Due	O
to	O
the	O
category	O
free	O
property	O
of	O
saliency	B-Task
detection	I-Task
,	O
the	O
objects	O
in	O
"	O
easy	O
"	O
images	O
have	O
larger	O
confidence	O
to	O
be	O
extracted	O
correctly	O
by	O
the	O
saliency	B-Task
detection	I-Task
methods	O
,	O
whereas	O
the	O
objects	O
in	O
"	O
hard	O
"	O
images	O
can	O
not	O
be	O
extracted	O
successfully	O
.	O
	
To	O
this	O
end	O
,	O
we	O
develop	O
a	O
novel	O
self	B-Method
-	I-Method
paced	I-Method
curriculum	I-Method
learning	I-Method
paradigm	O
to	O
guide	O
the	O
learner	O
to	O
gradually	O
achieve	O
the	O
faithful	O
knowledge	O
of	O
the	O
multiple	O
object	O
categories	O
from	O
easy	O
(	O
confident	O
)	O
to	O
hard	O
(	O
ambiguous	O
)	O
.	O
	
calculating	O
the	O
contrast	O
to	O
these	O
image	O
boundary	O
regions	O
.	O
	
As	O
can	O
be	O
seen	O
,	O
the	O
bottom	O
-	O
up	O
cues	O
explored	O
by	O
saliency	B-Task
detection	I-Task
models	O
are	O
highly	O
potential	O
to	O
provide	O
helpful	O
priors	O
to	O
the	O
object	B-Task
localizations	I-Task
in	O
each	O
image	O
.	O
	
Weakly	B-Task
-	I-Task
supervised	I-Task
object	I-Task
detection	I-Task
:	O
	
Two	O
key	O
issues	O
in	O
WOD	B-Task
are	O
1	O
)	O
predict	O
the	O
potential	B-Task
object	I-Task
localizations	I-Task
and	O
2	O
)	O
learn	O
the	O
object	B-Method
detectors	I-Method
.	O
	
Some	O
early	O
WOD	B-Task
methods	O
[	O
reference	O
]	O
held	O
the	O
view	O
that	O
a	O
better	O
initial	O
estimation	O
of	O
the	O
object	B-Task
localizations	I-Task
is	O
critical	O
to	O
this	O
task	O
as	O
they	O
can	O
largely	O
impact	O
the	O
subsequent	O
learning	B-Task
process	I-Task
.	O
	
Thus	O
,	O
they	O
explored	O
different	O
ways	O
,	O
e.g.	O
intra	O
-	O
class	O
similarity	O
[	O
reference	O
]	O
,	O
inter	O
-	O
class	O
variance	O
[	O
reference	O
]	O
,	O
and	O
distance	O
mapping	O
relation	O
[	O
reference	O
]	O
,	O
to	O
initialize	O
the	O
training	O
object	O
hypotheses	O
.	O
	
Later	O
on	O
,	O
some	O
recent	O
WOD	B-Task
methods	O
started	O
to	O
pay	O
more	O
attention	O
to	O
the	O
optimization	B-Method
procedure	I-Method
designed	O
for	O
better	O
training	B-Task
object	I-Task
detectors	I-Task
under	O
the	O
weak	O
supervision	O
.	O
	
For	O
example	O
,	O
[	O
reference	O
][	O
reference	O
]	O
proposed	O
to	O
smooth	O
the	O
object	B-Method
formulation	I-Method
to	O
better	O
obtain	O
the	O
optimal	O
solutions	O
.	O
	
[	O
reference	O
]	O
proposed	O
to	O
incorporate	O
convex	B-Method
clustering	I-Method
in	O
the	O
learning	B-Method
procedure	I-Method
,	O
which	O
enforces	O
the	O
local	O
similarity	O
of	O
the	O
selected	O
hypotheses	O
during	O
optimization	B-Task
.	O
	
Essentially	O
,	O
both	O
of	O
the	O
above	O
mentioned	O
problems	O
are	O
critical	O
in	O
WOD	B-Task
task	I-Task
.	O
	
To	O
this	O
end	O
,	O
this	O
paper	O
proposes	O
a	O
novel	O
SPCL	B-Method
model	I-Method
which	O
explicitly	O
encode	O
both	O
the	O
former	O
problem	O
(	O
with	O
the	O
designed	O
curriculum	B-Method
)	O
and	O
the	O
later	O
(	O
with	O
the	O
self	B-Method
-	I-Method
paced	I-Method
regularizer	I-Method
)	O
into	O
a	O
unified	O
formulation	O
and	O
handle	O
both	O
problems	O
in	O
a	O
theoretically	O
sound	O
manner	O
.	O
	
section	O
:	O
Self	B-Method
-	I-Method
paced	I-Method
(	I-Method
curriculum	I-Method
)	I-Method
learning	I-Method
:	O
	
Inspired	O
by	O
the	O
learning	B-Method
process	I-Method
of	O
humans	O
/	O
animals	O
,	O
the	O
theory	O
of	O
self	B-Method
-	I-Method
paced	I-Method
(	I-Method
or	I-Method
curriculum	I-Method
)	I-Method
learning	I-Method
[	O
reference	O
][	O
reference	O
]	O
is	O
proposed	O
lately	O
.	O
	
The	O
idea	O
is	O
to	O
learn	O
the	O
model	O
iteratively	O
from	O
easy	O
to	O
complex	O
samples	O
in	O
a	O
self	O
-	O
paced	O
fashion	O
.	O
	
By	O
virtue	O
of	O
its	O
generality	O
,	O
the	O
SPL	B-Method
theory	O
has	O
been	O
widely	O
applied	O
to	O
various	O
tasks	O
,	O
such	O
as	O
multi	B-Task
-	I-Task
view	I-Task
clustering	I-Task
[	O
reference	O
]	O
,	O
multi	B-Task
-	I-Task
label	I-Task
propagation	I-Task
[	O
reference	O
]	O
,	O
multimedia	B-Task
event	I-Task
detection	I-Task
,	O
and	O
co	O
-	O
saliency	B-Task
detection	I-Task
.	O
	
More	O
recently	O
,	O
introduced	O
the	O
pre	O
-	O
defined	O
learning	B-Method
curriculum	I-Method
to	O
the	O
conventional	O
self	B-Method
-	I-Method
paced	I-Method
learning	I-Method
regime	O
which	O
can	O
take	O
into	O
account	O
both	O
the	O
helpful	O
prior	O
knowledge	O
known	O
before	O
training	O
and	O
the	O
self	O
-	O
learning	O
progress	O
during	O
training	O
.	O
	
Inspired	O
by	O
this	O
work	O
,	O
we	O
design	O
a	O
task	B-Method
-	I-Method
specific	I-Method
learning	I-Method
curriculum	I-Method
and	O
construct	O
a	O
unified	B-Method
SPCL	I-Method
model	I-Method
specifically	O
for	O
both	O
the	O
saliency	B-Task
detection	I-Task
and	O
WOD	B-Task
tasks	O
,	O
through	O
which	O
both	O
can	O
be	O
naturally	O
related	O
.	O
	
section	O
:	O
The	O
Proposed	O
Approach	O
	
section	O
:	O
Algorithm	O
Overview	O
	
Given	O
K	O
training	O
images	O
with	O
weak	O
labels	O
consisting	O
of	O
C	O
categories	O
,	O
we	O
first	O
extract	O
the	O
bounding	O
box	O
object	O
hypotheses	O
and	O
their	O
corresponding	O
feature	B-Method
representations	I-Method
from	O
each	O
image	O
.	O
	
Denote	O
the	O
features	O
of	O
each	O
hypothesis	O
in	O
the	O
k	O
th	O
image	O
as	O
{	O
,	O
where	O
,	O
(	O
)	O
∈	O
[	O
0	O
,	O
1	O
]	O
,	O
indicating	O
the	O
labels	O
and	O
the	O
real	O
-	O
valued	O
importance	O
weights	O
of	O
each	O
hypothesis	O
,	O
respectively	O
,	O
which	O
are	O
unknown	O
at	O
the	O
beginning	O
and	O
will	O
be	O
optimized	O
during	O
the	O
proposed	O
learning	B-Method
regime	I-Method
.	O
	
The	O
aim	O
of	O
the	O
proposed	O
approach	O
is	O
to	O
learn	O
the	O
object	B-Method
detectors	I-Method
{	O
W	O
,	O
b	O
}	O
,	O
where	O
=	O
{	O
}	O
,	O
=	O
{	O
}	O
,	O
of	O
C	O
object	O
categories	O
from	O
the	O
weakly	O
-	O
labeled	O
training	O
images	O
,	O
and	O
then	O
use	O
them	O
to	O
detect	O
objects	O
in	O
the	O
test	O
images	O
.	O
	
Specifically	O
,	O
we	O
first	O
design	O
a	O
simple	O
yet	O
effective	O
curriculum	O
to	O
select	O
the	O
salient	O
hypotheses	O
in	O
"	O
easy	O
"	O
images	O
as	O
initialization	O
.	O
	
Then	O
,	O
the	O
object	B-Method
detectors	I-Method
are	O
trained	O
and	O
updated	O
gradually	O
under	O
the	O
guidance	O
of	O
the	O
proposed	O
self	B-Method
-	I-Method
paced	I-Method
learning	I-Method
strategy	O
.	O
	
Finally	O
,	O
the	O
obtained	O
object	B-Method
detectors	I-Method
are	O
used	O
to	O
detect	O
the	O
corresponding	O
objects	O
in	O
the	O
test	O
images	O
.	O
	
The	O
overall	O
algorithm	O
is	O
shown	O
in	O
Algorithm	O
1	O
.	O
	
section	O
:	O
Problem	O
Formulation	O
	
Given	O
object	O
hypotheses	O
from	O
the	O
training	O
images	O
,	O
we	O
propose	O
a	O
simple	O
yet	O
effective	O
curriculum	B-Method
to	O
initialize	O
the	O
learning	B-Method
procedure	I-Method
.	O
	
Specifically	O
,	O
we	O
first	O
obtain	O
the	O
"	O
easy	O
"	O
images	O
based	O
on	O
the	O
number	O
of	O
weak	O
labels	O
of	O
each	O
image	O
,	O
i.e.	O
,	O
images	O
weakly	O
labelled	O
as	O
only	O
containing	O
one	O
object	O
category	O
are	O
considered	O
as	O
"	O
easy	O
"	O
.	O
	
Then	O
,	O
for	O
each	O
"	O
easy	O
"	O
image	O
,	O
we	O
adopt	O
an	O
unsupervised	O
saliency	B-Task
detection	I-Task
method	O
,	O
i.e.	O
,	O
RC	B-Method
[	O
reference	O
]	O
in	O
this	O
paper	O
due	O
to	O
its	O
efficiency	O
,	O
to	O
generate	O
the	O
corresponding	O
saliency	B-Task
estimation	I-Task
.	O
	
Finally	O
,	O
the	O
important	O
weights	O
v	O
are	O
initialized	O
as	O
the	O
intersection	B-Metric
-	I-Metric
over	I-Metric
-	I-Metric
union	I-Metric
(	O
IOU	B-Metric
)	O
score	O
between	O
each	O
hypothesis	O
and	O
the	O
salient	O
region	O
.	O
	
The	O
hypotheses	O
with	O
weights	O
larger	O
than	O
0	O
are	O
selected	O
as	O
the	O
initial	O
training	O
hypotheses	O
and	O
their	O
labels	O
in	O
y	O
are	O
set	O
according	O
to	O
the	O
label	O
of	O
the	O
images	O
containing	O
them	O
.	O
	
Afterwards	O
,	O
in	O
order	O
to	O
gradually	O
adapt	O
the	O
learner	O
from	O
the	O
"	O
easy	O
"	O
domain	O
to	O
the	O
"	O
hard	O
"	O
domain	O
and	O
finally	O
capture	O
the	O
faithful	O
knowledge	O
of	O
the	O
objects	O
of	O
interest	O
,	O
a	O
novel	O
self	B-Method
-	I-Method
paced	I-Method
learning	I-Method
regularizer	O
is	O
proposed	O
as	O
follows	O
:	O
+	O
1	O
≤	O
2	O
,	O
enforces	O
that	O
each	O
hypothesis	O
should	O
belong	O
to	O
only	O
one	O
object	O
category	O
,	O
or	O
no	O
class	O
,	O
i.e.	O
,	O
the	O
background	O
category	O
.	O
	
This	O
constraint	O
inherently	O
penalizes	O
the	O
indiscriminative	O
object	O
hypotheses	O
,	O
i.e.	O
the	O
hypotheses	O
predicted	O
to	O
belong	O
to	O
multiple	O
object	O
categories	O
,	O
when	O
calculating	O
their	O
importance	O
weight	O
in	O
(	O
2	O
)	O
.	O
	
The	O
third	O
one	O
,	O
i.e.	O
∑	O
,	O
*	O
(	O
)	O
+	O
1	O
≥	O
2	O
,	O
means	O
that	O
for	O
all	O
object	O
hypotheses	O
located	O
in	O
the	O
k	O
th	O
image	O
,	O
at	O
least	O
one	O
should	O
belong	O
to	O
the	O
class	O
which	O
the	O
image	O
has	O
been	O
weakly	O
annotated	O
.	O
	
This	O
will	O
make	O
the	O
learned	O
result	O
finely	O
comply	O
with	O
the	O
prior	O
knowledge	O
.	O
	
In	O
the	O
proposed	O
SPCL	B-Method
regime	I-Method
,	O
the	O
self	O
-	O
paced	O
capability	O
is	O
followed	O
by	O
the	O
involvement	O
of	O
the	O
SPL	B-Method
regularizer	O
(	O
)	O
;	O
,	O
with	O
the	O
following	O
form	O
:	O
	
where	O
,	O
are	O
the	O
class	O
-	O
specific	O
parameters	O
imposed	O
on	O
the	O
easiness	O
term	O
and	O
the	O
diversity	O
term	O
,	O
respectively	O
.	O
	
The	O
negative	O
l	O
1	O
-	O
norm	O
term	O
is	O
inherited	O
from	O
the	O
conventional	O
SPL	B-Method
[	O
reference	O
]	O
,	O
which	O
favors	O
selecting	O
easy	O
over	O
complex	O
hypotheses	O
.	O
	
If	O
we	O
omit	O
the	O
diversity	O
term	O
,	O
i.e.	O
let	O
=	O
0	O
,	O
the	O
regularizer	B-Method
degenerates	O
to	O
the	O
traditional	O
hard	O
SPL	B-Method
function	O
proposed	O
in	O
[	O
reference	O
]	O
,	O
which	O
conducts	O
either	O
1	O
or	O
0	O
(	O
i.e.	O
selected	O
in	O
training	O
or	O
not	O
)	O
for	O
the	O
weight	O
,	O
(	O
)	O
imposed	O
on	O
hypothesis	O
(	O
)	O
,	O
by	O
judging	O
whether	O
its	O
loss	O
value	O
is	O
smaller	O
than	O
the	O
pace	O
parameter	O
or	O
not	O
.	O
	
That	O
is	O
,	O
a	O
sample	O
with	O
smaller	O
loss	O
is	O
taken	O
as	O
an	O
easy	O
sample	O
and	O
thus	O
should	O
be	O
learned	O
preferentially	O
and	O
vice	O
versa	O
.	O
	
Another	O
regularization	B-Method
term	I-Method
favors	O
selecting	O
diverse	O
hypotheses	O
residing	O
in	O
more	O
images	O
.	O
	
This	O
can	O
be	O
easily	O
understood	O
by	O
seeing	O
that	O
its	O
negative	O
leads	O
to	O
the	O
group	B-Method
-	I-Method
wise	I-Method
sparse	I-Method
representation	I-Method
of	O
v.	O
Contrariwise	O
,	O
this	O
diversity	O
term	O
should	O
have	O
a	O
counter	O
-	O
effect	O
to	O
group	O
-	O
wise	O
sparsity	O
.	O
	
That	O
is	O
,	O
minimizing	O
this	O
diversity	O
term	O
tends	O
to	O
disperse	O
non	O
-	O
zero	O
elements	O
of	O
v	O
over	O
more	O
images	O
,	O
and	O
thus	O
favors	O
selecting	O
more	O
diverse	O
hypotheses	O
.	O
	
Consequently	O
,	O
this	O
anti	B-Method
-	I-Method
group	I-Method
-	I-Method
sparsity	I-Method
representation	I-Method
is	O
expected	O
to	O
realize	O
the	O
desired	O
diversity	O
.	O
	
Different	O
from	O
the	O
commonly	O
utilized	O
l	B-Method
2	I-Method
,	I-Method
1	I-Method
norm	I-Method
,	O
our	O
utilized	O
group	B-Method
-	I-Method
sparsity	I-Method
term	I-Method
is	O
concave	O
,	O
leading	O
to	O
the	O
convexity	O
of	O
its	O
negative	O
.	O
	
This	O
on	O
one	O
side	O
simplifies	O
the	O
designation	O
of	O
the	O
solving	B-Method
strategy	I-Method
,	O
and	O
on	O
the	O
other	O
hand	O
well	O
fits	O
the	O
previous	O
axiomatic	O
definition	O
for	O
the	O
SPL	B-Method
regularizer	O
.	O
	
section	O
:	O
Optimization	B-Method
Method	I-Method
	
The	O
solution	O
of	O
(	O
1	O
)	O
can	O
be	O
approximately	O
attained	O
by	O
alternatively	O
optimizing	O
the	O
involved	O
parameters	O
{	O
W	O
,	O
b	O
}	O
,	O
y	O
and	O
v	O
as	O
described	O
in	O
Algorithm	O
1	O
.	O
	
The	O
optimization	B-Task
mainly	O
contains	O
following	O
steps	O
:	O
	
Object	B-Method
detectors	I-Method
updating	I-Method
:	O
Optimize	O
object	O
detector	O
parameters	O
{	O
W	O
,	O
b	O
}	O
via	O
one	B-Method
-	I-Method
vs	I-Method
-	I-Method
all	I-Method
SVM	I-Method
under	O
fixed	O
y	O
and	O
v.	O
	
In	O
this	O
case	O
,	O
(	O
1	O
)	O
degenerates	O
to	O
the	O
following	O
form	O
:	O
	
;	O
,	O
,	O
	
which	O
can	O
be	O
equivalently	O
reformulated	O
as	O
solving	O
the	O
following	O
sub	B-Task
-	I-Task
optimization	I-Task
problems	I-Task
for	O
each	O
c=1	O
,	O
2	O
,	O
…	O
,	O
C	O
:	O
	
,	O
.	O
	
This	O
is	O
a	O
standard	O
one	B-Method
-	I-Method
vs	I-Method
-	I-Method
all	I-Method
(	I-Method
weighted	I-Method
)	I-Method
SVM	I-Method
model	I-Method
[	O
reference	O
]	O
.	O
	
section	O
:	O
Hypotheses	B-Task
labelling	I-Task
:	O
Optimize	O
under	O
fixed	O
{	O
W	O
,	O
b	O
}	O
and	O
v	O
:	O
	
The	O
goal	O
of	O
this	O
step	O
is	O
to	O
learn	O
the	O
pseudo	O
-	O
labels	O
of	O
training	O
hypotheses	O
from	O
the	O
current	O
object	B-Method
detectors	I-Method
.	O
	
The	O
model	O
in	O
this	O
case	O
can	O
be	O
reformulated	O
as	O
:	O
This	O
problem	O
can	O
be	O
equivalently	O
decomposed	O
into	O
sub	O
-	O
problems	O
with	O
respect	O
to	O
each	O
=	O
1	O
,	O
⋯	O
,	O
,	O
i.e.	O
for	O
each	O
image	O
,	O
where	O
c	O
*	O
is	O
the	O
weak	O
labels	O
of	O
the	O
k	O
th	O
image	O
:	O
[	O
reference	O
]	O
indicates	O
the	O
labels	O
of	O
the	O
hypotheses	O
in	O
the	O
k	O
th	O
image	O
.	O
	
Its	O
global	O
optimum	O
can	O
be	O
attained	O
by	O
Algorithm	O
2	O
,	O
which	O
can	O
be	O
derived	O
from	O
the	O
theorem	O
in	O
.	O
	
Hypotheses	B-Task
re	I-Task
-	I-Task
weighting	I-Task
	
:	O
Optimize	O
v	O
under	O
fixed	O
{	O
W	O
,	O
b	O
}	O
and	O
y	O
:	O
	
After	O
updating	O
the	O
pseudo	O
-	O
labels	O
,	O
we	O
aim	O
to	O
renew	O
the	O
weights	O
on	O
all	O
hypotheses	O
to	O
reflect	O
their	O
different	O
importance	O
to	O
learning	O
of	O
the	O
current	O
decision	O
surface	O
.	O
	
In	O
this	O
case	O
,	O
(	O
1	O
)	O
degenerates	O
to	O
the	O
following	O
form	O
:	O
	
which	O
is	O
equivalent	O
to	O
independently	O
solving	O
the	O
following	O
sub	B-Task
-	I-Task
optimization	I-Task
problem	I-Task
for	O
each	O
=	O
1	O
,	O
⋯	O
,	O
and	O
=	O
1	O
,	O
⋯	O
,	O
via	O
:	O
	
We	O
can	O
easily	O
simplify	O
the	O
above	O
optimization	B-Task
problem	I-Task
as	O
:	O
	
This	O
model	O
is	O
convex	O
and	O
according	O
to	O
,	O
we	O
can	O
apdopt	O
an	O
effective	O
algorithm	O
,	O
i.e.	O
,	O
the	O
Algorithm	O
3	O
,	O
for	O
extracting	O
the	O
global	O
optimum	O
to	O
it	O
.	O
	
section	O
:	O
Experimental	O
Results	O
	
section	O
:	O
Experimental	O
Settings	O
	
We	O
evaluate	O
our	O
method	O
on	O
the	O
Pascal	B-Material
VOC	I-Material
2007	I-Material
dataset	I-Material
[	O
reference	O
]	O
which	O
is	O
widely	O
used	O
by	O
the	O
previous	O
works	O
.	O
	
In	O
our	O
experiments	O
,	O
we	O
follow	O
the	O
previous	O
works	O
[	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
to	O
discard	O
any	O
images	O
that	O
only	O
contain	O
object	O
instances	O
marked	O
as	O
"	O
difficult	O
"	O
or	O
"	O
truncated	O
"	O
during	O
the	O
training	O
phase	O
,	O
while	O
all	O
the	O
images	O
in	O
the	O
VOC07	O
-	O
Test	O
are	O
used	O
during	O
the	O
test	O
phase	O
.	O
	
For	O
fair	O
comparison	O
,	O
we	O
follow	O
the	O
standard	O
VOC	B-Method
procedure	I-Method
[	O
reference	O
]	O
and	O
report	O
average	B-Metric
precision	I-Metric
(	O
AP	B-Metric
)	O
on	O
the	O
Pascal	B-Material
VOC	I-Material
2007	I-Material
test	I-Material
split	I-Material
.	O
	
Being	O
consistent	O
with	O
the	O
recently	O
proposed	O
WOD	B-Task
methods	O
[	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
,	O
we	O
apply	O
Selective	B-Method
Search	I-Method
[	O
reference	O
]	O
to	O
generate	O
around	O
1500	O
bounding	O
box	O
object	O
hypotheses	O
in	O
each	O
image	O
and	O
adopt	O
the	O
CNN	B-Method
features	I-Method
[	O
reference	O
]	O
pre	O
-	O
trained	O
on	O
the	O
ImageNet	O
2012	O
to	O
represent	O
each	O
of	O
the	O
extracted	O
object	O
hypotheses	O
.	O
	
Before	O
training	O
,	O
and	O
in	O
(	O
2	O
)	O
need	O
to	O
be	O
set	O
in	O
advance	O
.	O
	
As	O
suggested	O
in	O
,	O
we	O
set	O
according	O
to	O
the	O
number	O
of	O
the	O
selected	O
training	O
hypotheses	O
which	O
is	O
set	O
to	O
be	O
2	O
%	O
of	O
the	O
total	O
bounding	O
box	O
windows	O
extracted	O
from	O
the	O
images	O
weakly	O
labelled	O
as	O
containing	O
the	O
c	O
th	O
object	O
category	O
.	O
	
Then	O
,	O
is	O
set	O
to	O
be	O
equal	O
to	O
empirically	O
.	O
	
section	O
:	O
Comparison	O
to	O
the	O
State	O
-	O
of	O
-	O
the	O
-	O
arts	O
	
In	O
this	O
section	O
,	O
we	O
evaluate	O
the	O
object	B-Task
detection	I-Task
performance	O
of	O
our	O
framework	O
by	O
comparing	O
it	O
with	O
6	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
WOD	B-Method
approaches	I-Method
which	O
are	O
PR	B-Method
[	O
reference	O
]	O
,	O
CC	B-Method
[	O
reference	O
]	O
,	O
MDD	B-Method
[	O
reference	O
]	O
,	O
	
LLO	B-Method
[	O
reference	O
]	O
,	O
VPC	B-Method
[	O
reference	O
]	O
,	O
and	O
MfMIL	B-Method
	
[	O
reference	O
]	O
.	O
For	O
quantitative	O
comparison	O
,	O
we	O
report	O
the	O
evaluation	O
results	O
in	O
terms	O
of	O
the	O
AP	B-Metric
score	O
in	O
Fig	O
.	O
2	O
.	O
	
As	O
can	O
be	O
seen	O
,	O
the	O
proposed	O
approach	O
obtains	O
the	O
highest	O
score	O
of	O
29.96	O
on	O
average	O
.	O
	
According	O
to	O
our	O
analysis	O
,	O
the	O
proposed	O
approach	O
can	O
obtain	O
significantly	O
better	O
results	O
than	O
MDD	B-Method
and	O
MfMIL	B-Method
mainly	O
due	O
to	O
the	O
better	O
feature	B-Method
representation	I-Method
,	O
stronger	O
saliency	O
prior	O
,	O
and	O
more	O
powerful	O
learning	B-Method
scheme	I-Method
.	O
	
Compared	O
with	O
PR	B-Method
,	O
CC	B-Method
,	O
LLO	B-Method
,	O
and	O
VPC	B-Method
,	O
the	O
performance	O
gain	O
of	O
the	O
proposed	O
approach	O
mainly	O
comes	O
from	O
the	O
core	O
insight	O
of	O
this	O
paper	O
,	O
i.e.	O
,	O
developing	O
property	O
way	O
to	O
bridge	O
saliency	B-Task
detection	I-Task
to	O
WOD	B-Task
,	O
as	O
we	O
used	O
the	O
same	O
feature	B-Method
representation	I-Method
with	O
these	O
methods	O
.	O
	
More	O
specifically	O
,	O
compared	O
with	O
PR	B-Method
and	O
CC	B-Method
,	O
the	O
performance	O
gain	O
of	O
the	O
proposed	O
approach	O
comes	O
mainly	O
from	O
the	O
idea	O
to	O
bridge	O
saliency	B-Task
detection	I-Task
to	O
WOD	B-Task
because	O
they	O
only	O
adopted	O
weak	O
priors	O
in	O
their	O
initialization	O
.	O
	
Compared	O
with	O
LLO	B-Method
and	O
VPC	B-Method
,	O
the	O
performance	O
gain	O
of	O
the	O
proposed	O
approach	O
mainly	O
comes	O
from	O
the	O
proposed	O
SPCL	B-Method
regime	I-Method
as	O
these	O
two	O
methods	O
also	O
explored	O
strong	O
prior	O
information	O
for	O
initializing	O
the	O
training	O
hypotheses	O
in	O
their	O
frameworks	O
.	O
	
Some	O
examples	O
of	O
the	O
detection	B-Task
results	O
are	O
also	O
shown	O
in	O
Fig	O
.	O
2	O
,	O
which	O
includes	O
some	O
successful	O
cases	O
,	O
i.e.	O
,	O
the	O
examples	O
in	O
the	O
bus	O
and	O
cat	O
categories	O
,	O
as	O
well	O
as	O
some	O
failure	O
cases	O
,	O
i.e.	O
,	O
examples	O
in	O
the	O
plant	O
and	O
chair	O
categories	O
.	O
	
The	O
successful	O
cases	O
subjectively	O
demonstrate	O
the	O
effectiveness	O
of	O
the	O
proposed	O
approach	O
.	O
	
For	O
the	O
failure	O
cases	O
,	O
the	O
main	O
problem	O
is	O
that	O
very	O
limited	O
number	O
of	O
images	O
only	O
contains	O
the	O
objects	O
like	O
plant	O
and	O
chair	O
,	O
leading	O
to	O
the	O
insufficient	O
training	O
hypotheses	O
in	O
the	O
initialization	B-Method
stage	I-Method
.	O
	
This	O
problem	O
can	O
be	O
solved	O
by	O
designing	O
more	O
proper	O
learning	B-Method
curriculum	I-Method
for	O
WOD	B-Task
in	O
future	O
works	O
.	O
	
section	O
:	O
Model	O
Analysis	O
	
To	O
further	O
analyze	O
the	O
proposed	O
framework	O
in	O
this	O
paper	O
,	O
we	O
make	O
more	O
comprehensive	O
evaluations	O
in	O
this	O
section	O
by	O
comparing	O
with	O
five	O
baseline	O
models	O
as	O
described	O
in	O
Table	O
1	O
.	O
	
The	O
experimental	O
results	O
are	O
shown	O
in	O
Fig	O
.	O
3	O
,	O
from	O
which	O
we	O
can	O
see	O
:	O
1	O
)	O
The	O
performance	O
gap	O
between	O
Sal	B-Method
+	O
SVM	O
and	O
OURS	O
demonstrates	O
the	O
importance	O
to	O
develop	O
proper	O
ways	O
to	O
bridge	O
saliency	B-Task
detection	I-Task
and	O
WOD	B-Task
.	O
	
2	O
)	O
	
The	O
experimental	O
results	O
of	O
Sal	B-Method
+	O
SPL	B-Method
,	O
Sal	B-Method
+	O
SPCL	B-Method
,	O
and	O
OURS	O
demonstrate	O
the	O
better	O
performance	O
of	O
the	O
proposed	O
learning	B-Method
regime	I-Method
as	O
compared	O
with	O
some	O
existing	O
self	B-Method
-	I-Method
paced	I-Method
(	I-Method
curriculum	I-Method
)	I-Method
learning	I-Method
regimes	I-Method
.	O
	
3	O
)	O
	
The	O
performance	O
gap	O
between	O
OURS	O
and	O
LLO	B-Method
+	O
SPCL	B-Method
*	O
demonstrates	O
the	O
saliency	O
prior	O
can	O
provide	O
more	O
helpful	O
information	O
than	O
the	O
prior	O
designed	O
in	O
LLO	B-Method
.	O
	
4	O
)	O
	
The	O
performance	O
gap	O
between	O
	
LLO	B-Method
+	O
SPCL	B-Method
*	O
and	O
LLO	B-Method
indicates	O
the	O
better	O
capability	O
of	O
the	O
proposed	O
learning	B-Method
regime	I-Method
as	O
compared	O
with	O
the	O
learning	B-Method
model	I-Method
in	O
one	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
	
WOD	B-Task
framework	O
.	O
	
According	O
to	O
the	O
above	O
analysis	O
,	O
the	O
key	O
insight	O
of	O
this	O
paper	O
,	O
i.e.	O
,	O
developing	O
powerful	O
learning	B-Method
regime	I-Method
,	O
i.e.	O
,	O
the	O
proposed	O
SPCL	B-Method
,	O
can	O
better	O
bridge	O
saliency	B-Task
detection	I-Task
to	O
WOD	B-Task
and	O
help	O
the	O
learner	O
to	O
capture	O
the	O
faithful	O
knowledge	O
of	O
the	O
object	O
categories	O
under	O
weak	O
supervision	O
,	O
has	O
been	O
demonstrated	O
comprehensively	O
.	O
	
section	O
:	O
Conclusion	O
	
In	O
this	O
paper	O
,	O
in	O
order	O
to	O
address	O
the	O
challenging	O
WOD	B-Task
problem	I-Task
,	O
we	O
proposed	O
an	O
effective	O
framework	O
to	O
bridge	O
saliency	B-Task
detection	I-Task
to	O
the	O
investigated	O
task	O
based	O
on	O
a	O
novel	O
SPCL	B-Method
regime	I-Method
.	O
	
The	O
insight	O
of	O
this	O
paper	O
is	O
that	O
by	O
developing	O
powerful	O
learning	B-Method
regime	I-Method
which	O
contains	O
both	O
the	O
task	B-Method
-	I-Method
specific	I-Method
learning	I-Method
curriculum	I-Method
and	O
the	O
data	B-Method
-	I-Method
driven	I-Method
self	I-Method
-	I-Method
learning	I-Method
pace	I-Method
,	O
saliency	B-Task
detection	I-Task
technique	O
can	O
be	O
better	O
leveraged	O
to	O
provide	O
beneficial	O
information	O
for	O
helping	O
the	O
learner	O
to	O
capture	O
the	O
faithful	O
knowledge	O
of	O
the	O
object	O
categories	O
under	O
weak	O
supervision	O
.	O
	
Experiments	O
including	O
comparisons	O
to	O
other	O
state	O
-	O
of	O
-	O
the	O
-	O
arts	O
and	O
comprehensive	O
analysis	O
of	O
the	O
proposed	O
framework	O
on	O
the	O
benchmark	O
dataset	O
have	O
demonstrated	O
the	O
effectiveness	O
of	O
our	O
approach	O
.	O
	
For	O
the	O
future	O
work	O
,	O
inspired	O
by	O
[	O
reference	O
]	O
,	O
we	O
plane	O
to	O
enable	O
the	O
proposed	O
method	O
to	O
transfer	O
the	O
knowledge	O
that	O
has	O
be	O
captured	O
to	O
new	O
concepts	O
via	O
novel	O
regularizers	B-Method
.	O
.	O
	
LLO	B-Method
Baseline	O
WOD	B-Task
framework	O
	
[	O
reference	O
]	O
.	O
LLO	B-Method
+	O
SPCL	B-Method
	
*	O
Replace	O
the	O
learning	B-Method
model	I-Method
,	O
i.e.	O
,	O
SLSVM	B-Method
,	O
in	O
LLO	B-Method
with	O
the	O
proposed	O
SPCL	B-Method
regime	I-Method
.	O
	
section	O
:	O
	
section	O
:	O
Acknowledgments	O
:	O
	
This	O
work	O
was	O
supported	O
in	O
part	O
by	O
the	O
National	O
Science	O
Foundation	O
of	O
China	O
under	O
Grants	O
61522207	O
and	O
61473231	O
,	O
the	O
Doctorate	O
Foundation	O
,	O
and	O
the	O
Excellent	O
Doctorate	O
Foundation	O
of	O
Northwestern	O
Polytechnical	O
University	O
.	O
	
section	O
:	O
	
document	O
:	O
The	O
IBM	B-Task
2016	I-Task
English	I-Task
Conversational	I-Task
Telephone	I-Task
Speech	I-Task
Recognition	I-Task
System	I-Task
	
We	O
describe	O
a	O
collection	O
of	O
acoustic	B-Method
and	I-Method
language	I-Method
modeling	I-Method
techniques	I-Method
that	O
lowered	O
the	O
word	B-Metric
error	I-Metric
rate	I-Metric
of	O
our	O
English	B-Method
conversational	I-Method
telephone	I-Method
LVCSR	I-Method
system	I-Method
to	O
a	O
record	O
6.6	O
%	O
on	O
the	O
Switchboard	B-Material
subset	I-Material
of	O
the	O
Hub5	O
2000	O
evaluation	O
testset	O
.	O
	
On	O
the	O
acoustic	O
side	O
,	O
we	O
use	O
a	O
score	O
fusion	O
of	O
three	O
strong	B-Method
models	I-Method
:	O
recurrent	B-Method
nets	I-Method
with	O
maxout	B-Method
activations	I-Method
,	O
very	O
deep	B-Method
convolutional	I-Method
nets	I-Method
with	O
3x3	B-Method
kernels	I-Method
,	O
and	O
bidirectional	B-Method
long	I-Method
short	I-Method
-	I-Method
term	I-Method
memory	I-Method
nets	I-Method
which	O
operate	O
on	O
FMLLR	O
and	O
i	O
-	O
vector	O
features	O
.	O
	
On	O
the	O
language	B-Task
modeling	I-Task
side	I-Task
,	O
we	O
use	O
an	O
updated	B-Method
model	I-Method
“	O
M	B-Method
”	I-Method
and	O
hierarchical	B-Method
neural	I-Method
network	I-Method
LMs	I-Method
.	O
	
GeorgeSaon	O
,	O
TomSercu	O
,	O
StevenRennieandHong	O
-	O
KwangJ.Kuo	O
IBMT.J.WatsonResearchCenter	O
,	O
YorktownHeights	O
,	O
NY	O
,	O
10598	O
gsaon@us.ibm.com	O
	
©	O
IEEE2004	O
	
SubmittedtoInterspeech2016	O
,	O
pleasedonotredistribute	O
Index	O
Terms	O
:	O
recurrent	B-Method
neural	I-Method
networks	I-Method
,	O
convolutional	B-Method
neural	I-Method
networks	I-Method
,	O
conversational	B-Task
speech	I-Task
recognition	I-Task
	
section	O
:	O
Introduction	O
	
The	O
landscape	O
of	O
neural	B-Method
network	I-Method
acoustic	I-Method
modeling	I-Method
is	O
rapidly	O
evolving	O
.	O
	
Spurred	O
by	O
the	O
success	O
of	O
deep	B-Method
feed	I-Method
-	I-Method
forward	I-Method
neural	I-Method
nets	I-Method
for	O
LVCSR	B-Method
in	O
and	O
inspired	O
by	O
other	O
research	O
areas	O
like	O
image	B-Task
classification	I-Task
and	O
natural	B-Task
language	I-Task
processing	I-Task
,	O
many	O
speech	O
groups	O
have	O
looked	O
at	O
more	O
sophisticated	O
architectures	O
such	O
as	O
deep	B-Method
convolutional	I-Method
nets	I-Method
,	O
deep	O
recurrent	B-Method
nets	I-Method
,	O
time	B-Method
-	I-Method
delay	I-Method
neural	I-Method
nets	I-Method
,	O
and	O
long	B-Method
-	I-Method
short	I-Method
term	I-Method
memory	I-Method
nets	I-Method
.	O
	
The	O
trend	O
is	O
to	O
remove	O
a	O
lot	O
of	O
the	O
complexity	O
and	O
human	O
knowledge	O
that	O
was	O
necessary	O
in	O
the	O
past	O
to	O
build	O
good	O
ASR	B-Method
systems	I-Method
(	O
e.g.	O
speaker	B-Task
adaptation	I-Task
,	O
phonetic	B-Task
context	I-Task
modeling	I-Task
,	O
discriminative	B-Task
feature	I-Task
processing	I-Task
,	O
etc	O
.	O
)	O
and	O
to	O
replace	O
them	O
with	O
a	O
powerful	O
neural	B-Method
network	I-Method
architecture	I-Method
that	O
can	O
be	O
trained	O
agnostically	O
on	O
a	O
lot	O
of	O
data	O
.	O
	
With	O
the	O
advent	O
of	O
numerous	O
neural	B-Method
network	I-Method
toolkits	I-Method
which	O
can	O
implement	O
these	O
sophisticated	O
models	O
out	O
-	O
of	O
-	O
the	O
-	O
box	O
and	O
powerful	O
hardware	O
based	O
on	O
GPUs	B-Method
,	O
the	O
barrier	O
of	O
entry	O
for	O
building	O
high	O
performing	O
ASR	B-Method
systems	I-Method
has	O
been	O
lowered	O
considerably	O
.	O
	
First	O
case	O
in	O
point	O
:	O
front	B-Task
-	I-Task
end	I-Task
processing	I-Task
has	O
been	O
simplified	O
considerably	O
with	O
the	O
use	O
of	O
CNNs	B-Method
which	O
treat	O
the	O
log	B-Method
-	I-Method
mel	I-Method
spectral	I-Method
representation	I-Method
as	O
an	O
image	O
and	O
do	O
n’t	B-Method
require	O
extra	O
processing	B-Method
steps	I-Method
such	O
as	O
PLP	B-Method
cepstra	I-Method
,	O
LDA	B-Method
,	O
FMLLR	B-Method
,	O
fMPE	B-Method
transforms	I-Method
,	O
etc	O
.	O
	
Second	O
case	O
in	O
point	O
:	O
end	B-Method
-	I-Method
to	I-Method
-	I-Method
end	I-Method
ASR	I-Method
systems	I-Method
such	O
as	O
bypass	O
the	O
need	O
of	O
having	O
phonetic	B-Method
context	I-Method
decision	I-Method
trees	I-Method
and	O
HMMs	B-Method
altogether	O
and	O
directly	O
map	O
the	O
sequence	O
of	O
acoustic	O
features	O
to	O
a	O
sequence	O
of	O
characters	O
or	O
context	O
independent	O
phones	O
.	O
	
Third	O
case	O
in	O
point	O
:	O
training	B-Method
algorithms	I-Method
such	O
as	O
connectionist	B-Method
temporal	I-Method
classification	I-Method
	
do	O
	
n’t	B-Method
require	O
an	O
initial	O
alignment	O
of	O
the	O
training	O
data	O
which	O
is	O
typically	O
done	O
with	O
a	O
GMM	B-Method
-	I-Method
based	I-Method
baseline	I-Method
model	I-Method
.	O
	
The	O
above	O
points	O
beg	O
the	O
question	O
whether	O
,	O
in	O
this	O
age	O
of	O
readily	O
available	O
NN	B-Method
toolkits	I-Method
,	O
speech	B-Task
recognition	I-Task
expertise	I-Task
is	O
still	O
necessary	O
or	O
whether	O
one	O
can	O
simply	O
point	O
a	O
neural	B-Method
net	I-Method
to	O
the	O
audio	O
and	O
transcripts	O
,	O
let	O
it	O
train	O
,	O
and	O
obtain	O
a	O
good	O
acoustic	B-Method
model	I-Method
.	O
	
While	O
it	O
is	O
true	O
that	O
,	O
as	O
the	O
amount	O
of	O
training	O
data	O
increases	O
,	O
the	O
need	O
for	O
human	O
ASR	O
expertise	O
is	O
lessened	O
,	O
at	O
the	O
moment	O
the	O
performance	O
of	O
end	O
-	O
to	O
-	O
end	O
systems	O
ultimately	O
remains	O
inferior	O
to	O
that	O
of	O
more	O
traditional	O
,	O
i.e.	O
HMM	B-Method
and	I-Method
decision	I-Method
tree	I-Method
-	I-Method
based	I-Method
,	O
approaches	O
.	O
	
Since	O
the	O
goal	O
of	O
this	O
work	O
is	O
to	O
obtain	O
the	O
lowest	O
possible	O
WER	B-Metric
on	O
the	O
Switchboard	B-Material
dataset	I-Material
regardless	O
of	O
other	O
practical	O
considerations	O
such	O
as	O
speed	O
and	O
/	O
or	O
simplicity	O
,	O
we	O
have	O
focused	O
on	O
the	O
latter	O
approaches	O
.	O
	
The	O
paper	O
is	O
organized	O
as	O
follows	O
:	O
	
in	O
section	O
[	O
reference	O
]	O
we	O
discuss	O
acoustic	B-Task
and	I-Task
language	I-Task
modeling	I-Task
improvements	O
and	O
in	O
section	O
[	O
reference	O
]	O
we	O
summarize	O
our	O
findings	O
.	O
	
section	O
:	O
System	O
improvements	O
	
In	O
this	O
section	O
we	O
describe	O
three	O
different	O
acoustic	B-Method
models	I-Method
that	O
were	O
trained	O
on	O
2000	O
hours	O
of	O
English	O
conversational	O
telephone	O
speech	O
:	O
recurrent	B-Method
nets	I-Method
with	O
maxout	B-Method
activations	I-Method
and	O
annealed	B-Method
dropout	I-Method
,	O
very	O
deep	B-Method
convolutional	I-Method
nets	I-Method
with	O
3	O
3	B-Method
kernels	I-Method
,	O
and	O
bidirectional	B-Method
long	I-Method
short	I-Method
-	I-Method
term	I-Method
memory	I-Method
nets	I-Method
operating	O
on	O
FMLLR	B-Method
and	O
i	O
-	O
vector	O
features	O
.	O
	
All	O
models	O
are	O
used	O
in	O
a	O
hybrid	B-Method
HMM	I-Method
decoding	I-Method
scenario	I-Method
by	O
subtracting	O
the	O
logarithm	O
of	O
the	O
HMM	O
state	O
priors	O
from	O
the	O
log	O
of	O
the	O
softmax	O
output	O
scores	O
.	O
	
The	O
training	O
and	O
test	O
data	O
,	O
frontend	B-Task
processing	I-Task
,	O
speaker	B-Task
adaptation	I-Task
are	O
identical	O
to	O
and	O
their	O
description	O
will	O
be	O
omitted	O
.	O
	
At	O
the	O
end	O
of	O
the	O
section	O
,	O
we	O
also	O
provide	O
an	O
update	O
on	O
our	O
vocabulary	B-Task
and	I-Task
language	I-Task
modeling	I-Task
experiments	O
.	O
	
subsection	O
:	O
Recurrent	B-Method
nets	I-Method
with	O
maxout	B-Method
activations	I-Method
	
We	O
remind	O
the	O
reader	O
that	O
maxout	B-Method
nets	I-Method
generalize	O
ReLu	B-Method
units	I-Method
by	O
employing	O
non	O
-	O
linearities	O
of	O
the	O
form	O
where	O
the	O
subsets	O
of	O
neurons	O
are	O
typically	O
disjoint	O
.	O
	
In	O
we	O
have	O
shown	O
that	O
maxout	B-Method
DNNs	I-Method
and	O
CNNs	B-Method
trained	O
with	O
annealed	B-Method
dropout	I-Method
outperform	O
their	O
sigmoid	B-Method
-	I-Method
based	I-Method
counterparts	I-Method
on	O
both	O
300	O
hours	O
and	O
2000	O
hours	O
training	O
regimes	O
.	O
	
What	O
was	O
missing	O
there	O
was	O
a	O
comparison	O
between	O
maxout	B-Method
and	O
sigmoid	B-Method
for	O
unfolded	B-Task
RNNs	I-Task
.	O
	
The	O
architecture	O
of	O
the	O
maxout	B-Method
RNNs	I-Method
comprises	O
one	O
recurrent	B-Method
layer	I-Method
with	O
2828	O
units	O
projected	O
to	O
1414	O
units	O
via	O
non	O
-	O
overlapping	O
maxout	O
operations	O
.	O
	
This	O
layer	O
is	O
followed	O
by	O
4	O
non	B-Method
-	I-Method
recurrent	I-Method
layers	I-Method
with	O
2828	O
units	O
(	O
also	O
projected	O
to	O
1414	O
)	O
followed	O
by	O
a	O
bottleneck	B-Method
with	O
1024	O
512	O
units	O
and	O
an	O
output	B-Method
layer	I-Method
with	O
32000	O
neurons	O
corresponding	O
to	O
as	O
many	O
context	O
-	O
dependent	O
HMM	O
states	O
.	O
	
The	O
number	O
of	O
neurons	O
for	O
the	O
maxout	O
layers	O
have	O
been	O
chosen	O
such	O
that	O
the	O
weight	O
matrices	O
have	O
roughly	O
the	O
same	O
number	O
of	O
parameters	O
as	O
the	O
baseline	B-Method
sigmoid	I-Method
network	I-Method
which	O
has	O
2048	O
units	O
per	O
hidden	O
layer	O
.	O
	
The	O
recurrent	B-Method
layer	I-Method
is	O
unfolded	O
backwards	O
in	O
time	O
for	O
6	O
time	O
steps	O
and	O
has	O
340	O
-	O
dimensional	O
inputs	O
consisting	O
of	O
6	O
spliced	O
right	O
context	O
40	O
-	O
dimensional	O
FMLLR	O
frames	O
(	O
)	O
to	O
which	O
we	O
append	O
a	O
100	B-Method
-	I-Method
dimensional	I-Method
speaker	I-Method
-	I-Method
based	I-Method
ivector	I-Method
.	O
	
The	O
unfolded	O
maxout	O
RNN	B-Method
architecture	O
is	O
depicted	O
in	O
Figure	O
[	O
reference	O
]	O
.	O
	
The	O
network	O
is	O
trained	O
one	O
hidden	B-Method
layer	I-Method
at	O
a	O
time	O
with	O
discriminative	B-Method
pretraining	I-Method
followed	O
by	O
12	O
epochs	O
of	O
SGD	B-Method
CE	I-Method
training	I-Method
on	O
randomized	O
minibatches	O
of	O
250	O
samples	O
.	O
	
The	O
model	O
is	O
refined	O
with	O
Hessian	B-Method
-	I-Method
free	I-Method
sequence	I-Method
discriminative	I-Method
training	I-Method
using	O
the	O
state	B-Method
-	I-Method
based	I-Method
MBR	I-Method
criterion	I-Method
for	O
10	O
iterations	O
.	O
	
In	O
Table	O
[	O
reference	O
]	O
we	O
report	O
the	O
error	B-Metric
rates	I-Metric
for	O
sigmoid	B-Method
and	I-Method
maxout	I-Method
RNNs	I-Method
on	O
the	O
Switchboard	B-Material
and	O
CallHome	O
subsets	O
of	O
Hub5’00	B-Material
.	O
	
The	O
decodings	B-Task
are	O
done	O
with	O
a	O
small	O
vocabulary	O
of	O
30	O
K	O
words	O
and	O
a	O
small	O
4	B-Method
-	I-Method
gram	I-Method
language	I-Method
model	I-Method
with	O
4	O
M	B-Method
n	I-Method
-	I-Method
grams	I-Method
.	O
	
Note	O
that	O
the	O
sigmoid	B-Method
RNNs	I-Method
have	O
better	O
error	B-Metric
rates	I-Metric
than	O
what	O
was	O
reported	O
in	O
because	O
they	O
have	O
been	O
retrained	O
after	O
the	O
data	O
has	O
been	O
realigned	O
with	O
the	O
best	O
joint	O
RNN	B-Method
/	O
CNN	O
model	O
.	O
	
We	O
observe	O
that	O
the	O
maxout	B-Method
RNNs	I-Method
are	O
consistently	O
better	O
and	O
that	O
,	O
by	O
themselves	O
,	O
they	O
achieve	O
a	O
similar	O
WER	B-Metric
as	O
our	O
previous	O
best	O
model	O
which	O
was	O
the	O
joint	O
RNN	B-Method
/	O
CNN	O
with	O
sigmoid	B-Method
activations	I-Method
.	O
	
subsection	O
:	O
Very	O
deep	B-Method
convolutional	I-Method
networks	I-Method
	
Very	O
deep	O
CNNs	B-Method
with	O
small	B-Method
kernels	I-Method
have	O
recently	O
been	O
shown	O
to	O
achieve	O
very	O
strong	O
performance	O
as	O
acoustic	B-Method
models	I-Method
in	O
hybrid	B-Task
NN	I-Task
-	I-Task
HMM	I-Task
speech	I-Task
recognition	I-Task
systems	I-Task
.	O
	
Results	O
were	O
provided	O
after	O
cross	B-Method
-	I-Method
entropy	I-Method
training	I-Method
on	O
the	O
300	O
hours	O
switchboard	B-Material
-	O
1	O
dataset	O
in	O
,	O
and	O
results	O
from	O
sequence	B-Method
training	I-Method
on	O
both	O
switchboard	B-Material
-	O
1	O
and	O
the	O
2000	O
hours	O
switchboard	B-Material
+	O
Fisher	O
dataset	O
are	O
in	O
.	O
	
The	O
very	O
deep	B-Method
convolutional	I-Method
networks	I-Method
are	O
inspired	O
by	O
the	O
“	O
VGG	B-Method
Net	I-Method
”	I-Method
architecture	I-Method
introduced	O
in	O
for	O
the	O
2014	O
ImageNet	B-Task
classification	I-Task
challenge	I-Task
,	O
with	O
the	O
central	O
idea	O
to	O
replace	O
large	O
convolutional	O
kernels	O
by	O
small	O
kernels	O
.	O
	
By	O
stacking	O
many	O
of	O
these	O
convolutional	B-Method
layers	I-Method
with	O
ReLU	B-Method
nonlinearities	I-Method
before	O
pooling	B-Method
layers	I-Method
,	O
the	O
same	O
receptive	O
field	O
is	O
created	O
with	O
less	O
parameters	O
and	O
more	O
nonlinearity	O
.	O
	
Figure	O
[	O
reference	O
]	O
shows	O
the	O
design	O
of	O
the	O
networks	O
.	O
	
Note	O
that	O
as	O
we	O
go	O
deeper	O
in	O
the	O
network	O
,	O
the	O
time	O
and	O
frequency	O
resolution	O
is	O
reduced	O
through	O
pooling	B-Method
only	O
,	O
while	O
the	O
convolutions	B-Method
are	O
zero	O
-	O
padded	O
as	O
to	O
not	O
reduce	O
the	O
size	O
of	O
the	O
feature	O
maps	O
.	O
	
We	O
increase	O
the	O
number	O
of	O
feature	O
maps	O
gradually	O
from	O
64	O
to	O
512	O
(	O
indicated	O
by	O
the	O
different	O
colors	O
)	O
.	O
	
We	O
pool	O
right	O
before	O
the	O
layer	O
that	O
increases	O
the	O
number	O
of	O
feature	O
maps	O
.	O
	
Note	O
that	O
the	O
indication	O
of	O
feature	O
map	O
size	O
on	O
the	O
right	O
only	O
applies	O
to	O
the	O
rightmost	O
2	O
designs	O
.	O
	
In	O
contrast	O
,	O
the	O
classical	O
CNN	B-Method
architecture	I-Method
has	O
only	O
two	O
layers	O
,	O
goes	O
to	O
512	O
feature	O
maps	O
directly	O
,	O
and	O
uses	O
a	O
large	O
kernel	B-Method
on	O
the	O
first	O
layer	O
.	O
	
Our	O
10	B-Method
-	I-Method
layer	I-Method
CNN	I-Method
has	O
about	O
the	O
same	O
number	O
of	O
parameters	O
as	O
the	O
classical	B-Method
CNN	I-Method
,	O
converges	O
in	O
5	O
times	O
fewer	O
epochs	O
,	O
but	O
is	O
computationally	O
more	O
expensive	O
.	O
	
Results	O
for	O
3	O
variations	O
of	O
the	O
10	B-Method
-	I-Method
layer	I-Method
CNN	I-Method
are	O
in	O
table	O
[	O
reference	O
]	O
.	O
	
For	O
model	B-Task
combination	I-Task
,	O
we	O
use	O
the	O
version	O
with	O
pooling	B-Method
,	O
which	O
is	O
the	O
exact	O
same	O
model	O
without	O
modifications	O
from	O
the	O
original	O
paper	O
.	O
	
Our	O
implementation	O
was	O
done	O
in	O
Torch	O
.	O
	
We	O
adopt	O
the	O
balanced	B-Method
sampling	I-Method
from	O
,	O
by	O
sampling	O
from	O
context	O
dependent	O
state	O
with	O
probability	O
.	O
	
We	O
keep	O
throughout	O
the	O
experiments	O
during	O
cross	B-Method
-	I-Method
entropy	I-Method
training	I-Method
.	O
	
During	O
CE	B-Task
training	I-Task
,	O
we	O
optimize	O
with	O
simple	O
SGD	B-Method
or	O
NAG	B-Method
,	O
during	O
ST	B-Method
we	O
found	O
NAG	B-Method
to	O
be	O
superior	O
to	O
SGD	B-Method
.	O
	
We	O
regularize	O
the	O
stochastic	O
sequence	B-Method
training	I-Method
by	O
adding	O
the	O
gradient	O
of	O
cross	B-Metric
-	I-Metric
entropy	I-Metric
loss	I-Metric
,	O
as	O
proposed	O
in	O
.	O
	
subsection	O
:	O
Bidirectional	B-Method
LSTMs	I-Method
	
Given	O
the	O
recent	O
popularity	O
of	O
LSTMs	B-Method
for	O
acoustic	B-Task
modeling	I-Task
,	O
we	O
have	O
experimented	O
with	O
such	O
models	O
on	O
the	O
Switchboard	B-Material
task	I-Material
using	O
the	O
Torch	B-Method
toolkit	I-Method
.	O
	
We	O
have	O
looked	O
at	O
the	O
effect	O
of	O
the	O
input	O
features	O
on	O
LSTM	B-Task
performance	O
,	O
the	O
number	O
of	O
layers	O
and	O
whether	O
start	O
states	O
for	O
the	O
recurrent	B-Method
layers	I-Method
should	O
be	O
reset	O
or	O
carried	O
over	O
.	O
	
We	O
use	O
bidirectional	B-Method
LSTMs	I-Method
that	O
are	O
trained	O
on	O
non	O
-	O
overlapping	O
subsequences	O
of	O
20	O
frames	O
.	O
	
The	O
subsequences	O
coming	O
from	O
the	O
same	O
utterance	O
are	O
contiguous	O
so	O
that	O
the	O
left	O
-	O
to	O
-	O
right	O
final	O
states	O
for	O
the	O
current	O
subsequence	O
can	O
be	O
copied	O
to	O
the	O
left	O
-	O
to	O
-	O
right	O
start	O
states	O
for	O
the	O
next	O
subsequence	O
(	O
i.e.	O
carried	O
over	O
)	O
.	O
	
For	O
processing	B-Metric
speed	I-Metric
and	O
in	O
order	O
to	O
get	O
good	O
gradient	B-Task
estimates	I-Task
,	O
we	O
group	O
subsequences	O
from	O
multiple	O
utterances	O
into	O
minibatches	O
of	O
size	O
256	O
.	O
	
Regardless	O
of	O
the	O
number	O
of	O
LSTM	B-Method
layers	I-Method
,	O
all	O
models	O
use	O
a	O
linear	B-Method
bottleneck	I-Method
of	O
size	O
256	O
before	O
the	O
softmax	O
output	O
layer	O
(	O
of	O
size	O
32000	O
)	O
.	O
	
In	O
one	O
experiment	O
,	O
we	O
compare	O
the	O
effect	O
of	O
input	O
features	O
on	O
model	O
performance	O
.	O
	
The	O
baseline	O
models	O
are	O
trained	O
on	O
40	O
-	O
dimensional	O
FMLLR	O
+	O
100	O
-	O
dimensional	O
ivector	O
frames	O
and	O
have	O
1024	O
(	O
or	O
512	O
)	O
LSTM	B-Method
units	I-Method
per	O
layer	O
and	O
per	O
direction	O
(	O
left	O
-	O
to	O
-	O
right	O
and	O
right	O
-	O
to	O
-	O
left	O
)	O
.	O
	
The	O
forward	O
and	O
backward	O
activations	O
from	O
the	O
previous	O
LSTM	B-Method
layer	I-Method
are	O
concatenated	O
and	O
fed	O
into	O
the	O
next	O
LSTM	B-Method
layer	I-Method
.	O
	
The	O
contrast	B-Method
model	I-Method
is	O
a	O
single	B-Method
layer	I-Method
bidirectional	I-Method
LSTM	I-Method
trained	O
on	O
128	O
-	O
dim	O
features	O
obtained	O
by	O
performing	O
PCA	B-Method
on	O
512	O
-	O
dimensional	O
bottleneck	O
features	O
.	O
	
The	O
features	O
are	O
obtained	O
from	O
a	O
6	B-Method
-	I-Method
layer	I-Method
DNN	I-Method
cross	I-Method
entropy	I-Method
trained	O
on	O
blocks	O
of	O
11	O
consecutive	O
FMLLR	O
frames	O
and	O
100	O
-	O
dimensional	O
i	O
-	O
vectors	O
.	O
	
In	O
Table	O
[	O
reference	O
]	O
,	O
we	O
report	O
recognition	B-Task
results	O
on	O
Hub5’00	B-Material
for	O
these	O
four	O
models	O
trained	O
with	O
15	O
passes	O
of	O
cross	B-Method
-	I-Method
entropy	I-Method
SGD	I-Method
on	O
the	O
300	O
hour	O
(	O
SWB	B-Material
-	O
1	O
)	O
subset	O
.	O
	
Due	O
to	O
a	O
bug	O
that	O
affected	O
our	O
earlier	O
multi	B-Method
-	I-Method
layer	I-Method
LSTM	I-Method
results	O
,	O
we	O
decided	O
to	O
go	O
ahead	O
with	O
single	B-Method
layer	I-Method
bidirectional	I-Method
LSTMs	I-Method
on	O
bottleneck	O
features	O
on	O
the	O
full	O
2000	O
hour	O
training	O
set	O
.	O
	
We	O
also	O
experimented	O
with	O
how	O
to	O
deal	O
with	O
the	O
start	O
states	O
at	O
the	O
beginning	O
of	O
the	O
left	O
-	O
to	O
-	O
right	O
pass	O
.	O
	
One	O
option	O
is	O
to	O
carry	O
them	O
over	O
from	O
the	O
previous	O
subsequence	O
and	O
the	O
other	O
one	O
is	O
to	O
reset	O
the	O
start	O
states	O
at	O
the	O
beginning	O
of	O
each	O
subsequence	O
.	O
	
In	O
Figure	O
[	O
reference	O
]	O
we	O
compare	O
the	O
cross	B-Metric
-	I-Metric
entropy	I-Metric
loss	I-Metric
on	O
held	O
-	O
out	O
data	O
between	O
these	O
two	O
models	O
.	O
	
As	O
can	O
be	O
seen	O
,	O
the	O
LSTM	B-Method
model	I-Method
with	O
carried	O
over	O
start	O
states	O
is	O
much	O
better	O
at	O
predicting	O
the	O
correct	O
HMM	O
state	O
.	O
	
However	O
,	O
when	O
comparing	O
word	B-Metric
error	I-Metric
rates	I-Metric
in	O
Table	O
[	O
reference	O
]	O
,	O
the	O
LSTM	B-Method
with	O
start	O
states	O
that	O
are	O
reset	O
has	O
a	O
better	O
performance	O
.	O
	
We	O
surmise	O
that	O
this	O
is	O
because	O
the	O
increased	O
memory	O
of	O
the	O
LSTM	B-Method
with	O
carried	O
over	O
start	O
states	O
is	O
in	O
conflict	O
with	O
the	O
state	O
sequence	O
constraints	O
imposed	O
by	O
the	O
HMM	B-Method
topology	I-Method
and	O
the	O
language	B-Method
model	I-Method
.	O
	
Additionally	O
,	O
we	O
show	O
the	O
WERs	B-Metric
of	O
the	O
DNN	B-Method
used	O
for	O
the	O
bottleneck	O
features	O
and	O
of	O
a	O
4	B-Method
-	I-Method
layer	I-Method
512	I-Method
unit	I-Method
LSTM	I-Method
.	O
	
We	O
observe	O
that	O
the	O
4	B-Method
layer	I-Method
LSTM	I-Method
is	O
significantly	O
better	O
than	O
the	O
DNN	B-Method
and	O
the	O
two	O
single	B-Method
layer	I-Method
LSTMs	I-Method
trained	O
on	O
bottleneck	O
features	O
.	O
	
subsection	O
:	O
Model	B-Method
combination	I-Method
	
In	O
Table	O
[	O
reference	O
]	O
we	O
report	O
the	O
performance	O
of	O
the	O
individual	O
models	O
(	O
RNN	B-Method
,	O
VGG	B-Method
and	I-Method
4	I-Method
-	I-Method
layer	I-Method
LSTM	I-Method
)	O
described	O
in	O
the	O
previous	O
subsections	O
as	O
well	O
as	O
the	O
results	O
after	O
frame	B-Method
-	I-Method
level	I-Method
score	I-Method
fusion	I-Method
.	O
	
All	O
decodings	B-Task
are	O
done	O
with	O
a	O
30	O
K	O
word	O
vocabulary	O
and	O
a	O
small	O
4	B-Method
-	I-Method
gram	I-Method
language	I-Method
model	I-Method
with	O
4	O
M	B-Method
n	I-Method
-	I-Method
grams	I-Method
.	O
	
We	O
note	O
that	O
RNNs	B-Method
and	O
VGG	B-Method
nets	I-Method
exhibit	O
similar	O
performance	O
and	O
have	O
a	O
strong	O
complementarity	O
which	O
improves	O
the	O
WER	B-Metric
by	O
0.6	O
%	O
and	O
0.9	O
%	O
on	O
SWB	B-Material
and	O
CH	B-Metric
,	O
respectively	O
.	O
	
subsection	O
:	O
Language	B-Task
modeling	I-Task
experiments	O
	
Our	O
language	B-Method
modeling	I-Method
strategy	I-Method
largely	O
parallels	O
that	O
described	O
in	O
.	O
	
For	O
completeness	O
,	O
we	O
will	O
repeat	O
some	O
of	O
the	O
details	O
here	O
.	O
	
The	O
main	O
difference	O
is	O
an	O
increase	O
in	O
the	O
vocabulary	B-Metric
size	I-Metric
from	O
30	O
K	O
words	O
to	O
85	O
K	O
words	O
.	O
	
When	O
comparing	O
acoustic	B-Method
models	I-Method
in	O
previous	O
sections	O
,	O
we	O
used	O
a	O
relatively	O
small	O
legacy	O
language	B-Method
model	I-Method
used	O
in	O
previous	O
publications	O
:	O
a	O
4	O
M	B-Method
n	I-Method
-	I-Method
gram	I-Method
(	I-Method
n=4	I-Method
)	I-Method
language	I-Method
model	I-Method
with	O
a	O
vocabulary	O
of	O
30.5	O
K	O
words	O
.	O
	
We	O
wanted	O
to	O
increase	O
the	O
language	O
model	O
coverage	O
in	O
a	O
manner	O
that	O
others	O
can	O
replicate	O
.	O
	
To	O
this	O
end	O
,	O
we	O
increased	O
the	O
vocabulary	B-Metric
size	I-Metric
from	O
30.5	O
K	O
words	O
to	O
85	O
K	O
words	O
by	O
adding	O
the	O
vocabulary	O
of	O
the	O
publicly	O
available	O
Broadcast	O
News	O
task	O
.	O
	
We	O
also	O
added	O
to	O
the	O
LM	O
publicly	O
available	O
text	O
data	O
from	O
LDC	O
,	O
including	O
Switchboard	B-Material
,	O
Fisher	O
,	O
Gigaword	O
,	O
and	O
Broadcast	O
News	O
and	O
Conversations	O
.	O
	
The	O
most	O
relevant	O
data	O
are	O
the	O
transcripts	O
of	O
the	O
1975	O
hour	O
audio	O
data	O
used	O
to	O
train	O
the	O
acoustic	B-Method
model	I-Method
,	O
consisting	O
of	O
about	O
24	O
M	O
words	O
.	O
	
For	O
each	O
corpus	O
we	O
trained	O
a	O
4	B-Method
-	I-Method
gram	I-Method
model	I-Method
with	O
modified	B-Method
Kneser	I-Method
-	I-Method
Ney	I-Method
smoothing	I-Method
.	O
	
The	O
component	B-Method
LMs	I-Method
are	O
linearly	O
interpolated	O
with	O
weights	O
chosen	O
to	O
optimize	O
perplexity	B-Metric
on	O
a	O
held	O
-	O
out	O
set	O
.	O
	
Entropy	B-Method
pruning	I-Method
was	O
applied	O
,	O
resulting	O
in	O
a	O
single	O
4	B-Method
-	I-Method
gram	I-Method
LM	I-Method
consisting	O
of	O
36	O
M	B-Method
n	I-Method
-	I-Method
grams	I-Method
.	O
	
This	O
new	O
n	B-Method
-	I-Method
gram	I-Method
LM	I-Method
was	O
used	O
together	O
with	O
our	O
best	O
acoustic	B-Method
model	I-Method
to	O
decode	O
and	O
generate	O
word	O
lattices	O
for	O
LM	B-Task
rescoring	I-Task
experiments	I-Task
.	O
	
The	O
first	O
two	O
lines	O
of	O
Table	O
[	O
reference	O
]	O
show	O
the	O
improvement	O
using	O
this	O
larger	O
n	B-Method
-	I-Method
gram	I-Method
LM	I-Method
with	O
larger	O
vocabulary	O
trained	O
on	O
more	O
data	O
.	O
	
The	O
WER	B-Metric
improved	O
by	O
1.0	O
%	O
for	O
SWB	B-Material
.	O
	
Part	O
of	O
this	O
improvement	O
(	O
0.1	O
-	O
0.2	O
%	O
)	O
was	O
due	O
to	O
also	O
using	O
a	O
larger	O
beam	O
for	O
decoding	B-Task
and	O
a	O
change	O
in	O
vocabulary	B-Task
tokenization	I-Task
.	O
	
We	O
used	O
two	O
types	O
of	O
LMs	B-Method
for	O
LM	B-Task
rescoring	I-Task
:	O
model	B-Method
M	I-Method
,	O
a	O
class	B-Method
-	I-Method
based	I-Method
exponential	I-Method
model	I-Method
and	O
feed	B-Method
-	I-Method
forward	I-Method
neural	I-Method
network	I-Method
LM	I-Method
(	I-Method
NNLM	I-Method
)	I-Method
.	O
	
We	O
built	O
a	O
model	B-Method
M	I-Method
LM	I-Method
on	O
each	O
corpus	O
and	O
interpolated	O
the	O
models	O
,	O
together	O
with	O
the	O
36	O
M	B-Method
n	I-Method
-	I-Method
gram	I-Method
LM	I-Method
.	O
	
As	O
shown	O
in	O
Table	O
[	O
reference	O
]	O
,	O
using	O
model	B-Method
M	I-Method
results	O
in	O
an	O
improvement	O
of	O
0.6	O
%	O
on	O
SWB	B-Material
.	O
	
We	O
built	O
two	O
NNLMs	B-Method
for	O
interpolation	B-Task
.	O
	
One	O
was	O
trained	O
on	O
just	O
the	O
most	O
relevant	O
data	O
:	O
the	O
24	O
M	O
word	O
corpus	O
(	O
Switchboard	B-Material
/	O
Fisher	O
/	O
CallHome	O
acoustic	O
transcripts	O
)	O
.	O
	
Another	O
was	O
trained	O
on	O
a	O
560	O
M	O
word	O
subset	O
of	O
the	O
LM	O
training	O
data	O
:	O
in	O
order	O
to	O
speed	O
up	O
training	B-Task
for	O
this	O
larger	O
set	O
,	O
we	O
employed	O
a	O
hierarchical	B-Method
NNLM	I-Method
approximation	I-Method
.	O
	
Table	O
[	O
reference	O
]	O
shows	O
that	O
the	O
NNLMs	B-Method
provided	O
an	O
additional	O
0.4	O
%	O
improvement	O
over	O
the	O
model	O
M	O
result	O
on	O
SWB	B-Material
.	O
	
Compared	O
with	O
the	O
n	B-Method
-	I-Method
gram	I-Method
LM	I-Method
baseline	I-Method
,	O
LM	B-Method
rescoring	I-Method
yielded	O
a	O
total	O
improvement	O
of	O
1.0	O
%	O
on	O
SWB	B-Material
(	O
7.6	O
%	O
to	O
6.6	O
%	O
)	O
and	O
1.5	O
%	O
on	O
CH	B-Task
(	O
13.7	O
%	O
to	O
12.2	O
%	O
)	O
.	O
	
section	O
:	O
Conclusion	O
	
In	O
our	O
previous	O
Switchboard	B-Method
system	I-Method
paper	O
we	O
have	O
observed	O
a	O
good	O
complementarity	O
between	O
recurrent	B-Method
nets	I-Method
and	O
convolutional	B-Method
nets	I-Method
and	O
their	O
combination	O
led	O
to	O
significant	O
accuracy	B-Metric
gains	O
.	O
	
In	O
this	O
paper	O
we	O
have	O
presented	O
an	O
improved	O
unfolded	O
RNN	B-Method
(	O
with	O
maxout	B-Method
instead	O
of	O
sigmoid	O
activations	O
)	O
and	O
a	O
stronger	O
CNN	B-Method
obtained	O
by	O
adding	O
more	O
convolutional	B-Method
layers	I-Method
with	O
smaller	O
kernels	O
and	O
ReLu	O
nonlinearities	O
.	O
	
These	O
improved	O
models	O
still	O
have	O
good	O
complementarity	O
and	O
their	O
frame	B-Method
-	I-Method
level	I-Method
score	I-Method
combination	I-Method
in	O
conjunction	O
with	O
a	O
multi	B-Method
-	I-Method
layer	I-Method
LSTM	I-Method
leads	O
to	O
a	O
0.4%	O
-	O
0.7	O
%	O
decrease	O
in	O
WER	B-Metric
over	O
the	O
LSTM	B-Method
.	O
	
Multi	B-Method
-	I-Method
layer	I-Method
LSTMs	I-Method
were	O
the	O
strongest	O
performing	O
model	O
followed	O
closely	O
by	O
the	O
RNN	B-Method
and	O
VGG	B-Method
nets	I-Method
.	O
	
We	O
also	O
believe	O
that	O
LSTMs	B-Method
have	O
more	O
potential	O
for	O
direct	B-Task
sequence	I-Task
-	I-Task
to	I-Task
-	I-Task
sequence	I-Task
modeling	I-Task
and	O
we	O
are	O
actively	O
exploring	O
this	O
area	O
of	O
research	O
.	O
	
On	O
the	O
language	B-Task
modeling	I-Task
side	I-Task
,	O
we	O
have	O
increased	O
our	O
vocabulary	O
from	O
30	O
K	O
to	O
85	O
K	O
words	O
and	O
updated	O
our	O
component	B-Method
LMs	I-Method
.	O
	
At	O
the	O
moment	O
,	O
we	O
are	O
less	O
than	O
3	O
%	O
away	O
from	O
achieving	O
human	O
performance	O
on	O
the	O
Switchboard	B-Material
data	I-Material
(	O
estimated	O
to	O
be	O
around	O
4	O
%	O
)	O
.	O
	
Unfortunately	O
,	O
it	O
looks	O
like	O
future	O
improvements	O
on	O
this	O
task	O
will	O
be	O
considerably	O
harder	O
to	O
get	O
and	O
will	O
probably	O
require	O
a	O
breakthrough	O
in	O
direct	B-Task
sequence	I-Task
-	I-Task
to	I-Task
-	I-Task
sequence	I-Task
modeling	I-Task
and	O
a	O
significant	O
increase	O
in	O
training	O
data	O
.	O
	
section	O
:	O
Acknowledgment	O
	
The	O
authors	O
wish	O
to	O
thank	O
E.	O
Marcheret	O
,	O
J.	O
Cui	O
and	O
M.	O
Nussbaum	O
-	O
Thom	O
for	O
useful	O
suggestions	O
about	O
LSTMs	B-Method
.	O
	
bibliography	O
:	O
References	O
	
document	O
:	O
Rethinking	O
the	O
Inception	B-Method
Architecture	I-Method
for	O
Computer	B-Task
Vision	I-Task
	
Convolutional	B-Method
networks	I-Method
are	O
at	O
the	O
core	O
of	O
most	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
computer	B-Method
vision	I-Method
solutions	I-Method
for	O
a	O
wide	O
variety	O
of	O
tasks	O
.	O
	
Since	O
2014	O
very	O
deep	B-Method
convolutional	I-Method
networks	I-Method
started	O
to	O
become	O
mainstream	O
,	O
yielding	O
substantial	O
gains	O
in	O
various	O
benchmarks	O
.	O
	
Although	O
increased	O
model	B-Metric
size	I-Metric
and	O
computational	B-Metric
cost	I-Metric
tend	O
to	O
translate	O
to	O
immediate	O
quality	O
gains	O
for	O
most	O
tasks	O
(	O
as	O
long	O
as	O
enough	O
labeled	O
data	O
is	O
provided	O
for	O
training	O
)	O
,	O
computational	B-Metric
efficiency	I-Metric
and	O
low	B-Metric
parameter	I-Metric
count	I-Metric
are	O
still	O
enabling	O
factors	O
for	O
various	O
use	O
cases	O
such	O
as	O
mobile	B-Task
vision	I-Task
and	O
big	B-Task
-	I-Task
data	I-Task
scenarios	I-Task
.	O
	
Here	O
we	O
are	O
exploring	O
ways	O
to	O
scale	O
up	O
networks	O
in	O
ways	O
that	O
aim	O
at	O
utilizing	O
the	O
added	O
computation	O
as	O
efficiently	O
as	O
possible	O
by	O
suitably	O
factorized	B-Method
convolutions	I-Method
and	O
aggressive	B-Method
regularization	I-Method
.	O
	
We	O
benchmark	O
our	O
methods	O
on	O
the	O
ILSVRC	B-Material
2012	I-Material
classification	I-Material
challenge	I-Material
validation	I-Material
set	I-Material
demonstrate	O
substantial	O
gains	O
over	O
the	O
state	O
of	O
the	O
art	O
:	O
top	B-Metric
-	I-Metric
and	O
top	B-Metric
-	I-Metric
error	I-Metric
for	O
single	B-Task
frame	I-Task
evaluation	I-Task
using	O
a	O
network	O
with	O
a	O
computational	B-Metric
cost	I-Metric
of	O
billion	O
multiply	O
-	O
adds	O
per	O
inference	B-Task
and	O
with	O
using	O
less	O
than	O
25	O
million	O
parameters	O
.	O
	
With	O
an	O
ensemble	B-Method
of	I-Method
models	I-Method
and	O
multi	B-Task
-	I-Task
crop	I-Task
evaluation	I-Task
,	O
we	O
report	O
top	B-Metric
-	I-Metric
error	I-Metric
and	O
top	B-Metric
-	I-Metric
error	I-Metric
.	O
	
section	O
:	O
Introduction	O
	
Since	O
the	O
2012	B-Material
ImageNet	I-Material
competition	O
winning	O
entry	O
by	O
Krizhevsky	O
et	O
al	O
,	O
their	O
network	O
“	O
AlexNet	B-Method
”	I-Method
has	O
been	O
successfully	O
applied	O
to	O
a	O
larger	O
variety	O
of	O
computer	B-Task
vision	I-Task
tasks	I-Task
,	O
for	O
example	O
to	O
object	B-Task
-	I-Task
detection	I-Task
,	O
segmentation	B-Task
,	O
human	B-Task
pose	I-Task
estimation	I-Task
,	O
video	B-Task
classification	I-Task
,	O
object	B-Task
tracking	I-Task
,	O
and	O
superresolution	B-Task
.	O
	
These	O
successes	O
spurred	O
a	O
new	O
line	O
of	O
research	O
that	O
focused	O
on	O
finding	O
higher	O
performing	O
convolutional	B-Method
neural	I-Method
networks	I-Method
.	O
	
Starting	O
in	O
2014	O
,	O
the	O
quality	O
of	O
network	B-Method
architectures	I-Method
significantly	O
improved	O
by	O
utilizing	O
deeper	O
and	O
wider	O
networks	O
.	O
	
VGGNet	B-Method
and	O
GoogLeNet	B-Method
yielded	O
similarly	O
high	O
performance	O
in	O
the	O
2014	O
ILSVRC	B-Task
classification	I-Task
challenge	I-Task
.	O
	
One	O
interesting	O
observation	O
was	O
that	O
gains	O
in	O
the	O
classification	B-Metric
performance	I-Metric
tend	O
to	O
transfer	O
to	O
significant	O
quality	O
gains	O
in	O
a	O
wide	O
variety	O
of	O
application	O
domains	O
.	O
	
This	O
means	O
that	O
architectural	O
improvements	O
in	O
deep	B-Method
convolutional	I-Method
architecture	I-Method
can	O
be	O
utilized	O
for	O
improving	O
performance	O
for	O
most	O
other	O
computer	B-Task
vision	I-Task
tasks	I-Task
that	O
are	O
increasingly	O
reliant	O
on	O
high	O
quality	O
,	O
learned	O
visual	O
features	O
.	O
	
Also	O
,	O
improvements	O
in	O
the	O
network	B-Metric
quality	I-Metric
resulted	O
in	O
new	O
application	O
domains	O
for	O
convolutional	B-Method
networks	I-Method
in	O
cases	O
where	O
AlexNet	O
features	O
could	O
not	O
compete	O
with	O
hand	O
engineered	O
,	O
crafted	O
solutions	O
,	O
e.g.	O
proposal	B-Task
generation	I-Task
in	O
detection	B-Task
.	O
	
Although	O
VGGNet	B-Method
has	O
the	O
compelling	O
feature	O
of	O
architectural	O
simplicity	O
,	O
this	O
comes	O
at	O
a	O
high	O
cost	O
:	O
evaluating	O
the	O
network	O
requires	O
a	O
lot	O
of	O
computation	O
.	O
	
On	O
the	O
other	O
hand	O
,	O
the	O
Inception	B-Method
architecture	I-Method
of	O
GoogLeNet	B-Method
was	O
also	O
designed	O
to	O
perform	O
well	O
even	O
under	O
strict	O
constraints	O
on	O
memory	O
and	O
computational	O
budget	O
.	O
	
For	O
example	O
,	O
GoogleNet	B-Method
employed	O
only	O
5	O
million	O
parameters	O
,	O
which	O
represented	O
a	O
reduction	O
with	O
respect	O
to	O
its	O
predecessor	O
AlexNet	B-Method
,	O
which	O
used	O
million	O
parameters	O
.	O
	
Furthermore	O
,	O
VGGNet	B-Method
employed	O
about	O
3x	O
more	O
parameters	O
than	O
AlexNet	B-Method
.	O
	
The	O
computational	B-Metric
cost	I-Metric
of	O
Inception	B-Method
is	O
also	O
much	O
lower	O
than	O
VGGNet	B-Method
or	O
its	O
higher	O
performing	O
successors	O
.	O
	
This	O
has	O
made	O
it	O
feasible	O
to	O
utilize	O
Inception	B-Method
networks	I-Method
in	O
big	B-Task
-	I-Task
data	I-Task
scenarios	I-Task
,	O
,	O
where	O
huge	O
amount	O
of	O
data	O
needed	O
to	O
be	O
processed	O
at	O
reasonable	O
cost	O
or	O
scenarios	O
where	O
memory	O
or	O
computational	O
capacity	O
is	O
inherently	O
limited	O
,	O
for	O
example	O
in	O
mobile	B-Task
vision	I-Task
settings	I-Task
.	O
	
It	O
is	O
certainly	O
possible	O
to	O
mitigate	O
parts	O
of	O
these	O
issues	O
by	O
applying	O
specialized	B-Method
solutions	I-Method
to	O
target	O
memory	O
use	O
,	O
or	O
by	O
optimizing	O
the	O
execution	O
of	O
certain	O
operations	O
via	O
computational	B-Method
tricks	I-Method
.	O
	
However	O
,	O
these	O
methods	O
add	O
extra	O
complexity	O
.	O
	
Furthermore	O
,	O
these	O
methods	O
could	O
be	O
applied	O
to	O
optimize	O
the	O
Inception	B-Method
architecture	I-Method
as	O
well	O
,	O
widening	O
the	O
efficiency	O
gap	O
again	O
.	O
	
Still	O
,	O
the	O
complexity	O
of	O
the	O
Inception	B-Method
architecture	I-Method
makes	O
it	O
more	O
difficult	O
to	O
make	O
changes	O
to	O
the	O
network	O
.	O
	
If	O
the	O
architecture	O
is	O
scaled	O
up	O
naively	O
,	O
large	O
parts	O
of	O
the	O
computational	B-Metric
gains	I-Metric
can	O
be	O
immediately	O
lost	O
.	O
	
Also	O
,	O
does	O
not	O
provide	O
a	O
clear	O
description	O
about	O
the	O
contributing	O
factors	O
that	O
lead	O
to	O
the	O
various	O
design	O
decisions	O
of	O
the	O
GoogLeNet	B-Method
architecture	I-Method
.	O
	
This	O
makes	O
it	O
much	O
harder	O
to	O
adapt	O
it	O
to	O
new	O
use	O
-	O
cases	O
while	O
maintaining	O
its	O
efficiency	O
.	O
	
For	O
example	O
,	O
if	O
it	O
is	O
deemed	O
necessary	O
to	O
increase	O
the	O
capacity	O
of	O
some	O
Inception	B-Method
-	I-Method
style	I-Method
model	I-Method
,	O
the	O
simple	O
transformation	O
of	O
just	O
doubling	O
the	O
number	O
of	O
all	O
filter	B-Method
bank	I-Method
sizes	I-Method
will	O
lead	O
to	O
a	O
4x	O
increase	O
in	O
both	O
computational	B-Metric
cost	I-Metric
and	O
number	O
of	O
parameters	O
.	O
	
This	O
might	O
prove	O
prohibitive	O
or	O
unreasonable	O
in	O
a	O
lot	O
of	O
practical	O
scenarios	O
,	O
especially	O
if	O
the	O
associated	O
gains	O
are	O
modest	O
.	O
	
In	O
this	O
paper	O
,	O
we	O
start	O
with	O
describing	O
a	O
few	O
general	O
principles	O
and	O
optimization	B-Method
ideas	I-Method
that	O
that	O
proved	O
to	O
be	O
useful	O
for	O
scaling	O
up	O
convolution	B-Method
networks	I-Method
in	O
efficient	O
ways	O
.	O
	
Although	O
our	O
principles	O
are	O
not	O
limited	O
to	O
Inception	B-Method
-	I-Method
type	I-Method
networks	I-Method
,	O
they	O
are	O
easier	O
to	O
observe	O
in	O
that	O
context	O
as	O
the	O
generic	O
structure	O
of	O
the	O
Inception	B-Method
style	I-Method
building	I-Method
blocks	I-Method
is	O
flexible	O
enough	O
to	O
incorporate	O
those	O
constraints	O
naturally	O
.	O
	
This	O
is	O
enabled	O
by	O
the	O
generous	O
use	O
of	O
dimensional	B-Method
reduction	I-Method
and	O
parallel	O
structures	O
of	O
the	O
Inception	B-Method
modules	I-Method
which	O
allows	O
for	O
mitigating	O
the	O
impact	O
of	O
structural	O
changes	O
on	O
nearby	O
components	O
.	O
	
Still	O
,	O
one	O
needs	O
to	O
be	O
cautious	O
about	O
doing	O
so	O
,	O
as	O
some	O
guiding	O
principles	O
should	O
be	O
observed	O
to	O
maintain	O
high	O
quality	O
of	O
the	O
models	O
.	O
	
section	O
:	O
General	O
Design	O
Principles	O
	
Here	O
we	O
will	O
describe	O
a	O
few	O
design	B-Method
principles	I-Method
based	O
on	O
large	O
-	O
scale	O
experimentation	O
with	O
various	O
architectural	O
choices	O
with	O
convolutional	B-Method
networks	I-Method
.	O
	
At	O
this	O
point	O
,	O
the	O
utility	O
of	O
the	O
principles	O
below	O
are	O
speculative	O
and	O
additional	O
future	O
experimental	O
evidence	O
will	O
be	O
necessary	O
to	O
assess	O
their	O
accuracy	B-Metric
and	O
domain	O
of	O
validity	O
.	O
	
Still	O
,	O
grave	O
deviations	O
from	O
these	O
principles	O
tended	O
to	O
result	O
in	O
deterioration	O
in	O
the	O
quality	O
of	O
the	O
networks	O
and	O
fixing	O
situations	O
where	O
those	O
deviations	O
were	O
detected	O
resulted	O
in	O
improved	O
architectures	O
in	O
general	O
.	O
	
Avoid	O
representational	B-Method
bottlenecks	I-Method
,	O
especially	O
early	O
in	O
the	O
network	O
.	O
	
Feed	B-Method
-	I-Method
forward	I-Method
networks	I-Method
can	O
be	O
represented	O
by	O
an	O
acyclic	O
graph	O
from	O
the	O
input	O
layer	O
(	O
s	O
)	O
to	O
the	O
classifier	B-Method
or	I-Method
regressor	I-Method
.	O
	
This	O
defines	O
a	O
clear	O
direction	O
for	O
the	O
information	B-Task
flow	I-Task
.	O
	
For	O
any	O
cut	O
separating	O
the	O
inputs	O
from	O
the	O
outputs	O
,	O
one	O
can	O
access	O
the	O
amount	O
of	O
information	O
passing	O
though	O
the	O
cut	O
.	O
	
One	O
should	O
avoid	O
bottlenecks	O
with	O
extreme	O
compression	B-Task
.	O
	
In	O
general	O
the	O
representation	O
size	O
should	O
gently	O
decrease	O
from	O
the	O
inputs	O
to	O
the	O
outputs	O
before	O
reaching	O
the	O
final	O
representation	O
used	O
for	O
the	O
task	O
at	O
hand	O
.	O
	
Theoretically	O
,	O
information	O
content	O
can	O
not	O
be	O
assessed	O
merely	O
by	O
the	O
dimensionality	O
of	O
the	O
representation	O
as	O
it	O
discards	O
important	O
factors	O
like	O
correlation	O
structure	O
;	O
the	O
dimensionality	O
merely	O
provides	O
a	O
rough	O
estimate	O
of	O
information	O
content	O
.	O
	
Higher	B-Method
dimensional	I-Method
representations	I-Method
are	O
easier	O
to	O
process	O
locally	O
within	O
a	O
network	O
.	O
	
Increasing	O
the	O
activations	O
per	O
tile	O
in	O
a	O
convolutional	B-Method
network	I-Method
allows	O
for	O
more	O
disentangled	O
features	O
.	O
	
The	O
resulting	O
networks	O
will	O
train	O
faster	O
.	O
	
Spatial	B-Task
aggregation	I-Task
can	O
be	O
done	O
over	O
lower	O
dimensional	O
embeddings	O
without	O
much	O
or	O
any	O
loss	O
in	O
representational	B-Metric
power	I-Metric
.	O
	
For	O
example	O
,	O
before	O
performing	O
a	O
more	O
spread	O
out	O
(	O
e.g.	O
)	O
convolution	B-Method
,	O
one	O
can	O
reduce	O
the	O
dimension	O
of	O
the	O
input	O
representation	O
before	O
the	O
spatial	B-Method
aggregation	I-Method
without	O
expecting	O
serious	O
adverse	O
effects	O
.	O
	
We	O
hypothesize	O
that	O
the	O
reason	O
for	O
that	O
is	O
the	O
strong	O
correlation	O
between	O
adjacent	O
unit	O
results	O
in	O
much	O
less	O
loss	O
of	O
information	O
during	O
dimension	B-Task
reduction	I-Task
,	O
if	O
the	O
outputs	O
are	O
used	O
in	O
a	O
spatial	O
aggregation	O
context	O
.	O
	
Given	O
that	O
these	O
signals	O
should	O
be	O
easily	O
compressible	O
,	O
the	O
dimension	B-Method
reduction	I-Method
even	O
promotes	O
faster	B-Task
learning	I-Task
.	O
	
Balance	O
the	O
width	O
and	O
depth	O
of	O
the	O
network	O
.	O
	
Optimal	O
performance	O
of	O
the	O
network	O
can	O
be	O
reached	O
by	O
balancing	O
the	O
number	O
of	O
filters	O
per	O
stage	O
and	O
the	O
depth	O
of	O
the	O
network	O
.	O
	
Increasing	O
both	O
the	O
width	O
and	O
the	O
depth	O
of	O
the	O
network	O
can	O
contribute	O
to	O
higher	O
quality	O
networks	O
.	O
	
However	O
,	O
the	O
optimal	O
improvement	O
for	O
a	O
constant	O
amount	O
of	O
computation	O
can	O
be	O
reached	O
if	O
both	O
are	O
increased	O
in	O
parallel	O
.	O
	
The	O
computational	O
budget	O
should	O
therefore	O
be	O
distributed	O
in	O
a	O
balanced	O
way	O
between	O
the	O
depth	O
and	O
width	O
of	O
the	O
network	O
.	O
	
Although	O
these	O
principles	O
might	O
make	O
sense	O
,	O
it	O
is	O
not	O
straightforward	O
to	O
use	O
them	O
to	O
improve	O
the	O
quality	O
of	O
networks	O
out	O
of	O
box	O
.	O
	
The	O
idea	O
is	O
to	O
use	O
them	O
judiciously	O
in	O
ambiguous	O
situations	O
only	O
.	O
	
section	O
:	O
Factorizing	B-Method
Convolutions	I-Method
with	O
Large	O
Filter	B-Method
Size	I-Method
	
Much	O
of	O
the	O
original	O
gains	O
of	O
the	O
GoogLeNet	B-Method
network	I-Method
arise	O
from	O
a	O
very	O
generous	O
use	O
of	O
dimension	B-Method
reduction	I-Method
.	O
	
This	O
can	O
be	O
viewed	O
as	O
a	O
special	O
case	O
of	O
factorizing	B-Method
convolutions	I-Method
in	O
a	O
computationally	O
efficient	O
manner	O
.	O
	
Consider	O
for	O
example	O
the	O
case	O
of	O
a	O
convolutional	B-Method
layer	I-Method
followed	O
by	O
a	O
convolutional	B-Method
layer	I-Method
.	O
	
In	O
a	O
vision	B-Method
network	I-Method
,	O
it	O
is	O
expected	O
that	O
the	O
outputs	O
of	O
near	O
-	O
by	O
activations	O
are	O
highly	O
correlated	O
.	O
	
Therefore	O
,	O
we	O
can	O
expect	O
that	O
their	O
activations	O
can	O
be	O
reduced	O
before	O
aggregation	B-Task
and	O
that	O
this	O
should	O
result	O
in	O
similarly	O
expressive	B-Method
local	I-Method
representations	I-Method
.	O
	
Here	O
we	O
explore	O
other	O
ways	O
of	O
factorizing	B-Method
convolutions	I-Method
in	O
various	O
settings	O
,	O
especially	O
in	O
order	O
to	O
increase	O
the	O
computational	B-Metric
efficiency	I-Metric
of	O
the	O
solution	O
.	O
	
Since	O
Inception	B-Method
networks	I-Method
are	O
fully	O
convolutional	B-Method
,	O
each	O
weight	O
corresponds	O
to	O
one	O
multiplication	O
per	O
activation	O
.	O
	
Therefore	O
,	O
any	O
reduction	O
in	O
computational	B-Metric
cost	I-Metric
results	O
in	O
reduced	O
number	O
of	O
parameters	O
.	O
	
This	O
means	O
that	O
with	O
suitable	O
factorization	B-Method
,	O
we	O
can	O
end	O
up	O
with	O
more	O
disentangled	O
parameters	O
and	O
therefore	O
with	O
faster	O
training	B-Task
.	O
	
Also	O
,	O
we	O
can	O
use	O
the	O
computational	O
and	O
memory	O
savings	O
to	O
increase	O
the	O
filter	O
-	O
bank	O
sizes	O
of	O
our	O
network	O
while	O
maintaining	O
our	O
ability	O
to	O
train	O
each	O
model	O
replica	O
on	O
a	O
single	O
computer	O
.	O
	
subsection	O
:	O
Factorization	O
into	O
smaller	O
convolutions	O
	
Convolutions	B-Method
with	O
larger	O
spatial	O
filters	O
(	O
e.g.	O
or	O
)	O
tend	O
to	O
be	O
disproportionally	O
expensive	O
in	O
terms	O
of	O
computation	B-Task
.	O
	
For	O
example	O
,	O
a	O
convolution	B-Method
with	I-Method
filters	I-Method
over	O
a	O
grid	B-Method
with	I-Method
filters	I-Method
is	O
25	O
/	O
9	O
=	O
2.78	O
times	O
more	O
computationally	O
expensive	O
than	O
a	O
convolution	B-Method
with	O
the	O
same	O
number	O
of	O
filters	O
.	O
	
Of	O
course	O
,	O
a	O
filter	B-Method
can	O
capture	O
dependencies	O
between	O
signals	O
between	O
activations	O
of	O
units	O
further	O
away	O
in	O
the	O
earlier	O
layers	O
,	O
so	O
a	O
reduction	O
of	O
the	O
geometric	B-Metric
size	I-Metric
of	O
the	O
filters	O
comes	O
at	O
a	O
large	O
cost	O
of	O
expressiveness	B-Metric
.	O
	
However	O
,	O
we	O
can	O
ask	O
whether	O
a	O
convolution	B-Method
could	O
be	O
replaced	O
by	O
a	O
multi	B-Method
-	I-Method
layer	I-Method
network	I-Method
with	O
less	O
parameters	O
with	O
the	O
same	O
input	O
size	O
and	O
output	O
depth	O
.	O
	
If	O
we	O
zoom	O
into	O
the	O
computation	O
graph	O
of	O
the	O
convolution	B-Method
,	O
we	O
see	O
that	O
each	O
output	O
looks	O
like	O
a	O
small	O
fully	B-Method
-	I-Method
connected	I-Method
network	I-Method
sliding	O
over	O
tiles	O
over	O
its	O
input	O
(	O
see	O
Figure	O
[	O
reference	O
]	O
)	O
.	O
	
Since	O
we	O
are	O
constructing	O
a	O
vision	B-Method
network	I-Method
,	O
it	O
seems	O
natural	O
to	O
exploit	O
translation	O
invariance	O
again	O
and	O
replace	O
the	O
fully	B-Method
connected	I-Method
component	I-Method
by	O
a	O
two	O
layer	B-Method
convolutional	I-Method
architecture	I-Method
:	O
the	O
first	O
layer	O
is	O
a	O
convolution	B-Method
,	O
the	O
second	O
is	O
a	O
fully	B-Method
connected	I-Method
layer	I-Method
on	O
top	O
of	O
the	O
output	O
grid	O
of	O
the	O
first	O
layer	O
(	O
see	O
Figure	O
[	O
reference	O
]	O
)	O
.	O
	
Sliding	O
this	O
small	O
network	O
over	O
the	O
input	O
activation	O
grid	O
boils	O
down	O
to	O
replacing	O
the	O
convolution	B-Method
with	O
two	O
layers	O
of	O
convolution	B-Method
(	O
compare	O
Figure	O
[	O
reference	O
]	O
with	O
[	O
reference	O
]	O
)	O
.	O
	
This	O
setup	O
clearly	O
reduces	O
the	O
parameter	O
count	O
by	O
sharing	O
the	O
weights	O
between	O
adjacent	O
tiles	O
.	O
	
To	O
analyze	O
the	O
expected	O
computational	B-Metric
cost	I-Metric
savings	I-Metric
,	O
we	O
will	O
make	O
a	O
few	O
simplifying	O
assumptions	O
that	O
apply	O
for	O
the	O
typical	O
situations	O
:	O
We	O
can	O
assume	O
that	O
,	O
that	O
is	O
that	O
we	O
want	O
to	O
change	O
the	O
number	O
of	O
activations	O
/	O
unit	O
by	O
a	O
constant	O
alpha	O
factor	O
.	O
	
Since	O
the	O
convolution	B-Method
is	O
aggregating	B-Task
,	O
is	O
typically	O
slightly	O
larger	O
than	O
one	O
(	O
around	O
1.5	O
in	O
the	O
case	O
of	O
GoogLeNet	O
)	O
.	O
	
Having	O
a	O
two	O
layer	B-Method
replacement	I-Method
for	O
the	O
layer	O
,	O
it	O
seems	O
reasonable	O
to	O
reach	O
this	O
expansion	O
in	O
two	O
steps	O
:	O
increasing	O
the	O
number	O
of	O
filters	O
by	O
in	O
both	O
steps	O
.	O
	
In	O
order	O
to	O
simplify	O
our	O
estimate	O
by	O
choosing	O
(	O
no	O
expansion	O
)	O
,	O
If	O
we	O
would	O
naivly	O
slide	O
a	O
network	O
without	O
reusing	O
the	O
computation	O
between	O
neighboring	O
grid	O
tiles	O
,	O
we	O
would	O
increase	O
the	O
computational	B-Metric
cost	I-Metric
.	O
	
sliding	O
this	O
network	O
can	O
be	O
represented	O
by	O
two	O
convolutional	B-Method
layers	I-Method
which	O
reuses	O
the	O
activations	O
between	O
adjacent	O
tiles	O
.	O
	
This	O
way	O
,	O
we	O
end	O
up	O
with	O
a	O
net	O
reduction	B-Task
of	I-Task
computation	I-Task
,	O
resulting	O
in	O
a	O
relative	O
gain	O
of	O
by	O
this	O
factorization	O
.	O
	
The	O
exact	O
same	O
saving	O
holds	O
for	O
the	O
parameter	O
count	O
as	O
each	O
parameter	O
is	O
used	O
exactly	O
once	O
in	O
the	O
computation	O
of	O
the	O
activation	O
of	O
each	O
unit	O
.	O
	
Still	O
,	O
this	O
setup	O
raises	O
two	O
general	O
questions	O
:	O
Does	O
this	O
replacement	O
result	O
in	O
any	O
loss	O
of	O
expressiveness	O
?	O
	
If	O
our	O
main	O
goal	O
is	O
to	O
factorize	O
the	O
linear	O
part	O
of	O
the	O
computation	O
,	O
would	O
it	O
not	O
suggest	O
to	O
keep	O
linear	O
activations	O
in	O
the	O
first	O
layer	O
?	O
	
We	O
have	O
ran	O
several	O
control	O
experiments	O
(	O
for	O
example	O
see	O
figure	O
[	O
reference	O
]	O
)	O
and	O
using	O
linear	O
activation	O
was	O
always	O
inferior	O
to	O
using	O
rectified	B-Method
linear	I-Method
units	I-Method
in	O
all	O
stages	O
of	O
the	O
factorization	B-Task
.	O
	
We	O
attribute	O
this	O
gain	O
to	O
the	O
enhanced	O
space	O
of	O
variations	O
that	O
the	O
network	O
can	O
learn	O
especially	O
if	O
we	O
batch	O
-	O
normalize	O
the	O
output	O
activations	O
.	O
	
One	O
can	O
see	O
similar	O
effects	O
when	O
using	O
linear	B-Method
activations	I-Method
for	O
the	O
dimension	B-Method
reduction	I-Method
components	I-Method
.	O
	
subsection	O
:	O
Spatial	B-Method
Factorization	I-Method
into	O
Asymmetric	B-Method
Convolutions	I-Method
	
The	O
above	O
results	O
suggest	O
that	O
convolutions	B-Method
with	O
filters	O
larger	O
a	O
might	O
not	O
be	O
generally	O
useful	O
as	O
they	O
can	O
always	O
be	O
reduced	O
into	O
a	O
sequence	O
of	O
convolutional	B-Method
layers	I-Method
.	O
	
Still	O
we	O
can	O
ask	O
the	O
question	O
whether	O
one	O
should	O
factorize	O
them	O
into	O
smaller	O
,	O
for	O
example	O
convolutions	B-Method
.	O
	
However	O
,	O
it	O
turns	O
out	O
that	O
one	O
can	O
do	O
even	O
better	O
than	O
by	O
using	O
asymmetric	B-Method
convolutions	I-Method
,	O
e.g.	O
.	O
	
For	O
example	O
using	O
a	O
convolution	B-Method
followed	O
by	O
a	O
convolution	B-Method
is	O
equivalent	O
to	O
sliding	O
a	O
two	B-Method
layer	I-Method
network	I-Method
with	O
the	O
same	O
receptive	O
field	O
as	O
in	O
a	O
convolution	O
(	O
see	O
figure	O
[	O
reference	O
]	O
)	O
.	O
	
Still	O
the	O
two	B-Method
-	I-Method
layer	I-Method
solution	I-Method
is	O
cheaper	O
for	O
the	O
same	O
number	O
of	O
output	O
filters	O
,	O
if	O
the	O
number	O
of	O
input	O
and	O
output	O
filters	O
is	O
equal	O
.	O
	
By	O
comparison	O
,	O
factorizing	O
a	O
convolution	B-Method
into	O
a	O
two	O
convolution	B-Method
represents	O
only	O
a	O
saving	O
of	O
computation	O
.	O
.	O
	
In	O
theory	O
,	O
we	O
could	O
go	O
even	O
further	O
and	O
argue	O
that	O
one	O
can	O
replace	O
any	O
convolution	B-Method
by	O
a	O
convolution	B-Method
followed	O
by	O
a	O
convolution	B-Method
and	O
the	O
computational	B-Metric
cost	I-Metric
saving	I-Metric
increases	O
dramatically	O
as	O
grows	O
(	O
see	O
figure	O
6	O
)	O
.	O
	
In	O
practice	O
,	O
we	O
have	O
found	O
that	O
employing	O
this	O
factorization	O
does	O
not	O
work	O
well	O
on	O
early	O
layers	O
,	O
but	O
it	O
gives	O
very	O
good	O
results	O
on	O
medium	O
grid	O
-	O
sizes	O
	
(	O
On	O
feature	O
maps	O
,	O
where	O
ranges	O
between	O
and	O
)	O
.	O
	
On	O
that	O
level	O
,	O
very	O
good	O
results	O
can	O
be	O
achieved	O
by	O
using	O
convolutions	B-Method
followed	O
by	O
convolutions	B-Method
.	O
	
section	O
:	O
Utility	O
of	O
Auxiliary	B-Method
Classifiers	I-Method
	
has	O
introduced	O
the	O
notion	O
of	O
auxiliary	B-Method
classifiers	I-Method
to	O
improve	O
the	O
convergence	B-Task
of	I-Task
very	I-Task
deep	I-Task
networks	I-Task
.	O
	
The	O
original	O
motivation	O
was	O
to	O
push	O
useful	O
gradients	O
to	O
the	O
lower	O
layers	O
to	O
make	O
them	O
immediately	O
useful	O
and	O
improve	O
the	O
convergence	O
during	O
training	B-Task
by	O
combating	O
the	O
vanishing	B-Task
gradient	I-Task
problem	I-Task
in	O
very	O
deep	B-Method
networks	I-Method
.	O
	
Also	O
Lee	O
et	O
al	O
argues	O
that	O
auxiliary	B-Method
classifiers	I-Method
promote	O
more	O
stable	O
learning	B-Task
and	O
better	O
convergence	B-Metric
.	O
	
Interestingly	O
,	O
we	O
found	O
that	O
auxiliary	B-Method
classifiers	I-Method
did	O
not	O
result	O
in	O
improved	O
convergence	O
early	O
in	O
the	O
training	O
:	O
the	O
training	O
progression	O
of	O
network	O
with	O
and	O
without	O
side	O
head	O
looks	O
virtually	O
identical	O
before	O
both	O
models	O
reach	O
high	O
accuracy	B-Metric
.	O
	
Near	O
the	O
end	O
of	O
training	O
,	O
the	O
network	O
with	O
the	O
auxiliary	O
branches	O
starts	O
to	O
overtake	O
the	O
accuracy	B-Metric
of	O
the	O
network	O
without	O
any	O
auxiliary	O
branch	O
and	O
reaches	O
a	O
slightly	O
higher	O
plateau	O
.	O
	
Also	O
used	O
two	O
side	O
-	O
heads	O
at	O
different	O
stages	O
in	O
the	O
network	O
.	O
	
The	O
removal	O
of	O
the	O
lower	O
auxiliary	O
branch	O
did	O
not	O
have	O
any	O
adverse	O
effect	O
on	O
the	O
final	O
quality	O
of	O
the	O
network	O
.	O
	
Together	O
with	O
the	O
earlier	O
observation	O
in	O
the	O
previous	O
paragraph	O
,	O
this	O
means	O
that	O
original	O
the	O
hypothesis	O
of	O
that	O
these	O
branches	O
help	O
evolving	O
the	O
low	O
-	O
level	O
features	O
is	O
most	O
likely	O
misplaced	O
.	O
	
Instead	O
,	O
we	O
argue	O
that	O
the	O
auxiliary	B-Method
classifiers	I-Method
act	O
as	O
regularizer	B-Method
.	O
	
This	O
is	O
supported	O
by	O
the	O
fact	O
that	O
the	O
main	O
classifier	B-Method
of	O
the	O
network	O
performs	O
better	O
if	O
the	O
side	O
branch	O
is	O
batch	O
-	O
normalized	O
or	O
has	O
a	O
dropout	B-Method
layer	I-Method
.	O
	
This	O
also	O
gives	O
a	O
weak	O
supporting	O
evidence	O
for	O
the	O
conjecture	O
that	O
batch	B-Task
normalization	I-Task
acts	O
as	O
a	O
regularizer	B-Method
.	O
	
section	O
:	O
Efficient	O
Grid	B-Task
Size	I-Task
Reduction	I-Task
	
Traditionally	O
,	O
convolutional	B-Method
networks	I-Method
used	O
some	O
pooling	B-Method
operation	I-Method
to	O
decrease	O
the	O
grid	O
size	O
of	O
the	O
feature	O
maps	O
.	O
	
In	O
order	O
to	O
avoid	O
a	O
representational	O
bottleneck	O
,	O
before	O
applying	O
maximum	B-Method
or	I-Method
average	I-Method
pooling	I-Method
the	O
activation	O
dimension	O
of	O
the	O
network	B-Method
filters	I-Method
is	O
expanded	O
.	O
	
For	O
example	O
,	O
starting	O
a	O
grid	O
with	O
filters	O
,	O
if	O
we	O
would	O
like	O
to	O
arrive	O
at	O
a	O
grid	O
with	O
filters	O
,	O
we	O
first	O
need	O
to	O
compute	O
a	O
stride	B-Method
-	I-Method
1	I-Method
convolution	I-Method
with	I-Method
filters	I-Method
and	O
then	O
apply	O
an	O
additional	O
pooling	B-Method
step	I-Method
.	O
	
This	O
means	O
that	O
the	O
overall	O
computational	B-Metric
cost	I-Metric
is	O
dominated	O
by	O
the	O
expensive	O
convolution	B-Method
on	O
the	O
larger	O
grid	O
using	O
operations	O
.	O
	
One	O
possibility	O
would	O
be	O
to	O
switch	O
to	O
pooling	B-Method
with	O
convolution	B-Method
and	O
therefore	O
resulting	O
in	O
reducing	O
the	O
computational	B-Metric
cost	I-Metric
by	O
a	O
quarter	O
.	O
	
However	O
,	O
this	O
creates	O
a	O
representational	O
bottlenecks	O
as	O
the	O
overall	O
dimensionality	O
of	O
the	O
representation	O
drops	O
to	O
resulting	O
in	O
less	O
expressive	O
networks	O
(	O
see	O
Figure	O
[	O
reference	O
]	O
)	O
.	O
	
Instead	O
of	O
doing	O
so	O
,	O
we	O
suggest	O
another	O
variant	O
	
the	O
reduces	O
the	O
computational	B-Metric
cost	I-Metric
even	O
further	O
while	O
removing	O
the	O
representational	O
bottleneck	O
.	O
	
(	O
see	O
Figure	O
[	O
reference	O
]	O
)	O
.	O
	
We	O
can	O
use	O
two	O
parallel	O
stride	O
2	O
blocks	O
:	O
and	O
.	O
is	O
a	O
pooling	B-Method
layer	I-Method
(	O
either	O
average	B-Method
or	I-Method
maximum	I-Method
pooling	I-Method
)	O
the	O
activation	O
,	O
both	O
of	O
them	O
are	O
stride	O
the	O
filter	O
banks	O
of	O
which	O
are	O
concatenated	O
as	O
in	O
figure	O
[	O
reference	O
]	O
.	O
	
section	O
:	O
Inception	O
-	O
v2	O
	
Here	O
we	O
are	O
connecting	O
the	O
dots	O
from	O
above	O
and	O
propose	O
a	O
new	O
architecture	O
with	O
improved	O
performance	O
on	O
the	O
ILSVRC	B-Material
2012	I-Material
classification	O
benchmark	O
.	O
	
The	O
layout	O
of	O
our	O
network	O
is	O
given	O
in	O
table	O
[	O
reference	O
]	O
.	O
	
Note	O
that	O
we	O
have	O
factorized	O
the	O
traditional	O
convolution	B-Method
into	O
three	O
convolutions	B-Method
based	O
on	O
the	O
same	O
ideas	O
as	O
described	O
in	O
section	O
[	O
reference	O
]	O
.	O
	
For	O
the	O
Inception	O
part	O
of	O
the	O
network	O
,	O
we	O
have	O
traditional	O
inception	B-Method
modules	I-Method
at	O
the	O
with	O
filters	O
each	O
.	O
	
This	O
is	O
reduced	O
to	O
a	O
grid	B-Method
with	I-Method
filters	I-Method
using	O
the	O
grid	B-Method
reduction	I-Method
technique	I-Method
described	O
in	O
section	O
[	O
reference	O
]	O
.	O
	
This	O
is	O
is	O
followed	O
by	O
instances	O
of	O
the	O
factorized	B-Method
inception	I-Method
modules	I-Method
as	O
depicted	O
in	O
figure	O
[	O
reference	O
]	O
.	O
	
This	O
is	O
reduced	O
to	O
a	O
grid	O
with	O
the	O
grid	B-Method
reduction	I-Method
technique	I-Method
depicted	O
in	O
figure	O
[	O
reference	O
]	O
.	O
	
At	O
the	O
coarsest	O
level	O
,	O
we	O
have	O
two	O
Inception	B-Method
modules	I-Method
as	O
depicted	O
in	O
figure	O
[	O
reference	O
]	O
,	O
with	O
a	O
concatenated	O
output	O
filter	O
bank	O
size	O
of	O
2048	O
for	O
each	O
tile	O
.	O
	
The	O
detailed	O
structure	O
of	O
the	O
network	O
,	O
including	O
the	O
sizes	O
of	O
filter	B-Method
banks	I-Method
inside	O
the	O
Inception	B-Method
modules	I-Method
,	O
is	O
given	O
in	O
the	O
supplementary	O
material	O
,	O
given	O
in	O
the	O
model.txt	O
that	O
is	O
in	O
the	O
tar	O
-	O
file	O
of	O
this	O
submission	O
.	O
	
However	O
,	O
we	O
have	O
observed	O
that	O
the	O
quality	O
of	O
the	O
network	O
is	O
relatively	O
stable	O
to	O
variations	O
as	O
long	O
as	O
the	O
principles	O
from	O
Section	O
[	O
reference	O
]	O
are	O
observed	O
.	O
	
Although	O
our	O
network	O
is	O
layers	O
deep	O
,	O
our	O
computation	B-Metric
cost	I-Metric
is	O
only	O
about	O
higher	O
than	O
that	O
of	O
GoogLeNet	B-Method
	
and	O
it	O
is	O
still	O
much	O
more	O
efficient	O
than	O
VGGNet	B-Method
.	O
	
section	O
:	O
Model	B-Task
Regularization	I-Task
via	O
Label	B-Method
Smoothing	I-Method
	
Here	O
we	O
propose	O
a	O
mechanism	O
to	O
regularize	O
the	O
classifier	B-Method
layer	I-Method
by	O
estimating	O
the	O
marginalized	B-Method
effect	I-Method
of	I-Method
label	I-Method
-	I-Method
dropout	I-Method
during	O
training	O
.	O
	
For	O
each	O
training	O
example	O
,	O
our	O
model	O
computes	O
the	O
probability	O
of	O
each	O
label	O
:	O
.	O
	
Here	O
,	O
are	O
the	O
logits	O
or	O
unnormalized	O
log	O
-	O
probabilities	O
.	O
	
Consider	O
the	O
ground	O
-	O
truth	O
distribution	O
over	O
labels	O
for	O
this	O
training	O
example	O
,	O
normalized	O
so	O
that	O
.	O
	
For	O
brevity	O
,	O
let	O
us	O
omit	O
the	O
dependence	O
of	O
and	O
on	O
example	O
.	O
	
We	O
define	O
the	O
loss	O
for	O
the	O
example	O
as	O
the	O
cross	B-Metric
entropy	I-Metric
:	O
.	O
	
Minimizing	O
this	O
is	O
equivalent	O
to	O
maximizing	O
the	O
expected	O
log	O
-	O
likelihood	O
of	O
a	O
label	O
,	O
where	O
the	O
label	O
is	O
selected	O
according	O
to	O
its	O
ground	O
-	O
truth	O
distribution	O
.	O
	
Cross	B-Metric
-	I-Metric
entropy	I-Metric
loss	I-Metric
is	O
differentiable	O
with	O
respect	O
to	O
the	O
logits	O
and	O
thus	O
can	O
be	O
used	O
for	O
gradient	B-Task
training	I-Task
of	I-Task
deep	I-Task
models	I-Task
.	O
	
The	O
gradient	O
has	O
a	O
rather	O
simple	O
form	O
:	O
,	O
which	O
is	O
bounded	O
between	O
and	O
.	O
	
Consider	O
the	O
case	O
of	O
a	O
single	O
ground	O
-	O
truth	O
label	O
,	O
so	O
that	O
and	O
for	O
all	O
.	O
	
In	O
this	O
case	O
,	O
minimizing	O
the	O
cross	O
entropy	O
is	O
equivalent	O
to	O
maximizing	O
the	O
log	O
-	O
likelihood	O
of	O
the	O
correct	O
label	O
.	O
	
For	O
a	O
particular	O
example	O
with	O
label	O
,	O
the	O
log	O
-	O
likelihood	O
is	O
maximized	O
for	O
,	O
where	O
is	O
Dirac	O
delta	O
,	O
which	O
equals	O
for	O
and	O
otherwise	O
.	O
	
This	O
maximum	O
is	O
not	O
achievable	O
for	O
finite	O
but	O
is	O
approached	O
if	O
for	O
all	O
–	O
that	O
is	O
,	O
if	O
the	O
logit	O
corresponding	O
to	O
the	O
ground	O
-	O
truth	O
label	O
is	O
much	O
great	O
than	O
all	O
other	O
logits	O
.	O
	
This	O
,	O
however	O
,	O
can	O
cause	O
two	O
problems	O
.	O
	
First	O
,	O
it	O
may	O
result	O
in	O
over	B-Task
-	I-Task
fitting	I-Task
:	O
if	O
the	O
model	O
learns	O
to	O
assign	O
full	O
probability	O
to	O
the	O
ground	O
-	O
truth	O
label	O
for	O
each	O
training	O
example	O
,	O
it	O
is	O
not	O
guaranteed	O
to	O
generalize	O
.	O
	
Second	O
,	O
it	O
encourages	O
the	O
differences	O
between	O
the	O
largest	O
logit	O
and	O
all	O
others	O
to	O
become	O
large	O
,	O
and	O
this	O
,	O
combined	O
with	O
the	O
bounded	O
gradient	O
,	O
reduces	O
the	O
ability	O
of	O
the	O
model	O
to	O
adapt	O
.	O
	
Intuitively	O
,	O
this	O
happens	O
because	O
the	O
model	O
becomes	O
too	O
confident	O
about	O
its	O
predictions	O
.	O
	
We	O
propose	O
a	O
mechanism	O
for	O
encouraging	O
the	O
model	O
to	O
be	O
less	O
confident	O
.	O
	
While	O
this	O
may	O
not	O
be	O
desired	O
if	O
the	O
goal	O
is	O
to	O
maximize	O
the	O
log	O
-	O
likelihood	O
of	O
training	O
labels	O
,	O
it	O
does	O
regularize	O
the	O
model	O
and	O
makes	O
it	O
more	O
adaptable	O
.	O
	
The	O
method	O
is	O
very	O
simple	O
.	O
	
Consider	O
a	O
distribution	O
over	O
labels	O
,	O
independent	O
of	O
the	O
training	O
example	O
x	O
,	O
and	O
a	O
smoothing	O
parameter	O
.	O
	
For	O
a	O
training	O
example	O
with	O
ground	O
-	O
truth	O
label	O
,	O
we	O
replace	O
the	O
label	O
distribution	O
with	O
which	O
is	O
a	O
mixture	O
of	O
the	O
original	O
ground	O
-	O
truth	O
distribution	O
and	O
the	O
fixed	O
distribution	O
,	O
with	O
weights	O
and	O
,	O
respectively	O
.	O
	
This	O
can	O
be	O
seen	O
as	O
the	O
distribution	O
of	O
the	O
label	O
obtained	O
as	O
follows	O
:	O
first	O
,	O
set	O
it	O
to	O
the	O
ground	O
-	O
truth	O
label	O
;	O
then	O
,	O
with	O
probability	O
,	O
replace	O
with	O
a	O
sample	O
drawn	O
from	O
the	O
distribution	O
.	O
	
We	O
propose	O
to	O
use	O
the	O
prior	O
distribution	O
over	O
labels	O
as	O
.	O
	
In	O
our	O
experiments	O
,	O
we	O
used	O
the	O
uniform	O
distribution	O
,	O
so	O
that	O
We	O
refer	O
to	O
this	O
change	O
in	O
ground	O
-	O
truth	O
label	O
distribution	O
as	O
label	B-Method
-	I-Method
smoothing	I-Method
regularization	I-Method
,	O
or	O
LSR	B-Method
.	O
	
Note	O
that	O
LSR	B-Method
achieves	O
the	O
desired	O
goal	O
of	O
preventing	O
the	O
largest	O
logit	O
from	O
becoming	O
much	O
larger	O
than	O
all	O
others	O
.	O
	
Indeed	O
,	O
if	O
this	O
were	O
to	O
happen	O
,	O
then	O
a	O
single	O
would	O
approach	O
while	O
all	O
others	O
would	O
approach	O
.	O
	
This	O
would	O
result	O
in	O
a	O
large	O
cross	B-Metric
-	I-Metric
entropy	I-Metric
with	O
because	O
,	O
unlike	O
,	O
all	O
have	O
a	O
positive	O
lower	O
bound	O
.	O
	
Another	O
interpretation	O
of	O
LSR	B-Method
can	O
be	O
obtained	O
by	O
considering	O
the	O
cross	O
entropy	O
:	O
	
Thus	O
,	O
LSR	B-Method
is	O
equivalent	O
to	O
replacing	O
a	O
single	O
cross	O
-	O
entropy	O
loss	O
with	O
a	O
pair	O
of	O
such	O
losses	O
and	O
.	O
	
The	O
second	O
loss	O
penalizes	O
the	O
deviation	O
of	O
predicted	O
label	O
distribution	O
from	O
the	O
prior	O
,	O
with	O
the	O
relative	O
weight	O
.	O
	
Note	O
that	O
this	O
deviation	O
could	O
be	O
equivalently	O
captured	O
by	O
the	O
KL	O
divergence	O
,	O
since	O
and	O
is	O
fixed	O
.	O
	
When	O
is	O
the	O
uniform	O
distribution	O
,	O
is	O
a	O
measure	O
of	O
how	O
dissimilar	O
the	O
predicted	O
distribution	O
is	O
to	O
uniform	O
,	O
which	O
could	O
also	O
be	O
measured	O
(	O
but	O
not	O
equivalently	O
)	O
by	O
negative	O
entropy	O
;	O
we	O
have	O
not	O
experimented	O
with	O
this	O
approach	O
.	O
	
In	O
our	O
ImageNet	B-Material
experiments	O
with	O
classes	O
,	O
we	O
used	O
and	O
.	O
	
For	O
ILSVRC	B-Material
2012	I-Material
,	O
we	O
have	O
found	O
a	O
consistent	O
improvement	O
of	O
about	O
absolute	O
both	O
for	O
top	B-Metric
-	I-Metric
error	I-Metric
and	O
the	O
top	B-Metric
-	I-Metric
error	I-Metric
(	O
cf	O
.	O
	
Table	O
[	O
reference	O
]	O
)	O
.	O
	
section	O
:	O
Training	O
Methodology	O
	
We	O
have	O
trained	O
our	O
networks	O
with	O
stochastic	B-Method
gradient	I-Method
utilizing	O
the	O
TensorFlow	B-Method
distributed	I-Method
machine	I-Method
learning	I-Method
system	I-Method
using	O
replicas	O
running	O
each	O
on	O
a	O
NVidia	O
Kepler	O
GPU	O
with	O
batch	O
size	O
for	O
epochs	O
.	O
	
Our	O
earlier	O
experiments	O
used	O
momentum	O
with	O
a	O
decay	O
of	O
,	O
while	O
our	O
best	O
models	O
were	O
achieved	O
using	O
RMSProp	B-Method
with	O
decay	O
of	O
and	O
.	O
	
We	O
used	O
a	O
learning	B-Metric
rate	I-Metric
of	O
,	O
decayed	O
every	O
two	O
epoch	O
using	O
an	O
exponential	O
rate	O
of	O
.	O
	
In	O
addition	O
,	O
gradient	O
clipping	O
with	O
threshold	O
was	O
found	O
to	O
be	O
useful	O
to	O
stabilize	O
the	O
training	B-Task
.	O
	
Model	O
evaluations	O
are	O
performed	O
using	O
a	O
running	O
average	O
of	O
the	O
parameters	O
computed	O
over	O
time	O
.	O
	
section	O
:	O
Performance	O
on	O
Lower	O
Resolution	O
Input	O
	
A	O
typical	O
use	O
-	O
case	O
of	O
vision	B-Method
networks	I-Method
is	O
for	O
the	O
the	O
post	B-Task
-	I-Task
classification	I-Task
of	I-Task
detection	I-Task
,	O
for	O
example	O
in	O
the	O
Multibox	B-Task
context	I-Task
.	O
	
This	O
includes	O
the	O
analysis	O
of	O
a	O
relative	O
small	O
patch	O
of	O
the	O
image	O
containing	O
a	O
single	O
object	O
with	O
some	O
context	O
.	O
	
The	O
tasks	O
is	O
to	O
decide	O
whether	O
the	O
center	O
part	O
of	O
the	O
patch	O
corresponds	O
to	O
some	O
object	O
and	O
determine	O
the	O
class	O
of	O
the	O
object	O
if	O
it	O
does	O
.	O
	
The	O
challenge	O
is	O
that	O
objects	O
tend	O
to	O
be	O
relatively	O
small	O
and	O
low	O
-	O
resolution	O
.	O
	
This	O
raises	O
the	O
question	O
of	O
how	O
to	O
properly	O
deal	O
with	O
lower	O
resolution	O
input	O
.	O
	
The	O
common	O
wisdom	O
is	O
that	O
models	O
employing	O
higher	O
resolution	O
receptive	O
fields	O
tend	O
to	O
result	O
in	O
significantly	O
improved	O
recognition	B-Metric
performance	I-Metric
.	O
	
However	O
it	O
is	O
important	O
to	O
distinguish	O
between	O
the	O
effect	O
of	O
the	O
increased	O
resolution	O
of	O
the	O
first	O
layer	O
receptive	O
field	O
and	O
the	O
effects	O
of	O
larger	O
model	O
capacitance	O
and	O
computation	B-Task
.	O
	
If	O
we	O
just	O
change	O
the	O
resolution	O
of	O
the	O
input	O
without	O
further	O
adjustment	O
to	O
the	O
model	O
,	O
then	O
we	O
end	O
up	O
using	O
computationally	O
much	O
cheaper	O
models	O
to	O
solve	O
more	O
difficult	O
tasks	O
.	O
	
Of	O
course	O
,	O
it	O
is	O
natural	O
,	O
that	O
these	O
solutions	O
loose	O
out	O
already	O
because	O
of	O
the	O
reduced	O
computational	B-Metric
effort	I-Metric
.	O
	
In	O
order	O
to	O
make	O
an	O
accurate	O
assessment	O
,	O
the	O
model	O
needs	O
to	O
analyze	O
vague	O
hints	O
in	O
order	O
to	O
be	O
able	O
to	O
“	O
hallucinate	O
”	O
the	O
fine	O
details	O
.	O
	
This	O
is	O
computationally	O
costly	O
.	O
	
The	O
question	O
remains	O
therefore	O
:	O
how	O
much	O
does	O
higher	O
input	O
resolution	O
helps	O
if	O
the	O
computational	B-Metric
effort	I-Metric
is	O
kept	O
constant	O
.	O
	
One	O
simple	O
way	O
to	O
ensure	O
constant	O
effort	O
is	O
to	O
reduce	O
the	O
strides	O
of	O
the	O
first	O
two	O
layer	O
in	O
the	O
case	O
of	O
lower	O
resolution	O
input	O
,	O
or	O
by	O
simply	O
removing	O
the	O
first	B-Method
pooling	I-Method
layer	I-Method
of	O
the	O
network	O
.	O
	
For	O
this	O
purpose	O
we	O
have	O
performed	O
the	O
following	O
three	O
experiments	O
:	O
receptive	O
field	O
with	O
stride	O
and	O
maximum	B-Method
pooling	I-Method
after	O
the	O
first	O
layer	O
.	O
	
receptive	O
field	O
with	O
stride	O
and	O
maximum	B-Method
pooling	I-Method
after	O
the	O
first	O
layer	O
.	O
	
receptive	O
field	O
with	O
stride	O
and	O
without	O
pooling	B-Method
after	O
the	O
first	O
layer	O
.	O
	
All	O
three	O
networks	O
have	O
almost	O
identical	O
computational	B-Metric
cost	I-Metric
.	O
	
Although	O
the	O
third	O
network	O
is	O
slightly	O
cheaper	O
,	O
the	O
cost	O
of	O
the	O
pooling	B-Method
layer	I-Method
is	O
marginal	O
and	O
(	O
within	O
of	O
the	O
total	O
cost	O
of	O
the	O
)	O
network	O
.	O
	
In	O
each	O
case	O
,	O
the	O
networks	O
were	O
trained	O
until	O
convergence	O
and	O
their	O
quality	O
was	O
measured	O
on	O
the	O
validation	O
set	O
of	O
the	O
ImageNet	B-Material
ILSVRC	I-Material
2012	I-Material
classification	I-Material
benchmark	I-Material
.	O
	
The	O
results	O
can	O
be	O
seen	O
in	O
table	O
[	O
reference	O
]	O
.	O
	
Although	O
the	O
lower	B-Method
-	I-Method
resolution	I-Method
networks	I-Method
take	O
longer	O
to	O
train	O
,	O
the	O
quality	O
of	O
the	O
final	O
result	O
is	O
quite	O
close	O
to	O
that	O
of	O
their	O
higher	O
resolution	O
counterparts	O
.	O
	
However	O
,	O
if	O
one	O
would	O
just	O
naively	O
reduce	O
the	O
network	O
size	O
according	O
to	O
the	O
input	O
resolution	O
,	O
then	O
network	O
would	O
perform	O
much	O
more	O
poorly	O
.	O
	
However	O
this	O
would	O
an	O
unfair	O
comparison	O
as	O
we	O
would	O
are	O
comparing	O
a	O
16	O
times	O
cheaper	O
model	O
on	O
a	O
more	O
difficult	O
task	O
.	O
	
Also	O
these	O
results	O
of	O
table	O
[	O
reference	O
]	O
suggest	O
,	O
one	O
might	O
consider	O
using	O
dedicated	O
high	B-Method
-	I-Method
cost	I-Method
low	I-Method
resolution	I-Method
networks	I-Method
for	O
smaller	O
objects	O
in	O
the	O
R	B-Task
-	I-Task
CNN	I-Task
context	I-Task
.	O
	
section	O
:	O
Experimental	O
Results	O
and	O
Comparisons	O
	
Inception	B-Method
-	O
v2	O
	
RMSProp	B-Method
Inception	I-Method
-	O
v2	O
Label	O
	
Smoothing	B-Method
Inception	I-Method
-	O
	
v2	O
Factorized	O
Table	O
[	O
reference	O
]	O
shows	O
the	O
experimental	O
results	O
about	O
the	O
recognition	B-Task
performance	O
of	O
our	O
proposed	O
architecture	O
(	O
Inception	B-Method
-	O
v2	O
)	O
as	O
described	O
in	O
Section	O
[	O
reference	O
]	O
.	O
	
Each	O
Inception	O
-	O
v2	O
line	O
shows	O
the	O
result	O
of	O
the	O
cumulative	O
changes	O
including	O
the	O
highlighted	O
new	O
modification	O
plus	O
all	O
the	O
earlier	O
ones	O
.	O
	
Label	B-Task
Smoothing	I-Task
refers	O
to	O
method	O
described	O
in	O
Section	O
[	O
reference	O
]	O
.	O
	
Factorized	B-Method
includes	O
a	O
change	O
that	O
factorizes	O
the	O
first	O
convolutional	O
layer	O
into	O
a	O
sequence	O
of	O
convolutional	B-Method
layers	I-Method
.	O
	
BN	B-Method
-	I-Method
auxiliary	I-Method
refers	O
to	O
the	O
version	O
in	O
which	O
the	O
fully	O
connected	O
layer	O
of	O
the	O
auxiliary	B-Method
classifier	I-Method
is	O
also	O
batch	O
-	O
normalized	O
,	O
not	O
just	O
the	O
convolutions	B-Method
.	O
	
We	O
are	O
referring	O
to	O
the	O
model	O
in	O
last	O
row	O
of	O
Table	O
[	O
reference	O
]	O
as	O
Inception	B-Method
-	I-Method
v3	I-Method
and	O
evaluate	O
its	O
performance	O
in	O
the	O
multi	B-Task
-	I-Task
crop	I-Task
and	I-Task
ensemble	I-Task
settings	I-Task
.	O
	
All	O
our	O
evaluations	O
are	O
done	O
on	O
the	O
48238	O
non	O
-	O
blacklisted	O
examples	O
on	O
the	O
ILSVRC	B-Material
-	I-Material
2012	I-Material
validation	I-Material
set	I-Material
,	O
as	O
suggested	O
by	O
.	O
	
We	O
have	O
evaluated	O
all	O
the	O
50000	O
examples	O
as	O
well	O
and	O
the	O
results	O
were	O
roughly	O
0.1	O
%	O
worse	O
in	O
top	B-Metric
-	I-Metric
5	I-Metric
error	I-Metric
and	O
around	O
0.2	O
%	O
in	O
top	B-Metric
-	I-Metric
1	I-Metric
error	I-Metric
.	O
	
In	O
the	O
upcoming	O
version	O
of	O
this	O
paper	O
,	O
we	O
will	O
verify	O
our	O
ensemble	O
result	O
on	O
the	O
test	O
set	O
,	O
but	O
at	O
the	O
time	O
of	O
our	O
last	O
evaluation	O
of	O
BN	B-Method
-	O
Inception	O
in	O
spring	O
indicates	O
that	O
the	O
test	B-Metric
and	I-Metric
validation	I-Metric
set	I-Metric
error	I-Metric
tends	O
to	O
correlate	O
very	O
well	O
.	O
	
section	O
:	O
Conclusions	O
	
We	O
have	O
provided	O
several	O
design	O
principles	O
to	O
scale	O
up	O
convolutional	B-Method
networks	I-Method
and	O
studied	O
them	O
in	O
the	O
context	O
of	O
the	O
Inception	B-Method
architecture	I-Method
.	O
	
This	O
guidance	O
can	O
lead	O
to	O
high	O
performance	O
vision	B-Task
networks	I-Task
that	O
have	O
a	O
relatively	O
modest	O
computation	B-Metric
cost	I-Metric
compared	O
to	O
simpler	O
,	O
more	O
monolithic	B-Method
architectures	I-Method
.	O
	
Our	O
highest	O
quality	O
version	O
of	O
Inception	B-Method
-	I-Method
v3	I-Method
reaches	O
,	O
top	B-Metric
-	I-Metric
and	O
top	B-Metric
-	I-Metric
5	I-Metric
error	I-Metric
for	O
single	B-Task
crop	I-Task
evaluation	I-Task
on	O
the	O
ILSVR	B-Material
2012	I-Material
classification	I-Material
,	O
setting	O
a	O
new	O
state	O
of	O
the	O
art	O
.	O
	
This	O
is	O
achieved	O
with	O
relatively	O
modest	O
(	O
)	O
increase	O
in	O
computational	B-Metric
cost	I-Metric
compared	O
to	O
the	O
network	O
described	O
in	O
Ioffe	O
et	O
al	O
.	O
	
Still	O
our	O
solution	O
uses	O
much	O
less	O
computation	O
than	O
the	O
best	O
published	O
results	O
based	O
on	O
denser	B-Method
networks	I-Method
:	O
our	O
model	O
outperforms	O
the	O
results	O
of	O
He	O
et	O
al	O
–	O
cutting	O
the	O
top	B-Metric
-	I-Metric
(	O
top	B-Metric
-	I-Metric
)	O
error	O
by	O
(	O
)	O
relative	O
,	O
respectively	O
–	O
while	O
being	O
six	O
times	O
cheaper	O
computationally	O
and	O
using	O
at	O
least	O
five	O
times	O
less	O
parameters	O
(	O
estimated	O
)	O
.	O
	
Our	O
ensemble	B-Method
of	I-Method
four	I-Method
Inception	I-Method
-	I-Method
v3	I-Method
models	I-Method
reaches	O
with	O
multi	B-Method
-	I-Method
crop	I-Method
evaluation	I-Method
reaches	O
top	B-Metric
-	I-Metric
error	I-Metric
which	O
represents	O
an	O
over	O
reduction	O
to	O
the	O
best	O
published	O
results	O
and	O
is	O
almost	O
half	O
of	O
the	O
error	O
of	O
ILSVRC	B-Method
2014	I-Method
winining	I-Method
GoogLeNet	I-Method
ensemble	I-Method
.	O
	
We	O
have	O
also	O
demonstrated	O
that	O
high	O
quality	O
results	O
can	O
be	O
reached	O
with	O
receptive	O
field	O
resolution	O
as	O
low	O
as	O
.	O
	
This	O
might	O
prove	O
to	O
be	O
helpful	O
in	O
systems	O
for	O
detecting	B-Task
relatively	I-Task
small	I-Task
objects	I-Task
.	O
	
We	O
have	O
studied	O
how	O
factorizing	B-Method
convolutions	I-Method
and	O
aggressive	B-Method
dimension	I-Method
reductions	I-Method
inside	O
neural	B-Method
network	I-Method
can	O
result	O
in	O
networks	O
with	O
relatively	O
low	B-Metric
computational	I-Metric
cost	I-Metric
while	O
maintaining	O
high	O
quality	B-Metric
.	O
	
The	O
combination	O
of	O
lower	O
parameter	O
count	O
and	O
additional	O
regularization	B-Method
with	O
batch	B-Method
-	I-Method
normalized	I-Method
auxiliary	I-Method
classifiers	I-Method
and	O
label	B-Method
-	I-Method
smoothing	I-Method
allows	O
for	O
training	O
high	O
quality	O
networks	O
on	O
relatively	O
modest	O
sized	O
training	O
sets	O
.	O
	
bibliography	O
:	O
References	O
	
document	O
:	O
ProNet	B-Method
:	O
Learning	B-Method
to	I-Method
Propose	I-Method
Object	I-Method
-	I-Method
specific	I-Method
Boxes	I-Method
for	I-Method
Cascaded	I-Method
Neural	I-Method
Networks	I-Method
	
This	O
paper	O
aims	O
to	O
classify	O
and	O
locate	O
objects	O
accurately	O
and	O
efficiently	O
,	O
without	O
using	O
bounding	O
box	O
annotations	O
.	O
	
It	O
is	O
challenging	O
as	O
objects	O
in	O
the	O
wild	O
could	O
appear	O
at	O
arbitrary	O
locations	O
and	O
in	O
different	O
scales	O
.	O
	
In	O
this	O
paper	O
,	O
we	O
propose	O
a	O
novel	O
classification	B-Method
architecture	I-Method
ProNet	I-Method
based	O
on	O
convolutional	B-Method
neural	I-Method
networks	I-Method
.	O
	
It	O
uses	O
computationally	O
efficient	O
neural	B-Method
networks	I-Method
to	O
propose	O
image	O
regions	O
that	O
are	O
likely	O
to	O
contain	O
objects	O
,	O
and	O
applies	O
more	O
powerful	O
but	O
slower	O
networks	O
on	O
the	O
proposed	O
regions	O
.	O
	
The	O
basic	O
building	O
block	O
is	O
a	O
multi	B-Method
-	I-Method
scale	I-Method
fully	I-Method
-	I-Method
convolutional	I-Method
network	I-Method
which	O
assigns	O
object	O
confidence	O
scores	O
to	O
boxes	O
at	O
different	O
locations	O
and	O
scales	O
.	O
	
We	O
show	O
that	O
such	O
networks	O
can	O
be	O
trained	O
effectively	O
using	O
image	O
-	O
level	O
annotations	O
,	O
and	O
can	O
be	O
connected	O
into	O
cascades	B-Method
or	O
trees	B-Method
for	O
efficient	O
object	B-Task
classification	I-Task
.	O
	
ProNet	B-Method
outperforms	O
previous	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
significantly	O
on	O
PASCAL	O
VOC	B-Task
2012	O
and	O
MS	B-Material
COCO	I-Material
datasets	I-Material
for	O
object	B-Task
classification	I-Task
and	O
point	O
-	O
based	O
localization	B-Task
.	O
	
section	O
:	O
Introduction	O
	
We	O
address	O
the	O
problem	O
of	O
object	B-Task
classification	I-Task
and	O
localization	B-Task
in	O
natural	O
images	O
.	O
	
As	O
objects	O
could	O
be	O
small	O
and	O
appear	O
at	O
arbitrary	O
locations	O
,	O
several	O
frameworks	O
rely	O
on	O
bounding	O
boxes	O
to	O
train	O
object	B-Method
-	I-Method
centric	I-Method
classifiers	I-Method
,	O
and	O
apply	O
the	O
classifiers	O
by	O
searching	O
over	O
different	O
locations	O
of	O
the	O
images	O
.	O
	
However	O
,	O
the	O
annotation	B-Task
process	I-Task
for	O
object	B-Task
bounding	I-Task
boxes	I-Task
is	O
usually	O
resource	O
intensive	O
and	O
difficult	O
to	O
scale	O
up	O
.	O
	
In	O
light	O
of	O
this	O
,	O
we	O
aim	O
to	O
simultaneously	O
classify	O
and	O
locate	O
objects	O
given	O
only	O
image	O
-	O
level	O
annotations	O
for	O
training	O
.	O
	
To	O
cope	O
with	O
the	O
lack	O
of	O
object	O
-	O
level	O
annotations	O
,	O
several	O
methods	O
extract	O
feature	B-Method
activations	I-Method
from	O
convolutional	B-Method
neural	I-Method
networks	I-Method
(	O
CNN	B-Method
)	O
by	O
scanning	O
over	O
different	O
image	O
regions	O
.	O
	
They	O
then	O
aggregate	O
the	O
extracted	O
features	O
into	O
image	B-Method
-	I-Method
level	I-Method
representations	I-Method
for	O
classification	B-Task
purpose	I-Task
.	O
	
Under	O
this	O
scheme	O
,	O
regions	O
that	O
belong	O
to	O
the	O
background	O
are	O
considered	O
as	O
important	O
as	O
regions	O
that	O
contain	O
objects	O
.	O
	
Such	O
global	B-Method
approaches	I-Method
tend	O
to	O
be	O
sensitive	O
to	O
background	O
,	O
and	O
can	O
not	O
be	O
used	O
directly	O
for	O
localization	B-Task
.	O
	
We	O
choose	O
to	O
use	O
the	O
fully	B-Method
-	I-Method
convolutional	I-Method
network	I-Method
(	I-Method
FCN	I-Method
)	I-Method
architecture	I-Method
for	O
simultaneous	O
object	B-Task
classification	I-Task
and	O
localization	B-Task
.	O
	
It	O
replaces	O
the	O
fully	B-Method
-	I-Method
connected	I-Method
layers	I-Method
of	O
a	O
standard	O
CNN	B-Method
(	O
e.g.	O
AlexNet	B-Method
)	O
with	O
convolutional	B-Method
layers	I-Method
.	O
	
This	O
enables	O
an	O
FCN	B-Method
to	O
take	O
images	O
of	O
arbitrary	O
sizes	O
,	O
and	O
generate	O
classification	O
score	O
maps	O
efficiently	O
.	O
	
Each	O
element	O
in	O
a	O
score	B-Method
map	I-Method
corresponds	O
to	O
a	O
rectangular	O
box	O
(	O
receptive	O
field	O
)	O
in	O
the	O
original	O
image	O
.	O
	
The	O
score	B-Method
maps	I-Method
can	O
then	O
be	O
used	O
for	O
classification	B-Task
and	O
localization	B-Task
.	O
	
The	O
sampling	O
strides	O
and	O
box	O
sizes	O
are	O
determined	O
by	O
the	O
FCN	B-Method
’s	I-Method
network	I-Method
architecture	I-Method
.	O
	
As	O
box	O
sizes	O
are	O
fixed	O
,	O
FCN	B-Method
might	O
face	O
difficulty	O
dealing	O
with	O
objects	O
of	O
different	O
scales	O
.	O
	
We	O
address	O
this	O
problem	O
by	O
using	O
a	O
multi	B-Method
-	I-Method
stream	I-Method
multi	I-Method
-	I-Method
scale	I-Method
architecture	I-Method
.	O
	
All	O
streams	O
share	O
the	O
same	O
parameters	O
,	O
but	O
take	O
input	O
images	O
of	O
different	O
scales	O
.	O
	
To	O
train	O
the	O
multi	B-Task
-	I-Task
scale	I-Task
FCN	I-Task
without	O
object	O
-	O
level	O
annotations	O
,	O
we	O
generate	O
image	O
-	O
level	O
scores	O
by	O
pooling	O
the	O
score	O
maps	O
over	O
multiple	O
-	O
scales	O
,	O
and	O
compute	O
the	O
losses	O
with	O
image	O
-	O
level	O
labels	O
for	O
back	B-Method
-	I-Method
propagation	I-Method
.	O
	
Once	O
a	O
multi	B-Method
-	I-Method
scale	I-Method
FCN	I-Method
is	O
trained	O
,	O
it	O
can	O
be	O
used	O
for	O
classification	O
and	O
localization	B-Task
directly	O
.	O
	
From	O
another	O
perspective	O
,	O
it	O
also	O
proposes	O
a	O
set	O
of	O
promising	O
boxes	O
that	O
are	O
likely	O
to	O
contain	O
objects	O
.	O
	
We	O
can	O
then	O
build	O
a	O
cascade	B-Method
architecture	I-Method
by	O
zooming	O
onto	O
those	O
promising	O
boxes	O
,	O
and	O
train	O
new	O
classifiers	B-Method
to	O
verify	O
them	O
.	O
	
The	O
cascade	B-Method
allows	O
the	O
system	O
to	O
balance	O
accuracy	B-Metric
and	O
speed	B-Metric
:	O
each	O
stage	O
filters	O
out	O
parts	O
of	O
image	O
regions	O
that	O
are	O
unlikely	O
to	O
contain	O
objects	O
.	O
	
We	O
name	O
this	O
propose	O
and	O
zoom	B-Method
pipeline	I-Method
as	O
ProNet	B-Method
.	O
	
Figure	O
[	O
reference	O
]	O
provides	O
the	O
high	O
-	O
level	O
intuition	O
behind	O
ProNet	B-Method
:	O
three	O
boxes	O
are	O
proposed	O
for	O
bird	O
,	O
potted	O
plant	O
and	O
cat	B-Task
categories	I-Task
.	O
	
The	O
boxes	O
are	O
cropped	O
out	O
and	O
verified	O
further	O
,	O
until	O
a	O
certain	O
decision	O
is	O
made	O
.	O
	
To	O
train	O
the	O
later	O
classifiers	B-Method
in	O
ProNet	B-Method
,	O
we	O
sample	O
hard	O
negatives	O
based	O
on	O
image	O
-	O
level	O
labels	O
.	O
	
For	O
positives	O
,	O
as	O
no	O
object	O
-	O
level	O
annotations	O
are	O
available	O
,	O
it	O
is	O
impossible	O
to	O
tell	O
objects	O
from	O
background	O
.	O
	
To	O
avoid	O
over	B-Task
-	I-Task
fitting	I-Task
,	O
we	O
randomly	O
sample	O
positive	O
boxes	O
above	O
a	O
relative	O
low	O
threshold	O
.	O
	
Different	O
positive	O
boxes	O
from	O
the	O
same	O
image	O
can	O
be	O
sampled	O
at	O
different	O
iterations	O
of	O
the	O
stochastic	B-Method
gradient	I-Method
descent	I-Method
training	I-Method
process	I-Method
.	O
	
At	O
test	O
time	O
,	O
only	O
a	O
small	O
subset	O
of	O
boxes	O
(	O
10	O
to	O
20	O
per	O
image	O
)	O
with	O
highest	O
object	O
confidence	O
scores	O
are	O
fed	O
to	O
the	O
later	O
classifiers	B-Method
.	O
	
This	O
allows	O
us	O
to	O
utilize	O
CNNs	B-Method
that	O
have	O
stronger	O
representation	O
power	O
with	O
little	O
computational	B-Metric
overhead	I-Metric
.	O
	
ProNet	B-Method
is	O
highly	O
configurable	O
:	O
for	O
example	O
,	O
one	O
could	O
set	O
a	O
list	O
of	O
important	O
object	O
categories	O
,	O
and	O
only	O
verify	O
the	O
proposed	O
boxes	O
for	O
those	O
categories	O
.	O
	
Moreover	O
,	O
apart	O
from	O
a	O
traditional	O
chain	B-Method
-	I-Method
structured	I-Method
cascade	I-Method
,	O
we	O
show	O
that	O
it	O
is	O
also	O
possible	O
to	O
build	O
tree	B-Method
-	I-Method
structured	I-Method
cascades	I-Method
,	O
where	O
each	O
branch	O
handles	O
categories	O
from	O
a	O
particular	O
domain	O
(	O
set	O
of	O
vehicles	O
or	O
animals	O
)	O
.	O
	
In	O
summary	O
,	O
our	O
paper	O
makes	O
the	O
following	O
contributions	O
:	O
We	O
propose	O
ProNet	B-Method
,	O
a	O
cascaded	B-Method
neural	I-Method
network	I-Method
framework	I-Method
that	O
zooms	O
onto	O
promising	O
object	O
-	O
specific	O
boxes	O
for	O
efficient	O
object	B-Task
classification	I-Task
and	O
localization	B-Task
.	O
	
We	O
introduce	O
strategies	O
to	O
train	O
ProNet	B-Method
with	O
image	O
-	O
level	O
annotations	O
effectively	O
;	O
and	O
demonstrate	O
the	O
implementations	O
of	O
chain	B-Method
-	I-Method
and	I-Method
tree	I-Method
-	I-Method
structured	I-Method
cascades	I-Method
.	O
	
We	O
show	O
that	O
ProNet	B-Method
outperforms	O
previous	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
significantly	O
on	O
the	O
object	B-Task
classification	I-Task
and	O
point	O
-	O
based	O
localization	B-Task
tasks	O
of	O
the	O
PASCAL	O
VOC	B-Task
2012	O
dataset	O
and	O
the	O
recently	O
released	O
MS	B-Material
COCO	I-Material
dataset	I-Material
.	O
	
section	O
:	O
Related	O
Work	O
	
Object	B-Task
classification	I-Task
is	O
a	O
fundamental	O
problem	O
in	O
Computer	B-Task
Vision	I-Task
.	O
	
Earlier	O
work	O
focused	O
on	O
classification	B-Task
from	O
object	O
-	O
centric	O
images	O
.	O
	
They	O
usually	O
extract	O
hand	O
-	O
crafted	O
low	O
-	O
level	O
features	O
and	O
aggregate	O
the	O
features	O
into	O
image	O
-	O
level	O
feature	O
vectors	O
.	O
	
More	O
challenging	O
datasets	O
have	O
since	O
been	O
collected	O
.	O
	
They	O
are	O
of	O
larger	O
scale	O
,	O
and	O
contain	O
smaller	O
objects	O
which	O
could	O
be	O
partially	O
occluded	O
.	O
	
Recently	O
,	O
deep	B-Method
convolutional	I-Method
neural	I-Method
networks	I-Method
(	O
CNN	B-Method
)	O
have	O
achieved	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
performance	O
on	O
a	O
wide	O
range	O
of	O
visual	B-Task
recognition	I-Task
tasks	I-Task
,	O
including	O
object	B-Task
classification	I-Task
and	O
detection	B-Task
.	O
	
Although	O
CNNs	B-Method
require	O
large	O
amount	O
of	O
data	O
for	O
training	O
,	O
it	O
has	O
been	O
shown	O
that	O
they	O
are	O
able	O
to	O
learn	O
representations	O
that	O
generalize	O
to	O
other	O
tasks	O
.	O
	
Such	O
representations	O
can	O
be	O
adapted	O
to	O
image	B-Task
classification	I-Task
by	O
fine	B-Task
-	I-Task
tuning	I-Task
,	O
or	O
extracted	O
as	O
holistic	O
features	O
for	O
classification	B-Task
with	O
linear	B-Method
SVMs	I-Method
.	O
	
When	O
used	O
as	O
generic	B-Method
feature	I-Method
extractors	I-Method
,	O
feature	B-Method
aggregation	I-Method
techniques	I-Method
designed	O
for	O
hand	O
-	O
crafted	O
features	O
can	O
also	O
work	O
with	O
CNN	B-Method
embeddings	I-Method
and	O
achieve	O
competitive	O
performance	O
.	O
	
An	O
alternative	O
approach	O
for	O
object	B-Task
classification	I-Task
is	O
via	O
detection	B-Task
.	O
	
Among	O
those	O
utilizing	O
bounding	O
box	O
annotations	O
,	O
RCNN	B-Method
achieves	O
competitive	O
performance	O
by	O
directly	O
representing	O
image	O
boxes	O
with	O
CNN	O
features	O
and	O
learning	O
classifiers	B-Method
on	O
top	O
of	O
the	O
features	O
.	O
	
Object	O
proposal	B-Method
techniques	O
are	O
used	O
to	O
sample	O
the	O
image	O
patches	O
for	O
classification	B-Task
.	O
	
A	O
recent	O
framework	O
,	O
fast	B-Method
RCNN	I-Method
,	O
uses	O
fully	B-Method
-	I-Method
convolutional	I-Method
networks	I-Method
(	O
FCN	B-Method
)	O
to	O
generate	O
box	O
-	O
level	O
features	O
in	O
batch	O
,	O
and	O
is	O
thus	O
more	O
computational	O
efficient	O
.	O
	
Object	O
localization	B-Task
with	O
image	B-Task
-	I-Task
level	I-Task
annotations	I-Task
is	O
a	O
weakly	B-Task
-	I-Task
supervised	I-Task
problem	I-Task
.	O
	
It	O
can	O
be	O
formulated	O
as	O
a	O
multiple	B-Task
instance	I-Task
learning	I-Task
problem	I-Task
,	O
and	O
has	O
been	O
addressed	O
to	O
learn	O
concept	B-Task
detectors	I-Task
from	O
Internet	O
data	O
.	O
	
It	O
has	O
also	O
been	O
studied	O
for	O
object	B-Task
detection	I-Task
and	O
segmentation	B-Task
.	O
	
For	O
object	B-Task
classification	I-Task
,	O
Wei	O
et	O
al	O
.	O
treat	O
images	O
as	O
bags	O
of	O
patches	O
,	O
where	O
the	O
patches	O
are	O
selected	O
using	O
objectness	O
criteria	O
.	O
	
They	O
then	O
use	O
max	B-Method
pooling	I-Method
to	O
fine	O
-	O
tune	O
CNNs	B-Method
based	O
on	O
image	O
-	O
level	O
annotations	O
.	O
	
Oquab	O
et	O
al	O
.	O
follow	O
a	O
similar	O
approach	O
,	O
but	O
make	O
the	O
training	O
process	O
end	O
-	O
to	O
-	O
end	O
by	O
converting	O
CNNs	B-Method
into	O
FCNs	B-Method
.	O
	
The	O
proposal	B-Method
generation	O
network	O
in	O
ProNet	B-Method
is	O
also	O
based	O
on	O
FCN	B-Method
,	O
but	O
uses	O
a	O
multi	B-Method
-	I-Method
stream	I-Method
architecture	I-Method
and	O
cross	B-Method
-	I-Method
scale	I-Method
LSE	I-Method
pooling	I-Method
to	O
achieve	O
scale	B-Task
-	I-Task
awareness	I-Task
.	O
	
Cascaded	B-Method
classifiers	I-Method
are	O
a	O
well	O
-	O
studied	O
technique	O
in	O
Computer	B-Task
Vision	I-Task
.	O
	
Cascades	B-Method
with	O
CNNs	B-Method
have	O
been	O
explored	O
for	O
facial	O
point	O
detection	B-Task
,	O
face	O
detection	B-Task
and	O
pose	B-Task
estimation	I-Task
.	O
	
However	O
,	O
such	O
methods	O
require	O
fully	O
annotated	O
training	O
examples	O
.	O
	
ProNet	B-Method
adopts	O
the	O
cascade	B-Method
philosophy	I-Method
to	O
balance	O
speed	B-Metric
and	O
accuracy	B-Metric
,	O
but	O
does	O
not	O
require	O
object	O
bounding	O
boxes	O
for	O
training	O
.	O
	
Since	O
ProNet	B-Method
is	O
a	O
general	B-Method
object	I-Method
classifier	I-Method
,	O
it	O
can	O
also	O
be	O
extended	O
to	O
have	O
tree	O
structure	O
,	O
where	O
each	O
leaf	O
is	O
a	O
domain	O
expert	O
.	O
	
section	O
:	O
ProNet	B-Method
Framework	I-Method
	
ProNet	B-Method
has	O
two	O
basic	O
components	O
:	O
an	O
object	O
-	O
specific	O
box	O
proposal	B-Method
unit	O
,	O
and	O
a	O
verification	B-Method
unit	I-Method
.	O
	
For	O
each	O
image	O
,	O
for	O
each	O
object	O
category	O
,	O
the	O
box	O
proposal	B-Method
unit	O
generates	O
a	O
list	O
of	O
confidence	B-Metric
scores	I-Metric
of	O
the	O
presence	O
of	O
the	O
object	O
instances	O
,	O
and	O
the	O
coordinates	O
indicating	O
the	O
locations	O
of	O
the	O
objects	O
.	O
	
ProNet	B-Method
then	O
zooms	O
onto	O
image	O
boxes	O
with	O
higher	O
scores	O
to	O
further	O
verify	O
if	O
they	O
are	O
positive	O
or	O
hard	O
negatives	O
.	O
	
The	O
verification	B-Method
units	I-Method
can	O
either	O
take	O
all	O
boxes	O
,	O
which	O
forms	O
a	O
chain	O
structure	O
;	O
or	O
a	O
subset	O
of	O
boxes	O
corresponding	O
to	O
certain	O
domains	O
(	O
animal	O
)	O
,	O
which	O
forms	O
a	O
tree	O
structure	O
.	O
	
We	O
implement	O
these	O
two	O
units	O
with	O
convolutional	B-Method
neural	I-Method
networks	I-Method
.	O
	
Figure	O
[	O
reference	O
]	O
illustrates	O
the	O
overall	O
ProNet	B-Method
framework	I-Method
.	O
	
subsection	O
:	O
Proposal	B-Task
Generation	I-Task
	
The	O
first	O
stage	O
in	O
our	O
framework	O
is	O
to	O
generate	O
object	B-Task
-	I-Task
specific	I-Task
box	I-Task
proposals	I-Task
with	O
CNNs	B-Method
.	O
	
For	O
an	O
input	O
image	O
and	O
object	B-Task
category	I-Task
,	O
we	O
want	O
to	O
learn	O
a	O
proposal	B-Method
scoring	O
function	O
where	O
corresponds	O
to	O
the	O
location	O
of	O
a	O
rectangular	O
image	O
region	O
denoted	O
by	O
its	O
top	O
left	O
and	O
bottom	O
right	O
corners	O
.	O
	
A	O
typical	O
CNN	B-Method
architecture	I-Method
for	O
image	B-Task
classification	I-Task
task	I-Task
(	O
e.g.	O
AlexNet	B-Method
)	O
involves	O
a	O
hierarchy	B-Method
of	I-Method
convolutional	I-Method
layers	I-Method
and	O
fully	B-Method
connected	I-Method
layers	I-Method
.	O
	
The	O
convolutional	B-Method
layers	I-Method
operate	O
on	O
local	O
image	O
patches	O
to	O
extract	O
feature	B-Method
representations	I-Method
.	O
	
For	O
a	O
color	O
image	O
with	O
3	O
channels	O
,	O
the	O
convolutional	B-Method
layers	I-Method
generate	O
a	O
feature	O
map	O
of	O
elements	O
,	O
where	O
is	O
the	O
output	O
feature	O
dimension	O
.	O
and	O
correspond	O
to	O
the	O
width	O
and	O
height	O
of	O
the	O
feature	O
map	O
,	O
they	O
are	O
controlled	O
by	O
input	O
image	O
size	O
,	O
as	O
well	O
as	O
the	O
kernel	O
size	O
,	O
sampling	O
step	O
and	O
padding	O
size	O
of	O
the	O
convolutional	B-Method
layers	I-Method
.	O
	
The	O
fully	B-Method
connected	I-Method
layers	I-Method
serve	O
as	O
classifiers	B-Method
which	O
take	O
fixed	O
-	O
size	O
inputs	O
,	O
thus	O
require	O
the	O
width	O
and	O
height	O
of	O
input	O
images	O
to	O
be	O
fixed	O
.	O
	
Therefore	O
,	O
one	O
possible	O
way	O
to	O
compute	O
is	O
to	O
enumerate	O
locations	O
and	O
scales	O
in	O
a	O
sliding	O
window	O
fashion	O
or	O
with	O
bounding	B-Method
box	I-Method
proposals	I-Method
,	O
and	O
feed	O
such	O
image	O
regions	O
to	O
CNNs	B-Method
.	O
	
We	O
take	O
an	O
alternative	O
approach	O
based	O
on	O
fully	B-Method
convolutional	I-Method
networks	I-Method
(	O
e.g.	O
OverFeat	B-Method
)	O
.	O
	
Fully	B-Method
convolutional	I-Method
networks	I-Method
(	O
FCN	B-Method
)	I-Method
do	O
not	O
contain	O
fully	B-Method
-	I-Method
connected	I-Method
layers	I-Method
.	O
	
Rather	O
,	O
they	O
use	O
only	O
the	O
convolutional	B-Method
layers	I-Method
,	O
which	O
allows	O
them	O
to	O
process	O
images	O
of	O
arbitrary	O
sizes	O
.	O
	
The	O
outputs	O
of	O
FCNs	B-Method
are	O
in	O
the	O
form	O
of	O
feature	O
maps	O
,	O
where	O
is	O
the	O
number	O
of	O
categories	O
.	O
	
Each	O
element	O
in	O
a	O
feature	O
map	O
corresponds	O
to	O
the	O
activation	O
response	O
for	O
a	O
particular	O
category	O
over	O
a	O
certain	O
region	O
.	O
	
Such	O
regions	O
are	O
called	O
receptive	O
fields	O
for	O
the	O
activations	O
.	O
	
Compared	O
with	O
region	B-Method
sampling	I-Method
with	O
sliding	B-Method
windows	I-Method
or	O
bounding	B-Method
box	I-Method
proposals	I-Method
,	O
FCNs	B-Method
offer	O
a	O
seamless	O
solution	O
for	O
end	B-Task
-	I-Task
to	I-Task
-	I-Task
end	I-Task
training	I-Task
under	O
the	O
CNN	B-Method
framework	I-Method
,	O
and	O
also	O
naturally	O
allow	O
the	O
sharing	O
of	O
intermediate	O
features	O
over	O
overlapping	O
image	O
regions	O
.	O
	
Scale	B-Method
adaptation	I-Method
with	O
multi	B-Method
-	I-Method
stream	I-Method
FCNs	I-Method
.	O
	
One	O
issue	O
in	O
use	O
of	O
FCNs	B-Method
is	O
that	O
the	O
sizes	O
of	O
receptive	O
fields	O
are	O
typically	O
fixed	O
,	O
while	O
the	O
object	O
scales	O
may	O
vary	O
a	O
lot	O
.	O
	
We	O
address	O
this	O
problem	O
by	O
using	O
a	O
multi	B-Method
-	I-Method
stream	I-Method
architecture	I-Method
.	O
	
Assume	O
an	O
FCN	B-Method
has	O
been	O
trained	O
with	O
inputs	O
where	O
objects	O
have	O
been	O
resized	O
to	O
the	O
same	O
scale	O
.	O
	
We	O
expand	O
the	O
network	O
into	O
streams	O
,	O
where	O
every	O
stream	O
shares	O
the	O
same	O
parameters	O
as	O
the	O
pre	O
-	O
trained	O
one	O
.	O
	
Given	O
an	O
image	O
,	O
we	O
scale	O
it	O
to	O
different	O
sizes	O
and	O
feed	O
to	O
the	O
-	B-Method
stream	I-Method
FCN	I-Method
.	O
	
The	O
output	O
feature	O
map	O
of	O
each	O
stream	O
corresponds	O
to	O
a	O
different	O
scale	O
in	O
the	O
original	O
image	O
.	O
	
Training	O
with	O
image	O
-	O
level	O
annotations	O
.	O
	
When	O
object	O
bounding	O
boxes	O
are	O
available	O
,	O
training	O
FCNs	B-Method
is	O
straight	O
-	O
forward	O
:	O
one	O
could	O
either	O
crop	O
images	O
with	O
the	O
bounding	O
boxes	O
,	O
or	O
use	O
a	O
loss	B-Method
function	I-Method
which	O
operates	O
directly	O
on	O
feature	O
maps	O
and	O
takes	O
the	O
object	O
locations	O
into	O
account	O
.	O
	
As	O
such	O
supervision	B-Task
is	O
absent	O
,	O
we	O
need	O
to	O
aggregate	O
local	O
responses	O
into	O
global	O
ones	O
so	O
that	O
image	O
-	O
level	O
labels	O
can	O
be	O
used	O
for	O
training	B-Task
.	O
	
We	O
use	O
the	O
log	B-Method
-	I-Method
sum	I-Method
-	I-Method
exp	I-Method
(	I-Method
LSE	I-Method
)	O
	
pooling	B-Method
function	I-Method
applied	O
by	O
for	O
semantic	O
segmentation	B-Task
:	O
where	O
is	O
the	O
category	O
,	O
corresponds	O
to	O
the	O
-	O
th	O
stream	O
of	O
FCN	B-Method
,	O
correspond	O
to	O
location	O
in	O
the	O
feature	O
map	O
,	O
is	O
the	O
total	O
number	O
of	O
such	O
elements	O
and	O
is	O
a	O
hyper	O
parameter	O
.	O
	
The	O
function	O
’s	O
output	O
is	O
close	O
to	O
average	O
when	O
is	O
small	O
and	O
maximum	O
when	O
is	O
large	O
.	O
	
Setting	O
larger	O
makes	O
the	O
aggregation	O
focus	O
on	O
a	O
smaller	O
subset	O
of	O
image	O
boxes	O
,	O
and	O
has	O
the	O
potential	O
to	O
handle	O
smaller	O
objects	O
better	O
.	O
	
LSE	B-Method
pooling	I-Method
function	I-Method
can	O
be	O
implemented	O
as	O
a	O
layer	B-Method
in	O
a	O
neural	B-Method
network	I-Method
.	O
	
As	O
illustrated	O
in	O
Figure	O
[	O
reference	O
]	O
,	O
it	O
is	O
connected	O
to	O
the	O
final	O
layers	O
of	O
all	B-Method
-	I-Method
stream	I-Method
FCNs	I-Method
and	O
produces	O
a	O
dimensional	O
vector	O
for	O
each	O
image	O
.	O
	
We	O
then	O
compute	O
the	O
loss	O
for	O
each	O
category	O
and	O
back	O
-	O
propagate	O
the	O
error	O
gradients	O
to	O
the	O
earlier	O
layers	O
.	O
	
Computing	O
proposal	B-Method
scores	O
.	O
	
Once	O
the	O
FCNs	B-Method
have	O
been	O
trained	O
,	O
we	O
compute	O
proposal	B-Method
scores	O
from	O
the	O
feature	O
maps	O
.	O
	
Specifically	O
,	O
for	O
every	O
neuron	O
in	O
the	O
final	O
layer	O
of	O
single	B-Method
-	I-Method
stream	I-Method
FCN	I-Method
,	O
we	O
compute	O
its	O
receptive	O
field	O
and	O
use	O
it	O
as	O
the	O
location	O
;	O
the	O
corresponding	O
activation	O
of	O
the	O
neuron	O
is	O
used	O
as	O
proposal	B-Method
score	O
.	O
	
Although	O
the	O
exact	O
receptive	O
field	O
may	O
vary	O
due	O
to	O
different	O
padding	B-Method
strategies	I-Method
,	O
we	O
use	O
a	O
simple	O
estimation	O
which	O
has	O
been	O
reported	O
to	O
work	O
well	O
in	O
practice	O
.	O
	
Denote	O
the	O
sampling	O
stride	O
of	O
a	O
spatial	B-Method
convolutional	I-Method
layer	I-Method
as	O
and	O
the	O
kernel	O
size	O
of	O
a	O
max	B-Method
pooling	I-Method
layer	I-Method
as	O
,	O
the	O
overall	O
sampling	O
stride	O
is	O
given	O
by	O
where	O
is	O
the	O
collection	O
of	O
all	O
convolutional	B-Method
layers	I-Method
and	O
is	O
the	O
collection	O
of	O
all	O
max	B-Method
pooling	I-Method
layers	I-Method
.	O
	
Implementation	O
.	O
	
Our	B-Method
-	I-Method
stream	I-Method
FCNs	I-Method
are	O
implemented	O
with	O
Torch	B-Method
.	O
	
For	O
each	O
stream	O
,	O
we	O
use	O
the	O
CNN	B-Method
-	I-Method
M	I-Method
2048	I-Method
architecture	I-Method
proposed	O
in	O
.	O
	
It	O
has	O
5	O
convolutional	B-Method
layers	I-Method
and	O
3	O
fully	B-Method
-	I-Method
connected	I-Method
layers	I-Method
.	O
	
It	O
achieves	O
higher	O
accuracy	B-Metric
on	O
ImageNet	O
than	O
AlexNet	B-Method
,	O
while	O
being	O
faster	O
and	O
less	O
memory	O
consuming	O
than	O
very	O
deep	B-Method
CNNs	I-Method
.	O
	
We	O
use	O
the	O
model	O
parameters	O
released	O
by	O
the	O
authors	O
,	O
which	O
were	O
pre	O
-	O
trained	O
from	O
ImageNet	O
dataset	O
with	O
1	O
,	O
000	O
categories	O
.	O
	
We	O
convert	O
the	O
model	O
into	O
an	O
FCN	B-Method
by	O
replacing	O
the	O
three	O
fully	B-Method
-	I-Method
connected	I-Method
layers	I-Method
with	O
convolutional	B-Method
layers	I-Method
.	O
	
The	O
first	O
convolutional	B-Method
layer	I-Method
has	O
512	O
input	O
planes	O
,	O
4096	O
output	O
planes	O
and	O
kernel	O
size	O
of	O
6	O
.	O
	
The	O
second	O
has	O
4096	O
input	O
planes	O
,	O
2048	O
output	O
planes	O
and	O
kernel	O
size	O
of	O
1	O
.	O
	
Since	O
the	O
final	O
layer	O
is	O
task	O
-	O
specific	O
,	O
it	O
is	O
initialized	O
from	O
scratch	O
with	O
2048	O
input	O
planes	O
,	O
output	O
planes	O
and	O
kernel	O
size	O
of	O
1	O
.	O
	
To	O
adapt	O
the	O
model	O
parameters	O
for	O
object	B-Task
classification	I-Task
on	O
different	O
datasets	O
,	O
we	O
only	O
fine	O
-	O
tune	O
the	O
final	O
two	O
layers	O
and	O
freeze	O
the	O
model	O
parameters	O
from	O
previous	O
layers	O
.	O
	
The	O
sampling	O
stride	O
of	O
feature	O
maps	O
is	O
32	O
pixels	O
,	O
and	O
the	O
window	O
size	O
is	O
223	O
pixels	O
.	O
	
We	O
set	O
the	O
number	O
of	O
streams	O
to	O
be	O
3	O
.	O
	
During	O
training	O
,	O
all	O
three	O
streams	O
share	O
the	O
same	O
set	O
of	O
parameters	O
.	O
	
To	O
facilitate	O
training	O
with	O
mini	B-Method
-	I-Method
batches	I-Method
,	O
every	O
image	O
is	O
rescaled	O
to	O
,	O
and	O
pixels	O
.	O
	
As	O
the	O
aspect	O
ratios	O
of	O
images	O
could	O
be	O
different	O
,	O
we	O
rescale	O
the	O
longer	O
edge	O
to	O
300	O
,	O
500	O
and	O
700	O
respectively	O
,	O
and	O
fill	O
the	O
empty	O
pixels	O
by	O
mirroring	O
the	O
images	O
.	O
	
Traditional	O
cross	B-Method
entropy	I-Method
loss	I-Method
for	O
multi	B-Task
-	I-Task
class	I-Task
classification	I-Task
introduces	O
competition	O
between	O
different	O
classes	O
,	O
thus	O
it	O
is	O
not	O
suitable	O
for	O
images	O
with	O
multiple	O
labels	O
.	O
	
We	O
compute	O
the	O
loss	B-Metric
with	O
binary	B-Metric
cross	I-Metric
entropy	I-Metric
criteria	I-Metric
for	O
each	O
class	O
separately	O
,	O
and	O
sum	O
up	O
the	O
error	O
gradients	O
from	O
losses	O
of	O
all	O
classes	O
for	O
back	B-Method
-	I-Method
propagation	I-Method
.	O
	
subsection	O
:	O
Cascade	B-Method
-	I-Method
style	I-Method
Proposal	I-Method
Verification	I-Method
	
By	O
setting	O
thresholds	O
on	O
proposal	B-Method
scores	O
,	O
a	O
small	O
subset	O
of	O
image	O
boxes	O
which	O
might	O
contain	O
objects	O
are	O
selected	O
.	O
	
Similar	O
to	O
object	O
detection	B-Task
frameworks	O
,	O
we	O
run	O
CNN	B-Method
classifiers	I-Method
on	O
the	O
selected	O
boxes	O
.	O
	
The	O
proposal	B-Method
step	O
also	O
serves	O
as	O
a	O
filter	B-Method
whose	O
goal	O
is	O
to	O
preserve	O
the	O
object	O
boxes	O
with	O
high	O
recall	B-Metric
rate	I-Metric
,	O
while	O
removing	O
the	O
easy	O
negatives	O
.	O
	
The	O
verification	B-Method
classifiers	I-Method
then	O
address	O
a	O
more	O
focused	O
problem	O
on	O
a	O
smaller	O
set	O
of	O
instances	O
.	O
	
Connecting	O
the	O
two	O
steps	O
is	O
essentially	O
the	O
same	O
as	O
training	O
a	O
cascade	B-Method
of	I-Method
classifiers	I-Method
.	O
	
Verification	B-Method
network	I-Method
architecture	I-Method
.	O
	
As	O
a	O
later	O
classifier	B-Method
in	O
the	O
cascade	B-Method
,	O
accuracy	B-Metric
is	O
more	O
important	O
than	O
speed	B-Metric
.	O
	
We	O
choose	O
the	O
VGG	B-Method
-	I-Method
16	I-Method
network	I-Method
architecture	I-Method
.	O
	
Compared	O
with	O
AlexNet	B-Method
variants	I-Method
,	O
it	O
offers	O
better	O
accuracy	B-Metric
for	O
most	O
visual	B-Task
recognition	I-Task
tasks	I-Task
,	O
but	O
is	O
also	O
slower	O
and	O
more	O
memory	O
demanding	O
.	O
	
We	O
use	O
the	O
VGG	B-Method
-	I-Method
16	I-Method
model	I-Method
parameters	I-Method
released	O
by	O
the	O
authors	O
,	O
which	O
was	O
trained	O
on	O
1	O
,	O
000	O
ImageNet	O
categories	O
.	O
	
We	O
use	O
the	O
same	O
binary	B-Metric
cross	I-Metric
entropy	I-Metric
criterion	I-Metric
to	O
compute	O
losses	O
.	O
	
To	O
make	O
the	O
training	O
process	O
faster	O
,	O
we	O
only	O
fine	O
-	O
tune	O
the	O
final	O
two	O
fully	B-Method
-	I-Method
connected	I-Method
layers	I-Method
and	O
freeze	O
all	O
previous	O
layers	O
.	O
	
InputInput	O
OutputOutput	O
Training	O
images	O
with	O
proposal	B-Method
scores	O
,	O
batch	O
size	O
,	O
threshold	O
stopping	O
criteria	O
not	O
met	O
Randomly	O
select	O
images	O
from	O
;	O
Initialize	O
mini	O
-	O
batch	O
;	O
has	O
proposal	B-Method
with	O
score	O
Randomly	O
sample	O
a	O
proposal	B-Method
where	O
;	O
Set	O
the	O
sample	O
	
’s	O
active	O
class	O
to	O
	
;	O
Add	O
proposed	O
region	O
to	O
;	O
Resize	O
and	O
add	O
full	O
image	O
to	O
;	O
Set	O
all	O
classes	O
as	O
active	O
;	O
Forward	O
pass	O
with	O
;	O
Compute	O
loss	O
for	O
the	O
active	O
class	O
of	O
each	O
sample	O
;	O
Update	O
model	B-Method
parameters	I-Method
.	O
	
Mini	B-Method
-	I-Method
batch	I-Method
sampling	I-Method
algorithm	I-Method
for	O
training	O
cascade	B-Method
classifier	I-Method
with	O
stochastic	B-Method
gradient	I-Method
descent	I-Method
.	O
	
Training	B-Method
strategy	I-Method
for	O
the	O
cascade	B-Method
.	O
	
Ideally	O
,	O
we	O
want	O
the	O
verification	B-Method
network	I-Method
to	O
handle	O
hard	O
examples	O
from	O
both	O
positive	O
and	O
negative	O
data	O
.	O
	
When	O
a	O
proposed	O
region	O
from	O
an	O
image	O
not	O
containing	O
a	O
given	O
label	O
has	O
a	O
high	O
score	O
of	O
that	O
class	O
,	O
we	O
know	O
it	O
is	O
a	O
hard	O
negative	O
.	O
	
However	O
,	O
it	O
is	O
impossible	O
to	O
tell	O
a	O
hard	O
positive	O
from	O
background	O
without	O
using	O
bounding	O
box	O
annotations	O
.	O
	
We	O
attempt	O
to	O
avoid	O
using	O
background	O
by	O
selecting	O
only	O
the	O
top	O
scoring	O
image	O
region	O
for	O
each	O
positive	O
class	O
.	O
	
This	O
results	O
in	O
significant	O
over	O
-	O
fitting	O
and	O
poor	O
generalizability	O
for	O
the	O
trained	O
verification	B-Method
net	I-Method
.	O
	
The	O
main	O
problem	O
with	O
the	O
above	O
sampling	B-Method
strategy	I-Method
is	O
that	O
for	O
positive	O
instances	O
,	O
only	O
easy	O
examples	O
which	O
have	O
been	O
learned	O
well	O
are	O
preserved	O
.	O
	
To	O
fix	O
this	O
,	O
we	O
use	O
a	O
random	B-Method
sampling	I-Method
strategy	I-Method
as	O
described	O
in	O
Algorithm	O
[	O
reference	O
]	O
.	O
	
For	O
each	O
image	O
,	O
we	O
randomly	O
select	O
an	O
image	O
box	O
whose	O
proposal	B-Method
score	O
is	O
higher	O
than	O
threshold	O
for	O
class	O
.	O
	
In	O
practice	O
,	O
the	O
threshold	O
is	O
set	O
to	O
a	O
relative	O
low	O
value	O
(	O
)	O
.	O
	
If	O
is	O
labeled	O
as	O
positive	O
for	O
the	O
image	O
,	O
we	O
treat	O
the	O
box	O
as	O
a	O
positive	O
instance	O
(	O
though	O
it	O
might	O
belong	O
to	O
background	O
)	O
,	O
and	O
otherwise	O
negative	O
.	O
	
Note	O
that	O
the	O
sampled	O
box	O
could	O
be	O
easy	O
negatives	O
for	O
classes	O
beyond	O
.	O
	
To	O
avoid	O
oversampling	O
the	O
easy	O
negatives	O
,	O
we	O
set	O
as	O
the	O
active	O
class	O
during	O
back	B-Method
-	I-Method
propagation	I-Method
and	O
only	O
compute	O
the	O
loss	O
for	O
the	O
active	O
class	O
.	O
	
Inference	B-Method
with	O
cascade	B-Method
.	O
	
During	O
inference	B-Method
,	O
an	O
image	O
is	O
passed	O
to	O
the	O
proposal	B-Method
generation	I-Method
FCN	I-Method
to	O
compute	O
proposal	B-Method
scores	O
.	O
	
A	O
small	O
subset	O
of	O
proposed	O
boxes	O
with	O
high	O
scores	O
are	O
then	O
passed	O
to	O
the	O
verification	B-Method
network	I-Method
.	O
	
For	O
each	O
class	O
,	O
we	O
select	O
the	O
top	O
scoring	O
proposals	O
if	O
the	O
scores	O
are	O
higher	O
than	O
threshold	O
.	O
	
We	O
then	O
use	O
the	O
following	O
equation	O
to	O
combine	O
the	O
outputs	O
from	O
both	O
networks	O
:	O
where	O
is	O
the	O
set	O
of	O
selected	O
proposals	O
for	O
class	O
,	O
is	O
the	O
score	O
of	O
class	O
from	O
the	O
proposal	B-Method
network	I-Method
after	O
LSE	B-Method
pooling	I-Method
,	O
and	O
is	O
the	O
verification	B-Method
network	I-Method
’s	O
output	O
for	O
class	O
on	O
region	O
.	O
	
When	O
no	O
proposal	B-Method
is	O
selected	O
,	O
we	O
preserve	O
scores	O
from	O
the	O
proposal	B-Method
network	I-Method
without	O
calibration	B-Method
as	O
they	O
are	O
typically	O
low	O
.	O
	
Discussion	O
.	O
	
Decomposing	O
classification	B-Task
into	O
cascade	O
of	O
proposal	B-Method
and	O
verification	B-Method
networks	I-Method
allows	O
the	O
system	O
to	O
achieve	O
high	O
accuracy	B-Metric
while	O
maintaining	O
a	O
reasonable	O
computational	B-Metric
cost	I-Metric
.	O
	
It	O
is	O
also	O
a	O
flexible	O
framework	O
for	O
different	O
design	O
choices	O
.	O
	
For	O
example	O
,	O
one	O
could	O
decide	O
to	O
verify	O
a	O
subset	O
of	O
object	O
classes	O
which	O
require	O
higher	O
accuracy	B-Metric
.	O
	
With	O
the	O
cascade	B-Method
training	I-Method
algorithm	I-Method
,	O
we	O
can	O
build	O
tree	B-Method
-	I-Method
structured	I-Method
cascaded	I-Method
neural	I-Method
networks	I-Method
,	O
where	O
each	O
branch	O
focuses	O
on	O
a	O
subset	O
of	O
categories	O
.	O
	
We	O
can	O
also	O
extend	O
the	O
cascade	B-Method
to	O
have	O
more	O
stages	O
,	O
and	O
train	O
the	O
new	O
stages	O
with	O
newly	O
annotated	O
training	O
data	O
.	O
	
Figure	O
[	O
reference	O
]	O
illustrates	O
these	O
structures	O
.	O
	
section	O
:	O
Experiments	O
	
Experimental	O
setup	O
.	O
	
We	O
work	O
with	O
the	O
PASCAL	O
VOC	B-Task
2012	O
dataset	O
and	O
the	O
MS	B-Material
COCO	I-Material
dataset	I-Material
.	O
	
VOC	B-Task
2012	O
has	O
5	O
,	O
000	O
images	O
for	O
training	O
,	O
5	O
,	O
000	O
for	O
validation	B-Task
and	O
10	O
,	O
000	O
for	O
testing	O
.	O
	
There	O
are	O
20	O
object	O
classes	O
in	O
total	O
.	O
	
COCO	B-Material
has	O
80	O
,	O
000	O
images	O
for	O
training	O
and	O
40	O
,	O
000	O
images	O
for	O
validation	B-Task
.	O
	
It	O
has	O
80	O
object	O
classes	O
in	O
12	O
super	O
-	O
categories	O
.	O
	
We	O
evaluated	O
ProNet	B-Method
on	O
object	B-Task
classification	I-Task
and	O
point	O
-	O
based	O
object	O
localization	B-Task
tasks	O
.	O
	
For	O
object	B-Task
classification	I-Task
,	O
we	O
use	O
the	O
average	B-Metric
precision	I-Metric
metric	I-Metric
.	O
	
We	O
used	O
VOC	B-Task
’s	O
result	O
server	O
to	O
compute	O
average	B-Metric
precisions	I-Metric
on	O
the	O
VOC	B-Task
2012	O
dataset	O
.	O
	
For	O
point	O
-	O
based	O
object	O
localization	B-Task
,	O
we	O
use	O
the	O
criteria	O
introduced	O
in	O
.	O
	
For	O
every	O
image	O
and	O
every	O
class	O
,	O
we	O
output	O
a	O
location	O
with	O
maximum	O
response	O
for	O
that	O
class	O
.	O
	
The	O
location	O
is	O
deemed	O
correct	O
if	O
it	O
falls	O
into	O
any	O
bounding	O
box	O
associated	O
with	O
that	O
class	O
,	O
with	O
a	O
tolerance	O
of	O
18	O
pixels	O
as	O
used	O
in	O
.	O
	
This	O
information	O
is	O
then	O
used	O
to	O
compute	O
average	B-Metric
precision	I-Metric
.	O
	
Although	O
object	O
extent	O
is	O
not	O
evaluated	O
,	O
the	O
metric	O
remains	O
challenging	O
as	O
shown	O
by	O
.	O
	
To	O
generate	O
localization	B-Task
coordinates	O
for	O
evaluation	O
,	O
we	O
kept	O
track	O
of	O
the	O
image	O
boxes	O
which	O
give	O
highest	O
responses	O
at	O
each	O
stage	O
,	O
and	O
used	O
the	O
center	O
point	O
of	O
the	O
selected	O
boxes	O
.	O
	
We	O
tried	O
different	O
values	O
of	O
hyper	O
-	O
parameter	O
for	O
LSE	B-Method
pooling	I-Method
,	O
and	O
found	O
that	O
generally	O
gave	O
good	O
performance	O
.	O
	
We	O
fixed	O
in	O
all	O
the	O
following	O
experiments	O
.	O
	
We	O
used	O
the	O
stochastic	B-Method
gradient	I-Method
descent	I-Method
algorithm	I-Method
for	O
training	O
.	O
	
To	O
train	O
proposal	B-Method
network	I-Method
,	O
the	O
learning	B-Metric
rate	I-Metric
was	O
set	O
to	O
0.01	O
;	O
to	O
train	O
verification	B-Method
network	I-Method
,	O
the	O
learning	B-Metric
rate	I-Metric
was	O
set	O
to	O
0.001	O
.	O
	
We	O
set	O
the	O
filtering	O
threshold	O
for	O
cascade	O
to	O
0.1	O
.	O
	
Which	O
pooling	B-Method
method	I-Method
is	O
better	O
?	O
	
We	O
compare	O
maximum	B-Method
pooling	I-Method
,	O
average	B-Method
pooling	I-Method
and	O
LSE	B-Method
pooling	I-Method
methods	I-Method
to	O
train	O
proposal	B-Method
network	I-Method
with	O
image	B-Task
-	I-Task
level	I-Task
supervision	I-Task
.	O
	
Table	O
[	O
reference	O
]	O
lists	O
the	O
classification	O
and	O
localization	B-Task
performance	O
of	O
the	O
three	O
different	O
pooling	B-Method
methods	I-Method
.	O
	
We	O
can	O
see	O
that	O
LSE	B-Method
achieves	O
the	O
best	O
classification	O
mAP	B-Metric
.	O
	
Average	B-Method
pooling	I-Method
is	O
3.7	O
%	O
worse	O
than	O
LSE	B-Method
,	O
which	O
we	O
believe	O
is	O
because	O
it	O
assigns	O
equal	O
importance	O
to	O
foreground	O
and	O
background	O
.	O
	
Max	B-Method
pooling	I-Method
is	O
1.4	O
%	O
worse	O
;	O
compared	O
with	O
LSE	B-Method
pooling	I-Method
,	O
it	O
only	O
uses	O
a	O
single	O
patch	O
to	O
generate	O
image	O
-	O
level	O
score	O
,	O
thus	O
is	O
more	O
sensitive	O
to	O
noise	O
and	O
model	B-Method
initialization	I-Method
during	O
training	B-Task
.	O
	
We	O
also	O
generated	O
visualizations	O
to	O
study	O
the	O
impact	O
of	O
pooling	B-Method
method	I-Method
on	O
trained	B-Method
models	I-Method
.	O
	
Figure	O
[	O
reference	O
]	O
shows	O
heat	O
maps	O
of	O
the	O
class	O
train	O
when	O
different	O
models	O
are	O
applied	O
to	O
the	O
same	O
image	O
.	O
	
We	O
can	O
see	O
that	O
the	O
model	O
trained	O
by	O
average	B-Method
pooling	I-Method
has	O
high	O
activations	O
not	O
only	O
on	O
the	O
train	O
but	O
also	O
on	O
part	O
of	O
the	O
background	O
.	O
	
For	O
max	B-Method
pooling	I-Method
,	O
only	O
the	O
wheel	O
of	O
the	O
train	O
has	O
high	O
response	O
,	O
presumably	O
because	O
it	O
is	O
the	O
most	O
discriminative	O
for	O
the	O
train	O
.	O
	
Model	O
trained	O
by	O
LSE	B-Method
pooling	I-Method
has	O
high	O
response	O
on	O
the	O
train	O
,	O
but	O
not	O
on	O
the	O
background	O
.	O
	
Does	O
cascade	O
help	O
?	O
	
We	O
study	O
the	O
impact	O
of	O
adding	O
cascaded	B-Method
classifiers	I-Method
on	O
classification	O
and	O
localization	B-Task
performance	O
.	O
	
We	O
first	O
use	O
a	O
single	O
level	O
of	O
cascade	B-Method
with	O
one	O
multi	B-Method
-	I-Method
scale	I-Method
FCN	I-Method
and	O
one	O
verification	B-Method
network	I-Method
.	O
	
For	O
each	O
image	O
and	O
each	O
class	O
,	O
we	O
selected	O
the	O
top	O
3	O
regions	O
per	O
scale	O
if	O
their	O
scores	O
are	O
higher	O
than	O
0.1	O
.	O
	
The	O
average	O
number	O
of	O
regions	O
to	O
be	O
verified	O
is	O
24	O
per	O
image	O
.	O
	
In	O
Table	O
[	O
reference	O
]	O
,	O
we	O
can	O
see	O
that	O
on	O
PASCAL	O
VOC	B-Task
2012	O
,	O
using	O
a	O
cascade	B-Method
helps	O
improve	O
classification	O
mAP	B-Metric
by	O
3.3	O
%	O
and	O
localization	B-Task
mAP	I-Metric
by	O
2.9	O
%	O
.	O
	
Is	O
a	O
longer	O
cascade	O
better	O
?	O
	
We	O
are	O
interested	O
in	O
observing	O
how	O
the	O
performance	O
changes	O
with	O
more	O
levels	O
of	O
cascade	O
.	O
	
For	O
this	O
purpose	O
,	O
we	O
first	O
trained	O
another	O
set	O
of	O
proposal	B-Method
and	O
verification	B-Method
networks	I-Method
using	O
PASCAL	O
VOC	B-Task
data	O
alone	O
,	O
but	O
found	O
that	O
the	O
network	O
overfitted	O
easily	O
.	O
	
Since	O
the	O
training	O
set	O
of	O
VOC	B-Task
2012	O
has	O
only	O
5	O
,	O
000	O
images	O
,	O
we	O
found	O
that	O
the	O
first	O
set	O
of	O
proposal	B-Method
and	O
verification	B-Method
networks	I-Method
“	O
perfectly	O
solved	O
”	O
this	O
training	O
set	O
,	O
leaving	O
little	O
room	O
to	O
improve	O
its	O
generalizability	O
.	O
	
In	O
light	O
of	O
this	O
,	O
we	O
used	O
the	O
80	O
,	O
000	O
images	O
from	O
COCO	B-Material
training	I-Material
set	I-Material
as	O
complementary	O
data	O
source	O
.	O
	
It	O
covers	O
the	O
20	O
categories	O
used	O
in	O
VOC	B-Task
but	O
also	O
has	O
60	O
other	O
categories	O
.	O
	
Rather	O
than	O
re	O
-	O
training	O
all	O
the	O
networks	O
by	O
combining	O
VOC	B-Task
and	O
COCO	B-Material
data	I-Material
,	O
we	O
take	O
that	O
the	O
previous	O
CNNs	B-Method
in	O
the	O
cascade	O
have	O
already	O
been	O
trained	O
and	O
fixed	O
,	O
and	O
only	O
train	O
new	O
CNNs	B-Method
with	O
the	O
extra	O
data	O
.	O
	
Note	O
that	O
our	O
cascade	B-Method
architecture	I-Method
offers	O
a	O
natural	O
way	O
to	O
select	O
the	O
challenging	O
instances	O
from	O
such	O
incoming	O
images	O
.	O
	
The	O
final	O
row	O
in	O
Table	O
[	O
reference	O
]	O
shows	O
the	O
mAPs	O
after	O
adding	O
a	O
new	O
set	O
of	O
cascades	B-Method
trained	O
from	O
COCO	B-Material
images	I-Material
.	O
	
We	O
can	O
see	O
that	O
it	O
offers	O
another	O
1	O
%	O
improvement	O
over	O
the	O
previous	O
cascade	O
,	O
which	O
indicates	O
that	O
it	O
is	O
desirable	O
to	O
train	O
a	O
longer	O
cascade	O
when	O
more	O
training	O
data	O
becomes	O
available	O
.	O
	
Expanding	O
cascades	O
into	O
trees	O
.	O
	
We	O
also	O
investigated	O
the	O
effect	O
of	O
building	O
tree	O
-	O
structured	O
cascades	O
.	O
	
COCO	B-Material
dataset	I-Material
is	O
used	O
for	O
evaluation	O
as	O
it	O
has	O
3	O
times	O
more	O
categories	O
than	O
VOC	B-Task
.	O
	
We	O
trained	O
12	O
verification	B-Method
networks	I-Method
corresponding	O
to	O
the	O
12	O
super	O
-	O
categories	O
of	O
COCO	B-Material
.	O
	
Each	O
network	O
focuses	O
on	O
a	O
single	O
super	O
-	O
category	O
,	O
and	O
processes	O
the	O
sampled	O
boxes	O
whose	O
active	O
classes	O
belong	O
to	O
that	O
super	O
-	O
category	O
.	O
	
At	O
test	O
time	O
,	O
each	O
proposed	O
box	O
only	O
goes	O
through	O
a	O
single	O
root	O
to	O
leaf	O
path	O
in	O
the	O
tree	O
.	O
	
The	O
final	O
row	O
of	O
Table	O
[	O
reference	O
]	O
shows	O
its	O
classification	B-Task
and	O
localization	B-Task
performance	O
.	O
	
We	O
can	O
see	O
that	O
compared	O
with	O
the	O
chain	B-Method
structured	I-Method
cascade	I-Method
,	O
tree	B-Method
-	I-Method
structured	I-Method
cascade	I-Method
achieves	O
better	O
performance	O
,	O
probably	O
because	O
it	O
trains	O
the	O
neural	B-Method
networks	I-Method
to	O
be	O
focused	O
on	O
a	O
small	O
subset	O
of	O
similar	O
categories	O
.	O
	
Comparison	O
with	O
detection	B-Task
based	O
approaches	O
.	O
	
We	O
compare	O
our	O
proposed	O
framework	O
with	O
two	O
recent	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
object	O
detection	B-Task
methods	O
:	O
RCNN	B-Method
and	O
Fast	B-Method
RCNN	I-Method
.	O
	
Unlike	O
our	O
framework	O
,	O
they	O
require	O
bounding	O
box	O
annotations	O
for	O
training	O
.	O
	
Both	O
methods	O
use	O
selective	B-Method
search	I-Method
to	O
generate	O
object	O
proposals	O
and	O
CNNs	B-Method
for	O
classification	B-Task
.	O
	
RCNN	B-Method
uses	O
AlexNet	B-Method
pre	O
-	O
trained	O
from	O
ImageNet	B-Method
,	O
while	O
fast	B-Method
RCNN	I-Method
uses	O
VGG	B-Method
-	I-Method
16	I-Method
pre	O
-	O
trained	O
from	O
ImageNet	O
.	O
	
To	O
generate	O
classification	O
and	O
localization	B-Task
results	O
,	O
for	O
each	O
class	O
we	O
select	O
the	O
detection	B-Task
output	O
with	O
maximum	O
confidence	O
score	O
,	O
and	O
use	O
the	O
center	O
of	O
the	O
detected	O
bounding	O
box	O
for	O
localization	B-Task
evaluation	O
.	O
	
We	O
first	O
fix	O
the	O
number	O
of	O
window	O
proposals	O
to	O
1000	O
for	O
RCNN	B-Method
and	O
fast	B-Method
RCNN	I-Method
.	O
	
Table	O
[	O
reference	O
]	O
shows	O
the	O
performance	O
comparison	O
.	O
	
We	O
can	O
see	O
that	O
for	O
classification	B-Task
,	O
our	O
proposed	O
framework	O
outperforms	O
both	O
RCNN	B-Method
and	O
fast	B-Method
RCNN	I-Method
.	O
	
For	O
localization	B-Task
,	O
our	O
proposed	O
framework	O
outperforms	O
RCNN	B-Method
,	O
but	O
is	O
4	O
%	O
worse	O
than	O
fast	B-Method
RCNN	I-Method
.	O
	
We	O
also	O
study	O
the	O
impact	O
of	O
number	O
of	O
proposed	O
boxes	O
on	O
our	O
system	O
	
’s	O
performance	O
.	O
	
For	O
this	O
purpose	O
,	O
we	O
let	O
the	O
proposal	B-Method
network	I-Method
select	O
top	O
regions	O
per	O
scale	O
for	O
each	O
class	O
,	O
and	O
compute	O
the	O
average	O
number	O
of	O
proposed	O
boxes	O
per	O
image	O
.	O
	
For	O
comparison	O
,	O
we	O
ask	O
fast	O
RCNN	B-Method
to	O
use	O
up	O
to	O
10	O
,	O
50	O
,	O
500	O
and	O
1000	O
selective	O
search	O
proposals	O
per	O
image	O
.	O
	
Table	O
[	O
reference	O
]	O
shows	O
the	O
classification	O
and	O
localization	B-Task
performances	O
respectively	O
.	O
	
We	O
can	O
see	O
that	O
ProNet	B-Method
is	O
quite	O
robust	O
to	O
the	O
number	O
of	O
proposed	O
boxes	O
,	O
and	O
achieves	O
reasonably	O
good	O
performance	O
with	O
only	O
9	O
boxes	O
on	O
average	O
.	O
	
This	O
confirms	O
that	O
ProNet	B-Method
offers	O
better	O
accuracy	B-Metric
with	O
relatively	O
small	O
computational	B-Metric
overhead	I-Metric
.	O
	
Meanwhile	O
,	O
fast	O
RCNN	B-Method
requires	O
many	O
more	O
proposals	O
to	O
reach	O
peak	O
performance	O
,	O
presumably	O
because	O
the	O
selective	O
search	O
proposals	O
are	O
for	O
general	O
objectness	O
and	O
not	O
optimized	O
for	O
object	B-Task
classification	I-Task
in	O
cascade	B-Task
fashion	I-Task
.	O
	
Comparison	O
with	O
other	O
weakly	B-Method
-	I-Method
supervised	I-Method
methods	I-Method
.	O
	
We	O
compare	O
ProNet	B-Method
with	O
several	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
object	B-Task
classification	I-Task
frameworks	O
.	O
	
Classification	B-Task
and	O
localization	B-Task
performance	O
on	O
PASCAL	O
VOC	B-Task
2012	O
are	O
shown	O
in	O
Table	O
[	O
reference	O
]	O
and	O
Table	O
[	O
reference	O
]	O
respectively	O
.	O
	
Table	O
[	O
reference	O
]	O
and	O
Figure	O
[	O
reference	O
]	O
show	O
results	O
and	O
localization	B-Task
examples	O
on	O
COCO	B-Material
dataset	I-Material
.	O
	
Among	O
the	O
compared	O
systems	O
,	O
Oquab	O
et	O
al	O
.	O
and	O
NUS	B-Method
-	I-Method
HCP	I-Method
use	O
CNNs	B-Method
pre	O
-	O
trained	O
on	O
the	O
expanded	O
ImageNet	O
data	O
with	O
more	O
than	O
1500	O
categories	O
,	O
which	O
has	O
been	O
shown	O
to	O
be	O
useful	O
for	O
classification	B-Task
.	O
	
Since	O
ProNet	B-Method
uses	O
cascades	B-Method
or	O
trees	B-Method
of	I-Method
CNNs	I-Method
,	O
it	O
can	O
apply	O
a	O
more	O
powerful	O
CNN	B-Method
model	I-Method
VGG	I-Method
-	I-Method
16	I-Method
with	O
small	O
computational	B-Metric
overhead	I-Metric
.	O
	
This	O
helps	O
our	O
system	O
outperform	O
most	O
of	O
the	O
previous	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
systems	O
significantly	O
on	O
both	O
datasets	O
.	O
	
ProNet	B-Method
is	O
also	O
slightly	O
better	O
than	O
Simonyan	O
et	O
al	O
.	O
which	O
extracts	O
VGG	O
-	O
16	O
features	O
at	O
three	O
different	O
scales	O
over	O
full	O
images	O
.	O
	
Their	O
system	O
is	O
3x	O
to	O
6x	O
slower	O
than	O
our	O
cascade	B-Method
at	O
test	O
time	O
.	O
	
Limitation	O
.	O
	
We	O
evaluate	O
ProNet	B-Method
using	O
the	O
standard	O
IOU	B-Metric
metric	I-Metric
,	O
which	O
considers	O
object	O
extent	O
as	O
well	O
as	O
location	O
.	O
	
Since	O
the	O
boxes	O
generated	O
by	O
our	O
proposal	B-Method
CNN	O
have	O
fixed	O
aspect	O
ratios	O
,	O
we	O
follow	O
to	O
aggregate	O
the	O
heat	O
maps	O
over	O
1000	O
bounding	B-Method
box	I-Method
proposals	I-Method
generated	O
by	O
selective	B-Method
search	I-Method
per	O
image	O
.	O
	
No	O
bounding	B-Method
box	I-Method
regression	I-Method
is	O
conducted	O
.	O
	
Cascade	B-Method
CNN	I-Method
is	O
then	O
used	O
to	O
verify	O
the	O
high	O
-	O
scoring	O
proposals	O
.	O
	
On	O
PASCAL	O
VOC	B-Task
2012	O
validation	O
set	O
,	O
our	O
proposal	B-Method
CNN	O
has	O
an	O
mAP	B-Metric
of	O
13.0	O
%	O
when	O
overlap	B-Metric
threshold	I-Metric
is	O
0.5	O
.	O
	
The	O
cascade	B-Method
CNN	I-Method
improves	O
the	O
mAP	B-Metric
to	O
15.5	O
%	O
.	O
	
Although	O
both	O
results	O
are	O
higher	O
than	O
11.7	O
%	O
as	O
reported	O
by	O
,	O
there	O
is	O
still	O
a	O
huge	O
gap	O
between	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
object	O
detection	B-Task
pipelines	O
.	O
	
Our	O
proposal	B-Method
network	I-Method
tends	O
to	O
select	O
the	O
most	O
discriminative	O
/	O
confusing	O
parts	O
of	O
objects	O
,	O
which	O
is	O
good	O
for	O
cascade	B-Task
classification	I-Task
but	O
bad	O
for	O
getting	O
full	B-Task
object	I-Task
extents	I-Task
.	O
	
Separating	B-Task
and	O
counting	B-Task
multiple	I-Task
objects	I-Task
are	O
also	O
challenging	O
issues	O
.	O
	
section	O
:	O
Conclusion	O
	
We	O
proposed	O
ProNet	B-Method
,	O
a	O
cascaded	B-Method
neural	I-Method
network	I-Method
for	O
object	B-Task
classification	I-Task
and	O
localization	B-Task
.	O
	
ProNet	B-Method
learns	O
to	O
propose	O
object	O
-	O
specific	O
boxes	O
by	O
multi	B-Method
-	I-Method
scale	I-Method
FCNs	I-Method
trained	O
from	O
image	O
-	O
level	O
annotations	O
.	O
	
It	O
then	O
sends	O
a	O
small	O
subset	O
of	O
promising	O
boxes	O
to	O
latter	O
CNNs	B-Method
for	O
verification	B-Task
.	O
	
Detailed	O
experimental	O
evaluations	O
have	O
shown	O
the	O
effectiveness	O
of	O
ProNet	B-Method
on	O
the	O
challenging	O
PASCAL	O
VOC	B-Task
2012	O
dataset	O
and	O
MS	B-Material
COCO	I-Material
dataset	I-Material
.	O
	
Acknowledgement	O
:	O
We	O
would	O
like	O
to	O
thank	O
Sergey	O
Zagoruyko	O
for	O
help	O
with	O
fast	O
RCNN	B-Method
experiments	O
;	O
Pedro	O
O.	O
Pinheiro	O
,	O
Bolei	O
Zhou	O
,	O
Maxime	O
Oquab	O
,	O
Joël	O
Legrand	O
,	O
Yuandong	O
Tian	O
,	O
Léon	O
Bottou	O
and	O
Florent	O
Perronnin	O
for	O
valuable	O
discussions	O
.	O
	
bibliography	O
:	O
References	O
	
document	O
:	O
Real	B-Task
-	I-Task
Time	I-Task
Video	I-Task
Super	I-Task
-	I-Task
Resolution	I-Task
with	O
Spatio	B-Method
-	I-Method
Temporal	I-Method
Networks	I-Method
and	O
Motion	B-Method
Compensation	I-Method
	
Convolutional	B-Method
neural	I-Method
networks	I-Method
have	O
enabled	O
accurate	O
image	B-Task
super	I-Task
-	I-Task
resolution	I-Task
in	I-Task
real	I-Task
-	I-Task
time	I-Task
.	O
	
However	O
,	O
recent	O
attempts	O
to	O
benefit	O
from	O
temporal	O
correlations	O
in	O
video	B-Task
super	I-Task
-	I-Task
resolution	I-Task
have	O
been	O
limited	O
to	O
naive	O
or	O
inefficient	O
architectures	O
.	O
	
In	O
this	O
paper	O
,	O
we	O
introduce	O
spatio	B-Method
-	I-Method
temporal	I-Method
sub	I-Method
-	I-Method
pixel	I-Method
convolution	I-Method
networks	I-Method
that	O
effectively	O
exploit	O
temporal	O
redundancies	O
and	O
improve	O
reconstruction	B-Metric
accuracy	I-Metric
while	O
maintaining	O
real	B-Metric
-	I-Metric
time	I-Metric
speed	I-Metric
.	O
	
Specifically	O
,	O
we	O
discuss	O
the	O
use	O
of	O
early	B-Method
fusion	I-Method
,	O
slow	B-Method
fusion	I-Method
and	O
3D	B-Method
convolutions	I-Method
for	O
the	O
joint	O
processing	O
of	O
multiple	O
consecutive	O
video	B-Task
frames	O
.	O
	
We	O
also	O
propose	O
a	O
novel	O
joint	B-Method
motion	I-Method
compensation	I-Method
and	O
video	B-Task
super	O
-	O
resolution	O
algorithm	O
that	O
is	O
orders	O
of	O
magnitude	O
more	O
efficient	O
than	O
competing	O
methods	O
,	O
relying	O
on	O
a	O
fast	O
multi	B-Method
-	I-Method
resolution	I-Method
spatial	I-Method
transformer	I-Method
module	I-Method
that	O
is	O
end	O
-	O
to	O
-	O
end	O
trainable	O
.	O
	
These	O
contributions	O
provide	O
both	O
higher	O
accuracy	B-Metric
and	O
temporally	O
more	O
consistent	O
videos	O
,	O
which	O
we	O
confirm	O
qualitatively	O
and	O
quantitatively	O
.	O
	
Relative	O
to	O
single	B-Method
-	I-Method
frame	I-Method
models	I-Method
,	O
spatio	B-Method
-	I-Method
temporal	I-Method
networks	I-Method
can	O
either	O
reduce	O
the	O
computational	B-Metric
cost	I-Metric
by	O
30	O
%	O
whilst	O
maintaining	O
the	O
same	O
quality	B-Metric
or	O
provide	O
a	O
0.2dB	O
gain	O
for	O
a	O
similar	O
computational	B-Metric
cost	I-Metric
.	O
	
Results	O
on	O
publicly	O
available	O
datasets	O
demonstrate	O
that	O
the	O
proposed	O
algorithms	O
surpass	O
current	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
performance	O
in	O
both	O
accuracy	B-Metric
and	O
efficiency	B-Metric
.	O
	
SRSRsuper	O
-	O
resolution	O
LRLRlow	O
-	O
resolution	O
HRHRhigh	O
-	O
resolution	O
CNNCNNconvolutionalneuralnetwork	O
TVTVtotalvariation	O
HDHDhighdefinition	O
MSEMSEmeansquarederror	O
PSNRPSNRpeaksignal	O
-	O
to	O
-	O
noiseratio	O
SSIMSSIMstructuralsimilarity	O
	
section	O
:	O
Introduction	O
	
Image	O
and	O
video	B-Task
SR	O
are	O
long	O
-	O
standing	O
challenges	O
of	O
signal	B-Task
processing	I-Task
.	O
	
SR	B-Method
aims	O
at	O
recovering	O
a	O
HR	B-Task
image	I-Task
or	O
video	B-Task
from	O
its	O
LR	O
version	O
,	O
and	O
finds	O
direct	O
applications	O
ranging	O
from	O
medical	B-Task
imaging	I-Task
to	O
satellite	B-Task
imaging	I-Task
,	O
as	O
well	O
as	O
facilitating	B-Task
tasks	I-Task
such	O
as	O
face	B-Task
recognition	I-Task
.	O
	
The	O
reconstruction	B-Task
of	I-Task
HR	I-Task
data	I-Task
from	O
a	O
LR	O
input	O
is	O
however	O
a	O
highly	O
ill	B-Task
-	I-Task
posed	I-Task
problem	I-Task
that	O
requires	O
additional	O
constraints	O
to	O
be	O
solved	O
.	O
	
While	O
those	O
constraints	O
are	O
often	O
application	O
-	O
dependent	O
,	O
they	O
usually	O
rely	O
on	O
data	O
redundancy	O
.	O
	
In	O
single	B-Task
image	I-Task
SR	I-Task
,	O
where	O
only	O
one	O
LR	O
image	O
is	O
provided	O
,	O
methods	O
exploit	O
inherent	O
image	O
redundancy	O
in	O
the	O
form	O
of	O
local	O
correlations	O
to	O
recover	O
lost	O
high	O
-	O
frequency	O
details	O
by	O
imposing	O
sparsity	O
constraints	O
or	O
assuming	O
other	O
types	O
of	O
image	O
statistics	O
such	O
as	O
multi	B-Method
-	I-Method
scale	I-Method
patch	I-Method
recurrence	I-Method
.	O
	
In	O
multi	B-Task
-	I-Task
image	I-Task
SR	I-Task
it	O
is	O
assumed	O
that	O
different	O
observations	O
of	O
the	O
same	O
scene	O
are	O
available	O
,	O
hence	O
the	O
shared	O
explicit	O
redundancy	O
can	O
be	O
used	O
to	O
constrain	O
the	O
problem	O
and	O
attempt	O
to	O
invert	O
the	O
downscaling	B-Method
process	I-Method
directly	O
.	O
	
Transitioning	O
from	O
images	O
to	O
videos	O
implies	O
an	O
additional	O
data	O
dimension	O
(	O
time	O
)	O
with	O
a	O
high	O
degree	O
of	O
correlation	O
that	O
can	O
also	O
be	O
exploited	O
to	O
improve	O
performance	O
in	O
terms	O
of	O
accuracy	B-Metric
as	O
well	O
as	O
efficiency	B-Metric
.	O
	
subsection	O
:	O
Related	O
work	O
	
Video	B-Method
SR	I-Method
methods	I-Method
have	O
mainly	O
emerged	O
as	O
adaptations	O
of	O
image	B-Method
SR	I-Method
techniques	I-Method
.	O
	
Kernel	B-Method
regression	I-Method
methods	I-Method
have	O
been	O
shown	O
to	O
be	O
applicable	O
to	O
videos	O
using	O
3D	O
kernels	O
instead	O
of	O
2D	O
ones	O
.	O
	
Dictionary	B-Method
learning	I-Method
approaches	I-Method
,	O
which	O
define	O
LR	O
images	O
as	O
a	O
sparse	B-Method
linear	I-Method
combination	I-Method
of	I-Method
dictionary	I-Method
atoms	I-Method
coupled	O
to	O
a	O
HR	O
dictionary	O
,	O
have	O
also	O
been	O
adapted	O
from	O
images	O
to	O
videos	O
.	O
	
Another	O
approach	O
is	O
example	B-Method
-	I-Method
based	I-Method
patch	I-Method
recurrence	I-Method
,	O
which	O
assumes	O
patches	O
in	O
a	O
single	O
image	O
or	O
video	B-Task
obey	O
multi	O
-	O
scale	O
relationships	O
,	O
and	O
therefore	O
missing	O
high	O
-	O
frequency	O
content	O
at	O
a	O
given	O
scale	O
can	O
be	O
inferred	O
from	O
coarser	O
scale	O
patches	O
.	O
	
This	O
was	O
successfully	O
presented	O
by	O
Glasner	O
et	O
al	O
.	O
for	O
image	B-Task
SR	I-Task
and	O
has	O
later	O
been	O
extended	O
to	O
videos	O
.	O
	
When	O
adapting	O
a	O
method	O
from	O
images	O
to	O
videos	O
it	O
is	O
usually	O
beneficial	O
to	O
incorporate	O
the	O
prior	O
knowledge	O
that	O
frames	O
of	O
the	O
same	O
scene	O
of	O
a	O
video	B-Task
can	O
be	O
approximated	O
by	O
a	O
single	O
image	O
and	O
a	O
motion	O
pattern	O
.	O
	
Estimating	B-Task
and	I-Task
compensating	I-Task
motion	I-Task
is	O
a	O
powerful	O
mechanism	O
to	O
further	O
constrain	O
the	O
problem	O
and	O
expose	O
temporal	O
correlations	O
.	O
	
It	O
is	O
therefore	O
very	O
common	O
to	O
find	O
video	B-Task
SR	O
methods	O
that	O
explicitly	O
model	O
motion	O
through	O
frames	O
.	O
	
A	O
natural	O
choice	O
has	O
been	O
to	O
preprocess	O
input	O
frames	O
by	O
compensating	O
inter	O
-	O
frame	O
motion	O
using	O
displacement	O
fields	O
obtained	O
from	O
off	B-Method
-	I-Method
the	I-Method
-	I-Method
shelf	I-Method
optical	I-Method
flow	I-Method
algorithms	I-Method
.	O
	
This	O
nevertheless	O
requires	O
frame	B-Method
preprocessing	I-Method
and	O
is	O
usually	O
expensive	O
.	O
	
Alternatively	O
,	O
motion	B-Task
compensation	I-Task
can	O
also	O
be	O
performed	O
jointly	O
with	O
the	O
SR	B-Task
task	I-Task
,	O
as	O
done	O
in	O
the	O
Bayesian	B-Method
approach	I-Method
of	O
Liu	O
et	O
al	O
.	O
by	O
iteratively	O
estimating	B-Task
motion	I-Task
as	O
part	O
of	O
its	O
wider	O
modeling	O
of	O
the	O
downscaling	B-Task
process	I-Task
.	O
	
The	O
advent	O
of	O
neural	B-Method
network	I-Method
techniques	I-Method
that	O
can	O
be	O
trained	O
from	O
data	O
to	O
approximate	O
complex	O
nonlinear	O
functions	O
has	O
set	O
new	O
performance	O
standards	O
in	O
many	O
applications	O
including	O
SR	B-Task
.	O
	
Dong	O
et	O
al	O
.	O
proposed	O
to	O
use	O
a	O
CNN	B-Method
architecture	I-Method
for	O
single	B-Task
image	I-Task
SR	I-Task
that	O
was	O
later	O
extended	O
by	O
Kappeler	O
et	O
al	O
.	O
	
in	O
a	O
video	B-Task
SR	O
network	O
(	O
VSRnet	B-Method
)	O
which	O
jointly	O
processes	O
multiple	O
input	O
frames	O
.	O
	
Additionally	O
,	O
compensating	O
the	O
motion	O
of	O
input	O
images	O
with	O
a	O
TV	B-Method
-	I-Method
based	I-Method
optical	I-Method
flow	I-Method
algorithm	I-Method
showed	O
an	O
improved	O
accuracy	B-Metric
.	O
	
Joint	B-Task
motion	I-Task
compensation	I-Task
for	O
SR	B-Task
with	O
neural	B-Method
networks	I-Method
has	O
also	O
been	O
studied	O
through	O
recurrent	B-Method
bidirectional	I-Method
networks	I-Method
.	O
	
The	O
common	O
paradigm	O
for	O
CNN	B-Method
based	I-Method
approaches	I-Method
has	O
been	O
to	O
upscale	O
the	O
LR	O
image	O
with	O
bicubic	B-Method
interpolation	I-Method
before	O
attempting	O
to	O
solve	O
the	O
SR	B-Task
problem	I-Task
.	O
	
However	O
,	O
increasing	O
input	O
image	O
size	O
through	O
interpolation	B-Method
considerably	O
impacts	O
the	O
computational	B-Metric
burden	I-Metric
for	O
CNN	B-Task
processing	I-Task
.	O
	
A	O
solution	O
was	O
proposed	O
by	O
Shi	O
et	O
al	O
.	O
with	O
an	O
efficient	B-Method
sub	I-Method
-	I-Method
pixel	I-Method
convolution	I-Method
network	I-Method
(	O
ESPCN	B-Method
)	I-Method
,	O
where	O
an	O
upscaling	B-Method
operation	I-Method
directly	O
mapping	O
from	O
LR	O
to	O
HR	O
space	O
is	O
learnt	O
by	O
the	O
network	O
.	O
	
This	O
technique	O
reduces	O
runtime	B-Metric
by	O
an	O
order	O
of	O
magnitude	O
and	O
enables	O
real	B-Task
-	I-Task
time	I-Task
video	I-Task
SR	I-Task
by	O
independently	O
processing	O
frames	O
with	O
a	O
single	B-Method
frame	I-Method
model	I-Method
.	O
	
Similar	O
solutions	O
to	O
improve	O
efficiency	O
have	O
also	O
been	O
proposed	O
based	O
on	O
transposed	B-Method
convolutions	I-Method
.	O
	
subsection	O
:	O
Motivation	O
and	O
contributions	O
	
[	O
b	O
]	O
0.32	O
[	O
b	O
]	O
0.32	O
[	O
b	O
]	O
0.32	O
Existing	O
solutions	O
for	O
HD	B-Task
video	I-Task
SR	I-Task
have	O
not	O
been	O
able	O
to	O
effectively	O
exploit	O
temporal	O
correlations	O
while	O
performing	O
in	O
real	B-Task
-	I-Task
time	I-Task
.	O
	
On	O
the	O
one	O
hand	O
,	O
ESPCN	B-Method
leverages	O
sub	B-Method
-	I-Method
pixel	I-Method
convolution	I-Method
for	O
a	O
very	O
efficient	O
operation	O
,	O
but	O
its	O
naive	O
extension	O
to	O
videos	O
treating	O
frames	O
independently	O
fails	O
to	O
exploit	O
inter	O
-	O
frame	O
redundancies	O
and	O
does	O
not	O
enforce	O
a	O
temporally	O
consistent	O
result	O
.	O
	
VSRnet	B-Method
,	O
on	O
the	O
other	O
hand	O
,	O
can	O
improve	O
reconstruction	B-Metric
quality	I-Metric
by	O
jointly	O
processing	O
multiple	O
input	O
frames	O
.	O
	
However	O
,	O
the	O
preprocessing	B-Task
of	I-Task
LR	I-Task
images	I-Task
with	O
bicubic	B-Method
upscaling	I-Method
and	O
the	O
use	O
of	O
an	O
inefficient	O
motion	B-Method
compensation	I-Method
mechanism	I-Method
slows	O
runtime	B-Metric
to	O
about	O
frames	O
per	O
second	O
even	O
on	O
videos	O
smaller	O
than	O
standard	O
definition	O
resolution	O
.	O
	
Spatial	B-Method
transformer	I-Method
networks	I-Method
provide	O
a	O
means	O
to	O
infer	O
parameters	O
for	O
a	O
spatial	B-Task
mapping	I-Task
between	O
two	O
images	O
.	O
	
These	O
are	O
differentiable	B-Method
networks	I-Method
that	O
can	O
be	O
seamlessly	O
combined	O
and	O
jointly	O
trained	O
with	O
networks	O
targeting	O
other	O
objectives	O
to	O
enhance	O
their	O
performance	O
.	O
	
For	O
instance	O
,	O
spatial	B-Method
transformer	I-Method
networks	I-Method
were	O
initially	O
shown	O
to	O
facilitate	O
image	B-Task
classification	I-Task
by	O
transforming	O
images	O
onto	O
the	O
same	O
frame	O
of	O
reference	O
.	O
	
Recently	O
,	O
it	O
has	O
been	O
shown	O
how	O
spatial	B-Method
transformers	I-Method
can	O
encode	O
optical	O
flow	O
features	O
with	O
unsupervised	B-Method
training	I-Method
,	O
but	O
they	O
have	O
nevertheless	O
not	O
yet	O
been	O
investigated	O
for	O
video	B-Task
motion	O
compensation	O
.	O
	
Related	O
approaches	O
have	O
emerged	O
for	O
view	B-Task
synthesis	I-Task
assuming	O
rigid	B-Task
transformations	I-Task
.	O
	
In	O
this	O
paper	O
,	O
we	O
combine	O
the	O
efficiency	O
of	O
sub	B-Method
-	I-Method
pixel	I-Method
convolution	I-Method
with	O
the	O
performance	O
of	O
spatio	B-Method
-	I-Method
temporal	I-Method
networks	I-Method
and	O
motion	B-Method
compensation	I-Method
to	O
obtain	O
a	O
fast	O
and	O
accurate	O
video	B-Task
SR	O
algorithm	O
.	O
	
We	O
study	O
different	O
treatments	O
of	O
the	O
temporal	O
dimension	O
with	O
early	B-Method
fusion	I-Method
,	O
slow	B-Method
fusion	I-Method
and	O
3D	B-Method
convolutions	I-Method
,	O
which	O
have	O
been	O
previously	O
suggested	O
to	O
extend	O
classification	B-Task
from	O
images	O
to	O
videos	O
.	O
	
Additionally	O
,	O
we	O
build	O
a	O
motion	B-Method
compensation	I-Method
scheme	I-Method
based	O
on	O
spatial	B-Method
transformers	I-Method
,	O
which	O
is	O
combined	O
with	O
spatio	B-Method
-	I-Method
temporal	I-Method
models	I-Method
to	O
lead	O
to	O
a	O
very	O
efficient	O
solution	O
for	O
video	B-Task
SR	O
with	O
motion	B-Task
compensation	I-Task
that	O
is	O
end	O
-	O
to	O
-	O
end	O
trainable	O
.	O
	
A	O
high	O
-	O
level	O
diagram	O
of	O
the	O
proposed	O
approach	O
is	O
show	O
in	O
fig	O
:	O
network	O
.	O
	
The	O
main	O
contributions	O
of	O
this	O
paper	O
are	O
:	O
Presenting	O
a	O
real	B-Method
-	I-Method
time	I-Method
approach	I-Method
for	O
video	B-Task
SR	O
based	O
on	O
sub	B-Method
-	I-Method
pixel	I-Method
convolution	I-Method
and	O
spatio	B-Method
-	I-Method
temporal	I-Method
networks	I-Method
that	O
improves	O
accuracy	B-Metric
and	O
temporal	B-Metric
consistency	I-Metric
.	O
	
Comparing	O
early	B-Method
fusion	I-Method
,	O
slow	B-Method
fusion	I-Method
and	O
3D	B-Method
convolutions	I-Method
as	O
alternative	O
architectures	O
for	O
discovering	B-Task
spatio	I-Task
-	I-Task
temporal	I-Task
correlations	I-Task
.	O
	
Proposing	O
an	O
efficient	O
method	O
for	O
dense	B-Task
inter	I-Task
-	I-Task
frame	I-Task
motion	I-Task
compensation	I-Task
based	O
on	O
a	O
multi	B-Method
-	I-Method
scale	I-Method
spatial	I-Method
transformer	I-Method
network	I-Method
.	O
	
Combining	O
the	O
proposed	O
motion	B-Method
compensation	I-Method
technique	I-Method
with	O
spatio	B-Method
-	I-Method
temporal	I-Method
models	I-Method
to	O
provide	O
an	O
efficient	O
,	O
end	O
-	O
to	O
-	O
end	O
trainable	O
motion	O
compensated	O
video	B-Task
SR	O
algorithm	O
.	O
	
section	O
:	O
Methods	O
	
Our	O
starting	O
point	O
is	O
the	O
real	O
-	O
time	O
image	O
SR	O
method	O
ESPCN	B-Method
.	O
	
We	O
restrict	O
our	O
analysis	O
to	O
standard	O
architectural	O
choices	O
and	O
do	O
not	O
further	O
investigate	O
potentially	O
beneficial	O
extensions	O
such	O
as	O
recurrence	O
,	O
residual	O
connections	O
or	O
training	B-Method
networks	I-Method
based	O
on	O
perceptual	O
loss	O
functions	O
.	O
	
Throughout	O
the	O
paper	O
we	O
assume	O
all	O
image	B-Task
processing	I-Task
is	O
performed	O
on	O
the	O
y	O
-	O
channel	O
in	O
colour	O
space	O
,	O
and	O
thus	O
we	O
represent	O
all	O
images	O
as	O
2D	O
matrices	O
.	O
	
subsection	O
:	O
Sub	B-Method
-	I-Method
pixel	I-Method
convolution	I-Method
SR	I-Method
	
For	O
a	O
given	O
LR	O
image	O
which	O
is	O
assumed	O
to	O
be	O
the	O
result	O
of	O
low	B-Method
-	I-Method
pass	I-Method
filtering	I-Method
and	O
downscaling	B-Method
by	O
a	O
factor	O
the	O
HR	O
image	O
,	O
the	O
CNN	B-Method
super	I-Method
-	I-Method
resolved	I-Method
solution	I-Method
can	O
be	O
expressed	O
as	O
Here	O
,	O
are	O
model	O
parameters	O
and	O
represents	O
the	O
mapping	O
function	O
from	O
LR	O
to	O
HR	O
.	O
	
A	O
convolutional	B-Method
network	I-Method
models	O
this	O
function	O
as	O
a	O
concatenation	B-Method
of	I-Method
layers	I-Method
defined	O
by	O
sets	O
of	O
weights	O
and	O
biases	O
,	O
each	O
followed	O
by	O
non	O
-	O
linearities	O
,	O
with	O
.	O
	
Formally	O
,	O
the	O
output	O
of	O
each	O
layer	O
is	O
written	O
as	O
with	O
.	O
	
We	O
assume	O
the	O
shape	O
of	O
filtering	O
weights	O
to	O
be	O
,	O
where	O
and	O
represent	O
the	O
number	O
and	O
size	O
of	O
filters	O
in	O
layer	O
,	O
with	O
the	O
single	O
frame	O
input	O
meaning	O
.	O
	
Model	B-Method
parameters	I-Method
are	O
optimised	O
minimising	O
a	O
loss	O
given	O
a	O
set	O
of	O
LR	O
and	O
HR	O
example	O
image	O
pairs	O
,	O
commonly	O
MSE	B-Metric
:	O
	
Methods	O
preprocessing	O
with	O
bicubic	B-Method
upsampling	I-Method
before	O
mapping	O
from	O
LR	O
to	O
HR	O
impose	O
that	O
the	O
output	O
number	O
of	O
filters	O
is	O
.	O
	
Using	O
sub	B-Method
-	I-Method
pixel	I-Method
convolution	I-Method
allows	O
to	O
process	O
directly	O
in	O
the	O
LR	O
space	O
and	O
then	O
use	O
output	B-Method
filters	I-Method
to	O
obtain	O
an	O
HR	O
output	O
tensor	O
with	O
shape	O
that	O
can	O
be	O
reordered	O
to	O
obtain	O
.	O
	
This	O
implies	O
that	O
if	O
there	O
exists	O
an	O
upscaling	B-Method
operation	I-Method
that	O
is	O
better	O
suited	O
for	O
the	O
problem	O
than	O
bicubic	B-Method
upsampling	I-Method
,	O
the	O
network	O
can	O
learn	O
it	O
.	O
	
Moreover	O
,	O
and	O
most	O
importantly	O
,	O
all	O
convolutional	B-Method
processing	I-Method
is	O
performed	O
in	O
LR	O
space	O
,	O
making	O
this	O
approach	O
very	O
efficient	O
.	O
	
subsection	O
:	O
Spatio	B-Task
-	I-Task
temporal	I-Task
networks	I-Task
	
Spatio	B-Method
-	I-Method
temporal	I-Method
networks	I-Method
assume	O
input	O
data	O
to	O
be	O
a	O
block	O
of	O
spatio	O
-	O
temporal	O
information	O
,	O
such	O
that	O
instead	O
of	O
a	O
single	O
input	O
frame	O
,	O
a	O
sequence	O
of	O
consecutive	O
frames	O
is	O
considered	O
.	O
	
This	O
can	O
be	O
represented	O
in	O
the	O
network	O
by	O
introducing	O
an	O
additional	O
dimension	O
for	O
temporal	O
depth	O
,	O
with	O
the	O
input	O
depth	O
representing	O
an	O
odd	O
number	O
of	O
consecutive	O
input	O
frames	O
.	O
	
If	O
we	O
denote	O
the	O
temporal	O
radius	O
of	O
a	O
spatio	O
-	O
temporal	O
block	O
to	O
be	O
,	O
we	O
define	O
the	O
group	O
of	O
input	O
frames	O
centered	O
at	O
time	O
as	O
,	O
and	O
the	O
problem	O
in	O
eq	O
:	O
image	B-Task
-	I-Task
sr	I-Task
becomes	O
The	O
shape	O
of	O
weighting	B-Method
filters	I-Method
is	O
also	O
extended	O
by	O
their	O
temporal	O
size	O
,	O
and	O
their	O
tensor	O
shape	O
becomes	O
.	O
	
We	O
note	O
that	O
it	O
is	O
possible	O
to	O
consider	O
solutions	O
that	O
aim	O
to	O
jointly	O
reconstruct	O
more	O
than	O
a	O
single	O
output	O
frame	O
,	O
which	O
could	O
have	O
advantages	O
at	O
least	O
in	O
terms	O
of	O
computational	B-Metric
efficiency	I-Metric
.	O
	
However	O
,	O
in	O
this	O
work	O
we	O
focus	O
on	O
the	O
reconstruction	B-Task
of	O
only	O
a	O
single	O
output	O
frame	O
.	O
	
subsubsection	O
:	O
Early	B-Method
fusion	I-Method
	
One	O
of	O
the	O
most	O
straightforward	O
approaches	O
for	O
a	O
CNN	B-Method
to	O
process	O
videos	O
is	O
to	O
match	O
the	O
temporal	O
depth	O
of	O
the	O
input	O
layer	O
to	O
the	O
number	O
of	O
frames	O
.	O
	
This	O
will	O
collapse	O
all	O
temporal	O
information	O
in	O
the	O
first	O
layer	O
and	O
the	O
remaining	O
operations	O
are	O
identical	O
to	O
those	O
in	O
a	O
single	O
image	B-Method
SR	I-Method
network	I-Method
,	O
meaning	O
.	O
	
An	O
illustration	O
of	O
early	B-Task
fusion	I-Task
is	O
shown	O
in	O
fig	O
:	O
early	B-Task
-	I-Task
fusion	I-Task
for	O
,	O
where	O
the	O
temporal	O
dimension	O
has	O
been	O
colour	O
coded	O
and	O
the	O
output	O
mapping	O
to	O
2D	O
space	O
is	O
omitted	O
.	O
	
This	O
design	O
has	O
been	O
studied	O
for	O
video	B-Task
classification	O
and	O
action	B-Task
recognition	I-Task
,	O
and	O
was	O
also	O
one	O
of	O
the	O
architectures	O
proposed	O
in	O
VSRnet	B-Method
.	O
	
However	O
,	O
VSRnet	B-Method
requires	O
bicubic	B-Method
upsampling	I-Method
as	O
opposed	O
to	O
sub	B-Method
-	I-Method
pixel	I-Method
convolution	I-Method
,	O
making	O
the	O
framework	O
computationally	O
much	O
less	O
efficient	O
in	O
comparison	O
.	O
	
subsubsection	O
:	O
Slow	B-Method
fusion	I-Method
	
Another	O
option	O
is	O
to	O
partially	O
merge	O
temporal	O
information	O
in	O
a	O
hierarchical	O
structure	O
,	O
so	O
it	O
is	O
slowly	O
fused	O
as	O
information	O
progresses	O
through	O
the	O
network	O
.	O
	
In	O
this	O
case	O
,	O
the	O
temporal	O
depth	O
of	O
network	O
layers	O
is	O
configured	O
to	O
be	O
,	O
and	O
therefore	O
some	O
layers	O
also	O
have	O
a	O
temporal	O
extent	O
until	O
all	O
information	O
has	O
been	O
merged	O
and	O
the	O
depth	O
of	O
the	O
network	O
reduces	O
to	O
.	O
	
This	O
architecture	O
,	O
termed	O
slow	B-Method
fusion	I-Method
,	O
has	O
shown	O
better	O
performance	O
than	O
early	B-Method
fusion	I-Method
for	O
video	B-Task
classification	O
.	O
	
In	O
fig	O
:	O
slow	B-Method
-	I-Method
fusion	I-Method
we	O
show	O
a	O
slow	B-Method
fusion	I-Method
network	I-Method
where	O
and	O
the	O
rate	B-Metric
of	I-Metric
fusion	I-Metric
is	O
defined	O
by	O
for	O
or	O
otherwise	O
,	O
meaning	O
that	O
at	O
each	O
layer	O
only	O
two	O
consecutive	O
frames	O
or	O
filter	O
activations	O
are	O
merged	O
until	O
the	O
network	O
’s	O
temporal	O
depth	O
shrinks	O
to	O
.	O
	
Note	O
that	O
early	B-Method
fusion	I-Method
is	O
an	O
special	O
case	O
of	O
slow	B-Method
fusion	I-Method
.	O
	
subsubsection	O
:	O
3D	B-Method
convolutions	I-Method
	
Another	O
variation	O
of	O
slow	B-Method
fusion	I-Method
is	O
to	O
force	O
layer	O
weights	O
to	O
be	O
shared	O
across	O
the	O
temporal	O
dimension	O
,	O
which	O
has	O
computational	O
advantages	O
.	O
	
Assuming	O
an	O
online	B-Task
processing	I-Task
of	I-Task
frames	I-Task
,	O
when	O
a	O
new	O
frame	O
becomes	O
available	O
the	O
result	O
of	O
some	O
layers	O
for	O
the	O
previous	O
frame	O
can	O
be	O
reused	O
.	O
	
For	O
instance	O
,	O
refering	O
to	O
the	O
diagram	O
in	O
fig	O
:	O
slow	B-Method
-	I-Method
fusion	I-Method
and	O
assuming	O
the	O
bottom	O
frame	O
to	O
be	O
the	O
latest	O
frame	O
received	O
,	O
all	O
activations	O
above	O
the	O
dashed	O
line	O
are	O
readily	O
available	O
because	O
they	O
were	O
required	O
for	O
processing	O
the	O
previous	O
frame	O
.	O
	
This	O
architecture	O
is	O
equivalent	O
to	O
using	O
3D	B-Method
convolutions	I-Method
,	O
initially	O
proposed	O
as	O
an	O
effective	O
tool	O
to	O
learn	O
spatio	O
-	O
temporal	O
features	O
that	O
can	O
help	O
for	O
video	B-Task
action	O
recognition	O
.	O
	
An	O
illustration	O
of	O
this	O
design	O
from	O
a	O
3D	B-Task
convolution	I-Task
perspective	I-Task
is	O
shown	O
in	O
fig:3dconv	O
,	O
where	O
the	O
arrangement	O
of	O
the	O
temporal	O
and	O
filter	O
features	O
is	O
swapped	O
relative	O
to	O
fig	O
:	O
slow	B-Method
-	I-Method
fusion	I-Method
.	O
	
subsection	O
:	O
Spatial	B-Task
transformer	I-Task
motion	I-Task
compensation	I-Task
	
We	O
propose	O
the	O
use	O
of	O
an	O
efficient	O
spatial	B-Method
transformer	I-Method
network	I-Method
to	O
compensate	O
the	O
motion	O
between	O
frames	O
fed	O
to	O
the	O
SR	B-Method
network	I-Method
.	O
	
It	O
has	O
been	O
shown	O
how	O
spatial	O
transformers	O
can	O
effectively	O
encode	O
optical	O
flow	O
to	O
describe	O
motion	O
,	O
and	O
are	O
therefore	O
suitable	O
for	O
motion	B-Task
compensation	I-Task
.	O
	
We	O
will	O
compensate	O
blocks	O
of	O
three	O
consecutive	O
frames	O
to	O
combine	O
the	O
compensation	B-Method
module	I-Method
with	O
the	O
SR	B-Method
network	I-Method
as	O
shown	O
in	O
fig	O
:	O
network	O
,	O
but	O
for	O
simplicity	O
we	O
first	O
introduce	O
motion	B-Task
compensation	I-Task
between	O
two	O
frames	O
.	O
	
Notice	O
that	O
the	O
data	O
used	O
contains	O
inherent	O
motion	O
blur	O
and	O
(	O
dis	O
)	O
occlusions	O
,	O
and	O
even	O
though	O
an	O
explicit	O
modelling	O
for	O
these	O
effects	O
is	O
not	O
used	O
it	O
could	O
potentially	O
improve	O
results	O
.	O
	
The	O
task	O
is	O
to	O
find	O
the	O
best	O
optical	B-Method
flow	I-Method
representation	I-Method
relating	O
a	O
new	O
frame	O
with	O
a	O
reference	O
current	O
frame	O
.	O
	
The	O
flow	O
is	O
assumed	O
pixel	O
-	O
wise	O
dense	O
,	O
allowing	O
to	O
displace	O
each	O
pixel	O
to	O
a	O
new	O
position	O
,	O
and	O
the	O
resulting	O
pixel	O
arrangement	O
requires	O
interpolation	O
back	O
onto	O
a	O
regular	O
grid	O
.	O
	
We	O
use	O
bilinear	B-Method
interpolation	I-Method
as	O
it	O
is	O
much	O
more	O
efficient	O
than	O
the	O
thin	B-Method
-	I-Method
plate	I-Method
spline	I-Method
interpolation	I-Method
originally	O
proposed	O
in	O
.	O
	
Optical	B-Task
flow	I-Task
is	O
a	O
function	O
of	O
parameters	O
and	O
is	O
represented	O
with	O
two	O
feature	O
maps	O
corresponding	O
to	O
displacements	O
for	O
the	O
and	O
dimensions	O
,	O
thus	O
a	O
compensated	O
image	O
can	O
be	O
expressed	O
as	O
,	O
or	O
more	O
concisely	O
We	O
adopt	O
a	O
multi	B-Method
-	I-Method
scale	I-Method
design	I-Method
to	O
represent	O
the	O
flow	O
,	O
which	O
has	O
been	O
shown	O
to	O
be	O
effective	O
in	O
classical	O
methods	O
and	O
also	O
in	O
more	O
recently	O
proposed	O
spatial	B-Method
transformer	I-Method
techniques	I-Method
.	O
	
A	O
schematic	O
of	O
the	O
design	O
is	O
shown	O
in	O
fig	O
:	O
transformer	B-Method
and	O
flow	B-Method
estimation	I-Method
modules	I-Method
are	O
detailed	O
in	O
tab	O
:	O
transformer	B-Method
.	O
	
First	O
,	O
a	O
coarse	B-Task
estimate	I-Task
of	I-Task
the	I-Task
flow	I-Task
is	O
obtained	O
by	O
early	O
fusing	O
the	O
two	O
input	O
frames	O
and	O
downscaling	O
spatial	O
dimensions	O
with	O
strided	B-Method
convolutions	I-Method
.	O
	
The	O
estimated	O
flow	O
is	O
upscaled	O
with	O
sub	B-Method
-	I-Method
pixel	I-Method
convolution	I-Method
and	O
the	O
result	O
is	O
applied	O
to	O
warp	O
the	O
target	O
frame	O
producing	O
.	O
	
The	O
warped	O
image	O
is	O
then	O
processed	O
together	O
with	O
the	O
coarse	O
flow	O
and	O
the	O
original	O
images	O
through	O
a	O
fine	B-Method
flow	I-Method
estimation	I-Method
module	I-Method
.	O
	
This	O
uses	O
a	O
single	O
strided	B-Method
convolution	I-Method
with	O
stride	B-Method
and	O
a	O
final	O
upscaling	B-Method
stage	I-Method
to	O
obtain	O
a	O
finer	O
flow	O
map	O
.	O
	
The	O
final	O
motion	O
compensated	O
frame	O
is	O
obtained	O
by	O
warping	O
the	O
target	O
frame	O
with	O
the	O
total	O
flow	O
.	O
	
Output	O
activations	O
use	O
tanh	B-Method
to	O
represent	O
pixel	O
displacement	O
in	O
normalised	O
space	O
,	O
such	O
that	O
a	O
displacement	O
of	O
means	O
maximum	O
displacement	O
from	O
the	O
center	O
to	O
the	O
border	O
of	O
the	O
image	O
.	O
	
To	O
train	O
the	O
spatial	B-Method
transformer	I-Method
to	O
perform	O
motion	B-Task
compensation	I-Task
we	O
optimise	O
its	O
parameters	O
to	O
minimise	O
the	O
MSE	B-Metric
between	O
the	O
transformed	O
frame	O
and	O
the	O
reference	O
frame	O
.	O
	
Similary	O
to	O
classical	O
optical	B-Method
flow	I-Method
methods	I-Method
,	O
we	O
found	O
that	O
it	O
is	O
generally	O
helpful	O
to	O
constrain	O
the	O
flow	O
to	O
behave	O
smoothly	O
in	O
space	O
,	O
and	O
so	O
we	O
penalise	O
the	O
Huber	O
loss	O
of	O
the	O
flow	O
map	O
gradients	O
,	O
	
namely	O
In	O
practice	O
we	O
approximate	O
the	O
Huber	O
loss	O
with	O
,	O
where	O
.	O
	
This	O
function	O
has	O
a	O
smooth	O
behaviour	O
near	O
the	O
origin	O
and	O
is	O
sparsity	O
promoting	O
far	O
from	O
it	O
.	O
	
The	O
spatial	B-Method
transformer	I-Method
module	I-Method
is	O
advantageous	O
relative	O
to	O
other	O
motion	B-Method
compensation	I-Method
mechanisms	I-Method
as	O
it	O
is	O
straightforward	O
to	O
combine	O
with	O
a	O
SR	B-Method
network	I-Method
to	O
perform	O
joint	B-Task
motion	I-Task
compensation	I-Task
and	O
video	B-Task
SR	O
.	O
	
Referring	O
to	O
fig	O
:	O
network	O
,	O
the	O
same	O
parameters	O
can	O
be	O
used	O
to	O
model	O
motion	O
of	O
the	O
outer	O
two	O
frames	O
relative	O
to	O
the	O
central	O
frame	O
.	O
	
The	O
spatial	B-Method
transformer	I-Method
and	O
SR	B-Method
modules	I-Method
are	O
both	O
differentiable	O
and	O
therefore	O
end	O
-	O
to	O
-	O
end	O
trainable	O
.	O
	
As	O
a	O
result	O
,	O
they	O
can	O
be	O
jointly	O
optimised	O
to	O
minimise	O
a	O
composite	B-Metric
loss	I-Metric
combining	O
the	O
accuracy	B-Metric
of	O
the	O
reconstruction	B-Task
in	O
eq	O
:	O
image	B-Task
-	I-Task
sr	I-Task
-	I-Task
objective	I-Task
with	O
the	O
fidelity	B-Task
of	I-Task
motion	I-Task
compensation	I-Task
in	O
eq	O
:	O
motion	B-Task
-	I-Task
compensation	I-Task
-	I-Task
objective	I-Task
,	O
namely	O
	
section	O
:	O
Experiments	O
and	O
results	O
	
In	O
this	O
section	O
,	O
we	O
first	O
analyse	O
spatio	B-Method
-	I-Method
temporal	I-Method
networks	I-Method
for	O
video	B-Task
SR	O
in	O
isolation	O
and	O
later	O
evaluate	O
the	O
benefits	O
of	O
introducing	O
motion	B-Task
compensation	I-Task
.	O
	
We	O
restrict	O
our	O
experiments	O
to	O
tackle	O
and	O
upscaling	O
of	O
full	O
HD	O
video	B-Task
resolution	O
(	O
)	O
,	O
and	O
no	O
compression	B-Method
is	O
applied	O
.	O
	
To	O
ensure	O
a	O
fair	O
comparison	O
of	O
methods	O
,	O
the	O
number	O
of	O
network	O
parameters	O
need	O
to	O
be	O
comparable	O
so	O
that	O
gains	O
in	O
performance	O
can	O
be	O
attributed	O
to	O
specific	O
choices	O
of	O
network	B-Task
resource	I-Task
allocation	I-Task
and	O
not	O
to	O
a	O
trivial	O
increase	O
in	O
capacity	O
.	O
	
For	O
a	O
layer	O
,	O
the	O
number	O
of	O
floating	O
-	O
point	O
operations	O
to	O
reconstruct	O
a	O
frame	O
is	O
approximated	O
by	O
In	O
measuring	O
the	O
complexity	B-Metric
of	O
slow	B-Method
fusion	I-Method
networks	I-Method
with	O
weight	B-Method
sharing	I-Method
we	O
look	O
at	O
steady	O
-	O
state	O
operation	O
where	O
the	O
output	O
of	O
some	O
layers	O
is	O
reused	O
from	O
one	O
frame	O
to	O
the	O
following	O
.	O
	
We	O
note	O
that	O
the	O
analysis	O
of	O
VSRnet	B-Task
variants	I-Task
in	O
does	O
not	O
take	O
into	O
account	O
model	O
complexity	O
.	O
	
subsection	O
:	O
Experimental	O
setup	O
	
subsubsection	O
:	O
Data	O
	
We	O
use	O
the	O
CDVL	O
database	O
,	O
which	O
contains	O
uncompressed	O
full	O
HD	O
videos	O
excluding	O
repeated	O
videos	O
,	O
and	O
choose	O
a	O
subset	O
of	O
videos	O
for	O
training	O
.	O
	
The	O
videos	O
are	O
downscaled	O
and	O
random	O
samples	O
are	O
extracted	O
from	O
each	O
HR	O
-	O
LR	O
video	B-Task
pair	O
to	O
obtain	O
training	O
samples	O
,	O
of	O
which	O
are	O
used	O
for	O
validation	B-Task
.	O
	
Depending	O
on	O
the	O
network	B-Method
architecture	I-Method
,	O
we	O
refer	O
to	O
a	O
sample	O
as	O
a	O
single	O
input	O
-	O
output	O
frame	O
pair	O
for	O
single	B-Method
frame	I-Method
networks	I-Method
,	O
or	O
as	O
a	O
block	O
of	O
consecutive	O
LR	O
input	O
frames	O
and	O
the	O
corresponding	O
central	O
HR	O
frame	O
for	O
spatio	B-Method
-	I-Method
temporal	I-Method
networks	I-Method
.	O
	
The	O
remaining	O
videos	O
are	O
used	O
for	O
testing	O
.	O
	
Although	O
the	O
total	O
number	O
of	O
training	O
frames	O
is	O
large	O
,	O
we	O
foresee	O
that	O
the	O
methods	O
presented	O
could	O
benefit	O
from	O
a	O
richer	O
,	O
more	O
diverse	O
set	O
of	O
videos	O
.	O
	
Additionally	O
,	O
we	O
present	O
a	O
benchmark	O
against	O
various	O
SR	B-Method
methods	I-Method
on	O
publicly	O
available	O
videos	O
that	O
are	O
recurrently	O
used	O
in	O
the	O
literature	O
and	O
we	O
refer	O
to	O
as	O
Vid4	B-Material
.	O
	
subsubsection	O
:	O
Network	B-Method
training	I-Method
and	O
parameters	O
	
All	O
SR	B-Method
models	I-Method
are	O
trained	O
following	O
the	O
same	O
protocol	O
and	O
share	O
similar	O
hyperparameters	O
.	O
	
Filter	O
sizes	O
are	O
set	O
to	O
,	O
and	O
all	O
non	O
-	O
linearities	O
are	O
rectified	B-Method
linear	I-Method
units	I-Method
except	O
for	O
the	O
output	O
layer	O
,	O
which	O
uses	O
a	O
linear	O
activation	O
.	O
	
Biases	O
are	O
initialised	O
to	O
and	O
weights	O
use	O
orthogonal	B-Method
initialisation	I-Method
with	O
gain	O
following	O
recommendations	O
in	O
.	O
	
All	O
hidden	O
layers	O
are	O
set	O
to	O
have	O
the	O
same	O
number	O
of	O
features	O
.	O
	
Video	O
samples	O
are	O
broken	O
into	O
non	O
-	O
overlapping	O
sub	O
-	O
samples	O
of	O
spatial	O
dimensions	O
,	O
which	O
are	O
randomly	O
grouped	O
in	O
batches	O
for	O
stochastic	B-Task
optimisation	I-Task
.	O
	
We	O
employ	O
Adam	B-Method
with	O
a	O
learning	B-Metric
rate	I-Metric
and	O
an	O
initial	O
batch	O
size	O
.	O
	
Every	O
epochs	O
the	O
batch	O
size	O
is	O
doubled	O
until	O
it	O
reaches	O
a	O
maximum	O
size	O
of	O
.	O
	
We	O
choose	O
for	O
layers	O
where	O
the	O
network	O
temporal	O
depth	O
is	O
(	O
layers	O
in	O
gray	O
in	O
fig	O
:	O
early	O
-	O
fusion	O
,	O
fig	O
:	O
slow	O
-	O
fusion	O
,	O
fig:3dconv	O
)	O
,	O
and	O
to	O
maintain	O
comparable	O
network	O
sizes	O
we	O
choose	O
.	O
	
This	O
ensures	O
that	O
the	O
number	O
of	O
features	O
per	O
hidden	O
layer	O
in	O
early	O
and	O
slow	B-Method
fusion	I-Method
networks	I-Method
is	O
always	O
the	O
same	O
.	O
	
For	O
instance	O
,	O
the	O
network	O
shown	O
in	O
fig	O
:	O
slow	B-Method
-	I-Method
fusion	I-Method
,	O
for	O
which	O
and	O
for	O
,	O
the	O
number	O
of	O
features	O
in	O
a	O
layer	B-Method
network	I-Method
for	O
SR	B-Task
would	O
be	O
6	O
,	O
8	O
,	O
12	O
,	O
24	O
,	O
24	O
,	O
.	O
	
subsection	O
:	O
Spatio	B-Task
-	I-Task
temporal	I-Task
video	I-Task
SR	I-Task
	
subsubsection	O
:	O
Single	O
vs	O
multi	B-Method
frame	I-Method
early	I-Method
fusion	I-Method
	
First	O
,	O
we	O
investigate	O
the	O
impact	O
of	O
the	O
number	O
of	O
input	O
frames	O
on	O
complexity	B-Metric
and	O
accuracy	B-Metric
without	O
motion	B-Task
compensation	I-Task
.	O
	
We	O
compare	O
single	B-Method
frame	I-Method
models	I-Method
(	O
SF	B-Method
)	O
against	O
early	B-Method
fusion	I-Method
spatio	I-Method
-	I-Method
temporal	I-Method
models	I-Method
using	O
3	O
,	O
5	O
and	O
7	O
input	O
frames	O
(	O
E3	O
,	O
E5	O
and	O
E7	O
)	O
.	O
	
PSNR	B-Metric
results	O
on	O
the	O
CDVL	O
dataset	O
for	O
networks	O
of	O
6	O
to	O
11	O
layers	O
are	O
plotted	O
in	O
fig	O
:	O
single	O
-	O
vs	O
-	O
multi	O
-	O
frame	O
.	O
	
Exploiting	O
spatio	O
-	O
temporal	O
correlations	O
provides	O
a	O
more	O
accurate	O
result	O
relative	O
to	O
an	O
independent	O
processing	O
of	O
frames	O
.	O
	
The	O
increase	O
in	O
complexity	B-Metric
from	O
early	B-Method
fusion	I-Method
is	O
marginal	O
because	O
only	O
the	O
first	O
layer	O
contributes	O
to	O
an	O
increase	O
of	O
operations	B-Metric
.	O
	
Although	O
the	O
accuracy	B-Metric
of	O
spatio	B-Method
-	I-Method
temporal	I-Method
models	I-Method
is	O
relatively	O
similar	O
,	O
we	O
find	O
that	O
E7	O
slightly	O
underperforms	O
.	O
	
It	O
is	O
likely	O
that	O
temporal	O
dependencies	O
beyond	O
5	O
frames	O
become	O
too	O
complex	O
for	O
networks	O
to	O
learn	O
useful	O
information	O
and	O
act	O
as	O
noise	O
degrading	O
their	O
performance	O
.	O
	
Notice	O
also	O
that	O
,	O
whereas	O
the	O
performance	O
increase	O
from	O
network	O
depth	O
is	O
minimal	O
after	O
8	O
layers	O
for	O
single	B-Method
frame	I-Method
networks	I-Method
,	O
this	O
increase	O
is	O
more	O
consistent	O
for	O
spatio	B-Method
-	I-Method
temporal	I-Method
models	I-Method
.	O
	
subsubsection	O
:	O
Early	O
vs	O
slow	O
fusion	O
	
Here	O
we	O
compare	O
the	O
different	O
treatments	O
of	O
the	O
temporal	O
dimension	O
discussed	O
in	O
ssec	B-Method
:	I-Method
st	I-Method
-	I-Method
networks	I-Method
.	O
	
We	O
assume	O
networks	O
with	O
an	O
input	O
of	O
frames	O
and	O
slow	B-Method
fusion	I-Method
models	I-Method
with	O
filter	O
temporal	O
depths	O
as	O
in	O
fig	O
:	O
st	B-Method
-	I-Method
networks	I-Method
.	O
	
Using	O
SF	O
,	O
E5	O
,	O
S5	O
,	O
and	O
S5	O
-	O
SW	O
to	O
refer	O
to	O
single	B-Method
frame	I-Method
networks	I-Method
and	O
5	O
frame	B-Method
input	I-Method
networks	I-Method
using	O
early	B-Method
fusion	I-Method
,	O
slow	B-Method
fusion	I-Method
,	O
and	O
slow	B-Method
fusion	I-Method
with	O
shared	O
weights	O
,	O
we	O
show	O
in	O
tab	O
:	O
early	O
-	O
vs	O
-	O
slow	B-Method
-	I-Method
fusion	I-Method
results	O
for	O
7	O
and	O
9	O
layer	B-Method
networks	I-Method
.	O
	
As	O
seen	O
previously	O
,	O
early	O
fusion	B-Method
networks	I-Method
attain	O
a	O
higher	O
accuracy	B-Metric
at	O
a	O
marginal	O
3	O
%	O
increase	O
in	O
operations	B-Metric
relative	O
to	O
the	O
single	B-Method
frame	I-Method
models	I-Method
,	O
and	O
as	O
expected	O
,	O
slow	B-Method
fusion	I-Method
architectures	I-Method
provide	O
efficiency	O
advantages	O
.	O
	
Slow	B-Method
fusion	I-Method
is	O
faster	O
than	O
early	B-Method
fusion	I-Method
because	O
it	O
uses	O
fewer	O
features	O
in	O
the	O
initial	O
layers	O
.	O
	
Referring	O
to	O
eq	O
:	O
operations	O
,	O
slow	B-Method
fusion	I-Method
uses	O
in	O
the	O
first	O
layers	O
and	O
,	O
which	O
results	O
in	O
fewer	O
operations	O
than	O
,	O
as	O
used	O
in	O
early	B-Method
fusion	I-Method
.	O
	
While	O
the	O
7	B-Method
layer	I-Method
network	I-Method
sees	O
a	O
considerable	O
decrease	O
in	O
accuracy	B-Metric
using	O
slow	B-Method
fusion	I-Method
relative	O
to	O
early	B-Method
fusion	I-Method
,	O
the	O
9	B-Method
layer	I-Method
network	I-Method
can	O
benefit	O
from	O
the	O
same	O
accuracy	B-Metric
while	O
reducing	O
its	O
complexity	B-Metric
with	O
slow	B-Method
fusion	I-Method
by	O
about	O
30	O
%	O
.	O
	
This	O
suggests	O
that	O
in	O
shallow	B-Method
networks	I-Method
the	O
best	O
use	O
of	O
network	O
resources	O
is	O
to	O
utilise	O
the	O
full	B-Method
network	I-Method
capacity	I-Method
to	O
jointly	O
process	O
all	O
temporal	O
information	O
as	O
done	O
by	O
early	B-Method
fusion	I-Method
,	O
but	O
that	O
in	O
deeper	B-Method
networks	I-Method
slowly	O
fusing	O
the	O
temporal	O
dimension	O
is	O
beneficial	O
,	O
which	O
is	O
in	O
line	O
with	O
the	O
results	O
presented	O
by	O
for	O
video	B-Task
classification	O
.	O
	
Additionally	O
,	O
weight	B-Method
sharing	I-Method
decreases	O
accuracy	B-Metric
because	O
of	O
the	O
reduction	O
in	O
network	O
parameters	O
,	O
but	O
the	O
reusability	O
of	O
network	O
features	O
means	O
fewer	O
operations	O
are	O
needed	O
per	O
frame	O
.	O
	
For	O
instance	O
,	O
the	O
7	B-Method
layer	I-Method
S5	I-Method
-	I-Method
SW	I-Method
network	I-Method
shows	O
a	O
reduction	O
of	O
almost	O
30	O
%	O
of	O
operations	O
with	O
a	O
minimal	O
decrease	O
in	O
accuracy	B-Metric
relative	O
to	O
SF	B-Method
.	O
	
Using	O
7	O
layers	O
with	O
E5	O
nevertheless	O
shows	O
better	O
performance	O
and	O
faster	O
operation	O
than	O
S5	B-Method
-	I-Method
SW	I-Method
with	O
9	O
layers	O
,	O
and	O
in	O
all	O
cases	O
we	O
found	O
that	O
early	O
or	O
slow	B-Method
fusion	I-Method
consistently	O
outperformed	O
slow	B-Method
fusion	I-Method
with	O
shared	O
weights	O
in	O
this	O
performance	O
and	O
efficiency	B-Metric
trade	O
-	O
off	O
.	O
	
Convolutions	B-Method
in	O
spatio	O
-	O
temporal	O
domain	O
were	O
shown	O
in	O
to	O
work	O
well	O
for	O
video	B-Task
action	O
recognition	O
,	O
but	O
with	O
larger	O
capacity	O
and	O
many	O
more	O
frames	O
processed	O
jointly	O
.	O
	
We	O
speculate	O
this	O
could	O
be	O
the	O
reason	O
why	O
the	O
conclusions	O
drawn	O
from	O
this	O
high	B-Task
-	I-Task
level	I-Task
vision	I-Task
task	I-Task
do	O
not	O
extrapolate	O
to	O
the	O
SR	B-Task
problem	I-Task
.	O
	
subsection	O
:	O
Motion	O
compensated	O
video	B-Task
SR	O
	
[	O
b	O
]	O
0.32	O
[	O
b	O
]	O
0.32	O
	
[	O
b	O
]	O
0.32	O
	
In	O
this	O
section	O
,	O
the	O
proposed	O
frame	B-Method
motion	I-Method
compensation	I-Method
is	O
combined	O
with	O
an	O
early	B-Method
fusion	I-Method
network	I-Method
of	I-Method
temporal	I-Method
depth	I-Method
.	O
	
First	O
,	O
the	O
motion	B-Method
compensation	I-Method
module	I-Method
is	O
trained	O
independently	O
using	O
eq	O
:	O
video	B-Task
-	O
sr	O
-	O
memc	O
,	O
where	O
the	O
first	O
term	O
is	O
ignored	O
and	O
,	O
.	O
	
This	O
results	O
in	O
a	O
network	O
that	O
will	O
compensate	O
the	O
motion	O
of	O
three	O
consecutive	O
frames	O
by	O
estimating	O
the	O
flow	O
maps	O
of	O
outer	O
frames	O
relative	O
to	O
the	O
middle	O
frame	O
.	O
	
An	O
example	O
of	O
a	O
flow	B-Task
map	I-Task
obtained	O
for	O
one	O
frame	O
is	O
shown	O
in	O
fig	O
:	O
memc	O
,	O
where	O
we	O
also	O
show	O
the	O
effect	O
the	O
motion	B-Method
compensation	I-Method
module	I-Method
has	O
on	O
three	O
consecutive	O
frames	O
.	O
	
The	O
early	B-Method
fusion	I-Method
motion	I-Method
compensated	I-Method
SR	I-Method
network	I-Method
(	O
E3	B-Method
-	I-Method
MC	I-Method
)	O
is	O
initialised	O
with	O
a	O
compensation	B-Method
and	O
a	O
SR	B-Method
network	I-Method
pretrained	O
separately	O
,	O
and	O
the	O
full	B-Method
model	I-Method
is	O
then	O
jointly	O
optimised	O
with	O
eq	O
:	O
video	B-Task
-	O
sr	O
-	O
memc	O
(	O
,	O
)	O
.	O
	
Results	O
for	O
SR	B-Task
on	O
CDVL	B-Task
are	O
compared	O
in	O
tab	O
:	O
motion	O
-	O
compensated	O
-	O
video	B-Task
-	O
sr	O
against	O
a	O
single	O
frame	O
(	O
SF	B-Method
)	I-Method
model	I-Method
and	O
early	B-Method
fusion	I-Method
without	O
motion	B-Method
compensation	I-Method
(	O
E3	O
)	O
.	O
	
E3	B-Method
-	I-Method
MC	I-Method
results	O
in	O
a	O
PSNR	B-Metric
that	O
is	O
sometimes	O
almost	O
twice	O
the	O
improvement	O
of	O
E3	B-Metric
relative	O
to	O
SF	O
,	O
which	O
we	O
attribute	O
to	O
the	O
fact	O
that	O
the	O
network	O
adapts	O
the	O
SR	O
input	O
to	O
maximise	O
temporal	O
redundancy	O
.	O
	
In	O
fig	O
:	O
mcsr	O
-	O
x3	O
	
we	O
show	O
how	O
this	O
improvement	O
is	O
reflected	O
in	O
better	O
structure	B-Task
preservation	I-Task
.	O
	
subsection	O
:	O
Comparison	O
to	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
	
We	O
show	O
in	O
tab	O
:	O
set4	O
the	O
performance	O
on	O
Vid4	B-Material
for	O
SRCNN	B-Method
,	O
ESPCN	B-Method
,	O
VSRnet	B-Method
and	O
the	O
proposed	O
method	O
,	O
which	O
we	O
refer	O
to	O
as	O
video	B-Method
ESPCN	I-Method
(	O
VESPCN	B-Method
)	O
.	O
	
To	O
demonstrate	O
its	O
benefits	O
in	O
efficiency	O
and	O
quality	B-Metric
we	O
evaluate	O
two	O
early	B-Method
fusion	I-Method
models	I-Method
:	O
a	O
5	B-Method
layer	I-Method
3	I-Method
frame	I-Method
network	I-Method
(	O
5L	O
-	O
E3	B-Method
)	O
and	O
a	O
9	B-Method
layer	I-Method
3	I-Method
frame	I-Method
network	I-Method
with	O
motion	B-Method
compensation	I-Method
(	O
9L	O
-	O
E3	O
-	O
MC	O
)	O
.	O
	
The	O
metrics	O
compared	O
are	O
PSNR	B-Metric
,	O
SSIM	B-Metric
and	O
MOVIE	B-Metric
indices	O
.	O
	
The	O
MOVIE	B-Metric
index	I-Metric
was	O
designed	O
as	O
a	O
metric	O
measuring	O
video	B-Task
quality	O
that	O
correlates	O
with	O
human	O
perception	O
and	O
incorporates	O
a	O
notion	O
of	O
temporal	B-Metric
consistency	I-Metric
.	O
	
We	O
also	O
directly	O
compare	O
the	O
number	O
of	O
operations	O
per	O
frame	O
of	O
all	O
CNN	B-Method
-	I-Method
based	I-Method
approaches	I-Method
for	O
upscaling	O
a	O
generic	O
p	O
frame	O
.	O
	
Reconstructions	B-Method
for	O
SRCNN	B-Method
,	O
ESPCN	B-Method
and	O
VSRnet	B-Method
use	O
models	O
provided	O
by	O
the	O
authors	O
.	O
	
SRCNN	B-Method
,	O
ESPCN	B-Method
and	O
VESPCN	B-Method
were	O
tested	O
on	O
Theano	O
and	O
Lasagne	O
,	O
and	O
for	O
VSRnet	B-Method
we	O
used	O
available	O
Caffe	O
Matlab	O
code	O
.	O
	
We	O
crop	O
spatial	O
borders	O
as	O
well	O
as	O
initial	O
and	O
final	O
frames	O
on	O
all	O
reconstructions	O
for	O
fair	O
comparison	O
against	O
VSRnet	B-Method
.	O
	
subsubsection	O
:	O
Quality	B-Metric
comparison	I-Metric
	
An	O
example	O
of	O
visual	O
differences	O
is	O
shown	O
in	O
fig	O
:	O
set4	O
-	O
visualisation	O
against	O
the	O
motion	B-Method
compensated	I-Method
network	I-Method
.	O
	
From	O
the	O
close	O
-	O
up	O
images	O
,	O
we	O
see	O
how	O
the	O
structural	O
detail	O
of	O
the	O
original	O
video	B-Task
is	O
better	O
recovered	O
by	O
the	O
proposed	O
VESPCN	B-Method
method	I-Method
.	O
	
This	O
is	O
reflected	O
in	O
tab	O
:	O
	
set4	O
,	O
where	O
it	O
surpasses	O
any	O
other	O
method	O
in	O
PSNR	B-Metric
and	O
SSIM	B-Metric
by	O
a	O
large	O
margin	O
.	O
	
fig	O
:	O
	
set4	O
-	O
visualisation	O
also	O
shows	O
temporal	O
profiles	O
on	O
the	O
row	O
highlighted	O
by	O
a	O
dashed	O
line	O
through	O
25	O
consecutive	O
frames	O
,	O
demonstrating	O
a	O
better	O
temporal	O
coherence	O
of	O
the	O
reconstruction	B-Method
proposed	O
.	O
	
The	O
great	O
temporal	O
coherence	O
of	O
VESPCN	B-Method
also	O
explains	O
the	O
significant	O
reduction	O
in	O
the	O
MOVIE	B-Metric
index	I-Metric
.	O
	
subsubsection	O
:	O
Efficiency	B-Metric
comparison	I-Metric
	
The	O
complexity	B-Metric
of	O
methods	O
in	O
tab	O
:	O
set4	O
is	O
determined	O
by	O
network	B-Method
and	O
input	O
image	O
sizes	O
.	O
	
SRCNN	B-Method
and	O
VSRnet	B-Method
upsample	O
LR	O
images	O
before	O
attempting	O
to	O
super	O
-	O
resolve	O
them	O
,	O
which	O
considerably	O
increases	O
the	O
required	O
number	O
of	O
operations	O
.	O
	
VSRnet	B-Method
is	O
particularly	O
expensive	O
because	O
it	O
processes	O
input	O
frames	O
in	O
and	O
feature	O
layers	O
,	O
whereas	O
sub	B-Method
-	I-Method
pixel	I-Method
convolution	I-Method
greatly	O
reduces	O
the	O
number	O
of	O
operations	O
required	O
in	O
ESPCN	B-Method
and	O
VESPCN	B-Method
.	O
	
As	O
a	O
reference	O
,	O
ESPCN	B-Method
runs	O
at	O
ms	O
per	O
frame	O
on	O
a	O
K2	O
GPU	O
.	O
	
The	O
enhanced	O
capabilities	O
of	O
spatio	B-Method
-	I-Method
temporal	I-Method
networks	I-Method
allow	O
to	O
reduce	O
the	O
network	O
operations	O
of	O
VESPCN	B-Method
relative	O
to	O
ESPCN	B-Method
while	O
still	O
matching	O
its	O
accuracy	B-Metric
.	O
	
As	O
an	O
example	O
we	O
show	O
VESPCN	B-Method
with	O
5L	O
-	O
E3	O
,	O
which	O
reduces	O
the	O
number	O
of	O
operations	O
by	O
about	O
20	O
%	O
relative	O
to	O
ESPCN	B-Method
while	O
maintaining	O
a	O
similar	O
performance	O
in	O
all	O
evaluated	O
quality	B-Metric
metrics	I-Metric
.	O
	
The	O
operations	O
for	O
motion	B-Task
compensation	I-Task
in	O
VESPCN	B-Method
with	O
9L	O
-	O
E3	O
-	O
MC	O
,	O
included	O
in	O
tab	O
:	O
set4	O
results	O
,	O
amount	O
to	O
and	O
GOps	O
for	O
and	O
upscaling	O
,	O
applied	O
twice	O
for	O
each	O
input	O
frame	O
requiring	O
motion	B-Task
compensation	I-Task
.	O
	
This	O
makes	O
the	O
proposed	O
motion	O
compensated	O
video	B-Task
SR	O
very	O
efficient	O
relative	O
to	O
other	O
approaches	O
.	O
	
For	O
example	O
,	O
motion	B-Task
compensation	I-Task
in	O
VSRnet	B-Task
is	O
said	O
to	O
require	O
55	O
seconds	O
per	O
frame	O
and	O
is	O
the	O
computational	B-Metric
bottleneck	I-Metric
.	O
	
This	O
is	O
not	O
accounted	O
for	O
in	O
tab	O
:	O
	
set4	O
but	O
is	O
slower	O
than	O
VESPCN	B-Method
with	O
9L	O
-	O
E3	O
-	O
MC	O
,	O
which	O
can	O
run	O
in	O
the	O
order	O
of	O
seconds	O
.	O
	
The	O
optical	B-Method
flow	I-Method
method	I-Method
in	O
VSRnet	B-Method
was	O
originally	O
shown	O
to	O
run	O
at	O
ms	O
on	O
GPU	O
for	O
each	O
frame	O
of	O
dimensions	O
,	O
but	O
this	O
is	O
still	O
considerably	O
slower	O
than	O
the	O
proposed	O
solution	O
considering	O
motion	B-Task
compensation	I-Task
is	O
required	O
for	O
more	O
than	O
a	O
single	O
frame	O
of	O
HD	O
dimensions	O
.	O
	
section	O
:	O
Conclusion	O
	
In	O
this	O
paper	O
we	O
combine	O
the	O
efficiency	O
advantages	O
of	O
sub	B-Method
-	I-Method
pixel	I-Method
convolutions	I-Method
with	O
temporal	B-Method
fusion	I-Method
strategies	I-Method
to	O
present	O
real	B-Method
-	I-Method
time	I-Method
spatio	I-Method
-	I-Method
temporal	I-Method
models	I-Method
for	O
video	B-Task
SR	O
.	O
	
The	O
spatio	B-Method
-	I-Method
temporal	I-Method
models	I-Method
used	O
are	O
shown	O
to	O
facilitate	O
an	O
improvement	O
in	O
reconstruction	B-Metric
accuracy	I-Metric
and	O
temporal	B-Metric
consistency	I-Metric
or	O
reduce	O
computational	B-Metric
complexity	I-Metric
relative	O
to	O
independent	O
single	B-Method
frame	I-Method
processing	I-Method
.	O
	
The	O
models	O
investigated	O
are	O
extended	O
with	O
a	O
motion	B-Method
compensation	I-Method
mechanism	I-Method
based	O
on	O
spatial	B-Method
transformer	I-Method
networks	I-Method
that	O
is	O
efficient	O
and	O
jointly	O
trainable	O
for	O
video	B-Task
SR	O
.	O
	
Results	O
obtained	O
with	O
approaches	O
that	O
incorporate	O
explicit	B-Task
motion	I-Task
compensation	I-Task
are	O
demonstrated	O
to	O
be	O
superior	O
in	O
terms	O
of	O
PSNR	B-Metric
and	O
temporal	B-Metric
consistency	I-Metric
compared	O
to	O
spatio	B-Method
-	I-Method
temporal	I-Method
models	I-Method
alone	O
,	O
and	O
outperform	O
the	O
current	O
state	O
of	O
the	O
art	O
in	O
video	B-Task
SR	O
.	O
	
bibliography	O
:	O
References	O
	
document	O
:	O
LINE	B-Method
:	O
Large	B-Method
-	I-Method
scale	I-Method
Information	I-Method
Network	I-Method
Embedding	I-Method
	
This	O
paper	O
studies	O
the	O
problem	O
of	O
embedding	B-Task
very	I-Task
large	I-Task
information	I-Task
networks	I-Task
into	O
low	B-Task
-	I-Task
dimensional	I-Task
vector	I-Task
spaces	I-Task
,	O
which	O
is	O
useful	O
in	O
many	O
tasks	O
such	O
as	O
visualization	B-Task
,	O
node	B-Task
classification	I-Task
,	O
and	O
link	B-Task
prediction	I-Task
.	O
	
Most	O
existing	O
graph	B-Method
embedding	I-Method
methods	I-Method
do	O
not	O
scale	O
for	O
real	B-Task
world	I-Task
information	I-Task
networks	I-Task
which	O
usually	O
contain	O
millions	O
of	O
nodes	O
.	O
	
In	O
this	O
paper	O
,	O
we	O
propose	O
a	O
novel	O
network	B-Method
embedding	I-Method
method	I-Method
called	O
the	O
“	O
LINE	B-Method
,	O
”	O
which	O
is	O
suitable	O
for	O
arbitrary	O
types	O
of	O
information	B-Task
networks	I-Task
:	O
undirected	O
,	O
directed	O
,	O
and	O
/	O
or	O
weighted	O
.	O
	
The	O
method	O
optimizes	O
a	O
carefully	O
designed	O
objective	B-Method
function	I-Method
that	O
preserves	O
both	O
the	O
local	O
and	O
global	O
network	O
structures	O
.	O
	
An	O
edge	B-Method
-	I-Method
sampling	I-Method
algorithm	I-Method
is	O
proposed	O
that	O
addresses	O
the	O
limitation	O
of	O
the	O
classical	O
stochastic	B-Method
gradient	I-Method
descent	I-Method
and	O
improves	O
both	O
the	O
effectiveness	O
and	O
the	O
efficiency	O
of	O
the	O
inference	B-Task
.	O
	
Empirical	O
experiments	O
prove	O
the	O
effectiveness	O
of	O
the	O
LINE	B-Method
on	O
a	O
variety	O
of	O
real	B-Task
-	I-Task
world	I-Task
information	I-Task
networks	I-Task
,	O
including	O
language	O
networks	O
,	O
social	O
networks	O
,	O
and	O
citation	O
networks	O
.	O
	
The	O
algorithm	O
is	O
very	O
efficient	O
,	O
which	O
is	O
able	O
to	O
learn	O
the	O
embedding	B-Task
of	O
a	O
network	O
with	O
millions	O
of	O
vertices	O
and	O
billions	O
of	O
edges	O
in	O
a	O
few	O
hours	O
on	O
a	O
typical	O
single	O
machine	O
.	O
	
The	O
source	O
code	O
of	O
the	O
LINE	B-Method
is	O
available	O
online	O
.	O
	
CopyrightisheldbytheInternationalWorldWideWebConferenceCommittee	O
(	O
IW3C2	O
)	O
.IW3C2reservestherighttoprovideahyperlinktotheauthor’ssiteiftheMaterialisusedinelectronicmedia	O
.	O
	
WWW2015	O
,	O
May18–22	O
,	O
2015	O
,	O
Florence	O
,	O
Italy	O
.	O
	
ACM	O
978	O
-	O
1	O
-	O
4503	O
-	O
3469	O
-	O
3	O
/	O
15	O
/	O
05	O
.	O
	
http:	O
//	O
dx.doi.org	O
/	O
10.1145	O
/	O
2736277.2741093	O
I.2.6Artificial	O
IntelligenceLearning	O
Algorithms	O
,	O
Experimentation	O
	
section	O
:	O
Introduction	O
	
Information	B-Task
networks	I-Task
are	O
ubiquitous	O
in	O
the	O
real	O
world	O
with	O
examples	O
such	O
as	O
airline	B-Task
networks	I-Task
,	O
publication	B-Task
networks	I-Task
,	O
social	B-Task
and	I-Task
communication	I-Task
networks	I-Task
,	O
and	O
the	O
World	B-Task
Wide	I-Task
Web	I-Task
.	O
	
The	O
size	O
of	O
these	O
information	B-Task
networks	I-Task
ranges	O
from	O
hundreds	O
of	O
nodes	O
to	O
millions	O
and	O
billions	O
of	O
nodes	O
.	O
	
Analyzing	B-Task
large	I-Task
information	I-Task
networks	I-Task
has	O
been	O
attracting	O
increasing	O
attention	O
in	O
both	O
academia	O
and	O
industry	O
.	O
	
This	O
paper	O
studies	O
the	O
problem	O
of	O
embedding	B-Task
information	I-Task
networks	I-Task
into	O
low	B-Task
-	I-Task
dimensional	I-Task
spaces	I-Task
,	O
in	O
which	O
every	O
vertex	O
is	O
represented	O
as	O
a	O
low	O
-	O
dimensional	O
vector	O
.	O
	
Such	O
a	O
low	B-Method
-	I-Method
dimensional	I-Method
embedding	I-Method
is	O
very	O
useful	O
in	O
a	O
variety	O
of	O
applications	O
such	O
as	O
visualization	B-Task
,	O
node	B-Task
classification	I-Task
,	O
link	B-Task
prediction	I-Task
,	O
and	O
recommendation	B-Task
.	O
	
Various	O
methods	O
of	O
graph	B-Method
embedding	I-Method
have	O
been	O
proposed	O
in	O
the	O
machine	O
learning	O
literature	O
(	O
e.g.	O
,	O
)	O
.	O
	
They	O
generally	O
perform	O
well	O
on	O
smaller	O
networks	O
.	O
	
The	O
problem	O
becomes	O
much	O
more	O
challenging	O
when	O
a	O
real	B-Task
world	I-Task
information	I-Task
network	I-Task
is	O
concerned	O
,	O
which	O
typically	O
contains	O
millions	O
of	O
nodes	O
and	O
billions	O
of	O
edges	O
.	O
	
For	O
example	O
,	O
the	O
Twitter	B-Task
followee	I-Task
-	I-Task
follower	I-Task
network	I-Task
contains	O
175	O
million	O
active	O
users	O
and	O
around	O
twenty	O
billion	O
edges	O
in	O
2012	O
.	O
	
Most	O
existing	O
graph	B-Method
embedding	I-Method
algorithms	I-Method
do	O
not	O
scale	O
for	O
networks	O
of	O
this	O
size	O
.	O
	
For	O
example	O
,	O
the	O
time	B-Metric
complexity	I-Metric
of	O
classical	O
graph	B-Method
embedding	I-Method
algorithms	I-Method
such	O
as	O
MDS	B-Method
,	O
IsoMap	B-Method
,	O
Laplacian	B-Method
eigenmap	I-Method
are	O
at	O
least	O
quadratic	O
to	O
the	O
number	O
of	O
vertices	O
,	O
which	O
is	O
too	O
expensive	O
for	O
networks	O
with	O
millions	O
of	O
nodes	O
.	O
	
Although	O
a	O
few	O
very	O
recent	O
studies	O
approach	O
the	O
embedding	B-Task
of	I-Task
large	I-Task
-	I-Task
scale	I-Task
networks	I-Task
,	O
these	O
methods	O
either	O
use	O
an	O
indirect	B-Method
approach	I-Method
that	O
is	O
not	O
designed	O
for	O
networks	O
(	O
e.g.	O
,	O
)	O
or	O
lack	O
a	O
clear	O
objective	O
function	O
tailored	O
for	O
network	B-Task
embedding	I-Task
(	O
e.g.	O
,	O
)	O
.	O
	
We	O
anticipate	O
that	O
a	O
new	O
model	O
with	O
a	O
carefully	O
designed	O
objective	B-Metric
function	I-Metric
that	O
preserves	O
properties	O
of	O
the	O
graph	O
and	O
an	O
efficient	O
optimization	B-Method
technique	I-Method
should	O
effectively	O
find	O
the	O
embedding	B-Task
of	I-Task
millions	I-Task
of	I-Task
nodes	I-Task
.	O
	
In	O
this	O
paper	O
,	O
we	O
propose	O
such	O
a	O
network	B-Method
embedding	I-Method
model	I-Method
called	O
the	O
“	O
LINE	B-Method
,	O
”	O
which	O
is	O
able	O
to	O
scale	O
to	O
very	O
large	O
,	O
arbitrary	O
types	O
of	O
networks	O
:	O
undirected	O
,	O
directed	O
and	O
/	O
or	O
weighted	O
.	O
	
The	O
model	O
optimizes	O
an	O
objective	O
which	O
preserves	O
both	O
the	O
local	O
and	O
global	O
network	O
structures	O
.	O
	
Naturally	O
,	O
the	O
local	O
structures	O
are	O
represented	O
by	O
the	O
observed	O
links	O
in	O
the	O
networks	O
,	O
which	O
capture	O
the	O
first	O
-	O
order	O
proximity	O
between	O
the	O
vertices	O
.	O
	
Most	O
existing	O
graph	B-Method
embedding	I-Method
algorithms	I-Method
are	O
designed	O
to	O
preserve	O
this	O
first	O
-	O
order	O
proximity	O
,	O
e.g.	O
,	O
IsoMap	O
and	O
Laplacian	B-Method
eigenmap	I-Method
,	O
even	O
if	O
they	O
do	O
not	O
scale	O
.	O
	
We	O
observe	O
that	O
in	O
a	O
real	O
-	O
world	O
network	O
many	O
(	O
if	O
not	O
the	O
majority	O
of	O
)	O
legitimate	O
links	O
are	O
actually	O
not	O
observed	O
.	O
	
In	O
other	O
words	O
,	O
the	O
observed	O
first	O
-	O
order	O
proximity	O
in	O
the	O
real	O
world	O
data	O
is	O
not	O
sufficient	O
for	O
preserving	O
the	O
global	O
network	O
structures	O
.	O
	
As	O
a	O
complement	O
,	O
we	O
explore	O
the	O
second	O
-	O
order	O
proximity	O
between	O
the	O
vertices	O
,	O
which	O
is	O
not	O
determined	O
through	O
the	O
observed	O
tie	O
strength	O
but	O
through	O
the	O
shared	O
neighborhood	O
structures	O
of	O
the	O
vertices	O
.	O
	
The	O
general	O
notion	O
of	O
the	O
second	O
-	O
order	O
proximity	O
can	O
be	O
interpreted	O
as	O
nodes	O
with	O
shared	O
neighbors	O
being	O
likely	O
to	O
be	O
similar	O
.	O
	
Such	O
an	O
intuition	O
can	O
be	O
found	O
in	O
the	O
theories	O
of	O
sociology	B-Task
and	O
linguistics	B-Task
.	O
	
For	O
example	O
,	O
“	O
the	O
degree	O
of	O
overlap	O
of	O
two	O
people	O
’s	O
friendship	O
networks	O
correlates	O
with	O
the	O
strength	O
of	O
ties	O
between	O
them	O
,	O
”	O
in	O
a	O
social	B-Task
network	I-Task
;	O
and	O
“	O
	
You	O
shall	O
know	O
a	O
word	O
by	O
the	O
company	O
it	O
keeps	O
”	O
(	O
Firth	O
,	O
J.	O
R.	O
1957:11	O
)	O
in	O
text	O
corpora	O
.	O
	
Indeed	O
,	O
people	O
who	O
share	O
many	O
common	O
friends	O
are	O
likely	O
to	O
share	O
the	O
same	O
interest	O
and	O
become	O
friends	O
,	O
and	O
words	O
that	O
are	O
used	O
together	O
with	O
many	O
similar	O
words	O
are	O
likely	O
to	O
have	O
similar	O
meanings	O
.	O
	
Fig	O
.	O
	
[	O
reference	O
]	O
presents	O
an	O
illustrative	O
example	O
.	O
	
As	O
the	O
weight	O
of	O
the	O
edge	O
between	O
vertex	O
6	O
and	O
7	O
is	O
large	O
,	O
i.e.	O
,	O
6	O
and	O
7	O
have	O
a	O
high	O
first	O
-	O
order	O
proximity	O
,	O
they	O
should	O
be	O
represented	O
closely	O
to	O
each	O
other	O
in	O
the	O
embedded	O
space	O
.	O
	
On	O
the	O
other	O
hand	O
,	O
though	O
there	O
is	O
no	O
link	O
between	O
vertex	O
5	O
and	O
6	O
,	O
they	O
share	O
many	O
common	O
neighbors	O
,	O
i.e.	O
,	O
they	O
have	O
a	O
high	O
second	O
-	O
order	O
proximity	O
and	O
therefore	O
should	O
also	O
be	O
represented	O
closely	O
to	O
each	O
other	O
.	O
	
We	O
expect	O
that	O
the	O
consideration	O
of	O
the	O
second	O
-	O
order	O
proximity	O
effectively	O
complements	O
the	O
sparsity	O
of	O
the	O
first	O
-	O
order	O
proximity	O
and	O
better	O
preserves	O
the	O
global	O
structure	O
of	O
the	O
network	O
.	O
	
In	O
this	O
paper	O
,	O
we	O
will	O
present	O
carefully	O
designed	O
objectives	O
that	O
preserve	O
the	O
first	O
-	O
order	O
and	O
the	O
second	O
-	O
order	O
proximities	O
.	O
	
Even	O
if	O
a	O
sound	O
objective	O
is	O
found	O
,	O
optimizing	O
it	O
for	O
a	O
very	O
large	O
network	O
is	O
challenging	O
.	O
	
One	O
approach	O
that	O
attracts	O
attention	O
in	O
recent	O
years	O
is	O
using	O
the	O
stochastic	B-Method
gradient	I-Method
descent	I-Method
for	O
the	O
optimization	B-Task
.	O
	
However	O
,	O
we	O
show	O
that	O
directly	O
deploying	O
the	O
stochastic	B-Method
gradient	I-Method
descent	I-Method
is	O
problematic	O
for	O
real	B-Task
world	I-Task
information	I-Task
networks	I-Task
.	O
	
This	O
is	O
because	O
in	O
many	O
networks	O
,	O
edges	O
are	O
weighted	O
and	O
the	O
weights	O
usually	O
present	O
a	O
high	O
variance	O
.	O
	
Consider	O
a	O
word	B-Method
co	I-Method
-	I-Method
occurrence	I-Method
network	I-Method
,	O
in	O
which	O
the	O
weights	O
(	O
co	O
-	O
occurrences	O
)	O
of	O
word	O
pairs	O
may	O
range	O
from	O
one	O
to	O
hundreds	O
of	O
thousands	O
.	O
	
These	O
weights	O
of	O
the	O
edges	O
will	O
be	O
multiplied	O
into	O
the	O
gradients	O
,	O
resulting	O
in	O
the	O
explosion	O
of	O
the	O
gradients	O
and	O
thus	O
compromise	O
the	O
performance	O
.	O
	
To	O
address	O
this	O
,	O
we	O
propose	O
a	O
novel	O
edge	B-Method
-	I-Method
sampling	I-Method
method	I-Method
,	O
which	O
improves	O
both	O
the	O
effectiveness	O
and	O
efficiency	O
of	O
the	O
inference	B-Task
.	O
	
We	O
sample	O
the	O
edges	O
with	O
the	O
probabilities	O
proportional	O
to	O
their	O
weights	O
,	O
and	O
then	O
treat	O
the	O
sampled	O
edges	O
as	O
binary	O
edges	O
for	O
model	B-Task
updating	I-Task
.	O
	
With	O
this	O
sampling	B-Method
process	I-Method
,	O
the	O
objective	O
function	O
remains	O
the	O
same	O
and	O
the	O
weights	O
of	O
the	O
edges	O
no	O
longer	O
affect	O
the	O
gradients	O
.	O
	
The	O
LINE	B-Method
is	O
very	O
general	O
,	O
which	O
works	O
well	O
for	O
directed	B-Task
or	O
undirected	B-Task
,	O
weighted	B-Task
or	O
unweighted	B-Task
graphs	I-Task
.	O
	
We	O
evaluate	O
the	O
performance	O
of	O
the	O
LINE	B-Method
with	O
various	O
real	B-Task
-	I-Task
world	I-Task
information	I-Task
networks	I-Task
,	O
including	O
language	O
networks	O
,	O
social	O
networks	O
,	O
and	O
citation	O
networks	O
.	O
	
The	O
effectiveness	O
of	O
the	O
learned	O
embeddings	O
is	O
evaluated	O
within	O
multiple	O
data	B-Task
mining	I-Task
tasks	I-Task
,	O
including	O
word	B-Task
analogy	I-Task
,	O
text	B-Task
classification	I-Task
,	O
and	O
node	B-Task
classification	I-Task
.	O
	
The	O
results	O
suggest	O
that	O
the	O
LINE	B-Method
model	O
outperforms	O
other	O
competitive	O
baselines	O
in	O
terms	O
of	O
both	O
effectiveness	B-Metric
and	O
efficiency	B-Metric
.	O
	
It	O
is	O
able	O
to	O
learn	O
the	O
embedding	O
of	O
a	O
network	O
with	O
millions	O
of	O
nodes	O
and	O
billions	O
of	O
edges	O
in	O
a	O
few	O
hours	O
on	O
a	O
single	O
machine	O
.	O
	
To	O
summarize	O
,	O
we	O
make	O
the	O
following	O
contributions	O
:	O
We	O
propose	O
a	O
novel	O
network	B-Method
embedding	I-Method
model	I-Method
called	O
the	O
“	O
LINE	B-Method
,	O
”	O
which	O
suits	O
arbitrary	O
types	O
of	O
information	B-Task
networks	I-Task
and	O
easily	O
scales	O
to	O
millions	O
of	O
nodes	O
.	O
	
It	O
has	O
a	O
carefully	O
designed	O
objective	O
function	O
that	O
preserves	O
both	O
the	O
first	O
-	O
order	O
and	O
second	O
-	O
order	O
proximities	O
.	O
	
We	O
propose	O
an	O
edge	B-Method
-	I-Method
sampling	I-Method
algorithm	I-Method
for	O
optimizing	O
the	O
objective	B-Task
.	O
	
The	O
algorithm	O
tackles	O
the	O
limitation	O
of	O
the	O
classical	O
stochastic	B-Method
gradient	I-Method
decent	I-Method
and	O
improves	O
the	O
effectiveness	O
and	O
efficiency	O
of	O
the	O
inference	B-Task
.	O
	
We	O
conduct	O
extensive	O
experiments	O
on	O
real	B-Task
-	I-Task
world	I-Task
information	I-Task
networks	I-Task
.	O
	
Experimental	O
results	O
prove	O
the	O
effectiveness	O
and	O
efficiency	O
of	O
the	O
proposed	O
LINE	B-Method
model	O
.	O
	
Organization	O
.	O
	
The	O
rest	O
of	O
this	O
paper	O
is	O
organized	O
as	O
follows	O
.	O
	
Section	O
[	O
reference	O
]	O
summarizes	O
the	O
related	O
work	O
.	O
	
Section	O
[	O
reference	O
]	O
formally	O
defines	O
the	O
problem	O
of	O
large	B-Task
-	I-Task
scale	I-Task
information	I-Task
network	I-Task
embedding	I-Task
.	O
	
Section	O
[	O
reference	O
]	O
introduces	O
the	O
LINE	B-Method
model	O
in	O
details	O
.	O
	
Section	O
[	O
reference	O
]	O
presents	O
the	O
experimental	O
results	O
.	O
	
Finally	O
we	O
conclude	O
in	O
Section	O
[	O
reference	O
]	O
.	O
	
section	O
:	O
Related	O
Work	O
	
Our	O
work	O
is	O
related	O
to	O
classical	O
methods	O
of	O
graph	B-Task
embedding	I-Task
or	O
dimension	B-Task
reduction	I-Task
in	O
general	O
,	O
such	O
as	O
multidimensional	B-Method
scaling	I-Method
(	O
MDS	B-Method
)	O
,	O
IsoMap	B-Method
,	O
LLE	B-Method
and	O
Laplacian	B-Method
Eigenmap	I-Method
.	O
	
These	O
approaches	O
typically	O
first	O
construct	O
the	O
affinity	B-Method
graph	I-Method
using	O
the	O
feature	O
vectors	O
of	O
the	O
data	O
points	O
,	O
e.g.	O
,	O
the	O
K	B-Method
-	I-Method
nearest	I-Method
neighbor	I-Method
graph	I-Method
of	I-Method
data	I-Method
,	O
and	O
then	O
embed	O
the	O
affinity	B-Method
graph	I-Method
into	O
a	O
low	O
dimensional	O
space	O
.	O
	
However	O
,	O
these	O
algorithms	O
usually	O
rely	O
on	O
solving	O
the	O
leading	O
eigenvectors	O
of	O
the	O
affinity	O
matrices	O
,	O
the	O
complexity	B-Metric
of	O
which	O
is	O
at	O
least	O
quadratic	O
to	O
the	O
number	O
of	O
nodes	O
,	O
making	O
them	O
inefficient	O
to	O
handle	O
large	B-Task
-	I-Task
scale	I-Task
networks	I-Task
.	O
	
Among	O
the	O
most	O
recent	O
literature	O
is	O
a	O
technique	O
called	O
graph	B-Method
factorization	I-Method
.	O
	
It	O
finds	O
the	O
low	B-Task
-	I-Task
dimensional	I-Task
embedding	I-Task
of	I-Task
a	I-Task
large	I-Task
graph	I-Task
through	O
matrix	B-Method
factorization	I-Method
,	O
which	O
is	O
optimized	O
using	O
stochastic	B-Method
gradient	I-Method
descent	I-Method
.	O
	
This	O
is	O
possible	O
because	O
a	O
graph	O
can	O
be	O
represented	O
as	O
an	O
affinity	O
matrix	O
.	O
	
However	O
,	O
the	O
objective	O
of	O
matrix	B-Method
factorization	I-Method
is	O
not	O
designed	O
for	O
networks	B-Task
,	O
therefore	O
does	O
not	O
necessarily	O
preserve	O
the	O
global	O
network	O
structure	O
.	O
	
Intuitively	O
,	O
graph	B-Method
factorization	I-Method
expects	O
nodes	O
with	O
higher	O
first	O
-	O
order	O
proximity	O
are	O
represented	O
closely	O
.	O
	
Instead	O
,	O
the	O
LINE	B-Method
model	O
uses	O
an	O
objective	O
that	O
is	O
particularly	O
designed	O
for	O
networks	B-Task
,	O
which	O
preserves	O
both	O
the	O
first	O
-	O
order	O
and	O
the	O
second	O
-	O
order	O
proximities	O
.	O
	
Practically	O
,	O
the	O
graph	B-Method
factorization	I-Method
method	I-Method
only	O
applies	O
to	O
undirected	O
graphs	O
while	O
the	O
proposed	O
model	O
is	O
applicable	O
for	O
both	O
undirected	B-Task
and	I-Task
directed	I-Task
graphs	I-Task
.	O
	
The	O
most	O
recent	O
work	O
related	O
with	O
ours	O
is	O
DeepWalk	B-Method
,	O
which	O
deploys	O
a	O
truncated	B-Method
random	I-Method
walk	I-Method
for	O
social	B-Task
network	I-Task
embedding	I-Task
.	O
	
Although	O
empirically	O
effective	O
,	O
the	O
DeepWalk	B-Method
does	O
not	O
provide	O
a	O
clear	O
objective	O
that	O
articulates	O
what	O
network	O
properties	O
are	O
preserved	O
.	O
	
Intuitively	O
,	O
DeepWalk	O
expects	O
nodes	O
with	O
higher	O
second	O
-	O
order	O
proximity	O
yield	O
similar	O
low	O
-	O
dimensional	O
representations	O
,	O
while	O
the	O
LINE	B-Method
preserves	O
both	O
first	O
-	O
order	O
and	O
second	O
-	O
order	O
proximities	O
.	O
	
DeepWalk	B-Method
uses	O
random	B-Method
walks	I-Method
to	O
expand	O
the	O
neighborhood	O
of	O
a	O
vertex	O
,	O
which	O
is	O
analogical	O
to	O
a	O
depth	B-Method
-	I-Method
first	I-Method
search	I-Method
.	O
	
We	O
use	O
a	O
breadth	B-Method
-	I-Method
first	I-Method
search	I-Method
strategy	I-Method
,	O
which	O
is	O
a	O
more	O
reasonable	O
approach	O
to	O
the	O
second	O
-	O
order	O
proximity	O
.	O
	
Practically	O
,	O
DeepWalk	B-Method
only	O
applies	O
to	O
unweighted	B-Task
networks	I-Task
,	O
while	O
our	O
model	O
is	O
applicable	O
for	O
networks	O
with	O
both	O
weighted	B-Task
and	O
unweighted	B-Task
edges	I-Task
.	O
	
In	O
Section	O
[	O
reference	O
]	O
,	O
we	O
empirically	O
compare	O
the	O
proposed	O
model	O
with	O
these	O
methods	O
using	O
various	O
real	O
world	O
networks	O
.	O
	
section	O
:	O
Problem	O
Definition	O
	
We	O
formally	O
define	O
the	O
problem	O
of	O
large	B-Task
-	I-Task
scale	I-Task
information	I-Task
network	I-Task
embedding	I-Task
using	O
first	O
-	O
order	O
and	O
second	O
-	O
order	O
proximities	O
.	O
	
We	O
first	O
define	O
an	O
information	B-Task
network	I-Task
as	O
follows	O
:	O
	
theorem	O
:	O
	
(	O
Information	B-Task
Network	I-Task
)	O
	
An	O
information	B-Task
network	I-Task
is	O
defined	O
as	O
=	O
G	O
(	O
V	O
,	O
E	O
)	O
,	O
where	O
V	O
is	O
the	O
set	O
of	O
vertices	O
,	O
each	O
representing	O
a	O
data	O
object	O
and	O
E	O
is	O
the	O
set	O
of	O
edges	O
between	O
the	O
vertices	O
,	O
each	O
representing	O
a	O
relationship	O
between	O
two	O
data	O
objects	O
.	O
	
Each	O
edge	O
∈eE	O
is	O
an	O
ordered	O
pair	O
=	O
	
e	O
(	O
u	O
,	O
v	O
)	O
and	O
is	O
associated	O
with	O
a	O
weight	O
>	O
w⁢uv0	O
,	O
which	O
indicates	O
the	O
strength	O
of	O
the	O
relation	O
.	O
	
If	O
G	O
is	O
undirected	O
,	O
we	O
have	O
	
≡	O
(	O
u	O
,	O
v	O
)(	O
v	O
,	O
u	O
)	O
and	O
≡w⁢uvw⁢vu	O
	
;	O
if	O
G	O
is	O
directed	O
,	O
we	O
have	O
≢	O
(	O
u	O
,	O
v	O
)(	O
v	O
,	O
u	O
)	O
and	O
≢w⁢uvw⁢vu	O
.	O
	
In	O
practice	O
,	O
information	B-Task
networks	I-Task
can	O
be	O
either	O
directed	O
(	O
e.g.	O
,	O
citation	O
networks	O
)	O
or	O
undirected	O
(	O
e.g.	O
,	O
social	O
network	O
of	O
users	O
in	O
Facebook	O
)	O
.	O
	
The	O
weights	O
of	O
the	O
edges	O
can	O
be	O
either	O
binary	O
or	O
take	O
any	O
real	O
value	O
.	O
	
Note	O
that	O
while	O
negative	O
edge	O
weights	O
are	O
possible	O
,	O
in	O
this	O
study	O
we	O
only	O
consider	O
non	O
-	O
negative	O
weights	O
.	O
	
For	O
example	O
,	O
in	O
citation	B-Task
networks	I-Task
and	O
social	B-Task
networks	I-Task
,	O
takes	O
binary	O
values	O
;	O
in	O
co	O
-	O
occurrence	O
networks	O
between	O
different	O
objects	O
,	O
can	O
take	O
any	O
non	O
-	O
negative	O
value	O
.	O
	
The	O
weights	O
of	O
the	O
edges	O
in	O
some	O
networks	O
may	O
diverge	O
as	O
some	O
objects	O
co	O
-	O
occur	O
many	O
times	O
while	O
others	O
may	O
just	O
co	O
-	O
occur	O
a	O
few	O
times	O
.	O
	
Embedding	O
an	O
information	B-Task
network	I-Task
into	O
a	O
low	O
-	O
dimensional	O
space	O
is	O
useful	O
in	O
a	O
variety	O
of	O
applications	O
.	O
	
To	O
conduct	O
the	O
embedding	B-Task
,	O
the	O
network	O
structures	O
must	O
be	O
preserved	O
.	O
	
The	O
first	O
intuition	O
is	O
that	O
the	O
local	O
network	O
structure	O
,	O
i.e.	O
,	O
the	O
local	O
pairwise	O
proximity	O
between	O
the	O
vertices	O
,	O
must	O
be	O
preserved	O
.	O
	
We	O
define	O
the	O
local	O
network	O
structures	O
as	O
the	O
first	O
-	O
order	O
proximity	O
between	O
the	O
vertices	O
:	O
	
theorem	O
:	O
	
(	O
First	O
-	O
order	O
Proximity	O
)	O
	
The	O
first	O
-	O
order	O
proximity	O
in	O
a	O
network	O
is	O
the	O
local	O
pairwise	O
proximity	O
between	O
two	O
vertices	O
.	O
	
For	O
each	O
pair	O
of	O
vertices	O
linked	O
by	O
an	O
edge	O
(	O
u	O
,	O
v	O
)	O
,	O
the	O
weight	O
on	O
that	O
edge	O
,	O
w⁢uv	O
,	O
indicates	O
the	O
first	O
-	O
order	O
proximity	O
between	O
u	O
and	O
v.	O
	
If	O
no	O
edge	O
is	O
observed	O
between	O
u	O
and	O
v	O
,	O
their	O
first	O
-	O
order	O
proximity	O
is	O
0	O
.	O
	
The	O
first	O
-	O
order	O
proximity	O
usually	O
implies	O
the	O
similarity	O
of	O
two	O
nodes	O
in	O
a	O
real	O
-	O
world	O
network	O
.	O
	
For	O
example	O
,	O
people	O
who	O
are	O
friends	O
with	O
each	O
other	O
in	O
a	O
social	O
network	O
tend	O
to	O
share	O
similar	O
interests	O
;	O
pages	O
linking	O
to	O
each	O
other	O
in	O
World	O
Wide	O
Web	O
tend	O
to	O
talk	O
about	O
similar	O
topics	O
.	O
	
Because	O
of	O
this	O
importance	O
,	O
many	O
existing	O
graph	B-Method
embedding	I-Method
algorithms	I-Method
such	O
as	O
IsoMap	B-Method
,	O
LLE	B-Method
,	O
Laplacian	B-Method
eigenmap	I-Method
,	O
and	O
graph	B-Method
factorization	I-Method
have	O
the	O
objective	O
to	O
preserve	O
the	O
first	O
-	O
order	O
proximity	O
.	O
	
However	O
,	O
in	O
a	O
real	B-Task
world	I-Task
information	I-Task
network	I-Task
,	O
the	O
links	O
observed	O
are	O
only	O
a	O
small	O
proportion	O
,	O
with	O
many	O
others	O
missing	O
.	O
	
A	O
pair	O
of	O
nodes	O
on	O
a	O
missing	O
link	O
has	O
a	O
zero	O
first	O
-	O
order	O
proximity	O
,	O
even	O
though	O
they	O
are	O
intrinsically	O
very	O
similar	O
to	O
each	O
other	O
.	O
	
Therefore	O
,	O
first	B-Method
-	I-Method
order	I-Method
proximity	I-Method
alone	O
is	O
not	O
sufficient	O
for	O
preserving	O
the	O
network	O
structures	O
,	O
and	O
it	O
is	O
important	O
to	O
seek	O
an	O
alternative	O
notion	O
of	O
proximity	O
that	O
addresses	O
the	O
problem	O
of	O
sparsity	B-Task
.	O
	
A	O
natural	O
intuition	O
is	O
that	O
vertices	O
that	O
share	O
similar	O
neighbors	O
tend	O
to	O
be	O
similar	O
to	O
each	O
other	O
.	O
	
For	O
example	O
,	O
in	O
social	B-Task
networks	I-Task
,	O
people	O
who	O
share	O
similar	O
friends	O
tend	O
to	O
have	O
similar	O
interests	O
and	O
thus	O
become	O
friends	O
;	O
in	O
word	O
co	O
-	O
occurrence	O
networks	O
,	O
words	O
that	O
always	O
co	O
-	O
occur	O
with	O
the	O
same	O
set	O
of	O
words	O
tend	O
to	O
have	O
similar	O
meanings	O
.	O
	
We	O
therefore	O
define	O
the	O
second	O
-	O
order	O
proximity	O
,	O
which	O
complements	O
the	O
first	O
-	O
order	O
proximity	O
and	O
preserves	O
the	O
network	O
structure	O
.	O
	
theorem	O
:	O
	
(	O
Second	O
-	O
order	O
Proximity	O
)	O
	
The	O
second	O
-	O
order	O
proximity	O
between	O
a	O
pair	O
of	O
vertices	O
(	O
u	O
,	O
v	O
)	O
in	O
a	O
network	O
is	O
the	O
similarity	O
between	O
their	O
neighborhood	O
network	O
structures	O
.	O
	
Mathematically	O
,	O
let	O
=	O
	
pu	O
(	O
wu	O
,	O
1	O
,	O
…	O
,	O
wu	O
,	O
|V|	O
)	O
denote	O
the	O
first	O
-	O
order	O
proximity	O
of	O
u	O
with	O
all	O
the	O
other	O
vertices	O
,	O
then	O
the	O
second	O
-	O
order	O
proximity	O
between	O
u	O
and	O
v	O
is	O
determined	O
by	O
the	O
similarity	O
between	O
pu	O
and	O
pv	O
.	O
	
If	O
no	O
vertex	O
is	O
linked	O
from	O
/	O
to	O
both	O
u	O
and	O
v	O
,	O
	
the	O
second	O
-	O
order	O
proximity	O
between	O
u	O
and	O
v	O
is	O
0	O
.	O
	
We	O
investigate	O
both	O
first	O
-	O
order	O
and	O
second	B-Task
-	I-Task
order	I-Task
proximity	I-Task
for	O
network	B-Task
embedding	I-Task
,	O
which	O
is	O
defined	O
as	O
follows	O
.	O
	
theorem	O
:	O
	
(	O
Large	B-Method
-	I-Method
scale	I-Method
Information	I-Method
Network	I-Method
Embedding	I-Method
)	O
	
Given	O
a	O
large	O
network	O
=	O
	
G	O
(	O
V	O
,	O
E	O
)	O
	
,	O
the	O
problem	O
of	O
Large	B-Method
-	I-Method
scale	I-Method
Information	I-Method
Network	I-Method
Embedding	I-Method
aims	O
to	O
represent	O
each	O
vertex	O
∈vV	O
into	O
a	O
low	O
-	O
dimensional	O
space	O
Rd	O
,	O
i.e.	O
,	O
learning	O
a	O
function	O
:	O
fG→VRd	B-Method
,	O
where	O
≪d|V|.	O
In	O
the	O
space	O
Rd	O
,	O
both	O
the	O
first	O
-	O
order	O
proximity	O
and	O
the	O
second	O
-	O
order	O
proximity	O
between	O
the	O
vertices	O
are	O
preserved	O
.	O
	
Next	O
,	O
we	O
introduce	O
a	O
large	B-Method
-	I-Method
scale	I-Method
network	I-Method
embedding	I-Method
model	I-Method
that	O
preserves	O
both	O
first	O
-	O
and	O
second	O
-	O
order	O
proximities	O
.	O
	
section	O
:	O
LINE	B-Method
:	O
Large	B-Method
-	I-Method
scale	I-Method
Information	I-Method
Network	I-Method
Embedding	I-Method
	
A	O
desirable	O
embedding	B-Method
model	I-Method
for	O
real	B-Task
world	I-Task
information	I-Task
networks	I-Task
must	O
satisfy	O
several	O
requirements	O
:	O
first	O
,	O
it	O
must	O
be	O
able	O
to	O
preserve	O
both	O
the	O
first	O
-	O
order	O
proximity	O
and	O
the	O
second	O
-	O
order	O
proximity	O
between	O
the	O
vertices	O
;	O
second	O
,	O
it	O
must	O
scale	O
for	O
very	O
large	O
networks	O
,	O
say	O
millions	O
of	O
vertices	O
and	O
billions	O
of	O
edges	O
;	O
third	O
,	O
it	O
can	O
deal	O
with	O
networks	O
with	O
arbitrary	O
types	O
of	O
edges	O
:	O
directed	O
,	O
undirected	O
and	O
/	O
or	O
weighted	O
.	O
	
In	O
this	O
section	O
,	O
we	O
present	O
a	O
novel	O
network	B-Method
embedding	I-Method
model	I-Method
called	O
the	O
“	O
LINE	B-Method
,	O
”	O
which	O
satisfies	O
all	O
the	O
three	O
requirements	O
.	O
	
subsection	O
:	O
Model	O
Description	O
	
We	O
describe	O
the	O
LINE	B-Method
model	O
to	O
preserve	O
the	O
first	O
-	O
order	O
proximity	O
and	O
second	O
-	O
order	O
proximity	O
separately	O
,	O
and	O
then	O
introduce	O
a	O
simple	O
way	O
to	O
combine	O
the	O
two	O
proximity	O
.	O
	
subsubsection	O
:	O
LINE	B-Method
with	O
First	B-Method
-	I-Method
order	I-Method
Proximity	I-Method
	
The	O
first	O
-	O
order	O
proximity	O
refers	O
to	O
the	O
local	O
pairwise	O
proximity	O
between	O
the	O
vertices	O
in	O
the	O
network	O
.	O
	
To	O
model	O
the	O
first	O
-	O
order	O
proximity	O
,	O
for	O
each	O
undirected	O
edge	O
,	O
we	O
define	O
the	O
joint	O
probability	O
between	O
vertex	O
and	O
as	O
follows	O
:	O
where	O
is	O
the	O
low	B-Method
-	I-Method
dimensional	I-Method
vector	I-Method
representation	I-Method
of	I-Method
vertex	I-Method
.	O
	
Eqn	O
.	O
	
(	O
[	O
reference	O
]	O
)	O
defines	O
a	O
distribution	O
over	O
the	O
space	O
,	O
and	O
its	O
empirical	O
probability	O
can	O
be	O
defined	O
as	O
,	O
where	O
.	O
	
To	O
preserve	O
the	O
first	O
-	O
order	O
proximity	O
,	O
a	O
straightforward	O
way	O
is	O
to	O
minimize	O
the	O
following	O
objective	O
function	O
:	O
where	O
is	O
the	O
distance	O
between	O
two	O
distributions	O
.	O
	
We	O
choose	O
to	O
minimize	O
the	O
KL	O
-	O
divergence	O
of	O
two	O
probability	O
distributions	O
.	O
	
Replacing	O
with	O
KL	O
-	O
divergence	O
and	O
omitting	O
some	O
constants	O
,	O
we	O
have	O
	
:	O
Note	O
that	O
the	O
first	O
-	O
order	O
proximity	O
is	O
only	O
applicable	O
for	O
undirected	O
graphs	O
,	O
not	O
for	O
directed	O
graphs	O
.	O
	
By	O
finding	O
the	O
that	O
minimize	O
the	O
objective	O
in	O
Eqn	O
.	O
	
(	O
[	O
reference	O
]	O
)	O
	
,	O
we	O
can	O
represent	O
every	O
vertex	O
in	O
the	O
d	O
-	O
dimensional	O
space	O
.	O
	
subsubsection	O
:	O
LINE	B-Method
with	O
Second	B-Method
-	I-Method
order	I-Method
Proximity	I-Method
	
The	O
second	O
-	O
order	O
proximity	O
is	O
applicable	O
for	O
both	O
directed	B-Task
and	I-Task
undirected	I-Task
graphs	I-Task
.	O
	
Given	O
a	O
network	O
,	O
without	O
loss	O
of	O
generality	O
,	O
we	O
assume	O
it	O
is	O
directed	O
(	O
an	O
undirected	O
edge	O
can	O
be	O
considered	O
as	O
two	O
directed	O
edges	O
with	O
opposite	O
directions	O
and	O
equal	O
weights	O
)	O
.	O
	
The	O
second	O
-	O
order	O
proximity	O
assumes	O
that	O
vertices	O
sharing	O
many	O
connections	O
to	O
other	O
vertices	O
are	O
similar	O
to	O
each	O
other	O
.	O
	
In	O
this	O
case	O
,	O
each	O
vertex	O
is	O
also	O
treated	O
as	O
a	O
specific	O
“	O
context	O
”	O
and	O
vertices	O
with	O
similar	O
distributions	O
over	O
the	O
“	O
contexts	O
”	O
are	O
assumed	O
to	O
be	O
similar	O
.	O
	
Therefore	O
,	O
each	O
vertex	O
plays	O
two	O
roles	O
:	O
the	O
vertex	O
itself	O
and	O
a	O
specific	O
“	O
context	O
”	O
of	O
other	O
vertices	O
.	O
	
We	O
introduce	O
two	O
vectors	O
and	O
,	O
where	O
is	O
the	O
representation	O
of	O
when	O
it	O
is	O
treated	O
as	O
a	O
vertex	O
while	O
is	O
the	O
representation	O
of	O
when	O
it	O
is	O
treated	O
as	O
a	O
specific	O
“	O
context	O
”	O
.	O
	
For	O
each	O
directed	O
edge	O
,	O
we	O
first	O
define	O
the	O
probability	O
of	O
“	O
context	O
”	O
generated	O
by	O
vertex	O
as	O
:	O
where	O
is	O
the	O
number	O
of	O
vertices	O
or	O
“	O
contexts	O
.	O
	
”	O
	
For	O
each	O
vertex	O
,	O
Eqn	O
.	O
	
(	O
[	O
reference	O
]	O
)	O
actually	O
defines	O
a	O
conditional	O
distribution	O
over	O
the	O
contexts	O
,	O
i.e.	O
,	O
the	O
entire	O
set	O
of	O
vertices	O
in	O
the	O
network	O
.	O
	
As	O
mentioned	O
above	O
,	O
the	O
second	O
-	O
order	O
proximity	O
assumes	O
that	O
vertices	O
with	O
similar	O
distributions	O
over	O
the	O
contexts	O
are	O
similar	O
to	O
each	O
other	O
.	O
	
To	O
preserve	O
the	O
second	O
-	O
order	O
proximity	O
,	O
we	O
should	O
make	O
the	O
conditional	O
distribution	O
of	O
the	O
contexts	O
specified	O
by	O
the	O
low	B-Method
-	I-Method
dimensional	I-Method
representation	I-Method
be	O
close	O
to	O
the	O
empirical	O
distribution	O
.	O
	
Therefore	O
,	O
we	O
minimize	O
the	O
following	O
objective	B-Metric
function	I-Metric
:	O
where	O
is	O
the	O
distance	O
between	O
two	O
distributions	O
.	O
	
As	O
the	O
importance	O
of	O
the	O
vertices	O
in	O
the	O
network	O
may	O
be	O
different	O
,	O
we	O
introduce	O
in	O
the	O
objective	O
function	O
to	O
represent	O
the	O
prestige	O
of	O
vertex	O
in	O
the	O
network	O
,	O
which	O
can	O
be	O
measured	O
by	O
the	O
degree	O
or	O
estimated	O
through	O
algorithms	O
such	O
as	O
PageRank	B-Method
.	O
	
The	O
empirical	O
distribution	O
is	O
defined	O
as	O
,	O
where	O
is	O
the	O
weight	O
of	O
the	O
edge	O
and	O
is	O
the	O
out	O
-	O
degree	O
of	O
vertex	O
,	O
i.e.	O
,	O
where	O
is	O
the	O
set	O
of	O
out	O
-	O
neighbors	O
of	O
.	O
	
In	O
this	O
paper	O
,	O
for	O
simplicity	O
we	O
set	O
as	O
the	O
degree	O
of	O
vertex	O
,	O
i.e.	O
,	O
,	O
and	O
here	O
we	O
also	O
adopt	O
KL	O
-	O
divergence	O
as	O
the	O
distance	O
function	O
.	O
	
Replacing	O
with	O
KL	O
-	O
divergence	O
,	O
setting	O
and	O
omitting	O
some	O
constants	O
,	O
we	O
have	O
:	O
	
By	O
learning	O
and	O
that	O
minimize	O
this	O
objective	O
,	O
we	O
are	O
able	O
to	O
represent	O
every	O
vertex	O
with	O
a	O
d	O
-	O
dimensional	O
vector	O
.	O
	
subsubsection	O
:	O
Combining	O
first	B-Method
-	I-Method
order	I-Method
and	I-Method
second	I-Method
-	I-Method
order	I-Method
proximities	I-Method
	
To	O
embed	O
the	O
networks	O
by	O
preserving	O
both	O
the	O
first	O
-	O
order	O
and	O
second	O
-	O
order	O
proximity	O
,	O
a	O
simple	O
and	O
effective	O
way	O
we	O
find	O
in	O
practice	O
is	O
to	O
train	O
the	O
LINE	B-Method
model	O
which	O
preserves	O
the	O
first	O
-	O
order	O
proximity	O
and	O
second	O
-	O
order	O
proximity	O
separately	O
and	O
then	O
concatenate	O
the	O
embeddings	O
trained	O
by	O
the	O
two	O
methods	O
for	O
each	O
vertex	O
.	O
	
A	O
more	O
principled	O
way	O
to	O
combine	O
the	O
two	O
proximity	O
is	O
to	O
jointly	O
train	O
the	O
objective	O
function	O
(	O
[	O
reference	O
]	O
)	O
and	O
(	O
[	O
reference	O
]	O
)	O
,	O
which	O
we	O
leave	O
as	O
future	O
work	O
.	O
	
subsection	O
:	O
Model	B-Task
Optimization	I-Task
	
Optimizing	B-Task
objective	I-Task
(	O
[	O
reference	O
]	O
)	O
is	O
computationally	O
expensive	O
,	O
which	O
requires	O
the	O
summation	O
over	O
the	O
entire	O
set	O
of	O
vertices	O
when	O
calculating	O
the	O
conditional	O
probability	O
.	O
	
To	O
address	O
this	O
problem	O
,	O
we	O
adopt	O
the	O
approach	O
of	O
negative	B-Method
sampling	I-Method
proposed	O
in	O
,	O
which	O
samples	O
multiple	O
negative	O
edges	O
according	O
to	O
some	O
noisy	O
distribution	O
for	O
each	O
edge	O
.	O
	
More	O
specifically	O
,	O
it	O
specifies	O
the	O
following	O
objective	O
function	O
for	O
each	O
edge	O
:	O
where	O
is	O
the	O
sigmoid	O
function	O
.	O
	
The	O
first	O
term	O
models	O
the	O
observed	O
edges	O
,	O
the	O
second	O
term	O
models	O
the	O
negative	O
edges	O
drawn	O
from	O
the	O
noise	O
distribution	O
and	O
is	O
the	O
number	O
of	O
negative	O
edges	O
.	O
	
We	O
set	O
as	O
proposed	O
in	O
,	O
where	O
is	O
the	O
out	O
-	O
degree	O
of	O
vertex	O
.	O
	
For	O
the	O
objective	B-Metric
function	I-Metric
(	O
[	O
reference	O
]	O
)	O
,	O
there	O
exists	O
a	O
trivial	O
solution	O
:	O
,	O
for	O
i=	O
and	O
.	O
	
To	O
avoid	O
the	O
trivial	O
solution	O
,	O
we	O
can	O
still	O
utilize	O
the	O
negative	B-Method
sampling	I-Method
approach	I-Method
(	O
[	O
reference	O
]	O
)	O
by	O
just	O
changing	O
to	O
.	O
	
We	O
adopt	O
the	O
asynchronous	B-Method
stochastic	I-Method
gradient	I-Method
algorithm	I-Method
(	O
ASGD	B-Method
)	O
for	O
optimizing	B-Task
Eqn	I-Task
.	O
	
(	O
[	O
reference	O
]	O
)	O
.	O
	
In	O
each	O
step	O
,	O
the	O
ASGD	B-Method
algorithm	I-Method
samples	O
a	O
mini	O
-	O
batch	O
of	O
edges	O
and	O
then	O
updates	O
the	O
model	O
parameters	O
.	O
	
If	O
an	O
edge	O
is	O
sampled	O
,	O
the	O
gradient	O
w.r.t	O
.	O
	
the	O
embedding	O
vector	O
of	O
vertex	O
will	O
be	O
calculated	O
as	O
:	O
	
Note	O
that	O
the	O
gradient	O
will	O
be	O
multiplied	O
by	O
the	O
weight	O
of	O
the	O
edge	O
.	O
	
This	O
will	O
become	O
problematic	O
when	O
the	O
weights	O
of	O
edges	O
have	O
a	O
high	O
variance	O
.	O
	
For	O
example	O
,	O
in	O
a	O
word	B-Method
co	I-Method
-	I-Method
occurrence	I-Method
network	I-Method
,	O
some	O
words	O
co	O
-	O
occur	O
many	O
times	O
(	O
e.g.	O
,	O
tens	O
of	O
thousands	O
)	O
while	O
some	O
words	O
co	O
-	O
occur	O
only	O
a	O
few	O
times	O
.	O
	
In	O
such	O
networks	O
,	O
the	O
scales	O
of	O
the	O
gradients	O
diverge	O
and	O
it	O
is	O
very	O
hard	O
to	O
find	O
a	O
good	O
learning	B-Metric
rate	I-Metric
.	O
	
If	O
we	O
select	O
a	O
large	O
learning	B-Metric
rate	I-Metric
according	O
to	O
the	O
edges	O
with	O
small	O
weights	O
,	O
the	O
gradients	O
on	O
edges	O
with	O
large	O
weights	O
will	O
explode	O
while	O
the	O
gradients	O
will	O
become	O
too	O
small	O
if	O
we	O
select	O
the	O
learning	O
rate	O
according	O
to	O
the	O
edges	O
with	O
large	O
weights	O
.	O
	
subsubsection	O
:	O
Optimization	B-Task
via	O
Edge	B-Method
Sampling	I-Method
	
The	O
intuition	O
in	O
solving	O
the	O
above	O
problem	O
is	O
that	O
if	O
the	O
weights	O
of	O
all	O
the	O
edges	O
are	O
equal	O
(	O
e.g.	O
,	O
network	O
with	O
binary	O
edges	O
)	O
,	O
then	O
there	O
will	O
be	O
no	O
problem	O
of	O
choosing	O
an	O
appropriate	O
learning	O
rate	O
.	O
	
A	O
simple	O
treatment	O
is	O
thus	O
to	O
unfold	O
a	O
weighted	O
edge	O
into	O
multiple	O
binary	O
edges	O
,	O
e.g.	O
,	O
an	O
edge	O
with	O
weight	O
is	O
unfolded	O
into	O
binary	O
edges	O
.	O
	
This	O
will	O
solve	O
the	O
problem	O
but	O
will	O
significantly	O
increase	O
the	O
memory	B-Metric
requirement	I-Metric
,	O
especially	O
when	O
the	O
weights	O
of	O
the	O
edges	O
are	O
very	O
large	O
.	O
	
To	O
resolve	O
this	O
,	O
one	O
can	O
sample	O
from	O
the	O
original	O
edges	O
and	O
treat	O
the	O
sampled	O
edges	O
as	O
binary	O
edges	O
,	O
with	O
the	O
sampling	O
probabilities	O
proportional	O
to	O
the	O
original	O
edge	O
weights	O
.	O
	
With	O
this	O
edge	B-Method
-	I-Method
sampling	I-Method
treatment	I-Method
,	O
the	O
overall	O
objective	B-Metric
function	I-Metric
remains	O
the	O
same	O
.	O
	
The	O
problem	O
boils	O
down	O
to	O
how	O
to	O
sample	O
the	O
edges	O
according	O
to	O
their	O
weights	O
.	O
	
Let	O
denote	O
the	O
sequence	O
of	O
the	O
weights	O
of	O
the	O
edges	O
.	O
	
One	O
can	O
simply	O
calculate	O
the	O
sum	O
of	O
the	O
weights	O
first	O
,	O
and	O
then	O
to	O
sample	O
a	O
random	O
value	O
within	O
the	O
range	O
of	O
to	O
see	O
which	O
interval	O
[	O
the	O
random	O
value	O
falls	O
into	O
.	O
	
This	O
approach	O
takes	O
time	O
to	O
draw	O
a	O
sample	O
,	O
which	O
is	O
costly	O
when	O
the	O
number	O
of	O
edges	O
is	O
large	O
.	O
	
We	O
use	O
the	O
alias	B-Method
table	I-Method
method	I-Method
to	O
draw	O
a	O
sample	O
according	O
to	O
the	O
weights	O
of	O
the	O
edges	O
,	O
which	O
takes	O
only	O
time	O
when	O
repeatedly	O
drawing	O
samples	O
from	O
the	O
same	O
discrete	O
distribution	O
.	O
	
Sampling	O
an	O
edge	O
from	O
the	O
alias	O
table	O
takes	O
constant	O
time	O
,	O
,	O
and	O
optimization	B-Task
with	O
negative	B-Task
sampling	I-Task
takes	O
time	O
,	O
where	O
is	O
the	O
number	O
of	O
negative	O
samples	O
.	O
	
Therefore	O
,	O
overall	O
each	O
step	O
takes	O
time	O
.	O
	
In	O
practice	O
,	O
we	O
find	O
that	O
the	O
number	O
of	O
steps	O
used	O
for	O
optimization	B-Task
is	O
usually	O
proportional	O
to	O
the	O
number	O
of	O
edges	O
.	O
	
Therefore	O
,	O
the	O
overall	O
time	B-Metric
complexity	I-Metric
of	O
the	O
LINE	B-Method
is	O
,	O
which	O
is	O
linear	O
to	O
the	O
number	O
of	O
edges	O
,	O
and	O
does	O
not	O
depend	O
on	O
the	O
number	O
of	O
vertices	O
.	O
	
The	O
edge	B-Method
sampling	I-Method
treatment	I-Method
improves	O
the	O
effectiveness	O
of	O
the	O
stochastic	B-Method
gradient	I-Method
descent	I-Method
without	O
compromising	O
the	O
efficiency	O
.	O
	
subsection	O
:	O
Discussion	O
	
We	O
discuss	O
several	O
practical	O
issues	O
of	O
the	O
LINE	B-Method
model	O
.	O
	
Low	O
degree	O
vertices	O
.	O
	
One	O
practical	O
issue	O
is	O
how	O
to	O
accurately	O
embed	O
vertices	O
with	O
small	O
degrees	O
.	O
	
As	O
the	O
number	O
of	O
neighbors	O
of	O
such	O
a	O
node	O
is	O
very	O
small	O
,	O
it	O
is	O
very	O
hard	O
to	O
accurately	O
infer	O
its	O
representation	O
,	O
especially	O
with	O
the	O
second	B-Method
-	I-Method
order	I-Method
proximity	I-Method
based	I-Method
methods	I-Method
which	O
heavily	O
rely	O
on	O
the	O
number	O
of	O
“	O
contexts	O
.	O
	
”	O
	
An	O
intuitive	O
solution	O
to	O
this	O
is	O
expanding	O
the	O
neighbors	O
of	O
those	O
vertices	O
by	O
adding	O
higher	O
order	O
neighbors	O
,	O
such	O
as	O
neighbors	O
of	O
neighbors	O
.	O
	
In	O
this	O
paper	O
,	O
we	O
only	O
consider	O
adding	O
second	O
-	O
order	O
neighbors	O
,	O
i.e.	O
,	O
neighbors	O
of	O
neighbors	O
,	O
to	O
each	O
vertex	O
.	O
	
The	O
weight	O
between	O
vertex	O
and	O
its	O
second	O
-	O
order	O
neighbor	O
is	O
measured	O
as	O
In	O
practice	O
,	O
one	O
can	O
only	O
add	O
a	O
subset	O
of	O
vertices	O
which	O
have	O
the	O
largest	O
proximity	O
with	O
the	O
low	O
degree	O
vertex	O
.	O
	
New	O
vertices	O
.	O
	
Another	O
practical	O
issue	O
is	O
how	O
to	O
find	O
the	O
representation	O
of	O
newly	O
arrived	O
vertices	O
.	O
	
For	O
a	O
new	O
vertex	O
,	O
if	O
its	O
connections	O
to	O
the	O
existing	O
vertices	O
are	O
known	O
,	O
we	O
can	O
obtain	O
the	O
empirical	O
distribution	O
and	O
over	O
existing	O
vertices	O
.	O
	
To	O
obtain	O
the	O
embedding	O
of	O
the	O
new	O
vertex	O
,	O
according	O
to	O
the	O
objective	O
function	O
Eqn	O
.	O
(	O
[	O
reference	O
]	O
)	O
or	O
Eqn	O
.	O
(	O
[	O
reference	O
]	O
)	O
,	O
a	O
straightforward	O
way	O
is	O
to	O
minimize	O
either	O
one	O
of	O
the	O
following	O
objective	O
functions	O
by	O
updating	O
the	O
embedding	O
of	O
the	O
new	O
vertex	O
and	O
keeping	O
the	O
embeddings	O
of	O
existing	O
vertices	O
.	O
	
If	O
no	O
connections	O
between	O
the	O
new	O
vertex	O
and	O
existing	O
vertices	O
are	O
observed	O
,	O
we	O
must	O
resort	O
to	O
other	O
information	O
,	O
such	O
as	O
the	O
textual	O
information	O
of	O
the	O
vertices	O
,	O
and	O
we	O
leave	O
it	O
as	O
our	O
future	O
work	O
.	O
	
section	O
:	O
Experiments	O
	
We	O
empirically	O
evaluated	O
the	O
effectiveness	O
and	O
efficiency	O
of	O
the	O
LINE	B-Method
.	O
	
We	O
applied	O
the	O
method	O
to	O
several	O
large	B-Task
-	I-Task
scale	I-Task
real	I-Task
-	I-Task
world	I-Task
networks	I-Task
of	O
different	O
types	O
,	O
including	O
a	O
language	O
network	O
,	O
two	O
social	O
networks	O
,	O
and	O
two	O
citation	O
networks	O
.	O
	
subsection	O
:	O
Experiment	O
Setup	O
	
paragraph	O
:	O
Data	O
Sets	O
	
(	O
1	O
)	O
Language	B-Method
network	I-Method
.	O
	
We	O
constructed	O
a	O
word	B-Method
co	I-Method
-	I-Method
occurrence	I-Method
network	I-Method
from	O
the	O
entire	O
set	O
of	O
English	B-Material
Wikipedia	I-Material
pages	I-Material
.	O
	
Words	O
within	O
every	O
5	O
-	O
word	O
sliding	O
window	O
are	O
considered	O
to	O
be	O
co	O
-	O
occurring	O
with	O
each	O
other	O
.	O
	
Words	O
with	O
frequency	O
smaller	O
than	O
5	O
are	O
filtered	O
out	O
.	O
	
(	O
2	O
)	O
Social	O
networks	O
.	O
	
We	O
use	O
two	O
social	O
networks	O
:	O
Flickr	B-Method
and	O
YoutubeAvailable	B-Method
at	O
http:	O
//	O
socialnetworks.mpi	O
-	O
sws.org	O
/	O
data	O
-	O
imc2007.html	O
.	O
	
The	O
Flickr	B-Method
network	I-Method
is	O
denser	O
than	O
the	O
Youtube	B-Method
network	I-Method
(	O
the	O
same	O
network	O
as	O
used	O
in	O
DeepWalk	O
)	O
.	O
	
(	O
3	O
)	O
Citation	O
Networks	O
.	O
	
Two	O
types	O
of	O
citation	B-Method
networks	I-Method
are	O
used	O
:	O
an	O
author	B-Method
citation	I-Method
network	I-Method
and	O
a	O
paper	B-Method
citation	I-Method
network	I-Method
.	O
	
We	O
use	O
the	O
DBLP	O
data	O
set	O
to	O
construct	O
the	O
citation	O
networks	O
between	O
authors	O
and	O
between	O
papers	O
.	O
	
The	O
author	B-Method
citation	I-Method
network	I-Method
records	O
the	O
number	O
of	O
papers	O
written	O
by	O
one	O
author	O
and	O
cited	O
by	O
another	O
author	O
.	O
	
The	O
detailed	O
statistics	O
of	O
these	O
networks	O
are	O
summarized	O
into	O
Table	O
[	O
reference	O
]	O
.	O
	
They	O
represent	O
a	O
variety	O
of	O
information	O
networks	O
:	O
directed	O
and	O
undirected	O
,	O
binary	O
and	O
weighted	O
.	O
	
Each	O
network	O
contains	O
at	O
least	O
half	O
a	O
million	O
nodes	O
and	O
millions	O
of	O
edges	O
,	O
with	O
the	O
largest	O
network	O
containing	O
around	O
two	O
million	O
nodes	O
and	O
a	O
billion	O
edges	O
.	O
	
paragraph	O
:	O
Compared	O
Algorithms	O
	
We	O
compare	O
the	O
LINE	B-Method
model	O
with	O
several	O
existing	O
graph	B-Method
embedding	I-Method
methods	I-Method
that	O
are	O
able	O
to	O
scale	O
up	O
to	O
very	O
large	O
networks	O
.	O
	
We	O
do	O
not	O
compare	O
with	O
some	O
classical	O
graph	B-Method
embedding	I-Method
algorithms	I-Method
such	O
as	O
MDS	B-Method
,	O
IsoMap	B-Method
,	O
and	O
Laplacian	B-Method
eigenmap	I-Method
,	O
as	O
they	O
can	O
not	O
handle	O
networks	O
of	O
this	O
scale	O
.	O
	
Graph	B-Method
factorization	I-Method
(	O
GF	B-Method
)	O
.	O
	
We	O
compare	O
with	O
the	O
matrix	B-Method
factorization	I-Method
techniques	I-Method
for	O
graph	B-Task
factorization	I-Task
.	O
	
An	O
information	B-Task
network	I-Task
can	O
be	O
represented	O
as	O
an	O
affinity	B-Method
matrix	I-Method
,	O
and	O
is	O
able	O
to	O
represent	O
each	O
vertex	O
with	O
a	O
low	O
-	O
dimensional	O
vector	O
through	O
matrix	B-Method
factorization	I-Method
.	O
	
Graph	B-Method
factorization	I-Method
is	O
optimized	O
through	O
stochastic	B-Method
gradient	I-Method
descent	I-Method
and	O
is	O
able	O
to	O
handle	O
large	O
networks	O
.	O
	
It	O
only	O
applies	O
to	O
undirected	B-Task
networks	I-Task
.	O
	
DeepWalk	B-Method
.	O
	
DeepWalk	B-Method
is	O
an	O
approach	O
recently	O
proposed	O
for	O
social	B-Task
network	I-Task
embedding	I-Task
,	O
which	O
is	O
only	O
applicable	O
for	O
networks	O
with	O
binary	O
edges	O
.	O
	
For	O
each	O
vertex	O
,	O
truncated	O
random	O
walks	O
starting	O
from	O
the	O
vertex	O
are	O
used	O
to	O
obtain	O
the	O
contextual	O
information	O
,	O
and	O
therefore	O
only	O
second	O
-	O
order	O
proximity	O
is	O
utilized	O
.	O
	
LINE	B-Method
-	O
SGD	O
.	O
	
This	O
is	O
the	O
LINE	B-Method
model	O
introduced	O
in	O
Section	O
[	O
reference	O
]	O
that	O
optimizes	O
the	O
objective	B-Metric
Eqn	I-Metric
.	O
	
(	O
[	O
reference	O
]	O
)	O
or	O
Eqn	O
.	O
	
(	O
[	O
reference	O
]	O
)	O
directly	O
with	O
stochastic	B-Method
gradient	I-Method
descent	I-Method
.	O
	
With	O
this	O
approach	O
,	O
the	O
weights	O
of	O
the	O
edges	O
are	O
directly	O
multiplied	O
into	O
the	O
gradients	O
when	O
the	O
edges	O
are	O
sampled	O
for	O
model	B-Task
updating	I-Task
.	O
	
There	O
are	O
two	O
variants	O
of	O
this	O
approach	O
:	O
LINE	B-Method
-	O
SGD	O
(	O
1st	O
)	O
and	O
LINE	B-Method
-	O
SGD	O
(	O
2nd	O
)	O
,	O
which	O
use	O
first	O
-	O
and	O
second	O
-	O
order	O
proximity	O
respectively	O
.	O
	
LINE	B-Method
.	O
	
This	O
is	O
the	O
LINE	B-Method
model	O
optimized	O
through	O
the	O
edge	B-Method
-	I-Method
sampling	I-Method
treatment	I-Method
introduced	O
in	O
Section	O
[	O
reference	O
]	O
.	O
	
In	O
each	O
stochastic	O
gradient	O
step	O
,	O
an	O
edge	O
is	O
sampled	O
with	O
the	O
probability	O
proportional	O
to	O
its	O
weight	O
and	O
then	O
treated	O
as	O
binary	O
for	O
model	B-Task
updating	I-Task
.	O
	
There	O
are	O
also	O
two	O
variants	O
:	O
LINE	B-Method
(	I-Method
1st	I-Method
)	I-Method
and	O
LINE	B-Method
(	I-Method
2nd	I-Method
)	I-Method
.	O
	
Like	O
the	O
graph	B-Method
factorization	I-Method
,	O
both	O
LINE	B-Method
(	I-Method
1st	I-Method
)	I-Method
and	O
LINE	B-Method
-	O
SGD	O
(	O
1st	O
)	O
only	O
apply	O
to	O
undirected	B-Method
graphs	I-Method
.	O
	
LINE	B-Method
(	I-Method
2nd	I-Method
)	I-Method
	
and	O
LINE	B-Method
-	O
SGD	O
(	O
2nd	O
)	O
apply	O
to	O
both	O
undirected	B-Method
and	O
directed	B-Method
graphs	I-Method
.	O
	
LINE	B-Method
(	O
1st	B-Method
+	I-Method
2nd	I-Method
)	O
:	O
	
To	O
utilize	O
both	O
first	O
-	O
order	O
and	O
second	O
-	O
order	O
proximity	O
,	O
a	O
simple	O
and	O
effective	O
way	O
is	O
to	O
concatenate	O
the	O
vector	B-Method
representations	I-Method
learned	O
by	O
LINE	B-Method
(	I-Method
1st	I-Method
)	I-Method
and	O
LINE	B-Method
(	I-Method
2nd	I-Method
)	I-Method
into	O
a	O
longer	O
vector	O
.	O
	
After	O
concatenation	O
,	O
the	O
dimensions	O
should	O
be	O
re	O
-	O
weighted	O
to	O
balance	O
the	O
two	O
representations	O
.	O
	
In	O
a	O
supervised	B-Task
learning	I-Task
task	I-Task
,	O
the	O
weighting	O
of	O
dimensions	O
can	O
be	O
automatically	O
found	O
based	O
on	O
the	O
training	O
data	O
.	O
	
In	O
an	O
unsupervised	B-Task
task	I-Task
,	O
however	O
,	O
it	O
is	O
more	O
difficult	O
to	O
set	O
the	O
weights	O
.	O
	
Therefore	O
we	O
only	O
apply	O
LINE	B-Method
(	O
1st	B-Method
+	I-Method
2nd	I-Method
)	O
to	O
the	O
scenario	O
of	O
supervised	B-Task
tasks	I-Task
.	O
	
paragraph	O
:	O
Parameter	O
Settings	O
	
The	O
mini	O
-	O
batch	O
size	O
of	O
the	O
stochastic	B-Method
gradient	I-Method
descent	I-Method
is	O
set	O
as	O
1	O
for	O
all	O
the	O
methods	O
.	O
	
Similar	O
to	O
,	O
the	O
learning	B-Metric
rate	I-Metric
is	O
set	O
with	O
the	O
starting	O
value	O
and	O
,	O
where	O
is	O
the	O
total	O
number	O
of	O
mini	O
-	O
batches	O
or	O
edge	O
samples	O
.	O
	
For	O
fair	O
comparisons	O
,	O
the	O
dimensionality	B-Metric
of	O
the	O
embeddings	O
of	O
the	O
language	B-Method
network	I-Method
is	O
set	O
to	O
200	O
,	O
as	O
used	O
in	O
word	B-Task
embedding	I-Task
.	O
	
For	O
other	O
networks	O
,	O
the	O
dimension	O
is	O
set	O
as	O
128	O
by	O
default	O
,	O
as	O
used	O
in	O
.	O
	
Other	O
default	O
settings	O
include	O
:	O
the	O
number	O
of	O
negative	O
samples	O
for	O
LINE	B-Method
and	O
LINE	B-Method
-	O
SGD	O
;	O
the	O
total	O
number	O
of	O
samples	O
billion	O
for	O
LINE	B-Method
(	I-Method
1st	I-Method
)	I-Method
and	O
LINE	B-Method
(	I-Method
2nd	I-Method
)	I-Method
,	O
billion	O
for	O
GF	B-Method
;	O
window	O
size	O
,	O
walk	O
length	O
,	O
walks	O
per	O
vertex	O
for	O
DeepWalk	B-Method
.	O
	
All	O
the	O
embedding	O
vectors	O
are	O
finally	O
normalized	O
by	O
setting	O
.	O
	
subsection	O
:	O
Quantitative	O
Results	O
	
subsubsection	O
:	O
Language	B-Method
Network	I-Method
	
We	O
start	O
with	O
the	O
results	O
on	O
the	O
language	B-Task
network	I-Task
,	O
which	O
contains	O
two	O
million	O
nodes	O
and	O
a	O
billion	O
edges	O
.	O
	
Two	O
applications	O
are	O
used	O
to	O
evaluate	O
the	O
effectiveness	O
of	O
the	O
learned	O
embeddings	B-Task
:	O
word	B-Task
analogy	I-Task
and	O
document	B-Task
classification	I-Task
.	O
	
Word	B-Task
Analogy	I-Task
.	O
	
This	O
task	O
is	O
introduced	O
by	O
Mikolov	O
et	O
al	O
.	O
.	O
	
Given	O
a	O
word	O
pair	O
and	O
a	O
word	O
,	O
the	O
task	O
aims	O
to	O
find	O
a	O
word	O
,	O
such	O
that	O
the	O
relation	O
between	O
and	O
is	O
similar	O
to	O
the	O
relation	O
between	O
and	O
,	O
or	O
denoted	O
as	O
:	O
.	O
	
For	O
instance	O
,	O
given	O
a	O
word	O
pair	O
(	O
“	O
China”	O
,	O
“Beijing	O
”	O
)	O
and	O
a	O
word	O
“	O
France	O
,	O
”	O
the	O
right	O
answer	O
should	O
be	O
“	O
Paris	O
”	O
because	O
“	O
Beijing	O
”	O
is	O
the	O
capital	O
of	O
“	O
China	O
”	O
just	O
as	O
“	O
Paris	O
”	O
is	O
the	O
capital	O
of	O
“	O
France	O
.	O
	
”	O
	
Given	O
the	O
word	O
embeddings	O
,	O
this	O
task	O
is	O
solved	O
by	O
finding	O
the	O
word	O
whose	O
embedding	O
is	O
closest	O
to	O
the	O
vector	O
in	O
terms	O
of	O
cosine	O
proximity	O
,	O
i.e.	O
,	O
.	O
	
Two	O
categories	O
of	O
word	B-Task
analogy	I-Task
are	O
used	O
in	O
this	O
task	O
:	O
semantic	B-Task
and	I-Task
syntactic	I-Task
.	O
	
Significantly	O
outperforms	O
GF	B-Method
at	O
the	O
:	O
	
*	O
*	O
0.01	O
and	O
*	O
0.05	O
level	O
,	O
paired	O
t	O
-	O
test	O
.	O
	
Table	O
[	O
reference	O
]	O
reports	O
the	O
results	O
of	O
word	B-Task
analogy	I-Task
using	O
the	O
embeddings	O
of	O
words	O
learned	O
on	O
the	O
Wikipedia	B-Material
corpora	I-Material
(	O
SkipGram	B-Material
)	O
or	O
the	O
Wikipedia	B-Material
word	I-Material
network	I-Material
(	O
all	O
other	O
methods	O
)	O
.	O
	
For	O
graph	B-Task
factorization	I-Task
,	O
the	O
weight	O
between	O
each	O
pair	O
of	O
words	O
is	O
defined	O
as	O
the	O
logarithm	O
of	O
the	O
number	O
of	O
co	O
-	O
occurrences	O
,	O
which	O
leads	O
to	O
better	O
performance	O
than	O
the	O
original	O
value	O
of	O
co	O
-	O
occurrences	O
.	O
	
For	O
DeepWalk	B-Method
,	O
different	O
cutoff	O
thresholds	O
are	O
tried	O
to	O
convert	O
the	O
language	O
network	O
into	O
a	O
binary	O
network	O
,	O
and	O
the	O
best	O
performance	O
is	O
achieved	O
when	O
all	O
the	O
edges	O
are	O
kept	O
in	O
the	O
network	O
.	O
	
We	O
also	O
compare	O
with	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
word	O
embedding	O
model	O
SkipGram	B-Material
,	O
which	O
learns	O
the	O
word	O
embeddings	O
directly	O
from	O
the	O
original	O
Wikipedia	B-Material
pages	I-Material
and	O
is	O
also	O
implicitly	O
a	O
matrix	B-Method
factorization	I-Method
approach	I-Method
.	O
	
The	O
window	O
size	O
is	O
set	O
as	O
5	O
,	O
the	O
same	O
as	O
used	O
for	O
constructing	O
the	O
language	B-Method
network	I-Method
.	O
	
We	O
can	O
see	O
that	O
LINE	B-Method
(	I-Method
2nd	I-Method
)	I-Method
outperforms	O
all	O
other	O
methods	O
,	O
including	O
the	O
graph	B-Method
embedding	I-Method
methods	I-Method
and	O
the	O
SkipGram	B-Material
.	O
	
This	O
indicates	O
that	O
the	O
second	O
-	O
order	O
proximity	O
better	O
captures	O
the	O
word	O
semantics	O
compared	O
to	O
the	O
first	O
-	O
order	O
proximity	O
.	O
	
This	O
is	O
not	O
surprising	O
,	O
as	O
a	O
high	O
second	O
-	O
order	O
proximity	O
implies	O
that	O
two	O
words	O
can	O
be	O
replaced	O
in	O
the	O
same	O
context	O
,	O
which	O
is	O
a	O
stronger	O
indicator	O
of	O
similar	O
semantics	O
than	O
first	O
-	O
order	O
co	O
-	O
occurrences	O
.	O
	
It	O
is	O
intriguing	O
that	O
the	O
LINE	B-Method
(	I-Method
2nd	I-Method
)	I-Method
outperforms	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
word	B-Method
embedding	I-Method
model	I-Method
trained	O
on	O
the	O
original	O
corpus	O
.	O
	
The	O
reason	O
may	O
be	O
that	O
a	O
language	B-Method
network	I-Method
better	O
captures	O
the	O
global	O
structure	O
of	O
word	O
co	O
-	O
occurrences	O
than	O
the	O
original	O
word	O
sequences	O
.	O
	
Among	O
other	O
methods	O
,	O
both	O
graph	B-Method
factorization	I-Method
and	O
LINE	B-Method
(	I-Method
1st	I-Method
)	I-Method
significantly	O
outperform	O
DeepWalk	B-Method
even	O
if	O
DeepWalk	B-Method
explores	O
second	O
-	O
order	O
proximity	O
.	O
	
This	O
is	O
because	O
DeepWalk	B-Method
has	O
to	O
ignore	O
the	O
weights	O
(	O
i.e.	O
,	O
co	O
-	O
occurrences	O
)	O
of	O
the	O
edges	O
,	O
which	O
is	O
very	O
important	O
in	O
a	O
language	B-Task
network	I-Task
.	O
	
The	O
performance	O
by	O
the	O
LINE	B-Method
models	O
directly	O
optimized	O
with	O
SGD	B-Method
is	O
much	O
worse	O
,	O
because	O
the	O
weights	O
of	O
the	O
edges	O
in	O
the	O
language	B-Method
network	I-Method
diverge	O
,	O
which	O
range	O
from	O
a	O
single	O
digit	O
to	O
tens	O
of	O
thousands	O
,	O
making	O
the	O
learning	B-Method
process	I-Method
suffer	O
.	O
	
The	O
LINE	B-Method
optimized	O
by	O
the	O
edge	B-Method
-	I-Method
sampling	I-Method
treatment	I-Method
effectively	O
addresses	O
this	O
problem	O
,	O
and	O
performs	O
very	O
well	O
using	O
either	O
first	B-Method
-	I-Method
order	I-Method
or	O
second	O
-	O
order	O
proximity	O
.	O
	
All	O
the	O
models	O
are	O
run	O
on	O
a	O
single	O
machine	O
with	O
1	O
T	O
memory	O
,	O
40	O
CPU	O
cores	O
at	O
2.0GHZ	O
using	O
16	O
threads	O
.	O
	
Both	O
the	O
LINE	B-Method
(	I-Method
1st	I-Method
)	I-Method
and	O
LINE	B-Method
(	I-Method
2nd	I-Method
)	I-Method
are	O
quite	O
efficient	O
,	O
which	O
take	O
less	O
than	O
3	O
hours	O
to	O
process	O
such	O
a	O
network	O
with	O
2	O
million	O
nodes	O
and	O
a	O
billion	O
edges	O
.	O
	
Both	O
are	O
at	O
least	O
10	O
%	O
faster	O
than	O
graph	B-Method
factorization	I-Method
,	O
and	O
much	O
more	O
efficient	O
than	O
DeepWalk	B-Method
(	O
five	O
times	O
slower	O
)	O
.	O
	
The	O
reason	O
that	O
LINE	B-Method
-	O
SGDs	O
are	O
slightly	O
slower	O
is	O
that	O
a	O
threshold	B-Method
-	I-Method
cutting	I-Method
technique	I-Method
has	O
to	O
be	O
applied	O
to	O
prevent	O
the	O
gradients	O
from	O
exploding	O
.	O
	
Document	B-Task
Classification	I-Task
.	O
	
Another	O
way	O
to	O
evaluate	O
the	O
quality	O
of	O
the	O
word	O
embeddings	O
is	O
to	O
use	O
the	O
word	O
vectors	O
to	O
compute	O
document	B-Task
representation	I-Task
,	O
which	O
can	O
be	O
evaluated	O
with	O
document	B-Task
classification	I-Task
tasks	I-Task
.	O
	
To	O
obtain	O
document	O
vectors	O
,	O
we	O
choose	O
a	O
very	O
simple	O
approach	O
,	O
taking	O
the	O
average	O
of	O
the	O
word	B-Method
vector	I-Method
representations	I-Method
in	O
that	O
document	O
.	O
	
This	O
is	O
because	O
we	O
aim	O
to	O
compare	O
the	O
word	B-Method
embeddings	I-Method
with	O
different	O
approaches	O
instead	O
of	O
finding	O
the	O
best	O
method	O
for	O
document	B-Task
embeddings	I-Task
.	O
	
The	O
readers	O
can	O
find	O
advanced	O
document	B-Method
embedding	I-Method
approaches	I-Method
in	O
.	O
	
We	O
download	O
the	O
abstracts	O
of	O
Wikipedia	B-Material
pages	I-Material
from	O
and	O
the	O
categories	O
of	O
these	O
pages	O
from	O
.	O
	
We	O
choose	O
7	O
diverse	O
categories	O
for	O
classification	B-Task
including	O
“	O
Arts	O
,	O
”	O
“	O
History	O
,	O
”	O
“	O
Human	O
,	O
”	O
“	O
Mathematics	O
,	O
”	O
“	O
Nature	O
,	O
”	O
“	O
Technology	O
,	O
”	O
and	O
“	O
Sports	O
.	O
	
”	O
	
For	O
each	O
category	O
,	O
we	O
randomly	O
select	O
10	O
,	O
000	O
articles	O
,	O
and	O
articles	O
belonging	O
to	O
multiple	O
categories	O
are	O
discarded	O
.	O
	
We	O
randomly	O
sample	O
different	O
percentages	O
of	O
the	O
labeled	O
documents	O
for	O
training	O
and	O
use	O
the	O
rest	O
for	O
evaluation	B-Task
.	O
	
All	O
document	O
vectors	O
are	O
used	O
to	O
train	O
a	O
one	B-Method
-	I-Method
vs	I-Method
-	I-Method
rest	I-Method
logistic	I-Method
regression	I-Method
classifier	I-Method
using	O
the	O
LibLinear	B-Method
package	I-Method
.	O
	
We	O
report	O
the	O
classification	B-Metric
metrics	I-Metric
Micro	I-Metric
-	I-Metric
F1	I-Metric
and	O
Macro	B-Metric
-	I-Metric
F1	I-Metric
.	O
	
The	O
results	O
are	O
averaged	O
over	O
10	O
different	O
runs	O
by	O
sampling	O
different	O
training	O
data	O
.	O
	
Table	O
[	O
reference	O
]	O
reports	O
the	O
results	O
of	O
Wikipedia	B-Task
page	I-Task
classification	I-Task
.	O
	
Similar	O
conclusion	O
can	O
be	O
made	O
as	O
in	O
the	O
word	B-Task
analogy	I-Task
task	I-Task
.	O
	
The	O
graph	B-Method
factorization	I-Method
outperforms	O
DeepWalk	B-Method
as	O
DeepWalk	B-Method
ignores	O
the	O
weights	O
of	O
the	O
edges	O
.	O
	
The	O
LINE	B-Method
-	O
SGDs	O
perform	O
worse	O
due	O
to	O
the	O
divergence	O
of	O
the	O
weights	O
of	O
the	O
edges	O
.	O
	
The	O
LINE	B-Method
optimized	O
by	O
the	O
edge	B-Method
-	I-Method
sampling	I-Method
treatment	I-Method
performs	O
much	O
better	O
than	O
directly	O
deploying	O
SGD	B-Method
.	O
	
The	O
LINE	B-Method
(	I-Method
2nd	I-Method
)	I-Method
outperforms	O
LINE	B-Method
(	I-Method
1st	I-Method
)	I-Method
and	O
is	O
slightly	O
better	O
than	O
the	O
graph	B-Method
factorization	I-Method
.	O
	
Note	O
that	O
with	O
the	O
supervised	B-Task
task	I-Task
,	O
it	O
is	O
feasible	O
to	O
concatenate	O
the	O
embeddings	O
learned	O
with	O
LINE	B-Method
(	I-Method
1st	I-Method
)	I-Method
and	O
LINE	B-Method
(	I-Method
2nd	I-Method
)	I-Method
.	O
	
As	O
a	O
result	O
,	O
the	O
LINE	B-Method
(	O
1st	B-Method
+	I-Method
2nd	I-Method
)	O
method	O
performs	O
significantly	O
better	O
than	O
all	O
other	O
methods	O
.	O
	
This	O
indicates	O
that	O
the	O
first	O
-	O
order	O
and	O
second	O
-	O
order	O
proximities	O
are	O
complementary	O
to	O
each	O
other	O
.	O
	
To	O
provide	O
the	O
readers	O
more	O
insight	O
about	O
the	O
first	O
-	O
order	O
and	O
second	O
-	O
order	O
proximities	O
,	O
Table	O
[	O
reference	O
]	O
compares	O
the	O
most	O
similar	O
words	O
to	O
a	O
given	O
word	O
using	O
first	O
-	O
order	O
and	O
second	O
-	O
order	O
proximity	O
.	O
	
We	O
can	O
see	O
that	O
by	O
using	O
the	O
contextual	O
proximity	O
,	O
the	O
most	O
similar	O
words	O
returned	O
by	O
the	O
second	O
-	O
order	O
proximity	O
are	O
all	O
semantically	O
related	O
words	O
.	O
	
The	O
most	O
similar	O
words	O
returned	O
by	O
the	O
first	B-Method
-	I-Method
order	I-Method
proximity	I-Method
are	O
a	O
mixture	O
of	O
syntactically	O
and	O
semantically	O
related	O
words	O
.	O
	
subsubsection	O
:	O
Social	B-Method
Network	I-Method
	
Significantly	O
outperforms	O
DeepWalk	B-Method
at	O
the	O
:	O
	
*	O
*	O
0.01	O
and	O
*	O
0.05	O
level	O
,	O
paired	O
t	O
-	O
test	O
.	O
	
Compared	O
with	O
the	O
language	B-Method
networks	I-Method
,	O
the	O
social	B-Method
networks	I-Method
are	O
much	O
sparser	O
,	O
especially	O
the	O
Youtube	B-Method
network	I-Method
.	O
	
We	O
evaluate	O
the	O
vertex	O
embeddings	O
through	O
a	O
multi	B-Task
-	I-Task
label	I-Task
classification	I-Task
task	I-Task
that	O
assigns	O
every	O
node	O
into	O
one	O
or	O
more	O
communities	O
.	O
	
Different	O
percentages	O
of	O
the	O
vertices	O
are	O
randomly	O
sampled	O
for	O
training	O
and	O
the	O
rest	O
are	O
used	O
for	O
evaluation	O
.	O
	
The	O
results	O
are	O
averaged	O
over	O
10	O
different	O
runs	O
.	O
	
Flickr	B-Method
Network	I-Method
.	O
	
Let	O
us	O
first	O
take	O
a	O
look	O
at	O
the	O
results	O
on	O
the	O
Flickr	B-Method
network	I-Method
.	O
	
We	O
choose	O
the	O
most	O
popular	O
5	O
communities	O
as	O
the	O
categories	O
of	O
the	O
vertices	O
for	O
multi	B-Task
-	I-Task
label	I-Task
classification	I-Task
.	O
	
Table	O
[	O
reference	O
]	O
reports	O
the	O
results	O
.	O
	
Again	O
,	O
LINE	B-Method
(	O
1st	B-Method
+	I-Method
2nd	I-Method
)	O
significantly	O
outperforms	O
all	O
other	O
methods	O
.	O
	
LINE	B-Method
(	I-Method
1st	I-Method
)	I-Method
is	O
slightly	O
better	O
than	O
LINE	B-Method
(	I-Method
2nd	I-Method
)	I-Method
,	O
which	O
is	O
opposite	O
to	O
the	O
results	O
on	O
the	O
language	B-Method
network	I-Method
.	O
	
The	O
reasons	O
are	O
two	O
fold	O
:	O
(	O
1	O
)	O
first	O
-	O
order	O
proximity	O
is	O
still	O
more	O
important	O
than	O
second	O
-	O
order	O
proximity	O
in	O
social	B-Method
network	I-Method
,	O
which	O
indicates	O
strong	O
ties	O
;	O
(	O
2	O
)	O
when	O
the	O
network	O
is	O
too	O
sparse	O
and	O
the	O
average	O
number	O
of	O
neighbors	O
of	O
a	O
node	O
is	O
too	O
small	O
,	O
the	O
second	O
-	O
order	O
proximity	O
may	O
become	O
inaccurate	O
.	O
	
We	O
will	O
further	O
investigate	O
this	O
issue	O
in	O
Section	O
[	O
reference	O
]	O
.	O
	
LINE	B-Method
(	I-Method
1st	I-Method
)	I-Method
outperforms	O
graph	B-Method
factorization	I-Method
,	O
indicating	O
a	O
better	O
capability	O
of	O
modeling	O
the	O
first	O
-	O
order	O
proximity	O
.	O
	
LINE	B-Method
(	I-Method
2nd	I-Method
)	I-Method
outperforms	O
DeepWalk	B-Method
,	O
indicating	O
a	O
better	O
capability	O
of	O
modeling	O
the	O
second	O
-	O
order	O
proximity	O
.	O
	
By	O
concatenating	O
the	O
representations	O
learned	O
by	O
LINE	B-Method
(	I-Method
1st	I-Method
)	I-Method
and	O
LINE	B-Method
(	I-Method
2nd	I-Method
)	I-Method
,	O
the	O
performance	O
further	O
improves	O
,	O
confirming	O
that	O
the	O
two	O
proximities	O
are	O
complementary	O
to	O
each	O
other	O
.	O
	
Significantly	O
outperforms	O
DeepWalk	B-Method
at	O
the	O
:	O
	
*	O
*	O
0.01	O
and	O
*	O
0.05	O
level	O
,	O
paired	O
t	O
-	O
test	O
.	O
	
Significantly	O
outperforms	O
DeepWalk	B-Method
at	O
the	O
:	O
	
*	O
*	O
0.01	O
and	O
*	O
0.05	O
level	O
,	O
paired	O
t	O
-	O
test	O
.	O
	
Significantly	O
outperforms	O
DeepWalk	B-Method
at	O
the	O
:	O
	
*	O
*	O
0.01	O
and	O
*	O
0.05	O
level	O
,	O
paired	O
t	O
-	O
test	O
.	O
	
Youtube	B-Method
Network	I-Method
.	O
	
Table	O
[	O
reference	O
]	O
reports	O
the	O
results	O
on	O
Youtube	B-Method
network	I-Method
,	O
which	O
is	O
extremely	O
sparse	O
and	O
the	O
average	O
degree	O
is	O
as	O
low	O
as	O
5	O
.	O
	
In	O
most	O
cases	O
with	O
different	O
percentages	O
of	O
training	O
data	O
,	O
LINE	B-Method
(	I-Method
1st	I-Method
)	I-Method
outperforms	O
LINE	B-Method
(	I-Method
2nd	I-Method
)	I-Method
,	O
consistent	O
with	O
the	O
results	O
on	O
the	O
Flickr	B-Method
network	I-Method
.	O
	
Due	O
to	O
the	O
extreme	O
sparsity	O
,	O
the	O
performance	O
of	O
LINE	B-Method
(	I-Method
2nd	I-Method
)	I-Method
is	O
even	O
inferior	O
to	O
DeepWalk	B-Method
.	O
	
By	O
combining	O
the	O
representations	O
learned	O
by	O
the	O
LINE	B-Method
with	O
both	O
the	O
first	O
-	O
and	O
second	O
-	O
order	O
proximity	O
,	O
the	O
performance	O
of	O
LINE	B-Method
outperforms	O
DeepWalk	B-Method
with	O
either	O
128	O
or	O
256	O
dimension	O
,	O
showing	O
that	O
the	O
two	O
proximities	O
are	O
complementary	O
to	O
each	O
other	O
and	O
able	O
to	O
address	O
the	O
problem	O
of	O
network	B-Task
sparsity	I-Task
.	O
	
It	O
is	O
interesting	O
to	O
observe	O
how	O
DeepWalk	B-Method
tackles	O
the	O
network	O
sparsity	O
through	O
truncated	O
random	O
walks	O
,	O
which	O
enrich	O
the	O
neighbors	O
or	O
contexts	O
of	O
each	O
vertex	O
.	O
	
The	O
random	B-Method
walk	I-Method
approach	I-Method
acts	O
like	O
a	O
depth	B-Method
-	I-Method
first	I-Method
search	I-Method
.	O
	
Such	O
an	O
approach	O
may	O
quickly	O
alleviate	O
the	O
sparsity	O
of	O
the	O
neighborhood	O
of	O
nodes	O
by	O
bringing	O
in	O
indirect	O
neighbors	O
,	O
but	O
it	O
may	O
also	O
introduce	O
nodes	O
that	O
are	O
long	O
range	O
away	O
.	O
	
A	O
more	O
reasonable	O
way	O
is	O
to	O
expand	O
the	O
neighborhood	O
of	O
each	O
vertex	O
using	O
a	O
breadth	B-Method
-	I-Method
first	I-Method
search	I-Method
strategy	I-Method
,	O
i.e.	O
,	O
recursively	O
adding	O
neighbors	O
of	O
neighbors	O
.	O
	
To	O
verify	O
this	O
,	O
we	O
expand	O
the	O
neighborhood	O
of	O
the	O
vertices	O
whose	O
degree	O
are	O
less	O
than	O
1	O
,	O
000	O
by	O
adding	O
the	O
neighbors	O
of	O
neighbors	O
until	O
the	O
size	O
of	O
the	O
extended	O
neighborhood	O
reaches	O
1	O
,	O
000	O
nodes	O
.	O
	
We	O
find	O
that	O
adding	O
more	O
than	O
1	O
,	O
000	O
vertices	O
does	O
not	O
further	O
increase	O
the	O
performance	O
.	O
	
The	O
results	O
in	O
the	O
brackets	O
in	O
Table	O
[	O
reference	O
]	O
are	O
obtained	O
on	O
this	O
reconstructed	B-Method
network	I-Method
.	O
	
The	O
performance	O
of	O
GF	B-Method
,	O
LINE	B-Method
(	I-Method
1st	I-Method
)	I-Method
and	O
LINE	B-Method
(	I-Method
2nd	I-Method
)	I-Method
all	O
improves	O
,	O
especially	O
LINE	B-Method
(	I-Method
2nd	I-Method
)	I-Method
.	O
	
In	O
the	O
reconstructed	B-Method
network	I-Method
,	O
the	O
LINE	B-Method
(	I-Method
2nd	I-Method
)	I-Method
outperforms	O
DeepWalk	B-Method
in	O
most	O
cases	O
.	O
	
We	O
can	O
also	O
see	O
that	O
the	O
performance	O
of	O
LINE	B-Method
(	O
1st	B-Method
+	I-Method
2nd	I-Method
)	O
on	O
the	O
reconstructed	B-Method
network	I-Method
does	O
not	O
improve	O
too	O
much	O
compared	O
with	O
those	O
on	O
the	O
original	O
network	O
.	O
	
This	O
implies	O
that	O
the	O
combination	O
of	O
first	O
-	O
order	O
and	O
second	O
-	O
order	O
proximity	O
on	O
the	O
original	O
network	O
has	O
already	O
captured	O
most	O
information	O
and	O
LINE	B-Method
(	O
1st	B-Method
+	I-Method
2nd	I-Method
)	O
approach	O
is	O
a	O
quite	O
effective	O
and	O
efficient	O
way	O
for	O
network	B-Task
embedding	I-Task
,	O
suitable	O
for	O
both	O
dense	B-Task
and	I-Task
sparse	I-Task
networks	I-Task
.	O
	
subsubsection	O
:	O
Citation	B-Method
Network	I-Method
	
We	O
present	O
the	O
results	O
on	O
two	O
citation	B-Method
networks	I-Method
,	O
both	O
of	O
which	O
are	O
directed	B-Method
networks	I-Method
.	O
	
Both	O
the	O
GF	O
and	O
LINE	B-Method
methods	O
,	O
which	O
use	O
first	O
-	O
order	O
proximity	O
,	O
are	O
not	O
applicable	O
for	O
directed	B-Task
networks	I-Task
,	O
and	O
hence	O
we	O
only	O
compare	O
DeepWalk	B-Method
and	O
LINE	B-Method
(	I-Method
2nd	I-Method
)	I-Method
.	O
	
We	O
also	O
evaluate	O
the	O
vertex	O
embeddings	O
through	O
a	O
multi	B-Task
-	I-Task
label	I-Task
classification	I-Task
task	I-Task
.	O
	
We	O
choose	O
7	O
popular	O
conferences	O
including	O
AAAI	B-Method
,	O
CIKM	B-Method
,	O
ICML	B-Method
,	O
KDD	B-Method
,	O
NIPS	B-Method
,	O
SIGIR	B-Method
,	O
and	O
WWW	B-Method
as	O
the	O
classification	B-Task
categories	I-Task
.	O
	
Authors	O
publishing	O
in	O
the	O
conferences	O
or	O
papers	O
published	O
in	O
the	O
conferences	O
are	O
assumed	O
to	O
belong	O
to	O
the	O
categories	O
corresponding	O
to	O
the	O
conferences	O
.	O
	
DBLP	B-Method
(	I-Method
AuthorCitation	I-Method
)	I-Method
Network	I-Method
.	O
	
Table	O
[	O
reference	O
]	O
reports	O
the	O
results	O
on	O
the	O
DBLP	B-Method
(	I-Method
AuthorCitation	I-Method
)	I-Method
network	I-Method
.	O
	
As	O
this	O
network	O
is	O
also	O
very	O
sparse	O
,	O
DeepWalk	B-Method
outperforms	O
LINE	B-Method
(	O
2nd	O
)	O
.	O
	
However	O
,	O
by	O
reconstructing	O
the	O
network	O
through	O
recursively	O
adding	O
neighbors	O
of	O
neighbors	O
for	O
vertices	O
with	O
small	O
degrees	O
(	O
smaller	O
than	O
500	O
)	O
,	O
the	O
performance	O
of	O
LINE	B-Method
(	I-Method
2nd	I-Method
)	I-Method
significantly	O
increases	O
and	O
outperforms	O
DeepWalk	B-Method
.	O
	
The	O
LINE	B-Method
model	O
directly	O
optimized	O
by	O
stochastic	B-Method
gradient	I-Method
descent	I-Method
,	O
LINE	B-Method
(	I-Method
2nd	I-Method
)	I-Method
,	O
does	O
not	O
perform	O
well	O
as	O
expected	O
.	O
	
DBLP	B-Method
(	I-Method
PaperCitation	I-Method
)	I-Method
Network	I-Method
.	O
	
Table	O
[	O
reference	O
]	O
reports	O
the	O
results	O
on	O
the	O
DBLP	B-Method
(	I-Method
PaperCitation	I-Method
)	I-Method
network	I-Method
.	O
	
The	O
LINE	B-Method
(	I-Method
2nd	I-Method
)	I-Method
significantly	O
outperforms	O
DeepWalk	B-Method
.	O
	
This	O
is	O
because	O
the	O
random	O
walk	O
on	O
the	O
paper	B-Method
citation	I-Method
network	I-Method
can	O
only	O
reach	O
papers	O
along	O
the	O
citing	O
path	O
(	O
i.e.	O
,	O
older	O
papers	O
)	O
and	O
can	O
not	O
reach	O
other	O
references	O
.	O
	
Instead	O
,	O
the	O
LINE	B-Method
(	I-Method
2nd	I-Method
)	I-Method
represents	O
each	O
paper	O
with	O
its	O
references	O
,	O
which	O
is	O
obviously	O
more	O
reasonable	O
.	O
	
The	O
performance	O
of	O
LINE	B-Method
(	I-Method
2nd	I-Method
)	I-Method
is	O
further	O
improved	O
when	O
the	O
network	O
is	O
reconstructed	O
by	O
enriching	O
the	O
neighbors	O
of	O
vertices	O
with	O
small	O
degrees	O
(	O
smaller	O
than	O
200	O
)	O
.	O
	
subsection	O
:	O
Network	B-Method
Layouts	I-Method
	
An	O
important	O
application	O
of	O
network	B-Task
embedding	I-Task
is	O
to	O
create	O
meaningful	B-Task
visualizations	I-Task
that	O
layout	O
a	O
network	O
on	O
a	O
two	O
dimensional	O
space	O
.	O
	
We	O
visualize	O
a	O
co	B-Method
-	I-Method
author	I-Method
network	I-Method
extracted	O
from	O
the	O
DBLP	O
data	O
.	O
	
We	O
select	O
some	O
conferences	O
from	O
three	O
different	O
research	O
fields	O
:	O
WWW	B-Method
,	O
KDD	B-Method
from	O
“	O
data	B-Task
mining	I-Task
,	O
”	O
NIPS	B-Method
,	O
ICML	B-Method
from	O
“	O
machine	B-Task
learning	I-Task
,	O
”	O
and	O
CVPR	B-Method
,	O
ICCV	B-Method
from	O
“	O
computer	B-Task
vision	I-Task
.	O
	
”	O
	
The	O
co	B-Method
-	I-Method
author	I-Method
network	I-Method
is	O
built	O
from	O
the	O
papers	O
published	O
in	O
these	O
conferences	O
.	O
	
Authors	O
with	O
degree	O
less	O
than	O
3	O
are	O
filtered	O
out	O
,	O
and	O
finally	O
the	O
network	O
contains	O
18	O
,	O
561	O
authors	O
and	O
207	O
,	O
074	O
edges	O
.	O
	
Laying	O
out	O
this	O
co	B-Method
-	I-Method
author	I-Method
network	I-Method
is	O
very	O
challenging	O
as	O
the	O
three	O
research	O
fields	O
are	O
very	O
close	O
to	O
each	O
other	O
.	O
	
We	O
first	O
map	O
the	O
co	B-Method
-	I-Method
author	I-Method
network	I-Method
into	O
a	O
low	O
-	O
dimensional	O
space	O
with	O
different	O
embedding	B-Method
approaches	I-Method
and	O
then	O
further	O
map	O
the	O
low	O
-	O
dimensional	O
vectors	O
of	O
the	O
vertices	O
to	O
a	O
2	O
-	O
D	O
space	O
with	O
the	O
t	B-Method
-	I-Method
SNE	I-Method
package	I-Method
.	O
	
Fig	O
.	O
	
[	O
reference	O
]	O
compares	O
the	O
visualization	B-Task
results	O
with	O
different	O
embedding	B-Method
approaches	I-Method
.	O
	
The	O
visualization	B-Task
using	O
graph	B-Method
factorization	I-Method
is	O
not	O
very	O
meaningful	O
,	O
in	O
which	O
the	O
authors	O
belonging	O
to	O
the	O
same	O
communities	O
are	O
not	O
clustered	O
together	O
.	O
	
The	O
result	O
of	O
DeepWalk	B-Method
is	O
much	O
better	O
.	O
	
However	O
,	O
many	O
authors	O
belonging	O
to	O
different	O
communities	O
are	O
clustered	O
tightly	O
into	O
the	O
center	O
area	O
,	O
most	O
of	O
which	O
are	O
high	O
degree	O
vertices	O
.	O
	
This	O
is	O
because	O
DeepWalk	B-Method
uses	O
a	O
random	B-Method
walk	I-Method
based	I-Method
approach	I-Method
to	O
enrich	O
the	O
neighbors	O
of	O
the	O
vertices	O
,	O
which	O
brings	O
in	O
a	O
lot	O
of	O
noise	O
due	O
to	O
the	O
randomness	O
,	O
especially	O
for	O
vertices	O
with	O
higher	O
degrees	O
.	O
	
The	O
LINE	B-Method
(	O
2nd	O
)	O
performs	O
quite	O
well	O
and	O
generates	O
meaningful	O
layout	O
of	O
the	O
network	O
(	O
nodes	O
with	O
same	O
colors	O
are	O
distributed	O
closer	O
)	O
.	O
	
subsection	O
:	O
Performance	O
w.r.t	O
.	O
Network	O
Sparsity	O
	
In	O
this	O
subsection	O
,	O
we	O
formally	O
analyze	O
the	O
performance	O
of	O
the	O
above	O
models	O
w.r.t	O
.	O
	
the	O
sparsity	B-Task
of	I-Task
networks	I-Task
.	O
	
We	O
use	O
the	O
social	B-Method
networks	I-Method
as	O
examples	O
.	O
	
We	O
first	O
investigate	O
how	O
the	O
sparsity	O
of	O
the	O
networks	O
affects	O
the	O
LINE	B-Method
(	I-Method
1st	I-Method
)	I-Method
and	O
LINE	B-Method
(	I-Method
2nd	I-Method
)	I-Method
.	O
	
Fig	O
.	O
	
[	O
reference	O
]	O
shows	O
the	O
results	O
w.r.t	O
.	O
	
the	O
percentage	O
of	O
links	O
on	O
the	O
Flickr	B-Method
network	I-Method
.	O
	
We	O
choose	O
Flickr	B-Method
network	I-Method
as	O
it	O
is	O
much	O
denser	O
than	O
the	O
Youtube	B-Method
network	I-Method
.	O
	
We	O
randomly	O
select	O
different	O
percentages	O
of	O
links	O
from	O
the	O
original	O
network	O
to	O
construct	O
networks	O
with	O
different	O
levels	O
of	O
sparsity	O
.	O
	
We	O
can	O
see	O
that	O
in	O
the	O
beginning	O
,	O
when	O
the	O
network	O
is	O
very	O
sparse	O
,	O
the	O
LINE	B-Method
(	I-Method
1st	I-Method
)	I-Method
outperforms	O
LINE	B-Method
(	I-Method
2nd	I-Method
)	I-Method
.	O
	
As	O
we	O
gradually	O
increase	O
the	O
percentage	O
of	O
links	O
,	O
the	O
LINE	B-Method
(	I-Method
2nd	I-Method
)	I-Method
begins	O
to	O
outperform	O
the	O
LINE	B-Method
(	I-Method
1st	I-Method
)	I-Method
.	O
	
This	O
shows	O
that	O
the	O
second	B-Method
-	I-Method
order	I-Method
proximity	I-Method
suffers	O
when	O
the	O
network	O
is	O
extremely	O
sparse	O
,	O
and	O
it	O
outperforms	O
first	B-Method
-	I-Method
order	I-Method
proximity	I-Method
when	O
there	O
are	O
sufficient	O
nodes	O
in	O
the	O
neighborhood	O
of	O
a	O
node	O
.	O
	
Fig	O
.	O
	
[	O
reference	O
]	O
shows	O
the	O
performance	O
w.r.t	O
.	O
	
the	O
degrees	O
of	O
the	O
vertices	O
on	O
both	O
the	O
original	O
and	O
reconstructed	B-Method
Youtube	I-Method
networks	I-Method
.	O
	
We	O
categorize	O
the	O
vertices	O
into	O
different	O
groups	O
according	O
to	O
their	O
degrees	O
including	O
,	O
and	O
then	O
evaluate	O
the	O
performance	O
of	O
vertices	O
in	O
different	O
groups	O
.	O
	
Overall	O
,	O
the	O
performance	O
of	O
different	O
models	O
increases	O
when	O
the	O
degrees	O
of	O
the	O
vertices	O
increase	O
.	O
	
In	O
the	O
original	O
network	O
,	O
the	O
LINE	B-Method
(	I-Method
2nd	I-Method
)	I-Method
outperforms	O
LINE	B-Method
(	I-Method
1st	I-Method
)	I-Method
except	O
for	O
the	O
first	O
group	O
,	O
which	O
confirms	O
that	O
the	O
second	O
-	O
order	O
proximity	O
does	O
not	O
work	O
well	O
for	O
nodes	O
with	O
a	O
low	O
degree	O
.	O
	
In	O
the	O
reconstructed	B-Task
dense	I-Task
network	I-Task
,	O
the	O
performance	O
of	O
the	O
LINE	B-Method
(	I-Method
1st	I-Method
)	I-Method
or	O
LINE	B-Method
(	I-Method
2nd	I-Method
)	I-Method
improves	O
,	O
especially	O
the	O
LINE	B-Method
(	I-Method
2nd	I-Method
)	I-Method
that	O
preserves	O
the	O
second	O
-	O
order	O
proximity	O
.	O
	
We	O
can	O
also	O
see	O
that	O
the	O
LINE	B-Method
(	O
2nd	O
)	O
model	O
on	O
the	O
reconstructed	B-Method
network	I-Method
outperforms	O
DeepWalk	B-Method
in	O
all	O
the	O
groups	O
.	O
	
subsection	O
:	O
Parameter	B-Metric
Sensitivity	I-Metric
	
Next	O
,	O
we	O
investigate	O
the	O
performance	O
w.r.t	O
.	O
	
the	O
parameter	O
dimension	O
and	O
the	O
converging	O
performance	O
of	O
different	O
models	O
	
w.r.t	O
the	O
number	O
of	O
samples	O
on	O
the	O
reconstructed	B-Method
Youtube	I-Method
network	I-Method
.	O
	
Fig	O
.	O
	
[	O
reference	O
]	O
reports	O
the	O
performance	O
of	O
the	O
LINE	B-Method
model	O
w.r.t	O
.	O
	
the	O
dimension	O
.	O
	
We	O
can	O
see	O
that	O
the	O
performance	O
of	O
the	O
LINE	B-Method
(	I-Method
1st	I-Method
)	I-Method
or	O
LINE	B-Method
(	I-Method
2nd	I-Method
)	I-Method
drops	O
when	O
the	O
dimension	O
becomes	O
too	O
large	O
.	O
	
Fig	O
.	O
	
[	O
reference	O
]	O
shows	O
the	O
results	O
of	O
the	O
LINE	B-Method
and	O
DeepWalk	B-Method
w.r.t	O
.	O
	
the	O
number	O
of	O
samples	O
during	O
the	O
optimization	B-Task
.	O
	
The	O
LINE	B-Method
(	I-Method
2nd	I-Method
)	I-Method
consistently	O
outperforms	O
LINE	B-Method
(	I-Method
1st	I-Method
)	I-Method
and	O
DeepWalk	B-Method
,	O
and	O
both	O
the	O
LINE	B-Method
(	I-Method
1st	I-Method
)	I-Method
and	O
	
LINE	B-Method
(	O
2nd	O
)	O
converge	O
much	O
faster	O
than	O
DeepWalk	B-Method
.	O
	
subsection	O
:	O
Scalability	O
	
Finally	O
,	O
we	O
investigate	O
the	O
scalability	O
of	O
the	O
LINE	B-Method
model	O
optimized	O
by	O
the	O
edge	B-Method
-	I-Method
sampling	I-Method
treatment	I-Method
and	O
asynchronous	B-Method
stochastic	I-Method
gradient	I-Method
descent	I-Method
,	O
which	O
deploys	O
multiple	O
threads	O
for	O
optimization	B-Task
.	O
	
Fig	O
.	O
	
[	O
reference	O
]	O
shows	O
the	O
speed	O
up	O
w.r.t	O
.	O
	
the	O
number	O
of	O
threads	O
on	O
the	O
Youtube	B-Method
data	I-Method
set	I-Method
.	O
	
The	O
speed	O
up	O
is	O
quite	O
close	O
to	O
linear	O
.	O
	
Fig	O
.	O
	
[	O
reference	O
]	O
shows	O
that	O
the	O
classification	B-Task
performance	O
remains	O
stable	O
when	O
using	O
multiple	O
threads	O
for	O
model	B-Task
updating	I-Task
.	O
	
The	O
two	O
figures	O
together	O
show	O
that	O
the	O
inference	B-Method
algorithm	I-Method
of	O
the	O
LINE	B-Method
model	O
is	O
quite	O
scalable	O
.	O
	
section	O
:	O
Conclusion	O
	
This	O
paper	O
presented	O
a	O
novel	O
network	B-Method
embedding	I-Method
model	I-Method
called	O
the	O
“	O
LINE	B-Method
,	O
”	O
which	O
can	O
easily	O
scale	O
up	O
to	O
networks	O
with	O
millions	O
of	O
vertices	O
and	O
billions	O
of	O
edges	O
.	O
	
It	O
has	O
carefully	O
designed	O
objective	O
functions	O
that	O
preserve	O
both	O
the	O
first	O
-	O
order	O
and	O
second	O
-	O
order	O
proximities	O
,	O
which	O
are	O
complementary	O
to	O
each	O
other	O
.	O
	
An	O
efficient	O
and	O
effective	O
edge	B-Method
-	I-Method
sampling	I-Method
method	I-Method
is	O
proposed	O
for	O
model	B-Task
inference	I-Task
,	O
which	O
solved	O
the	O
limitation	O
of	O
stochastic	B-Method
gradient	I-Method
descent	I-Method
on	O
weighted	O
edges	O
without	O
compromising	O
the	O
efficiency	O
.	O
	
Experimental	O
results	O
on	O
various	O
real	B-Task
-	I-Task
world	I-Task
networks	I-Task
prove	O
the	O
efficiency	O
and	O
effectiveness	O
of	O
LINE	B-Method
.	O
	
In	O
the	O
future	O
,	O
we	O
plan	O
to	O
investigate	O
higher	O
-	O
order	O
proximity	O
beyond	O
the	O
first	O
-	O
order	O
and	O
second	O
-	O
order	O
proximities	O
in	O
the	O
network	O
.	O
	
Besides	O
,	O
we	O
also	O
plan	O
to	O
investigate	O
the	O
embedding	B-Task
of	I-Task
heterogeneous	I-Task
information	I-Task
networks	I-Task
,	O
e.g.	O
,	O
vertices	O
with	O
multiple	O
types	O
.	O
	
section	O
:	O
Acknowledgments	O
	
The	O
authors	O
thank	O
the	O
three	O
anonymous	O
reviewers	O
for	O
the	O
helpful	O
comments	O
.	O
	
The	O
co	O
-	O
author	O
Ming	O
Zhang	O
is	O
supported	O
by	O
the	O
National	O
Natural	O
Science	O
Foundation	O
of	O
China	O
(	O
NSFC	O
Grant	O
No	O
.	O
61472006	O
)	O
;	O
Qiaozhu	O
Mei	O
is	O
supported	O
by	O
the	O
National	O
Science	O
Foundation	O
under	O
grant	O
numbers	O
IIS	O
-	O
1054199	O
and	O
CCF	O
-	O
1048168	O
.	O
	
bibliography	O
:	O
References	O
	
document	O
:	O
Compositional	B-Method
Sequence	I-Method
Labeling	I-Method
Models	I-Method
for	O
Error	B-Task
Detection	I-Task
in	O
Learner	B-Task
Writing	I-Task
	
In	O
this	O
paper	O
,	O
we	O
present	O
the	O
first	O
experiments	O
using	O
neural	B-Method
network	I-Method
models	I-Method
for	O
the	O
task	O
of	O
error	B-Task
detection	I-Task
in	O
learner	B-Task
writing	I-Task
.	O
	
We	O
perform	O
a	O
systematic	O
comparison	O
of	O
alternative	O
compositional	B-Method
architectures	I-Method
and	O
propose	O
a	O
framework	O
for	O
error	B-Task
detection	I-Task
based	O
on	O
bidirectional	O
LSTMs	B-Method
.	O
	
Experiments	O
on	O
the	O
CoNLL	B-Material
-	I-Material
14	I-Material
shared	I-Material
task	I-Material
dataset	I-Material
show	O
the	O
model	O
is	O
able	O
to	O
outperform	O
other	O
participants	O
on	O
detecting	B-Task
errors	I-Task
in	I-Task
learner	I-Task
writing	I-Task
.	O
	
Finally	O
,	O
the	O
model	O
is	O
integrated	O
with	O
a	O
publicly	O
deployed	O
self	B-Method
-	I-Method
assessment	I-Method
system	O
,	O
leading	O
to	O
performance	O
comparable	O
to	O
human	O
annotators	O
.	O
	
section	O
:	O
Introduction	O
	
Automated	B-Method
systems	I-Method
for	O
detecting	B-Task
errors	I-Task
in	O
learner	B-Task
writing	I-Task
are	O
valuable	O
tools	O
for	O
second	B-Task
language	I-Task
learning	I-Task
and	O
assessment	B-Task
.	O
	
Most	O
work	O
in	O
recent	O
years	O
has	O
focussed	O
on	O
error	B-Task
correction	I-Task
,	O
with	O
error	B-Task
detection	I-Task
performance	O
measured	O
as	O
a	O
byproduct	O
of	O
the	O
correction	B-Metric
output	I-Metric
.	O
	
However	O
,	O
this	O
assumes	O
that	O
systems	O
are	O
able	O
to	O
propose	O
a	O
correction	O
for	O
every	O
detected	O
error	O
,	O
and	O
accurate	O
systems	O
for	O
correction	B-Task
might	O
not	O
be	O
optimal	O
for	O
detection	B-Task
.	O
	
While	O
closed	O
-	O
class	O
errors	O
such	O
as	O
incorrect	O
prepositions	O
and	O
determiners	O
can	O
be	O
modeled	O
with	O
a	O
supervised	B-Method
classification	I-Method
approach	I-Method
,	O
content	B-Metric
-	I-Metric
content	I-Metric
word	I-Metric
errors	I-Metric
are	O
the	O
3rd	O
most	O
frequent	O
error	O
type	O
and	O
pose	O
a	O
serious	O
challenge	O
to	O
error	B-Method
correction	I-Method
frameworks	I-Method
.	O
	
Evaluation	B-Task
of	I-Task
error	I-Task
correction	I-Task
is	O
also	O
highly	O
subjective	O
and	O
human	O
annotators	O
have	O
rather	O
low	O
agreement	O
on	O
gold	O
-	O
standard	O
corrections	O
.	O
	
Therefore	O
,	O
we	O
treat	O
error	B-Task
detection	I-Task
in	O
learner	B-Task
writing	I-Task
as	O
an	O
independent	B-Task
task	I-Task
and	O
propose	O
a	O
system	O
for	O
labeling	O
each	O
token	O
as	O
being	O
correct	O
or	O
incorrect	O
in	O
context	O
.	O
	
Common	O
approaches	O
to	O
similar	O
sequence	B-Task
labeling	I-Task
tasks	I-Task
involve	O
learning	O
weights	O
or	O
probabilities	O
for	O
context	O
n	O
-	O
grams	O
of	O
varying	O
sizes	O
,	O
or	O
relying	O
on	O
previously	O
extracted	O
high	O
-	O
confidence	O
context	O
patterns	O
.	O
	
Both	O
of	O
these	O
methods	O
can	O
suffer	O
from	O
data	O
sparsity	O
,	O
as	O
they	O
treat	O
words	O
as	O
independent	O
units	O
and	O
miss	O
out	O
on	O
potentially	O
related	O
patterns	O
.	O
	
In	O
addition	O
,	O
they	O
need	O
to	O
specify	O
a	O
fixed	O
context	O
size	O
and	O
are	O
therefore	O
often	O
limited	O
to	O
using	O
a	O
small	O
window	O
near	O
the	O
target	O
.	O
	
Neural	B-Method
network	I-Method
models	I-Method
aim	O
to	O
address	O
these	O
weaknesses	O
and	O
have	O
achieved	O
success	O
in	O
various	O
NLP	B-Task
tasks	I-Task
such	O
as	O
language	B-Task
modeling	I-Task
and	O
speech	B-Task
recognition	I-Task
.	O
	
Recent	O
developments	O
in	O
machine	B-Task
translation	I-Task
have	O
also	O
shown	O
that	O
text	O
of	O
varying	O
length	O
can	O
be	O
represented	O
as	O
a	O
fixed	B-Method
-	I-Method
size	I-Method
vector	I-Method
using	O
convolutional	B-Method
networks	I-Method
or	O
recurrent	B-Method
neural	I-Method
networks	I-Method
.	O
	
In	O
this	O
paper	O
,	O
we	O
present	O
the	O
first	O
experiments	O
using	O
neural	B-Method
network	I-Method
models	I-Method
for	O
the	O
task	O
of	O
error	B-Task
detection	I-Task
in	O
learner	B-Task
writing	I-Task
.	O
	
We	O
perform	O
a	O
systematic	O
comparison	O
of	O
alternative	O
compositional	B-Method
structures	I-Method
for	O
constructing	O
informative	B-Task
context	I-Task
representations	I-Task
.	O
	
Based	O
on	O
the	O
findings	O
,	O
we	O
propose	O
a	O
novel	O
framework	O
for	O
performing	O
error	B-Task
detection	I-Task
in	O
learner	B-Task
writing	I-Task
,	O
which	O
achieves	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
results	O
on	O
two	O
datasets	O
of	O
error	O
-	O
annotated	O
learner	O
essays	O
.	O
	
The	O
sequence	B-Method
labeling	I-Method
model	I-Method
creates	O
a	O
single	O
variable	B-Method
-	I-Method
size	I-Method
network	I-Method
over	O
the	O
whole	O
sentence	O
,	O
conditions	O
each	O
label	O
on	O
all	O
the	O
words	O
,	O
and	O
predicts	O
all	O
labels	O
together	O
.	O
	
The	O
effects	O
of	O
different	O
datasets	O
on	O
the	O
overall	O
performance	O
are	O
investigated	O
by	O
incrementally	O
providing	O
additional	O
training	O
data	O
to	O
the	O
model	O
.	O
	
Finally	O
,	O
we	O
integrate	O
the	O
error	B-Method
detection	I-Method
framework	I-Method
with	O
a	O
publicly	O
deployed	O
self	B-Method
-	I-Method
assessment	I-Method
system	O
,	O
leading	O
to	O
performance	O
comparable	O
to	O
human	O
annotators	O
.	O
	
section	O
:	O
Background	O
and	O
Related	O
Work	O
	
The	O
field	O
of	O
automatically	B-Task
detecting	I-Task
errors	I-Task
in	O
learner	B-Task
text	I-Task
has	O
a	O
long	O
and	O
rich	O
history	O
.	O
	
Most	O
work	O
has	O
focussed	O
on	O
tackling	O
specific	O
types	O
of	O
errors	O
,	O
such	O
as	O
usage	O
of	O
incorrect	O
prepositions	O
,	O
articles	O
,	O
verb	O
forms	O
,	O
and	O
adjective	O
-	O
noun	O
pairs	O
.	O
	
However	O
,	O
there	O
has	O
been	O
limited	O
work	O
on	O
more	O
general	O
error	B-Method
detection	I-Method
systems	I-Method
that	O
could	O
handle	O
all	O
types	O
of	O
errors	O
in	O
learner	O
text	O
.	O
	
Chodorow1998	O
proposed	O
a	O
method	O
based	O
on	O
mutual	O
information	O
and	O
the	O
chi	B-Method
-	I-Method
square	I-Method
statistic	I-Method
to	O
detect	O
sequences	O
of	O
part	O
-	O
of	O
-	O
speech	O
tags	O
and	O
function	O
words	O
that	O
are	O
likely	O
to	O
be	O
ungrammatical	O
in	O
English	O
.	O
	
Gamon2011	O
used	O
Maximum	B-Method
Entropy	I-Method
Markov	I-Method
Models	I-Method
with	O
a	O
range	O
of	O
features	O
,	O
such	O
as	O
POS	O
tags	O
,	O
string	O
features	O
,	O
and	O
outputs	O
from	O
a	O
constituency	B-Method
parser	I-Method
.	O
	
The	O
pilot	O
Helping	O
	
Our	O
Own	O
shared	O
task	O
also	O
evaluated	O
grammatical	B-Task
error	I-Task
detection	I-Task
of	O
a	O
number	O
of	O
different	O
error	O
types	O
,	O
though	O
most	O
systems	O
were	O
error	O
-	O
type	O
specific	O
and	O
the	O
best	O
approach	O
was	O
heavily	O
skewed	O
towards	O
article	O
and	O
preposition	O
errors	O
.	O
	
We	O
extend	O
this	O
line	O
of	O
research	O
,	O
working	O
towards	O
general	O
error	B-Task
detection	I-Task
systems	I-Task
,	O
and	O
investigate	O
the	O
use	O
of	O
neural	B-Method
compositional	I-Method
models	I-Method
on	O
this	O
task	O
.	O
	
The	O
related	O
area	O
of	O
grammatical	B-Task
error	I-Task
correction	I-Task
has	O
also	O
gained	O
considerable	O
momentum	O
in	O
the	O
past	O
years	O
,	O
with	O
four	O
recent	O
shared	O
tasks	O
highlighting	O
several	O
emerging	O
directions	O
.	O
	
The	O
current	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
approaches	O
can	O
broadly	O
be	O
separated	O
into	O
two	O
categories	O
:	O
Phrase	B-Method
-	I-Method
based	I-Method
statistical	I-Method
machine	I-Method
translation	I-Method
techniques	I-Method
,	O
essentially	O
translating	O
the	O
incorrect	O
source	O
text	O
into	O
the	O
corrected	O
version	O
Averaged	O
Perceptrons	B-Method
and	O
Naive	B-Method
Bayes	I-Method
classifiers	I-Method
making	O
use	O
of	O
native	O
-	O
language	O
error	O
correction	O
priors	O
.	O
	
Error	B-Method
correction	I-Method
systems	I-Method
require	O
very	O
specialised	O
models	O
,	O
as	O
they	O
need	O
to	O
generate	O
an	O
improved	O
version	O
of	O
the	O
input	O
text	O
,	O
whereas	O
a	O
wider	O
range	O
of	O
tagging	B-Method
and	I-Method
classification	I-Method
models	I-Method
can	O
be	O
deployed	O
on	O
error	B-Task
detection	I-Task
.	O
	
In	O
addition	O
,	O
automated	B-Task
writing	I-Task
feedback	I-Task
systems	I-Task
that	O
indicate	O
the	O
presence	O
and	O
location	O
of	O
errors	O
may	O
be	O
better	O
from	O
a	O
pedagogic	O
point	O
of	O
view	O
,	O
rather	O
than	O
providing	O
a	O
panacea	O
and	O
correcting	O
all	O
errors	O
in	O
learner	O
text	O
.	O
	
In	O
Section	O
[	O
reference	O
]	O
we	O
evaluate	O
a	O
neural	B-Method
sequence	I-Method
tagging	I-Method
model	I-Method
on	O
the	O
latest	O
shared	O
task	O
test	O
data	O
,	O
and	O
compare	O
it	O
to	O
the	O
top	O
participating	O
systems	O
on	O
the	O
task	O
of	O
error	B-Task
detection	I-Task
.	O
	
section	O
:	O
Sequence	B-Method
Labeling	I-Method
Architectures	I-Method
	
We	O
construct	O
a	O
neural	B-Method
network	I-Method
sequence	I-Method
labeling	I-Method
framework	I-Method
for	O
the	O
task	O
of	O
error	B-Task
detection	I-Task
in	O
learner	B-Task
writing	I-Task
.	O
	
The	O
model	O
receives	O
only	O
a	O
series	O
of	O
tokens	O
as	O
input	O
,	O
and	O
outputs	O
the	O
probability	O
of	O
each	O
token	O
in	O
the	O
sentence	O
being	O
correct	O
or	O
incorrect	O
in	O
a	O
given	O
context	O
.	O
	
The	O
architectures	O
start	O
with	O
the	O
vector	B-Method
representations	I-Method
of	O
individual	O
words	O
,	O
,	O
where	O
is	O
the	O
length	O
of	O
the	O
sentence	O
.	O
	
Different	O
composition	B-Method
functions	I-Method
are	O
then	O
used	O
to	O
calculate	O
a	O
hidden	B-Method
vector	I-Method
representation	I-Method
of	O
each	O
token	O
in	O
context	O
,	O
.	O
	
These	O
representations	O
are	O
passed	O
through	O
a	O
softmax	B-Method
layer	I-Method
,	O
producing	O
a	O
probability	O
distribution	O
over	O
the	O
possible	O
labels	O
for	O
every	O
token	O
in	O
context	O
:	O
where	O
is	O
the	O
weight	O
matrix	O
between	O
the	O
hidden	O
vector	O
and	O
the	O
output	B-Method
layer	I-Method
.	O
	
We	O
investigate	O
six	O
alternative	O
neural	B-Method
network	I-Method
architectures	I-Method
for	O
the	O
task	O
of	O
error	B-Task
detection	I-Task
:	O
convolutional	B-Method
,	O
bidirectional	B-Method
recurrent	I-Method
,	O
bidirectional	O
LSTM	B-Method
,	O
and	O
multi	B-Method
-	I-Method
layer	I-Method
variants	I-Method
of	O
each	O
of	O
them	O
.	O
	
In	O
the	O
convolutional	B-Method
neural	I-Method
network	I-Method
(	O
CNN	B-Method
,	O
Figure	O
[	O
reference	O
]	O
a	O
)	O
for	O
token	B-Task
labeling	I-Task
,	O
the	O
hidden	O
vector	O
is	O
calculated	O
based	O
on	O
a	O
fixed	O
-	O
size	O
context	O
window	O
.	O
	
The	O
convolution	B-Method
acts	O
as	O
a	O
feedforward	B-Method
network	I-Method
,	O
using	O
surrounding	O
context	O
words	O
as	O
input	O
,	O
and	O
therefore	O
it	O
will	O
learn	O
to	O
detect	O
the	O
presence	O
of	O
different	O
types	O
of	O
n	O
-	O
grams	O
.	O
	
The	O
assumption	O
behind	O
the	O
convolutional	B-Method
architecture	I-Method
is	O
that	O
memorising	O
erroneous	O
token	O
sequences	O
from	O
the	O
training	O
data	O
is	O
sufficient	O
for	O
performing	O
error	B-Task
detection	I-Task
.	O
	
The	O
convolution	B-Method
uses	O
tokens	O
on	O
either	O
side	O
of	O
the	O
target	O
token	O
,	O
and	O
the	O
vectors	O
for	O
these	O
tokens	O
are	O
concatenated	O
,	O
preserving	O
the	O
ordering	O
:	O
where	O
is	O
used	O
as	O
notation	O
for	O
vector	O
concatenation	O
of	O
	
and	O
.	O
	
The	O
combined	O
vector	O
is	O
then	O
passed	O
through	O
a	O
non	B-Method
-	I-Method
linear	I-Method
layer	I-Method
to	O
produce	O
the	O
hidden	B-Method
representation	I-Method
:	O
The	O
deep	B-Method
convolutional	I-Method
network	I-Method
(	O
Figure	O
[	O
reference	O
]	O
b	O
)	O
adds	O
an	O
extra	O
convolutional	B-Method
layer	I-Method
to	O
the	O
architecture	O
,	O
using	O
the	O
first	O
layer	O
as	O
input	O
.	O
	
It	O
creates	O
convolutions	B-Method
of	I-Method
convolutions	I-Method
,	O
thereby	O
capturing	O
more	O
complex	O
higher	O
-	O
order	O
features	O
from	O
the	O
dataset	O
.	O
	
In	O
a	O
recurrent	B-Method
neural	I-Method
network	I-Method
(	O
RNN	B-Method
)	I-Method
,	O
each	O
hidden	B-Method
representation	I-Method
is	O
calculated	O
based	O
on	O
the	O
current	O
token	O
embedding	O
and	O
the	O
hidden	O
vector	O
at	O
the	O
previous	O
time	O
step	O
:	O
where	O
is	O
a	O
nonlinear	O
function	O
,	O
such	O
as	O
the	O
sigmoid	B-Method
function	I-Method
.	O
	
Instead	O
of	O
a	O
fixed	O
context	O
window	O
,	O
information	O
is	O
passed	O
through	O
the	O
sentence	O
using	O
a	O
recursive	B-Method
function	I-Method
and	O
the	O
network	O
is	O
able	O
to	O
learn	O
which	O
patterns	O
to	O
disregard	O
or	O
pass	O
forward	O
.	O
	
This	O
recurrent	B-Method
network	I-Method
structure	I-Method
is	O
referred	O
to	O
as	O
an	O
Elman	B-Method
-	I-Method
type	I-Method
network	I-Method
,	O
after	O
Elman1990	O
.	O
	
The	O
bidirectional	B-Method
RNN	I-Method
(	O
Figure	O
[	O
reference	O
]	O
c	O
)	O
consists	O
of	O
two	O
recurrent	B-Method
components	I-Method
,	O
moving	O
in	O
opposite	O
directions	O
through	O
the	O
sentence	O
.	O
	
While	O
the	O
unidirectional	B-Method
version	I-Method
takes	O
into	O
account	O
only	O
context	O
on	O
the	O
left	O
of	O
the	O
target	O
token	O
,	O
the	O
bidirectional	B-Method
version	I-Method
recursively	O
builds	O
separate	O
context	B-Method
representations	I-Method
from	O
either	O
side	O
of	O
the	O
target	O
token	O
.	O
	
The	O
left	O
and	O
right	O
context	O
are	O
then	O
concatenated	O
and	O
used	O
as	O
the	O
hidden	B-Method
representation	I-Method
:	O
Recurrent	B-Method
networks	I-Method
have	O
been	O
shown	O
to	O
perform	O
well	O
on	O
the	O
task	O
of	O
language	B-Task
modeling	I-Task
,	O
where	O
they	O
learn	O
an	O
incremental	B-Method
composition	I-Method
function	I-Method
for	O
predicting	O
the	O
next	O
token	O
in	O
the	O
sequence	O
.	O
	
However	O
,	O
while	O
language	B-Method
models	I-Method
can	O
estimate	O
the	O
probability	O
of	O
each	O
token	O
,	O
they	O
are	O
unable	O
to	O
differentiate	O
between	O
infrequent	O
and	O
incorrect	O
token	O
sequences	O
.	O
	
For	O
error	B-Task
detection	I-Task
,	O
the	O
composition	B-Method
function	I-Method
needs	O
to	O
learn	O
to	O
identify	O
semantic	O
anomalies	O
or	O
ungrammatical	O
combinations	O
,	O
independent	O
of	O
their	O
frequency	O
.	O
	
The	O
bidirectional	B-Method
model	I-Method
provides	O
extra	O
information	O
,	O
as	O
it	O
allows	O
the	O
network	O
to	O
use	O
context	O
on	O
both	O
sides	O
of	O
the	O
target	O
token	O
.	O
	
Irsoy2014a	O
created	O
an	O
extension	O
of	O
this	O
architecture	O
by	O
connecting	O
together	O
multiple	O
layers	O
of	O
bidirectional	B-Method
Elman	I-Method
-	I-Method
type	I-Method
recurrent	I-Method
network	I-Method
modules	I-Method
.	O
	
This	O
deep	B-Method
bidirectional	I-Method
RNN	I-Method
(	O
Figure	O
[	O
reference	O
]	O
d	O
)	O
calculates	O
a	O
context	B-Method
-	I-Method
dependent	I-Method
representation	I-Method
for	O
each	O
token	O
using	O
a	O
bidirectional	B-Method
RNN	I-Method
,	O
and	O
then	O
uses	O
this	O
as	O
input	O
to	O
another	O
bidirectional	B-Method
RNN	I-Method
.	O
	
The	O
multi	O
-	O
layer	O
structure	O
allows	O
the	O
model	O
to	O
learn	O
more	O
complex	O
higher	O
-	O
level	O
features	O
and	O
effectively	O
perform	O
multiple	O
recurrent	O
passes	O
through	O
the	O
sentence	O
.	O
	
The	O
long	B-Method
-	I-Method
short	I-Method
term	I-Method
memory	I-Method
(	O
LSTM	B-Method
)	O
is	O
an	O
advanced	O
alternative	O
to	O
the	O
Elman	B-Method
-	I-Method
type	I-Method
networks	I-Method
that	O
has	O
recently	O
become	O
increasingly	O
popular	O
.	O
	
It	O
uses	O
two	O
separate	O
hidden	O
vectors	O
to	O
pass	O
information	O
between	O
different	O
time	O
steps	O
,	O
and	O
includes	O
gating	B-Method
mechanisms	I-Method
for	O
modulating	O
its	O
own	O
output	O
.	O
	
LSTMs	B-Method
have	O
been	O
successfully	O
applied	O
to	O
various	O
tasks	O
,	O
such	O
as	O
speech	B-Task
recognition	I-Task
,	O
machine	B-Task
translation	I-Task
,	O
and	O
natural	B-Task
language	I-Task
generation	I-Task
.	O
	
Two	O
sets	O
of	O
gating	O
values	O
(	O
referred	O
to	O
as	O
the	O
input	O
and	O
forget	O
gates	O
)	O
are	O
first	O
calculated	O
based	O
on	O
the	O
previous	O
states	O
of	O
the	O
network	O
:	O
where	O
is	O
the	O
current	O
input	O
,	O
is	O
the	O
previous	O
hidden	O
state	O
,	O
and	O
are	O
biases	O
,	O
is	O
the	O
previous	O
internal	O
state	O
(	O
referred	O
to	O
as	O
the	O
cell	O
)	O
,	O
and	O
is	O
the	O
logistic	B-Method
function	I-Method
.	O
	
The	O
new	O
internal	O
state	O
is	O
calculated	O
based	O
on	O
the	O
current	O
input	O
and	O
the	O
previous	O
hidden	O
state	O
,	O
and	O
then	O
interpolated	O
with	O
the	O
previous	O
internal	O
state	O
using	O
and	O
as	O
weights	O
:	O
where	O
is	O
element	O
-	O
wise	O
multiplication	O
.	O
	
Finally	O
,	O
the	O
hidden	O
state	O
is	O
calculated	O
by	O
passing	O
the	O
internal	O
state	O
through	O
a	O
nonlinearity	O
,	O
and	O
weighting	O
it	O
with	O
.	O
	
The	O
values	O
of	O
are	O
conditioned	O
on	O
the	O
new	O
internal	O
state	O
(	O
)	O
,	O
as	O
opposed	O
to	O
the	O
previous	O
one	O
(	O
)	O
:	O
	
Because	O
of	O
the	O
linear	B-Method
combination	I-Method
in	O
equation	O
(	O
[	O
reference	O
]	O
)	O
,	O
the	O
LSTM	B-Method
is	O
less	O
susceptible	O
to	O
vanishing	O
gradients	O
over	O
time	O
,	O
thereby	O
being	O
able	O
to	O
make	O
use	O
of	O
longer	O
context	O
when	O
making	O
predictions	B-Task
.	O
	
In	O
addition	O
,	O
the	O
network	O
learns	O
to	O
modulate	O
itself	O
,	O
effectively	O
using	O
the	O
gates	O
to	O
predict	O
which	O
operation	O
is	O
required	O
at	O
each	O
time	O
step	O
,	O
thereby	O
incorporating	O
higher	O
-	O
level	O
features	O
.	O
	
In	O
order	O
to	O
use	O
this	O
architecture	O
for	O
error	B-Task
detection	I-Task
,	O
we	O
create	O
a	O
bidirectional	O
LSTM	B-Method
,	O
making	O
use	O
of	O
the	O
advanced	O
features	O
of	O
LSTM	B-Method
and	O
incorporating	O
context	O
on	O
both	O
sides	O
of	O
the	O
target	O
token	O
.	O
	
In	O
addition	O
,	O
we	O
experiment	O
with	O
a	O
deep	B-Method
bidirectional	I-Method
LSTM	I-Method
,	O
which	O
includes	O
two	O
consecutive	O
layers	O
of	O
bidirectional	O
LSTMs	B-Method
,	O
modeling	O
even	O
more	O
complex	O
features	O
and	O
performing	O
multiple	O
passes	O
through	O
the	O
sentence	O
.	O
	
For	O
comparison	O
with	O
non	B-Method
-	I-Method
neural	I-Method
models	I-Method
,	O
we	O
also	O
report	O
results	O
using	O
CRFs	B-Method
,	O
which	O
are	O
a	O
popular	O
choice	O
for	O
sequence	B-Task
labeling	I-Task
tasks	I-Task
.	O
	
We	O
trained	O
the	O
CRF	B-Method
++	I-Method
implementation	I-Method
on	O
the	O
same	O
dataset	O
,	O
using	O
as	O
features	O
unigrams	O
,	O
bigrams	O
and	O
trigrams	O
in	O
a	O
7	O
-	O
word	O
window	O
surrouding	O
the	O
target	O
word	O
(	O
3	O
words	O
before	O
and	O
after	O
)	O
.	O
	
The	O
predicted	O
label	O
is	O
also	O
conditioned	O
on	O
the	O
previous	O
label	O
in	O
the	O
sequence	O
.	O
	
section	O
:	O
Experiments	O
	
We	O
evaluate	O
the	O
alternative	O
network	B-Method
structures	I-Method
on	O
the	O
publicly	O
released	O
First	B-Material
Certificate	I-Material
in	I-Material
English	I-Material
dataset	I-Material
(	O
FCE	B-Material
-	I-Material
public	I-Material
,	O
Yannakoudakis2011	O
)	O
.	O
	
The	O
dataset	O
contains	O
short	O
texts	O
,	O
written	O
by	O
learners	O
of	O
English	O
as	O
an	O
additional	O
language	O
in	O
response	O
to	O
exam	O
prompts	O
eliciting	O
free	O
-	O
text	O
answers	O
and	O
assessing	O
mastery	O
of	O
the	O
upper	O
-	O
intermediate	O
proficiency	O
level	O
.	O
	
The	O
texts	O
have	O
been	O
manually	O
error	O
-	O
annotated	O
using	O
a	O
taxonomy	O
of	O
77	O
error	O
types	O
.	O
	
We	O
use	O
the	O
released	O
test	O
set	O
for	O
evaluation	O
,	O
containing	O
2	O
,	O
720	O
sentences	O
,	O
leaving	O
30	O
,	O
953	O
sentences	O
for	O
training	O
.	O
	
We	O
further	O
separate	O
2	O
,	O
222	O
sentences	O
from	O
the	O
training	O
set	O
for	O
development	O
and	O
hyper	B-Method
-	I-Method
parameter	I-Method
tuning	I-Method
.	O
	
The	O
dataset	O
contains	O
manually	O
annotated	O
error	O
spans	O
of	O
various	O
types	O
of	O
errors	O
,	O
together	O
with	O
their	O
suggested	O
corrections	O
.	O
	
We	O
convert	O
this	O
to	O
a	O
token	B-Task
-	I-Task
level	I-Task
error	I-Task
detection	I-Task
task	I-Task
by	O
labeling	O
each	O
token	O
inside	O
the	O
error	O
span	O
as	O
being	O
incorrect	O
.	O
	
In	O
order	O
to	O
capture	O
errors	O
involving	O
missing	O
words	O
,	O
the	O
error	O
label	O
is	O
assigned	O
to	O
the	O
token	O
immediately	O
after	O
the	O
incorrect	O
gap	O
–	O
	
this	O
is	O
motivated	O
by	O
the	O
intuition	O
that	O
while	O
this	O
token	O
is	O
correct	O
when	O
considered	O
in	O
isolation	O
,	O
it	O
is	O
incorrect	O
in	O
the	O
current	O
context	O
,	O
as	O
another	O
token	O
should	O
have	O
preceeded	O
it	O
.	O
	
As	O
the	O
main	O
evaluation	B-Metric
measure	I-Metric
for	O
error	B-Task
detection	I-Task
we	O
use	O
,	O
which	O
was	O
also	O
the	O
measure	O
adopted	O
in	O
the	O
CoNLL	B-Material
-	I-Material
14	I-Material
shared	I-Material
task	I-Material
on	O
error	B-Task
correction	I-Task
.	O
	
It	O
combines	O
both	O
precision	B-Metric
and	O
recall	B-Metric
,	O
while	O
assigning	O
twice	O
as	O
much	O
weight	O
to	O
precision	B-Metric
,	O
since	O
accurate	O
feedback	O
is	O
often	O
more	O
important	O
than	O
coverage	O
in	O
error	B-Task
detection	I-Task
applications	I-Task
.	O
	
Following	O
Chodorow2012	O
,	O
we	O
also	O
report	O
raw	O
counts	O
for	O
predicted	O
and	O
correct	O
tokens	O
.	O
	
Related	O
evaluation	B-Metric
measures	I-Metric
,	O
such	O
as	O
the	O
-	B-Method
scorer	I-Method
and	O
the	O
I	B-Metric
-	I-Metric
measure	I-Metric
,	O
require	O
the	O
system	O
to	O
propose	O
a	O
correction	B-Task
and	O
are	O
therefore	O
not	O
directly	O
applicable	O
on	O
the	O
task	O
of	O
error	B-Task
detection	I-Task
.	O
	
During	O
the	O
experiments	O
,	O
the	O
input	O
text	O
was	O
lowercased	O
and	O
all	O
tokens	O
that	O
occurred	O
less	O
than	O
twice	O
in	O
the	O
training	O
data	O
were	O
represented	O
as	O
a	O
single	O
unk	O
token	O
.	O
	
Word	O
embeddings	O
were	O
set	O
to	O
size	O
and	O
initialised	O
using	O
the	O
publicly	O
released	O
pretrained	O
Word2Vec	O
vectors	O
.	O
	
The	O
convolutional	B-Method
networks	I-Method
use	O
window	O
size	O
on	O
either	O
side	O
of	O
the	O
target	O
token	O
and	O
produce	O
a	O
300	O
-	O
dimensional	O
context	O
-	O
dependent	O
vector	O
.	O
	
The	O
recurrent	B-Method
networks	I-Method
use	O
hidden	O
layers	O
of	O
size	O
200	O
in	O
either	O
direction	O
.	O
	
We	O
also	O
added	O
an	O
extra	O
hidden	O
layer	O
of	O
size	O
between	O
each	O
of	O
the	O
composition	O
functions	O
and	O
the	O
output	O
layer	O
–	O
	
this	O
allows	O
the	O
network	O
to	O
learn	O
a	O
separate	O
non	B-Method
-	I-Method
linear	I-Method
transformation	I-Method
and	O
reduces	O
the	O
dimensionality	O
of	O
the	O
compositional	O
vectors	O
.	O
	
The	O
parameters	O
were	O
optimised	O
using	O
gradient	B-Method
descent	I-Method
with	O
initial	O
learning	B-Metric
rate	I-Metric
,	O
the	O
ADAM	B-Method
algorithm	I-Method
for	O
dynamically	O
adapting	O
the	O
learning	B-Metric
rate	I-Metric
,	O
and	O
batch	O
size	O
of	O
64	O
sentences	O
.	O
	
on	O
the	O
development	O
set	O
was	O
evaluated	O
at	O
each	O
epoch	O
,	O
and	O
the	O
best	O
model	O
was	O
used	O
for	O
final	O
evaluations	O
.	O
	
section	O
:	O
Results	O
	
Table	O
[	O
reference	O
]	O
contains	O
results	O
for	O
experiments	O
comparing	O
different	O
composition	B-Method
architectures	I-Method
on	O
the	O
task	O
of	O
error	B-Task
detection	I-Task
.	O
	
The	O
CRF	B-Method
has	O
the	O
lowest	O
score	O
compared	O
to	O
any	O
of	O
the	O
neural	B-Method
models	I-Method
.	O
	
It	O
memorises	O
frequent	O
error	O
sequences	O
with	O
high	O
precision	B-Metric
,	O
but	O
does	O
not	O
generalise	O
sufficiently	O
,	O
resulting	O
in	O
low	O
recall	B-Metric
.	O
	
The	O
ability	O
to	O
condition	O
on	O
the	O
previous	O
label	O
also	O
does	O
not	O
provide	O
much	O
help	O
on	O
this	O
task	O
–	O
there	O
are	O
only	O
two	O
possible	O
labels	O
and	O
the	O
errors	O
are	O
relatively	O
sparse	O
.	O
	
The	O
architecture	O
using	O
convolutional	B-Method
networks	I-Method
performs	O
well	O
and	O
achieves	O
the	O
second	O
-	O
highest	O
result	O
on	O
the	O
test	O
set	O
.	O
	
It	O
is	O
designed	O
to	O
detect	O
error	O
patterns	O
from	O
a	O
fixed	O
window	O
of	O
7	O
words	O
,	O
which	O
is	O
large	O
enough	O
to	O
not	O
require	O
the	O
use	O
of	O
more	O
advanced	O
composition	O
functions	O
.	O
	
In	O
contrast	O
,	O
the	O
performance	O
of	O
the	O
bidirectional	B-Method
recurrent	I-Method
network	I-Method
(	O
Bi	B-Method
-	I-Method
RNN	I-Method
)	O
is	O
somewhat	O
lower	O
,	O
especially	O
on	O
the	O
test	O
set	O
.	O
	
In	O
Elman	B-Method
-	I-Method
type	I-Method
recurrent	I-Method
networks	I-Method
,	O
the	O
context	O
signal	O
from	O
distant	O
words	O
decreases	O
fairly	O
rapidly	O
due	O
to	O
the	O
sigmoid	O
activation	O
function	O
and	O
diminishing	O
gradients	O
.	O
	
This	O
is	O
likely	O
why	O
the	O
Bi	B-Method
-	I-Method
RNN	I-Method
achieves	O
the	O
highest	O
precision	B-Metric
of	O
all	O
systems	O
	
–	O
	
the	O
predicted	O
label	O
is	O
mostly	O
influenced	O
by	O
the	O
target	O
token	O
and	O
its	O
immediate	O
neighbours	O
,	O
allowing	O
the	O
network	O
to	O
only	O
detect	O
short	O
high	O
-	O
confidence	O
error	O
patterns	O
.	O
	
The	O
convolutional	B-Method
network	I-Method
,	O
which	O
uses	O
7	O
context	O
words	O
with	O
equal	O
attention	O
,	O
is	O
able	O
to	O
outperform	O
the	O
Bi	B-Method
-	I-Method
RNN	I-Method
despite	O
the	O
fixed	O
-	O
size	O
context	O
window	O
.	O
	
The	O
best	O
overall	O
result	O
and	O
highest	O
is	O
achieved	O
by	O
the	O
bidirectional	B-Method
LSTM	I-Method
composition	I-Method
model	I-Method
(	O
Bi	O
-	O
LSTM	B-Method
)	O
.	O
	
This	O
architecture	O
makes	O
use	O
of	O
the	O
full	O
sentence	O
for	O
building	O
context	O
vectors	O
on	O
both	O
sides	O
of	O
the	O
target	O
token	O
,	O
but	O
improves	O
on	O
Bi	B-Method
-	I-Method
RNN	I-Method
by	O
utilising	O
a	O
more	O
advanced	O
composition	B-Method
function	I-Method
.	O
	
Through	O
the	O
application	O
of	O
a	O
linear	B-Method
update	I-Method
for	O
the	O
internal	B-Method
cell	I-Method
representation	I-Method
,	O
the	O
LSTM	B-Method
is	O
able	O
to	O
capture	O
dependencies	O
over	O
longer	O
distances	O
.	O
	
In	O
addition	O
,	O
the	O
gating	O
functions	O
allow	O
it	O
to	O
adaptively	O
decide	O
which	O
information	O
to	O
include	O
in	O
the	O
hidden	O
representations	O
or	O
output	O
for	O
error	B-Task
detection	I-Task
.	O
	
We	O
found	O
that	O
using	O
multiple	O
layers	O
of	O
compositional	O
functions	O
in	O
a	O
deeper	B-Method
network	I-Method
gave	O
comparable	O
or	O
slightly	O
lower	O
results	O
for	O
all	O
the	O
composition	B-Method
architectures	I-Method
.	O
	
This	O
is	O
in	O
contrast	O
to	O
Irsoy2014a	O
,	O
who	O
experimented	O
with	O
Elman	B-Method
-	I-Method
type	I-Method
networks	I-Method
and	O
found	O
some	O
improvements	O
using	O
multiple	B-Method
layers	I-Method
of	I-Method
Bi	I-Method
-	I-Method
RNNs	I-Method
.	O
	
The	O
differences	O
can	O
be	O
explained	O
by	O
their	O
task	O
benefiting	O
from	O
alternative	O
features	O
:	O
the	O
evaluation	O
was	O
performed	O
on	O
opinion	B-Task
mining	I-Task
where	O
most	O
target	O
sequences	O
are	O
longer	O
phrases	O
that	O
need	O
to	O
be	O
identified	O
based	O
on	O
their	O
semantics	O
,	O
whereas	O
many	O
errors	O
in	O
learner	B-Task
writing	I-Task
are	O
short	O
and	O
can	O
only	O
be	O
identified	O
by	O
a	O
contextual	O
mismatch	O
.	O
	
In	O
addition	O
,	O
our	O
networks	O
contain	O
an	O
extra	O
hidden	O
layer	O
before	O
the	O
output	O
,	O
which	O
allows	O
the	O
models	O
to	O
learn	O
higher	O
-	O
level	O
representations	O
without	O
adding	O
complexity	O
through	O
an	O
extra	O
compositional	B-Method
layer	I-Method
.	O
	
section	O
:	O
Additional	O
Training	O
Data	O
	
There	O
are	O
essentially	O
infinitely	O
many	O
ways	O
of	O
committing	O
errors	O
in	O
text	O
and	O
introducing	O
additional	O
training	O
data	O
should	O
alleviate	O
some	O
of	O
the	O
problems	O
with	O
data	O
sparsity	O
.	O
	
We	O
experimented	O
with	O
incrementally	O
adding	O
different	O
error	O
-	O
tagged	O
corpora	O
into	O
the	O
training	O
set	O
and	O
measured	O
the	O
resulting	O
performance	O
.	O
	
This	O
allows	O
us	O
to	O
provide	O
some	O
context	O
to	O
the	O
results	O
obtained	O
by	O
using	O
each	O
of	O
the	O
datasets	O
,	O
and	O
gives	O
us	O
an	O
estimate	O
of	O
how	O
much	O
annotated	O
data	O
is	O
required	O
for	O
optimal	O
performance	O
on	O
error	B-Task
detection	I-Task
.	O
	
The	O
datasets	O
we	O
consider	O
are	O
as	O
follows	O
:	O
FCE	B-Material
-	I-Material
public	I-Material
–	O
	
the	O
publicly	O
released	O
subset	O
of	O
FCE	B-Material
,	O
as	O
described	O
in	O
Section	O
[	O
reference	O
]	O
.	O
	
NUCLE	O
–	O
the	O
NUS	O
Corpus	O
of	O
Learner	O
English	O
,	O
used	O
as	O
the	O
main	O
training	O
set	O
for	O
CoNLL	B-Task
shared	I-Task
tasks	I-Task
on	O
error	B-Task
correction	I-Task
.	O
	
IELTS	B-Method
–	O
	
a	O
subset	O
of	O
the	O
IELTS	O
examination	O
dataset	O
extracted	O
from	O
the	O
Cambridge	O
Learner	O
Corpus	O
(	O
CLC	O
,	O
Nicholls2003	O
)	O
,	O
containing	O
68	O
,	O
505	O
sentences	O
from	O
all	O
proficiency	O
levels	O
,	O
also	O
used	O
by	O
Felice2014	O
.	O
	
FCE	B-Material
–	O
a	O
larger	O
selection	O
of	O
FCE	B-Material
texts	I-Material
from	O
the	O
CLC	B-Method
,	O
containing	O
323	O
,	O
192	O
sentences	O
.	O
	
CPE	B-Method
–	O
essays	O
from	O
the	O
proficient	O
examination	O
level	O
in	O
the	O
CLC	B-Method
,	O
containing	O
210	O
,	O
678	O
sentences	O
.	O
	
CAE	B-Method
–	O
essays	O
from	O
the	O
advanced	O
examination	O
level	O
in	O
the	O
CLC	B-Method
,	O
containing	O
219	O
,	O
953	O
sentences	O
.	O
	
Table	O
[	O
reference	O
]	O
contains	O
results	O
obtained	O
by	O
incrementally	O
adding	O
training	O
data	O
to	O
the	O
Bi	O
-	O
LSTM	B-Method
model	O
.	O
	
We	O
found	O
that	O
incorporating	O
the	O
NUCLE	O
dataset	O
does	O
not	O
improve	O
performance	O
over	O
using	O
only	O
the	O
FCE	B-Material
-	I-Material
public	I-Material
dataset	O
,	O
which	O
is	O
likely	O
due	O
to	O
the	O
two	O
corpora	O
containing	O
texts	O
with	O
different	O
domains	O
and	O
writing	O
styles	O
.	O
	
The	O
texts	O
in	O
FCE	B-Material
are	O
written	O
by	O
young	O
intermediate	O
students	O
,	O
in	O
response	O
to	O
prompts	O
eliciting	O
letters	O
,	O
emails	O
and	O
reviews	O
,	O
whereas	O
NUCLE	O
contains	O
mostly	O
argumentative	O
essays	O
written	O
by	O
advanced	O
adult	O
learners	O
.	O
	
The	O
differences	O
in	O
the	O
datasets	O
offset	O
the	O
benefits	O
from	O
additional	O
training	O
data	O
,	O
and	O
the	O
performance	O
remains	O
roughly	O
the	O
same	O
.	O
	
In	O
contrast	O
,	O
substantial	O
improvements	O
are	O
obtained	O
when	O
introducing	O
the	O
IELTS	O
and	O
FCE	B-Material
datasets	I-Material
,	O
with	O
each	O
of	O
them	O
increasing	O
the	O
score	O
by	O
roughly	O
.	O
	
The	O
IELTS	O
dataset	O
contains	O
essays	O
from	O
all	O
proficiency	O
levels	O
,	O
and	O
FCE	B-Material
from	O
mid	O
-	O
level	O
English	O
learners	O
,	O
which	O
provides	O
the	O
model	O
with	O
a	O
distribution	O
of	O
‘	O
average	O
’	O
errors	O
to	O
learn	O
from	O
.	O
	
Adding	O
even	O
more	O
training	O
data	O
from	O
high	O
-	O
proficiency	O
essays	O
in	O
CPE	O
and	O
CAE	O
only	O
provides	O
minor	O
further	O
improvements	O
.	O
	
Figure	O
[	O
reference	O
]	O
also	O
shows	O
on	O
the	O
FCE	B-Material
-	I-Material
public	I-Material
test	O
set	O
as	O
a	O
function	O
of	O
the	O
total	O
number	O
of	O
tokens	O
in	O
the	O
training	O
data	O
.	O
	
The	O
optimal	O
trade	O
-	O
off	O
between	O
performance	O
and	O
data	B-Metric
size	I-Metric
is	O
obtained	O
at	O
around	O
8	O
million	O
tokens	O
,	O
after	O
introducing	O
the	O
FCE	B-Material
dataset	I-Material
.	O
	
section	O
:	O
CoNLL	B-Material
-	I-Material
14	I-Material
Shared	I-Material
Task	I-Material
	
The	O
CoNLL	B-Material
-	I-Material
14	I-Material
shared	I-Material
task	I-Material
focussed	O
on	O
automatically	B-Task
correcting	I-Task
errors	I-Task
in	O
learner	B-Task
writing	I-Task
.	O
	
The	O
NUCLE	O
dataset	O
was	O
provided	O
as	O
the	O
main	O
training	O
dataset	O
,	O
but	O
participants	O
were	O
allowed	O
to	O
include	O
other	O
annotated	O
corpora	O
and	O
external	O
resources	O
.	O
	
For	O
evaluation	O
,	O
25	O
students	O
were	O
recruited	O
to	O
each	O
write	O
two	O
new	O
essays	O
,	O
which	O
were	O
then	O
annotated	O
by	O
two	O
experts	O
.	O
	
We	O
used	O
the	O
same	O
methods	O
from	O
Section	O
[	O
reference	O
]	O
for	O
converting	O
the	O
shared	B-Task
task	I-Task
annotation	I-Task
to	O
a	O
token	B-Task
-	I-Task
level	I-Task
labeling	I-Task
task	I-Task
in	O
order	O
to	O
evaluate	O
the	O
models	O
on	O
error	B-Task
detection	I-Task
.	O
	
In	O
addition	O
,	O
the	O
correction	O
outputs	O
of	O
all	O
the	O
participating	O
systems	O
were	O
made	O
available	O
online	O
,	O
therefore	O
we	O
are	O
able	O
to	O
report	O
their	O
performance	O
on	O
this	O
task	O
.	O
	
In	O
order	O
to	O
convert	O
their	O
output	O
to	O
error	O
detection	O
labels	O
,	O
the	O
corrected	O
sentences	O
were	O
aligned	O
with	O
the	O
original	O
input	O
using	O
Levenshtein	O
distance	O
,	O
and	O
any	O
changes	O
proposed	O
by	O
the	O
system	O
resulted	O
in	O
the	O
corresponding	O
source	O
words	O
being	O
labeled	O
as	O
errors	O
.	O
	
The	O
results	O
on	O
the	O
two	O
annotations	O
of	O
the	O
shared	O
task	O
test	O
data	O
can	O
be	O
seen	O
in	O
Table	O
[	O
reference	O
]	O
.	O
	
We	O
first	O
evaluated	O
each	O
of	O
the	O
human	O
annotators	O
with	O
respect	O
to	O
the	O
other	O
,	O
in	O
order	O
to	O
estimate	O
the	O
upper	O
bound	O
on	O
this	O
task	O
.	O
	
The	O
average	O
of	O
roughly	O
50	O
%	O
shows	O
that	O
the	O
task	O
is	O
difficult	O
and	O
even	O
human	O
experts	O
have	O
a	O
rather	O
low	O
agreement	O
.	O
	
It	O
has	O
been	O
shown	O
before	O
that	O
correcting	O
grammatical	O
errors	O
is	O
highly	O
subjective	O
,	O
but	O
these	O
results	O
indicate	O
that	O
trained	O
annotators	O
can	O
disagree	O
even	O
on	O
the	O
number	O
and	O
location	O
of	O
errors	O
.	O
	
In	O
the	O
same	O
table	O
,	O
we	O
provide	O
error	B-Task
detection	I-Task
results	O
for	O
the	O
top	O
3	O
participants	O
in	O
the	O
shared	B-Task
task	I-Task
:	O
CAMB	B-Method
,	O
CUUI	B-Method
,	O
and	O
AMU	B-Method
.	O
	
They	O
each	O
preserve	O
their	O
relative	O
ranking	O
also	O
in	O
the	O
error	B-Task
detection	I-Task
evaluation	I-Task
.	O
	
The	O
CAMB	B-Method
system	I-Method
has	O
a	O
lower	O
precision	B-Metric
but	O
the	O
highest	O
recall	B-Metric
,	O
also	O
resulting	O
in	O
the	O
highest	O
.	O
	
CUUI	B-Method
and	O
AMU	B-Method
are	O
close	O
in	O
performance	O
,	O
with	O
AMU	B-Method
having	O
slightly	O
higher	O
precision	B-Metric
.	O
	
After	O
the	O
official	B-Task
shared	I-Task
task	I-Task
,	O
Susanto2014	O
published	O
a	O
system	O
which	O
combines	O
several	O
alternative	O
models	O
and	O
outperforms	O
the	O
shared	O
task	O
participants	O
when	O
evaluated	O
on	O
error	B-Task
correction	I-Task
.	O
	
However	O
,	O
on	O
error	B-Task
detection	I-Task
it	O
receives	O
lower	O
results	O
,	O
ranking	O
3rd	O
and	O
4th	O
when	O
evaluated	O
on	O
(	O
P1	O
+	O
P2	O
+	O
S1	O
+	O
S2	O
in	O
Table	O
[	O
reference	O
]	O
)	O
.	O
	
The	O
system	O
has	O
detected	O
a	O
small	O
number	O
of	O
errors	O
with	O
high	O
precision	B-Metric
,	O
and	O
does	O
not	O
reach	O
the	O
highest	O
.	O
	
Finally	O
,	O
we	O
present	O
results	O
for	O
the	O
Bi	O
-	O
LSTM	B-Method
sequence	O
labeling	O
system	O
for	O
error	B-Task
detection	I-Task
.	O
	
Using	O
only	O
FCE	B-Material
-	I-Material
public	I-Material
for	O
training	B-Task
,	O
the	O
overall	O
performance	O
is	O
rather	O
low	O
as	O
the	O
training	O
set	O
is	O
very	O
small	O
and	O
contains	O
texts	O
from	O
a	O
different	O
domain	O
.	O
	
However	O
,	O
these	O
results	O
show	O
that	O
the	O
model	O
behaves	O
as	O
expected	O
–	O
since	O
it	O
has	O
not	O
seen	O
similar	O
language	O
during	O
training	O
,	O
it	O
labels	O
a	O
very	O
large	O
portion	O
of	O
tokens	O
as	O
errors	O
.	O
	
This	O
indicates	O
that	O
the	O
network	O
is	O
trying	O
to	O
learn	O
correct	O
language	O
constructions	O
from	O
the	O
limited	O
data	O
and	O
classifies	O
unseen	O
structures	O
as	O
errors	O
,	O
as	O
opposed	O
to	O
simply	O
memorising	O
error	O
sequences	O
from	O
the	O
training	O
data	O
.	O
	
When	O
trained	O
on	O
all	O
the	O
datasets	O
from	O
Section	O
[	O
reference	O
]	O
,	O
the	O
model	O
achieves	O
the	O
highest	O
of	O
all	O
systems	O
on	O
both	O
of	O
the	O
CoNLL	B-Material
-	I-Material
14	I-Material
shared	I-Material
task	I-Material
test	O
annotations	O
,	O
with	O
an	O
absolute	O
improvement	O
of	O
over	O
the	O
previous	O
best	O
result	O
.	O
	
It	O
is	O
worth	O
noting	O
that	O
the	O
full	O
Bi	O
-	O
LSTM	B-Method
has	O
been	O
trained	O
on	O
more	O
data	O
than	O
the	O
other	O
CoNLL	B-Material
contestants	I-Material
.	O
	
However	O
,	O
as	O
the	O
shared	B-Method
task	I-Method
systems	I-Method
were	O
not	O
restricted	O
to	O
the	O
NUCLE	O
training	O
set	O
,	O
all	O
the	O
submissions	O
also	O
used	O
differing	O
amounts	O
of	O
training	O
data	O
from	O
various	O
sources	O
.	O
	
In	O
addition	O
,	O
the	O
CoNLL	B-Method
systems	I-Method
are	O
mostly	O
combinations	O
of	O
many	O
alternative	O
models	O
:	O
the	O
CAMB	B-Method
system	I-Method
is	O
a	O
hybrid	O
of	O
machine	B-Method
translation	I-Method
,	O
a	O
rule	B-Method
-	I-Method
based	I-Method
system	I-Method
,	O
and	O
a	O
language	B-Method
model	I-Method
re	I-Method
-	I-Method
ranker	I-Method
;	O
CUUI	B-Method
consists	O
of	O
different	O
classifiers	B-Method
for	O
each	O
individual	O
error	O
type	O
;	O
and	O
P1	B-Method
+	I-Method
P2	I-Method
+	I-Method
S1	I-Method
+	I-Method
S2	I-Method
is	O
a	O
combination	O
of	O
four	O
different	O
error	B-Method
correction	I-Method
systems	I-Method
.	O
	
In	O
contrast	O
,	O
the	O
Bi	O
-	O
LSTM	B-Method
is	O
a	O
single	O
model	O
for	O
detecting	O
all	O
error	B-Task
types	I-Task
,	O
and	O
therefore	O
represents	O
a	O
more	O
scalable	O
data	B-Method
-	I-Method
driven	I-Method
approach	I-Method
.	O
	
section	O
:	O
Essay	B-Metric
Scoring	I-Metric
	
In	O
this	O
section	O
,	O
we	O
perform	O
an	O
extrinsic	O
evaluation	O
of	O
the	O
efficacy	O
of	O
the	O
error	B-Method
detection	I-Method
system	I-Method
and	O
examine	O
the	O
extent	O
to	O
which	O
it	O
generalises	O
at	O
higher	O
levels	O
of	O
granularity	O
on	O
the	O
task	O
of	O
automated	B-Task
essay	I-Task
scoring	I-Task
.	O
	
More	O
specifically	O
,	O
we	O
replicate	O
experiments	O
using	O
the	O
text	B-Method
-	I-Method
level	I-Method
model	I-Method
described	O
by	O
Andersen2013	O
,	O
which	O
is	O
currently	O
deployed	O
in	O
a	O
self	B-Method
-	I-Method
assessment	I-Method
and	O
tutoring	B-Method
system	I-Method
(	O
SAT	B-Method
)	O
,	O
an	O
online	B-Task
automated	I-Task
writing	I-Task
feedback	I-Task
tool	I-Task
actively	O
used	O
by	O
language	B-Task
learners	I-Task
.	O
	
The	O
SAT	B-Method
system	O
predicts	O
an	O
overall	O
score	O
for	O
a	O
given	O
text	O
,	O
which	O
provides	O
a	O
holistic	B-Task
assessment	I-Task
of	I-Task
linguistic	I-Task
competence	I-Task
and	O
language	B-Task
proficiency	I-Task
.	O
	
The	O
authors	O
trained	O
a	O
supervised	B-Method
ranking	I-Method
perceptron	I-Method
model	I-Method
on	O
the	O
FCE	B-Material
-	I-Material
public	I-Material
dataset	O
,	O
using	O
features	O
such	O
as	O
error	B-Metric
-	I-Metric
rate	I-Metric
estimates	I-Metric
from	O
a	O
language	B-Method
model	I-Method
and	O
various	O
lexical	O
and	O
grammatical	O
properties	O
of	O
text	O
(	O
e.g.	O
,	O
word	O
n	O
-	O
grams	O
,	O
part	O
-	O
of	O
-	O
speech	O
n	O
-	O
grams	O
and	O
phrase	O
-	O
structure	O
rules	O
)	O
.	O
	
We	O
replicate	O
this	O
experiment	O
and	O
add	O
the	O
average	O
probability	O
of	O
each	O
token	O
in	O
the	O
essay	O
being	O
correct	O
,	O
according	O
to	O
the	O
error	B-Method
detection	I-Method
model	I-Method
,	O
as	O
an	O
additional	O
feature	O
for	O
the	O
scoring	B-Method
framework	I-Method
.	O
	
The	O
system	O
was	O
then	O
retrained	O
on	O
FCE	B-Material
-	I-Material
public	I-Material
and	O
evaluated	O
on	O
correctly	O
predicting	O
the	O
assigned	O
essay	B-Metric
score	I-Metric
.	O
	
Table	O
[	O
reference	O
]	O
presents	O
the	O
experimental	O
results	O
.	O
	
The	O
human	O
performance	O
on	O
the	O
test	O
set	O
is	O
calculated	O
as	O
the	O
average	B-Metric
inter	I-Metric
-	I-Metric
annotator	I-Metric
correlation	I-Metric
on	O
the	O
same	O
data	O
,	O
and	O
the	O
existing	O
SAT	B-Method
system	O
has	O
demonstrated	O
levels	O
of	O
performance	O
that	O
are	O
very	O
close	O
to	O
that	O
of	O
human	O
assessors	O
.	O
	
Nevertheless	O
,	O
the	O
Bi	O
-	O
LSTM	B-Method
model	O
trained	O
only	O
on	O
FCE	B-Material
-	I-Material
public	I-Material
complements	O
the	O
existing	O
features	O
,	O
and	O
the	O
combined	O
model	O
achieves	O
an	O
absolute	O
improvement	O
of	O
around	O
1	O
%	O
percent	O
,	O
corresponding	O
to	O
20	O
-	O
31	O
%	O
relative	B-Metric
error	I-Metric
reduction	I-Metric
with	O
respect	O
to	O
the	O
human	O
performance	O
.	O
	
Even	O
though	O
the	O
Bi	O
-	O
LSTM	B-Method
is	O
trained	O
on	O
the	O
same	O
dataset	O
and	O
the	O
SAT	B-Method
system	O
already	O
includes	O
various	O
linguistic	O
features	O
for	O
capturing	O
errors	O
,	O
our	O
error	B-Method
detection	I-Method
model	I-Method
manages	O
to	O
further	O
improve	O
its	O
performance	O
.	O
	
When	O
the	O
Bi	O
-	O
LSTM	B-Method
is	O
trained	O
on	O
all	O
the	O
available	O
data	O
from	O
Section	O
[	O
reference	O
]	O
,	O
the	O
combination	O
achieves	O
further	O
substantial	O
improvements	O
.	O
	
The	O
relative	B-Metric
error	I-Metric
reduction	I-Metric
on	O
Pearson	B-Metric
’s	I-Metric
correlation	I-Metric
is	O
64	O
%	O
,	O
and	O
the	O
system	O
actually	O
outperforms	O
human	O
annotators	O
on	O
Spearman	B-Metric
’s	I-Metric
correlation	I-Metric
.	O
	
section	O
:	O
Conclusions	O
	
In	O
this	O
paper	O
,	O
we	O
presented	O
the	O
first	O
experiments	O
using	O
neural	B-Method
network	I-Method
models	I-Method
for	O
the	O
task	O
of	O
error	B-Task
detection	I-Task
in	O
learner	B-Task
writing	I-Task
.	O
	
Six	O
alternative	O
compositional	B-Method
network	I-Method
architectures	I-Method
for	O
modeling	B-Task
context	I-Task
were	O
evaluated	O
.	O
	
Based	O
on	O
the	O
findings	O
,	O
we	O
propose	O
a	O
novel	O
error	B-Method
detection	I-Method
framework	I-Method
using	O
token	B-Method
-	I-Method
level	I-Method
embeddings	I-Method
,	O
bidirectional	O
LSTMs	B-Method
for	O
context	B-Method
representation	I-Method
,	O
and	O
a	O
multi	B-Method
-	I-Method
layer	I-Method
architecture	I-Method
for	O
learning	O
more	O
complex	O
features	O
.	O
	
This	O
structure	O
allows	O
the	O
model	O
to	O
classify	O
each	O
token	O
as	O
being	O
correct	O
or	O
incorrect	O
,	O
using	O
the	O
full	O
sentence	O
as	O
context	O
.	O
	
The	O
self	B-Method
-	I-Method
modulation	I-Method
architecture	I-Method
of	O
LSTMs	B-Method
was	O
also	O
shown	O
to	O
be	O
beneficial	O
,	O
as	O
it	O
allows	O
the	O
network	O
to	O
learn	O
more	O
advanced	O
composition	O
rules	O
and	O
remember	O
dependencies	O
over	O
longer	O
distances	O
.	O
	
Substantial	O
performance	O
improvements	O
were	O
achieved	O
by	O
training	O
the	O
best	O
model	O
on	O
additional	O
datasets	O
.	O
	
We	O
found	O
that	O
the	O
largest	O
benefit	O
was	O
obtained	O
from	O
training	O
on	O
8	O
million	O
tokens	O
of	O
text	O
from	O
learners	O
with	O
varying	O
levels	O
of	O
language	O
proficiency	O
.	O
	
In	O
contrast	O
,	O
including	O
even	O
more	O
data	O
from	O
higher	O
-	O
proficiency	O
learners	O
gave	O
marginal	O
further	O
improvements	O
.	O
	
As	O
part	O
of	O
future	O
work	O
,	O
it	O
would	O
be	O
beneficial	O
to	O
investigate	O
the	O
effect	O
of	O
automatically	O
generated	O
training	O
data	O
for	O
error	B-Task
detection	I-Task
(	O
e.g.	O
,	O
Rozovskaya2010	O
)	O
.	O
	
We	O
evaluated	O
the	O
performance	O
of	O
existing	O
error	B-Method
correction	I-Method
systems	I-Method
from	O
CoNLL	B-Material
-	I-Material
14	I-Material
on	O
the	O
task	O
of	O
error	B-Task
detection	I-Task
.	O
	
The	O
experiments	O
showed	O
that	O
success	O
on	O
error	B-Task
correction	I-Task
does	O
not	O
necessarily	O
mean	O
success	O
on	O
error	B-Task
detection	I-Task
,	O
as	O
the	O
current	O
best	O
correction	B-Method
system	I-Method
(	O
P1	B-Method
+	I-Method
P2	I-Method
+	I-Method
S1	I-Method
+	I-Method
S2	I-Method
)	O
is	O
not	O
the	O
same	O
as	O
the	O
best	O
shared	B-Method
task	I-Method
detection	I-Method
system	I-Method
(	O
CAMB	B-Method
)	O
.	O
	
In	O
addition	O
,	O
the	O
neural	B-Method
sequence	I-Method
tagging	I-Method
model	I-Method
,	O
specialised	O
for	O
error	B-Task
detection	I-Task
,	O
was	O
able	O
to	O
outperform	O
all	O
other	O
participating	O
systems	O
.	O
	
Finally	O
,	O
we	O
performed	O
an	O
extrinsic	B-Task
evaluation	I-Task
by	O
incorporating	O
probabilities	O
from	O
the	O
error	B-Method
detection	I-Method
system	I-Method
as	O
features	O
in	O
an	O
essay	B-Method
scoring	I-Method
model	I-Method
.	O
	
Even	O
without	O
any	O
additional	O
data	O
,	O
the	O
combination	O
further	O
improved	O
performance	O
which	O
is	O
already	O
close	O
to	O
the	O
results	O
from	O
human	O
annotators	O
.	O
	
In	O
addition	O
,	O
when	O
the	O
error	B-Method
detection	I-Method
model	I-Method
was	O
trained	O
on	O
a	O
larger	O
training	O
set	O
,	O
the	O
essay	B-Metric
scorer	I-Metric
was	O
able	O
to	O
exceed	O
human	O
-	O
level	O
performance	O
.	O
	
section	O
:	O
Acknowledgments	O
	
We	O
would	O
like	O
to	O
thank	O
Prof	O
Ted	O
Briscoe	O
and	O
the	O
reviewers	O
for	O
providing	O
useful	O
feedback	O
.	O
	
bibliography	O
:	O
References	O
	
document	O
:	O
Filtered	B-Method
Channel	I-Method
Features	I-Method
for	O
Pedestrian	B-Task
Detection	I-Task
	
This	O
paper	O
starts	O
from	O
the	O
observation	O
that	O
multiple	O
top	B-Method
performing	I-Method
pedestrian	I-Method
detectors	I-Method
can	O
be	O
modelled	O
by	O
using	O
an	O
intermediate	B-Method
layer	I-Method
filtering	I-Method
low	I-Method
-	I-Method
level	I-Method
features	I-Method
in	O
combination	O
with	O
a	O
boosted	B-Method
decision	I-Method
forest	I-Method
.	O
	
Based	O
on	O
this	O
observation	O
we	O
propose	O
a	O
unifying	B-Method
framework	I-Method
and	O
experimentally	O
explore	O
different	O
filter	B-Method
families	I-Method
.	O
	
We	O
report	O
extensive	O
results	O
enabling	O
a	O
systematic	O
analysis	O
.	O
	
Using	O
filtered	O
channel	O
features	O
we	O
obtain	O
top	O
performance	O
on	O
the	O
challenging	O
Caltech	B-Material
and	O
KITTI	B-Material
datasets	O
,	O
while	O
using	O
only	O
HOG	O
+	O
LUV	O
as	O
low	O
-	O
level	O
features	O
.	O
	
When	O
adding	O
optical	O
flow	O
features	O
we	O
further	O
improve	O
detection	B-Metric
quality	I-Metric
and	O
report	O
the	O
best	O
known	O
results	O
on	O
the	O
Caltech	B-Material
dataset	I-Material
,	O
reaching	O
93	O
%	O
recall	B-Metric
at	O
1	O
FPPI	B-Metric
.	O
=	O
	
-	O
1	O
	
section	O
:	O
Introduction	O
	
Pedestrian	B-Task
detection	I-Task
is	O
an	O
active	O
research	O
area	O
,	O
with	O
1000	O
+	O
papers	O
published	O
in	O
the	O
last	O
decade	O
,	O
and	O
well	O
established	O
benchmark	O
datasets	O
.	O
	
It	O
is	O
considered	O
a	O
canonical	O
case	O
of	O
object	B-Task
detection	I-Task
,	O
and	O
has	O
served	O
as	O
playground	O
to	O
explore	O
ideas	O
that	O
might	O
be	O
effective	O
for	O
generic	B-Task
object	I-Task
detection	I-Task
.	O
	
Although	O
many	O
different	O
ideas	O
have	O
been	O
explored	O
,	O
and	O
detection	B-Metric
quality	I-Metric
has	O
been	O
steadily	O
improving	O
,	O
arguably	O
it	O
is	O
still	O
unclear	O
what	O
are	O
the	O
key	O
ingredients	O
for	O
good	O
pedestrian	B-Task
detection	I-Task
;	O
e.g.	O
it	O
remains	O
unclear	O
how	O
effective	O
parts	O
,	O
components	O
,	O
and	O
features	B-Method
learning	I-Method
are	O
for	O
this	O
task	O
.	O
	
Current	O
top	O
performing	O
pedestrian	B-Method
detection	I-Method
methods	I-Method
all	O
point	O
to	O
an	O
intermediate	O
layer	O
(	O
such	O
as	O
max	B-Method
-	I-Method
pooling	I-Method
or	O
filtering	B-Method
)	O
between	O
the	O
low	O
-	O
level	O
feature	O
maps	O
and	O
the	O
classification	B-Method
layer	I-Method
.	O
	
In	O
this	O
paper	O
we	O
explore	O
the	O
simplest	O
of	O
such	O
intermediary	O
:	O
a	O
linear	B-Method
transformation	I-Method
implemented	O
as	O
convolution	B-Method
with	O
a	O
filter	B-Method
bank	I-Method
.	O
	
We	O
propose	O
a	O
framework	O
for	O
filtered	O
channel	O
features	O
(	O
see	O
figure	O
[	O
reference	O
]	O
)	O
that	O
unifies	O
multiple	O
top	O
performing	O
methods	O
,	O
and	O
that	O
enables	O
a	O
systematic	O
exploration	O
of	O
different	O
filter	B-Method
banks	I-Method
.	O
	
With	O
our	O
experiments	O
we	O
show	O
that	O
,	O
with	O
the	O
proper	O
filter	B-Method
bank	I-Method
,	O
filtered	O
channel	O
features	O
reach	O
top	B-Metric
detection	I-Metric
quality	I-Metric
.	O
	
It	O
has	O
been	O
shown	O
that	O
using	O
extra	O
information	O
at	O
test	O
time	O
(	O
such	O
as	O
context	O
,	O
stereo	O
images	O
,	O
optical	O
flow	O
,	O
etc	O
.	O
)	O
can	O
boost	O
detection	B-Metric
quality	I-Metric
.	O
	
In	O
this	O
paper	O
we	O
focus	O
on	O
the	O
‘	O
	
‘	O
core	O
’	O
’	O
sliding	B-Method
window	I-Method
algorithm	I-Method
using	O
solely	O
HOG	O
+	O
LUV	O
features	O
(	O
i.e.	O
oriented	O
gradient	O
magnitude	O
and	O
colour	O
features	O
)	O
.	O
	
We	O
consider	O
context	O
information	O
and	O
optical	O
flow	O
as	O
add	O
-	O
ons	O
,	O
included	O
in	O
the	O
experiments	O
section	O
for	O
the	O
sake	O
of	O
completeness	O
and	O
comparison	O
with	O
existing	O
methods	O
.	O
	
Using	O
only	O
HOG	O
+	O
LUV	O
features	O
we	O
already	O
reach	O
top	O
performance	O
on	O
the	O
challenging	O
Caltech	B-Material
and	O
KITTI	B-Material
datasets	O
,	O
matching	O
results	O
using	O
optical	O
flow	O
and	O
significantly	O
more	O
features	O
(	O
such	O
as	O
LBP	O
and	O
covariance	O
)	O
.	O
	
subsection	O
:	O
Related	O
work	O
	
Recent	O
survey	O
papers	O
discuss	O
the	O
diverse	O
set	O
of	O
ideas	O
explored	O
for	O
pedestrian	B-Task
detection	I-Task
.	O
	
The	O
most	O
recent	O
survey	O
indicates	O
that	O
the	O
classifier	B-Method
choice	I-Method
(	O
e.g.	O
linear	B-Method
/	I-Method
non	I-Method
-	I-Method
linear	I-Method
SVM	I-Method
versus	O
decision	B-Method
forest	I-Method
)	O
is	O
not	O
a	O
clear	O
differentiator	O
regarding	O
quality	B-Metric
;	O
rather	O
the	O
features	O
used	O
seem	O
more	O
important	O
.	O
	
Creativity	O
regarding	O
different	O
types	O
of	O
features	O
has	O
not	O
been	O
lacking	O
.	O
	
HOG	O
)	O
	
The	O
classic	O
HOG	B-Method
descriptor	I-Method
is	O
based	O
on	O
local	O
image	O
differences	O
(	O
plus	O
pooling	B-Method
and	I-Method
normalization	I-Method
steps	I-Method
)	O
,	O
and	O
has	O
been	O
used	O
directly	O
,	O
as	O
input	O
for	O
a	O
deformable	B-Method
parts	I-Method
model	I-Method
,	O
or	O
as	O
features	O
to	O
be	O
boosted	O
.	O
	
The	O
integral	B-Method
channel	I-Method
features	I-Method
detector	I-Method
uses	O
a	O
simpler	O
HOG	B-Method
variant	I-Method
with	O
sum	B-Method
pooling	I-Method
and	O
no	O
normalizations	B-Method
.	O
	
Many	O
extensions	O
of	O
HOG	B-Method
have	O
been	O
proposed	O
(	O
e.g.	O
)	O
.	O
	
LBP	O
)	O
	
Instead	O
of	O
using	O
the	O
magnitude	O
of	O
local	O
pixel	O
differences	O
,	O
LBP	B-Method
uses	O
the	O
difference	O
sign	O
only	O
as	O
signal	O
.	O
	
Colour	O
)	O
	
Although	O
the	O
appearance	O
of	O
pedestrians	O
is	O
diverse	O
,	O
the	O
background	O
and	O
skin	O
areas	O
do	O
exhibit	O
a	O
colour	O
bias	O
.	O
	
Colour	O
has	O
shown	O
to	O
be	O
an	O
effective	O
feature	O
for	O
pedestrian	B-Task
detection	I-Task
and	O
hence	O
multiple	O
colour	O
spaces	O
have	O
been	O
explored	O
(	O
both	O
hand	O
-	O
crafted	O
and	O
learned	O
)	O
.	O
	
Local	O
structure	O
)	O
	
Instead	O
of	O
simple	O
pixel	O
values	O
,	O
some	O
approaches	O
try	O
to	O
encode	O
a	O
larger	O
local	O
structure	O
based	O
on	O
colour	O
similarities	O
(	O
soft	O
-	O
cue	O
)	O
,	O
segmentation	B-Method
methods	I-Method
(	O
hard	O
-	O
decision	O
)	O
,	O
or	O
by	O
estimating	O
local	O
boundaries	O
.	O
	
Covariance	B-Method
)	O
	
Another	O
popular	O
way	O
to	O
encode	O
richer	O
information	O
is	O
to	O
compute	O
the	O
covariance	O
amongst	O
features	O
(	O
commonly	O
colour	O
,	O
gradient	O
,	O
and	O
oriented	O
gradient	O
)	O
.	O
	
Etc	O
.	O
)	O
	
Other	O
features	O
include	O
bag	O
-	O
of	O
-	O
words	O
over	O
colour	O
,	O
HOG	O
,	O
or	O
LBP	O
features	O
;	O
learning	O
sparse	B-Method
dictionary	I-Method
encoders	I-Method
;	O
and	O
training	O
features	O
via	O
a	O
convolutional	B-Method
neural	I-Method
network	I-Method
.	O
	
Additional	O
features	O
specific	O
for	O
stereo	B-Task
depth	I-Task
or	O
optical	B-Task
flow	I-Task
have	O
been	O
proposed	O
,	O
however	O
we	O
consider	O
these	O
beyond	O
the	O
focus	O
of	O
this	O
paper	O
.	O
	
For	O
our	O
flow	O
experiments	O
we	O
will	O
use	O
difference	O
of	O
frames	O
from	O
weakly	O
stabilized	O
videos	O
(	O
SDt	B-Method
)	O
.	O
	
All	O
the	O
feature	O
types	O
listed	O
above	O
can	O
be	O
used	O
in	O
the	O
integral	B-Method
channel	I-Method
features	I-Method
detector	I-Method
framework	I-Method
.	O
	
This	O
family	O
of	O
detectors	O
is	O
an	O
extension	O
of	O
the	O
old	O
ideas	O
from	O
Viola	O
&	O
Jones	O
.	O
	
Sums	O
of	O
rectangular	O
regions	O
are	O
used	O
as	O
input	O
to	O
decision	B-Method
trees	I-Method
trained	O
via	O
Adaboost	B-Method
.	O
	
Both	O
the	O
regions	O
to	O
pool	O
from	O
and	O
the	O
thresholds	O
in	O
the	O
decision	O
trees	O
are	O
selected	O
during	O
training	O
.	O
	
The	O
crucial	O
difference	O
from	O
the	O
pioneer	O
work	O
is	O
that	O
the	O
sums	O
are	O
done	O
over	O
feature	O
channels	O
other	O
than	O
simple	O
image	O
luminance	O
.	O
	
Current	O
top	O
performing	O
pedestrian	B-Method
detection	I-Method
methods	I-Method
(	O
dominating	O
INRIA	O
,	O
Caltech	B-Material
and	O
KITTI	B-Material
datasets	O
)	O
are	O
all	O
extensions	O
of	O
the	O
basic	O
integral	B-Method
channel	I-Method
features	I-Method
detector	I-Method
(	O
named	O
ChnFtrs	B-Method
in	O
,	O
which	O
uses	O
only	O
HOG	O
+	O
LUV	O
features	O
)	O
.	O
	
SquaresChnFtrs	B-Method
,	O
InformedHaar	B-Method
,	O
and	O
LDCF	B-Method
,	O
are	O
discussed	O
in	O
detail	O
in	O
section	O
[	O
reference	O
]	O
.	O
	
Katamari	O
exploits	O
context	O
and	O
optical	B-Method
flow	I-Method
for	O
improved	O
performance	O
.	O
	
SpatialPooling	B-Method
(+	I-Method
)	I-Method
adds	O
max	B-Method
-	I-Method
pooling	I-Method
on	O
top	O
of	O
sum	B-Method
-	I-Method
pooling	I-Method
,	O
and	O
uses	O
additional	O
features	O
such	O
as	O
covariance	O
,	O
LBP	O
,	O
and	O
optical	O
flow	O
.	O
	
Similarly	O
,	O
Regionlets	B-Method
also	O
uses	O
extended	O
features	O
and	O
max	B-Method
-	I-Method
pooling	I-Method
,	O
together	O
with	O
stronger	O
weak	B-Method
classifiers	I-Method
and	O
training	O
a	O
cascade	B-Method
of	I-Method
classifiers	I-Method
.	O
	
Out	O
of	O
these	O
,	O
Regionlets	B-Method
is	O
the	O
only	O
method	O
that	O
has	O
also	O
shown	O
good	O
performance	O
on	O
general	O
classes	O
datasets	O
such	O
as	O
Pascal	O
VOC	O
and	O
ImageNet	O
.	O
	
In	O
this	O
paper	O
we	O
will	O
show	O
that	O
vanilla	O
HOG	O
+	O
LUV	O
features	O
have	O
not	O
yet	O
saturated	O
,	O
and	O
that	O
,	O
when	O
properly	O
used	O
,	O
they	O
can	O
reach	O
top	O
performance	O
for	O
pedestrian	B-Task
detection	I-Task
.	O
	
subsection	O
:	O
Contributions	O
	
We	O
point	O
out	O
the	O
link	O
between	O
ACF	B-Method
,	O
(	O
Squares	B-Method
)	I-Method
ChnFtrs	I-Method
,	O
InformedHaar	B-Method
,	O
and	O
LDCF	B-Method
.	O
	
See	O
section	O
[	O
reference	O
]	O
.	O
	
We	O
provide	O
extensive	O
experiments	O
to	O
enable	O
a	O
systematic	O
analysis	O
of	O
the	O
filtered	B-Method
integral	I-Method
channels	I-Method
,	O
covering	O
aspects	O
not	O
explored	O
by	O
related	O
work	O
.	O
	
We	O
report	O
the	O
summary	O
of	O
trained	O
models	O
(	O
corresponding	O
days	O
of	O
single	O
machine	B-Task
computation	I-Task
)	O
.	O
	
See	O
sections	O
[	O
reference	O
]	O
,	O
[	O
reference	O
]	O
and	O
[	O
reference	O
]	O
.	O
	
We	O
show	O
that	O
top	O
detection	B-Task
performance	O
can	O
be	O
reached	O
on	O
Caltech	B-Material
and	O
KITTI	B-Material
using	O
HOG	O
+	O
LUV	O
features	O
only	O
.	O
	
We	O
additionally	O
report	O
the	O
best	O
known	O
results	O
on	O
Caltech	B-Material
.	O
	
See	O
section	O
[	O
reference	O
]	O
.	O
	
section	O
:	O
Filtered	O
channel	O
features	O
	
Before	O
entering	O
the	O
experimental	O
section	O
,	O
let	O
us	O
describe	O
our	O
general	O
architecture	O
.	O
	
Methods	O
such	O
as	O
ChnFtrs	B-Method
,	O
SquaresChnFtrs	B-Method
and	O
ACF	B-Method
all	O
use	O
the	O
basic	O
architecture	O
depicted	O
in	O
figure	O
[	O
reference	O
]	O
top	O
part	O
(	O
best	O
viewed	O
in	O
colours	O
)	O
.	O
	
The	O
input	O
image	O
is	O
transformed	O
into	O
a	O
set	O
of	O
feature	O
channels	O
(	O
also	O
called	O
feature	O
maps	O
)	O
,	O
the	O
feature	O
vector	O
is	O
constructed	O
by	O
sum	B-Method
-	I-Method
pooling	I-Method
over	O
a	O
(	O
large	O
)	O
set	O
of	O
rectangular	O
regions	O
.	O
	
This	O
feature	O
vector	O
is	O
fed	O
into	O
a	O
decision	B-Method
forest	I-Method
learned	O
via	O
Adaboost	B-Method
.	O
	
The	O
split	O
nodes	O
in	O
the	O
trees	O
are	O
a	O
simple	O
comparison	O
between	O
a	O
feature	O
value	O
and	O
a	O
learned	O
threshold	O
.	O
	
Commonly	O
only	O
a	O
subset	O
of	O
the	O
feature	O
vector	O
is	O
used	O
by	O
the	O
learned	O
decision	B-Method
forest	I-Method
.	O
	
Adaboost	B-Method
serves	O
both	O
for	O
feature	B-Task
selection	I-Task
and	O
for	O
learning	O
the	O
thresholds	O
in	O
the	O
split	O
nodes	O
.	O
	
A	O
key	O
observation	O
,	O
illustrated	O
in	O
figure	O
[	O
reference	O
]	O
(	O
bottom	O
)	O
,	O
is	O
that	O
such	O
sum	B-Method
-	I-Method
pooling	I-Method
can	O
be	O
re	O
-	O
written	O
as	O
convolution	B-Method
with	O
a	O
filter	B-Method
bank	I-Method
(	O
one	O
filter	O
per	O
rectangular	O
shape	O
)	O
followed	O
by	O
reading	O
a	O
single	O
value	O
of	O
the	O
convolution	B-Method
’s	I-Method
response	I-Method
map	I-Method
.	O
	
This	O
‘	O
	
‘	O
filter	B-Method
+	I-Method
pick	I-Method
’	O
’	O
view	O
generalizes	O
the	O
integral	B-Method
channel	I-Method
features	I-Method
detectors	I-Method
by	O
allowing	O
to	O
use	O
any	O
filter	B-Method
bank	I-Method
(	O
instead	O
of	O
only	O
rectangular	O
shapes	O
)	O
.	O
	
We	O
name	O
this	O
generalization	O
	
‘	O
‘	O
filtered	B-Method
channel	I-Method
features	I-Method
detectors	I-Method
’	O
’	O
.	O
	
In	O
our	O
framework	O
,	O
ACF	B-Method
has	O
a	O
single	O
filter	B-Method
in	O
its	O
bank	O
,	O
corresponding	O
to	O
a	O
uniform	O
pooling	O
region	O
.	O
	
ChnFtrs	B-Method
was	O
a	O
very	O
large	O
(	O
tens	O
of	O
thousands	O
)	O
filter	B-Method
bank	I-Method
comprised	O
of	O
random	O
rectangular	O
shapes	O
.	O
	
SquaresChnFtrs	B-Method
,	O
on	O
the	O
other	O
hand	O
,	O
was	O
only	O
filters	O
,	O
each	O
with	O
a	O
square	O
-	O
shaped	O
uniform	O
pooling	O
region	O
of	O
different	O
sizes	O
.	O
	
See	O
figure	O
[	O
reference	O
]	O
for	O
an	O
illustration	O
of	O
the	O
SquaresChnFtrs	B-Method
filters	O
,	O
the	O
upper	O
-	O
left	O
filter	O
corresponds	O
to	O
ACF	O
’s	O
one	O
.	O
	
The	O
InformedHaar	B-Method
method	I-Method
can	O
also	O
be	O
seen	O
as	O
a	O
filtered	B-Method
channel	I-Method
features	I-Method
detector	I-Method
,	O
where	O
the	O
filter	B-Method
bank	I-Method
(	O
and	O
read	O
locations	O
)	O
are	O
based	O
on	O
a	O
human	O
shape	O
template	O
(	O
thus	O
the	O
	
‘	O
	
‘	O
informed	O
’	O
’	O
naming	O
)	O
.	O
	
LDCF	B-Method
is	O
also	O
a	O
particular	O
instance	O
of	O
this	O
framework	O
,	O
where	O
the	O
filter	B-Method
bank	I-Method
consists	O
of	O
PCA	B-Method
bases	I-Method
of	O
patches	O
from	O
the	O
training	O
dataset	O
.	O
	
In	O
sections	O
[	O
reference	O
]	O
and	O
[	O
reference	O
]	O
we	O
provide	O
experiments	O
revisiting	O
some	O
of	O
the	O
design	O
decisions	O
of	O
these	O
methods	O
.	O
	
Note	O
that	O
all	O
the	O
methods	O
mentioned	O
above	O
(	O
and	O
in	O
the	O
majority	O
of	O
experiments	O
below	O
)	O
use	O
only	O
HOG	O
+	O
LUV	O
feature	O
channels	O
(	O
10	O
channels	O
total	O
)	O
.	O
	
Using	O
linear	B-Method
filters	I-Method
and	O
decision	B-Method
trees	I-Method
on	O
top	O
of	O
these	O
does	O
not	O
allow	O
to	O
reconstruct	O
the	O
decision	O
functions	O
obtained	O
when	O
using	O
LBP	O
or	O
covariance	O
features	O
(	O
used	O
by	O
SpatialPooling	B-Method
and	I-Method
Regionlets	I-Method
)	O
.	O
	
We	O
thus	O
consider	O
the	O
approach	O
considered	O
here	O
orthogonal	O
to	O
adding	O
such	O
types	O
of	O
features	O
.	O
	
subsection	O
:	O
Evaluation	O
protocol	O
	
For	O
our	O
experiments	O
we	O
use	O
the	O
Caltech	B-Material
and	O
KITTI	B-Material
datasets	O
.	O
	
The	O
popular	O
INRIA	O
dataset	O
is	O
considered	O
too	O
small	O
and	O
too	O
close	O
to	O
saturation	O
to	O
provide	O
interesting	O
results	O
.	O
	
All	O
Caltech	B-Material
results	O
are	O
evaluated	O
using	O
the	O
provided	O
toolbox	O
,	O
and	O
summarised	O
by	O
log	B-Metric
-	I-Metric
average	I-Metric
miss	I-Metric
-	I-Metric
rate	I-Metric
(	O
MR	B-Metric
,	O
lower	O
is	O
better	O
)	O
in	O
the	O
range	O
for	O
the	O
‘	O
‘	O
reasonable	O
’	O
’	O
setup	O
.	O
	
KITTI	B-Material
results	O
are	O
evaluated	O
via	O
the	O
online	B-Metric
evaluation	I-Metric
portal	I-Metric
,	O
and	O
summarised	O
as	O
average	B-Metric
precision	I-Metric
(	O
AP	B-Metric
,	O
higher	O
is	O
better	O
)	O
for	O
the	O
‘	O
‘	O
moderate	O
’	O
’	O
setup	O
.	O
	
paragraph	O
:	O
Caltech10x	B-Material
	
The	O
raw	O
Caltech	B-Material
dataset	I-Material
consists	O
of	O
videos	O
(	O
acquired	O
at	O
)	O
with	O
every	O
frame	O
annotated	O
.	O
	
The	O
standard	O
training	O
and	O
evaluation	O
considers	O
one	O
out	O
of	O
each	O
frames	O
(	O
pedestrians	O
over	O
frames	O
in	O
training	O
,	O
pedestrians	O
over	O
frames	O
in	O
testing	O
)	O
.	O
	
In	O
our	O
experiments	O
of	O
section	O
[	O
reference	O
]	O
we	O
will	O
also	O
consider	O
a	O
increased	O
training	O
set	O
where	O
every	O
rd	O
frame	O
is	O
used	O
(	O
linear	O
growth	O
in	O
pedestrians	O
and	O
images	O
)	O
.	O
	
We	O
name	O
this	O
extended	O
training	O
set	O
	
‘	O
	
‘	O
Caltech10x	B-Material
’	O
’	O
.	O
	
LDCF	B-Method
uses	O
a	O
similar	O
extended	O
set	O
for	O
training	O
its	O
model	O
(	O
every	O
th	O
frame	O
)	O
.	O
	
paragraph	O
:	O
Flow	O
	
Methods	O
using	O
optical	B-Method
flow	I-Method
do	O
not	O
only	O
use	O
additional	O
neighbour	O
frames	O
during	O
training	O
(	O
depending	O
on	O
the	O
method	O
)	O
,	O
but	O
they	O
also	O
do	O
so	O
at	O
test	O
time	O
.	O
	
Because	O
they	O
have	O
access	O
to	O
additional	O
information	O
at	O
test	O
time	O
,	O
we	O
consider	O
them	O
as	O
a	O
separate	O
group	O
in	O
our	O
results	O
section	O
.	O
	
paragraph	O
:	O
Validation	O
set	O
	
In	O
order	O
to	O
explore	O
the	O
design	O
space	O
of	O
our	O
pedestrian	B-Method
detector	I-Method
we	O
setup	O
a	O
Caltech	B-Material
validation	I-Material
set	I-Material
by	O
splitting	O
the	O
six	O
training	O
videos	O
into	O
five	O
for	O
training	O
and	O
one	O
for	O
testing	O
(	O
one	O
of	O
the	O
splits	O
suggested	O
in	O
)	O
.	O
	
Most	O
of	O
our	O
experiments	O
use	O
this	O
validation	O
setup	O
.	O
	
We	O
also	O
report	O
(	O
a	O
posteriori	O
)	O
our	O
key	O
results	O
on	O
the	O
standard	O
test	O
set	O
for	O
comparison	O
to	O
the	O
state	O
of	O
the	O
art	O
.	O
	
For	O
the	O
KITTI	B-Material
experiments	O
we	O
also	O
validate	O
some	O
design	O
choices	O
(	O
such	O
as	O
search	O
range	O
and	O
number	O
of	O
scales	O
)	O
before	O
submission	O
on	O
the	O
evaluation	O
server	O
.	O
	
There	O
we	O
use	O
a	O
validation	O
setup	O
.	O
	
subsection	O
:	O
Baselines	O
	
paragraph	O
:	O
ACF	O
	
Our	O
experiments	O
are	O
based	O
on	O
the	O
open	O
source	O
release	O
of	O
ACF	B-Method
.	O
	
Our	O
first	O
baseline	O
is	O
vanilla	B-Method
ACF	I-Method
re	I-Method
-	I-Method
trained	I-Method
on	O
the	O
standard	O
Caltech	B-Material
set	I-Material
(	O
not	O
Caltech10x	B-Material
)	O
.	O
	
On	O
the	O
Caltech	B-Material
test	I-Material
set	I-Material
it	O
obtains	O
(	O
on	O
validation	O
set	O
)	O
.	O
	
Note	O
that	O
this	O
baseline	O
already	O
improves	O
over	O
more	O
than	O
previously	O
published	O
methods	O
on	O
this	O
dataset	O
.	O
	
There	O
is	O
also	O
a	O
large	O
gap	O
between	O
ACF	O
-	O
Ours	O
(	O
)	O
and	O
the	O
original	O
number	O
from	O
ACF	O
-	O
Caltech	B-Material
(	O
)	O
.	O
	
The	O
improvement	O
is	O
mainly	O
due	O
to	O
the	O
change	O
towards	O
a	O
larger	O
model	O
size	O
(	O
from	O
to	O
)	O
.	O
	
All	O
parameter	O
details	O
are	O
described	O
in	O
section	O
[	O
reference	O
]	O
,	O
and	O
kept	O
identical	O
across	O
experiments	O
unless	O
explicitly	O
stated	O
.	O
	
paragraph	O
:	O
InformedHaar	O
	
Our	O
second	O
baseline	O
is	O
a	O
re	O
-	O
implementation	O
of	O
InformedHaar	B-Method
.	O
	
Here	O
again	O
we	O
observe	O
an	O
important	O
gain	O
from	O
using	O
a	O
larger	O
model	O
size	O
(	O
same	O
change	O
as	O
for	O
ACF	B-Method
)	O
.	O
	
While	O
the	O
original	O
InformedHaar	O
paper	O
reports	O
,	O
	
InformedHaar	B-Method
-	I-Method
Ours	I-Method
reaches	O
on	O
the	O
Caltech	B-Material
test	I-Material
set	I-Material
(	O
on	O
validation	O
set	O
)	O
.	O
	
For	O
both	O
our	O
baselines	O
we	O
use	O
exactly	O
the	O
same	O
training	O
set	O
as	O
the	O
original	O
papers	O
.	O
	
Note	O
that	O
the	O
InformedHaar	B-Method
-	I-Method
Ours	I-Method
baseline	I-Method
(	O
)	O
is	O
right	O
away	O
the	O
best	O
known	O
result	O
for	O
a	O
method	O
trained	O
on	O
the	O
standard	O
Caltech	B-Material
training	I-Material
set	I-Material
.	O
	
In	O
section	O
[	O
reference	O
]	O
we	O
will	O
discuss	O
our	O
re	O
-	O
implementation	O
of	O
LDCF	B-Method
.	O
	
subsection	O
:	O
Model	O
parameters	O
	
Unless	O
otherwise	O
specified	O
we	O
train	O
all	O
our	O
models	O
using	O
the	O
following	O
parameters	O
.	O
	
Feature	O
channels	O
are	O
HOG	B-Method
+	I-Method
LUV	I-Method
only	O
.	O
	
The	O
final	O
classifier	B-Method
includes	O
level	B-Method
-	I-Method
2	I-Method
decision	I-Method
trees	I-Method
(	O
L2	O
,	O
3	O
stumps	O
per	O
tree	O
)	O
,	O
trained	O
via	O
vanilla	B-Method
discrete	I-Method
Adaboost	I-Method
.	O
	
Each	O
tree	O
is	O
built	O
by	O
doing	O
exhaustive	B-Method
greedy	I-Method
search	I-Method
for	O
each	O
node	O
(	O
no	O
randomization	O
)	O
.	O
	
The	O
model	O
has	O
size	O
,	O
and	O
is	O
built	O
via	O
four	O
rounds	O
of	O
hard	B-Method
negative	I-Method
mining	I-Method
(	O
starting	O
from	O
a	O
model	O
with	O
trees	O
,	O
and	O
then	O
,	O
,	O
,	O
trees	O
)	O
.	O
	
Each	O
round	O
adds	O
additional	O
negatives	O
to	O
the	O
training	O
set	O
.	O
	
The	O
sliding	O
window	O
stride	O
is	O
(	O
both	O
during	O
hard	B-Task
negative	I-Task
mining	I-Task
and	O
at	O
test	O
time	O
)	O
.	O
	
Compared	O
to	O
the	O
default	O
ACF	O
parameters	O
,	O
we	O
use	O
a	O
bigger	O
model	O
,	O
more	O
trees	O
,	O
more	O
negative	O
samples	O
,	O
and	O
more	O
boosting	O
rounds	O
.	O
	
But	O
we	O
do	O
use	O
the	O
same	O
code	O
-	O
base	O
and	O
the	O
same	O
training	O
set	O
.	O
	
Starting	O
from	O
section	O
[	O
reference	O
]	O
we	O
will	O
also	O
consider	O
results	O
with	O
the	O
Caltech10x	B-Material
data	O
,	O
there	O
we	O
use	O
level	B-Method
-	I-Method
4	I-Method
decision	I-Method
trees	I-Method
(	O
L4	O
)	O
,	O
and	O
Realboost	B-Method
instead	O
of	O
discrete	B-Method
Adaboost	I-Method
.	O
	
All	O
other	O
parameters	O
are	O
left	O
unchanged	O
.	O
	
section	O
:	O
Filter	B-Method
bank	I-Method
families	I-Method
	
Given	O
the	O
general	O
architecture	O
and	O
the	O
baselines	O
described	O
in	O
section	O
[	O
reference	O
]	O
,	O
we	O
now	O
proceed	O
to	O
explore	O
different	O
types	O
of	O
filter	B-Method
banks	I-Method
.	O
	
Some	O
of	O
them	O
are	O
designed	O
using	O
prior	O
knowledge	O
and	O
they	O
do	O
not	O
change	O
when	O
applied	O
across	O
datasets	O
,	O
others	O
exploit	O
data	B-Method
-	I-Method
driven	I-Method
techniques	I-Method
for	O
learning	O
their	O
filters	O
.	O
	
Sections	O
[	O
reference	O
]	O
and	O
[	O
reference	O
]	O
will	O
compare	O
their	O
detection	B-Metric
quality	I-Metric
.	O
	
paragraph	O
:	O
InformedFilters	O
	
Starting	O
from	O
the	O
InformedHaar	B-Method
baseline	I-Method
we	O
use	O
the	O
same	O
‘	O
‘	O
informed	O
’	O
’	O
filters	O
but	O
let	O
free	O
the	O
positions	O
where	O
they	O
are	O
applied	O
(	O
instead	O
of	O
fixed	O
in	O
InformedHaar	O
)	O
;	O
these	O
are	O
selected	O
during	O
the	O
boosting	B-Method
learning	I-Method
.	O
	
Our	O
initial	O
experiments	O
show	O
that	O
removing	O
the	O
position	O
constraint	O
has	O
a	O
small	O
(	O
positive	O
)	O
effect	O
.	O
	
Additionally	O
we	O
observe	O
that	O
the	O
original	O
InformedHaar	B-Method
filters	I-Method
do	O
not	O
include	O
simple	O
square	O
pooling	O
regions	O
(	O
à	O
la	O
SquaresChnFtrs	B-Method
)	O
,	O
we	O
thus	O
add	O
these	O
too	O
.	O
	
We	O
end	O
up	O
with	O
filters	O
in	O
total	O
,	O
to	O
be	O
applied	O
over	O
each	O
of	O
the	O
feature	O
channels	O
.	O
	
This	O
is	O
equivalent	O
to	O
training	O
decision	B-Method
trees	I-Method
over	O
(	O
non	O
filtered	O
)	O
channel	O
features	O
.	O
	
As	O
illustrated	O
in	O
figure	O
[	O
reference	O
]	O
the	O
InformedFilters	O
have	O
different	O
sizes	O
,	O
from	O
to	O
cells	O
(	O
)	O
,	O
and	O
each	O
cell	O
takes	O
a	O
value	O
in	O
.	O
	
These	O
filters	O
are	O
applied	O
with	O
a	O
step	O
size	O
of	O
.	O
	
For	O
a	O
model	O
of	O
this	O
results	O
in	O
features	O
per	O
channel	O
,	O
features	O
in	O
total	O
.	O
	
In	O
practice	O
considering	O
border	O
effects	O
(	O
large	O
filters	O
are	O
not	O
applied	O
on	O
the	O
border	O
of	O
the	O
model	O
to	O
avoid	O
reading	O
outside	O
it	O
)	O
	
we	O
end	O
up	O
with	O
features	O
.	O
	
When	O
training	O
level	O
-	O
2	O
decision	B-Method
trees	I-Method
,	O
at	O
most	O
features	O
will	O
be	O
used	O
,	O
that	O
is	O
of	O
the	O
total	O
.	O
	
In	O
this	O
scenario	O
(	O
and	O
all	O
others	O
considered	O
in	O
this	O
paper	O
)	O
Adaboost	B-Method
has	O
a	O
strong	O
role	O
of	O
feature	B-Task
selection	I-Task
.	O
	
paragraph	O
:	O
Checkerboards	O
	
As	O
seen	O
in	O
section	O
[	O
reference	O
]	O
InformedHaar	B-Method
is	O
a	O
strong	O
baseline	O
.	O
	
It	O
is	O
however	O
unclear	O
how	O
much	O
the	O
	
‘	O
‘	O
informed	O
’	O
’	O
design	O
of	O
the	O
filters	O
is	O
effective	O
compared	O
to	O
other	O
possible	O
choices	O
.	O
	
Checkerboards	B-Method
is	O
a	O
naïve	O
set	O
of	O
filters	B-Method
that	O
covers	O
the	O
same	O
sizes	O
(	O
in	O
number	O
of	O
cells	O
)	O
as	O
InformedHaar	O
/	O
InformedFilters	O
and	O
for	O
each	O
size	O
defines	O
(	O
see	O
figure	O
[	O
reference	O
]	O
)	O
:	O
	
a	O
uniform	O
square	O
,	O
all	O
horizontal	O
and	O
vertical	O
gradient	O
detectors	O
(	O
values	O
)	O
,	O
and	O
all	O
possible	O
checkerboard	O
patterns	O
.	O
	
These	O
configurations	O
are	O
comparable	O
to	O
InformedFilters	B-Method
but	O
do	O
not	O
use	O
the	O
human	O
shape	O
as	O
prior	O
.	O
	
The	O
total	O
number	O
of	O
filters	O
is	O
a	O
direct	O
function	O
of	O
the	O
maximum	O
size	O
selected	O
.	O
	
For	O
up	O
to	O
cells	O
we	O
end	O
up	O
with	O
filters	O
,	O
up	O
to	O
cells	O
filters	O
,	O
up	O
to	O
cells	O
filters	O
,	O
and	O
up	O
to	O
cells	O
filters	O
.	O
	
paragraph	O
:	O
RandomFilters	O
	
Our	O
next	O
step	O
towards	O
removing	O
a	O
hand	B-Method
-	I-Method
crafted	I-Method
design	I-Method
is	O
simply	O
using	O
random	B-Method
filters	I-Method
(	O
see	O
figure	O
[	O
reference	O
]	O
)	O
.	O
	
Given	O
a	O
desired	O
number	O
of	O
filters	O
and	O
a	O
maximum	O
filter	O
size	O
(	O
in	O
cells	O
)	O
,	O
we	O
sample	O
the	O
filter	O
size	O
with	O
uniform	O
distribution	O
,	O
and	O
set	O
its	O
cell	O
values	O
to	O
with	O
uniform	O
probability	O
.	O
	
We	O
also	O
experimented	O
with	O
values	O
and	O
observed	O
a	O
(	O
small	O
)	O
quality	O
decrease	O
compared	O
to	O
the	O
binary	O
option	O
)	O
.	O
	
The	O
design	O
of	O
the	O
filters	O
considered	O
above	O
completely	O
ignores	O
the	O
available	O
training	O
data	O
.	O
	
In	O
the	O
following	O
,	O
we	O
consider	O
additional	O
filters	B-Method
learned	O
from	O
data	O
.	O
	
paragraph	O
:	O
LDCF	B-Method
	
The	O
work	O
on	O
PCANet	B-Method
showed	O
that	O
applying	O
arbitrary	O
non	O
-	O
linearities	O
on	O
top	O
of	O
PCA	B-Method
projections	I-Method
of	I-Method
image	I-Method
patches	I-Method
can	O
be	O
surprisingly	O
effective	O
for	O
image	B-Task
classification	I-Task
.	O
	
Following	O
this	O
intuition	O
LDCF	B-Method
uses	O
learned	O
PCA	O
eigenvectors	O
as	O
filters	O
(	O
see	O
figure	O
[	O
reference	O
]	O
)	O
.	O
	
We	O
present	O
a	O
re	O
-	O
implementation	O
of	O
based	O
on	O
ACF	B-Method
’s	I-Method
source	I-Method
code	I-Method
.	O
	
We	O
try	O
to	O
follow	O
the	O
original	O
description	O
as	O
closely	O
as	O
possible	O
.	O
	
We	O
use	O
the	O
same	O
top	O
filters	O
of	O
,	O
selected	O
per	O
feature	O
channel	O
based	O
on	O
their	O
eigenvalues	O
(	O
filters	O
total	O
)	O
.	O
	
We	O
do	O
change	O
some	O
parameters	O
to	O
be	O
consistent	O
amongst	O
all	O
experiments	O
,	O
see	O
sections	O
[	O
reference	O
]	O
and	O
[	O
reference	O
]	O
.	O
	
The	O
main	O
changes	O
are	O
the	O
training	O
set	O
(	O
we	O
use	O
Caltech10x	B-Material
,	O
sampled	O
every	O
3	O
frames	O
,	O
instead	O
of	O
every	O
4	O
frames	O
in	O
)	O
,	O
and	O
the	O
model	O
size	O
(	O
pixels	O
instead	O
of	O
)	O
.	O
	
As	O
will	O
be	O
shown	O
in	O
section	O
[	O
reference	O
]	O
,	O
our	O
implementation	O
(	O
LDCF	B-Method
-	I-Method
Ours	I-Method
)	O
clearly	O
improves	O
over	O
the	O
previously	O
published	O
numbers	O
,	O
showing	O
the	O
potential	O
of	O
the	O
method	O
.	O
	
For	O
comparison	O
with	O
PcaForeground	B-Method
we	O
also	O
consider	O
training	O
LDCF8	B-Method
where	O
the	O
top	O
filters	O
are	O
selected	O
per	O
channel	O
(	O
filters	O
total	O
)	O
.	O
	
paragraph	O
:	O
PcaForeground	B-Method
	
In	O
LDCF	B-Method
the	O
filters	O
are	O
learned	O
using	O
all	O
of	O
the	O
training	O
data	O
available	O
.	O
	
In	O
practice	O
this	O
means	O
that	O
the	O
learned	O
filters	B-Method
will	O
be	O
dominated	O
by	O
background	O
information	O
,	O
and	O
will	O
have	O
minimal	O
information	O
about	O
the	O
pedestrians	O
.	O
	
Put	O
differently	O
,	O
learning	B-Method
filters	I-Method
from	O
all	O
the	O
data	O
assumes	O
that	O
the	O
decision	O
boundary	O
is	O
defined	O
by	O
a	O
single	O
distribution	O
(	O
like	O
in	O
Linear	B-Method
Discriminant	I-Method
Analysis	I-Method
)	O
,	O
while	O
we	O
might	O
want	O
to	O
define	O
it	O
based	O
on	O
the	O
relation	O
between	O
the	O
background	O
distribution	O
and	O
the	O
foreground	O
distribution	O
(	O
like	O
Fisher	B-Method
’s	I-Method
Discriminant	I-Method
Analysis	I-Method
)	O
.	O
	
In	O
PcaForeground	B-Method
we	O
train	O
filters	B-Method
per	O
feature	O
channel	O
,	O
learned	O
from	O
background	O
image	O
patches	O
,	O
and	O
learned	O
from	O
patches	O
extracted	O
over	O
pedestrians	O
(	O
see	O
figure	O
[	O
reference	O
]	O
)	O
.	O
	
Compared	O
to	O
LDCF8	B-Method
the	O
obtained	O
filters	O
are	O
similar	O
but	O
not	O
identical	O
,	O
all	O
other	O
parameters	O
are	O
kept	O
identical	O
.	O
	
Other	O
than	O
via	O
PcaForeground	B-Method
/	I-Method
LDCF8	I-Method
,	O
it	O
is	O
not	O
clear	O
how	O
to	O
further	O
increase	O
the	O
number	O
of	O
filters	O
used	O
in	O
LDCF	B-Method
.	O
	
Past	O
filters	O
per	O
channel	O
,	O
the	O
eigenvalues	O
decrease	O
to	O
negligible	O
values	O
and	O
the	O
eigenvectors	O
become	O
essentially	O
random	O
(	O
similar	O
to	O
RandomFilters	O
)	O
.	O
	
To	O
keep	O
the	O
filtered	O
channel	O
features	O
setup	O
close	O
to	O
InformedHaar	O
,	O
the	O
filters	O
are	O
applied	O
with	O
a	O
step	O
of	O
However	O
,	O
to	O
stay	O
close	O
to	O
the	O
original	O
LDCF	B-Method
,	O
the	O
LDCF	B-Method
/	I-Method
PcaForeground	I-Method
filters	I-Method
are	O
evaluated	O
every	O
.	O
	
Although	O
(	O
for	O
example	O
)	O
LDCF8	B-Method
uses	O
only	O
of	O
the	O
number	O
of	O
filters	O
per	O
channel	O
compared	O
to	O
Checkerboards4x4	O
,	O
due	O
to	O
the	O
step	O
size	O
increase	O
,	O
the	O
obtained	O
feature	B-Metric
vector	I-Metric
size	I-Metric
is	O
.	O
	
section	O
:	O
How	O
many	O
filters	O
?	O
	
Given	O
a	O
fixed	O
set	O
of	O
channel	O
features	O
,	O
a	O
larger	O
filter	B-Method
bank	I-Method
provides	O
a	O
richer	O
view	O
over	O
the	O
data	O
compared	O
to	O
a	O
smaller	O
one	O
.	O
	
With	O
enough	O
training	O
data	O
one	O
would	O
expect	O
larger	O
filter	B-Method
banks	I-Method
to	O
perform	O
best	O
.	O
	
We	O
want	O
thus	O
to	O
analyze	O
the	O
trade	O
-	O
off	O
between	O
number	O
of	O
filters	O
and	O
detection	B-Metric
quality	I-Metric
,	O
as	O
well	O
as	O
which	O
filter	B-Method
bank	I-Method
family	I-Method
performs	O
best	O
.	O
	
Figure	O
[	O
reference	O
]	O
presents	O
the	O
results	O
of	O
our	O
initial	O
experiments	O
on	O
the	O
Caltech	B-Material
validation	I-Material
set	I-Material
.	O
	
It	O
shows	O
detection	B-Metric
quality	I-Metric
versus	O
number	O
of	O
filters	O
per	O
channel	O
.	O
	
This	O
figure	O
densely	O
summarizes	O
trained	O
models	O
.	O
	
paragraph	O
:	O
InformedFilters	O
	
The	O
first	O
aspect	O
to	O
notice	O
is	O
that	O
there	O
is	O
a	O
meaningful	O
gap	O
between	O
InformedHaar	B-Method
-	I-Method
Ours	I-Method
and	O
InformedFilters	B-Method
despite	O
having	O
a	O
similar	O
number	O
of	O
filters	O
(	O
versus	O
)	O
.	O
	
This	O
validates	O
the	O
importance	O
of	O
letting	O
Adaboost	B-Method
choose	O
the	O
pooling	O
locations	O
instead	O
of	O
hand	O
-	O
crafting	O
them	O
.	O
	
Keep	O
in	O
mind	O
that	O
InformedHaar	B-Method
-	I-Method
Ours	I-Method
is	O
a	O
top	O
performing	O
baseline	O
(	O
see	O
§	O
[	O
reference	O
]	O
)	O
.	O
	
Secondly	O
,	O
we	O
observe	O
that	O
(	O
for	O
the	O
fixed	O
training	O
data	O
available	O
)	O
filters	B-Method
is	O
better	O
than	O
.	O
	
Below	O
filters	O
the	O
performance	O
degrades	O
for	O
all	O
methods	O
(	O
as	O
expected	O
)	O
.	O
	
To	O
change	O
the	O
number	O
of	O
filters	O
in	O
InformedFilters	O
we	O
train	O
a	O
full	B-Method
model	I-Method
(	O
filters	B-Method
)	O
,	O
pick	O
the	O
most	O
frequently	O
used	O
filters	O
(	O
selected	O
from	O
node	O
splitting	O
in	O
the	O
decision	O
forest	O
)	O
,	O
and	O
use	O
these	O
to	O
train	O
the	O
desired	O
reduced	B-Method
model	I-Method
.	O
	
We	O
can	O
select	O
the	O
most	O
frequent	O
filters	O
across	O
channels	O
or	O
per	O
channel	O
(	O
marked	O
as	O
Inf	O
.	O
FiltersPerChannel	O
)	O
.	O
	
We	O
observe	O
that	O
per	B-Task
channel	I-Task
selection	I-Task
is	O
slightly	O
worse	O
than	O
across	O
channels	O
,	O
thus	O
we	O
stick	O
to	O
the	O
latter	O
.	O
	
Using	O
the	O
most	O
frequently	O
used	O
filters	O
for	O
selection	B-Task
is	O
clearly	O
a	O
crude	O
strategy	O
since	O
frequent	O
usage	O
does	O
not	O
guarantee	O
discriminative	O
power	O
,	O
and	O
it	O
ignores	O
relation	O
amongst	O
filters	O
.	O
	
We	O
find	O
this	O
strategy	O
good	O
enough	O
to	O
convey	O
the	O
main	O
points	O
of	O
this	O
work	O
.	O
	
paragraph	O
:	O
Checkerboards	O
	
also	O
reaches	O
best	O
results	O
in	O
the	O
filters	O
region	O
.	O
	
Here	O
the	O
number	O
of	O
filters	O
is	O
varied	O
by	O
changing	O
the	O
maximum	O
filter	O
size	O
(	O
in	O
number	O
of	O
cells	O
)	O
.	O
	
Regarding	O
the	O
lowest	O
miss	B-Metric
-	I-Metric
rate	I-Metric
there	O
is	O
no	O
large	O
gap	O
between	O
the	O
‘	O
‘	O
informed	O
’	O
’	O
filters	O
and	O
this	O
naïve	O
baseline	O
.	O
	
paragraph	O
:	O
RandomFilters	O
	
The	O
hexagonal	O
dots	O
and	O
their	O
deviation	O
bars	O
indicate	O
the	O
mean	O
,	O
maximum	O
and	O
minimum	B-Metric
miss	I-Metric
-	I-Metric
rate	I-Metric
obtained	O
out	O
of	O
five	O
random	O
runs	O
.	O
	
When	O
using	O
a	O
larger	O
number	O
of	O
filters	O
(	O
)	O
we	O
observe	O
a	O
lower	O
(	O
better	O
)	O
mean	O
but	O
a	O
larger	O
variance	O
compared	O
to	O
when	O
using	O
fewer	O
filters	O
(	O
)	O
.	O
	
Here	O
again	O
the	O
gap	O
between	O
the	O
best	O
random	O
run	O
and	O
the	O
best	O
result	O
of	O
other	O
methods	O
is	O
not	O
large	O
.	O
	
Given	O
a	O
set	O
of	O
five	O
models	O
,	O
we	O
select	O
the	O
most	O
frequently	O
used	O
filters	O
and	O
train	O
new	O
reduced	B-Method
models	I-Method
;	O
these	O
are	O
shown	O
in	O
the	O
RandomFilters	O
line	O
.	O
	
Overall	O
the	O
random	B-Method
filters	I-Method
are	O
surprisingly	O
close	O
to	O
the	O
other	O
filter	B-Method
families	I-Method
.	O
	
This	O
indicates	O
that	O
expanding	O
the	O
feature	O
channels	O
via	O
filtering	B-Method
is	O
the	O
key	O
step	O
for	O
improving	O
detection	B-Metric
quality	I-Metric
,	O
while	O
selecting	O
the	O
‘	O
‘	O
perfect	O
’	O
’	O
filters	O
is	O
a	O
secondary	O
concern	O
.	O
	
paragraph	O
:	O
LDCF	B-Method
/	O
PcaForeground	B-Method
	
In	O
contrast	O
to	O
the	O
other	O
filter	B-Method
bank	I-Method
families	I-Method
,	O
LDCF	B-Method
under	O
-	O
performs	O
when	O
increasing	O
the	O
number	O
of	O
filters	O
(	O
from	O
to	O
)	O
while	O
using	O
the	O
standard	O
Caltech	B-Material
training	I-Material
set	I-Material
(	O
consistent	O
with	O
the	O
observations	O
in	O
)	O
.	O
	
PcaForeground	B-Method
improves	O
marginally	O
over	O
LDCF8	B-Method
.	O
	
paragraph	O
:	O
Takeaways	O
	
From	O
figure	O
[	O
reference	O
]	O
we	O
observe	O
two	O
overall	O
trends	O
.	O
	
First	O
,	O
the	O
more	O
filters	O
the	O
merrier	O
,	O
with	O
filters	B-Method
as	O
sweet	O
spot	O
for	O
Caltech	B-Material
training	I-Material
data	I-Material
.	O
	
Second	O
,	O
there	O
is	O
no	O
flagrant	O
difference	O
between	O
the	O
different	O
filter	O
types	O
.	O
	
section	O
:	O
Additional	O
training	O
data	O
	
One	O
caveat	O
of	O
the	O
previous	O
experiments	O
is	O
that	O
as	O
we	O
increase	O
the	O
number	O
of	O
filters	O
used	O
,	O
so	O
does	O
the	O
number	O
of	O
features	O
Adaboost	O
must	O
pick	O
from	O
.	O
	
Since	O
we	O
increased	O
the	O
model	O
capacity	O
(	O
compared	O
to	O
ACF	B-Method
which	O
uses	O
a	O
single	O
filter	B-Method
)	O
,	O
we	O
consider	O
using	O
the	O
Caltech10x	B-Material
dataset	O
(	O
§	O
[	O
reference	O
]	O
)	O
to	O
verify	O
that	O
our	O
models	O
are	O
not	O
starving	O
for	O
data	O
.	O
	
Similar	O
to	O
the	O
experiments	O
in	O
,	O
we	O
also	O
reconsider	O
the	O
decision	O
tree	O
depth	O
,	O
since	O
additional	O
training	O
data	O
enables	O
bigger	O
models	O
.	O
	
Results	O
for	O
two	O
representative	O
methods	O
are	O
collected	O
in	O
table	O
[	O
reference	O
]	O
.	O
	
First	O
we	O
observe	O
that	O
already	O
with	O
the	O
original	O
training	O
data	O
,	O
deeper	O
trees	O
do	O
provide	O
significant	O
improvement	O
over	O
level	O
-	O
2	O
(	O
which	O
was	O
selected	O
when	O
tuning	O
over	O
INRIA	O
data	O
)	O
.	O
	
Second	O
,	O
we	O
notice	O
that	O
increasing	O
the	O
training	O
data	O
volume	O
does	O
provide	O
the	O
expected	O
improvement	O
only	O
when	O
the	O
decision	O
trees	O
are	O
deep	O
enough	O
.	O
	
For	O
our	O
following	O
experiments	O
we	O
choose	O
to	O
use	O
level	B-Method
-	I-Method
4	I-Method
decision	I-Method
trees	I-Method
(	O
)	O
as	O
a	O
good	O
balance	O
between	O
increased	O
detection	B-Metric
quality	I-Metric
and	O
reasonable	O
training	B-Metric
times	I-Metric
.	O
	
paragraph	O
:	O
Realboost	O
	
Although	O
previous	O
papers	O
on	O
ChnFtrs	B-Task
detectors	I-Task
reported	O
that	O
different	O
boosting	B-Method
variants	I-Method
all	O
obtain	O
equal	O
results	O
on	O
this	O
task	O
,	O
the	O
recent	O
indicated	O
that	O
Realboost	B-Method
has	O
an	O
edge	O
over	O
discrete	B-Method
Adaboost	I-Method
when	O
additional	O
training	O
data	O
is	O
used	O
.	O
	
We	O
observe	O
the	O
same	O
behaviour	O
in	O
our	O
Caltech10x	B-Material
setup	I-Material
.	O
	
As	O
summarized	O
in	O
table	O
[	O
reference	O
]	O
using	O
filtered	O
channels	O
,	O
deeper	O
trees	O
,	O
additional	O
training	O
data	O
,	O
and	O
Realboost	B-Method
does	O
provide	O
a	O
significant	O
detection	B-Metric
quality	I-Metric
boost	I-Metric
.	O
	
For	O
the	O
rest	O
of	O
the	O
paper	O
our	O
models	O
trained	O
on	O
Caltech10x	B-Material
all	O
use	O
level	O
-	O
4	O
trees	O
and	O
RealBoost	B-Method
,	O
instead	O
of	O
level	B-Method
-	I-Method
2	I-Method
and	I-Method
discrete	I-Method
Adaboost	I-Method
for	O
the	O
Caltech1x	B-Method
models	I-Method
.	O
	
paragraph	O
:	O
Timing	O
	
When	O
using	O
Caltech	B-Material
data	I-Material
ACF	O
takes	O
about	O
one	O
hour	O
for	O
training	O
and	O
one	O
for	O
testing	O
.	O
	
Checkerboards4x4	B-Method
takes	O
about	O
and	O
hours	O
respectively	O
.	O
	
When	O
using	O
Caltech10x	B-Material
the	O
training	B-Metric
times	I-Metric
for	O
these	O
methods	O
augment	O
to	O
2	O
and	O
29	O
hours	O
,	O
respectively	O
.	O
	
The	O
training	B-Metric
time	I-Metric
does	O
not	O
increase	O
proportionally	O
with	O
the	O
training	O
data	O
volume	O
because	O
the	O
hard	B-Method
negative	I-Method
mining	I-Method
reads	O
a	O
variable	O
amount	O
of	O
images	O
to	O
attain	O
the	O
desired	O
quota	O
of	O
negative	O
samples	O
.	O
	
This	O
amount	O
increases	O
when	O
a	O
detector	O
has	O
less	O
false	O
positive	O
mistakes	O
.	O
	
subsection	O
:	O
Validation	O
set	O
experiments	O
	
Based	O
on	O
the	O
results	O
in	O
table	O
[	O
reference	O
]	O
we	O
proceed	O
to	O
evaluate	O
on	O
Caltech10x	B-Material
the	O
most	O
promising	O
configurations	O
(	O
filter	O
type	O
and	O
number	O
)	O
from	O
section	O
[	O
reference	O
]	O
.	O
	
The	O
results	O
over	O
the	O
Caltech	B-Material
validation	I-Material
set	I-Material
are	O
collected	O
in	O
table	O
[	O
reference	O
]	O
.	O
	
We	O
observe	O
a	O
clear	O
overall	O
gain	O
from	O
increasing	O
the	O
training	O
data	O
.	O
	
Interestingly	O
with	O
enough	O
RandomFilters	O
we	O
can	O
outperform	O
the	O
strong	O
performance	O
of	O
LDCF	B-Method
-	I-Method
Ours	I-Method
.	O
	
We	O
also	O
notice	O
that	O
the	O
naïve	O
Checkerboards	B-Method
outperforms	O
the	O
manual	B-Method
design	I-Method
of	I-Method
InformedFilters	I-Method
.	O
	
section	O
:	O
Add	O
-	O
ons	O
	
Before	O
presenting	O
the	O
final	O
test	O
set	O
results	O
of	O
our	O
‘	O
‘	O
core	O
’	O
’	O
method	O
(	O
section	O
[	O
reference	O
]	O
)	O
,	O
we	O
also	O
consider	O
some	O
possible	O
	
‘	O
	
‘	O
add	O
-	O
ons	O
’	O
’	O
based	O
on	O
the	O
suggestions	O
from	O
.	O
	
For	O
the	O
sake	O
of	O
evaluating	O
complementarity	B-Task
,	O
comparison	O
with	O
existing	O
method	O
,	O
and	O
reporting	O
the	O
best	O
possible	O
detection	B-Metric
quality	I-Metric
,	O
we	O
consider	O
extending	O
our	O
detector	O
with	O
context	O
and	O
optical	O
flow	O
information	O
.	O
	
paragraph	O
:	O
Context	O
	
Context	O
is	O
modelled	O
via	O
the	O
2Ped	B-Method
re	I-Method
-	I-Method
scoring	I-Method
method	I-Method
of	O
.	O
	
It	O
is	O
a	O
post	O
-	O
processing	O
step	O
that	O
merges	O
our	O
detection	B-Metric
scores	I-Metric
with	O
the	O
results	O
of	O
a	O
two	B-Method
person	I-Method
DPM	I-Method
trained	O
on	O
the	O
INRIA	O
dataset	O
(	O
with	O
extended	O
annotations	O
)	O
.	O
	
In	O
the	O
authors	O
reported	O
an	O
improvement	O
of	O
(	O
percent	O
points	O
)	O
on	O
the	O
Caltech	B-Material
set	I-Material
,	O
across	O
different	O
methods	O
.	O
	
In	O
an	O
improvement	O
of	O
is	O
reported	O
over	O
their	O
strong	O
detector	B-Method
(	O
SquaresChnFtrs	B-Method
+	O
DCT	B-Method
+	O
SDt	B-Method
)	O
.	O
	
In	O
our	O
experiments	O
however	O
we	O
obtain	O
a	O
gain	O
inferior	O
to	O
.	O
	
We	O
have	O
also	O
investigated	O
fusing	O
the	O
2Ped	B-Task
detection	I-Task
results	O
via	O
a	O
different	O
,	O
more	O
principled	O
,	O
fusion	B-Method
method	I-Method
.	O
	
We	O
observe	O
consistent	O
results	O
:	O
as	O
the	O
strength	O
of	O
the	O
starting	O
point	O
increases	O
,	O
the	O
gain	O
from	O
2Ped	O
decreases	O
.	O
	
When	O
reaching	O
our	O
Checkerboards	O
results	O
,	O
all	O
gains	O
have	O
evaporated	O
.	O
	
We	O
believe	O
that	O
the	O
2Ped	B-Method
approach	I-Method
is	O
a	O
promising	O
one	O
,	O
but	O
our	O
experiments	O
indicate	O
that	O
the	O
used	O
DPM	B-Method
template	I-Method
is	O
simply	O
too	O
weak	O
in	O
comparison	O
to	O
our	O
filtered	O
channels	O
.	O
	
paragraph	O
:	O
Optical	B-Method
flow	I-Method
	
Optical	O
flow	O
is	O
fed	O
to	O
our	O
detector	O
as	O
an	O
additional	O
set	O
of	O
channels	O
(	O
not	O
filtered	O
)	O
.	O
	
We	O
use	O
the	O
implementation	O
from	O
SDt	B-Method
which	O
uses	O
differences	O
of	O
weakly	O
stabilized	O
video	O
frames	O
.	O
	
On	O
Caltech	B-Material
,	O
the	O
authors	O
of	O
reported	O
a	O
gain	O
over	O
ACF	B-Method
(	O
)	O
,	O
while	O
reported	O
a	O
percent	O
points	O
improvement	O
over	O
their	O
strong	O
baseline	O
(	O
SquaresChnFtrs	B-Method
+	O
DCT	B-Method
+	O
2Ped	O
⁢%27.4MR	O
)	O
.	O
	
When	O
using	O
+	O
SDt	B-Method
our	O
results	O
are	O
directly	O
comparable	O
to	O
Katamari	B-Method
and	O
SpatialPooling	B-Method
+	I-Method
which	O
both	O
use	O
optical	O
flow	O
too	O
.	O
	
Using	O
our	O
stronger	O
Checkerboards	B-Method
results	O
SDt	B-Method
provides	O
a	O
gain	O
.	O
	
Here	O
again	O
we	O
observe	O
an	O
erosion	O
as	O
the	O
starting	O
point	O
improves	O
(	O
for	O
confirmation	O
,	O
reproduced	O
the	O
ACF	O
+	O
SDt	B-Method
results	O
,	O
)	O
.	O
	
We	O
name	O
our	O
Checkerboards	B-Method
+	I-Method
SDt	I-Method
detector	O
All	O
-	O
in	O
-	O
one	O
.	O
	
Our	O
filtered	O
channel	O
features	O
results	O
are	O
strong	O
enough	O
to	O
erode	O
existing	O
context	O
and	O
flow	O
features	O
.	O
	
Although	O
these	O
remain	O
complementary	O
cues	O
,	O
more	O
sophisticated	O
ways	O
of	O
extracting	O
this	O
information	O
will	O
be	O
required	O
to	O
further	O
progress	O
in	O
detection	B-Metric
quality	I-Metric
.	O
	
It	O
should	O
be	O
noted	O
that	O
despite	O
our	O
best	O
efforts	O
we	O
could	O
not	O
reproduce	O
the	O
results	O
from	O
neither	O
2Ped	B-Method
nor	O
SDt	B-Method
on	O
the	O
KITTI	B-Material
dataset	O
(	O
in	O
spite	O
of	O
its	O
apparent	O
similarity	O
to	O
Caltech	B-Material
)	O
.	O
	
Effective	O
methods	O
for	O
context	B-Task
and	I-Task
optical	I-Task
flow	I-Task
across	O
datasets	O
have	O
yet	O
to	O
be	O
shown	O
.	O
	
Our	O
main	O
contribution	O
remains	O
on	O
the	O
core	B-Method
detector	I-Method
(	O
only	O
HOG	O
+	O
LUV	O
features	O
over	O
local	O
sliding	O
window	O
pixels	O
in	O
a	O
single	O
frame	O
)	O
.	O
	
section	O
:	O
Test	O
set	O
results	O
	
Having	O
done	O
our	O
exploration	O
of	O
the	O
parameters	O
space	O
on	O
the	O
validation	O
set	O
,	O
we	O
now	O
evaluate	O
the	O
most	O
promising	O
methods	O
on	O
the	O
Caltech	B-Material
and	O
KITTI	B-Material
test	O
sets	O
.	O
	
paragraph	O
:	O
Caltech	B-Material
test	I-Material
set	I-Material
	
Figures	O
[	O
reference	O
]	O
and	O
[	O
reference	O
]	O
present	O
our	O
key	O
results	O
on	O
the	O
Caltech	B-Material
test	I-Material
set	I-Material
.	O
	
For	O
proper	O
comparison	O
,	O
only	O
methods	O
using	O
the	O
same	O
training	O
set	O
should	O
be	O
compared	O
(	O
see	O
for	O
a	O
similar	O
table	O
comparing	O
previous	O
methods	O
)	O
.	O
	
We	O
include	O
for	O
comparison	O
the	O
baselines	O
mentioned	O
in	O
section	O
[	O
reference	O
]	O
,	O
Roerei	O
[	O
]	O
the	O
best	O
known	O
method	O
trained	O
without	O
any	O
Caltech	B-Material
images	I-Material
,	O
MT	B-Method
-	I-Method
DPM	I-Method
[	O
]	O
the	O
best	O
known	O
method	O
based	O
on	O
DPM	B-Method
,	O
and	O
SDN	B-Method
[	O
]	O
the	O
best	O
known	O
method	O
using	O
convolutional	B-Method
neural	I-Method
networks	I-Method
.	O
	
We	O
also	O
include	O
the	O
top	O
performers	O
Katamari	O
and	O
SpatialPooling	B-Method
+	I-Method
.	O
	
We	O
mark	O
as	O
‘	O
	
‘	O
’’	O
both	O
the	O
Caltech10x	B-Material
training	O
set	O
and	O
the	O
one	O
used	O
in	O
LDCF	B-Method
(	O
see	O
section	O
[	O
reference	O
]	O
)	O
.	O
	
paragraph	O
:	O
KITTI	B-Material
test	O
set	O
	
Figure	O
[	O
reference	O
]	O
presents	O
the	O
results	O
on	O
the	O
KITTI	B-Material
test	O
set	O
(	O
‘	O
‘	O
moderate	O
’	O
’	O
setup	O
)	O
,	O
together	O
with	O
all	O
other	O
reported	O
methods	O
using	O
only	O
monocular	O
image	O
content	O
(	O
no	O
stereo	O
or	O
LIDAR	O
data	O
)	O
.	O
	
The	O
KITTI	B-Material
evaluation	O
server	O
only	O
recently	O
has	O
started	O
receiving	O
submissions	O
(	O
for	O
this	O
task	O
,	O
in	O
the	O
last	O
year	O
)	O
,	O
and	O
thus	O
is	O
less	O
prone	O
to	O
dataset	O
over	O
-	O
fitting	O
.	O
	
We	O
train	O
our	O
model	O
on	O
the	O
KITTI	B-Material
training	O
set	O
using	O
almost	O
identical	O
parameters	O
as	O
for	O
Caltech	B-Material
.	O
	
The	O
only	O
change	O
is	O
a	O
subtle	O
pre	B-Method
-	I-Method
processing	I-Method
step	I-Method
in	O
the	O
HOG	B-Task
+	I-Task
LUV	I-Task
computation	I-Task
.	O
	
On	O
KITTI	B-Material
the	O
input	O
image	O
is	O
smoothed	O
(	O
radius	O
)	O
before	O
the	O
feature	O
channels	O
are	O
computed	O
,	O
while	O
on	O
Caltech	B-Material
we	O
do	O
not	O
.	O
	
This	O
subtle	O
change	O
provided	O
a	O
(	O
percent	O
points	O
)	O
improvement	O
on	O
the	O
KITTI	B-Material
validation	O
set	O
.	O
	
subsection	O
:	O
Analysis	O
	
With	O
a	O
(	O
percent	O
points	O
)	O
gap	O
between	O
ACF	O
/	O
InformedHaar	O
and	O
ACF	B-Method
/	O
InformedHaar	O
-	O
	
Ours	O
(	O
see	O
figure	O
[	O
reference	O
]	O
)	O
	
,	O
the	O
results	O
of	O
our	O
baselines	O
show	O
the	O
importance	O
of	O
proper	O
validation	O
of	O
training	O
parameters	O
(	O
large	O
enough	O
model	O
size	O
and	O
negative	O
samples	O
)	O
.	O
	
InformedHaar	B-Method
-	I-Method
	
Ours	B-Method
is	O
the	O
best	O
reported	O
result	O
when	O
training	O
with	O
Caltech1x	O
.	O
	
When	O
considering	O
methods	O
trained	O
on	O
Caltech10x	B-Material
,	O
we	O
obtain	O
a	O
clear	O
gap	O
with	O
the	O
previous	O
best	O
results	O
(	O
LDCF	O
Checkerboards	O
)	O
.	O
	
Using	O
our	O
architecture	O
and	O
the	O
adequate	O
number	O
of	O
filters	O
one	O
can	O
obtain	O
strong	O
results	O
using	O
only	O
HOG	O
+	O
LUV	O
features	O
.	O
	
The	O
exact	O
type	O
of	O
filters	O
seems	O
not	O
critical	O
,	O
in	O
our	O
experiments	O
Checkerboards4x3	B-Method
gets	O
best	O
performance	O
given	O
the	O
available	O
training	O
data	O
.	O
	
RandomFilters	B-Method
reaches	O
the	O
same	O
result	O
,	O
but	O
requires	O
training	O
and	O
merging	O
multiple	O
models	O
.	O
	
Our	O
results	O
cut	O
by	O
half	O
miss	B-Metric
-	I-Metric
rate	I-Metric
of	O
the	O
best	O
known	O
convnet	B-Method
for	O
pedestrian	B-Task
detection	I-Task
(	O
SDN	B-Method
[	O
]	O
)	O
,	O
which	O
in	O
principle	O
could	O
learn	O
similar	O
low	O
-	O
level	O
features	O
and	O
their	O
filtering	B-Method
.	O
	
When	O
adding	O
optical	B-Method
flow	I-Method
we	O
further	O
push	O
the	O
state	O
of	O
the	O
art	O
and	O
reach	O
,	O
a	O
comfortable	O
improvement	O
over	O
the	O
previous	O
best	O
optical	B-Method
flow	I-Method
method	I-Method
(	O
SpatialPooling	B-Method
+	I-Method
)	O
.	O
	
This	O
is	O
the	O
best	O
reported	O
result	O
on	O
this	O
challenging	O
dataset	O
.	O
	
The	O
results	O
on	O
the	O
KITTI	B-Material
dataset	O
confirm	O
the	O
strength	O
of	O
our	O
approach	O
,	O
reaching	O
,	O
just	O
below	O
the	O
best	O
known	O
result	O
on	O
this	O
dataset	O
.	O
	
Competing	O
methods	O
(	O
Regionlets	B-Method
[	O
]	O
and	O
SpatialPooling	B-Method
)	O
both	O
use	O
HOG	B-Method
together	O
with	O
additional	O
LBP	O
and	O
covariance	O
features	O
.	O
	
Adding	O
these	O
remains	O
a	O
possibility	O
for	O
our	O
system	O
.	O
	
Note	O
that	O
our	O
results	O
also	O
improve	O
over	O
methods	O
using	O
LIDAR	O
+	O
Image	O
,	O
such	O
as	O
Fusion	B-Method
-	I-Method
DPM	I-Method
(	O
,	O
not	O
included	O
in	O
figure	O
[	O
reference	O
]	O
for	O
clarity	O
)	O
.	O
	
section	O
:	O
Conclusion	O
	
Through	O
this	O
paper	O
we	O
have	O
shown	O
that	O
the	O
seemingly	O
disconnected	B-Method
methods	I-Method
ACF	I-Method
,	O
(	B-Method
Squares	I-Method
)	I-Method
ChnFtrs	I-Method
,	O
InformedHaar	B-Method
,	O
and	O
LDCF	B-Method
can	O
be	O
all	O
put	O
under	O
the	O
filtered	B-Method
channel	I-Method
features	I-Method
detectors	I-Method
umbrella	I-Method
.	O
	
We	O
have	O
systematically	O
explored	O
different	O
filter	B-Method
banks	I-Method
for	O
such	O
architecture	O
and	O
shown	O
that	O
they	O
provide	O
means	O
for	O
important	O
improvements	O
for	O
pedestrian	B-Task
detection	I-Task
.	O
	
Our	O
results	O
indicate	O
that	O
HOG	O
+	O
LUV	O
features	O
have	O
not	O
yet	O
saturated	O
,	O
and	O
that	O
competitive	O
results	O
(	O
over	O
Caltech	B-Material
and	O
KITTI	B-Material
datasets	O
)	O
can	O
be	O
obtained	O
using	O
only	O
them	O
.	O
	
When	O
optical	O
flow	O
information	O
is	O
added	O
we	O
set	O
the	O
new	O
state	O
of	O
art	O
for	O
the	O
Caltech	B-Material
dataset	I-Material
,	O
reaching	O
(	O
recall	B-Metric
at	O
false	B-Metric
positive	I-Metric
per	I-Metric
image	I-Metric
)	O
.	O
	
In	O
future	O
work	O
we	O
plan	O
to	O
explore	O
how	O
the	O
insights	O
of	O
this	O
work	O
can	O
be	O
exploited	O
into	O
a	O
more	O
general	O
detection	B-Method
architecture	I-Method
such	O
as	O
convolutional	B-Method
neural	I-Method
networks	I-Method
.	O
	
paragraph	O
:	O
Acknowledgements	O
	
We	O
thank	O
Jan	O
Hosang	O
for	O
the	O
help	O
provided	O
setting	O
up	O
some	O
of	O
the	O
experiments	O
.	O
	
We	O
also	O
thank	O
Seong	O
Joon	O
Oh	O
and	O
Sabrina	O
Hoppe	O
for	O
their	O
useful	O
comments	O
.	O
	
bibliography	O
:	O
References	O
	
appendix	O
:	O
Learned	O
model	O
	
In	O
figures	O
[	O
reference	O
]	O
and	O
[	O
reference	O
]	O
we	O
present	O
some	O
qualitative	O
aspects	O
of	O
the	O
final	O
learned	O
models	O
Checkerboards4x3	B-Method
and	O
RandomFilters	B-Method
(	O
see	O
results	O
section	O
of	O
main	O
paper	O
)	O
,	O
not	O
included	O
in	O
the	O
main	O
submission	O
due	O
to	O
space	O
limitations	O
.	O
	
In	O
figure	O
[	O
reference	O
]	O
we	O
compare	O
the	O
spatial	O
distribution	O
of	O
our	O
models	O
versus	O
a	O
significantly	O
weaker	O
model	O
(	O
Roerei	O
,	O
trained	O
on	O
INRIA	O
,	O
see	O
figure	O
5	O
of	O
main	O
paper	O
)	O
.	O
	
We	O
observe	O
that	O
our	O
strong	O
models	O
focalize	O
in	O
similar	O
areas	O
than	O
the	O
weak	B-Method
Roerei	I-Method
model	I-Method
.	O
	
This	O
indicates	O
that	O
using	O
filtered	O
channels	O
does	O
not	O
change	O
which	O
areas	O
of	O
the	O
pedestrian	O
are	O
informative	O
,	O
but	O
rather	O
that	O
at	O
the	O
same	O
locations	O
filtered	O
channels	O
are	O
able	O
to	O
extract	O
more	O
discriminative	O
information	O
.	O
	
In	O
all	O
three	O
models	O
we	O
observe	O
that	O
diagonal	O
oriented	O
channels	O
focus	O
on	O
left	O
and	O
right	O
shoulders	O
.	O
	
The	O
U	O
colour	O
channel	O
is	O
mainly	O
used	O
around	O
the	O
face	O
,	O
while	O
L	O
(	O
luminance	O
)	O
and	O
gradient	O
magnitude	O
(	O
)	O
channels	O
are	O
used	O
all	O
over	O
the	O
body	O
.	O
	
Overall	O
head	O
,	O
feet	O
,	O
and	O
upper	O
torso	O
areas	O
provide	O
most	O
clues	O
for	O
detection	B-Task
.	O
	
In	O
figure	O
[	O
reference	O
]	O
we	O
observe	O
that	O
the	O
filters	O
usage	O
distribution	O
is	O
similar	O
across	O
different	O
filter	B-Method
bank	I-Method
families	I-Method
.	O
	
[	O
Filters	O
from	O
Roerei	B-Method
(	I-Method
scale	I-Method
)	I-Method
model	I-Method
.	O
	
Copied	O
from	O
]	O
	
[	O
Final	O
Checkerboards4x3	B-Method
model	I-Method
]	O
	
[	O
Final	O
RandomFilters	B-Method
model	I-Method
]	O
[	O
Filters	O
used	O
in	O
our	O
final	O
Checkerboards4x3	B-Method
model	I-Method
]	O
[	O
Filters	O
used	O
in	O
our	O
final	O
RandomFilters	B-Method
model	I-Method
]	O
	
document	O
:	O
Semi	B-Method
-	I-Method
Supervised	I-Method
Sequence	I-Method
Modeling	I-Method
with	O
Cross	B-Method
-	I-Method
View	I-Method
Training	I-Method
	
kevclark@cs.stanford.edu	O
,	O
thangluong@google.com	O
,	O
manning@cs.stanford.edu	O
,	O
qvl@google.com	O
Unsupervised	B-Method
representation	I-Method
learning	I-Method
algorithms	I-Method
such	O
as	O
word2vec	B-Method
and	O
ELMo	B-Method
improve	O
the	O
accuracy	B-Metric
of	O
many	O
supervised	B-Method
NLP	I-Method
models	I-Method
,	O
mainly	O
because	O
they	O
can	O
take	O
advantage	O
of	O
large	O
amounts	O
of	O
unlabeled	O
text	O
.	O
	
However	O
,	O
the	O
supervised	B-Method
models	I-Method
only	O
learn	O
from	O
task	O
-	O
specific	O
labeled	O
data	O
during	O
the	O
main	O
training	O
phase	O
.	O
	
We	O
therefore	O
propose	O
Cross	B-Method
-	I-Method
View	I-Method
Training	I-Method
(	O
CVT	B-Method
)	O
,	O
a	O
semi	B-Method
-	I-Method
supervised	I-Method
learning	I-Method
algorithm	I-Method
that	O
improves	O
the	O
representations	O
of	O
a	O
Bi	B-Method
-	I-Method
LSTM	I-Method
sentence	I-Method
encoder	I-Method
using	O
a	O
mix	O
of	O
labeled	O
and	O
unlabeled	O
data	O
.	O
	
On	O
labeled	O
examples	O
,	O
standard	O
supervised	B-Method
learning	I-Method
is	O
used	O
.	O
	
On	O
unlabeled	O
examples	O
,	O
CVT	B-Method
teaches	O
auxiliary	B-Method
prediction	I-Method
modules	I-Method
that	O
see	O
restricted	O
views	O
of	O
the	O
input	O
(	O
e.g.	O
,	O
only	O
part	O
of	O
a	O
sentence	O
)	O
to	O
match	O
the	O
predictions	O
of	O
the	O
full	B-Method
model	I-Method
seeing	O
the	O
whole	O
input	O
.	O
	
Since	O
the	O
auxiliary	B-Method
modules	I-Method
and	O
the	O
full	B-Method
model	I-Method
share	O
intermediate	B-Method
representations	I-Method
,	O
this	O
in	O
turn	O
improves	O
the	O
full	B-Method
model	I-Method
.	O
	
Moreover	O
,	O
we	O
show	O
that	O
CVT	B-Method
is	O
particularly	O
effective	O
when	O
combined	O
with	O
multi	B-Method
-	I-Method
task	I-Method
learning	O
.	O
	
We	O
evaluate	O
CVT	B-Method
on	O
five	O
sequence	B-Task
tagging	I-Task
tasks	I-Task
,	O
machine	B-Task
translation	I-Task
,	O
and	O
dependency	B-Task
parsing	I-Task
,	O
achieving	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
results	O
.	O
	
section	O
:	O
Introduction	O
	
Deep	B-Method
learning	I-Method
models	I-Method
work	O
best	O
when	O
trained	O
on	O
large	O
amounts	O
of	O
labeled	O
data	O
.	O
	
However	O
,	O
acquiring	B-Task
labels	I-Task
is	O
costly	O
,	O
motivating	O
the	O
need	O
for	O
effective	O
semi	B-Method
-	I-Method
supervised	I-Method
learning	I-Method
techniques	I-Method
that	O
leverage	O
unlabeled	O
examples	O
.	O
	
A	O
widely	O
successful	O
semi	B-Method
-	I-Method
supervised	I-Method
learning	I-Method
strategy	I-Method
for	O
neural	B-Task
NLP	I-Task
is	O
pre	O
-	O
training	O
word	O
vectors	O
Mikolov2013DistributedRO	O
.	O
	
More	O
recent	O
work	O
trains	O
a	O
Bi	B-Method
-	I-Method
LSTM	I-Method
sentence	I-Method
encoder	I-Method
to	O
do	O
language	B-Task
modeling	I-Task
and	O
then	O
incorporates	O
its	O
context	B-Method
-	I-Method
sensitive	I-Method
representations	I-Method
into	O
supervised	B-Method
models	I-Method
dai2015semi	O
,	O
peters2018deep	O
.	O
	
Such	O
pre	B-Method
-	I-Method
training	I-Method
methods	I-Method
perform	O
unsupervised	B-Method
representation	I-Method
learning	I-Method
on	O
a	O
large	O
corpus	O
of	O
unlabeled	O
data	O
followed	O
by	O
supervised	B-Method
training	I-Method
.	O
	
A	O
key	O
disadvantage	O
of	O
pre	B-Task
-	I-Task
training	I-Task
is	O
that	O
the	O
first	O
representation	B-Method
learning	I-Method
phase	I-Method
does	O
not	O
take	O
advantage	O
of	O
labeled	O
data	O
–	O
the	O
model	O
attempts	O
to	O
learn	O
generally	O
effective	O
representations	O
rather	O
than	O
ones	O
that	O
are	O
targeted	O
towards	O
a	O
particular	O
task	O
.	O
	
Older	O
semi	B-Method
-	I-Method
supervised	I-Method
learning	I-Method
algorithms	I-Method
like	O
self	B-Method
-	I-Method
training	I-Method
do	O
not	O
suffer	O
from	O
this	O
problem	O
because	O
they	O
continually	O
learn	O
about	O
a	O
task	O
on	O
a	O
mix	O
of	O
labeled	O
and	O
unlabeled	O
data	O
.	O
	
Self	B-Method
-	I-Method
training	I-Method
has	O
historically	O
been	O
effective	O
for	O
NLP	B-Method
yarowsky1995unsupervised	O
,	O
mcclosky2006effective	O
,	O
but	O
is	O
less	O
commonly	O
used	O
with	O
neural	B-Method
models	I-Method
.	O
	
This	O
paper	O
presents	O
Cross	B-Method
-	I-Method
View	I-Method
Training	I-Method
(	O
CVT	B-Method
)	O
,	O
a	O
new	O
self	B-Method
-	I-Method
training	I-Method
algorithm	I-Method
that	O
works	O
well	O
for	O
neural	B-Method
sequence	I-Method
models	I-Method
.	O
	
In	O
self	B-Task
-	I-Task
training	I-Task
,	O
the	O
model	O
learns	O
as	O
normal	O
on	O
labeled	O
examples	O
.	O
	
On	O
unlabeled	O
examples	O
,	O
the	O
model	O
acts	O
as	O
both	O
a	O
âteacherâ	B-Method
that	O
makes	O
predictions	O
about	O
the	O
examples	O
and	O
a	O
âstudentâ	O
that	O
is	O
trained	O
on	O
those	O
predictions	O
.	O
	
Although	O
this	O
process	O
has	O
shown	O
value	O
for	O
some	O
tasks	O
,	O
it	O
is	O
somewhat	O
tautological	O
:	O
the	O
model	O
already	O
produces	O
the	O
predictions	O
it	O
is	O
being	O
trained	O
on	O
.	O
	
Recent	O
research	O
on	O
computer	B-Task
vision	I-Task
addresses	O
this	O
by	O
adding	O
noise	O
to	O
the	O
student	O
’s	O
input	O
,	O
training	O
the	O
model	O
so	O
it	O
is	O
robust	O
to	O
input	O
perturbations	O
sajjadi2016regularization	O
,	O
wei2018improving	O
.	O
	
However	O
,	O
applying	O
noise	O
is	O
difficult	O
for	O
discrete	O
inputs	O
like	O
text	O
.	O
	
As	O
a	O
solution	O
,	O
we	O
take	O
inspiration	O
from	O
multi	B-Method
-	I-Method
view	I-Method
learning	I-Method
blum1998combining	O
,	O
Xu2013ASO	B-Method
and	O
train	O
the	O
model	O
to	O
produce	O
consistent	O
predictions	O
across	O
different	O
views	O
of	O
the	O
input	O
.	O
	
Instead	O
of	O
only	O
training	O
the	O
full	B-Method
model	I-Method
as	O
a	O
student	O
,	O
CVT	B-Method
adds	O
auxiliary	B-Method
prediction	I-Method
modules	I-Method
	
–	O
neural	B-Method
networks	I-Method
that	O
transform	O
vector	B-Method
representations	I-Method
into	O
predictions	O
–	O
to	O
the	O
model	O
and	O
also	O
trains	O
them	O
as	O
students	O
.	O
	
The	O
input	O
to	O
each	O
student	B-Method
prediction	I-Method
module	I-Method
is	O
a	O
subset	O
of	O
the	O
model	O
	
’s	O
intermediate	B-Method
representations	I-Method
corresponding	O
to	O
a	O
restricted	O
view	O
of	O
the	O
input	O
example	O
.	O
	
For	O
example	O
,	O
one	O
auxiliary	B-Method
prediction	I-Method
module	I-Method
for	O
sequence	B-Task
tagging	I-Task
is	O
attached	O
to	O
only	O
the	O
“	O
forward	B-Method
”	I-Method
LSTM	I-Method
in	O
the	O
model	O
	
’s	O
first	O
Bi	B-Method
-	I-Method
LSTM	I-Method
layer	I-Method
,	O
so	O
it	O
makes	O
predictions	O
without	O
seeing	O
any	O
tokens	O
to	O
the	O
right	O
of	O
the	O
current	O
one	O
.	O
	
CVT	B-Method
works	O
by	O
improving	O
the	O
model	O
	
’s	O
representation	B-Method
learning	I-Method
.	O
	
The	O
auxiliary	B-Method
prediction	I-Method
modules	I-Method
can	O
learn	O
from	O
the	O
full	B-Method
model	I-Method
’s	O
predictions	O
because	O
the	O
full	B-Method
model	I-Method
has	O
a	O
better	O
,	O
unrestricted	O
view	O
of	O
the	O
input	O
.	O
	
As	O
the	O
auxiliary	B-Method
modules	I-Method
learn	O
to	O
make	O
accurate	O
predictions	O
despite	O
their	O
restricted	O
views	O
of	O
the	O
input	O
,	O
they	O
improve	O
the	O
quality	O
of	O
the	O
representations	O
they	O
are	O
built	O
on	O
top	O
of	O
.	O
	
This	O
in	O
turn	O
improves	O
the	O
full	B-Method
model	I-Method
,	O
which	O
uses	O
the	O
same	O
shared	O
representations	O
.	O
	
In	O
short	O
,	O
our	O
method	O
combines	O
the	O
idea	O
of	O
representation	B-Method
learning	I-Method
on	O
unlabeled	O
data	O
with	O
classic	O
self	B-Method
-	I-Method
training	I-Method
.	O
	
CVT	B-Method
can	O
be	O
applied	O
to	O
a	O
variety	O
of	O
tasks	O
and	O
neural	B-Method
architectures	I-Method
,	O
but	O
we	O
focus	O
on	O
sequence	B-Task
modeling	I-Task
tasks	I-Task
where	O
the	O
prediction	B-Method
modules	I-Method
are	O
attached	O
to	O
a	O
shared	B-Method
Bi	I-Method
-	I-Method
LSTM	I-Method
encoder	I-Method
.	O
	
We	O
propose	O
auxiliary	B-Method
prediction	I-Method
modules	I-Method
that	O
work	O
well	O
for	O
sequence	B-Task
taggers	I-Task
,	O
graph	B-Method
-	I-Method
based	I-Method
dependency	I-Method
parsers	I-Method
,	O
and	O
sequence	B-Method
-	I-Method
to	I-Method
-	I-Method
sequence	I-Method
models	I-Method
.	O
	
We	O
evaluate	O
our	O
approach	O
on	O
English	O
dependency	B-Task
parsing	I-Task
,	O
combinatory	B-Task
categorial	I-Task
grammar	I-Task
supertagging	I-Task
,	O
named	B-Task
entity	I-Task
recognition	I-Task
,	O
part	B-Task
-	I-Task
of	I-Task
-	I-Task
speech	I-Task
tagging	I-Task
,	O
and	O
text	B-Task
chunking	I-Task
,	O
as	O
well	O
as	O
English	B-Task
to	I-Task
Vietnamese	I-Task
machine	I-Task
translation	I-Task
.	O
	
CVT	B-Method
improves	O
over	O
previously	O
published	O
results	O
on	O
all	O
these	O
tasks	O
.	O
	
Furthermore	O
,	O
CVT	B-Method
can	O
easily	O
and	O
effectively	O
be	O
combined	O
with	O
multi	B-Method
-	I-Method
task	I-Method
learning	O
:	O
we	O
just	O
add	O
additional	O
prediction	B-Method
modules	I-Method
for	O
the	O
different	O
tasks	O
on	O
top	O
of	O
the	O
shared	B-Method
Bi	I-Method
-	I-Method
LSTM	I-Method
encoder	I-Method
.	O
	
Training	O
a	O
unified	B-Method
model	I-Method
to	O
jointly	O
perform	O
all	O
of	O
the	O
tasks	O
except	O
machine	B-Task
translation	I-Task
improves	O
results	O
(	O
outperforming	O
a	O
multi	B-Method
-	I-Method
task	I-Method
ELMo	I-Method
model	O
)	O
while	O
decreasing	O
the	O
total	O
training	B-Metric
time	I-Metric
.	O
	
section	O
:	O
Cross	B-Method
-	I-Method
View	I-Method
Training	I-Method
	
We	O
first	O
present	O
Cross	B-Method
-	I-Method
View	I-Method
Training	I-Method
and	O
describe	O
how	O
it	O
can	O
be	O
combined	O
effectively	O
with	O
multi	B-Method
-	I-Method
task	I-Method
learning	O
.	O
	
See	O
Figure	O
[	O
reference	O
]	O
for	O
an	O
overview	O
of	O
the	O
training	B-Method
method	I-Method
.	O
	
subsection	O
:	O
Method	O
	
Let	O
represent	O
a	O
labeled	O
dataset	O
and	O
represent	O
an	O
unlabeled	O
dataset	O
We	O
use	O
to	O
denote	O
the	O
output	O
distribution	O
over	O
classes	O
produced	O
by	O
the	O
model	O
with	O
parameters	O
on	O
input	O
.	O
	
During	O
CVT	B-Method
,	O
the	O
model	O
alternates	O
learning	B-Method
on	O
a	O
minibatch	O
of	O
labeled	O
examples	O
and	O
learning	O
on	O
a	O
minibatch	O
of	O
unlabeled	O
examples	O
.	O
	
For	O
labeled	O
examples	O
,	O
CVT	B-Method
uses	O
standard	O
cross	B-Method
-	I-Method
entropy	I-Method
loss	I-Method
:	O
CVT	B-Method
adds	O
auxiliary	B-Method
prediction	I-Method
modules	I-Method
to	O
the	O
model	O
,	O
which	O
are	O
used	O
when	O
learning	O
on	O
unlabeled	O
examples	O
.	O
	
A	O
prediction	B-Method
module	I-Method
is	O
usually	O
a	O
small	B-Method
neural	I-Method
network	I-Method
(	O
e.g.	O
,	O
a	O
hidden	O
layer	O
followed	O
by	O
a	O
softmax	B-Method
layer	I-Method
)	O
.	O
	
Each	O
one	O
takes	O
as	O
input	O
an	O
intermediate	O
representation	O
produced	O
by	O
the	O
model	O
(	O
e.g.	O
,	O
the	O
outputs	O
of	O
one	O
of	O
the	O
LSTMs	B-Method
in	O
a	O
Bi	B-Method
-	I-Method
LSTM	I-Method
model	I-Method
)	O
.	O
	
It	O
outputs	O
a	O
distribution	O
over	O
labels	O
.	O
	
Each	O
is	O
chosen	O
such	O
that	O
it	O
only	O
uses	O
a	O
part	O
of	O
the	O
input	O
;	O
the	O
particular	O
choice	O
can	O
depend	O
on	O
the	O
task	O
and	O
model	B-Method
architecture	I-Method
.	O
	
We	O
propose	O
variants	O
for	O
several	O
tasks	O
in	O
Section	O
[	O
reference	O
]	O
.	O
	
The	O
auxiliary	B-Method
prediction	I-Method
modules	I-Method
are	O
only	O
used	O
during	O
training	O
;	O
the	O
test	B-Task
-	I-Task
time	I-Task
prediction	I-Task
come	O
from	O
the	O
primary	B-Method
prediction	I-Method
module	I-Method
that	O
produces	O
.	O
	
On	O
an	O
unlabeled	O
example	O
,	O
the	O
model	O
first	O
produces	O
soft	O
targets	O
by	O
performing	O
inference	B-Task
.	O
	
CVT	B-Method
trains	O
the	O
auxiliary	B-Method
prediction	I-Method
modules	I-Method
to	O
match	O
the	O
primary	B-Method
prediction	I-Method
module	I-Method
on	O
the	O
unlabeled	O
data	O
by	O
minimizing	O
where	O
is	O
a	O
distance	O
function	O
between	O
probability	O
distributions	O
(	O
we	O
use	O
KL	O
divergence	O
)	O
.	O
	
We	O
hold	O
the	O
primary	O
module	O
’s	O
prediction	O
fixed	O
during	O
training	O
(	O
i.e.	O
,	O
we	O
do	O
not	O
back	O
-	O
propagate	O
through	O
it	O
)	O
so	O
the	O
auxiliary	B-Method
modules	I-Method
learn	O
to	O
imitate	O
the	O
primary	O
one	O
,	O
but	O
not	O
vice	O
versa	O
.	O
	
CVT	B-Method
works	O
by	O
enhancing	O
the	O
model	O
	
’s	O
representation	B-Method
learning	I-Method
.	O
	
As	O
the	O
auxiliary	B-Method
modules	I-Method
train	O
,	O
the	O
representations	O
they	O
take	O
as	O
input	O
improve	O
so	O
they	O
are	O
useful	O
for	O
making	B-Task
predictions	I-Task
even	O
when	O
some	O
of	O
the	O
model	O
’s	O
inputs	O
are	O
not	O
available	O
.	O
	
This	O
in	O
turn	O
improves	O
the	O
primary	B-Method
prediction	I-Method
module	I-Method
,	O
which	O
is	O
built	O
on	O
top	O
of	O
the	O
same	O
shared	B-Method
representations	I-Method
.	O
	
We	O
combine	O
the	O
supervised	O
and	O
CVT	B-Method
losses	O
into	O
the	O
total	B-Metric
loss	I-Metric
,	O
,	O
and	O
minimize	O
it	O
with	O
stochastic	B-Method
gradient	I-Method
descent	I-Method
.	O
	
In	O
particular	O
,	O
we	O
alternate	O
minimizing	B-Task
over	O
a	O
minibatch	O
of	O
labeled	O
examples	O
and	O
minimizing	O
over	O
a	O
minibatch	O
of	O
unlabeled	O
examples	O
.	O
	
For	O
most	O
neural	B-Method
networks	I-Method
,	O
adding	O
a	O
few	O
additional	O
prediction	B-Method
modules	I-Method
is	O
computationally	O
cheap	O
compared	O
to	O
the	O
portion	O
of	O
the	O
model	O
building	O
up	O
representations	O
(	O
such	O
as	O
an	O
RNN	B-Method
or	O
CNN	B-Method
)	O
.	O
	
Therefore	O
our	O
method	O
contributes	O
little	O
overhead	O
to	O
training	B-Metric
time	I-Metric
over	O
other	O
self	B-Method
-	I-Method
training	I-Method
approaches	I-Method
for	O
most	O
tasks	O
.	O
	
CVT	B-Method
does	O
not	O
change	O
inference	B-Metric
time	I-Metric
or	O
the	O
number	O
of	O
parameters	O
in	O
the	O
fully	B-Method
-	I-Method
trained	I-Method
model	I-Method
because	O
the	O
auxiliary	B-Method
prediction	I-Method
modules	I-Method
are	O
only	O
used	O
during	O
training	O
.	O
	
subsection	O
:	O
Combining	O
CVT	B-Method
with	O
Multi	B-Method
-	I-Method
Task	I-Method
Learning	O
	
CVT	B-Method
can	O
easily	O
be	O
combined	O
with	O
multi	B-Method
-	I-Method
task	I-Method
learning	O
by	O
adding	O
additional	O
prediction	B-Method
modules	I-Method
for	O
the	O
other	O
tasks	O
on	O
top	O
of	O
the	O
shared	B-Method
Bi	I-Method
-	I-Method
LSTM	I-Method
encoder	I-Method
.	O
	
During	O
supervised	B-Task
learning	I-Task
,	O
we	O
randomly	O
select	O
a	O
task	O
and	O
then	O
update	O
using	O
a	O
minibatch	O
of	O
labeled	O
data	O
for	O
that	O
task	O
.	O
	
When	O
learning	O
on	O
the	O
unlabeled	O
data	O
,	O
we	O
optimize	O
jointly	O
across	O
all	O
tasks	O
at	O
once	O
,	O
first	O
running	O
inference	B-Task
with	O
all	O
the	O
primary	B-Method
prediction	I-Method
modules	I-Method
and	O
then	O
learning	O
from	O
the	O
predictions	O
with	O
all	O
the	O
auxiliary	B-Method
prediction	I-Method
modules	I-Method
.	O
	
As	O
before	O
,	O
the	O
model	O
alternates	O
training	O
on	O
minibatches	O
of	O
labeled	O
and	O
unlabeled	O
examples	O
.	O
	
Examples	O
labeled	O
across	O
many	O
tasks	O
are	O
useful	O
for	O
multi	B-Method
-	I-Method
task	I-Method
systems	O
to	O
learn	O
from	O
,	O
but	O
most	O
datasets	O
are	O
only	O
labeled	O
with	O
one	O
task	O
.	O
	
A	O
benefit	O
of	O
multi	B-Method
-	I-Method
task	I-Method
CVT	I-Method
is	O
that	O
the	O
model	O
creates	O
(	O
artificial	O
)	O
all	O
-	O
tasks	O
-	O
labeled	O
examples	O
from	O
unlabeled	O
data	O
.	O
	
This	O
significantly	O
improves	O
the	O
model	O
	
’s	O
data	B-Metric
efficiency	I-Metric
and	O
training	B-Metric
time	I-Metric
.	O
	
Since	O
running	O
prediction	B-Method
modules	I-Method
is	O
computationally	O
cheap	O
,	O
computing	B-Task
is	O
not	O
much	O
slower	O
for	O
many	O
tasks	O
than	O
it	O
is	O
for	O
a	O
single	O
one	O
.	O
	
However	O
,	O
we	O
find	O
the	O
all	O
-	O
tasks	O
-	O
labeled	O
examples	O
substantially	O
speed	O
up	O
model	B-Task
convergence	I-Task
.	O
	
For	O
example	O
,	O
our	O
model	O
trained	O
on	O
six	O
tasks	O
takes	O
about	O
three	O
times	O
as	O
long	O
to	O
converge	O
as	O
the	O
average	O
model	O
trained	O
on	O
one	O
task	O
,	O
a	O
50	O
%	O
decrease	O
in	O
total	O
training	B-Metric
time	I-Metric
.	O
	
section	O
:	O
Cross	B-Method
-	I-Method
View	I-Method
Training	I-Method
Models	O
	
CVT	B-Method
relies	O
on	O
auxiliary	B-Method
prediction	I-Method
modules	I-Method
that	O
have	O
restricted	O
views	O
of	O
the	O
input	O
.	O
	
In	O
this	O
section	O
,	O
we	O
describe	O
specific	O
constructions	O
of	O
the	O
auxiliary	B-Method
prediction	I-Method
modules	I-Method
that	O
are	O
effective	O
for	O
sequence	B-Task
tagging	I-Task
,	O
dependency	B-Task
parsing	I-Task
,	O
and	O
sequence	B-Task
-	I-Task
to	I-Task
-	I-Task
sequence	I-Task
learning	I-Task
.	O
	
subsection	O
:	O
Bi	B-Method
-	I-Method
LSTM	I-Method
Sentence	I-Method
Encoder	I-Method
	
All	O
of	O
our	O
models	O
use	O
a	O
two	B-Method
-	I-Method
layer	I-Method
CNN	I-Method
-	I-Method
BiLSTM	I-Method
chiu2015named	O
,	O
ma2016end	O
sentence	B-Method
encoder	I-Method
.	O
	
It	O
takes	O
as	O
input	O
a	O
sequence	O
of	O
words	O
.	O
	
First	O
,	O
each	O
word	O
is	O
represented	O
as	O
the	O
sum	O
of	O
an	O
embedding	O
vector	O
and	O
the	O
output	O
of	O
a	O
character	B-Method
-	I-Method
level	I-Method
Convolutional	I-Method
Neural	I-Method
Network	I-Method
,	O
resulting	O
in	O
a	O
sequence	O
of	O
vectors	O
.	O
	
The	O
encoder	O
applies	O
a	O
two	B-Method
-	I-Method
layer	I-Method
bidirectional	I-Method
LSTM	O
graves2005framewise	O
to	O
these	O
representations	O
.	O
	
The	O
first	O
layer	O
runs	O
a	O
Long	B-Method
Short	I-Method
-	I-Method
Term	I-Method
Memory	I-Method
unit	I-Method
hochreiter1997long	I-Method
in	O
the	O
forward	O
direction	O
(	O
taking	O
as	O
input	O
at	O
each	O
step	O
)	O
and	O
the	O
backward	O
direction	O
(	O
taking	O
at	O
each	O
step	O
)	O
to	O
produce	O
vector	O
sequences	O
and	O
.	O
	
The	O
output	O
of	O
the	O
Bi	B-Method
-	I-Method
LSTM	I-Method
is	O
the	O
concatenation	O
of	O
these	O
vectors	O
:	O
The	O
second	O
Bi	B-Method
-	I-Method
LSTM	I-Method
layer	I-Method
works	O
the	O
same	O
,	O
producing	O
outputs	O
,	O
except	O
it	O
takes	O
as	O
input	O
instead	O
of	O
.	O
	
subsection	O
:	O
CVT	B-Method
for	O
Sequence	B-Task
Tagging	I-Task
	
In	O
sequence	B-Task
tagging	I-Task
,	O
each	O
token	O
has	O
a	O
corresponding	O
label	O
.	O
	
The	O
primary	B-Method
prediction	I-Method
module	I-Method
for	O
sequence	B-Task
tagging	I-Task
produces	O
a	O
probability	O
distribution	O
over	O
classes	O
for	O
the	O
label	O
using	O
a	O
one	B-Method
-	I-Method
hidden	I-Method
-	I-Method
layer	I-Method
neural	I-Method
network	I-Method
applied	O
to	O
the	O
corresponding	O
encoder	O
outputs	O
:	O
The	O
auxiliary	B-Method
prediction	I-Method
modules	I-Method
take	O
and	O
,	O
the	O
outputs	O
of	O
the	O
forward	B-Method
and	I-Method
backward	I-Method
LSTMs	I-Method
in	O
the	O
first	O
Bi	B-Method
-	I-Method
LSTM	I-Method
layer	I-Method
,	O
as	O
inputs	O
.	O
	
We	O
add	O
the	O
following	O
four	O
auxiliary	O
prediction	B-Method
modules	I-Method
to	O
the	O
model	O
(	O
see	O
Figure	O
[	O
reference	O
]	O
)	O
:	O
	
The	O
“	O
forward	B-Method
”	I-Method
module	I-Method
makes	O
each	O
prediction	O
without	O
seeing	O
the	O
right	O
context	O
of	O
the	O
current	O
token	O
.	O
	
The	O
“	O
future	B-Method
”	I-Method
module	I-Method
makes	O
each	O
prediction	O
without	O
the	O
right	O
context	O
or	O
the	O
current	O
token	O
itself	O
.	O
	
Therefore	O
it	O
works	O
like	O
a	O
neural	B-Method
language	I-Method
model	I-Method
that	O
,	O
instead	O
of	O
predicting	O
which	O
token	O
comes	O
next	O
in	O
the	O
sequence	O
,	O
predicts	O
which	O
class	O
of	O
token	O
comes	O
next	O
.	O
	
The	O
“	O
backward	O
”	O
and	O
“	O
past	B-Method
”	I-Method
modules	I-Method
are	O
analogous	O
.	O
	
subsection	O
:	O
CVT	B-Method
for	O
Dependency	B-Task
Parsing	I-Task
	
In	O
a	O
dependency	B-Task
parse	I-Task
,	O
words	O
in	O
a	O
sentence	O
are	O
treated	O
as	O
nodes	O
in	O
a	O
graph	O
.	O
	
Typed	O
directed	O
edges	O
connect	O
the	O
words	O
,	O
forming	O
a	O
tree	O
structure	O
describing	O
the	O
syntactic	O
structure	O
of	O
the	O
sentence	O
.	O
	
In	O
particular	O
,	O
each	O
word	O
in	O
a	O
sentence	O
receives	O
exactly	O
one	O
in	O
-	O
going	O
edge	O
going	O
from	O
word	O
(	O
called	O
the	O
“	O
head	O
”	O
)	O
to	O
it	O
(	O
the	O
“	O
dependent	O
”	O
)	O
of	O
type	O
(	O
the	O
“	O
relation	O
”	O
)	O
.	O
	
We	O
use	O
a	O
graph	B-Method
-	I-Method
based	I-Method
dependency	I-Method
parser	I-Method
similar	O
to	O
the	O
one	O
from	O
Dozat2017Deep	O
.	O
	
This	O
treats	O
dependency	B-Task
parsing	I-Task
as	O
a	O
classification	B-Task
task	I-Task
where	O
the	O
goal	O
is	O
to	O
predict	O
which	O
in	O
-	O
going	O
edge	O
connects	O
to	O
each	O
word	O
.	O
	
First	O
,	O
the	O
representations	O
produced	O
by	O
the	O
encoder	O
for	O
the	O
candidate	O
head	O
and	O
dependent	O
are	O
passed	O
through	O
separate	O
hidden	B-Method
layers	I-Method
.	O
	
A	O
bilinear	B-Method
classifier	I-Method
applied	O
to	O
these	O
representations	O
produces	O
a	O
score	O
for	O
each	O
candidate	O
edge	O
.	O
	
Lastly	O
,	O
these	O
scores	O
are	O
passed	O
through	O
a	O
softmax	B-Method
layer	I-Method
to	O
produce	O
probabilities	O
.	O
	
Mathematically	O
,	O
the	O
probability	O
of	O
an	O
edge	O
is	O
given	O
as	O
:	O
where	O
is	O
the	O
scoring	O
function	O
:	O
The	O
bilinear	B-Method
classifier	I-Method
uses	O
a	O
weight	O
matrix	O
specific	O
to	O
the	O
candidate	O
relation	O
as	O
well	O
as	O
a	O
weight	O
matrix	O
shared	O
across	O
all	O
relations	O
.	O
	
Note	O
that	O
unlike	O
in	O
most	O
prior	O
work	O
,	O
our	O
dependency	B-Method
parser	I-Method
only	O
takes	O
words	O
as	O
inputs	O
,	O
not	O
words	O
and	O
part	O
-	O
of	O
-	O
speech	O
tags	O
.	O
	
We	O
add	O
four	O
auxiliary	B-Method
prediction	I-Method
modules	I-Method
to	O
our	O
model	O
for	O
cross	B-Task
-	I-Task
view	I-Task
training	I-Task
:	O
Each	O
one	O
has	O
some	O
missing	O
context	O
(	O
not	O
seeing	O
either	O
the	O
preceding	O
or	O
following	O
words	O
)	O
for	O
the	O
candidate	O
head	O
and	O
candidate	O
dependent	O
.	O
	
subsection	O
:	O
CVT	B-Method
for	O
Sequence	B-Task
-	I-Task
to	I-Task
-	I-Task
Sequence	I-Task
Learning	I-Task
	
We	O
use	O
an	O
encoder	B-Method
-	I-Method
decoder	I-Method
sequence	I-Method
-	I-Method
to	I-Method
-	I-Method
sequence	I-Method
model	I-Method
with	O
attention	B-Method
sutskever2014sequence	O
,	O
bahdanau2014neural	O
.	O
	
Each	O
example	O
consists	O
of	O
an	O
input	O
(	O
source	O
)	O
sequence	O
and	O
output	O
(	O
target	O
)	O
sequence	O
.	O
	
The	O
encoder	B-Method
’s	I-Method
representations	I-Method
are	O
passed	O
into	O
an	O
LSTM	B-Method
decoder	I-Method
using	O
a	O
bilinear	B-Method
attention	I-Method
mechanism	I-Method
Luong2015EffectiveAT	O
.	O
	
In	O
particular	O
,	O
at	O
each	O
time	O
step	O
the	O
decoder	B-Method
computes	O
an	O
attention	B-Method
distribution	I-Method
over	O
source	O
sequence	O
hidden	O
states	O
as	O
where	O
is	O
the	O
decoder	O
’s	O
current	O
hidden	O
state	O
.	O
	
The	O
source	O
hidden	O
states	O
weighted	O
by	O
the	O
attention	O
distribution	O
form	O
a	O
context	O
vector	O
:	O
.	O
	
Next	O
,	O
the	O
context	O
vector	O
and	O
current	O
hidden	O
state	O
are	O
combined	O
into	O
an	O
attention	O
vector	O
.	O
	
Lastly	O
,	O
a	O
softmax	B-Method
layer	I-Method
predicts	O
the	O
next	O
token	O
in	O
the	O
output	O
sequence	O
:	O
.	O
	
We	O
add	O
two	O
auxiliary	B-Method
decoders	I-Method
when	O
applying	O
CVT	B-Method
.	O
	
The	O
auxiliary	B-Method
decoders	I-Method
share	O
embedding	O
and	O
LSTM	O
parameters	O
with	O
the	O
primary	B-Method
decoder	I-Method
,	O
but	O
have	O
different	O
parameters	O
for	O
the	O
attention	B-Method
mechanisms	I-Method
and	O
softmax	O
layers	O
.	O
	
For	O
the	O
first	O
one	O
,	O
we	O
restrict	O
its	O
view	O
of	O
the	O
input	O
by	O
applying	O
attention	B-Method
dropout	I-Method
,	O
randomly	O
zeroing	O
out	O
a	O
fraction	O
of	O
its	O
attention	O
weights	O
.	O
	
The	O
second	O
one	O
is	O
trained	O
to	O
predict	O
the	O
next	O
word	O
in	O
the	O
target	O
sequence	O
rather	O
than	O
the	O
current	O
one	O
:	O
.	O
	
Since	O
there	O
is	O
no	O
target	O
sequence	O
for	O
unlabeled	O
examples	O
,	O
we	O
can	O
not	O
apply	O
teacher	B-Method
forcing	I-Method
to	O
get	O
an	O
output	O
distribution	O
over	O
the	O
vocabulary	O
from	O
the	O
primary	B-Method
decoder	I-Method
at	O
each	O
time	O
step	O
.	O
	
Instead	O
,	O
we	O
produce	O
hard	O
targets	O
for	O
the	O
auxiliary	B-Method
modules	I-Method
by	O
running	O
the	O
primary	B-Method
decoder	I-Method
with	O
beam	B-Method
search	I-Method
on	O
the	O
input	O
sequence	O
.	O
	
This	O
idea	O
has	O
previously	O
been	O
applied	O
to	O
sequence	B-Task
-	I-Task
level	I-Task
knowledge	I-Task
distillation	I-Task
by	O
Kim2016SequenceLevelKD	O
and	O
makes	O
the	O
training	B-Method
procedure	I-Method
similar	O
to	O
back	B-Method
-	I-Method
translation	I-Method
Sennrich2016ImprovingNM	O
.	O
	
section	O
:	O
Experiments	O
	
We	O
compare	O
Cross	B-Method
-	I-Method
View	I-Method
Training	I-Method
against	O
several	O
strong	O
baselines	O
on	O
seven	O
tasks	O
:	O
Combinatory	B-Task
Categorial	I-Task
Grammar	I-Task
(	O
CCG	B-Task
)	O
	
Supertagging	B-Task
:	O
We	O
use	O
data	O
from	O
CCGBank	B-Material
hockenmaier2007ccgbank	O
.	O
	
Text	B-Task
Chunking	I-Task
:	O
We	O
use	O
the	O
CoNLL	O
-	O
2000	O
data	O
tjong2000introduction	O
.	O
	
Named	B-Task
Entity	I-Task
Recognition	I-Task
(	O
NER	B-Task
)	O
	
:	O
We	O
use	O
the	O
CoNLL	B-Material
-	I-Material
2003	I-Material
data	O
tjong2003introduction	O
.	O
	
Fine	B-Task
-	I-Task
Grained	I-Task
NER	I-Task
(	O
FGN	B-Task
)	O
:	O
	
We	O
use	O
the	O
OntoNotes	B-Material
hovy2006ontonotes	O
dataset	O
.	O
	
Part	B-Metric
-	I-Metric
of	I-Metric
-	I-Metric
Speech	I-Metric
(	O
POS	B-Metric
)	O
Tagging	O
:	O
We	O
use	O
the	O
Wall	O
Street	O
Journal	O
portion	O
of	O
the	O
Penn	B-Material
Treebank	I-Material
marcus1993building	O
.	O
	
Dependency	B-Task
Parsing	I-Task
:	O
We	O
use	O
the	O
Penn	B-Material
Treebank	I-Material
converted	O
to	O
Stanford	O
Dependencies	O
version	O
3.3.0	O
.	O
	
Machine	B-Task
Translation	I-Task
:	O
We	O
use	O
the	O
English	O
-	O
Vietnamese	O
translation	O
dataset	O
from	O
IWSLT	O
2015	O
iwslt15	O
.	O
	
We	O
report	O
(	O
tokenized	B-Metric
)	I-Metric
BLEU	I-Metric
scores	I-Metric
on	O
the	O
tst2013	O
test	O
set	O
.	O
	
We	O
use	O
the	O
1	O
Billion	O
Word	O
Language	O
Model	O
Benchmark	O
chelba2013one	O
as	O
a	O
pool	O
of	O
unlabeled	O
sentences	O
for	O
semi	B-Task
-	I-Task
supervised	I-Task
learning	I-Task
.	O
	
subsection	O
:	O
Model	O
Details	O
and	O
Baselines	O
	
We	O
apply	O
dropout	B-Method
during	O
training	O
,	O
but	O
not	O
when	O
running	O
the	O
primary	B-Method
prediction	I-Method
module	I-Method
to	O
produce	O
soft	O
targets	O
on	O
unlabeled	O
examples	O
.	O
	
In	O
addition	O
to	O
the	O
auxiliary	O
prediction	B-Method
modules	I-Method
listed	O
in	O
Section	O
[	O
reference	O
]	O
,	O
we	O
find	O
it	O
slightly	O
improves	O
results	O
to	O
add	O
another	O
one	O
that	O
sees	O
the	O
whole	O
input	O
rather	O
than	O
a	O
subset	O
(	O
but	O
unlike	O
the	O
primary	B-Method
prediction	I-Method
module	I-Method
,	O
does	O
have	O
dropout	O
applied	O
to	O
its	O
representations	O
)	O
.	O
	
Unless	O
indicated	O
otherwise	O
,	O
our	O
models	O
have	O
LSTMs	B-Method
with	O
1024	O
-	O
sized	O
hidden	O
states	O
and	O
512	B-Method
-	I-Method
sized	I-Method
projection	I-Method
layers	I-Method
.	O
	
See	O
the	O
appendix	O
for	O
full	O
training	O
details	O
and	O
hyperparameters	O
.	O
	
We	O
compare	O
CVT	B-Method
with	O
the	O
following	O
other	O
semi	B-Method
-	I-Method
supervised	I-Method
learning	I-Method
algorithms	I-Method
:	O
Word	B-Method
Dropout	I-Method
.	O
	
In	O
this	O
method	O
,	O
we	O
only	O
train	O
the	O
primary	B-Method
prediction	I-Method
module	I-Method
.	O
	
When	O
acting	O
as	O
a	O
teacher	O
it	O
is	O
run	O
as	O
normal	O
,	O
but	O
when	O
acting	O
as	O
a	O
student	O
,	O
we	O
randomly	O
replace	O
some	O
of	O
the	O
input	O
words	O
with	O
a	O
REMOVED	O
token	O
.	O
	
This	O
is	O
similar	O
to	O
CVT	B-Method
in	O
that	O
it	O
exposes	O
the	O
model	O
to	O
a	O
restricted	O
view	O
of	O
the	O
input	O
.	O
	
However	O
,	O
it	O
is	O
less	O
data	O
efficient	O
.	O
	
By	O
carefully	O
designing	O
the	O
auxiliary	B-Method
prediction	I-Method
modules	I-Method
,	O
it	O
is	O
possible	O
to	O
train	O
the	O
auxiliary	B-Method
prediction	I-Method
modules	I-Method
to	O
match	O
the	O
primary	O
one	O
across	O
many	O
different	O
views	O
of	O
the	O
input	O
a	O
once	O
,	O
rather	O
than	O
just	O
one	O
view	O
at	O
a	O
time	O
.	O
	
Virtual	B-Method
Adversarial	I-Method
Training	I-Method
(	O
VAT	B-Method
)	O
.	O
	
VAT	B-Method
miyato2015distributional	O
works	O
like	O
word	B-Method
dropout	I-Method
,	O
but	O
adds	O
noise	O
to	O
the	O
word	O
embeddings	O
of	O
the	O
student	O
instead	O
of	O
dropping	O
out	O
words	O
.	O
	
Notably	O
,	O
the	O
noise	O
is	O
chosen	O
adversarially	O
so	O
it	O
most	O
changes	O
the	O
model	O
	
’s	O
prediction	B-Task
.	O
	
This	O
method	O
was	O
applied	O
successfully	O
to	O
semi	B-Task
-	I-Task
supervised	I-Task
text	I-Task
classification	I-Task
by	O
miyato2016adversarial	O
.	O
	
ELMo	B-Method
.	O
	
ELMo	B-Method
incorporates	O
the	O
representations	O
from	O
a	O
large	O
separately	B-Method
-	I-Method
trained	I-Method
language	I-Method
model	I-Method
into	O
a	O
task	B-Method
-	I-Method
specific	I-Method
model	I-Method
.	O
	
Our	O
implementaiton	O
follows	O
peters2018deep	O
.	O
	
When	O
combining	O
ELMo	B-Method
with	O
multi	B-Method
-	I-Method
task	I-Method
learning	O
,	O
we	O
allow	O
each	O
task	O
to	O
learn	O
its	O
own	O
weights	O
for	O
the	O
ELMo	B-Method
embeddings	O
going	O
into	O
each	O
prediction	B-Method
module	I-Method
.	O
	
We	O
found	O
applying	O
dropout	B-Method
to	O
the	O
ELMo	B-Method
embeddings	O
was	O
crucial	O
for	O
achieving	O
good	O
performance	O
.	O
	
subsection	O
:	O
Results	O
	
Results	O
are	O
shown	O
in	O
Table	O
[	O
reference	O
]	O
.	O
	
CVT	B-Method
on	O
its	O
own	O
outperforms	O
or	O
is	O
comparable	O
to	O
the	O
best	O
previously	O
published	O
results	O
on	O
all	O
tasks	O
.	O
	
Figure	O
[	O
reference	O
]	O
shows	O
an	O
example	O
win	O
for	O
CVT	B-Method
over	O
supervised	B-Method
learning	I-Method
.	O
.	O
	
Of	O
the	O
prior	O
results	O
listed	O
in	O
Table	O
[	O
reference	O
]	O
,	O
only	O
TagLM	B-Method
and	O
ELMo	B-Method
are	O
semi	O
-	O
supervised	O
.	O
	
These	O
methods	O
first	O
train	O
an	O
enormous	O
language	B-Method
model	I-Method
on	O
unlabeled	O
data	O
and	O
incorporate	O
the	O
representations	O
produced	O
by	O
the	O
language	B-Method
model	I-Method
into	O
a	O
supervised	B-Method
classifier	I-Method
.	O
	
Our	O
base	O
models	O
use	O
1024	O
hidden	O
units	O
in	O
their	O
LSTMs	B-Method
(	O
compared	O
to	O
4096	O
in	O
ELMo	B-Method
)	O
,	O
require	O
fewer	O
training	O
steps	O
(	O
around	O
one	O
pass	O
over	O
the	O
billion	O
-	O
word	O
benchmark	O
rather	O
than	O
many	O
passes	O
)	O
,	O
and	O
do	O
not	O
require	O
a	O
pipelined	B-Method
training	I-Method
procedure	I-Method
.	O
	
Therefore	O
,	O
although	O
they	O
perform	O
on	O
par	O
with	O
ELMo	B-Method
,	O
they	O
are	O
faster	O
and	O
simpler	O
to	O
train	O
.	O
	
Increasing	O
the	O
size	O
of	O
our	O
CVT	B-Method
+	O
Multi	B-Method
-	I-Method
task	I-Method
model	O
so	O
it	O
has	O
4096	O
units	O
in	O
its	O
LSTMs	B-Method
like	O
ELMo	B-Method
improves	O
results	O
further	O
so	O
they	O
are	O
significantly	O
better	O
than	O
the	O
ELMo	B-Method
+	O
Multi	B-Method
-	I-Method
task	I-Method
ones	O
.	O
	
We	O
suspect	O
there	O
could	O
be	O
further	O
gains	O
from	O
combining	O
our	O
method	O
with	O
language	B-Method
model	I-Method
pre	I-Method
-	I-Method
training	I-Method
,	O
which	O
we	O
leave	O
for	O
future	O
work	O
.	O
	
CVT	B-Method
+	O
Multi	B-Method
-	I-Method
Task	I-Method
.	O
	
We	O
train	O
a	O
single	O
shared	O
-	O
encoder	O
CVT	B-Method
model	O
to	O
perform	O
all	O
of	O
the	O
tasks	O
except	O
machine	B-Task
translation	I-Task
(	O
as	O
it	O
is	O
quite	O
different	O
and	O
requires	O
more	O
training	O
time	O
than	O
the	O
other	O
ones	O
)	O
.	O
	
Multi	B-Method
-	I-Method
task	I-Method
learning	O
improves	O
results	O
on	O
all	O
of	O
the	O
tasks	O
except	O
fine	B-Task
-	I-Task
grained	I-Task
NER	I-Task
,	O
sometimes	O
by	O
large	O
margins	O
.	O
	
Prior	O
work	O
on	O
many	B-Task
-	I-Task
task	I-Task
NLP	I-Task
such	O
as	O
hashimoto2016joint	O
uses	O
complicated	O
architectures	B-Method
and	O
training	B-Method
algorithms	I-Method
.	O
	
Our	O
result	O
shows	O
that	O
simple	O
parameter	B-Method
sharing	I-Method
can	O
be	O
enough	O
for	O
effective	O
many	B-Task
-	I-Task
task	I-Task
learning	I-Task
when	O
the	O
model	O
is	O
big	O
and	O
trained	O
on	O
a	O
large	O
amount	O
of	O
data	O
.	O
	
Interestingly	O
,	O
multi	B-Method
-	I-Method
task	I-Method
learning	O
works	O
better	O
in	O
conjunction	O
with	O
CVT	B-Method
than	O
with	O
ELMo	B-Method
.	O
	
We	O
hypothesize	O
that	O
the	O
ELMo	B-Method
models	O
quickly	O
fit	O
to	O
the	O
data	O
primarily	O
using	O
the	O
ELMo	B-Method
vectors	O
,	O
which	O
perhaps	O
hinders	O
the	O
model	O
from	O
learning	O
effective	O
representations	O
that	O
transfer	O
across	O
tasks	O
.	O
	
We	O
also	O
believe	O
CVT	B-Method
alleviates	O
the	O
danger	O
of	O
the	O
model	O
	
“	O
forgetting	O
”	O
one	O
task	O
while	O
training	O
on	O
the	O
other	O
ones	O
,	O
a	O
well	O
-	O
known	O
problem	O
in	O
many	B-Method
-	I-Method
task	I-Method
learning	I-Method
Kirkpatrick2017OvercomingCF	O
.	O
	
During	O
multi	B-Method
-	I-Method
task	I-Method
CVT	I-Method
,	O
the	O
model	O
makes	O
predictions	O
about	O
unlabeled	O
examples	O
across	O
all	O
tasks	O
,	O
creating	O
(	O
artificial	O
)	O
all	O
-	O
tasks	O
-	O
labeled	O
examples	O
,	O
so	O
the	O
model	O
does	O
not	O
only	O
see	O
one	O
task	O
at	O
a	O
time	O
.	O
	
In	O
fact	O
,	O
multi	B-Method
-	I-Method
task	I-Method
learning	O
plus	O
self	B-Task
training	I-Task
is	O
similar	O
to	O
the	O
Learning	B-Method
without	I-Method
Forgetting	I-Method
algorithm	I-Method
Li2016LearningWF	O
,	O
which	O
trains	O
the	O
model	O
to	O
keep	O
its	O
predictions	O
on	O
an	O
old	O
task	O
unchanged	O
when	O
learning	O
a	O
new	O
task	O
.	O
	
To	O
test	O
the	O
value	O
of	O
all	O
-	O
tasks	O
-	O
labeled	O
examples	O
,	O
we	O
trained	O
a	O
multi	B-Method
-	I-Method
task	I-Method
CVT	I-Method
model	O
that	O
only	O
computes	O
on	O
one	O
task	O
at	O
a	O
time	O
(	O
chosen	O
randomly	O
for	O
each	O
unlabeled	O
minibatch	O
)	O
instead	O
of	O
for	O
all	O
tasks	O
in	O
parallel	O
.	O
	
The	O
one	B-Method
-	I-Method
at	I-Method
-	I-Method
a	I-Method
-	I-Method
time	I-Method
model	I-Method
performs	O
substantially	O
worse	O
(	O
see	O
Table	O
[	O
reference	O
]	O
)	O
.	O
	
Model	B-Task
Generalization	I-Task
.	O
	
In	O
order	O
to	O
evaluate	O
how	O
our	O
models	O
generalize	O
to	O
the	O
dev	B-Metric
set	O
from	O
the	O
train	O
set	O
,	O
we	O
plot	O
the	O
dev	B-Metric
vs.	O
train	B-Metric
accuracy	I-Metric
for	O
our	O
different	O
methods	O
as	O
they	O
learn	O
(	O
see	O
Figure	O
[	O
reference	O
]	O
)	O
.	O
	
Both	O
CVT	B-Method
and	O
multi	B-Method
-	I-Method
task	I-Method
learning	O
improve	O
model	B-Method
generalization	I-Method
:	O
for	O
the	O
same	O
train	B-Metric
accuracy	I-Metric
,	O
the	O
models	O
get	O
better	O
dev	B-Metric
accuracy	O
than	O
purely	O
supervised	B-Method
learning	I-Method
.	O
	
Interestingly	O
,	O
CVT	B-Method
continues	O
to	O
improve	O
in	O
dev	B-Metric
set	O
accuracy	O
while	O
close	O
to	O
100	O
%	O
train	B-Metric
accuracy	I-Metric
for	O
CCG	B-Task
,	O
Chunking	B-Task
,	O
and	O
NER	B-Task
,	O
perhaps	O
because	O
the	O
model	O
is	O
still	O
learning	O
from	O
unlabeled	O
data	O
even	O
when	O
it	O
has	O
completely	O
fit	O
to	O
the	O
train	O
set	O
.	O
	
We	O
also	O
show	O
results	O
for	O
a	O
smaller	O
multi	B-Method
-	I-Method
task	I-Method
+	O
CVT	B-Method
model	O
.	O
	
Although	O
it	O
generalizes	O
at	O
least	O
as	O
well	O
as	O
the	O
larger	O
one	O
,	O
it	O
halts	O
making	O
progress	O
on	O
the	O
train	O
set	O
earlier	O
.	O
	
This	O
suggests	O
it	O
is	O
important	O
to	O
use	O
sufficiently	O
large	O
neural	B-Method
networks	I-Method
for	O
multi	B-Method
-	I-Method
task	I-Method
learning	O
:	O
otherwise	O
the	O
model	O
does	O
not	O
have	O
the	O
capacity	O
to	O
fit	O
to	O
all	O
the	O
training	O
data	O
.	O
	
Auxiliary	B-Method
Prediction	I-Method
Module	I-Method
Ablation	I-Method
.	O
	
We	O
briefly	O
explore	O
which	O
auxiliary	B-Method
prediction	I-Method
modules	I-Method
are	O
more	O
important	O
for	O
the	O
sequence	B-Task
tagging	I-Task
tasks	I-Task
in	O
Table	O
[	O
reference	O
]	O
.	O
	
We	O
find	O
that	O
both	O
kinds	O
of	O
auxiliary	B-Method
prediction	I-Method
modules	I-Method
improve	O
performance	O
,	O
but	O
that	O
the	O
future	O
and	O
past	B-Method
modules	I-Method
improve	O
results	O
more	O
than	O
the	O
forward	O
and	O
backward	O
ones	O
,	O
perhaps	O
because	O
they	O
see	O
a	O
more	O
restricted	O
and	O
challenging	O
view	O
of	O
the	O
input	O
.	O
	
Training	B-Method
Models	I-Method
on	O
Small	O
Datasets	O
.	O
	
We	O
explore	O
how	O
CVT	B-Method
scales	O
with	O
dataset	O
size	O
by	O
varying	O
the	O
amount	O
of	O
training	O
data	O
the	O
model	O
has	O
access	O
to	O
.	O
	
Unsurprisingly	O
,	O
the	O
improvement	O
of	O
CVT	B-Method
over	O
purely	O
supervised	B-Method
learning	I-Method
grows	O
larger	O
as	O
the	O
amount	O
of	O
labeled	O
data	O
decreases	O
(	O
see	O
Figure	O
[	O
reference	O
]	O
,	O
left	O
)	O
.	O
	
Using	O
only	O
25	O
%	O
of	O
the	O
labeled	O
data	O
,	O
our	O
approach	O
already	O
performs	O
as	O
well	O
or	O
better	O
than	O
a	O
fully	B-Method
supervised	I-Method
model	I-Method
using	O
100	O
%	O
of	O
the	O
training	O
data	O
,	O
demonstrating	O
that	O
CVT	B-Method
is	O
particularly	O
useful	O
on	O
small	O
datasets	O
.	O
	
Training	O
Larger	O
Models	O
.	O
	
Most	O
sequence	B-Method
taggers	I-Method
and	O
dependency	B-Method
parsers	I-Method
in	O
prior	O
work	O
use	O
small	O
LSTMs	B-Method
(	O
hidden	O
state	O
sizes	O
of	O
around	O
300	O
)	O
because	O
larger	O
models	O
yield	O
little	O
to	O
no	O
gains	O
in	O
performance	O
reimers2017reporting	O
.	O
	
We	O
found	O
our	O
own	O
supervised	B-Method
approaches	I-Method
also	O
do	O
not	O
benefit	O
greatly	O
from	O
increasing	O
the	O
model	O
size	O
.	O
	
In	O
contrast	O
,	O
when	O
using	O
CVT	B-Method
accuracy	O
scales	O
better	O
with	O
model	O
size	O
(	O
see	O
Figure	O
[	O
reference	O
]	O
,	O
right	O
)	O
.	O
	
This	O
finding	O
suggests	O
the	O
appropriate	O
semi	B-Method
-	I-Method
supervised	I-Method
learning	I-Method
methods	I-Method
may	O
enable	O
the	O
development	O
of	O
larger	O
,	O
more	O
sophisticated	O
models	O
for	O
NLP	B-Task
tasks	I-Task
with	O
limited	O
amounts	O
of	O
labeled	O
data	O
.	O
	
Generalizable	B-Method
Representations	I-Method
.	O
	
Lastly	O
,	O
we	O
explore	O
training	O
the	O
CVT	B-Method
+	O
multi	B-Method
-	I-Method
task	I-Method
model	I-Method
on	O
five	O
tasks	O
,	O
freezing	O
the	O
encoder	B-Method
,	O
and	O
then	O
only	O
training	O
a	O
prediction	B-Method
module	I-Method
on	O
the	O
sixth	O
task	O
.	O
	
This	O
tests	O
whether	O
the	O
encoder	B-Method
’s	I-Method
representations	I-Method
generalize	O
to	O
a	O
new	O
task	O
not	O
seen	O
during	O
its	O
training	O
.	O
	
Only	O
training	O
the	O
prediction	B-Method
module	I-Method
is	O
very	O
fast	O
because	O
(	O
1	O
)	O
the	O
encoder	B-Method
(	O
which	O
is	O
by	O
far	O
the	O
slowest	O
part	O
of	O
the	O
model	O
)	O
has	O
to	O
be	O
run	O
over	O
each	O
example	O
only	O
once	O
and	O
(	O
2	O
)	O
we	O
do	O
not	O
back	O
-	O
propagate	O
into	O
the	O
encoder	B-Method
.	O
	
Results	O
are	O
shown	O
in	O
Table	O
[	O
reference	O
]	O
.	O
	
Training	O
only	O
a	O
prediction	B-Method
module	I-Method
on	O
top	O
of	O
multi	B-Method
-	I-Method
task	I-Method
representations	O
works	O
remarkably	O
well	O
,	O
outperforming	O
ELMo	B-Method
embeddings	O
and	O
sometimes	O
even	O
a	O
vanilla	B-Method
supervised	I-Method
model	I-Method
,	O
showing	O
the	O
multi	B-Method
-	I-Method
task	I-Method
model	I-Method
is	O
building	O
up	O
effective	O
representations	O
for	O
language	B-Task
.	O
	
In	O
particular	O
,	O
the	O
representations	O
could	O
be	O
used	O
like	O
skip	B-Method
-	I-Method
thought	I-Method
vectors	I-Method
kiros2015skip	O
to	O
quickly	O
train	O
models	O
on	O
new	O
tasks	O
without	O
slow	B-Method
representation	I-Method
learning	I-Method
.	O
	
section	O
:	O
Related	O
Work	O
	
Unsupervised	B-Method
Representation	I-Method
Learning	I-Method
.	O
	
Early	O
approaches	O
to	O
deep	B-Task
semi	I-Task
-	I-Task
supervised	I-Task
learning	I-Task
pre	O
-	O
train	O
neural	B-Method
models	I-Method
on	O
unlabeled	O
data	O
,	O
which	O
has	O
been	O
successful	O
for	O
applications	O
in	O
computer	B-Task
vision	I-Task
jarrett2009best	O
,	O
lecun2010convolutional	O
and	O
NLP	B-Task
.	O
	
Particularly	O
noteworthy	O
for	O
NLP	B-Method
are	O
algorithms	O
for	O
learning	O
effective	B-Task
word	I-Task
embeddings	I-Task
and	O
language	B-Method
model	I-Method
pretraining	I-Method
dai2015semi	O
,	O
ramachandran2016unsupervised	O
,	O
peters2018deep	O
,	O
howard2018universal	O
,	O
radford2018improving	O
.	O
	
Pre	B-Task
-	I-Task
training	I-Task
on	O
other	O
tasks	O
such	O
as	O
machine	B-Task
translation	I-Task
has	O
also	O
been	O
studied	O
McCann2017LearnedIT	O
.	O
	
Other	O
approaches	O
train	O
	
“	O
thought	O
vectors	O
”	O
representing	O
sentences	O
through	O
unsupervised	B-Method
or	I-Method
supervised	I-Method
learning	I-Method
.	O
	
Self	B-Method
-	I-Method
Training	I-Method
.	O
	
One	O
of	O
the	O
earliest	O
approaches	O
to	O
semi	B-Task
-	I-Task
supervised	I-Task
learning	I-Task
is	O
self	B-Method
-	I-Method
training	I-Method
scudder1965probability	O
,	O
which	O
has	O
been	O
successfully	O
applied	O
to	O
NLP	B-Task
tasks	I-Task
such	O
as	O
word	B-Task
-	I-Task
sense	I-Task
disambiguation	I-Task
yarowsky1995unsupervised	O
and	O
parsing	B-Task
mcclosky2006effective	O
.	O
	
In	O
each	O
round	O
of	O
training	O
,	O
the	O
classifier	B-Method
,	O
acting	O
as	O
a	O
“	O
teacher	O
,	O
”	O
labels	O
some	O
of	O
the	O
unlabeled	O
data	O
and	O
adds	O
it	O
to	O
the	O
training	O
set	O
.	O
	
Then	O
,	O
acting	O
as	O
a	O
“	O
student	O
,	O
”	O
it	O
is	O
retrained	O
on	O
the	O
new	O
training	O
set	O
.	O
	
Many	O
recent	O
approaches	O
(	O
including	O
the	O
consistentency	B-Method
regularization	I-Method
methods	I-Method
discussed	O
below	O
and	O
our	O
own	O
method	O
)	O
train	O
the	O
student	O
with	O
soft	O
targets	O
from	O
the	O
teacher	O
’s	O
output	O
distribution	O
rather	O
than	O
a	O
hard	O
label	O
,	O
making	O
the	O
procedure	O
more	O
akin	O
to	O
knowledge	B-Task
distillation	I-Task
hinton2015distilling	O
.	O
	
It	O
is	O
also	O
possible	O
to	O
use	O
multiple	O
models	O
or	O
prediction	B-Method
modules	I-Method
for	O
the	O
teacher	O
,	O
such	O
as	O
in	O
tri	B-Task
-	I-Task
training	I-Task
zhou2005tri	O
,	O
ruder2018strong	O
.	O
	
Consistency	B-Method
Regularization	I-Method
.	O
	
Recent	O
works	O
add	O
noise	O
(	O
e.g.	O
,	O
drawn	O
from	O
a	O
Gaussian	B-Method
distribution	I-Method
)	O
or	O
apply	O
stochastic	B-Method
transformations	I-Method
(	O
e.g.	O
,	O
horizontally	O
flipping	O
an	O
image	O
)	O
to	O
the	O
student	O
’s	O
inputs	O
.	O
	
This	O
trains	O
the	O
model	O
to	O
give	O
consistent	O
predictions	O
to	O
nearby	O
data	O
points	O
,	O
encouraging	O
distributional	O
smoothness	O
in	O
the	O
model	O
.	O
	
Consistency	B-Method
regularization	I-Method
has	O
been	O
very	O
successful	O
for	O
computer	B-Task
vision	I-Task
applications	I-Task
bachman2014learning	O
,	O
laine2016temporal	O
,	O
tarvainen2017weight	O
.	O
	
However	O
,	O
stochastic	O
input	O
alterations	O
are	O
more	O
difficult	O
to	O
apply	O
to	O
discrete	O
data	O
like	O
text	O
,	O
making	O
consistency	B-Method
regularization	I-Method
less	O
used	O
for	O
natural	B-Task
language	I-Task
processing	I-Task
.	O
	
One	O
solution	O
is	O
to	O
add	O
noise	O
to	O
the	O
model	O
	
’s	O
word	B-Method
embeddings	I-Method
miyato2016adversarial	O
;	O
we	O
compare	O
against	O
this	O
approach	O
in	O
our	O
experiments	O
.	O
	
CVT	B-Method
is	O
easily	O
applicable	O
to	O
text	O
because	O
it	O
does	O
not	O
require	O
changing	O
the	O
student	O
’s	O
inputs	O
.	O
	
Multi	B-Method
-	I-Method
View	I-Method
Learning	I-Method
.	O
	
Multi	B-Method
-	I-Method
view	I-Method
learning	I-Method
on	O
data	O
where	O
features	O
can	O
be	O
separated	O
into	O
distinct	O
subsets	O
has	O
been	O
well	O
studied	O
Xu2013ASO	O
.	O
	
Particularly	O
relevant	O
are	O
co	B-Method
-	I-Method
training	I-Method
blum1998combining	O
and	O
co	B-Method
-	I-Method
regularization	I-Method
Sindhwani2005ACA	O
,	O
which	O
trains	O
two	O
models	O
with	O
disjoint	O
views	O
of	O
the	O
input	O
.	O
	
On	O
unlabeled	O
data	O
,	O
each	O
one	O
acts	O
as	O
a	O
“	O
teacher	O
”	O
for	O
the	O
other	O
model	O
.	O
	
In	O
contrast	O
to	O
these	O
methods	O
,	O
our	O
approach	O
trains	O
a	O
single	O
unified	B-Method
model	I-Method
where	O
auxiliary	B-Method
prediction	I-Method
modules	I-Method
see	O
different	O
,	O
but	O
not	O
necessarily	O
independent	O
views	O
of	O
the	O
input	O
.	O
	
Self	B-Task
Supervision	I-Task
.	O
	
Self	B-Method
-	I-Method
supervised	I-Method
learning	I-Method
methods	I-Method
train	O
auxiliary	B-Method
prediction	I-Method
modules	I-Method
on	O
tasks	O
where	O
performance	O
can	O
be	O
measured	O
without	O
human	O
-	O
provided	O
labels	O
.	O
	
Recent	O
work	O
has	O
jointly	O
trained	O
image	B-Method
classifiers	I-Method
with	O
tasks	O
like	O
relative	O
position	O
and	O
colorization	O
doersch2017multi	O
,	O
sequence	B-Method
taggers	I-Method
with	O
language	B-Method
modeling	I-Method
rei2017semi	O
,	O
and	O
reinforcement	B-Method
learning	I-Method
agents	I-Method
with	O
predicting	O
changes	O
in	O
the	O
environment	O
jaderberg2016reinforcement	O
.	O
	
Unlike	O
these	O
approaches	O
,	O
our	O
auxiliary	B-Method
losses	I-Method
are	O
based	O
on	O
self	B-Method
-	I-Method
labeling	I-Method
,	O
not	O
labels	O
deterministically	O
constructed	O
from	O
the	O
input	O
.	O
	
Multi	B-Method
-	I-Method
Task	I-Method
Learning	O
.	O
	
There	O
has	O
been	O
extensive	O
prior	O
work	O
on	O
multi	B-Method
-	I-Method
task	I-Method
learning	O
Caruana1997MultitaskL	O
,	O
Ruder2017AnOO	O
.	O
	
For	O
NLP	B-Task
,	O
most	O
work	O
has	O
focused	O
on	O
a	O
small	O
number	O
of	O
closely	O
related	O
tasks	O
Luong2015MultitaskST	O
,	O
zhang2016stack	O
,	O
Sgaard2016DeepML	O
,	O
Peng2017DeepML	O
.	O
	
Many	B-Method
-	I-Method
task	I-Method
systems	I-Method
are	O
less	O
commonly	O
developed	O
.	O
	
Collobert2008AUA	O
propose	O
a	O
many	B-Method
-	I-Method
task	I-Method
system	I-Method
sharing	O
word	B-Method
embeddings	I-Method
between	O
the	O
tasks	O
,	O
hashimoto2016joint	O
train	O
a	O
many	B-Method
-	I-Method
task	I-Method
model	I-Method
where	O
the	O
tasks	O
are	O
arranged	O
hierarchically	O
according	O
to	O
their	O
linguistic	O
level	O
,	O
and	O
subramanian2018learning	O
train	O
a	O
shared	B-Method
-	I-Method
encoder	I-Method
many	I-Method
-	I-Method
task	I-Method
model	I-Method
for	O
the	O
purpose	O
of	O
learning	O
better	O
sentence	B-Task
representations	I-Task
for	O
use	O
in	O
downstream	B-Task
tasks	I-Task
,	O
not	O
for	O
improving	O
results	O
on	O
the	O
original	O
tasks	O
.	O
	
section	O
:	O
Conclusion	O
	
We	O
propose	O
Cross	B-Method
-	I-Method
View	I-Method
Training	I-Method
,	O
a	O
new	O
method	O
for	O
semi	B-Task
-	I-Task
supervised	I-Task
learning	I-Task
.	O
	
Our	O
approach	O
allows	O
models	O
to	O
effectively	O
leverage	O
their	O
own	O
predictions	O
on	O
unlabeled	O
data	O
,	O
training	O
them	O
to	O
produce	O
effective	O
representations	O
that	O
yield	O
accurate	O
predictions	O
even	O
when	O
some	O
of	O
the	O
input	O
is	O
not	O
available	O
.	O
	
We	O
achieve	O
excellent	O
results	O
across	O
seven	O
NLP	B-Task
tasks	I-Task
,	O
especially	O
when	O
CVT	B-Method
is	O
combined	O
with	O
multi	B-Method
-	I-Method
task	I-Method
learning	O
.	O
	
section	O
:	O
Acknowledgements	O
	
We	O
thank	O
Abi	O
See	O
,	O
Christopher	O
Clark	O
,	O
	
He	O
He	O
,	O
Peng	O
Qi	O
,	O
Reid	O
Pryzant	O
,	O
Yuaho	O
Zhang	O
,	O
and	O
the	O
anonymous	O
reviewers	O
for	O
their	O
thoughtful	O
comments	O
and	O
suggestions	O
.	O
	
We	O
thank	O
Takeru	O
Miyato	O
for	O
help	O
with	O
his	O
virtual	B-Method
adversarial	I-Method
training	I-Method
code	I-Method
and	O
Emma	O
Strubell	O
for	O
answering	O
our	O
questions	O
about	O
OntoNotes	B-Task
NER	I-Task
.	O
	
Kevin	O
is	O
supported	O
by	O
a	O
Google	O
PhD	O
Fellowship	O
.	O
	
bibliography	O
:	O
References	O
	
appendix	O
:	O
Detailed	O
Results	O
	
We	O
provide	O
a	O
more	O
detailed	O
version	O
of	O
the	O
test	O
set	O
results	O
in	O
the	O
paper	O
,	O
adding	O
two	O
decimals	O
of	O
precision	O
,	O
standard	O
deviations	O
of	O
the	O
5	O
runs	O
for	O
each	O
model	O
,	O
and	O
more	O
prior	O
work	O
,	O
in	O
Table	O
[	O
reference	O
]	O
.	O
	
appendix	O
:	O
Model	O
Details	O
	
Our	O
models	O
use	O
two	B-Method
layer	I-Method
CNN	I-Method
-	I-Method
BiLSTM	I-Method
encoders	I-Method
chiu2015named	O
,	O
ma2016end	O
,	O
lample2016neural	O
and	O
task	B-Method
-	I-Method
specific	I-Method
prediction	I-Method
modules	I-Method
.	O
	
See	O
Section	O
[	O
reference	O
]	O
of	O
the	O
paper	O
for	O
details	O
.	O
	
We	O
provide	O
a	O
few	O
minor	O
details	O
not	O
covered	O
there	O
below	O
.	O
	
Sequence	B-Task
Tagging	I-Task
.	O
	
For	O
Chunking	B-Task
and	O
Named	B-Task
Entity	I-Task
Recognition	I-Task
,	O
we	O
use	O
a	O
BIOES	B-Method
tagging	I-Method
scheme	I-Method
.	O
	
We	O
apply	O
label	O
smoothing	B-Method
szegedy2016rethinking	O
,	O
pereyra2017regularizing	B-Method
with	O
a	O
rate	O
of	O
0.1	O
to	O
the	O
target	O
labels	O
when	O
training	O
on	O
the	O
labeled	O
data	O
.	O
	
Dependency	B-Task
Parsing	I-Task
.	O
	
We	O
omit	O
punctuation	O
from	O
evaluation	O
,	O
which	O
is	O
standard	O
practice	O
for	O
the	O
PTB	O
-	O
SD	O
3.3.0	O
dataset	O
.	O
	
ROOT	O
is	O
represented	O
with	O
a	O
fixed	O
vector	O
instead	O
of	O
using	O
a	O
vector	O
from	O
the	O
encoder	B-Method
,	O
but	O
otherwise	O
dependencies	O
coming	O
from	O
ROOT	O
are	O
scored	O
the	O
same	O
way	O
as	O
the	O
other	O
dependencies	O
.	O
	
Machine	B-Task
Translation	I-Task
.	O
	
We	O
apply	O
dropout	B-Method
to	O
the	O
output	O
of	O
each	O
LSTM	B-Method
layer	I-Method
in	O
the	O
decoder	B-Method
.	O
	
Our	O
implementation	O
is	O
heavily	O
based	O
off	O
of	O
the	O
Google	B-Method
NMT	I-Method
Tutorial	I-Method
luong17	I-Method
.	O
	
We	O
attribute	O
our	O
significantly	O
better	O
results	O
to	O
using	O
pre	O
-	O
trained	O
word	B-Method
embeddings	I-Method
,	O
a	O
character	B-Method
-	I-Method
level	I-Method
CNN	I-Method
,	O
a	O
larger	O
model	O
,	O
stronger	O
regularization	B-Method
,	O
and	O
better	O
hyperparameter	B-Method
tuning	I-Method
.	O
	
Target	O
words	O
occurring	O
5	O
or	O
fewer	O
times	O
in	O
the	O
train	O
set	O
are	O
replaced	O
with	O
a	O
UNK	O
token	O
(	O
but	O
not	O
during	O
evaluation	O
)	O
.	O
	
We	O
use	O
a	O
beam	O
size	O
of	O
10	O
when	O
performing	O
beam	B-Method
search	I-Method
.	O
	
We	O
found	O
it	O
slightly	O
beneficial	O
to	O
apply	O
label	B-Method
smoothing	I-Method
with	O
a	O
rate	O
of	O
0.1	O
to	O
the	O
teacher	O
	
’s	O
predictions	O
(	O
unlike	O
our	O
other	O
tasks	O
,	O
the	O
teacher	O
only	O
provides	O
hard	O
targets	O
to	O
the	O
students	O
for	O
translation	B-Task
)	O
.	O
	
Multi	B-Method
-	I-Method
Task	I-Method
Learning	O
.	O
	
Several	O
of	O
our	O
datasets	O
are	O
constructed	O
from	O
the	O
Penn	B-Material
Treebank	I-Material
.	O
	
However	O
,	O
we	O
treat	O
them	O
as	O
separate	O
rather	O
than	O
providing	O
examples	O
labeled	O
across	O
multiple	O
tasks	O
to	O
our	O
model	O
during	O
supervised	B-Task
training	I-Task
.	O
	
Furthermore	O
,	O
the	O
Penn	B-Material
Treebank	I-Material
tasks	O
do	O
not	O
all	O
use	O
the	O
same	O
train	O
/	O
dev	B-Metric
/	O
test	O
splits	O
.	O
	
We	O
ensure	O
the	O
training	O
split	O
of	O
one	O
task	O
never	O
overlaps	O
the	O
evaluation	O
split	O
of	O
another	O
by	O
discarding	O
the	O
overlapping	O
examples	O
from	O
the	O
train	O
sets	O
.	O
	
Other	O
Details	O
.	O
	
We	O
apply	O
dropout	B-Method
hinton2012improving	O
to	O
the	O
word	O
embeddings	O
and	O
outputs	O
of	O
each	O
Bi	B-Method
-	I-Method
LSTM	I-Method
.	O
	
We	O
use	O
an	O
exponential	O
-	O
moving	O
-	O
average	O
(	O
EMA	B-Method
)	O
of	O
the	O
model	B-Method
weights	I-Method
from	O
training	O
for	O
the	O
final	O
model	O
;	O
we	O
found	O
this	O
to	O
slightly	O
improve	O
accuracy	B-Metric
and	O
significantly	O
reduce	O
the	O
variance	O
in	O
accuracy	B-Metric
between	O
models	O
trained	O
with	O
different	O
random	B-Method
initializations	I-Method
.	O
	
The	O
model	O
is	O
trained	O
using	O
SGD	B-Method
with	O
momentum	B-Method
polyak1964some	O
,	O
sutskever2013importance	O
.	O
	
Word	O
embeddings	O
are	O
initialized	O
with	O
GloVe	O
vectors	O
pennington2014glove	O
and	O
fine	O
-	O
tuned	O
during	O
training	O
.	O
	
The	O
full	O
set	O
of	O
model	O
hyperparameters	O
are	O
listed	O
in	O
Table	O
[	O
reference	O
]	O
.	O
	
Baselines	O
.	O
	
Baselines	O
were	O
run	O
with	O
the	O
same	O
architecture	O
and	O
hyperparameters	B-Method
as	O
the	O
CVT	B-Method
model	O
.	O
	
For	O
the	O
“	O
word	B-Method
dropout	I-Method
”	I-Method
model	I-Method
,	O
we	O
randomly	O
replace	O
words	O
in	O
the	O
input	O
sentence	O
with	O
a	O
REMOVED	O
token	O
with	O
probability	O
0.1	O
(	O
this	O
value	O
worked	O
well	O
on	O
the	O
dev	B-Metric
sets	O
)	O
.	O
	
For	O
Virtual	B-Task
Adversarial	I-Task
Training	I-Task
,	O
we	O
set	O
the	O
norm	O
of	O
the	O
perturbation	O
to	O
be	O
1.5	O
for	O
CCG	B-Task
,	O
1.0	O
for	O
Dependency	B-Task
Parsing	I-Task
,	O
and	O
0.5	O
for	O
the	O
other	O
tasks	O
(	O
these	O
values	O
worked	O
best	O
on	O
the	O
dev	B-Metric
sets	O
)	O
.	O
	
Otherwise	O
,	O
the	O
implementation	O
is	O
as	O
described	O
in	O
miyato2016adversarial	O
;	O
we	O
based	O
our	O
implementation	O
off	O
of	O
their	O
code	O
.	O
	
We	O
were	O
unable	O
to	O
successfully	O
apply	O
VAT	B-Method
to	O
machine	B-Task
translation	I-Task
,	O
perhaps	O
because	O
the	O
student	O
is	O
provided	O
hard	O
targets	O
for	O
that	O
task	O
.	O
	
For	O
ELMo	B-Method
,	O
we	O
applied	O
dropout	B-Method
to	O
the	O
ELMo	B-Method
embeddings	O
before	O
they	O
are	O
incorporated	O
into	O
the	O
rest	O
of	O
the	O
model	O
.	O
	
When	O
training	O
the	O
multi	B-Method
-	I-Method
task	I-Method
ELMo	I-Method
model	O
,	O
each	O
prediction	B-Method
module	I-Method
has	O
its	O
own	O
set	O
of	O
softmax	O
-	O
normalized	O
weights	O
(	O
in	O
peters2018deep	O
)	O
for	O
the	O
ELMo	B-Method
emeddings	O
going	O
into	O
the	O
task	O
-	O
specific	O
prediction	B-Method
modules	I-Method
.	O
	
All	O
tasks	O
share	O
the	O
same	O
weights	O
for	O
the	O
ELMo	B-Method
embeddings	O
going	O
into	O
the	O
shared	B-Method
Bi	I-Method
-	I-Method
LSTM	I-Method
encoder	I-Method
.	O
	
appendix	O
:	O
CVT	B-Method
for	O
Image	B-Task
Recognition	I-Task
	
Although	O
the	O
focus	O
of	O
our	O
work	O
is	O
on	O
NLP	B-Task
,	O
we	O
also	O
applied	O
CVT	B-Method
to	O
image	B-Task
recognition	I-Task
and	O
found	O
it	O
performs	O
competitively	O
with	O
existing	O
methods	O
.	O
	
Most	O
of	O
the	O
semi	B-Method
-	I-Method
supervised	I-Method
image	I-Method
recognition	I-Method
approaches	I-Method
we	O
compare	O
against	O
rely	O
on	O
the	O
inputs	O
being	O
continuous	O
,	O
so	O
they	O
would	O
be	O
difficult	O
to	O
apply	O
to	O
text	O
.	O
	
More	O
specifically	O
,	O
consistency	B-Method
regularization	I-Method
methods	I-Method
sajjadi2016regularization	O
,	O
laine2016temporal	O
,	O
miyato2017virtual	O
rely	O
on	O
adding	O
continuous	O
noise	O
and	O
applying	O
image	O
-	O
specific	O
transformations	O
like	O
cropping	O
to	O
inputs	O
,	O
GANs	B-Method
salimans2016improved	O
,	O
wei2018improving	O
are	O
very	O
difficult	O
to	O
train	O
on	O
text	O
due	O
to	O
its	O
discrete	O
nature	O
,	O
and	O
mixup	O
zhang2017mixup	O
,	O
verma2018manifold	O
requires	O
a	O
way	O
of	O
smoothly	O
interpolating	O
between	O
different	O
inputs	O
.	O
	
Approach	O
.	O
	
Our	O
image	B-Method
recognition	I-Method
models	I-Method
are	O
based	O
on	O
Convolutional	B-Method
Neural	I-Method
Networks	I-Method
,	O
which	O
produce	O
a	O
set	O
of	O
features	O
from	O
an	O
image	O
.	O
	
The	O
first	O
two	O
dimensions	O
of	O
index	O
into	O
the	O
spatial	O
coordinates	O
of	O
feature	O
vectors	O
and	O
is	O
the	O
size	O
of	O
the	O
feature	O
vectors	O
.	O
	
For	O
shallower	B-Method
CNNs	I-Method
,	O
a	O
particular	O
feature	O
vector	O
corresponds	O
to	O
a	O
region	O
of	O
the	O
input	O
image	O
.	O
	
For	O
example	O
,	O
would	O
be	O
a	O
-	O
dimensional	O
vector	O
of	O
features	O
extracted	O
from	O
the	O
upper	O
left	O
corner	O
.	O
	
For	O
deeper	B-Method
CNNs	I-Method
,	O
a	O
particular	O
feature	O
vector	O
would	O
be	O
extracted	O
from	O
the	O
whole	O
image	O
,	O
but	O
still	O
only	O
use	O
a	O
“	O
region	O
”	O
of	O
the	O
representations	O
from	O
an	O
earlier	O
layer	O
.	O
	
The	O
CNNs	B-Method
in	O
our	O
experiments	O
are	O
all	O
in	O
the	O
first	O
category	O
.	O
	
The	O
primary	O
prediction	B-Method
layers	I-Method
of	O
our	O
CNNs	B-Method
take	O
as	O
input	O
the	O
mean	O
of	O
over	O
the	O
first	O
two	O
dimensions	O
,	O
which	O
results	O
in	O
a	O
-	O
dimensional	O
vector	O
that	O
is	O
fed	O
into	O
a	O
softmax	B-Method
layer	I-Method
:	O
We	O
add	O
auxiliary	B-Method
prediction	I-Method
layers	I-Method
to	O
the	O
top	O
of	O
the	O
CNN	B-Method
.	O
	
The	O
th	O
layer	O
takes	O
a	O
single	O
feature	O
vector	O
as	O
input	O
:	O
Data	O
.	O
	
We	O
evaluated	O
our	O
models	O
on	O
the	O
CIFAR	O
-	O
10	O
krizhevsky2009learning	O
dataset	O
.	O
	
Following	O
previous	O
work	O
,	O
we	O
make	O
the	O
datasets	O
semi	B-Task
-	I-Task
supervised	I-Task
by	O
only	O
using	O
the	O
provided	O
labels	O
for	O
a	O
subset	O
of	O
the	O
examples	O
in	O
the	O
training	O
set	O
;	O
the	O
rest	O
are	O
treated	O
as	O
unlabeled	O
examples	O
.	O
	
Model	O
.	O
	
We	O
use	O
the	O
convolutional	B-Method
neural	I-Method
network	I-Method
from	O
miyato2017virtual	O
,	O
adapting	O
their	O
TensorFlow	B-Method
implementation	I-Method
.	O
	
Their	O
model	O
contains	O
9	O
convolutional	B-Method
layers	I-Method
and	O
2	O
max	B-Method
pooling	I-Method
layers	I-Method
.	O
	
See	O
Appendix	O
D	O
of	O
Miyato	O
et	O
al	O
.	O
	
’s	O
paper	O
for	O
more	O
details	O
.	O
	
We	O
add	O
36	O
auxiliary	O
softmax	O
layers	O
to	O
the	O
collection	O
of	O
feature	O
vectors	O
produced	O
by	O
the	O
CNN	B-Method
.	O
	
Each	O
auxiliary	B-Method
layer	I-Method
sees	O
a	O
patch	O
of	O
the	O
image	O
ranging	O
in	O
size	O
from	O
pixels	O
(	O
the	O
corner	O
)	O
to	O
pixels	O
(	O
the	O
center	O
)	O
of	O
the	O
pixel	O
images	O
.	O
	
For	O
some	O
experiments	O
,	O
we	O
combine	O
CVT	B-Method
with	O
standard	O
consistency	B-Method
regularization	I-Method
by	O
adding	O
a	O
perturbation	O
(	O
e.g.	O
,	O
a	O
small	O
random	O
vector	O
)	O
to	O
the	O
student	O
’s	O
inputs	O
when	O
computing	O
.	O
	
Results	O
.	O
	
The	O
results	O
are	O
shown	O
in	O
Table	O
[	O
reference	O
]	O
.	O
	
Unsurprisingly	O
,	O
adding	O
continuous	O
noise	O
to	O
the	O
inputs	O
works	O
much	O
better	O
with	O
images	O
,	O
where	O
the	O
inputs	O
are	O
naturally	O
continuous	O
,	O
than	O
with	O
language	O
.	O
	
Therefore	O
we	O
see	O
much	O
better	O
results	O
from	O
VAT	B-Method
on	O
semi	B-Task
-	I-Task
supervised	I-Task
CIFAR	I-Task
-	I-Task
10	I-Task
compared	O
to	O
on	O
our	O
NLP	B-Task
tasks	I-Task
.	O
	
However	O
,	O
we	O
still	O
find	O
incorporating	O
CVT	B-Method
improves	O
over	O
models	O
without	O
CVT	B-Method
.	O
	
Our	O
CVT	B-Method
+	O
VAT	B-Method
models	I-Method
are	O
competitive	O
with	O
current	O
start	O
-	O
of	O
-	O
the	O
-	O
art	O
approaches	O
.	O
	
We	O
found	O
the	O
gains	O
from	O
CVT	B-Method
are	O
larger	O
when	O
no	O
data	B-Task
augmentation	I-Task
is	O
applied	O
,	O
perhaps	O
because	O
random	O
translations	O
of	O
the	O
input	O
expose	O
the	O
model	O
to	O
different	O
“	O
views	O
”	O
in	O
a	O
similar	O
manner	O
as	O
with	O
CVT	B-Method
.	O
	
appendix	O
:	O
Negative	O
Results	O
	
We	O
briefly	O
describe	O
a	O
few	O
ideas	O
we	O
implemented	O
that	O
did	O
not	O
seem	O
to	O
be	O
effective	O
in	O
initial	O
experiments	O
.	O
	
Note	O
these	O
findings	O
are	O
from	O
early	O
one	O
-	O
off	O
experiments	O
.	O
	
We	O
did	O
not	O
pursue	O
them	O
further	O
after	O
our	O
first	O
attempts	O
did	O
not	O
pan	O
out	O
,	O
so	O
it	O
is	O
possible	O
that	O
some	O
of	O
these	O
approaches	O
could	O
be	O
effective	O
with	O
the	O
proper	O
adjustments	O
and	O
tuning	O
.	O
	
Hard	O
vs	O
soft	O
targets	O
:	O
Classic	O
self	B-Method
-	I-Method
training	I-Method
algorithms	I-Method
train	O
the	O
student	B-Method
model	I-Method
with	O
one	O
-	O
hot	O
“	O
hard	O
”	O
targets	O
corresponding	O
to	O
the	O
teacher	O
	
’s	O
highest	O
probability	O
prediction	O
.	O
	
In	O
our	O
experiments	O
,	O
this	O
decreased	O
performance	O
compared	O
to	O
using	O
soft	O
targets	O
.	O
	
This	O
finding	O
is	O
consistent	O
with	O
research	O
on	O
knowledge	B-Task
distillation	I-Task
hinton2015distilling	O
,	O
furlanello2018born	O
where	O
soft	O
targets	O
also	O
work	O
notably	O
better	O
than	O
hard	O
targets	O
.	O
	
Confidence	B-Method
thresholding	I-Method
:	O
Classic	O
self	B-Method
-	I-Method
training	I-Method
often	O
only	O
trains	O
the	O
student	O
on	O
a	O
subset	O
of	O
the	O
unlabeled	O
examples	O
on	O
which	O
the	O
teacher	O
has	O
confident	O
predictions	O
(	O
i.e.	O
,	O
the	O
output	O
distribution	O
has	O
low	O
entropy	O
)	O
.	O
	
We	O
tried	O
both	O
“	O
hard	O
”	O
(	O
where	O
the	O
student	O
ignores	O
low	O
-	O
confidence	O
examples	O
)	O
and	O
“	O
soft	O
”	O
(	O
where	O
examples	O
are	O
weighted	O
according	O
to	O
the	O
teacher	O
	
’s	O
confidence	O
)	O
versions	O
of	O
this	O
for	O
training	O
our	O
models	O
,	O
but	O
they	O
did	O
not	O
seem	O
to	O
improve	O
performance	O
.	O
	
Mean	O
	
Teacher	O
:	O
	
The	O
Mean	B-Method
Teacher	I-Method
method	I-Method
	
tarvainen2017weight	O
tracks	O
an	O
exponential	B-Method
moving	I-Method
average	I-Method
(	O
EMA	B-Method
)	O
of	O
model	O
weights	O
,	O
which	O
are	O
used	O
to	O
produce	O
targets	O
for	O
the	O
students	O
.	O
	
The	O
idea	O
is	O
that	O
these	O
targets	O
may	O
be	O
better	O
quality	O
due	O
to	O
a	O
self	O
-	O
ensembling	O
effect	O
.	O
	
However	O
,	O
we	O
found	O
this	O
approach	O
to	O
have	O
little	O
to	O
no	O
benefit	O
in	O
our	O
experiments	O
,	O
although	O
using	O
EMA	B-Method
model	O
weights	O
at	O
test	O
time	O
did	O
improve	O
results	O
slightly	O
.	O
	
Purely	O
supervised	O
CVT	B-Method
	
:	O
Lastly	O
,	O
we	O
explored	O
adding	O
cross	O
-	O
view	O
losses	O
to	O
purely	O
supervised	B-Method
classifiers	I-Method
.	O
	
We	O
hoped	O
that	O
adding	O
auxiliary	O
softmax	O
layers	O
with	O
different	O
views	O
of	O
the	O
input	O
would	O
act	O
as	O
a	O
regularizer	O
on	O
the	O
model	O
.	O
	
However	O
,	O
we	O
found	O
little	O
to	O
no	O
benefit	O
from	O
this	O
approach	O
.	O
	
This	O
negative	O
result	O
suggests	O
that	O
the	O
gains	O
from	O
CVT	B-Method
are	O
from	O
the	O
improved	O
semi	B-Method
-	I-Method
supervised	I-Method
learning	I-Method
mechanism	I-Method
,	O
not	O
the	O
additional	O
prediction	B-Method
layers	I-Method
regularizing	I-Method
the	O
model	O
.	O
	
Skip	B-Task
-	I-Task
gram	I-Task
Language	I-Task
Modeling	I-Task
Using	O
Sparse	B-Method
Non	I-Method
-	I-Method
negative	I-Method
Matrix	I-Method
Probability	I-Method
Estimation	I-Method
	
section	O
:	O
Abstract	O
	
We	O
present	O
a	O
novel	O
family	O
of	O
language	B-Method
model	I-Method
	
(	O
LM	B-Method
)	I-Method
estimation	I-Method
techniques	I-Method
named	O
Sparse	B-Method
Non	I-Method
-	I-Method
negative	I-Method
Matrix	I-Method
(	O
SNM	B-Method
)	O
estimation	O
.	O
	
A	O
first	O
set	O
of	O
experiments	O
empirically	O
evaluating	O
it	O
on	O
the	O
One	B-Material
Billion	I-Material
Word	I-Material
Benchmark	I-Material
[	O
reference	O
]	O
shows	O
that	O
SNM	B-Method
n	I-Method
-	I-Method
gram	I-Method
LMs	I-Method
perform	O
almost	O
as	O
well	O
as	O
the	O
well	O
-	O
established	O
Kneser	B-Method
-	I-Method
Ney	I-Method
(	O
KN	B-Method
)	O
models	O
.	O
	
When	O
using	O
skip	B-Method
-	O
gram	O
features	O
the	O
models	O
are	O
able	O
to	O
match	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
recurrent	B-Method
neural	I-Method
network	I-Method
(	O
RNN	B-Method
)	O
LMs	O
;	O
combining	O
the	O
two	O
modeling	B-Method
techniques	I-Method
yields	O
the	O
best	O
known	O
result	O
on	O
the	O
benchmark	O
.	O
	
The	O
computational	B-Metric
advantages	O
of	O
SNM	B-Method
over	O
both	O
maximum	B-Method
entropy	I-Method
and	O
RNN	B-Method
LM	O
estimation	O
are	O
probably	O
its	O
main	O
strength	O
,	O
promising	O
an	O
approach	O
that	O
has	O
the	O
same	O
flexibility	O
in	O
combining	O
arbitrary	O
features	O
effectively	O
and	O
yet	O
should	O
scale	O
to	O
very	O
large	O
amounts	O
of	O
data	O
as	O
gracefully	O
as	O
n	B-Method
-	I-Method
gram	I-Method
LMs	I-Method
do	O
.	O
	
section	O
:	O
Introduction	O
	
A	O
statistical	B-Method
language	I-Method
model	I-Method
estimates	O
probability	O
values	O
P	O
(	O
W	O
)	O
for	O
strings	O
of	O
words	O
W	O
in	O
a	O
vocabulary	O
V	O
whose	O
size	O
is	O
in	O
the	O
tens	O
,	O
hundreds	O
of	O
thousands	O
and	O
sometimes	O
even	O
millions	O
.	O
	
Typically	O
the	O
string	O
W	O
is	O
broken	O
into	O
sentences	O
,	O
or	O
other	O
segments	O
such	O
as	O
utterances	O
in	O
automatic	B-Task
speech	I-Task
recognition	I-Task
,	O
which	O
are	O
often	O
assumed	O
to	O
be	O
conditionally	O
independent	O
;	O
we	O
will	O
assume	O
that	O
W	O
is	O
such	O
a	O
segment	O
,	O
or	O
sentence	O
.	O
	
Estimating	B-Task
full	I-Task
sentence	I-Task
language	I-Task
models	I-Task
is	O
computationally	O
hard	O
if	O
one	O
seeks	O
a	O
properly	O
normalized	B-Method
probability	I-Method
model	I-Method
1	O
over	O
strings	O
of	O
words	O
of	O
finite	O
length	O
in	O
[	O
reference	O
]	O
	
We	O
note	O
that	O
in	O
some	O
practical	O
systems	O
the	O
constraint	O
on	O
using	O
a	O
properly	O
normalized	O
language	O
V	O
*	O
.	O
	
A	O
simple	O
and	O
sufficient	O
way	O
to	O
ensure	O
proper	O
normalization	O
of	O
the	O
model	O
is	O
to	O
decompose	O
the	O
sentence	O
probability	O
according	O
to	O
the	O
chain	B-Method
rule	I-Method
and	O
make	O
sure	O
that	O
the	O
end	O
-	O
of	O
-	O
sentence	O
symbol	O
<	O
	
/	O
s	O
	
>	O
is	O
predicted	O
with	O
non	O
-	O
zero	O
probability	O
in	O
any	O
context	O
.	O
	
With	O
W	O
=	O
w	O
1	O
,	O
w	O
2	O
,	O
.	O
.	O
.	O
,	O
w	O
n	O
we	O
get	O
:	O
	
P	O
(	O
w	O
i	O
|w	O
1	O
,	O
w	O
2	O
,	O
.	O
.	O
.	O
,	O
w	O
i−1	O
)	O
	
Since	O
the	O
parameter	O
space	O
of	O
P	O
(	O
w	O
k	O
|w	O
1	O
,	O
w	O
2	O
,	O
.	O
.	O
.	O
,	O
w	O
k−1	O
)	O
is	O
too	O
large	O
,	O
the	O
language	B-Method
model	I-Method
is	O
forced	O
to	O
put	O
the	O
context	O
W	O
k−1	O
=	O
w	O
1	O
,	O
w	O
2	O
,	O
.	O
.	O
.	O
	
,	O
w	O
k−1	O
into	O
an	O
equivalence	O
class	O
determined	O
by	O
a	O
function	O
Φ	O
(	O
W	O
k−1	O
)	O
.	O
	
As	O
a	O
result	O
,	O
	
Research	O
in	O
language	B-Task
modeling	I-Task
consists	O
of	O
finding	O
appropriate	O
equivalence	B-Method
classifiers	I-Method
Φ	I-Method
and	O
methods	O
to	O
estimate	O
P	O
(	O
w	O
k	O
|Φ	O
(	O
W	O
k−1	O
)	O
)	O
.	O
	
The	O
most	O
successful	O
paradigm	O
in	O
language	B-Task
modeling	I-Task
uses	O
the	O
(	O
n	B-Task
−	I-Task
1	I-Task
)-	I-Task
gram	I-Task
equivalence	I-Task
classification	I-Task
,	O
that	O
is	O
,	O
defines	O
Φ	O
(	O
W	O
k−1	O
)	O
.	O
	
=	O
	
w	O
k−n	O
+	O
1	O
,	O
w	O
k−n	O
+	O
2	O
,	O
.	O
.	O
.	O
,	O
w	O
k−1	O
	
Once	O
the	O
form	O
Φ	O
(	O
W	O
k−1	O
)	O
is	O
specified	O
,	O
only	O
the	O
problem	O
of	O
estimating	O
P	O
(	O
w	O
k	O
|Φ	O
(	O
W	O
k−1	O
)	O
)	O
from	O
training	O
data	O
remains	O
.	O
	
section	O
:	O
Perplexity	B-Metric
as	O
a	O
Measure	O
of	O
Language	B-Metric
Model	I-Metric
Quality	I-Metric
	
A	O
statistical	B-Method
language	I-Method
model	I-Method
can	O
be	O
evaluated	O
by	O
how	O
well	O
it	O
predicts	O
a	O
string	O
of	O
symbols	O
W	O
t	O
-	O
commonly	O
referred	O
to	O
as	O
test	O
data	O
-	O
generated	O
by	O
the	O
source	O
to	O
be	O
modeled	O
.	O
	
A	O
commonly	O
used	O
quality	B-Metric
measure	I-Metric
for	O
a	O
given	O
model	O
M	O
is	O
related	O
to	O
the	O
entropy	O
of	O
the	O
underlying	O
source	O
and	O
was	O
introduced	O
under	O
the	O
name	O
of	O
perplexity	B-Metric
(	O
PPL	B-Metric
)	O
:	O
	
For	O
an	O
excellent	O
discussion	O
on	O
the	O
use	O
of	O
perplexity	B-Metric
in	O
statistical	B-Task
language	I-Task
modeling	I-Task
,	O
as	O
well	O
as	O
various	O
estimates	O
for	O
the	O
entropy	O
of	O
English	O
the	O
reader	O
is	O
referred	O
to	O
[	O
reference	O
]	O
,	O
Section	O
8.4	O
,	O
pages	O
141	O
-	O
142	O
and	O
the	O
additional	O
reading	O
suggested	O
in	O
Section	O
8.5	O
of	O
the	O
same	O
book	O
.	O
	
model	O
is	O
side	O
-	O
stepped	O
at	O
a	O
gain	O
in	O
modeling	B-Metric
power	I-Metric
and	O
simplicity	B-Metric
.	O
	
Very	O
likely	O
,	O
not	O
all	O
words	O
in	O
the	O
test	O
string	O
W	O
t	O
are	O
part	O
of	O
the	O
language	O
model	O
vocabulary	O
.	O
	
It	O
is	O
common	O
practice	O
to	O
map	O
all	O
words	O
that	O
are	O
out	O
-	O
of	O
-	O
vocabulary	O
to	O
a	O
distinguished	O
unknown	O
word	O
symbol	O
,	O
and	O
report	O
the	O
out	O
-	O
of	O
-	O
vocabulary	O
(	O
OOV	B-Metric
)	I-Metric
rate	I-Metric
on	O
test	O
data	O
-	O
the	O
rate	O
at	O
which	O
one	O
encounters	O
OOV	O
words	O
in	O
the	O
test	O
string	O
W	O
tas	O
yet	O
another	O
language	B-Metric
model	I-Metric
performance	I-Metric
metric	I-Metric
besides	O
perplexity	B-Metric
.	O
	
Usually	O
the	O
unknown	O
word	O
is	O
assumed	O
to	O
be	O
part	O
of	O
the	O
language	B-Method
model	I-Method
vocabulary	I-Method
-	O
open	B-Method
vocabulary	I-Method
language	I-Method
models	I-Method
-	O
and	O
its	O
occurrences	O
are	O
counted	O
in	O
the	O
language	O
model	O
perplexity	B-Metric
calculation	O
,	O
Eq	O
.	O
	
(	O
3	O
)	O
.	O
	
A	O
situation	O
less	O
common	O
in	O
practice	O
is	O
that	O
of	O
closed	B-Method
vocabulary	I-Method
language	I-Method
models	I-Method
where	O
all	O
words	O
in	O
the	O
test	O
data	O
will	O
always	O
be	O
part	O
of	O
the	O
vocabulary	O
V.	O
	
section	O
:	O
Skip	B-Task
-	I-Task
gram	I-Task
Language	I-Task
Modeling	I-Task
	
Recently	O
,	O
neural	B-Method
network	I-Method
(	O
NN	B-Method
)	O
smoothing	O
[	O
reference	O
]	O
,	O
[	O
reference	O
]	O
,	O
[	O
reference	O
]	O
,	O
and	O
in	O
particular	O
recurrent	B-Method
neural	I-Method
networks	I-Method
[	O
reference	O
]	O
(	O
RNN	B-Method
)	O
have	O
shown	O
excellent	O
performance	O
in	O
language	B-Task
modeling	I-Task
[	O
reference	O
]	O
.	O
Their	O
excellent	O
performance	O
is	O
attributed	O
to	O
a	O
combination	O
of	O
leveraging	O
long	O
-	O
distance	O
context	O
,	O
and	O
training	O
a	O
vector	B-Method
representation	I-Method
for	O
words	O
.	O
	
Another	O
simple	O
way	O
of	O
leveraging	O
long	O
distance	O
context	O
is	O
to	O
use	O
skip	B-Method
-	O
grams	O
.	O
	
In	O
our	O
approach	O
,	O
a	O
skip	B-Method
-	O
gram	O
feature	O
extracted	O
from	O
the	O
context	O
W	O
k−1	O
is	O
characterized	O
by	O
the	O
tuple	O
(	O
r	O
,	O
s	O
,	O
a	O
)	O
where	O
:	O
	
•	O
	
r	O
denotes	O
number	O
of	O
remote	O
context	O
words	O
•	O
	
s	O
denotes	O
the	O
number	O
of	O
skipped	O
words	O
	
•	O
	
a	O
denotes	O
the	O
number	O
of	O
adjacent	O
context	O
words	O
relative	O
to	O
the	O
target	O
word	O
w	O
k	O
being	O
predicted	O
.	O
	
For	O
example	O
,	O
in	O
the	O
sentence	O
,	O
<	O
S	O
>	O
	
The	O
quick	O
brown	O
fox	O
jumps	O
over	O
the	O
lazy	O
dog	O
<	O
	
/	O
S	O
	
>	O
	
a	O
(	O
1	O
,	O
2	O
,	O
3	O
)	O
skip	B-Method
-	O
gram	O
feature	O
for	O
the	O
target	O
word	O
dog	O
is	O
:	O
[	O
brown	O
skip	B-Method
-	O
2	O
over	O
the	O
lazy	O
]	O
	
For	O
performance	O
reasons	O
,	O
it	O
is	O
recommended	O
to	O
limit	O
s	O
and	O
to	O
limit	O
either	O
(	O
r	O
+	O
a	O
)	O
or	O
limit	O
both	O
r	O
and	O
s	O
;	O
not	O
setting	O
any	O
limits	O
will	O
result	O
in	O
events	O
containing	O
a	O
set	O
of	O
skip	B-Method
-	O
gram	O
features	O
whose	O
total	O
representation	O
size	O
is	O
quintic	O
in	O
the	O
length	O
of	O
the	O
sentence	O
.	O
	
We	O
configure	O
the	O
skip	B-Method
-	O
gram	O
feature	O
extractor	O
to	O
produce	O
all	O
features	O
f	O
,	O
defined	O
by	O
the	O
equivalence	O
class	O
Φ	O
(	O
W	O
k−1	O
)	O
,	O
that	O
meet	O
constraints	O
on	O
the	O
minimum	O
and	O
maximum	O
values	O
for	O
:	O
	
•	O
the	O
number	O
of	O
context	O
words	O
used	O
r	O
+	O
a	O
;	O
	
•	O
the	O
number	O
of	O
remote	O
words	O
r	O
;	O
	
•	O
the	O
number	O
of	O
adjacent	O
words	O
a	O
;	O
	
•	O
the	O
skip	B-Method
length	O
s.	O
	
We	O
also	O
allow	O
the	O
option	O
of	O
not	O
including	O
the	O
exact	O
value	O
of	O
s	O
in	O
the	O
feature	B-Method
representation	I-Method
;	O
this	O
may	O
help	O
with	O
smoothing	B-Task
by	O
sharing	O
counts	O
for	O
various	O
skip	B-Method
features	O
.	O
	
Tied	O
skip	B-Method
-	O
gram	O
features	O
will	O
look	O
like	O
:	O
[	O
curiousity	O
skip	B-Method
-	O
	
*	O
the	O
cat	O
]	O
	
In	O
order	O
to	O
build	O
a	O
good	O
probability	B-Method
estimate	I-Method
for	O
the	O
target	O
word	O
w	O
k	O
in	O
a	O
context	O
W	O
k−1	O
we	O
need	O
a	O
way	O
of	O
combining	O
an	O
arbitrary	O
number	O
of	O
skip	B-Method
-	O
gram	O
features	O
f	O
k−1	O
,	O
which	O
do	O
not	O
fall	O
into	O
a	O
simple	O
hierarchy	O
like	O
regular	O
n	O
-	O
gram	O
features	O
.	O
	
The	O
following	O
section	O
describes	O
a	O
simple	O
,	O
yet	O
novel	O
approach	O
for	O
combining	O
such	O
predictors	O
in	O
a	O
way	O
that	O
is	O
computationally	O
easy	O
,	O
scales	O
up	O
gracefully	O
to	O
large	O
amounts	O
of	O
data	O
and	O
as	O
it	O
turns	O
out	O
is	O
also	O
very	O
effective	O
from	O
a	O
modeling	O
point	O
of	O
view	O
.	O
	
section	O
:	O
Sparse	B-Method
Non	I-Method
-	I-Method
negative	I-Method
Matrix	I-Method
Modeling	O
	
section	O
:	O
Model	O
definition	O
	
In	O
the	O
Sparse	B-Method
Non	I-Method
-	I-Method
negative	I-Method
Matrix	I-Method
(	O
SNM	B-Method
)	O
paradigm	O
,	O
we	O
represent	O
the	O
training	O
data	O
as	O
a	O
sequence	O
of	O
events	O
E	O
=	O
e	O
1	O
,	O
e	O
2	O
,	O
...	O
where	O
each	O
event	O
e	O
∈	O
E	O
consists	O
of	O
a	O
sparse	O
non	O
-	O
negative	O
feature	O
vector	O
f	O
and	O
a	O
sparse	O
non	O
-	O
negative	O
target	O
word	O
vector	O
	
t.	O
	
Both	O
vectors	O
are	O
binary	O
-	O
valued	O
,	O
indicating	O
the	O
presence	O
or	O
absence	O
of	O
a	O
feature	O
or	O
target	O
words	O
,	O
respectively	O
.	O
	
Hence	O
,	O
the	O
training	O
data	O
consists	O
of	O
|E||P	O
os	O
(	O
f	O
)	O
|	O
positive	O
and	O
|E||P	O
os	O
(	O
f	O
)	O
	
|	O
(	O
|V|	O
−	O
1	O
)	O
negative	O
training	O
examples	O
,	O
where	O
P	O
os	O
(	O
f	O
)	O
denotes	O
the	O
number	O
of	O
positive	O
elements	O
in	O
the	O
vector	O
f	O
.	O
	
A	O
language	B-Method
model	I-Method
is	O
represented	O
by	O
a	O
non	B-Method
-	I-Method
negative	I-Method
matrix	I-Method
M	I-Method
that	O
,	O
when	O
applied	O
to	O
a	O
given	O
feature	O
vector	O
f	O
,	O
produces	O
a	O
dense	O
prediction	O
vector	O
y	O
:	O
	
Upon	O
evaluation	O
,	O
we	O
normalize	O
y	O
such	O
that	O
we	O
end	O
up	O
with	O
a	O
conditional	B-Method
probability	I-Method
distribution	I-Method
P	I-Method
M	I-Method
(	O
t|f	O
)	O
for	O
a	O
model	O
M.	O
	
For	O
each	O
word	O
w	O
∈	O
V	O
that	O
corresponds	O
to	O
index	O
j	O
in	O
t	O
,	O
and	O
its	O
feature	O
vector	O
f	O
that	O
is	O
defined	O
by	O
the	O
equivalence	O
class	O
Φ	O
applied	O
to	O
the	O
history	O
h	O
(	O
w	O
)	O
of	O
that	O
word	O
in	O
a	O
text	O
,	O
the	O
conditional	O
probability	O
P	O
M	O
(	O
w|Φ	O
(	O
h	O
(	O
w	O
)	O
)	O
)	O
then	O
becomes	O
:	O
	
For	O
convenience	O
,	O
we	O
will	O
write	O
P	O
(	O
t	O
j	O
|f	O
)	O
instead	O
of	O
P	O
M	O
(	O
t	O
j	O
|f	O
)	O
in	O
the	O
rest	O
of	O
the	O
paper	O
.	O
	
As	O
required	O
by	O
the	O
denominator	O
in	O
Eq	O
.	O
	
(	O
5	O
)	O
,	O
this	O
computation	O
involves	O
summing	O
over	O
all	O
of	O
the	O
present	O
features	O
for	O
the	O
entire	O
vocabulary	O
.	O
	
However	O
,	O
if	O
we	O
precompute	O
the	O
row	O
sums	O
	
|V|	O
	
u=1	O
M	O
iu	O
and	O
store	O
them	O
together	O
with	O
the	O
model	O
,	O
the	O
evaluation	O
can	O
be	O
done	O
very	O
efficiently	O
in	O
only	O
|P	O
	
os	O
(	O
f	O
)	O
	
|	O
time	O
.	O
	
Moreover	O
,	O
only	O
the	O
positive	O
entries	O
in	O
M	O
i	O
need	O
to	O
be	O
considered	O
,	O
making	O
the	O
range	O
of	O
the	O
sum	O
sparse	O
.	O
	
section	O
:	O
Adjustment	O
function	O
and	O
metafeatures	O
	
We	O
let	O
the	O
entries	O
of	O
M	O
be	O
a	O
slightly	O
modified	O
version	O
of	O
the	O
relative	O
frequencies	O
:	O
	
where	O
C	O
is	O
a	O
feature	O
-	O
target	O
count	O
matrix	O
,	O
computed	O
over	O
the	O
entire	O
training	O
corpus	O
and	O
A	O
(	O
i	O
,	O
j	O
)	O
is	O
a	O
real	O
-	O
valued	O
function	O
,	O
dubbed	O
adjustment	O
function	O
.	O
	
For	O
each	O
featuretarget	O
pair	O
(	O
f	O
i	O
,	O
t	O
j	O
)	O
,	O
the	O
adjustment	B-Method
function	I-Method
extracts	O
k	O
new	O
features	O
	
α	O
k	O
,	O
called	O
metafeatures	O
,	O
which	O
are	O
hashed	O
as	O
keys	O
to	O
store	O
corresponding	O
weights	O
θ	O
(	O
hash	O
(	O
α	O
k	O
)	O
)	O
in	O
a	O
huge	O
hash	O
table	O
.	O
	
To	O
limit	O
memory	O
usage	O
,	O
we	O
use	O
a	O
flat	O
hash	O
table	O
and	O
allow	O
collisions	O
,	O
although	O
this	O
has	O
the	O
potentially	O
undesirable	O
effect	O
of	O
tying	O
together	O
the	O
weights	O
of	O
different	O
metafeatures	O
.	O
	
Computing	O
the	O
adjustment	O
function	O
for	O
any	O
(	O
f	O
i	O
,	O
t	O
j	O
)	O
then	O
amounts	O
to	O
summing	O
the	O
weights	O
that	O
correspond	O
to	O
its	O
metafeatures	O
:	O
	
From	O
the	O
given	O
input	O
features	O
,	O
such	O
as	O
regular	O
n	O
-	O
grams	O
and	O
skip	B-Method
n	O
-	O
grams	O
,	O
we	O
construct	O
our	O
metafeatures	B-Method
as	O
conjunctions	O
of	O
any	O
or	O
all	O
of	O
the	O
following	O
elementary	O
metafeatures	O
:	O
	
•	O
feature	O
identity	O
,	O
e.g.	O
[	O
brown	O
skip	B-Method
-	O
2	O
over	O
the	O
lazy	O
]	O
	
•	O
feature	O
type	O
,	O
e.g.	O
(	O
1	O
,	O
2	O
,	O
3	O
)	O
skip	B-Method
-	O
grams	O
	
•	O
	
feature	O
count	O
C	O
	
i	O
	
*	O
	
•	O
target	O
identity	O
,	O
e.g.	O
dog	O
	
where	O
we	O
reused	O
the	O
example	O
from	O
Section	O
2	O
.	O
	
Note	O
that	O
the	O
seemingly	O
absent	O
feature	O
-	O
target	O
identity	O
is	O
represented	O
by	O
the	O
conjunction	O
of	O
the	O
feature	O
identity	O
and	O
the	O
target	O
identity	O
.	O
	
Since	O
the	O
metafeatures	O
may	O
involve	O
the	O
feature	O
count	O
and	O
feature	O
-	O
target	O
count	O
,	O
in	O
the	O
rest	O
of	O
the	O
paper	O
we	O
will	O
write	O
α	O
k	O
(	O
i	O
,	O
j	O
,	O
C	O
i	O
	
*	O
,	O
C	O
ij	O
)	O
.	O
	
This	O
will	O
become	O
important	O
later	O
when	O
we	O
discuss	O
leave	B-Task
-	I-Task
one	I-Task
-	I-Task
out	I-Task
training	I-Task
.	O
	
Each	O
elementary	O
metafeature	O
is	O
joined	O
with	O
the	O
others	O
to	O
form	O
more	O
complex	O
metafeatures	O
which	O
in	O
turn	O
are	O
joined	O
with	O
all	O
the	O
other	O
elementary	O
and	O
complex	O
metafeatures	O
,	O
ultimately	O
ending	O
up	O
with	O
all	O
2	O
5	O
−	O
1	O
possible	O
combinations	O
of	O
metafeatures	O
.	O
	
Before	O
they	O
are	O
joined	O
,	O
count	O
metafeatures	O
are	O
bucketed	O
together	O
according	O
to	O
their	O
(	O
floored	O
)	O
log	O
2	O
value	O
.	O
	
As	O
this	O
effectively	O
puts	O
the	O
lowest	O
count	O
values	O
,	O
of	O
which	O
there	O
are	O
many	O
,	O
into	O
a	O
different	O
bucket	O
,	O
we	O
optionally	O
introduce	O
a	O
second	O
(	O
ceiled	O
)	O
bucket	O
to	O
assure	O
smoother	O
transitions	O
.	O
	
Both	O
buckets	O
are	O
then	O
weighted	O
according	O
to	O
the	O
log	O
2	O
fraction	O
lost	O
by	O
the	O
corresponding	O
rounding	B-Method
operation	I-Method
.	O
	
Note	O
that	O
if	O
we	O
apply	O
double	O
bucketing	O
to	O
both	O
the	O
feature	O
and	O
feature	O
-	O
target	O
count	O
,	O
the	O
amount	O
of	O
metafeatures	O
per	O
input	O
feature	O
becomes	O
2	O
7	O
−	O
1	O
.	O
	
We	O
will	O
come	O
back	O
to	O
these	O
metafeatures	O
in	O
Section	O
4.4	O
where	O
we	O
examine	O
their	O
individual	O
effect	O
on	O
the	O
model	O
.	O
	
section	O
:	O
Loss	B-Method
function	I-Method
	
Estimating	O
a	O
model	O
	
M	O
corresponds	O
to	O
finding	O
optimal	O
weights	O
	
θ	O
k	O
for	O
all	O
the	O
metafeatures	O
for	O
all	O
events	O
in	O
such	O
a	O
way	O
that	O
the	O
average	O
loss	O
over	O
all	O
events	O
between	O
the	O
target	O
vector	O
t	O
and	O
the	O
prediction	O
vector	O
y	O
is	O
minimized	O
,	O
according	O
to	O
some	O
loss	B-Method
function	I-Method
L.	O
	
The	O
most	O
natural	O
choice	O
of	O
loss	O
function	O
is	O
one	O
that	O
is	O
based	O
on	O
the	O
multinomial	O
distribution	O
.	O
	
That	O
is	O
,	O
we	O
consider	O
t	O
to	O
be	O
multinomially	O
distributed	O
with	O
|V|	O
possible	O
outcomes	O
.	O
	
The	O
loss	O
function	O
L	O
	
multi	O
then	O
is	O
:	O
	
Another	O
possibility	O
is	O
the	O
loss	B-Method
function	I-Method
based	O
on	O
the	O
Poisson	B-Method
distribution	I-Method
2	O
:	O
we	O
consider	O
each	O
t	O
j	O
in	O
t	O
to	O
be	O
Poisson	O
distributed	O
with	O
parameter	O
	
y	O
j	O
.	O
	
The	O
conditional	O
probability	O
of	O
P	O
P	O
oisson	O
(	O
t|f	O
)	O
	
then	O
is	O
:	O
	
and	O
the	O
corresponding	O
Poisson	B-Method
loss	I-Method
function	I-Method
is	O
:	O
	
where	O
we	O
dropped	O
the	O
last	O
term	O
,	O
since	O
t	O
j	O
is	O
binary	O
-	O
valued	O
3	O
.	O
	
Although	O
this	O
choice	O
is	O
not	O
obvious	O
in	O
the	O
context	O
of	O
language	B-Task
modeling	I-Task
,	O
it	O
is	O
well	O
suited	O
to	O
gradient	B-Method
-	I-Method
based	I-Method
optimization	I-Method
and	O
,	O
as	O
we	O
will	O
see	O
,	O
the	O
experimental	O
results	O
are	O
in	O
fact	O
excellent	O
.	O
	
section	O
:	O
Model	B-Task
Estimation	I-Task
	
The	O
adjustment	O
function	O
is	O
learned	O
by	O
applying	O
stochastic	B-Method
gradient	I-Method
descent	I-Method
on	O
the	O
loss	O
function	O
.	O
	
That	O
is	O
,	O
for	O
each	O
feature	O
-	O
target	O
pair	O
(	O
f	O
i	O
,	O
t	O
j	O
)	O
	
in	O
each	O
event	O
we	O
need	O
to	O
update	O
the	O
parameters	O
of	O
the	O
metafeatures	O
by	O
calculating	O
the	O
gradient	O
with	O
respect	O
to	O
the	O
adjustment	O
function	O
.	O
	
For	O
the	O
multinomial	B-Task
loss	I-Task
,	O
this	O
gradient	O
is	O
:	O
	
The	O
problem	O
with	O
this	O
update	B-Method
rule	I-Method
is	O
that	O
we	O
need	O
to	O
sum	O
over	O
the	O
entire	O
vocabulary	O
V	O
in	O
the	O
denominator	O
.	O
	
For	O
most	O
features	O
f	O
i	O
,	O
this	O
is	O
not	O
a	O
big	O
deal	O
as	O
C	O
iu	O
=	O
0	O
,	O
but	O
some	O
features	O
occur	O
with	O
many	O
if	O
not	O
all	O
targets	O
e.g.	O
the	O
empty	O
feature	O
for	O
unigrams	O
.	O
	
Although	O
we	O
might	O
be	O
able	O
to	O
get	O
away	O
with	O
this	O
by	O
re	O
-	O
using	O
these	O
sums	O
and	O
applying	O
them	O
to	O
many	O
/	O
all	O
events	O
in	O
a	O
mini	O
batch	O
,	O
we	O
chose	O
to	O
work	O
with	O
the	O
Poisson	O
loss	O
in	O
our	O
first	O
implementation	O
.	O
	
If	O
we	O
calculate	O
the	O
gradient	O
of	O
the	O
Poisson	O
loss	O
,	O
we	O
get	O
the	O
following	O
:	O
	
If	O
we	O
were	O
to	O
apply	O
this	O
gradient	O
to	O
each	O
(	O
positive	O
and	O
negative	O
)	O
training	O
example	O
,	O
it	O
would	O
be	O
computationally	O
too	O
expensive	O
,	O
because	O
even	O
though	O
the	O
second	O
term	O
is	O
zero	O
for	O
all	O
the	O
negative	O
training	O
examples	O
,	O
the	O
first	O
term	O
needs	O
to	O
be	O
computed	O
for	O
all	O
|E||P	O
os	O
(	O
f	O
)	O
||V|	O
training	O
examples	O
.	O
	
However	O
,	O
since	O
the	O
first	O
term	O
does	O
not	O
depend	O
on	O
y	O
	
j	O
,	O
we	O
are	O
able	O
to	O
distribute	O
the	O
updates	O
for	O
the	O
negative	O
examples	O
over	O
the	O
positive	O
ones	O
by	O
adding	O
in	O
gradients	O
for	O
a	O
fraction	O
of	O
the	O
events	O
where	O
f	O
i	O
=	O
1	O
,	O
but	O
	
t	O
j	O
=	O
0	O
.	O
	
In	O
particular	O
,	O
instead	O
of	O
adding	O
the	O
term	O
f	O
i	O
	
M	O
ij	O
,	O
we	O
add	O
f	O
i	O
t	O
	
j	O
	
which	O
lets	O
us	O
update	O
the	O
gradient	O
only	O
on	O
positive	O
examples	O
.	O
	
We	O
note	O
that	O
this	O
update	O
is	O
only	O
strictly	O
correct	O
for	O
batch	B-Task
training	I-Task
,	O
and	O
not	O
for	O
online	B-Task
training	I-Task
since	O
M	O
ij	O
changes	O
after	O
each	O
update	O
.	O
	
Nonetheless	O
,	O
we	O
found	O
this	O
to	O
yield	O
good	O
results	O
as	O
well	O
as	O
seriously	O
reducing	O
the	O
computational	B-Metric
cost	I-Metric
.	O
	
The	O
online	O
gradient	O
applied	O
to	O
each	O
training	O
example	O
then	O
becomes	O
:	O
	
which	O
is	O
non	O
-	O
zero	O
only	O
for	O
positive	O
training	O
examples	O
,	O
hence	O
speeding	O
up	O
computation	B-Task
by	O
a	O
factor	O
of	O
|V|.	O
	
These	O
aggregated	O
gradients	O
however	O
do	O
not	O
allow	O
us	O
to	O
use	O
additional	O
data	O
to	O
train	O
the	O
adjustment	B-Method
function	I-Method
,	O
since	O
they	O
tie	O
the	O
update	B-Task
computation	I-Task
to	O
the	O
relative	O
frequencies	O
	
.	O
	
Instead	O
,	O
we	O
have	O
to	O
resort	O
to	O
leave	B-Method
-	I-Method
one	I-Method
-	I-Method
out	I-Method
training	I-Method
to	O
prevent	O
the	O
model	O
from	O
overfitting	O
the	O
training	O
data	O
.	O
	
We	O
do	O
this	O
by	O
excluding	O
the	O
event	O
,	O
generating	O
the	O
gradients	O
,	O
from	O
the	O
counts	O
used	O
to	O
compute	O
those	O
gradients	O
.	O
	
So	O
,	O
for	O
each	O
positive	O
example	O
	
(	O
f	O
i	O
,	O
t	O
j	O
)	O
of	O
each	O
event	O
e	O
=	O
(	O
f	O
,	O
t	O
)	O
,	O
we	O
compute	O
the	O
gradient	O
,	O
excluding	O
f	O
i	O
from	O
C	O
	
i	O
	
*	O
	
and	O
f	O
	
i	O
	
t	O
	
j	O
from	O
C	O
ij	O
.	O
	
For	O
the	O
gradients	O
of	O
the	O
negative	O
examples	O
on	O
the	O
other	O
hand	O
we	O
only	O
exclude	O
f	O
i	O
from	O
C	O
	
i	O
	
*	O
	
and	O
we	O
leave	O
C	O
ij	O
untouched	O
,	O
since	O
here	O
we	O
did	O
not	O
observe	O
t	O
j	O
.	O
	
In	O
order	O
to	O
keep	O
the	O
aggregate	O
computation	O
of	O
the	O
gradients	O
for	O
the	O
negative	O
examples	O
,	O
we	O
distribute	O
them	O
uniformly	O
over	O
all	O
the	O
positive	O
examples	O
with	O
the	O
same	O
feature	O
;	O
each	O
of	O
the	O
C	O
ij	O
positive	O
examples	O
will	O
then	O
compute	O
the	O
gradient	O
of	O
	
negative	O
examples	O
.	O
	
To	O
summarize	O
,	O
when	O
we	O
do	O
leave	B-Task
-	I-Task
one	I-Task
-	I-Task
out	I-Task
training	I-Task
we	O
apply	O
the	O
following	O
gradient	B-Method
update	I-Method
rule	I-Method
on	O
all	O
positive	O
training	O
examples	O
:	O
	
where	O
y	O
′	O
j	O
is	O
the	O
product	O
of	O
leaving	O
one	O
out	O
for	O
all	O
the	O
relevant	O
features	O
i.e.	O
	
section	O
:	O
Experiments	O
	
section	O
:	O
Corpus	O
:	O
One	B-Material
Billion	I-Material
Benchmark	I-Material
	
Our	O
experimental	O
setup	O
used	O
the	O
One	B-Material
Billion	I-Material
Word	I-Material
Benchmark	I-Material
corpus	O
4	O
made	O
available	O
by	O
[	O
reference	O
]	O
.	O
For	O
completeness	O
,	O
here	O
is	O
a	O
short	O
description	O
of	O
the	O
corpus	O
,	O
containing	O
only	O
monolingual	O
English	O
data	O
:	O
	
•	O
	
Total	O
number	O
of	O
training	O
tokens	O
is	O
about	O
0.8	O
billion	O
	
•	O
	
The	O
vocabulary	O
provided	O
consists	O
of	O
793471	O
words	O
including	O
sentence	O
boundary	O
markers	O
<	O
S	O
>	O
,	O
<	O
\S	O
>	O
,	O
and	O
was	O
constructed	O
by	O
discarding	O
all	O
words	O
with	O
count	O
below	O
3	O
	
•	O
	
Words	O
outside	O
of	O
the	O
vocabulary	O
were	O
mapped	O
to	O
<	O
UNK	O
>	O
token	O
,	O
also	O
part	O
of	O
the	O
vocabulary	O
	
•	O
	
Sentence	O
order	O
was	O
randomized	O
•	O
	
The	O
test	O
data	O
consisted	O
of	O
159658	O
words	O
(	O
without	O
counting	O
the	O
sentence	O
beginning	O
marker	O
<	O
S	O
>	O
which	O
is	O
never	O
predicted	O
by	O
the	O
language	B-Method
model	I-Method
)	O
	
•	O
	
The	O
out	B-Metric
-	I-Metric
of	I-Metric
-	I-Metric
vocabulary	I-Metric
(	O
OoV	B-Metric
)	I-Metric
rate	I-Metric
on	O
the	O
test	O
set	O
was	O
0.28	O
%	O
.	O
	
section	O
:	O
SNM	B-Method
for	O
n	B-Method
-	I-Method
gram	I-Method
LMs	I-Method
	
When	O
trained	O
using	O
solely	O
n	O
-	O
gram	O
features	O
,	O
SNM	B-Method
comes	O
very	O
close	O
to	O
the	O
stateof	O
-	O
the	O
-	O
art	O
Kneser	B-Method
-	I-Method
Ney	I-Method
[	O
reference	O
]	O
	
(	O
KN	B-Method
)	O
models	O
.	O
	
Table	O
1	O
shows	O
that	O
Katz	B-Method
[	O
reference	O
]	O
performs	O
considerably	O
worse	O
than	O
both	O
SNM	B-Method
and	O
KN	B-Method
which	O
only	O
differ	O
by	O
about	O
5	O
%	O
.	O
	
When	O
we	O
interpolate	O
these	O
two	O
models	O
linearly	O
,	O
the	O
added	O
gain	O
is	O
only	O
about	O
1	O
%	O
,	O
suggesting	O
that	O
they	O
are	O
approximately	O
modeling	O
the	O
same	O
things	O
.	O
	
The	O
difference	O
between	O
KN	B-Method
and	O
SNM	B-Method
becomes	O
smaller	O
when	O
we	O
increase	O
the	O
size	O
of	O
the	O
context	O
,	O
going	O
from	O
5	O
%	O
for	O
5	O
-	O
grams	O
to	O
3	O
%	O
for	O
8	O
-	O
grams	O
,	O
which	O
indicates	O
that	O
SNM	B-Method
is	O
better	O
suited	O
to	O
a	O
large	O
number	O
of	O
features	O
.	O
	
section	O
:	O
Sparse	B-Method
Non	I-Method
-	I-Method
negative	I-Method
Modeling	I-Method
for	O
Skip	B-Task
n	I-Task
-	I-Task
grams	I-Task
	
When	O
we	O
incorporate	O
skip	B-Method
-	O
gram	O
features	O
,	O
we	O
can	O
either	O
build	O
a	O
'	O
pure	B-Method
'	I-Method
skip	I-Method
-	I-Method
gram	I-Method
SNM	I-Method
that	O
contains	O
no	O
regular	O
n	O
-	O
gram	O
features	O
,	O
except	O
for	O
unigrams	O
,	O
and	O
interpolate	O
this	O
model	O
with	O
KN	B-Method
,	O
or	O
we	O
can	O
build	O
a	O
single	O
SNM	B-Method
that	O
has	O
both	O
the	O
regular	O
ngram	O
features	O
and	O
the	O
skip	B-Method
-	O
gram	O
features	O
.	O
	
We	O
compared	O
the	O
two	O
approaches	O
by	O
choosing	O
skip	B-Method
-	O
gram	O
features	O
that	O
can	O
be	O
considered	O
the	O
skip	B-Method
-	O
equivalent	O
of	O
5	O
-	O
grams	O
	
i.e.	O
they	O
contain	O
at	O
most	O
4	O
words	O
.	O
	
In	O
particular	O
,	O
we	O
used	O
skip	B-Method
-	O
gram	O
features	O
where	O
the	O
remote	O
span	O
is	O
limited	O
to	O
at	O
most	O
3	O
words	O
for	O
skips	O
of	O
length	O
between	O
1	O
and	O
3	O
	
(	O
r	O
=	O
	
[	O
1	O
.	O
	
section	O
:	O
]	O
)	O
.	O
	
We	O
then	O
built	O
a	O
model	O
that	O
uses	O
both	O
these	O
features	O
and	O
regular	O
5	O
-	O
grams	O
(	O
SNM5	B-Method
-	I-Method
skip	I-Method
)	O
,	O
as	O
well	O
as	O
one	O
that	O
only	O
uses	O
the	O
skip	B-Method
-	O
gram	O
features	O
(	O
SNM5	B-Method
-	I-Method
skip	I-Method
(	O
no	B-Method
n	I-Method
-	I-Method
grams	I-Method
)	O
)	O
.	O
	
section	O
:	O
Model	O
	
Num	O
.	O
	
Params	B-Metric
PPL	I-Metric
SNM5	I-Method
-	I-Method
skip	I-Method
(	O
no	O
n	O
-	O
grams	O
)	O
	
61	O
B	O
69.8	O
SNM5	B-Method
-	I-Method
skip	I-Method
62	O
B	O
54.2	O
KN5	B-Method
+	O
SNM5	B-Method
-	O
skip	B-Method
	
(	O
no	O
n	O
-	O
grams	O
)	O
	
56.5	O
KN5	B-Method
+	O
SNM5	B-Method
-	O
skip	B-Method
	
53.6	O
Table	O
2	O
:	O
Number	O
of	O
parameters	O
(	O
in	O
billions	O
)	O
and	O
perplexity	B-Metric
results	O
for	O
SNM5	B-Method
-	O
skip	B-Method
models	O
with	O
and	O
without	O
n	O
-	O
grams	O
,	O
as	O
well	O
as	O
perplexity	B-Metric
results	O
for	O
the	O
interpolation	B-Method
with	O
KN5	B-Method
.	O
	
As	O
it	O
turns	O
out	O
and	O
as	O
can	O
be	O
seen	O
from	O
Table	O
2	O
,	O
it	O
is	O
better	O
to	O
incorporate	O
all	O
the	O
features	O
into	O
one	O
single	O
SNM	B-Method
model	I-Method
than	O
to	O
interpolate	O
with	O
a	O
KN	B-Method
5	O
-	O
gram	O
model	O
(	O
KN5	B-Method
)	O
.	O
	
Interpolating	O
the	O
all	O
-	O
in	O
-	O
one	O
SNM5	B-Method
-	O
skip	B-Method
with	O
KN5	B-Method
yields	O
almost	O
no	O
additional	O
gain	O
.	O
	
The	O
best	O
SNM	B-Method
results	O
so	O
far	O
(	O
SNM10	B-Method
-	I-Method
skip	I-Method
)	O
were	O
achieved	O
using	O
10	B-Method
-	I-Method
grams	I-Method
,	O
together	O
with	O
untied	O
skip	B-Method
features	O
of	O
at	O
most	O
5	O
words	O
with	O
a	O
skip	B-Method
of	O
exactly	O
1	O
word	O
(	O
s	O
=	O
1	O
,	O
r	O
+	O
a	O
=	O
	
[	O
1	O
.	O
	
section	O
:	O
]	O
)	O
.	O
	
This	O
mixture	O
of	O
rich	O
short	O
-	O
distance	O
and	O
shallow	O
long	O
-	O
distance	O
features	O
enables	O
the	O
model	O
to	O
achieve	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
results	O
,	O
as	O
can	O
be	O
seen	O
in	O
Table	O
3	O
.	O
	
When	O
we	O
compare	O
the	O
perplexity	B-Metric
of	O
this	O
model	O
with	O
the	O
state	O
-	O
of	O
-	O
the	O
art	O
RNN	B-Method
results	O
in	O
[	O
reference	O
]	O
,	O
the	O
difference	O
is	O
only	O
3	O
%	O
.	O
	
Moreover	O
,	O
although	O
our	O
model	O
has	O
more	O
parameters	O
than	O
the	O
RNN	B-Method
(	O
33	O
vs	O
20	O
billion	O
)	O
,	O
training	B-Task
takes	O
about	O
a	O
tenth	O
of	O
the	O
time	O
(	O
24	O
hours	O
vs	O
240	O
hours	O
)	O
.	O
	
Interestingly	O
,	O
when	O
we	O
interpolate	O
the	O
two	O
models	O
,	O
we	O
have	O
an	O
additional	O
gain	O
of	O
20	O
%	O
,	O
and	O
as	O
far	O
as	O
we	O
know	O
,	O
the	O
perplexity	B-Metric
of	O
41.3	O
is	O
already	O
the	O
best	O
ever	O
reported	O
on	O
this	O
database	O
,	O
beating	O
the	O
previous	O
best	O
by	O
6	O
%	O
[	O
reference	O
]	O
.	O
	
Finally	O
,	O
when	O
we	O
optimize	O
interpolation	O
weights	O
over	O
all	O
models	O
in	O
[	O
reference	O
]	O
,	O
including	O
SNM5	B-Method
-	I-Method
skip	I-Method
and	O
SNM10	B-Method
-	I-Method
skip	I-Method
,	O
the	O
contribution	O
of	O
the	O
other	O
models	O
as	O
well	O
as	O
the	O
perplexity	B-Metric
reduction	O
is	O
negligible	O
,	O
as	O
can	O
be	O
seen	O
in	O
Table	O
3	O
,	O
which	O
also	O
summarizes	O
the	O
perplexity	B-Metric
results	O
for	O
each	O
of	O
the	O
individual	O
models	O
.	O
	
section	O
:	O
Ablation	B-Task
Experiments	O
	
To	O
find	O
out	O
how	O
much	O
,	O
if	O
anything	O
at	O
all	O
,	O
each	O
metafeature	O
contributes	O
to	O
the	O
adjustment	O
function	O
,	O
we	O
ran	O
a	O
series	O
of	O
ablation	O
experiments	O
in	O
which	O
we	O
ablated	O
one	O
metafeature	O
at	O
a	O
time	O
.	O
	
When	O
we	O
experimented	O
on	O
SNM5	B-Method
,	O
we	O
found	O
,	O
unsurprisingly	O
,	O
that	O
the	O
most	O
important	O
metafeature	O
is	O
the	O
feature	O
-	O
target	O
count	O
.	O
	
At	O
first	O
glance	O
,	O
it	O
does	O
not	O
seem	O
to	O
matter	O
much	O
whether	O
the	O
counts	O
are	O
stored	O
in	O
1	O
or	O
2	O
buckets	O
,	O
but	O
the	O
second	O
bucket	O
really	O
starts	O
to	O
pay	O
off	O
for	O
models	O
with	O
a	O
large	O
number	O
of	O
singleton	O
features	O
e.g.	O
SNM10	O
-	O
skip	B-Method
5	O
.	O
	
This	O
is	O
not	O
the	O
case	O
for	O
the	O
feature	O
counts	O
,	O
where	O
having	O
a	O
single	O
bucket	O
is	O
always	O
better	O
,	O
although	O
in	O
general	O
the	O
feature	O
counts	O
do	O
not	O
contribute	O
much	O
.	O
	
In	O
any	O
case	O
,	O
feature	O
counts	O
are	O
definitely	O
the	O
least	O
important	O
for	O
the	O
model	O
.	O
	
The	O
remaining	O
metafeatures	O
all	O
contribute	O
more	O
or	O
less	O
equally	O
,	O
all	O
of	O
which	O
can	O
be	O
seen	O
in	O
Table	O
4	O
.	O
	
section	O
:	O
Related	O
Work	O
	
SNM	B-Method
estimation	I-Method
is	O
closely	O
related	O
to	O
all	O
n	B-Method
-	I-Method
gram	I-Method
LM	I-Method
smoothing	I-Method
techniques	I-Method
that	O
rely	O
on	O
mixing	O
relative	O
frequencies	O
at	O
various	O
orders	O
.	O
	
Unlike	O
most	O
of	O
those	O
,	O
it	O
combines	O
the	O
predictors	O
at	O
various	O
orders	O
without	O
relying	O
on	O
a	O
hierarchical	O
nesting	O
of	O
the	O
contexts	O
,	O
setting	O
it	O
closer	O
to	O
the	O
family	O
of	O
maximum	B-Method
entropy	I-Method
(	O
ME	B-Task
)	O
[	O
reference	O
]	O
,	O
or	O
exponential	B-Method
models	I-Method
.	O
	
We	O
are	O
not	O
the	O
first	O
ones	O
to	O
highlight	O
the	O
effectiveness	O
of	O
skip	B-Method
n	O
-	O
grams	O
at	O
capturing	O
dependencies	O
across	O
longer	O
contexts	O
,	O
similar	O
to	O
RNN	B-Method
LMs	O
;	O
previous	O
such	O
results	O
were	O
reported	O
in	O
[	O
reference	O
]	O
.	O
[	O
reference	O
]	O
	
attempts	O
to	O
capture	O
long	O
range	O
dependencies	O
in	O
language	O
where	O
the	O
skip	B-Method
n	O
-	O
grams	O
are	O
identified	O
using	O
a	O
left	B-Method
-	I-Method
to	I-Method
-	I-Method
right	I-Method
syntactic	I-Method
parser	I-Method
.	O
	
Approaches	O
such	O
as	O
[	O
reference	O
]	O
leverage	O
latent	O
semantic	O
information	O
,	O
whereas	O
[	O
reference	O
]	O
integrates	O
both	O
syntactic	B-Method
and	I-Method
topic	I-Method
-	I-Method
based	I-Method
modeling	I-Method
in	O
a	O
unified	O
approach	O
.	O
	
The	O
speed	O
-	O
ups	O
to	O
ME	B-Task
,	O
and	O
RNN	B-Method
LM	O
training	O
provided	O
by	O
hierarchically	O
predicting	O
words	O
at	O
the	O
output	O
layer	O
[	O
reference	O
]	O
,	O
and	O
subsampling	O
[	O
reference	O
]	O
still	O
require	O
updates	O
that	O
are	O
linear	O
in	O
the	O
vocabulary	O
size	O
times	O
the	O
number	O
of	O
words	O
in	O
the	O
training	O
data	O
,	O
whereas	O
the	O
SNM	B-Method
updates	I-Method
in	O
Eq	O
.	O
	
(	O
15	O
)	O
for	O
the	O
much	O
smaller	O
adjustment	O
function	O
eliminate	O
the	O
dependency	O
on	O
the	O
vocabulary	O
size	O
.	O
	
Scaling	O
up	O
RNN	B-Method
LM	O
training	O
is	O
described	O
in	O
[	O
reference	O
]	O
and	O
[	O
reference	O
]	O
.	O
	
The	O
computational	B-Metric
advantages	O
of	O
SNM	B-Method
over	O
both	O
Maximum	O
Entropy	O
and	O
RNN	B-Method
LM	O
estimation	O
are	O
probably	O
its	O
main	O
strength	O
,	O
promising	O
an	O
approach	O
that	O
has	O
the	O
same	O
flexibility	O
in	O
combining	O
arbitrary	O
features	O
effectively	O
and	O
yet	O
should	O
scale	O
to	O
very	O
large	O
amounts	O
of	O
data	O
as	O
gracefully	O
as	O
n	B-Method
-	I-Method
gram	I-Method
LMs	I-Method
do	O
.	O
	
section	O
:	O
	
section	O
:	O
Conclusions	O
and	O
Future	O
Work	O
	
We	O
have	O
presented	O
SNM	B-Method
,	O
a	O
new	O
family	O
of	O
LM	B-Method
estimation	I-Method
techniques	I-Method
.	O
	
A	O
first	O
empirical	O
evaluation	O
on	O
the	O
One	B-Material
Billion	I-Material
Word	I-Material
Benchmark	I-Material
[	O
reference	O
]	O
shows	O
that	O
SNM	B-Method
n	I-Method
-	I-Method
gram	I-Method
LMs	I-Method
perform	O
almost	O
as	O
well	O
as	O
the	O
well	O
-	O
established	O
KN	B-Method
models	O
.	O
	
When	O
using	O
skip	B-Method
-	O
gram	O
features	O
the	O
models	O
are	O
able	O
to	O
match	O
the	O
stat	O
-	O
of	O
-	O
the	O
-	O
art	O
RNN	B-Method
LMs	O
;	O
combining	O
the	O
two	O
modeling	B-Method
techniques	I-Method
yields	O
the	O
best	O
known	O
result	O
on	O
the	O
benchmark	O
.	O
	
Future	O
work	O
items	O
include	O
model	B-Task
pruning	I-Task
,	O
exploring	O
richer	O
features	O
similar	O
to	O
[	O
reference	O
]	O
,	O
as	O
well	O
as	O
richer	O
metafeatures	O
in	O
the	O
adjustment	B-Method
model	I-Method
,	O
mixing	O
SNM	B-Method
models	I-Method
trained	O
on	O
various	O
data	O
sources	O
such	O
that	O
they	O
perform	O
best	O
on	O
a	O
given	O
development	O
set	O
,	O
and	O
estimation	B-Method
techniques	I-Method
that	O
are	O
more	O
flexible	O
in	O
this	O
respect	O
.	O
	
section	O
:	O
	
Domain	B-Method
-	I-Method
Adversarial	I-Method
Training	I-Method
of	I-Method
Neural	I-Method
Networks	I-Method
	
section	O
:	O
Abstract	O
	
We	O
introduce	O
a	O
new	O
representation	B-Method
learning	I-Method
approach	I-Method
for	O
domain	B-Method
adaptation	I-Method
,	O
in	O
which	O
data	O
at	O
training	O
and	O
test	O
time	O
come	O
from	O
similar	O
but	O
different	O
distributions	O
.	O
	
Our	O
approach	O
is	O
directly	O
inspired	O
by	O
the	O
theory	O
on	O
domain	B-Method
adaptation	I-Method
suggesting	O
that	O
,	O
for	O
effective	O
domain	B-Task
transfer	I-Task
to	O
be	O
achieved	O
,	O
predictions	B-Task
must	O
be	O
made	O
based	O
on	O
features	O
that	O
can	O
not	O
discriminate	O
between	O
the	O
training	O
(	O
source	O
)	O
and	O
test	O
(	O
target	O
)	O
domains	O
.	O
	
The	O
approach	O
implements	O
this	O
idea	O
in	O
the	O
context	O
of	O
neural	B-Method
network	I-Method
architectures	I-Method
that	O
are	O
trained	O
on	O
labeled	O
data	O
from	O
the	O
source	O
domain	O
and	O
unlabeled	O
data	O
from	O
the	O
target	O
domain	O
(	O
no	O
labeled	O
target	O
-	O
domain	O
data	O
is	O
necessary	O
)	O
.	O
	
As	O
the	O
training	O
progresses	O
,	O
the	O
approach	O
promotes	O
the	O
emergence	O
of	O
features	O
that	O
are	O
(	O
i	O
)	O
discriminative	O
for	O
the	O
main	O
learning	B-Task
task	I-Task
on	O
the	O
source	O
domain	O
and	O
(	O
ii	O
)	O
indiscriminate	O
with	O
respect	O
to	O
the	O
shift	O
between	O
the	O
domains	O
.	O
	
We	O
show	O
that	O
this	O
adaptation	O
behaviour	O
can	O
be	O
achieved	O
in	O
almost	O
any	O
feed	B-Method
-	I-Method
forward	I-Method
model	I-Method
by	O
augmenting	O
it	O
with	O
few	O
standard	B-Method
layers	I-Method
and	O
a	O
new	O
gradient	B-Method
reversal	I-Method
layer	I-Method
.	O
	
The	O
resulting	O
augmented	B-Method
architecture	I-Method
can	O
be	O
trained	O
using	O
standard	B-Method
backpropagation	I-Method
and	O
stochastic	B-Method
gradient	I-Method
descent	I-Method
,	O
and	O
can	O
thus	O
be	O
implemented	O
with	O
little	O
effort	O
using	O
any	O
of	O
the	O
deep	B-Method
learning	I-Method
packages	I-Method
.	O
	
We	O
demonstrate	O
the	O
success	O
of	O
our	O
approach	O
for	O
two	O
distinct	O
classification	B-Task
problems	I-Task
(	O
document	B-Task
sentiment	I-Task
analysis	I-Task
and	O
image	B-Task
classification	I-Task
)	O
,	O
where	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
domain	B-Method
adaptation	I-Method
performance	O
on	O
standard	O
benchmarks	O
is	O
achieved	O
.	O
	
We	O
also	O
validate	O
the	O
approach	O
for	O
descriptor	B-Task
learning	I-Task
task	I-Task
in	O
the	O
context	O
of	O
person	B-Task
re	I-Task
-	I-Task
identification	I-Task
application	I-Task
.	O
	
section	O
:	O
Introduction	O
	
The	O
cost	O
of	O
generating	O
labeled	O
data	O
for	O
a	O
new	O
machine	B-Task
learning	I-Task
task	I-Task
is	O
often	O
an	O
obstacle	O
for	O
applying	O
machine	B-Method
learning	I-Method
methods	I-Method
.	O
	
In	O
particular	O
,	O
this	O
is	O
a	O
limiting	O
factor	O
for	O
the	O
further	O
progress	O
of	O
deep	B-Method
neural	I-Method
network	I-Method
architectures	I-Method
,	O
that	O
have	O
already	O
brought	O
impressive	O
advances	O
to	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
across	O
a	O
wide	O
variety	O
of	O
machine	B-Task
-	I-Task
learning	I-Task
tasks	I-Task
and	O
applications	O
.	O
	
For	O
problems	O
lacking	O
labeled	O
data	O
,	O
it	O
may	O
be	O
still	O
possible	O
to	O
obtain	O
training	O
sets	O
that	O
are	O
big	O
enough	O
for	O
training	O
large	B-Method
-	I-Method
scale	I-Method
deep	I-Method
models	I-Method
,	O
but	O
that	O
suffer	O
from	O
the	O
shift	O
in	O
data	O
distribution	O
from	O
the	O
actual	O
data	O
encountered	O
at	O
"	O
test	O
time	O
"	O
.	O
	
One	O
important	O
example	O
is	O
training	O
an	O
image	B-Method
classifier	I-Method
on	O
synthetic	O
or	O
semi	O
-	O
synthetic	O
images	O
,	O
which	O
may	O
come	O
in	O
abundance	O
and	O
be	O
fully	O
labeled	O
,	O
but	O
which	O
inevitably	O
have	O
a	O
distribution	O
that	O
is	O
different	O
from	O
real	O
images	O
[	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
.	O
	
Another	O
example	O
is	O
in	O
the	O
context	O
of	O
sentiment	B-Task
analysis	I-Task
in	O
written	B-Material
reviews	I-Material
,	O
where	O
one	O
might	O
have	O
labeled	O
data	O
for	O
reviews	O
of	O
one	O
type	O
of	O
product	O
(	O
e.g.	O
,	O
movies	O
)	O
,	O
while	O
having	O
the	O
need	O
to	O
classify	O
reviews	O
of	O
other	O
products	O
(	O
e.g.	O
,	O
books	B-Material
)	O
.	O
	
Learning	O
a	O
discriminative	B-Method
classifier	I-Method
or	O
other	O
predictor	O
in	O
the	O
presence	O
of	O
a	O
shift	O
between	O
training	O
and	O
test	O
distributions	O
is	O
known	O
as	O
domain	B-Method
adaptation	I-Method
(	O
DA	B-Method
)	O
.	O
	
The	O
proposed	O
approaches	O
build	O
mappings	O
between	O
the	O
source	O
(	O
training	O
-	O
time	O
)	O
and	O
the	O
target	O
(	O
test	O
-	O
time	O
)	O
domains	O
,	O
so	O
that	O
the	O
classifier	B-Method
learned	O
for	O
the	O
source	O
domain	O
can	O
also	O
be	O
applied	O
to	O
the	O
target	O
domain	O
,	O
when	O
composed	O
with	O
the	O
learned	O
mapping	O
between	O
domains	O
.	O
	
The	O
appeal	O
of	O
the	O
domain	B-Method
adaptation	I-Method
approaches	I-Method
is	O
the	O
ability	O
to	O
learn	O
a	O
mapping	O
between	O
domains	O
in	O
the	O
situation	O
when	O
the	O
target	O
domain	O
data	O
are	O
either	O
fully	O
unlabeled	O
(	O
unsupervised	B-Task
domain	I-Task
annotation	I-Task
)	O
or	O
have	O
few	O
labeled	O
samples	O
(	O
semi	O
-	O
supervised	O
domain	B-Method
adaptation	I-Method
)	O
.	O
	
Below	O
,	O
we	O
focus	O
on	O
the	O
harder	O
unsupervised	B-Task
case	I-Task
,	O
although	O
the	O
proposed	O
approach	O
(	O
domain	B-Method
-	I-Method
adversarial	I-Method
learning	I-Method
)	O
can	O
be	O
generalized	O
to	O
the	O
semi	B-Task
-	I-Task
supervised	I-Task
case	I-Task
rather	O
straightforwardly	O
.	O
	
Unlike	O
many	O
previous	O
papers	O
on	O
domain	B-Method
adaptation	I-Method
that	O
worked	O
with	O
fixed	B-Method
feature	I-Method
representations	I-Method
,	O
we	O
focus	O
on	O
combining	O
domain	B-Method
adaptation	I-Method
and	O
deep	B-Method
feature	I-Method
learning	I-Method
within	O
one	O
training	O
process	O
.	O
	
Our	O
goal	O
is	O
to	O
embed	O
domain	B-Method
adaptation	I-Method
into	O
the	O
process	O
of	O
learning	B-Task
representation	I-Task
,	O
so	O
that	O
the	O
final	O
classification	B-Task
decisions	I-Task
are	O
made	O
based	O
on	O
features	O
that	O
are	O
both	O
discriminative	O
and	O
invariant	O
to	O
the	O
change	O
of	O
domains	O
,	O
i.e.	O
,	O
have	O
the	O
same	O
or	O
very	O
similar	O
distributions	O
in	O
the	O
source	O
and	O
the	O
target	O
domains	O
.	O
	
In	O
this	O
way	O
,	O
the	O
obtained	O
feed	B-Method
-	I-Method
forward	I-Method
network	I-Method
can	O
be	O
applicable	O
to	O
the	O
target	O
domain	O
without	O
being	O
hindered	O
by	O
the	O
shift	O
between	O
the	O
two	O
domains	O
.	O
	
Our	O
approach	O
is	O
motivated	O
by	O
the	O
theory	O
on	O
domain	B-Method
adaptation	I-Method
[	O
reference	O
]	O
,	O
that	O
suggests	O
that	O
a	O
good	O
representation	O
for	O
cross	B-Task
-	I-Task
domain	I-Task
transfer	I-Task
is	O
one	O
for	O
which	O
an	O
algorithm	O
can	O
not	O
learn	O
to	O
identify	O
the	O
domain	O
of	O
origin	O
of	O
the	O
input	O
observation	O
.	O
	
We	O
thus	O
focus	O
on	O
learning	O
features	O
that	O
combine	O
(	O
	
i	O
)	O
discriminativeness	O
and	O
(	O
ii	O
)	O
domaininvariance	O
.	O
	
This	O
is	O
achieved	O
by	O
jointly	O
optimizing	O
the	O
underlying	O
features	O
as	O
well	O
as	O
two	O
discriminative	B-Method
classifiers	I-Method
operating	O
on	O
these	O
features	O
:	O
(	O
i	O
)	O
	
the	O
label	B-Method
predictor	I-Method
that	O
predicts	O
class	O
labels	O
and	O
is	O
used	O
both	O
during	O
training	O
and	O
at	O
test	O
time	O
and	O
(	O
ii	O
)	O
the	O
domain	B-Method
classifier	I-Method
that	O
discriminates	O
between	O
the	O
source	O
and	O
the	O
target	O
domains	O
during	O
training	O
.	O
	
While	O
the	O
parameters	O
of	O
the	O
classifiers	B-Method
are	O
optimized	O
in	O
order	O
to	O
minimize	O
their	O
error	O
on	O
the	O
training	O
set	O
,	O
the	O
parameters	O
of	O
the	O
underlying	O
deep	B-Method
feature	I-Method
mapping	I-Method
are	O
optimized	O
in	O
order	O
to	O
minimize	O
the	O
loss	O
of	O
the	O
label	B-Method
classifier	I-Method
and	O
to	O
maximize	O
the	O
loss	O
of	O
the	O
domain	B-Method
classifier	I-Method
.	O
	
The	O
latter	O
update	O
thus	O
works	O
adversarially	O
to	O
the	O
domain	B-Method
classifier	I-Method
,	O
and	O
it	O
encourages	O
domain	O
-	O
invariant	O
features	O
to	O
emerge	O
in	O
the	O
course	O
of	O
the	O
optimization	B-Task
.	O
	
Crucially	O
,	O
we	O
show	O
that	O
all	O
three	O
training	B-Method
processes	I-Method
can	O
be	O
embedded	O
into	O
an	O
appropriately	O
composed	O
deep	B-Method
feed	I-Method
-	I-Method
forward	I-Method
network	I-Method
,	O
called	O
domain	B-Method
-	I-Method
adversarial	I-Method
neural	I-Method
network	I-Method
(	O
DANN	B-Method
)	O
(	O
illustrated	O
by	O
Figure	O
1	O
,	O
page	O
12	O
)	O
that	O
uses	O
standard	O
layers	O
and	O
loss	O
functions	O
,	O
and	O
can	O
be	O
trained	O
using	O
standard	B-Method
backpropagation	I-Method
algorithms	O
based	O
on	O
stochastic	B-Method
gradient	I-Method
descent	I-Method
or	O
its	O
modifications	O
(	O
e.g.	O
,	O
SGD	B-Method
with	I-Method
momentum	I-Method
)	O
.	O
	
The	O
approach	O
is	O
generic	O
as	O
a	O
DANN	B-Method
version	O
can	O
be	O
created	O
for	O
almost	O
any	O
existing	O
feed	B-Method
-	I-Method
forward	I-Method
architecture	I-Method
that	O
is	O
trainable	O
by	O
backpropagation	B-Method
.	O
	
In	O
practice	O
,	O
the	O
only	O
non	O
-	O
standard	O
component	O
of	O
the	O
proposed	O
architecture	O
is	O
a	O
rather	O
trivial	O
gradient	B-Method
reversal	I-Method
layer	I-Method
that	O
leaves	O
the	O
input	O
unchanged	O
during	O
forward	B-Method
propagation	I-Method
and	O
reverses	O
the	O
gradient	O
by	O
multiplying	O
it	O
by	O
a	O
negative	O
scalar	O
during	O
the	O
backpropagation	O
.	O
	
We	O
provide	O
an	O
experimental	O
evaluation	O
of	O
the	O
proposed	O
domain	B-Method
-	I-Method
adversarial	I-Method
learning	I-Method
idea	I-Method
over	O
a	O
range	O
of	O
deep	B-Method
architectures	I-Method
and	O
applications	O
.	O
	
We	O
first	O
consider	O
the	O
simplest	O
DANN	B-Method
architecture	O
where	O
the	O
three	O
parts	O
(	O
label	B-Method
predictor	I-Method
,	O
domain	B-Method
classifier	I-Method
and	O
feature	B-Method
extractor	I-Method
)	O
are	O
linear	O
,	O
and	O
demonstrate	O
the	O
success	O
of	O
domain	B-Method
-	I-Method
adversarial	I-Method
learning	I-Method
for	O
such	O
architecture	O
.	O
	
The	O
evaluation	O
is	O
performed	O
for	O
synthetic	O
data	O
as	O
well	O
as	O
for	O
the	O
sentiment	B-Task
analysis	I-Task
problem	I-Task
in	O
natural	B-Task
language	I-Task
processing	I-Task
,	O
where	O
DANN	B-Method
improves	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
marginalized	B-Method
Stacked	I-Method
Autoencoders	I-Method
(	O
mSDA	B-Method
)	O
of	O
[	O
reference	O
]	O
on	O
the	O
common	B-Material
Amazon	I-Material
reviews	I-Material
benchmark	I-Material
.	O
	
We	O
further	O
evaluate	O
the	O
approach	O
extensively	O
for	O
an	O
image	B-Task
classification	I-Task
task	I-Task
,	O
and	O
present	O
results	O
on	O
traditional	O
deep	B-Method
learning	I-Method
image	O
data	O
sets	O
-	O
such	O
as	O
MNIST	O
[	O
reference	O
]	O
and	O
SVHN	O
[	O
reference	O
])-	O
as	O
well	O
as	O
on	O
Office	O
benchmarks	O
[	O
reference	O
]	O
,	O
where	O
domain	B-Method
-	I-Method
adversarial	I-Method
learning	I-Method
allows	O
obtaining	O
a	O
deep	B-Method
architecture	I-Method
that	O
considerably	O
improves	O
over	O
previous	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
accuracy	B-Metric
.	O
	
Finally	O
,	O
we	O
evaluate	O
domain	B-Method
-	I-Method
adversarial	I-Method
descriptor	I-Method
learning	I-Method
in	O
the	O
context	O
of	O
person	B-Task
re	I-Task
-	I-Task
identification	I-Task
application	I-Task
[	O
reference	O
]	O
,	O
where	O
the	O
task	O
is	O
to	O
obtain	O
good	O
pedestrian	B-Task
image	I-Task
descriptors	I-Task
that	O
are	O
suitable	O
for	O
retrieval	B-Task
and	I-Task
verification	I-Task
.	O
	
We	O
apply	O
domainadversarial	B-Method
learning	I-Method
,	O
as	O
we	O
consider	O
a	O
descriptor	B-Method
predictor	I-Method
trained	O
with	O
a	O
Siamese	B-Method
-	I-Method
like	I-Method
loss	I-Method
instead	O
of	O
the	O
label	B-Method
predictor	I-Method
trained	O
with	O
a	O
classification	B-Method
loss	I-Method
.	O
	
In	O
a	O
series	O
of	O
experiments	O
,	O
we	O
demonstrate	O
that	O
domain	B-Method
-	I-Method
adversarial	I-Method
learning	I-Method
can	O
improve	O
cross	B-Task
-	I-Task
data	I-Task
-	I-Task
set	I-Task
re	I-Task
-	I-Task
identification	I-Task
considerably	O
.	O
	
section	O
:	O
Related	O
work	O
	
The	O
general	O
approach	O
of	O
achieving	O
domain	B-Method
adaptation	I-Method
explored	O
under	O
many	O
facets	O
.	O
	
Over	O
the	O
years	O
,	O
a	O
large	O
part	O
of	O
the	O
literature	O
has	O
focused	O
mainly	O
on	O
linear	O
hypothesis	O
(	O
see	O
for	O
instance	O
[	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
.	O
More	O
recently	O
,	O
non	B-Method
-	I-Method
linear	I-Method
representations	I-Method
have	O
become	O
increasingly	O
studied	O
,	O
including	O
neural	B-Method
network	I-Method
representations	I-Method
[	O
reference	O
]	O
and	O
most	O
notably	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
mSDA	B-Method
	
[	O
reference	O
]	O
.	O
	
That	O
literature	O
has	O
mostly	O
focused	O
on	O
exploiting	O
the	O
principle	O
of	O
robust	B-Method
representations	I-Method
,	O
based	O
on	O
the	O
denoising	B-Method
autoencoder	I-Method
paradigm	I-Method
[	O
reference	O
]	O
.	O
	
Concurrently	O
,	O
multiple	O
methods	O
of	O
matching	O
the	O
feature	O
distributions	O
in	O
the	O
source	O
and	O
the	O
target	O
domains	O
have	O
been	O
proposed	O
for	O
unsupervised	O
domain	B-Method
adaptation	I-Method
.	O
	
Some	O
ap	O
-	O
proaches	O
perform	O
this	O
by	O
reweighing	O
or	O
selecting	O
samples	O
from	O
the	O
source	O
domain	O
[	O
reference	O
]	O
,	O
while	O
others	O
seek	O
an	O
explicit	O
feature	B-Method
space	I-Method
transformation	I-Method
that	O
would	O
map	O
source	O
distribution	O
into	O
the	O
target	O
one	O
[	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
)	O
.	O
	
An	O
important	O
aspect	O
of	O
the	O
distribution	B-Method
matching	I-Method
approach	I-Method
is	O
the	O
way	O
the	O
(	O
dis	O
)	O
similarity	O
between	O
distributions	O
is	O
measured	O
.	O
	
Here	O
,	O
one	O
popular	O
choice	O
is	O
matching	O
the	O
distribution	O
means	O
in	O
the	O
kernelreproducing	O
Hilbert	O
space	O
[	O
reference	O
]	O
,	O
whereas	O
[	O
reference	O
]	O
and	O
[	O
reference	O
]	O
map	O
the	O
principal	O
axes	O
associated	O
with	O
each	O
of	O
the	O
distributions	O
.	O
	
Our	O
approach	O
also	O
attempts	O
to	O
match	O
feature	O
space	O
distributions	O
,	O
however	O
this	O
is	O
accomplished	O
by	O
modifying	O
the	O
feature	B-Method
representation	I-Method
itself	O
rather	O
than	O
by	O
reweighing	O
or	O
geometric	B-Method
transformation	I-Method
.	O
	
Also	O
,	O
our	O
method	O
uses	O
a	O
rather	O
different	O
way	O
to	O
measure	O
the	O
disparity	O
between	O
distributions	O
based	O
on	O
their	O
separability	O
by	O
a	O
deep	B-Method
discriminatively	I-Method
-	I-Method
trained	I-Method
classifier	I-Method
.	O
	
Note	O
also	O
that	O
several	O
approaches	O
perform	O
transition	O
from	O
the	O
source	O
to	O
the	O
target	O
domain	O
[	O
reference	O
][	O
reference	O
]	O
by	O
changing	O
gradually	O
the	O
training	O
distribution	O
.	O
	
Among	O
these	O
methods	O
,	O
[	O
reference	O
]	O
does	O
this	O
in	O
a	O
"	O
deep	O
"	O
way	O
by	O
the	O
layerwise	B-Method
training	I-Method
of	O
a	O
sequence	O
of	O
deep	B-Method
autoencoders	I-Method
,	O
while	O
gradually	O
replacing	O
source	O
-	O
domain	O
samples	O
with	O
target	O
-	O
domain	O
samples	O
.	O
	
This	O
improves	O
over	O
a	O
similar	O
approach	O
of	O
[	O
reference	O
]	O
that	O
simply	O
trains	O
a	O
single	O
deep	B-Method
autoencoder	I-Method
for	O
both	O
domains	O
.	O
	
In	O
both	O
approaches	O
,	O
the	O
actual	O
classifier	B-Method
/	I-Method
predictor	I-Method
is	O
learned	O
in	O
a	O
separate	O
step	O
using	O
the	O
feature	B-Method
representation	I-Method
learned	O
by	O
autoencoder	B-Method
(	I-Method
s	I-Method
)	O
.	O
	
In	O
contrast	O
to	O
[	O
reference	O
][	O
reference	O
]	O
,	O
our	O
approach	O
performs	O
feature	B-Task
learning	I-Task
,	O
domain	B-Method
adaptation	I-Method
and	O
classifier	B-Task
learning	I-Task
jointly	O
,	O
in	O
a	O
unified	B-Method
architecture	I-Method
,	O
and	O
using	O
a	O
single	O
learning	B-Method
algorithm	I-Method
(	O
backpropagation	B-Method
)	O
.	O
	
We	O
therefore	O
argue	O
that	O
our	O
approach	O
is	O
simpler	O
(	O
both	O
conceptually	O
and	O
in	O
terms	O
of	O
its	O
implementation	O
)	O
.	O
	
Our	O
method	O
also	O
achieves	O
considerably	O
better	O
results	O
on	O
the	O
popular	O
Office	O
benchmark	O
.	O
	
While	O
the	O
above	O
approaches	O
perform	O
unsupervised	O
domain	B-Method
adaptation	I-Method
,	O
there	O
are	O
approaches	O
that	O
perform	O
supervised	O
domain	B-Method
adaptation	I-Method
by	O
exploiting	O
labeled	O
data	O
from	O
the	O
target	O
domain	O
.	O
	
In	O
the	O
context	O
of	O
deep	B-Method
feed	I-Method
-	I-Method
forward	I-Method
architectures	I-Method
,	O
such	O
data	O
can	O
be	O
used	O
to	O
"	O
fine	O
-	O
tune	O
"	O
the	O
network	O
trained	O
on	O
the	O
source	O
domain	O
[	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
.	O
Our	O
approach	O
does	O
not	O
require	O
labeled	O
target	O
-	O
domain	O
data	O
.	O
	
At	O
the	O
same	O
time	O
,	O
it	O
can	O
easily	O
incorporate	O
such	O
data	O
when	O
they	O
are	O
available	O
.	O
	
An	O
idea	O
related	O
to	O
ours	O
is	O
described	O
in	O
[	O
reference	O
]	O
.	O
	
While	O
their	O
goal	O
is	O
quite	O
different	O
(	O
building	O
generative	B-Method
deep	I-Method
networks	I-Method
that	O
can	O
synthesize	O
samples	O
)	O
,	O
the	O
way	O
they	O
measure	O
and	O
minimize	O
the	O
discrepancy	O
between	O
the	O
distribution	O
of	O
the	O
training	O
data	O
and	O
the	O
distribution	O
of	O
the	O
synthesized	O
data	O
is	O
very	O
similar	O
to	O
the	O
way	O
our	O
architecture	O
measures	O
and	O
minimizes	O
the	O
discrepancy	O
between	O
feature	O
distributions	O
for	O
the	O
two	O
domains	O
.	O
	
Moreover	O
,	O
the	O
authors	O
mention	O
the	O
problem	O
of	O
saturating	O
sigmoids	O
which	O
may	O
arise	O
at	O
the	O
early	O
stages	O
of	O
training	B-Task
due	O
to	O
the	O
significant	O
dissimilarity	O
of	O
the	O
domains	O
.	O
	
The	O
technique	O
they	O
use	O
to	O
circumvent	O
this	O
issue	O
(	O
the	O
"	O
adversarial	O
"	O
part	O
of	O
the	O
gradient	O
is	O
replaced	O
by	O
a	O
gradient	O
computed	O
with	O
respect	O
to	O
a	O
suitable	O
cost	O
)	O
is	O
directly	O
applicable	O
to	O
our	O
method	O
.	O
	
Also	O
,	O
recent	O
and	O
concurrent	O
reports	O
by	O
[	O
reference	O
]	O
focus	O
on	O
domain	B-Method
adaptation	I-Method
in	O
feed	B-Method
-	I-Method
forward	I-Method
networks	I-Method
.	O
	
Their	O
set	O
of	O
techniques	O
measures	O
and	O
minimizes	O
the	O
distance	B-Metric
between	O
the	O
data	O
distribution	O
means	O
across	O
domains	O
(	O
potentially	O
,	O
after	O
embedding	O
distributions	O
into	O
RKHS	B-Method
)	O
.	O
	
Their	O
approach	O
is	O
thus	O
different	O
from	O
our	O
idea	O
of	O
matching	O
distributions	O
by	O
making	O
them	O
indistinguishable	O
for	O
a	O
discriminative	B-Method
classifier	I-Method
.	O
	
Below	O
,	O
we	O
compare	O
our	O
approach	O
to	O
;	O
[	O
reference	O
]	O
on	O
the	O
Office	O
benchmark	O
.	O
	
Another	O
approach	O
to	O
deep	O
domain	B-Method
adaptation	I-Method
,	O
which	O
is	O
arguably	O
more	O
different	O
from	O
ours	O
,	O
has	O
been	O
developed	O
in	O
parallel	O
by	O
[	O
reference	O
]	O
.	O
	
From	O
a	O
theoretical	O
standpoint	O
,	O
our	O
approach	O
is	O
directly	O
derived	O
from	O
the	O
seminal	O
theoretical	O
works	O
of	O
	
[	O
reference	O
]	O
.	O
Indeed	O
,	O
DANN	B-Method
directly	O
optimizes	O
the	O
notion	O
of	O
H	O
-	O
divergence	O
.	O
	
We	O
do	O
note	O
the	O
work	O
of	O
[	O
reference	O
]	O
,	O
in	O
which	O
HMM	B-Method
representations	I-Method
are	O
learned	O
for	O
word	B-Task
tagging	I-Task
using	O
a	O
posterior	B-Method
regularizer	I-Method
that	O
is	O
also	O
inspired	O
by	O
	
Ben	O
-	O
David	O
et	O
al	O
.	O
's	O
work	O
.	O
	
In	O
addition	O
to	O
the	O
tasks	O
being	O
different	O
-	O
Huang	O
and	O
Yates	O
(	O
2012	O
)	O
focus	O
on	O
word	B-Task
tagging	I-Task
problems	I-Task
-	I-Task
,	O
we	O
would	O
argue	O
that	O
DANN	B-Method
learning	I-Metric
objective	I-Metric
more	O
closely	O
optimizes	O
the	O
H	O
-	O
divergence	O
,	O
with	O
Huang	O
and	O
Yates	O
(	O
2012	O
)	O
relying	O
on	O
cruder	O
approximations	O
for	O
efficiency	O
reasons	O
.	O
	
A	O
part	O
of	O
this	O
paper	O
has	O
been	O
published	O
as	O
a	O
conference	O
paper	O
[	O
reference	O
]	O
.	O
	
This	O
version	O
extends	O
[	O
reference	O
]	O
very	O
considerably	O
by	O
incorporating	O
the	O
report	O
[	O
reference	O
]	O
(	O
presented	O
as	O
part	O
of	O
the	O
Second	O
Workshop	O
on	O
Transfer	B-Task
and	I-Task
Multi	I-Task
-	I-Task
Task	I-Task
Learning	I-Task
)	O
,	O
which	O
brings	O
in	O
new	O
terminology	O
,	O
in	O
-	O
depth	O
theoretical	O
analysis	O
and	O
justification	O
of	O
the	O
approach	O
,	O
extensive	O
experiments	O
with	O
the	O
shallow	O
DANN	B-Method
case	O
on	O
synthetic	O
data	O
as	O
well	O
as	O
on	O
a	O
natural	B-Task
language	I-Task
processing	I-Task
task	I-Task
(	O
sentiment	B-Task
analysis	I-Task
)	O
.	O
	
Furthermore	O
,	O
in	O
this	O
version	O
we	O
go	O
beyond	O
classification	B-Task
and	O
evaluate	O
domain	B-Method
-	I-Method
adversarial	I-Method
learning	I-Method
for	O
descriptor	B-Task
learning	I-Task
setting	I-Task
within	O
the	O
person	B-Task
re	I-Task
-	I-Task
identification	I-Task
application	I-Task
.	O
	
section	O
:	O
Domain	B-Task
Adaptation	I-Task
	
We	O
consider	O
classification	B-Task
tasks	I-Task
where	O
X	O
is	O
the	O
input	O
space	O
and	O
Y	O
=	O
{	O
0	O
,	O
1	O
,	O
.	O
.	O
.	O
	
,	O
L−1	O
}	O
is	O
the	O
set	O
of	O
L	O
possible	O
labels	O
.	O
	
Moreover	O
,	O
we	O
have	O
two	O
different	O
distributions	O
over	O
X×Y	O
,	O
called	O
the	O
source	O
domain	O
D	O
S	O
and	O
the	O
target	O
domain	O
D	O
T	O
.	O
	
An	O
unsupervised	B-Method
domain	I-Method
adaptation	I-Method
learning	I-Method
algorithm	I-Method
is	O
then	O
provided	O
with	O
a	O
labeled	O
source	O
sample	O
S	O
drawn	O
i.i.d	O
.	O
from	O
D	O
S	O
,	O
and	O
an	O
unlabeled	O
target	O
sample	O
	
with	O
N	O
=	O
n	O
+	O
n	O
being	O
the	O
total	O
number	O
of	O
samples	O
.	O
	
The	O
goal	O
of	O
the	O
learning	B-Method
algorithm	I-Method
is	O
to	O
build	O
a	O
classifier	B-Method
η	I-Method
:	O
X	O
→	O
Y	O
with	O
a	O
low	O
target	O
risk	O
	
while	O
having	O
no	O
information	O
about	O
the	O
labels	O
of	O
D	O
T	O
.	O
	
section	O
:	O
Domain	O
Divergence	O
	
To	O
tackle	O
the	O
challenging	O
domain	B-Method
adaptation	I-Method
task	O
,	O
many	O
approaches	O
bound	O
the	O
target	B-Metric
error	I-Metric
by	O
the	O
sum	O
of	O
the	O
source	B-Metric
error	I-Metric
and	O
a	O
notion	O
of	O
distance	B-Metric
between	O
the	O
source	O
and	O
the	O
target	O
distributions	O
.	O
	
These	O
methods	O
are	O
intuitively	O
justified	O
by	O
a	O
simple	O
assumption	O
:	O
the	O
source	B-Metric
risk	I-Metric
is	O
expected	O
to	O
be	O
a	O
good	O
indicator	O
of	O
the	O
target	O
risk	O
when	O
both	O
distributions	O
are	O
similar	O
.	O
	
Several	O
notions	O
of	O
distance	B-Metric
have	O
been	O
proposed	O
for	O
domain	B-Method
adaptation	I-Method
[	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
.	O
	
In	O
this	O
paper	O
,	O
we	O
focus	O
on	O
the	O
H	O
-	O
divergence	O
used	O
by	O
[	O
reference	O
]	O
,	O
and	O
based	O
on	O
the	O
earlier	O
work	O
of	O
[	O
reference	O
]	O
.	O
Note	O
that	O
we	O
assume	O
in	O
definition	O
1	O
below	O
that	O
the	O
hypothesis	O
class	O
H	O
is	O
a	O
(	O
discrete	O
or	O
continuous	O
)	O
set	O
of	O
binary	O
classifiers	O
η	O
:	O
X	O
→	O
{	O
0	O
,	O
1}.	O
1	O
	
Definition	O
1	O
[	O
reference	O
][	O
reference	O
]	O
	
That	O
is	O
,	O
the	O
H	O
-	O
divergence	O
relies	O
on	O
the	O
capacity	O
of	O
the	O
hypothesis	O
class	O
H	O
to	O
distinguish	O
between	O
examples	O
generated	O
by	O
D	O
X	O
S	O
from	O
examples	O
generated	O
by	O
D	O
X	O
T	O
.	O
	
[	O
reference	O
]	O
proved	O
that	O
,	O
for	O
a	O
symmetric	O
hypothesis	O
class	O
H	O
,	O
one	O
can	O
compute	O
the	O
empirical	O
	
where	O
I	O
[	O
a	O
]	O
is	O
the	O
indicator	O
function	O
which	O
is	O
1	O
if	O
predicate	O
a	O
is	O
true	O
,	O
and	O
0	O
otherwise	O
.	O
	
section	O
:	O
Proxy	O
Distance	O
	
Ben	O
-	O
David	O
et	O
al	O
.	O
	
[	O
reference	O
]	O
suggested	O
that	O
,	O
even	O
if	O
it	O
is	O
generally	O
hard	O
to	O
computed	O
H	O
(	O
S	O
,	O
T	O
)	O
exactly	O
(	O
e.g.	O
,	O
when	O
H	O
is	O
the	O
space	O
of	O
linear	B-Method
classifiers	I-Method
on	O
X	O
)	O
,	O
we	O
can	O
easily	O
approximate	O
it	O
by	O
running	O
a	O
learning	B-Method
algorithm	I-Method
on	O
the	O
problem	O
of	O
discriminating	O
between	O
source	O
and	O
target	O
examples	O
.	O
	
To	O
do	O
so	O
,	O
we	O
construct	O
a	O
new	O
data	O
set	O
	
where	O
the	O
examples	O
of	O
the	O
source	O
sample	O
are	O
labeled	O
0	O
and	O
the	O
examples	O
of	O
the	O
target	O
sample	O
are	O
labeled	O
1	O
.	O
	
Then	O
,	O
the	O
risk	O
of	O
the	O
classifier	B-Method
trained	O
on	O
the	O
new	O
data	O
set	O
U	O
approximates	O
the	O
"	O
min	O
"	O
part	O
of	O
Equation	O
(	O
1	O
)	O
.	O
	
Given	O
a	O
generalization	B-Metric
error	I-Metric
on	O
the	O
problem	O
of	O
discriminating	O
between	O
source	O
and	O
target	O
examples	O
,	O
the	O
H	O
-	O
divergence	O
is	O
then	O
approximated	O
bŷ	O
	
In	O
[	O
reference	O
]	O
,	O
the	O
valued	O
A	O
is	O
called	O
the	O
	
,	O
where	O
A	O
is	O
a	O
subset	O
of	O
X.	O
Note	O
that	O
,	O
by	O
choosing	O
A	O
=	O
{	O
A	O
η	O
|η	O
∈	O
H	O
}	O
,	O
with	O
A	O
η	O
the	O
set	O
represented	O
by	O
the	O
characteristic	O
function	O
η	O
,	O
the	O
A	O
-	O
distance	B-Metric
and	O
the	O
H	B-Metric
-	I-Metric
divergence	I-Metric
of	O
Definition	O
1	O
are	O
identical	O
.	O
	
In	O
the	O
experiments	O
section	O
of	O
this	O
paper	O
,	O
we	O
compute	O
the	O
PAD	B-Metric
value	I-Metric
following	O
the	O
approach	O
of	O
[	O
reference	O
][	O
reference	O
]	O
,	O
i.e.	O
,	O
we	O
train	O
either	O
a	O
linear	O
SVM	B-Method
or	O
a	O
deeper	B-Method
MLP	I-Method
classifier	I-Method
on	O
a	O
subset	O
of	O
U	O
(	O
Equation	O
2	O
)	O
,	O
and	O
we	O
use	O
the	O
obtained	O
classifier	B-Metric
error	I-Metric
on	O
the	O
other	O
subset	O
as	O
the	O
value	O
of	O
in	O
Equation	O
(	O
3	O
)	O
.	O
	
More	O
details	O
and	O
illustrations	O
of	O
the	O
linear	O
SVM	B-Method
case	O
are	O
provided	O
in	O
Section	O
5.1.5	O
.	O
	
section	O
:	O
Generalization	O
Bound	O
on	O
the	O
Target	B-Metric
Risk	I-Metric
	
The	O
work	O
of	O
[	O
reference	O
]	O
	
is	O
upper	O
bounded	O
by	O
its	O
empirical	O
estimated	O
H	O
(	O
S	O
,	O
T	O
)	O
plus	O
a	O
constant	O
complexity	O
term	O
that	O
depends	O
on	O
the	O
VC	O
dimension	O
of	O
H	O
and	O
the	O
size	O
of	O
samples	O
S	O
and	O
T	O
.	O
	
By	O
combining	O
this	O
result	O
with	O
a	O
similar	O
bound	O
on	O
the	O
source	O
risk	O
,	O
the	O
following	O
theorem	O
is	O
obtained	O
.	O
	
,	O
and	O
	
is	O
the	O
empirical	B-Metric
source	I-Metric
risk	I-Metric
.	O
	
The	O
previous	O
result	O
tells	O
us	O
that	O
R	O
D	O
T	O
(	O
η	O
)	O
can	O
be	O
low	O
only	O
when	O
the	O
β	O
term	O
is	O
low	O
,	O
i.e.	O
,	O
only	O
when	O
there	O
exists	O
a	O
classifier	B-Method
that	O
can	O
achieve	O
a	O
low	O
risk	O
on	O
both	O
distributions	O
.	O
	
It	O
also	O
tells	O
us	O
that	O
,	O
to	O
find	O
a	O
classifier	B-Method
with	O
a	O
small	O
R	O
D	O
T	O
(	O
η	O
)	O
in	O
a	O
given	O
class	O
of	O
fixed	O
VC	O
dimension	O
,	O
the	O
learning	B-Method
algorithm	I-Method
should	O
minimize	O
(	O
in	O
that	O
class	O
)	O
a	O
trade	O
-	O
off	O
between	O
the	O
source	B-Metric
risk	I-Metric
R	I-Metric
S	O
(	O
η	O
)	O
and	O
the	O
empirical	B-Metric
H	I-Metric
-	I-Metric
divergenced	I-Metric
H	O
(	O
S	O
,	O
T	O
)	O
.	O
	
As	O
pointed	O
-	O
out	O
by	O
[	O
reference	O
]	O
,	O
a	O
strategy	O
to	O
control	O
the	O
H	O
-	O
divergence	O
is	O
to	O
find	O
a	O
representation	O
of	O
the	O
examples	O
where	O
both	O
the	O
source	O
and	O
the	O
target	O
domain	O
are	O
as	O
indistinguishable	O
as	O
possible	O
.	O
	
Under	O
such	O
a	O
representation	O
,	O
a	O
hypothesis	O
with	O
a	O
low	O
source	O
risk	O
will	O
,	O
according	O
to	O
Theorem	O
2	O
,	O
perform	O
well	O
on	O
the	O
target	O
data	O
.	O
	
In	O
this	O
paper	O
,	O
we	O
present	O
an	O
algorithm	O
that	O
directly	O
exploits	O
this	O
idea	O
.	O
	
section	O
:	O
Domain	B-Method
-	I-Method
Adversarial	I-Method
Neural	I-Method
Networks	I-Method
(	O
DANN	B-Method
)	O
	
An	O
original	O
aspect	O
of	O
our	O
approach	O
is	O
to	O
explicitly	O
implement	O
the	O
idea	O
exhibited	O
by	O
Theorem	O
2	O
into	O
a	O
neural	B-Method
network	I-Method
classifier	I-Method
.	O
	
That	O
is	O
,	O
to	O
learn	O
a	O
model	O
that	O
can	O
generalize	O
well	O
from	O
one	O
domain	O
to	O
another	O
,	O
we	O
ensure	O
that	O
the	O
internal	B-Method
representation	I-Method
of	O
the	O
neural	B-Method
network	I-Method
contains	O
no	O
discriminative	O
information	O
about	O
the	O
origin	O
of	O
the	O
input	O
(	O
source	O
or	O
target	O
)	O
,	O
while	O
preserving	O
a	O
low	O
risk	O
on	O
the	O
source	O
(	O
labeled	O
)	O
examples	O
.	O
	
In	O
this	O
section	O
,	O
we	O
detail	O
the	O
proposed	O
approach	O
for	O
incorporating	O
a	O
"	O
domain	B-Method
adaptation	I-Method
component	I-Method
"	O
to	O
neural	B-Method
networks	I-Method
.	O
	
In	O
Subsection	O
4.1	O
,	O
we	O
start	O
by	O
developing	O
the	O
idea	O
for	O
the	O
simplest	O
possible	O
case	O
,	O
i.e.	O
,	O
a	O
single	O
hidden	B-Method
layer	I-Method
,	I-Method
fully	I-Method
connected	I-Method
neural	I-Method
network	I-Method
.	O
	
We	O
then	O
describe	O
how	O
to	O
generalize	O
the	O
approach	O
to	O
arbitrary	O
(	O
deep	B-Method
)	I-Method
network	I-Method
architectures	I-Method
.	O
	
section	O
:	O
Example	O
Case	O
with	O
a	O
Shallow	B-Method
Neural	I-Method
Network	I-Method
	
Let	O
us	O
first	O
consider	O
a	O
standard	O
neural	O
network	O
(	O
NN	B-Method
)	O
architecture	O
with	O
a	O
single	O
hidden	B-Method
layer	I-Method
.	O
	
For	O
simplicity	O
,	O
we	O
suppose	O
that	O
the	O
input	O
space	O
is	O
formed	O
by	O
m	O
-	O
dimensional	O
real	O
vectors	O
.	O
	
Thus	O
,	O
X	O
=	O
R	O
m	O
.	O
	
The	O
hidden	O
layer	O
G	O
f	O
learns	O
a	O
function	O
	
G	O
f	O
:	O
	
X	O
→	O
R	O
D	O
that	O
maps	O
an	O
example	O
into	O
a	O
new	O
D	O
-	O
dimensional	O
representation	O
2	O
,	O
and	O
is	O
parameterized	O
by	O
a	O
matrix	O
-	O
vector	O
pair	O
(	O
W	O
,	O
b	O
)	O
∈	O
R	O
D×m	O
×	O
R	O
D	O
:	O
	
with	O
sigm	B-Method
(	I-Method
a	I-Method
)	O
=	O
	
Similarly	O
,	O
the	O
prediction	B-Method
layer	I-Method
G	I-Method
y	I-Method
learns	O
a	O
function	O
	
Here	O
we	O
have	O
L	O
=	O
|Y	O
	
|.	O
	
By	O
using	O
the	O
softmax	B-Method
function	I-Method
,	O
each	O
component	O
of	O
vector	O
G	O
y	O
	
(	O
G	O
f	O
(	O
x	O
)	O
)	O
denotes	O
the	O
conditional	O
probability	O
that	O
the	O
neural	B-Method
network	I-Method
assigns	O
x	O
to	O
the	O
class	O
in	O
Y	O
represented	O
by	O
that	O
component	O
.	O
	
Given	O
a	O
source	O
example	O
	
(	O
x	O
i	O
,	O
y	O
i	O
)	O
,	O
the	O
natural	O
classification	B-Metric
loss	I-Metric
to	O
use	O
is	O
the	O
negative	O
log	O
-	O
probability	O
of	O
the	O
correct	O
label	O
:	O
	
Training	O
the	O
neural	B-Method
network	I-Method
then	O
leads	O
to	O
the	O
following	O
optimization	B-Task
problem	I-Task
on	O
the	O
source	O
domain	O
:	O
	
where	O
	
,	O
y	O
i	O
is	O
a	O
shorthand	O
notation	O
for	O
the	O
prediction	O
loss	O
on	O
the	O
i	O
-	O
th	O
example	O
,	O
and	O
R	O
(	O
W	O
,	O
b	O
)	O
is	O
an	O
optional	B-Method
regularizer	I-Method
that	O
is	O
weighted	O
by	O
hyper	O
-	O
parameter	O
λ	O
.	O
	
The	O
heart	O
of	O
our	O
approach	O
is	O
to	O
design	O
a	O
domain	B-Method
regularizer	I-Method
directly	O
derived	O
from	O
the	O
H	O
-	O
divergence	O
of	O
Definition	O
1	O
.	O
	
To	O
this	O
end	O
,	O
we	O
view	O
the	O
output	O
of	O
the	O
hidden	O
layer	O
G	O
f	O
(	O
·	O
)	O
(	O
Equation	O
4	O
)	O
as	O
the	O
internal	B-Method
representation	I-Method
of	O
the	O
neural	B-Method
network	I-Method
.	O
	
Thus	O
,	O
we	O
denote	O
the	O
source	B-Method
sample	I-Method
representations	I-Method
as	O
	
Similarly	O
,	O
given	O
an	O
unlabeled	O
sample	O
from	O
the	O
target	O
domain	O
we	O
denote	O
the	O
corresponding	O
representations	O
	
Based	O
on	O
Equation	O
(	O
1	O
)	O
,	O
the	O
empirical	B-Metric
H	I-Metric
-	I-Metric
divergence	I-Metric
of	O
a	O
symmetric	O
hypothesis	O
class	O
H	O
between	O
samples	O
S	O
(	O
G	O
f	O
)	O
and	O
	
Let	O
us	O
consider	O
H	O
as	O
the	O
class	O
of	O
hyperplanes	O
in	O
the	O
representation	O
space	O
.	O
	
Inspired	O
by	O
the	O
Proxy	O
A	O
-	O
distance	B-Metric
(	O
see	O
Section	O
3.2	O
)	O
,	O
we	O
suggest	O
estimating	O
the	O
"	O
min	O
"	O
part	O
of	O
Equation	O
(	O
6	O
)	O
by	O
a	O
domain	B-Method
classification	I-Method
layer	I-Method
G	O
d	O
that	O
learns	O
a	O
logistic	B-Method
regressor	I-Method
	
parameterized	O
by	O
a	O
vector	O
-	O
scalar	O
pair	O
(	O
u	O
,	O
z	O
)	O
∈	O
R	O
D	O
×	O
R	O
,	O
that	O
models	O
the	O
probability	O
that	O
a	O
given	O
input	O
is	O
from	O
the	O
source	O
domain	O
D	O
	
Hence	O
,	O
the	O
function	O
G	O
d	O
(	O
·	O
)	O
is	O
a	O
domain	B-Method
regressor	I-Method
.	O
	
We	O
define	O
its	O
loss	O
by	O
	
where	O
d	O
i	O
denotes	O
the	O
binary	O
variable	O
(	O
domain	O
label	O
)	O
for	O
the	O
i	O
-	O
th	O
example	O
,	O
which	O
indicates	O
whether	O
x	O
i	O
come	O
from	O
the	O
source	O
distribution	O
(	O
	
Recall	O
that	O
for	O
the	O
examples	O
from	O
the	O
source	O
distribution	O
(	O
d	O
i	O
=	O
0	O
)	O
,	O
the	O
corresponding	O
labels	O
	
y	O
	
i	O
	
∈	O
Y	O
are	O
known	O
at	O
training	O
time	O
.	O
	
For	O
the	O
examples	O
from	O
the	O
target	O
domains	O
,	O
we	O
do	O
not	O
know	O
the	O
labels	O
at	O
training	O
time	O
,	O
and	O
we	O
want	O
to	O
predict	O
such	O
labels	O
at	O
test	O
time	O
.	O
	
This	O
enables	O
us	O
to	O
add	O
a	O
domain	B-Method
adaptation	I-Method
term	I-Method
to	O
the	O
objective	O
of	O
Equation	O
(	O
5	O
)	O
,	O
giving	O
the	O
following	O
regularizer	B-Method
:	O
	
where	O
	
This	O
regularizer	B-Method
seeks	O
to	O
approximate	O
the	O
H	O
-	O
divergence	O
of	O
Equation	O
(	O
6	O
)	O
,	O
as	O
2	O
(	O
1−R	O
(	O
W	O
,	O
b	O
)	O
)	O
is	O
a	O
surrogate	O
ford	O
H	O
S	O
(	O
G	O
f	O
)	O
,	O
T	O
(	O
G	O
f	O
)	O
.	O
	
In	O
line	O
with	O
Theorem	O
2	O
,	O
the	O
optimization	B-Task
problem	I-Task
given	O
by	O
Equations	O
(	O
5	O
)	O
and	O
(	O
8	O
)	O
implements	O
a	O
trade	O
-	O
off	O
between	O
the	O
minimization	O
of	O
the	O
source	B-Metric
risk	I-Metric
R	I-Metric
S	I-Metric
(	O
·	O
)	O
and	O
the	O
divergenced	O
H	O
(	O
·	O
,	O
·	O
)	O
.	O
	
The	O
hyper	O
-	O
parameter	O
λ	O
is	O
then	O
used	O
to	O
tune	O
the	O
trade	O
-	O
off	O
between	O
these	O
two	O
quantities	O
during	O
the	O
learning	B-Method
process	I-Method
.	O
	
For	O
learning	B-Task
,	O
we	O
first	O
note	O
that	O
we	O
can	O
rewrite	O
the	O
complete	O
optimization	B-Metric
objective	I-Metric
of	O
Equation	O
(	O
5	O
)	O
as	O
follows	O
:	O
	
where	O
we	O
are	O
seeking	O
the	O
parametersŴ	O
,	O
V	O
,	O
b	O
,	O
ĉ	O
,	O
û	O
,	O
ẑ	O
that	O
deliver	O
a	O
saddle	O
point	O
given	O
by	O
	
Thus	O
,	O
the	O
optimization	B-Task
problem	I-Task
involves	O
a	O
minimization	B-Task
with	O
respect	O
to	O
some	O
parameters	O
,	O
as	O
well	O
as	O
a	O
maximization	B-Task
with	O
respect	O
to	O
the	O
others	O
.	O
	
Algorithm	O
1	O
Shallow	B-Method
DANN	I-Method
-	I-Method
Stochastic	I-Method
training	I-Method
update	I-Method
	
while	O
stopping	B-Metric
criterion	I-Metric
is	O
not	O
met	O
do	O
6	O
:	O
	
for	O
i	O
from	O
1	O
to	O
n	O
do	O
7	O
:	O
	
#	O
Forward	B-Method
propagation	I-Method
8	O
:	O
	
32	O
:	O
	
#	O
Update	O
neural	B-Method
network	I-Method
parameters	I-Method
33	O
:	O
	
end	O
for	O
41	O
:	O
end	O
	
while	O
Note	O
:	O
In	O
this	O
pseudo	O
-	O
code	O
,	O
e	O
(	O
y	O
)	O
refers	O
to	O
a	O
"	O
one	O
-	O
hot	O
"	O
vector	O
,	O
consisting	O
of	O
all	O
0s	O
except	O
for	O
a	O
1	O
at	O
position	O
y	O
,	O
and	O
is	O
the	O
element	O
-	O
wise	O
product	O
.	O
	
We	O
propose	O
to	O
tackle	O
this	O
problem	O
with	O
a	O
simple	O
stochastic	B-Method
gradient	I-Method
procedure	I-Method
,	O
in	O
which	O
updates	O
are	O
made	O
in	O
the	O
opposite	O
direction	O
of	O
the	O
gradient	O
of	O
Equation	O
(	O
9	O
)	O
for	O
the	O
minimizing	O
parameters	O
,	O
and	O
in	O
the	O
direction	O
of	O
the	O
gradient	O
for	O
the	O
maximizing	O
parameters	O
.	O
	
Stochastic	B-Method
estimates	I-Method
of	O
the	O
gradient	O
are	O
made	O
,	O
using	O
a	O
subset	O
of	O
the	O
training	O
samples	O
to	O
compute	O
the	O
averages	O
.	O
	
Algorithm	O
1	O
provides	O
the	O
complete	O
pseudo	O
-	O
code	O
of	O
this	O
learning	B-Method
procedure	I-Method
.	O
	
3	O
	
In	O
words	O
,	O
during	O
training	B-Task
,	O
the	O
neural	B-Method
network	I-Method
(	O
parameterized	O
by	O
W	O
,	O
b	O
,	O
V	O
,	O
c	O
)	O
and	O
the	O
domain	B-Method
regressor	I-Method
(	O
parameterized	O
by	O
u	O
,	O
z	O
)	O
are	O
competing	O
against	O
each	O
other	O
,	O
in	O
an	O
adversarial	O
way	O
,	O
over	O
the	O
objective	O
of	O
Equation	O
(	O
9	O
)	O
.	O
	
For	O
this	O
reason	O
,	O
we	O
refer	O
to	O
networks	O
trained	O
according	O
to	O
this	O
objective	O
as	O
Domain	B-Method
-	I-Method
Adversarial	I-Method
Neural	I-Method
Networks	I-Method
(	O
DANN	B-Method
)	O
.	O
	
DANN	B-Method
will	O
effectively	O
attempt	O
to	O
learn	O
a	O
hidden	B-Method
layer	I-Method
G	I-Method
f	I-Method
(	O
·	O
)	O
that	O
maps	O
an	O
example	O
(	O
either	O
source	O
or	O
target	O
)	O
into	O
a	O
representation	O
allowing	O
the	O
output	O
layer	O
G	O
y	O
(	O
·	O
)	O
to	O
accurately	O
classify	O
source	O
samples	O
,	O
but	O
crippling	O
the	O
ability	O
of	O
the	O
domain	B-Method
regressor	I-Method
G	I-Method
d	O
(	O
·	O
)	O
to	O
detect	O
whether	O
each	O
example	O
belongs	O
to	O
the	O
source	O
or	O
target	O
domains	O
.	O
	
section	O
:	O
Generalization	O
to	O
Arbitrary	O
Architectures	O
	
For	O
illustration	O
purposes	O
,	O
we	O
'	O
ve	O
so	O
far	O
focused	O
on	O
the	O
case	O
of	O
a	O
single	O
hidden	O
layer	O
DANN	B-Method
.	O
	
However	O
,	O
it	O
is	O
straightforward	O
to	O
generalize	O
to	O
other	O
sophisticated	O
architectures	O
,	O
which	O
might	O
be	O
more	O
appropriate	O
for	O
the	O
data	O
at	O
hand	O
.	O
	
For	O
example	O
,	O
deep	B-Method
convolutional	I-Method
neural	I-Method
networks	I-Method
are	O
well	O
known	O
for	O
being	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
models	O
for	O
learning	B-Task
discriminative	I-Task
features	I-Task
of	I-Task
images	I-Task
	
[	O
reference	O
]	O
.	O
	
Let	O
us	O
now	O
use	O
a	O
more	O
general	O
notation	O
for	O
the	O
different	O
components	O
of	O
DANN	B-Method
.	O
	
Namely	O
,	O
let	O
G	O
f	O
(	O
·	O
;	O
θ	O
f	O
)	O
be	O
the	O
D	B-Method
-	I-Method
dimensional	I-Method
neural	I-Method
network	I-Method
feature	I-Method
extractor	I-Method
,	O
with	O
	
parameters	O
θ	O
f	O
.	O
	
Also	O
,	O
let	O
G	O
y	O
(	O
·	O
;	O
θ	O
y	O
)	O
be	O
the	O
part	O
of	O
DANN	B-Method
that	O
computes	O
the	O
network	O
's	O
label	O
prediction	O
output	O
layer	O
,	O
with	O
parameters	O
θ	O
y	O
,	O
while	O
G	O
d	O
(	O
·	O
;	O
	
θ	O
d	O
)	O
now	O
corresponds	O
to	O
the	O
computation	O
of	O
the	O
domain	O
prediction	O
output	O
of	O
the	O
network	O
,	O
with	O
parameters	O
θ	O
d	O
.	O
	
Note	O
that	O
for	O
preserving	O
the	O
theoretical	O
guarantees	O
of	O
Theorem	O
2	O
,	O
the	O
hypothesis	O
class	O
H	O
d	O
generated	O
by	O
the	O
domain	B-Method
prediction	I-Method
component	I-Method
G	O
d	O
should	O
include	O
the	O
hypothesis	O
class	O
H	O
y	O
generated	O
by	O
the	O
label	B-Method
prediction	I-Method
component	I-Method
G	O
y	O
.	O
	
Thus	O
,	O
	
We	O
will	O
note	O
the	O
prediction	O
loss	O
and	O
the	O
domain	O
loss	O
respectively	O
by	O
	
Training	O
DANN	B-Method
then	O
parallels	O
the	O
single	O
layer	O
case	O
and	O
consists	O
in	O
optimizing	O
	
by	O
finding	O
the	O
saddle	O
pointθ	O
f	O
,	O
θ	O
y	O
,	O
θ	O
d	O
such	O
that	O
	
As	O
suggested	O
previously	O
,	O
a	O
saddle	O
point	O
defined	O
by	O
Equations	O
(	O
11	O
-	O
12	O
)	O
can	O
be	O
found	O
as	O
a	O
stationary	O
point	O
of	O
the	O
following	O
gradient	B-Method
updates	I-Method
:	O
	
where	O
µ	O
is	O
the	O
learning	B-Metric
rate	I-Metric
.	O
	
We	O
use	O
stochastic	B-Method
estimates	I-Method
of	O
these	O
gradients	O
,	O
by	O
sampling	O
examples	O
from	O
the	O
data	O
set	O
.	O
	
The	O
updates	O
of	O
Equations	O
(	O
13	O
-	O
15	O
)	O
are	O
very	O
similar	O
to	O
stochastic	B-Method
gradient	I-Method
descent	I-Method
(	O
SGD	O
)	O
updates	O
for	O
a	O
feed	B-Method
-	I-Method
forward	I-Method
deep	I-Method
model	I-Method
that	O
comprises	O
feature	B-Method
extractor	I-Method
fed	O
into	O
the	O
label	O
Figure	O
1	O
:	O
The	O
proposed	O
architecture	O
includes	O
a	O
deep	B-Method
feature	I-Method
extractor	I-Method
(	O
green	O
)	O
and	O
a	O
deep	B-Method
label	I-Method
predictor	I-Method
(	O
blue	O
)	O
,	O
which	O
together	O
form	O
a	O
standard	O
feed	B-Method
-	I-Method
forward	I-Method
architecture	I-Method
.	O
	
Unsupervised	O
domain	B-Method
adaptation	I-Method
is	O
achieved	O
by	O
adding	O
a	O
domain	B-Method
classifier	I-Method
(	O
red	B-Method
)	O
connected	O
to	O
the	O
feature	B-Method
extractor	I-Method
via	O
a	O
gradient	B-Method
reversal	I-Method
layer	I-Method
that	O
multiplies	O
the	O
gradient	O
by	O
a	O
certain	O
negative	O
constant	O
during	O
the	O
backpropagation	B-Method
-	I-Method
based	I-Method
training	I-Method
.	O
	
Otherwise	O
,	O
the	O
training	O
proceeds	O
standardly	O
and	O
minimizes	O
the	O
label	B-Metric
prediction	I-Metric
loss	I-Metric
(	O
for	O
source	O
examples	O
)	O
and	O
the	O
domain	B-Metric
classification	I-Metric
loss	I-Metric
(	O
for	O
all	O
samples	O
)	O
.	O
	
Gradient	B-Task
reversal	I-Task
ensures	O
that	O
the	O
feature	O
distributions	O
over	O
the	O
two	O
domains	O
are	O
made	O
similar	O
(	O
as	O
indistinguishable	O
as	O
possible	O
for	O
the	O
domain	B-Method
classifier	I-Method
)	O
,	O
thus	O
resulting	O
in	O
the	O
domain	O
-	O
invariant	O
features	O
.	O
	
predictor	B-Method
and	O
into	O
the	O
domain	B-Method
classifier	I-Method
(	O
with	O
loss	O
weighted	O
by	O
λ	O
)	O
.	O
	
The	O
only	O
difference	O
is	O
that	O
in	O
(	O
13	O
)	O
,	O
the	O
gradients	O
from	O
the	O
class	O
and	O
domain	O
predictors	O
are	O
subtracted	O
,	O
instead	O
of	O
being	O
summed	O
(	O
the	O
difference	O
is	O
important	O
,	O
as	O
otherwise	O
SGD	B-Method
would	O
try	O
to	O
make	O
features	O
dissimilar	O
across	O
domains	O
in	O
order	O
to	O
minimize	O
the	O
domain	B-Task
classification	I-Task
loss	I-Task
)	O
.	O
	
Since	O
SGDand	B-Method
its	O
many	O
variants	O
,	O
such	O
as	O
ADAGRAD	B-Method
[	O
reference	O
]	O
or	O
ADADELTA	B-Method
[	O
reference	O
]-	O
is	O
the	O
main	O
learning	B-Method
algorithm	I-Method
implemented	O
in	O
most	O
libraries	O
for	O
deep	B-Method
learning	I-Method
,	O
it	O
would	O
be	O
convenient	O
to	O
frame	O
an	O
implementation	O
of	O
our	O
stochastic	B-Method
saddle	I-Method
point	I-Method
procedure	I-Method
as	O
SGD	B-Method
.	O
	
Fortunately	O
,	O
such	O
a	O
reduction	O
can	O
be	O
accomplished	O
by	O
introducing	O
a	O
special	O
gradient	B-Method
reversal	I-Method
layer	I-Method
(	O
GRL	B-Method
)	O
,	O
defined	O
as	O
follows	O
.	O
	
The	O
gradient	B-Method
reversal	I-Method
layer	I-Method
has	O
no	O
parameters	O
associated	O
with	O
it	O
.	O
	
During	O
the	O
forward	B-Method
propagation	I-Method
,	O
the	O
GRL	B-Method
acts	O
as	O
an	O
identity	B-Method
transformation	I-Method
.	O
	
During	O
the	O
backpropagation	B-Task
however	O
,	O
the	O
GRL	B-Method
takes	O
the	O
gradient	O
from	O
the	O
subsequent	O
level	O
and	O
changes	O
its	O
sign	O
,	O
i.e.	O
,	O
multiplies	O
it	O
by	O
−1	O
,	O
before	O
passing	O
it	O
to	O
the	O
preceding	O
layer	O
.	O
	
Implementing	O
such	O
a	O
layer	O
using	O
existing	O
object	B-Method
-	I-Method
oriented	I-Method
packages	I-Method
for	O
deep	B-Method
learning	I-Method
is	O
simple	O
,	O
requiring	O
only	O
to	O
define	O
procedures	O
for	O
the	O
forward	B-Method
propagation	I-Method
(	O
identity	B-Method
transformation	I-Method
)	O
,	O
and	O
backpropagation	B-Method
(	O
multiplying	O
by	O
−1	O
)	O
.	O
	
The	O
layer	O
requires	O
no	O
parameter	O
update	O
.	O
	
The	O
GRL	B-Method
as	O
defined	O
above	O
is	O
inserted	O
between	O
the	O
feature	B-Method
extractor	I-Method
G	I-Method
f	I-Method
and	O
the	O
domain	B-Method
classifier	I-Method
G	I-Method
d	I-Method
,	O
resulting	O
in	O
the	O
architecture	O
depicted	O
in	O
Figure	O
1	O
.	O
	
As	O
the	O
backpropagation	B-Method
process	I-Method
passes	O
through	O
the	O
GRL	B-Method
,	O
the	O
partial	O
derivatives	O
of	O
the	O
loss	O
that	O
is	O
downstream	O
the	O
GRL	O
(	O
i.e.	O
,	O
L	O
d	O
)	O
	
w.r.t	O
.	O
	
the	O
layer	O
parameters	O
that	O
are	O
upstream	O
the	O
GRL	O
(	O
i.e.	O
,	O
θ	O
f	O
)	O
get	O
multiplied	O
by	O
−1	O
,	O
i.e.	O
,	O
	
.	O
	
Therefore	O
,	O
running	O
SGD	B-Method
in	O
the	O
resulting	O
model	O
implements	O
the	O
updates	O
of	O
Equations	O
(	O
13	O
-	O
15	O
)	O
and	O
converges	O
to	O
a	O
saddle	O
point	O
of	O
Equation	O
(	O
10	O
)	O
.	O
	
Mathematically	O
,	O
we	O
can	O
formally	O
treat	O
the	O
gradient	B-Method
reversal	I-Method
layer	I-Method
as	O
a	O
"	O
pseudo	O
-	O
function	O
"	O
R	O
(	O
x	O
)	O
defined	O
by	O
two	O
(	O
incompatible	O
)	O
equations	O
describing	O
its	O
forward	B-Method
and	I-Method
backpropagation	I-Method
behaviour	I-Method
:	O
	
where	O
I	O
is	O
an	O
identity	O
matrix	O
.	O
	
We	O
can	O
then	O
define	O
the	O
objective	O
"	O
pseudo	B-Metric
-	I-Metric
function	I-Metric
"	O
of	O
(	O
θ	O
f	O
,	O
θ	O
y	O
,	O
θ	O
d	O
)	O
that	O
is	O
being	O
optimized	O
by	O
the	O
stochastic	B-Method
gradient	I-Method
descent	I-Method
within	O
our	O
method	O
:	O
	
Running	O
updates	O
(	O
13	O
-	O
15	O
)	O
can	O
then	O
be	O
implemented	O
as	O
doing	O
SGD	B-Method
for	O
(	O
18	O
)	O
and	O
leads	O
to	O
the	O
emergence	O
of	O
features	O
that	O
are	O
domain	O
-	O
invariant	O
and	O
discriminative	O
at	O
the	O
same	O
time	O
.	O
	
After	O
the	O
learning	B-Task
,	O
the	O
label	B-Method
predictor	I-Method
G	O
y	O
(	O
G	O
f	O
(	O
x	O
;	O
θ	O
f	O
)	O
;	O
θ	O
y	O
)	O
can	O
be	O
used	O
to	O
predict	O
labels	O
for	O
samples	O
from	O
the	O
target	O
domain	O
(	O
as	O
well	O
as	O
from	O
the	O
source	O
domain	O
)	O
.	O
	
Note	O
that	O
we	O
release	O
the	O
source	O
code	O
for	O
the	O
Gradient	B-Method
Reversal	I-Method
layer	I-Method
along	O
with	O
the	O
usage	O
examples	O
as	O
an	O
extension	O
to	O
Caffe	B-Task
.	O
	
4	O
	
section	O
:	O
Experiments	O
	
In	O
this	O
section	O
,	O
we	O
present	O
a	O
variety	O
of	O
empirical	O
results	O
for	O
both	O
shallow	B-Method
domain	I-Method
adversarial	I-Method
neural	I-Method
networks	I-Method
(	O
Subsection	O
5.1	O
)	O
and	O
deep	O
ones	O
(	O
Subsections	O
5.2	O
and	O
5.3	O
)	O
.	O
	
section	O
:	O
Experiments	O
with	O
Shallow	B-Method
Neural	I-Method
Networks	I-Method
	
In	O
this	O
first	O
experiment	O
section	O
,	O
we	O
evaluate	O
the	O
behavior	O
of	O
the	O
simple	O
version	O
of	O
DANN	B-Method
described	O
by	O
Subsection	O
4.1	O
.	O
	
Note	O
that	O
the	O
results	O
reported	O
in	O
the	O
present	O
subsection	O
are	O
obtained	O
using	O
Algorithm	O
1	O
.	O
	
Thus	O
,	O
the	O
stochastic	B-Method
gradient	I-Method
descent	I-Method
approach	O
here	O
consists	O
of	O
sampling	O
a	O
pair	O
of	O
source	O
and	O
target	O
examples	O
and	O
performing	O
a	O
gradient	B-Method
step	I-Method
update	I-Method
of	O
all	O
parameters	O
of	O
DANN	B-Method
.	O
	
Crucially	O
,	O
while	O
the	O
update	O
of	O
the	O
regular	O
parameters	O
follows	O
as	O
usual	O
the	O
opposite	O
direction	O
of	O
the	O
gradient	O
,	O
for	O
the	O
adversarial	O
parameters	O
the	O
step	O
must	O
follow	O
the	O
gradient	O
's	O
direction	O
(	O
since	O
we	O
maximize	O
with	O
respect	O
to	O
them	O
,	O
instead	O
of	O
minimizing	O
)	O
.	O
	
section	O
:	O
Experiments	O
on	O
a	O
Toy	B-Task
Problem	I-Task
	
As	O
a	O
first	O
experiment	O
,	O
we	O
study	O
the	O
behavior	O
of	O
the	O
proposed	O
algorithm	O
on	O
a	O
variant	O
of	O
the	O
inter	B-Task
-	I-Task
twinning	I-Task
moons	I-Task
2D	I-Task
problem	I-Task
,	O
where	O
the	O
target	O
distribution	O
is	O
a	O
rotation	O
of	O
the	O
source	O
one	O
.	O
	
As	O
the	O
source	O
sample	O
S	O
,	O
we	O
generate	O
a	O
lower	O
moon	O
and	O
an	O
upper	O
moon	O
labeled	O
0	O
and	O
1	O
respectively	O
,	O
each	O
of	O
which	O
containing	O
150	O
examples	O
.	O
	
The	O
target	O
sample	O
T	O
is	O
obtained	O
by	O
the	O
following	O
procedure	O
:	O
(	O
1	O
)	O
we	O
generate	O
a	O
sample	O
S	O
the	O
same	O
way	O
S	O
has	O
been	O
generated	O
;	O
(	O
2	O
)	O
we	O
rotate	O
each	O
example	O
by	O
35	O
•	O
;	O
and	O
(	O
3	O
)	O
we	O
remove	O
all	O
the	O
labels	O
.	O
	
Thus	O
,	O
T	O
contains	O
300	O
unlabeled	O
examples	O
.	O
	
We	O
have	O
represented	O
those	O
examples	O
in	O
Figure	O
2	O
.	O
	
We	O
study	O
the	O
adaptation	B-Metric
capability	I-Metric
of	O
DANN	B-Method
by	O
comparing	O
it	O
to	O
the	O
standard	O
neural	B-Method
network	I-Method
(	O
NN	B-Method
)	O
.	O
	
In	O
these	O
toy	O
experiments	O
,	O
both	O
algorithms	O
share	O
the	O
same	O
network	B-Method
architecture	I-Method
,	O
with	O
a	O
hidden	O
layer	O
size	O
of	O
15	O
neurons	O
.	O
	
We	O
train	O
the	O
NN	B-Method
using	O
the	O
same	O
procedure	O
as	O
the	O
DANN	B-Method
.	O
	
That	O
is	O
,	O
we	O
keep	O
updating	O
the	O
domain	B-Method
regressor	I-Method
component	I-Method
using	O
target	O
sample	O
T	O
(	O
with	O
a	O
hyper	O
-	O
parameter	O
λ	O
=	O
6	O
;	O
the	O
same	O
value	O
is	O
used	O
for	O
DANN	B-Method
)	O
,	O
but	O
we	O
disable	O
the	O
adversarial	B-Method
back	I-Method
-	I-Method
propagation	I-Method
into	O
the	O
hidden	B-Method
layer	I-Method
.	O
	
To	O
do	O
so	O
,	O
we	O
execute	O
Algorithm	O
1	O
by	O
omitting	O
the	O
lines	O
numbered	O
22	O
and	O
31	O
.	O
	
This	O
allows	O
recovering	O
the	O
NN	B-Method
learning	O
algorithm	O
-	O
based	O
on	O
the	O
source	B-Method
risk	I-Method
minimization	I-Method
of	O
Equation	O
(	O
5	O
)	O
without	O
any	O
regularizer	B-Method
-	O
and	O
simultaneously	O
train	O
the	O
domain	B-Method
regressor	I-Method
of	O
Equation	O
(	O
7	O
)	O
to	O
discriminate	O
between	O
source	O
and	O
target	O
domains	O
.	O
	
With	O
this	O
toy	O
experience	O
,	O
we	O
will	O
first	O
illustrate	O
how	O
DANN	B-Method
adapts	O
its	O
decision	O
boundary	O
when	O
compared	O
to	O
NN	B-Method
.	O
	
Moreover	O
,	O
we	O
will	O
also	O
illustrate	O
how	O
the	O
representation	O
given	O
by	O
the	O
hidden	B-Method
layer	I-Method
is	O
less	O
adapted	O
to	O
the	O
source	B-Task
domain	I-Task
task	I-Task
with	O
DANN	B-Method
than	O
with	O
NN	B-Method
(	O
this	O
is	O
why	O
we	O
need	O
a	O
domain	O
regressor	O
in	O
the	O
NN	B-Method
experiment	O
)	O
.	O
	
We	O
recall	O
that	O
this	O
is	O
the	O
founding	O
idea	O
behind	O
our	O
proposed	O
algorithm	O
.	O
	
The	O
analysis	O
of	O
the	O
experiment	O
appears	O
in	O
Figure	O
2	O
,	O
where	O
upper	O
graphs	O
relate	O
to	O
standard	O
NN	B-Method
,	O
and	O
lower	O
graphs	O
relate	O
to	O
DANN	B-Method
.	O
	
By	O
looking	O
at	O
the	O
lower	O
and	O
upper	O
graphs	O
pairwise	O
,	O
we	O
compare	O
NN	B-Method
and	O
DANN	B-Method
from	O
four	O
different	O
perspectives	O
,	O
described	O
in	O
details	O
below	O
.	O
	
The	O
column	O
"	O
Label	B-Task
Classification	I-Task
"	O
of	O
Figure	O
2	O
shows	O
the	O
decision	O
boundaries	O
of	O
DANN	B-Method
and	O
NN	B-Method
on	O
the	O
problem	O
of	O
predicting	O
the	O
labels	O
of	O
both	O
source	O
and	O
the	O
target	O
examples	O
.	O
	
As	O
expected	O
,	O
NN	B-Method
accurately	O
classifies	O
the	O
two	O
classes	O
of	O
the	O
source	O
sample	O
S	O
,	O
but	O
is	O
not	O
fully	O
adapted	O
to	O
the	O
target	O
sample	O
T	O
.	O
	
On	O
the	O
contrary	O
,	O
the	O
decision	O
boundary	O
of	O
DANN	B-Method
perfectly	O
classifies	O
examples	O
from	O
both	O
source	O
and	O
target	O
samples	O
.	O
	
In	O
the	O
studied	O
task	O
,	O
DANN	B-Method
clearly	O
adapts	O
to	O
the	O
target	O
distribution	O
.	O
	
The	O
column	O
"	O
Representation	B-Method
PCA	I-Method
"	O
studies	O
how	O
the	O
domain	B-Method
adaptation	I-Method
regularizer	I-Method
affects	O
the	O
representation	O
	
G	O
f	O
(	O
·	O
)	O
provided	O
by	O
the	O
network	B-Method
hidden	I-Method
layer	I-Method
.	O
	
The	O
graphs	O
are	O
obtained	O
by	O
applying	O
a	O
Principal	B-Method
component	I-Method
analysis	I-Method
(	O
PCA	B-Method
)	O
on	O
the	O
set	O
of	O
all	O
representation	O
of	O
source	O
and	O
target	O
data	O
points	O
,	O
i.e.	O
,	O
S	O
(	O
G	O
f	O
)	O
∪	O
T	O
(	O
G	O
f	O
)	O
.	O
	
Thus	O
,	O
given	O
the	O
trained	O
network	O
(	O
NN	B-Method
or	O
DANN	B-Method
)	O
,	O
every	O
point	O
from	O
S	O
and	O
T	O
is	O
mapped	O
into	O
a	O
15	O
-	O
dimensional	O
feature	O
space	O
through	O
the	O
hidden	O
layer	O
,	O
and	O
projected	O
back	O
into	O
a	O
two	O
-	O
dimensional	O
plane	O
by	O
the	O
PCA	B-Method
transformation	I-Method
.	O
	
In	O
the	O
DANN	B-Method
-	I-Method
PCA	I-Method
representation	I-Method
,	O
we	O
observe	O
that	O
target	O
points	O
are	O
homogeneously	O
spread	O
out	O
among	O
source	O
points	O
;	O
In	O
the	O
NN	B-Method
-	O
PCA	O
representation	O
,	O
a	O
number	O
of	O
target	O
points	O
belong	O
to	O
clusters	O
containing	O
no	O
source	O
points	O
.	O
	
Hence	O
,	O
labeling	O
the	O
target	O
points	O
seems	O
an	O
easier	O
task	O
given	O
the	O
DANN	B-Method
-	I-Method
PCA	I-Method
representation	I-Method
.	O
	
To	O
push	O
the	O
analysis	O
further	O
,	O
the	O
PCA	B-Method
graphs	I-Method
tag	O
four	O
crucial	O
data	O
points	O
by	O
the	O
letters	O
A	O
,	O
B	O
,	O
C	O
and	O
D	O
,	O
that	O
correspond	O
to	O
the	O
moon	O
extremities	O
in	O
the	O
original	O
space	O
(	O
note	O
that	O
the	O
original	O
point	O
locations	O
are	O
tagged	O
in	O
the	O
first	O
column	O
graphs	O
)	O
.	O
	
We	O
observe	O
that	O
points	O
A	O
and	O
B	O
are	O
very	O
close	O
to	O
each	O
other	O
in	O
the	O
NN	B-Method
-	O
PCA	O
representation	O
,	O
while	O
they	O
clearly	O
belong	O
to	O
different	O
classes	O
.	O
	
The	O
same	O
happens	O
to	O
points	O
C	O
and	O
D.	O
	
Conversely	O
,	O
these	O
four	O
points	O
are	O
at	O
the	O
opposite	O
four	O
corners	O
in	O
the	O
DANN	B-Method
-	I-Method
PCA	I-Method
representation	I-Method
.	O
	
Note	O
also	O
that	O
the	O
target	O
point	O
A	O
(	O
resp	O
.	O
	
D	O
)-	O
that	O
is	O
difficult	O
to	O
classify	O
in	O
the	O
original	O
space	O
-	O
is	O
located	O
in	O
the	O
"	O
+	O
"	O
cluster	O
(	O
resp	O
.	O
	
"	O
	
−	O
−	O
−"cluster	O
)	O
in	O
the	O
DANN	B-Method
-	I-Method
PCA	I-Method
representation	I-Method
.	O
	
Therefore	O
,	O
the	O
representation	O
promoted	O
by	O
DANN	B-Method
is	O
better	O
suited	O
to	O
the	O
adaptation	B-Task
problem	I-Task
.	O
	
The	O
column	O
"	O
Domain	B-Task
Classification	I-Task
"	O
shows	O
the	O
decision	O
boundary	O
on	O
the	O
domain	B-Task
classification	I-Task
problem	I-Task
,	O
which	O
is	O
given	O
by	O
the	O
domain	B-Method
regressor	I-Method
G	I-Method
d	I-Method
of	O
Equation	O
(	O
7	O
)	O
.	O
	
More	O
precisely	O
,	O
an	O
example	O
x	O
is	O
classified	O
as	O
a	O
source	O
example	O
when	O
G	O
d	O
(	O
G	O
f	O
(	O
x	O
)	O
)	O
	
≥	O
0.5	O
,	O
and	O
is	O
classified	O
as	O
a	O
domain	O
example	O
otherwise	O
.	O
	
Remember	O
that	O
,	O
during	O
the	O
learning	O
process	O
of	O
DANN	B-Method
,	O
the	O
G	B-Method
d	I-Method
regressor	I-Method
struggles	O
to	O
discriminate	O
between	O
source	O
and	O
target	O
domains	O
,	O
while	O
the	O
hidden	B-Method
representation	I-Method
G	O
f	O
(	O
·	O
)	O
is	O
adversarially	O
updated	O
to	O
prevent	O
it	O
to	O
succeed	O
.	O
	
As	O
explained	O
above	O
,	O
we	O
trained	O
a	O
domain	B-Method
regressor	I-Method
during	O
the	O
learning	B-Method
process	I-Method
of	O
NN	B-Method
,	O
but	O
without	O
allowing	O
it	O
to	O
influence	O
the	O
learned	O
representation	O
	
G	O
f	O
(	O
·	O
)	O
.	O
	
On	O
one	O
hand	O
,	O
the	O
DANN	B-Method
domain	O
regressor	O
clearly	O
fails	O
to	O
generalize	O
source	O
and	O
target	O
distribution	O
topologies	O
.	O
	
On	O
the	O
other	O
hand	O
,	O
the	O
NN	B-Method
domain	O
regressor	O
shows	O
a	O
better	O
(	O
although	O
imperfect	O
)	O
generalization	B-Metric
capability	I-Metric
.	O
	
Inter	O
alia	O
,	O
it	O
seems	O
to	O
roughly	O
capture	O
the	O
rotation	O
angle	O
of	O
the	O
target	O
distribution	O
.	O
	
This	O
again	O
corroborates	O
that	O
the	O
DANN	B-Method
representation	O
does	O
not	O
allow	O
discriminating	O
between	O
domains	O
.	O
	
The	O
column	O
"	O
Hidden	O
Neurons	O
"	O
shows	O
the	O
configuration	O
of	O
hidden	O
layer	O
neurons	O
(	O
by	O
Equation	O
4	O
,	O
we	O
have	O
that	O
each	O
neuron	O
is	O
indeed	O
a	O
linear	B-Method
regressor	I-Method
)	O
.	O
	
In	O
other	O
words	O
,	O
each	O
of	O
the	O
fifteen	O
plot	O
line	O
corresponds	O
to	O
the	O
coordinates	O
x	O
∈	O
R	O
2	O
for	O
which	O
the	O
i	O
-	O
th	O
component	O
of	O
G	O
f	O
(	O
x	O
)	O
equals	O
1	O
2	O
,	O
for	O
i	O
∈	O
{	O
1	O
,	O
.	O
.	O
	
.	O
	
,	O
15}.	O
We	O
observe	O
that	O
the	O
standard	O
NN	B-Method
neurons	O
are	O
grouped	O
in	O
three	O
clusters	O
,	O
each	O
one	O
allowing	O
to	O
generate	O
a	O
straight	O
line	O
of	O
the	O
zigzag	O
decision	O
boundary	O
for	O
the	O
label	B-Task
classification	I-Task
problem	I-Task
.	O
	
However	O
,	O
most	O
of	O
these	O
neurons	O
are	O
also	O
able	O
to	O
(	O
roughly	O
)	O
capture	O
the	O
rotation	O
angle	O
of	O
the	O
domain	B-Task
classification	I-Task
problem	I-Task
.	O
	
Hence	O
,	O
we	O
observe	O
that	O
the	O
adaptation	O
regularizer	O
of	O
DANN	B-Method
prevents	O
these	O
kinds	O
of	O
neurons	O
to	O
be	O
produced	O
.	O
	
It	O
is	O
indeed	O
striking	O
to	O
see	O
that	O
the	O
two	O
predominant	O
patterns	O
in	O
the	O
NN	B-Method
neurons	O
(	O
i.e.	O
,	O
the	O
two	O
parallel	O
lines	O
crossing	O
the	O
plane	O
from	O
lower	O
left	O
to	O
upper	O
right	O
)	O
are	O
vanishing	O
in	O
the	O
DANN	B-Method
neurons	O
.	O
	
section	O
:	O
Unsupervised	B-Method
Hyper	I-Method
-	I-Method
Parameter	I-Method
Selection	I-Method
	
To	O
perform	O
unsupervised	B-Task
domain	I-Task
adaption	I-Task
,	O
one	O
should	O
provide	O
ways	O
to	O
set	O
hyper	O
-	O
parameters	O
(	O
such	O
as	O
the	O
domain	O
regularization	O
parameter	O
λ	O
,	O
the	O
learning	B-Metric
rate	I-Metric
,	O
the	O
network	B-Method
architecture	I-Method
for	O
our	O
method	O
)	O
in	O
an	O
unsupervised	O
way	O
,	O
i.e.	O
,	O
without	O
referring	O
to	O
labeled	O
data	O
in	O
the	O
target	O
domain	O
.	O
	
In	O
the	O
following	O
experiments	O
of	O
Sections	O
5.1.3	O
and	O
5.1.4	O
,	O
we	O
select	O
the	O
hyper	O
-	O
parameters	O
of	O
each	O
algorithm	O
by	O
using	O
a	O
variant	O
of	O
reverse	B-Method
cross	I-Method
-	I-Method
validation	I-Method
approach	I-Method
proposed	O
by	O
[	O
reference	O
]	O
,	O
that	O
we	O
call	O
reverse	B-Method
validation	I-Method
.	O
	
To	O
evaluate	O
the	O
reverse	B-Metric
validation	I-Metric
risk	I-Metric
associated	O
to	O
a	O
tuple	O
of	O
hyper	O
-	O
parameters	O
,	O
we	O
proceed	O
as	O
follows	O
.	O
	
Given	O
the	O
labeled	O
source	O
sample	O
S	O
and	O
the	O
unlabeled	O
target	O
sample	O
T	O
,	O
we	O
split	O
each	O
set	O
into	O
training	O
sets	O
(	O
S	O
and	O
T	O
respectively	O
,	O
containing	O
90	O
%	O
of	O
the	O
original	O
examples	O
)	O
and	O
the	O
validation	O
sets	O
(	O
S	O
V	O
and	O
T	O
V	O
respectively	O
)	O
.	O
	
We	O
use	O
the	O
labeled	O
set	O
S	O
and	O
the	O
unlabeled	O
target	O
set	O
T	O
to	O
learn	O
a	O
classifier	B-Method
η	I-Method
.	O
	
Then	O
,	O
using	O
the	O
same	O
algorithm	O
,	O
we	O
learn	O
a	O
reverse	B-Method
classifier	I-Method
η	I-Method
r	I-Method
using	O
the	O
self	O
-	O
labeled	O
set	O
{	O
(	O
x	O
,	O
η	O
(	O
x	O
)	O
)	O
}	O
	
x∈T	O
and	O
the	O
unlabeled	O
part	O
of	O
S	O
as	O
target	O
sample	O
.	O
	
Finally	O
,	O
the	O
reverse	B-Method
classifier	I-Method
η	I-Method
r	I-Method
is	O
evaluated	O
on	O
the	O
validation	O
set	O
S	O
V	O
of	O
source	O
sample	O
.	O
	
We	O
then	O
say	O
that	O
the	O
classifier	B-Method
η	I-Method
has	O
a	O
reverse	B-Metric
validation	I-Metric
risk	I-Metric
of	O
R	O
S	O
V	O
(	O
η	O
r	O
)	O
.	O
	
The	O
process	O
is	O
repeated	O
with	O
multiple	O
values	O
of	O
hyper	O
-	O
parameters	O
and	O
the	O
selected	O
parameters	O
are	O
those	O
corresponding	O
to	O
the	O
classifier	B-Method
with	O
the	O
lowest	O
reverse	B-Metric
validation	I-Metric
risk	I-Metric
.	O
	
Note	O
that	O
when	O
we	O
train	O
neural	B-Method
network	I-Method
architectures	I-Method
,	O
the	O
validation	O
set	O
S	O
V	O
is	O
also	O
used	O
as	O
an	O
early	B-Metric
stopping	I-Metric
criterion	I-Metric
during	O
the	O
learning	O
of	O
η	B-Task
,	O
and	O
self	O
-	O
labeled	O
validation	O
set	O
{	O
(	O
x	O
,	O
η	O
(	O
x	O
)	O
)	O
}	O
	
x∈T	O
	
V	O
is	O
used	O
as	O
an	O
early	O
stopping	O
criterion	O
during	O
the	O
learning	B-Task
of	I-Task
η	I-Task
r	I-Task
.	O
	
We	O
also	O
observed	O
better	O
accuracies	B-Metric
when	O
we	O
initialized	O
the	O
learning	O
of	O
the	O
reverse	B-Method
classifier	I-Method
η	I-Method
r	I-Method
with	O
the	O
configuration	O
learned	O
by	O
the	O
network	B-Method
η	I-Method
.	O
	
section	O
:	O
Experiments	O
on	O
Sentiment	B-Material
Analysis	I-Material
Data	I-Material
Sets	I-Material
	
We	O
now	O
compare	O
the	O
performance	O
of	O
our	O
proposed	O
DANN	B-Method
algorithm	O
to	O
a	O
standard	O
neural	B-Method
network	I-Method
with	O
one	O
hidden	B-Method
layer	I-Method
(	O
NN	B-Method
)	O
described	O
by	O
Equation	O
(	O
5	O
)	O
,	O
and	O
a	O
Support	B-Method
Vector	I-Method
Machine	I-Method
(	O
SVM	B-Method
)	O
with	O
a	O
linear	B-Method
kernel	I-Method
.	O
	
We	O
compare	O
the	O
algorithms	O
on	O
the	O
Amazon	B-Material
reviews	I-Material
data	I-Material
set	I-Material
,	O
as	O
pre	O
-	O
processed	O
by	O
[	O
reference	O
]	O
.	O
This	O
data	O
set	O
includes	O
four	O
domains	O
,	O
each	O
one	O
composed	O
of	O
reviews	O
of	O
a	O
specific	O
kind	O
of	O
product	O
(	O
books	B-Material
,	O
dvd	B-Material
disks	I-Material
,	O
electronics	B-Material
,	O
and	O
kitchen	B-Material
appliances	I-Material
)	O
.	O
	
Reviews	B-Material
are	O
encoded	O
in	O
5	O
000	O
dimensional	O
feature	O
vectors	O
of	O
unigrams	O
and	O
bigrams	B-Method
,	O
and	O
labels	O
are	O
binary	O
:	O
"	O
0	O
"	O
if	O
the	O
product	O
is	O
ranked	O
up	O
to	O
3	O
stars	O
,	O
and	O
"	O
1	O
"	O
if	O
the	O
product	O
is	O
ranked	O
4	O
or	O
5	O
stars	O
.	O
	
We	O
perform	O
twelve	O
domain	B-Method
adaptation	I-Method
tasks	O
.	O
	
All	O
learning	B-Method
algorithms	I-Method
are	O
given	O
2	O
000	O
labeled	O
source	O
examples	O
and	O
2	O
000	O
unlabeled	O
target	O
examples	O
.	O
	
Then	O
,	O
we	O
evaluate	O
them	O
on	O
separate	O
target	O
test	O
sets	O
(	O
between	O
3	O
000	O
and	O
6	O
000	O
examples	O
)	O
.	O
	
Note	O
that	O
NN	B-Method
and	O
SVM	B-Method
do	O
not	O
use	O
the	O
unlabeled	O
target	O
sample	O
for	O
learning	B-Task
.	O
	
Here	O
are	O
more	O
details	O
about	O
the	O
procedure	O
used	O
for	O
each	O
learning	B-Method
algorithms	I-Method
leading	O
to	O
the	O
empirical	O
results	O
of	O
Table	O
1	O
:	O
Classification	B-Metric
accuracy	I-Metric
on	O
the	O
Amazon	B-Material
reviews	I-Material
data	I-Material
set	I-Material
,	O
and	O
Pairwise	B-Task
Poisson	I-Task
binomial	I-Task
test	I-Task
.	O
	
•	O
	
For	O
the	O
DANN	B-Method
algorithm	O
,	O
the	O
adaptation	O
parameter	O
λ	O
is	O
chosen	O
among	O
9	O
values	O
between	O
10	O
−2	O
and	O
1	O
on	O
a	O
logarithmic	O
scale	O
.	O
	
The	O
hidden	O
layer	O
size	O
l	O
is	O
either	O
50	O
or	O
100	O
.	O
	
Finally	O
,	O
the	O
learning	B-Metric
rate	I-Metric
µ	I-Metric
is	O
fixed	O
at	O
10	O
−3	O
.	O
	
•	O
	
For	O
the	O
NN	B-Method
algorithm	O
,	O
we	O
use	O
exactly	O
the	O
same	O
hyper	O
-	O
parameters	O
grid	O
and	O
training	B-Method
procedure	I-Method
as	O
DANN	B-Method
above	O
,	O
except	O
that	O
we	O
do	O
not	O
need	O
an	O
adaptation	O
parameter	O
.	O
	
Note	O
that	O
one	O
can	O
train	O
NN	B-Method
by	O
using	O
the	O
DANN	B-Method
implementation	O
(	O
Algorithm	O
1	O
)	O
with	O
λ	O
=	O
0	O
.	O
	
•	O
	
For	O
the	O
SVM	B-Method
algorithm	O
,	O
the	O
hyper	O
-	O
parameter	O
C	O
is	O
chosen	O
among	O
10	O
values	O
between	O
10	O
−5	O
and	O
1	O
on	O
a	O
logarithmic	O
scale	O
.	O
	
This	O
range	O
of	O
values	O
is	O
the	O
same	O
as	O
used	O
by	O
[	O
reference	O
]	O
in	O
their	O
experiments	O
.	O
	
As	O
presented	O
at	O
Section	O
5.1.2	O
,	O
we	O
used	O
reverse	B-Method
cross	I-Method
validation	I-Method
selecting	O
the	O
hyper	O
-	O
parameters	O
for	O
all	O
three	O
learning	B-Method
algorithms	I-Method
,	O
with	O
early	O
stopping	O
as	O
the	O
stopping	B-Metric
criterion	I-Metric
for	O
DANN	B-Method
and	O
NN	B-Method
.	O
	
The	O
"	O
Original	O
data	O
"	O
part	O
of	O
Table	O
1a	O
shows	O
the	O
target	O
test	O
accuracy	B-Metric
of	O
all	O
algorithms	O
,	O
and	O
Table	O
1b	O
reports	O
the	O
probability	O
that	O
one	O
algorithm	O
is	O
significantly	O
better	O
than	O
the	O
others	O
according	O
to	O
the	O
Poisson	B-Method
binomial	I-Method
test	I-Method
[	O
reference	O
]	O
.	O
	
We	O
note	O
that	O
DANN	B-Method
has	O
a	O
significantly	O
better	O
performance	O
than	O
NN	B-Method
and	O
SVM	B-Method
,	O
with	O
respective	O
probabilities	O
0.87	O
and	O
0.83	O
.	O
	
As	O
the	O
only	O
difference	O
between	O
DANN	B-Method
and	O
NN	B-Method
is	O
the	O
domain	B-Method
adaptation	I-Method
regularizer	I-Method
,	O
we	O
conclude	O
that	O
our	O
approach	O
successfully	O
helps	O
to	O
find	O
a	O
representation	O
suitable	O
for	O
the	O
target	O
domain	O
.	O
	
section	O
:	O
Combining	O
DANN	B-Method
with	O
Denoising	B-Method
Autoencoders	I-Method
	
We	O
now	O
investigate	O
on	O
whether	O
the	O
DANN	B-Method
algorithm	O
can	O
improve	O
on	O
the	O
representation	O
learned	O
by	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
Marginalized	B-Method
Stacked	I-Method
Denoising	I-Method
Autoencoders	I-Method
(	O
mSDA	B-Method
)	O
proposed	O
by	O
[	O
reference	O
]	O
.	O
	
In	O
brief	O
,	O
mSDA	B-Method
is	O
an	O
unsupervised	B-Method
algorithm	I-Method
that	O
learns	O
a	O
new	O
robust	B-Method
feature	I-Method
representation	I-Method
of	O
the	O
training	O
samples	O
.	O
	
It	O
takes	O
the	O
unlabeled	O
parts	O
of	O
both	O
source	O
and	O
target	O
samples	O
to	O
learn	O
a	O
feature	O
map	O
from	O
input	O
space	O
X	O
to	O
a	O
new	O
representation	O
space	O
.	O
	
As	O
a	O
denoising	B-Method
autoencoders	I-Method
algorithm	I-Method
,	O
it	O
finds	O
a	O
feature	B-Method
representation	I-Method
from	O
which	O
one	O
can	O
(	O
approximately	O
)	O
reconstruct	O
the	O
original	O
features	O
of	O
an	O
example	O
from	O
its	O
noisy	O
counterpart	O
.	O
	
[	O
reference	O
]	O
showed	O
that	O
using	O
mSDA	B-Method
with	O
a	O
linear	O
SVM	B-Method
classifier	O
reaches	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
performance	O
on	O
the	O
Amazon	B-Material
reviews	I-Material
data	I-Material
sets	I-Material
.	O
	
As	O
an	O
alternative	O
to	O
the	O
SVM	B-Method
,	O
we	O
propose	O
to	O
apply	O
our	O
Shallow	O
DANN	B-Method
algorithm	O
on	O
the	O
same	O
representations	O
generated	O
by	O
mSDA	B-Method
(	O
using	O
representations	O
of	O
both	O
source	O
and	O
target	O
samples	O
)	O
.	O
	
Note	O
that	O
,	O
even	O
if	O
mSDA	B-Method
and	O
DANN	B-Method
are	O
two	O
representation	B-Method
learning	I-Method
approaches	I-Method
,	O
they	O
optimize	O
different	O
objectives	O
,	O
which	O
can	O
be	O
complementary	O
.	O
	
We	O
perform	O
this	O
experiment	O
on	O
the	O
same	O
Amazon	B-Material
reviews	I-Material
data	I-Material
set	I-Material
described	O
in	O
the	O
previous	O
subsection	O
.	O
	
For	O
each	O
source	O
-	O
target	O
domain	O
pair	O
,	O
we	O
generate	O
the	O
mSDA	B-Method
representations	I-Method
using	O
a	O
corruption	B-Metric
probability	I-Metric
of	O
50	O
%	O
and	O
a	O
number	O
of	O
layers	O
of	O
5	O
.	O
	
We	O
then	O
execute	O
the	O
three	O
learning	B-Method
algorithms	I-Method
(	O
DANN	B-Method
,	O
NN	B-Method
,	O
and	O
SVM	B-Method
)	O
on	O
these	O
representations	O
.	O
	
More	O
precisely	O
,	O
following	O
the	O
experimental	O
procedure	O
of	O
[	O
reference	O
]	O
,	O
we	O
use	O
the	O
concatenation	O
of	O
the	O
output	O
of	O
the	O
5	O
layers	O
and	O
the	O
original	O
input	O
as	O
the	O
new	O
representation	O
.	O
	
Thus	O
,	O
each	O
example	O
is	O
now	O
encoded	O
in	O
a	O
vector	O
of	O
30	O
000	O
dimensions	O
.	O
	
Note	O
that	O
we	O
use	O
the	O
same	O
grid	B-Method
search	I-Method
as	O
in	O
the	O
previous	O
Subsection	O
5.1.3	O
,	O
but	O
use	O
a	O
learning	B-Metric
rate	I-Metric
µ	I-Metric
of	O
10	O
−4	O
for	O
both	O
DANN	B-Method
and	O
the	O
NN	B-Method
.	O
	
The	O
results	O
of	O
"	O
mSDA	B-Method
representation	I-Method
"	O
columns	O
in	O
Table	O
1a	O
confirm	O
that	O
combining	O
mSDA	B-Method
and	O
DANN	B-Method
is	O
a	O
sound	O
approach	O
.	O
	
Indeed	O
,	O
the	O
Poisson	B-Method
binomial	I-Method
test	I-Method
shows	O
that	O
DANN	B-Method
has	O
a	O
better	O
performance	O
than	O
the	O
NN	B-Method
and	O
the	O
SVM	B-Method
,	O
with	O
probabilities	O
0.92	O
and	O
0.88	O
respectively	O
,	O
as	O
reported	O
in	O
Table	O
1b	O
.	O
	
We	O
note	O
however	O
that	O
the	O
standard	O
NN	B-Method
and	O
the	O
SVM	B-Method
find	O
the	O
best	O
solution	O
on	O
respectively	O
the	O
second	O
and	O
the	O
fourth	O
tasks	O
.	O
	
This	O
suggests	O
that	O
DANN	B-Method
and	O
mSDA	B-Method
adaptation	O
strategies	O
are	O
not	O
fully	O
complementary	O
.	O
	
section	O
:	O
Proxy	O
Distance	O
	
The	O
theoretical	O
foundation	O
of	O
the	O
DANN	B-Method
algorithm	O
is	O
the	O
domain	B-Method
adaptation	I-Method
theory	I-Method
of	O
[	O
reference	O
][	O
reference	O
]	O
.	O
	
We	O
claimed	O
that	O
DANN	B-Method
finds	O
a	O
representation	O
in	O
which	O
the	O
source	O
and	O
the	O
target	O
example	O
are	O
hardly	O
distinguishable	O
.	O
	
Our	O
toy	O
experiment	O
of	O
Section	O
5.1.1	O
already	O
points	O
out	O
some	O
evidence	O
for	O
that	O
	
and	O
here	O
we	O
provide	O
analysis	O
on	O
real	O
data	O
.	O
	
To	O
do	O
so	O
,	O
we	O
compare	O
the	O
Proxy	O
A	O
-	O
distance	B-Metric
(	O
PAD	B-Method
)	O
on	O
various	O
representations	O
of	O
the	O
Amazon	B-Material
Reviews	I-Material
data	I-Material
set	I-Material
;	O
these	O
representations	O
are	O
obtained	O
by	O
running	O
either	O
NN	B-Method
,	O
DANN	B-Method
,	O
mSDA	B-Method
,	O
or	O
mSDA	B-Method
and	O
DANN	B-Method
combined	O
.	O
	
Recall	O
that	O
PAD	B-Method
,	O
as	O
described	O
in	O
Section	O
3.2	O
,	O
is	O
a	O
metric	O
estimating	O
the	O
similarity	B-Metric
of	O
the	O
source	O
and	O
the	O
target	O
representations	O
.	O
	
More	O
precisely	O
,	O
to	O
obtain	O
a	O
PAD	O
value	O
,	O
we	O
use	O
the	O
following	O
procedure	O
:	O
(	O
1	O
)	O
we	O
construct	O
the	O
data	O
set	O
U	O
of	O
Equation	O
(	O
2	O
)	O
using	O
both	O
source	O
and	O
target	O
representations	O
of	O
the	O
training	O
samples	O
;	O
(	O
2	O
)	O
we	O
randomly	O
split	O
U	O
in	O
two	O
subsets	O
of	O
equal	O
size	O
;	O
(	O
3	O
)	O
we	O
train	O
linear	B-Method
SVMs	I-Method
on	O
the	O
first	O
subset	O
of	O
U	O
using	O
a	O
large	O
range	O
of	O
C	O
values	O
;	O
(	O
4	O
)	O
we	O
compute	O
the	O
error	O
of	O
all	O
obtained	O
classifiers	B-Method
on	O
the	O
second	O
subset	O
of	O
U	O
;	O
and	O
(	O
5	O
)	O
we	O
use	O
the	O
lowest	O
error	O
to	O
compute	O
the	O
PAD	B-Metric
value	I-Metric
of	O
Equation	O
(	O
3	O
)	O
.	O
	
Firstly	O
,	O
Figure	O
3a	O
compares	O
the	O
PAD	O
of	O
DANN	B-Method
representations	O
obtained	O
in	O
the	O
experiments	O
of	O
Section	O
5.1.3	O
(	O
using	O
the	O
hyper	O
-	O
parameters	O
values	O
leading	O
to	O
the	O
results	O
of	O
Table	O
1	O
)	O
to	O
the	O
PAD	B-Method
computed	O
on	O
raw	O
data	O
.	O
	
As	O
expected	O
,	O
the	O
PAD	O
values	O
are	O
driven	O
down	O
by	O
the	O
DANN	B-Method
representations	O
.	O
	
Secondly	O
,	O
Figure	O
3b	O
compares	O
the	O
PAD	O
of	O
DANN	B-Method
representations	O
to	O
the	O
PAD	O
of	O
standard	O
NN	B-Method
representations	O
.	O
	
As	O
the	O
PAD	O
is	O
influenced	O
by	O
the	O
hidden	O
layer	O
size	O
(	O
the	O
discriminating	O
power	O
tends	O
to	O
increase	O
with	O
the	O
representation	O
length	O
)	O
,	O
we	O
fix	O
here	O
the	O
size	O
to	O
100	O
neurons	O
for	O
both	O
algorithms	O
.	O
	
We	O
also	O
fix	O
the	O
adaptation	O
parameter	O
of	O
DANN	B-Method
to	O
λ	O
0.31	O
;	O
it	O
was	O
the	O
value	O
that	O
has	O
been	O
selected	O
most	O
of	O
the	O
time	O
during	O
our	O
preceding	O
experiments	O
on	O
the	O
Amazon	B-Material
Reviews	I-Material
data	I-Material
set	I-Material
.	O
	
Again	O
,	O
DANN	B-Method
is	O
clearly	O
leading	O
to	O
the	O
lowest	O
PAD	O
values	O
.	O
	
Lastly	O
,	O
Figure	O
3c	O
presents	O
two	O
sets	O
of	O
results	O
related	O
to	O
Section	O
5.1.4	O
experiments	O
.	O
	
On	O
one	O
hand	O
,	O
we	O
reproduce	O
the	O
results	O
of	O
[	O
reference	O
]	O
,	O
which	O
noticed	O
that	O
the	O
mSDA	B-Method
representations	I-Method
have	O
greater	O
PAD	O
values	O
than	O
original	O
(	O
raw	O
)	O
data	O
.	O
	
Although	O
the	O
mSDA	B-Method
approach	O
clearly	O
helps	O
to	O
adapt	O
to	O
the	O
target	O
task	O
,	O
it	O
seems	O
to	O
contradict	O
the	O
theory	O
of	O
BenDavid	O
et	O
al	O
..	O
	
On	O
the	O
other	O
hand	O
,	O
we	O
observe	O
that	O
,	O
when	O
running	O
DANN	B-Method
on	O
top	O
of	O
mSDA	B-Method
(	O
using	O
the	O
hyper	O
-	O
parameters	O
values	O
leading	O
to	O
the	O
results	O
of	O
Table	O
1	O
)	O
,	O
the	O
obtained	O
representations	O
have	O
much	O
lower	O
PAD	B-Metric
values	I-Metric
.	O
	
These	O
observations	O
might	O
explain	O
the	O
improvements	O
provided	O
by	O
DANN	B-Method
when	O
combined	O
with	O
the	O
mSDA	B-Method
procedure	O
.	O
	
section	O
:	O
Experiments	O
with	O
Deep	B-Method
Networks	I-Method
on	O
Image	B-Task
Classification	I-Task
	
We	O
now	O
perform	O
extensive	O
evaluation	O
of	O
a	O
deep	B-Method
version	I-Method
of	O
DANN	B-Method
(	O
see	O
Subsection	O
4.2	O
)	O
on	O
a	O
number	O
of	O
popular	O
image	O
data	O
sets	O
and	O
their	O
modifications	O
.	O
	
These	O
include	O
large	O
-	O
scale	O
data	O
sets	O
of	O
small	O
images	O
popular	O
with	O
deep	B-Method
learning	I-Method
methods	I-Method
,	O
and	O
the	O
Office	O
data	O
sets	O
[	O
reference	O
]	O
,	O
which	O
are	O
a	O
de	O
facto	O
standard	O
for	O
domain	B-Method
adaptation	I-Method
in	O
computer	B-Task
vision	I-Task
,	O
but	O
have	O
much	O
fewer	O
images	O
.	O
	
section	O
:	O
Baselines	O
	
The	O
following	O
baselines	O
are	O
evaluated	O
in	O
the	O
experiments	O
of	O
this	O
subsection	O
.	O
	
The	O
source	B-Method
-	I-Method
only	I-Method
model	I-Method
is	O
trained	O
without	O
consideration	O
for	O
target	O
-	O
domain	O
data	O
(	O
no	O
domain	B-Method
classifier	I-Method
branch	I-Method
included	O
into	O
the	O
network	O
)	O
.	O
	
The	O
train	B-Method
-	I-Method
on	I-Method
-	I-Method
target	I-Method
model	I-Method
is	O
trained	O
on	O
the	O
target	O
domain	O
with	O
class	O
labels	O
revealed	O
.	O
	
This	O
model	O
serves	O
as	O
an	O
upper	O
bound	O
on	O
DA	B-Method
methods	O
,	O
assuming	O
that	O
target	O
data	O
are	O
abundant	O
and	O
the	O
shift	O
between	O
the	O
domains	O
is	O
considerable	O
.	O
	
In	O
addition	O
,	O
we	O
compare	O
our	O
approach	O
against	O
the	O
recently	O
proposed	O
unsupervised	O
DA	B-Method
method	O
based	O
on	O
subspace	B-Method
alignment	I-Method
(	I-Method
SA	I-Method
)	I-Method
[	O
reference	O
]	O
,	O
which	O
is	O
simple	O
to	O
setup	O
and	O
test	O
on	O
new	O
data	O
sets	O
,	O
but	O
has	O
also	O
been	O
shown	O
to	O
perform	O
very	O
well	O
in	O
experimental	O
comparisons	O
with	O
other	O
"	O
shallow	O
"	O
DA	B-Method
methods	O
.	O
	
To	O
boost	O
the	O
performance	O
of	O
this	O
baseline	O
,	O
we	O
pick	O
its	O
most	O
important	O
free	O
parameter	O
(	O
the	O
number	O
of	O
principal	O
components	O
)	O
from	O
the	O
range	O
{	O
2	O
,	O
.	O
.	O
	
.	O
	
,	O
60	O
}	O
,	O
so	O
that	O
the	O
test	O
performance	O
on	O
the	O
target	O
domain	O
is	O
maximized	O
.	O
	
To	O
apply	O
SA	B-Method
in	O
our	O
setting	O
,	O
we	O
train	O
a	O
source	B-Method
-	I-Method
only	I-Method
model	I-Method
and	O
then	O
consider	O
the	O
activations	O
of	O
the	O
last	O
hidden	O
layer	O
in	O
the	O
label	B-Method
predictor	I-Method
(	O
before	O
the	O
final	O
linear	B-Method
classifier	I-Method
)	O
as	O
descriptors	O
/	O
features	O
,	O
and	O
learn	O
the	O
mapping	O
between	O
the	O
source	O
and	O
the	O
target	O
domains	O
[	O
reference	O
]	O
.	O
	
Since	O
the	O
SA	B-Method
baseline	I-Method
requires	O
training	O
a	O
new	O
classifier	B-Method
after	O
adapting	O
the	O
features	O
,	O
and	O
in	O
order	O
to	O
put	O
all	O
the	O
compared	O
settings	O
on	O
an	O
equal	O
footing	O
,	O
we	O
retrain	O
the	O
last	O
layer	O
of	O
the	O
label	B-Method
predictor	I-Method
using	O
a	O
standard	O
linear	O
SVM	B-Method
[	O
reference	O
]	O
for	O
all	O
four	O
considered	O
methods	O
(	O
including	O
ours	O
;	O
the	O
performance	O
on	O
the	O
target	O
domain	O
remains	O
approximately	O
the	O
same	O
after	O
the	O
retraining	O
)	O
.	O
	
For	O
the	O
Office	O
data	O
set	O
[	O
reference	O
]	O
,	O
we	O
directly	O
compare	O
the	O
performance	O
of	O
our	O
full	B-Method
network	I-Method
(	O
feature	B-Method
extractor	I-Method
and	O
label	B-Method
predictor	I-Method
)	O
against	O
recent	O
DA	B-Method
approaches	O
using	O
previously	O
published	O
results	O
.	O
	
section	O
:	O
CNN	B-Method
architectures	I-Method
and	O
Training	O
Procedure	O
	
In	O
general	O
,	O
we	O
compose	O
feature	B-Method
extractor	I-Method
from	O
two	O
or	O
three	O
convolutional	B-Method
layers	I-Method
,	O
picking	O
their	O
exact	O
configurations	O
from	O
previous	O
works	O
.	O
	
More	O
precisely	O
,	O
four	O
different	O
architectures	O
were	O
used	O
in	O
our	O
experiments	O
.	O
	
The	O
first	O
three	O
are	O
shown	O
in	O
Figure	O
4	O
.	O
	
For	O
the	O
Office	O
domains	O
,	O
we	O
use	O
pre	O
-	O
trained	O
AlexNet	B-Method
from	O
the	O
Caffe	B-Method
-	I-Method
package	I-Method
.	O
	
The	O
adaptation	B-Method
architecture	I-Method
is	O
identical	O
to	O
.	O
	
[	O
reference	O
]	O
	
For	O
the	O
domain	B-Method
adaption	I-Method
component	I-Method
,	O
we	O
use	O
three	O
(	O
x→1024→1024→2	O
)	O
fully	B-Method
connected	I-Method
layers	I-Method
,	O
except	O
for	O
MNIST	B-Method
where	O
we	O
used	O
a	O
simpler	O
(	O
x→100→2	O
)	O
architecture	O
to	O
speed	O
up	O
the	O
experiments	O
.	O
	
Admittedly	O
these	O
choices	O
for	O
domain	B-Method
classifier	I-Method
are	O
arbitrary	O
,	O
and	O
better	O
adaptation	B-Task
performance	O
might	O
be	O
attained	O
if	O
this	O
part	O
of	O
the	O
architecture	O
is	O
tuned	O
.	O
	
(	O
x→1024→1024→2	O
)	O
	
For	O
the	O
loss	O
functions	O
,	O
we	O
set	O
L	O
y	O
and	O
L	O
d	O
to	O
be	O
the	O
logistic	B-Method
regression	I-Method
loss	I-Method
and	O
the	O
binomial	B-Method
cross	I-Method
-	I-Method
entropy	I-Method
respectively	O
.	O
	
Following	O
[	O
reference	O
]	O
we	O
also	O
use	O
dropout	O
and	O
2	O
-	O
norm	O
restriction	O
when	O
we	O
train	O
the	O
SVHN	B-Method
architecture	I-Method
.	O
	
section	O
:	O
A	O
2	B-Method
-	I-Method
layer	I-Method
domain	I-Method
classifier	I-Method
	
The	O
other	O
hyper	O
-	O
parameters	O
are	O
not	O
selected	O
through	O
a	O
grid	B-Method
search	I-Method
as	O
in	O
the	O
small	O
scale	O
experiments	O
of	O
Section	O
5.1	O
,	O
which	O
would	O
be	O
computationally	O
costly	O
.	O
	
Instead	O
,	O
the	O
learning	B-Metric
rate	I-Metric
is	O
adjusted	O
during	O
the	O
stochastic	B-Method
gradient	I-Method
descent	I-Method
using	O
the	O
following	O
formula	O
:	O
	
where	O
p	O
is	O
the	O
training	O
progress	O
linearly	O
changing	O
from	O
0	O
to	O
1	O
,	O
µ	O
0	O
=	O
0.01	O
,	O
α	O
=	O
10	O
and	O
β	O
	
=	O
0.75	O
	
(	O
the	O
schedule	O
was	O
optimized	O
to	O
promote	O
convergence	O
and	O
low	B-Metric
error	I-Metric
on	O
the	O
source	O
domain	O
)	O
.	O
	
A	O
momentum	O
term	O
of	O
0.9	O
is	O
also	O
used	O
.	O
	
The	O
domain	B-Method
adaptation	I-Method
parameter	O
λ	O
is	O
initiated	O
at	O
0	O
and	O
is	O
gradually	O
changed	O
to	O
1	O
using	O
the	O
following	O
schedule	O
:	O
	
where	O
γ	O
was	O
set	O
to	O
10	O
in	O
all	O
experiments	O
(	O
the	O
schedule	O
was	O
not	O
optimized	O
/	O
tweaked	O
)	O
.	O
	
This	O
strategy	O
allows	O
the	O
domain	B-Method
classifier	I-Method
to	O
be	O
less	O
sensitive	O
to	O
noisy	O
signal	O
at	O
the	O
early	O
stages	O
of	O
the	O
training	O
procedure	O
.	O
	
Note	O
however	O
that	O
these	O
λ	O
p	O
were	O
used	O
only	O
for	O
updating	O
the	O
feature	B-Method
extractor	I-Method
component	I-Method
	
G	O
f	O
.	O
	
For	O
updating	O
the	O
domain	B-Method
classification	I-Method
component	I-Method
,	O
we	O
used	O
a	O
fixed	O
λ	O
=	O
1	O
,	O
to	O
ensure	O
that	O
the	O
latter	O
trains	O
as	O
fast	O
as	O
the	O
label	B-Method
predictor	I-Method
G	I-Method
y	I-Method
.	O
	
[	O
reference	O
]	O
	
Finally	O
,	O
note	O
that	O
the	O
model	O
is	O
trained	O
on	O
128	O
-	O
sized	O
batches	O
(	O
images	O
are	O
preprocessed	O
by	O
the	O
mean	B-Method
subtraction	I-Method
)	O
.	O
	
A	O
half	O
of	O
each	O
batch	O
is	O
populated	O
by	O
the	O
samples	O
from	O
the	O
source	O
domain	O
(	O
with	O
known	O
labels	O
)	O
,	O
the	O
rest	O
constitutes	O
the	O
target	O
domain	O
(	O
with	O
labels	O
not	O
revealed	O
to	O
the	O
algorithms	O
except	O
for	O
the	O
train	B-Metric
-	I-Metric
on	I-Metric
-	I-Metric
target	I-Metric
baseline	I-Metric
)	O
.	O
	
section	O
:	O
Visualizations	B-Task
	
We	O
use	O
t	B-Method
-	I-Method
SNE	I-Method
(	O
van	O
der	O
Maaten	O
,	O
2013	O
)	O
projection	O
to	O
visualize	O
feature	O
distributions	O
at	O
different	O
points	O
of	O
the	O
network	O
,	O
while	O
color	O
-	O
coding	O
the	O
domains	O
(	O
Figure	O
5	O
)	O
.	O
	
As	O
we	O
already	O
observed	O
with	O
the	O
shallow	B-Method
version	I-Method
of	O
DANN	B-Method
(	O
see	O
Figure	O
2	O
)	O
,	O
there	O
is	O
a	O
strong	O
correspondence	O
6	O
.	O
	
Equivalently	O
,	O
one	O
can	O
use	O
the	O
same	O
λp	B-Method
for	O
both	O
feature	B-Method
extractor	I-Method
and	O
domain	B-Method
classification	I-Method
components	I-Method
,	O
but	O
use	O
a	O
learning	B-Metric
rate	I-Metric
of	O
µ	O
/	O
λp	O
for	O
the	O
latter	O
.	O
	
between	O
the	O
success	O
of	O
the	O
adaptation	O
in	O
terms	O
of	O
the	O
classification	B-Metric
accuracy	I-Metric
for	O
the	O
target	O
domain	O
,	O
and	O
the	O
overlap	O
between	O
the	O
domain	O
distributions	O
in	O
such	O
visualizations	B-Method
.	O
	
section	O
:	O
Results	O
On	O
Image	O
Data	O
Sets	O
	
We	O
now	O
discuss	O
the	O
experimental	O
settings	O
and	O
the	O
results	O
.	O
	
In	O
each	O
case	O
,	O
we	O
train	O
on	O
the	O
source	O
data	O
set	O
and	O
test	O
on	O
a	O
different	O
target	O
domain	O
data	O
set	O
,	O
with	O
considerable	O
shifts	O
between	O
domains	O
(	O
see	O
Figure	O
6	O
)	O
.	O
	
The	O
results	O
are	O
summarized	O
in	O
Table	O
2	O
and	O
Table	O
3	O
.	O
	
MNIST	O
→	O
	
MNIST	O
-	O
M.	O
	
Our	O
first	O
experiment	O
deals	O
with	O
the	O
MNIST	O
data	O
set	O
[	O
reference	O
]	O
.	O
	
In	O
order	O
to	O
obtain	O
the	O
target	O
domain	O
(	O
MNIST	O
-	O
M	O
)	O
we	O
blend	O
digits	O
from	O
the	O
original	O
set	O
over	O
patches	O
randomly	O
extracted	O
from	O
color	O
photos	O
from	O
BSDS500	O
	
[	O
reference	O
]	O
.	O
	
This	O
operation	O
is	O
formally	O
defined	O
for	O
two	O
images	O
I	O
1	O
,	O
I	O
2	O
	
as	O
I	O
out	O
ijk	O
=	O
	
|I	O
1	O
	
ijk	O
	
−	O
	
I	O
2	O
ijk	O
|	O
,	O
where	O
i	O
,	O
j	O
are	O
the	O
coordinates	O
of	O
a	O
pixel	O
and	O
k	O
is	O
a	O
channel	O
index	O
.	O
	
In	O
other	O
words	O
,	O
an	O
output	O
sample	O
is	O
produced	O
by	O
taking	O
a	O
patch	O
from	O
a	O
photo	O
and	O
inverting	O
its	O
pixels	O
at	O
positions	O
corresponding	O
to	O
the	O
pixels	O
of	O
a	O
digit	O
.	O
	
For	O
a	O
human	O
the	O
classification	B-Task
task	I-Task
becomes	O
only	O
slightly	O
harder	O
compared	O
to	O
the	O
original	O
data	O
set	O
(	O
the	O
digits	O
are	O
still	O
clearly	O
distinguishable	O
)	O
whereas	O
for	O
a	O
CNN	O
trained	O
on	O
MNIST	O
this	O
domain	O
is	O
quite	O
distinct	O
,	O
as	O
the	O
background	O
and	O
the	O
strokes	O
are	O
no	O
longer	O
constant	O
.	O
	
Consequently	O
,	O
the	O
source	B-Method
-	I-Method
only	I-Method
model	I-Method
performs	O
poorly	O
.	O
	
Our	O
approach	O
succeeded	O
at	O
aligning	O
feature	O
distributions	O
(	O
Figure	O
5	O
)	O
,	O
which	O
led	O
to	O
successful	O
adaptation	B-Task
results	O
(	O
considering	O
that	O
the	O
adaptation	B-Task
is	O
unsupervised	O
)	O
.	O
	
At	O
the	O
same	O
time	O
,	O
the	O
improvement	O
over	O
source	B-Method
-	I-Method
only	I-Method
model	I-Method
achieved	O
by	O
subspace	B-Method
alignment	I-Method
(	O
SA	B-Method
)	O
	
[	O
reference	O
]	O
)	O
is	O
quite	O
modest	O
,	O
thus	O
highlighting	O
the	O
difficulty	O
of	O
the	O
adaptation	B-Task
task	I-Task
.	O
	
Synthetic	O
numbers	O
→	O
SVHN	O
.	O
	
To	O
address	O
a	O
common	O
scenario	O
of	O
training	B-Task
on	O
synthetic	O
data	O
and	O
testing	O
on	O
real	O
data	O
,	O
we	O
use	O
Street	O
-	O
View	O
House	O
Number	O
data	O
set	O
SVHN	O
[	O
reference	O
]	O
as	O
the	O
target	O
domain	O
and	O
synthetic	O
digits	O
as	O
the	O
source	O
.	O
	
The	O
latter	O
(	O
Syn	O
Numbers	O
)	O
consists	O
of	O
≈	O
500	O
,	O
000	O
images	O
generated	O
by	O
ourselves	O
from	O
Windows	O
TM	O
fonts	O
by	O
varying	O
the	O
text	O
(	O
that	O
includes	O
different	O
one	O
-	O
,	O
two	O
-	O
,	O
and	O
three	O
-	O
digit	O
numbers	O
)	O
,	O
positioning	O
,	O
orientation	O
,	O
background	O
and	O
stroke	O
colors	O
,	O
and	O
the	O
amount	O
of	O
blur	O
.	O
	
The	O
degrees	O
of	O
variation	O
were	O
chosen	O
manually	O
to	O
simulate	O
SVHN	O
,	O
however	O
the	O
two	O
data	O
sets	O
are	O
still	O
rather	O
distinct	O
,	O
the	O
biggest	O
difference	O
being	O
the	O
structured	O
clutter	O
in	O
the	O
background	O
of	O
SVHN	O
images	O
.	O
	
The	O
proposed	O
backpropagation	B-Method
-	I-Method
based	I-Method
technique	I-Method
works	O
well	O
covering	O
almost	O
80	O
%	O
of	O
the	O
gap	O
between	O
training	O
with	O
source	O
data	O
only	O
and	O
training	O
on	O
target	O
domain	O
data	O
with	O
known	O
target	O
labels	O
.	O
	
In	O
contrast	O
,	O
SA	B-Method
[	O
reference	O
]	O
results	O
in	O
a	O
slight	O
classification	B-Metric
accuracy	I-Metric
drop	I-Metric
(	O
probably	O
due	O
to	O
the	O
information	O
loss	O
during	O
the	O
dimensionality	B-Task
reduction	I-Task
)	O
,	O
indicating	O
that	O
the	O
adaptation	B-Task
task	I-Task
is	O
even	O
more	O
challenging	O
than	O
in	O
the	O
case	O
of	O
the	O
MNIST	O
experiment	O
.	O
	
MNIST	O
↔	O
SVHN	O
.	O
	
In	O
this	O
experiment	O
,	O
we	O
further	O
increase	O
the	O
gap	O
between	O
distributions	O
,	O
and	O
test	O
on	O
MNIST	O
and	O
SVHN	O
,	O
which	O
are	O
significantly	O
different	O
in	O
appearance	O
.	O
	
Training	O
on	O
SVHN	O
even	O
without	O
adaptation	B-Method
is	O
challenging	O
-	O
classification	O
	
error	B-Metric
stays	O
high	O
during	O
the	O
first	O
150	O
epochs	O
.	O
	
In	O
order	O
to	O
avoid	O
ending	O
up	O
in	O
a	O
poor	O
local	O
minimum	O
we	O
,	O
therefore	O
,	O
do	O
not	O
use	O
learning	B-Method
rate	I-Method
annealing	I-Method
here	O
.	O
	
Obviously	O
,	O
the	O
two	O
directions	O
(	O
MNIST	O
→	O
SVHN	O
and	O
SVHN	O
→	O
MNIST	O
)	O
are	O
not	O
equally	O
difficult	O
.	O
	
As	O
SVHN	O
is	O
more	O
diverse	O
,	O
a	O
model	O
trained	O
on	O
SVHN	O
is	O
expected	O
to	O
be	O
more	O
generic	O
and	O
to	O
perform	O
reasonably	O
on	O
the	O
MNIST	O
data	O
set	O
.	O
	
This	O
,	O
indeed	O
,	O
turns	O
out	O
to	O
be	O
the	O
case	O
and	O
is	O
supported	O
by	O
the	O
appearance	O
of	O
the	O
Table	O
2	O
:	O
	
Classification	B-Metric
accuracies	I-Metric
for	O
digit	B-Task
image	I-Task
classifications	I-Task
for	O
different	O
source	O
and	O
target	O
domains	O
.	O
	
MNIST	O
-	O
M	O
corresponds	O
to	O
difference	O
-	O
blended	O
digits	O
over	O
nonuniform	O
background	O
.	O
	
The	O
first	O
row	O
corresponds	O
to	O
the	O
lower	B-Metric
performance	I-Metric
bound	I-Metric
(	O
i.e.	O
,	O
if	O
no	O
adaptation	O
is	O
performed	O
)	O
.	O
	
The	O
last	O
row	O
corresponds	O
to	O
training	O
on	O
the	O
target	O
domain	O
data	O
with	O
known	O
class	O
labels	O
(	O
upper	O
bound	O
on	O
the	O
DA	B-Method
performance	O
)	O
.	O
	
For	O
each	O
of	O
the	O
two	O
DA	B-Method
methods	O
[	O
reference	O
]	O
we	O
show	O
how	O
much	O
of	O
the	O
gap	O
between	O
the	O
lower	O
and	O
the	O
upper	O
bounds	O
was	O
covered	O
(	O
in	O
brackets	O
)	O
.	O
	
For	O
all	O
five	O
cases	O
,	O
our	O
approach	O
outperforms	O
[	O
reference	O
]	O
considerably	O
,	O
and	O
covers	O
a	O
big	O
portion	O
of	O
the	O
gap	O
.	O
	
Table	O
3	O
:	O
Accuracy	B-Metric
evaluation	O
of	O
different	O
DA	B-Method
approaches	O
on	O
the	O
standard	O
Office	O
[	O
reference	O
]	O
)	O
	
data	O
set	O
.	O
	
All	O
methods	O
(	O
except	O
SA	B-Method
)	O
are	O
evaluated	O
in	O
the	O
"	O
fullytransductive	O
"	O
protocol	O
(	O
some	O
results	O
are	O
reproduced	O
from	O
[	O
reference	O
]	O
.	O
Our	O
method	O
(	O
last	O
row	O
)	O
outperforms	O
competitors	O
setting	O
the	O
new	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
.	O
	
Syn	O
and	O
Real	O
denote	O
available	O
labeled	O
data	O
(	O
100	O
,	O
000	O
synthetic	O
and	O
430	O
real	O
images	O
respectively	O
)	O
;	O
Adapted	O
means	O
that	O
≈	O
31	O
,	O
000	O
unlabeled	O
target	O
domain	O
images	O
were	O
used	O
for	O
adaptation	B-Task
.	O
	
The	O
best	O
performance	O
is	O
achieved	O
by	O
employing	O
both	O
the	O
labeled	O
samples	O
and	O
the	O
large	O
unlabeled	O
corpus	O
in	O
the	O
target	O
domain	O
.	O
	
feature	O
distributions	O
.	O
	
We	O
observe	O
a	O
quite	O
strong	O
separation	O
between	O
the	O
domains	O
when	O
we	O
feed	O
them	O
into	O
the	O
CNN	O
trained	O
solely	O
on	O
MNIST	O
,	O
whereas	O
for	O
the	O
SVHN	O
-	O
trained	O
network	O
the	O
features	O
are	O
much	O
more	O
intermixed	O
.	O
	
This	O
difference	O
probably	O
explains	O
why	O
our	O
method	O
succeeded	O
in	O
improving	O
the	O
performance	O
by	O
adaptation	B-Task
in	O
the	O
SVHN	O
	
→	O
MNIST	O
scenario	O
(	O
see	O
Table	O
2	O
)	O
but	O
not	O
in	O
the	O
opposite	O
direction	O
(	O
SA	O
is	O
not	O
able	O
to	O
perform	O
adaptation	B-Task
in	O
this	O
case	O
either	O
)	O
.	O
	
Unsupervised	B-Method
adaptation	I-Method
from	O
MNIST	O
to	O
SVHN	O
gives	O
a	O
failure	O
example	O
for	O
our	O
approach	O
:	O
it	O
does	O
n't	O
manage	O
to	O
improve	O
upon	O
the	O
performance	O
of	O
the	O
non	B-Method
-	I-Method
adapted	I-Method
model	I-Method
which	O
achieves	O
≈	O
0.25	O
accuracy	B-Metric
(	O
we	O
are	O
unaware	O
of	O
any	O
unsupervised	O
DA	B-Method
methods	O
capable	O
of	O
performing	O
such	O
adaptation	O
)	O
.	O
	
Synthetic	O
Signs	O
→	O
GTSRB	B-Method
.	O
	
Overall	O
,	O
this	O
setting	O
is	O
similar	O
to	O
the	O
Syn	O
Numbers	O
→	O
SVHN	O
experiment	O
,	O
except	O
the	O
distribution	O
of	O
the	O
features	O
is	O
more	O
complex	O
due	O
to	O
the	O
significantly	O
larger	O
number	O
of	O
classes	O
(	O
43	O
instead	O
of	O
10	O
)	O
.	O
	
For	O
the	O
source	O
domain	O
we	O
obtained	O
100	O
,	O
000	O
synthetic	O
images	O
(	O
which	O
we	O
call	O
Syn	O
Signs	O
)	O
simulating	O
various	O
imaging	O
conditions	O
.	O
	
In	O
the	O
target	O
domain	O
,	O
we	O
use	O
31	O
,	O
367	O
random	O
training	O
samples	O
for	O
unsupervised	B-Task
adaptation	I-Task
and	O
the	O
rest	O
for	O
evaluation	O
.	O
	
Once	O
again	O
,	O
our	O
method	O
achieves	O
a	O
sensible	O
increase	O
in	O
performance	O
proving	O
its	O
suitability	O
for	O
the	O
synthetic	B-Task
-	I-Task
to	I-Task
-	I-Task
real	I-Task
data	I-Task
adaptation	I-Task
.	O
	
As	O
an	O
additional	O
experiment	O
,	O
we	O
also	O
evaluate	O
the	O
proposed	O
algorithm	O
for	O
semi	O
-	O
supervised	O
domain	B-Method
adaptation	I-Method
,	O
i.e.	O
,	O
when	O
one	O
is	O
additionally	O
provided	O
with	O
a	O
small	O
amount	O
of	O
labeled	O
target	O
data	O
.	O
	
Here	O
,	O
we	O
reveal	O
430	O
labeled	O
examples	O
(	O
10	O
samples	O
per	O
class	O
)	O
and	O
add	O
them	O
to	O
the	O
training	O
set	O
for	O
the	O
label	B-Task
predictor	I-Task
.	O
	
Figure	O
7	O
shows	O
the	O
change	O
of	O
the	O
validation	B-Metric
error	I-Metric
throughout	O
the	O
training	O
.	O
	
While	O
the	O
graph	O
clearly	O
suggests	O
that	O
our	O
method	O
can	O
be	O
beneficial	O
in	O
the	O
semi	B-Task
-	I-Task
supervised	I-Task
setting	I-Task
,	O
thorough	O
verification	O
of	O
semi	B-Task
-	I-Task
supervised	I-Task
setting	I-Task
is	O
left	O
for	O
future	O
work	O
.	O
	
Office	O
data	O
set	O
.	O
	
We	O
finally	O
evaluate	O
our	O
method	O
on	O
Office	O
data	O
set	O
,	O
which	O
is	O
a	O
collection	O
of	O
three	O
distinct	O
domains	O
:	O
Amazon	B-Material
,	O
DSLR	O
,	O
and	O
Webcam	O
.	O
	
Unlike	O
previously	O
discussed	O
data	O
sets	O
,	O
Office	B-Method
is	O
rather	O
small	O
-	O
scale	O
with	O
only	O
2817	O
labeled	O
images	O
spread	O
across	O
31	O
different	O
categories	O
in	O
the	O
largest	O
domain	O
.	O
	
The	O
amount	O
of	O
available	O
data	O
is	O
crucial	O
for	O
a	O
successful	O
training	O
of	O
a	O
deep	B-Method
model	I-Method
,	O
hence	O
we	O
opted	O
for	O
the	O
fine	O
-	O
tuning	O
of	O
the	O
CNN	B-Method
pre	O
-	O
trained	O
on	O
the	O
ImageNet	O
(	O
AlexNet	O
from	O
the	O
Caffe	B-Method
package	I-Method
,	O
see	O
as	O
it	O
is	O
done	O
in	O
some	O
recent	O
DA	B-Method
works	O
	
[	O
reference	O
][	O
reference	O
]	O
.	O
	
We	O
make	O
our	O
approach	O
more	O
comparable	O
with	O
by	O
using	O
exactly	O
the	O
same	O
network	B-Method
architecture	I-Method
replacing	O
domain	B-Method
mean	I-Method
-	I-Method
based	I-Method
regularization	I-Method
with	O
the	O
domain	B-Method
classifier	I-Method
.	O
	
Following	O
previous	O
works	O
,	O
we	O
assess	O
the	O
performance	O
of	O
our	O
method	O
across	O
three	O
transfer	B-Task
tasks	I-Task
most	O
commonly	O
used	O
for	O
evaluation	O
.	O
	
Our	O
training	O
protocol	O
is	O
adopted	O
from	O
;	O
[	O
reference	O
]	O
;	O
[	O
reference	O
]	O
as	O
during	O
adaptation	B-Task
we	O
use	O
all	O
available	O
labeled	O
source	O
examples	O
and	O
unlabeled	O
target	O
examples	O
(	O
the	O
premise	O
of	O
our	O
method	O
is	O
the	O
abundance	O
of	O
unlabeled	O
data	O
in	O
the	O
target	O
domain	O
)	O
.	O
	
Also	O
,	O
all	O
source	B-Material
domain	I-Material
data	I-Material
are	O
used	O
for	O
training	O
.	O
	
Under	O
this	O
"	O
fully	O
-	O
transductive	O
"	O
setting	O
,	O
our	O
method	O
is	O
able	O
to	O
improve	O
previously	O
-	O
reported	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
accuracy	B-Metric
for	O
unsupervised	B-Task
adaptation	I-Task
very	O
considerably	O
(	O
Table	O
3	O
)	O
,	O
especially	O
in	O
the	O
most	O
challenging	O
Amazon	O
→	O
	
Webcam	O
scenario	O
(	O
the	O
two	O
domains	O
with	O
the	O
largest	O
domain	O
shift	O
)	O
.	O
	
Interestingly	O
,	O
in	O
all	O
three	O
experiments	O
we	O
observe	O
a	O
slight	O
over	O
-	O
fitting	O
(	O
performance	O
on	O
the	O
target	O
domain	O
degrades	O
while	O
accuracy	B-Metric
on	O
the	O
source	O
continues	O
to	O
improve	O
)	O
as	O
training	O
progresses	O
,	O
however	O
,	O
it	O
does	O
n't	O
ruin	O
the	O
validation	B-Metric
accuracy	I-Metric
.	O
	
Moreover	O
,	O
switching	O
off	O
the	O
domain	B-Method
classifier	I-Method
branch	I-Method
makes	O
this	O
effect	O
far	O
more	O
apparent	O
,	O
from	O
which	O
we	O
conclude	O
that	O
our	O
technique	O
serves	O
as	O
a	O
regularizer	B-Method
.	O
	
section	O
:	O
Experiments	O
with	O
Deep	B-Method
Image	I-Method
Descriptors	I-Method
for	O
Re	B-Task
-	I-Task
Identification	I-Task
	
In	O
this	O
section	O
we	O
discuss	O
the	O
application	O
of	O
the	O
described	O
adaptation	B-Method
method	I-Method
to	O
person	B-Task
re	I-Task
-	I-Task
identification	I-Task
(	I-Task
re	I-Task
-	I-Task
i	I-Task
d	I-Task
)	I-Task
problem	I-Task
.	O
	
The	O
task	O
of	O
person	B-Task
re	I-Task
-	I-Task
identification	I-Task
is	O
to	O
associate	O
people	O
seen	O
from	O
different	O
camera	O
views	O
.	O
	
More	O
formally	O
,	O
it	O
can	O
be	O
defined	O
as	O
follows	O
:	O
given	O
two	O
sets	O
of	O
images	O
from	O
different	O
cameras	O
(	O
probe	O
and	O
gallery	O
)	O
such	O
that	O
each	O
person	O
depicted	O
in	O
the	O
probe	O
set	O
has	O
an	O
image	O
in	O
the	O
gallery	O
set	O
,	O
for	O
each	O
image	O
of	O
a	O
person	O
from	O
the	O
probe	O
set	O
find	O
an	O
image	O
of	O
the	O
same	O
person	O
in	O
the	O
gallery	O
set	O
.	O
	
Disjoint	O
camera	O
views	O
,	O
different	O
illumination	O
conditions	O
,	O
various	O
poses	O
and	O
low	O
quality	O
of	O
data	O
make	O
this	O
problem	O
difficult	O
even	O
for	O
humans	O
(	O
e.g.	O
,	O
[	O
reference	O
]	O
,	O
reports	O
human	O
performance	O
at	O
Rank1=71.08	B-Metric
%	O
)	O
.	O
	
Unlike	O
classification	B-Task
problems	I-Task
that	O
are	O
discussed	O
above	O
,	O
re	B-Task
-	I-Task
identification	I-Task
problem	I-Task
implies	O
that	O
each	O
image	O
is	O
mapped	O
to	O
a	O
vector	B-Method
descriptor	I-Method
.	O
	
The	O
distance	B-Metric
between	O
descriptors	O
is	O
then	O
used	O
to	O
match	O
images	O
from	O
the	O
probe	O
set	O
and	O
the	O
gallery	O
set	O
.	O
	
To	O
evaluate	O
results	O
of	O
re	O
-	O
i	O
d	O
methods	O
	
the	O
Cumulative	B-Method
Match	I-Method
Characteristic	I-Method
(	I-Method
CMC	I-Method
)	I-Method
curve	I-Method
is	O
commonly	O
used	O
.	O
	
It	O
is	O
a	O
plot	O
of	O
the	O
identification	B-Metric
rate	I-Metric
(	O
recall	B-Metric
)	O
at	O
rank	B-Metric
-	I-Metric
k	I-Metric
,	O
that	O
is	O
the	O
probability	O
of	O
the	O
matching	O
gallery	O
image	O
to	O
be	O
within	O
the	O
closest	O
k	O
images	O
(	O
in	O
terms	O
of	O
descriptor	O
distance	B-Metric
)	O
to	O
the	O
probe	O
image	O
.	O
	
Most	O
existing	O
works	O
train	O
descriptor	B-Method
mappings	I-Method
and	O
evaluate	O
them	O
within	O
the	O
same	O
data	O
set	O
containing	O
images	O
from	O
a	O
certain	O
camera	O
network	O
with	O
similar	O
imaging	O
conditions	O
.	O
	
Several	O
papers	O
,	O
however	O
,	O
observed	O
that	O
the	O
performance	O
of	O
the	O
resulting	O
re	B-Method
-	I-Method
identification	I-Method
systems	I-Method
drops	O
very	O
considerably	O
when	O
descriptors	O
trained	O
on	O
one	O
data	O
set	O
and	O
tested	O
on	O
another	O
.	O
	
It	O
is	O
therefore	O
natural	O
to	O
handle	O
such	O
cross	B-Task
-	I-Task
domain	I-Task
evaluation	I-Task
as	O
a	O
domain	B-Task
-	I-Task
adaptation	I-Task
problem	I-Task
,	O
where	O
each	O
camera	B-Method
network	I-Method
(	O
data	O
set	O
)	O
constitutes	O
a	O
domain	O
.	O
	
Recently	O
,	O
several	O
papers	O
with	O
significantly	O
improved	O
re	B-Metric
-	I-Metric
identification	I-Metric
performance	O
[	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
have	O
been	O
presented	O
,	O
with	O
[	O
reference	O
]	O
reporting	O
good	O
results	O
in	O
cross	B-Task
-	I-Task
data	I-Task
-	I-Task
set	I-Task
evaluation	I-Task
scenario	I-Task
.	O
	
At	O
the	O
moment	O
,	O
deep	B-Method
learning	I-Method
methods	I-Method
[	O
reference	O
]	O
do	O
not	O
achieve	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
results	O
probably	O
because	O
of	O
the	O
limited	O
size	O
of	O
the	O
training	O
sets	O
.	O
	
Domain	B-Method
adaptation	I-Method
thus	O
represents	O
a	O
viable	O
direction	O
for	O
improving	O
deep	B-Task
re	I-Task
-	I-Task
identification	I-Task
descriptors	I-Task
.	O
	
section	O
:	O
Data	O
Sets	O
and	O
Protocols	O
	
Following	O
[	O
reference	O
]	O
,	O
we	O
use	O
PRID	O
[	O
reference	O
]	O
,	O
VIPeR	O
[	O
reference	O
]	O
,	O
CUHK	O
[	O
reference	O
]	O
as	O
target	O
data	O
sets	O
for	O
our	O
experiments	O
.	O
	
The	O
PRID	O
data	O
set	O
exists	O
in	O
two	O
versions	O
,	O
and	O
as	O
in	O
[	O
reference	O
]	O
we	O
use	O
a	O
single	B-Method
-	I-Method
shot	I-Method
variant	I-Method
.	O
	
It	O
contains	O
images	O
of	O
385	O
persons	O
viewed	O
from	O
camera	O
A	O
and	O
images	O
of	O
749	O
persons	O
viewed	O
from	O
camera	O
B	O
,	O
200	O
persons	O
appear	O
in	O
both	O
cameras	O
.	O
	
The	O
VIPeR	O
data	O
set	O
also	O
contains	O
images	O
taken	O
with	O
two	O
cameras	O
,	O
and	O
in	O
total	O
632	O
persons	O
are	O
captured	O
,	O
for	O
every	O
person	O
there	O
is	O
one	O
image	O
for	O
each	O
of	O
the	O
two	O
camera	O
views	O
.	O
	
The	O
CUHK	O
data	O
set	O
consists	O
of	O
images	O
from	O
five	O
pairs	O
of	O
cameras	O
,	O
two	O
images	O
for	O
each	O
person	O
from	O
each	O
of	O
the	O
two	O
cameras	O
.	O
	
We	O
refer	O
to	O
the	O
subset	O
of	O
this	O
data	O
set	O
that	O
includes	O
the	O
first	O
pair	O
of	O
cameras	O
only	O
as	O
CUHK	O
/	O
p1	O
(	O
as	O
most	O
papers	O
use	O
this	O
subset	O
)	O
.	O
	
See	O
Figure	O
8	O
for	O
samples	O
of	O
these	O
data	O
sets	O
.	O
	
We	O
perform	O
extensive	O
experiments	O
for	O
various	O
pairs	O
of	O
data	O
sets	O
,	O
where	O
one	O
data	O
set	O
serves	O
as	O
a	O
source	O
domain	O
,	O
i.e.	O
,	O
it	O
is	O
used	O
to	O
train	O
a	O
descriptor	B-Method
mapping	I-Method
in	O
a	O
supervised	B-Method
way	I-Method
with	O
known	O
correspondences	O
between	O
probe	O
and	O
gallery	O
images	O
.	O
	
The	O
second	O
data	O
set	O
is	O
used	O
as	O
a	O
target	O
domain	O
,	O
so	O
that	O
images	O
from	O
that	O
data	O
set	O
are	O
used	O
without	O
probe	O
-	O
gallery	O
correspondence	O
.	O
	
In	O
more	O
detail	O
,	O
CUHK	O
/	O
p1	O
is	O
used	O
for	O
experiments	O
when	O
CUHK	O
serves	O
as	O
a	O
target	O
domain	O
and	O
two	O
settings	O
(	O
"	O
whole	O
CUHK	O
"	O
and	O
CUHK	O
/	O
p1	O
)	O
are	O
used	O
for	O
experiments	O
when	O
CUHK	O
serves	O
as	O
a	O
source	O
domain	O
.	O
	
Given	O
PRID	O
as	O
a	O
target	O
data	O
set	O
,	O
we	O
randomly	O
choose	O
100	O
persons	O
appearing	O
in	O
both	O
camera	O
views	O
as	O
training	O
set	O
.	O
	
The	O
images	O
of	O
the	O
other	O
100	O
persons	O
from	O
camera	O
A	O
are	O
used	O
as	O
probe	O
,	O
all	O
images	O
from	O
camera	O
B	O
excluding	O
those	O
used	O
in	O
training	O
(	O
649	O
in	O
total	O
)	O
are	O
used	O
as	O
gallery	O
at	O
test	O
time	O
.	O
	
For	O
VIPeR	O
,	O
we	O
use	O
random	O
316	O
persons	O
for	O
training	O
and	O
all	O
others	O
for	O
testing	O
.	O
	
For	O
CUHK	O
,	O
971	O
persons	O
are	O
split	O
into	O
485	O
for	O
training	O
and	O
486	O
for	O
testing	O
.	O
	
Unlike	O
[	O
reference	O
]	O
,	O
we	O
use	O
all	O
images	O
in	O
the	O
first	O
pair	O
of	O
cameras	O
of	O
CUHK	O
instead	O
of	O
choosing	O
one	O
image	O
of	O
a	O
person	O
from	O
each	O
camera	O
view	O
.	O
	
We	O
also	O
performed	O
two	O
experiments	O
with	O
all	O
images	O
of	O
the	O
whole	O
CUHK	O
data	O
set	O
as	O
source	O
domain	O
and	O
VIPeR	O
and	O
PRID	O
data	O
sets	O
as	O
target	O
domains	O
as	O
in	O
the	O
original	O
paper	O
[	O
reference	O
]	O
.	O
	
Following	O
[	O
reference	O
]	O
,	O
we	O
augmented	O
our	O
data	O
with	O
mirror	O
images	O
,	O
and	O
during	O
test	O
time	O
we	O
calculate	O
similarity	B-Metric
score	I-Metric
between	O
two	O
images	O
as	O
the	O
mean	O
of	O
the	O
four	O
scores	O
corresponding	O
to	O
different	O
flips	O
of	O
the	O
two	O
compared	O
images	O
.	O
	
In	O
case	O
of	O
CUHK	O
,	O
where	O
there	O
are	O
4	O
images	O
(	O
including	O
mirror	O
images	O
)	O
for	O
each	O
of	O
the	O
two	O
camera	O
views	O
for	O
each	O
person	O
,	O
all	O
16	O
combinations	O
'	O
scores	O
are	O
averaged	O
.	O
	
section	O
:	O
CNN	B-Method
architectures	I-Method
and	O
Training	O
Procedure	O
	
In	O
our	O
experiments	O
,	O
we	O
use	O
siamese	B-Method
architecture	I-Method
described	O
in	O
[	O
reference	O
]	O
(	O
Deep	B-Method
Metric	I-Method
Learning	I-Method
or	O
DML	B-Method
)	O
for	O
learning	O
deep	B-Task
image	I-Task
descriptors	I-Task
on	O
the	O
source	O
data	O
set	O
.	O
	
This	O
architecture	O
incorporates	O
two	O
convolution	B-Method
layers	I-Method
(	O
with	O
7	O
×	O
7	O
and	O
5	O
×	O
5	O
filter	B-Method
banks	I-Method
)	O
,	O
followed	O
by	O
ReLU	B-Method
and	I-Method
max	I-Method
pooling	I-Method
,	O
and	O
one	O
fully	B-Method
-	I-Method
connected	I-Method
layer	I-Method
,	O
which	O
gives	O
500	O
-	O
dimensional	O
descriptors	O
as	O
an	O
output	O
.	O
	
There	O
are	O
three	O
parallel	B-Method
flows	I-Method
within	O
the	O
CNN	B-Method
for	O
processing	O
three	O
part	O
of	O
an	O
image	O
:	O
the	O
upper	O
,	O
the	O
middle	O
,	O
and	O
the	O
lower	O
one	O
.	O
	
The	O
first	O
convolution	B-Method
layer	I-Method
shares	O
parameters	O
between	O
three	O
parts	O
,	O
and	O
the	O
outputs	O
of	O
the	O
second	O
convolution	B-Method
layers	I-Method
are	O
concatenated	O
.	O
	
During	O
training	O
,	O
we	O
follow	O
[	O
reference	O
]	O
and	O
calculate	O
pairwise	O
cosine	O
similarities	O
between	O
500	O
-	O
dimensional	O
features	O
within	O
each	O
batch	O
and	O
backpropagate	O
the	O
loss	O
for	O
all	O
pairs	O
within	O
batch	O
.	O
	
To	O
perform	O
domain	B-Method
-	I-Method
adversarial	I-Method
training	I-Method
,	O
we	O
construct	O
a	O
DANN	B-Method
architecture	O
.	O
	
The	O
feature	B-Method
extractor	I-Method
includes	O
the	O
two	O
convolutional	B-Method
layers	I-Method
(	O
followed	O
by	O
max	B-Method
-	I-Method
pooling	I-Method
and	O
ReLU	B-Method
)	O
discussed	O
above	O
.	O
	
The	O
label	B-Method
predictor	I-Method
in	O
this	O
case	O
is	O
replaced	O
with	O
descriptor	B-Method
predictor	I-Method
that	O
includes	O
one	O
fully	B-Method
-	I-Method
connected	I-Method
layer	I-Method
.	O
	
The	O
domain	B-Method
classifier	I-Method
includes	O
two	O
fully	B-Method
-	I-Method
connected	I-Method
layers	I-Method
with	O
500	O
units	O
in	O
the	O
intermediate	B-Method
representation	I-Method
(	O
x→500→1	O
)	O
.	O
	
For	O
the	O
verification	B-Metric
loss	I-Metric
function	I-Metric
in	O
the	O
descriptor	B-Method
predictor	I-Method
we	O
used	O
Binomial	O
Deviance	O
loss	O
,	O
defined	O
in	O
[	O
reference	O
]	O
with	O
similar	O
parameters	O
:	O
α	O
=	O
2	O
,	O
	
β	O
=	O
0.5	O
,	O
	
c	O
=	O
2	O
(	O
the	O
asymmetric	O
cost	O
parameter	O
for	O
negative	O
pairs	O
)	O
.	O
	
The	O
domain	B-Method
classifier	I-Method
is	O
trained	O
with	O
logistic	B-Method
loss	I-Method
as	O
in	O
subsection	O
5.2.2	O
.	O
	
We	O
used	O
learning	B-Metric
rate	I-Metric
fixed	O
to	O
0.001	O
and	O
momentum	O
of	O
0.9	O
.	O
	
The	O
schedule	O
of	O
adaptation	B-Task
similar	O
to	O
the	O
one	O
described	O
in	O
subsection	O
5.2.2	O
was	O
used	O
.	O
	
We	O
also	O
inserted	O
dropout	O
layer	O
with	O
rate	O
0.5	O
after	O
the	O
concatenation	O
of	O
outputs	O
of	O
the	O
second	O
max	B-Method
-	I-Method
pooling	I-Method
layer	I-Method
.	O
	
128	O
-	O
sized	O
batches	O
were	O
used	O
for	O
source	O
data	O
and	O
128	O
-	O
sized	O
batches	O
for	O
target	O
data	O
.	O
	
Figure	O
9	O
shows	O
results	O
in	O
the	O
form	O
of	O
CMC	O
-	O
curves	O
for	O
eight	O
pairs	O
of	O
data	O
sets	O
.	O
	
Depending	O
on	O
the	O
hardness	O
of	O
the	O
annotation	B-Task
problem	I-Task
we	O
trained	O
either	O
for	O
50	O
,	O
000	O
iterations	O
(	O
	
CUHK	O
/	O
p1	O
→	O
VIPeR	O
,	O
VIPeR	O
→	O
CUHK	O
/	O
p1	O
,	O
PRID	O
	
→	O
VIPeR	O
)	O
or	O
for	O
20	O
,	O
000	O
iterations	O
(	O
the	O
other	O
five	O
pairs	O
)	O
.	O
	
section	O
:	O
Results	O
on	O
Re	B-Task
-	I-Task
identification	I-Task
data	I-Task
sets	O
	
After	O
the	O
sufficient	O
number	O
of	O
iterations	O
,	O
domain	B-Method
-	I-Method
adversarial	I-Method
training	I-Method
consistently	O
improves	O
the	O
performance	O
of	O
re	B-Task
-	I-Task
identification	I-Task
.	O
	
For	O
the	O
pairs	O
that	O
involve	O
PRID	O
data	O
set	O
,	O
which	O
is	O
more	O
dissimilar	O
to	O
the	O
other	O
two	O
data	O
sets	O
,	O
the	O
improvement	O
is	O
considerable	O
.	O
	
Overall	O
,	O
this	O
demonstrates	O
the	O
applicability	O
of	O
the	O
domain	B-Method
-	I-Method
adversarial	I-Method
learning	I-Method
beyond	O
classification	B-Task
problems	I-Task
.	O
	
section	O
:	O
Conclusion	O
	
The	O
paper	O
proposes	O
a	O
new	O
approach	O
to	O
domain	B-Method
adaptation	I-Method
of	O
feed	B-Method
-	I-Method
forward	I-Method
neural	I-Method
networks	I-Method
,	O
which	O
allows	O
large	B-Task
-	I-Task
scale	I-Task
training	I-Task
based	O
on	O
large	O
amount	O
of	O
annotated	O
data	O
in	O
the	O
source	O
domain	O
and	O
large	O
amount	O
of	O
unannotated	O
data	O
in	O
the	O
target	O
domain	O
.	O
	
Similarly	O
to	O
many	O
previous	O
shallow	O
and	O
deep	O
DA	B-Method
techniques	O
,	O
the	O
adaptation	O
is	O
achieved	O
through	O
aligning	O
the	O
distributions	O
of	O
features	O
across	O
the	O
two	O
domains	O
.	O
	
However	O
,	O
unlike	O
previous	O
approaches	O
,	O
the	O
alignment	B-Task
is	O
accomplished	O
through	O
standard	B-Method
backpropagation	I-Method
training	O
.	O
	
The	O
approach	O
is	O
motivated	O
and	O
supported	O
by	O
the	O
domain	B-Method
adaptation	I-Method
theory	I-Method
of	O
[	O
reference	O
]	O
.	O
	
The	O
main	O
idea	O
behind	O
DANN	B-Method
is	O
to	O
enjoin	O
the	O
network	B-Method
hidden	I-Method
layer	I-Method
to	O
learn	O
a	O
representation	O
which	O
is	O
predictive	O
of	O
the	O
source	O
example	O
labels	O
,	O
but	O
uninformative	O
about	O
the	O
domain	O
of	O
the	O
input	O
(	O
source	O
or	O
target	O
)	O
.	O
	
We	O
implement	O
this	O
new	O
approach	O
within	O
both	O
shallow	B-Method
and	I-Method
deep	I-Method
feed	I-Method
-	I-Method
forward	I-Method
architectures	I-Method
.	O
	
The	O
latter	O
allows	O
simple	O
implementation	O
within	O
virtually	O
any	O
deep	B-Method
learning	I-Method
package	I-Method
through	O
the	O
introduction	O
of	O
a	O
simple	O
gradient	B-Method
reversal	I-Method
layer	I-Method
.	O
	
We	O
have	O
shown	O
that	O
our	O
approach	O
is	O
flexible	O
and	O
achieves	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
results	O
on	O
a	O
variety	O
of	O
benchmark	O
in	O
domain	B-Method
adaptation	I-Method
,	O
namely	O
for	O
sentiment	B-Task
analysis	I-Task
and	O
image	B-Task
classification	I-Task
tasks	I-Task
.	O
	
A	O
convenient	O
aspect	O
of	O
our	O
approach	O
is	O
that	O
the	O
domain	B-Method
adaptation	I-Method
component	I-Method
can	O
be	O
added	O
to	O
almost	O
any	O
neural	B-Method
network	I-Method
architecture	I-Method
that	O
is	O
trainable	O
with	O
backpropagation	B-Method
.	O
	
Towards	O
this	O
end	O
,	O
We	O
have	O
demonstrated	O
experimentally	O
that	O
the	O
approach	O
is	O
not	O
confined	O
to	O
classification	B-Task
tasks	I-Task
but	O
can	O
be	O
used	O
in	O
other	O
feed	B-Method
-	I-Method
forward	I-Method
architectures	I-Method
,	O
e.g.	O
,	O
for	O
descriptor	B-Task
learning	I-Task
for	O
person	B-Task
re	I-Task
-	I-Task
identification	I-Task
.	O
	
section	O
:	O
	
section	O
:	O
Acknowledgments	O
	
This	O
work	O
has	O
been	O
supported	O
by	O
National	O
Science	O
and	O
Engineering	O
Research	O
Council	O
	
(	O
NSERC	O
)	O
Discovery	O
grants	O
262067	O
and	O
0122405	O
as	O
well	O
as	O
the	O
Russian	O
Ministry	O
of	O
Science	O
and	O
Education	O
grant	O
	
RFMEFI57914X0071	O
.	O
	
Computations	O
were	O
performed	O
on	O
the	O
Colosse	O
supercomputer	O
grid	O
at	O
Université	O
Laval	O
,	O
under	O
the	O
auspices	O
of	O
Calcul	O
Québec	O
and	O
Compute	O
Canada	O
.	O
	
The	O
operations	O
of	O
Colosse	O
are	O
funded	O
by	O
the	O
NSERC	O
,	O
the	O
Canada	O
Foundation	O
for	O
Innovation	O
(	O
CFI	O
)	O
,	O
NanoQuébec	O
,	O
and	O
the	O
Fonds	O
de	O
recherche	O
	
du	O
Québec	O
-	O
Nature	O
et	O
technologies	O
(	O
FRQNT	O
)	O
.	O
	
We	O
also	O
thank	O
the	O
Graphics	O
&	O
Media	O
Lab	O
,	O
Faculty	O
of	O
Computational	O
Mathematics	O
and	O
Cybernetics	O
,	O
Lomonosov	O
Moscow	O
State	O
University	O
for	O
providing	O
the	O
synthetic	O
road	O
signs	O
data	O
set	O
.	O
	
section	O
:	O
	
document	O
:	O
PixelGAN	B-Method
Autoencoders	I-Method
	
In	O
this	O
paper	O
,	O
we	O
describe	O
the	O
‘	O
‘	O
PixelGAN	O
autoencoder	B-Method
’	O
’	O
,	O
a	O
generative	B-Method
autoencoder	I-Method
in	O
which	O
the	O
generative	B-Method
path	I-Method
is	O
a	O
convolutional	B-Method
autoregressive	I-Method
neural	I-Method
network	I-Method
on	I-Method
pixels	I-Method
(	O
PixelCNN	B-Method
)	O
that	O
is	O
conditioned	O
on	O
a	O
latent	O
code	O
,	O
and	O
the	O
recognition	B-Method
path	I-Method
uses	O
a	O
generative	B-Method
adversarial	I-Method
network	I-Method
(	O
GAN	B-Method
)	O
to	O
impose	O
a	O
prior	O
distribution	O
on	O
the	O
latent	O
code	O
.	O
	
We	O
show	O
that	O
different	O
priors	O
result	O
in	O
different	O
decompositions	O
of	O
information	O
between	O
the	O
latent	O
code	O
and	O
the	O
autoregressive	B-Method
decoder	I-Method
.	O
	
For	O
example	O
,	O
by	O
imposing	O
a	O
Gaussian	B-Method
distribution	I-Method
as	O
the	O
prior	O
,	O
we	O
can	O
achieve	O
a	O
global	O
vs.	O
local	O
decomposition	O
,	O
or	O
by	O
imposing	O
a	O
categorical	O
distribution	O
as	O
the	O
prior	O
,	O
we	O
can	O
disentangle	O
the	O
style	O
and	O
content	O
information	O
of	O
images	O
in	O
an	O
unsupervised	B-Method
fashion	I-Method
.	O
	
We	O
further	O
show	O
how	O
the	O
PixelGAN	O
autoencoder	B-Method
with	O
a	O
categorical	O
prior	O
can	O
be	O
directly	O
used	O
in	O
semi	B-Task
-	I-Task
supervised	I-Task
settings	I-Task
and	O
achieve	O
competitive	B-Task
semi	I-Task
-	I-Task
supervised	I-Task
classification	I-Task
results	O
on	O
the	O
MNIST	B-Material
,	O
SVHN	O
and	O
NORB	O
datasets	O
.	O
	
numbers	O
,	O
compressnatbib	O
	
section	O
:	O
Introduction	O
	
In	O
recent	O
years	O
,	O
generative	B-Method
models	I-Method
that	O
can	O
be	O
trained	O
via	O
direct	B-Method
back	I-Method
-	I-Method
propagation	I-Method
have	O
enabled	O
remarkable	O
progress	O
in	O
modeling	O
natural	O
images	O
.	O
	
One	O
of	O
the	O
most	O
successful	O
models	O
is	O
the	O
generative	B-Method
adversarial	I-Method
network	I-Method
(	O
GAN	B-Method
)	O
gan	B-Method
,	O
which	O
employs	O
a	O
two	B-Method
player	I-Method
min	I-Method
-	I-Method
max	I-Method
game	I-Method
.	O
	
The	O
generative	B-Method
model	I-Method
,	O
,	O
samples	O
the	O
prior	O
and	O
generates	O
the	O
sample	O
.	O
	
The	O
discriminator	B-Method
,	O
,	O
is	O
trained	O
to	O
identify	O
whether	O
a	O
point	O
is	O
a	O
sample	O
from	O
the	O
data	O
distribution	O
or	O
a	O
sample	O
from	O
the	O
generative	B-Method
model	I-Method
.	O
	
The	O
generator	O
is	O
trained	O
to	O
maximally	O
confuse	O
the	O
discriminator	O
into	O
believing	O
that	O
generated	O
samples	O
come	O
from	O
the	O
data	O
distribution	O
.	O
	
The	O
cost	B-Method
function	I-Method
of	O
GAN	B-Method
is	O
GANs	B-Method
can	O
be	O
considered	O
within	O
the	O
wider	O
framework	O
of	O
implicit	B-Method
generative	I-Method
models	I-Method
mohamed2016learning	O
,	O
ference	O
,	O
dustin	O
.	O
	
Implicit	O
distributions	O
can	O
be	O
sampled	O
through	O
their	O
generative	O
path	O
,	O
but	O
their	O
likelihood	B-Method
function	I-Method
is	O
not	O
tractable	O
.	O
	
Recently	O
,	O
several	O
papers	O
have	O
proposed	O
another	O
application	O
of	O
GAN	B-Method
-	O
style	O
algorithms	O
for	O
approximate	B-Task
inference	I-Task
,	O
mohamed2016learning	O
,	O
ference	O
,	O
dustin	O
,	O
ranganath2016operator	O
,	O
aae	B-Method
,	O
avb	O
,	O
ali	O
,	O
bigan	O
.	O
	
These	O
algorithms	O
use	O
implicit	O
distributions	O
to	O
learn	O
posterior	B-Method
approximations	I-Method
that	O
are	O
more	O
expressive	O
than	O
the	O
distributions	O
with	O
tractable	O
densities	O
that	O
are	O
often	O
used	O
in	O
variational	B-Task
inference	I-Task
.	O
	
For	O
example	O
,	O
adversarial	B-Method
autoencoders	I-Method
(	O
AAE	B-Method
)	O
aae	B-Method
use	O
a	O
universal	B-Method
approximator	I-Method
posterior	I-Method
as	O
the	O
implicit	O
posterior	O
distribution	O
and	O
use	O
adversarial	B-Method
training	O
to	O
match	O
the	O
aggregated	O
posterior	O
of	O
the	O
latent	O
code	O
to	O
the	O
prior	O
distribution	O
.	O
	
Adversarial	B-Method
variational	I-Method
Bayes	I-Method
ference	I-Method
,	O
avb	B-Method
uses	O
a	O
more	O
general	O
amortized	O
GAN	B-Method
inference	O
framework	O
within	O
a	O
maximum	B-Method
-	I-Method
likelihood	I-Method
learning	I-Method
setting	I-Method
.	O
	
Another	O
type	O
of	O
GAN	B-Method
inference	O
technique	O
is	O
used	O
in	O
the	O
ALI	B-Method
ali	I-Method
and	I-Method
BiGAN	I-Method
bigan	I-Method
models	I-Method
,	O
which	O
have	O
been	O
shown	O
to	O
approximate	O
maximum	B-Method
likelihood	I-Method
learning	I-Method
ference	I-Method
.	O
	
In	O
these	O
models	O
,	O
both	O
the	O
recognition	B-Method
and	I-Method
generative	I-Method
models	I-Method
are	O
implicit	O
and	O
are	O
jointly	O
learnt	O
by	O
an	O
adversarial	B-Method
training	O
process	O
.	O
	
Variational	B-Method
autoencoders	I-Method
(	O
VAE	B-Method
)	O
	
vae	B-Method
,	O
rezende	B-Method
are	O
another	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
image	B-Method
modeling	I-Method
technique	I-Method
that	O
use	O
neural	B-Method
networks	I-Method
to	O
parametrize	O
the	O
posterior	O
distribution	O
and	O
pair	O
it	O
with	O
a	O
top	B-Method
-	I-Method
down	I-Method
generative	I-Method
network	I-Method
.	O
	
Both	O
networks	O
are	O
jointly	O
trained	O
to	O
maximize	O
a	O
variational	B-Metric
lower	I-Metric
bound	I-Metric
on	O
the	O
data	O
log	O
-	O
likelihood	O
.	O
	
A	O
different	O
framework	O
for	O
learning	O
density	B-Method
models	I-Method
is	O
autoregressive	B-Method
neural	I-Method
networks	I-Method
such	O
as	O
NADE	O
nade	O
,	O
MADE	O
made	O
,	O
PixelRNN	O
pixelrnn	O
and	O
PixelCNN	B-Method
pixelcnn	I-Method
.	O
	
Unlike	O
variational	B-Method
autoencoders	I-Method
,	O
which	O
capture	O
the	O
statistics	O
of	O
the	O
data	O
in	O
hierarchical	O
latent	O
codes	O
,	O
the	O
autoregressive	B-Method
models	I-Method
learn	O
the	O
image	O
densities	O
directly	O
at	O
the	O
pixel	O
level	O
without	O
learning	O
a	O
hierarchical	B-Method
latent	I-Method
representation	I-Method
.	O
	
In	O
this	O
paper	O
,	O
we	O
present	O
the	O
PixelGAN	O
autoencoder	B-Method
as	O
a	O
generative	B-Method
autoencoder	I-Method
that	O
combines	O
the	O
benefits	O
of	O
latent	B-Method
variable	I-Method
models	I-Method
with	O
autoregressive	B-Method
architectures	I-Method
.	O
	
The	O
PixelGAN	O
autoencoder	B-Method
is	O
a	O
generative	B-Method
autoencoder	I-Method
in	O
which	O
the	O
generative	O
path	O
is	O
a	O
PixelCNN	B-Method
that	O
is	O
conditioned	O
on	O
a	O
latent	O
variable	O
.	O
	
The	O
latent	O
variable	O
is	O
inferred	O
by	O
matching	O
the	O
aggregated	O
posterior	O
distribution	O
to	O
the	O
prior	O
distribution	O
by	O
an	O
adversarial	B-Method
training	O
technique	O
similar	O
to	O
that	O
of	O
the	O
adversarial	B-Method
autoencoder	I-Method
aae	I-Method
.	O
	
However	O
,	O
whereas	O
in	O
adversarial	B-Method
autoencoders	O
the	O
statistics	O
of	O
the	O
data	O
distribution	O
are	O
captured	O
by	O
the	O
latent	O
code	O
,	O
in	O
the	O
PixelGAN	O
autoencoder	B-Method
they	O
are	O
captured	O
jointly	O
by	O
the	O
latent	B-Method
code	I-Method
and	O
the	O
autoregressive	B-Method
decoder	I-Method
.	O
	
We	O
show	O
that	O
imposing	O
different	O
distributions	O
as	O
the	O
prior	O
results	O
in	O
different	O
factorizations	O
of	O
information	O
between	O
the	O
latent	O
code	O
and	O
the	O
autoregressive	B-Method
decoder	I-Method
.	O
	
For	O
example	O
,	O
in	O
:	O
pixelgan_gaussian	O
]	O
Section	O
[	O
reference	O
]	O
,	O
we	O
show	O
that	O
by	O
imposing	O
a	O
Gaussian	O
distribution	O
on	O
the	O
latent	O
code	O
,	O
we	O
can	O
achieve	O
a	O
global	O
vs.	O
local	O
decomposition	O
of	O
information	O
.	O
	
In	O
this	O
case	O
,	O
the	O
global	B-Method
latent	I-Method
code	I-Method
no	O
longer	O
has	O
to	O
model	O
all	O
the	O
irrelevant	O
and	O
fine	O
details	O
of	O
the	O
image	O
,	O
and	O
can	O
use	O
its	O
capacity	O
to	O
capture	O
more	O
relevant	O
and	O
global	O
statistics	O
of	O
the	O
image	O
.	O
	
Another	O
type	O
of	O
decomposition	O
of	O
information	O
that	O
can	O
be	O
learnt	O
by	O
PixelGAN	B-Method
autoencoders	I-Method
is	O
a	O
discrete	B-Method
vs.	I-Method
continuous	I-Method
decomposition	I-Method
.	O
	
In	O
:	O
pixelgan_cat	O
]	O
Section	O
[	O
reference	O
]	O
,	O
we	O
show	O
that	O
we	O
can	O
achieve	O
this	O
decomposition	O
by	O
imposing	O
a	O
categorical	O
prior	O
on	O
the	O
latent	O
code	O
using	O
adversarial	B-Method
training	O
.	O
	
In	O
this	O
case	O
,	O
the	O
categorical	O
latent	O
code	O
captures	O
the	O
discrete	O
underlying	O
factors	O
of	O
variation	O
in	O
the	O
data	O
,	O
such	O
as	O
class	O
label	O
information	O
,	O
and	O
the	O
autoregressive	B-Method
decoder	I-Method
captures	O
the	O
remaining	O
continuous	O
structure	O
,	O
such	O
as	O
style	O
information	O
,	O
in	O
an	O
unsupervised	B-Method
fashion	I-Method
.	O
	
We	O
then	O
show	O
how	O
PixelGAN	B-Method
autoencoders	I-Method
with	O
categorical	O
priors	O
can	O
be	O
directly	O
used	O
in	O
clustering	B-Task
and	I-Task
semi	I-Task
-	I-Task
supervised	I-Task
scenarios	I-Task
and	O
achieve	O
very	O
competitive	O
classification	B-Task
results	O
on	O
several	O
datasets	O
in	O
:	O
experiments	O
]	O
Section	O
[	O
reference	O
]	O
.	O
	
Finally	O
,	O
we	O
present	O
one	O
of	O
the	O
main	O
potential	O
applications	O
of	O
PixelGAN	B-Method
autoencoders	I-Method
in	O
learning	B-Task
cross	I-Task
-	I-Task
domain	I-Task
relations	I-Task
between	O
two	O
different	O
domains	O
in	O
:	O
cross	O
-	O
domain	O
]	O
Section	O
[	O
reference	O
]	O
.	O
	
section	O
:	O
PixelGAN	B-Method
Autoencoders	I-Method
	
Let	O
be	O
a	O
datapoint	O
that	O
comes	O
from	O
the	O
distribution	O
and	O
be	O
the	O
hidden	O
code	O
.	O
	
The	O
recognition	B-Method
path	I-Method
of	O
the	O
PixelGAN	O
autoencoder	B-Method
(	O
:	O
pixelgan_gaussian	B-Method
]	I-Method
Figure	I-Method
[	O
reference	O
]	O
)	O
defines	O
an	O
implicit	O
posterior	O
distribution	O
by	O
using	O
a	O
deterministic	B-Method
neural	I-Method
function	I-Method
that	O
takes	O
the	O
input	O
along	O
with	O
random	O
noise	O
with	O
a	O
fixed	O
distribution	O
and	O
outputs	O
.	O
	
The	O
aggregated	O
posterior	O
of	O
this	O
model	O
is	O
defined	O
as	O
follows	O
:	O
This	O
parametrization	O
of	O
the	O
implicit	O
posterior	O
distribution	O
was	O
originally	O
proposed	O
in	O
the	O
adversarial	B-Method
autoencoder	I-Method
work	I-Method
aae	I-Method
as	O
the	O
universal	B-Method
approximator	I-Method
posterior	I-Method
.	O
	
We	O
can	O
sample	O
from	O
this	O
implicit	O
distribution	O
,	O
by	O
evaluating	O
at	O
different	O
samples	O
of	O
,	O
but	O
the	O
density	O
function	O
of	O
this	O
posterior	B-Method
distribution	I-Method
is	O
intractable	O
.	O
	
endix	O
:	O
	
input_noise	O
]	O
Appendix	O
[	O
reference	O
]	O
discusses	O
the	O
importance	O
of	O
the	O
input	O
noise	O
in	O
training	O
PixelGAN	B-Method
autoencoders	I-Method
.	O
	
The	O
generative	B-Method
path	I-Method
is	O
a	O
conditional	B-Method
PixelCNN	I-Method
pixelcnn	I-Method
that	O
conditions	O
on	O
the	O
latent	O
vector	O
using	O
an	O
adaptive	O
bias	O
in	O
PixelCNN	B-Method
layers	I-Method
.	O
	
The	O
inference	B-Task
is	O
done	O
by	O
an	O
amortized	O
GAN	B-Method
inference	O
technique	O
that	O
was	O
originally	O
proposed	O
in	O
the	O
adversarial	B-Method
autoencoder	I-Method
work	I-Method
aae	I-Method
.	O
	
In	O
this	O
method	O
,	O
an	O
adversarial	B-Method
network	O
is	O
attached	O
on	O
top	O
of	O
the	O
hidden	O
code	O
vector	O
of	O
the	O
autoencoder	B-Method
and	O
matches	O
the	O
aggregated	O
posterior	O
distribution	O
,	O
,	O
to	O
an	O
arbitrary	O
prior	O
,	O
.	O
	
Samples	O
from	O
and	O
are	O
provided	O
to	O
the	O
adversarial	B-Method
network	O
as	O
the	O
negative	O
and	O
positive	O
examples	O
respectively	O
,	O
and	O
the	O
generator	O
of	O
the	O
adversarial	B-Method
network	O
,	O
which	O
is	O
also	O
the	O
encoder	B-Method
of	O
the	O
autoencoder	B-Method
,	O
tries	O
to	O
match	O
to	O
by	O
the	O
gradient	O
that	O
comes	O
through	O
the	O
discriminative	O
adversarial	B-Method
network	O
.	O
	
The	O
adversarial	B-Method
network	O
,	O
the	O
PixelCNN	B-Method
decoder	I-Method
and	O
the	O
encoder	B-Method
are	O
trained	O
jointly	O
in	O
two	O
phases	O
–	O
the	O
reconstruction	B-Method
phase	I-Method
and	O
the	O
adversarial	B-Method
phase	O
–	O
executed	O
on	O
each	O
mini	O
-	O
batch	O
.	O
	
In	O
the	O
reconstruction	B-Task
phase	I-Task
,	O
the	O
ground	O
truth	O
input	O
along	O
with	O
the	O
hidden	O
code	O
inferred	O
by	O
the	O
encoder	B-Method
are	O
provided	O
to	O
the	O
PixelCNN	B-Method
decoder	I-Method
.	O
	
The	O
PixelCNN	O
decoder	O
weights	O
are	O
updated	O
to	O
maximize	O
the	O
log	O
-	O
likelihood	O
of	O
the	O
input	O
.	O
	
The	O
encoder	B-Method
weights	O
are	O
also	O
updated	O
at	O
this	O
stage	O
by	O
the	O
gradient	O
that	O
comes	O
through	O
the	O
conditioning	O
vector	O
of	O
the	O
PixelCNN	B-Method
.	O
	
In	O
the	O
adversarial	B-Method
phase	O
,	O
the	O
adversarial	B-Method
network	O
updates	O
both	O
its	O
discriminative	B-Method
network	I-Method
and	O
its	O
generative	B-Method
network	I-Method
(	O
the	O
encoder	B-Method
)	O
to	O
match	O
to	O
.	O
	
Once	O
the	O
training	O
is	O
done	O
,	O
we	O
can	O
sample	O
from	O
the	O
model	O
by	O
first	O
sampling	O
from	O
the	O
prior	O
distribution	O
,	O
and	O
then	O
sampling	O
from	O
the	O
conditional	O
likelihood	O
parametrized	O
by	O
the	O
PixelCNN	B-Method
decoder	I-Method
.	O
	
We	O
now	O
establish	O
a	O
connection	O
between	O
the	O
PixelGAN	O
autoencoder	B-Method
cost	O
and	O
maximum	B-Method
likelihood	I-Method
learning	I-Method
using	O
a	O
decomposition	O
of	O
the	O
aggregated	B-Method
evidence	I-Method
lower	I-Method
bound	I-Method
(	O
ELBO	B-Method
)	O
proposed	O
in	O
surgery	O
:	O
	
The	O
first	O
term	O
in	O
elbo	O
]	O
Equation	O
[	O
reference	O
]	O
is	O
the	O
reconstruction	O
term	O
and	O
the	O
second	O
term	O
is	O
the	O
marginal	O
KL	O
divergence	O
between	O
the	O
aggregated	O
posterior	O
and	O
the	O
prior	O
distribution	O
.	O
	
The	O
third	O
term	O
is	O
the	O
mutual	O
information	O
between	O
the	O
latent	O
code	O
and	O
the	O
input	O
.	O
	
This	O
is	O
a	O
regularization	B-Method
term	I-Method
that	O
encourages	O
and	O
to	O
be	O
decoupled	O
by	O
removing	O
the	O
information	O
of	O
the	O
data	O
distribution	O
from	O
the	O
hidden	O
code	O
.	O
	
If	O
the	O
training	O
set	O
has	O
examples	O
,	O
is	O
bounded	O
as	O
follows	O
(	O
see	O
surgery	O
)	O
.	O
	
In	O
order	O
to	O
maximize	O
the	O
ELBO	O
,	O
we	O
need	O
to	O
minimize	O
all	O
the	O
three	O
terms	O
of	O
elbo	O
]	O
Equation	O
[	O
reference	O
]	O
.	O
	
We	O
consider	O
two	O
cases	O
for	O
the	O
decoder	B-Method
:	O
Deterministic	B-Method
Decoder	I-Method
.	O
	
If	O
the	O
decoder	B-Method
is	O
deterministic	O
or	O
has	O
very	O
limited	O
stochasticity	O
such	O
as	O
the	O
simple	O
factorized	B-Method
decoder	I-Method
of	O
the	O
VAE	B-Method
,	O
the	O
mutual	O
information	O
term	O
acts	O
in	O
the	O
complete	O
opposite	O
direction	O
of	O
the	O
reconstruction	O
term	O
.	O
	
This	O
is	O
because	O
the	O
only	O
way	O
to	O
minimize	O
the	O
reconstruction	B-Metric
error	I-Metric
of	O
is	O
to	O
learn	O
a	O
hidden	O
code	O
that	O
is	O
relevant	O
to	O
,	O
which	O
results	O
in	O
maximizing	O
.	O
	
Indeed	O
,	O
it	O
can	O
be	O
shown	O
that	O
minimizing	O
the	O
reconstruction	O
term	O
maximizes	O
a	O
variational	B-Metric
lower	I-Metric
bound	I-Metric
on	O
i	B-Metric
m	I-Metric
,	O
infogan	O
.	O
	
For	O
example	O
,	O
in	O
the	O
case	O
of	O
the	O
VAE	B-Method
trained	O
on	O
MNIST	B-Material
,	O
since	O
the	O
reconstruction	B-Method
is	O
precise	O
,	O
the	O
mutual	B-Metric
information	I-Metric
term	I-Metric
is	O
dominated	O
and	O
is	O
close	O
to	O
its	O
maximum	O
value	O
surgery	O
.	O
	
Stochastic	B-Method
Decoder	I-Method
.	O
	
If	O
we	O
use	O
a	O
powerful	O
decoder	B-Method
such	O
as	O
the	O
PixelCNN	B-Method
,	O
the	O
reconstruction	O
term	O
and	O
the	O
mutual	O
information	O
term	O
will	O
not	O
compete	O
with	O
each	O
other	O
anymore	O
and	O
the	O
network	O
can	O
minimize	O
both	O
independently	O
.	O
	
In	O
this	O
case	O
,	O
the	O
optimal	O
solution	O
for	O
maximizing	O
the	O
ELBO	B-Task
would	O
be	O
to	O
model	O
solely	O
by	O
and	O
thereby	O
minimizing	O
the	O
reconstruction	O
term	O
,	O
and	O
at	O
the	O
same	O
time	O
,	O
minimizing	O
the	O
mutual	O
information	O
term	O
by	O
ignoring	O
the	O
latent	O
code	O
.	O
	
As	O
a	O
result	O
,	O
even	O
though	O
the	O
model	O
achieves	O
a	O
high	O
likelihood	O
,	O
the	O
latent	B-Method
code	I-Method
does	O
not	O
learn	O
any	O
useful	O
representation	O
,	O
which	O
is	O
undesirable	O
.	O
	
This	O
problem	O
has	O
been	O
observed	O
in	O
several	O
previous	O
works	O
bowman	B-Method
,	O
vlae	B-Method
and	O
different	O
techniques	O
such	O
as	O
annealing	O
the	O
weight	O
of	O
the	O
KL	B-Method
term	I-Method
bowman	I-Method
or	O
weakening	O
the	O
decoder	B-Method
vlae	I-Method
have	O
been	O
proposed	O
to	O
make	O
and	O
more	O
dependent	O
.	O
	
As	O
suggested	O
in	O
ference_ml	O
,	O
vlae	O
,	O
we	O
think	O
that	O
the	O
maximum	B-Metric
likelihood	I-Metric
objective	I-Metric
by	O
itself	O
is	O
not	O
a	O
useful	O
objective	O
for	O
representation	B-Task
learning	I-Task
especially	O
when	O
a	O
powerful	O
decoder	B-Method
is	O
used	O
.	O
	
In	O
PixelGAN	B-Method
autoencoders	I-Method
,	O
in	O
order	O
to	O
encourage	O
learning	O
more	O
useful	O
representations	O
,	O
we	O
modify	O
the	O
ELBO	B-Method
(	O
elbo	O
]	O
Equation	O
[	O
reference	O
]	O
)	O
by	O
removing	O
the	O
mutual	O
information	O
term	O
from	O
it	O
,	O
since	O
this	O
term	O
is	O
explicitly	O
encouraging	O
to	O
become	O
independent	O
of	O
.	O
	
So	O
our	O
cost	O
function	O
only	O
includes	O
the	O
reconstruction	O
term	O
and	O
the	O
marginal	O
KL	O
term	O
.	O
	
The	O
reconstruction	O
term	O
is	O
optimized	O
by	O
the	O
reconstruction	B-Method
phase	I-Method
of	I-Method
training	I-Method
and	O
the	O
marginal	B-Method
KL	I-Method
term	I-Method
is	O
approximately	O
optimized	O
by	O
the	O
adversarial	B-Method
phase	O
.	O
	
Note	O
that	O
since	O
the	O
mutual	O
information	O
term	O
is	O
upper	O
bounded	O
by	O
a	O
constant	O
(	O
)	O
,	O
we	O
are	O
still	O
maximizing	O
a	O
lower	O
bound	O
on	O
the	O
log	O
-	O
likelihood	O
of	O
data	O
.	O
	
However	O
,	O
this	O
bound	O
is	O
weaker	O
than	O
the	O
ELBO	B-Method
,	O
which	O
is	O
the	O
price	O
that	O
is	O
paid	O
for	O
learning	O
more	O
useful	O
latent	O
representations	O
by	O
balancing	O
the	O
decomposition	O
of	O
information	O
between	O
the	O
latent	O
code	O
and	O
the	O
autoregressive	B-Method
decoder	I-Method
.	O
	
For	O
implementing	O
the	O
conditioning	O
adaptive	O
bias	O
in	O
the	O
PixelCNN	B-Method
decoder	I-Method
,	O
we	O
explore	O
two	O
different	O
architectures	B-Method
pixelcnn	I-Method
.	O
	
In	O
the	O
location	O
-	O
invariant	O
bias	O
,	O
for	O
each	O
PixelCNN	B-Method
layer	I-Method
,	O
we	O
use	O
the	O
latent	O
code	O
to	O
construct	O
a	O
vector	O
that	O
is	O
broadcasted	O
within	O
each	O
feature	O
map	O
of	O
the	O
layer	O
and	O
then	O
added	O
as	O
an	O
adaptive	O
bias	O
to	O
that	O
layer	O
.	O
	
In	O
the	O
location	O
-	O
dependent	O
bias	O
,	O
we	O
use	O
the	O
latent	O
code	O
to	O
construct	O
a	O
spatial	O
feature	O
map	O
that	O
is	O
broadcasted	O
across	O
different	O
feature	O
maps	O
and	O
then	O
added	O
only	O
to	O
the	O
first	O
layer	O
of	O
the	O
decoder	B-Method
as	O
an	O
adaptive	O
bias	O
.	O
	
We	O
will	O
discuss	O
the	O
effect	O
of	O
these	O
architectures	O
on	O
the	O
learnt	B-Method
representation	I-Method
in	O
:	O
mnist_code	O
]	O
Figure	O
[	O
reference	O
]	O
of	O
:	O
	
pixelgan_gaussian	B-Method
]	I-Method
Section	I-Method
[	O
reference	O
]	O
and	O
their	O
implementation	O
details	O
in	O
endix	O
:	O
conditioning_of_pixelcnn	O
]	O
Appendix	O
[	O
reference	O
]	O
.	O
	
subsection	O
:	O
PixelGAN	B-Method
Autoencoders	I-Method
with	O
Gaussian	B-Method
Priors	I-Method
	
Here	O
,	O
we	O
show	O
that	O
PixelGAN	B-Method
autoencoders	I-Method
with	O
Gaussian	B-Method
priors	I-Method
can	O
decompose	O
the	O
global	O
and	O
local	O
statistics	O
of	O
the	O
images	O
between	O
the	O
latent	O
code	O
and	O
the	O
autoregressive	B-Method
decoder	I-Method
.	O
	
:	O
mnist	O
]	O
Figure	O
[	O
reference	O
]	O
a	O
shows	O
the	O
samples	O
of	O
a	O
PixelGAN	O
autoencoder	B-Method
model	O
with	O
the	O
location	B-Method
-	I-Method
dependent	I-Method
bias	I-Method
trained	O
on	O
the	O
MNIST	B-Material
dataset	O
.	O
	
For	O
the	O
purpose	O
of	O
better	O
illustrating	O
the	O
decomposition	B-Task
of	I-Task
information	I-Task
,	O
we	O
have	O
chosen	O
a	O
2	B-Method
-	I-Method
D	I-Method
Gaussian	I-Method
latent	I-Method
code	I-Method
and	O
a	O
limited	O
the	O
receptive	O
field	O
of	O
size	O
9	O
for	O
the	O
PixelGAN	O
autoencoder	B-Method
.	O
	
:	O
mnist	O
]	O
Figure	O
[	O
reference	O
]	O
b	O
shows	O
the	O
samples	O
of	O
a	O
PixelCNN	B-Method
model	I-Method
with	O
the	O
same	O
limited	O
receptive	O
field	O
size	O
of	O
9	O
and	O
:	O
mnist	O
]	O
Figure	O
[	O
reference	O
]	O
	
c	O
shows	O
the	O
samples	O
of	O
an	O
adversarial	B-Method
autoencoder	I-Method
with	O
the	O
2	B-Method
-	I-Method
D	I-Method
Gaussian	I-Method
latent	I-Method
code	I-Method
.	O
	
The	O
PixelCNN	B-Method
can	O
successfully	O
capture	O
the	O
local	O
statistics	O
,	O
but	O
fails	O
to	O
capture	O
the	O
global	O
statistics	O
due	O
to	O
the	O
limited	O
receptive	O
field	O
size	O
.	O
	
In	O
contrast	O
,	O
the	O
adversarial	B-Method
autoencoder	I-Method
,	O
whose	O
sample	B-Metric
quality	I-Metric
is	O
very	O
similar	O
to	O
that	O
of	O
the	O
VAE	B-Method
,	O
can	O
successfully	O
capture	O
the	O
global	O
statistics	O
,	O
but	O
fails	O
to	O
generate	O
the	O
details	O
of	O
the	O
images	O
.	O
	
However	O
,	O
the	O
PixelGAN	O
autoencoder	B-Method
,	O
with	O
the	O
same	O
receptive	O
field	O
and	O
code	O
size	O
,	O
can	O
combine	O
the	O
best	O
of	O
both	O
and	O
generates	O
sharp	O
images	O
with	O
global	O
statistics	O
.	O
	
In	O
PixelGAN	B-Method
autoencoders	I-Method
,	O
both	O
the	O
PixelCNN	O
depth	O
and	O
the	O
conditioning	B-Method
architecture	I-Method
affect	O
the	O
decomposition	O
of	O
information	O
between	O
the	O
latent	O
code	O
and	O
the	O
autoregressive	B-Method
decoder	I-Method
.	O
	
We	O
investigate	O
these	O
effects	O
in	O
:	O
mnist_code	O
]	O
Figure	O
[	O
reference	O
]	O
by	O
training	O
a	O
PixelGAN	O
autoencoder	B-Method
on	O
MNIST	B-Material
where	O
the	O
code	O
size	O
is	O
chosen	O
to	O
be	O
for	O
the	O
visualization	B-Task
purpose	I-Task
.	O
	
As	O
shown	O
in	O
:	O
mnist_code	O
]	O
Figure	O
[	O
reference	O
]	O
a	O
,	O
b	O
,	O
when	O
a	O
shallow	B-Method
decoder	I-Method
is	O
used	O
,	O
most	O
of	O
the	O
information	O
will	O
be	O
encoded	O
in	O
the	O
hidden	O
code	O
and	O
there	O
is	O
a	O
clean	O
separation	O
between	O
the	O
digit	O
clusters	O
.	O
	
As	O
we	O
make	O
the	O
PixelCNN	B-Method
more	O
powerful	O
(	O
:	O
mnist_code	O
]	O
Figure	O
[	O
reference	O
]	O
c	O
,	O
d	O
)	O
,	O
we	O
can	O
see	O
that	O
the	O
hidden	O
code	O
is	O
still	O
used	O
to	O
capture	O
some	O
relevant	O
information	O
of	O
the	O
input	O
,	O
but	O
the	O
separation	O
of	O
digit	O
clusters	O
is	O
not	O
as	O
sharp	O
when	O
the	O
limited	O
code	O
size	O
of	O
2	O
is	O
used	O
.	O
	
In	O
the	O
next	O
section	O
,	O
we	O
will	O
show	O
that	O
by	O
using	O
a	O
larger	O
code	O
size	O
(	O
e.g.	O
,	O
30	O
)	O
,	O
we	O
can	O
get	O
a	O
much	O
better	O
separation	O
of	O
digit	O
clusters	O
even	O
when	O
a	O
powerful	O
PixelCNN	B-Method
is	O
used	O
.	O
	
The	O
conditioning	B-Method
architecture	I-Method
also	O
affects	O
the	O
decomposition	B-Task
of	I-Task
information	I-Task
.	O
	
In	O
the	O
case	O
of	O
the	O
location	O
-	O
invariant	O
bias	O
,	O
the	O
hidden	O
code	O
is	O
encouraged	O
to	O
learn	O
the	O
global	O
information	O
that	O
is	O
location	O
-	O
invariant	O
(	O
the	O
what	O
information	O
and	O
not	O
the	O
where	O
information	O
)	O
such	O
as	O
the	O
class	O
label	O
information	O
.	O
	
For	O
example	O
,	O
we	O
can	O
see	O
in	O
:	O
	
mnist_code	O
]	O
Figure	O
[	O
reference	O
]	O
	
a	O
,	O
c	O
that	O
the	O
network	O
has	O
learnt	O
to	O
use	O
one	O
of	O
the	O
axes	O
of	O
the	O
2D	O
Gaussian	O
code	O
to	O
explicitly	O
encode	O
the	O
digit	O
label	O
even	O
though	O
a	O
continuous	O
prior	O
is	O
imposed	O
.	O
	
In	O
this	O
case	O
,	O
we	O
can	O
potentially	O
get	O
a	O
much	O
better	O
separation	O
if	O
we	O
impose	O
a	O
discrete	O
prior	O
.	O
	
This	O
makes	O
this	O
architecture	O
suitable	O
for	O
the	O
discrete	B-Task
vs.	I-Task
continuous	I-Task
decomposition	I-Task
and	O
we	O
use	O
it	O
for	O
our	O
clustering	B-Task
and	I-Task
semi	I-Task
-	I-Task
supervised	I-Task
learning	I-Task
experiments	I-Task
.	O
	
In	O
the	O
case	O
of	O
the	O
location	O
-	O
dependent	O
bias	O
(	O
:	O
mnist_code	O
]	O
Figure	O
[	O
reference	O
]	O
b	O
,	O
d	O
)	O
,	O
the	O
hidden	O
code	O
is	O
encouraged	O
to	O
learn	O
the	O
global	O
information	O
that	O
has	O
location	O
dependent	O
information	O
such	O
as	O
low	O
-	O
frequency	O
content	O
of	O
the	O
image	O
,	O
similar	O
to	O
what	O
the	O
hidden	O
code	O
of	O
an	O
adversarial	B-Method
or	O
variational	B-Method
autoencoder	I-Method
would	O
learn	O
(	O
:	O
mnist	O
]	O
Figure	O
[	O
reference	O
]	O
	
c	O
)	O
.	O
	
This	O
makes	O
this	O
architecture	O
suitable	O
for	O
the	O
global	B-Task
vs.	I-Task
local	I-Task
decomposition	I-Task
experiments	I-Task
such	O
as	O
:	O
mnist	O
]	O
Figure	O
[	O
reference	O
]	O
	
a.	O
	
From	O
:	O
mnist_code	O
]	O
Figure	O
[	O
reference	O
]	O
,	O
we	O
can	O
see	O
that	O
the	O
class	O
label	O
information	O
is	O
mostly	O
captured	O
by	O
while	O
the	O
style	O
information	O
of	O
the	O
images	O
is	O
captured	O
by	O
both	O
and	O
.	O
	
This	O
decomposition	O
of	O
information	O
has	O
also	O
been	O
studied	O
in	O
other	O
works	O
that	O
combine	O
the	O
latent	B-Method
variable	I-Method
models	I-Method
with	O
autoregressive	B-Method
decoders	I-Method
such	O
as	O
PixelVAE	B-Method
pixelvae	I-Method
and	O
variational	B-Method
lossy	I-Method
autoencoders	I-Method
(	O
VLAE	B-Method
)	O
vlae	O
.	O
	
For	O
example	O
,	O
the	O
VLAE	B-Method
model	O
vlae	O
proposes	O
to	O
use	O
the	O
depth	O
of	O
the	O
PixelCNN	B-Method
decoder	I-Method
to	O
control	O
the	O
decomposition	B-Task
of	I-Task
information	I-Task
.	O
	
In	O
their	O
model	O
,	O
the	O
PixelCNN	B-Method
decoder	I-Method
is	O
designed	O
to	O
have	O
a	O
shallow	O
depth	O
(	O
small	O
local	O
receptive	O
field	O
)	O
so	O
that	O
the	O
latent	O
code	O
is	O
forced	O
to	O
capture	O
more	O
global	O
information	O
.	O
	
This	O
approach	O
is	O
very	O
similar	O
to	O
our	O
example	O
of	O
the	O
PixelGAN	O
autoencoder	B-Method
in	O
:	O
mnist	O
]	O
Figure	O
[	O
reference	O
]	O
.	O
	
However	O
,	O
the	O
question	O
that	O
has	O
remained	O
unanswered	O
is	O
whether	O
it	O
is	O
possible	O
to	O
achieve	O
a	O
complete	O
decomposition	O
of	O
content	O
and	O
style	O
in	O
an	O
unsupervised	B-Method
fashion	I-Method
,	O
where	O
the	O
class	O
label	O
or	O
discrete	O
structure	O
information	O
is	O
encoded	O
in	O
the	O
latent	O
code	O
,	O
and	O
the	O
remaining	O
continuous	O
structure	O
such	O
as	O
style	O
is	O
captured	O
by	O
a	O
powerful	O
and	B-Method
deep	I-Method
PixelCNN	I-Method
decoder	I-Method
.	O
	
This	O
kind	O
of	O
decomposition	O
is	O
particularly	O
interesting	O
as	O
it	O
can	O
be	O
directly	O
used	O
for	O
clustering	O
and	O
semi	B-Task
-	I-Task
supervised	I-Task
classification	I-Task
.	O
	
In	O
the	O
next	O
section	O
,	O
we	O
show	O
that	O
we	O
can	O
learn	O
this	O
decomposition	O
of	O
content	O
and	O
style	O
by	O
imposing	O
a	O
categorical	O
distribution	O
on	O
the	O
latent	B-Method
representation	I-Method
using	O
adversarial	B-Method
training	O
.	O
	
Note	O
that	O
this	O
discrete	B-Method
vs.	I-Method
continuous	I-Method
decomposition	I-Method
is	O
very	O
different	O
from	O
the	O
global	O
vs.	O
local	O
decomposition	O
,	O
because	O
a	O
continuous	O
factor	O
of	O
variation	O
such	O
as	O
style	O
can	O
have	O
both	O
global	O
and	O
local	O
effect	O
on	O
the	O
image	O
.	O
	
Indeed	O
,	O
in	O
order	O
to	O
achieve	O
the	O
discrete	B-Task
vs.	I-Task
continuous	I-Task
decomposition	I-Task
,	O
we	O
have	O
to	O
use	O
very	O
deep	O
and	O
powerful	O
PixelCNN	B-Method
decoders	I-Method
(	O
up	O
to	O
20	O
residual	O
blocks	O
)	O
to	O
capture	O
both	O
the	O
global	O
and	O
local	O
statistics	O
of	O
the	O
style	O
by	O
the	O
PixelCNN	B-Method
while	O
the	O
discrete	O
content	O
of	O
the	O
image	O
is	O
captured	O
by	O
the	O
categorical	O
latent	O
variable	O
.	O
	
subsection	O
:	O
PixelGAN	B-Method
Autoencoders	I-Method
with	O
Categorical	B-Method
Priors	I-Method
	
In	O
this	O
section	O
,	O
we	O
present	O
an	O
architecture	O
of	O
the	O
PixelGAN	O
autoencoder	B-Method
that	O
can	O
separate	O
the	O
discrete	O
information	O
(	O
e.g.	O
,	O
class	O
label	O
)	O
from	O
the	O
continuous	O
information	O
(	O
e.g.	O
,	O
style	O
information	O
)	O
in	O
the	O
images	O
.	O
	
We	O
then	O
show	O
how	O
our	O
architecture	O
can	O
be	O
naturally	O
adopted	O
for	O
the	O
semi	B-Task
-	I-Task
supervised	I-Task
settings	I-Task
.	O
	
The	O
architecture	O
that	O
we	O
use	O
is	O
similar	O
to	O
:	O
pixelgan_gaussian	O
]	O
Figure	O
[	O
reference	O
]	O
,	O
with	O
the	O
difference	O
that	O
we	O
impose	O
a	O
categorical	O
distribution	O
as	O
the	O
prior	O
rather	O
the	O
Gaussian	B-Method
distribution	I-Method
(	O
:	O
pixelgan_cat	O
]	O
Figure	O
[	O
reference	O
]	O
)	O
and	O
also	O
use	O
the	O
location	B-Method
-	I-Method
independent	I-Method
bias	I-Method
architecture	I-Method
.	O
	
Another	O
difference	O
is	O
that	O
we	O
use	O
a	O
convolutional	B-Method
network	I-Method
as	O
the	O
inference	B-Method
network	I-Method
to	O
encourage	O
the	O
encoder	B-Method
to	O
preserve	O
the	O
content	O
and	O
lose	O
the	O
style	O
information	O
of	O
the	O
image	O
.	O
	
The	O
inference	B-Method
network	I-Method
has	O
a	O
softmax	O
output	O
and	O
predicts	O
a	O
one	O
-	O
hot	O
vector	O
whose	O
dimension	O
is	O
the	O
number	O
of	O
discrete	O
labels	O
or	O
categories	O
that	O
we	O
wish	O
the	O
data	O
to	O
be	O
clustered	O
into	O
.	O
	
The	O
adversarial	B-Method
network	O
is	O
trained	O
directly	O
on	O
the	O
continuous	O
probability	O
outputs	O
of	O
the	O
softmax	B-Method
layer	I-Method
of	O
the	O
encoder	B-Method
.	O
	
Imposing	O
a	O
categorical	O
distribution	O
at	O
the	O
output	O
of	O
the	O
encoder	B-Method
imposes	O
two	O
constraints	O
.	O
	
The	O
first	O
constraint	O
is	O
that	O
the	O
encoder	B-Method
has	O
to	O
make	O
confident	O
decisions	O
about	O
the	O
class	O
labels	O
of	O
the	O
inputs	O
.	O
	
The	O
adversarial	B-Method
training	O
pushes	O
the	O
output	O
of	O
the	O
encoder	B-Method
to	O
the	O
corners	O
of	O
the	O
softmax	O
simplex	O
,	O
by	O
which	O
it	O
ensures	O
that	O
the	O
autoencoder	B-Method
can	O
not	O
use	O
the	O
latent	O
vector	O
to	O
carry	O
any	O
continuous	O
style	O
information	O
.	O
	
The	O
second	O
constraint	O
imposed	O
by	O
adversarial	B-Method
training	O
is	O
that	O
the	O
aggregated	O
posterior	O
distribution	O
of	O
should	O
match	O
the	O
categorical	O
prior	O
distribution	O
with	O
uniform	O
outcome	O
probabilities	O
.	O
	
This	O
constraint	O
enforces	O
the	O
encoder	B-Method
to	O
evenly	O
distribute	O
the	O
class	O
labels	O
across	O
the	O
corners	O
of	O
the	O
softmax	O
simplex	O
.	O
	
Because	O
of	O
these	O
constraints	O
,	O
the	O
latent	O
variable	O
will	O
only	O
capture	O
the	O
discrete	O
content	O
of	O
the	O
image	O
and	O
all	O
the	O
continuous	O
style	O
information	O
will	O
be	O
captured	O
by	O
the	O
autoregressive	B-Method
decoder	I-Method
.	O
	
In	O
order	O
to	O
better	O
understand	O
and	O
visualize	O
the	O
effect	O
of	O
the	O
adversarial	B-Method
training	O
on	O
shaping	O
the	O
hidden	O
code	O
distribution	O
,	O
we	O
train	O
a	O
PixelGAN	O
autoencoder	B-Method
on	O
the	O
first	O
three	O
digits	O
of	O
MNIST	B-Material
(	O
18000	O
training	O
and	O
3000	O
test	O
points	O
)	O
and	O
choose	O
the	O
number	O
of	O
clusters	O
to	O
be	O
3	O
.	O
	
Suppose	O
is	O
the	O
hidden	O
code	O
which	O
in	O
this	O
case	O
is	O
the	O
output	O
probabilities	O
of	O
the	O
softmax	B-Method
layer	I-Method
of	O
the	O
inference	B-Method
network	I-Method
.	O
	
In	O
:	O
pixelgan_cluster_toy	O
]	O
Figure	O
[	O
reference	O
]	O
a	O
,	O
we	O
project	O
the	O
3D	O
softmax	O
simplex	O
of	O
onto	O
a	O
2D	O
triangle	O
and	O
plot	O
the	O
hidden	O
codes	O
of	O
the	O
training	O
examples	O
when	O
no	O
distribution	O
is	O
imposed	O
on	O
the	O
hidden	O
code	O
.	O
	
We	O
can	O
see	O
from	O
this	O
figure	O
that	O
the	O
network	O
has	O
learnt	O
to	O
use	O
the	O
surface	O
of	O
the	O
softmax	O
simplex	O
to	O
encode	O
style	O
information	O
of	O
the	O
digits	O
and	O
thus	O
the	O
three	O
corners	O
of	O
the	O
simplex	O
do	O
not	O
have	O
any	O
meaningful	O
interpretation	O
.	O
:	O
	
pixelgan_cluster_toy	O
]	O
Figure	O
[	O
reference	O
]	O
	
b	O
corresponds	O
to	O
the	O
code	O
space	O
of	O
the	O
same	O
network	O
when	O
a	O
categorical	O
distribution	O
is	O
imposed	O
using	O
the	O
adversarial	B-Method
training	O
.	O
	
In	O
this	O
case	O
,	O
we	O
can	O
see	O
the	O
network	O
has	O
successfully	O
learnt	O
to	O
encode	O
the	O
label	O
information	O
of	O
the	O
three	O
digits	O
in	O
the	O
three	O
corners	O
of	O
the	O
simplex	O
,	O
and	O
all	O
the	O
style	O
information	O
has	O
been	O
separately	O
captured	O
by	O
the	O
autoregressive	B-Method
decoder	I-Method
.	O
	
This	O
network	O
achieves	O
an	O
almost	O
perfect	O
test	B-Metric
error	I-Metric
-	I-Metric
rate	I-Metric
of	O
on	O
the	O
first	O
three	O
digits	O
of	O
MNIST	B-Material
,	O
even	O
though	O
it	O
is	O
trained	O
in	O
a	O
purely	O
unsupervised	B-Method
fashion	I-Method
.	O
	
Once	O
the	O
PixelGAN	O
autoencoder	B-Method
is	O
trained	O
,	O
its	O
encoder	B-Method
can	O
be	O
used	O
for	O
clustering	O
new	O
points	O
and	O
its	O
decoder	O
can	O
be	O
used	O
to	O
generate	O
samples	O
from	O
each	O
cluster	O
.	O
	
Figure	O
[	O
reference	O
]	O
illustrates	O
the	O
samples	O
of	O
the	O
PixelGAN	O
autoencoder	B-Method
trained	O
on	O
the	O
full	O
MNIST	B-Material
dataset	O
.	O
	
The	O
number	O
of	O
clusters	O
is	O
set	O
to	O
be	O
30	O
and	O
each	O
row	O
corresponds	O
to	O
the	O
conditional	O
samples	O
of	O
one	O
of	O
the	O
clusters	O
(	O
only	O
16	O
are	O
shown	O
)	O
.	O
	
We	O
can	O
see	O
that	O
the	O
discrete	O
latent	O
code	O
of	O
the	O
network	O
has	O
learnt	O
discrete	O
factors	O
of	O
variation	O
such	O
as	O
class	O
label	O
information	O
and	O
some	O
discrete	O
style	O
information	O
.	O
	
For	O
example	O
digit	O
s	O
are	O
put	O
in	O
different	O
clusters	O
based	O
on	O
how	O
much	O
tilted	O
they	O
are	O
.	O
	
The	O
network	O
is	O
also	O
assigning	O
different	O
clusters	O
to	O
digit	O
s	O
(	O
based	O
on	O
whether	O
they	O
have	O
a	O
loop	O
)	O
and	O
digit	O
s	O
(	O
based	O
on	O
whether	O
they	O
have	O
a	O
dash	O
in	O
the	O
middle	O
)	O
.	O
	
In	O
:	O
experiments	O
:	O
unsup	O
]	O
Section	O
[	O
reference	O
]	O
,	O
we	O
will	O
show	O
that	O
by	O
using	O
the	O
encoder	B-Method
of	O
this	O
network	O
,	O
we	O
can	O
obtain	O
about	O
5	O
%	O
error	B-Metric
rate	I-Metric
in	O
classifying	B-Task
digits	I-Task
in	O
an	O
unsupervised	O
fashion	O
,	O
just	O
by	O
matching	O
each	O
cluster	O
to	O
a	O
digit	O
type	O
.	O
	
Semi	O
-	O
Supervised	O
PixelGAN	B-Method
Autoencoders	I-Method
.	O
	
The	O
PixelGAN	O
autoencoder	B-Method
can	O
be	O
used	O
in	O
a	O
semi	B-Task
-	I-Task
supervised	I-Task
setting	I-Task
.	O
	
In	O
order	O
to	O
incorporate	O
the	O
label	O
information	O
,	O
we	O
add	O
a	O
semi	B-Method
-	I-Method
supervised	I-Method
training	I-Method
phase	I-Method
.	O
	
Specifically	O
,	O
we	O
set	O
the	O
number	O
of	O
clusters	O
to	O
be	O
the	O
same	O
as	O
the	O
number	O
of	O
class	O
labels	O
and	O
after	O
executing	O
the	O
reconstruction	O
and	O
the	O
adversarial	B-Method
phases	O
on	O
an	O
unlabeled	O
mini	O
-	O
batch	O
,	O
the	O
semi	B-Method
-	I-Method
supervised	I-Method
phase	I-Method
is	O
executed	O
on	O
a	O
labeled	O
mini	O
-	O
batch	O
,	O
by	O
updating	O
the	O
weights	O
of	O
the	O
encoder	B-Method
to	O
minimize	O
the	O
cross	B-Metric
-	I-Metric
entropy	I-Metric
cost	I-Metric
.	O
	
The	O
semi	B-Method
-	I-Method
supervised	I-Method
cost	I-Method
also	O
reduces	O
the	O
mode	O
-	O
missing	O
behavior	O
of	O
the	O
GAN	B-Method
training	O
by	O
enforcing	O
the	O
encoder	B-Method
to	O
learn	O
all	O
the	O
modes	O
of	O
the	O
categorical	O
distribution	O
.	O
	
In	O
:	O
experiments	O
:	O
semi	O
]	O
Section	O
[	O
reference	O
]	O
,	O
we	O
will	O
evaluate	O
the	O
performance	O
of	O
the	O
PixelGAN	B-Method
autoencoders	I-Method
on	O
the	O
semi	B-Task
-	I-Task
supervised	I-Task
classification	I-Task
tasks	O
.	O
	
section	O
:	O
Experiments	O
	
In	O
this	O
paper	O
,	O
we	O
presented	O
the	O
PixelGAN	O
autoencoder	B-Method
as	O
a	O
generative	B-Method
model	I-Method
,	O
but	O
the	O
currently	O
available	O
metrics	O
for	O
evaluating	O
the	O
likelihood	O
of	O
GAN	B-Method
-	O
based	O
generative	O
models	O
such	O
as	O
Parzen	B-Method
window	I-Method
estimate	I-Method
are	O
fundamentally	O
flawed	O
theis	O
.	O
	
So	O
in	O
this	O
section	O
,	O
we	O
only	O
present	O
the	O
performance	O
of	O
the	O
PixelGAN	O
autoencoder	B-Method
on	O
downstream	B-Task
tasks	I-Task
such	O
as	O
unsupervised	B-Task
clustering	I-Task
and	O
semi	B-Task
-	I-Task
supervised	I-Task
classification	I-Task
.	O
	
The	O
details	O
of	O
all	O
the	O
experiments	O
can	O
be	O
found	O
in	O
endix	O
:	O
experiment	O
]	O
Appendix	O
[	O
reference	O
]	O
.	O
	
subsection	O
:	O
Unsupervised	B-Method
Clustering	I-Method
	
We	O
trained	O
a	O
PixelGAN	O
autoencoder	B-Method
in	O
an	O
unsupervised	B-Method
fashion	I-Method
on	O
the	O
MNIST	B-Material
dataset	O
(	O
:	O
pixelgan_cluster	O
]	O
Figure	O
[	O
reference	O
]	O
)	O
.	O
	
We	O
chose	O
the	O
number	O
of	O
clusters	O
to	O
be	O
30	O
and	O
used	O
the	O
following	O
evaluation	O
protocol	O
:	O
once	O
the	O
training	O
is	O
done	O
,	O
for	O
each	O
cluster	O
,	O
we	O
found	O
the	O
validation	O
example	O
that	O
maximizes	O
,	O
and	O
assigned	O
the	O
label	O
of	O
to	O
all	O
the	O
points	O
in	O
the	O
cluster	O
.	O
	
We	O
then	O
computed	O
the	O
test	B-Metric
error	I-Metric
based	O
on	O
the	O
assigned	O
class	O
labels	O
to	O
each	O
cluster	O
.	O
	
As	O
shown	O
in	O
the	O
first	O
column	O
of	O
le	O
:	O
semi	O
]	O
Table	O
[	O
reference	O
]	O
,	O
the	O
performance	O
of	O
PixelGAN	B-Method
autoencoders	I-Method
is	O
on	O
par	O
with	O
other	O
GAN	B-Method
-	O
based	O
clustering	O
algorithms	O
such	O
as	O
CatGAN	B-Method
catgan	I-Method
,	O
InfoGAN	B-Method
infogan	I-Method
and	O
adversarial	B-Method
autoencoders	I-Method
aae	I-Method
.	O
	
subsection	O
:	O
Semi	B-Task
-	I-Task
supervised	I-Task
Classification	I-Task
	
le	O
:	O
semi	O
]	O
Table	O
[	O
reference	O
]	O
and	O
:	O
plot	O
]	O
Figure	O
[	O
reference	O
]	O
report	O
the	O
results	O
of	O
semi	B-Task
-	I-Task
supervised	I-Task
classification	I-Task
experiments	O
on	O
the	O
MNIST	B-Material
,	O
SVHN	O
and	O
NORB	O
datasets	O
.	O
	
On	O
the	O
MNIST	B-Material
dataset	O
with	O
20	O
,	O
50	O
and	O
100	O
labels	O
,	O
our	O
classification	B-Task
results	O
are	O
highly	O
competitive	O
.	O
	
Note	O
that	O
the	O
classification	B-Metric
rate	I-Metric
of	O
unsupervised	O
clustering	O
of	O
MNIST	B-Material
is	O
better	O
than	O
semi	O
-	O
supervised	O
MNIST	B-Material
with	O
20	O
labels	O
.	O
	
This	O
is	O
because	O
in	O
the	O
unsupervised	B-Task
case	I-Task
,	O
the	O
number	O
of	O
clusters	O
is	O
30	O
,	O
but	O
in	O
the	O
semi	B-Task
-	I-Task
supervised	I-Task
case	I-Task
,	O
there	O
are	O
only	O
10	O
class	O
labels	O
which	O
makes	O
it	O
more	O
likely	O
to	O
confuse	O
two	O
digits	O
.	O
	
On	O
the	O
SVHN	O
dataset	O
with	O
500	O
and	O
1000	O
labels	O
,	O
the	O
PixelGAN	O
autoencoder	B-Method
outperforms	O
all	O
the	O
other	O
methods	O
except	O
the	O
recently	O
proposed	O
temporal	B-Method
ensembling	I-Method
work	O
temporal	B-Method
-	I-Method
ensembling	I-Method
which	O
is	O
not	O
a	O
generative	B-Method
model	I-Method
.	O
	
On	O
the	O
NORB	O
dataset	O
with	O
1000	O
labels	O
,	O
the	O
PixelGAN	O
autoencoder	B-Method
outperforms	O
all	O
the	O
other	O
reported	O
results	O
.	O
	
:	O
disentangle	O
]	O
Figure	O
[	O
reference	O
]	O
shows	O
the	O
conditional	O
samples	O
of	O
the	O
semi	O
-	O
supervised	O
PixelGAN	O
autoencoder	B-Method
on	O
the	O
MNIST	B-Material
,	O
SVHN	O
and	O
NORB	O
datasets	O
.	O
	
Each	O
column	O
of	O
this	O
figure	O
presents	O
sampled	O
images	O
conditioned	O
on	O
a	O
fixed	O
one	B-Method
-	I-Method
hot	I-Method
latent	I-Method
code	I-Method
.	O
	
We	O
can	O
see	O
from	O
this	O
figure	O
that	O
the	O
PixelGAN	O
autoencoder	B-Method
can	O
achieve	O
a	O
rather	O
clean	O
separation	O
of	O
style	O
and	O
content	O
on	O
these	O
datasets	O
with	O
very	O
few	O
labeled	O
data	O
.	O
	
section	O
:	O
Learning	B-Task
Cross	I-Task
-	I-Task
Domain	I-Task
Relations	I-Task
with	O
PixelGAN	B-Method
Autoencoders	I-Method
	
In	O
this	O
section	O
,	O
we	O
discuss	O
how	O
the	O
PixelGAN	O
autoencoder	B-Method
can	O
be	O
viewed	O
in	O
the	O
context	O
of	O
learning	B-Task
cross	I-Task
-	I-Task
domain	I-Task
relations	I-Task
between	O
two	O
different	O
domains	O
.	O
	
We	O
also	O
describe	O
how	O
the	O
problem	O
of	O
clustering	B-Task
or	I-Task
semi	I-Task
-	I-Task
supervised	I-Task
learning	I-Task
can	O
be	O
cast	O
as	O
the	O
problem	O
of	O
finding	O
a	O
smooth	B-Task
cross	I-Task
-	I-Task
domain	I-Task
mapping	I-Task
from	O
the	O
data	O
distribution	O
to	O
the	O
categorical	O
distribution	O
.	O
	
Recently	O
several	O
GAN	B-Method
-	O
based	O
methods	O
have	O
been	O
developed	O
to	O
learn	O
a	O
cross	B-Task
-	I-Task
domain	I-Task
mapping	I-Task
between	O
two	O
different	O
domains	O
discogan	O
,	O
cyclegan	O
,	O
cross	B-Method
-	I-Method
domain	I-Method
-	I-Method
ilya	I-Method
,	O
aae	B-Method
,	O
cross	B-Method
-	I-Method
domain	I-Method
-	I-Method
nlp	I-Method
.	O
	
In	O
cross	B-Task
-	I-Task
domain	I-Task
-	I-Task
ilya	I-Task
,	O
an	O
unsupervised	B-Method
cost	I-Method
function	I-Method
called	O
the	O
output	B-Method
distribution	I-Method
matching	I-Method
(	O
ODM	B-Method
)	O
is	O
proposed	O
to	O
find	O
a	O
cross	B-Task
-	I-Task
domain	I-Task
mapping	I-Task
between	O
two	O
domains	O
and	O
by	O
imposing	O
the	O
following	O
unsupervised	O
constraint	O
on	O
the	O
uncorrelated	O
samples	O
from	O
and	O
:	O
where	O
denotes	O
the	O
distribution	O
of	O
the	O
random	O
variable	O
.	O
	
The	O
adversarial	B-Method
training	O
is	O
proposed	O
as	O
one	O
of	O
the	O
methods	O
for	O
matching	O
these	O
distributions	O
.	O
	
If	O
we	O
have	O
access	O
to	O
a	O
few	O
labeled	O
pairs	O
,	O
then	O
can	O
be	O
further	O
trained	O
on	O
them	O
in	O
a	O
supervised	B-Method
fashion	I-Method
to	O
satisfy	O
.	O
	
For	O
example	O
,	O
in	O
speech	B-Task
recognition	I-Task
,	O
we	O
want	O
to	O
find	O
a	O
cross	B-Task
-	I-Task
domain	I-Task
mapping	I-Task
from	O
a	O
sequence	O
of	O
phonemes	O
to	O
a	O
sequence	O
of	O
characters	O
.	O
	
By	O
optimizing	O
the	O
ODM	B-Method
cost	I-Method
function	I-Method
in	O
odm	B-Method
]	I-Method
Equation	I-Method
[	O
reference	O
]	O
,	O
we	O
can	O
find	O
a	O
smooth	B-Method
function	I-Method
that	O
takes	O
phonemes	O
at	O
its	O
input	O
and	O
outputs	O
a	O
sequence	O
of	O
characters	O
that	O
respects	O
the	O
language	B-Method
model	I-Method
.	O
	
However	O
,	O
the	O
main	O
problem	O
with	O
this	O
method	O
is	O
that	O
the	O
network	O
can	O
learn	O
to	O
ignore	O
part	O
of	O
the	O
input	O
distribution	O
and	O
still	O
satisfy	O
the	O
ODM	O
cost	O
function	O
by	O
its	O
output	O
distribution	O
.	O
	
This	O
problem	O
has	O
also	O
been	O
observed	O
in	O
other	O
works	O
such	O
as	O
discogan	B-Method
.	O
	
One	O
way	O
to	O
avoid	O
this	O
problem	O
is	O
to	O
add	O
a	O
reconstruction	O
term	O
to	O
the	O
ODM	B-Method
cost	I-Method
function	I-Method
by	O
introducing	O
a	O
reverse	O
mapping	O
from	O
the	O
output	O
of	O
the	O
encoder	B-Method
to	O
the	O
input	O
domain	O
.	O
	
The	O
is	O
essentially	O
the	O
idea	O
of	O
the	O
adversarial	B-Method
autoencoder	I-Method
aae	I-Method
which	O
learns	O
a	O
generative	B-Method
model	I-Method
by	O
finding	O
a	O
cross	B-Method
-	I-Method
domain	I-Method
mapping	I-Method
between	O
a	O
Gaussian	B-Method
distribution	I-Method
and	O
the	O
data	O
distribution	O
.	O
	
Using	O
the	O
ODM	B-Method
cost	I-Method
function	I-Method
along	O
with	O
a	O
reconstruction	B-Method
term	I-Method
to	O
learn	O
cross	O
-	O
domain	O
relations	O
have	O
been	O
explored	O
in	O
several	O
previous	O
works	O
.	O
	
For	O
example	O
,	O
InfoGAN	O
infogan	O
adds	O
a	O
mutual	O
information	O
term	O
to	O
the	O
ODM	B-Method
cost	I-Method
function	I-Method
and	O
optimizes	O
a	O
variational	B-Metric
lower	I-Metric
bound	I-Metric
on	O
this	O
term	O
.	O
	
It	O
can	O
be	O
shown	O
that	O
maximizing	O
this	O
variational	O
bound	O
is	O
indeed	O
minimizing	O
the	O
reconstruction	B-Metric
cost	I-Metric
of	O
an	O
autoencoder	B-Method
i	O
m	O
.	O
	
Similarly	O
,	O
in	O
cross	B-Task
-	I-Task
domain	I-Task
-	I-Task
nlp	I-Task
,	O
zhangadversarial	B-Task
,	O
an	O
adversarial	B-Method
autoencoder	I-Method
is	O
used	O
to	O
learn	O
the	O
cross	O
-	O
domain	O
relations	O
of	O
the	O
vector	B-Method
representations	I-Method
of	O
words	O
from	O
two	O
different	O
languages	O
.	O
	
The	O
architecture	O
of	O
the	O
recent	O
works	O
of	O
DiscoGAN	B-Method
discogan	I-Method
and	O
CycleGAN	B-Method
cyclegan	I-Method
are	O
also	O
similar	O
to	O
an	O
adversarial	B-Method
autoencoder	I-Method
in	O
which	O
the	O
latent	B-Method
representation	I-Method
is	O
enforced	O
to	O
have	O
the	O
distribution	O
of	O
the	O
other	O
domain	O
.	O
	
Here	O
we	O
describe	O
how	O
our	O
proposed	O
PixelGAN	O
autoencoder	B-Method
can	O
be	O
potentially	O
used	O
in	O
all	O
these	O
application	O
areas	O
to	O
learn	O
better	O
cross	O
-	O
domain	O
relations	O
.	O
	
Suppose	O
we	O
want	O
to	O
learn	O
a	O
mapping	O
from	O
domain	O
to	O
.	O
	
In	O
the	O
architecture	O
of	O
:	O
pixelgan_gaussian	B-Method
]	I-Method
Figure	I-Method
[	O
reference	O
]	O
,	O
we	O
can	O
use	O
independent	O
samples	O
of	O
at	O
the	O
input	O
and	O
instead	O
of	O
imposing	O
a	O
Gaussian	O
distribution	O
on	O
the	O
latent	O
code	O
,	O
we	O
can	O
impose	O
the	O
distribution	O
of	O
the	O
second	O
domain	O
using	O
its	O
independent	O
samples	O
.	O
	
Unlike	O
adversarial	B-Method
autoencoders	I-Method
,	O
the	O
encoder	B-Method
of	O
PixelGAN	B-Method
autoencoders	I-Method
does	O
not	O
have	O
to	O
retain	O
all	O
the	O
input	O
information	O
in	O
order	O
to	O
have	O
a	O
lossless	B-Task
reconstruction	I-Task
.	O
	
So	O
the	O
encoder	B-Method
can	O
use	O
all	O
its	O
capacity	O
to	O
learn	O
the	O
most	O
relevant	O
mapping	O
from	O
to	O
and	O
at	O
the	O
same	O
time	O
,	O
the	O
PixelCNN	B-Method
decoder	I-Method
can	O
capture	O
the	O
remaining	O
information	O
that	O
has	O
been	O
lost	O
by	O
the	O
encoder	B-Method
.	O
	
We	O
can	O
adopt	O
the	O
ODM	B-Method
idea	I-Method
for	O
semi	B-Task
-	I-Task
supervised	I-Task
learning	I-Task
by	O
assuming	O
is	O
the	O
image	O
domain	O
and	O
is	O
the	O
label	O
domain	O
(	O
:	O
related	O
]	O
Figure	O
[	O
reference	O
]	O
a	O
)	O
.	O
	
Independent	O
samples	O
of	O
and	O
correspond	O
to	O
samples	O
from	O
the	O
data	O
distribution	O
and	O
the	O
categorical	O
distribution	O
.	O
	
The	O
function	O
can	O
be	O
parametrized	O
by	O
a	O
neural	B-Method
network	I-Method
that	O
is	O
trained	O
to	O
satisfy	O
the	O
ODM	O
cost	O
function	O
by	O
matching	O
the	O
aggregated	O
distribution	O
to	O
the	O
categorical	O
distribution	O
using	O
adversarial	B-Method
training	O
.	O
	
The	O
few	O
labeled	O
examples	O
are	O
used	O
to	O
further	O
train	O
to	O
satisfy	O
.	O
	
However	O
,	O
as	O
explained	O
above	O
,	O
the	O
problem	O
with	O
this	O
method	O
is	O
that	O
the	O
network	O
can	O
learn	O
to	O
generate	O
the	O
categorical	O
distribution	O
by	O
ignoring	O
some	O
part	O
of	O
the	O
input	O
distribution	O
.	O
	
The	O
adversarial	B-Method
autoencoder	I-Method
(	O
:	O
related	O
]	O
Figure	O
[	O
reference	O
]	O
b	O
)	O
solves	O
this	O
problem	O
by	O
adding	O
an	O
inverse	O
mapping	O
from	O
the	O
categorical	O
distribution	O
to	O
the	O
data	O
distribution	O
.	O
	
However	O
,	O
the	O
main	O
drawback	O
of	O
the	O
adversarial	B-Method
autoencoder	I-Method
architecture	O
is	O
that	O
due	O
to	O
the	O
reconstruction	B-Method
term	I-Method
,	O
the	O
latent	B-Method
representation	I-Method
now	O
has	O
to	O
model	O
all	O
the	O
underlying	O
factors	O
of	O
variation	O
in	O
the	O
image	O
.	O
	
For	O
example	O
,	O
in	O
the	O
architecture	O
of	O
:	O
related	O
]	O
Figure	O
[	O
reference	O
]	O
	
b	O
,	O
while	O
we	O
are	O
only	O
interested	O
in	O
the	O
one	B-Method
-	I-Method
hot	I-Method
label	I-Method
representation	I-Method
to	O
do	O
semi	B-Task
-	I-Task
supervised	I-Task
learning	I-Task
,	O
we	O
also	O
need	O
to	O
infer	O
the	O
style	O
of	O
the	O
image	O
so	O
that	O
we	O
can	O
have	O
a	O
lossless	B-Task
reconstruction	I-Task
of	I-Task
the	I-Task
image	I-Task
.	O
	
The	O
PixelGAN	O
autoencoder	B-Method
solves	O
this	O
problem	O
by	O
enabling	O
the	O
encoder	B-Method
to	O
only	O
infer	O
the	O
factor	O
of	O
variation	O
that	O
we	O
are	O
interested	O
in	O
(	O
i.e.	O
,	O
label	O
information	O
)	O
,	O
while	O
the	O
remaining	O
structure	O
of	O
the	O
input	O
(	O
i.e.	O
,	O
style	O
information	O
)	O
is	O
automatically	O
captured	O
by	O
the	O
autoregressive	B-Method
decoder	I-Method
.	O
	
section	O
:	O
Conclusion	O
	
In	O
this	O
paper	O
,	O
we	O
proposed	O
the	O
PixelGAN	O
autoencoder	B-Method
,	O
which	O
is	O
a	O
generative	B-Method
autoencoder	I-Method
that	O
combines	O
a	O
generative	B-Method
PixelCNN	I-Method
with	O
a	O
GAN	B-Method
inference	O
network	O
that	O
can	O
impose	O
arbitrary	O
priors	O
on	O
the	O
latent	O
code	O
.	O
	
We	O
showed	O
that	O
imposing	O
different	O
distributions	O
as	O
the	O
prior	O
enables	O
us	O
to	O
learn	O
a	O
latent	B-Method
representation	I-Method
that	O
captures	O
the	O
type	O
of	O
statistics	O
that	O
we	O
care	O
about	O
,	O
while	O
the	O
remaining	O
structure	O
of	O
the	O
image	O
is	O
captured	O
by	O
the	O
PixelCNN	B-Method
decoder	I-Method
.	O
	
Specifically	O
,	O
by	O
imposing	O
a	O
Gaussian	O
prior	O
,	O
we	O
were	O
able	O
to	O
disentangle	O
the	O
low	O
-	O
frequency	O
and	O
high	O
-	O
frequency	O
statistics	O
of	O
the	O
images	O
,	O
and	O
by	O
imposing	O
a	O
categorical	O
prior	O
we	O
were	O
able	O
to	O
disentangle	O
the	O
style	O
and	O
content	O
of	O
images	O
and	O
learn	O
representations	O
that	O
are	O
specifically	O
useful	O
for	O
clustering	B-Task
and	I-Task
semi	I-Task
-	I-Task
supervised	I-Task
learning	I-Task
tasks	I-Task
.	O
	
While	O
the	O
main	O
focus	O
of	O
this	O
paper	O
was	O
to	O
demonstrate	O
the	O
application	O
of	O
PixelGAN	B-Method
autoencoders	I-Method
in	O
downstream	B-Task
tasks	I-Task
such	O
as	O
semi	B-Task
-	I-Task
supervised	I-Task
learning	I-Task
,	O
we	O
discussed	O
how	O
these	O
architectures	O
have	O
many	O
other	O
potentials	O
such	O
as	O
learning	B-Task
cross	I-Task
-	I-Task
domain	I-Task
relations	I-Task
between	O
two	O
different	O
domains	O
.	O
	
section	O
:	O
Acknowledgments	O
	
We	O
would	O
like	O
to	O
thank	O
Nathan	O
Killoran	O
for	O
helpful	O
discussions	O
.	O
	
We	O
also	O
thank	O
NVIDIA	O
for	O
GPU	O
donations	O
.	O
	
bibliography	O
:	O
References	O
	
section	O
:	O
Implementation	O
Details	O
	
In	O
this	O
section	O
,	O
we	O
describe	O
two	O
important	O
architecture	O
design	O
choices	O
for	O
training	O
PixelGAN	B-Method
autoencoders	I-Method
.	O
	
subsection	O
:	O
Input	O
noise	O
	
In	O
all	O
the	O
semi	B-Task
-	I-Task
supervised	I-Task
experiments	I-Task
,	O
we	O
found	O
it	O
crucial	O
to	O
use	O
the	O
universal	B-Method
approximator	I-Method
posterior	I-Method
discussed	O
in	O
:	O
pixelgan	O
]	O
Section	O
[	O
reference	O
]	O
,	O
as	O
opposed	O
to	O
a	O
deterministic	B-Method
posterior	I-Method
.	O
	
Specifically	O
,	O
the	O
input	O
noise	O
that	O
we	O
use	O
is	O
an	O
additive	O
Gaussian	O
noise	O
,	O
which	O
results	O
in	O
a	O
posterior	O
distribution	O
that	O
is	O
more	O
expressive	O
than	O
that	O
of	O
a	O
model	O
without	O
the	O
input	O
corruption	O
.	O
	
This	O
is	O
similar	O
to	O
the	O
denoising	B-Method
criterion	I-Method
idea	I-Method
proposed	O
in	O
denoising	B-Method
-	I-Method
vae	I-Method
.	O
	
We	O
believe	O
this	O
additive	O
noise	O
is	O
also	O
playing	O
an	O
important	O
role	O
in	O
preventing	O
the	O
mode	B-Task
-	I-Task
missing	I-Task
behavior	I-Task
of	O
the	O
GAN	B-Method
when	O
imposing	O
a	O
degenerate	O
distribution	O
such	O
as	O
the	O
categorical	O
distribution	O
.	O
	
Similar	O
related	O
ideas	O
have	O
been	O
used	O
to	O
stabilize	O
GAN	B-Method
training	O
such	O
as	O
instance	B-Method
noise	I-Method
instance	I-Method
or	O
one	O
-	O
sided	O
label	O
noise	O
improved	O
-	O
gan	B-Method
.	O
	
subsection	O
:	O
Conditioning	O
of	O
PixelCNN	B-Method
	
There	O
are	O
three	O
methods	O
to	O
implement	O
how	O
the	O
PixelCNN	O
conditions	O
on	O
the	O
latent	O
vector	O
.	O
	
Location	O
-	O
Invariant	O
Bias	O
.	O
	
This	O
is	O
the	O
method	O
that	O
was	O
proposed	O
in	O
the	O
conditional	B-Method
PixelCNN	I-Method
model	I-Method
pixelcnn	I-Method
.	O
	
Suppose	O
the	O
size	O
of	O
the	O
convolutional	B-Method
layer	I-Method
of	O
the	O
decoder	B-Method
is	O
(	O
batch	O
,	O
width	O
,	O
height	O
,	O
channels	O
)	O
.	O
	
Then	O
the	O
PixelCNN	B-Method
can	O
use	O
a	O
linear	B-Method
mapping	I-Method
to	O
convert	O
the	O
conditioning	O
tensor	O
of	O
size	O
(	O
batch	O
,	O
condition_size	O
)	O
to	O
generate	O
a	O
tensor	O
of	O
size	O
(	O
batch	O
,	O
channels	O
)	O
that	O
is	O
then	O
broadcasted	O
and	O
added	O
to	O
the	O
feature	O
maps	O
of	O
all	O
the	O
layers	O
of	O
the	O
PixelCNN	B-Method
decoder	I-Method
as	O
an	O
adaptive	O
bias	O
.	O
	
In	O
this	O
method	O
,	O
the	O
hidden	O
code	O
is	O
encouraged	O
to	O
learn	O
the	O
global	O
information	O
that	O
is	O
location	O
-	O
invariant	O
(	O
the	O
what	O
information	O
and	O
not	O
the	O
where	O
information	O
)	O
such	O
as	O
the	O
class	O
label	O
information	O
.	O
	
We	O
use	O
this	O
method	O
in	O
all	O
the	O
clustering	B-Task
and	I-Task
semi	I-Task
-	I-Task
supervised	I-Task
learning	I-Task
experiments	I-Task
.	O
	
Location	O
-	O
Dependent	O
Bias	O
.	O
	
Suppose	O
the	O
size	O
of	O
the	O
convolutional	B-Method
layer	I-Method
of	O
the	O
PixelCNN	B-Method
decoder	I-Method
is	O
(	O
batch	O
,	O
width	O
,	O
height	O
,	O
channels	O
)	O
.	O
	
Then	O
the	O
PixelCNN	B-Method
can	O
use	O
a	O
one	B-Method
layer	I-Method
neural	I-Method
network	I-Method
to	O
convert	O
the	O
conditioning	O
tensor	O
of	O
size	O
(	O
batch	O
,	O
condition_size	O
)	O
to	O
generate	O
a	O
spatial	O
tensor	O
of	O
size	O
(	O
batch	O
,	O
width	O
,	O
height	O
,	O
k	O
)	O
followed	O
by	O
a	O
convolutional	B-Method
layer	I-Method
to	O
construct	O
a	O
tensor	O
of	O
size	O
(	O
batch	O
,	O
width	O
,	O
height	O
,	O
channels	O
)	O
that	O
is	O
then	O
added	O
only	O
to	O
the	O
feature	O
maps	O
of	O
the	O
first	O
layer	O
of	O
the	O
decoder	O
as	O
an	O
adaptive	O
bias	O
(	O
similar	O
to	O
the	O
VPN	B-Method
model	I-Method
vpn	I-Method
)	O
.	O
	
When	O
,	O
we	O
can	O
simply	O
broadcast	O
the	O
tensor	O
of	O
size	O
(	O
batch	O
,	O
width	O
,	O
height	O
,	O
k=1	O
)	O
to	O
get	O
a	O
tensor	O
of	O
size	O
(	O
batch	O
,	O
width	O
,	O
height	O
,	O
channels	O
)	O
instead	O
of	O
using	O
the	O
convolution	B-Method
.	O
	
In	O
this	O
method	O
,	O
the	O
latent	O
vector	O
has	O
spatial	O
and	O
location	O
-	O
dependent	O
information	O
within	O
the	O
feature	O
map	O
.	O
	
This	O
is	O
the	O
method	O
that	O
we	O
used	O
in	O
experiments	O
of	O
:	O
mnist	O
]	O
Figure	O
[	O
reference	O
]	O
a.	O
Input	O
Channel	O
.	O
	
Another	O
method	O
for	O
conditioning	B-Task
is	O
proposed	O
in	O
the	O
PixelVAE	B-Task
pixelvae	I-Task
and	O
the	O
variational	B-Method
lossy	I-Method
autoencoder	I-Method
(	O
VLAE	B-Method
)	O
vlae	O
.	O
	
In	O
this	O
method	O
,	O
first	O
a	O
tensor	O
of	O
size	O
(	O
batch	O
,	O
width	O
,	O
height	O
,	O
k	O
)	O
is	O
constructed	O
using	O
the	O
conditioning	B-Method
tensor	I-Method
similar	O
to	O
the	O
location	O
-	O
dependent	O
bias	O
.	O
	
This	O
tensor	O
is	O
then	O
concatenated	O
to	O
the	O
input	O
of	O
the	O
PixelCNN	B-Method
.	O
	
The	O
performance	O
and	O
computational	B-Metric
complexity	I-Metric
of	O
this	O
method	O
is	O
very	O
similar	O
to	O
that	O
of	O
the	O
location	B-Method
-	I-Method
dependent	I-Method
bias	I-Method
method	I-Method
.	O
	
section	O
:	O
Experiment	O
Details	O
	
We	O
used	O
TensorFlow	B-Method
tensorflow2015	O
-	O
whitepaper	O
in	O
all	O
of	O
our	O
experiments	O
.	O
	
As	O
suggested	O
in	O
gan	B-Method
,	O
in	O
order	O
to	O
improve	O
the	O
stability	O
of	O
GAN	B-Method
training	O
,	O
the	O
generator	B-Method
of	O
the	O
GAN	B-Method
in	O
all	O
our	O
experiments	O
is	O
trained	O
to	O
maximize	O
rather	O
than	O
minimizing	O
.	O
	
subsection	O
:	O
MNIST	B-Material
Dataset	O
	
The	O
MNIST	B-Material
dataset	O
has	O
50	O
K	O
training	O
points	O
,	O
10	O
K	O
validation	O
points	O
and	O
10	O
K	O
test	O
points	O
.	O
	
We	O
perform	O
experiments	O
on	O
both	O
the	O
binary	B-Material
MNIST	I-Material
and	O
the	O
real	B-Material
-	I-Material
valued	I-Material
MNIST	I-Material
.	O
	
In	O
the	O
real	O
valued	O
MNIST	B-Material
experiments	O
,	O
we	O
subtract	O
127.5	O
from	O
the	O
data	O
points	O
and	O
then	O
divide	O
them	O
by	O
127.5	O
and	O
use	O
the	O
discretized	O
logistic	B-Method
mixture	I-Method
likelihood	I-Method
pixelcnn	I-Method
++	I-Method
as	O
the	O
cost	B-Method
function	I-Method
for	O
the	O
PixelCNN	B-Method
.	O
	
In	O
the	O
case	O
of	O
binary	B-Material
MNIST	I-Material
,	O
the	O
data	O
points	O
are	O
binarized	O
by	O
setting	O
pixel	O
values	O
larger	O
than	O
0.5	O
to	O
1	O
,	O
and	O
values	O
smaller	O
than	O
0.5	O
to	O
0	O
.	O
	
subsubsection	O
:	O
PixelGAN	B-Method
Autoencoders	I-Method
with	O
Gaussian	B-Method
Prior	I-Method
on	O
MNIST	B-Material
	
Here	O
we	O
describe	O
the	O
model	O
architecture	O
used	O
for	O
training	O
the	O
PixelGAN	O
autoencoder	B-Method
with	O
a	O
Gaussian	B-Method
prior	I-Method
on	O
the	O
binary	O
MNIST	B-Material
dataset	O
in	O
:	O
mnist	O
]	O
Figure	O
[	O
reference	O
]	O
	
a.	O
	
The	O
PixelCNN	B-Method
decoder	I-Method
uses	O
both	O
the	O
vertical	O
and	O
horizontal	O
stacks	O
similar	O
to	O
pixelcnn	B-Method
.	O
	
The	O
cost	B-Metric
function	I-Metric
of	O
the	O
PixelCNN	B-Method
is	O
the	O
cross	B-Metric
-	I-Metric
entropy	I-Metric
cost	I-Metric
function	I-Metric
.	O
	
The	O
PixelCNN	B-Method
uses	O
the	O
location	O
-	O
dependent	O
bias	O
as	O
described	O
in	O
endix	O
:	O
conditioning_of_pixelcnn	O
]	O
Appendix	O
[	O
reference	O
]	O
.	O
	
Specifically	O
,	O
a	O
tensor	O
of	O
size	O
(	O
batch	O
,	O
width	O
,	O
height	O
,	O
1	O
)	O
is	O
constructed	O
from	O
the	O
conditioning	O
vector	O
by	O
using	O
a	O
one	B-Method
-	I-Method
layer	I-Method
neural	I-Method
network	I-Method
with	O
1000	O
hidden	O
units	O
,	O
ReLU	O
activation	O
and	O
linear	O
output	O
.	O
	
This	O
tensor	O
is	O
then	O
broadcasted	O
and	O
added	O
only	O
to	O
the	O
feature	O
maps	O
of	O
the	O
first	B-Method
layer	I-Method
of	O
the	O
PixelCNN	B-Method
decoder	I-Method
.	O
	
The	O
PixelCNN	B-Method
is	O
designed	O
to	O
have	O
a	O
local	O
receptive	O
field	O
by	O
having	O
3	O
residual	O
blocks	O
(	O
filter	O
size	O
of	O
3x5	O
,	O
32	O
feature	O
maps	O
,	O
ReLU	O
non	O
-	O
linearity	O
as	O
in	O
pixelcnn	B-Method
)	O
.	O
	
The	O
adversarial	B-Method
discriminator	O
has	O
two	O
layers	O
of	O
2000	O
hidden	O
units	O
with	O
ReLU	B-Method
activation	I-Method
function	I-Method
.	O
	
The	O
encoder	B-Method
architecture	O
has	O
two	O
fully	B-Method
-	I-Method
connected	I-Method
layers	I-Method
of	O
size	O
2000	O
with	O
ReLU	B-Method
non	I-Method
-	I-Method
linearity	I-Method
.	O
	
The	O
last	O
layer	O
of	O
the	O
encoder	B-Method
has	O
a	O
linear	B-Method
activation	I-Method
function	I-Method
.	O
	
On	O
the	O
latent	B-Task
representation	I-Task
of	I-Task
size	I-Task
,	O
we	O
impose	O
a	O
Gaussian	B-Method
distribution	I-Method
with	O
standard	O
deviation	O
of	O
.	O
	
We	O
used	O
the	O
gradient	B-Method
descent	I-Method
with	O
momentum	B-Method
algorithm	I-Method
for	O
optimizing	O
all	O
the	O
cost	O
functions	O
of	O
the	O
network	O
.	O
	
For	O
the	O
PixelCNN	B-Task
reconstruction	I-Task
cost	I-Task
,	O
we	O
used	O
the	O
learning	B-Metric
rate	I-Metric
of	I-Metric
0.001	I-Metric
and	O
the	O
momentum	O
value	O
of	O
0.9	O
.	O
	
After	O
25	O
epochs	O
we	O
reduce	O
the	O
learning	B-Metric
rate	I-Metric
to	O
0.0001	O
.	O
	
For	O
both	O
of	O
the	O
generator	B-Method
and	O
the	O
discriminator	O
costs	O
,	O
the	O
learning	B-Metric
rates	I-Metric
and	O
the	O
momentum	O
values	O
were	O
set	O
to	O
0.1	O
.	O
	
subsubsection	O
:	O
Unsupervised	B-Task
Clustering	I-Task
of	I-Task
MNIST	I-Task
	
Here	O
we	O
describe	O
the	O
model	O
architecture	O
used	O
for	O
clustering	B-Task
the	O
binary	O
MNIST	B-Material
dataset	O
in	O
:	O
pixelgan_cluster	O
]	O
Figure	O
[	O
reference	O
]	O
and	O
:	O
experiments	O
:	O
unsup	O
]	O
Section	O
[	O
reference	O
]	O
.	O
	
The	O
PixelCNN	B-Method
decoder	I-Method
uses	O
both	O
the	O
vertical	O
and	O
horizontal	O
stacks	O
similar	O
to	O
pixelcnn	B-Method
.	O
	
The	O
cost	B-Metric
function	I-Metric
of	O
the	O
PixelCNN	B-Method
is	O
the	O
cross	B-Metric
-	I-Metric
entropy	I-Metric
cost	I-Metric
function	I-Metric
.	O
	
The	O
PixelCNN	B-Method
uses	O
the	O
location	O
-	O
invariant	O
bias	O
as	O
described	O
in	O
endix	O
:	O
conditioning_of_pixelcnn	O
]	O
Appendix	O
[	O
reference	O
]	O
and	O
has	O
15	O
residual	O
blocks	O
(	O
filter	O
size	O
of	O
3x5	O
,	O
32	O
feature	O
maps	O
,	O
ReLU	O
non	O
-	O
linearity	O
as	O
in	O
pixelcnn	B-Method
)	O
.	O
	
The	O
adversarial	B-Method
discriminator	O
has	O
two	O
layers	O
of	O
3000	O
hidden	O
units	O
with	O
ReLU	B-Method
activation	I-Method
function	I-Method
.	O
	
The	O
encoder	B-Method
architecture	O
has	O
a	O
convolutional	B-Method
layer	I-Method
(	O
filter	O
size	O
of	O
7	O
,	O
32	O
feature	O
maps	O
,	O
ReLU	B-Method
activation	I-Method
)	O
and	O
a	O
max	B-Method
-	I-Method
pooling	I-Method
layer	I-Method
(	O
pooling	O
size	O
2	O
)	O
,	O
followed	O
by	O
another	O
convolutional	B-Method
layer	I-Method
(	O
filter	O
size	O
of	O
7	O
,	O
32	O
feature	O
maps	O
,	O
ReLU	B-Method
activation	I-Method
)	O
and	O
a	O
max	B-Method
-	I-Method
pooling	I-Method
layer	I-Method
(	O
pooling	O
size	O
2	O
)	O
with	O
no	O
fully	B-Method
-	I-Method
connected	I-Method
layer	I-Method
.	O
	
The	O
last	O
layer	O
of	O
the	O
encoder	B-Method
has	O
the	O
softmax	O
activation	O
function	O
.	O
	
We	O
found	O
it	O
important	O
to	O
use	O
batch	O
-	O
normalization	O
batch	O
for	O
all	O
the	O
layers	O
of	O
the	O
encoder	B-Method
including	O
the	O
softmax	B-Method
layer	I-Method
.	O
	
The	O
number	O
of	O
clusters	O
is	O
chosen	O
to	O
be	O
.	O
	
The	O
clusters	O
are	O
represented	O
by	O
a	O
discrete	O
one	O
-	O
hot	O
variable	O
of	O
size	O
30	O
.	O
	
On	O
the	O
continuous	O
probability	O
output	O
of	O
the	O
softmax	B-Method
,	O
we	O
impose	O
a	O
categorical	O
distribution	O
with	O
uniform	O
probabilities	O
.	O
	
We	O
use	O
Adam	B-Method
Adam	I-Method
optimizer	I-Method
with	O
learning	B-Metric
rate	I-Metric
of	O
for	O
optimizing	O
the	O
PixelCNN	B-Task
reconstruction	I-Task
cost	I-Task
function	I-Task
,	O
but	O
we	O
found	O
it	O
important	O
to	O
use	O
the	O
gradient	B-Method
descent	I-Method
with	O
momentum	B-Method
algorithm	I-Method
for	O
optimizing	O
the	O
generator	O
and	O
the	O
discriminator	O
costs	O
of	O
the	O
adversarial	B-Method
network	O
.	O
	
For	O
both	O
of	O
the	O
generator	B-Method
and	O
the	O
discriminator	O
costs	O
,	O
the	O
momentum	O
values	O
were	O
set	O
to	O
0.1	O
and	O
the	O
learning	B-Metric
rates	I-Metric
were	O
set	O
to	O
0.01	O
.	O
	
We	O
use	O
an	O
input	O
dropout	O
noise	O
with	O
the	O
keep	O
probability	O
of	O
at	O
the	O
input	O
layer	O
and	O
only	O
at	O
the	O
training	O
time	O
.	O
	
The	O
model	O
architecture	O
used	O
for	O
:	O
pixelgan_cluster_toy	O
]	O
Figure	O
[	O
reference	O
]	O
is	O
the	O
same	O
as	O
this	O
architecture	O
except	O
that	O
the	O
number	O
of	O
clusters	O
is	O
chosen	O
to	O
be	O
.	O
	
subsubsection	O
:	O
Semi	B-Task
-	I-Task
Supervised	I-Task
MNIST	I-Task
	
We	O
performed	O
semi	B-Task
-	I-Task
supervised	I-Task
learning	I-Task
experiments	O
on	O
both	O
binary	O
and	O
real	B-Material
-	I-Material
valued	I-Material
MNIST	I-Material
dataset	I-Material
.	O
	
We	O
found	O
that	O
the	O
semi	B-Metric
-	I-Metric
supervised	I-Metric
error	I-Metric
-	I-Metric
rate	I-Metric
of	O
the	O
real	B-Material
-	I-Material
valued	I-Material
MNIST	I-Material
is	O
roughly	O
the	O
same	O
as	O
the	O
binary	B-Material
MNIST	I-Material
(	O
about	O
1.10	O
%	O
with	O
100	O
labels	O
)	O
,	O
but	O
it	O
takes	O
longer	O
to	O
train	O
due	O
to	O
the	O
logistic	B-Method
mixture	I-Method
likelihood	I-Method
cost	I-Method
function	I-Method
pixelcnn	I-Method
++	I-Method
.	O
	
So	O
in	O
le	O
:	O
semi	O
]	O
Table	O
[	O
reference	O
]	O
,	O
we	O
only	O
report	O
the	O
performance	O
with	O
the	O
binary	B-Material
MNIST	I-Material
,	O
but	O
in	O
:	O
disentangle	O
]	O
Figure	O
[	O
reference	O
]	O
b	O
we	O
are	O
showing	O
the	O
samples	O
of	O
the	O
real	B-Material
-	I-Material
valued	I-Material
MNIST	I-Material
with	O
100	O
labels	O
.	O
	
Binary	B-Material
MNIST	I-Material
.	O
	
Here	O
we	O
describe	O
the	O
model	O
architecture	O
used	O
for	O
the	O
semi	B-Task
-	I-Task
supervised	I-Task
learning	I-Task
experiments	I-Task
on	O
the	O
binary	B-Material
MNIST	I-Material
in	O
:	O
experiments	O
:	O
semi	O
]	O
Section	O
[	O
reference	O
]	O
and	O
le	O
:	O
semi	O
]	O
Table	O
[	O
reference	O
]	O
.	O
	
The	O
PixelCNN	B-Method
decoder	I-Method
uses	O
both	O
the	O
vertical	O
and	O
horizontal	O
stacks	O
similar	O
to	O
pixelcnn	B-Method
and	O
uses	O
the	O
cross	B-Method
-	I-Method
entropy	I-Method
cost	I-Method
function	I-Method
.	O
	
The	O
PixelCNN	B-Method
uses	O
the	O
location	O
-	O
invariant	O
bias	O
as	O
described	O
in	O
endix	O
:	O
conditioning_of_pixelcnn	O
]	O
Appendix	O
[	O
reference	O
]	O
.	O
	
The	O
PixelCNN	B-Method
has	O
6	O
residual	O
blocks	O
(	O
filter	O
size	O
of	O
3x5	O
,	O
32	O
feature	O
maps	O
,	O
ReLU	O
non	O
-	O
linearity	O
as	O
in	O
pixelcnn	B-Method
)	O
.	O
	
The	O
adversarial	B-Method
discriminator	O
has	O
two	O
layers	O
of	O
1000	O
hidden	O
units	O
with	O
ReLU	B-Method
activation	I-Method
function	I-Method
.	O
	
The	O
encoder	B-Method
architecture	O
has	O
three	O
convolutional	B-Method
layers	I-Method
(	O
filter	O
size	O
of	O
5	O
,	O
32	O
feature	O
maps	O
,	O
ReLU	B-Method
activation	I-Method
)	O
and	O
a	O
max	B-Method
-	I-Method
pooling	I-Method
layer	I-Method
(	O
pooling	O
size	O
2	O
)	O
,	O
followed	O
by	O
another	O
three	O
convolutional	B-Method
layers	I-Method
(	O
filter	O
size	O
of	O
5	O
,	O
32	O
feature	O
maps	O
,	O
ReLU	B-Method
activation	I-Method
)	O
and	O
a	O
max	B-Method
-	I-Method
pooling	I-Method
layer	I-Method
(	O
pooling	O
size	O
2	O
)	O
with	O
no	O
fully	B-Method
-	I-Method
connected	I-Method
layer	I-Method
.	O
	
The	O
last	O
layer	O
of	O
the	O
encoder	B-Method
has	O
the	O
softmax	O
activation	O
function	O
.	O
	
All	O
the	O
convolutional	B-Method
layers	I-Method
of	O
the	O
encoder	B-Method
except	O
the	O
softmax	B-Method
layer	I-Method
use	O
batch	B-Method
-	I-Method
normalization	I-Method
batch	I-Method
.	O
	
On	O
the	O
latent	B-Method
representation	I-Method
,	O
we	O
impose	O
a	O
categorical	O
distribution	O
with	O
uniform	O
probabilities	O
.	O
	
The	O
semi	B-Metric
-	I-Metric
supervised	I-Metric
cost	I-Metric
is	O
the	O
cross	B-Metric
-	I-Metric
entropy	I-Metric
cost	I-Metric
function	I-Metric
at	O
the	O
output	O
of	O
.	O
	
We	O
use	O
Adam	B-Method
Adam	I-Method
optimizer	I-Method
with	O
learning	B-Metric
rate	I-Metric
of	O
for	O
optimizing	O
the	O
PixelCNN	B-Metric
cost	I-Metric
and	O
the	O
cross	B-Metric
-	I-Metric
entropy	I-Metric
cost	I-Metric
,	O
but	O
we	O
found	O
it	O
important	O
to	O
use	O
the	O
gradient	B-Method
descent	I-Method
with	O
momentum	B-Method
algorithm	I-Method
for	O
optimizing	O
the	O
generator	B-Method
and	O
the	O
discriminator	O
costs	O
of	O
the	O
adversarial	B-Method
network	O
.	O
	
For	O
both	O
of	O
the	O
generator	B-Method
and	O
the	O
discriminator	O
costs	O
,	O
the	O
momentum	O
values	O
were	O
set	O
to	O
0.1	O
and	O
the	O
learning	B-Metric
rates	I-Metric
were	O
set	O
to	O
0.1	O
.	O
	
We	O
add	O
a	O
Gaussian	O
noise	O
with	O
standard	O
deviation	O
of	O
to	O
the	O
input	O
layer	O
as	O
described	O
in	O
endix	O
:	O
input_noise	O
]	O
Appendix	O
[	O
reference	O
]	O
.	O
	
The	O
labeled	O
examples	O
were	O
chosen	O
at	O
random	O
but	O
evenly	O
distributed	O
across	O
the	O
classes	O
.	O
	
Real	B-Material
-	I-Material
valued	I-Material
MNIST	I-Material
.	O
	
Here	O
we	O
describe	O
the	O
model	O
architecture	O
used	O
for	O
the	O
semi	B-Task
-	I-Task
supervised	I-Task
learning	I-Task
experiments	O
on	O
the	O
real	B-Material
-	I-Material
valued	I-Material
MNIST	I-Material
in	O
:	O
disentangle	O
]	O
Figure	O
[	O
reference	O
]	O
	
b.	O
	
The	O
PixelCNN	B-Method
decoder	I-Method
uses	O
both	O
the	O
vertical	O
and	O
horizontal	O
stacks	O
similar	O
to	O
pixelcnn	B-Method
and	O
uses	O
a	O
discretized	B-Method
logistic	I-Method
mixture	I-Method
likelihood	I-Method
cost	I-Method
function	I-Method
with	O
10	O
logistic	O
distribution	O
as	O
proposed	O
in	O
pixelcnn	B-Method
++	I-Method
.	O
	
The	O
PixelCNN	B-Method
uses	O
the	O
location	O
-	O
invariant	O
bias	O
as	O
described	O
in	O
endix	O
:	O
conditioning_of_pixelcnn	O
]	O
Appendix	O
[	O
reference	O
]	O
.	O
	
The	O
PixelCNN	B-Method
has	O
20	O
residual	O
blocks	O
(	O
filter	O
size	O
of	O
2x3	O
,	O
64	O
feature	O
maps	O
,	O
gated	B-Method
sigmoid	I-Method
-	I-Method
tanh	I-Method
non	I-Method
-	I-Method
linearity	I-Method
as	O
in	O
pixelcnn	B-Method
)	O
.	O
	
The	O
adversarial	B-Method
discriminator	O
has	O
two	O
layers	O
of	O
1000	O
hidden	O
units	O
with	O
ReLU	B-Method
activation	I-Method
function	I-Method
.	O
	
The	O
encoder	B-Method
architecture	O
has	O
three	O
convolutional	B-Method
layers	I-Method
(	O
filter	O
size	O
of	O
5	O
,	O
32	O
feature	O
maps	O
,	O
ReLU	B-Method
activation	I-Method
)	O
and	O
a	O
max	B-Method
-	I-Method
pooling	I-Method
layer	I-Method
(	O
pooling	O
size	O
2	O
)	O
,	O
followed	O
by	O
another	O
three	O
convolutional	B-Method
layers	I-Method
(	O
filter	O
size	O
of	O
5	O
,	O
32	O
feature	O
maps	O
,	O
ReLU	B-Method
activation	I-Method
)	O
and	O
a	O
max	B-Method
-	I-Method
pooling	I-Method
layer	I-Method
(	O
pooling	O
size	O
2	O
)	O
with	O
no	O
fully	B-Method
-	I-Method
connected	I-Method
layer	I-Method
.	O
	
The	O
last	O
layer	O
of	O
the	O
encoder	B-Method
has	O
the	O
softmax	O
activation	O
function	O
.	O
	
All	O
the	O
convolutional	B-Method
layers	I-Method
of	O
the	O
encoder	B-Method
except	O
the	O
softmax	B-Method
layer	I-Method
use	O
batch	B-Method
-	I-Method
normalization	I-Method
batch	I-Method
.	O
	
On	O
the	O
latent	B-Method
representation	I-Method
,	O
we	O
impose	O
a	O
categorical	O
distribution	O
with	O
uniform	O
probabilities	O
.	O
	
The	O
semi	B-Metric
-	I-Metric
supervised	I-Metric
cost	I-Metric
is	O
the	O
cross	B-Metric
-	I-Metric
entropy	I-Metric
cost	I-Metric
function	I-Metric
at	O
the	O
output	O
of	O
.	O
	
We	O
use	O
Adam	B-Method
Adam	I-Method
optimizer	I-Method
with	O
learning	B-Metric
rate	I-Metric
of	O
for	O
optimizing	O
the	O
PixelCNN	B-Metric
cost	I-Metric
and	O
the	O
cross	B-Metric
-	I-Metric
entropy	I-Metric
cost	I-Metric
,	O
but	O
we	O
found	O
it	O
important	O
to	O
use	O
the	O
gradient	B-Method
descent	I-Method
with	O
momentum	B-Method
algorithm	I-Method
for	O
optimizing	O
the	O
generator	B-Method
and	O
the	O
discriminator	O
costs	O
of	O
the	O
adversarial	B-Method
network	O
.	O
	
For	O
both	O
of	O
the	O
generator	B-Method
and	O
the	O
discriminator	O
costs	O
,	O
the	O
momentum	O
values	O
were	O
set	O
to	O
0.1	O
and	O
the	O
learning	B-Metric
rates	I-Metric
were	O
set	O
to	O
0.1	O
.	O
	
After	O
150	O
epochs	O
,	O
we	O
divide	O
all	O
the	O
learning	B-Metric
rates	I-Metric
by	O
10	O
.	O
	
We	O
add	O
a	O
Gaussian	O
noise	O
with	O
standard	O
deviation	O
of	O
to	O
the	O
input	O
layer	O
as	O
described	O
in	O
endix	O
:	O
input_noise	O
]	O
Appendix	O
[	O
reference	O
]	O
.	O
	
The	O
labeled	O
examples	O
were	O
chosen	O
at	O
random	O
but	O
evenly	O
distributed	O
across	O
the	O
classes	O
.	O
	
subsection	O
:	O
SVHN	O
Dataset	O
	
The	O
SVHN	O
dataset	O
has	O
about	O
530	O
K	O
training	O
points	O
and	O
26	O
K	O
test	O
points	O
.	O
	
We	O
use	O
10	O
K	O
points	O
for	O
the	O
validation	O
set	O
.	O
	
Similar	O
to	O
vat	B-Method
,	O
we	O
downsample	O
the	O
images	O
from	O
to	O
and	O
then	O
subtracte	O
127.5	O
from	O
the	O
data	O
points	O
and	O
then	O
divide	O
them	O
by	O
127.5	O
.	O
	
subsubsection	O
:	O
Semi	B-Task
-	I-Task
Supervised	I-Task
SVHN	I-Task
	
Here	O
we	O
describe	O
the	O
model	B-Method
architecture	I-Method
used	O
for	O
the	O
semi	B-Task
-	I-Task
supervised	I-Task
learning	I-Task
experiments	I-Task
on	O
the	O
SVHN	O
dataset	O
in	O
:	O
experiments	O
:	O
semi	O
]	O
Section	O
[	O
reference	O
]	O
.	O
	
The	O
PixelCNN	B-Method
decoder	I-Method
uses	O
both	O
the	O
vertical	O
and	O
horizontal	O
stacks	O
similar	O
to	O
pixelcnn	B-Method
.	O
	
The	O
cost	B-Metric
function	I-Metric
of	O
the	O
PixelCNN	B-Method
is	O
a	O
discretized	B-Method
logistic	I-Method
mixture	I-Method
likelihood	I-Method
cost	I-Method
function	I-Method
with	O
10	O
logistic	B-Method
distribution	I-Method
as	O
proposed	O
in	O
pixelcnn	B-Method
++	I-Method
.	O
	
The	O
PixelCNN	B-Method
uses	O
the	O
location	O
-	O
invariant	O
bias	O
as	O
described	O
in	O
endix	O
:	O
conditioning_of_pixelcnn	O
]	O
Appendix	O
[	O
reference	O
]	O
and	O
has	O
20	O
residual	O
blocks	O
(	O
filter	O
size	O
of	O
3x5	O
,	O
32	O
feature	O
maps	O
,	O
gated	B-Method
sigmoid	I-Method
-	I-Method
tanh	I-Method
non	I-Method
-	I-Method
linearity	I-Method
as	O
in	O
pixelcnn	B-Method
)	O
.	O
	
The	O
adversarial	B-Method
discriminator	O
has	O
two	O
layers	O
of	O
1000	O
hidden	O
units	O
with	O
ReLU	B-Method
activation	I-Method
function	I-Method
.	O
	
The	O
encoder	B-Method
architecture	O
has	O
two	O
convolutional	B-Method
layers	I-Method
(	O
filter	O
size	O
of	O
5	O
,	O
32	O
feature	O
maps	O
,	O
ReLU	B-Method
activation	I-Method
)	O
and	O
a	O
max	B-Method
-	I-Method
pooling	I-Method
layer	I-Method
(	O
pooling	O
size	O
2	O
)	O
,	O
followed	O
by	O
another	O
two	O
convolutional	B-Method
layers	I-Method
(	O
filter	O
size	O
of	O
5	O
,	O
32	O
feature	O
maps	O
,	O
ReLU	B-Method
activation	I-Method
)	O
and	O
a	O
max	B-Method
-	I-Method
pooling	I-Method
layer	I-Method
(	O
pooling	O
size	O
2	O
)	O
with	O
no	O
fully	B-Method
-	I-Method
connected	I-Method
layer	I-Method
.	O
	
The	O
last	O
layer	O
of	O
the	O
encoder	B-Method
has	O
the	O
softmax	O
activation	O
function	O
.	O
	
All	O
the	O
convolutional	B-Method
layers	I-Method
of	O
the	O
encoder	B-Method
except	O
the	O
softmax	B-Method
layer	I-Method
use	O
batch	B-Method
-	I-Method
normalization	I-Method
batch	I-Method
.	O
	
On	O
the	O
latent	B-Method
representation	I-Method
,	O
we	O
impose	O
a	O
categorical	O
distribution	O
with	O
uniform	O
probabilities	O
.	O
	
The	O
semi	B-Metric
-	I-Metric
supervised	I-Metric
cost	I-Metric
is	O
the	O
cross	B-Metric
-	I-Metric
entropy	I-Metric
cost	I-Metric
function	I-Metric
at	O
the	O
output	O
of	O
.	O
	
We	O
use	O
Adam	B-Method
Adam	I-Method
optimizer	I-Method
for	O
optimizing	O
all	O
the	O
cost	B-Metric
function	I-Metric
.	O
	
For	O
the	O
PixelCNN	B-Metric
cost	I-Metric
and	O
the	O
cross	B-Metric
-	I-Metric
entropy	I-Metric
cost	I-Metric
we	O
use	O
the	O
learning	B-Metric
rate	I-Metric
of	O
and	O
for	O
the	O
generator	B-Method
and	O
the	O
discriminator	B-Metric
costs	I-Metric
of	O
the	O
adversarial	B-Method
network	O
we	O
use	O
the	O
learning	B-Metric
rate	I-Metric
of	O
.	O
	
We	O
add	O
a	O
Gaussian	O
noise	O
with	O
standard	O
deviation	O
of	O
to	O
the	O
input	O
layer	O
as	O
described	O
in	O
endix	O
:	O
input_noise	O
]	O
Appendix	O
[	O
reference	O
]	O
.	O
	
subsection	O
:	O
NORB	O
Dataset	O
	
The	O
NORB	O
dataset	O
has	O
about	O
24	O
K	O
training	O
points	O
and	O
24	O
K	O
test	O
points	O
.	O
	
We	O
use	O
4	O
K	O
points	O
for	O
the	O
validation	O
set	O
.	O
	
This	O
dataset	O
has	O
5	O
object	O
categories	O
:	O
animals	O
,	O
human	O
figures	O
,	O
airplanes	O
,	O
trucks	O
and	O
cars	O
.	O
	
We	O
downsample	O
the	O
images	O
to	O
have	O
the	O
size	O
of	O
,	O
subtract	O
127.5	O
from	O
the	O
data	O
points	O
and	O
then	O
divide	O
them	O
by	O
127.5	O
.	O
	
subsubsection	O
:	O
Semi	B-Method
-	I-Method
Supervised	I-Method
NORB	I-Method
	
The	O
PixelCNN	B-Method
decoder	I-Method
uses	O
both	O
the	O
vertical	O
and	O
horizontal	O
stacks	O
similar	O
to	O
pixelcnn	B-Method
.	O
	
The	O
cost	B-Metric
function	I-Metric
of	O
the	O
PixelCNN	B-Method
is	O
a	O
discretized	B-Method
logistic	I-Method
mixture	I-Method
likelihood	I-Method
cost	I-Method
function	I-Method
with	O
10	O
logistic	B-Method
distribution	I-Method
as	O
proposed	O
in	O
pixelcnn	B-Method
++	I-Method
.	O
	
The	O
PixelCNN	B-Method
uses	O
the	O
location	O
-	O
invariant	O
bias	O
as	O
described	O
in	O
endix	O
:	O
conditioning_of_pixelcnn	O
]	O
Appendix	O
[	O
reference	O
]	O
and	O
has	O
15	O
residual	O
blocks	O
(	O
filter	O
size	O
of	O
3x5	O
,	O
32	O
feature	O
maps	O
,	O
gated	B-Method
sigmoid	I-Method
-	I-Method
tanh	I-Method
non	I-Method
-	I-Method
linearity	I-Method
as	O
in	O
pixelcnn	B-Method
)	O
.	O
	
The	O
adversarial	B-Method
discriminator	O
has	O
two	O
layers	O
of	O
1000	O
hidden	O
units	O
with	O
ReLU	B-Method
activation	I-Method
function	I-Method
.	O
	
The	O
encoder	B-Method
architecture	O
has	O
a	O
convolutional	B-Method
layer	I-Method
(	O
filter	O
size	O
of	O
7	O
,	O
32	O
feature	O
maps	O
,	O
ReLU	B-Method
activation	I-Method
)	O
and	O
a	O
max	B-Method
-	I-Method
pooling	I-Method
layer	I-Method
(	O
pooling	O
size	O
2	O
)	O
,	O
followed	O
by	O
another	O
convolutional	B-Method
layer	I-Method
(	O
filter	O
size	O
of	O
7	O
,	O
32	O
feature	O
maps	O
,	O
ReLU	B-Method
activation	I-Method
)	O
and	O
a	O
max	B-Method
-	I-Method
pooling	I-Method
layer	I-Method
(	O
pooling	O
size	O
2	O
)	O
,	O
followed	O
by	O
another	O
convolutional	B-Method
layer	I-Method
(	O
filter	O
size	O
of	O
7	O
,	O
32	O
feature	O
maps	O
,	O
ReLU	O
activation	O
)	O
and	O
a	O
max	B-Method
-	I-Method
pooling	I-Method
layer	I-Method
(	O
pooling	O
size	O
2	O
)	O
with	O
no	O
fully	B-Method
-	I-Method
connected	I-Method
layer	I-Method
.	O
	
The	O
last	O
layer	O
of	O
the	O
encoder	B-Method
has	O
the	O
softmax	O
activation	O
function	O
.	O
	
All	O
the	O
convolutional	B-Method
layers	I-Method
of	O
the	O
encoder	B-Method
except	O
the	O
softmax	B-Method
layer	I-Method
use	O
batch	B-Method
-	I-Method
normalization	I-Method
batch	I-Method
.	O
	
On	O
the	O
latent	B-Method
representation	I-Method
,	O
we	O
impose	O
a	O
categorical	O
distribution	O
with	O
uniform	O
probabilities	O
.	O
	
The	O
semi	B-Metric
-	I-Metric
supervised	I-Metric
cost	I-Metric
is	O
the	O
cross	B-Metric
-	I-Metric
entropy	I-Metric
cost	I-Metric
function	I-Metric
at	O
the	O
output	O
of	O
.	O
	
We	O
use	O
Adam	B-Method
Adam	I-Method
optimizer	I-Method
for	O
optimizing	O
all	O
the	O
cost	B-Metric
function	I-Metric
.	O
	
For	O
the	O
PixelCNN	B-Metric
cost	I-Metric
and	O
the	O
cross	B-Metric
-	I-Metric
entropy	I-Metric
cost	I-Metric
we	O
use	O
the	O
learning	B-Metric
rate	I-Metric
of	O
and	O
for	O
the	O
generator	B-Method
and	O
the	O
discriminator	B-Metric
costs	I-Metric
of	O
the	O
adversarial	B-Method
network	O
we	O
use	O
the	O
learning	B-Metric
rate	I-Metric
of	O
.	O
	
We	O
add	O
a	O
Gaussian	O
noise	O
with	O
standard	O
deviation	O
of	O
to	O
the	O
input	O
layer	O
as	O
described	O
in	O
endix	O
:	O
input_noise	O
]	O
Appendix	O
[	O
reference	O
]	O
.	O
	
The	O
labeled	O
examples	O
were	O
chosen	O
at	O
random	O
but	O
evenly	O
distributed	O
across	O
the	O
classes	O
.	O
	
In	O
the	O
case	O
of	O
NORB	O
with	O
1000	O
labels	O
,	O
the	O
test	B-Metric
error	I-Metric
after	O
10	O
epochs	O
is	O
12.97	O
%	O
,	O
after	O
100	O
epochs	O
is	O
11.63	O
%	O
and	O
after	O
500	O
epochs	O
is	O
8.17	O
%	O
.	O
	
document	O
:	O
Submanifold	B-Method
Sparse	I-Method
Convolutional	I-Method
Networks	I-Method
	
Convolutional	B-Method
network	I-Method
are	O
the	O
de	O
-	O
facto	O
standard	O
for	O
analysing	O
spatio	O
-	O
temporal	O
data	O
such	O
as	O
images	O
,	O
videos	O
,	O
3D	O
shapes	O
,	O
etc	O
.	O
	
Whilst	O
some	O
of	O
this	O
data	O
is	O
naturally	O
dense	O
(	O
for	O
instance	O
,	O
photos	O
)	O
,	O
many	O
other	O
data	O
sources	O
are	O
inherently	O
sparse	O
.	O
	
Examples	O
include	O
pen	O
-	O
strokes	O
forming	O
on	O
a	O
piece	O
of	O
paper	O
,	O
or	O
(	O
colored	O
)	O
3D	O
point	O
clouds	O
that	O
were	O
obtained	O
using	O
a	O
LiDAR	B-Method
scanner	I-Method
or	O
RGB	B-Method
-	I-Method
D	I-Method
camera	I-Method
.	O
	
Standard	O
	
‘	O
	
‘	O
dense	B-Method
’	I-Method
’	I-Method
implementations	I-Method
of	O
convolutional	B-Method
networks	I-Method
are	O
very	O
inefficient	O
when	O
applied	O
on	O
such	O
sparse	O
data	O
.	O
	
We	O
introduce	O
a	O
sparse	B-Method
convolutional	I-Method
operation	I-Method
tailored	O
to	O
processing	O
sparse	O
data	O
that	O
differs	O
from	O
prior	O
work	O
on	O
sparse	B-Method
convolutional	I-Method
networks	I-Method
in	O
that	O
it	O
operates	O
strictly	O
on	O
submanifolds	O
,	O
rather	O
than	O
‘	O
	
‘	O
dilating	O
’	O
’	O
the	O
observation	O
with	O
every	O
layer	O
in	O
the	O
network	O
.	O
	
Our	O
empirical	O
analysis	O
of	O
the	O
resulting	O
submanifold	B-Method
sparse	I-Method
convolutional	I-Method
networks	I-Method
shows	O
that	O
they	O
perform	O
on	O
par	O
with	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
methods	O
whilst	O
requiring	O
substantially	O
less	O
computation	O
.	O
	
section	O
:	O
Introduction	O
	
Convolutional	B-Method
networks	I-Method
constitute	O
the	O
state	O
-	O
of	O
-	O
the	O
art	O
method	O
for	O
a	O
wide	O
range	O
of	O
tasks	O
that	O
involve	O
the	O
analysis	B-Task
of	I-Task
data	I-Task
with	I-Task
spatial	I-Task
and	I-Task
/	I-Task
or	I-Task
temporal	I-Task
structure	I-Task
,	O
such	O
as	O
photographs	O
,	O
videos	O
,	O
or	O
three	B-Method
-	I-Method
dimensional	I-Method
surface	I-Method
models	I-Method
.	O
	
While	O
such	O
data	O
frequently	O
comprises	O
a	O
densely	O
filled	O
(	O
2D	O
or	O
3D	O
)	O
grid	O
,	O
other	O
spatio	O
-	O
temporal	O
datasets	O
are	O
naturally	O
sparse	O
.	O
	
For	O
instance	O
,	O
handwriting	O
is	O
made	O
up	O
of	O
one	O
-	O
dimensional	O
lines	O
in	O
two	O
-	O
dimensional	O
space	O
,	O
pictures	O
made	O
by	O
RGB	B-Method
-	I-Method
D	I-Method
cameras	I-Method
are	O
three	O
-	O
dimensional	O
point	O
clouds	O
,	O
and	O
OFF	B-Method
models	I-Method
form	O
two	O
-	O
dimensional	O
surfaces	O
in	O
3D	O
space	O
.	O
	
The	O
curse	O
of	O
dimensionality	O
applies	O
,	O
in	O
particular	O
,	O
on	O
data	O
that	O
lives	O
on	O
grids	O
that	O
have	O
three	O
or	O
more	O
dimensions	O
:	O
the	O
number	O
of	O
points	O
on	O
the	O
grid	O
grows	O
exponentially	O
with	O
its	O
dimensionality	O
.	O
	
In	O
such	O
scenarios	O
,	O
it	O
becomes	O
increasingly	O
important	O
to	O
exploit	O
data	O
sparsity	O
whenever	O
possible	O
in	O
order	O
to	O
reduce	O
the	O
computational	B-Metric
resources	O
needed	O
for	O
data	B-Task
processing	I-Task
.	O
	
Indeed	O
,	O
exploiting	O
sparsity	O
is	O
paramount	O
when	O
analyzing	O
,	O
for	O
instance	O
,	O
RGB	O
-	O
D	O
videos	O
which	O
are	O
sparsely	O
populated	O
4D	O
structures	O
.	O
	
Traditional	O
convolutional	B-Method
network	I-Method
implementations	I-Method
are	O
optimized	O
for	O
data	O
that	O
lives	O
on	O
densely	O
populated	O
grids	O
,	O
and	O
can	O
not	O
process	O
sparse	O
data	O
efficiently	O
.	O
	
More	O
recently	O
,	O
a	O
number	O
of	O
convolutional	B-Method
network	I-Method
implementations	I-Method
have	O
been	O
presented	O
that	O
are	O
tailored	O
to	O
work	O
efficiently	O
on	O
sparse	O
data	O
.	O
	
Mathematically	O
,	O
some	O
of	O
these	O
implementations	O
are	O
identical	O
to	O
a	O
regular	B-Method
convolutional	I-Method
network	I-Method
,	O
but	O
they	O
require	O
fewer	O
computational	B-Metric
resources	O
in	O
terms	O
of	O
FLOPs	O
and	O
/	O
or	O
in	O
terms	O
of	O
memory	O
.	O
	
OctNets	B-Method
slightly	O
modify	O
the	O
convolution	B-Method
operator	I-Method
to	O
produce	O
‘	O
‘	O
averaged	O
’	O
’	O
hidden	O
states	O
in	O
parts	O
of	O
the	O
grid	O
that	O
are	O
away	O
from	O
regions	O
of	O
interest	O
.	O
	
One	O
of	O
the	O
downsides	O
of	O
prior	O
sparse	B-Method
implementations	I-Method
of	I-Method
convolutional	I-Method
networks	I-Method
is	O
that	O
they	O
	
‘	O
	
‘	O
dilate	O
’	O
’	O
the	O
sparse	O
data	O
in	O
every	O
layer	O
,	O
because	O
they	O
implement	O
a	O
‘	O
‘	O
full	B-Method
’	I-Method
’	I-Method
convolution	I-Method
.	O
	
In	O
this	O
work	O
,	O
we	O
show	O
that	O
it	O
is	O
possible	O
to	O
successfully	O
train	O
convolutional	B-Method
networks	I-Method
that	O
keep	O
the	O
same	O
sparsity	O
pattern	O
throughout	O
the	O
layers	O
of	O
the	O
network	O
,	O
without	O
dilating	O
the	O
feature	O
maps	O
.	O
	
To	O
this	O
end	O
,	O
we	O
explore	O
two	O
novel	O
convolution	B-Method
operators	I-Method
:	O
sparse	B-Method
convolution	I-Method
(	O
SC	B-Method
)	O
and	O
valid	B-Method
sparse	I-Method
convolution	I-Method
(	O
VSC	B-Method
)	O
.	O
	
In	O
our	O
experiments	O
with	O
recognizing	B-Task
handwritten	I-Task
digits	I-Task
and	I-Task
3D	I-Task
shapes	I-Task
,	O
networks	O
using	O
SC	B-Method
and	O
VSC	B-Method
achieve	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
performance	O
whilst	O
reducing	O
the	O
computation	O
and	O
memory	B-Metric
requirements	I-Metric
by	O
.	O
	
section	O
:	O
Motivation	O
	
We	O
define	O
a	O
-	B-Method
dimensional	I-Method
convolutional	I-Method
network	I-Method
as	O
a	O
network	O
that	O
takes	O
as	O
input	O
that	O
is	O
a	O
-	O
dimensional	O
tensor	O
:	O
the	O
input	O
tensor	O
contains	O
spatiotemporal	O
dimensions	O
(	O
such	O
as	O
length	O
,	O
width	O
,	O
height	O
,	O
time	O
,	O
etc	O
.	O
)	O
and	O
one	O
additional	O
feature	O
space	O
dimension	O
(	O
for	O
instance	O
,	O
RGB	O
color	O
channels	O
,	O
surface	O
normal	O
vectors	O
,	O
etc	O
.	O
)	O
.	O
	
A	O
sparse	O
input	O
corresponds	O
to	O
a	O
-	O
dimensional	O
grid	O
of	O
sites	O
that	O
is	O
associated	O
with	O
a	O
feature	O
vector	O
.	O
	
We	O
define	O
a	O
site	O
in	O
the	O
input	O
to	O
be	O
active	O
if	O
any	O
element	O
in	O
the	O
feature	O
vector	O
is	O
not	O
in	O
its	O
ground	O
state	O
,	O
for	O
instance	O
,	O
if	O
it	O
is	O
non	O
-	O
zero	O
.	O
	
In	O
many	O
practical	O
problems	O
,	O
thresholding	B-Task
may	O
be	O
used	O
to	O
eliminate	O
sites	O
at	O
which	O
the	O
feature	O
vector	O
is	O
within	O
a	O
very	O
small	O
distance	O
from	O
the	O
ground	O
state	O
.	O
	
Note	O
that	O
even	O
though	O
the	O
input	O
tensor	O
is	O
-	O
dimensional	O
,	O
activity	O
is	O
a	O
-	O
dimensional	O
phenomenon	O
:	O
	
entire	O
planes	O
along	O
the	O
feature	O
dimension	O
are	O
either	O
active	O
or	O
not	O
.	O
	
The	O
hidden	O
layers	O
of	O
a	O
convolutional	B-Method
network	I-Method
are	O
also	O
represented	O
by	O
-	O
dimensional	O
grids	O
of	O
feature	O
-	O
space	O
vectors	O
.	O
	
When	O
propagating	O
the	O
input	O
data	O
through	O
the	O
network	O
,	O
a	O
site	O
in	O
a	O
hidden	B-Method
layer	I-Method
is	O
active	O
if	O
any	O
of	O
the	O
sites	O
in	O
the	O
layer	O
that	O
it	O
takes	O
as	O
input	O
is	O
active	O
.	O
	
(	O
Note	O
that	O
when	O
using	O
convolutions	B-Method
,	O
each	O
site	O
is	O
connected	O
to	O
sites	O
in	O
the	O
hidden	O
layer	O
below	O
.	O
)	O
	
Activity	O
in	O
a	O
hidden	O
layer	O
thus	O
follows	O
an	O
inductive	B-Method
definition	I-Method
in	O
which	O
each	O
layer	O
determines	O
the	O
set	O
of	O
active	O
states	O
in	O
the	O
next	O
.	O
	
In	O
each	O
hidden	O
layer	O
,	O
inactive	O
sites	O
all	O
have	O
the	O
same	O
feature	O
vector	O
:	O
the	O
one	O
corresponding	O
to	O
the	O
ground	O
state	O
.	O
	
Note	O
that	O
the	O
ground	O
state	O
in	O
a	O
hidden	O
layer	O
is	O
often	O
not	O
equal	O
to	O
zero	O
,	O
in	O
particular	O
,	O
when	O
convolutions	B-Method
with	O
a	O
bias	O
term	O
are	O
used	O
.	O
	
However	O
,	O
irrespective	O
of	O
the	O
value	O
of	O
the	O
ground	O
state	O
,	O
the	O
ground	O
-	O
state	O
value	O
only	O
needs	O
to	O
be	O
calculated	O
once	O
per	O
forward	O
pass	O
during	O
training	O
(	O
and	O
	
only	O
once	O
for	O
all	O
forward	O
passes	O
at	O
test	O
time	O
)	O
.	O
	
This	O
allows	O
for	O
substantial	O
savings	O
in	O
computational	B-Metric
and	O
memory	B-Metric
requirements	I-Metric
;	O
the	O
exact	O
savings	O
depend	O
on	O
the	O
data	O
sparsity	O
and	O
the	O
network	O
depth	O
.	O
	
In	O
this	O
paper	O
,	O
we	O
argue	O
that	O
the	O
framework	O
described	O
above	O
is	O
unduly	O
restrictive	O
,	O
in	O
particular	O
,	O
because	O
the	O
convolution	B-Method
operation	I-Method
has	O
not	O
been	O
modified	O
to	O
accommodate	O
the	O
sparsity	O
of	O
the	O
input	O
data	O
.	O
	
If	O
the	O
input	O
data	O
contains	O
a	O
single	O
active	O
site	O
,	O
then	O
after	O
applying	O
a	O
convolution	B-Method
,	O
there	O
will	O
be	O
active	O
sites	O
.	O
	
Applying	O
a	O
second	O
convolution	O
of	O
the	O
same	O
size	O
will	O
yield	O
active	O
sites	O
,	O
and	O
so	O
on	O
.	O
	
This	O
rapid	O
growth	O
of	O
the	O
number	O
of	O
active	O
sites	O
is	O
a	O
poor	O
prospect	O
when	O
implementing	O
modern	O
convolutional	B-Method
network	I-Method
architectures	I-Method
that	O
comprise	O
tens	O
or	O
even	O
hundreds	O
of	O
convolutions	O
,	O
such	O
as	O
VGG	B-Method
networks	O
,	O
ResNets	B-Method
,	O
and	O
DenseNets	B-Method
.	O
	
Of	O
course	O
,	O
convolutional	B-Method
networks	I-Method
are	O
not	O
often	O
applied	O
to	O
inputs	O
that	O
only	O
have	O
a	O
single	O
active	O
site	O
,	O
but	O
the	O
aforementioned	O
‘	O
‘	O
dilation	O
’	O
’	O
problems	O
are	O
equally	O
problematic	O
when	O
the	O
input	O
data	O
comprises	O
one	O
-	O
dimensional	O
curves	O
in	O
spaces	O
with	O
two	O
or	O
more	O
dimensions	O
,	O
or	O
two	O
-	O
dimensional	O
surfaces	O
in	O
three	O
or	O
more	O
dimensions	O
.	O
	
To	O
address	O
the	O
problems	O
with	O
dilation	B-Task
of	I-Task
active	I-Task
sites	I-Task
,	O
we	O
propose	O
two	O
slightly	O
different	O
convolution	B-Method
operations	I-Method
for	O
use	O
in	O
convolutional	B-Method
networks	I-Method
.	O
	
What	O
the	O
two	O
operations	O
have	O
in	O
common	O
is	O
that	O
they	O
both	O
ignore	O
the	O
ground	O
state	O
:	O
they	O
replace	O
the	O
ground	O
state	O
with	O
a	O
zero	O
vector	O
to	O
simplify	O
the	O
convolution	O
operations	O
.	O
	
The	O
difference	O
between	O
both	O
operations	O
is	O
in	O
how	O
they	O
handle	O
active	O
sites	O
:	O
instead	O
of	O
automatically	O
making	O
a	O
site	O
active	O
if	O
any	O
of	O
the	O
inputs	O
to	O
its	O
receptive	O
field	O
is	O
active	O
(	O
thereby	O
dilating	O
the	O
set	O
of	O
active	O
sites	O
)	O
,	O
our	O
most	O
efficient	O
convolutional	B-Method
operation	I-Method
only	O
considers	O
the	O
central	O
input	O
.	O
	
As	O
a	O
result	O
,	O
the	O
output	O
set	O
of	O
active	O
sites	O
exactly	O
mirrors	O
that	O
of	O
the	O
input	O
set	O
.	O
	
We	O
empirically	O
demonstrate	O
that	O
use	O
of	O
our	O
adapted	O
convolutional	B-Method
operators	I-Method
allows	O
us	O
to	O
build	O
much	O
deeper	B-Method
networks	I-Method
that	O
achieve	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
results	O
whilst	O
requiring	O
much	O
fewer	O
resources	O
by	O
preserving	O
sparsity	O
.	O
	
subsection	O
:	O
Submanifold	B-Method
Dilation	I-Method
	
In	O
Figure	O
[	O
reference	O
]	O
,	O
we	O
show	O
an	O
example	O
of	O
a	O
one	O
-	O
dimensional	O
curve	O
that	O
is	O
embedded	O
on	O
a	O
two	O
-	O
dimensional	O
grid	O
.	O
	
The	O
figure	O
shows	O
that	O
even	O
when	O
we	O
apply	O
small	O
convolutions	B-Method
on	O
this	O
grid	O
,	O
the	O
sparsity	O
on	O
the	O
grid	O
rapidly	O
disappears	O
.	O
	
At	O
the	O
same	O
time	O
,	O
if	O
we	O
restrict	O
the	O
output	O
of	O
the	O
convolution	B-Method
only	O
to	O
the	O
set	O
of	O
active	O
input	O
points	O
,	O
hidden	O
layers	O
in	O
the	O
network	O
can	O
not	O
capture	O
a	O
lot	O
of	O
information	O
that	O
may	O
relevant	O
to	O
the	O
classification	B-Task
of	I-Task
the	I-Task
curve	I-Task
.	O
	
In	O
particular	O
,	O
two	O
neighboring	O
connected	O
components	O
will	O
be	O
treated	O
completely	O
independently	O
.	O
	
Luckily	O
,	O
nearly	O
all	O
convolutional	B-Method
networks	I-Method
incorporate	O
some	O
form	O
of	O
pooling	B-Method
,	O
or	O
use	O
strided	B-Method
convolutions	I-Method
.	O
	
These	O
operations	O
are	O
essential	O
in	O
the	O
sparse	B-Method
convolutional	I-Method
networks	I-Method
we	O
investigate	O
,	O
as	O
they	O
allow	O
neighboring	O
components	O
to	O
merge	O
.	O
	
In	O
particular	O
,	O
the	O
closer	O
the	O
components	O
are	O
,	O
the	O
smaller	O
the	O
number	O
of	O
poolings	O
/	O
strided	B-Method
convolutions	I-Method
is	O
that	O
is	O
necessary	O
for	O
the	O
components	O
to	O
merge	O
in	O
the	O
hidden	B-Method
-	I-Method
layer	I-Method
representations	I-Method
.	O
	
subsection	O
:	O
Very	O
Deep	B-Method
Convolutional	I-Method
Networks	I-Method
	
In	O
image	B-Task
classification	I-Task
,	O
very	O
deep	B-Method
convolutional	I-Method
networks	I-Method
with	O
small	B-Method
filters	I-Method
,	O
often	O
of	O
size	O
pixels	O
and	O
a	O
padding	O
of	O
pixel	O
(	O
to	O
preserve	O
the	O
size	O
of	O
the	O
feature	O
maps	O
)	O
,	O
have	O
proven	O
to	O
be	O
very	O
effective	O
.	O
	
Such	O
small	O
filters	O
were	O
used	O
successfully	O
in	O
VGG	B-Method
networks	O
,	O
which	O
have	O
relatively	O
wide	O
layers	O
.	O
	
The	O
introduction	O
of	O
residual	B-Method
networks	I-Method
(	O
ResNets	B-Method
)	O
showed	O
that	O
deeper	O
but	O
narrow	B-Method
networks	I-Method
with	O
small	B-Method
filters	I-Method
are	O
more	O
efficient	O
.	O
	
The	O
success	O
of	O
very	O
deep	B-Task
ResNets	I-Task
,	O
ResNeXt	B-Method
models	I-Method
,	O
and	O
DenseNets	B-Method
with	I-Method
bottleneck	I-Method
connections	I-Method
shows	O
that	O
it	O
can	O
be	O
useful	O
to	O
calculate	O
a	O
relatively	O
small	O
number	O
of	O
features	O
at	O
a	O
time	O
and	O
amalgamate	O
these	O
features	O
into	O
a	O
larger	O
state	O
variable	O
,	O
either	O
by	O
vector	B-Method
-	I-Method
addition	I-Method
or	O
feature	B-Method
-	I-Method
vector	I-Method
concatenation	I-Method
.	O
	
Unfortunately	O
,	O
these	O
techniques	O
are	O
impractical	O
using	O
existing	O
sparse	B-Method
convolutional	I-Method
network	I-Method
implementations	I-Method
.	O
	
One	O
problem	O
is	O
that	O
networks	O
with	O
multiple	O
paths	O
will	O
tend	O
to	O
generate	O
different	O
sets	O
of	O
active	O
paths	O
,	O
which	O
would	O
have	O
to	O
be	O
merged	O
to	O
reconnect	O
the	O
outputs	O
.	O
	
It	O
seems	O
that	O
this	O
would	O
be	O
difficult	O
to	O
perform	O
this	O
merging	O
efficiently	O
.	O
	
More	O
importantly	O
,	O
ResNets	B-Method
and	O
DenseNets	B-Method
generate	O
such	O
large	O
receptive	O
fields	O
that	O
sparsity	O
would	O
almost	O
immediately	O
be	O
destroyed	O
by	O
the	O
explosion	O
in	O
the	O
number	O
of	O
active	O
sites	O
.	O
	
section	O
:	O
(	O
Valid	O
)	O
Sparse	B-Method
Convolutions	I-Method
:	O
SC	B-Method
and	O
VSC	B-Method
	
We	O
define	O
a	O
sparse	B-Method
convolution	I-Method
SC	I-Method
(	O
with	O
input	O
feature	O
planes	O
,	O
output	O
feature	O
planes	O
,	O
a	O
filter	O
size	O
of	O
,	O
and	O
stride	O
.	O
	
We	O
assume	O
and	O
to	O
be	O
odd	O
integers	O
,	O
but	O
we	O
can	O
allow	O
generalization	O
to	O
non	O
-	O
square	O
filters	O
,	O
e.g.	O
,	O
or	O
,	O
if	O
we	O
want	O
to	O
implement	O
Inception	B-Method
-	I-Method
style	I-Method
factorised	I-Method
convolutions	I-Method
.	O
	
An	O
SC	B-Method
convolution	O
computes	O
the	O
set	O
of	O
active	O
sites	O
in	O
the	O
same	O
way	O
as	O
a	O
regular	B-Method
convolution	I-Method
:	O
it	O
looks	O
for	O
the	O
presence	O
of	O
any	O
active	O
sites	O
in	O
its	O
receptive	O
field	O
of	O
size	O
.	O
	
If	O
the	O
input	O
has	O
size	O
then	O
the	O
output	O
will	O
have	O
size	O
.	O
	
An	O
SC	B-Method
convolution	O
differs	O
from	O
a	O
regular	B-Method
convolution	I-Method
in	O
that	O
it	O
discards	O
the	O
ground	O
state	O
for	O
non	O
-	O
active	O
sites	O
by	O
assuming	O
that	O
the	O
input	O
from	O
those	O
sites	O
is	O
exactly	O
zero	O
.	O
	
Whereas	O
this	O
is	O
a	O
seemingly	O
small	O
change	O
to	O
the	O
convolution	B-Method
operation	I-Method
,	O
it	O
may	O
bring	O
computational	B-Metric
benefits	O
in	O
practice	O
.	O
	
Next	O
,	O
we	O
define	O
a	O
second	O
type	O
of	O
sparse	B-Method
convolution	I-Method
,	O
which	O
forms	O
the	O
main	O
contribution	O
of	O
this	O
paper	O
.	O
	
Again	O
,	O
let	O
denote	O
an	O
odd	O
number	O
,	O
or	O
collection	O
of	O
odd	O
numbers	O
,	O
e.g.	O
,	O
or	O
.	O
	
We	O
define	O
a	O
valid	O
sparse	B-Method
convolution	I-Method
VSC	I-Method
as	O
a	O
modified	O
SC	B-Method
convolution	O
.	O
	
First	O
,	O
we	O
pad	O
the	O
input	O
with	O
on	O
each	O
side	O
,	O
so	O
that	O
the	O
output	O
will	O
have	O
the	O
same	O
size	O
as	O
the	O
input	O
.	O
	
Next	O
,	O
we	O
restrict	O
an	O
output	O
site	O
to	O
be	O
active	O
if	O
and	O
only	O
if	O
the	O
site	O
at	O
the	O
corresponding	O
site	O
in	O
the	O
input	O
is	O
active	O
(	O
i.e.	O
,	O
if	O
the	O
central	O
site	O
in	O
the	O
receptive	O
field	O
is	O
active	O
)	O
.	O
	
Whenever	O
an	O
output	O
site	O
is	O
determined	O
to	O
be	O
active	O
,	O
its	O
output	O
feature	O
vector	O
is	O
calculated	O
by	O
the	O
SC	B-Method
operation	O
.	O
	
Table	O
[	O
reference	O
]	O
presents	O
the	O
computational	B-Metric
and	O
memory	B-Metric
requirements	I-Metric
of	O
a	O
regular	B-Method
convolution	I-Method
(	O
C	O
)	O
and	O
of	O
our	O
SC	B-Method
and	O
VSC	B-Method
convolutions	I-Method
.	O
	
To	O
construct	O
convolutional	B-Method
networks	I-Method
using	O
SC	B-Method
and	O
VSC	B-Method
,	O
we	O
also	O
need	O
activation	O
functions	O
,	O
batch	B-Method
normalization	I-Method
,	O
and	O
pooling	B-Method
.	O
	
Activation	O
functions	O
are	O
defined	O
as	O
usual	O
,	O
but	O
are	O
restricted	O
to	O
the	O
set	O
of	O
active	O
sites	O
.	O
	
Similarly	O
,	O
we	O
define	O
batch	B-Method
normalization	I-Method
in	O
terms	O
of	O
regular	B-Method
batch	I-Method
-	I-Method
normalization	I-Method
applied	O
over	O
the	O
set	O
of	O
active	O
sites	O
.	O
	
Max	B-Method
-	I-Method
pooling	I-Method
MP	I-Method
and	O
average	B-Method
-	I-Method
pooling	I-Method
AP	I-Method
operations	I-Method
are	O
defined	O
as	O
a	O
variant	O
of	O
SC	B-Method
.	O
	
MP	B-Method
takes	O
the	O
maximum	O
of	O
the	O
zero	O
vector	O
and	O
the	O
input	O
feature	O
vectors	O
in	O
the	O
receptive	O
field	O
.	O
	
AP	B-Method
calculates	O
times	O
the	O
sum	O
of	O
the	O
active	O
input	O
vectors	O
.	O
	
We	O
also	O
define	O
a	O
deconvolution	B-Method
operation	I-Method
DC	I-Method
as	O
an	O
inverse	O
of	O
the	O
SC	B-Method
convolution	O
.	O
	
The	O
set	O
of	O
active	O
output	O
sites	O
from	O
a	O
DC	B-Method
convolution	I-Method
is	O
exactly	O
the	O
set	O
of	O
input	O
active	O
sites	O
to	O
the	O
matching	O
SC	B-Method
convolution	O
.	O
	
The	O
set	O
of	O
connections	O
between	O
input	O
-	O
output	O
sites	O
is	O
simply	O
inverted	O
.	O
	
subsection	O
:	O
Submanifold	B-Method
Convolutional	I-Method
Networks	I-Method
	
We	O
use	O
a	O
combination	O
of	O
VSC	B-Method
convolutions	I-Method
,	O
strided	B-Method
SC	I-Method
convolutions	I-Method
,	O
and	O
sparse	B-Method
pooling	I-Method
operations	I-Method
to	O
build	O
sparse	B-Method
versions	I-Method
of	O
the	O
popular	O
VGG	B-Method
,	O
ResNet	B-Method
,	O
and	O
DenseNet	B-Method
convolutional	I-Method
networks	I-Method
.	O
	
The	O
blocks	O
we	O
use	O
in	O
our	O
networks	O
are	O
presented	O
in	O
Figure	O
[	O
reference	O
]	O
.	O
	
We	O
refer	O
to	O
our	O
networks	O
as	O
submanifold	B-Method
convolutional	I-Method
networks	I-Method
,	O
because	O
they	O
are	O
optimised	O
to	O
process	O
low	O
-	O
dimensional	O
data	O
living	O
in	O
a	O
space	O
of	O
higher	O
dimensionality	O
.	O
	
We	O
use	O
the	O
name	O
VGG	B-Method
to	O
refer	O
to	O
networks	O
that	O
contain	O
a	O
number	O
of	O
VSC	B-Method
(	O
,	O
,	O
3	O
,	O
1	O
)	O
convolutions	O
,	O
separated	O
by	O
max	B-Method
-	I-Method
pooling	I-Method
.	O
	
Each	O
convolution	B-Method
is	O
followed	O
by	O
batch	B-Method
normalization	I-Method
and	O
a	O
ReLU	B-Method
non	I-Method
-	I-Method
linearity	I-Method
.	O
	
Similarly	O
,	O
we	O
define	O
‘	O
‘	O
pre	O
-	O
activated	O
ResNets	O
’	O
’	O
in	O
which	O
most	O
data	B-Task
processing	I-Task
is	O
performed	O
by	O
pairs	O
of	O
VSC	B-Method
(	O
,	O
,	O
3	O
,	O
1	O
)	O
convolutions	O
,	O
and	O
in	O
which	O
the	O
residual	O
connections	O
are	O
identity	O
functions	O
.	O
	
Whenever	O
the	O
number	O
of	O
input	O
/	O
output	O
features	O
is	O
different	O
,	O
we	O
use	O
a	O
VSC	B-Method
(	O
,	O
,	O
1	O
,	O
1	O
)	O
instead	O
.	O
	
Whenever	O
there	O
is	O
change	O
of	O
scale	O
,	O
we	O
replace	O
the	O
first	B-Method
convolution	I-Method
and	O
the	O
residual	O
connection	O
by	O
a	O
SC	B-Method
(	O
,	O
,	O
3	O
,	O
2	O
)	O
convolution	O
.	O
	
This	O
ensures	O
that	O
two	O
branches	O
can	O
use	O
the	O
same	O
hash	O
table	O
of	O
active	O
sites	O
,	O
and	O
reduces	O
additions	O
to	O
a	O
simple	O
sum	O
of	O
two	O
equally	O
sized	O
matrices	O
.	O
	
The	O
increased	O
size	O
of	O
the	O
residual	O
connection	O
’s	O
receptive	O
field	O
also	O
prevents	O
excessive	O
information	O
loss	O
.	O
	
We	O
also	O
experiment	O
with	O
submanifold	O
DenseNets	O
.	O
	
Herein	O
,	O
the	O
word	O
dense	O
does	O
not	O
refer	O
to	O
a	O
lack	O
of	O
spatial	O
sparsity	O
but	O
rather	O
to	O
the	O
pattern	O
of	O
connections	O
between	O
convolution	O
operations	O
.	O
	
A	O
simple	O
DenseNet	B-Method
module	I-Method
is	O
a	O
sequence	O
of	O
convolutions	B-Method
in	O
which	O
each	O
convolution	B-Method
takes	O
as	O
input	O
the	O
concatenated	O
output	O
of	O
all	O
the	O
previous	O
convolution	B-Method
operations	I-Method
.	O
	
The	O
bottleneck	O
layers	O
in	O
our	O
submanifold	B-Method
DenseNets	I-Method
are	O
implemented	O
in	O
the	O
same	O
way	O
as	O
for	O
ResNets	B-Method
.	O
	
section	O
:	O
Implementation	O
	
To	O
implement	O
(	O
V	O
)	O
SC	B-Method
convolutions	O
efficiently	O
,	O
we	O
store	O
the	O
state	O
of	O
a	O
input	O
/	O
hidden	O
layer	O
in	O
two	O
parts	O
:	O
a	O
hash	O
table	O
and	O
a	O
matrix	O
.	O
	
The	O
matrix	O
has	O
size	O
and	O
contains	O
one	O
row	O
for	O
each	O
of	O
the	O
active	O
sites	O
.	O
	
The	O
hash	O
table	O
contains	O
(	O
location	O
,	O
row	O
)	O
pairs	O
for	O
all	O
active	O
sites	O
:	O
the	O
location	O
is	O
a	O
tuple	O
of	O
integer	O
coordinates	O
,	O
and	O
the	O
row	O
number	O
indicates	O
the	O
corresponding	O
row	O
in	O
the	O
feature	O
matrix	O
.	O
	
Given	O
a	O
convolution	B-Method
with	I-Method
filter	I-Method
size	I-Method
,	O
we	O
define	O
a	O
rule	O
book	O
to	O
be	O
a	O
collection	O
of	O
integer	O
matrices	O
of	O
size	O
.	O
	
To	O
implement	O
an	O
SC	B-Method
(	O
convolution	O
,	O
we	O
:	O
Iterate	O
once	O
through	O
the	O
the	O
input	O
hash	O
-	O
table	O
.	O
	
We	O
build	O
the	O
output	O
hash	O
table	O
and	O
rule	O
book	O
on	O
-	O
the	O
-	O
fly	O
by	O
iterating	O
over	O
points	O
in	O
the	O
output	O
layer	O
that	O
receive	O
input	O
from	O
a	O
given	O
point	O
in	O
the	O
input	O
layer	O
.	O
	
When	O
an	O
output	O
site	O
is	O
visited	O
for	O
the	O
first	O
time	O
,	O
a	O
new	O
entry	O
is	O
created	O
in	O
the	O
output	O
hash	O
table	O
.	O
	
Based	O
on	O
the	O
spatial	O
offset	O
between	O
the	O
input	O
and	O
output	O
points	O
,	O
a	O
(	O
input	O
index	O
,	O
output	O
index	O
)	O
pair	O
is	O
added	O
to	O
the	O
rule	O
book	O
.	O
	
Initialize	O
the	O
output	O
matrix	O
to	O
all	O
zeros	O
.	O
	
For	O
each	O
,	O
there	O
is	O
a	O
parameter	O
matrix	O
with	O
size	O
.	O
	
For	O
each	O
,	O
multiply	O
the	O
-	O
th	O
row	O
of	O
the	O
input	O
feature	O
matrix	O
by	O
and	O
add	O
it	O
to	O
the	O
-	O
th	O
row	O
of	O
the	O
the	O
output	O
feature	O
matrix	O
.	O
	
This	O
can	O
be	O
implemented	O
very	O
efficiently	O
on	O
GPUs	B-Method
because	O
it	O
is	O
a	O
matrix	B-Method
-	I-Method
matrix	I-Method
multiply	I-Method
-	I-Method
add	I-Method
operation	I-Method
.	O
	
To	O
implement	O
a	O
VSC	B-Method
convolution	O
,	O
we	O
re	O
-	O
use	O
the	O
input	O
hash	O
table	O
for	O
the	O
output	O
,	O
and	O
construct	O
an	O
appropriate	O
rule	O
book	O
.	O
	
Note	O
that	O
because	O
the	O
sparsity	O
pattern	O
does	O
not	O
change	O
,	O
the	O
same	O
rule	O
book	O
can	O
be	O
re	O
-	O
used	O
in	O
VGG	B-Method
/	O
ResNet	B-Method
/	O
DenseNet	B-Method
networks	I-Method
until	O
a	O
pooling	B-Method
or	I-Method
subsampling	I-Method
layer	I-Method
is	O
encountered	O
.	O
	
If	O
there	O
are	O
active	O
points	O
in	O
the	O
input	O
layer	O
,	O
the	O
cost	O
of	O
building	O
the	O
input	O
hash	O
-	O
table	O
is	O
.	O
	
For	O
VGG	B-Method
/	O
ResNet	B-Method
/	O
DenseNet	B-Method
networks	I-Method
,	O
assuming	O
the	O
number	O
of	O
active	O
sites	O
reduces	O
by	O
a	O
multiplicative	O
factor	O
with	O
each	O
pooling	B-Method
operation	I-Method
,	O
the	O
cost	O
of	O
building	O
all	O
the	O
hash	O
-	O
tables	O
and	O
rule	O
-	O
books	O
is	O
also	O
,	O
regardless	O
of	O
the	O
depth	O
of	O
the	O
network	O
.	O
	
section	O
:	O
Experiments	O
	
We	O
perform	O
experiments	O
on	O
a	O
2D	O
and	O
a	O
3D	O
dataset	O
with	O
sparse	O
images	O
.	O
	
The	O
CASIA	O
dataset	O
contains	O
samples	O
of	O
3755	O
GBK	O
level	O
-	O
1	O
characters	O
with	O
approximately	O
240	O
train	O
and	O
60	O
test	O
images	O
per	O
class	O
.	O
	
CJVK	O
characters	O
are	O
good	O
test	O
cases	O
for	O
our	O
models	O
because	O
they	O
are	O
a	O
worst	O
-	O
case	O
scenario	O
for	O
sparse	B-Method
convolutional	I-Method
networks	I-Method
:	O
when	O
drawn	O
at	O
scale	O
,	O
about	O
8	O
%	O
of	O
the	O
pixels	O
are	O
active	O
,	O
but	O
this	O
percentage	O
rapidly	O
decreases	O
after	O
pooling	B-Method
due	O
to	O
the	O
small	O
density	O
of	O
the	O
pen	O
strokes	O
.	O
	
This	O
makes	O
them	O
a	O
good	O
test	O
case	O
for	O
our	O
models	O
.	O
	
The	O
ModelNet	O
-	O
40	O
datasethttp:	O
//	O
3dshapenets.cs.princeton.edu	O
/	O
contain	O
2468	O
CAD	B-Method
models	I-Method
that	O
contain	O
shapes	O
corresponding	O
to	O
40	O
classes	O
.	O
	
We	O
follow	O
the	O
preprocessing	O
of	O
before	O
feeding	O
the	O
models	O
into	O
our	O
convolutional	B-Method
networks	I-Method
.	O
	
All	O
CAD	B-Method
models	I-Method
were	O
rendered	O
as	O
surfaces	O
at	O
size	O
.	O
	
subsection	O
:	O
Results	O
on	O
CASIA	O
	
We	O
first	O
experiment	O
with	O
two	O
VGG	B-Method
architectures	O
on	O
the	O
CASIA	O
dataset	O
.	O
	
We	O
trained	O
all	O
models	O
for	O
100	O
epochs	O
using	O
batches	O
of	O
size	O
100	O
,	O
SGD	B-Method
with	O
momentum	O
0.9	O
,	O
a	O
weight	O
decay	O
of	O
,	O
and	O
a	O
learning	B-Metric
rate	I-Metric
decay	I-Metric
of	O
5	O
%	O
per	O
epoch	O
.	O
	
For	O
simplicity	O
,	O
we	O
do	O
not	O
employ	O
any	O
data	B-Method
augmentation	I-Method
.	O
	
The	O
architectures	O
of	O
our	O
VGG	B-Method
networks	O
and	O
their	O
performances	O
are	O
presented	O
in	O
Table	O
[	O
reference	O
]	O
.	O
	
We	O
observe	O
that	O
‘	O
‘	O
regular	O
’	O
’	O
C	B-Method
convolutions	I-Method
and	O
‘	O
‘	O
sparse	O
’	O
’	O
SC	B-Method
convolutions	O
achieve	O
the	O
same	O
error	O
:	O
this	O
result	O
suggests	O
that	O
discarding	O
the	O
ground	O
state	O
has	O
essentially	O
no	O
negative	O
impact	O
on	O
performance	O
.	O
	
This	O
is	O
an	O
argument	O
for	O
always	O
discarding	O
ground	O
states	O
,	O
as	O
it	O
makes	O
things	O
easier	O
computationally	O
and	O
algorithmically	O
.	O
	
Comparing	O
SC	B-Method
with	O
VSC	B-Method
convolutions	I-Method
,	O
we	O
observe	O
a	O
minimal	O
loss	O
in	O
performance	O
by	O
considering	O
only	O
the	O
valid	O
part	O
of	O
the	O
convolution	O
.	O
	
This	O
minimal	O
loss	O
in	O
accuracy	B-Metric
does	O
facilitate	O
great	O
computational	B-Metric
improvements	O
:	O
networks	B-Method
using	O
VSC	B-Method
use	O
2	O
to	O
3	O
less	O
computation	O
and	O
memory	O
.	O
	
Next	O
,	O
we	O
performed	O
experiments	O
on	O
CASIA	B-Task
with	O
submanifold	B-Task
ResNets	I-Task
.	O
	
The	O
key	O
difference	O
between	O
our	O
implementation	O
of	O
ResNets	B-Method
and	O
regular	B-Method
ResNets	I-Method
is	O
that	O
stride	O
-	O
2	O
ResNet	B-Method
modules	O
use	O
SC	B-Method
(	O
,	O
,	O
3	O
,	O
2	O
)	O
convolutions	O
for	O
the	O
strided	B-Method
convolution	I-Method
,	O
rather	O
than	O
SC	B-Method
(	O
,	O
,	O
1	O
,	O
2	O
)	O
.	O
	
This	O
change	O
is	O
necessary	O
to	O
ensure	O
the	O
two	O
branches	O
produce	O
the	O
same	O
set	O
of	O
active	O
sites	O
,	O
which	O
simplifies	O
bookkeeping	O
and	O
turns	O
the	O
addition	B-Method
operation	I-Method
into	O
a	O
simple	O
matrix	B-Method
-	I-Method
matrix	I-Method
addition	I-Method
.	O
	
Unlike	O
the	O
VSC	B-Method
convolutions	I-Method
that	O
are	O
used	O
in	O
most	O
layers	O
,	O
the	O
SC	B-Method
(	O
,	O
,	O
3	O
,	O
2	O
)	O
we	O
use	O
after	O
downsampling	O
leads	O
sites	O
to	O
be	O
active	O
if	O
any	O
of	O
its	O
inputs	O
are	O
active	O
,	O
which	O
avoids	O
information	O
loss	O
in	O
the	O
transition	O
.	O
	
The	O
architectures	O
of	O
our	O
ResNet	B-Method
networks	O
and	O
their	O
performances	O
are	O
presented	O
in	O
Table	O
[	O
reference	O
]	O
.	O
	
The	O
results	O
with	O
ResNets	B-Method
are	O
in	O
line	O
with	O
those	O
obtained	O
using	O
VGG	B-Method
networks	O
:	O
we	O
obtain	O
reductions	O
in	O
computational	B-Metric
and	O
memory	B-Metric
requirements	I-Metric
by	O
at	O
least	O
a	O
factor	O
of	O
2	O
at	O
a	O
minimal	O
loss	O
in	O
accuracy	B-Metric
.	O
	
We	O
also	O
performed	O
experiments	O
with	O
DenseNets	O
;	O
please	O
see	O
Table	O
[	O
reference	O
]	O
.	O
	
Next	O
we	O
experimented	O
with	O
adding	O
extra	O
connections	O
to	O
VGG	B-Method
networks	O
to	O
increase	O
the	O
effective	O
receptive	O
fields	O
of	O
the	O
hidden	O
states	O
;	O
see	O
Table	O
[	O
reference	O
]	O
for	O
results	O
.	O
	
In	O
the	O
table	O
,	O
denotes	O
a	O
VSC	B-Method
convolution	O
performed	O
in	O
parallel	O
with	O
a	O
chain	O
of	O
SC	B-Method
-	I-Method
VSC	I-Method
-	I-Method
DC	I-Method
operations	I-Method
;	O
outputs	O
are	O
concatenated	O
to	O
produce	O
output	O
feature	O
planes	O
.	O
	
To	O
simplify	O
the	O
network	B-Method
design	I-Method
,	O
we	O
switched	O
to	O
size	O
-	O
3	O
stride	B-Method
-	I-Method
2	I-Method
max	I-Method
-	I-Method
pooling	I-Method
,	O
matching	O
the	O
SC	B-Method
convolutions	O
in	O
the	O
SC	B-Method
-	I-Method
VSC	I-Method
-	I-Method
DC	I-Method
branches	I-Method
,	O
and	O
reduce	O
the	O
input	O
size	O
from	O
64	O
64	O
to	O
63	O
63	O
.	O
	
Figure	O
[	O
reference	O
]	O
presents	O
an	O
overview	O
of	O
all	O
our	O
results	O
on	O
the	O
CASIA	O
dataset	O
.	O
	
subsection	O
:	O
Results	O
on	O
ModelNet	O
	
In	O
a	O
second	O
set	O
of	O
experiments	O
,	O
we	O
compare	O
two	O
submanifold	O
VGG	B-Method
networks	O
with	O
a	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
dense	B-Method
convolutional	I-Method
network	I-Method
on	O
the	O
ModelNet	O
-	O
40	O
dataset	O
.	O
	
The	O
results	O
of	O
these	O
experiments	O
are	O
shown	O
in	O
Table	O
[	O
reference	O
]	O
:	O
the	O
left	O
part	O
of	O
the	O
table	O
shows	O
the	O
architecture	O
and	O
performance	O
of	O
our	O
submanifold	O
VGG	B-Method
networks	O
,	O
whereas	O
the	O
right	O
part	O
of	O
the	O
table	O
shows	O
that	O
of	O
the	O
dense	B-Method
3DNiN	I-Method
network	I-Method
.	O
	
The	O
results	O
clearly	O
demonstrate	O
that	O
submanifold	B-Method
have	O
the	O
potential	O
for	O
designing	O
convolutional	B-Method
networks	I-Method
for	O
sparse	O
data	O
that	O
obtain	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
performance	O
with	O
limited	O
computational	B-Metric
requirements	O
:	O
in	O
particular	O
,	O
our	O
VGG	B-Method
-	O
A	O
network	O
makes	O
2	O
%	O
more	O
errors	O
at	O
13	O
fewer	O
computations	O
,	O
and	O
our	O
VGG	B-Method
-	O
B	O
performs	O
roughly	O
on	O
par	O
with	O
the	O
dense	B-Method
3DNiN	I-Method
whilst	O
performing	O
fewer	O
computations	O
.	O
	
section	O
:	O
Related	O
Work	O
	
This	O
paper	O
is	O
not	O
the	O
first	O
to	O
study	O
sparse	B-Method
convolutional	I-Method
networks	I-Method
.	O
	
Most	O
prior	B-Method
networks	I-Method
for	O
sparse	O
data	O
implements	O
a	O
standard	O
convolutional	B-Method
operator	I-Method
that	O
increases	O
the	O
number	O
of	O
active	O
sites	O
with	O
each	O
layer	O
.	O
	
By	O
contrast	O
,	O
our	O
submanifold	B-Method
convolutional	I-Method
networks	I-Method
allows	O
sparse	O
data	O
to	O
be	O
processed	O
whilst	O
retraining	O
a	O
much	O
greater	O
degree	O
of	O
sparsity	O
.	O
	
We	O
have	O
shown	O
that	O
this	O
makes	O
it	O
practical	O
to	O
train	O
deep	B-Method
and	I-Method
efficient	I-Method
VGG	I-Method
and	O
ResNet	B-Method
models	I-Method
.	O
	
Submanifold	B-Method
convolutional	I-Method
networks	I-Method
are	O
also	O
much	O
sparser	O
than	O
OctNets	B-Method
.	O
	
OctNet	B-Method
stores	O
data	O
in	O
oct	B-Method
-	I-Method
trees	I-Method
:	O
a	O
data	B-Method
structure	I-Method
in	O
which	O
the	O
grid	O
cube	O
is	O
progressively	O
subdivided	O
into	O
smaller	O
sub	O
-	O
cubes	O
until	O
the	O
sub	O
-	O
cubes	O
are	O
either	O
empty	O
or	O
contain	O
a	O
single	O
active	O
site	O
.	O
	
To	O
compare	O
the	O
efficiency	O
of	O
OctNets	B-Method
with	O
that	O
of	O
submanifold	B-Method
convolutional	I-Method
networks	I-Method
,	O
we	O
picked	O
a	O
random	O
sample	O
from	O
the	O
ModelNet	O
-	O
40	O
dataset	O
and	O
rendered	O
it	O
in	O
a	O
cube	O
with	O
grid	O
points	O
.	O
	
The	O
resulting	O
grid	O
had	O
423	O
active	O
sites	O
,	O
which	O
corresponds	O
to	O
1.3	O
%	O
of	O
the	O
total	O
number	O
of	O
sites	O
.	O
	
Each	O
active	O
site	O
had	O
on	O
average	O
12.4	O
active	O
neighbors	O
(	O
the	O
maximum	O
possible	O
number	O
of	O
neighbors	O
is	O
27	O
)	O
.	O
	
VSC	B-Method
convolutions	I-Method
,	O
therefore	O
,	O
require	O
only	O
0.6	O
%	O
of	O
the	O
work	O
of	O
a	O
dense	B-Method
(	I-Method
C	I-Method
)	I-Method
convolution	I-Method
.	O
	
However	O
,	O
in	O
the	O
OctTree	B-Method
,	O
80	O
%	O
,	O
13	O
%	O
,	O
4	O
%	O
,	O
and	O
3	O
%	O
of	O
the	O
volume	O
of	O
the	O
cube	O
is	O
covered	O
by	O
sub	O
-	O
cubes	O
of	O
size	O
,	O
,	O
and	O
,	O
respectively	O
.	O
	
As	O
a	O
result	O
,	O
an	O
OctNet	B-Method
convolution	I-Method
,	O
which	O
operates	O
over	O
the	O
surfaces	O
of	O
the	O
smaller	O
cubes	O
,	O
requires	O
about	O
35	O
%	O
of	O
the	O
computations	O
that	O
a	O
dense	B-Method
(	I-Method
C	I-Method
)	I-Method
convolution	I-Method
requires	O
.	O
	
In	O
this	O
particular	O
example	O
,	O
an	O
OctNet	B-Method
convolution	I-Method
thus	O
has	O
a	O
computational	B-Metric
cost	O
that	O
is	O
60	O
times	O
higher	O
than	O
that	O
of	O
a	O
VSC	B-Method
convolution	O
.	O
	
Submanifold	B-Method
convolutional	I-Method
networks	I-Method
also	O
have	O
advantages	O
in	O
terms	O
of	O
memory	B-Metric
requirements	I-Metric
.	O
	
In	O
particular	O
,	O
a	O
submanifold	B-Method
network	I-Method
stores	O
a	O
single	O
feature	O
vector	O
for	O
each	O
of	O
the	O
active	O
sites	O
.	O
	
By	O
contrast	O
,	O
OctTrees	B-Method
have	O
about	O
twice	O
as	O
many	O
empty	O
child	O
nodes	O
as	O
active	O
nodes	O
,	O
which	O
implies	O
they	O
have	O
to	O
store	O
roughly	O
three	O
times	O
as	O
many	O
features	O
as	O
a	O
submanifold	B-Method
convolutional	I-Method
network	I-Method
.	O
	
Having	O
said	O
that	O
,	O
some	O
of	O
the	O
ideas	O
of	O
may	O
be	O
combined	O
with	O
VSC	B-Method
convolutions	I-Method
.	O
	
In	O
particular	O
,	O
it	O
is	O
possible	O
to	O
use	O
oct	B-Method
-	I-Method
trees	I-Method
as	O
a	O
specialized	O
hash	B-Method
function	I-Method
in	O
VSC	B-Method
convolutions	I-Method
.	O
	
Such	O
an	O
oct	B-Method
-	I-Method
tree	I-Method
-	I-Method
based	I-Method
hash	I-Method
function	I-Method
has	O
the	O
potential	O
to	O
be	O
faster	O
than	O
a	O
standard	O
universal	B-Method
hash	I-Method
function	I-Method
that	O
operates	O
on	O
integer	O
tuple	O
keys	O
,	O
like	O
in	O
our	O
implementation	O
of	O
VSC	B-Method
.	O
	
section	O
:	O
Conclusion	O
	
We	O
introduced	O
a	O
new	O
sparse	B-Method
convolutional	I-Method
operator	I-Method
,	O
called	O
valid	B-Method
sparse	I-Method
convolution	I-Method
(	O
VSC	B-Method
)	O
,	O
that	O
facilitates	O
the	O
design	O
of	O
efficient	O
,	O
deep	B-Method
convolutional	I-Method
networks	I-Method
for	O
sparse	O
data	O
.	O
	
We	O
have	O
shown	O
that	O
VSC	B-Method
convolutions	I-Method
lead	O
to	O
substantial	O
computational	B-Metric
savings	O
whilst	O
maintain	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
accuracies	B-Metric
on	O
two	O
datasets	O
:	O
a	O
dataset	O
comprising	O
one	O
-	O
dimensional	O
manifolds	O
embedded	O
in	O
two	O
-	O
dimensional	O
space	O
,	O
and	O
a	O
dataset	O
comprising	O
two	O
-	O
dimensional	O
surfaces	O
embedded	O
in	O
three	O
-	O
dimensional	O
space	O
.	O
	
As	O
part	O
of	O
this	O
paper	O
,	O
we	O
are	O
releasing	O
easy	O
-	O
to	O
-	O
use	O
implementations	O
of	O
VSC	B-Method
and	O
the	O
other	O
sparse	B-Method
operations	I-Method
we	O
used	O
in	O
the	O
networks	O
described	O
in	O
this	O
paper	O
.	O
	
We	O
will	O
also	O
release	O
code	O
to	O
reproduce	O
the	O
results	O
of	O
our	O
experiments	O
.	O
	
bibliography	O
:	O
References	O
	
document	O
:	O
Natural	B-Task
Language	I-Task
Inference	I-Task
by	O
Tree	B-Method
-	I-Method
Based	I-Method
Convolution	I-Method
and	O
Heuristic	B-Method
Matching	I-Method
	
In	O
this	O
paper	O
,	O
we	O
propose	O
the	O
TBCNN	B-Method
-	I-Method
pair	I-Method
model	I-Method
to	O
recognize	B-Task
entailment	I-Task
and	I-Task
contradiction	I-Task
between	O
two	O
sentences	O
.	O
	
In	O
our	O
model	O
,	O
a	O
tree	B-Method
-	I-Method
based	I-Method
convolutional	I-Method
neural	I-Method
network	I-Method
(	O
TBCNN	B-Method
)	O
captures	O
sentence	O
-	O
level	O
semantics	O
;	O
then	O
heuristic	B-Method
matching	I-Method
layers	I-Method
like	O
concatenation	B-Method
,	O
element	O
-	O
wise	O
product	O
/	O
difference	O
combine	O
the	O
information	O
in	O
individual	O
sentences	O
.	O
	
Experimental	O
results	O
show	O
that	O
our	O
model	O
outperforms	O
existing	O
sentence	B-Method
encoding	I-Method
-	I-Method
based	I-Method
approaches	I-Method
by	O
a	O
large	O
margin	O
.	O
	
section	O
:	O
Introduction	O
	
Recognizing	B-Task
entailment	I-Task
and	O
contradiction	O
between	O
two	O
sentences	O
(	O
called	O
a	O
premise	O
and	O
a	O
hypothesis	O
)	O
is	O
known	O
as	O
natural	O
language	O
inference	B-Task
(	O
NLI	B-Task
)	O
in	O
inference	B-Task
.	O
	
Provided	O
with	O
a	O
premise	O
sentence	O
,	O
the	O
task	O
is	O
to	O
judge	O
whether	O
the	O
hypothesis	O
can	O
be	O
inferred	O
(	O
entailment	O
)	O
,	O
or	O
the	O
hypothesis	O
can	O
not	O
be	O
true	O
(	O
contradiction	O
)	O
.	O
	
Several	O
examples	O
are	O
illustrated	O
in	O
Table	O
[	O
reference	O
]	O
.	O
	
NLI	B-Task
is	O
in	O
the	O
core	O
of	O
natural	B-Task
language	I-Task
understanding	I-Task
and	O
has	O
wide	O
applications	O
in	O
NLP	B-Task
,	O
e.g.	O
,	O
question	B-Task
answering	I-Task
and	O
automatic	B-Task
summarization	I-Task
.	O
	
Moreover	O
,	O
NLI	B-Task
is	O
also	O
related	O
to	O
other	O
tasks	O
of	O
sentence	B-Task
pair	I-Task
modeling	I-Task
,	O
including	O
paraphrase	B-Task
detection	I-Task
,	O
relation	B-Task
recognition	I-Task
of	I-Task
discourse	I-Task
units	I-Task
,	O
etc	O
.	O
	
Traditional	O
approaches	O
to	O
NLI	B-Task
mainly	O
fall	O
into	O
two	O
groups	O
:	O
feature	B-Method
-	I-Method
rich	I-Method
models	I-Method
and	O
formal	B-Method
reasoning	I-Method
methods	I-Method
.	O
	
Feature	B-Method
-	I-Method
based	I-Method
approaches	I-Method
typically	O
leverage	O
machine	B-Method
learning	I-Method
models	I-Method
,	O
but	O
require	O
intensive	O
human	O
engineering	O
to	O
represent	O
lexical	O
and	O
syntactic	O
information	O
in	O
two	O
sentences	O
.	O
	
Formal	B-Task
reasoning	I-Task
,	O
on	O
the	O
other	O
hand	O
,	O
converts	O
a	O
sentence	O
into	O
a	O
formal	B-Method
logical	I-Method
representation	I-Method
and	O
uses	O
interpreters	B-Method
to	O
search	O
for	O
a	O
proof	O
.	O
	
However	O
,	O
such	O
approaches	O
are	O
limited	O
in	O
terms	O
of	O
scope	B-Metric
and	O
accuracy	B-Metric
.	O
	
The	O
renewed	O
prosperity	O
of	O
neural	B-Method
networks	I-Method
has	O
made	O
significant	O
achievements	O
in	O
various	O
NLP	B-Task
applications	I-Task
,	O
including	O
individual	B-Task
sentence	I-Task
modeling	I-Task
as	O
well	O
as	O
sentence	B-Task
matching	I-Task
.	O
	
A	O
typical	O
neural	B-Method
architecture	I-Method
to	O
model	O
sentence	B-Task
pairs	I-Task
is	O
the	O
“	O
Siamese	O
”	O
structure	O
,	O
which	O
involves	O
an	O
underlying	O
sentence	B-Method
model	I-Method
and	O
a	O
matching	B-Method
layer	I-Method
to	O
determine	O
the	O
relationship	O
between	O
two	O
sentences	O
.	O
	
Prevailing	O
sentence	B-Method
models	I-Method
include	O
convolutional	B-Method
networks	I-Method
and	O
recurrent	B-Method
/	I-Method
recursive	I-Method
networks	I-Method
.	O
	
Although	O
they	O
have	O
achieved	O
high	O
performance	O
,	O
they	O
may	O
either	O
fail	O
to	O
fully	O
make	O
use	O
of	O
the	O
syntactical	O
information	O
in	O
sentences	O
or	O
be	O
difficult	O
to	O
train	O
due	O
to	O
the	O
long	O
propagation	O
path	O
.	O
	
Recently	O
,	O
we	O
propose	O
a	O
novel	O
tree	B-Method
-	I-Method
based	I-Method
convolutional	I-Method
neural	I-Method
network	I-Method
(	O
TBCNN	B-Method
)	I-Method
to	O
alleviate	O
the	O
aforementioned	O
problems	O
and	O
have	O
achieved	O
higher	O
performance	O
in	O
two	O
sentence	B-Task
classification	I-Task
tasks	I-Task
.	O
	
However	O
,	O
it	O
is	O
less	O
clear	O
whether	O
TBCNN	B-Method
can	O
be	O
harnessed	O
to	O
model	O
sentence	O
pairs	O
for	O
implicit	O
logical	O
inference	B-Task
,	O
as	O
is	O
in	O
the	O
NLI	B-Task
task	I-Task
.	O
	
In	O
this	O
paper	O
,	O
we	O
propose	O
the	O
TBCNN	B-Method
-	I-Method
pair	I-Method
neural	I-Method
model	I-Method
to	O
recognize	O
entailment	O
and	O
contradiction	O
between	O
two	O
sentences	O
.	O
	
We	O
leverage	O
our	O
newly	O
proposed	O
TBCNN	B-Method
model	I-Method
to	O
capture	O
structural	O
information	O
in	O
sentences	O
,	O
which	O
is	O
important	O
to	O
NLI	B-Task
.	O
	
For	O
example	O
,	O
the	O
phrase	O
“	O
riding	O
bicycles	O
on	O
the	O
streets	O
”	O
in	O
Table	O
[	O
reference	O
]	O
can	O
be	O
well	O
recognized	O
by	O
TBCNN	B-Method
via	O
the	O
dependency	O
relations	O
dobj	O
(	O
riding	O
,	O
bicycles	O
)	O
and	O
prep_on	O
(	O
riding	O
,	O
street	O
)	O
.	O
	
As	O
we	O
can	O
see	O
,	O
TBCNN	B-Method
is	O
more	O
robust	O
than	O
sequential	B-Method
convolution	I-Method
in	O
terms	O
of	O
word	O
order	O
distortion	O
,	O
which	O
may	O
be	O
introduced	O
by	O
determinators	O
,	O
modifiers	O
,	O
etc	O
.	O
	
A	O
pooling	B-Method
layer	I-Method
then	O
aggregates	O
information	O
along	O
the	O
tree	O
,	O
serving	O
as	O
a	O
way	O
of	O
semantic	B-Method
compositonality	I-Method
.	O
	
Finally	O
,	O
two	O
sentences	O
’	O
information	O
is	O
combined	O
by	O
several	O
heuristic	B-Method
matching	I-Method
layers	I-Method
,	O
including	O
concatenation	B-Method
,	O
element	B-Method
-	I-Method
wise	I-Method
product	I-Method
and	O
difference	B-Method
;	O
they	O
are	O
effective	O
in	O
capturing	O
relationships	O
between	O
two	O
sentences	O
,	O
but	O
remain	O
low	B-Metric
complexity	I-Metric
.	O
	
To	O
sum	O
up	O
,	O
the	O
main	O
contributions	O
of	O
this	O
paper	O
are	O
two	O
-	O
fold	O
:	O
(	O
1	O
)	O
We	O
are	O
the	O
first	O
to	O
introduce	O
tree	B-Method
-	I-Method
based	I-Method
convolution	I-Method
to	O
sentence	B-Task
pair	I-Task
modeling	I-Task
tasks	I-Task
like	O
NLI	B-Task
;	O
(	O
2	O
)	O
Leveraging	O
additional	O
heuristics	O
further	O
improves	O
the	O
accuracy	B-Metric
while	O
remaining	O
low	B-Metric
complexity	I-Metric
,	O
outperforming	O
existing	O
sentence	B-Method
encoding	I-Method
-	I-Method
based	I-Method
approaches	I-Method
to	O
a	O
large	O
extent	O
,	O
including	O
feature	B-Method
-	I-Method
rich	I-Method
methods	I-Method
and	O
long	B-Method
short	I-Method
term	I-Method
memory	I-Method
(	O
LSTM	B-Method
)-	O
based	O
recurrent	O
networks	O
.	O
	
section	O
:	O
Related	O
Work	O
	
Entailment	B-Task
recognition	I-Task
can	O
be	O
viewed	O
as	O
a	O
task	O
of	O
sentence	B-Task
pair	I-Task
modeling	I-Task
.	O
	
Most	O
neural	B-Method
networks	I-Method
in	O
this	O
field	O
involve	O
a	O
sentence	B-Method
-	I-Method
level	I-Method
model	I-Method
,	O
followed	O
by	O
one	O
or	O
a	O
few	O
matching	B-Method
layers	I-Method
.	O
	
They	O
are	O
sometimes	O
called	O
“	O
Siamese	B-Method
”	I-Method
architectures	I-Method
.	O
	
CNN	B-Method
:	O
NIPS	B-Method
and	O
CNN	B-Method
:	O
	
NAACL	B-Method
apply	O
convolutional	B-Method
neural	I-Method
networks	I-Method
(	O
CNNs	B-Method
)	O
as	O
the	O
individual	O
sentence	B-Method
model	I-Method
,	O
where	O
a	O
set	O
of	O
feature	B-Method
detectors	I-Method
over	O
successive	O
words	O
are	O
designed	O
to	O
extract	O
local	O
features	O
.	O
	
LSTM	B-Method
:	O
	
AAAI	B-Method
build	O
sentence	B-Method
pair	I-Method
models	I-Method
upon	O
recurrent	B-Method
neural	I-Method
networks	I-Method
(	O
RNNs	B-Method
)	O
to	O
iteratively	O
integrate	O
information	O
along	O
a	O
sentence	O
.	O
	
recurparaphrase	B-Method
dynamically	O
construct	O
tree	O
structures	O
(	O
analogous	O
to	O
parse	O
trees	O
)	O
by	O
recursive	B-Method
autoencoders	I-Method
to	O
detect	O
paraphrase	O
between	O
two	O
sentences	O
.	O
	
As	O
shown	O
,	O
inherent	O
structural	O
information	O
in	O
sentences	O
is	O
oftentimes	O
important	O
to	O
natural	B-Task
language	I-Task
understanding	I-Task
.	O
	
The	O
simplest	O
approach	O
to	O
match	O
two	O
sentences	O
,	O
perhaps	O
,	O
is	O
to	O
concatenate	O
their	O
vector	B-Method
representations	I-Method
.	O
	
Concatenation	B-Method
is	O
also	O
applied	O
in	O
our	O
previous	O
work	O
of	O
matching	O
the	O
subject	B-Task
and	I-Task
object	I-Task
in	I-Task
relation	I-Task
classification	I-Task
.	O
	
CNN	B-Method
:	O
	
EMNLP	B-Method
apply	O
additional	O
heuristics	O
,	O
namely	O
Euclidean	O
distance	O
,	O
cosine	B-Method
measure	I-Method
,	O
and	O
element	B-Method
-	I-Method
wise	I-Method
absolute	I-Method
difference	I-Method
.	O
	
The	O
above	O
methods	O
operate	O
on	O
a	O
fixed	B-Method
-	I-Method
size	I-Method
vector	I-Method
representation	I-Method
of	O
a	O
sentence	O
,	O
categorized	O
as	O
sentence	B-Method
encoding	I-Method
-	I-Method
based	I-Method
approaches	I-Method
.	O
	
Thus	O
the	O
matching	B-Metric
complexity	I-Metric
is	O
,	O
i.e.	O
,	O
independent	O
of	O
the	O
sentence	O
length	O
.	O
	
Word	O
-	O
by	O
-	O
word	O
similarity	O
matrices	O
are	O
introduced	O
to	O
enhance	O
interaction	B-Task
.	O
	
To	O
obtain	O
the	O
similarity	O
matrix	O
,	O
CNN	B-Method
:	O
	
NIPS	B-Method
(	O
Arc	O
-	O
II	O
)	O
concatenate	O
two	O
words	O
’	O
vectors	O
(	O
after	O
convolution	B-Method
)	O
,	O
recurparaphrase	B-Method
compute	O
Euclidean	B-Method
distance	I-Method
,	O
and	O
LSTM	B-Method
:	O
	
AAAI	B-Method
apply	O
tensor	B-Method
product	I-Method
.	O
	
In	O
this	O
way	O
,	O
the	O
complexity	B-Metric
is	O
of	O
,	O
where	O
is	O
the	O
length	O
of	O
a	O
sentence	O
;	O
hence	O
similarity	O
matrices	O
are	O
difficult	O
to	O
scale	O
and	O
less	O
efficient	O
for	O
large	O
datasets	O
.	O
	
Recently	O
,	O
attention	O
introduce	O
several	O
context	B-Method
-	I-Method
aware	I-Method
methods	I-Method
for	O
sentence	B-Task
matching	I-Task
.	O
	
They	O
report	O
that	O
RNNs	B-Method
over	O
a	O
single	O
chain	O
of	O
two	O
sentences	O
are	O
more	O
informative	O
than	O
separate	O
RNNs	B-Method
;	O
a	O
static	O
attention	O
over	O
the	O
first	O
sentence	O
is	O
also	O
useful	O
when	O
modeling	O
the	O
second	O
one	O
.	O
	
Such	O
context	B-Method
-	I-Method
awareness	I-Method
interweaves	O
the	O
sentence	B-Method
modeling	I-Method
and	I-Method
matching	I-Method
steps	I-Method
.	O
	
In	O
some	O
scenarios	O
like	O
sentence	B-Task
pair	I-Task
re	I-Task
-	I-Task
ranking	I-Task
,	O
it	O
is	O
not	O
feasible	O
to	O
pre	O
-	O
calculate	O
the	O
vector	B-Method
representations	I-Method
of	I-Method
sentences	I-Method
,	O
so	O
the	O
matching	B-Metric
complexity	I-Metric
is	O
of	O
.	O
	
attention	O
further	O
develop	O
a	O
word	B-Method
-	I-Method
by	I-Method
-	I-Method
word	I-Method
attention	I-Method
mechanism	I-Method
and	O
obtain	O
a	O
higher	O
accuracy	B-Metric
with	O
a	O
complexity	O
order	O
of	O
.	O
	
section	O
:	O
Our	O
Approach	O
	
We	O
follow	O
the	O
“	O
Siamese	B-Method
”	I-Method
architecture	I-Method
(	O
like	O
most	O
work	O
in	O
Section	O
[	O
reference	O
]	O
)	O
and	O
adopt	O
a	O
two	O
-	O
step	O
strategy	O
to	O
classify	O
the	O
relation	O
between	O
two	O
sentences	O
.	O
	
Concretely	O
,	O
our	O
model	O
comprises	O
two	O
parts	O
:	O
A	O
tree	B-Method
-	I-Method
based	I-Method
convolutional	I-Method
neural	I-Method
network	I-Method
models	O
each	O
individual	O
sentence	O
(	O
Figure	O
[	O
reference	O
]	O
a	O
)	O
.	O
	
Notice	O
that	O
,	O
the	O
two	O
sentences	O
,	O
premise	O
and	O
hypothesis	O
,	O
share	O
a	O
same	O
TBCNN	B-Method
model	I-Method
(	O
with	O
same	O
parameters	O
)	O
,	O
because	O
this	O
part	O
aims	O
to	O
capture	O
general	O
semantics	O
of	O
sentences	O
.	O
	
A	O
matching	B-Method
layer	I-Method
combines	O
two	O
sentences	O
’	O
information	O
by	O
heuristics	O
(	O
Figure	O
[	O
reference	O
]	O
b	O
)	O
.	O
	
After	O
individual	O
sentence	B-Method
models	I-Method
,	O
we	O
design	O
a	O
sentence	B-Method
matching	I-Method
layer	I-Method
to	O
aggregate	O
information	O
.	O
	
We	O
use	O
simple	O
heuristics	B-Method
,	O
including	O
concatenation	O
,	O
element	B-Method
-	I-Method
wise	I-Method
product	I-Method
and	O
difference	B-Method
,	O
which	O
are	O
effective	O
and	O
efficient	O
.	O
	
Finally	O
,	O
we	O
add	O
a	O
softmax	B-Method
layer	I-Method
for	O
output	O
.	O
	
The	O
training	B-Metric
objective	I-Metric
is	O
cross	B-Metric
-	I-Metric
entropy	I-Metric
loss	I-Metric
,	O
and	O
we	O
adopt	O
mini	B-Method
-	I-Method
batch	I-Method
stochastic	I-Method
gradient	I-Method
descent	I-Method
,	O
computed	O
by	O
back	B-Method
-	I-Method
propagation	I-Method
.	O
	
subsection	O
:	O
Tree	B-Method
-	I-Method
Based	I-Method
Convolution	I-Method
	
The	O
tree	B-Method
-	I-Method
based	I-Method
convolutoinal	I-Method
neural	I-Method
network	I-Method
(	O
TBCNN	B-Method
)	O
is	O
first	O
proposed	O
in	O
our	O
previous	O
work	O
to	O
classify	O
program	O
source	O
code	O
;	O
later	O
,	O
we	O
further	O
propose	O
TBCNN	B-Method
variants	I-Method
to	O
model	O
sentences	O
.	O
	
This	O
subsection	O
details	O
the	O
tree	B-Method
-	I-Method
based	I-Method
convolution	I-Method
process	I-Method
.	O
	
The	O
basic	O
idea	O
of	O
TBCNN	B-Method
is	O
to	O
design	O
a	O
set	O
of	O
subtree	B-Method
feature	I-Method
detectors	I-Method
sliding	O
over	O
the	O
parse	O
tree	O
of	O
a	O
sentence	O
;	O
either	O
a	O
constituency	O
tree	O
or	O
a	O
dependency	O
tree	O
applies	O
.	O
	
In	O
this	O
paper	O
,	O
we	O
prefer	O
the	O
dependency	B-Method
tree	I-Method
-	I-Method
based	I-Method
convolution	I-Method
for	O
its	O
efficiency	O
and	O
compact	B-Metric
expressiveness	I-Metric
.	O
	
Concretely	O
,	O
a	O
sentence	O
is	O
first	O
converted	O
to	O
a	O
dependency	O
parse	O
tree	O
.	O
	
Each	O
node	O
in	O
the	O
dependency	O
tree	O
corresponds	O
to	O
a	O
word	O
in	O
the	O
sentence	O
;	O
an	O
edge	O
indicates	O
is	O
governed	O
by	O
.	O
	
Edges	O
are	O
labeled	O
with	O
grammatical	O
relations	O
(	O
e.g.	O
,	O
nsubj	O
)	O
between	O
the	O
parent	O
node	O
and	O
its	O
children	O
.	O
	
Words	O
are	O
represented	O
by	O
pretrained	B-Method
vector	I-Method
representations	I-Method
,	O
also	O
known	O
as	O
word	B-Method
embeddings	I-Method
.	O
	
Now	O
,	O
we	O
consider	O
a	O
set	O
of	O
two	B-Method
-	I-Method
layer	I-Method
subtree	I-Method
feature	I-Method
detectors	I-Method
sliding	O
over	O
the	O
dependency	O
tree	O
.	O
	
At	O
a	O
position	O
where	O
the	O
parent	O
node	O
is	O
with	O
child	O
nodes	O
,	O
the	O
output	O
of	O
the	O
feature	B-Method
detector	I-Method
,	O
,	O
is	O
Let	O
us	O
assume	O
word	O
embeddings	O
(	O
and	O
)	O
are	O
of	O
dimensions	O
;	O
that	O
the	O
convolutional	B-Method
layer	I-Method
is	O
-	O
dimensional	O
.	O
	
is	O
the	O
weight	O
matrix	O
;	O
is	O
the	O
bias	O
vector	O
.	O
	
denotes	O
the	O
dependency	O
relation	O
between	O
and	O
.	O
	
is	O
the	O
non	O
-	O
linear	O
activation	O
function	O
,	O
and	O
we	O
apply	O
ReLU	B-Method
in	O
our	O
experiments	O
.	O
	
After	O
tree	B-Method
-	I-Method
based	I-Method
convolution	I-Method
,	O
we	O
obtain	O
a	O
set	O
of	O
feature	O
maps	O
,	O
which	O
are	O
one	O
-	O
one	O
corresponding	O
to	O
original	O
words	O
in	O
the	O
sentence	O
.	O
	
Therefore	O
,	O
they	O
may	O
vary	O
in	O
size	O
and	O
length	O
.	O
	
A	O
dynamic	B-Method
pooling	I-Method
layer	I-Method
is	O
applied	O
to	O
aggregate	O
information	O
along	O
different	O
parts	O
of	O
the	O
tree	O
,	O
serving	O
as	O
a	O
way	O
of	O
semantic	B-Task
compositionality	I-Task
.	O
	
We	O
use	O
the	O
pooling	B-Method
operation	I-Method
,	O
which	O
takes	O
the	O
maximum	O
value	O
in	O
each	O
dimension	O
.	O
	
Then	O
we	O
add	O
a	O
fully	B-Method
-	I-Method
connected	I-Method
hidden	I-Method
layer	I-Method
to	O
further	O
mix	O
the	O
information	O
in	O
a	O
sentence	O
.	O
	
The	O
obtained	O
vector	B-Method
representation	I-Method
of	O
a	O
sentence	O
is	O
denoted	O
as	O
(	O
also	O
called	O
a	O
sentence	B-Task
embedding	I-Task
)	O
.	O
	
Notice	O
that	O
the	O
same	O
tree	B-Method
-	I-Method
based	I-Method
convolution	I-Method
applies	O
to	O
both	O
the	O
premise	O
and	O
hypothesis	O
.	O
	
Tree	B-Method
-	I-Method
based	I-Method
convolution	I-Method
along	O
with	O
pooling	B-Method
enables	O
structural	O
features	O
to	O
reach	O
the	O
output	O
layer	O
with	O
short	O
propagation	O
paths	O
,	O
as	O
opposed	O
to	O
the	O
recursive	B-Method
network	I-Method
,	O
which	O
is	O
also	O
structure	O
-	O
sensitive	O
but	O
may	O
suffer	O
from	O
the	O
problem	O
of	O
long	O
propagation	O
path	O
.	O
	
By	O
contrast	O
,	O
TBCNN	B-Method
is	O
effective	O
and	O
efficient	O
in	O
learning	O
such	O
structural	O
information	O
.	O
	
subsection	O
:	O
Matching	B-Method
Heuristics	I-Method
	
In	O
this	O
part	O
,	O
we	O
introduce	O
how	O
vector	B-Method
representations	I-Method
of	O
individual	O
sentences	O
are	O
combined	O
to	O
capture	O
the	O
relation	O
between	O
the	O
premise	O
and	O
hypothesis	O
.	O
	
As	O
the	O
dataset	O
is	O
large	O
,	O
we	O
prefer	O
matching	B-Method
operations	I-Method
because	O
of	O
efficiency	O
concerns	O
.	O
	
Concretely	O
,	O
we	O
have	O
three	O
matching	B-Method
heuristics	I-Method
:	O
	
Concatenation	O
of	O
the	O
two	O
sentence	O
vectors	O
,	O
Element	B-Method
-	I-Method
wise	I-Method
product	I-Method
,	O
and	O
Element	B-Method
-	I-Method
wise	I-Method
difference	I-Method
.	O
	
The	O
first	O
heuristic	O
follows	O
the	O
most	O
standard	O
procedure	O
of	O
the	O
“	O
Siamese	B-Method
”	I-Method
architectures	I-Method
,	O
while	O
the	O
latter	O
two	O
are	O
certain	O
measures	O
of	O
“	B-Metric
similarity	I-Metric
”	O
or	O
“	O
closeness	O
.	O
	
”	O
	
These	O
matching	B-Method
layers	I-Method
are	O
further	O
concatenated	O
(	O
Figure	O
[	O
reference	O
]	O
b	O
)	O
,	O
given	O
by	O
where	O
and	O
are	O
the	O
sentence	O
vectors	O
of	O
the	O
premise	O
and	O
hypothesis	O
,	O
respectively	O
;	O
“	O
”	O
denotes	O
element	O
-	O
wise	O
product	O
;	O
semicolons	O
refer	O
to	O
column	B-Method
vector	I-Method
concatenation	I-Method
.	O
	
is	O
the	O
output	O
of	O
the	O
matching	B-Method
layer	I-Method
.	O
	
We	O
would	O
like	O
to	O
point	O
out	O
that	O
,	O
with	O
subsequent	O
linear	B-Method
transformation	I-Method
,	O
element	B-Method
-	I-Method
wise	I-Method
difference	I-Method
is	O
a	O
special	O
case	O
of	O
concatenation	O
.	O
	
If	O
we	O
assume	O
the	O
subsequent	O
transformation	O
takes	O
the	O
form	O
of	O
,	O
where	O
is	O
the	O
weights	O
for	O
concatenated	O
sentence	O
representations	O
,	O
then	O
element	O
-	O
wise	O
difference	O
can	O
be	O
viewed	O
as	O
such	O
that	O
.	O
	
(	O
is	O
the	O
weights	O
corresponding	O
to	O
element	O
-	O
wise	O
difference	O
.	O
)	O
	
Thus	O
,	O
our	O
third	O
heuristic	O
can	O
be	O
absorbed	O
into	O
the	O
first	O
one	O
in	O
terms	O
of	O
model	B-Metric
capacity	I-Metric
.	O
	
However	O
,	O
as	O
will	O
be	O
shown	O
in	O
the	O
experiment	O
,	O
explicitly	O
specifying	O
this	O
heuristic	O
significantly	O
improves	O
the	O
performance	O
,	O
indicating	O
that	O
optimization	B-Task
differs	O
,	O
despite	O
the	O
same	O
model	O
capacity	O
.	O
	
Moreover	O
,	O
word	B-Task
embedding	I-Task
studies	O
show	O
that	O
linear	O
offset	O
of	O
vectors	O
can	O
capture	O
relationships	O
between	O
two	O
words	O
,	O
but	O
it	O
has	O
not	O
been	O
exploited	O
in	O
sentence	B-Task
-	I-Task
pair	I-Task
relation	I-Task
recognition	I-Task
.	O
	
Although	O
element	O
-	O
wise	O
distance	O
is	O
used	O
to	O
detect	B-Task
paraphrase	I-Task
in	O
CNN	B-Method
:	O
EMNLP	B-Method
,	O
it	O
mainly	O
reflects	O
“	O
similarity	O
”	O
information	O
.	O
	
Our	O
study	O
verifies	O
that	O
vector	B-Method
offset	I-Method
is	O
useful	O
in	O
capturing	O
generic	B-Task
sentence	I-Task
relationships	I-Task
,	O
akin	O
to	O
the	O
word	B-Task
analogy	I-Task
task	I-Task
.	O
	
section	O
:	O
Evaluation	O
	
subsection	O
:	O
Dataset	O
	
To	O
evaluate	O
our	O
TBCNN	B-Method
-	I-Method
pair	I-Method
model	I-Method
,	O
we	O
used	O
the	O
newly	O
published	O
Stanford	B-Material
Natural	I-Material
Language	I-Material
Inference	I-Material
(	O
SNLI	B-Material
)	O
dataset	O
.	O
	
The	O
dataset	O
is	O
constructed	O
by	O
crowdsourced	O
efforts	O
,	O
each	O
sentence	O
written	O
by	O
humans	O
.	O
	
Moreover	O
,	O
the	O
SNLI	B-Material
dataset	O
is	O
magnitudes	O
of	O
larger	O
than	O
previous	O
resources	O
,	O
and	O
hence	O
is	O
particularly	O
suitable	O
for	O
comparing	O
neural	B-Method
models	I-Method
.	O
	
The	O
target	O
labels	O
comprise	O
three	O
classes	O
:	O
Entailment	O
,	O
Contradiction	O
,	O
and	O
Neutral	O
(	O
two	O
irrelevant	O
sentences	O
)	O
.	O
	
We	O
applied	O
the	O
standard	O
train	B-Method
/	I-Method
validation	I-Method
/	I-Method
test	I-Method
split	I-Method
,	O
contraining	O
550k	O
,	O
10k	O
,	O
and	O
10k	O
samples	O
,	O
respectively	O
.	O
	
Figure	O
[	O
reference	O
]	O
presents	O
additional	O
dataset	O
statistics	O
,	O
especially	O
those	O
relevant	O
to	O
dependency	O
parse	O
trees	O
.	O
	
subsection	O
:	O
Hyperparameter	O
Settings	O
	
All	O
our	O
neural	B-Method
layers	I-Method
,	O
including	O
embeddings	B-Method
,	O
were	O
set	O
to	O
300	O
dimensions	O
.	O
	
The	O
model	O
is	O
mostly	O
robust	O
when	O
the	O
dimension	O
is	O
large	O
,	O
e.g.	O
,	O
several	O
hundred	O
.	O
	
Word	O
embeddings	O
were	O
pretrained	O
ourselves	O
by	O
word2vec	O
on	O
the	O
English	O
Wikipedia	O
corpus	O
and	O
fined	O
tuned	O
during	O
training	O
as	O
a	O
part	O
of	O
model	O
parameters	O
.	O
	
We	O
applied	O
penalty	O
of	O
;	O
dropout	O
was	O
chosen	O
by	O
validation	O
with	O
a	O
granularity	O
of	O
0.1	O
(	O
Figure	O
[	O
reference	O
]	O
)	O
.	O
	
We	O
see	O
that	O
a	O
large	O
dropout	B-Metric
rate	I-Metric
(	O
0.3	O
)	O
hurts	O
the	O
performance	O
(	O
and	O
also	O
makes	O
training	B-Task
slow	O
)	O
for	O
such	O
a	O
large	O
dataset	O
as	O
opposed	O
to	O
small	O
datasets	O
in	O
other	O
tasks	O
.	O
	
Initial	O
learning	B-Metric
rate	I-Metric
was	O
set	O
to	O
1	O
,	O
and	O
a	O
power	O
decay	O
was	O
applied	O
.	O
	
We	O
used	O
stochastic	B-Method
gradient	I-Method
descent	I-Method
with	O
a	O
batch	O
size	O
of	O
50	O
.	O
	
subsection	O
:	O
Performance	O
	
Table	O
[	O
reference	O
]	O
compares	O
our	O
model	O
with	O
previous	O
results	O
.	O
	
As	O
seen	O
,	O
the	O
TBCNN	B-Method
sentence	I-Method
pair	I-Method
model	I-Method
,	O
followed	O
by	O
simple	O
concatenation	B-Method
alone	I-Method
,	O
outperforms	O
existing	O
sentence	B-Method
encoding	I-Method
-	I-Method
based	I-Method
approaches	I-Method
(	O
without	O
pretraining	B-Method
)	O
,	O
including	O
a	O
feature	B-Method
-	I-Method
rich	I-Method
method	I-Method
using	O
6	O
groups	O
of	O
human	O
-	O
engineered	O
features	O
,	O
long	B-Method
short	I-Method
term	I-Method
memory	I-Method
(	O
LSTM	B-Method
)-	O
based	O
RNNs	B-Method
,	O
and	O
traditional	O
CNNs	B-Method
.	O
	
This	O
verifies	O
the	O
rationale	O
for	O
using	O
tree	B-Method
-	I-Method
based	I-Method
convolution	I-Method
as	O
the	O
sentence	B-Method
-	I-Method
level	I-Method
neural	I-Method
model	I-Method
for	O
NLI	B-Task
.	O
	
Table	O
[	O
reference	O
]	O
compares	O
different	O
heuristics	O
of	O
matching	B-Task
.	O
	
We	O
first	O
analyze	O
each	O
heuristic	O
separately	O
:	O
using	O
element	B-Method
-	I-Method
wise	I-Method
product	I-Method
alone	I-Method
is	O
significantly	O
worse	O
than	O
concatenation	O
or	O
element	O
-	O
wise	O
difference	O
;	O
the	O
latter	O
two	O
are	O
comparable	O
to	O
each	O
other	O
.	O
	
Combining	O
different	O
matching	B-Method
heuristics	I-Method
improves	O
the	O
result	O
:	O
the	O
TBCNN	B-Method
-	I-Method
pair	I-Method
model	I-Method
with	O
concatenation	B-Method
,	O
element	B-Method
-	I-Method
wise	I-Method
product	I-Method
and	O
difference	B-Method
yields	O
the	O
highest	O
performance	O
of	O
82.1	O
%	O
.	O
	
As	O
analyzed	O
in	O
Section	O
[	O
reference	O
]	O
,	O
the	O
element	B-Method
-	I-Method
wise	I-Method
difference	I-Method
matching	I-Method
layer	I-Method
does	O
not	O
add	O
to	O
model	B-Metric
complexity	I-Metric
and	O
can	O
be	O
absorbed	O
as	O
a	O
special	O
case	O
into	O
simple	O
concatenation	B-Method
.	O
	
However	O
,	O
explicitly	O
using	O
such	O
heuristic	O
yields	O
an	O
accuracy	B-Metric
boost	O
of	O
1–2	O
%	O
.	O
	
Further	O
applying	O
element	B-Method
-	I-Method
wise	I-Method
product	I-Method
improves	O
the	O
accuracy	B-Metric
by	O
another	O
0.5	O
%	O
.	O
	
The	O
full	O
TBCNN	B-Method
-	I-Method
pair	I-Method
model	I-Method
outperforms	O
all	O
existing	O
sentence	B-Method
encoding	I-Method
-	I-Method
based	I-Method
approaches	I-Method
,	O
including	O
a	O
1024d	O
gated	B-Method
recurrent	I-Method
unit	I-Method
(	O
GRU	B-Method
)-	O
based	O
RNN	O
with	O
“	O
	
skip	O
-	O
thought	O
”	O
	
pretraining	O
.	O
	
The	O
results	O
obtained	O
by	O
our	O
model	O
are	O
also	O
comparable	O
to	O
several	O
attention	B-Method
-	I-Method
based	I-Method
LSTMs	I-Method
,	O
which	O
are	O
more	O
computationally	O
intensive	O
than	O
ours	O
in	O
terms	O
of	O
complexity	B-Metric
order	I-Metric
.	O
	
subsection	O
:	O
Complexity	B-Metric
Concerns	I-Metric
	
For	O
most	O
sentence	B-Method
models	I-Method
including	O
TBCNN	B-Method
,	O
the	O
overall	B-Metric
complexity	I-Metric
is	O
at	O
least	O
.	O
	
However	O
,	O
an	O
efficient	O
matching	B-Method
approach	I-Method
is	O
still	O
important	O
,	O
especially	O
to	O
retrieval	B-Task
-	I-Task
and	I-Task
-	I-Task
reranking	I-Task
systems	I-Task
.	O
	
For	O
example	O
,	O
in	O
a	O
retrieval	B-Task
-	I-Task
based	I-Task
question	I-Task
-	I-Task
answering	I-Task
or	I-Task
conversation	I-Task
system	I-Task
,	O
we	O
can	O
largely	O
reduce	O
response	B-Metric
time	I-Metric
by	O
performing	O
sentence	B-Method
matching	I-Method
based	O
on	O
precomputed	O
candidates	O
’	O
embeddings	O
.	O
	
By	O
contrast	O
,	O
context	B-Method
-	I-Method
aware	I-Method
matching	I-Method
approaches	I-Method
as	O
described	O
in	O
Section	O
[	O
reference	O
]	O
involve	O
processing	O
each	O
candidate	O
given	O
a	O
new	O
user	O
-	O
issued	O
query	O
,	O
which	O
is	O
time	O
-	O
consuming	O
in	O
terms	O
of	O
most	O
industrial	B-Task
products	I-Task
.	O
	
In	O
our	O
experiments	O
,	O
the	O
matching	O
part	O
(	O
Figure	O
[	O
reference	O
]	O
b	O
)	O
counts	O
1.71	O
%	O
of	O
the	O
total	O
time	O
during	O
prediction	B-Task
(	O
single	O
-	O
CPU	O
,	O
C	O
++	O
implementation	O
)	O
,	O
showing	O
the	O
potential	O
applications	O
of	O
our	O
approach	O
in	O
efficient	O
retrieval	B-Task
of	I-Task
semantically	I-Task
related	I-Task
sentences	I-Task
.	O
	
section	O
:	O
Conclusion	O
	
In	O
this	O
paper	O
,	O
we	O
proposed	O
the	O
TBCNN	B-Method
-	I-Method
pair	I-Method
model	I-Method
for	O
natural	O
language	O
inference	B-Task
.	O
	
Our	O
model	O
relies	O
on	O
the	O
tree	B-Method
-	I-Method
based	I-Method
convolutional	I-Method
neural	I-Method
network	I-Method
(	O
TBCNN	B-Method
)	O
to	O
capture	O
sentence	O
-	O
level	O
semantics	O
;	O
then	O
two	O
sentences	O
’	O
information	O
is	O
combined	O
by	O
several	O
heuristics	O
including	O
concatenation	B-Method
,	O
element	B-Method
-	I-Method
wise	I-Method
product	I-Method
and	O
difference	O
.	O
	
Experimental	O
results	O
on	O
a	O
large	O
dataset	O
show	O
a	O
high	O
performance	O
of	O
our	O
TBCNN	B-Method
-	I-Method
pair	I-Method
model	I-Method
while	O
remaining	O
a	O
low	O
complexity	B-Metric
order	I-Metric
.	O
	
section	O
:	O
Acknowledgments	O
	
We	O
thank	O
all	O
anonymous	O
reviewers	O
for	O
their	O
constructive	O
comments	O
,	O
especially	O
those	O
on	O
complexity	O
issues	O
.	O
	
We	O
also	O
thank	O
Sam	O
Bowman	O
,	O
Edward	O
Grefenstette	O
,	O
and	O
Tim	O
Rocktäschel	O
for	O
their	O
discussion	O
.	O
	
This	O
research	O
was	O
supported	O
by	O
the	O
National	O
Basic	O
Research	O
Program	O
of	O
China	O
(	O
the	O
973	O
Program	O
)	O
under	O
Grant	O
No	O
.	O
2015CB352201	O
and	O
the	O
National	O
Natural	O
Science	O
Foundation	O
of	O
China	O
under	O
Grant	O
Nos	O
.	O
	
61232015	O
,	O
61421091	O
,	O
and	O
61502014	O
.	O
	
bibliography	O
:	O
References	O
	
document	O
:	O
Grounded	B-Task
Textual	I-Task
Entailment	I-Task
	
Capturing	B-Task
semantic	I-Task
relations	I-Task
between	I-Task
sentences	I-Task
,	O
such	O
as	O
entailment	O
,	O
is	O
a	O
long	O
-	O
standing	O
challenge	O
for	O
computational	B-Task
semantics	I-Task
.	O
	
Logic	B-Method
-	I-Method
based	I-Method
models	I-Method
analyse	O
entailment	O
in	O
terms	O
of	O
possible	O
worlds	O
(	O
interpretations	O
,	O
or	O
situations	O
)	O
where	O
a	O
premise	O
P	O
entails	O
a	O
hypothesis	O
H	O
iff	O
in	O
all	O
worlds	O
where	O
P	O
is	O
true	O
,	O
H	O
is	O
also	O
true	O
.	O
	
Statistical	B-Method
models	I-Method
view	O
this	O
relationship	O
probabilistically	O
,	O
addressing	O
it	O
in	O
terms	O
of	O
whether	O
a	O
human	O
would	O
likely	O
infer	O
H	O
from	O
P.	O
	
In	O
this	O
paper	O
,	O
we	O
wish	O
to	O
bridge	O
these	O
two	O
perspectives	O
,	O
by	O
arguing	O
for	O
a	O
visually	B-Method
-	I-Method
grounded	I-Method
version	I-Method
of	O
the	O
Textual	B-Task
Entailment	I-Task
task	I-Task
.	O
	
Specifically	O
,	O
we	O
ask	O
whether	O
models	O
can	O
perform	O
better	O
if	O
,	O
in	O
addition	O
to	O
P	O
and	O
H	O
,	O
there	O
is	O
also	O
an	O
image	O
(	O
corresponding	O
to	O
the	O
relevant	O
“	O
world	O
”	O
or	O
“	O
situation	O
”	O
)	O
.	O
	
We	O
use	O
a	O
multimodal	B-Method
version	I-Method
of	O
the	O
SNLI	O
dataset	O
and	O
we	O
compare	O
“	O
blind	O
”	O
and	O
visually	B-Method
-	I-Method
augmented	I-Method
models	I-Method
of	O
textual	B-Task
entailment	I-Task
.	O
	
We	O
show	O
that	O
visual	O
information	O
is	O
beneficial	O
,	O
but	O
we	O
also	O
conduct	O
an	O
in	O
-	O
depth	B-Task
error	I-Task
analysis	I-Task
that	O
reveals	O
that	O
current	O
multimodal	B-Method
models	I-Method
are	O
not	O
performing	O
“	O
grounding	O
”	O
in	O
an	O
optimal	O
fashion	O
.	O
	
section	O
:	O
Introduction	O
	
Correspondence	O
should	O
be	O
addressed	O
to	O
Raffaella	O
Bernardi	O
(	O
raffaella.bernardi@unitn.it	O
)	O
and	O
Albert	O
Gatt	O
(	O
albert.gatt@um.edu.mt	O
)	O
.	O
	
This	O
work	O
is	O
licensed	O
under	O
a	O
Creative	O
Commons	O
Attribution	O
4.0	O
International	O
License	O
.	O
	
License	O
details	O
:	O
.	O
	
The	O
dataset	O
,	O
annotation	O
and	O
code	O
is	O
available	O
from	O
.	O
	
Evaluating	O
the	O
ability	O
to	O
infer	O
information	O
from	O
a	O
text	O
is	O
a	O
crucial	O
test	O
of	O
the	O
capability	O
of	O
models	O
to	O
grasp	O
meaning	O
.	O
	
As	O
a	O
result	O
,	O
the	O
computational	B-Task
linguistics	I-Task
community	I-Task
has	O
invested	O
huge	O
efforts	O
into	O
developing	O
textual	O
entailment	O
(	O
TE	B-Task
)	O
datasets	O
.	O
	
After	O
formal	O
semanticists	O
developed	O
FraCas	O
in	O
the	O
mid	O
’	O
90	O
,	O
an	O
increase	O
in	O
statistical	B-Method
approaches	I-Method
to	O
computational	B-Task
semantics	I-Task
gave	O
rise	O
to	O
the	O
need	O
for	O
suitable	O
evaluation	O
datasets	O
.	O
	
Hence	O
,	O
Recognizing	B-Task
Textual	I-Task
Entailment	I-Task
(	I-Task
RTE	I-Task
)	I-Task
shared	I-Task
tasks	I-Task
have	O
been	O
organized	O
regularly	O
.	O
	
Recent	O
work	O
on	O
compositional	B-Method
distributional	I-Method
models	I-Method
has	O
motivated	O
the	O
development	O
of	O
the	O
SICK	O
dataset	O
of	O
sentence	O
pairs	O
in	O
entailment	O
relations	O
for	O
evaluating	O
such	O
models	O
.	O
	
Further	O
advances	O
with	O
Neural	B-Method
Networks	I-Method
(	O
NNs	B-Method
)	O
have	O
once	O
more	O
motivated	O
efforts	O
to	O
develop	O
a	O
large	O
natural	B-Task
language	I-Task
inference	I-Task
dataset	O
,	O
SNLI	O
,	O
since	O
NNs	B-Method
need	O
to	O
be	O
trained	O
on	O
big	O
data	O
.	O
	
However	O
,	O
meaning	O
is	O
not	O
something	O
we	O
obtain	O
just	O
from	O
text	O
and	O
the	O
ability	O
to	O
reason	O
is	O
not	O
unimodal	O
either	O
.	O
	
The	O
importance	O
of	O
enriching	O
meaning	B-Task
representations	I-Task
with	O
other	O
modalities	O
has	O
been	O
advocated	O
by	O
cognitive	O
scientists	O
,	O
(	O
e.g.	O
,	O
)	O
and	O
computational	B-Task
linguists	I-Task
(	O
e.g.	O
,	O
)	O
.	O
	
While	O
efforts	O
have	O
been	O
put	O
into	O
developing	O
multimodal	O
datasets	O
for	O
the	O
task	O
of	O
checking	B-Task
Semantic	I-Task
Text	I-Task
Similarity	I-Task
Text	I-Task
,	O
we	O
are	O
not	O
aware	O
of	O
any	O
available	O
datasets	O
to	O
tackle	O
the	O
problem	O
of	O
Grounded	B-Task
Textual	I-Task
Entailment	I-Task
(	O
GTE	B-Task
)	O
.	O
	
Our	O
paper	O
is	O
a	O
first	O
effort	O
in	O
this	O
direction	O
.	O
	
[	O
b	O
]	O
0.45	O
[	O
scale=0.5	O
]	O
figures	O
/	O
warm	O
-	O
entailment	O
	
[	O
b	O
]	O
0.45	O
[	O
scale=0.5	O
]	O
figures	O
/	O
neutral	O
-	O
mis	O
Textual	O
Entailment	O
is	O
defined	O
in	O
terms	O
of	O
the	O
likelihood	O
of	O
two	O
sentences	O
(	O
a	O
premise	O
P	O
and	O
an	O
hypothesis	O
H	O
)	O
to	O
be	O
in	O
a	O
certain	O
relation	O
:	O
P	O
entails	O
,	O
contradicts	O
or	O
is	O
unrelated	O
to	O
H.	O
	
For	O
instance	O
,	O
the	O
premise	O
“	O
People	O
trying	O
to	O
get	O
warm	O
in	O
front	O
of	O
a	O
chimney	O
”	O
and	O
the	O
hypothesis	O
“	O
People	O
trying	O
to	O
get	O
warm	O
at	O
home	O
”	O
are	O
highly	O
likely	O
to	O
be	O
in	O
an	O
entailment	O
relation	O
.	O
	
Our	O
question	O
is	O
whether	O
having	O
an	O
image	O
that	O
illustrates	O
the	O
event	O
(	O
e.g.	O
,	O
Figure	O
[	O
reference	O
]	O
)	O
can	O
help	O
a	O
model	O
to	O
capture	O
the	O
relation	O
.	O
	
In	O
order	O
to	O
answer	O
this	O
question	O
,	O
we	O
augment	O
the	O
largest	O
available	O
TE	B-Task
dataset	O
with	O
images	O
,	O
we	O
enhance	O
a	O
state	O
of	O
the	O
art	O
model	O
of	O
textual	B-Task
entailment	I-Task
to	O
take	O
images	O
into	O
account	O
and	O
we	O
evaluate	O
it	O
against	O
the	O
GTE	B-Task
task	I-Task
.	O
	
The	O
inclusion	O
of	O
images	O
can	O
also	O
alter	O
relations	O
which	O
,	O
based	O
on	O
text	O
alone	O
,	O
would	O
seem	O
likely	O
.	O
	
For	O
example	O
,	O
to	O
a	O
“	O
blind	O
”	O
model	O
the	O
sentences	O
of	O
the	O
sentence	O
pair	O
in	O
Figure	O
[	O
reference	O
]	O
would	O
seem	O
to	O
be	O
unrelated	O
,	O
but	O
when	O
the	O
two	O
sentences	O
are	O
viewed	O
in	O
the	O
context	O
of	O
the	O
image	O
,	O
they	O
do	O
become	O
related	O
.	O
	
A	O
suitable	O
GTE	B-Method
model	I-Method
therefore	O
has	O
to	O
perform	O
two	O
sub	B-Task
-	I-Task
tasks	I-Task
:	O
(	O
a	O
)	O
it	O
needs	O
to	O
ground	O
its	O
linguistic	B-Method
representations	I-Method
of	O
P	O
,	O
H	O
or	O
both	O
in	O
non	O
-	O
linguistic	O
(	O
visual	O
)	O
data	O
;	O
(	O
b	O
)	O
it	O
needs	O
to	O
reason	O
about	O
the	O
possible	O
relationship	O
between	O
P	O
and	O
H	O
(	O
modulo	O
the	O
visual	O
information	O
)	O
.	O
	
section	O
:	O
Related	O
Work	O
	
Grounding	B-Task
language	I-Task
through	O
vision	O
has	O
recently	O
become	O
the	O
focus	O
of	O
several	O
tasks	O
,	O
including	O
Image	B-Task
Captioning	I-Task
(	O
IC	B-Task
,	O
e.g.	O
)	O
and	O
Visual	B-Task
Question	I-Task
Answering	I-Task
(	O
VQA	B-Task
,	O
eg	O
.	O
)	O
,	O
and	O
even	O
more	O
recently	O
,	O
Visual	B-Task
Reasoning	I-Task
and	O
Visual	B-Task
Dialog	I-Task
.	O
	
Our	O
focus	O
is	O
on	O
Grounded	B-Task
Textual	I-Task
Entailment	I-Task
(	O
GTE	B-Task
)	O
.	O
	
While	O
the	O
literature	O
on	O
TE	B-Task
is	O
rather	O
vast	O
,	O
GTE	B-Method
is	O
still	O
rather	O
unexplored	O
territory	O
.	O
	
paragraph	O
:	O
Textual	B-Task
Entailment	I-Task
	
Throughout	O
the	O
history	O
of	O
Computational	O
Linguistics	O
various	O
datasets	O
have	O
been	O
built	O
to	O
evaluate	O
Computational	B-Method
Semantics	I-Method
models	I-Method
on	O
the	O
TE	B-Task
task	O
.	O
	
Usually	O
they	O
contain	O
data	O
divided	O
into	O
entailment	O
,	O
contradiction	O
or	O
unknown	O
classes	O
.	O
	
The	O
“	O
unknown	O
”	O
label	O
has	O
sometimes	O
been	O
replaced	O
with	O
the	O
“	O
unrelated	O
”	O
or	O
“	O
neutral	O
”	O
label	O
,	O
capturing	O
slightly	O
different	O
types	O
of	O
phenomena	O
.	O
	
Interestingly	O
,	O
the	O
“	O
entailment	O
”	O
and	O
“	O
contradiction	O
”	O
classes	O
also	O
differ	O
across	O
datasets	O
.	O
	
In	O
the	O
mid	O
-	O
’90s	O
a	O
group	O
of	O
formal	B-Method
semanticists	I-Method
developed	O
FraCaS	B-Method
	
(	O
Framework	O
for	O
Computational	B-Task
Semantics	I-Task
)	O
.	O
	
The	O
dataset	O
contains	O
logical	B-Task
entailment	I-Task
problems	I-Task
in	O
which	O
a	O
conclusion	O
has	O
to	O
be	O
derived	O
from	O
one	O
or	O
more	O
premises	O
(	O
but	O
not	O
necessarily	O
all	O
premises	O
are	O
needed	O
to	O
verify	O
the	O
entailment	O
)	O
.	O
	
The	O
entailments	O
are	O
driven	O
by	O
logical	O
properties	O
of	O
linguistic	O
expressions	O
,	O
like	O
the	O
monotonicity	O
of	O
quantifiers	O
,	O
or	O
their	O
conservativity	O
property	O
etc	O
.	O
	
Hence	O
,	O
the	O
set	O
of	O
premises	O
entails	O
the	O
conclusion	O
iff	O
in	O
all	O
the	O
interpretations	O
(	O
worlds	O
)	O
in	O
which	O
the	O
premises	O
are	O
true	O
the	O
conclusion	O
is	O
also	O
true	O
;	O
otherwise	O
the	O
conclusion	O
contradicts	O
the	O
premises	O
.	O
	
In	O
2005	O
,	O
the	O
PASCAL	B-Task
RTE	I-Task
(	O
Recognizing	B-Task
Textual	I-Task
Entailment	I-Task
)	O
challenge	O
was	O
launched	O
,	O
to	O
become	O
a	O
task	O
organized	O
annually	O
.	O
	
In	O
2008	O
,	O
the	O
RTE	B-Method
-	I-Method
4	I-Method
committee	I-Method
made	O
the	O
task	O
more	O
fine	O
-	O
grained	O
by	O
requiring	O
the	O
classification	B-Task
of	O
the	O
pairs	O
as	O
“	O
entailment	O
”	O
,	O
“	O
contradiction	O
”	O
and	O
“	O
unknown	O
”	O
.	O
	
The	O
RTE	O
datasets	O
,	O
unlike	O
FraCaS	B-Method
,	O
contain	O
real	O
-	O
life	O
natural	O
language	O
sentences	O
and	O
the	O
sort	O
of	O
entailment	B-Task
problems	I-Task
which	O
occur	O
in	O
corpora	O
collected	O
from	O
the	O
web	O
.	O
	
Importantly	O
,	O
the	O
sentence	O
pair	O
relations	O
are	O
annotated	O
as	O
entailment	O
,	O
contradiction	O
or	O
neutral	O
based	O
on	O
a	O
likelihood	O
condition	O
:	O
if	O
a	O
human	O
reading	O
the	O
premise	O
would	O
typically	O
infer	O
that	O
the	O
conclusion	O
(	O
called	O
the	O
hypothesis	O
)	O
is	O
most	O
likely	O
true	O
(	O
entailment	O
)	O
,	O
its	O
negation	O
is	O
most	O
likely	O
true	O
(	O
contradiction	O
)	O
or	O
the	O
conclusion	O
can	O
be	O
either	O
true	O
or	O
false	O
(	O
neutral	O
)	O
.	O
	
At	O
SemEval	O
2014	O
,	O
in	O
order	O
to	O
evaluate	O
Compositional	B-Method
Distributional	I-Method
Semantics	I-Method
Models	I-Method
focusing	O
on	O
the	O
compositionality	O
ability	O
of	O
those	O
models	O
,	O
the	O
SICK	O
dataset	O
(	O
Sentences	O
Involving	O
Compositional	O
Knowledge	O
)	O
was	O
used	O
in	O
a	O
shared	B-Task
entailment	I-Task
task	I-Task
.	O
	
Sentence	O
pairs	O
were	O
obtained	O
through	O
re	O
-	O
writing	O
rules	O
and	O
annotated	O
with	O
the	O
three	O
RTE	O
labels	O
via	O
a	O
crowdsourcing	B-Method
platform	I-Method
.	O
	
Both	O
in	O
RTE	O
and	O
SICK	O
the	O
label	O
assigned	O
to	O
the	O
sentence	O
pairs	O
captures	O
the	O
relation	O
holding	O
between	O
the	O
two	O
sentences	O
.	O
	
A	O
different	O
approach	O
has	O
been	O
used	O
to	O
build	O
the	O
much	O
larger	O
SNLI	O
(	O
Stanford	O
Natural	O
Language	O
Inference	O
)	O
	
dataset	O
:	O
Premises	O
are	O
taken	O
from	O
a	O
dataset	O
of	O
images	O
annotated	O
with	O
descriptive	O
captions	O
;	O
the	O
corresponding	O
hypotheses	O
were	O
produced	O
through	O
crowdsourcing	B-Method
,	O
where	O
for	O
a	O
given	O
premise	O
,	O
annotators	O
provided	O
a	O
sentence	O
which	O
is	O
true	O
or	O
not	O
true	O
with	O
respect	O
to	O
a	O
possible	O
image	O
which	O
the	O
premise	O
could	O
describe	O
.	O
	
A	O
consequence	O
of	O
this	O
choice	O
is	O
that	O
the	O
contradiction	O
relation	O
can	O
be	O
assigned	O
to	O
pairs	O
which	O
are	O
rather	O
unrelated	O
	
(	O
“	O
A	O
person	O
in	O
a	O
black	O
wetsuit	O
is	O
surfing	O
a	O
small	O
wave	O
”	O
and	O
“	O
	
A	O
woman	O
is	O
trying	O
to	O
sleep	O
on	O
her	O
bed	O
”	O
)	O
,	O
differently	O
from	O
what	O
happens	O
in	O
RTE	O
and	O
SICK	O
.	O
	
Since	O
the	O
inception	O
of	O
RTE	B-Task
shared	I-Task
tasks	I-Task
,	O
there	O
has	O
been	O
an	O
increasing	O
emphasis	O
on	O
data	B-Method
-	I-Method
driven	I-Method
approaches	I-Method
which	O
,	O
given	O
the	O
hypothesis	O
H	O
and	O
premise	O
P	O
,	O
seek	O
to	O
classify	O
the	O
semantic	O
relation	O
(	O
see	O
for	O
a	O
review	O
)	O
.	O
	
More	O
recently	O
,	O
neural	B-Method
approaches	I-Method
have	O
come	O
to	O
dominate	O
the	O
scene	O
,	O
as	O
shown	O
by	O
the	O
recent	O
RepEval	O
2017	O
task	O
,	O
where	O
all	O
submissions	O
relied	O
on	O
bidirectional	B-Method
LSTM	I-Method
models	I-Method
,	O
with	O
or	O
without	O
pretrained	O
embeddings	O
.	O
	
RTE	B-Method
also	O
intersects	O
with	O
a	O
number	O
of	O
related	O
inference	B-Task
problems	I-Task
,	O
including	O
semantic	B-Task
text	I-Task
similarity	I-Task
and	O
Question	B-Task
Answering	I-Task
,	O
and	O
some	O
models	O
have	O
been	O
proposed	O
to	O
address	O
several	O
such	O
problems	O
.	O
	
In	O
one	O
popular	O
approach	O
,	O
both	O
P	O
and	O
H	O
are	O
encoded	O
within	O
the	O
same	O
embedding	O
space	O
,	O
using	O
a	O
single	O
RNN	B-Method
,	O
with	O
a	O
decision	O
made	O
based	O
on	O
the	O
encodings	O
of	O
the	O
two	O
sentences	O
.	O
	
This	O
is	O
the	O
approach	O
we	O
adopt	O
for	O
our	O
baseline	B-Method
LSTM	I-Method
in	O
Section	O
[	O
reference	O
]	O
,	O
based	O
on	O
the	O
model	O
proposed	O
by	O
snli	B-Method
:	O
	
emnlp2015	O
,	O
albeit	O
with	O
some	O
modifications	O
(	O
see	O
also	O
)	O
.	O
	
A	O
second	O
promising	O
approach	O
,	O
based	O
on	O
which	O
we	O
adapt	O
our	O
state	O
of	O
the	O
art	O
model	O
,	O
relies	O
on	O
matching	B-Method
and	I-Method
aggregation	I-Method
.	O
	
Here	O
,	O
the	O
decision	O
concerning	O
the	O
relationship	O
between	O
P	O
and	O
H	O
is	O
based	O
on	O
an	O
aggregate	B-Method
representation	I-Method
achieved	O
after	O
the	O
two	O
sentences	O
are	O
matched	O
.	O
	
Yet	O
another	O
area	O
where	O
neural	B-Method
approaches	I-Method
are	O
being	O
applied	O
to	O
sentence	B-Task
pairs	I-Task
in	O
an	O
entailment	B-Task
relationship	I-Task
is	O
generation	B-Task
,	O
where	O
an	O
RNN	B-Method
generates	O
an	O
entailed	O
hypothesis	O
(	O
or	O
a	O
chain	O
of	O
such	O
hypotheses	O
)	O
given	O
an	O
encoding	O
of	O
the	O
premise	O
.	O
	
paragraph	O
:	O
Vision	B-Task
and	O
Textual	B-Task
Entailment	I-Task
	
In	O
recent	O
years	O
,	O
several	O
models	O
have	O
been	O
proposed	O
to	O
integrate	O
the	O
language	O
and	O
vision	O
modalities	O
;	O
usually	O
the	O
integration	O
is	O
operationalized	O
by	O
element	B-Method
-	I-Method
wise	I-Method
multiplication	I-Method
between	O
linguistic	O
and	O
visual	O
vectors	O
.	O
	
Though	O
the	O
interest	O
in	O
these	O
modalities	O
has	O
spread	O
in	O
an	O
astonishing	O
way	O
thanks	O
to	O
various	O
multimodal	B-Task
tasks	I-Task
proposed	O
,	O
including	O
the	O
IC	B-Task
,	O
VQA	B-Task
,	O
Visual	B-Task
Reasoning	I-Task
and	O
Visual	B-Task
Dialogue	I-Task
tasks	I-Task
mentioned	O
above	O
,	O
very	O
little	O
work	O
has	O
been	O
done	O
on	O
grounding	B-Task
entailment	I-Task
.	O
	
Interestingly	O
,	O
youn	O
:	O
	
from14	O
has	O
proposed	O
the	O
idea	O
of	O
considering	O
images	O
as	O
the	O
“	O
possible	O
worlds	O
”	O
on	O
which	O
sentences	O
find	O
their	O
denotation	O
.	O
	
Hence	O
,	O
they	O
released	O
a	O
“	O
visual	B-Method
denotation	I-Method
graph	I-Method
”	O
which	O
associates	O
sentences	O
with	O
their	O
denotation	O
(	O
sets	O
of	O
images	O
)	O
.	O
	
The	O
idea	O
has	O
been	O
further	O
exploited	O
by	O
lai	O
:	O
lear17	O
and	O
han	O
:	O
visd17	O
.	O
	
vend	O
:	O
	
orde16	O
look	O
at	O
hypernymy	O
,	O
textual	B-Task
entailment	I-Task
and	O
image	B-Task
captioning	I-Task
as	O
special	O
cases	O
of	O
a	O
single	O
visual	O
-	O
semantic	O
hierarchy	O
over	O
words	O
,	O
sentences	O
and	O
images	O
,	O
and	O
they	O
claim	O
that	O
modelling	O
the	O
partial	O
order	O
structure	O
of	O
this	O
hierarchy	O
in	O
visual	O
and	O
linguistic	O
semantic	O
spaces	O
improves	O
model	O
performance	O
on	O
those	O
three	O
tasks	O
.	O
	
We	O
share	O
with	O
this	O
work	O
the	O
idea	O
that	O
the	O
image	O
can	O
be	O
taken	O
as	O
a	O
possible	O
world	O
.	O
	
However	O
,	O
we	O
do	O
	
n’t	O
use	O
sets	O
of	O
images	O
to	O
obtain	O
the	O
visual	O
denotation	O
of	O
text	O
in	O
order	O
to	O
check	O
whether	O
entailment	O
is	O
logically	O
valid	O
/	O
highly	O
likely	O
.	O
	
Rather	O
,	O
we	O
take	O
the	O
image	O
to	O
be	O
the	O
world	O
/	O
situation	O
in	O
which	O
the	O
text	O
finds	O
its	O
interpretation	O
.	O
	
The	O
only	O
work	O
that	O
is	O
close	O
to	O
ours	O
is	O
an	O
unpublished	O
student	O
report	O
,	O
which	O
however	O
lacks	O
the	O
in	O
-	O
depth	O
analysis	O
presented	O
here	O
.	O
	
section	O
:	O
Annotated	O
dataset	O
of	O
images	O
and	O
sentence	O
pairs	O
	
We	O
took	O
as	O
our	O
starting	O
point	O
the	O
Stanford	O
Natural	O
Language	O
Inference	O
(	O
SNLI	O
)	O
dataset	O
,	O
the	O
largest	O
natural	B-Task
language	I-Task
inference	I-Task
dataset	O
available	O
with	O
sentence	O
pairs	O
labelled	O
with	O
entailment	O
,	O
contradiction	O
and	O
neutral	O
relations	O
.	O
	
We	O
augmented	O
this	O
dataset	O
with	O
images	O
.	O
	
It	O
has	O
been	O
shown	O
very	O
recently	O
that	O
SNLI	O
contains	O
language	O
bias	O
,	O
such	O
that	O
a	O
simple	O
classifier	B-Method
can	O
achieve	O
high	O
accuracy	B-Metric
in	O
predicting	O
the	O
three	O
classes	O
just	O
by	O
having	O
as	O
input	O
the	O
hypothesis	O
sentence	O
.	O
	
A	O
subset	O
of	O
the	O
SNLI	O
test	O
set	O
with	O
‘	O
hard	O
’	O
cases	O
,	O
where	O
such	O
a	O
simplistic	B-Method
classifier	I-Method
fails	O
(	O
hereafter	O
SNLI	O
)	O
has	O
been	O
released	O
.	O
	
Hence	O
,	O
in	O
this	O
paper	O
we	O
will	O
report	O
our	O
results	O
on	O
both	O
the	O
full	O
dataset	O
and	O
the	O
hard	O
test	O
set	O
,	O
but	O
then	O
zoom	O
in	O
on	O
SNLI	O
to	O
understand	O
the	O
models	O
’	O
behaviour	O
.	O
	
We	O
briefly	O
introduce	O
SNLI	O
and	O
the	O
new	O
test	O
set	O
and	O
compare	O
them	O
through	O
our	O
annotation	B-Task
of	I-Task
linguistic	I-Task
phenomena	I-Task
.	O
	
subsection	O
:	O
Dataset	O
construction	O
	
paragraph	O
:	O
SNLI	O
and	O
SNLI	O
test	O
set	O
	
The	O
SNLI	O
dataset	O
was	O
built	O
through	O
Amazon	O
Mechanical	O
Turk	O
.	O
	
Workers	O
were	O
shown	O
captions	O
of	O
photographs	O
without	O
the	O
photo	O
and	O
were	O
asked	O
to	O
write	O
a	O
new	O
caption	O
that	O
(	O
a	O
)	O
is	O
definitely	O
a	O
true	O
description	O
of	O
the	O
photo	O
(	O
entailment	O
)	O
;	O
(	O
b	O
)	O
might	O
be	O
a	O
true	O
description	O
of	O
the	O
photo	O
(	O
neutral	O
)	O
;	O
(	O
c	O
)	O
is	O
definitely	O
a	O
false	O
description	O
of	O
the	O
photo	O
(	O
contradiction	O
)	O
.	O
	
Examples	O
were	O
provided	O
for	O
each	O
of	O
the	O
three	O
cases	O
.	O
	
The	O
premises	O
are	O
captions	O
which	O
come	O
mostly	O
from	O
Flickr30	O
K	O
;	O
only	O
4	O
K	O
captions	O
are	O
from	O
VisualGenome	O
.	O
	
In	O
total	O
,	O
the	O
dataset	O
contains	O
570	O
,	O
152	O
sentence	O
pairs	O
,	O
balanced	O
with	O
respect	O
to	O
the	O
three	O
labels	O
.	O
	
Around	O
10	O
%	O
of	O
these	O
data	O
have	O
been	O
validated	O
(	O
4	O
annotators	O
for	O
each	O
example	O
plus	O
the	O
label	O
assigned	O
through	O
the	O
previous	O
data	O
collection	O
phase	O
)	O
.	O
	
The	O
development	O
and	O
test	O
datasets	O
contain	O
10	O
K	O
examples	O
each	O
.	O
	
Moreover	O
,	O
each	O
Image	O
/	O
Flickr	O
caption	O
occurs	O
in	O
only	O
one	O
of	O
the	O
three	O
sets	O
,	O
and	O
all	O
the	O
examples	O
in	O
the	O
development	O
and	O
test	O
sets	O
have	O
been	O
validated	O
.	O
	
paragraph	O
:	O
V	B-Material
-	I-Material
SNLI	I-Material
and	O
V	B-Material
-	I-Material
SNLI	I-Material
test	I-Material
set	O
	
Our	O
grounded	O
version	O
of	O
SNLI	O
,	O
V	B-Material
-	I-Material
SNLI	I-Material
,	O
has	O
been	O
built	O
by	O
matching	O
each	O
sentence	O
pair	O
in	O
SNLI	O
with	O
the	O
corresponding	O
image	O
coming	O
from	O
the	O
Flickr30	O
K	O
dataset	O
;	O
thus	O
the	O
V	B-Material
-	I-Material
SNLI	I-Material
dataset	I-Material
is	O
slightly	O
smaller	O
than	O
the	O
original	O
,	O
which	O
also	O
contains	O
captions	O
from	O
VisualGenome	O
.	O
	
V	B-Material
-	I-Material
SNLI	I-Material
consists	O
of	O
565	O
,	O
286	O
pairs	O
(	O
187	O
,	O
969	O
neutral	O
,	O
188	O
,	O
453	O
contradiction	O
,	O
and	O
188	O
,	O
864	O
entailment	O
)	O
.	O
	
Training	O
,	O
test	O
,	O
and	O
development	O
splits	O
have	O
been	O
built	O
according	O
to	O
the	O
splits	O
in	O
SNLI	O
.	O
	
The	O
main	O
statistics	O
of	O
the	O
splits	O
of	O
the	O
dataset	O
are	O
reported	O
in	O
Table	O
[	O
reference	O
]	O
together	O
with	O
statistics	O
for	O
the	O
visual	B-Method
counterpart	I-Method
of	O
Hard	O
SNLI	O
,	O
namely	O
V	B-Material
-	I-Material
SNLI	I-Material
.	O
	
By	O
construction	O
,	O
V	B-Material
-	I-Material
SNLI	I-Material
contains	O
datapoints	O
such	O
that	O
the	O
premise	O
is	O
always	O
true	O
with	O
respect	O
to	O
the	O
image	O
,	O
whereas	O
the	O
hypothesis	O
can	O
be	O
either	O
true	O
(	O
entailment	O
or	O
neutral	O
cases	O
)	O
or	O
false	O
(	O
contradiction	O
or	O
neutral	O
cases	O
.	O
)	O
	
subsection	O
:	O
Dataset	O
annotation	O
	
For	O
deeper	O
analysis	O
and	O
comparison	O
of	O
the	O
contents	O
of	O
SNLI	O
and	O
SNLI	O
,	O
we	O
have	O
annotated	O
the	O
SNLI	O
dataset	O
by	O
both	O
automatically	O
detecting	O
some	O
surface	O
linguistic	O
cues	O
and	O
manually	O
labelling	O
less	O
trivial	O
phenomena	O
.	O
	
Using	O
an	O
in	O
-	O
house	O
annotation	O
interface	O
,	O
we	O
collected	O
human	O
judgments	O
aiming	O
to	O
(	O
a	O
)	O
filter	O
out	O
those	O
cases	O
for	O
which	O
the	O
gold	O
-	O
standard	O
annotation	O
was	O
considered	O
to	O
be	O
wrong	O
;	O
(	O
b	O
)	O
connect	O
the	O
three	O
ungrounded	O
relations	O
to	O
various	O
linguistic	O
phenomena	O
.	O
	
To	O
achieve	O
this	O
,	O
we	O
annotated	O
a	O
random	O
sample	O
of	O
the	O
SNLI	O
test	O
set	O
containing	O
527	O
sentence	O
pairs	O
(	O
185	O
entailment	O
,	O
171	O
contradiction	O
,	O
171	O
neutral	O
)	O
,	O
out	O
of	O
which	O
176	O
were	O
from	O
the	O
hard	O
test	O
set	O
(	O
56	O
entailment	O
,	O
62	O
contradiction	O
,	O
58	O
neutral	O
)	O
.	O
	
All	O
the	O
pairs	O
were	O
annotated	O
by	O
at	O
least	O
two	O
annotators	O
,	O
as	O
follows	O
:	O
(	O
a	O
)	O
We	O
filtered	O
out	O
all	O
the	O
pairs	O
which	O
had	O
a	O
wrong	O
gold	O
label	O
(	O
see	O
Table	O
[	O
reference	O
]	O
for	O
details	O
)	O
.	O
	
When	O
our	O
annotators	O
did	O
not	O
agree	O
whether	O
a	O
given	O
relation	O
holds	O
for	O
a	O
specific	O
pair	O
,	O
we	O
appealed	O
to	O
the	O
corresponding	O
five	O
judgments	O
coming	O
from	O
the	O
validation	O
stage	O
of	O
the	O
SNLI	O
dataset	O
to	O
reach	O
a	O
consensus	O
based	O
on	O
the	O
majority	O
of	O
labels	O
.	O
	
(	O
b	O
)	O
We	O
considered	O
as	O
valid	O
any	O
linguistic	O
tag	O
assigned	O
by	O
at	O
least	O
one	O
annotator	O
.	O
	
Since	O
the	O
annotation	O
for	O
(	O
a	O
)	O
is	O
binary	O
whereas	O
for	O
(	O
b	O
)	O
it	O
is	O
multi	O
-	O
class	O
,	O
we	O
used	O
Cohen	O
’s	O
for	O
the	O
former	O
and	O
	
also	O
Scott	O
’s	O
and	O
Krippendorff	O
’s	O
for	O
the	O
latter	O
as	O
suggested	O
by	O
Passonneau	O
pass	O
:	O
	
inte06	O
.	O
	
The	O
inter	O
-	O
annotator	O
agreement	O
for	O
the	O
relation	O
type	O
(	O
a	O
)	O
was	O
;	O
for	O
(	O
b	O
)	O
linguistic	O
tags	O
it	O
was	O
,	O
,	O
and	O
.	O
	
paragraph	O
:	O
Linguistic	O
phenomena	O
	
Following	O
the	O
error	B-Method
analysis	I-Method
approach	I-Method
described	O
in	O
recent	O
work	O
,	O
we	O
compiled	O
a	O
new	O
list	O
of	O
linguistic	O
features	O
that	O
can	O
be	O
of	O
interest	O
when	O
contrasting	O
SNLI	O
and	O
SNLI	O
,	O
as	O
well	O
as	O
for	O
evaluating	O
RTE	B-Method
models	I-Method
.	O
	
Some	O
of	O
these	O
were	O
detected	O
automatically	O
,	O
while	O
others	O
were	O
assigned	O
manually	O
.	O
	
Automatic	O
tags	O
included	O
Synonym	O
and	O
Antonym	O
,	O
which	O
were	O
detected	O
using	O
WordNet	O
.	O
	
Quantifier	O
,	O
Pronoun	O
,	O
Diff	O
Tense	O
,	O
Superlative	O
and	O
Bare	O
NP	O
were	O
identified	O
using	O
Penn	O
treebank	O
labels	O
,	O
while	O
labels	O
such	O
as	O
Negation	O
were	O
found	O
with	O
a	O
straightforward	O
keyword	B-Method
search	I-Method
.	O
	
The	O
tag	O
Long	O
has	O
been	O
assigned	O
to	O
sentence	O
pairs	O
with	O
a	O
premise	O
containing	O
more	O
than	O
30	O
tokens	O
,	O
or	O
a	O
hypothesis	O
with	O
more	O
than	O
16	O
tokens	O
.	O
	
Details	O
about	O
the	O
tags	O
used	O
in	O
the	O
manual	B-Task
annotation	I-Task
are	O
presented	O
in	O
Table	O
[	O
reference	O
]	O
.	O
	
We	O
examined	O
the	O
differences	O
in	O
the	O
tags	O
distributions	O
between	O
the	O
SNLI	O
and	O
SNLI	O
test	O
sets	O
(	O
Table	O
[	O
reference	O
]	O
)	O
.	O
	
Interestingly	O
,	O
the	O
hard	O
sentence	O
pairs	O
from	O
our	O
random	O
sample	O
include	O
proportionately	O
more	O
antonyms	O
but	O
fewer	O
pronouns	O
,	O
as	O
well	O
as	O
examples	O
with	O
different	O
verb	O
tenses	O
in	O
the	O
premise	O
and	O
hypothesis	O
,	O
compared	O
to	O
the	O
full	O
test	O
set	O
.	O
	
Furthermore	O
,	O
SNLI	O
contains	O
a	O
significantly	O
larger	O
proportion	O
of	O
gold	O
-	O
standard	O
labels	O
which	O
become	O
wrong	O
when	O
the	O
image	O
is	O
factored	O
in	O
(	O
-	O
test	O
with	O
)	O
.	O
	
section	O
:	O
Models	O
	
In	O
this	O
section	O
,	O
we	O
describe	O
a	O
variety	O
of	O
models	O
that	O
were	O
compared	O
on	O
both	O
V	B-Material
-	I-Material
SNLI	I-Material
and	O
V	B-Material
-	I-Material
SNLI	I-Material
,	O
ranging	O
from	O
baseline	B-Method
models	I-Method
based	O
on	O
snli	O
:	O
emnlp2015	O
to	O
a	O
state	O
of	O
the	O
art	O
model	O
by	O
Wang2017	O
.	O
	
We	O
compare	O
the	O
original	O
‘	O
blind	O
’	O
version	O
of	O
a	O
model	O
with	O
a	O
visually	B-Method
-	I-Method
augmented	I-Method
counterpart	I-Method
.	O
	
In	O
what	O
follows	O
,	O
we	O
use	O
P	O
and	O
H	O
to	O
refer	O
to	O
a	O
premise	O
and	O
hypothesis	O
,	O
respectively	O
.	O
	
paragraph	O
:	O
LSTM	B-Method
baseline	I-Method
(	O
Blind	O
)	O
	
This	O
model	O
exploits	O
a	O
Recurrent	B-Method
Neural	I-Method
Network	I-Method
with	O
Long	B-Method
Short	I-Method
-	I-Method
Term	I-Method
Memory	I-Method
units	I-Method
to	O
encode	O
both	O
P	O
and	O
H	O
in	O
512D	O
vectors	O
.	O
	
The	O
two	O
vectors	O
are	O
then	O
concatenated	O
in	O
a	O
stack	O
of	O
three	O
512D	B-Method
layers	I-Method
having	O
a	O
ReLU	B-Method
activation	I-Method
function	I-Method
,	O
with	O
a	O
final	O
softmax	B-Method
layer	I-Method
to	O
classify	O
the	O
relation	O
between	O
the	O
two	O
sentences	O
as	O
entailment	O
,	O
contradiction	O
or	O
neutral	O
.	O
	
The	O
model	O
is	O
inspired	O
by	O
the	O
LSTM	B-Method
baseline	I-Method
proposed	O
by	O
snli	O
:	O
emnlp2015	O
.	O
	
The	O
model	O
exploits	O
the	O
300	O
,	O
000	O
most	O
frequent	O
pretrained	B-Method
GloVe	I-Method
embeddings	I-Method
and	O
improves	O
them	O
during	O
the	O
training	O
process	O
.	O
	
To	O
regularize	O
the	O
model	O
,	O
Dropout	B-Method
is	O
applied	O
to	O
the	O
inputs	O
and	O
outputs	O
of	O
the	O
recurrent	O
layers	O
and	O
to	O
the	O
ReLU	B-Method
fully	I-Method
connected	I-Method
layers	I-Method
with	O
a	O
keeping	O
probability	O
of	O
0.5	O
.	O
	
The	O
model	O
is	O
trained	O
using	O
the	O
Adam	B-Method
optimizer	I-Method
with	O
a	O
learning	B-Metric
rate	I-Metric
of	O
0.001	O
until	O
its	O
accuracy	B-Metric
on	O
the	O
development	O
set	O
drops	O
for	O
three	O
successive	O
iterations	O
.	O
	
paragraph	O
:	O
V	B-Material
-	I-Material
LSTM	I-Material
baseline	I-Material
	
The	O
LSTM	B-Method
model	I-Method
described	O
above	O
is	O
augmented	O
with	O
a	O
visual	B-Method
component	I-Method
following	O
a	O
standard	O
Visual	B-Method
Question	I-Method
Answering	I-Method
baseline	I-Method
model	I-Method
.	O
	
Following	O
initial	O
representation	O
of	O
P	O
and	O
H	O
in	O
512D	O
vectors	O
through	O
an	O
LSTM	B-Method
,	O
a	O
fully	B-Method
-	I-Method
connected	I-Method
layer	I-Method
projects	O
the	O
L2	O
-	O
normalized	O
4096D	O
image	O
vector	O
coming	O
from	O
the	O
penultimate	B-Method
layer	I-Method
of	O
a	O
VGGnet16	B-Method
Convolutional	I-Method
Neural	I-Method
Network	I-Method
to	O
a	O
reduced	O
512D	O
vector	O
.	O
	
A	O
fully	B-Method
-	I-Method
connected	I-Method
layer	I-Method
with	O
a	O
ReLU	O
activation	O
function	O
is	O
also	O
applied	O
to	O
P	O
and	O
H	O
to	O
obtain	O
two	O
512D	O
vectors	O
.	O
	
The	O
multimodal	B-Task
fusion	I-Task
between	O
the	O
text	O
and	O
the	O
image	O
is	O
obtained	O
by	O
performing	O
an	O
element	B-Method
-	I-Method
wise	I-Method
multiplication	I-Method
between	O
the	O
vector	B-Method
of	I-Method
the	I-Method
text	I-Method
representation	I-Method
and	O
the	O
reduced	O
vector	O
of	O
the	O
image	O
.	O
	
The	O
multimodal	B-Method
fusion	I-Method
is	O
performed	O
between	O
the	O
image	O
and	O
both	O
the	O
premise	O
and	O
the	O
hypothesis	O
,	O
resulting	O
in	O
two	O
multimodal	B-Method
representations	I-Method
.	O
	
The	O
relation	O
between	O
them	O
is	O
captured	O
as	O
in	O
the	O
model	O
described	O
above	O
.	O
	
This	O
model	O
uses	O
GloVe	B-Method
embeddings	I-Method
and	O
the	O
same	O
optimization	O
and	O
procedure	O
described	O
above	O
.	O
	
We	O
have	O
also	O
adapted	O
a	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
attention	B-Method
-	I-Method
based	I-Method
model	I-Method
for	O
IC	B-Task
and	O
VQA	B-Task
to	O
the	O
GTE	B-Task
task	I-Task
.	O
	
It	O
obtains	O
results	O
comparable	O
to	O
the	O
V	B-Material
-	I-Material
LSTM	I-Material
.	O
	
This	O
lack	O
of	O
improvement	O
might	O
be	O
due	O
to	O
the	O
need	O
of	O
further	O
parameter	B-Method
tuning	I-Method
.	O
	
We	O
report	O
the	O
details	O
of	O
our	O
implementation	O
and	O
its	O
results	O
in	O
the	O
Supplementary	O
Material	O
.	O
	
paragraph	O
:	O
BiMPM	B-Method
	
The	O
Bilateral	B-Method
Multi	I-Method
-	I-Method
Perspective	I-Method
Matching	I-Method
(	O
BiMPM	B-Method
)	O
model	O
obtains	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
performance	O
on	O
the	O
SNLI	O
dataset	O
,	O
achieving	O
a	O
maximum	O
accuracy	B-Metric
of	O
86.9	O
%	O
,	O
and	O
going	O
up	O
to	O
88.8	O
%	O
in	O
an	O
ensemble	B-Method
setup	I-Method
.	O
	
An	O
initial	O
embedding	B-Method
layer	I-Method
vectorises	O
words	O
in	O
P	O
and	O
H	O
using	O
pretrained	O
GLoVe	B-Method
embeddings	I-Method
,	O
and	O
passing	O
them	O
to	O
a	O
context	B-Method
representation	I-Method
layer	I-Method
,	O
which	O
uses	O
bidirectional	B-Method
LSTMs	I-Method
(	O
BiLSTMs	B-Method
)	O
to	O
encode	O
context	O
vectors	O
for	O
each	O
time	O
-	O
step	O
.	O
	
The	O
core	O
part	O
of	O
the	O
model	O
is	O
the	O
subsequent	O
matching	B-Method
layer	I-Method
,	O
where	O
each	O
contextual	O
embedding	O
or	O
time	O
-	O
step	O
of	O
P	O
is	O
matched	O
against	O
all	O
the	O
embeddings	O
of	O
H	O
,	O
and	O
vice	O
versa	O
.	O
	
The	O
output	O
of	O
this	O
layer	O
is	O
composed	O
of	O
two	O
sequences	O
of	O
matching	O
vectors	O
,	O
which	O
constitute	O
the	O
input	O
to	O
another	O
BiLSTM	B-Method
at	O
the	O
aggregation	B-Method
layer	I-Method
.	O
	
The	O
vectors	O
from	O
the	O
last	O
time	O
-	O
step	O
of	O
the	O
BiLSTM	B-Method
are	O
concatenated	O
into	O
a	O
fixed	O
-	O
length	O
vector	O
,	O
which	O
is	O
passed	O
to	O
the	O
final	O
prediction	B-Method
tier	I-Method
,	O
a	O
two	B-Method
-	I-Method
layer	I-Method
feed	I-Method
-	I-Method
forward	I-Method
network	I-Method
which	O
classifies	O
the	O
relation	O
between	O
P	O
and	O
H	O
via	O
softmax	B-Method
.	O
	
Matching	B-Task
is	O
performed	O
via	O
a	O
cosine	B-Method
operation	I-Method
,	O
which	O
yields	O
an	O
-	O
dimensional	O
vector	O
,	O
where	O
is	O
the	O
number	O
of	O
perspectives	O
.	O
	
Wang2017	O
experiment	O
with	O
four	O
different	O
matching	B-Method
strategies	I-Method
.	O
	
In	O
their	O
results	O
,	O
the	O
best	O
-	O
performing	O
version	O
of	O
the	O
BiMPM	B-Method
model	O
used	O
all	O
four	O
matching	B-Method
strategies	I-Method
.	O
	
We	O
adopt	O
this	O
version	O
of	O
the	O
model	O
in	O
what	O
follows	O
.	O
	
paragraph	O
:	O
V	O
-	O
BiMPM	B-Method
model	O
	
We	O
enhanced	O
BiMPM	B-Method
to	O
account	O
for	O
the	O
image	O
,	O
too	O
.	O
	
Our	O
version	O
of	O
this	O
model	O
is	O
referred	O
to	O
as	O
the	O
V	B-Method
-	I-Method
BiMPM	I-Method
.	O
	
Here	O
,	O
the	O
feature	O
vector	O
for	O
an	O
image	O
is	O
obtained	O
from	O
the	O
layer	O
before	O
the	O
fully	B-Method
-	I-Method
connected	I-Method
layer	I-Method
of	O
a	O
VGGnet	B-Method
-	I-Method
16	I-Method
.	O
	
This	O
results	O
in	O
a	O
tensor	O
,	O
which	O
we	O
consider	O
as	O
49	O
512	O
-	O
dimensional	O
vectors	O
.	O
	
The	O
same	O
matching	B-Method
operations	I-Method
are	O
performed	O
,	O
except	O
that	O
matching	B-Task
occurs	O
between	O
P	O
,	O
H	O
,	O
and	O
the	O
image	O
.	O
	
Since	O
the	O
textual	O
and	O
visual	O
vectors	O
have	O
different	O
dimensionality	O
and	O
belong	O
to	O
different	O
spaces	O
,	O
we	O
first	O
map	O
them	O
to	O
a	O
mutual	O
space	O
using	O
an	O
affine	B-Method
transformation	I-Method
.	O
	
We	O
match	O
textual	O
and	O
image	O
vectors	O
using	O
a	O
cosine	B-Method
operation	I-Method
,	O
as	O
before	O
.	O
	
Full	O
details	O
of	O
the	O
model	O
are	O
reported	O
in	O
the	O
Supplementary	O
Materials	O
for	O
this	O
paper	O
.	O
	
section	O
:	O
Experiments	O
and	O
Results	O
	
The	O
models	O
described	O
in	O
the	O
previous	O
sections	O
were	O
evaluated	O
on	O
both	O
(	O
V	B-Material
-)	I-Material
SNLI	I-Material
and	O
(	O
V	B-Material
-)	I-Material
SNLI	I-Material
.	O
	
For	O
the	O
visually	B-Method
-	I-Method
augmented	I-Method
models	I-Method
,	O
we	O
experimented	O
with	O
configurations	O
where	O
image	O
vectors	O
were	O
combined	O
with	O
both	O
P	O
and	O
H	O
(	O
namely	O
P	O
+	O
I	O
and	O
H	O
+	O
I	O
)	O
,	O
or	O
only	O
with	O
H	O
(	O
P	O
and	O
H	O
+	O
I	O
)	O
.	O
	
The	O
best	O
setting	O
was	O
invariably	O
the	O
one	O
where	O
only	O
H	O
was	O
grounded	O
;	O
hence	O
,	O
we	O
focus	O
on	O
these	O
results	O
in	O
what	O
follows	O
,	O
comparing	O
them	O
to	O
“	O
blind	B-Method
”	I-Method
models	I-Method
.	O
	
In	O
view	O
of	O
recent	O
results	O
suggesting	O
that	O
biases	O
in	O
SNLI	O
afford	O
a	O
high	O
accuracy	B-Metric
in	O
the	O
prediction	B-Task
task	I-Task
with	O
only	O
the	O
hypothesis	O
sentence	O
as	O
input	O
,	O
we	O
also	O
include	O
results	O
for	O
the	O
blind	B-Method
models	I-Method
without	O
the	O
premise	O
(	O
denoted	O
with	O
[	O
H	O
]	O
in	O
what	O
follows	O
)	O
.	O
	
Table	O
[	O
reference	O
]	O
shows	O
the	O
results	O
of	O
the	O
various	O
models	O
on	O
the	O
full	O
V	B-Material
-	I-Material
SNLI	I-Material
dataset	O
.	O
	
The	O
same	O
models	O
are	O
compared	O
in	O
Table	O
[	O
reference	O
]	O
on	O
V	B-Material
-	I-Material
SNLI	I-Material
.	O
	
First	O
,	O
note	O
that	O
the	O
LSTM	B-Method
[	I-Method
H	I-Method
]	I-Method
model	I-Method
evinces	O
a	O
drop	O
in	O
performance	O
compared	O
to	O
LSTM	B-Method
(	O
from	O
81.49	O
%	O
to	O
68.49	O
%	O
)	O
,	O
though	O
the	O
drop	O
is	O
much	O
greater	O
on	O
the	O
unbiased	B-Metric
SNLI	I-Metric
subset	I-Metric
(	O
from	O
60.99	O
to	O
25.57	O
%	O
)	O
.	O
	
This	O
confirms	O
the	O
results	O
reported	O
by	O
guru	O
:	O
anno18	O
and	O
justifies	O
our	O
additional	O
focus	O
on	O
this	O
subset	O
of	O
the	O
data	O
.	O
	
The	O
effect	O
of	O
grounding	O
in	O
these	O
models	O
is	O
less	O
clear	O
.	O
	
The	O
LSTM	B-Method
baseline	I-Method
performs	O
worse	O
when	O
it	O
is	O
visually	O
augmented	O
;	O
this	O
is	O
the	O
case	O
of	O
V	B-Material
-	I-Material
SNLI	I-Material
and	O
,	O
even	O
more	O
drastically	O
,	O
V	B-Material
-	I-Material
SNLI	I-Material
.	O
	
It	O
is	O
also	O
true	O
irrespective	O
of	O
the	O
relationship	O
type	O
.	O
	
On	O
the	O
other	O
hand	O
,	O
the	O
V	O
-	O
BiMPM	B-Method
model	O
improves	O
marginally	O
across	O
the	O
board	O
,	O
compared	O
to	O
BiMPM	B-Method
,	O
on	O
the	O
V	B-Material
-	I-Material
SNLI	I-Material
data	O
.	O
	
On	O
the	O
hard	O
subset	O
,	O
the	O
images	O
appear	O
to	O
hurt	O
performance	O
somewhat	O
in	O
the	O
case	O
of	O
contradiction	O
(	O
from	O
77.62	O
%	O
to	O
76.12	O
%	O
)	O
,	O
but	O
improve	O
it	O
by	O
a	O
substantial	O
margin	O
on	O
neutral	O
cases	O
(	O
from	O
59.36	O
%	O
to	O
63.67	O
%	O
)	O
.	O
	
The	O
neutral	O
case	O
is	O
the	O
hardest	O
for	O
all	O
models	O
,	O
with	O
the	O
possible	O
exception	O
of	O
LSTM	B-Method
[	O
H	O
]	O
on	O
the	O
full	O
dataset	O
.	O
	
Overall	O
,	O
the	O
results	O
suggest	O
that	O
factoring	O
in	O
images	O
either	O
hinders	O
performance	O
(	O
as	O
in	O
the	O
case	O
of	O
the	O
V	B-Material
-	I-Material
LSTM	I-Material
baseline	I-Material
)	O
,	O
or	O
helps	O
only	O
marginally	O
(	O
as	O
in	O
the	O
case	O
of	O
V	B-Method
-	I-Method
BiMPM	I-Method
)	O
.	O
	
In	O
the	O
latter	O
case	O
,	O
we	O
also	O
observe	O
instances	O
where	O
factoring	O
in	O
images	O
hurts	O
performance	O
.	O
	
In	O
an	O
effort	O
to	O
understand	O
the	O
results	O
,	O
we	O
turn	O
to	O
a	O
more	O
detailed	O
error	B-Method
analysis	I-Method
of	O
the	O
V	O
-	O
BiMPM	B-Method
model	O
,	O
first	O
in	O
relation	O
to	O
the	O
dataset	O
annotations	O
,	O
and	O
then	O
by	O
zooming	O
in	O
somewhat	O
closer	O
on	O
V	B-Material
-	I-Material
SNLI	I-Material
.	O
	
subsection	O
:	O
Error	B-Task
analysis	I-Task
by	O
linguistic	O
annotation	O
label	O
	
In	O
Table	O
[	O
reference	O
]	O
,	O
accuracies	B-Metric
for	O
the	O
blind	B-Method
and	I-Method
grounded	I-Method
version	I-Method
of	O
BiMPM	B-Method
are	O
broken	O
down	O
by	O
the	O
labels	O
given	O
to	O
the	O
sentence	O
pairs	O
in	O
the	O
annotated	O
subset	O
of	O
SNLI	O
described	O
in	O
Section	O
[	O
reference	O
]	O
.	O
	
We	O
only	O
observe	O
a	O
significant	O
difference	O
in	O
the	O
Entity	B-Task
case	I-Task
,	O
that	O
is	O
,	O
where	O
the	O
referents	O
in	O
P	O
and	O
H	O
are	O
inconsistent	O
.	O
	
Here	O
,	O
the	O
blind	B-Method
model	I-Method
outperforms	O
the	O
grounded	O
one	O
,	O
an	O
unexpected	O
result	O
,	O
since	O
one	O
would	O
assume	O
a	O
grounded	B-Method
model	I-Method
to	O
be	O
better	O
equipped	O
to	O
identify	O
mismatched	O
referents	O
.	O
	
Hence	O
,	O
in	O
the	O
following	O
we	O
aim	O
to	O
understand	O
whether	O
the	O
models	O
properly	O
deal	O
with	O
the	O
grounding	B-Task
sub	I-Task
-	I-Task
task	I-Task
.	O
	
subsection	O
:	O
Error	B-Task
analysis	I-Task
on	O
grounding	B-Task
in	O
the	O
SNLI	O
	
We	O
next	O
turn	O
to	O
the	O
“	O
hard	O
”	O
subset	O
of	O
the	O
data	O
,	O
where	O
V	B-Method
-	I-Method
BiMPM	I-Method
showed	O
some	O
improvement	O
over	O
the	O
blind	B-Task
case	I-Task
,	O
but	O
suffered	O
on	O
contradiction	O
cases	O
(	O
Table	O
[	O
reference	O
]	O
)	O
.	O
	
We	O
analysed	O
the	O
207	O
cases	O
in	O
SNLI	O
where	O
the	O
V	B-Method
-	I-Method
BiMPM	I-Method
made	O
incorrect	O
predictions	O
compared	O
to	O
the	O
blind	B-Method
model	I-Method
,	O
that	O
is	O
,	O
where	O
the	O
image	O
hurt	O
performance	O
.	O
	
These	O
were	O
annotated	O
independently	O
by	O
two	O
of	O
the	O
authors	O
(	O
raw	O
inter	O
-	O
annotator	O
agreement	O
:	O
96	O
%	O
)	O
who	O
(	O
a	O
)	O
read	O
the	O
two	O
sentences	O
,	O
P	O
and	O
H	O
;	O
(	O
b	O
)	O
checked	O
whether	O
the	O
relation	O
annotated	O
in	O
the	O
dataset	O
actually	O
held	O
or	O
whether	O
it	O
was	O
an	O
annotation	O
error	O
;	O
(	O
c	O
)	O
in	O
those	O
cases	O
where	O
it	O
held	O
,	O
checked	O
whether	O
including	O
the	O
image	O
actually	O
resulted	O
in	O
a	O
change	O
in	O
the	O
relation	O
.	O
	
Table	O
[	O
reference	O
]	O
displays	O
the	O
proportions	O
of	O
image	O
mismatch	O
and	O
incorrect	O
annotations	O
.	O
	
As	O
the	O
table	O
suggests	O
,	O
in	O
the	O
cases	O
where	O
images	O
hinder	O
performance	O
in	O
the	O
V	B-Method
-	I-Method
BiMPM	I-Method
,	O
it	O
is	O
usually	O
because	O
the	O
image	O
changes	O
the	O
relation	O
(	O
thus	O
,	O
these	O
are	O
cases	O
of	O
image	O
mismatch	O
;	O
see	O
Section	O
[	O
reference	O
]	O
for	O
an	O
example	O
)	O
;	O
this	O
occurs	O
in	O
a	O
large	O
proportion	O
of	O
cases	O
labelled	O
as	O
neutral	O
in	O
the	O
dataset	O
.	O
	
Inspired	O
by	O
the	O
work	O
in	O
,	O
we	O
further	O
explored	O
the	O
impact	O
of	O
visual	B-Task
grounding	I-Task
in	O
both	O
the	O
V	B-Material
-	I-Material
LSTM	I-Material
and	O
V	B-Method
-	I-Method
BiMPM	I-Method
by	O
comparing	O
their	O
performance	O
on	O
SNLI	O
,	O
with	O
the	O
same	O
subset	O
incorporating	O
image	O
“	O
foils	O
”	O
.	O
	
Vectors	O
for	O
the	O
images	O
in	O
the	O
V	B-Material
-	I-Material
SNLI	I-Material
test	O
set	O
were	O
compared	O
pairwise	O
using	O
cosine	B-Method
,	O
and	O
for	O
each	O
test	O
case	O
in	O
V	B-Material
-	I-Material
SNLI	I-Material
,	O
the	O
actual	O
image	O
was	O
replaced	O
with	O
the	O
most	O
dissimilar	O
image	O
in	O
the	O
full	O
test	O
set	O
.	O
	
The	O
rationale	O
is	O
that	O
,	O
if	O
visual	B-Task
grounding	I-Task
is	O
really	O
helpful	O
in	O
recognising	O
the	O
semantic	O
relationship	O
between	O
P	O
and	O
H	O
,	O
we	O
should	O
observe	O
a	O
drop	O
in	O
performance	O
when	O
the	O
images	O
are	O
unrelated	O
to	O
the	O
scenario	O
described	O
by	O
the	O
sentences	O
.	O
	
The	O
results	O
are	O
displayed	O
in	O
Table	O
[	O
reference	O
]	O
,	O
which	O
also	O
reproduces	O
the	O
original	O
results	O
on	O
V	B-Material
-	I-Material
SNLI	I-Material
from	O
Table	O
[	O
reference	O
]	O
for	O
ease	O
of	O
reference	O
.	O
	
As	O
the	O
results	O
show	O
,	O
models	O
are	O
not	O
hurt	O
by	O
the	O
foil	O
image	O
,	O
contrary	O
to	O
our	O
expectations	O
.	O
	
V	B-Method
-	I-Method
BiMPM	I-Method
overall	O
drops	O
just	O
by	O
0.67	O
%	O
whereas	O
V	B-Material
-	I-Material
LSTM	I-Material
drop	O
is	O
somewhat	O
higher	O
(	O
-	O
2.11	O
%	O
)	O
showing	O
it	O
might	O
be	O
doing	O
a	O
better	O
job	O
on	O
the	O
grounding	B-Task
sub	I-Task
-	I-Task
task	I-Task
.	O
	
As	O
a	O
final	O
check	O
,	O
we	O
sought	O
to	O
isolate	O
the	O
grounding	O
from	O
the	O
reasoning	B-Task
sub	I-Task
-	I-Task
task	I-Task
,	O
focusing	O
only	O
on	O
the	O
former	O
.	O
	
We	O
compared	O
the	O
models	O
when	O
grounding	O
only	O
the	O
hypothesis	O
[	O
H	O
+	O
I	O
]	O
,	O
while	O
leaving	O
out	O
the	O
premise	O
.	O
	
Note	O
that	O
this	O
test	O
is	O
different	O
from	O
the	O
evaluation	O
of	O
the	O
model	O
using	O
only	O
the	O
hypothesis	O
[	O
H	O
]	O
:	O
Whereas	O
in	O
that	O
case	O
the	O
input	O
is	O
not	O
expected	O
to	O
provide	O
any	O
useful	O
information	O
to	O
perform	O
the	O
task	O
,	O
here	O
it	O
is	O
.	O
	
As	O
we	O
noted	O
in	O
Section	O
[	O
reference	O
]	O
,	O
by	O
construction	O
the	O
premise	O
is	O
always	O
true	O
with	O
respect	O
to	O
the	O
image	O
while	O
the	O
hypothesis	O
can	O
be	O
either	O
true	O
(	O
entailment	O
or	O
neutral	O
cases	O
)	O
or	O
false	O
(	O
contradiction	O
or	O
neutral	O
cases	O
)	O
.	O
	
A	O
model	O
that	O
is	O
grounding	O
the	O
text	O
adequately	O
would	O
be	O
expected	O
to	O
confuse	O
both	O
entailment	O
and	O
contradiction	O
cases	O
with	O
neutral	O
ones	O
;	O
on	O
the	O
other	O
hand	O
,	O
neutral	O
cases	O
should	O
be	O
confused	O
with	O
entailments	O
or	O
contradictions	O
.	O
	
Confusing	O
contradictions	O
with	O
entailments	O
would	O
be	O
a	O
sign	O
that	O
a	O
model	O
is	O
grounding	O
inadequately	O
,	O
since	O
it	O
is	O
not	O
recognising	O
that	O
H	O
is	O
false	O
with	O
respect	O
to	O
the	O
image	O
.	O
	
As	O
the	O
left	O
panel	O
of	O
Table	O
[	O
reference	O
]	O
shows	O
,	O
V	B-Method
-	I-Method
BiMPM	I-Method
outperforms	O
V	B-Material
-	I-Material
LSTM	I-Material
by	O
a	O
substantial	O
margin	O
,	O
though	O
the	O
performance	O
of	O
both	O
models	O
drops	O
substantially	O
with	O
this	O
setup	O
.	O
	
The	O
right	O
panel	O
in	O
the	O
table	O
shows	O
that	O
neither	O
model	O
is	O
free	O
of	O
implausible	O
errors	O
(	O
confusing	O
entailments	O
and	O
contradictions	O
)	O
,	O
though	O
V	B-Method
-	I-Method
BiMPM	I-Method
makes	O
substantially	O
fewer	O
of	O
these	O
.	O
	
section	O
:	O
Conclusion	O
	
This	O
paper	O
has	O
investigated	O
the	O
potential	O
of	O
grounding	O
the	O
textual	B-Task
entailment	I-Task
task	I-Task
in	O
visual	O
data	O
.	O
	
We	O
argued	O
that	O
a	O
Grounded	B-Method
Textual	I-Method
Entailment	I-Method
model	I-Method
needs	O
to	O
perform	O
two	O
tasks	O
:	O
(	O
a	O
)	O
the	O
grounding	B-Task
itself	O
,	O
and	O
(	O
b	O
)	O
reasoning	O
about	O
the	O
relation	O
between	O
the	O
sentences	O
,	O
against	O
the	O
visual	O
information	O
.	O
	
Our	O
results	O
suggest	O
that	O
a	O
model	O
based	O
on	O
matching	B-Method
and	I-Method
aggregation	I-Method
like	O
the	O
BiMPM	B-Method
model	O
can	O
perform	O
very	O
well	O
at	O
the	O
reasoning	B-Task
task	I-Task
,	O
classifying	B-Task
entailment	I-Task
relations	I-Task
correctly	O
much	O
more	O
frequently	O
than	O
a	O
baseline	O
V	B-Material
-	I-Material
LSTM	I-Material
.	O
	
On	O
the	O
other	O
hand	O
,	O
it	O
is	O
not	O
clear	O
that	O
grounding	O
is	O
being	O
performed	O
adequately	O
in	O
this	O
model	O
.	O
	
It	O
is	O
primarily	O
in	O
the	O
case	O
of	O
contradictions	O
that	O
the	O
image	O
seems	O
to	O
play	O
a	O
direct	O
role	O
in	O
biasing	O
the	O
classification	B-Task
towards	O
the	O
right	O
or	O
wrong	O
class	O
,	O
depending	O
on	O
whether	O
the	O
image	O
is	O
correct	O
.	O
	
In	O
summary	O
,	O
two	O
conclusions	O
can	O
be	O
drawn	O
from	O
these	O
results	O
.	O
	
First	O
,	O
in	O
those	O
cases	O
where	O
the	O
inclusion	O
of	O
visual	O
information	O
results	O
in	O
a	O
loss	O
of	O
accuracy	B-Metric
,	O
this	O
is	O
often	O
due	O
to	O
the	O
image	O
resulting	O
in	O
a	O
change	O
in	O
the	O
original	O
relation	O
annotated	O
in	O
the	O
dataset	O
.	O
	
A	O
related	O
observation	O
is	O
that	O
using	O
foil	O
images	O
results	O
in	O
a	O
greater	O
drop	O
in	O
performance	O
on	O
contradiction	O
cases	O
,	O
possibly	O
because	O
in	O
such	O
cases	O
,	O
grounding	O
serves	O
to	O
identify	O
a	O
mismatch	O
between	O
the	O
hypothesis	O
and	O
the	O
scene	O
described	O
by	O
the	O
premise	O
,	O
a	O
situation	O
which	O
is	O
rendered	O
opaque	O
by	O
the	O
introduction	O
of	O
foils	O
.	O
	
Second	O
,	O
in	O
those	O
cases	O
where	O
improvements	O
are	O
observed	O
in	O
the	O
state	O
of	O
the	O
art	O
V	B-Method
-	I-Method
BiMPM	I-Method
,	O
the	O
precise	O
role	O
played	O
by	O
the	O
image	O
is	O
not	O
straightforward	O
.	O
	
Indeed	O
,	O
we	O
find	O
that	O
this	O
model	O
still	O
marginally	O
outperforms	O
the	O
‘	O
blind	B-Method
’	I-Method
,	I-Method
text	I-Method
-	I-Method
only	I-Method
model	I-Method
	
overall	O
,	O
when	O
the	O
images	O
involved	O
are	O
foils	O
rather	O
than	O
actual	O
images	O
.	O
	
We	O
believe	O
that	O
further	O
research	O
on	O
grounded	O
TE	B-Task
is	O
worthy	O
of	O
the	O
NLP	O
community	O
	
’s	O
attention	O
.	O
	
While	O
linking	B-Task
language	I-Task
with	O
perception	B-Task
is	O
currently	O
a	O
topical	O
issue	O
,	O
there	O
has	O
been	O
relatively	O
little	O
work	O
on	O
linking	B-Task
grounding	I-Task
directly	O
with	O
inference	B-Task
.	O
	
By	O
drawing	O
closer	O
to	O
a	O
joint	O
solution	O
to	O
the	O
grounding	B-Task
and	I-Task
inference	I-Task
tasks	I-Task
,	O
models	O
will	O
also	O
be	O
better	O
able	O
to	O
address	O
language	B-Task
understanding	I-Task
in	O
the	O
real	O
world	O
.	O
	
The	O
present	O
paper	O
presented	O
a	O
first	O
step	O
in	O
this	O
direction	O
using	O
a	O
version	O
of	O
an	O
existing	O
TE	B-Task
dataset	O
which	O
was	O
augmented	O
with	O
images	O
that	O
could	O
be	O
paired	O
directly	O
with	O
the	O
premises	O
,	O
since	O
these	O
were	O
originally	O
captions	O
for	O
those	O
images	O
.	O
	
However	O
,	O
it	O
is	O
important	O
to	O
note	O
that	O
in	O
this	O
dataset	O
premise	O
-	O
hypotheses	O
pairs	O
were	O
not	O
generated	O
directly	O
with	O
reference	O
to	O
the	O
images	O
themselves	O
.	O
	
An	O
important	O
issue	O
to	O
consider	O
in	O
future	O
work	O
on	O
GTE	B-Task
,	O
besides	O
the	O
development	O
of	O
better	O
models	O
,	O
is	O
the	O
development	O
of	O
datasets	O
in	O
which	O
the	O
role	O
of	O
perceptual	O
information	O
is	O
controlled	O
,	O
ensuring	O
that	O
the	O
data	O
on	O
which	O
models	O
are	O
trained	O
represents	O
truly	O
grounded	O
inferences	O
.	O
	
section	O
:	O
Acknowledgements	O
	
We	O
kindly	O
acknowledge	O
the	O
European	O
Network	O
on	O
Integrating	O
Vision	O
and	O
Language	O
	
(	O
iV	O
&	O
L	O
Net	O
)	O
	
ICT	B-Task
COST	I-Task
Action	I-Task
IC1307	I-Task
.	O
	
Moreover	O
,	O
we	O
thank	O
the	O
Erasmus	O
Mundus	O
European	O
Program	O
in	O
Language	B-Task
and	I-Task
Communication	I-Task
Technology	I-Task
.	O
	
Marc	O
Tanti	O
’s	O
work	O
is	O
partially	O
funded	O
by	O
the	O
Endeavour	O
Scholarship	O
Scheme	O
(	O
Malta	O
)	O
,	O
part	O
-	O
financed	O
by	O
the	O
European	O
Union	O
’s	O
European	O
Social	O
Fund	O
(	O
ESF	O
)	O
.	O
	
Finally	O
,	O
we	O
gratefully	O
acknowledge	O
the	O
support	O
of	O
NVIDIA	O
Corporation	O
with	O
the	O
donations	O
to	O
the	O
University	O
of	O
Trento	O
of	O
the	O
GPUs	O
used	O
in	O
our	O
research	O
.	O
	
section	O
:	O
Appendix	O
A	O
:	O
Bottom	O
-	O
up	O
top	B-Task
-	I-Task
down	I-Task
attention	I-Task
(	O
VQA	B-Method
)	O
	
We	O
adapted	O
the	O
Visual	B-Method
Question	I-Method
Answering	I-Method
model	I-Method
proposed	O
in	O
to	O
the	O
Grounded	B-Task
Textual	I-Task
Entailment	I-Task
task	I-Task
.	O
	
The	O
model	O
presents	O
a	O
more	O
fine	O
-	O
grained	B-Method
attention	I-Method
mechanism	I-Method
which	O
allows	O
to	O
identify	O
the	O
most	O
important	O
regions	O
discovered	O
in	O
the	O
image	O
and	O
to	O
perform	O
attention	O
over	O
each	O
of	O
them	O
.	O
	
The	O
model	O
uses	O
a	O
a	O
Recurrent	B-Method
Neural	I-Method
Network	I-Method
with	O
Long	B-Method
Short	I-Method
-	I-Method
Term	I-Method
Memory	I-Method
units	I-Method
to	O
encode	O
the	O
premise	O
P	O
and	O
hypothesis	O
H	O
in	O
512D	O
vectors	O
.	O
	
A	O
bottom	B-Method
-	I-Method
up	I-Method
attention	I-Method
mechanism	I-Method
exploits	O
a	O
Fast	B-Method
R	I-Method
-	I-Method
CNN	I-Method
based	O
on	O
a	O
ResNet	B-Method
-	I-Method
101	I-Method
convolutional	I-Method
neural	I-Method
network	I-Method
to	O
obtain	O
region	O
proposals	O
corresponding	O
to	O
the	O
36	O
most	O
informative	O
regions	O
of	O
the	O
image	O
.	O
	
A	O
top	B-Method
-	I-Method
down	I-Method
attention	I-Method
mechanism	I-Method
is	O
used	O
between	O
the	O
premise	O
(	O
resp	O
.	O
hypothesis	O
)	O
and	O
each	O
of	O
the	O
L2	O
-	O
normalized	O
2048D	O
image	O
vectors	O
corresponding	O
to	O
the	O
region	O
proposals	O
to	O
obtain	O
an	O
attention	B-Metric
score	I-Metric
for	O
each	O
of	O
them	O
.	O
	
Then	O
,	O
a	O
2048D	O
image	O
vector	O
encoding	O
the	O
most	O
interesting	O
visual	O
features	O
for	O
the	O
premise	O
(	O
hypothesis	O
)	O
is	O
obtained	O
as	O
a	O
sum	O
of	O
the	O
36	O
image	O
vectors	O
weighted	O
by	O
the	O
corresponding	O
attention	O
scores	O
for	O
the	O
premise	O
(	O
hypothesis	O
)	O
.	O
	
A	O
fully	B-Method
-	I-Method
connected	I-Method
layer	I-Method
with	O
a	O
gated	B-Method
tanh	I-Method
activation	I-Method
function	I-Method
is	O
applied	O
to	O
the	O
image	O
vector	O
of	O
the	O
most	O
interesting	O
visual	O
features	O
for	O
the	O
premise	O
and	O
for	O
the	O
hypothesis	O
to	O
obtain	O
a	O
reduced	O
512D	O
vector	O
for	O
each	O
of	O
them	O
.	O
	
A	O
fully	B-Method
-	I-Method
connected	I-Method
layer	I-Method
with	O
a	O
gated	B-Method
tanh	I-Method
activation	I-Method
function	I-Method
is	O
also	O
applied	O
to	O
the	O
premise	O
and	O
to	O
the	O
hypothesis	O
in	O
order	O
to	O
obtain	O
a	O
reduced	O
512D	O
vector	O
for	O
each	O
of	O
them	O
.	O
	
The	O
multimodal	B-Task
fusion	I-Task
between	O
the	O
premise	O
(	O
hypothesis	O
)	O
and	O
the	O
image	O
vector	O
of	O
the	O
most	O
interesting	O
visual	O
features	O
for	O
the	O
premise	O
(	O
hypothesis	O
)	O
is	O
obtained	O
by	O
performing	O
an	O
element	B-Method
-	I-Method
wise	I-Method
multiplication	I-Method
between	O
the	O
reduced	O
vector	O
of	O
the	O
premise	O
(	O
hypothesis	O
)	O
and	O
the	O
reduced	O
vector	O
of	O
the	O
most	O
interesting	O
visual	O
features	O
for	O
the	O
premise	O
(	O
hypothesis	O
)	O
.	O
	
After	O
that	O
,	O
the	O
model	O
feeds	O
the	O
concatenation	O
of	O
the	O
two	O
resulting	O
multimodal	B-Method
representations	I-Method
to	O
a	O
stack	O
of	O
three	O
512D	B-Method
layers	I-Method
having	O
a	O
gated	B-Method
tanh	I-Method
activation	I-Method
function	I-Method
,	O
with	O
a	O
final	O
softmax	B-Method
layer	I-Method
to	O
classify	O
the	O
relation	O
between	O
the	O
two	O
sentences	O
as	O
entailment	O
,	O
contradiction	O
or	O
neutral	O
.	O
	
This	O
model	O
uses	O
GloVe	B-Method
embeddings	I-Method
and	O
the	O
same	O
optimization	B-Method
tricks	I-Method
and	O
procedure	O
of	O
the	O
LSTM	O
and	O
V	B-Material
-	I-Material
LSTM	I-Material
models	O
.	O
	
We	O
report	O
the	O
accuracies	B-Metric
of	O
the	O
VQA	B-Method
models	I-Method
against	O
the	O
various	O
tests	O
reported	O
in	O
the	O
paper	O
.	O
	
For	O
ease	O
of	O
comparison	O
we	O
reproduce	O
the	O
full	O
table	O
from	O
the	O
main	O
paper	O
,	O
with	O
the	O
addition	O
of	O
the	O
VQA	O
results	O
.	O
	
section	O
:	O
Appendix	O
B	O
:	O
V	B-Method
-	I-Method
biMPM	I-Method
Model	I-Method
details	O
	
arrows	O
,	O
calc	O
,	O
fit	O
positioning	O
,	O
shapes.multipart	O
,	O
shapes.callouts	O
decorations.pathreplacing	O
hbox=	O
[	O
rectangle	O
,	O
minimum	O
width=7pt	O
,	O
minimum	O
height=25pt	O
]	O
	
vbox=	O
[	O
rectangle	O
,	O
fill	O
=	O
	
black!25	O
,	O
minimum	O
width=35pt	O
,	O
minimum	O
height=10pt	O
]	O
	
blue	O
hbox=	O
[	O
hbox	O
,	O
fill	O
=	O
blue	O
]	O
dots	O
hbox=	O
[	O
hbox	O
]	O
green	O
hbox=	O
[	O
hbox	O
,	O
fill	O
	
=	O
green	O
]	O
green	O
vbox=	O
[	O
vbox	O
,	O
fill	O
	
=	O
green	O
]	O
tbox=	O
[	O
rectangle	O
,	O
minimum	O
width=45pt	O
,	O
minimum	O
height=20pt	O
,	O
	
draw	O
=	O
black	O
,	O
text	O
centered	O
,	O
text	O
=	O
black	O
]	O
red	O
arrow=	O
[-	O
¿	O
,	O
red	O
]	O
match	O
	
arrow=	O
[-	O
¿	O
,	O
black	O
]	O
red	O
matching=	O
[	O
text	O
=	O
red	O
,	O
inner	O
sep=0	O
]	O
	
black	O
matching=	O
[	O
text	O
=	O
black	O
,	O
inner	O
sep=0	O
]	O
context	O
container	O
/	O
.style	O
	
=	O
draw	O
	
=	O
orange	O
,	O
rectangle	O
callout	O
,	O
inner	O
sep=0.6em	O
0.95	O
!	O
	
[	O
scale=0.2	O
]	O
[	O
]	O
	
(	O
prem_text	O
)	O
at	O
	
(	O
10	O
,-	O
7	O
)	O
Premise	O
;	O
[	O
]	O
(	O
hypo_text	O
)	O
at	O
(	O
35	O
,-	O
7	O
)	O
Hypothesis	O
;	O
[	O
blue	O
hbox	O
,	O
label	O
=	O
below	O
:	O
]	O
(	O
w	O
-	O
1	O
)	O
at	O
(	O
0	O
,	O
0	O
)	O
;	O
[	O
blue	O
hbox	O
,	O
right	O
of	O
=	O
w	O
-	O
1	O
,	O
node	O
distance=0.7	O
cm	O
,	O
label	O
=	O
below	O
:	O
]	O
(	O
w	O
-	O
2	O
)	O
;	O
[	O
dots	O
hbox	O
,	O
right	O
of	O
=	O
w	O
-	O
2	O
,	O
node	O
distance=0.7	O
cm	O
,	O
label	O
=	O
below	O
:	O
…	O
]	O
(	O
w	O
-	O
3	O
)	O
	
…	O
;	O
	
[	O
blue	O
hbox	O
,	O
right	O
of	O
=	O
w	O
-	O
3	O
,	O
node	O
distance=0.7	O
cm	O
,	O
label	O
=	O
below	O
:	O
]	O
(	O
w	O
-	O
4	O
)	O
;	O
[	O
dots	O
hbox	O
,	O
right	O
of	O
=	O
w	O
-	O
4	O
,	O
node	O
distance=0.7	O
cm	O
,	O
label	O
=	O
below	O
:	O
	
…	O
]	O
(	O
w	O
-	O
5	O
)	O
…	O
;	O
[	O
blue	O
hbox	O
,	O
right	O
of	O
=	O
w	O
-	O
5	O
,	O
node	O
distance=0.7	O
cm	O
,	O
label	O
=	O
below	O
:	O
]	O
(	O
w	O
-	O
6	O
)	O
;	O
[	O
blue	O
hbox	O
,	O
right	O
of	O
=	O
w	O
-	O
6	O
,	O
node	O
distance=1.5cm*1.2	O
,	O
label	O
=	O
below	O
:	O
]	O
(	O
w	O
-	O
7	O
)	O
;	O
[	O
blue	O
hbox	O
,	O
right	O
of	O
=	O
w	O
-	O
7	O
,	O
node	O
distance=0.7	O
cm	O
,	O
label	O
=	O
below	O
:	O
]	O
(	O
w	O
-	O
8	O
)	O
;	O
[	O
dots	O
hbox	O
,	O
right	O
of	O
=	O
w	O
-	O
8	O
,	O
node	O
distance=0.7	O
cm	O
,	O
label	O
=	O
below	O
:	O
…	O
]	O
(	O
w	O
-	O
9	O
)	O
…	O
;	O
	
[	O
blue	O
hbox	O
,	O
right	O
of	O
=	O
w	O
-	O
9	O
,	O
node	O
distance=0.7	O
cm	O
,	O
label	O
=	O
below	O
:	O
]	O
	
(	O
w	O
-	O
10	O
)	O
;	O
[	O
dots	O
hbox	O
,	O
right	O
of	O
=	O
	
w	O
-	O
10	O
,	O
node	O
distance=0.7	O
cm	O
,	O
label	O
=	O
below	O
:	O
…	O
]	O
	
(	O
w	O
-	O
11	O
)	O
…	O
;	O
[	O
blue	O
hbox	O
,	O
right	O
of	O
=	O
	
w	O
-	O
11	O
,	O
node	O
distance=0.7	O
cm	O
,	O
label	O
=	O
below	O
:	O
]	O
	
(	O
w	O
-	O
12	O
)	O
;	O
[	O
inner	O
sep=0pt	O
,	O
right	O
of	O
=	O
w	O
-	O
12	O
,	O
node	O
distance=1.5cm*2.15	O
]	O
	
(	O
image	O
)	O
	
[	O
width=.10	O
]	O
figures	O
/	O
cat.jpg	O
;	O
[	O
blue	O
hbox	O
]	O
(	O
c	O
-	O
1	O
)	O
at	O
(	O
0	O
,	O
1.5cm*7	O
)	O
;	O
	
[	O
blue	O
hbox	O
,	O
right	O
of	O
=	O
c	O
-	O
1	O
,	O
node	O
distance=0.7	O
cm	O
]	O
(	O
c	O
-	O
2	O
)	O
;	O
[	O
dots	O
hbox	O
,	O
right	O
of	O
=	O
c	O
-	O
2	O
,	O
node	O
distance=0.7	O
cm	O
]	O
(	O
c	O
-	O
3	O
)	O
	
…	O
;	O
[	O
blue	O
hbox	O
,	O
right	O
of	O
=	O
c	O
-	O
3	O
,	O
node	O
distance=0.7	O
cm	O
]	O
(	O
c	O
-	O
4	O
)	O
;	O
[	O
dots	O
hbox	O
,	O
right	O
of	O
=	O
c	O
-	O
4	O
,	O
node	O
distance=0.7	O
cm	O
]	O
(	O
c	O
-	O
5	O
)	O
…	O
;	O
[	O
blue	O
hbox	O
,	O
right	O
of	O
=	O
c	O
-	O
5	O
,	O
node	O
distance=0.7	O
cm	O
]	O
(	O
c	O
-	O
6	O
)	O
;	O
	
[	O
red	O
arrow	O
,	O
shorten	O
¿	O
=	O
1pt	O
,	O
shorten	O
¡	O
=	O
1pt	O
]	O
(	O
c	O
-	O
1	O
)	O
	
–	O
(	O
c	O
-	O
2	O
)	O
;	O
	
[	O
red	O
arrow	O
,	O
shorten	O
¿	O
=	O
1pt	O
,	O
shorten	O
¡	O
=	O
1pt	O
]	O
(	O
c	O
-	O
2	O
)	O
	
–	O
(	O
c	O
-	O
3	O
)	O
;	O
	
[	O
red	O
arrow	O
,	O
shorten	O
¿	O
=	O
1pt	O
,	O
shorten	O
¡	O
=	O
1pt	O
]	O
(	O
c	O
-	O
3	O
)	O
–	O
(	O
c	O
-	O
4	O
)	O
;	O
[	O
red	O
arrow	O
,	O
shorten	O
¿	O
=	O
1pt	O
,	O
shorten	O
¡	O
=	O
1pt	O
]	O
(	O
c	O
-	O
4	O
)	O
–	O
(	O
c	O
-	O
5	O
)	O
;	O
	
[	O
red	O
arrow	O
,	O
shorten	O
¿	O
=	O
1pt	O
,	O
shorten	O
¡	O
=	O
1pt	O
]	O
(	O
c	O
-	O
5	O
)	O
	
–	O
(	O
c	O
-	O
6	O
)	O
;	O
[	O
blue	O
hbox	O
,	O
above	O
of	O
=	O
c	O
-	O
1	O
,	O
node	O
distance=1.5cm	O
/	O
1.2	O
]	O
	
(	O
c	O
-	O
1u	O
)	O
;	O
[	O
blue	O
hbox	O
,	O
right	O
of	O
	
=	O
c	O
-	O
1u	O
,	O
node	O
distance=0.7	O
cm	O
]	O
(	O
c	O
-	O
2u	O
)	O
;	O
[	O
dots	O
hbox	O
,	O
right	O
of	O
	
=	O
c	O
-	O
2u	O
,	O
node	O
distance=0.7	O
cm	O
]	O
(	O
c	O
-	O
3u	O
)	O
	
…	O
	
;	O
[	O
blue	O
hbox	O
,	O
right	O
of	O
=	O
c	O
-	O
3u	O
,	O
node	O
distance=0.7	O
cm	O
]	O
(	O
c	O
-	O
4u	O
)	O
;	O
[	O
dots	O
hbox	O
,	O
right	O
of	O
=	O
c	O
-	O
4u	O
,	O
node	O
distance=0.7	O
cm	O
]	O
	
(	O
c	O
-	O
5u	O
)	O
…	O
	
;	O
[	O
blue	O
hbox	O
,	O
right	O
of	O
=	O
c	O
-	O
5u	O
,	O
node	O
distance=0.7	O
cm	O
]	O
(	O
c	O
-	O
6u	O
)	O
;	O
	
[	O
red	O
arrow	O
,	O
shorten	O
¿	O
=	O
1pt	O
,	O
shorten	O
¡	O
=	O
1pt	O
]	O
(	O
c	O
-	O
2u	O
)	O
	
–	O
	
(	O
c	O
-	O
1u	O
)	O
;	O
	
[	O
red	O
arrow	O
,	O
shorten	O
¿	O
=	O
1pt	O
,	O
shorten	O
¡	O
=	O
1pt	O
]	O
(	O
c	O
-	O
3u	O
)	O
	
–	O
(	O
c	O
-	O
2u	O
)	O
;	O
	
[	O
red	O
arrow	O
,	O
shorten	O
¿	O
=	O
1pt	O
,	O
shorten	O
¡	O
=	O
1pt	O
]	O
	
(	O
c	O
-	O
4u	O
)	O
	
–	O
(	O
c	O
-	O
3u	O
)	O
;	O
	
[	O
red	O
arrow	O
,	O
shorten	O
¿	O
=	O
1pt	O
,	O
shorten	O
¡	O
=	O
1pt	O
]	O
(	O
c	O
-	O
5u	O
)	O
	
–	O
(	O
c	O
-	O
4u	O
)	O
;	O
	
[	O
red	O
arrow	O
,	O
shorten	O
¿	O
=	O
1pt	O
,	O
shorten	O
¡	O
=	O
1pt	O
]	O
	
(	O
c	O
-	O
6u	O
)	O
	
–	O
	
(	O
c	O
-	O
5u	O
)	O
;	O
[	O
red	O
arrow	O
,	O
shorten	O
¿	O
=	O
10pt	O
,	O
shorten	O
	
¡	O
=	O
-	O
3pt	O
]	O
(	O
w	O
-	O
3	O
)	O
	
–	O
(	O
c	O
-	O
3	O
)	O
;	O
[	O
inner	O
sep=0	O
]	O
(	O
p	O
-	O
callout	O
-	O
pointer	O
)	O
at	O
(	O
)	O
;	O
[	O
context	O
container	O
,	O
callout	O
absolute	O
pointer=	O
(	O
p	O
-	O
callout	O
-	O
pointer	O
)	O
,	O
	
fit=	O
(	O
c	O
-	O
1	O
)	O
	
(	O
c	O
-	O
6u	O
)	O
]	O
	
(	O
premise	O
-	O
callout	O
)	O
;	O
[	O
blue	O
hbox	O
,	O
right	O
of	O
=	O
c	O
-	O
6	O
,	O
node	O
distance=1.5cm*1.2	O
]	O
(	O
c	O
-	O
7	O
)	O
;	O
[	O
blue	O
hbox	O
,	O
right	O
of	O
=	O
c	O
-	O
7	O
,	O
node	O
distance=0.7	O
cm	O
]	O
	
(	O
c	O
-	O
8	O
)	O
;	O
[	O
dots	O
hbox	O
,	O
right	O
of	O
=	O
c	O
-	O
8	O
,	O
node	O
distance=0.7	O
cm	O
]	O
	
(	O
c	O
-	O
9	O
)	O
…	O
	
;	O
[	O
blue	O
hbox	O
,	O
right	O
of	O
=	O
c	O
-	O
9	O
,	O
node	O
distance=0.7	O
cm	O
]	O
(	O
c	O
-	O
10	O
)	O
;	O
[	O
dots	O
hbox	O
,	O
right	O
of	O
=	O
	
c	O
-	O
10	O
,	O
node	O
distance=0.7	O
cm	O
]	O
	
(	O
c	O
-	O
11	O
)	O
…	O
;	O
[	O
blue	O
hbox	O
,	O
	
right	O
of	O
=	O
c	O
-	O
11	O
,	O
node	O
distance=0.7	O
cm	O
]	O
(	O
c	O
-	O
12	O
)	O
;	O
[	O
red	O
arrow	O
,	O
shorten	O
¿	O
=	O
1pt	O
,	O
shorten	O
¡	O
=	O
1pt	O
]	O
	
(	O
c	O
-	O
7	O
	
)	O
–	O
(	O
c	O
-	O
8	O
)	O
;	O
	
[	O
red	O
arrow	O
,	O
shorten	O
¿	O
=	O
1pt	O
,	O
shorten	O
¡	O
=	O
1pt	O
]	O
(	O
c	O
-	O
8	O
)	O
	
–	O
(	O
c	O
-	O
9	O
)	O
;	O
	
[	O
red	O
arrow	O
,	O
shorten	O
¿	O
=	O
1pt	O
,	O
shorten	O
¡	O
=	O
1pt	O
]	O
(	O
c	O
-	O
9	O
)	O
	
–	O
	
(	O
c	O
-	O
10	O
)	O
;	O
	
[	O
red	O
arrow	O
,	O
shorten	O
¿	O
=	O
1pt	O
,	O
shorten	O
¡	O
=	O
1pt	O
]	O
	
(	O
c	O
-	O
10	O
)	O
–	O
(	O
c	O
-	O
11	O
)	O
;	O
	
[	O
red	O
arrow	O
,	O
shorten	O
¿	O
=	O
1pt	O
,	O
shorten	O
¡	O
=	O
1pt	O
]	O
	
(	O
c	O
-	O
11	O
)	O
–	O
(	O
c	O
-	O
12	O
)	O
;	O
[	O
blue	O
hbox	O
,	O
right	O
of	O
=	O
c	O
-	O
6u	O
,	O
node	O
distance=1.5cm*1.2	O
]	O
	
(	O
c	O
-	O
7u	O
)	O
;	O
[	O
blue	O
hbox	O
,	O
right	O
of	O
=	O
	
c	O
-	O
7u	O
,	O
node	O
distance=0.7	O
cm	O
]	O
(	O
c	O
-	O
8u	O
)	O
;	O
[	O
dots	O
hbox	O
,	O
right	O
of	O
=	O
c	O
-	O
8u	O
,	O
node	O
distance=0.7	O
cm	O
]	O
	
(	O
c	O
-	O
9u	O
)	O
…	O
	
;	O
[	O
blue	O
hbox	O
,	O
right	O
of	O
=	O
c	O
-	O
9u	O
,	O
node	O
distance=0.7	O
cm	O
]	O
	
(	O
c	O
-	O
10u	O
)	O
;	O
[	O
dots	O
hbox	O
,	O
right	O
of	O
=	O
c	O
-	O
10u	O
,	O
node	O
distance=0.7	O
cm	O
]	O
	
(	O
c	O
-	O
11u	O
)	O
…	O
;	O
[	O
blue	O
hbox	O
,	O
right	O
of	O
=	O
	
c	O
-	O
11u	O
,	O
node	O
distance=0.7	O
cm	O
]	O
(	O
c	O
-	O
12u	O
)	O
;	O
	
[	O
red	O
arrow	O
,	O
shorten	O
¿	O
=	O
1pt	O
,	O
shorten	O
¡	O
=	O
1pt	O
]	O
(	O
c	O
-	O
8u	O
)	O
	
–	O
	
(	O
c	O
-	O
7u	O
)	O
;	O
	
[	O
red	O
arrow	O
,	O
shorten	O
¿	O
=	O
1pt	O
,	O
shorten	O
¡	O
=	O
1pt	O
]	O
	
(	O
c	O
-	O
9u	O
)	O
–	O
(	O
c	O
-	O
8u	O
)	O
;	O
	
[	O
red	O
arrow	O
,	O
shorten	O
¿	O
=	O
1pt	O
,	O
shorten	O
¡	O
=	O
1pt	O
]	O
	
(	O
c	O
-	O
10u	O
)	O
	
–	O
(	O
c	O
-	O
9u	O
)	O
;	O
	
[	O
red	O
arrow	O
,	O
shorten	O
¿	O
=	O
1pt	O
,	O
shorten	O
¡	O
=	O
1pt	O
]	O
(	O
c	O
-	O
11u	O
)	O
	
–	O
	
(	O
c	O
-	O
10u	O
)	O
;	O
	
[	O
red	O
arrow	O
,	O
shorten	O
¿	O
=	O
1pt	O
,	O
shorten	O
¡	O
=	O
1pt	O
]	O
	
(	O
c	O
-	O
12u	O
)	O
–	O
	
(	O
c	O
-	O
11u	O
)	O
;	O
[	O
red	O
arrow	O
,	O
shorten	O
¿	O
=	O
10pt	O
,	O
shorten	O
	
¡	O
=	O
-	O
3pt	O
]	O
(	O
w	O
-	O
9	O
)	O
	
–	O
(	O
c	O
-	O
9	O
)	O
;	O
[	O
inner	O
sep=0	O
]	O
(	O
h	O
-	O
callout	O
-	O
pointer	O
)	O
at	O
(	O
)	O
;	O
[	O
context	O
container	O
,	O
callout	O
absolute	O
pointer=	O
(	O
h	O
-	O
callout	O
-	O
pointer	O
)	O
,	O
fit=	O
(	O
c	O
-	O
7	O
)(	O
c	O
-	O
12u	O
)	O
]	O
	
(	O
left	O
-	O
callout	O
)	O
;	O
[	O
blue	O
hbox	O
,	O
right	O
of	O
=	O
	
c	O
-	O
12	O
,	O
node	O
distance=1.5cm*1.2	O
,	O
yshift=1.2	O
cm	O
,	O
	
label	O
=	O
below	O
:	O
]	O
	
(	O
ci	O
-	O
1	O
)	O
;	O
[	O
blue	O
hbox	O
,	O
right	O
of	O
=	O
ci	O
-	O
1	O
,	O
node	O
distance=0.7	O
cm	O
,	O
label	O
=	O
below	O
:	O
]	O
(	O
ci	O
-	O
2	O
)	O
;	O
[	O
dots	O
hbox	O
,	O
right	O
of	O
=	O
ci	O
-	O
2	O
,	O
node	O
distance=0.7	O
cm	O
,	O
	
label	O
=	O
below	O
:	O
	
…	O
]	O
	
(	O
ci	O
-	O
3	O
)	O
…	O
;	O
[	O
blue	O
hbox	O
,	O
right	O
of	O
=	O
	
ci	O
-	O
3	O
,	O
node	O
distance=0.7	O
cm	O
,	O
label	O
=	O
below	O
:	O
]	O
(	O
ci	O
-	O
4	O
)	O
;	O
[	O
dots	O
hbox	O
,	O
right	O
of	O
=	O
ci	O
-	O
4	O
,	O
node	O
distance=0.7	O
cm	O
,	O
label	O
=	O
below	O
:	O
…	O
]	O
(	O
ci	O
-	O
5	O
)	O
…	O
;	O
[	O
blue	O
hbox	O
,	O
right	O
of	O
=	O
	
ci	O
-	O
5	O
,	O
node	O
distance=0.7	O
cm	O
,	O
label	O
=	O
below	O
:	O
]	O
	
(	O
ci	O
-	O
6	O
)	O
;	O
[	O
red	O
arrow	O
,	O
shorten	O
¿	O
=	O
9pt	O
,	O
shorten	O
	
¡	O
=	O
	
5pt	O
]	O
(	O
image	O
)	O
	
–	O
(	O
ci	O
-	O
3	O
)	O
node	O
[	O
pos=0.35	O
,	O
right	O
,	O
font=	O
]	O
	
VGGnet	O
;	O
[	O
inner	O
sep=0em	O
]	O
	
(	O
i	O
-	O
callout	O
-	O
pointer	O
)	O
at	O
(	O
-(-	O
⁢ci1	O
)(	O
⁢3cm	O
,-	O
⁢1	O
cm	O
)	O
)	O
	
;	O
container	O
,	O
callout	O
absolute	O
pointer=	O
(	O
i	O
-	O
callout	O
-	O
pointer	O
)	O
,	O
fit=	O
(	O
ci	O
-	O
1	O
)(	O
ci	O
-	O
6	O
)	O
,	O
inner	O
sep=0.26em	O
]	O
(	O
left	O
-	O
callout	O
)	O
;	O
[	O
blue	O
hbox	O
,	O
above	O
of	O
=	O
c	O
-	O
1u	O
,	O
node	O
distance=1.5cm*2.9	O
]	O
(	O
m	O
-	O
1	O
)	O
;	O
hbox	O
,	O
right	O
of	O
=	O
m	O
-	O
1	O
,	O
node	O
distance=0.5	O
cm	O
]	O
(	O
m	O
-	O
2	O
)	O
;	O
hbox	O
,	O
right	O
of	O
=	O
m	O
-	O
2	O
,	O
node	O
distance=0.5	O
cm	O
,	O
]	O
(	O
m	O
-	O
3	O
)	O
…	O
;	O
hbox	O
,	O
right	O
of	O
=	O
m	O
-	O
3	O
,	O
node	O
distance=0.5	O
cm	O
]	O
(	O
m	O
-	O
4	O
)	O
;	O
hbox	O
,	O
right	O
of	O
=	O
m	O
-	O
4	O
,	O
node	O
distance=0.5	O
cm	O
]	O
	
(	O
m	O
-	O
5	O
)	O
…	O
;	O
hbox	O
,	O
right	O
of	O
=	O
m	O
-	O
5	O
,	O
node	O
distance=0.5	O
cm	O
,	O
]	O
(	O
m	O
-	O
6	O
)	O
;	O
(	O
[	O
xshift=0pt	O
,	O
yshift=	O
-	O
0.2cm	O
]	O
m	O
-	O
6.south	O
east	O
)	O
	
–	O
	
(	O
[	O
xshift=0pt	O
,	O
yshift=	O
-	O
0.2cm	O
]	O
m	O
-	O
1.south	O
west	O
)	O
node	O
[	O
black	O
,	O
midway	O
,	O
yshift=	O
-	O
0.35	O
cm	O
]	O
P	O
vs	O
H	O
;	O
[	O
blue	O
hbox	O
,	O
right	O
of	O
=	O
m	O
-	O
6	O
,	O
node	O
distance=0.9cm*1.5	O
]	O
(	O
m	O
-	O
7	O
)	O
;	O
hbox	O
,	O
right	O
of	O
=	O
m	O
-	O
7	O
,	O
node	O
distance=0.5	O
cm	O
]	O
	
(	O
m	O
-	O
8	O
)	O
;	O
hbox	O
,	O
right	O
of	O
=	O
m	O
-	O
8	O
,	O
node	O
distance=0.5	O
cm	O
]	O
(	O
m	O
-	O
9	O
)	O
…	O
;	O
hbox	O
,	O
right	O
of	O
=	O
m	O
-	O
9	O
,	O
node	O
distance=0.5	O
cm	O
]	O
	
(	O
m	O
-	O
10	O
)	O
	
;	O
hbox	O
,	O
right	O
of	O
=	O
	
m	O
-	O
10	O
,	O
node	O
distance=0.5	O
cm	O
]	O
	
(	O
m	O
-	O
11	O
)	O
…	O
;	O
hbox	O
,	O
right	O
of	O
=	O
	
m	O
-	O
11	O
,	O
node	O
distance=0.5	O
cm	O
]	O
(	O
m	O
-	O
12	O
)	O
;	O
	
(	O
[	O
xshift=0pt	O
,	O
yshift=	O
-	O
0.2cm	O
]	O
m	O
-	O
12.south	O
east	O
)	O
	
–	O
	
(	O
[	O
xshift=0pt	O
,	O
yshift=	O
-	O
0.2cm	O
]	O
m	O
-	O
7.south	O
west	O
)	O
node	O
[	O
black	O
,	O
midway	O
,	O
yshift=	O
-	O
0.35	O
cm	O
]	O
H	O
vs	O
P	O
;	O
[	O
blue	O
hbox	O
,	O
right	O
of	O
=	O
	
m	O
-	O
12	O
,	O
node	O
distance=0.9cm*1.5	O
]	O
(	O
mi	O
-	O
13	O
)	O
;	O
hbox	O
,	O
right	O
of	O
=	O
mi	O
-	O
13	O
,	O
node	O
distance=0.5	O
cm	O
]	O
(	O
mi	O
-	O
14	O
)	O
;	O
hbox	O
,	O
right	O
of	O
=	O
mi	O
-	O
14	O
,	O
node	O
distance=0.5	O
cm	O
]	O
	
(	O
mi	O
-	O
15	O
)	O
	
…	O
;	O
hbox	O
	
,	O
right	O
of	O
=	O
mi	O
-	O
15	O
,	O
node	O
distance=0.5	O
cm	O
]	O
(	O
mi	O
-	O
16	O
)	O
;	O
hbox	O
,	O
right	O
of	O
=	O
mi	O
-	O
16	O
,	O
node	O
distance=0.5	O
cm	O
]	O
	
(	O
mi	O
-	O
17	O
)	O
…	O
;	O
hbox	O
	
,	O
right	O
of	O
=	O
mi	O
-	O
17	O
,	O
node	O
distance=0.5	O
cm	O
]	O
	
(	O
mi	O
-	O
18	O
)	O
;	O
	
(	O
[	O
xshift=0pt	O
,	O
yshift=	O
-	O
0.2cm	O
]	O
mi	O
-	O
18.south	O
east	O
)	O
	
–	O
	
(	O
[	O
xshift=0pt	O
,	O
yshift=	O
-	O
0.2cm	O
]	O
mi	O
-	O
13.south	O
west	O
)	O
node	O
[	O
black	O
,	O
midway	O
,	O
yshift=	O
-	O
0.35	O
cm	O
]	O
	
H	O
vs	O
Image	O
;	O
[	O
blue	O
hbox	O
,	O
right	O
of	O
=	O
mi	O
-	O
18	O
,	O
node	O
distance=0.9cm*1.5	O
]	O
(	O
mi	O
-	O
19	O
)	O
	
;	O
hbox	O
,	O
right	O
of	O
=	O
mi	O
-	O
19	O
,	O
node	O
distance=0.5	O
cm	O
]	O
(	O
mi	O
-	O
20	O
)	O
;	O
hbox	O
,	O
right	O
of	O
=	O
mi	O
-	O
20	O
,	O
node	O
distance=0.5	O
cm	O
]	O
	
(	O
mi	O
-	O
21	O
)	O
…	O
;	O
hbox	O
	
,	O
right	O
of	O
=	O
mi	O
-	O
21	O
,	O
node	O
distance=0.5	O
cm	O
]	O
(	O
mi	O
-	O
22	O
)	O
;	O
hbox	O
,	O
right	O
of	O
=	O
mi	O
-	O
22	O
,	O
node	O
distance=0.5	O
cm	O
]	O
(	O
mi	O
-	O
23	O
)	O
	
…	O
;	O
hbox	O
	
,	O
right	O
of	O
=	O
mi	O
-	O
23	O
,	O
node	O
distance=0.5	O
cm	O
]	O
	
(	O
mi	O
-	O
24	O
)	O
;	O
(	O
[	O
xshift=0pt	O
,	O
yshift=	O
-	O
0.2cm	O
]	O
mi	O
-	O
24.south	O
east	O
)	O
	
–	O
	
(	O
[	O
xshift=0pt	O
,	O
yshift=	O
-	O
0.2cm	O
]	O
mi	O
-	O
19.south	O
west	O
)	O
	
node	O
[	O
black	O
,	O
midway	O
,	O
yshift=	O
-	O
0.35	O
cm	O
]	O
	
Image	O
vs	O
H	O
;	O
[	O
red	O
matching	O
,	O
below	O
of	O
=	O
m	O
-	O
1	O
,	O
node	O
distance=1.5cm*1.5	O
]	O
	
(	O
mp	O
-	O
1	O
)	O
⊗	O
;	O
matching	O
,	O
below	O
of	O
=	O
m	O
-	O
2	O
,	O
node	O
distance=1.5cm*1.5	O
]	O
	
(	O
mp	O
-	O
2	O
)	O
⊗	O
;	O
matching	O
,	O
below	O
of	O
=	O
m	O
-	O
4	O
,	O
node	O
distance=1.5cm*1.5	O
]	O
(	O
mp	O
-	O
3	O
)	O
⊗	O
;	O
	
matching	B-Task
,	O
below	O
of	O
=	O
m	O
-	O
6	O
,	O
node	O
distance=1.5cm*1.5	O
]	O
	
(	O
mp	O
-	O
4	O
)	O
⊗	O
;	O
	
[	O
red	O
matching	O
,	O
below	O
of	O
=	O
m	O
-	O
7	O
,	O
node	O
distance=1.5cm*1.5	O
]	O
(	O
mp	O
-	O
5	O
)	O
⊗	O
;	O
matching	O
,	O
below	O
of	O
=	O
m	O
-	O
8	O
,	O
node	O
distance=1.5cm*1.5	O
]	O
	
(	O
mp	O
-	O
6	O
)	O
⊗	O
;	O
matching	O
,	O
below	O
of	O
=	O
	
m	O
-	O
10	O
,	O
node	O
distance=1.5cm*1.5	O
]	O
(	O
mp	O
-	O
7	O
)	O
⊗	O
;	O
matching	O
,	O
below	O
of	O
=	O
	
m	O
-	O
12	O
,	O
node	O
distance=1.5cm*1.5	O
]	O
	
(	O
mp	O
-	O
8	O
)	O
⊗	O
;	O
	
[	O
black	O
matching	O
,	O
below	O
of	O
=	O
mi	O
-	O
13	O
,	O
node	O
distance=1.5cm*1.5	O
]	O
	
(	O
mp	O
-	O
9	O
)	O
⊗	O
	
;	O
matching	B-Task
,	O
below	O
of	O
=	O
mi	O
-	O
14	O
,	O
node	O
distance=1.5cm*1.5	O
]	O
	
(	O
mp	O
-	O
10	O
)	O
⊗	O
	
;	O
matching	B-Task
,	O
below	O
of	O
=	O
mi	O
-	O
16	O
,	O
node	O
distance=1.5cm*1.5	O
]	O
	
(	O
mp	O
-	O
11	O
)	O
⊗	O
;	O
matching	O
,	O
below	O
of	O
=	O
mi	O
-	O
18	O
,	O
node	O
distance=1.5cm*1.5	O
]	O
	
(	O
mp	O
-	O
12	O
)	O
⊗	O
;	O
	
[	O
black	O
matching	O
,	O
below	O
of	O
=	O
mi	O
-	O
19	O
,	O
node	O
distance=1.5cm*1.5	O
]	O
(	O
mp	O
-	O
13	O
)	O
⊗	O
;	O
matching	O
,	O
below	O
of	O
=	O
mi	O
-	O
20	O
,	O
node	O
distance=1.5cm*1.5	O
]	O
	
(	O
mp	O
-	O
14	O
)	O
⊗	O
;	O
matching	O
,	O
below	O
of	O
=	O
mi	O
-	O
22	O
,	O
node	O
distance=1.5cm*1.5	O
]	O
	
(	O
mp	O
-	O
15	O
)	O
⊗	O
;	O
matching	O
,	O
below	O
of	O
=	O
mi	O
-	O
24	O
,	O
node	O
distance=1.5cm*1.5	O
]	O
	
(	O
mp	O
-	O
16	O
)	O
⊗	O
;	O
mp	O
-	O
1	O
)	O
;	O
h	O
-	O
callout	O
-	O
pointer	O
)	O
␣	O
edge	O
[-	O
>	O
,	O
␣	O
out=165	O
,	O
␣	O
in=	O
-	O
70	O
]	O
mp	O
-	O
2	O
)	O
;	O
h	O
-	O
callout	O
-	O
pointer	O
)	O
␣	O
edge	O
[-	O
>	O
,	O
␣	O
out=160	O
,	O
␣	O
in=	O
-	O
75	O
]	O
mp	O
-	O
3	O
)	O
;	O
h	O
-	O
callout	O
-	O
pointer	O
)	O
␣	O
edge	O
[-	O
>	O
,	O
␣	O
out=155	O
,	O
␣	O
in=	O
-	O
80	O
]	O
mp	O
-	O
4	O
)	O
;	O
mp	O
-	O
5	O
)	O
;	O
p	O
-	O
callout	O
-	O
pointer	O
)	O
␣	O
edge	O
[-	O
>	O
,	O
␣	O
out=110	O
,	O
␣	O
in=	O
-	O
100	O
]	O
mp	O
-	O
6	O
)	O
;	O
p	O
-	O
callout	O
-	O
pointer	O
)	O
␣	O
edge	O
[-	O
>	O
,	O
␣	O
out=65	O
,	O
␣	O
in=	O
-	O
90	O
]	O
mp	O
-	O
7	O
)	O
;	O
p	O
-	O
callout	O
-	O
pointer	O
)	O
␣	O
edge	O
[-	O
>	O
,	O
␣	O
out=60	O
,	O
␣	O
in=	O
-	O
90	O
]	O
mp	O
-	O
8	O
)	O
;	O
mp	O
-	O
13	O
)	O
;	O
h	O
-	O
callout	O
-	O
pointer	O
)	O
␣	O
edge	O
[-	O
>	O
,	O
␣	O
out=20	O
,	O
␣	O
in=	O
-	O
100	O
]	O
mp	O
-	O
14	O
)	O
;	O
h	O
-	O
callout	O
-	O
pointer	O
)	O
␣	O
edge	O
[-	O
>	O
,	O
␣	O
out=15	O
,	O
␣	O
in=	O
-	O
105	O
]	O
mp	O
-	O
15	O
)	O
;	O
h	O
-	O
callout	O
-	O
pointer	O
)	O
␣	O
edge	O
[-	O
>	O
,	O
␣	O
out=10	O
,	O
␣	O
in=	O
-	O
110	O
]	O
mp	O
-	O
16	O
)	O
;	O
mp	O
-	O
9	O
)	O
;	O
i	O
-	O
callout	O
-	O
pointer	O
)	O
␣	O
edge	O
[-	O
>	O
,	O
␣	O
out=145	O
,	O
␣	O
in=	O
-	O
60	O
]	O
mp	O
-	O
10	O
)	O
;	O
i	O
-	O
callout	O
-	O
pointer	O
)	O
␣	O
edge	O
[-	O
>	O
,	O
␣	O
out=140	O
,	O
␣	O
in=	O
-	O
105	O
]	O
mp	O
-	O
11	O
)	O
;	O
i	O
-	O
callout	O
-	O
pointer	O
)	O
␣	O
edge	O
[-	O
>	O
,	O
␣	O
out=65	O
,	O
␣	O
	
in=	O
-	O
60	O
]	O
mp	O
-	O
12	O
)	O
;	O
[	O
red	O
arrow	O
,	O
shorten	O
¿	O
=	O
18pt	O
]	O
	
(	O
mp	O
-	O
1	O
)	O
–	O
(	O
m	O
-	O
1	O
)	O
;	O
arrow	O
,	O
shorten	O
¿	O
=	O
18pt	O
]	O
	
(	O
mp	O
-	O
2	O
)	O
–	O
(	O
m	O
-	O
2	O
)	O
;	O
arrow	O
,	O
shorten	O
¿	O
=	O
18pt	O
]	O
	
(	O
mp	O
-	O
3	O
)	O
	
–	O
(	O
m	O
-	O
4	O
)	O
;	O
arrow	O
,	O
shorten	O
¿	O
=	O
18pt	O
]	O
	
(	O
mp	O
-	O
4	O
)	O
–	O
(	O
m	O
-	O
6	O
)	O
;	O
[	O
red	O
arrow	O
,	O
shorten	O
¿	O
=	O
18pt	O
]	O
	
(	O
mp	O
-	O
5	O
)	O
	
–	O
(	O
m	O
-	O
7	O
)	O
	
;	O
arrow	O
,	O
shorten	O
¿	O
=	O
18pt	O
]	O
	
(	O
mp	O
-	O
6	O
)	O
–	O
(	O
m	O
-	O
8	O
)	O
;	O
arrow	O
,	O
shorten	O
¿	O
=	O
18pt	O
]	O
	
(	O
mp	O
-	O
7	O
)	O
	
–	O
	
(	O
m	O
-	O
10	O
)	O
;	O
arrow	O
,	O
shorten	O
¿	O
=	O
18pt	O
]	O
	
(	O
mp	O
-	O
8	O
)	O
–	O
	
(	O
m	O
-	O
12	O
)	O
;	O
[	O
red	O
arrow	O
,	O
shorten	O
¿	O
=	O
18pt	O
]	O
	
(	O
mp	O
-	O
9	O
)	O
	
–	O
(	O
mi	O
-	O
13	O
)	O
	
;	O
arrow	O
,	O
shorten	O
¿	O
=	O
18pt	O
]	O
	
(	O
mp	O
-	O
10	O
)	O
	
–	O
(	O
mi	O
-	O
14	O
)	O
;	O
arrow	O
,	O
shorten	O
¿	O
=	O
18pt	O
]	O
	
(	O
mp	O
-	O
11	O
)	O
	
–	O
(	O
mi	O
-	O
16	O
)	O
;	O
arrow	O
,	O
shorten	O
¿	O
=	O
18pt	O
]	O
	
(	O
mp	O
-	O
12	O
)	O
	
–	O
(	O
mi	O
-	O
18	O
)	O
;	O
arrow	O
,	O
shorten	O
¿	O
=	O
18pt	O
]	O
	
(	O
mp	O
-	O
13	O
)	O
	
–	O
(	O
mi	O
-	O
19	O
)	O
;	O
arrow	O
,	O
shorten	O
¿	O
=	O
18pt	O
]	O
	
(	O
mp	O
-	O
14	O
)	O
	
–	O
(	O
mi	O
-	O
20	O
)	O
;	O
arrow	O
,	O
shorten	O
¿	O
=	O
18pt	O
]	O
	
(	O
mp	O
-	O
15	O
)	O
	
–	O
	
(	O
mi	O
-	O
22	O
)	O
;	O
arrow	O
,	O
shorten	O
¿	O
=	O
18pt	O
]	O
	
(	O
mp	O
-	O
16	O
)	O
	
–	O
(	O
mi	O
-	O
24	O
)	O
;	O
[	O
match	O
arrow	O
,	O
shorten	O
¡	O
=	O
6pt	O
]	O
	
(	O
c	O
-	O
1u	O
)	O
	
–	O
(	O
mp	O
-	O
1	O
)	O
;	O
arrow	O
,	O
shorten	O
	
¡	O
=	O
	
6pt	O
]	O
	
(	O
c	O
-	O
2u	O
)	O
	
–	O
(	O
mp	O
-	O
2	O
)	O
;	O
arrow	O
	
,	O
shorten	O
¡	O
=	O
	
7pt	O
]	O
	
(	O
c	O
-	O
4u	O
)	O
to	O
[	O
out=80	O
,	O
in=	O
-	O
45	O
]	O
(	O
	
mp	O
-	O
3	O
)	O
;	O
arrow	O
,	O
shorten	O
¡	O
=	O
6pt	O
]	O
	
(	O
c	O
-	O
6u	O
)	O
to	O
[	O
out=100	O
,	O
in=	O
-	O
45	O
]	O
(	O
mp	O
-	O
4	O
)	O
;	O
	
[	O
match	O
arrow	O
,	O
shorten	O
¡	O
=	O
9pt	O
]	O
	
(	O
c	O
-	O
7u	O
)	O
to	O
[	O
out=110	O
,	O
in=	O
-	O
40	O
]	O
(	O
mp	O
-	O
5	O
)	O
;	O
	
arrow	O
,	O
shorten	O
¡	O
=	O
7pt	O
]	O
(	O
c	O
-	O
8u	O
)	O
to	O
[	O
out=100	O
,	O
in=	O
-	O
35	O
]	O
	
(	O
mp	O
-	O
6	O
)	O
	
;	O
arrow	O
,	O
shorten	O
¡	O
=	O
20pt	O
]	O
	
(	O
c	O
-	O
10u	O
)	O
	
–	O
(	O
mp	O
-	O
7	O
)	O
;	O
arrow	O
,	O
shorten	O
	
¡	O
=	O
22pt	O
]	O
	
(	O
c	O
-	O
12u	O
)	O
–	O
(	O
mp	O
-	O
8	O
)	O
;	O
[	O
match	O
arrow	O
,	O
shorten	O
	
¡	O
=	O
22pt	O
]	O
	
(	O
c	O
-	O
7u	O
)	O
	
–	O
(	O
mp	O
-	O
9	O
)	O
	
;	O
arrow	O
,	O
shorten	O
¡	O
=	O
20pt	O
]	O
	
(	O
c	O
-	O
8u	O
)	O
	
–	O
(	O
mp	O
-	O
10	O
)	O
	
;	O
arrow	O
,	O
shorten	O
¡	O
=	O
7pt	O
]	O
	
(	O
c	O
-	O
10u	O
)	O
to	O
[	O
out=80	O
,	O
in=220	O
]	O
(	O
mp	O
-	O
11	O
)	O
;	O
	
arrow	O
,	O
shorten	O
¡	O
=	O
7pt	O
]	O
	
(	O
c	O
-	O
12u	O
)	O
to	O
[	O
out=80	O
,	O
in=230	O
]	O
(	O
mp	O
-	O
12	O
)	O
	
;	O
[	O
match	O
arrow	O
,	O
shorten	O
¡	O
=	O
3pt	O
]	O
(	O
ci	O
-	O
1	O
)	O
to	O
[	O
out=80	O
,	O
in=220	O
]	O
(	O
mp	O
-	O
13	O
)	O
;	O
arrow	O
,	O
shorten	O
¡	O
=	O
3pt	O
]	O
(	O
ci	O
-	O
2	O
)	O
to	O
[	O
out=90	O
,	O
in=220	O
]	O
(	O
mp	O
-	O
14	O
)	O
;	O
arrow	O
,	O
shorten	O
	
¡	O
=	O
10pt	O
]	O
	
(	O
ci	O
-	O
4	O
)	O
to	O
[	O
out=60	O
,	O
in=	O
-	O
70	O
]	O
(	O
mp	O
-	O
15	O
)	O
	
;	O
arrow	O
,	O
shorten	O
¡	O
=	O
3pt	O
]	O
(	O
ci	O
-	O
6	O
)	O
	
–	O
(	O
mp	O
-	O
16	O
)	O
;	O
[	O
blue	O
hbox	O
,	O
above	O
of	O
=	O
m	O
-	O
1	O
,	O
node	O
distance=1.5cm*1.2	O
]	O
(	O
a	O
-	O
1	O
)	O
;	O
hbox	O
,	O
right	O
of	O
=	O
a	O
-	O
1	O
,	O
node	O
distance=0.5	O
cm	O
]	O
(	O
a	O
-	O
2	O
)	O
;	O
hbox	O
,	O
right	O
of	O
=	O
a	O
-	O
2	O
,	O
node	O
distance=0.5	O
cm	O
]	O
(	O
a	O
-	O
3	O
)	O
	
…	O
;	O
hbox	O
,	O
right	O
of	O
=	O
a	O
-	O
3	O
,	O
node	O
distance=0.5	O
cm	O
]	O
(	O
a	O
-	O
4	O
)	O
;	O
hbox	O
,	O
right	O
of	O
=	O
a	O
-	O
4	O
,	O
node	O
distance=0.5	O
cm	O
]	O
(	O
a	O
-	O
5	O
)	O
…	O
;	O
hbox	O
,	O
right	O
of	O
=	O
a	O
-	O
5	O
,	O
node	O
distance=0.5	O
cm	O
]	O
	
(	O
a	O
-	O
6	O
)	O
;	O
arrow	O
,	O
shorten	O
¿	O
	
=	O
1pt	O
,	O
shorten	O
¡	O
=	O
	
1pt	O
]	O
(	O
a	O
-	O
1	O
)	O
	
–	O
(	O
a	O
-	O
2	O
)	O
;	O
arrow	O
,	O
shorten	O
¿	O
=	O
-	O
2pt	O
,	O
shorten	O
	
¡	O
=	O
0pt	O
]	O
(	O
a	O
-	O
2	O
)	O
–	O
(	O
a	O
-	O
3	O
)	O
;	O
arrow	O
,	O
shorten	O
¿	O
=	O
0pt	O
,	O
shorten	O
	
¡	O
=	O
-	O
2pt	O
]	O
(	O
a	O
-	O
3	O
)	O
–	O
(	O
a	O
-	O
4	O
)	O
;	O
arrow	O
,	O
shorten	O
¿	O
=	O
-	O
2pt	O
,	O
shorten	O
	
¡	O
=	O
0pt	O
]	O
(	O
a	O
-	O
4	O
)	O
–	O
(	O
a	O
-	O
5	O
)	O
;	O
arrow	O
,	O
shorten	O
¿	O
=	O
0pt	O
,	O
shorten	O
	
¡	O
=	O
-	O
2pt	O
]	O
	
(	O
a	O
-	O
5	O
)	O
–	O
(	O
a	O
-	O
6	O
)	O
;	O
[	O
green	O
hbox	O
,	O
above	O
of	O
=	O
a	O
-	O
1	O
,	O
node	O
distance=1.5cm	O
/	O
1.2	O
]	O
(	O
a	O
-	O
1u	O
)	O
;	O
hbox	O
,	O
right	O
of	O
=	O
a	O
-	O
1u	O
,	O
node	O
distance=0.5	O
cm	O
]	O
(	O
a	O
-	O
2u	O
)	O
;	O
hbox	O
,	O
right	O
of	O
=	O
	
a	O
-	O
2u	O
,	O
node	O
distance=0.5	O
cm	O
]	O
	
(	O
a	O
-	O
3u	O
)	O
	
…	O
;	O
hbox	O
,	O
right	O
of	O
=	O
a	O
-	O
3u	O
,	O
node	O
distance=0.5	O
cm	O
]	O
	
(	O
a	O
-	O
4u	O
)	O
;	O
hbox	O
,	O
right	O
of	O
=	O
	
a	O
-	O
4u	O
,	O
node	O
distance=0.5	O
cm	O
]	O
	
(	O
a	O
-	O
5u	O
)	O
	
…	O
;	O
hbox	O
,	O
right	O
of	O
=	O
a	O
-	O
5u	O
,	O
node	O
distance=0.5	O
cm	O
]	O
(	O
a	O
-	O
6u	O
)	O
;	O
arrow	O
,	O
shorten	O
¿	O
	
=	O
1pt	O
,	O
shorten	O
	
¡	O
=	O
	
1pt	O
]	O
(	O
a	O
-	O
2u	O
)	O
	
–	O
(	O
a	O
-	O
1u	O
)	O
;	O
arrow	O
,	O
shorten	O
¿	O
=	O
0pt	O
,	O
shorten	O
	
¡	O
=	O
-	O
2pt	O
]	O
	
(	O
a	O
-	O
3u	O
)	O
	
–	O
(	O
a	O
-	O
2u	O
)	O
;	O
arrow	O
,	O
shorten	O
¿	O
=	O
-	O
2pt	O
,	O
shorten	O
	
¡	O
=	O
0pt	O
]	O
	
(	O
a	O
-	O
4u	O
)	O
–	O
(	O
a	O
-	O
3u	O
)	O
;	O
arrow	O
,	O
shorten	O
¿	O
=	O
0pt	O
,	O
shorten	O
	
¡	O
=	O
-	O
2pt	O
]	O
	
(	O
a	O
-	O
5u	O
)	O
	
–	O
(	O
a	O
-	O
4u	O
)	O
	
;	O
arrow	O
,	O
shorten	O
¿	O
=	O
-	O
2pt	O
,	O
shorten	O
¡	O
=	O
0pt	O
]	O
	
(	O
a	O
-	O
6u	O
)	O
–	O
(	O
a	O
-	O
5u	O
)	O
;	O
[	O
blue	O
hbox	O
,	O
right	O
of	O
=	O
a	O
-	O
6	O
,	O
node	O
distance=0.9cm*1.5	O
]	O
(	O
a	O
-	O
7	O
)	O
;	O
hbox	O
,	O
right	O
of	O
=	O
a	O
-	O
7	O
,	O
node	O
distance=0.5	O
cm	O
]	O
(	O
a	O
-	O
8	O
)	O
;	O
hbox	O
,	O
right	O
of	O
=	O
a	O
-	O
8	O
,	O
node	O
distance=0.5	O
cm	O
]	O
(	O
a	O
-	O
9	O
)	O
	
…	O
;	O
hbox	O
,	O
	
right	O
of	O
=	O
a	O
-	O
9	O
,	O
node	O
distance=0.5	O
cm	O
]	O
(	O
a	O
-	O
10	O
)	O
;	O
	
hbox	B-Method
,	O
right	O
of	O
=	O
	
a	O
-	O
10	O
,	O
node	O
distance=0.5	O
cm	O
]	O
	
(	O
a	O
-	O
11	O
)	O
…	O
;	O
hbox	B-Method
,	O
right	O
of	O
=	O
	
a	O
-	O
11	O
,	O
node	O
distance=0.5	O
cm	O
]	O
	
(	O
a	O
-	O
12	O
)	O
;	O
arrow	O
,	O
shorten	O
¿	O
	
=	O
1pt	O
,	O
shorten	O
	
¡	O
=	O
	
1pt	O
]	O
	
(	O
a	O
-	O
7	O
)	O
–	O
(	O
a	O
-	O
8	O
)	O
	
;	O
arrow	O
,	O
shorten	O
¿	O
=	O
-	O
2pt	O
,	O
shorten	O
¡	O
=	O
0pt	O
]	O
(	O
a	O
-	O
8	O
)	O
–	O
(	O
a	O
-	O
9	O
)	O
;	O
arrow	O
,	O
shorten	O
¿	O
=	O
0pt	O
,	O
shorten	O
	
¡	O
=	O
-	O
2pt	O
]	O
(	O
a	O
-	O
9	O
)	O
	
–	O
(	O
a	O
-	O
10	O
)	O
;	O
arrow	O
,	O
shorten	O
¿	O
=	O
-	O
2pt	O
,	O
shorten	O
	
¡	O
=	O
0pt	O
]	O
	
(	O
a	O
-	O
10	O
)	O
–	O
(	O
a	O
-	O
11	O
)	O
;	O
arrow	O
,	O
shorten	O
¿	O
=	O
0pt	O
,	O
shorten	O
	
¡	O
=	O
-	O
2pt	O
]	O
	
(	O
a	O
-	O
11	O
)	O
–	O
(	O
a	O
-	O
12	O
)	O
	
;	O
[	O
green	O
hbox	O
,	O
right	O
of	O
=	O
a	O
-	O
6u	O
,	O
node	O
distance=0.9cm*1.5	O
]	O
(	O
a	O
-	O
7u	O
)	O
;	O
hbox	O
,	O
right	O
of	O
=	O
	
a	O
-	O
7u	O
,	O
node	O
distance=0.5	O
cm	O
]	O
	
(	O
a	O
-	O
8u	O
)	O
;	O
hbox	O
,	O
right	O
of	O
=	O
	
a	O
-	O
8u	O
,	O
node	O
distance=0.5	O
cm	O
]	O
	
(	O
a	O
-	O
9u	O
)	O
	
…	O
;	O
hbox	B-Method
,	O
right	O
of	O
=	O
a	O
-	O
9u	O
,	O
node	O
distance=0.5	O
cm	O
]	O
	
(	O
a	O
-	O
10u	O
)	O
;	O
hbox	B-Method
,	O
right	O
of	O
=	O
	
a	O
-	O
10u	O
	
,	O
node	O
distance=0.5	O
cm	O
]	O
	
(	O
a	O
-	O
11u	O
)	O
…	O
;	O
hbox	O
,	O
right	O
of	O
=	O
	
a	O
-	O
11u	O
,	O
node	O
distance=0.5	O
cm	O
]	O
	
(	O
a	O
-	O
12u	O
)	O
;	O
arrow	O
,	O
shorten	O
¿	O
	
=	O
1pt	O
,	O
shorten	O
	
¡	O
=	O
	
1pt	O
]	O
	
(	O
a	O
-	O
8u	O
)	O
	
–	O
	
(	O
a	O
-	O
7u	O
)	O
;	O
arrow	O
,	O
	
shorten	O
¿	O
=	O
0pt	O
,	O
shorten	O
	
¡	O
=	O
-	O
2pt	O
]	O
	
(	O
a	O
-	O
9u	O
)	O
	
–	O
	
(	O
a	O
-	O
8u	O
)	O
;	O
arrow	O
,	O
shorten	O
¿	O
=	O
-	O
2pt	O
,	O
shorten	O
	
¡	O
=	O
0pt	O
]	O
	
(	O
a	O
-	O
10u	O
)	O
–	O
(	O
a	O
-	O
9u	O
)	O
;	O
arrow	O
,	O
shorten	O
¿	O
=	O
0pt	O
,	O
shorten	O
	
¡	O
=	O
-	O
2pt	O
]	O
	
(	O
a	O
-	O
11u	O
)	O
	
–	O
	
(	O
a	O
-	O
10u	O
)	O
;	O
arrow	O
,	O
shorten	O
¿	O
=	O
-	O
2pt	O
,	O
shorten	O
	
¡	O
=	O
0pt	O
]	O
	
(	O
a	O
-	O
12u	O
)	O
–	O
	
(	O
a	O
-	O
11u	O
)	O
;	O
[	O
blue	O
hbox	O
,	O
right	O
of	O
=	O
a	O
-	O
12	O
,	O
node	O
distance=0.9cm*1.5	O
]	O
(	O
ai	O
-	O
13	O
)	O
;	O
hbox	O
,	O
right	O
of	O
=	O
ai	O
-	O
13	O
,	O
node	O
distance=0.5	O
cm	O
]	O
(	O
ai	O
-	O
14	O
)	O
;	O
hbox	O
,	O
right	O
of	O
=	O
ai	O
-	O
14	O
,	O
node	O
distance=0.5	O
cm	O
]	O
	
(	O
ai	O
-	O
15	O
)	O
	
…	O
;	O
hbox	O
,	O
right	O
of	O
=	O
ai	O
-	O
15	O
,	O
node	O
distance=0.5	O
cm	O
]	O
(	O
ai	O
-	O
16	O
)	O
;	O
hbox	O
,	O
right	O
of	O
=	O
ai	O
-	O
16	O
,	O
node	O
distance=0.5	O
cm	O
]	O
	
(	O
ai	O
-	O
17	O
)	O
	
…	O
;	O
hbox	O
,	O
right	O
of	O
=	O
ai	O
-	O
17	O
,	O
node	O
distance=0.5	O
cm	O
]	O
(	O
ai	O
-	O
18	O
)	O
;	O
arrow	O
,	O
shorten	O
¿	O
	
=	O
1pt	O
,	O
shorten	O
	
¡	O
=	O
	
1pt	O
]	O
(	O
ai	O
-	O
13	O
)	O
	
–	O
	
(	O
ai	O
-	O
14	O
)	O
;	O
arrow	O
,	O
shorten	O
¿	O
=	O
-	O
2pt	O
,	O
shorten	O
	
¡	O
=	O
0pt	O
]	O
(	O
ai	O
-	O
14	O
)	O
–	O
(	O
ai	O
-	O
15	O
)	O
;	O
arrow	O
,	O
shorten	O
¿	O
=	O
0pt	O
,	O
shorten	O
	
¡	O
=	O
-	O
2pt	O
]	O
	
(	O
ai	O
-	O
15	O
)	O
	
–	O
(	O
ai	O
-	O
16	O
)	O
;	O
arrow	O
,	O
shorten	O
¿	O
=	O
-	O
2pt	O
,	O
shorten	O
	
¡	O
=	O
0pt	O
]	O
(	O
ai	O
-	O
16	O
)	O
	
–	O
(	O
ai	O
-	O
17	O
)	O
;	O
arrow	O
,	O
	
shorten	O
¿	O
=	O
0pt	O
,	O
shorten	O
	
¡	O
=	O
-	O
2pt	O
]	O
	
(	O
ai	O
-	O
17	O
)	O
–	O
(	O
ai	O
-	O
18	O
)	O
;	O
[	O
green	O
hbox	O
,	O
right	O
of	O
=	O
	
a	O
-	O
12u	O
,	O
node	O
distance=0.9cm*1.5	O
]	O
	
(	O
ai	O
-	O
13u	O
)	O
;	O
hbox	O
,	O
right	O
of	O
=	O
ai	O
-	O
13u	O
,	O
node	O
distance=0.5	O
cm	O
]	O
	
(	O
ai	O
-	O
14u	O
)	O
	
;	O
hbox	O
,	O
right	O
of	O
=	O
ai	O
-	O
14u	O
,	O
node	O
distance=0.5	O
cm	O
]	O
(	O
ai	O
-	O
15u	O
)	O
	
…	O
;	O
hbox	O
,	O
	
right	O
of	O
=	O
ai	O
-	O
15u	O
,	O
node	O
distance=0.5	O
cm	O
]	O
	
(	O
ai	O
-	O
16u	O
)	O
;	O
hbox	O
,	O
right	O
of	O
=	O
ai	O
-	O
16u	O
,	O
node	O
distance=0.5	O
cm	O
]	O
	
(	O
ai	O
-	O
17u	O
)	O
…	O
;	O
hbox	O
,	O
right	O
of	O
=	O
	
ai	O
-	O
17u	O
,	O
node	O
distance=0.5	O
cm	O
]	O
(	O
ai	O
-	O
18u	O
)	O
;	O
arrow	O
,	O
shorten	O
¿	O
	
=	O
1pt	O
,	O
shorten	O
	
¡	O
=	O
	
1pt	O
]	O
	
(	O
ai	O
-	O
14u	O
)	O
	
–	O
	
(	O
ai	O
-	O
13u	O
)	O
;	O
arrow	O
,	O
	
shorten	O
¿	O
=	O
0pt	O
,	O
shorten	O
	
¡	O
=	O
-	O
2pt	O
]	O
	
(	O
ai	O
-	O
15u	O
)	O
	
–	O
	
(	O
ai	O
-	O
14u	O
)	O
;	O
arrow	O
,	O
shorten	O
¿	O
=	O
-	O
2pt	O
,	O
shorten	O
	
¡	O
=	O
0pt	O
]	O
	
(	O
ai	O
-	O
16u	O
)	O
	
–	O
(	O
ai	O
-	O
15u	O
)	O
;	O
arrow	O
,	O
	
shorten	O
¿	O
=	O
0pt	O
,	O
shorten	O
	
¡	O
=	O
-	O
2pt	O
]	O
	
(	O
ai	O
-	O
17u	O
)	O
–	O
(	O
ai	O
-	O
16u	O
)	O
;	O
arrow	O
,	O
shorten	O
¿	O
=	O
-	O
2pt	O
,	O
shorten	O
	
¡	O
=	O
0pt	O
]	O
	
(	O
ai	O
-	O
18u	O
)	O
	
–	O
	
(	O
ai	O
-	O
17u	O
)	O
;	O
[	O
blue	O
hbox	O
,	O
right	O
of	O
=	O
ai	O
-	O
18	O
,	O
node	O
distance=0.9cm*1.5	O
]	O
(	O
ai	O
-	O
19	O
)	O
;	O
hbox	O
,	O
right	O
of	O
=	O
ai	O
-	O
19	O
,	O
node	O
distance=0.5	O
cm	O
]	O
(	O
ai	O
-	O
20	O
)	O
;	O
hbox	O
,	O
right	O
of	O
=	O
ai	O
-	O
20	O
,	O
node	O
distance=0.5	O
cm	O
]	O
	
(	O
ai	O
-	O
21	O
)	O
…	O
;	O
hbox	O
,	O
right	O
of	O
=	O
ai	O
-	O
21	O
,	O
node	O
distance=0.5	O
cm	O
]	O
(	O
ai	O
-	O
22	O
)	O
	
;	O
hbox	O
,	O
right	O
of	O
=	O
ai	O
-	O
22	O
,	O
node	O
distance=0.5	O
cm	O
]	O
(	O
ai	O
-	O
23	O
)	O
	
…	O
;	O
hbox	O
	
,	O
right	O
of	O
=	O
ai	O
-	O
23	O
,	O
node	O
distance=0.5	O
cm	O
]	O
	
(	O
ai	O
-	O
24	O
)	O
;	O
arrow	O
,	O
shorten	O
¿	O
	
=	O
1pt	O
,	O
shorten	O
	
¡	O
=	O
	
1pt	O
]	O
(	O
ai	O
-	O
19	O
)	O
	
–	O
(	O
ai	O
-	O
20	O
)	O
;	O
arrow	O
,	O
shorten	O
¿	O
=	O
-	O
2pt	O
,	O
shorten	O
	
¡	O
=	O
0pt	O
]	O
(	O
ai	O
-	O
20	O
)	O
–	O
(	O
ai	O
-	O
21	O
)	O
;	O
arrow	O
,	O
shorten	O
¿	O
=	O
0pt	O
,	O
shorten	O
	
¡	O
=	O
-	O
2pt	O
]	O
	
(	O
ai	O
-	O
21	O
)	O
	
–	O
(	O
ai	O
-	O
22	O
)	O
;	O
arrow	O
,	O
shorten	O
¿	O
=	O
-	O
2pt	O
,	O
shorten	O
	
¡	O
=	O
0pt	O
]	O
(	O
ai	O
-	O
22	O
)	O
	
–	O
(	O
ai	O
-	O
23	O
)	O
;	O
arrow	O
,	O
	
shorten	O
¿	O
=	O
0pt	O
,	O
shorten	O
	
¡	O
=	O
-	O
2pt	O
]	O
	
(	O
ai	O
-	O
23	O
)	O
	
–	O
(	O
ai	O
-	O
24	O
)	O
;	O
[	O
green	O
hbox	O
,	O
right	O
of	O
=	O
ai	O
-	O
18u	O
,	O
node	O
distance=0.9cm*1.5	O
]	O
(	O
ai	O
-	O
19u	O
)	O
;	O
hbox	O
,	O
	
right	O
of	O
=	O
ai	O
-	O
19u	O
,	O
node	O
distance=0.5	O
cm	O
]	O
	
(	O
ai	O
-	O
20u	O
)	O
;	O
hbox	O
,	O
right	O
of	O
=	O
ai	O
-	O
20u	O
,	O
node	O
distance=0.5	O
cm	O
]	O
	
(	O
ai	O
-	O
21u	O
)	O
	
…	O
;	O
hbox	O
	
,	O
right	O
of	O
=	O
ai	O
-	O
21u	O
,	O
node	O
distance=0.5	O
cm	O
]	O
	
(	O
ai	O
-	O
22u	O
)	O
;	O
hbox	B-Method
,	O
right	O
of	O
=	O
	
ai	O
-	O
22u	O
,	O
node	O
distance=0.5	O
cm	O
]	O
	
(	O
ai	O
-	O
23u	O
)	O
…	O
;	O
hbox	O
,	O
	
right	O
of	O
=	O
ai	O
-	O
23u	O
,	O
node	O
distance=0.5	O
cm	O
]	O
	
(	O
ai	O
-	O
24u	O
)	O
;	O
arrow	O
,	O
shorten	O
¿	O
	
=	O
1pt	O
,	O
shorten	O
	
¡	O
=	O
	
1pt	O
]	O
	
(	O
ai	O
-	O
20u	O
)	O
	
–	O
	
(	O
ai	O
-	O
19u	O
)	O
;	O
arrow	O
,	O
	
shorten	O
¿	O
=	O
0pt	O
,	O
shorten	O
	
¡	O
=	O
-	O
2pt	O
]	O
	
(	O
ai	O
-	O
21u	O
)	O
	
–	O
	
(	O
ai	O
-	O
20u	O
)	O
	
;	O
arrow	O
,	O
shorten	O
¿	O
=	O
-	O
2pt	O
,	O
shorten	O
¡	O
=	O
0pt	O
]	O
	
(	O
ai	O
-	O
22u	O
)	O
	
–	O
	
(	O
ai	O
-	O
21u	O
)	O
;	O
arrow	O
,	O
shorten	O
¿	O
=	O
0pt	O
,	O
shorten	O
	
¡	O
=	O
-	O
2pt	O
]	O
	
(	O
ai	B-Method
-	I-Method
23u	I-Method
)	O
–	O
	
(	O
ai	O
-	O
22u	O
)	O
;	O
arrow	O
,	O
shorten	O
¿	O
=	O
-	O
2pt	O
,	O
shorten	O
	
¡	O
=	O
0pt	O
]	O
	
(	O
ai	O
-	O
24u	O
)	O
	
–	O
	
(	O
ai	O
-	O
23u	O
)	O
;	O
	
arrow	O
,	O
shorten	O
¿	O
=	O
6pt	O
,	O
shorten	O
	
¡	O
=	O
-	O
5pt	O
]	O
	
(	O
m	O
-	O
3	O
)	O
–	O
(	O
a	O
-	O
3	O
)	O
;	O
arrow	O
,	O
shorten	O
¿	O
=	O
6pt	O
,	O
shorten	O
	
¡	O
=	O
-	O
5pt	O
]	O
(	O
m	O
-	O
9	O
)	O
–	O
(	O
a	O
-	O
9	O
)	O
;	O
arrow	O
,	O
shorten	O
¿	O
=	O
6pt	O
,	O
shorten	O
	
¡	O
=	O
-	O
5pt	O
]	O
	
(	O
mi	O
-	O
15	O
)	O
–	O
(	O
ai	O
-	O
15	O
)	O
;	O
	
arrow	O
,	O
shorten	O
¿	O
=	O
6pt	O
,	O
shorten	O
	
¡	O
=	O
-	O
5pt	O
]	O
	
(	O
mi	O
-	O
21	O
)	O
	
–	O
(	O
ai	O
-	O
21	O
)	O
;	O
[	O
green	O
vbox	O
,	O
above	O
of	O
=	O
a	O
-	O
3u	O
,	O
node	O
distance=1.5cm*1.2	O
,	O
xshift=	O
-	O
0.3	O
cm	O
]	O
(	O
ap	O
-	O
1	O
)	O
;	O
vbox	O
,	O
right	O
of	O
=	O
ap	O
-	O
1	O
,	O
node	O
distance=0.9cm*2	O
]	O
(	O
ap	O
-	O
2	O
)	O
;	O
	
vbox	O
,	O
right	O
of	O
=	O
ap	O
-	O
2	O
,	O
node	O
distance=0.9cm*2	O
]	O
(	O
ap	O
-	O
3	O
)	O
;	O
vbox	O
,	O
right	O
of	O
=	O
ap	O
-	O
3	O
,	O
node	O
distance=0.9cm*2	O
]	O
(	O
ap	O
-	O
4	O
)	O
;	O
vbox	O
,	O
right	O
of	O
=	O
ap	O
-	O
4	O
,	O
node	O
distance=0.9cm*2	O
]	O
(	O
ap	O
-	O
5	O
)	O
;	O
vbox	O
,	O
right	O
of	O
=	O
ap	O
-	O
5	O
,	O
node	O
distance=0.9cm*2	O
]	O
(	O
ap	O
-	O
6	O
)	O
;	O
vbox	O
,	O
right	O
of	O
=	O
	
ap	O
-	O
6	O
,	O
node	O
distance=0.9cm*2	O
]	O
(	O
ap	O
-	O
7	O
)	O
;	O
	
vbox	O
,	O
right	O
of	O
=	O
ap	O
-	O
7	O
,	O
node	O
distance=0.9cm*2	O
]	O
(	O
ap	O
-	O
8	O
)	O
;	O
[	O
red	O
arrow	O
,	O
shorten	O
¿	O
=	O
3pt	O
,	O
shorten	O
¡	O
=	O
	
3pt	O
]	O
(	O
a	O
-	O
1u	O
)	O
	
–	O
(	O
ap	O
-	O
1	O
)	O
;	O
arrow	O
,	O
shorten	O
¿	O
=	O
	
3pt	O
,	O
shorten	O
	
¡	O
=	O
3pt	O
]	O
(	O
a	O
-	O
6.east	O
)	O
–	O
	
(	O
[	O
xshift=	O
-	O
1	O
cm	O
]	O
ap	O
-	O
2.south	O
east	O
)	O
;	O
	
[	O
red	O
arrow	O
,	O
shorten	O
¿	O
=	O
3pt	O
,	O
shorten	O
¡	O
=	O
3pt	O
]	O
(	O
a	O
-	O
7u	O
)	O
	
–	O
(	O
ap	O
-	O
3	O
)	O
;	O
arrow	O
,	O
shorten	O
¿	O
=	O
3pt	O
,	O
shorten	O
	
¡	O
=	O
3pt	O
]	O
(	O
a	O
-	O
12.west	O
)	O
	
–	O
	
(	O
[	O
xshift=	O
-	O
0.5cm	O
]	O
ap	O
-	O
4.south	O
)	O
;	O
[	O
red	O
arrow	O
,	O
shorten	O
¿	O
=	O
3pt	O
,	O
shorten	O
¡	O
=	O
3pt	O
]	O
(	O
ai	O
-	O
13u	O
)	O
	
–	O
(	O
ap	O
-	O
5	O
)	O
;	O
arrow	O
,	O
shorten	O
¿	O
=	O
3pt	O
,	O
shorten	O
	
¡	O
=	O
3pt	O
]	O
(	O
ai	O
-	O
18.west	O
)	O
	
–	O
	
(	O
[	O
xshift=	O
-	O
1cm	O
]	O
ap	O
-	O
6	O
)	O
;	O
[	O
red	O
arrow	O
,	O
shorten	O
¿	O
=	O
3pt	O
,	O
shorten	O
¡	O
=	O
	
3pt	O
]	O
	
(	O
ai	O
-	O
19u	O
)	O
–	O
(	O
ap	O
-	O
7	O
)	O
;	O
arrow	O
,	O
shorten	O
¿	O
	
=	O
3pt	O
,	O
shorten	O
	
¡	O
=	O
3pt	O
]	O
(	O
ai	O
-	O
24.west	O
)	O
	
–	O
(	O
ap	O
-	O
8	O
)	O
;	O
[	O
tbox	O
,	O
above	O
of	O
=	O
ap	O
-	O
4	O
,	O
node	O
distance=0.9cm*1.6	O
,	O
xshift=1	O
	
cm	O
]	O
	
(	O
softmax	B-Method
)	O
softmax	O
;	O
of	O
=	O
softmax	O
,	O
node	O
distance=0.9	O
cm	O
]	O
(	O
output	O
)	O
P	O
(	O
y|premise	O
,	O
image	O
,	O
hypothesis	O
)	O
;	O
arrow	O
,	O
shorten	O
¿	O
	
=	O
3pt	O
,	O
shorten	O
	
¡	O
=	O
3pt	O
]	O
(	O
[	O
xshift=1.5cm	O
]	O
ap	O
-	O
4.north	O
east	O
)	O
	
–	O
(	O
softmax	O
)	O
;	O
[	O
decorate	O
,	O
thick	O
,	O
decoration	O
=	O
brace	O
,	O
amplitude=6pt	O
,	O
yshift=0pt	O
]	O
	
(	O
[	O
yshift=	O
-	O
65pt	O
,	O
xshift=	O
-	O
50pt	O
]	O
w	O
-	O
1.south	O
west	O
)	O
	
–	O
	
(	O
[	O
xshift=	O
-	O
50pt	O
,	O
yshift=	O
-	O
125pt	O
]	O
c	O
-	O
1.south	O
west	O
)	O
node	O
	
[	O
black	O
,	O
midway	O
,	O
xshift=	O
-	O
1	O
cm	O
,	O
yshift=	O
-	O
0.2	O
cm	O
,	O
rotate=90	O
,	O
anchor	O
=	O
north	O
]	O
Embedding	O
layer	O
;	O
[	O
decorate	O
,	O
thick	O
,	O
decoration	O
=	O
brace	O
,	O
amplitude=6pt	O
,	O
yshift=0pt	O
]	O
	
(	O
[	O
yshift=	O
-	O
5pt	O
,	O
xshift=	O
-	O
50pt	O
]	O
c	O
-	O
1.south	O
west	O
)	O
	
–	O
	
(	O
[	O
xshift=	O
-	O
50pt	O
,	O
yshift=25pt	O
]	O
c	O
-	O
1u.north	O
west	O
)	O
node	O
	
[	O
black	O
,	O
midway	O
,	O
xshift=	O
-	O
1	O
cm	O
,	O
rotate=90	O
,	O
anchor	O
=	O
north	O
]	O
Context	O
layer	O
;	O
[	O
decorate	O
,	O
thick	O
,	O
decoration	O
=	O
brace	O
,	O
amplitude=6pt	O
,	O
yshift=0pt	O
]	O
	
(	O
[	O
yshift=	O
-	O
95pt	O
,	O
xshift=	O
-	O
50pt	O
]	O
mp	O
-	O
1.south	O
west	O
)	O
	
–	O
	
(	O
[	O
xshift=	O
-	O
50pt	O
,	O
yshift=	O
-	O
45pt	O
]	O
m	O
-	O
1.north	O
west	O
)	O
	
node	O
	
[	O
black	O
,	O
midway	O
,	O
xshift=	O
-	O
1	O
cm	O
,	O
rotate=90	O
,	O
anchor	O
=	O
north	O
]	O
Matching	O
layer	O
;	O
[	O
decorate	O
,	O
thick	O
,	O
decoration	O
=	O
brace	O
,	O
amplitude=6pt	O
,	O
yshift=0pt	O
]	O
	
(	O
[	O
xshift=	O
-	O
50pt	O
]	O
a	O
-	O
1.south	O
west	O
)	O
	
–	O
	
(	O
[	O
xshift=	O
-	O
50pt	O
,	O
yshift=1.5cm*3	O
]	O
a	O
-	O
1u.north	O
west	O
)	O
node	O
	
[	O
black	O
,	O
midway	O
,	O
xshift=	O
-	O
1	O
cm	O
,	O
rotate=90	O
,	O
anchor	O
=	O
north	O
]	O
Aggregation	O
layer	O
;	O
[	O
decorate	O
,	O
thick	O
,	O
decoration	O
=	O
brace	O
,	O
amplitude=6pt	O
,	O
yshift=0pt	O
]	O
	
(	O
[	O
xshift=	O
-	O
50pt	O
,	O
yshift=1.5cm*5.5	O
]	O
a	O
-	O
1u.north	O
west	O
)	O
	
–	O
	
(	O
[	O
xshift=	O
-	O
50pt	O
,	O
yshift=1.5cm*12.5	O
]	O
a	O
-	O
1u.north	O
west	O
)	O
node	O
[	O
black	O
,	O
midway	O
,	O
xshift=	O
-	O
1	O
cm	O
,	O
rotate=90	O
,	O
anchor	O
=	O
north	O
	
]	O
Prediction	B-Method
layer	I-Method
	
;	O
Here	O
,	O
we	O
report	O
some	O
further	O
details	O
of	O
our	O
implementation	O
of	O
the	O
V	O
-	O
BiMPM	B-Method
model	O
described	O
in	O
Section	O
4	O
of	O
the	O
main	O
paper	O
,	O
based	O
on	O
the	O
work	O
of	O
Wang2017	O
.	O
	
Our	O
model	O
is	O
displayed	O
in	O
Figure	O
[	O
reference	O
]	O
.	O
	
The	O
core	O
part	O
of	O
the	O
original	O
BiMPM	B-Method
is	O
the	O
matching	B-Method
layer	I-Method
.	O
	
Given	O
two	O
-	O
dimensional	O
vectors	O
and	O
,	O
each	O
replicated	O
times	O
(	O
is	O
the	O
number	O
of	O
‘	O
perspectives	O
’	O
)	O
and	O
a	O
trainable	O
weight	B-Method
matrix	I-Method
,	O
matching	B-Task
involves	O
a	O
cosine	B-Method
similarity	I-Method
computation	I-Method
that	O
yields	O
an	O
-	O
dimensional	O
matching	O
vector	O
,	O
whose	O
elements	O
are	O
defined	O
as	O
follows	O
:	O
	
The	O
matching	B-Method
operations	I-Method
included	O
are	O
the	O
following	O
:	O
full	B-Task
-	I-Task
matching	I-Task
,	O
where	O
each	O
forward	O
or	O
backward	O
contextual	O
embedding	O
of	O
the	O
premise	O
P	O
(	O
resp	O
.	O
	
the	O
hypothesis	O
H	O
)	O
is	O
matched	O
to	O
the	O
last	O
time	O
-	O
step	O
of	O
H	O
(	O
resp	O
.	O
	
P	O
)	O
;	O
max	B-Method
-	I-Method
pooling	I-Method
,	O
where	O
each	O
forward	B-Method
/	I-Method
backward	I-Method
contextual	I-Method
embedding	I-Method
of	O
one	O
sentence	O
is	O
compared	O
to	O
the	O
embeddings	O
of	O
the	O
other	O
,	O
retaining	O
the	O
maximum	O
value	O
for	O
each	O
dimension	O
;	O
attentive	B-Method
matching	I-Method
,	O
where	O
first	O
,	O
the	O
pairwise	O
cosine	O
similarity	O
between	O
forward	O
/	O
backward	O
embeddings	O
of	O
P	O
and	O
H	O
is	O
estimated	O
,	O
before	O
calculating	O
an	O
attentive	O
vector	O
over	O
the	O
weighted	O
sum	O
of	O
contextual	O
embeddings	O
for	O
H	O
and	O
matching	O
each	O
forward	O
/	O
backward	O
embedding	O
of	O
P	O
against	O
the	O
attentive	B-Method
vector	I-Method
;	O
max	B-Method
-	I-Method
attentive	I-Method
matching	I-Method
,	O
a	O
version	O
of	O
attentive	B-Method
matching	I-Method
where	O
the	O
contextual	O
embedding	O
with	O
the	O
highest	O
cosine	O
is	O
used	O
as	O
the	O
attentive	O
vector	O
,	O
instead	O
of	O
the	O
weighted	B-Method
sum	I-Method
.	O
	
The	O
visually	O
-	O
augmented	O
version	O
of	O
the	O
original	O
model	O
,	O
V	B-Method
-	I-Method
BiMPM	I-Method
,	O
is	O
displayed	O
in	O
Figure	O
[	O
reference	O
]	O
.	O
	
To	O
perform	O
multimodal	B-Task
matching	I-Task
,	O
the	O
visual	O
and	O
textual	O
vectors	O
are	O
mapped	O
to	O
a	O
mutual	O
space	O
using	O
the	O
following	O
affine	O
transformation	O
:	O
where	O
,	O
,	O
,	O
and	O
are	O
the	O
weight	O
matrix	O
,	O
the	O
bias	O
,	O
the	O
input	O
features	O
and	O
output	O
features	O
,	O
respectively	O
,	O
and	O
is	O
any	O
text	O
(	O
P	O
or	O
H	O
)	O
.	O
	
Given	O
weight	O
matrices	O
for	O
text	O
and	O
for	O
images	O
,	O
we	O
compute	O
the	O
matching	O
vector	O
between	O
a	O
textual	O
vector	O
and	O
image	O
vector	O
as	O
:	O
	
bibliography	O
:	O
References	O
	
document	O
:	O
Going	O
deeper	O
with	O
convolutions	B-Method
	
We	O
propose	O
a	O
deep	B-Method
convolutional	I-Method
neural	I-Method
network	I-Method
architecture	I-Method
codenamed	I-Method
âInceptionâ	I-Method
,	O
which	O
was	O
responsible	O
for	O
setting	O
the	O
new	O
state	O
of	O
the	O
art	O
for	O
classification	B-Task
and	O
detection	B-Task
in	O
the	O
ImageNet	B-Task
Large	I-Task
-	I-Task
Scale	I-Task
Visual	I-Task
Recognition	I-Task
Challenge	I-Task
2014	I-Task
(	O
ILSVRCâ14	B-Task
)	O
.	O
	
The	O
main	O
hallmark	O
of	O
this	O
architecture	O
is	O
the	O
improved	O
utilization	O
of	O
the	O
computing	O
resources	O
inside	O
the	O
network	O
.	O
	
This	O
was	O
achieved	O
by	O
a	O
carefully	O
crafted	O
design	O
that	O
allows	O
for	O
increasing	O
the	O
depth	O
and	O
width	O
of	O
the	O
network	O
while	O
keeping	O
the	O
computational	O
budget	O
constant	O
.	O
	
To	O
optimize	O
quality	B-Metric
,	O
the	O
architectural	O
decisions	O
were	O
based	O
on	O
the	O
Hebbian	B-Method
principle	I-Method
and	O
the	O
intuition	B-Method
of	I-Method
multi	I-Method
-	I-Method
scale	I-Method
processing	I-Method
.	O
	
One	O
particular	O
incarnation	O
used	O
in	O
our	O
submission	O
for	O
ILSVRCâ14	B-Task
is	O
called	O
GoogLeNet	B-Method
,	O
a	O
22	B-Method
layers	I-Method
deep	I-Method
network	I-Method
,	O
the	O
quality	O
of	O
which	O
is	O
assessed	O
in	O
the	O
context	O
of	O
classification	B-Task
and	O
detection	B-Task
.	O
	
parskip	O
[	O
]	O
	
section	O
:	O
Introduction	O
	
In	O
the	O
last	O
three	O
years	O
,	O
mainly	O
due	O
to	O
the	O
advances	O
of	O
deep	B-Method
learning	I-Method
,	O
more	O
concretely	O
convolutional	B-Method
networks	I-Method
,	O
the	O
quality	O
of	O
image	B-Task
recognition	I-Task
and	O
object	B-Task
detection	I-Task
has	O
been	O
progressing	O
at	O
a	O
dramatic	O
pace	O
.	O
	
One	O
encouraging	O
news	O
is	O
that	O
most	O
of	O
this	O
progress	O
is	O
not	O
just	O
the	O
result	O
of	O
more	O
powerful	O
hardware	O
,	O
larger	O
datasets	O
and	O
bigger	O
models	O
,	O
but	O
mainly	O
a	O
consequence	O
of	O
new	O
ideas	O
,	O
algorithms	O
and	O
improved	O
network	B-Method
architectures	I-Method
.	O
	
No	O
new	O
data	O
sources	O
were	O
used	O
,	O
for	O
example	O
,	O
by	O
the	O
top	O
entries	O
in	O
the	O
ILSVRC	B-Task
2014	I-Task
competition	I-Task
besides	O
the	O
classification	B-Task
dataset	O
of	O
the	O
same	O
competition	O
for	O
detection	B-Task
purposes	O
.	O
	
Our	O
GoogLeNet	B-Method
submission	I-Method
to	O
ILSVRC	B-Task
2014	I-Task
actually	O
uses	O
fewer	O
parameters	O
than	O
the	O
winning	O
architecture	O
of	O
Krizhevsky	O
et	O
al	O
from	O
two	O
years	O
ago	O
,	O
while	O
being	O
significantly	O
more	O
accurate	B-Metric
.	O
	
The	O
biggest	O
gains	O
in	O
object	O
-	O
detection	B-Task
have	O
not	O
come	O
from	O
the	O
utilization	O
of	O
deep	B-Method
networks	I-Method
alone	O
or	O
bigger	B-Method
models	I-Method
,	O
but	O
from	O
the	O
synergy	O
of	O
deep	B-Method
architectures	I-Method
and	O
classical	O
computer	B-Method
vision	I-Method
,	O
like	O
the	O
R	B-Method
-	I-Method
CNN	I-Method
algorithm	I-Method
by	O
Girshick	O
et	O
al	O
.	O
	
Another	O
notable	O
factor	O
is	O
that	O
with	O
the	O
ongoing	O
traction	O
of	O
mobile	B-Task
and	I-Task
embedded	I-Task
computing	I-Task
,	O
the	O
efficiency	O
of	O
our	O
algorithms	O
–	O
especially	O
their	O
power	O
and	O
memory	B-Metric
use	I-Metric
–	O
gains	O
importance	O
.	O
	
It	O
is	O
noteworthy	O
that	O
the	O
considerations	O
leading	O
to	O
the	O
design	O
of	O
the	O
deep	B-Method
architecture	I-Method
presented	O
in	O
this	O
paper	O
included	O
this	O
factor	O
rather	O
than	O
having	O
a	O
sheer	O
fixation	O
on	O
accuracy	B-Metric
numbers	I-Metric
.	O
	
For	O
most	O
of	O
the	O
experiments	O
,	O
the	O
models	O
were	O
designed	O
to	O
keep	O
a	O
computational	O
budget	O
of	O
billion	O
	
multiply	O
-	O
adds	O
at	O
inference	O
time	O
,	O
so	O
that	O
the	O
they	O
do	O
not	O
end	O
up	O
to	O
be	O
a	O
purely	O
academic	O
curiosity	O
,	O
but	O
could	O
be	O
put	O
to	O
real	O
world	O
use	O
,	O
even	O
on	O
large	O
datasets	O
,	O
at	O
a	O
reasonable	O
cost	O
.	O
	
In	O
this	O
paper	O
,	O
we	O
will	O
focus	O
on	O
an	O
efficient	O
deep	B-Method
neural	I-Method
network	I-Method
architecture	I-Method
for	O
computer	B-Task
vision	I-Task
,	O
codenamed	O
âInceptionâ	O
,	O
which	O
derives	O
its	O
name	O
from	O
the	O
âNetwork	O
in	O
networkâ	O
paper	O
by	O
Lin	O
et	O
al	O
in	O
conjunction	O
with	O
the	O
famous	O
“	O
	
we	O
need	O
to	O
go	O
deeper	O
”	O
internet	O
meme	O
.	O
	
In	O
our	O
case	O
,	O
the	O
word	O
“	O
deep	O
”	O
is	O
used	O
in	O
two	O
different	O
meanings	O
:	O
first	O
of	O
all	O
,	O
in	O
the	O
sense	O
that	O
we	O
introduce	O
a	O
new	O
level	O
of	O
organization	O
in	O
the	O
form	O
of	O
the	O
“	O
Inception	B-Method
module	I-Method
”	O
and	O
also	O
in	O
the	O
more	O
direct	O
sense	O
of	O
increased	O
network	O
depth	O
.	O
	
In	O
general	O
,	O
one	O
can	O
view	O
the	O
Inception	B-Method
model	I-Method
as	O
a	O
logical	O
culmination	O
of	O
while	O
taking	O
inspiration	O
and	O
guidance	O
from	O
the	O
theoretical	O
work	O
by	O
Arora	O
et	O
al	O
.	O
	
The	O
benefits	O
of	O
the	O
architecture	O
are	O
experimentally	O
verified	O
on	O
the	O
ILSVRC	O
2014	O
classification	B-Task
and	O
detection	B-Task
challenges	O
,	O
on	O
which	O
it	O
significantly	O
outperforms	O
the	O
current	O
state	O
of	O
the	O
art	O
.	O
	
section	O
:	O
Related	O
Work	O
	
Starting	O
with	O
LeNet	B-Method
-	I-Method
5	I-Method
,	O
convolutional	B-Method
neural	I-Method
networks	I-Method
(	O
CNN	B-Method
)	O
have	O
typically	O
had	O
a	O
standard	O
structure	O
–	O
stacked	B-Method
convolutional	I-Method
layers	I-Method
(	O
optionally	O
followed	O
by	O
contrast	B-Method
normalization	I-Method
and	O
max	B-Method
-	I-Method
pooling	I-Method
)	O
are	O
followed	O
by	O
one	O
or	O
more	O
fully	B-Method
-	I-Method
connected	I-Method
layers	I-Method
.	O
	
Variants	O
of	O
this	O
basic	O
design	O
are	O
prevalent	O
in	O
the	O
image	O
classification	B-Task
literature	O
and	O
have	O
yielded	O
the	O
best	O
results	O
to	O
-	O
date	O
on	O
MNIST	O
,	O
CIFAR	O
and	O
most	O
notably	O
on	O
the	O
ImageNet	O
classification	B-Task
challenge	O
.	O
	
Â	O
For	O
larger	O
datasets	O
such	O
as	O
Imagenet	B-Material
,	O
the	O
recent	O
trend	O
has	O
been	O
to	O
increase	O
the	O
number	O
of	O
layers	O
and	O
layer	O
size	O
,	O
while	O
using	O
dropout	B-Method
to	O
address	O
the	O
problem	O
of	O
overfitting	B-Task
.	O
	
Despite	O
concerns	O
that	O
max	B-Method
-	I-Method
pooling	I-Method
layers	I-Method
result	O
in	O
loss	O
of	O
accurate	B-Metric
spatial	O
information	O
,	O
the	O
same	O
convolutional	B-Method
network	I-Method
architecture	I-Method
as	O
has	O
also	O
been	O
successfully	O
employed	O
for	O
localization	B-Task
,	O
object	B-Task
detection	I-Task
and	O
human	B-Task
pose	I-Task
estimation	I-Task
.	O
	
Inspired	O
by	O
a	O
neuroscience	B-Method
model	I-Method
of	O
the	O
primate	O
visual	O
cortex	O
,	O
Serre	O
et	O
al	O
.	O
use	O
a	O
series	O
of	O
fixed	B-Method
Gabor	I-Method
filters	I-Method
of	O
different	O
sizes	O
in	O
order	O
to	O
handle	O
multiple	O
scales	O
,	O
similarly	O
to	O
the	O
Inception	B-Method
model	I-Method
.	O
	
However	O
,	O
contrary	O
to	O
the	O
fixed	B-Method
2	I-Method
-	I-Method
layer	I-Method
deep	I-Method
model	I-Method
of	O
,	O
all	O
filters	O
in	O
the	O
Inception	B-Method
model	I-Method
are	O
learned	O
.	O
	
Furthermore	O
,	O
Inception	B-Method
layers	O
are	O
repeated	O
many	O
times	O
,	O
leading	O
to	O
a	O
22	B-Method
-	I-Method
layer	I-Method
deep	I-Method
model	I-Method
in	O
the	O
case	O
of	O
the	O
GoogLeNet	B-Method
model	I-Method
.	O
	
Network	B-Task
-	I-Task
in	I-Task
-	I-Task
Network	I-Task
is	O
an	O
approach	O
proposed	O
by	O
Lin	O
et	O
al	O
.	O
	
in	O
order	O
to	O
increase	O
the	O
representational	B-Method
power	I-Method
of	O
neural	B-Method
networks	I-Method
.	O
	
When	O
applied	O
to	O
convolutional	B-Method
layers	I-Method
,	O
the	O
method	O
could	O
be	O
viewed	O
as	O
additional	O
convolutional	O
layers	O
followed	O
typically	O
by	O
the	O
rectified	B-Method
linear	I-Method
activation	I-Method
.	O
	
This	O
enables	O
it	O
to	O
be	O
easily	O
integrated	O
in	O
the	O
current	O
CNN	B-Method
pipelines	I-Method
.	O
	
We	O
use	O
this	O
approach	O
heavily	O
in	O
our	O
architecture	O
.	O
	
However	O
,	O
in	O
our	O
setting	O
,	O
convolutions	B-Method
have	O
dual	O
purpose	O
:	O
most	O
critically	O
,	O
they	O
are	O
used	O
mainly	O
as	O
dimension	B-Method
reduction	I-Method
modules	I-Method
to	O
remove	O
computational	O
bottlenecks	O
,	O
that	O
would	O
otherwise	O
limit	O
the	O
size	O
of	O
our	O
networks	O
.	O
	
Â	O
	
This	O
allows	O
for	O
not	O
just	O
increasing	O
the	O
depth	O
,	O
but	O
also	O
the	O
width	O
of	O
our	O
networks	O
without	O
significant	O
performance	O
penalty	O
.	O
	
The	O
current	O
leading	O
approach	O
for	O
object	B-Task
detection	I-Task
is	O
the	O
Regions	B-Method
with	I-Method
Convolutional	I-Method
Neural	I-Method
Networks	I-Method
(	O
R	B-Method
-	I-Method
CNN	I-Method
)	O
proposed	O
by	O
Girshick	O
et	O
al	O
.	O
.	O
	
R	B-Method
-	I-Method
CNN	I-Method
decomposes	O
the	O
overall	O
detection	B-Task
problem	O
into	O
two	O
subproblems	O
:	O
to	O
first	O
utilize	O
low	O
-	O
level	O
cues	O
such	O
as	O
color	O
and	O
superpixel	O
consistency	O
for	O
potential	O
object	O
proposals	O
in	O
a	O
category	O
-	O
agnostic	O
fashion	O
,	O
and	O
to	O
then	O
use	O
CNN	B-Method
classifiers	I-Method
to	O
identify	O
object	O
categories	O
at	O
those	O
locations	O
.	O
	
Such	O
a	O
two	O
stage	O
approach	O
leverages	O
the	O
accuracy	B-Metric
of	O
bounding	B-Task
box	I-Task
segmentation	I-Task
with	O
low	O
-	O
level	O
cues	O
,	O
as	O
well	O
as	O
the	O
highly	O
powerful	O
classification	B-Task
power	O
of	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
CNNs	B-Method
.	O
	
We	O
adopted	O
a	O
similar	O
pipeline	O
in	O
our	O
detection	B-Task
submissions	O
,	O
but	O
have	O
explored	O
enhancements	O
in	O
both	O
stages	O
,	O
such	O
as	O
multi	B-Method
-	I-Method
box	I-Method
prediction	I-Method
for	O
higher	O
object	B-Task
bounding	I-Task
box	I-Task
recall	I-Task
,	O
and	O
ensemble	B-Method
approaches	I-Method
for	O
better	O
categorization	B-Task
of	I-Task
bounding	I-Task
box	I-Task
proposals	I-Task
.	O
	
section	O
:	O
Motivation	O
and	O
High	O
Level	O
Considerations	O
	
The	O
most	O
straightforward	O
way	O
of	O
improving	O
the	O
performance	O
of	O
deep	B-Method
neural	I-Method
networks	I-Method
is	O
by	O
increasing	O
their	O
size	O
.	O
	
This	O
includes	O
both	O
increasing	O
the	O
depth	O
–	O
the	O
number	O
of	O
levels	O
–	O
of	O
the	O
network	O
and	O
its	O
width	O
:	O
the	O
number	O
of	O
units	O
at	O
each	O
level	O
.	O
	
This	O
is	O
as	O
an	O
easy	O
and	O
safe	O
way	O
of	O
training	O
higher	O
quality	O
models	O
,	O
especially	O
given	O
the	O
availability	O
of	O
a	O
large	O
amount	O
of	O
labeled	O
training	O
data	O
.	O
	
However	O
this	O
simple	O
solution	O
comes	O
with	O
two	O
major	O
drawbacks	O
.	O
	
Bigger	O
size	O
typically	O
means	O
a	O
larger	O
number	O
of	O
parameters	O
,	O
which	O
makes	O
the	O
enlarged	B-Method
network	I-Method
more	O
prone	O
to	O
overfitting	O
,	O
especially	O
if	O
the	O
number	O
of	O
labeled	O
examples	O
in	O
the	O
training	O
set	O
is	O
limited	O
.	O
	
This	O
can	O
become	O
a	O
major	O
bottleneck	O
,	O
since	O
the	O
creation	O
of	O
high	O
quality	O
training	O
sets	O
can	O
be	O
tricky	O
and	O
expensive	O
,	O
especially	O
if	O
expert	O
human	B-Metric
raters	I-Metric
are	O
necessary	O
to	O
distinguish	O
between	O
fine	O
-	O
grained	O
visual	O
categories	O
like	O
those	O
in	O
ImageNet	B-Material
(	O
even	O
in	O
the	O
1000	O
-	O
class	O
ILSVRC	O
subset	O
)	O
as	O
demonstrated	O
by	O
Figure	O
[	O
reference	O
]	O
.	O
	
Another	O
drawback	O
of	O
uniformly	O
increased	O
network	O
size	O
is	O
the	O
dramatically	O
increased	O
use	O
of	O
computational	O
resources	O
.	O
	
For	O
example	O
,	O
in	O
a	O
deep	B-Task
vision	I-Task
network	I-Task
,	O
if	O
two	O
convolutional	B-Method
layers	I-Method
are	O
chained	O
,	O
any	O
uniform	O
increase	O
in	O
the	O
number	O
of	O
their	O
filters	O
results	O
in	O
a	O
quadratic	O
increase	O
of	O
computation	B-Task
.	O
	
If	O
the	O
added	O
capacity	O
is	O
used	O
inefficiently	O
(	O
for	O
example	O
,	O
if	O
most	O
weights	O
end	O
up	O
to	O
be	O
close	O
to	O
zero	O
)	O
,	O
then	O
a	O
lot	O
of	O
computation	O
is	O
wasted	O
.	O
	
Since	O
in	O
practice	O
the	O
computational	O
budget	O
is	O
always	O
finite	O
,	O
an	O
efficient	O
distribution	O
of	O
computing	O
resources	O
is	O
preferred	O
to	O
an	O
indiscriminate	O
increase	O
of	O
size	O
,	O
even	O
when	O
the	O
main	O
objective	O
is	O
to	O
increase	O
the	O
quality	O
of	O
results	O
.	O
	
The	O
fundamental	O
way	O
of	O
solving	O
both	O
issues	O
would	O
be	O
by	O
ultimately	O
moving	O
from	O
fully	B-Method
connected	I-Method
to	O
sparsely	B-Method
connected	I-Method
architectures	I-Method
,	O
even	O
inside	O
the	O
convolutions	B-Method
.	O
	
Besides	O
mimicking	O
biological	B-Method
systems	I-Method
,	O
this	O
would	O
also	O
have	O
the	O
advantage	O
of	O
firmer	O
theoretical	O
underpinnings	O
due	O
to	O
the	O
groundbreaking	O
work	O
of	O
Arora	O
et	O
al	O
.	O
.	O
	
Their	O
main	O
result	O
states	O
that	O
if	O
the	O
probability	O
distribution	O
of	O
the	O
data	O
-	O
set	O
is	O
representable	O
by	O
a	O
large	O
,	O
very	O
sparse	B-Method
deep	I-Method
neural	I-Method
network	I-Method
,	O
then	O
the	O
optimal	O
network	B-Method
topology	I-Method
can	O
be	O
constructed	O
layer	O
by	O
layer	O
by	O
analyzing	O
the	O
correlation	O
statistics	O
of	O
the	O
activations	O
of	O
the	O
last	O
layer	O
and	O
clustering	B-Method
neurons	I-Method
with	O
highly	O
correlated	O
outputs	O
.	O
	
Although	O
the	O
strict	O
mathematical	O
proof	O
requires	O
very	O
strong	O
conditions	O
,	O
the	O
fact	O
that	O
this	O
statement	O
resonates	O
with	O
the	O
well	O
known	O
Hebbian	B-Method
principle	I-Method
–	O
neurons	O
that	O
fire	O
together	O
,	O
wire	O
together	O
–	O
suggests	O
that	O
the	O
underlying	O
idea	O
is	O
applicable	O
even	O
under	O
less	O
strict	O
conditions	O
,	O
in	O
practice	O
.	O
	
On	O
the	O
downside	O
,	O
todayâs	O
computing	B-Task
infrastructures	I-Task
are	O
very	O
inefficient	O
when	O
it	O
comes	O
to	O
numerical	B-Task
calculation	I-Task
on	O
non	O
-	O
uniform	O
sparse	O
data	O
structures	O
.	O
	
Even	O
if	O
the	O
number	O
of	O
arithmetic	O
operations	O
is	O
reduced	O
by	O
,	O
the	O
overhead	O
of	O
lookups	O
and	O
cache	O
misses	O
is	O
so	O
dominant	O
that	O
switching	O
to	O
sparse	O
matrices	O
would	O
not	O
pay	O
off	O
.	O
	
The	O
gap	O
is	O
widened	O
even	O
further	O
by	O
the	O
use	O
of	O
steadily	O
improving	O
,	O
highly	O
tuned	O
,	O
numerical	B-Method
libraries	I-Method
that	O
allow	O
for	O
extremely	O
fast	O
dense	B-Task
matrix	I-Task
multiplication	I-Task
,	O
exploiting	O
the	O
minute	O
details	O
of	O
the	O
underlying	O
CPU	O
or	O
GPU	O
hardware	O
.	O
	
Also	O
,	O
non	B-Method
-	I-Method
uniform	I-Method
sparse	I-Method
models	I-Method
require	O
more	O
sophisticated	O
engineering	O
and	O
computing	O
infrastructure	O
.	O
	
Most	O
current	O
vision	B-Method
oriented	I-Method
machine	I-Method
learning	I-Method
systems	I-Method
utilize	O
sparsity	O
in	O
the	O
spatial	O
domain	O
just	O
by	O
the	O
virtue	O
of	O
employing	O
convolutions	B-Method
.	O
	
However	O
,	O
convolutions	B-Method
are	O
implemented	O
as	O
collections	O
of	O
dense	O
connections	O
to	O
the	O
patches	O
in	O
the	O
earlier	O
layer	O
.	O
	
ConvNets	B-Method
have	O
traditionally	O
used	O
random	O
and	O
sparse	O
connection	O
tables	O
in	O
the	O
feature	O
dimensions	O
since	O
in	O
order	O
to	O
break	O
the	O
symmetry	O
and	O
improve	O
learning	B-Task
,	O
the	O
trend	O
changed	O
back	O
to	O
full	O
connections	O
with	O
in	O
order	O
to	O
better	O
optimize	O
parallel	B-Task
computing	I-Task
.	O
	
The	O
uniformity	O
of	O
the	O
structure	O
and	O
a	O
large	O
number	O
of	O
filters	O
and	O
greater	O
batch	O
size	O
allow	O
for	O
utilizing	O
efficient	O
dense	B-Task
computation	I-Task
.	O
	
This	O
raises	O
the	O
question	O
whether	O
there	O
is	O
any	O
hope	O
for	O
a	O
next	O
,	O
intermediate	O
step	O
:	O
an	O
architecture	O
that	O
makes	O
use	O
of	O
the	O
extra	O
sparsity	O
,	O
even	O
at	O
filter	O
level	O
,	O
as	O
suggested	O
by	O
the	O
theory	O
,	O
but	O
exploits	O
our	O
current	O
hardware	O
by	O
utilizing	O
computations	O
on	O
dense	O
matrices	O
.	O
	
The	O
vast	O
literature	O
on	O
sparse	B-Task
matrix	I-Task
computations	I-Task
(	O
e.g.	O
)	O
suggests	O
that	O
clustering	O
sparse	O
matrices	O
into	O
relatively	O
dense	O
submatrices	O
tends	O
to	O
give	O
state	O
of	O
the	O
art	O
practical	O
performance	O
for	O
sparse	B-Task
matrix	I-Task
multiplication	I-Task
.	O
	
It	O
does	O
not	O
seem	O
far	O
-	O
fetched	O
to	O
think	O
that	O
similar	O
methods	O
would	O
be	O
utilized	O
for	O
the	O
automated	B-Task
construction	I-Task
of	I-Task
non	I-Task
-	I-Task
uniform	I-Task
deep	I-Task
-	I-Task
learning	I-Task
architectures	I-Task
in	O
the	O
near	O
future	O
.	O
	
The	O
Inception	B-Method
architecture	O
started	O
out	O
as	O
a	O
case	O
study	O
of	O
the	O
first	O
author	O
for	O
assessing	O
the	O
hypothetical	O
output	O
of	O
a	O
sophisticated	O
network	B-Method
topology	I-Method
construction	I-Method
algorithm	I-Method
that	O
tries	O
to	O
approximate	O
a	O
sparse	O
structure	O
implied	O
by	O
for	O
vision	B-Method
networks	I-Method
and	O
covering	O
the	O
hypothesized	O
outcome	O
by	O
dense	O
,	O
readily	O
available	O
components	O
.	O
	
Despite	O
being	O
a	O
highly	O
speculative	O
undertaking	O
,	O
only	O
after	O
two	O
iterations	O
on	O
the	O
exact	O
choice	O
of	O
topology	O
,	O
we	O
could	O
already	O
see	O
modest	O
gains	O
against	O
the	O
reference	O
architecture	O
based	O
on	O
.	O
	
After	O
further	O
tuning	O
of	O
learning	B-Metric
rate	I-Metric
,	O
hyperparameters	B-Method
and	O
improved	O
training	O
methodology	O
,	O
we	O
established	O
that	O
the	O
resulting	O
Inception	B-Method
architecture	O
was	O
especially	O
useful	O
in	O
the	O
context	O
of	O
localization	B-Task
and	O
object	B-Task
detection	I-Task
as	O
the	O
base	O
network	O
for	O
and	O
.	O
	
Interestingly	O
,	O
while	O
most	O
of	O
the	O
original	O
architectural	O
choices	O
have	O
been	O
questioned	O
and	O
tested	O
thoroughly	O
,	O
they	O
turned	O
out	O
to	O
be	O
at	O
least	O
locally	O
optimal	O
.	O
	
One	O
must	O
be	O
cautious	O
though	O
:	O
although	O
the	O
proposed	O
architecture	O
has	O
become	O
a	O
success	O
for	O
computer	B-Task
vision	I-Task
,	O
it	O
is	O
still	O
questionable	O
whether	O
its	O
quality	O
can	O
be	O
attributed	O
to	O
the	O
guiding	O
principles	O
that	O
have	O
lead	O
to	O
its	O
construction	O
.	O
	
Making	O
sure	O
would	O
require	O
much	O
more	O
thorough	O
analysis	O
and	O
verification	B-Task
:	O
for	O
example	O
,	O
if	O
automated	B-Method
tools	I-Method
based	O
on	O
the	O
principles	O
described	O
below	O
would	O
find	O
similar	O
,	O
but	O
better	O
topology	O
for	O
the	O
vision	B-Task
networks	I-Task
.	O
	
The	O
most	O
convincing	O
proof	O
would	O
be	O
if	O
an	O
automated	B-Method
system	I-Method
would	O
create	O
network	O
topologies	O
resulting	O
in	O
similar	O
gains	O
in	O
other	O
domains	O
using	O
the	O
same	O
algorithm	O
but	O
with	O
very	O
differently	O
looking	O
global	O
architecture	O
.	O
	
At	O
very	O
least	O
,	O
the	O
initial	O
success	O
of	O
the	O
Inception	B-Method
architecture	O
yields	O
firm	O
motivation	O
for	O
exciting	O
future	O
work	O
in	O
this	O
direction	O
.	O
	
section	O
:	O
Architectural	O
Details	O
	
The	O
main	O
idea	O
of	O
the	O
Inception	B-Method
architecture	O
is	O
based	O
on	O
finding	O
out	O
how	O
an	O
optimal	O
local	O
sparse	O
structure	O
in	O
a	O
convolutional	B-Method
vision	I-Method
network	I-Method
can	O
be	O
approximated	O
and	O
covered	O
by	O
readily	O
available	O
dense	B-Method
components	I-Method
.	O
	
Note	O
that	O
assuming	O
translation	O
invariance	O
means	O
that	O
our	O
network	O
will	O
be	O
built	O
from	O
convolutional	B-Method
building	I-Method
blocks	I-Method
.	O
	
All	O
we	O
need	O
is	O
to	O
find	O
the	O
optimal	O
local	B-Method
construction	I-Method
and	O
to	O
repeat	O
it	O
spatially	O
.	O
	
Arora	O
et	O
al	O
.	O
suggests	O
a	O
layer	B-Method
-	I-Method
by	I-Method
layer	I-Method
construction	I-Method
in	O
which	O
one	O
should	O
analyze	O
the	O
correlation	O
statistics	O
of	O
the	O
last	O
layer	O
and	O
cluster	O
them	O
into	O
groups	O
of	O
units	O
with	O
high	O
correlation	O
.	O
	
These	O
clusters	O
form	O
the	O
units	O
of	O
the	O
next	O
layer	O
and	O
are	O
connected	O
to	O
the	O
units	O
in	O
the	O
previous	O
layer	O
.	O
	
We	O
assume	O
that	O
each	O
unit	O
from	O
the	O
earlier	O
layer	O
corresponds	O
to	O
some	O
region	O
of	O
the	O
input	O
image	O
and	O
these	O
units	O
are	O
grouped	O
into	O
filter	B-Method
banks	I-Method
.	O
	
In	O
the	O
lower	O
layers	O
(	O
the	O
ones	O
close	O
to	O
the	O
input	O
)	O
correlated	O
units	O
would	O
concentrate	O
in	O
local	O
regions	O
.	O
	
This	O
means	O
,	O
we	O
would	O
end	O
up	O
with	O
a	O
lot	O
of	O
clusters	O
concentrated	O
in	O
a	O
single	O
region	O
and	O
they	O
can	O
be	O
covered	O
by	O
a	O
layer	O
of	O
convolutions	B-Method
in	O
the	O
next	O
layer	O
,	O
as	O
suggested	O
in	O
.	O
	
However	O
,	O
one	O
can	O
also	O
expect	O
that	O
there	O
will	O
be	O
a	O
smaller	O
number	O
of	O
more	O
spatially	O
spread	O
out	O
clusters	O
that	O
can	O
be	O
covered	O
by	O
convolutions	B-Method
over	O
larger	O
patches	O
,	O
and	O
there	O
will	O
be	O
a	O
decreasing	O
number	O
of	O
patches	O
over	O
larger	O
and	O
larger	O
regions	O
.	O
	
In	O
order	O
to	O
avoid	O
patch	B-Task
-	I-Task
alignment	I-Task
issues	I-Task
,	O
current	O
incarnations	O
of	O
the	O
Inception	B-Method
architecture	O
are	O
restricted	O
to	O
filter	O
sizes	O
,	O
and	O
,	O
however	O
this	O
decision	O
was	O
based	O
more	O
on	O
convenience	O
rather	O
than	O
necessity	O
.	O
	
It	O
also	O
means	O
that	O
the	O
suggested	O
architecture	O
is	O
a	O
combination	O
of	O
all	O
those	O
layers	O
with	O
their	O
output	O
filter	B-Method
banks	I-Method
concatenated	O
into	O
a	O
single	O
output	O
vector	O
forming	O
the	O
input	O
of	O
the	O
next	O
stage	O
.	O
	
Additionally	O
,	O
since	O
pooling	B-Method
operations	I-Method
have	O
been	O
essential	O
for	O
the	O
success	O
in	O
current	O
state	O
of	O
the	O
art	O
convolutional	B-Method
networks	I-Method
,	O
it	O
suggests	O
that	O
adding	O
an	O
alternative	O
parallel	O
pooling	O
path	O
in	O
each	O
such	O
stage	O
should	O
have	O
additional	O
beneficial	O
effect	O
,	O
too	O
(	O
see	O
Figure	O
[	O
reference	O
]	O
)	O
.	O
	
As	O
these	O
“	O
Inception	B-Method
modules	O
”	O
are	O
stacked	O
on	O
top	O
of	O
each	O
other	O
,	O
their	O
output	O
correlation	B-Metric
statistics	I-Metric
are	O
bound	O
to	O
vary	O
:	O
as	O
features	O
of	O
higher	O
abstraction	O
are	O
captured	O
by	O
higher	O
layers	O
,	O
their	O
spatial	O
concentration	O
is	O
expected	O
to	O
decrease	O
suggesting	O
that	O
the	O
ratio	O
of	O
and	O
convolutions	O
should	O
increase	O
as	O
we	O
move	O
to	O
higher	O
layers	O
.	O
	
One	O
big	O
problem	O
with	O
the	O
above	O
modules	O
,	O
at	O
least	O
in	O
this	O
naïve	O
form	O
,	O
is	O
that	O
even	O
a	O
modest	O
number	O
of	O
convolutions	B-Method
can	O
be	O
prohibitively	O
expensive	O
on	O
top	O
of	O
a	O
convolutional	B-Method
layer	I-Method
with	O
a	O
large	O
number	O
of	O
filters	O
.	O
	
This	O
problem	O
becomes	O
even	O
more	O
pronounced	O
once	O
pooling	O
units	O
are	O
added	O
to	O
the	O
mix	O
:	O
their	O
number	O
of	O
output	O
filters	O
equals	O
to	O
the	O
number	O
of	O
filters	O
in	O
the	O
previous	O
stage	O
.	O
	
The	O
merging	O
of	O
the	O
output	O
of	O
the	O
pooling	B-Method
layer	I-Method
with	O
the	O
outputs	O
of	O
convolutional	B-Method
layers	I-Method
would	O
lead	O
to	O
an	O
inevitable	O
increase	O
in	O
the	O
number	O
of	O
outputs	O
from	O
stage	O
to	O
stage	O
.	O
	
Even	O
while	O
this	O
architecture	O
might	O
cover	O
the	O
optimal	O
sparse	O
structure	O
,	O
it	O
would	O
do	O
it	O
very	O
inefficiently	O
,	O
leading	O
to	O
a	O
computational	O
blow	O
up	O
within	O
a	O
few	O
stages	O
.	O
	
This	O
leads	O
to	O
the	O
second	O
idea	O
of	O
the	O
proposed	O
architecture	O
:	O
judiciously	O
applying	O
dimension	B-Method
reductions	I-Method
and	O
projections	O
wherever	O
the	O
computational	B-Metric
requirements	I-Metric
would	O
increase	O
too	O
much	O
otherwise	O
.	O
	
This	O
is	O
based	O
on	O
the	O
success	O
of	O
embeddings	B-Method
:	O
even	O
low	B-Method
dimensional	I-Method
embeddings	I-Method
might	O
contain	O
a	O
lot	O
of	O
information	O
about	O
a	O
relatively	O
large	O
image	O
patch	O
.	O
	
However	O
,	O
embeddings	O
represent	O
information	O
in	O
a	O
dense	O
,	O
compressed	O
form	O
and	O
compressed	O
information	O
is	O
harder	O
to	O
model	O
.	O
	
We	O
would	O
like	O
to	O
keep	O
our	O
representation	O
sparse	O
at	O
most	O
places	O
(	O
as	O
required	O
by	O
the	O
conditions	O
of	O
)	O
and	O
compress	O
the	O
signals	O
only	O
whenever	O
they	O
have	O
to	O
be	O
aggregated	O
en	O
masse	O
.	O
	
That	O
is	O
,	O
convolutions	B-Method
are	O
used	O
to	O
compute	O
reductions	O
before	O
the	O
expensive	O
and	O
convolutions	O
.	O
	
Besides	O
being	O
used	O
as	O
reductions	O
,	O
they	O
also	O
include	O
the	O
use	O
of	O
rectified	B-Method
linear	I-Method
activation	I-Method
which	O
makes	O
them	O
dual	O
-	O
purpose	O
.	O
	
The	O
final	O
result	O
is	O
depicted	O
in	O
Figure	O
[	O
reference	O
]	O
.	O
	
In	O
general	O
,	O
an	O
Inception	B-Method
network	O
is	O
a	O
network	O
consisting	O
of	O
modules	O
of	O
the	O
above	O
type	O
stacked	O
upon	O
each	O
other	O
,	O
with	O
occasional	O
max	B-Method
-	I-Method
pooling	I-Method
layers	I-Method
with	O
stride	O
2	O
to	O
halve	O
the	O
resolution	O
of	O
the	O
grid	O
.	O
	
For	O
technical	O
reasons	O
(	O
memory	B-Metric
efficiency	I-Metric
during	O
training	B-Task
)	O
,	O
it	O
seemed	O
beneficial	O
to	O
start	O
using	O
Inception	B-Method
modules	O
only	O
at	O
higher	O
layers	O
while	O
keeping	O
the	O
lower	O
layers	O
in	O
traditional	O
convolutional	B-Method
fashion	I-Method
.	O
	
This	O
is	O
not	O
strictly	O
necessary	O
,	O
simply	O
reflecting	O
some	O
infrastructural	O
inefficiencies	O
in	O
our	O
current	O
implementation	O
.	O
	
One	O
of	O
the	O
main	O
beneficial	O
aspects	O
of	O
this	O
architecture	O
is	O
that	O
it	O
allows	O
for	O
increasing	O
the	O
number	O
of	O
units	O
at	O
each	O
stage	O
significantly	O
without	O
an	O
uncontrolled	O
blow	O
-	O
up	O
in	O
computational	B-Metric
complexity	I-Metric
.	O
	
The	O
ubiquitous	O
use	O
of	O
dimension	B-Method
reduction	I-Method
allows	O
for	O
shielding	O
the	O
large	O
number	O
of	O
input	O
filters	O
of	O
the	O
last	O
stage	O
to	O
the	O
next	O
layer	O
,	O
first	O
reducing	O
their	O
dimension	O
before	O
convolving	O
over	O
them	O
with	O
a	O
large	O
patch	O
size	O
.	O
	
Another	O
practically	O
useful	O
aspect	O
of	O
this	O
design	O
is	O
that	O
it	O
aligns	O
with	O
the	O
intuition	O
that	O
visual	O
information	O
should	O
be	O
processed	O
at	O
various	O
scales	O
and	O
then	O
aggregated	O
so	O
that	O
the	O
next	O
stage	O
can	O
abstract	O
features	O
from	O
different	O
scales	O
simultaneously	O
.	O
	
The	O
improved	O
use	O
of	O
computational	O
resources	O
allows	O
for	O
increasing	O
both	O
the	O
width	O
of	O
each	O
stage	O
as	O
well	O
as	O
the	O
number	O
of	O
stages	O
without	O
getting	O
into	O
computational	O
difficulties	O
.	O
	
Another	O
way	O
to	O
utilize	O
the	O
inception	B-Method
architecture	I-Method
is	O
to	O
create	O
slightly	O
inferior	O
,	O
but	O
computationally	O
cheaper	O
versions	O
of	O
it	O
.	O
	
We	O
have	O
found	O
that	O
all	O
the	O
included	O
the	O
knobs	B-Method
and	O
levers	O
allow	O
for	O
a	O
controlled	O
balancing	O
of	O
computational	O
resources	O
that	O
can	O
result	O
in	O
networks	O
that	O
are	O
faster	O
than	O
similarly	O
performing	O
networks	O
with	O
non	O
-	O
Inception	B-Method
architecture	O
,	O
however	O
this	O
requires	O
careful	O
manual	O
design	O
at	O
this	O
point	O
.	O
	
section	O
:	O
GoogLeNet	O
	
We	O
chose	O
GoogLeNet	B-Method
as	O
our	O
team	O
-	O
name	O
in	O
the	O
ILSVRC14	B-Task
competition	I-Task
.	O
	
This	O
name	O
is	O
an	O
homage	O
to	O
Yann	O
LeCunâs	O
pioneering	O
LeNet	O
5	O
network	O
.	O
	
We	O
also	O
use	O
GoogLeNet	O
to	O
refer	O
to	O
the	O
particular	O
incarnation	O
of	O
the	O
Inception	B-Method
architecture	O
used	O
in	O
our	O
submission	O
for	O
the	O
competition	O
.	O
	
We	O
have	O
also	O
used	O
a	O
deeper	O
and	O
wider	O
Inception	B-Method
network	O
,	O
the	O
quality	O
of	O
which	O
was	O
slightly	O
inferior	O
,	O
but	O
adding	O
it	O
to	O
the	O
ensemble	O
seemed	O
to	O
improve	O
the	O
results	O
marginally	O
.	O
	
We	O
omit	O
the	O
details	O
of	O
that	O
network	O
,	O
since	O
our	O
experiments	O
have	O
shown	O
that	O
the	O
influence	O
of	O
the	O
exact	O
architectural	O
parameters	O
is	O
relatively	O
minor	O
.	O
	
Here	O
,	O
the	O
most	O
successful	O
particular	O
instance	O
(	O
named	O
GoogLeNet	B-Method
)	O
is	O
described	O
in	O
Table	O
[	O
reference	O
]	O
for	O
demonstrational	O
purposes	O
.	O
	
The	O
exact	O
same	O
topology	O
(	O
trained	O
with	O
different	O
sampling	B-Method
methods	I-Method
)	O
was	O
used	O
for	O
6	O
out	O
of	O
the	O
7	O
models	O
in	O
our	O
ensemble	O
.	O
	
All	O
the	O
convolutions	B-Method
,	O
including	O
those	O
inside	O
the	O
Inception	B-Method
modules	O
,	O
use	O
rectified	B-Method
linear	I-Method
activation	I-Method
.	O
	
The	O
size	O
of	O
the	O
receptive	O
field	O
in	O
our	O
network	O
is	O
taking	O
RGB	O
color	O
channels	O
with	O
mean	B-Method
subtraction	I-Method
.	O
	
“	O
reduce	O
”	O
and	O
“	O
reduce	O
”	O
stands	O
for	O
the	O
number	O
of	O
filters	O
in	O
the	O
reduction	B-Method
layer	I-Method
used	O
before	O
the	O
and	B-Method
convolutions	I-Method
.	O
	
One	O
can	O
see	O
the	O
number	O
of	O
filters	O
in	O
the	O
projection	O
layer	O
after	O
the	O
built	O
-	O
in	O
max	B-Method
-	I-Method
pooling	I-Method
in	O
the	O
âpool	O
projâ	O
column	O
.	O
	
All	O
these	O
reduction	B-Method
/	I-Method
projection	I-Method
layers	I-Method
use	O
rectified	B-Method
linear	I-Method
activation	I-Method
as	O
well	O
.	O
	
The	O
network	O
was	O
designed	O
with	O
computational	B-Metric
efficiency	I-Metric
and	O
practicality	O
in	O
mind	O
,	O
so	O
that	O
inference	B-Task
can	O
be	O
run	O
on	O
individual	O
devices	O
including	O
even	O
those	O
with	O
limited	O
computational	O
resources	O
,	O
especially	O
with	O
low	O
-	O
memory	O
footprint	O
.	O
	
The	O
network	O
is	O
22	O
layers	O
deep	O
when	O
counting	O
only	O
layers	O
with	O
parameters	O
(	O
or	O
27	O
layers	O
if	O
we	O
also	O
count	O
pooling	O
)	O
.	O
	
The	O
overall	O
number	O
of	O
âlayersâ	O
	
(	O
independent	O
building	O
blocks	O
)	O
used	O
for	O
the	O
construction	O
of	O
the	O
network	O
is	O
about	O
100	O
.	O
	
However	O
this	O
number	O
depends	O
on	O
the	O
machine	B-Method
learning	I-Method
infrastructure	I-Method
system	I-Method
used	O
.	O
	
The	O
use	O
of	O
average	B-Method
pooling	I-Method
before	O
the	O
classifier	B-Method
is	O
based	O
on	O
,	O
although	O
our	O
implementation	O
differs	O
in	O
that	O
we	O
use	O
an	O
extra	O
linear	B-Method
layer	I-Method
.	O
	
This	O
enables	O
adapting	O
and	O
fine	O
-	O
tuning	O
our	O
networks	O
for	O
other	O
label	O
sets	O
easily	O
,	O
but	O
it	O
is	O
mostly	O
convenience	O
and	O
we	O
do	O
not	O
expect	O
it	O
to	O
have	O
a	O
major	O
effect	O
.	O
	
It	O
was	O
found	O
that	O
a	O
move	O
from	O
fully	B-Method
connected	I-Method
layers	I-Method
to	O
average	B-Method
pooling	I-Method
improved	O
the	O
top	B-Metric
-	I-Metric
1	I-Metric
accuracy	I-Metric
by	O
about	O
0.6	O
%	O
,	O
however	O
the	O
use	O
of	O
dropout	O
remained	O
essential	O
even	O
after	O
removing	O
the	O
fully	O
connected	O
layers	O
.	O
	
Given	O
the	O
relatively	O
large	O
depth	O
of	O
the	O
network	O
,	O
the	O
ability	O
to	O
propagate	O
gradients	O
back	O
through	O
all	O
the	O
layers	O
in	O
an	O
effective	O
manner	O
was	O
a	O
concern	O
.	O
	
One	O
interesting	O
insight	O
is	O
that	O
the	O
strong	O
performance	O
of	O
relatively	O
shallower	B-Method
networks	I-Method
on	O
this	O
task	O
suggests	O
that	O
the	O
features	O
produced	O
by	O
the	O
layers	O
in	O
the	O
middle	O
of	O
the	O
network	O
should	O
be	O
very	O
discriminative	O
.	O
	
By	O
adding	O
auxiliary	B-Method
classifiers	I-Method
connected	O
to	O
these	O
intermediate	O
layers	O
,	O
we	O
would	O
expect	O
to	O
encourage	O
discrimination	O
in	O
the	O
lower	O
stages	O
in	O
the	O
classifier	B-Method
,	O
increase	O
the	O
gradient	O
signal	O
that	O
gets	O
propagated	O
back	O
,	O
and	O
provide	O
additional	O
regularization	O
.	O
	
These	O
classifiers	O
take	O
the	O
form	O
of	O
smaller	B-Method
convolutional	I-Method
networks	I-Method
put	O
on	O
top	O
of	O
the	O
output	O
of	O
the	O
Inception	B-Method
(	O
4a	O
)	O
and	O
(	O
4d	O
)	O
modules	O
.	O
	
During	O
training	B-Task
,	O
their	O
loss	O
gets	O
added	O
to	O
the	O
total	O
loss	O
of	O
the	O
network	O
with	O
a	O
discount	O
weight	O
(	O
the	O
losses	O
of	O
the	O
auxiliary	B-Method
classifiers	I-Method
were	O
weighted	O
by	O
0.3	O
)	O
.	O
	
At	O
inference	O
time	O
,	O
these	O
auxiliary	B-Method
networks	I-Method
are	O
discarded	O
.	O
	
The	O
exact	O
structure	O
of	O
the	O
extra	B-Method
network	I-Method
on	O
the	O
side	O
,	O
including	O
the	O
auxiliary	B-Method
classifier	I-Method
,	O
is	O
as	O
follows	O
:	O
	
An	O
average	B-Method
pooling	I-Method
layer	I-Method
with	O
filter	O
size	O
and	O
stride	O
,	O
resulting	O
in	O
an	O
output	O
for	O
the	O
(	O
4a	O
)	O
,	O
and	O
for	O
the	O
(	O
4d	O
)	O
stage	O
.	O
	
A	O
convolution	B-Method
with	O
128	B-Method
filters	I-Method
for	O
dimension	B-Task
reduction	I-Task
and	O
rectified	B-Task
linear	I-Task
activation	I-Task
.	O
	
A	O
fully	B-Method
connected	I-Method
layer	I-Method
with	O
1024	O
units	O
and	O
rectified	B-Method
linear	I-Method
activation	I-Method
.	O
	
A	O
dropout	B-Method
layer	I-Method
with	O
70	O
%	O
ratio	O
of	O
dropped	O
outputs	O
.	O
	
A	O
linear	B-Method
layer	I-Method
with	O
softmax	O
loss	O
as	O
the	O
classifier	B-Method
(	O
predicting	O
the	O
same	O
1000	O
classes	O
as	O
the	O
main	O
classifier	B-Method
,	O
but	O
removed	O
at	O
inference	O
time	O
)	O
.	O
	
A	O
schematic	O
view	O
of	O
the	O
resulting	O
network	O
is	O
depicted	O
in	O
Figure	O
[	O
reference	O
]	O
.	O
	
section	O
:	O
Training	O
Methodology	O
	
Our	O
networks	O
were	O
trained	O
using	O
the	O
DistBelief	B-Method
distributed	I-Method
machine	I-Method
learning	I-Method
system	I-Method
using	O
modest	O
amount	O
of	O
model	O
and	O
data	O
-	O
parallelism	O
.	O
	
Although	O
we	O
used	O
CPU	B-Method
based	I-Method
implementation	I-Method
only	O
,	O
a	O
rough	O
estimate	O
suggests	O
that	O
the	O
GoogLeNet	B-Method
network	I-Method
could	O
be	O
trained	O
to	O
convergence	O
using	O
few	O
high	O
-	O
end	O
GPUs	O
within	O
a	O
week	O
,	O
the	O
main	O
limitation	O
being	O
the	O
memory	O
usage	O
.	O
	
Our	O
training	O
used	O
asynchronous	B-Method
stochastic	I-Method
gradient	I-Method
descent	I-Method
with	O
0.9	O
momentum	O
,	O
fixed	O
learning	O
rate	O
schedule	O
(	O
decreasing	O
the	O
learning	B-Metric
rate	I-Metric
by	O
4	O
%	O
every	O
8	O
epochs	O
)	O
.	O
	
Polyak	B-Method
averaging	I-Method
was	O
used	O
to	O
create	O
the	O
final	O
model	O
used	O
at	O
inference	O
time	O
.	O
	
Our	O
image	B-Method
sampling	I-Method
methods	I-Method
have	O
changed	O
substantially	O
over	O
the	O
months	O
leading	O
to	O
the	O
competition	O
,	O
and	O
already	O
converged	O
models	O
were	O
trained	O
on	O
with	O
other	O
options	O
,	O
sometimes	O
in	O
conjunction	O
with	O
changed	O
hyperparameters	O
,	O
like	O
dropout	O
and	O
learning	B-Metric
rate	I-Metric
,	O
so	O
it	O
is	O
hard	O
to	O
give	O
a	O
definitive	O
guidance	O
to	O
the	O
most	O
effective	O
single	O
way	O
to	O
train	O
these	O
networks	O
.	O
	
To	O
complicate	O
matters	O
further	O
,	O
some	O
of	O
the	O
models	O
were	O
mainly	O
trained	O
on	O
smaller	O
relative	O
crops	O
,	O
others	O
on	O
larger	O
ones	O
,	O
inspired	O
by	O
.	O
	
Still	O
,	O
one	O
prescription	O
that	O
was	O
verified	O
to	O
work	O
very	O
well	O
after	O
the	O
competition	O
includes	O
sampling	O
of	O
various	O
sized	O
patches	O
of	O
the	O
image	O
whose	O
size	O
is	O
distributed	O
evenly	O
between	O
8	O
%	O
and	O
100	O
%	O
of	O
the	O
image	O
area	O
and	O
whose	O
aspect	O
ratio	O
is	O
chosen	O
randomly	O
between	O
and	O
.	O
	
Also	O
,	O
we	O
found	O
that	O
the	O
photometric	O
distortions	O
by	O
Andrew	O
Howard	O
were	O
useful	O
to	O
combat	O
overfitting	O
to	O
some	O
extent	O
.	O
	
In	O
addition	O
,	O
we	O
started	O
to	O
use	O
random	B-Method
interpolation	I-Method
methods	I-Method
(	O
bilinear	O
,	O
area	O
,	O
nearest	O
neighbor	O
and	O
cubic	O
,	O
with	O
equal	O
probability	O
)	O
for	O
resizing	O
relatively	O
late	O
and	O
in	O
conjunction	O
with	O
other	O
hyperparameter	O
changes	O
,	O
so	O
we	O
could	O
not	O
tell	O
definitely	O
whether	O
the	O
final	O
results	O
were	O
affected	O
positively	O
by	O
their	O
use	O
.	O
	
section	O
:	O
ILSVRC	O
2014	O
Classification	B-Task
Challenge	I-Task
Setup	O
and	O
Results	O
	
The	O
ILSVRC	O
2014	O
classification	B-Task
challenge	O
involves	O
the	O
task	O
of	O
classifying	O
the	O
image	O
into	O
one	O
of	O
1000	O
leaf	O
-	O
node	O
categories	O
in	O
the	O
Imagenet	B-Material
hierarchy	O
.	O
	
There	O
are	O
about	O
1.2	O
million	O
images	O
for	O
training	O
,	O
50	O
,	O
000	O
for	O
validation	B-Task
and	O
100	O
,	O
000	O
images	O
for	O
testing	O
.	O
	
Each	O
image	O
is	O
associated	O
with	O
one	O
ground	O
truth	O
category	O
,	O
and	O
performance	O
is	O
measured	O
based	O
on	O
the	O
highest	O
scoring	O
classifier	B-Method
predictions	I-Method
.	O
	
Two	O
numbers	O
are	O
usually	O
reported	O
:	O
the	O
top	O
-	O
1	O
accuracy	B-Metric
rate	O
,	O
which	O
compares	O
the	O
ground	B-Metric
truth	I-Metric
against	O
the	O
first	O
predicted	O
class	O
,	O
and	O
the	O
top	B-Metric
-	I-Metric
5	I-Metric
error	I-Metric
rate	I-Metric
,	O
which	O
compares	O
the	O
ground	B-Metric
truth	I-Metric
against	O
the	O
first	O
5	O
predicted	O
classes	O
:	O
an	O
image	O
is	O
deemed	O
correctly	O
classified	O
if	O
the	O
ground	O
truth	O
is	O
among	O
the	O
top	O
-	O
5	O
,	O
regardless	O
of	O
its	O
rank	O
in	O
them	O
.	O
	
The	O
challenge	O
uses	O
the	O
top	B-Metric
-	I-Metric
5	I-Metric
error	I-Metric
rate	I-Metric
for	O
ranking	B-Task
purposes	I-Task
.	O
	
We	O
participated	O
in	O
the	O
challenge	O
with	O
no	O
external	O
data	O
used	O
for	O
training	O
.	O
	
In	O
addition	O
to	O
the	O
training	B-Method
techniques	I-Method
aforementioned	O
in	O
this	O
paper	O
,	O
we	O
adopted	O
a	O
set	O
of	O
techniques	O
during	O
testing	O
to	O
obtain	O
a	O
higher	O
performance	O
,	O
which	O
we	O
elaborate	O
below	O
.	O
	
We	O
independently	O
trained	O
7	O
versions	O
of	O
the	O
same	O
GoogLeNet	B-Method
model	I-Method
(	O
including	O
one	O
wider	O
version	O
)	O
,	O
and	O
performed	O
ensemble	B-Method
prediction	I-Method
with	O
them	O
.	O
	
These	O
models	O
were	O
trained	O
with	O
the	O
same	O
initialization	O
(	O
even	O
with	O
the	O
same	O
initial	O
weights	O
,	O
mainly	O
because	O
of	O
an	O
oversight	O
)	O
and	O
learning	B-Method
rate	I-Method
policies	I-Method
,	O
and	O
they	O
only	O
differ	O
in	O
sampling	B-Method
methodologies	I-Method
and	O
the	O
random	O
order	O
in	O
which	O
they	O
see	O
input	O
images	O
.	O
	
During	O
testing	O
,	O
we	O
adopted	O
a	O
more	O
aggressive	O
cropping	B-Method
approach	I-Method
than	O
that	O
of	O
Krizhevsky	O
et	O
al	O
.	O
.	O
	
Specifically	O
,	O
we	O
resize	O
the	O
image	O
to	O
4	O
scales	O
where	O
the	O
shorter	O
dimension	O
(	O
height	O
or	O
width	O
)	O
is	O
256	O
,	O
288	O
,	O
320	O
and	O
352	O
respectively	O
,	O
take	O
the	O
left	O
,	O
center	O
and	O
right	O
square	O
of	O
these	O
resized	O
images	O
(	O
in	O
the	O
case	O
of	O
portrait	O
images	O
,	O
we	O
take	O
the	O
top	O
,	O
center	O
and	O
bottom	O
squares	O
)	O
.	O
	
For	O
each	O
square	O
,	O
we	O
then	O
take	O
the	O
4	O
corners	O
and	O
the	O
center	O
crop	O
as	O
well	O
as	O
the	O
square	O
resized	O
to	O
,	O
and	O
their	O
mirrored	O
versions	O
.	O
	
This	O
results	O
in	O
crops	O
per	O
image	O
.	O
	
A	O
similar	O
approach	O
was	O
used	O
by	O
Andrew	O
Howard	O
in	O
the	O
previous	O
year	O
’s	O
entry	O
,	O
which	O
we	O
empirically	O
verified	O
to	O
perform	O
slightly	O
worse	O
than	O
the	O
proposed	O
scheme	O
.	O
	
We	O
note	O
that	O
such	O
aggressive	B-Method
cropping	I-Method
may	O
not	O
be	O
necessary	O
in	O
real	O
applications	O
,	O
as	O
the	O
benefit	O
of	O
more	O
crops	O
becomes	O
marginal	O
after	O
a	O
reasonable	O
number	O
of	O
crops	O
are	O
present	O
(	O
as	O
we	O
will	O
show	O
later	O
on	O
)	O
.	O
	
The	O
softmax	O
probabilities	O
are	O
averaged	O
over	O
multiple	O
crops	O
and	O
over	O
all	O
the	O
individual	O
classifiers	B-Method
to	O
obtain	O
the	O
final	O
prediction	B-Task
.	O
	
In	O
our	O
experiments	O
we	O
analyzed	O
alternative	O
approaches	O
on	O
the	O
validation	O
data	O
,	O
such	O
as	O
max	B-Method
pooling	I-Method
over	I-Method
crops	I-Method
and	O
averaging	B-Method
over	I-Method
classifiers	I-Method
,	O
but	O
they	O
lead	O
to	O
inferior	O
performance	O
than	O
the	O
simple	O
averaging	B-Method
.	O
	
In	O
the	O
remainder	O
of	O
this	O
paper	O
,	O
we	O
analyze	O
the	O
multiple	O
factors	O
that	O
contribute	O
to	O
the	O
overall	O
performance	O
of	O
the	O
final	O
submission	O
.	O
	
Our	O
final	O
submission	O
in	O
the	O
challenge	O
obtains	O
a	O
top	B-Metric
-	I-Metric
5	I-Metric
error	I-Metric
of	O
6.67	O
%	O
on	O
both	O
the	O
validation	O
and	O
testing	O
data	O
,	O
ranking	O
the	O
first	O
among	O
other	O
participants	O
.	O
	
This	O
is	O
a	O
56.5	O
%	O
relative	O
reduction	O
compared	O
to	O
the	O
SuperVision	B-Method
approach	I-Method
in	O
2012	O
,	O
and	O
about	O
40	O
%	O
relative	O
reduction	O
compared	O
to	O
the	O
previous	O
year	O
’s	O
best	O
approach	O
(	O
Clarifai	O
)	O
,	O
both	O
of	O
which	O
used	O
external	O
data	O
for	O
training	O
the	O
classifiers	B-Method
.	O
	
The	O
following	O
table	O
shows	O
the	O
statistics	O
of	O
some	O
of	O
the	O
top	O
-	O
performing	O
approaches	O
.	O
	
We	O
also	O
analyze	O
and	O
report	O
the	O
performance	O
of	O
multiple	O
testing	O
choices	O
,	O
by	O
varying	O
the	O
number	O
of	O
models	O
and	O
the	O
number	O
of	O
crops	O
used	O
when	O
predicting	O
an	O
image	O
in	O
the	O
following	O
table	O
.	O
	
When	O
we	O
use	O
one	O
model	O
,	O
we	O
chose	O
the	O
one	O
with	O
the	O
lowest	O
top	B-Metric
-	I-Metric
1	I-Metric
error	I-Metric
rate	I-Metric
on	O
the	O
validation	O
data	O
.	O
	
All	O
numbers	O
are	O
reported	O
on	O
the	O
validation	O
dataset	O
in	O
order	O
to	O
not	O
overfit	O
to	O
the	O
testing	O
data	O
statistics	O
.	O
	
section	O
:	O
ILSVRC	B-Task
2014	I-Task
Detection	I-Task
Challenge	I-Task
Setup	O
and	O
Results	O
	
The	O
ILSVRC	O
detection	B-Task
task	O
is	O
to	O
produce	O
bounding	O
boxes	O
around	O
objects	O
in	O
images	O
among	O
200	O
possible	O
classes	O
.	O
	
Detected	O
objects	O
count	O
as	O
correct	O
if	O
they	O
match	O
the	O
class	O
of	O
the	O
groundtruth	O
and	O
their	O
bounding	O
boxes	O
overlap	O
by	O
at	O
least	O
50	O
%	O
(	O
using	O
the	O
Jaccard	B-Metric
index	I-Metric
)	O
.	O
	
Extraneous	O
detections	O
count	O
as	O
false	O
positives	O
and	O
are	O
penalized	O
.	O
	
Contrary	O
to	O
the	O
classification	B-Task
task	O
,	O
each	O
image	O
may	O
contain	O
many	O
objects	O
or	O
none	O
,	O
and	O
their	O
scale	O
may	O
vary	O
from	O
large	O
to	O
tiny	O
.	O
	
Results	O
are	O
reported	O
using	O
the	O
mean	B-Metric
average	I-Metric
precision	I-Metric
(	O
mAP	B-Metric
)	O
.	O
	
The	O
approach	O
taken	O
by	O
GoogLeNet	B-Method
for	O
detection	B-Task
is	O
similar	O
to	O
the	O
R	B-Method
-	I-Method
CNN	I-Method
by	O
,	O
but	O
is	O
augmented	O
with	O
the	O
Inception	B-Method
model	I-Method
as	O
the	O
region	B-Method
classifier	I-Method
.	O
	
Additionally	O
,	O
the	O
region	B-Method
proposal	I-Method
step	I-Method
is	O
improved	O
by	O
combining	O
the	O
Selective	B-Method
Search	I-Method
approach	I-Method
with	O
multi	B-Method
-	I-Method
box	I-Method
predictions	I-Method
for	O
higher	O
object	B-Metric
bounding	I-Metric
box	I-Metric
recall	I-Metric
.	O
	
In	O
order	O
to	O
cut	O
down	O
the	O
number	O
of	O
false	O
positives	O
,	O
the	O
superpixel	O
size	O
was	O
increased	O
by	O
.	O
	
This	O
halves	O
the	O
proposals	O
coming	O
from	O
the	O
selective	B-Method
search	I-Method
algorithm	I-Method
.	O
	
We	O
added	O
back	O
200	O
region	O
proposals	O
coming	O
from	O
multi	O
-	O
box	O
resulting	O
,	O
in	O
total	O
,	O
in	O
about	O
60	O
%	O
of	O
the	O
proposals	O
used	O
by	O
,	O
while	O
increasing	O
the	O
coverage	B-Metric
from	O
92	O
%	O
to	O
93	O
%	O
.	O
	
The	O
overall	O
effect	O
of	O
cutting	O
the	O
number	O
of	O
proposals	O
with	O
increased	O
coverage	O
is	O
a	O
1	O
%	O
improvement	O
of	O
the	O
mean	B-Metric
average	I-Metric
precision	I-Metric
for	O
the	O
single	O
model	O
case	O
.	O
	
Finally	O
,	O
we	O
use	O
an	O
ensemble	O
of	O
6	O
ConvNets	B-Method
when	O
classifying	O
each	O
region	O
which	O
improves	O
results	O
from	O
40	O
%	O
to	O
43.9	O
%	O
accuracy	B-Metric
.	O
	
Note	O
that	O
contrary	O
to	O
R	B-Method
-	I-Method
CNN	I-Method
,	O
we	O
did	O
not	O
use	O
bounding	B-Method
box	I-Method
regression	I-Method
due	O
to	O
lack	O
of	O
time	O
.	O
	
We	O
first	O
report	O
the	O
top	O
detection	B-Task
results	O
and	O
show	O
the	O
progress	O
since	O
the	O
first	O
edition	O
of	O
the	O
detection	B-Task
task	O
.	O
	
Compared	O
to	O
the	O
2013	O
result	O
,	O
the	O
accuracy	B-Metric
has	O
almost	O
doubled	O
.	O
	
The	O
top	O
performing	O
teams	O
all	O
use	O
Convolutional	B-Method
Networks	I-Method
.	O
	
We	O
report	O
the	O
official	B-Metric
scores	I-Metric
in	O
Table	O
[	O
reference	O
]	O
and	O
common	O
strategies	O
for	O
each	O
team	O
:	O
the	O
use	O
of	O
external	O
data	O
,	O
ensemble	B-Method
models	I-Method
or	O
contextual	B-Method
models	I-Method
.	O
	
The	O
external	O
data	O
is	O
typically	O
the	O
ILSVRC12	B-Task
classification	I-Task
data	I-Task
for	O
pre	O
-	O
training	O
a	O
model	O
that	O
is	O
later	O
refined	O
on	O
the	O
detection	B-Task
data	O
.	O
	
Some	O
teams	O
also	O
mention	O
the	O
use	O
of	O
the	O
localization	B-Task
data	O
.	O
	
Since	O
a	O
good	O
portion	O
of	O
the	O
localization	B-Task
task	O
bounding	O
boxes	O
are	O
not	O
included	O
in	O
the	O
detection	B-Task
dataset	O
,	O
one	O
can	O
pre	O
-	O
train	O
a	O
general	B-Method
bounding	I-Method
box	I-Method
regressor	I-Method
with	O
this	O
data	O
the	O
same	O
way	O
classification	B-Task
is	O
used	O
for	O
pre	B-Task
-	I-Task
training	I-Task
.	O
	
The	O
GoogLeNet	O
entry	O
did	O
not	O
use	O
the	O
localization	B-Task
data	O
for	O
pretraining	B-Task
.	O
	
In	O
Table	O
[	O
reference	O
]	O
,	O
we	O
compare	O
results	O
using	O
a	O
single	O
model	O
only	O
.	O
	
The	O
top	O
performing	O
model	O
is	O
by	O
Deep	O
Insight	O
and	O
surprisingly	O
only	O
improves	O
by	O
0.3	O
points	O
with	O
an	O
ensemble	O
of	O
3	O
models	O
while	O
the	O
GoogLeNet	B-Method
obtains	O
significantly	O
stronger	O
results	O
with	O
the	O
ensemble	O
.	O
	
section	O
:	O
Conclusions	O
	
Our	O
results	O
seem	O
to	O
yield	O
a	O
solid	O
evidence	O
that	O
approximating	O
the	O
expected	O
optimal	O
sparse	O
structure	O
by	O
readily	O
available	O
dense	B-Method
building	I-Method
blocks	I-Method
is	O
a	O
viable	O
method	O
for	O
improving	O
neural	B-Method
networks	I-Method
for	O
computer	B-Task
vision	I-Task
.	O
	
The	O
main	O
advantage	O
of	O
this	O
method	O
is	O
a	O
significant	O
quality	B-Metric
gain	O
at	O
a	O
modest	O
increase	O
of	O
computational	B-Metric
requirements	I-Metric
compared	O
to	O
shallower	B-Method
and	I-Method
less	I-Method
wide	I-Method
networks	I-Method
.	O
	
Also	O
note	O
that	O
our	O
detection	B-Task
work	O
was	O
competitive	O
despite	O
of	O
neither	O
utilizing	O
context	O
nor	O
performing	O
bounding	B-Method
box	I-Method
regression	I-Method
and	O
this	O
fact	O
provides	O
further	O
evidence	O
of	O
the	O
strength	O
of	O
the	O
Inception	B-Method
architecture	O
.	O
	
Although	O
it	O
is	O
expected	O
that	O
similar	O
quality	O
of	O
result	O
can	O
be	O
achieved	O
by	O
much	O
more	O
expensive	O
networks	O
of	O
similar	O
depth	O
and	O
width	O
,	O
our	O
approach	O
yields	O
solid	O
evidence	O
that	O
moving	O
to	O
sparser	B-Method
architectures	I-Method
is	O
feasible	O
and	O
useful	O
idea	O
in	O
general	O
.	O
	
This	O
suggest	O
promising	O
future	O
work	O
towards	O
creating	O
sparser	O
and	O
more	O
refined	O
structures	O
in	O
automated	O
ways	O
on	O
the	O
basis	O
of	O
.	O
	
section	O
:	O
Acknowledgements	O
	
We	O
would	O
like	O
to	O
thank	O
Sanjeev	O
Arora	O
and	O
Aditya	O
Bhaskara	O
for	O
fruitful	O
discussions	O
on	O
.	O
	
Also	O
we	O
are	O
indebted	O
to	O
the	O
DistBelief	O
team	O
for	O
their	O
support	O
especially	O
to	O
Rajat	O
Monga	O
,	O
Jon	O
Shlens	O
,	O
Alex	O
Krizhevsky	O
,	O
Jeff	O
Dean	O
,	O
Ilya	O
Sutskever	O
and	O
Andrea	O
Frome	O
.	O
	
We	O
would	O
also	O
like	O
to	O
thank	O
to	O
Tom	O
Duerig	O
and	O
Ning	O
Ye	O
for	O
their	O
help	O
on	O
photometric	O
distortions	O
.	O
	
Also	O
our	O
work	O
would	O
not	O
have	O
been	O
possible	O
without	O
the	O
support	O
of	O
Chuck	O
Rosenberg	O
and	O
Hartwig	O
Adam	O
.	O
	
bibliography	O
:	O
References	O
	
Image	B-Task
Super	I-Task
-	I-Task
resolution	I-Task
via	O
Feature	B-Method
-	I-Method
augmented	I-Method
Random	I-Method
Forest	I-Method
	
section	O
:	O
	
Abstract	O
-	O
Recent	B-Method
random	I-Method
-	I-Method
forest	I-Method
(	O
RF	B-Method
)-	O
based	O
image	O
super	O
-	O
resolution	O
approaches	O
inherit	O
some	O
properties	O
from	O
dictionary	B-Method
-	I-Method
learning	I-Method
-	I-Method
based	I-Method
algorithms	I-Method
,	O
but	O
the	O
effectiveness	O
of	O
the	O
properties	O
in	O
RF	B-Method
is	O
overlooked	O
in	O
the	O
literature	O
.	O
	
In	O
this	O
paper	O
,	O
we	O
present	O
a	O
novel	O
feature	B-Method
-	I-Method
augmented	I-Method
random	I-Method
forest	I-Method
(	O
FARF	B-Method
)	O
for	O
image	B-Task
super	I-Task
-	I-Task
resolution	I-Task
,	O
where	O
the	O
conventional	O
gradient	B-Method
-	I-Method
based	I-Method
features	I-Method
are	O
augmented	O
with	O
gradient	O
magnitudes	O
and	O
different	O
feature	O
recipes	O
are	O
formulated	O
on	O
different	O
stages	O
in	O
an	O
RF	B-Method
.	O
	
The	O
advantages	O
of	O
our	O
method	O
are	O
that	O
,	O
firstly	O
,	O
the	O
dictionary	B-Method
-	I-Method
learning	I-Method
-	I-Method
based	I-Method
features	I-Method
are	O
enhanced	O
by	O
adding	O
gradient	O
magnitudes	O
,	O
based	O
on	O
the	O
observation	O
that	O
the	O
non	O
-	O
linear	O
gradient	O
magnitude	O
are	O
with	O
highly	O
discriminative	O
property	O
.	O
	
Secondly	O
,	O
generalized	O
locality	O
-	O
sensitive	O
hashing	O
(	O
LSH	B-Method
)	O
is	O
used	O
to	O
replace	O
principal	B-Method
component	I-Method
analysis	I-Method
(	O
PCA	B-Method
)	O
for	O
feature	B-Task
dimensionality	I-Task
reduction	I-Task
and	O
original	O
high	O
-	O
dimensional	O
features	O
are	O
employed	O
,	O
instead	O
of	O
the	O
compressed	O
ones	O
,	O
for	O
the	O
leaf	O
-	O
nodes	O
'	O
regressors	O
,	O
since	O
regressors	O
can	O
benefit	O
from	O
higher	O
dimensional	O
features	O
.	O
	
This	O
original	O
-	O
compressed	B-Method
coupled	I-Method
feature	I-Method
sets	I-Method
scheme	I-Method
unifies	O
the	O
unsupervised	O
LSH	B-Method
evaluation	O
on	O
both	O
image	B-Task
super	I-Task
-	I-Task
resolution	I-Task
and	O
content	B-Method
-	I-Method
based	I-Method
image	I-Method
retrieval	I-Method
(	O
CBIR	B-Method
)	O
.	O
	
Finally	O
,	O
we	O
present	O
a	O
generalized	B-Method
weighted	I-Method
ridge	I-Method
regression	I-Method
(	O
GWRR	B-Method
)	O
model	O
for	O
the	O
leaf	O
-	O
nodes	O
'	O
regressors	O
.	O
	
Experiment	O
results	O
on	O
several	O
public	O
benchmark	O
datasets	O
show	O
that	O
our	O
FARF	B-Method
method	O
can	O
achieve	O
an	O
average	O
gain	O
of	O
about	O
0.3	O
dB	O
,	O
compared	O
to	O
traditional	O
RF	B-Method
-	O
based	O
methods	O
.	O
	
Furthermore	O
,	O
a	O
fine	O
-	O
tuned	O
FARF	B-Method
model	O
can	O
compare	O
to	O
or	O
(	O
in	O
many	O
cases	O
)	O
outperform	O
some	O
recent	O
stateof	O
-	O
the	O
-	O
art	O
deep	B-Method
-	I-Method
learning	I-Method
-	I-Method
based	I-Method
algorithms	I-Method
.	O
	
section	O
:	O
INTRODUCTION	O
	
In	O
the	O
past	O
few	O
years	O
,	O
random	B-Method
forest	I-Method
(	O
RF	B-Method
)	O
[	O
reference	O
][	O
reference	O
]	O
as	O
a	O
machine	B-Method
-	I-Method
learning	I-Method
tool	I-Method
,	O
working	O
via	O
an	O
ensemble	B-Method
of	I-Method
multiple	I-Method
decision	I-Method
trees	I-Method
,	O
has	O
been	O
employed	O
for	O
efficient	O
classification	B-Task
or	I-Task
regression	I-Task
problems	I-Task
,	O
and	O
applied	O
to	O
a	O
large	O
variety	O
of	O
computer	B-Task
-	I-Task
vision	I-Task
applications	I-Task
,	O
such	O
as	O
object	B-Task
recognition	I-Task
[	O
reference	O
]	O
,	O
face	B-Task
alignment	I-Task
[	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
,	O
data	O
clustering	B-Method
[	O
reference	O
]	O
,	O
single	B-Task
image	I-Task
super	I-Task
-	I-Task
resolution	I-Task
(	O
SISR	B-Task
)	O
	
[	O
reference	O
][	O
reference	O
]	O
,	O
and	O
so	O
on	O
.	O
	
The	O
RF	B-Method
method	O
,	O
which	O
benefits	O
from	O
its	O
simple	O
implementation	O
of	O
binary	B-Method
trees	I-Method
,	O
has	O
been	O
widely	O
used	O
,	O
and	O
exhibits	O
a	O
number	O
of	O
merits	O
,	O
including	O
(	O
1	O
)	O
it	O
works	O
with	O
an	O
ensemble	B-Method
of	I-Method
multiple	I-Method
decision	I-Method
trees	I-Method
to	O
express	O
the	O
principle	O
that	O
"	O
two	O
heads	O
are	O
better	O
than	O
one	O
"	O
,	O
[	O
reference	O
]	O
it	O
is	O
easy	O
to	O
be	O
sped	O
up	O
with	O
parallel	B-Method
processing	I-Method
technology	I-Method
,	O
on	O
both	O
the	O
training	B-Task
and	I-Task
inference	I-Task
stages	I-Task
,	O
(	O
3	O
)	O
it	O
has	O
sub	B-Metric
-	I-Metric
linear	I-Metric
search	I-Metric
complexity	I-Metric
,	O
because	O
of	O
the	O
use	O
of	O
the	O
binary	O
tree	O
structure	O
,	O
(	O
4	O
)	O
the	O
bagging	B-Method
strategy	I-Method
for	O
feature	O
candidates	O
on	O
splitnodes	O
enable	O
it	O
to	O
handle	O
high	O
-	O
dimensional	O
features	O
and	O
avoid	O
over	O
-	O
fitting	O
on	O
regression	B-Task
,	O
and	O
(	O
5	O
)	O
the	O
clustering	B-Method
-	O
regression	O
scheme	O
employs	O
the	O
"	O
divide	B-Method
and	I-Method
conquer	I-Method
"	I-Method
strategy	I-Method
,	O
which	O
can	O
tackle	O
the	O
classification	B-Task
and	I-Task
regression	I-Task
tasks	I-Task
with	O
more	O
stable	O
performance	O
.	O
	
The	O
RF	B-Method
-	O
based	O
image	O
super	O
-	O
resolution	O
approach	O
can	O
be	O
considered	O
as	O
a	O
clustering	B-Method
/	O
classificationbased	B-Method
method	I-Method
,	O
as	O
shown	O
in	O
Fig	O
.	O
1	O
.	O
	
But	O
the	O
clustering	B-Method
and	O
regression	O
problems	O
in	O
RF	B-Method
require	O
with	O
different	O
discriminative	O
features	O
,	O
which	O
have	O
not	O
been	O
systematically	O
studied	O
in	O
existing	O
literature	O
.	O
	
Feature	B-Method
engineering	I-Method
has	O
been	O
a	O
research	O
hotspot	O
for	O
decades	O
.	O
	
Several	O
features	O
have	O
been	O
proposed	O
for	O
learning	O
the	O
mapping	B-Task
functions	I-Task
from	O
low	B-Task
-	I-Task
resolution	I-Task
(	O
LR	B-Task
)	O
patches	O
to	O
high	O
-	O
resolution	O
(	O
HR	O
)	O
patches	O
on	O
image	B-Task
restoration	I-Task
problems	I-Task
.	O
	
Pioneer	O
work	O
in	O
[	O
reference	O
]	O
used	O
a	O
simple	O
high	B-Method
-	I-Method
pass	I-Method
filter	I-Method
as	O
simple	O
as	O
subtracting	O
a	O
low	O
-	O
pass	O
filtered	O
values	O
from	O
the	O
input	O
image	O
raw	O
values	O
.	O
	
Meanwhile	O
,	O
most	O
algorithms	O
[	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
follow	O
the	O
approach	O
in	O
[	O
reference	O
]	O
,	O
which	O
concatenates	O
the	O
first	O
-	O
and	O
second	O
-	O
order	O
gradients	O
to	O
form	O
the	O
features	O
,	O
as	O
an	O
inexpensive	O
solution	O
to	O
approximating	B-Task
high	I-Task
-	I-Task
pass	I-Task
filtering	I-Task
.	O
	
Since	O
RF	B-Method
is	O
used	O
as	O
a	O
dictionarylearning	B-Method
-	I-Method
based	I-Method
tool	I-Method
,	O
it	O
inherits	O
many	O
properties	O
from	O
the	O
conventional	O
dictionary	B-Method
-	I-Method
learning	I-Method
-	I-Method
based	I-Method
algorithms	I-Method
on	O
feature	B-Task
extraction	I-Task
.	O
	
However	O
,	O
the	O
discriminative	B-Metric
ability	I-Metric
of	O
those	O
gradient	B-Method
-	I-Method
based	I-Method
features	I-Method
for	O
random	B-Method
forest	I-Method
has	O
been	O
overlooked	O
in	O
the	O
literature	O
.	O
	
We	O
found	O
,	O
from	O
experiments	O
,	O
that	O
augmented	O
features	O
based	O
on	O
two	O
gradient	B-Method
-	I-Method
magnitude	I-Method
filters	I-Method
can	O
achieve	O
more	O
than	O
0.1dB	O
quality	B-Metric
improvement	I-Metric
in	O
RF	B-Method
based	O
SISR	B-Task
,	O
with	O
the	O
same	O
parameter	O
setting	O
.	O
	
In	O
most	O
dictionary	B-Method
-	I-Method
learning	I-Method
-	I-Method
based	I-Method
algorithms	I-Method
,	O
principal	B-Method
component	I-Method
analysis	I-Method
(	O
PCA	B-Method
)	I-Method
is	O
used	O
for	O
dimensionality	B-Task
reduction	I-Task
before	O
classification	B-Task
and	I-Task
regression	I-Task
processes	I-Task
.	O
	
The	O
impact	O
of	O
using	O
PCA	B-Method
has	O
also	O
been	O
paid	O
less	O
attention	O
in	O
the	O
literature	O
.	O
	
PCA	B-Method
projection	I-Method
may	O
damage	O
the	O
structure	O
of	O
features	O
,	O
which	O
are	O
originally	O
discriminative	O
for	O
clustering	B-Method
at	O
the	O
split	O
-	O
nodes	O
and	O
regression	O
at	O
the	O
leaf	O
-	O
nodes	O
.	O
	
Motivated	O
from	O
content	B-Method
-	I-Method
based	I-Method
image	I-Method
retrieval	I-Method
(	O
CBIR	B-Method
)	O
	
[	O
reference	O
][	O
reference	O
]	O
,	O
where	O
the	O
coarse	B-Method
-	I-Method
level	I-Method
search	I-Method
uses	O
compressed	O
features	O
,	O
while	O
the	O
fine	B-Method
-	I-Method
level	I-Method
search	I-Method
uses	O
augmented	O
features	O
.	O
	
Therefore	O
,	O
in	O
our	O
method	O
,	O
we	O
use	O
the	O
original	O
features	O
rather	O
than	O
the	O
compressed	O
features	O
generated	O
by	O
PCA	B-Method
as	O
worked	O
in	O
[	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
,	O
so	O
that	O
more	O
accurate	O
regression	B-Task
and	O
higher	O
image	B-Metric
quality	I-Metric
improvement	I-Metric
can	O
be	O
achieved	O
.	O
	
Moreover	O
,	O
the	O
unsupervised	O
locality	O
-	O
sensitive	O
hashing	O
(	O
LSH	B-Method
)	O
model	O
,	O
instead	O
of	O
PCA	B-Method
,	O
is	O
employed	O
for	O
feature	B-Task
dimensionality	I-Task
reduction	I-Task
,	O
which	O
can	O
reduce	O
the	O
damage	O
on	O
the	O
feature	O
structure	O
for	O
the	O
compressed	O
features	O
used	O
on	O
clustering	B-Method
at	O
the	O
split	O
-	O
nodes	O
and	O
thus	O
improve	O
the	O
final	O
image	B-Metric
quality	I-Metric
.	O
	
For	O
regression	B-Task
problems	I-Task
at	O
the	O
leaf	O
-	O
nodes	O
,	O
we	O
propose	O
a	O
generalized	B-Method
weighted	I-Method
ridge	I-Method
regression	I-Method
(	O
GWRR	B-Method
)	O
as	O
an	O
extension	O
of	O
the	O
work	O
in	O
[	O
reference	O
]	O
.	O
GWRR	B-Method
models	O
are	O
generated	O
based	O
on	O
the	O
data	O
distributions	O
from	O
the	O
leaf	O
-	O
nodes	O
.	O
	
The	O
main	O
contribution	O
of	O
our	O
method	O
is	O
on	O
feature	B-Task
augmentation	I-Task
,	O
so	O
we	O
call	O
our	O
method	O
featureaugmented	B-Method
random	I-Method
forest	I-Method
(	O
FARF	B-Method
)	O
.	O
	
The	O
pipeline	O
of	O
our	O
FARF	B-Method
method	O
,	O
which	O
includes	O
feature	B-Task
extraction	I-Task
,	O
the	O
training	B-Method
stage	I-Method
,	O
and	O
inference	B-Method
stages	I-Method
for	O
SISR	B-Task
,	O
is	O
shown	O
in	O
Fig	O
.	O
1	O
.	O
	
In	O
the	O
FARF	B-Method
-	O
based	O
image	O
SR	B-Task
scheme	O
,	O
higher	O
discriminative	O
features	O
are	O
extracted	O
by	O
using	O
the	O
first	O
-	O
and	O
second	O
-	O
order	O
gradients	O
and	O
their	O
magnitudes	O
.	O
	
Then	O
,	O
the	O
conventional	O
PCA	B-Method
is	O
replaced	O
by	O
the	O
generalized	O
LSH	B-Method
for	O
dimensionality	B-Task
reduction	I-Task
,	O
and	O
the	O
compressed	O
features	O
are	O
used	O
for	O
clustering	B-Method
in	O
the	O
split	O
-	O
nodes	O
on	O
an	O
RF	B-Method
.	O
	
Finally	O
,	O
the	O
respective	O
regressors	O
at	O
the	O
leaf	O
-	O
nodes	O
are	O
learned	O
by	O
using	O
the	O
original	O
high	O
dimensional	O
features	O
with	O
the	O
GWRR	B-Method
models	O
.	O
	
Having	O
introduced	O
the	O
main	O
idea	O
of	O
our	O
paper	O
,	O
the	O
remainder	O
of	O
this	O
paper	O
is	O
organized	O
as	O
follows	O
.	O
	
In	O
Section	O
2	O
,	O
we	O
review	O
the	O
related	O
works	O
on	O
SISR	B-Task
,	O
particularly	O
the	O
RF	B-Method
-	O
based	O
approaches	O
and	O
our	O
insights	O
.	O
	
In	O
Section	O
3	O
,	O
we	O
introduce	O
the	O
proposed	O
method	O
FARF	B-Method
,	O
including	O
the	O
discriminative	O
feature	O
augmented	O
by	O
the	O
gradient	B-Method
-	I-Method
magnitude	I-Method
filters	I-Method
,	O
the	O
generalized	B-Method
weighted	I-Method
ridge	I-Method
regression	I-Method
(	O
GWRR	B-Method
)	O
model	O
,	O
and	O
the	O
fine	O
-	O
tuned	O
FARF	B-Method
version	O
.	O
	
In	O
Section	O
4	O
,	O
we	O
evaluate	O
our	O
FARF	B-Method
scheme	O
on	O
public	O
datasets	O
,	O
and	O
conclusions	O
are	O
given	O
in	O
Section	O
5	O
.	O
	
section	O
:	O
IMAGE	B-Task
SUPER	I-Task
-	I-Task
RESOLUTION	I-Task
VIA	O
RANDOM	B-Method
FOREST	I-Method
	
section	O
:	O
Image	B-Task
Super	I-Task
-	I-Task
Resolution	I-Task
	
Image	O
SR	B-Task
attempts	O
to	O
achieve	O
an	O
impressive	O
HR	O
quality	O
image	O
from	O
one	O
or	O
a	O
set	O
of	O
LR	B-Task
images	O
via	O
artistic	O
skills	O
,	O
which	O
has	O
been	O
an	O
active	O
research	O
topic	O
for	O
decades	O
in	O
the	O
image	B-Task
restoration	I-Task
area	I-Task
.	O
	
Generalized	O
SR	B-Task
includes	O
interpolation	B-Method
algorithms	I-Method
,	O
such	O
as	O
the	O
classic	O
bicubic	B-Method
interpolation	I-Method
,	O
and	O
other	O
edge	B-Method
-	I-Method
preserving	I-Method
algorithms	I-Method
	
[	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
.	O
	
The	O
traditional	O
super	B-Method
-	I-Method
resolution	I-Method
algorithms	I-Method
are	O
based	O
on	O
pixel	B-Method
operations	I-Method
.	O
	
Intuitively	O
,	O
operating	O
on	O
a	O
"	O
big	O
pixel	O
"	O
,	O
i.e.	O
a	O
patch	O
[	O
reference	O
]	O
,	O
is	O
more	O
effective	O
.	O
	
Since	O
patch	B-Method
-	I-Method
based	I-Method
algorithms	I-Method
can	O
preserve	O
the	O
local	O
texture	O
structure	O
of	O
an	O
image	O
,	O
various	O
methods	O
based	O
on	O
image	O
patches	O
,	O
such	O
as	O
non	B-Method
-	I-Method
local	I-Method
means	I-Method
[	O
reference	O
]	O
,	O
self	O
-	O
similarity	O
[	O
reference	O
]	O
,	O
manifold	B-Method
learning	I-Method
[	O
reference	O
]	O
,	O
block	B-Method
-	I-Method
matching	I-Method
and	O
3D	B-Method
filtering	I-Method
(	O
BM3D	B-Method
)	I-Method
[	O
reference	O
]	O
,	O
sparse	B-Method
representation	I-Method
[	O
reference	O
]	O
,	O
etc	O
.	O
have	O
been	O
proposed	O
.	O
	
The	O
neighbor	B-Method
-	I-Method
embedding	I-Method
(	O
NE	B-Method
)	O
methods	O
[	O
reference	O
][	O
reference	O
]	O
are	O
the	O
milestone	O
for	O
patch	B-Method
-	I-Method
based	I-Method
dictionary	I-Method
learning	I-Method
methods	I-Method
.	O
	
NE	B-Method
learns	O
the	O
mapping	B-Task
between	I-Task
low	I-Task
-	I-Task
and	I-Task
high	I-Task
-	I-Task
resolution	I-Task
patches	I-Task
,	O
with	O
the	O
use	O
of	O
manifold	B-Method
learning	I-Method
.	O
	
Based	O
on	O
the	O
locally	B-Method
linear	I-Method
embedding	I-Method
(	I-Method
LLE	I-Method
)	I-Method
theory	I-Method
,	O
an	O
LR	B-Task
patch	O
can	O
be	O
represented	O
as	O
a	O
linear	B-Method
combination	I-Method
of	O
its	O
nearest	O
neighbors	O
in	O
a	O
learned	O
dictionary	O
,	O
and	O
its	O
HR	B-Method
counterpart	I-Method
can	O
be	O
approximated	O
as	O
a	O
linear	B-Method
combination	I-Method
of	O
the	O
corresponding	O
HR	O
patches	O
of	O
its	O
LR	B-Task
neighbors	O
,	O
with	O
the	O
same	O
coefficients	O
.	O
	
Although	O
the	O
NE	B-Method
method	O
is	O
simple	O
and	O
sounds	O
practical	O
,	O
a	O
problem	O
with	O
the	O
method	O
is	O
how	O
to	O
build	O
a	O
feasible	O
patch	O
dictionary	O
.	O
	
For	O
example	O
,	O
for	O
a	O
patch	O
size	O
of	O
5×5	O
,	O
with	O
256	O
gray	O
levels	O
,	O
it	O
is	O
necessary	O
to	O
have	O
a	O
massive	O
dataset	O
,	O
which	O
has	O
millions	O
of	O
patches	O
,	O
in	O
order	O
to	O
achieve	O
high	O
-	O
quality	O
reconstructed	O
HR	O
patches	O
,	O
if	O
the	O
patches	O
are	O
collected	O
directly	O
from	O
natural	O
scene	O
images	O
.	O
	
Because	O
of	O
the	O
large	O
dictionary	O
size	O
,	O
it	O
is	O
time	O
consuming	O
to	O
search	O
for	O
a	O
neighbor	O
in	O
such	O
a	O
large	O
dataset	O
.	O
	
Other	O
method	O
to	O
reduce	O
the	O
dictionary	O
size	O
is	O
to	O
learn	O
a	O
relatively	O
smaller	O
dictionary	O
with	O
discrete	B-Method
cosine	I-Method
transform	I-Method
(	O
DCT	B-Method
)	O
or	O
wavelet	O
fixed	O
basis	O
,	O
which	O
the	O
adaptiveness	O
is	O
sacrificed	O
.	O
	
In	O
2010	O
,	O
Yang	O
et	O
al	O
.	O
	
[	O
reference	O
]	O
proposed	O
a	O
sparse	B-Method
prior	I-Method
for	O
dictionary	B-Task
learning	I-Task
.	O
	
Using	O
sparse	B-Method
coding	I-Method
,	O
image	B-Task
representation	I-Task
can	O
work	O
with	O
a	O
relatively	O
smaller	O
dictionary	O
while	O
keep	O
the	O
adaptiveness	O
by	O
learning	O
the	O
basis	O
from	O
data	O
directly	O
,	O
which	O
opens	O
the	O
era	O
for	O
sparse	B-Method
coding	I-Method
in	O
the	O
image	B-Task
inverse	I-Task
problems	I-Task
.	O
	
With	O
the	O
sparse	O
constraint	O
used	O
in	O
the	O
sparse	B-Method
-	I-Method
coding	I-Method
super	I-Method
-	I-Method
resolution	I-Method
(	O
ScSR	B-Method
)	O
framework	O
,	O
an	O
LR	B-Task
patch	O
and	O
its	O
corresponding	O
HR	O
patch	O
can	O
both	O
be	O
reconstructed	O
through	O
two	O
learned	O
coupled	B-Method
dictionaries	I-Method
,	O
with	O
the	O
same	O
coefficients	O
as	O
following	O
:	O
	
where	O
and	O
denote	O
an	O
LR	B-Task
patch	O
and	O
its	O
HR	O
counterpart	O
,	O
respectively	O
,	O
and	O
D	O
and	O
D	O
ℎ	O
are	O
the	O
low	B-Method
and	I-Method
high	I-Method
-	I-Method
resolution	I-Method
coupled	I-Method
dictionaries	I-Method
trained	O
jointly	O
from	O
LR	B-Task
and	O
HR	O
patch	O
samples	O
.	O
	
The	O
value	O
of	O
in	O
‖	O
‖	O
ϑ	O
is	O
the	O
sparsity	O
factor	O
of	O
the	O
coefficients	O
.	O
	
‖	O
‖	O
0	O
,	O
called	O
the	O
0	O
-	O
norm	O
,	O
is	O
the	O
non	O
-	O
zero	O
count	O
of	O
the	O
coefficients	O
in	O
.	O
	
The	O
LR	B-Task
and	O
HR	B-Method
coupled	I-Method
dictionaries	I-Method
are	O
trained	O
jointly	O
with	O
a	O
sparsity	O
constraint	O
,	O
as	O
following	O
:	O
	
an	O
LR	B-Task
patch	O
of	O
an	O
input	O
LR	B-Task
image	O
	
Y	O
can	O
be	O
formulated	O
in	O
terms	O
of	O
D	O
as	O
following	O
:	O
	
where	O
is	O
a	O
feature	B-Method
-	I-Method
extraction	I-Method
operator	I-Method
on	O
the	O
LR	B-Task
patches	O
,	O
which	O
aims	O
to	O
extract	O
discriminative	O
features	O
from	O
LR	B-Task
patches	O
,	O
rather	O
than	O
using	O
the	O
raw	O
pixel	O
intensity	O
.	O
	
Although	O
the	O
0	O
-	O
norm	O
of	O
α	O
is	O
an	O
ideal	O
regularization	O
term	O
for	O
the	O
sparse	B-Task
constraint	I-Task
,	O
this	O
strong	O
constraint	O
leads	O
to	O
an	O
NP	B-Task
-	I-Task
hard	I-Task
problem	I-Task
in	O
solving	O
the	O
coefficients	O
α	O
.	O
	
Yang	O
et	O
al	O
.	O
	
[	O
reference	O
]	O
relaxed	O
the	O
0	O
-	O
norm	O
to	O
1	O
-	O
norm	O
,	O
so	O
as	O
to	O
achieve	O
a	O
feasible	O
solution	O
as	O
following	O
:	O
	
and	O
an	O
equivalent	O
formulation	O
can	O
be	O
achieved	O
by	O
using	O
the	O
Lagrange	O
multiplier	O
,	O
	
where	O
the	O
parameter	O
balances	O
the	O
sparsity	O
of	O
the	O
solution	O
and	O
the	O
fidelity	O
of	O
the	O
approximation	O
to	O
.	O
	
As	O
the	O
sparse	O
constraint	O
in	O
[	O
reference	O
]	O
is	O
still	O
a	O
bottleneck	O
on	O
training	B-Task
dictionaries	I-Task
considering	O
the	O
computation	B-Task
,	O
an	O
intuitive	O
way	O
to	O
solve	O
it	O
is	O
to	O
relax	O
the	O
constraint	O
again	O
to	O
2	O
-	O
norm	O
.	O
	
Meanwhile	O
,	O
the	O
effectiveness	O
of	O
sparsity	O
is	O
challenged	O
[	O
reference	O
][	O
reference	O
]	O
by	O
researchers	O
as	O
to	O
whether	O
sparsity	O
or	O
collaborative	B-Method
representation	I-Method
really	O
helps	O
in	O
image	B-Task
classification	I-Task
and	I-Task
restoration	I-Task
.	O
	
As	O
a	O
natural	O
solution	O
to	O
that	O
,	O
Timofte	O
et	O
al	O
.	O
proposed	O
an	O
anchored	B-Method
neighborhood	I-Method
regression	I-Method
(	O
ANR	B-Method
)	O
[	O
reference	O
]	O
framework	O
,	O
where	O
there	O
is	O
no	O
sparse	O
constraint	O
in	O
the	O
model	O
.	O
	
ANR	B-Method
replaces	O
the	O
sparse	B-Method
-	I-Method
decomposition	I-Method
optimization	I-Method
(	O
1	O
-	O
norm	O
)	O
with	O
a	O
ridge	B-Method
regression	I-Method
(	O
i.e.	O
2	O
-	O
norm	O
)	O
,	O
where	O
the	O
coefficients	O
can	O
be	O
computed	O
offline	O
and	O
each	O
coefficient	O
can	O
be	O
stored	O
as	O
an	O
atom	O
(	O
anchor	O
)	O
in	O
the	O
dictionary	O
.	O
	
This	O
offline	B-Method
learning	I-Method
can	O
greatly	O
speed	O
-	O
up	O
the	O
prediction	B-Task
stage	I-Task
,	O
and	O
this	O
approach	O
has	O
subsequently	O
led	O
to	O
several	O
variant	O
algorithms	O
.	O
	
Timofte	O
et	O
al	O
.	O
	
later	O
extended	O
the	O
ANR	B-Method
approach	O
to	O
the	O
A	O
+	O
	
[	O
reference	O
]	O
.	O
In	O
A	O
+	O
[	O
reference	O
]	O
,	O
the	O
coupled	B-Method
dictionaries	I-Method
are	O
trained	O
from	O
a	O
large	O
pool	O
of	O
training	O
samples	O
(	O
in	O
the	O
order	O
of	O
millions	O
)	O
rather	O
than	O
only	O
from	O
the	O
anchoring	O
atoms	O
,	O
which	O
greatly	O
improves	O
the	O
image	B-Metric
quality	I-Metric
.	O
	
After	O
that	O
,	O
more	O
extensions	O
based	O
on	O
ANR	B-Method
and	O
A	O
+	O
have	O
emerged	O
[	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
.	O
	
However	O
,	O
in	O
the	O
above	O
-	O
mentioned	O
dictionary	B-Method
-	I-Method
learning	I-Method
methods	I-Method
,	O
the	O
complexity	O
of	O
finding	O
those	O
similar	O
patches	O
by	O
comparing	O
an	O
input	O
patch	O
with	O
all	O
the	O
dictionary	O
items	O
has	O
been	O
overlooked	O
.	O
	
Recently	O
,	O
algorithms	O
using	O
random	B-Method
forest	I-Method
(	O
RF	B-Method
)	O
[	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
have	O
achieved	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
performances	O
,	O
in	O
terms	O
of	O
both	O
accuracy	B-Metric
and	O
efficiency	B-Metric
for	O
classification	B-Task
and	I-Task
regression	I-Task
tasks	I-Task
.	O
	
This	O
is	O
mainly	O
due	O
to	O
the	O
use	O
of	O
ensemble	B-Method
learning	I-Method
and	O
sublinear	B-Method
search	I-Method
based	O
on	O
binary	O
trees	O
.	O
	
Schulter	O
et	O
al	O
.	O
	
[	O
reference	O
]	O
adopted	O
random	B-Method
forest	I-Method
and	O
the	O
clustering	B-Method
-	O
regression	O
scheme	O
to	O
learn	O
regressors	O
from	O
the	O
patches	O
in	O
leaf	O
-	O
nodes	O
for	O
SISR	B-Task
.	O
	
With	O
the	O
same	O
number	O
of	O
regressors	O
,	O
the	O
RF	B-Method
-	O
based	O
algorithm	O
can	O
outperform	O
or	O
achieve	O
comparable	O
performance	O
with	O
A	O
+	O
and	O
its	O
variants	O
,	O
in	O
terms	O
of	O
accuracy	B-Metric
but	O
with	O
less	O
computational	B-Metric
complexity	I-Metric
.	O
	
In	O
recent	O
years	O
,	O
deep	B-Method
learning	I-Method
has	O
achieved	O
promising	O
performances	O
on	O
image	B-Task
super	I-Task
-	I-Task
resolution	I-Task
[	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
.	O
	
In	O
[	O
reference	O
][	O
reference	O
]	O
,	O
milestone	O
works	O
on	O
image	B-Task
super	I-Task
-	I-Task
resolution	I-Task
based	O
on	O
deep	B-Method
learning	I-Method
were	O
presented	O
,	O
where	O
a	O
convolutional	B-Method
neural	I-Method
network	I-Method
(	O
SRCNN	B-Method
)	O
was	O
proposed	O
to	O
learn	O
an	O
end	B-Task
-	I-Task
to	I-Task
-	I-Task
end	I-Task
mapping	I-Task
between	O
LR	B-Task
and	O
HR	O
images	O
for	O
image	B-Task
super	I-Task
-	I-Task
resolution	I-Task
.	O
	
Later	O
a	O
scheme	O
with	O
very	O
deep	B-Method
networks	I-Method
for	O
SISR	B-Task
was	O
proposed	O
in	O
[	O
reference	O
]	O
,	O
where	O
the	O
convergence	B-Metric
rate	I-Metric
of	O
the	O
deep	B-Method
network	I-Method
is	O
improved	O
by	O
using	O
residual	B-Method
learning	I-Method
and	O
extremely	O
high	O
learning	B-Metric
rates	I-Metric
.	O
	
In	O
addition	O
,	O
Ledig	O
et	O
al	O
.	O
	
[	O
reference	O
]	O
introduced	O
a	O
generative	B-Method
adversarial	I-Method
network	I-Method
(	O
GAN	B-Method
)	O
	
based	O
image	B-Task
super	I-Task
-	I-Task
resolution	I-Task
model	I-Task
(	O
SRGAN	B-Task
)	I-Task
,	O
where	O
the	O
image	O
perceptual	O
loss	O
function	O
is	O
reformulated	O
as	O
the	O
combination	O
of	O
content	O
loss	O
and	O
adversarial	B-Method
loss	I-Method
.	O
	
Although	O
deeplearning	B-Method
-	I-Method
based	I-Method
approaches	I-Method
have	O
achieved	O
promising	O
progress	O
on	O
SISR	B-Task
,	O
the	O
heavy	O
computational	B-Metric
requirement	I-Metric
is	O
still	O
a	O
large	O
burden	O
even	O
though	O
the	O
implementation	O
is	O
accelerated	O
by	O
GPU	O
.	O
	
This	O
may	O
limit	O
them	O
from	O
those	O
applications	O
without	O
powerful	O
GPU	B-Method
,	O
such	O
as	O
smart	O
mobile	O
terminals	O
.	O
	
cluster	O
all	O
the	O
feature	O
data	O
assigned	O
to	O
this	O
node	O
.	O
	
This	O
results	O
in	O
separating	O
the	O
three	O
data	O
samples	O
(	O
quadrangle	O
,	O
pentagon	O
and	O
hexagon	O
)	O
into	O
three	O
leaf	O
nodes	O
.	O
	
section	O
:	O
Image	B-Task
Super	I-Task
-	I-Task
Resolution	I-Task
via	O
Random	B-Method
Forest	I-Method
	
In	O
the	O
inference	B-Task
stage	I-Task
,	O
each	O
decision	B-Method
tree	I-Method
returns	O
a	O
class	O
probability	O
(	O
|	O
)	O
for	O
a	O
given	O
test	O
sample	O
∈	O
,	O
and	O
the	O
final	O
class	O
label	O
*	O
is	O
then	O
obtained	O
via	O
averaging	B-Method
,	O
as	O
follows	O
:	O
	
A	O
splitting	B-Method
function	I-Method
(	O
;	O
Θ	O
)	O
is	O
typically	O
parameterized	O
by	O
two	O
values	O
:	O
(	O
i	O
)	O
a	O
feature	O
dimensional	O
index	O
:	O
Θ	O
{1	O
,	O
.	O
.	O
.	O
,	O
}	O
,	O
and	O
(	O
ii	O
)	O
a	O
threshold	O
Θ	O
ℝ.	O
	
The	O
splitting	O
function	O
is	O
defined	O
as	O
follows	O
:	O
	
where	O
the	O
outcome	O
defines	O
to	O
which	O
child	O
node	O
is	O
routed	O
,	O
and	O
0	O
and	O
1	O
are	O
the	O
two	O
labels	O
belonging	O
to	O
the	O
left	O
and	O
right	O
child	O
node	O
,	O
respectively	O
.	O
	
Each	O
node	O
chooses	O
the	O
best	O
splitting	O
function	O
Θ	O
*	O
out	O
of	O
a	O
randomly	O
sampled	O
set	O
{	O
Θ	O
}	O
,	O
and	O
the	O
threshold	O
Θ	O
is	O
determined	O
by	O
optimizing	O
the	O
following	O
function	O
:	O
	
where	O
and	O
are	O
the	O
sets	O
of	O
samples	O
that	O
are	O
routed	O
to	O
the	O
left	O
and	O
right	O
child	O
nodes	O
,	O
respectively	O
,	O
and	O
|	O
|	O
represents	O
the	O
number	O
of	O
samples	O
in	O
the	O
set	O
.	O
	
During	O
the	O
training	O
of	O
an	O
RF	B-Method
,	O
the	O
decision	B-Method
trees	I-Method
are	O
provided	O
with	O
a	O
random	O
subset	O
of	O
the	O
training	O
data	O
(	O
i.e.	O
bagging	O
)	O
,	O
and	O
are	O
trained	O
independently	O
.	O
	
Training	O
a	O
single	O
decision	O
tree	O
involves	O
recursively	O
splitting	O
each	O
node	O
,	O
such	O
that	O
the	O
training	O
data	O
in	O
the	O
newly	O
created	O
child	O
node	O
is	O
clustered	O
conforming	O
to	O
class	O
labels	O
.	O
	
Each	O
tree	O
is	O
grown	O
until	O
a	O
stopping	B-Metric
criterion	I-Metric
is	O
reached	O
(	O
e.g.	O
the	O
number	O
of	O
samples	O
in	O
a	O
node	O
is	O
less	O
than	O
a	O
threshold	O
or	O
the	O
tree	O
depth	O
reaches	O
a	O
maximum	O
value	O
)	O
and	O
the	O
class	O
probability	O
distributions	O
are	O
estimated	O
in	O
the	O
leaf	O
nodes	O
.	O
	
After	O
fulfilling	O
one	O
of	O
the	O
stopping	B-Metric
criteria	I-Metric
,	O
the	O
density	B-Method
model	I-Method
(	O
)	O
in	O
each	O
leaf	O
node	O
is	O
estimated	O
by	O
using	O
all	O
the	O
samples	O
falling	O
into	O
the	O
leaf	O
node	O
,	O
which	O
will	O
be	O
used	O
as	O
a	O
prediction	O
of	O
class	O
probabilities	O
in	O
the	O
inference	B-Task
stage	I-Task
.	O
	
A	O
simple	O
way	O
to	O
estimate	O
the	O
probability	O
distribution	O
function	O
(	O
)	O
is	O
by	O
averaging	O
all	O
the	O
samples	O
in	O
the	O
leaf	O
node	O
,	O
and	O
there	O
are	O
many	O
variants	O
,	O
such	O
as	O
fitting	O
a	O
Gaussian	B-Method
distribution	I-Method
,	O
kernel	B-Method
density	I-Method
estimation	I-Method
,	O
etc	O
.	O
	
In	O
(	O
9	O
)	O
,	O
(	O
)	O
is	O
the	O
local	O
score	O
for	O
a	O
set	O
of	O
samples	O
in	O
S	O
	
(	O
S	O
is	O
either	O
L	O
or	O
R	O
)	O
,	O
which	O
is	O
usually	O
calculated	O
by	O
entropy	O
,	O
as	O
shown	O
in	O
Eqn	O
.	O
	
[	O
reference	O
]	O
,	O
and	O
it	O
can	O
be	O
replaced	O
by	O
variance	O
[	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
or	O
by	O
the	O
Gini	B-Method
index	I-Method
	
[	O
reference	O
]	O
.	O
	
where	O
is	O
the	O
number	O
of	O
classes	O
,	O
and	O
(	O
|	O
)	O
is	O
the	O
probability	O
for	O
class	O
,	O
which	O
is	O
estimated	O
from	O
the	O
set	O
.	O
	
For	O
the	O
regression	B-Task
problem	I-Task
,	O
the	O
differential	B-Metric
entropy	I-Metric
is	O
used	O
,	O
and	O
is	O
defined	O
as	O
,	O
	
where	O
(	O
|	O
)	O
denotes	O
the	O
conditional	O
probability	O
of	O
a	O
target	O
variable	O
given	O
an	O
input	O
sample	O
.	O
	
Assuming	O
that	O
(	O
.	O
,	O
.	O
)	O
is	O
of	O
Gaussian	O
distribution	O
,	O
and	O
has	O
only	O
a	O
set	O
of	O
finite	O
samples	O
,	O
the	O
differential	O
entropy	O
can	O
be	O
written	O
as	O
,	O
	
where	O
det	O
(	O
Σ	O
)	O
is	O
the	O
determinant	O
of	O
the	O
estimated	O
covariance	O
matrix	O
of	O
the	O
target	O
variables	O
in	O
.	O
	
RF	B-Method
-	O
based	O
approaches	O
hold	O
some	O
properties	O
,	O
which	O
make	O
them	O
powerful	O
classifiers	B-Method
as	O
SVM	B-Method
(	O
support	B-Method
vector	I-Method
machine	I-Method
)	O
[	O
reference	O
]	O
and	O
AdaBoost	B-Method
(	O
short	O
for	O
"	O
Adaptive	B-Method
Boosting	I-Method
"	O
)	O
	
[	O
reference	O
]	O
.	O
Both	O
SVM	B-Method
and	O
AdaBoost	B-Method
work	O
as	O
to	O
approximate	O
the	O
Bayes	O
decision	O
rule	O
-	O
known	O
to	O
be	O
the	O
optimal	O
classifiers	B-Method
-	O
via	O
minimizing	O
a	O
margin	B-Metric
-	I-Metric
based	I-Metric
global	I-Metric
loss	I-Metric
function	I-Metric
.	O
	
RF	B-Task
-	I-Task
based	I-Task
image	I-Task
super	I-Task
-	I-Task
resolution	I-Task
(	O
SR	B-Task
)	O
,	O
following	O
a	O
recent	O
emerging	O
stream	O
[	O
reference	O
][	O
reference	O
]	O
on	O
single	O
-	O
image	O
SR	B-Task
,	O
formulates	O
the	O
SR	B-Task
problem	O
as	O
a	O
clustering	B-Method
-	O
regression	O
problem	O
.	O
	
These	O
emerging	O
approaches	O
attempt	O
to	O
reconstruct	O
an	O
HR	O
image	O
from	O
patches	O
with	O
the	O
aid	O
of	O
an	O
external	O
database	O
.	O
	
These	O
methods	O
first	O
decompose	O
an	O
image	O
into	O
patches	O
,	O
then	O
classify	O
the	O
patches	O
into	O
different	O
clusters	O
,	O
and	O
later	O
regressors	B-Method
are	O
trained	O
for	O
all	O
the	O
clusters	O
respectively	O
,	O
which	O
generate	O
mappings	O
from	O
an	O
input	O
LR	B-Task
patch	O
's	O
features	O
to	O
its	O
corresponding	O
HR	O
patch	O
.	O
	
In	O
the	O
inference	B-Task
stage	I-Task
,	O
an	O
LR	B-Task
image	O
follows	O
the	O
same	O
procedures	O
,	O
such	O
that	O
it	O
is	O
divided	O
into	O
patches	O
and	O
features	O
are	O
extracted	O
from	O
each	O
patch	O
.	O
	
Then	O
,	O
the	O
patches	O
are	O
classified	O
into	O
different	O
clusters	O
using	O
K	B-Method
-	I-Method
NN	I-Method
[	O
reference	O
][	O
reference	O
]	O
or	O
RF	B-Method
[	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
,	O
and	O
their	O
super	O
-	O
resolved	O
HR	O
patches	O
are	O
computed	O
through	O
regression	B-Method
in	O
the	O
leaf	O
nodes	O
(	O
see	O
Fig	O
.	O
1	O
)	O
.	O
	
This	O
kind	O
of	O
clustering	B-Method
-	O
regression	O
-	O
based	O
random	B-Method
forest	I-Method
[	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
methods	O
has	O
achieved	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
performance	O
in	O
SISR	B-Task
,	O
both	O
in	O
terms	O
of	O
accuracy	B-Metric
and	O
efficiency	B-Metric
.	O
	
section	O
:	O
FEATURE	B-Method
-	I-Method
AUGMENTED	I-Method
RANDOM	I-Method
FOREST	I-Method
	
Classification	B-Task
and	O
regression	B-Task
can	O
be	O
regarded	O
as	O
probability	B-Task
problems	I-Task
from	O
the	O
statistical	B-Method
theory	I-Method
.	O
	
Historical	O
frequentist	O
probability	O
is	O
the	O
probability	O
obtained	O
from	O
the	O
relative	O
frequency	O
in	O
a	O
large	O
number	O
of	O
trials	O
.	O
	
In	O
contrast	O
,	O
the	O
Bayesian	O
probability	O
is	O
an	O
interpretation	O
of	O
the	O
concept	O
of	O
probability	O
,	O
in	O
which	O
probability	O
is	O
interpreted	O
as	O
an	O
expectation	O
taking	O
the	O
knowledge	O
and	O
personal	O
belief	O
into	O
account	O
.	O
	
From	O
the	O
Bayesian	B-Method
theory	I-Method
,	O
the	O
posterior	O
probability	O
of	O
a	O
random	O
event	O
is	O
a	O
conditional	O
probability	O
,	O
which	O
can	O
be	O
calculated	O
if	O
the	O
relevant	O
evidence	O
or	O
context	O
is	O
considered	O
.	O
	
Therefore	O
,	O
the	O
posterior	O
probability	O
is	O
the	O
probability	O
(	O
|	O
)	O
of	O
the	O
parameters	O
given	O
the	O
evidence	O
.	O
	
We	O
denote	O
the	O
probability	O
distribution	O
function	O
of	O
the	O
prior	O
for	O
parameters	O
as	O
(	O
)	O
,	O
and	O
the	O
likelihood	O
as	O
(	O
|	O
)	O
,	O
which	O
is	O
the	O
probability	O
of	O
given	O
.	O
	
Then	O
,	O
based	O
on	O
the	O
Bayesian	B-Method
rule	I-Method
,	O
the	O
posterior	O
probability	O
can	O
be	O
defined	O
as	O
follows	O
:	O
	
The	O
posterior	O
probability	O
can	O
be	O
denoted	O
in	O
a	O
memorable	O
form	O
as	O
:	O
	
Based	O
on	O
the	O
Bayesian	B-Method
framework	I-Method
,	O
the	O
likelihood	O
term	O
and	O
the	O
prior	O
term	O
are	O
both	O
required	O
to	O
be	O
determined	O
in	O
order	O
to	O
solve	O
the	O
inverse	B-Task
problems	I-Task
,	O
and	O
the	O
extracted	O
features	O
are	O
normally	O
worked	O
as	O
prior	O
or	O
likelihood	O
,	O
particularly	O
on	O
some	O
image	B-Task
restoration	I-Task
problems	I-Task
.	O
	
From	O
this	O
point	O
of	O
view	O
,	O
most	O
research	O
works	O
,	O
from	O
classic	O
feature	B-Method
extractors	I-Method
to	O
deep	B-Method
-	I-Method
learning	I-Method
neural	I-Method
networks	I-Method
,	O
are	O
essentially	O
done	O
under	O
the	O
Bayesian	B-Method
inference	I-Method
framework	I-Method
.	O
	
Since	O
SISR	B-Task
is	O
a	O
well	O
-	O
known	O
ill	B-Task
-	I-Task
posed	I-Task
problem	I-Task
,	O
researchers	O
have	O
put	O
their	O
efforts	O
into	O
the	O
priors	O
of	O
the	O
problem	O
with	O
skills	O
from	O
mathematics	O
,	O
computer	B-Task
vision	I-Task
and	O
machine	B-Task
learning	I-Task
.	O
	
One	O
of	O
the	O
obvious	O
and	O
most	O
studied	O
priors	O
is	O
the	O
edge	O
prior	O
,	O
which	O
can	O
be	O
found	O
in	O
many	O
pioneering	O
works	O
:	O
new	O
edgedirected	B-Method
interpolation	I-Method
(	O
NEDI	B-Method
)	O
	
[	O
reference	O
]	O
,	O
soft	B-Method
-	I-Method
decision	I-Method
adaptive	I-Method
interpolation	I-Method
(	O
SAI	B-Method
)	O
	
[	O
reference	O
]	O
,	O
directional	B-Method
filtering	I-Method
and	I-Method
data	I-Method
-	I-Method
fusion	I-Method
(	O
DFDF	B-Method
)	O
	
[	O
reference	O
]	O
,	O
modified	O
edge	B-Method
-	I-Method
directed	I-Method
interpolation	I-Method
(	I-Method
MEDI	I-Method
)	I-Method
[	O
reference	O
]	O
,	O
and	O
so	O
on	O
.	O
	
The	O
edge	B-Method
prior	I-Method
is	O
effective	O
on	O
image	B-Task
processing	I-Task
,	O
and	O
the	O
first	O
and	O
second	O
-	O
order	O
gradients	O
are	O
studied	O
and	O
employed	O
by	O
Yang	O
et	O
al	O
.	O
	
[	O
reference	O
]	O
in	O
a	O
pioneering	O
dictionary	B-Method
-	I-Method
learning	I-Method
-	I-Method
based	I-Method
algorithm	I-Method
.	O
	
However	O
,	O
the	O
effect	O
of	O
edgebased	O
features	O
has	O
not	O
been	O
investigated	O
in	O
depth	O
.	O
	
For	O
the	O
clustering	B-Method
and	O
classification	O
problems	O
,	O
feature	B-Task
engineering	I-Task
is	O
a	O
critical	O
research	O
point	O
,	O
and	O
in	O
some	O
cases	O
,	O
the	O
chosen	O
feature	O
may	O
dominate	O
the	O
performance	O
.	O
	
As	O
shown	O
in	O
Eqn	O
.	O
	
(	O
6	O
)	O
,	O
a	O
feature	B-Method
filter	I-Method
,	O
whose	O
coefficients	O
are	O
computed	O
to	O
fit	O
the	O
most	O
relevant	O
parts	O
in	O
the	O
LR	B-Task
image	O
patches	O
,	O
is	O
employed	O
,	O
and	O
the	O
generated	O
features	O
can	O
achieve	O
more	O
accurate	O
predictions	O
for	O
reconstructing	O
their	O
counterpart	O
HR	O
image	O
patches	O
,	O
as	O
shown	O
in	O
Fig	O
.	O
3	O
.	O
	
section	O
:	O
Augmented	O
Features	O
via	O
Gradient	B-Method
Magnitude	I-Method
Filters	I-Method
	
Normally	O
it	O
is	O
unstable	O
to	O
directly	O
use	O
pixel	O
intensities	O
as	O
features	O
,	O
which	O
are	O
susceptible	O
to	O
the	O
environmental	O
lighting	O
variations	O
and	O
camera	O
noise	O
.	O
	
Instead	O
,	O
the	O
differences	O
between	O
the	O
neighboring	O
pixels	O
'	O
intensity	O
values	O
,	O
which	O
are	O
computationally	O
efficient	O
,	O
and	O
are	O
immune	O
to	O
lighting	O
changes	O
and	O
noise	O
,	O
are	O
examined	O
.	O
	
This	O
type	O
of	O
features	O
can	O
be	O
implemented	O
efficiently	O
through	O
convolutional	B-Method
filters	I-Method
.	O
	
Typically	O
,	O
the	O
feature	B-Method
filter	I-Method
can	O
be	O
chosen	O
as	O
a	O
high	B-Method
-	I-Method
pass	I-Method
filter	I-Method
,	O
while	O
in	O
[	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
,	O
the	O
first	B-Method
and	I-Method
second	I-Method
-	I-Method
order	I-Method
gradient	I-Method
operators	I-Method
are	O
used	O
to	O
generate	O
an	O
up	O
-	O
sampled	O
version	O
from	O
a	O
low	B-Task
-	I-Task
resolution	I-Task
image	O
,	O
then	O
four	O
patches	O
are	O
extracted	O
from	O
the	O
gradient	O
maps	O
at	O
each	O
location	O
,	O
and	O
finally	O
the	O
patches	O
are	O
concatenated	O
to	O
form	O
feature	O
vectors	O
.	O
	
The	O
four	O
1	B-Method
-	I-Method
D	I-Method
filters	I-Method
used	O
to	O
extract	O
the	O
derivatives	O
are	O
described	O
in	O
Eqn	O
.	O
	
(	O
14	O
)	O
,	O
	
These	O
features	O
can	O
work	O
well	O
on	O
dictionary	B-Method
-	I-Method
learning	I-Method
-	I-Method
based	I-Method
methods	I-Method
,	O
because	O
when	O
searching	O
a	O
matched	O
patch	O
in	O
a	O
dictionary	O
,	O
the	O
distance	O
is	O
calculated	O
based	O
on	O
the	O
whole	O
feature	O
vectors	O
with	O
the	O
Euclidean	O
distance	O
.	O
	
However	O
,	O
when	O
training	O
a	O
split	O
node	O
in	O
a	O
decision	O
tree	O
of	O
an	O
RF	B-Method
,	O
only	O
one	O
or	O
a	O
few	O
of	O
the	O
feature	O
dimensions	O
are	O
chosen	O
as	O
candidate	O
features	O
for	O
comparison	O
.	O
	
Therefore	O
,	O
more	O
discriminative	O
features	O
are	O
required	O
for	O
RF	B-Method
,	O
when	O
compared	O
with	O
dictionary	B-Method
-	I-Method
learning	I-Method
-	I-Method
based	I-Method
methods	I-Method
.	O
	
The	O
first	O
and	O
second	O
-	O
order	O
gradients	O
of	O
an	O
image	O
can	O
provide	O
the	O
directions	O
of	O
edges	O
in	O
a	O
perceptual	O
manner	O
as	O
shown	O
in	O
Fig	O
.	O
4	O
and	O
Fig	O
.	O
5	O
,	O
which	O
can	O
be	O
calculated	O
as	O
Eqn	O
.	O
	
(	O
15	O
)	O
,	O
	
where	O
/	O
and	O
/	O
are	O
the	O
gradients	O
in	O
the	O
x	O
-	O
axis	O
and	O
y	O
-	O
axis	O
directions	O
,	O
respectively	O
,	O
at	O
a	O
given	O
pixel	O
.	O
	
Meanwhile	O
,	O
the	O
gradient	O
magnitude	O
image	O
can	O
provide	O
the	O
edge	O
strength	O
,	O
as	O
described	O
in	O
Eqn	O
.	O
	
[	O
reference	O
]	O
.	O
Fig	O
.	O
	
4	O
shows	O
a	O
toy	O
example	O
of	O
a	O
man	O
-	O
made	O
"	O
circle	O
"	O
image	O
,	O
to	O
demonstrate	O
its	O
discriminative	O
property	O
.	O
	
With	O
a	O
natural	O
image	O
shown	O
in	O
Fig	O
.	O
5	O
,	O
it	O
can	O
be	O
observed	O
that	O
the	O
gradient	O
magnitude	O
image	O
has	O
more	O
detailed	O
textures	O
than	O
the	O
gradient	O
images	O
(	O
/	O
and	O
/	O
)	O
,	O
as	O
well	O
as	O
the	O
sum	O
of	O
the	O
horizontal	O
gradient	O
and	O
vertical	O
gradient	O
image	O
,	O
i.e.	O
	
/	O
+	O
/	O
,	O
perceptually	O
.	O
	
An	O
explanation	O
for	O
this	O
phenomenon	O
is	O
that	O
non	O
-	O
linear	O
features	O
are	O
usually	O
more	O
discriminative	O
.	O
	
Thus	O
,	O
in	O
our	O
work	O
,	O
all	O
the	O
first	O
and	O
second	O
-	O
order	O
gradients	O
,	O
and	O
gradient	O
magnitude	O
are	O
employed	O
,	O
and	O
are	O
concatenated	O
to	O
form	O
more	O
discriminative	O
,	O
augmented	O
features	O
.	O
	
On	O
the	O
other	O
hand	O
,	O
the	O
image	O
orientation	O
(	O
gradient	O
angle	O
)	O
is	O
defined	O
by	O
the	O
following	O
formulation	O
,	O
	
where	O
atan	O
(	O
)	O
is	O
the	O
gradient	O
orientation	O
,	O
with	O
a	O
value	O
between	O
-	O
90	O
and	O
90.	O
	
As	O
shown	O
in	O
Eqn	O
.	O
	
(	O
17	O
)	O
,	O
when	O
the	O
value	O
of	O
is	O
equal	O
to	O
0	O
or	O
close	O
to	O
0	O
,	O
the	O
value	O
of	O
∠∇	O
becomes	O
infinitely	O
large	O
and	O
unstable	O
,	O
i.e.	O
,	O
different	O
will	O
result	O
in	O
approximately	O
the	O
same	O
∠∇	O
value	O
.	O
	
Based	O
on	O
this	O
analysis	O
,	O
we	O
only	O
use	O
the	O
two	O
gradient	B-Method
magnitude	I-Method
filters	I-Method
derived	O
from	O
the	O
four	O
gradient	B-Method
filters	I-Method
[	O
reference	O
]	O
to	O
generate	O
the	O
augmented	O
features	O
.	O
	
Experiments	O
validate	O
that	O
the	O
use	O
of	O
the	O
augmented	O
features	O
can	O
improve	O
the	O
conventional	O
RF	B-Method
algorithm	O
[	O
reference	O
]	O
to	O
achieve	O
a	O
performance	O
gain	O
of	O
more	O
than	O
0.1dB	O
,	O
which	O
is	O
a	O
remarkable	O
improvement	O
,	O
with	O
the	O
same	O
setting	O
and	O
parameters	O
.	O
	
section	O
:	O
Fine	O
-	O
grained	O
Features	O
for	O
Regression	B-Task
	
The	O
inference	B-Method
stage	I-Method
of	O
the	O
RF	B-Method
-	O
based	O
image	O
super	O
-	O
resolution	O
process	O
is	O
similar	O
to	O
the	O
content	B-Method
-	I-Method
based	I-Method
image	I-Method
retrieval	I-Method
(	O
CBIR	B-Method
)	O
framework	O
,	O
as	O
shown	O
in	O
Fig	O
.	O
1	O
.	O
	
The	O
general	O
approximated	B-Method
nearest	I-Method
neighbor	I-Method
(	O
ANN	B-Method
)	O
search	O
framework	O
[	O
reference	O
][	O
reference	O
]	O
is	O
an	O
efficient	O
strategy	O
for	O
large	B-Task
-	I-Task
scale	I-Task
image	I-Task
retrieval	I-Task
,	O
which	O
mainly	O
consists	O
of	O
4	O
parts	O
:	O
(	O
1	O
)	O
extracting	O
compact	O
features	O
(	O
e.g.	O
,	O
locality	B-Method
-	I-Method
sensitive	I-Method
Hashing	I-Method
(	O
LSH	B-Method
)	O
[	O
reference	O
]	O
feature	O
)	O
for	O
a	O
query	O
image	O
;	O
(	O
2	O
)	O
coarse	B-Method
-	I-Method
level	I-Method
search	I-Method
using	O
Hamming	O
distance	O
to	O
measure	O
the	O
similarity	B-Metric
between	O
binary	O
compact	O
Hash	O
features	O
,	O
then	O
narrow	O
the	O
search	O
scope	O
into	O
a	O
smaller	O
candidate	O
group	O
;	O
(	O
3	O
)	O
fine	B-Method
-	I-Method
level	I-Method
search	I-Method
by	O
using	O
Euclidean	B-Method
distance	I-Method
to	O
measure	O
the	O
similarity	O
between	O
their	O
corresponding	O
feature	O
vectors	O
;	O
and	O
(	O
4	O
)	O
finding	O
the	O
object	O
in	O
the	O
smaller	O
candidate	O
group	O
that	O
is	O
the	O
nearest	O
one	O
to	O
the	O
query	O
image	O
.	O
	
In	O
the	O
inference	B-Task
stage	I-Task
of	O
conventional	O
RF	B-Task
-	I-Task
based	I-Task
SISR	I-Task
,	O
PCA	B-Method
projection	I-Method
is	O
worked	O
as	O
a	O
Hash	O
-	O
like	O
function	O
to	O
compress	O
the	O
feature	O
dimension	O
for	O
decreasing	O
the	O
search	O
range	O
,	O
which	O
can	O
speed	O
up	O
the	O
searching	B-Task
as	O
the	O
coarse	B-Task
-	I-Task
level	I-Task
search	I-Task
in	O
a	O
CBIR	B-Method
framework	O
,	O
but	O
the	O
impact	O
of	O
using	O
PCA	B-Method
on	O
feature	B-Task
dimensionality	I-Task
reduction	I-Task
has	O
been	O
overlooked	O
in	O
previous	O
works	O
[	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
.	O
Inspired	O
by	O
the	O
finelevel	B-Method
search	I-Method
using	O
augmented	O
features	O
in	O
CBIR	B-Method
frameworks	O
,	O
the	O
high	O
dimensional	O
features	O
in	O
the	O
leaf	O
nodes	O
in	O
an	O
RF	B-Method
can	O
further	O
improve	O
the	O
prediction	B-Metric
accuracy	I-Metric
in	O
the	O
regression	B-Task
step	I-Task
,	O
which	O
has	O
not	O
been	O
studied	O
previously	O
.	O
	
Consequently	O
,	O
we	O
use	O
the	O
original	O
features	O
,	O
rather	O
than	O
	
PCA	B-Method
or	O
the	O
LSH	B-Method
compressed	O
features	O
,	O
to	O
perform	O
ridge	B-Method
regression	I-Method
in	O
the	O
leaf	O
nodes	O
.	O
	
Experimental	O
results	O
show	O
that	O
the	O
new	O
RF	B-Method
scheme	O
can	O
greatly	O
improve	O
the	O
quality	B-Metric
of	O
super	B-Task
-	I-Task
resolved	I-Task
images	I-Task
,	O
by	O
using	O
this	O
augmented	O
feature	O
.	O
	
Another	O
explanation	O
for	O
this	O
is	O
that	O
the	O
regression	B-Task
problems	I-Task
can	O
benefit	O
more	O
from	O
higher	O
dimensional	O
features	O
than	O
classification	B-Task
problems	I-Task
.	O
	
Based	O
on	O
the	O
observation	O
that	O
the	O
original	O
edge	O
-	O
like	O
features	O
are	O
used	O
for	O
the	O
final	O
regressors	O
in	O
the	O
leaf	O
nodes	O
and	O
the	O
compressed	O
features	O
(	O
either	O
produced	O
by	O
PCA	B-Method
or	O
LSH	B-Method
)	O
are	O
used	O
for	O
clustering	B-Method
in	O
the	O
split	O
nodes	O
,	O
a	O
new	O
clustering	B-Method
-	O
regression	O
-	O
based	O
SISR	B-Task
approach	O
can	O
be	O
designed	O
as	O
shown	O
in	O
Fig	O
.	O
6	O
.	O
	
In	O
this	O
new	O
scheme	O
,	O
the	O
original	O
-	O
compressed	O
coupled	O
feature	O
sets	O
are	O
worked	O
for	O
different	O
purposes	O
at	O
different	O
stages	O
,	O
	
i.e.	O
,	O
the	O
original	O
edge	O
features	O
are	O
used	O
for	O
regression	B-Task
in	O
the	O
leaf	O
nodes	O
,	O
and	O
the	O
compressed	O
features	O
derived	O
from	O
the	O
LSH	B-Method
-	O
like	O
functions	O
are	O
employed	O
for	O
node	B-Task
splitting	I-Task
(	O
clustering	B-Method
)	O
in	O
the	O
training	B-Task
stage	I-Task
,	O
and	O
node	B-Task
searching	I-Task
in	O
the	O
inference	B-Task
stage	I-Task
in	O
the	O
split	O
nodes	O
.	O
	
section	O
:	O
Fig	O
.	O
6	O
:	O
Augmented	O
features	O
for	O
regressors	O
and	O
the	O
LSH	B-Method
compressed	O
features	O
for	O
searching	B-Task
in	O
a	O
random	B-Method
forest	I-Method
	
In	O
the	O
new	O
scheme	O
,	O
we	O
unify	O
the	O
research	O
of	O
LSH	B-Method
-	O
based	O
SISR	B-Task
and	O
image	B-Task
retrieval	I-Task
(	O
CBIR	B-Method
)	O
	
[	O
reference	O
][	O
reference	O
]	O
.	O
	
In	O
brief	O
,	O
the	O
new	O
achievement	O
on	O
unsupervised	O
LSH	B-Method
can	O
be	O
evaluated	O
not	O
only	O
in	O
CBIR	B-Method
systems	O
,	O
but	O
also	O
in	O
the	O
clustering	B-Method
-	O
regression	O
RF	B-Method
-	O
based	O
SISR	B-Task
methods	O
.	O
	
Moreover	O
,	O
as	O
evidence	O
from	O
[	O
reference	O
]	O
,	O
proper	O
unsupervised	O
LSH	B-Method
models	O
,	O
e.g.	O
,	O
iterative	B-Method
quantization	I-Method
(	O
ITQ	B-Method
)	O
[	O
reference	O
]	O
used	O
for	O
feature	B-Task
dimension	I-Task
reduction	I-Task
instead	O
of	O
PCA	B-Method
,	O
can	O
reduce	O
the	O
damage	O
on	O
the	O
image	O
structure	O
.	O
	
This	O
can	O
further	O
improve	O
the	O
superresolved	B-Metric
image	I-Metric
quality	I-Metric
.	O
	
Different	O
from	O
[	O
reference	O
]	O
using	O
an	O
ITQ	B-Method
-	I-Method
like	I-Method
algorithm	I-Method
to	O
rotate	O
the	O
original	O
features	O
into	O
a	O
new	O
feature	O
space	O
,	O
with	O
the	O
use	O
of	O
the	O
proposed	O
original	O
-	O
compressed	O
coupled	O
feature	O
sets	O
,	O
any	O
unsupervised	O
LSH	B-Method
generated	O
features	O
can	O
directly	O
be	O
employed	O
.	O
	
section	O
:	O
Generalized	B-Method
Weighted	I-Method
Ridge	I-Method
Regression	I-Method
Model	I-Method
	
In	O
this	O
sub	O
-	O
section	O
,	O
we	O
further	O
analyze	O
the	O
ridge	B-Method
regression	I-Method
employed	O
in	O
the	O
RF	B-Method
leaf	O
nodes	O
.	O
	
The	O
anchored	B-Method
neighborhood	I-Method
regression	I-Method
(	O
ANR	B-Method
)	O
[	O
reference	O
]	O
model	O
relaxes	O
the	O
1	O
-	O
norm	O
in	O
Eqn	O
.	O
	
(	O
6	O
)	O
to	O
the	O
2	O
-	O
norm	O
constraint	O
,	O
with	O
least	B-Method
-	I-Method
squares	I-Method
minimization	I-Method
as	O
the	O
following	O
equation	O
,	O
	
Based	O
on	O
the	O
ridge	B-Method
regression	I-Method
[	O
reference	O
]	O
theory	O
,	O
this	O
2	B-Method
-	I-Method
norm	I-Method
constrained	I-Method
least	I-Method
square	I-Method
regression	I-Method
regularized	I-Method
problem	I-Method
has	O
a	O
closed	O
-	O
form	O
solution	O
,	O
according	O
to	O
the	O
Tikhonov	B-Method
regularization	I-Method
theory	I-Method
,	O
as	O
follows	O
:	O
	
With	O
the	O
assumption	O
in	O
[	O
reference	O
]	O
,	O
where	O
HR	O
patches	O
and	O
their	O
counterpart	O
LR	B-Task
patches	O
share	O
the	O
same	O
reconstructed	O
coefficient	O
α	O
,	O
i.e.	O
=	O
D	O
ℎ	O
,	O
from	O
Eqn	O
.	O
	
[	O
reference	O
]	O
	
we	O
have	O
	
If	O
we	O
define	O
as	O
a	O
pre	O
-	O
calculated	O
projection	O
matrix	O
,	O
as	O
follows	O
,	O
	
then	O
the	O
HR	O
patches	O
can	O
be	O
reconstructed	O
with	O
=	O
.	O
	
Having	O
studied	O
the	O
model	O
in	O
Eqn	O
.	O
	
(	O
18	O
)	O
,	O
the	O
authors	O
in	O
[	O
reference	O
]	O
argued	O
that	O
different	O
weights	O
should	O
be	O
given	O
to	O
different	O
atoms	O
when	O
reconstructing	O
an	O
HR	O
patch	O
so	O
as	O
to	O
emphasize	O
the	O
similarity	O
to	O
the	O
anchor	O
atom	O
.	O
	
Based	O
on	O
this	O
idea	O
,	O
[	O
reference	O
]	O
proposed	O
a	O
weighted	B-Method
collaborative	I-Method
representation	I-Method
(	O
WCR	B-Method
)	O
model	O
by	O
generalizing	O
the	O
normal	B-Method
collaborative	I-Method
representation	I-Method
(	O
CR	B-Method
)	I-Method
model	I-Method
in	O
the	O
ANR	B-Method
,	O
	
where	O
is	O
a	O
diagonal	O
weight	O
matrix	O
,	O
in	O
which	O
the	O
non	O
-	O
zero	O
entries	O
are	O
proportional	O
to	O
the	O
similarities	O
between	O
the	O
atoms	O
and	O
the	O
anchor	O
atom	O
.	O
	
Same	O
as	O
the	O
ANR	B-Method
model	O
,	O
a	O
new	O
closed	B-Method
-	I-Method
form	I-Method
solution	I-Method
can	O
be	O
computed	O
offline	O
through	O
the	O
following	O
	
and	O
the	O
new	O
projection	O
matrix	O
can	O
be	O
derived	O
as	O
	
The	O
WCR	B-Method
model	O
further	O
improves	O
the	O
ANR	B-Method
/	O
A	O
+	O
model	O
in	O
terms	O
of	O
image	B-Metric
quality	I-Metric
,	O
while	O
keeping	O
the	O
same	O
level	O
of	O
computation	O
.	O
	
In	O
[	O
reference	O
]	O
,	O
the	O
local	O
geometry	O
prior	O
of	O
the	O
data	O
sub	O
-	O
space	O
is	O
used	O
.	O
	
However	O
,	O
all	O
the	O
weighted	B-Method
ridge	I-Method
regression	I-Method
models	I-Method
[	O
reference	O
][	O
reference	O
]	O
are	O
constructed	O
based	O
on	O
an	O
existing	O
dictionary	O
,	O
e.g.	O
,	O
Zeyde	O
et	O
al	O
.	O
	
[	O
reference	O
]	O
used	O
K	B-Method
-	I-Method
SVD	I-Method
to	O
train	O
a	O
sparse	B-Method
-	I-Method
coding	I-Method
-	I-Method
based	I-Method
dictionary	I-Method
with	O
1024	O
items	O
.	O
	
This	O
limits	O
the	O
models	O
to	O
collect	O
samples	O
in	O
a	O
smaller	O
sub	O
-	O
space	O
when	O
constructing	O
linear	B-Method
regressors	I-Method
based	O
on	O
existing	O
anchor	O
points	O
.	O
	
section	O
:	O
Fig	O
.	O
7	O
:	O
	
Gaussian	B-Method
mixture	I-Method
model	I-Method
(	O
GMM	B-Method
)	O
is	O
used	O
to	O
generate	O
the	O
weights	O
for	O
weighted	B-Task
ridge	I-Task
regression	I-Task
,	O
and	O
the	O
weight	O
of	O
each	O
entry	O
lies	O
on	O
its	O
belonging	O
cluster	O
's	O
weight	O
and	O
its	O
weight	O
in	O
the	O
belonging	O
cluster	O
.	O
	
When	O
training	O
the	O
regressors	O
in	O
an	O
RF	B-Method
,	O
there	O
is	O
no	O
existing	O
anchor	O
point	O
in	O
the	O
clustered	O
groups	O
of	O
the	O
leaf	O
nodes	O
,	O
similar	O
to	O
the	O
previous	O
models	O
[	O
	
reference	O
][	O
reference	O
]	O
.	O
A	O
solution	O
to	O
mentioned	O
problem	O
is	O
inspired	O
from	O
the	O
work	O
on	O
image	B-Task
classification	I-Task
using	O
locality	B-Method
-	I-Method
constrained	I-Method
linear	I-Method
coding	I-Method
(	O
LLC	B-Method
)	O
[	O
reference	O
]	O
,	O
where	O
Gaussian	B-Method
mixture	I-Method
model	I-Method
(	O
GMM	B-Method
)	O
is	O
used	O
to	O
describe	O
the	O
locality	B-Method
-	I-Method
constrained	I-Method
affine	I-Method
subspace	I-Method
coding	I-Method
(	O
LASC	B-Method
)	O
	
[	O
reference	O
]	O
.	O
	
We	O
employ	O
GMM	B-Method
to	O
construct	O
the	O
data	O
distribution	O
in	O
the	O
sub	O
-	O
space	O
for	O
each	O
leaf	O
node	O
,	O
which	O
derives	O
the	O
weights	O
of	O
all	O
the	O
entries	O
in	O
the	O
ridge	B-Method
regression	I-Method
models	I-Method
.	O
	
Through	O
the	O
derived	O
weights	O
,	O
we	O
can	O
obtain	O
a	O
generalized	B-Method
weighted	I-Method
ridge	I-Method
regression	I-Method
(	O
GWRR	B-Method
)	O
model	O
for	O
ridge	B-Task
regression	I-Task
.	O
	
The	O
new	O
projection	O
matrix	O
is	O
given	O
as	O
follows	O
:	O
	
where	O
is	O
a	O
diagonal	O
weight	O
matrix	O
,	O
and	O
the	O
weight	O
of	O
each	O
diagonal	O
entry	O
is	O
related	O
to	O
its	O
belonging	O
cluster	O
's	O
weight	O
and	O
its	O
local	O
weight	O
in	O
its	O
belongingwhi	O
cluster	O
,	O
as	O
illustrated	O
in	O
the	O
right	O
part	O
of	O
Fig	O
.	O
7	O
.	O
	
Obviously	O
,	O
a	O
query	O
entry	O
falling	O
into	O
a	O
bigger	O
cluster	O
and	O
closer	O
to	O
the	O
center	O
of	O
the	O
belonging	O
cluster	O
achieves	O
a	O
larger	O
weight	O
.	O
	
In	O
a	O
rough	O
form	O
,	O
the	O
diagonal	O
weight	O
matrix	O
is	O
given	O
as	O
follows	O
:	O
	
where	O
is	O
the	O
weight	O
of	O
the	O
th	O
entry	O
,	O
is	O
number	O
of	O
samples	O
in	O
the	O
leaf	O
nodes	O
,	O
is	O
the	O
th	O
cluster	O
's	O
weight	O
for	O
the	O
th	O
entry	O
,	O
is	O
the	O
th	O
entry	O
's	O
local	O
weight	O
in	O
the	O
th	O
cluster	O
,	O
which	O
is	O
approximated	O
with	O
the	O
inverse	O
value	O
of	O
the	O
distance	O
to	O
the	O
center	O
of	O
the	O
belonging	O
cluster	O
,	O
and	O
is	O
the	O
number	O
of	O
clusters	O
generated	O
by	O
the	O
GMM	B-Method
model	O
for	O
a	O
leaf	O
node	O
.	O
	
Experimental	O
results	O
in	O
Table	O
-	O
1	O
show	O
that	O
the	O
proposed	O
GWRR	B-Method
model	O
can	O
achieve	O
the	O
same	O
level	O
of	O
performance	O
as	O
WCR	B-Method
[	O
reference	O
]	O
,	O
and	O
obtain	O
0.2dB	O
gain	O
more	O
than	O
the	O
ANR	B-Method
[	O
1	O
]	O
model	O
.	O
	
Note	O
that	O
when	O
the	O
number	O
of	O
samples	O
in	O
a	O
leaf	O
node	O
becomes	O
bigger	O
,	O
the	O
performance	O
of	O
the	O
GWRR	B-Method
model	O
will	O
achieve	O
less	O
advantage	O
than	O
the	O
normal	B-Method
regression	I-Method
model	I-Method
,	O
because	O
the	O
higher	O
weights	O
will	O
be	O
averaged	O
by	O
a	O
large	O
number	O
of	O
other	O
samples	O
.	O
	
Theoretically	O
,	O
the	O
regression	B-Task
of	I-Task
a	I-Task
leaf	I-Task
node	I-Task
can	O
benefit	O
from	O
the	O
GWRR	B-Method
model	O
,	O
particularly	O
when	O
there	O
are	O
a	O
few	O
samples	O
falling	O
into	O
the	O
leaf	O
node	O
.	O
	
section	O
:	O
Initial	B-Task
Estimation	I-Task
with	O
Iterative	B-Method
Back	I-Method
Projection	I-Method
	
Generally	O
speaking	O
,	O
SISR	B-Task
is	O
a	O
low	B-Task
-	I-Task
level	I-Task
computer	I-Task
vision	I-Task
task	I-Task
,	O
which	O
attempts	O
to	O
restore	O
an	O
HR	O
image	O
from	O
a	O
single	O
input	O
LR	B-Task
image	O
.	O
	
A	O
mathematical	B-Method
model	I-Method
for	O
image	B-Task
degradation	I-Task
can	O
be	O
formulated	O
as	O
follows	O
:	O
	
where	O
ℬ	O
is	O
a	O
low	B-Method
-	I-Method
pass	I-Method
(	I-Method
blur	I-Method
)	I-Method
filter	I-Method
and	O
	O
denotes	O
the	O
down	B-Method
-	I-Method
sampling	I-Method
operator	I-Method
with	O
factor	O
.	O
	
Based	O
on	O
a	O
given	O
LR	B-Task
image	O
,	O
how	O
to	O
achieve	O
an	O
approximated	B-Task
HR	I-Task
image	I-Task
̂	I-Task
is	O
a	O
classic	O
inverse	B-Task
problem	I-Task
,	O
which	O
requires	O
priors	O
based	O
on	O
the	O
Bayesian	B-Method
theory	I-Method
.	O
	
Irani	O
and	O
Peleg	O
[	O
reference	O
]	O
firstly	O
proposed	O
an	O
iterative	B-Method
back	I-Method
projection	I-Method
(	O
IBP	B-Method
)	O
method	O
for	O
SR	B-Task
reconstruction	O
,	O
and	O
IBP	B-Method
is	O
the	O
most	O
effective	O
way	O
to	O
obtain	O
an	O
HR	O
image	O
when	O
comparing	O
it	O
with	O
other	O
SR	B-Task
methods	O
.	O
	
In	O
the	O
IBP	B-Method
method	O
,	O
the	O
reconstruction	B-Metric
error	I-Metric
of	O
an	O
estimated	O
LR	B-Task
image	O
̂	O
is	O
the	O
difference	O
between	O
the	O
input	O
LR	B-Task
and	O
the	O
synthesized	O
image	O
̂	O
generated	O
from	O
the	O
estimated	O
HR	O
image	O
̂	O
as	O
follows	O
:	O
	
IBP	B-Method
is	O
an	O
efficient	O
approach	O
to	O
obtain	O
the	O
HR	B-Task
image	I-Task
by	O
minimizing	O
the	O
reconstruction	B-Metric
error	I-Metric
defined	O
by	O
Eqn	O
.	O
	
[	O
reference	O
]	O
.	O
For	O
the	O
IBP	B-Method
approach	O
on	O
SISR	B-Task
,	O
the	O
updating	B-Method
procedure	I-Method
can	O
be	O
summarized	O
as	O
the	O
following	O
two	O
steps	O
,	O
performed	O
iteratively	O
:	O
	
•	O
	
Compute	O
the	O
reconstruction	B-Metric
error	I-Metric
(	O
̂	O
)	O
with	O
the	O
following	O
equation	O
:	O
	
where	O
↑	O
is	O
the	O
up	B-Method
-	I-Method
sampling	I-Method
operator	I-Method
and	O
is	O
a	O
constant	B-Method
back	I-Method
-	I-Method
projection	I-Method
kernel	I-Method
to	O
approximate	O
the	O
inverse	O
operation	O
of	O
the	O
low	B-Method
-	I-Method
pass	I-Method
filter	I-Method
ℬ.	O
	
•	O
	
Update	O
the	O
estimating	B-Task
HR	I-Task
image	I-Task
̂	I-Task
by	O
back	O
-	O
projecting	O
errors	O
as	O
follows	O
:	O
	
where	O
̂	O
is	O
the	O
estimated	O
HR	O
image	O
at	O
the	O
-	O
th	O
iteration	O
.	O
	
Most	O
learning	B-Method
-	I-Method
based	I-Method
algorithms	I-Method
[	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
follow	O
the	O
milestone	O
work	O
in	O
[	O
reference	O
]	O
,	O
which	O
uses	O
the	O
coarse	B-Task
estimation	I-Task
firstly	O
obtained	O
via	O
bicubic	B-Method
interpolation	I-Method
.	O
	
As	O
we	O
know	O
,	O
the	O
classic	O
IBP	B-Method
algorithm	O
is	O
an	O
efficient	O
way	O
to	O
obtain	O
high	O
-	O
quality	O
up	O
-	O
scaled	O
images	O
,	O
but	O
it	O
will	O
inevitably	O
produce	O
artifacts	O
(	O
such	O
as	O
ringing	O
,	O
jaggy	O
effects	O
,	O
and	O
noise	O
)	O
at	O
the	O
output	O
,	O
because	O
the	O
kernel	O
operator	O
in	O
Eqn	O
.	O
	
(	O
29	O
)	O
is	O
hard	O
to	O
estimate	O
accurately	O
.	O
	
That	O
is	O
the	O
reason	O
why	O
algorithms	O
with	O
IBP	B-Method
need	O
an	O
additional	O
denoising	B-Method
process	I-Method
[	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
.	O
	
However	O
,	O
the	O
sparse	B-Method
-	I-Method
constraint	I-Method
-	I-Method
based	I-Method
approach	I-Method
[	O
reference	O
]	O
does	O
not	O
have	O
this	O
denoising	B-Method
capability	I-Method
.	O
	
As	O
the	O
2	B-Method
-	I-Method
norm	I-Method
constraint	I-Method
-	I-Method
based	I-Method
ridge	I-Method
regression	I-Method
has	O
the	O
denoising	O
effect	O
,	O
due	O
to	O
its	O
averaging	B-Method
-	I-Method
like	I-Method
process	I-Method
,	O
this	O
means	O
that	O
the	O
ridge	O
regression	O
-	O
based	O
RF	B-Method
scheme	O
has	O
the	O
denoise	O
capability	O
intrinsically	O
.	O
	
Based	O
on	O
this	O
observation	O
,	O
we	O
obtain	O
the	O
coarse	B-Task
estimation	I-Task
of	I-Task
an	I-Task
HR	I-Task
image	I-Task
̂	O
by	O
applying	O
IBP	B-Method
to	O
the	O
corresponding	O
input	O
LR	B-Task
image	O
.	O
	
Experimental	O
results	O
in	O
Table	O
-	O
2	O
and	O
Table	O
-	O
3	O
validate	O
that	O
using	O
IBP	B-Method
,	O
instead	O
of	O
bicubic	O
,	O
to	O
obtain	O
the	O
initial	B-Task
coarse	I-Task
estimation	I-Task
can	O
help	O
the	O
RF	B-Method
-	O
based	O
SR	B-Task
method	O
obtain	O
a	O
remarkable	O
improvement	O
.	O
	
As	O
the	O
number	O
of	O
trees	O
is	O
an	O
important	O
parameter	O
in	O
RF	B-Method
-	O
based	O
approaches	O
,	O
we	O
plot	O
the	O
performance	O
with	O
respect	O
to	O
the	O
number	O
of	O
trees	O
.	O
	
As	O
shown	O
in	O
Fig	O
.	O
8	O
,	O
the	O
performance	O
of	O
the	O
RF	B-Method
-	O
based	O
image	O
superresolution	O
method	O
increases	O
as	O
expected	O
,	O
but	O
the	O
increment	O
becomes	O
relatively	O
smaller	O
after	O
a	O
certain	O
number	O
of	O
trees	O
are	O
used	O
.	O
	
The	O
experimental	O
results	O
in	O
Fig	O
.	O
	
8	O
	
section	O
:	O
Fine	B-Task
-	I-Task
Tuning	I-Task
with	O
Proper	O
Trees	O
in	O
Random	B-Method
Forest	I-Method
	
section	O
:	O
PSNR	B-Metric
	
section	O
:	O
Set14	B-Material
	
million	O
samples	O
from	O
the	O
dataset	O
are	O
used	O
for	O
all	O
training	O
stages	O
.	O
	
It	O
shows	O
that	O
using	O
45	O
trees	O
is	O
an	O
optimal	O
number	O
,	O
as	O
a	O
trade	O
-	O
off	O
between	O
performance	O
and	O
computational	B-Metric
cost	I-Metric
.	O
	
Therefore	O
,	O
we	O
set	O
the	O
number	O
of	O
trees	O
for	O
the	O
proposed	O
FARF	B-Method
method	O
at	O
45	O
,	O
and	O
our	O
method	O
with	O
this	O
number	O
is	O
denoted	O
as	O
FARF*.	B-Method
The	O
performances	O
of	O
our	O
methods	O
,	O
and	O
other	O
methods	O
,	O
are	O
tabulated	O
in	O
	
Table	O
-	O
2	O
and	O
Table	O
-	O
3	O
.	O
	
We	O
also	O
compare	O
our	O
methods	O
with	O
a	O
recently	O
proposed	O
deep	B-Method
-	I-Method
learning	I-Method
-	I-Method
based	I-Method
algorithm	I-Method
,	O
SRCNN	B-Method
algorithm	I-Method
[	O
reference	O
][	O
reference	O
]	O
,	O
and	O
our	O
methods	O
outperform	O
it	O
in	O
some	O
cases	O
.	O
	
section	O
:	O
Algorithm	O
Workflow	O
	
The	O
training	O
and	O
inference	B-Task
stages	I-Task
of	O
the	O
proposed	O
FARF	B-Method
algorithm	I-Method
are	O
described	O
in	O
Algorithm	O
1	O
and	O
Algorithm	O
2	O
,	O
respectively	O
.	O
	
To	O
help	O
the	O
readers	O
understand	O
our	O
paper	O
,	O
the	O
source	O
code	O
of	O
our	O
algorithm	O
will	O
be	O
available	O
at	O
:	O
https:	O
//	O
github.com	O
/	O
HarleyHK	O
/	O
FARF	B-Method
,	O
for	O
reference	O
.	O
	
section	O
:	O
EXPERIMENTS	O
	
In	O
this	O
section	O
,	O
we	O
evaluate	O
our	O
algorithm	O
on	O
standard	O
super	O
-	O
resolution	O
benchmarks	O
Set	B-Material
5	I-Material
,	O
Set14	B-Material
and	O
B100	B-Material
[	O
reference	O
]	O
,	O
and	O
compare	O
it	O
with	O
some	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
methods	O
.	O
	
They	O
are	O
bicubic	B-Method
interpolation	I-Method
,	O
adjusted	O
anchored	B-Method
neighborhood	I-Method
regression	I-Method
(	O
A	O
+	O
)	O
[	O
reference	O
]	O
,	O
standard	O
RF	B-Method
[	O
reference	O
]	O
,	O
alternating	B-Method
regression	I-Method
forests	I-Method
(	O
ARF	B-Method
)	O
[	O
reference	O
]	O
,	O
and	O
the	O
convolutional	B-Method
neural	I-Method
-	I-Method
network	I-Method
-	I-Method
based	I-Method
image	I-Method
super	I-Method
-	I-Method
resolution	I-Method
(	O
SRCNN	B-Method
)	O
[	O
reference	O
][	O
reference	O
]	O
,	O
as	O
listed	O
in	O
Table	O
-	O
2	O
and	O
	
Table	O
-	O
Table	O
-	O
2	O
:	O
Results	O
of	O
the	O
proposed	O
method	O
compared	O
with	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
works	O
on	O
3	O
datasets	O
in	O
terms	O
of	O
PSNR	B-Metric
(	O
dB	O
)	O
using	O
three	O
different	O
magnification	O
factors	O
(	O
#	O
)	O
(	O
×2	O
,	O
×3	O
,	O
×4	O
)	O
.	O
	
Table	O
-	O
2	O
summarizes	O
the	O
performances	O
of	O
our	O
proposed	O
algorithm	O
on	O
the	O
3	O
datasets	O
,	O
in	O
terms	O
of	O
the	O
average	B-Metric
peak	I-Metric
signal	I-Metric
to	I-Metric
noise	I-Metric
ratio	I-Metric
(	O
PSNR	B-Metric
)	O
scores	O
,	O
with	O
different	O
magnification	O
factors	O
(	O
×2	O
,	O
×3	O
,	O
×4	O
)	O
.	O
	
The	O
objective	B-Metric
quality	I-Metric
metric	I-Metric
,	O
PSNR	B-Metric
,	O
in	O
Table	O
-	O
2	O
also	O
shows	O
that	O
the	O
fine	O
-	O
tuned	O
FARF	B-Method
,	O
i.e.	O
FARF	B-Method
*	O
,	O
can	O
further	O
improve	O
the	O
image	B-Metric
quality	I-Metric
,	O
which	O
is	O
comparable	O
to	O
recently	O
proposed	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
deeplearning	B-Method
-	I-Method
based	I-Method
algorithms	I-Method
,	O
such	O
as	O
SRCNN	B-Method
[	O
reference	O
][	O
reference	O
]	O
.	O
	
Comparing	O
our	O
proposed	O
FARF	B-Method
algorithm	I-Method
to	O
other	O
methods	O
,	O
the	O
improved	O
visual	B-Metric
quality	I-Metric
of	O
our	O
results	O
is	O
obvious	O
,	O
as	O
shown	O
in	O
Fig	O
.	O
9	O
.	O
	
This	O
shows	O
that	O
our	O
method	O
can	O
produce	O
more	O
details	O
,	O
particularly	O
on	O
some	O
texture	O
-	O
rich	O
regions	O
.	O
	
Fig	O
.	O
	
9	O
:	O
	
Super	B-Task
-	I-Task
resolution	I-Task
(	O
×3	O
)	O
images	O
from	O
B100	B-Material
,	O
bicubic	O
,	O
A	O
+	O
(	O
ACCV	O
-	O
2014	O
)	O
	
[	O
reference	O
]	O
,	O
ARF	B-Method
(	O
CVPR	B-Method
-	I-Method
2015	I-Method
)	O
[	O
reference	O
]	O
,	O
SRCNN	B-Method
(	O
PAMI	B-Method
-	I-Method
2016	I-Method
)	O
[	O
reference	O
]	O
,	O
our	O
proposed	O
algorithm	O
FARF	B-Method
,	O
and	O
ground	B-Metric
truth	I-Metric
.	O
	
The	O
results	O
show	O
that	O
our	O
FARF	B-Method
algorithm	I-Method
can	O
produce	O
more	O
details	O
and	O
its	O
performance	O
is	O
comparable	O
to	O
a	O
recent	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
deep	B-Method
-	I-Method
learning	I-Method
method	I-Method
[	O
reference	O
]	O
.	O
	
section	O
:	O
CONCLUSIONS	O
	
This	O
paper	O
presents	O
a	O
feature	B-Method
-	I-Method
augmented	I-Method
random	I-Method
forest	I-Method
(	O
FARF	B-Method
)	O
scheme	O
for	O
the	O
single	B-Task
image	I-Task
superresolution	I-Task
(	O
SISR	B-Task
)	O
task	O
by	O
augmenting	O
features	O
and	O
redesigning	O
the	O
inner	O
structure	O
of	O
a	O
random	B-Method
forest	I-Method
(	O
RF	B-Method
)	O
,	O
with	O
different	O
feature	B-Method
recipes	I-Method
at	O
different	O
stages	O
,	O
where	O
the	O
compressed	O
features	O
are	O
used	O
for	O
clustering	B-Method
in	O
the	O
split	O
nodes	O
and	O
the	O
original	O
features	O
are	O
used	O
for	O
regression	B-Task
in	O
the	O
leaf	O
nodes	O
.	O
	
The	O
contributions	O
of	O
this	O
paper	O
are	O
threefold	O
:	O
(	O
1	O
)	O
the	O
more	O
discriminative	B-Method
gradient	I-Method
magnitude	I-Method
-	I-Method
based	I-Method
augmented	I-Method
features	I-Method
are	O
proposed	O
for	O
clustering	B-Method
on	O
split	O
nodes	O
and	O
regression	B-Task
on	O
leaf	O
nodes	O
;	O
(	O
2	O
)	O
By	O
extending	O
principal	B-Method
component	I-Method
analysis	I-Method
(	O
PCA	B-Method
)	O
to	O
a	O
generalized	O
unsupervised	O
locality	O
-	O
sensitive	O
hashing	O
(	O
LSH	B-Method
)	O
model	O
for	O
dimensionality	B-Task
reduction	I-Task
,	O
we	O
lay	O
out	O
an	O
original	O
compressed	O
coupled	O
feature	O
set	O
for	O
tackling	O
the	O
clustering	B-Method
-	O
regression	O
tasks	O
,	O
which	O
unify	O
SISR	B-Task
and	O
content	B-Method
-	I-Method
based	I-Method
image	I-Method
retrieval	I-Method
(	O
CBIR	B-Method
)	O
for	O
LSH	B-Method
evaluation	O
;	O
and	O
(	O
3	O
)	O
we	O
have	O
extended	O
WCR	B-Method
model	O
to	O
a	O
generalized	O
GWRR	B-Method
model	O
for	O
ridge	B-Method
regression	I-Method
.	O
	
The	O
proposed	O
FAFR	B-Method
scheme	I-Method
can	O
achieve	O
highly	O
competitive	O
quality	O
results	O
,	O
e.g.	O
,	O
obtaining	O
about	O
a	O
0.3dB	O
gain	O
in	O
PSNR	B-Metric
,	O
on	O
average	O
,	O
when	O
compared	O
to	O
conventional	O
RF	B-Method
-	O
based	O
super	O
-	O
resolution	O
approaches	O
.	O
	
Furthermore	O
,	O
a	O
fine	O
-	O
tuned	O
version	O
of	O
our	O
proposed	O
FARF	B-Method
approach	O
is	O
provided	O
,	O
whose	O
performance	O
is	O
comparable	O
to	O
recent	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
deep	B-Method
-	I-Method
learning	I-Method
-	I-Method
based	I-Method
algorithms	I-Method
.	O
	
section	O
:	O
	
document	O
:	O
Massively	B-Task
Multilingual	I-Task
Sentence	I-Task
Embeddings	I-Task
for	O
Zero	B-Task
-	I-Task
Shot	I-Task
Cross	I-Task
-	I-Task
Lingual	I-Task
Transfer	I-Task
and	O
Beyond	O
	
We	O
introduce	O
an	O
architecture	O
to	O
learn	O
joint	O
multilingual	O
sentence	B-Task
representations	I-Task
for	O
93	O
languages	O
,	O
belonging	O
to	O
more	O
than	O
30	O
different	O
language	O
families	O
and	O
written	O
in	O
28	O
different	O
scripts	O
.	O
	
Our	O
system	O
uses	O
a	O
single	O
BiLSTM	B-Method
encoder	I-Method
with	O
a	O
shared	O
BPE	B-Method
vocabulary	O
for	O
all	O
languages	O
,	O
which	O
is	O
coupled	O
with	O
an	O
auxiliary	B-Method
decoder	I-Method
and	O
trained	O
on	O
publicly	O
available	O
parallel	O
corpora	O
.	O
	
This	O
enables	O
us	O
to	O
learn	O
a	O
classifier	B-Method
on	O
top	O
of	O
the	O
resulting	O
sentence	B-Method
embeddings	I-Method
using	O
English	O
annotated	O
data	O
only	O
,	O
and	O
transfer	O
it	O
to	O
any	O
of	O
the	O
93	O
languages	O
without	O
any	O
modification	O
.	O
	
Our	O
approach	O
sets	O
a	O
new	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
on	O
zero	O
-	O
shot	O
cross	B-Task
-	I-Task
lingual	I-Task
natural	I-Task
language	I-Task
inference	I-Task
for	O
all	O
the	O
14	O
languages	O
in	O
the	O
XNLI	B-Material
dataset	I-Material
but	O
one	O
.	O
	
We	O
also	O
achieve	O
very	O
competitive	O
results	O
in	O
cross	B-Task
-	I-Task
lingual	I-Task
document	I-Task
classification	I-Task
(	O
MLDoc	B-Material
dataset	I-Material
)	O
.	O
	
Our	O
sentence	B-Method
embeddings	I-Method
are	O
also	O
strong	O
at	O
parallel	B-Task
corpus	I-Task
mining	I-Task
,	O
establishing	O
a	O
new	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
in	O
the	O
BUCC	B-Material
shared	O
task	O
for	O
3	O
of	O
its	O
4	O
language	O
pairs	O
.	O
	
Finally	O
,	O
we	O
introduce	O
a	O
new	O
test	O
set	O
of	O
aligned	O
sentences	O
in	O
122	O
languages	O
based	O
on	O
the	O
Tatoeba	O
corpus	O
,	O
and	O
show	O
that	O
our	O
sentence	B-Method
embeddings	I-Method
obtain	O
strong	O
results	O
in	O
multilingual	B-Task
similarity	I-Task
search	I-Task
even	O
for	O
low	O
-	O
resource	O
languages	O
.	O
	
Our	O
PyTorch	B-Method
implementation	I-Method
,	O
pre	B-Method
-	I-Method
trained	I-Method
encoder	I-Method
and	O
the	O
multilingual	O
test	O
set	O
will	O
be	O
freely	O
available	O
.	O
	
section	O
:	O
Introduction	O
	
While	O
the	O
recent	O
advent	O
of	O
deep	B-Method
learning	I-Method
has	O
led	O
to	O
impressive	O
progress	O
in	O
Natural	B-Task
Language	I-Task
Processing	I-Task
(	O
NLP	B-Task
)	O
,	O
these	O
techniques	O
are	O
known	O
to	O
be	O
particularly	O
data	O
hungry	O
,	O
limiting	O
their	O
applicability	O
in	O
many	O
practical	O
scenarios	O
.	O
	
An	O
increasingly	O
popular	O
approach	O
to	O
alleviate	O
this	O
issue	O
is	O
to	O
first	O
learn	O
general	B-Method
language	I-Method
representations	I-Method
on	O
unlabeled	O
data	O
,	O
which	O
are	O
then	O
integrated	O
in	O
task	B-Task
-	I-Task
specific	I-Task
downstream	I-Task
systems	I-Task
.	O
	
This	O
approach	O
was	O
first	O
popularized	O
by	O
word	B-Method
embeddings	I-Method
mikolov2013distributed	O
,	O
pennington2014glove	O
,	O
but	O
has	O
recently	O
been	O
superseded	O
by	O
sentence	B-Method
-	I-Method
level	I-Method
representations	I-Method
Alexis:2017:emnlp	O
,	O
Peters:2018:naacl_elmo	O
,	O
Devlin:2018:arxiv_bert	O
.	O
	
Nevertheless	O
,	O
all	O
these	O
works	O
learn	O
a	O
separate	O
model	O
for	O
each	O
language	O
and	O
are	O
thus	O
unable	O
to	O
leverage	O
information	O
across	O
different	O
languages	O
,	O
greatly	O
limiting	O
their	O
potential	O
performance	O
for	O
low	O
-	O
resource	O
languages	O
.	O
	
In	O
this	O
work	O
,	O
we	O
are	O
interested	O
in	O
universal	O
language	O
agnostic	O
sentence	B-Method
embeddings	I-Method
,	O
that	O
is	O
,	O
vector	B-Method
representations	I-Method
of	O
sentences	O
that	O
are	O
general	O
with	O
respect	O
to	O
two	O
dimensions	O
:	O
the	O
input	O
language	O
and	O
the	O
NLP	B-Task
task	O
.	O
	
The	O
motivations	O
for	O
such	O
a	O
representation	O
are	O
multiple	O
:	O
the	O
hope	O
that	O
languages	O
with	O
limited	O
resources	O
benefit	O
from	O
joint	O
training	O
over	O
many	O
languages	O
,	O
the	O
desire	O
to	O
perform	O
zero	B-Method
-	I-Method
shot	I-Method
transfer	I-Method
of	O
an	O
NLP	B-Task
model	O
from	O
one	O
language	O
(	O
e.g.	O
English	O
)	O
to	O
another	O
,	O
and	O
the	O
possibility	O
to	O
handle	O
code	B-Task
-	I-Task
switching	I-Task
.	O
	
We	O
achieve	O
this	O
by	O
using	O
a	O
single	O
encoder	B-Method
that	O
can	O
handle	O
multiple	O
languages	O
,	O
so	O
that	O
semantically	O
similar	O
sentences	O
in	O
different	O
languages	O
are	O
close	O
in	O
the	O
resulting	O
embedding	O
space	O
.	O
	
Most	O
research	O
in	O
multilingual	O
NLP	B-Task
focuses	O
on	O
high	O
-	O
resource	O
languages	O
like	O
Chinese	O
,	O
Arabic	O
or	O
major	O
European	O
languages	O
,	O
and	O
is	O
usually	O
limited	O
to	O
a	O
few	O
(	O
most	O
often	O
only	O
two	O
)	O
languages	O
.	O
	
In	O
contrast	O
,	O
we	O
learn	O
joint	O
sentence	B-Task
representations	I-Task
for	O
93	O
different	O
languages	O
,	O
including	O
under	O
-	O
resourced	O
and	O
minority	O
languages	O
(	O
see	O
Tables	O
[	O
reference	O
]	O
and	O
[	O
reference	O
]	O
)	O
.	O
	
Our	O
system	O
is	O
trained	O
on	O
freely	O
available	O
parallel	O
texts	O
only	O
.	O
	
The	O
contributions	O
of	O
this	O
paper	O
are	O
as	O
follows	O
:	O
We	O
substantially	O
improve	O
on	O
previous	O
work	O
to	O
learn	O
joint	O
multilingual	O
sentence	B-Task
representations	I-Task
.	O
	
We	O
learn	O
one	O
shared	B-Method
encoder	I-Method
that	O
can	O
handle	O
93	O
different	O
languages	O
.	O
	
All	O
languages	O
are	O
jointly	O
embedded	O
in	O
a	O
shared	O
space	O
,	O
in	O
contrast	O
to	O
most	O
other	O
works	O
which	O
usually	O
consider	O
separate	O
English	O
/	O
foreign	O
alignments	O
.	O
	
We	O
cover	O
34	O
language	O
families	O
and	O
28	O
different	O
scripts	O
.	O
	
We	O
outperform	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
on	O
zero	O
-	O
shot	O
cross	B-Task
-	I-Task
lingual	I-Task
natural	I-Task
language	I-Task
inference	I-Task
(	O
XNLI	B-Material
dataset	I-Material
)	O
and	O
classification	B-Task
(	O
MLDoc	B-Material
dataset	I-Material
)	O
,	O
bitext	B-Task
mining	I-Task
(	O
BUCC	B-Material
dataset	I-Material
)	O
and	O
multilingual	B-Task
similarity	I-Task
search	I-Task
(	O
Tatoeba	O
dataset	O
)	O
,	O
for	O
almost	O
all	O
considered	O
languages	O
.	O
	
These	O
results	O
were	O
obtained	O
with	O
a	O
single	O
pre	O
-	O
trained	O
BiLSTM	B-Method
encoder	I-Method
for	O
all	O
93	O
languages	O
and	O
tasks	O
,	O
without	O
any	O
fine	B-Method
-	I-Method
tuning	I-Method
.	O
	
We	O
define	O
a	O
new	O
test	O
set	O
based	O
on	O
the	O
freely	O
available	O
Tatoeba	O
corpus	O
and	O
provide	O
baseline	O
results	O
for	O
122	O
languages	O
.	O
	
We	O
report	O
accuracy	B-Metric
for	O
multilingual	B-Task
similarity	I-Task
search	I-Task
on	O
this	O
test	O
set	O
,	O
but	O
the	O
corpus	O
could	O
also	O
be	O
used	O
for	O
MT	B-Task
evaluation	O
.	O
	
The	O
remaining	O
of	O
this	O
paper	O
is	O
organized	O
as	O
follows	O
.	O
	
In	O
the	O
next	O
section	O
,	O
we	O
first	O
summarize	O
related	O
work	O
.	O
	
Section	O
[	O
reference	O
]	O
then	O
describe	O
our	O
approach	O
in	O
detail	O
.	O
	
All	O
experimental	O
results	O
are	O
given	O
in	O
Sections	O
[	O
reference	O
]	O
and	O
[	O
reference	O
]	O
,	O
and	O
the	O
paper	O
concludes	O
with	O
a	O
discussion	O
and	O
directions	O
for	O
future	O
research	O
.	O
	
Dataset	O
details	O
and	O
additional	O
result	O
analysis	O
can	O
be	O
found	O
in	O
the	O
appendix	O
.	O
	
section	O
:	O
Related	O
work	O
	
Following	O
the	O
success	O
of	O
word	B-Task
embeddings	I-Task
mikolov2013distributed	O
,	O
pennington2014glove	O
,	O
there	O
has	O
been	O
an	O
increasing	O
interest	O
in	O
learning	O
continuous	B-Method
vector	I-Method
representations	I-Method
of	O
longer	O
linguistic	O
units	O
like	O
sentences	O
.	O
	
These	O
sentence	B-Method
embeddings	I-Method
are	O
commonly	O
obtained	O
using	O
a	O
Recurrent	B-Method
Neural	I-Method
Network	I-Method
(	O
RNN	B-Method
)	O
encoder	O
,	O
which	O
is	O
typically	O
trained	O
in	O
an	O
unsupervised	B-Method
way	I-Method
over	O
large	O
collections	O
of	O
unlabelled	O
corpora	O
.	O
	
For	O
instance	O
,	O
the	O
skip	B-Method
-	I-Method
thought	I-Method
model	I-Method
of	O
Kiros:2015:nips_skipthought	O
couple	O
the	O
encoder	B-Method
with	O
an	O
auxiliary	B-Method
decoder	I-Method
,	O
and	O
train	O
the	O
entire	O
system	O
end	O
-	O
to	O
-	O
end	O
to	O
predict	O
the	O
surrounding	O
sentences	O
over	O
a	O
large	O
collection	O
of	O
books	O
.	O
	
It	O
was	O
later	O
shown	O
that	O
more	O
competitive	O
results	O
could	O
be	O
obtained	O
by	O
training	O
the	O
encoder	B-Method
over	O
labeled	O
Natural	B-Task
Language	I-Task
Inference	I-Task
(	O
NLI	B-Task
)	O
data	O
Alexis:2017:emnlp	O
.	O
	
This	O
was	O
recently	O
extended	O
to	O
multitask	B-Task
learning	I-Task
,	O
combining	O
different	O
training	B-Metric
objectives	I-Metric
like	O
that	O
of	O
skip	B-Task
-	I-Task
thought	I-Task
,	O
NLI	B-Task
and	O
machine	B-Task
translation	I-Task
	
Google:2018:arxiv_srep	O
	
,	O
MLIA	O
-	O
MSR:2018:iclr_srep	O
.	O
	
While	O
the	O
previous	O
methods	O
consider	O
a	O
single	O
language	O
at	O
a	O
time	O
,	O
multilingual	B-Method
representations	I-Method
have	O
attracted	O
a	O
large	O
attention	O
in	O
recent	O
times	O
.	O
	
Most	O
of	O
this	O
research	O
focuses	O
on	O
cross	B-Task
-	I-Task
lingual	I-Task
word	I-Task
embeddings	I-Task
ruder2017survey	O
,	O
which	O
are	O
commonly	O
learned	O
jointly	O
from	O
parallel	O
corpora	O
gouws2015bilbowa	O
,	O
luong2015bilingual	O
.	O
	
An	O
alternative	O
approach	O
that	O
is	O
becoming	O
increasingly	O
popular	O
is	O
to	O
train	O
word	O
embeddings	O
independently	O
for	O
each	O
language	O
over	O
monolingual	O
corpora	O
,	O
and	O
then	O
map	O
them	O
to	O
a	O
shared	O
space	O
based	O
on	O
a	O
bilingual	O
dictionary	O
mikolov2013exploiting	O
,	O
artetxe2018generalizing	O
or	O
even	O
in	O
a	O
fully	O
unsupervised	B-Method
manner	I-Method
.	O
	
Cross	B-Method
-	I-Method
lingual	I-Method
word	I-Method
embeddings	I-Method
are	O
often	O
used	O
to	O
build	O
bag	B-Method
-	I-Method
of	I-Method
-	I-Method
word	I-Method
representations	I-Method
of	O
longer	O
linguistic	O
units	O
by	O
taking	O
their	O
respective	O
centroid	O
Klementiev:2012:coling_reuters	O
.	O
	
While	O
this	O
approach	O
has	O
the	O
advantage	O
of	O
requiring	O
a	O
weak	O
(	O
or	O
even	O
no	O
)	O
cross	O
-	O
lingual	O
signal	O
,	O
it	O
has	O
been	O
shown	O
that	O
the	O
resulting	O
sentence	B-Method
embeddings	I-Method
works	O
rather	O
poorly	O
in	O
practical	O
cross	B-Task
-	I-Task
lingual	I-Task
transfer	I-Task
settings	I-Task
Conneau:2018:emnlp_xnli	O
.	O
	
A	O
more	O
competitive	O
approach	O
that	O
we	O
follow	O
here	O
is	O
to	O
use	O
a	O
sequence	B-Method
-	I-Method
to	I-Method
-	I-Method
sequence	I-Method
encoder	I-Method
-	I-Method
decoder	I-Method
architecture	I-Method
Schwenk:2017:repl4nlp	O
,	O
hassan2018achieving	O
.	O
	
The	O
full	O
system	O
is	O
trained	O
end	O
-	O
to	O
-	O
end	O
on	O
parallel	O
corpora	O
akin	O
to	O
neural	B-Task
machine	I-Task
translation	I-Task
:	O
the	O
encoder	O
maps	O
the	O
source	O
sequence	O
into	O
a	O
fixed	O
-	O
length	O
vector	B-Method
representation	I-Method
,	O
which	O
is	O
used	O
by	O
the	O
decoder	B-Method
to	O
create	O
the	O
target	O
sequence	O
.	O
	
This	O
decoder	O
is	O
then	O
discarded	O
,	O
and	O
the	O
encoder	B-Method
is	O
kept	O
to	O
embed	O
sentences	O
in	O
any	O
of	O
the	O
training	O
languages	O
.	O
	
While	O
some	O
proposals	O
use	O
a	O
separate	O
encoder	O
for	O
each	O
language	O
Schwenk:2017:repl4nlp	O
,	O
sharing	O
a	O
single	O
encoder	O
for	O
all	O
languages	O
also	O
gives	O
strong	O
results	O
Schwenk:2018:acl_mine	O
.	O
	
Nevertheless	O
,	O
most	O
existing	O
work	O
is	O
either	O
limited	O
to	O
few	O
,	O
rather	O
close	O
languages	O
or	O
,	O
more	O
commonly	O
,	O
consider	O
pairwise	B-Method
joint	I-Method
embeddings	I-Method
with	O
English	B-Material
and	O
one	O
foreign	O
language	O
only	O
.	O
	
To	O
the	O
best	O
of	O
our	O
knowledge	O
,	O
all	O
existing	O
work	O
on	O
learning	O
multilingual	B-Task
representations	I-Task
for	O
a	O
large	O
number	O
of	O
languages	O
is	O
limited	O
to	O
word	B-Method
embeddings	I-Method
ammar2016massively	O
,	O
ours	O
being	O
the	O
first	O
paper	O
exploring	O
massively	O
multilingual	O
sentence	B-Task
representations	I-Task
.	O
	
Finally	O
,	O
while	O
all	O
the	O
previous	O
approaches	O
learn	O
a	O
fixed	B-Method
-	I-Method
length	I-Method
representation	I-Method
for	O
each	O
sentence	O
,	O
a	O
recent	O
research	O
line	O
has	O
obtained	O
very	O
strong	O
results	O
using	O
variable	B-Method
-	I-Method
length	I-Method
representations	I-Method
instead	O
,	O
consisting	O
of	O
contextualized	O
embeddings	O
of	O
the	O
words	O
in	O
the	O
sentence	O
Peters:2018:naacl_elmo	O
,	O
howard2018universal	O
,	O
Devlin:2018:arxiv_bert	O
.	O
	
For	O
that	O
purpose	O
,	O
these	O
methods	O
train	O
either	O
an	O
RNN	B-Method
or	O
self	O
-	O
attentional	O
encoder	O
over	O
unnanotated	O
corpora	O
using	O
some	O
form	O
of	O
language	B-Method
modeling	I-Method
.	O
	
A	O
classifier	B-Method
can	O
then	O
be	O
learned	O
on	O
top	O
of	O
the	O
resulting	O
encoder	B-Method
,	O
which	O
is	O
commonly	O
further	O
fine	O
-	O
tuned	O
during	O
this	O
supervised	B-Task
training	I-Task
.	O
	
Despite	O
the	O
strong	O
performance	O
of	O
these	O
approaches	O
in	O
monolingual	B-Task
settings	I-Task
,	O
we	O
argue	O
that	O
fixed	B-Method
-	I-Method
length	I-Method
approaches	I-Method
provide	O
a	O
more	O
generic	O
,	O
flexible	O
and	O
compatible	O
representation	O
form	O
for	O
our	O
multilingual	B-Task
scenario	I-Task
,	O
and	O
our	O
model	O
indeed	O
outperforms	O
the	O
multilingual	B-Method
BERT	I-Method
model	I-Method
Devlin:2018:arxiv_bert	O
in	O
zero	B-Task
-	I-Task
shot	I-Task
transfer	I-Task
(	O
	
see	O
Section	O
[	O
reference	O
]	O
)	O
.	O
	
section	O
:	O
Proposed	O
method	O
	
We	O
use	O
a	O
single	O
,	O
language	O
agnostic	O
BiLSTM	B-Method
encoder	I-Method
to	O
build	O
our	O
sentence	B-Method
embeddings	I-Method
,	O
which	O
is	O
coupled	O
with	O
an	O
auxiliary	B-Method
decoder	I-Method
and	O
trained	O
over	O
parallel	O
corpora	O
.	O
	
From	O
Section	O
[	O
reference	O
]	O
to	O
[	O
reference	O
]	O
,	O
we	O
describe	O
its	O
architecture	O
,	O
our	O
training	B-Method
strategy	I-Method
to	O
scale	O
to	O
up	O
to	O
93	O
languages	O
,	O
and	O
the	O
training	O
data	O
used	O
for	O
that	O
purpose	O
.	O
	
subsection	O
:	O
Architecture	O
	
Figure	O
[	O
reference	O
]	O
illustrates	O
the	O
architecture	O
of	O
the	O
proposed	O
system	O
,	O
which	O
is	O
based	O
on	O
Schwenk:2018:acl_mine	O
.	O
	
As	O
it	O
can	O
be	O
seen	O
,	O
sentence	B-Method
embeddings	I-Method
are	O
obtained	O
by	O
applying	O
a	O
max	B-Method
-	I-Method
pooling	I-Method
operation	I-Method
over	O
the	O
output	O
of	O
a	O
BiLSTM	B-Method
encoder	I-Method
.	O
	
These	O
sentence	B-Method
embeddings	I-Method
are	O
used	O
to	O
initialize	O
the	O
decoder	B-Method
LSTM	I-Method
through	O
a	O
linear	B-Method
transformation	I-Method
,	O
and	O
are	O
also	O
concatenated	O
to	O
its	O
input	O
embeddings	O
at	O
every	O
time	O
step	O
.	O
	
Note	O
that	O
there	O
is	O
no	O
other	O
connection	O
between	O
the	O
encoder	B-Method
and	O
the	O
decoder	B-Method
,	O
as	O
we	O
want	O
all	O
relevant	O
information	O
of	O
the	O
input	O
sequence	O
to	O
be	O
captured	O
by	O
the	O
sentence	B-Method
embedding	I-Method
.	O
	
We	O
use	O
a	O
single	O
encoder	B-Method
and	I-Method
decoder	I-Method
in	O
our	O
system	O
,	O
which	O
are	O
shared	O
by	O
all	O
languages	O
involved	O
.	O
	
For	O
that	O
purpose	O
,	O
we	O
build	O
a	O
joint	O
byte	B-Method
-	I-Method
pair	I-Method
encoding	I-Method
(	O
BPE	B-Method
)	O
vocabulary	O
with	O
50k	O
operations	O
,	O
which	O
is	O
learned	O
on	O
the	O
concatenation	O
of	O
all	O
training	O
corpora	O
.	O
	
This	O
way	O
,	O
the	O
encoder	O
has	O
no	O
explicit	O
signal	O
on	O
what	O
the	O
input	O
language	O
is	O
,	O
encouraging	O
it	O
to	O
learn	O
language	B-Method
independent	I-Method
representations	I-Method
.	O
	
In	O
contrast	O
,	O
the	O
decoder	B-Method
takes	O
a	O
language	B-Method
ID	I-Method
embedding	I-Method
that	O
specifies	O
the	O
language	O
to	O
generate	O
,	O
which	O
is	O
concatenated	O
to	O
the	O
input	O
and	O
sentence	B-Method
embeddings	I-Method
at	O
every	O
time	O
step	O
.	O
	
Scaling	O
up	O
to	O
almost	O
hundred	O
languages	O
,	O
which	O
use	O
very	O
different	O
syntax	O
,	O
writing	O
scripts	O
and	O
linguistic	O
concepts	O
,	O
naturally	O
calls	O
for	O
an	O
encoder	B-Method
with	O
sufficient	O
capacity	O
.	O
	
In	O
this	O
paper	O
,	O
we	O
limit	O
our	O
study	O
to	O
a	O
stacked	B-Method
BiLSTM	I-Method
with	O
1	O
to	O
5	O
layers	O
,	O
each	O
512	O
-	O
dimensional	O
.	O
	
The	O
resulting	O
sentence	B-Task
representations	I-Task
(	O
after	O
concatenating	O
both	O
directions	O
)	O
are	O
1024	O
dimensional	O
.	O
	
The	O
decoder	B-Method
has	O
always	O
one	O
layer	O
of	O
dimension	O
2048	O
.	O
	
The	O
input	O
embedding	B-Metric
size	I-Metric
is	O
set	O
to	O
320	O
,	O
while	O
the	O
language	B-Method
ID	I-Method
embedding	I-Method
has	O
32	O
dimensions	O
.	O
	
Training	O
[	O
-	O
1pt	O
]	O
corpus	O
[	O
-	O
2pt	O
]	O
	
size	O
	
Tatoeba	O
[	O
-	O
1pt	O
]	O
test	O
set	O
[	O
-	O
2pt	O
]	O
	
size	O
Training	O
[	O
-	O
1pt	O
]	O
corpus	O
[	O
-	O
2pt	O
]	O
	
size	O
	
Tatoeba	O
[	O
-	O
1pt	O
]	O
test	O
set	O
[	O
-	O
2pt	O
]	O
size	O
	
subsection	O
:	O
Training	O
strategies	O
	
In	O
preceding	O
work	O
,	O
each	O
sentence	O
at	O
the	O
input	O
was	O
jointly	O
translated	O
into	O
all	O
other	O
languages	O
.	O
	
While	O
this	O
approach	O
was	O
shown	O
to	O
learn	O
high	O
-	O
quality	O
representations	O
,	O
it	O
poses	O
two	O
obvious	O
drawbacks	O
when	O
trying	O
to	O
scale	O
to	O
a	O
large	O
number	O
of	O
languages	O
.	O
	
First	O
,	O
it	O
requires	O
an	O
N	O
-	O
way	O
parallel	O
corpus	O
,	O
which	O
is	O
difficult	O
to	O
obtain	O
for	O
all	O
languages	O
.	O
	
Second	O
,	O
it	O
has	O
a	O
quadratic	B-Metric
cost	I-Metric
with	O
respect	O
to	O
the	O
number	O
of	O
languages	O
,	O
making	O
training	B-Task
prohibitively	O
slow	O
as	O
the	O
number	O
of	O
languages	O
is	O
increased	O
.	O
	
In	O
our	O
preliminary	O
experiments	O
,	O
we	O
observed	O
that	O
similar	O
results	O
can	O
be	O
obtained	O
by	O
using	O
less	O
target	O
languages	O
–	O
two	O
seem	O
to	O
be	O
enough	O
.	O
	
At	O
the	O
same	O
time	O
,	O
we	O
relax	O
the	O
requirement	O
for	O
N	O
-	O
way	O
parallel	O
corpora	O
by	O
considering	O
independent	O
alignments	O
with	O
the	O
two	O
target	O
languages	O
,	O
e.g.	O
we	O
do	O
not	O
require	O
each	O
source	O
sentence	O
to	O
be	O
translated	O
into	O
the	O
two	O
target	O
languages	O
.	O
	
Training	B-Method
minimizes	O
the	O
cross	B-Metric
-	I-Metric
entropy	I-Metric
loss	I-Metric
on	O
the	O
training	O
corpus	O
,	O
alternating	O
over	O
all	O
combinations	O
of	O
the	O
languages	O
involved	O
.	O
	
For	O
that	O
purpose	O
,	O
we	O
use	O
Adam	B-Method
with	O
a	O
constant	O
learning	B-Metric
rate	I-Metric
of	O
0.001	O
and	O
dropout	O
set	O
to	O
0.1	O
,	O
and	O
train	O
for	O
a	O
fixed	O
number	O
of	O
epochs	O
.	O
	
Our	O
implementation	O
is	O
based	O
on	O
fairseq	B-Method
,	O
and	O
we	O
make	O
use	O
of	O
its	O
multi	B-Method
-	I-Method
GPU	I-Method
support	I-Method
to	O
train	O
on	O
16	O
NVIDIA	B-Method
V100	I-Method
GPUs	I-Method
with	O
a	O
total	O
batch	O
size	O
of	O
128	O
,	O
000	O
tokens	O
.	O
	
Unless	O
otherwise	O
specified	O
,	O
we	O
train	O
our	O
model	O
for	O
17	O
epochs	O
,	O
which	O
takes	O
about	O
5	O
days	O
.	O
	
Stopping	O
training	O
early	O
decreases	O
the	O
overall	O
performance	O
only	O
slightly	O
.	O
	
subsection	O
:	O
Training	O
data	O
and	O
pre	B-Task
-	I-Task
processing	I-Task
	
As	O
described	O
in	O
Section	O
[	O
reference	O
]	O
,	O
training	B-Task
requires	O
bitexts	O
aligned	O
with	O
two	O
target	O
languages	O
.	O
	
We	O
choose	O
English	B-Material
and	O
Spanish	B-Material
for	O
that	O
purpose	O
,	O
as	O
most	O
of	O
the	O
data	O
is	O
aligned	O
with	O
these	O
languages	O
.	O
	
We	O
collect	O
training	O
corpora	O
for	O
93	O
input	O
languages	O
by	O
combining	O
the	O
Europarl	O
,	O
United	O
Nations	O
,	O
OpenSubtitles2018	O
,	O
Global	O
Voices	O
,	O
Tanzil	O
and	O
Tatoeba	O
corpus	O
,	O
which	O
are	O
all	O
publicly	O
available	O
on	O
the	O
OPUS	O
website	O
.	O
	
Appendix	O
[	O
reference	O
]	O
provides	O
a	O
more	O
detailed	O
description	O
of	O
this	O
training	O
data	O
,	O
while	O
Tables	O
[	O
reference	O
]	O
and	O
[	O
reference	O
]	O
summarize	O
the	O
list	O
of	O
all	O
languages	O
used	O
for	O
training	O
,	O
their	O
language	O
family	O
,	O
writing	O
script	O
and	O
the	O
size	O
of	O
the	O
bitexts	O
.	O
	
Our	O
training	O
data	O
comprises	O
a	O
total	O
of	O
223	O
million	O
parallel	O
sentences	O
.	O
	
In	O
preliminary	O
experiments	O
,	O
we	O
observed	O
that	O
the	O
domain	O
of	O
the	O
training	O
data	O
played	O
a	O
key	O
role	O
in	O
the	O
performance	O
of	O
our	O
sentence	B-Method
embeddings	I-Method
in	O
different	O
tasks	O
.	O
	
Some	O
tasks	O
(	O
BUCC	B-Material
,	O
MLDoc	B-Material
)	O
tend	O
to	O
perform	O
better	O
when	O
the	O
encoder	B-Method
is	O
trained	O
on	O
long	O
and	O
formal	O
sentences	O
,	O
whereas	O
other	O
tasks	O
(	O
XNLI	B-Material
,	O
Tatoeba	O
)	O
benefit	O
from	O
training	O
on	O
shorter	O
and	O
more	O
informal	O
sentences	O
.	O
	
In	O
an	O
attempt	O
to	O
achieve	O
a	O
general	B-Method
purpose	I-Method
sentence	I-Method
encoder	I-Method
that	O
performs	O
well	O
on	O
all	O
tasks	O
,	O
we	O
aimed	O
at	O
balancing	O
the	O
size	O
of	O
training	O
corpora	O
with	O
long	O
and	O
short	O
sentences	O
.	O
	
For	O
that	O
purpose	O
,	O
we	O
used	O
at	O
most	O
two	O
million	O
sentences	O
from	O
OpenSubtitles	O
,	O
although	O
more	O
data	O
is	O
available	O
for	O
some	O
languages	O
.	O
	
All	O
pre	B-Task
-	I-Task
processing	I-Task
is	O
done	O
with	O
Moses	B-Method
tools	I-Method
:	O
punctuation	B-Method
normalization	I-Method
,	O
removing	O
non	O
-	O
printing	O
characters	O
and	O
tokenization	O
.	O
	
As	O
the	O
only	O
exception	O
,	O
Chinese	O
and	O
Japanese	O
texts	O
were	O
segmented	O
with	O
Jieba	O
and	O
Mecab	O
,	O
respectively	O
.	O
	
All	O
the	O
languages	O
are	O
kept	O
in	O
their	O
original	O
script	O
with	O
the	O
exception	O
of	O
Greek	O
,	O
which	O
we	O
romanize	O
into	O
the	O
Latin	O
alphabet	O
.	O
	
section	O
:	O
Experimental	O
evaluation	O
	
In	O
contrast	O
with	O
the	O
well	O
-	O
established	O
evaluation	B-Method
frameworks	I-Method
for	O
English	O
sentence	B-Task
representations	I-Task
,	O
there	O
is	O
not	O
yet	O
a	O
commonly	O
accepted	O
standard	O
to	O
evaluate	O
multilingual	O
sentence	B-Method
embeddings	I-Method
.	O
	
The	O
most	O
notable	O
effort	O
in	O
this	O
regard	O
is	O
probably	O
the	O
XNLI	B-Material
corpus	I-Material
,	O
an	O
NLI	B-Task
test	O
set	O
similar	O
to	O
MultiNLI	O
for	O
which	O
the	O
premises	O
and	O
hypotheses	O
were	O
translated	O
into	O
14	O
languages	O
by	O
professional	O
translators	O
.	O
	
We	O
train	O
an	O
NLI	B-Task
classifier	O
on	O
top	O
of	O
our	O
multilingual	B-Method
sentence	I-Method
embedding	I-Method
using	O
English	B-Material
training	I-Material
data	I-Material
,	O
and	O
evaluate	O
its	O
zero	B-Metric
-	I-Metric
shot	I-Metric
transfer	I-Metric
performance	O
in	O
the	O
remaining	O
languages	O
(	O
Section	O
[	O
reference	O
]	O
)	O
.	O
	
So	O
as	O
to	O
obtain	O
a	O
more	O
complete	O
picture	O
of	O
the	O
behavior	O
of	O
our	O
multilingual	O
sentence	B-Task
representations	I-Task
,	O
we	O
also	O
evaluate	O
them	O
in	O
cross	B-Task
-	I-Task
lingual	I-Task
document	I-Task
classification	I-Task
(	O
MLDoc	B-Material
,	O
Section	O
[	O
reference	O
]	O
)	O
,	O
and	O
bitext	B-Task
mining	I-Task
(	O
BUCC	B-Material
,	O
Section	O
[	O
reference	O
]	O
)	O
.	O
	
However	O
,	O
all	O
these	O
datasets	O
only	O
cover	O
a	O
subset	O
of	O
our	O
93	O
languages	O
,	O
so	O
we	O
also	O
introduce	O
a	O
new	O
test	O
set	O
for	O
multilingual	B-Task
similarity	I-Task
search	I-Task
in	O
122	O
languages	O
,	O
including	O
several	O
languages	O
for	O
which	O
we	O
have	O
no	O
training	O
data	O
but	O
whose	O
language	O
family	O
is	O
covered	O
(	O
Section	O
[	O
reference	O
]	O
)	O
.	O
	
We	O
remark	O
that	O
we	O
use	O
the	O
same	O
pre	O
-	O
trained	O
BiLSTM	B-Method
encoder	I-Method
for	O
all	O
tasks	O
and	O
languages	O
without	O
any	O
fine	O
-	O
tuning	O
.	O
	
subsection	O
:	O
XNLI	B-Material
:	O
cross	O
-	O
lingual	O
NLI	B-Task
	
NLI	B-Task
has	O
become	O
a	O
widely	O
used	O
task	O
to	O
evaluate	O
sentence	B-Task
representations	I-Task
snli:2015	O
,	O
multinli:2017	O
.	O
	
Given	O
two	O
sentences	O
,	O
a	O
premise	O
and	O
a	O
hypothesis	O
,	O
the	O
task	O
consists	O
in	O
deciding	O
whether	O
there	O
is	O
an	O
entailment	O
,	O
contradiction	O
or	O
neutral	O
relationship	O
between	O
them	O
.	O
	
XNLI	B-Material
is	O
a	O
recent	O
effort	O
to	O
create	O
a	O
dataset	O
similar	O
to	O
the	O
English	B-Material
MultiNLI	I-Material
for	O
several	O
languages	O
.	O
	
2	O
,	O
500	O
development	O
and	O
5	O
,	O
000	O
test	O
sentences	O
have	O
been	O
translated	O
from	O
English	O
into	O
14	O
languages	O
by	O
professional	O
translators	O
,	O
making	O
results	O
across	O
different	O
languages	O
directly	O
comparable	O
.	O
	
Note	O
that	O
no	O
human	O
translated	O
training	O
data	O
is	O
provided	O
;	O
instead	O
,	O
different	O
systems	O
are	O
to	O
use	O
English	B-Material
training	I-Material
data	I-Material
from	O
MultiNLI	O
,	O
and	O
their	O
transfer	B-Task
performance	O
is	O
evaluated	O
on	O
the	O
rest	O
of	O
languages	O
.	O
	
We	O
train	O
a	O
classifier	B-Method
on	O
top	O
of	O
our	O
multilingual	B-Method
encoder	I-Method
using	O
the	O
usual	O
combination	O
of	O
the	O
two	O
sentence	B-Method
embeddings	I-Method
:	O
,	O
where	O
and	O
are	O
the	O
premise	O
and	O
hypothesis	O
.	O
	
For	O
that	O
purpose	O
,	O
we	O
use	O
a	O
feed	B-Method
-	I-Method
forward	I-Method
neural	I-Method
network	I-Method
with	O
two	O
hidden	O
layers	O
of	O
size	O
512	O
and	O
384	O
,	O
trained	O
with	O
Adam	B-Method
.	O
	
All	O
hyperparameters	B-Method
were	O
optimized	O
on	O
the	O
English	O
XNLI	B-Material
development	O
corpus	O
,	O
and	O
then	O
,	O
the	O
same	O
classifier	B-Method
was	O
applied	O
to	O
all	O
languages	O
of	O
the	O
XNLI	B-Material
test	O
set	O
.	O
	
As	O
such	O
,	O
we	O
did	O
not	O
use	O
any	O
training	O
or	O
development	O
data	O
in	O
any	O
of	O
the	O
foreign	O
languages	O
.	O
	
Note	O
,	O
moreover	O
,	O
that	O
the	O
multilingual	O
sentence	B-Method
embeddings	I-Method
are	O
fixed	O
and	O
not	O
fine	O
-	O
tuned	O
on	O
the	O
task	O
or	O
the	O
language	O
.	O
	
We	O
report	O
our	O
results	O
in	O
Table	O
[	O
reference	O
]	O
,	O
along	O
with	O
several	O
baselines	O
from	O
Conneau:2018:emnlp_xnli	O
and	O
the	O
recently	O
released	O
multilingual	B-Method
BERT	I-Method
model	I-Method
Devlin:2018:arxiv_bert	O
.	O
	
As	O
it	O
can	O
be	O
seen	O
,	O
our	O
proposed	O
method	O
establishes	O
a	O
new	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
in	O
zero	B-Task
-	I-Task
shot	I-Task
cross	I-Task
-	I-Task
lingual	I-Task
transfer	I-Task
(	O
i.e.	O
training	O
a	O
classifier	B-Method
on	O
English	B-Material
data	I-Material
and	O
applying	O
it	O
to	O
all	O
other	O
languages	O
)	O
for	O
all	O
languages	O
but	O
Spanish	B-Material
.	O
	
Our	O
transfer	O
results	O
are	O
strong	O
and	O
homogeneous	O
across	O
all	O
languages	O
:	O
for	O
11	O
of	O
them	O
,	O
the	O
zero	B-Metric
-	I-Metric
short	I-Metric
performance	I-Metric
is	O
(	O
at	O
most	O
)	O
5	O
%	O
lower	O
than	O
the	O
one	O
on	O
English	B-Material
,	O
including	O
distant	O
languages	O
like	O
Arabic	O
,	O
Chinese	O
and	O
Vietnamese	O
,	O
and	O
we	O
also	O
achieve	O
remarkable	O
good	O
results	O
on	O
low	O
-	O
resource	O
languages	O
like	O
Swahili	O
.	O
	
In	O
contrast	O
,	O
BERT	B-Method
achieves	O
excellent	O
results	O
on	O
English	B-Material
,	O
outperforming	O
our	O
system	O
by	O
7.5	O
points	O
,	O
but	O
its	O
zero	B-Metric
-	I-Metric
shot	I-Metric
cross	I-Metric
-	I-Metric
lingual	I-Metric
transfer	I-Metric
performance	I-Metric
is	O
much	O
weaker	O
.	O
	
For	O
instance	O
,	O
the	O
loss	B-Metric
in	O
accuracy	B-Metric
for	O
both	O
Arabic	O
and	O
Chinese	O
is	O
2.5	O
points	O
for	O
our	O
system	O
,	O
compared	O
to	O
19.3	O
and	O
17.6	O
points	O
for	O
BERT	B-Task
.	O
	
Finally	O
,	O
we	O
also	O
outperform	O
all	O
baselines	O
of	O
Conneau:2018:emnlp_xnli	O
by	O
a	O
substantial	O
margin	O
,	O
with	O
the	O
additional	O
advantage	O
that	O
we	O
use	O
a	O
single	O
pre	B-Method
-	I-Method
trained	I-Method
encoder	I-Method
,	O
whereas	O
X	B-Method
-	I-Method
BiLSTM	I-Method
learns	O
a	O
separate	O
encoder	O
for	O
each	O
language	O
by	O
aligning	O
it	O
to	O
the	O
English	O
one	O
.	O
	
For	O
completeness	O
,	O
we	O
also	O
provide	O
results	O
that	O
include	O
the	O
use	O
of	O
Machine	B-Task
Translation	I-Task
(	O
MT	B-Task
)	O
.	O
	
This	O
can	O
be	O
done	O
in	O
two	O
ways	O
:	O
	
1	O
)	O
translate	O
the	O
test	O
data	O
into	O
English	B-Material
and	O
apply	O
the	O
English	O
NLI	B-Task
classifier	O
,	O
or	O
2	O
)	O
translate	O
the	O
English	B-Material
training	I-Material
data	I-Material
and	O
train	O
a	O
language	O
specific	O
NLI	B-Task
classifier	O
for	O
each	O
language	O
.	O
	
It	O
should	O
be	O
stressed	O
that	O
we	O
are	O
not	O
evaluating	O
multilingual	O
sentence	B-Method
embeddings	I-Method
anymore	O
,	O
but	O
rather	O
the	O
quality	O
of	O
the	O
MT	B-Task
system	O
and	O
a	O
monolingual	B-Method
model	I-Method
.	O
	
Moreover	O
,	O
the	O
use	O
of	O
MT	B-Task
incurs	O
in	O
an	O
important	O
overhead	O
with	O
either	O
strategy	O
:	O
	
translating	B-Task
test	I-Task
makes	O
inference	B-Task
substantially	O
more	O
expensive	O
,	O
whereas	O
translating	B-Task
train	I-Task
results	O
in	O
a	O
separate	O
model	O
for	O
each	O
language	O
.	O
	
As	O
shown	O
in	O
Table	O
[	O
reference	O
]	O
,	O
our	O
approach	O
outperforms	O
all	O
translation	B-Metric
baselines	I-Metric
of	O
Conneau:2018:emnlp_xnli	O
with	O
the	O
exception	O
of	O
Urdu	O
.	O
	
We	O
also	O
outperform	O
MT	B-Task
BERT	O
for	O
Arabic	O
and	O
Thai	O
,	O
and	O
are	O
very	O
close	O
for	O
Urdu	O
.	O
	
Finally	O
,	O
it	O
is	O
worth	O
mentioning	O
that	O
,	O
thanks	O
to	O
its	O
multilingual	O
nature	O
,	O
our	O
system	O
can	O
also	O
handle	O
premises	O
and	O
hypothesis	O
in	O
different	O
languages	O
.	O
	
As	O
reported	O
in	O
Appendix	O
[	O
reference	O
]	O
,	O
the	O
proposed	O
method	O
obtains	O
very	O
strong	O
results	O
in	O
these	O
settings	O
,	O
even	O
for	O
distant	O
language	O
combinations	O
like	O
French	B-Material
-	O
Chinese	O
.	O
	
subsection	O
:	O
MLDoc	B-Material
:	O
cross	B-Task
-	I-Task
lingual	I-Task
classification	I-Task
	
Cross	B-Task
-	I-Task
lingual	I-Task
document	I-Task
classification	I-Task
is	O
a	O
typical	O
application	O
of	O
multilingual	B-Task
representations	I-Task
.	O
	
In	O
order	O
to	O
evaluate	O
our	O
sentence	B-Method
embeddings	I-Method
in	O
this	O
task	O
,	O
we	O
use	O
the	O
MLDoc	B-Material
dataset	I-Material
of	O
Schwenk:2018:lrec_mldoc	O
,	O
which	O
is	O
an	O
improved	O
version	O
of	O
the	O
Reuters	O
benchmark	O
Lewis	O
:	O
Reuters:2004	O
,	O
Klementiev:2012:coling_reuters	O
with	O
uniform	O
class	O
priors	O
and	O
a	O
wider	O
language	O
coverage	O
.	O
	
There	O
are	O
1	O
,	O
000	O
training	O
and	O
development	O
documents	O
and	O
4	O
,	O
000	O
test	O
documents	O
for	O
each	O
language	O
,	O
divided	O
in	O
4	O
different	O
genders	O
.	O
	
Just	O
as	O
with	O
the	O
XNLI	B-Material
evaluation	O
,	O
we	O
consider	O
the	O
zero	B-Task
-	I-Task
shot	I-Task
transfer	I-Task
scenario	I-Task
:	O
we	O
train	O
a	O
classifier	B-Method
on	O
top	O
of	O
our	O
multilingual	B-Method
encoder	I-Method
using	O
the	O
English	B-Material
training	I-Material
data	I-Material
,	O
optimizing	O
hyper	O
-	O
parameters	O
on	O
the	O
English	B-Material
development	I-Material
set	I-Material
,	O
and	O
evaluating	O
the	O
resulting	O
system	O
in	O
the	O
remaining	O
languages	O
.	O
	
We	O
use	O
a	O
feed	B-Method
-	I-Method
forward	I-Method
neural	I-Method
network	I-Method
with	O
one	O
hidden	B-Method
layer	I-Method
of	O
10	O
units	O
.	O
	
As	O
shown	O
in	O
Table	O
[	O
reference	O
]	O
,	O
our	O
system	O
obtains	O
the	O
best	O
published	O
results	O
for	O
5	O
of	O
the	O
7	O
transfer	O
languages	O
.	O
	
We	O
believe	O
that	O
our	O
weaker	O
performance	O
on	O
Japanese	O
can	O
be	O
attributed	O
to	O
the	O
domain	O
and	O
sentence	O
length	O
mismatch	O
between	O
MLDoc	B-Material
and	O
the	O
parallel	O
corpus	O
we	O
use	O
for	O
this	O
language	O
(	O
OpenSubtitles	O
)	O
.	O
	
subsection	O
:	O
BUCC	B-Material
:	O
bitext	B-Task
mining	I-Task
	
Bitext	B-Task
mining	I-Task
is	O
another	O
natural	O
application	O
for	O
multilingual	O
sentence	B-Method
embeddings	I-Method
.	O
	
Given	O
two	O
comparable	O
corpora	O
in	O
different	O
languages	O
,	O
the	O
task	O
consists	O
in	O
identifying	O
sentence	O
pairs	O
that	O
are	O
translations	O
of	O
each	O
other	O
.	O
	
For	O
that	O
purpose	O
,	O
one	O
would	O
commonly	O
score	O
sentence	O
pairs	O
by	O
taking	O
the	O
cosine	O
similarity	O
of	O
their	O
respective	O
embeddings	O
,	O
so	O
parallel	O
sentences	O
can	O
be	O
extracted	O
through	O
nearest	B-Method
neighbor	I-Method
retrieval	I-Method
and	O
filtered	O
by	O
setting	O
a	O
fixed	O
threshold	O
over	O
this	O
cosine	B-Metric
score	I-Metric
Schwenk:2018:acl_mine	O
.	O
	
However	O
,	O
it	O
was	O
recently	O
shown	O
that	O
this	O
approach	O
suffers	O
from	O
scale	O
inconsistency	O
issues	O
guo2018effective	O
,	O
and	O
artetxe2018margin	O
proposed	O
the	O
following	O
alternative	O
score	O
addressing	O
it	O
:	O
where	O
and	O
are	O
the	O
source	O
and	O
target	O
sentences	O
,	O
and	O
denotes	O
the	O
nearest	O
neighbors	O
of	O
in	O
the	O
other	O
language	O
.	O
	
The	O
paper	O
explores	O
different	O
margin	O
functions	O
,	O
with	O
ratio	O
(	O
)	O
yielding	O
the	O
best	O
results	O
.	O
	
This	O
notion	O
of	O
margin	O
is	O
related	O
to	O
CSLS	B-Method
as	O
proposed	O
in	O
Conneau:2018:iclr_muse	O
.	O
	
The	O
reader	O
is	O
referred	O
to	O
artetxe2018margin	O
for	O
a	O
detailed	O
discussion	O
.	O
	
We	O
use	O
this	O
method	O
to	O
evaluate	O
our	O
sentence	B-Method
embeddings	I-Method
on	O
the	O
BUCC	B-Material
mining	O
task	O
zweigenbaum2017overview	O
,	O
zweigenbaum2018overview	O
,	O
using	O
exact	O
same	O
hyper	O
-	O
parameters	O
as	O
artetxe2018margin	O
.	O
	
The	O
goal	O
is	O
to	O
extract	O
parallel	O
sentences	O
from	O
a	O
comparable	O
corpus	O
between	O
English	B-Material
and	O
four	O
foreign	O
languages	O
:	O
German	B-Material
,	O
French	B-Material
,	O
Russian	O
and	O
Chinese	O
.	O
	
The	O
dataset	O
consists	O
of	O
150	O
K	O
to	O
1.2	O
M	O
sentences	O
for	O
each	O
language	O
,	O
split	O
into	O
a	O
sample	O
,	O
training	O
and	O
test	O
set	O
,	O
with	O
about	O
2–3	O
%	O
of	O
the	O
sentences	O
being	O
parallel	O
.	O
	
As	O
shown	O
in	O
our	O
results	O
in	O
Table	O
[	O
reference	O
]	O
,	O
our	O
sentence	B-Method
embeddings	I-Method
establish	O
a	O
new	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
for	O
all	O
language	O
pairs	O
with	O
the	O
exception	O
of	O
English	B-Material
-	I-Material
Chinese	I-Material
test	I-Material
.	O
	
Quite	O
remarkably	O
,	O
we	O
also	O
outperform	O
artetxe2018margin	O
themselves	O
,	O
who	O
use	O
two	O
separate	O
models	O
covering	O
4	O
languages	O
each	O
(	O
English	O
/	O
French	B-Material
/	O
Spanish	B-Material
/	O
German	B-Material
and	O
English	B-Material
/	O
French	B-Material
/	O
Russian	O
/	O
Chinese	O
)	O
.	O
	
The	O
average	O
performance	O
over	O
the	O
four	O
languages	O
increased	O
from	O
93.27	O
to	O
93.92	O
.	O
	
Not	O
only	O
are	O
our	O
results	O
better	O
,	O
but	O
our	O
model	O
also	O
covers	O
many	O
more	O
languages	O
,	O
so	O
it	O
can	O
potentially	O
be	O
used	O
to	O
mine	O
bitext	O
for	O
any	O
combination	O
of	O
the	O
93	O
languages	O
supported	O
.	O
	
subsection	O
:	O
Tatoeba	O
:	O
similarity	B-Task
search	I-Task
	
While	O
XNLI	B-Material
,	O
MLDoc	B-Material
and	O
BUCC	B-Material
are	O
well	O
established	O
benchmarks	O
with	O
comparative	O
results	O
available	O
,	O
they	O
only	O
cover	O
a	O
small	O
subset	O
of	O
our	O
93	O
languages	O
.	O
	
So	O
as	O
to	O
better	O
assess	O
the	O
performance	O
of	O
our	O
model	O
in	O
all	O
these	O
different	O
languages	O
,	O
we	O
introduce	O
a	O
new	O
test	O
set	O
of	O
similarity	B-Task
search	I-Task
for	O
122	O
languages	O
based	O
on	O
the	O
Tatoeba	O
corpus	O
.	O
	
The	O
dataset	O
consists	O
of	O
up	O
to	O
1	O
,	O
000	O
English	O
-	O
aligned	O
sentence	O
pairs	O
for	O
each	O
language	O
.	O
	
Appendix	O
[	O
reference	O
]	O
describes	O
how	O
the	O
dataset	O
was	O
constructed	O
in	O
more	O
details	O
.	O
	
Evaluation	O
is	O
done	O
by	O
finding	O
the	O
nearest	O
neighbor	O
for	O
each	O
sentence	O
in	O
the	O
other	O
language	O
according	O
to	O
cosine	B-Metric
similarity	I-Metric
and	O
computing	O
the	O
error	B-Metric
rate	I-Metric
.	O
	
We	O
report	O
our	O
results	O
in	O
Tables	O
[	O
reference	O
]	O
and	O
[	O
reference	O
]	O
.	O
	
Contrasting	O
these	O
results	O
with	O
those	O
of	O
XNLI	B-Material
,	O
one	O
would	O
assume	O
that	O
similarity	B-Metric
error	I-Metric
rates	I-Metric
below	O
5	O
%	O
are	O
indicative	O
of	O
strong	O
downstream	B-Task
performance	O
.	O
	
This	O
is	O
the	O
case	O
for	O
37	O
languages	O
,	O
while	O
there	O
are	O
48	O
languages	O
with	O
an	O
error	B-Metric
rate	I-Metric
below	O
10	O
%	O
and	O
55	O
with	O
less	O
than	O
20	O
%	O
,	O
covering	O
22	O
different	O
families	O
and	O
15	O
different	O
scripts	O
.	O
	
There	O
are	O
only	O
15	O
languages	O
with	O
error	B-Metric
rates	I-Metric
above	O
50	O
%	O
.	O
	
We	O
believe	O
that	O
our	O
competitive	O
results	O
for	O
many	O
low	O
-	O
resource	O
languages	O
are	O
indicative	O
of	O
the	O
benefits	O
of	O
joint	B-Method
training	I-Method
,	O
which	O
is	O
also	O
supported	O
by	O
our	O
ablation	O
results	O
in	O
Section	O
[	O
reference	O
]	O
.	O
	
In	O
relation	O
to	O
that	O
,	O
Appendix	O
[	O
reference	O
]	O
reports	O
similarity	B-Task
search	I-Task
results	O
for	O
29	O
additional	O
languages	O
without	O
any	O
training	O
data	O
,	O
showing	O
that	O
our	O
encoder	O
can	O
also	O
generalize	O
to	O
unseen	O
languages	O
to	O
some	O
extent	O
as	O
long	O
as	O
it	O
was	O
trained	O
in	O
related	O
languages	O
.	O
	
section	O
:	O
Ablation	B-Task
experiments	O
	
In	O
this	O
section	O
,	O
we	O
explore	O
different	O
variants	O
of	O
our	O
approach	O
and	O
study	O
the	O
impact	O
on	O
the	O
performance	O
for	O
all	O
our	O
evaluation	B-Task
tasks	I-Task
.	O
	
We	O
report	O
average	O
results	O
across	O
all	O
languages	O
.	O
	
For	O
XNLI	B-Material
,	O
we	O
also	O
report	O
the	O
accuracy	B-Metric
on	O
English	B-Material
.	O
	
subsection	O
:	O
Encoder	O
depth	O
	
Table	O
[	O
reference	O
]	O
reports	O
the	O
performance	O
on	O
the	O
different	O
tasks	O
for	O
encoders	B-Method
with	O
one	O
,	O
three	O
or	O
five	O
layers	O
.	O
	
We	O
were	O
not	O
able	O
to	O
achieve	O
good	O
convergence	O
with	O
deeper	B-Method
models	I-Method
.	O
	
It	O
can	O
be	O
seen	O
that	O
all	O
tasks	O
benefit	O
from	O
deeper	B-Method
models	I-Method
,	O
in	O
particular	O
XNLI	B-Material
and	O
Tatoeba	O
,	O
suggesting	O
that	O
a	O
single	B-Method
layer	I-Method
BiLSTM	I-Method
has	O
not	O
enough	O
capacity	O
to	O
encode	O
so	O
many	O
languages	O
.	O
	
subsection	O
:	O
Multitask	B-Task
learning	I-Task
	
Multitask	B-Method
learning	I-Method
has	O
been	O
shown	O
to	O
be	O
helpful	O
to	O
learn	O
English	B-Method
sentence	I-Method
embeddings	I-Method
.	O
	
The	O
most	O
important	O
task	O
in	O
this	O
approach	O
is	O
arguably	O
NLI	B-Task
,	O
so	O
we	O
explored	O
adding	O
an	O
additional	O
NLI	B-Task
objective	O
to	O
our	O
system	O
with	O
different	O
weighting	B-Method
schemes	I-Method
.	O
	
As	O
shown	O
in	O
Table	O
[	O
reference	O
]	O
,	O
the	O
NLI	B-Task
objective	O
leads	O
to	O
a	O
better	O
performance	O
on	O
the	O
English	O
NLI	B-Task
test	O
set	O
,	O
but	O
this	O
comes	O
at	O
the	O
cost	O
of	O
a	O
worse	O
cross	B-Metric
-	I-Metric
lingual	I-Metric
transfer	I-Metric
performance	I-Metric
in	O
XNLI	B-Material
and	O
Tatoeba	O
.	O
	
The	O
effect	O
in	O
BUCC	B-Material
is	O
negligible	O
.	O
	
subsection	O
:	O
Number	O
of	O
training	O
languages	O
	
So	O
as	O
to	O
better	O
understand	O
how	O
our	O
architecture	O
scales	O
to	O
a	O
large	O
amount	O
of	O
languages	O
,	O
we	O
train	O
a	O
separate	O
model	O
on	O
a	O
subset	O
of	O
18	O
evaluation	O
languages	O
,	O
and	O
compare	O
it	O
to	O
our	O
main	O
model	O
trained	O
on	O
93	O
languages	O
.	O
	
We	O
replaced	O
the	O
Tatoeba	O
corpus	O
with	O
the	O
WMT	O
2014	O
test	O
set	O
to	O
evaluate	O
the	O
multilingual	B-Metric
similarity	I-Metric
error	I-Metric
rate	I-Metric
.	O
	
This	O
covers	O
English	B-Material
,	O
Czech	O
,	O
French	B-Material
,	O
German	B-Material
and	O
Spanish	B-Material
,	O
so	O
results	O
between	O
both	O
models	O
are	O
directly	O
comparable	O
.	O
	
As	O
shown	O
in	O
Table	O
[	O
reference	O
]	O
,	O
the	O
full	O
model	O
equals	O
or	O
outperforms	O
the	O
one	O
covering	O
the	O
evaluation	O
languages	O
only	O
for	O
all	O
tasks	O
but	O
MLDoc	B-Material
.	O
	
This	O
suggests	O
that	O
the	O
joint	B-Method
training	I-Method
also	O
yields	O
to	O
overall	O
better	O
representations	O
.	O
	
section	O
:	O
Conclusions	O
	
In	O
this	O
paper	O
,	O
we	O
propose	O
an	O
architecture	O
to	O
learn	O
multilingual	O
sentence	B-Method
embeddings	I-Method
for	O
93	O
languages	O
.	O
	
We	O
use	O
a	O
single	O
language	O
-	O
agnostic	O
BiLSTM	B-Method
encoder	I-Method
for	O
all	O
languages	O
,	O
which	O
is	O
trained	O
on	O
publicly	O
available	O
parallel	O
corpora	O
and	O
applied	O
to	O
different	O
downstream	B-Task
tasks	I-Task
without	O
any	O
fine	B-Method
-	I-Method
tuning	I-Method
.	O
	
Our	O
model	O
sets	O
a	O
new	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
for	O
most	O
languages	O
in	O
zero	O
-	O
shot	O
cross	B-Task
-	I-Task
lingual	I-Task
natural	I-Task
language	I-Task
inference	I-Task
(	O
XNLI	B-Material
)	O
,	O
cross	B-Task
-	I-Task
lingual	I-Task
document	I-Task
classification	I-Task
(	O
MLDoc	B-Material
)	O
,	O
and	O
bitext	B-Task
mining	I-Task
(	O
BUCC	B-Material
)	O
.	O
	
We	O
also	O
introduce	O
a	O
new	O
test	O
set	O
of	O
cross	B-Task
-	I-Task
lingual	I-Task
similarity	I-Task
search	I-Task
in	O
122	O
languages	O
,	O
and	O
show	O
that	O
our	O
approach	O
is	O
competitive	O
even	O
for	O
low	O
-	O
resource	O
languages	O
.	O
	
To	O
the	O
best	O
of	O
our	O
knowledge	O
,	O
this	O
is	O
the	O
first	O
successful	O
exploration	O
of	O
massively	O
multilingual	O
sentence	B-Task
representations	I-Task
.	O
	
In	O
the	O
future	O
,	O
we	O
would	O
like	O
to	O
explore	O
alternative	O
architectures	O
for	O
the	O
encoder	B-Method
.	O
	
In	O
particular	O
,	O
we	O
plan	O
to	O
replace	O
our	O
BiLSTM	B-Method
with	O
the	O
Transformer	B-Method
,	O
which	O
has	O
been	O
shown	O
to	O
work	O
better	O
in	O
different	O
settings	O
vaswani2017attention	O
,	O
Devlin:2018:arxiv_bert	O
.	O
	
Moreover	O
,	O
we	O
would	O
like	O
to	O
explore	O
possible	O
strategies	O
to	O
exploit	O
monolingual	O
training	O
data	O
in	O
addition	O
to	O
parallel	O
corpora	O
,	O
such	O
as	O
using	O
pre	O
-	O
trained	O
word	B-Method
embeddings	I-Method
,	O
backtranslation	O
sennrich2016improving	O
,	O
edunov2018understanding	O
,	O
or	O
other	O
ideas	O
from	O
unsupervised	B-Method
machine	I-Method
translation	I-Method
Artetxe:2018:emnlp_unsupmt	O
,	O
Lample:2018:emnlp_unsupmt	O
.	O
	
Finally	O
,	O
we	O
would	O
like	O
to	O
replace	O
our	O
language	B-Method
-	I-Method
specific	I-Method
tokenization	I-Method
and	O
BPE	B-Method
segmentation	O
with	O
a	O
language	B-Method
agnostic	I-Method
approach	I-Method
similar	O
to	O
SentencePiece	O
.	O
	
The	O
model	O
and	O
code	O
used	O
in	O
this	O
paper	O
will	O
be	O
freely	O
available	O
in	O
the	O
framework	O
of	O
the	O
LASER	B-Method
toolkit	I-Method
.	O
	
bibliography	O
:	O
References	O
	
appendix	O
:	O
Training	O
data	O
	
Our	O
training	O
data	O
consists	O
of	O
the	O
combination	O
of	O
the	O
following	O
publicly	O
available	O
parallel	O
corpora	O
:	O
Europarl	O
provides	O
high	O
-	O
quality	O
translations	O
for	O
21	O
European	O
languages	O
.	O
	
The	O
size	O
varies	O
from	O
400k	O
to	O
2	O
M	O
sentence	O
pairs	O
,	O
in	O
function	O
of	O
the	O
date	O
the	O
respective	O
country	O
joined	O
the	O
European	O
Union	O
.	O
	
United	O
Nations	O
:	O
More	O
than	O
11	O
million	O
sentences	O
in	O
the	O
six	O
official	O
languages	O
of	O
the	O
United	O
Nations	O
.	O
	
We	O
only	O
use	O
the	O
first	O
two	O
million	O
sentences	O
in	O
Arabic	O
,	O
Russian	O
and	O
Chinese	O
.	O
	
OpenSubtitles2018	O
:	O
	
A	O
collection	O
of	O
translations	O
of	O
movie	O
subtitles	O
in	O
57	O
languages	O
.	O
	
The	O
corpus	O
size	O
varies	O
from	O
few	O
thousand	O
sentences	O
(	O
e.g.	O
Armenian	O
or	O
Kazakh	O
)	O
to	O
more	O
than	O
50	O
million	O
(	O
e.g.	O
Spanish	B-Material
or	O
Romanian	O
)	O
.	O
	
We	O
keep	O
at	O
most	O
2	O
million	O
entries	O
for	O
each	O
language	O
pair	O
.	O
	
Global	O
Voices	O
:	O
	
A	O
parallel	O
corpus	O
of	O
news	O
stories	O
from	O
the	O
Global	O
Voices	O
website	O
(	O
38	O
languages	O
)	O
.	O
	
This	O
is	O
a	O
rather	O
small	O
corpus	O
with	O
less	O
than	O
100k	O
sentence	O
in	O
most	O
of	O
the	O
languages	O
.	O
	
Tanzil	O
:	O
	
A	O
collection	O
of	O
Quran	O
translations	O
in	O
42	O
languages	O
.	O
	
The	O
style	O
and	O
vocabulary	O
is	O
very	O
different	O
from	O
news	O
texts	O
.	O
	
The	O
average	O
size	O
is	O
135k	O
sentences	O
.	O
	
Tatoeba	O
:	O
	
A	O
community	O
supported	O
collection	O
of	O
English	B-Material
sentences	I-Material
and	O
translations	O
into	O
more	O
than	O
300	O
languages	O
.	O
	
We	O
use	O
this	O
corpus	O
to	O
extract	O
a	O
separate	O
test	O
set	O
of	O
up	O
to	O
1	O
,	O
000	O
sentences	O
for	O
many	O
languages	O
(	O
see	O
Section	O
[	O
reference	O
]	O
and	O
[	O
reference	O
]	O
)	O
.	O
	
For	O
languages	O
with	O
more	O
than	O
1	O
,	O
000	O
entries	O
,	O
we	O
use	O
the	O
remaining	O
ones	O
for	O
training	O
.	O
	
Using	O
all	O
these	O
corpora	O
would	O
provide	O
parallel	O
data	O
for	O
more	O
than	O
hundred	O
languages	O
.	O
	
However	O
,	O
we	O
finally	O
only	O
kept	O
93	O
different	O
languages	O
to	O
train	O
the	O
multilingual	O
sentence	B-Method
embeddings	I-Method
.	O
	
In	O
particular	O
,	O
we	O
discarded	O
several	O
constructed	O
languages	O
with	O
little	O
practical	O
use	O
(	O
Klingon	O
,	O
Kotava	O
,	O
Lojban	O
,	O
Toki	O
Pona	O
and	O
Volapük	O
)	O
.	O
	
appendix	O
:	O
XNLI	B-Material
results	O
for	O
all	O
language	O
combinations	O
	
Table	O
[	O
reference	O
]	O
reports	O
the	O
accuracies	B-Metric
of	O
our	O
system	O
on	O
the	O
XNLI	B-Material
test	O
set	O
when	O
the	O
premises	O
and	O
hypothesis	O
are	O
in	O
a	O
different	O
language	O
(	O
e.g.	O
premise	O
in	O
Russian	O
and	O
hypothesis	O
in	O
Thai	O
)	O
.	O
	
The	O
numbers	O
in	O
the	O
diagonal	O
correspond	O
to	O
the	O
main	O
results	O
reported	O
in	O
Table	O
[	O
reference	O
]	O
.	O
	
We	O
observe	O
that	O
our	O
approach	O
seems	O
to	O
handle	O
the	O
combination	O
of	O
different	O
languages	O
very	O
well	O
.	O
	
We	O
do	O
not	O
have	O
evidence	O
that	O
very	O
distant	O
languages	O
perform	O
considerably	O
worse	O
.	O
	
It	O
rather	O
seems	O
that	O
the	O
combined	O
performance	O
is	O
mostly	O
bounded	O
by	O
the	O
accuracy	B-Metric
of	O
the	O
language	O
which	O
performs	O
worst	O
when	O
used	O
alone	O
.	O
	
As	O
an	O
example	O
,	O
Greek	O
-	O
Russian	O
achieves	O
very	O
similar	O
results	O
than	O
Bulgarian	O
-	O
Russian	O
,	O
two	O
Slavic	O
languages	O
.	O
	
Combing	O
French	B-Material
with	O
Chinese	O
,	O
two	O
totally	O
different	O
languages	O
,	O
is	O
only	O
1.5	O
points	O
worse	O
than	O
French	B-Material
/	O
Spanish	B-Material
,	O
two	O
very	O
close	O
languages	O
.	O
	
appendix	O
:	O
Tatoeba	O
dataset	O
	
Tatoeba	O
is	O
an	O
open	O
collection	O
of	O
English	O
sentences	O
and	O
high	O
quality	O
translations	O
into	O
more	O
than	O
three	O
hundred	O
languages	O
.	O
	
The	O
number	O
of	O
available	O
translations	O
is	O
updated	O
every	O
Saturday	O
.	O
	
We	O
downloaded	O
the	O
snapshot	O
on	O
November	O
19th	O
2018	O
and	O
performed	O
the	O
following	O
processing	O
:	O
Removal	O
of	O
sentences	O
that	O
contain	O
“	O
@	O
”	O
or	O
“	O
http	O
”	O
.	O
	
This	O
is	O
motivated	O
by	O
the	O
fact	O
that	O
emails	O
and	O
web	O
addresses	O
are	O
not	O
language	O
specific	O
.	O
	
Removal	O
of	O
sentences	O
with	O
less	O
than	O
three	O
words	O
(	O
before	O
tokenization	O
)	O
.	O
	
These	O
are	O
usually	O
sentences	O
with	O
limited	O
semantic	O
information	O
.	O
	
Removal	O
of	O
sentences	O
that	O
appear	O
multiple	O
times	O
,	O
either	O
in	O
the	O
source	O
or	O
the	O
target	O
.	O
	
After	O
filtering	O
,	O
we	O
created	O
test	O
sets	O
of	O
up	O
to	O
1	O
,	O
000	O
aligned	O
sentences	O
with	O
English	B-Material
.	O
	
This	O
amount	O
of	O
texts	O
is	O
available	O
for	O
78	O
languages	O
.	O
	
Limiting	O
the	O
number	O
of	O
sentences	O
to	O
500	O
,	O
we	O
increase	O
the	O
coverage	O
to	O
101	O
languages	O
,	O
and	O
even	O
141	O
languages	O
with	O
100	O
parallel	O
sentences	O
.	O
	
It	O
should	O
be	O
stressed	O
that	O
,	O
in	O
general	O
,	O
the	O
English	B-Material
sentences	I-Material
are	O
not	O
the	O
same	O
for	O
the	O
different	O
languages	O
.	O
	
This	O
implies	O
that	O
the	O
error	B-Metric
rates	I-Metric
are	O
not	O
necessarily	O
comparable	O
between	O
the	O
languages	O
.	O
	
appendix	O
:	O
Tatoeba	O
:	O
result	O
analysis	O
	
We	O
provide	O
here	O
some	O
analysis	O
on	O
the	O
results	O
given	O
in	O
Tables	O
[	O
reference	O
]	O
and	O
[	O
reference	O
]	O
.	O
	
We	O
have	O
48	O
languages	O
with	O
an	O
error	B-Metric
rate	I-Metric
below	O
10	O
%	O
and	O
55	O
with	O
less	O
than	O
20	O
%	O
,	O
respectively	O
(	O
English	O
included	O
)	O
.	O
	
The	O
languages	O
with	O
less	O
than	O
20	O
%	O
error	O
belong	O
to	O
20	O
different	O
families	O
and	O
use	O
12	O
different	O
scripts	O
.	O
	
It	O
is	O
nice	O
to	O
find	O
six	O
languages	O
in	O
this	O
list	O
for	O
which	O
we	O
have	O
only	O
small	O
amounts	O
of	O
bitexts	O
(	O
less	O
than	O
400k	O
)	O
,	O
namely	O
Esperanto	O
,	O
Galician	O
,	O
Hindi	O
,	O
Interlingua	O
,	O
Malayam	O
and	O
Marathi	O
.	O
	
The	O
two	O
constructed	O
languages	O
probably	O
benefit	O
from	O
their	O
inspiration	O
by	O
other	O
European	O
languages	O
.	O
	
Overall	O
,	O
we	O
observe	O
low	O
similarity	B-Metric
error	I-Metric
rates	I-Metric
on	O
the	O
Indo	O
-	O
Aryan	O
languages	O
,	O
namely	O
Hindi	O
,	O
Bengali	O
,	O
Marathi	O
and	O
Urdu	O
.	O
	
The	O
performance	O
on	O
Berber	O
languages	O
(	O
“	O
ber	O
”	O
and	O
“	O
kab	O
”	O
)	O
is	O
remarkable	O
,	O
although	O
we	O
have	O
less	O
than	O
100	O
thousand	O
sentences	O
to	O
train	O
them	O
.	O
	
This	O
is	O
a	O
typical	O
example	O
of	O
languages	O
which	O
are	O
spoken	O
by	O
several	O
millions	O
of	O
people	O
,	O
but	O
for	O
which	O
the	O
amount	O
of	O
written	O
resources	O
is	O
very	O
limited	O
.	O
	
It	O
is	O
quite	O
unlikely	O
that	O
we	O
would	O
be	O
able	O
to	O
train	O
a	O
good	O
sentence	B-Method
embedding	I-Method
with	O
language	O
specific	O
corpora	O
only	O
.	O
	
This	O
clearly	O
shows	O
the	O
benefit	O
of	O
joint	B-Method
training	I-Method
on	O
many	O
languages	O
.	O
	
Fifteen	O
languages	O
have	O
similarity	B-Metric
error	I-Metric
rates	I-Metric
of	O
more	O
than	O
50	O
%	O
.	O
	
Four	O
of	O
them	O
are	O
low	O
-	O
resource	O
languages	O
with	O
their	O
own	O
script	O
and	O
which	O
are	O
alone	O
in	O
their	O
family	O
:	O
Amharic	O
,	O
Armenian	O
,	O
Khmer	O
and	O
Georgian	O
.	O
	
This	O
makes	O
it	O
difficult	O
to	O
benefit	O
from	O
joint	B-Method
training	I-Method
.	O
	
On	O
the	O
other	O
hand	O
,	O
one	O
can	O
also	O
argue	O
that	O
is	O
surprising	O
that	O
a	O
language	O
like	O
Khmer	B-Method
performs	O
much	O
better	O
than	O
random	B-Method
(	O
99.9	O
%	O
error	B-Metric
rate	I-Metric
)	O
with	O
only	O
625	O
training	O
examples	O
.	O
	
Khmer	O
probably	O
benefits	O
of	O
the	O
fact	O
that	O
he	O
have	O
trained	O
our	O
model	O
on	O
other	O
languages	O
of	O
the	O
region	O
which	O
have	O
influenced	O
Khmer	O
,	O
namely	O
Thai	O
and	O
Vietnamese	O
.	O
	
There	O
are	O
also	O
several	O
Turkic	O
languages	O
(	O
Kazakh	O
,	O
Tatar	O
,	O
Uighur	O
and	O
Uzbek	O
)	O
and	O
Celtic	O
languages	O
(	O
Breton	O
and	O
Cornish	O
)	O
with	O
high	O
error	B-Metric
rates	I-Metric
.	O
	
We	O
hope	O
to	O
improve	O
their	O
performance	O
in	O
the	O
future	O
.	O
	
appendix	O
:	O
Tatoeba	O
:	O
results	O
for	O
unseen	O
languages	O
	
We	O
extend	O
our	O
Tatoeba	O
experiments	O
to	O
29	O
languages	O
without	O
any	O
training	O
data	O
(	O
see	O
Table	O
[	O
reference	O
]	O
)	O
.	O
	
Many	O
of	O
them	O
are	O
recognized	O
minority	O
languages	O
spoken	O
in	O
specific	O
regions	O
,	O
e.g.	O
Asturian	O
,	O
Faroese	O
,	O
Frisian	O
,	O
Kashubian	O
,	O
North	O
Moluccan	O
Malay	O
,	O
Piemontese	O
,	O
Swabian	O
or	O
Sorbian	O
.	O
	
All	O
share	O
some	O
similarities	O
,	O
at	O
various	O
degrees	O
,	O
with	O
other	O
major	O
languages	O
,	O
but	O
also	O
differ	O
by	O
their	O
own	O
grammar	O
or	O
specific	O
vocabulary	O
.	O
	
This	O
enables	O
our	O
encoder	O
to	O
perform	O
reasonably	O
well	O
.	O
	
We	O
can	O
probably	O
assume	O
that	O
these	O
are	O
mainly	O
spoken	O
languages	O
with	O
limited	O
resources	O
in	O
written	O
form	O
.	O
	
The	O
six	O
languages	O
which	O
perform	O
worst	O
are	O
Mongolian	O
,	O
Welsh	O
,	O
Xhosa	O
Pampangan	O
,	O
Yiddish	O
and	O
Gaelic	O
.	O
	
We	O
include	O
these	O
results	O
here	O
as	O
baseline	O
for	O
future	O
research	O
.	O
	
Premise	B-Task
Training	I-Task
[	O
-	O
1pt	O
]	O
corpus	O
[	O
-	O
2pt	O
]	O
	
size	O
	
Tatoeba	O
[	O
-	O
1pt	O
]	O
test	O
set	O
[	O
-	O
2pt	O
]	O
size	O
	
document	O
:	O
Image	B-Task
Super	I-Task
-	I-Task
Resolution	I-Task
via	O
Dual	B-Method
-	I-Method
State	I-Method
Recurrent	I-Method
Networks	I-Method
	
Advances	O
in	O
image	B-Task
super	I-Task
-	I-Task
resolution	I-Task
(	O
SR	B-Task
)	O
have	O
recently	O
benefited	O
significantly	O
from	O
rapid	O
developments	O
in	O
deep	B-Method
neural	I-Method
networks	I-Method
.	O
	
Inspired	O
by	O
these	O
recent	O
discoveries	O
,	O
we	O
note	O
that	O
many	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
deep	O
SR	B-Task
architectures	O
can	O
be	O
reformulated	O
as	O
a	O
single	B-Method
-	I-Method
state	I-Method
recurrent	I-Method
neural	I-Method
network	I-Method
(	O
RNN	B-Method
)	O
with	O
finite	B-Method
unfoldings	I-Method
.	O
	
In	O
this	O
paper	O
,	O
we	O
explore	O
new	O
structures	O
for	O
SR	B-Task
based	O
on	O
this	O
compact	B-Method
RNN	I-Method
view	I-Method
,	O
leading	O
us	O
to	O
a	O
dual	B-Method
-	I-Method
state	I-Method
design	I-Method
,	O
the	O
Dual	B-Method
-	I-Method
State	I-Method
Recurrent	I-Method
Network	I-Method
(	O
DSRN	B-Method
)	O
.	O
	
Compared	O
to	O
its	O
single	O
-	O
state	O
counterparts	O
that	O
operate	O
at	O
a	O
fixed	O
spatial	O
resolution	O
,	O
DSRN	B-Method
exploits	O
both	O
low	O
-	O
resolution	O
(	O
LR	O
)	O
and	O
high	B-Task
-	I-Task
resolution	I-Task
(	O
HR	B-Task
)	O
signals	O
jointly	O
.	O
	
Recurrent	O
signals	O
are	O
exchanged	O
between	O
these	O
states	O
in	O
both	O
directions	O
(	O
both	O
LR	O
to	O
HR	B-Task
and	O
HR	B-Task
to	O
LR	O
)	O
via	O
delayed	O
feedback	O
.	O
	
Extensive	O
quantitative	O
and	O
qualitative	O
evaluations	O
on	O
benchmark	O
datasets	O
and	O
on	O
a	O
recent	O
challenge	O
demonstrate	O
that	O
the	O
proposed	O
DSRN	B-Method
performs	O
favorably	O
against	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
algorithms	O
in	O
terms	O
of	O
both	O
memory	B-Metric
consumption	I-Metric
and	O
predictive	B-Metric
accuracy	I-Metric
.	O
	
section	O
:	O
Introduction	O
	
In	O
the	O
problem	O
of	O
single	B-Task
-	I-Task
image	I-Task
super	I-Task
-	I-Task
resolution	I-Task
(	O
SR	B-Task
)	O
,	O
the	O
aim	O
is	O
to	O
recover	O
a	O
high	B-Task
-	I-Task
resolution	I-Task
(	O
HR	B-Task
)	O
image	O
from	O
a	O
single	O
low	O
-	O
resolution	O
(	O
LR	O
)	O
image	O
.	O
	
In	O
recent	O
years	O
,	O
SR	B-Task
performance	O
has	O
been	O
significantly	O
improved	O
due	O
to	O
rapid	O
developments	O
in	O
deep	B-Method
neural	I-Method
networks	I-Method
(	O
DNNs	B-Method
)	O
.	O
	
Specifically	O
,	O
convolutional	B-Method
neural	I-Method
networks	I-Method
(	O
CNNs	B-Method
)	I-Method
and	O
residual	B-Method
learning	I-Method
have	O
been	O
widely	O
applied	O
in	O
much	O
recent	O
SR	B-Task
work	O
.	O
	
In	O
these	O
approaches	O
,	O
two	O
principles	O
have	O
been	O
consistently	O
observed	O
.	O
	
The	O
first	O
is	O
that	O
increasing	O
the	O
depth	O
of	O
a	O
CNN	B-Method
model	I-Method
improves	O
SR	B-Task
performance	O
;	O
a	O
deeper	B-Method
model	I-Method
with	O
more	O
parameters	O
can	O
represent	O
a	O
more	O
complex	O
mapping	O
from	O
LR	O
to	O
HR	B-Task
images	O
.	O
	
In	O
addition	O
,	O
increasing	O
network	O
depth	O
enlarges	O
the	O
size	O
of	O
receptive	O
fields	O
,	O
providing	O
more	O
contextual	O
information	O
that	O
can	O
be	O
exploited	O
to	O
reconstruct	O
missing	O
HR	B-Task
components	O
.	O
	
The	O
second	O
principle	O
is	O
that	O
adding	O
residual	O
connections	O
(	O
globally	O
,	O
locally	O
or	O
jointly	O
)	O
prevents	O
the	O
problems	O
of	O
vanishing	O
and	O
exploding	O
gradients	O
,	O
facilitating	O
the	O
training	B-Task
of	I-Task
deep	I-Task
models	I-Task
.	O
	
While	O
these	O
recent	O
models	O
have	O
demonstrated	O
promising	O
results	O
,	O
there	O
are	O
also	O
drawbacks	O
.	O
	
One	O
major	O
issue	O
is	O
that	O
increasing	O
the	O
depth	O
of	O
models	O
by	O
adding	O
new	O
layers	O
introduces	O
more	O
parameters	O
,	O
and	O
thus	O
raises	O
the	O
likelihood	O
of	O
model	B-Task
overfitting	I-Task
.	O
	
At	O
the	O
same	O
time	O
,	O
larger	O
models	O
demand	O
more	O
storage	O
space	O
,	O
which	O
is	O
a	O
hurdle	O
to	O
deployment	O
in	O
resource	B-Task
-	I-Task
constrained	I-Task
environments	I-Task
(	O
e.g.	O
mobile	B-Task
systems	I-Task
)	O
.	O
	
To	O
resolve	O
this	O
issue	O
,	O
the	O
Deep	B-Method
Recursive	I-Method
Residual	I-Method
Network	I-Method
(	O
DRRN	B-Method
)	O
inspired	O
by	O
the	O
Deeply	B-Method
-	I-Method
Recursive	I-Method
Convolutional	I-Method
Network	I-Method
(	O
DRCN	B-Method
)	O
shares	O
weights	O
across	O
different	O
residual	O
units	O
and	O
achieves	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
performance	O
with	O
a	O
small	O
number	O
of	O
parameters	O
.	O
	
Separate	O
efforts	O
in	O
neural	B-Task
architectural	I-Task
design	I-Task
have	O
recently	O
shown	O
that	O
commonly	O
-	O
used	O
deep	O
structures	O
can	O
be	O
represented	O
more	O
compactly	O
using	O
recurrent	B-Method
neural	I-Method
networks	I-Method
(	O
RNNs	B-Method
)	O
.	O
	
Specifically	O
,	O
Liao	O
and	O
Poggio	O
demonstrated	O
that	O
a	O
weight	B-Method
-	I-Method
sharing	I-Method
Residual	I-Method
Neural	I-Method
Network	I-Method
(	O
ResNet	B-Method
)	I-Method
is	O
equivalent	O
to	O
a	O
shallow	B-Method
RNN	I-Method
.	O
	
Inspired	O
by	O
their	O
findings	O
,	O
we	O
first	O
explore	O
the	O
connections	O
between	O
the	O
neural	B-Method
architectures	I-Method
of	O
existing	O
SR	B-Task
algorithms	O
and	O
their	O
compact	B-Method
RNN	I-Method
formulations	I-Method
.	O
	
We	O
note	O
that	O
previous	O
SR	B-Task
models	O
with	O
recursive	B-Method
computation	I-Method
and	O
weight	B-Method
sharing	I-Method
,	O
including	O
DRRN	B-Method
and	O
DRCN	O
,	O
work	O
at	O
a	O
single	O
spatial	O
resolution	O
(	O
bicubic	B-Method
interpolation	I-Method
is	O
first	O
applied	O
to	O
upscale	O
LR	O
images	O
to	O
a	O
desired	O
spatial	O
resolution	O
)	O
.	O
	
This	O
enables	O
their	O
model	O
structures	O
to	O
be	O
represented	O
as	O
a	O
unified	O
single	B-Method
-	I-Method
state	I-Method
RNN	I-Method
.	O
	
Thus	O
,	O
both	O
DRRN	B-Method
and	O
DRCN	O
can	O
be	O
viewed	O
as	O
a	O
finite	O
unfolding	O
in	O
time	O
of	O
the	O
same	O
RNN	O
structure	O
,	O
but	O
with	O
different	O
transition	O
functions	O
.	O
	
This	O
is	O
illustrated	O
in	O
Figure	O
[	O
reference	O
]	O
,	O
and	O
will	O
be	O
discussed	O
in	O
detail	O
in	O
Section	O
[	O
reference	O
]	O
.	O
	
It	O
is	O
worth	O
mentioning	O
that	O
we	O
follow	O
the	O
terminology	O
used	O
in	O
,	O
where	O
a	O
	
‘	O
	
‘	O
state	O
’	O
’	O
can	O
be	O
considered	O
as	O
corresponding	O
to	O
a	O
‘	O
‘	O
layer	O
’	O
’	O
in	O
the	O
normal	O
RNN	B-Method
setting	I-Method
.	O
	
Based	O
on	O
this	O
compact	O
RNN	B-Method
view	I-Method
of	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
SR	B-Task
models	O
,	O
in	O
this	O
paper	O
we	O
explore	O
new	O
structures	O
to	O
extend	O
the	O
frontier	O
of	O
SR	B-Task
.	O
	
The	O
first	O
approach	O
in	O
improving	O
a	O
conventional	O
RNN	B-Method
model	I-Method
is	O
generally	O
to	O
make	O
it	O
multi	B-Method
-	I-Method
layer	I-Method
.	O
	
We	O
apply	O
this	O
experience	O
in	O
designing	O
the	O
SR	B-Task
architecture	O
in	O
our	O
compact	B-Method
RNN	I-Method
view	I-Method
by	O
adding	O
an	O
additional	O
state	O
,	O
rendering	O
our	O
model	O
a	O
Dual	B-Method
-	I-Method
State	I-Method
Recurrent	I-Method
Network	I-Method
(	O
DSRN	B-Method
)	O
,	O
where	O
the	O
two	O
states	O
operate	O
at	O
different	O
spatial	O
resolutions	O
.	O
	
Specifically	O
,	O
the	O
bottom	O
state	O
captures	O
information	O
at	O
LR	O
,	O
while	O
the	O
top	O
state	O
operates	O
in	O
the	O
HR	B-Task
regime	O
.	O
	
As	O
with	O
a	O
conventional	O
two	B-Method
-	I-Method
layer	I-Method
stacked	I-Method
RNN	I-Method
,	O
there	O
is	O
a	O
connection	O
from	O
the	O
bottom	O
to	O
the	O
top	O
state	O
via	O
deconvolutional	B-Method
operations	I-Method
.	O
	
This	O
provides	O
information	O
flow	O
from	O
LR	O
to	O
HR	B-Task
at	O
every	O
single	O
unrolling	O
time	O
.	O
	
In	O
addition	O
,	O
to	O
allow	O
information	O
flow	O
from	O
previously	O
predicted	O
HR	B-Task
features	O
to	O
LR	O
features	O
,	O
we	O
incorporate	O
a	O
delayed	B-Method
feedback	I-Method
mechanism	I-Method
from	O
the	O
top	O
(	O
HR	B-Task
)	O
state	O
to	O
the	O
bottom	O
one	O
.	O
	
The	O
overall	O
structure	O
of	O
the	O
proposed	O
DSRN	B-Method
is	O
shown	O
in	O
Figure	O
[	O
reference	O
]	O
,	O
which	O
not	O
only	O
utilizes	O
parameters	O
efficiently	O
but	O
also	O
allows	O
both	O
LR	O
and	O
HR	B-Task
signals	O
to	O
contribute	O
jointly	O
to	O
learning	O
the	O
mappings	O
.	O
	
To	O
demonstrate	O
the	O
effectiveness	O
of	O
the	O
proposed	O
method	O
,	O
we	O
compare	O
DSRN	B-Method
with	O
other	O
recent	O
image	O
SR	B-Task
approaches	O
on	O
four	O
common	O
benchmarks	O
as	O
well	O
as	O
on	O
the	O
DIV2	O
K	O
dataset	O
from	O
the	O
"	O
New	O
Trends	O
in	O
Image	B-Task
Restoration	I-Task
and	I-Task
Enhancement	I-Task
workshop	O
and	O
challenge	O
on	O
image	B-Task
super	I-Task
-	I-Task
resolution	I-Task
(	O
NTIRE	O
SR	B-Task
2017	O
)	O
"	O
.	O
	
Extensive	O
experimental	O
results	O
validate	O
that	O
DSRN	B-Method
delivers	O
higher	O
parameter	B-Metric
efficiency	I-Metric
,	O
low	B-Metric
memory	I-Metric
consumption	I-Metric
and	O
high	O
restoration	B-Metric
accuracy	I-Metric
.	O
	
section	O
:	O
Related	O
Work	O
	
Single	B-Task
image	I-Task
SR	I-Task
has	O
been	O
widely	O
studied	O
in	O
the	O
past	O
few	O
decades	O
and	O
has	O
an	O
extensive	O
literature	O
.	O
	
In	O
recent	O
years	O
,	O
due	O
to	O
the	O
fast	O
development	O
of	O
deep	B-Method
learning	I-Method
,	O
significant	O
progress	O
has	O
been	O
made	O
in	O
this	O
field	O
.	O
	
Dong	O
et	O
al	O
.	O
	
first	O
exploited	O
a	O
fully	B-Method
convolutional	I-Method
neural	I-Method
network	I-Method
,	O
termed	O
SRCNN	B-Method
,	O
to	O
predict	O
the	O
nonlinear	O
LR	O
-	O
HR	B-Task
mapping	O
.	O
	
It	O
demonstrated	O
superior	O
performance	O
to	O
many	O
other	O
example	B-Method
-	I-Method
based	I-Method
learning	I-Method
paradigms	I-Method
,	O
such	O
as	O
nearest	B-Method
neighbor	I-Method
,	O
sparse	B-Method
representation	I-Method
,	O
neighborhood	B-Method
embedding	I-Method
,	O
random	B-Method
forest	I-Method
,	O
etc	O
.	O
	
Although	O
all	O
layers	O
of	O
a	O
SRCNN	B-Method
are	O
trained	O
jointly	O
in	O
an	O
end	O
-	O
to	O
-	O
end	O
fashion	O
,	O
conceptually	O
the	O
network	O
is	O
split	O
into	O
three	O
stages	O
:	O
patch	B-Method
representation	I-Method
,	O
non	B-Task
-	I-Task
linear	I-Task
mapping	I-Task
,	O
and	O
reconstruction	B-Task
.	O
	
Much	O
of	O
the	O
later	O
work	O
follows	O
a	O
similar	O
network	B-Method
design	I-Method
with	O
more	O
complicated	O
building	O
blocks	O
or	O
advanced	O
optimization	B-Method
techniques	I-Method
.	O
	
Wang	O
et	O
al	O
.	O
proposed	O
a	O
sparse	B-Method
coding	I-Method
network	I-Method
(	I-Method
SCN	I-Method
)	I-Method
that	O
encodes	O
a	O
sparse	B-Method
representation	I-Method
prior	I-Method
for	O
image	O
SR	B-Task
and	O
can	O
be	O
trained	O
end	O
-	O
to	O
-	O
end	O
,	O
demonstrating	O
the	O
benefit	O
of	O
domain	B-Method
expertise	I-Method
in	O
sparse	B-Method
coding	I-Method
for	O
image	O
SR	B-Task
.	O
	
Both	O
external	O
and	O
self	O
examples	O
were	O
utilized	O
to	O
synthesize	O
the	O
HR	B-Task
prediction	O
via	O
a	O
neural	B-Method
network	I-Method
in	O
.	O
	
Inspired	O
by	O
the	O
success	O
of	O
very	O
deep	B-Method
models	I-Method
on	O
ImageNet	B-Task
challenges	I-Task
,	O
Kim	O
et	O
al	O
.	O
proposed	O
a	O
very	B-Method
deep	I-Method
CNN	I-Method
,	O
VDSR	B-Method
,	O
which	O
stacks	O
20	O
convolutional	B-Method
layers	I-Method
with	O
kernels	B-Method
.	O
	
Both	O
residual	B-Method
learning	I-Method
and	O
adjustable	B-Method
gradient	I-Method
clipping	I-Method
are	O
used	O
to	O
prevent	O
vanishing	O
and	O
exploding	O
gradients	O
.	O
	
However	O
,	O
as	O
the	O
model	O
gets	O
deeper	O
,	O
the	O
number	O
of	O
parameters	O
increases	O
.	O
	
To	O
control	O
the	O
size	O
of	O
the	O
model	O
,	O
DRCN	B-Method
introduces	O
16	O
recursive	B-Method
layers	I-Method
,	O
each	O
with	O
the	O
same	O
structure	O
and	O
shared	O
parameters	O
.	O
	
Moreover	O
,	O
DRCN	B-Method
makes	O
use	O
of	O
skip	O
connections	O
and	O
recursive	B-Method
supervision	I-Method
to	O
mitigate	O
the	O
difficulty	O
of	O
training	B-Task
.	O
	
Tai	O
et	O
al	O
.	O
discovered	O
that	O
many	O
residual	O
SR	B-Task
learning	O
algorithms	O
are	O
based	O
on	O
either	O
global	B-Method
residual	I-Method
learning	I-Method
or	O
local	B-Method
residual	I-Method
learning	I-Method
,	O
which	O
are	O
insufficient	O
for	O
very	O
deep	B-Method
models	I-Method
.	O
	
Instead	O
,	O
they	O
proposed	O
the	O
DRRN	B-Method
that	O
applies	O
both	O
global	B-Method
and	I-Method
local	I-Method
learning	I-Method
while	O
remaining	O
parameter	O
efficient	O
via	O
recursive	B-Method
learning	I-Method
.	O
	
More	O
recently	O
,	O
Tong	O
et	O
al	O
.	O
proposed	O
making	O
use	O
of	O
Densely	B-Method
Connected	I-Method
Networks	I-Method
(	O
DenseNet	B-Method
)	O
instead	O
of	O
ResNet	B-Method
as	O
the	O
building	B-Method
block	I-Method
for	O
image	O
SR	B-Task
.	O
	
They	O
demonstrated	O
that	O
the	O
DenseNet	O
structure	O
is	O
better	O
at	O
combining	O
features	O
at	O
different	O
levels	O
,	O
which	O
boosts	O
SR	B-Task
performance	O
.	O
	
Apart	O
from	O
deep	B-Method
models	I-Method
working	O
on	O
bicubic	O
upscaled	O
input	O
images	O
,	O
Shi	O
et	O
al	O
.	O
used	O
a	O
compact	B-Method
network	I-Method
model	I-Method
to	O
conduct	O
convolutions	B-Method
on	O
LR	O
images	O
directly	O
and	O
learned	O
upscaling	B-Method
filters	I-Method
in	O
the	O
last	O
layer	O
,	O
which	O
considerably	O
reduces	O
the	O
computation	B-Metric
cost	I-Metric
.	O
	
Similarly	O
,	O
Dong	O
et	O
al	O
.	O
adopted	O
deconvolution	B-Method
layers	I-Method
to	O
accelerate	O
SRCNN	B-Method
in	O
combination	O
with	O
smaller	O
filter	O
sizes	O
and	O
more	O
convolution	B-Method
layers	I-Method
.	O
	
However	O
,	O
these	O
networks	O
are	O
relatively	O
small	O
and	O
have	O
difficulty	O
capturing	O
complicated	O
mappings	O
owing	O
to	O
limited	O
network	O
capacity	O
.	O
	
The	O
Laplacian	B-Method
Pyramid	I-Method
Super	I-Method
-	I-Method
Resolution	I-Method
Network	I-Method
(	O
LapSRN	B-Method
)	O
works	O
on	O
LR	O
images	O
directly	O
and	O
progressively	O
predicts	O
sub	O
-	O
band	O
residuals	O
on	O
various	O
scales	O
.	O
	
Lim	O
et	O
al	O
.	O
proposed	O
the	O
Enhanced	B-Method
Deep	I-Method
Super	I-Method
-	I-Method
Resolution	I-Method
(	O
EDSR	B-Method
)	O
network	O
and	O
a	O
multi	B-Method
-	I-Method
scale	I-Method
variant	I-Method
,	O
which	O
learns	O
different	O
scaled	O
mapping	O
functions	O
in	O
parallel	O
via	O
weight	B-Method
sharing	I-Method
.	O
	
It	O
is	O
noteworthy	O
that	O
most	O
SR	B-Task
algorithms	O
minimize	O
the	O
mean	B-Metric
squared	I-Metric
reconstruction	I-Metric
error	I-Metric
(	O
i.e.	O
via	O
loss	B-Metric
)	O
.	O
	
They	O
often	O
suffer	O
from	O
regression	O
-	O
to	O
-	O
the	O
-	O
mean	O
due	O
to	O
the	O
ill	O
-	O
posed	O
nature	O
of	O
single	O
image	O
SR	B-Task
,	O
resulting	O
in	O
blurry	O
predictions	O
and	O
poor	O
subjective	B-Metric
scores	I-Metric
.	O
	
To	O
overcome	O
this	O
drawback	O
,	O
Generative	B-Method
Adversarial	I-Method
Networks	I-Method
have	O
been	O
used	O
along	O
with	O
perceptual	O
loss	O
for	O
SR	B-Task
.	O
	
Subjective	B-Metric
evaluation	I-Metric
by	O
mean	B-Metric
-	I-Metric
opinion	I-Metric
-	I-Metric
score	I-Metric
showed	O
huge	O
improvement	O
over	O
other	O
regression	B-Method
-	I-Method
based	I-Method
methods	I-Method
.	O
	
Our	O
work	O
is	O
also	O
strongly	O
related	O
to	O
and	O
built	O
upon	O
the	O
idea	O
of	O
viewing	O
a	O
ResNet	B-Method
as	O
an	O
unrolled	B-Method
RNN	I-Method
.	O
	
It	O
was	O
first	O
proposed	O
in	O
,	O
which	O
aids	O
understanding	O
of	O
a	O
family	O
of	O
deep	O
structures	O
from	O
the	O
perspective	O
of	O
RNNs	B-Method
.	O
	
Later	O
,	O
Chen	O
et	O
al	O
.	O
unified	O
several	O
different	O
residual	O
functions	O
to	O
provide	O
a	O
better	O
understanding	O
of	O
the	O
design	O
of	O
DNNs	B-Method
with	O
high	O
learning	B-Metric
capacity	I-Metric
.	O
	
Recently	O
,	O
the	O
equivalence	O
to	O
RNNs	B-Method
has	O
been	O
further	O
extended	O
to	O
DenseNet	O
.	O
	
Based	O
on	O
this	O
finding	O
,	O
Dual	B-Method
Path	I-Method
Networks	I-Method
were	O
proposed	O
and	O
showed	O
superior	O
performance	O
to	O
DenseNet	B-Method
and	O
ResNet	B-Method
in	O
a	O
varity	O
of	O
applications	O
.	O
	
section	O
:	O
Single	B-Method
-	I-Method
State	I-Method
Recurrent	I-Method
Networks	I-Method
	
In	O
this	O
section	O
,	O
we	O
first	O
revisit	O
the	O
discovery	O
that	O
a	O
ResNet	O
with	O
shared	O
weights	O
can	O
be	O
reformulated	O
as	O
a	O
recurrent	B-Method
system	I-Method
.	O
	
Then	O
,	O
based	O
on	O
this	O
view	O
,	O
we	O
unite	O
the	O
recent	O
development	O
of	O
SR	B-Task
models	O
with	O
such	O
RNN	B-Method
reformulations	I-Method
to	O
show	O
DRCN	B-Method
and	O
DRRN	B-Method
are	O
structurally	O
equivalent	O
to	O
an	O
unrolled	B-Method
single	I-Method
-	I-Method
state	I-Method
RNN	I-Method
.	O
	
To	O
establish	O
the	O
equivalence	O
,	O
we	O
adopt	O
the	O
commonly	O
used	O
definition	O
of	O
a	O
RNN	B-Method
,	O
which	O
is	O
characterized	O
by	O
a	O
set	O
of	O
states	O
and	O
transition	O
functions	O
among	O
the	O
states	O
.	O
	
A	O
RNN	B-Method
often	O
consists	O
of	O
the	O
input	O
state	O
,	O
output	O
state	O
,	O
and	O
the	O
recurrent	O
states	O
.	O
	
Depending	O
on	O
the	O
number	O
recurrent	O
states	O
,	O
we	O
describe	O
RNNs	B-Method
as	O
‘	O
‘	O
single	O
-	O
state	O
’	O
’	O
(	O
i.e.	O
one	O
recurrent	O
state	O
)	O
or	O
‘	O
‘	O
dual	O
-	O
state	O
’	O
’	O
(	O
i.e.	O
two	O
recurrent	O
states	O
)	O
.	O
	
An	O
illustration	O
of	O
a	O
single	B-Method
-	I-Method
state	I-Method
RNN	I-Method
is	O
shown	O
in	O
Figure	O
[	O
reference	O
]	O
	
(	O
a	O
)	O
.	O
	
The	O
input	O
,	O
output	O
,	O
and	O
recurrent	O
states	O
are	O
represented	O
as	O
,	O
and	O
respectively	O
.	O
	
The	O
arrow	O
link	O
indicates	O
the	O
state	O
transition	O
function	O
.	O
	
The	O
square	O
on	O
the	O
directed	O
cycle	O
indicates	O
that	O
the	O
recurrent	B-Method
function	I-Method
travels	O
one	O
time	O
step	O
forward	O
during	O
the	O
unfolding	O
.	O
	
Interested	O
readers	O
are	O
referred	O
to	O
for	O
detailed	O
information	O
on	O
this	O
general	O
formulation	O
of	O
a	O
RNN	B-Method
.	O
	
Based	O
on	O
Figure	O
[	O
reference	O
]	O
(	O
a	O
)	O
,	O
we	O
unfold	O
along	O
the	O
temporal	O
direction	O
to	O
a	O
fixed	O
length	O
.	O
	
The	O
unfolded	O
graph	O
is	O
shown	O
in	O
figure	O
[	O
reference	O
]	O
	
(	O
b	O
)	O
,	O
and	O
the	O
dynamics	O
of	O
a	O
single	O
-	O
state	O
RNN	B-Method
can	O
be	O
characterized	O
by	O
:	O
where	O
the	O
upper	O
script	O
indicates	O
the	O
-	O
th	O
unrolling	O
.	O
	
The	O
parameters	O
of	O
,	O
,	O
and	O
are	O
often	O
time	O
-	O
independent	O
,	O
which	O
means	O
these	O
parameters	O
are	O
reused	O
at	O
every	O
unfolding	O
step	O
.	O
	
This	O
allows	O
us	O
to	O
unify	O
ResNet	B-Method
,	O
DRCN	B-Method
,	O
and	O
DRRN	B-Method
as	O
unrolled	B-Method
networks	I-Method
with	O
the	O
same	O
recurrent	O
structure	O
but	O
with	O
the	O
different	O
realizations	O
of	O
and	O
different	O
rules	O
of	O
parameter	O
sharing	O
.	O
	
ResNet	O
:	O
	
We	O
consider	O
a	O
ResNet	B-Method
in	O
its	O
simplest	O
form	O
without	O
any	O
down	B-Method
-	I-Method
sampling	I-Method
or	O
up	B-Method
-	I-Method
sampling	I-Method
operations	I-Method
.	O
	
In	O
other	O
words	O
,	O
both	O
of	O
the	O
spatial	O
dimensions	O
and	O
feature	O
dimensions	O
remain	O
the	O
same	O
across	O
all	O
intermediate	O
layers	O
.	O
	
To	O
render	O
Figure	O
[	O
reference	O
]	O
(	O
b	O
)	O
equivalent	O
to	O
a	O
ResNet	B-Method
with	I-Method
residual	I-Method
blocks	I-Method
,	O
one	O
possible	O
technique	O
is	O
to	O
make	O
:	O
be	O
the	O
input	O
image	O
or	O
a	O
function	O
of	O
.	O
,	O
and	O
.	O
	
Thus	O
,	O
the	O
state	O
transition	O
becomes	O
.	O
	
The	O
recurrent	O
function	O
be	O
the	O
same	O
as	O
a	O
conventional	O
residual	O
block	O
,	O
which	O
contains	O
two	O
convolutional	B-Method
layers	I-Method
with	O
skip	O
connections	O
as	O
shown	O
in	O
Figure	O
[	O
reference	O
]	O
(	O
c	O
)	O
.	O
	
Differences	O
in	O
color	O
indicate	O
different	O
sets	O
of	O
parameters	O
.	O
	
The	O
prediction	O
state	O
be	O
calculated	O
only	O
at	O
the	O
time	O
as	O
the	O
final	O
output	O
.	O
	
It	O
is	O
worth	O
mentioning	O
that	O
the	O
only	O
difference	O
between	O
an	O
unrolled	B-Method
RNN	I-Method
following	O
the	O
above	O
definitions	O
and	O
a	O
conventional	O
ResNet	B-Method
is	O
that	O
the	O
parameters	O
in	O
need	O
to	O
be	O
reused	O
among	O
all	O
residual	O
blocks	O
.	O
	
DRCN	B-Method
:	O
	
To	O
realize	O
the	O
DRCN	B-Method
expressible	O
by	O
the	O
same	O
single	B-Method
-	I-Method
state	I-Method
RNN	I-Method
,	O
we	O
define	O
and	O
in	O
the	O
same	O
way	O
as	O
for	O
the	O
ResNet	B-Method
.	O
	
Since	O
DRCN	B-Method
recursively	I-Method
applies	O
only	O
a	O
single	O
convolutional	B-Method
layer	I-Method
to	O
the	O
input	O
feature	O
map	O
16	O
times	O
,	O
with	O
the	O
parameters	O
of	O
the	O
layer	O
reused	O
across	O
the	O
whole	O
network	O
,	O
we	O
could	O
use	O
a	O
single	O
convolutional	B-Method
layer	I-Method
to	O
express	O
.	O
	
The	O
graph	O
is	O
illustrated	O
in	O
Figure	O
[	O
reference	O
]	O
(	O
d	O
)	O
.	O
	
Moreover	O
,	O
unlike	O
the	O
ResNet	B-Method
where	O
the	O
output	O
is	O
predicted	O
only	O
at	O
the	O
end	O
of	O
unfolding	O
,	O
DRCN	B-Method
utilizes	O
recursive	B-Method
supervision	I-Method
,	O
which	O
generates	O
an	O
output	O
at	O
every	O
unfolding	O
.	O
	
The	O
final	O
HR	B-Task
prediction	O
of	O
DRCN	B-Method
is	O
the	O
weighted	O
sum	O
of	O
the	O
outputs	O
at	O
every	O
unfolding	O
.	O
	
DRRN	B-Method
:	O
	
The	O
recurrent	B-Method
structure	I-Method
of	O
DRRN	B-Method
differs	O
only	O
slightly	O
from	O
a	O
ResNet	B-Method
.	O
	
In	O
a	O
ResNet	B-Method
,	O
the	O
skip	O
connection	O
comes	O
from	O
the	O
previous	O
residual	O
block	O
,	O
whereas	O
in	O
a	O
DRRN	B-Method
the	O
skip	O
connection	O
always	O
comes	O
from	O
the	O
first	O
unrolled	O
state	O
.	O
	
Figure	O
[	O
reference	O
]	O
	
(	O
e	O
)	O
shows	O
the	O
equivalent	O
recurrent	O
function	O
for	O
a	O
DRRN	B-Method
with	O
one	O
recursive	B-Method
block	I-Method
(	O
i.e.	O
)	O
using	O
the	O
definition	O
in	O
the	O
original	O
paper	O
.	O
	
section	O
:	O
Dual	B-Method
-	I-Method
State	I-Method
Recurrent	I-Method
Networks	I-Method
	
Drawing	O
on	O
the	O
connections	O
between	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
SR	B-Task
models	O
and	O
RNNs	B-Method
,	O
we	O
have	O
investigated	O
new	O
compact	B-Method
RNN	I-Method
architectures	I-Method
for	O
image	O
SR	B-Task
.	O
	
Specifically	O
,	O
we	O
propose	O
a	O
dual	B-Method
-	I-Method
state	I-Method
design	I-Method
,	O
which	O
adopts	O
two	O
recurrent	O
states	O
enable	O
use	O
of	O
features	O
from	O
both	O
LR	O
and	O
HR	B-Task
spaces	O
.	O
	
The	O
RNN	B-Method
view	I-Method
of	O
our	O
DSRN	B-Method
is	O
shown	O
in	O
Figure	O
[	O
reference	O
]	O
(	O
a	O
)	O
and	O
is	O
introduced	O
as	O
follows	O
.	O
	
Dual	B-Method
-	I-Method
state	I-Method
design	I-Method
:	O
Unlike	O
single	B-Method
-	I-Method
state	I-Method
models	I-Method
working	O
at	O
the	O
same	O
spatial	O
resolution	O
,	O
DSRN	B-Method
incorporates	O
information	O
from	O
both	O
the	O
LR	O
and	O
HR	B-Task
spaces	O
.	O
	
Specifically	O
,	O
and	O
in	O
Figure	O
[	O
reference	O
]	O
(	O
a	O
)	O
indicate	O
the	O
LR	O
state	O
and	O
HR	B-Task
state	O
,	O
respectively	O
.	O
	
Four	O
colored	O
arrows	O
indicate	O
the	O
transition	O
functions	O
between	O
these	O
two	O
states	O
.	O
	
The	O
blue	O
(	O
)	O
,	O
orange	O
(	O
)	O
and	O
yellow	O
(	O
)	O
links	O
exist	O
in	O
a	O
conventional	O
two	B-Method
-	I-Method
layer	I-Method
RNN	I-Method
,	O
providing	O
information	O
flow	O
from	O
LR	O
to	O
LR	O
,	O
HR	B-Task
to	O
HR	B-Task
,	O
and	O
LR	O
to	O
HR	B-Task
,	O
respectively	O
.	O
	
To	O
further	O
enable	O
two	O
-	O
way	O
information	O
flows	O
between	O
and	O
,	O
we	O
add	O
the	O
green	O
link	O
,	O
which	O
is	O
inspired	O
by	O
the	O
delayed	B-Method
feedback	I-Method
mechanism	I-Method
of	O
traditional	O
multi	B-Method
-	I-Method
layer	I-Method
RNNs	I-Method
.	O
	
Here	O
,	O
it	O
introduces	O
a	O
delayed	O
HR	B-Task
to	O
LR	O
connection	O
.	O
	
The	O
overall	O
dynamics	O
of	O
our	O
DSRN	B-Method
is	O
given	O
as	O
:	O
Figure	O
[	O
reference	O
]	O
(	O
b	O
)	O
demonstrates	O
the	O
same	O
concept	O
via	O
an	O
unfolded	B-Method
graph	I-Method
,	O
where	O
the	O
top	O
row	O
represents	O
HR	B-Task
state	O
while	O
the	O
bottom	O
one	O
is	O
LR	O
.	O
	
This	O
design	O
choice	O
encourages	O
feature	O
specialization	O
for	O
different	O
resolutions	O
and	O
information	O
sharing	O
across	O
different	O
resolutions	O
.	O
	
Transition	O
functions	O
:	O
	
Our	O
model	O
is	O
characterized	O
by	O
six	O
transition	O
functions	O
.	O
	
,	O
,	O
,	O
and	O
as	O
illustrated	O
in	O
Figure	O
[	O
reference	O
]	O
(	O
b	O
)	O
.	O
	
Specifically	O
,	O
we	O
use	O
the	O
standard	O
residual	B-Method
block	I-Method
for	O
both	O
self	B-Task
-	I-Task
transitions	I-Task
.	O
	
A	O
single	O
convolutional	B-Method
layer	I-Method
is	O
used	O
for	O
the	O
down	B-Task
-	I-Task
sampling	I-Task
transition	I-Task
and	O
a	O
single	O
transposed	B-Method
convolutional	I-Method
(	I-Method
or	I-Method
deconvolutional	I-Method
)	I-Method
layer	I-Method
is	O
used	O
for	O
the	O
up	B-Task
-	I-Task
sampling	I-Task
transition	I-Task
.	O
	
The	O
strides	O
in	O
both	O
inter	O
-	O
state	O
layers	O
are	O
set	O
to	O
be	O
the	O
same	O
as	O
the	O
SR	B-Task
upscaling	O
factor	O
.	O
	
Unfolding	B-Task
details	I-Task
:	O
Similarly	O
to	O
unfolding	O
a	O
single	B-Method
-	I-Method
state	I-Method
RNN	I-Method
to	O
obtain	O
a	O
ResNet	B-Method
,	O
for	O
image	O
SR	B-Task
,	O
we	O
let	O
have	O
no	O
contribution	O
to	O
calculating	O
the	O
state	O
transition	O
.	O
	
In	O
other	O
words	O
,	O
for	O
any	O
choice	O
of	O
(	O
e.g.	O
choose	O
)	O
.	O
	
Furthermore	O
,	O
we	O
set	O
as	O
the	O
output	O
of	O
two	O
convolutional	B-Method
layers	I-Method
with	O
skip	O
connections	O
,	O
which	O
takes	O
the	O
LR	O
input	O
image	O
and	O
transform	O
it	O
into	O
a	O
desired	O
feature	O
space	O
.	O
	
In	O
addition	O
,	O
is	O
set	O
to	O
zero	O
.	O
	
Finally	O
,	O
we	O
use	O
deep	O
supervision	O
for	O
the	O
HR	B-Task
prediction	O
,	O
as	O
discussed	O
below	O
.	O
	
Deep	B-Task
supervision	I-Task
:	O
The	O
unrolled	O
DSRN	B-Method
is	O
capable	O
of	O
making	O
a	O
prediction	O
at	O
every	O
time	O
step	O
.	O
	
Denote	O
as	O
a	O
prediction	O
at	O
the	O
unfolding	O
,	O
where	O
is	O
characterized	O
by	O
a	O
single	O
convolutional	B-Method
layer	I-Method
.	O
	
Then	O
,	O
instead	O
of	O
taking	O
the	O
prediction	O
only	O
at	O
the	O
final	O
unfolding	O
,	O
we	O
average	O
all	O
the	O
predictions	O
as	O
Thus	O
,	O
every	O
unrolled	B-Method
layer	I-Method
directly	O
connects	O
to	O
the	O
loss	B-Method
layer	I-Method
to	O
facilitate	O
the	O
training	O
of	O
such	O
a	O
very	O
deep	B-Method
network	I-Method
.	O
	
Moreover	O
,	O
the	O
model	O
predicts	O
the	O
residual	O
image	O
and	O
minimizes	O
the	O
following	O
mean	B-Metric
square	I-Metric
error	I-Metric
where	O
is	O
the	O
group	O
-	O
truth	O
image	O
in	O
HR	B-Task
and	O
is	O
the	O
residual	O
map	O
between	O
the	O
ground	O
truth	O
and	O
bicubic	O
upsampled	O
LR	O
image	O
.	O
	
section	O
:	O
Experiments	O
	
In	O
this	O
section	O
,	O
we	O
first	O
provide	O
implementation	O
details	O
,	O
including	O
both	O
model	B-Method
hyper	I-Method
-	I-Method
parameters	I-Method
and	O
training	B-Method
data	I-Method
augmentation	I-Method
.	O
	
Then	O
we	O
analyze	O
a	O
number	O
of	O
design	O
choices	O
and	O
their	O
contributions	O
to	O
final	O
performance	O
.	O
	
Finally	O
,	O
we	O
compare	O
DSRN	B-Method
to	O
other	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
methods	O
on	O
several	O
benchmark	O
datasets	O
.	O
	
subsection	O
:	O
Datasets	O
	
To	O
evaluate	O
the	O
proposed	O
DSRN	B-Method
algorithm	O
,	O
we	O
train	O
our	O
model	O
using	O
91	O
images	O
proposed	O
in	O
and	O
test	O
on	O
the	O
following	O
datasets	O
:	O
Set5	B-Material
,	O
Set14	B-Material
,	O
B100	B-Material
and	O
Urban100	B-Material
.	O
	
The	O
training	O
data	O
is	O
augmented	O
in	O
a	O
similar	O
way	O
to	O
previous	O
methods	O
,	O
which	O
includes	O
1	O
)	O
random	O
flipping	O
along	O
the	O
vertical	O
or	O
horizontal	O
axis	O
;	O
2	O
)	O
random	O
rotation	O
by	O
90	O
,	O
180	O
or	O
270	O
;	O
and	O
3	O
)	O
random	O
scaling	O
by	O
a	O
factor	O
from	O
[	O
0.5	O
,	O
0.6	O
,	O
0.7	O
,	O
0.8	O
,	O
0.9	O
,	O
	
1	O
]	O
.	O
Tensorflow	B-Method
is	O
used	O
for	O
our	O
full	B-Task
data	I-Task
processing	I-Task
pipeline	I-Task
;	O
the	O
LR	O
training	O
images	O
are	O
generated	O
by	O
the	O
built	O
-	O
in	O
bicubic	B-Method
down	I-Method
-	I-Method
sampling	I-Method
function	I-Method
.	O
	
We	O
additionally	O
test	O
our	O
algorithm	O
on	O
the	O
DIV2	O
K	O
dataset	O
of	O
the	O
NTIRE	O
SR	B-Task
2017	O
challenge	O
,	O
where	O
we	O
use	O
the	O
provided	O
training	O
and	O
validation	O
sets	O
with	O
all	O
of	O
the	O
aforementioned	O
data	B-Method
augmentations	I-Method
except	O
random	B-Method
scaling	I-Method
.	O
	
subsection	O
:	O
Implementation	O
Details	O
	
We	O
use	O
our	O
model	O
to	O
super	O
-	O
resolve	O
only	O
the	O
luminance	O
channel	O
of	O
images	O
,	O
and	O
use	O
bicubic	B-Method
interpolation	I-Method
to	O
upscale	O
the	O
other	O
two	O
color	O
channels	O
,	O
following	O
.	O
	
We	O
train	O
independent	B-Method
models	I-Method
for	O
each	O
scale	O
(	O
2	O
,	O
3	O
,	O
and	O
4	O
)	O
with	O
64	O
filters	O
on	O
the	O
first	O
input	O
convolutional	B-Method
layer	I-Method
and	O
128	O
filters	O
in	O
the	O
rest	O
of	O
the	O
network	O
.	O
	
All	O
layers	O
use	O
convolution	B-Method
filters	I-Method
.	O
	
Due	O
to	O
our	O
dual	B-Method
-	I-Method
state	I-Method
design	I-Method
,	O
the	O
feature	O
maps	O
of	O
and	O
in	O
each	O
time	O
step	O
have	O
the	O
same	O
spatial	O
dimensions	O
as	O
the	O
LR	O
and	O
HR	B-Task
images	O
,	O
respectively	O
.	O
	
We	O
zero	O
-	O
pad	O
the	O
boundaries	O
of	O
feature	O
maps	O
to	O
ensure	O
the	O
spatial	O
size	O
of	O
each	O
feature	O
map	O
is	O
the	O
same	O
as	O
the	O
input	O
size	O
after	O
the	O
convolution	B-Method
is	O
applied	O
.	O
	
All	O
the	O
weights	O
in	O
the	O
network	O
are	O
initialized	O
with	O
a	O
uniform	O
distribution	O
using	O
the	O
method	O
proposed	O
in	O
.	O
	
We	O
use	O
standard	O
stochastic	B-Method
gradient	I-Method
descent	I-Method
(	O
SGD	B-Method
)	O
with	O
momentum	B-Method
0.95	I-Method
as	O
our	O
optimizer	O
to	O
minimize	O
the	O
MSE	B-Metric
loss	I-Metric
function	I-Metric
in	O
Equation	O
(	O
[	O
reference	O
]	O
)	O
.	O
	
We	O
search	O
for	O
the	O
best	O
initial	O
learning	B-Metric
rate	I-Metric
from	O
and	O
reduce	O
it	O
by	O
a	O
factor	O
of	O
10	O
three	O
times	O
during	O
the	O
entire	O
training	O
process	O
.	O
	
This	O
learning	B-Metric
rate	I-Metric
annealing	I-Metric
is	O
driven	O
by	O
observing	O
that	O
the	O
loss	B-Metric
on	O
the	O
validation	O
set	O
stops	O
decreasing	O
.	O
	
Gradient	B-Method
clipping	I-Method
at	O
is	O
adopted	O
during	O
training	B-Task
to	O
prevent	O
the	O
gradient	O
explosion	O
.	O
	
We	O
sample	O
image	O
patches	O
with	O
a	O
size	O
of	O
and	O
use	O
a	O
mini	O
-	O
batch	O
size	O
of	O
to	O
train	O
our	O
network	O
.	O
	
We	O
observe	O
that	O
the	O
recursion	O
defined	O
in	O
Equation	O
(	O
[	O
reference	O
]	O
)	O
may	O
lead	O
to	O
an	O
exponential	O
increase	O
in	O
the	O
scale	O
of	O
feature	O
values	O
,	O
especially	O
when	O
is	O
large	O
.	O
	
In	O
,	O
the	O
authors	O
proposed	O
the	O
use	O
of	O
unshared	B-Method
batch	I-Method
normalization	I-Method
at	O
every	O
unfolding	O
time	O
to	O
resolve	O
this	O
issue	O
.	O
	
Batch	B-Method
normalization	I-Method
is	O
not	O
used	O
in	O
our	O
network	O
;	O
we	O
found	O
that	O
normalizing	O
the	O
scale	O
with	O
two	O
scalar	O
parameters	O
was	O
sufficient	O
.	O
	
Specifically	O
,	O
we	O
use	O
one	O
unshared	O
PReLU	O
activation	O
for	O
each	O
recurrent	O
state	O
after	O
every	O
unrolling	O
step	O
.	O
	
All	O
other	O
layers	O
have	O
ordinary	O
ReLU	B-Method
as	O
the	O
activation	O
function	O
.	O
	
Ours	O
Others	O
	
.24	O
	
.24	O
	
.24	O
	
.24	O
	
.24	O
	
.24	O
	
.24	O
	
.24	O
	
.24	O
	
.24	O
	
.24	O
	
.24	O
	
.24	O
	
.24	O
	
.24	O
	
.24	O
	
.24	O
	
.24	O
	
.24	O
	
.24	O
	
.24	O
	
.24	O
	
.24	O
	
.24	O
	
.24	O
	
.24	O
	
.24	O
	
.24	O
	
.24	O
	
.24	O
	
.24	O
	
.24	O
	
.24	O
	
.24	O
	
.24	O
.24	O
	
subsection	O
:	O
Model	O
Analysis	O
	
In	O
this	O
section	O
,	O
we	O
analyze	O
our	O
proposed	O
model	O
in	O
the	O
following	O
respects	O
:	O
Unrolling	O
length	O
:	O
The	O
unrolling	O
length	O
changes	O
the	O
maximum	O
effective	O
depth	O
of	O
the	O
unrolled	B-Method
network	I-Method
.	O
	
In	O
particular	O
,	O
for	O
a	O
DSRN	B-Method
with	O
times	B-Method
unrolling	I-Method
,	O
the	O
maximum	O
number	O
of	O
convolution	O
layers	O
between	O
input	O
and	O
output	O
of	O
the	O
network	O
is	O
.	O
	
The	O
multiplier	O
comes	O
from	O
the	O
two	O
layers	O
in	O
a	O
residual	O
block	O
,	O
while	O
the	O
extra	O
4	O
is	O
from	O
the	O
auxiliary	O
input	O
and	O
output	O
layers	O
.	O
	
However	O
,	O
the	O
number	O
of	O
model	O
parameters	O
remains	O
independent	O
of	O
the	O
length	O
of	O
unrolling	O
.	O
	
Essentially	O
,	O
controls	O
the	O
trade	O
-	O
off	O
between	O
model	B-Metric
capacity	I-Metric
and	O
computation	B-Metric
cost	I-Metric
.	O
	
We	O
study	O
the	O
influence	O
of	O
by	O
training	O
the	O
model	O
with	O
different	O
unrolling	O
lengths	O
.	O
	
The	O
empirical	O
results	O
are	O
shown	O
in	O
Figure	O
[	O
reference	O
]	O
.	O
	
The	O
test	O
performance	O
increases	O
when	O
the	O
number	O
of	O
unfolding	O
steps	O
increases	O
,	O
but	O
the	O
benefit	O
seems	O
to	O
diminish	O
after	O
.	O
	
Unless	O
otherwise	O
mentioned	O
,	O
we	O
use	O
for	O
all	O
our	O
models	O
.	O
	
It	O
is	O
worth	O
mentioning	O
that	O
we	O
also	O
experimented	O
with	O
stochastic	O
depth	O
by	O
randomly	B-Method
sampling	I-Method
during	O
training	O
,	O
but	O
we	O
observed	O
no	O
improvement	O
in	O
validation	B-Metric
accuracy	I-Metric
.	O
	
Parameter	B-Method
sharing	I-Method
:	O
We	O
empirically	O
find	O
parameter	O
sharing	O
to	O
be	O
crucial	O
for	O
training	O
a	O
deep	B-Method
recursive	I-Method
model	I-Method
.	O
	
As	O
shown	O
in	O
Table	O
[	O
reference	O
]	O
,	O
the	O
same	O
model	O
with	O
untied	O
weights	O
performs	O
much	O
more	O
poorly	O
than	O
its	O
weight	B-Method
-	I-Method
sharing	I-Method
counterpart	I-Method
.	O
	
Specifically	O
,	O
we	O
observe	O
around	O
0.2dB	O
performance	O
drop	O
across	O
all	O
three	O
upscaling	O
scales	O
when	O
changing	O
from	O
shared	O
weights	O
to	O
untied	O
weights	O
.	O
	
We	O
speculate	O
that	O
the	O
model	O
with	O
untied	O
weights	O
suffers	O
a	O
larger	O
risk	O
of	O
model	B-Method
over	I-Method
-	I-Method
fitting	I-Method
and	O
much	O
slower	O
training	B-Metric
convergence	I-Metric
,	O
both	O
of	O
which	O
diminish	O
the	O
model	O
’s	O
restoration	B-Metric
accuracy	I-Metric
.	O
	
Dual	O
-	O
state	O
and	O
delayed	O
feedback	O
	
:	O
We	O
compare	O
our	O
DSRN	B-Method
with	O
two	O
baselines	O
under	O
the	O
same	O
unrolling	O
time	O
steps	O
to	O
understand	O
how	O
each	O
module	O
of	O
our	O
model	O
contributes	O
to	O
the	O
final	O
performance	O
:	O
1	O
)	O
a	O
single	B-Method
-	I-Method
state	I-Method
RNN	I-Method
unrolled	I-Method
ResNet	I-Method
;	O
and	O
2	O
)	O
a	O
dual	B-Method
-	I-Method
state	I-Method
RNN	I-Method
without	I-Method
delayed	I-Method
feedback	I-Method
connections	I-Method
.	O
	
The	O
quantitative	O
comparison	O
on	O
the	O
NTIRE	O
SR	B-Task
2017	O
challenge	O
is	O
shown	O
in	O
Table	O
[	O
reference	O
]	O
.	O
	
Comparing	O
the	O
single	B-Method
-	I-Method
state	I-Method
baseline	I-Method
and	O
the	O
DSRN	B-Method
without	O
feedback	O
,	O
it	O
is	O
clear	O
that	O
considering	O
information	O
from	O
both	O
LR	O
and	O
HR	B-Task
spaces	O
as	O
two	O
separated	O
states	O
provides	O
performance	O
gains	O
.	O
	
In	O
addition	O
,	O
comparing	O
our	O
models	O
with	O
and	O
without	O
feedback	O
,	O
we	O
realize	O
that	O
incorporating	O
such	O
an	O
information	O
flow	O
from	O
HR	B-Task
space	O
back	O
to	O
LR	O
space	O
consistently	O
improves	O
performance	O
on	O
all	O
three	O
different	O
scales	O
.	O
	
In	O
all	O
,	O
both	O
the	O
dual	B-Method
-	I-Method
state	I-Method
and	I-Method
delayed	I-Method
feedback	I-Method
designs	I-Method
are	O
beneficial	O
to	O
our	O
model	O
.	O
	
State	B-Method
visualization	I-Method
Since	O
DSRN	B-Method
has	O
independent	O
scaling	O
parameters	O
on	O
each	O
unrolled	O
state	O
,	O
the	O
model	O
implicitly	O
learns	O
a	O
weighted	B-Method
-	I-Method
average	I-Method
of	O
all	O
the	O
unrolled	O
states	O
for	O
the	O
final	O
prediction	B-Task
.	O
	
Empirically	O
we	O
observe	O
that	O
this	O
strategy	O
performs	O
better	O
than	O
output	O
from	O
the	O
last	O
state	O
only	O
.	O
	
To	O
demonstrate	O
how	O
the	O
network	O
aggregates	O
different	O
unrolled	O
states	O
,	O
we	O
show	O
feature	O
response	O
maps	O
at	O
different	O
unrolling	O
steps	O
in	O
Figure	O
[	O
reference	O
]	O
,	O
demonstrating	O
that	O
the	O
network	O
distributes	O
slightly	O
different	O
features	O
to	O
each	O
unrolled	O
state	O
.	O
	
subsection	O
:	O
Comparison	O
with	O
the	O
State	O
-	O
of	O
-	O
the	O
-	O
Art	O
	
We	O
provide	O
results	O
of	O
evaluation	O
of	O
our	O
model	O
on	O
several	O
public	O
benchmark	O
datasets	O
in	O
Table	O
[	O
reference	O
]	O
,	O
with	O
three	O
commonly	O
-	O
used	O
evaluation	B-Metric
metrics	I-Metric
:	O
Peak	B-Metric
Signal	I-Metric
-	I-Metric
to	I-Metric
-	I-Metric
Noise	I-Metric
Ratio	I-Metric
(	O
PSNR	B-Metric
)	O
,	O
Structural	B-Metric
SIMilarity	I-Metric
(	O
SSIM	B-Metric
)	O
and	O
the	O
Information	B-Metric
Fidelity	I-Metric
Criterion	I-Metric
(	O
IFC	B-Method
)	O
.	O
	
Specifically	O
,	O
we	O
perform	O
a	O
comprehensive	O
comparison	O
between	O
our	O
method	O
and	O
10	O
other	O
existing	O
SR	B-Task
algorithms	O
,	O
including	O
both	O
deep	B-Method
learning	I-Method
and	I-Method
non	I-Method
-	I-Method
deep	I-Method
-	I-Method
learning	I-Method
based	I-Method
methods	I-Method
.	O
	
Note	O
that	O
many	O
recent	O
deep	B-Method
learning	I-Method
based	I-Method
competitors	I-Method
,	O
including	O
VDSR	B-Method
,	O
LapSRN	B-Method
and	O
DRRN	B-Method
,	O
use	O
291	O
training	O
samples	O
with	O
the	O
additional	O
200	O
from	O
the	O
training	O
set	O
of	O
Berkeley	O
Segmentation	O
Dataset	O
,	O
while	O
our	O
model	O
was	O
trained	O
on	O
only	O
the	O
91	O
images	O
.	O
	
Still	O
,	O
our	O
DSRN	B-Method
method	O
achieves	O
competitive	O
performance	O
across	O
all	O
datasets	O
and	O
scales	O
.	O
	
It	O
achieves	O
particularly	O
strong	O
performance	O
in	O
the	O
and	O
settings	O
.	O
	
In	O
addition	O
,	O
we	O
report	O
quantitative	O
evaluations	O
on	O
the	O
recently	O
developed	O
DIV2	O
K	O
dataset	O
and	O
comparisons	O
with	O
top	B-Method
-	I-Method
ranking	I-Method
algorithms	I-Method
in	O
Table	O
[	O
reference	O
]	O
.	O
	
Our	O
method	O
achieves	O
competitive	O
performance	O
with	O
the	O
best	O
algorithm	O
,	O
EDSR	B-Method
+	I-Method
,	O
and	O
outperforms	O
all	O
the	O
other	O
algorithms	O
by	O
a	O
large	O
margin	O
,	O
which	O
demonstrates	O
the	O
effectiveness	O
of	O
our	O
proposed	O
dual	B-Method
-	I-Method
state	I-Method
recurrent	I-Method
structure	I-Method
.	O
	
To	O
further	O
analyze	O
the	O
proposed	O
DSRN	B-Method
against	O
other	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
SR	B-Task
approaches	O
in	O
a	O
qualitative	O
manner	O
,	O
in	O
Figure	O
[	O
reference	O
]	O
we	O
present	O
several	O
visual	O
examples	O
of	O
super	O
-	O
resolved	O
images	O
on	O
Set14	B-Material
with	O
upscaling	O
among	O
different	O
SR	B-Task
approaches	O
.	O
	
For	O
these	O
competing	O
methods	O
,	O
we	O
use	O
SR	B-Task
results	O
publicly	O
released	O
by	O
the	O
authors	O
.	O
	
As	O
shown	O
in	O
Figure	O
[	O
reference	O
]	O
,	O
our	O
method	O
can	O
construct	O
sharp	O
and	O
detailed	O
structures	O
and	O
is	O
less	O
prone	O
to	O
generating	O
spurious	O
artifacts	O
.	O
	
Furthermore	O
,	O
the	O
proposed	O
DSRN	B-Method
benefits	O
from	O
inherent	O
parameter	B-Method
sharing	I-Method
and	O
therefore	O
obtains	O
higher	O
parameter	B-Metric
efficiency	I-Metric
compared	O
to	O
other	O
methods	O
.	O
	
In	O
Figure	O
[	O
reference	O
]	O
,	O
we	O
illustrate	O
the	O
parameters	O
-	O
to	O
-	O
PSNR	B-Metric
relationship	I-Metric
of	O
our	O
model	O
and	O
several	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
methods	O
,	O
including	O
SRCNN	B-Method
,	O
VDSR	B-Method
,	O
DRCN	B-Method
,	O
DRRN	B-Method
and	O
RED30	B-Method
.	O
	
Our	O
method	O
represents	O
a	O
favorable	O
trade	O
-	O
off	O
between	O
model	B-Metric
size	I-Metric
and	O
SR	B-Task
performance	O
,	O
and	O
has	O
modest	O
inference	B-Metric
time	I-Metric
.	O
	
The	O
DSRN	B-Method
takes	O
0.4s	O
on	O
the	O
x4	B-Task
task	I-Task
with	O
a	O
288x288	O
output	O
image	O
size	O
,	O
on	O
an	O
NVIDIA	O
Titan	O
X	O
GPU	O
.	O
	
section	O
:	O
Conclusion	O
	
In	O
this	O
work	O
,	O
we	O
have	O
provided	O
a	O
unique	O
formulation	O
that	O
expresses	O
many	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
SR	B-Task
models	O
as	O
a	O
finite	B-Method
unfolding	I-Method
of	O
a	O
single	B-Method
-	I-Method
state	I-Method
RNN	I-Method
with	O
various	O
recurrent	O
functions	O
.	O
	
Based	O
on	O
this	O
,	O
we	O
extend	O
existing	O
methods	O
by	O
considering	O
a	O
dual	B-Method
-	I-Method
state	I-Method
design	I-Method
;	O
the	O
two	O
hidden	O
states	O
of	O
our	O
proposed	O
DSRN	B-Method
operate	O
at	O
different	O
spatial	O
resolutions	O
.	O
	
One	O
captures	O
the	O
LR	O
information	O
while	O
the	O
other	O
one	O
targets	O
the	O
HR	B-Task
domains	O
.	O
	
To	O
ensure	O
two	O
-	O
way	O
communication	O
between	O
states	O
,	O
we	O
integrate	O
a	O
delayed	B-Method
feedback	I-Method
mechanism	I-Method
.	O
	
Thus	O
,	O
the	O
predicted	O
features	O
from	O
both	O
LR	O
and	O
HR	B-Task
states	O
can	O
be	O
exploited	O
jointly	O
for	O
final	O
predictions	B-Task
.	O
	
Extensive	O
experiments	O
on	O
benchmark	O
datasets	O
have	O
demonstrated	O
that	O
the	O
proposed	O
DSRN	B-Method
performs	O
favorably	O
against	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
SR	B-Task
models	O
in	O
terms	O
of	O
both	O
efficiency	B-Metric
and	O
accuracy	B-Metric
.	O
	
For	O
the	O
future	O
work	O
,	O
we	O
will	O
explore	O
use	O
of	O
our	O
proposed	O
DSRN	B-Method
to	O
capture	O
temporal	O
dependencies	O
for	O
video	O
SR	B-Task
.	O
	
bibliography	O
:	O
References	O
	
document	O
:	O
Natural	B-Task
Language	I-Task
Inference	I-Task
over	O
Interaction	B-Task
Space	I-Task
	
Natural	B-Task
Language	I-Task
Inference	I-Task
(	O
NLI	B-Task
)	O
task	O
requires	O
an	O
agent	O
to	O
determine	O
the	O
logical	O
relationship	O
between	O
a	O
natural	O
language	O
premise	O
and	O
a	O
natural	O
language	O
hypothesis	O
.	O
	
We	O
introduce	O
Interactive	B-Method
Inference	I-Method
Network	I-Method
(	O
IIN	B-Method
)	I-Method
,	O
a	O
novel	O
class	O
of	O
neural	B-Method
network	I-Method
architectures	I-Method
that	O
is	O
able	O
to	O
achieve	O
high	O
-	O
level	O
understanding	O
of	O
the	O
sentence	O
pair	O
by	O
hierarchically	O
extracting	O
semantic	O
features	O
from	O
interaction	O
space	O
.	O
	
We	O
show	O
that	O
an	O
interaction	O
tensor	O
(	O
attention	O
weight	O
)	O
contains	O
semantic	O
information	O
to	O
solve	O
natural	B-Task
language	I-Task
inference	I-Task
,	O
and	O
a	O
denser	O
interaction	O
tensor	O
contains	O
richer	O
semantic	O
information	O
.	O
	
One	O
instance	O
of	O
such	O
architecture	O
,	O
Densely	B-Method
Interactive	I-Method
Inference	I-Method
Network	I-Method
(	O
DIIN	B-Method
)	O
,	O
demonstrates	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
performance	O
on	O
large	O
scale	O
NLI	B-Task
copora	O
and	O
large	O
-	O
scale	O
NLI	B-Task
alike	O
corpus	O
.	O
	
It	O
’s	O
noteworthy	O
that	O
DIIN	B-Method
achieve	O
a	O
greater	O
than	O
20	O
%	O
error	B-Metric
reduction	I-Metric
on	O
the	O
challenging	O
Multi	O
-	O
Genre	O
NLI	B-Task
(	O
MultiNLI	O
;	O
)	O
dataset	O
with	O
respect	O
to	O
the	O
strongest	O
published	O
system	O
.	O
	
section	O
:	O
Introduction	O
	
Natural	B-Task
Language	I-Task
Inference	I-Task
(	O
NLI	B-Task
also	O
known	O
as	O
recognizing	B-Task
textual	I-Task
entiailment	I-Task
,	O
or	O
RTE	B-Task
)	O
task	O
requires	O
one	O
to	O
determine	O
whether	O
the	O
logical	O
relationship	O
between	O
two	O
sentences	O
is	O
among	O
entailment	O
(	O
if	O
the	O
premise	O
is	O
true	O
,	O
then	O
the	O
hypothesis	O
must	O
be	O
true	O
)	O
,	O
contradiction	O
(	O
if	O
the	O
premise	O
is	O
true	O
,	O
then	O
the	O
hypothesis	O
must	O
be	O
false	O
)	O
and	O
neutral	O
(	O
neither	O
entailment	O
nor	O
contradiction	O
)	O
.	O
	
NLI	B-Task
is	O
known	O
as	O
a	O
fundamental	O
and	O
yet	O
challenging	O
task	O
for	O
natural	B-Task
language	I-Task
understanding	I-Task
,	O
not	O
only	O
because	O
it	O
requires	O
one	O
to	O
identify	O
the	O
language	O
pattern	O
,	O
but	O
also	O
to	O
understand	O
certain	O
common	O
sense	O
knowledge	O
.	O
	
In	O
Table	O
[	O
reference	O
]	O
,	O
three	O
samples	O
from	O
MultiNLI	O
corpus	O
show	O
solving	O
the	O
task	O
requires	O
one	O
to	O
handle	O
the	O
full	O
complexity	O
of	O
lexical	O
and	O
compositional	O
semantics	O
.	O
	
The	O
previous	O
work	O
on	O
NLI	B-Task
(	O
or	O
RTE	B-Task
)	O
has	O
extensively	O
researched	O
on	O
conventional	O
approaches	O
.	O
	
Recent	O
progress	O
on	O
NLI	B-Task
is	O
enabled	O
by	O
the	O
availability	O
of	O
570k	O
human	O
annotated	O
dataset	O
and	O
the	O
advancement	O
of	O
representation	B-Method
learning	I-Method
technique	I-Method
.	O
	
Among	O
the	O
core	B-Method
representation	I-Method
learning	I-Method
techniques	I-Method
,	O
attention	B-Method
mechanism	I-Method
is	O
broadly	O
applied	O
in	O
many	O
NLU	B-Task
tasks	O
since	O
its	O
introduction	O
:	O
machine	B-Task
translation	I-Task
,	O
abstractive	B-Task
summarization	I-Task
,	O
Reading	B-Task
Comprehension	I-Task
,	O
dialog	B-Task
system	I-Task
,	O
etc	O
.	O
	
As	O
described	O
by	O
,	O
“	O
	
An	O
attention	B-Method
function	I-Method
can	O
be	O
described	O
as	O
mapping	O
a	O
query	O
and	O
a	O
set	O
of	O
key	O
-	O
value	O
pairs	O
to	O
an	O
output	O
,	O
where	O
the	O
query	O
,	O
keys	O
,	O
values	O
,	O
and	O
output	O
are	O
all	O
vectors	O
.	O
	
The	O
output	O
is	O
computed	O
as	O
a	O
weighted	O
sum	O
of	O
the	O
values	O
,	O
where	O
the	O
weight	O
assigned	O
to	O
each	O
value	O
is	O
computed	O
by	O
a	O
compatibility	O
function	O
of	O
the	O
query	O
with	O
the	O
corresponding	O
key	O
”	O
.	O
	
Attention	B-Method
mechanism	I-Method
is	O
known	O
for	O
its	O
alignment	O
between	O
representations	O
,	O
focusing	O
one	O
part	O
of	O
representation	O
over	O
another	O
,	O
and	O
modeling	O
the	O
dependency	O
regardless	O
of	O
sequence	O
length	O
.	O
	
Observing	O
attention	O
’s	O
powerful	O
capability	O
,	O
we	O
hypothesize	O
that	O
the	O
attention	O
weight	O
can	O
assist	O
with	O
machine	O
to	O
understanding	O
the	O
text	O
.	O
	
A	O
regular	O
attention	O
weight	O
,	O
the	O
core	O
component	O
of	O
the	O
attention	B-Method
mechanism	I-Method
,	O
encodes	O
the	O
cross	O
-	O
sentence	O
word	O
relationship	O
into	O
a	O
alignment	O
matrix	O
.	O
	
However	O
,	O
a	O
multi	O
-	O
head	O
attention	O
weight	O
can	O
encode	O
such	O
interaction	O
into	O
multiple	O
alignment	O
matrices	O
,	O
which	O
shows	O
a	O
more	O
powerful	O
alignment	O
.	O
	
In	O
this	O
work	O
,	O
we	O
push	O
the	O
multi	B-Task
-	I-Task
head	I-Task
attention	I-Task
to	O
a	O
extreme	O
by	O
building	O
a	O
word	B-Method
-	I-Method
by	I-Method
-	I-Method
word	I-Method
dimension	I-Method
-	I-Method
wise	I-Method
alignment	I-Method
tensor	I-Method
which	O
we	O
call	O
interaction	B-Method
tensor	I-Method
.	O
	
The	O
interaction	O
tensor	O
encodes	O
the	O
high	O
-	O
order	O
alignment	O
relationship	O
between	O
sentences	O
pair	O
.	O
	
Our	O
experiments	O
demonstrate	O
that	O
by	O
capturing	O
the	O
rich	O
semantic	O
features	O
in	O
the	O
interaction	O
tensor	O
,	O
we	O
are	O
able	O
to	O
solve	O
natural	B-Task
language	I-Task
inference	I-Task
task	O
well	O
,	O
especially	O
in	O
cases	O
with	O
paraphrase	O
,	O
antonyms	O
and	O
overlapping	O
words	O
.	O
	
We	O
dub	O
the	O
general	O
framework	O
as	O
Interactive	O
Inference	B-Method
Network	I-Method
(	O
IIN	B-Method
)	O
.	O
	
To	O
the	O
best	O
of	O
our	O
knowledge	O
,	O
it	O
is	O
the	O
first	O
attempt	O
to	O
solve	O
natural	B-Task
language	I-Task
inference	I-Task
task	O
in	O
the	O
interaction	O
space	O
.	O
	
We	O
further	O
explore	O
one	O
instance	O
of	O
Interactive	B-Method
Inference	I-Method
Network	I-Method
,	O
Densely	B-Method
Interactive	I-Method
Inference	I-Method
Network	I-Method
(	O
DIIN	B-Method
)	O
,	O
which	O
achieves	O
new	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
performance	O
on	O
both	O
SNLI	B-Material
and	O
MultiNLI	O
copora	O
.	O
	
To	O
test	O
the	O
generality	O
of	O
the	O
architecture	O
,	O
we	O
interpret	O
the	O
paraphrase	B-Task
identification	I-Task
task	I-Task
as	O
natural	B-Task
language	I-Task
inference	I-Task
task	O
where	O
matching	B-Task
as	O
entailment	O
,	O
not	O
-	O
matching	O
as	O
neutral	O
.	O
	
We	O
test	O
the	O
model	O
on	O
Quora	B-Material
Question	I-Material
Pair	I-Material
dataset	I-Material
,	O
which	O
contains	O
over	O
400k	O
real	O
world	O
question	O
pair	O
,	O
and	O
achieves	O
new	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
performance	O
.	O
	
We	O
introduce	O
the	O
related	O
work	O
in	O
Section	O
2	O
,	O
and	O
discuss	O
the	O
general	O
framework	O
of	O
IIN	B-Method
along	O
with	O
a	O
specific	O
instance	O
that	O
enjoys	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
performance	O
on	O
multiple	O
datasets	O
in	O
Section	O
3	O
.	O
	
We	O
describe	O
experiments	O
and	O
analysis	O
in	O
Section	O
4	O
.	O
	
Finally	O
,	O
we	O
conclude	O
and	O
discuss	O
future	O
work	O
in	O
Section	O
5	O
.	O
	
section	O
:	O
Related	O
Work	O
	
The	O
early	O
exploration	O
on	O
NLI	B-Task
mainly	O
rely	O
on	O
conventional	O
methods	O
and	O
small	O
scale	O
datasets	O
.	O
	
The	O
availability	O
of	O
SNLI	B-Material
dataset	I-Material
with	O
570k	O
human	O
annotated	O
sentence	O
pairs	O
has	O
enabled	O
a	O
good	O
deal	O
of	O
progress	O
on	O
natural	B-Task
language	I-Task
understanding	I-Task
.	O
	
The	O
essential	O
representation	B-Method
learning	I-Method
techniques	I-Method
for	O
NLU	B-Task
such	O
as	O
attention	O
,	O
memory	O
and	O
the	O
use	O
of	O
parse	O
structure	O
are	O
studied	O
on	O
the	O
SNLI	B-Material
which	O
serves	O
as	O
an	O
important	O
benchmark	O
for	O
sentence	B-Task
understanding	I-Task
.	O
	
The	O
models	O
trained	O
on	O
NLI	B-Task
task	O
can	O
be	O
divided	O
into	O
two	O
categories	O
:	O
(	O
i	O
)	O
sentence	B-Method
encoding	I-Method
-	I-Method
based	I-Method
model	I-Method
which	O
aims	O
to	O
find	O
vector	B-Method
representation	I-Method
for	O
each	O
sentence	O
and	O
classifies	O
the	O
relation	O
by	O
using	O
the	O
concatenation	O
of	O
two	O
vector	B-Method
representation	I-Method
along	O
with	O
their	O
absolute	O
element	O
-	O
wise	O
difference	O
and	O
element	O
-	O
wise	O
product	O
.	O
	
(	O
ii	O
)	O
	
Joint	B-Method
feature	I-Method
models	I-Method
which	O
use	O
the	O
cross	O
sentence	O
feature	O
or	O
attention	O
from	O
one	O
sentence	O
to	O
another	O
.	O
	
After	O
neural	B-Method
attention	I-Method
mechanism	I-Method
is	O
successfully	O
applied	O
on	O
the	O
machine	B-Task
translation	I-Task
task	I-Task
,	O
such	O
technique	O
has	O
became	O
widely	O
used	O
in	O
both	O
natural	B-Task
language	I-Task
process	I-Task
and	O
computer	B-Task
vision	I-Task
domains	I-Task
.	O
	
Many	O
variants	O
of	O
attention	B-Method
technique	I-Method
such	O
as	O
hard	O
-	O
attention	O
,	O
self	O
-	O
attention	O
,	O
multi	B-Task
-	I-Task
hop	I-Task
attention	I-Task
,	O
bidirectional	O
attention	O
and	O
multi	B-Task
-	I-Task
head	I-Task
attention	I-Task
are	O
also	O
introduced	O
to	O
tackle	O
more	O
complicated	O
tasks	O
.	O
	
Before	O
this	O
work	O
,	O
neural	B-Method
attention	I-Method
mechanism	I-Method
is	O
mainly	O
used	O
to	O
make	O
alignment	B-Task
,	O
focusing	O
on	O
specific	O
part	O
of	O
the	O
representation	O
.	O
	
In	O
this	O
work	O
,	O
we	O
want	O
to	O
show	O
that	O
attention	O
weight	O
contains	O
rich	O
semantic	O
information	O
required	O
for	O
understanding	O
the	O
logical	O
relationship	O
between	O
sentence	O
pair	O
.	O
	
Though	O
RNN	B-Method
or	I-Method
LSTM	I-Method
are	O
very	O
good	O
for	O
variable	B-Task
length	I-Task
sequence	I-Task
modeling	I-Task
,	O
using	O
Convolutional	B-Method
neural	I-Method
network	I-Method
in	O
NLU	B-Task
tasks	O
is	O
very	O
desirable	O
because	O
of	O
its	O
parallelism	O
in	O
computation	B-Task
.	O
	
Convolutional	B-Method
structure	I-Method
has	O
been	O
successfully	O
applied	O
in	O
various	O
domain	O
such	O
as	O
machine	B-Task
translation	I-Task
,	O
sentence	B-Task
classification	I-Task
,	O
text	B-Task
matching	I-Task
and	O
sentiment	B-Task
analysis	I-Task
,	O
etc	O
.	O
	
The	O
convolution	B-Method
structure	I-Method
is	O
also	O
applied	O
on	O
different	O
level	O
of	O
granularity	O
such	O
as	O
byte	O
,	O
character	O
,	O
word	O
and	O
sentences	O
levels	O
.	O
	
section	O
:	O
Model	O
	
subsection	O
:	O
Interactive	B-Method
Inference	I-Method
Network	I-Method
	
The	O
Interactive	B-Method
Inference	I-Method
Network	I-Method
(	O
IIN	B-Method
)	O
is	O
a	O
hierarchical	B-Method
multi	I-Method
-	I-Method
stage	I-Method
process	I-Method
and	O
consists	O
of	O
five	O
components	O
.	O
	
Each	O
of	O
the	O
components	O
is	O
compatible	O
with	O
different	O
type	O
of	O
implementations	O
.	O
	
Potentially	O
all	O
exiting	B-Method
approaches	I-Method
in	O
machine	B-Task
learning	I-Task
,	O
such	O
as	O
decision	B-Method
tree	I-Method
,	O
support	B-Method
vector	I-Method
machine	I-Method
and	O
neural	B-Method
network	I-Method
approach	I-Method
,	O
can	O
be	O
transfer	O
to	O
replace	O
certain	O
component	O
in	O
this	O
architecture	O
.	O
	
We	O
focus	O
on	O
neural	B-Method
network	I-Method
approaches	I-Method
below	O
.	O
	
Figure	O
[	O
reference	O
]	O
provides	O
a	O
visual	O
illustration	O
of	O
Interactive	B-Method
Inference	I-Method
Network	I-Method
.	O
	
Embedding	B-Method
Layer	I-Method
converts	O
each	O
word	O
or	O
phrase	O
to	O
a	O
vector	B-Method
representation	I-Method
and	O
construct	O
the	O
representation	B-Method
matrix	I-Method
for	O
sentences	O
.	O
	
In	O
embedding	B-Method
layer	I-Method
,	O
a	O
model	O
can	O
map	O
tokens	O
to	O
vectors	O
with	O
the	O
pre	O
-	O
trained	O
word	B-Method
representation	I-Method
such	O
as	O
GloVe	B-Method
,	O
word2Vec	B-Method
and	O
fasttext	B-Method
.	O
	
It	O
can	O
also	O
utilize	O
the	O
pre	B-Method
-	I-Method
processing	I-Method
tool	I-Method
,	O
e.g.	O
named	B-Method
entity	I-Method
recognizer	I-Method
,	O
part	B-Method
-	I-Method
of	I-Method
-	I-Method
speech	I-Method
recognizer	I-Method
,	O
lexical	B-Method
parser	I-Method
and	O
coreference	B-Method
identifier	I-Method
etc	O
.	O
,	O
to	O
incorporate	O
more	O
lexical	O
and	O
syntactical	O
information	O
into	O
the	O
feature	O
vector	O
.	O
	
Encoding	B-Method
Layer	I-Method
encodes	O
the	O
representations	O
by	O
incorporating	O
the	O
context	O
information	O
or	O
enriching	O
the	O
representation	O
with	O
desirable	O
features	O
for	O
future	O
use	O
.	O
	
For	O
instance	O
,	O
a	O
model	O
can	O
adopt	O
bidirectional	B-Method
recurrent	I-Method
neural	I-Method
network	I-Method
to	O
model	O
the	O
temporal	O
interaction	O
on	O
both	O
direction	O
,	O
recursive	B-Method
neural	I-Method
network	I-Method
(	O
also	O
known	O
as	O
TreeRNN	B-Method
)	O
to	O
model	O
the	O
compositionality	O
and	O
the	O
recursive	O
structure	O
of	O
language	O
,	O
or	O
self	B-Method
-	I-Method
attention	I-Method
to	O
model	O
the	O
long	O
-	O
term	O
dependency	O
on	O
sentence	O
.	O
	
Different	O
components	O
of	O
encoder	B-Method
can	O
be	O
combined	O
to	O
obtain	O
a	O
better	O
sentence	B-Method
matrix	I-Method
representation	I-Method
.	O
	
Interaction	B-Method
Layer	I-Method
creates	O
an	O
word	O
-	O
by	O
-	O
word	O
interaction	O
tensor	O
by	O
both	O
premise	O
and	O
hypothesis	B-Method
representation	I-Method
matrix	I-Method
.	O
	
The	O
interaction	O
can	O
be	O
modeled	O
in	O
different	O
ways	O
.	O
	
A	O
common	O
approach	O
is	O
to	O
compute	O
the	O
cosine	O
similarity	O
or	O
dot	O
product	O
between	O
each	O
pair	O
of	O
feature	O
vector	O
.	O
	
On	O
the	O
other	O
hand	O
,	O
a	O
high	O
-	O
order	O
interaction	O
tensor	O
can	O
be	O
constructed	O
with	O
the	O
outer	O
product	O
between	O
two	O
matrix	B-Method
representations	I-Method
.	O
	
Feature	B-Method
Extraction	I-Method
Layer	I-Method
adopts	O
feature	B-Method
extractor	I-Method
to	O
extract	O
the	O
semantic	O
feature	O
from	O
interaction	O
tensor	O
.	O
	
The	O
convolutional	B-Method
feature	I-Method
extractors	I-Method
,	O
such	O
as	O
AlexNet	B-Method
,	O
VGG	B-Method
,	O
Inception	B-Method
,	O
ResNet	B-Method
and	O
DenseNet	B-Method
,	O
proven	O
work	O
well	O
on	O
image	B-Task
recognition	I-Task
are	O
completely	O
compatible	O
under	O
such	O
architecture	O
.	O
	
Unlike	O
the	O
work	O
who	O
employs	O
1	O
-	O
D	O
sliding	O
window	O
,	O
our	O
CNN	B-Method
architecture	I-Method
allows	O
2	B-Method
-	I-Method
D	I-Method
kernel	I-Method
to	O
extract	O
semantic	O
interaction	O
feature	O
from	O
the	O
word	O
-	O
by	O
-	O
word	O
interaction	O
between	O
n	O
-	O
gram	O
pair	O
.	O
	
Sequential	B-Method
or	I-Method
tree	I-Method
-	I-Method
like	I-Method
feature	I-Method
extractors	I-Method
are	O
also	O
applicable	O
in	O
the	O
feature	B-Method
extraction	I-Method
layer	I-Method
.	O
	
Output	B-Method
Layer	I-Method
decodes	O
the	O
acquired	O
features	O
to	O
give	O
prediction	B-Task
.	O
	
Under	O
the	O
setting	O
of	O
NLI	B-Task
,	O
the	O
output	B-Method
layer	I-Method
predicts	O
the	O
confidence	O
on	O
each	O
class	O
.	O
	
subsection	O
:	O
Densely	B-Method
Interactive	I-Method
Inference	I-Method
Network	I-Method
	
Here	O
we	O
introduce	O
Densely	B-Method
Interactive	I-Method
Inference	I-Method
Network	I-Method
(	O
DIIN	B-Method
)	O
,	O
which	O
is	O
a	O
relatively	O
simple	O
instantiation	O
of	O
IIN	B-Method
but	O
produces	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
performance	O
on	O
multiple	O
datasets	O
.	O
	
paragraph	O
:	O
Embedding	B-Method
Layer	I-Method
:	O
	
For	O
DIIN	B-Method
,	O
we	O
use	O
the	O
concatenation	O
of	O
word	O
embedding	O
,	O
character	O
feature	O
and	O
syntactical	O
features	O
.	O
	
The	O
word	B-Method
embedding	I-Method
is	O
obtained	O
by	O
mapping	O
token	O
to	O
high	O
dimensional	O
vector	O
space	O
by	O
pre	O
-	O
trained	O
word	O
vector	O
(	O
840B	O
GloVe	O
)	O
.	O
	
The	O
word	B-Method
embedding	I-Method
is	O
updated	O
during	O
training	O
.	O
	
As	O
in	O
,	O
we	O
filter	O
character	B-Method
embedding	I-Method
with	O
1D	B-Method
convolution	I-Method
kernel	I-Method
.	O
	
The	O
character	B-Method
convolutional	I-Method
feature	I-Method
maps	I-Method
are	O
then	O
max	O
pooled	O
over	O
time	O
dimension	O
for	O
each	O
token	O
to	O
obtain	O
a	O
vector	O
.	O
	
The	O
character	O
features	O
supplies	O
extra	O
information	O
for	O
some	O
out	O
-	O
of	O
-	O
vocabulary	O
(	O
OOV	O
)	O
words	O
.	O
	
Syntactical	O
features	O
include	O
one	O
-	O
hot	B-Method
part	I-Method
-	I-Method
of	I-Method
-	I-Method
speech	I-Method
(	I-Method
POS	I-Method
)	I-Method
tagging	I-Method
feature	I-Method
and	O
binary	B-Method
exact	I-Method
match	I-Method
(	O
EM	B-Method
)	I-Method
feature	I-Method
.	O
	
The	O
EM	O
value	O
is	O
activated	O
if	O
there	O
are	O
tokens	O
with	O
same	O
stem	O
or	O
lemma	O
in	O
the	O
other	O
sentence	O
as	O
the	O
corresponding	O
token	O
.	O
	
The	O
EM	B-Method
feature	I-Method
is	O
simple	O
while	O
found	O
useful	O
as	O
in	O
reading	B-Task
comprehension	I-Task
task	I-Task
.	O
	
In	O
analysis	O
section	O
,	O
we	O
study	O
how	O
EM	B-Method
feature	I-Method
helps	O
text	B-Task
understanding	I-Task
.	O
	
Now	O
we	O
have	O
premise	B-Method
representation	I-Method
and	O
hypothesis	B-Method
representation	I-Method
,	O
where	O
refers	O
to	O
the	O
sequence	O
length	O
of	O
premise	O
,	O
refers	O
to	O
the	O
sequence	O
length	O
of	O
hypothesis	O
and	O
means	O
the	O
dimension	O
of	O
both	O
representation	O
.	O
	
The	O
1	B-Method
-	I-Method
D	I-Method
convolutional	I-Method
neural	I-Method
network	I-Method
and	O
character	O
features	O
weights	O
share	O
the	O
same	O
set	O
of	O
parameters	O
between	O
premise	O
and	O
hypothesis	O
.	O
	
paragraph	O
:	O
Encoding	B-Method
Layer	I-Method
:	O
	
In	O
the	O
encoding	B-Method
layer	I-Method
,	O
the	O
premise	B-Method
representation	I-Method
and	O
the	O
hypothesis	B-Method
representation	I-Method
are	O
passed	O
through	O
a	O
two	B-Method
-	I-Method
layer	I-Method
highway	I-Method
network	I-Method
,	O
thus	O
having	O
and	O
for	O
new	O
premise	B-Method
representation	I-Method
and	O
new	O
hypothesis	B-Method
representation	I-Method
.	O
	
These	O
new	O
representation	O
are	O
then	O
passed	O
to	O
self	B-Method
-	I-Method
attention	I-Method
layer	I-Method
to	O
take	O
into	O
account	O
the	O
word	O
order	O
and	O
context	O
information	O
.	O
	
Take	O
premise	O
as	O
example	O
,	O
we	O
model	O
self	B-Task
-	I-Task
attention	I-Task
by	O
where	O
is	O
a	O
weighted	B-Method
summation	I-Method
of	O
.	O
	
We	O
choose	O
,	O
where	O
is	O
a	O
trainable	O
weight	O
,	O
is	O
element	B-Method
-	I-Method
wise	I-Method
multiplication	I-Method
,	O
[	O
;	O
]	O
is	O
vector	O
concatenation	O
across	O
row	O
,	O
and	O
the	O
implicit	B-Method
multiplication	I-Method
is	O
matrix	B-Method
multiplication	I-Method
.	O
	
Then	O
both	O
and	O
are	O
fed	O
into	O
a	O
semantic	B-Method
composite	I-Method
fuse	I-Method
gate	I-Method
(	O
fuse	B-Method
gate	I-Method
in	O
short	O
)	O
,	O
which	O
acts	O
as	O
a	O
skip	O
connection	O
.	O
	
The	O
fuse	B-Method
gate	I-Method
is	O
implemented	O
as	O
where	O
,	O
,	O
and	O
,	O
are	O
trainable	O
weights	O
,	O
is	O
sigmoid	O
nonlinear	O
operation	O
.	O
	
We	O
do	O
the	O
same	O
operation	O
on	O
hypothesis	B-Task
representation	I-Task
,	O
thus	O
having	O
.	O
	
The	O
weights	O
of	O
intra	O
-	O
attention	O
and	O
fuse	O
gate	O
for	O
premise	O
and	O
hypothesis	O
are	O
not	O
shared	O
,	O
but	O
the	O
difference	O
between	O
the	O
weights	O
of	O
are	O
penalized	O
.	O
	
The	O
penalization	B-Method
aims	O
to	O
ensure	O
the	O
parallel	O
structure	O
learns	O
the	O
similar	O
functionality	O
but	O
is	O
aware	O
of	O
the	O
subtle	O
semantic	O
difference	O
between	O
premise	O
and	O
hypothesis	O
.	O
	
paragraph	O
:	O
Interaction	O
Layer	O
:	O
	
The	O
interaction	B-Method
layer	I-Method
models	O
the	O
interaction	O
between	O
premise	B-Method
encoded	I-Method
representation	I-Method
and	O
hypothesis	B-Method
encoded	I-Method
representation	I-Method
as	O
follows	O
:	O
	
where	O
is	O
the	O
-	O
th	O
row	O
vector	O
of	O
,	O
and	O
is	O
the	O
-	O
th	O
row	O
vector	O
of	O
.	O
	
Though	O
there	O
are	O
many	O
implementations	O
of	O
interaction	O
,	O
we	O
find	O
very	O
useful	O
.	O
	
paragraph	O
:	O
Feature	B-Method
Extraction	I-Method
Layer	I-Method
:	O
	
We	O
adopt	O
DenseNet	B-Method
as	O
convolutional	B-Method
feature	I-Method
extractor	I-Method
in	O
DIIN	B-Method
.	O
	
Though	O
our	O
experiments	O
show	O
ResNet	B-Method
works	O
well	O
in	O
the	O
architecture	O
,	O
we	O
choose	O
DenseNet	B-Method
because	O
it	O
is	O
effective	O
in	O
saving	B-Task
parameters	I-Task
.	O
	
One	O
interesting	O
observation	O
with	O
ResNet	B-Method
is	O
that	O
if	O
we	O
remove	O
the	O
skip	O
connection	O
in	O
residual	O
structure	O
,	O
the	O
model	O
does	O
not	O
converge	O
at	O
all	O
.	O
	
We	O
found	O
batch	B-Method
normalization	I-Method
delays	O
convergence	B-Task
without	O
contributing	O
to	O
accuracy	B-Metric
,	O
therefore	O
we	O
does	O
not	O
use	O
it	O
in	O
our	O
case	O
.	O
	
A	O
ReLU	B-Method
activation	I-Method
function	I-Method
is	O
applied	O
after	O
all	O
convolution	B-Method
unless	O
otherwise	O
noted	O
.	O
	
Once	O
we	O
have	O
the	O
interaction	O
tensor	O
,	O
we	O
use	O
a	O
convolution	B-Method
with	I-Method
kernel	I-Method
to	O
scale	O
down	O
the	O
tensor	O
in	O
a	O
ratio	O
,	O
,	O
without	O
following	O
ReLU	B-Method
.	O
	
If	O
the	O
input	O
channel	O
is	O
then	O
the	O
output	O
channel	O
is	O
.	O
	
Then	O
the	O
generated	O
feature	O
map	O
is	O
feed	O
into	O
three	O
sets	O
of	O
Dense	O
block	O
and	O
transition	O
block	O
pair	O
.	O
	
The	O
DenseNet	B-Method
block	O
contains	O
n	O
layers	O
of	O
convolution	B-Method
layer	I-Method
with	O
growth	O
rate	O
of	O
g	O
.	O
	
The	O
transition	B-Method
layer	I-Method
has	O
a	O
convolution	B-Method
layer	I-Method
with	O
kernel	B-Method
for	O
scaling	B-Task
down	I-Task
purpose	I-Task
,	O
followed	O
by	O
a	O
max	B-Method
pooling	I-Method
layer	I-Method
with	O
stride	O
.	O
	
The	O
transition	B-Metric
scale	I-Metric
down	I-Metric
ratio	I-Metric
in	O
transition	O
layer	O
is	O
.	O
	
paragraph	O
:	O
Output	O
Layer	O
:	O
	
DIIN	B-Method
uses	O
a	O
linear	B-Method
layer	I-Method
to	O
classify	O
final	O
flattened	B-Method
feature	I-Method
representation	I-Method
to	O
three	O
classes	O
.	O
	
section	O
:	O
Experiments	O
	
In	O
this	O
section	O
,	O
we	O
present	O
the	O
evaluation	O
of	O
our	O
model	O
.	O
	
We	O
first	O
perform	O
quantitative	O
evaluation	O
,	O
comparing	O
our	O
model	O
with	O
other	O
competitive	B-Method
models	I-Method
.	O
	
We	O
then	O
conduct	O
some	O
qualitative	O
analyses	O
to	O
understand	O
how	O
DIIN	B-Method
achieve	O
the	O
high	O
level	O
understanding	O
through	O
interaction	O
.	O
	
subsection	O
:	O
Data	O
	
Here	O
we	O
introduce	O
three	O
datasets	O
we	O
evaluate	O
our	O
model	O
on	O
.	O
	
The	O
evaluation	B-Metric
metric	I-Metric
for	O
all	O
dataset	O
is	O
accuracy	B-Metric
.	O
	
paragraph	O
:	O
SNLI	B-Material
	
Stanford	B-Material
Natural	I-Material
Language	I-Material
Inference	I-Material
(	O
SNLI	B-Material
;	O
)	O
has	O
570k	O
human	O
annotated	O
sentence	O
pairs	O
.	O
	
The	O
premise	O
data	O
is	O
draw	O
from	O
the	O
captions	O
of	O
the	O
Flickr30k	O
corpus	O
,	O
and	O
the	O
hypothesis	O
data	O
is	O
manually	O
composed	O
.	O
	
The	O
labels	O
provided	O
in	O
are	O
“	O
entailment	O
”	O
,	O
“	O
neutral	O
’	O
,	O
“	O
contradiction	O
”	O
and	O
“	O
-	O
”	O
.	O
	
“	O
	
-	O
”	O
shows	O
that	O
annotators	O
can	O
not	O
reach	O
consensus	O
with	O
each	O
other	O
,	O
thus	O
removed	O
during	O
training	O
and	O
testing	O
as	O
in	O
other	O
works	O
.	O
	
We	O
use	O
the	O
same	O
data	O
split	O
as	O
in	O
.	O
	
paragraph	O
:	O
MultiNLI	O
	
Multi	O
-	O
Genre	O
NLI	B-Task
Corpus	O
(	O
MultiNLI	O
;	O
)	O
has	O
433k	O
sentence	O
pairs	O
,	O
whose	O
collection	O
process	O
and	O
task	O
detail	O
are	O
modeled	O
closely	O
to	O
SNLI	B-Material
.	O
	
The	O
premise	O
data	O
is	O
collected	O
from	O
maximally	O
broad	O
range	O
of	O
genre	O
of	O
American	O
English	O
such	O
as	O
written	O
non	O
-	O
fiction	O
genres	O
(	O
SLATE	O
,	O
OUP	O
,	O
GOVERNMENT	O
,	O
VERBATIM	O
,	O
TRAVEL	O
)	O
,	O
spoken	O
genres	O
(	O
TELEPHONE	O
,	O
FACE	O
-	O
TO	O
-	O
FACE	O
)	O
,	O
less	O
formal	O
written	O
genres	O
(	O
FICTION	O
,	O
LETTERS	O
)	O
and	O
a	O
specialized	O
one	O
for	O
9	O
/	O
11	O
.	O
	
Half	O
of	O
these	O
selected	O
genres	O
appear	O
in	O
training	O
set	O
while	O
the	O
rest	O
are	O
not	O
,	O
creating	O
in	O
-	O
domain	O
(	O
matched	O
)	O
and	O
cross	O
-	O
domain	O
(	O
mismatched	O
)	O
development	O
/	O
test	O
sets	O
.	O
	
We	O
use	O
the	O
same	O
data	O
split	O
as	O
provided	O
by	O
.	O
	
Since	O
test	O
set	O
labels	O
are	O
not	O
provided	O
,	O
the	O
test	O
performance	O
is	O
obtained	O
through	O
submission	O
on	O
Kaggle.com	O
.	O
	
Each	O
team	O
is	O
limited	O
to	O
two	O
submissions	O
per	O
day	O
.	O
	
paragraph	O
:	O
Quora	B-Material
question	I-Material
pair	I-Material
	
Quora	B-Material
question	I-Material
pair	I-Material
dataset	I-Material
contains	O
over	O
400k	O
real	O
world	O
question	O
pair	O
selected	O
from	O
Quora.com	O
.	O
	
A	O
binary	O
annotation	O
which	O
stands	O
for	O
match	O
(	O
duplicate	O
)	O
or	O
not	O
match	O
(	O
not	O
duplicate	O
)	O
is	O
provided	O
for	O
each	O
question	O
pair	O
.	O
	
In	O
our	O
case	O
,	O
duplicate	O
question	O
pair	O
can	O
be	O
interpreted	O
as	O
entailment	O
relation	O
and	O
not	O
duplicate	O
as	O
neutral	O
.	O
	
We	O
use	O
the	O
same	O
split	O
ratio	O
as	O
mentioned	O
in	O
.	O
	
subsection	O
:	O
Experiments	O
setting	O
	
We	O
implement	O
our	O
algorithm	O
with	O
Tensorflow	B-Method
framework	I-Method
.	O
	
An	O
Adadelta	B-Method
optimizer	I-Method
with	O
as	O
0.95	O
and	O
as	O
is	O
used	O
to	O
optimize	O
all	O
the	O
trainable	O
weights	O
.	O
	
The	O
initial	O
learning	B-Metric
rate	I-Metric
is	O
set	O
to	O
0.5	O
and	O
batch	O
size	O
to	O
70	O
.	O
	
When	O
the	O
model	O
does	O
not	O
improve	O
best	O
in	O
-	O
domain	O
performance	O
for	O
30	O
,	O
000	O
steps	O
,	O
an	O
SGD	B-Method
optimizer	I-Method
with	O
learning	B-Metric
rate	I-Metric
of	O
is	O
used	O
to	O
help	O
model	O
to	O
find	O
a	O
better	O
local	O
optimum	O
.	O
	
Dropout	B-Method
layers	I-Method
are	O
applied	O
before	O
all	O
linear	B-Method
layers	I-Method
and	O
after	O
word	B-Method
-	I-Method
embedding	I-Method
layer	I-Method
.	O
	
We	O
use	O
an	O
exponential	B-Method
decayed	I-Method
keep	I-Method
rate	I-Method
during	O
training	B-Method
,	O
where	O
the	O
initial	O
keep	B-Metric
rate	I-Metric
is	O
1.0	O
and	O
the	O
decay	B-Metric
rate	I-Metric
is	O
0.977	O
for	O
every	O
10	O
,	O
000	O
step	O
.	O
	
We	O
initialize	O
our	O
word	B-Method
embeddings	I-Method
with	O
pre	O
-	O
trained	O
300D	B-Method
GloVe	I-Method
840B	I-Method
vectors	I-Method
while	O
the	O
out	O
-	O
of	O
-	O
vocabulary	O
word	O
are	O
randomly	O
initialized	O
with	O
uniform	O
distribution	O
.	O
	
The	O
character	O
embeddings	O
are	O
randomly	O
initialized	O
with	O
100D.	O
	
We	O
crop	O
or	O
pad	O
each	O
token	O
to	O
have	O
16	O
characters	O
.	O
	
The	O
1D	B-Method
convolution	I-Method
kernel	I-Method
size	I-Method
for	O
character	B-Task
embedding	I-Task
is	O
5	O
.	O
	
All	O
weights	O
are	O
constraint	O
by	O
L2	B-Method
regularization	I-Method
,	O
and	O
the	O
L2	B-Method
regularization	I-Method
at	O
step	O
is	O
calculated	O
as	O
follows	O
:	O
where	O
determines	O
the	O
maximum	O
L2	O
regularization	O
ratio	O
,	O
and	O
determines	O
at	O
which	O
step	O
the	O
maximum	O
L2	O
regularization	O
ratio	O
would	O
be	O
applied	O
on	O
the	O
L2	B-Method
regularization	I-Method
.	O
	
We	O
choose	O
as	O
and	O
as	O
100	O
,	O
000	O
.	O
	
The	O
ratio	O
of	O
L2	O
penalty	O
between	O
the	O
difference	O
of	O
two	O
encoder	O
weights	O
is	O
set	O
to	O
.	O
	
For	O
a	O
dense	O
block	O
in	O
feature	B-Task
extraction	I-Task
layer	I-Task
,	O
the	O
number	O
of	O
layer	O
is	O
set	O
to	O
and	O
growth	O
rate	O
g	O
is	O
set	O
to	O
.	O
	
The	O
first	O
scale	O
down	O
ratio	O
in	O
feature	B-Method
extraction	I-Method
layer	I-Method
is	O
set	O
to	O
and	O
transitional	O
scale	O
down	O
ratio	O
is	O
set	O
to	O
.	O
	
The	O
sequence	O
length	O
is	O
set	O
as	O
a	O
hard	O
cutoff	O
on	O
all	O
experiments	O
:	O
48	O
for	O
MultiNLI	O
,	O
32	O
for	O
SNLI	B-Material
and	O
24	O
for	O
Quora	B-Material
Question	I-Material
Pair	I-Material
Dataset	I-Material
.	O
	
During	O
the	O
experiments	O
on	O
MultiNLI	O
,	O
we	O
use	O
15	O
%	O
of	O
data	O
from	O
SNLI	B-Material
as	O
in	O
.	O
	
We	O
select	O
the	O
parameter	O
by	O
the	O
best	O
run	O
of	O
development	B-Metric
accuracy	I-Metric
.	O
	
Our	O
ensembling	B-Method
approach	I-Method
considers	O
the	O
majority	O
vote	O
of	O
the	O
predictions	O
given	O
by	O
multiple	O
runs	O
of	O
the	O
same	O
model	O
under	O
different	O
random	B-Method
parameter	I-Method
initialization	I-Method
.	O
	
subsection	O
:	O
Experiment	O
on	O
MultiNLI	O
	
We	O
compare	O
our	O
result	O
with	O
all	O
other	O
published	O
systems	O
in	O
Table	O
[	O
reference	O
]	O
.	O
	
Besides	O
ESIM	B-Method
,	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
model	O
on	O
SNLI	B-Material
,	O
all	O
other	O
models	O
appear	O
at	O
RepEval	O
2017	O
workshop	O
.	O
	
RepEval	B-Method
2017	O
workshop	O
requires	O
all	O
submitted	O
model	O
to	O
be	O
sentence	B-Method
encoding	I-Method
-	I-Method
based	I-Method
model	I-Method
therefore	O
alignment	O
between	O
sentences	O
and	O
memory	B-Method
module	I-Method
are	O
not	O
eligible	O
for	O
competition	O
.	O
	
All	O
models	O
except	O
ours	O
share	O
one	O
common	O
feature	O
that	O
they	O
use	O
LSTM	B-Method
as	O
a	O
essential	O
building	O
block	O
as	O
encoder	B-Method
.	O
	
Our	O
approach	O
,	O
without	O
using	O
any	O
recurrent	B-Method
structure	I-Method
,	O
achieves	O
the	O
new	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
performance	O
of	O
80.0	O
%	O
,	O
exceeding	O
current	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
performance	O
by	O
more	O
than	O
5	O
%	O
.	O
	
Unlike	O
the	O
observation	O
from	O
,	O
we	O
find	O
the	O
out	B-Metric
-	I-Metric
of	I-Metric
-	I-Metric
domain	I-Metric
test	I-Metric
performance	I-Metric
is	O
consistently	O
lower	O
than	O
in	O
-	O
domain	O
test	O
performance	O
.	O
	
Selecting	O
parameters	O
from	O
the	O
best	O
in	B-Metric
-	I-Metric
domain	I-Metric
development	I-Metric
accuracy	I-Metric
partially	O
contributes	O
to	O
this	O
result	O
.	O
	
subsection	O
:	O
Experiment	O
on	O
SNLI	B-Material
	
In	O
Table	O
[	O
reference	O
]	O
,	O
we	O
compare	O
our	O
model	O
to	O
other	O
model	O
performance	O
on	O
SNLI	B-Material
.	O
	
Experiments	O
(	O
2	O
-	O
7	O
)	O
are	O
sentence	B-Method
encoding	I-Method
based	I-Method
model	I-Method
.	O
	
provides	O
a	O
BiLSTM	B-Method
baseline	I-Method
.	O
	
adopts	O
two	B-Method
layer	I-Method
GRU	I-Method
encoder	I-Method
with	O
pre	O
-	O
trained	O
”	O
skip	O
-	O
thoughts	O
”	O
vectors	O
.	O
	
To	O
capture	O
sentence	O
-	O
level	O
semantics	O
,	O
use	O
tree	B-Method
-	I-Method
based	I-Method
CNN	I-Method
and	O
propose	O
a	O
stack	B-Method
-	I-Method
augmented	I-Method
parser	I-Method
-	I-Method
interpreter	I-Method
neural	I-Method
network	I-Method
(	O
SPINN	B-Method
)	O
which	O
incorporates	O
parsing	O
information	O
in	O
a	O
sequential	O
manner	O
.	O
uses	O
intra	O
-	O
attention	O
on	O
top	O
of	O
BiLSTM	B-Method
to	O
generate	O
sentence	B-Task
representation	I-Task
,	O
and	O
proposes	O
an	O
memory	B-Method
augmented	I-Method
neural	I-Method
network	I-Method
to	O
encode	O
the	O
sentence	O
.	O
	
The	O
next	O
group	O
of	O
model	O
,	O
experiments	O
(	O
8	O
-	O
18	O
)	O
,	O
uses	O
cross	O
sentence	O
feature	O
.	O
	
aligns	O
each	O
sentence	O
word	O
-	O
by	O
-	O
word	O
with	O
attention	O
on	O
top	O
of	O
LSTMs	B-Method
.	O
	
enforces	O
cross	B-Task
sentence	I-Task
attention	I-Task
word	I-Task
-	I-Task
by	I-Task
-	I-Task
word	I-Task
matching	I-Task
with	O
the	O
proprosed	B-Method
mLSTM	I-Method
model	I-Method
.	O
	
proposes	O
long	B-Method
short	I-Method
-	I-Method
term	I-Method
memory	I-Method
-	I-Method
network	I-Method
(	O
LSTMN	B-Method
)	O
with	O
deep	B-Method
attention	I-Method
fusion	I-Method
that	O
links	O
the	O
current	O
word	O
to	O
previous	O
word	O
stored	O
in	O
memory	O
.	O
	
decomposes	O
the	O
task	O
into	O
sub	O
-	O
problems	O
and	O
conquer	O
them	O
respectively	O
.	O
	
proposes	O
neural	B-Method
tree	I-Method
indexer	I-Method
,	O
a	O
full	B-Method
n	I-Method
-	I-Method
ary	I-Method
tree	I-Method
whose	O
subtrees	O
can	O
be	O
overlapped	O
.	O
	
Re	B-Method
-	I-Method
read	I-Method
LSTM	I-Method
proposed	O
by	O
considers	O
the	O
attention	O
vector	O
of	O
one	O
sentence	O
as	O
the	O
inner	O
-	O
state	O
of	O
LSTM	B-Method
for	O
another	O
sentence	O
.	O
	
propose	O
a	O
sequential	B-Method
model	I-Method
that	O
infers	O
locally	O
,	O
and	O
a	O
ensemble	B-Method
with	I-Method
tree	I-Method
-	I-Method
like	I-Method
inference	I-Method
module	I-Method
that	O
further	O
improves	O
performance	O
.	O
	
We	O
show	O
our	O
model	O
,	O
DIIN	B-Method
,	O
achieves	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
performance	O
on	O
the	O
competitive	O
leaderboard	O
.	O
	
subsection	O
:	O
Experiment	O
on	O
Quora	B-Material
Question	I-Material
Pair	I-Material
dataset	I-Material
	
In	O
this	O
subsection	O
,	O
we	O
evaluate	O
the	O
effectiveness	O
of	O
our	O
model	O
for	O
paraphrase	B-Task
identification	I-Task
as	O
natural	B-Task
language	I-Task
inference	I-Task
task	O
.	O
	
Other	O
than	O
our	O
baselines	O
,	O
we	O
compare	O
with	O
and	O
.	O
	
BiMPM	B-Method
models	O
different	O
perspective	O
of	O
matching	O
between	O
sentence	O
pair	O
on	O
both	O
direction	O
,	O
then	O
aggregates	O
matching	O
vector	O
with	O
LSTM	B-Method
.	O
	
DecAtt⁢word	O
and	O
DecAtt⁢char	O
uses	O
automatically	O
collected	O
in	O
-	O
domain	O
paraphrase	O
data	O
to	O
noisy	O
pretrain	B-Task
-	I-Task
gram	I-Task
word	I-Task
embedding	I-Task
and	O
-	B-Task
gram	I-Task
subword	I-Task
embedding	I-Task
correspondingly	O
on	O
decomposable	B-Method
attention	I-Method
model	I-Method
proposed	O
by	O
.	O
	
In	O
Table	O
[	O
reference	O
]	O
,	O
our	O
experiment	O
shows	O
DIIN	B-Method
has	O
better	O
performance	O
than	O
all	O
other	O
models	O
and	O
an	O
ensemble	B-Metric
score	I-Metric
is	O
higher	O
than	O
the	O
former	O
best	O
result	O
for	O
more	O
than	O
1	O
percent	O
.	O
	
subsection	O
:	O
Analysis	O
	
paragraph	O
:	O
Ablation	B-Task
Study	I-Task
	
We	O
conduct	O
a	O
ablation	O
study	O
on	O
our	O
base	O
model	O
to	O
examine	O
the	O
effectiveness	O
of	O
each	O
component	O
.	O
	
We	O
study	O
our	O
model	O
on	O
MultiNLI	O
dataset	O
and	O
we	O
use	O
Matched	B-Metric
validation	I-Metric
score	I-Metric
as	O
the	O
standard	O
for	O
model	B-Task
selection	I-Task
.	O
	
The	O
result	O
is	O
shown	O
in	O
Table	O
[	O
reference	O
]	O
.	O
	
We	O
studies	O
how	O
EM	O
feature	O
contributes	O
to	O
the	O
system	O
.	O
	
After	O
removing	O
the	O
exact	O
match	O
binary	O
feature	O
,	O
we	O
find	O
the	O
performance	O
degrade	O
to	O
78.2	O
on	O
matched	B-Metric
score	I-Metric
on	O
development	O
set	O
and	O
78.0	O
on	O
mismatched	B-Metric
score	I-Metric
.	O
	
As	O
observed	O
in	O
reading	B-Task
comprehension	I-Task
task	I-Task
,	O
the	O
simple	O
exact	O
match	O
feature	O
does	O
help	O
the	O
model	O
to	O
better	O
understand	O
the	O
sentences	O
.	O
	
In	O
the	O
experiment	O
3	O
,	O
we	O
remove	O
the	O
convolutional	B-Method
feature	I-Method
extractor	I-Method
and	O
then	O
model	O
is	O
structured	O
as	O
a	O
sentence	B-Method
-	I-Method
encoding	I-Method
based	I-Method
model	I-Method
.	O
	
The	O
sentence	B-Method
representation	I-Method
matrix	I-Method
is	O
max	O
-	O
pooled	O
over	O
time	O
to	O
obtain	O
a	O
feature	O
vector	O
.	O
	
Once	O
we	O
have	O
the	O
feature	O
vector	O
for	O
premise	O
and	O
for	O
hypothesis	O
,	O
we	O
use	O
as	O
final	O
feature	O
vector	O
to	O
classify	O
the	O
relationship	O
.	O
	
We	O
obtain	O
73.2	O
for	O
matched	B-Metric
score	I-Metric
and	O
73.6	O
on	O
mismatched	O
data	O
.	O
	
The	O
result	O
is	O
competitive	O
among	O
other	O
sentence	B-Method
-	I-Method
encoding	I-Method
based	I-Method
model	I-Method
.	O
	
We	O
further	O
study	O
how	O
encoding	B-Method
layer	I-Method
contribute	O
in	O
enriching	O
the	O
feature	O
space	O
in	O
interaction	O
tensor	O
.	O
	
If	O
we	O
remove	O
encoding	O
layer	O
completely	O
,	O
then	O
we	O
’ll	O
	
obtain	O
a	O
73.5	O
for	O
matched	B-Metric
score	I-Metric
and	O
73.2	O
for	O
mismatched	O
score	O
.	O
	
The	O
result	O
demonstrate	O
the	O
feature	B-Method
extraction	I-Method
layer	I-Method
have	O
powerful	O
capability	O
to	O
capture	O
the	O
semantic	O
feature	O
.	O
	
In	O
experiment	O
5	O
,	O
we	O
remove	O
both	O
self	O
-	O
attention	O
and	O
fuse	O
gate	O
,	O
thus	O
retaining	O
only	O
highway	B-Method
network	I-Method
.	O
	
The	O
result	O
improves	O
to	O
77.7	O
and	O
77.3	O
respectively	O
on	O
matched	O
and	O
mismatched	O
development	O
set	O
.	O
	
However	O
,	O
in	O
experiment	O
6	O
,	O
when	O
we	O
only	O
remove	O
fuse	O
gate	O
,	O
to	O
our	O
surprise	O
,	O
the	O
performance	O
degrade	O
to	O
73.5	O
for	O
matched	B-Metric
score	I-Metric
and	O
73.8	O
for	O
mismatched	O
.	O
	
On	O
the	O
other	O
hand	O
,	O
if	O
we	O
use	O
the	O
addition	O
of	O
the	O
representation	O
after	O
highway	B-Method
network	I-Method
and	O
the	O
representation	O
after	O
self	O
-	O
attention	O
as	O
skip	O
connection	O
as	O
in	O
experiment	O
7	O
,	O
the	O
performance	O
increase	O
to	O
77.3	O
and	O
76.3	O
.	O
	
The	O
comparison	O
indicates	O
self	B-Method
-	I-Method
attention	I-Method
layer	I-Method
makes	O
the	O
training	O
harder	O
to	O
converge	O
while	O
a	O
skip	O
connection	O
could	O
ease	O
the	O
gradient	O
flow	O
for	O
both	O
highway	B-Method
layer	I-Method
and	O
self	B-Method
-	I-Method
attention	I-Method
layer	I-Method
.	O
	
By	O
comparing	O
the	O
base	O
model	O
and	O
the	O
model	O
the	O
in	O
experiment	O
6	O
,	O
we	O
show	O
that	O
the	O
fuse	B-Method
gate	I-Method
not	O
only	O
well	O
serves	O
as	O
a	O
skip	O
connection	O
,	O
but	O
also	O
makes	O
good	O
decision	O
upon	O
which	O
information	O
the	O
fuse	O
for	O
both	O
representation	O
.	O
	
To	O
show	O
that	O
dense	O
interaction	O
tensor	O
contains	O
more	O
semantic	O
information	O
,	O
we	O
replace	O
the	O
dense	O
interaction	O
tensor	O
with	O
dot	O
product	O
similarity	O
matrix	O
between	O
the	O
encoded	B-Method
representation	I-Method
of	O
premise	O
and	O
hypothesis	O
.	O
	
The	O
result	O
shows	O
that	O
the	O
dot	B-Method
product	I-Method
similarity	I-Method
matrix	I-Method
has	O
an	O
inferior	O
capacity	O
of	O
semantic	O
information	O
.	O
	
Another	O
dimensionality	O
study	O
is	O
provided	O
in	O
supplementary	O
material	O
.	O
	
In	O
experiment	O
9	O
,	O
we	O
share	O
the	O
encoding	O
layer	O
weight	O
,	O
and	O
the	O
result	O
decrease	O
from	O
the	O
baseline	O
.	O
	
The	O
result	O
shows	O
that	O
the	O
two	O
set	O
of	O
encoding	O
weights	O
learn	O
the	O
subtle	O
difference	O
between	O
premise	O
and	O
hypothesis	O
.	O
	
paragraph	O
:	O
Error	B-Method
analysis	I-Method
	
To	O
analyze	O
the	O
model	O
prediction	B-Task
,	O
we	O
use	O
annotated	O
subset	O
of	O
development	O
set	O
provided	O
by	O
that	O
consists	O
of	O
1	O
,	O
000	O
examples	O
each	O
tagged	O
with	O
zero	O
or	O
more	O
following	O
tags	O
:	O
CONDITIONAL	O
:	O
whether	O
the	O
sentence	O
contains	O
a	O
conditional	O
.	O
	
WORD	O
OVERLAP	O
:	O
whether	O
both	O
sentences	O
share	O
more	O
than	O
70	O
%	O
of	O
their	O
tokens	O
.	O
	
NEGATION	O
:	O
whether	O
a	O
negation	O
shows	O
up	O
in	O
either	O
sentence	O
.	O
	
ANTO	B-Method
:	O
whether	O
two	O
sentences	O
contain	O
antonym	O
pair	O
.	O
	
LONG	O
SENTENCE	O
:	O
	
whether	O
premise	O
or	O
hypothesis	O
is	O
longer	O
than	O
30	O
or	O
16	O
tokens	O
respectively	O
.	O
	
TENSE	O
DIFFERENCE	O
:	O
whether	O
any	O
verb	O
in	O
two	O
sentences	O
uses	O
different	O
tense	O
.	O
	
ACTIVE	O
	
/	O
PASSIVE	O
:	O
whether	O
there	O
is	O
an	O
active	O
-	O
to	O
-	O
passive	O
(	O
or	O
vice	O
versa	O
)	O
transformation	O
from	O
the	O
premise	O
to	O
the	O
hypothesis	O
.	O
	
PARAPHRASE	B-Method
:	O
	
whether	O
the	O
two	O
sentences	O
are	O
close	O
paraphrases	B-Task
QUANTITY	I-Task
/	I-Task
TIME	I-Task
REASONING	I-Task
:	O
whether	O
understanding	O
the	O
pair	O
requires	O
quantity	O
or	O
time	O
reasoning	O
.	O
	
COREF	B-Method
:	O
	
Whether	O
the	O
hypothesis	O
contains	O
a	O
pronoun	O
or	O
referring	O
expression	O
that	O
needs	O
to	O
be	O
resolved	O
using	O
the	O
premise	O
.	O
	
QUANTIFIER	B-Method
:	O
	
Whether	O
either	O
sentence	O
contains	O
one	O
of	O
the	O
following	O
quantifier	O
:	O
much	O
,	O
enough	O
,	O
more	O
,	O
most	O
,	O
less	O
,	O
least	O
,	O
no	O
,	O
none	O
,	O
some	O
,	O
any	O
,	O
many	O
,	O
few	O
,	O
several	O
,	O
almost	O
,	O
nearly	O
.	O
	
MODAL	B-Method
:	O
	
Whether	O
one	O
of	O
the	O
following	O
modal	O
verbs	O
appears	O
in	O
either	O
sentence	O
:	O
can	O
,	O
could	O
,	O
may	O
,	O
might	O
,	O
must	O
,	O
will	O
,	O
would	O
,	O
should	O
.	O
	
BELIEF	O
:	O
	
Whether	O
one	O
of	O
the	O
following	O
belief	O
verbs	O
appear	O
in	O
either	O
sentence	O
:	O
know	O
,	O
believe	O
,	O
understand	O
,	O
doubt	O
,	O
think	O
,	O
	
suppose	O
,	O
recognize	O
,	O
forget	O
,	O
remember	O
,	O
imagine	O
,	O
mean	O
,	O
agree	O
,	O
disagree	O
,	O
deny	O
,	O
promise	O
.	O
	
For	O
more	O
detailed	O
descriptions	O
,	O
please	O
resort	O
to	O
.	O
	
The	O
result	O
is	O
shown	O
in	O
Table	O
[	O
reference	O
]	O
.	O
	
We	O
find	O
DIIN	B-Method
is	O
consistently	O
better	O
on	O
sentence	O
pair	O
with	O
WORD	O
OVERLAP	O
,	O
ANTO	B-Method
,	O
LONG	O
SENTENCE	O
,	O
PARAPHRASE	O
and	O
BELIEF	O
tags	O
by	O
a	O
large	O
margin	O
.	O
	
During	O
investigation	O
,	O
we	O
hypothesize	O
exact	O
match	O
feature	O
helps	O
the	O
model	O
to	O
better	O
understand	O
paraphrase	O
,	O
therefore	O
we	O
study	O
the	O
result	O
from	O
second	O
ablation	B-Task
ablation	I-Task
study	I-Task
where	O
exact	O
match	O
feature	O
is	O
not	O
used	O
.	O
	
Surprisingly	O
,	O
the	O
model	O
without	O
exact	B-Method
model	I-Method
feature	I-Method
does	O
not	O
work	O
worse	O
on	O
PARAPHRASE	B-Task
,	O
instead	O
,	O
the	O
accuracy	B-Metric
on	O
ANTO	B-Method
drops	O
about	O
10	O
%	O
.	O
	
DIIN	B-Method
is	O
also	O
work	O
well	O
on	O
LONG	O
SENTENCE	O
,	O
partially	O
because	O
the	O
receptive	O
field	O
is	O
large	O
enough	O
to	O
cover	O
all	O
tokens	O
.	O
	
paragraph	O
:	O
Visualization	B-Task
	
We	O
also	O
visualize	O
the	O
hidden	O
representation	O
from	O
interaction	O
tensor	O
and	O
the	O
feature	O
map	O
from	O
first	O
dense	O
block	O
in	O
Figure	O
[	O
reference	O
]	O
.	O
	
We	O
pick	O
a	O
sentence	O
pair	O
whose	O
premise	O
is	O
“	O
South	O
Carolina	O
has	O
no	O
referendum	O
right	O
,	O
so	O
the	O
Supreme	O
Court	O
canceled	O
the	O
vote	O
and	O
upheld	O
the	O
ban	O
.	O
”	O
and	O
hypothesis	O
is	O
“	O
South	O
Carolina	O
has	O
a	O
referendum	O
right	O
,	O
so	O
the	O
Supreme	O
Court	O
was	O
powerless	O
over	O
the	O
state	O
.	O
”	O
.	O
	
The	O
upper	O
row	O
of	O
figures	O
are	O
sampled	O
from	O
hidden	B-Method
representation	I-Method
of	I-Method
interaction	I-Method
tensor	I-Method
.	O
	
We	O
observe	O
the	O
values	O
of	O
neurons	O
are	O
highly	O
correlated	O
row	O
-	O
wise	O
and	O
column	O
-	O
wise	O
in	O
the	O
interaction	O
tensor	O
and	O
different	O
channel	O
of	O
hidden	B-Method
representation	I-Method
shows	O
different	O
aspect	O
of	O
interaction	O
.	O
	
Though	O
in	O
certain	O
channel	O
same	O
words	O
,	O
“	O
referendum	O
”	O
,	O
or	O
phrases	O
,	O
“	O
supreme	O
court	O
”	O
,	O
cause	O
activation	O
,	O
different	O
word	O
or	O
phrase	O
pair	O
,	O
such	O
as	O
“	O
ban	O
”	O
and	O
“	O
powerless	O
over	O
”	O
,	O
also	O
cause	O
activation	O
in	O
other	O
activation	O
.	O
	
It	O
shows	O
the	O
model	O
’s	O
strong	O
capacity	O
of	O
understanding	O
text	O
in	O
different	O
perspective	O
.	O
	
The	O
lower	O
row	O
of	O
Figure	O
[	O
reference	O
]	O
shows	O
the	O
feature	O
map	O
from	O
first	O
dense	O
block	O
.	O
	
After	O
being	O
convolved	O
from	O
the	O
interaction	O
tensor	O
and	O
previous	O
feature	B-Method
map	I-Method
,	O
new	O
feature	B-Method
maps	I-Method
shows	O
activation	O
in	O
different	O
position	O
,	O
demonstrating	O
different	O
semantic	O
features	O
are	O
found	O
.	O
	
The	O
first	O
figure	O
in	O
the	O
lower	O
row	O
has	O
similar	O
pattern	O
as	O
normal	O
attention	O
weight	O
whereas	O
others	O
has	O
no	O
obvious	O
pattern	O
.	O
	
Different	O
channels	O
of	O
feature	O
maps	O
indicate	O
different	O
kinds	O
of	O
semantic	O
feature	O
.	O
	
section	O
:	O
Conclusion	O
and	O
Future	O
Work	O
	
We	O
show	O
the	O
interaction	O
tensor	O
(	O
or	O
attention	O
weight	O
)	O
contains	O
semantic	O
information	O
to	O
understand	O
the	O
natural	O
language	O
.	O
	
We	O
introduce	O
Interactive	B-Method
Inference	I-Method
Network	I-Method
,	O
a	O
novel	O
class	O
of	O
architecture	O
that	O
allows	O
the	O
model	O
to	O
solve	O
NLI	B-Task
or	O
NLI	B-Task
alike	O
tasks	O
via	O
extracting	O
semantic	O
feature	O
from	O
interaction	O
tensor	O
end	O
-	O
to	O
-	O
end	O
.	O
	
One	O
instance	O
of	O
such	O
architecture	O
,	O
Densely	B-Method
Interactive	I-Method
Inference	I-Method
Network	I-Method
(	O
DIIN	B-Method
)	O
,	O
achieves	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
performance	O
on	O
multiple	O
datasets	O
.	O
	
By	O
ablating	O
each	O
component	O
in	O
DIIN	B-Method
and	O
changing	O
the	O
dimensionality	O
,	O
we	O
show	O
the	O
effectiveness	O
of	O
each	O
component	O
in	O
DIIN	B-Method
.	O
	
Though	O
we	O
have	O
the	O
initial	O
exploration	O
of	O
natural	B-Task
language	I-Task
inference	I-Task
in	O
interaction	O
space	O
,	O
the	O
full	O
potential	O
is	O
not	O
yet	O
clear	O
.	O
	
We	O
will	O
keep	O
exploring	O
the	O
potential	O
of	O
interaction	O
space	O
.	O
	
Incorporating	O
common	O
-	O
sense	O
knowledge	O
from	O
external	O
resources	O
such	O
as	O
knowledge	O
base	O
to	O
leverage	O
the	O
capacity	O
of	O
the	O
mode	O
is	O
another	O
research	O
goal	O
of	O
ours	O
.	O
	
subsubsection	O
:	O
Acknowledgments	O
	
We	O
thank	O
Yuchen	O
Lu	O
,	O
Chang	O
Huang	O
and	O
Kai	O
Yu	O
for	O
their	O
sincere	O
and	O
insightful	O
advice	O
.	O
	
bibliography	O
:	O
References	O
	
appendix	O
:	O
Supplementary	O
Material	O
	
paragraph	O
:	O
Dimensionality	O
and	O
Parameter	O
number	O
study	O
	
To	O
study	O
the	O
influence	O
of	O
the	O
model	O
dimension	O
which	O
is	O
also	O
the	O
channel	O
number	O
of	O
interaction	O
tensor	O
,	O
we	O
design	O
experiments	O
to	O
find	O
out	O
whether	O
dimension	O
has	O
influence	O
on	O
performance	O
.	O
	
We	O
also	O
present	O
the	O
parameter	O
count	O
of	O
these	O
models	O
.	O
	
The	O
dimensionality	O
is	O
448	O
where	O
300	O
comes	O
from	O
word	O
embedding	O
,	O
100	O
comes	O
from	O
char	O
feature	O
,	O
47	O
comes	O
from	O
Part	B-Method
of	I-Method
speech	I-Method
tagging	I-Method
and	O
1	O
comes	O
from	O
the	O
binary	O
exact	O
match	O
feature	O
.	O
	
Since	O
Highway	B-Method
network	I-Method
sets	O
the	O
output	O
dimensionality	O
default	O
as	O
that	O
in	O
input	O
,	O
we	O
design	O
a	O
variant	O
to	O
highway	B-Method
network	I-Method
so	O
that	O
different	O
output	O
size	O
could	O
be	O
obtained	O
.	O
	
The	O
variant	O
of	O
highway	B-Method
layer	I-Method
is	O
designed	O
as	O
follows	O
:	O
where	O
is	O
the	O
-	O
th	O
vector	O
of	O
input	O
matrix	O
,	O
is	O
the	O
-	O
th	O
vector	O
of	O
output	O
matrix	O
,	O
,	O
,	O
and	O
,	O
,	O
are	O
trainable	O
weights	O
.	O
	
The	O
result	O
shows	O
that	O
higher	O
dimension	O
number	O
have	O
better	O
performance	O
when	O
the	O
dimension	O
number	O
is	O
lower	O
certain	O
threshold	O
,	O
however	O
,	O
when	O
the	O
number	O
of	O
dimensionality	O
is	O
greater	O
than	O
the	O
threshold	O
,	O
larger	O
number	O
of	O
parameter	O
and	O
higher	O
dimensionality	O
does	O
n’t	O
contribute	O
to	O
performance	O
.	O
	
In	O
the	O
case	O
of	O
SNLI	B-Material
,	O
due	O
to	O
its	O
simplicity	O
in	O
language	O
pattern	O
,	O
250D	O
would	O
be	O
suffice	O
to	O
obtain	O
a	O
good	O
performance	O
.	O
	
On	O
the	O
other	O
hand	O
,	O
it	O
requires	O
350D	B-Method
to	O
achieve	O
a	O
competitive	O
performance	O
on	O
MultiNLI	O
.	O
	
We	O
fail	O
to	O
reproduce	O
our	O
best	O
performance	O
with	O
the	O
new	O
structure	O
on	O
MultiNLI	O
.	O
	
It	O
shows	O
that	O
the	O
additional	O
layer	O
on	O
highway	B-Method
network	I-Method
does	O
n’t	O
helps	O
convergence	O
.	O
	
document	O
:	O
Fraternal	O
Dropout	O
	
Recurrent	B-Method
neural	I-Method
networks	I-Method
(	O
RNNs	B-Method
)	O
form	O
an	O
important	O
class	O
of	O
architectures	O
among	O
neural	B-Method
networks	I-Method
useful	O
for	O
language	B-Task
modeling	I-Task
and	O
sequential	B-Task
prediction	I-Task
.	O
	
However	O
,	O
optimizing	B-Task
RNNs	I-Task
is	O
known	O
to	O
be	O
harder	O
compared	O
to	O
feed	B-Method
-	I-Method
forward	I-Method
neural	I-Method
networks	I-Method
.	O
	
A	O
number	O
of	O
techniques	O
have	O
been	O
proposed	O
in	O
literature	O
to	O
address	O
this	O
problem	O
.	O
	
In	O
this	O
paper	O
we	O
propose	O
a	O
simple	O
technique	O
called	O
fraternal	B-Method
dropout	I-Method
that	O
takes	O
advantage	O
of	O
dropout	B-Method
to	O
achieve	O
this	O
goal	O
.	O
	
Specifically	O
,	O
we	O
propose	O
to	O
train	O
two	O
identical	O
copies	O
of	O
an	O
RNN	B-Method
(	O
that	O
share	O
parameters	O
)	O
with	O
different	O
dropout	O
masks	O
while	O
minimizing	O
the	O
difference	O
between	O
their	O
(	O
pre	O
-	O
softmax	O
)	O
predictions	O
.	O
	
In	O
this	O
way	O
our	O
regularization	B-Method
encourages	O
the	O
representations	O
of	O
RNNs	B-Method
to	O
be	O
invariant	O
to	O
dropout	O
mask	O
,	O
thus	O
being	O
robust	O
.	O
	
We	O
show	O
that	O
our	O
regularization	B-Method
term	I-Method
is	O
upper	O
bounded	O
by	O
the	O
expectation	B-Method
-	I-Method
linear	I-Method
dropout	I-Method
objective	I-Method
which	O
has	O
been	O
shown	O
to	O
address	O
the	O
gap	O
due	O
to	O
the	O
difference	O
between	O
the	O
train	B-Method
and	I-Method
inference	I-Method
phases	I-Method
of	I-Method
dropout	I-Method
.	O
	
We	O
evaluate	O
our	O
model	O
and	O
achieve	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
results	O
in	O
sequence	B-Task
modeling	I-Task
tasks	I-Task
on	O
two	O
benchmark	O
datasets	O
–	O
Penn	B-Material
Treebank	I-Material
and	O
	
Wikitext	B-Material
-	I-Material
2	I-Material
.	O
	
We	O
also	O
show	O
that	O
our	O
approach	O
leads	O
to	O
performance	O
improvement	O
by	O
a	O
significant	O
margin	O
in	O
image	B-Task
captioning	I-Task
(	O
Microsoft	O
COCO	O
)	O
and	O
semi	B-Task
-	I-Task
supervised	I-Task
(	I-Task
CIFAR	I-Task
-	I-Task
10	I-Task
)	I-Task
tasks	I-Task
.	O
	
section	O
:	O
Introduction	O
	
Recurrent	B-Method
neural	I-Method
networks	I-Method
(	O
RNNs	B-Method
)	O
like	O
long	B-Method
short	I-Method
-	I-Method
term	I-Method
memory	I-Method
(	I-Method
LSTM	I-Method
;	I-Method
)	I-Method
networks	I-Method
and	O
gated	B-Method
recurrent	I-Method
unit	I-Method
(	O
GRU	B-Method
;	O
)	O
are	O
popular	O
architectures	O
for	O
sequence	B-Task
modeling	I-Task
tasks	I-Task
like	O
language	B-Task
generation	I-Task
,	O
translation	B-Task
,	O
speech	B-Task
synthesis	I-Task
,	O
and	O
machine	B-Task
comprehension	I-Task
.	O
	
However	O
,	O
they	O
are	O
harder	O
to	O
optimize	O
compared	O
to	O
feed	B-Method
-	I-Method
forward	I-Method
networks	I-Method
due	O
to	O
challenges	O
like	O
variable	O
length	O
input	O
sequences	O
,	O
repeated	O
application	O
of	O
the	O
same	O
transition	O
operator	O
at	O
each	O
time	O
step	O
,	O
and	O
largely	O
-	O
dense	O
embedding	O
matrix	O
that	O
depends	O
on	O
the	O
vocabulary	O
size	O
.	O
	
Due	O
to	O
these	O
optimization	B-Task
challenges	I-Task
in	O
RNNs	B-Task
,	O
the	O
application	O
of	O
batch	B-Method
normalization	I-Method
and	O
its	O
variants	O
(	O
layer	B-Method
normalization	I-Method
,	O
recurrent	B-Method
batch	I-Method
normalization	I-Method
,	O
recurrent	B-Method
normalization	I-Method
propagation	I-Method
)	O
have	O
not	O
been	O
as	O
successful	O
as	O
their	O
counterparts	O
in	O
feed	B-Method
-	I-Method
forward	I-Method
networks	I-Method
,	O
although	O
they	O
do	O
considerably	O
provide	O
performance	O
gains	O
.	O
	
Similarly	O
,	O
naive	B-Method
application	I-Method
of	I-Method
dropout	I-Method
has	O
been	O
shown	O
to	O
be	O
ineffective	O
in	O
RNNs	B-Task
.	O
	
Therefore	O
,	O
regularization	B-Method
techniques	I-Method
for	O
RNNs	B-Method
is	O
an	O
active	O
area	O
of	O
research	O
.	O
	
To	O
address	O
these	O
challenges	O
,	O
proposed	O
to	O
apply	O
dropout	B-Method
only	I-Method
to	O
the	O
non	O
-	O
recurrent	O
connections	O
in	O
multi	B-Method
-	I-Method
layer	I-Method
RNNs	I-Method
.	O
	
Variational	B-Method
dropout	I-Method
(	O
)	O
uses	O
the	O
same	O
dropout	O
mask	O
throughout	O
a	O
sequence	O
during	O
training	O
.	O
	
DropConnect	B-Method
applies	O
the	O
dropout	B-Method
operation	I-Method
on	O
the	O
weight	O
matrices	O
.	O
	
Zoneout	B-Method
(	I-Method
)	O
,	O
in	O
a	O
similar	O
spirit	O
with	O
dropout	B-Method
,	O
randomly	O
chooses	O
to	O
use	O
the	O
previous	O
time	O
step	O
hidden	O
state	O
instead	O
of	O
using	O
the	O
current	O
one	O
.	O
	
Similarly	O
as	O
a	O
substitute	O
for	O
batch	B-Method
normalization	I-Method
,	O
layer	B-Method
normalization	I-Method
normalizes	O
the	O
hidden	O
units	O
within	O
each	O
sample	O
to	O
have	O
zero	O
mean	O
and	O
unit	O
standard	O
deviation	O
.	O
	
Recurrent	B-Method
batch	I-Method
normalization	I-Method
applies	O
batch	B-Method
normalization	I-Method
but	O
with	O
unshared	O
mini	O
-	O
batch	O
statistics	O
for	O
each	O
time	O
step	O
.	O
	
and	O
on	O
the	O
other	O
hand	O
show	O
that	O
activity	B-Method
regularization	I-Method
(	O
AR	B-Method
)	O
and	O
temporal	B-Method
activation	I-Method
regularization	I-Method
(	O
TAR	B-Method
)	O
are	O
also	O
effective	O
methods	O
for	O
regularizing	B-Method
LSTMs	I-Method
.	O
	
Another	O
more	O
recent	O
way	O
of	O
regularizing	B-Method
RNNs	I-Method
,	O
that	O
is	O
similar	O
in	O
spirit	O
to	O
the	O
approach	O
we	O
take	O
,	O
involves	O
minimizing	O
the	O
difference	O
between	O
the	O
hidden	O
states	O
of	O
the	O
original	O
and	O
the	O
auxiliary	B-Method
network	I-Method
.	O
	
In	O
this	O
paper	O
we	O
propose	O
a	O
simple	O
regularization	B-Method
based	O
on	O
dropout	B-Method
that	O
we	O
call	O
fraternal	B-Method
dropout	I-Method
,	O
where	O
we	O
minimize	O
an	O
equally	O
weighted	O
sum	O
of	O
prediction	O
losses	O
from	O
two	O
identical	O
copies	O
of	O
the	O
same	O
LSTM	B-Method
with	O
different	O
dropout	O
masks	O
,	O
and	O
add	O
as	O
a	O
regularization	O
the	O
difference	O
between	O
the	O
predictions	O
(	O
pre	O
-	O
softmax	O
)	O
of	O
the	O
two	O
networks	O
.	O
	
We	O
analytically	O
show	O
that	O
our	O
regularization	B-Metric
objective	I-Metric
is	O
equivalent	O
to	O
minimizing	O
the	O
variance	O
in	O
predictions	O
from	O
different	O
i.i.d	O
.	O
	
dropout	O
masks	O
;	O
thus	O
encouraging	O
the	O
predictions	O
to	O
be	O
invariant	O
to	O
dropout	O
masks	O
.	O
	
We	O
also	O
discuss	O
how	O
our	O
regularization	B-Method
is	O
related	O
to	O
expectation	B-Method
linear	I-Method
dropout	I-Method
,	O
-	B-Method
model	I-Method
and	I-Method
activity	I-Method
regularization	I-Method
,	O
and	O
empirically	O
show	O
that	O
our	O
method	O
provides	O
non	O
-	O
trivial	O
gains	O
over	O
these	O
related	O
methods	O
which	O
we	O
explain	O
furthermore	O
in	O
our	O
ablation	O
study	O
(	O
Section	O
[	O
reference	O
]	O
)	O
.	O
	
section	O
:	O
Fraternal	O
dropout	O
	
Dropout	B-Method
is	O
a	O
powerful	O
regularization	B-Method
for	O
neural	B-Method
networks	I-Method
.	O
	
It	O
is	O
usually	O
more	O
effective	O
on	O
densely	O
connected	O
layers	O
because	O
they	O
suffer	O
more	O
from	O
overfitting	O
compared	O
with	O
convolution	O
layers	O
where	O
the	O
parameters	O
are	O
shared	O
.	O
	
For	O
this	O
reason	O
dropout	B-Method
is	O
an	O
important	O
regularization	B-Method
for	O
RNNs	B-Task
.	O
	
However	O
,	O
dropout	B-Method
has	O
a	O
gap	O
between	O
its	O
training	O
and	O
inference	B-Task
phase	I-Task
since	O
the	O
latter	O
phase	O
assumes	O
linear	O
activations	O
to	O
correct	O
for	O
the	O
factor	O
by	O
which	O
the	O
expected	O
value	O
of	O
each	O
activation	O
would	O
be	O
different	O
.	O
	
In	O
addition	O
,	O
the	O
prediction	O
of	O
models	O
with	O
dropout	O
generally	O
vary	O
with	O
different	O
dropout	O
mask	O
.	O
	
However	O
,	O
the	O
desirable	O
property	O
in	O
such	O
cases	O
would	O
be	O
to	O
have	O
final	O
predictions	O
be	O
invariant	O
to	O
dropout	O
masks	O
.	O
	
As	O
such	O
,	O
the	O
idea	O
behind	O
fraternal	B-Method
dropout	I-Method
is	O
to	O
train	O
a	O
neural	B-Method
network	I-Method
model	I-Method
in	O
a	O
way	O
that	O
encourages	O
the	O
variance	O
in	O
predictions	O
under	O
different	O
dropout	O
masks	O
to	O
be	O
as	O
small	O
as	O
possible	O
.	O
	
Specifically	O
,	O
consider	O
we	O
have	O
an	O
RNN	B-Method
model	I-Method
denoted	O
by	O
that	O
	
takes	O
as	O
input	O
,	O
where	O
denotes	O
the	O
model	O
parameters	O
.	O
	
Let	O
be	O
the	O
prediction	O
of	O
the	O
model	O
for	O
input	O
sample	O
at	O
time	O
,	O
for	O
dropout	O
mask	O
and	O
current	O
input	O
,	O
where	O
is	O
a	O
function	O
of	O
and	O
the	O
hidden	O
states	O
corresponding	O
to	O
the	O
previous	O
time	O
steps	O
.	O
	
Similarly	O
,	O
let	O
be	O
the	O
corresponding	O
time	O
step	O
loss	O
value	O
for	O
the	O
overall	O
input	O
-	O
target	O
sample	O
pair	O
.	O
	
Then	O
in	O
fraternal	B-Method
dropout	I-Method
,	O
we	O
simultaneously	O
feed	O
-	O
forward	O
the	O
input	O
sample	O
through	O
two	O
identical	O
copies	O
of	O
the	O
RNN	B-Method
that	O
share	O
the	O
same	O
parameters	O
but	O
with	O
different	O
dropout	O
masks	O
and	O
at	O
each	O
time	O
step	O
.	O
	
This	O
yields	O
two	O
loss	O
values	O
at	O
each	O
time	O
step	O
given	O
by	O
,	O
and	O
.	O
	
Then	O
the	O
overall	B-Metric
loss	I-Metric
function	I-Metric
of	O
fraternal	B-Method
dropout	I-Method
is	O
given	O
by	O
,	O
where	O
is	O
the	O
regularization	O
coefficient	O
,	O
is	O
the	O
dimensions	O
of	O
and	O
is	O
the	O
fraternal	B-Method
dropout	I-Method
regularization	I-Method
given	O
by	O
	
,	O
We	O
use	O
Monte	B-Method
Carlo	I-Method
sampling	I-Method
to	O
approximate	O
where	O
and	O
are	O
the	O
same	O
as	O
the	O
one	O
used	O
to	O
calculate	O
values	O
.	O
	
Hence	O
,	O
the	O
additional	O
computation	O
is	O
negligible	O
.	O
	
We	O
note	O
that	O
the	O
regularization	O
term	O
of	O
our	O
objective	O
is	O
equivalent	O
to	O
minimizing	O
the	O
variance	O
in	O
the	O
prediction	O
function	O
with	O
different	O
dropout	O
masks	O
as	O
shown	O
below	O
(	O
proof	O
in	O
the	O
appendix	O
)	O
.	O
	
theorem	O
:	O
.	O
	
Let	O
sit	O
and	O
sjt	O
be	O
i.i.d	O
.	O
	
dropout	O
masks	O
and	O
∈⁢pt	O
(	O
zt	O
	
,	O
sit;θ	O
)	O
Rm	O
be	O
the	O
prediction	B-Method
function	I-Method
as	O
described	O
above	O
.	O
	
Then	O
,	O
Note	O
that	O
a	O
generalization	O
of	O
our	O
approach	O
would	O
be	O
to	O
minimize	O
the	O
difference	O
between	O
the	O
predictions	O
of	O
the	O
two	O
networks	O
with	O
different	O
data	B-Method
/	I-Method
model	I-Method
augmentations	I-Method
.	O
	
However	O
,	O
in	O
this	O
paper	O
we	O
focus	O
on	O
using	O
different	O
dropout	O
masks	O
and	O
experiment	O
mainly	O
with	O
RNNs	B-Method
.	O
	
section	O
:	O
Related	O
Work	O
	
subsection	O
:	O
Relation	O
to	O
Expectation	B-Method
Linear	I-Method
Dropout	I-Method
(	I-Method
ELD	I-Method
)	O
	
analytically	O
showed	O
that	O
the	O
expected	B-Metric
error	I-Metric
(	O
over	O
samples	O
)	O
between	O
a	O
model	O
’s	O
expected	O
prediction	O
over	O
all	O
dropout	O
masks	O
,	O
and	O
the	O
prediction	O
using	O
the	O
average	O
mask	O
,	O
is	O
upper	O
bounded	O
.	O
	
Based	O
on	O
this	O
result	O
,	O
they	O
propose	O
to	O
explicitly	O
minimize	O
the	O
difference	O
(	O
we	O
have	O
adapted	O
their	O
regularization	O
to	O
our	O
notations	O
)	O
,	O
where	O
is	O
the	O
dropout	O
mask	O
.	O
	
However	O
,	O
due	O
to	O
feasibility	O
consideration	O
,	O
they	O
instead	O
propose	O
to	O
use	O
the	O
following	O
regularization	B-Method
in	O
practice	O
,	O
Specifically	O
,	O
this	O
is	O
achieved	O
by	O
feed	O
-	O
forwarding	O
the	O
input	O
twice	O
through	O
the	O
network	O
,	O
with	O
and	O
without	O
dropout	O
mask	O
,	O
and	O
minimizing	O
the	O
main	O
network	B-Metric
loss	I-Metric
(	O
with	O
dropout	B-Method
)	O
along	O
with	O
the	O
regularization	O
term	O
specified	O
above	O
(	O
but	O
without	O
back	O
-	O
propagating	O
the	O
gradients	O
through	O
the	O
network	O
without	O
dropout	B-Method
)	O
.	O
	
The	O
goal	O
of	O
is	O
to	O
minimize	O
the	O
network	O
loss	O
along	O
with	O
the	O
expected	O
difference	O
between	O
the	O
prediction	O
from	O
individual	O
dropout	O
mask	O
and	O
the	O
prediction	O
from	O
the	O
expected	O
dropout	O
mask	O
.	O
	
We	O
note	O
that	O
our	O
regularization	B-Metric
objective	I-Metric
is	O
upper	O
bounded	O
by	O
the	O
expectation	B-Method
-	I-Method
linear	I-Method
dropout	I-Method
regularization	I-Method
as	O
shown	O
below	O
(	O
proof	O
in	O
the	O
appendix	O
)	O
.	O
	
theorem	O
:	O
.	O
	
.	O
	
This	O
result	O
shows	O
that	O
minimizing	O
the	O
ELD	B-Metric
objective	I-Metric
indirectly	O
minimizes	O
our	O
regularization	O
term	O
.	O
	
Finally	O
as	O
indicated	O
above	O
,	O
they	O
apply	O
the	O
target	O
loss	O
only	O
on	O
the	O
network	O
with	O
dropout	B-Method
.	O
	
In	O
fact	O
,	O
in	O
our	O
own	O
ablation	O
studies	O
(	O
see	O
Section	O
[	O
reference	O
]	O
)	O
we	O
find	O
that	O
back	O
-	O
propagating	O
target	O
loss	O
through	O
the	O
network	O
(	O
without	O
dropout	B-Method
)	O
makes	O
optimizing	O
the	O
model	O
harder	O
.	O
	
However	O
,	O
in	O
our	O
setting	O
,	O
simultaneously	O
back	O
-	O
propagating	O
target	O
loss	O
through	O
both	O
networks	O
yields	O
both	O
performance	O
gain	O
as	O
well	O
as	O
convergence	B-Metric
gain	I-Metric
.	O
	
We	O
believe	O
convergence	B-Metric
is	O
faster	O
for	O
our	O
regularization	B-Method
because	O
network	O
weights	O
are	O
more	O
likely	O
to	O
get	O
target	O
based	O
updates	O
from	O
back	B-Method
-	I-Method
propagation	I-Method
in	O
our	O
case	O
.	O
	
This	O
is	O
especially	O
true	O
for	O
weight	B-Task
dropout	I-Task
since	O
in	O
this	O
case	O
dropped	O
weights	O
do	O
not	O
get	O
updated	O
in	O
the	O
training	O
iteration	O
.	O
	
subsection	O
:	O
Relation	O
to	O
-	O
model	O
	
propose	O
-	O
model	O
with	O
the	O
goal	O
of	O
improving	O
performance	O
on	O
classification	B-Task
tasks	I-Task
in	O
the	O
semi	B-Task
-	I-Task
supervised	I-Task
setting	I-Task
.	O
	
They	O
propose	O
a	O
model	O
similar	O
to	O
ours	O
(	O
considering	O
the	O
equivalent	O
deep	B-Method
feed	I-Method
-	I-Method
forward	I-Method
version	I-Method
of	O
our	O
model	O
)	O
except	O
they	O
apply	O
target	B-Method
loss	I-Method
only	O
on	O
one	O
of	O
the	O
networks	O
and	O
use	O
time	O
-	O
dependent	O
weighting	O
function	O
(	O
while	O
we	O
use	O
constant	O
)	O
.	O
	
The	O
intuition	O
in	O
their	O
case	O
is	O
to	O
leverage	O
unlabeled	B-Material
data	I-Material
by	O
using	O
them	O
to	O
minimize	O
the	O
difference	O
in	O
prediction	O
between	O
the	O
two	O
copies	O
of	O
the	O
network	O
with	O
different	O
dropout	O
masks	O
.	O
	
Further	O
,	O
they	O
also	O
test	O
their	O
model	O
in	O
the	O
supervised	B-Task
setting	I-Task
but	O
fail	O
to	O
explain	O
the	O
improvements	O
they	O
obtain	O
by	O
using	O
this	O
regularization	B-Method
.	O
	
We	O
note	O
that	O
in	O
our	O
case	O
we	O
analytically	O
show	O
that	O
minimizing	O
our	O
regularizer	B-Method
(	O
also	O
used	O
in	O
-	O
model	O
)	O
is	O
equivalent	O
to	O
minimizing	O
the	O
variance	O
in	O
the	O
model	O
predictions	O
(	O
Remark	O
[	O
reference	O
]	O
)	O
.	O
	
Furthermore	O
,	O
we	O
also	O
show	O
the	O
relation	O
of	O
our	O
regularizer	B-Method
to	O
expectation	B-Method
linear	I-Method
dropout	I-Method
(	O
Proposition	O
[	O
reference	O
]	O
)	O
.	O
	
In	O
Section	O
[	O
reference	O
]	O
,	O
we	O
study	O
the	O
effects	O
of	O
target	B-Metric
based	I-Metric
loss	I-Metric
on	O
both	O
networks	O
,	O
which	O
is	O
not	O
used	O
in	O
the	O
-	O
model	O
.	O
	
We	O
find	O
that	O
applying	O
target	O
loss	O
on	O
both	O
the	O
networks	O
leads	O
to	O
significantly	O
faster	O
convergence	B-Metric
.	O
	
Finally	O
,	O
we	O
bring	O
to	O
attention	O
that	O
temporal	B-Method
embedding	I-Method
(	O
another	O
model	O
proposed	O
by	O
,	O
claimed	O
to	O
be	O
a	O
better	O
version	O
of	O
-	O
model	O
for	O
semi	B-Task
-	I-Task
supervised	I-Task
,	I-Task
learning	I-Task
)	O
is	O
intractable	O
in	O
natural	B-Task
language	I-Task
processing	I-Task
applications	I-Task
because	O
storing	O
averaged	O
predictions	O
over	O
all	O
of	O
the	O
time	O
steps	O
would	O
be	O
memory	O
exhaustive	O
(	O
since	O
predictions	O
are	O
usually	O
huge	O
-	O
tens	O
of	O
thousands	O
values	O
)	O
.	O
	
On	O
a	O
final	O
note	O
,	O
we	O
argue	O
that	O
in	O
the	O
supervised	B-Task
case	I-Task
,	O
using	O
a	O
time	O
-	O
dependent	O
weighting	O
function	O
instead	O
of	O
a	O
constant	O
value	O
is	O
not	O
needed	O
.	O
	
Since	O
the	O
ground	O
truth	O
labels	O
are	O
known	O
,	O
we	O
have	O
not	O
observed	O
the	O
problem	O
mentioned	O
by	O
,	O
that	O
the	O
network	O
gets	O
stuck	O
in	O
a	O
degenerate	O
solution	O
when	O
is	O
too	O
large	O
in	O
earlier	O
epochs	O
of	O
training	O
.	O
	
We	O
note	O
that	O
it	O
is	O
much	O
easier	O
to	O
search	O
for	O
an	O
optimal	O
constant	O
value	O
,	O
which	O
is	O
true	O
in	O
our	O
case	O
,	O
as	O
opposed	O
to	O
tuning	O
the	O
time	O
-	O
dependent	O
function	O
.	O
	
Similarity	O
to	O
-	O
model	O
makes	O
our	O
method	O
related	O
to	O
other	O
semi	B-Task
-	I-Task
supervised	I-Task
works	I-Task
,	O
mainly	O
and	O
.	O
	
Since	O
semi	B-Task
-	I-Task
supervised	I-Task
learning	I-Task
is	O
not	O
a	O
primary	O
focus	O
of	O
this	O
paper	O
,	O
we	O
refer	O
to	O
for	O
more	O
details	O
.	O
	
We	O
note	O
that	O
the	O
idea	O
of	O
adding	O
a	O
penalty	O
encouraging	O
the	O
representation	O
to	O
be	O
similar	O
for	O
two	O
different	O
masks	O
was	O
previously	O
implemented	O
by	O
the	O
authors	O
of	O
a	O
Multi	B-Method
-	I-Method
Prediction	I-Method
Deep	I-Method
Boltzmann	I-Method
Machines	I-Method
.	O
	
Nevertheless	O
,	O
the	O
idea	O
is	O
not	O
discussed	O
in	O
their	O
paper	O
.	O
	
Another	O
way	O
to	O
address	O
the	O
gap	O
between	O
the	O
train	B-Metric
and	I-Metric
evaluation	I-Metric
mode	I-Metric
of	O
dropout	B-Method
is	O
to	O
perform	O
Monte	B-Method
Carlo	I-Method
sampling	I-Method
of	I-Method
masks	I-Method
and	O
average	O
the	O
predictions	O
during	O
evaluation	B-Task
,	O
and	O
this	O
has	O
been	O
used	O
for	O
feed	B-Method
-	I-Method
forward	I-Method
networks	I-Method
.	O
	
We	O
find	O
that	O
this	O
technique	O
does	O
not	O
work	O
well	O
for	O
RNNs	B-Method
.	O
	
The	O
details	O
of	O
these	O
experiments	O
can	O
be	O
found	O
in	O
the	O
appendix	O
.	O
	
section	O
:	O
Experiments	O
	
subsection	O
:	O
Language	B-Method
Models	I-Method
	
In	O
the	O
case	O
of	O
language	B-Task
modeling	I-Task
we	O
test	O
our	O
model	O
on	O
two	O
benchmark	O
datasets	O
	
–	O
Penn	B-Material
Tree	I-Material
-	I-Material
bank	I-Material
(	I-Material
PTB	I-Material
)	I-Material
dataset	I-Material
and	O
WikiText	B-Material
-	I-Material
2	I-Material
(	I-Material
WT2	I-Material
)	I-Material
dataset	I-Material
.	O
	
We	O
use	O
preprocessing	B-Method
as	O
specified	O
by	O
(	O
for	O
PTB	B-Material
corpus	I-Material
)	O
and	O
Moses	B-Material
tokenizer	I-Material
(	O
for	O
the	O
WT2	B-Material
dataset	I-Material
)	O
.	O
	
For	O
both	O
datasets	O
we	O
use	O
the	O
AWD	B-Method
-	I-Method
LSTM	I-Method
3	I-Method
-	I-Method
layer	I-Method
architecture	I-Method
described	O
in	O
which	O
we	O
call	O
the	O
baseline	B-Method
model	I-Method
.	O
	
The	O
number	O
of	O
parameters	O
in	O
the	O
model	O
used	O
for	O
PTB	B-Method
is	O
24	O
million	O
as	O
compared	O
to	O
34	O
million	O
in	O
the	O
case	O
of	O
WT2	B-Method
because	O
WT2	B-Method
has	O
a	O
larger	O
vocabulary	O
size	O
for	O
which	O
we	O
use	O
a	O
larger	O
embedding	O
matrix	O
.	O
	
Apart	O
from	O
those	O
differences	O
,	O
the	O
architectures	O
are	O
identical	O
.	O
	
When	O
we	O
use	O
fraternal	B-Method
dropout	I-Method
,	O
we	O
simply	O
add	O
our	O
regularization	B-Method
on	O
top	O
of	O
this	O
baseline	O
model	O
.	O
	
Word	O
level	O
Penn	B-Material
Treebank	I-Material
(	O
PTB	B-Material
)	O
.	O
	
Influenced	O
by	O
,	O
our	O
goal	O
here	O
is	O
to	O
make	O
sure	O
that	O
fraternal	B-Method
dropout	I-Method
outperforms	O
existing	O
methods	O
not	O
simply	O
because	O
of	O
extensive	O
hyper	B-Method
-	I-Method
parameter	I-Method
grid	I-Method
search	I-Method
but	O
rather	O
due	O
to	O
its	O
regularization	O
effects	O
.	O
	
Hence	O
,	O
in	O
our	O
experiments	O
we	O
leave	O
a	O
vast	O
majority	O
of	O
hyper	O
-	O
parameters	O
used	O
in	O
the	O
baseline	O
model	O
unchanged	O
i.e.	O
embedding	O
and	O
hidden	O
states	O
sizes	O
,	O
gradient	O
clipping	O
value	O
,	O
weight	O
decay	O
and	O
the	O
values	O
used	O
for	O
all	O
dropout	B-Method
layers	I-Method
(	O
dropout	O
on	O
the	O
word	O
vectors	O
,	O
the	O
output	O
between	O
LSTM	O
layers	O
,	O
the	O
output	O
of	O
the	O
final	O
LSTM	B-Method
,	O
and	O
embedding	B-Method
dropout	I-Method
)	O
.	O
	
However	O
,	O
a	O
few	O
changes	O
are	O
necessary	O
:	O
the	O
coefficients	O
for	O
AR	O
and	O
TAR	O
needed	O
to	O
be	O
altered	O
because	O
fraternal	O
dropout	O
also	O
affects	O
RNNs	O
activation	O
(	O
as	O
explained	O
in	O
Subsection	O
[	O
reference	O
]	O
)	O
	
–	O
we	O
did	O
not	O
run	O
grid	B-Method
search	I-Method
to	O
obtain	O
the	O
best	O
values	O
but	O
simply	O
deactivated	O
AR	B-Method
and	I-Method
TAR	I-Method
regularizers	I-Method
;	O
since	O
fraternal	B-Method
dropout	I-Method
needs	O
twice	O
as	O
much	O
memory	O
,	O
batch	O
size	O
is	O
halved	O
so	O
the	O
model	O
needs	O
approximately	O
the	O
same	O
amount	O
of	O
memory	O
and	O
hence	O
fits	O
on	O
the	O
same	O
GPU	O
.	O
	
The	O
final	O
change	O
in	O
hyper	O
-	O
parameters	O
is	O
to	O
alter	O
the	O
non	O
-	O
monotone	O
interval	O
used	O
in	O
non	B-Method
-	I-Method
monotonically	I-Method
triggered	I-Method
averaged	I-Method
SGD	I-Method
(	I-Method
NT	I-Method
-	I-Method
ASGD	I-Method
)	I-Method
optimizer	I-Method
.	O
	
We	O
run	O
a	O
grid	B-Method
search	I-Method
on	O
and	O
obtain	O
very	O
similar	O
results	O
for	O
the	O
largest	O
values	O
(	O
40	O
,	O
50	O
and	O
60	O
)	O
in	O
the	O
candidate	O
set	O
.	O
	
Hence	O
,	O
our	O
model	O
is	O
trained	O
longer	O
using	O
ordinary	O
SGD	B-Method
optimizer	I-Method
as	O
compared	O
to	O
the	O
baseline	O
model	O
.	O
	
We	O
evaluate	O
our	O
model	O
using	O
the	O
perplexity	B-Metric
metric	I-Metric
and	O
compare	O
the	O
results	O
that	O
we	O
obtain	O
against	O
the	O
existing	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
results	O
.	O
	
The	O
results	O
are	O
reported	O
in	O
Table	O
[	O
reference	O
]	O
.	O
	
Our	O
approach	O
achieves	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
performance	O
compared	O
with	O
existing	O
benchmarks	O
.	O
	
To	O
confirm	O
that	O
the	O
gains	O
are	O
robust	O
to	O
initialization	O
,	O
we	O
run	O
ten	O
experiments	O
for	O
the	O
baseline	B-Method
model	I-Method
with	O
different	O
seeds	O
(	O
without	O
fine	B-Method
-	I-Method
tuning	I-Method
)	O
for	O
PTB	B-Material
dataset	I-Material
to	O
compute	O
confidence	O
intervals	O
.	O
	
The	O
average	B-Metric
best	I-Metric
validation	I-Metric
perplexity	I-Metric
is	O
with	O
the	O
minimum	O
value	O
equals	O
.	O
	
The	O
same	O
for	O
test	B-Task
perplexity	I-Task
is	O
and	O
,	O
respectively	O
.	O
	
Our	O
score	O
(	O
validation	B-Metric
and	I-Metric
test	I-Metric
perplexity	I-Metric
)	O
beats	O
ordinal	O
dropout	O
minimum	O
values	O
.	O
	
We	O
also	O
perform	O
experiments	O
using	O
fraternal	B-Method
dropout	I-Method
with	O
a	O
grid	B-Method
search	I-Method
on	O
all	O
the	O
hyper	O
-	O
parameters	O
and	O
find	O
that	O
it	O
leads	O
to	O
further	O
improvements	O
in	O
performance	O
.	O
	
The	O
details	O
of	O
this	O
experiment	O
can	O
be	O
found	O
in	O
section	O
[	O
reference	O
]	O
.	O
	
Word	B-Method
level	I-Method
WikiText	I-Method
-	I-Method
2	I-Method
(	O
WT2	B-Method
)	O
.	O
	
In	O
the	O
case	O
of	O
WikiText	B-Task
-	I-Task
2	I-Task
language	I-Task
modeling	I-Task
task	I-Task
,	O
we	O
outperform	O
the	O
current	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
using	O
the	O
perplexity	B-Metric
metric	I-Metric
by	O
a	O
significant	O
margin	O
.	O
	
Due	O
to	O
the	O
lack	O
of	O
computational	O
power	O
,	O
we	O
run	O
a	O
single	O
training	B-Method
procedure	I-Method
for	O
fraternal	B-Task
dropout	I-Task
on	O
WT2	B-Material
dataset	I-Material
because	O
it	O
is	O
larger	O
than	O
PTB	O
.	O
	
In	O
this	O
experiment	O
,	O
we	O
use	O
the	O
best	O
hyper	O
-	O
parameters	O
found	O
for	O
PTB	B-Material
dataset	I-Material
(	O
,	O
non	O
-	O
monotone	O
interval	O
and	O
halved	O
batch	O
size	O
;	O
the	O
rest	O
of	O
the	O
hyper	O
-	O
parameters	O
are	O
the	O
same	O
as	O
described	O
in	O
for	O
WT2	B-Method
)	O
.	O
	
The	O
final	O
results	O
are	O
presented	O
in	O
Table	O
[	O
reference	O
]	O
.	O
	
subsection	O
:	O
Image	B-Task
captioning	I-Task
	
We	O
also	O
apply	O
fraternal	B-Method
dropout	I-Method
on	O
an	O
image	B-Task
captioning	I-Task
task	I-Task
.	O
	
We	O
use	O
the	O
well	O
-	O
known	O
show	B-Method
and	I-Method
tell	I-Method
model	I-Method
as	O
a	O
baseline	O
.	O
	
We	O
emphasize	O
that	O
in	O
the	O
image	B-Task
captioning	I-Task
task	I-Task
,	O
the	O
image	B-Method
encoder	I-Method
and	I-Method
sentence	I-Method
decoder	I-Method
architectures	I-Method
are	O
usually	O
learned	O
together	O
.	O
	
Since	O
we	O
want	O
to	O
focus	O
on	O
the	O
benefits	O
of	O
using	O
fraternal	B-Method
dropout	I-Method
in	O
RNNs	B-Method
we	O
use	O
frozen	B-Method
pretrained	I-Method
ResNet	I-Method
-	I-Method
101	I-Method
model	I-Method
as	O
our	O
image	B-Method
encoder	I-Method
.	O
	
It	O
means	O
that	O
our	O
results	O
are	O
not	O
directly	O
comparable	O
with	O
other	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
methods	O
,	O
however	O
we	O
report	O
results	O
for	O
the	O
original	O
methods	O
so	O
readers	O
can	O
see	O
that	O
our	O
baseline	O
performs	O
well	O
.	O
	
The	O
final	O
results	O
are	O
presented	O
in	O
Table	O
[	O
reference	O
]	O
.	O
	
We	O
argue	O
that	O
in	O
this	O
task	O
smaller	O
values	O
are	O
optimal	O
because	O
the	O
image	B-Method
captioning	I-Method
encoder	I-Method
is	O
given	O
all	O
information	O
in	O
the	O
beginning	O
and	O
hence	O
the	O
variance	O
of	O
consecutive	O
predictions	O
is	O
smaller	O
that	O
in	O
unconditioned	B-Task
natural	I-Task
language	I-Task
processing	I-Task
tasks	I-Task
.	O
	
Fraternal	B-Method
dropout	I-Method
may	O
benefits	O
here	O
mainly	O
due	O
to	O
averaging	O
gradients	O
for	O
different	O
mask	O
and	O
hence	O
updating	O
weights	O
more	O
frequently	O
.	O
	
section	O
:	O
Ablation	B-Task
Studies	I-Task
	
In	O
this	O
section	O
,	O
the	O
goal	O
is	O
to	O
study	O
existing	O
methods	O
closely	O
related	O
to	O
ours	O
–	O
expectation	B-Method
linear	I-Method
dropout	I-Method
,	O
-	B-Method
model	I-Method
and	I-Method
activity	I-Method
regularization	I-Method
.	O
	
All	O
of	O
our	O
experiments	O
for	O
ablation	B-Task
studies	I-Task
,	O
which	O
apply	O
a	O
single	B-Method
layer	I-Method
LSTM	I-Method
,	O
use	O
the	O
same	O
hyper	O
-	O
parameters	O
and	O
model	B-Method
architecture	I-Method
as	O
.	O
	
subsection	O
:	O
Expectation	B-Method
-	I-Method
linear	I-Method
dropout	I-Method
(	I-Method
ELD	I-Method
)	O
	
The	O
relation	O
with	O
expectation	B-Method
-	I-Method
linear	I-Method
dropout	I-Method
has	O
been	O
discussed	O
in	O
Section	O
[	O
reference	O
]	O
.	O
	
Here	O
we	O
perform	O
experiments	O
to	O
study	O
the	O
difference	O
in	O
performance	O
when	O
using	O
the	O
ELD	B-Method
regularization	I-Method
versus	O
our	O
regularization	B-Method
(	I-Method
FD	I-Method
)	I-Method
.	O
	
In	O
addition	O
to	O
ELD	B-Method
,	O
we	O
also	O
study	O
a	O
modification	O
(	O
ELDM	B-Method
)	O
of	O
ELD	B-Method
which	O
applies	O
target	O
loss	O
to	O
both	O
copies	O
of	O
LSTMs	B-Method
in	O
ELD	O
similar	O
to	O
FD	B-Method
(	O
notice	O
in	O
their	O
case	O
they	O
only	O
have	O
dropout	O
on	O
one	O
LSTM	B-Method
)	O
.	O
	
Finally	O
we	O
also	O
evaluate	O
a	O
baseline	B-Method
model	I-Method
without	O
any	O
of	O
these	O
regularizations	O
.	O
	
The	O
learning	O
dynamics	O
curves	O
are	O
shown	O
in	O
Figure	O
[	O
reference	O
]	O
.	O
	
Our	O
regularization	B-Method
performs	O
better	O
in	O
terms	O
of	O
convergence	B-Metric
compared	O
with	O
other	O
methods	O
.	O
	
In	O
terms	O
of	O
generalization	B-Task
,	O
we	O
find	O
that	O
FD	B-Method
is	O
similar	O
to	O
ELD	B-Method
,	O
but	O
baseline	B-Method
and	O
ELDM	B-Method
are	O
much	O
worse	O
.	O
	
Interestingly	O
,	O
looking	O
at	O
the	O
train	B-Metric
and	I-Metric
validation	I-Metric
curves	I-Metric
together	O
,	O
ELDM	B-Method
seems	O
to	O
be	O
suffering	O
from	O
optimization	B-Task
problems	I-Task
.	O
	
subsection	O
:	O
-	O
model	O
	
Since	O
-	O
model	O
is	O
similar	O
to	O
our	O
algorithm	O
(	O
even	O
though	O
it	O
is	O
designed	O
for	O
semi	B-Task
-	I-Task
supervised	I-Task
learning	I-Task
in	I-Task
feed	I-Task
-	I-Task
forward	I-Task
networks	I-Task
)	O
,	O
we	O
study	O
the	O
difference	O
in	O
performance	O
with	O
-	O
model	O
both	O
qualitatively	O
and	O
quantitatively	O
to	O
establish	O
the	O
advantage	O
of	O
our	O
approach	O
.	O
	
First	O
,	O
we	O
run	O
both	O
single	B-Method
layer	I-Method
LSTM	I-Method
and	I-Method
3	I-Method
-	I-Method
layer	I-Method
AWD	I-Method
-	I-Method
LSTM	I-Method
on	O
PTB	B-Task
task	I-Task
to	O
check	O
how	O
their	O
model	O
compares	O
with	O
ours	O
in	O
the	O
case	O
of	O
language	B-Task
modeling	I-Task
.	O
	
The	O
results	O
are	O
shown	O
in	O
Figure	O
[	O
reference	O
]	O
and	O
[	O
reference	O
]	O
.	O
	
We	O
find	O
that	O
our	O
model	O
converges	O
significantly	O
faster	O
than	O
-	O
model	O
.	O
	
We	O
believe	O
this	O
happens	O
because	O
we	O
back	O
-	O
propagate	O
the	O
target	O
loss	O
through	O
both	O
networks	O
(	O
in	O
contrast	O
to	O
-	O
model	O
)	O
that	O
leads	O
to	O
weights	O
getting	O
updated	O
using	O
target	O
-	O
based	O
gradients	O
more	O
often	O
.	O
	
Even	O
though	O
we	O
designed	O
our	O
algorithm	O
specifically	O
to	O
address	O
problems	O
in	O
RNNs	B-Task
,	O
to	O
have	O
a	O
fair	O
comparison	O
,	O
we	O
compare	O
with	O
-	O
model	O
on	O
a	O
semi	B-Task
-	I-Task
supervised	I-Task
task	I-Task
which	O
is	O
their	O
goal	O
.	O
	
Specifically	O
,	O
we	O
use	O
the	O
CIFAR	B-Material
-	I-Material
10	I-Material
dataset	I-Material
that	O
consists	O
of	O
images	O
from	O
10	O
classes	O
.	O
	
Following	O
the	O
usual	O
splits	O
used	O
in	O
semi	B-Task
-	I-Task
supervised	I-Task
learning	I-Task
literature	I-Task
,	O
we	O
use	O
4	O
thousand	O
labeled	O
and	O
41	O
thousand	O
unlabeled	O
samples	O
for	O
training	O
,	O
5	O
thousand	O
labeled	O
samples	O
for	O
validation	O
and	O
10	O
thousand	O
labeled	O
samples	O
for	O
test	O
set	O
.	O
	
We	O
use	O
the	O
original	O
ResNet	B-Method
-	I-Method
56	I-Method
architecture	I-Method
.	O
	
We	O
run	O
grid	B-Method
search	I-Method
on	O
,	O
dropout	O
rates	O
in	O
and	O
leave	O
the	O
rest	O
of	O
the	O
hyper	O
-	O
parameters	O
unchanged	O
.	O
	
We	O
additionally	O
check	O
importance	O
of	O
using	O
unlabeled	B-Material
data	I-Material
.	O
	
The	O
results	O
are	O
reported	O
in	O
Table	O
[	O
reference	O
]	O
.	O
	
We	O
find	O
that	O
our	O
algorithm	O
performs	O
at	O
par	O
with	O
-	O
model	O
.	O
	
When	O
unlabeled	B-Material
data	I-Material
is	O
not	O
used	O
,	O
fraternal	B-Method
dropout	I-Method
provides	O
slightly	O
better	O
results	O
as	O
compared	O
to	O
traditional	O
dropout	B-Method
.	O
	
subsection	O
:	O
Activity	B-Method
regularization	I-Method
and	O
temporal	B-Method
activity	I-Method
regularization	I-Method
analysis	I-Method
	
The	O
authors	O
of	O
study	O
the	O
importance	O
of	O
activity	B-Method
regularization	I-Method
(	O
AR	B-Method
)	O
and	O
temporal	B-Method
activity	I-Method
regularization	I-Method
(	O
TAR	B-Method
)	O
in	O
LSTMs	B-Method
given	O
as	O
,	O
where	O
is	O
the	O
LSTM	O
’s	O
output	O
activation	O
at	O
time	O
step	O
(	O
hence	O
depends	O
on	O
both	O
current	O
input	O
and	O
the	O
model	O
parameters	O
)	O
.	O
	
Notice	O
that	O
AR	B-Method
and	I-Method
TAR	I-Method
regularizations	I-Method
are	O
applied	O
on	O
the	O
output	O
of	O
the	O
LSTM	B-Method
,	O
while	O
our	O
regularization	O
is	O
applied	O
on	O
the	O
pre	O
-	O
softmax	O
output	O
of	O
the	O
LSTM	B-Method
.	O
	
However	O
,	O
since	O
our	O
regularization	B-Method
can	O
be	O
decomposed	O
as	O
and	O
encapsulates	O
an	O
term	O
along	O
with	O
the	O
dot	O
product	O
term	O
,	O
we	O
perform	O
experiments	O
to	O
confirm	O
that	O
the	O
gains	O
in	O
our	O
approach	O
is	O
not	O
due	O
to	O
the	O
regularization	B-Method
alone	O
.	O
	
A	O
similar	O
argument	O
goes	O
for	O
the	O
TAR	B-Metric
objective	I-Metric
.	O
	
We	O
run	O
a	O
grid	B-Method
search	I-Method
on	O
,	O
,	O
which	O
include	O
the	O
hyper	O
-	O
parameters	O
mentioned	O
in	O
.	O
	
For	O
our	O
regularization	B-Task
,	O
we	O
use	O
.	O
	
Furthermore	O
,	O
we	O
also	O
compare	O
with	O
a	O
regularization	B-Method
(	O
PR	B-Method
)	O
that	O
regularizes	O
to	O
further	O
rule	O
-	O
out	O
any	O
gains	O
only	O
from	O
regularization	B-Method
.	O
	
Based	O
on	O
this	O
grid	B-Method
search	I-Method
,	O
we	O
pick	O
the	O
best	O
model	O
on	O
the	O
validation	O
set	O
for	O
all	O
the	O
regularizations	B-Method
,	O
and	O
additionally	O
report	O
a	O
baseline	O
model	O
without	O
any	O
of	O
these	O
four	O
mentioned	O
regularizations	O
.	O
	
The	O
learning	B-Method
dynamics	I-Method
is	O
shown	O
in	O
Figure	O
[	O
reference	O
]	O
.	O
	
Our	O
regularization	B-Method
performs	O
better	O
both	O
in	O
terms	O
of	O
convergence	B-Metric
and	O
generalization	B-Task
compared	O
with	O
other	O
methods	O
.	O
	
Average	O
hidden	O
state	O
activation	O
is	O
reduced	O
when	O
any	O
of	O
the	O
regularizer	B-Method
described	I-Method
is	O
applied	O
(	O
see	O
Figure	O
[	O
reference	O
]	O
)	O
.	O
	
subsection	O
:	O
Improvements	O
using	O
fine	B-Method
-	I-Method
tuning	I-Method
	
We	O
confirm	O
that	O
models	O
trained	O
with	O
fraternal	B-Method
dropout	I-Method
benefit	O
from	O
the	O
NT	B-Method
-	I-Method
ASGD	I-Method
fine	I-Method
-	I-Method
tuning	I-Method
step	I-Method
(	O
as	O
also	O
used	O
in	O
)	O
.	O
	
However	O
,	O
this	O
is	O
a	O
very	O
time	O
-	O
consuming	O
practice	O
and	O
since	O
different	O
hyper	O
-	O
parameters	O
may	O
be	O
used	O
in	O
this	O
additional	O
part	O
of	O
the	O
learning	B-Method
procedure	I-Method
,	O
the	O
probability	O
of	O
obtaining	O
better	O
results	O
due	O
to	O
the	O
extensive	O
grid	B-Method
search	I-Method
is	O
higher	O
.	O
	
Hence	O
,	O
in	O
our	O
experiments	O
we	O
use	O
the	O
same	O
fine	B-Method
-	I-Method
tuning	I-Method
procedure	I-Method
as	O
implemented	O
in	O
the	O
official	B-Material
repository	I-Material
(	O
even	O
fraternal	O
dropout	O
was	O
not	O
used	O
)	O
.	O
	
We	O
present	O
the	O
importance	O
of	O
fine	O
-	O
tuning	O
in	O
Table	O
[	O
reference	O
]	O
.	O
	
subsection	O
:	O
Fraternal	B-Method
dropout	I-Method
and	O
expectation	B-Method
linear	I-Method
dropout	I-Method
comparison	I-Method
	
We	O
perform	O
extensive	O
grid	B-Task
search	I-Task
for	O
the	O
baseline	O
model	O
from	O
Subsection	O
[	O
reference	O
]	O
(	O
an	O
AWD	B-Method
-	I-Method
LSTM	I-Method
3	I-Method
-	I-Method
layer	I-Method
architecture	I-Method
)	O
trained	O
with	O
either	O
fraternal	B-Method
dropout	I-Method
or	O
expectation	B-Method
linear	I-Method
dropout	I-Method
regularizations	I-Method
,	O
to	O
further	O
contrast	O
the	O
performance	O
of	O
these	O
two	O
methods	O
.	O
	
The	O
experiments	O
are	O
run	O
without	O
fine	B-Method
-	I-Method
tuning	I-Method
on	O
the	O
PTB	B-Material
dataset	I-Material
.	O
	
In	O
each	O
run	O
,	O
all	O
five	O
dropout	B-Metric
rates	I-Metric
are	O
randomly	O
altered	O
(	O
they	O
are	O
set	O
to	O
their	O
original	O
value	O
,	O
as	O
in	O
,	O
multiplied	O
by	O
a	O
value	O
drawn	O
from	O
the	O
uniform	O
distribution	O
on	O
the	O
interval	O
)	O
and	O
the	O
rest	O
of	O
the	O
hyper	O
-	O
parameters	O
are	O
drawn	O
as	O
shown	O
in	O
Table	O
[	O
reference	O
]	O
.	O
	
As	O
in	O
Subsection	O
[	O
reference	O
]	O
,	O
AR	O
and	O
TAR	B-Method
regularizers	I-Method
are	O
deactivated	O
.	O
	
Together	O
we	O
run	O
more	O
than	O
400	O
experiments	O
.	O
	
The	O
results	O
are	O
presented	O
in	O
Table	O
[	O
reference	O
]	O
.	O
	
Both	O
FD	B-Method
and	O
ELD	B-Method
perform	O
better	O
than	O
the	O
baseline	O
model	O
that	O
instead	O
uses	O
AR	B-Method
and	I-Method
TAR	I-Method
regularizers	I-Method
.	O
	
Hence	O
,	O
we	O
confirm	O
our	O
previous	O
finding	O
(	O
see	O
Subsection	O
[	O
reference	O
]	O
)	O
that	O
both	O
FD	B-Method
and	O
ELD	B-Method
are	O
better	O
.	O
	
However	O
,	O
as	O
found	O
previously	O
for	O
smaller	O
model	O
in	O
Subsection	O
[	O
reference	O
]	O
,	O
the	O
convergence	O
of	O
FD	B-Method
is	O
faster	O
than	O
that	O
of	O
ELD	B-Method
.	O
	
Additionally	O
,	O
fraternal	B-Method
dropout	I-Method
is	O
more	O
robust	O
to	O
different	O
hyper	O
-	O
parameters	O
choice	O
(	O
more	O
runs	O
performing	O
better	O
than	O
the	O
baseline	O
and	O
better	O
average	O
for	O
top	O
performing	O
runs	O
)	O
.	O
	
section	O
:	O
Conclusion	O
	
In	O
this	O
paper	O
we	O
propose	O
a	O
simple	O
regularization	B-Method
method	I-Method
for	O
RNNs	B-Method
called	O
fraternal	B-Method
dropout	I-Method
that	O
acts	O
as	O
a	O
regularization	B-Method
by	O
reducing	O
the	O
variance	O
in	O
model	O
predictions	O
across	O
different	O
dropout	O
masks	O
.	O
	
We	O
show	O
that	O
our	O
model	O
achieves	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
results	O
on	O
benchmark	O
language	B-Task
modeling	I-Task
tasks	I-Task
along	O
with	O
faster	O
convergence	B-Metric
.	O
	
We	O
also	O
analytically	O
study	O
the	O
relationship	O
between	O
our	O
regularization	B-Method
and	O
expectation	B-Method
linear	I-Method
dropout	I-Method
.	O
	
We	O
perform	O
a	O
number	O
of	O
ablation	O
studies	O
to	O
evaluate	O
our	O
model	O
from	O
different	O
aspects	O
and	O
carefully	O
compare	O
it	O
with	O
related	O
methods	O
both	O
qualitatively	O
and	O
quantitatively	O
.	O
	
section	O
:	O
Acknowledgements	O
	
The	O
authors	O
would	O
like	O
to	O
acknowledge	O
the	O
support	O
of	O
the	O
following	O
agencies	O
for	O
research	O
funding	O
and	O
computing	O
support	O
:	O
NSERC	B-Material
,	O
CIFAR	B-Material
,	O
and	O
IVADO	B-Material
.	O
	
We	O
would	O
like	O
to	O
thank	O
Rosemary	O
Nan	O
Ke	O
and	O
Philippe	O
Lacaille	O
for	O
their	O
thoughts	O
and	O
comments	O
throughout	O
the	O
project	O
.	O
	
We	O
would	O
also	O
like	O
to	O
thank	O
Stanisław	O
Jastrzębski	O
and	O
Evan	O
Racah	O
for	O
useful	O
discussions	O
.	O
	
bibliography	O
:	O
References	O
	
appendix	O
:	O
Appendix	O
	
subsection	O
:	O
Monte	B-Task
Carlo	I-Task
evaluation	I-Task
	
A	O
well	O
known	O
way	O
to	O
address	O
the	O
gap	O
between	O
the	O
train	B-Metric
and	I-Metric
evaluation	I-Metric
mode	I-Metric
of	I-Metric
dropout	I-Metric
is	O
to	O
perform	O
Monte	B-Method
Carlo	I-Method
sampling	I-Method
of	I-Method
masks	I-Method
and	O
average	O
the	O
predictions	O
during	O
evaluation	B-Task
(	O
MC	B-Method
-	I-Method
eval	I-Method
)	O
,	O
and	O
this	O
has	O
been	O
used	O
for	O
feed	B-Method
-	I-Method
forward	I-Method
networks	I-Method
.	O
	
Since	O
fraternal	O
dropout	O
addresses	O
the	O
same	O
problem	O
,	O
we	O
would	O
like	O
to	O
clarify	O
that	O
it	O
is	O
not	O
straight	O
-	O
forward	O
and	O
feasible	O
to	O
apply	O
MC	B-Method
-	I-Method
eval	I-Method
for	O
RNNs	B-Method
.	O
	
In	O
feed	B-Method
-	I-Method
forward	I-Method
networks	I-Method
,	O
we	O
average	O
the	O
output	O
prediction	O
scores	O
from	O
different	O
masks	O
.	O
	
However	O
,	O
in	O
the	O
case	O
RNNs	B-Method
(	O
for	O
next	B-Task
step	I-Task
predictions	I-Task
)	O
,	O
there	O
is	O
more	O
than	O
one	O
way	O
to	O
perform	O
such	O
evaluation	O
,	O
but	O
each	O
one	O
is	O
problematic	O
.	O
	
They	O
are	O
as	O
follows	O
:	O
1	O
.	O
	
Online	B-Task
averaging	I-Task
Consider	O
that	O
we	O
first	O
make	O
the	O
prediction	O
at	O
time	O
step	O
1	O
using	O
different	O
masks	O
by	O
averaging	O
the	O
prediction	B-Metric
score	I-Metric
.	O
	
Then	O
we	O
use	O
this	O
output	O
to	O
feed	O
as	O
input	O
to	O
the	O
time	O
step	O
2	O
,	O
then	O
use	O
different	O
masks	O
at	O
time	O
step	O
2	O
to	O
generate	O
the	O
output	O
at	O
time	O
step	O
2	O
,	O
and	O
so	O
on	O
.	O
	
But	O
in	O
order	O
to	O
do	O
so	O
,	O
because	O
of	O
the	O
way	O
RNNs	B-Method
work	O
,	O
we	O
also	O
need	O
to	O
feed	O
the	O
previous	O
time	O
hidden	O
state	O
to	O
time	O
step	O
2	O
.	O
	
One	O
way	O
would	O
be	O
to	O
average	O
the	O
hidden	O
states	O
over	O
different	O
masks	O
at	O
time	O
step	O
1	O
.	O
	
But	O
the	O
hidden	O
space	O
can	O
in	O
general	O
be	O
highly	O
nonlinear	O
,	O
and	O
it	O
is	O
not	O
clear	O
if	O
averaging	O
in	O
this	O
space	O
is	O
a	O
good	O
strategy	O
.	O
	
This	O
approach	O
is	O
not	O
justified	O
.	O
	
Besides	O
,	O
this	O
strategy	O
as	O
a	O
whole	O
is	O
extremely	O
time	O
consuming	O
because	O
we	O
would	O
need	O
to	O
sequentially	O
make	O
predictions	O
with	O
multiple	O
masks	O
at	O
each	O
time	O
step	O
.	O
	
2	O
.	O
	
Sequence	B-Method
averaging	I-Method
	
Let	O
’s	O
consider	O
that	O
we	O
use	O
a	O
different	O
mask	O
each	O
time	O
we	O
want	O
to	O
generate	O
a	O
sequence	O
,	O
and	O
then	O
we	O
average	O
the	O
prediction	O
scores	O
,	O
and	O
compute	O
the	O
argmax	B-Method
(	O
at	O
each	O
time	O
step	O
)	O
to	O
get	O
the	O
actual	O
generated	O
sequence	O
.	O
	
In	O
this	O
case	O
,	O
notice	O
it	O
is	O
not	O
guaranteed	O
that	O
the	O
predicted	O
word	O
at	O
time	O
step	O
due	O
to	O
averaging	O
the	O
predictions	O
would	O
lead	O
to	O
the	O
next	O
word	O
(	O
generated	O
by	O
the	O
same	O
process	O
)	O
if	O
we	O
were	O
to	O
feed	O
the	O
time	O
step	O
output	O
as	O
input	O
to	O
the	O
time	O
step	O
.	O
	
For	O
example	O
,	O
with	O
different	O
dropout	O
masks	O
,	O
if	O
the	O
probability	O
of	O
time	O
step	O
outputs	O
are	O
:	O
I	O
40	O
%	O
)	O
,	O
he	O
(	O
30	O
%	O
)	O
,	O
she	O
(	O
30	O
%	O
)	O
,	O
and	O
the	O
probability	O
of	O
the	O
2nd	O
time	O
step	O
outputs	O
are	O
:	O
am	O
(	O
30	O
%	O
)	O
,	O
is	O
(	O
60	O
%	O
)	O
,	O
was	O
(	O
10	O
%	O
)	O
.	O
	
Then	O
the	O
averaged	B-Metric
prediction	I-Metric
score	I-Metric
followed	O
by	O
argmax	B-Method
will	O
result	O
in	O
the	O
prediction	O
	
‘	O
	
‘	O
	
I	O
is	O
’	O
’	O
,	O
but	O
this	O
would	O
be	O
incorrect	O
.	O
	
A	O
similar	O
concern	O
applies	O
for	O
output	B-Task
predictions	I-Task
varying	O
in	O
temporal	O
length	O
.	O
	
Hence	O
,	O
this	O
approach	O
can	O
not	O
be	O
used	O
to	O
generate	O
a	O
sequence	O
(	O
it	O
has	O
to	O
be	O
done	O
by	O
by	O
sampling	O
a	O
mask	O
and	O
generating	O
a	O
single	O
sequence	O
)	O
.	O
	
However	O
,	O
this	O
approach	O
may	O
be	O
used	O
to	O
estimate	O
the	O
probability	O
assigned	O
by	O
the	O
model	O
to	O
a	O
given	O
sequence	O
.	O
	
Nonetheless	O
,	O
we	O
run	O
experiments	O
on	O
the	O
PTB	B-Material
dataset	I-Material
using	O
MC	B-Method
-	I-Method
eval	I-Method
(	O
the	O
results	O
are	O
summarized	O
in	O
Table	O
[	O
reference	O
]	O
)	O
.	O
	
We	O
start	O
with	O
a	O
simple	O
comparison	O
that	O
compares	O
fraternal	B-Method
dropout	I-Method
with	O
the	O
averaged	O
mask	O
and	O
the	O
AWD	B-Method
-	I-Method
LSTM	I-Method
3	I-Method
-	I-Method
layer	I-Method
baseline	I-Method
with	O
a	O
single	O
fixed	O
mask	O
that	O
we	O
call	O
MC1	B-Method
.	O
	
The	O
MC1	B-Method
model	I-Method
performs	O
much	O
worse	O
than	O
fraternal	B-Method
dropout	I-Method
.	O
	
Hence	O
,	O
it	O
would	O
be	O
hard	O
to	O
use	O
MC1	B-Method
model	I-Method
in	O
practice	O
because	O
a	O
single	O
sample	O
is	O
inaccurate	O
.	O
	
We	O
also	O
check	O
MC	O
-	O
eval	O
for	O
a	O
larger	O
number	O
of	O
models	O
(	O
MC50	O
)	O
	
(	O
50	O
models	O
were	O
used	O
since	O
we	O
were	O
not	O
able	O
to	O
fit	O
more	O
models	O
simultaneously	O
on	O
a	O
single	O
GPU	O
)	O
.	O
	
The	O
final	O
results	O
for	O
MC50	B-Method
are	O
worse	O
than	O
the	O
baseline	O
which	O
uses	O
the	O
averaged	O
mask	O
.	O
	
For	O
comparison	O
,	O
we	O
also	O
evaluate	O
MC10	B-Method
.	O
	
Note	O
that	O
no	O
fine	B-Method
-	I-Method
tuning	I-Method
is	O
used	O
for	O
the	O
above	O
experiments	O
.	O
	
subsection	O
:	O
Reasons	O
for	O
focusing	O
on	O
RNNs	B-Task
	
The	O
fraternal	B-Method
dropout	I-Method
method	I-Method
is	O
general	O
and	O
may	O
be	O
applied	O
in	O
feed	B-Method
-	I-Method
forward	I-Method
architectures	I-Method
(	O
as	O
shown	O
in	O
Subsection	O
[	O
reference	O
]	O
for	O
CIFAR	B-Material
-	I-Material
10	I-Material
semisupervised	I-Material
example	I-Material
)	O
.	O
	
However	O
,	O
we	O
believe	O
that	O
it	O
is	O
more	O
powerful	O
in	O
the	O
case	O
of	O
RNNs	B-Method
because	O
:	O
Variance	O
in	O
prediction	B-Task
accumulates	O
among	O
time	O
steps	O
in	O
RNNs	B-Method
and	O
since	O
we	O
share	O
parameters	O
for	O
all	O
time	O
steps	O
,	O
one	O
may	O
use	O
the	O
same	O
value	O
at	O
each	O
step	O
.	O
	
In	O
feed	B-Method
-	I-Method
forward	I-Method
networks	I-Method
the	O
layers	O
usually	O
do	O
not	O
share	O
parameters	O
and	O
hence	O
one	O
may	O
want	O
to	O
use	O
different	O
values	O
for	O
different	O
layers	O
(	O
which	O
may	O
be	O
hard	O
to	O
tune	O
)	O
.	O
	
The	O
simple	O
way	O
to	O
alleviate	O
this	O
problem	O
is	O
to	O
apply	O
the	O
regularization	O
term	O
on	O
the	O
pre	O
-	O
softmax	O
predictions	O
only	O
(	O
as	O
shown	O
in	O
the	O
paper	O
)	O
or	O
use	O
the	O
same	O
value	O
for	O
all	O
layers	O
.	O
	
However	O
,	O
we	O
believe	O
that	O
it	O
may	O
limit	O
possible	O
gains	O
.	O
	
The	O
best	O
performing	O
RNN	B-Method
architectures	I-Method
(	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
)	O
usually	O
use	O
some	O
kind	O
of	O
dropout	B-Method
(	O
embedding	B-Method
dropout	I-Method
,	O
word	O
dropout	O
,	O
weight	O
dropout	O
etc	O
.	O
)	O
,	O
very	O
often	O
with	O
high	O
dropout	B-Metric
rates	I-Metric
(	O
even	O
larger	O
than	O
50	O
%	O
for	O
input	B-Task
word	I-Task
embedding	I-Task
in	O
NLP	B-Task
tasks	I-Task
)	O
.	O
	
However	O
,	O
this	O
is	O
not	O
true	O
for	O
feed	B-Method
-	I-Method
forward	I-Method
networks	I-Method
.	O
	
For	O
instance	O
,	O
ResNet	B-Method
architectures	I-Method
very	O
often	O
do	O
not	O
use	O
dropout	B-Method
at	O
all	O
(	O
probably	O
because	O
batch	B-Method
normalization	I-Method
is	O
often	O
better	O
to	O
use	O
)	O
.	O
	
It	O
can	O
be	O
seen	O
in	O
the	O
paper	O
(	O
Subsection	O
[	O
reference	O
]	O
,	O
semisupervised	B-Task
CIFAR	I-Task
-	I-Task
10	I-Task
task	I-Task
)	O
that	O
when	O
unlabeled	B-Material
data	I-Material
is	O
not	O
used	O
the	O
regular	B-Method
dropout	I-Method
hurts	O
performance	O
and	O
using	O
fraternal	B-Method
dropout	I-Method
seems	O
to	O
improve	O
just	O
a	O
little	O
.	O
	
On	O
a	O
final	O
note	O
,	O
the	O
Monte	B-Method
Carlo	I-Method
sampling	I-Method
(	O
a	O
well	O
known	O
method	O
that	O
adresses	O
the	O
gap	O
betweem	O
the	O
train	B-Method
and	I-Method
evaluation	I-Method
mode	I-Method
of	I-Method
dropout	I-Method
)	O
can	O
not	O
be	O
easily	O
applied	O
for	O
RNNs	B-Method
and	O
fraternal	B-Method
dropout	I-Method
may	O
be	O
seen	O
as	O
an	O
alternative	O
.	O
	
To	O
conclude	O
,	O
we	O
believe	O
that	O
when	O
the	O
use	O
of	O
dropout	O
benefits	O
in	O
a	O
given	O
architecture	O
,	O
applying	O
fraternal	B-Method
dropout	I-Method
should	O
improve	O
performance	O
even	O
more	O
.	O
	
As	O
mentioned	O
before	O
,	O
in	O
image	B-Task
recognition	I-Task
tasks	I-Task
,	O
one	O
may	O
experiment	O
with	O
something	O
what	O
we	O
would	O
temporarily	O
dub	O
fraternal	B-Task
augmentation	I-Task
(	O
even	O
though	O
dropout	B-Method
is	O
not	O
used	O
,	O
one	O
can	O
use	O
random	B-Method
data	I-Method
augmentation	I-Method
such	O
as	O
random	O
crop	O
or	O
random	O
flip	O
)	O
.	O
	
Hence	O
,	O
one	O
may	O
force	O
a	O
given	O
neural	B-Method
network	I-Method
to	O
have	O
the	O
same	O
predictions	O
for	O
different	O
augmentations	O
.	O
	
subsection	O
:	O
Proofs	O
	
theorem	O
:	O
.	O
	
Let	O
sit	O
and	O
sjt	O
be	O
i.i.d	O
.	O
	
dropout	O
masks	O
and	O
∈⁢pt	O
(	O
zt	O
	
,	O
sit;θ	O
)	O
Rm	O
be	O
the	O
prediction	B-Method
function	I-Method
as	O
described	O
above	O
.	O
	
Then	O
,	O
	
proof	O
:	O
Proof	O
.	O
	
For	O
simplicity	O
of	O
notation	O
,	O
we	O
omit	O
the	O
time	O
index	O
.	O
	
∎	O
	
theorem	O
:	O
.	O
	
.	O
	
proof	O
:	O
Proof	O
.	O
	
Let	O
,	O
then	O
Then	O
using	O
Jensen	O
’s	O
inequality	O
,	O
∎	O
	
document	O
:	O
Speech	B-Task
Recognition	I-Task
with	O
Deep	B-Method
Recurrent	I-Method
Neural	I-Method
Networks	I-Method
	
Recurrent	B-Method
neural	I-Method
networks	I-Method
(	O
RNNs	B-Method
)	O
are	O
a	O
powerful	O
model	O
for	O
sequential	O
data	O
.	O
	
End	O
-	O
to	O
-	O
end	B-Method
training	I-Method
methods	I-Method
such	O
as	O
Connectionist	B-Method
Temporal	I-Method
Classification	I-Method
make	O
it	O
possible	O
to	O
train	O
RNNs	B-Method
for	O
sequence	B-Task
labelling	I-Task
problems	I-Task
where	O
the	O
input	O
-	O
output	O
alignment	O
is	O
unknown	O
.	O
	
The	O
combination	O
of	O
these	O
methods	O
with	O
the	O
Long	B-Method
Short	I-Method
-	I-Method
term	I-Method
Memory	I-Method
RNN	I-Method
architecture	I-Method
has	O
proved	O
particularly	O
fruitful	O
,	O
delivering	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
results	O
in	O
cursive	O
handwriting	B-Task
recognition	I-Task
.	O
	
However	O
RNN	B-Method
performance	O
in	O
speech	B-Task
recognition	O
has	O
so	O
far	O
been	O
disappointing	O
,	O
with	O
better	O
results	O
returned	O
by	O
deep	B-Method
feedforward	I-Method
networks	I-Method
.	O
	
This	O
paper	O
investigates	O
deep	B-Method
recurrent	I-Method
neural	I-Method
networks	I-Method
,	O
which	O
combine	O
the	O
multiple	O
levels	O
of	O
representation	O
that	O
have	O
proved	O
so	O
effective	O
in	O
deep	B-Method
networks	I-Method
with	O
the	O
flexible	O
use	O
of	O
long	O
range	O
context	O
that	O
empowers	O
RNNs	B-Method
.	O
	
When	O
trained	O
end	O
-	O
to	O
-	O
end	O
with	O
suitable	O
regularisation	B-Method
,	O
we	O
find	O
that	O
deep	B-Method
Long	I-Method
Short	I-Method
-	I-Method
term	I-Method
Memory	I-Method
RNNs	I-Method
achieve	O
a	O
test	B-Metric
set	I-Metric
error	I-Metric
of	O
17.7	O
%	O
on	O
the	O
TIMIT	B-Task
phoneme	I-Task
recognition	I-Task
benchmark	I-Task
,	O
which	O
to	O
our	O
knowledge	O
is	O
the	O
best	O
recorded	O
score	O
.	O
	
AlexGraves	O
,	O
Abdel	O
-	O
rahmanMohamedandGeoffreyHinton	O
DepartmentofComputerScience	O
,	O
UniversityofToronto	O
recurrent	B-Method
neural	I-Method
networks	I-Method
,	O
deep	B-Method
neural	I-Method
networks	I-Method
,	O
speech	B-Task
recognition	O
	
section	O
:	O
Introduction	O
	
Neural	B-Method
networks	I-Method
have	O
a	O
long	O
history	O
in	O
speech	B-Task
recognition	O
,	O
usually	O
in	O
combination	O
with	O
hidden	B-Method
Markov	I-Method
models	I-Method
.	O
	
They	O
have	O
gained	O
attention	O
in	O
recent	O
years	O
with	O
the	O
dramatic	O
improvements	O
in	O
acoustic	B-Task
modelling	I-Task
yielded	O
by	O
deep	B-Method
feedforward	I-Method
networks	I-Method
.	O
	
Given	O
that	O
speech	B-Task
is	O
an	O
inherently	O
dynamic	B-Task
process	I-Task
,	O
it	O
seems	O
natural	O
to	O
consider	O
recurrent	B-Method
neural	I-Method
networks	I-Method
(	O
RNNs	B-Method
)	O
as	O
an	O
alternative	O
model	O
.	O
	
HMM	B-Method
-	I-Method
RNN	I-Method
systems	I-Method
have	O
also	O
seen	O
a	O
recent	O
revival	O
,	O
but	O
do	O
not	O
currently	O
perform	O
as	O
well	O
as	O
deep	B-Method
networks	I-Method
.	O
	
Instead	O
of	O
combining	O
RNNs	B-Method
with	O
HMMs	B-Method
,	O
it	O
is	O
possible	O
to	O
train	O
RNNs	B-Method
‘	O
end	O
-	O
to	O
-	O
end	O
’	O
for	O
speech	B-Task
recognition	O
.	O
	
This	O
approach	O
exploits	O
the	O
larger	O
state	O
-	O
space	O
and	O
richer	O
dynamics	O
of	O
RNNs	B-Method
compared	O
to	O
HMMs	B-Method
,	O
and	O
avoids	O
the	O
problem	O
of	O
using	O
potentially	O
incorrect	O
alignments	O
as	O
training	O
targets	O
.	O
	
The	O
combination	O
of	O
Long	B-Method
Short	I-Method
-	I-Method
term	I-Method
Memory	I-Method
,	O
an	O
RNN	B-Method
architecture	I-Method
with	O
an	O
improved	O
memory	B-Method
,	O
with	O
end	B-Task
-	I-Task
to	I-Task
-	I-Task
end	I-Task
training	I-Task
has	O
proved	O
especially	O
effective	O
for	O
cursive	O
handwriting	B-Task
recognition	I-Task
.	O
	
However	O
it	O
has	O
so	O
far	O
made	O
little	O
impact	O
on	O
speech	B-Task
recognition	O
.	O
	
RNNs	B-Method
are	O
inherently	O
deep	O
in	O
time	O
,	O
since	O
their	O
hidden	O
state	O
is	O
a	O
function	O
of	O
all	O
previous	O
hidden	O
states	O
.	O
	
The	O
question	O
that	O
inspired	O
this	O
paper	O
was	O
whether	O
RNNs	B-Method
could	O
also	O
benefit	O
from	O
depth	O
in	O
space	O
;	O
that	O
is	O
from	O
stacking	O
multiple	O
recurrent	O
hidden	O
layers	O
on	O
top	O
of	O
each	O
other	O
,	O
just	O
as	O
feedforward	B-Method
layers	I-Method
are	O
stacked	O
in	O
conventional	O
deep	B-Method
networks	I-Method
.	O
	
To	O
answer	O
this	O
question	O
we	O
introduce	O
deep	B-Method
Long	I-Method
Short	I-Method
-	I-Method
term	I-Method
Memory	I-Method
RNNs	I-Method
and	O
assess	O
their	O
potential	O
for	O
speech	B-Task
recognition	O
.	O
	
We	O
also	O
present	O
an	O
enhancement	O
to	O
a	O
recently	O
introduced	O
end	B-Method
-	I-Method
to	I-Method
-	I-Method
end	I-Method
learning	I-Method
method	I-Method
that	O
jointly	O
trains	O
two	O
separate	O
RNNs	B-Method
as	O
acoustic	B-Method
and	I-Method
linguistic	I-Method
models	I-Method
.	O
	
Sections	O
[	O
reference	O
]	O
and	O
[	O
reference	O
]	O
describe	O
the	O
network	B-Method
architectures	I-Method
and	O
training	B-Method
methods	I-Method
,	O
sec	O
:	O
experiments	O
provides	O
experimental	O
results	O
and	O
concluding	O
remarks	O
are	O
given	O
in	O
sec	O
:	O
conclusion	O
.	O
	
section	O
:	O
Recurrent	B-Method
Neural	I-Method
Networks	I-Method
	
Given	O
an	O
input	O
sequence	O
,	O
a	O
standard	O
recurrent	B-Method
neural	I-Method
network	I-Method
(	O
RNN	B-Method
)	O
computes	O
the	O
hidden	O
vector	O
sequence	O
and	O
output	O
vector	O
sequence	O
by	O
iterating	O
the	O
following	O
equations	O
from	O
to	O
:	O
where	O
the	O
terms	O
denote	O
weight	O
matrices	O
(	O
e.g.	O
is	O
the	O
input	O
-	O
hidden	O
weight	O
matrix	O
)	O
,	O
the	O
terms	O
denote	O
bias	O
vectors	O
(	O
e.g.	O
is	O
hidden	O
bias	O
vector	O
)	O
and	O
is	O
the	O
hidden	O
layer	O
function	O
.	O
is	O
usually	O
an	O
elementwise	B-Method
application	I-Method
of	O
a	O
sigmoid	B-Method
function	I-Method
.	O
	
However	O
we	O
have	O
found	O
that	O
the	O
Long	B-Method
Short	I-Method
-	I-Method
Term	I-Method
Memory	I-Method
(	O
LSTM	B-Method
)	O
architecture	O
,	O
which	O
uses	O
purpose	O
-	O
built	O
memory	O
cells	O
to	O
store	O
information	O
,	O
is	O
better	O
at	O
finding	O
and	O
exploiting	O
long	O
range	O
context	O
.	O
	
fig	O
:	O
lstm	B-Method
illustrates	O
a	O
single	O
LSTM	B-Method
memory	O
cell	O
.	O
	
For	O
the	O
version	O
of	O
LSTM	B-Method
used	O
in	O
this	O
paper	O
is	O
implemented	O
by	O
the	O
following	O
composite	B-Method
function	I-Method
:	O
where	O
is	O
the	O
logistic	B-Method
sigmoid	I-Method
function	I-Method
,	O
and	O
,	O
,	O
and	O
are	O
respectively	O
the	O
input	O
gate	O
,	O
forget	O
gate	O
,	O
output	O
gate	O
and	O
cell	O
activation	O
vectors	O
,	O
all	O
of	O
which	O
are	O
the	O
same	O
size	O
as	O
the	O
hidden	O
vector	O
.	O
	
The	O
weight	O
matrices	O
from	O
the	O
cell	O
to	O
gate	O
vectors	O
(	O
e.g.	O
)	O
are	O
diagonal	O
,	O
so	O
element	O
in	O
each	O
gate	O
vector	O
only	O
receives	O
input	O
from	O
element	O
of	O
the	O
cell	O
vector	O
.	O
	
One	O
shortcoming	O
of	O
conventional	O
RNNs	B-Method
is	O
that	O
they	O
are	O
only	O
able	O
to	O
make	O
use	O
of	O
previous	O
context	O
.	O
	
In	O
speech	B-Task
recognition	O
,	O
where	O
whole	O
utterances	O
are	O
transcribed	O
at	O
once	O
,	O
there	O
is	O
no	O
reason	O
not	O
to	O
exploit	O
future	O
context	O
as	O
well	O
.	O
	
Bidirectional	B-Method
RNNs	I-Method
(	O
BRNNs	B-Method
)	O
do	O
this	O
by	O
processing	O
the	O
data	O
in	O
both	O
directions	O
with	O
two	O
separate	O
hidden	O
layers	O
,	O
which	O
are	O
then	O
fed	O
forwards	O
to	O
the	O
same	O
output	O
layer	O
.	O
	
As	O
illustrated	O
in	O
fig	O
:	O
brnn	B-Method
,	O
a	O
BRNN	B-Method
computes	O
the	O
forward	O
hidden	O
sequence	O
,	O
the	O
backward	O
hidden	O
sequence	O
and	O
the	O
output	O
sequence	O
by	O
iterating	O
the	O
backward	B-Method
layer	I-Method
from	O
to	O
,	O
the	O
forward	B-Method
layer	I-Method
from	O
to	O
and	O
then	O
updating	O
the	O
output	O
layer	O
:	O
Combing	O
BRNNs	B-Method
with	O
LSTM	B-Method
gives	O
bidirectional	B-Method
LSTM	I-Method
,	O
which	O
can	O
access	O
long	O
-	O
range	O
context	O
in	O
both	O
input	O
directions	O
.	O
	
A	O
crucial	O
element	O
of	O
the	O
recent	O
success	O
of	O
hybrid	B-Method
HMM	I-Method
-	I-Method
neural	I-Method
network	I-Method
systems	I-Method
is	O
the	O
use	O
of	O
deep	B-Method
architectures	I-Method
,	O
which	O
are	O
able	O
to	O
build	O
up	O
progressively	O
higher	B-Method
level	I-Method
representations	I-Method
of	O
acoustic	O
data	O
.	O
	
Deep	B-Method
RNNs	I-Method
can	O
be	O
created	O
by	O
stacking	O
multiple	O
RNN	B-Method
hidden	I-Method
layers	I-Method
on	O
top	O
of	O
each	O
other	O
,	O
with	O
the	O
output	O
sequence	O
of	O
one	O
layer	O
forming	O
the	O
input	O
sequence	O
for	O
the	O
next	O
.	O
	
Assuming	O
the	O
same	O
hidden	O
layer	O
function	O
is	O
used	O
for	O
all	O
layers	O
in	O
the	O
stack	O
,	O
the	O
hidden	O
vector	O
sequences	O
are	O
iteratively	O
computed	O
from	O
to	O
and	O
to	O
:	O
where	O
we	O
define	O
.	O
	
The	O
network	O
outputs	O
are	O
Deep	B-Method
bidirectional	I-Method
RNNs	I-Method
can	O
be	O
implemented	O
by	O
replacing	O
each	O
hidden	O
sequence	O
with	O
the	O
forward	O
and	O
backward	O
sequences	O
and	O
,	O
and	O
ensuring	O
that	O
every	O
hidden	B-Method
layer	I-Method
receives	O
input	O
from	O
both	O
the	O
forward	O
and	O
backward	O
layers	O
at	O
the	O
level	O
below	O
.	O
	
If	O
LSTM	B-Method
is	O
used	O
for	O
the	O
hidden	O
layers	O
we	O
get	O
deep	O
bidirectional	O
LSTM	B-Method
,	O
the	O
main	O
architecture	O
used	O
in	O
this	O
paper	O
.	O
	
As	O
far	O
as	O
we	O
are	O
aware	O
this	O
is	O
the	O
first	O
time	O
deep	B-Method
LSTM	I-Method
has	O
been	O
applied	O
to	O
speech	B-Task
recognition	O
,	O
and	O
we	O
find	O
that	O
it	O
yields	O
a	O
dramatic	O
improvement	O
over	O
single	O
-	O
layer	O
LSTM	B-Method
.	O
	
section	O
:	O
Network	B-Method
Training	I-Method
	
We	O
focus	O
on	O
end	B-Task
-	I-Task
to	I-Task
-	I-Task
end	I-Task
training	I-Task
,	O
where	O
RNNs	B-Method
learn	O
to	O
map	O
directly	O
from	O
acoustic	O
to	O
phonetic	O
sequences	O
.	O
	
One	O
advantage	O
of	O
this	O
approach	O
is	O
that	O
it	O
removes	O
the	O
need	O
for	O
a	O
predefined	O
(	O
and	O
error	O
-	O
prone	O
)	O
alignment	O
to	O
create	O
the	O
training	O
targets	O
.	O
	
The	O
first	O
step	O
is	O
to	O
to	O
use	O
the	O
network	O
outputs	O
to	O
parameterise	O
a	O
differentiable	O
distribution	O
over	O
all	O
possible	O
phonetic	O
output	O
sequences	O
given	O
an	O
acoustic	O
input	O
sequence	O
.	O
	
The	O
log	O
-	O
probability	O
of	O
the	O
target	O
output	O
sequence	O
can	O
then	O
be	O
differentiated	O
with	O
respect	O
to	O
the	O
network	O
weights	O
using	O
backpropagation	B-Method
through	O
time	O
,	O
and	O
the	O
whole	O
system	O
can	O
be	O
optimised	O
with	O
gradient	B-Method
descent	I-Method
.	O
	
We	O
now	O
describe	O
two	O
ways	O
to	O
define	O
the	O
output	O
distribution	O
and	O
hence	O
train	O
the	O
network	O
.	O
	
We	O
refer	O
throughout	O
to	O
the	O
length	O
of	O
as	O
,	O
the	O
length	O
of	O
as	O
,	O
and	O
the	O
number	O
of	O
possible	O
phonemes	O
as	O
.	O
	
subsection	O
:	O
Connectionist	B-Method
Temporal	I-Method
Classification	I-Method
	
The	O
first	O
method	O
,	O
known	O
as	O
Connectionist	B-Method
Temporal	I-Method
Classification	I-Method
(	O
CTC	B-Method
)	O
,	O
uses	O
a	O
softmax	B-Method
layer	I-Method
to	O
define	O
a	O
separate	O
output	O
distribution	O
at	O
every	O
step	O
along	O
the	O
input	O
sequence	O
.	O
	
This	O
distribution	O
covers	O
the	O
phonemes	O
plus	O
an	O
extra	O
blank	O
symbol	O
which	O
represents	O
a	O
non	O
-	O
output	O
(	O
the	O
softmax	B-Method
layer	I-Method
is	O
therefore	O
size	O
)	O
.	O
	
Intuitively	O
the	O
network	O
decides	O
whether	O
to	O
emit	O
any	O
label	O
,	O
or	O
no	O
label	O
,	O
at	O
every	O
timestep	O
.	O
	
Taken	O
together	O
these	O
decisions	O
define	O
a	O
distribution	O
over	O
alignments	O
between	O
the	O
input	O
and	O
target	O
sequences	O
.	O
	
CTC	B-Method
then	O
uses	O
a	O
forward	B-Method
-	I-Method
backward	I-Method
algorithm	I-Method
to	O
sum	O
over	O
all	O
possible	O
alignments	O
and	O
determine	O
the	O
normalised	O
probability	O
of	O
the	O
target	O
sequence	O
given	O
the	O
input	O
sequence	O
.	O
	
Similar	O
procedures	O
have	O
been	O
used	O
elsewhere	O
in	O
speech	B-Task
and	O
handwriting	B-Task
recognition	I-Task
to	O
integrate	O
out	O
over	O
possible	O
segmentations	O
;	O
however	O
CTC	B-Method
differs	O
in	O
that	O
it	O
ignores	O
segmentation	B-Task
altogether	O
and	O
sums	O
over	O
single	O
-	O
timestep	O
label	O
decisions	O
instead	O
.	O
	
RNNs	B-Method
trained	O
with	O
CTC	B-Method
are	O
generally	O
bidirectional	O
,	O
to	O
ensure	O
that	O
every	O
depends	O
on	O
the	O
entire	O
input	O
sequence	O
,	O
and	O
not	O
just	O
the	O
inputs	O
up	O
to	O
.	O
	
In	O
this	O
work	O
we	O
focus	O
on	O
deep	B-Method
bidirectional	I-Method
networks	I-Method
,	O
with	O
defined	O
as	O
follows	O
:	O
where	O
is	O
the	O
element	O
of	O
the	O
length	O
unnormalised	O
output	O
vector	O
,	O
and	O
is	O
the	O
number	O
of	O
bidirectional	O
levels	O
.	O
	
subsection	O
:	O
RNN	B-Method
Transducer	I-Method
	
CTC	B-Method
defines	O
a	O
distribution	B-Method
over	I-Method
phoneme	I-Method
sequences	I-Method
that	O
depends	O
only	O
on	O
the	O
acoustic	O
input	O
sequence	O
.	O
	
It	O
is	O
therefore	O
an	O
acoustic	B-Method
-	I-Method
only	I-Method
model	I-Method
.	O
	
A	O
recent	O
augmentation	O
,	O
known	O
as	O
an	O
RNN	B-Method
transducer	I-Method
combines	O
a	O
CTC	B-Method
-	O
like	O
network	O
with	O
a	O
separate	O
RNN	B-Method
that	O
predicts	O
each	O
phoneme	O
given	O
the	O
previous	O
ones	O
,	O
thereby	O
yielding	O
a	O
jointly	O
trained	O
acoustic	B-Method
and	I-Method
language	I-Method
model	I-Method
.	O
	
Joint	B-Method
LM	I-Method
-	I-Method
acoustic	I-Method
training	I-Method
has	O
proved	O
beneficial	O
in	O
the	O
past	O
for	O
speech	B-Task
recognition	O
.	O
	
Whereas	O
CTC	B-Method
determines	O
an	O
output	O
distribution	O
at	O
every	O
input	O
timestep	O
,	O
an	O
RNN	B-Method
transducer	I-Method
determines	O
a	O
separate	O
distribution	O
for	O
every	O
combination	O
of	O
input	O
timestep	O
and	O
output	O
timestep	O
.	O
	
As	O
with	O
CTC	B-Method
,	O
each	O
distribution	O
covers	O
the	O
phonemes	O
plus	O
.	O
	
Intuitively	O
the	O
network	O
‘	O
decides	O
’	O
what	O
to	O
output	O
depending	O
both	O
on	O
where	O
it	O
is	O
in	O
the	O
input	O
sequence	O
and	O
the	O
outputs	O
it	O
has	O
already	O
emitted	O
.	O
	
For	O
a	O
length	O
target	O
sequence	O
,	O
the	O
complete	O
set	O
of	O
decisions	O
jointly	O
determines	O
a	O
distribution	O
over	O
all	O
possible	O
alignments	O
between	O
and	O
,	O
which	O
can	O
then	O
be	O
integrated	O
out	O
with	O
a	O
forward	B-Method
-	I-Method
backward	I-Method
algorithm	I-Method
to	O
determine	O
.	O
	
In	O
the	O
original	O
formulation	O
was	O
defined	O
by	O
taking	O
an	O
‘	O
acoustic	B-Method
’	I-Method
distribution	I-Method
from	O
the	O
CTC	B-Method
network	O
,	O
a	O
‘	O
linguistic	B-Method
’	I-Method
distribution	I-Method
from	O
the	O
prediction	B-Method
network	I-Method
,	O
then	O
multiplying	O
the	O
two	O
together	O
and	O
renormalising	O
.	O
	
An	O
improvement	O
introduced	O
in	O
this	O
paper	O
is	O
to	O
instead	O
feed	O
the	O
hidden	O
activations	O
of	O
both	O
networks	O
into	O
a	O
separate	O
feedforward	B-Method
output	I-Method
network	I-Method
,	O
whose	O
outputs	O
are	O
then	O
normalised	O
with	O
a	O
softmax	O
function	O
to	O
yield	O
.	O
	
This	O
allows	O
a	O
richer	O
set	O
of	O
possibilities	O
for	O
combining	O
linguistic	O
and	O
acoustic	O
information	O
,	O
and	O
appears	O
to	O
lead	O
to	O
better	O
generalisation	O
.	O
	
In	O
particular	O
we	O
have	O
found	O
that	O
the	O
number	O
of	O
deletion	B-Metric
errors	I-Metric
encountered	O
during	O
decoding	B-Task
is	O
reduced	O
.	O
	
Denote	O
by	O
and	O
the	O
uppermost	O
forward	O
and	O
backward	O
hidden	O
sequences	O
of	O
the	O
CTC	B-Method
network	O
,	O
and	O
by	O
the	O
hidden	O
sequence	O
of	O
the	O
prediction	B-Method
network	I-Method
.	O
	
At	O
each	O
the	O
output	B-Method
network	I-Method
is	O
implemented	O
by	O
feeding	O
and	O
to	O
a	O
linear	B-Method
layer	I-Method
to	O
generate	O
the	O
vector	O
,	O
then	O
feeding	O
and	O
to	O
a	O
hidden	B-Method
layer	I-Method
to	O
yield	O
,	O
and	O
finally	O
feeding	O
to	O
a	O
size	O
softmax	B-Method
layer	I-Method
to	O
determine	O
:	O
where	O
is	O
the	O
element	O
of	O
the	O
length	O
unnormalised	O
output	O
vector	O
.	O
	
For	O
simplicity	O
we	O
constrained	O
all	O
non	O
-	O
output	O
layers	O
to	O
be	O
the	O
same	O
size	O
(	O
;	O
however	O
they	O
could	O
be	O
varied	O
independently	O
.	O
	
RNN	B-Method
transducers	I-Method
can	O
be	O
trained	O
from	O
random	O
initial	O
weights	O
.	O
	
However	O
they	O
appear	O
to	O
work	O
better	O
when	O
initialised	O
with	O
the	O
weights	O
of	O
a	O
pretrained	O
CTC	B-Method
network	O
and	O
a	O
pretrained	B-Method
next	I-Method
-	I-Method
step	I-Method
prediction	I-Method
network	I-Method
(	O
so	O
that	O
only	O
the	O
output	B-Method
network	I-Method
starts	O
from	O
random	O
weights	O
)	O
.	O
	
The	O
output	O
layers	O
(	O
and	O
all	O
associated	O
weights	O
)	O
used	O
by	O
the	O
networks	O
during	O
pretraining	B-Task
are	O
removed	O
during	O
retraining	B-Task
.	O
	
In	O
this	O
work	O
we	O
pretrain	O
the	O
prediction	B-Method
network	I-Method
on	O
the	O
phonetic	O
transcriptions	O
of	O
the	O
audio	O
training	O
data	O
;	O
however	O
for	O
large	B-Task
-	I-Task
scale	I-Task
applications	I-Task
it	O
would	O
make	O
more	O
sense	O
to	O
pretrain	O
on	O
a	O
separate	O
text	O
corpus	O
.	O
	
subsection	O
:	O
Decoding	B-Task
	
RNN	B-Method
transducers	I-Method
can	O
be	O
decoded	O
with	O
beam	B-Method
search	I-Method
to	O
yield	O
an	O
n	O
-	O
best	O
list	O
of	O
candidate	O
transcriptions	O
.	O
	
In	O
the	O
past	O
CTC	B-Method
networks	O
have	O
been	O
decoded	O
using	O
either	O
a	O
form	O
of	O
best	B-Method
-	I-Method
first	I-Method
decoding	I-Method
known	O
as	O
prefix	B-Method
search	I-Method
,	O
or	O
by	O
simply	O
taking	O
the	O
most	O
active	O
output	O
at	O
every	O
timestep	O
.	O
	
In	O
this	O
work	O
however	O
we	O
exploit	O
the	O
same	O
beam	B-Method
search	I-Method
as	O
the	O
transducer	B-Method
,	O
with	O
the	O
modification	O
that	O
the	O
output	O
label	O
probabilities	O
do	O
not	O
depend	O
on	O
the	O
previous	O
outputs	O
	
(	O
so	O
)	O
.	O
	
We	O
find	O
beam	B-Method
search	I-Method
both	O
faster	O
and	O
more	O
effective	O
than	O
prefix	B-Method
search	I-Method
for	O
CTC	B-Method
.	O
	
Note	O
the	O
n	O
-	O
best	O
list	O
from	O
the	O
transducer	B-Method
was	O
originally	O
sorted	O
by	O
the	O
length	O
normalised	O
log	O
-	O
probabilty	O
;	O
in	O
the	O
current	O
work	O
we	O
dispense	O
with	O
the	O
normalisation	B-Method
(	O
which	O
only	O
helps	O
when	O
there	O
are	O
many	O
more	O
deletions	O
than	O
insertions	O
)	O
and	O
sort	O
by	O
.	O
	
subsection	O
:	O
Regularisation	B-Method
	
Regularisation	B-Method
is	O
vital	O
for	O
good	O
performance	O
with	O
RNNs	B-Method
,	O
as	O
their	O
flexibility	O
makes	O
them	O
prone	O
to	O
overfitting	O
.	O
	
Two	O
regularisers	B-Method
were	O
used	O
in	O
this	O
paper	O
:	O
early	B-Task
stopping	I-Task
and	O
weight	O
noise	O
(	O
the	O
addition	O
of	O
Gaussian	O
noise	O
to	O
the	O
network	O
weights	O
during	O
training	O
)	O
.	O
	
Weight	O
noise	O
was	O
added	O
once	O
per	O
training	O
sequence	O
,	O
rather	O
than	O
at	O
every	O
timestep	O
.	O
	
Weight	O
noise	O
tends	O
to	O
‘	O
simplify	O
’	O
neural	B-Method
networks	I-Method
,	O
in	O
the	O
sense	O
of	O
reducing	O
the	O
amount	O
of	O
information	O
required	O
to	O
transmit	O
the	O
parameters	O
,	O
which	O
improves	O
generalisation	B-Task
.	O
	
section	O
:	O
Experiments	O
	
Phoneme	B-Task
recognition	I-Task
experiments	O
were	O
performed	O
on	O
the	O
TIMIT	B-Material
corpus	I-Material
.	O
	
The	O
standard	O
462	O
speaker	O
set	O
with	O
all	O
SA	O
records	O
removed	O
was	O
used	O
for	O
training	O
,	O
and	O
a	O
separate	O
development	O
set	O
of	O
50	O
speakers	O
was	O
used	O
for	O
early	B-Task
stopping	I-Task
.	O
	
Results	O
are	O
reported	O
for	O
the	O
24	O
-	O
speaker	O
core	O
test	O
set	O
.	O
	
The	O
audio	O
data	O
was	O
encoded	O
using	O
a	O
Fourier	B-Method
-	I-Method
transform	I-Method
-	I-Method
based	I-Method
filter	I-Method
-	I-Method
bank	I-Method
with	O
40	O
coefficients	O
(	O
plus	O
energy	O
)	O
distributed	O
on	O
a	O
mel	O
-	O
scale	O
,	O
together	O
with	O
their	O
first	O
and	O
second	O
temporal	O
derivatives	O
.	O
	
Each	O
input	O
vector	O
was	O
therefore	O
size	O
123	O
.	O
	
The	O
data	O
were	O
normalised	O
so	O
that	O
every	O
element	O
of	O
the	O
input	O
vectors	O
had	O
zero	O
mean	O
and	O
unit	O
variance	O
over	O
the	O
training	O
set	O
.	O
	
All	O
61	O
phoneme	O
labels	O
were	O
used	O
during	O
training	O
and	O
decoding	B-Task
(	O
so	O
)	O
,	O
then	O
mapped	O
to	O
39	O
classes	O
for	O
scoring	B-Task
.	O
	
Note	O
that	O
all	O
experiments	O
were	O
run	O
only	O
once	O
,	O
so	O
the	O
variance	O
due	O
to	O
random	O
weight	O
initialisation	O
and	O
weight	O
noise	O
is	O
unknown	O
.	O
	
As	O
shown	O
in	O
tab	O
:	O
timit	B-Material
,	O
nine	O
RNNs	B-Method
were	O
evaluated	O
,	O
varying	O
along	O
three	O
main	O
dimensions	O
:	O
	
the	O
training	B-Method
method	I-Method
used	O
(	O
CTC	B-Method
,	O
Transducer	B-Method
or	O
pretrained	B-Method
Transducer	I-Method
)	O
,	O
the	O
number	O
of	O
hidden	O
levels	O
(	O
1–5	O
)	O
,	O
and	O
the	O
number	O
of	O
LSTM	B-Method
cells	O
in	O
each	O
hidden	O
layer	O
.	O
	
Bidirectional	O
LSTM	B-Method
was	O
used	O
for	O
all	O
networks	O
except	O
CTC	B-Method
-	O
3l	O
-	O
500h	O
-	O
tanh	O
,	O
which	O
had	O
units	O
instead	O
of	O
LSTM	B-Method
cells	O
,	O
and	O
CTC	B-Method
-	O
3l	O
-	O
421h	O
-	O
uni	O
where	O
the	O
LSTM	B-Method
layers	O
were	O
unidirectional	O
.	O
	
All	O
networks	O
were	O
trained	O
using	O
stochastic	B-Method
gradient	I-Method
descent	I-Method
,	O
with	O
learning	B-Metric
rate	I-Metric
,	O
momentum	O
and	O
random	O
initial	O
weights	O
drawn	O
uniformly	O
from	O
.	O
	
All	O
networks	O
except	O
CTC	B-Method
-	O
3l	O
-	O
500h	O
-	O
tanh	O
and	O
PreTrans	B-Method
-	I-Method
3l	I-Method
-	I-Method
250h	I-Method
were	O
first	O
trained	O
with	O
no	O
noise	O
	
and	O
then	O
,	O
starting	O
from	O
the	O
point	O
of	O
highest	O
log	O
-	O
probability	O
on	O
the	O
development	O
set	O
,	O
retrained	O
with	O
Gaussian	B-Method
weight	I-Method
noise	I-Method
(	O
)	O
until	O
the	O
point	O
of	O
lowest	O
phoneme	O
error	B-Metric
rate	I-Metric
on	O
the	O
development	O
set	O
.	O
	
PreTrans	B-Method
-	I-Method
3l	I-Method
-	I-Method
250h	I-Method
was	O
initialised	O
with	O
the	O
weights	O
of	O
CTC	B-Method
-	O
3l	O
-	O
250h	O
,	O
along	O
with	O
the	O
weights	O
of	O
a	O
phoneme	B-Method
prediction	I-Method
network	I-Method
(	O
which	O
also	O
had	O
a	O
hidden	O
layer	O
of	O
250	O
LSTM	B-Method
cells	O
)	O
,	O
both	O
of	O
which	O
were	O
trained	O
without	O
noise	O
,	O
retrained	O
with	O
noise	O
,	O
and	O
stopped	O
at	O
the	O
point	O
of	O
highest	O
log	O
-	O
probability	O
.	O
	
PreTrans	B-Method
-	I-Method
3l	I-Method
-	I-Method
250h	I-Method
was	O
trained	O
from	O
this	O
point	O
with	O
noise	O
added	O
.	O
	
CTC	B-Method
-	O
3l	O
-	O
500h	O
-	O
tanh	O
was	O
entirely	O
trained	O
without	O
weight	O
noise	O
because	O
it	O
failed	O
to	O
learn	O
with	O
noise	O
added	O
.	O
	
Beam	B-Method
search	I-Method
decoding	I-Method
was	O
used	O
for	O
all	O
networks	O
,	O
with	O
a	O
beam	O
width	O
of	O
100	O
.	O
	
The	O
advantage	O
of	O
deep	B-Method
networks	I-Method
is	O
immediately	O
obvious	O
,	O
with	O
the	O
error	B-Metric
rate	I-Metric
for	O
CTC	B-Method
dropping	O
from	O
23.9	O
%	O
to	O
18.4	O
%	O
as	O
the	O
number	O
of	O
hidden	O
levels	O
increases	O
from	O
one	O
to	O
five	O
.	O
	
The	O
four	O
networks	O
CTC	B-Method
-	O
3l	O
-	O
500h	O
-	O
tanh	O
,	O
CTC	B-Method
-	O
1l	O
-	O
622h	O
,	O
CTC	B-Method
-	O
3l	O
-	O
421h	O
-	O
uni	O
and	O
CTC	B-Method
-	O
3l	O
-	O
250h	O
all	O
had	O
approximately	O
the	O
same	O
number	O
of	O
weights	O
,	O
but	O
give	O
radically	O
different	O
results	O
.	O
	
The	O
three	O
main	O
conclusions	O
we	O
can	O
draw	O
from	O
this	O
are	O
(	O
a	O
)	O
LSTM	B-Method
works	O
much	O
better	O
than	O
for	O
this	O
task	O
,	O
(	O
b	O
)	O
bidirectional	B-Method
LSTM	I-Method
has	O
a	O
slight	O
advantage	O
over	O
unidirectional	B-Method
LSTMand	I-Method
(	O
c	O
)	O
depth	O
is	O
more	O
important	O
than	O
layer	O
size	O
(	O
which	O
supports	O
previous	O
findings	O
for	O
deep	B-Method
networks	I-Method
)	O
.	O
	
Although	O
the	O
advantage	O
of	O
the	O
transducer	O
is	O
slight	O
when	O
the	O
weights	O
are	O
randomly	O
initialised	O
,	O
it	O
becomes	O
more	O
substantial	O
when	O
pretraining	B-Task
is	O
used	O
.	O
	
section	O
:	O
Conclusions	O
and	O
future	O
work	O
	
We	O
have	O
shown	O
that	O
the	O
combination	O
of	O
deep	B-Method
,	I-Method
bidirectional	I-Method
Long	I-Method
Short	I-Method
-	I-Method
term	I-Method
Memory	I-Method
RNNs	I-Method
with	O
end	B-Method
-	I-Method
to	I-Method
-	I-Method
end	I-Method
training	I-Method
and	O
weight	O
noise	O
gives	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
results	O
in	O
phoneme	B-Task
recognition	I-Task
on	O
the	O
TIMIT	B-Material
database	I-Material
.	O
	
An	O
obvious	O
next	O
step	O
is	O
to	O
extend	O
the	O
system	O
to	O
large	O
vocabulary	O
speech	B-Task
recognition	O
.	O
	
Another	O
interesting	O
direction	O
would	O
be	O
to	O
combine	O
frequency	B-Method
-	I-Method
domain	I-Method
convolutional	I-Method
neural	I-Method
networks	I-Method
with	O
deep	B-Method
LSTM	I-Method
.	O
	
bibliography	O
:	O
References	O
	
document	O
:	O
Image	B-Task
Restoration	I-Task
Using	O
Very	O
Deep	B-Method
Convolutional	I-Method
Encoder	I-Method
-	I-Method
Decoder	I-Method
Networks	I-Method
with	O
Symmetric	B-Method
Skip	I-Method
Connections	I-Method
	
In	O
this	O
paper	O
,	O
we	O
propose	O
a	O
very	O
deep	B-Method
fully	I-Method
convolutional	I-Method
encoding	I-Method
-	I-Method
decoding	I-Method
framework	I-Method
for	O
image	B-Task
restoration	I-Task
such	O
as	O
denoising	B-Task
and	O
super	B-Task
-	I-Task
resolution	I-Task
.	O
	
The	O
network	O
is	O
composed	O
of	O
multiple	O
layers	B-Method
of	I-Method
convolution	I-Method
and	I-Method
de	I-Method
-	I-Method
convolution	I-Method
operators	I-Method
,	O
learning	O
end	O
-	O
to	O
-	O
end	O
mappings	O
from	O
corrupted	O
images	O
to	O
the	O
original	O
ones	O
.	O
	
The	O
convolutional	B-Method
layers	I-Method
act	O
as	O
the	O
feature	B-Method
extractor	I-Method
,	O
which	O
capture	O
the	O
abstraction	O
of	O
image	O
contents	O
while	O
eliminating	O
noises	O
/	O
corruptions	O
.	O
	
De	B-Method
-	I-Method
convolutional	I-Method
layers	I-Method
are	O
then	O
used	O
to	O
recover	O
the	O
image	O
details	O
.	O
	
We	O
propose	O
to	O
symmetrically	O
link	O
convolutional	B-Method
and	I-Method
de	I-Method
-	I-Method
convolutional	I-Method
layers	I-Method
with	O
skip	B-Method
-	I-Method
layer	I-Method
connections	I-Method
,	O
with	O
which	O
the	O
training	O
converges	O
much	O
faster	O
and	O
attains	O
a	O
higher	O
-	O
quality	O
local	B-Metric
optimum	I-Metric
.	O
	
First	O
,	O
The	O
skip	O
connections	O
allow	O
the	O
signal	O
to	O
be	O
back	O
-	O
propagated	O
to	O
bottom	O
layers	O
directly	O
,	O
and	O
thus	O
tackles	O
the	O
problem	O
of	O
gradient	B-Task
vanishing	I-Task
,	O
making	O
training	O
deep	B-Method
networks	I-Method
easier	O
and	O
achieving	O
restoration	B-Task
performance	O
gains	O
consequently	O
.	O
	
Second	O
,	O
these	O
skip	O
connections	O
pass	O
image	O
details	O
from	O
convolutional	B-Method
layers	I-Method
to	O
de	B-Method
-	I-Method
convolutional	I-Method
layers	I-Method
,	O
which	O
is	O
beneficial	O
in	O
recovering	O
the	O
original	O
image	O
.	O
	
Significantly	O
,	O
with	O
the	O
large	O
capacity	O
,	O
we	O
can	O
handle	O
different	O
levels	O
of	O
noises	O
using	O
a	O
single	O
model	O
.	O
	
Experimental	O
results	O
show	O
that	O
our	O
network	O
achieves	O
better	O
performance	O
than	O
all	O
previously	O
reported	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
methods	O
.	O
	
.	O
/	O
figs	O
/	O
	
section	O
:	O
Introduction	O
	
The	O
task	O
of	O
image	B-Task
restoration	I-Task
is	O
to	O
recover	O
an	O
clean	O
image	O
from	O
its	O
corrupted	O
observation	O
,	O
which	O
is	O
known	O
to	O
be	O
an	O
ill	B-Task
-	I-Task
posed	I-Task
inverse	I-Task
problem	I-Task
.	O
	
By	O
accommodating	O
different	O
types	O
of	O
corruption	O
distributions	O
,	O
the	O
same	O
mathematical	B-Method
model	I-Method
applies	O
to	O
problems	O
such	O
as	O
image	O
denoising	B-Task
and	O
super	B-Task
-	I-Task
resolution	I-Task
.	O
	
Recently	O
,	O
deep	B-Method
neural	I-Method
networks	I-Method
(	O
DNNs	B-Method
)	O
have	O
shown	O
their	O
superior	O
performance	O
in	O
image	B-Task
processing	I-Task
and	O
computer	B-Task
vision	I-Task
tasks	I-Task
,	O
ranging	O
from	O
high	B-Task
-	I-Task
level	I-Task
recognition	I-Task
,	O
semantic	B-Task
segmentation	I-Task
to	O
low	O
-	O
level	O
denoising	B-Task
,	O
super	B-Task
-	I-Task
resolution	I-Task
,	O
deblur	B-Task
,	O
inpainting	B-Task
and	O
recovering	B-Task
raw	I-Task
images	I-Task
from	O
compressed	O
images	O
.	O
	
Despite	O
the	O
progress	O
that	O
DNNs	B-Method
achieve	O
,	O
there	O
still	O
are	O
some	O
problems	O
.	O
	
For	O
example	O
,	O
can	O
a	O
deeper	B-Method
network	I-Method
in	O
general	O
achieve	O
better	O
performance	O
;	O
can	O
we	O
design	O
a	O
single	O
model	O
to	O
handle	O
different	O
levels	O
of	O
corruption	O
.	O
	
Observing	O
recent	O
superior	O
performance	O
of	O
DNNs	B-Method
on	O
image	B-Task
processing	I-Task
tasks	I-Task
,	O
we	O
propose	O
a	O
convolutional	B-Method
neural	I-Method
network	I-Method
(	O
CNN	B-Method
)-	O
based	O
framework	O
for	O
image	B-Task
restoration	I-Task
.	O
	
We	O
observe	O
that	O
in	O
order	O
to	O
obtain	O
good	O
restoration	B-Task
performance	O
,	O
it	O
is	O
beneficial	O
to	O
train	O
a	O
very	O
deep	B-Method
model	I-Method
.	O
	
Meanwhile	O
,	O
we	O
show	O
that	O
it	O
is	O
possible	O
to	O
achieve	O
good	O
performance	O
with	O
a	O
single	O
network	O
when	O
processing	O
multiple	O
different	O
levels	O
of	O
corruptions	O
due	O
to	O
the	O
benefits	O
of	O
large	B-Method
-	I-Method
capacity	I-Method
networks	I-Method
.	O
	
Specifically	O
,	O
the	O
proposed	O
framework	O
learns	O
end	O
-	O
to	O
-	O
end	O
fully	B-Method
convolutional	I-Method
mappings	I-Method
from	O
corrupted	O
images	O
to	O
the	O
clean	O
ones	O
.	O
	
The	O
network	O
is	O
composed	O
of	O
multiple	B-Method
layers	I-Method
of	I-Method
convolution	I-Method
and	I-Method
de	I-Method
-	I-Method
convolution	I-Method
operators	I-Method
.	O
	
As	O
deeper	B-Method
networks	I-Method
tend	O
to	O
be	O
more	O
difficult	O
to	O
train	O
,	O
we	O
propose	O
to	O
symmetrically	O
link	O
convolutional	B-Method
and	I-Method
de	I-Method
-	I-Method
convolutional	I-Method
layers	I-Method
with	O
skip	O
-	O
layer	O
connections	O
,	O
with	O
which	O
the	O
training	O
converges	O
much	O
faster	O
and	O
attains	O
a	O
higher	O
-	O
quality	O
local	O
optimum	O
.	O
	
Our	O
main	O
contributions	O
are	O
briefly	O
outlined	O
as	O
follows	O
:	O
1	O
)	O
A	O
very	O
deep	B-Method
network	I-Method
architecture	I-Method
,	O
which	O
consists	O
of	O
a	O
chain	B-Method
of	I-Method
symmetric	I-Method
convolutional	I-Method
and	I-Method
deconvolutional	I-Method
layers	I-Method
,	O
for	O
image	B-Task
restoration	I-Task
is	O
proposed	O
in	O
this	O
paper	O
.	O
	
The	O
convolutional	B-Method
layers	I-Method
act	O
as	O
the	O
feature	B-Method
extractor	I-Method
which	O
encode	O
the	O
primary	O
components	O
of	O
image	O
contents	O
while	O
eliminating	O
the	O
corruption	O
.	O
	
The	O
deconvolutional	B-Method
layers	I-Method
then	O
decode	O
the	O
image	B-Task
abstraction	I-Task
to	O
recover	O
the	O
image	O
content	O
details	O
.	O
	
2	O
)	O
	
We	O
propose	O
to	O
add	O
skip	O
connections	O
between	O
corresponding	O
convolutional	B-Method
and	I-Method
de	I-Method
-	I-Method
convolutional	I-Method
layers	I-Method
.	O
	
These	O
skip	O
connections	O
help	O
to	O
back	O
-	O
propagate	O
the	O
gradients	O
to	O
bottom	O
layers	O
and	O
pass	O
image	O
details	O
to	O
the	O
top	O
layers	O
,	O
making	O
training	O
of	O
the	O
end	B-Task
-	I-Task
to	I-Task
-	I-Task
end	I-Task
mapping	I-Task
more	O
easier	O
and	O
effective	O
,	O
and	O
thus	O
achieve	O
performance	O
improvement	O
while	O
the	O
network	O
going	O
deeper	O
.	O
	
3	O
)	O
	
Relying	O
on	O
the	O
large	O
capacity	O
and	O
fitting	O
ability	O
of	O
our	O
very	O
deep	B-Method
network	I-Method
,	O
we	O
propose	O
to	O
handle	O
different	O
level	O
of	O
noises	O
/	O
corruption	O
using	O
a	O
single	O
model	O
.	O
	
To	O
our	O
knowledge	O
,	O
this	O
is	O
the	O
first	O
approach	O
that	O
achieves	O
good	O
accuracy	B-Metric
for	O
processing	O
different	O
levels	O
of	O
noises	O
with	O
a	O
single	O
model	O
.	O
	
4	O
)	O
	
Experimental	O
results	O
demonstrate	O
the	O
advantages	O
of	O
our	O
network	O
over	O
other	O
recent	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
methods	O
on	O
image	O
denoising	B-Task
and	O
super	B-Task
-	I-Task
resolution	I-Task
,	O
setting	O
new	O
records	O
on	O
these	O
topics	O
.	O
	
Related	O
work	O
Extensive	O
work	O
has	O
been	O
done	O
on	O
image	B-Task
restoration	I-Task
in	O
the	O
literature	O
.	O
	
See	O
detail	O
reviews	O
in	O
a	O
survey	O
.	O
	
Traditional	O
methods	O
such	O
as	O
Total	B-Method
variation	I-Method
,	O
BM3D	B-Method
algorithm	I-Method
and	O
dictionary	B-Method
learning	I-Method
based	I-Method
methods	I-Method
have	O
shown	O
very	O
good	O
performance	O
on	O
image	B-Task
restoration	I-Task
topics	I-Task
such	O
as	O
image	O
denoising	B-Task
and	O
super	B-Task
-	I-Task
resolution	I-Task
.	O
	
Since	O
image	B-Task
restoration	I-Task
is	O
in	O
general	O
an	O
ill	B-Task
-	I-Task
posed	I-Task
problem	I-Task
,	O
the	O
use	O
of	O
regularization	B-Method
has	O
been	O
proved	O
to	O
be	O
essential	O
.	O
	
An	O
active	O
(	O
and	O
probably	O
more	O
promising	O
)	O
category	O
for	O
image	B-Task
restoration	I-Task
is	O
the	O
DNN	B-Method
based	I-Method
methods	I-Method
.	O
	
Stacked	O
denoising	B-Task
auto	O
-	O
encoder	O
is	O
one	O
of	O
the	O
most	O
well	O
-	O
known	O
DNN	B-Method
models	I-Method
which	O
can	O
be	O
used	O
for	O
image	B-Task
restoration	I-Task
.	O
	
Xie	O
et	O
al	O
.	O
	
combined	O
sparse	B-Method
coding	I-Method
and	O
DNN	B-Method
pre	I-Method
-	O
trained	O
with	O
denoising	B-Task
auto	O
-	O
encoder	O
for	O
low	B-Task
-	I-Task
level	I-Task
vision	I-Task
tasks	I-Task
such	O
as	O
image	O
denoising	B-Task
and	O
inpainting	B-Task
.	O
	
Other	O
neural	B-Method
networks	I-Method
based	I-Method
methods	I-Method
such	O
as	O
multi	O
-	O
layer	O
perceptron	O
and	O
CNN	B-Method
for	O
image	O
denoising	B-Task
,	O
as	O
well	O
as	O
DNN	B-Method
for	O
image	O
or	O
video	O
super	B-Task
-	I-Task
resolution	I-Task
and	O
compression	B-Task
artifacts	I-Task
reduction	I-Task
have	O
been	O
actively	O
studied	O
in	O
these	O
years	O
.	O
	
Burger	O
et	O
al	O
.	O
presented	O
a	O
patch	B-Method
-	I-Method
based	I-Method
algorithm	I-Method
learned	O
with	O
a	O
plain	B-Method
multi	I-Method
-	I-Method
layer	I-Method
perceptron	I-Method
.	O
	
They	O
also	O
concluded	O
that	O
with	O
large	B-Method
networks	I-Method
,	O
large	O
training	O
data	O
,	O
neural	B-Method
networks	I-Method
can	O
achieve	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
image	O
denoising	B-Task
performance	O
.	O
	
Jain	O
and	O
Seung	O
proposed	O
fully	O
convolutional	O
CNN	B-Method
for	O
denoising	B-Task
.	O
	
They	O
found	O
that	O
CNN	B-Method
provide	O
comparable	O
or	O
even	O
superior	O
performance	O
to	O
wavelet	B-Method
and	I-Method
Markov	I-Method
Random	I-Method
Field	I-Method
(	I-Method
MRF	I-Method
)	I-Method
methods	I-Method
.	O
	
Cui	O
et	O
al	O
.	O
employed	O
non	B-Method
-	I-Method
local	I-Method
self	I-Method
-	I-Method
similarity	I-Method
(	I-Method
NLSS	I-Method
)	I-Method
search	I-Method
on	O
the	O
input	O
image	O
in	O
multi	O
-	O
scale	O
,	O
and	O
then	O
used	O
collaborative	B-Method
local	I-Method
auto	I-Method
-	I-Method
encoder	I-Method
for	O
super	B-Task
-	I-Task
resolution	I-Task
in	O
a	O
layer	O
by	O
layer	O
fashion	O
.	O
	
Dong	O
et	O
al	O
.	O
proposed	O
to	O
directly	O
learn	O
an	O
end	B-Task
-	I-Task
to	I-Task
-	I-Task
end	I-Task
mapping	I-Task
between	O
the	O
low	O
/	O
high	O
-	O
resolution	O
images	O
.	O
	
Wang	O
et	O
al	O
.	O
argued	O
that	O
domain	O
expertise	O
represented	O
by	O
the	O
conventional	O
sparse	B-Method
coding	I-Method
can	O
be	O
combined	O
to	O
achieve	O
further	O
improved	O
results	O
.	O
	
In	O
general	O
,	O
DNN	B-Method
-	I-Method
based	I-Method
methods	I-Method
learn	O
restoration	O
parameters	O
directly	O
from	O
data	O
,	O
which	O
tends	O
to	O
been	O
more	O
effective	O
in	O
real	O
-	O
world	B-Task
image	I-Task
restoration	I-Task
applications	I-Task
.	O
	
An	O
advantage	O
of	O
DNN	B-Method
methods	I-Method
is	O
that	O
these	O
methods	O
are	O
purely	O
data	O
driven	O
and	O
no	O
assumption	O
about	O
the	O
noise	O
distributions	O
are	O
made	O
.	O
	
section	O
:	O
Very	O
deep	O
RED	B-Method
-	I-Method
Net	I-Method
for	O
Image	B-Task
Restoration	I-Task
	
The	O
proposed	O
framework	O
mainly	O
contains	O
a	O
chain	B-Method
of	I-Method
convolutional	I-Method
layers	I-Method
and	O
symmetric	B-Method
deconvolutional	I-Method
layers	I-Method
,	O
as	O
shown	O
in	O
Figure	O
[	O
reference	O
]	O
.	O
	
We	O
term	O
our	O
method	O
	
‘	O
‘	O
RED	B-Method
-	I-Method
Net’’—very	I-Method
deep	I-Method
Residual	I-Method
Encoder	I-Method
-	I-Method
Decoder	I-Method
Networks	I-Method
.	O
	
subsection	O
:	O
Architecture	O
	
The	O
framework	O
is	O
fully	O
convolutional	B-Method
and	I-Method
deconvolutional	I-Method
.	O
	
Rectification	B-Method
layers	I-Method
are	O
added	O
after	O
each	O
convolution	B-Method
and	I-Method
deconvolution	I-Method
.	O
	
The	O
convolutional	B-Method
layers	I-Method
act	O
as	O
feature	B-Method
extractor	I-Method
,	O
which	O
preserve	O
the	O
primary	O
components	O
of	O
objects	O
in	O
the	O
image	O
and	O
meanwhile	O
eliminating	O
the	O
corruptions	O
.	O
	
The	O
deconvolutional	B-Method
layers	I-Method
are	O
then	O
combined	O
to	O
recover	O
the	O
details	O
of	O
image	O
contents	O
.	O
	
The	O
output	O
of	O
the	O
deconvolutional	B-Method
layers	I-Method
is	O
the	O
‘	O
‘	O
clean	O
’	O
’	O
version	O
of	O
the	O
input	O
image	O
.	O
	
Moreover	O
,	O
skip	O
connections	O
are	O
also	O
added	O
from	O
a	O
convolutional	B-Method
layer	I-Method
to	O
its	O
corresponding	O
mirrored	B-Method
deconvolutional	I-Method
layer	I-Method
.	O
	
The	O
passed	O
convolutional	O
feature	O
maps	O
are	O
summed	O
to	O
the	O
deconvolutional	O
feature	O
maps	O
element	O
-	O
wise	O
,	O
and	O
passed	O
to	O
the	O
next	O
layer	O
after	O
rectification	B-Task
.	O
	
For	O
low	B-Task
-	I-Task
level	I-Task
image	I-Task
restoration	I-Task
problems	I-Task
,	O
we	O
use	O
neither	O
pooling	B-Method
nor	O
unpooling	B-Method
in	O
the	O
network	O
as	O
usually	O
pooling	B-Method
discards	O
useful	O
image	O
details	O
that	O
are	O
essential	O
for	O
these	O
tasks	O
.	O
	
Motivated	O
by	O
the	O
VGG	B-Method
model	I-Method
,	O
the	O
kernel	B-Method
size	I-Method
for	O
convolution	B-Method
and	I-Method
deconvolution	I-Method
is	O
set	O
to	O
,	O
which	O
has	O
shown	O
excellent	O
image	B-Task
recognition	I-Task
performance	O
.	O
	
It	O
is	O
worth	O
mentioning	O
that	O
the	O
size	O
of	O
input	O
image	O
can	O
be	O
arbitrary	O
since	O
our	O
network	O
is	O
essentially	O
a	O
pixel	B-Method
-	I-Method
wise	I-Method
prediction	I-Method
.	O
	
The	O
input	O
and	O
output	O
of	O
the	O
network	O
are	O
images	O
of	O
the	O
same	O
size	O
,	O
where	O
,	O
and	O
are	O
width	O
,	O
height	O
and	O
number	O
of	O
channels	O
.	O
	
In	O
this	O
paper	O
,	O
we	O
use	O
although	O
it	O
is	O
straightforward	O
to	O
apply	O
to	O
images	O
with	O
.	O
	
We	O
found	O
that	O
using	O
64	O
feature	O
maps	O
for	O
convolutional	B-Method
and	I-Method
deconvolutional	I-Method
layers	I-Method
achieves	O
satisfactory	O
results	O
,	O
although	O
more	O
feature	O
maps	O
leads	O
to	O
slightly	O
better	O
performance	O
.	O
	
Deriving	O
from	O
the	O
above	O
architecture	O
,	O
we	O
propose	O
two	O
networks	O
,	O
which	O
are	O
20	O
-	O
layer	O
and	O
30	O
-	O
layer	O
respectively	O
.	O
	
subsubsection	B-Method
:	O
Deconvolution	B-Method
decoder	I-Method
	
Architectures	B-Method
combining	O
layers	B-Method
of	I-Method
convolution	I-Method
and	I-Method
deconvolution	I-Method
have	O
been	O
proposed	O
for	O
semantic	B-Task
segmentation	I-Task
lately	O
.	O
	
In	O
contrast	O
to	O
convolutional	B-Method
layers	I-Method
,	O
in	O
which	O
multiple	O
input	O
activations	O
within	O
a	O
filter	O
window	O
are	O
fused	O
to	O
output	O
a	O
single	O
activation	O
,	O
deconvolutional	B-Method
layers	I-Method
associate	O
a	O
single	O
input	O
activation	O
with	O
multiple	O
outputs	O
.	O
	
One	O
can	O
simply	O
replace	O
deconvolution	B-Method
with	O
convolution	B-Method
,	O
which	O
results	O
in	O
a	O
architecture	O
that	O
is	O
very	O
similar	O
to	O
recently	O
proposed	O
very	O
deep	B-Method
fully	I-Method
convolutional	I-Method
neural	I-Method
networks	I-Method
.	O
	
However	O
,	O
there	O
exist	O
essential	O
differences	O
between	O
a	O
fully	B-Method
convolution	I-Method
model	I-Method
and	O
our	O
model	O
.	O
	
In	O
the	O
fully	B-Task
convolution	I-Task
case	I-Task
,	O
the	O
noise	O
is	O
eliminated	O
step	O
by	O
step	O
,	O
i.e.	O
,	O
the	O
noise	O
level	O
is	O
reduced	O
after	O
each	O
layer	O
.	O
	
During	O
this	O
process	O
,	O
the	O
details	O
of	O
the	O
image	O
content	O
may	O
be	O
lost	O
.	O
	
Nevertheless	O
,	O
in	O
our	O
network	O
,	O
convolution	B-Method
preserves	O
the	O
primary	O
image	O
content	O
.	O
	
Then	O
deconvolution	B-Method
is	O
used	O
to	O
compensate	O
the	O
details	O
.	O
	
We	O
compare	O
the	O
5	B-Method
-	I-Method
layer	I-Method
and	I-Method
10	I-Method
-	I-Method
layer	I-Method
fully	I-Method
convolutional	I-Method
network	I-Method
with	O
our	O
network	O
(	O
combining	O
convolution	B-Method
and	I-Method
deconvolution	I-Method
,	O
but	O
without	O
skip	O
connection	O
)	O
.	O
	
For	O
fully	B-Method
convolutional	I-Method
networks	I-Method
,	O
we	O
use	O
padding	O
and	O
up	O
-	O
sample	O
the	O
input	O
to	O
make	O
the	O
input	O
and	O
output	O
the	O
same	O
size	O
.	O
	
For	O
our	O
network	O
,	O
the	O
first	O
5	O
layers	O
are	O
convolutional	B-Method
and	O
the	O
second	O
5	O
layers	O
are	O
deconvolutional	B-Method
.	O
	
All	O
the	O
other	O
parameters	O
for	O
training	O
are	O
the	O
same	O
,	O
i.e.	O
,	O
trained	O
with	O
SGD	B-Method
and	O
learning	B-Metric
rate	I-Metric
of	O
,	O
noise	B-Metric
level	I-Metric
.	O
	
In	O
terms	O
of	O
PSNR	B-Metric
,	O
using	O
deconvolution	B-Method
works	O
better	O
than	O
the	O
fully	B-Method
convolutional	I-Method
counterpart	I-Method
.	O
	
We	O
see	O
that	O
,	O
the	O
fully	B-Method
convolutional	I-Method
network	I-Method
reduces	O
noise	B-Method
layer	I-Method
by	I-Method
layer	I-Method
,	O
and	O
our	O
network	O
preserve	O
primary	O
image	O
contents	O
by	O
convolution	B-Method
and	O
recover	O
some	O
details	O
by	O
using	O
deconvolution	B-Method
.	O
	
Detailed	O
results	O
are	O
in	O
the	O
supplementary	O
materials	O
.	O
	
subsubsection	B-Method
:	O
Skip	B-Method
connections	I-Method
	
An	O
intuitive	O
question	O
is	O
that	O
,	O
is	O
deconvolution	B-Method
able	O
to	O
recover	O
image	O
details	O
from	O
the	O
image	O
abstraction	O
only	O
?	O
	
We	O
find	O
that	O
in	O
shallow	B-Method
networks	I-Method
with	O
only	O
a	O
few	O
layers	O
of	O
convolution	B-Method
,	O
deconvolution	B-Method
is	O
able	O
to	O
recover	O
the	O
details	O
.	O
	
However	O
,	O
when	O
the	O
network	O
goes	O
deeper	O
or	O
using	O
operations	O
such	O
as	O
max	B-Method
pooling	I-Method
,	O
deconvolution	B-Method
does	O
not	O
work	O
so	O
well	O
,	O
possibly	O
because	O
too	O
much	O
details	O
are	O
already	O
lost	O
in	O
the	O
convolution	B-Method
.	O
	
The	O
second	O
question	O
is	O
that	O
,	O
when	O
our	O
network	O
goes	O
deeper	O
,	O
does	O
it	O
achieve	O
performance	O
gain	O
?	O
	
We	O
observe	O
that	O
deeper	B-Method
networks	I-Method
often	O
suffer	O
from	O
gradients	O
vanishing	O
and	O
become	O
hard	O
to	O
train	O
—	O
a	O
problem	O
that	O
is	O
well	O
addressed	O
in	O
the	O
literature	O
.	O
	
To	O
address	O
the	O
above	O
two	O
problems	O
,	O
inspired	O
by	O
highway	B-Method
networks	I-Method
and	O
deep	B-Method
residual	I-Method
networks	I-Method
,	O
we	O
add	O
skip	O
connections	O
between	O
two	O
corresponding	O
convolutional	B-Method
and	I-Method
deconvolutional	I-Method
layers	I-Method
as	O
shown	O
in	O
Figure	O
[	O
reference	O
]	O
.	O
	
A	O
building	O
block	O
is	O
shown	O
in	O
Figure	O
[	O
reference	O
]	O
.	O
	
There	O
are	O
two	O
reasons	O
for	O
using	O
such	O
connections	O
.	O
	
First	O
,	O
when	O
the	O
network	O
goes	O
deeper	O
,	O
as	O
mentioned	O
above	O
,	O
image	O
details	O
can	O
be	O
lost	O
,	O
making	O
deconvolution	B-Method
weaker	O
in	O
recovering	O
them	O
.	O
	
However	O
,	O
the	O
feature	O
maps	O
passed	O
by	O
skip	B-Method
connections	I-Method
carry	O
much	O
image	O
detail	O
,	O
which	O
helps	O
deconvolution	B-Task
to	O
recover	O
a	O
better	O
clean	O
image	O
.	O
	
Second	O
,	O
the	O
skip	O
connections	O
also	O
achieve	O
benefits	O
on	O
back	O
-	O
propagating	O
the	O
gradient	O
to	O
bottom	O
layer	O
,	O
which	O
makes	O
training	O
deeper	B-Method
network	I-Method
much	O
easier	O
as	O
observed	O
in	O
and	O
.	O
	
Note	O
that	O
our	O
skip	B-Method
layer	I-Method
connections	I-Method
are	O
very	O
different	O
from	O
the	O
ones	O
proposed	O
in	O
and	O
,	O
where	O
the	O
only	O
concern	O
is	O
on	O
the	O
optimization	O
side	O
.	O
	
In	O
our	O
case	O
,	O
we	O
want	O
to	O
pass	O
information	O
of	O
the	O
convolutional	O
feature	O
maps	O
to	O
the	O
corresponding	O
deconvolutional	B-Method
layers	I-Method
.	O
	
Instead	O
of	O
directly	O
learning	O
the	O
mappings	O
from	O
input	O
to	O
the	O
output	O
,	O
we	O
would	O
like	O
the	O
network	O
to	O
fit	O
the	O
residual	O
of	O
the	O
problem	O
,	O
which	O
is	O
denoted	O
as	O
.	O
	
Such	O
a	O
learning	B-Method
strategy	I-Method
is	O
applied	O
to	O
inner	O
blocks	O
of	O
the	O
encoding	B-Method
-	I-Method
decoding	I-Method
network	I-Method
to	O
make	O
training	B-Task
more	O
effective	O
.	O
	
Skip	O
connections	O
are	O
passed	O
every	O
two	O
convolutional	B-Method
layers	I-Method
to	O
their	O
mirrored	B-Method
deconvolutional	I-Method
layers	I-Method
.	O
	
Other	O
configurations	O
are	O
possible	O
and	O
our	O
experiments	O
show	O
that	O
this	O
configuration	O
already	O
works	O
very	O
well	O
.	O
	
Using	O
such	O
shortcuts	O
makes	O
the	O
network	O
easier	O
to	O
be	O
trained	O
and	O
gains	O
restoration	B-Task
performance	O
via	O
increasing	O
network	O
depth	O
.	O
	
The	O
very	O
deep	B-Method
highway	I-Method
networks	I-Method
are	O
essentially	O
feed	B-Method
-	I-Method
forward	I-Method
long	I-Method
short	I-Method
-	I-Method
term	I-Method
memory	I-Method
(	I-Method
LSTMs	I-Method
)	I-Method
with	O
forget	B-Method
gates	I-Method
;	O
and	O
the	O
CNN	B-Method
layers	O
of	O
deep	B-Method
residual	I-Method
network	I-Method
are	O
feed	B-Method
-	I-Method
forward	I-Method
LSTMs	I-Method
without	I-Method
gates	I-Method
.	O
	
Note	O
that	O
our	O
deep	B-Method
residual	I-Method
networks	I-Method
are	O
in	O
general	O
not	O
in	O
the	O
format	O
of	O
standard	O
feed	B-Method
-	I-Method
forward	I-Method
LSTMs	I-Method
.	O
	
subsection	O
:	O
Discussions	O
	
Training	O
with	O
symmetric	O
skip	O
connections	O
As	O
mentioned	O
above	O
,	O
using	O
skip	O
connections	O
mainly	O
has	O
two	O
benefits	O
:	O
(	O
1	O
)	O
passing	O
image	O
detail	O
forwardly	O
,	O
which	O
helps	O
recovering	O
clean	O
images	O
and	O
(	O
2	O
)	O
passing	O
gradient	O
backwardly	O
,	O
which	O
helps	O
finding	O
better	O
local	O
minimum	O
.	O
	
We	O
design	O
experiments	O
to	O
show	O
these	O
observations	O
.	O
	
We	O
first	O
compare	O
two	O
networks	O
trained	O
for	O
denoising	B-Task
noises	O
of	O
.	O
	
In	O
the	O
first	O
network	O
,	O
we	O
use	O
5	O
layers	O
of	O
convolution	B-Method
with	O
stride	O
3	O
.	O
	
The	O
input	O
size	O
of	O
training	O
data	O
is	O
,	O
which	O
results	O
in	O
a	O
vector	O
after	O
5	O
layers	O
of	O
convolution	B-Method
.	O
	
Then	O
deconvolution	B-Method
is	O
used	O
to	O
recover	O
the	O
input	O
.	O
	
The	O
second	O
network	O
uses	O
the	O
same	O
settings	O
as	O
the	O
first	O
one	O
,	O
except	O
for	O
adding	O
skip	O
connections	O
.	O
	
The	O
results	O
are	O
show	O
in	O
Figure	O
[	O
reference	O
]	O
	
(	O
a	O
)	O
.	O
	
We	O
can	O
observe	O
that	O
it	O
is	O
hard	O
for	O
deconvolution	B-Task
to	O
recover	O
details	O
from	O
only	O
a	O
vector	O
encoding	O
the	O
abstraction	O
of	O
the	O
input	O
,	O
which	O
shows	O
that	O
the	O
ability	O
on	O
recovering	B-Task
image	I-Task
details	I-Task
for	O
deconvolution	B-Task
is	O
limited	O
.	O
	
However	O
,	O
if	O
we	O
use	O
skip	O
connections	O
,	O
the	O
network	O
can	O
still	O
recover	O
the	O
input	O
,	O
because	O
details	O
are	O
passed	O
to	O
topper	O
layers	O
in	O
the	O
network	O
.	O
	
We	O
also	O
train	O
five	O
networks	O
to	O
show	O
that	O
using	O
skip	O
connections	O
help	O
to	O
back	O
-	O
propagate	O
gradient	O
in	O
training	O
to	O
better	O
fit	O
the	O
end	O
-	O
to	O
-	O
end	B-Task
mapping	I-Task
,	O
as	O
shown	O
in	O
Figure	O
[	O
reference	O
]	O
	
(	O
b	O
)	O
.	O
	
The	O
five	O
networks	O
are	O
:	O
10	O
,	O
20	O
and	O
30	O
layer	B-Method
networks	I-Method
without	O
skip	O
connections	O
,	O
and	O
20	O
,	O
30	B-Method
layer	I-Method
networks	I-Method
with	O
skip	O
connections	O
.	O
	
As	O
we	O
can	O
see	O
,	O
the	O
training	B-Metric
loss	I-Metric
increases	O
when	O
the	O
network	O
going	O
deeper	O
without	O
shortcuts	O
(	O
similar	O
phenomenon	O
is	O
also	O
observed	O
in	O
)	O
,	O
but	O
we	O
obtain	O
smaller	O
loss	B-Metric
when	O
using	O
skip	O
connections	O
.	O
	
Comparison	O
with	O
deep	B-Method
residual	I-Method
networks	I-Method
[	O
]	O
One	O
may	O
use	O
different	O
types	O
of	O
skip	O
connections	O
in	O
our	O
network	O
,	O
a	O
straightforward	O
alternate	O
is	O
that	O
in	O
.	O
	
In	O
,	O
the	O
skip	O
connections	O
are	O
added	O
to	O
divide	O
the	O
network	O
into	O
sequential	O
blocks	O
.	O
	
A	O
benefit	O
of	O
our	O
model	O
is	O
that	O
our	O
skip	O
connections	O
have	O
element	O
-	O
wise	O
correspondence	O
,	O
which	O
can	O
be	O
very	O
important	O
in	O
pixel	B-Task
-	I-Task
wise	I-Task
prediction	I-Task
problems	I-Task
.	O
	
We	O
carry	O
out	O
experiments	O
to	O
compare	O
the	O
two	O
types	O
of	O
skip	O
connections	O
.	O
	
Here	O
the	O
block	O
size	O
indicates	O
the	O
span	O
of	O
the	O
connections	O
.	O
	
The	O
results	O
are	O
shown	O
in	O
Figure	O
[	O
reference	O
]	O
	
(	O
c	O
)	O
.	O
	
We	O
can	O
observe	O
that	O
our	O
connections	O
often	O
converge	O
to	O
a	O
better	O
optimum	O
,	O
demonstrating	O
that	O
element	O
-	O
wise	O
correspondence	O
can	O
be	O
important	O
.	O
	
Dealing	O
with	O
different	O
levels	O
of	O
noises	O
/	O
corruption	O
	
An	O
important	O
question	O
is	O
,	O
can	O
we	O
handle	O
different	O
levels	O
of	O
corruption	O
with	O
a	O
single	O
model	O
.	O
	
Almost	O
all	O
existing	O
methods	O
need	O
to	O
train	O
different	O
models	O
for	O
different	O
levels	O
of	O
corruption	O
and	O
estimate	O
the	O
corruption	O
level	O
at	O
first	O
.	O
	
We	O
use	O
a	O
trained	O
model	O
in	O
,	O
to	O
denoise	O
different	O
levels	O
of	O
noises	O
with	O
being	O
10	O
,	O
30	O
,	O
50	O
and	O
70	O
.	O
	
The	O
obtained	O
average	O
PSNR	B-Metric
on	O
the	O
14	O
images	O
are	O
29.95dB	O
,	O
27.81dB	O
,	O
18.62dB	O
and	O
14.84dB	O
,	O
respectively	O
.	O
	
The	O
results	O
show	O
that	O
the	O
parameters	O
trained	O
on	O
a	O
single	O
noise	O
level	O
can	O
not	O
handle	O
different	O
levels	O
of	O
noises	O
well	O
.	O
	
Therefore	O
,	O
in	O
this	O
paper	O
,	O
we	O
aim	O
to	O
train	O
a	O
single	O
model	O
for	O
recovering	O
different	O
levels	O
of	O
corruption	O
,	O
which	O
are	O
different	O
noise	O
levels	O
in	O
the	O
task	O
of	O
image	O
denoising	B-Task
and	O
different	O
scaling	O
parameters	O
in	O
image	O
super	B-Task
-	I-Task
resolution	I-Task
.	O
	
The	O
large	O
capacity	O
of	O
the	O
network	O
is	O
the	O
key	O
to	O
this	O
success	O
.	O
	
subsection	O
:	O
Training	O
	
Learning	O
the	O
end	B-Task
-	I-Task
to	I-Task
-	I-Task
end	I-Task
mapping	I-Task
from	O
corrupted	O
images	O
to	O
clean	O
ones	O
needs	O
to	O
estimate	O
the	O
weights	O
represented	O
by	O
the	O
convolutional	B-Method
and	I-Method
deconvolutional	I-Method
kernels	I-Method
.	O
	
This	O
is	O
achieved	O
by	O
minimizing	O
the	O
Euclidean	O
loss	O
between	O
the	O
outputs	O
of	O
the	O
network	O
and	O
the	O
clean	O
image	O
.	O
	
In	O
specific	O
,	O
given	O
a	O
collection	O
of	O
training	O
sample	O
pairs	O
,	O
where	O
is	O
a	O
corrupted	O
image	O
and	O
is	O
the	O
clean	O
version	O
as	O
the	O
groundtruth	O
.	O
	
We	O
minimize	O
the	O
following	O
Mean	B-Metric
Squared	I-Metric
Error	I-Metric
(	I-Metric
MSE	I-Metric
)	I-Metric
:	O
We	O
implement	O
and	O
train	O
our	O
network	O
using	O
Caffe	B-Method
.	O
	
In	O
practice	O
,	O
we	O
find	O
that	O
using	O
Adam	B-Method
with	O
learning	B-Method
rate	I-Method
for	O
training	B-Task
converges	O
faster	O
than	O
traditional	O
stochastic	B-Method
gradient	I-Method
descent	I-Method
(	O
SGD	B-Method
)	O
.	O
	
The	O
base	O
learning	B-Metric
rate	I-Metric
for	O
all	O
layers	O
are	O
the	O
same	O
,	O
different	O
from	O
,	O
in	O
which	O
a	O
smaller	O
learning	B-Metric
rate	I-Metric
is	O
set	O
for	O
the	O
last	O
layer	O
.	O
	
This	O
trick	O
is	O
not	O
necessary	O
in	O
our	O
network	O
.	O
	
As	O
general	O
settings	O
in	O
the	O
literature	O
,	O
we	O
use	O
gray	O
-	O
scale	O
image	O
for	O
denoising	B-Task
and	O
the	O
luminance	O
channel	O
for	O
super	B-Task
-	I-Task
resolution	I-Task
in	O
this	O
paper	O
.	O
	
300	O
images	O
from	O
the	O
Berkeley	B-Material
Segmentation	I-Material
Dataset	I-Material
(	O
BSD	B-Material
)	O
are	O
used	O
to	O
generate	O
the	O
training	O
set	O
.	O
	
For	O
each	O
image	O
,	O
patches	O
of	O
size	O
are	O
sampled	O
as	O
ground	O
truth	O
.	O
	
For	O
denoising	B-Task
,	O
we	O
add	O
additive	O
Gaussian	O
noise	O
to	O
the	O
patches	O
multiple	O
times	O
to	O
generate	O
a	O
large	O
training	O
set	O
(	O
about	O
0.5	O
M	O
)	O
.	O
	
For	O
super	B-Task
-	I-Task
resolution	I-Task
,	O
we	O
first	O
down	O
-	O
sample	O
a	O
patch	O
	
and	O
then	O
up	O
-	O
sample	O
it	O
to	O
its	O
original	O
size	O
,	O
obtaining	O
a	O
low	O
-	O
resolution	O
version	O
as	O
the	O
input	O
of	O
the	O
network	O
.	O
	
subsection	O
:	O
Testing	O
	
Although	O
trained	O
on	O
local	O
patches	O
,	O
our	O
network	O
can	O
perform	O
denoising	B-Task
and	O
super	B-Task
-	I-Task
resolution	I-Task
on	O
images	O
of	O
arbitrary	O
size	O
.	O
	
Given	O
a	O
testing	O
image	O
,	O
one	O
can	O
simply	O
go	O
forward	O
through	O
the	O
network	O
,	O
which	O
is	O
able	O
to	O
obtain	O
a	O
better	O
performance	O
than	O
existing	O
methods	O
.	O
	
To	O
achieve	O
more	O
smooth	O
results	O
,	O
we	O
propose	O
to	O
process	O
a	O
corrupted	O
image	O
on	O
multiple	O
orientations	O
.	O
	
Different	O
from	O
segmentation	B-Task
,	O
the	O
filter	B-Method
kernels	I-Method
in	O
our	O
network	O
only	O
eliminate	O
the	O
corruptions	O
,	O
which	O
is	O
not	O
sensitive	O
to	O
the	O
orientation	O
of	O
image	O
contents	O
.	O
	
Therefore	O
,	O
we	O
can	O
rotate	O
and	O
mirror	O
flip	O
the	O
kernels	O
and	O
perform	O
forward	O
multiple	O
times	O
,	O
and	O
then	O
average	O
the	O
output	O
to	O
get	O
a	O
more	O
smooth	O
image	O
.	O
	
We	O
see	O
that	O
this	O
can	O
lead	O
to	O
slightly	O
better	O
denoising	B-Task
and	O
super	B-Task
-	I-Task
resolution	I-Task
performance	O
.	O
	
section	O
:	O
Experiments	O
	
In	O
this	O
section	O
,	O
we	O
provide	O
evaluation	O
of	O
denoising	B-Task
and	O
super	B-Task
-	I-Task
resolution	I-Task
performance	O
of	O
our	O
models	O
against	O
a	O
few	O
existing	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
methods	O
.	O
	
Denoising	B-Task
experiments	O
are	O
performed	O
on	O
two	O
datasets	O
:	O
14	O
common	O
benchmark	O
images	O
and	O
the	O
BSD200	O
dataset	O
.	O
	
We	O
test	O
additive	O
Gaussian	O
noises	O
with	O
zero	O
mean	O
and	O
standard	O
deviation	O
10	O
,	O
30	O
,	O
50	O
and	O
70	O
respectively	O
.	O
	
BM3D	B-Method
,	O
NCSR	B-Method
,	O
EPLL	B-Method
,	O
PCLR	B-Method
,	O
PDPD	B-Method
and	O
WMMN	B-Method
are	O
compared	O
with	O
our	O
method	O
.	O
	
For	O
super	B-Task
-	I-Task
resolution	I-Task
,	O
we	O
compare	O
our	O
network	O
with	O
SRCNN	B-Method
,	O
NBSRF	B-Method
,	O
CSCN	B-Method
,	O
CSC	B-Method
,	O
TSE	B-Method
and	O
ARFL	B-Method
+	I-Method
on	O
three	O
dataset	O
:	O
	
Set5	B-Material
,	O
Set14	O
and	O
BSD100	B-Material
.	O
	
The	O
scaling	O
parameter	O
are	O
tested	O
with	O
2	O
,	O
3	O
and	O
4	O
.	O
	
Peak	B-Metric
Signal	I-Metric
-	I-Metric
to	I-Metric
-	I-Metric
Noise	I-Metric
Ratio	I-Metric
(	O
PSNR	B-Metric
)	O
and	O
Structural	B-Metric
SIMilarity	I-Metric
(	O
SSIM	B-Metric
)	O
index	O
are	O
calculated	O
for	O
evaluation	O
.	O
	
For	O
our	O
method	O
,	O
which	O
is	O
denoted	O
as	O
RED	B-Method
-	I-Method
Net	I-Method
,	O
we	O
implement	O
three	O
versions	O
:	O
	
RED10	B-Method
contains	O
5	O
convolutional	B-Method
and	I-Method
deconvolutional	I-Method
layers	I-Method
without	O
shortcuts	B-Method
,	O
RED20	B-Method
contains	O
10	O
convolutional	B-Method
and	I-Method
deconvolutional	I-Method
layers	I-Method
with	O
shortcuts	B-Method
,	O
and	O
RED30	B-Method
contains	O
15	O
convolutional	B-Method
and	I-Method
deconvolutional	I-Method
layers	I-Method
with	O
shortcuts	B-Method
.	O
	
subsection	O
:	O
Image	B-Task
Denoising	I-Task
	
Evaluation	O
on	O
the	O
14	O
images	O
Table	O
[	O
reference	O
]	O
presents	O
the	O
PSNR	B-Metric
and	O
SSIM	B-Metric
results	O
of	O
10	O
,	O
30	O
,	O
50	O
,	O
and	O
70	O
.	O
	
We	O
can	O
make	O
some	O
observations	O
from	O
the	O
results	O
.	O
	
First	O
of	O
all	O
,	O
the	O
10	B-Method
layer	I-Method
convolutional	I-Method
and	I-Method
deconvolutional	I-Method
network	I-Method
has	O
already	O
achieved	O
better	O
results	O
than	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
methods	O
,	O
which	O
demonstrates	O
that	O
combining	O
convolution	B-Method
and	I-Method
deconvolution	I-Method
for	O
denoising	B-Task
works	O
well	O
,	O
even	O
without	O
any	O
skip	O
connections	O
.	O
	
Moreover	O
,	O
when	O
the	O
network	O
goes	O
deeper	O
,	O
the	O
skip	O
connections	O
proposed	O
in	O
this	O
paper	O
help	O
to	O
achieve	O
even	O
better	O
denoising	B-Task
performance	O
,	O
which	O
exceeds	O
the	O
existing	O
best	O
method	O
WNNM	B-Method
by	O
0.32dB	O
,	O
0.43dB	O
,	O
0.49dB	O
and	O
0.51dB	O
on	O
noise	B-Metric
levels	I-Metric
of	O
being	O
10	O
,	O
30	O
,	O
50	O
and	O
70	O
respectively	O
.	O
	
While	O
WNNM	B-Method
is	O
only	O
slightly	O
better	O
than	O
the	O
second	O
best	O
existing	O
method	O
PCLR	B-Method
by	O
0.01dB	O
,	O
0.06dB	O
,	O
0.03dB	O
and	O
0.01dB	O
respectively	O
,	O
which	O
shows	O
the	O
large	O
improvement	O
of	O
our	O
model	O
.	O
	
Last	O
,	O
we	O
can	O
observe	O
that	O
the	O
more	O
complex	O
the	O
noise	O
is	O
,	O
the	O
more	O
improvement	O
our	O
model	O
achieves	O
than	O
other	O
methods	O
.	O
	
Similar	O
observations	O
can	O
be	O
made	O
on	O
the	O
evaluation	O
of	O
SSIM	B-Metric
.	O
	
Evaluation	O
on	O
BSD200	B-Method
For	O
testing	O
efficiency	O
,	O
we	O
convert	O
the	O
images	O
to	O
gray	O
-	O
scale	O
and	O
resize	O
them	O
to	O
smaller	O
ones	O
on	O
BSD	B-Method
-	I-Method
200	I-Method
.	O
	
Then	O
all	O
the	O
methods	O
are	O
run	O
on	O
these	O
images	O
to	O
get	O
average	O
PSNR	B-Metric
and	O
SSIM	B-Metric
results	O
of	O
10	O
,	O
30	O
,	O
50	O
,	O
and	O
70	O
,	O
as	O
shown	O
in	O
Table	O
[	O
reference	O
]	O
.	O
	
For	O
existing	O
methods	O
,	O
their	O
denoising	B-Task
performance	O
does	O
not	O
differ	O
much	O
,	O
while	O
our	O
model	O
achieves	O
0.38dB	O
,	O
0.47dB	O
,	O
0.49dB	O
and	O
0.42dB	O
higher	O
of	O
PSNR	B-Metric
over	O
WNNM	B-Method
.	O
	
subsection	O
:	O
Image	B-Task
super	I-Task
-	I-Task
resolution	I-Task
	
The	O
evaluation	O
on	O
Set5	B-Material
is	O
shown	O
in	O
Table	O
[	O
reference	O
]	O
.	O
	
Our	O
10	B-Method
-	I-Method
layer	I-Method
network	I-Method
outperforms	O
the	O
compared	O
methods	O
already	O
,	O
and	O
we	O
achieve	O
better	O
performance	O
with	O
deeper	B-Method
networks	I-Method
.	O
	
The	O
30	B-Method
-	I-Method
layer	I-Method
network	I-Method
exceeds	O
the	O
second	O
best	O
method	O
CSCN	B-Method
for	O
0.52dB	O
,	O
0.56dB	O
and	O
0.47dB	O
on	O
scale	O
2	O
,	O
3	O
and	O
4	O
respectively	O
.	O
	
The	O
evaluation	O
on	O
Set14	O
is	O
shown	O
in	O
Table	O
[	O
reference	O
]	O
.	O
	
The	O
improvement	O
on	O
Set14	O
in	O
not	O
as	O
significant	O
as	O
that	O
on	O
Set5	B-Material
,	O
but	O
we	O
can	O
still	O
observe	O
that	O
the	O
30	B-Method
layer	I-Method
network	I-Method
achieves	O
higher	O
PSNR	B-Metric
than	O
the	O
second	O
best	O
CSCN	B-Method
for	O
0.23dB	O
,	O
0.06dB	O
and	O
0.1dB.	O
	
The	O
results	O
on	O
BSD100	B-Material
,	O
as	O
shown	O
in	O
Table	O
[	O
reference	O
]	O
,	O
is	O
similar	O
than	O
that	O
on	O
Set5	B-Material
.	O
	
The	O
second	O
best	O
method	O
is	O
still	O
CSCN	B-Method
,	O
the	O
performance	O
of	O
which	O
is	O
not	O
as	O
good	O
as	O
our	O
10	B-Method
layer	I-Method
network	I-Method
.	O
	
Our	O
deeper	B-Method
network	I-Method
obtains	O
much	O
more	O
performance	O
gain	O
than	O
the	O
others	O
.	O
	
subsection	O
:	O
Evaluation	O
with	O
a	O
single	O
model	O
	
To	O
construct	O
the	O
training	O
set	O
,	O
we	O
extract	O
image	O
patches	O
with	O
different	O
noise	O
levels	O
and	O
scaling	O
parameters	O
for	O
denoising	B-Task
and	O
super	B-Task
-	I-Task
resolution	I-Task
.	O
	
Then	O
a	O
30	B-Method
-	I-Method
layer	I-Method
network	I-Method
is	O
trained	O
for	O
the	O
two	O
tasks	O
respectively	O
.	O
	
The	O
evaluation	O
results	O
are	O
shown	O
in	O
Table	O
[	O
reference	O
]	O
and	O
Table	O
[	O
reference	O
]	O
.	O
	
Although	O
training	O
with	O
different	O
levels	O
of	O
corruption	O
,	O
we	O
can	O
observe	O
that	O
the	O
performance	O
of	O
our	O
network	O
only	O
slightly	O
degrades	O
comparing	O
to	O
the	O
case	O
in	O
which	O
using	O
separate	O
models	O
for	O
denoising	B-Task
and	O
super	B-Task
-	I-Task
resolution	I-Task
.	O
	
This	O
may	O
be	O
due	O
the	O
fact	O
that	O
the	O
network	O
has	O
to	O
fit	O
much	O
more	O
complex	O
mappings	O
.	O
	
Except	O
that	O
CSCN	B-Method
works	O
slightly	O
better	O
on	O
super	B-Task
-	I-Task
resolution	I-Task
with	O
scales	O
3	O
and	O
4	O
,	O
our	O
network	O
still	O
beats	O
the	O
existing	O
methods	O
,	O
showing	O
that	O
our	O
network	O
works	O
much	O
better	O
in	O
image	O
denoising	B-Task
and	O
super	B-Task
-	I-Task
resolution	I-Task
even	O
using	O
only	O
one	O
single	O
model	O
to	O
deal	O
with	O
complex	O
corruption	O
.	O
	
section	O
:	O
Conclusions	O
	
In	O
this	O
paper	O
we	O
have	O
proposed	O
a	O
deep	B-Method
encoding	I-Method
and	I-Method
decoding	I-Method
framework	I-Method
for	O
image	B-Task
restoration	I-Task
.	O
	
Convolution	B-Method
and	O
deconvolution	B-Method
are	O
combined	O
,	O
modeling	O
the	O
restoration	B-Task
problem	I-Task
by	O
extracting	O
primary	O
image	O
content	O
and	O
recovering	O
details	O
.	O
	
More	O
importantly	O
,	O
we	O
propose	O
to	O
use	O
skip	O
connections	O
,	O
which	O
helps	O
on	O
recovering	O
clean	O
images	O
and	O
tackles	O
the	O
optimization	B-Task
difficulty	I-Task
caused	O
by	O
gradient	O
vanishing	O
,	O
and	O
thus	O
obtains	O
performance	O
gains	O
when	O
the	O
network	O
goes	O
deeper	O
.	O
	
Experimental	O
results	O
and	O
our	O
analysis	O
show	O
that	O
our	O
network	O
achieves	O
better	O
performance	O
than	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
methods	O
on	O
image	O
denoising	B-Task
and	O
super	B-Task
-	I-Task
resolution	I-Task
.	O
	
X.	O
-	O
J.	O
	
Mao	O
’s	O
contribution	O
was	O
made	O
when	O
visiting	O
The	O
University	O
of	O
Adelaide	O
.	O
	
This	O
work	O
was	O
in	O
part	O
supported	O
by	O
ARC	O
Future	O
Fellowship	O
(	O
FT120100969	O
)	O
.	O
	
Correspondence	O
should	O
be	O
addressed	O
to	O
C.	O
Shen	O
.	O
	
bibliography	O
:	O
References	O
	
document	O
:	O
A	O
Discriminatively	B-Method
Learned	I-Method
CNN	I-Method
Embedding	I-Method
for	O
Person	B-Task
Re	I-Task
-	I-Task
identification	I-Task
	
In	O
this	O
paper	O
,	O
we	O
revisit	O
two	O
popular	O
convolutional	B-Method
neural	I-Method
networks	I-Method
(	O
CNN	B-Method
)	O
in	O
person	B-Task
re	I-Task
-	I-Task
identification	I-Task
(	O
re	B-Task
-	I-Task
ID	I-Task
)	O
,	O
i.e.	O
,	O
verification	B-Task
and	O
identification	B-Task
models	I-Task
.	O
	
The	O
two	O
models	O
have	O
their	O
respective	O
advantages	O
and	O
limitations	O
due	O
to	O
different	O
loss	O
functions	O
.	O
	
In	O
this	O
paper	O
,	O
we	O
shed	O
light	O
on	O
how	O
to	O
combine	O
the	O
two	O
models	O
to	O
learn	O
more	O
discriminative	B-Task
pedestrian	I-Task
descriptors	I-Task
.	O
	
Specifically	O
,	O
we	O
propose	O
a	O
siamese	B-Method
network	I-Method
that	O
simultaneously	O
computes	O
the	O
identification	B-Metric
loss	I-Metric
and	O
verification	B-Task
loss	O
.	O
	
Given	O
a	O
pair	O
of	O
training	O
images	O
,	O
the	O
network	O
predicts	O
the	O
identities	O
of	O
the	O
two	O
input	O
images	O
and	O
whether	O
they	O
belong	O
to	O
the	O
same	O
identity	O
.	O
	
Our	O
network	O
learns	O
a	O
discriminative	O
embedding	B-Method
and	O
a	O
similarity	B-Method
measurement	I-Method
at	O
the	O
same	O
time	O
,	O
thus	O
making	O
full	O
usage	O
of	O
the	O
re	B-Task
-	I-Task
ID	I-Task
annotations	O
.	O
	
Our	O
method	O
can	O
be	O
easily	O
applied	O
on	O
different	O
pre	B-Method
-	I-Method
trained	I-Method
networks	I-Method
.	O
	
Albeit	O
simple	O
,	O
the	O
learned	O
embedding	B-Method
improves	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
performance	O
on	O
two	O
public	O
person	O
re	B-Task
-	I-Task
ID	I-Task
benchmarks	O
.	O
	
Further	O
,	O
we	O
show	O
our	O
architecture	O
can	O
also	O
be	O
applied	O
in	O
image	B-Task
retrieval	I-Task
.	O
	
Large	O
-	O
scale	O
Person	B-Task
Re	I-Task
-	I-Task
identification	I-Task
,	O
Convolutional	B-Method
Neural	I-Method
Networks	I-Method
.	O
	
section	O
:	O
Introduction	O
	
Person	B-Task
re	I-Task
-	I-Task
identification	I-Task
(	O
re	B-Task
-	I-Task
ID	I-Task
)	O
is	O
usually	O
viewed	O
as	O
an	O
image	B-Task
retrieval	I-Task
problem	I-Task
,	O
which	O
matches	O
pedestrians	O
from	O
different	O
cameras	O
.	O
	
Given	O
a	O
person	O
-	O
of	O
-	O
interest	O
(	O
query	O
)	O
,	O
person	O
re	B-Task
-	I-Task
ID	I-Task
determines	O
whether	O
the	O
person	O
has	O
been	O
observed	O
by	O
another	O
camera	O
.	O
	
Recent	O
progress	O
in	O
this	O
area	O
has	O
been	O
due	O
to	O
two	O
factors	O
:	O
1	O
)	O
the	O
availability	O
of	O
the	O
large	O
-	O
scale	O
pedestrian	O
datasets	O
.	O
	
The	O
datasets	O
contain	O
the	O
general	O
visual	O
variance	O
of	O
pedestrian	O
and	O
provide	O
a	O
comprehensive	O
evaluation	O
.	O
	
2	O
)	O
the	O
learned	O
embedding	B-Method
of	O
pedestrian	O
using	O
a	O
convolutional	B-Method
neural	I-Method
network	I-Method
(	O
CNN	B-Method
)	O
.	O
	
Recently	O
,	O
the	O
convolutional	B-Method
neural	I-Method
network	I-Method
(	O
CNN	B-Method
)	O
has	O
shown	O
potential	O
for	O
learning	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
feature	B-Metric
embeddings	I-Metric
or	O
deep	B-Metric
metrics	I-Metric
.	O
	
As	O
shown	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
	
,	O
there	O
are	O
two	O
major	O
types	O
of	O
CNN	B-Method
structures	O
,	O
i.e.	O
,	O
verification	B-Task
models	O
and	O
identification	B-Task
models	I-Task
.	O
	
The	O
two	O
models	O
are	O
different	O
in	O
terms	O
of	O
input	O
,	O
feature	B-Task
extraction	I-Task
and	O
loss	O
function	O
for	O
training	O
.	O
	
Our	O
motivation	O
is	O
to	O
combine	O
the	O
strengths	O
of	O
the	O
two	O
models	O
and	O
learn	O
a	O
more	O
discriminative	O
pedestrian	O
embedding	B-Method
.	O
	
Verification	B-Method
models	I-Method
take	O
a	O
pair	O
of	O
images	O
as	O
input	O
and	O
determine	O
whether	O
they	O
belong	O
to	O
the	O
same	O
person	O
or	O
not	O
.	O
	
A	O
number	O
of	O
previous	O
works	O
treat	O
person	O
re	B-Task
-	I-Task
ID	I-Task
as	O
a	O
binary	B-Task
-	I-Task
class	I-Task
classification	I-Task
task	I-Task
or	O
a	O
similarity	B-Task
regression	I-Task
task	I-Task
.	O
	
Given	O
a	O
label	O
,	O
the	O
verification	B-Task
network	O
forces	O
two	O
images	O
of	O
the	O
same	O
person	O
to	O
be	O
mapped	O
to	O
nearby	O
points	O
in	O
the	O
feature	O
space	O
.	O
	
If	O
the	O
images	O
are	O
of	O
different	O
people	O
,	O
the	O
points	O
are	O
far	O
apart	O
.	O
	
However	O
,	O
the	O
major	O
problem	O
in	O
the	O
verification	B-Task
models	O
is	O
that	O
they	O
only	O
use	O
weak	O
re	B-Task
-	I-Task
ID	I-Task
labels	O
,	O
and	O
do	O
not	O
take	O
all	O
the	O
annotated	O
information	O
into	O
consideration	O
.	O
	
Therefore	O
,	O
the	O
verification	B-Task
network	O
lacks	O
the	O
consideration	O
of	O
the	O
relationship	O
between	O
the	O
image	O
pairs	O
and	O
other	O
images	O
in	O
the	O
dataset	O
.	O
	
In	O
the	O
attempt	O
to	O
take	O
full	O
advantages	O
of	O
the	O
re	B-Task
-	I-Task
ID	I-Task
labels	O
,	O
identification	B-Task
models	I-Task
which	O
treat	O
person	B-Task
re	I-Task
-	I-Task
identification	I-Task
as	O
a	O
multi	B-Task
-	I-Task
class	I-Task
recognition	I-Task
task	I-Task
,	O
are	O
employed	O
for	O
feature	B-Method
learning	I-Method
.	O
	
They	O
directly	O
learn	O
the	O
non	O
-	O
linear	O
functions	O
from	O
an	O
input	O
image	O
to	O
the	O
person	O
ID	O
and	O
the	O
cross	B-Metric
-	I-Metric
entropy	I-Metric
loss	I-Metric
is	O
used	O
following	O
the	O
final	O
layer	O
.	O
	
During	O
testing	O
,	O
the	O
feature	O
is	O
extracted	O
from	O
a	O
fully	B-Method
connected	I-Method
layer	I-Method
and	O
then	O
normalized	O
.	O
	
The	O
similarity	O
of	O
two	O
images	O
is	O
thus	O
computed	O
by	O
the	O
Euclidean	O
distance	O
between	O
their	O
normalized	O
CNN	B-Method
embeddings	O
.	O
	
The	O
major	O
drawback	O
of	O
the	O
identification	B-Method
model	I-Method
is	O
that	O
the	O
training	O
objective	O
is	O
different	O
from	O
the	O
testing	O
procedure	O
,	O
i.e.	O
,	O
it	O
does	O
not	O
account	O
for	O
the	O
similarity	O
measurement	O
between	O
image	O
pairs	O
,	O
which	O
can	O
be	O
problematic	O
during	O
the	O
pedestrian	B-Task
retrieval	I-Task
process	I-Task
.	O
	
The	O
above	O
-	O
mentioned	O
observations	O
demonstrate	O
that	O
the	O
two	O
types	O
of	O
models	O
have	O
complementary	O
advantages	O
and	O
limitations	O
as	O
shown	O
in	O
Table	O
[	O
reference	O
]	O
.	O
	
Motivated	O
by	O
these	O
properties	O
,	O
this	O
work	O
proposes	O
to	O
combine	O
the	O
strengths	O
of	O
the	O
two	O
networks	O
and	O
leverage	O
their	O
complementary	O
nature	O
to	O
improve	O
the	O
discriminative	B-Metric
ability	I-Metric
of	O
the	O
learned	O
embeddings	O
.	O
	
The	O
proposed	O
model	O
is	O
a	O
siamese	B-Method
network	I-Method
that	O
predicts	O
person	O
identities	O
and	O
similarity	O
scores	O
at	O
the	O
same	O
time	O
.	O
	
Compared	O
to	O
previous	O
networks	O
,	O
we	O
take	O
full	O
advantages	O
of	O
the	O
annotated	O
data	O
in	O
terms	O
of	O
pair	B-Metric
-	I-Metric
wise	I-Metric
similarity	I-Metric
and	O
image	B-Metric
identities	I-Metric
.	O
	
During	O
testing	O
,	O
the	O
final	O
convolutional	O
activations	O
are	O
extracted	O
for	O
Euclidepdfan	B-Task
distance	I-Task
based	I-Task
pedestrian	I-Task
retrieval	I-Task
.	O
	
To	O
summarize	O
,	O
our	O
contributions	O
are	O
:	O
We	O
propose	O
a	O
siamese	B-Method
network	I-Method
that	O
has	O
two	O
losses	B-Metric
:	O
identification	B-Metric
loss	I-Metric
and	O
verification	B-Task
loss	O
.	O
	
This	O
network	O
simultaneously	O
learns	O
a	O
discriminative	O
CNN	B-Method
embedding	I-Method
and	O
a	O
similarity	B-Metric
metric	I-Metric
,	O
thus	O
improving	O
pedestrian	B-Metric
retrieval	I-Metric
accuracy	I-Metric
.	O
	
We	O
report	O
competitive	B-Metric
accuracy	I-Metric
compared	O
to	O
the	O
state	O
-	O
of	O
-	O
art	O
methods	O
on	O
two	O
large	O
-	O
scale	O
person	O
re	B-Task
-	I-Task
ID	I-Task
datasets	O
(	O
Market1501	B-Material
and	O
CUHK03	O
)	O
and	O
one	O
instance	O
retrieval	O
dataset	O
(	O
Oxford5k	O
)	O
.	O
	
The	O
paper	O
is	O
organized	O
as	O
follows	O
.	O
	
We	O
first	O
review	O
some	O
related	O
works	O
in	O
Section	O
[	O
reference	O
]	O
.	O
	
In	O
Section	O
[	O
reference	O
]	O
,	O
we	O
describe	O
how	O
we	O
combine	O
the	O
two	O
losses	O
and	O
define	O
the	O
CNN	B-Method
structure	O
.	O
	
The	O
implementation	O
details	O
are	O
provided	O
.	O
	
In	O
Section	O
[	O
reference	O
]	O
,	O
we	O
present	O
the	O
experimental	O
results	O
on	O
two	O
large	O
-	O
scale	O
person	B-Task
re	I-Task
-	I-Task
identification	I-Task
datasets	O
and	O
one	O
instance	O
retrieval	O
dataset	O
.	O
	
We	O
conclude	O
this	O
paper	O
in	O
Section	O
[	O
reference	O
]	O
.	O
	
section	O
:	O
Related	O
Work	O
	
In	O
this	O
section	O
we	O
describe	O
previous	O
works	O
relevant	O
to	O
the	O
approach	O
discussed	O
in	O
this	O
paper	O
.	O
	
They	O
are	O
mainly	O
based	O
on	O
verification	B-Task
models	O
or	O
identification	B-Task
models	I-Task
.	O
	
subsection	O
:	O
Verification	B-Method
Models	I-Method
	
In	O
1993	O
,	O
Bromley	O
et	O
al	O
.	O
first	O
used	O
verification	B-Task
models	O
to	O
deep	B-Method
metric	I-Method
learning	I-Method
in	O
signature	O
verification	B-Task
.	O
	
Verification	B-Method
models	I-Method
usually	O
take	O
a	O
pair	O
of	O
images	O
as	O
input	O
and	O
output	O
a	O
similarity	B-Metric
score	I-Metric
by	O
calculating	O
the	O
cosine	O
distance	O
between	O
low	O
-	O
dimensional	O
features	O
,	O
which	O
can	O
be	O
penalized	O
by	O
the	O
contrastive	O
loss	O
.	O
	
Recently	O
researchers	O
have	O
begun	O
to	O
apply	O
verification	B-Task
models	O
to	O
person	B-Task
re	I-Task
-	I-Task
identification	I-Task
with	O
a	O
focus	O
on	O
data	B-Task
augmentation	I-Task
and	O
image	B-Task
matching	I-Task
.	O
	
Yi	O
et	O
al	O
.	O
split	O
a	O
pedestrian	O
image	O
into	O
three	O
horizontal	O
parts	O
and	O
train	O
three	O
part	B-Method
-	I-Method
CNNs	I-Method
to	O
extract	O
features	O
.	O
	
The	O
similarity	O
of	O
two	O
images	O
is	O
computed	O
by	O
the	O
cosine	O
distance	O
of	O
their	O
features	O
.	O
	
Similarly	O
,	O
Cheng	O
et	O
al	O
.	O
split	O
the	O
convolutional	O
map	O
into	O
four	O
parts	O
and	O
fuse	O
the	O
part	O
features	O
with	O
the	O
global	O
features	O
.	O
	
Li	O
et	O
al	O
.	O
add	O
a	O
patch	B-Method
-	I-Method
matching	I-Method
layer	I-Method
that	O
multiplies	O
the	O
activation	O
of	O
two	O
images	O
in	O
different	O
horizontal	O
stripes	O
.	O
	
They	O
use	O
it	O
to	O
find	O
similar	O
locations	O
and	O
treat	O
similarity	B-Method
regression	I-Method
as	O
binary	O
-	O
class	O
penalized	O
by	O
softmax	B-Method
loss	I-Method
.	O
	
Later	O
,	O
Ahmed	O
et	O
al	O
.	O
improve	O
the	O
verification	B-Task
model	O
by	O
adding	O
a	O
different	O
matching	B-Method
layer	I-Method
that	O
compares	O
the	O
activation	O
of	O
two	O
images	O
in	O
neighboring	O
pixels	O
.	O
	
Besides	O
,	O
Wu	O
et	O
al	O
.	O
use	O
smaller	O
filters	B-Method
and	O
a	O
deeper	B-Method
network	I-Method
to	O
extract	O
features	O
.	O
	
Varior	O
et	O
al	O
.	O
combine	O
CNN	B-Method
with	O
some	O
gate	B-Method
functions	I-Method
,	O
similar	O
to	O
long	B-Method
-	I-Method
short	I-Method
-	I-Method
term	I-Method
memory	I-Method
(	O
LSTM	B-Method
)	O
in	O
spirit	O
,	O
which	O
aims	O
to	O
adaptively	O
focus	O
on	O
the	O
similar	O
parts	O
of	O
input	O
image	O
pairs	O
.	O
	
But	O
it	O
is	O
limited	O
by	O
the	O
computational	B-Metric
inefficiency	I-Metric
because	O
the	O
query	O
image	O
has	O
to	O
pair	O
with	O
every	O
gallery	O
image	O
to	O
pass	O
through	O
the	O
network	O
.	O
	
Moreover	O
,	O
Ding	O
et	O
al	O
.	O
use	O
triplet	O
samples	O
for	O
training	O
the	O
network	O
which	O
considers	O
the	O
images	O
from	O
the	O
same	O
people	O
and	O
the	O
different	O
people	O
at	O
the	O
same	O
time	O
.	O
	
subsection	O
:	O
Identification	B-Method
Models	I-Method
	
Recent	O
datasets	O
such	O
as	O
CUHK03	O
and	O
Market1501	B-Material
provide	O
large	O
-	O
scale	O
training	O
sets	O
,	O
which	O
make	O
it	O
possible	O
to	O
train	O
a	O
deeper	O
classification	B-Method
model	I-Method
without	O
over	O
-	O
fitting	O
.	O
	
Every	O
identity	O
has	O
9.6	O
training	O
images	O
on	O
average	O
in	O
CUHK03	O
and	O
has	O
17.2	O
images	O
in	O
Market1501	B-Material
.	O
	
CNN	B-Method
can	O
learn	O
discriminative	O
embeddings	O
by	O
itself	O
without	O
part	B-Method
-	I-Method
matching	I-Method
.	O
	
Zheng	O
et	O
al	O
.	O
directly	O
use	O
a	O
conventional	O
fine	B-Method
-	I-Method
tuning	I-Method
approach	I-Method
on	O
Market1501	B-Material
,	O
PRW	O
and	O
MARS	O
and	O
outperform	O
many	O
recent	O
results	O
.	O
	
Wu	O
et	O
al	O
.	O
combine	O
CNN	B-Method
embeddings	O
with	O
the	O
hand	O
-	O
crafted	O
features	O
in	O
the	O
FC	B-Method
layer	O
.	O
	
Besides	O
,	O
Xiao	O
et	O
al	O
.	O
jointly	O
train	O
a	O
classification	B-Method
model	I-Method
using	O
multiple	O
datasets	O
and	O
propose	O
a	O
new	O
dropout	B-Method
function	I-Method
to	O
deal	O
with	O
the	O
hundreds	O
of	O
classes	O
.	O
	
In	O
,	O
Xiao	O
et	O
al	O
.	O
train	O
a	O
classification	B-Method
model	I-Method
similar	O
to	O
the	O
faster	B-Method
-	I-Method
RCNN	I-Method
method	I-Method
and	O
automatically	O
predict	O
the	O
location	O
of	O
the	O
candidate	O
pedestrian	O
from	O
the	O
whole	O
image	O
,	O
which	O
alleviates	O
the	O
pedestrian	B-Task
detection	I-Task
errors	I-Task
.	O
	
subsection	O
:	O
Verification	B-Method
-	I-Method
identification	I-Method
Models	I-Method
	
In	O
face	B-Task
recognition	I-Task
,	O
the	O
“	O
DeepID	B-Method
networks	I-Method
”	O
train	O
the	O
network	O
with	O
the	O
verification	B-Task
and	O
identification	O
losses	O
,	O
which	O
is	O
similar	O
to	O
our	O
network	O
.	O
	
In	O
,	O
Sun	O
et	O
al	O
.	O
jointly	O
train	O
face	O
identification	O
and	O
verification	B-Task
.	O
	
Then	O
more	O
verification	B-Task
supervision	O
is	O
added	O
into	O
the	O
model	O
and	O
a	O
deeper	B-Method
network	I-Method
is	O
used	O
.	O
	
Our	O
method	O
is	O
different	O
from	O
their	O
models	O
in	O
the	O
following	O
aspects	O
.	O
	
First	O
,	O
in	O
face	B-Task
recognition	I-Task
,	O
the	O
training	O
dataset	O
contains	O
202	O
,	O
599	O
face	O
images	O
of	O
10	O
,	O
177	O
identities	O
while	O
the	O
current	O
largest	O
person	O
re	O
-	O
i	O
d	O
training	O
dataset	O
contains	O
12	O
,	O
936	O
images	O
of	O
751	O
identities	O
.	O
	
DeepID	B-Method
networks	I-Method
apply	O
contrastive	B-Method
loss	I-Method
to	O
the	O
verification	B-Task
problem	O
,	O
wile	O
our	O
model	O
uses	O
the	O
cross	B-Metric
-	I-Metric
entropy	I-Metric
loss	I-Metric
.	O
	
We	O
find	O
that	O
the	O
contrastive	O
loss	O
leads	O
to	O
over	B-Task
-	I-Task
fitting	I-Task
when	O
the	O
number	O
of	O
images	O
is	O
limited	O
.	O
	
In	O
the	O
experiment	O
,	O
we	O
show	O
the	O
proposed	O
method	O
learns	O
more	O
robust	O
person	O
representative	O
and	O
outperforms	O
using	O
contrastive	B-Method
loss	I-Method
.	O
	
Second	O
,	O
dropout	B-Method
can	O
not	O
be	O
applied	O
on	O
the	O
embedding	B-Method
before	O
the	O
contrastive	O
loss	O
,	O
which	O
introduces	O
zero	O
values	O
at	O
random	O
locations	O
.	O
	
On	O
the	O
contrary	O
,	O
we	O
can	O
add	O
dropout	B-Method
regularization	I-Method
on	O
the	O
embedding	B-Method
in	O
the	O
proposed	O
model	O
.	O
	
Third	O
,	O
the	O
DeepID	B-Method
networks	I-Method
are	O
trained	O
from	O
scratch	O
,	O
while	O
our	O
model	O
benefits	O
from	O
the	O
networks	O
pretrained	O
on	O
ImageNet	O
.	O
	
Finally	O
,	O
we	O
evaluate	O
our	O
method	O
on	O
the	O
tasks	O
of	O
person	O
re	B-Task
-	I-Task
ID	I-Task
and	O
instance	O
retrieval	O
,	O
providing	O
more	O
insights	O
in	O
the	O
verification	B-Task
-	O
classification	O
models	O
.	O
	
section	O
:	O
Proposed	O
Method	O
	
subsection	O
:	O
Preview	O
	
Fig	O
.	O
	
[	O
reference	O
]	O
	
(	O
a	O
)	O
and	O
Fig	O
.	O
	
[	O
reference	O
]	O
	
(	O
b	O
)	O
illustrate	O
the	O
relational	O
graph	O
built	O
by	O
verification	B-Task
and	O
identification	B-Task
models	I-Task
.	O
	
In	O
a	O
sample	O
batch	O
of	O
size	O
,	O
red	O
edges	O
represent	O
the	O
positive	O
pairs	O
(	O
the	O
same	O
person	O
)	O
and	O
blue	O
edges	O
represent	O
the	O
negative	O
pairs	O
(	O
different	O
persons	O
)	O
.	O
	
The	O
dotted	O
edges	O
denote	O
implicit	O
relationships	O
built	O
by	O
the	O
identification	O
loss	O
and	O
the	O
solid	O
edges	O
denote	O
explicit	O
relationships	O
built	O
by	O
the	O
verification	B-Task
loss	O
.	O
	
In	O
verification	B-Task
models	O
,	O
there	O
are	O
several	O
operations	O
between	O
the	O
two	O
inputs	O
.	O
	
The	O
explicit	O
relationship	O
between	O
data	O
is	O
built	O
by	O
the	O
pair	B-Method
-	I-Method
wise	I-Method
comparison	I-Method
,	O
such	O
as	O
part	B-Method
matching	I-Method
or	O
contrastive	B-Method
loss	I-Method
.	O
	
For	O
example	O
,	O
contrastive	O
loss	O
directly	O
calculates	O
the	O
Euclidean	O
distance	O
between	O
two	O
embeddings	O
.	O
	
In	O
identification	B-Task
models	I-Task
,	O
the	O
input	O
is	O
independent	O
to	O
each	O
other	O
.	O
	
But	O
there	O
is	O
implicit	O
relationship	O
between	O
the	O
learned	O
embeddings	O
built	O
by	O
the	O
cross	B-Method
-	I-Method
entropy	I-Method
loss	I-Method
.	O
	
The	O
cross	B-Metric
-	I-Metric
entropy	I-Metric
loss	I-Metric
can	O
be	O
formulated	O
as	O
.	O
	
is	O
the	O
weight	O
of	O
the	O
linear	B-Method
function	I-Method
.	O
	
are	O
the	O
embeddings	O
of	O
the	O
two	O
images	O
from	O
the	O
same	O
class	O
.	O
	
To	O
maximize	O
,	O
,	O
the	O
network	O
converges	O
when	O
and	O
have	O
similar	O
vector	O
direction	O
with	O
.	O
	
In	O
,	O
similar	O
observation	O
and	O
visualization	O
are	O
shown	O
.	O
	
So	O
the	O
learned	O
embeddings	O
are	O
eventually	O
close	O
for	O
images	O
within	O
the	O
same	O
class	O
and	O
far	O
away	O
for	O
images	O
in	O
the	O
different	O
classes	O
.	O
	
The	O
relationship	O
is	O
implicitly	O
built	O
between	O
and	O
bridged	O
by	O
the	O
weight	O
.	O
	
Due	O
to	O
the	O
usage	O
of	O
the	O
weak	O
labels	O
,	O
verification	B-Task
models	O
take	O
limited	O
relationships	O
into	O
consideration	O
.	O
	
On	O
the	O
other	O
hand	O
,	O
classification	B-Method
models	I-Method
do	O
not	O
explicitly	O
consider	O
similarity	O
measurements	O
.	O
	
Fig	O
.	O
	
[	O
reference	O
]	O
(	O
c	O
)	O
illustrates	O
how	O
our	O
model	O
works	O
in	O
a	O
batch	O
.	O
	
We	O
benefit	O
from	O
simultaneously	O
considering	O
the	O
verification	B-Task
and	O
identification	O
losses	O
.	O
	
The	O
proposed	O
model	O
thus	O
combines	O
the	O
strength	O
of	O
the	O
two	O
models	O
(	O
see	O
Table	O
[	O
reference	O
]	O
)	O
.	O
	
subsection	O
:	O
Overall	O
Network	O
	
Our	O
network	O
is	O
basically	O
a	O
convolutional	B-Method
siamese	I-Method
network	I-Method
that	O
combines	O
the	O
verification	B-Task
and	O
identification	O
losses	O
.	O
	
Fig	O
.	O
	
[	O
reference	O
]	O
briefly	O
illustrates	O
the	O
architecture	O
of	O
the	O
proposed	O
network	O
.	O
	
Given	O
an	O
input	O
pair	O
of	O
images	O
resized	O
to	O
,	O
the	O
proposed	O
network	O
simultaneously	O
predicts	O
the	O
IDs	O
of	O
the	O
two	O
images	O
and	O
the	O
similarity	B-Metric
score	I-Metric
.	O
	
The	O
network	O
consists	O
of	O
two	O
ImageNet	O
pre	O
-	O
trained	O
CNN	B-Method
models	O
,	O
three	O
additional	O
Convolutional	B-Method
Layers	I-Method
,	O
one	O
Square	B-Method
Layer	I-Method
and	O
three	O
losses	O
.	O
	
It	O
is	O
supervised	O
by	O
the	O
identification	O
label	O
and	O
the	O
verification	B-Task
label	O
.	O
	
The	O
pre	O
-	O
trained	O
CNN	B-Method
model	O
can	O
be	O
CaffeNet	B-Method
,	O
VGG16	B-Method
or	O
ResNet	B-Method
-	I-Method
50	I-Method
,	O
from	O
which	O
we	O
have	O
removed	O
the	O
final	O
fully	B-Method
-	I-Method
connected	I-Method
(	O
FC	B-Method
)	O
layer	O
.	O
	
The	O
re	B-Task
-	I-Task
ID	I-Task
performance	O
of	O
the	O
three	O
models	O
is	O
comprehensively	O
evaluated	O
in	O
Section	O
[	O
reference	O
]	O
.	O
	
Here	O
,	O
we	O
do	O
not	O
provide	O
detailed	O
descriptions	O
of	O
the	O
architecture	O
of	O
the	O
CNN	B-Method
models	O
and	O
only	O
take	O
CaffeNet	B-Method
as	O
an	O
example	O
in	O
the	O
following	O
subsections	O
.	O
	
The	O
three	O
optimization	B-Metric
objectives	I-Metric
include	O
two	O
identification	O
losses	O
and	O
one	O
verification	B-Task
loss	O
.	O
	
We	O
use	O
the	O
final	O
convolutional	O
activations	O
as	O
the	O
discriminative	B-Method
descriptor	I-Method
for	O
person	O
re	B-Task
-	I-Task
ID	I-Task
,	O
which	O
is	O
directly	O
supervised	O
by	O
three	O
objectives	O
.	O
	
subsection	O
:	O
Identification	B-Task
Loss	I-Task
	
There	O
are	O
two	O
CaffeNets	B-Method
in	O
our	O
architecture	O
.	O
	
They	O
share	O
weights	O
and	O
predict	O
the	O
two	O
identity	O
labels	O
of	O
the	O
input	O
image	O
pair	O
simultaneously	O
.	O
	
In	O
order	O
to	O
fine	O
-	O
tune	O
the	O
network	O
on	O
a	O
new	O
dataset	O
,	O
we	O
replace	O
the	O
final	O
fully	B-Method
-	I-Method
connected	I-Method
layer	O
(	O
1	O
,	O
000	O
-	O
dim	O
)	O
of	O
the	O
pre	O
-	O
trained	O
CNN	B-Method
model	O
with	O
a	O
convolutional	B-Method
layer	I-Method
.	O
	
The	O
number	O
of	O
the	O
training	O
identities	O
in	O
Market	O
-	O
1501	O
is	O
751	O
.	O
	
So	O
this	O
convolutional	B-Method
layer	I-Method
has	O
kernels	O
of	O
size	O
connected	O
to	O
the	O
output	O
of	O
CaffeNet	B-Method
	
and	O
then	O
we	O
add	O
a	O
softmax	B-Method
unit	I-Method
to	O
normalize	O
the	O
output	O
.	O
	
The	O
size	O
of	O
the	O
result	O
tensor	O
is	O
.	O
	
The	O
Rectified	B-Method
Linear	I-Method
Unit	I-Method
(	O
ReLU	B-Method
)	I-Method
is	O
not	O
added	O
after	O
this	O
convolution	B-Method
.	O
	
Similar	O
to	O
conventional	O
multi	B-Method
-	I-Method
class	I-Method
recognition	I-Method
approaches	I-Method
,	O
we	O
use	O
the	O
cross	B-Metric
-	I-Metric
entropy	I-Metric
loss	I-Metric
for	O
identity	B-Task
prediction	I-Task
,	O
which	O
is	O
Here	O
denotes	O
the	O
convolutional	B-Method
operation	I-Method
.	O
	
is	O
a	O
tensor	O
,	O
is	O
the	O
target	O
class	O
and	O
denotes	O
the	O
parameters	O
of	O
the	O
added	O
convolutional	B-Method
layer	I-Method
.	O
	
is	O
the	O
predicted	O
probability	O
,	O
is	O
the	O
target	O
probability	O
.	O
	
for	O
all	O
except	O
.	O
	
subsection	O
:	O
Verification	B-Metric
Loss	I-Metric
	
While	O
some	O
previous	O
works	O
contain	O
a	O
matching	B-Method
function	I-Method
in	O
the	O
intermediate	O
layers	O
,	O
our	O
work	O
directly	O
compares	O
the	O
high	O
-	O
level	O
features	O
for	O
similarity	B-Task
estimation	I-Task
.	O
	
The	O
high	O
-	O
level	O
feature	O
from	O
the	O
fine	O
-	O
tuned	O
CNN	B-Method
has	O
shown	O
a	O
discriminative	O
ability	O
and	O
it	O
is	O
more	O
compact	O
than	O
the	O
activations	O
in	O
the	O
intermediate	O
layers	O
.	O
	
So	O
in	O
our	O
model	O
,	O
the	O
pedestrian	B-Method
descriptor	I-Method
in	O
the	O
identification	B-Method
model	I-Method
are	O
directly	O
supervised	O
by	O
the	O
verification	B-Task
loss	O
.	O
	
As	O
shown	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
	
,	O
we	O
introduce	O
a	O
non	B-Method
-	I-Method
parametric	I-Method
layer	I-Method
called	O
Square	B-Method
Layer	I-Method
to	O
compare	O
the	O
high	O
-	O
level	O
features	O
.	O
	
It	O
takes	O
two	O
tensors	O
as	O
inputs	O
and	O
outputs	O
one	O
tensor	O
after	O
subtracting	O
and	O
squaring	O
element	O
-	O
wisely	O
.	O
	
The	O
Square	B-Method
Layer	I-Method
is	O
denoted	O
as	O
,	O
where	O
are	O
the	O
4	O
,	O
096	O
-	O
dim	O
embeddings	O
and	O
is	O
the	O
output	O
tensor	O
of	O
the	O
Square	B-Method
Layer	I-Method
.	O
	
We	O
then	O
add	O
a	O
convolutional	B-Method
layer	I-Method
and	O
the	O
softmax	O
output	O
function	O
to	O
embed	O
the	O
resulting	O
tensor	O
to	O
a	O
2	O
-	O
dim	O
vector	O
(	O
,	O
)	O
which	O
represents	O
the	O
predicted	O
probability	O
of	O
the	O
two	O
input	O
images	O
belonging	O
to	O
the	O
same	O
identity	O
.	O
	
The	O
convolutional	B-Method
layer	I-Method
takes	O
as	O
input	O
and	O
filters	O
it	O
with	O
kernels	O
of	O
size	O
.	O
	
The	O
ReLU	B-Method
is	O
not	O
added	O
after	O
this	O
convolution	B-Method
.	O
	
We	O
treat	O
pedestrian	O
verification	B-Task
as	O
a	O
binary	B-Task
classification	I-Task
problem	I-Task
and	O
use	O
the	O
cross	B-Metric
-	I-Metric
entropy	I-Metric
loss	I-Metric
that	O
is	O
similar	O
to	O
the	O
one	O
in	O
the	O
identification	B-Task
loss	I-Task
,	O
which	O
is	O
Here	O
	
are	O
the	O
two	O
tensors	O
of	O
size	O
.	O
	
is	O
the	O
target	O
class	O
(	O
same	O
/	O
different	O
)	O
,	O
denotes	O
the	O
parameters	O
of	O
the	O
added	O
convolutional	B-Method
layer	I-Method
and	O
is	O
the	O
predicted	O
probability	O
.	O
	
If	O
the	O
image	O
pair	O
depicts	O
the	O
same	O
person	O
,	O
;	O
otherwise	O
,	O
.	O
	
Departing	O
from	O
,	O
we	O
do	O
not	O
use	O
the	O
contrastive	O
loss	O
.	O
	
On	O
the	O
one	O
hand	O
,	O
the	O
contrastive	B-Method
loss	I-Method
,	O
as	O
a	O
regression	B-Method
loss	I-Method
,	O
forces	O
the	O
same	O
-	O
class	O
embeddings	O
to	O
be	O
as	O
close	O
as	O
possible	O
.	O
	
It	O
may	O
make	O
the	O
model	O
over	O
-	O
fitting	O
because	O
the	O
number	O
of	O
training	O
of	O
each	O
identity	O
is	O
limited	O
in	O
person	O
re	B-Task
-	I-Task
ID	I-Task
.	O
	
On	O
the	O
other	O
hand	O
,	O
dropout	B-Method
,	O
which	O
introduces	O
zero	O
values	O
at	O
random	O
locations	O
,	O
can	O
not	O
be	O
applied	O
on	O
the	O
embedding	B-Method
before	O
the	O
contrastive	O
loss	O
.	O
	
But	O
the	O
cross	B-Metric
-	I-Metric
entropy	I-Metric
loss	I-Metric
in	O
our	O
model	O
can	O
work	O
with	O
dropout	B-Method
to	O
regularize	O
the	O
model	O
.	O
	
In	O
Section	O
[	O
reference	O
]	O
,	O
we	O
show	O
that	O
the	O
result	O
using	O
contrastive	B-Method
loss	I-Method
is	O
4.39	O
%	O
and	O
6.55	O
%	O
lower	O
than	O
the	O
one	O
using	O
the	O
cross	B-Metric
-	I-Metric
entropy	I-Metric
loss	I-Metric
on	O
rank	B-Metric
-	I-Metric
1	I-Metric
accuracy	I-Metric
and	O
mAP	B-Metric
respectively	O
.	O
	
subsection	O
:	O
Identification	B-Task
vs.	O
Verification	B-Task
	
The	O
proposed	O
network	O
is	O
trained	O
to	O
minimize	O
the	O
three	O
cross	B-Metric
-	I-Metric
entropy	I-Metric
losses	I-Metric
jointly	O
.	O
	
To	O
figure	O
out	O
which	O
objective	O
contributes	O
more	O
,	O
we	O
train	O
the	O
identification	B-Method
model	I-Method
and	O
verification	B-Task
model	O
separately	O
.	O
	
Following	O
the	O
learning	B-Metric
rate	I-Metric
setting	I-Metric
in	O
Section	O
[	O
reference	O
]	O
,	O
we	O
train	O
the	O
models	O
until	O
convergence	O
.	O
	
We	O
also	O
train	O
the	O
network	O
with	O
the	O
two	O
losses	O
jointly	O
until	O
two	O
objectives	O
both	O
converge	O
.	O
	
As	O
the	O
quantitative	O
results	O
shown	O
in	O
Table	O
[	O
reference	O
]	O
,	O
the	O
fine	O
-	O
tuned	O
CNN	B-Method
model	O
with	O
two	O
kinds	O
of	O
losses	O
outperforms	O
the	O
one	O
trained	O
individually	O
.	O
	
This	O
result	O
has	O
been	O
confirmed	O
on	O
the	O
three	O
different	O
network	O
structures	O
.	O
	
Further	O
,	O
we	O
visualize	O
the	O
intermediate	O
feature	O
maps	O
that	O
are	O
trained	O
using	O
ResNet	B-Method
-	I-Method
50	I-Method
as	O
the	O
pretrained	B-Method
model	I-Method
and	O
try	O
to	O
find	O
the	O
differences	O
between	O
identification	B-Metric
loss	I-Metric
and	O
verification	B-Task
loss	O
.	O
	
We	O
select	O
three	O
test	O
images	O
in	O
the	O
Market1501	B-Material
.	O
	
One	O
image	O
is	O
considered	O
to	O
be	O
well	O
detected	O
and	O
the	O
other	O
two	O
images	O
are	O
not	O
well	O
aligned	O
.	O
	
Given	O
one	O
image	O
as	O
input	O
,	O
we	O
get	O
its	O
activation	O
in	O
the	O
intermediate	O
layer	O
“	O
res4fx	O
”	O
,	O
the	O
size	O
of	O
which	O
is	O
.	O
	
We	O
visualize	O
the	O
sum	O
of	O
several	O
activation	O
maps	O
.	O
	
As	O
shown	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
,	O
	
the	O
identification	B-Task
and	O
the	O
verification	B-Task
networks	O
exhibit	O
different	O
activation	O
patterns	O
to	O
the	O
pedestrian	O
.	O
	
We	O
find	O
that	O
if	O
we	O
use	O
only	O
one	O
kind	O
of	O
loss	O
,	O
the	O
network	O
tends	O
to	O
find	O
one	O
discriminative	O
part	O
.	O
	
The	O
proposed	O
model	O
takes	O
advantages	O
of	O
both	O
networks	O
,	O
so	O
the	O
new	O
activation	B-Method
map	I-Method
is	O
mostly	O
a	O
union	O
of	O
the	O
two	O
individual	O
maps	O
.	O
	
This	O
also	O
illustrates	O
the	O
complementary	O
nature	O
of	O
the	O
two	O
baseline	O
networks	O
.	O
	
The	O
proposed	O
model	O
makes	O
more	O
neurons	O
activated	O
.	O
	
Moreover	O
,	O
as	O
shown	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
we	O
visualize	O
the	O
embedding	B-Method
by	O
plot	O
them	O
to	O
the	O
2	O
-	O
dimension	O
map	O
.	O
	
In	O
regard	O
to	O
Fig	O
.	O
	
[	O
reference	O
]	O
	
,	O
we	O
find	O
the	O
network	O
usually	O
has	O
strong	O
attention	O
on	O
the	O
center	O
part	O
of	O
the	O
human	O
(	O
usually	O
clothes	O
)	O
and	O
it	O
also	O
illustrates	O
the	O
color	O
of	O
the	O
clothes	O
is	O
the	O
major	O
clue	O
for	O
the	O
person	B-Task
re	I-Task
-	I-Task
identification	I-Task
.	O
	
subsection	O
:	O
Training	O
and	O
Optimization	B-Task
	
Input	B-Task
preparation	I-Task
.	O
	
We	O
resize	O
all	O
the	O
training	O
images	O
to	O
.	O
	
The	O
mean	O
image	O
computed	O
from	O
all	O
the	O
training	O
images	O
is	O
subtracted	O
from	O
all	O
the	O
images	O
.	O
	
During	O
training	O
,	O
all	O
the	O
images	O
are	O
randomly	O
cropped	O
to	O
for	O
CaffeNet	B-Method
and	O
mirrored	O
horizontally	O
.	O
	
For	O
ResNet	B-Method
-	I-Method
50	I-Method
and	O
VGG16	B-Method
,	O
we	O
randomly	O
crop	O
images	O
to	O
.	O
	
We	O
shuffle	O
the	O
dataset	O
and	O
use	O
a	O
random	O
order	O
of	O
the	O
images	O
.	O
	
Then	O
we	O
sample	O
another	O
image	O
from	O
the	O
same	O
/	O
different	O
class	O
to	O
compose	O
a	O
positive	O
/	O
negative	O
pair	O
.	O
	
The	O
initial	O
ratio	O
between	O
negative	O
pairs	O
and	O
positive	O
pairs	O
is	O
to	O
alleviate	O
the	O
prediction	O
bias	O
and	O
we	O
multiple	O
it	O
by	O
a	O
factor	O
of	O
every	O
epoch	O
until	O
it	O
reaches	O
,	O
since	O
the	O
number	O
of	O
positive	O
pairs	O
is	O
so	O
limited	O
that	O
the	O
network	O
risks	O
over	O
-	O
fitting	O
.	O
	
Training	O
.	O
	
We	O
use	O
the	O
Matconvnet	B-Method
package	I-Method
for	O
training	O
and	O
testing	O
the	O
embedding	B-Method
with	O
CaffeNet	B-Method
,	O
VGG16	B-Method
and	O
ResNet	B-Method
-	I-Method
50	I-Method
,	O
respectively	O
.	O
	
The	O
maximum	O
number	O
of	O
training	O
epochs	O
is	O
set	O
to	O
75	O
for	O
ResNet	B-Method
-	I-Method
50	I-Method
,	O
65	O
for	O
VGG16net	B-Method
and	O
155	O
for	O
CaffeNet	B-Method
.	O
	
The	O
batch	O
size	O
(	O
in	O
image	O
pairs	O
)	O
is	O
set	O
to	O
128	O
for	O
CaffeNet	B-Method
,	O
48	O
for	O
VGG16	B-Method
and	O
ResNet	B-Method
-	I-Method
50	I-Method
.	O
	
The	O
learning	B-Metric
rate	I-Metric
is	O
initialized	O
as	O
0.001	O
and	O
then	O
set	O
to	O
0.0001	O
for	O
the	O
final	O
5	O
epochs	O
.	O
	
We	O
adopt	O
the	O
mini	B-Method
-	I-Method
batch	I-Method
stochastic	I-Method
gradient	I-Method
descent	I-Method
(	O
SGD	B-Method
)	O
to	O
update	O
the	O
parameters	O
of	O
the	O
network	O
.	O
	
There	O
are	O
three	O
objectives	O
in	O
our	O
network	O
.	O
	
Therefore	O
,	O
we	O
first	O
compute	O
all	O
the	O
gradients	O
produced	O
by	O
every	O
objectives	O
respectively	O
and	O
add	O
the	O
weighted	O
gradients	O
together	O
to	O
update	O
the	O
network	O
.	O
	
We	O
assign	O
a	O
weight	O
of	O
1	O
to	O
the	O
gradient	O
produced	O
by	O
the	O
verification	B-Task
loss	O
and	O
0.5	O
for	O
the	O
two	O
gradients	O
produced	O
by	O
two	O
identification	B-Method
losses	I-Method
.	O
	
Moreover	O
,	O
we	O
insert	O
the	O
dropout	B-Method
function	I-Method
before	O
the	O
final	O
convolutional	B-Method
layer	I-Method
.	O
	
Testing	O
.	O
	
We	O
adopt	O
an	O
efficient	O
method	O
to	O
extract	O
features	O
as	O
well	O
as	O
the	O
activation	O
in	O
the	O
intermediate	O
layer	O
.	O
	
Because	O
two	O
CaffeNet	B-Method
share	O
weights	O
,	O
our	O
model	O
has	O
nearly	O
the	O
same	O
memory	B-Metric
consumption	I-Metric
with	O
the	O
pretrained	B-Method
model	I-Method
.	O
	
So	O
we	O
extract	O
features	O
by	O
only	O
activating	O
one	O
fine	B-Method
-	I-Method
tuned	I-Method
model	I-Method
.	O
	
Given	O
a	O
image	O
,	O
we	O
feed	O
forward	O
the	O
image	O
to	O
one	O
CaffeNet	B-Method
in	O
our	O
network	O
and	O
obtain	O
a	O
4	B-Method
,	I-Method
096	I-Method
-	I-Method
dim	I-Method
pedestrian	I-Method
descriptor	I-Method
.	O
	
Once	O
the	O
descriptors	O
for	O
the	O
gallery	O
sets	O
are	O
obtained	O
,	O
they	O
are	O
stored	O
offline	O
.	O
	
Given	O
a	O
query	O
image	O
,	O
its	O
descriptor	O
is	O
extracted	O
online	O
.	O
	
We	O
sort	O
the	O
cosine	O
distance	O
between	O
the	O
query	O
and	O
all	O
the	O
gallery	O
features	O
to	O
obtain	O
the	O
final	O
ranking	B-Task
result	O
.	O
	
Note	O
that	O
the	O
cosine	O
distance	O
is	O
equivalent	O
to	O
Euclidean	O
distance	O
when	O
the	O
feature	O
is	O
L2	O
-	O
normalized	O
.	O
	
section	O
:	O
Experiments	O
	
We	O
mainly	O
verify	O
the	O
proposed	O
model	O
on	O
two	O
large	O
-	O
scale	O
datasets	O
Market1501	B-Material
and	O
CUHK03	O
.	O
	
We	O
report	O
the	O
results	O
trained	O
by	O
three	O
network	B-Method
structures	I-Method
.	O
	
Besides	O
,	O
we	O
also	O
report	O
the	O
result	O
on	O
Market1501	B-Material
+	O
500k	O
dataset	O
.	O
	
Meanwhile	O
,	O
the	O
proposed	O
architecture	O
is	O
also	O
applied	O
on	O
the	O
image	B-Task
retrieval	I-Task
task	I-Task
.	O
	
We	O
modify	O
our	O
model	O
and	O
test	O
it	O
on	O
a	O
popular	O
image	O
retrieval	O
dataset	O
,	O
i.e.	O
,	O
Oxford	O
Buildings	O
.	O
	
The	O
performance	O
is	O
comparable	O
to	O
the	O
state	O
of	O
the	O
art	O
.	O
	
subsection	O
:	O
Dataset	O
	
Market1501	B-Material
contains	O
32	O
,	O
668	O
annotated	O
bounding	O
boxes	O
of	O
1	O
,	O
501	O
identities	O
.	O
	
Images	O
of	O
each	O
identity	O
are	O
captured	O
by	O
at	O
most	O
six	O
cameras	O
.	O
	
According	O
to	O
the	O
dataset	O
setting	O
,	O
the	O
training	O
set	O
contains	O
12	O
,	O
936	O
cropped	O
images	O
of	O
751	O
identities	O
and	O
testing	O
set	O
contains	O
19	O
,	O
732	O
cropped	O
images	O
of	O
750	O
identities	O
and	O
distractors	O
.	O
	
They	O
are	O
directly	O
detected	O
by	O
the	O
Deformable	B-Method
Part	I-Method
Model	I-Method
(	O
DPM	B-Method
)	I-Method
instead	O
of	O
using	O
hand	B-Method
-	I-Method
drawn	I-Method
bboxes	I-Method
,	O
which	O
is	O
closer	O
to	O
the	O
realistic	O
setting	O
.	O
	
For	O
each	O
query	O
,	O
we	O
aim	O
to	O
retrieve	O
the	O
ground	O
truth	O
images	O
from	O
the	O
19	O
,	O
732	O
candidate	O
images	O
.	O
	
The	O
searching	O
pool	O
(	O
gallery	O
)	O
is	O
important	O
to	O
person	B-Task
re	I-Task
-	I-Task
identification	I-Task
.	O
	
In	O
the	O
realistic	B-Task
setting	I-Task
,	O
the	O
scale	O
of	O
the	O
gallery	O
is	O
usually	O
large	O
.	O
	
The	O
distractor	O
dataset	O
of	O
Market1501	B-Material
provides	O
extra	O
500	O
,	O
000	O
bboxes	O
,	O
consisting	O
of	O
false	O
alarms	O
on	O
the	O
background	O
as	O
well	O
as	O
the	O
persons	O
not	O
belonging	O
to	O
any	O
of	O
the	O
original	O
1	O
,	O
501	O
identities	O
.	O
	
When	O
testing	O
,	O
we	O
add	O
the	O
500k	O
images	O
to	O
the	O
original	O
gallery	O
,	O
which	O
makes	O
the	O
retrieval	B-Task
more	O
difficult	O
.	O
	
CUHK03	O
dataset	O
contains	O
14	O
,	O
097	O
cropped	O
images	O
of	O
1	O
,	O
467	O
identities	O
collected	O
in	O
the	O
CUHK	O
campus	O
.	O
	
Each	O
identity	O
is	O
observed	O
by	O
two	O
camera	O
views	O
and	O
has	O
4.8	O
images	O
in	O
average	O
for	O
each	O
view	O
.	O
	
The	O
Author	O
provides	O
two	O
kinds	O
of	O
bounding	O
boxes	O
.	O
	
We	O
evaluate	O
our	O
model	O
on	O
the	O
bounding	O
boxes	O
detected	O
by	O
DPM	B-Method
,	O
which	O
is	O
closer	O
to	O
the	O
realistic	O
setting	O
.	O
	
Following	O
the	O
setting	O
of	O
the	O
dataset	O
,	O
the	O
dataset	O
is	O
partitioned	O
into	O
a	O
training	O
set	O
of	O
1	O
,	O
367	O
persons	O
and	O
a	O
testing	O
set	O
of	O
100	O
persons	O
.	O
	
The	O
experiment	O
is	O
repeated	O
with	O
20	O
random	O
splits	O
.	O
	
Both	O
the	O
single	O
-	O
shot	O
and	O
multiple	O
-	O
shot	O
results	O
will	O
be	O
reported	O
.	O
	
Oxford5k	O
buildings	O
consists	O
of	O
5062	O
images	O
collected	O
from	O
the	O
internet	O
and	O
corresponding	O
to	O
particular	O
Oxford	O
landmarks	O
.	O
	
Some	O
images	O
have	O
complex	O
structures	O
and	O
may	O
contain	O
other	O
buildings	O
.	O
	
The	O
images	O
corresponding	O
to	O
11	O
Oxford	O
landmarks	O
are	O
manually	O
annotated	O
and	O
a	O
set	O
of	O
55	O
queries	O
for	O
11	O
different	O
landmarks	O
are	O
provided	O
.	O
	
This	O
benchmark	O
contains	O
many	O
high	O
-	O
resolution	O
images	O
and	O
the	O
mean	O
image	O
size	O
of	O
this	O
dataset	O
is	O
.	O
	
We	O
use	O
the	O
rank	B-Metric
-	I-Metric
1	I-Metric
accuracy	I-Metric
and	O
mean	B-Metric
average	I-Metric
precision	I-Metric
(	O
mAP	B-Metric
)	O
for	O
performance	O
evaluation	O
on	O
Market1501	B-Material
	
(	O
+	O
100k	O
)	O
and	O
CUHK03	O
,	O
while	O
on	O
Oxford	O
,	O
we	O
use	O
mAP	B-Metric
.	O
	
subsection	O
:	O
Person	B-Task
Re	I-Task
-	I-Task
i	I-Task
d	I-Task
Evaluation	I-Task
	
Comparison	O
with	O
the	O
CNN	B-Method
baseline	O
.	O
	
We	O
train	O
the	O
baseline	B-Method
networks	I-Method
according	O
the	O
conventional	O
fine	B-Method
-	I-Method
tuning	I-Method
method	I-Method
.	O
	
The	O
baseline	O
networks	O
are	O
pretrained	O
on	O
ImageNet	O
and	O
fine	O
-	O
tuned	O
to	O
predict	O
the	O
person	O
identities	O
.	O
	
As	O
shown	O
in	O
Tab	O
.	O
	
[	O
reference	O
]	O
,	O
we	O
obtain	O
50.89	O
%	O
,	O
65.02	O
%	O
and	O
73.69	O
%	O
rank	B-Metric
-	I-Metric
1	I-Metric
accuracy	I-Metric
by	O
CaffeNet	B-Method
,	O
VGG16	B-Method
and	O
ResNet	B-Method
-	I-Method
50	I-Method
,	O
respectively	O
on	O
Market1501	B-Material
.	O
	
Note	O
that	O
using	O
the	O
baseline	O
alone	O
exceeds	O
many	O
previous	O
works	O
.	O
	
Our	O
model	O
further	O
improves	O
these	O
baselines	O
on	O
Market1501	B-Material
.	O
	
The	O
improvement	O
can	O
be	O
observed	O
on	O
three	O
network	B-Method
architectures	I-Method
.	O
	
To	O
be	O
specific	O
,	O
we	O
obtain	O
11.25	O
%	O
,	O
5.14	O
%	O
and	O
5.82	O
%	O
improvement	O
,	O
respectively	O
,	O
using	O
CaffeNet	B-Method
,	O
VGG16	B-Method
and	O
ResNet	B-Method
-	I-Method
50	I-Method
on	O
Market1501	B-Material
.	O
	
Similarly	O
,	O
we	O
observe	O
35.8	O
%	O
,	O
49.1	O
%	O
and	O
71.5	O
%	O
baseline	O
rank	B-Metric
-	I-Metric
1	I-Metric
accuracy	O
on	O
CUHK03	O
in	O
single	B-Task
-	I-Task
shot	I-Task
setting	I-Task
.	O
	
As	O
show	O
in	O
Tab	O
.	O
	
[	O
reference	O
]	O
,	O
these	O
baseline	O
results	O
exceed	O
some	O
previous	O
works	O
as	O
well	O
.	O
	
We	O
further	O
get	O
14.0	O
%	O
,	O
22.7	O
%	O
and	O
11.9	O
%	O
improvement	O
on	O
the	O
baseline	O
by	O
our	O
method	O
.	O
	
These	O
results	O
show	O
that	O
our	O
method	O
can	O
work	O
with	O
different	O
networks	O
and	O
improve	O
their	O
results	O
.	O
	
It	O
indicates	O
that	O
the	O
proposed	O
model	O
helps	O
the	O
network	O
to	O
learn	O
more	O
discriminative	O
features	O
.	O
	
Cross	B-Metric
-	I-Metric
entropy	I-Metric
vs.	O
Contrastive	B-Method
loss	I-Method
.	O
	
We	O
replace	O
the	O
cross	B-Method
-	I-Method
entropy	I-Method
loss	I-Method
with	O
the	O
contrastive	O
loss	O
as	O
used	O
in	O
“	O
DeepID	B-Method
network	I-Method
”	O
.	O
	
However	O
,	O
we	O
find	O
a	O
4.39	O
%	O
and	O
6.55	O
%	O
drop	O
in	O
rank	B-Metric
-	I-Metric
1	I-Metric
and	O
mAP	B-Metric
.	O
	
The	O
ResNet	B-Method
-	I-Method
50	I-Method
model	O
using	O
the	O
contrastive	B-Method
loss	I-Method
has	O
75.12	O
%	O
rank	B-Metric
-	I-Metric
1	I-Metric
accuracy	I-Metric
and	O
53.32	O
%	O
mAP	B-Metric
.	O
	
We	O
speculate	O
that	O
the	O
contrastive	B-Method
loss	I-Method
tends	O
to	O
over	O
-	O
fit	O
on	O
the	O
re	B-Task
-	I-Task
ID	I-Task
dataset	O
because	O
no	O
regularization	B-Method
is	O
added	O
to	O
the	O
verification	B-Task
.	O
	
Cross	B-Method
-	I-Method
entropy	I-Method
loss	I-Method
designed	O
in	O
our	O
model	O
can	O
work	O
with	O
the	O
dropout	O
function	O
and	O
avoid	O
the	O
over	O
-	O
fitting	O
.	O
	
Comparison	O
with	O
the	O
state	O
of	O
the	O
art	O
.	O
	
As	O
shown	O
in	O
Table	O
[	O
reference	O
]	O
,	O
we	O
compare	O
our	O
method	O
with	O
other	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
algorithms	O
in	O
terms	O
of	O
mean	B-Metric
average	I-Metric
precision	I-Metric
(	O
mAP	B-Metric
)	O
and	O
rank	B-Metric
-	I-Metric
1	I-Metric
accuracy	I-Metric
on	O
Market1501	B-Material
.	O
	
We	O
report	O
the	O
single	O
-	O
query	O
as	O
well	O
as	O
multiple	B-Task
-	I-Task
query	I-Task
evaluation	I-Task
results	O
.	O
	
Our	O
model	O
(	O
CaffeNet	B-Method
)	O
achieves	O
62.14	O
%	O
rank	B-Metric
-	I-Metric
1	I-Metric
accuracy	I-Metric
and	O
39.61	O
%	O
mAP	B-Metric
,	O
which	O
is	O
comparable	O
to	O
the	O
state	O
of	O
the	O
art	O
65.88	O
%	O
rank	B-Metric
-	I-Metric
1	I-Metric
accuracy	I-Metric
and	O
39.55	O
%	O
mAP	B-Metric
.	O
	
Our	O
model	O
using	O
ResNet	B-Method
-	I-Method
50	I-Method
produces	O
the	O
best	O
performance	O
79.51	O
%	O
in	O
rank	B-Metric
-	I-Metric
1	I-Metric
accuracy	I-Metric
and	O
59.87	O
%	O
in	O
mAP	B-Metric
,	O
which	O
outperforms	O
other	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
algorithms	O
.	O
	
For	O
CUHK03	O
,	O
we	O
evaluate	O
our	O
method	O
in	O
the	O
single	B-Task
-	I-Task
shot	I-Task
setting	I-Task
as	O
shown	O
in	O
Tab	O
.	O
	
[	O
reference	O
]	O
.	O
	
There	O
is	O
only	O
one	O
right	O
image	O
in	O
the	O
searching	O
pool	O
.	O
	
In	O
the	O
evaluation	O
,	O
we	O
randomly	O
select	O
100	O
images	O
from	O
100	O
identities	O
under	O
the	O
other	O
camera	O
as	O
gallery	O
.	O
	
The	O
proposed	O
model	O
yields	O
83.4	O
%	O
rank	B-Metric
-	I-Metric
1	I-Metric
and	O
86.4	O
%	O
mAP	B-Metric
and	O
outperforms	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
performance	O
.	O
	
As	O
shown	O
in	O
Tab	O
.	O
	
[	O
reference	O
]	O
	
,	O
we	O
also	O
report	O
the	O
results	O
in	O
the	O
multi	B-Task
-	I-Task
shot	I-Task
setting	I-Task
,	O
which	O
uses	O
all	O
the	O
images	O
from	O
the	O
other	O
camera	O
as	O
gallery	O
and	O
the	O
number	O
of	O
the	O
gallery	O
images	O
is	O
about	O
500	O
.	O
	
We	O
think	O
this	O
setting	O
is	O
much	O
closer	O
to	O
image	B-Task
retrieval	I-Task
and	O
alleviate	O
the	O
unstable	O
effect	O
caused	O
by	O
the	O
random	B-Method
searching	I-Method
pool	I-Method
under	O
single	O
-	O
shot	O
settings	O
.	O
	
Fig	O
.	O
	
[	O
reference	O
]	O
presents	O
some	O
re	B-Task
-	I-Task
ID	I-Task
samples	O
on	O
CUHK03	O
dataset	O
.	O
	
The	O
images	O
in	O
the	O
first	O
column	O
are	O
the	O
query	O
images	O
.	O
	
The	O
retrieval	O
images	O
are	O
sorted	O
according	O
to	O
the	O
similarity	O
scores	O
from	O
left	O
to	O
right	O
.	O
	
Most	O
ground	O
-	O
truth	O
candidate	O
images	O
are	O
correctly	O
retrieved	O
.	O
	
Although	O
the	O
model	O
retrieves	O
some	O
incorrect	O
candidates	O
on	O
the	O
third	O
row	O
,	O
we	O
find	O
it	O
is	O
a	O
reasonable	O
prediction	O
since	O
the	O
man	O
with	O
red	O
hat	O
and	O
blue	O
coat	O
is	O
similar	O
to	O
the	O
query	O
.	O
	
The	O
proposed	O
model	O
yields	O
88.3	O
%	O
rank	B-Metric
-	I-Metric
1	I-Metric
and	O
85.0	O
%	O
mAP	B-Metric
and	O
also	O
outperforms	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
performance	O
in	O
the	O
multi	B-Task
-	I-Task
shot	I-Task
setting	I-Task
.	O
	
Results	O
between	O
camera	O
pairs	O
.	O
	
CUHK03	O
only	O
contains	O
two	O
camera	O
views	O
.	O
	
So	O
this	O
experiment	O
is	O
evaluated	O
on	O
Market1501	B-Material
since	O
it	O
contains	O
six	O
different	O
cameras	O
.	O
	
We	O
provide	O
the	O
re	B-Task
-	I-Task
identification	I-Task
results	O
between	O
all	O
camera	O
pairs	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
.	O
	
Although	O
camera	B-Method
-	I-Method
6	I-Method
is	O
a	O
low	O
-	O
resolution	B-Method
camera	I-Method
and	O
captures	O
distinct	O
background	O
with	O
the	O
other	O
HD	B-Method
cameras	I-Method
,	O
the	O
re	B-Task
-	I-Task
ID	I-Task
accuracy	O
between	O
camera	O
6	O
and	O
the	O
others	O
is	O
relatively	O
high	O
.	O
	
We	O
also	O
compute	O
the	O
cross	O
-	O
camera	O
average	O
mAP	B-Metric
and	O
average	O
rank	B-Metric
-	I-Metric
1	I-Metric
accuracy	O
:	O
48.42	O
%	O
and	O
54.42	O
%	O
respectively	O
.	O
	
Comparing	O
to	O
the	O
previous	O
reported	O
results	O
,	O
i.e.	O
,	O
10.51	O
%	O
and	O
13.72	O
%	O
in	O
,	O
our	O
method	O
largely	O
improves	O
the	O
performance	O
and	O
observes	O
a	O
smaller	O
standard	O
deviation	O
between	O
cameras	O
.	O
	
It	O
suggests	O
that	O
the	O
discriminatively	O
learned	O
embedding	B-Method
works	O
under	O
different	O
viewpoints	O
.	O
	
Further	O
,	O
Fig	O
.	O
	
[	O
reference	O
]	O
shows	O
the	O
Barnes	O
-	O
Hut	O
t	O
-	O
SNE	O
visualization	O
on	O
the	O
learned	O
embeddings	B-Method
of	O
our	O
model	O
.	O
	
By	O
the	O
clustering	B-Method
algorithm	I-Method
,	O
the	O
persons	O
wearing	O
the	O
similar	O
-	O
color	O
clothes	O
are	O
quit	O
clustered	O
together	O
and	O
are	O
apart	O
from	O
other	O
persons	O
.	O
	
The	O
learned	O
pedestrian	B-Method
descriptor	I-Method
pay	O
more	O
attention	O
to	O
the	O
color	O
and	O
it	O
is	O
robust	O
to	O
some	O
illusion	O
and	O
viewpoint	O
variations	O
.	O
	
In	O
realistic	O
setting	O
,	O
we	O
think	O
color	O
provides	O
the	O
most	O
important	O
information	O
to	O
figure	O
out	O
the	O
person	O
.	O
	
Large	O
-	O
scale	O
experiments	O
.	O
	
The	O
Market1501	B-Material
dataset	O
also	O
provides	O
an	O
additional	O
distractor	O
set	O
with	O
500k	O
images	O
to	O
enlarge	O
the	O
gallery	O
.	O
	
In	O
general	O
,	O
more	O
candidate	O
images	O
may	O
confuse	O
the	O
image	B-Task
retrieval	I-Task
.	O
	
The	O
re	B-Metric
-	I-Metric
ID	I-Metric
performance	I-Metric
of	O
our	O
model	O
(	O
ResNet	B-Method
)	O
on	O
the	O
large	O
-	O
scale	O
dataset	O
is	O
presented	O
in	O
Tab	O
.	O
	
[	O
reference	O
]	O
.	O
	
As	O
the	O
searching	O
pool	O
gets	O
larger	O
,	O
the	O
accuracy	B-Metric
drops	O
.	O
	
With	O
the	O
gallery	O
size	O
of	O
,	O
we	O
still	O
achieve	O
68.26	O
%	O
rank1	B-Metric
accuracy	I-Metric
and	O
45.24	O
%	O
mAP	B-Metric
.	O
	
A	O
relative	O
drop	O
24.4	O
%	O
from	O
59.87	O
%	O
to	O
45.24	O
%	O
on	O
mAP	B-Metric
is	O
observed	O
,	O
compared	O
to	O
a	O
relative	O
drop	O
37.88	O
%	O
from	O
13.94	O
%	O
to	O
8.66	O
%	O
in	O
our	O
previous	O
work	O
.	O
	
Besides	O
,	O
we	O
also	O
compare	O
our	O
result	O
with	O
the	O
performance	O
of	O
the	O
ResNet	B-Method
Baseline	I-Method
.	O
	
As	O
shown	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
	
,	O
it	O
is	O
interesting	O
that	O
the	O
re	B-Task
-	I-Task
ID	I-Task
precision	O
of	O
our	O
model	O
decreases	O
more	O
quickly	O
comparing	O
to	O
the	O
baseline	O
model	O
.	O
	
We	O
speculate	O
that	O
the	O
Market1501	B-Material
training	O
set	O
is	O
relatively	O
small	O
in	O
covering	O
the	O
pedestrian	O
variations	O
encountered	O
in	O
a	O
much	O
larger	O
test	O
set	O
.	O
	
In	O
fact	O
,	O
the	O
500k	O
dataset	O
was	O
collected	O
in	O
a	O
different	O
time	O
(	O
the	O
same	O
location	O
)	O
with	O
the	O
Market1501	B-Material
dataset	O
,	O
so	O
the	O
transfer	O
effect	O
is	O
large	O
enough	O
that	O
the	O
learned	O
embedding	B-Method
is	O
inferior	O
to	O
the	O
baseline	O
on	O
the	O
scale	O
of	O
500	O
k	O
images	O
.	O
	
In	O
the	O
future	O
,	O
we	O
will	O
look	O
into	O
this	O
interesting	O
problem	O
and	O
design	O
more	O
robust	O
descriptors	O
for	O
the	O
transfer	O
dataset	O
.	O
	
subsection	O
:	O
Instance	B-Task
Retrieval	I-Task
	
We	O
apply	O
the	O
identification	O
-	O
verification	B-Task
model	O
to	O
the	O
generic	B-Task
image	I-Task
retrieval	I-Task
task	I-Task
.	O
	
Oxford5k	O
is	O
a	O
testing	O
dataset	O
containing	O
buildings	O
in	O
the	O
Oxford	O
University	O
.	O
	
We	O
train	O
the	O
network	O
on	O
another	O
scene	O
dataset	O
proposed	O
in	O
,	O
which	O
comprises	O
of	O
a	O
number	O
of	O
buildings	O
without	O
overlapping	O
with	O
the	O
Oxford5k	O
.	O
	
Similarly	O
,	O
the	O
model	O
is	O
trained	O
to	O
not	O
only	O
tell	O
which	O
building	O
the	O
image	O
depicts	O
but	O
also	O
determine	O
whether	O
the	O
two	O
input	O
images	O
are	O
from	O
the	O
same	O
architecture	O
.	O
	
The	O
training	O
data	O
is	O
high	O
-	O
resolution	O
.	O
	
In	O
order	O
to	O
obtain	O
more	O
information	O
from	O
the	O
high	O
-	O
resolution	O
building	O
images	O
,	O
we	O
modify	O
the	O
final	O
pooling	B-Method
layer	I-Method
of	O
our	O
model	O
to	O
a	O
MAC	B-Method
layer	I-Method
,	O
which	O
outputs	O
the	O
maximum	O
value	O
over	O
the	O
whole	O
activation	O
map	O
.	O
	
This	O
layer	O
helps	O
us	O
to	O
handle	O
large	O
images	O
without	O
resizing	O
them	O
to	O
a	O
fixed	O
size	O
and	O
output	O
a	O
fixed	O
-	O
dimension	O
feature	O
to	O
retrieve	O
the	O
images	O
.	O
	
During	O
training	O
,	O
the	O
input	O
image	O
is	O
randomly	O
cropped	O
to	O
from	O
and	O
mirrored	O
horizontally	O
.	O
	
During	O
testing	O
,	O
we	O
keep	O
the	O
original	O
size	O
of	O
the	O
images	O
that	O
are	O
not	O
cropped	O
or	O
resized	O
and	O
extract	O
the	O
feature	O
.	O
	
In	O
Table	O
[	O
reference	O
]	O
,	O
many	O
previous	O
works	O
are	O
based	O
on	O
CaffeNet	B-Method
or	O
VGG16	B-Method
.	O
	
For	O
fair	O
comparison	O
,	O
we	O
report	O
the	O
baseline	O
results	O
and	O
the	O
results	O
of	O
our	O
model	O
based	O
on	O
these	O
two	O
network	O
structures	O
,	O
respectively	O
.	O
	
Our	O
model	O
which	O
uses	O
CaffeNet	B-Method
as	O
pretrained	B-Method
model	I-Method
outperforms	O
the	O
state	O
of	O
the	O
art	O
.	O
	
Meanwhile	O
,	O
the	O
model	O
using	O
VGG16	B-Method
is	O
comparable	O
to	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
arts	O
methods	O
.	O
	
The	O
proposed	O
method	O
show	O
a	O
6.0	O
%	O
and	O
6.6	O
%	O
improvement	O
over	O
the	O
baseline	O
networks	O
CaffeNet	B-Method
and	O
VGG16	B-Method
,	O
respectively	O
.	O
	
We	O
visualize	O
some	O
retrieval	B-Task
results	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
.	O
	
The	O
images	O
in	O
the	O
first	O
column	O
are	O
the	O
query	O
images	O
.	O
	
The	O
retrieval	O
images	O
are	O
sorted	O
according	O
to	O
the	O
similarity	O
scores	O
from	O
left	O
to	O
right	O
.	O
	
The	O
main	O
difficulty	O
in	O
the	O
image	B-Task
retrieval	I-Task
is	O
various	O
object	O
sizes	O
in	O
the	O
image	O
.	O
	
In	O
the	O
first	O
row	O
,	O
we	O
use	O
the	O
roof	O
(	O
part	O
of	O
the	O
building	O
)	O
to	O
retrieve	O
the	O
images	O
and	O
the	O
top	O
five	O
images	O
are	O
correct	O
candidate	O
images	O
.	O
	
The	O
other	O
retrieval	O
samples	O
also	O
show	O
our	O
model	O
is	O
robust	O
to	O
the	O
scale	O
variations	O
.	O
	
section	O
:	O
Conclusion	O
	
In	O
this	O
work	O
,	O
we	O
propose	O
a	O
siamese	B-Method
network	I-Method
that	O
simultaneously	O
considers	O
the	O
identification	B-Metric
loss	I-Metric
and	O
the	O
verification	B-Task
loss	O
.	O
	
The	O
proposed	O
model	O
learns	O
a	O
discriminative	O
embedding	B-Method
and	O
a	O
similarity	O
measurement	O
at	O
the	O
same	O
time	O
.	O
	
It	O
outperforms	O
the	O
state	O
of	O
the	O
art	O
on	O
two	O
popular	O
person	O
re	B-Task
-	I-Task
ID	I-Task
benchmarks	O
and	O
shows	O
potential	O
ability	O
to	O
apply	O
on	O
the	O
generic	B-Task
instance	I-Task
retrieval	I-Task
task	I-Task
.	O
	
Future	O
work	O
includes	O
exploring	O
more	O
novel	O
applications	O
of	O
the	O
proposed	O
method	O
,	O
such	O
as	O
car	B-Task
recognition	I-Task
and	O
fine	B-Task
-	I-Task
grained	I-Task
classification	I-Task
.	O
	
Besides	O
,	O
we	O
will	O
investigate	O
how	O
to	O
learn	O
a	O
robust	B-Method
descriptor	I-Method
to	O
further	O
improve	O
the	O
performance	O
of	O
the	O
person	B-Task
re	I-Task
-	I-Task
identification	I-Task
on	O
large	O
-	O
scale	O
testing	O
set	O
.	O
	
bibliography	O
:	O
References	O
	
document	O
:	O
Learning	O
to	O
Adapt	O
Structured	O
Output	O
Space	O
for	O
Semantic	B-Task
Segmentation	I-Task
	
Convolutional	B-Method
neural	I-Method
network	I-Method
-	I-Method
based	I-Method
approaches	I-Method
for	O
semantic	B-Task
segmentation	I-Task
rely	O
on	O
supervision	O
with	O
pixel	O
-	O
level	O
ground	O
truth	O
,	O
but	O
may	O
not	O
generalize	O
well	O
to	O
unseen	O
image	O
domains	O
.	O
	
As	O
the	O
labeling	B-Task
process	I-Task
is	O
tedious	O
and	O
labor	O
intensive	O
,	O
developing	O
algorithms	O
that	O
can	O
adapt	O
source	O
ground	O
truth	O
labels	O
to	O
the	O
target	O
domain	O
is	O
of	O
great	O
interest	O
.	O
	
In	O
this	O
paper	O
,	O
we	O
propose	O
an	O
adversarial	B-Method
learning	I-Method
method	I-Method
for	O
domain	B-Method
adaptation	I-Method
in	O
the	O
context	O
of	O
semantic	B-Task
segmentation	I-Task
.	O
	
Considering	O
semantic	B-Task
segmentations	I-Task
as	O
structured	O
outputs	O
that	O
contain	O
spatial	O
similarities	O
between	O
the	O
source	O
and	O
target	O
domains	O
,	O
we	O
adopt	O
adversarial	B-Method
learning	I-Method
in	O
the	O
output	O
space	O
.	O
	
To	O
further	O
enhance	O
the	O
adapted	O
model	O
,	O
we	O
construct	O
a	O
multi	B-Method
-	I-Method
level	I-Method
adversarial	I-Method
network	I-Method
to	O
effectively	O
perform	O
output	O
space	O
domain	B-Method
adaptation	I-Method
at	O
different	O
feature	O
levels	O
.	O
	
Extensive	O
experiments	O
and	O
ablation	O
study	O
are	O
conducted	O
under	O
various	O
domain	B-Method
adaptation	I-Method
settings	O
,	O
including	O
synthetic	B-Task
-	I-Task
to	I-Task
-	I-Task
real	I-Task
and	O
cross	B-Task
-	I-Task
city	I-Task
scenarios	I-Task
.	O
	
We	O
show	O
that	O
the	O
proposed	O
method	O
performs	O
favorably	O
against	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
methods	O
in	O
terms	O
of	O
accuracy	B-Metric
and	O
visual	B-Metric
quality	I-Metric
.	O
	
section	O
:	O
Introduction	O
	
Semantic	B-Task
segmentation	I-Task
aims	O
to	O
assign	O
each	O
pixel	O
a	O
semantic	O
label	O
,	O
e.g.	O
,	O
person	O
,	O
car	O
,	O
road	O
or	O
tree	O
,	O
in	O
an	O
image	O
.	O
	
Recently	O
,	O
methods	O
based	O
on	O
convolutional	B-Method
neural	I-Method
networks	I-Method
(	O
CNNs	B-Method
)	O
have	O
achieved	O
significant	O
progress	O
in	O
semantic	B-Task
segmentation	I-Task
with	O
applications	O
for	O
autonomous	B-Task
driving	I-Task
and	I-Task
image	I-Task
editing	I-Task
.	O
	
The	O
crux	O
of	O
CNN	B-Method
-	I-Method
based	I-Method
approaches	I-Method
is	O
to	O
annotate	O
a	O
large	O
number	O
of	O
images	O
that	O
cover	O
possible	O
scene	O
variations	O
.	O
	
However	O
,	O
this	O
trained	O
model	O
may	O
not	O
generalize	O
well	O
to	O
unseen	O
images	O
,	O
especially	O
when	O
there	O
is	O
a	O
domain	O
gap	O
between	O
the	O
training	O
(	O
source	O
)	O
and	O
test	O
(	O
target	O
)	O
images	O
.	O
	
For	O
instance	O
,	O
the	O
distribution	O
of	O
appearance	O
for	O
objects	O
and	O
scenes	O
may	O
vary	O
in	O
different	O
cities	O
,	O
and	O
even	O
weather	O
and	O
lighting	O
conditions	O
can	O
change	O
significantly	O
in	O
the	O
same	O
city	O
.	O
	
In	O
such	O
cases	O
,	O
relying	O
only	O
on	O
the	O
supervised	B-Method
model	I-Method
that	O
requires	O
re	O
-	O
annotating	O
per	O
-	O
pixel	O
ground	O
truths	O
in	O
different	O
scenarios	O
would	O
entail	O
prohibitively	O
high	O
labor	B-Metric
cost	I-Metric
.	O
	
To	O
address	O
this	O
issue	O
,	O
knowledge	B-Method
transfer	I-Method
or	O
domain	B-Method
adaptation	I-Method
techniques	O
have	O
been	O
proposed	O
to	O
close	O
the	O
gap	O
between	O
source	O
and	O
target	O
domains	O
,	O
where	O
annotations	O
are	O
not	O
available	O
in	O
the	O
target	O
domain	O
.	O
	
For	O
image	B-Task
classification	I-Task
,	O
one	O
effective	O
approach	O
is	O
to	O
align	O
features	O
across	O
two	O
domains	O
such	O
that	O
the	O
adapted	O
features	O
can	O
generalize	O
to	O
both	O
domains	O
.	O
	
Similar	O
efforts	O
have	O
been	O
made	O
for	O
semantic	B-Task
segmentation	I-Task
via	O
adversarial	B-Method
learning	I-Method
in	O
the	O
feature	O
space	O
.	O
	
However	O
,	O
different	O
from	O
the	O
image	B-Task
classification	I-Task
task	I-Task
,	O
feature	B-Method
adaptation	I-Method
for	O
semantic	B-Task
segmentation	I-Task
may	O
suffer	O
from	O
the	O
complexity	O
of	O
high	O
-	O
dimensional	O
features	O
that	O
needs	O
to	O
encode	O
diverse	O
visual	O
cues	O
,	O
including	O
appearance	O
,	O
shape	O
and	O
context	O
.	O
	
This	O
motivates	O
us	O
to	O
develop	O
an	O
effective	O
method	O
for	O
adapting	B-Task
pixel	I-Task
-	I-Task
level	I-Task
prediction	I-Task
tasks	I-Task
rather	O
than	O
using	O
feature	B-Method
adaptation	I-Method
.	O
	
In	O
semantic	B-Task
segmentation	I-Task
,	O
we	O
note	O
that	O
the	O
output	O
space	O
contains	O
rich	O
information	O
,	O
both	O
spatially	O
and	O
locally	O
.	O
	
For	O
instance	O
,	O
even	O
if	O
images	O
from	O
two	O
domains	O
are	O
very	O
different	O
in	O
appearance	O
,	O
their	O
segmentation	O
outputs	O
share	O
a	O
significant	O
amount	O
of	O
similarities	O
,	O
e.g.	O
,	O
spatial	O
layout	O
and	O
local	O
context	O
(	O
see	O
Figure	O
[	O
reference	O
]	O
)	O
.	O
	
Based	O
on	O
this	O
observation	O
,	O
we	O
address	O
the	O
pixel	O
-	O
level	O
domain	B-Method
adaptation	I-Method
problem	O
in	O
the	O
output	B-Task
(	I-Task
segmentation	I-Task
)	I-Task
space	I-Task
.	O
	
In	O
this	O
paper	O
,	O
we	O
propose	O
an	O
end	O
-	O
to	O
-	O
end	O
CNN	O
-	O
based	O
domain	B-Method
adaptation	I-Method
algorithm	O
for	O
semantic	B-Task
segmentation	I-Task
.	O
	
Our	O
formulation	O
is	O
based	O
on	O
adversarial	B-Method
learning	I-Method
in	O
the	O
output	O
space	O
,	O
where	O
the	O
intuition	O
is	O
to	O
directly	O
make	O
the	O
predicted	O
label	O
distributions	O
close	O
to	O
each	O
other	O
across	O
source	O
and	O
target	O
domains	O
.	O
	
Based	O
on	O
the	O
generative	B-Method
adversarial	I-Method
network	I-Method
(	O
GAN	B-Method
)	O
,	O
the	O
proposed	O
model	O
consists	O
of	O
two	O
parts	O
:	O
1	O
)	O
a	O
segmentation	B-Method
model	I-Method
to	O
predict	O
output	O
results	O
,	O
and	O
2	O
)	O
a	O
discriminator	B-Method
to	O
distinguish	O
whether	O
the	O
input	O
is	O
from	O
the	O
source	O
or	O
target	O
segmentation	O
output	O
.	O
	
With	O
an	O
adversarial	B-Method
loss	I-Method
,	O
the	O
proposed	O
segmentation	B-Method
model	I-Method
aims	O
to	O
fool	O
the	O
discriminator	B-Method
,	O
with	O
the	O
goal	O
of	O
generating	O
similar	O
distributions	O
in	O
the	O
output	O
space	O
for	O
either	O
source	O
or	O
target	O
images	O
.	O
	
The	O
proposed	O
method	O
also	O
adapts	O
features	O
as	O
the	O
errors	O
are	O
back	O
-	O
propagated	O
to	O
the	O
feature	O
level	O
from	O
the	O
output	O
labels	O
.	O
	
However	O
,	O
one	O
concern	O
is	O
that	O
lower	O
-	O
level	O
features	O
may	O
not	O
be	O
adapted	O
well	O
as	O
they	O
are	O
far	O
away	O
from	O
the	O
high	O
-	O
level	O
output	O
labels	O
.	O
	
To	O
address	O
this	O
issue	O
,	O
we	O
develop	O
a	O
multi	B-Method
-	I-Method
level	I-Method
strategy	I-Method
by	O
incorporating	O
adversarial	B-Method
learning	I-Method
at	O
different	O
feature	O
levels	O
of	O
the	O
segmentation	B-Method
model	I-Method
.	O
	
For	O
instance	O
,	O
we	O
can	O
use	O
both	O
conv5	O
and	O
conv4	O
features	O
to	O
predict	O
segmentation	B-Task
results	O
in	O
the	O
output	O
space	O
.	O
	
Then	O
two	O
discriminators	O
can	O
be	O
connected	O
to	O
each	O
of	O
the	O
predicted	O
output	O
for	O
multi	B-Method
-	I-Method
level	I-Method
adversarial	I-Method
learning	I-Method
.	O
	
We	O
perform	O
one	O
-	O
stage	O
end	B-Task
-	I-Task
to	I-Task
-	I-Task
end	I-Task
training	I-Task
for	O
the	O
segmentation	B-Method
model	I-Method
and	O
discriminators	B-Method
jointly	O
,	O
without	O
using	O
any	O
prior	O
knowledge	O
of	O
the	O
data	O
in	O
the	O
target	O
domain	O
.	O
	
In	O
the	O
testing	O
phase	O
,	O
we	O
can	O
simply	O
discard	O
discriminators	B-Method
and	O
use	O
the	O
adapted	O
segmentation	B-Method
model	I-Method
on	O
target	O
images	O
,	O
with	O
no	O
extra	O
computational	B-Metric
requirements	I-Metric
.	O
	
Due	O
to	O
the	O
high	O
labor	B-Metric
cost	I-Metric
of	O
annotating	B-Task
segmentation	I-Task
ground	I-Task
truth	I-Task
,	O
there	O
has	O
been	O
great	O
interest	O
in	O
large	O
-	O
scale	O
synthetic	O
datasets	O
with	O
annotations	O
,	O
e.g.	O
,	O
GTA5	O
and	O
SYNTHIA	O
.	O
	
As	O
a	O
result	O
,	O
one	O
critical	O
setting	O
is	O
to	O
adapt	O
the	O
model	O
trained	O
on	O
synthetic	O
data	O
to	O
real	O
-	O
world	O
datasets	O
,	O
such	O
as	O
Cityscapes	O
.	O
	
We	O
follow	O
this	O
setting	O
and	O
conduct	O
extensive	O
experiments	O
to	O
validate	O
the	O
proposed	O
domain	B-Method
adaptation	I-Method
method	I-Method
.	O
	
First	O
,	O
we	O
use	O
a	O
strong	O
baseline	O
model	O
that	O
is	O
able	O
to	O
generalize	O
to	O
different	O
domains	O
.	O
	
We	O
note	O
that	O
a	O
strong	O
baseline	O
facilitates	O
real	B-Task
-	I-Task
world	I-Task
applications	I-Task
and	O
can	O
evaluate	O
the	O
limitation	O
of	O
the	O
proposed	O
adaptation	B-Method
approach	I-Method
.	O
	
Based	O
on	O
this	O
baseline	O
model	O
,	O
we	O
show	O
comparisons	O
using	O
adversarial	B-Method
adaptation	I-Method
in	O
the	O
feature	O
and	O
output	O
spaces	O
.	O
	
Furthermore	O
,	O
we	O
show	O
that	O
the	O
multi	B-Method
-	I-Method
level	I-Method
adversarial	I-Method
learning	I-Method
improves	O
the	O
results	O
over	O
single	B-Method
-	O
level	O
adaptation	O
.	O
	
In	O
addition	O
to	O
the	O
synthetic	B-Task
-	I-Task
to	I-Task
-	I-Task
real	I-Task
setting	I-Task
,	O
we	O
show	O
experimental	O
results	O
on	O
the	O
Cross	O
-	O
City	O
dataset	O
,	O
where	O
annotations	O
are	O
provided	O
in	O
one	O
city	O
(	O
source	O
)	O
,	O
while	O
testing	O
the	O
model	O
on	O
another	O
unseen	O
city	O
(	O
target	O
)	O
.	O
	
Overall	O
,	O
our	O
method	O
performs	O
favorably	O
against	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
algorithms	O
on	O
numerous	O
benchmark	O
datasets	O
under	O
different	O
settings	O
.	O
	
The	O
contributions	O
of	O
this	O
work	O
are	O
as	O
follows	O
.	O
	
First	O
,	O
we	O
propose	O
a	O
domain	B-Method
adaptation	I-Method
method	I-Method
for	O
pixel	B-Task
-	I-Task
level	I-Task
semantic	I-Task
segmentation	I-Task
via	O
adversarial	B-Method
learning	I-Method
.	O
	
Second	O
,	O
we	O
demonstrate	O
that	O
adaptation	O
in	O
the	O
output	O
(	O
segmentation	O
)	O
space	O
can	O
effectively	O
align	O
scene	O
layout	O
and	O
local	O
context	O
between	O
source	O
and	O
target	O
images	O
.	O
	
Third	O
,	O
a	O
multi	B-Method
-	I-Method
level	I-Method
adversarial	I-Method
learning	I-Method
scheme	O
is	O
developed	O
to	O
adapt	O
features	O
at	O
different	O
levels	O
of	O
the	O
segmentation	B-Method
model	I-Method
,	O
which	O
leads	O
to	O
improved	O
performance	O
.	O
	
section	O
:	O
Related	O
Work	O
	
Semantic	B-Task
Segmentation	I-Task
.	O
	
State	O
-	O
of	O
-	O
the	O
-	O
art	O
semantic	B-Method
segmentation	I-Method
methods	I-Method
are	O
mainly	O
based	O
on	O
the	O
recent	O
advances	O
of	O
deep	B-Method
neural	I-Method
networks	I-Method
.	O
	
As	O
proposed	O
by	O
Long	O
,	O
one	O
can	O
transform	O
a	O
classification	B-Method
CNN	I-Method
(	O
e.g.	O
,	O
AlexNet	B-Method
,	O
VGG	B-Method
,	O
or	O
ResNet	B-Method
)	O
to	O
a	O
fully	B-Method
-	I-Method
convolutional	I-Method
network	I-Method
(	O
FCN	B-Method
)	O
for	O
semantic	B-Task
segmentation	I-Task
.	O
	
Numerous	O
methods	O
have	O
since	O
been	O
developed	O
to	O
improve	O
this	O
model	O
by	O
utilizing	O
context	O
information	O
or	O
enlarging	O
receptive	O
fields	O
.	O
	
To	O
train	O
these	O
advanced	O
networks	O
,	O
a	O
substantial	O
amount	O
of	O
dense	O
pixel	O
annotations	O
must	O
be	O
collected	O
in	O
order	O
to	O
match	O
the	O
model	O
capacity	O
of	O
deep	B-Method
CNNs	I-Method
.	O
	
As	O
a	O
result	O
,	O
weakly	B-Method
and	I-Method
semi	I-Method
-	I-Method
supervised	I-Method
approaches	I-Method
are	O
proposed	O
in	O
recent	O
years	O
to	O
reduce	O
the	O
heavy	B-Metric
labeling	I-Metric
cost	I-Metric
of	O
collecting	B-Task
segmentation	I-Task
ground	I-Task
truths	I-Task
.	O
	
However	O
,	O
in	O
most	O
real	O
-	O
world	B-Task
applications	I-Task
,	O
it	O
is	O
difficult	O
to	O
obtain	O
weak	O
annotations	O
and	O
the	O
trained	O
model	O
may	O
not	O
generalize	O
well	O
to	O
unseen	O
image	O
domains	O
.	O
	
Another	O
approach	O
to	O
tackle	O
the	O
annotation	B-Task
problem	I-Task
is	O
to	O
construct	O
synthetic	O
datasets	O
based	O
on	O
rendering	B-Method
,	O
e.g.	O
,	O
GTA5	B-Method
and	O
SYNTHIA	O
.	O
	
While	O
the	O
data	B-Task
collection	I-Task
is	O
less	O
costly	O
since	O
the	O
pixel	B-Task
-	I-Task
level	I-Task
annotation	I-Task
can	O
be	O
done	O
with	O
a	O
partially	O
automated	B-Method
process	I-Method
,	O
these	O
datasets	O
are	O
usually	O
used	O
in	O
conjunction	O
with	O
real	O
-	O
world	O
datasets	O
for	O
joint	B-Task
learning	I-Task
to	O
improve	O
the	O
performance	O
.	O
	
However	O
,	O
when	O
training	O
solely	O
on	O
the	O
synthetic	O
dataset	O
,	O
the	O
model	O
does	O
not	O
generalize	O
well	O
to	O
real	O
-	O
world	O
data	O
,	O
mainly	O
due	O
to	O
the	O
large	O
domain	O
shift	O
between	O
synthetic	O
images	O
and	O
real	O
-	O
world	O
images	O
,	O
i.e.	O
,	O
appearance	O
differences	O
are	O
still	O
significant	O
with	O
current	O
rendering	B-Method
techniques	I-Method
.	O
	
Although	O
synthesizing	O
more	O
realistic	O
images	O
can	O
decrease	O
the	O
domain	O
shift	O
,	O
it	O
is	O
necessary	O
to	O
use	O
domain	B-Method
adaptation	I-Method
to	O
narrow	O
the	O
performance	O
gap	O
.	O
	
Domain	B-Method
Adaptation	I-Method
.	O
	
Domain	B-Method
adaptation	I-Method
methods	I-Method
for	O
image	B-Task
classification	I-Task
have	O
been	O
developed	O
to	O
address	O
the	O
domain	B-Task
-	I-Task
shift	I-Task
problem	I-Task
between	O
the	O
source	O
and	O
target	O
domains	O
.	O
	
Numerous	O
methods	O
are	O
developed	O
based	O
on	O
CNN	B-Method
classifiers	I-Method
due	O
to	O
performance	O
gain	O
.	O
	
The	O
main	O
insight	O
behind	O
these	O
approaches	O
is	O
to	O
tackle	O
the	O
problem	O
by	O
aligning	O
the	O
feature	O
distribution	O
between	O
source	O
and	O
target	O
images	O
.	O
	
Ganin	B-Method
propose	O
the	O
Domain	B-Method
-	I-Method
Adversarial	I-Method
Neural	I-Method
Network	I-Method
(	O
DANN	B-Method
)	O
to	O
transfer	O
the	O
feature	O
distribution	O
.	O
	
A	O
number	O
of	O
variants	O
have	O
since	O
been	O
proposed	O
with	O
different	O
loss	B-Method
functions	I-Method
or	O
classifiers	B-Method
.	O
	
Recently	O
,	O
the	O
PixelDA	B-Method
method	I-Method
addresses	O
domain	B-Method
adaptation	I-Method
for	O
image	B-Task
classification	I-Task
by	O
transferring	O
the	O
source	O
images	O
to	O
target	O
domain	O
,	O
thereby	O
obtaining	O
a	O
simulated	O
training	O
set	O
for	O
target	O
images	O
.	O
	
We	O
note	O
that	O
domain	B-Method
adaptation	I-Method
for	O
pixel	B-Task
-	I-Task
level	I-Task
prediction	I-Task
tasks	I-Task
have	O
not	O
been	O
explored	O
widely	O
.	O
	
Hoffman	O
introduce	O
the	O
task	O
of	O
domain	B-Method
adaptation	I-Method
on	O
semantic	B-Task
segmentation	I-Task
by	O
applying	O
adversarial	B-Method
learning	I-Method
(	O
i.e.	O
,	O
DANN	B-Method
)	O
in	O
a	O
fully	B-Method
-	I-Method
convolutional	I-Method
way	I-Method
on	O
feature	B-Method
representations	I-Method
and	O
additional	O
category	O
constraints	O
similar	O
to	O
the	O
constrained	B-Method
CNN	I-Method
.	O
	
Other	O
methods	O
focus	O
on	O
adapting	O
synthetic	B-Task
-	I-Task
to	I-Task
-	I-Task
real	I-Task
or	O
cross	B-Task
-	I-Task
city	I-Task
images	I-Task
by	O
adopting	O
class	B-Method
-	I-Method
wise	I-Method
adversarial	I-Method
learning	I-Method
or	O
label	B-Method
transfer	I-Method
.	O
	
Similar	O
to	O
the	O
PixelDA	B-Method
method	I-Method
,	O
one	O
concurrent	O
work	O
,	O
CyCADA	B-Method
uses	O
the	O
CycleGAN	B-Method
and	O
transfers	O
source	O
domain	O
images	O
to	O
the	O
target	O
domain	O
with	O
pixel	O
alignment	O
,	O
thus	O
generating	O
extra	O
training	O
data	O
combined	O
with	O
feature	B-Method
space	I-Method
adversarial	I-Method
learning	I-Method
.	O
	
Although	O
feature	B-Method
space	I-Method
adaptation	I-Method
has	O
been	O
successfully	O
applied	O
to	O
image	B-Task
classification	I-Task
,	O
pixel	B-Task
-	I-Task
level	I-Task
tasks	I-Task
such	O
as	O
semantic	B-Task
segmentation	I-Task
remains	O
challenging	O
based	O
on	O
feature	B-Method
adaptation	I-Method
-	O
based	O
approaches	O
.	O
	
In	O
this	O
paper	O
,	O
we	O
use	O
the	O
property	O
that	O
pixel	O
-	O
level	O
predictions	O
are	O
structured	O
outputs	O
that	O
contain	O
information	O
spatially	O
and	O
locally	O
,	O
to	O
propose	O
an	O
efficient	O
domain	B-Method
adaptation	I-Method
algorithm	O
through	O
adversarial	B-Method
learning	I-Method
in	O
the	O
output	O
space	O
.	O
	
section	O
:	O
Algorithmic	O
Overview	O
	
subsection	O
:	O
Overview	O
of	O
the	O
Proposed	O
Model	O
	
Our	O
domain	B-Method
adaptation	I-Method
algorithm	O
consists	O
of	O
two	O
modules	O
:	O
a	O
segmentation	B-Method
network	I-Method
and	O
the	O
discriminator	B-Method
,	O
where	O
indicates	O
the	O
level	O
of	O
a	O
discriminator	O
in	O
the	O
multi	B-Method
-	I-Method
level	I-Method
adversarial	I-Method
learning	I-Method
.	O
	
Two	O
sets	O
of	O
images	O
from	O
source	O
and	O
target	O
domains	O
are	O
denoted	O
as	O
and	O
.	O
	
We	O
first	O
forward	O
the	O
source	O
image	O
(	O
with	O
annotations	O
)	O
to	O
the	O
segmentation	B-Method
network	I-Method
for	O
optimizing	B-Task
.	O
	
Then	O
we	O
predict	O
the	O
segmentation	O
softmax	O
output	O
for	O
the	O
target	O
image	O
(	O
without	O
annotations	O
)	O
.	O
	
Since	O
our	O
goal	O
is	O
to	O
make	O
segmentation	O
predictions	O
of	O
source	O
and	O
target	O
images	O
(	O
i.e.	O
,	O
and	O
)	O
close	O
to	O
each	O
other	O
,	O
we	O
use	O
these	O
two	O
predictions	O
as	O
the	O
input	O
to	O
the	O
discriminator	O
to	O
distinguish	O
whether	O
the	O
input	O
is	O
from	O
the	O
source	O
or	O
target	O
domain	O
.	O
	
With	O
an	O
adversarial	O
loss	O
on	O
the	O
target	O
prediction	O
,	O
the	O
network	O
propagates	O
gradients	O
from	O
to	O
,	O
which	O
would	O
encourage	O
to	O
generate	O
similar	O
segmentation	O
distributions	O
in	O
the	O
target	O
domain	O
to	O
the	O
source	O
prediction	O
.	O
	
Figure	O
[	O
reference	O
]	O
shows	O
the	O
overview	O
of	O
the	O
proposed	O
algorithm	O
.	O
	
subsection	O
:	O
Objective	B-Metric
Function	I-Metric
for	O
Domain	B-Method
Adaptation	I-Method
	
With	O
the	O
proposed	O
network	O
,	O
we	O
formulate	O
the	O
adaptation	B-Task
task	I-Task
containing	O
two	O
loss	B-Method
functions	I-Method
from	O
both	O
modules	O
:	O
where	O
is	O
the	O
cross	B-Metric
-	I-Metric
entropy	I-Metric
loss	I-Metric
using	O
ground	O
truth	O
annotations	O
in	O
the	O
source	O
domain	O
,	O
and	O
is	O
the	O
adversarial	B-Method
loss	I-Method
that	O
adapts	O
predicted	O
segmentations	O
of	O
target	O
images	O
to	O
the	O
distribution	O
of	O
source	O
predictions	O
(	O
see	O
Section	O
[	O
reference	O
]	O
)	O
.	O
	
In	O
(	O
[	O
reference	O
]	O
)	O
,	O
is	O
the	O
weight	O
used	O
to	O
balance	O
the	O
two	O
losses	O
.	O
	
section	O
:	O
Output	B-Method
Space	I-Method
Adaptation	I-Method
	
Different	O
from	O
image	B-Task
classification	I-Task
based	O
on	O
features	O
that	O
describe	O
the	O
global	O
visual	O
information	O
of	O
the	O
image	O
,	O
high	O
-	O
dimensional	O
features	O
learned	O
for	O
semantic	B-Task
segmentation	I-Task
encodes	O
complex	O
representations	O
.	O
	
As	O
a	O
result	O
,	O
adaptation	O
in	O
the	O
feature	O
space	O
may	O
not	O
be	O
the	O
best	O
choice	O
for	O
semantic	B-Task
segmentation	I-Task
.	O
	
On	O
the	O
other	O
hand	O
,	O
although	O
segmentation	O
outputs	O
are	O
in	O
the	O
low	O
-	O
dimensional	O
space	O
,	O
they	O
contain	O
rich	O
information	O
,	O
e.g.	O
,	O
scene	O
layout	O
and	O
context	O
.	O
	
Our	O
intuition	O
is	O
that	O
no	O
matter	O
images	O
are	O
from	O
the	O
source	O
or	O
target	O
domain	O
,	O
their	O
segmentations	O
should	O
share	O
strong	O
similarities	O
,	O
spatially	O
and	O
locally	O
.	O
	
Thus	O
,	O
we	O
utilize	O
this	O
property	O
to	O
adapt	O
low	O
-	O
dimensional	O
softmax	O
outputs	O
of	O
segmentation	O
predictions	O
via	O
an	O
adversarial	B-Method
learning	I-Method
scheme	I-Method
.	O
	
subsection	O
:	O
Single	B-Method
-	I-Method
level	I-Method
Adversarial	I-Method
Learning	I-Method
	
Discriminator	B-Method
Training	I-Method
.	O
	
Before	O
introducing	O
how	O
to	O
adapt	O
the	O
segmentation	B-Method
network	I-Method
via	O
adversarial	B-Method
learning	I-Method
,	O
we	O
first	O
describe	O
the	O
training	B-Metric
objective	I-Metric
for	O
the	O
discriminator	B-Method
.	O
	
Given	O
the	O
segmentation	O
softmax	O
output	O
,	O
where	O
is	O
the	O
number	O
of	O
categories	O
,	O
we	O
forward	O
to	O
a	O
fully	B-Method
-	I-Method
convolutional	I-Method
discriminator	I-Method
using	O
a	O
cross	B-Metric
-	I-Metric
entropy	I-Metric
loss	I-Metric
for	O
the	O
two	O
classes	O
(	O
i.e.	O
,	O
source	O
and	O
target	O
)	O
.	O
	
The	O
loss	O
can	O
be	O
written	O
as	O
:	O
where	O
if	O
the	O
sample	O
is	O
drawn	O
from	O
the	O
target	O
domain	O
,	O
and	O
for	O
the	O
sample	O
from	O
the	O
source	O
domain	O
.	O
	
Segmentation	B-Method
Network	I-Method
Training	I-Method
.	O
	
First	O
,	O
we	O
define	O
the	O
segmentation	O
loss	O
in	O
(	O
[	O
reference	O
]	O
)	O
as	O
the	O
cross	B-Metric
-	I-Metric
entropy	I-Metric
loss	I-Metric
for	O
images	O
from	O
the	O
source	O
domain	O
:	O
where	O
is	O
the	O
ground	O
truth	O
annotations	O
for	O
source	O
images	O
and	O
is	O
the	O
segmentation	O
output	O
.	O
	
Second	O
,	O
for	O
images	O
in	O
the	O
target	O
domain	O
,	O
we	O
forward	O
them	O
to	O
and	O
obtain	O
the	O
prediction	O
.	O
	
To	O
make	O
the	O
distribution	O
of	O
closer	O
to	O
,	O
we	O
use	O
an	O
adversarial	B-Method
loss	I-Method
in	O
(	O
[	O
reference	O
]	O
)	O
as	O
:	O
This	O
loss	O
is	O
designed	O
to	O
train	O
the	O
segmentation	B-Method
network	I-Method
and	O
fool	O
the	O
discriminator	B-Method
by	O
maximizing	O
the	O
probability	O
of	O
the	O
target	O
prediction	O
being	O
considered	O
as	O
the	O
source	O
prediction	O
.	O
	
subsection	O
:	O
Multi	B-Method
-	I-Method
level	I-Method
Adversarial	I-Method
Learning	I-Method
	
Although	O
performing	O
adversarial	B-Method
learning	I-Method
in	O
the	O
output	O
space	O
directly	O
adapts	O
predictions	O
,	O
low	O
-	O
level	O
features	O
may	O
not	O
be	O
adapted	O
well	O
as	O
they	O
are	O
far	O
away	O
from	O
the	O
output	O
.	O
	
Similar	O
to	O
the	O
deep	B-Method
supervision	I-Method
method	I-Method
that	O
uses	O
auxiliary	O
loss	O
for	O
semantic	B-Task
segmentation	I-Task
,	O
we	O
incorporate	O
additional	O
adversarial	B-Method
module	I-Method
in	O
the	O
low	O
-	O
level	O
feature	O
space	O
to	O
enhance	O
the	O
adaptation	B-Task
.	O
	
The	O
training	B-Metric
objective	I-Metric
for	O
the	O
segmentation	B-Method
network	I-Method
can	O
be	O
extended	O
from	O
(	O
[	O
reference	O
]	O
)	O
as	O
:	O
where	O
indicates	O
the	O
level	O
used	O
for	O
predicting	O
the	O
segmentation	O
output	O
.	O
	
We	O
note	O
that	O
,	O
the	O
segmentation	O
output	O
is	O
still	O
predicted	O
in	O
each	O
feature	O
space	O
,	O
before	O
passing	O
through	O
individual	O
discriminators	B-Method
for	O
adversarial	B-Method
learning	I-Method
.	O
	
Hence	O
,	O
and	O
remain	O
in	O
the	O
same	O
form	O
as	O
in	O
(	O
[	O
reference	O
]	O
)	O
and	O
(	O
[	O
reference	O
]	O
)	O
,	O
respectively	O
.	O
	
Based	O
on	O
(	O
[	O
reference	O
]	O
)	O
,	O
we	O
optimize	O
the	O
following	O
min	B-Metric
-	I-Metric
max	I-Metric
criterion	I-Metric
:	O
The	O
ultimate	O
goal	O
is	O
to	O
minimize	O
the	O
segmentation	B-Metric
loss	I-Metric
in	O
for	O
source	O
images	O
,	O
while	O
maximizing	O
the	O
probability	O
of	O
target	O
predictions	O
being	O
considered	O
as	O
source	O
predictions	O
.	O
	
road	O
sidewalk	O
building	O
wall	O
fence	O
pole	O
light	O
sign	O
veg	O
terrain	O
sky	O
person	O
rider	O
car	O
truck	O
bus	O
train	O
mbike	O
bike	O
	
section	O
:	O
Network	B-Method
Architecture	I-Method
and	O
Training	O
	
Discriminator	B-Method
.	O
	
For	O
the	O
discriminator	B-Method
,	O
we	O
use	O
an	O
architecture	O
similar	O
to	O
but	O
utilize	O
all	O
fully	B-Method
-	I-Method
convolutional	I-Method
layers	I-Method
to	O
retain	O
the	O
spatial	O
information	O
.	O
	
The	O
network	O
consists	O
of	O
5	O
convolution	B-Method
layers	I-Method
with	O
kernel	O
and	O
stride	O
of	O
2	O
,	O
where	O
the	O
channel	O
number	O
is	O
{	O
64	O
,	O
128	O
,	O
256	O
,	O
512	O
,	O
1	O
}	O
,	O
respectively	O
.	O
	
Except	O
for	O
the	O
last	O
layer	O
,	O
each	O
convolution	B-Method
layer	I-Method
is	O
followed	O
by	O
a	O
leaky	B-Method
ReLU	I-Method
parameterized	I-Method
by	O
.	O
	
An	O
up	B-Method
-	I-Method
sampling	I-Method
layer	I-Method
is	O
added	O
to	O
the	O
last	O
convolution	B-Method
layer	I-Method
for	O
re	O
-	O
scaling	O
the	O
output	O
to	O
the	O
size	O
of	O
the	O
input	O
.	O
	
We	O
do	O
not	O
use	O
any	O
batch	B-Method
-	I-Method
normalization	I-Method
layers	I-Method
as	O
we	O
jointly	O
train	O
the	O
discriminator	B-Method
with	O
the	O
segmentation	B-Method
network	I-Method
using	O
a	O
small	O
batch	O
size	O
.	O
	
Segmentation	B-Method
Network	I-Method
.	O
	
It	O
is	O
essential	O
to	O
build	O
upon	O
a	O
good	O
baseline	B-Method
model	I-Method
to	O
achieve	O
high	O
-	O
quality	O
segmentation	B-Task
results	O
.	O
	
We	O
adopt	O
the	O
DeepLab	B-Method
-	I-Method
v2	I-Method
framework	I-Method
with	O
ResNet	B-Method
-	I-Method
101	I-Method
model	I-Method
pre	O
-	O
trained	O
on	O
ImageNet	B-Method
as	O
our	O
segmentation	B-Method
baseline	I-Method
network	I-Method
.	O
	
However	O
,	O
we	O
do	O
not	O
use	O
the	O
multi	B-Method
-	I-Method
scale	I-Method
fusion	I-Method
strategy	I-Method
due	O
to	O
the	O
memory	O
issue	O
.	O
	
Similar	O
to	O
the	O
recent	O
work	O
on	O
semantic	B-Task
segmentation	I-Task
,	O
we	O
remove	O
the	O
last	O
classification	B-Method
layer	I-Method
and	O
modify	O
the	O
stride	O
of	O
the	O
last	O
two	O
convolution	B-Method
layers	I-Method
from	O
2	O
to	O
1	O
,	O
making	O
the	O
resolution	O
of	O
the	O
output	O
feature	O
maps	O
effectively	O
times	O
the	O
input	O
image	O
size	O
.	O
	
To	O
enlarge	O
the	O
receptive	O
field	O
,	O
we	O
apply	O
dilated	B-Method
convolution	I-Method
layers	I-Method
in	O
conv4	B-Method
and	I-Method
conv5	I-Method
layers	I-Method
with	O
a	O
stride	O
of	O
2	O
and	O
4	O
,	O
respectively	O
.	O
	
After	O
the	O
last	O
layer	O
,	O
we	O
use	O
the	O
Atrous	B-Method
Spatial	I-Method
Pyramid	I-Method
Pooling	I-Method
(	O
ASPP	B-Method
)	O
as	O
the	O
final	O
classifier	B-Method
.	O
	
Finally	O
,	O
we	O
apply	O
an	O
up	B-Method
-	I-Method
sampling	I-Method
layer	I-Method
along	O
with	O
the	O
softmax	O
output	O
to	O
match	O
the	O
size	O
of	O
the	O
input	O
image	O
.	O
	
Based	O
on	O
this	O
architecture	O
,	O
our	O
segmentation	B-Method
model	I-Method
achieves	O
65.1	O
%	O
mean	B-Metric
intersection	I-Metric
-	I-Metric
over	I-Metric
-	I-Metric
union	I-Metric
(	O
IoU	B-Metric
)	O
when	O
trained	O
on	O
the	O
Cityscapes	O
training	O
set	O
and	O
tested	O
on	O
the	O
Cityscapes	O
validation	O
set	O
.	O
	
Multi	B-Method
-	I-Method
level	I-Method
Adaptation	I-Method
Model	I-Method
.	O
	
We	O
construct	O
the	O
above	O
-	O
mentioned	O
discriminator	B-Method
and	I-Method
segmentation	I-Method
network	I-Method
as	O
our	O
single	B-Method
-	I-Method
level	I-Method
adaptation	I-Method
model	I-Method
.	O
	
For	O
the	O
multi	O
-	O
level	O
structure	O
,	O
we	O
extract	O
feature	O
maps	O
from	O
the	O
conv4	B-Method
layer	I-Method
and	O
add	O
an	O
ASPP	B-Method
module	I-Method
as	O
the	O
auxiliary	B-Method
classifier	I-Method
.	O
	
Similarly	O
,	O
a	O
discriminator	B-Method
with	O
the	O
same	O
architecture	O
is	O
added	O
for	O
adversarial	B-Task
learning	I-Task
.	O
	
Figure	O
[	O
reference	O
]	O
shows	O
the	O
proposed	O
multi	B-Method
-	I-Method
level	I-Method
adaptation	I-Method
model	I-Method
.	O
	
In	O
this	O
paper	O
,	O
we	O
use	O
two	O
levels	O
due	O
to	O
the	O
balance	O
of	O
its	O
efficiency	O
and	O
accuracy	B-Metric
.	O
	
Network	B-Method
Training	I-Method
.	O
	
To	O
train	O
the	O
proposed	O
single	B-Method
/	O
multi	B-Method
-	I-Method
level	I-Method
adaptation	I-Method
model	I-Method
,	O
we	O
find	O
that	O
jointly	O
training	O
the	O
segmentation	B-Method
network	I-Method
and	O
discriminators	B-Method
in	O
one	O
stage	O
is	O
effective	O
.	O
	
In	O
each	O
training	O
batch	O
,	O
we	O
first	O
forward	O
the	O
source	O
image	O
to	O
optimize	O
the	O
segmentation	B-Method
network	I-Method
for	O
in	O
(	O
[	O
reference	O
]	O
)	O
and	O
generate	O
the	O
output	O
.	O
	
For	O
the	O
target	O
image	O
,	O
we	O
obtain	O
the	O
segmentation	O
output	O
,	O
and	O
pass	O
it	O
along	O
with	O
to	O
the	O
discriminator	O
for	O
optimizing	O
in	O
(	O
[	O
reference	O
]	O
)	O
.	O
	
In	O
addition	O
,	O
we	O
compute	O
the	O
adversarial	O
loss	O
in	O
(	O
[	O
reference	O
]	O
)	O
for	O
the	O
target	B-Task
prediction	I-Task
.	O
	
For	O
the	O
multi	B-Task
-	I-Task
level	I-Task
training	I-Task
objective	I-Task
in	O
(	O
[	O
reference	O
]	O
)	O
,	O
we	O
simply	O
repeat	O
the	O
same	O
procedure	O
for	O
each	O
adaptation	B-Method
module	I-Method
.	O
	
We	O
implement	O
our	O
network	O
using	O
the	O
PyTorch	B-Method
toolbox	I-Method
on	O
a	O
single	B-Method
Titan	I-Method
X	I-Method
GPU	I-Method
with	O
12	O
GB	O
memory	O
.	O
	
To	O
train	O
the	O
segmentation	B-Method
network	I-Method
,	O
we	O
use	O
the	O
Stochastic	B-Method
Gradient	I-Method
Descent	I-Method
(	O
SGD	B-Method
)	O
optimizer	O
with	O
Nesterov	O
acceleration	O
where	O
the	O
momentum	O
is	O
0.9	O
and	O
the	O
weight	O
decay	O
is	O
.	O
	
The	O
initial	O
learning	B-Metric
rate	I-Metric
is	O
set	O
as	O
and	O
is	O
decreased	O
using	O
the	O
polynomial	O
decay	O
with	O
power	O
of	O
0.9	O
as	O
mentioned	O
in	O
.	O
	
For	O
training	O
the	O
discriminator	B-Method
,	O
we	O
use	O
the	O
Adam	B-Method
optimizer	I-Method
with	O
the	O
learning	B-Metric
rate	I-Metric
as	O
and	O
the	O
same	O
polynomial	O
decay	O
as	O
the	O
segmentation	B-Method
network	I-Method
.	O
	
The	O
momentum	O
is	O
set	O
as	O
0.9	O
and	O
0.99	O
.	O
	
section	O
:	O
Experimental	O
Results	O
	
In	O
this	O
section	O
,	O
we	O
present	O
experimental	O
results	O
to	O
validate	O
the	O
proposed	O
domain	B-Method
adaptation	I-Method
method	I-Method
for	O
semantic	B-Task
segmentation	I-Task
under	O
different	O
settings	O
.	O
	
First	O
,	O
we	O
show	O
evaluations	O
of	O
the	O
model	O
trained	O
on	O
synthetic	O
datasets	O
(	O
i.e.	O
,	O
GTA5	O
and	O
SYNTHIA	O
)	O
and	O
test	O
the	O
adapted	O
model	O
on	O
real	O
-	O
world	O
images	O
from	O
the	O
Cityscapes	O
dataset	O
.	O
	
Extensive	O
experiments	O
including	O
comparisons	O
to	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
methods	O
and	O
ablation	B-Method
study	I-Method
are	O
also	O
conducted	O
,	O
e.g.	O
,	O
adaptation	B-Task
in	O
the	O
feature	O
/	O
output	O
spaces	O
and	O
single	B-Method
/	O
multi	B-Method
-	I-Method
level	I-Method
adversarial	I-Method
learning	I-Method
.	O
	
Second	O
,	O
we	O
carry	O
out	O
experiments	O
on	O
the	O
Cross	O
-	O
City	O
dataset	O
,	O
where	O
the	O
model	O
is	O
trained	O
on	O
one	O
city	O
and	O
adapted	O
to	O
another	O
city	O
without	O
using	O
annotations	O
.	O
	
In	O
all	O
the	O
experiments	O
,	O
the	O
IoU	B-Metric
metric	O
is	O
used	O
.	O
	
The	O
code	O
and	O
model	O
are	O
available	O
at	O
.	O
	
subsection	O
:	O
GTA5	O
	
The	O
GTA5	O
dataset	O
consists	O
of	O
images	O
with	O
the	O
resolution	O
of	O
synthesized	O
from	O
the	O
video	O
game	O
based	O
on	O
the	O
city	O
of	O
Los	O
Angeles	O
.	O
	
The	O
ground	O
truth	O
annotations	O
are	O
compatible	O
with	O
the	O
Cityscapes	O
dataset	O
that	O
contains	O
19	O
categories	O
.	O
	
Following	O
,	O
we	O
use	O
the	O
full	O
set	O
of	O
GTA5	O
and	O
adapt	O
the	O
model	O
to	O
the	O
Cityscapes	O
training	O
set	O
with	O
2975	O
images	O
.	O
	
During	O
testing	O
,	O
we	O
evaluate	O
on	O
the	O
Cityscapes	O
validation	O
set	O
with	O
500	O
images	O
.	O
	
Overall	O
Results	O
.	O
	
We	O
present	O
adaptation	O
results	O
in	O
Table	O
[	O
reference	O
]	O
with	O
comparisons	O
to	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
domain	B-Method
adaptation	I-Method
methods	I-Method
.	O
	
For	O
these	O
approaches	O
,	O
the	O
baseline	B-Method
model	I-Method
is	O
trained	O
using	O
VGG	B-Method
-	I-Method
based	I-Method
architectures	I-Method
.	O
	
To	O
fairly	O
evaluate	O
our	O
method	O
,	O
we	O
first	O
use	O
the	O
same	O
baseline	O
architecture	O
(	O
VGG	B-Method
-	I-Method
16	I-Method
)	O
and	O
train	O
our	O
model	O
with	O
the	O
proposed	O
single	B-Method
-	I-Method
level	I-Method
adaptation	I-Method
module	I-Method
.	O
	
Table	O
[	O
reference	O
]	O
shows	O
that	O
our	O
method	O
performs	O
favorably	O
against	O
the	O
other	O
algorithms	O
.	O
	
While	O
these	O
methods	O
all	O
have	O
feature	B-Method
adaptation	I-Method
modules	I-Method
,	O
our	O
results	O
show	O
that	O
adapting	O
the	O
model	O
in	O
the	O
output	O
space	O
achieves	O
better	O
performance	O
.	O
	
We	O
note	O
that	O
CyCADA	B-Method
has	O
a	O
pixel	B-Method
adaptation	I-Method
module	I-Method
by	O
transforming	O
source	O
domain	O
images	O
to	O
the	O
target	O
domain	O
and	O
hence	O
obtains	O
additional	O
training	O
samples	O
.	O
	
Although	O
this	O
strategy	O
achieves	O
a	O
similar	O
performance	O
as	O
ours	O
,	O
one	O
can	O
always	O
apply	O
pixel	B-Method
transformation	I-Method
combined	O
with	O
our	O
output	B-Method
space	I-Method
adaptation	I-Method
to	O
improve	O
the	O
results	O
.	O
	
On	O
the	O
other	O
hand	O
,	O
we	O
argue	O
that	O
utilizing	O
a	O
stronger	O
baseline	B-Method
model	I-Method
is	O
critical	O
for	O
understanding	O
the	O
importance	O
of	O
different	O
adaptation	B-Method
components	I-Method
as	O
well	O
as	O
for	O
enhancing	O
the	O
performance	O
to	O
enable	O
real	B-Task
-	I-Task
world	I-Task
applications	I-Task
.	O
	
Thus	O
,	O
we	O
use	O
the	O
ResNet	B-Method
-	I-Method
101	I-Method
based	I-Method
network	I-Method
introduced	O
in	O
Section	O
[	O
reference	O
]	O
and	O
train	O
the	O
proposed	O
adaptation	B-Method
model	I-Method
.	O
	
Table	O
[	O
reference	O
]	O
shows	O
the	O
baseline	O
results	O
only	O
trained	O
on	O
source	O
images	O
without	O
adaptation	O
,	O
with	O
comparisons	O
to	O
our	O
adapted	O
models	O
under	O
different	O
settings	O
,	O
including	O
feature	B-Method
adaptation	I-Method
and	O
single	B-Method
/	O
multi	B-Method
-	I-Method
level	I-Method
adversarial	I-Method
learning	I-Method
in	O
the	O
output	O
space	O
.	O
	
Figure	O
[	O
reference	O
]	O
presents	O
some	O
example	O
results	O
for	O
adapted	B-Task
segmentation	I-Task
.	O
	
We	O
note	O
that	O
for	O
small	O
objects	O
such	O
as	O
poles	O
and	O
traffic	O
signs	O
,	O
they	O
are	O
harder	O
to	O
adapt	O
since	O
they	O
easily	O
get	O
merged	O
with	O
background	O
classes	O
.	O
	
In	O
addition	O
,	O
another	O
factor	O
to	O
evaluate	O
the	O
adaptation	B-Task
performance	O
is	O
to	O
measure	O
how	O
much	O
gap	O
is	O
narrowed	O
between	O
the	O
adaptation	B-Method
model	I-Method
and	O
the	O
fully	B-Method
-	I-Method
supervised	I-Method
model	I-Method
.	O
	
Hence	O
,	O
we	O
train	O
the	O
model	O
using	O
annotated	O
ground	O
truths	O
in	O
the	O
Cityscapes	O
dataset	O
as	O
the	O
oracle	O
results	O
.	O
	
Table	O
[	O
reference	O
]	O
shows	O
the	O
gap	O
under	O
different	O
baseline	O
models	O
.	O
	
We	O
observe	O
that	O
,	O
although	O
the	O
oracle	O
result	O
does	O
not	O
differ	O
a	O
lot	O
between	O
VGG	B-Method
-	I-Method
16	I-Method
and	O
ResNet	B-Method
-	I-Method
101	I-Method
based	I-Method
models	I-Method
,	O
the	O
gap	O
is	O
larger	O
for	O
the	O
VGG	B-Method
one	I-Method
.	O
	
It	O
suggests	O
us	O
that	O
to	O
narrow	O
the	O
gap	O
,	O
using	O
a	O
deeper	B-Method
model	I-Method
with	O
larger	O
capacity	O
is	O
more	O
practical	O
.	O
	
Parameter	B-Method
Analysis	I-Method
.	O
	
During	O
optimizing	O
the	O
segmentation	B-Method
network	I-Method
,	O
it	O
is	O
essential	O
to	O
balance	O
the	O
weight	O
between	O
segmentation	O
and	O
adversarial	O
losses	O
.	O
	
We	O
first	O
consider	O
the	O
single	B-Method
-	O
level	O
case	O
in	O
(	O
[	O
reference	O
]	O
)	O
and	O
conduct	O
experiments	O
to	O
observe	O
the	O
impact	O
of	O
changing	O
.	O
	
Table	O
[	O
reference	O
]	O
shows	O
that	O
a	O
smaller	O
may	O
not	O
facilitate	O
the	O
training	B-Task
process	I-Task
significantly	O
,	O
while	O
a	O
larger	O
may	O
propagate	O
incorrect	O
gradients	O
to	O
the	O
network	O
.	O
	
We	O
empirically	O
choose	O
as	O
0.001	O
in	O
the	O
single	B-Method
-	O
level	O
setting	O
.	O
	
Feature	B-Method
Level	I-Method
v.s	O
.	O
	
Output	B-Method
Space	I-Method
Adaptation	I-Method
.	O
	
In	O
the	O
single	B-Method
-	O
level	O
setting	O
in	O
(	O
[	O
reference	O
]	O
)	O
,	O
we	O
compare	O
results	O
by	O
using	O
feature	B-Method
-	I-Method
level	I-Method
or	O
output	B-Method
space	I-Method
adaptation	I-Method
via	O
adversarial	B-Method
learning	I-Method
.	O
	
For	O
feature	B-Method
-	I-Method
level	I-Method
adaptation	O
,	O
we	O
adopt	O
a	O
similar	O
strategy	O
as	O
used	O
in	O
and	O
train	O
our	O
model	O
accordingly	O
.	O
	
Table	O
[	O
reference	O
]	O
shows	O
that	O
the	O
proposed	O
adaptation	B-Method
method	I-Method
in	O
the	O
output	O
space	O
performs	O
better	O
than	O
the	O
one	O
in	O
the	O
feature	O
level	O
.	O
	
In	O
addition	O
,	O
Table	O
[	O
reference	O
]	O
shows	O
that	O
adaptation	O
in	O
the	O
feature	O
space	O
is	O
more	O
sensitive	O
to	O
,	O
which	O
causes	O
the	O
training	B-Task
process	I-Task
more	O
difficult	O
,	O
while	O
output	B-Method
space	I-Method
adaptation	I-Method
allows	O
for	O
a	O
wider	O
range	O
of	O
.	O
	
One	O
reason	O
is	O
that	O
as	O
feature	B-Method
adaptation	I-Method
is	O
performed	O
in	O
the	O
high	O
-	O
dimensional	O
space	O
,	O
the	O
problem	O
for	O
the	O
discriminator	B-Method
becomes	O
easier	O
.	O
	
Thus	O
,	O
such	O
an	O
adapted	B-Method
model	I-Method
can	O
not	O
effectively	O
match	O
distributions	O
between	O
source	O
and	O
target	O
domains	O
via	O
adversarial	B-Method
learning	I-Method
.	O
	
Single	O
-	O
level	O
v.s	O
.	O
	
Multi	B-Method
-	I-Method
level	I-Method
Adversarial	I-Method
Learning	I-Method
.	O
	
We	O
have	O
shown	O
the	O
merits	O
of	O
adopting	O
adversarial	B-Method
learning	I-Method
in	O
the	O
output	O
space	O
.	O
	
In	O
addition	O
,	O
we	O
present	O
the	O
results	O
of	O
using	O
multi	B-Method
-	I-Method
level	I-Method
adversarial	I-Method
learning	I-Method
in	O
Table	O
[	O
reference	O
]	O
.	O
	
Here	O
,	O
we	O
utilize	O
an	O
additional	O
adversarial	B-Method
module	I-Method
(	O
see	O
Figure	O
[	O
reference	O
]	O
)	O
and	O
jointly	O
optimize	O
(	O
[	O
reference	O
]	O
)	O
for	O
two	O
levels	O
.	O
	
To	O
properly	O
balance	O
and	O
,	O
we	O
use	O
the	O
same	O
weight	O
as	O
in	O
the	O
single	B-Method
-	O
level	O
setting	O
for	O
the	O
high	O
-	O
level	O
output	O
space	O
(	O
i.e.	O
,	O
=	O
1	O
and	O
=	O
0.001	O
)	O
.	O
	
Since	O
the	O
low	O
-	O
level	O
output	O
carries	O
less	O
information	O
to	O
predict	O
the	O
segmentation	B-Task
,	O
we	O
use	O
smaller	O
weights	O
for	O
both	O
the	O
segmentation	B-Task
and	O
adversarial	B-Metric
loss	I-Metric
(	O
i.e.	O
,	O
=	O
0.1	O
and	O
=	O
0.0002	O
)	O
.	O
	
Evaluation	O
results	O
show	O
that	O
our	O
multi	B-Method
-	I-Method
level	I-Method
adversarial	I-Method
adaptation	I-Method
further	O
improves	O
the	O
segmentation	B-Metric
accuracy	I-Metric
.	O
	
More	O
results	O
and	O
analysis	O
are	O
presented	O
in	O
the	O
supplementary	O
material	O
.	O
	
road	O
sidewalk	O
building	O
light	O
sign	O
veg	O
sky	O
person	O
rider	O
car	O
bus	O
mbike	O
bike	O
	
subsection	O
:	O
SYNTHIA	O
	
To	O
adapt	O
from	O
the	O
SYNTHIA	O
to	O
Cityscapes	O
datasets	O
,	O
we	O
use	O
the	O
SYNTHIA	O
-	O
RAND	O
-	O
CITYSCAPES	O
set	O
as	O
the	O
source	O
domain	O
which	O
contains	O
9400	O
images	O
compatible	O
with	O
the	O
cityscapes	O
annotated	O
classes	O
.	O
	
Similar	O
to	O
,	O
we	O
evaluate	O
images	O
on	O
the	O
Cityscapes	O
validation	O
set	O
with	O
13	O
classes	O
.	O
	
For	O
the	O
weight	O
in	O
(	O
[	O
reference	O
]	O
)	O
and	O
(	O
[	O
reference	O
]	O
)	O
,	O
we	O
use	O
the	O
same	O
ones	O
as	O
in	O
the	O
case	O
of	O
GTA5	O
dataset	O
.	O
	
Table	O
[	O
reference	O
]	O
shows	O
evaluation	O
results	O
of	O
the	O
proposed	O
algorithm	O
against	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
methods	O
that	O
use	O
feature	B-Method
adaptation	I-Method
.	O
	
Similar	O
to	O
the	O
experiments	O
with	O
the	O
GTA5	O
dataset	O
,	O
we	O
first	O
utilize	O
the	O
same	O
VGG	B-Method
-	I-Method
based	I-Method
model	I-Method
and	O
train	O
our	O
single	B-Method
-	I-Method
level	I-Method
adaptation	I-Method
model	I-Method
for	O
fair	O
comparisons	O
.	O
	
The	O
experimental	O
results	O
suggest	O
that	O
adapting	O
the	O
model	O
in	O
the	O
output	O
space	O
performs	O
better	O
.	O
	
Second	O
,	O
we	O
compare	O
results	O
using	O
different	O
components	O
of	O
the	O
proposed	O
method	O
with	O
the	O
ResNet	B-Method
based	I-Method
model	I-Method
.	O
	
We	O
show	O
that	O
the	O
multi	B-Method
-	I-Method
level	I-Method
adaptation	I-Method
module	I-Method
improves	O
the	O
results	O
over	O
the	O
baseline	O
,	O
feature	B-Method
space	I-Method
adaptation	I-Method
and	O
single	B-Method
-	O
level	O
adaptation	O
models	O
.	O
	
In	O
addition	O
,	O
we	O
present	O
comparisons	O
of	O
mean	O
IoU	B-Metric
gap	O
between	O
adapted	O
and	O
oracle	O
results	O
in	O
Table	O
[	O
reference	O
]	O
.	O
	
Our	O
method	O
achieves	O
the	O
smallest	O
gap	O
and	O
is	O
the	O
only	O
one	O
that	O
can	O
minimize	O
the	O
gap	O
below	O
30	O
%	O
.	O
	
road	O
sidewalk	O
building	O
light	O
sign	O
veg	O
sky	O
person	O
rider	O
car	O
bus	O
mbike	O
bike	O
	
subsection	O
:	O
Cross	O
-	O
City	O
Dataset	O
	
In	O
addition	O
to	O
the	O
synthetic	B-Task
-	I-Task
to	I-Task
-	I-Task
real	I-Task
adaptation	I-Task
for	O
a	O
larger	O
domain	O
gap	O
,	O
we	O
conduct	O
experiment	O
on	O
the	O
Cross	O
-	O
City	O
dataset	O
with	O
smaller	O
domain	O
gaps	O
between	O
cities	O
.	O
	
The	O
dataset	O
contains	O
four	O
different	O
cities	O
:	O
Rio	O
,	O
Rome	O
,	O
Tokyo	O
and	O
Taipei	O
,	O
in	O
which	O
each	O
city	O
has	O
3200	O
images	O
without	O
annotations	O
and	O
100	O
images	O
with	O
pixel	O
-	O
level	O
ground	O
truths	O
for	O
13	O
classes	O
.	O
	
Similar	O
to	O
,	O
we	O
use	O
the	O
Cityscapes	O
training	O
set	O
as	O
the	O
source	O
domain	O
and	O
adapt	O
it	O
to	O
each	O
target	O
city	O
using	O
3200	O
images	O
,	O
while	O
100	O
annotated	O
images	O
are	O
used	O
for	O
evaluation	O
.	O
	
Since	O
a	O
smaller	O
domain	O
gap	O
results	O
in	O
smaller	O
output	O
differences	O
,	O
we	O
use	O
smaller	O
weights	O
for	O
the	O
adversarial	O
loss	O
(	O
i.e.	O
,	O
)	O
when	O
training	O
our	O
models	O
,	O
while	O
the	O
weights	O
for	O
segmentation	B-Task
remain	O
the	O
same	O
as	O
previous	O
experiments	O
.	O
	
We	O
show	O
our	O
results	O
in	O
Table	O
[	O
reference	O
]	O
with	O
comparisons	O
to	O
and	O
our	O
baseline	O
models	O
under	O
different	O
settings	O
.	O
	
Again	O
,	O
our	O
final	O
multi	B-Method
-	I-Method
level	I-Method
model	I-Method
achieves	O
consistent	O
improvement	O
for	O
different	O
cities	O
,	O
which	O
demonstrates	O
the	O
advantages	O
of	O
the	O
proposed	O
adaptation	B-Method
method	I-Method
in	O
the	O
output	O
space	O
.	O
	
Note	O
that	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
method	O
uses	O
a	O
different	O
baseline	O
model	O
,	O
and	O
we	O
present	O
it	O
as	O
a	O
reference	O
to	O
analyze	O
how	O
much	O
the	O
proposed	O
algorithm	O
can	O
improve	O
.	O
	
section	O
:	O
Concluding	O
Remarks	O
	
In	O
this	O
paper	O
,	O
we	O
exploit	O
the	O
fact	O
that	O
segmentations	O
are	O
structured	O
outputs	O
and	O
share	O
many	O
similarities	O
between	O
source	O
and	O
target	O
domains	O
.	O
	
We	O
tackle	O
the	O
domain	B-Method
adaptation	I-Method
problem	O
for	O
semantic	B-Task
segmentation	I-Task
via	O
adversarial	B-Method
learning	I-Method
in	O
the	O
output	O
space	O
.	O
	
To	O
further	O
enhance	O
the	O
adapted	O
model	O
,	O
we	O
construct	O
a	O
multi	B-Method
-	I-Method
level	I-Method
adversarial	I-Method
network	I-Method
to	O
effectively	O
perform	O
output	O
space	O
domain	B-Method
adaptation	I-Method
at	O
different	O
feature	O
levels	O
.	O
	
Experimental	O
results	O
show	O
that	O
the	O
proposed	O
method	O
performs	O
favorably	O
against	O
numerous	O
baseline	O
models	O
and	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
algorithms	O
.	O
	
We	O
hope	O
that	O
our	O
proposed	O
method	O
can	O
be	O
a	O
generic	O
adaptation	B-Method
model	I-Method
for	O
a	O
wide	O
range	O
of	O
pixel	B-Task
-	I-Task
level	I-Task
prediction	I-Task
tasks	I-Task
.	O
	
Acknowledgments	O
.	O
	
W.	O
-	O
C.	O
Hung	O
is	O
supported	O
in	O
part	O
by	O
the	O
NSF	O
CAREER	O
Grant	O
#	O
1149783	O
,	O
gifts	O
from	O
Adobe	O
and	O
NVIDIA	O
.	O
	
bibliography	O
:	O
References	O
	
document	O
:	O
Pose	B-Method
-	I-Method
driven	I-Method
Deep	I-Method
Convolutional	I-Method
Model	O
for	O
Person	B-Task
Re	I-Task
-	I-Task
identification	I-Task
	
Feature	B-Task
extraction	I-Task
and	O
matching	B-Task
are	O
two	O
crucial	O
components	O
in	O
person	B-Task
Re	I-Task
-	I-Task
Identification	I-Task
(	O
ReID	B-Task
)	O
.	O
	
The	O
large	O
pose	O
deformations	O
and	O
the	O
complex	O
view	O
variations	O
exhibited	O
by	O
the	O
captured	O
person	O
images	O
significantly	O
increase	O
the	O
difficulty	O
of	O
learning	B-Task
and	I-Task
matching	I-Task
of	I-Task
the	I-Task
features	I-Task
from	O
person	O
images	O
.	O
	
To	O
overcome	O
these	O
difficulties	O
,	O
in	O
this	O
work	O
we	O
propose	O
a	O
Pose	B-Method
-	I-Method
driven	I-Method
Deep	I-Method
Convolutional	I-Method
(	O
PDC	B-Method
)	O
model	O
to	O
learn	O
improved	O
feature	B-Method
extraction	I-Method
and	O
matching	B-Method
models	I-Method
from	O
end	O
to	O
end	O
.	O
	
Our	O
deep	B-Method
architecture	I-Method
explicitly	O
leverages	O
the	O
human	O
part	O
cues	O
to	O
alleviate	O
the	O
pose	O
variations	O
and	O
learn	O
robust	B-Method
feature	I-Method
representations	I-Method
from	O
both	O
the	O
global	O
image	O
and	O
different	O
local	O
parts	O
.	O
	
To	O
match	O
the	O
features	O
from	O
global	O
human	O
body	O
and	O
local	O
body	O
parts	O
,	O
a	O
pose	B-Method
driven	I-Method
feature	I-Method
weighting	I-Method
sub	I-Method
-	I-Method
network	I-Method
is	O
further	O
designed	O
to	O
learn	O
adaptive	B-Method
feature	I-Method
fusions	I-Method
.	O
	
Extensive	O
experimental	O
analyses	O
and	O
results	O
on	O
three	O
popular	O
datasets	O
demonstrate	O
significant	O
performance	O
improvements	O
of	O
our	O
model	O
over	O
all	O
published	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
methods	O
.	O
	
section	O
:	O
Introduction	O
	
Person	B-Task
Re	I-Task
-	I-Task
Identification	I-Task
(	O
ReID	B-Task
)	O
is	O
an	O
important	O
component	O
in	O
a	O
video	B-Task
surveillance	I-Task
system	I-Task
.	O
	
Here	O
person	O
ReID	B-Task
refers	O
to	O
the	O
process	O
of	O
identifying	O
a	O
probe	B-Task
person	I-Task
from	O
a	O
gallery	O
captured	O
by	O
different	O
cameras	O
,	O
and	O
is	O
generally	O
deployed	O
in	O
the	O
following	O
scenario	O
:	O
given	O
a	O
probe	O
image	O
or	O
video	O
sequence	O
containing	O
a	O
specific	O
person	O
under	O
a	O
certain	O
camera	O
,	O
querying	O
the	O
images	O
,	O
locations	O
,	O
and	O
time	O
stamps	O
of	O
this	O
person	O
from	O
other	O
cameras	O
.	O
	
Despite	O
decades	O
of	O
studies	O
,	O
the	O
person	O
ReID	B-Task
problem	O
is	O
still	O
far	O
from	O
being	O
solved	O
.	O
	
This	O
is	O
mainly	O
because	O
of	O
challenging	O
situations	O
like	O
complex	O
view	O
variations	O
and	O
large	O
pose	O
deformations	O
on	O
the	O
captured	O
person	O
images	O
.	O
	
Most	O
of	O
traditional	O
works	O
try	O
to	O
address	O
these	O
challenges	O
with	O
the	O
following	O
two	O
approaches	O
:	O
(	O
1	O
)	O
representing	O
the	O
visual	O
appearance	O
of	O
a	O
person	O
using	O
customized	O
local	O
invariant	O
features	O
extracted	O
from	O
images	O
or	O
(	O
2	O
)	O
learning	O
a	O
discriminative	B-Method
distance	I-Method
metric	I-Method
to	O
reduce	O
the	O
distance	O
among	O
features	O
of	O
images	O
containing	O
the	O
same	O
person	O
.	O
	
Because	O
the	O
human	O
poses	O
and	O
viewpoints	O
are	O
uncontrollable	O
in	O
real	O
scenarios	O
,	O
hand	O
-	O
coded	O
features	O
may	O
be	O
not	O
robust	O
enough	O
to	O
pose	O
and	O
viewpoint	O
variations	O
.	O
	
Distance	B-Metric
metric	I-Metric
is	O
computed	O
for	O
each	O
pair	O
of	O
cameras	O
,	O
making	O
distance	B-Method
metric	I-Method
learning	I-Method
based	O
person	O
ReID	B-Task
suffers	O
from	O
the	O
computational	B-Metric
complexity	I-Metric
.	O
	
In	O
recent	O
years	O
,	O
deep	B-Method
learning	I-Method
has	O
demonstrated	O
strong	O
model	O
capabilities	O
and	O
obtains	O
very	O
promising	O
performances	O
in	O
many	O
computer	B-Task
vision	I-Task
tasks	I-Task
.	O
	
Meanwhile	O
,	O
the	O
release	O
of	O
person	O
ReID	B-Task
datasets	O
like	O
CUHK	B-Material
03	I-Material
,	O
Market	B-Material
-	I-Material
1501	I-Material
,	O
and	O
MARS	B-Material
,	O
both	O
of	O
which	O
contain	O
many	O
annotated	O
person	O
images	O
,	O
makes	O
training	O
deep	B-Method
models	I-Method
for	O
person	O
ReID	B-Task
feasible	O
.	O
	
Therefore	O
,	O
many	O
researchers	O
attempt	O
to	O
leverage	O
deep	B-Method
models	I-Method
in	O
person	O
ReID	B-Task
.	O
	
Most	O
of	O
these	O
methods	O
first	O
learn	O
a	O
pedestrian	O
feature	O
and	O
then	O
compute	O
Euclidean	O
distance	O
to	O
measure	O
the	O
similarity	O
between	O
two	O
samples	O
.	O
	
More	O
specifically	O
,	O
existing	O
deep	O
learning	O
based	O
person	O
ReID	B-Task
approaches	O
can	O
be	O
summarized	O
into	O
two	O
categories	O
:	O
1	O
)	O
use	O
Softmax	O
Loss	O
with	O
person	O
ID	O
labels	O
to	O
learn	O
a	O
global	B-Method
representation	I-Method
,	O
and	O
2	O
)	O
first	O
learn	O
local	B-Method
representations	I-Method
using	O
predefined	O
rigid	O
body	O
parts	O
,	O
then	O
fuse	O
the	O
local	B-Method
and	I-Method
global	I-Method
representations	I-Method
to	O
depict	O
person	O
images	O
.	O
	
Deep	B-Method
learning	I-Method
based	I-Method
methods	I-Method
have	O
demonstrated	O
significant	O
performance	O
improvements	O
over	O
the	O
traditional	O
methods	O
.	O
	
Although	O
these	O
approaches	O
have	O
achieved	O
remarkable	O
results	O
on	O
mainstream	O
person	O
ReID	B-Task
datasets	O
,	O
most	O
of	O
them	O
do	O
not	O
consider	O
pose	O
variation	O
of	O
human	O
body	O
.	O
	
Because	O
pose	O
variations	O
may	O
significantly	O
change	O
the	O
appearance	O
of	O
a	O
person	O
,	O
considering	O
the	O
human	O
pose	O
cues	O
is	O
potential	O
to	O
help	O
person	B-Task
re	I-Task
-	I-Task
identification	I-Task
.	O
	
Although	O
there	O
are	O
several	O
methods	O
that	O
segment	O
the	O
person	O
images	O
according	O
to	O
the	O
predefined	O
configuration	O
,	O
such	O
simple	O
segmentation	O
can	O
not	O
capture	O
the	O
pose	O
cues	O
effectively	O
.	O
	
Some	O
recent	O
works	O
attempt	O
to	O
use	O
pose	B-Method
estimation	I-Method
algorithms	I-Method
to	O
predict	O
human	O
pose	O
and	O
then	O
train	O
deep	B-Method
models	I-Method
for	O
person	O
ReID	B-Task
.	O
	
However	O
,	O
they	O
use	O
manually	O
cropped	O
human	O
body	O
parts	O
and	O
their	O
models	O
are	O
not	O
trained	O
from	O
end	O
to	O
end	O
.	O
	
Therefore	O
,	O
the	O
potential	O
of	O
pose	O
information	O
to	O
boost	O
the	O
ReID	B-Task
performance	O
has	O
not	O
been	O
fully	O
explored	O
.	O
	
To	O
better	O
alleviate	O
the	O
challenges	O
from	O
pose	O
variations	O
,	O
we	O
propose	O
a	O
Pose	B-Method
-	I-Method
driven	I-Method
Deep	I-Method
Convolutional	I-Method
(	O
PDC	B-Method
)	O
model	O
for	O
person	O
ReID	B-Task
.	O
	
The	O
proposed	O
PDC	B-Method
model	O
learns	O
the	O
global	B-Method
representation	I-Method
depicting	O
the	O
whole	O
body	O
and	O
local	B-Method
representations	I-Method
depicting	O
body	O
parts	O
simultaneously	O
.	O
	
The	O
global	B-Method
representation	I-Method
is	O
learned	O
using	O
the	O
Softmax	O
Loss	O
with	O
person	O
ID	O
labels	O
on	O
the	O
whole	O
input	O
image	O
.	O
	
For	O
the	O
learning	B-Task
of	I-Task
local	I-Task
representations	I-Task
,	O
a	O
novel	O
Feature	B-Method
Embedding	I-Method
sub	I-Method
-	I-Method
Net	I-Method
(	O
FEN	B-Method
)	O
is	O
proposed	O
to	O
learn	O
and	O
readjust	O
human	O
parts	O
so	O
that	O
parts	O
are	O
affine	O
transformed	O
and	O
re	O
-	O
located	O
at	O
more	O
reasonable	O
regions	O
which	O
can	O
be	O
easily	O
recognizable	O
through	O
two	O
different	O
cameras	O
.	O
	
In	O
Feature	B-Method
Embedding	I-Method
sub	I-Method
-	I-Method
Net	I-Method
,	O
each	O
body	O
part	O
region	O
is	O
first	O
automatically	O
cropped	O
.	O
	
The	O
cropped	O
part	O
regions	O
are	O
hence	O
transformed	O
by	O
a	O
Pose	B-Method
Transformation	I-Method
Network	I-Method
(	O
PTN	B-Method
)	I-Method
to	O
eliminate	O
the	O
pose	O
variations	O
.	O
	
The	O
local	B-Method
representations	I-Method
are	O
hence	O
learned	O
on	O
the	O
transformed	O
regions	O
.	O
	
We	O
further	O
propose	O
a	O
Feature	B-Method
Weighting	I-Method
sub	I-Method
-	I-Method
Net	I-Method
(	O
FWN	B-Method
)	O
to	O
learn	O
the	O
weights	O
of	O
global	O
representations	O
and	O
local	B-Method
representations	I-Method
on	O
different	O
parts	O
.	O
	
Therefore	O
,	O
more	O
reasonable	O
feature	B-Method
fusion	I-Method
is	O
conducted	O
to	O
facilitate	O
feature	B-Task
similarity	I-Task
measurement	I-Task
.	O
	
Some	O
more	O
detailed	O
descriptions	O
to	O
our	O
local	B-Method
representation	I-Method
generation	I-Method
are	O
illustrated	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
.	O
	
Our	O
method	O
first	O
locates	O
the	O
key	O
body	O
joints	O
from	O
the	O
input	O
image	O
,	O
,	O
illustrated	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
(	O
c	O
)	O
.	O
	
From	O
the	O
detected	O
joints	O
,	O
six	O
body	O
parts	O
are	O
extracted	O
,	O
,	O
shown	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
(	O
d	O
)	O
.	O
	
As	O
shown	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
(	O
e	O
)	O
,	O
those	O
parts	O
are	O
extracted	O
and	O
normalized	O
into	O
fixed	O
sizes	O
and	O
orientations	O
.	O
	
Finally	O
,	O
they	O
are	O
fed	O
into	O
the	O
Pose	B-Method
Transformation	I-Method
Network	I-Method
(	O
PTN	B-Method
)	I-Method
to	O
further	O
eliminate	O
the	O
pose	O
variations	O
.	O
	
With	O
the	O
normalized	O
and	O
transformed	O
part	O
regions	O
,	O
,	O
Fig	O
.	O
	
[	O
reference	O
]	O
(	O
f	O
)	O
,	O
local	O
representations	O
are	O
learned	O
by	O
training	O
the	O
deep	B-Method
neural	I-Method
network	I-Method
.	O
	
Different	O
parts	O
commonly	O
convey	O
different	O
levels	O
of	O
discriminative	O
cues	O
to	O
identify	O
the	O
person	O
.	O
	
We	O
thus	O
further	O
learn	O
weights	O
for	O
representations	O
on	O
different	O
parts	O
with	O
a	O
sub	B-Method
-	I-Method
network	I-Method
.	O
	
Most	O
of	O
current	O
deep	B-Method
learning	I-Method
based	O
person	B-Task
ReID	I-Task
works	I-Task
do	O
not	O
consider	O
the	O
human	O
pose	O
cues	O
and	O
the	O
weights	O
of	O
representation	O
on	O
different	O
parts	O
.	O
	
This	O
paper	O
proposes	O
a	O
novel	O
deep	B-Method
architecture	I-Method
that	O
transforms	O
body	O
parts	O
into	O
normalized	O
and	O
homologous	O
feature	O
representations	O
to	O
better	O
overcome	O
the	O
pose	O
variations	O
.	O
	
Moreover	O
,	O
a	O
sub	B-Method
-	I-Method
network	I-Method
is	O
proposed	O
to	O
automatically	O
learn	O
weights	O
for	O
different	O
parts	O
to	O
facilitate	O
feature	B-Task
similarity	I-Task
measurement	I-Task
.	O
	
Both	O
the	O
representation	O
and	O
weighting	B-Task
are	O
learned	O
jointly	O
from	O
end	O
to	O
end	O
.	O
	
Since	O
pose	B-Task
estimation	I-Task
is	O
not	O
the	O
focus	O
of	O
this	O
paper	O
,	O
the	O
used	O
pose	B-Method
estimation	I-Method
algorithm	I-Method
,	O
,	O
Fully	B-Method
Convolutional	I-Method
Networks	I-Method
(	O
FCN	B-Method
)	O
based	B-Method
pose	I-Method
estimation	I-Method
method	I-Method
is	O
simple	O
and	O
trained	O
independently	O
.	O
	
Once	O
the	O
FCN	B-Method
is	O
trained	O
,	O
it	O
is	O
incorporated	O
in	O
our	O
framework	O
,	O
which	O
is	O
hence	O
trained	O
in	O
an	O
end	O
-	O
to	O
-	O
end	O
manner	O
,	O
,	O
using	O
images	O
as	O
inputs	O
and	O
person	O
ID	O
labels	O
as	O
outputs	O
.	O
	
Experimental	O
results	O
on	O
three	O
popular	O
datasets	O
show	O
that	O
our	O
algorithm	O
significantly	O
outperforms	O
many	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
ones	O
.	O
	
section	O
:	O
Related	O
Work	O
	
Traditional	O
algorithms	O
perform	O
person	B-Task
re	I-Task
-	I-Task
identification	I-Task
through	O
two	O
ways	O
:	O
(	O
a	O
)	O
acquiring	O
robust	O
local	O
features	O
visually	O
representing	O
a	O
person	O
’s	O
appearance	O
and	O
then	O
encoding	O
them	O
;	O
(	O
b	O
)	O
closing	O
the	O
gap	O
between	O
a	O
person	O
’s	O
different	O
features	O
by	O
learning	O
a	O
discriminative	B-Method
distance	I-Method
metric	I-Method
.	O
	
Some	O
recent	O
works	O
have	O
started	O
to	O
apply	O
deep	B-Method
learning	I-Method
in	O
person	O
ReID	B-Task
and	O
achieved	O
promising	O
performance	O
.	O
	
In	O
the	O
following	O
,	O
we	O
briefly	O
review	O
recent	O
deep	O
learning	O
based	O
person	O
ReID	B-Task
methods	O
.	O
	
Deep	B-Method
learning	I-Method
is	O
commonly	O
used	O
to	O
either	O
learn	O
a	O
person	B-Method
’s	I-Method
representation	I-Method
or	O
the	O
distance	B-Metric
metric	I-Metric
.	O
	
When	O
handling	O
a	O
pair	O
of	O
person	O
images	O
,	O
existing	O
deep	B-Method
learning	I-Method
methods	I-Method
usually	O
learn	O
feature	B-Method
representations	I-Method
of	O
each	O
person	O
by	O
using	O
a	O
deep	B-Method
matching	I-Method
function	I-Method
from	O
convolutional	O
features	O
or	O
from	O
the	O
Fully	B-Method
Connected	I-Method
(	O
FC	B-Method
)	O
features	O
.	O
	
Apart	O
from	O
deep	B-Method
metric	I-Method
learning	I-Method
methods	I-Method
,	O
some	O
algorithms	O
first	O
learn	O
image	O
representations	O
directly	O
with	O
the	O
Triplet	O
Loss	O
or	O
the	O
Siamese	O
Contrastive	O
Loss	O
,	O
then	O
utilize	O
Euclidean	O
distance	O
for	O
comparison	O
.	O
	
Wang	O
use	O
a	O
joint	B-Method
learning	I-Method
framework	I-Method
to	O
unify	O
single	B-Task
-	I-Task
image	I-Task
representation	I-Task
and	O
cross	B-Task
-	I-Task
image	I-Task
representation	I-Task
using	O
a	O
doublet	B-Method
or	I-Method
triplet	I-Method
CNN	I-Method
.	O
	
Shi	O
propose	O
a	O
moderate	B-Method
positive	I-Method
mining	I-Method
method	I-Method
to	O
use	O
deep	B-Method
distance	I-Method
metric	I-Method
learning	I-Method
for	O
person	O
ReID	B-Task
.	O
	
Another	O
novel	O
method	O
learns	O
deep	O
attributes	O
feature	O
for	O
ReID	B-Task
with	O
semi	B-Method
-	I-Method
supervised	I-Method
learning	I-Method
.	O
	
Xiao	O
train	O
one	O
network	O
with	O
several	O
person	O
ReID	B-Task
datasets	O
using	O
a	O
Domain	B-Method
Guided	I-Method
Dropout	I-Method
algorithm	I-Method
.	O
	
Predefined	O
rigid	O
body	O
parts	O
are	O
also	O
used	O
by	O
many	O
deep	B-Method
learning	I-Method
based	I-Method
methods	I-Method
for	O
the	O
purpose	O
of	O
learning	B-Task
local	I-Task
pedestrian	I-Task
features	I-Task
.	O
	
Different	O
from	O
these	O
algorithms	O
,	O
our	O
work	O
and	O
the	O
ones	O
in	O
use	O
more	O
accurate	O
human	B-Method
pose	I-Method
estimation	I-Method
algorithms	I-Method
to	O
acquire	O
human	O
pose	O
features	O
.	O
	
However	O
,	O
due	O
to	O
the	O
limited	O
accuracy	B-Metric
of	O
pose	B-Method
estimation	I-Method
algorithms	I-Method
as	O
well	O
as	O
reasons	O
like	O
occlusion	O
and	O
lighting	O
change	O
,	O
pose	B-Task
estimation	I-Task
might	O
be	O
not	O
accurate	O
enough	O
.	O
	
Moreover	O
,	O
different	O
parts	O
convey	O
different	O
levels	O
of	O
discriminative	O
cues	O
.	O
	
Therefore	O
,	O
we	O
normalize	O
the	O
part	O
regions	O
to	O
get	O
more	O
robust	O
feature	B-Method
representation	I-Method
using	O
Feature	B-Method
Embedding	I-Method
sub	I-Method
-	I-Method
Net	I-Method
(	O
FEN	B-Method
)	O
and	O
propose	O
a	O
Feature	B-Method
Weighting	I-Method
sub	I-Method
-	I-Method
Net	I-Method
(	O
FWN	B-Method
)	O
to	O
learn	O
the	O
weight	O
for	O
each	O
part	O
feature	O
.	O
	
In	O
this	O
way	O
,	O
the	O
part	O
with	O
high	O
discriminative	O
power	O
can	O
be	O
identified	O
and	O
emphasized	O
.	O
	
This	O
also	O
makes	O
our	O
work	O
different	O
from	O
existing	O
ones	O
,	O
which	O
do	O
not	O
consider	O
the	O
inaccuracy	O
of	O
human	B-Task
poses	I-Task
estimation	I-Task
and	O
weighting	O
on	O
different	O
parts	O
features	O
.	O
	
section	O
:	O
Pose	O
-	O
driven	O
Deep	O
ReID	B-Task
Model	O
	
In	O
this	O
section	O
,	O
we	O
describe	O
the	O
overall	O
framework	O
of	O
the	O
proposed	O
approach	O
,	O
where	O
we	O
mainly	O
introduce	O
the	O
Feature	B-Method
Embedding	I-Method
sub	I-Method
-	I-Method
Net	I-Method
(	O
FEN	B-Method
)	O
and	O
the	O
Feature	B-Method
Weighting	I-Method
sub	I-Method
-	I-Method
Net	I-Method
(	O
FWN	B-Method
)	O
.	O
	
Details	O
about	O
the	O
training	O
and	O
test	O
procedures	O
of	O
the	O
proposed	O
approach	O
will	O
also	O
be	O
presented	O
.	O
	
subsection	O
:	O
Framework	O
	
Fig	O
.	O
	
[	O
reference	O
]	O
shows	O
the	O
framework	O
of	O
our	O
proposed	O
deep	O
ReID	B-Task
model	O
.	O
	
It	O
can	O
be	O
seen	O
that	O
the	O
global	O
image	O
and	O
part	O
images	O
are	O
simultaneously	O
considered	O
during	O
each	O
round	O
of	O
training	B-Task
.	O
	
Given	O
a	O
training	O
sample	O
,	O
we	O
use	O
an	O
human	B-Method
pose	I-Method
estimation	I-Method
algorithm	I-Method
to	O
acquire	O
the	O
locations	O
of	O
human	O
pose	O
joints	O
.	O
	
These	O
pose	O
joints	O
are	O
combined	O
into	O
different	O
human	O
body	O
parts	O
.	O
	
The	O
part	O
regions	O
are	O
first	O
transformed	O
using	O
our	O
Feature	B-Method
Embedding	I-Method
sub	I-Method
-	I-Method
Net	I-Method
(	O
FEN	B-Method
)	O
and	O
then	O
are	O
combined	O
to	O
form	O
a	O
new	O
modified	O
part	O
image	O
containing	O
the	O
normalized	O
body	O
parts	O
.	O
	
The	O
global	O
image	O
and	O
the	O
new	O
modified	O
part	O
image	O
are	O
then	O
fed	O
into	O
our	O
CNN	B-Method
together	O
.	O
	
The	O
two	O
images	O
share	O
the	O
same	O
weights	O
for	O
the	O
first	O
several	O
layers	O
,	O
then	O
have	O
their	O
own	O
network	O
weights	O
in	O
the	O
subsequent	O
layers	O
.	O
	
At	O
last	O
,	O
we	O
use	O
Feature	B-Method
Weighting	I-Method
	
sub	B-Method
-	I-Method
Net	I-Method
(	O
FWN	B-Method
)	O
	
to	O
learn	O
the	O
weights	O
of	O
part	O
features	O
before	O
fusing	O
them	O
with	O
the	O
global	O
features	O
for	O
final	O
Softmax	B-Task
Loss	I-Task
computation	I-Task
.	O
	
Considering	O
that	O
pedestrian	O
images	O
form	O
different	O
datasets	O
have	O
different	O
sizes	O
,	O
it	O
is	O
not	O
appropriate	O
to	O
directly	O
use	O
the	O
CNN	B-Method
models	I-Method
pre	O
-	O
trained	O
on	O
the	O
ImageNet	B-Material
dataset	I-Material
.	O
	
We	O
thus	O
modify	O
and	O
design	O
a	O
network	O
based	O
on	O
the	O
GoogLeNet	B-Method
,	O
as	O
shown	O
in	O
the	O
Table	O
[	O
reference	O
]	O
.	O
	
Layers	O
from	O
data	O
to	O
inception	O
(	O
4e	O
)	O
in	O
Table	O
[	O
reference	O
]	O
corresponds	O
to	O
the	O
blue	O
CNN	O
block	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
	
,	O
CNNg	B-Method
and	O
CNNp	B-Method
are	O
inception	O
(	O
5a	O
)	O
and	O
inception	O
(	O
5b	O
)	O
,	O
respectively	O
.	O
	
The	O
green	B-Method
CONV	I-Method
matches	O
the	O
subsequent	O
1	O
1	O
convolution	O
.	O
	
The	O
loss	O
layers	O
are	O
not	O
shown	O
in	O
Table	O
[	O
reference	O
]	O
.	O
	
The	O
Batch	B-Method
Normalization	I-Method
Layers	I-Method
are	O
inserted	O
before	O
every	O
ReLU	B-Method
Layer	I-Method
to	O
accelerate	O
the	O
convergence	O
.	O
	
We	O
employ	O
a	O
Convolutional	B-Method
Layer	I-Method
and	O
a	O
Global	B-Method
Average	I-Method
Pooling	I-Method
Layer	I-Method
(	O
GAP	B-Method
)	O
at	O
the	O
end	O
of	O
network	O
to	O
let	O
our	O
network	O
can	O
fit	O
different	O
sizes	O
of	O
input	O
images	O
.	O
	
In	O
this	O
work	O
,	O
we	O
fix	O
input	O
image	O
size	O
as	O
512	O
256	O
.	O
	
subsection	O
:	O
Feature	B-Method
Embedding	I-Method
sub	I-Method
-	I-Method
Net	I-Method
	
The	O
Feature	B-Method
Embedding	I-Method
sub	I-Method
-	I-Method
Net	I-Method
(	O
FEN	B-Method
)	O
is	O
divided	O
into	O
four	O
steps	O
,	O
including	O
locating	O
the	O
joint	O
,	O
generating	O
the	O
original	O
part	O
images	O
,	O
PTN	B-Method
,	O
and	O
outputting	O
the	O
final	O
modified	O
part	O
images	O
.	O
	
With	O
a	O
given	O
person	O
image	O
,	O
FEN	B-Method
first	O
locates	O
the	O
14	O
joints	O
of	O
human	O
body	O
using	O
human	B-Method
pose	I-Method
estimation	I-Method
algorithm	I-Method
.	O
	
Fig	O
.	O
	
[	O
reference	O
]	O
	
(	O
c	O
)	O
shows	O
an	O
example	O
of	O
the	O
14	O
joints	O
of	O
human	O
body	O
.	O
	
According	O
to	O
number	O
,	O
the	O
14	O
joints	O
are	O
{	O
}	O
.	O
	
Then	O
we	O
propose	O
six	O
rectangles	O
to	O
cover	O
six	O
different	O
parts	O
of	O
human	O
body	O
,	O
including	O
the	O
head	O
region	O
,	O
the	O
upper	O
body	O
,	O
two	O
arms	O
and	O
two	O
legs	O
.	O
	
For	O
each	O
human	O
joint	O
,	O
we	O
calculate	O
a	O
response	B-Method
feature	I-Method
map	I-Method
.	O
	
The	O
horizontal	O
and	O
vertical	O
dimensions	O
of	O
the	O
feature	O
maps	O
are	O
denoted	O
by	O
and	O
,	O
respectively	O
.	O
	
With	O
the	O
feature	O
maps	O
,	O
the	O
fourteen	O
body	O
joints	O
,	O
can	O
be	O
located	O
by	O
finding	O
the	O
center	O
of	O
mass	O
with	O
the	O
feature	O
values	O
:	O
where	O
in	O
Eq	O
.	O
	
[	O
reference	O
]	O
are	O
the	O
coordinates	O
of	O
joints	O
,	O
and	O
is	O
the	O
value	O
of	O
pixels	O
in	O
response	O
feature	O
maps	O
.	O
	
Different	O
from	O
,	O
we	O
do	O
not	O
use	O
complex	O
pose	B-Method
estimation	I-Method
networks	I-Method
as	O
the	O
pre	B-Method
-	I-Method
trained	I-Method
network	I-Method
.	O
	
Instead	O
,	O
we	O
use	O
a	O
standard	O
FCN	B-Method
trained	O
on	O
the	O
LSP	B-Material
dataset	I-Material
and	O
MPII	B-Material
human	I-Material
pose	I-Material
dataset	I-Material
.	O
	
In	O
the	O
second	O
step	O
,	O
the	O
FEN	B-Method
uses	O
the	O
14	O
human	O
joints	O
to	O
further	O
locate	O
six	O
sub	O
-	O
regions	O
(	O
head	O
,	O
upper	O
body	O
,	O
left	O
arm	O
,	O
right	O
arm	O
,	O
left	O
leg	O
,	O
and	O
right	O
leg	O
)	O
as	O
human	O
parts	O
.	O
	
These	O
parts	O
are	O
normalized	O
through	O
cropping	B-Method
,	O
rotating	O
,	O
and	O
resizing	O
to	O
fixed	O
size	O
and	O
orientation	O
.	O
	
As	O
shown	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
(	O
d	O
)	O
	
,	O
the	O
14	O
located	O
body	O
joints	O
are	O
assigned	O
to	O
six	O
rectangles	O
indicating	O
six	O
parts	O
.	O
	
The	O
head	O
part	O
,	O
the	O
upper	O
body	O
part	O
,	O
the	O
left	O
arm	O
part	O
,	O
the	O
right	O
arm	O
part	O
,	O
the	O
left	O
leg	O
part	O
,	O
and	O
the	O
right	O
leg	O
part	O
,	O
respectively	O
.	O
	
For	O
each	O
body	O
part	O
set	O
,	O
The	O
corresponding	O
sub	O
-	O
region	O
bounding	O
box	O
can	O
be	O
obtained	O
based	O
on	O
the	O
location	O
coordinates	O
of	O
all	O
body	O
joints	O
in	O
each	O
part	O
set	O
:	O
An	O
example	O
of	O
the	O
extracted	O
six	O
body	O
sub	O
-	O
regions	O
are	O
visualized	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
(	O
d	O
)	O
.	O
	
As	O
shown	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
(	O
e	O
)	O
,	O
these	O
body	O
sub	O
-	O
regions	O
are	O
normalized	O
through	O
cropping	B-Method
,	O
rotating	O
,	O
and	O
resizing	O
to	O
fixed	O
sizes	O
and	O
orientations	O
.	O
	
All	O
body	O
parts	O
are	O
rotated	O
to	O
fixed	O
vertical	O
direction	O
.	O
	
Arms	O
and	O
legs	O
are	O
resized	O
to	O
256	O
64	O
,	O
upper	O
body	O
is	O
resized	O
to	O
256	O
128	O
and	O
head	O
is	O
resized	O
to	O
128	O
128	O
.	O
	
Those	O
resized	O
and	O
rotated	O
parts	O
are	O
combined	O
to	O
form	O
the	O
body	O
part	O
image	O
.	O
	
Because	O
6	O
body	O
parts	O
have	O
different	O
sizes	O
,	O
black	O
area	O
is	O
unavoidable	O
in	O
body	O
part	O
image	O
.	O
	
Simply	O
resizing	O
and	O
rotation	O
can	O
not	O
overcome	O
the	O
complex	O
pose	O
variations	O
,	O
especially	O
if	O
the	O
pose	O
estimations	O
are	O
inaccurate	O
.	O
	
We	O
thus	O
design	O
a	O
PTN	B-Method
modified	O
from	O
Spatial	B-Method
Transformer	I-Method
Networks	I-Method
(	O
STN	B-Method
)	O
to	O
learn	O
the	O
angles	O
required	O
for	O
rotating	O
the	O
five	O
body	O
parts	O
.	O
	
STN	B-Method
is	O
a	O
spatial	B-Method
transformer	I-Method
module	I-Method
which	O
can	O
be	O
inserted	O
to	O
a	O
neural	B-Method
network	I-Method
to	O
provide	O
spatial	O
transformation	O
capabilities	O
.	O
	
It	O
thus	O
is	O
potential	O
to	O
adjust	O
the	O
localizations	O
and	O
angles	O
of	O
parts	O
.	O
	
A	O
STN	B-Method
is	O
a	O
small	O
net	O
which	O
allows	O
for	O
end	B-Task
-	I-Task
to	I-Task
-	I-Task
end	I-Task
training	I-Task
with	O
standard	O
back	B-Method
-	I-Method
propagation	I-Method
,	O
therefore	O
,	O
the	O
introduction	O
of	O
STN	B-Method
does	O
n’t	O
substantially	O
increase	O
the	O
complexity	O
of	O
training	B-Method
procedure	I-Method
.	O
	
The	O
STN	B-Method
consist	O
of	O
three	O
components	O
:	O
localisation	B-Method
network	I-Method
,	O
parameterised	B-Method
sampling	I-Method
grid	I-Method
,	O
and	O
differentiable	B-Method
image	I-Method
sampling	I-Method
.	O
	
The	O
localisation	B-Method
network	I-Method
takes	O
the	O
input	O
feature	O
map	O
and	O
outputs	O
the	O
parameters	O
of	O
the	O
transformation	O
.	O
	
For	O
our	O
net	O
,	O
we	O
choose	O
affine	O
transformation	O
so	O
our	O
transformation	O
parameter	O
is	O
6	O
-	O
dimensional	O
.	O
	
The	O
parameterized	B-Method
sampling	I-Method
grid	I-Method
computes	O
each	O
output	O
pixel	O
and	O
the	O
differentiable	B-Method
image	I-Method
sampling	I-Method
component	I-Method
produces	O
the	O
sampled	O
output	O
image	O
.	O
	
For	O
more	O
details	O
about	O
STN	B-Method
,	O
please	O
refer	O
to	O
.	O
	
As	O
discussed	O
above	O
,	O
we	O
use	O
a	O
6	O
-	O
dimensional	O
parameter	O
to	O
complete	O
affine	B-Task
transformation	I-Task
:	O
where	O
the	O
are	O
the	O
scale	O
and	O
rotation	O
parameters	O
,	O
while	O
the	O
are	O
the	O
translation	O
parameters	O
.	O
	
The	O
in	O
Eq	O
.	O
	
[	O
reference	O
]	O
are	O
the	O
target	O
coordinates	O
of	O
the	O
output	O
image	O
and	O
the	O
are	O
the	O
source	O
coordinates	O
of	O
the	O
input	O
image	O
.	O
	
Usually	O
the	O
STN	B-Method
computes	O
one	O
affine	B-Method
transform	I-Method
for	O
the	O
whole	O
image	O
,	O
considering	O
a	O
pedestrian	O
’s	O
different	O
parts	O
have	O
various	O
orientations	O
and	O
sizes	O
from	O
each	O
other	O
,	O
STN	B-Method
is	O
not	O
applicable	O
to	O
a	O
part	O
image	O
.	O
	
Inspired	O
by	O
STN	B-Method
,	O
we	O
design	O
a	O
Pose	B-Method
Transformer	I-Method
Network	I-Method
(	O
PTN	B-Method
)	O
which	O
computes	O
the	O
affine	O
transformation	O
for	O
each	O
part	O
in	O
part	O
image	O
individually	O
and	O
combines	O
6	O
transformed	O
parts	O
together	O
.	O
	
Similar	O
to	O
STN	B-Method
,	O
our	O
PTN	B-Method
is	O
also	O
a	O
small	O
net	O
and	O
does	O
n’t	O
substantially	O
increase	O
the	O
complexity	B-Metric
of	O
our	O
training	B-Method
procedure	I-Method
.	O
	
As	O
a	O
consequence	O
,	O
PTN	B-Method
has	O
potential	O
to	O
perform	O
better	O
than	O
STN	B-Method
for	O
person	B-Task
images	I-Task
.	O
	
Fig	O
.	O
	
[	O
reference	O
]	O
shows	O
the	O
detailed	O
structure	O
of	O
PTN	B-Method
.	O
	
Considering	O
a	O
pedestrian	O
’s	O
head	O
seldom	O
has	O
a	O
large	O
rotation	O
angle	O
,	O
we	O
do	O
n’t	O
insert	O
a	O
PTN	B-Method
net	I-Method
for	O
the	O
pedestrian	O
’s	O
head	O
part	O
.	O
	
Therefore	O
,	O
we	O
totally	O
have	O
5	O
independent	O
PTN	B-Method
,	O
namely	O
,	O
,	O
,	O
,	O
.	O
	
Each	O
PTN	B-Method
can	O
generate	O
a	O
6	O
-	O
dimensional	O
transformation	O
parameter	O
and	O
use	O
to	O
adjust	O
pedestrian	O
’s	O
part	O
,	O
we	O
can	O
get	O
modified	O
body	O
part	O
.	O
	
By	O
combining	O
the	O
five	O
transformed	O
parts	O
and	O
a	O
head	O
part	O
together	O
,	O
we	O
obtain	O
the	O
modified	O
part	O
image	O
.	O
	
subsection	O
:	O
Feature	B-Method
Weighting	I-Method
sub	I-Method
-	I-Method
Net	I-Method
	
The	O
generated	O
part	O
features	O
are	O
combined	O
with	O
the	O
global	O
feature	O
to	O
generate	O
a	O
robust	B-Method
feature	I-Method
representation	I-Method
for	O
precise	O
person	B-Task
re	I-Task
-	I-Task
identification	I-Task
.	O
	
As	O
the	O
poses	O
generated	O
by	O
the	O
pose	B-Method
detector	I-Method
might	O
be	O
affected	O
by	O
factors	O
like	O
occlusions	O
,	O
pose	O
changes	O
,	O
etc	O
.	O
	
Then	O
inaccurate	O
part	B-Task
detection	I-Task
results	O
could	O
be	O
obtained	O
.	O
	
Examples	O
are	O
shown	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
.	O
	
Therefore	O
,	O
the	O
part	O
features	O
could	O
be	O
not	O
reliable	O
enough	O
.	O
	
This	O
happens	O
frequently	O
in	O
real	O
applications	O
with	O
unconstrained	B-Task
video	I-Task
gathering	I-Task
environment	I-Task
.	O
	
Simply	O
fusing	O
global	O
feature	O
and	O
the	O
part	O
feature	O
may	O
introduces	O
noises	O
.	O
	
This	O
motivates	O
us	O
to	O
introduce	O
Feature	B-Method
Weighting	I-Method
	
sub	B-Method
-	I-Method
Net	I-Method
(	O
FWN	B-Method
)	O
	
to	O
seek	O
a	O
more	O
optimal	O
feature	B-Method
fusion	I-Method
.	O
	
FWN	B-Method
is	O
consisted	O
with	O
a	O
Weight	B-Method
Layer	I-Method
and	O
a	O
nonlinear	B-Method
transformation	I-Method
,	O
which	O
decides	O
the	O
importance	O
of	O
each	O
dimension	O
in	O
the	O
part	O
feature	O
vector	O
.	O
	
Considering	O
that	O
a	O
single	O
linear	B-Method
Weight	I-Method
Layer	I-Method
might	O
cause	O
excessive	O
response	O
on	O
some	O
specific	O
dimensions	O
of	O
the	O
part	O
vector	O
,	O
we	O
add	O
a	O
nonlinear	B-Method
function	I-Method
to	O
equalize	O
the	O
response	O
of	O
part	O
feature	O
vector	O
,	O
and	O
the	O
fused	B-Method
feature	I-Method
representation	I-Method
is	O
where	O
the	O
and	O
the	O
are	O
the	O
global	O
and	O
part	O
feature	O
vectors	O
.	O
	
The	O
and	O
in	O
Eq	O
.	O
	
[	O
reference	O
]	O
are	O
the	O
weight	O
and	O
bias	O
vectors	O
which	O
have	O
the	O
same	O
dimensions	O
with	O
.	O
	
The	O
means	O
the	O
Hadamard	O
product	O
of	O
two	O
vectors	O
,	O
and	O
the	O
means	O
concatenation	O
of	O
two	O
vectors	O
together	O
.	O
	
The	O
imposes	O
the	O
hyperbolic	O
tangent	O
nonlinearity	O
.	O
	
is	O
our	O
final	O
person	O
feature	O
generated	O
by	O
and	O
.	O
	
To	O
allow	O
back	O
-	O
propagation	O
of	O
the	O
loss	O
through	O
the	O
FWN	B-Method
,	O
we	O
give	O
the	O
gradient	B-Method
formula	I-Method
:	O
where	O
,	O
,	O
,	O
,	O
,	O
and	O
are	O
the	O
dimensions	O
of	O
and	O
.	O
	
subsection	O
:	O
ReID	B-Task
Feature	O
Extraction	O
	
The	O
global	O
feature	O
and	O
body	O
-	O
part	O
features	O
are	O
learned	O
by	O
training	O
the	O
Pose	B-Method
-	I-Method
driven	I-Method
Deep	I-Method
Convolutional	I-Method
model	O
.	O
	
These	O
two	O
types	O
of	O
features	O
are	O
then	O
fused	O
under	O
a	O
unified	B-Method
framework	I-Method
for	O
multi	B-Task
-	I-Task
class	I-Task
person	I-Task
identification	I-Task
.	O
	
PDC	B-Method
extracts	O
the	O
global	O
feature	O
maps	O
from	O
the	O
global	B-Method
body	I-Method
-	I-Method
based	I-Method
representation	I-Method
and	O
learns	O
a	O
1024	B-Method
-	I-Method
dimensional	I-Method
feature	I-Method
embedding	I-Method
.	O
	
Similarly	O
,	O
a	O
1024	O
-	O
dimension	O
feature	O
is	O
acquired	O
from	O
the	O
modified	O
part	O
image	O
after	O
the	O
FEN	B-Method
.	O
	
The	O
global	O
body	O
feature	O
and	O
the	O
local	O
body	O
part	O
features	O
are	O
compensated	O
into	O
a	O
2048	O
-	O
dimensional	O
feature	O
as	O
the	O
final	O
representation	O
.	O
	
After	O
being	O
weighted	O
by	O
FWN	B-Method
,	O
the	O
final	O
representation	O
is	O
used	O
for	O
Person	O
ReID	B-Task
with	O
Euclidean	O
distance	O
.	O
	
section	O
:	O
Experiment	O
	
subsection	O
:	O
Datasets	O
	
We	O
select	O
three	O
widely	O
used	O
person	O
ReID	B-Task
datasets	O
as	O
our	O
evaluation	O
protocols	O
,	O
including	O
the	O
CUHK	B-Material
03	I-Material
,	O
Market	B-Material
1501	I-Material
,	O
and	O
VIPeR	B-Material
.	O
	
Note	O
that	O
,	O
because	O
the	O
amount	O
of	O
images	O
in	O
VIPeR	B-Material
is	O
not	O
enough	O
for	O
training	O
a	O
deep	B-Method
model	I-Method
,	O
we	O
combine	O
the	O
training	O
sets	O
of	O
VIPeR	B-Material
,	O
CUHK	B-Material
03	I-Material
and	O
Market	B-Material
1501	I-Material
together	O
to	O
train	O
the	O
model	O
for	O
VIPeR	B-Material
.	O
	
CUHK	B-Material
03	I-Material
	
:	O
This	O
dataset	O
is	O
made	O
up	O
of	O
14	O
,	O
096	O
images	O
of	O
1	O
,	O
467	O
different	O
persons	O
taken	O
by	O
six	O
campus	O
cameras	O
.	O
	
Each	O
person	O
only	O
appears	O
in	O
two	O
views	O
.	O
	
This	O
dataset	O
provides	O
two	O
types	O
of	O
annotations	O
,	O
including	O
manually	O
labelled	O
pedestrian	O
bounding	O
boxes	O
and	O
bounding	O
boxes	O
automatically	O
detected	O
by	O
the	O
Deformable	B-Method
-	I-Method
Part	I-Method
-	I-Method
Model	I-Method
(	I-Method
DPM	I-Method
)	I-Method
detector	I-Method
.	O
	
We	O
denote	O
the	O
two	O
corresponding	O
subsets	O
as	O
labeled	O
dataset	O
and	O
detected	O
dataset	O
,	O
respectively	O
.	O
	
The	O
dataset	O
also	O
provides	O
20	O
test	O
sets	O
,	O
each	O
includes	O
100	O
identities	O
.	O
	
We	O
select	O
the	O
first	O
set	O
and	O
use	O
100	O
identities	O
for	O
testing	O
and	O
the	O
rest	O
1	O
,	O
367	O
identities	O
for	O
training	O
.	O
	
We	O
report	O
the	O
averaged	O
performance	O
after	O
repeating	O
the	O
experiments	O
for	O
20	O
times	O
.	O
	
Market	B-Material
1501	I-Material
:	O
	
This	O
dataset	O
is	O
made	O
up	O
of	O
32	O
,	O
368	O
pedestrian	O
images	O
taken	O
by	O
six	O
manually	O
configured	O
cameras	O
.	O
	
It	O
has	O
1	O
,	O
501	O
different	O
persons	O
in	O
it	O
.	O
	
On	O
average	O
,	O
there	O
are	O
3.6	O
images	O
for	O
each	O
person	O
captured	O
from	O
each	O
angle	O
.	O
	
The	O
images	O
can	O
be	O
classified	O
into	O
two	O
types	O
,	O
,	O
cropped	O
images	O
and	O
images	O
of	O
pedestrians	O
automatically	O
detected	O
by	O
the	O
DPM	B-Method
.	O
	
Because	O
Market	B-Material
1501	I-Material
has	O
provided	O
the	O
training	O
set	O
and	O
testing	O
set	O
,	O
we	O
use	O
images	O
in	O
the	O
training	O
set	O
for	O
training	O
our	O
PDC	B-Method
network	O
and	O
follow	O
the	O
protocol	O
to	O
report	O
the	O
ReID	B-Metric
performance	I-Metric
.	O
	
VIPeR	B-Material
:	O
	
This	O
dataset	O
is	O
made	O
up	O
of	O
632	O
person	O
images	O
captured	O
from	O
two	O
views	O
.	O
	
Each	O
pair	O
of	O
images	O
depicting	O
a	O
person	O
are	O
collected	O
by	O
different	O
cameras	O
with	O
varying	O
viewpoints	O
and	O
illumination	O
conditions	O
.	O
	
Because	O
the	O
amount	O
of	O
images	O
in	O
VIPeR	B-Material
is	O
not	O
enough	O
to	O
train	O
the	O
deep	B-Method
model	I-Method
,	O
we	O
also	O
perform	O
data	B-Method
augmentation	I-Method
with	O
similar	O
methods	O
in	O
existing	O
deep	B-Method
learning	I-Method
based	O
person	O
ReID	B-Task
works	O
.	O
	
For	O
each	O
training	O
image	O
,	O
we	O
generate	O
5	O
augmented	O
images	O
around	O
the	O
image	O
center	O
by	O
performing	O
random	B-Method
2D	I-Method
transformations	I-Method
.	O
	
Finally	O
,	O
we	O
combine	O
the	O
augmented	O
training	O
images	O
of	O
VIPeR	B-Material
,	O
training	O
images	O
of	O
CUHK	B-Material
03	I-Material
and	O
Market	B-Material
1501	I-Material
together	O
,	O
as	O
the	O
final	O
training	O
set	O
.	O
	
subsection	O
:	O
Implementation	O
Details	O
	
The	O
pedestrian	B-Method
representations	I-Method
are	O
learned	O
through	O
multi	B-Method
-	I-Method
class	I-Method
classification	I-Method
CNN	I-Method
.	O
	
We	O
use	O
the	O
full	O
body	O
and	O
body	O
parts	O
to	O
learn	O
the	O
representations	O
with	O
Softmax	O
Loss	O
,	O
respectively	O
.	O
	
We	O
report	O
rank1	B-Metric
,	O
rank5	B-Metric
,	O
rank10	B-Metric
and	O
rank20	B-Metric
accuracy	I-Metric
of	O
cumulative	B-Metric
match	I-Metric
curve	I-Metric
(	O
CMC	B-Metric
)	O
on	O
the	O
three	O
datasets	O
to	O
evaluate	O
the	O
ReID	B-Metric
performance	I-Metric
.	O
	
As	O
for	O
Market	B-Material
-	I-Material
1051	I-Material
,	O
mean	B-Metric
Average	I-Metric
Precision	I-Metric
(	O
mAP	B-Metric
)	I-Metric
is	O
also	O
reported	O
as	O
an	O
additional	O
criterion	O
to	O
evaluate	O
the	O
performance	O
.	O
	
Our	O
model	O
is	O
trained	O
and	O
fine	O
-	O
tuned	O
on	O
Caffe	B-Method
.	O
	
Stochastic	B-Method
Gradient	I-Method
Descent	I-Method
(	O
SGD	B-Method
)	I-Method
is	O
used	O
to	O
optimize	O
our	O
model	O
.	O
	
Images	O
for	O
training	O
are	O
randomly	O
divided	O
into	O
several	O
batches	O
,	O
each	O
of	O
which	O
includes	O
16	O
images	O
.	O
	
The	O
initial	O
learning	B-Metric
rate	I-Metric
is	O
set	O
as	O
0.01	O
,	O
and	O
is	O
gradually	O
lowered	O
after	O
each	O
iterations	O
.	O
	
It	O
should	O
be	O
noted	O
that	O
,	O
the	O
learning	B-Metric
rate	I-Metric
in	O
part	B-Method
localization	I-Method
network	I-Method
is	O
only	O
0.1	O
%	O
of	O
that	O
in	O
feature	B-Method
learning	I-Method
network	I-Method
.	O
	
For	O
each	O
dataset	O
,	O
we	O
train	O
a	O
model	O
on	O
its	O
corresponding	O
training	O
set	O
as	O
the	O
pretrained	B-Method
body	I-Method
-	I-Method
based	I-Method
model	I-Method
.	O
	
For	O
the	O
overall	O
network	B-Task
training	I-Task
,	O
the	O
network	O
is	O
initialized	O
using	O
pretrained	B-Method
body	I-Method
-	I-Method
based	I-Method
model	I-Method
.	O
	
Then	O
,	O
we	O
adopt	O
the	O
same	O
training	B-Method
strategy	I-Method
as	O
described	O
above	O
.	O
	
We	O
implement	O
our	O
approach	O
with	O
GTX	B-Method
TITAN	I-Method
X	I-Method
GPU	I-Method
,	O
Intel	O
i7	O
CPU	O
,	O
and	O
128	O
GB	O
memory	O
.	O
	
All	O
images	O
are	O
resized	O
to	O
.	O
	
The	O
mean	O
value	O
is	O
subtracted	O
from	O
each	O
channel	O
(	O
B	O
,	O
G	O
,	O
and	O
R	O
)	O
for	O
training	O
the	O
network	O
.	O
	
The	O
images	O
of	O
each	O
dataset	O
are	O
randomized	O
in	O
the	O
process	O
of	O
training	O
stage	O
.	O
	
subsection	O
:	O
Evaluation	O
of	O
Individual	O
Components	O
	
We	O
evaluate	O
five	O
variants	O
of	O
our	O
approach	O
to	O
verify	O
the	O
validity	O
of	O
individual	O
components	O
in	O
our	O
PDC	B-Method
,	O
,	O
components	O
like	O
Feature	B-Method
Embedding	I-Method
sub	I-Method
-	I-Method
Net	I-Method
(	O
FEN	B-Method
)	O
and	O
Feature	B-Method
Weighting	I-Method
sub	I-Method
-	I-Method
Net	I-Method
(	O
FWN	B-Method
)	O
.	O
	
Comparisons	O
on	O
three	O
datasets	O
are	O
summarized	O
in	O
Table	O
[	O
reference	O
]	O
.	O
	
In	O
the	O
table	O
,	O
“	O
Global	O
Only	O
”	O
means	O
we	O
train	O
our	O
deep	B-Method
model	I-Method
without	O
using	O
any	O
part	O
information	O
.	O
	
“	O
	
Global	B-Method
+	I-Method
Part	I-Method
”	I-Method
denotes	O
CNN	B-Method
trained	O
through	O
two	O
streams	O
without	O
FEN	B-Method
and	O
FWN	B-Method
.	O
	
Based	O
on	O
“	O
Global	O
+	O
Part	O
”	O
,	O
considering	O
FEN	B-Method
is	O
denoted	O
as	O
“	O
Global	O
+	O
Part	O
+	O
FEN	B-Method
”	O
.	O
	
Similarly	O
,	O
“	O
Global	O
+	O
Part	O
+	O
FWN	B-Method
”	O
means	O
considering	O
FWN	B-Method
.	O
	
In	O
addition	O
,	O
“	O
Part	O
Only	O
”	O
denotes	O
only	O
using	O
part	O
features	O
.	O
	
PDC	B-Method
considers	O
all	O
of	O
these	O
components	O
.	O
	
From	O
the	O
experimental	O
results	O
,	O
it	O
can	O
be	O
observed	O
that	O
,	O
fusing	O
global	O
features	O
and	O
part	O
features	O
achieves	O
better	O
performance	O
than	O
only	O
using	O
one	O
of	O
them	O
.	O
	
Compared	O
with	O
“	O
Global	B-Method
Only	I-Method
”	I-Method
,	O
considering	O
extra	O
part	O
cues	O
,	O
,	O
“	O
Global	O
+	O
Part	O
”	O
,	O
largely	O
improves	O
the	O
ReID	B-Metric
performance	I-Metric
and	O
achieves	O
the	O
rank1	B-Metric
accuracy	O
of	O
85.07	O
%	O
and	O
76.33	O
%	O
on	O
CUHK	B-Material
03	I-Material
labeled	O
and	O
detected	O
datasets	O
,	O
respectively	O
.	O
	
Moreover	O
,	O
using	O
FEN	B-Method
and	O
FWN	B-Method
further	O
boosts	O
the	O
rank1	B-Metric
identification	I-Metric
rate	I-Metric
.	O
	
This	O
shows	O
that	O
training	O
our	O
model	O
using	O
PTN	B-Method
and	I-Method
Weight	I-Method
Layer	I-Method
gets	O
more	O
competitive	O
performance	O
on	O
three	O
datasets	O
.	O
	
The	O
above	O
experiments	O
shows	O
that	O
each	O
of	O
the	O
components	O
in	O
our	O
method	O
is	O
helpful	O
for	O
improving	O
the	O
performance	O
.	O
	
By	O
considering	O
all	O
of	O
these	O
components	O
,	O
PDC	B-Method
exhibits	O
the	O
best	O
performance	O
.	O
	
subsection	O
:	O
Comparison	O
with	O
Related	O
Works	O
	
CUHK	B-Material
03	I-Material
	
:	O
For	O
the	O
CUHK	B-Material
03	I-Material
dataset	O
,	O
we	O
compare	O
our	O
PDC	B-Method
with	O
some	O
recent	O
methods	O
,	O
including	O
distance	B-Method
metric	I-Method
learning	I-Method
methods	I-Method
:	O
MLAPG	B-Method
,	O
LOMO	B-Method
+	I-Method
XQDA	I-Method
,	O
BoW	B-Method
+	I-Method
HS	I-Method
,	O
WARCA	B-Method
,	O
LDNS	B-Method
,	O
feature	B-Method
extraction	I-Method
method	I-Method
:	O
	
GOG	B-Method
and	I-Method
deep	I-Method
learning	I-Method
based	I-Method
methods	I-Method
:	O
IDLA	B-Method
,	O
PersonNet	B-Method
,	O
DGDropout	B-Method
,	O
SI	B-Method
+	I-Method
CI	I-Method
,	O
Gate	B-Method
S	I-Method
-	I-Method
CNN	I-Method
,	O
LSTM	B-Method
S	I-Method
-	I-Method
CNN	I-Method
,	O
EDM	B-Method
,	O
PIE	B-Method
and	O
Spindle	B-Method
.	O
	
We	O
conduct	O
experiments	O
on	O
both	O
the	O
detected	O
dataset	O
and	O
the	O
labeled	O
dataset	O
.	O
	
Experimental	O
results	O
are	O
presented	O
in	O
Table	O
[	O
reference	O
]	O
and	O
Table	O
[	O
reference	O
]	O
.	O
	
Experimental	O
results	O
show	O
that	O
our	O
approach	O
outperforms	O
all	O
distance	B-Method
metric	I-Method
learning	I-Method
methods	I-Method
by	O
a	O
large	O
margin	O
.	O
	
It	O
can	O
be	O
seen	O
that	O
PIE	B-Method
,	O
Spindle	B-Method
and	O
our	O
PDC	B-Method
which	O
all	O
use	O
the	O
human	O
pose	O
cues	O
achieve	O
better	O
performance	O
than	O
the	O
other	O
methods	O
.	O
	
This	O
shows	O
the	O
advantages	O
of	O
considering	O
extra	O
pose	O
cues	O
in	O
person	O
ReID	B-Task
.	O
	
It	O
is	O
also	O
clear	O
that	O
,	O
our	O
PDC	B-Method
achieves	O
the	O
rank1	B-Metric
accuracy	O
of	O
78.29	O
and	O
88.70	O
on	O
detected	O
and	O
labeled	O
datasets	O
,	O
respectively	O
.	O
	
This	O
leads	O
to	O
11.19	O
and	O
0.20	O
performance	O
gains	O
over	O
the	O
reported	O
performance	O
of	O
PIE	B-Method
and	O
Spindle	O
,	O
respectively	O
.	O
	
Market	B-Material
1501	I-Material
:	O
	
On	O
Market	B-Material
1501	I-Material
,	O
the	O
compared	O
works	O
that	O
learn	O
distance	B-Metric
metrics	I-Metric
for	O
person	O
ReID	B-Task
include	O
LOMO	B-Method
+	I-Method
XQDA	I-Method
,	O
BoW	B-Method
+	I-Method
Kissme	I-Method
,	O
WARCA	B-Method
,	O
LDNS	B-Method
,	O
TMA	B-Method
and	O
HVIL	B-Method
.	O
	
Compared	O
works	O
based	O
on	O
deep	B-Method
learning	I-Method
are	O
PersonNet	B-Method
,	O
Gate	B-Method
S	I-Method
-	I-Method
CNN	I-Method
,	O
LSTM	B-Method
S	I-Method
-	I-Method
CNN	I-Method
,	O
PIE	B-Method
and	O
Spindle	B-Method
.	O
	
DGDropout	B-Method
does	O
not	O
report	O
performance	O
on	O
Market1501	B-Material
.	O
	
So	O
we	O
implemented	O
DGDroput	B-Method
and	O
show	O
experimental	O
results	O
in	O
Table	O
[	O
reference	O
]	O
.	O
	
It	O
is	O
clear	O
that	O
our	O
method	O
outperforms	O
these	O
compared	O
works	O
by	O
a	O
large	O
margin	O
.	O
	
Specifically	O
,	O
PDC	B-Method
achieves	O
rank1	B-Metric
accuracy	O
of	O
84.14	O
%	O
,	O
and	O
mAP	B-Metric
of	O
63.41	O
%	O
using	O
the	O
single	B-Method
query	I-Method
mode	I-Method
.	O
	
They	O
are	O
higher	O
than	O
the	O
rank1	B-Metric
accuracy	O
and	O
mAP	B-Metric
of	I-Metric
PIE	I-Metric
,	O
which	O
performs	O
best	O
among	O
the	O
compared	O
works	O
.	O
	
This	O
is	O
because	O
our	O
PDC	B-Method
not	O
only	O
learns	O
pose	O
invariant	O
features	O
with	O
FEN	B-Method
but	O
also	O
learns	O
better	O
fusion	B-Method
strategy	I-Method
with	O
FWN	B-Method
to	O
emphasize	O
the	O
more	O
discriminative	O
features	O
.	O
	
VIPeR	B-Material
	
:	O
We	O
also	O
evaluate	O
our	O
method	O
by	O
comparing	O
it	O
with	O
several	O
existing	O
methods	O
on	O
VIPeR	B-Material
.	O
	
The	O
compared	O
methods	O
include	O
distance	B-Method
metric	I-Method
learning	I-Method
ones	I-Method
:	O
MLAPG	B-Method
,	O
LOMO	B-Method
+	I-Method
XQDA	I-Method
,	O
BoW	B-Method
,	O
WARCA	B-Method
and	O
LDNS	B-Method
,	O
and	O
deep	B-Method
learning	I-Method
based	I-Method
ones	I-Method
:	O
IDLA	B-Method
,	O
DGDropout	B-Method
,	O
SI	B-Method
+	I-Method
CI	I-Method
,	O
Gate	B-Method
S	I-Method
-	I-Method
CNN	I-Method
,	O
LSTM	B-Method
S	I-Method
-	I-Method
CNN	I-Method
,	O
MTL	B-Method
-	I-Method
LORAE	I-Method
and	O
Spindle	B-Method
.	O
	
From	O
the	O
results	O
shown	O
in	O
Table	O
[	O
reference	O
]	O
,	O
our	O
PDC	B-Method
achieves	O
the	O
rank1	B-Metric
accuracy	O
of	O
51.27	O
%	O
.	O
	
This	O
outperforms	O
most	O
of	O
compared	O
methods	O
except	O
Spindle	B-Method
which	O
also	O
considers	O
the	O
human	O
pose	O
cues	O
.	O
	
We	O
assume	O
the	O
reason	O
might	O
be	O
because	O
,	O
Spindle	O
involves	O
more	O
training	O
sets	O
to	O
learn	O
the	O
model	O
for	O
VIPeR	B-Material
.	O
	
Therefore	O
,	O
the	O
training	O
set	O
of	O
Spindle	O
is	O
larger	O
than	O
ours	O
,	O
,	O
the	O
combination	O
of	O
Market	B-Material
1501	I-Material
,	O
CUHK03	B-Material
and	O
VIPeR	B-Material
.	O
	
For	O
the	O
other	O
two	O
datasets	O
,	O
our	O
PDC	B-Method
achieves	O
better	O
performance	O
than	O
Spindle	O
.	O
	
subsection	O
:	O
Evaluation	O
of	O
Feature	B-Method
Weighting	I-Method
sub	I-Method
-	I-Method
Net	I-Method
	
To	O
test	O
the	O
effectiveness	O
of	O
Feature	B-Method
Weighting	I-Method
sub	I-Method
-	I-Method
Net	I-Method
(	O
FWN	B-Method
)	O
,	O
we	O
verify	O
the	O
performance	O
of	O
five	O
variants	O
of	O
FWN	B-Method
,	O
which	O
are	O
denoted	O
as	O
,	O
=	O
{	O
0	O
,	O
1	O
,	O
2	O
,	O
3	O
,	O
4	O
}	O
,	O
where	O
is	O
the	O
number	O
of	O
Weight	O
Layers	O
in	O
FWN	B-Method
with	O
nonlinear	B-Method
transformation	I-Method
.	O
	
For	O
example	O
,	O
means	O
we	O
cascade	O
two	O
Weight	B-Method
Layers	I-Method
with	O
nonlinear	B-Method
transformation	I-Method
,	O
means	O
we	O
only	O
have	O
one	O
Weight	B-Method
Layer	I-Method
without	O
nonlinear	B-Method
transformation	I-Method
.	O
	
The	O
experimental	O
results	O
are	O
shown	O
in	O
Table	O
[	O
reference	O
]	O
.	O
	
As	O
we	O
can	O
see	O
that	O
one	O
Weight	B-Method
Layer	I-Method
with	O
nonlinear	B-Method
transformation	I-Method
gets	O
the	O
best	O
performance	O
on	O
the	O
three	O
datasets	O
.	O
	
The	O
ReID	B-Metric
performance	I-Metric
starts	O
to	O
drop	O
as	O
we	O
increase	O
of	O
the	O
number	O
of	O
Weight	O
Layers	O
,	O
despite	O
more	O
computations	O
are	O
being	O
brought	O
in	O
.	O
	
It	O
also	O
can	O
be	O
observed	O
that	O
,	O
using	O
one	B-Method
layer	I-Method
with	O
nonlinear	B-Method
transformation	I-Method
gets	O
better	O
performance	O
than	O
one	O
layer	O
without	O
nonlinear	B-Method
transformation	I-Method
,	O
,	O
.	O
	
This	O
means	O
adding	O
one	O
nonlinear	O
transformation	O
after	O
a	O
Weight	B-Method
Layer	I-Method
learns	O
more	O
reliable	O
weights	O
for	O
feature	B-Task
fusion	I-Task
and	I-Task
matching	I-Task
.	O
	
Based	O
on	O
the	O
above	O
observations	O
,	O
we	O
adopt	O
as	O
our	O
final	O
model	O
in	O
this	O
paper	O
.	O
	
Examples	O
of	O
features	O
before	O
and	O
after	O
FWN	B-Method
are	O
shown	O
Fig	O
.	O
	
[	O
reference	O
]	O
.	O
	
section	O
:	O
Conclusions	O
	
This	O
paper	O
presents	O
a	O
pose	B-Method
-	I-Method
driven	I-Method
deep	I-Method
convolutional	I-Method
model	I-Method
for	O
the	O
person	O
ReID	B-Task
.	O
	
The	O
proposed	O
deep	B-Method
architecture	I-Method
explicitly	O
leverages	O
the	O
human	O
part	O
cues	O
to	O
learn	O
effective	O
feature	B-Method
representations	I-Method
and	O
adaptive	O
similarity	O
measurements	O
.	O
	
For	O
the	O
feature	B-Method
representations	I-Method
,	O
both	O
global	O
human	O
body	O
and	O
local	O
body	O
parts	O
are	O
transformed	O
to	O
a	O
normalized	O
and	O
homologous	O
state	O
for	O
better	O
feature	B-Method
embedding	I-Method
.	O
	
For	O
similarity	B-Task
measurements	I-Task
,	O
weights	O
of	O
feature	B-Method
representations	I-Method
from	O
human	O
body	O
and	O
different	O
body	O
parts	O
are	O
learned	O
to	O
adaptively	O
chase	O
a	O
more	O
discriminative	B-Method
feature	I-Method
fusion	I-Method
.	O
	
Experimental	O
results	O
on	O
three	O
benchmark	O
datasets	O
demonstrate	O
the	O
superiority	O
of	O
the	O
proposed	O
model	O
over	O
current	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
methods	O
.	O
	
Acknowledgments	O
	
This	O
work	O
is	O
partly	O
supported	O
by	O
National	O
Science	O
Foundation	O
of	O
China	O
under	O
Grant	O
No	O
.	O
61572050	O
,	O
91538111	O
,	O
61620106009	O
,	O
61429201	O
,	O
61672519	O
,	O
and	O
the	O
National	O
1000	O
Youth	O
Talents	O
Plan	O
.	O
	
Dr.	O
Qi	O
Tian	O
is	O
supported	O
by	O
ARO	O
grant	O
W911NF	O
-	O
15	O
-	O
1	O
-	O
0290	O
and	O
Faculty	O
Research	O
Gift	O
Awards	O
by	O
NEC	O
Laboratories	O
of	O
America	O
and	O
Blippar	O
.	O
	
bibliography	O
:	O
References	O
	
document	O
:	O
Distributed	B-Task
Prioritized	I-Task
Experience	I-Task
Replay	I-Task
	
We	O
propose	O
a	O
distributed	B-Method
architecture	I-Method
for	O
deep	B-Task
reinforcement	I-Task
learning	I-Task
at	O
scale	O
,	O
that	O
enables	O
agents	O
to	O
learn	O
effectively	O
from	O
orders	O
of	O
magnitude	O
more	O
data	O
than	O
previously	O
possible	O
.	O
	
The	O
algorithm	O
decouples	O
acting	O
from	O
learning	B-Task
:	O
the	O
actors	O
interact	O
with	O
their	O
own	O
instances	O
of	O
the	O
environment	O
by	O
selecting	O
actions	O
according	O
to	O
a	O
shared	B-Method
neural	I-Method
network	I-Method
,	O
and	O
accumulate	O
the	O
resulting	O
experience	O
in	O
a	O
shared	O
experience	O
replay	O
memory	O
;	O
the	O
learner	O
replays	O
samples	O
of	O
experience	O
and	O
updates	O
the	O
neural	B-Method
network	I-Method
.	O
	
The	O
architecture	O
relies	O
on	O
prioritized	B-Task
experience	I-Task
replay	I-Task
to	O
focus	O
only	O
on	O
the	O
most	O
significant	O
data	O
generated	O
by	O
the	O
actors	O
.	O
	
Our	O
architecture	O
substantially	O
improves	O
the	O
state	O
of	O
the	O
art	O
on	O
the	O
Arcade	B-Material
Learning	I-Material
Environment	I-Material
,	O
achieving	O
better	O
final	O
performance	O
in	O
a	O
fraction	O
of	O
the	O
wall	B-Metric
-	I-Metric
clock	I-Metric
training	I-Metric
time	I-Metric
.	O
	
section	O
:	O
Introduction	O
	
A	O
broad	O
trend	O
in	O
deep	B-Task
learning	I-Task
is	O
that	O
combining	O
more	O
computation	O
Dean:2012:LSD:2999134.2999271	O
with	O
more	O
powerful	O
models	O
DBLP	O
:	O
journals	O
/	O
corr	O
/	O
KaiserGSVPJU17	O
and	O
larger	O
datasets	O
imagenet_cvpr09	O
yields	O
more	O
impressive	O
results	O
.	O
	
It	O
is	O
reasonable	O
to	O
hope	O
that	O
a	O
similar	O
principle	O
holds	O
for	O
deep	B-Task
reinforcement	I-Task
learning	I-Task
.	O
	
There	O
are	O
a	O
growing	O
number	O
of	O
examples	O
to	O
justify	O
this	O
optimism	O
:	O
effective	O
use	O
of	O
greater	O
computational	O
resources	O
has	O
been	O
a	O
critical	O
factor	O
in	O
the	O
success	O
of	O
such	O
algorithms	O
as	O
Gorila	O
gorila	O
,	O
A3C	O
a3c	O
,	O
	
GPU	B-Method
Advantage	I-Method
Actor	I-Method
Critic	I-Method
ga3c	I-Method
,	O
	
Distributed	B-Method
PPO	I-Method
heess	I-Method
:	O
dppo	B-Method
and	O
AlphaGo	B-Method
alphago	I-Method
.	O
	
Deep	B-Method
learning	I-Method
frameworks	I-Method
such	O
as	O
TensorFlow	B-Method
tensorflow	I-Method
support	O
distributed	B-Task
training	I-Task
,	O
making	O
large	B-Task
scale	I-Task
machine	I-Task
learning	I-Task
systems	I-Task
easier	O
to	O
implement	O
and	O
deploy	O
.	O
	
Despite	O
this	O
,	O
much	O
current	O
research	O
in	O
deep	B-Task
reinforcement	I-Task
learning	I-Task
concerns	O
itself	O
with	O
improving	O
performance	O
within	O
the	O
computational	B-Metric
budget	I-Metric
of	O
a	O
single	O
machine	O
,	O
and	O
the	O
question	O
of	O
how	O
to	O
best	O
harness	O
more	O
resources	O
is	O
comparatively	O
underexplored	O
.	O
	
In	O
this	O
paper	O
we	O
describe	O
an	O
approach	O
to	O
scaling	O
up	O
deep	B-Method
reinforcement	I-Method
learning	I-Method
by	O
generating	O
more	O
data	O
and	O
selecting	O
from	O
it	O
in	O
a	O
prioritized	O
fashion	O
prioritized	O
-	O
replay	O
.	O
	
Standard	O
approaches	O
to	O
distributed	B-Task
training	I-Task
of	I-Task
neural	I-Task
networks	I-Task
focus	O
on	O
parallelizing	O
the	O
computation	B-Task
of	I-Task
gradients	I-Task
,	O
to	O
more	O
rapidly	O
optimize	O
the	O
parameters	O
Dean:2012:LSD:2999134.2999271	O
.	O
	
In	O
contrast	O
,	O
we	O
distribute	O
the	O
generation	B-Task
and	I-Task
selection	I-Task
of	I-Task
experience	I-Task
data	I-Task
,	O
and	O
find	O
that	O
this	O
alone	O
suffices	O
to	O
improve	O
results	O
.	O
	
This	O
is	O
complementary	O
to	O
distributing	B-Task
gradient	I-Task
computation	I-Task
,	O
and	O
the	O
two	O
approaches	O
can	O
be	O
combined	O
,	O
but	O
in	O
this	O
work	O
we	O
focus	O
purely	O
on	O
data	B-Task
-	I-Task
generation	I-Task
.	O
	
We	O
use	O
this	O
distributed	B-Method
architecture	I-Method
to	O
scale	O
up	O
variants	O
of	O
Deep	B-Method
Q	I-Method
-	I-Method
Networks	I-Method
(	O
DQN	B-Method
)	O
and	O
Deep	B-Method
Deterministic	I-Method
Policy	I-Method
Gradient	I-Method
(	O
DDPG	B-Method
)	O
,	O
and	O
we	O
evaluate	O
these	O
on	O
the	O
Arcade	B-Material
Learning	I-Material
Environment	I-Material
benchmark	I-Material
bellemare2013arcade	O
,	O
and	O
on	O
a	O
range	O
of	O
continuous	B-Task
control	I-Task
tasks	I-Task
.	O
	
Our	O
architecture	O
achieves	O
a	O
new	O
state	O
of	O
the	O
art	O
performance	O
on	O
Atari	B-Task
games	I-Task
,	O
using	O
a	O
fraction	O
of	O
the	O
wall	B-Metric
-	I-Metric
clock	I-Metric
time	I-Metric
compared	O
to	O
the	O
previous	O
state	O
of	O
the	O
art	O
,	O
and	O
without	O
per	B-Method
-	I-Method
game	I-Method
hyperparameter	I-Method
tuning	I-Method
.	O
	
We	O
empirically	O
investigate	O
the	O
scalability	O
of	O
our	O
framework	O
,	O
analysing	O
how	O
prioritization	B-Task
affects	O
performance	O
as	O
we	O
increase	O
the	O
number	O
of	O
data	O
-	O
generating	O
workers	O
.	O
	
Our	O
experiments	O
include	O
an	O
analysis	O
of	O
factors	O
such	O
as	O
the	O
replay	O
capacity	O
,	O
the	O
recency	O
of	O
the	O
experience	O
,	O
and	O
the	O
use	O
of	O
different	O
data	B-Method
-	I-Method
generating	I-Method
policies	I-Method
for	O
different	O
workers	O
.	O
	
Finally	O
,	O
we	O
discuss	O
implications	O
for	O
deep	B-Method
reinforcement	I-Method
learning	I-Method
agents	I-Method
that	O
may	O
apply	O
beyond	O
our	O
distributed	B-Method
framework	I-Method
.	O
	
section	O
:	O
Background	O
	
paragraph	O
:	O
Distributed	B-Method
Stochastic	I-Method
Gradient	I-Method
Descent	I-Method
	
Distributed	B-Method
stochastic	I-Method
gradient	I-Method
descent	I-Method
is	O
widely	O
used	O
in	O
supervised	B-Task
learning	I-Task
to	O
speed	O
up	O
training	B-Task
of	I-Task
deep	I-Task
neural	I-Task
networks	I-Task
,	O
by	O
parallelizing	O
the	O
computation	O
of	O
the	O
gradients	O
used	O
to	O
update	O
their	O
parameters	O
.	O
	
The	O
resulting	O
parameter	O
updates	O
may	O
be	O
applied	O
synchronously	O
krizhevsky2014one	O
or	O
asynchronously	O
Dean:2012:LSD:2999134.2999271	O
.	O
	
Both	O
approaches	O
have	O
proven	O
effective	O
and	O
are	O
an	O
increasingly	O
standard	O
part	O
of	O
the	O
deep	B-Method
learning	I-Method
toolbox	I-Method
.	O
	
Inspired	O
by	O
this	O
,	O
applied	O
distributed	B-Method
asynchronous	I-Method
parameter	I-Method
updates	I-Method
and	O
distributed	B-Method
data	I-Method
generation	I-Method
to	O
deep	B-Task
reinforcement	I-Task
learning	I-Task
.	O
	
Asynchronous	B-Task
parameter	I-Task
updates	I-Task
and	O
parallel	B-Task
data	I-Task
generation	I-Task
have	O
also	O
been	O
successfully	O
used	O
within	O
a	O
single	O
-	O
machine	O
,	O
in	O
a	O
multi	O
-	O
threaded	O
rather	O
than	O
a	O
distributed	O
context	O
a3c	O
.	O
	
GPU	B-Method
Asynchronous	I-Method
Actor	I-Method
-	I-Method
Critic	I-Method
	
[	O
GA3C;	O
][]	O
ga3c	O
and	O
	
Parallel	B-Method
Advantage	I-Method
Actor	I-Method
-	I-Method
Critic	I-Method
	
[	O
PAAC;	O
][]	O
paac	O
adapt	O
this	O
approach	O
to	O
make	O
efficient	O
use	O
of	O
GPUs	B-Method
.	O
	
paragraph	O
:	O
Distributed	B-Method
Importance	I-Method
Sampling	I-Method
	
A	O
complementary	O
family	O
of	O
techniques	O
for	O
speeding	B-Task
up	I-Task
training	I-Task
is	O
based	O
on	O
variance	B-Method
reduction	I-Method
by	O
means	O
of	O
importance	B-Method
sampling	I-Method
[	O
cf.	O
][]	O
hastings1970monte	O
.	O
	
This	O
has	O
been	O
shown	O
to	O
be	O
useful	O
in	O
the	O
context	O
of	O
neural	B-Task
networks	I-Task
Hinton2007	I-Task
-	I-Task
vs	I-Task
.	O
	
Sampling	O
non	O
-	O
uniformly	O
from	O
a	O
dataset	O
and	O
weighting	O
updates	O
according	O
to	O
the	O
sampling	O
probability	O
in	O
order	O
to	O
counteract	O
the	O
bias	O
thereby	O
introduced	O
can	O
increase	O
the	O
speed	O
of	O
convergence	B-Metric
by	O
reducing	O
the	O
variance	O
of	O
the	O
gradients	O
.	O
	
One	O
way	O
of	O
doing	O
this	O
is	O
to	O
select	O
samples	O
with	O
probability	O
proportional	O
to	O
the	O
norm	O
of	O
the	O
corresponding	O
gradients	O
.	O
	
In	O
supervised	B-Task
learning	I-Task
,	O
this	O
approach	O
has	O
been	O
successfully	O
extended	O
to	O
the	O
distributed	B-Task
setting	I-Task
alain2015variance	O
.	O
	
An	O
alternative	O
is	O
to	O
rank	O
samples	O
according	O
to	O
their	O
latest	O
known	O
loss	O
value	O
and	O
make	O
the	O
sampling	O
probability	O
a	O
function	O
of	O
the	O
rank	O
rather	O
than	O
of	O
the	O
loss	O
itself	O
loshchilov2015online	O
.	O
	
paragraph	O
:	O
Prioritized	B-Task
Experience	I-Task
Replay	I-Task
	
Experience	B-Method
replay	I-Method
experience	I-Method
-	I-Method
replay	I-Method
has	O
long	O
been	O
used	O
in	O
reinforcement	B-Method
learning	I-Method
to	O
improve	O
data	B-Task
efficiency	I-Task
.	O
	
It	O
is	O
particularly	O
useful	O
when	O
training	O
neural	B-Method
network	I-Method
function	I-Method
approximators	I-Method
with	O
stochastic	B-Method
gradient	I-Method
descent	I-Method
algorithms	I-Method
,	O
as	O
in	O
Neural	B-Method
Fitted	I-Method
Q	I-Method
-	I-Method
Iteration	I-Method
nfq	I-Method
and	O
Deep	B-Method
Q	I-Method
-	I-Method
Learning	I-Method
dqn	I-Method
.	O
	
Experience	B-Task
replay	I-Task
may	O
also	O
help	O
to	O
prevent	O
overfitting	O
by	O
allowing	O
the	O
agent	O
to	O
learn	O
from	O
data	O
generated	O
by	O
previous	O
versions	O
of	O
the	O
policy	O
.	O
	
Prioritized	B-Method
experience	I-Method
replay	I-Method
prioritized	I-Method
-	I-Method
replay	I-Method
extends	O
classic	O
prioritized	B-Method
sweeping	I-Method
ideas	O
prioritized	B-Method
-	I-Method
sweeping	I-Method
to	O
work	O
with	O
deep	B-Method
neural	I-Method
network	I-Method
function	I-Method
approximators	I-Method
.	O
	
The	O
approach	O
is	O
strongly	O
related	O
to	O
the	O
importance	B-Method
sampling	I-Method
techniques	I-Method
discussed	O
in	O
the	O
previous	O
section	O
,	O
but	O
using	O
a	O
more	O
general	O
class	O
of	O
biased	B-Method
sampling	I-Method
procedures	I-Method
that	O
focus	O
learning	O
on	O
the	O
most	O
‘	O
surprising	O
’	O
experiences	O
.	O
	
Biased	B-Method
sampling	I-Method
can	O
be	O
particularly	O
helpful	O
in	O
reinforcement	B-Task
learning	I-Task
,	O
since	O
the	O
reward	O
signal	O
may	O
be	O
sparse	O
and	O
the	O
data	O
distribution	O
depends	O
on	O
the	O
agent	B-Method
’s	I-Method
policy	I-Method
.	O
	
As	O
a	O
result	O
,	O
prioritized	B-Task
experience	I-Task
replay	I-Task
is	O
used	O
in	O
many	O
agents	O
,	O
such	O
as	O
Prioritized	O
Dueling	O
DQN	B-Method
dueling	O
,	O
UNREAL	B-Method
unreal	I-Method
,	O
DQfD	B-Method
dqfd	I-Method
,	O
and	O
Rainbow	B-Method
rainbow	I-Method
.	O
	
In	O
an	O
ablation	O
study	O
conducted	O
to	O
investigate	O
the	O
relative	O
importance	O
of	O
several	O
algorithmic	O
ingredients	O
rainbow	O
,	O
prioritization	O
was	O
found	O
to	O
be	O
the	O
most	O
important	O
ingredient	O
contributing	O
to	O
the	O
agent	O
	
’s	O
performance	O
.	O
	
section	O
:	O
Our	O
Contribution	O
:	O
Distributed	B-Task
Prioritized	I-Task
Experience	I-Task
Replay	I-Task
	
In	O
this	O
paper	O
we	O
extend	O
prioritized	B-Task
experience	I-Task
replay	I-Task
to	O
the	O
distributed	B-Task
setting	I-Task
and	O
show	O
that	O
this	O
is	O
a	O
highly	O
scalable	O
approach	O
to	O
deep	B-Task
reinforcement	I-Task
learning	I-Task
.	O
	
We	O
introduce	O
a	O
few	O
key	O
modifications	O
that	O
enable	O
this	O
scalability	O
,	O
and	O
we	O
refer	O
to	O
our	O
approach	O
as	O
Ape	B-Method
-	I-Method
X	I-Method
.	O
	
As	O
in	O
Gorila	O
gorila	O
,	O
we	O
decompose	O
the	O
standard	O
deep	B-Method
reinforcement	I-Method
learning	I-Method
algorithm	I-Method
into	O
two	O
parts	O
,	O
which	O
run	O
concurrently	O
with	O
no	O
high	O
-	O
level	O
synchronization	O
.	O
	
The	O
first	O
part	O
consists	O
of	O
stepping	O
through	O
an	O
environment	O
,	O
evaluating	O
a	O
policy	B-Method
implemented	O
as	O
a	O
deep	B-Method
neural	I-Method
network	I-Method
,	O
and	O
storing	O
the	O
observed	O
data	O
in	O
a	O
replay	O
memory	O
.	O
	
We	O
refer	O
to	O
this	O
as	O
acting	O
.	O
	
The	O
second	O
part	O
consists	O
of	O
sampling	O
batches	O
of	O
data	O
from	O
the	O
memory	O
to	O
update	O
the	O
policy	O
parameters	O
.	O
	
We	O
term	O
this	O
learning	O
.	O
	
[	O
width	O
=	O
trim=0pt	O
400pt	O
0pt	O
0pt	O
,	O
clip	O
]	O
images	O
/	O
apex_architecture.pdf	O
	
[	O
t	O
!	O
]	O
	
Actor	O
{	O
algorithmic}	O
[	O
1	O
]	O
T	O
agent	O
in	O
environment	O
instance	O
,	O
storing	O
experiences	O
.	O
	
call	O
to	O
obtain	O
latest	O
network	O
parameters	O
.	O
	
initial	O
state	O
from	O
environment	O
.	O
	
to	O
T	O
an	O
action	O
using	O
the	O
current	O
policy	O
.	O
	
the	O
action	O
in	O
the	O
environment	O
.	O
	
data	O
to	O
local	O
buffer	O
.	O
	
a	O
background	B-Method
thread	I-Method
,	O
periodically	O
send	O
data	O
to	O
replay	O
.	O
	
buffered	O
data	O
(	O
e.g.	O
batch	O
of	O
multi	O
-	O
step	O
transitions	O
)	O
.	O
	
priorities	O
for	O
experience	O
(	O
e.g.	O
absolute	B-Metric
TD	I-Metric
error	I-Metric
)	O
.	O
	
call	O
to	O
add	O
experience	O
to	O
replay	O
memory	O
.	O
	
latest	O
network	O
parameters	O
.	O
	
[	O
t	O
!	O
]	O
	
Learner	B-Method
{	O
algorithmic}	O
[	O
1	O
]	O
network	O
using	O
batches	O
sampled	O
from	O
memory	O
.	O
	
to	O
T	O
the	O
parameters	O
T	O
times	O
.	O
	
a	O
prioritized	O
batch	O
of	O
transitions	O
(	O
in	O
a	O
background	O
thread	O
)	O
.	O
	
learning	B-Method
rule	I-Method
;	O
e.g.	O
double	B-Method
Q	I-Method
-	I-Method
learning	I-Method
or	O
DDPG	B-Method
priorities	O
for	O
experience	O
,	O
(	O
e.g.	O
absolute	B-Metric
TD	I-Metric
error	I-Metric
)	O
.	O
	
call	O
to	O
update	O
priorities	O
.	O
	
old	O
experience	O
from	O
replay	O
memory	O
.	O
	
In	O
principle	O
,	O
both	O
acting	O
and	O
learning	B-Task
may	O
be	O
distributed	O
across	O
multiple	O
workers	O
.	O
	
In	O
our	O
experiments	O
,	O
hundreds	O
of	O
actors	O
run	O
on	O
CPUs	B-Method
to	O
generate	O
data	O
,	O
and	O
a	O
single	O
learner	B-Method
running	O
on	O
a	O
GPU	O
samples	O
the	O
most	O
useful	O
experiences	O
(	O
Figure	O
[	O
reference	O
]	O
)	O
.	O
	
Pseudocode	O
for	O
the	O
actors	O
and	O
learners	O
is	O
shown	O
in	O
Algorithms	O
[	O
reference	O
]	O
and	O
[	O
reference	O
]	O
.	O
	
Updated	O
network	O
parameters	O
are	O
periodically	O
communicated	O
to	O
the	O
actors	O
from	O
the	O
learner	O
.	O
	
In	O
contrast	O
to	O
gorila	B-Method
,	O
we	O
use	O
a	O
shared	O
,	O
centralized	O
replay	O
memory	O
,	O
and	O
instead	O
of	O
sampling	O
uniformly	O
,	O
we	O
prioritize	O
,	O
to	O
sample	O
the	O
most	O
useful	O
data	O
more	O
often	O
.	O
	
Since	O
priorities	O
are	O
shared	O
,	O
high	O
priority	O
data	O
discovered	O
by	O
any	O
actor	O
can	O
benefit	O
the	O
whole	O
system	O
.	O
	
Priorities	O
can	O
be	O
defined	O
in	O
various	O
ways	O
,	O
depending	O
on	O
the	O
learning	B-Method
algorithm	I-Method
;	O
two	O
instances	O
are	O
described	O
in	O
the	O
next	O
sections	O
.	O
	
In	O
Prioritized	O
DQN	B-Method
prioritized	O
-	O
replay	O
priorities	O
for	O
new	O
transitions	O
were	O
initialized	O
to	O
the	O
maximum	O
priority	O
seen	O
so	O
far	O
,	O
and	O
only	O
updated	O
once	O
they	O
were	O
sampled	O
.	O
	
This	O
does	O
not	O
scale	O
well	O
:	O
due	O
to	O
the	O
large	O
number	O
of	O
actors	O
in	O
our	O
architecture	O
,	O
waiting	O
for	O
the	O
learner	O
to	O
update	O
priorities	O
would	O
result	O
in	O
a	O
myopic	O
focus	O
on	O
the	O
most	O
recent	O
data	O
,	O
which	O
has	O
maximum	O
priority	O
by	O
construction	O
.	O
	
Instead	O
,	O
we	O
take	O
advantage	O
of	O
the	O
computation	O
the	O
actors	O
in	O
Ape	B-Method
-	I-Method
X	I-Method
are	O
already	O
doing	O
to	O
evaluate	O
their	O
local	O
copies	O
of	O
the	O
policy	O
,	O
by	O
making	O
them	O
also	O
compute	O
suitable	O
priorities	O
for	O
new	O
transitions	O
online	O
.	O
	
This	O
ensures	O
that	O
data	O
entering	O
the	O
replay	O
has	O
more	O
accurate	O
priorities	O
,	O
at	O
no	O
extra	O
cost	O
.	O
	
Sharing	O
experiences	O
has	O
certain	O
advantages	O
compared	O
to	O
sharing	O
gradients	O
.	O
	
Low	B-Task
latency	I-Task
communication	I-Task
is	O
not	O
as	O
important	O
as	O
in	O
distributed	B-Method
SGD	I-Method
,	O
because	O
experience	O
data	O
becomes	O
outdated	O
less	O
rapidly	O
than	O
gradients	O
,	O
provided	O
the	O
learning	B-Method
algorithm	I-Method
is	O
robust	O
to	O
off	O
-	O
policy	O
data	O
.	O
	
Across	O
the	O
system	O
,	O
we	O
take	O
advantage	O
of	O
this	O
by	O
batching	O
all	O
communications	O
with	O
the	O
centralized	B-Method
replay	I-Method
,	O
increasing	O
the	O
efficiency	O
and	O
throughput	B-Metric
at	O
the	O
cost	O
of	O
some	O
latency	O
.	O
	
With	O
this	O
approach	O
it	O
is	O
even	O
possible	O
for	O
actors	O
and	O
learners	O
to	O
run	O
in	O
different	O
data	O
-	O
centers	O
without	O
limiting	O
performance	O
.	O
	
Finally	O
,	O
by	O
learning	O
off	B-Method
-	I-Method
policy	I-Method
	
[	O
cf.	O
][]	O
SuttonBarto:1998	O
,	O
SuttonBarto:2017	O
,	O
we	O
can	O
further	O
take	O
advantage	O
of	O
Ape	B-Method
-	I-Method
X	I-Method
’s	O
ability	O
to	O
combine	O
data	O
from	O
many	O
distributed	O
actors	O
,	O
by	O
giving	O
the	O
different	O
actors	O
different	O
exploration	O
policies	O
,	O
broadening	O
the	O
diversity	O
of	O
the	O
experience	O
they	O
jointly	O
encounter	O
.	O
	
As	O
we	O
will	O
see	O
in	O
the	O
results	O
,	O
this	O
can	O
be	O
sufficient	O
to	O
make	O
progress	O
on	O
difficult	O
exploration	B-Task
problems	I-Task
.	O
	
subsection	O
:	O
Ape	B-Method
-	I-Method
X	I-Method
DQN	I-Method
	
The	O
general	O
framework	O
we	O
have	O
described	O
may	O
be	O
combined	O
with	O
different	O
learning	B-Method
algorithms	I-Method
.	O
	
First	O
,	O
we	O
combined	O
it	O
with	O
a	O
variant	O
of	O
DQN	B-Method
dqn	O
with	O
some	O
of	O
the	O
components	O
of	O
Rainbow	B-Method
rainbow	I-Method
.	O
	
More	O
specifically	O
,	O
we	O
used	O
double	B-Method
Q	I-Method
-	I-Method
learning	I-Method
doubleq	I-Method
,	O
deepdoubleqlearning	B-Method
with	O
multi	O
-	O
step	O
bootstrap	O
targets	O
[	O
cf.	O
][]	O
Sutton:1988	O
,	O
SuttonBarto:1998	O
,	O
SuttonBarto:2017	O
,	O
a3c	O
as	O
the	O
learning	B-Method
algorithm	I-Method
,	O
and	O
a	O
dueling	B-Method
network	I-Method
architecture	I-Method
dueling	O
as	O
the	O
function	B-Method
approximator	I-Method
.	O
	
This	O
results	O
in	O
computing	O
for	O
all	O
elements	O
in	O
the	O
batch	O
the	O
loss	O
with	O
where	O
is	O
a	O
time	O
index	O
for	O
an	O
experience	O
sampled	O
from	O
the	O
replay	O
starting	O
with	O
state	O
and	O
action	O
,	O
and	O
denotes	O
parameters	O
of	O
the	O
target	O
network	B-Method
dqn	I-Method
,	O
a	O
slow	O
moving	O
copy	O
of	O
the	O
online	O
parameters	O
.	O
	
Multi	O
-	O
step	O
returns	O
are	O
truncated	O
if	O
the	O
episode	O
ends	O
in	O
fewer	O
than	O
steps	O
.	O
	
In	O
principle	O
,	O
Q	B-Method
-	I-Method
learning	I-Method
variants	I-Method
are	O
off	B-Method
-	I-Method
policy	I-Method
methods	I-Method
,	O
so	O
we	O
are	O
free	O
to	O
choose	O
the	O
policies	O
we	O
use	O
to	O
generate	O
data	O
.	O
	
However	O
,	O
in	O
practice	O
,	O
the	O
choice	O
of	O
behaviour	B-Method
policy	I-Method
does	O
affect	O
both	O
exploration	B-Task
and	O
the	O
quality	O
of	O
function	B-Method
approximation	I-Method
.	O
	
Furthermore	O
,	O
we	O
are	O
using	O
a	O
multi	B-Method
-	I-Method
step	I-Method
return	I-Method
with	O
no	O
off	B-Method
-	I-Method
policy	I-Method
correction	I-Method
,	O
which	O
in	O
theory	O
could	O
adversely	O
affect	O
the	O
value	B-Task
estimation	I-Task
.	O
	
Nonetheless	O
,	O
in	O
Ape	B-Method
-	I-Method
X	I-Method
DQN	I-Method
,	O
each	O
actor	O
executes	O
a	O
different	O
policy	O
,	O
and	O
this	O
allows	O
experience	O
to	O
be	O
generated	O
from	O
a	O
variety	O
of	O
strategies	O
,	O
relying	O
on	O
the	O
prioritization	B-Method
mechanism	I-Method
to	O
pick	O
out	O
the	O
most	O
effective	O
experiences	O
.	O
	
In	O
our	O
experiments	O
,	O
the	O
actors	O
use	O
-	B-Method
greedy	I-Method
policies	I-Method
with	O
different	O
values	O
of	O
.	O
	
Low	O
policies	O
allow	O
exploring	O
deeper	O
in	O
the	O
environment	O
,	O
while	O
high	O
policies	O
prevent	O
over	O
-	O
specialization	O
.	O
	
subsection	O
:	O
Ape	B-Method
-	I-Method
X	I-Method
DPG	I-Method
	
To	O
test	O
the	O
generality	O
of	O
the	O
framework	O
we	O
also	O
combined	O
it	O
with	O
a	O
continuous	B-Method
-	I-Method
action	I-Method
policy	I-Method
gradient	I-Method
system	I-Method
based	O
on	O
DDPG	B-Method
ddpg	O
,	O
an	O
implementation	O
of	O
deterministic	B-Method
policy	I-Method
gradients	I-Method
also	O
similar	O
to	O
older	O
methods	O
adhdp	B-Method
,	O
acd	B-Method
,	O
and	O
tested	O
it	O
on	O
continuous	B-Task
control	I-Task
tasks	I-Task
from	O
the	O
DeepMind	B-Material
Control	I-Material
Suite	I-Material
tassa2018suite	O
.	O
	
The	O
Ape	B-Method
-	I-Method
X	I-Method
DPG	I-Method
setup	O
is	O
similar	O
to	O
Ape	B-Method
-	I-Method
X	I-Method
DQN	I-Method
,	O
but	O
the	O
actor	B-Method
’s	I-Method
policy	I-Method
is	O
now	O
represented	O
explicitly	O
by	O
a	O
separate	O
policy	B-Method
network	I-Method
,	O
in	O
addition	O
to	O
the	O
Q	B-Method
-	I-Method
network	I-Method
.	O
	
The	O
two	O
networks	O
are	O
optimized	O
separately	O
,	O
by	O
minimizing	O
different	O
losses	O
on	O
the	O
sampled	O
experience	O
.	O
	
We	O
denote	O
the	O
policy	O
and	O
Q	O
-	O
network	O
parameters	O
by	O
and	O
respectively	O
,	O
and	O
adopt	O
the	O
same	O
convention	O
as	O
above	O
to	O
denote	O
target	O
networks	O
.	O
	
The	O
Q	B-Method
-	I-Method
network	I-Method
outputs	O
an	O
action	B-Method
-	I-Method
value	I-Method
estimate	I-Method
for	O
a	O
given	O
state	O
,	O
and	O
multi	O
-	O
dimensional	O
action	O
.	O
	
It	O
is	O
updated	O
using	O
temporal	B-Method
-	I-Method
difference	I-Method
learning	I-Method
with	O
a	O
multi	O
-	O
step	O
bootstrap	O
target	O
.	O
	
The	O
Q	B-Method
-	I-Method
network	I-Method
loss	I-Method
can	O
be	O
written	O
as	O
,	O
where	O
The	O
policy	B-Method
network	I-Method
outputs	O
an	O
action	O
.	O
	
The	O
policy	O
parameters	O
are	O
updated	O
using	O
policy	B-Method
gradient	I-Method
ascent	I-Method
on	O
the	O
estimated	O
Q	O
-	O
value	O
,	O
using	O
gradient	O
—	O
note	O
that	O
this	O
depends	O
on	O
the	O
policy	O
parameters	O
only	O
through	O
the	O
action	O
that	O
is	O
input	O
to	O
the	O
critic	B-Method
network	I-Method
.	O
	
Further	O
details	O
of	O
the	O
Ape	B-Method
-	I-Method
X	I-Method
DPG	I-Method
algorithm	O
are	O
available	O
in	O
the	O
appendix	O
.	O
	
section	O
:	O
Experiments	O
	
subsection	O
:	O
Atari	B-Task
	
[	O
width=	O
]	O
images	O
/	O
	
apex_iclr_aggregate_scatter_jan_04	O
[	O
width=	O
]	O
images	O
/	O
	
apex_iclr_selected_levels_jan_04	O
	
In	O
our	O
first	O
set	O
of	O
experiments	O
we	O
evaluate	O
Ape	B-Method
-	I-Method
X	I-Method
DQN	I-Method
on	O
Atari	B-Task
,	O
and	O
show	O
state	O
of	O
the	O
art	O
results	O
on	O
this	O
standard	O
reinforcement	B-Task
learning	I-Task
benchmark	I-Task
.	O
	
We	O
use	O
360	O
actor	B-Method
machines	I-Method
(	O
each	O
using	O
one	O
CPU	O
core	O
)	O
to	O
feed	O
data	O
into	O
the	O
replay	O
memory	O
as	O
fast	O
as	O
they	O
can	O
generate	O
it	O
;	O
approximately	O
139	O
frames	O
per	O
second	O
(	O
FPS	O
)	O
each	O
,	O
for	O
a	O
total	O
of	O
50	O
K	O
FPS	O
,	O
which	O
corresponds	O
to	O
12.5	O
K	O
transitions	O
(	O
because	O
of	O
a	O
fixed	O
action	O
repeat	O
of	O
4	O
)	O
.	O
	
The	O
actors	O
batch	O
experience	O
data	O
locally	O
before	O
sending	O
it	O
to	O
the	O
replay	O
:	O
up	O
to	O
100	O
transitions	O
may	O
be	O
buffered	O
at	O
a	O
time	O
,	O
which	O
are	O
then	O
sent	O
asynchronously	O
in	O
batches	O
of	O
.	O
	
The	O
learner	O
asynchronously	O
prefetches	O
up	O
to	O
16	O
batches	O
of	O
512	O
transitions	O
,	O
and	O
computes	O
updates	O
for	O
19	O
such	O
batches	O
each	O
second	O
,	O
meaning	O
that	O
gradients	O
are	O
computed	O
for	O
9.7	O
K	O
transitions	O
per	O
second	O
on	O
average	O
.	O
	
To	O
reduce	O
memory	O
and	O
bandwidth	O
requirements	O
,	O
observation	O
data	O
is	O
compressed	O
using	O
a	O
PNG	B-Method
codec	I-Method
when	O
sent	O
and	O
when	O
stored	O
in	O
the	O
replay	O
.	O
	
The	O
learner	O
decompresses	O
data	O
as	O
it	O
prefetches	O
it	O
,	O
in	O
parallel	O
with	O
computing	O
and	O
applying	O
gradients	O
.	O
	
The	O
learner	O
also	O
asynchronously	O
handles	O
any	O
requests	O
for	O
parameters	O
from	O
actors	O
.	O
	
Actors	O
copy	O
the	O
network	O
parameters	O
from	O
the	O
learner	O
every	O
400	O
frames	O
(	O
2.8	O
seconds	O
)	O
.	O
	
Each	O
actor	O
executes	O
an	O
-	B-Method
greedy	I-Method
policy	I-Method
where	O
with	O
,	O
.	O
	
Each	O
is	O
held	O
constant	O
throughout	O
training	O
.	O
	
The	O
episode	O
length	O
is	O
limited	O
to	O
50000	O
frames	O
during	O
training	O
.	O
	
The	O
capacity	O
of	O
the	O
shared	B-Method
experience	I-Method
replay	I-Method
memory	I-Method
is	O
soft	O
-	O
limited	O
to	O
2	O
million	O
transitions	O
:	O
adding	O
new	O
data	O
is	O
always	O
permitted	O
,	O
to	O
not	O
slow	O
down	O
the	O
actors	O
,	O
but	O
every	O
100	O
learning	O
steps	O
any	O
excess	O
data	O
above	O
this	O
capacity	O
threshold	O
is	O
removed	O
en	O
masse	O
,	O
in	O
FIFO	O
order	O
.	O
	
The	O
median	O
actual	O
size	O
of	O
the	O
memory	O
is	O
2035050	O
.	O
	
Data	O
is	O
sampled	O
according	O
to	O
proportional	O
prioritization	O
,	O
with	O
a	O
priority	O
exponent	O
of	O
0.6	O
and	O
an	O
importance	O
sampling	O
exponent	O
set	O
to	O
0.4	O
.	O
	
In	O
Figure	O
[	O
reference	O
]	O
,	O
on	O
the	O
left	O
,	O
we	O
compare	O
the	O
median	O
human	B-Metric
normalized	I-Metric
score	I-Metric
across	O
all	O
57	O
games	O
to	O
several	O
baselines	O
:	O
	
DQN	B-Method
,	O
Prioritized	O
DQN	B-Method
,	O
Distributional	O
DQN	B-Method
distributional	O
,	O
Rainbow	B-Method
,	O
and	O
Gorila	B-Method
.	O
	
In	O
all	O
cases	O
the	O
performance	O
is	O
measured	O
at	O
the	O
end	O
of	O
training	O
under	O
the	O
no	B-Method
-	I-Method
op	I-Method
starts	I-Method
testing	I-Method
regime	I-Method
dqn	I-Method
.	O
	
On	O
the	O
right	O
,	O
we	O
show	O
initial	O
learning	O
curves	O
(	O
taken	O
from	O
the	O
greediest	B-Method
actor	I-Method
)	O
for	O
a	O
selection	O
of	O
6	O
games	O
(	O
full	O
learning	O
curves	O
for	O
all	O
games	O
are	O
in	O
the	O
appendix	O
)	O
.	O
	
Given	O
that	O
Ape	B-Method
-	I-Method
X	I-Method
can	O
harness	O
substantially	O
more	O
computation	O
than	O
most	O
baselines	O
,	O
one	O
might	O
expect	O
it	O
to	O
train	O
faster	O
.	O
	
Figure	O
[	O
reference	O
]	O
shows	O
that	O
this	O
was	O
indeed	O
the	O
case	O
.	O
	
Perhaps	O
more	O
surprisingly	O
,	O
our	O
agent	O
achieved	O
a	O
substantially	O
higher	O
final	O
performance	O
.	O
	
In	O
Table	O
[	O
reference	O
]	O
we	O
compare	O
the	O
median	B-Metric
human	I-Metric
-	I-Metric
normalized	I-Metric
performance	I-Metric
of	O
Ape	B-Method
-	I-Method
X	I-Method
DQN	I-Method
on	O
the	O
Atari	B-Task
benchmark	O
to	O
corresponding	O
metrics	O
as	O
reported	O
for	O
other	O
baseline	O
agents	O
in	O
their	O
respective	O
publications	O
.	O
	
Whenever	O
available	O
we	O
report	O
results	O
both	O
for	O
no	B-Task
-	I-Task
op	I-Task
starts	I-Task
and	O
for	O
human	B-Task
starts	I-Task
.	O
	
The	O
human	B-Method
-	I-Method
starts	I-Method
regime	I-Method
gorila	I-Method
corresponds	O
to	O
a	O
more	O
challenging	O
generalization	B-Task
test	I-Task
,	O
as	O
the	O
agent	O
is	O
initialized	O
from	O
random	O
starts	O
drawn	O
from	O
games	O
played	O
by	O
human	O
experts	O
.	O
	
Ape	B-Method
-	I-Method
X	I-Method
’s	O
performance	O
is	O
higher	O
than	O
the	O
performance	O
of	O
any	O
of	O
the	O
baselines	O
according	O
to	O
both	O
metrics	O
.	O
	
subsection	O
:	O
Continuous	B-Method
Control	I-Method
	
In	O
a	O
second	O
set	O
of	O
experiments	O
we	O
evaluated	O
Ape	B-Method
-	I-Method
X	I-Method
DPG	I-Method
on	O
four	O
continuous	B-Task
control	I-Task
tasks	I-Task
.	O
	
In	O
the	O
manipulator	B-Task
domain	I-Task
the	O
agent	O
must	O
learn	O
to	O
bring	O
a	O
ball	O
to	O
a	O
specified	O
location	O
.	O
	
In	O
the	O
humanoid	B-Task
domain	I-Task
the	O
agent	O
must	O
learn	O
to	O
control	O
a	O
humanoid	O
body	O
to	O
solve	O
three	O
distinct	O
tasks	O
of	O
increasing	O
complexity	O
:	O
Standing	O
,	O
Walking	B-Task
and	O
Running	B-Task
.	O
	
Since	O
here	O
we	O
learn	O
from	O
features	O
,	O
rather	O
than	O
from	O
pixels	O
,	O
the	O
observation	O
space	O
is	O
much	O
smaller	O
than	O
it	O
is	O
in	O
the	O
Atari	B-Task
domain	O
.	O
	
We	O
therefore	O
use	O
small	O
,	O
fully	O
-	O
connected	O
networks	O
(	O
details	O
in	O
the	O
appendix	O
)	O
.	O
	
With	O
64	O
actors	O
on	O
this	O
domain	O
,	O
we	O
obtain	O
14	O
K	O
total	O
FPS	O
(	O
the	O
same	O
number	O
of	O
transitions	O
per	O
second	O
;	O
here	O
we	O
do	O
not	O
use	O
action	O
repeats	O
)	O
.	O
	
We	O
process	O
86	O
batches	O
of	O
256	O
transitions	O
per	O
second	O
,	O
or	O
22	O
K	O
transitions	O
processed	O
per	O
second	O
.	O
	
Figure	O
[	O
reference	O
]	O
shows	O
that	O
Ape	B-Method
-	I-Method
X	I-Method
DPG	I-Method
achieved	O
very	O
good	O
performance	O
on	O
all	O
four	O
tasks	O
.	O
	
The	O
figure	O
shows	O
the	O
performance	O
of	O
Ape	B-Method
-	I-Method
X	I-Method
DPG	I-Method
for	O
different	O
numbers	O
of	O
actors	O
:	O
as	O
the	O
number	O
of	O
actors	O
increases	O
our	O
agent	O
becomes	O
increasingly	O
effective	O
at	O
solving	O
these	O
problems	O
rapidly	O
and	O
reliably	O
,	O
outperforming	O
a	O
standard	O
DDPG	B-Method
baseline	O
trained	O
for	O
over	O
10	O
times	O
longer	O
.	O
	
A	O
parallel	O
paper	O
d4pg	O
builds	O
on	O
this	O
work	O
by	O
combining	O
Ape	B-Method
-	I-Method
X	I-Method
DPG	I-Method
with	O
distributional	B-Method
value	I-Method
functions	I-Method
,	O
and	O
the	O
resulting	O
algorithm	O
is	O
successfully	O
applied	O
to	O
further	O
continuous	B-Task
control	I-Task
tasks	I-Task
.	O
	
[	O
width=0.8clip	O
]	O
images	O
/	O
apex_iclr_continuous_control	O
	
section	O
:	O
Analysis	O
	
[	O
width=0.85trim=0pt	O
0	O
0pt	O
40pt	O
,	O
clip	O
]	O
images	O
	
/	O
	
apex_iclr_num_actors_prioritized_only	O
	
In	O
this	O
section	O
we	O
describe	O
additional	O
Ape	B-Method
-	I-Method
X	I-Method
DQN	I-Method
experiments	O
on	O
Atari	B-Task
that	O
helped	O
improve	O
our	O
understanding	O
of	O
the	O
framework	O
,	O
and	O
we	O
investigate	O
the	O
contribution	O
of	O
different	O
components	O
.	O
	
First	O
,	O
we	O
investigated	O
how	O
the	O
performance	O
scales	O
with	O
the	O
number	O
of	O
actors	O
.	O
	
We	O
trained	O
our	O
agent	O
with	O
different	O
numbers	O
of	O
actors	O
(	O
8	O
,	O
16	O
,	O
32	O
,	O
64	O
,	O
128	O
and	O
256	O
)	O
for	O
35	O
hours	O
on	O
a	O
subset	O
of	O
6	O
Atari	B-Task
games	I-Task
.	O
	
In	O
all	O
experiments	O
we	O
kept	O
the	O
size	O
of	O
the	O
shared	O
experience	O
replay	O
memory	O
fixed	O
at	O
1	O
million	O
transitions	O
.	O
	
Figure	O
[	O
reference	O
]	O
shows	O
that	O
the	O
performance	O
consistently	O
improved	O
as	O
the	O
number	O
of	O
actors	O
increased	O
.	O
	
The	O
appendix	O
contains	O
learning	O
curves	O
for	O
additional	O
games	O
,	O
and	O
a	O
comparison	O
of	O
the	O
scalability	O
of	O
the	O
algorithm	O
with	O
and	O
without	O
prioritized	B-Method
replay	I-Method
.	O
	
It	O
is	O
perhaps	O
surprising	O
that	O
performance	O
improved	O
so	O
substantially	O
purely	O
by	O
increasing	O
the	O
number	O
of	O
actors	O
,	O
without	O
changing	O
the	O
rate	O
at	O
which	O
the	O
network	O
parameters	O
are	O
updated	O
,	O
the	O
structure	O
of	O
the	O
network	O
,	O
or	O
the	O
update	B-Method
rule	I-Method
.	O
	
We	O
hypothesize	O
that	O
the	O
proposed	O
architecture	O
helps	O
with	O
a	O
common	O
deep	B-Task
reinforcement	I-Task
learning	I-Task
failure	I-Task
mode	I-Task
,	O
in	O
which	O
the	O
policy	O
discovered	O
is	O
a	O
local	O
optimum	O
in	O
the	O
parameter	O
space	O
,	O
but	O
not	O
a	O
global	O
one	O
,	O
e.g.	O
,	O
due	O
to	O
insufficient	O
exploration	O
.	O
	
Using	O
a	O
large	O
number	O
of	O
actors	O
with	O
varying	O
amounts	O
of	O
exploration	O
helps	O
to	O
discover	O
promising	O
new	O
courses	O
of	O
action	O
,	O
and	O
prioritized	O
replay	O
ensures	O
that	O
when	O
this	O
happens	O
,	O
the	O
learning	B-Method
algorithm	I-Method
focuses	O
its	O
efforts	O
on	O
this	O
important	O
information	O
.	O
	
Next	O
,	O
we	O
investigated	O
varying	O
the	O
capacity	O
of	O
the	O
replay	O
memory	O
(	O
see	O
Figure	O
[	O
reference	O
]	O
)	O
.	O
	
We	O
used	O
a	O
setup	O
with	O
256	O
actors	O
,	O
for	O
a	O
median	O
of	O
37	O
K	O
total	O
environment	O
frames	O
per	O
second	O
(	O
approximately	O
9	O
K	O
transitions	O
)	O
.	O
	
With	O
such	O
a	O
large	O
number	O
of	O
actors	O
,	O
the	O
contents	O
of	O
the	O
memory	O
is	O
replaced	O
much	O
faster	O
than	O
in	O
most	O
DQN	B-Method
-	O
like	O
agents	O
.	O
	
We	O
observed	O
a	O
small	O
benefit	O
to	O
using	O
a	O
larger	O
replay	O
capacity	O
.	O
	
We	O
hypothesize	O
this	O
is	O
due	O
to	O
the	O
value	O
of	O
keeping	O
some	O
high	O
priority	O
experiences	O
around	O
for	O
longer	O
and	O
replaying	O
them	O
.	O
	
As	O
above	O
,	O
a	O
single	O
learner	B-Method
machine	I-Method
trained	O
the	O
network	O
with	O
median	O
19	O
batches	O
per	O
second	O
,	O
each	O
of	O
512	O
transitions	O
,	O
for	O
a	O
median	O
of	O
9.7	O
K	O
transitions	O
processed	O
per	O
second	O
.	O
	
[	O
width	O
=	O
trim=0pt	O
0	O
	
0pt	O
40pt	O
,	O
clip	O
]	O
images	O
/	O
	
apex_iclr_vary_replay_size.pdf	B-Method
Finally	O
,	O
we	O
ran	O
additional	O
experiments	O
to	O
disentangle	O
potential	O
effects	O
of	O
two	O
confounding	O
factors	O
in	O
our	O
scalability	B-Task
analysis	I-Task
:	O
recency	O
of	O
the	O
experience	O
data	O
in	O
the	O
replay	O
memory	O
,	O
and	O
diversity	O
of	O
the	O
data	B-Method
-	I-Method
generating	I-Method
policies	I-Method
.	O
	
The	O
full	O
description	O
of	O
these	O
experiments	O
is	O
confined	O
to	O
the	O
appendix	O
;	O
to	O
summarize	O
,	O
neither	O
factor	O
alone	O
is	O
sufficient	O
to	O
explain	O
the	O
performance	O
we	O
see	O
.	O
	
We	O
therefore	O
conclude	O
that	O
the	O
results	O
are	O
due	O
substantially	O
to	O
the	O
positive	O
effects	O
of	O
gathering	O
more	O
experience	O
data	O
;	O
namely	O
better	O
exploration	O
of	O
the	O
environment	O
and	O
better	O
avoidance	O
of	O
overfitting	O
.	O
	
section	O
:	O
Conclusion	O
	
We	O
have	O
designed	O
,	O
implemented	O
,	O
and	O
analyzed	O
a	O
distributed	B-Method
framework	I-Method
for	O
prioritized	B-Task
replay	I-Task
in	O
deep	B-Task
reinforcement	I-Task
learning	I-Task
.	O
	
This	O
architecture	O
achieved	O
state	O
of	O
the	O
art	O
results	O
in	O
a	O
wide	O
range	O
of	O
discrete	B-Task
and	I-Task
continuous	I-Task
tasks	I-Task
,	O
both	O
in	O
terms	O
of	O
wall	B-Metric
-	I-Metric
clock	I-Metric
learning	I-Metric
speed	I-Metric
and	O
final	O
performance	O
.	O
	
In	O
this	O
paper	O
we	O
focused	O
on	O
applying	O
the	O
Ape	B-Method
-	I-Method
X	I-Method
framework	O
to	O
DQN	B-Method
and	O
DPG	B-Method
,	O
but	O
it	O
could	O
also	O
be	O
combined	O
with	O
any	O
other	O
off	B-Method
-	I-Method
policy	I-Method
reinforcement	I-Method
learning	I-Method
update	I-Method
.	O
	
For	O
methods	O
that	O
use	O
temporally	O
extended	O
sequences	O
[	O
e.g.	O
,	O
]	O
[	O
]	O
a3c	O
,	O
acer	B-Method
,	O
the	O
Ape	B-Method
-	I-Method
X	I-Method
framework	O
may	O
be	O
adapted	O
to	O
prioritize	O
sequences	O
of	O
past	O
experiences	O
instead	O
of	O
individual	O
transitions	O
.	O
	
Ape	B-Method
-	I-Method
X	I-Method
is	O
designed	O
for	O
regimes	O
in	O
which	O
it	O
is	O
possible	O
to	O
generate	O
large	O
quantities	O
of	O
data	O
in	O
parallel	O
.	O
	
This	O
includes	O
simulated	O
environments	O
but	O
also	O
a	O
variety	O
of	O
real	B-Task
-	I-Task
world	I-Task
applications	I-Task
,	O
such	O
as	O
robotic	B-Task
arm	I-Task
farms	I-Task
,	O
self	B-Task
-	I-Task
driving	I-Task
cars	I-Task
,	O
online	B-Task
recommender	I-Task
systems	I-Task
,	O
or	O
other	O
multi	B-Task
-	I-Task
user	I-Task
systems	I-Task
in	O
which	O
data	O
is	O
generated	O
by	O
many	O
instances	O
of	O
the	O
same	O
environment	O
[	O
c.f.	O
][]	O
concurrent	O
-	O
rl	B-Method
.	O
	
In	O
applications	O
where	O
data	O
is	O
costly	O
to	O
obtain	O
,	O
our	O
approach	O
will	O
not	O
be	O
directly	O
applicable	O
.	O
	
With	O
powerful	O
function	B-Method
approximators	I-Method
,	O
overfitting	O
is	O
an	O
issue	O
:	O
generating	O
more	O
training	O
data	O
is	O
the	O
simplest	O
way	O
of	O
addressing	O
it	O
,	O
but	O
may	O
also	O
provide	O
guidance	O
towards	O
data	O
-	O
efficient	O
solutions	O
.	O
	
Many	O
deep	B-Method
reinforcement	I-Method
learning	I-Method
algorithms	I-Method
are	O
fundamentally	O
limited	O
by	O
their	O
ability	O
to	O
explore	O
effectively	O
in	O
large	O
domains	O
.	O
	
Ape	B-Method
-	I-Method
X	I-Method
uses	O
a	O
naive	O
yet	O
effective	O
mechanism	O
to	O
address	O
this	O
issue	O
:	O
generating	O
a	O
diverse	O
set	O
of	O
experiences	O
and	O
then	O
identifying	O
and	O
learning	O
from	O
the	O
most	O
useful	O
events	O
.	O
	
The	O
success	O
of	O
this	O
approach	O
suggests	O
that	O
simple	O
and	O
direct	B-Method
approaches	I-Method
to	O
exploration	B-Task
may	O
be	O
feasible	O
,	O
even	O
for	O
synchronous	B-Task
agents	I-Task
.	O
	
Our	O
architecture	O
illustrates	O
that	O
distributed	B-Method
systems	I-Method
are	O
now	O
practical	O
both	O
for	O
research	O
and	O
,	O
potentially	O
,	O
large	B-Task
-	I-Task
scale	I-Task
applications	I-Task
of	O
deep	B-Task
reinforcement	I-Task
learning	I-Task
.	O
	
We	O
hope	O
that	O
the	O
algorithms	O
,	O
architecture	O
,	O
and	O
analysis	O
we	O
have	O
presented	O
will	O
help	O
to	O
accelerate	O
future	O
efforts	O
in	O
this	O
direction	O
.	O
	
subsubsection	O
:	O
Acknowledgments	O
	
We	O
would	O
like	O
to	O
acknowledge	O
the	O
contributions	O
of	O
our	O
colleagues	O
at	O
DeepMind	O
,	O
whose	O
input	O
and	O
support	O
has	O
been	O
vital	O
to	O
the	O
success	O
of	O
this	O
work	O
.	O
	
Thanks	O
in	O
particular	O
to	O
Tom	O
Schaul	O
,	O
Joseph	O
Modayil	O
,	O
Sriram	O
Srinivasan	O
,	O
Georg	O
Ostrovski	O
,	O
Josh	O
Abramson	O
,	O
Todd	O
Hester	O
,	O
Jean	O
-	O
Baptiste	O
Lespiau	O
,	O
Alban	O
Rrustemi	O
and	O
Dan	O
Belov	O
.	O
	
bibliography	O
:	O
References	O
	
appendix	O
:	O
Recency	O
of	O
Experience	O
	
[	O
width=	O
]	O
images	O
/	O
apex_iclr_virtual_actors	O
[	O
width=	O
]	O
images	O
/	O
apex_iclr_varying_the_pool_of_policies.pdf	O
	
In	O
our	O
main	O
experiments	O
we	O
do	O
not	O
change	O
the	O
size	O
of	O
the	O
replay	O
memory	O
in	O
proportion	O
to	O
the	O
number	O
of	O
actors	O
,	O
so	O
by	O
changing	O
the	O
number	O
of	O
actors	O
we	O
also	O
increased	O
the	O
rate	O
at	O
which	O
the	O
contents	O
of	O
the	O
replay	O
memory	O
is	O
replaced	O
.	O
	
This	O
means	O
that	O
in	O
the	O
experiments	O
with	O
more	O
actors	O
,	O
transitions	O
in	O
the	O
replay	O
memory	O
are	O
more	O
recent	O
:	O
they	O
are	O
generated	O
by	O
following	O
policies	O
whose	O
parameters	O
are	O
closer	O
to	O
version	O
of	O
the	O
parameters	O
being	O
optimized	O
by	O
the	O
learner	B-Method
,	O
and	O
in	O
this	O
sense	O
they	O
are	O
more	O
on	O
-	O
policy	O
.	O
	
Could	O
this	O
alone	O
be	O
sufficient	O
to	O
explain	O
the	O
improved	O
performance	O
?	O
	
If	O
so	O
,	O
we	O
might	O
be	O
able	O
to	O
recover	O
the	O
results	O
without	O
needing	O
a	O
large	O
number	O
of	O
actor	O
machines	O
.	O
	
To	O
test	O
this	O
,	O
we	O
constructed	O
an	O
experiment	O
wherein	O
we	O
replicate	O
the	O
rate	O
at	O
which	O
the	O
contents	O
of	O
the	O
replay	O
memory	O
is	O
replaced	O
in	O
the	O
256	O
-	O
actor	O
experiments	O
,	O
but	O
instead	O
of	O
actually	O
using	O
256	O
actors	O
,	O
we	O
use	O
32	O
actors	O
but	O
add	O
each	O
transition	O
they	O
generate	O
to	O
the	O
replay	O
memory	O
8	O
times	O
over	O
.	O
	
In	O
this	O
setup	O
,	O
the	O
contents	O
of	O
the	O
replay	O
memory	O
is	O
similarly	O
generated	O
by	O
policies	B-Method
with	O
a	O
recent	O
version	O
of	O
the	O
network	O
parameters	O
:	O
the	O
only	O
difference	O
is	O
that	O
the	O
data	O
is	O
not	O
as	O
diverse	O
as	O
in	O
the	O
256	O
-	O
actor	O
case	O
.	O
	
We	O
observe	O
(	O
see	O
Figure	O
[	O
reference	O
]	O
)	O
that	O
this	O
does	O
not	O
recover	O
the	O
same	O
performance	O
,	O
and	O
therefore	O
conclude	O
that	O
the	O
recency	O
of	O
the	O
experience	O
alone	O
is	O
not	O
sufficient	O
to	O
explain	O
the	O
performance	O
of	O
our	O
method	O
.	O
	
Indeed	O
,	O
we	O
see	O
that	O
adding	O
the	O
same	O
data	O
multiple	O
times	O
can	O
sometimes	O
harm	O
performance	O
,	O
since	O
although	O
it	O
increases	O
recency	O
this	O
comes	O
at	O
the	O
expense	O
of	O
diversity	O
.	O
	
Note	O
:	O
in	O
principle	O
,	O
duplicating	O
the	O
added	O
data	O
in	O
this	O
fashion	O
has	O
a	O
similar	O
effect	O
to	O
reducing	O
the	O
capacity	O
of	O
the	O
replay	O
memory	O
,	O
and	O
indeed	O
,	O
our	O
results	O
with	O
a	O
smaller	O
replay	O
memory	O
in	O
Figure	O
[	O
reference	O
]	O
do	O
corroborate	O
the	O
finding	O
.	O
	
However	O
,	O
we	O
test	O
also	O
by	O
duplicating	O
the	O
data	O
primarily	O
in	O
order	O
to	O
exclude	O
any	O
effects	O
arising	O
from	O
the	O
implementation	O
.	O
	
In	O
particular	O
,	O
in	O
contrast	O
to	O
simply	O
reducing	O
the	O
replay	O
capacity	O
,	O
duplicating	O
each	O
data	O
point	O
means	O
that	O
the	O
computational	O
demands	O
on	O
the	O
replay	B-Method
server	I-Method
in	O
these	O
runs	O
are	O
the	O
same	O
as	O
when	O
we	O
use	O
the	O
corresponding	O
number	O
of	O
real	O
actors	O
.	O
	
appendix	O
:	O
Varying	O
the	O
Data	O
-	O
Generating	B-Method
Policies	I-Method
	
Another	O
factor	O
that	O
could	O
conceivably	O
contribute	O
to	O
the	O
scalability	O
of	O
our	O
algorithm	O
is	O
the	O
fact	O
that	O
each	O
actor	O
has	O
a	O
different	O
.	O
	
To	O
determine	O
the	O
extent	O
to	O
which	O
this	O
impacts	O
upon	O
the	O
performance	O
,	O
we	O
ran	O
an	O
experiment	O
(	O
see	O
Figure	O
[	O
reference	O
]	O
)	O
with	O
some	O
simple	O
variations	O
on	O
the	O
mechanism	O
we	O
use	O
to	O
choose	O
the	O
policies	O
that	O
generate	O
the	O
data	O
we	O
train	O
on	O
.	O
	
The	O
first	O
alternative	O
we	O
tested	O
is	O
to	O
choose	O
a	O
small	O
fixed	O
set	O
of	O
6	O
values	O
for	O
,	O
instead	O
of	O
the	O
full	O
range	O
that	O
we	O
typically	O
use	O
.	O
	
In	O
this	O
test	O
,	O
we	O
use	O
prioritized	O
replay	O
as	O
normal	O
,	O
and	O
we	O
find	O
that	O
the	O
results	O
with	O
the	O
full	O
range	O
of	O
are	O
overall	O
slightly	O
better	O
.	O
	
However	O
,	O
it	O
is	O
not	O
essential	O
for	O
achieving	O
good	O
results	O
within	O
our	O
distributed	B-Method
framework	I-Method
.	O
	
appendix	O
:	O
Atari	B-Task
:	O
Additional	O
Details	O
	
The	O
frames	O
received	O
from	O
the	O
environment	O
are	O
preprocessed	O
on	O
the	O
actor	O
side	O
with	O
the	O
standard	O
transformations	O
introduced	O
by	O
DQN	B-Method
.	O
	
This	O
includes	O
greyscaling	O
,	O
frame	B-Method
stacking	I-Method
,	O
repeating	O
actions	O
4	O
times	O
,	O
and	O
clipping	O
rewards	O
to	O
.	O
	
The	O
learner	O
waits	O
for	O
at	O
least	O
50000	O
transitions	O
to	O
be	O
accumulated	O
in	O
the	O
replay	O
before	O
starting	O
learning	B-Task
.	O
	
We	O
use	O
a	O
Centered	B-Method
RMSProp	I-Method
optimizer	I-Method
with	O
a	O
learning	B-Metric
rate	I-Metric
of	O
0.00025	O
/	O
4	O
,	O
decay	O
of	O
0.95	O
,	O
epsilon	O
of	O
1.5e	O
-	O
7	O
,	O
and	O
no	O
momentum	O
to	O
minimize	O
the	O
multi	O
-	O
step	O
loss	O
(	O
with	O
)	O
.	O
	
Gradient	O
norms	O
are	O
clipped	O
to	O
40	O
.	O
	
The	O
target	O
network	O
used	O
in	O
the	O
loss	B-Task
calculation	I-Task
is	O
copied	O
from	O
the	O
online	B-Method
network	I-Method
every	O
2500	O
training	O
batches	O
.	O
	
We	O
use	O
the	O
same	O
network	O
as	O
in	O
the	O
Dueling	B-Method
DDQN	I-Method
agent	I-Method
.	O
	
appendix	O
:	O
Continuous	B-Task
Control	I-Task
:	O
Additional	O
Details	O
	
The	O
critic	B-Method
network	I-Method
has	O
a	O
layer	O
with	O
400	O
units	O
,	O
followed	O
by	O
a	O
tanh	O
activation	O
,	O
followed	O
by	O
another	O
layer	O
of	O
300	O
units	O
.	O
	
The	O
actor	B-Method
network	I-Method
has	O
a	O
layer	O
with	O
300	O
units	O
,	O
followed	O
by	O
a	O
tanh	B-Method
activation	I-Method
,	O
followed	O
by	O
another	O
layer	O
of	O
200	O
units	O
.	O
	
The	O
gradient	O
used	O
to	O
update	O
the	O
actor	B-Method
network	I-Method
is	O
clipped	O
to	O
,	O
element	O
-	O
wise	O
.	O
	
Training	B-Method
uses	O
the	O
Adam	B-Method
optimizer	I-Method
(	O
)	O
with	O
learning	B-Metric
rate	I-Metric
of	O
.	O
	
The	O
target	O
network	O
used	O
in	O
the	O
loss	B-Task
calculation	I-Task
is	O
copied	O
from	O
the	O
online	B-Method
network	I-Method
every	O
100	O
training	O
batches	O
.	O
	
Replay	O
sampling	O
priorities	O
are	O
set	O
according	O
to	O
the	O
absolute	B-Metric
TD	I-Metric
error	I-Metric
as	O
given	O
by	O
the	O
critic	B-Method
,	O
and	O
are	O
sampled	O
by	O
the	O
learner	B-Method
using	O
proportional	B-Method
prioritized	I-Method
sampling	I-Method
(	O
see	O
appendix	O
[	O
reference	O
]	O
)	O
with	O
priority	O
exponent	O
.	O
	
To	O
maintain	O
a	O
fixed	O
replay	O
capacity	O
of	O
,	O
transitions	O
are	O
periodically	O
evicted	O
using	O
proportional	B-Method
prioritized	I-Method
sampling	I-Method
,	O
with	O
priority	O
exponent	O
.	O
	
This	O
is	O
a	O
different	O
strategy	O
for	O
removing	O
data	O
than	O
in	O
the	O
Atari	B-Task
experiments	O
,	O
which	O
simply	O
removed	O
the	O
oldest	O
data	O
first	O
-	O
it	O
remains	O
to	O
be	O
seen	O
which	O
is	O
superior	O
.	O
	
Unlike	O
the	O
original	O
DPG	B-Method
algorithm	O
which	O
applies	O
autocorrelated	O
noise	O
sampled	O
from	O
a	O
Ornstein	B-Method
-	I-Method
Uhlenbeck	I-Method
process	I-Method
(	O
)	O
,	O
we	O
apply	O
exploration	O
noise	O
to	O
each	O
action	O
sampled	O
from	O
a	O
normal	O
distribution	O
with	O
.	O
	
Evaluation	B-Task
is	O
performed	O
using	O
the	O
noiseless	B-Method
deterministic	I-Method
policy	I-Method
.	O
	
Hyperparameters	B-Method
are	O
otherwise	O
as	O
per	O
DQN	B-Method
.	O
	
Benchmarking	O
was	O
performed	O
in	O
two	O
continuous	O
control	O
domains	O
(	O
(	O
a	O
)	O
Humanoid	B-Material
and	O
(	O
b	O
	
)	O
Manipulator	B-Method
,	O
see	O
Figure	O
[	O
reference	O
]	O
)	O
implemented	O
in	O
the	O
MuJoCo	B-Method
physics	I-Method
simulator	I-Method
(	O
)	O
.	O
	
Humanoid	B-Material
is	O
a	O
humanoid	O
walker	O
with	O
action	O
,	O
state	O
and	O
observation	O
dimensionalities	O
,	O
and	O
respectively	O
.	O
	
Three	O
Humanoid	B-Material
tasks	O
were	O
considered	O
:	O
walk	O
(	O
reward	O
for	O
exceeding	O
a	O
minimum	O
velocity	O
)	O
,	O
run	O
(	O
reward	O
proportional	O
to	O
movement	O
speed	O
)	O
and	O
stand	O
(	O
reward	O
proportional	O
to	O
standing	O
height	O
)	O
.	O
	
Manipulator	B-Method
is	O
a	O
2	O
-	O
dimensional	O
planar	O
arm	O
with	O
,	O
and	O
,	O
which	O
receives	O
reward	O
for	O
catching	O
a	O
randomly	O
-	O
initialized	O
moving	O
ball	O
.	O
	
.5	O
	
[	O
width=.6	O
]	O
.	O
/	O
images	O
	
/	O
humanoid.png	O
.5	O
	
[	O
width=.6	O
]	O
.	O
/	O
images	O
/	O
manipulator.png	O
	
appendix	O
:	O
Tuning	O
	
On	O
Atari	B-Task
,	O
we	O
performed	O
some	O
limited	O
tuning	O
of	O
the	O
learning	B-Metric
rate	I-Metric
and	O
batch	B-Metric
size	I-Metric
:	O
we	O
found	O
that	O
larger	O
batch	O
sizes	O
contribute	O
significantly	O
to	O
performance	O
,	O
when	O
using	O
many	O
actors	O
.	O
	
We	O
tried	O
batch	O
sizes	O
from	O
{	O
32	O
,	O
128	O
,	O
256	O
,	O
512	O
,	O
1024	O
}	O
,	O
seeing	O
clear	O
benefits	O
up	O
to	O
512	O
.	O
	
We	O
attempted	O
increasing	O
the	O
learning	B-Metric
rate	I-Metric
to	O
0.00025	O
with	O
the	O
larger	O
batch	O
sizes	O
but	O
this	O
destabilized	O
training	O
on	O
some	O
games	O
.	O
	
We	O
also	O
tried	O
a	O
lower	O
learning	B-Metric
rate	I-Metric
of	O
0.00025	O
/	O
8	O
,	O
but	O
this	O
did	O
not	O
reliably	O
improve	O
results	O
.	O
	
Likewise	O
for	O
continuous	B-Task
control	I-Task
,	O
we	O
experimented	O
with	O
batch	O
sizes	O
{	O
32	O
,	O
128	O
,	O
256	O
,	O
512	O
,	O
1024	O
}	O
and	O
learning	B-Metric
rates	I-Metric
from	O
to	O
.	O
	
We	O
also	O
experimented	O
with	O
the	O
prioritization	O
exponents	O
from	O
to	O
,	O
with	O
results	O
proving	O
essentially	O
consistent	O
within	O
the	O
range	O
[	O
0.3	O
,	O
0.7	O
]	O
(	O
beyond	O
0.7	O
,	O
training	O
would	O
sometimes	O
become	O
unstable	O
and	O
diverge	O
)	O
.	O
	
For	O
the	O
experiments	O
with	O
many	O
actors	O
,	O
we	O
set	O
the	O
period	O
for	O
updating	O
network	O
parameters	O
on	O
the	O
actors	O
to	O
be	O
high	O
enough	O
that	O
the	O
learner	O
was	O
not	O
overloaded	O
with	O
requests	O
,	O
and	O
we	O
set	O
the	O
number	O
of	O
transitions	O
that	O
are	O
locally	O
accumulated	O
on	O
each	O
actor	O
to	O
be	O
high	O
enough	O
that	O
the	O
replay	B-Method
server	I-Method
would	O
not	O
be	O
overloaded	O
with	O
network	O
traffic	O
,	O
but	O
we	O
did	O
not	O
otherwise	O
tune	O
those	O
parameters	O
and	O
have	O
not	O
observed	O
them	O
to	O
have	O
significant	O
impact	O
on	O
the	O
learning	B-Task
dynamics	I-Task
.	O
	
appendix	O
:	O
Implementation	O
	
The	O
following	O
section	O
makes	O
explicit	O
some	O
of	O
the	O
more	O
practical	O
details	O
that	O
may	O
be	O
of	O
interest	O
to	O
anyone	O
wishing	O
to	O
implement	O
a	O
similar	O
system	O
.	O
	
paragraph	O
:	O
Data	B-Task
Storage	I-Task
	
The	O
algorithm	O
is	O
implemented	O
using	O
TensorFlow	B-Method
tensorflow	I-Method
.	O
	
Replay	O
data	O
is	O
kept	O
in	O
a	O
distributed	B-Method
in	I-Method
-	I-Method
memory	I-Method
key	I-Method
-	I-Method
value	I-Method
store	I-Method
implemented	O
using	O
custom	O
TensorFlow	B-Method
ops	I-Method
,	O
similar	O
to	O
the	O
lookup	B-Method
ops	I-Method
available	O
in	O
core	B-Method
TensorFlow	I-Method
.	O
	
The	O
ops	B-Method
allow	O
adding	O
,	O
reading	O
,	O
and	O
removing	O
batches	O
of	O
Tensor	B-Material
data	I-Material
efficiently	O
.	O
	
paragraph	O
:	O
Sampling	O
Data	O
	
We	O
also	O
implemented	O
ops	B-Method
for	O
efficiently	O
maintaining	O
and	O
sampling	O
from	O
a	O
prioritized	O
distribution	O
over	O
the	O
keys	O
,	O
using	O
the	O
algorithm	O
for	O
proportional	B-Task
prioritization	I-Task
described	O
in	O
.	O
	
The	O
probability	O
of	O
sampling	O
a	O
transition	O
is	O
where	O
is	O
the	O
priority	O
of	O
the	O
transition	O
with	O
key	O
.	O
	
The	O
exponent	O
controls	O
the	O
amount	O
of	O
prioritization	O
,	O
and	O
when	O
uniform	B-Method
sampling	I-Method
is	O
recovered	O
.	O
	
The	O
proportional	B-Method
variant	I-Method
sets	O
priority	O
where	O
is	O
the	O
TD	O
error	O
for	O
transition	O
.	O
	
Whenever	O
a	O
batch	O
of	O
data	O
is	O
added	O
to	O
or	O
removed	O
from	O
the	O
store	O
,	O
or	O
is	O
processed	O
by	O
the	O
learner	O
,	O
this	O
distribution	O
is	O
correspondingly	O
updated	O
,	O
recording	O
any	O
change	O
to	O
the	O
set	O
of	O
valid	O
keys	O
and	O
the	O
priorities	O
associated	O
with	O
them	O
.	O
	
A	O
background	O
thread	O
on	O
the	O
learner	O
fetches	O
batches	O
of	O
sampled	O
data	O
from	O
the	O
remote	O
replay	O
and	O
decompresses	O
it	O
using	O
the	O
learner	O
’s	O
CPU	O
,	O
in	O
parallel	O
with	O
the	O
gradients	O
being	O
computed	O
on	O
the	O
GPU	O
.	O
	
The	O
fetched	O
data	O
is	O
buffered	O
in	O
a	O
TensorFlow	O
queue	O
,	O
so	O
that	O
the	O
GPU	O
always	O
has	O
data	O
available	O
to	O
train	O
on	O
.	O
	
paragraph	O
:	O
Adding	O
Data	O
	
In	O
order	O
to	O
efficiently	O
construct	O
-	O
step	O
transition	O
data	O
,	O
each	O
actor	O
maintains	O
a	O
circular	O
buffer	O
of	O
capacity	O
containing	O
tuples	O
,	O
where	O
is	O
the	O
current	O
size	O
of	O
the	O
buffer	O
.	O
	
With	O
each	O
step	O
,	O
the	O
new	O
data	O
is	O
appended	O
and	O
the	O
accumulated	O
per	O
-	O
step	O
discounts	O
and	O
partial	O
returns	O
for	O
all	O
entries	O
in	O
the	O
buffer	O
are	O
updated	O
.	O
	
If	O
the	O
buffer	O
has	O
reached	O
its	O
capacity	O
,	O
,	O
then	O
its	O
first	O
element	O
may	O
be	O
combined	O
with	O
the	O
latest	O
state	O
and	O
value	O
estimates	O
to	O
produce	O
a	O
valid	O
-	O
step	O
transition	O
(	O
with	O
accompanying	O
Q	O
-	O
values	O
)	O
.	O
	
However	O
,	O
instead	O
of	O
being	O
directly	O
added	O
to	O
the	O
remote	O
replay	O
memory	O
on	O
each	O
step	O
,	O
the	O
constructed	O
transitions	O
are	O
first	O
stored	O
in	O
a	O
local	O
TensorFlow	O
queue	O
,	O
in	O
order	O
to	O
reduce	O
the	O
number	O
of	O
requests	O
to	O
the	O
replay	B-Method
server	I-Method
.	O
	
The	O
queue	O
is	O
periodically	O
flushed	O
,	O
at	O
which	O
stage	O
the	O
absolute	B-Metric
-	I-Metric
step	I-Metric
TD	I-Metric
-	I-Metric
errors	I-Metric
(	O
and	O
thus	O
the	O
initial	O
priorities	O
)	O
for	O
the	O
queued	O
transitions	O
are	O
computed	O
in	O
batch	O
,	O
using	O
the	O
buffered	O
Q	O
-	O
values	O
to	O
avoid	O
recomputation	O
.	O
	
The	O
Q	O
-	O
value	O
estimates	O
from	O
which	O
the	O
initial	O
priorities	O
are	O
derived	O
are	O
therefore	O
based	O
on	O
the	O
actor	O
’s	O
copy	O
of	O
the	O
network	O
parameters	O
at	O
the	O
time	O
the	O
corresponding	O
state	O
was	O
obtained	O
from	O
the	O
environment	O
,	O
rather	O
than	O
the	O
latest	O
version	O
on	O
the	O
learner	O
.	O
	
These	O
Q	O
-	O
values	O
need	O
not	O
be	O
stored	O
after	O
this	O
,	O
since	O
the	O
learner	O
does	O
not	O
require	O
them	O
,	O
although	O
they	O
can	O
be	O
helpful	O
for	O
debugging	B-Task
.	O
	
A	O
unique	O
key	O
is	O
assigned	O
to	O
each	O
transition	O
,	O
which	O
records	O
which	O
actor	O
and	O
environment	O
step	O
it	O
came	O
from	O
,	O
and	O
the	O
dequeued	O
transition	O
tuples	O
are	O
stored	O
in	O
the	O
remote	O
replay	O
memory	O
.	O
	
As	O
mentioned	O
in	O
the	O
previous	O
section	O
,	O
the	O
remote	B-Method
sampling	I-Method
distribution	I-Method
is	O
immediately	O
updated	O
with	O
the	O
newly	O
added	O
keys	O
and	O
the	O
corresponding	O
initial	O
priorities	O
computed	O
by	O
the	O
actor	O
.	O
	
Note	O
that	O
,	O
since	O
we	O
store	O
both	O
the	O
start	O
and	O
the	O
end	O
state	O
with	O
each	O
transition	O
,	O
we	O
are	O
storing	O
some	O
data	O
twice	O
:	O
this	O
costs	O
more	O
RAM	O
,	O
but	O
simplifies	O
the	O
code	O
.	O
	
paragraph	O
:	O
Contention	O
	
It	O
is	O
important	O
that	O
the	O
replay	B-Method
server	I-Method
be	O
able	O
to	O
handle	O
all	O
requests	O
in	O
a	O
timely	O
fashion	O
,	O
in	O
order	O
to	O
avoid	O
slowing	O
down	O
the	O
whole	O
system	O
.	O
	
Possible	O
bottlenecks	O
include	O
CPU	O
,	O
network	O
bandwidth	O
,	O
and	O
any	O
locks	O
protecting	O
the	O
shared	O
data	O
.	O
	
In	O
our	O
experiments	O
we	O
found	O
CPU	O
to	O
be	O
the	O
main	O
bottleneck	O
,	O
but	O
this	O
was	O
resolved	O
by	O
ensuring	O
all	O
requests	O
and	O
responses	O
use	O
sufficiently	O
large	O
batches	O
.	O
	
Nonetheless	O
,	O
it	O
is	O
advisable	O
to	O
consider	O
all	O
of	O
these	O
potential	O
performance	O
concerns	O
when	O
designing	O
such	O
systems	O
.	O
	
paragraph	O
:	O
Asynchronicity	O
	
In	O
our	O
framework	O
,	O
since	O
acting	B-Task
and	I-Task
learning	I-Task
proceed	O
with	O
no	O
synchronization	O
,	O
and	O
performance	O
depends	O
on	O
both	O
,	O
it	O
can	O
be	O
misleading	O
to	O
consider	O
performance	O
with	O
reference	O
to	O
only	O
one	O
of	O
these	O
.	O
	
For	O
example	O
,	O
the	O
results	O
after	O
a	O
given	O
total	O
number	O
of	O
environment	O
frames	O
have	O
been	O
experienced	O
are	O
highly	O
dependent	O
on	O
the	O
number	O
of	O
updates	O
the	O
learner	O
has	O
performed	O
in	O
that	O
time	O
.	O
	
For	O
this	O
reason	O
it	O
is	O
important	O
to	O
monitor	O
and	O
report	O
the	O
speeds	O
of	O
all	O
parts	O
of	O
the	O
system	O
and	O
to	O
consider	O
them	O
when	O
analyzing	O
results	O
.	O
	
paragraph	O
:	O
Failure	B-Task
Tolerance	I-Task
	
In	O
distributed	B-Task
systems	I-Task
with	O
many	O
workers	O
,	O
it	O
is	O
inevitable	O
that	O
interruptions	O
or	O
failures	O
will	O
occur	O
,	O
either	O
due	O
to	O
occasional	O
hardware	O
issues	O
or	O
because	O
shared	O
resources	O
are	O
needed	O
by	O
higher	O
priority	O
jobs	O
.	O
	
All	O
stateful	O
parts	O
of	O
the	O
system	O
therefore	O
must	O
periodically	O
save	O
their	O
work	O
and	O
be	O
able	O
to	O
resume	O
where	O
they	O
left	O
off	O
when	O
restarted	O
.	O
	
In	O
our	O
system	O
,	O
actors	O
may	O
be	O
interrupted	O
at	O
any	O
time	O
and	O
this	O
will	O
not	O
prevent	O
continued	O
learning	B-Task
,	O
albeit	O
with	O
a	O
temporarily	O
reduced	O
rate	O
of	O
new	O
data	O
entering	O
the	O
replay	O
memory	O
.	O
	
If	O
the	O
replay	B-Method
server	I-Method
is	O
interrupted	O
,	O
the	O
data	O
it	O
contains	O
is	O
discarded	O
,	O
and	O
upon	O
resuming	O
,	O
the	O
memory	O
is	O
refilled	O
quickly	O
by	O
the	O
actors	O
.	O
	
In	O
this	O
event	O
,	O
to	O
avoid	O
overfitting	O
,	O
the	O
learner	B-Method
will	O
pause	O
training	O
briefly	O
,	O
until	O
the	O
minimum	O
amount	O
of	O
data	O
has	O
once	O
again	O
been	O
accumulated	O
.	O
	
If	O
the	O
learner	O
is	O
interrupted	O
,	O
progress	O
will	O
stall	O
until	O
it	O
resumes	O
.	O
	
[	O
width=0.99	O
]	O
images	O
/	O
apex_iclr_full_sweep_oct_24	O
[	O
width=0.99	O
]	O
images	O
/	O
	
apex_iclr_full_sweep_oct_24_data_efficiency	O
	
[	O
height=4cm	O
]	O
images	O
/	O
apex_iclr_scalability_of_data_generation	O
[	O
width=0.95	O
]	O
images	O
/	O
	
apex_iclr_num_actors	O
	
document	O
:	O
Graph2Seq	B-Method
:	O
Graph	B-Task
to	I-Task
Sequence	I-Task
Learning	I-Task
with	O
Attention	B-Method
-	I-Method
Based	I-Method
Neural	I-Method
Networks	I-Method
	
The	O
celebrated	O
Sequence	B-Method
to	I-Method
Sequence	I-Method
learning	I-Method
(	O
Seq2Seq	B-Method
)	O
technique	O
and	O
its	O
numerous	O
variants	O
achieve	O
excellent	O
performance	O
on	O
many	O
tasks	O
.	O
	
However	O
,	O
many	O
machine	B-Task
learning	I-Task
tasks	I-Task
have	O
inputs	O
naturally	O
represented	O
as	O
graphs	O
;	O
existing	O
Seq2Seq	B-Method
models	O
face	O
a	O
significant	O
challenge	O
in	O
achieving	O
accurate	O
conversion	B-Task
from	O
graph	O
form	O
to	O
the	O
appropriate	O
sequence	O
.	O
	
To	O
address	O
this	O
challenge	O
,	O
we	O
introduce	O
a	O
novel	O
general	O
end	B-Method
-	I-Method
to	I-Method
-	I-Method
end	I-Method
graph	I-Method
-	I-Method
to	I-Method
-	I-Method
sequence	I-Method
neural	I-Method
encoder	I-Method
-	I-Method
decoder	I-Method
model	I-Method
that	O
maps	O
an	O
input	O
graph	O
to	O
a	O
sequence	O
of	O
vectors	O
and	O
uses	O
an	O
attention	O
-	O
based	O
LSTM	B-Method
method	O
to	O
decode	O
the	O
target	O
sequence	O
from	O
these	O
vectors	O
.	O
	
Our	O
method	O
first	O
generates	O
the	O
node	B-Method
and	I-Method
graph	I-Method
embeddings	I-Method
using	O
an	O
improved	O
graph	B-Method
-	I-Method
based	I-Method
neural	I-Method
network	I-Method
with	O
a	O
novel	O
aggregation	B-Method
strategy	I-Method
to	O
incorporate	O
edge	O
direction	O
information	O
in	O
the	O
node	O
embeddings	O
.	O
	
We	O
further	O
introduce	O
an	O
attention	B-Method
mechanism	I-Method
that	O
aligns	O
node	O
embeddings	O
and	O
the	O
decoding	O
sequence	O
to	O
better	O
cope	O
with	O
large	O
graphs	O
.	O
	
Experimental	O
results	O
on	O
bAbI	B-Task
,	O
Shortest	B-Task
Path	I-Task
,	O
and	O
Natural	B-Task
Language	I-Task
Generation	I-Task
tasks	I-Task
demonstrate	O
that	O
our	O
model	O
achieves	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
performance	O
and	O
significantly	O
outperforms	O
existing	O
graph	B-Method
neural	I-Method
networks	I-Method
,	O
Seq2Seq	B-Method
,	O
and	O
Tree2Seq	B-Method
models	I-Method
;	O
using	O
the	O
proposed	O
bi	B-Method
-	I-Method
directional	I-Method
node	I-Method
embedding	I-Method
aggregation	I-Method
strategy	I-Method
,	O
the	O
model	O
can	O
converge	O
rapidly	O
to	O
the	O
optimal	O
performance	O
.	O
	
section	O
:	O
Introduction	O
	
The	O
celebrated	O
Sequence	B-Method
to	I-Method
Sequence	I-Method
learning	I-Method
(	O
Seq2Seq	B-Method
)	O
technique	O
and	O
its	O
numerous	O
variants	O
achieve	O
excellent	O
performance	O
on	O
many	O
tasks	O
such	O
as	O
Neural	B-Task
Machine	I-Task
Translation	I-Task
bahdanau2014neural	O
,	O
gehring2017convolutional	O
,	O
Natural	B-Task
Language	I-Task
Generation	I-Task
(	O
NLG	B-Task
)	O
	
DBLP	B-Method
:	O
	
conf	O
/	O
acl	O
/	O
SongPZWG17	O
and	O
Speech	B-Task
Recognition	I-Task
zhang2017very	O
.	O
	
Most	O
of	O
the	O
proposed	O
Seq2Seq	B-Method
models	O
can	O
be	O
viewed	O
as	O
a	O
family	O
of	O
encoder	B-Method
-	I-Method
decoders	I-Method
DBLP	I-Method
:	O
conf	O
/	O
nips	O
/	O
SutskeverVL14	O
,	O
cho2014learning	O
,	O
bahdanau2014neural	O
,	O
where	O
an	O
encoder	B-Method
reads	O
and	O
encodes	O
a	O
source	O
input	O
in	O
the	O
form	O
of	O
sequences	O
into	O
a	O
continuous	B-Method
vector	I-Method
representation	I-Method
of	O
fixed	O
dimension	O
,	O
and	O
a	O
decoder	B-Method
takes	O
the	O
encoded	O
vectors	O
and	O
outputs	O
a	O
target	O
sequence	O
.	O
	
Many	O
other	O
enhancements	O
including	O
Bidirectional	B-Method
Recurrent	I-Method
Neural	I-Method
Networks	I-Method
(	I-Method
Bi	I-Method
-	I-Method
RNN	I-Method
)	O
schuster1997bidirectional	O
or	O
Bidirectional	B-Method
Long	I-Method
Short	I-Method
-	I-Method
Term	I-Method
Memory	I-Method
Networks	I-Method
(	O
Bi	O
-	O
LSTM	B-Method
)	O
graves2005framewise	O
as	O
encoder	B-Method
,	O
and	O
attention	B-Method
mechanism	I-Method
bahdanau2014neural	O
,	O
luong2015effective	O
,	O
have	O
been	O
proposed	O
to	O
further	O
improve	O
its	O
practical	O
performance	O
for	O
general	B-Task
or	I-Task
domain	I-Task
-	I-Task
specific	I-Task
applications	I-Task
.	O
	
Despite	O
their	O
flexibility	O
and	O
expressive	O
power	O
,	O
a	O
significant	O
limitation	O
with	O
the	O
Seq2Seq	B-Method
models	O
is	O
that	O
they	O
can	O
only	O
be	O
applied	O
to	O
problems	O
whose	O
inputs	O
are	O
represented	O
as	O
sequences	O
.	O
	
However	O
,	O
the	O
sequences	O
are	O
probably	O
the	O
simplest	O
structured	O
data	O
,	O
and	O
many	O
important	O
problems	O
are	O
best	O
expressed	O
with	O
a	O
more	O
complex	O
structure	O
such	O
as	O
graphs	O
that	O
have	O
more	O
capacity	O
to	O
encode	O
complicated	O
pair	O
-	O
wise	O
relationships	O
in	O
the	O
data	O
.	O
	
For	O
example	O
,	O
one	O
task	O
in	O
NLG	B-Task
applications	O
is	O
to	O
translate	O
a	O
graph	B-Method
-	I-Method
structured	I-Method
semantic	I-Method
representation	I-Method
such	O
as	O
Abstract	B-Method
Meaning	I-Method
Representation	I-Method
to	O
a	O
text	O
expressing	O
its	O
meaning	O
banarescu2013abstract	O
.	O
	
In	O
addition	O
,	O
path	B-Task
planning	I-Task
for	O
a	O
mobile	B-Task
robot	I-Task
hu2004knowledge	O
and	O
path	B-Task
finding	I-Task
for	O
question	B-Task
answering	I-Task
in	O
bAbI	B-Task
task	I-Task
li2015gated	O
can	O
also	O
be	O
cast	O
as	O
graph	B-Task
-	I-Task
to	I-Task
-	I-Task
sequence	I-Task
problems	I-Task
.	O
	
On	O
the	O
other	O
hand	O
,	O
even	O
if	O
the	O
raw	O
inputs	O
are	O
originally	O
expressed	O
in	O
a	O
sequence	O
form	O
,	O
it	O
can	O
still	O
benefit	O
from	O
the	O
enhanced	O
inputs	O
with	O
additional	O
information	O
(	O
to	O
formulate	O
graph	O
inputs	O
)	O
.	O
	
For	O
example	O
,	O
for	O
semantic	B-Task
parsing	I-Task
tasks	I-Task
(	O
text	B-Task
-	I-Task
to	I-Task
-	I-Task
AMR	I-Task
or	O
text	B-Task
-	I-Task
to	I-Task
-	I-Task
SQL	I-Task
)	O
,	O
they	O
have	O
been	O
shown	O
better	O
performance	O
by	O
augmenting	O
the	O
original	O
sentence	O
sequences	O
with	O
other	O
structural	O
information	O
such	O
as	O
dependency	B-Method
parsing	I-Method
trees	O
pust2015parsing	O
.	O
	
Intuitively	O
,	O
the	O
ideal	O
solution	O
for	O
graph	B-Task
-	I-Task
to	I-Task
-	I-Task
sequence	I-Task
tasks	I-Task
is	O
to	O
build	O
a	O
more	O
powerful	O
encoder	B-Method
which	O
is	O
able	O
to	O
learn	O
the	O
input	O
representation	O
regardless	O
of	O
its	O
inherent	O
structure	O
.	O
	
To	O
cope	O
with	O
graph	B-Task
-	I-Task
to	I-Task
-	I-Task
sequence	I-Task
problems	I-Task
,	O
a	O
simple	O
and	O
straightforward	O
approach	O
is	O
to	O
directly	O
convert	O
more	O
complex	O
structured	O
graph	O
data	O
into	O
sequences	O
iyer2016summarizing	O
,	O
gomez2016automatic	O
,	O
liu2017retrosynthetic	O
,	O
and	O
apply	O
sequence	B-Method
models	I-Method
to	O
the	O
resulting	O
sequences	O
.	O
	
However	O
,	O
the	O
Seq2Seq	B-Method
model	O
often	O
fails	O
to	O
perform	O
as	O
well	O
as	O
hoped	O
on	O
these	O
problems	O
,	O
in	O
part	O
because	O
it	O
inevitably	O
suffers	O
significant	O
information	O
loss	O
due	O
to	O
the	O
conversion	O
of	O
complex	O
structured	O
data	O
into	O
a	O
sequence	O
,	O
especially	O
when	O
the	O
input	O
data	O
is	O
naturally	O
represented	O
as	O
graphs	O
.	O
	
Recently	O
,	O
a	O
line	O
of	O
research	O
efforts	O
have	O
been	O
devoted	O
to	O
incorporate	O
additional	O
information	O
by	O
extracting	O
syntactic	O
information	O
such	O
as	O
the	O
phrase	O
structure	O
of	O
a	O
source	O
sentence	O
(	O
Tree2seq	O
)	O
eriguchi2016tree	O
,	O
by	O
utilizing	O
attention	B-Method
mechanisms	I-Method
for	O
input	O
sets	O
(	O
Set2seq	O
)	O
vinyals2015order	O
,	O
and	O
by	O
encoding	O
sentences	O
recursively	O
as	O
trees	O
socher2010learning	O
,	O
tai2015improved	O
.	O
	
Although	O
these	O
methods	O
achieve	O
promising	O
results	O
on	O
certain	O
classes	O
of	O
problems	O
,	O
most	O
of	O
the	O
presented	O
techniques	O
largely	O
depend	O
on	O
the	O
underlying	O
application	O
and	O
may	O
not	O
be	O
able	O
to	O
generalize	O
to	O
a	O
broad	O
class	O
of	O
problems	O
in	O
a	O
general	O
way	O
.	O
	
To	O
address	O
this	O
issue	O
,	O
we	O
propose	O
Graph2Seq	B-Method
,	O
a	O
novel	O
general	B-Method
attention	I-Method
-	I-Method
based	I-Method
neural	I-Method
network	I-Method
model	I-Method
for	O
graph	B-Task
-	I-Task
to	I-Task
-	I-Task
sequence	I-Task
learning	I-Task
.	O
	
The	O
Graph2Seq	B-Method
model	I-Method
follows	O
the	O
conventional	O
encoder	B-Method
-	I-Method
decoder	I-Method
approach	I-Method
with	O
two	O
main	O
components	O
,	O
a	O
graph	B-Method
encoder	I-Method
and	O
a	O
sequence	B-Method
decoder	I-Method
.	O
	
The	O
proposed	O
graph	B-Method
encoder	I-Method
aims	O
to	O
learn	O
expressive	O
node	O
embeddings	O
and	O
then	O
to	O
reassemble	O
them	O
into	O
the	O
corresponding	O
graph	O
embeddings	O
.	O
	
To	O
this	O
end	O
,	O
inspired	O
by	O
a	O
recent	O
graph	B-Method
representation	I-Method
learning	I-Method
method	I-Method
hamilton2017inductive	I-Method
,	O
we	O
propose	O
an	O
inductive	B-Method
graph	I-Method
-	I-Method
based	I-Method
neural	I-Method
network	I-Method
to	O
learn	O
node	O
embeddings	O
from	O
node	O
attributes	O
through	O
aggregation	O
of	O
neighborhood	O
information	O
for	O
directed	O
and	O
undirected	O
graphs	O
,	O
which	O
explores	O
two	O
distinct	O
aggregators	O
on	O
each	O
node	O
to	O
yield	O
two	O
representations	O
that	O
are	O
concatenated	O
to	O
form	O
the	O
final	O
node	B-Method
embedding	I-Method
.	O
	
In	O
addition	O
,	O
we	O
further	O
design	O
an	O
attention	O
-	O
based	O
RNN	B-Method
sequence	O
decoder	O
that	O
takes	O
the	O
graph	B-Method
embedding	I-Method
as	O
its	O
initial	O
hidden	O
state	O
and	O
outputs	O
a	O
target	O
prediction	O
by	O
learning	O
to	O
align	O
and	O
translate	O
jointly	O
based	O
on	O
the	O
context	O
vectors	O
associated	O
with	O
the	O
corresponding	O
nodes	O
and	O
all	O
previous	O
predictions	O
.	O
	
Our	O
code	O
and	O
data	O
are	O
available	O
at	O
.	O
	
Graph2Seq	B-Method
is	O
simple	O
yet	O
general	O
and	O
is	O
highly	O
extensible	O
where	O
its	O
two	O
building	O
blocks	O
,	O
graph	B-Method
encoder	I-Method
and	O
sequence	B-Method
decoder	I-Method
,	O
can	O
be	O
replaced	O
by	O
other	O
models	O
such	O
as	O
Graph	B-Method
Convolutional	I-Method
	
(	O
Attention	B-Method
)	I-Method
Networks	I-Method
kipf2016semi	O
,	O
velickovic2017graph	O
or	O
their	O
extensions	O
schlichtkrull2017modeling	O
,	O
and	O
LSTM	B-Method
hochreiter1997long	O
.	O
	
We	O
highlight	O
three	O
main	O
contributions	O
of	O
this	O
paper	O
as	O
follows	O
:	O
	
We	O
propose	O
a	O
novel	O
general	B-Method
attention	I-Method
-	I-Method
based	I-Method
neural	I-Method
networks	I-Method
model	I-Method
to	O
elegantly	O
address	O
graph	B-Task
-	I-Task
to	I-Task
-	I-Task
sequence	I-Task
learning	I-Task
problems	I-Task
that	O
learns	O
a	O
mapping	O
between	O
graph	O
-	O
structured	O
inputs	O
to	O
sequence	O
outputs	O
,	O
which	O
current	O
Seq2Seq	B-Method
and	O
Tree2Seq	B-Method
may	O
be	O
inadequate	O
to	O
handle	O
.	O
	
We	O
propose	O
a	O
novel	O
graph	B-Method
encoder	I-Method
to	O
learn	O
a	O
bi	O
-	O
directional	O
node	O
embeddings	O
for	O
directed	O
and	O
undirected	O
graphs	O
with	O
node	O
attributes	O
by	O
employing	O
various	O
aggregation	B-Method
strategies	I-Method
,	O
and	O
to	O
learn	O
graph	B-Method
-	I-Method
level	I-Method
embedding	I-Method
by	O
exploiting	O
two	O
different	O
graph	B-Method
embedding	I-Method
techniques	I-Method
.	O
	
Equally	O
importantly	O
,	O
we	O
present	O
an	O
attention	B-Method
mechanism	I-Method
to	O
learn	O
the	O
alignments	O
between	O
nodes	O
and	O
sequence	O
elements	O
to	O
better	O
cope	O
with	O
large	O
graphs	O
.	O
	
Experimental	O
results	O
show	O
that	O
our	O
model	O
achieves	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
performance	O
on	O
three	O
recently	O
introduced	O
graph	B-Task
-	I-Task
to	I-Task
-	I-Task
sequence	I-Task
tasks	I-Task
and	O
significantly	O
outperforms	O
existing	O
graph	B-Method
neural	I-Method
networks	I-Method
,	O
Seq2Seq	B-Method
,	O
and	O
Tree2Seq	B-Method
models	I-Method
.	O
	
section	O
:	O
Related	O
Work	O
	
Our	O
model	O
draws	O
inspiration	O
from	O
the	O
research	O
fields	O
of	O
graph	B-Task
representation	I-Task
learning	I-Task
,	O
neural	B-Method
networks	I-Method
on	O
graphs	O
,	O
and	O
neural	B-Method
encoder	I-Method
-	I-Method
decoder	I-Method
models	I-Method
.	O
	
Graph	B-Method
Representation	I-Method
Learning	I-Method
.	O
	
Graph	B-Method
representation	I-Method
learning	I-Method
has	O
been	O
proven	O
extremely	O
useful	O
for	O
a	O
broad	O
range	O
of	O
the	O
graph	B-Task
-	I-Task
based	I-Task
analysis	I-Task
and	I-Task
prediction	I-Task
tasks	I-Task
hamilton2017representation	O
,	O
goyal2017graph	O
.	O
	
The	O
main	O
goal	O
for	O
graph	B-Task
representation	I-Task
learning	I-Task
is	O
to	O
learn	O
a	O
mapping	O
that	O
embeds	O
nodes	O
as	O
points	O
in	O
a	O
low	O
-	O
dimensional	O
vector	O
space	O
.	O
	
These	O
representation	B-Method
learning	I-Method
approaches	I-Method
can	O
be	O
roughly	O
categorized	O
into	O
two	O
classes	O
including	O
matrix	B-Method
factorization	I-Method
-	I-Method
based	I-Method
algorithms	I-Method
and	O
random	B-Method
-	I-Method
walk	I-Method
based	I-Method
methods	I-Method
.	O
	
A	O
line	O
of	O
research	O
learn	O
the	O
embeddings	B-Task
of	I-Task
graph	I-Task
nodes	I-Task
through	O
matrix	B-Method
factorization	I-Method
roweis2000nonlinear	O
,	O
belkin2002laplacian	O
,	O
ahmed2013distributed	O
,	O
cao2015grarep	O
,	O
ou2016asymmetric	O
.	O
	
These	O
methods	O
directly	O
train	O
embeddings	O
for	O
individual	O
nodes	O
of	O
training	O
and	O
testing	O
data	O
jointly	O
and	O
thus	O
inherently	O
transductive	B-Method
.	O
	
Another	O
family	O
of	O
work	O
is	O
the	O
use	O
of	O
random	B-Method
walk	I-Method
-	I-Method
based	I-Method
methods	I-Method
to	O
learn	O
low	B-Task
-	I-Task
dimensional	I-Task
embeddings	I-Task
of	I-Task
nodes	I-Task
by	O
exploring	O
neighborhood	O
information	O
for	O
a	O
single	O
large	O
-	O
scale	O
graph	O
duran2017leanring	O
,	O
hamilton2017inductive	O
,	O
tang2015line	O
,	O
grover2016node2vec	O
,	O
perozzi2014deepwalk	O
,	O
velickovic2017graph	O
.	O
	
GraphSAGE	B-Material
hamilton2017inductive	O
is	O
such	O
a	O
technique	O
that	O
learns	O
node	O
embeddings	O
through	O
aggregation	O
from	O
a	O
node	O
local	O
neighborhood	O
using	O
node	O
attributes	O
or	O
degrees	O
for	O
inductive	B-Method
learning	I-Method
,	O
which	O
has	O
better	O
capability	O
to	O
generate	O
node	O
embeddings	O
for	O
previously	O
unseen	O
data	O
.	O
	
Our	O
graph	B-Method
encoder	I-Method
is	O
an	O
extension	O
to	O
GraphSAGE	B-Material
with	O
two	O
major	O
distinctions	O
.	O
	
First	O
,	O
we	O
non	O
-	O
trivially	O
generalize	O
it	O
to	O
cope	O
with	O
both	O
directed	B-Task
and	I-Task
undirected	I-Task
graphs	I-Task
by	O
splitting	O
original	O
node	O
into	O
forward	O
nodes	O
(	O
a	O
node	O
directs	O
to	O
)	O
and	O
backward	O
nodes	O
(	O
direct	O
to	O
a	O
node	O
)	O
according	O
to	O
edge	O
direction	O
and	O
applying	O
two	O
distinct	O
aggregation	B-Method
functions	I-Method
to	O
these	O
types	O
of	O
nodes	O
.	O
	
Second	O
,	O
we	O
exploit	O
two	O
different	O
schemes	O
(	O
pooling	B-Method
-	I-Method
based	I-Method
and	I-Method
supernode	I-Method
-	I-Method
based	I-Method
)	O
to	O
reassemble	O
the	O
learned	O
node	O
embeddings	O
to	O
generate	O
graph	B-Task
embedding	I-Task
,	O
which	O
is	O
not	O
studied	O
in	O
GraphSAGE	B-Material
.	O
	
We	O
show	O
the	O
advantages	O
of	O
our	O
graph	B-Method
encoder	I-Method
over	O
GraphSAGE	B-Material
in	O
our	O
experiments	O
.	O
	
Neural	B-Method
Networks	I-Method
on	O
Graphs	B-Material
.	O
	
Over	O
the	O
past	O
few	O
years	O
,	O
there	O
has	O
been	O
a	O
surge	O
of	O
approaches	O
that	O
seek	O
to	O
learn	O
the	O
representations	O
of	O
graph	O
nodes	O
,	O
or	O
entire	O
(	O
sub	O
)	O
graphs	O
,	O
based	O
on	O
Graph	B-Method
Neural	I-Method
Networks	I-Method
(	O
GNN	B-Method
)	O
that	O
extend	O
well	O
-	O
known	O
network	B-Method
architectures	I-Method
including	O
RNN	B-Method
and	O
CNN	B-Method
to	O
graph	O
data	O
gori2005new	O
,	O
scarselli2009graph	O
,	O
li2015gated	O
,	O
bruna2013spectral	O
,	O
duvenaud2015convolutional	O
,	O
niepert2016learning	O
,	O
defferrard2016convolutional	O
,	O
yang2016revisiting	O
,	O
kipf2016semi	O
,	O
chen2018fastgcn	O
.	O
	
A	O
line	O
of	O
research	O
is	O
the	O
neural	B-Method
networks	I-Method
that	O
operate	O
on	O
graphs	O
as	O
a	O
form	O
of	O
RNN	B-Method
gori2005new	O
,	O
scarselli2009graph	O
,	O
and	O
recently	O
extended	O
by	O
Li	O
et	O
al	O
.	O
	
li2015gated	O
by	O
introducing	O
modern	O
practices	O
of	O
RNN	B-Method
(	O
using	O
of	O
GRU	B-Method
updates	I-Method
)	O
in	O
the	O
original	O
GNN	B-Method
framework	I-Method
.	O
	
Another	O
important	O
stream	O
of	O
work	O
that	O
has	O
recently	O
drawn	O
fast	O
increasing	O
interest	O
is	O
graph	B-Method
convolutional	I-Method
networks	I-Method
(	O
GCN	B-Method
)	O
built	O
on	O
spectral	B-Method
graph	I-Method
theory	I-Method
,	O
introduced	O
by	O
and	O
then	O
extended	O
by	O
with	O
fast	B-Method
localized	I-Method
convolution	I-Method
.	O
	
Most	O
of	O
these	O
approaches	O
can	O
not	O
scale	O
to	O
large	O
graphs	O
,	O
which	O
is	O
improved	O
by	O
using	O
a	O
localized	B-Method
first	I-Method
-	I-Method
order	I-Method
approximation	I-Method
of	I-Method
spectral	I-Method
graph	I-Method
convolution	I-Method
kipf2016semi	O
and	O
further	O
equipping	O
with	O
important	B-Method
sampling	I-Method
for	O
deriving	O
a	O
fast	B-Method
GCN	I-Method
chen2018fastgcn	O
.	O
	
The	O
closely	O
relevant	O
work	O
to	O
our	O
graph	B-Method
encoder	I-Method
is	O
GCN	B-Method
kipf2016semi	O
,	O
which	O
is	O
designed	O
for	O
semi	B-Task
-	I-Task
supervised	I-Task
learning	I-Task
in	O
transductive	B-Task
setting	I-Task
that	O
requires	O
full	O
graph	O
Laplacian	O
to	O
be	O
given	O
during	O
training	O
and	O
is	O
typically	O
applicable	O
to	O
a	O
single	O
large	O
undirected	O
graph	O
.	O
	
An	O
extension	O
of	O
GCN	B-Method
can	O
be	O
shown	O
to	O
be	O
mathematically	O
related	O
to	O
one	O
variant	O
of	O
our	O
graph	B-Method
encoder	I-Method
on	O
undirected	O
graphs	O
.	O
	
We	O
compare	O
the	O
difference	O
between	O
our	O
graph	B-Method
encoder	I-Method
and	O
GCN	B-Method
in	O
our	O
experiments	O
.	O
	
Another	O
relevant	O
work	O
is	O
gated	B-Method
graph	I-Method
sequence	I-Method
neural	I-Method
networks	I-Method
(	O
GGS	B-Method
-	I-Method
NNs	I-Method
)	O
	
li2015gated	O
.	O
	
Although	O
it	O
is	O
also	O
designed	O
for	O
outputting	O
a	O
sequence	O
,	O
it	O
is	O
essentially	O
a	O
prediction	B-Method
model	I-Method
that	O
learns	O
to	O
predict	O
a	O
sequence	O
embedded	O
in	O
graph	O
while	O
our	O
approach	O
is	O
a	O
generative	B-Method
model	I-Method
that	O
learns	O
a	O
mapping	O
between	O
graph	O
inputs	O
and	O
sequence	O
outputs	O
.	O
	
A	O
good	O
analogy	O
that	O
can	O
be	O
drawn	O
between	O
our	O
proposed	O
Graph2Seq	B-Method
and	O
GGS	B-Method
-	I-Method
NNs	I-Method
is	O
the	O
relationship	O
between	O
convolutional	O
Seq2Seq	B-Method
and	O
RNN	B-Method
.	O
	
Neural	B-Method
Encoder	I-Method
-	I-Method
Decoder	I-Method
Models	I-Method
.	O
	
One	O
of	O
the	O
most	O
successful	O
encoder	B-Method
-	I-Method
decoder	I-Method
architectures	I-Method
is	O
the	O
sequence	B-Method
to	I-Method
sequence	I-Method
learning	I-Method
DBLP	I-Method
:	O
conf	O
/	O
nips	O
/	O
SutskeverVL14	O
,	O
cho2014learning	O
,	O
bahdanau2014neural	O
,	O
luong2015effective	O
,	O
gehring2017convolutional	O
,	O
which	O
are	O
originally	O
proposed	O
for	O
machine	B-Task
translation	I-Task
.	O
	
Recently	O
,	O
the	O
classical	O
Seq2Seq	B-Method
model	O
and	O
its	O
variants	O
have	O
been	O
applied	O
to	O
several	O
applications	O
in	O
which	O
these	O
models	O
can	O
perform	O
mappings	O
from	O
objects	O
to	O
sequences	O
,	O
including	O
mapping	O
from	O
an	O
image	O
to	O
a	O
sentence	O
vinyals2015show	O
,	O
models	O
for	O
computation	B-Task
map	O
from	O
problem	O
statements	O
of	O
a	O
python	O
program	O
to	O
their	O
solutions	O
(	O
the	O
answers	O
to	O
the	O
program	O
)	O
zaremba2014learning	O
,	O
the	O
traveling	B-Task
salesman	I-Task
problem	I-Task
for	O
the	O
set	O
of	O
points	O
vinyals2015pointer	O
and	O
deep	B-Method
generative	I-Method
model	I-Method
for	O
molecules	B-Task
generation	I-Task
from	O
existing	O
known	O
molecules	O
in	O
drug	B-Task
discovery	I-Task
.	O
	
It	O
is	O
easy	O
to	O
see	O
that	O
the	O
objects	O
that	O
are	O
mapped	O
to	O
sequences	O
in	O
the	O
listed	O
examples	O
are	O
often	O
naturally	O
represented	O
in	O
graphs	O
rather	O
than	O
sequences	O
.	O
	
Recently	O
,	O
many	O
research	O
efforts	O
and	O
the	O
key	O
contributions	O
have	O
been	O
made	O
to	O
address	O
the	O
limitations	O
of	O
Seq2Seq	B-Method
when	O
dealing	O
with	O
more	O
complex	O
data	O
,	O
that	O
leverage	O
external	O
information	O
using	O
specialized	O
neural	B-Method
models	I-Method
attached	O
to	O
underlying	O
targeted	O
applications	O
,	O
including	O
Tree2Seq	B-Method
eriguchi2016tree	O
,	O
Set2Seq	B-Method
vinyals2015order	O
,	O
Recursive	B-Method
Neural	I-Method
Networks	I-Method
socher2010learning	O
,	O
and	O
Tree	B-Method
-	I-Method
Structured	I-Method
LSTM	I-Method
tai2015improved	O
.	O
	
Due	O
to	O
more	O
recent	O
advances	O
in	O
graph	B-Method
representations	I-Method
and	O
graph	B-Method
convolutional	I-Method
networks	I-Method
,	O
a	O
number	O
of	O
research	O
has	O
investigated	O
to	O
utilize	O
various	O
GNN	B-Method
to	O
improve	O
the	O
performance	O
over	O
the	O
Seq2Seq	B-Method
models	O
in	O
the	O
domains	O
of	O
machine	B-Task
translation	I-Task
and	O
graph	B-Task
generation	I-Task
bastings2017graph	O
,	O
beck2018graph	O
,	O
simonovsky2018graphvae	O
,	O
li2018learning	O
.	O
	
There	O
are	O
several	O
distinctions	O
between	O
these	O
work	O
and	O
ours	O
.	O
	
First	O
,	O
our	O
model	O
is	O
the	O
first	O
general	B-Method
-	I-Method
purpose	I-Method
encoder	I-Method
-	I-Method
decoder	I-Method
model	I-Method
for	O
graph	B-Task
-	I-Task
to	I-Task
-	I-Task
sequence	I-Task
learning	I-Task
that	O
is	O
applicable	O
to	O
different	O
applications	O
while	O
the	O
aforementioned	O
research	O
has	O
to	O
utilize	O
domain	O
-	O
specific	O
information	O
.	O
	
Second	O
,	O
we	O
design	O
our	O
own	O
graph	B-Method
embedding	I-Method
techniques	I-Method
for	O
our	O
graph	B-Method
decoder	I-Method
while	O
most	O
of	O
other	O
work	O
directly	O
apply	O
existing	O
GNN	B-Method
to	O
their	O
problems	O
.	O
	
section	O
:	O
Graph	B-Method
-	I-Method
to	I-Method
-	I-Method
Sequence	I-Method
Model	I-Method
	
As	O
shown	O
in	O
Figure	O
[	O
reference	O
]	O
,	O
our	O
graph	B-Method
-	I-Method
to	I-Method
-	I-Method
sequence	I-Method
model	I-Method
includes	O
a	O
graph	B-Method
encoder	I-Method
,	O
a	O
sequence	B-Method
decoder	I-Method
,	O
and	O
a	O
node	B-Method
attention	I-Method
mechanism	I-Method
.	O
	
Following	O
the	O
conventional	O
encoder	B-Method
-	I-Method
decoder	I-Method
architecture	I-Method
,	O
the	O
graph	B-Method
encoder	I-Method
first	O
generates	O
node	O
embeddings	O
,	O
and	O
then	O
constructs	O
graph	O
embeddings	O
based	O
on	O
the	O
learned	O
node	O
embeddings	O
.	O
	
Finally	O
,	O
the	O
sequence	B-Method
decoder	I-Method
takes	O
both	O
the	O
graph	O
embeddings	O
and	O
node	O
embeddings	O
as	O
input	O
and	O
employs	O
attention	O
over	O
the	O
node	O
embeddings	O
whilst	O
generating	O
sequences	O
.	O
	
In	O
this	O
section	O
,	O
we	O
first	O
introduce	O
the	O
node	B-Method
-	I-Method
embedding	I-Method
generation	I-Method
algorithm	I-Method
which	O
derives	O
the	O
bi	O
-	O
directional	O
node	O
embeddings	O
by	O
aggregating	O
information	O
from	O
both	O
forward	O
and	O
backward	O
neighborhoods	O
of	O
a	O
node	O
in	O
a	O
graph	O
.	O
	
Upon	O
these	O
node	B-Method
embeddings	I-Method
,	O
we	O
propose	O
two	O
methods	O
for	O
generating	O
graph	B-Task
embeddings	I-Task
capturing	O
the	O
whole	O
-	O
graph	O
information	O
.	O
	
subsection	O
:	O
Node	B-Task
Embedding	I-Task
Generation	I-Task
	
Inspired	O
by	O
,	O
we	O
design	O
a	O
new	O
inductive	B-Method
node	I-Method
embedding	I-Method
algorithm	I-Method
that	O
generates	O
bi	O
-	O
directional	O
node	O
embeddings	O
by	O
aggregating	O
information	O
from	O
a	O
node	O
local	O
forward	O
and	O
backward	O
neighborhood	O
within	O
hops	O
for	O
both	O
directed	O
and	O
undirected	O
graphs	O
.	O
	
In	O
order	O
to	O
make	O
it	O
more	O
clear	O
,	O
we	O
take	O
the	O
embedding	B-Task
generation	I-Task
process	I-Task
for	O
node	O
as	O
an	O
example	O
to	O
explain	O
our	O
node	B-Method
embedding	I-Method
generation	I-Method
algorithm	I-Method
:	O
We	O
first	O
transform	O
node	O
’s	O
text	O
attribute	O
to	O
a	O
feature	O
vector	O
,	O
av	O
,	O
by	O
looking	O
up	O
the	O
embedding	B-Method
matrix	I-Method
W	I-Method
.	O
	
Note	O
that	O
for	O
some	O
tasks	O
where	O
’s	O
text	O
attribute	O
may	O
be	O
a	O
word	O
sequence	O
,	O
one	O
neural	B-Method
network	I-Method
layer	I-Method
,	O
such	O
as	O
an	O
LSTM	B-Method
layer	O
,	O
could	O
be	O
additionally	O
used	O
to	O
generate	O
av	O
.	O
	
We	O
categorize	O
the	O
neighbors	O
of	O
into	O
forward	O
neighbors	O
,	O
,	O
and	O
backward	O
neighbors	O
,	O
,	O
according	O
to	O
the	O
edge	O
direction	O
.	O
	
In	O
particular	O
,	O
returns	O
the	O
nodes	O
that	O
directs	O
to	O
and	O
returns	O
the	O
nodes	O
that	O
direct	O
to	O
;	O
We	O
aggregate	O
the	O
forward	O
representations	O
of	O
’s	O
forward	O
neighbors	O
{	O
h⊢u	O
-	O
k1	O
,	O
}	O
into	O
a	O
single	O
vector	O
,	O
h⁢N⊢	O
(	O
v	O
)	O
k	O
,	O
where	O
is	O
the	O
iteration	O
index	O
.	O
	
In	O
our	O
experiments	O
,	O
we	O
find	O
that	O
the	O
aggregator	O
choice	O
,	O
,	O
may	O
heavily	O
affect	O
the	O
overall	O
performance	O
and	O
we	O
will	O
discuss	O
it	O
later	O
.	O
	
Notice	O
that	O
at	O
iteration	O
,	O
this	O
aggregator	B-Method
only	O
uses	O
the	O
representations	O
generated	O
at	O
.	O
	
The	O
initial	O
forward	B-Method
representation	I-Method
of	O
each	O
node	O
is	O
its	O
feature	O
vector	O
calculated	O
in	O
step	O
(	O
1	O
)	O
;	O
We	O
concatenate	O
’s	O
current	O
forward	B-Method
representation	I-Method
,	O
h⊢v	O
-	O
k1	O
,	O
with	O
the	O
newly	O
generated	O
neighborhood	O
vector	O
,	O
h⁢N⊢	O
(	O
v	O
)	O
k	O
.	O
	
This	O
concatenated	O
vector	O
is	O
fed	O
into	O
a	O
fully	B-Method
connected	I-Method
layer	I-Method
with	O
nonlinear	B-Method
activation	I-Method
function	I-Method
,	O
which	O
updates	O
the	O
forward	B-Method
representation	I-Method
of	O
,	O
h⊢vk	O
,	O
to	O
be	O
used	O
at	O
the	O
next	O
iteration	O
;	O
We	O
update	O
the	O
backward	B-Method
representation	I-Method
of	O
,	O
h⊣vk	O
,	O
using	O
the	O
similar	O
procedure	O
as	O
introduced	O
in	O
step	O
(	O
3	O
)	O
and	O
(	O
4	O
)	O
except	O
that	O
operating	O
on	O
the	O
backward	O
representations	O
instead	O
of	O
the	O
forward	B-Method
representations	I-Method
;	O
We	O
repeat	O
steps	O
(	O
3	O
)	O
(	O
5	O
)	O
times	O
,	O
and	O
the	O
concatenation	O
of	O
the	O
final	O
forward	B-Method
and	I-Method
backward	I-Method
representation	I-Method
is	O
used	O
as	O
the	O
final	O
bi	B-Method
-	I-Method
directional	I-Method
representation	I-Method
of	I-Method
.	O
	
Since	O
the	O
neighbor	O
information	O
from	O
different	O
hops	O
may	O
have	O
different	O
impact	O
on	O
the	O
node	B-Task
embedding	I-Task
,	O
we	O
learn	O
a	O
distinct	O
aggregator	O
at	O
each	O
iteration	O
.	O
	
Aggregator	B-Method
Architectures	I-Method
.	O
	
Since	O
a	O
node	O
neighbors	O
have	O
no	O
natural	O
ordering	O
,	O
the	O
aggregator	O
function	O
should	O
be	O
invariant	O
to	O
permutations	O
of	O
its	O
inputs	O
,	O
ensuring	O
that	O
our	O
neural	B-Method
network	I-Method
model	I-Method
can	O
be	O
trained	O
and	O
applied	O
to	O
arbitrarily	O
ordered	O
node	O
-	O
neighborhood	O
feature	O
sets	O
.	O
	
In	O
practice	O
,	O
we	O
examined	O
the	O
following	O
three	O
aggregator	B-Method
functions	I-Method
:	O
	
Mean	B-Method
aggregator	I-Method
:	O
This	O
aggregator	B-Method
function	I-Method
takes	O
the	O
element	O
-	O
wise	O
mean	O
of	O
the	O
vectors	O
in	O
{	O
h⊢u	O
-	O
k1	O
,	O
}	O
and	O
{	O
h⊣u	O
-	O
k1	O
,	O
}	O
.	O
	
LSTM	B-Method
aggregator	O
:	O
	
Similar	O
to	O
hamilton2017inductive	O
,	O
we	O
also	O
examined	O
a	O
more	O
complex	O
aggregator	B-Method
based	O
on	O
an	O
Long	B-Method
Short	I-Method
Term	I-Method
Memory	I-Method
(	O
LSTM	B-Method
)	O
architecture	O
.	O
	
Note	O
that	O
LSTMs	B-Method
are	O
not	O
inherently	O
symmetric	O
since	O
they	O
process	O
their	O
inputs	O
sequentially	O
.	O
	
We	O
use	O
LSTMs	B-Method
to	O
operate	O
on	O
unordered	O
sets	O
by	O
simply	O
applying	O
them	O
to	O
a	O
single	O
random	O
permutation	O
of	O
the	O
node	O
neighbors	O
.	O
	
Pooling	B-Method
aggregator	I-Method
:	O
In	O
this	O
aggregator	O
,	O
each	O
neighbor	O
	
’s	O
vector	O
is	O
fed	O
through	O
a	O
fully	B-Method
-	I-Method
connected	I-Method
neural	I-Method
network	I-Method
,	O
and	O
an	O
element	B-Method
-	I-Method
wise	I-Method
max	I-Method
-	I-Method
pooling	I-Method
operation	I-Method
is	O
applied	O
:	O
where	O
max	B-Method
denotes	O
the	O
element	B-Method
-	I-Method
wise	I-Method
max	I-Method
operator	I-Method
,	O
and	O
is	O
a	O
nonlinear	O
activation	O
function	O
.	O
	
By	O
applying	O
max	B-Method
-	I-Method
pooling	I-Method
,	O
the	O
model	O
can	O
capture	O
different	O
information	O
across	O
the	O
neighborhood	O
set	O
.	O
	
subsection	O
:	O
Graph	B-Task
Embedding	I-Task
Generation	I-Task
	
Most	O
existing	O
works	O
of	O
graph	B-Method
convolution	I-Method
neural	I-Method
networks	I-Method
focus	O
more	O
on	O
node	O
embeddings	O
rather	O
than	O
graph	O
embeddings	O
since	O
their	O
focus	O
is	O
on	O
the	O
node	B-Task
-	I-Task
wise	I-Task
classification	I-Task
task	I-Task
.	O
	
However	O
,	O
graph	O
embeddings	O
that	O
convey	O
the	O
entire	O
graph	O
information	O
are	O
essential	O
to	O
the	O
downstream	B-Task
decoder	I-Task
.	O
	
In	O
this	O
work	O
,	O
we	O
introduce	O
two	O
approaches	O
(	O
i.e.	O
,	O
Pooling	B-Method
-	I-Method
based	I-Method
and	I-Method
Node	I-Method
-	I-Method
based	I-Method
)	O
to	O
generate	O
these	O
graph	O
embeddings	O
from	O
the	O
node	O
embeddings	O
.	O
	
Pooling	B-Method
-	I-Method
based	I-Method
Graph	I-Method
Embedding	I-Method
.	O
	
In	O
this	O
approach	O
,	O
we	O
investigated	O
three	O
pooling	B-Method
techniques	I-Method
:	O
max	B-Method
-	I-Method
pooling	I-Method
,	O
min	B-Method
-	I-Method
pooling	I-Method
and	O
average	B-Method
-	I-Method
pooling	I-Method
.	O
	
In	O
our	O
experiments	O
,	O
we	O
fed	O
the	O
node	O
embeddings	O
to	O
a	O
fully	B-Method
-	I-Method
connected	I-Method
neural	I-Method
network	I-Method
and	O
applied	O
each	O
pooling	B-Method
method	I-Method
element	O
-	O
wise	O
.	O
	
We	O
found	O
no	O
significant	O
performance	O
difference	O
across	O
the	O
three	O
different	O
pooling	B-Method
approaches	I-Method
;	O
we	O
thus	O
adopt	O
the	O
max	B-Method
-	I-Method
pooling	I-Method
method	I-Method
as	O
our	O
default	B-Method
pooling	I-Method
approach	I-Method
.	O
	
Node	B-Method
-	I-Method
based	I-Method
Graph	I-Method
Embedding	I-Method
.	O
	
In	O
this	O
approach	O
,	O
we	O
add	O
one	O
super	O
node	O
,	O
,	O
into	O
the	O
input	O
graph	O
,	O
and	O
all	O
other	O
nodes	O
in	O
the	O
graph	O
direct	O
to	O
.	O
	
We	O
use	O
the	O
aforementioned	O
node	B-Method
embedding	I-Method
generation	I-Method
algorithm	I-Method
to	O
generate	O
the	O
embedding	O
of	O
by	O
aggregating	O
the	O
embeddings	O
of	O
the	O
neighbor	O
nodes	O
.	O
	
The	O
embedding	O
of	O
that	O
captures	O
the	O
information	O
of	O
all	O
nodes	O
is	O
regarded	O
as	O
the	O
graph	B-Method
embedding	I-Method
.	O
	
subsection	O
:	O
Attention	B-Method
Based	I-Method
Decoder	I-Method
	
The	O
sequence	B-Method
decoder	I-Method
is	O
a	O
Recurrent	B-Method
Neural	I-Method
Network	I-Method
(	O
RNN	B-Method
)	O
that	O
predicts	O
the	O
next	O
token	O
,	O
given	O
all	O
the	O
previous	O
words	O
,	O
the	O
RNN	B-Method
hidden	O
state	O
for	O
time	O
,	O
and	O
a	O
context	O
vector	O
that	O
directs	O
attention	O
to	O
the	O
encoder	O
side	O
.	O
	
In	O
particular	O
,	O
the	O
context	O
vector	O
depends	O
on	O
a	O
set	O
of	O
node	B-Method
representations	I-Method
(	O
,	O
…	O
,	O
)	O
which	O
the	O
graph	B-Method
encoder	I-Method
maps	O
the	O
input	O
graph	O
to	O
.	O
	
Each	O
node	B-Method
representation	I-Method
contains	O
information	O
about	O
the	O
whole	O
graph	O
with	O
a	O
strong	O
focus	O
on	O
the	O
parts	O
surrounding	O
the	O
-	O
th	O
node	O
of	O
the	O
input	O
graph	O
.	O
	
The	O
context	O
vector	O
is	O
computed	O
as	O
a	O
weighted	O
sum	O
of	O
these	O
node	B-Method
representations	I-Method
and	O
the	O
weight	O
of	O
each	O
node	B-Method
representation	I-Method
is	O
computed	O
by	O
:	O
where	O
is	O
an	O
which	O
scores	O
how	O
well	O
the	O
input	O
node	O
around	O
position	O
and	O
the	O
output	O
at	O
position	O
match	O
.	O
	
The	O
score	O
is	O
based	O
on	O
the	O
RNN	B-Method
hidden	O
state	O
and	O
the	O
-	B-Method
th	I-Method
node	I-Method
representation	I-Method
of	I-Method
the	I-Method
input	I-Method
graph	I-Method
.	O
	
We	O
parameterize	O
the	O
alignment	B-Method
model	I-Method
as	O
a	O
feed	B-Method
-	I-Method
forward	I-Method
neural	I-Method
network	I-Method
which	O
is	O
jointly	O
trained	O
with	O
other	O
components	O
of	O
the	O
proposed	O
system	O
.	O
	
Our	O
model	O
is	O
jointly	O
trained	O
to	O
maximize	O
the	O
conditional	O
log	O
-	O
probability	O
of	O
the	O
correct	O
description	O
given	O
a	O
source	O
graph	O
.	O
	
In	O
the	O
inference	B-Task
phase	I-Task
,	O
we	O
use	O
the	O
beam	B-Method
search	I-Method
to	O
generate	O
a	O
sequence	O
with	O
the	O
beam	O
size	O
=	O
5	O
.	O
	
section	O
:	O
Experiments	O
	
We	O
conduct	O
experiments	O
to	O
demonstrate	O
the	O
effectiveness	O
and	O
efficiency	O
of	O
the	O
proposed	O
method	O
.	O
	
Following	O
the	O
experimental	O
settings	O
in	O
li2015gated	O
,	O
we	O
firstly	O
compare	O
its	O
performance	O
with	O
classical	O
LSTM	B-Method
,	O
GGS	B-Method
-	I-Method
NN	I-Method
,	O
and	O
GCN	B-Method
based	O
methods	O
on	O
two	O
selected	O
tasks	O
including	O
bAbI	B-Task
Task	O
19	O
and	O
the	O
Shortest	B-Task
Path	I-Task
Task	O
.	O
	
We	O
then	O
compare	O
Graph2Seq	B-Method
against	O
other	O
Seq2Seq	B-Method
based	O
methods	O
on	O
a	O
real	O
-	O
world	O
application	O
-	O
Natural	B-Task
Language	I-Task
Generation	I-Task
Task	O
.	O
	
Note	O
that	O
the	O
parameters	O
of	O
all	O
baselines	O
are	O
set	O
based	O
on	O
performance	O
on	O
the	O
development	O
set	O
.	O
	
Experimental	O
Settings	O
.	O
	
Our	O
proposed	O
model	O
is	O
trained	O
using	O
the	O
Adam	B-Method
optimizer	I-Method
DBLP	I-Method
:	I-Method
journals	I-Method
/	I-Method
corr	I-Method
/	I-Method
KingmaB14	I-Method
,	O
with	O
mini	B-Method
-	I-Method
batch	I-Method
size	I-Method
30	O
.	O
	
The	O
learning	B-Metric
rate	I-Metric
is	O
set	O
to	O
0.001	O
.	O
	
We	O
apply	O
the	O
dropout	B-Method
strategy	I-Method
DBLP	I-Method
:	O
journals	O
/	O
jmlr	O
/	O
SrivastavaHKSS14	O
with	O
a	O
ratio	O
of	O
0.5	O
at	O
the	O
decoder	O
layer	O
to	O
avoid	O
overfitting	O
.	O
	
Gradients	O
are	O
clipped	O
when	O
their	O
norm	O
is	O
bigger	O
than	O
20	O
.	O
	
For	O
the	O
graph	B-Method
encoder	I-Method
,	O
the	O
default	O
hop	O
size	O
is	O
set	O
to	O
6	O
,	O
the	O
size	O
of	O
node	O
initial	O
feature	O
vector	O
is	O
set	O
to	O
40	O
,	O
the	O
non	O
-	O
linearity	O
function	O
is	O
ReLU	B-Method
DBLP	I-Method
:	O
	
journals	O
/	O
jmlr	O
/	O
GlorotBB11	O
,	O
the	O
parameters	O
of	O
aggregators	B-Method
are	O
randomly	O
initialized	O
.	O
	
The	O
decoder	B-Method
has	O
1	O
layer	O
and	O
hidden	O
state	O
size	O
is	O
80	O
.	O
	
Since	O
Graph2Seq	B-Method
with	O
mean	B-Method
aggregator	I-Method
and	I-Method
pooling	I-Method
-	I-Method
based	I-Method
graph	I-Method
embeddings	I-Method
generally	O
performs	O
better	O
than	O
other	O
configurations	O
(	O
we	O
defer	O
this	O
discussion	O
to	O
Sec	O
.	O
	
[	O
reference	O
]	O
)	O
	
,	O
we	O
use	O
this	O
setting	O
as	O
our	O
default	B-Method
model	I-Method
in	O
the	O
following	O
sections	O
.	O
	
subsection	O
:	O
bAbI	B-Task
Task	O
19	O
	
Setup	O
.	O
	
The	O
bAbI	B-Task
artificial	O
intelligence	O
	
(	O
AI	O
)	O
tasks	O
DBLP	O
:	O
journals	O
/	O
corr	O
	
/	O
WestonBCM15	B-Method
are	O
designed	O
to	O
test	O
reasoning	O
capabilities	O
that	O
an	O
AI	B-Method
system	I-Method
possesses	O
.	O
	
Among	O
these	O
tasks	O
,	O
Task	O
19	O
(	O
Path	B-Task
Finding	I-Task
)	O
is	O
arguably	O
the	O
most	O
challenging	O
task	O
(	O
see	O
,	O
e.g.	O
,	O
DBLP	O
:	O
conf	O
/	O
nips	O
/	O
SukhbaatarSWF15	O
which	O
reports	O
an	O
accuracy	B-Metric
of	O
less	O
than	O
20	O
%	O
for	O
all	O
methods	O
that	O
do	O
not	O
use	O
strong	O
supervision	O
)	O
.	O
	
We	O
apply	O
the	O
transformation	B-Method
procedure	I-Method
introduced	O
in	O
li2015gated	O
to	O
transform	O
the	O
description	O
as	O
a	O
graph	O
as	O
shown	O
in	O
Figure	O
[	O
reference	O
]	O
.	O
	
The	O
left	O
part	O
shows	O
an	O
instance	O
of	O
bAbI	B-Task
task	I-Task
19	O
:	O
given	O
a	O
set	O
of	O
sentences	O
describing	O
the	O
relative	O
geographical	O
positions	O
for	O
a	O
pair	O
of	O
objects	O
and	O
,	O
we	O
aim	O
to	O
find	O
the	O
geographical	O
path	O
between	O
and	O
.	O
	
The	O
question	O
is	O
then	O
treated	O
as	O
finding	O
the	O
shortest	O
path	O
between	O
two	O
nodes	O
,	O
and	O
,	O
which	O
represent	O
and	O
in	O
the	O
graph	O
.	O
	
To	O
tackle	O
this	O
problem	O
with	O
Graph2Seq	B-Method
,	O
we	O
annotate	O
with	O
text	O
attribute	O
START	O
and	O
with	O
text	O
attribute	O
END	O
.	O
	
For	O
other	O
nodes	O
,	O
we	O
assign	O
their	O
IDs	O
in	O
the	O
graph	O
as	O
their	O
text	O
attributes	O
.	O
	
It	O
is	O
worth	O
noting	O
that	O
,	O
in	O
our	O
model	O
,	O
the	O
START	O
and	O
END	O
tokens	O
are	O
node	O
features	O
whose	O
vector	B-Method
representations	I-Method
are	O
first	O
randomly	O
initialized	O
and	O
then	O
learned	O
by	O
the	O
model	O
later	O
.	O
	
In	O
contrast	O
,	O
in	O
GGS	B-Method
-	I-Method
NN	I-Method
,	O
the	O
vector	B-Method
representations	I-Method
of	O
staring	O
and	O
end	O
nodes	O
are	O
set	O
as	O
one	O
-	O
hot	O
vectors	O
,	O
which	O
is	O
specially	O
designed	O
for	O
the	O
shortest	B-Task
path	I-Task
task	I-Task
.	O
	
To	O
aggregate	O
the	O
edge	O
information	O
into	O
the	O
node	B-Method
embedding	I-Method
,	O
for	O
each	O
edge	O
,	O
we	O
additionally	O
add	O
a	O
node	O
representing	O
this	O
edge	O
into	O
the	O
graph	O
and	O
assign	O
the	O
edge	O
’s	O
text	O
as	O
its	O
text	O
attribute	O
.	O
	
We	O
generate	O
1000	O
training	O
examples	O
,	O
1000	O
development	O
examples	O
and	O
1000	O
test	O
examples	O
where	O
each	O
example	O
is	O
a	O
graph	O
-	O
path	O
pair	O
.	O
	
We	O
use	O
a	O
standard	O
LSTM	B-Method
model	I-Method
hochreiter1997long	O
and	O
GGS	B-Method
-	I-Method
NN	I-Method
li2015gated	O
as	O
our	O
baselines	O
.	O
	
Since	O
GCN	B-Method
kipf2016semi	O
itself	O
can	O
not	O
output	O
a	O
sequence	O
,	O
we	O
also	O
create	O
a	O
baseline	O
that	O
combines	O
GCN	B-Method
with	O
our	O
sequence	B-Method
decoder	I-Method
.	O
	
figurePath	B-Task
Finding	I-Task
Example	I-Task
.	O
	
Results	O
.	O
	
From	O
Table	O
[	O
reference	O
]	O
,	O
we	O
can	O
see	O
that	O
the	O
LSTM	B-Method
model	I-Method
fails	O
on	O
this	O
task	O
while	O
our	O
model	O
makes	O
perfect	O
predictions	O
,	O
which	O
underlines	O
the	O
importance	O
of	O
the	O
use	O
of	O
graph	B-Method
encoder	I-Method
to	O
directly	O
encode	O
a	O
graph	O
instead	O
of	O
using	O
sequence	B-Method
model	I-Method
on	O
the	O
converted	O
inputs	O
from	O
a	O
graph	O
.	O
	
Comparing	O
to	O
GGS	B-Method
-	I-Method
NN	I-Method
that	O
uses	O
carefully	O
designed	O
initial	O
embeddings	O
for	O
different	O
types	O
of	O
nodes	O
such	O
as	O
START	O
and	O
END	O
,	O
our	O
model	O
uses	O
a	O
purely	O
end	O
-	O
to	O
-	O
end	B-Method
approach	I-Method
which	O
generates	O
the	O
initial	O
node	O
feature	O
vectors	O
based	O
on	O
random	B-Method
initialization	I-Method
of	O
the	O
embeddings	O
for	O
words	O
in	O
text	O
attributes	O
.	O
	
However	O
,	O
we	O
still	O
significantly	O
outperform	O
GGS	B-Method
-	I-Method
NN	I-Method
,	O
demonstrating	O
the	O
expressive	O
power	O
of	O
our	O
graph	B-Method
encoder	I-Method
that	O
considers	O
information	O
flows	O
in	O
both	O
forward	O
and	O
backward	O
directions	O
.	O
	
We	O
observe	O
similar	O
results	O
when	O
comparing	O
our	O
whole	O
Graph2Seq	B-Method
model	I-Method
to	O
GCN	B-Method
with	O
our	O
decoder	O
,	O
which	O
mainly	O
because	O
the	O
current	O
form	O
of	O
GCN	B-Method
kipf2016semi	O
is	O
designed	O
for	O
undirected	O
graph	O
and	O
thus	O
may	O
have	O
information	O
loss	O
when	O
converting	O
directed	O
graph	O
to	O
undirected	O
one	O
as	O
suggested	O
in	O
kipf2016semi	O
.	O
	
subsection	O
:	O
Shortest	B-Task
Path	I-Task
Task	O
	
Setup	O
.	O
	
We	O
further	O
evaluate	O
our	O
model	O
on	O
the	O
Shortest	B-Task
Path	I-Task
(	O
SP	B-Task
)	O
	
Task	O
whose	O
goal	O
is	O
to	O
find	O
the	O
shortest	O
directed	O
path	O
between	O
two	O
nodes	O
in	O
a	O
graph	O
,	O
introduced	O
in	O
li2015gated	O
.	O
	
For	O
this	O
task	O
,	O
we	O
created	O
datasets	O
by	O
generating	O
random	O
graphs	O
,	O
and	O
choosing	O
pairs	O
random	O
nodes	O
A	O
and	O
B	O
which	O
are	O
connected	O
by	O
a	O
unique	O
shortest	O
directed	O
path	O
.	O
	
Since	O
we	O
can	O
control	O
the	O
size	O
of	O
generated	O
graphs	O
,	O
we	O
can	O
easily	O
test	O
the	O
performance	O
changes	O
of	O
each	O
model	O
when	O
increasing	O
the	O
size	O
of	O
graphs	O
as	O
well	O
.	O
	
Two	O
such	O
datasets	O
,	O
SP	B-Task
-	O
S	O
and	O
SP	B-Task
-	O
L	O
,	O
were	O
created	O
,	O
containing	O
S	O
mall	O
(	O
node	O
size=5	O
)	O
and	O
L	O
arge	O
graphs	O
(	O
node	O
size=100	O
)	O
,	O
respectively	O
.	O
	
We	O
restricted	O
the	O
length	O
of	O
the	O
generated	O
shortest	O
paths	O
for	O
SP	B-Task
-	O
S	O
to	O
be	O
at	O
least	O
2	O
and	O
at	O
least	O
4	O
for	O
SP	B-Task
-	O
L.	O
	
For	O
each	O
dataset	O
,	O
we	O
used	O
1000	O
training	O
examples	O
and	O
1000	O
development	O
examples	O
for	O
parameter	B-Task
tuning	I-Task
,	O
and	O
evaluated	O
on	O
1000	O
test	O
examples	O
.	O
	
We	O
choose	O
the	O
same	O
baselines	O
as	O
introduced	O
in	O
the	O
previous	O
section	O
.	O
	
Results	O
.	O
	
Table	O
[	O
reference	O
]	O
shows	O
that	O
the	O
LSTM	B-Method
model	I-Method
still	O
fails	O
on	O
both	O
of	O
these	O
two	O
datasets	O
.	O
	
Our	O
Graph2Seq	B-Method
model	I-Method
achieves	O
comparable	O
performance	O
with	O
GGS	B-Method
-	I-Method
NN	I-Method
that	O
both	O
models	O
could	O
achieve	O
100	O
%	O
accuracy	B-Metric
on	O
the	O
SP	B-Task
-	O
S	O
dataset	O
while	O
achieves	O
much	O
better	O
on	O
larger	O
graphs	O
on	O
the	O
SP	B-Task
-	O
L	O
dataset	O
.	O
	
This	O
is	O
because	O
our	O
graph	B-Method
encoder	I-Method
is	O
more	O
expressive	O
in	O
learning	O
the	O
graph	O
structural	O
information	O
with	O
our	O
dual	B-Method
-	I-Method
direction	I-Method
aggregators	I-Method
,	O
which	O
is	O
the	O
key	O
to	O
maintaining	O
good	O
performance	O
when	O
the	O
graph	O
size	O
grows	O
larger	O
,	O
while	O
the	O
performance	O
of	O
GGS	B-Method
-	I-Method
NN	I-Method
significantly	O
degrades	O
due	O
to	O
hardness	O
of	O
capturing	O
the	O
long	O
-	O
range	O
dependence	O
in	O
a	O
graph	O
with	O
large	O
size	O
.	O
	
Compared	O
to	O
GCN	B-Method
,	O
it	O
achieves	O
better	O
performance	O
than	O
GGS	B-Method
-	I-Method
NN	I-Method
but	O
still	O
much	O
lower	O
than	O
our	O
Graph2Seq	B-Method
,	O
in	O
part	O
because	O
of	O
both	O
the	O
poor	O
effectiveness	O
of	O
graph	B-Method
encoder	I-Method
and	O
incapability	O
of	O
handling	O
with	O
directed	O
graph	O
.	O
	
subsection	O
:	O
Natural	B-Task
Language	I-Task
Generation	I-Task
Task	O
	
Setup	O
.	O
	
We	O
finally	O
evaluate	O
our	O
model	O
on	O
a	O
real	O
-	O
world	O
application	O
-	O
Natural	B-Task
Language	I-Task
Generation	I-Task
(	O
NLG	B-Task
)	O
task	O
where	O
we	O
translate	O
a	O
structured	B-Method
semantic	I-Method
representation	I-Method
—	O
in	O
this	O
case	O
	
a	O
structured	B-Method
query	I-Method
language	I-Method
(	O
SQL	B-Method
)	I-Method
query	I-Method
—	O
to	O
a	O
natural	O
language	O
description	O
expressing	O
its	O
meaning	O
.	O
	
As	O
indicated	O
in	O
DBLP	B-Material
:	O
journals	O
/	O
is	O
/	O
SpiliopoulouH92	O
,	O
the	O
structure	O
of	O
SQL	O
query	O
is	O
essentially	O
a	O
graph	O
.	O
	
Thus	O
we	O
naturally	O
cast	O
this	O
task	O
as	O
an	O
application	O
of	O
the	O
graph	B-Method
-	I-Method
to	I-Method
-	I-Method
sequence	I-Method
model	I-Method
which	O
takes	O
a	O
graph	O
representing	O
the	O
semantic	O
structure	O
as	O
input	O
and	O
outputs	O
a	O
sequence	O
.	O
	
Figure	O
[	O
reference	O
]	O
illustrates	O
the	O
process	O
of	O
translation	B-Task
of	O
an	O
SQL	B-Task
query	I-Task
to	O
a	O
corresponding	O
natural	O
language	O
description	O
via	O
our	O
Graph2Seq	B-Method
model	I-Method
.	O
	
We	O
use	O
the	O
BLEU	B-Metric
-	I-Metric
4	I-Metric
score	I-Metric
to	O
evaluate	O
our	O
model	O
on	O
the	O
WikiSQL	B-Material
dataset	I-Material
zhongSeq2SQL2017	O
,	O
a	O
corpus	O
of	O
87	O
,	O
726	O
hand	O
-	O
annotated	O
instances	O
of	O
natural	O
language	O
questions	O
,	O
SQL	O
queries	O
,	O
and	O
SQL	O
tables	O
.	O
	
WikiSQL	B-Material
was	O
created	O
as	O
the	O
benchmark	O
dataset	O
for	O
the	O
table	B-Task
-	I-Task
based	I-Task
question	I-Task
answering	I-Task
task	I-Task
(	O
for	O
which	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
performance	O
is	O
82.6	O
%	O
execution	B-Metric
accuracy	I-Metric
yu2018typesql	O
)	O
;	O
here	O
we	O
reverse	O
the	O
use	O
of	O
the	O
dataset	O
,	O
treating	O
the	O
SQL	O
query	O
as	O
the	O
input	O
and	O
having	O
the	O
goal	O
of	O
generating	O
the	O
correct	O
English	B-Material
question	I-Material
.	O
	
These	O
WikiSQL	B-Material
SQL	O
queries	O
are	O
split	O
into	O
training	O
,	O
development	O
and	O
test	O
sets	O
,	O
which	O
contain	O
61297	O
queries	O
,	O
9145	O
queries	O
and	O
17284	O
queries	O
,	O
respectively	O
.	O
	
Since	O
the	O
SQL	B-Task
-	I-Task
to	I-Task
-	I-Task
Text	I-Task
task	I-Task
can	O
be	O
cast	O
as	O
”	O
machine	B-Task
translation	I-Task
”	O
type	O
of	O
problems	O
,	O
we	O
implemented	O
several	O
baselines	O
to	O
address	O
this	O
task	O
.	O
	
The	O
first	O
one	O
is	O
an	O
attention	B-Method
-	I-Method
based	I-Method
sequence	I-Method
-	I-Method
to	I-Method
-	I-Method
sequence	I-Method
(	O
Seq2Seq	B-Method
)	O
model	O
proposed	O
by	O
bahdanau2014neural	O
;	O
the	O
second	O
one	O
additionally	O
introduces	O
the	O
copy	B-Method
mechanism	I-Method
in	O
the	O
decoder	B-Method
side	I-Method
gu2016incorporating	O
;	O
the	O
third	O
one	O
is	O
a	O
tree	B-Method
-	I-Method
to	I-Method
-	I-Method
sequence	I-Method
(	O
Tree2Seq	B-Method
)	O
model	O
proposed	O
by	O
eriguchi2016tree	O
as	O
our	O
baseline	O
;	O
the	O
fourth	O
one	O
is	O
to	O
combine	O
a	O
GCN	B-Method
kipf2016semi	O
with	O
our	O
PGE	B-Method
graph	I-Method
embeddings	I-Method
with	O
our	O
sequence	B-Method
decoder	I-Method
;	O
the	O
fifth	O
one	O
is	O
to	O
combine	O
a	O
GGS	B-Method
-	I-Method
NN	I-Method
li2015gated	O
with	O
our	O
sequence	B-Method
decoder	I-Method
.	O
	
To	O
apply	O
these	O
baselines	O
,	O
we	O
convert	O
an	O
SQL	O
query	O
to	O
a	O
sequence	O
or	O
a	O
tree	O
using	O
some	O
templates	O
which	O
we	O
discuss	O
in	O
detail	O
in	O
the	O
Appendix	O
.	O
	
Results	O
.	O
	
From	O
Table	O
[	O
reference	O
]	O
,	O
we	O
can	O
see	O
that	O
our	O
Graph2Seq	B-Method
model	I-Method
performs	O
significantly	O
better	O
than	O
the	O
Seq2Seq	B-Method
,	O
Tree2Seq	B-Method
,	O
and	O
Graph2Seq	B-Method
baselines	I-Method
.	O
	
This	O
result	O
is	O
expected	O
since	O
the	O
structure	O
of	O
SQL	O
query	O
is	O
essentially	O
a	O
graph	O
despite	O
its	O
expressions	O
in	O
sequence	O
and	O
a	O
graph	B-Method
encoder	I-Method
is	O
able	O
to	O
capture	O
much	O
more	O
information	O
directly	O
in	O
graph	O
.	O
	
Among	O
all	O
Graph2Seq	B-Method
models	I-Method
,	O
our	O
Graph2Seq	B-Method
model	I-Method
performed	O
best	O
,	O
in	O
part	O
due	O
to	O
a	O
more	O
effective	O
graph	B-Method
encoder	I-Method
.	O
	
Tree2Seq	B-Method
achieves	O
better	O
performance	O
compared	O
to	O
Seq2Seq	B-Method
since	O
its	O
tree	B-Method
-	I-Method
based	I-Method
encoder	I-Method
explicitly	O
takes	O
the	O
syntactic	O
structure	O
of	O
a	O
SQL	O
query	O
into	O
consideration	O
.	O
	
Two	O
variants	O
of	O
the	O
Graph2Seq	B-Method
models	I-Method
can	O
substantially	O
outperform	O
Tree2Seq	B-Method
,	O
which	O
demonstrates	O
that	O
a	O
general	O
graph	B-Method
to	I-Method
sequence	I-Method
model	I-Method
that	O
is	O
independent	O
of	O
different	O
structural	O
information	O
in	O
complex	O
data	O
is	O
very	O
useful	O
.	O
	
Interestingly	O
,	O
we	O
also	O
observe	O
that	O
Graph2Seq	B-Method
-	I-Method
PGE	I-Method
(	O
pooling	B-Method
-	I-Method
based	I-Method
graph	I-Method
embedding	I-Method
)	O
performs	O
better	O
than	O
Graph2Seq	B-Method
-	I-Method
NGE	I-Method
(	O
node	B-Method
-	I-Method
based	I-Method
graph	I-Method
embedding	I-Method
)	O
.	O
	
One	O
potential	O
reason	O
is	O
that	O
the	O
node	B-Method
-	I-Method
based	I-Method
graph	I-Method
embedding	I-Method
method	I-Method
artificially	O
added	O
a	O
super	O
node	O
in	O
graph	O
which	O
changes	O
the	O
original	O
graph	O
topology	O
and	O
brings	O
unnecessary	O
noise	O
into	O
the	O
graph	O
.	O
	
figureA	O
running	O
example	O
of	O
the	O
NLG	B-Task
task	O
.	O
	
subsection	O
:	O
Impacts	O
of	O
Aggregator	B-Method
,	O
Hop	B-Metric
Size	I-Metric
and	O
Attention	B-Method
Mechanism	I-Method
on	O
Garph2Seq	B-Method
Model	I-Method
	
Setup	O
.	O
	
We	O
now	O
investigate	O
the	O
impact	O
of	O
the	O
aggregator	B-Method
and	O
the	O
hop	O
size	O
on	O
the	O
Graph2Seq	B-Method
model	I-Method
.	O
	
Following	O
the	O
previous	O
SP	B-Task
task	O
,	O
we	O
further	O
create	O
three	O
synthetic	O
datasets	O
:	O
i	O
)	O
SDP⁢DAG	O
whose	O
graphs	O
are	O
directed	O
acyclic	O
graphs	O
(	O
DAGs	O
)	O
;	O
ii	O
)	O
SDP⁢DCG	O
whose	O
graphs	O
are	O
directed	B-Method
cyclic	I-Method
graphs	I-Method
(	O
DCGs	B-Method
)	O
that	O
always	O
contain	O
cycles	O
;	O
iii	O
)	O
SDP⁢SEQ	O
whose	O
graphs	O
are	O
essentially	O
sequential	O
lines	O
.	O
	
For	O
each	O
dataset	O
,	O
we	O
randomly	O
generated	O
10000	O
graphs	O
with	O
the	O
graph	O
size	O
100	O
and	O
split	O
them	O
as	O
8000	O
/	O
1000	O
/	O
1000	O
for	O
the	O
training	O
/	O
development	O
/	O
test	O
set	O
.	O
	
For	O
each	O
graph	O
,	O
we	O
generated	O
an	O
SDP	B-Material
query	O
by	O
choosing	O
two	O
random	O
nodes	O
with	O
the	O
constraints	O
that	O
there	O
should	O
be	O
a	O
unique	O
shortest	O
path	O
connecting	O
these	O
two	O
nodes	O
,	O
and	O
that	O
its	O
length	O
should	O
be	O
at	O
least	O
4	O
.	O
	
We	O
create	O
six	O
variants	O
of	O
the	O
Graph2Seq	B-Method
model	I-Method
coupling	I-Method
with	O
different	O
aggregation	B-Method
strategies	I-Method
in	O
the	O
node	B-Task
embedding	I-Task
generation	I-Task
.	O
	
The	O
first	O
three	O
(	O
Graph2Seq	B-Method
-	I-Method
MA	I-Method
,	O
-	O
LA	O
,	O
-	O
PA	O
)	O
use	O
the	O
M	B-Method
ean	I-Method
A	I-Method
ggregator	I-Method
,	O
L	O
STM	O
	
A	O
ggregator	B-Method
and	O
P	B-Method
ooling	I-Method
A	O
ggregator	B-Method
to	O
aggregate	O
node	O
neighbor	O
information	O
,	O
respectively	O
.	O
	
Unlike	O
these	O
three	O
models	O
that	O
aggregate	O
the	O
information	O
of	O
both	O
forward	O
and	O
backward	O
nodes	O
,	O
the	O
other	O
two	O
models	O
(	O
Graph2Seq	B-Method
-	I-Method
MA	I-Method
-	I-Method
F	I-Method
,	O
-	O
MA	O
-	O
B	O
)	O
only	O
consider	O
one	O
-	O
way	O
information	O
aggregating	O
the	O
information	O
from	O
the	O
forward	O
nodes	O
or	O
the	O
information	O
from	O
the	O
backward	O
nodes	O
with	O
the	O
mean	B-Method
aggregator	I-Method
,	O
respectively	O
.	O
	
We	O
use	O
the	O
path	B-Metric
accuracy	I-Metric
to	O
evaluate	O
these	O
models	O
.	O
	
The	O
hop	O
size	O
is	O
set	O
to	O
10	O
.	O
	
Impacts	O
of	O
the	O
Aggregator	B-Method
.	O
	
Table	O
[	O
reference	O
]	O
shows	O
that	O
on	O
the	O
SDP	B-Material
dataset	O
,	O
both	O
Graph2Seq	B-Method
-	I-Method
MA	I-Method
and	O
Graph2Seq	B-Method
-	I-Method
PA	I-Method
achieve	O
the	O
best	O
performance	O
.	O
	
On	O
more	O
complicated	O
structured	O
data	O
,	O
such	O
as	O
SDP	B-Material
and	O
SDP	B-Material
,	O
Graph2Seq	B-Method
-	I-Method
MA	I-Method
(	O
our	O
default	B-Method
model	I-Method
)	O
also	O
performs	O
better	O
than	O
other	O
variants	O
.	O
	
We	O
can	O
also	O
see	O
that	O
Graph2Seq	B-Method
-	I-Method
MA	I-Method
performs	O
better	O
than	O
Graph2Seq	B-Method
-	I-Method
MA	I-Method
-	I-Method
F	I-Method
and	O
Graph2Seq	B-Method
-	I-Method
MA	I-Method
-	I-Method
B	I-Method
on	O
SDP	B-Material
and	O
SDP	B-Material
since	O
it	O
captures	O
more	O
information	O
from	O
both	O
directions	O
to	O
learn	O
better	O
node	O
embeddings	O
.	O
	
However	O
,	O
Graph2Seq	B-Method
-	I-Method
MA	I-Method
-	I-Method
F	I-Method
and	O
Graph2Seq	B-Method
-	I-Method
MA	I-Method
-	I-Method
B	I-Method
achieve	O
comparable	O
performance	O
to	O
Graph2Seq	B-Method
-	I-Method
MA	I-Method
on	O
SDP	B-Material
.	O
	
This	O
is	O
because	O
in	O
almost	O
95	O
%	O
of	O
the	O
graphs	O
,	O
90	O
%	O
of	O
the	O
nodes	O
could	O
reach	O
each	O
other	O
by	O
traversing	O
the	O
graph	O
for	O
a	O
given	O
hop	O
size	O
,	O
which	O
dramatically	O
restores	O
its	O
information	O
loss	O
.	O
	
figureTest	O
Results	O
on	O
SDP	B-Material
.	O
	
Impact	O
of	O
Hop	B-Metric
Size	I-Metric
.	O
	
To	O
study	O
the	O
impact	O
of	O
the	O
hop	O
size	O
,	O
we	O
create	O
a	O
SDP	B-Material
dataset	O
,	O
SDP	B-Material
and	O
results	O
are	O
shown	O
in	O
Figure	O
[	O
reference	O
]	O
.	O
	
We	O
see	O
that	O
the	O
performance	O
of	O
all	O
variants	O
of	O
Graph2Seq	B-Method
converges	O
to	O
its	O
optimal	O
performance	O
when	O
increasing	O
the	O
number	O
of	O
hop	B-Metric
size	I-Metric
.	O
	
Specifically	O
,	O
Graph2Seq	B-Method
-	I-Method
MA	I-Method
achieves	O
significantly	O
better	O
performance	O
than	O
its	O
counterparts	O
considering	O
only	O
one	O
direction	O
propagation	O
,	O
especially	O
when	O
the	O
hop	B-Metric
size	I-Metric
is	O
small	O
.	O
	
As	O
the	O
hop	O
size	O
increases	O
,	O
the	O
performance	O
differences	O
diminish	O
.	O
	
This	O
is	O
the	O
desired	O
property	O
since	O
Graph2Seq	B-Method
-	I-Method
MA	I-Method
can	O
use	O
much	O
smaller	O
hop	O
size	O
(	O
about	O
the	O
half	O
)	O
to	O
achieve	O
the	O
same	O
performance	O
of	O
Graph2Seq	B-Method
-	I-Method
MA	I-Method
-	I-Method
F	I-Method
or	O
Graph2Seq	B-Method
-	I-Method
MA	I-Method
-	I-Method
B	I-Method
with	O
a	O
larger	O
size	O
.	O
	
This	O
is	O
particularly	O
useful	O
for	O
large	O
graphs	O
where	O
increasing	O
hop	O
size	O
may	O
need	O
considerable	O
computing	O
resources	O
and	O
long	O
run	O
-	O
time	O
.	O
	
We	O
also	O
compare	O
Graph2Seq	B-Method
with	O
GCN	B-Method
,	O
where	O
the	O
hop	O
size	O
means	O
the	O
number	O
of	O
layers	O
in	O
the	O
settings	O
of	O
GCN	B-Method
.	O
	
Surprisingly	O
,	O
even	O
Graph2Seq	B-Method
-	I-Method
MA	I-Method
-	I-Method
F	I-Method
or	O
Graph2Seq	B-Method
-	I-Method
MA	I-Method
-	I-Method
B	I-Method
can	O
significantly	O
outperform	O
GCN	B-Method
with	O
the	O
same	O
hope	O
size	O
despite	O
its	O
rough	O
equivalence	O
between	O
these	O
two	O
architectures	O
.	O
	
It	O
again	O
illustrates	O
the	O
importance	O
of	O
the	O
methods	O
that	O
could	O
take	O
into	O
account	O
both	O
directed	O
and	O
undirected	O
graphs	O
.	O
	
For	O
additional	O
experimental	O
results	O
on	O
the	O
impact	O
of	O
hop	B-Metric
size	I-Metric
for	O
graphs	O
of	O
different	O
sizes	O
,	O
please	O
refer	O
to	O
the	O
Table	O
4	O
in	O
Appendix	O
C.	O
Impact	O
of	O
Attention	B-Method
Mechanism	I-Method
.	O
	
To	O
investigate	O
the	O
impact	O
of	O
attention	B-Method
mechanism	I-Method
to	O
the	O
Graph2Seq	B-Method
model	I-Method
,	O
we	O
still	O
evaluate	O
our	O
model	O
on	O
SDP	B-Material
,	O
SDP	B-Material
and	O
SDP	B-Material
datasets	I-Material
but	O
without	O
considering	O
the	O
attention	B-Method
strategy	I-Method
.	O
	
As	O
shown	O
in	O
Table	O
4	O
,	O
we	O
find	O
that	O
the	O
attention	B-Method
strategy	I-Method
significantly	O
improves	O
the	O
performance	O
of	O
all	O
variants	O
of	O
Graph2Seq	B-Method
by	O
at	O
least	O
14.9	O
%	O
.	O
	
This	O
result	O
is	O
expected	O
since	O
for	O
larger	O
graphs	O
it	O
is	O
more	O
difficult	O
for	O
the	O
encoder	B-Method
to	O
compress	O
all	O
necessary	O
information	O
into	O
a	O
fixed	O
-	O
length	O
vector	O
;	O
as	O
intended	O
,	O
applying	O
the	O
attention	B-Method
mechanism	I-Method
in	O
decoding	B-Task
enabled	O
our	O
proposed	O
Graph2Seq	B-Method
model	I-Method
to	O
successfully	O
handle	O
large	O
graphs	O
.	O
	
section	O
:	O
Conclusion	O
	
In	O
this	O
paper	O
,	O
we	O
study	O
the	O
graph	B-Task
-	I-Task
to	I-Task
-	I-Task
sequence	I-Task
problem	I-Task
,	O
introducing	O
a	O
new	O
general	O
and	O
flexible	O
Graph2Seq	B-Method
model	O
that	O
follows	O
the	O
encoder	B-Method
-	I-Method
decoder	I-Method
architecture	I-Method
.	O
	
We	O
showed	O
that	O
,	O
using	O
our	O
proposed	O
bi	B-Method
-	I-Method
directional	I-Method
node	I-Method
embedding	I-Method
aggregation	I-Method
strategy	I-Method
,	O
the	O
graph	B-Method
encoder	I-Method
could	O
successfully	O
learn	O
representations	O
for	O
three	O
representative	O
classes	O
of	O
directed	O
graph	O
,	O
i.e.	O
,	O
directed	O
acyclic	O
graphs	O
,	O
directed	O
cyclic	O
graphs	O
and	O
sequence	O
-	O
styled	O
graphs	O
.	O
	
Experimental	O
results	O
on	O
three	O
tasks	O
demonstrate	O
that	O
our	O
model	O
significantly	O
outperforms	O
existing	O
graph	B-Method
neural	I-Method
networks	I-Method
,	O
Seq2Seq	B-Method
,	O
and	O
Tree2Seq	B-Method
baselines	O
on	O
both	O
synthetic	O
and	O
real	O
application	O
datasets	O
.	O
	
We	O
also	O
showed	O
that	O
introducing	O
an	O
attention	B-Method
mechanism	I-Method
over	O
node	B-Method
representation	I-Method
into	O
the	O
decoding	B-Task
substantially	O
enhances	O
the	O
ability	O
of	O
our	O
model	O
to	O
produce	O
correct	O
target	O
sequences	O
from	O
large	O
graphs	O
.	O
	
Since	O
much	O
symbolic	O
data	O
is	O
represented	O
as	O
graphs	O
and	O
many	O
tasks	O
express	O
their	O
desired	O
outputs	O
as	O
sequences	O
,	O
we	O
expect	O
Graph2Seq	B-Method
to	O
be	O
broadly	O
applicable	O
to	O
unify	O
symbolic	B-Task
AI	I-Task
and	O
beyond	O
.	O
	
bibliography	O
:	O
References	O
	
appendix	O
:	O
Pseudo	O
-	O
code	O
of	O
the	O
Graph	B-Method
-	I-Method
to	I-Method
-	I-Method
sequence	I-Method
Algorithm	I-Method
	
[	O
h	O
]	O
Node	B-Method
embedding	I-Method
generation	I-Method
algorithm	I-Method
{	O
algorithmic}	O
[	O
1	O
]	O
Graph	O
⁢G	O
(	O
V	O
,	O
E	O
)	O
;	O
node	O
initial	O
feature	O
vector	O
av	O
,	O
∈∀vV	O
;	O
	
hops	O
K	O
;	O
weight	O
matrices	O
	
Wk	O
,	O
∈∀k{1	O
,	O
…	O
,	O
K	O
}	O
;	O
non	O
-	O
linearity	O
σ	O
;	O
aggregator	O
functions	O
AGGREGATEk⊢	O
,	O
AGGREGATEk⊣	O
,	O
	
∈∀k{1	O
,	O
…	O
,	O
K	O
}	O
;	O
neighborhood	O
functions	O
N⊢	O
,	O
	
N⊣	O
Vector	B-Method
representations	I-Method
zv	O
for	O
all	O
∈vV	O
←	O
av	O
,	O
	
∈∀vV	O
←	O
av	O
,	O
∈∀vV	O
←	O
AGGREGATEk⊢	O
(	O
{h⊢u	O
-	O
k1	O
,	O
∈∀u⁢N⊢	O
(	O
v	O
)	O
}	O
)	O
	
←	O
σ	O
	
(	O
W⋅k	O
CONCAT	O
(	O
h⊢v	O
-	O
k1	O
,	O
h⁢N⊢	O
(	O
v	O
)	O
k	O
)	O
)	O
	
h⁢N⊣	O
(	O
v	O
)	O
k	O
←	O
	
AGGREGATEk⊣	O
(	O
{h⊣u	O
-	O
k1	O
,	O
∈∀u⁢N⊣	O
(	O
v	O
)	O
}	O
)	O
	
←	O
σ	O
	
(	O
W⋅k	O
CONCAT	O
(	O
h⊣v	O
-	O
k1	O
,	O
h⁢N⊣	O
(	O
v	O
)	O
k	O
)	O
)	O
	
←	O
CONCAT	B-Method
(	I-Method
h⊢vK	I-Method
,	O
h⊣vK	O
)	O
,	O
∈∀vV	O
Algorithm	O
[	O
reference	O
]	O
describes	O
the	O
embedding	B-Task
generation	I-Task
process	I-Task
where	O
the	O
entire	O
graph	O
and	O
initial	O
feature	O
vectors	O
for	O
all	O
nodes	O
av	O
,	O
,	O
are	O
provided	O
as	O
input	O
.	O
	
Here	O
denotes	O
the	O
current	O
hop	O
in	O
the	O
outer	O
loop	O
.	O
	
The	O
h⊢vk	O
denotes	O
node	B-Method
’s	I-Method
forward	I-Method
representation	I-Method
which	O
aggregates	O
the	O
information	O
of	O
nodes	O
in	O
.	O
	
Similarly	O
,	O
the	O
h⊣vk	O
denotes	O
node	O
’s	O
backward	B-Method
representation	I-Method
which	O
is	O
generated	O
by	O
aggregating	O
the	O
information	O
of	O
nodes	O
in	O
.	O
	
Each	O
step	O
in	O
the	O
outer	O
loop	O
of	O
Algorithm	O
[	O
reference	O
]	O
proceeds	O
as	O
follows	O
.	O
	
First	O
,	O
each	O
node	O
in	O
a	O
graph	O
aggregates	O
the	O
forward	O
representations	O
of	O
the	O
nodes	O
in	O
its	O
immediate	O
neighborhood	O
,	O
{	O
h⊢u	O
-	O
k1	O
,	O
}	O
,	O
into	O
a	O
single	O
vector	O
,	O
h⁢N⊢	O
(	O
v	O
)	O
k	O
(	O
line	O
5	O
)	O
.	O
	
Note	O
that	O
this	O
aggregation	B-Method
step	I-Method
depends	O
on	O
the	O
representations	O
generated	O
at	O
the	O
previous	O
iteration	O
of	O
the	O
outer	B-Method
loop	I-Method
,	O
,	O
and	O
the	O
forward	B-Method
representations	I-Method
are	O
defined	O
as	O
the	O
input	O
node	O
feature	O
vector	O
.	O
	
After	O
aggregating	O
the	O
neighboring	O
feature	O
vectors	O
,	O
we	O
concatenate	O
the	O
node	B-Method
current	I-Method
forward	I-Method
representation	I-Method
,	O
h⊢v	B-Method
-	I-Method
k1	I-Method
,	O
with	O
the	O
aggregated	O
neighborhood	O
vector	O
,	O
h⁢N⊢	O
(	O
v	O
)	O
k	O
.	O
	
Then	O
this	O
concatenated	O
vector	O
is	O
fed	O
through	O
a	O
fully	B-Method
connected	I-Method
layer	I-Method
with	O
nonlinear	B-Method
activation	I-Method
function	I-Method
,	O
which	O
updates	O
the	O
forward	B-Method
representation	I-Method
of	O
the	O
current	O
node	O
to	O
be	O
used	O
at	O
the	O
next	O
step	O
of	O
the	O
algorithm	O
(	O
line	O
6	O
)	O
.	O
	
We	O
apply	O
similar	O
process	O
to	O
generate	O
the	O
backward	O
representations	O
of	O
the	O
nodes	O
(	O
line	O
7	O
,	O
8	O
)	O
.	O
	
Finally	O
,	O
the	O
representation	O
of	O
each	O
node	O
zv	O
is	O
the	O
concatenation	O
of	O
the	O
forward	B-Method
representation	I-Method
(	O
i.e.	O
,	O
h⊢vK	O
)	O
and	O
the	O
backward	B-Method
representation	I-Method
(	O
i.e.	O
,	O
h⊣vK	O
)	O
at	O
the	O
last	O
iteration	O
.	O
	
appendix	O
:	O
Structured	B-Method
Representation	I-Method
of	O
the	O
SQL	B-Method
Query	I-Method
	
To	O
apply	O
Graph2Seq	B-Method
,	O
Seq2Seq	B-Method
and	O
Tree2Seq	B-Method
models	I-Method
on	O
the	O
natural	B-Task
language	I-Task
generation	I-Task
task	I-Task
,	O
we	O
need	O
to	O
convert	O
the	O
SQL	O
query	O
to	O
a	O
graph	O
,	O
sequence	O
and	O
tree	O
,	O
respectively	O
.	O
	
In	O
this	O
section	O
,	O
we	O
describe	O
these	O
representations	O
of	O
the	O
SQL	B-Task
query	I-Task
.	O
	
subsection	O
:	O
Sequence	B-Method
Representation	I-Method
	
We	O
apply	O
a	O
simple	O
template	O
to	O
construct	O
the	O
SQL	O
query	O
sequence	O
:	O
“	O
SELECT	O
+	O
aggregation	O
function	O
>	O
+	O
Split	O
Symbol	O
+	O
selected	O
column	O
>	O
	
+	O
WHERE	O
	
+	O
condition0	O
>	O
+	O
Split	O
Symbol	O
+	O
condition1	O
>	O
+	O
	
…	O
”	O
.	O
	
subsection	O
:	O
Tree	B-Method
Representation	I-Method
	
We	O
apply	O
the	O
SQL	B-Method
Parser	I-Method
tool	I-Method
to	O
convert	O
an	O
SQL	O
query	O
to	O
a	O
tree	O
which	O
is	O
illustrated	O
in	O
Figure	O
[	O
reference	O
]	O
.	O
	
Specifically	O
,	O
the	O
root	O
of	O
this	O
tree	O
has	O
two	O
child	O
nodes	O
,	O
namely	O
SELECT	O
LIST	O
and	O
WHERE	O
CLAUSE	O
.	O
	
The	O
child	O
nodes	O
of	O
SELECT	O
LIST	O
node	O
are	O
the	O
selected	O
columns	O
in	O
the	O
SQL	O
query	O
.	O
	
The	O
WHERE	O
CLAUSE	O
node	O
has	O
all	O
occurred	O
logical	O
operators	O
in	O
the	O
SQL	O
query	O
as	O
its	O
children	O
.	O
	
The	O
children	O
of	O
a	O
logical	O
operator	O
node	O
are	O
the	O
columns	O
on	O
which	O
this	O
operator	O
works	O
.	O
	
subsection	O
:	O
Graph	B-Method
Representation	I-Method
	
We	O
use	O
the	O
following	O
method	O
to	O
transform	O
the	O
SQL	O
query	O
to	O
a	O
graph	O
:	O
SELECT	O
Clause	O
.	O
	
For	O
the	O
SELECT	O
clause	O
such	O
as	O
“	O
SELECT	O
company	O
”	O
,	O
we	O
first	O
create	O
a	O
node	O
assigned	O
with	O
text	O
attribute	O
select	O
.	O
	
This	O
SELECT	O
node	O
connects	O
with	O
column	O
nodes	O
whose	O
text	O
attributes	O
are	O
the	O
selected	O
column	O
names	O
such	O
as	O
company	O
.	O
	
For	O
the	O
SQL	O
queries	O
that	O
contain	O
aggregation	O
functions	O
such	O
as	O
count	O
or	O
max	O
,	O
we	O
add	O
one	O
aggregation	O
node	O
which	O
is	O
connected	O
with	O
the	O
column	O
node	O
	
—	O
	
their	O
text	O
attributes	O
are	O
the	O
aggregation	O
function	O
names	O
.	O
	
WHERE	O
Clause	O
.	O
	
The	O
WHERE	O
clause	O
usually	O
contains	O
more	O
than	O
one	O
condition	O
.	O
	
For	O
each	O
condition	O
,	O
we	O
use	O
the	O
same	O
process	O
as	O
for	O
the	O
SELECT	O
clause	O
to	O
create	O
nodes	O
.	O
	
For	O
example	O
,	O
in	O
Figure	O
[	O
reference	O
]	O
,	O
we	O
create	O
node	O
assets	O
and	O
for	O
the	O
first	O
condition	O
,	O
the	O
node	O
sales	O
and	O
for	O
the	O
second	O
condition	O
.	O
	
We	O
then	O
integrate	O
the	O
constraint	O
nodes	O
that	O
have	O
the	O
same	O
text	O
attribute	O
(	O
e.g.	O
,	O
in	O
Figure	O
[	O
reference	O
]	O
)	O
.	O
	
For	O
a	O
logical	O
operator	O
such	O
as	O
AND	O
,	O
OR	O
and	O
NOT	O
,	O
we	O
create	O
a	O
node	O
that	O
connects	O
with	O
all	O
column	O
nodes	O
that	O
the	O
operator	O
works	O
on	O
(	O
e.g.	O
,	O
AND	O
in	O
Figure	O
[	O
reference	O
]	O
)	O
.	O
	
These	O
logical	O
operator	O
nodes	O
then	O
connect	O
with	O
SELECT	O
node	O
.	O
	
appendix	O
:	O
More	O
Results	O
on	O
the	O
Impact	O
of	O
Hop	B-Metric
Size	I-Metric
	
In	O
Algorithm	O
[	O
reference	O
]	O
,	O
we	O
can	O
see	O
that	O
there	O
are	O
three	O
key	O
factors	O
in	O
the	O
node	B-Task
embedding	I-Task
generation	I-Task
.	O
	
The	O
first	O
factor	O
is	O
the	O
aggregator	O
choice	O
which	O
determines	O
how	O
information	O
from	O
neighborhood	O
nodes	O
is	O
combined	O
.	O
	
The	O
other	O
two	O
are	O
the	O
hop	O
size	O
(	O
)	O
and	O
the	O
neighborhood	O
function	O
(	O
,	O
)	O
,	O
which	O
together	O
determine	O
which	O
neighbor	O
nodes	O
should	O
be	O
aggregated	O
to	O
generate	O
each	O
node	O
embedding	O
.	O
	
To	O
study	O
the	O
impact	O
of	O
the	O
hop	O
size	O
in	O
our	O
model	O
,	O
we	O
create	O
two	O
SDP	B-Material
datasets	I-Material
,	O
SDP	B-Material
and	O
SDP	B-Material
,	O
where	O
each	O
graph	O
has	O
100	O
nodes	O
or	O
1000	O
nodes	O
,	O
respectively	O
.	O
	
Both	O
of	O
these	O
two	O
datasets	O
contain	O
8000	O
training	O
examples	O
,	O
1000	O
dev	O
examples	O
and	O
1000	O
test	O
examples	O
.	O
	
We	O
evaluated	O
three	O
models	O
,	O
Graph2Seq	B-Method
-	I-Method
MA	I-Method
-	I-Method
F	I-Method
,	O
Graph2Seq	B-Method
-	I-Method
MA	I-Method
-	I-Method
B	I-Method
and	O
Graph2Seq	B-Method
-	I-Method
MA	I-Method
,	O
on	O
these	O
two	O
datasets	O
;	O
results	O
are	O
listed	O
in	O
Table	O
[	O
reference	O
]	O
.	O
	
We	O
see	O
that	O
Graph2Seq	B-Method
-	I-Method
MA	I-Method
-	I-Method
F	I-Method
and	O
Graph2Seq	B-Method
-	I-Method
MA	I-Method
-	I-Method
B	I-Method
could	O
show	O
significant	O
performance	O
improvements	O
with	O
increasing	O
the	O
hop	B-Metric
size	I-Metric
.	O
	
Specifically	O
,	O
on	O
the	O
SDP	B-Material
dataset	O
,	O
Graph2Seq	B-Method
-	I-Method
MA	I-Method
-	I-Method
F	I-Method
and	O
Graph2Seq	B-Method
-	I-Method
MA	I-Method
-	I-Method
B	I-Method
achieve	O
their	O
best	O
performance	O
when	O
the	O
hop	B-Metric
size	I-Metric
reaches	O
7	O
;	O
further	O
increases	O
do	O
not	O
improve	O
the	O
overall	O
performance	O
.	O
	
A	O
similar	O
situation	O
is	O
also	O
observed	O
on	O
the	O
SDP	B-Material
dataset	O
;	O
performance	O
converges	O
at	O
the	O
hop	B-Metric
size	I-Metric
of	O
85	O
.	O
	
Interestingly	O
,	O
the	O
average	O
diameters	O
of	O
the	O
graphs	O
in	O
the	O
two	O
datasets	O
are	O
6.8	O
and	O
80.2	O
,	O
respectively	O
,	O
suggesting	O
that	O
the	O
ideal	O
hop	B-Metric
size	I-Metric
for	O
best	O
Graph2Seq	B-Method
-	I-Method
MA	I-Method
-	I-Method
F	I-Method
performance	O
should	O
be	O
the	O
graph	O
diameter	O
.	O
	
This	O
should	O
not	O
be	O
surprising	O
;	O
if	O
the	O
hop	O
size	O
equals	O
the	O
graph	O
diameter	O
,	O
each	O
node	O
is	O
guaranteed	O
to	O
aggregate	O
the	O
information	O
of	O
all	O
reachable	O
nodes	O
on	O
the	O
graph	O
within	O
its	O
embedding	O
.	O
	
Note	O
that	O
in	O
the	O
experiments	O
on	O
SDP	B-Material
,	O
in	O
the	O
(	O
¿	O
10	O
)	O
hop	O
,	O
we	O
always	O
use	O
the	O
aggregator	O
in	O
the	O
10	O
-	O
th	O
hop	O
,	O
because	O
introducing	O
too	O
many	O
aggregators	O
(	O
i.e.	O
,	O
parameters	O
)	O
may	O
make	O
the	O
model	O
over	O
-	O
fitting	O
.	O
	
Like	O
Graph2Seq	B-Method
-	I-Method
MA	I-Method
-	I-Method
F	I-Method
,	O
Graph2Seq	B-Method
-	I-Method
MA	I-Method
also	O
benefited	O
from	O
increasing	O
the	O
hop	B-Metric
size	I-Metric
.	O
	
However	O
,	O
on	O
both	O
datasets	O
,	O
Graph2Seq	B-Method
-	I-Method
MA	I-Method
could	O
reach	O
peak	O
performance	O
at	O
a	O
smaller	O
hop	B-Metric
size	I-Metric
than	O
Graph2Seq	B-Method
-	I-Method
MA	I-Method
-	I-Method
F.	I-Method
	
For	O
example	O
,	O
on	O
the	O
SDP	B-Material
dataset	O
,	O
Graph2Seq	B-Method
-	I-Method
MA	I-Method
achieves	O
99.2	O
%	O
accuracy	B-Metric
once	O
the	O
hop	B-Metric
size	I-Metric
is	O
greater	O
than	O
4	O
while	O
Graph2Seq	B-Method
-	I-Method
MA	I-Method
-	I-Method
F	I-Method
requires	O
a	O
hop	O
size	O
greater	O
than	O
7	O
to	O
achieve	O
comparable	O
accuracy	B-Metric
;	O
similar	O
observations	O
hold	O
for	O
the	O
SDP	B-Material
dataset	O
.	O
	
Moreover	O
,	O
we	O
can	O
see	O
that	O
the	O
minimum	B-Metric
required	I-Metric
hop	I-Metric
size	I-Metric
that	O
Graph2Seq	B-Method
-	I-Method
MA	I-Method
could	O
achieve	O
its	O
best	O
performance	O
is	O
approximately	O
the	O
average	B-Metric
radii	I-Metric
(	O
c.f	O
.	O
diameter	B-Metric
)	O
of	O
the	O
graphs	O
,	O
which	O
are	O
3.4	O
and	O
40.1	O
,	O
respectively	O
.	O
	
Recall	O
that	O
the	O
main	O
difference	O
between	O
Graph2Seq	B-Method
-	I-Method
MA	I-Method
and	O
Graph2Seq	B-Method
-	I-Method
MA	I-Method
-	I-Method
F	I-Method
(	O
or	O
Graph2Seq	B-Method
-	I-Method
MA	I-Method
-	I-Method
B	I-Method
)	O
lies	O
in	O
whether	O
the	O
system	O
aggregates	O
information	O
propagated	O
from	O
backward	O
nodes	O
;	O
the	O
performance	O
difference	O
indicates	O
that	O
by	O
incorporating	O
forward	O
and	O
backward	O
nodes	O
’	O
information	O
,	O
it	O
is	O
possible	O
for	O
the	O
model	O
to	O
achieve	O
the	O
best	O
performance	O
by	O
traversing	O
less	O
of	O
the	O
graph	O
.	O
	
This	O
is	O
useful	O
in	O
practice	O
,	O
especially	O
for	O
large	O
graphs	O
where	O
increasing	O
hop	O
size	O
may	O
consume	O
considerable	O
computing	O
resources	O
and	O
run	B-Metric
-	I-Metric
time	I-Metric
.	O
	
Table	O
[	O
reference	O
]	O
also	O
makes	O
clear	O
the	O
utility	O
of	O
the	O
attention	B-Method
strategy	I-Method
;	O
the	O
performance	O
of	O
both	O
Graph2Seq	B-Method
-	I-Method
MA	I-Method
-	I-Method
F	I-Method
and	O
Graph2Seq	B-Method
-	I-Method
MA	I-Method
decreases	O
by	O
at	O
least	O
9.8	O
%	O
on	O
SDP	B-Material
and	O
14.9	O
%	O
on	O
SDP	B-Material
.	O
	
This	O
result	O
is	O
expected	O
,	O
since	O
for	O
larger	O
graphs	O
it	O
is	O
more	O
difficult	O
for	O
the	O
encoder	B-Method
to	O
compress	O
all	O
necessary	O
information	O
into	O
a	O
fixed	O
-	O
length	O
vector	O
;	O
as	O
intended	O
,	O
applying	O
the	O
attention	B-Method
mechanism	I-Method
in	O
decoding	B-Task
enabled	O
our	O
proposed	O
Graph2Seq	B-Method
model	I-Method
to	O
handle	O
large	B-Task
graphs	I-Task
successfully	O
.	O
	
As	O
shown	O
in	O
Algorithm	O
[	O
reference	O
]	O
,	O
the	O
neighborhood	B-Method
function	I-Method
takes	O
a	O
given	O
node	O
as	O
input	O
and	O
returns	O
its	O
directly	O
connected	O
neighbor	O
nodes	O
,	O
which	O
are	O
then	O
fed	O
to	O
the	O
node	B-Method
embedding	I-Method
generator	I-Method
.	O
	
Intuitively	O
,	O
to	O
obtain	O
a	O
better	O
representation	O
of	O
a	O
node	O
,	O
this	O
function	O
should	O
return	O
all	O
its	O
neighbor	O
nodes	O
in	O
the	O
graph	O
.	O
	
However	O
,	O
this	O
may	O
result	O
in	O
high	O
training	B-Metric
times	I-Metric
on	O
large	O
graphs	O
.	O
	
To	O
address	O
this	O
,	O
hamilton2017inductive	B-Method
proposes	O
a	O
sampling	B-Method
method	I-Method
which	O
randomly	O
selects	O
a	O
fixed	O
number	O
of	O
neighbor	O
nodes	O
from	O
which	O
to	O
aggregate	O
information	O
at	O
each	O
hop	O
.	O
	
We	O
use	O
this	O
sampling	B-Method
method	I-Method
to	O
manage	O
the	O
neighbor	O
node	O
size	O
at	O
each	O
aggregation	O
step	O
.	O
	
document	O
:	O
You	O
Only	O
Look	O
Once	O
:	O
Unified	O
,	O
Real	B-Task
-	I-Task
Time	I-Task
Object	I-Task
Detection	I-Task
	
We	O
present	O
YOLO	B-Method
,	O
a	O
new	O
approach	O
to	O
object	B-Task
detection	I-Task
.	O
	
Prior	O
work	O
on	O
object	B-Task
detection	I-Task
repurposes	O
classifiers	B-Method
to	O
perform	O
detection	B-Task
.	O
	
Instead	O
,	O
we	O
frame	O
object	B-Task
detection	I-Task
as	O
a	O
regression	B-Task
problem	I-Task
to	O
spatially	O
separated	O
bounding	O
boxes	O
and	O
associated	O
class	O
probabilities	O
.	O
	
A	O
single	O
neural	B-Method
network	I-Method
predicts	O
bounding	O
boxes	O
and	O
class	O
probabilities	O
directly	O
from	O
full	O
images	O
in	O
one	O
evaluation	O
.	O
	
Since	O
the	O
whole	O
detection	B-Method
pipeline	I-Method
is	O
a	O
single	O
network	O
,	O
it	O
can	O
be	O
optimized	O
end	O
-	O
to	O
-	O
end	O
directly	O
on	O
detection	B-Task
performance	O
.	O
	
Our	O
unified	B-Method
architecture	I-Method
is	O
extremely	O
fast	O
.	O
	
Our	O
base	O
YOLO	B-Method
model	O
processes	O
images	O
in	O
real	O
-	O
time	O
at	O
45	O
frames	O
per	O
second	O
.	O
	
A	O
smaller	O
version	O
of	O
the	O
network	O
,	O
Fast	O
YOLO	B-Method
,	O
processes	O
an	O
astounding	O
155	O
frames	O
per	O
second	O
while	O
still	O
achieving	O
double	O
the	O
mAP	B-Metric
of	O
other	O
real	B-Method
-	I-Method
time	I-Method
detectors	I-Method
.	O
	
Compared	O
to	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
detection	B-Method
systems	I-Method
,	O
YOLO	B-Method
makes	O
more	O
localization	O
errors	O
but	O
is	O
less	O
likely	O
to	O
predict	O
false	O
positives	O
on	O
background	O
.	O
	
Finally	O
,	O
YOLO	B-Method
learns	O
very	O
general	O
representations	B-Method
of	I-Method
objects	I-Method
.	O
	
It	O
outperforms	O
other	O
detection	B-Method
methods	I-Method
,	O
including	O
DPM	B-Method
and	O
R	B-Method
-	I-Method
CNN	I-Method
,	O
when	O
generalizing	O
from	O
natural	O
images	O
to	O
other	O
domains	O
like	O
artwork	O
.	O
	
section	O
:	O
Introduction	O
	
Humans	O
glance	O
at	O
an	O
image	O
and	O
instantly	O
know	O
what	O
objects	O
are	O
in	O
the	O
image	O
,	O
where	O
they	O
are	O
,	O
and	O
how	O
they	O
interact	O
.	O
	
The	O
human	B-Method
visual	I-Method
system	I-Method
is	O
fast	O
and	O
accurate	O
,	O
allowing	O
us	O
to	O
perform	O
complex	O
tasks	O
like	O
driving	B-Task
with	O
little	O
conscious	O
thought	O
.	O
	
Fast	O
,	O
accurate	O
algorithms	O
for	O
object	B-Task
detection	I-Task
would	O
allow	O
computers	O
to	O
drive	O
cars	O
without	O
specialized	O
sensors	O
,	O
enable	O
assistive	O
devices	O
to	O
convey	O
real	O
-	O
time	O
scene	O
information	O
to	O
human	O
users	O
,	O
and	O
unlock	O
the	O
potential	O
for	O
general	O
purpose	O
,	O
responsive	B-Task
robotic	I-Task
systems	I-Task
.	O
	
Current	O
detection	B-Method
systems	I-Method
repurpose	O
classifiers	B-Method
to	O
perform	O
detection	B-Task
.	O
	
To	O
detect	O
an	O
object	O
,	O
these	O
systems	O
take	O
a	O
classifier	B-Method
for	O
that	O
object	O
and	O
evaluate	O
it	O
at	O
various	O
locations	O
and	O
scales	O
in	O
a	O
test	O
image	O
.	O
	
Systems	O
like	O
deformable	B-Method
parts	I-Method
models	I-Method
(	O
DPM	B-Method
)	O
use	O
a	O
sliding	B-Method
window	I-Method
approach	I-Method
where	O
the	O
classifier	B-Method
is	O
run	O
at	O
evenly	O
spaced	O
locations	O
over	O
the	O
entire	O
image	O
.	O
	
More	O
recent	O
approaches	O
like	O
R	B-Method
-	I-Method
CNN	I-Method
use	O
region	B-Method
proposal	I-Method
methods	I-Method
to	O
first	O
generate	O
potential	O
bounding	O
boxes	O
in	O
an	O
image	O
and	O
then	O
run	O
a	O
classifier	B-Method
on	O
these	O
proposed	O
boxes	O
.	O
	
After	O
classification	B-Task
,	O
post	B-Task
-	I-Task
processing	I-Task
is	O
used	O
to	O
refine	O
the	O
bounding	O
boxes	O
,	O
eliminate	O
duplicate	O
detections	O
,	O
and	O
rescore	O
the	O
boxes	O
based	O
on	O
other	O
objects	O
in	O
the	O
scene	O
.	O
	
These	O
complex	O
pipelines	O
are	O
slow	O
and	O
hard	O
to	O
optimize	O
because	O
each	O
individual	O
component	O
must	O
be	O
trained	O
separately	O
.	O
	
We	O
reframe	O
object	B-Task
detection	I-Task
as	O
a	O
single	O
regression	B-Task
problem	I-Task
,	O
straight	O
from	O
image	O
pixels	O
to	O
bounding	O
box	O
coordinates	O
and	O
class	O
probabilities	O
.	O
	
Using	O
our	O
system	O
,	O
you	O
only	O
look	O
once	O
(	O
YOLO	B-Method
)	O
at	O
an	O
image	O
to	O
predict	O
what	O
objects	O
are	O
present	O
and	O
where	O
they	O
are	O
.	O
	
YOLO	B-Method
is	O
refreshingly	O
simple	O
:	O
	
see	O
Figure	O
[	O
reference	O
]	O
.	O
	
A	O
single	O
convolutional	B-Method
network	I-Method
simultaneously	O
predicts	O
multiple	O
bounding	O
boxes	O
and	O
class	O
probabilities	O
for	O
those	O
boxes	O
.	O
	
YOLO	B-Method
trains	O
on	O
full	O
images	O
and	O
directly	O
optimizes	O
detection	B-Task
performance	O
.	O
	
This	O
unified	O
model	O
has	O
several	O
benefits	O
over	O
traditional	O
methods	O
of	O
object	B-Task
detection	I-Task
.	O
	
First	O
,	O
YOLO	B-Method
is	O
extremely	O
fast	O
.	O
	
Since	O
we	O
frame	B-Task
detection	I-Task
as	O
a	O
regression	B-Task
problem	I-Task
we	O
do	O
n’t	O
need	O
a	O
complex	O
pipeline	O
.	O
	
We	O
simply	O
run	O
our	O
neural	B-Method
network	I-Method
on	O
a	O
new	O
image	O
at	O
test	O
time	O
to	O
predict	O
detections	O
.	O
	
Our	O
base	O
network	O
runs	O
at	O
45	O
frames	O
per	O
second	O
with	O
no	O
batch	B-Method
processing	I-Method
on	O
a	O
Titan	O
X	O
GPU	O
and	O
a	O
fast	O
version	O
runs	O
at	O
more	O
than	O
150	O
fps	B-Metric
.	O
	
This	O
means	O
we	O
can	O
process	O
streaming	O
video	O
in	O
real	O
-	O
time	O
with	O
less	O
than	O
25	O
milliseconds	O
of	O
latency	O
.	O
	
Furthermore	O
,	O
YOLO	B-Method
achieves	O
more	O
than	O
twice	O
the	O
mean	B-Metric
average	I-Metric
precision	I-Metric
of	O
other	O
real	B-Method
-	I-Method
time	I-Method
systems	I-Method
.	O
	
For	O
a	O
demo	O
of	O
our	O
system	O
running	O
in	O
real	O
-	O
time	O
on	O
a	O
webcam	O
please	O
see	O
our	O
project	O
webpage	O
:	O
.	O
	
Second	O
,	O
YOLO	B-Method
reasons	O
globally	O
about	O
the	O
image	O
when	O
making	O
predictions	B-Task
.	O
	
Unlike	O
sliding	B-Method
window	I-Method
and	I-Method
region	I-Method
proposal	I-Method
-	I-Method
based	I-Method
techniques	I-Method
,	O
YOLO	B-Method
sees	O
the	O
entire	O
image	O
during	O
training	O
and	O
test	O
time	O
so	O
it	O
implicitly	O
encodes	O
contextual	O
information	O
about	O
classes	O
as	O
well	O
as	O
their	O
appearance	O
.	O
	
Fast	O
R	B-Method
-	I-Method
CNN	I-Method
,	O
a	O
top	B-Method
detection	I-Method
method	I-Method
,	O
mistakes	O
background	O
patches	O
in	O
an	O
image	O
for	O
objects	O
because	O
it	O
ca	O
n’t	O
see	O
the	O
larger	O
context	O
.	O
	
YOLO	B-Method
makes	O
less	O
than	O
half	O
the	O
number	O
of	O
background	B-Metric
errors	I-Metric
compared	O
to	O
Fast	O
R	B-Method
-	I-Method
CNN	I-Method
.	O
	
Third	O
,	O
YOLO	B-Method
learns	O
generalizable	B-Method
representations	I-Method
of	I-Method
objects	I-Method
.	O
	
When	O
trained	O
on	O
natural	O
images	O
and	O
tested	O
on	O
artwork	O
,	O
YOLO	B-Method
outperforms	O
top	B-Method
detection	I-Method
methods	I-Method
like	O
DPM	B-Method
and	O
R	B-Method
-	I-Method
CNN	I-Method
by	O
a	O
wide	O
margin	O
.	O
	
Since	O
YOLO	B-Method
is	O
highly	O
generalizable	O
it	O
is	O
less	O
likely	O
to	O
break	O
down	O
when	O
applied	O
to	O
new	O
domains	O
or	O
unexpected	O
inputs	O
.	O
	
YOLO	B-Method
still	O
lags	O
behind	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
detection	B-Method
systems	I-Method
in	O
accuracy	B-Metric
.	O
	
While	O
it	O
can	O
quickly	O
identify	O
objects	O
in	O
images	O
it	O
struggles	O
to	O
precisely	O
localize	O
some	O
objects	O
,	O
especially	O
small	O
ones	O
.	O
	
We	O
examine	O
these	O
tradeoffs	O
further	O
in	O
our	O
experiments	O
.	O
	
All	O
of	O
our	O
training	O
and	O
testing	O
code	O
is	O
open	O
source	O
.	O
	
A	O
variety	O
of	O
pretrained	B-Method
models	I-Method
are	O
also	O
available	O
to	O
download	O
.	O
	
section	O
:	O
Unified	B-Task
Detection	I-Task
	
We	O
unify	O
the	O
separate	O
components	O
of	O
object	B-Task
detection	I-Task
into	O
a	O
single	O
neural	B-Method
network	I-Method
.	O
	
Our	O
network	O
uses	O
features	O
from	O
the	O
entire	O
image	O
to	O
predict	O
each	O
bounding	O
box	O
.	O
	
It	O
also	O
predicts	O
all	O
bounding	O
boxes	O
across	O
all	O
classes	O
for	O
an	O
image	O
simultaneously	O
.	O
	
This	O
means	O
our	O
network	O
reasons	O
globally	O
about	O
the	O
full	O
image	O
and	O
all	O
the	O
objects	O
in	O
the	O
image	O
.	O
	
The	O
YOLO	B-Method
design	O
enables	O
end	O
-	O
to	O
-	O
end	B-Task
training	I-Task
and	O
real	B-Metric
-	I-Metric
time	I-Metric
speeds	I-Metric
while	O
maintaining	O
high	O
average	B-Metric
precision	I-Metric
.	O
	
Our	O
system	O
divides	O
the	O
input	O
image	O
into	O
an	O
grid	O
.	O
	
If	O
the	O
center	O
of	O
an	O
object	O
falls	O
into	O
a	O
grid	O
cell	O
,	O
that	O
grid	O
cell	O
is	O
responsible	O
for	O
detecting	O
that	O
object	O
.	O
	
Each	O
grid	O
cell	O
predicts	O
bounding	O
boxes	O
and	O
confidence	O
scores	O
for	O
those	O
boxes	O
.	O
	
These	O
confidence	B-Metric
scores	I-Metric
reflect	O
how	O
confident	O
the	O
model	O
is	O
that	O
the	O
box	O
contains	O
an	O
object	O
and	O
also	O
how	O
accurate	O
it	O
thinks	O
the	O
box	O
is	O
that	O
it	O
predicts	O
.	O
	
Formally	O
we	O
define	O
confidence	O
as	O
.	O
	
If	O
no	O
object	O
exists	O
in	O
that	O
cell	O
,	O
the	O
confidence	O
scores	O
should	O
be	O
zero	O
.	O
	
Otherwise	O
we	O
want	O
the	O
confidence	B-Metric
score	I-Metric
to	O
equal	O
the	O
intersection	O
over	O
union	O
(	O
IOU	O
)	O
between	O
the	O
predicted	O
box	O
and	O
the	O
ground	O
truth	O
.	O
	
Each	O
bounding	O
box	O
consists	O
of	O
5	O
predictions	O
:	O
,	O
,	O
,	O
,	O
and	O
confidence	O
.	O
	
The	O
coordinates	O
represent	O
the	O
center	O
of	O
the	O
box	O
relative	O
to	O
the	O
bounds	O
of	O
the	O
grid	O
cell	O
.	O
	
The	O
width	O
and	O
height	O
are	O
predicted	O
relative	O
to	O
the	O
whole	O
image	O
.	O
	
Finally	O
the	O
confidence	B-Task
prediction	I-Task
represents	O
the	O
IOU	O
between	O
the	O
predicted	O
box	O
and	O
any	O
ground	O
truth	O
box	O
.	O
	
Each	O
grid	O
cell	O
also	O
predicts	O
conditional	O
class	O
probabilities	O
,	O
.	O
	
These	O
probabilities	O
are	O
conditioned	O
on	O
the	O
grid	O
cell	O
containing	O
an	O
object	O
.	O
	
We	O
only	O
predict	O
one	O
set	O
of	O
class	O
probabilities	O
per	O
grid	O
cell	O
,	O
regardless	O
of	O
the	O
number	O
of	O
boxes	O
.	O
	
At	O
test	O
time	O
we	O
multiply	O
the	O
conditional	O
class	O
probabilities	O
and	O
the	O
individual	O
box	O
confidence	O
predictions	O
,	O
which	O
gives	O
us	O
class	O
-	O
specific	O
confidence	O
scores	O
for	O
each	O
box	O
.	O
	
These	O
scores	O
encode	O
both	O
the	O
probability	O
of	O
that	O
class	O
appearing	O
in	O
the	O
box	O
and	O
how	O
well	O
the	O
predicted	O
box	O
fits	O
the	O
object	O
.	O
	
For	O
evaluating	O
YOLO	B-Method
on	O
Pascal	B-Material
VOC	I-Material
,	O
we	O
use	O
,	O
.	O
	
Pascal	B-Material
VOC	I-Material
has	O
20	O
labelled	O
classes	O
so	O
.	O
	
Our	O
final	O
prediction	O
is	O
a	O
tensor	O
.	O
	
subsection	O
:	O
Network	B-Method
Design	I-Method
	
We	O
implement	O
this	O
model	O
as	O
a	O
convolutional	B-Method
neural	I-Method
network	I-Method
and	O
evaluate	O
it	O
on	O
the	O
Pascal	B-Material
VOC	O
detection	O
dataset	O
.	O
	
The	O
initial	O
convolutional	B-Method
layers	I-Method
of	O
the	O
network	O
extract	O
features	O
from	O
the	O
image	O
while	O
the	O
fully	B-Method
connected	I-Method
layers	I-Method
predict	O
the	O
output	O
probabilities	O
and	O
coordinates	O
.	O
	
Our	O
network	B-Method
architecture	I-Method
is	O
inspired	O
by	O
the	O
GoogLeNet	B-Method
model	I-Method
for	O
image	B-Task
classification	I-Task
.	O
	
Our	O
network	O
has	O
24	O
convolutional	B-Method
layers	I-Method
followed	O
by	O
2	O
fully	B-Method
connected	I-Method
layers	I-Method
.	O
	
Instead	O
of	O
the	O
inception	B-Method
modules	I-Method
used	O
by	O
GoogLeNet	B-Method
,	O
we	O
simply	O
use	O
reduction	B-Method
layers	I-Method
followed	O
by	O
convolutional	B-Method
layers	I-Method
,	O
similar	O
to	O
Lin	O
et	O
al	O
.	O
	
The	O
full	O
network	O
is	O
shown	O
in	O
Figure	O
[	O
reference	O
]	O
.	O
	
We	O
also	O
train	O
a	O
fast	O
version	O
of	O
YOLO	B-Method
designed	O
to	O
push	O
the	O
boundaries	O
of	O
fast	O
object	B-Task
detection	I-Task
.	O
	
Fast	B-Method
YOLO	I-Method
uses	O
a	O
neural	B-Method
network	I-Method
with	O
fewer	O
convolutional	B-Method
layers	I-Method
(	O
9	O
instead	O
of	O
24	O
)	O
and	O
fewer	O
filters	O
in	O
those	O
layers	O
.	O
	
Other	O
than	O
the	O
size	O
of	O
the	O
network	O
,	O
all	O
training	B-Metric
and	I-Metric
testing	I-Metric
parameters	I-Metric
are	O
the	O
same	O
between	O
YOLO	B-Method
and	O
Fast	B-Method
YOLO	I-Method
.	O
	
The	O
final	O
output	O
of	O
our	O
network	O
is	O
the	O
tensor	O
of	O
predictions	O
.	O
	
subsection	O
:	O
Training	O
	
We	O
pretrain	O
our	O
convolutional	B-Method
layers	I-Method
on	O
the	O
ImageNet	B-Material
1000	I-Material
-	I-Material
class	I-Material
competition	I-Material
dataset	I-Material
.	O
	
For	O
pretraining	B-Task
we	O
use	O
the	O
first	O
20	O
convolutional	B-Method
layers	I-Method
from	O
Figure	O
[	O
reference	O
]	O
followed	O
by	O
a	O
average	B-Method
-	I-Method
pooling	I-Method
layer	I-Method
and	O
a	O
fully	B-Method
connected	I-Method
layer	I-Method
.	O
	
We	O
train	O
this	O
network	O
for	O
approximately	O
a	O
week	O
and	O
achieve	O
a	O
single	O
crop	O
	
top	O
-	O
5	O
accuracy	B-Metric
of	O
88	O
%	O
on	O
the	O
ImageNet	B-Material
2012	I-Material
validation	I-Material
set	I-Material
,	O
comparable	O
to	O
the	O
GoogLeNet	B-Method
models	I-Method
in	O
Caffe	B-Method
’s	I-Method
Model	I-Method
Zoo	I-Method
.	O
	
We	O
use	O
the	O
Darknet	B-Method
framework	I-Method
for	O
all	O
training	B-Task
and	I-Task
inference	I-Task
.	O
	
We	O
then	O
convert	O
the	O
model	O
to	O
perform	O
detection	B-Task
.	O
	
Ren	O
et	O
al	O
.	O
show	O
that	O
adding	O
both	O
convolutional	B-Method
and	I-Method
connected	I-Method
layers	I-Method
to	O
pretrained	B-Method
networks	I-Method
can	O
improve	O
performance	O
.	O
	
Following	O
their	O
example	O
,	O
we	O
add	O
four	O
convolutional	B-Method
layers	I-Method
and	O
two	O
fully	B-Method
connected	I-Method
layers	I-Method
with	O
randomly	O
initialized	O
weights	O
.	O
	
Detection	B-Task
often	O
requires	O
fine	O
-	O
grained	O
visual	O
information	O
so	O
we	O
increase	O
the	O
input	O
resolution	O
of	O
the	O
network	O
from	O
to	O
.	O
	
Our	O
final	O
layer	O
predicts	O
both	O
class	O
probabilities	O
and	O
bounding	O
box	O
coordinates	O
.	O
	
We	O
normalize	O
the	O
bounding	O
box	O
width	O
and	O
height	O
by	O
the	O
image	O
width	O
and	O
height	O
so	O
that	O
they	O
fall	O
between	O
0	O
and	O
1	O
.	O
	
We	O
parametrize	O
the	O
bounding	O
box	O
and	O
coordinates	O
to	O
be	O
offsets	O
of	O
a	O
particular	O
grid	O
cell	O
location	O
so	O
they	O
are	O
also	O
bounded	O
between	O
0	O
and	O
1	O
.	O
	
We	O
use	O
a	O
linear	B-Method
activation	I-Method
function	I-Method
for	O
the	O
final	O
layer	O
and	O
all	O
other	O
layers	O
use	O
the	O
following	O
leaky	B-Method
rectified	I-Method
linear	I-Method
activation	I-Method
:	O
We	O
optimize	O
for	O
sum	B-Metric
-	I-Metric
squared	I-Metric
error	I-Metric
in	O
the	O
output	O
of	O
our	O
model	O
.	O
	
We	O
use	O
sum	B-Metric
-	I-Metric
squared	I-Metric
error	I-Metric
because	O
it	O
is	O
easy	O
to	O
optimize	O
,	O
however	O
it	O
does	O
not	O
perfectly	O
align	O
with	O
our	O
goal	O
of	O
maximizing	B-Metric
average	I-Metric
precision	I-Metric
.	O
	
It	O
weights	O
localization	B-Metric
error	I-Metric
equally	O
with	O
classification	B-Metric
error	I-Metric
which	O
may	O
not	O
be	O
ideal	O
.	O
	
Also	O
,	O
in	O
every	O
image	O
many	O
grid	O
cells	O
do	O
not	O
contain	O
any	O
object	O
.	O
	
This	O
pushes	O
the	O
“	O
confidence	O
”	O
scores	O
of	O
those	O
cells	O
towards	O
zero	O
,	O
often	O
overpowering	O
the	O
gradient	O
from	O
cells	O
that	O
do	O
contain	O
objects	O
.	O
	
This	O
can	O
lead	O
to	O
model	O
instability	O
,	O
causing	O
training	B-Task
to	O
diverge	O
early	O
on	O
.	O
	
To	O
remedy	O
this	O
,	O
we	O
increase	O
the	O
loss	O
from	O
bounding	B-Method
box	I-Method
coordinate	I-Method
predictions	I-Method
and	O
decrease	O
the	O
loss	O
from	O
confidence	O
predictions	O
for	O
boxes	O
that	O
do	O
n’t	O
contain	O
objects	O
.	O
	
We	O
use	O
two	O
parameters	O
,	O
and	O
to	O
accomplish	O
this	O
.	O
	
We	O
set	O
and	O
.	O
	
Sum	B-Metric
-	I-Metric
squared	I-Metric
error	I-Metric
also	O
equally	O
weights	O
errors	O
in	O
large	O
boxes	O
and	O
small	O
boxes	O
.	O
	
Our	O
error	B-Metric
metric	I-Metric
should	O
reflect	O
that	O
small	O
deviations	O
in	O
large	O
boxes	O
matter	O
less	O
than	O
in	O
small	O
boxes	O
.	O
	
To	O
partially	O
address	O
this	O
we	O
predict	O
the	O
square	O
root	O
of	O
the	O
bounding	O
box	O
width	O
and	O
height	O
instead	O
of	O
the	O
width	O
and	O
height	O
directly	O
.	O
	
YOLO	B-Method
predicts	O
multiple	O
bounding	O
boxes	O
per	O
grid	O
cell	O
.	O
	
At	O
training	O
time	O
we	O
only	O
want	O
one	O
bounding	B-Method
box	I-Method
predictor	I-Method
to	O
be	O
responsible	O
for	O
each	O
object	O
.	O
	
We	O
assign	O
one	O
predictor	O
to	O
be	O
“	O
responsible	O
”	O
for	O
predicting	O
an	O
object	O
based	O
on	O
which	O
prediction	O
has	O
the	O
highest	O
current	O
IOU	O
with	O
the	O
ground	O
truth	O
.	O
	
This	O
leads	O
to	O
specialization	O
between	O
the	O
bounding	B-Method
box	I-Method
predictors	I-Method
.	O
	
Each	O
predictor	O
gets	O
better	O
at	O
predicting	O
certain	O
sizes	O
,	O
aspect	O
ratios	O
,	O
or	O
classes	O
of	O
object	O
,	O
improving	O
overall	O
recall	B-Metric
.	O
	
During	O
training	B-Task
we	O
optimize	O
the	O
following	O
,	O
multi	O
-	O
part	O
loss	O
function	O
:	O
where	O
denotes	O
if	O
object	O
appears	O
in	O
cell	O
and	O
denotes	O
that	O
the	O
th	O
bounding	B-Method
box	I-Method
predictor	I-Method
in	O
cell	O
is	O
“	O
responsible	O
”	O
for	O
that	O
prediction	O
.	O
	
Note	O
that	O
the	O
loss	B-Method
function	I-Method
only	O
penalizes	O
classification	B-Metric
error	I-Metric
if	O
an	O
object	O
is	O
present	O
in	O
that	O
grid	O
cell	O
(	O
hence	O
the	O
conditional	O
class	O
probability	O
discussed	O
earlier	O
)	O
.	O
	
It	O
also	O
only	O
penalizes	O
bounding	O
box	O
coordinate	O
error	O
if	O
that	O
predictor	O
is	O
“	O
responsible	O
”	O
for	O
the	O
ground	O
truth	O
box	O
(	O
i.e.	O
has	O
the	O
highest	O
IOU	O
of	O
any	O
predictor	O
in	O
that	O
grid	O
cell	O
)	O
.	O
	
We	O
train	O
the	O
network	O
for	O
about	O
135	O
epochs	O
on	O
the	O
training	O
and	O
validation	O
data	O
sets	O
from	O
Pascal	B-Material
VOC	O
2007	O
and	O
2012	O
.	O
	
When	O
testing	O
on	O
2012	O
we	O
also	O
include	O
the	O
VOC	B-Material
2007	I-Material
test	I-Material
data	I-Material
for	O
training	O
.	O
	
Throughout	O
training	O
we	O
use	O
a	O
batch	O
size	O
of	O
64	O
,	O
a	O
momentum	O
of	O
and	O
a	O
decay	O
of	O
.	O
	
Our	O
learning	B-Metric
rate	I-Metric
schedule	I-Metric
is	O
as	O
follows	O
:	O
	
For	O
the	O
first	O
epochs	O
we	O
slowly	O
raise	O
the	O
learning	B-Metric
rate	I-Metric
from	O
to	O
.	O
	
If	O
we	O
start	O
at	O
a	O
high	O
learning	B-Metric
rate	I-Metric
our	O
model	O
often	O
diverges	O
due	O
to	O
unstable	O
gradients	O
.	O
	
We	O
continue	O
training	O
with	O
for	O
75	O
epochs	O
,	O
then	O
for	O
30	O
epochs	O
,	O
and	O
finally	O
for	O
30	O
epochs	O
.	O
	
To	O
avoid	O
overfitting	O
we	O
use	O
dropout	B-Method
and	O
extensive	O
data	B-Method
augmentation	I-Method
.	O
	
A	O
dropout	B-Method
layer	I-Method
with	O
rate	O
=	O
	
.5	O
after	O
the	O
first	O
connected	B-Method
layer	I-Method
prevents	O
co	O
-	O
adaptation	O
between	O
layers	O
.	O
	
For	O
data	B-Task
augmentation	I-Task
we	O
introduce	O
random	O
scaling	O
and	O
translations	O
of	O
up	O
to	O
20	O
%	O
of	O
the	O
original	O
image	O
size	O
.	O
	
We	O
also	O
randomly	O
adjust	O
the	O
exposure	O
and	O
saturation	O
of	O
the	O
image	O
by	O
up	O
to	O
a	O
factor	O
of	O
in	O
the	O
HSV	O
color	O
space	O
.	O
	
subsection	O
:	O
Inference	B-Task
	
Just	O
like	O
in	O
training	O
,	O
predicting	B-Task
detections	I-Task
for	O
a	O
test	O
image	O
only	O
requires	O
one	O
network	B-Method
evaluation	I-Method
.	O
	
On	O
Pascal	B-Material
VOC	I-Material
the	O
network	O
predicts	O
98	O
bounding	O
boxes	O
per	O
image	O
and	O
class	O
probabilities	O
for	O
each	O
box	O
.	O
	
YOLO	B-Method
is	O
extremely	O
fast	O
at	O
test	O
time	O
since	O
it	O
only	O
requires	O
a	O
single	O
network	B-Method
evaluation	I-Method
,	O
unlike	O
classifier	B-Method
-	I-Method
based	I-Method
methods	I-Method
.	O
	
The	O
grid	B-Method
design	I-Method
enforces	O
spatial	O
diversity	O
in	O
the	O
bounding	B-Task
box	I-Task
predictions	I-Task
.	O
	
Often	O
it	O
is	O
clear	O
which	O
grid	O
cell	O
an	O
object	O
falls	O
in	O
to	O
and	O
the	O
network	O
only	O
predicts	O
one	O
box	O
for	O
each	O
object	O
.	O
	
However	O
,	O
some	O
large	O
objects	O
or	O
objects	O
near	O
the	O
border	O
of	O
multiple	O
cells	O
can	O
be	O
well	O
localized	O
by	O
multiple	O
cells	O
.	O
	
Non	B-Method
-	I-Method
maximal	I-Method
suppression	I-Method
can	O
be	O
used	O
to	O
fix	O
these	O
multiple	O
detections	O
.	O
	
While	O
not	O
critical	O
to	O
performance	O
as	O
it	O
is	O
for	O
R	B-Method
-	I-Method
CNN	I-Method
or	O
DPM	B-Method
,	O
non	B-Method
-	I-Method
maximal	I-Method
suppression	I-Method
adds	O
2	O
-	O
3	O
%	O
in	O
mAP	B-Metric
.	O
	
subsection	O
:	O
Limitations	O
of	O
YOLO	B-Method
	
YOLO	B-Method
imposes	O
strong	O
spatial	O
constraints	O
on	O
bounding	B-Task
box	I-Task
predictions	I-Task
since	O
each	O
grid	O
cell	O
only	O
predicts	O
two	O
boxes	O
and	O
can	O
only	O
have	O
one	O
class	O
.	O
	
This	O
spatial	O
constraint	O
limits	O
the	O
number	O
of	O
nearby	O
objects	O
that	O
our	O
model	O
can	O
predict	O
.	O
	
Our	O
model	O
struggles	O
with	O
small	O
objects	O
that	O
appear	O
in	O
groups	O
,	O
such	O
as	O
flocks	O
of	O
birds	O
.	O
	
Since	O
our	O
model	O
learns	O
to	O
predict	O
bounding	O
boxes	O
from	O
data	O
,	O
it	O
struggles	O
to	O
generalize	O
to	O
objects	O
in	O
new	O
or	O
unusual	O
aspect	O
ratios	O
or	O
configurations	O
.	O
	
Our	O
model	O
also	O
uses	O
relatively	O
coarse	O
features	O
for	O
predicting	B-Task
bounding	I-Task
boxes	I-Task
since	O
our	O
architecture	O
has	O
multiple	O
downsampling	O
layers	O
from	O
the	O
input	O
image	O
.	O
	
Finally	O
,	O
while	O
we	O
train	O
on	O
a	O
loss	B-Method
function	I-Method
that	O
approximates	O
detection	B-Task
performance	O
,	O
our	O
loss	B-Method
function	I-Method
treats	O
errors	O
the	O
same	O
in	O
small	O
bounding	O
boxes	O
versus	O
large	O
bounding	O
boxes	O
.	O
	
A	O
small	O
error	O
in	O
a	O
large	O
box	O
is	O
generally	O
benign	O
but	O
a	O
small	O
error	O
in	O
a	O
small	O
box	O
has	O
a	O
much	O
greater	O
effect	O
on	O
IOU	B-Task
.	O
	
Our	O
main	O
source	O
of	O
error	O
is	O
incorrect	B-Task
localizations	I-Task
.	O
	
section	O
:	O
Comparison	O
to	O
Other	O
Detection	B-Method
Systems	I-Method
	
Object	B-Task
detection	I-Task
is	O
a	O
core	O
problem	O
in	O
computer	B-Task
vision	I-Task
.	O
	
Detection	B-Method
pipelines	I-Method
generally	O
start	O
by	O
extracting	O
a	O
set	O
of	O
robust	O
features	O
from	O
input	O
images	O
(	O
Haar	O
,	O
SIFT	O
,	O
HOG	O
,	O
convolutional	O
features	O
)	O
.	O
	
Then	O
,	O
classifiers	B-Method
or	O
localizers	B-Method
are	O
used	O
to	O
identify	O
objects	O
in	O
the	O
feature	O
space	O
.	O
	
These	O
classifiers	B-Method
or	O
localizers	B-Method
are	O
run	O
either	O
in	O
sliding	B-Method
window	I-Method
fashion	I-Method
over	O
the	O
whole	O
image	O
or	O
on	O
some	O
subset	O
of	O
regions	O
in	O
the	O
image	O
.	O
	
We	O
compare	O
the	O
YOLO	B-Method
detection	O
system	O
to	O
several	O
top	B-Method
detection	I-Method
frameworks	I-Method
,	O
highlighting	O
key	O
similarities	O
and	O
differences	O
.	O
	
Deformable	B-Method
parts	I-Method
models	I-Method
.	O
	
Deformable	B-Method
parts	I-Method
models	I-Method
(	O
DPM	B-Method
)	O
use	O
a	O
sliding	B-Method
window	I-Method
approach	I-Method
to	O
object	B-Task
detection	I-Task
.	O
	
DPM	B-Method
uses	O
a	O
disjoint	B-Method
pipeline	I-Method
to	O
extract	O
static	O
features	O
,	O
classify	O
regions	O
,	O
predict	O
bounding	O
boxes	O
for	O
high	O
scoring	O
regions	O
,	O
etc	O
.	O
	
Our	O
system	O
replaces	O
all	O
of	O
these	O
disparate	O
parts	O
with	O
a	O
single	O
convolutional	B-Method
neural	I-Method
network	I-Method
.	O
	
The	O
network	O
performs	O
feature	B-Task
extraction	I-Task
,	O
bounding	B-Task
box	I-Task
prediction	I-Task
,	O
non	B-Task
-	I-Task
maximal	I-Task
suppression	I-Task
,	O
and	O
contextual	B-Task
reasoning	I-Task
all	O
concurrently	O
.	O
	
Instead	O
of	O
static	O
features	O
,	O
the	O
network	O
trains	O
the	O
features	O
in	O
-	O
line	O
and	O
optimizes	O
them	O
for	O
the	O
detection	B-Task
task	I-Task
.	O
	
Our	O
unified	B-Method
architecture	I-Method
leads	O
to	O
a	O
faster	O
,	O
more	O
accurate	O
model	O
than	O
DPM	B-Method
.	O
	
R	B-Method
-	I-Method
CNN	I-Method
.	O
	
R	B-Method
-	I-Method
CNN	I-Method
and	O
its	O
variants	O
use	O
region	B-Method
proposals	I-Method
instead	O
of	O
sliding	O
windows	O
to	O
find	O
objects	O
in	O
images	O
.	O
	
Selective	B-Task
Search	I-Task
generates	O
potential	O
bounding	O
boxes	O
,	O
a	O
convolutional	B-Method
network	I-Method
extracts	O
features	O
,	O
an	O
SVM	B-Method
scores	O
the	O
boxes	O
,	O
a	O
linear	B-Method
model	I-Method
adjusts	O
the	O
bounding	O
boxes	O
,	O
and	O
non	B-Method
-	I-Method
max	I-Method
suppression	I-Method
eliminates	O
duplicate	O
detections	O
.	O
	
Each	O
stage	O
of	O
this	O
complex	O
pipeline	O
must	O
be	O
precisely	O
tuned	O
independently	O
and	O
the	O
resulting	O
system	O
is	O
very	O
slow	O
,	O
taking	O
more	O
than	O
40	O
seconds	O
per	O
image	O
at	O
test	O
time	O
.	O
	
YOLO	B-Method
shares	O
some	O
similarities	O
with	O
R	B-Method
-	I-Method
CNN	I-Method
.	O
	
Each	O
grid	O
cell	O
proposes	O
potential	O
bounding	O
boxes	O
and	O
scores	O
those	O
boxes	O
using	O
convolutional	B-Method
features	I-Method
.	O
	
However	O
,	O
our	O
system	O
puts	O
spatial	O
constraints	O
on	O
the	O
grid	O
cell	O
proposals	O
which	O
helps	O
mitigate	O
multiple	O
detections	O
of	O
the	O
same	O
object	O
.	O
	
Our	O
system	O
also	O
proposes	O
far	O
fewer	O
bounding	O
boxes	O
,	O
only	O
98	O
per	O
image	O
compared	O
to	O
about	O
2000	O
from	O
Selective	B-Method
Search	I-Method
.	O
	
Finally	O
,	O
our	O
system	O
combines	O
these	O
individual	O
components	O
into	O
a	O
single	O
,	O
jointly	B-Method
optimized	I-Method
model	I-Method
.	O
	
Other	O
Fast	B-Method
Detectors	I-Method
Fast	O
and	O
Faster	O
R	B-Method
-	I-Method
CNN	I-Method
focus	O
on	O
speeding	O
up	O
the	O
R	B-Method
-	I-Method
CNN	I-Method
framework	O
by	O
sharing	O
computation	B-Method
and	O
using	O
neural	B-Method
networks	I-Method
to	O
propose	O
regions	O
instead	O
of	O
Selective	B-Method
Search	I-Method
.	O
	
While	O
they	O
offer	O
speed	B-Metric
and	O
accuracy	B-Metric
improvements	O
over	O
R	B-Method
-	I-Method
CNN	I-Method
,	O
both	O
still	O
fall	O
short	O
of	O
real	O
-	O
time	O
performance	O
.	O
	
Many	O
research	O
efforts	O
focus	O
on	O
speeding	O
up	O
the	O
DPM	B-Method
pipeline	O
.	O
	
They	O
speed	B-Metric
up	O
HOG	B-Task
computation	I-Task
,	O
use	O
cascades	B-Method
,	O
and	O
push	B-Task
computation	I-Task
to	O
GPUs	O
.	O
	
However	O
,	O
only	O
30Hz	O
DPM	B-Method
actually	O
runs	O
in	O
real	O
-	O
time	O
.	O
	
Instead	O
of	O
trying	O
to	O
optimize	O
individual	O
components	O
of	O
a	O
large	O
detection	B-Method
pipeline	I-Method
,	O
YOLO	B-Method
throws	O
out	O
the	O
pipeline	O
entirely	O
and	O
is	O
fast	O
by	O
design	O
.	O
	
Detectors	B-Method
for	O
single	O
classes	O
like	O
faces	O
or	O
people	O
can	O
be	O
highly	O
optimized	O
since	O
they	O
have	O
to	O
deal	O
with	O
much	O
less	O
variation	O
.	O
	
YOLO	B-Method
is	O
a	O
general	B-Method
purpose	I-Method
detector	I-Method
that	O
learns	O
to	O
detect	O
a	O
variety	O
of	O
objects	O
simultaneously	O
.	O
	
Deep	B-Task
MultiBox	I-Task
.	O
	
Unlike	O
R	B-Method
-	I-Method
CNN	I-Method
,	O
Szegedy	O
et	O
al	O
.	O
train	O
a	O
convolutional	B-Method
neural	I-Method
network	I-Method
to	O
predict	O
regions	O
of	O
interest	O
instead	O
of	O
using	O
Selective	B-Method
Search	I-Method
.	O
	
MultiBox	B-Method
can	O
also	O
perform	O
single	O
object	B-Task
detection	I-Task
by	O
replacing	O
the	O
confidence	B-Method
prediction	I-Method
with	O
a	O
single	O
class	B-Method
prediction	I-Method
.	O
	
However	O
,	O
MultiBox	B-Method
can	O
not	O
perform	O
general	O
object	B-Task
detection	I-Task
and	O
is	O
still	O
just	O
a	O
piece	O
in	O
a	O
larger	O
detection	B-Task
pipeline	I-Task
,	O
requiring	O
further	O
image	B-Task
patch	I-Task
classification	I-Task
.	O
	
Both	O
YOLO	B-Method
and	O
MultiBox	B-Method
use	O
a	O
convolutional	B-Method
network	I-Method
to	O
predict	O
bounding	B-Task
boxes	I-Task
in	O
an	O
image	O
but	O
YOLO	B-Method
is	O
a	O
complete	O
detection	B-Method
system	I-Method
.	O
	
OverFeat	O
.	O
	
Sermanet	O
et	O
al	O
.	O
train	O
a	O
convolutional	B-Method
neural	I-Method
network	I-Method
to	O
perform	O
localization	B-Task
and	O
adapt	O
that	O
localizer	B-Method
to	O
perform	O
detection	B-Task
.	O
	
OverFeat	B-Method
efficiently	O
performs	O
sliding	B-Method
window	I-Method
detection	I-Method
but	O
it	O
is	O
still	O
a	O
disjoint	O
system	O
.	O
	
OverFeat	B-Method
optimizes	O
for	O
localization	B-Task
,	O
not	O
detection	B-Task
performance	O
.	O
	
Like	O
DPM	B-Method
,	O
the	O
localizer	B-Method
only	O
sees	O
local	O
information	O
when	O
making	O
a	O
prediction	B-Task
.	O
	
OverFeat	B-Method
can	O
not	O
reason	O
about	O
global	O
context	O
and	O
thus	O
requires	O
significant	O
post	B-Method
-	I-Method
processing	I-Method
to	O
produce	O
coherent	O
detections	O
.	O
	
MultiGrasp	B-Method
.	O
	
Our	O
work	O
is	O
similar	O
in	O
design	O
to	O
work	O
on	O
grasp	B-Task
detection	I-Task
by	O
Redmon	O
et	O
al	O
.	O
	
Our	O
grid	B-Method
approach	I-Method
to	O
bounding	B-Task
box	I-Task
prediction	I-Task
is	O
based	O
on	O
the	O
MultiGrasp	B-Method
system	I-Method
for	O
regression	B-Task
to	I-Task
grasps	I-Task
.	O
	
However	O
,	O
grasp	B-Task
detection	I-Task
is	O
a	O
much	O
simpler	O
task	O
than	O
object	B-Task
detection	I-Task
.	O
	
MultiGrasp	B-Method
only	O
needs	O
to	O
predict	O
a	O
single	O
graspable	O
region	O
for	O
an	O
image	O
containing	O
one	O
object	O
.	O
	
It	O
does	O
n’t	O
have	O
to	O
estimate	O
the	O
size	O
,	O
location	O
,	O
or	O
boundaries	O
of	O
the	O
object	O
or	O
predict	O
it	O
’s	O
class	O
,	O
only	O
find	O
a	O
region	O
suitable	O
for	O
grasping	B-Task
.	O
	
YOLO	B-Method
predicts	O
both	O
bounding	O
boxes	O
and	O
class	O
probabilities	O
for	O
multiple	O
objects	O
of	O
multiple	O
classes	O
in	O
an	O
image	O
.	O
	
section	O
:	O
Experiments	O
	
First	O
we	O
compare	O
YOLO	B-Method
with	O
other	O
real	B-Method
-	I-Method
time	I-Method
detection	I-Method
systems	I-Method
on	O
Pascal	B-Material
VOC	O
2007	O
.	O
	
To	O
understand	O
the	O
differences	O
between	O
YOLO	B-Method
and	O
R	B-Method
-	I-Method
CNN	I-Method
variants	I-Method
we	O
explore	O
the	O
errors	O
on	O
VOC	B-Material
2007	I-Material
made	O
by	O
YOLO	B-Method
and	O
Fast	O
R	B-Method
-	I-Method
CNN	I-Method
,	O
one	O
of	O
the	O
highest	O
performing	O
versions	O
of	O
R	B-Method
-	I-Method
CNN	I-Method
.	O
	
Based	O
on	O
the	O
different	O
error	O
profiles	O
we	O
show	O
that	O
YOLO	B-Method
can	O
be	O
used	O
to	O
rescore	O
Fast	O
R	B-Method
-	I-Method
CNN	I-Method
detections	O
and	O
reduce	O
the	O
errors	O
from	O
background	O
false	O
positives	O
,	O
giving	O
a	O
significant	O
performance	O
boost	O
.	O
	
We	O
also	O
present	O
VOC	B-Material
2012	I-Material
results	O
and	O
compare	O
mAP	B-Metric
to	O
current	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
methods	O
.	O
	
Finally	O
,	O
we	O
show	O
that	O
YOLO	B-Method
generalizes	O
to	O
new	O
domains	O
better	O
than	O
other	O
detectors	O
on	O
two	O
artwork	O
datasets	O
.	O
	
subsection	O
:	O
Comparison	O
to	O
Other	O
Real	B-Task
-	I-Task
Time	I-Task
Systems	I-Task
	
Many	O
research	O
efforts	O
in	O
object	B-Task
detection	I-Task
focus	O
on	O
making	O
standard	O
detection	B-Method
pipelines	I-Method
fast	O
.	O
	
However	O
,	O
only	O
Sadeghi	O
et	O
al	O
.	O
actually	O
produce	O
a	O
detection	B-Method
system	I-Method
that	O
runs	O
in	O
real	O
-	O
time	O
(	O
30	O
frames	O
per	O
second	O
or	O
better	O
)	O
.	O
	
We	O
compare	O
YOLO	B-Method
to	O
their	O
GPU	B-Method
implementation	I-Method
of	O
DPM	B-Method
which	O
runs	O
either	O
at	O
30Hz	O
or	O
100Hz	O
.	O
	
While	O
the	O
other	O
efforts	O
do	O
n’t	O
reach	O
the	O
real	O
-	O
time	O
milestone	O
we	O
also	O
compare	O
their	O
relative	O
mAP	B-Metric
and	O
speed	B-Metric
to	O
examine	O
the	O
accuracy	B-Metric
-	O
performance	O
tradeoffs	O
available	O
in	O
object	B-Task
detection	I-Task
systems	O
.	O
	
Fast	B-Method
YOLO	I-Method
is	O
the	O
fastest	O
object	B-Task
detection	I-Task
method	O
on	O
Pascal	B-Material
;	O
as	O
far	O
as	O
we	O
know	O
,	O
it	O
is	O
the	O
fastest	O
extant	O
object	B-Method
detector	I-Method
.	O
	
With	O
mAP	B-Metric
,	O
it	O
is	O
more	O
than	O
twice	O
as	O
accurate	O
as	O
prior	O
work	O
on	O
real	B-Task
-	I-Task
time	I-Task
detection	I-Task
.	O
	
YOLO	B-Method
pushes	O
mAP	B-Metric
to	O
while	O
still	O
maintaining	O
real	O
-	O
time	O
performance	O
.	O
	
We	O
also	O
train	O
YOLO	B-Method
using	O
VGG	B-Method
-	I-Method
16	I-Method
.	O
	
This	O
model	O
is	O
more	O
accurate	O
but	O
also	O
significantly	O
slower	O
than	O
YOLO	B-Method
.	O
	
It	O
is	O
useful	O
for	O
comparison	O
to	O
other	O
detection	B-Method
systems	I-Method
that	O
rely	O
on	O
VGG	B-Method
-	I-Method
16	I-Method
	
but	O
since	O
it	O
is	O
slower	O
than	O
real	O
-	O
time	O
the	O
rest	O
of	O
the	O
paper	O
focuses	O
on	O
our	O
faster	O
models	O
.	O
	
Fastest	O
DPM	B-Method
effectively	O
speeds	O
up	O
DPM	B-Method
without	O
sacrificing	O
much	O
mAP	B-Metric
but	O
it	O
still	O
misses	O
real	B-Metric
-	I-Metric
time	I-Metric
performance	I-Metric
by	O
a	O
factor	O
of	O
2	O
.	O
	
It	O
also	O
is	O
limited	O
by	O
DPM	B-Method
’s	O
relatively	O
low	O
accuracy	B-Metric
on	O
detection	B-Task
compared	O
to	O
neural	B-Method
network	I-Method
approaches	I-Method
.	O
	
R	B-Method
-	I-Method
CNN	I-Method
minus	O
R	O
replaces	O
Selective	B-Method
Search	I-Method
with	O
static	B-Method
bounding	I-Method
box	I-Method
proposals	I-Method
.	O
	
While	O
it	O
is	O
much	O
faster	O
than	O
R	B-Method
-	I-Method
CNN	I-Method
,	O
it	O
still	O
falls	O
short	O
of	O
real	O
-	O
time	O
and	O
takes	O
a	O
significant	O
accuracy	B-Metric
hit	O
from	O
not	O
having	O
good	O
proposals	O
.	O
	
Fast	O
R	B-Method
-	I-Method
CNN	I-Method
speeds	O
up	O
the	O
classification	B-Method
stage	I-Method
of	O
R	B-Method
-	I-Method
CNN	I-Method
but	O
it	O
still	O
relies	O
on	O
selective	B-Method
search	I-Method
which	O
can	O
take	O
around	O
2	O
seconds	O
per	O
image	O
to	O
generate	O
bounding	O
box	O
proposals	O
.	O
	
Thus	O
it	O
has	O
high	O
mAP	B-Metric
but	O
at	O
fps	B-Metric
it	O
is	O
still	O
far	O
from	O
real	O
-	O
time	O
.	O
	
The	O
recent	O
Faster	O
R	B-Method
-	I-Method
CNN	I-Method
replaces	O
selective	B-Method
search	I-Method
with	O
a	O
neural	B-Method
network	I-Method
to	O
propose	O
bounding	O
boxes	O
,	O
similar	O
to	O
Szegedy	O
et	O
al	O
.	O
	
In	O
our	O
tests	O
,	O
their	O
most	O
accurate	O
model	O
achieves	O
7	O
fps	B-Metric
while	O
a	O
smaller	O
,	O
less	O
accurate	O
one	O
runs	O
at	O
18	O
fps	B-Metric
.	O
	
The	O
VGG	O
-	O
16	O
version	O
of	O
Faster	O
R	B-Method
-	I-Method
CNN	I-Method
is	O
10	O
mAP	B-Metric
higher	O
but	O
is	O
also	O
6	O
times	O
slower	O
than	O
YOLO	B-Method
.	O
	
The	O
Zeiler	O
-	O
Fergus	O
Faster	O
R	B-Method
-	I-Method
CNN	I-Method
is	O
only	O
2.5	O
times	O
slower	O
than	O
YOLO	B-Method
but	O
is	O
also	O
less	O
accurate	O
.	O
	
subsection	O
:	O
VOC	B-Task
2007	I-Task
Error	I-Task
Analysis	I-Task
	
To	O
further	O
examine	O
the	O
differences	O
between	O
YOLO	B-Method
and	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
detectors	O
,	O
we	O
look	O
at	O
a	O
detailed	O
breakdown	O
of	O
results	O
on	O
VOC	B-Material
2007	I-Material
.	O
	
We	O
compare	O
YOLO	B-Method
to	O
Fast	O
R	B-Method
-	I-Method
CNN	I-Method
since	O
Fast	O
R	B-Method
-	I-Method
CNN	I-Method
is	O
one	O
of	O
the	O
highest	O
performing	O
detectors	O
on	O
Pascal	B-Material
and	O
it	O
	
’s	O
detections	O
are	O
publicly	O
available	O
.	O
	
We	O
use	O
the	O
methodology	O
and	O
tools	O
of	O
Hoiem	O
et	O
al	O
.	O
	
For	O
each	O
category	O
at	O
test	O
time	O
we	O
look	O
at	O
the	O
top	O
N	O
predictions	O
for	O
that	O
category	O
.	O
	
Each	O
prediction	O
is	O
either	O
correct	O
or	O
it	O
is	O
classified	O
based	O
on	O
the	O
type	O
of	O
error	O
:	O
	
Correct	O
:	O
correct	O
class	O
and	O
Localization	B-Task
:	O
	
correct	O
class	O
,	O
Similar	O
:	O
class	O
is	O
similar	O
,	O
Other	O
:	O
class	O
is	O
wrong	O
,	O
Background	O
:	O
for	O
any	O
object	O
Figure	O
[	O
reference	O
]	O
shows	O
the	O
breakdown	O
of	O
each	O
error	O
type	O
averaged	O
across	O
all	O
20	O
classes	O
.	O
	
YOLO	B-Method
struggles	O
to	O
localize	O
objects	O
correctly	O
.	O
	
Localization	B-Task
errors	I-Task
account	O
for	O
more	O
of	O
YOLO	B-Method
’s	O
errors	O
than	O
all	O
other	O
sources	O
combined	O
.	O
	
Fast	O
R	B-Method
-	I-Method
CNN	I-Method
makes	O
much	O
fewer	O
localization	B-Task
errors	I-Task
but	O
far	O
more	O
background	O
errors	O
.	O
	
13.6	O
%	O
of	O
it	O
	
’s	O
top	O
detections	O
are	O
false	O
positives	O
that	O
do	O
n’t	O
contain	O
any	O
objects	O
.	O
	
Fast	O
R	B-Method
-	I-Method
CNN	I-Method
is	O
almost	O
3x	O
more	O
likely	O
to	O
predict	O
background	B-Task
detections	I-Task
than	O
YOLO	B-Method
.	O
	
subsection	O
:	O
Combining	O
Fast	O
R	B-Method
-	I-Method
CNN	I-Method
and	O
YOLO	B-Method
	
YOLO	B-Method
makes	O
far	O
fewer	O
background	O
mistakes	O
than	O
Fast	O
R	B-Method
-	I-Method
CNN	I-Method
.	O
	
By	O
using	O
YOLO	B-Method
to	O
eliminate	O
background	O
detections	O
from	O
Fast	O
R	B-Method
-	I-Method
CNN	I-Method
we	O
get	O
a	O
significant	O
boost	O
in	O
performance	O
.	O
	
For	O
every	O
bounding	O
box	O
that	O
R	B-Method
-	I-Method
CNN	I-Method
predicts	O
we	O
check	O
to	O
see	O
if	O
YOLO	B-Method
predicts	O
a	O
similar	O
box	O
.	O
	
If	O
it	O
does	O
,	O
we	O
give	O
that	O
prediction	O
a	O
boost	O
based	O
on	O
the	O
probability	O
predicted	O
by	O
YOLO	B-Method
and	O
the	O
overlap	O
between	O
the	O
two	O
boxes	O
.	O
	
The	O
best	O
Fast	O
R	B-Method
-	I-Method
CNN	I-Method
model	O
achieves	O
a	O
mAP	B-Metric
of	O
71.8	O
%	O
on	O
the	O
VOC	B-Material
2007	I-Material
test	I-Material
set	I-Material
.	O
	
When	O
combined	O
with	O
YOLO	B-Method
,	O
its	O
mAP	B-Metric
increases	O
by	O
3.2	O
%	O
to	O
75.0	O
%	O
.	O
	
We	O
also	O
tried	O
combining	O
the	O
top	O
Fast	O
R	B-Method
-	I-Method
CNN	I-Method
model	O
with	O
several	O
other	O
versions	O
of	O
Fast	O
R	B-Method
-	I-Method
CNN	I-Method
.	O
	
Those	O
ensembles	O
produced	O
small	O
increases	O
in	O
mAP	B-Metric
between	O
.3	O
and	O
.6	O
%	O
,	O
see	O
Table	O
[	O
reference	O
]	O
for	O
details	O
.	O
	
The	O
boost	O
from	O
YOLO	B-Method
is	O
not	O
simply	O
a	O
byproduct	O
of	O
model	B-Method
ensembling	I-Method
since	O
there	O
is	O
little	O
benefit	O
from	O
combining	O
different	O
versions	O
of	O
Fast	O
R	B-Method
-	I-Method
CNN	I-Method
.	O
	
Rather	O
,	O
it	O
is	O
precisely	O
because	O
YOLO	B-Method
makes	O
different	O
kinds	O
of	O
mistakes	O
at	O
test	O
time	O
that	O
it	O
is	O
so	O
effective	O
at	O
boosting	O
Fast	O
R	B-Method
-	I-Method
CNN	I-Method
’s	O
performance	O
.	O
	
Unfortunately	O
,	O
this	O
combination	O
does	O
n’t	O
benefit	O
from	O
the	O
speed	B-Metric
of	O
YOLO	B-Method
since	O
we	O
run	O
each	O
model	O
seperately	O
and	O
then	O
combine	O
the	O
results	O
.	O
	
However	O
,	O
since	O
YOLO	B-Method
is	O
so	O
fast	O
it	O
does	O
n’t	O
add	O
any	O
significant	O
computational	B-Metric
time	I-Metric
compared	O
to	O
Fast	O
R	B-Method
-	I-Method
CNN	I-Method
.	O
	
subsection	O
:	O
VOC	B-Material
2012	I-Material
Results	O
	
On	O
the	O
VOC	B-Material
2012	I-Material
test	I-Material
set	I-Material
,	O
YOLO	B-Method
scores	O
57.9	O
%	O
mAP	B-Metric
.	O
	
This	O
is	O
lower	O
than	O
the	O
current	O
state	O
of	O
the	O
art	O
,	O
closer	O
to	O
the	O
original	O
R	B-Method
-	I-Method
CNN	I-Method
using	O
VGG	B-Method
-	I-Method
16	I-Method
,	O
see	O
Table	O
[	O
reference	O
]	O
.	O
	
Our	O
system	O
struggles	O
with	O
small	O
objects	O
compared	O
to	O
its	O
closest	O
competitors	O
.	O
	
On	O
categories	O
like	O
bottle	O
,	O
sheep	O
,	O
and	O
tv	O
/	O
monitor	O
YOLO	B-Method
scores	O
8	O
-	O
10	O
%	O
lower	O
than	O
R	B-Method
-	I-Method
CNN	I-Method
or	O
Feature	B-Method
Edit	I-Method
.	O
	
However	O
,	O
on	O
other	O
categories	O
like	O
cat	O
and	O
train	O
YOLO	B-Method
achieves	O
higher	O
performance	O
.	O
	
Our	O
combined	O
Fast	O
R	B-Method
-	I-Method
CNN	I-Method
+	O
YOLO	B-Method
model	O
is	O
one	O
of	O
the	O
highest	O
performing	O
detection	B-Method
methods	I-Method
.	O
	
Fast	O
R	B-Method
-	I-Method
CNN	I-Method
gets	O
a	O
2.3	O
%	O
improvement	O
from	O
the	O
combination	O
with	O
YOLO	B-Method
,	O
boosting	O
it	O
5	O
spots	O
up	O
on	O
the	O
public	O
leaderboard	O
.	O
	
subsection	O
:	O
Generalizability	O
:	O
Person	B-Task
Detection	I-Task
in	O
Artwork	B-Task
	
[	O
b	O
]	O
.45	O
[	O
b	O
]	O
.55	O
Academic	B-Material
datasets	I-Material
for	O
object	B-Task
detection	I-Task
draw	O
the	O
training	O
and	O
testing	O
data	O
from	O
the	O
same	O
distribution	O
.	O
	
In	O
real	B-Task
-	I-Task
world	I-Task
applications	I-Task
it	O
is	O
hard	O
to	O
predict	O
all	O
possible	O
use	O
cases	O
and	O
the	O
test	O
data	O
can	O
diverge	O
from	O
what	O
the	O
system	O
has	O
seen	O
before	O
.	O
	
We	O
compare	O
YOLO	B-Method
to	O
other	O
detection	B-Method
systems	I-Method
on	O
the	O
Picasso	B-Material
Dataset	I-Material
and	O
the	O
People	B-Material
-	I-Material
Art	I-Material
Dataset	I-Material
,	O
two	O
datasets	O
for	O
testing	O
person	B-Task
detection	I-Task
on	O
artwork	O
.	O
	
Figure	O
[	O
reference	O
]	O
shows	O
comparative	O
performance	O
between	O
YOLO	B-Method
and	O
other	O
detection	B-Method
methods	I-Method
.	O
	
For	O
reference	O
,	O
we	O
give	O
VOC	O
2007	O
detection	O
AP	B-Metric
on	O
person	O
where	O
all	O
models	O
are	O
trained	O
only	O
on	O
VOC	B-Material
2007	I-Material
data	I-Material
.	O
	
On	O
Picasso	B-Method
models	I-Method
are	O
trained	O
on	O
VOC	B-Material
2012	I-Material
while	O
on	O
People	B-Method
-	I-Method
Art	I-Method
they	O
are	O
trained	O
on	O
VOC	B-Material
2010	I-Material
.	O
	
R	B-Method
-	I-Method
CNN	I-Method
has	O
high	O
AP	B-Metric
on	O
VOC	B-Material
2007	I-Material
.	O
	
However	O
,	O
R	B-Method
-	I-Method
CNN	I-Method
drops	O
off	O
considerably	O
when	O
applied	O
to	O
artwork	B-Material
.	O
	
R	B-Method
-	I-Method
CNN	I-Method
uses	O
Selective	B-Method
Search	I-Method
for	O
bounding	B-Method
box	I-Method
proposals	I-Method
which	O
is	O
tuned	O
for	O
natural	B-Material
images	I-Material
.	O
	
The	O
classifier	B-Method
step	I-Method
in	O
R	B-Method
-	I-Method
CNN	I-Method
only	O
sees	O
small	O
regions	O
and	O
needs	O
good	O
proposals	O
.	O
	
DPM	B-Method
maintains	O
its	O
AP	B-Metric
well	O
when	O
applied	O
to	O
artwork	B-Material
.	O
	
Prior	O
work	O
theorizes	O
that	O
DPM	B-Method
performs	O
well	O
because	O
it	O
has	O
strong	O
spatial	B-Method
models	I-Method
of	O
the	O
shape	O
and	O
layout	O
of	O
objects	O
.	O
	
Though	O
DPM	B-Method
does	O
n’t	O
degrade	O
as	O
much	O
as	O
R	B-Method
-	I-Method
CNN	I-Method
,	O
it	O
starts	O
from	O
a	O
lower	O
AP	B-Metric
.	O
	
YOLO	B-Method
has	O
good	O
performance	O
on	O
VOC	B-Material
2007	I-Material
and	O
its	O
AP	B-Metric
degrades	O
less	O
than	O
other	O
methods	O
when	O
applied	O
to	O
artwork	O
.	O
	
Like	O
DPM	B-Method
,	O
YOLO	B-Method
models	O
the	O
size	O
and	O
shape	O
of	O
objects	O
,	O
as	O
well	O
as	O
relationships	O
between	O
objects	O
and	O
where	O
objects	O
commonly	O
appear	O
.	O
	
Artwork	O
and	O
natural	O
images	O
are	O
very	O
different	O
on	O
a	O
pixel	O
level	O
but	O
they	O
are	O
similar	O
in	O
terms	O
of	O
the	O
size	O
and	O
shape	O
of	O
objects	O
,	O
thus	O
YOLO	B-Method
can	O
still	O
predict	O
good	O
bounding	O
boxes	O
and	O
detections	O
.	O
	
section	O
:	O
Real	B-Task
-	I-Task
Time	I-Task
Detection	I-Task
In	I-Task
The	I-Task
Wild	I-Task
	
YOLO	B-Method
is	O
a	O
fast	O
,	O
accurate	O
object	B-Method
detector	I-Method
,	O
making	O
it	O
ideal	O
for	O
computer	B-Task
vision	I-Task
applications	I-Task
.	O
	
We	O
connect	O
YOLO	B-Method
to	O
a	O
webcam	O
and	O
verify	O
that	O
it	O
maintains	O
real	O
-	O
time	O
performance	O
,	O
including	O
the	O
time	O
to	O
fetch	O
images	O
from	O
the	O
camera	O
and	O
display	O
the	O
detections	O
.	O
	
The	O
resulting	O
system	O
is	O
interactive	O
and	O
engaging	O
.	O
	
While	O
YOLO	B-Method
processes	O
images	O
individually	O
,	O
when	O
attached	O
to	O
a	O
webcam	B-Method
it	I-Method
functions	O
like	O
a	O
tracking	B-Method
system	I-Method
,	O
detecting	O
objects	O
as	O
they	O
move	O
around	O
and	O
change	O
in	O
appearance	O
.	O
	
A	O
demo	O
of	O
the	O
system	O
and	O
the	O
source	O
code	O
can	O
be	O
found	O
on	O
our	O
project	O
website	O
:	O
.	O
	
section	O
:	O
Conclusion	O
	
We	O
introduce	O
YOLO	B-Method
,	O
a	O
unified	B-Method
model	I-Method
for	O
object	B-Task
detection	I-Task
.	O
	
Our	O
model	O
is	O
simple	O
to	O
construct	O
and	O
can	O
be	O
trained	O
directly	O
on	O
full	O
images	O
.	O
	
Unlike	O
classifier	B-Method
-	I-Method
based	I-Method
approaches	I-Method
,	O
YOLO	B-Method
is	O
trained	O
on	O
a	O
loss	B-Method
function	I-Method
that	O
directly	O
corresponds	O
to	O
detection	B-Task
performance	O
and	O
the	O
entire	O
model	O
is	O
trained	O
jointly	O
.	O
	
Fast	B-Method
YOLO	I-Method
is	O
the	O
fastest	O
general	B-Method
-	I-Method
purpose	I-Method
object	I-Method
detector	I-Method
in	O
the	O
literature	O
and	O
YOLO	B-Method
pushes	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
in	O
real	O
-	O
time	O
object	B-Task
detection	I-Task
.	O
	
YOLO	B-Method
also	O
generalizes	O
well	O
to	O
new	O
domains	O
making	O
it	O
ideal	O
for	O
applications	O
that	O
rely	O
on	O
fast	O
,	O
robust	O
object	B-Task
detection	I-Task
.	O
	
Acknowledgements	O
:	O
This	O
work	O
is	O
partially	O
supported	O
by	O
ONR	O
N00014	O
-	O
13	O
-	O
1	O
-	O
0720	O
,	O
NSF	O
IIS	O
-	O
1338054	O
,	O
and	O
The	O
Allen	O
Distinguished	O
Investigator	O
Award	O
.	O
	
bibliography	O
:	O
References	O
	
In	O
this	O
work	O
,	O
we	O
build	O
on	O
recent	O
advances	O
in	O
distributional	O
reinforcement	B-Method
learning	I-Method
to	O
give	O
a	O
generally	O
applicable	O
,	O
flexible	O
,	O
and	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
distributional	B-Method
variant	I-Method
of	O
DQN	B-Method
.	O
	
We	O
achieve	O
this	O
by	O
using	O
quantile	B-Method
regression	I-Method
to	O
approximate	O
the	O
full	O
quantile	O
function	O
for	O
the	O
state	O
-	O
action	O
return	O
distribution	O
.	O
	
By	O
reparameterizing	O
a	O
distribution	O
over	O
the	O
sample	O
space	O
,	O
this	O
yields	O
an	O
implicitly	O
defined	O
return	O
distribution	O
and	O
gives	O
rise	O
to	O
a	O
large	O
class	O
of	O
risk	B-Method
-	I-Method
sensitive	I-Method
policies	I-Method
.	O
	
We	O
demonstrate	O
improved	O
performance	O
on	O
the	O
57	O
Atari	B-Material
2600	I-Material
games	I-Material
in	O
the	O
ALE	O
,	O
and	O
use	O
our	O
algorithm	O
’s	O
implicitly	O
defined	O
distributions	O
to	O
study	O
the	O
effects	O
of	O
risk	B-Task
-	I-Task
sensitive	I-Task
policies	I-Task
in	O
Atari	B-Task
games	I-Task
.	O
	
ImplicitQuantileNetworksforDistributionalReinforcementLearning	O
	
section	O
:	O
Introduction	O
	
Distributional	O
reinforcement	B-Method
learning	I-Method
focuses	O
on	O
the	O
intrinsic	O
randomness	O
of	O
returns	O
within	O
the	O
reinforcement	B-Method
learning	I-Method
(	O
RL	B-Method
)	O
framework	O
.	O
	
As	O
the	O
agent	O
interacts	O
with	O
the	O
environment	O
,	O
irreducible	O
randomness	O
seeps	O
in	O
through	O
the	O
stochasticity	O
of	O
these	O
interactions	O
,	O
the	O
approximations	O
in	O
the	O
agent	B-Method
’s	I-Method
representation	I-Method
,	O
and	O
even	O
the	O
inherently	O
chaotic	O
nature	O
of	O
physical	O
interaction	O
.	O
	
Distributional	O
RL	B-Method
aims	O
to	O
model	O
the	O
distribution	O
over	O
returns	O
,	O
whose	O
mean	O
is	O
the	O
traditional	O
value	O
function	O
,	O
and	O
to	O
use	O
these	O
distributions	O
to	O
evaluate	O
and	O
optimize	O
a	O
policy	B-Task
.	O
	
Any	O
distributional	O
RL	B-Method
algorithm	O
is	O
characterized	O
by	O
two	O
aspects	O
:	O
the	O
parameterization	B-Method
of	I-Method
the	I-Method
return	I-Method
distribution	I-Method
,	O
and	O
the	O
distance	B-Metric
metric	I-Metric
or	O
loss	O
function	O
being	O
optimized	O
.	O
	
Together	O
,	O
these	O
choices	O
control	O
assumptions	O
about	O
the	O
random	O
returns	O
and	O
how	O
approximations	O
will	O
be	O
traded	O
off	O
.	O
	
Categorical	B-Method
DQN	I-Method
[	O
C51	O
]	O
c51	O
combines	O
a	O
categorical	O
distribution	O
and	O
the	O
cross	B-Method
-	I-Method
entropy	I-Method
loss	I-Method
with	O
the	O
Cramér	B-Method
-	I-Method
minimizing	I-Method
projection	I-Method
.	O
	
For	O
this	O
,	O
it	O
assumes	O
returns	O
are	O
bounded	O
in	O
a	O
known	O
range	O
and	O
trades	O
off	O
mean	B-Metric
-	I-Metric
preservation	I-Metric
at	O
the	O
cost	O
of	O
overestimating	O
variance	O
.	O
	
C51	B-Method
outperformed	O
all	O
previous	O
improvements	O
to	O
DQN	B-Method
on	O
a	O
set	O
of	O
57	O
Atari	B-Material
2600	I-Material
games	I-Material
in	O
the	O
Arcade	B-Task
Learning	I-Task
Environment	I-Task
,	O
which	O
we	O
refer	O
to	O
as	O
the	O
Atari	B-Task
-	I-Task
57	I-Task
benchmark	O
.	O
	
Subsequently	O
,	O
several	O
papers	O
have	O
built	O
upon	O
this	O
successful	O
combination	O
to	O
achieve	O
significant	O
improvements	O
to	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
in	O
Atari	B-Task
-	I-Task
57	I-Task
,	O
and	O
challenging	O
continuous	B-Task
control	I-Task
tasks	I-Task
.	O
	
These	O
algorithms	O
are	O
restricted	O
to	O
assigning	O
probabilities	O
to	O
an	O
a	O
priori	O
fixed	O
,	O
discrete	O
set	O
of	O
possible	O
returns	O
.	O
	
dabney2017qr	O
propose	O
an	O
alternate	O
pair	O
of	O
choices	O
,	O
parameterizing	O
the	O
distribution	O
by	O
a	O
uniform	B-Method
mixture	I-Method
of	I-Method
Diracs	I-Method
whose	O
locations	O
are	O
adjusted	O
using	O
quantile	B-Method
regression	I-Method
.	O
	
Their	O
algorithm	O
,	O
QR	B-Method
-	I-Method
DQN	I-Method
,	O
while	O
restricted	O
to	O
a	O
discrete	O
set	O
of	O
quantiles	O
,	O
automatically	O
adapts	O
return	O
quantiles	O
to	O
minimize	O
the	O
Wasserstein	O
distance	O
between	O
the	O
Bellman	O
updated	O
and	O
current	O
return	O
distributions	O
.	O
	
This	O
flexibility	O
allows	O
QR	B-Method
-	I-Method
DQN	I-Method
to	O
significantly	O
improve	O
on	O
C51	O
’s	O
Atari	B-Task
-	I-Task
57	I-Task
performance	O
.	O
	
In	O
this	O
paper	O
,	O
we	O
extend	O
the	O
approach	O
of	O
dabney2017qr	O
,	O
from	O
learning	O
a	O
discrete	O
set	O
of	O
quantiles	O
to	O
learning	O
the	O
full	O
quantile	O
function	O
,	O
a	O
continuous	O
map	O
from	O
probabilities	O
to	O
returns	O
.	O
	
When	O
combined	O
with	O
a	O
base	B-Method
distribution	I-Method
,	O
such	O
as	O
,	O
this	O
forms	O
an	O
implicit	B-Method
distribution	I-Method
capable	O
of	O
approximating	O
any	O
distribution	O
over	O
returns	O
given	O
sufficient	O
network	O
capacity	O
.	O
	
Our	O
approach	O
,	O
implicit	B-Method
quantile	I-Method
networks	I-Method
(	O
IQN	B-Method
)	O
,	O
is	O
best	O
viewed	O
as	O
a	O
simple	O
distributional	B-Method
generalization	I-Method
of	I-Method
the	I-Method
DQN	I-Method
algorithm	I-Method
,	O
and	O
provides	O
several	O
benefits	O
over	O
QR	B-Method
-	I-Method
DQN	I-Method
.	O
	
First	O
,	O
the	O
approximation	B-Metric
error	I-Metric
for	O
the	O
distribution	O
is	O
no	O
longer	O
controlled	O
by	O
the	O
number	O
of	O
quantiles	O
output	O
by	O
the	O
network	O
,	O
but	O
by	O
the	O
size	O
of	O
the	O
network	O
itself	O
,	O
and	O
the	O
amount	O
of	O
training	O
.	O
	
Second	O
,	O
IQN	B-Method
can	O
be	O
used	O
with	O
as	O
few	O
,	O
or	O
as	O
many	O
,	O
samples	O
per	O
update	O
as	O
desired	O
,	O
providing	O
improved	O
data	B-Metric
efficiency	I-Metric
with	O
increasing	O
number	O
of	O
samples	O
per	O
training	O
update	O
.	O
	
Third	O
,	O
the	O
implicit	B-Method
representation	I-Method
of	I-Method
the	I-Method
return	I-Method
distribution	I-Method
allows	O
us	O
to	O
expand	O
the	O
class	O
of	O
policies	O
to	O
more	O
fully	O
take	O
advantage	O
of	O
the	O
learned	O
distribution	O
.	O
	
Specifically	O
,	O
by	O
taking	O
the	O
base	O
distribution	O
to	O
be	O
non	O
-	O
uniform	O
,	O
we	O
expand	O
the	O
class	O
of	O
policies	O
to	O
-	O
greedy	O
policies	O
on	O
arbitrary	O
distortion	B-Metric
risk	I-Metric
measures	I-Metric
.	O
	
We	O
begin	O
by	O
reviewing	O
distributional	O
reinforcement	B-Method
learning	I-Method
,	O
related	O
work	O
,	O
and	O
introducing	O
the	O
concepts	O
surrounding	O
risk	O
-	O
sensitive	O
RL	B-Method
.	O
	
In	O
subsequent	O
sections	O
,	O
we	O
introduce	O
our	O
proposed	O
algorithm	O
,	O
IQN	B-Method
,	O
and	O
present	O
a	O
series	O
of	O
experiments	O
using	O
the	O
Atari	B-Task
-	I-Task
57	I-Task
benchmark	O
,	O
investigating	O
the	O
robustness	B-Metric
and	O
performance	O
of	O
IQN	B-Method
.	O
	
Despite	O
being	O
a	O
simple	O
distributional	B-Method
extension	I-Method
to	O
DQN	B-Method
,	O
and	O
forgoing	O
any	O
other	O
improvements	O
,	O
IQN	B-Method
significantly	O
outperforms	O
QR	B-Method
-	I-Method
DQN	I-Method
and	O
nearly	O
matches	O
the	O
performance	O
of	O
Rainbow	B-Method
,	O
which	O
combines	O
many	O
orthogonal	B-Method
advances	I-Method
.	O
	
In	O
fact	O
,	O
in	O
human	O
-	O
starts	O
as	O
well	O
as	O
in	O
the	O
hardest	O
Atari	B-Material
games	I-Material
(	O
where	O
current	O
RL	B-Method
agents	O
still	O
underperform	O
human	O
players	O
)	O
	
IQN	B-Method
improves	O
over	O
Rainbow	O
.	O
	
section	O
:	O
Background	O
/	O
Related	O
Work	O
	
We	O
consider	O
the	O
standard	O
RL	B-Method
setting	O
,	O
in	O
which	O
the	O
interaction	O
of	O
an	O
agent	O
and	O
an	O
environment	O
is	O
modeled	O
as	O
a	O
Markov	B-Method
Decision	I-Method
Process	I-Method
,	O
where	O
and	O
denote	O
the	O
state	O
and	O
action	O
spaces	O
,	O
the	O
(	O
state	O
-	O
and	O
action	O
-	O
dependent	O
)	O
reward	O
function	O
,	O
the	O
transition	O
kernel	O
,	O
and	O
a	O
discount	O
factor	O
.	O
	
A	O
policy	B-Method
maps	O
a	O
state	O
to	O
a	O
distribution	O
over	O
actions	O
.	O
	
For	O
an	O
agent	B-Task
following	I-Task
policy	I-Task
,	O
the	O
discounted	O
sum	O
of	O
future	O
rewards	O
is	O
denoted	O
by	O
the	O
random	O
variable	O
,	O
where	O
,	O
,	O
,	O
and	O
.	O
	
The	O
action	O
-	O
value	O
function	O
is	O
defined	O
as	O
,	O
and	O
can	O
be	O
characterized	O
by	O
the	O
Bellman	B-Method
equation	I-Method
	
The	O
objective	O
in	O
RL	B-Method
is	O
to	O
find	O
an	O
optimal	B-Method
policy	I-Method
,	O
which	O
maximizes	O
,	O
i.e.	O
for	O
all	O
and	O
all	O
.	O
	
One	O
approach	O
is	O
to	O
find	O
the	O
unique	O
fixed	O
point	O
of	O
the	O
Bellman	B-Method
optimality	I-Method
operator	I-Method
:	O
To	O
this	O
end	O
,	O
Q	B-Method
-	I-Method
learning	I-Method
iteratively	O
improves	O
an	O
estimate	O
,	O
,	O
of	O
the	O
optimal	O
action	O
-	O
value	O
function	O
,	O
,	O
by	O
repeatedly	O
applying	O
the	O
Bellman	B-Method
update	I-Method
:	O
The	O
action	B-Method
-	I-Method
value	I-Method
function	I-Method
can	O
be	O
approximated	O
by	O
a	O
parameterized	B-Method
function	I-Method
(	O
e.g.	O
a	O
neural	B-Method
network	I-Method
)	O
,	O
and	O
trained	O
by	O
minimizing	O
the	O
squared	B-Metric
temporal	I-Metric
difference	I-Metric
(	O
TD	B-Metric
)	O
error	O
,	O
over	O
samples	O
observed	O
while	O
following	O
an	O
-	B-Method
greedy	I-Method
policy	I-Method
over	O
.	O
	
This	O
policy	O
acts	O
greedily	O
with	O
respect	O
to	O
with	O
probability	O
and	O
uniformly	O
at	O
random	O
otherwise	O
.	O
	
DQN	B-Method
uses	O
a	O
convolutional	B-Method
neural	I-Method
network	I-Method
to	O
parameterize	O
and	O
the	O
Q	B-Method
-	I-Method
learning	I-Method
algorithm	I-Method
to	O
achieve	O
human	O
-	O
level	O
play	O
on	O
the	O
Atari	B-Task
-	I-Task
57	I-Task
benchmark	O
.	O
	
subsection	O
:	O
Distributional	O
RL	B-Method
	
In	O
distributional	O
RL	B-Method
,	O
the	O
distribution	O
over	O
returns	O
(	O
the	O
law	O
of	O
)	O
is	O
considered	O
instead	O
of	O
the	O
scalar	O
value	O
function	O
that	O
is	O
its	O
expectation	O
.	O
	
This	O
change	O
in	O
perspective	O
has	O
yielded	O
new	O
insights	O
into	O
the	O
dynamics	O
of	O
RL	B-Method
,	O
and	O
been	O
a	O
useful	O
tool	O
for	O
analysis	O
.	O
	
Empirically	O
,	O
distributional	O
RL	B-Method
algorithms	O
show	O
improved	O
sample	B-Metric
complexity	I-Metric
and	O
final	B-Metric
performance	I-Metric
,	O
as	O
well	O
as	O
increased	O
robustness	B-Metric
to	O
hyperparameter	O
variation	O
.	O
	
An	O
analogous	O
distributional	B-Method
Bellman	I-Method
equation	I-Method
of	O
the	O
form	O
can	O
be	O
derived	O
,	O
where	O
denotes	O
that	O
two	O
random	O
variables	O
and	O
have	O
equal	O
probability	O
laws	O
,	O
and	O
the	O
random	O
variables	O
and	O
are	O
distributed	O
according	O
to	O
and	O
,	O
respectively	O
.	O
	
morimura10parametric	O
defined	O
the	O
distributional	O
Bellman	O
operator	O
explicitly	O
in	O
terms	O
of	O
conditional	O
probabilities	O
,	O
parameterized	O
by	O
the	O
mean	O
and	O
scale	O
of	O
a	O
Gaussian	O
or	O
Laplace	O
distribution	O
,	O
and	O
minimized	O
the	O
Kullback	O
-	O
Leibler	O
(	O
KL	O
)	O
divergence	O
between	O
the	O
Bellman	O
target	O
and	O
the	O
current	O
estimated	B-Method
return	I-Method
distribution	I-Method
.	O
	
However	O
,	O
the	O
distributional	B-Method
Bellman	I-Method
operator	I-Method
is	O
not	O
a	O
contraction	O
in	O
the	O
KL	O
.	O
	
As	O
with	O
the	O
scalar	B-Task
setting	I-Task
,	O
a	O
distributional	B-Method
Bellman	I-Method
optimality	I-Method
operator	I-Method
can	O
be	O
defined	O
by	O
with	O
distributed	O
according	O
to	O
.	O
	
While	O
the	O
distributional	B-Method
Bellman	I-Method
operator	I-Method
for	O
policy	B-Task
evaluation	I-Task
is	O
a	O
contraction	O
in	O
the	O
-	O
Wasserstein	O
distance	O
,	O
this	O
no	O
longer	O
holds	O
for	O
the	O
control	B-Task
case	I-Task
.	O
	
Convergence	B-Task
to	O
the	O
optimal	B-Method
policy	I-Method
can	O
still	O
be	O
established	O
,	O
but	O
requires	O
a	O
more	O
involved	O
argument	O
.	O
	
c51	O
parameterize	O
the	O
return	O
distribution	O
as	O
a	O
categorical	B-Method
distribution	I-Method
over	O
a	O
fixed	O
set	O
of	O
equidistant	O
points	O
and	O
minimize	O
the	O
KL	O
divergence	O
to	O
the	O
projected	O
distributional	O
Bellman	O
target	O
.	O
	
Their	O
algorithm	O
,	O
C51	B-Method
,	O
outperformed	O
previous	O
DQN	B-Method
variants	I-Method
on	O
the	O
Atari	B-Task
-	I-Task
57	I-Task
benchmark	O
.	O
	
Subsequently	O
,	O
hessel2018rainbow	B-Method
combined	O
C51	B-Method
with	O
enhancements	O
such	O
as	O
prioritized	O
experience	O
replay	O
,	O
-	O
step	O
updates	O
,	O
and	O
the	O
dueling	B-Method
architecture	I-Method
,	O
leading	O
to	O
the	O
Rainbow	B-Method
agent	I-Method
,	O
current	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
in	O
Atari	B-Task
-	I-Task
57	I-Task
.	O
	
The	O
categorical	B-Method
parameterization	I-Method
,	O
using	O
the	O
projected	B-Method
KL	I-Method
loss	I-Method
,	O
has	O
also	O
been	O
used	O
in	O
recent	O
work	O
to	O
improve	O
the	O
critic	O
of	O
a	O
policy	B-Method
gradient	I-Method
algorithm	I-Method
,	O
D4PG	B-Method
,	O
achieving	O
significantly	O
improved	O
robustness	B-Metric
and	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
performance	O
across	O
a	O
variety	O
of	O
continuous	B-Task
control	I-Task
tasks	I-Task
.	O
	
subsection	O
:	O
-	O
Wasserstein	O
Metric	O
	
The	O
-	B-Metric
Wasserstein	I-Metric
metric	I-Metric
,	O
for	O
,	O
plays	O
a	O
key	O
role	O
in	O
recent	O
results	O
in	O
distributional	O
RL	B-Method
.	O
	
It	O
has	O
also	O
been	O
a	O
topic	O
of	O
increasing	O
interest	O
in	O
generative	B-Task
modeling	I-Task
,	O
because	O
unlike	O
the	O
KL	O
divergence	O
,	O
the	O
Wasserstein	B-Method
metric	I-Method
inherently	O
trades	O
off	O
approximate	B-Method
solutions	I-Method
with	O
likelihoods	O
.	O
	
The	O
-	B-Method
Wasserstein	I-Method
distance	I-Method
is	O
the	O
metric	O
on	O
inverse	B-Method
cumulative	I-Method
distribution	I-Method
functions	I-Method
(	O
c.d.f	O
.	O
)	O
,	O
also	O
known	O
as	O
quantile	O
functions	O
.	O
	
For	O
random	O
variables	O
and	O
with	O
quantile	O
functions	O
and	O
,	O
respectively	O
,	O
the	O
-	O
Wasserstein	O
distance	O
is	O
given	O
by	O
The	O
class	O
of	O
optimal	B-Metric
transport	I-Metric
metrics	I-Metric
express	O
distances	O
between	O
distributions	O
in	O
terms	O
of	O
the	O
minimal	B-Metric
cost	I-Metric
for	O
transporting	O
mass	O
to	O
make	O
the	O
two	O
distributions	O
identical	O
.	O
	
This	O
cost	O
is	O
given	O
in	O
terms	O
of	O
some	O
metric	O
,	O
,	O
on	O
the	O
underlying	O
space	O
.	O
	
The	O
-	O
Wasserstein	O
metric	O
corresponds	O
to	O
.	O
	
We	O
are	O
particularly	O
interested	O
in	O
the	O
Wasserstein	B-Metric
metrics	I-Metric
due	O
to	O
the	O
predominant	O
use	O
of	O
spaces	O
in	O
mean	O
-	O
value	O
reinforcement	B-Method
learning	I-Method
.	O
	
subsection	O
:	O
Quantile	B-Method
Regression	I-Method
for	O
Distributional	O
RL	B-Method
	
c51	O
showed	O
that	O
the	O
distributional	B-Method
Bellman	I-Method
operator	I-Method
is	O
a	O
contraction	B-Method
in	O
the	O
-	O
Wasserstein	O
metric	O
,	O
but	O
as	O
the	O
proposed	O
algorithm	O
did	O
not	O
itself	O
minimize	O
the	O
Wasserstein	O
metric	O
,	O
this	O
left	O
a	O
theory	O
-	O
practice	O
gap	O
for	O
distributional	O
RL	B-Method
.	O
	
Recently	O
,	O
this	O
gap	O
was	O
closed	O
,	O
in	O
both	O
directions	O
.	O
	
First	O
and	O
most	O
relevant	O
to	O
this	O
work	O
,	O
dabney2017qr	O
proposed	O
the	O
use	O
of	O
quantile	B-Method
regression	I-Method
for	O
distributional	O
RL	B-Method
and	O
showed	O
that	O
by	O
choosing	O
the	O
quantile	O
targets	O
suitably	O
the	O
resulting	O
projected	B-Method
distributional	I-Method
Bellman	I-Method
operator	I-Method
is	O
a	O
contraction	O
in	O
the	O
-	B-Metric
Wasserstein	I-Metric
metric	I-Metric
.	O
	
Concurrently	O
,	O
rowland2018analysis	O
showed	O
the	O
original	O
class	O
of	O
categorical	B-Method
algorithms	I-Method
are	O
a	O
contraction	B-Method
in	O
the	O
Cramér	B-Metric
distance	I-Metric
,	O
the	O
metric	O
on	O
cumulative	B-Method
distribution	I-Method
functions	I-Method
.	O
	
By	O
estimating	O
the	O
quantile	O
function	O
at	O
precisely	O
chosen	O
points	O
,	O
QR	B-Method
-	I-Method
DQN	I-Method
minimizes	O
the	O
Wasserstein	O
distance	O
to	O
the	O
distributional	O
Bellman	O
target	O
.	O
	
This	O
estimation	O
uses	O
quantile	B-Method
regression	I-Method
,	O
which	O
has	O
been	O
shown	O
to	O
converge	O
to	O
the	O
true	O
quantile	O
function	O
value	O
when	O
minimized	O
using	O
stochastic	B-Method
approximation	I-Method
.	O
	
In	O
QR	B-Method
-	I-Method
DQN	I-Method
,	O
the	O
random	O
return	O
is	O
approximated	O
by	O
a	O
uniform	B-Method
mixture	I-Method
of	I-Method
Diracs	I-Method
,	O
with	O
each	O
assigned	O
a	O
fixed	O
quantile	O
target	O
,	O
for	O
,	O
where	O
.	O
	
These	O
quantile	B-Method
estimates	I-Method
are	O
trained	O
using	O
the	O
huber1964robust	O
quantile	B-Method
regression	I-Method
loss	I-Method
,	O
with	O
threshold	O
,	O
on	O
the	O
pairwise	O
TD	B-Metric
-	O
errors	O
At	O
the	O
time	O
of	O
this	O
writing	O
,	O
QR	B-Method
-	I-Method
DQN	I-Method
achieves	O
the	O
best	O
performance	O
on	O
Atari	B-Task
-	I-Task
57	I-Task
,	O
human	B-Metric
-	I-Metric
normalized	I-Metric
mean	I-Metric
and	I-Metric
median	I-Metric
,	O
of	O
all	O
agents	O
that	O
do	O
not	O
combine	O
distributional	O
RL	B-Method
,	O
prioritized	B-Method
replay	I-Method
,	O
and	O
-	O
step	O
updates	O
.	O
	
subsection	O
:	O
Risk	B-Task
in	O
Reinforcement	B-Task
Learning	I-Task
	
Distributional	O
RL	B-Method
algorithms	O
have	O
been	O
theoretically	O
justified	O
for	O
the	O
Wasserstein	B-Metric
and	I-Metric
Cramér	I-Metric
metrics	I-Metric
,	O
and	O
learning	O
the	O
distribution	O
over	O
returns	O
,	O
in	O
and	O
of	O
itself	O
,	O
empirically	O
results	O
in	O
significant	O
improvements	O
to	O
data	B-Metric
efficiency	I-Metric
,	O
final	B-Metric
performance	I-Metric
,	O
and	O
stability	B-Metric
.	O
	
However	O
,	O
in	O
each	O
of	O
these	O
recent	O
works	O
the	O
policy	O
used	O
was	O
based	O
entirely	O
on	O
the	O
mean	O
of	O
the	O
return	B-Method
distribution	I-Method
,	O
just	O
as	O
in	O
standard	O
reinforcement	B-Method
learning	I-Method
.	O
	
A	O
natural	O
question	O
arises	O
:	O
can	O
we	O
expand	O
the	O
class	O
of	O
policies	O
using	O
information	O
provided	O
by	O
the	O
distribution	O
over	O
returns	O
(	O
i.e.	O
to	O
the	O
class	O
of	O
risk	B-Method
-	I-Method
sensitive	I-Method
policies	I-Method
)	O
?	O
	
Furthermore	O
,	O
when	O
would	O
this	O
larger	O
policy	O
class	O
be	O
beneficial	O
?	O
	
Here	O
,	O
‘	O
risk	O
’	O
refers	O
to	O
the	O
uncertainty	O
over	O
possible	O
outcomes	O
,	O
and	O
risk	O
-	O
sensitive	O
policies	O
are	O
those	O
which	O
depend	O
upon	O
more	O
than	O
the	O
mean	O
of	O
the	O
outcomes	O
.	O
	
At	O
this	O
point	O
,	O
it	O
is	O
important	O
to	O
highlight	O
the	O
difference	O
between	O
intrinsic	O
uncertainty	O
,	O
captured	O
by	O
the	O
distribution	O
over	O
returns	O
,	O
and	O
parametric	O
uncertainty	O
,	O
the	O
uncertainty	O
over	O
the	O
value	B-Method
estimate	I-Method
typically	O
associated	O
with	O
Bayesian	B-Method
approaches	I-Method
such	O
as	O
PSRL	B-Method
and	O
Kalman	O
TD	B-Metric
.	O
	
Distributional	O
RL	B-Method
seeks	O
to	O
capture	O
the	O
former	O
,	O
which	O
classic	O
approaches	O
to	O
risk	B-Task
are	O
built	O
upon	O
.	O
	
Expected	B-Method
utility	I-Method
theory	I-Method
states	O
that	O
if	O
a	O
decision	B-Method
policy	I-Method
is	O
consistent	O
with	O
a	O
particular	O
set	O
of	O
four	O
axioms	O
regarding	O
its	O
choices	O
then	O
the	O
decision	B-Method
policy	I-Method
behaves	O
as	O
though	O
it	O
is	O
maximizing	O
the	O
expected	O
value	O
of	O
some	O
utility	O
function	O
,	O
This	O
is	O
perhaps	O
the	O
most	O
pervasive	O
notion	O
of	O
risk	B-Task
-	I-Task
sensitivity	I-Task
.	O
	
A	O
policy	O
maximizing	O
a	O
linear	O
utility	O
function	O
is	O
called	O
risk	O
-	O
neutral	O
,	O
whereas	O
concave	O
or	O
convex	O
utility	O
functions	O
give	O
rise	O
to	O
risk	O
-	O
averse	O
or	O
risk	B-Task
-	I-Task
seeking	I-Task
policies	I-Task
,	O
respectively	O
.	O
	
Many	O
previous	O
studies	O
on	O
risk	O
-	O
sensitive	O
RL	B-Method
adopt	O
the	O
utility	B-Method
function	I-Method
approach	I-Method
.	O
	
A	O
crucial	O
axiom	O
of	O
expected	O
utility	O
is	O
independence	O
:	O
given	O
random	O
variables	O
,	O
and	O
,	O
such	O
that	O
(	O
preferred	O
over	O
)	O
,	O
any	O
mixture	O
between	O
and	O
is	O
preferred	O
to	O
the	O
same	O
mixture	O
between	O
and	O
.	O
	
Stated	O
in	O
terms	O
of	O
the	O
cumulative	O
probability	O
functions	O
,	O
.	O
	
This	O
axiom	O
in	O
particular	O
has	O
troubled	O
many	O
researchers	O
because	O
it	O
is	O
consistently	O
violated	O
by	O
human	O
behavior	O
.	O
	
The	O
Allais	B-Material
paradox	I-Material
is	O
a	O
frequently	O
used	O
example	O
of	O
a	O
decision	B-Task
problem	I-Task
where	O
people	O
violate	O
the	O
independence	O
axiom	O
of	O
expected	B-Method
utility	I-Method
theory	I-Method
.	O
	
However	O
,	O
as	O
yaari1987dual	O
showed	O
,	O
this	O
axiom	O
can	O
be	O
replaced	O
by	O
one	O
in	O
terms	O
of	O
convex	O
combinations	O
of	O
outcome	O
values	O
,	O
instead	O
of	O
mixtures	O
of	O
distributions	O
.	O
	
Specifically	O
,	O
if	O
as	O
before	O
,	O
then	O
for	O
any	O
and	O
random	O
variable	O
,	O
.	O
	
This	O
leads	O
to	O
an	O
alternate	O
,	O
dual	O
,	O
theory	O
of	O
choice	B-Task
than	O
that	O
of	O
expected	O
utility	O
.	O
	
Under	O
these	O
axioms	O
the	O
decision	B-Method
policy	I-Method
behaves	O
as	O
though	O
it	O
is	O
maximizing	O
a	O
distorted	O
expectation	O
,	O
for	O
some	O
continuous	O
monotonic	O
function	O
:	O
Such	O
a	O
function	O
is	O
known	O
as	O
a	O
distortion	B-Metric
risk	I-Metric
measure	I-Metric
,	O
as	O
it	O
distorts	O
the	O
cumulative	O
probabilities	O
of	O
the	O
random	O
variable	O
.	O
	
That	O
is	O
,	O
we	O
have	O
two	O
fundamentally	O
equivalent	O
approaches	O
to	O
risk	B-Task
-	I-Task
sensitivity	I-Task
.	O
	
Either	O
,	O
we	O
choose	O
a	O
utility	O
function	O
and	O
follow	O
the	O
expectation	O
of	O
this	O
utility	O
.	O
	
Or	O
,	O
we	O
choose	O
a	O
reweighting	O
of	O
the	O
distribution	O
and	O
compute	O
expectation	O
under	O
this	O
distortion	B-Metric
measure	I-Metric
.	O
	
Indeed	O
,	O
yaari1987dual	O
further	O
showed	O
that	O
these	O
two	O
functions	O
are	O
inverses	O
of	O
each	O
other	O
.	O
	
The	O
choice	O
between	O
them	O
amounts	O
to	O
a	O
choice	O
over	O
whether	O
the	O
behavior	O
should	O
be	O
invariant	O
to	O
mixing	O
with	O
random	O
events	O
or	O
to	O
convex	O
combinations	O
of	O
outcomes	O
.	O
	
Distortion	B-Metric
risk	I-Metric
measures	I-Metric
include	O
,	O
as	O
special	O
cases	O
,	O
cumulative	B-Method
probability	I-Method
weighting	I-Method
used	O
in	O
cumulative	B-Method
prospect	I-Method
theory	I-Method
,	O
conditional	B-Metric
value	I-Metric
at	I-Metric
risk	I-Metric
,	O
and	O
many	O
other	O
methods	O
.	O
	
Recently	O
majumdar2017should	O
argued	O
for	O
the	O
use	O
of	O
distortion	B-Metric
risk	I-Metric
measures	I-Metric
in	O
robotics	B-Task
.	O
	
section	O
:	O
Implicit	B-Method
Quantile	I-Method
Networks	I-Method
	
We	O
now	O
introduce	O
the	O
implicit	B-Method
quantile	I-Method
network	I-Method
(	O
IQN	B-Method
)	O
,	O
a	O
deterministic	B-Method
parametric	I-Method
function	I-Method
trained	O
to	O
reparameterize	O
samples	O
from	O
a	O
base	O
distribution	O
,	O
e.g.	O
,	O
to	O
the	O
respective	O
quantile	O
values	O
of	O
a	O
target	O
distribution	O
.	O
	
IQN	B-Method
provides	O
an	O
effective	O
way	O
to	O
learn	O
an	O
implicit	B-Method
representation	I-Method
of	I-Method
the	I-Method
return	I-Method
distribution	I-Method
,	O
yielding	O
a	O
powerful	O
function	B-Method
approximator	I-Method
for	O
a	O
new	O
DQN	B-Method
-	I-Method
like	I-Method
agent	I-Method
.	O
	
Let	O
be	O
the	O
quantile	O
function	O
at	O
for	O
the	O
random	O
variable	O
.	O
	
For	O
notational	O
simplicity	O
we	O
write	O
,	O
thus	O
for	O
the	O
resulting	O
state	B-Method
-	I-Method
action	I-Method
return	I-Method
distribution	I-Method
sample	I-Method
is	O
.	O
	
We	O
propose	O
to	O
model	O
the	O
state	B-Method
-	I-Method
action	I-Method
quantile	I-Method
function	I-Method
as	O
a	O
mapping	O
from	O
state	O
-	O
actions	O
and	O
samples	O
from	O
some	O
base	O
distribution	O
,	O
typically	O
,	O
to	O
,	O
viewed	O
as	O
samples	O
from	O
the	O
implicitly	O
defined	O
return	O
distribution	O
.	O
	
Let	O
be	O
a	O
distortion	B-Metric
risk	I-Metric
measure	I-Metric
,	O
with	O
identity	O
corresponding	O
to	O
risk	O
-	O
neutrality	O
.	O
	
Then	O
,	O
the	O
distorted	O
expectation	O
of	O
under	O
is	O
given	O
by	O
Notice	O
that	O
the	O
distorted	O
expectation	O
is	O
equal	O
to	O
the	O
expected	O
value	O
of	O
weighted	O
by	O
,	O
that	O
is	O
,	O
.	O
	
The	O
immediate	O
implication	O
of	O
this	O
is	O
that	O
for	O
any	O
,	O
there	O
exists	O
a	O
sampling	B-Method
distribution	I-Method
for	O
such	O
that	O
the	O
mean	O
of	O
is	O
equal	O
to	O
the	O
distorted	O
expectation	O
of	O
under	O
,	O
that	O
is	O
,	O
any	O
distorted	O
expectation	O
can	O
be	O
represented	O
as	O
a	O
weighted	O
sum	O
over	O
the	O
quantiles	O
.	O
	
Denote	O
by	O
the	O
risk	B-Method
-	I-Method
sensitive	I-Method
greedy	I-Method
policy	I-Method
For	O
two	O
samples	O
,	O
and	O
policy	O
,	O
	
the	O
sampled	O
temporal	O
difference	O
(	O
TD	B-Metric
)	O
error	O
at	O
step	O
is	O
	
Then	O
,	O
the	O
IQN	B-Method
loss	O
function	O
is	O
given	O
by	O
where	O
and	O
denote	O
the	O
respective	O
number	O
of	O
iid	O
samples	O
used	O
to	O
estimate	O
the	O
loss	B-Task
.	O
	
A	O
corresponding	O
sample	B-Method
-	I-Method
based	I-Method
risk	I-Method
-	I-Method
sensitive	I-Method
policy	I-Method
is	O
obtained	O
by	O
approximating	O
in	O
Equation	O
[	O
reference	O
]	O
by	O
samples	O
of	O
:	O
Implicit	B-Method
quantile	I-Method
networks	I-Method
differ	O
from	O
the	O
approach	O
of	O
dabney2017qr	O
in	O
two	O
ways	O
.	O
	
First	O
,	O
instead	O
of	O
approximating	O
the	O
quantile	O
function	O
at	O
fixed	O
values	O
of	O
we	O
approximate	O
it	O
with	O
for	O
some	O
differentiable	O
functions	O
,	O
,	O
and	O
.	O
	
If	O
we	O
ignore	O
the	O
distributional	O
interpretation	O
for	O
a	O
moment	O
and	O
view	O
each	O
as	O
a	O
separate	O
action	O
-	O
value	O
function	O
,	O
this	O
highlights	O
that	O
implicit	B-Method
quantile	I-Method
networks	I-Method
are	O
a	O
type	O
of	O
universal	B-Method
value	I-Method
function	I-Method
approximator	I-Method
(	O
UVFA	B-Method
)	O
.	O
	
There	O
may	O
be	O
additional	O
benefits	O
to	O
implicit	B-Method
quantile	I-Method
networks	I-Method
beyond	O
the	O
obvious	O
increase	O
in	O
representational	B-Metric
fidelity	I-Metric
.	O
	
As	O
with	O
UVFAs	B-Method
,	O
we	O
might	O
hope	O
that	O
training	O
over	O
many	O
different	O
’s	O
(	O
goals	O
in	O
the	O
case	O
of	O
the	O
UVFA	B-Method
)	O
leads	O
to	O
better	O
generalization	O
between	O
values	O
and	O
improved	O
sample	B-Metric
complexity	I-Metric
than	O
attempting	O
to	O
train	O
each	O
separately	O
.	O
	
Second	O
,	O
,	O
,	O
and	O
are	O
sampled	O
from	O
continuous	O
,	O
independent	O
,	O
distributions	O
.	O
	
Besides	O
,	O
we	O
also	O
explore	O
risk	B-Method
-	I-Method
sentive	I-Method
policies	I-Method
,	O
with	O
non	O
-	O
linear	O
.	O
	
The	O
independent	O
sampling	O
of	O
each	O
,	O
results	O
in	O
the	O
sample	O
TD	B-Metric
errors	O
being	O
decorrelated	O
,	O
and	O
the	O
estimated	O
action	O
-	O
values	O
go	O
from	O
being	O
the	O
true	O
mean	O
of	O
a	O
mixture	O
of	O
Diracs	O
to	O
a	O
sample	O
mean	O
of	O
the	O
implicit	O
distribution	O
defined	O
by	O
reparameterizing	O
the	O
sampling	O
distribution	O
via	O
the	O
learned	O
quantile	B-Method
function	I-Method
.	O
	
subsection	O
:	O
Implementation	O
	
Consider	O
the	O
neural	B-Method
network	I-Method
structure	I-Method
used	O
by	O
the	O
DQN	B-Method
agent	I-Method
.	O
	
Let	O
be	O
the	O
function	O
computed	O
by	O
the	O
convolutional	B-Method
layers	I-Method
and	O
the	O
subsequent	O
fully	B-Method
-	I-Method
connected	I-Method
layers	I-Method
mapping	O
to	O
the	O
estimated	O
action	O
-	O
values	O
,	O
such	O
that	O
.	O
	
For	O
our	O
network	O
we	O
use	O
the	O
same	O
functions	O
and	O
as	O
in	O
DQN	B-Method
,	O
but	O
include	O
an	O
additional	O
function	O
computing	O
an	O
embedding	O
for	O
the	O
sample	O
point	O
.	O
	
We	O
combine	O
these	O
to	O
form	O
the	O
approximation	B-Method
,	O
where	O
denotes	O
the	O
element	B-Method
-	I-Method
wise	I-Method
(	I-Method
Hadamard	I-Method
)	I-Method
product	I-Method
.	O
	
As	O
the	O
network	O
for	O
is	O
not	O
particularly	O
deep	O
,	O
we	O
use	O
the	O
multiplicative	O
form	O
,	O
,	O
to	O
force	O
interaction	O
between	O
the	O
convolutional	O
features	O
and	O
the	O
sample	B-Method
embedding	I-Method
.	O
	
Alternative	O
functional	O
forms	O
,	O
e.g.	O
concatenation	O
or	O
a	O
‘	O
residual	O
’	O
function	O
,	O
are	O
conceivable	O
,	O
and	O
can	O
be	O
parameterized	O
in	O
different	O
ways	O
.	O
	
To	O
investigate	O
these	O
,	O
we	O
compared	O
performance	O
across	O
a	O
number	O
of	O
architectural	B-Method
variants	I-Method
on	O
six	O
Atari	B-Material
2600	I-Material
games	I-Material
(	O
Asterix	B-Material
,	O
Assault	B-Material
,	O
Breakout	B-Material
,	O
Ms	O
.	O
	
Pacman	O
,	O
QBert	B-Material
,	O
Space	B-Material
Invaders	I-Material
)	O
.	O
	
Full	O
results	O
are	O
given	O
in	O
the	O
Appendix	O
.	O
	
Despite	O
minor	O
variation	O
in	O
performance	O
,	O
we	O
found	O
the	O
general	O
approach	O
to	O
be	O
robust	O
to	O
the	O
various	O
choices	O
.	O
	
Based	O
upon	O
the	O
results	O
we	O
used	O
the	O
following	O
function	O
in	O
our	O
later	O
experiments	O
,	O
for	O
embedding	B-Metric
dimension	I-Metric
:	O
After	O
settling	O
on	O
a	O
network	B-Method
architecture	I-Method
,	O
we	O
study	O
the	O
effect	O
of	O
the	O
number	O
of	O
samples	O
,	O
and	O
,	O
used	O
in	O
the	O
estimate	O
terms	O
of	O
Equation	O
[	O
reference	O
]	O
.	O
	
We	O
hypothesized	O
that	O
,	O
the	O
number	O
of	O
samples	O
of	O
,	O
would	O
affect	O
the	O
sample	B-Metric
complexity	I-Metric
of	O
IQN	B-Method
,	O
with	O
larger	O
values	O
leading	O
to	O
faster	O
learning	B-Task
,	O
and	O
that	O
with	O
one	O
would	O
potentially	O
approach	O
the	O
performance	O
of	O
DQN	B-Method
.	O
	
This	O
would	O
support	O
the	O
hypothesis	O
that	O
the	O
improved	O
performance	O
of	O
many	O
distributional	O
RL	B-Method
algorithms	O
rests	O
on	O
their	O
effect	O
as	O
auxiliary	O
loss	O
functions	O
,	O
which	O
would	O
vanish	O
in	O
the	O
case	O
of	O
.	O
	
Furthermore	O
,	O
we	O
believed	O
that	O
,	O
the	O
number	O
of	O
samples	O
of	O
,	O
would	O
affect	O
the	O
variance	O
of	O
the	O
gradient	O
	
estimates	O
much	O
like	O
a	O
mini	B-Method
-	I-Method
batch	I-Method
size	I-Method
hyperparameter	I-Method
.	O
	
Our	O
prediction	O
was	O
that	O
would	O
have	O
the	O
greatest	O
effect	O
on	O
variance	O
of	O
the	O
long	O
-	O
term	O
performance	O
of	O
the	O
agent	O
.	O
	
We	O
used	O
the	O
same	O
set	O
of	O
six	O
games	O
as	O
before	O
,	O
with	O
our	O
chosen	O
architecture	O
,	O
and	O
varied	O
.	O
	
In	O
Figure	O
[	O
reference	O
]	O
we	O
report	O
the	O
average	O
human	O
-	O
normalized	O
scores	O
on	O
the	O
six	O
games	O
for	O
each	O
configuration	O
.	O
	
Figure	O
[	O
reference	O
]	O
(	O
left	O
)	O
shows	O
the	O
average	O
performance	O
over	O
the	O
first	O
ten	O
million	O
frames	O
,	O
while	O
(	O
right	O
)	O
shows	O
the	O
average	O
performance	O
over	O
the	O
last	O
ten	O
million	O
(	O
from	O
190	O
M	O
to	O
200	O
M	O
)	O
.	O
	
As	O
expected	O
,	O
we	O
found	O
that	O
has	O
a	O
dramatic	O
effect	O
on	O
early	O
performance	O
,	O
shown	O
by	O
the	O
continual	O
improvement	O
in	O
score	O
as	O
the	O
value	O
increases	O
.	O
	
Additionally	O
,	O
we	O
observed	O
that	O
affected	O
performance	O
very	O
differently	O
than	O
expected	O
:	O
it	O
had	O
a	O
strong	O
effect	O
on	O
early	O
performance	O
,	O
but	O
minimal	O
impact	O
on	O
long	O
-	O
term	O
performance	O
past	O
.	O
	
Overall	O
,	O
while	O
using	O
more	O
samples	O
for	O
both	O
distributions	O
is	O
generally	O
favorable	O
,	O
appears	O
to	O
be	O
sufficient	O
to	O
achieve	O
the	O
majority	O
of	O
improvements	O
offered	O
by	O
IQN	B-Method
for	O
long	O
-	O
term	O
performance	O
,	O
with	O
variation	O
past	O
this	O
point	O
largely	O
insignificant	O
.	O
	
To	O
our	O
surprise	O
we	O
found	O
that	O
even	O
for	O
,	O
which	O
is	O
comparable	O
to	O
DQN	B-Method
in	O
the	O
number	O
of	O
loss	B-Method
components	I-Method
,	O
the	O
longer	O
term	O
performance	O
is	O
still	O
quite	O
strong	O
(	O
DQN	B-Method
)	O
.	O
	
In	O
an	O
informal	O
evaluation	O
,	O
we	O
did	O
not	O
find	O
IQN	B-Method
to	O
be	O
sensitive	O
to	O
,	O
the	O
number	O
of	O
samples	O
used	O
for	O
the	O
policy	O
,	O
and	O
have	O
fixed	O
it	O
at	O
for	O
all	O
experiments	O
.	O
	
section	O
:	O
Risk	B-Method
-	I-Method
Sensitive	I-Method
Reinforcement	I-Method
Learning	I-Method
	
In	O
this	O
section	O
,	O
we	O
explore	O
the	O
effects	O
of	O
varying	O
the	O
distortion	B-Metric
risk	I-Metric
measure	I-Metric
,	O
,	O
away	O
from	O
identity	O
.	O
	
This	O
only	O
affects	O
the	O
policy	O
,	O
,	O
used	O
both	O
in	O
Equation	O
[	O
reference	O
]	O
and	O
for	O
acting	O
in	O
the	O
environment	O
.	O
	
As	O
we	O
have	O
argued	O
,	O
evaluating	O
under	O
different	O
distortion	B-Metric
risk	I-Metric
measures	I-Metric
is	O
equivalent	O
to	O
changing	O
the	O
sampling	O
distribution	O
for	O
,	O
allowing	O
us	O
to	O
achieve	O
various	O
forms	O
of	O
risk	B-Task
-	I-Task
sensitive	I-Task
policies	I-Task
.	O
	
We	O
focus	O
on	O
a	O
handful	O
of	O
sampling	B-Method
distributions	I-Method
and	O
their	O
corresponding	O
distortion	B-Metric
measures	I-Metric
.	O
	
The	O
first	O
one	O
is	O
the	O
cumulative	B-Method
probability	I-Method
weighting	I-Method
parameterization	I-Method
proposed	O
in	O
cumulative	B-Method
prospect	I-Method
theory	I-Method
:	O
In	O
particular	O
,	O
we	O
use	O
the	O
parameter	O
value	O
found	O
by	O
wu1996curvature	O
to	O
most	O
closely	O
match	O
human	O
subjects	O
.	O
	
This	O
choice	O
is	O
interesting	O
as	O
,	O
unlike	O
the	O
others	O
we	O
consider	O
,	O
it	O
is	O
neither	O
globally	O
convex	O
nor	O
concave	O
.	O
	
For	O
small	O
values	O
of	O
it	O
is	O
locally	O
concave	O
and	O
for	O
larger	O
values	O
of	O
it	O
	
becomes	O
locally	O
convex	O
.	O
	
Recall	O
that	O
concavity	O
corresponds	O
to	O
risk	O
-	O
averse	O
and	O
convexity	O
to	O
risk	B-Task
-	I-Task
seeking	I-Task
policies	I-Task
.	O
	
Second	O
,	O
we	O
consider	O
the	O
distortion	B-Metric
risk	I-Metric
measure	I-Metric
proposed	O
by	O
wang2000class	O
,	O
where	O
and	O
are	O
taken	O
to	O
be	O
the	O
standard	O
Normal	B-Method
cumulative	I-Method
distribution	I-Method
function	I-Method
and	O
its	O
inverse	O
:	O
For	O
,	O
this	O
produces	O
risk	O
-	O
averse	O
policies	O
and	O
we	O
include	O
it	O
due	O
to	O
its	O
simple	O
interpretation	O
and	O
ability	O
to	O
switch	O
between	O
risk	O
-	O
averse	O
and	O
risk	O
-	O
seeking	O
distortions	O
.	O
	
Third	O
,	O
we	O
consider	O
a	O
simple	O
power	B-Method
formula	I-Method
for	O
risk	B-Task
-	I-Task
averse	I-Task
(	I-Task
)	I-Task
or	I-Task
risk	I-Task
-	I-Task
seeking	I-Task
(	I-Task
)	I-Task
policies	I-Task
:	O
Finally	O
,	O
we	O
consider	O
conditional	B-Method
value	I-Method
-	I-Method
at	I-Method
-	I-Method
risk	I-Method
(	O
CVaR	B-Method
)	O
:	O
CVaR	B-Method
has	O
been	O
widely	O
studied	O
in	O
and	O
out	O
of	O
reinforcement	B-Method
learning	I-Method
.	O
	
Its	O
implementation	O
as	O
a	O
modification	O
to	O
the	O
sampling	O
distribution	O
of	O
is	O
particularly	O
simple	O
,	O
as	O
it	O
changes	O
to	O
.	O
	
Another	O
interesting	O
sampling	B-Method
distribution	I-Method
,	O
not	O
included	O
in	O
our	O
experiments	O
,	O
is	O
denoted	O
and	O
corresponds	O
to	O
sampled	O
by	O
averaging	O
samples	O
from	O
.	O
	
In	O
Figure	O
[	O
reference	O
]	O
(	O
right	O
)	O
we	O
give	O
an	O
example	O
of	O
a	O
distribution	O
(	O
Neutral	O
)	O
and	O
how	O
each	O
of	O
these	O
distortion	B-Metric
measures	I-Metric
affects	O
the	O
implied	O
distribution	O
due	O
to	O
changing	O
the	O
sampling	O
distribution	O
of	O
.	O
and	O
reduce	O
the	O
impact	O
of	O
the	O
tails	O
of	O
the	O
distribution	O
,	O
while	O
and	O
heavily	O
shift	O
the	O
distribution	O
mass	O
towards	O
the	O
tails	O
,	O
creating	O
a	O
risk	O
-	O
averse	O
or	O
risk	O
-	O
seeking	O
preference	O
.	O
	
Additionally	O
,	O
while	O
CVaR	B-Method
entirely	O
ignores	O
all	O
values	O
corresponding	O
to	O
,	O
gives	O
these	O
non	O
-	O
zero	O
,	O
but	O
vanishingly	O
small	O
,	O
probability	O
.	O
	
By	O
using	O
these	O
sampling	B-Method
distributions	I-Method
we	O
can	O
induce	O
various	O
risk	B-Task
-	I-Task
sensitive	I-Task
policies	I-Task
in	O
IQN	B-Method
.	O
	
We	O
evaluate	O
these	O
on	O
the	O
same	O
set	O
of	O
six	O
Atari	B-Material
2600	I-Material
games	I-Material
previously	O
used	O
.	O
	
Our	O
algorithm	O
simply	O
changes	O
the	O
policy	O
to	O
maximize	O
the	O
distorted	O
expectations	O
instead	O
of	O
the	O
usual	O
sample	O
mean	O
.	O
	
Figure	O
[	O
reference	O
]	O
	
(	O
left	O
)	O
shows	O
our	O
results	O
in	O
this	O
experiment	O
,	O
with	O
average	O
scores	O
reported	O
under	O
the	O
usual	O
,	O
risk	O
-	O
neutral	O
,	O
evaluation	B-Metric
criterion	I-Metric
.	O
	
Intuitively	O
,	O
we	O
expected	O
to	O
see	O
a	O
qualitative	O
effect	O
from	O
risk	B-Method
-	I-Method
sensitive	I-Method
training	I-Method
,	O
e.g.	O
strengthened	O
exploration	B-Task
from	O
a	O
risk	O
-	O
seeking	O
objective	O
.	O
	
Although	O
we	O
did	O
see	O
qualitative	O
differences	O
,	O
these	O
did	O
not	O
always	O
match	O
our	O
expectations	O
.	O
	
For	O
two	O
of	O
the	O
games	O
,	O
Asterix	B-Material
and	O
Assault	B-Material
,	O
there	O
is	O
a	O
very	O
significant	O
advantage	O
to	O
the	O
risk	B-Method
-	I-Method
averse	I-Method
policies	I-Method
.	O
	
Although	O
tends	O
to	O
perform	O
almost	O
identically	O
to	O
the	O
standard	O
risk	B-Method
-	I-Method
neutral	I-Method
policy	I-Method
,	O
and	O
the	O
risk	B-Method
-	I-Method
seeking	I-Method
performs	O
as	O
well	O
or	O
worse	O
than	O
risk	O
-	O
neutral	O
,	O
we	O
find	O
that	O
both	O
risk	B-Method
-	I-Method
averse	I-Method
policies	I-Method
improve	O
performance	O
over	O
standard	O
IQN	B-Method
.	O
	
However	O
,	O
we	O
also	O
observe	O
that	O
the	O
more	O
risk	O
-	O
averse	O
of	O
the	O
two	O
,	O
,	O
suffers	O
some	O
loss	O
in	O
performance	O
on	O
two	O
other	O
games	O
(	O
QBert	B-Material
and	O
Space	B-Material
Invaders	I-Material
)	O
.	O
	
Additionally	O
,	O
we	O
note	O
that	O
the	O
risk	B-Method
-	I-Method
seeking	I-Method
policy	I-Method
significantly	O
underperforms	O
the	O
risk	B-Method
-	I-Method
neutral	I-Method
policy	I-Method
on	O
three	O
of	O
the	O
six	O
games	O
.	O
	
It	O
remains	O
an	O
open	O
question	O
as	O
to	O
exactly	O
why	O
we	O
see	O
improved	O
performance	O
for	O
risk	B-Method
-	I-Method
averse	I-Method
policies	I-Method
.	O
	
There	O
are	O
many	O
possible	O
explanations	O
for	O
this	O
phenomenon	O
,	O
e.g.	O
that	O
risk	O
-	O
aversion	O
encodes	O
a	O
heuristic	O
to	O
stay	O
alive	O
longer	O
,	O
which	O
in	O
many	O
games	O
is	O
correlated	O
with	O
increased	O
rewards	O
.	O
	
section	O
:	O
Full	O
Atari	B-Task
-	I-Task
57	I-Task
Results	O
	
Finally	O
,	O
we	O
evaluate	O
IQN	B-Method
on	O
the	O
full	O
Atari	B-Task
-	I-Task
57	I-Task
benchmark	O
,	O
comparing	O
with	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
performance	O
of	O
Rainbow	B-Method
,	O
a	O
distributional	O
RL	B-Method
agent	O
that	O
combines	O
several	O
advances	O
in	O
deep	O
RL	B-Method
,	O
the	O
closely	O
related	O
algorithm	O
QR	B-Method
-	I-Method
DQN	I-Method
,	O
prioritized	B-Method
experience	I-Method
replay	I-Method
DQN	I-Method
,	O
and	O
the	O
original	O
DQN	B-Method
agent	I-Method
.	O
	
Note	O
that	O
in	O
this	O
section	O
we	O
use	O
the	O
risk	O
-	O
neutral	O
variant	O
of	O
the	O
IQN	B-Method
,	O
that	O
is	O
,	O
the	O
policy	B-Method
of	O
the	O
IQN	B-Method
agent	O
is	O
the	O
regular	B-Method
-	I-Method
greedy	I-Method
policy	I-Method
with	O
respect	O
to	O
the	O
mean	O
of	O
the	O
state	O
-	O
action	O
return	O
distribution	O
.	O
	
It	O
is	O
important	O
to	O
remember	O
that	O
Rainbow	B-Method
builds	O
upon	O
the	O
distributional	O
RL	B-Method
algorithm	O
C51	O
,	O
but	O
also	O
includes	O
prioritized	B-Method
experience	I-Method
replay	I-Method
,	O
Double	B-Method
DQN	I-Method
,	O
Dueling	B-Method
Network	I-Method
architecture	I-Method
,	O
Noisy	B-Method
Networks	I-Method
,	O
and	O
multi	B-Method
-	I-Method
step	I-Method
updates	I-Method
.	O
	
In	O
particular	O
,	O
besides	O
the	O
distributional	O
update	O
,	O
-	O
step	O
updates	O
and	O
prioritized	O
experience	O
replay	O
were	O
found	O
to	O
have	O
significant	O
impact	O
on	O
the	O
performance	O
of	O
Rainbow	B-Task
.	O
	
Our	O
other	O
competitive	O
baseline	O
is	O
QR	B-Method
-	I-Method
DQN	I-Method
,	O
which	O
is	O
currently	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
for	O
agents	O
that	O
do	O
not	O
combine	O
distributional	O
updates	O
,	O
-	O
step	O
updates	O
,	O
and	O
prioritized	O
replay	O
.	O
	
Thus	O
,	O
between	O
QR	B-Method
-	I-Method
DQN	I-Method
and	O
the	O
much	O
more	O
complex	O
Rainbow	O
we	O
compare	O
to	O
the	O
two	O
most	O
closely	O
related	O
,	O
and	O
best	O
performing	O
,	O
agents	O
in	O
published	O
work	O
.	O
	
In	O
particular	O
,	O
we	O
would	O
expect	O
that	O
IQN	B-Method
would	O
benefit	O
from	O
the	O
additional	O
enhancements	O
in	O
Rainbow	O
,	O
just	O
as	O
Rainbow	B-Method
improved	O
significantly	O
over	O
C51	O
.	O
	
Figure	O
[	O
reference	O
]	O
shows	O
the	O
mean	O
(	O
left	O
)	O
and	O
median	O
(	O
right	O
)	O
human	B-Metric
-	I-Metric
normalized	I-Metric
scores	I-Metric
during	O
training	O
over	O
the	O
Atari	B-Task
-	I-Task
57	I-Task
benchmark	O
.	O
	
IQN	B-Method
dramatically	O
improves	O
over	O
QR	B-Method
-	I-Method
DQN	I-Method
,	O
which	O
itself	O
improves	O
on	O
many	O
previously	O
published	O
results	O
.	O
	
At	O
100	O
million	O
frames	O
IQN	B-Method
has	O
reached	O
the	O
same	O
level	O
of	O
performance	O
as	O
QR	B-Method
-	I-Method
DQN	I-Method
at	O
200	O
million	O
frames	O
.	O
	
Table	O
[	O
reference	O
]	O
gives	O
a	O
comparison	O
between	O
the	O
same	O
methods	O
in	O
terms	O
of	O
their	O
best	O
,	O
human	B-Metric
-	I-Metric
normalized	I-Metric
,	I-Metric
scores	I-Metric
per	O
game	O
under	O
the	O
30	O
random	O
	
no	O
-	O
op	O
start	O
condition	O
.	O
	
These	O
are	O
averages	O
over	O
the	O
given	O
number	O
of	O
seeds	O
.	O
	
Additionally	O
,	O
using	O
human	O
-	O
starts	O
,	O
IQN	B-Method
achieves	O
median	O
human	B-Metric
-	I-Metric
normalized	I-Metric
score	I-Metric
,	O
whereas	O
Rainbow	B-Method
reaches	O
,	O
see	O
Table	O
[	O
reference	O
]	O
.	O
	
Finally	O
,	O
we	O
took	O
a	O
closer	O
look	O
at	O
the	O
games	O
in	O
which	O
each	O
algorithm	O
continues	O
to	O
underperform	O
humans	O
,	O
and	O
computed	O
,	O
on	O
average	O
,	O
how	O
far	O
below	O
human	O
-	O
level	O
they	O
perform	O
.	O
	
We	O
refer	O
to	O
this	O
value	O
as	O
the	O
human	O
-	O
gapThanks	O
to	O
Joseph	O
Modayil	O
for	O
proposing	O
this	O
metric	O
.	O
	
metric	O
and	O
give	O
results	O
in	O
Table	O
[	O
reference	O
]	O
.	O
	
Interestingly	O
,	O
C51	B-Method
outperforms	O
QR	B-Method
-	I-Method
DQN	I-Method
in	O
this	O
metric	O
,	O
and	O
IQN	B-Method
outperforms	O
all	O
others	O
.	O
	
This	O
shows	O
that	O
the	O
remaining	O
gap	O
between	O
Rainbow	B-Method
and	O
IQN	B-Method
is	O
entirely	O
from	O
games	O
on	O
which	O
both	O
algorithms	O
are	O
already	O
super	O
-	O
human	O
.	O
	
The	O
games	O
where	O
the	O
most	O
progress	O
in	O
RL	B-Method
is	O
needed	O
happen	O
to	O
be	O
the	O
games	O
where	O
IQN	B-Method
shows	O
the	O
greatest	O
improvement	O
over	O
QR	B-Method
-	I-Method
DQN	I-Method
and	O
Rainbow	B-Method
.	O
	
section	O
:	O
Discussion	O
and	O
Conclusions	O
	
We	O
have	O
proposed	O
a	O
generalization	O
of	O
recent	O
work	O
based	O
around	O
using	O
quantile	B-Method
regression	I-Method
to	O
learn	O
the	O
distribution	O
over	O
returns	O
of	O
the	O
current	O
policy	O
.	O
	
Our	O
generalization	O
leads	O
to	O
a	O
simple	O
change	O
to	O
the	O
DQN	B-Method
agent	I-Method
to	O
enable	O
distributional	O
RL	B-Method
,	O
the	O
natural	B-Task
integration	I-Task
of	I-Task
risk	I-Task
-	I-Task
sensitive	I-Task
policies	I-Task
,	O
and	O
significantly	O
improved	O
performance	O
over	O
existing	O
methods	O
.	O
	
The	O
IQN	B-Method
algorithm	O
provides	O
,	O
for	O
the	O
first	O
time	O
,	O
a	O
fully	O
integrated	O
distributional	O
RL	B-Method
agent	O
without	O
prior	O
assumptions	O
on	O
the	O
parameterization	O
of	O
the	O
return	O
distribution	O
.	O
	
IQN	B-Method
can	O
be	O
trained	O
with	O
as	O
little	O
as	O
a	O
single	O
sample	O
from	O
each	O
state	O
-	O
action	O
value	O
distribution	O
,	O
or	O
as	O
many	O
as	O
computational	O
limits	O
allow	O
to	O
improve	O
the	O
algorithm	O
’s	O
data	B-Metric
efficiency	I-Metric
.	O
	
Furthermore	O
,	O
IQN	B-Method
allows	O
us	O
to	O
expand	O
the	O
class	O
of	O
control	B-Method
policies	I-Method
to	O
a	O
large	O
class	O
of	O
risk	B-Method
-	I-Method
sensitive	I-Method
policies	I-Method
connected	O
to	O
distortion	B-Metric
risk	I-Metric
measures	I-Metric
.	O
	
Finally	O
,	O
we	O
show	O
substantial	O
gains	O
on	O
the	O
Atari	B-Task
-	I-Task
57	I-Task
benchmark	O
over	O
QR	B-Method
-	I-Method
DQN	I-Method
,	O
and	O
even	O
halving	O
the	O
distance	B-Metric
between	O
QR	B-Method
-	I-Method
DQN	I-Method
and	O
Rainbow	B-Method
.	O
	
Despite	O
the	O
significant	O
empirical	O
successes	O
in	O
this	O
paper	O
there	O
are	O
many	O
areas	O
in	O
need	O
of	O
additional	O
theoretical	O
analysis	O
.	O
	
We	O
highlight	O
a	O
few	O
particularly	O
relevant	O
open	O
questions	O
we	O
were	O
unable	O
to	O
address	O
in	O
the	O
present	O
work	O
.	O
	
First	O
,	O
sample	O
-	O
based	O
convergence	O
results	O
have	O
been	O
recently	O
shown	O
for	O
a	O
class	O
of	O
categorical	O
distributional	O
RL	B-Method
algorithms	O
.	O
	
Could	O
existing	O
sample	O
-	O
based	O
RL	B-Method
convergence	O
results	O
be	O
extended	O
to	O
the	O
QR	B-Method
-	I-Method
based	I-Method
algorithms	I-Method
?	O
	
Second	O
,	O
can	O
the	O
contraction	B-Method
mapping	I-Method
results	O
for	O
a	O
fixed	O
grid	O
of	O
quantiles	O
given	O
by	O
dabney2017qr	O
be	O
extended	O
to	O
the	O
more	O
general	O
class	O
of	O
approximate	O
quantile	O
functions	O
studied	O
in	O
this	O
work	O
?	O
	
Finally	O
,	O
and	O
particularly	O
salient	O
to	O
our	O
experiments	O
with	O
distortion	B-Metric
risk	I-Metric
measures	I-Metric
,	O
theoretical	O
guarantees	O
for	O
risk	O
-	O
sensitive	O
RL	B-Method
have	O
been	O
building	O
over	O
recent	O
years	O
,	O
but	O
have	O
been	O
largely	O
limited	O
to	O
special	O
cases	O
and	O
restricted	O
classes	O
of	O
risk	B-Method
-	I-Method
sensitive	I-Method
policies	I-Method
.	O
	
Can	O
the	O
convergence	O
of	O
the	O
distribution	O
of	O
returns	O
under	O
the	O
Bellman	B-Method
operator	I-Method
be	O
leveraged	O
to	O
show	O
convergence	O
to	O
a	O
fixed	O
-	O
point	O
in	O
distorted	O
expectations	O
?	O
	
In	O
particular	O
,	O
can	O
the	O
control	O
results	O
of	O
c51	B-Method
be	O
expanded	O
to	O
cover	O
some	O
class	O
of	O
risk	B-Task
-	I-Task
sensitive	I-Task
policies	I-Task
?	O
	
There	O
remain	O
many	O
intriguing	O
directions	O
for	O
future	O
research	O
into	O
distributional	O
RL	B-Method
,	O
even	O
on	O
purely	O
empirical	O
fronts	O
.	O
	
hessel2018rainbow	O
recently	O
showed	O
that	O
distributional	O
RL	B-Method
agents	O
can	O
be	O
significantly	O
improved	O
,	O
when	O
combined	O
with	O
other	O
techniques	O
.	O
	
Creating	O
a	O
Rainbow	O
-	O
IQN	B-Method
agent	O
could	O
yield	O
even	O
greater	O
improvements	O
on	O
Atari	B-Task
-	I-Task
57	I-Task
.	O
	
We	O
also	O
recall	O
the	O
surprisingly	O
rich	O
return	O
distributions	O
found	O
by	O
barthmaron2018d4pg	O
,	O
and	O
hypothesize	O
that	O
the	O
continuous	B-Task
control	I-Task
setting	I-Task
may	O
be	O
a	O
particularly	O
fruitful	O
area	O
for	O
the	O
application	O
of	O
distributional	O
RL	B-Method
in	O
general	O
,	O
and	O
IQN	B-Method
in	O
particular	O
.	O
	
bibliography	O
:	O
References	O
	
section	O
:	O
Appendix	O
	
subsection	O
:	O
Architecture	O
and	O
Hyperparameters	O
	
We	O
considered	O
multiple	O
architectural	B-Method
variants	I-Method
for	O
parameterizing	O
an	O
IQN	B-Method
.	O
	
All	O
of	O
these	O
build	O
on	O
the	O
Q	B-Method
-	I-Method
network	I-Method
of	O
a	O
regular	B-Method
DQN	I-Method
,	O
which	O
can	O
be	O
seen	O
as	O
the	O
composition	O
of	O
a	O
convolutional	B-Method
stack	I-Method
and	O
an	O
MLP	B-Method
,	O
and	O
extend	O
it	O
by	O
an	O
embedding	O
of	O
the	O
sample	O
point	O
,	O
,	O
and	O
a	O
merging	O
function	O
,	O
resulting	O
in	O
the	O
function	O
For	O
the	O
embedding	B-Task
,	O
we	O
considered	O
a	O
number	O
of	O
variants	O
:	O
a	O
learned	B-Method
linear	I-Method
embedding	I-Method
,	O
a	O
learned	O
MLP	B-Method
embedding	I-Method
with	O
a	O
single	O
hidden	O
layer	O
of	O
size	O
,	O
and	O
a	O
learned	O
linear	O
function	O
of	O
cosine	O
basis	O
functions	O
of	O
the	O
form	O
.	O
	
Each	O
of	O
those	O
was	O
followed	O
by	O
either	O
a	O
ReLU	B-Method
or	I-Method
sigmoid	I-Method
nonlinearity	I-Method
.	O
	
For	O
the	O
merging	B-Method
function	I-Method
,	O
the	O
simplest	O
choice	O
would	O
be	O
a	O
simple	O
vector	B-Method
concatenation	I-Method
of	I-Method
and	I-Method
.	O
	
Note	O
however	O
,	O
that	O
the	O
MLP	B-Method
which	O
takes	O
in	O
the	O
output	O
of	O
and	O
outputs	O
the	O
action	O
-	O
value	O
quantiles	O
,	O
only	O
has	O
a	O
single	O
hidden	B-Method
layer	I-Method
in	O
the	O
DQN	B-Method
network	I-Method
.	O
	
Therefore	O
,	O
to	O
force	O
a	O
sufficiently	O
early	O
interaction	O
between	O
the	O
two	O
representations	O
,	O
we	O
also	O
considered	O
a	O
multiplicative	O
function	O
,	O
where	O
denotes	O
the	O
element	O
-	O
wise	O
(	O
Hadamard	O
)	O
product	O
of	O
two	O
vectors	O
,	O
as	O
well	O
as	O
a	O
‘	O
residual	O
’	O
function	O
.	O
	
Early	O
experiments	O
showed	O
that	O
a	O
simple	O
linear	B-Method
embedding	I-Method
of	I-Method
was	O
insufficient	O
to	O
achieve	O
good	O
performance	O
,	O
and	O
the	O
residual	B-Method
version	I-Method
of	O
did	O
n’t	O
show	O
any	O
marked	O
difference	O
to	O
the	O
multiplicative	B-Method
variant	I-Method
,	O
so	O
we	O
do	O
not	O
include	O
results	O
for	O
these	O
here	O
.	O
	
For	O
the	O
other	O
configurations	O
,	O
Figure	O
[	O
reference	O
]	O
shows	O
pairwise	O
comparisons	O
between	O
1	O
)	O
a	O
cosine	B-Method
basis	I-Method
function	I-Method
embedding	I-Method
and	O
a	O
completely	O
learned	O
MLP	B-Method
embedding	I-Method
,	O
2	O
)	O
an	O
embedding	O
size	O
(	O
hidden	O
layer	O
size	O
or	O
number	O
of	O
cosine	O
basis	O
elements	O
)	O
32	O
and	O
64	O
,	O
3	O
)	O
ReLU	O
and	O
sigmoid	O
nonlinearity	O
following	O
the	O
embedding	O
,	O
and	O
4	O
)	O
concatenation	O
and	O
a	O
multiplicative	O
interaction	O
between	O
and	O
.	O
	
Each	O
comparison	O
‘	O
violin	O
plot	O
’	O
can	O
be	O
understood	O
as	O
a	O
marginalization	O
over	O
the	O
other	O
variants	O
of	O
the	O
architecture	O
,	O
with	O
the	O
human	O
-	O
normalized	O
performance	O
at	O
the	O
end	O
of	O
training	O
,	O
averaged	O
across	O
six	O
Atari	B-Material
2600	I-Material
games	I-Material
,	O
on	O
the	O
y	O
-	O
axis	O
.	O
	
Each	O
white	O
dot	O
corresponds	O
to	O
a	O
configuration	O
(	O
each	O
represented	O
by	O
two	O
seeds	O
)	O
	
,	O
the	O
black	O
dots	O
show	O
the	O
position	O
of	O
our	O
preferred	O
configuration	O
.	O
	
The	O
width	O
of	O
the	O
colored	O
regions	O
corresponds	O
to	O
a	O
kernel	B-Method
density	I-Method
estimate	I-Method
of	O
the	O
number	O
of	O
configurations	O
at	O
each	O
performance	O
level	O
.	O
	
Our	O
final	O
choice	O
is	O
a	O
multiplicative	O
interaction	O
with	O
a	O
linear	O
function	O
of	O
a	O
cosine	B-Method
embedding	I-Method
,	O
with	O
and	O
a	O
ReLU	O
nonlinearity	O
(	O
see	O
Equation	O
[	O
reference	O
]	O
)	O
,	O
as	O
this	O
configuration	O
yielded	O
the	O
highest	O
performance	O
consistently	O
over	O
multiple	O
seeds	O
.	O
	
Also	O
noteworthy	O
is	O
the	O
overall	O
robustness	O
of	O
the	O
approach	O
to	O
these	O
variations	O
:	O
most	O
of	O
the	O
configurations	O
consistently	O
outperform	O
the	O
QR	B-Method
-	I-Method
DQN	I-Method
baseline	I-Method
shown	O
as	O
a	O
grey	O
horizontal	O
line	O
for	O
comparison	O
.	O
	
We	O
give	O
pseudo	O
-	O
code	O
for	O
the	O
IQN	B-Method
loss	I-Method
in	O
Algorithm	O
[	O
reference	O
]	O
.	O
	
All	O
other	O
hyperparameters	O
for	O
this	O
agent	O
correspond	O
to	O
the	O
ones	O
used	O
by	O
dabney2017qr	O
.	O
	
In	O
particular	O
,	O
the	O
Bellman	O
target	O
is	O
computed	O
using	O
a	O
target	B-Method
network	I-Method
.	O
	
Notice	O
that	O
IQN	B-Method
will	O
generally	O
be	O
more	O
computationally	O
expensive	O
per	O
-	O
sample	O
than	O
QR	B-Method
-	I-Method
DQN	I-Method
.	O
	
However	O
,	O
in	O
practice	O
IQN	B-Method
requires	O
many	O
fewer	O
samples	O
per	O
update	O
than	O
QR	B-Method
-	I-Method
DQN	I-Method
so	O
that	O
the	O
actual	O
running	B-Metric
times	I-Metric
are	O
comparable	O
.	O
	
[	O
ht	O
]	O
Implicit	O
Quantile	B-Method
Network	I-Method
Loss	I-Method
and	I-Method
functions	I-Method
,	O
	
#	O
Compute	O
greedy	B-Method
next	I-Method
action	I-Method
	
#	O
Sample	O
quantile	O
thresholds	O
#	O
Compute	O
distributional	O
temporal	O
differences	O
#	O
Compute	O
Huber	B-Method
quantile	I-Method
loss	I-Method
	
subsection	O
:	O
Evaluation	O
	
The	O
human	B-Metric
-	I-Metric
normalized	I-Metric
scores	I-Metric
reported	O
in	O
this	O
paper	O
are	O
given	O
by	O
the	O
formula	O
where	O
,	O
and	O
are	O
the	O
per	O
-	O
game	O
raw	O
scores	O
(	O
undiscounted	O
returns	O
)	O
for	O
the	O
given	O
agent	O
,	O
a	O
reference	O
human	O
player	O
,	O
and	O
random	B-Method
agent	I-Method
baseline	I-Method
.	O
	
The	O
‘	O
human	B-Metric
-	I-Metric
gap	I-Metric
’	I-Metric
metric	I-Metric
referred	O
to	O
at	O
the	O
end	O
of	O
Section	O
[	O
reference	O
]	O
builds	O
on	O
the	O
human	B-Metric
-	I-Metric
normalized	I-Metric
score	I-Metric
,	O
but	O
emphasizes	O
the	O
remaining	O
improvement	O
for	O
the	O
agent	O
to	O
reach	O
super	O
-	O
human	O
performance	O
.	O
	
It	O
is	O
given	O
by	O
,	O
with	O
a	O
value	O
of	O
corresponding	O
to	O
random	O
play	O
,	O
and	O
a	O
value	O
of	O
corresponding	O
to	O
super	O
-	O
human	O
level	O
of	O
performance	O
.	O
	
To	O
avoid	O
degeneracies	O
in	O
the	O
case	O
of	O
,	O
the	O
quantity	O
is	O
being	O
clipped	O
above	O
at	O
.	O
	
document	O
:	O
SeqGAN	B-Method
:	O
Sequence	B-Method
Generative	I-Method
Adversarial	I-Method
Nets	I-Method
with	O
Policy	B-Method
Gradient	I-Method
	
As	O
a	O
new	O
way	O
of	O
training	O
generative	B-Method
models	I-Method
,	O
Generative	B-Method
Adversarial	I-Method
Net	I-Method
(	O
GAN	B-Method
)	O
that	O
uses	O
a	O
discriminative	B-Method
model	I-Method
to	O
guide	O
the	O
training	O
of	O
the	O
generative	B-Method
model	I-Method
has	O
enjoyed	O
considerable	O
success	O
in	O
generating	O
real	O
-	O
valued	O
data	O
.	O
	
However	O
,	O
it	O
has	O
limitations	O
when	O
the	O
goal	O
is	O
for	O
generating	B-Task
sequences	I-Task
of	I-Task
discrete	I-Task
tokens	I-Task
.	O
	
A	O
major	O
reason	O
lies	O
in	O
that	O
the	O
discrete	O
outputs	O
from	O
the	O
generative	B-Method
model	I-Method
make	O
it	O
difficult	O
to	O
pass	O
the	O
gradient	O
update	O
from	O
the	O
discriminative	B-Method
model	I-Method
to	O
the	O
generative	B-Method
model	I-Method
.	O
	
Also	O
,	O
the	O
discriminative	B-Method
model	I-Method
can	O
only	O
assess	O
a	O
complete	O
sequence	O
,	O
while	O
for	O
a	O
partially	O
generated	O
sequence	O
,	O
it	O
is	O
non	O
-	O
trivial	O
to	O
balance	O
its	O
current	O
score	O
and	O
the	O
future	O
one	O
once	O
the	O
entire	O
sequence	O
has	O
been	O
generated	O
.	O
	
In	O
this	O
paper	O
,	O
we	O
propose	O
a	O
sequence	B-Method
generation	I-Method
framework	I-Method
,	O
called	O
SeqGAN	B-Method
,	O
to	O
solve	O
the	O
problems	O
.	O
	
Modeling	O
the	O
data	B-Method
generator	I-Method
as	O
a	O
stochastic	B-Method
policy	I-Method
in	O
reinforcement	B-Method
learning	I-Method
(	O
RL	B-Method
)	O
,	O
SeqGAN	B-Method
bypasses	O
the	O
generator	B-Task
differentiation	I-Task
problem	I-Task
by	O
directly	O
performing	O
gradient	B-Method
policy	I-Method
update	I-Method
.	O
	
The	O
RL	B-Method
reward	O
signal	O
comes	O
from	O
the	O
GAN	B-Method
discriminator	O
judged	O
on	O
a	O
complete	O
sequence	O
,	O
and	O
is	O
passed	O
back	O
to	O
the	O
intermediate	O
state	B-Method
-	I-Method
action	I-Method
steps	I-Method
using	O
Monte	B-Method
Carlo	I-Method
search	I-Method
.	O
	
Extensive	O
experiments	O
on	O
synthetic	O
data	O
and	O
real	O
-	O
world	O
tasks	O
demonstrate	O
significant	O
improvements	O
over	O
strong	O
baselines	O
.	O
	
section	O
:	O
Introduction	O
	
Generating	O
sequential	O
synthetic	O
data	O
that	O
mimics	O
the	O
real	O
one	O
is	O
an	O
important	O
problem	O
in	O
unsupervised	B-Task
learning	I-Task
.	O
	
Recently	O
,	O
recurrent	B-Method
neural	I-Method
networks	I-Method
(	O
RNNs	B-Method
)	O
with	O
long	B-Method
short	I-Method
-	I-Method
term	I-Method
memory	I-Method
(	O
LSTM	B-Method
)	O
cells	O
have	O
shown	O
excellent	O
performance	O
ranging	O
from	O
natural	B-Task
language	I-Task
generation	I-Task
to	O
handwriting	B-Task
generation	I-Task
.	O
	
The	O
most	O
common	O
approach	O
to	O
training	O
an	O
RNN	B-Method
is	O
to	O
maximize	O
the	O
log	O
predictive	O
likelihood	O
of	O
each	O
true	O
token	O
in	O
the	O
training	O
sequence	O
given	O
the	O
previous	O
observed	O
tokens	O
.	O
	
However	O
,	O
as	O
argued	O
in	O
,	O
the	O
maximum	B-Method
likelihood	I-Method
approaches	I-Method
suffer	O
from	O
so	O
-	O
called	O
exposure	O
bias	O
in	O
the	O
inference	B-Task
stage	I-Task
:	O
the	O
model	O
generates	O
a	O
sequence	O
iteratively	O
and	O
predicts	O
next	O
token	O
conditioned	O
on	O
its	O
previously	O
predicted	O
ones	O
that	O
may	O
be	O
never	O
observed	O
in	O
the	O
training	O
data	O
.	O
	
Such	O
a	O
discrepancy	O
between	O
training	O
and	O
inference	B-Task
can	O
incur	O
accumulatively	O
along	O
with	O
the	O
sequence	O
and	O
will	O
become	O
prominent	O
as	O
the	O
length	O
of	O
sequence	O
increases	O
.	O
	
To	O
address	O
this	O
problem	O
,	O
proposed	O
a	O
training	B-Method
strategy	I-Method
called	O
scheduled	B-Method
sampling	I-Method
(	O
SS	B-Method
)	O
,	O
where	O
the	O
generative	B-Method
model	I-Method
is	O
partially	O
fed	O
with	O
its	O
own	O
synthetic	O
data	O
as	O
prefix	O
(	O
observed	O
tokens	O
)	O
rather	O
than	O
the	O
true	O
data	O
when	O
deciding	O
the	O
next	O
token	O
in	O
the	O
training	O
stage	O
.	O
	
Nevertheless	O
,	O
showed	O
that	O
SS	B-Method
is	O
an	O
inconsistent	B-Method
training	I-Method
strategy	I-Method
and	O
fails	O
to	O
address	O
the	O
problem	O
fundamentally	O
.	O
	
Another	O
possible	O
solution	O
of	O
the	O
training	B-Task
/	I-Task
inference	I-Task
discrepancy	I-Task
problem	I-Task
is	O
to	O
build	O
the	O
loss	B-Method
function	I-Method
on	O
the	O
entire	O
generated	O
sequence	O
instead	O
of	O
each	O
transition	O
.	O
	
For	O
instance	O
,	O
in	O
the	O
application	O
of	O
machine	B-Task
translation	I-Task
,	O
a	O
task	B-Metric
specific	I-Metric
sequence	I-Metric
score	I-Metric
/	I-Metric
loss	I-Metric
,	O
bilingual	B-Metric
evaluation	I-Metric
understudy	I-Metric
(	O
BLEU	B-Metric
)	I-Metric
,	O
can	O
be	O
adopted	O
to	O
guide	O
the	O
sequence	B-Task
generation	I-Task
.	O
	
However	O
,	O
in	O
many	O
other	O
practical	O
applications	O
,	O
such	O
as	O
poem	B-Task
generation	I-Task
and	O
chatbot	B-Task
,	O
a	O
task	O
specific	O
loss	O
may	O
not	O
be	O
directly	O
available	O
to	O
score	O
a	O
generated	O
sequence	O
accurately	O
.	O
	
General	B-Method
adversarial	I-Method
net	I-Method
(	O
GAN	B-Method
)	O
proposed	O
by	O
is	O
a	O
promising	O
framework	O
for	O
alleviating	O
the	O
above	O
problem	O
.	O
	
Specifically	O
,	O
in	O
GAN	B-Method
a	O
discriminative	B-Method
net	I-Method
learns	O
to	O
distinguish	O
whether	O
a	O
given	O
data	O
instance	O
is	O
real	O
or	O
not	O
,	O
and	O
a	O
generative	B-Method
net	I-Method
learns	O
to	O
confuse	O
by	O
generating	O
high	O
quality	O
data	O
.	O
	
This	O
approach	O
has	O
been	O
successful	O
and	O
been	O
mostly	O
applied	O
in	O
computer	B-Task
vision	I-Task
tasks	I-Task
of	O
generating	B-Task
samples	I-Task
of	I-Task
natural	I-Task
images	I-Task
.	O
	
Unfortunately	O
,	O
applying	O
GAN	B-Method
to	O
generating	B-Task
sequences	I-Task
has	O
two	O
problems	O
.	O
	
Firstly	O
,	O
GAN	B-Method
is	O
designed	O
for	O
generating	O
real	O
-	O
valued	O
,	O
continuous	O
data	O
but	O
has	O
difficulties	O
in	O
directly	O
generating	B-Task
sequences	I-Task
of	I-Task
discrete	I-Task
tokens	I-Task
,	O
such	O
as	O
texts	O
.	O
	
The	O
reason	O
is	O
that	O
in	O
GANs	B-Method
,	O
the	O
generator	B-Method
starts	O
with	O
random	B-Method
sampling	I-Method
first	O
and	O
then	O
a	O
determistic	B-Method
transform	I-Method
,	O
govermented	O
by	O
the	O
model	O
parameters	O
.	O
	
As	O
such	O
,	O
the	O
gradient	O
of	O
the	O
loss	O
from	O
w.r.t	O
.	O
	
the	O
outputs	O
by	O
is	O
used	O
to	O
guide	O
the	O
generative	B-Method
model	I-Method
(	O
paramters	B-Method
)	O
to	O
slightly	O
change	O
the	O
generated	O
value	O
to	O
make	O
it	O
more	O
realistic	O
.	O
	
If	O
the	O
generated	O
data	O
is	O
based	O
on	O
discrete	O
tokens	O
,	O
the	O
“	O
slight	O
change	O
”	O
guidance	O
from	O
the	O
discriminative	B-Method
net	I-Method
makes	O
little	O
sense	O
because	O
there	O
is	O
probably	O
no	O
corresponding	O
token	O
for	O
such	O
slight	O
change	O
in	O
the	O
limited	O
dictionary	O
space	O
.	O
	
Secondly	O
,	O
GAN	B-Method
can	O
only	O
give	O
the	O
score	O
/	O
loss	O
for	O
an	O
entire	O
sequence	O
when	O
it	O
has	O
been	O
generated	O
;	O
for	O
a	O
partially	O
generated	O
sequence	O
,	O
it	O
is	O
non	O
-	O
trivial	O
to	O
balance	O
how	O
good	O
as	O
it	O
is	O
now	O
and	O
the	O
future	O
score	O
as	O
the	O
entire	O
sequence	O
.	O
	
In	O
this	O
paper	O
,	O
to	O
address	O
the	O
above	O
two	O
issues	O
,	O
we	O
follow	O
and	O
consider	O
the	O
sequence	B-Method
generation	I-Method
procedure	I-Method
as	O
a	O
sequential	B-Task
decision	I-Task
making	I-Task
process	I-Task
.	O
	
The	O
generative	B-Method
model	I-Method
is	O
treated	O
as	O
an	O
agent	O
of	O
reinforcement	B-Method
learning	I-Method
(	O
RL	B-Method
)	O
;	O
the	O
state	O
is	O
the	O
generated	O
tokens	O
so	O
far	O
and	O
the	O
action	O
is	O
the	O
next	O
token	O
to	O
be	O
generated	O
.	O
	
Unlike	O
the	O
work	O
in	O
that	O
requires	O
a	O
task	O
-	O
specific	O
sequence	O
score	O
,	O
such	O
as	O
BLEU	B-Metric
in	O
machine	B-Task
translation	I-Task
,	O
to	O
give	O
the	O
reward	O
,	O
we	O
employ	O
a	O
discriminator	B-Method
to	O
evaluate	O
the	O
sequence	O
and	O
feedback	O
the	O
evaluation	O
to	O
guide	O
the	O
learning	O
of	O
the	O
generative	B-Method
model	I-Method
.	O
	
To	O
solve	O
the	O
problem	O
that	O
the	O
gradient	O
can	O
not	O
pass	O
back	O
to	O
the	O
generative	B-Method
model	I-Method
when	O
the	O
output	O
is	O
discrete	O
,	O
we	O
regard	O
the	O
generative	B-Method
model	I-Method
as	O
a	O
stochastic	B-Method
parametrized	I-Method
policy	I-Method
.	O
	
In	O
our	O
policy	B-Method
gradient	I-Method
,	O
we	O
employ	O
Monte	B-Method
Carlo	I-Method
(	I-Method
MC	I-Method
)	I-Method
search	I-Method
to	O
approximate	O
the	O
state	O
-	O
action	O
value	O
.	O
	
We	O
directly	O
train	O
the	O
policy	B-Method
(	I-Method
generative	I-Method
model	I-Method
)	O
via	O
policy	B-Method
gradient	I-Method
,	O
which	O
naturally	O
avoids	O
the	O
differentiation	O
difficulty	O
for	O
discrete	O
data	O
in	O
a	O
conventional	O
GAN	B-Method
.	O
	
Extensive	O
experiments	O
based	O
on	O
synthetic	O
and	O
real	O
data	O
are	O
conducted	O
to	O
investigate	O
the	O
efficacy	O
and	O
properties	O
of	O
the	O
proposed	O
SeqGAN	B-Method
.	O
	
In	O
our	O
synthetic	O
data	O
environment	O
,	O
SeqGAN	B-Method
significantly	O
outperforms	O
the	O
maximum	B-Method
likelihood	I-Method
methods	I-Method
,	O
scheduled	B-Method
sampling	I-Method
and	O
PG	B-Method
-	I-Method
BLEU	I-Method
.	O
	
In	O
three	O
real	B-Task
-	I-Task
world	I-Task
tasks	I-Task
,	O
i.e.	O
poem	B-Task
generation	I-Task
,	O
speech	B-Task
language	I-Task
generation	O
and	O
music	B-Task
generation	I-Task
,	O
SeqGAN	B-Method
significantly	O
outperforms	O
the	O
compared	O
baselines	O
in	O
various	O
metrics	B-Metric
including	O
human	B-Metric
expert	I-Metric
judgement	I-Metric
.	O
	
section	O
:	O
Related	O
Work	O
	
Deep	B-Method
generative	I-Method
models	I-Method
have	O
recently	O
drawn	O
significant	O
attention	O
,	O
and	O
the	O
ability	O
of	O
learning	O
over	O
large	O
(	O
unlabeled	O
)	O
data	O
endows	O
them	O
with	O
more	O
potential	O
and	O
vitality	O
.	O
	
first	O
proposed	O
to	O
use	O
the	O
contrastive	B-Method
divergence	I-Method
algorithm	I-Method
to	O
efficiently	O
training	O
deep	B-Method
belief	I-Method
nets	I-Method
(	O
DBN	B-Method
)	I-Method
.	O
	
proposed	O
denoising	B-Method
autoencoder	I-Method
(	O
DAE	B-Method
)	O
that	O
learns	O
the	O
data	O
distribution	O
in	O
a	O
supervised	B-Method
learning	I-Method
fashion	I-Method
.	O
	
Both	O
DBN	B-Method
and	O
DAE	B-Method
learn	O
a	O
low	B-Method
dimensional	I-Method
representation	I-Method
(	O
encoding	B-Method
)	O
for	O
each	O
data	O
instance	O
and	O
generate	O
it	O
from	O
a	O
decoding	B-Method
network	I-Method
.	O
	
Recently	O
,	O
variational	B-Method
autoencoder	I-Method
(	O
VAE	B-Method
)	O
that	O
combines	O
deep	B-Method
learning	I-Method
with	O
statistical	B-Method
inference	I-Method
intended	O
to	O
represent	O
a	O
data	O
instance	O
in	O
a	O
latent	O
hidden	O
space	O
,	O
while	O
still	O
utilizing	O
(	O
deep	B-Method
)	I-Method
neural	I-Method
networks	I-Method
for	O
non	B-Task
-	I-Task
linear	I-Task
mapping	I-Task
.	O
	
The	O
inference	B-Task
is	O
done	O
via	O
variational	B-Method
methods	I-Method
.	O
	
All	O
these	O
generative	B-Method
models	I-Method
are	O
trained	O
by	O
maximizing	O
(	O
the	O
lower	O
bound	O
of	O
)	O
training	O
data	O
likelihood	O
,	O
which	O
,	O
as	O
mentioned	O
by	O
,	O
suffers	O
from	O
the	O
difficulty	O
of	O
approximating	B-Task
intractable	I-Task
probabilistic	I-Task
computations	I-Task
.	O
	
proposed	O
an	O
alternative	O
training	B-Method
methodology	I-Method
to	O
generative	B-Method
models	I-Method
,	O
i.e.	O
GANs	B-Method
,	O
where	O
the	O
training	B-Method
procedure	I-Method
is	O
a	O
minimax	B-Method
game	I-Method
between	O
a	O
generative	B-Method
model	I-Method
and	O
a	O
discriminative	B-Method
model	I-Method
.	O
	
This	O
framework	O
bypasses	O
the	O
difficulty	O
of	O
maximum	B-Method
likelihood	I-Method
learning	I-Method
and	O
has	O
gained	O
striking	O
successes	O
in	O
natural	B-Task
image	I-Task
generation	I-Task
.	O
	
However	O
,	O
little	O
progress	O
has	O
been	O
made	O
in	O
applying	O
GANs	B-Method
to	O
sequence	B-Task
discrete	I-Task
data	I-Task
generation	I-Task
problems	I-Task
,	O
e.g.	O
natural	B-Task
language	I-Task
generation	I-Task
.	O
	
This	O
is	O
due	O
to	O
the	O
generator	B-Method
network	I-Method
in	O
GAN	B-Method
is	O
designed	O
to	O
be	O
able	O
to	O
adjust	O
the	O
output	O
continuously	O
,	O
which	O
does	O
not	O
work	O
on	O
discrete	B-Task
data	I-Task
generation	I-Task
.	O
	
On	O
the	O
other	O
hand	O
,	O
a	O
lot	O
of	O
efforts	O
have	O
been	O
made	O
to	O
generate	O
structured	O
sequences	O
.	O
	
Recurrent	B-Method
neural	I-Method
networks	I-Method
can	O
be	O
trained	O
to	O
produce	O
sequences	O
of	O
tokens	O
in	O
many	O
applications	O
such	O
as	O
machine	B-Task
translation	I-Task
.	O
	
The	O
most	O
popular	O
way	O
of	O
training	O
RNNs	B-Method
is	O
to	O
maximize	O
the	O
likelihood	O
of	O
each	O
token	O
in	O
the	O
training	O
data	O
whereas	O
pointed	O
out	O
that	O
the	O
discrepancy	O
between	O
training	O
and	O
generating	O
makes	O
the	O
maximum	B-Method
likelihood	I-Method
estimation	I-Method
suboptimal	O
and	O
proposed	O
scheduled	B-Method
sampling	I-Method
strategy	O
(	O
SS	B-Method
)	O
.	O
	
Later	O
theorized	O
that	O
the	O
objective	O
function	O
underneath	O
SS	B-Method
is	O
improper	O
and	O
explained	O
the	O
reason	O
why	O
GANs	B-Method
tend	O
to	O
generate	O
natural	O
-	O
looking	O
samples	O
in	O
theory	O
.	O
	
Consequently	O
,	O
the	O
GANs	B-Method
have	O
great	O
potential	O
but	O
are	O
not	O
practically	O
feasible	O
to	O
discrete	B-Method
probabilistic	I-Method
models	I-Method
currently	O
.	O
	
As	O
pointed	O
out	O
by	O
,	O
the	O
sequence	B-Task
data	I-Task
generation	I-Task
can	O
be	O
formulated	O
as	O
a	O
sequential	B-Task
decision	I-Task
making	I-Task
process	I-Task
,	O
which	O
can	O
be	O
potentially	O
be	O
solved	O
by	O
reinforcement	B-Method
learning	I-Method
techniques	O
.	O
	
Modeling	O
the	O
sequence	B-Method
generator	I-Method
as	O
a	O
policy	O
of	O
picking	O
the	O
next	O
token	O
,	O
policy	B-Method
gradient	I-Method
methods	I-Method
can	O
be	O
adopted	O
to	O
optimize	O
the	O
generator	O
once	O
there	O
is	O
an	O
(	O
implicit	O
)	O
reward	O
function	O
to	O
guide	O
the	O
policy	O
.	O
	
For	O
most	O
practical	O
sequence	B-Task
generation	I-Task
tasks	I-Task
,	O
e.g.	O
machine	B-Task
translation	I-Task
,	O
the	O
reward	O
signal	O
is	O
meaningful	O
only	O
for	O
the	O
entire	O
sequence	O
,	O
for	O
instance	O
in	O
the	O
game	O
of	O
Go	B-Task
,	O
the	O
reward	O
signal	O
is	O
only	O
set	O
at	O
the	O
end	O
of	O
the	O
game	O
.	O
	
In	O
those	O
cases	O
,	O
state	B-Method
-	I-Method
action	I-Method
evaluation	I-Method
methods	I-Method
such	O
as	O
Monte	B-Method
Carlo	I-Method
(	I-Method
tree	I-Method
)	I-Method
search	I-Method
have	O
been	O
adopted	O
.	O
	
By	O
contract	O
,	O
our	O
proposed	O
SeqGAN	B-Method
extends	O
GANs	B-Method
with	O
the	O
RL	B-Method
-	O
based	O
generator	O
to	O
solve	O
the	O
sequence	B-Task
generation	I-Task
problem	I-Task
,	O
where	O
a	O
reward	O
signal	O
is	O
provided	O
by	O
the	O
discriminator	O
at	O
the	O
end	O
of	O
each	O
episode	O
via	O
Monte	B-Method
Carlo	I-Method
approach	I-Method
,	O
and	O
the	O
generator	O
picks	O
the	O
action	O
and	O
learns	O
the	O
policy	O
using	O
estimated	O
overall	O
rewards	O
.	O
	
section	O
:	O
Sequence	B-Method
Generative	I-Method
Adversarial	I-Method
Nets	I-Method
	
The	O
sequence	B-Task
generation	I-Task
problem	I-Task
is	O
denoted	O
as	O
follows	O
.	O
	
Given	O
a	O
dataset	O
of	O
real	O
-	O
world	O
structured	O
sequences	O
,	O
train	O
a	O
-	B-Method
parameterized	I-Method
generative	I-Method
model	I-Method
to	O
produce	O
a	O
sequence	O
,	O
where	O
is	O
the	O
vocabulary	O
of	O
candidate	O
tokens	O
.	O
	
We	O
interpret	O
this	O
problem	O
based	O
on	O
reinforcement	B-Method
learning	I-Method
.	O
	
In	O
timestep	O
,	O
the	O
state	O
is	O
the	O
current	O
produced	O
tokens	O
and	O
the	O
action	O
is	O
the	O
next	O
token	O
to	O
select	O
.	O
	
Thus	O
the	O
policy	B-Method
model	I-Method
is	O
stochastic	O
,	O
whereas	O
the	O
state	O
transition	O
is	O
deterministic	O
after	O
an	O
action	O
has	O
been	O
chosen	O
,	O
i.e.	O
for	O
the	O
next	O
state	O
if	O
the	O
current	O
state	O
and	O
the	O
action	O
;	O
for	O
other	O
next	O
states	O
,	O
.	O
	
Additionally	O
,	O
we	O
also	O
train	O
a	O
-	B-Method
parameterized	I-Method
discriminative	I-Method
model	I-Method
to	O
provide	O
a	O
guidance	O
for	O
improving	O
generator	B-Task
.	O
	
is	O
a	O
probability	O
indicating	O
how	O
likely	O
a	O
sequence	O
is	O
from	O
real	O
sequence	O
data	O
or	O
not	O
.	O
	
As	O
illustrated	O
in	O
Figure	O
[	O
reference	O
]	O
,	O
the	O
discriminative	B-Method
model	I-Method
is	O
trained	O
by	O
providing	O
positive	O
examples	O
from	O
the	O
real	O
sequence	O
data	O
and	O
negative	O
examples	O
from	O
the	O
synthetic	O
sequences	O
generated	O
from	O
the	O
generative	B-Method
model	I-Method
.	O
	
At	O
the	O
same	O
time	O
,	O
the	O
generative	B-Method
model	I-Method
is	O
updated	O
by	O
employing	O
a	O
policy	B-Method
gradient	I-Method
and	O
MC	B-Method
search	I-Method
on	O
the	O
basis	O
of	O
the	O
expected	O
end	O
reward	O
received	O
from	O
the	O
discriminative	B-Method
model	I-Method
.	O
	
The	O
reward	O
is	O
estimated	O
by	O
the	O
likelihood	O
that	O
it	O
would	O
fool	O
the	O
discriminative	B-Method
model	I-Method
.	O
	
The	O
specific	O
formulation	O
is	O
given	O
in	O
the	O
next	O
subsection	O
.	O
	
subsection	O
:	O
SeqGAN	B-Method
via	O
Policy	B-Method
Gradient	I-Method
	
Following	O
,	O
when	O
there	O
is	O
no	O
intermediate	O
reward	O
,	O
the	O
objective	O
of	O
the	O
generator	B-Method
model	I-Method
(	O
policy	B-Method
)	O
is	O
to	O
generate	O
a	O
sequence	O
from	O
the	O
start	O
state	O
to	O
maximize	O
its	O
expected	O
end	O
reward	O
:	O
where	O
is	O
the	O
reward	O
for	O
a	O
complete	O
sequence	O
.	O
	
Note	O
that	O
the	O
reward	O
is	O
from	O
the	O
discriminator	B-Method
,	O
which	O
we	O
will	O
discuss	O
later	O
.	O
	
is	O
the	O
action	O
-	O
value	O
function	O
of	O
a	O
sequence	O
,	O
i.e.	O
the	O
expected	O
accumulative	O
reward	O
starting	O
from	O
state	O
,	O
taking	O
action	O
,	O
and	O
then	O
following	O
policy	B-Method
.	O
	
The	O
rational	O
of	O
the	O
objective	O
function	O
for	O
a	O
sequence	O
is	O
that	O
starting	O
from	O
a	O
given	O
initial	O
state	O
,	O
the	O
goal	O
of	O
the	O
generator	O
is	O
to	O
generate	O
a	O
sequence	O
which	O
would	O
make	O
the	O
discriminator	O
consider	O
it	O
is	O
real	O
.	O
	
The	O
next	O
question	O
is	O
how	O
to	O
estimate	O
the	O
action	O
-	O
value	O
function	O
.	O
	
In	O
this	O
paper	O
,	O
we	O
use	O
the	O
REINFORCE	B-Method
algorithm	I-Method
and	O
consider	O
the	O
estimated	O
probability	O
of	O
being	O
real	O
by	O
the	O
discriminator	B-Method
as	O
the	O
reward	O
.	O
	
Formally	O
,	O
we	O
have	O
:	O
However	O
,	O
the	O
discriminator	B-Method
only	O
provides	O
a	O
reward	O
value	O
for	O
a	O
finished	O
sequence	O
.	O
	
Since	O
we	O
actually	O
care	O
about	O
the	O
long	O
-	O
term	O
reward	O
,	O
at	O
every	O
timestep	O
,	O
we	O
should	O
not	O
only	O
consider	O
the	O
fitness	O
of	O
previous	O
tokens	O
(	O
prefix	O
)	O
but	O
also	O
the	O
resulted	O
future	O
outcome	O
.	O
	
This	O
is	O
similar	O
to	O
playing	O
the	O
games	O
such	O
as	O
Go	O
or	O
Chess	B-Task
where	O
players	O
sometimes	O
would	O
give	O
up	O
the	O
immediate	O
interests	O
for	O
the	O
long	O
-	O
term	O
victory	O
.	O
	
Thus	O
,	O
to	O
evaluate	O
the	O
action	O
-	O
value	O
for	O
an	O
intermediate	O
state	O
,	O
we	O
apply	O
Monte	B-Method
Carlo	I-Method
search	I-Method
with	O
a	O
roll	B-Method
-	I-Method
out	I-Method
policy	I-Method
to	O
sample	O
the	O
unknown	O
last	O
tokens	O
.	O
	
We	O
represent	O
an	O
-	B-Method
time	I-Method
Monte	I-Method
Carlo	I-Method
search	I-Method
as	O
where	O
and	O
is	O
sampled	O
based	O
on	O
the	O
roll	B-Method
-	I-Method
out	I-Method
policy	I-Method
and	O
the	O
current	O
state	O
.	O
	
In	O
our	O
experiment	O
,	O
is	O
set	O
the	O
same	O
as	O
the	O
generator	O
,	O
but	O
one	O
can	O
use	O
a	O
simplified	O
version	O
if	O
the	O
speed	O
is	O
the	O
priority	O
.	O
	
To	O
reduce	O
the	O
variance	O
and	O
get	O
more	O
accurate	O
assessment	O
of	O
the	O
action	O
value	O
,	O
we	O
run	O
the	O
roll	B-Method
-	I-Method
out	I-Method
policy	I-Method
starting	O
from	O
current	O
state	O
till	O
the	O
end	O
of	O
the	O
sequence	O
for	O
times	O
to	O
get	O
a	O
batch	O
of	O
output	O
samples	O
.	O
	
Thus	O
,	O
we	O
have	O
:	O
where	O
,	O
we	O
see	O
that	O
when	O
no	O
intermediate	O
reward	O
,	O
the	O
function	O
is	O
iteratively	O
defined	O
as	O
the	O
next	O
-	O
state	O
value	O
starting	O
from	O
state	O
and	O
rolling	O
out	O
to	O
the	O
end	O
.	O
	
A	O
benefit	O
of	O
using	O
the	O
discriminator	B-Method
as	O
a	O
reward	O
function	O
is	O
that	O
it	O
can	O
be	O
dynamically	O
updated	O
to	O
further	O
improve	O
the	O
generative	B-Method
model	I-Method
iteratively	O
.	O
	
Once	O
we	O
have	O
a	O
set	O
of	O
more	O
realistic	O
generated	O
sequences	O
,	O
we	O
shall	O
re	O
-	O
train	O
the	O
discriminator	B-Method
model	I-Method
as	O
follows	O
	
:	O
Each	O
time	O
when	O
a	O
new	O
discriminator	B-Method
model	I-Method
has	O
been	O
obtained	O
,	O
we	O
are	O
ready	O
to	O
update	O
the	O
generator	B-Method
.	O
	
The	O
proposed	O
policy	B-Method
based	I-Method
method	I-Method
relies	O
upon	O
optimizing	O
a	O
parametrized	B-Method
policy	I-Method
to	O
directly	O
maximize	O
the	O
long	O
-	O
term	O
reward	O
.	O
	
Following	O
,	O
the	O
gradient	O
of	O
the	O
objective	O
function	O
w.r.t	O
.	O
	
the	O
generator	O
’s	O
parameters	O
can	O
be	O
derived	O
as	O
The	O
above	O
form	O
is	O
due	O
to	O
the	O
deterministic	O
state	O
transition	O
and	O
zero	O
intermediate	O
rewards	O
.	O
	
The	O
detailed	O
derivation	O
is	O
provided	O
in	O
the	O
appendix	O
.	O
	
Using	O
likelihood	O
ratios	O
,	O
we	O
build	O
an	O
unbiased	B-Method
estimation	I-Method
for	O
Eq	B-Task
.	O
	
(	O
[	O
reference	O
]	O
)	O
	
(	O
on	O
one	O
episode	O
)	O
:	O
where	O
is	O
the	O
observed	O
intermediate	O
state	O
sampled	O
from	O
.	O
	
Since	O
the	O
expectation	O
can	O
be	O
approximated	O
by	O
sampling	B-Method
methods	I-Method
,	O
we	O
then	O
update	O
the	O
generator	O
	
’s	O
parameters	O
as	O
:	O
where	O
denotes	O
the	O
corresponding	O
learning	O
rate	O
at	O
-	O
th	O
step	O
.	O
	
Also	O
the	O
advanced	O
gradient	B-Method
algorithms	I-Method
such	O
as	O
Adam	B-Method
and	O
RMSprop	B-Method
can	O
be	O
adopted	O
here	O
.	O
	
In	O
summary	O
,	O
Algorithm	O
[	O
reference	O
]	O
shows	O
full	O
details	O
of	O
the	O
proposed	O
SeqGAN	B-Method
.	O
	
At	O
the	O
beginning	O
of	O
the	O
training	O
,	O
we	O
use	O
the	O
maximum	B-Method
likelihood	I-Method
estimation	I-Method
(	O
MLE	B-Method
)	I-Method
to	O
pre	O
-	O
train	O
on	O
training	O
set	O
.	O
	
We	O
found	O
the	O
supervised	O
signal	O
from	O
the	O
pre	O
-	O
trained	O
discriminator	B-Method
is	O
informative	O
to	O
help	O
adjust	O
the	O
generator	B-Method
efficiently	O
.	O
	
After	O
the	O
pre	B-Task
-	I-Task
training	I-Task
,	O
the	O
generator	B-Method
and	I-Method
discriminator	I-Method
are	O
trained	O
alternatively	O
.	O
	
As	O
the	O
generator	O
gets	O
progressed	O
via	O
training	O
on	O
g	O
-	O
steps	O
updates	O
,	O
the	O
discriminator	B-Method
needs	O
to	O
be	O
re	O
-	O
trained	O
periodically	O
to	O
keeps	O
a	O
good	O
pace	O
with	O
the	O
generator	O
.	O
	
When	O
training	O
the	O
discriminator	B-Method
,	O
positive	O
examples	O
are	O
from	O
the	O
given	O
dataset	O
,	O
whereas	O
negative	O
examples	O
are	O
generated	O
from	O
our	O
generator	O
.	O
	
In	O
order	O
to	O
keep	O
the	O
balance	O
,	O
the	O
number	O
of	O
negative	O
examples	O
we	O
generate	O
for	O
each	O
d	B-Method
-	I-Method
step	I-Method
is	O
the	O
same	O
as	O
the	O
positive	O
examples	O
.	O
	
And	O
to	O
reduce	O
the	O
variability	O
of	O
the	O
estimation	B-Task
,	O
we	O
use	O
different	O
sets	O
of	O
negative	O
samples	O
combined	O
with	O
positive	O
ones	O
,	O
which	O
is	O
similar	O
to	O
bootstrapping	B-Method
.	O
	
[	O
t	O
]	O
Sequence	B-Method
Generative	I-Method
Adversarial	I-Method
Nets	I-Method
[	O
1	O
]	O
generator	B-Method
policy	I-Method
Gθ	I-Method
;	O
roll	B-Method
-	I-Method
out	I-Method
policy	I-Method
Gβ	I-Method
;	O
discriminator	B-Method
Dϕ	I-Method
;	O
a	O
sequence	O
dataset	O
=	O
	
S{X:1	O
T	O
}	O
Initialize	O
Gθ	B-Method
,	O
Dϕ	O
with	O
random	O
weights	O
θ	O
,	O
ϕ.	O
Gθ	O
using	O
MLE	B-Method
on	O
S	O
negative	O
samples	O
using	O
Gθ	O
for	O
training	O
Dϕ	O
Dϕ	O
via	O
minimizing	O
the	O
cross	B-Metric
entropy	I-Metric
a	O
sequence	O
Y:1T=	O
(	O
y1	O
,	O
…	O
,	O
yT	O
)	O
∼Gθ	O
in	O
:1	O
T	O
	
Q	O
(	O
a	O
=	O
	
yt;s	O
	
=	O
Y:1	O
-	O
t1	O
)	O
by	O
Eq	O
.	O
	
(	O
)	O
generator	O
parameters	O
via	O
policy	B-Method
gradient	I-Method
Eq	I-Method
.	O
	
(	O
)	O
current	O
Gθ	O
to	O
generate	O
negative	O
examples	O
and	O
combine	O
with	O
given	O
positive	O
examples	O
S	O
discriminator	O
Dϕ	O
for	O
k	O
epochs	O
by	O
Eq	O
.	O
	
(	O
)	O
converges	O
	
subsection	O
:	O
The	O
Generative	B-Method
Model	I-Method
for	O
Sequences	B-Task
	
We	O
use	O
recurrent	B-Method
neural	I-Method
networks	I-Method
(	O
RNNs	B-Method
)	O
as	O
the	O
generative	B-Method
model	I-Method
.	O
	
An	O
RNN	B-Method
maps	O
the	O
input	O
embedding	O
representations	O
of	O
the	O
sequence	O
into	O
a	O
sequence	O
of	O
hidden	O
states	O
by	O
using	O
the	O
update	O
function	O
recursively	O
.	O
	
Moreover	O
,	O
a	O
softmax	B-Method
output	I-Method
layer	I-Method
maps	O
the	O
hidden	O
states	O
into	O
the	O
output	O
token	O
distribution	O
where	O
the	O
parameters	O
are	O
a	O
bias	O
vector	O
and	O
a	O
weight	O
matrix	O
.	O
	
To	O
deal	O
with	O
the	O
common	O
vanishing	B-Task
and	I-Task
exploding	I-Task
gradient	I-Task
problem	I-Task
of	O
the	O
backpropagation	B-Task
through	I-Task
time	I-Task
,	O
we	O
leverage	O
the	O
Long	B-Method
Short	I-Method
-	I-Method
Term	I-Method
Memory	I-Method
(	O
LSTM	B-Method
)	O
cells	O
to	O
implement	O
the	O
update	O
function	O
in	O
Eq	O
.	O
	
(	O
[	O
reference	O
]	O
)	O
.	O
	
It	O
is	O
worth	O
noticing	O
that	O
most	O
of	O
the	O
RNN	B-Method
variants	I-Method
,	O
such	O
as	O
the	O
gated	B-Method
recurrent	I-Method
unit	I-Method
(	O
GRU	B-Method
)	O
and	O
soft	B-Method
attention	I-Method
mechanism	I-Method
,	O
can	O
be	O
used	O
as	O
a	O
generator	B-Method
in	O
SeqGAN	B-Method
.	O
	
subsection	O
:	O
The	O
Discriminative	B-Method
Model	I-Method
for	O
Sequences	B-Task
	
Deep	B-Method
discriminative	I-Method
models	I-Method
such	O
as	O
deep	B-Method
neural	I-Method
network	I-Method
(	O
DNN	B-Method
)	O
,	O
convolutional	B-Method
neural	I-Method
network	I-Method
(	O
CNN	B-Method
)	O
and	O
recurrent	O
convolutional	B-Method
neural	I-Method
network	I-Method
(	O
RCNN	B-Method
)	O
have	O
shown	O
a	O
high	O
performance	O
in	O
complicated	B-Task
sequence	I-Task
classification	I-Task
tasks	I-Task
.	O
	
In	O
this	O
paper	O
,	O
we	O
choose	O
the	O
CNN	B-Method
as	O
our	O
discriminator	B-Method
as	O
CNN	B-Method
has	O
recently	O
been	O
shown	O
of	O
great	O
effectiveness	O
in	O
text	B-Task
(	I-Task
token	I-Task
sequence	I-Task
)	I-Task
classification	I-Task
.	O
	
Most	O
discriminative	B-Method
models	I-Method
can	O
only	O
perform	O
classification	B-Task
well	O
for	O
an	O
entire	O
sequence	O
rather	O
than	O
the	O
unfinished	O
one	O
.	O
	
In	O
this	O
paper	O
,	O
we	O
also	O
focus	O
on	O
the	O
situation	O
where	O
the	O
discriminator	B-Method
predicts	O
the	O
probability	O
that	O
a	O
finished	O
sequence	O
is	O
real	O
.	O
	
We	O
first	O
represent	O
an	O
input	O
sequence	O
as	O
:	O
where	O
is	O
the	O
-	B-Method
dimensional	I-Method
token	I-Method
embedding	I-Method
and	O
is	O
the	O
concatenation	O
operator	O
to	O
build	O
the	O
matrix	O
.	O
	
Then	O
a	O
kernel	B-Method
applies	O
a	O
convolutional	B-Method
operation	I-Method
to	O
a	O
window	O
size	O
of	O
words	O
to	O
produce	O
a	O
new	O
feature	O
map	O
:	O
where	O
operator	O
is	O
the	O
summation	B-Method
of	I-Method
elementwise	I-Method
production	I-Method
,	O
is	O
a	O
bias	O
term	O
and	O
is	O
a	O
non	B-Method
-	I-Method
linear	I-Method
function	I-Method
.	O
	
We	O
can	O
use	O
various	O
numbers	O
of	O
kernels	O
with	O
different	O
window	O
sizes	O
to	O
extract	O
different	O
features	O
.	O
	
Finally	O
we	O
apply	O
a	O
max	B-Method
-	I-Method
over	I-Method
-	I-Method
time	I-Method
pooling	I-Method
operation	I-Method
over	O
the	O
feature	O
maps	O
.	O
	
To	O
enhance	O
the	O
performance	O
,	O
we	O
also	O
add	O
the	O
highway	B-Method
architecture	I-Method
based	O
on	O
the	O
pooled	O
feature	O
maps	O
.	O
	
Finally	O
,	O
a	O
fully	B-Method
connected	I-Method
layer	I-Method
with	O
sigmoid	O
activation	O
is	O
used	O
to	O
output	O
the	O
probability	O
that	O
the	O
input	O
sequence	O
is	O
real	O
.	O
	
The	O
optimization	B-Task
target	O
is	O
to	O
minimize	O
the	O
cross	O
entropy	O
between	O
the	O
ground	O
truth	O
label	O
and	O
the	O
predicted	O
probability	O
as	O
formulated	O
in	O
Eq	O
.	O
	
(	O
[	O
reference	O
]	O
)	O
.	O
	
Detailed	O
implementations	O
of	O
the	O
generative	B-Method
and	I-Method
discriminative	I-Method
models	I-Method
are	O
provided	O
in	O
the	O
appendix	O
.	O
	
section	O
:	O
Synthetic	O
Data	O
Experiments	O
	
To	O
test	O
the	O
efficacy	O
and	O
add	O
our	O
understanding	O
of	O
SeqGAN	B-Method
,	O
we	O
conduct	O
a	O
simulated	O
test	O
with	O
synthetic	O
data	O
.	O
	
To	O
simulate	O
the	O
real	O
-	O
world	O
structured	O
sequences	O
,	O
we	O
consider	O
a	O
language	B-Method
model	I-Method
to	O
capture	O
the	O
dependency	O
of	O
the	O
tokens	O
.	O
	
We	O
use	O
a	O
randomly	O
initialized	O
LSTM	B-Method
as	O
the	O
true	B-Method
model	I-Method
,	O
aka	B-Method
,	O
the	O
oracle	B-Method
,	O
to	O
generate	O
the	O
real	O
data	O
distribution	O
for	O
the	O
following	O
experiments	O
.	O
	
subsection	O
:	O
Evaluation	B-Metric
Metric	I-Metric
	
The	O
benefit	O
of	O
having	O
such	O
oracle	O
is	O
that	O
firstly	O
,	O
it	O
provides	O
the	O
training	O
dataset	O
and	O
secondly	O
evaluates	O
the	O
exact	O
performance	O
of	O
the	O
generative	B-Method
models	I-Method
,	O
which	O
will	O
not	O
be	O
possible	O
with	O
real	O
data	O
.	O
	
We	O
know	O
that	O
MLE	B-Method
is	O
trying	O
to	O
minimize	O
the	O
cross	B-Metric
-	I-Metric
entropy	I-Metric
between	O
the	O
true	O
data	O
distribution	O
and	O
our	O
approximation	O
,	O
i.e.	O
.	O
	
However	O
,	O
the	O
most	O
accurate	O
way	O
of	O
evaluating	O
generative	B-Method
models	I-Method
is	O
that	O
we	O
draw	O
some	O
samples	O
from	O
it	O
and	O
let	O
human	O
observers	O
review	O
them	O
based	O
on	O
their	O
prior	O
knowledge	O
.	O
	
We	O
assume	O
that	O
the	O
human	B-Method
observer	I-Method
has	O
learned	O
an	O
accurate	O
model	O
of	O
the	O
natural	O
distribution	O
.	O
	
Then	O
in	O
order	O
to	O
increase	O
the	O
chance	O
of	O
passing	O
Turing	O
Test	O
,	O
we	O
actually	O
need	O
to	O
minimize	O
the	O
exact	O
opposite	O
average	O
negative	O
log	O
-	O
likelihood	O
,	O
with	O
the	O
role	O
of	O
and	O
exchanged	O
.	O
	
In	O
our	O
synthetic	O
data	O
experiments	O
,	O
we	O
can	O
consider	O
the	O
oracle	O
to	O
be	O
the	O
human	O
observer	O
for	O
real	B-Task
-	I-Task
world	I-Task
problems	I-Task
,	O
thus	O
a	O
perfect	O
evaluation	B-Metric
metric	I-Metric
should	O
be	O
where	O
and	O
denote	O
our	O
generative	B-Method
model	I-Method
and	O
the	O
oracle	O
respectively	O
.	O
	
At	O
the	O
test	O
stage	O
,	O
we	O
use	O
to	O
generate	O
100	O
,	O
000	O
sequence	O
samples	O
and	O
calculate	O
for	O
each	O
sample	O
by	O
and	O
their	O
average	O
score	O
.	O
	
Also	O
significance	O
tests	O
are	O
performed	O
to	O
compare	O
the	O
statistical	B-Metric
properties	I-Metric
of	O
the	O
generation	B-Metric
performance	I-Metric
between	O
the	O
baselines	O
and	O
SeqGAN	B-Method
.	O
	
subsection	O
:	O
Training	O
Setting	O
	
To	O
set	O
up	O
the	O
synthetic	O
data	O
experiments	O
,	O
we	O
first	O
initialize	O
the	O
parameters	O
of	O
an	O
LSTM	B-Method
network	O
following	O
the	O
normal	B-Method
distribution	I-Method
as	O
the	O
oracle	O
describing	O
the	O
real	O
data	O
distribution	O
.	O
	
Then	O
we	O
use	O
it	O
to	O
generate	O
10	O
,	O
000	O
sequences	O
of	O
length	O
20	O
as	O
the	O
training	O
set	O
for	O
the	O
generative	B-Method
models	I-Method
.	O
	
In	O
SeqGAN	B-Method
algorithm	O
,	O
the	O
training	O
set	O
for	O
the	O
discriminator	B-Method
is	O
comprised	O
by	O
the	O
generated	O
examples	O
with	O
the	O
label	O
0	O
and	O
the	O
instances	O
from	O
with	O
the	O
label	O
1	O
.	O
	
For	O
different	O
tasks	O
,	O
one	O
should	O
design	O
specific	O
structure	O
for	O
the	O
convolutional	B-Method
layer	I-Method
and	O
in	O
our	O
synthetic	O
data	O
experiments	O
,	O
the	O
kernel	O
size	O
is	O
from	O
1	O
to	O
and	O
the	O
number	O
of	O
each	O
kernel	O
size	O
is	O
between	O
100	O
to	O
200	O
.	O
	
Dropout	B-Method
and	O
L2	B-Method
regularization	I-Method
are	O
used	O
to	O
avoid	O
over	B-Task
-	I-Task
fitting	I-Task
.	O
	
Four	O
generative	B-Method
models	I-Method
are	O
compared	O
with	O
SeqGAN	B-Method
.	O
	
The	O
first	O
model	O
is	O
a	O
random	B-Method
token	I-Method
generation	I-Method
.	O
	
The	O
second	O
one	O
is	O
the	O
MLE	O
trained	O
LSTM	B-Method
.	O
	
The	O
third	O
one	O
is	O
scheduled	B-Method
sampling	I-Method
.	O
	
The	O
fourth	O
one	O
is	O
the	O
Policy	B-Method
Gradient	I-Method
with	I-Method
BLEU	I-Method
(	O
PG	B-Method
-	I-Method
BLEU	I-Method
)	O
.	O
	
In	O
the	O
scheduled	B-Method
sampling	I-Method
,	O
the	O
training	O
process	O
gradually	O
changes	O
from	O
a	O
fully	B-Method
guided	I-Method
scheme	I-Method
feeding	O
the	O
true	O
previous	O
tokens	O
into	O
LSTM	B-Method
,	O
towards	O
a	O
less	O
guided	B-Method
scheme	I-Method
which	O
mostly	O
feeds	O
the	O
LSTM	B-Method
with	O
its	O
generated	O
tokens	O
.	O
	
A	O
curriculum	B-Metric
rate	I-Metric
is	O
used	O
to	O
control	O
the	O
probability	O
of	O
replacing	O
the	O
true	O
tokens	O
with	O
the	O
generated	O
ones	O
.	O
	
To	O
get	O
a	O
good	O
and	O
stable	O
performance	O
,	O
we	O
decrease	O
by	O
0.002	O
for	O
every	O
training	O
epoch	O
.	O
	
In	O
the	O
PG	B-Method
-	I-Method
BLEU	I-Method
algorithm	O
,	O
we	O
use	O
BLEU	B-Metric
,	O
a	O
metric	O
measuring	O
the	O
similarity	B-Metric
between	O
a	O
generated	O
sequence	O
and	O
references	O
(	O
training	O
data	O
)	O
,	O
to	O
score	O
the	O
finished	O
samples	O
from	O
Monte	B-Method
Carlo	I-Method
search	I-Method
.	O
	
subsection	O
:	O
Results	O
	
The	O
performance	O
of	O
generating	O
sequences	O
from	O
the	O
compared	O
policies	O
is	O
provided	O
in	O
Table	O
[	O
reference	O
]	O
.	O
	
Since	O
the	O
evaluation	B-Metric
metric	I-Metric
is	O
fundamentally	O
instructive	O
,	O
we	O
can	O
see	O
the	O
impact	O
of	O
SeqGAN	B-Method
,	O
which	O
outperforms	O
other	O
baselines	O
significantly	O
.	O
	
A	O
significance	O
	
T	O
-	O
test	O
on	O
the	O
score	O
distribution	O
of	O
the	O
generated	O
sequences	O
from	O
the	O
compared	O
models	O
is	O
also	O
performed	O
,	O
which	O
demonstrates	O
the	O
significant	O
improvement	O
of	O
SeqGAN	B-Method
over	O
all	O
compared	O
models	O
.	O
	
The	O
learning	O
curves	O
shown	O
in	O
Figure	O
[	O
reference	O
]	O
illustrate	O
the	O
superiority	O
of	O
SeqGAN	B-Method
explicitly	O
.	O
	
After	O
about	O
150	O
training	O
epochs	O
,	O
both	O
the	O
maximum	B-Method
likelihood	I-Method
estimation	I-Method
and	O
the	O
schedule	B-Method
sampling	I-Method
methods	I-Method
converge	O
to	O
a	O
relatively	O
high	O
score	O
,	O
whereas	O
SeqGAN	B-Method
can	O
improve	O
the	O
limit	O
of	O
the	O
generator	O
with	O
the	O
same	O
structure	O
as	O
the	O
baselines	O
significantly	O
.	O
	
This	O
indicates	O
the	O
prospect	O
of	O
applying	O
adversarial	B-Method
training	I-Method
strategies	I-Method
to	O
discrete	B-Method
sequence	I-Method
generative	I-Method
models	I-Method
to	O
breakthrough	O
the	O
limitations	O
of	O
MLE	B-Method
.	O
	
Additionally	O
,	O
SeqGAN	B-Method
outperforms	O
PG	B-Method
-	I-Method
BLEU	I-Method
,	O
which	O
means	O
the	O
discriminative	O
signal	O
in	O
GAN	B-Method
is	O
more	O
general	O
and	O
effective	O
than	O
a	O
predefined	O
score	O
(	O
e.g.	O
BLEU	B-Metric
)	O
to	O
guide	O
the	O
generative	B-Method
policy	I-Method
to	O
capture	O
the	O
underlying	O
distribution	O
of	O
the	O
sequence	O
data	O
.	O
	
subsection	O
:	O
Discussion	O
	
In	O
our	O
synthetic	O
data	O
experiments	O
,	O
we	O
find	O
that	O
the	O
stability	B-Metric
of	O
SeqGAN	B-Method
depends	O
on	O
the	O
training	B-Method
strategy	I-Method
.	O
	
More	O
specifically	O
,	O
the	O
g	O
-	O
steps	O
,	O
d	O
-	O
steps	O
and	O
parameters	O
in	O
Algorithm	O
[	O
reference	O
]	O
have	O
a	O
large	O
effect	O
on	O
the	O
convergence	B-Metric
and	O
performance	O
of	O
SeqGAN	B-Method
.	O
	
Figure	O
[	O
reference	O
]	O
shows	O
the	O
effect	O
of	O
these	O
parameters	O
.	O
	
In	O
Figure	O
[	O
reference	O
]	O
,	O
the	O
g	O
-	O
steps	O
is	O
much	O
larger	O
than	O
the	O
d	O
-	O
steps	O
and	O
epoch	O
number	O
,	O
which	O
means	O
we	O
train	O
the	O
generator	O
for	O
many	O
times	O
until	O
we	O
update	O
the	O
discriminator	B-Method
.	O
	
This	O
strategy	O
leads	O
to	O
a	O
fast	O
convergence	B-Metric
but	O
as	O
the	O
generator	B-Method
improves	O
quickly	O
,	O
the	O
discriminator	B-Method
can	O
not	O
get	O
fully	O
trained	O
and	O
thus	O
will	O
provide	O
a	O
misleading	O
signal	O
gradually	O
.	O
	
In	O
Figure	O
[	O
reference	O
]	O
,	O
with	O
more	O
discriminator	O
training	O
epochs	O
,	O
the	O
unstable	O
training	O
process	O
is	O
alleviated	O
.	O
	
In	O
Figure	O
[	O
reference	O
]	O
,	O
we	O
train	O
the	O
generator	O
for	O
only	O
one	O
epoch	O
and	O
then	O
before	O
the	O
discriminator	B-Method
gets	O
fooled	O
,	O
we	O
update	O
it	O
immediately	O
based	O
on	O
the	O
more	O
realistic	O
negative	O
examples	O
.	O
	
In	O
such	O
a	O
case	O
,	O
SeqGAN	B-Method
learns	O
stably	O
.	O
	
The	O
d	O
-	O
steps	O
in	O
all	O
three	O
training	O
strategies	O
described	O
above	O
is	O
set	O
to	O
1	O
,	O
which	O
means	O
we	O
only	O
generate	O
one	O
set	O
of	O
negative	O
examples	O
with	O
the	O
same	O
number	O
as	O
the	O
given	O
dataset	O
,	O
and	O
then	O
train	O
the	O
discriminator	O
on	O
it	O
for	O
various	O
epochs	O
.	O
	
But	O
actually	O
we	O
can	O
utilize	O
the	O
potentially	O
unlimited	O
number	O
of	O
negative	O
examples	O
to	O
improve	O
the	O
discriminator	B-Method
.	O
	
This	O
trick	O
can	O
be	O
considered	O
as	O
a	O
type	O
of	O
bootstrapping	B-Task
,	O
where	O
we	O
combine	O
the	O
fixed	O
positive	O
examples	O
with	O
different	O
negative	O
examples	O
to	O
obtain	O
multiple	O
training	O
sets	O
.	O
	
Figure	O
[	O
reference	O
]	O
shows	O
this	O
technique	O
can	O
improve	O
the	O
overall	O
performance	O
with	O
good	O
stability	O
,	O
since	O
the	O
discriminator	B-Method
is	O
shown	O
more	O
negative	O
examples	O
and	O
each	O
time	O
the	O
positive	O
examples	O
are	O
emphasized	O
,	O
which	O
will	O
lead	O
to	O
a	O
more	O
comprehensive	O
guidance	O
for	O
training	O
generator	O
.	O
	
This	O
is	O
in	O
line	O
with	O
the	O
theorem	O
in	O
.	O
	
When	O
analyzing	O
the	O
convergence	O
of	O
generative	B-Method
adversarial	I-Method
nets	I-Method
,	O
an	O
important	O
assumption	O
is	O
that	O
the	O
discriminator	B-Method
is	O
allowed	O
to	O
reach	O
its	O
optimum	O
given	O
.	O
	
Only	O
if	O
the	O
discriminator	B-Method
is	O
capable	O
of	O
differentiating	O
real	O
data	O
from	O
unnatural	O
data	O
consistently	O
,	O
the	O
supervised	O
signal	O
from	O
it	O
can	O
be	O
meaningful	O
and	O
the	O
whole	O
adversarial	B-Method
training	I-Method
process	I-Method
can	O
be	O
stable	O
and	O
effective	O
.	O
	
section	O
:	O
Real	B-Task
-	I-Task
world	I-Task
Scenarios	I-Task
	
To	O
complement	O
the	O
previous	O
experiments	O
,	O
we	O
also	O
test	O
SeqGAN	B-Method
on	O
several	O
real	B-Task
-	I-Task
world	I-Task
tasks	I-Task
,	O
i.e.	B-Task
poem	I-Task
composition	I-Task
,	O
speech	B-Task
language	I-Task
generation	O
and	O
music	B-Task
generation	I-Task
.	O
	
subsection	O
:	O
Text	B-Task
Generation	I-Task
	
For	O
text	B-Task
generation	I-Task
scenarios	I-Task
,	O
we	O
apply	O
the	O
proposed	O
SeqGAN	B-Method
to	O
generate	O
Chinese	B-Material
poems	I-Material
and	O
Barack	B-Material
Obama	I-Material
political	I-Material
speeches	I-Material
.	O
	
In	O
the	O
poem	B-Task
composition	I-Task
task	I-Task
,	O
we	O
use	O
a	O
corpus	O
of	O
16	O
,	O
394	O
Chinese	B-Material
quatrains	I-Material
,	O
each	O
containing	O
four	O
lines	O
of	O
twenty	O
characters	O
in	O
total	O
.	O
	
To	O
focus	O
on	O
a	O
fully	O
automatic	B-Task
solution	I-Task
and	O
stay	O
general	O
,	O
we	O
did	O
not	O
use	O
any	O
prior	O
knowledge	O
of	O
special	O
structure	O
rules	O
in	O
Chinese	B-Material
poems	I-Material
such	O
as	O
specific	O
phonological	O
rules	O
.	O
	
In	O
the	O
Obama	B-Task
political	I-Task
speech	I-Task
generation	I-Task
task	I-Task
,	O
we	O
use	O
a	O
corpus	O
,	O
which	O
is	O
a	O
collection	O
of	O
11	O
,	O
092	O
paragraphs	O
from	O
Obama	B-Material
’s	I-Material
political	I-Material
speeches	I-Material
.	O
	
We	O
use	O
BLEU	B-Metric
score	I-Metric
as	O
an	O
evaluation	B-Metric
metric	I-Metric
to	O
measure	O
the	O
similarity	B-Metric
degree	I-Metric
between	O
the	O
generated	O
texts	O
and	O
the	O
human	O
-	O
created	O
texts	O
.	O
	
BLEU	B-Metric
is	O
originally	O
designed	O
to	O
automatically	O
judge	O
the	O
machine	B-Metric
translation	I-Metric
quality	I-Metric
.	O
	
The	O
key	O
point	O
is	O
to	O
compare	O
the	O
similarity	O
between	O
the	O
results	O
created	O
by	O
machine	O
and	O
the	O
references	O
provided	O
by	O
human	O
.	O
	
Specifically	O
,	O
for	O
poem	B-Task
evaluation	I-Task
,	O
we	O
set	O
n	O
-	O
gram	O
to	O
be	O
2	O
(	O
BLEU	B-Metric
-	I-Metric
2	I-Metric
)	O
since	O
most	O
words	O
(	O
dependency	O
)	O
in	O
classical	O
Chinese	B-Material
poems	I-Material
consist	O
of	O
one	O
or	O
two	O
characters	O
and	O
for	O
the	O
similar	O
reason	O
,	O
we	O
use	O
BLEU	B-Metric
-	I-Metric
3	I-Metric
and	O
BLEU	B-Metric
-	I-Metric
4	I-Metric
to	O
evaluate	O
Obama	B-Task
speech	I-Task
generation	I-Task
performance	O
.	O
	
In	O
our	O
work	O
,	O
we	O
use	O
the	O
whole	O
test	O
set	O
as	O
the	O
references	O
instead	O
of	O
trying	O
to	O
find	O
some	O
references	O
for	O
the	O
following	O
line	O
given	O
the	O
previous	O
line	O
.	O
	
The	O
reason	O
is	O
in	O
generation	B-Task
tasks	I-Task
we	O
only	O
provide	O
some	O
positive	O
examples	O
and	O
then	O
let	O
the	O
model	O
catch	O
the	O
patterns	O
of	O
them	O
and	O
generate	O
new	O
ones	O
.	O
	
In	O
addition	O
to	O
BLEU	B-Metric
,	O
we	O
also	O
choose	O
poem	B-Task
generation	I-Task
as	O
a	O
case	O
for	O
human	B-Task
judgement	I-Task
since	O
a	O
poem	B-Material
is	O
a	O
creative	B-Task
text	I-Task
construction	I-Task
and	O
human	B-Task
evaluation	I-Task
is	O
ideal	O
.	O
	
Specifically	O
,	O
we	O
mix	O
the	O
20	O
real	O
poems	B-Task
and	O
20	O
each	O
generated	O
from	O
SeqGAN	B-Method
and	O
MLE	B-Method
.	O
	
Then	O
70	O
experts	O
on	O
Chinese	B-Material
poems	I-Material
are	O
invited	O
to	O
judge	O
whether	O
each	O
of	O
the	O
60	O
poem	O
is	O
created	O
by	O
human	O
or	O
machines	O
.	O
	
Once	O
regarded	O
to	O
be	O
real	O
,	O
it	O
gets	O
+	O
1	O
score	O
,	O
otherwise	O
0	O
.	O
	
Finally	O
,	O
the	O
average	O
score	O
for	O
each	O
algorithm	O
is	O
calculated	O
.	O
	
The	O
experiment	O
results	O
are	O
shown	O
in	O
Tables	O
[	O
reference	O
]	O
and	O
[	O
reference	O
]	O
,	O
from	O
which	O
we	O
can	O
see	O
the	O
significant	O
advantage	O
of	O
SeqGAN	B-Method
over	O
the	O
MLE	B-Method
in	O
text	B-Task
generation	I-Task
.	O
	
Particularly	O
,	O
for	O
poem	B-Task
composition	I-Task
,	O
SeqGAN	B-Method
performs	O
comparably	O
to	O
real	O
human	O
data	O
.	O
	
subsection	O
:	O
Music	B-Task
Generation	I-Task
	
For	O
music	B-Task
composition	I-Task
,	O
we	O
use	O
Nottingham	B-Material
dataset	I-Material
as	O
our	O
training	O
data	O
,	O
which	O
is	O
a	O
collection	O
of	O
695	O
music	O
of	O
folk	O
tunes	O
in	O
midi	O
file	O
format	O
.	O
	
We	O
study	O
the	O
solo	O
track	O
of	O
each	O
music	O
.	O
	
In	O
our	O
work	O
,	O
we	O
use	O
88	O
numbers	O
to	O
represent	O
88	O
pitches	O
,	O
which	O
correspond	O
to	O
the	O
88	O
keys	O
on	O
the	O
piano	O
.	O
	
With	O
the	O
pitch	B-Method
sampling	I-Method
for	O
every	O
0.4s	O
,	O
we	O
transform	O
the	O
midi	O
files	O
into	O
sequences	O
of	O
numbers	O
from	O
1	O
to	O
88	O
with	O
the	O
length	O
32	O
.	O
	
To	O
model	O
the	O
fitness	O
of	O
the	O
discrete	O
piano	O
key	O
patterns	O
,	O
BLEU	B-Metric
is	O
used	O
as	O
the	O
evaluation	B-Metric
metric	I-Metric
.	O
	
To	O
model	O
the	O
fitness	O
of	O
the	O
continuous	O
pitch	O
data	O
patterns	O
,	O
the	O
mean	B-Metric
squared	I-Metric
error	I-Metric
(	O
MSE	B-Metric
)	O
is	O
used	O
for	O
evaluation	O
.	O
	
From	O
Table	O
[	O
reference	O
]	O
,	O
we	O
see	O
that	O
SeqGAN	B-Method
outperforms	O
the	O
MLE	B-Method
significantly	O
in	O
both	O
metrics	O
in	O
the	O
music	B-Task
generation	I-Task
task	I-Task
.	O
	
section	O
:	O
Conclusion	O
	
In	O
this	O
paper	O
,	O
we	O
proposed	O
a	O
sequence	B-Method
generation	I-Method
method	I-Method
,	O
SeqGAN	B-Method
,	O
to	O
effectively	O
train	O
generative	B-Method
adversarial	I-Method
nets	I-Method
for	O
structured	B-Task
sequences	I-Task
generation	I-Task
via	O
policy	B-Method
gradient	I-Method
.	O
	
To	O
our	O
best	O
knowledge	O
,	O
this	O
is	O
the	O
first	O
work	O
extending	O
GANs	B-Method
to	O
generate	O
sequences	O
of	O
discrete	O
tokens	O
.	O
	
In	O
our	O
synthetic	O
data	O
experiments	O
,	O
we	O
used	O
an	O
oracle	B-Method
evaluation	I-Method
mechanism	I-Method
to	O
explicitly	O
illustrate	O
the	O
superiority	O
of	O
SeqGAN	B-Method
over	O
strong	O
baselines	O
.	O
	
For	O
three	O
real	B-Task
-	I-Task
world	I-Task
scenarios	I-Task
,	O
i.e.	O
,	O
poems	B-Task
,	O
speech	B-Task
language	I-Task
and	O
music	B-Task
generation	I-Task
,	O
SeqGAN	B-Method
showed	O
excellent	O
performance	O
on	O
generating	O
the	O
creative	O
sequences	O
.	O
	
We	O
also	O
performed	O
a	O
set	O
of	O
experiments	O
to	O
investigate	O
the	O
robustness	B-Metric
and	O
stability	B-Metric
of	O
training	O
SeqGAN	B-Method
.	O
	
For	O
future	O
work	O
,	O
we	O
plan	O
to	O
build	O
Monte	B-Method
Carlo	I-Method
tree	I-Method
search	I-Method
and	O
value	B-Method
network	I-Method
to	O
improve	O
action	B-Task
decision	I-Task
making	I-Task
for	O
large	O
scale	O
data	O
and	O
in	O
the	O
case	O
of	O
longer	B-Task
-	I-Task
term	I-Task
planning	I-Task
.	O
	
section	O
:	O
Acknowledgments	O
	
We	O
sincerely	O
thank	O
Tianxing	O
He	O
for	O
many	O
helpful	O
discussions	O
and	O
comments	O
on	O
the	O
manuscript	O
.	O
	
bibliography	O
:	O
References	O
	
appendix	O
:	O
Appendix	O
	
In	O
Section	O
1	O
,	O
we	O
present	O
the	O
step	O
-	O
by	O
-	O
step	O
derivation	O
of	O
Eq	O
.	O
	
(	O
6	O
)	O
in	O
the	O
paper	O
.	O
	
In	O
Section	O
2	O
,	O
the	O
detailed	O
realization	O
of	O
the	O
generative	B-Method
model	I-Method
and	O
the	O
discriminative	B-Method
model	I-Method
is	O
discussed	O
,	O
including	O
the	O
model	O
parameter	O
settings	O
.	O
	
In	O
Section	O
3	O
,	O
an	O
interesting	O
ablation	B-Task
study	I-Task
is	O
provided	O
,	O
which	O
is	O
a	O
supplementary	O
to	O
the	O
discussions	O
of	O
the	O
synthetic	O
data	O
experiments	O
.	O
	
subsection	O
:	O
Proof	O
for	O
Eq	O
.	O
(	O
6	O
)	O
	
For	O
readability	O
,	O
we	O
provide	O
the	O
detailed	O
derivation	O
of	O
Eq	O
.	O
	
(	O
6	O
)	O
here	O
by	O
following	O
.	O
	
As	O
mentioned	O
in	O
Sequence	B-Method
Generative	I-Method
Adversarial	I-Method
Nets	I-Method
section	O
,	O
the	O
state	O
transition	O
is	O
deterministic	O
after	O
an	O
action	O
has	O
been	O
chosen	O
,	O
i.e.	O
for	O
the	O
next	O
state	O
if	O
the	O
current	O
state	O
and	O
the	O
action	O
;	O
for	O
other	O
next	O
states	O
,	O
.	O
	
In	O
addition	O
,	O
the	O
intermediate	O
reward	O
is	O
0	O
.	O
	
We	O
re	O
-	O
write	O
the	O
action	O
value	O
and	O
state	O
value	O
as	O
follows	O
:	O
For	O
the	O
start	O
state	O
,	O
the	O
value	O
is	O
calculated	O
as	O
which	O
is	O
the	O
objective	O
function	O
to	O
maximize	O
in	O
Eq	O
.	O
	
(	O
1	O
)	O
of	O
the	O
paper	O
.	O
	
Then	O
we	O
can	O
obtain	O
the	O
gradient	O
of	O
the	O
objective	O
function	O
,	O
defined	O
in	O
Eq	O
.	O
	
(	O
1	O
)	O
,	O
w.r.t	O
.	O
	
the	O
generator	O
	
’s	O
parameters	O
:	O
which	O
is	O
the	O
result	O
in	O
Eq	O
.	O
	
(	O
6	O
)	O
of	O
the	O
paper	O
.	O
	
subsection	O
:	O
Model	O
Implementations	O
	
In	O
this	O
section	O
,	O
we	O
present	O
a	O
full	O
version	O
of	O
the	O
discussed	O
generative	B-Method
model	I-Method
and	O
discriminative	B-Method
model	I-Method
in	O
our	O
paper	O
submission	O
.	O
	
subsubsection	O
:	O
The	O
Generative	B-Method
Model	I-Method
for	O
Sequences	B-Task
	
We	O
use	O
recurrent	B-Method
neural	I-Method
networks	I-Method
(	O
RNNs	B-Method
)	O
as	O
the	O
generative	B-Method
model	I-Method
.	O
	
An	O
RNN	B-Method
maps	O
the	O
input	O
embedding	O
representations	O
of	O
the	O
sequence	O
into	O
a	O
sequence	O
of	O
hidden	O
states	O
by	O
using	O
the	O
update	O
function	O
recursively	O
.	O
	
Moreover	O
,	O
a	O
softmax	B-Method
output	I-Method
layer	I-Method
maps	O
the	O
hidden	O
states	O
into	O
the	O
output	O
token	O
distribution	O
where	O
the	O
parameters	O
are	O
a	O
bias	O
vector	O
and	O
a	O
weight	O
matrix	O
.	O
	
The	O
vanishing	B-Task
and	I-Task
exploding	I-Task
gradient	I-Task
problem	I-Task
in	O
backpropagation	B-Task
through	I-Task
time	I-Task
(	O
BPTT	B-Method
)	I-Method
issues	O
a	O
challenge	O
of	O
learning	B-Task
long	I-Task
-	I-Task
term	I-Task
dependencies	I-Task
to	O
recurrent	B-Method
neural	I-Method
network	I-Method
.	O
	
To	O
address	O
such	O
problems	O
,	O
gated	B-Method
RNNs	I-Method
have	O
been	O
designed	O
based	O
on	O
the	O
basic	O
idea	O
of	O
creating	O
paths	O
through	O
time	O
that	O
have	O
derivatives	O
that	O
neither	O
vanish	O
nor	O
explode	O
.	O
	
Among	O
various	O
gated	B-Method
RNNs	I-Method
,	O
we	O
choose	O
the	O
Long	B-Method
Short	I-Method
-	I-Method
Term	I-Method
Memory	I-Method
(	O
LSTM	B-Method
)	O
to	O
be	O
our	O
generative	B-Method
networks	I-Method
with	O
the	O
update	O
equations	O
:	O
where	O
is	O
the	O
vector	O
concatenation	O
and	O
is	O
the	O
elementwise	O
product	O
.	O
	
For	O
simplicity	O
,	O
we	O
use	O
the	O
standard	O
LSTM	B-Method
as	O
the	O
generator	B-Method
,	O
while	O
it	O
is	O
worth	O
noticing	O
that	O
most	O
of	O
the	O
RNN	B-Method
variants	I-Method
,	O
such	O
as	O
the	O
gated	B-Method
recurrent	I-Method
unit	I-Method
(	O
GRU	B-Method
)	O
and	O
soft	B-Method
attention	I-Method
mechanism	I-Method
,	O
can	O
be	O
used	O
as	O
a	O
generator	B-Method
in	O
SeqGAN	B-Method
.	O
	
The	O
standard	O
way	O
of	O
training	O
an	O
RNN	B-Method
is	O
the	O
maximum	B-Method
likelihood	I-Method
estimation	I-Method
(	O
MLE	B-Method
)	I-Method
,	O
which	O
involves	O
minimizing	O
the	O
negative	O
log	O
-	O
likelihood	O
for	O
a	O
generated	O
sequence	O
given	O
input	O
.	O
	
However	O
,	O
when	O
applying	O
MLE	B-Method
to	O
generative	B-Method
models	I-Method
,	O
there	O
is	O
a	O
discrepancy	O
between	O
training	O
and	O
generating	B-Task
,	O
which	O
motivates	O
our	O
work	O
.	O
	
subsubsection	B-Method
:	O
The	O
Discriminative	B-Method
Model	I-Method
for	O
Sequences	O
	
Deep	B-Method
discriminative	I-Method
models	I-Method
such	O
as	O
deep	B-Method
neural	I-Method
network	I-Method
(	O
DNN	B-Method
)	O
,	O
convolutional	B-Method
neural	I-Method
network	I-Method
(	O
CNN	B-Method
)	O
and	O
recurrent	O
convolutional	B-Method
neural	I-Method
network	I-Method
(	O
RCNN	B-Method
)	O
have	O
shown	O
a	O
high	O
performance	O
in	O
complicated	B-Task
sequence	I-Task
classification	I-Task
tasks	I-Task
.	O
	
In	O
this	O
paper	O
,	O
we	O
choose	O
the	O
CNN	B-Method
as	O
our	O
discriminator	B-Method
as	O
CNN	B-Method
has	O
recently	O
been	O
shown	O
of	O
great	O
effectiveness	O
in	O
text	B-Task
(	I-Task
token	I-Task
sequence	I-Task
)	I-Task
classification	I-Task
.	O
	
As	O
far	O
as	O
we	O
know	O
,	O
except	O
for	O
some	O
specific	O
tasks	O
,	O
most	O
discriminative	B-Method
models	I-Method
can	O
only	O
perform	O
classification	B-Task
well	O
for	O
a	O
whole	O
sequence	O
rather	O
than	O
the	O
unfinished	O
one	O
.	O
	
In	O
case	O
of	O
some	O
specific	O
tasks	O
,	O
one	O
may	O
design	O
a	O
classifier	B-Method
to	O
provide	O
intermediate	O
reward	O
signal	O
to	O
enhance	O
the	O
performance	O
of	O
our	O
framework	O
.	O
	
But	O
to	O
make	O
it	O
more	O
general	O
,	O
we	O
focus	O
on	O
the	O
situation	O
where	O
discriminator	B-Method
can	O
only	O
provide	O
final	O
reward	O
,	O
i.e.	O
,	O
the	O
probability	O
that	O
a	O
finished	O
sequence	O
was	O
real	O
.	O
	
We	O
first	O
represent	O
an	O
input	O
sequence	O
as	O
:	O
where	O
is	O
the	O
-	B-Method
dimensional	I-Method
token	I-Method
embedding	I-Method
and	O
is	O
the	O
vertical	O
concatenation	O
operator	O
to	O
build	O
the	O
matrix	O
.	O
	
Then	O
a	O
kernel	B-Method
applies	O
a	O
convolutional	B-Method
operation	I-Method
to	O
a	O
window	O
size	O
of	O
words	O
to	O
produce	O
a	O
new	O
feature	O
map	O
:	O
where	O
operator	O
is	O
the	O
summation	B-Method
of	I-Method
elementwise	I-Method
production	I-Method
,	O
is	O
a	O
bias	O
term	O
and	O
is	O
a	O
non	B-Method
-	I-Method
linear	I-Method
function	I-Method
.	O
	
We	O
can	O
use	O
various	O
numbers	O
of	O
kernels	O
with	O
different	O
window	O
sizes	O
to	O
extract	O
different	O
features	O
.	O
	
Specifically	O
,	O
a	O
kernel	B-Method
with	O
window	O
size	O
applied	O
to	O
the	O
concatenated	O
embeddings	O
of	O
input	O
sequence	O
will	O
produce	O
a	O
feature	B-Method
map	I-Method
	
Finally	O
we	O
apply	O
a	O
max	B-Method
-	I-Method
over	I-Method
-	I-Method
time	I-Method
pooling	I-Method
operation	I-Method
over	O
the	O
feature	O
map	O
and	O
pass	O
all	O
pooled	O
features	O
from	O
different	O
kernels	O
to	O
a	O
fully	B-Method
connected	I-Method
softmax	I-Method
layer	I-Method
to	O
get	O
the	O
probability	O
that	O
a	O
given	O
sequence	O
is	O
real	O
.	O
	
We	O
perform	O
an	O
empirical	O
experiment	O
to	O
choose	O
the	O
kernel	O
window	O
sizes	O
and	O
numbers	O
as	O
shown	O
in	O
Table	O
[	O
reference	O
]	O
.	O
	
For	O
different	O
tasks	O
,	O
one	O
should	O
design	O
specific	O
structures	O
for	O
the	O
discriminator	B-Method
.	O
	
To	O
enhance	O
the	O
performance	O
,	O
we	O
also	O
add	O
the	O
highway	B-Method
architecture	I-Method
before	O
the	O
final	O
fully	B-Method
connected	I-Method
layer	I-Method
:	O
where	O
,	O
and	O
are	O
highway	O
layer	O
weights	O
,	O
denotes	O
an	O
affine	O
transform	O
followed	O
by	O
a	O
non	O
-	O
linear	O
activation	O
function	O
such	O
as	O
a	O
rectified	B-Method
linear	I-Method
unit	I-Method
(	O
ReLU	B-Method
)	O
and	O
is	O
the	O
“	O
transform	O
gate	O
”	O
with	O
the	O
same	O
dimensionality	O
as	O
and	O
.	O
	
Finally	O
,	O
we	O
apply	O
a	O
sigmoid	B-Method
transformation	I-Method
to	O
get	O
the	O
probability	O
that	O
a	O
given	O
sequence	O
is	O
real	O
:	O
where	O
and	O
is	O
the	O
output	O
layer	O
weight	O
and	O
bias	O
.	O
	
When	O
optimizing	O
discriminative	B-Method
models	I-Method
,	O
supervised	B-Method
training	I-Method
is	O
applied	O
to	O
minimize	O
the	O
cross	B-Metric
entropy	I-Metric
,	O
which	O
is	O
widely	O
used	O
as	O
the	O
objective	B-Metric
function	I-Metric
for	O
classification	B-Task
and	I-Task
prediction	I-Task
tasks	I-Task
:	O
where	O
is	O
the	O
ground	O
truth	O
label	O
of	O
the	O
input	O
sequence	O
and	O
is	O
the	O
predicted	O
probability	O
from	O
the	O
discriminative	B-Method
models	I-Method
.	O
	
subsection	O
:	O
More	O
Ablation	B-Task
Study	I-Task
	
In	O
the	O
Discussion	O
subsection	O
of	O
Synthetic	O
Data	O
Experiments	O
section	O
of	O
our	O
paper	O
,	O
we	O
discussed	O
the	O
ablation	B-Task
study	I-Task
of	O
three	O
hyperparameters	O
of	O
SeqGAN	B-Method
,	O
i.e.	O
,	O
g	O
-	O
steps	O
,	O
d	O
-	O
steps	O
and	O
epoch	O
number	O
.	O
	
Here	O
we	O
provide	O
another	O
ablation	O
study	O
which	O
is	O
instructive	O
for	O
the	O
better	O
training	B-Task
of	O
SeqGAN	B-Method
.	O
	
As	O
described	O
in	O
our	O
paper	O
,	O
we	O
start	O
the	O
adversarial	B-Method
training	I-Method
process	I-Method
after	O
the	O
convergence	O
of	O
MLE	B-Method
supervised	I-Method
pre	I-Method
-	I-Method
training	I-Method
.	O
	
Here	O
we	O
further	O
conduct	O
experiments	O
to	O
investigate	O
the	O
performance	O
of	O
SeqGAN	B-Method
when	O
the	O
supervised	B-Task
pre	I-Task
-	I-Task
training	I-Task
is	O
insufficient	O
.	O
	
As	O
shown	O
in	O
Figure	O
[	O
reference	O
]	O
,	O
if	O
we	O
pre	O
-	O
train	O
the	O
generative	B-Method
model	I-Method
with	O
conventional	O
MLE	B-Method
methods	I-Method
for	O
only	O
20	O
epochs	O
,	O
which	O
is	O
far	O
from	O
convergence	O
,	O
then	O
the	O
adversarial	B-Method
training	I-Method
process	I-Method
improves	O
the	O
generator	O
quite	O
slowly	O
and	O
unstably	O
.	O
	
The	O
reason	O
is	O
that	O
in	O
SeqGAN	B-Method
,	O
the	O
discriminative	B-Method
model	I-Method
provides	O
reward	O
guidance	O
when	O
training	O
the	O
generator	O
and	O
if	O
the	O
generator	O
acts	O
almost	O
randomly	O
,	O
the	O
discriminator	B-Method
will	O
identify	O
the	O
generated	O
sequence	O
to	O
be	O
unreal	O
with	O
high	O
confidence	O
and	O
almost	O
every	O
action	O
the	O
generator	O
takes	O
receives	O
a	O
low	O
(	O
unified	O
)	O
reward	O
,	O
which	O
does	O
not	O
guide	O
the	O
generator	O
towards	O
a	O
good	O
improvement	O
direction	O
,	O
resulting	O
in	O
an	O
ineffective	O
training	B-Method
procedure	I-Method
.	O
	
This	O
indicates	O
that	O
in	O
order	O
to	O
apply	O
adversarial	B-Method
training	I-Method
strategies	I-Method
to	O
sequence	B-Method
generative	I-Method
models	I-Method
,	O
a	O
sufficient	O
pre	B-Method
-	I-Method
training	I-Method
is	O
necessary	O
.	O
	
Joint	B-Method
Maximum	I-Method
Purity	I-Method
Forest	I-Method
with	O
Application	O
to	O
Image	B-Task
Super	I-Task
-	I-Task
Resolution	I-Task
	
section	O
:	O
	
Abstract	O
-	O
In	O
this	O
paper	O
,	O
we	O
propose	O
a	O
novel	O
random	B-Method
-	I-Method
forest	I-Method
scheme	I-Method
,	O
namely	O
Joint	B-Method
Maximum	I-Method
Purity	I-Method
Forest	I-Method
(	O
JMPF	B-Method
)	O
,	O
for	O
classification	B-Task
,	I-Task
clustering	I-Task
,	I-Task
and	I-Task
regression	I-Task
tasks	I-Task
.	O
	
In	O
the	O
JMPF	B-Method
scheme	O
,	O
the	O
original	O
feature	O
space	O
is	O
transformed	O
into	O
a	O
compactly	O
pre	O
-	O
clustered	O
feature	O
space	O
,	O
via	O
a	O
trained	O
rotation	O
matrix	O
.	O
	
The	O
rotation	O
matrix	O
is	O
obtained	O
through	O
an	O
iterative	B-Method
quantization	I-Method
process	I-Method
,	O
where	O
the	O
input	O
data	O
belonging	O
to	O
different	O
classes	O
are	O
clustered	O
to	O
the	O
respective	O
vertices	O
of	O
the	O
new	O
feature	O
space	O
with	O
maximum	O
purity	O
.	O
	
In	O
the	O
new	O
feature	O
space	O
,	O
orthogonal	O
hyperplanes	O
,	O
which	O
are	O
employed	O
at	O
the	O
split	O
-	O
nodes	O
of	O
decision	O
trees	O
in	O
random	B-Method
forests	I-Method
,	O
can	O
tackle	O
the	O
clustering	B-Task
problems	I-Task
effectively	O
.	O
	
We	O
evaluated	O
our	O
proposed	O
method	O
on	O
public	O
benchmark	O
datasets	O
for	O
regression	B-Task
and	I-Task
classification	I-Task
tasks	I-Task
,	O
and	O
experiments	O
showed	O
that	O
JMPF	B-Method
remarkably	O
outperforms	O
other	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
random	B-Method
-	I-Method
forest	I-Method
-	I-Method
based	I-Method
approaches	I-Method
.	O
	
Furthermore	O
,	O
we	O
applied	O
JMPF	B-Method
to	O
image	B-Task
super	I-Task
-	I-Task
resolution	I-Task
,	O
because	O
the	O
transformed	O
,	O
compact	O
features	O
are	O
more	O
discriminative	O
to	O
the	O
clustering	B-Method
-	I-Method
regression	I-Method
scheme	I-Method
.	O
	
Experiment	O
results	O
on	O
several	O
public	O
benchmark	O
datasets	O
also	O
showed	O
that	O
the	O
JMPF	B-Method
-	O
based	O
image	O
super	O
-	O
resolution	O
scheme	O
is	O
consistently	O
superior	O
to	O
recent	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
image	B-Method
super	I-Method
-	I-Method
resolution	I-Method
algorithms	I-Method
.	O
	
section	O
:	O
	
from	O
achieving	O
the	O
optimal	O
hyperplanes	O
as	O
SVM	B-Method
does	O
(	O
i.e.	O
,	O
there	O
is	O
no	O
orthogonal	O
constraint	O
in	O
SVM	B-Method
)	O
in	O
some	O
original	O
feature	O
space	O
,	O
as	O
shown	O
in	O
Fig	O
.	O
1	O
(	O
a	O
)	O
.	O
	
In	O
this	O
paper	O
,	O
we	O
aim	O
to	O
solve	O
this	O
orthogonalconstraint	O
limitation	O
.	O
	
With	O
the	O
fixed	O
orthogonal	O
hyperplanes	O
,	O
we	O
propose	O
to	O
rotate	O
the	O
feature	O
space	O
,	O
this	O
is	O
equivalent	O
to	O
rotating	O
the	O
hyperplanes	O
,	O
in	O
such	O
a	O
way	O
that	O
global	B-Metric
maximum	I-Metric
purity	I-Metric
on	O
the	O
clustered	O
data	O
can	O
be	O
achieved	O
,	O
as	O
illustrated	O
in	O
Fig	O
.	O
2	O
.	O
	
This	O
strategy	O
can	O
achieve	O
a	O
joint	O
maximum	B-Metric
purity	I-Metric
for	O
all	O
the	O
split	O
-	O
nodes	O
when	O
training	O
a	O
random	B-Method
forest	I-Method
.	O
	
Image	B-Task
super	I-Task
-	I-Task
resolution	I-Task
can	O
be	O
performed	O
based	O
on	O
clustering	B-Method
/	I-Method
classification	I-Method
,	O
according	O
to	O
the	O
recent	O
emerging	O
clustering	B-Method
-	I-Method
regression	I-Method
stream	I-Method
[	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
,	O
and	O
the	O
JMPF	B-Method
scheme	O
can	O
achieve	O
remarkable	O
performance	O
on	O
both	O
the	O
classification	B-Task
and	I-Task
regression	I-Task
tasks	I-Task
.	O
	
Therefore	O
,	O
JMPF	B-Method
is	O
applied	O
to	O
single	B-Task
-	I-Task
image	I-Task
super	I-Task
-	I-Task
resolution	I-Task
in	O
this	O
paper	O
.	O
	
In	O
our	O
algorithm	O
,	O
principal	B-Method
component	I-Method
analysis	I-Method
(	O
PCA	B-Method
)	O
is	O
applied	O
to	O
the	O
features	O
for	O
dimensionality	B-Task
reduction	I-Task
.	O
	
The	O
projected	O
feature	O
space	O
is	O
then	O
rotated	O
to	O
a	O
compact	O
,	O
preclustered	O
feature	O
space	O
via	O
a	O
learned	O
rotation	O
matrix	O
.	O
	
Finally	O
,	O
for	O
all	O
the	O
split	O
-	O
nodes	O
trained	O
for	O
a	O
random	B-Method
forest	I-Method
,	O
their	O
thresholds	O
are	O
directly	O
set	O
to	O
the	O
inherent	O
zero	O
-	O
center	O
orthogonal	O
hyperplanes	O
in	O
the	O
rotated	O
feature	O
space	O
to	O
meet	O
the	O
maximum	B-Metric
-	I-Metric
purity	I-Metric
criterion	I-Metric
.	O
	
Experiment	O
results	O
show	O
that	O
JMPF	B-Method
can	O
achieve	O
more	O
accurate	O
clustering	B-Metric
/	I-Metric
classification	I-Metric
performance	O
on	O
random	B-Method
forests	I-Method
,	O
and	O
applying	O
JMPF	B-Method
to	O
image	B-Task
super	I-Task
-	I-Task
resolution	I-Task
can	O
achieve	O
superior	O
quality	O
,	O
compared	O
to	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
methods	O
.	O
	
Having	O
introduced	O
the	O
main	O
idea	O
of	O
our	O
proposed	O
algorithm	O
,	O
the	O
remainder	O
of	O
this	O
paper	O
is	O
organized	O
as	O
follows	O
.	O
	
In	O
Section	O
II	O
,	O
we	O
will	O
describe	O
our	O
proposed	O
scheme	O
,	O
the	O
joint	B-Method
maximum	I-Method
purity	I-Method
forest	I-Method
scheme	O
,	O
and	O
present	O
in	O
detail	O
how	O
to	O
compute	O
the	O
rotation	O
matrix	O
via	O
clustering	O
data	O
into	O
the	O
feature	O
-	O
space	O
vertices	O
.	O
	
Section	O
III	O
will	O
evaluate	O
our	O
proposed	O
method	O
and	O
compare	O
its	O
performance	O
with	O
recent	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
random	B-Method
-	I-Method
forest	I-Method
-	I-Method
based	I-Method
approaches	I-Method
on	O
regression	B-Task
and	I-Task
classification	I-Task
tasks	I-Task
.	O
	
In	O
Section	O
IV	O
,	O
we	O
will	O
validate	O
the	O
performance	O
of	O
JMPF	B-Method
scheme	O
on	O
single	B-Task
-	I-Task
image	I-Task
super	I-Task
-	I-Task
resolution	I-Task
.	O
	
Conclusions	O
are	O
given	O
in	O
Section	O
V.	O
	
section	O
:	O
II	O
.	O
JOINT	B-Method
MAXIMUM	I-Method
PURITY	I-Method
FOREST	I-Method
SCHEME	I-Method
	
section	O
:	O
II.1	O
Random	B-Method
Forest	I-Method
and	O
Our	O
Insights	O
	
A	O
random	B-Method
forest	I-Method
is	O
an	O
ensemble	B-Method
of	I-Method
binary	I-Method
decision	I-Method
trees	I-Method
	
(	O
)	O
:	O
→	O
ℝ	O
,	O
where	O
(	O
=	O
1	O
,	O
2	O
,	O
…	O
,	O
)	O
is	O
the	O
index	O
of	O
the	O
trees	O
,	O
∈	O
ℝ	O
is	O
the	O
m	O
-	O
dimension	O
feature	O
space	O
,	O
and	O
ℝ	O
=	O
	
[	O
0	O
,	O
1	O
]	O
represents	O
the	O
space	O
of	O
class	O
probability	O
distributions	O
over	O
the	O
label	O
space	O
=	O
{	O
1	O
,	O
.	O
.	O
.	O
,	O
}	O
.	O
	
As	O
shown	O
in	O
Fig	O
.	O
	
1	O
(	O
b	O
)	O
,	O
the	O
vertical	O
dotted	O
line	O
forms	O
a	O
hyperplane	O
,	O
=	O
0	O
,	O
chosen	O
in	O
the	O
first	O
split	O
-	O
node	O
for	O
separating	O
training	O
samples	O
,	O
and	O
the	O
horizontal	O
dotted	O
line	O
is	O
the	O
hyperplane	O
,	O
=	O
0	O
,	O
for	O
the	O
second	O
split	O
-	O
node	O
to	O
cluster	O
all	O
the	O
feature	O
data	O
assigned	O
to	O
this	O
node	O
.	O
	
This	O
results	O
in	O
separating	O
the	O
three	O
data	O
samples	O
(	O
Red	O
,	O
Green	O
and	O
Blue	O
)	O
into	O
three	O
leaf	O
-	O
nodes	O
.	O
	
It	O
can	O
be	O
seen	O
from	O
Fig	O
.	O
	
1	O
(	O
b	O
)	O
	
that	O
,	O
for	O
each	O
split	O
-	O
node	O
,	O
the	O
optimal	O
hyperplane	O
with	O
more	O
generalization	O
capability	O
is	O
the	O
one	O
which	O
can	O
achieve	O
maximum	O
purity	O
in	O
clustering	O
samples	O
into	O
two	O
groups	O
.	O
	
For	O
example	O
,	O
the	O
vertical	O
dotted	O
line	O
is	O
the	O
first	O
optimal	O
hyperplane	O
because	O
it	O
clusters	O
all	O
the	O
red	O
training	O
samples	O
into	O
the	O
right	O
node	O
,	O
while	O
all	O
the	O
blue	O
and	O
green	O
samples	O
are	O
clustered	O
into	O
the	O
left	O
node	O
.	O
	
Furthermore	O
,	O
the	O
left	O
margin	O
and	O
the	O
right	O
margin	O
are	O
equal	O
.	O
	
Although	O
there	O
is	O
no	O
guarantee	O
that	O
optimal	O
hyperplanes	O
can	O
be	O
determined	O
for	O
all	O
the	O
split	O
-	O
nodes	O
in	O
a	O
random	B-Method
forest	I-Method
,	O
approximated	O
optimal	O
hyperplanes	O
can	O
be	O
obtained	O
through	O
a	O
random	B-Method
bagging	I-Method
strategy	I-Method
.	O
	
The	O
training	O
of	O
a	O
whole	O
random	B-Method
forest	I-Method
is	O
to	O
train	O
all	O
of	O
its	O
decision	B-Method
trees	I-Method
,	O
by	O
choosing	O
the	O
candidate	O
features	O
and	O
thresholds	O
for	O
each	O
of	O
the	O
split	O
-	O
nodes	O
,	O
where	O
the	O
feature	O
dimensions	O
and	O
thresholds	O
are	O
determined	O
using	O
a	O
random	B-Method
bagging	I-Method
strategy	I-Method
.	O
	
In	O
the	O
prediction	B-Task
stage	I-Task
,	O
each	O
decision	B-Method
tree	I-Method
returns	O
a	O
class	O
probability	O
(	O
|	O
)	O
for	O
a	O
given	O
query	O
sample	O
∈	O
ℝ	O
,	O
and	O
the	O
final	O
class	O
label	O
y	O
	
*	O
is	O
then	O
obtained	O
via	O
averaging	B-Method
,	O
as	O
follows	O
:	O
	
*	O
=	O
arg	O
max	O
	
∑	O
(	O
|	O
)	O
.	O
	
The	O
splitting	B-Method
function	I-Method
for	O
a	O
split	O
-	O
node	O
is	O
denoted	O
as	O
(	O
;	O
Θ	O
)	O
,	O
where	O
is	O
a	O
sample	O
and	O
Θ	O
is	O
typically	O
parameterized	O
by	O
two	O
values	O
:	O
(	O
i	O
)	O
a	O
feature	O
dimension	O
Θ	O
Î{1	O
,	O
.	O
.	O
.	O
,	O
}	O
,	O
and	O
(	O
ii	O
)	O
a	O
threshold	O
Θ	O
Îℝ.	O
	
The	O
splitting	O
function	O
is	O
defined	O
as	O
follows	O
:	O
	
where	O
the	O
outcome	O
defines	O
to	O
which	O
child	O
node	O
the	O
sample	O
is	O
routed	O
,	O
and	O
0	O
and	O
1	O
are	O
the	O
two	O
labels	O
for	O
the	O
left	O
and	O
right	O
child	O
nodes	O
,	O
respectively	O
.	O
	
Each	O
node	O
chooses	O
the	O
best	O
splitting	O
function	O
Θ	O
*	O
out	O
of	O
a	O
randomly	O
sampled	O
set	O
{	O
Θ	O
}	O
by	O
optimizing	O
the	O
following	O
function	O
:	O
	
where	O
and	O
are	O
the	O
sets	O
of	O
samples	O
that	O
are	O
routed	O
to	O
the	O
left	O
and	O
the	O
right	O
child	O
nodes	O
,	O
and	O
|	O
|	O
represents	O
the	O
number	O
of	O
samples	O
in	O
the	O
set	O
.	O
	
During	O
the	O
training	O
of	O
a	O
random	B-Method
forest	I-Method
,	O
the	O
decision	B-Method
trees	I-Method
are	O
provided	O
with	O
a	O
random	O
subset	O
of	O
the	O
training	O
data	O
(	O
i.e.	O
bagging	O
)	O
,	O
and	O
are	O
trained	O
independently	O
of	O
each	O
other	O
.	O
	
Therefore	O
,	O
the	O
decision	B-Method
trees	I-Method
are	O
working	O
as	O
independent	O
experts	O
.	O
	
Taking	O
random	B-Method
-	I-Method
forest	I-Method
-	I-Method
based	I-Method
classification	I-Method
as	O
an	O
example	O
,	O
training	O
a	O
single	O
decision	B-Method
tree	I-Method
involves	O
recursively	O
splitting	O
each	O
node	O
,	O
such	O
that	O
the	O
training	O
data	O
in	O
each	O
newly	O
created	O
child	O
node	O
is	O
clustered	O
according	O
to	O
their	O
corresponding	O
class	O
labels	O
,	O
so	O
the	O
purity	O
at	O
each	O
node	O
is	O
increasing	O
along	O
a	O
tree	O
.	O
	
Each	O
tree	O
is	O
grown	O
until	O
a	O
stopping	B-Metric
criterion	I-Metric
is	O
reached	O
(	O
e.g.	O
the	O
number	O
of	O
samples	O
in	O
a	O
node	O
is	O
less	O
than	O
a	O
threshold	O
or	O
the	O
tree	O
depth	O
reaches	O
a	O
maximum	O
value	O
)	O
and	O
the	O
class	O
probability	O
distributions	O
are	O
estimated	O
in	O
the	O
leaf	O
-	O
nodes	O
.	O
	
After	O
fulfilling	O
one	O
of	O
these	O
criteria	O
,	O
a	O
density	B-Method
model	I-Method
(	O
)	O
in	O
the	O
leaf	O
-	O
node	O
is	O
estimated	O
by	O
all	O
samples	O
falling	O
into	O
this	O
leaf	O
-	O
node	O
for	O
predicting	O
the	O
target	O
value	O
in	O
the	O
testing	O
stage	O
.	O
	
A	O
simple	O
way	O
to	O
estimate	O
the	O
probability	O
distribution	O
(	O
)	O
is	O
averaging	O
all	O
the	O
samples	O
in	O
the	O
leaf	O
-	O
node	O
,	O
while	O
there	O
are	O
also	O
variant	O
methods	O
,	O
such	O
as	O
fitting	O
a	O
Gaussian	B-Method
distribution	I-Method
or	O
kernel	B-Method
density	I-Method
estimation	I-Method
,	O
ridge	B-Method
regression	I-Method
[	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
,	O
and	O
so	O
on	O
.	O
	
(	O
)	O
is	O
the	O
local	O
score	O
for	O
a	O
set	O
of	O
samples	O
(	O
is	O
either	O
or	O
)	O
,	O
which	O
normally	O
is	O
calculated	O
using	O
entropy	O
as	O
in	O
Eqn	O
.	O
	
(	O
4	O
)	O
,	O
but	O
it	O
can	O
be	O
replaced	O
by	O
variance	O
[	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
or	O
the	O
Gini	O
index	O
	
[	O
reference	O
]	O
.	O
	
where	O
K	O
is	O
the	O
number	O
of	O
classes	O
,	O
and	O
(	O
|	O
)	O
is	O
the	O
probability	O
for	O
class	O
,	O
given	O
the	O
set	O
.	O
	
For	O
the	O
regression	B-Task
problem	I-Task
,	O
the	O
differential	O
entropy	O
:	O
	
over	O
continuous	O
outputs	O
can	O
be	O
employed	O
,	O
where	O
(	O
|	O
)	O
denotes	O
the	O
conditional	O
probability	O
of	O
a	O
target	O
variable	O
given	O
the	O
input	O
sample	O
.	O
	
Assuming	O
(	O
.	O
,	O
.	O
)	O
	
to	O
be	O
a	O
Gaussian	B-Method
distribution	I-Method
and	O
having	O
only	O
a	O
finite	O
set	O
of	O
samples	O
,	O
the	O
differential	O
entropy	O
can	O
be	O
written	O
in	O
closed	O
form	O
as	O
	
where	O
det	O
(	O
Σ	O
)	O
is	O
the	O
determinant	O
of	O
the	O
estimated	O
covariance	O
matrix	O
of	O
the	O
target	O
variables	O
in	O
.	O
	
For	O
training	O
each	O
decision	O
tree	O
in	O
a	O
random	B-Method
forest	I-Method
,	O
the	O
goal	O
on	O
each	O
split	O
-	O
node	O
is	O
to	O
maximize	O
the	O
information	B-Metric
gain	I-Metric
(	O
IG	B-Metric
)	O
by	O
reducing	O
the	O
entropy	O
after	O
splitting	O
.	O
	
IG	B-Method
is	O
defined	O
as	O
follows	O
:	O
	
Since	O
each	O
decision	O
tree	O
is	O
a	O
binary	O
tree	O
and	O
each	O
step	O
is	O
to	O
split	O
a	O
current	O
node	O
(	O
a	O
parent	O
set	O
)	O
into	O
two	O
children	O
nodes	O
(	O
and	O
sets	O
)	O
,	O
IG	O
can	O
be	O
described	O
as	O
follows	O
:	O
	
where	O
ℋ	O
is	O
the	O
optimal	O
hyperplane	O
of	O
the	O
split	O
-	O
node	O
,	O
and	O
Eqn	O
.	O
	
(	O
8	O
)	O
is	O
the	O
target	O
function	O
of	O
each	O
splitnode	O
when	O
training	O
each	O
decision	B-Method
tree	I-Method
of	O
a	O
random	B-Method
forest	I-Method
.	O
	
As	O
we	O
can	O
see	O
from	O
Fig	O
.	O
	
1	O
(	O
b	O
)	O
,	O
all	O
the	O
optimal	O
hyperplanes	O
from	O
split	O
-	O
nodes	O
are	O
achieved	O
independently	O
and	O
locally	O
.	O
	
Since	O
each	O
optimal	O
hyperplane	O
is	O
obtained	O
from	O
a	O
subset	O
of	O
feature	O
-	O
dimension	O
candidates	O
with	O
the	O
randomly	B-Method
bagging	I-Method
strategy	I-Method
,	O
there	O
is	O
no	O
guarantee	O
of	O
obtaining	O
a	O
global	O
optimum	O
with	O
respect	O
to	O
all	O
the	O
hyperplanes	O
in	O
all	O
the	O
split	O
-	O
nodes	O
.	O
	
An	O
intuitive	O
thinking	O
,	O
which	O
was	O
inspired	O
by	O
the	O
data	O
distribution	O
in	O
Fig	O
.	O
	
1	O
(	O
b	O
)	O
,	O
is	O
to	O
achieve	O
a	O
global	O
optimum	O
by	O
jointly	O
considering	O
all	O
the	O
hyperplanes	O
of	O
all	O
the	O
split	O
-	O
nodes	O
,	O
in	O
the	O
form	O
as	O
follows	O
:	O
	
where	O
is	O
the	O
total	O
number	O
of	O
split	O
-	O
nodes	O
that	O
a	O
training	O
sample	O
has	O
routed	O
through	O
a	O
decision	B-Method
tree	I-Method
.	O
	
As	O
there	O
is	O
no	O
mathematical	O
solution	O
to	O
the	O
problem	O
described	O
in	O
Eqn	O
.	O
	
[	O
reference	O
]	O
,	O
an	O
alternative	O
way	O
(	O
i.e.	O
,	O
an	O
approximate	B-Method
method	I-Method
)	O
to	O
numerically	B-Task
solving	I-Task
Eqn	I-Task
.	O
	
(	O
9	O
)	O
is	O
to	O
jointly	O
maximize	O
the	O
purity	O
of	O
the	O
clustered	O
data	O
groups	O
at	O
each	O
of	O
the	O
split	O
-	O
nodes	O
.	O
	
This	O
also	O
means	O
that	O
all	O
the	O
data	O
is	O
clustered	O
into	O
the	O
corners	O
(	O
feature	O
-	O
space	O
vertices	O
)	O
of	O
the	O
feature	O
space	O
,	O
as	O
shown	O
in	O
Fig	O
.	O
2	O
.	O
	
section	O
:	O
II.2	O
The	O
Joint	B-Method
Maximum	I-Method
Purity	I-Method
Forest	I-Method
Scheme	O
	
To	O
calculate	O
the	O
threshold	O
for	O
each	O
split	O
-	O
node	O
in	O
each	O
decision	O
tree	O
when	O
training	O
a	O
random	B-Method
forest	I-Method
,	O
we	O
are	O
attempting	O
to	O
determine	O
an	O
orthogonal	O
hyperplane	O
for	O
a	O
three	O
-	O
category	B-Task
classification	I-Task
problem	I-Task
,	O
as	O
shown	O
in	O
Fig	O
.	O
1	O
.	O
	
Since	O
the	O
hyperplanes	O
for	O
the	O
split	O
-	O
nodes	O
of	O
a	O
decision	O
tree	O
are	O
required	O
to	O
be	O
orthogonal	O
to	O
each	O
other	O
,	O
seeking	O
an	O
optimal	O
orthogonal	O
hyperplane	O
locally	O
can	O
not	O
guarantee	O
obtaining	O
maximum	O
purity	O
for	O
the	O
whole	O
tree	O
globally	O
.	O
	
As	O
shown	O
in	O
Fig	O
.	O
2	O
,	O
it	O
is	O
easy	O
to	O
determine	O
the	O
vertical	O
hyperplane	O
for	O
maximum	O
purity	O
,	O
but	O
it	O
is	O
hard	O
to	O
obtain	O
the	O
horizontal	O
hyperplane	O
for	O
maximum	O
purity	O
in	O
the	O
original	O
feature	O
space	O
.	O
	
To	O
achieve	O
an	O
optimal	O
classification	B-Task
performance	O
for	O
the	O
whole	O
decision	O
tree	O
,	O
all	O
the	O
split	O
-	O
nodes	O
should	O
be	O
considered	O
globally	O
or	O
simultaneously	O
.	O
	
As	O
shown	O
in	O
Fig	O
.	O
2	O
,	O
a	O
number	O
of	O
split	O
-	O
nodes	O
,	O
which	O
have	O
their	O
hyperplanes	O
orthogonal	O
to	O
each	O
other	O
,	O
are	O
required	O
to	O
separate	O
the	O
samples	O
into	O
different	O
nodes	O
.	O
	
However	O
,	O
if	O
we	O
can	O
transform	O
the	O
samples	O
(	O
zerocentered	O
feature	O
data	O
)	O
to	O
locate	O
them	O
at	O
the	O
respective	O
corners	O
of	O
the	O
feature	O
space	O
,	O
i.e.	O
{	O
−1	O
,	O
1	O
}	O
for	O
mdimensional	O
features	O
,	O
the	O
feature	O
data	O
can	O
be	O
easily	O
and	O
accurately	O
separated	O
by	O
the	O
orthogonal	O
(	O
either	O
vertical	O
or	O
horizontal	O
)	O
hyperplanes	O
,	O
which	O
contain	O
the	O
space	O
center	O
{	O
0	O
}	O
,	O
as	O
illustrated	O
in	O
Fig	O
.	O
1	O
(	O
b	O
)	O
.	O
	
The	O
insight	O
behind	O
this	O
is	O
that	O
the	O
data	O
is	O
clustered	O
into	O
the	O
feature	O
-	O
space	O
vertices	O
(	O
the	O
corners	O
in	O
a	O
2	O
-	O
D	O
feature	O
space	O
means	O
that	O
the	O
data	O
points	O
belong	O
to	O
{	O
−1	O
,	O
1	O
}	O
as	O
the	O
coordinate	O
range	O
is	O
set	O
to	O
[	O
−1	O
,	O
1	O
]	O
)	O
.	O
	
To	O
tackle	O
the	O
original	O
feature	O
data	O
,	O
which	O
is	O
not	O
ideally	O
clustered	O
in	O
the	O
vertices	O
or	O
corners	O
of	O
the	O
feature	O
space	O
or	O
close	O
to	O
them	O
,	O
as	O
shown	O
in	O
Fig	O
.	O
1	O
(	O
a	O
)	O
,	O
an	O
intuitive	O
idea	O
is	O
to	O
rotate	O
the	O
feature	O
space	O
(	O
this	O
is	O
equivalent	O
to	O
rotating	O
the	O
hyperplanes	O
)	O
.	O
	
This	O
transformation	O
clusters	O
the	O
feature	O
data	O
compactly	O
into	O
feature	O
-	O
space	O
vertices	O
{	O
−1	O
,	O
1	O
}	O
with	O
a	O
total	O
of	O
2	O
vertices	O
.	O
	
Therefore	O
,	O
a	O
possible	O
solution	O
to	O
the	O
problem	O
described	O
in	O
Eqn	O
.	O
	
(	O
10	O
)	O
is	O
to	O
rotate	O
the	O
data	O
features	O
by	O
a	O
rotation	O
matrix	O
ℛ	O
×	O
,	O
as	O
shown	O
in	O
Fig	O
.	O
2	O
,	O
through	O
which	O
the	O
original	O
feature	O
space	O
is	O
transformed	O
into	O
a	O
more	O
compact	O
clustered	O
feature	O
space	O
,	O
where	O
all	O
the	O
feature	O
data	O
is	O
clustered	O
close	O
to	O
the	O
feature	O
-	O
space	O
vertices	O
.	O
	
This	O
solution	O
can	O
be	O
mathematically	O
defined	O
as	O
follows	O
:	O
	
where	O
∈	O
ℝ	O
×	O
contains	O
n	O
samples	O
,	O
each	O
of	O
which	O
is	O
a	O
-	O
dimensional	O
feature	O
vector	O
arranged	O
in	O
a	O
row	O
,	O
and	O
is	O
zero	O
-	O
centered	O
,	O
i.e.	O
all	O
the	O
feature	O
vectors	O
are	O
demeaned	O
by	O
subtracting	O
the	O
mean	O
vector	O
from	O
each	O
feature	O
vector	O
.	O
	
This	O
idea	O
of	O
clustering	B-Task
data	I-Task
into	O
the	O
feature	O
-	O
space	O
vertices	O
can	O
also	O
be	O
found	O
in	O
locality	B-Method
-	I-Method
sensitive	I-Method
hashing	I-Method
(	I-Method
LSH	I-Method
)	I-Method
[	O
reference	O
]	O
and	O
image	B-Method
representation	I-Method
[	O
reference	O
]	O
.	O
	
In	O
[	O
reference	O
]	O
,	O
a	O
simple	O
and	O
efficient	O
alternating	B-Method
minimization	I-Method
scheme	I-Method
was	O
proposed	O
to	O
find	O
a	O
rotation	O
matrix	O
for	O
zero	O
-	O
centered	O
feature	O
data	O
,	O
which	O
minimizes	O
the	O
quantization	B-Metric
errors	I-Metric
by	O
mapping	O
the	O
feature	O
data	O
to	O
the	O
vertices	O
of	O
a	O
zero	O
-	O
centered	O
binary	O
hypercube	O
.	O
	
The	O
method	O
is	O
termed	O
as	O
iterative	B-Method
quantization	I-Method
(	I-Method
ITQ	I-Method
)	I-Method
,	O
which	O
can	O
work	O
on	O
multi	B-Task
-	I-Task
class	I-Task
spectral	I-Task
clustering	I-Task
and	O
orthogonal	B-Task
Procrustes	I-Task
problem	I-Task
.	O
	
Yu	O
et	O
al	O
.	O
	
[	O
reference	O
]	O
proposed	O
using	O
a	O
circulant	B-Method
matrix	I-Method
to	O
speed	O
up	O
the	O
computation	B-Task
,	O
because	O
the	O
circulant	O
structure	O
enables	O
the	O
use	O
of	O
Fast	B-Method
Fourier	I-Method
Transformation	I-Method
(	O
FFT	B-Method
)	O
.	O
	
As	O
the	O
computation	O
of	O
the	O
rotation	O
matrix	O
in	O
the	O
training	B-Task
and	I-Task
testing	I-Task
stage	I-Task
is	O
ignorable	O
,	O
we	O
choose	O
a	O
similar	O
scheme	O
to	O
ITQ	B-Method
[	O
reference	O
]	O
to	O
determine	O
the	O
rotation	O
matrix	O
(	O
we	O
throw	O
away	O
the	O
final	O
quantization	O
matrix	O
described	O
in	O
Eqn	O
.	O
	
[	O
reference	O
]	O
,	O
which	O
is	O
used	O
for	O
hashing	B-Task
in	O
[	O
reference	O
]	O
)	O
,	O
through	O
which	O
the	O
original	O
feature	O
space	O
can	O
be	O
transformed	O
into	O
a	O
new	O
compact	O
clustered	O
feature	O
space	O
:	O
=	O
	
ℛ	O
,	O
where	O
the	O
data	O
is	O
located	O
at	O
the	O
respective	O
vertices	O
in	O
the	O
new	O
feature	O
space	O
.	O
	
After	O
this	O
transformation	O
,	O
a	O
random	B-Method
forest	I-Method
with	O
globally	O
joint	O
maximum	O
purity	O
of	O
all	O
the	O
clustered	O
data	O
can	O
be	O
trained	O
,	O
through	O
all	O
the	O
hyperplanes	O
in	O
the	O
split	O
-	O
nodes	O
of	O
each	O
decision	O
tree	O
.	O
	
Based	O
on	O
this	O
idea	O
,	O
our	O
proposed	O
scheme	O
is	O
called	O
joint	B-Method
maximum	I-Method
purity	I-Method
forest	I-Method
(	O
JMPF	B-Method
)	O
.	O
	
section	O
:	O
II.3	O
Learning	O
the	O
Rotation	O
Matrix	O
via	O
Clustering	O
Data	O
into	O
Feature	O
-	O
Space	O
Vertices	O
	
Assuming	O
that	O
∈	O
ℝ	O
is	O
one	O
point	O
in	O
the	O
-	O
dimensional	O
feature	O
space	O
(	O
zero	O
-	O
centered	O
data	O
)	O
,	O
the	O
respective	O
vertices	O
in	O
the	O
zero	O
-	O
centered	O
binary	O
hypercube	O
space	O
can	O
be	O
denoted	O
as	O
(	O
)	O
∈	O
{	O
−1	O
,	O
1	O
}	O
,	O
and	O
there	O
is	O
a	O
total	O
of	O
2	O
vertices	O
in	O
the	O
-	O
dimensional	O
feature	O
space	O
.	O
	
It	O
is	O
easy	O
to	O
see	O
from	O
We	O
denote	O
a	O
binary	O
code	O
matrix	O
∈	O
{	O
−1	O
,	O
1	O
}	O
×	O
,	O
	
whose	O
rows	O
=	O
(	O
)	O
∈	O
.	O
	
For	O
a	O
matrix	O
or	O
a	O
vector	O
,	O
(	O
.	O
)	O
applies	O
the	O
sign	O
operation	O
to	O
it	O
element	O
-	O
wise	O
.	O
	
Our	O
objective	O
is	O
to	O
minimize	O
the	O
error	O
between	O
the	O
feature	O
and	O
the	O
feature	O
-	O
space	O
vertices	O
,	O
i.e.	O
,	O
min‖	O
−	O
‖	O
.	O
	
As	O
we	O
can	O
see	O
in	O
Fig	O
.	O
2	O
,	O
when	O
the	O
feature	O
space	O
is	O
rotated	O
,	O
the	O
feature	O
points	O
will	O
be	O
more	O
concentrated	O
around	O
their	O
nearest	O
vertices	O
,	O
which	O
means	O
that	O
the	O
quantization	B-Metric
error	I-Metric
will	O
become	O
smaller	O
.	O
	
Therefore	O
,	O
the	O
minimization	B-Task
problem	I-Task
of	I-Task
min‖	I-Task
	
−	O
‖	O
is	O
equivalent	O
to	O
minimizing	O
the	O
error	B-Metric
of	O
the	O
zerocentered	O
data	O
with	O
respect	O
to	O
the	O
Frobenius	O
norm	O
,	O
as	O
in	O
the	O
following	O
formulation	O
:	O
	
Therefore	O
,	O
the	O
task	O
of	O
this	O
minimization	B-Task
problem	I-Task
is	O
to	O
determine	O
an	O
optimal	O
rotation	O
matrix	O
ℛ	O
to	O
satisfy	O
Eqn	O
.	O
	
[	O
reference	O
]	O
.	O
	
Since	O
there	O
are	O
two	O
variables	O
in	O
Eqn	O
.	O
	
(	O
11	O
)	O
,	O
the	O
expectation	B-Method
-	I-Method
maximization	I-Method
(	I-Method
E	I-Method
-	I-Method
M	I-Method
)	I-Method
algorithm	I-Method
is	O
applied	O
to	O
cluster	O
data	O
into	O
the	O
feature	O
-	O
space	O
vertices	O
,	O
such	O
that	O
a	O
local	O
minimum	O
of	O
the	O
binary	O
code	O
matrix	O
and	O
the	O
rotation	O
matrix	O
ℛ	O
are	O
computed	O
simultaneously	O
.	O
	
The	O
idea	O
of	O
rotating	O
feature	O
data	O
to	O
minimize	O
the	O
error	O
between	O
the	O
transformed	O
data	O
and	O
the	O
featurespace	O
vertices	O
can	O
also	O
be	O
found	O
in	O
[	O
reference	O
]	O
,	O
which	O
showed	O
that	O
the	O
rotation	O
matrix	O
ℛ	O
can	O
be	O
initialized	O
randomly	O
,	O
and	O
then	O
iterated	O
to	O
converge	O
to	O
the	O
required	O
rotation	O
matrix	O
.	O
	
Two	O
iteration	O
steps	O
will	O
be	O
performed	O
:	O
in	O
every	O
iteration	O
,	O
each	O
feature	O
vector	O
in	O
the	O
feature	O
space	O
is	O
firstly	O
quantized	O
to	O
the	O
nearest	O
vertex	O
of	O
the	O
binary	O
hypercube	O
,	O
i.e.	O
to	O
a	O
vertex	O
in	O
,	O
and	O
then	O
the	O
rotation	O
matrix	O
ℛ	O
is	O
updated	O
to	O
minimize	O
the	O
quantization	B-Metric
error	I-Metric
by	O
fixing	O
.	O
	
These	O
two	O
alternating	O
steps	O
are	O
described	O
in	O
detail	O
below	O
:	O
	
(	O
1	O
)	O
Fix	O
ℛ	O
and	O
update	O
:	O
	
Because	O
the	O
zero	O
-	O
centered	O
data	O
matrix	O
is	O
fixed	O
,	O
minimizing	O
Eqn	O
.	O
	
(	O
12	O
)	O
is	O
equivalent	O
to	O
maximizing	O
the	O
following	O
term	O
:	O
	
where	O
is	O
an	O
element	O
of	O
=	O
ℛ.	O
To	O
maximize	O
Eqn	O
.	O
	
(	O
13	O
)	O
with	O
respect	O
to	O
	
,	O
=	O
1	O
whenever	O
≥	O
0	O
and	O
=	O
	
−1	O
otherwise	O
,	O
i.e.	O
=	O
(	O
ℛ	O
)	O
∈	O
{	O
−1	O
,	O
1	O
}	O
.	O
	
(	O
2	O
)	O
Fix	O
and	O
update	O
ℛ	O
:	O
	
The	O
problem	O
of	O
fixing	O
to	O
obtain	O
a	O
rotation	O
matrix	O
based	O
on	O
the	O
objective	B-Metric
function	I-Metric
Eqn	I-Metric
.	O
	
(	O
11	O
)	O
is	O
relative	O
to	O
the	O
classic	O
orthogonal	B-Task
Procrustes	I-Task
problem	I-Task
[	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
,	O
in	O
which	O
a	O
rotation	O
matrix	O
is	O
determined	O
to	O
align	O
one	O
point	O
set	O
with	O
another	O
.	O
	
In	O
our	O
algorithm	O
,	O
these	O
two	O
point	O
sets	O
are	O
the	O
zero	O
-	O
centered	O
data	O
set	O
and	O
the	O
quantized	O
matrix	O
.	O
	
Therefore	O
,	O
a	O
closed	B-Method
-	I-Method
form	I-Method
solution	I-Method
for	O
ℛ	O
is	O
available	O
,	O
by	O
applying	O
SVD	B-Method
on	O
the	O
×	O
matrix	O
to	O
obtain	O
Ω	O
(	O
Ω	O
is	O
a	O
diagonal	O
matrix	O
)	O
,	O
then	O
set	O
ℛ	O
=	O
to	O
update	O
ℛ.	O
	
section	O
:	O
II.4	O
Proof	O
of	O
the	O
Orthogonal	B-Task
Procrustes	I-Task
Problem	I-Task
:	O
	
For	O
completeness	O
,	O
we	O
prove	O
the	O
orthogonal	B-Task
Procrustes	I-Task
problem	I-Task
,	O
for	O
which	O
the	O
solution	O
can	O
be	O
found	O
in	O
[	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
:	O
	
Proof	O
:	O
	
Thus	O
,	O
min	O
ℛ	O
‖	O
−	O
ℛ	O
‖	O
equals	O
to	O
maximizing	O
:	O
	
The	O
last	O
inequality	O
holds	O
because	O
Z	O
is	O
also	O
an	O
orthonormal	O
matrix	O
,	O
and	O
∑	O
,	O
=	O
1	O
,	O
,	O
≤	O
1	O
.	O
	
The	O
objective	O
function	O
can	O
be	O
maximized	O
if	O
Z	O
	
=	O
,	O
i.e.	O
	
section	O
:	O
ℛ	O
=	O
∎	O
	
section	O
:	O
III	O
.	O
JOINT	B-Method
MAXIMUM	I-Method
PURITY	I-Method
FOREST	I-Method
FOR	O
REGRESSION	B-Task
AND	I-Task
CLASSIFICATION	I-Task
	
section	O
:	O
III.1	O
The	O
Workflow	O
of	O
Joint	B-Method
Maximum	I-Method
Purity	I-Method
Forest	I-Method
	
Random	B-Method
forest	I-Method
is	O
a	O
machine	B-Method
-	I-Method
learning	I-Method
method	I-Method
using	O
an	O
ensemble	B-Method
of	I-Method
randomized	I-Method
decision	I-Method
trees	I-Method
for	O
classification	B-Task
.	O
	
Each	O
tree	O
in	O
a	O
random	B-Method
forest	I-Method
consists	O
of	O
split	O
-	O
nodes	O
and	O
leaf	O
-	O
nodes	O
,	O
which	O
can	O
be	O
trained	O
recursively	O
.	O
	
A	O
random	B-Method
forest	I-Method
is	O
constructed	O
recursively	O
,	O
where	O
each	O
node	O
attempts	O
to	O
find	O
a	O
splitting	O
function	O
or	O
a	O
hyperplane	O
to	O
separate	O
its	O
samples	O
into	O
two	O
leaf	O
-	O
nodes	O
,	O
such	O
that	O
the	O
information	B-Metric
gain	I-Metric
is	O
optimized	O
.	O
	
A	O
tree	B-Method
stops	O
growing	O
if	O
the	O
maximum	O
depth	O
is	O
reached	O
or	O
if	O
a	O
node	O
has	O
achieved	O
maximum	O
purity	O
,	O
i.e.	O
it	O
contains	O
only	O
samples	O
from	O
one	O
class	O
.	O
	
Then	O
,	O
each	O
leaf	O
-	O
node	O
collects	O
the	O
statistics	O
of	O
the	O
samples	O
falling	O
in	O
it	O
.	O
	
In	O
the	O
evaluation	B-Task
phase	I-Task
,	O
the	O
probability	O
of	O
a	O
query	O
sample	O
x	O
belonging	O
to	O
class	O
k	O
is	O
given	O
by	O
averaging	O
all	O
the	O
trees	O
,	O
or	O
by	O
other	O
methods	O
.	O
	
Most	O
random	B-Method
-	I-Method
forest	I-Method
-	I-Method
based	I-Method
models	I-Method
[	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
share	O
a	O
similar	O
workflow	O
,	O
as	O
shown	O
in	O
Fig	O
.	O
	
3	O
,	O
in	O
which	O
the	O
main	O
task	O
on	O
training	O
a	O
tree	O
in	O
a	O
random	B-Task
forest	I-Task
is	O
to	O
decide	O
thresholds	O
in	O
the	O
split	O
-	O
nodes	O
and	O
learn	O
the	O
regressors	O
or	O
classes	O
in	O
the	O
leaf	O
-	O
nodes	O
.	O
	
Rigid	B-Method
regression	I-Method
or	O
linear	B-Method
regression	I-Method
is	O
often	O
employed	O
in	O
the	O
leaf	O
-	O
nodes	O
for	O
the	O
prediction	B-Task
task	I-Task
,	O
because	O
rigid	B-Method
regression	I-Method
has	O
a	O
closed	B-Method
-	I-Method
form	I-Method
solution	I-Method
,	O
while	O
linear	B-Method
regression	I-Method
is	O
an	O
efficient	O
optimization	B-Method
tool	I-Method
,	O
and	O
the	O
LibLinear	B-Method
package	I-Method
[	O
reference	O
]	O
can	O
be	O
used	O
to	O
fine	O
-	O
tune	O
its	O
configurations	O
.	O
	
Compared	O
to	O
conventional	O
random	B-Method
forests	I-Method
,	O
our	O
JMPF	B-Method
scheme	O
has	O
one	O
more	O
step	O
,	O
as	O
shown	O
in	O
the	O
left	O
of	O
Fig	O
.	O
	
3	O
,	O
the	O
rotation	O
matrix	O
.	O
	
The	O
JMPF	B-Method
scheme	O
transforms	O
the	O
original	O
feature	O
space	O
by	O
rotating	O
it	O
into	O
a	O
more	O
compact	O
,	O
pre	O
-	O
clustered	O
feature	O
space	O
,	O
using	O
a	O
trained	O
rotation	O
matrix	O
learned	O
through	O
clustering	O
feature	O
vectors	O
iteratively	O
into	O
the	O
vertices	O
of	O
a	O
new	O
feature	O
space	O
.	O
	
The	O
whole	O
workflow	O
of	O
our	O
proposed	O
algorithm	O
,	O
the	O
JMPF	B-Method
scheme	O
,	O
is	O
outlined	O
in	O
Fig	O
.	O
3	O
.	O
	
The	O
source	O
code	O
of	O
our	O
algorithm	O
is	O
available	O
to	O
download	O
at	O
:	O
https:	O
//	O
github.com	O
/	O
HarleyHK	O
/	O
JMPF	B-Method
.	O
	
a	O
	
section	O
:	O
III.2	O
The	O
inherent	O
zero	O
-	O
center	O
hyperplanes	O
as	O
thresholds	O
for	O
split	O
-	O
nodes	O
	
In	O
training	O
a	O
random	B-Method
forest	I-Method
,	O
the	O
two	O
main	O
operations	O
for	O
training	O
(	O
splitting	B-Task
)	O
each	O
split	O
-	O
node	O
are	O
to	O
choose	O
splitting	O
feature	O
(	O
s	O
)	O
,	O
and	O
to	O
determine	O
the	O
threshold	O
,	O
using	O
a	O
random	B-Method
bagging	I-Method
strategy	I-Method
,	O
which	O
can	O
avoid	O
over	O
-	O
fitting	O
in	O
training	O
classifiers	B-Method
.	O
	
In	O
the	O
rotated	O
compact	O
pre	O
-	O
clustered	O
feature	O
space	O
,	O
the	O
inherent	O
zerocenter	O
hyperplanes	O
are	O
inherently	O
the	O
optimal	O
thresholds	O
(	O
to	O
meet	O
the	O
max	B-Metric
-	I-Metric
purity	I-Metric
criterion	I-Metric
on	O
two	O
clustered	O
data	O
groups	O
)	O
after	O
training	O
the	O
rotation	O
matrix	O
.	O
	
Therefore	O
,	O
these	O
inherent	O
zero	O
-	O
center	O
hyperplanes	O
can	O
directly	O
be	O
set	O
as	O
the	O
thresholds	O
to	O
achieve	O
optimal	O
classification	B-Task
performance	O
on	O
training	O
a	O
random	B-Method
forest	I-Method
.	O
	
Compared	O
to	O
conventional	O
random	B-Method
forests	I-Method
,	O
our	O
proposed	O
JMPF	B-Method
only	O
needs	O
to	O
choose	O
which	O
feature	O
(	O
s	O
)	O
to	O
split	O
data	O
at	O
split	O
-	O
nodes	O
.	O
	
This	O
can	O
speed	O
up	O
the	O
training	B-Method
process	I-Method
for	O
a	O
random	B-Method
forest	I-Method
.	O
	
Experimental	O
results	O
in	O
the	O
next	O
subsection	O
will	O
validate	O
this	O
performance	O
.	O
	
section	O
:	O
III.3	O
:	O
Experimental	O
results	O
on	O
JMPF	B-Method
regression	O
and	O
classification	B-Task
	
To	O
evaluate	O
the	O
performances	O
of	O
the	O
proposed	O
JMPF	B-Method
,	O
we	O
test	O
it	O
with	O
15	O
standard	O
machine	B-Task
-	I-Task
learning	I-Task
tasks	I-Task
,	O
7	O
for	O
classification	B-Task
and	O
8	O
for	O
regression	B-Task
.	O
	
The	O
datasets	O
used	O
in	O
the	O
experiments	O
are	O
summarized	O
in	O
Table	O
-	O
1	O
.	O
	
We	O
use	O
standard	O
performance	B-Metric
evaluation	I-Metric
metrics	I-Metric
:	O
error	B-Metric
rate	I-Metric
for	O
classification	B-Metric
and	O
root	B-Metric
mean	I-Metric
squared	I-Metric
error	I-Metric
(	I-Metric
RMSE	I-Metric
)	I-Metric
for	O
regression	B-Task
,	O
unless	O
otherwise	O
specified	O
.	O
	
We	O
firstly	O
evaluate	O
the	O
proposed	O
approach	O
on	O
two	O
real	O
applications	O
,	O
one	O
for	O
classification	B-Task
(	O
Table	O
-	O
2	O
)	O
and	O
one	O
for	O
regression	B-Task
(	O
Table	O
-	O
3	O
)	O
.	O
	
Our	O
proposed	O
JMPF	B-Method
is	O
compared	O
with	O
the	O
original	O
random	B-Method
forest	I-Method
before	I-Method
refinement	I-Method
(	O
denoted	O
as	O
RF	B-Method
)	O
,	O
and	O
two	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
variants	O
:	O
alternating	B-Method
decision	I-Method
forests	I-Method
(	O
ADF	B-Method
)	O
[	O
reference	O
]	O
and	O
alternating	B-Method
regression	I-Method
forests	I-Method
(	O
ARF	B-Method
)	O
[	O
reference	O
]	O
,	O
for	O
classification	B-Task
and	I-Task
regression	I-Task
,	O
respectively	O
.	O
	
Furthermore	O
,	O
we	O
compare	O
with	O
JMPF	B-Method
+	O
ADF	O
/	O
ARF	O
,	O
for	O
demonstrating	O
that	O
our	O
algorithm	O
can	O
be	O
combined	O
with	O
other	O
methods	O
.	O
	
We	O
follow	O
the	O
experiment	O
settings	O
in	O
[	O
reference	O
][	O
reference	O
]	O
.	O
	
We	O
set	O
the	O
maximum	O
tree	O
depth	O
D	O
at	O
15	O
,	O
and	O
the	O
minimum	O
sample	O
number	O
in	O
a	O
splitting	O
node	O
is	O
set	O
at	O
5	O
.	O
	
The	O
experiments	O
were	O
repeated	O
five	O
times	O
,	O
and	O
the	O
average	B-Metric
error	I-Metric
and	O
standard	O
deviation	O
were	O
measured	O
.	O
	
The	O
results	O
are	O
presented	O
in	O
Table	O
-	O
2	O
and	O
Table	O
-	O
3	O
,	O
for	O
the	O
classification	B-Task
and	I-Task
regression	I-Task
tasks	I-Task
,	O
respectively	O
.	O
	
In	O
terms	O
of	O
accuracy	B-Metric
,	O
our	O
proposed	O
JMPF	B-Method
significantly	O
outperforms	O
the	O
standard	O
random	B-Method
forest	I-Method
on	O
all	O
classification	B-Task
and	I-Task
regression	I-Task
tasks	I-Task
.	O
	
Compared	O
to	O
RF	B-Method
,	O
JMPF	B-Method
achieves	O
an	O
average	O
of	O
23.57	O
%	O
improvement	O
on	O
the	O
classification	B-Task
tasks	I-Task
,	O
and	O
an	O
average	O
of	O
23.13	O
%	O
improvement	O
on	O
the	O
regression	B-Task
tasks	I-Task
.	O
	
Our	O
method	O
also	O
consistently	O
outperforms	O
the	O
state	O
-	O
of	O
-	O
theart	O
variants	O
:	O
ADF	B-Method
/	I-Method
ARF	I-Method
.	O
	
Moreover	O
,	O
the	O
performance	O
of	O
our	O
JMPF	B-Method
algorithm	O
can	O
be	O
further	O
improved	O
by	O
integrating	O
with	O
ADF	B-Method
and	I-Method
ARF	I-Method
,	O
denoted	O
as	O
JMPF	B-Method
+	O
ADF	O
/	O
ARF	O
.	O
	
As	O
shown	O
in	O
Table	O
-	O
2	O
and	O
Table	O
-	O
	
[	O
reference	O
]	O
,	O
JMPF	B-Method
:	O
proposed	O
algorithm	O
,	O
JMPF	B-Method
+	O
ARF	O
:	O
our	O
proposed	O
algorithm	O
embedded	O
into	O
ARF	B-Method
.	O
	
is	O
the	O
error	O
scale	O
.	O
	
The	O
number	O
of	O
randomly	O
chosen	O
hyperplanes	O
	
#	O
ℋ	O
is	O
3	O
.	O
	
The	O
percentages	O
in	O
brackets	O
for	O
JMPF	B-Method
and	O
JMPF	B-Method
+	O
ARF	O
are	O
the	O
reduction	B-Metric
rates	I-Metric
in	I-Metric
RMSE	I-Metric
compared	O
with	O
the	O
RF	B-Method
algorithm	I-Method
.	O
	
section	O
:	O
III.4	O
:	O
Discussions	O
on	O
Experimental	O
Results	O
	
The	O
computational	B-Metric
complexity	I-Metric
of	O
JMPF	B-Method
is	O
similar	O
to	O
that	O
of	O
the	O
standard	O
random	B-Method
forest	I-Method
.	O
	
As	O
illustrated	O
in	O
the	O
workflow	O
of	O
JMPF	B-Method
in	O
Fig	O
.	O
	
3	O
,	O
	
only	O
one	O
additional	O
step	O
,	O
which	O
computes	O
the	O
rotation	O
matrix	O
,	O
is	O
required	O
,	O
when	O
compared	O
to	O
the	O
standard	O
random	B-Method
forest	I-Method
.	O
	
For	O
a	O
small	O
dataset	O
(	O
e.g.	O
,	O
feature	O
dimension	O
size	O
less	O
than	O
500	O
and	O
data	O
size	O
less	O
than	O
10	O
,	O
000	O
)	O
,	O
the	O
computation	O
required	O
to	O
compute	O
the	O
rotation	O
matrix	O
for	O
clustering	O
data	O
into	O
the	O
feature	O
-	O
space	O
vertices	O
is	O
acceptable	O
in	O
the	O
training	O
stage	O
(	O
about	O
10	O
seconds	O
per	O
level	O
,	O
using	O
MatLab	B-Method
)	O
and	O
negligible	O
in	O
the	O
testing	O
stage	O
.	O
	
When	O
the	O
dimension	B-Metric
size	I-Metric
becomes	O
larger	O
,	O
PCA	B-Method
dimensionality	I-Method
reduction	I-Method
can	O
be	O
employed	O
.	O
	
If	O
the	O
size	O
of	O
the	O
dataset	O
increases	O
,	O
such	O
that	O
using	O
PCA	B-Method
still	O
involves	O
heavy	O
computation	O
,	O
bagging	B-Method
can	O
be	O
used	O
to	O
achieve	O
comparable	O
accuracy	B-Metric
and	O
the	O
whole	O
extra	O
computation	O
will	O
be	O
insignificant	O
.	O
	
,	O
the	O
number	O
	
hyperplane	O
(	O
s	O
)	O
	
#	O
ℋ	O
on	O
training	O
the	O
random	B-Method
forest	I-Method
is	O
3	O
)	O
.	O
	
To	O
study	O
the	O
stability	O
of	O
JMPF	B-Method
,	O
we	O
choose	O
the	O
letterorig	O
dataset	O
for	O
classification	B-Task
and	O
the	O
kin8	O
nm	O
dataset	O
for	O
regression	B-Task
,	O
and	O
the	O
respective	O
results	O
are	O
shown	O
in	O
Fig	O
.	O
4	O
(	O
a	O
)	O
and	O
Fig	O
.	O
4	O
(	O
b	O
)	O
,	O
respectively	O
.	O
	
In	O
the	O
experiments	O
,	O
the	O
number	O
of	O
trees	O
,	O
i.e.	O
,	O
the	O
number	O
of	O
weak	B-Method
classifiers	I-Method
in	O
the	O
random	B-Method
forest	I-Method
,	O
varies	O
from	O
10	O
to	O
200	O
,	O
and	O
we	O
have	O
three	O
observations	O
.	O
	
Firstly	O
,	O
as	O
shown	O
in	O
Fig	O
.	O
4	O
,	O
when	O
the	O
number	O
of	O
trees	O
increases	O
,	O
the	O
performance	O
of	O
all	O
the	O
algorithms	O
improves	O
.	O
	
For	O
classification	B-Task
,	O
as	O
shown	O
in	O
Fig	O
.	O
4	O
(	O
a	O
)	O
,	O
when	O
the	O
number	O
of	O
trees	O
is	O
larger	O
than	O
100	O
,	O
the	O
errors	O
are	O
converged	O
to	O
become	O
steady	O
.	O
	
On	O
the	O
contrary	O
,	O
for	O
the	O
regression	B-Task
task	I-Task
as	O
shown	O
in	O
Fig	O
.	O
4	O
(	O
b	O
)	O
,	O
the	O
errors	O
are	O
almost	O
stable	O
,	O
ranged	O
from	O
10	O
to	O
200	O
.	O
	
Secondly	O
,	O
the	O
results	O
show	O
that	O
JMPF	B-Method
consistently	O
outperforms	O
ADF	B-Method
and	O
RF	B-Method
,	O
irrespective	O
of	O
the	O
number	O
of	O
trees	O
used	O
.	O
	
Finally	O
,	O
Fig	O
.	O
4	O
clearly	O
shows	O
that	O
JMPF	B-Method
can	O
integrate	O
with	O
ADF	B-Method
or	O
ARF	B-Method
to	O
further	O
improve	O
its	O
performance	O
.	O
	
section	O
:	O
IV	O
.	O
IMAGE	B-Task
SUPER	I-Task
-	I-Task
RESOLUTION	I-Task
BASED	O
ON	O
JOINT	B-Method
MAXIMUM	I-Method
PURITY	I-Method
FOREST	I-Method
	
section	O
:	O
IV.1	O
Overview	O
of	O
Image	B-Task
Super	I-Task
-	I-Task
resolution	I-Task
and	O
Related	O
Works	O
	
Image	B-Task
super	I-Task
-	I-Task
resolution	I-Task
(	O
SR	B-Task
)	O
,	O
which	O
recovers	O
a	O
high	B-Task
-	I-Task
resolution	I-Task
(	O
HR	B-Task
)	O
image	O
from	O
one	O
single	O
image	O
or	O
a	O
number	O
of	O
low	B-Task
-	I-Task
resolution	I-Task
(	O
LR	B-Task
)	O
images	O
,	O
has	O
been	O
a	O
hot	O
research	O
topic	O
in	O
the	O
field	O
of	O
image	B-Task
processing	I-Task
for	O
decades	O
.	O
	
SR	B-Task
is	O
a	O
well	O
-	O
known	O
ill	B-Task
-	I-Task
posed	I-Task
problem	I-Task
,	O
which	O
needs	O
artistic	O
skills	O
from	O
mathematics	O
and	O
machine	B-Task
learning	I-Task
.	O
	
Prior	O
methods	O
on	O
SR	B-Task
are	O
mainly	O
based	O
on	O
edge	B-Method
preserving	I-Method
,	O
such	O
as	O
New	B-Method
Edge	I-Method
-	I-Method
directed	I-Method
Interpolation	I-Method
(	O
NEDI	B-Method
)	O
[	O
reference	O
]	O
,	O
Soft	B-Method
-	I-Method
decision	I-Method
Adaptive	I-Method
Interpolation	I-Method
(	O
SAI	B-Method
)	O
[	O
reference	O
]	O
,	O
Directional	B-Method
Filtering	I-Method
and	O
Data	B-Method
-	I-Method
Fusion	I-Method
	
(	O
DFDF	O
)	O
	
[	O
reference	O
]	O
,	O
Modified	B-Method
Edge	I-Method
-	I-Method
Directed	I-Method
Interpolation	I-Method
(	O
MEDI	B-Method
)	O
[	O
reference	O
]	O
,	O
etc	O
.	O
	
The	O
neighbor	B-Method
-	I-Method
embedding	I-Method
(	O
NE	B-Method
)	O
methods	O
[	O
reference	O
][	O
reference	O
]	O
set	O
the	O
milestone	O
on	O
the	O
patch	B-Method
-	I-Method
learning	I-Method
-	I-Method
based	I-Method
superresolution	I-Method
approach	I-Method
.	O
	
In	O
this	O
approach	O
,	O
each	O
LR	B-Task
patch	O
is	O
approximated	O
as	O
a	O
linear	B-Method
regression	I-Method
of	O
its	O
nearest	O
LR	B-Task
neighbors	O
in	O
a	O
collected	O
dataset	O
,	O
while	O
its	O
HR	B-Task
counterpart	O
can	O
be	O
reconstructed	O
with	O
the	O
same	O
coefficients	O
of	O
corresponding	O
HR	B-Task
neighbors	O
,	O
based	O
on	O
the	O
non	O
-	O
linear	O
manifold	O
structure	O
.	O
	
Although	O
the	O
NE	B-Method
method	O
is	O
simple	O
and	O
practical	O
,	O
it	O
requires	O
a	O
huge	O
dataset	O
(	O
millions	O
of	O
patches	O
)	O
to	O
achieve	O
good	O
reconstruction	B-Metric
quality	I-Metric
and	O
it	O
is	O
computationally	O
intensive	O
,	O
because	O
k	B-Method
-	I-Method
NN	I-Method
is	O
used	O
in	O
searching	O
neighboring	O
patches	O
in	O
the	O
huge	O
dataset	O
.	O
	
Instead	O
of	O
using	O
the	O
patches	O
extracted	O
directly	O
from	O
natural	O
images	O
,	O
Yang	O
et	O
al	O
.	O
	
[	O
reference	O
]	O
employed	O
sparse	B-Method
coding	I-Method
[	O
reference	O
][	O
reference	O
]	O
to	O
represent	O
patch	O
images	O
,	O
of	O
large	O
size	O
,	O
efficiently	O
,	O
which	O
opens	O
the	O
era	O
for	O
sparse	B-Task
coding	I-Task
in	O
the	O
image	B-Task
inverse	I-Task
problems	I-Task
.	O
	
The	O
sparse	B-Method
-	I-Method
coding	I-Method
super	I-Method
-	I-Method
resolution	I-Method
(	O
ScSR	B-Method
)	O
approach	O
is	O
a	O
framework	O
that	O
the	O
HR	B-Task
counterpart	O
of	O
an	O
LR	B-Task
patch	O
can	O
be	O
reconstructed	O
aided	O
by	O
two	O
learned	B-Method
dictionaries	I-Method
,	O
with	O
the	O
sparse	O
constraint	O
on	O
the	O
coefficients	O
via	O
the	O
following	O
formulations	O
:	O
	
The	O
compact	O
LR	B-Task
and	O
HR	B-Task
dictionaries	O
can	O
be	O
jointly	O
learned	O
with	O
a	O
sparsity	O
constraint	O
,	O
using	O
the	O
following	O
sparse	B-Method
representation	I-Method
:	O
	
where	O
and	O
are	O
the	O
LR	B-Task
patch	O
and	O
the	O
corresponding	O
HR	B-Task
patch	O
,	O
respectively	O
;	O
and	O
D	O
and	O
D	O
are	O
the	O
LR	B-Task
and	O
HR	B-Task
dictionaries	O
learned	O
from	O
the	O
LR	B-Task
and	O
the	O
corresponding	O
HR	B-Task
patch	O
samples	O
,	O
respectively	O
.	O
	
The	O
value	O
of	O
in	O
‖	O
‖	O
is	O
the	O
sparsity	O
factor	O
of	O
the	O
coefficients	O
.	O
	
‖	O
‖	O
is	O
-	O
norm	O
,	O
which	O
means	O
the	O
non	O
-	O
zero	O
count	O
of	O
the	O
coefficients	O
in	O
.	O
	
For	O
each	O
LR	B-Task
patch	O
of	O
an	O
input	O
LR	B-Task
image	O
,	O
the	O
problem	O
of	O
finding	O
the	O
sparse	O
coefficients	O
can	O
be	O
formulated	O
as	O
follows	O
:	O
	
where	O
is	O
a	O
linear	B-Method
or	I-Method
non	I-Method
-	I-Method
linear	I-Method
feature	I-Method
-	I-Method
extraction	I-Method
operator	I-Method
on	O
the	O
LR	B-Task
patches	O
,	O
which	O
makes	O
the	O
LR	B-Task
patches	O
more	O
discriminative	O
from	O
each	O
other	O
.	O
	
Typically	O
,	O
can	O
be	O
chosen	O
as	O
a	O
high	B-Method
-	I-Method
pass	I-Method
filter	I-Method
,	O
and	O
a	O
simple	O
high	B-Method
-	I-Method
pass	I-Method
filter	I-Method
can	O
be	O
obtained	O
by	O
subtracting	O
the	O
input	O
from	O
the	O
output	O
of	O
a	O
low	B-Method
-	I-Method
pass	I-Method
filter	I-Method
,	O
as	O
in	O
an	O
early	O
work	O
[	O
reference	O
]	O
.	O
In	O
	
The	O
ideal	O
regularization	O
term	O
for	O
the	O
sparse	O
constraint	O
on	O
the	O
coefficients	O
α	O
is	O
the	O
-	O
norm	O
(	O
nonconvex	O
)	O
,	O
but	O
,	O
based	O
on	O
greedy	B-Method
matching	I-Method
,	O
it	O
leads	O
to	O
an	O
NP	B-Task
-	I-Task
hard	I-Task
problem	I-Task
.	O
	
Alternatively	O
,	O
Yang	O
et	O
al	O
.	O
	
[	O
reference	O
]	O
relaxed	O
it	O
to	O
-	O
norm	O
,	O
as	O
shown	O
in	O
the	O
following	O
formulation	O
:	O
	
The	O
Lagrange	O
multiplier	O
provides	O
an	O
equivalent	O
formulation	O
as	O
follows	O
:	O
	
where	O
the	O
parameter	O
balances	O
the	O
sparsity	O
of	O
the	O
solution	O
and	O
the	O
fidelity	O
of	O
the	O
approximation	O
to	O
.	O
	
However	O
,	O
the	O
effectiveness	O
of	O
sparsity	O
was	O
challenged	O
in	O
[	O
reference	O
][	O
reference	O
]	O
,	O
as	O
to	O
whether	O
real	O
sparsity	O
can	O
help	O
image	B-Task
classification	I-Task
and	O
restoration	B-Task
,	O
or	O
locality	O
property	O
can	O
achieve	O
the	O
same	O
effect	O
.	O
	
Timofte	O
et	O
al	O
.	O
	
[	O
reference	O
]	O
proposed	O
an	O
anchored	B-Method
neighborhood	I-Method
regression	I-Method
(	O
ANR	B-Method
)	O
framework	O
,	O
which	O
relaxes	O
the	O
sparse	B-Method
decomposition	I-Method
optimization	I-Method
(	O
-	O
norm	O
)	O
of	O
[	O
reference	O
][	O
reference	O
]	O
to	O
a	O
ridge	B-Method
regression	I-Method
(	O
-	B-Task
norm	I-Task
)	I-Task
problem	I-Task
.	O
	
An	O
important	O
step	O
in	O
the	O
ANR	B-Method
model	O
is	O
the	O
relaxation	O
of	O
the	O
-	O
norm	O
in	O
Eqn	O
.	O
	
(	O
23	O
)	O
to	O
the	O
-	B-Task
norm	I-Task
least	I-Task
-	I-Task
squares	I-Task
minimization	I-Task
constraint	I-Task
,	O
as	O
follows	O
:	O
	
where	O
D	O
and	O
D	O
are	O
the	O
LR	B-Task
and	O
HR	B-Task
patch	O
-	O
based	O
dictionaries	O
,	O
respectively	O
.	O
	
This	O
-	B-Task
norm	I-Task
constraint	I-Task
problem	I-Task
can	O
be	O
solved	O
with	O
a	O
closed	B-Method
-	I-Method
form	I-Method
solution	I-Method
from	O
the	O
ridge	B-Method
regression	I-Method
[	O
reference	O
]	O
theory	O
.	O
	
Based	O
on	O
the	O
Tikhonov	B-Method
regularization	I-Method
/	I-Method
ridge	I-Method
-	I-Method
regression	I-Method
theory	I-Method
,	O
the	O
closed	B-Method
-	I-Method
form	I-Method
solution	I-Method
of	O
the	O
coefficients	O
is	O
given	O
:	O
	
We	O
assume	O
that	O
the	O
HR	B-Task
patches	O
share	O
the	O
same	O
coefficient	O
α	O
from	O
their	O
counterpart	O
LR	B-Task
patches	O
,	O
i.e.	O
,	O
=	O
D	O
.	O
	
From	O
Eqn	O
.	O
	
(	O
25	O
)	O
,	O
we	O
have	O
:	O
	
Therefore	O
,	O
the	O
HR	B-Task
patches	O
can	O
be	O
reconstructed	O
by	O
:	O
=	O
y	O
,	O
where	O
can	O
be	O
considered	O
a	O
projection	O
matrix	O
,	O
which	O
can	O
be	O
calculated	O
offline	O
,	O
as	O
follows	O
:	O
	
Ridge	B-Method
regression	I-Method
allows	O
the	O
coefficients	O
to	O
be	O
calculated	O
by	O
multiplying	O
the	O
constant	O
projection	O
matrix	O
with	O
the	O
new	O
extracted	O
feature	O
,	O
as	O
described	O
in	O
Eqn	O
.	O
	
(	O
26	O
)	O
and	O
Eqn	O
.	O
	
[	O
reference	O
]	O
.	O
More	O
importantly	O
,	O
the	O
projection	O
matrix	O
can	O
be	O
pre	O
-	O
computed	O
,	O
and	O
this	O
offline	B-Method
learning	I-Method
enables	O
significant	O
speed	O
-	O
up	O
at	O
the	O
prediction	B-Task
stage	I-Task
.	O
	
Timofte	O
et	O
al	O
.	O
	
[	O
reference	O
]	O
further	O
extended	O
the	O
ANR	B-Method
approach	O
to	O
the	O
A	B-Method
+	I-Method
approach	I-Method
,	O
which	O
learns	O
regressors	O
from	O
all	O
the	O
training	O
samples	O
,	O
rather	O
than	O
from	O
a	O
small	O
quantity	O
of	O
neighbors	O
of	O
the	O
anchor	O
atoms	O
as	O
ANR	B-Method
does	O
.	O
	
Later	O
,	O
there	O
are	O
numerous	O
variants	O
and	O
extended	O
approaches	O
,	O
based	O
on	O
ANR	B-Method
and	O
A	O
+	O
[	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
.	O
	
By	O
investigating	O
the	O
ANR	B-Method
model	O
,	O
Li	O
et	O
al	O
.	O
	
[	O
reference	O
]	O
found	O
that	O
the	O
weights	O
of	O
the	O
supporting	O
atoms	O
can	O
be	O
of	O
different	O
values	O
to	O
represent	O
their	O
similarities	O
to	O
the	O
anchor	O
atom	O
.	O
	
Based	O
on	O
this	O
idea	O
,	O
the	O
normal	O
collaborative	B-Method
representation	I-Method
(	O
CR	B-Method
)	O
model	O
in	O
ANR	B-Method
is	O
generalized	O
to	O
a	O
weighted	B-Method
model	I-Method
,	O
named	O
as	O
weighted	O
collaborative	B-Method
representation	I-Method
(	O
WCR	B-Method
)	I-Method
model	I-Method
,	O
as	O
follows	O
:	O
	
where	O
is	O
a	O
diagonal	O
matrix	O
.	O
	
The	O
weights	O
on	O
the	O
diagonal	O
atoms	O
are	O
proportional	O
to	O
their	O
similarities	O
to	O
the	O
anchor	O
atom	O
.	O
	
Similarly	O
,	O
the	O
new	O
closed	B-Method
-	I-Method
form	I-Method
solution	I-Method
for	O
the	O
coefficients	O
can	O
be	O
calculated	O
offline	O
,	O
as	O
follows	O
:	O
	
and	O
the	O
new	O
projection	O
matrix	O
is	O
given	O
as	O
follows	O
:	O
	
The	O
WCR	B-Method
model	I-Method
can	O
further	O
improve	O
the	O
ANR	B-Method
or	O
A	O
+	O
model	O
in	O
terms	O
of	O
image	B-Metric
quality	I-Metric
,	O
but	O
it	O
is	O
still	O
a	O
time	O
-	O
consuming	O
problem	O
to	O
find	O
the	O
most	O
similar	O
anchor	O
atoms	O
in	O
a	O
dictionary	O
,	O
and	O
this	O
always	O
hinders	O
its	O
applications	O
where	O
fast	B-Metric
speed	I-Metric
is	O
greatly	O
required	O
.	O
	
Schulter	O
et	O
al	O
.	O
	
[	O
reference	O
]	O
adopted	O
the	O
random	B-Method
forest	I-Method
as	O
a	O
classifier	B-Method
,	O
and	O
the	O
regressors	O
are	O
learned	O
from	O
the	O
patches	O
in	O
the	O
leaf	O
-	O
nodes	O
.	O
	
With	O
the	O
same	O
number	O
of	O
regressors	O
,	O
these	O
random	B-Method
-	I-Method
forest	I-Method
-	I-Method
based	I-Method
methods	I-Method
[	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
can	O
perform	O
on	O
a	O
par	O
with	O
the	O
A	O
+	O
method	O
in	O
terms	O
of	O
accuracy	B-Metric
.	O
	
However	O
,	O
they	O
achieve	O
an	O
increase	O
in	O
speed	B-Metric
,	O
because	O
the	O
sublinear	O
search	O
property	O
of	O
random	B-Method
forest	I-Method
can	O
remarkably	O
reduce	O
the	O
regressors	B-Metric
'	I-Metric
search	I-Metric
complexity	I-Metric
.	O
	
Recently	O
,	O
deep	B-Method
learning	I-Method
has	O
become	O
a	O
hot	O
research	O
topic	O
,	O
which	O
has	O
been	O
successfully	O
applied	O
to	O
image	B-Task
super	I-Task
-	I-Task
resolution	I-Task
[	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
and	O
achieved	O
promising	O
performance	O
,	O
particularly	O
in	O
terms	O
of	O
image	B-Metric
quality	I-Metric
.	O
	
In	O
[	O
reference	O
][	O
reference	O
]	O
,	O
a	O
convolutional	B-Method
neural	I-Method
-	I-Method
network	I-Method
-	I-Method
based	I-Method
image	I-Method
super	I-Method
-	I-Method
resolution	I-Method
(	O
SRCNN	B-Method
)	O
was	O
proposed	O
,	O
in	O
which	O
an	O
end	O
-	O
to	O
-	O
end	B-Task
mapping	I-Task
between	O
LR	B-Task
and	O
HR	B-Task
images	I-Task
is	O
learned	O
through	O
a	O
deep	B-Method
convolutional	I-Method
neural	I-Method
network	I-Method
(	O
CNN	B-Method
)	O
.	O
	
The	O
recent	O
emerging	O
stream	O
[	O
reference	O
][	O
reference	O
]	O
on	O
single	O
-	O
image	O
SR	B-Task
is	O
to	O
formulate	O
the	O
problem	O
as	O
a	O
clusteringregression	B-Task
problem	I-Task
,	O
which	O
can	O
be	O
solved	O
with	O
machine	B-Method
-	I-Method
learning	I-Method
tools	I-Method
.	O
	
These	O
approaches	O
are	O
learningbased	B-Method
methods	I-Method
,	O
which	O
attempt	O
to	O
reconstruct	O
an	O
HR	B-Task
image	I-Task
from	O
patches	O
with	O
the	O
help	O
of	O
an	O
external	O
database	O
.	O
	
These	O
methods	O
first	O
decompose	O
an	O
image	O
into	O
patches	O
,	O
then	O
classify	O
them	O
into	O
clusters	O
.	O
	
Regressors	B-Method
are	O
then	O
trained	O
for	O
each	O
of	O
the	O
clusters	O
,	O
which	O
generate	O
mappings	O
from	O
an	O
input	O
LR	B-Task
patch	O
's	O
feature	O
to	O
its	O
corresponding	O
HR	B-Task
patch	O
(	O
see	O
Fig	O
.	O
5	O
)	O
.	O
	
In	O
the	O
testing	O
stage	O
,	O
an	O
LR	B-Task
query	I-Task
image	I-Task
follows	O
the	O
same	O
procedures	O
to	O
cut	O
into	O
patches	O
and	O
to	O
extract	O
features	O
,	O
which	O
are	O
then	O
assigned	O
to	O
their	O
corresponding	O
clusters	O
using	O
the	O
k	B-Method
-	I-Method
NN	I-Method
algorithm	I-Method
[	O
reference	O
][	O
reference	O
]	O
or	O
random	B-Method
forest	I-Method
[	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
.	O
	
The	O
respective	O
HR	B-Task
patches	O
are	O
constructed	O
through	O
regressors	B-Method
learned	O
for	O
the	O
clusters	O
(	O
see	O
Fig	O
.	O
6	O
)	O
.	O
	
This	O
kind	O
of	O
clustering	B-Method
-	I-Method
regression	I-Method
algorithms	I-Method
,	O
based	O
on	O
random	B-Method
forest	I-Method
[	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
,	O
has	O
achieved	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
performance	O
in	O
single	B-Task
image	I-Task
super	I-Task
-	I-Task
resolution	I-Task
,	O
both	O
in	O
terms	O
of	O
accuracy	B-Metric
and	O
efficiency	B-Metric
,	O
because	O
of	O
the	O
use	O
of	O
ensemble	B-Method
learning	I-Method
and	O
sublinear	B-Method
search	I-Method
.	O
	
As	O
JMPF	B-Method
achieves	O
promising	O
results	O
on	O
both	O
classification	B-Task
and	I-Task
regression	I-Task
tasks	I-Task
,	O
it	O
can	O
be	O
employed	O
for	O
image	B-Task
super	I-Task
-	I-Task
resolution	I-Task
for	O
better	O
performances	O
.	O
	
An	O
overview	O
of	O
the	O
training	O
and	O
testing	O
processes	O
of	O
the	O
proposed	O
JMPF	B-Method
-	O
based	O
image	O
SR	B-Task
method	O
is	O
illustrated	O
in	O
Fig	O
.	O
5	O
and	O
Fig	O
.	O
6	O
,	O
respectively	O
.	O
	
In	O
our	O
method	O
,	O
the	O
first	O
and	O
second	O
-	O
order	O
gradients	O
are	O
extracted	O
as	O
features	O
from	O
each	O
patch	O
,	O
followed	O
by	O
PCA	B-Method
for	O
dimensionality	B-Task
reduction	I-Task
.	O
	
These	O
features	O
are	O
then	O
rotated	O
into	O
a	O
more	O
compact	O
,	O
pre	O
-	O
clustered	O
feature	O
space	O
.	O
	
Finally	O
,	O
all	O
the	O
thresholds	O
are	O
directly	O
set	O
to	O
the	O
inherent	O
zero	O
-	O
center	O
hyperplanes	O
when	O
training	O
the	O
random	B-Method
forest	I-Method
,	O
and	O
similar	O
to	O
other	O
algorithms	O
,	O
the	O
regressors	O
at	O
the	O
leaf	O
-	O
nodes	O
are	O
computed	O
using	O
the	O
rigid	B-Method
regression	I-Method
algorithms	I-Method
.	O
	
This	O
approach	O
is	O
named	O
as	O
JMPF	B-Method
-	O
based	O
image	O
super	O
-	O
resolution	O
method	O
.	O
	
section	O
:	O
IV.3	O
The	O
Working	O
Processes	O
of	O
JMPF	B-Method
-	O
based	O
Image	O
Super	O
-	O
resolution	O
	
JMPF	B-Method
has	O
been	O
shown	O
to	O
achieve	O
a	O
better	O
performance	O
for	O
clustering	B-Task
and	O
classification	B-Task
than	O
other	O
random	B-Method
forest	I-Method
methods	I-Method
.	O
	
Since	O
image	B-Task
super	I-Task
-	I-Task
resolution	I-Task
can	O
be	O
considered	O
as	O
a	O
clustering	B-Task
/	I-Task
classification	I-Task
problem	I-Task
,	O
using	O
JMPF	B-Method
is	O
likely	O
to	O
result	O
in	O
better	O
performance	O
.	O
	
This	O
is	O
mainly	O
due	O
to	O
the	O
features	O
transformed	O
to	O
the	O
vertices	O
in	O
the	O
new	O
feature	O
space	O
,	O
so	O
the	O
features	O
become	O
more	O
discriminative	O
.	O
	
The	O
image	B-Task
super	I-Task
-	I-Task
resolution	I-Task
training	I-Task
and	O
testing	O
processes	O
of	O
our	O
proposed	O
JMPF	B-Method
-	O
based	O
method	O
are	O
described	O
in	O
Algorithm	O
1	O
and	O
Algorithm	O
2	O
,	O
respectively	O
.	O
	
section	O
:	O
IV.4	O
Experimental	O
Results	O
on	O
JMPF	B-Method
-	O
based	O
Image	B-Task
Super	I-Task
-	I-Task
Resolution	I-Task
	
In	O
this	O
section	O
,	O
we	O
evaluate	O
our	O
image	O
SR	B-Task
algorithm	O
on	O
some	O
standard	O
super	O
-	O
resolution	O
datasets	O
,	O
including	O
Set	O
5	O
,	O
Set14	O
,	O
and	O
B100	B-Material
[	O
reference	O
]	O
,	O
and	O
compare	O
it	O
with	O
a	O
number	O
of	O
classical	O
or	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
methods	O
.	O
	
These	O
include	O
bicubic	B-Method
interpolation	I-Method
,	O
sparse	O
representation	O
SR	B-Task
(	O
Zeyde	O
)	O
	
[	O
reference	O
]	O
,	O
anchored	B-Method
neighborhood	I-Method
regression	I-Method
(	O
ANR	B-Method
)	O
	
[	O
reference	O
]	O
,	O
A	O
+	O
[	O
reference	O
]	O
,	O
standard	O
random	B-Method
forest	I-Method
(	I-Method
RF	I-Method
)	I-Method
[	O
reference	O
]	O
,	O
and	O
alternating	B-Method
regression	I-Method
forests	I-Method
(	O
ARF	B-Method
)	O
	
[	O
reference	O
]	O
.	O
	
We	O
set	O
the	O
same	O
parameters	O
for	O
all	O
the	O
random	B-Method
-	I-Method
forest	I-Method
-	I-Method
based	I-Method
algorithms	I-Method
:	O
the	O
number	O
of	O
trees	O
in	O
the	O
random	B-Method
forest	I-Method
is	O
10	O
,	O
and	O
the	O
maximum	O
depth	O
of	O
each	O
tree	O
is	O
15	O
.	O
	
Experiment	O
results	O
are	O
tabulated	O
in	O
Tables	O
-	O
4	O
and	O
Tables	O
-	O
5	O
,	O
where	O
JMPF	B-Method
is	O
our	O
proposed	O
JMPF	B-Method
-	O
based	O
image	O
super	O
-	O
resolution	O
method	O
,	O
and	O
JMPF	B-Method
	O
is	O
a	O
trimmed	B-Method
version	I-Method
,	O
such	O
that	O
the	O
thresholds	O
for	O
the	O
splitnodes	O
are	O
not	O
the	O
inherent	O
zero	O
-	O
center	O
hyperplanes	O
,	O
but	O
set	O
by	O
the	O
standard	O
random	B-Method
-	I-Method
forest	I-Method
bagging	I-Method
strategy	I-Method
.	O
	
We	O
use	O
the	O
same	O
training	O
images	O
(	O
91	O
images	O
)	O
for	O
all	O
the	O
algorithms	O
as	O
previous	O
works	O
[	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
do	O
.	O
	
However	O
,	O
for	O
JMPF	B-Method
+	I-Method
,	O
100	O
more	O
images	O
from	O
the	O
General	B-Material
-	I-Material
100	I-Material
dataset	I-Material
[	O
reference	O
]	O
are	O
used	O
,	O
so	O
as	O
to	O
check	O
whether	O
or	O
not	O
more	O
training	O
samples	O
can	O
further	O
improve	O
our	O
proposed	O
algorithm	O
.	O
	
Table	O
-	O
5	O
	
:	O
Detailed	O
results	O
of	O
the	O
proposed	O
method	O
,	O
compared	O
with	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
methods	O
on	O
the	O
dataset	O
Set5	B-Material
,	O
in	O
terms	O
of	O
PSNR	B-Metric
(	O
dB	O
)	O
using	O
three	O
different	O
magnification	O
factors	O
(	O
×2	O
,	O
×3	O
,	O
×4	O
)	O
.	O
	
Table	O
-	O
4	O
tabulates	O
the	O
performances	O
,	O
in	O
terms	O
of	O
the	O
average	O
peak	B-Metric
signal	I-Metric
to	I-Metric
noise	I-Metric
ratio	I-Metric
(	O
PSNR	B-Metric
)	O
scores	O
,	O
of	O
our	O
proposed	O
algorithm	O
and	O
other	O
image	O
SR	B-Task
methods	O
,	O
on	O
the	O
3	O
datasets	O
with	O
different	O
magnification	O
factors	O
.	O
	
For	O
the	O
Set5	B-Material
and	O
Set14	B-Material
datasets	I-Material
,	O
with	O
different	O
magnification	O
factors	O
,	O
our	O
proposed	O
JMPF	B-Method
-	O
based	O
algorithm	O
can	O
achieve	O
a	O
comparable	O
performance	O
to	O
other	O
recent	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
methods	O
,	O
such	O
as	O
A	O
+	O
and	O
ARF	B-Method
.	O
	
As	O
those	O
random	B-Method
-	I-Method
forest	I-Method
-	I-Method
based	I-Method
algorithms	I-Method
may	O
not	O
be	O
stable	O
on	O
small	O
datasets	O
,	O
when	O
evaluation	O
works	O
on	O
extensive	O
datasets	O
,	O
such	O
as	O
B100	B-Material
,	O
our	O
proposed	O
algorithm	O
JMPF	B-Method
can	O
stably	O
outperform	O
A	O
+	O
and	O
ARF	B-Method
for	O
all	O
magnification	O
factors	O
(	O
×2	O
,	O
×3	O
,	O
×4	O
)	O
.	O
	
Moreover	O
,	O
the	O
objective	B-Metric
quality	I-Metric
metrics	I-Metric
on	O
PSNR	B-Metric
also	O
	
show	O
that	O
the	O
JMPF	B-Method
algorithm	O
can	O
achieve	O
a	O
better	O
performance	O
when	O
more	O
samples	O
are	O
used	O
for	O
training	O
,	O
as	O
shown	O
from	O
JMPF	B-Method
+	I-Method
in	O
Table	O
-	O
4	O
.	O
	
Table	O
-	O
5	O
provides	O
more	O
details	O
of	O
the	O
performances	O
in	O
datasets	O
Set5	B-Material
.	O
	
To	O
compare	O
the	O
visual	B-Metric
quality	I-Metric
of	O
our	O
proposed	O
JMPF	B-Method
-	O
based	O
SR	B-Task
algorithm	O
to	O
other	O
methods	O
,	O
Fig	O
.	O
7	O
,	O
shows	O
the	O
reconstructed	B-Task
HR	I-Task
images	I-Task
using	O
different	O
methods	O
.	O
	
Some	O
regions	O
in	O
the	O
reconstructed	O
images	O
are	O
also	O
enlarged	O
,	O
so	O
as	O
to	O
show	O
the	O
details	O
in	O
the	O
images	O
.	O
	
In	O
general	O
,	O
our	O
proposed	O
method	O
can	O
produce	O
better	O
quality	O
images	O
,	O
particularly	O
in	O
areas	O
with	O
rich	O
texture	O
,	O
which	O
verifies	O
the	O
feature	O
discrimination	O
of	O
the	O
proposed	O
JMPF	B-Method
scheme	O
.	O
	
section	O
:	O
V.	O
CONCLUSIONS	O
	
In	O
this	O
paper	O
,	O
we	O
have	O
proposed	O
a	O
novel	O
random	B-Method
-	I-Method
forest	I-Method
scheme	I-Method
,	O
namely	O
the	O
Joint	B-Method
Maximum	I-Method
Purity	I-Method
Forest	I-Method
(	O
JMPF	B-Method
)	O
scheme	O
,	O
which	O
rotates	O
the	O
feature	O
space	O
into	O
a	O
compact	O
,	O
clustered	O
feature	O
space	O
,	O
by	O
jointly	O
maximizing	O
the	O
purity	O
of	O
all	O
the	O
feature	O
-	O
space	O
vertices	O
.	O
	
In	O
the	O
new	O
pre	O
-	O
clustered	O
feature	O
space	O
,	O
orthogonal	O
hyperplanes	O
can	O
be	O
effectively	O
used	O
in	O
the	O
split	O
-	O
nodes	O
of	O
a	O
decision	O
tree	O
,	O
which	O
can	O
improve	O
the	O
performance	O
of	O
the	O
trained	O
random	B-Method
forest	I-Method
.	O
	
Compared	O
to	O
the	O
standard	O
random	B-Method
forests	I-Method
and	O
the	O
recent	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
variants	O
,	O
such	O
as	O
alternating	B-Method
decision	I-Method
forests	I-Method
(	O
ADF	B-Method
)	O
[	O
reference	O
]	O
and	O
alternating	B-Method
regression	I-Method
forests	I-Method
(	O
ARF	B-Method
)	O
[	O
reference	O
]	O
,	O
our	O
proposed	O
random	B-Method
-	I-Method
forest	I-Method
method	I-Method
inherits	O
the	O
merits	O
of	O
random	B-Method
forests	I-Method
(	O
fast	O
training	O
and	O
testing	B-Task
,	O
multi	B-Metric
-	I-Metric
class	I-Metric
capability	I-Metric
,	O
etc	O
.	O
)	O
,	O
and	O
also	O
yields	O
promising	O
results	O
on	O
both	O
classification	B-Task
and	I-Task
regression	I-Task
tasks	I-Task
.	O
	
Experiments	O
have	O
shown	O
that	O
our	O
method	O
achieves	O
an	O
average	O
improvement	O
of	O
about	O
20	O
%	O
for	O
classification	B-Task
and	I-Task
regression	I-Task
on	O
publicly	O
benchmarked	O
datasets	O
.	O
	
Furthermore	O
,	O
our	O
proposed	O
scheme	O
can	O
integrate	O
with	O
other	O
methods	O
,	O
such	O
as	O
ADF	B-Method
and	O
ARF	B-Method
,	O
to	O
further	O
improve	O
the	O
performance	O
.	O
	
We	O
have	O
also	O
applied	O
JMPF	B-Method
to	O
single	B-Task
-	I-Task
image	I-Task
super	I-Task
-	I-Task
resolution	I-Task
.	O
	
We	O
tackle	O
image	B-Task
super	I-Task
-	I-Task
resolution	I-Task
as	O
a	O
clustering	B-Task
-	I-Task
regression	I-Task
problem	I-Task
,	O
and	O
focus	O
on	O
the	O
clustering	B-Task
stage	I-Task
,	O
which	O
happens	O
at	O
the	O
split	O
-	O
nodes	O
of	O
each	O
decision	O
tree	O
.	O
	
By	O
employing	O
the	O
JMPF	B-Method
strategy	O
,	O
we	O
rotate	O
the	O
feature	O
space	O
into	O
a	O
pre	O
-	O
clustered	O
feature	O
space	O
,	O
which	O
can	O
cluster	O
samples	O
into	O
different	O
sub	O
-	O
spaces	O
more	O
compactly	O
in	O
an	O
unsupervised	B-Task
problem	I-Task
.	O
	
The	O
compact	O
pre	O
-	O
clustered	O
feature	O
space	O
can	O
provide	O
the	O
optimal	O
thresholds	O
for	O
split	O
-	O
nodes	O
in	O
decision	O
trees	O
,	O
which	O
are	O
the	O
zero	O
-	O
centered	O
orthogonal	O
hyperplanes	O
.	O
	
Our	O
experiment	O
results	O
on	O
intensive	O
image	O
benchmark	O
datasets	O
,	O
such	O
as	O
B100	B-Material
,	O
show	O
that	O
the	O
proposed	O
JMPF	B-Method
-	O
based	O
image	O
super	O
-	O
resolution	O
approach	O
can	O
consistently	O
outperform	O
recent	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
algorithms	O
,	O
in	O
terms	O
of	O
PSNR	B-Metric
and	O
visual	B-Metric
quality	I-Metric
.	O
	
Our	O
method	O
also	O
inherits	O
the	O
advantages	O
of	O
random	B-Method
forests	I-Method
,	O
which	O
have	O
fast	O
speed	O
on	O
both	O
the	O
training	B-Task
and	I-Task
inference	I-Task
processes	I-Task
.	O
	
section	O
:	O
	
document	O
:	O
Cell	O
-	O
aware	O
Stacked	O
LSTMs	B-Method
for	O
Modeling	B-Task
Sentences	I-Task
	
We	O
propose	O
a	O
method	O
of	O
stacking	O
multiple	B-Method
long	I-Method
short	I-Method
-	I-Method
term	I-Method
memory	I-Method
(	O
LSTM	B-Method
)	O
layers	O
for	O
modeling	B-Task
sentences	I-Task
.	O
	
In	O
contrast	O
to	O
the	O
conventional	O
stacked	O
LSTMs	B-Method
where	O
only	O
hidden	O
states	O
are	O
fed	O
as	O
input	O
to	O
the	O
next	O
layer	O
,	O
our	O
architecture	O
accepts	O
both	O
hidden	O
and	O
memory	O
cell	O
states	O
of	O
the	O
preceding	O
layer	O
and	O
fuses	O
information	O
from	O
the	O
left	O
and	O
the	O
lower	O
context	O
using	O
the	O
soft	B-Method
gating	I-Method
mechanism	I-Method
of	O
LSTMs	B-Method
.	O
	
Thus	O
the	O
proposed	O
stacked	O
LSTM	B-Method
architecture	O
modulates	O
the	O
amount	O
of	O
information	O
to	O
be	O
delivered	O
not	O
only	O
in	O
horizontal	O
recurrence	O
but	O
also	O
in	O
vertical	O
connections	O
,	O
from	O
which	O
useful	O
features	O
extracted	O
from	O
lower	O
layers	O
are	O
effectively	O
conveyed	O
to	O
upper	O
layers	O
.	O
	
We	O
dub	O
this	O
architecture	O
Cell	B-Method
-	I-Method
aware	I-Method
Stacked	I-Method
LSTM	I-Method
(	O
CAS	B-Method
-	I-Method
LSTM	I-Method
)	O
and	O
show	O
from	O
experiments	O
that	O
our	O
models	O
achieve	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
results	O
on	O
benchmark	O
datasets	O
for	O
natural	B-Task
language	I-Task
inference	I-Task
,	O
paraphrase	B-Task
detection	I-Task
,	O
and	O
sentiment	B-Task
classification	I-Task
.	O
	
section	O
:	O
Introduction	O
	
In	O
the	O
field	O
of	O
natural	B-Task
language	I-Task
processing	I-Task
(	O
NLP	B-Task
)	O
,	O
the	O
most	O
prevalent	O
neural	B-Method
approach	I-Method
to	O
obtaining	O
sentence	B-Task
representations	I-Task
is	O
to	O
use	O
recurrent	B-Method
neural	I-Method
networks	I-Method
(	O
RNNs	B-Method
)	O
,	O
where	O
words	O
in	O
a	O
sentence	O
are	O
processed	O
in	O
a	O
sequential	O
and	O
recurrent	O
manner	O
.	O
	
Along	O
with	O
their	O
intuitive	O
design	O
,	O
RNNs	B-Method
have	O
shown	O
outstanding	O
performance	O
across	O
various	O
NLP	B-Task
tasks	O
e.g.	O
language	B-Task
modeling	I-Task
,	O
machine	B-Task
translation	I-Task
,	O
text	B-Task
classification	I-Task
,	O
and	O
parsing	B-Task
.	O
	
Among	O
several	O
variants	O
of	O
the	O
original	O
RNN	B-Method
,	O
gated	B-Method
recurrent	I-Method
architectures	I-Method
such	O
as	O
long	B-Method
short	I-Method
-	I-Method
term	I-Method
memory	I-Method
(	O
LSTM	B-Method
)	O
and	O
gated	B-Method
recurrent	I-Method
unit	I-Method
(	O
GRU	B-Method
)	O
have	O
been	O
accepted	O
as	O
de	O
-	O
facto	O
standard	O
choices	O
for	O
RNNs	B-Method
due	O
to	O
their	O
capability	O
of	O
addressing	O
the	O
vanishing	B-Task
and	I-Task
exploding	I-Task
gradient	I-Task
problem	I-Task
and	O
considering	O
long	O
-	O
term	O
dependencies	O
.	O
	
Gated	B-Method
RNNs	I-Method
achieve	O
these	O
properties	O
by	O
introducing	O
additional	O
gating	B-Method
units	I-Method
that	O
learn	O
to	O
control	O
the	O
amount	O
of	O
information	O
to	O
be	O
transferred	O
or	O
forgotten	O
,	O
and	O
are	O
proven	O
to	O
work	O
well	O
without	O
relying	O
on	O
complex	O
optimization	B-Method
algorithms	I-Method
or	O
careful	O
initialization	O
.	O
	
Meanwhile	O
,	O
the	O
common	O
practice	O
for	O
further	O
enhancing	O
the	O
expressiveness	B-Metric
of	O
RNNs	B-Task
is	O
to	O
stack	O
multiple	O
RNN	B-Method
layers	I-Method
,	O
each	O
of	O
which	O
has	O
distinct	O
parameter	O
sets	O
(	O
stacked	B-Method
RNN	I-Method
)	O
.	O
	
In	O
stacked	B-Method
RNNs	I-Method
,	O
the	O
hidden	O
states	O
of	O
a	O
layer	O
are	O
fed	O
as	O
input	O
to	O
the	O
subsequent	O
layer	O
,	O
and	O
they	O
are	O
shown	O
to	O
work	O
well	O
due	O
to	O
increased	O
depth	O
or	O
their	O
ability	O
to	O
capture	O
hierarchical	O
time	O
series	O
which	O
are	O
inherent	O
to	O
the	O
nature	O
of	O
the	O
problem	O
being	O
modeled	O
.	O
	
0.25	O
0.25	O
	
However	O
this	O
setting	O
of	O
stacking	B-Task
RNNs	I-Task
might	O
hinder	O
the	O
possibility	O
of	O
more	O
sophisticated	O
recurrence	B-Method
-	I-Method
based	I-Method
structures	I-Method
since	O
the	O
information	O
from	O
lower	O
layers	O
is	O
simply	O
treated	O
as	O
input	O
to	O
the	O
next	O
layer	O
,	O
rather	O
than	O
as	O
another	O
class	O
of	O
state	O
that	O
participates	O
in	O
core	B-Method
RNN	I-Method
computations	I-Method
.	O
	
Especially	O
for	O
gated	B-Method
RNNs	I-Method
such	O
as	O
LSTMs	B-Method
and	O
GRUs	B-Method
,	O
this	O
means	O
that	O
layer	O
-	O
to	O
-	O
layer	O
connections	O
can	O
not	O
fully	O
benefit	O
from	O
the	O
carefully	O
constructed	O
gating	B-Method
mechanism	I-Method
used	O
in	O
temporal	O
transitions	O
.	O
	
Some	O
recent	O
work	O
on	O
stacking	B-Task
RNNs	I-Task
suggests	O
alternative	O
methods	O
that	O
encourage	O
direct	O
and	O
effective	O
interaction	O
between	O
RNN	O
layers	O
by	O
adding	O
residual	O
connections	O
,	O
by	O
shortcut	O
connections	O
,	O
or	O
by	O
using	O
cell	O
states	O
of	O
LSTMs	B-Method
.	O
	
In	O
this	O
paper	O
,	O
we	O
propose	O
a	O
method	O
of	O
constructing	O
multi	B-Method
-	I-Method
layer	I-Method
LSTMs	I-Method
where	O
cell	O
states	O
are	O
used	O
in	O
controlling	O
the	O
vertical	B-Task
information	I-Task
flow	I-Task
.	O
	
This	O
system	O
utilizes	O
states	O
from	O
the	O
left	O
and	O
the	O
lower	O
context	O
equally	O
in	O
computation	O
of	O
the	O
new	O
state	O
,	O
thus	O
the	O
information	O
from	O
lower	O
layers	O
is	O
elaborately	O
filtered	O
and	O
reflected	O
through	O
a	O
soft	B-Method
gating	I-Method
mechanism	I-Method
.	O
	
Our	O
method	O
is	O
easy	O
-	O
to	O
-	O
implement	O
,	O
effective	O
,	O
and	O
can	O
replace	O
conventional	O
stacked	O
LSTMs	B-Method
without	O
much	O
modification	O
of	O
the	O
overall	O
architecture	O
.	O
	
We	O
call	O
the	O
proposed	O
architecture	B-Method
Cell	I-Method
-	I-Method
aware	I-Method
Stacked	I-Method
LSTM	I-Method
,	O
or	O
CAS	B-Method
-	I-Method
LSTM	I-Method
,	O
and	O
evaluate	O
our	O
method	O
on	O
multiple	O
benchmark	O
datasets	O
:	O
SNLI	B-Material
,	O
MultiNLI	B-Material
,	O
Quora	B-Material
Question	I-Material
Pairs	I-Material
,	O
and	O
SST	B-Material
.	O
	
From	O
experiments	O
we	O
show	O
that	O
the	O
CAS	B-Method
-	I-Method
LSTMs	I-Method
consistently	O
outperform	O
typical	O
stacked	O
LSTMs	B-Method
,	O
opening	O
the	O
possibility	O
of	O
performance	O
improvement	O
of	O
architectures	O
that	O
use	O
stacked	O
LSTMs	B-Method
.	O
	
Our	O
contribution	O
is	O
summarized	O
as	O
follows	O
.	O
	
We	O
bring	O
the	O
idea	O
of	O
utilizing	O
states	O
coming	O
from	O
multiple	O
directions	O
to	O
construction	O
of	O
stacked	O
LSTM	B-Method
and	O
apply	O
the	O
idea	O
to	O
the	O
research	O
of	O
sentence	B-Task
representation	I-Task
learning	I-Task
.	O
	
There	O
is	O
some	O
prior	O
work	O
addressing	O
the	O
idea	O
of	O
incorporating	O
more	O
than	O
one	O
type	O
of	O
state	O
,	O
however	O
to	O
the	O
best	O
of	O
our	O
knowledge	O
there	O
is	O
little	O
work	O
on	O
applying	O
the	O
idea	O
to	O
sentence	B-Task
encoding	I-Task
and	O
text	B-Task
classification	I-Task
.	O
	
We	O
conduct	O
extensive	O
evaluation	O
of	O
the	O
proposed	O
method	O
and	O
empirically	O
prove	O
its	O
effectiveness	O
on	O
encoding	B-Task
sentences	I-Task
.	O
	
Our	O
models	O
achieve	O
new	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
results	O
on	O
SNLI	B-Material
and	O
Quora	B-Material
Question	I-Material
Pairs	I-Material
datasets	I-Material
,	O
and	O
are	O
on	O
par	O
with	O
the	O
best	O
performing	O
models	O
on	O
MultiNLI	B-Material
and	O
SST	B-Material
datasets	I-Material
.	O
	
This	O
paper	O
is	O
organized	O
as	O
follows	O
.	O
	
We	O
give	O
a	O
detailed	O
description	O
about	O
the	O
proposed	O
method	O
in	O
§	O
[	O
reference	O
]	O
.	O
	
Experimental	O
results	O
are	O
given	O
in	O
§	O
[	O
reference	O
]	O
.	O
	
We	O
study	O
prior	O
work	O
related	O
to	O
our	O
objective	O
in	O
§	O
	
[	O
reference	O
]	O
and	O
conclude	O
in	O
§	O
[	O
reference	O
]	O
.	O
	
section	O
:	O
Model	O
Description	O
	
In	O
this	O
section	O
,	O
we	O
give	O
a	O
detailed	O
formulation	O
of	O
the	O
architectures	O
used	O
in	O
experiments	O
.	O
	
subsection	O
:	O
Notation	O
	
Throughout	O
this	O
paper	O
,	O
we	O
denote	O
matrices	O
as	O
boldface	O
capital	O
letters	O
(	O
)	O
,	O
vectors	O
as	O
boldface	O
lowercase	O
letters	O
(	O
)	O
,	O
and	O
scalars	O
as	O
normal	O
italic	O
letters	O
(	O
)	O
.	O
	
For	O
LSTM	B-Method
states	O
,	O
we	O
denote	O
a	O
hidden	O
state	O
as	O
and	O
a	O
cell	O
state	O
as	O
.	O
	
Also	O
,	O
a	O
layer	O
index	O
of	O
or	O
is	O
denoted	O
by	O
superscript	O
and	O
a	O
time	O
index	O
is	O
denoted	O
by	O
a	O
subscript	O
,	O
i.e.	O
indicates	O
the	O
hidden	O
state	O
at	O
time	O
and	O
layer	O
.	O
	
means	O
the	O
element	O
-	O
wise	O
multiplication	O
between	O
two	O
vectors	O
.	O
	
We	O
write	O
-	O
th	O
component	O
of	O
vector	O
as	O
.	O
	
All	O
vectors	O
are	O
assumed	O
to	O
be	O
column	O
vectors	O
.	O
	
subsection	O
:	O
Stacked	O
LSTMs	B-Method
	
While	O
there	O
exist	O
various	O
versions	O
of	O
LSTM	B-Method
formulation	O
,	O
in	O
this	O
work	O
we	O
use	O
the	O
following	O
,	O
one	O
of	O
the	O
most	O
common	O
versions	O
:	O
where	O
,	O
,	O
and	O
,	O
,	O
are	O
trainable	O
parameters	O
.	O
	
and	O
are	O
the	O
sigmoid	O
activation	O
and	O
the	O
hyperbolic	O
tangent	O
activation	O
function	O
respectively	O
.	O
	
Also	O
we	O
assume	O
that	O
where	O
is	O
the	O
-	O
th	O
input	O
to	O
the	O
network	O
.	O
	
The	O
input	O
gate	O
and	O
the	O
forget	O
gate	O
control	O
the	O
amount	O
of	O
information	O
transmitted	O
from	O
and	O
,	O
the	O
candidate	O
cell	O
state	O
and	O
the	O
previous	O
cell	O
state	O
,	O
to	O
the	O
new	O
cell	O
state	O
.	O
	
Similarly	O
the	O
output	O
gate	O
soft	O
-	O
selects	O
which	O
portion	O
of	O
the	O
cell	O
state	O
is	O
to	O
be	O
used	O
in	O
the	O
final	O
hidden	O
state	O
.	O
	
We	O
can	O
clearly	O
see	O
that	O
cell	O
states	O
(	O
,	O
,	O
)	O
play	O
a	O
crucial	O
role	O
in	O
forming	O
horizontal	O
recurrence	O
.	O
	
However	O
the	O
current	O
formulation	O
does	O
not	O
consider	O
,	O
the	O
cell	O
state	O
from	O
-	O
th	O
layer	O
,	O
in	O
computation	B-Task
and	O
thus	O
the	O
lower	O
context	O
is	O
reflected	O
only	O
through	O
the	O
rudimentary	O
way	O
,	O
hindering	O
the	O
possibility	O
of	O
controlling	O
vertical	B-Task
information	I-Task
flow	I-Task
.	O
	
subsection	O
:	O
Cell	O
-	O
aware	O
Stacked	O
LSTMs	B-Method
	
Now	O
we	O
extend	O
the	O
stacked	O
LSTM	B-Method
formulation	O
defined	O
above	O
to	O
address	O
the	O
problem	O
noted	O
in	O
the	O
previous	O
subsection	O
.	O
	
To	O
enhance	O
the	O
interaction	O
between	O
layers	O
in	O
a	O
way	O
similar	O
to	O
how	O
LSTMs	B-Method
keep	O
and	O
forget	O
the	O
information	O
from	O
the	O
previous	O
time	O
step	O
,	O
we	O
introduce	O
the	O
additional	O
forget	O
gate	O
that	O
determines	O
whether	O
to	O
accept	O
or	O
ignore	O
the	O
signals	O
coming	O
from	O
the	O
previous	O
layer	O
.	O
	
Therefore	O
the	O
proposed	O
Cell	B-Method
-	I-Method
aware	I-Method
Stacked	I-Method
LSTM	I-Method
is	O
formulated	O
as	O
follows	O
:	O
where	O
and	O
.	O
	
can	O
either	O
be	O
a	O
vector	O
of	O
constants	O
or	O
parameters	O
.	O
	
When	O
,	O
the	O
equations	O
defined	O
in	O
the	O
previous	O
subsection	O
are	O
used	O
.	O
	
Therefore	O
,	O
it	O
can	O
be	O
said	O
that	O
each	O
non	B-Method
-	I-Method
bottom	I-Method
layer	I-Method
of	I-Method
CAS	I-Method
-	I-Method
LSTM	I-Method
accepts	O
two	O
sets	O
of	O
hidden	O
and	O
cell	O
states	O
	
—	O
one	O
from	O
the	O
left	O
context	O
and	O
the	O
other	O
from	O
the	O
below	O
context	O
.	O
	
The	O
left	O
and	O
the	O
below	O
context	O
participate	O
in	O
computation	B-Task
with	O
the	O
equivalent	O
procedure	O
so	O
that	O
the	O
information	O
from	O
lower	O
layers	O
can	O
be	O
efficiently	O
propagated	O
.	O
	
Fig	O
.	O
	
[	O
reference	O
]	O
compares	O
CAS	B-Method
-	I-Method
LSTM	I-Method
to	O
the	O
conventional	O
stacked	O
LSTM	B-Method
architecture	O
,	O
and	O
Fig	O
.	O
	
[	O
reference	O
]	O
depicts	O
the	O
computation	O
flow	O
of	O
the	O
CAS	B-Method
-	I-Method
LSTM	I-Method
.	O
	
We	O
argue	O
that	O
considering	O
in	B-Task
computation	I-Task
is	O
beneficial	O
for	O
the	O
following	O
reasons	O
.	O
	
First	O
,	O
contains	O
additional	O
information	O
compared	O
to	O
since	O
it	O
is	O
not	O
filtered	O
by	O
.	O
	
Thus	O
a	O
model	O
that	O
directly	O
uses	O
does	O
not	O
rely	O
solely	O
on	O
for	O
extracting	B-Task
information	I-Task
,	O
due	O
to	O
the	O
fact	O
that	O
it	O
has	O
access	O
to	O
the	O
raw	O
information	O
,	O
as	O
in	O
temporal	O
connections	O
.	O
	
In	O
other	O
words	O
,	O
no	O
longer	O
has	O
to	O
take	O
all	O
responsibility	O
for	O
selecting	O
useful	O
features	O
for	O
both	O
horizontal	O
and	O
vertical	O
transitions	O
,	O
and	O
the	O
burden	O
of	O
selecting	O
information	O
is	O
shared	O
with	O
.	O
	
Another	O
advantage	O
of	O
using	O
the	O
lies	O
in	O
the	O
fact	O
that	O
it	O
directly	O
connects	O
and	O
.	O
	
This	O
direct	O
connection	O
helps	O
and	O
stabilizes	O
training	B-Task
,	O
since	O
the	O
terminal	O
error	O
signals	O
can	O
be	O
easily	O
backpropagated	O
to	O
model	O
parameters	O
.	O
	
Fig	O
.	O
	
[	O
reference	O
]	O
illustrates	O
paths	O
between	O
the	O
two	O
cell	O
states	O
.	O
	
We	O
find	O
experimentally	O
that	O
there	O
is	O
little	O
difference	O
between	O
letting	O
be	O
constant	O
and	O
letting	O
it	O
be	O
trainable	O
parameters	O
,	O
thus	O
we	O
set	O
in	O
all	O
experiments	O
.	O
	
We	O
also	O
experimented	O
with	O
the	O
architecture	O
without	O
i.e.	O
two	O
cell	O
states	O
are	O
combined	O
by	O
unweighted	B-Method
summation	I-Method
similar	O
to	O
multidimensional	B-Method
RNNs	I-Method
,	O
and	O
found	O
that	O
it	O
leads	O
to	O
performance	O
degradation	O
and	O
unstable	B-Metric
convergence	I-Metric
,	O
likely	O
due	O
to	O
mismatch	O
in	O
the	O
range	O
of	O
cell	O
state	O
values	O
between	O
layers	O
(	O
for	O
the	O
first	O
layer	O
and	O
for	O
the	O
others	O
)	O
.	O
	
Experimental	O
results	O
on	O
various	O
are	O
presented	O
in	O
§	O
[	O
reference	O
]	O
.	O
	
paragraph	O
:	O
Connection	O
to	O
tree	B-Method
-	I-Method
structured	I-Method
RNNs	I-Method
.	O
	
The	O
idea	O
of	O
having	O
multiple	O
states	O
is	O
also	O
related	O
to	O
tree	B-Method
-	I-Method
structured	I-Method
RNNs	I-Method
.	O
	
Among	O
them	O
,	O
tree	O
-	O
structured	O
LSTMs	B-Method
(	O
Tree	O
-	O
LSTMs	B-Method
)	O
are	O
similar	O
to	O
ours	O
in	O
that	O
they	O
use	O
both	O
hidden	O
and	O
cell	O
states	O
from	O
children	O
nodes	O
.	O
	
In	O
Tree	O
-	O
LSTMs	B-Method
,	O
states	O
for	O
all	O
children	O
nodes	O
are	O
regarded	O
as	O
input	O
,	O
and	O
they	O
participate	O
in	O
the	O
computation	O
equally	O
through	O
weight	O
-	O
shared	O
(	O
in	O
Child	O
-	O
Sum	O
Tree	O
-	O
LSTMs	B-Method
)	O
or	O
weight	O
-	O
unshared	O
(	O
in	O
-	O
ary	O
Tree	O
-	O
LSTMs	B-Method
)	O
projection	O
.	O
	
From	O
this	O
perspective	O
,	O
each	O
CAS	B-Method
-	I-Method
LSTM	I-Method
layer	I-Method
(	O
where	O
)	O
can	O
be	O
seen	O
as	O
a	O
binary	O
Tree	O
-	O
LSTM	B-Method
where	O
the	O
structures	O
it	O
operates	O
on	O
are	O
fixed	O
to	O
right	O
-	O
branching	O
trees	O
.	O
	
The	O
use	O
of	O
cell	O
state	O
in	O
computation	O
could	O
be	O
one	O
reason	O
that	O
Tree	O
-	O
LSTMs	B-Method
perform	O
better	O
than	O
sequential	O
LSTMs	B-Method
even	O
when	O
trivial	O
trees	O
(	O
strictly	O
left	O
-	O
or	O
right	O
-	O
branching	O
)	O
are	O
given	O
.	O
	
paragraph	O
:	O
Connection	O
to	O
multidimensional	B-Task
RNNs	I-Task
.	O
	
Multidimensional	B-Method
RNNs	I-Method
(	O
MDRNN	B-Method
)	I-Method
are	O
an	O
extension	O
of	O
1D	B-Method
sequential	I-Method
RNNs	I-Method
that	O
can	O
accept	O
multidimensional	O
input	O
e.g.	O
images	O
,	O
and	O
have	O
been	O
successfully	O
applied	O
to	O
image	B-Task
segmentation	I-Task
and	O
handwriting	B-Task
recognition	I-Task
.	O
	
Notably	O
multidimensional	B-Method
LSTMs	I-Method
(	O
MDLSTM	B-Method
)	O
have	O
an	O
analogous	O
formulation	O
to	O
ours	O
except	O
the	O
term	O
and	O
the	O
fact	O
that	O
we	O
use	O
distinct	O
weights	O
per	O
column	O
(	O
or	O
‘	O
layer	O
’	O
in	O
our	O
case	O
)	O
.	O
	
From	O
this	O
view	O
,	O
CAS	B-Method
-	I-Method
LSTM	I-Method
can	O
be	O
seen	O
as	O
a	O
certain	O
kind	O
of	O
MDLSTM	B-Method
that	O
accepts	O
a	O
2D	O
input	O
.	O
	
Grid	O
LSTMs	B-Method
also	O
take	O
inputs	O
but	O
emit	O
outputs	O
,	O
which	O
is	O
different	O
from	O
our	O
case	O
where	O
a	O
single	O
set	O
of	O
hidden	O
and	O
cell	O
states	O
is	O
produced	O
.	O
	
subsection	O
:	O
Sentence	B-Method
Encoders	I-Method
	
The	O
sentence	B-Method
encoder	I-Method
network	I-Method
we	O
use	O
in	O
our	O
experiments	O
takes	O
words	O
(	O
assumed	O
to	O
be	O
one	O
-	O
hot	O
vectors	O
)	O
as	O
input	O
.	O
	
The	O
words	O
are	O
projected	O
to	O
corresponding	O
word	B-Method
representations	I-Method
:	O
where	O
.	O
	
Then	O
is	O
fed	O
to	O
a	O
-	O
layer	O
CAS	B-Method
-	I-Method
LSTM	I-Method
model	I-Method
,	O
resulting	O
in	O
the	O
representations	O
.	O
	
The	O
sentence	B-Method
representation	I-Method
,	O
,	O
is	O
computed	O
by	O
max	B-Method
-	I-Method
pooling	I-Method
over	O
time	O
as	O
in	O
the	O
work	O
of	O
conneau2017infersent	O
conneau2017infersent	O
.	O
	
Similar	O
to	O
their	O
results	O
,	O
from	O
preliminary	O
experiments	O
we	O
found	O
that	O
the	O
max	B-Method
-	I-Method
pooling	I-Method
performs	O
consistently	O
better	O
than	O
mean	B-Method
-	I-Method
and	I-Method
last	I-Method
-	I-Method
pooling	I-Method
.	O
	
To	O
make	O
models	O
more	O
expressive	O
,	O
a	O
bidirectional	B-Method
CAS	I-Method
-	I-Method
LSTM	I-Method
network	I-Method
may	O
also	O
be	O
used	O
.	O
	
In	O
the	O
bidirectional	O
case	O
,	O
the	O
forward	B-Method
representations	I-Method
and	O
the	O
backward	B-Method
representations	I-Method
are	O
concatenated	O
and	O
max	B-Method
-	I-Method
pooled	I-Method
to	O
yield	O
the	O
sentence	B-Method
representation	I-Method
.	O
	
We	O
call	O
this	O
bidirectional	O
architecture	O
Bi	O
-	O
CAS	O
-	O
LSTM	B-Method
in	O
experiments	O
.	O
	
subsection	O
:	O
Top	B-Method
-	I-Method
layer	I-Method
Classifiers	I-Method
	
For	O
the	O
natural	B-Task
language	I-Task
inference	I-Task
experiments	O
,	O
we	O
use	O
the	O
following	O
heuristic	B-Method
function	I-Method
proposed	O
by	O
mou2016snli	O
mou2016snli	O
in	O
feature	B-Task
extraction	I-Task
:	O
where	O
means	O
vector	B-Method
concatenation	I-Method
,	O
and	O
and	O
are	O
applied	O
element	O
-	O
wise	O
.	O
	
And	O
we	O
use	O
the	O
following	O
function	O
in	O
paraphrase	B-Task
identification	I-Task
experiments	O
:	O
as	O
in	O
the	O
work	O
of	O
ji2013discriminative	O
ji2013discriminative	O
.	O
	
For	O
sentiment	B-Task
classification	I-Task
,	O
we	O
use	O
the	O
sentence	B-Method
representation	I-Method
itself	O
.	O
	
We	O
feed	O
the	O
feature	O
extracted	O
from	O
as	O
input	O
to	O
the	O
MLP	B-Method
classifier	I-Method
with	O
ReLU	B-Method
activation	I-Method
followed	O
by	O
the	O
fully	B-Method
-	I-Method
connected	I-Method
softmax	I-Method
layer	I-Method
to	O
predict	O
the	O
label	B-Task
distribution	I-Task
:	O
where	O
,	O
is	O
the	O
number	O
of	O
label	O
classes	O
,	O
and	O
the	O
dimension	O
of	O
the	O
MLP	O
output	O
,	O
	
section	O
:	O
Experiments	O
	
We	O
evaluate	O
our	O
method	O
on	O
natural	B-Task
language	I-Task
inference	I-Task
(	O
NLI	B-Task
)	O
,	O
paraphrase	B-Task
identification	I-Task
(	O
PI	B-Task
)	O
,	O
and	O
sentiment	B-Task
classification	I-Task
.	O
	
We	O
also	O
conduct	O
analysis	O
on	O
gate	O
values	O
and	O
experiments	O
on	O
model	B-Method
variants	I-Method
.	O
	
For	O
detailed	O
experimental	O
settings	O
,	O
we	O
refer	O
readers	O
to	O
the	O
supplemental	O
material	O
.	O
	
For	O
the	O
NLI	B-Task
and	O
PI	B-Task
tasks	I-Task
,	O
there	O
exists	O
recent	O
work	O
specializing	O
in	O
sentence	B-Task
pair	I-Task
classification	I-Task
.	O
	
However	O
in	O
this	O
work	O
we	O
confine	O
our	O
model	O
to	O
the	O
architecture	O
that	O
encodes	O
each	O
sentence	O
using	O
a	O
shared	B-Method
encoder	I-Method
without	O
any	O
inter	O
-	O
sentence	O
interaction	O
,	O
in	O
order	O
to	O
focus	O
on	O
the	O
effectiveness	O
of	O
the	O
models	O
in	O
extracting	B-Task
semantics	I-Task
.	O
	
But	O
note	O
that	O
the	O
applicability	O
of	O
CAS	B-Method
-	I-Method
LSTM	I-Method
is	O
not	O
limited	O
to	O
sentence	B-Method
encoding	I-Method
based	I-Method
approaches	I-Method
.	O
	
subsection	O
:	O
Natural	B-Task
Language	I-Task
Inference	I-Task
	
For	O
the	O
evaluation	O
of	O
performance	O
of	O
the	O
proposed	O
method	O
on	O
the	O
NLI	B-Task
task	I-Task
,	O
SNLI	B-Material
and	O
MultiNLI	B-Material
datasets	I-Material
are	O
used	O
.	O
	
The	O
objective	O
of	O
both	O
datasets	O
is	O
to	O
predict	O
the	O
relationship	O
between	O
a	O
premise	O
and	O
a	O
hypothesis	O
sentence	O
:	O
entailment	O
,	O
contradiction	O
,	O
and	O
neutral	O
.	O
	
SNLI	B-Material
and	O
MultiNLI	B-Material
datasets	O
are	O
composed	O
of	O
about	O
570k	O
and	O
430k	O
premise	O
-	O
hypothesis	O
pairs	O
respectively	O
.	O
	
GloVe	O
pretrained	O
word	O
embeddings	O
are	O
used	O
and	O
remain	O
fixed	O
during	O
training	O
.	O
	
The	O
dimension	O
of	O
encoder	O
states	O
(	O
)	O
is	O
set	O
to	O
300	O
and	O
a	O
1024D	B-Method
MLP	I-Method
with	O
one	O
or	O
two	O
hidden	O
layers	O
is	O
used	O
.	O
	
We	O
apply	O
dropout	B-Method
to	O
the	O
word	O
embeddings	O
and	O
the	O
MLP	B-Method
layers	I-Method
.	O
	
The	O
features	O
used	O
as	O
input	O
to	O
the	O
MLP	B-Method
classifier	I-Method
are	O
extracted	O
following	O
Eq	O
.	O
	
[	O
reference	O
]	O
.	O
	
Table	O
[	O
reference	O
]	O
and	O
[	O
reference	O
]	O
contain	O
results	O
of	O
the	O
models	O
on	O
SNLI	B-Material
and	O
MultiNLI	B-Material
datasets	I-Material
.	O
	
In	O
SNLI	B-Material
,	O
our	O
best	O
model	O
achieves	O
the	O
new	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
accuracy	B-Metric
of	O
87.0	O
%	O
with	O
relatively	O
fewer	O
parameters	O
.	O
	
Similarly	O
in	O
MultiNLI	B-Material
,	O
our	O
models	O
match	O
the	O
accuracy	B-Metric
of	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
models	O
in	O
both	O
in	B-Task
-	I-Task
domain	I-Task
(	O
matched	O
)	O
and	O
cross	O
-	O
domain	O
(	O
mismatched	O
)	O
test	O
sets	O
.	O
	
Note	O
that	O
only	O
the	O
GloVe	O
word	O
vectors	O
are	O
used	O
as	O
word	B-Method
representations	I-Method
,	O
as	O
opposed	O
to	O
some	O
models	O
that	O
introduce	O
character	O
-	O
level	O
features	O
.	O
	
It	O
is	O
also	O
notable	O
that	O
our	O
proposed	O
architecture	O
does	O
not	O
restrict	O
the	O
selection	O
of	O
pooling	B-Method
method	I-Method
;	O
the	O
performance	O
could	O
further	O
be	O
improved	O
by	O
replacing	O
max	B-Method
-	I-Method
pooling	I-Method
with	O
other	O
advanced	O
algorithms	O
e.g.	O
intra	B-Method
-	I-Method
sentence	I-Method
attention	I-Method
and	O
generalized	B-Method
pooling	I-Method
.	O
	
subsection	O
:	O
Paraphrase	B-Task
Identification	I-Task
	
We	O
use	O
Quora	B-Material
Question	I-Material
Pairs	I-Material
dataset	O
in	O
evaluating	O
the	O
performance	O
of	O
our	O
method	O
on	O
the	O
PI	B-Task
task	I-Task
.	O
	
The	O
dataset	O
consists	O
of	O
over	O
400k	O
question	O
pairs	O
,	O
and	O
each	O
pair	O
is	O
annotated	O
with	O
whether	O
the	O
two	O
sentences	O
are	O
paraphrase	O
of	O
each	O
other	O
or	O
not	O
.	O
	
Similar	O
to	O
the	O
NLI	B-Task
experiments	O
,	O
GloVe	O
pretrained	O
vectors	O
,	O
300D	B-Method
encoders	I-Method
,	O
and	O
1024D	B-Method
MLP	I-Method
are	O
used	O
.	O
	
The	O
number	O
of	O
CAS	B-Method
-	I-Method
LSTM	I-Method
layers	I-Method
is	O
fixed	O
to	O
2	O
in	O
PI	O
experiments	O
.	O
	
Two	O
sentence	O
vectors	O
are	O
aggregated	O
using	O
Eq	O
.	O
	
[	O
reference	O
]	O
and	O
fed	O
as	O
input	O
to	O
the	O
MLP	B-Method
.	O
	
The	O
results	O
on	O
the	O
Quora	B-Material
Question	I-Material
Pairs	I-Material
dataset	O
are	O
summarized	O
in	O
Table	O
[	O
reference	O
]	O
.	O
	
Again	O
we	O
can	O
see	O
that	O
our	O
models	O
outperform	O
other	O
models	O
by	O
large	O
margin	O
,	O
achieving	O
the	O
new	O
state	O
of	O
the	O
art	O
.	O
	
0.22	O
0.22	O
0.22	O
0.22	O
0.22	O
0.22	O
	
subsection	O
:	O
Sentiment	B-Task
Classification	I-Task
	
In	O
evaluating	O
sentiment	B-Task
classification	I-Task
performance	O
,	O
the	O
Stanford	B-Material
Sentiment	I-Material
Treebank	I-Material
(	O
SST	B-Material
)	O
is	O
used	O
.	O
	
It	O
consists	O
of	O
about	O
12	O
,	O
000	O
binary	O
-	O
parsed	O
sentences	O
where	O
constituents	O
(	O
phrases	O
)	O
of	O
each	O
parse	O
tree	O
are	O
annotated	O
with	O
a	O
sentiment	O
label	O
(	O
very	O
positive	O
,	O
positive	O
,	O
neutral	O
,	O
negative	O
,	O
very	O
negative	O
)	O
.	O
	
Following	O
the	O
convention	O
of	O
prior	O
work	O
,	O
all	O
phrases	O
and	O
their	O
labels	O
are	O
used	O
in	O
training	O
but	O
only	O
the	O
sentence	O
-	O
level	O
data	O
are	O
used	O
in	O
evaluation	B-Task
.	O
	
In	O
evaluation	O
we	O
consider	O
two	O
settings	O
,	O
namely	O
SST	B-Material
-	I-Material
2	I-Material
and	O
SST	B-Material
-	I-Material
5	I-Material
,	O
the	O
two	O
differing	O
only	O
in	O
their	O
level	O
of	O
granularity	O
with	O
regard	O
to	O
labels	O
.	O
	
In	O
SST	B-Material
-	I-Material
2	I-Material
,	O
data	O
samples	O
annotated	O
with	O
‘	O
neutral	O
’	O
are	O
ignored	O
from	O
training	O
and	O
evaluation	O
.	O
	
The	O
two	O
positive	O
labels	O
(	O
very	O
positive	O
,	O
positive	O
)	O
are	O
considered	O
as	O
the	O
same	O
label	O
,	O
and	O
similarly	O
for	O
the	O
two	O
negative	O
labels	O
.	O
	
As	O
a	O
result	O
98	O
,	O
794	O
/	O
872	O
/	O
1	O
,	O
821	O
data	O
samples	O
are	O
used	O
in	O
training	O
/	O
validation	O
/	O
test	O
,	O
and	O
the	O
task	O
is	O
considered	O
as	O
a	O
binary	B-Task
classification	I-Task
problem	I-Task
.	O
	
In	O
SST	B-Material
-	I-Material
5	I-Material
,	O
data	O
are	O
used	O
as	O
-	O
is	O
and	O
thus	O
the	O
task	O
is	O
a	O
5	B-Task
-	I-Task
class	I-Task
classification	I-Task
problem	I-Task
.	O
	
All	O
318	O
,	O
582	O
/	O
1	O
,	O
101	O
/	O
2	O
,	O
210	O
data	O
samples	O
for	O
training	O
/	O
validation	O
/	O
test	O
are	O
used	O
in	O
the	O
SST	B-Material
-	O
5	O
setting	O
.	O
	
We	O
use	O
300D	O
GloVe	O
vectors	O
,	O
2	O
-	O
layer	O
150D	B-Method
or	I-Method
300D	I-Method
encoders	I-Method
,	O
and	O
a	O
300D	B-Method
MLP	I-Method
classifier	I-Method
for	O
the	O
models	O
,	O
however	O
unlike	O
previous	O
experiments	O
we	O
tune	O
the	O
word	O
embeddings	O
during	O
training	O
.	O
	
The	O
results	O
on	O
SST	B-Material
are	O
listed	O
in	O
Table	O
[	O
reference	O
]	O
.	O
	
Our	O
models	O
achieve	O
the	O
new	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
accuracy	B-Metric
on	O
SST	B-Material
-	I-Material
2	I-Material
and	O
competitive	O
accuracy	B-Metric
on	O
SST	B-Material
-	I-Material
5	I-Material
,	O
without	O
utilizing	O
parse	O
tree	O
information	O
.	O
	
subsection	O
:	O
Forget	B-Method
Gate	I-Method
Analysis	I-Method
	
To	O
inspect	O
the	O
effect	O
of	O
the	O
additional	O
forget	O
gate	O
,	O
we	O
investigate	O
how	O
the	O
values	O
of	O
vertical	O
forget	O
gates	O
are	O
distributed	O
.	O
	
We	O
sample	O
1	O
,	O
000	O
random	O
sentences	O
from	O
the	O
development	O
set	O
of	O
the	O
SNLI	B-Material
dataset	I-Material
,	O
and	O
use	O
the	O
3	B-Method
-	I-Method
layer	I-Method
CAS	I-Method
-	I-Method
LSTM	I-Method
model	I-Method
trained	O
on	O
the	O
SNLI	B-Material
dataset	I-Material
to	O
compute	O
gate	O
values	O
.	O
	
If	O
all	O
values	O
from	O
a	O
vertical	O
forget	O
gate	O
were	O
to	O
be	O
0	O
,	O
this	O
would	O
mean	O
that	O
the	O
introduction	O
of	O
the	O
additional	O
forget	O
gate	O
is	O
meaningless	O
and	O
the	O
model	O
would	O
reduce	O
to	O
a	O
plain	O
stacked	O
LSTM	B-Method
.	O
	
On	O
the	O
contrary	O
if	O
all	O
values	O
were	O
1	O
,	O
meaning	O
that	O
the	O
vertical	O
forget	O
gates	O
were	O
always	O
open	O
,	O
it	O
would	O
be	O
impossible	O
to	O
say	O
that	O
the	O
information	O
is	O
modulated	O
effectively	O
.	O
	
Fig	O
.	O
	
[	O
reference	O
]	O
and	O
[	O
reference	O
]	O
represent	O
histograms	O
of	O
the	O
vertical	O
forget	O
gate	O
values	O
from	O
the	O
second	O
and	O
the	O
third	O
layer	O
.	O
	
From	O
the	O
figures	O
we	O
can	O
validate	O
that	O
the	O
trained	O
model	O
does	O
not	O
fall	O
into	O
the	O
degenerate	O
case	O
where	O
vertical	O
forget	O
gates	O
are	O
ignored	O
.	O
	
Also	O
the	O
figures	O
show	O
that	O
the	O
values	O
are	O
right	O
-	O
skewed	O
,	O
which	O
we	O
conjecture	O
to	O
be	O
a	O
result	O
of	O
focusing	O
more	O
on	O
a	O
strong	O
interaction	O
between	O
adjacent	O
layers	O
.	O
	
To	O
further	O
verify	O
that	O
the	O
gate	O
values	O
are	O
diverse	O
enough	O
within	O
each	O
time	O
step	O
,	O
we	O
compute	O
the	O
distribution	O
of	O
the	O
range	O
of	O
values	O
per	O
time	O
step	O
,	O
,	O
where	O
.	O
	
We	O
plot	O
the	O
histograms	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
and	O
[	O
reference	O
]	O
.	O
	
From	O
the	O
figure	O
we	O
see	O
that	O
a	O
vertical	O
forget	O
gate	O
controls	O
the	O
amount	O
of	O
information	O
flow	O
effectively	O
,	O
making	O
the	O
decision	O
of	O
retaining	B-Task
or	I-Task
discarding	I-Task
signals	I-Task
.	O
	
Finally	O
,	O
to	O
investigate	O
the	O
argument	O
presented	O
in	O
§	O
[	O
reference	O
]	O
that	O
the	O
additional	O
forget	O
gate	O
helps	O
the	O
previous	O
output	O
gate	O
with	O
reducing	O
the	O
burden	O
of	O
extracting	O
all	O
needed	O
information	O
,	O
we	O
inspect	O
the	O
distribution	O
of	O
the	O
values	O
from	O
.	O
	
This	O
distribution	O
indicates	O
how	O
differently	O
the	O
vertical	O
forget	O
gate	O
and	O
the	O
previous	O
output	O
gate	O
select	O
information	O
from	O
.	O
	
From	O
Fig	O
.	O
	
[	O
reference	O
]	O
and	O
[	O
reference	O
]	O
	
we	O
can	O
see	O
that	O
the	O
two	O
gates	O
make	O
fairly	O
different	O
decisions	O
,	O
from	O
which	O
we	O
demonstrate	O
that	O
the	O
direct	O
path	O
between	O
and	O
enables	O
a	O
model	O
to	O
utilize	O
signals	O
overlooked	O
by	O
.	O
	
subsection	O
:	O
Model	O
Variations	O
	
In	O
this	O
subsection	O
,	O
we	O
see	O
the	O
influence	O
of	O
each	O
component	O
of	O
a	O
model	O
on	O
performance	O
by	O
removing	O
or	O
replacing	O
its	O
components	O
.	O
	
the	O
SNLI	B-Material
dataset	I-Material
is	O
used	O
for	O
experiments	O
,	O
and	O
the	O
best	O
performing	O
configuration	O
is	O
used	O
as	O
a	O
baseline	O
for	O
modifications	B-Task
.	O
	
We	O
consider	O
the	O
following	O
variants	O
:	O
(	O
i	O
)	O
models	O
that	O
use	O
plain	O
stacked	O
LSTMs	B-Method
,	O
(	O
ii	O
)	O
models	O
with	O
different	O
,	O
(	O
iii	O
)	O
models	O
without	O
,	O
and	O
(	O
iv	O
)	O
models	O
that	O
integrate	O
lower	O
contexts	O
via	O
peephole	O
connections	O
.	O
	
Variant	O
(	O
iv	O
)	O
integrates	O
lower	O
contexts	O
via	O
the	O
following	O
equations	O
:	O
where	O
represent	O
peephole	O
weights	O
that	O
take	O
cell	O
states	O
into	O
account	O
.	O
	
Among	O
the	O
above	O
equations	O
,	O
those	O
that	O
use	O
the	O
lower	O
cell	O
state	O
are	O
Eq	O
.	O
	
[	O
reference	O
]	O
and	O
[	O
reference	O
]	O
.	O
	
We	O
can	O
see	O
that	O
affects	O
the	O
value	O
of	O
only	O
via	O
peephole	O
connections	O
,	O
which	O
makes	O
independent	O
of	O
.	O
	
Table	O
[	O
reference	O
]	O
summarizes	O
the	O
results	O
of	O
model	O
variants	O
.	O
	
We	O
can	O
again	O
see	O
that	O
the	O
use	O
of	O
cell	O
states	O
clearly	O
improves	O
sentence	B-Task
modeling	I-Task
performance	O
(	O
baseline	O
vs.	O
(	O
i	O
)	O
and	O
(	O
iv	O
)	O
vs.	O
(	O
i	O
)	O
)	O
.	O
	
Also	O
from	O
the	O
results	O
of	O
baseline	O
and	O
(	O
ii	O
)	O
,	O
we	O
validate	O
that	O
the	O
selection	O
of	O
does	O
not	O
significantly	O
affect	O
performance	O
but	O
introducing	O
is	O
beneficial	O
(	O
baseline	O
vs.	O
(	O
iii	O
)	O
)	O
possibly	O
due	O
to	O
its	O
effect	O
on	O
normalizing	O
information	O
from	O
multiple	O
sources	O
,	O
as	O
mentioned	O
in	O
§	O
[	O
reference	O
]	O
.	O
	
Finally	O
,	O
from	O
the	O
comparison	O
between	O
baseline	B-Metric
and	O
(	O
iv	O
)	O
,	O
we	O
show	O
that	O
the	O
proposed	O
way	O
of	O
combining	O
the	O
left	O
and	O
the	O
lower	O
contexts	O
leads	O
to	O
better	O
modeling	O
of	O
sentence	B-Task
representations	I-Task
than	O
that	O
of	O
zhang2016highway	B-Method
zhang2016highway	I-Method
in	O
encoding	O
sentences	O
.	O
	
section	O
:	O
Related	O
Work	O
	
paragraph	O
:	O
Stacked	B-Method
recurrent	I-Method
neural	I-Method
networks	I-Method
.	O
	
There	O
is	O
some	O
prior	O
work	O
on	O
methods	O
of	O
stacking	B-Task
RNNs	I-Task
beyond	O
the	O
plain	B-Method
stacked	I-Method
RNNs	I-Method
.	O
	
Residual	O
LSTMs	B-Method
add	O
residual	O
connections	O
between	O
the	O
hidden	O
states	O
computed	O
at	O
each	O
LSTM	B-Method
layer	I-Method
,	O
and	O
shortcut	O
-	O
stacked	O
LSTMs	B-Method
concatenate	O
hidden	O
states	O
from	O
all	O
previous	O
layers	O
to	O
make	O
the	O
backpropagation	O
path	O
short	O
.	O
	
In	O
our	O
method	O
,	O
the	O
lower	O
context	O
is	O
aggregated	O
via	O
a	O
gating	B-Method
mechanism	I-Method
,	O
and	O
we	O
believe	O
it	O
modulates	O
the	O
amount	O
of	O
information	O
to	O
be	O
transmitted	O
in	O
a	O
more	O
efficient	O
and	O
effective	O
way	O
than	O
vector	B-Method
addition	I-Method
or	O
concatenation	B-Method
.	O
	
Also	O
,	O
compared	O
to	O
concatenation	B-Method
,	O
our	O
method	O
does	O
not	O
significantly	O
increase	O
the	O
number	O
of	O
parameters	O
.	O
	
Highway	B-Method
LSTMs	I-Method
and	O
depth	B-Method
-	I-Method
gated	I-Method
LSTMs	I-Method
are	O
similar	O
to	O
our	O
proposed	O
models	O
in	O
that	O
they	O
use	O
cell	O
states	O
from	O
the	O
previous	O
layer	O
,	O
and	O
they	O
are	O
successfully	O
applied	O
to	O
the	O
field	O
of	O
automatic	B-Task
speech	I-Task
recognition	I-Task
and	O
language	B-Task
modeling	I-Task
.	O
	
However	O
in	O
contrast	O
to	O
CAS	B-Method
-	I-Method
LSTM	I-Method
,	O
where	O
the	O
additional	O
forget	O
gate	O
aggregates	O
the	O
previous	O
layer	O
states	O
,	O
and	O
thus	O
contexts	O
from	O
the	O
left	O
and	O
below	O
participate	O
in	O
computation	O
equitably	O
,	O
in	O
Highway	B-Method
LSTMs	I-Method
and	O
depth	B-Method
-	I-Method
gated	I-Method
LSTMs	I-Method
the	O
previous	O
layer	O
states	O
are	O
considered	O
only	O
through	O
peephole	O
connections	O
.	O
	
The	O
comparison	O
of	O
our	O
models	O
and	O
this	O
architecture	O
is	O
presented	O
in	O
§	O
[	O
reference	O
]	O
.	O
	
paragraph	O
:	O
Multidimensional	B-Method
recurrent	I-Method
neural	I-Method
networks	I-Method
.	O
	
There	O
is	O
another	O
line	O
of	O
research	O
that	O
aims	O
to	O
extend	O
RNNs	B-Method
to	O
operate	O
on	O
multidimensional	O
inputs	O
.	O
	
Grid	O
LSTMs	B-Method
are	O
a	O
general	O
-	O
dimensional	O
LSTM	B-Method
architecture	O
that	O
accepts	O
sets	O
of	O
hidden	O
and	O
cell	O
states	O
as	O
input	O
and	O
yields	O
sets	O
of	O
states	O
as	O
output	O
,	O
in	O
contrast	O
to	O
our	O
architecture	O
,	O
which	O
emits	O
a	O
single	O
set	O
of	O
states	O
.	O
	
2D	O
and	O
3D	O
Grid	O
LSTMs	B-Method
bring	O
a	O
performance	O
gain	O
on	O
character	B-Task
-	I-Task
level	I-Task
language	I-Task
modeling	I-Task
and	O
machine	B-Task
translation	I-Task
respectively	O
.	O
	
Multidimensional	B-Method
RNNs	I-Method
have	O
a	O
similar	O
formulation	O
as	O
ours	O
,	O
except	O
that	O
they	O
do	O
not	O
normalize	O
cell	O
states	O
and	O
weights	O
for	O
all	O
columns	O
(	O
layers	O
)	O
are	O
tied	O
.	O
	
However	O
they	O
are	O
often	O
employed	O
to	O
model	O
multidimensional	O
data	O
such	O
as	O
images	O
of	O
handwritten	O
text	O
with	O
RNNs	B-Method
,	O
rather	O
than	O
stacking	B-Method
RNN	I-Method
layers	I-Method
for	O
modeling	O
sequential	O
data	O
.	O
	
paragraph	O
:	O
Deep	O
recurrent	O
transitions	O
.	O
	
Rather	O
than	O
stacking	O
recurrent	O
layers	O
,	O
some	O
work	O
focuses	O
on	O
increasing	O
the	O
depth	O
of	O
horizontal	O
recurrence	O
.	O
	
pascanu2014construct	O
pascanu2014construct	O
have	O
investigated	O
various	O
architectures	O
to	O
increase	O
the	O
depth	O
of	O
RNNs	O
,	O
inter	O
alia	O
	
Deep	B-Method
Transition	I-Method
RNNs	I-Method
address	O
the	O
problem	O
of	O
deep	B-Task
hidden	I-Task
-	I-Task
to	I-Task
-	I-Task
hidden	I-Task
transitions	I-Task
.	O
	
graves2016adaptive	O
graves2016adaptive	O
proposed	O
an	O
adaptive	B-Method
computation	I-Method
time	I-Method
algorithm	I-Method
that	O
learns	O
how	O
many	O
micro	O
time	O
steps	O
to	O
take	O
between	O
receiving	O
an	O
input	O
and	O
emitting	O
an	O
output	O
.	O
	
Fast	B-Method
-	I-Method
Slow	I-Method
RNNs	I-Method
process	O
data	O
on	O
different	O
timescales	O
by	O
letting	O
a	O
fast	O
cell	O
iterate	O
for	O
a	O
fixed	O
number	O
of	O
time	O
steps	O
before	O
a	O
slow	O
cell	O
receives	O
the	O
next	O
input	O
.	O
	
Multiscale	B-Method
RNNs	I-Method
e.g.	O
Clockwork	B-Method
RNNs	I-Method
and	O
Hierarchical	B-Method
Multiscale	I-Method
RNNs	I-Method
can	O
be	O
also	O
regarded	O
as	O
architectures	O
with	O
increased	O
recurrence	O
depth	O
.	O
	
However	O
as	O
noted	O
by	O
zilly2017rhn	O
zilly2017rhn	O
,	O
increase	O
in	O
recurrent	O
depth	O
results	O
in	O
a	O
longer	O
maximum	O
path	O
than	O
stacking	B-Method
recurrent	I-Method
layers	I-Method
and	O
makes	O
training	B-Task
difficult	O
without	O
careful	O
initialization	O
or	O
architectural	O
choice	O
.	O
	
section	O
:	O
Conclusion	O
	
In	O
this	O
paper	O
,	O
we	O
proposed	O
a	O
method	O
of	O
stacking	O
multiple	O
LSTM	B-Method
layers	O
for	O
modeling	B-Task
sentences	I-Task
,	O
dubbed	O
CAS	B-Method
-	I-Method
LSTM	I-Method
.	O
	
It	O
uses	O
not	O
only	O
hidden	O
states	O
but	O
also	O
cell	O
states	O
from	O
the	O
previous	O
layer	O
,	O
for	O
the	O
purpose	O
of	O
controlling	O
the	O
vertical	O
information	O
flow	O
in	O
a	O
more	O
elaborate	O
way	O
.	O
	
We	O
evaluated	O
the	O
proposed	O
method	O
on	O
various	O
benchmark	O
tasks	O
:	O
natural	B-Task
language	I-Task
inference	I-Task
,	O
paraphrase	B-Task
identification	I-Task
,	O
and	O
sentiment	B-Task
classification	I-Task
.	O
	
Our	O
models	O
achieve	O
the	O
new	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
accuracy	B-Metric
on	O
SNLI	B-Material
and	O
Quora	B-Material
Question	I-Material
Pairs	I-Material
datasets	I-Material
and	O
obtain	O
comparable	O
results	O
on	O
MultiNLI	B-Material
and	O
SST	B-Material
datasets	I-Material
.	O
	
The	O
proposed	O
architecture	O
can	O
replace	O
any	O
stacked	O
LSTM	B-Method
under	O
one	O
weak	O
restriction	O
—	O
the	O
size	O
of	O
states	O
should	O
be	O
identical	O
across	O
all	O
layers	O
.	O
	
For	O
future	O
work	O
we	O
plan	O
to	O
apply	O
the	O
CAS	O
-	O
LSTM	B-Method
architecture	O
beyond	O
sentence	B-Task
modeling	I-Task
tasks	I-Task
.	O
	
Various	O
problems	O
e.g.	O
sequence	B-Task
labeling	I-Task
,	O
sequence	B-Task
generation	I-Task
,	O
and	O
language	B-Task
modeling	I-Task
might	O
benefit	O
from	O
sophisticated	O
modulation	O
on	O
context	B-Task
integration	I-Task
.	O
	
Aggregating	O
diverse	O
contexts	O
from	O
sequential	O
data	O
,	O
e.g.	O
those	O
from	O
forward	O
and	O
backward	O
reading	O
of	O
text	O
,	O
could	O
also	O
be	O
an	O
intriguing	O
research	O
direction	O
.	O
	
section	O
:	O
Acknowledgments	O
	
We	O
thank	O
Dan	O
Edmiston	O
for	O
the	O
review	O
of	O
the	O
manuscript	O
.	O
	
bibliography	O
:	O
References	O
	
document	O
:	O
Robust	B-Task
Face	I-Task
Detection	I-Task
via	O
Learning	B-Task
Small	I-Task
Faces	I-Task
on	O
Hard	B-Material
Images	I-Material
	
Recent	O
anchor	B-Method
-	I-Method
based	I-Method
deep	I-Method
face	I-Method
detectors	I-Method
have	O
achieved	O
promising	O
performance	O
,	O
but	O
they	O
are	O
still	O
struggling	O
to	O
detect	O
hard	O
faces	O
,	O
such	O
as	O
small	O
,	O
blurred	O
and	O
partially	O
occluded	O
faces	O
.	O
	
A	O
reason	O
is	O
that	O
they	O
treat	O
all	O
images	O
and	O
faces	O
equally	O
,	O
without	O
putting	O
more	O
effort	O
on	O
hard	O
ones	O
;	O
however	O
,	O
many	O
training	O
images	O
only	O
contain	O
easy	O
faces	O
,	O
which	O
are	O
less	O
helpful	O
to	O
achieve	O
better	O
performance	O
on	O
hard	B-Material
images	I-Material
.	O
	
In	O
this	O
paper	O
,	O
we	O
propose	O
that	O
the	O
robustness	B-Metric
of	O
a	O
face	B-Method
detector	I-Method
against	O
hard	O
faces	O
can	O
be	O
improved	O
by	O
learning	O
small	O
faces	O
on	O
hard	B-Material
images	I-Material
.	O
	
Our	O
intuitions	O
are	O
(	O
1	O
)	O
hard	B-Material
images	I-Material
are	O
the	O
images	O
which	O
contain	O
at	O
least	O
one	O
hard	O
face	O
,	O
thus	O
they	O
facilitate	O
training	O
robust	O
face	B-Method
detectors	I-Method
;	O
(	O
2	O
)	O
most	O
hard	O
faces	O
are	O
small	O
faces	O
and	O
other	O
types	O
of	O
hard	O
faces	O
can	O
be	O
easily	O
converted	O
to	O
small	O
faces	O
by	O
shrinking	O
.	O
	
We	O
build	O
an	O
anchor	B-Method
-	I-Method
based	I-Method
deep	I-Method
face	I-Method
detector	I-Method
,	O
which	O
only	O
output	O
a	O
single	O
feature	O
map	O
with	O
small	O
anchors	O
,	O
to	O
specifically	O
learn	O
small	O
faces	O
and	O
train	O
it	O
by	O
a	O
novel	O
hard	B-Method
image	I-Method
mining	I-Method
strategy	I-Method
.	O
	
Extensive	O
experiments	O
have	O
been	O
conducted	O
on	O
WIDER	B-Material
FACE	I-Material
,	O
FDDB	B-Material
,	O
Pascal	B-Material
Faces	I-Material
,	O
and	O
AFW	B-Material
datasets	I-Material
to	O
show	O
the	O
effectiveness	O
of	O
our	O
method	O
.	O
	
Our	O
method	O
achieves	O
APs	B-Metric
of	O
95.7	O
,	O
94.9	O
and	O
89.7	O
on	O
easy	O
,	O
medium	O
and	O
hard	O
WIDER	O
	
FACE	B-Material
val	I-Material
dataset	I-Material
respectively	O
,	O
which	O
surpass	O
the	O
previous	O
state	O
-	O
of	O
-	O
the	O
-	O
arts	O
,	O
especially	O
on	O
the	O
hard	O
subset	O
.	O
	
Code	O
and	O
model	O
are	O
available	O
at	O
.	O
	
section	O
:	O
Introduction	O
	
Face	B-Task
detection	I-Task
is	O
a	O
fundamental	O
and	O
important	O
computer	B-Task
vision	I-Task
problem	I-Task
,	O
which	O
is	O
critical	O
for	O
many	O
face	B-Task
-	I-Task
related	I-Task
tasks	I-Task
,	O
such	O
as	O
face	B-Task
alignment	I-Task
,	O
tracking	B-Task
and	I-Task
recognition	I-Task
.	O
	
Stem	O
from	O
the	O
recent	O
successful	O
development	O
of	O
deep	B-Method
neural	I-Method
networks	I-Method
,	O
massive	B-Method
CNN	I-Method
-	I-Method
based	I-Method
face	I-Method
detection	I-Method
approaches	I-Method
have	O
been	O
proposed	O
and	O
achieved	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
performance	O
.	O
	
However	O
,	O
face	B-Task
detection	I-Task
remains	O
a	O
challenging	O
task	O
due	O
to	O
occlusion	O
,	O
illumination	O
,	O
makeup	O
,	O
as	O
well	O
as	O
pose	O
and	O
scale	O
variance	O
,	O
as	O
shown	O
in	O
the	O
benchmark	B-Material
dataset	I-Material
WIDER	I-Material
FACE	I-Material
.	O
	
Current	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
CNN	B-Method
-	I-Method
based	I-Method
face	I-Method
detectors	I-Method
attempt	O
to	O
address	O
these	O
challenges	O
by	O
employing	O
more	O
powerful	O
backbone	B-Method
models	I-Method
,	O
exploiting	O
feature	B-Method
pyramid	I-Method
-	I-Method
style	I-Method
architectures	I-Method
to	O
combine	O
features	O
from	O
multiple	O
detection	O
feature	O
maps	O
,	O
designing	O
denser	O
anchors	O
and	O
utilizing	O
larger	O
contextual	O
information	O
.	O
	
These	O
methods	O
and	O
techniques	O
have	O
been	O
shown	O
to	O
be	O
successful	O
to	O
build	O
a	O
robust	B-Method
face	I-Method
detector	I-Method
,	O
and	O
improve	O
the	O
performance	O
towards	O
human	O
-	O
level	O
for	O
most	O
images	O
.	O
	
In	O
spite	O
of	O
their	O
success	O
for	O
most	O
images	O
,	O
an	O
evident	O
performance	O
gap	O
still	O
exists	O
especially	O
for	O
those	O
hard	B-Material
images	I-Material
which	O
contain	O
small	O
,	O
blurred	O
and	O
partially	O
occluded	O
faces	O
.	O
	
We	O
realize	O
that	O
these	O
hard	B-Material
images	I-Material
have	O
become	O
the	O
main	O
barriers	O
for	O
face	B-Task
detectors	I-Task
to	O
achieve	O
human	B-Task
-	I-Task
level	I-Task
detection	I-Task
performance	O
.	O
	
In	O
Figure	O
[	O
reference	O
]	O
,	O
we	O
show	O
that	O
,	O
even	O
on	O
the	O
train	O
set	O
of	O
WIDER	B-Material
FACE	I-Material
,	O
the	O
official	O
pre	O
-	O
trained	O
SSH	B-Method
still	O
fails	O
on	O
some	O
of	O
the	O
images	O
with	O
extremely	O
hard	O
faces	O
.	O
	
We	O
show	O
two	O
such	O
hard	O
training	O
images	O
in	O
the	O
upper	O
right	O
corner	O
in	O
Figure	O
[	O
reference	O
]	O
.	O
	
On	O
the	O
other	O
hand	O
,	O
most	O
training	O
images	O
with	O
easy	O
faces	O
can	O
be	O
almost	O
perfectly	O
detected	O
(	O
see	O
the	O
illustration	O
in	O
the	O
right	O
lower	O
corner	O
of	O
Figure	O
[	O
reference	O
]	O
)	O
.	O
	
As	O
shown	O
in	O
left	O
part	O
of	O
Figure	O
[	O
reference	O
]	O
,	O
over	O
two	O
thirds	O
of	O
the	O
training	O
images	O
already	O
obtained	O
perfect	O
detection	B-Metric
accuracy	I-Metric
,	O
which	O
indicates	O
that	O
those	O
easy	O
images	O
are	O
less	O
useful	O
towards	O
training	O
a	O
robust	B-Method
face	I-Method
detector	I-Method
.	O
	
To	O
address	O
this	O
issue	O
,	O
in	O
this	O
paper	O
,	O
we	O
propose	O
a	O
robust	B-Method
face	I-Method
detector	I-Method
by	O
putting	O
more	O
training	O
focus	O
on	O
those	O
hard	O
images	O
.	O
	
This	O
issue	O
is	O
most	O
related	O
to	O
anchor	B-Task
-	I-Task
level	I-Task
hard	I-Task
example	I-Task
mining	I-Task
discussed	O
in	O
OHEM	B-Method
.	O
	
However	O
,	O
due	O
to	O
the	O
sparsity	O
of	O
ground	O
-	O
truth	O
faces	O
and	O
positive	O
anchors	O
,	O
traditional	O
anchor	B-Method
-	I-Method
level	I-Method
hard	I-Method
example	I-Method
mining	I-Method
mainly	O
focuses	O
on	O
mining	O
hard	O
negative	O
anchors	O
,	O
and	O
mining	O
hard	O
anchors	O
on	O
well	O
-	O
detected	O
images	O
exhibits	O
less	O
effectiveness	O
since	O
there	O
is	O
no	O
useful	O
information	O
that	O
can	O
be	O
further	O
exploited	O
in	O
these	O
easy	O
images	O
.	O
	
To	O
address	O
this	O
issue	O
,	O
we	O
propose	O
to	O
mine	O
hard	O
examples	O
at	O
image	O
level	O
in	O
parallel	O
with	O
anchor	O
level	O
.	O
	
More	O
specifically	O
,	O
we	O
propose	O
to	O
dynamically	O
assign	O
difficulty	O
scores	O
to	O
training	O
images	O
during	O
the	O
learning	B-Task
process	I-Task
,	O
which	O
can	O
determine	O
whether	O
an	O
image	O
is	O
already	O
well	O
-	O
detected	O
or	O
still	O
useful	O
for	O
further	O
training	O
.	O
	
This	O
allows	O
us	O
to	O
fully	O
utilize	O
the	O
images	O
which	O
were	O
not	O
perfectly	O
detected	O
to	O
better	O
facilitate	O
the	O
following	O
learning	B-Task
process	I-Task
.	O
	
We	O
show	O
this	O
strategy	O
can	O
make	O
our	O
detector	O
more	O
robust	O
towards	O
hard	O
faces	O
,	O
without	O
involving	O
more	O
complex	O
network	O
architecture	O
and	O
computation	O
overhead	O
.	O
	
Apart	O
from	O
mining	O
the	O
hard	B-Material
images	I-Material
,	O
we	O
also	O
propose	O
to	O
improve	O
the	O
detection	B-Metric
quality	I-Metric
by	O
exclusively	O
exploiting	O
small	O
faces	O
.	O
	
Small	O
faces	O
are	O
typically	O
hard	O
and	O
have	O
attracted	O
extensive	O
research	O
attention	O
.	O
	
Existing	O
methods	O
aim	O
at	O
building	O
a	O
scale	B-Method
-	I-Method
invariant	I-Method
face	I-Method
detector	I-Method
to	O
learn	O
and	O
infer	O
on	O
both	O
small	O
and	O
big	O
faces	O
,	O
with	O
multiple	O
levels	O
of	O
detection	O
features	O
and	O
anchors	O
of	O
different	O
sizes	O
.	O
	
Compared	O
with	O
these	O
methods	O
,	O
our	O
detector	O
is	O
more	O
efficient	O
since	O
it	O
is	O
specially	O
designed	O
to	O
aggressively	O
leveraging	O
the	O
small	O
faces	O
during	O
training	O
.	O
	
More	O
specifically	O
,	O
large	O
faces	O
are	O
automatically	O
ignored	O
during	O
training	O
due	O
to	O
our	O
anchor	B-Method
design	I-Method
,	O
so	O
that	O
the	O
model	O
can	O
fully	O
focus	O
on	O
the	O
small	O
hard	O
faces	O
.	O
	
Additionally	O
,	O
experiments	O
demonstrate	O
that	O
this	O
design	O
effectively	O
achieves	O
improvements	O
on	O
detecting	O
all	O
faces	O
in	O
spite	O
of	O
its	O
simple	O
and	O
shallow	B-Method
architecture	I-Method
.	O
	
To	O
conclude	O
,	O
in	O
this	O
paper	O
,	O
we	O
propose	O
a	O
novel	O
face	B-Method
detector	I-Method
with	O
the	O
following	O
contributions	O
:	O
We	O
propose	O
a	O
hard	B-Method
image	I-Method
mining	I-Method
strategy	I-Method
,	O
to	O
improve	O
the	O
robustness	B-Metric
of	O
our	O
detector	O
to	O
those	O
extremely	O
hard	O
faces	O
.	O
	
This	O
is	O
done	O
without	O
any	O
extra	O
modules	O
,	O
parameters	O
or	O
computation	O
overhead	O
added	O
on	O
the	O
existing	O
detector	O
.	O
	
We	O
design	O
a	O
single	B-Method
shot	I-Method
detector	I-Method
with	O
only	O
one	O
detection	B-Method
feature	I-Method
map	I-Method
,	O
which	O
focuses	O
on	O
small	O
faces	O
with	O
a	O
specific	O
range	O
of	O
sizes	O
.	O
	
This	O
allows	O
our	O
model	O
to	O
be	O
simple	O
and	O
focus	O
on	O
difficult	O
small	O
faces	O
without	O
struggling	O
with	O
scale	O
variance	O
.	O
	
Our	O
face	B-Method
detector	I-Method
establishes	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
performance	O
on	O
all	O
popular	O
face	O
detection	O
datasets	O
,	O
including	O
WIDER	B-Material
FACE	I-Material
,	O
FDDB	B-Material
,	O
Pascal	B-Material
Faces	I-Material
,	O
and	O
AFW	B-Material
.	O
	
We	O
achieve	O
95.7	O
,	O
94.9	O
and	O
89.7	O
on	O
easy	O
,	O
medium	O
and	O
hard	O
WIDER	O
	
FACE	B-Material
val	I-Material
dataset	I-Material
.	O
	
Our	O
method	O
also	O
achieves	O
APs	B-Metric
of	O
99.00	O
and	O
99.60	O
on	O
Pascal	B-Material
Faces	I-Material
and	O
AFW	O
respectively	O
,	O
as	O
well	O
as	O
a	O
TPR	B-Metric
of	O
98.7	O
on	O
FDDB	B-Material
.	O
	
The	O
remainder	O
of	O
this	O
paper	O
is	O
organized	O
as	O
follows	O
.	O
	
In	O
Section	O
[	O
reference	O
]	O
,	O
we	O
discuss	O
some	O
studies	O
have	O
been	O
done	O
which	O
are	O
related	O
to	O
our	O
paper	O
.	O
	
In	O
Section	O
[	O
reference	O
]	O
,	O
we	O
dive	O
into	O
details	O
of	O
our	O
proposed	O
method	O
,	O
and	O
we	O
discuss	O
experiment	O
results	O
and	O
ablation	O
experiments	O
in	O
Section	O
[	O
reference	O
]	O
.	O
	
Finally	O
,	O
conclusions	O
are	O
drawn	O
in	O
Section	O
[	O
reference	O
]	O
.	O
	
section	O
:	O
Related	O
work	O
	
Face	B-Task
detection	I-Task
has	O
received	O
extensive	O
research	O
attention	O
.	O
	
With	O
the	O
emergence	O
of	O
modern	O
CNN	B-Method
and	I-Method
object	I-Method
detector	I-Method
,	O
there	O
are	O
many	O
face	B-Method
detectors	I-Method
proposed	O
to	O
achieve	O
promising	O
performances	O
,	O
by	O
adapting	O
general	O
object	B-Task
detection	I-Task
framework	O
into	O
face	B-Task
detection	I-Task
domain	I-Task
.	O
	
We	O
briefly	O
review	O
hard	B-Task
example	I-Task
mining	I-Task
,	O
face	B-Method
detection	I-Method
architecture	I-Method
,	O
and	O
anchor	B-Task
design	I-Task
&	I-Task
matching	I-Task
.	O
	
subsection	O
:	O
Hard	B-Task
example	I-Task
mining	I-Task
	
Hard	B-Method
example	I-Method
mining	I-Method
is	O
an	O
important	O
strategy	O
to	O
improve	O
model	B-Metric
quality	I-Metric
,	O
and	O
has	O
been	O
studied	O
extensively	O
in	O
image	B-Task
classification	I-Task
and	O
general	O
object	B-Task
detection	I-Task
.	O
	
The	O
main	O
idea	O
is	O
to	O
find	O
some	O
hard	O
positive	O
and	O
hard	O
negative	O
examples	O
at	O
each	O
step	O
,	O
and	O
put	O
more	O
effort	O
into	O
training	O
on	O
those	O
hard	O
examples	O
.	O
	
Recently	O
,	O
with	O
modern	O
detection	B-Method
frameworks	I-Method
proposed	O
to	O
boost	O
the	O
performance	O
,	O
OHEM	B-Method
and	O
Focal	O
loss	O
have	O
been	O
proposed	O
to	O
select	O
hard	O
examples	O
.	O
	
OHEM	B-Method
computed	O
the	O
gradients	O
of	O
the	O
networks	O
by	O
selecting	O
the	O
proposals	O
with	O
highest	O
losses	O
in	O
every	O
minibatch	O
;	O
while	O
Focal	O
loss	O
aimed	O
at	O
naturally	O
putting	O
more	O
focus	O
on	O
hard	O
and	O
misclassified	O
examples	O
by	O
adding	O
a	O
factor	O
to	O
the	O
standard	O
cross	B-Metric
entropy	I-Metric
criterion	I-Metric
.	O
	
However	O
,	O
these	O
algorithms	O
mainly	O
focused	O
on	O
anchor	B-Task
-	I-Task
level	I-Task
or	I-Task
proposal	I-Task
-	I-Task
level	I-Task
mining	I-Task
.	O
	
It	O
can	O
not	O
handle	O
the	O
imbalance	O
of	O
easy	O
and	O
hard	B-Material
images	I-Material
in	O
the	O
dataset	O
.	O
	
In	O
our	O
paper	O
,	O
we	O
propose	O
to	O
exploit	O
hard	B-Method
example	I-Method
mining	I-Method
on	O
image	B-Task
level	I-Task
,	O
hard	B-Task
image	I-Task
mining	I-Task
,	O
to	O
improve	O
the	O
quality	O
of	O
face	B-Task
detector	I-Task
on	O
extremely	O
hard	O
faces	O
.	O
	
More	O
specifically	O
,	O
we	O
assign	O
difficulty	O
scores	O
to	O
training	O
images	O
while	O
training	O
with	O
an	O
SGD	B-Method
mechanism	I-Method
,	O
and	O
re	O
-	O
sample	O
the	O
training	O
images	O
to	O
build	O
a	O
new	O
training	O
subset	O
at	O
the	O
next	O
epoch	O
.	O
	
subsection	O
:	O
Face	B-Method
Detection	I-Method
Architecture	I-Method
	
Recent	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
face	B-Method
detectors	I-Method
are	O
generally	O
built	O
based	O
on	O
Faster	B-Method
-	I-Method
RCNN	I-Method
,	O
R	B-Method
-	I-Method
FCN	I-Method
or	O
SSD	B-Method
.	O
	
SSH	B-Method
exploited	O
the	O
RPN	B-Method
(	I-Method
Region	I-Method
Proposal	I-Method
Network	I-Method
)	O
from	O
Faster	B-Method
-	I-Method
RCNN	I-Method
to	O
detect	O
faces	O
,	O
by	O
building	O
three	O
detection	B-Method
feature	I-Method
maps	I-Method
and	O
designing	O
six	O
anchors	O
with	O
different	O
sizes	O
attached	O
to	O
the	O
detection	O
feature	O
maps	O
.	O
	
S	B-Method
FD	I-Method
and	O
PyramidBox	B-Method
,	O
on	O
the	O
other	O
hand	O
,	O
adopted	O
SSD	B-Method
as	O
their	O
detection	B-Method
architecture	I-Method
with	O
six	O
different	O
detection	O
feature	O
maps	O
.	O
	
Different	O
from	O
S	B-Method
FD	I-Method
,	O
PyramidBox	B-Method
exploited	O
a	O
feature	O
pyramid	O
-	O
style	O
structure	O
to	O
combine	O
features	O
from	O
different	O
detection	O
feature	O
maps	O
.	O
	
Our	O
proposed	O
method	O
,	O
on	O
the	O
other	O
hand	O
,	O
only	O
builds	O
single	O
level	O
detection	O
feature	O
map	O
,	O
based	O
on	O
VGG16	B-Method
,	O
for	O
classification	B-Task
and	O
bounding	B-Task
-	I-Task
box	I-Task
regression	I-Task
,	O
which	O
is	O
both	O
simple	O
and	O
effective	O
.	O
	
subsection	O
:	O
Anchor	B-Method
design	I-Method
and	O
matching	B-Task
	
Usually	O
,	O
anchors	O
are	O
designed	O
to	O
have	O
different	O
sizes	O
to	O
detect	O
objects	O
with	O
different	O
scales	O
,	O
in	O
order	O
to	O
build	O
a	O
scale	B-Method
-	I-Method
invariant	I-Method
detector	I-Method
.	O
	
SSD	B-Method
as	O
well	O
as	O
its	O
follow	O
-	O
up	O
detectors	B-Method
S	I-Method
FD	I-Method
and	O
PyramidBox	B-Method
,	O
had	O
six	O
sets	O
of	O
anchors	O
with	O
different	O
sizes	O
,	O
ranging	O
from	O
(	O
)	O
to	O
(	O
)	O
,	O
and	O
their	O
network	B-Method
architectures	I-Method
had	O
six	O
levels	O
of	O
detection	B-Method
feature	I-Method
maps	I-Method
,	O
with	O
resolutions	O
ranging	O
from	O
to	O
,	O
respectively	O
.	O
	
Similarly	O
,	O
SSH	B-Method
had	O
the	O
same	O
anchor	O
setting	O
,	O
and	O
those	O
anchors	O
were	O
attached	O
to	O
three	O
levels	O
of	O
detection	O
feature	O
maps	O
with	O
resolutions	O
ranging	O
from	O
to	O
.	O
	
The	O
difference	O
between	O
SSH	B-Method
and	O
S	B-Method
DF	I-Method
is	O
that	O
in	O
SSH	B-Method
,	O
anchors	O
with	O
two	O
neighboring	O
sizes	O
shared	O
the	O
same	O
detection	O
feature	O
map	O
,	O
while	O
in	O
S	B-Method
DF	I-Method
,	O
anchors	O
with	O
different	O
sizes	O
are	O
attached	O
to	O
different	O
detection	O
feature	O
maps	O
.	O
	
SNIP	B-Method
discussed	O
an	O
alternative	O
approach	O
to	O
handle	O
scales	O
.	O
	
It	O
showed	O
that	O
CNNs	B-Method
are	O
not	O
robust	O
to	O
changes	O
in	O
scale	O
,	O
so	O
training	O
and	O
testing	O
on	O
the	O
same	O
scales	O
of	O
an	O
image	O
pyramid	O
can	O
be	O
a	O
more	O
optimal	O
strategy	O
.	O
	
In	O
our	O
paper	O
,	O
we	O
exploit	O
this	O
idea	O
by	O
limiting	O
the	O
anchor	O
sizes	O
to	O
be	O
(	O
)	O
,	O
(	O
)	O
and	O
(	O
)	O
.	O
	
Then	O
those	O
faces	O
with	O
either	O
too	O
small	O
or	O
too	O
big	O
sizes	O
will	O
not	O
be	O
matched	O
to	O
any	O
of	O
the	O
anchors	O
,	O
thus	O
will	O
be	O
ignored	O
during	O
the	O
training	O
and	O
testing	B-Task
.	O
	
By	O
removing	O
those	O
large	O
anchors	O
with	O
sizes	O
larger	O
than	O
(	O
)	O
,	O
our	O
network	O
focuses	O
more	O
on	O
small	O
faces	O
which	O
are	O
potentially	O
more	O
difficult	O
.	O
	
To	O
deal	O
with	O
large	O
faces	O
,	O
we	O
use	O
multiscale	B-Method
training	I-Method
and	O
testing	O
to	O
resize	O
them	O
to	O
match	O
our	O
anchors	O
.	O
	
Experiments	O
show	O
this	O
design	O
performs	O
well	O
on	O
both	O
small	O
and	O
big	O
faces	O
,	O
although	O
it	O
has	O
fewer	O
detection	O
feature	O
maps	O
and	O
anchor	O
sizes	O
.	O
	
section	O
:	O
Proposed	O
method	O
	
In	O
this	O
section	O
,	O
we	O
introduce	O
our	O
proposed	O
method	O
for	O
effective	B-Task
face	I-Task
detection	I-Task
.	O
	
We	O
first	O
discuss	O
the	O
architecture	O
of	O
our	O
detector	O
in	O
Section	O
[	O
reference	O
]	O
,	O
then	O
we	O
elaborate	O
our	O
hard	B-Method
image	I-Method
mining	I-Method
strategy	I-Method
in	O
Section	O
[	O
reference	O
]	O
,	O
as	O
well	O
as	O
some	O
other	O
useful	O
training	B-Method
techniques	I-Method
in	O
Section	O
[	O
reference	O
]	O
.	O
	
subsection	O
:	O
Single	B-Method
-	I-Method
level	I-Method
small	I-Method
face	I-Method
detection	I-Method
framework	I-Method
	
The	O
framework	O
of	O
our	O
face	B-Method
detector	I-Method
is	O
illustrated	O
in	O
Figure	O
[	O
reference	O
]	O
.	O
	
We	O
use	O
VGG16	B-Method
network	I-Method
as	O
our	O
backbone	B-Method
CNN	I-Method
,	O
and	O
combine	O
conv4_3	O
and	O
conv5_3	O
features	O
,	O
to	O
build	O
the	O
detection	B-Method
feature	I-Method
map	I-Method
with	O
both	O
low	O
-	O
level	O
and	O
high	O
-	O
level	O
semantic	O
information	O
.	O
	
Similar	O
to	O
SSH	B-Method
,	O
we	O
apply	O
1	O
1	B-Method
convolution	I-Method
layers	I-Method
after	O
conv4_3	B-Method
and	O
conv5_3	B-Method
to	O
reduce	O
dimension	O
,	O
and	O
then	O
apply	O
a	O
3	O
3	B-Method
convolution	I-Method
layer	I-Method
on	O
the	O
concatenation	O
of	O
these	O
two	O
dimension	O
reduced	O
features	O
.	O
	
The	O
output	O
feature	O
of	O
the	O
3	B-Method
3	I-Method
convolution	I-Method
layer	I-Method
is	O
the	O
final	O
detection	O
feature	O
map	O
,	O
which	O
will	O
be	O
fed	O
into	O
the	O
detection	B-Method
head	I-Method
for	O
classification	B-Task
and	O
bounding	B-Task
-	I-Task
box	I-Task
regression	I-Task
.	O
	
The	O
detection	B-Method
feature	I-Method
map	I-Method
has	O
a	O
resolution	O
of	O
of	O
the	O
original	O
image	O
(	O
of	O
size	O
)	O
.	O
	
We	O
attach	O
three	O
anchors	O
at	O
each	O
point	O
in	O
the	O
grid	O
as	O
default	O
face	O
detection	O
boxes	O
.	O
	
Then	O
we	O
do	O
classification	B-Method
and	O
bounding	B-Method
-	I-Method
box	I-Method
regression	I-Method
on	O
those	O
anchors	O
.	O
	
Unlike	O
many	O
other	O
face	B-Method
detectors	I-Method
which	O
build	O
multiple	O
feature	O
maps	O
to	O
detect	O
face	O
with	O
a	O
variant	O
range	O
of	O
scales	O
,	O
inspired	O
by	O
SNIP	B-Method
,	O
faces	O
are	O
trained	O
and	O
inferred	O
with	O
roughly	O
the	O
same	O
scales	O
.	O
	
We	O
only	O
have	O
one	O
detection	B-Method
feature	I-Method
map	I-Method
,	O
with	O
three	O
sets	O
of	O
anchors	O
attached	O
to	O
it	O
.	O
	
The	O
anchors	O
have	O
sizes	O
of	O
(	O
)	O
,	O
(	O
)	O
and	O
(	O
)	O
,	O
and	O
the	O
aspect	O
ratio	O
is	O
set	O
to	O
be	O
1	O
.	O
	
By	O
making	O
this	O
configuration	O
,	O
our	O
network	O
only	O
trains	O
and	O
infers	O
on	O
small	O
and	O
medium	O
size	O
of	O
faces	O
;	O
and	O
we	O
propose	O
to	O
handle	O
large	O
faces	O
by	O
shrinking	O
the	O
images	O
in	O
the	O
test	O
phase	O
.	O
	
We	O
argue	O
that	O
there	O
is	O
no	O
speed	O
or	O
accuracy	B-Metric
degradation	I-Metric
for	O
large	B-Task
faces	I-Task
,	O
since	O
inferring	O
on	O
a	O
tiny	O
image	O
(	O
with	O
short	O
side	O
containing	O
100	O
or	O
300	O
pixels	O
)	O
is	O
very	O
fast	O
,	O
and	O
the	O
shrinked	O
large	O
face	O
will	O
still	O
have	O
enough	O
information	O
to	O
be	O
recognized	O
.	O
	
To	O
handle	O
the	O
difference	O
of	O
anchor	O
sizes	O
attached	O
to	O
the	O
same	O
detection	O
feature	O
map	O
,	O
we	O
propose	O
a	O
detection	B-Method
head	I-Method
which	O
uses	O
different	O
dilation	O
rates	O
for	O
anchors	O
with	O
different	O
sizes	O
,	O
as	O
shown	O
in	O
Figure	O
[	O
reference	O
]	O
.	O
	
The	O
intuition	O
is	O
that	O
in	O
order	O
to	O
detect	O
faces	O
with	O
different	O
sizes	O
,	O
different	O
effective	O
receptive	O
fields	O
are	O
required	O
.	O
	
This	O
naturally	O
requires	O
the	O
backbone	O
feature	O
map	O
to	O
be	O
invariant	O
to	O
scales	O
.	O
	
To	O
this	O
end	O
,	O
we	O
adopt	O
different	O
dilation	O
rates	O
for	O
anchors	O
with	O
different	O
sizes	O
.	O
	
For	O
anchors	O
with	O
size	O
(	O
)	O
,	O
(	O
)	O
and	O
(	O
)	O
,	O
we	O
use	O
a	O
convolution	B-Method
with	O
kernel	O
size	O
of	O
and	O
dilation	O
rate	O
of	O
,	O
and	O
to	O
gather	O
context	O
features	O
at	O
different	O
scales	O
.	O
	
These	O
three	O
convolution	B-Method
layers	I-Method
share	O
weights	O
to	O
reduce	O
the	O
model	O
size	O
.	O
	
With	O
this	O
design	O
,	O
the	O
input	O
of	O
the	O
convolution	B-Method
,	O
will	O
be	O
aligned	O
to	O
the	O
same	O
location	O
of	O
faces	O
,	O
regardless	O
of	O
the	O
size	O
of	O
faces	O
and	O
anchors	O
.	O
	
Ablation	O
experiments	O
show	O
the	O
effectiveness	O
of	O
this	O
multi	B-Method
-	I-Method
dilation	I-Method
design	I-Method
.	O
	
subsection	O
:	O
Hard	B-Task
image	I-Task
mining	I-Task
	
Different	O
from	O
OHEM	B-Method
discussed	O
in	O
Section	O
[	O
reference	O
]	O
,	O
which	O
selects	O
proposals	O
or	O
anchors	O
with	O
the	O
highest	O
losses	O
,	O
we	O
propose	O
a	O
novel	O
hard	B-Method
image	I-Method
mining	I-Method
strategy	I-Method
at	O
image	O
level	O
.	O
	
The	O
intuition	O
is	O
that	O
most	O
images	O
in	O
the	O
dataset	O
are	O
very	O
easy	O
,	O
and	O
we	O
can	O
achieve	O
a	O
very	O
high	O
AP	B-Metric
even	O
on	O
the	O
hard	O
subset	O
of	O
the	O
WIDER	B-Material
FACE	I-Material
val	I-Material
dataset	I-Material
with	O
our	O
baseline	O
model	O
.	O
	
We	O
believe	O
not	O
all	O
training	O
images	O
should	O
be	O
treated	O
equally	O
,	O
and	O
well	O
-	O
recognized	O
images	O
will	O
not	O
help	O
towards	O
training	O
a	O
more	O
robust	O
face	B-Method
detector	I-Method
.	O
	
To	O
put	O
more	O
attention	O
on	O
training	O
hard	O
images	O
instead	O
of	O
easy	O
ones	O
,	O
we	O
use	O
a	O
subset	O
of	O
all	O
training	O
images	O
,	O
to	O
contain	O
hard	O
ones	O
for	O
training	O
.	O
	
At	O
the	O
beginning	O
of	O
each	O
epoch	O
,	O
we	O
build	O
based	O
on	O
the	O
difficulty	O
scores	O
obtained	O
in	O
the	O
previous	O
epoch	O
.	O
	
We	O
initially	O
use	O
all	O
training	O
images	O
to	O
train	O
our	O
model	O
(	O
)	O
.	O
	
This	O
is	O
due	O
to	O
the	O
fact	O
that	O
our	O
initial	O
ImageNet	B-Method
pre	I-Method
-	I-Method
trained	I-Method
model	I-Method
will	O
only	O
give	O
random	O
guess	O
towards	O
face	B-Task
detection	I-Task
.	O
	
In	O
this	O
case	O
,	O
there	O
is	O
no	O
easy	O
image	O
.	O
	
In	O
other	O
words	O
,	O
every	O
image	O
is	O
considered	O
as	O
hard	O
image	O
and	O
fed	O
to	O
the	O
network	O
for	O
training	O
at	O
the	O
first	O
epoch	O
.	O
	
During	O
the	O
training	O
procedure	O
,	O
we	O
dynamically	O
assign	O
different	O
difficulty	O
scores	O
to	O
training	O
images	O
,	O
which	O
is	O
defined	O
by	O
the	O
metric	B-Metric
Worst	I-Metric
Positive	I-Metric
Anchor	I-Metric
Score	I-Metric
(	O
WPAS	B-Metric
)	O
:	O
where	O
is	O
the	O
set	O
of	O
positive	O
anchors	O
for	O
image	O
,	O
with	O
IoU	O
over	O
0.5	O
against	O
ground	O
-	O
truth	O
boxes	O
,	O
is	O
the	O
classification	O
logit	O
and	O
,	O
are	O
the	O
logits	O
of	O
anchor	O
for	O
image	O
to	O
be	O
foreground	O
face	O
and	O
background	O
.	O
	
All	O
images	O
are	O
initially	O
marked	O
as	O
hard	O
,	O
and	O
any	O
image	O
with	O
WPAS	B-Metric
greater	O
than	O
a	O
threshold	O
will	O
be	O
marked	O
as	O
easy	O
image	O
.	O
	
At	O
the	O
beginning	O
of	O
each	O
epoch	O
,	O
we	O
first	O
randomly	O
shuffle	O
the	O
training	O
dataset	O
to	O
generate	O
the	O
complete	O
training	O
list	O
for	O
the	O
following	O
epoch	O
of	O
training	O
.	O
	
Then	O
given	O
an	O
image	O
marked	O
as	O
easy	O
,	O
we	O
remove	O
it	O
from	O
with	O
a	O
probability	O
of	O
.	O
	
The	O
remaining	O
training	O
list	O
,	O
which	O
focuses	O
more	O
on	O
hard	B-Material
images	I-Material
,	O
will	O
be	O
used	O
for	O
training	O
at	O
this	O
epoch	O
.	O
	
Note	O
that	O
for	O
multi	B-Task
-	I-Task
GPU	I-Task
training	I-Task
,	O
each	O
GPU	O
will	O
maintain	O
its	O
training	O
list	O
independently	O
.	O
	
In	O
our	O
experiments	O
,	O
we	O
set	O
the	O
probability	O
to	O
be	O
0.7	O
,	O
and	O
the	O
threshold	O
to	O
be	O
0.85	O
.	O
	
subsection	O
:	O
Training	O
strategy	O
	
subsubsection	O
:	O
Multi	B-Task
-	I-Task
scale	I-Task
training	I-Task
and	O
anchor	B-Task
matching	I-Task
	
Since	O
we	O
only	O
have	O
anchors	O
covering	O
a	O
limited	O
range	O
of	O
face	O
scales	O
,	O
we	O
train	O
our	O
model	O
by	O
varying	O
the	O
sizes	O
of	O
training	O
images	O
.	O
	
During	O
the	O
training	O
phase	O
,	O
we	O
resize	O
the	O
training	O
images	O
so	O
that	O
the	O
short	O
side	O
of	O
the	O
image	O
contains	O
pixels	O
,	O
where	O
is	O
randomly	O
selected	O
from	O
.	O
	
We	O
also	O
set	O
an	O
upper	O
bound	O
of	O
2000	O
pixels	O
to	O
the	O
long	O
side	O
of	O
the	O
image	O
considering	O
the	O
GPU	O
memory	O
limitation	O
.	O
	
For	O
each	O
anchor	O
,	O
we	O
assign	O
a	O
label	O
based	O
on	O
how	O
well	O
it	O
matches	O
with	O
any	O
ground	O
-	O
truth	O
face	O
bounding	O
box	O
.	O
	
If	O
an	O
anchor	O
has	O
an	O
IoU	O
(	O
Intersection	O
over	O
Union	O
)	O
over	O
0.5	O
against	O
a	O
ground	O
-	O
truth	O
face	O
bounding	O
box	O
,	O
we	O
assign	O
to	O
that	O
anchor	O
.	O
	
On	O
the	O
other	O
hand	O
,	O
if	O
the	O
IoU	O
against	O
any	O
ground	O
-	O
truth	O
face	O
bounding	O
box	O
is	O
lower	O
than	O
0.3	O
,	O
we	O
assign	O
to	O
that	O
anchor	O
.	O
	
All	O
other	O
anchors	O
will	O
be	O
given	O
as	O
the	O
label	O
,	O
and	O
thus	O
will	O
be	O
ignored	O
in	O
the	O
classification	B-Metric
loss	I-Metric
.	O
	
By	O
doing	O
so	O
,	O
we	O
only	O
train	O
on	O
faces	O
with	O
designated	O
scales	O
.	O
	
Those	O
faces	O
with	O
no	O
anchor	O
matching	O
will	O
be	O
simply	O
ignored	O
,	O
since	O
we	O
do	O
not	O
assign	O
the	O
anchor	O
with	O
largest	O
IoU	O
to	O
it	O
(	O
thus	O
assign	O
the	O
corresponding	O
anchor	O
label	O
)	O
as	O
Faster	O
-	O
RCNN	B-Method
does	O
.	O
	
This	O
anchor	B-Method
matching	I-Method
strategy	I-Method
will	O
ignore	O
the	O
large	O
faces	O
,	O
and	O
our	O
model	O
can	O
put	O
more	O
capacity	O
on	O
learning	O
different	O
face	O
patterns	O
on	O
hard	O
small	O
faces	O
instead	O
of	O
memorizing	O
the	O
change	O
in	O
scales	O
.	O
	
For	O
the	O
regression	B-Task
loss	I-Task
,	O
all	O
anchors	O
with	O
IoU	O
greater	O
than	O
0.3	O
against	O
ground	O
-	O
truth	O
faces	O
will	O
be	O
taken	O
into	O
account	O
and	O
contribute	O
to	O
the	O
smooth	B-Metric
loss	I-Metric
.	O
	
We	O
use	O
a	O
smaller	O
threshold	O
(	O
0.3	O
)	O
because	O
(	O
1	O
)	O
this	O
will	O
allow	O
imperfectly	O
matched	O
anchors	O
to	O
be	O
able	O
to	O
localize	O
the	O
face	O
,	O
which	O
may	O
be	O
useful	O
during	O
the	O
testing	O
and	O
(	O
2	O
)	O
the	O
regression	B-Task
task	I-Task
has	O
less	O
supervision	O
since	O
unlike	O
classification	B-Task
,	O
there	O
are	O
no	O
negative	O
anchors	O
for	O
computing	O
loss	O
and	O
the	O
positive	O
anchors	O
are	O
usually	O
sparse	O
.	O
	
subsubsection	O
:	O
Anchor	O
-	O
level	O
hard	O
example	B-Method
mining	I-Method
	
OHEM	B-Method
has	O
been	O
proven	O
to	O
be	O
useful	O
for	O
object	B-Task
detection	I-Task
and	O
face	B-Task
detection	I-Task
in	O
.	O
	
During	O
our	O
training	O
,	O
in	O
parallel	O
with	O
our	O
newly	O
proposed	O
hard	B-Task
image	I-Task
mining	I-Task
,	O
we	O
also	O
exploit	O
the	O
traditional	O
hard	B-Method
anchor	I-Method
mining	I-Method
method	I-Method
to	O
focus	O
more	O
on	O
the	O
hard	O
and	O
misclassificed	O
anchors	O
.	O
	
Given	O
a	O
training	O
image	O
with	O
size	O
,	O
there	O
are	O
anchors	O
at	O
the	O
detection	O
head	O
,	O
and	O
we	O
only	O
select	O
256	O
of	O
them	O
to	O
be	O
involved	O
in	O
computing	O
the	O
classification	B-Task
loss	I-Task
.	O
	
For	O
all	O
positive	O
anchors	O
with	O
IoU	O
greater	O
than	O
against	O
ground	O
-	O
truth	O
boxes	O
,	O
we	O
select	O
the	O
top	O
64	O
of	O
them	O
with	O
lowest	O
confidences	O
to	O
be	O
recognized	O
as	O
face	O
.	O
	
After	O
selecting	O
positive	O
anchors	O
,	O
(	O
)	O
negative	O
anchors	O
with	O
highest	O
face	O
confidence	O
are	O
selected	O
to	O
compute	O
the	O
classification	B-Metric
loss	I-Metric
as	O
the	O
hard	O
negative	O
anchors	O
.	O
	
Note	O
that	O
we	O
only	O
perform	O
OHEM	B-Method
for	O
classification	B-Task
loss	I-Task
,	O
and	O
we	O
keep	O
all	O
anchors	O
with	O
IoU	O
greater	O
than	O
0.3	O
for	O
computing	O
regression	B-Task
loss	I-Task
,	O
without	O
selecting	O
a	O
subset	O
based	O
on	O
either	O
classification	B-Method
loss	I-Method
or	O
bounding	B-Method
-	I-Method
box	I-Method
regression	I-Method
loss	I-Method
.	O
	
subsubsection	O
:	O
Data	B-Task
augmentation	I-Task
	
Data	B-Task
augmentation	I-Task
is	O
extremely	O
useful	O
to	O
make	O
the	O
model	O
robust	O
to	O
light	O
,	O
scale	O
changes	O
and	O
small	O
shifts	O
.	O
	
In	O
our	O
proposed	O
method	O
,	O
we	O
exploit	O
cropping	O
and	O
photometric	O
distortion	O
as	O
data	B-Task
augmentation	I-Task
.	O
	
Given	O
a	O
training	O
image	O
after	O
resizing	O
,	O
we	O
crop	O
a	O
patch	O
of	O
it	O
with	O
a	O
probability	O
of	O
.	O
	
The	O
patch	O
has	O
a	O
height	O
of	O
and	O
a	O
width	O
of	O
which	O
are	O
independently	O
drawn	O
from	O
and	O
,	O
where	O
is	O
the	O
uniform	O
distribution	O
and	O
,	O
are	O
the	O
height	O
and	O
width	O
of	O
the	O
resized	O
training	O
image	O
.	O
	
All	O
ground	O
-	O
truth	O
boxes	O
whose	O
centers	O
are	O
located	O
inside	O
the	O
patch	O
are	O
kept	O
.	O
	
After	O
the	O
random	B-Task
cropping	I-Task
,	O
we	O
apply	O
photometric	B-Method
distortion	I-Method
following	O
SSD	B-Method
by	O
randomly	O
modifying	O
the	O
brightness	O
,	O
contrast	O
,	O
saturation	O
and	O
hue	O
of	O
the	O
cropped	O
image	O
randomly	O
.	O
	
[	O
b	O
]	O
0.33	O
easy	O
subset	O
[	O
b	O
]	O
0.33	O
medium	O
subset	O
[	O
b	O
]	O
0.33	O
hard	O
subset	O
	
[	O
b	O
]	O
0.33	O
	
[	O
b	O
]	O
0.33	O
	
[	O
b	O
]	O
0.33	O
	
section	O
:	O
Experiments	O
	
To	O
verify	O
the	O
effectiveness	O
of	O
our	O
model	O
and	O
proposed	O
method	O
,	O
we	O
conduct	O
extensive	O
experiments	O
on	O
popular	O
face	O
detection	O
datasets	O
,	O
including	O
WIDER	B-Material
FACE	I-Material
,	O
FDDB	B-Material
,	O
Pascal	B-Material
Faces	I-Material
and	O
AFW	B-Material
.	O
	
It	O
is	O
worth	O
noting	O
that	O
the	O
training	O
is	O
only	O
performed	O
on	O
the	O
train	O
set	O
of	O
WIDER	B-Material
FACE	I-Material
,	O
and	O
we	O
use	O
the	O
same	O
model	O
for	O
evaluation	O
on	O
all	O
these	O
datasets	O
without	O
further	O
fine	B-Task
-	I-Task
tuning	I-Task
.	O
	
subsection	O
:	O
Experimental	O
settings	O
	
We	O
train	O
our	O
model	O
on	O
the	O
train	O
set	O
of	O
WIDER	B-Material
FACE	I-Material
,	O
which	O
has	O
12880	O
images	O
with	O
159k	O
faces	O
annotated	O
.	O
	
We	O
flip	O
all	O
images	O
horizontally	O
,	O
to	O
double	O
the	O
size	O
of	O
our	O
training	O
dataset	O
to	O
25760	O
.	O
	
For	O
each	O
training	O
image	O
,	O
we	O
first	O
randomly	O
resize	O
it	O
,	O
and	O
then	O
we	O
use	O
the	O
cropping	B-Method
and	I-Method
photometric	I-Method
distortion	I-Method
data	I-Method
augmentation	I-Method
methods	I-Method
discussed	O
in	O
Section	O
[	O
reference	O
]	O
to	O
pre	O
-	O
process	O
the	O
resized	O
image	O
.	O
	
We	O
use	O
an	O
ImageNet	B-Method
pre	I-Method
-	I-Method
trained	I-Method
VGG16	I-Method
model	I-Method
to	O
initialize	O
our	O
network	B-Method
backbone	I-Method
,	O
and	O
our	O
newly	O
introduced	O
layers	O
are	O
randomly	O
initialized	O
with	O
Gaussian	B-Method
initialization	I-Method
.	O
	
We	O
train	O
the	O
model	O
with	O
the	O
itersize	O
to	O
be	O
2	O
,	O
for	O
46k	O
iterations	O
,	O
with	O
a	O
learning	B-Metric
rate	I-Metric
of	O
,	O
and	O
then	O
for	O
another	O
14k	O
iterations	O
with	O
a	O
smaller	O
learning	B-Metric
rate	I-Metric
of	O
.	O
	
During	O
training	B-Task
,	O
we	O
use	O
4	O
GPUs	O
to	O
simultaneously	O
to	O
compute	O
the	O
gradient	O
and	O
update	O
the	O
weight	O
by	O
synchronized	B-Method
SGD	I-Method
with	O
Momentum	B-Method
.	O
	
The	O
first	O
two	O
blocks	O
of	O
VGG16	B-Method
are	O
frozen	O
during	O
the	O
training	O
,	O
and	O
the	O
rest	O
layers	O
of	O
VGG16	B-Method
are	O
set	O
to	O
have	O
a	O
double	O
learning	B-Metric
rate	I-Metric
.	O
	
Since	O
our	O
model	O
is	O
designed	O
and	O
trained	O
on	O
only	O
small	O
faces	O
,	O
we	O
use	O
a	O
multiscale	O
image	O
pyramid	O
for	O
testing	O
to	O
deal	O
with	O
faces	O
larger	O
than	O
our	O
anchors	O
.	O
	
Specifically	O
,	O
we	O
resize	O
the	O
testing	O
image	O
so	O
that	O
the	O
short	O
side	O
contains	O
100	O
,	O
300	O
,	O
600	O
,	O
1000	O
and	O
1400	O
pixels	O
for	O
evaluation	O
on	O
WIDER	B-Material
FACE	I-Material
dataset	I-Material
.	O
	
We	O
also	O
follow	O
the	O
testing	B-Method
strategies	I-Method
used	O
in	O
PyramidBox	B-Method
such	O
as	O
horizontal	O
flip	O
and	O
bounding	B-Method
-	I-Method
box	I-Method
voting	I-Method
.	O
	
subsection	O
:	O
Experiment	O
results	O
	
WIDER	B-Material
FACE	I-Material
dataset	I-Material
includes	O
3226	O
images	O
and	O
39708	O
faces	O
labelled	O
in	O
the	O
val	O
dataset	O
,	O
with	O
three	O
subsets	O
–	O
easy	O
,	O
medium	O
and	O
hard	O
.	O
	
In	O
Figure	O
[	O
reference	O
]	O
,	O
we	O
show	O
the	O
precision	B-Metric
-	I-Metric
recall	I-Metric
(	O
PR	B-Metric
)	O
curve	O
and	O
average	B-Metric
precision	I-Metric
(	O
AP	B-Metric
)	O
for	O
our	O
model	O
compared	O
with	O
many	O
other	O
state	O
-	O
of	O
-	O
the	O
-	O
arts	O
on	O
these	O
three	O
subsets	O
.	O
	
As	O
we	O
can	O
see	O
,	O
our	O
method	O
achieves	O
the	O
best	O
performance	O
on	O
the	O
hard	O
subset	O
,	O
and	O
outperforms	O
the	O
current	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
by	O
a	O
large	O
margin	O
.	O
	
Since	O
the	O
hard	B-Material
set	I-Material
is	O
a	O
super	O
set	O
of	O
small	O
and	O
medium	O
,	O
which	O
contains	O
all	O
faces	O
taller	O
than	O
10	O
pixels	O
,	O
the	O
performance	O
on	O
hard	O
set	O
can	O
represent	O
the	O
performance	O
on	O
the	O
full	O
testing	O
dataset	O
more	O
accurately	O
.	O
	
Our	O
performance	O
on	O
the	O
medium	O
subset	O
is	O
comparable	O
to	O
the	O
most	O
recent	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
and	O
the	O
performance	O
on	O
the	O
easy	O
subset	O
is	O
a	O
bit	O
worse	O
since	O
our	O
method	O
focuses	O
on	O
learning	B-Task
hard	I-Task
faces	I-Task
,	O
and	O
the	O
architecture	O
of	O
our	O
model	O
is	O
simpler	O
compared	O
with	O
other	O
state	O
-	O
of	O
-	O
the	O
-	O
arts	O
.	O
	
There	O
is	O
also	O
a	O
WIDER	B-Material
FACE	I-Material
test	I-Material
dataset	I-Material
with	O
no	O
annotations	O
provided	O
publicly	O
.	O
	
It	O
contains	O
16097	O
images	O
,	O
and	O
is	O
evaluated	O
by	O
WIDER	B-Material
FACE	I-Material
author	I-Material
team	I-Material
.	O
	
We	O
report	O
the	O
performance	O
of	O
our	O
method	O
at	O
Figure	O
[	O
reference	O
]	O
for	O
the	O
hard	O
subset	O
.	O
	
FDDB	B-Material
dataset	O
includes	O
5171	O
faces	O
on	O
a	O
set	O
of	O
2845	O
images	O
,	O
and	O
we	O
use	O
our	O
model	O
trained	O
on	O
WIDER	B-Material
FACE	I-Material
train	I-Material
set	I-Material
to	O
infer	O
on	O
the	O
FDDB	B-Material
dataset	O
.	O
	
We	O
use	O
the	O
raw	O
bounding	O
-	O
box	O
result	O
without	O
fitting	O
it	O
into	O
ellipse	O
to	O
compute	O
ROC	O
.	O
	
We	O
show	O
the	O
discontinuous	O
ROC	O
curve	O
at	O
Figure	O
[	O
reference	O
]	O
compared	O
with	O
,	O
and	O
our	O
method	O
achieves	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
performance	O
of	O
TPR=98.7	B-Metric
%	O
given	O
1000	O
false	B-Metric
positives	I-Metric
.	O
	
Pascal	B-Material
Faces	I-Material
dataset	O
includes	O
1335	O
labeled	O
faces	O
on	O
a	O
set	O
of	O
851	O
images	O
extracted	O
for	O
the	O
Pascal	B-Material
VOC	I-Material
dataset	I-Material
.	O
	
We	O
show	O
the	O
PR	B-Metric
curve	O
at	O
Figure	O
[	O
reference	O
]	O
compared	O
with	O
,	O
and	O
our	O
method	O
achieves	O
a	O
new	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
performance	O
of	O
AP=99.0	B-Metric
.	O
	
AFW	B-Material
dataset	I-Material
includes	O
473	O
faces	O
labelled	O
in	O
a	O
set	O
of	O
205	O
images	O
.	O
	
As	O
shown	O
in	O
Figure	O
[	O
reference	O
]	O
compared	O
with	O
,	O
our	O
method	O
achieves	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
and	O
almost	O
perfect	O
performance	O
,	O
with	O
an	O
AP	B-Metric
of	O
99.60	O
.	O
	
subsection	O
:	O
Ablation	B-Task
study	I-Task
and	O
diagnosis	B-Task
	
subsubsection	O
:	O
Ablation	B-Task
experiments	O
	
In	O
order	O
to	O
verify	O
the	O
performance	O
of	O
our	O
single	B-Method
level	I-Method
face	I-Method
detector	I-Method
,	O
as	O
well	O
as	O
the	O
effectiveness	O
of	O
our	O
proposed	O
hard	B-Method
image	I-Method
mining	I-Method
,	O
the	O
dilated	B-Method
-	I-Method
head	I-Method
classification	I-Method
and	O
regression	B-Method
structure	I-Method
,	O
we	O
conduct	O
various	O
ablation	O
experiments	O
on	O
the	O
WIDER	B-Material
FACE	I-Material
val	I-Material
dataset	I-Material
.	O
	
All	O
results	O
are	O
summarized	O
in	O
Table	O
[	O
reference	O
]	O
.	O
	
From	O
Table	O
[	O
reference	O
]	O
,	O
we	O
can	O
see	O
that	O
our	O
single	B-Method
level	I-Method
baseline	I-Method
model	I-Method
can	O
achieve	O
performance	O
comparable	O
to	O
the	O
current	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
face	B-Method
detector	I-Method
,	O
especially	O
on	O
the	O
hard	B-Material
subset	I-Material
.	O
	
Our	O
model	O
with	O
single	B-Method
detection	I-Method
feature	I-Method
map	I-Method
performs	O
better	O
than	O
the	O
one	O
with	O
three	O
detection	B-Method
feature	I-Method
maps	I-Method
,	O
despite	O
its	O
shallower	O
structure	O
,	O
fewer	O
parameters	O
and	O
anchors	O
.	O
	
This	O
confirms	O
the	O
effectiveness	O
of	O
our	O
simple	O
face	B-Method
detector	I-Method
with	O
single	B-Method
detection	I-Method
feature	I-Method
map	I-Method
focusing	O
on	O
small	O
faces	O
.	O
	
We	O
also	O
separately	O
verify	O
our	O
newly	O
proposed	O
hard	B-Method
image	I-Method
mining	I-Method
(	I-Method
HIM	I-Method
)	I-Method
and	O
dilated	B-Method
head	I-Method
architecture	I-Method
(	O
DH	B-Method
)	O
described	O
in	O
Subsection	O
[	O
reference	O
]	O
and	O
Figure	O
[	O
reference	O
]	O
respectively	O
.	O
	
HIM	B-Method
can	O
improve	O
the	O
performance	O
on	O
hard	O
subset	O
significantly	O
without	O
involving	O
more	O
complex	O
network	O
architecture	O
nor	O
computation	B-Metric
overhead	I-Metric
.	O
	
DH	B-Method
itself	O
can	O
also	O
boost	O
the	O
performance	O
,	O
which	O
shows	O
the	O
effectiveness	O
of	O
designing	O
larger	O
convolution	B-Method
for	O
larger	O
anchors	O
.	O
	
Combining	O
HIM	B-Method
and	O
DH	B-Method
together	O
can	O
improve	O
further	O
towards	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
performance	O
.	O
	
subsubsection	O
:	O
Diagnosis	O
of	O
hard	B-Task
image	I-Task
mining	I-Task
	
We	O
investigate	O
the	O
effects	O
of	O
our	O
hard	B-Method
image	I-Method
mining	I-Method
mechanism	I-Method
.	O
	
We	O
show	O
the	O
ratio	O
of	O
and	O
(	O
the	O
ratio	O
of	O
the	O
number	O
of	O
selected	O
training	O
images	O
to	O
the	O
number	O
of	O
ignored	O
training	O
images	O
)	O
in	O
Figure	O
[	O
reference	O
]	O
for	O
each	O
epoch	O
.	O
	
We	O
can	O
see	O
that	O
at	O
the	O
first	O
epoch	O
,	O
all	O
training	O
images	O
are	O
used	O
to	O
train	O
the	O
model	O
.	O
	
Meanwhile	O
,	O
as	O
the	O
training	O
process	O
continues	O
,	O
more	O
and	O
more	O
training	O
images	O
will	O
be	O
ignored	O
.	O
	
At	O
the	O
last	O
epoch	O
,	O
over	O
a	O
half	O
images	O
will	O
be	O
ignored	O
and	O
thus	O
will	O
not	O
be	O
included	O
in	O
.	O
	
subsubsection	O
:	O
Diagnosis	O
of	O
data	B-Task
augmentation	I-Task
	
We	O
investigate	O
the	O
effectiveness	O
of	O
the	O
photometric	O
distortion	O
as	O
well	O
as	O
the	O
cropping	B-Method
mechanisms	I-Method
as	O
discussed	O
in	O
Subsection	O
[	O
reference	O
]	O
.	O
	
The	O
ablation	O
results	O
evaluated	O
on	O
WIDER	B-Material
FACE	I-Material
val	I-Material
dataset	I-Material
are	O
shown	O
in	O
Table	O
[	O
reference	O
]	O
.	O
	
Both	O
photometric	O
distortion	O
and	O
cropping	B-Method
can	O
contribute	O
to	O
a	O
more	O
robust	O
face	B-Task
detector	I-Task
.	O
	
subsubsection	O
:	O
Diagnosis	O
of	O
multi	B-Task
-	I-Task
scale	I-Task
testing	I-Task
	
Our	O
face	B-Method
detector	I-Method
with	O
one	O
detection	B-Method
feature	I-Method
map	I-Method
is	O
design	O
for	O
small	B-Task
face	I-Task
detection	I-Task
,	O
and	O
our	O
anchors	B-Method
are	O
only	O
capable	O
of	O
capturing	O
faces	O
with	O
sizes	O
ranging	O
from	O
(	O
)	O
to	O
(	O
)	O
.	O
	
As	O
a	O
result	O
,	O
it	O
is	O
critical	O
to	O
adopt	O
multi	B-Task
-	I-Task
scale	I-Task
testing	I-Task
to	O
deal	O
with	O
large	O
faces	O
.	O
	
Different	O
from	O
SSH	B-Method
,	O
S	B-Method
FD	I-Method
and	O
PyramidBox	B-Method
,	O
our	O
testing	O
pyramid	B-Method
includes	O
some	O
extreme	O
small	O
scales	O
(	O
short	O
side	O
contains	O
only	O
100	O
or	O
300	O
pixels	O
)	O
.	O
	
In	O
Table	O
[	O
reference	O
]	O
,	O
we	O
show	O
the	O
effectiveness	O
of	O
these	O
extreme	O
small	O
scales	O
to	O
deal	O
with	O
easy	O
and	O
large	O
images	O
.	O
	
Our	O
full	O
evaluation	O
resizes	O
the	O
image	O
so	O
that	O
the	O
short	O
side	O
contains	O
100	O
,	O
300	O
,	O
600	O
,	O
1000	O
and	O
1400	O
pixels	O
respectively	O
,	O
to	O
build	O
an	O
image	O
pyramid	O
.	O
	
We	O
diagnose	O
the	O
impact	O
of	O
the	O
extra	O
small	O
scales	O
(	O
100	O
and	O
300	O
)	O
by	O
removing	O
them	O
from	O
the	O
image	O
pyramid	O
.	O
	
As	O
shown	O
in	O
Table	O
[	O
reference	O
]	O
,	O
the	O
extra	O
small	O
scales	O
are	O
crucial	O
to	O
detect	O
easy	O
faces	O
.	O
	
Without	O
resizing	O
the	O
short	O
side	O
to	O
contain	O
100	O
and	O
300	O
pixels	O
,	O
the	O
performance	O
on	O
easy	O
subset	O
is	O
only	O
,	O
which	O
is	O
even	O
lower	O
than	O
the	O
performance	O
on	O
medium	O
and	O
hard	O
which	O
contain	O
much	O
harder	O
faces	O
.	O
	
We	O
will	O
show	O
in	O
the	O
next	O
subsection	O
that	O
these	O
extra	O
small	O
scales	O
(	O
and	O
)	O
lead	O
to	O
negligible	O
computation	B-Metric
overhead	I-Metric
,	O
due	O
to	O
the	O
lower	O
resolution	O
.	O
	
subsubsection	O
:	O
Diagnosis	O
of	O
accuracy	B-Metric
/	I-Metric
speed	I-Metric
trade	I-Metric
-	I-Metric
off	I-Metric
	
We	O
evaluate	O
the	O
speed	O
of	O
our	O
method	O
as	O
well	O
as	O
some	O
other	O
popular	O
face	B-Method
detectors	I-Method
in	O
Table	O
[	O
reference	O
]	O
.	O
	
For	O
fair	O
comparison	O
,	O
we	O
run	O
all	O
methods	O
on	O
the	O
same	O
machine	O
,	O
with	O
one	O
Titan	O
X	O
(	O
Maxwell	O
)	O
GPU	O
,	O
and	O
Intel	O
Core	O
i7	O
-	O
4770	O
K	O
3.50GHz	O
.	O
	
All	O
methods	O
except	O
for	O
PyramidBox	B-Method
are	O
based	O
on	O
Caffe1	B-Method
implementation	I-Method
,	O
which	O
is	O
compiled	O
with	O
CUDA	O
9.0	O
and	O
CUDNN	B-Method
7	I-Method
.	O
	
For	O
PyramidBox	B-Task
,	O
we	O
follow	O
the	O
official	O
fluid	B-Method
code	I-Method
and	O
the	O
default	O
configurations	O
.	O
	
We	O
use	O
the	O
officially	O
built	O
PaddlePaddle	B-Method
with	O
CUDA	B-Method
9.0	I-Method
and	O
CUDNN	B-Method
7	I-Method
.	O
	
For	O
SSH	B-Method
,	O
S	B-Method
FD	I-Method
and	O
Pyramid	B-Method
,	O
we	O
use	O
the	O
official	B-Method
inference	I-Method
code	I-Method
and	O
configurations	O
.	O
	
For	O
SSH	B-Method
,	O
we	O
use	O
multi	B-Method
-	I-Method
scale	I-Method
testing	I-Method
with	O
the	O
short	O
side	O
containing	O
500	O
,	O
800	O
,	O
1200	O
and	O
1600	O
pixels	O
,	O
and	O
for	O
S	B-Method
FD	I-Method
,	O
we	O
execute	O
the	O
official	O
evaluation	O
code	O
with	O
both	O
multi	B-Method
-	I-Method
scale	I-Method
testing	I-Method
and	O
horizontal	O
flip	O
.	O
	
PyramidBox	B-Method
takes	O
a	O
similar	O
testing	O
configuration	O
as	O
S	O
FD	O
.	O
	
As	O
shown	O
in	O
Table	O
[	O
reference	O
]	O
,	O
our	O
detector	O
can	O
outperform	O
SSH	B-Method
,	O
S	B-Method
FD	I-Method
and	O
PyramidBox	B-Method
significantly	O
with	O
a	O
smaller	O
inference	B-Metric
time	I-Metric
.	O
	
Based	O
on	O
that	O
,	O
using	O
horizontal	O
flip	O
can	O
further	O
improve	O
the	O
performance	O
slightly	O
.	O
	
In	O
terms	O
of	O
GPU	B-Metric
memory	I-Metric
usage	I-Metric
,	O
our	O
method	O
uses	O
only	O
a	O
half	O
of	O
what	O
PyramidBox	O
occupies	O
,	O
while	O
achieving	O
better	O
performance	O
.	O
	
Ours	O
in	O
Table	O
[	O
reference	O
]	O
indicates	O
our	O
method	O
without	O
extra	O
small	O
scales	O
in	O
inference	B-Task
,	O
,	O
evaluated	O
with	O
scales	O
[	O
600	O
,	O
1000	O
,	O
1400	O
]	O
.	O
	
It	O
is	O
only	O
faster	O
than	O
evaluation	O
with	O
[	O
100	O
,	O
300	O
,	O
600	O
,	O
1000	O
,	O
1400	O
]	O
	
(	O
1.59	O
compared	O
with	O
1.70	O
)	O
.	O
	
This	O
proves	O
that	O
although	O
our	O
face	B-Method
detector	I-Method
is	O
only	O
trained	O
on	O
small	O
faces	O
,	O
it	O
can	O
perform	O
well	O
on	O
large	O
faces	O
,	O
by	O
simply	O
shrinking	O
the	O
testing	O
image	O
with	O
negligible	O
computation	B-Metric
overhead	I-Metric
.	O
	
section	O
:	O
Conclusion	O
	
To	O
conclude	O
,	O
we	O
propose	O
a	O
novel	O
face	B-Method
detector	I-Method
to	O
focus	O
on	O
learning	O
small	B-Task
faces	I-Task
on	O
hard	B-Material
images	I-Material
,	O
which	O
achieves	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
performance	O
on	O
all	O
popular	O
face	O
detection	O
datasets	O
.	O
	
We	O
propose	O
a	O
hard	B-Method
image	I-Method
mining	I-Method
strategy	I-Method
by	O
dynamically	O
assigning	O
difficulty	O
scores	O
to	O
training	O
images	O
,	O
and	O
re	O
-	O
sampling	O
subsets	O
with	O
hard	O
images	O
for	O
training	O
before	O
each	O
epoch	O
.	O
	
We	O
also	O
design	O
a	O
single	B-Method
shot	I-Method
face	I-Method
detector	I-Method
with	O
only	O
one	O
detection	B-Method
feature	I-Method
map	I-Method
,	O
to	O
train	O
and	O
test	O
on	O
small	O
faces	O
.	O
	
With	O
these	O
designs	O
,	O
our	O
model	O
can	O
put	O
more	O
attention	O
on	O
learning	B-Task
small	I-Task
hard	I-Task
faces	I-Task
instead	O
of	O
memorizing	O
change	O
of	O
scales	O
.	O
	
Extensive	O
experiments	O
and	O
ablations	O
have	O
been	O
done	O
to	O
show	O
the	O
effectiveness	O
of	O
our	O
method	O
,	O
and	O
our	O
face	B-Method
detector	I-Method
achieves	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
performance	O
on	O
all	O
popular	O
face	O
detection	O
datasets	O
,	O
including	O
WIDER	B-Material
FACE	I-Material
,	O
FDDB	B-Material
,	O
Pascal	B-Material
Faces	I-Material
and	O
AFW	B-Material
.	O
	
Our	O
face	B-Method
detector	I-Method
also	O
enjoys	O
faster	O
multi	B-Metric
-	I-Metric
scale	I-Metric
inference	I-Metric
speed	I-Metric
and	O
less	O
GPU	B-Metric
memory	I-Metric
usage	I-Metric
.	O
	
Our	O
proposed	O
method	O
are	O
flexible	O
and	O
can	O
be	O
applied	O
to	O
other	O
backbones	O
and	O
tasks	O
,	O
which	O
we	O
remain	O
as	O
future	O
work	O
.	O
	
bibliography	O
:	O
References	O
	
Convolutional	B-Method
Pose	I-Method
Machines	I-Method
	
section	O
:	O
Abstract	O
	
Pose	B-Method
Machines	I-Method
provide	O
a	O
sequential	B-Method
prediction	I-Method
framework	I-Method
for	O
learning	O
rich	O
implicit	B-Method
spatial	I-Method
models	I-Method
.	O
	
In	O
this	O
work	O
we	O
show	O
a	O
systematic	O
design	O
for	O
how	O
convolutional	B-Method
networks	I-Method
can	O
be	O
incorporated	O
into	O
the	O
pose	B-Method
machine	I-Method
framework	O
for	O
learning	B-Task
image	I-Task
features	I-Task
and	O
image	B-Method
-	I-Method
dependent	I-Method
spatial	I-Method
models	I-Method
for	O
the	O
task	O
of	O
pose	B-Task
estimation	I-Task
.	O
	
The	O
contribution	O
of	O
this	O
paper	O
is	O
to	O
implicitly	O
model	O
long	B-Task
-	I-Task
range	I-Task
dependencies	I-Task
between	I-Task
variables	I-Task
in	O
structured	B-Task
prediction	I-Task
tasks	I-Task
such	O
as	O
articulated	O
pose	B-Task
estimation	I-Task
.	O
	
We	O
achieve	O
this	O
by	O
designing	O
a	O
sequential	B-Method
architecture	I-Method
composed	O
of	O
convolutional	B-Method
networks	I-Method
that	O
directly	O
operate	O
on	O
belief	O
maps	O
from	O
previous	O
stages	O
,	O
producing	O
increasingly	O
refined	O
estimates	O
for	O
part	O
locations	O
,	O
without	O
the	O
need	O
for	O
explicit	O
graphical	B-Method
model	I-Method
-	I-Method
style	I-Method
inference	I-Method
.	O
	
Our	O
approach	O
addresses	O
the	O
characteristic	O
difficulty	O
of	O
vanishing	O
gradients	O
during	O
training	B-Task
by	O
providing	O
a	O
natural	O
learning	O
objective	O
function	O
that	O
enforces	O
intermediate	O
supervision	O
,	O
thereby	O
replenishing	O
back	O
-	O
propagated	O
gradients	O
and	O
conditioning	O
the	O
learning	B-Method
procedure	I-Method
.	O
	
We	O
demonstrate	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
performance	O
and	O
outperform	O
competing	O
methods	O
on	O
standard	O
benchmarks	O
including	O
the	O
MPII	B-Material
,	O
LSP	B-Material
,	O
and	O
FLIC	B-Material
datasets	I-Material
.	O
	
section	O
:	O
Introduction	O
	
We	O
introduce	O
Convolutional	B-Method
Pose	I-Method
Machines	I-Method
(	O
CPMs	B-Method
)	I-Method
for	O
the	O
task	O
of	O
articulated	O
pose	B-Task
estimation	I-Task
.	O
	
CPMs	B-Method
inherit	O
the	O
benefits	O
of	O
the	O
pose	B-Method
machine	I-Method
[	O
reference	O
]	O
architecture	O
-	O
the	O
implicit	B-Method
learning	I-Method
of	I-Method
long	I-Method
-	I-Method
range	I-Method
dependencies	I-Method
between	O
image	O
and	O
multi	O
-	O
part	O
cues	O
,	O
tight	O
integration	O
between	O
learning	B-Task
and	O
inference	B-Task
,	O
a	O
modular	B-Method
sequential	I-Method
design	I-Method
-	O
and	O
combine	O
them	O
with	O
the	O
advantages	O
afforded	O
by	O
convolutional	B-Method
architectures	I-Method
:	O
the	O
ability	O
to	O
learn	O
feature	B-Method
representations	I-Method
for	O
both	O
image	O
and	O
spatial	O
context	O
directly	O
from	O
data	O
;	O
a	O
differentiable	B-Method
architecture	I-Method
that	O
allows	O
for	O
globally	B-Task
joint	I-Task
training	I-Task
with	O
backpropagation	B-Method
;	O
and	O
the	O
ability	O
to	O
efficiently	O
handle	O
large	O
training	O
datasets	O
.	O
	
CPMs	B-Method
consist	O
of	O
a	O
sequence	O
of	O
convolutional	B-Method
networks	I-Method
that	O
repeatedly	O
produce	O
2D	O
belief	O
maps	O
[	O
reference	O
]	O
for	O
the	O
location	O
[	O
reference	O
]	O
	
We	O
use	O
the	O
term	O
belief	O
in	O
a	O
slightly	O
loose	O
sense	O
,	O
however	O
the	O
belief	O
of	O
each	O
part	O
.	O
	
At	O
each	O
stage	O
in	O
a	O
CPM	O
,	O
image	O
features	O
and	O
the	O
belief	O
maps	O
produced	O
by	O
the	O
previous	O
stage	O
are	O
used	O
as	O
input	O
.	O
	
The	O
belief	B-Method
maps	I-Method
provide	O
the	O
subsequent	O
stage	O
an	O
expressive	O
non	B-Method
-	I-Method
parametric	I-Method
encoding	I-Method
of	O
the	O
spatial	O
uncertainty	O
of	O
location	O
for	O
each	O
part	O
,	O
allowing	O
the	O
CPM	B-Method
to	O
learn	O
rich	O
image	B-Method
-	I-Method
dependent	I-Method
spatial	I-Method
models	I-Method
of	O
the	O
relationships	O
between	O
parts	O
.	O
	
Instead	O
of	O
explicitly	O
parsing	O
such	O
belief	O
maps	O
either	O
using	O
graphical	B-Method
models	I-Method
[	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
or	O
specialized	O
post	B-Method
-	I-Method
processing	I-Method
steps	I-Method
[	O
reference	O
][	O
reference	O
]	O
,	O
we	O
learn	O
convolutional	B-Method
networks	I-Method
that	O
directly	O
operate	O
on	O
intermediate	O
belief	O
maps	O
and	O
learn	O
implicit	B-Method
image	I-Method
-	I-Method
dependent	I-Method
spatial	I-Method
models	I-Method
of	O
the	O
relationships	O
between	O
parts	O
.	O
	
The	O
overall	O
proposed	O
multistage	B-Method
architecture	I-Method
is	O
fully	O
differentiable	O
and	O
therefore	O
can	O
be	O
trained	O
in	O
an	O
end	O
-	O
to	O
-	O
end	O
fashion	O
using	O
backpropagation	B-Method
.	O
	
At	O
a	O
particular	O
stage	O
in	O
the	O
CPM	O
,	O
the	O
spatial	O
context	O
of	O
part	O
beliefs	O
provide	O
strong	O
disambiguating	O
cues	O
to	O
a	O
subsequent	O
stage	O
.	O
	
As	O
a	O
result	O
,	O
each	O
stage	O
of	O
a	O
CPM	B-Method
produces	O
belief	B-Method
maps	I-Method
with	O
increasingly	O
refined	O
estimates	O
for	O
the	O
locations	O
of	O
each	O
part	O
(	O
see	O
Figure	O
1	O
)	O
.	O
	
In	O
order	O
to	O
capture	O
longrange	O
interactions	O
between	O
parts	O
,	O
the	O
design	O
of	O
the	O
network	O
in	O
each	O
stage	O
of	O
our	O
sequential	B-Method
prediction	I-Method
framework	I-Method
is	O
motivated	O
by	O
the	O
goal	O
of	O
achieving	O
a	O
large	O
receptive	O
field	O
on	O
both	O
the	O
image	O
and	O
the	O
belief	O
maps	O
.	O
	
We	O
find	O
,	O
through	O
experiments	O
,	O
that	O
large	O
receptive	O
fields	O
on	O
the	O
belief	O
maps	O
are	O
crucial	O
for	O
learning	B-Task
long	I-Task
range	I-Task
spatial	I-Task
relationships	I-Task
and	O
remaps	O
described	O
are	O
closely	O
related	O
to	O
beliefs	O
produced	O
in	O
message	B-Task
passing	I-Task
inference	I-Task
in	O
graphical	B-Method
models	I-Method
.	O
	
The	O
overall	O
architecture	O
can	O
be	O
viewed	O
as	O
an	O
unrolled	B-Method
mean	I-Method
-	I-Method
field	I-Method
message	I-Method
passing	I-Method
inference	I-Method
algorithm	I-Method
[	O
reference	O
]	O
that	O
is	O
learned	O
end	O
-	O
to	O
-	O
end	O
using	O
backpropagation	B-Method
.	O
	
sult	O
in	O
improved	O
accuracy	B-Metric
.	O
	
Composing	O
multiple	O
convolutional	B-Method
networks	I-Method
in	O
a	O
CPM	B-Method
results	O
in	O
an	O
overall	B-Method
network	I-Method
with	O
many	O
layers	O
that	O
is	O
at	O
risk	O
of	O
the	O
problem	O
of	O
vanishing	O
gradients	O
[	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
during	O
learning	B-Task
.	O
	
This	O
problem	O
can	O
occur	O
because	O
backpropagated	O
gradients	O
diminish	O
in	O
strength	O
as	O
they	O
are	O
propagated	O
through	O
the	O
many	O
layers	O
of	O
the	O
network	O
.	O
	
While	O
there	O
exists	O
recent	O
work	O
2	O
which	O
shows	O
that	O
supervising	O
very	O
deep	B-Method
networks	I-Method
at	O
intermediate	O
layers	O
aids	O
in	O
learning	B-Task
[	O
reference	O
][	O
reference	O
]	O
,	O
they	O
have	O
mostly	O
been	O
restricted	O
to	O
classification	B-Task
problems	I-Task
.	O
	
In	O
this	O
work	O
,	O
we	O
show	O
how	O
for	O
a	O
structured	B-Task
prediction	I-Task
problem	I-Task
such	O
as	O
pose	B-Task
estimation	I-Task
,	O
CPMs	B-Method
naturally	O
suggest	O
a	O
systematic	O
framework	O
that	O
replenishes	O
gradients	O
and	O
guides	O
the	O
network	O
to	O
produce	O
increasingly	O
accurate	O
belief	O
maps	O
by	O
enforcing	O
intermediate	O
supervision	O
periodically	O
through	O
the	O
network	O
.	O
	
We	O
also	O
discuss	O
different	O
training	B-Method
schemes	I-Method
of	O
such	O
a	O
sequential	B-Method
prediction	I-Method
architecture	I-Method
.	O
	
Our	O
main	O
contributions	O
are	O
(	O
a	O
)	O
learning	O
implicit	B-Method
spatial	I-Method
models	I-Method
via	O
a	O
sequential	O
composition	O
of	O
convolutional	B-Method
architectures	I-Method
and	O
(	O
b	O
)	O
a	O
systematic	O
approach	O
to	O
designing	O
and	O
training	O
such	O
an	O
architecture	O
to	O
learn	O
both	O
image	O
features	O
and	O
image	B-Method
-	I-Method
dependent	I-Method
spatial	I-Method
models	I-Method
for	O
structured	B-Task
prediction	I-Task
tasks	I-Task
,	O
without	O
the	O
need	O
for	O
any	O
graphical	B-Method
model	I-Method
style	I-Method
inference	I-Method
.	O
	
We	O
achieve	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
results	O
on	O
standard	O
benchmarks	O
including	O
the	O
MPII	B-Material
,	O
LSP	B-Material
,	O
and	O
FLIC	B-Material
datasets	I-Material
,	O
and	O
analyze	O
the	O
effects	O
of	O
jointly	O
training	O
a	O
multi	B-Method
-	I-Method
staged	I-Method
architecture	I-Method
with	O
repeated	O
intermediate	O
supervision	O
.	O
	
section	O
:	O
Related	O
Work	O
	
The	O
classical	O
approach	O
to	O
articulated	O
pose	B-Task
estimation	I-Task
is	O
the	O
pictorial	B-Method
structures	I-Method
model	I-Method
[	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
in	O
which	O
spatial	O
correlations	O
between	O
parts	O
of	O
the	O
body	O
are	O
expressed	O
as	O
a	O
tree	B-Method
-	I-Method
structured	I-Method
graphical	I-Method
model	I-Method
with	O
kinematic	O
priors	O
that	O
couple	O
connected	O
limbs	O
.	O
	
These	O
methods	O
have	O
been	O
successful	O
on	O
images	O
where	O
all	O
the	O
limbs	O
of	O
the	O
person	O
are	O
visible	O
,	O
but	O
are	O
prone	O
to	O
characteristic	O
errors	O
such	O
as	O
double	O
-	O
counting	O
image	O
evidence	O
,	O
which	O
occur	O
because	O
of	O
correlations	O
between	O
variables	O
that	O
are	O
not	O
captured	O
by	O
a	O
tree	B-Method
-	I-Method
structured	I-Method
model	I-Method
.	O
	
The	O
work	O
of	O
Kiefel	O
et	O
al	O
.	O
	
[	O
reference	O
]	O
is	O
based	O
on	O
the	O
pictorial	B-Method
structures	I-Method
model	I-Method
but	O
differs	O
in	O
the	O
underlying	O
graph	B-Method
representation	I-Method
.	O
	
Hierarchical	B-Method
models	I-Method
[	O
reference	O
][	O
reference	O
]	O
represent	O
the	O
relationships	O
between	O
parts	O
at	O
different	O
scales	O
and	O
sizes	O
in	O
a	O
hierarchical	O
tree	O
structure	O
.	O
	
The	O
underlying	O
assumption	O
of	O
these	O
models	O
is	O
that	O
larger	O
parts	O
(	O
that	O
correspond	O
to	O
full	O
limbs	O
instead	O
of	O
joints	O
)	O
can	O
often	O
have	O
discriminative	O
image	O
structure	O
that	O
can	O
be	O
easier	O
to	O
detect	O
and	O
consequently	O
help	O
reason	O
about	O
the	O
location	O
of	O
smaller	O
,	O
harder	O
-	O
to	O
-	O
detect	O
parts	O
.	O
	
Non	B-Method
-	I-Method
tree	I-Method
models	I-Method
[	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
incorporate	O
interactions	O
that	O
introduce	O
loops	O
to	O
augment	O
the	O
tree	O
structure	O
with	O
additional	O
edges	O
that	O
capture	O
symmetry	O
,	O
occlusion	O
and	O
long	O
-	O
range	O
relation	O
-	O
ships	O
.	O
	
These	O
methods	O
usually	O
have	O
to	O
rely	O
on	O
approximate	B-Method
inference	I-Method
during	O
both	O
learning	B-Task
and	O
at	O
test	O
time	O
,	O
and	O
therefore	O
have	O
to	O
trade	O
off	O
accurate	O
modeling	B-Task
of	I-Task
spatial	I-Task
relationships	I-Task
with	O
models	O
that	O
allow	O
efficient	O
inference	B-Task
,	O
often	O
with	O
a	O
simple	O
parametric	O
form	O
to	O
allow	O
for	O
fast	B-Task
inference	I-Task
.	O
	
In	O
contrast	O
,	O
methods	O
based	O
on	O
a	O
sequential	B-Method
prediction	I-Method
framework	I-Method
[	O
reference	O
]	O
learn	O
an	O
implicit	B-Method
spatial	I-Method
model	I-Method
with	O
potentially	O
complex	O
interactions	O
between	O
variables	O
by	O
directly	O
training	O
an	O
inference	B-Method
procedure	I-Method
,	O
as	O
in	O
[	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
.	O
	
There	O
has	O
been	O
a	O
recent	O
surge	O
of	O
interest	O
in	O
models	O
that	O
employ	O
convolutional	B-Method
architectures	I-Method
for	O
the	O
task	O
of	O
articulated	O
pose	B-Task
estimation	I-Task
	
[	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
.	O
Toshev	O
et	O
al	O
.	O
	
[	O
reference	O
]	O
take	O
the	O
approach	O
of	O
directly	O
regressing	O
the	O
Cartesian	O
coordinates	O
using	O
a	O
standard	O
convolutional	B-Method
architecture	I-Method
	
[	O
reference	O
]	O
.	O
Recent	O
work	O
regresses	O
image	O
to	O
confidence	O
maps	O
,	O
and	O
resort	O
to	O
graphical	B-Method
models	I-Method
,	O
which	O
require	O
hand	O
-	O
designed	O
energy	O
functions	O
or	O
heuristic	B-Method
initialization	I-Method
of	O
spatial	O
probability	O
priors	O
,	O
to	O
remove	O
outliers	O
on	O
the	O
regressed	O
confidence	O
maps	O
.	O
	
Some	O
of	O
them	O
also	O
utilize	O
a	O
dedicated	O
network	B-Method
module	I-Method
for	O
precision	B-Metric
refinement	O
	
[	O
reference	O
][	O
reference	O
]	O
.	O
	
In	O
this	O
work	O
,	O
we	O
show	O
the	O
regressed	O
confidence	O
maps	O
are	O
suitable	O
to	O
be	O
inputted	O
to	O
further	O
convolutional	B-Method
networks	I-Method
with	O
large	O
receptive	O
fields	O
to	O
learn	O
implicit	O
spatial	O
dependencies	O
without	O
the	O
use	O
of	O
hand	O
designed	O
priors	O
,	O
and	O
achieve	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
performance	O
over	O
all	O
precision	B-Metric
region	O
without	O
careful	O
initialization	O
and	O
dedicated	O
precision	B-Metric
refinement	O
.	O
	
Pfister	O
et	O
al	O
.	O
	
[	O
reference	O
]	O
also	O
used	O
a	O
network	B-Method
module	I-Method
with	O
large	O
receptive	O
field	O
to	O
capture	O
implicit	B-Method
spatial	I-Method
models	I-Method
.	O
	
Due	O
to	O
the	O
differentiable	O
nature	O
of	O
convolutions	B-Method
,	O
our	O
model	O
can	O
be	O
globally	O
trained	O
,	O
where	O
Tompson	O
et	O
al	O
.	O
	
[	O
reference	O
]	O
and	O
Steward	O
et	O
al	O
.	O
	
[	O
reference	O
]	O
also	O
discussed	O
the	O
benefit	O
of	O
joint	B-Method
training	I-Method
.	O
	
Carreira	O
et	O
al	O
.	O
	
[	O
reference	O
]	O
train	O
a	O
deep	B-Method
network	I-Method
that	O
iteratively	O
improves	O
part	O
detections	O
using	O
error	O
feedback	O
but	O
use	O
a	O
cartesian	B-Method
representation	I-Method
as	O
in	O
[	O
reference	O
]	O
which	O
does	O
not	O
preserve	O
spatial	O
uncertainty	O
and	O
results	O
in	O
lower	O
accuracy	B-Metric
in	O
the	O
highprecision	O
regime	O
.	O
	
In	O
this	O
work	O
,	O
we	O
show	O
how	O
the	O
sequential	B-Method
prediction	I-Method
framework	I-Method
takes	O
advantage	O
of	O
the	O
preserved	O
uncertainty	O
in	O
the	O
confidence	O
maps	O
to	O
encode	O
the	O
rich	O
spatial	O
context	O
,	O
with	O
enforcing	O
the	O
intermediate	O
local	O
supervisions	O
to	O
address	O
the	O
problem	O
of	O
vanishing	O
gradients	O
.	O
	
section	O
:	O
Method	O
	
section	O
:	O
Pose	B-Method
Machines	I-Method
	
We	O
denote	O
the	O
pixel	O
location	O
of	O
the	O
p	O
-	O
th	O
anatomical	O
landmark	O
(	O
which	O
we	O
refer	O
to	O
as	O
a	O
part	O
)	O
,	O
Y	O
p	O
∈	O
Z	O
⊂	O
R	O
2	O
,	O
where	O
Z	O
is	O
the	O
set	O
of	O
all	O
(	O
u	O
,	O
v	O
)	O
locations	O
in	O
an	O
image	O
.	O
	
Our	O
goal	O
is	O
to	O
predict	O
the	O
image	O
locations	O
Y	O
=	O
	
(	O
Y	O
1	O
,	O
.	O
.	O
	
.	O
	
,	O
Y	O
P	O
)	O
for	O
all	O
P	O
parts	O
.	O
	
A	O
pose	B-Method
machine	I-Method
[	O
reference	O
]	O
(	O
see	O
Figure	O
2a	O
and	O
2b	O
)	O
consists	O
of	O
a	O
sequence	O
of	O
multi	B-Method
-	I-Method
class	I-Method
predictors	I-Method
,	O
g	O
t	O
(	O
·	O
)	O
,	O
that	O
are	O
trained	O
to	O
predict	O
the	O
location	O
of	O
each	O
part	O
in	O
each	O
level	O
of	O
the	O
hierarchy	O
.	O
	
In	O
each	O
stage	O
t	O
∈	O
{	O
1	O
.	O
.	O
.	O
	
T	O
}	O
,	O
the	O
classifiers	O
	
g	O
	
t	O
predict	O
beliefs	O
for	O
assigning	O
a	O
location	O
to	O
each	O
part	O
Y	O
p	O
	
=	O
z	O
	
,	O
∀z	O
∈	O
Z	O
,	O
based	O
on	O
features	O
extracted	O
from	O
the	O
image	O
at	O
the	O
location	O
z	O
denoted	O
by	O
x	O
z	O
∈	O
R	O
d	O
and	O
contextual	O
information	O
from	O
the	O
preceding	O
classifier	B-Method
in	O
the	O
neighbor	O
-	O
	
26	O
⇥	O
26	O
60	O
⇥	O
60	O
96	O
⇥	O
96	O
160	O
	
⇥	O
160	O
240	O
	
⇥	O
240	O
320	O
⇥	O
320	O
	
400	O
⇥	O
400	O
hood	O
around	O
each	O
Y	O
p	O
in	O
stage	O
	
t.	O
	
A	O
classifier	B-Method
in	O
the	O
first	O
stage	O
t	O
=	O
1	O
,	O
therefore	O
produces	O
the	O
following	O
belief	O
values	O
:	O
	
where	O
	
is	O
the	O
score	O
predicted	O
by	O
the	O
classifier	B-Method
g	I-Method
1	O
for	O
assigning	O
the	O
p	O
th	O
part	O
in	O
the	O
first	O
stage	O
at	O
image	O
location	O
	
z.	O
	
We	O
represent	O
all	O
the	O
beliefs	O
of	O
part	O
p	O
evaluated	O
at	O
every	O
location	O
z	O
=	O
(	O
u	O
,	O
v	O
)	O
	
T	O
in	O
the	O
image	O
as	O
b	O
p	O
t	O
∈	O
R	O
w×h	O
,	O
where	O
w	O
and	O
h	O
are	O
the	O
width	O
and	O
height	O
of	O
the	O
image	O
,	O
respectively	O
.	O
	
That	O
is	O
,	O
b	O
	
For	O
convenience	O
,	O
we	O
denote	O
the	O
collection	O
of	O
belief	O
maps	O
for	O
all	O
the	O
parts	O
as	O
b	O
t	O
∈	O
R	O
w×h×	O
(	O
P	O
+	O
1	O
)	O
	
(	O
P	O
parts	O
plus	O
one	O
for	O
background	O
)	O
.	O
	
In	O
subsequent	O
stages	O
,	O
the	O
classifier	B-Method
predicts	O
a	O
belief	O
for	O
assigning	O
a	O
location	O
to	O
each	O
part	O
Y	O
p	O
	
=	O
z	O
	
,	O
∀z	O
∈	O
Z	O
,	O
based	O
on	O
(	O
1	O
)	O
features	O
of	O
the	O
image	O
data	O
x	O
t	O
z	O
∈	O
R	O
d	O
again	O
,	O
and	O
(	O
2	O
)	O
contextual	O
information	O
from	O
the	O
preceeding	B-Method
classifier	I-Method
in	O
the	O
neighborhood	O
around	O
each	O
Y	O
p	O
:	O
	
where	O
ψ	O
t>1	O
(	O
·	O
)	O
is	O
a	O
mapping	O
from	O
the	O
beliefs	O
b	O
t−1	O
to	O
context	O
features	O
.	O
	
In	O
each	O
stage	O
,	O
the	O
computed	O
beliefs	O
provide	O
an	O
increasingly	O
refined	O
estimate	O
for	O
the	O
location	O
of	O
each	O
part	O
.	O
	
Note	O
that	O
we	O
allow	O
image	O
features	O
x	O
z	O
for	O
subsequent	O
stage	O
to	O
be	O
different	O
from	O
the	O
image	O
feature	O
used	O
in	O
the	O
first	O
stage	O
	
x.	O
	
The	O
pose	B-Method
machine	I-Method
proposed	O
in	O
[	O
reference	O
]	O
used	O
boosted	B-Method
random	I-Method
forests	I-Method
for	O
prediction	B-Task
(	O
{	O
g	O
t	O
}	O
)	O
,	O
fixed	O
hand	O
-	O
crafted	O
image	O
features	O
across	O
all	O
stages	O
(	O
x	O
=	O
x	O
)	O
,	O
and	O
fixed	O
hand	O
-	O
crafted	O
context	O
feature	O
maps	O
(	O
ψ	O
t	O
(	O
·	O
)	O
)	O
to	O
capture	O
spatial	O
context	O
across	O
all	O
stages	O
.	O
	
section	O
:	O
Convolutional	B-Method
Pose	I-Method
Machines	I-Method
	
We	O
show	O
how	O
the	O
prediction	B-Method
and	I-Method
image	I-Method
feature	I-Method
computation	I-Method
modules	I-Method
of	O
a	O
pose	B-Method
machine	I-Method
can	O
be	O
replaced	O
by	O
a	O
deep	B-Method
convolutional	I-Method
architecture	I-Method
allowing	O
for	O
both	O
image	B-Method
and	I-Method
contextual	I-Method
feature	I-Method
representations	I-Method
to	O
be	O
learned	O
directly	O
from	O
data	O
.	O
	
Convolutional	B-Method
architectures	I-Method
also	O
have	O
the	O
advantage	O
of	O
being	O
completely	O
differentiable	O
,	O
thereby	O
enabling	O
endto	O
-	O
end	O
joint	B-Task
training	I-Task
of	O
all	O
stages	O
of	O
a	O
CPM	B-Method
.	O
	
We	O
describe	O
our	O
design	O
for	O
a	O
CPM	B-Method
that	O
combines	O
the	O
advantages	O
of	O
deep	B-Method
convolutional	I-Method
architectures	I-Method
with	O
the	O
implicit	B-Method
spatial	I-Method
modeling	I-Method
afforded	O
by	O
the	O
pose	B-Method
machine	I-Method
framework	O
.	O
	
section	O
:	O
Keypoint	B-Task
Localization	I-Task
Using	O
Local	O
Image	O
Evidence	O
	
The	O
first	O
stage	O
of	O
a	O
convolutional	B-Method
pose	I-Method
machine	I-Method
predicts	O
part	O
beliefs	O
from	O
only	O
local	O
image	O
evidence	O
.	O
	
Figure	O
2c	O
shows	O
the	O
network	B-Method
structure	I-Method
used	O
for	O
part	B-Task
detection	I-Task
from	O
local	O
image	O
evidence	O
using	O
a	O
deep	B-Method
convolutional	I-Method
network	I-Method
.	O
	
The	O
evidence	O
is	O
local	O
because	O
the	O
receptive	O
field	O
of	O
the	O
first	O
stage	O
of	O
the	O
network	O
is	O
constrained	O
to	O
a	O
small	O
patch	O
around	O
the	O
output	O
pixel	O
location	O
.	O
	
We	O
use	O
a	O
network	B-Method
structure	I-Method
composed	O
of	O
five	O
convolutional	B-Method
layers	I-Method
followed	O
by	O
two	O
1	O
×	O
1	O
convolutional	B-Method
layers	I-Method
which	O
results	O
in	O
a	O
fully	B-Method
convolutional	I-Method
archi	I-Method
-	I-Method
Figure	O
3	O
:	O
Spatial	O
context	O
from	O
belief	O
maps	O
of	O
easier	O
-	O
to	O
-	O
detect	O
parts	O
can	O
provide	O
strong	O
cues	O
for	O
localizing	B-Task
difficult	I-Task
-	I-Task
to	I-Task
-	I-Task
detect	I-Task
parts	I-Task
.	O
	
The	O
spatial	O
contexts	O
from	O
shoulder	O
,	O
neck	O
and	O
head	O
can	O
help	O
eliminate	O
wrong	O
(	O
red	O
)	O
and	O
strengthen	O
correct	O
(	O
green	O
)	O
estimations	O
on	O
the	O
belief	O
map	O
of	O
right	O
elbow	O
in	O
the	O
subsequent	O
stages	O
.	O
	
tecture	O
[	O
reference	O
]	O
.	O
	
In	O
practice	O
,	O
to	O
achieve	O
certain	O
precision	B-Metric
,	O
we	O
normalize	O
input	O
cropped	O
images	O
to	O
size	O
368	O
×	O
368	O
(	O
see	O
Section	O
4.2	O
for	O
details	O
)	O
,	O
and	O
the	O
receptive	O
field	O
of	O
the	O
network	O
shown	O
above	O
is	O
160	O
×	O
160	O
pixels	O
.	O
	
The	O
network	O
can	O
effectively	O
be	O
viewed	O
as	O
sliding	O
a	O
deep	B-Method
network	I-Method
across	O
an	O
image	O
and	O
regressing	O
from	O
the	O
local	O
image	O
evidence	O
in	O
each	O
160	O
×	O
160	O
image	O
patch	O
to	O
a	O
P	O
+	O
1	O
sized	O
output	O
vector	O
that	O
represents	O
a	O
score	O
for	O
each	O
part	O
at	O
that	O
image	O
location	O
.	O
	
section	O
:	O
Sequential	B-Task
Prediction	I-Task
with	O
Learned	O
Spatial	O
Context	O
Features	O
	
While	O
the	O
detection	B-Metric
rate	I-Metric
on	O
landmarks	O
with	O
consistent	O
appearance	O
,	O
such	O
as	O
the	O
head	O
and	O
shoulders	O
,	O
can	O
be	O
favorable	O
,	O
the	O
accuracies	B-Metric
are	O
often	O
much	O
lower	O
for	O
landmarks	O
lower	O
down	O
the	O
kinematic	O
chain	O
of	O
the	O
human	O
skeleton	O
due	O
to	O
their	O
large	O
variance	O
in	O
configuration	O
and	O
appearance	O
.	O
	
The	O
landscape	O
of	O
the	O
belief	O
maps	O
around	O
a	O
part	O
location	O
,	O
albeit	O
noisy	O
,	O
can	O
,	O
however	O
,	O
be	O
very	O
informative	O
.	O
	
Illustrated	O
in	O
Figure	O
3	O
,	O
when	O
detecting	O
challenging	O
parts	O
such	O
as	O
right	O
elbow	O
,	O
the	O
belief	O
map	O
for	O
right	O
shoulder	O
with	O
a	O
sharp	O
peak	O
can	O
be	O
used	O
as	O
a	O
strong	O
cue	O
.	O
	
A	O
predictor	O
in	O
subsequent	O
stages	O
(	O
g	O
t>1	O
)	O
can	O
use	O
the	O
spatial	O
context	O
(	O
ψ	O
t>1	O
(	O
·	O
)	O
)	O
of	O
the	O
noisy	O
belief	O
maps	O
in	O
a	O
region	O
around	O
the	O
image	O
location	O
z	O
and	O
improve	O
its	O
predictions	O
by	O
leveraging	O
the	O
fact	O
that	O
parts	O
occur	O
in	O
consistent	O
geometric	O
configurations	O
.	O
	
In	O
the	O
second	O
stage	O
of	O
a	O
pose	B-Method
machine	I-Method
,	O
the	O
classifier	B-Method
g	I-Method
2	O
accepts	O
as	O
input	O
the	O
image	O
features	O
x	O
2	O
z	O
and	O
features	O
computed	O
on	O
the	O
beliefs	O
via	O
the	O
feature	O
function	O
ψ	O
for	O
each	O
of	O
the	O
parts	O
in	O
the	O
previous	O
stage	O
.	O
	
The	O
feature	O
function	O
ψ	O
serves	O
to	O
encode	O
the	O
landscape	O
of	O
the	O
belief	O
maps	O
from	O
the	O
previous	O
stage	O
in	O
a	O
spatial	O
region	O
around	O
the	O
location	O
z	O
of	O
the	O
different	O
parts	O
.	O
	
For	O
a	O
convolutional	B-Method
pose	I-Method
machine	I-Method
,	O
we	O
do	O
not	O
have	O
an	O
explicit	O
function	O
that	O
computes	O
context	O
features	O
.	O
	
Instead	O
,	O
we	O
define	O
ψ	O
as	O
being	O
the	O
receptive	O
field	O
of	O
the	O
predictor	O
on	O
the	O
beliefs	O
from	O
the	O
previous	O
stage	O
.	O
	
The	O
design	O
of	O
the	O
network	O
is	O
guided	O
by	O
achieving	O
a	O
receptive	O
field	O
at	O
the	O
output	O
layer	O
of	O
the	O
second	B-Method
stage	I-Method
network	I-Method
that	O
is	O
large	O
enough	O
to	O
allow	O
the	O
learning	O
of	O
potentially	O
complex	O
and	O
long	O
-	O
range	O
correlations	O
between	O
parts	O
.	O
	
By	O
simply	O
supplying	O
features	O
on	O
the	O
outputs	O
of	O
the	O
previous	O
stage	O
(	O
as	O
opposed	O
to	O
specifying	O
potential	O
functions	O
in	O
a	O
graphical	B-Method
model	I-Method
)	O
,	O
the	O
convolutional	B-Method
layers	I-Method
in	O
the	O
subsequent	O
stage	O
allow	O
the	O
classifier	B-Method
to	O
freely	O
combine	O
contextual	O
information	O
by	O
picking	O
the	O
most	O
predictive	O
features	O
.	O
	
The	O
belief	B-Method
maps	I-Method
from	O
the	O
first	O
stage	O
are	O
generated	O
from	O
a	O
network	O
that	O
examined	O
the	O
image	O
locally	O
with	O
a	O
small	O
receptive	O
field	O
.	O
	
In	O
the	O
second	O
stage	O
,	O
we	O
design	O
a	O
network	O
that	O
drastically	O
increases	O
the	O
equivalent	O
receptive	O
field	O
.	O
	
Large	O
receptive	O
fields	O
can	O
be	O
achieved	O
either	O
by	O
pooling	B-Method
at	O
the	O
expense	O
of	O
precision	B-Metric
,	O
increasing	O
the	O
kernel	O
size	O
of	O
the	O
convolutional	B-Method
filters	I-Method
at	O
the	O
expense	O
of	O
increasing	O
the	O
number	O
of	O
parameters	O
,	O
or	O
by	O
increasing	O
the	O
number	O
of	O
convolutional	B-Method
layers	I-Method
at	O
the	O
risk	O
of	O
encountering	O
vanishing	O
gradients	O
during	O
training	O
.	O
	
Our	O
network	B-Method
design	I-Method
and	O
corresponding	O
receptive	O
field	O
for	O
the	O
subsequent	O
stages	O
(	O
t	O
≥	O
2	O
)	O
is	O
shown	O
in	O
Figure	O
2d	O
.	O
	
We	O
choose	O
to	O
use	O
multiple	O
convolutional	B-Method
layers	I-Method
to	O
achieve	O
large	O
receptive	O
field	O
on	O
the	O
8×	O
downscaled	O
heatmaps	O
,	O
as	O
it	O
allows	O
us	O
to	O
be	O
parsimonious	O
with	O
respect	O
to	O
the	O
number	O
of	O
parameters	O
of	O
the	O
model	O
.	O
	
We	O
found	O
that	O
our	O
stride	B-Method
-	I-Method
8	I-Method
network	I-Method
performs	O
as	O
well	O
as	O
a	O
stride	B-Method
-	I-Method
4	I-Method
one	I-Method
even	O
at	O
high	O
precision	B-Metric
region	O
,	O
while	O
it	O
makes	O
us	O
easier	O
to	O
achieve	O
larger	O
receptive	O
fields	O
.	O
	
We	O
also	O
repeat	O
similar	O
structure	O
for	O
image	O
feature	O
maps	O
to	O
make	O
the	O
spatial	O
context	O
be	O
image	O
-	O
dependent	O
and	O
allow	O
error	B-Task
correction	I-Task
,	O
following	O
the	O
structure	O
of	O
pose	B-Method
machine	I-Method
.	O
	
We	O
find	O
that	O
accuracy	B-Metric
improves	O
with	O
the	O
size	O
of	O
the	O
receptive	O
field	O
.	O
	
In	O
Figure	O
4	O
we	O
show	O
the	O
improvement	O
in	O
accuracy	B-Metric
on	O
the	O
FLIC	B-Material
dataset	O
[	O
reference	O
]	O
as	O
the	O
size	O
of	O
the	O
receptive	O
field	O
on	O
the	O
original	O
image	O
is	O
varied	O
by	O
varying	O
the	O
architecture	O
without	O
significantly	O
changing	O
the	O
number	O
of	O
parameters	O
,	O
through	O
a	O
series	O
of	O
experimental	O
trials	O
on	O
input	O
images	O
normalized	O
to	O
a	O
size	O
of	O
304	O
×	O
304	O
.	O
	
We	O
see	O
that	O
the	O
accuracy	B-Metric
improves	O
as	O
the	O
effective	O
receptive	O
field	O
increases	O
,	O
and	O
starts	O
to	O
saturate	O
around	O
250	O
pixels	O
,	O
which	O
also	O
happens	O
to	O
be	O
roughly	O
the	O
size	O
of	O
the	O
normalized	O
object	O
.	O
	
This	O
improvement	O
in	O
accuracy	B-Metric
with	O
receptive	O
field	O
size	O
suggests	O
that	O
the	O
network	O
does	O
indeed	O
encode	O
long	O
range	O
interactions	O
between	O
parts	O
and	O
that	O
doing	O
so	O
is	O
beneficial	O
.	O
	
In	O
our	O
best	O
performing	O
setting	O
in	O
Figure	O
2	O
,	O
we	O
normalize	O
cropped	O
images	O
into	O
a	O
larger	O
size	O
of	O
368	O
×	O
368	O
pixels	O
for	O
better	O
precision	B-Metric
,	O
and	O
the	O
receptive	O
field	O
of	O
the	O
second	O
stage	O
output	O
on	O
the	O
belief	B-Method
maps	I-Method
of	O
the	O
first	O
stage	O
is	O
set	O
to	O
31	O
×	O
31	O
,	O
which	O
is	O
equivalently	O
400	O
×	O
400	O
pixels	O
on	O
the	O
original	O
image	O
,	O
where	O
the	O
radius	O
can	O
usually	O
cover	O
any	O
pair	O
of	O
the	O
parts	O
.	O
	
With	O
more	O
stages	O
,	O
the	O
effective	O
receptive	O
field	O
is	O
even	O
larger	O
.	O
	
In	O
the	O
following	O
section	O
we	O
show	O
our	O
results	O
from	O
up	O
to	O
6	O
stages	O
.	O
	
section	O
:	O
Learning	O
in	O
Convolutional	B-Method
Pose	I-Method
Machines	I-Method
	
The	O
design	O
described	O
above	O
for	O
a	O
pose	B-Method
machine	I-Method
results	O
in	O
a	O
deep	B-Method
architecture	I-Method
that	O
can	O
have	O
a	O
large	O
number	O
of	O
layers	O
.	O
	
Training	O
such	O
a	O
network	O
with	O
many	O
layers	O
can	O
be	O
prone	O
to	O
the	O
problem	O
of	O
vanishing	O
gradients	O
[	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
where	O
,	O
as	O
observed	O
by	O
Bradley	O
[	O
reference	O
]	O
and	O
Bengio	O
et	O
al	O
.	O
	
[	O
reference	O
]	O
,	O
the	O
magnitude	O
of	O
back	O
-	O
propagated	O
gradients	O
decreases	O
in	O
strength	O
with	O
the	O
number	O
of	O
intermediate	O
layers	O
between	O
the	O
output	O
layer	O
and	O
the	O
input	O
layer	O
.	O
	
Fortunately	O
,	O
the	O
sequential	B-Method
prediction	I-Method
framework	I-Method
of	O
the	O
pose	B-Method
machine	I-Method
provides	O
a	O
natural	O
approach	O
to	O
training	O
our	O
deep	B-Method
architecture	I-Method
that	O
addresses	O
this	O
problem	O
.	O
	
Each	O
stage	O
of	O
the	O
pose	B-Method
machine	I-Method
is	O
trained	O
to	O
repeatedly	O
produce	O
the	O
belief	O
maps	O
for	O
the	O
locations	O
of	O
each	O
of	O
the	O
parts	O
.	O
	
We	O
encourage	O
the	O
network	O
to	O
repeatedly	O
arrive	O
at	O
such	O
a	O
representation	O
by	O
defining	O
a	O
loss	O
function	O
at	O
the	O
output	O
of	O
each	O
stage	O
t	O
that	O
minimizes	O
the	O
l	O
2	O
distance	O
between	O
the	O
predicted	O
and	O
ideal	O
belief	O
maps	O
for	O
each	O
part	O
.	O
	
The	O
ideal	O
belief	O
map	O
for	O
a	O
part	O
p	O
is	O
written	O
as	O
b	O
p	O
	
*	O
(	O
Y	O
p	O
	
=	O
z	O
)	O
,	O
which	O
are	O
created	O
by	O
putting	O
Gaussian	O
peaks	O
at	O
ground	O
truth	O
locations	O
of	O
each	O
body	O
part	O
	
p.	O
	
The	O
cost	B-Metric
function	I-Metric
we	O
aim	O
to	O
minimize	O
at	O
the	O
output	O
of	O
each	O
stage	O
at	O
each	O
level	O
is	O
therefore	O
given	O
by	O
:	O
	
The	O
overall	O
objective	O
for	O
the	O
full	O
architecture	O
is	O
obtained	O
by	O
adding	O
the	O
losses	O
at	O
each	O
stage	O
and	O
is	O
given	O
by	O
:	O
	
We	O
use	O
standard	O
stochastic	B-Method
gradient	I-Method
descend	I-Method
to	O
jointly	O
train	O
all	O
the	O
T	O
stages	O
in	O
the	O
network	O
.	O
	
To	O
share	O
the	O
image	O
feature	O
x	O
across	O
all	O
subsequent	O
stages	O
,	O
we	O
share	O
the	O
weights	O
of	O
corresponding	O
convolutional	B-Method
layers	I-Method
(	O
see	O
Figure	O
2	O
)	O
across	O
stages	O
	
t	O
≥	O
2	O
.	O
	
section	O
:	O
Evaluation	O
	
section	O
:	O
Analysis	O
	
Addressing	B-Task
vanishing	I-Task
gradients	I-Task
.	O
	
The	O
objective	O
in	O
Equation	O
5	O
describes	O
a	O
decomposable	B-Method
loss	I-Method
function	I-Method
that	O
operates	O
on	O
different	O
parts	O
of	O
the	O
network	O
(	O
see	O
Figure	O
2	O
)	O
.	O
	
Specifically	O
,	O
each	O
term	O
in	O
the	O
summation	O
is	O
applied	O
to	O
the	O
network	O
after	O
each	O
stage	O
t	O
effectively	O
enforcing	O
supervision	O
in	O
intermediate	O
stages	O
through	O
the	O
network	O
.	O
	
Intermediate	B-Method
supervision	I-Method
has	O
the	O
advantage	O
that	O
,	O
even	O
though	O
the	O
full	B-Method
architecture	I-Method
can	O
have	O
many	O
layers	O
,	O
it	O
does	O
not	O
fall	O
prey	O
to	O
the	O
vanishing	B-Task
gradient	I-Task
problem	I-Task
as	O
the	O
intermediate	O
loss	O
functions	O
replenish	O
the	O
gradients	O
at	O
each	O
stage	O
.	O
	
We	O
verify	O
this	O
claim	O
by	O
observing	O
histograms	O
of	O
gradient	O
magnitude	O
(	O
see	O
Figure	O
5	O
)	O
at	O
different	O
depths	O
in	O
the	O
architecture	O
across	O
training	O
epochs	O
for	O
models	O
with	O
and	O
without	O
intermediate	O
supervision	O
.	O
	
In	O
early	O
epochs	O
,	O
as	O
we	O
move	O
from	O
the	O
output	O
layer	O
to	O
the	O
input	O
layer	O
,	O
we	O
observe	O
on	O
the	O
model	O
larger	O
variance	O
across	O
all	O
layers	O
,	O
suggesting	O
that	O
learning	B-Task
is	O
indeed	O
occurring	O
in	O
all	O
the	O
layers	O
thanks	O
to	O
intermediate	O
supervision	O
.	O
	
We	O
also	O
notice	O
that	O
as	O
training	O
progresses	O
,	O
the	O
variance	O
in	O
the	O
gradient	O
magnitude	O
distributions	O
decreases	O
pointing	O
to	O
model	B-Task
convergence	I-Task
.	O
	
Benefit	O
of	O
end	O
-	O
to	O
-	O
end	B-Task
learning	I-Task
.	O
	
We	O
see	O
in	O
Figure	O
6a	O
that	O
replacing	O
the	O
modules	O
of	O
a	O
pose	B-Method
machine	I-Method
with	O
the	O
appropriately	O
designed	O
convolutional	B-Method
architecture	I-Method
provides	O
a	O
large	O
boost	O
of	O
42.4	O
percentage	O
points	O
over	O
the	O
previous	O
approach	O
of	O
[	O
reference	O
]	O
in	O
the	O
high	B-Metric
precision	I-Metric
regime	I-Metric
(	O
PCK@0.1	B-Metric
)	O
and	O
30.9	O
percentage	O
points	O
in	O
the	O
low	B-Metric
precision	I-Metric
regime	I-Metric
(	O
PCK@0.2	B-Metric
)	O
.	O
	
Comparison	O
on	O
training	B-Method
schemes	I-Method
.	O
	
We	O
compare	O
different	O
variants	O
of	O
training	O
the	O
network	O
in	O
Figure	O
6b	O
on	O
the	O
LSP	B-Material
dataset	I-Material
with	O
person	O
-	O
centric	O
(	O
PC	B-Material
)	O
annotations	O
.	O
	
To	O
demonstrate	O
the	O
benefit	O
of	O
intermediate	B-Task
supervision	I-Task
with	O
joint	B-Task
training	I-Task
across	O
stages	O
,	O
we	O
train	O
the	O
model	O
in	O
four	O
ways	O
:	O
(	O
i	O
)	O
training	O
from	O
scratch	O
using	O
a	O
global	O
loss	O
function	O
that	O
enforces	O
intermediate	O
supervision	O
(	O
ii	O
)	O
stage	O
-	O
wise	O
;	O
where	O
each	O
stage	O
is	O
trained	O
in	O
a	O
feed	B-Method
-	I-Method
forward	I-Method
fashion	I-Method
and	O
stacked	O
(	O
iii	O
)	O
as	O
same	O
as	O
(	O
i	O
)	O
but	O
initialized	O
with	O
weights	O
from	O
(	O
ii	O
)	O
,	O
and	O
(	O
iv	O
)	O
as	O
same	O
as	O
(	O
i	O
)	O
	
but	O
with	O
no	O
intermediate	O
supervision	O
.	O
	
We	O
find	O
that	O
network	O
(	O
i	O
)	O
outperforms	O
all	O
other	O
training	B-Method
methods	I-Method
,	O
showing	O
that	O
intermediate	O
supervision	O
and	O
joint	B-Method
training	I-Method
across	O
stage	O
is	O
indeed	O
crucial	O
in	O
achieving	O
good	O
performance	O
.	O
	
The	O
stagewise	B-Method
training	I-Method
in	O
(	O
ii	O
)	O
saturate	O
at	O
suboptimal	O
,	O
and	O
the	O
jointly	B-Task
fine	I-Task
-	I-Task
tuning	I-Task
in	O
(	O
iii	O
)	O
improves	O
from	O
this	O
sub	O
-	O
optimal	O
to	O
the	O
accuracy	B-Metric
level	O
	
closed	O
to	O
(	O
i	O
)	O
,	O
however	O
with	O
effectively	O
longer	O
training	O
iterations	O
.	O
	
Performance	O
across	O
stages	O
.	O
	
We	O
show	O
a	O
comparison	O
of	O
performance	O
across	O
each	O
stage	O
on	O
the	O
LSP	B-Material
dataset	I-Material
(	O
PC	B-Material
)	O
in	O
Figure	O
6c	O
.	O
	
We	O
show	O
that	O
the	O
performance	O
increases	O
monotonically	O
until	O
5	O
stages	O
,	O
as	O
the	O
predictors	O
in	O
subsequent	O
stages	O
make	O
use	O
of	O
contextual	O
information	O
in	O
a	O
large	O
receptive	O
field	O
on	O
the	O
previous	O
stage	O
beliefs	O
maps	O
to	O
resolve	O
confusions	O
between	O
parts	O
and	O
background	O
.	O
	
We	O
see	O
diminishing	O
returns	O
at	O
the	O
6th	O
stage	O
,	O
which	O
is	O
the	O
number	O
we	O
choose	O
for	O
reporting	O
our	O
best	O
results	O
in	O
this	O
paper	O
for	O
LSP	B-Material
and	O
MPII	B-Material
datasets	I-Material
.	O
	
section	O
:	O
Datasets	O
and	O
Quantitative	B-Task
Analysis	I-Task
	
In	O
this	O
section	O
we	O
present	O
our	O
numerical	O
results	O
in	O
various	O
standard	O
benchmarks	O
including	O
the	O
MPII	B-Material
,	O
LSP	B-Material
,	O
and	O
FLIC	B-Material
datasets	I-Material
.	O
	
To	O
have	O
normalized	O
input	O
samples	O
of	O
368	O
×	O
368	O
for	O
training	O
,	O
we	O
first	O
resize	O
the	O
images	O
to	O
roughly	O
make	O
the	O
samples	O
into	O
the	O
same	O
scale	O
,	O
and	O
then	O
crop	O
or	O
pad	O
the	O
image	O
according	O
to	O
the	O
center	O
positions	O
and	O
rough	O
scale	O
estimations	O
provided	O
in	O
the	O
datasets	O
if	O
available	O
.	O
	
In	O
datasets	O
such	O
as	O
LSP	B-Material
without	O
these	O
information	O
,	O
we	O
estimate	O
them	O
according	O
to	O
joint	O
positions	O
or	O
image	O
sizes	O
.	O
	
For	O
testing	O
,	O
we	O
perform	O
similar	O
resizing	B-Task
and	I-Task
cropping	I-Task
(	O
or	O
padding	O
)	O
,	O
but	O
estimate	O
center	O
position	O
and	O
scale	O
only	O
from	O
image	O
sizes	O
when	O
necessary	O
.	O
	
In	O
addition	O
,	O
we	O
merge	O
the	O
belief	O
maps	O
from	O
different	O
scales	O
(	O
perturbed	O
around	O
the	O
given	O
one	O
)	O
for	O
final	O
predictions	O
,	O
to	O
handle	O
the	O
inaccuracy	O
of	O
the	O
given	O
scale	B-Method
estimation	I-Method
.	O
	
We	O
define	O
and	O
implement	O
our	O
model	O
using	O
the	O
Caffe	B-Method
[	O
13	O
]	O
libraries	O
for	O
deep	B-Task
learning	I-Task
.	O
	
We	O
publicly	O
release	O
the	O
source	O
code	O
and	O
details	O
on	O
the	O
architecture	O
,	O
learning	O
parameters	O
,	O
design	O
decisions	O
and	O
data	B-Task
augmentation	I-Task
to	O
ensure	O
full	O
reproducibility	O
.	O
	
[	O
reference	O
]	O
	
MPII	B-Material
Human	O
Pose	O
Dataset	O
.	O
	
We	O
show	O
in	O
Figure	O
8	O
our	O
results	O
on	O
the	O
MPII	B-Material
Human	O
Pose	O
dataset	O
[	O
reference	O
]	O
which	O
consists	O
more	O
than	O
28000	O
training	O
samples	O
.	O
	
We	O
choose	O
to	O
randomly	O
augment	O
the	O
data	O
with	O
rotation	O
degrees	O
in	O
[	O
−40	O
	
•	O
,	O
40	O
	
•	O
]	O
,	O
scaling	O
with	O
factors	O
in	O
[	O
0.7	O
,	O
1.3	O
]	O
,	O
and	O
horizonal	O
flipping	O
.	O
	
The	O
evaluation	O
is	O
based	O
on	O
PCKh	B-Method
metric	I-Method
[	O
reference	O
]	O
where	O
the	O
error	B-Metric
tolerance	I-Metric
is	O
normalized	O
with	O
respect	O
to	O
head	O
size	O
of	O
the	O
target	O
.	O
	
Because	O
there	O
often	O
are	O
multiple	O
people	O
in	O
the	O
proximity	O
of	O
the	O
interested	O
person	O
(	O
rough	O
center	O
position	O
is	O
given	O
in	O
the	O
dataset	O
)	O
,	O
we	O
made	O
two	O
sets	O
of	O
ideal	O
belief	B-Method
maps	I-Method
for	O
training	O
:	O
one	O
includes	O
all	O
the	O
peaks	O
for	O
every	O
person	O
appearing	O
in	O
the	O
proximity	O
of	O
the	O
primary	O
subject	O
and	O
the	O
second	O
type	O
where	O
we	O
only	O
place	O
peaks	O
for	O
the	O
primary	O
subject	O
.	O
	
We	O
supply	O
the	O
first	O
set	O
of	O
belief	O
maps	O
to	O
the	O
loss	O
layers	O
in	O
the	O
first	O
stage	O
as	O
the	O
initial	O
stage	O
only	O
relies	O
on	O
local	O
image	O
evidence	O
to	O
make	O
predictions	O
.	O
	
We	O
supply	O
the	O
second	O
type	O
of	O
belief	O
maps	O
to	O
the	O
	
Wrists	O
Elbows	O
(	O
a	O
)	O
(	O
b	O
)	O
loss	O
layers	O
of	O
all	O
subsequent	O
stages	O
.	O
	
We	O
also	O
find	O
that	O
supplying	O
to	O
all	O
subsequent	O
stages	O
an	O
additional	O
heat	O
-	O
map	O
with	O
a	O
Gaussian	O
peak	O
indicating	O
center	O
of	O
the	O
primary	O
subject	O
is	O
beneficial	O
.	O
	
Our	O
total	O
PCKh	B-Metric
-	I-Metric
0.5	I-Metric
score	I-Metric
achieves	O
state	O
of	O
the	O
art	O
at	O
87.95	O
%	O
(	O
88.52	O
%	O
when	O
adding	O
LSP	B-Material
training	I-Material
data	I-Material
)	O
,	O
which	O
is	O
6.11	O
%	O
higher	O
than	O
the	O
closest	O
competitor	O
,	O
and	O
it	O
is	O
noteworthy	O
that	O
on	O
the	O
ankle	O
(	O
the	O
most	O
challenging	O
part	O
)	O
,	O
our	O
PCKh	B-Metric
-	I-Metric
0.5	I-Metric
score	I-Metric
is	O
78.28	O
%	O
(	O
79.41	O
%	O
when	O
adding	O
LSP	B-Material
training	I-Material
data	I-Material
)	O
,	O
which	O
is	O
10.76	O
%	O
higher	O
than	O
the	O
closest	O
competitor	O
.	O
	
This	O
result	O
shows	O
the	O
capability	O
of	O
our	O
model	O
to	O
capture	O
long	O
distance	O
context	O
given	O
ankles	O
are	O
the	O
farthest	O
parts	O
from	O
head	O
and	O
other	O
more	O
recognizable	O
parts	O
.	O
	
Figure	O
11	O
shows	O
our	O
accuracy	B-Metric
is	O
also	O
consistently	O
significantly	O
higher	O
than	O
other	O
methods	O
across	O
various	O
view	O
angles	O
defined	O
in	O
[	O
reference	O
]	O
,	O
especially	O
in	O
those	O
challenging	O
non	O
-	O
frontal	O
views	O
.	O
	
In	O
summary	O
,	O
our	O
method	O
improves	O
the	O
accuracy	B-Metric
in	O
all	O
parts	O
,	O
over	O
all	O
precisions	B-Metric
,	O
across	O
all	O
view	O
angles	O
,	O
and	O
is	O
the	O
first	O
one	O
achieving	O
such	O
high	O
accuracy	B-Metric
without	O
any	O
pre	O
-	O
training	O
from	O
other	O
data	O
,	O
or	O
post	B-Method
-	I-Method
inference	I-Method
parsing	I-Method
with	O
hand	O
-	O
design	O
priors	O
or	O
initialization	O
of	O
such	O
a	O
structured	B-Task
prediction	I-Task
task	I-Task
as	O
in	O
[	O
reference	O
][	O
reference	O
]	O
.	O
Our	O
methods	O
also	O
does	O
not	O
need	O
another	O
module	O
dedicated	O
to	O
location	B-Task
refinement	I-Task
as	O
in	O
[	O
reference	O
]	O
to	O
achieve	O
great	O
high	O
-	O
precision	B-Metric
accuracy	O
with	O
a	O
stride	B-Method
-	I-Method
8	I-Method
network	I-Method
.	O
	
Leeds	B-Material
Sports	I-Material
Pose	I-Material
(	O
LSP	B-Material
)	O
Dataset	O
.	O
	
We	O
evaluate	O
our	O
method	O
on	O
the	O
Extended	B-Material
Leeds	I-Material
Sports	I-Material
Dataset	I-Material
[	O
reference	O
]	O
that	O
consists	O
of	O
11000	O
images	O
for	O
training	O
and	O
1000	O
images	O
for	O
testing	O
.	O
	
We	O
trained	O
on	O
person	O
-	O
centric	O
(	O
PC	B-Material
)	O
annotations	O
and	O
evaluate	O
our	O
method	O
using	O
the	O
Percentage	B-Metric
Correct	I-Metric
Keypoints	I-Metric
(	O
PCK	B-Metric
)	O
metric	O
[	O
reference	O
]	O
.	O
	
Using	O
the	O
same	O
augmentation	B-Method
scheme	I-Method
as	O
for	O
the	O
MPI	B-Material
dataset	I-Material
,	O
our	O
model	O
again	O
achieves	O
state	O
of	O
the	O
art	O
at	O
84.32	O
%	O
(	O
90.5	O
%	O
when	O
adding	O
MPII	B-Material
train	O
-	O
MPII	B-Material
FLIC	I-Material
LSP	I-Material
Figure	O
10	O
:	O
Qualitative	O
results	O
of	O
our	O
method	O
on	O
the	O
MPII	B-Material
,	O
LSP	B-Material
and	O
FLIC	B-Material
datasets	O
respectively	O
.	O
	
We	O
see	O
that	O
the	O
method	O
is	O
able	O
to	O
handle	O
non	O
-	O
standard	O
poses	O
and	O
resolve	O
ambiguities	O
between	O
symmetric	O
parts	O
for	O
a	O
variety	O
of	O
different	O
relative	O
camera	O
views	O
.	O
	
ing	O
data	O
)	O
.	O
	
Note	O
that	O
adding	O
MPII	B-Material
data	O
here	O
significantly	O
boosts	O
our	O
performance	O
,	O
due	O
to	O
its	O
labeling	B-Metric
quality	I-Metric
being	O
much	O
better	O
than	O
LSP	B-Material
.	O
	
Because	O
of	O
the	O
noisy	O
label	O
in	O
the	O
LSP	B-Material
dataset	I-Material
,	O
Pishchulin	O
et	O
al	O
.	O
	
[	O
reference	O
]	O
reproduced	O
the	O
dataset	O
with	O
original	O
high	O
resolution	O
images	O
and	O
better	O
labeling	B-Metric
quality	I-Metric
.	O
	
FLIC	B-Material
Dataset	O
.	O
	
We	O
evaluate	O
our	O
method	O
on	O
the	O
FLIC	B-Material
Dataset	O
[	O
reference	O
]	O
which	O
consists	O
of	O
3987	O
images	O
for	O
training	O
and	O
1016	O
images	O
for	O
testing	O
.	O
	
We	O
report	O
accuracy	B-Metric
as	O
per	O
the	O
metric	O
introduced	O
in	O
Sapp	O
et	O
al	O
.	O
	
[	O
reference	O
]	O
for	O
the	O
elbow	O
and	O
wrist	O
joints	O
in	O
Figure	O
12	O
.	O
	
Again	O
,	O
we	O
outperform	O
all	O
prior	O
art	O
at	O
PCK@0.2	B-Metric
with	O
97.59	O
%	O
on	O
elbows	B-Metric
and	O
95.03	O
%	O
on	O
wrists	O
.	O
	
In	O
higher	O
precision	B-Metric
region	O
our	O
advantage	O
is	O
even	O
more	O
significant	O
:	O
14.8	O
percentage	O
points	O
on	O
wrists	O
and	O
12.7	O
percentage	O
points	O
on	O
elbows	O
at	O
	
PCK@0.05	B-Metric
,	O
and	O
8.9	O
percentage	O
points	O
on	O
wrists	O
and	O
9.3	O
percentage	O
points	O
on	O
elbows	O
at	O
PCK@0.1	B-Metric
.	O
	
section	O
:	O
Discussion	O
	
Convolutional	B-Method
pose	I-Method
machines	I-Method
provide	O
an	O
end	O
-	O
to	O
-	O
end	B-Method
architecture	I-Method
for	O
tackling	O
structured	B-Task
prediction	I-Task
problems	I-Task
in	O
computer	B-Task
vision	I-Task
without	O
the	O
need	O
for	O
graphical	B-Method
-	I-Method
model	I-Method
style	I-Method
inference	I-Method
.	O
	
We	O
showed	O
that	O
a	O
sequential	B-Method
architecture	I-Method
composed	O
of	O
convolutional	B-Method
networks	I-Method
is	O
capable	O
of	O
implicitly	O
learning	O
a	O
spatial	B-Method
models	I-Method
for	O
pose	O
by	O
communicating	O
increasingly	O
refined	O
uncertainty	O
-	O
preserving	O
beliefs	O
between	O
stages	O
.	O
	
Problems	O
with	O
spatial	O
dependencies	O
between	O
variables	O
arise	O
in	O
multiple	O
domains	O
of	O
computer	B-Task
vision	I-Task
such	O
as	O
semantic	B-Task
image	I-Task
labeling	I-Task
,	O
single	B-Task
image	I-Task
depth	I-Task
prediction	I-Task
and	O
object	B-Task
detection	I-Task
and	O
future	O
work	O
will	O
involve	O
extending	O
our	O
architecture	O
to	O
these	O
problems	O
.	O
	
Our	O
approach	O
achieves	O
state	O
of	O
the	O
art	O
accuracy	B-Metric
on	O
all	O
primary	O
benchmarks	O
,	O
however	O
we	O
do	O
observe	O
failure	O
cases	O
mainly	O
when	O
multiple	O
people	O
are	O
in	O
close	O
proximity	O
.	O
	
Handling	O
multiple	O
people	O
in	O
a	O
single	O
end	B-Task
-	I-Task
to	I-Task
-	I-Task
end	I-Task
architecture	I-Task
is	O
also	O
a	O
challenging	O
problem	O
and	O
an	O
interesting	O
avenue	O
for	O
future	O
work	O
.	O
	
section	O
:	O
	
Published	O
as	O
a	O
conference	O
paper	O
at	O
ICLR	O
2017	O
QUERY	B-Method
-	I-Method
REDUCTION	I-Method
NETWORKS	I-Method
FOR	O
QUESTION	B-Task
ANSWERING	I-Task
	
section	O
:	O
ABSTRACT	O
	
In	O
this	O
paper	O
,	O
we	O
study	O
the	O
problem	O
of	O
question	B-Task
answering	I-Task
when	O
reasoning	O
over	O
multiple	O
facts	O
is	O
required	O
.	O
	
We	O
propose	O
Query	B-Method
-	I-Method
Reduction	I-Method
Network	I-Method
(	O
QRN	B-Method
)	O
,	O
a	O
variant	O
of	O
Recurrent	B-Method
Neural	I-Method
Network	I-Method
(	O
RNN	B-Method
)	O
that	O
effectively	O
handles	O
both	O
short	O
-	O
term	O
(	O
local	O
)	O
and	O
long	O
-	O
term	O
(	O
global	O
)	O
sequential	O
dependencies	O
to	O
reason	O
over	O
multiple	O
facts	O
.	O
	
QRN	B-Method
considers	O
the	O
context	O
sentences	O
as	O
a	O
sequence	O
of	O
state	O
-	O
changing	O
triggers	O
,	O
and	O
reduces	O
the	O
original	O
query	O
to	O
a	O
more	O
informed	O
query	O
as	O
it	O
observes	O
each	O
trigger	O
(	O
context	O
sentence	O
)	O
through	O
time	O
.	O
	
Our	O
experiments	O
show	O
that	O
QRN	B-Method
produces	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
results	O
in	O
bAbI	O
QA	B-Task
and	O
dialog	O
tasks	O
,	O
and	O
in	O
a	O
real	O
goal	O
-	O
oriented	O
dialog	O
dataset	O
.	O
	
In	O
addition	O
,	O
QRN	B-Method
formulation	O
allows	O
parallelization	O
on	O
RNN	B-Method
's	O
time	O
axis	O
,	O
saving	O
an	O
order	O
of	O
magnitude	O
in	O
time	B-Metric
complexity	I-Metric
for	O
training	B-Task
and	O
inference	B-Task
.	O
	
section	O
:	O
INTRODUCTION	O
	
In	O
this	O
paper	O
,	O
we	O
address	O
the	O
problem	O
of	O
question	B-Task
answering	I-Task
(	O
QA	B-Task
)	O
when	O
reasoning	O
over	O
multiple	O
facts	O
is	O
required	O
.	O
	
For	O
example	O
,	O
consider	O
we	O
know	O
that	O
Frogs	O
eat	O
insects	O
and	O
Flies	O
are	O
insects	O
.	O
	
Then	O
answering	O
Do	O
frogs	O
eat	O
flies	O
?	O
	
requires	O
reasoning	O
over	O
both	O
of	O
the	O
above	O
facts	O
.	O
	
Question	B-Task
answering	I-Task
,	O
more	O
specifically	O
context	B-Task
-	I-Task
based	I-Task
QA	I-Task
,	O
has	O
been	O
extensively	O
studied	O
in	O
machine	B-Task
comprehension	I-Task
tasks	I-Task
[	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
.	O
	
However	O
,	O
most	O
of	O
the	O
datasets	O
are	O
primarily	O
focused	O
on	O
lexical	B-Task
and	I-Task
syntactic	I-Task
understanding	I-Task
,	O
and	O
hardly	O
concentrate	O
on	O
inference	B-Task
over	O
multiple	O
facts	O
.	O
	
Recently	O
,	O
several	O
datasets	O
aimed	O
for	O
testing	O
multi	B-Task
-	I-Task
hop	I-Task
reasoning	I-Task
have	O
emerged	O
;	O
among	O
them	O
are	O
story	O
-	O
based	O
QA	B-Task
and	O
the	O
dialog	B-Task
task	I-Task
.	O
	
Recurrent	B-Method
Neural	I-Method
Network	I-Method
(	O
RNN	B-Method
)	O
and	O
its	O
variants	O
,	O
such	O
as	O
Long	B-Method
Short	I-Method
-	I-Method
Term	I-Method
Memory	I-Method
(	O
LSTM	B-Method
)	O
[	O
reference	O
]	O
and	O
Gated	B-Method
Recurrent	I-Method
Unit	I-Method
(	O
GRU	B-Method
)	O
	
[	O
reference	O
]	O
,	O
are	O
popular	O
choices	O
for	O
modeling	B-Task
natural	I-Task
language	I-Task
.	O
	
However	O
,	O
when	O
used	O
for	O
multi	B-Task
-	I-Task
hop	I-Task
reasoning	I-Task
in	O
question	B-Task
answering	I-Task
,	O
purely	O
RNN	B-Method
-	O
based	O
models	O
have	O
shown	O
to	O
perform	O
poorly	O
.	O
	
This	O
is	O
largely	O
due	O
to	O
the	O
fact	O
that	O
RNN	B-Method
's	O
internal	O
memory	O
is	O
inherently	O
unstable	O
over	O
a	O
long	O
term	O
.	O
	
For	O
this	O
reason	O
,	O
most	O
recent	O
approaches	O
in	O
the	O
literature	O
have	O
mainly	O
relied	O
on	O
global	B-Method
attention	I-Method
mechanism	I-Method
and	O
shared	O
external	O
memory	O
[	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
.	O
The	O
attention	B-Method
mechanism	I-Method
allows	O
these	O
models	O
to	O
focus	O
on	O
a	O
single	O
sentence	O
in	O
each	O
layer	O
.	O
	
They	O
can	O
sequentially	O
read	O
multiple	O
relevant	O
sentences	O
from	O
the	O
memory	O
with	O
multiple	O
layers	O
to	O
perform	O
multi	B-Task
-	I-Task
hop	I-Task
reasoning	I-Task
.	O
	
However	O
,	O
one	O
major	O
drawback	O
of	O
these	O
standard	O
attention	B-Method
mechanisms	I-Method
is	O
that	O
they	O
are	O
insensitive	O
to	O
the	O
time	O
step	O
(	O
memory	O
address	O
)	O
of	O
the	O
sentences	O
when	O
accessing	O
them	O
.	O
	
Our	O
proposed	O
model	O
,	O
Query	B-Method
-	I-Method
Reduction	I-Method
Network	I-Method
1	I-Method
(	O
QRN	B-Method
)	O
,	O
is	O
a	O
single	O
recurrent	B-Method
unit	I-Method
that	O
addresses	O
the	O
long	B-Task
-	I-Task
term	I-Task
dependency	I-Task
problem	I-Task
of	O
most	O
RNN	B-Method
-	O
based	O
models	O
by	O
simplifying	O
the	O
recurrent	B-Method
update	I-Method
,	O
while	O
taking	O
the	O
advantage	O
of	O
RNN	B-Method
's	O
capability	O
to	O
model	O
sequential	O
data	O
(	O
Figure	O
1	O
)	O
.	O
	
QRN	B-Method
considers	O
the	O
context	O
sentences	O
as	O
a	O
sequence	O
of	O
state	O
-	O
changing	O
triggers	O
,	O
and	O
transforms	O
(	O
reduces	O
)	O
the	O
original	O
query	O
to	O
a	O
more	O
informed	O
query	O
as	O
it	O
observes	O
each	O
trigger	O
through	O
time	O
.	O
	
For	O
instance	O
in	O
Figure	O
1b	O
,	O
the	O
original	O
question	O
,	O
Where	O
is	O
the	O
apple	O
?	O
,	O
can	O
not	O
be	O
directly	O
answered	O
by	O
any	O
single	O
sentence	O
from	O
the	O
story	O
.	O
	
After	O
observing	O
the	O
first	O
sentence	O
,	O
Sandra	O
got	O
the	O
apple	O
there	O
,	O
QRN	B-Method
transforms	O
the	O
original	O
question	O
to	O
a	O
reduced	O
query	O
Where	O
is	O
Sandra	O
?	O
,	O
which	O
is	O
presumably	O
1	O
Code	O
is	O
publicly	O
available	O
at	O
:	O
seominjoon.github.io	O
/	O
qrn	O
/	O
Figure	O
1	O
:	O
(	O
1a	O
)	O
QRN	B-Method
unit	O
,	O
(	O
	
1b	O
)	O
2	O
-	O
layer	O
	
QRN	B-Method
on	O
5	B-Material
-	I-Material
sentence	I-Material
story	I-Material
,	O
and	O
(	O
1c	O
)	O
entire	O
QA	B-Task
system	O
(	O
QRN	B-Method
and	O
input	B-Method
/	I-Method
output	I-Method
modules	I-Method
)	O
.	O
	
x	O
,	O
q	O
,	O
ŷ	O
are	O
the	O
story	O
,	O
question	O
and	O
predicted	O
answer	O
in	O
natural	O
language	O
,	O
respectively	O
.	O
	
x	O
=	O
x1	O
,	O
.	O
.	O
.	O
	
,	O
xT	O
,	O
q	O
,	O
ŷ	O
are	O
their	O
corresponding	O
vector	B-Method
representations	I-Method
(	O
upright	O
font	O
)	O
.	O
	
α	O
and	O
ρ	O
are	O
update	O
gate	O
and	O
reduce	O
functions	O
,	O
respectively.ŷ	O
is	O
assigned	O
to	O
be	O
h	O
2	O
5	O
,	O
the	O
local	O
query	O
at	O
the	O
last	O
time	O
step	O
in	O
the	O
last	O
layer	O
.	O
	
Also	O
,	O
red	O
-	O
colored	O
text	O
is	O
the	O
inferred	O
meanings	O
of	O
the	O
vectors	O
(	O
see	O
'	O
Interpretations	O
'	O
of	O
Section	O
5.3	O
)	O
.	O
	
easier	O
to	O
answer	O
than	O
the	O
original	O
question	O
given	O
the	O
context	O
provided	O
by	O
the	O
first	O
sentence	O
.	O
	
2	O
Unlike	O
RNN	B-Method
-	O
based	O
models	O
,	O
QRN	B-Method
's	O
candidate	O
state	O
(	O
h	O
t	O
in	O
Figure	O
1a	O
)	O
does	O
not	O
depend	O
on	O
the	O
previous	O
hidden	O
state	O
(	O
h	O
t−1	O
)	O
.	O
	
Compared	O
to	O
memory	B-Method
-	I-Method
based	I-Method
approaches	I-Method
[	O
reference	B-Method
][	I-Method
reference	I-Method
][	I-Method
reference	I-Method
][	I-Method
reference	I-Method
]	O
,	O
QRN	B-Method
can	O
better	O
encodes	O
locality	O
information	O
because	O
it	O
does	O
not	O
use	O
a	O
global	O
memory	O
access	O
controller	O
(	O
circle	O
nodes	O
in	O
Figure	O
2	O
)	O
,	O
and	O
the	O
query	O
updates	O
are	O
performed	O
locally	O
.	O
	
In	O
short	O
,	O
the	O
main	O
contribution	O
of	O
QRN	B-Method
is	O
threefold	O
.	O
	
First	O
,	O
QRN	B-Method
is	O
a	O
simple	O
variant	O
of	O
RNN	B-Method
that	O
reduces	O
the	O
query	O
given	O
the	O
context	O
sentences	O
in	O
a	O
differentiable	O
manner	O
.	O
	
Second	O
,	O
QRN	B-Method
is	O
situated	O
between	O
the	O
attention	B-Method
mechanism	I-Method
and	O
RNN	B-Method
,	O
effectively	O
handling	O
time	B-Task
dependency	I-Task
and	O
long	B-Task
-	I-Task
term	I-Task
dependency	I-Task
problems	I-Task
of	O
each	O
technique	O
,	O
respectively	O
.	O
	
Hence	O
it	O
is	O
well	O
-	O
suited	O
for	O
sequential	B-Material
data	I-Material
with	O
both	O
local	O
and	O
global	O
interactions	O
(	O
note	O
that	O
QRN	B-Method
is	O
not	O
the	O
replacement	O
of	O
RNN	B-Method
,	O
which	O
is	O
arguably	O
better	O
for	O
modeling	O
complex	O
local	O
interactions	O
)	O
.	O
	
Third	O
,	O
unlike	O
most	O
RNN	B-Method
-	O
based	O
models	O
,	O
QRN	B-Method
can	O
be	O
parallelized	O
over	O
time	O
by	O
computing	O
candidate	O
reduced	O
queries	O
(	O
h	O
t	O
)	O
directly	O
from	O
local	O
input	O
queries	O
(	O
q	O
t	O
)	O
and	O
context	O
sentence	O
vectors	O
(	O
x	O
t	O
)	O
.	O
	
In	O
fact	O
,	O
the	O
parallelizability	O
of	O
QRN	B-Method
implies	O
that	O
QRN	B-Method
does	O
not	O
suffer	O
from	O
the	O
vanishing	O
gradient	O
problem	O
of	O
RNN	B-Method
,	O
hence	O
effectively	O
addressing	O
the	O
long	O
-	O
term	O
dependency	O
.	O
	
We	O
experimentally	O
demonstrate	O
these	O
contributions	O
by	O
achieving	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
results	O
on	O
story	O
-	O
based	O
QA	B-Task
and	O
interactive	B-Material
dialog	I-Material
datasets	I-Material
.	O
	
section	O
:	O
MODEL	O
	
In	O
story	O
-	O
based	O
QA	B-Task
(	O
or	O
dialog	B-Material
dataset	I-Material
)	O
,	O
the	O
input	O
is	O
the	O
context	O
as	O
a	O
sequence	O
of	O
sentences	O
(	O
story	O
or	O
past	O
conversations	O
)	O
and	O
a	O
question	O
in	O
natural	B-Material
language	I-Material
(	O
equivalent	O
to	O
the	O
user	O
's	O
last	O
utterance	O
in	O
the	O
dialog	O
)	O
.	O
	
The	O
output	O
is	O
the	O
predicted	O
answer	O
to	O
the	O
question	O
in	O
natural	B-Material
language	I-Material
(	O
the	O
system	O
's	O
next	O
utterance	O
in	O
the	O
dialog	O
)	O
.	O
	
The	O
only	O
supervision	O
provided	O
during	O
training	O
is	O
the	O
answer	O
to	O
the	O
question	O
.	O
	
In	O
this	O
paper	O
we	O
particularly	O
focus	O
on	O
end	B-Task
-	I-Task
to	I-Task
-	I-Task
end	I-Task
solutions	I-Task
,	O
i.e.	O
,	O
the	O
only	O
supervision	O
comes	O
from	O
questions	O
and	O
answers	O
,	O
and	O
we	O
restrain	O
from	O
using	O
manually	O
defined	O
rules	O
or	O
external	O
language	O
resources	O
,	O
such	O
as	O
lexicon	B-Method
or	O
dependency	B-Method
parser	I-Method
.	O
	
Let	O
x	O
1	O
,	O
.	O
.	O
.	O
	
,	O
x	O
T	O
denote	O
the	O
sequence	O
of	O
sentences	O
,	O
where	O
T	O
is	O
the	O
number	O
of	O
sentences	O
in	O
the	O
story	O
,	O
and	O
let	O
q	O
denote	O
the	O
question	O
.	O
	
Letŷ	O
denote	O
the	O
predicted	O
answer	O
,	O
and	O
y	O
denote	O
the	O
true	O
answer	O
.	O
	
Our	O
proposed	O
system	O
for	O
end	O
-	O
to	O
-	O
end	O
QA	B-Task
task	O
is	O
divided	O
into	O
three	O
modules	O
(	O
Figure	O
1c	O
)	O
:	O
input	B-Method
module	I-Method
,	O
QRN	B-Method
layers	O
,	O
and	O
output	B-Method
module	I-Method
.	O
	
Input	B-Method
module	I-Method
.	O
	
Input	O
module	O
maps	O
each	O
sentence	O
	
x	O
t	O
and	O
the	O
question	O
q	O
to	O
d	O
-	O
dimensional	O
vector	O
space	O
,	O
x	O
t	O
∈	O
R	O
d	O
and	O
q	O
t	O
∈	O
R	O
d	O
.	O
	
We	O
adopt	O
a	O
previous	O
solution	O
for	O
the	O
input	O
module	O
(	O
details	O
in	O
Section	O
5	O
)	O
.	O
	
QRN	B-Method
layers	O
.	O
	
QRN	B-Method
layers	O
use	O
the	O
sentence	O
vectors	O
and	O
the	O
question	O
vector	O
from	O
the	O
input	O
module	O
to	O
obtain	O
the	O
predicted	O
answer	O
in	O
vector	O
space	O
,	O
ŷ	O
∈	O
R	O
d	O
.	O
	
A	O
QRN	B-Method
layer	O
refers	O
to	O
the	O
recurrent	B-Method
application	I-Method
of	O
a	O
QRN	B-Method
unit	O
,	O
which	O
can	O
be	O
considered	O
as	O
a	O
variant	O
of	O
RNN	B-Method
with	O
two	O
inputs	O
,	O
two	O
outputs	O
,	O
and	O
a	O
hidden	O
state	O
(	O
reduced	O
query	O
)	O
,	O
all	O
of	O
which	O
operate	O
in	O
vector	O
space	O
.	O
	
The	O
details	O
of	O
the	O
QRN	B-Method
module	O
is	O
explained	O
throughout	O
this	O
section	O
(	O
2.1	O
,	O
2.2	O
)	O
.	O
	
Output	B-Method
module	I-Method
.	O
	
Output	B-Method
module	I-Method
mapsŷ	O
obtained	O
from	O
QRN	B-Method
to	O
a	O
natural	O
language	O
answerŷ	O
.	O
	
Similar	O
to	O
the	O
input	O
module	O
,	O
we	O
adopt	O
a	O
standard	O
solution	O
for	O
the	O
output	O
module	O
(	O
details	O
in	O
Section	O
5	O
)	O
.	O
	
We	O
first	O
formally	O
define	O
the	O
base	B-Method
model	I-Method
of	O
a	O
QRN	B-Method
unit	O
,	O
and	O
then	O
we	O
explain	O
how	O
we	O
connect	O
the	O
input	O
and	O
output	O
modules	O
to	O
it	O
(	O
Section	O
2.1	O
)	O
.	O
	
We	O
also	O
present	O
a	O
few	O
extensions	O
to	O
the	O
network	O
that	O
can	O
improve	O
QRN	B-Method
's	O
performance	O
(	O
Section	O
2.2	O
)	O
.	O
	
Finally	O
,	O
we	O
show	O
that	O
QRN	B-Method
can	O
be	O
parallelized	O
over	O
time	O
,	O
giving	O
computational	B-Metric
advantage	O
over	O
most	O
RNN	B-Method
-	O
based	O
models	O
by	O
one	O
order	O
of	O
magnitude	O
(	O
Section	O
3	O
)	O
.	O
	
section	O
:	O
QRN	B-Method
UNIT	O
	
As	O
an	O
RNN	B-Method
-	O
based	O
model	O
,	O
QRN	B-Method
is	O
a	O
single	O
recurrent	B-Method
unit	I-Method
that	O
updates	O
its	O
hidden	O
state	O
(	O
reduced	O
query	O
)	O
through	O
time	O
and	O
layers	O
.	O
	
Figure	O
1a	O
depicts	O
the	O
schematic	O
structure	O
of	O
a	O
QRN	B-Method
unit	O
,	O
and	O
Figure	O
1b	O
demonstrates	O
how	O
layers	O
are	O
stacked	O
.	O
	
A	O
QRN	B-Method
unit	O
accepts	O
two	O
inputs	O
(	O
local	O
query	O
vector	O
q	O
t	O
∈	O
R	O
d	O
and	O
sentence	O
vector	O
x	O
t	O
∈	O
R	O
d	O
)	O
,	O
and	O
two	O
outputs	O
(	O
reduced	O
query	O
vector	O
h	O
t	O
∈	O
R	O
d	O
,	O
which	O
is	O
similar	O
to	O
the	O
hidden	O
state	O
in	O
RNN	B-Method
,	O
and	O
the	O
sentence	O
vector	O
x	O
t	O
from	O
the	O
input	O
without	O
modification	O
)	O
.	O
	
The	O
local	O
query	O
vector	O
is	O
not	O
necessarily	O
identical	O
to	O
the	O
original	O
query	O
(	O
question	O
)	O
	
vector	O
q.	O
	
In	O
order	O
to	O
compute	O
the	O
outputs	O
,	O
we	O
use	O
update	O
gate	O
function	O
α	O
:	O
	
Intuitively	O
,	O
the	O
update	O
gate	O
function	O
measures	O
the	O
relevance	O
between	O
the	O
sentence	O
and	O
the	O
local	O
query	O
and	O
is	O
used	O
to	O
update	O
the	O
hidden	O
state	O
.	O
	
The	O
reduce	B-Method
function	I-Method
transforms	O
the	O
local	O
query	O
input	O
to	O
a	O
candidate	O
state	O
which	O
is	O
a	O
new	O
reduced	O
(	O
easier	O
)	O
query	O
given	O
the	O
sentence	O
.	O
	
The	O
outputs	O
are	O
calculated	O
with	O
the	O
following	O
equations	O
:	O
	
where	O
z	O
t	O
is	O
the	O
scalar	O
update	O
gate	O
,	O
h	O
t	O
is	O
the	O
candidate	O
reduced	O
query	O
,	O
and	O
h	O
t	O
is	O
the	O
final	O
reduced	O
query	O
at	O
time	O
step	O
t	O
,	O
σ	O
(	O
·	O
)	O
is	O
sigmoid	O
activation	O
,	O
tanh	O
(	O
·	O
)	O
	
is	O
hyperboolic	O
tangent	O
activation	O
	
(	O
applied	O
element	O
-	O
wise	O
)	O
,	O
	
•	O
	
is	O
element	B-Method
-	I-Method
wise	I-Method
vector	I-Method
multiplication	I-Method
,	O
and	O
[	O
;	O
]	O
is	O
vector	O
concatenation	O
along	O
the	O
row	O
.	O
	
As	O
a	O
base	O
case	O
,	O
h	O
0	O
=	O
0	O
.	O
	
Here	O
we	O
have	O
explicitly	O
defined	O
α	O
and	O
ρ	O
,	O
but	O
they	O
can	O
be	O
any	O
reasonable	O
differentiable	O
functions	O
.	O
	
The	O
update	B-Method
gate	I-Method
is	O
similar	O
to	O
the	O
global	B-Method
attention	I-Method
mechanism	I-Method
[	O
reference	O
][	O
reference	O
]	O
in	O
that	O
it	O
measures	O
the	O
similarity	O
between	O
the	O
sentence	O
(	O
a	O
memory	O
slot	O
)	O
and	O
the	O
query	O
.	O
	
However	O
,	O
a	O
significant	O
difference	O
is	O
that	O
the	O
update	O
gate	O
is	O
computed	O
using	O
sigmoid	B-Method
(	I-Method
σ	I-Method
)	I-Method
function	I-Method
on	O
the	O
current	O
memory	O
slot	O
only	O
(	O
hence	O
internally	O
embedded	O
within	O
the	O
unit	O
)	O
,	O
whereas	O
the	O
global	O
attention	O
is	O
computed	O
using	O
softmax	B-Method
function	I-Method
over	O
the	O
entire	O
memory	O
(	O
hence	O
globally	O
defined	O
)	O
.	O
	
The	O
update	B-Method
gate	I-Method
can	O
be	O
rather	O
considered	O
as	O
local	O
sigmoid	O
attention	O
.	O
	
section	O
:	O
Stacking	B-Method
layers	I-Method
	
We	O
just	O
showed	O
the	O
single	O
-	O
layer	O
case	O
of	O
QRN	B-Method
,	O
but	O
QRN	B-Method
with	O
multiple	O
layers	O
is	O
able	O
to	O
perform	O
reasoning	O
over	O
multiple	O
facts	O
more	O
effectively	O
,	O
as	O
shown	O
in	O
the	O
example	O
of	O
Figure	O
1b	O
.	O
	
In	O
order	O
to	O
stack	O
several	O
layers	O
of	O
QRN	B-Method
,	O
the	O
outputs	O
of	O
the	O
current	O
layer	O
are	O
used	O
as	O
the	O
inputs	O
to	O
the	O
next	O
layer	O
.	O
	
That	O
is	O
,	O
using	O
superscript	O
k	O
to	O
denote	O
the	O
current	O
layer	O
's	O
index	O
(	O
assuming	O
1	B-Task
-	I-Task
based	I-Task
indexing	I-Task
)	O
,	O
we	O
let	O
q	O
k	O
+	O
1	O
t	O
=	O
	
h	O
	
k	O
	
t	O
.	O
	
Note	O
that	O
x	O
t	O
is	O
passed	O
to	O
the	O
next	O
layer	O
without	O
any	O
modification	O
,	O
so	O
we	O
do	O
not	O
put	O
a	O
layer	O
index	O
on	O
it	O
.	O
	
Bi	O
-	O
direction	O
.	O
	
So	O
far	O
we	O
have	O
assumed	O
that	O
QRN	B-Method
only	O
needs	O
to	O
look	O
at	O
past	O
sentences	O
,	O
whereas	O
often	O
times	O
,	O
query	O
answers	O
can	O
depend	O
on	O
future	O
sentences	O
.	O
	
For	O
instance	O
,	O
consider	O
a	O
sentence	O
	
"	O
John	O
dropped	O
the	O
football	O
.	O
	
"	O
	
at	O
time	O
	
t.	O
	
Then	O
,	O
even	O
if	O
there	O
is	O
no	O
mention	O
about	O
the	O
"	O
football	O
"	O
in	O
the	O
past	O
(	O
at	O
time	O
i	O
<	O
t	O
)	O
	
,	O
it	O
can	O
be	O
implied	O
that	O
"	O
John	O
"	O
has	O
the	O
"	O
football	O
"	O
at	O
the	O
current	O
time	O
	
t.	O
	
In	O
order	O
to	O
incorporate	O
the	O
future	O
dependency	O
,	O
we	O
obtain	O
−	O
→	O
h	O
t	O
and	O
←	O
	
−	O
h	O
t	O
in	O
both	O
forward	O
and	O
backward	O
directions	O
,	O
respectively	O
,	O
using	O
Equation	O
3	O
.	O
	
We	O
then	O
add	O
them	O
together	O
to	O
get	O
q	O
t	O
for	O
the	O
next	O
layer	O
.	O
	
That	O
is	O
,	O
[	O
reference	O
]	O
are	O
shared	O
between	O
the	O
two	O
directions	O
.	O
	
Connecting	O
input	O
and	O
output	O
modules	O
.	O
	
Figure	O
1c	O
depicts	O
how	O
QRN	B-Method
is	O
connected	O
with	O
the	O
input	O
and	O
output	O
modules	O
.	O
	
In	O
the	O
first	O
layer	O
of	O
QRN	B-Method
,	O
q	O
1	O
t	O
=	O
q	O
for	O
all	O
t	O
,	O
where	O
q	O
is	O
obtained	O
from	O
the	O
input	O
module	O
by	O
processing	O
the	O
natural	O
language	O
question	O
input	O
	
q.	O
	
x	O
t	O
is	O
also	O
obtained	O
from	O
x	O
t	O
by	O
the	O
same	O
input	O
module	O
.	O
	
The	O
output	O
at	O
the	O
last	O
time	O
step	O
in	O
the	O
last	O
layer	O
is	O
passed	O
to	O
the	O
output	B-Method
module	I-Method
.	O
	
That	O
is	O
,	O
y	O
=	O
h	O
K	O
t	O
where	O
K	O
represent	O
the	O
number	O
of	O
layers	O
in	O
the	O
network	O
.	O
	
Then	O
the	O
output	O
module	O
gives	O
the	O
predicted	O
answerŷ	O
in	O
natural	O
language	O
.	O
	
section	O
:	O
EXTENSIONS	O
	
Here	O
we	O
introduce	O
a	O
few	O
extensions	O
of	O
QRN	B-Method
,	O
and	O
later	O
in	O
our	O
experiments	O
,	O
we	O
test	O
QRN	B-Method
's	O
performance	O
with	O
and	O
without	O
each	O
of	O
these	O
extensions	O
.	O
	
Reset	O
gate	O
.	O
	
Inspired	O
by	O
GRU	O
[	O
reference	O
]	O
,	O
we	O
found	O
that	O
it	O
is	O
useful	O
to	O
allow	O
the	O
QRN	B-Method
unit	O
to	O
reset	O
(	O
nullify	O
)	O
	
the	O
candidate	O
reduced	O
query	O
(	O
i.e.	O
,	O
h	O
t	O
)	O
when	O
necessary	O
.	O
	
For	O
this	O
we	O
use	O
a	O
reset	O
gate	O
function	O
β	O
:	O
	
,	O
which	O
can	O
be	O
defined	O
similarly	O
to	O
the	O
update	O
gate	O
function	O
:	O
	
where	O
W	O
(	O
r	O
)	O
∈	O
R	O
1×d	O
is	O
a	O
weight	O
matrix	O
,	O
and	O
b	O
(	O
r	O
)	O
∈	O
R	O
is	O
a	O
bias	O
term	O
.	O
	
Equation	O
3	O
is	O
rewritten	O
as	O
	
Note	O
that	O
we	O
do	O
not	O
use	O
the	O
reset	O
gate	O
in	O
the	O
last	O
layer	O
.	O
	
Vector	O
gates	O
.	O
	
As	O
in	O
LSTM	B-Method
and	O
GRU	O
,	O
update	O
and	O
reset	O
gates	O
can	O
be	O
vectors	O
instead	O
of	O
scalar	O
values	O
for	O
fine	B-Task
-	I-Task
controlled	I-Task
gating	I-Task
.	O
	
For	O
vector	B-Task
gates	I-Task
,	O
we	O
modify	O
the	O
row	O
dimension	O
of	O
weights	O
and	O
biases	O
in	O
Equation	O
1	O
and	O
5	O
from	O
1	O
to	O
d.	O
	
Then	O
we	O
obtain	O
z	O
t	O
,	O
r	O
t	O
	
∈	O
R	O
d	O
(	O
instead	O
of	O
z	O
t	O
,	O
r	O
t	O
∈	O
R	O
)	O
,	O
and	O
these	O
can	O
be	O
element	O
-	O
wise	O
multiplied	O
(	O
•	O
)	O
instead	O
of	O
being	O
broadcasted	O
in	O
Equation	O
3	O
and	O
6	O
.	O
	
section	O
:	O
PARALLELIZATION	B-Task
	
An	O
important	O
advantage	O
of	O
QRN	B-Method
is	O
that	O
the	O
recurrent	O
updates	O
in	O
Equation	O
3	O
and	O
5	O
can	O
be	O
computed	O
in	O
parallel	O
across	O
time	O
.	O
	
This	O
is	O
in	O
contrast	O
with	O
most	O
RNN	B-Method
-	O
based	O
models	O
that	O
can	O
not	O
be	O
parallelized	O
,	O
where	O
computing	O
the	O
candidate	O
hidden	O
state	O
at	O
time	O
t	O
explicitly	O
requires	O
the	O
previous	O
hidden	O
state	O
.	O
	
In	O
QRN	B-Method
,	O
the	O
final	O
reduced	O
queries	O
(	O
h	O
t	O
)	O
can	O
be	O
decomposed	O
into	O
computing	O
over	O
candidate	O
reduced	O
queries	O
(	O
h	O
t	O
)	O
,	O
without	O
looking	O
at	O
the	O
previous	O
reduced	O
query	O
.	O
	
Here	O
we	O
primarily	O
show	O
that	O
the	O
query	B-Task
update	I-Task
in	O
Equation	O
3	O
can	O
be	O
parallelized	O
by	O
rewriting	O
the	O
equation	O
with	O
matrix	B-Method
operations	I-Method
.	O
	
The	O
extension	O
to	O
Equation	O
5	O
is	O
straightforward	O
.	O
	
The	O
proof	O
for	O
QRN	B-Method
with	O
vector	O
gates	O
is	O
shown	O
in	O
Appendix	O
B.	O
	
The	O
recursive	O
definition	O
of	O
Equation	O
3	O
can	O
be	O
explicitly	O
written	O
as	O
	
Let	O
b	O
i	O
=	O
	
log	O
(	O
1	O
	
−	O
z	O
i	O
)	O
for	O
brevity	O
.	O
	
Then	O
we	O
can	O
rewrite	O
Equation	O
7	O
as	O
the	O
following	O
equation	O
:	O
[	O
reference	O
]	O
Figure	O
2	O
:	O
The	O
schematics	O
of	O
QRN	B-Method
and	O
the	O
two	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
models	O
,	O
End	B-Method
-	I-Method
to	I-Method
-	I-Method
End	I-Method
Memory	I-Method
Networks	I-Method
(	O
N2N	B-Method
)	O
and	O
Improved	B-Method
Dynamic	I-Method
Memory	I-Method
Networks	I-Method
(	O
DMN	B-Method
+	I-Method
)	O
,	O
simplified	O
to	O
emphasize	O
the	O
differences	O
among	O
the	O
models	O
.	O
	
AGRU	B-Method
is	O
a	O
variant	O
of	O
GRU	B-Method
where	O
the	O
update	O
gate	O
is	O
replaced	O
with	O
soft	O
attention	O
,	O
proposed	O
by	O
[	O
reference	O
]	O
.	O
	
where	O
L	O
,	O
L	O
∈	O
R	O
T	O
×T	O
are	O
lower	O
and	O
strictly	O
lower	O
triangular	O
matrices	O
of	O
1	O
's	O
,	O
respectively	O
,	O
•	O
is	O
elementwise	O
multiplication	O
,	O
and	O
B	O
is	O
a	O
matrix	O
where	O
T	O
b	O
's	O
are	O
tiled	O
across	O
the	O
column	O
,	O
i.	O
	
section	O
:	O
RELATED	O
WORK	O
	
QRN	B-Method
is	O
inspired	O
by	O
RNN	B-Method
-	O
based	O
models	O
with	O
gating	B-Method
mechanism	I-Method
,	O
such	O
as	O
LSTM	B-Method
[	O
reference	O
]	O
and	O
GRU	B-Method
[	O
reference	O
]	O
.	O
	
While	O
GRU	O
and	O
LSTM	B-Method
use	O
the	O
previous	O
hidden	O
state	O
and	O
the	O
current	O
input	O
to	O
obtain	O
the	O
candidate	O
hidden	O
state	O
,	O
QRN	B-Method
only	O
uses	O
the	O
current	O
two	O
inputs	O
to	O
obtain	O
the	O
candidate	O
reduced	O
query	O
(	O
equivalent	O
to	O
candidate	O
hidden	O
state	O
)	O
.	O
	
We	O
conjecture	O
that	O
this	O
not	O
only	O
gives	O
computational	B-Metric
advantage	O
via	O
parallelization	B-Method
,	O
but	O
also	O
makes	O
training	B-Task
easier	O
,	O
i.e.	O
,	O
avoiding	O
vanishing	O
gradient	O
(	O
which	O
is	O
critical	O
for	O
long	O
-	O
term	O
dependency	O
)	O
,	O
overfitting	O
(	O
by	O
simplifying	O
the	O
model	O
)	O
,	O
and	O
converging	O
to	O
local	O
minima	O
.	O
	
The	O
idea	O
of	O
structurally	B-Method
simplifying	I-Method
(	I-Method
constraining	I-Method
)	I-Method
RNNs	I-Method
for	O
learning	B-Task
longer	I-Task
-	I-Task
term	I-Task
patterns	I-Task
has	O
been	O
explored	O
in	O
recent	O
previous	O
work	O
,	O
such	O
as	O
Structurally	B-Method
Constrained	I-Method
Recurrent	I-Method
Network	I-Method
[	O
reference	O
]	O
and	O
Strongly	O
-	O
Typed	O
Recurrent	B-Method
Neural	I-Method
Network	I-Method
(	O
STRNN	B-Method
)	O
	
[	O
reference	O
]	O
.	O
QRN	B-Method
is	O
similar	O
to	O
STRNN	B-Method
in	O
that	O
both	O
architectures	O
use	O
gating	B-Method
mechanism	I-Method
,	O
and	O
the	O
gates	O
and	O
the	O
candidate	O
hidden	O
states	O
do	O
not	O
depend	O
on	O
the	O
previous	O
hidden	O
states	O
,	O
which	O
simplifies	O
the	O
recurrent	O
relation	O
.	O
	
However	O
,	O
QRN	B-Method
can	O
be	O
distinguished	O
from	O
STRNN	B-Method
in	O
three	O
ways	O
.	O
	
First	O
,	O
QRN	B-Method
's	O
update	O
gate	O
simulates	O
attention	B-Method
mechanism	I-Method
,	O
measuring	O
the	O
relevance	O
between	O
the	O
input	O
sentence	O
and	O
query	O
.	O
	
On	O
the	O
other	O
hand	O
,	O
the	O
gates	O
in	O
STRNN	B-Method
can	O
be	O
considered	O
as	O
the	O
simplification	O
of	O
LSTM	B-Method
/	O
GRU	O
by	O
removing	O
their	O
dependency	O
on	O
previous	O
hidden	O
state	O
.	O
	
Second	O
,	O
QRN	B-Method
is	O
an	O
RNN	B-Method
that	O
is	O
natively	O
compatible	O
with	O
context	O
-	O
based	O
QA	B-Task
tasks	O
,	O
where	O
the	O
QRN	B-Method
unit	O
accepts	O
two	O
inputs	O
,	O
i.e.	O
each	O
context	O
sentence	O
and	O
query	O
.	O
	
This	O
is	O
distinct	O
from	O
STRNN	B-Method
which	O
has	O
only	O
one	O
input	O
.	O
	
Third	O
,	O
we	O
show	O
that	O
QRN	B-Method
is	O
timewise	O
-	O
parallelizable	O
on	O
GPUs	B-Method
.	O
	
Our	O
parallelization	B-Method
algorithm	I-Method
is	O
also	O
applicable	O
to	O
STRNN	B-Method
.	O
	
End	B-Method
-	I-Method
to	I-Method
-	I-Method
end	I-Method
Memory	I-Method
Network	I-Method
(	O
N2N	B-Method
)	O
[	O
reference	O
]	O
uses	O
external	O
memory	O
with	O
multi	B-Method
-	I-Method
layer	I-Method
attention	I-Method
mechanism	I-Method
to	O
focus	O
on	O
sentences	O
that	O
are	O
relevant	O
to	O
the	O
question	O
.	O
	
There	O
are	O
two	O
key	O
differences	O
between	O
N2N	B-Method
and	O
our	O
QRN	B-Method
.	O
	
First	O
,	O
N2N	B-Method
summarizes	O
the	O
entire	O
memory	O
in	O
each	O
layer	O
to	O
control	O
the	O
attention	O
in	O
the	O
next	O
layer	O
(	O
circle	O
nodes	O
in	O
Figure	O
2b	O
)	O
.	O
	
Instead	O
,	O
QRN	B-Method
does	O
not	O
have	O
any	O
controller	O
node	O
(	O
Figure	O
2a	O
)	O
and	O
is	O
able	O
to	O
focus	O
on	O
relevant	O
sentences	O
through	O
the	O
update	O
gate	O
that	O
is	O
internally	O
embodied	O
within	O
its	O
unit	O
.	O
	
Second	O
,	O
N2N	B-Method
adds	O
time	O
-	O
dependent	O
trainable	O
weights	O
to	O
the	O
sentence	B-Method
representations	I-Method
to	O
model	O
the	O
time	O
dependency	O
of	O
the	O
sentences	O
(	O
as	O
discussed	O
in	O
Section	O
1	O
)	O
.	O
	
QRN	B-Method
does	O
not	O
need	O
such	O
additional	O
weights	O
as	O
its	O
inherent	O
RNN	B-Method
architecture	O
allows	O
QRN	B-Method
to	O
effectively	O
model	O
the	O
time	O
dependency	O
.	O
	
Neural	B-Method
Reasoner	I-Method
[	O
reference	O
]	O
and	O
Gated	B-Method
End	I-Method
-	I-Method
toend	I-Method
Memory	I-Method
Network	I-Method
[	O
reference	O
]	O
)	O
are	O
variants	O
of	O
MemN2N	B-Method
that	O
share	O
its	O
fundamental	O
characteristics	O
.	O
	
Improved	B-Method
Dynamic	I-Method
Memory	I-Method
Network	I-Method
(	O
DMN	O
+	O
)	O
[	O
reference	O
]	O
uses	O
the	O
hybrid	O
of	O
the	O
attention	B-Method
mechanism	I-Method
and	O
the	O
RNN	B-Method
architecture	O
to	O
model	O
the	O
sequence	O
of	O
sentences	O
.	O
	
It	O
consists	O
of	O
two	O
distinct	O
GRUs	B-Method
,	O
one	O
for	O
the	O
time	O
axis	O
(	O
rectangle	O
nodes	O
in	O
Figure	O
2c	O
)	O
and	O
one	O
for	O
the	O
layer	O
axis	O
(	O
circle	O
nodes	O
in	O
Figure	O
2c	O
)	O
.	O
	
Note	O
that	O
the	O
update	O
gate	O
of	O
the	O
GRU	B-Method
for	O
the	O
time	O
axis	O
is	O
replaced	O
with	O
external	O
softmax	O
attention	O
weights	O
.	O
	
DMN	B-Method
+	I-Method
uses	O
the	O
time	B-Method
-	I-Method
axis	I-Method
GRU	I-Method
to	O
summarizes	O
the	O
entire	O
memory	O
in	O
each	O
layer	O
,	O
and	O
then	O
the	O
layer	O
-	O
axis	O
GRU	B-Method
controls	O
the	O
attention	O
weights	O
in	O
each	O
layer	O
.	O
	
In	O
contrast	O
,	O
QRN	B-Method
is	O
simply	O
a	O
single	O
recurrent	B-Method
unit	I-Method
without	O
any	O
controller	O
node	O
.	O
	
section	O
:	O
EXPERIMENTS	O
	
5.1	O
DATA	O
bAbI	O
story	O
-	O
based	O
QA	B-Task
dataset	O
bAbI	O
story	O
-	O
based	O
QA	B-Task
dataset	O
is	O
composed	O
of	O
20	O
different	O
tasks	O
(	O
Appendix	O
A	O
)	O
,	O
each	O
of	O
which	O
has	O
1	O
,	O
000	O
(	O
1k	O
)	O
synthetically	O
-	O
generated	O
story	O
-	O
question	O
pair	O
.	O
	
A	O
story	O
can	O
be	O
as	O
short	O
as	O
two	O
sentences	O
and	O
as	O
long	O
as	O
200	O
+	O
sentences	O
.	O
	
A	O
system	O
is	O
evaluated	O
on	O
the	O
accuracy	B-Metric
of	O
getting	O
the	O
correct	O
answers	O
to	O
the	O
questions	O
.	O
	
The	O
answers	O
are	O
single	O
words	O
or	O
lists	O
(	O
e.g.	O
"	O
football	O
,	O
apple	O
"	O
)	O
.	O
	
Answering	O
questions	O
in	O
each	O
task	O
requires	O
selecting	O
a	O
set	O
of	O
relevant	O
sentences	O
and	O
applying	O
different	O
kinds	O
of	O
logical	B-Method
reasoning	I-Method
over	O
them	O
.	O
	
The	O
dataset	O
also	O
includes	O
10k	O
training	O
data	O
(	O
for	O
each	O
task	O
)	O
,	O
which	O
allows	O
training	O
more	O
complex	O
models	O
.	O
	
Note	O
that	O
DMN	B-Method
+	I-Method
[	O
reference	O
]	O
only	O
reports	O
on	O
the	O
10k	O
dataset	O
.	O
	
bAbI	B-Material
dialog	I-Material
dataset	I-Material
bAbI	I-Material
dialog	I-Material
dataset	I-Material
consists	O
of	O
5	O
different	O
tasks	O
(	O
Table	O
3	O
)	O
,	O
each	O
of	O
which	O
has	O
1k	O
synthetically	O
-	O
generated	O
goal	O
-	O
oriented	O
dialogs	O
between	O
a	O
user	O
and	O
the	O
system	O
in	O
the	O
domain	O
of	O
restaurant	B-Task
reservation	I-Task
.	O
	
Each	O
dialog	O
is	O
as	O
long	O
as	O
96	O
utterances	O
and	O
comes	O
with	O
external	O
knowledge	O
base	O
(	O
KB	O
)	O
providing	O
information	O
of	O
each	O
restaurant	O
.	O
	
The	O
authors	O
also	O
provide	O
Out	B-Method
-	I-Method
Of	I-Method
-	I-Method
Vocabulary	I-Method
(	O
OOV	B-Method
)	O
version	O
of	O
the	O
dataset	O
,	O
where	O
many	O
of	O
the	O
words	O
and	O
KB	O
keywords	O
in	O
test	O
data	O
are	O
not	O
seen	O
during	O
training	O
.	O
	
A	O
system	O
is	O
evaluated	O
on	O
the	O
accuracy	B-Metric
of	O
its	O
response	O
to	O
each	O
utterance	O
of	O
the	O
user	O
,	O
choosing	O
from	O
up	O
to	O
2500	O
possible	O
candidate	O
responses	O
.	O
	
A	O
system	O
is	O
required	O
not	O
only	O
to	O
understand	O
the	O
user	O
's	O
request	O
but	O
also	O
refer	O
to	O
previous	O
conversations	O
in	O
order	O
to	O
obtain	O
the	O
context	O
information	O
of	O
the	O
current	O
conversation	O
.	O
	
transformed	O
the	O
Second	O
Dialog	B-Material
State	I-Material
Tracking	I-Material
Challenge	I-Material
(	O
DSTC2	B-Material
)	O
dataset	O
[	O
reference	O
]	O
into	O
the	O
same	O
format	O
as	O
the	O
bAbI	B-Material
dialog	I-Material
dataset	I-Material
,	O
for	O
the	O
measurement	O
of	O
performance	O
on	O
a	O
real	O
dataset	O
.	O
	
Each	O
dialog	O
can	O
be	O
as	O
long	O
as	O
800	O
+	O
utterances	O
,	O
and	O
a	O
system	O
needs	O
to	O
choose	O
from	O
2407	O
possible	O
candidate	O
responses	O
for	O
each	O
utterance	O
of	O
the	O
user	O
.	O
	
Note	O
that	O
the	O
evaluation	B-Metric
metric	I-Metric
of	O
the	O
original	O
DSTC2	B-Material
is	O
different	O
from	O
that	O
of	O
the	O
transformed	O
DSTC2	B-Material
,	O
so	O
previous	O
work	O
on	O
the	O
original	O
DSTC2	B-Material
should	O
not	O
be	O
directly	O
compared	O
to	O
our	O
work	O
.	O
	
We	O
will	O
refer	O
to	O
this	O
transformed	O
DSTC2	B-Material
dataset	O
by	O
"	O
Task	O
6	O
"	O
of	O
dialog	O
dataset	O
.	O
	
section	O
:	O
DSTC2	B-Material
(	O
Task	O
6	O
)	O
dialog	O
dataset	O
	
section	O
:	O
MODEL	O
DETAILS	O
	
Input	B-Method
Module	I-Method
.	O
	
In	O
the	O
input	O
module	O
,	O
we	O
are	O
given	O
sentences	O
(	O
previous	O
conversations	O
in	O
dialog	O
)	O
x	O
t	O
and	O
a	O
question	O
(	O
most	O
recent	O
user	O
utterance	O
)	O
q	O
,	O
and	O
we	O
want	O
to	O
obtain	O
their	O
vector	B-Method
representations	I-Method
,	O
x	O
t	O
,	O
q	O
∈	O
R	O
d	O
.	O
	
We	O
use	O
a	O
trainable	B-Method
embedding	I-Method
matrix	I-Method
	
A	O
∈	O
R	O
d×V	O
to	O
encode	O
the	O
one	O
-	O
hot	O
vector	O
of	O
each	O
word	O
	
x	O
tj	O
in	O
each	O
sentence	O
x	O
t	O
into	O
a	O
d	O
-	O
dimensional	O
vector	O
x	O
tj	O
∈	O
R	O
d	O
.	O
	
Then	O
the	O
sentence	B-Method
representation	I-Method
x	O
t	O
is	O
obtained	O
by	O
Position	B-Method
Encoder	I-Method
.	O
	
The	O
same	O
encoder	O
with	O
the	O
same	O
embedding	O
matrix	O
is	O
also	O
used	O
to	O
obtain	O
the	O
question	O
vector	O
q	O
from	O
q.	O
	
Output	B-Method
Module	I-Method
for	O
story	O
-	O
based	O
QA	B-Task
.	O
	
In	O
the	O
output	O
module	O
,	O
we	O
are	O
given	O
the	O
vector	B-Method
representation	I-Method
of	O
the	O
predicted	O
answerŷ	O
and	O
we	O
want	O
to	O
obtain	O
the	O
natural	O
language	O
form	O
of	O
the	O
answer	O
,	O
	
ŷ	O
.	O
	
We	O
use	O
a	O
V	B-Method
-	I-Method
way	I-Method
single	I-Method
-	I-Method
layer	I-Method
softmax	I-Method
classifier	I-Method
to	O
mapŷ	O
to	O
a	O
V	O
-	O
dimensional	O
sparse	O
vector	O
,	O
v	O
	
=	O
softmax	O
W	O
(	O
y	O
)	O
ŷ	O
∈	O
R	O
V	O
,	O
where	O
W	O
(	O
y	O
)	O
∈	O
R	O
V	O
×d	O
is	O
a	O
weight	O
matrix	O
.	O
	
Then	O
the	O
final	O
answerŷ	O
is	O
simply	O
the	O
argmax	O
word	O
inv	O
.	O
	
To	O
handle	O
questions	O
with	O
multiple	O
-	O
word	O
answers	O
,	O
we	O
consider	O
each	O
of	O
them	O
as	O
a	O
single	O
word	O
that	O
contains	O
punctuations	O
such	O
as	O
space	O
and	O
comma	O
,	O
and	O
put	O
it	O
in	O
the	O
vocabulary	O
.	O
	
Output	B-Method
Module	I-Method
for	O
dialog	B-Task
.	O
	
We	O
use	O
a	O
fixed	O
number	O
single	B-Method
-	I-Method
layer	I-Method
softmax	I-Method
classifiers	I-Method
,	O
each	O
of	O
which	O
is	O
similar	O
to	O
that	O
of	O
the	O
sotry	O
-	O
based	O
QA	B-Task
model	O
,	O
to	O
sequentially	O
output	O
each	O
word	O
of	O
the	O
system	O
's	O
response	O
.	O
	
While	O
it	O
is	O
similar	O
in	O
spirit	O
to	O
the	O
RNN	B-Method
decoder	O
[	O
reference	O
]	O
,	O
our	O
output	B-Method
module	I-Method
does	O
not	O
have	O
a	O
recurrent	B-Method
hidden	I-Method
state	I-Method
or	I-Method
gating	I-Method
mechanism	I-Method
.	O
	
Instead	O
,	O
it	O
solely	O
uses	O
the	O
final	O
ouptut	O
of	O
the	O
QRN	B-Method
,	O
ŷ	O
,	O
and	O
the	O
current	O
word	O
output	O
to	O
influence	O
the	O
prediction	O
of	O
the	O
next	O
word	O
among	O
possible	O
candidates	O
.	O
	
Training	O
.	O
	
We	O
withhold	O
10	O
%	O
of	O
the	O
training	O
for	O
development	B-Task
.	O
	
We	O
use	O
the	O
hidden	O
state	O
size	O
of	O
50	O
by	O
deafult	O
.	O
	
Batch	O
sizes	O
of	O
32	O
for	O
bAbI	B-Material
story	I-Material
-	I-Material
based	I-Material
QA	I-Material
1k	O
,	O
bAbI	B-Material
dialog	I-Material
and	O
DSTC2	B-Material
dialog	O
,	O
and	O
128	O
for	O
bAbI	B-Material
QA	I-Material
10k	O
are	O
used	O
.	O
	
The	O
weights	O
in	O
the	O
input	O
and	O
output	O
modules	O
are	O
initialized	O
with	O
zero	O
mean	O
and	O
the	O
standard	O
deviation	O
of	O
1	O
/	O
	
√	O
	
d.	O
	
Weights	O
in	O
the	O
QRN	B-Method
unit	O
are	O
initialized	O
using	O
techniques	O
by	O
[	O
reference	O
]	O
,	O
and	O
are	O
tied	O
across	O
the	O
layers	O
.	O
	
Forget	O
bias	O
of	O
2.5	O
is	O
used	O
for	O
update	O
gates	O
(	O
no	O
bias	O
for	O
reset	O
gates	O
)	O
.	O
	
L2	B-Metric
weight	I-Metric
decay	I-Metric
of	O
0.001	O
(	O
0.0005	O
for	O
QA	B-Task
10k	O
)	O
is	O
used	O
for	O
all	O
weights	O
.	O
	
The	O
loss	B-Metric
function	I-Metric
is	O
the	O
cross	O
entropy	O
betweenv	O
and	O
the	O
one	O
-	O
hot	O
vector	O
of	O
the	O
true	O
answer	O
.	O
	
The	O
loss	O
is	O
minimized	O
by	O
stochastic	B-Method
gradient	I-Method
descent	I-Method
for	O
maximally	O
500	O
epochs	O
,	O
but	O
training	O
is	O
early	O
stopped	O
if	O
the	O
loss	O
on	O
the	O
development	O
data	O
does	O
not	O
decrease	O
for	O
50	O
epochs	O
.	O
	
The	O
learning	B-Metric
rate	I-Metric
is	O
controlled	O
by	O
AdaGrad	B-Method
[	O
reference	O
]	O
with	O
the	O
initial	O
learning	B-Metric
rate	I-Metric
of	O
0.5	O
(	O
0.1	O
for	O
QA	B-Task
10k	O
)	O
.	O
	
Since	O
the	O
model	O
is	O
sensitive	O
to	O
the	O
weight	B-Method
initialization	I-Method
,	O
we	O
repeat	O
each	O
training	O
procedure	O
10	O
times	O
(	O
50	O
times	O
for	O
10k	O
)	O
with	O
the	O
new	O
random	O
initialization	O
of	O
the	O
weights	O
and	O
report	O
the	O
result	O
on	O
the	O
test	O
data	O
with	O
the	O
lowest	O
loss	B-Metric
on	O
the	O
development	O
data	O
.	O
	
section	O
:	O
RESULTS	O
.	O
	
We	O
compare	O
our	O
model	O
with	O
baselines	O
and	O
previous	O
state	O
-	O
of	O
-	O
the	B-Method
-	I-Method
art	I-Method
models	I-Method
on	O
story	B-Task
-	I-Task
based	I-Task
and	I-Task
dialog	I-Task
tasks	I-Task
(	O
Table	O
1	O
)	O
.	O
	
These	O
include	O
LSTM	B-Method
[	O
reference	O
]	O
,	O
End	B-Method
-	I-Method
to	I-Method
-	I-Method
end	I-Method
Memory	I-Method
Networks	I-Method
(	O
N2N	B-Method
)	O
[	O
reference	O
]	O
,	O
Dynamic	B-Method
Memory	I-Method
Networks	I-Method
(	O
DMN	B-Method
+	I-Method
)	O
	
[	O
reference	O
]	O
,	O
Gated	B-Method
End	I-Method
-	I-Method
to	I-Method
-	I-Method
end	I-Method
Memory	I-Method
Networks	I-Method
(	O
GMemN2N	B-Method
)	O
	
[	O
reference	O
]	O
,	O
and	O
Differentiable	B-Method
Neural	I-Method
Computer	I-Method
(	O
DNC	B-Method
)	O
	
[	O
reference	O
]	O
.	O
	
Story	O
-	O
based	O
QA	B-Task
.	O
	
Table	O
1	O
(	O
top	O
)	O
reports	O
the	O
summary	O
of	O
results	O
of	O
our	O
model	O
(	O
QRN	B-Method
)	O
and	O
previous	O
work	O
on	O
bAbI	B-Material
QA	I-Material
(	O
task	O
-	O
wise	O
results	O
are	O
shown	O
in	O
Table	O
2	O
in	O
Appendix	O
)	O
.	O
	
In	O
1k	B-Material
data	I-Material
,	O
QRN	B-Method
's	O
'	O
2r	O
'	O
(	O
2	O
layers	O
+	O
reset	O
gate	O
+	O
d	O
=	O
50	O
)	O
outperforms	O
all	O
other	O
models	O
by	O
a	O
large	O
margin	O
(	O
2.8	O
+	O
%	O
)	O
.	O
	
In	O
10k	B-Material
dataset	I-Material
,	O
the	O
average	B-Metric
accuracy	I-Metric
of	O
QRN	B-Method
's	O
'	O
6r200	O
'	O
(	O
6	O
layers	O
+	O
reset	O
gate	O
+	O
d	O
=	O
200	O
)	O
model	O
outperforms	O
all	O
previous	O
models	O
by	O
a	O
large	O
margin	O
(	O
2.5	O
+	O
%	O
)	O
,	O
achieving	O
a	O
nearly	O
perfect	O
score	O
of	O
99.7	O
%	O
.	O
	
Dialog	O
.	O
	
Table	O
1	O
(	O
bottom	O
)	O
reports	O
the	O
summary	O
of	O
the	O
results	O
of	O
our	O
model	O
(	O
QRN	B-Method
)	O
and	O
previous	O
work	O
on	O
bAbI	B-Material
dialog	I-Material
and	O
Task	O
6	O
dialog	O
(	O
task	O
-	O
wise	O
results	O
are	O
shown	O
in	O
Table	O
3	O
in	O
Appendix	O
)	O
.	O
	
As	O
done	O
in	O
previous	O
work	O
[	O
reference	O
]	O
,	O
we	O
also	O
report	O
results	O
when	O
we	O
use	O
'	O
Match	O
'	O
for	O
dialogs	O
.	O
'	O
	
Match	B-Method
'	I-Method
is	O
the	O
extension	O
to	O
the	O
model	O
which	O
additionally	O
takes	O
as	O
input	O
whether	O
each	O
answer	O
candidate	O
matches	O
with	O
context	O
(	O
more	O
details	O
on	O
Appendix	O
)	O
.	O
	
QRN	B-Method
outperforms	O
previous	O
work	O
by	O
a	O
large	O
margin	O
(	O
2.0	O
+	O
%	O
)	O
in	O
every	O
comparison	O
.	O
	
Ablations	B-Method
.	O
	
We	O
test	O
four	O
types	O
of	O
ablations	B-Method
(	O
also	O
discussed	O
in	O
Section	O
2.2	O
)	O
:	O
number	O
of	O
layers	O
(	O
1	O
,	O
2	O
,	O
3	O
,	O
or	O
6	O
)	O
,	O
reset	O
gate	O
(	O
r	O
)	O
,	O
and	O
gate	O
vectorization	O
(	O
v	O
)	O
and	O
the	O
dimension	O
of	O
the	O
hidden	O
vector	O
(	O
50	O
,	O
100	O
)	O
.	O
	
We	O
show	O
a	O
subset	O
of	O
combinations	O
of	O
the	O
ablations	B-Method
for	O
bAbI	B-Material
QA	I-Material
in	O
Table	O
1	O
and	O
Table	O
2	O
;	O
other	O
combinations	O
performed	O
poorly	O
and	O
/	O
or	O
did	O
not	O
give	O
interesting	O
observations	O
.	O
	
According	O
to	O
the	O
ablation	O
results	O
,	O
we	O
infer	O
that	O
:	O
(	O
a	O
)	O
	
When	O
the	O
number	O
of	O
layers	O
is	O
only	O
one	O
,	O
the	O
model	O
lacks	O
reasoning	O
capability	O
.	O
	
In	O
the	O
case	O
of	O
1k	B-Material
dataset	I-Material
,	O
when	O
there	O
are	O
too	O
many	O
layers	O
(	O
6	O
)	O
,	O
it	O
seems	O
correctly	O
training	O
the	O
model	O
becomes	O
increasingly	O
difficult	O
.	O
	
In	O
the	O
case	O
of	O
10k	O
dataset	O
,	O
many	O
layers	O
(	O
6	O
)	O
and	O
hidden	O
dimensions	O
(	O
200	O
)	O
Parallelization	O
.	O
	
We	O
implement	O
QRN	B-Method
with	O
and	O
without	O
parallelization	B-Method
in	O
TensorFlow	B-Method
[	O
reference	O
]	O
)	O
on	O
a	O
single	O
Titan	O
X	O
GPU	O
to	O
qunaitify	O
the	O
computational	B-Metric
gain	O
of	O
the	O
parallelization	B-Method
.	O
	
For	O
QRN	B-Method
without	O
parallelization	O
,	O
we	O
use	O
the	O
RNN	B-Method
library	O
provided	O
by	O
TensorFlow	B-Method
.	O
	
QRN	B-Method
with	O
parallelization	B-Method
gives	O
6.2	O
times	O
faster	O
training	B-Task
and	O
inference	B-Task
than	O
QRN	B-Method
without	O
parallelization	B-Method
on	O
average	O
.	O
	
We	O
expect	O
that	O
the	O
speedup	O
can	O
be	O
even	O
higher	O
for	O
datasets	O
with	O
larger	O
context	O
.	O
	
Interpretations	O
.	O
	
An	O
advantage	O
of	O
QRN	B-Method
is	O
that	O
the	O
intermediate	O
query	O
updates	O
are	O
interpretable	O
.	O
	
Figure	O
1	O
shows	O
intermediate	O
local	O
queries	O
(	O
q	O
k	O
t	O
)	O
interpreted	O
in	O
natural	O
language	O
,	O
such	O
as	O
"	O
Where	O
is	O
Sandra	O
?	O
"	O
.	O
	
In	O
order	O
to	O
obtain	O
these	O
,	O
we	O
place	O
a	O
decoder	B-Method
on	O
the	O
input	O
question	O
embedding	O
q	O
and	O
add	O
its	O
loss	O
for	O
recovering	O
the	O
question	O
to	O
the	O
classification	O
loss	O
(	O
similarly	O
to	O
[	O
reference	O
]	O
)	O
.	O
	
We	O
then	O
use	O
the	O
same	O
decoder	B-Method
to	O
decode	O
the	O
intermediate	O
queries	O
.	O
	
This	O
helps	O
us	O
understand	O
the	O
flow	O
of	O
information	O
in	O
the	O
networks	O
.	O
	
In	O
Figure	O
1	O
,	O
the	O
question	O
Where	O
is	O
apple	O
?	O
is	O
transformed	O
into	O
Where	O
is	O
Sandra	O
?	O
	
at	O
t	O
	
=	O
1	O
.	O
	
At	O
t	O
=	O
2	O
,	O
as	O
Sandra	O
dropped	O
the	O
apple	O
,	O
the	O
apple	O
is	O
no	O
more	O
relevant	O
to	O
Sandra	O
.	O
	
We	O
obtain	O
Where	O
is	O
Daniel	O
?	O
	
at	O
time	O
t	O
=	O
3	O
,	O
and	O
it	O
is	O
propagated	O
until	O
t	O
=	O
5	O
,	O
where	O
we	O
observe	O
a	O
sentence	O
(	O
fact	O
)	O
that	O
can	O
be	O
used	O
to	O
answer	O
the	O
query	O
.	O
	
Visualization	B-Task
.	O
	
Figure	O
3	O
shows	O
vizualization	O
of	O
the	O
(	O
scalar	O
)	O
magnitudes	O
of	O
update	O
and	O
reset	O
gates	O
on	O
story	O
sentences	O
and	O
dialog	O
utterances	O
.	O
	
More	O
visualizations	O
are	O
shown	O
in	O
Appendices	O
:	O
Figure	O
4	O
and	O
Figure	O
5	O
.	O
	
In	O
Figure	O
3	O
,	O
we	O
observe	O
high	O
values	O
on	O
facts	O
that	O
provide	O
information	O
to	O
answer	O
question	O
(	O
the	O
system	O
's	O
next	O
utterance	O
for	O
dialog	O
)	O
.	O
	
In	O
QA	B-Task
Task	O
2	O
example	O
(	O
top	O
left	O
)	O
,	O
we	O
observe	O
high	O
update	O
gate	O
values	O
in	O
the	O
first	O
layer	O
on	O
facts	O
that	O
state	O
who	O
has	O
the	O
apple	O
,	O
and	O
in	O
the	O
second	O
layer	O
,	O
the	O
high	O
update	O
gate	O
values	O
are	O
on	O
those	O
that	O
inform	O
where	O
that	O
person	O
went	O
to	O
.	O
	
We	O
also	O
observe	O
that	O
the	O
forward	O
reset	O
gate	O
at	O
t	O
=	O
2	O
in	O
the	O
first	O
layer	O
(	O
−	O
→	O
r	O
1	O
2	O
)	O
is	O
low	O
,	O
which	O
is	O
signifying	O
that	O
apple	O
no	O
more	O
belongs	O
to	O
Sandra	O
.	O
	
In	O
dialog	B-Task
Task	I-Task
3	O
(	O
bottom	O
left	O
)	O
,	O
the	O
model	O
is	O
able	O
to	O
infer	O
that	O
three	O
restaurants	O
are	O
already	O
recommended	O
so	O
that	O
it	O
can	O
recommend	O
another	O
one	O
.	O
	
In	O
dialog	B-Task
Task	I-Task
6	O
(	O
bottom	O
)	O
,	O
the	O
model	O
focuses	O
on	O
the	O
sentences	O
containing	O
Spanish	B-Material
,	O
and	O
does	O
not	O
concentrate	O
much	O
on	O
other	O
facts	O
such	O
as	O
I	O
do	O
n't	O
care	O
.	O
	
section	O
:	O
CONCLUSION	O
	
In	O
this	O
paper	O
,	O
we	O
introduce	O
Query	B-Method
-	I-Method
Reduction	I-Method
Network	I-Method
(	O
QRN	B-Method
)	O
to	O
answer	O
context	B-Task
-	I-Task
based	I-Task
questions	I-Task
and	O
carry	O
out	O
conversations	O
with	O
users	O
that	O
require	O
multi	B-Method
-	I-Method
hop	I-Method
reasoning	I-Method
.	O
	
We	O
show	O
the	O
state	O
-	O
of	O
-	O
theart	O
results	O
in	O
the	O
three	O
datasets	O
of	O
story	O
-	O
based	O
QA	B-Task
and	O
dialog	O
.	O
	
We	O
model	O
a	O
story	O
or	O
a	O
dialog	O
as	O
a	O
sequence	O
of	O
state	O
-	O
changing	O
triggers	O
and	O
compute	O
the	O
final	O
answer	O
to	O
the	O
question	O
or	O
the	O
system	O
's	O
next	O
utterance	O
by	O
recurrently	O
updating	O
(	O
or	O
reducing	O
)	O
the	O
query	O
.	O
	
QRN	B-Method
is	O
situated	O
between	O
the	O
attention	B-Method
mechanism	I-Method
and	O
RNN	B-Method
,	O
effectively	O
handling	O
time	B-Task
dependency	I-Task
and	O
long	B-Task
-	I-Task
term	I-Task
dependency	I-Task
problems	I-Task
of	O
each	O
technique	O
,	O
respectively	O
.	O
	
It	O
addresses	O
the	O
long	B-Task
-	I-Task
term	I-Task
dependency	I-Task
problem	I-Task
of	O
most	O
RNNs	B-Method
by	O
simplifying	O
the	O
recurrent	B-Method
update	I-Method
,	O
in	O
which	O
the	O
candidate	O
hidden	O
state	O
(	O
reduced	O
query	O
)	O
does	O
not	O
depend	O
on	O
the	O
previous	O
state	O
.	O
	
Moreover	O
,	O
QRN	B-Method
can	O
be	O
parallelized	O
and	O
can	O
address	O
the	O
well	O
-	O
known	O
problem	O
of	O
RNN	B-Method
's	O
vanishing	O
gradients	O
.	O
	
section	O
:	O
A	O
TASK	O
-	O
WISE	O
RESULTS	O
	
Here	O
we	O
provide	O
detailed	O
per	O
-	O
task	O
breakdown	O
of	O
our	O
results	O
in	O
QA	B-Task
(	O
Table	O
2	O
)	O
and	O
dialog	O
datasets	O
(	O
Table	O
3	O
)	O
.	O
	
Table	O
2	O
:	O
	
bAbI	O
QA	B-Task
dataset	O
error	B-Metric
rates	I-Metric
(	O
%	O
)	O
of	O
QRN	B-Method
and	O
previous	O
work	O
:	O
LSTM	B-Method
,	O
End	B-Method
-	I-Method
to	I-Method
-	I-Method
end	I-Method
Memory	I-Method
Networks	I-Method
(	O
N2N	B-Method
)	O
	
[	O
reference	O
]	O
,	O
Dynamic	B-Method
Memory	I-Method
Networks	I-Method
(	O
DMN	B-Method
+	I-Method
)	O
[	O
reference	O
]	O
,	O
Gated	O
End	B-Method
-	I-Method
to	I-Method
-	I-Method
end	I-Method
Memory	I-Method
Networks	I-Method
(	O
GMemN2N	B-Method
)	O
	
[	O
reference	O
]	O
.	O
Results	O
within	O
each	O
task	O
of	O
Differentiable	B-Method
Neural	I-Method
Computer	I-Method
(	O
DNC	B-Method
)	O
were	O
not	O
provided	O
in	O
its	O
paper	O
[	O
reference	O
]	O
Table	O
3	O
:	O
bAbI	B-Material
dialog	I-Material
and	O
DSTC2	B-Material
dialog	O
dataset	O
average	O
error	B-Metric
rates	I-Metric
(	O
%	O
)	O
of	O
QRN	B-Method
and	O
previous	O
work	O
:	O
End	B-Method
-	I-Method
to	I-Method
-	I-Method
end	I-Method
Memory	I-Method
Networks	I-Method
(	O
N2N	B-Method
)	O
and	O
Gated	B-Method
End	I-Method
-	I-Method
to	I-Method
-	I-Method
end	I-Method
Memory	I-Method
Networks	I-Method
(	O
GMemN2N	B-Method
[	O
reference	O
]	O
)	O
.	O
	
For	O
QRN	B-Method
,	O
a	O
number	O
in	O
the	O
front	O
[	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
indicates	O
the	O
number	O
of	O
layers	O
and	O
a	O
number	O
in	O
the	O
back	O
(	O
100	O
)	O
indicates	O
the	O
dimension	O
of	O
hidden	O
vector	O
,	O
while	O
the	O
default	O
value	O
is	O
50	O
.	O
	
'	O
r	O
'	O
indicates	O
that	O
the	O
reset	O
gate	O
is	O
used	O
,	O
'	O
v	O
'	O
indicates	O
that	O
the	O
gates	O
were	O
vectorized	O
,	O
and	O
'	O
+	O
'	O
indicates	O
that	O
'	O
match	O
'	O
was	O
used	O
.	O
	
section	O
:	O
B	O
VECTOR	B-Task
GATE	I-Task
PARALLELIZATION	I-Task
	
For	O
vector	B-Task
gates	I-Task
,	O
we	O
have	O
z	O
t	O
	
∈	O
R	O
d	O
instead	O
of	O
z	O
t	O
∈	O
R.	O
	
Therefore	O
the	O
following	O
equation	O
replaces	O
Equation	O
7	O
:	O
	
where	O
z	O
j	O
k	O
is	O
the	O
k	O
-	O
th	O
column	O
vector	O
of	O
z	O
j	O
.	O
	
Let	O
b	O
ij	O
=	O
	
log	O
(	O
1	O
	
−	O
z	O
	
i	O
j	O
)	O
for	O
brevity	O
.	O
	
Then	O
,	O
we	O
can	O
rewrite	O
Equation	O
8	O
as	O
following	O
:	O
	
.	O
.	O
.	O
	
where	O
L	O
,	O
L	O
∈	O
R	O
T	O
×T	O
are	O
lower	O
and	O
strictly	O
lower	O
triangular	O
matrices	O
of	O
1	O
's	O
are	O
tiled	O
across	O
the	O
column	O
.	O
	
section	O
:	O
C	O
MODEL	O
DETAILS	O
	
Match	O
.	O
	
While	O
similar	O
in	O
spirit	O
,	O
our	O
'	O
Match	B-Method
'	I-Method
model	I-Method
is	O
slightly	O
different	O
from	O
previous	O
work	O
(	O
Bordes	O
and	O
[	O
reference	O
]	O
.	O
	
We	O
use	O
answer	B-Method
candidate	I-Method
embedding	I-Method
matrix	I-Method
,	O
and	O
add	O
2	O
dimension	O
of	O
0	O
-	O
1	O
matrix	O
which	O
expresses	O
whether	O
the	O
answer	O
candidate	O
matches	O
with	O
any	O
word	O
in	O
the	O
paragraph	O
and	O
the	O
question	O
.	O
	
In	O
other	O
words	O
,	O
the	O
softmax	O
is	O
computed	O
bŷ	O
	
are	O
trainable	O
weight	O
matrices	O
,	O
and	O
M	O
(	O
y	O
)	O
∈	O
R	O
V	O
×2	O
is	O
the	O
0	O
-	O
1	O
match	O
matrix	O
.	O
	
section	O
:	O
D	O
VISUALIZATIONS	O
	
Visualization	O
of	O
Story	O
-	O
based	O
QA	B-Task
.	O
	
Figure	O
4	O
shows	O
visualization	B-Method
of	I-Method
models	I-Method
for	O
story	O
-	O
based	O
QA	B-Task
tasks	O
.	O
	
In	O
the	O
task	O
3	O
(	O
left	O
)	O
,	O
the	O
model	O
focuses	O
on	O
the	O
facts	O
that	O
contain	O
'	O
football	O
'	O
in	O
the	O
first	O
layer	O
,	O
and	O
found	O
out	O
where	O
Mary	O
journeyed	O
to	O
before	O
the	O
bathroom	O
in	O
the	O
second	O
layer	O
.	O
	
In	O
task	O
7	O
(	O
right	O
)	O
,	O
the	O
model	O
focuses	O
on	O
the	O
facts	O
that	O
provide	O
information	O
about	O
the	O
location	O
of	O
Sandra	O
.	O
	
Can	O
you	O
make	O
a	O
restaurant	O
reservation	O
for	O
eight	O
in	O
a	O
cheap	O
price	O
range	O
in	O
madrid	O
0.00	O
1.00	O
0.93	O
1.00	O
I	O
'	O
m	O
on	O
it	O
.	O
	
0.00	O
1.00	O
0.74	O
0.00	O
	
Any	O
preference	O
on	O
a	O
type	O
of	O
cuisine	O
.	O
	
0.00	O
0.11	O
1.00	O
0.01	O
I	O
love	O
british	O
food	O
.	O
	
0.00	O
0.99	O
0.99	O
0.57	O
	
Okay	O
let	O
me	O
look	O
into	O
some	O
options	O
for	O
you	O
.	O
	
Here	O
it	O
is	O
:	O
resto	O
-	O
paris	O
-	O
expen	O
-	O
spanish	O
-	O
8stars	O
-	O
address	O
Figure	O
5	O
:	O
Visualization	O
of	O
update	O
and	O
reset	O
gates	O
in	O
QRN	B-Method
'	O
2r	O
'	O
model	O
for	O
on	O
several	O
tasks	O
of	O
bAbI	B-Material
dialog	I-Material
and	O
DSTC2	B-Material
dialog	O
(	O
Table	O
3	O
)	O
.	O
	
We	O
do	O
not	O
put	O
reset	O
gate	O
in	O
the	O
last	O
layer	O
.	O
	
Note	O
that	O
we	O
only	O
show	O
some	O
of	O
recent	O
sentences	O
here	O
,	O
even	O
the	O
dialog	O
has	O
more	O
sentences	O
.	O
	
Visualization	B-Task
of	I-Task
Dialog	I-Task
.	O
	
Figure	O
5	O
shows	O
visualization	O
of	O
models	O
for	O
dialog	B-Task
tasks	I-Task
.	O
	
In	O
the	O
first	O
dialog	O
of	O
task	O
1	O
,	O
the	O
model	O
focuses	O
on	O
the	O
user	O
utterance	O
that	O
mentions	O
the	O
user	O
's	O
desired	O
cuisine	O
and	O
location	O
,	O
and	O
the	O
current	O
query	O
(	O
user	O
's	O
last	O
utterance	O
)	O
informs	O
the	O
system	O
of	O
the	O
number	O
of	O
people	O
,	O
so	O
the	O
system	O
is	O
able	O
to	O
learn	O
that	O
it	O
now	O
needs	O
to	O
ask	O
the	O
user	O
about	O
the	O
desired	O
price	O
range	O
.	O
	
In	O
the	O
second	O
dialog	O
of	O
task	O
1	O
,	O
the	O
model	O
focuses	O
on	O
the	O
facts	O
that	O
provide	O
information	O
about	O
the	O
requests	O
of	O
the	O
user	O
.	O
	
In	O
task	O
4	O
(	O
third	O
)	O
,	O
the	O
model	O
focuses	O
on	O
what	O
restaurant	O
a	O
user	O
is	O
talking	O
about	O
and	O
the	O
information	O
about	O
the	O
restaurant	O
.	O
	
section	O
:	O
	
section	O
:	O
ACKNOWLEDGMENTS	O
	
This	O
research	O
was	O
supported	O
by	O
the	O
NSF	O
(	O
IIS	O
1616112	O
)	O
,	O
Allen	O
Institute	O
for	O
AI	O
(	O
66	O
-	O
9175	O
)	O
,	O
Allen	O
Distinguished	O
Investigator	O
Award	O
,	O
Google	O
Research	O
Faculty	O
Award	O
,	O
and	O
Samsung	O
GRO	O
Award	O
.	O
	
We	O
thank	O
the	O
anonymous	O
reviewers	O
for	O
their	O
helpful	O
comments	O
.	O
	
section	O
:	O
	
document	O
:	O
Neural	B-Method
Tree	I-Method
Indexers	I-Method
for	O
Text	B-Task
Understanding	I-Task
	
Recurrent	B-Method
neural	I-Method
networks	I-Method
(	O
RNNs	B-Method
)	O
process	O
input	O
text	O
sequentially	O
and	O
model	O
the	O
conditional	O
transition	O
between	O
word	O
tokens	O
.	O
	
In	O
contrast	O
,	O
the	O
advantages	O
of	O
recursive	B-Method
networks	I-Method
include	O
that	O
they	O
explicitly	O
model	O
the	O
compositionality	O
and	O
the	O
recursive	O
structure	O
of	O
natural	O
language	O
.	O
	
However	O
,	O
the	O
current	O
recursive	B-Method
architecture	I-Method
is	O
limited	O
by	O
its	O
dependence	O
on	O
syntactic	O
tree	B-Method
.	O
	
In	O
this	O
paper	O
,	O
we	O
introduce	O
a	O
robust	O
syntactic	O
parsing	O
-	O
independent	O
tree	B-Method
structured	O
model	O
,	O
Neural	B-Method
Tree	I-Method
Indexers	I-Method
(	O
NTI	B-Method
)	O
that	O
provides	O
a	O
middle	O
ground	O
between	O
the	O
sequential	O
RNNs	B-Method
and	O
the	O
syntactic	O
tree	B-Method
-	O
based	O
recursive	O
models	O
.	O
	
NTI	B-Method
constructs	O
a	O
full	O
n	O
-	O
ary	O
tree	B-Method
by	O
processing	O
the	O
input	O
text	O
with	O
its	O
node	O
function	O
in	O
a	O
bottom	O
-	O
up	O
fashion	O
.	O
	
Attention	B-Method
mechanism	I-Method
can	O
then	O
be	O
applied	O
to	O
both	O
structure	O
and	O
node	O
function	O
.	O
	
We	O
implemented	O
and	O
evaluated	O
a	O
binary	O
-	O
tree	B-Method
model	O
of	O
NTI	B-Method
,	O
showing	O
the	O
model	O
achieved	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
performance	O
on	O
three	O
different	O
NLP	B-Task
tasks	I-Task
:	O
natural	B-Task
language	I-Task
inference	I-Task
,	O
answer	B-Task
sentence	I-Task
selection	I-Task
,	O
and	O
sentence	B-Task
classification	I-Task
,	O
outperforming	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
recurrent	B-Method
and	I-Method
recursive	I-Method
neural	I-Method
networks	I-Method
.	O
	
section	O
:	O
Introduction	O
	
Recurrent	B-Method
neural	I-Method
networks	I-Method
(	O
RNNs	B-Method
)	O
have	O
been	O
successful	O
for	O
modeling	O
sequence	O
data	O
.	O
	
RNNs	B-Method
equipped	O
with	O
gated	O
hidden	O
units	O
and	O
internal	B-Method
short	I-Method
-	I-Method
term	I-Method
memories	I-Method
,	O
such	O
as	O
long	B-Method
short	I-Method
-	I-Method
term	I-Method
memories	I-Method
(	O
LSTM	B-Method
)	O
have	O
achieved	O
a	O
notable	O
success	O
in	O
several	O
NLP	B-Task
tasks	I-Task
including	O
named	B-Task
entity	I-Task
recognition	I-Task
,	O
constituency	B-Task
parsing	I-Task
,	O
textual	B-Task
entailment	I-Task
recognition	I-Task
,	O
question	B-Task
answering	I-Task
,	O
and	O
machine	B-Task
translation	I-Task
.	O
	
However	O
,	O
most	O
LSTM	B-Method
models	O
explored	O
so	O
far	O
are	O
sequential	O
.	O
	
It	O
encodes	O
text	O
sequentially	O
from	O
left	O
to	O
right	O
or	O
vice	O
versa	O
and	O
do	O
not	O
naturally	O
support	O
compositionality	O
of	O
language	O
.	O
	
Sequential	O
LSTM	B-Method
models	O
seem	O
to	O
learn	O
syntactic	O
structure	O
from	O
the	O
natural	O
language	O
however	O
their	O
generalization	O
on	O
unseen	O
text	O
is	O
relatively	O
poor	O
comparing	O
with	O
models	O
that	O
exploit	O
syntactic	O
tree	B-Method
structure	O
.	O
	
Unlike	O
sequential	B-Method
models	I-Method
,	O
recursive	B-Method
neural	I-Method
networks	I-Method
compose	O
word	O
phrases	O
over	O
syntactic	O
tree	B-Method
structure	O
and	O
have	O
shown	O
improved	O
performance	O
in	O
sentiment	B-Task
analysis	I-Task
.	O
	
However	O
its	O
dependence	O
on	O
a	O
syntactic	O
tree	B-Method
architecture	O
limits	O
practical	O
NLP	B-Task
applications	I-Task
.	O
	
In	O
this	O
study	O
,	O
we	O
introduce	O
Neural	B-Method
Tree	I-Method
Indexers	I-Method
(	O
NTI	B-Method
)	O
,	O
a	O
class	O
of	O
tree	B-Method
structured	O
models	O
for	O
NLP	B-Task
tasks	I-Task
.	O
	
NTI	B-Method
takes	O
a	O
sequence	O
of	O
tokens	O
and	O
produces	O
its	O
representation	O
by	O
constructing	O
a	O
full	O
n	O
-	O
ary	O
tree	B-Method
in	O
a	O
bottom	O
-	O
up	O
fashion	O
.	O
	
Each	O
node	O
in	O
NTI	B-Method
is	O
associated	O
with	O
one	O
of	O
the	O
node	B-Method
transformation	I-Method
functions	I-Method
:	O
leaf	B-Method
node	I-Method
mapping	I-Method
and	O
non	O
-	O
leaf	O
node	O
composition	O
functions	O
.	O
	
Unlike	O
previous	O
recursive	B-Method
models	I-Method
,	O
the	O
tree	B-Method
structure	O
for	O
NTI	B-Method
is	O
relaxed	O
,	O
i.e.	O
,	O
NTI	B-Method
does	O
not	O
require	O
the	O
input	O
sequences	O
to	O
be	O
parsed	O
syntactically	O
;	O
and	O
therefore	O
it	O
is	O
flexible	O
and	O
can	O
be	O
directly	O
applied	O
to	O
a	O
wide	O
range	O
of	O
NLP	B-Task
tasks	I-Task
beyond	O
sentence	B-Task
modeling	I-Task
.	O
	
Furthermore	O
,	O
we	O
propose	O
different	O
variants	O
of	O
node	B-Method
composition	I-Method
function	I-Method
and	O
attention	B-Method
over	I-Method
tree	I-Method
for	O
our	O
NTI	B-Method
models	O
.	O
	
When	O
a	O
sequential	B-Method
leaf	I-Method
node	I-Method
transformer	I-Method
such	O
as	O
LSTM	B-Method
is	O
chosen	O
,	O
the	O
NTI	B-Method
network	O
forms	O
a	O
sequence	O
-	O
tree	B-Method
hybrid	O
model	O
taking	O
advantage	O
of	O
both	O
conditional	B-Method
and	I-Method
compositional	I-Method
powers	I-Method
of	I-Method
sequential	I-Method
and	I-Method
recursive	I-Method
models	I-Method
.	O
	
Figure	O
shows	O
a	O
binary	O
-	O
tree	B-Method
model	O
of	O
NTI	B-Method
.	O
	
Although	O
the	O
model	O
does	O
not	O
follow	O
the	O
syntactic	O
tree	B-Method
structure	O
,	O
we	O
empirically	O
show	O
that	O
it	O
achieved	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
performance	O
on	O
three	O
different	O
NLP	B-Task
applications	I-Task
:	O
natural	B-Task
language	I-Task
inference	I-Task
,	O
answer	B-Task
sentence	I-Task
selection	I-Task
,	O
and	O
sentence	B-Task
classification	I-Task
.	O
	
section	O
:	O
Related	O
Work	O
	
subsection	O
:	O
Recurrent	B-Method
Neural	I-Method
Networks	I-Method
and	O
Attention	B-Method
Mechanism	I-Method
	
RNNs	B-Method
model	O
input	O
text	O
sequentially	O
by	O
taking	O
a	O
single	O
token	O
at	O
each	O
time	O
step	O
and	O
producing	O
a	O
corresponding	O
hidden	O
state	O
.	O
	
The	O
hidden	O
state	O
is	O
then	O
passed	O
along	O
through	O
the	O
next	O
time	O
step	O
to	O
provide	O
historical	O
sequence	O
information	O
.	O
	
Although	O
a	O
great	O
success	O
in	O
a	O
variety	O
of	O
tasks	O
,	O
RNNs	B-Method
have	O
limitations	O
.	O
	
Among	O
them	O
,	O
it	O
is	O
not	O
efficient	O
at	O
memorizing	O
long	O
or	O
distant	O
sequence	O
.	O
	
This	O
is	O
frequently	O
called	O
as	O
information	B-Task
flow	I-Task
bottleneck	I-Task
.	O
	
Approaches	O
have	O
therefore	O
been	O
developed	O
to	O
overcome	O
the	O
limitations	O
.	O
	
For	O
example	O
,	O
to	O
mitigate	O
the	O
information	B-Task
flow	I-Task
bottleneck	I-Task
,	O
bahdanau:15	O
extended	O
RNNs	B-Method
with	O
a	O
soft	B-Method
attention	I-Method
mechanism	I-Method
in	O
the	O
context	O
of	O
neural	B-Task
machine	I-Task
translation	I-Task
,	O
leading	O
to	O
improved	O
the	O
results	O
in	O
translating	O
longer	O
sentences	O
.	O
	
RNNs	B-Method
are	O
linear	B-Method
chain	I-Method
-	I-Method
structured	I-Method
;	O
this	O
limits	O
its	O
potential	O
for	O
natural	O
language	O
which	O
can	O
be	O
represented	O
by	O
complex	O
structures	O
including	O
syntactic	O
structure	O
.	O
	
In	O
this	O
study	O
,	O
we	O
propose	O
models	O
to	O
mitigate	O
this	O
limitation	O
.	O
	
subsection	O
:	O
Recursive	B-Method
Neural	I-Method
Networks	I-Method
	
Unlike	O
RNNs	B-Method
,	O
recursive	B-Method
neural	I-Method
networks	I-Method
explicitly	O
model	O
the	O
compositionality	O
and	O
the	O
recursive	O
structure	O
of	O
natural	O
language	O
over	O
tree	B-Method
.	O
	
The	O
tree	B-Method
structure	O
can	O
be	O
predefined	O
by	O
a	O
syntactic	B-Method
parser	I-Method
.	O
	
Each	O
non	O
-	O
leaf	O
tree	B-Method
node	O
is	O
associated	O
with	O
a	O
node	B-Method
composition	I-Method
function	I-Method
which	O
combines	O
its	O
children	O
nodes	O
and	O
produces	O
its	O
own	O
representation	O
.	O
	
The	O
model	O
is	O
then	O
trained	O
by	O
back	O
-	O
propagating	O
error	O
through	O
structures	O
.	O
	
The	O
node	O
composition	O
function	O
can	O
be	O
varied	O
.	O
	
A	O
single	B-Method
layer	I-Method
network	I-Method
with	O
non	O
-	O
linearity	O
was	O
adopted	O
in	O
recursive	B-Method
auto	I-Method
-	I-Method
associate	I-Method
memories	I-Method
and	O
recursive	B-Method
autoencoders	I-Method
.	O
	
socher2012semantic	O
extended	O
this	O
network	O
with	O
an	O
additional	O
matrix	B-Method
representation	I-Method
for	O
each	O
node	O
to	O
augment	O
the	O
expressive	O
power	O
of	O
the	O
model	O
.	O
	
Tensor	B-Method
networks	I-Method
have	O
also	O
been	O
used	O
as	O
composition	B-Method
function	I-Method
for	O
sentence	B-Task
-	I-Task
level	I-Task
sentiment	I-Task
analysis	I-Task
task	I-Task
.	O
	
Recently	O
,	O
zhu2015long	O
introduced	O
S	B-Method
-	I-Method
LSTM	I-Method
which	O
extends	O
LSTM	B-Method
units	O
to	O
compose	O
tree	B-Method
nodes	O
in	O
a	O
recursive	O
fashion	O
.	O
	
In	O
this	O
paper	O
,	O
we	O
introduce	O
a	O
novel	O
attentive	B-Method
node	I-Method
composition	I-Method
function	I-Method
that	O
is	O
based	O
on	O
S	B-Method
-	I-Method
LSTM	I-Method
.	O
	
Our	O
NTI	B-Method
model	O
does	O
not	O
rely	O
on	O
either	O
a	O
parser	O
output	O
or	O
a	O
fine	O
-	O
grained	O
supervision	O
of	O
non	O
-	O
leaf	O
nodes	O
,	O
both	O
required	O
in	O
previous	O
work	O
.	O
	
In	O
NTI	B-Method
,	O
the	O
supervision	O
from	O
the	O
target	O
labels	O
is	O
provided	O
at	O
the	O
root	O
node	O
.	O
	
As	O
such	O
,	O
our	O
NTI	B-Method
model	O
is	O
robust	O
and	O
applicable	O
to	O
a	O
wide	O
range	O
of	O
NLP	B-Task
tasks	I-Task
.	O
	
We	O
introduce	O
attention	B-Method
over	I-Method
tree	I-Method
in	O
NTI	B-Method
to	O
overcome	O
the	O
vanishing	B-Task
/	I-Task
explode	I-Task
gradients	I-Task
challenges	I-Task
as	O
shown	O
in	O
RNNs	B-Method
.	O
	
section	O
:	O
Methods	O
	
Our	O
training	O
set	O
consists	O
of	O
examples	O
,	O
where	O
the	O
input	O
is	O
a	O
sequence	O
of	O
word	O
tokens	O
and	O
the	O
output	O
can	O
be	O
either	O
a	O
single	O
target	O
or	O
a	O
sequence	O
.	O
	
Each	O
input	O
word	O
token	O
is	O
represented	O
by	O
its	O
word	B-Method
embedding	I-Method
.	O
	
NTI	B-Method
is	O
a	O
full	O
n	O
-	O
ary	O
tree	B-Method
(	O
and	O
the	O
sub	O
-	O
trees	O
can	O
be	O
overlapped	O
)	O
.	O
	
It	O
has	O
two	O
types	O
of	O
transformation	O
function	O
:	O
non	O
-	O
leaf	O
node	O
function	O
and	O
leaf	O
node	O
function	O
.	O
	
computes	O
a	O
(	O
possibly	O
non	O
-	O
linear	O
)	O
transformation	O
of	O
the	O
input	O
word	B-Method
embedding	I-Method
.	O
	
is	O
a	O
function	O
of	O
its	O
child	O
nodes	O
representation	O
,	O
where	O
is	O
the	O
total	O
number	O
of	O
child	O
nodes	O
of	O
this	O
non	O
-	O
leaf	O
node	O
.	O
	
NTI	B-Method
can	O
be	O
implemented	O
with	O
different	O
tree	B-Method
structures	O
.	O
	
In	O
this	O
study	O
we	O
implemented	O
and	O
evaluated	O
a	O
binary	O
tree	B-Method
form	O
of	O
NTI	B-Method
:	O
a	O
non	O
-	O
leaf	O
node	O
can	O
take	O
in	O
only	O
two	O
direct	O
child	O
nodes	O
(	O
i.e.	O
,	O
)	O
.	O
	
Therefore	O
,	O
the	O
function	O
composes	O
its	O
left	O
child	O
node	O
and	O
right	O
child	O
node	O
.	O
	
Figure	O
illustrates	O
our	O
NTI	B-Method
model	O
that	O
is	O
applied	O
to	O
question	B-Task
answering	I-Task
(	O
a	O
)	O
and	O
natural	B-Task
language	I-Task
inference	I-Task
tasks	O
(	O
b	O
)	O
.	O
	
Note	O
that	O
the	O
node	O
and	O
leaf	O
node	O
functions	O
are	O
neural	B-Method
networks	I-Method
and	O
are	O
the	O
only	O
training	O
parameters	O
in	O
NTI	B-Method
.	O
	
We	O
explored	O
two	O
different	O
approaches	O
to	O
compose	O
node	B-Method
representations	I-Method
:	O
an	O
extended	O
LSTM	B-Method
and	O
attentive	B-Method
node	I-Method
composition	I-Method
functions	I-Method
,	O
to	O
be	O
described	O
below	O
.	O
	
subsection	O
:	O
Non	O
-	O
Leaf	O
Node	O
Composition	O
Functions	O
	
We	O
define	O
two	O
different	O
methods	O
for	O
non	B-Task
-	I-Task
leaf	I-Task
node	I-Task
function	I-Task
.	O
	
LSTM	B-Method
-	O
based	O
Non	O
-	O
leaf	O
Node	O
Function	O
(	O
S	B-Method
-	I-Method
LSTM	I-Method
)	O
:	O
	
We	O
initiate	O
with	O
LSTM	B-Method
.	O
	
For	O
non	B-Task
-	I-Task
leaf	I-Task
node	I-Task
,	O
we	O
adopt	O
S	O
-	O
LSTM	B-Method
zhu2015long	O
,	O
an	O
extension	O
of	O
LSTM	B-Method
to	O
tree	B-Method
structures	O
,	O
to	O
learn	O
a	O
node	B-Method
representation	I-Method
by	O
its	O
children	O
nodes	O
.	O
	
Let	O
,	O
,	O
and	O
be	O
vector	O
representations	O
and	O
cell	O
states	O
for	O
the	O
left	O
and	O
right	O
children	O
.	O
	
An	O
S	B-Method
-	I-Method
LSTM	I-Method
computes	O
a	O
parent	B-Method
node	I-Method
representation	I-Method
and	O
a	O
node	O
cell	O
state	O
as	O
where	O
and	O
biases	O
(	O
for	O
brevity	O
we	O
eliminated	O
the	O
bias	O
terms	O
)	O
are	O
the	O
training	O
parameters	O
.	O
and	O
denote	O
the	O
element	O
-	O
wise	O
function	O
and	O
the	O
element	B-Method
-	I-Method
wise	I-Method
vector	I-Method
multiplication	I-Method
.	O
	
Extension	O
of	O
S	O
-	O
LSTM	B-Method
non	O
-	O
leaf	O
node	O
function	O
to	O
compose	O
more	O
children	O
is	O
straightforward	O
.	O
	
However	O
,	O
the	O
number	O
of	O
parameters	O
increases	O
quadratically	O
in	O
S	B-Method
-	I-Method
LSTM	I-Method
as	O
we	O
add	O
more	O
child	O
nodes	O
.	O
	
Attentive	B-Method
Non	I-Method
-	I-Method
leaf	I-Method
Node	I-Method
Function	I-Method
(	O
ANF	B-Method
)	O
:	O
	
Some	O
NLP	B-Task
applications	I-Task
(	O
e.g.	O
,	O
QA	B-Task
and	O
machine	B-Task
translation	I-Task
)	O
would	O
benefit	O
from	O
a	O
dynamic	B-Method
query	I-Method
dependent	I-Method
composition	I-Method
function	I-Method
.	O
	
We	O
introduce	O
ANF	B-Method
as	O
a	O
new	O
non	O
-	O
leaf	O
node	O
function	O
.	O
	
Unlike	O
S	B-Method
-	I-Method
LSTM	I-Method
,	O
ANF	B-Method
composes	O
the	O
child	O
nodes	O
attentively	O
in	O
respect	O
to	O
another	O
relevant	O
input	O
vector	O
.	O
	
The	O
input	O
vector	O
can	O
be	O
a	O
learnable	B-Method
representation	I-Method
from	O
a	O
sequence	B-Method
representation	I-Method
.	O
	
Given	O
a	O
matrix	O
resulted	O
by	O
concatenating	O
the	O
child	O
node	O
representations	O
,	O
and	O
the	O
third	O
input	O
vector	O
,	O
ANF	O
is	O
defined	O
as	O
where	O
is	O
a	O
learnable	O
matrix	O
,	O
the	O
attention	O
score	O
and	O
the	O
attention	O
weight	O
vector	O
for	O
each	O
child	O
.	O
	
is	O
an	O
attention	B-Method
scoring	I-Method
function	I-Method
,	O
which	O
can	O
be	O
implemented	O
as	O
a	O
multi	B-Method
-	I-Method
layer	I-Method
perceptron	I-Method
(	I-Method
MLP	I-Method
)	O
or	O
a	O
matrix	B-Method
-	I-Method
vector	I-Method
product	I-Method
.	O
	
The	O
matrices	O
and	O
and	O
the	O
vector	O
are	O
training	O
parameters	O
.	O
	
is	O
a	O
vector	O
of	O
ones	O
and	O
the	O
outer	O
product	O
.	O
	
We	O
use	O
function	O
for	O
non	B-Task
-	I-Task
linear	I-Task
transformation	I-Task
.	O
	
subsection	O
:	O
Attention	O
Over	O
Tree	O
	
Comparing	O
with	O
sequential	O
LSTM	B-Method
models	O
,	O
NTI	B-Method
has	O
less	O
recurrence	O
,	O
which	O
is	O
defined	O
by	O
the	O
tree	B-Method
depth	O
,	O
for	O
binary	O
tree	B-Method
where	O
is	O
the	O
length	O
of	O
the	O
input	O
sequence	O
.	O
	
However	O
,	O
NTI	B-Method
still	O
needs	O
to	O
compress	O
all	O
the	O
input	O
information	O
into	O
a	O
single	O
representation	O
vector	O
of	O
the	O
root	O
.	O
	
This	O
imposes	O
practical	O
difficulties	O
when	O
processing	O
long	O
sequences	O
.	O
	
We	O
address	O
this	O
issue	O
with	O
attention	B-Method
mechanism	I-Method
over	O
tree	B-Method
.	O
	
In	O
addition	O
,	O
the	O
attention	B-Method
mechanism	I-Method
can	O
be	O
used	O
for	O
matching	O
trees	O
(	O
described	O
in	O
Section	O
4	O
as	O
Tree	O
matching	O
NTI	B-Method
)	O
that	O
carry	O
different	O
sequence	O
information	O
.	O
	
We	O
first	O
define	O
a	O
global	B-Method
attention	I-Method
and	O
then	O
introduce	O
a	O
tree	B-Method
attention	I-Method
which	O
considers	O
the	O
parent	O
-	O
child	O
dependency	O
for	O
calculation	O
of	O
the	O
attention	O
weights	O
.	O
	
Global	B-Method
Attention	I-Method
:	O
An	O
attention	B-Method
neural	I-Method
network	I-Method
for	O
the	O
global	B-Method
attention	I-Method
takes	O
all	O
node	O
representations	O
as	O
input	O
and	O
produces	O
an	O
attentively	O
blended	O
vector	O
for	O
the	O
whole	O
tree	B-Method
.	O
	
This	O
neural	B-Method
net	I-Method
is	O
similar	O
to	O
ANF	B-Method
.	O
	
Particularly	O
,	O
given	O
a	O
matrix	O
resulted	O
by	O
concatenating	O
the	O
node	O
representations	O
,	O
…	O
,	O
and	O
the	O
relevant	O
input	O
representation	O
,	O
the	O
global	B-Method
attention	I-Method
is	O
defined	O
as	O
where	O
and	O
are	O
training	O
parameters	O
and	O
the	O
attention	O
weight	O
vector	O
for	O
each	O
node	O
.	O
	
This	O
attention	B-Method
mechanism	I-Method
is	O
robust	O
as	O
it	O
globally	O
normalizes	O
the	O
attention	O
score	O
with	O
to	O
obtain	O
the	O
weights	O
.	O
	
However	O
,	O
it	O
does	O
not	O
consider	O
the	O
tree	B-Method
structure	O
when	O
producing	O
the	O
final	O
representation	O
.	O
	
Tree	O
Attention	O
	
:	O
We	O
modify	O
the	O
global	B-Method
attention	I-Method
network	I-Method
to	O
the	O
tree	B-Method
attention	O
mechanism	O
.	O
	
The	O
resulting	O
tree	B-Method
attention	O
network	O
performs	O
almost	O
the	O
same	O
computation	O
as	O
ANF	O
for	O
each	O
node	O
.	O
	
It	O
compares	O
the	O
parent	O
and	O
children	O
nodes	O
to	O
produce	O
a	O
new	O
representation	O
assuming	O
that	O
all	O
node	B-Method
representations	I-Method
are	O
constructed	O
.	O
	
Given	O
a	O
matrix	O
resulted	O
by	O
concatenating	O
the	O
parent	B-Method
node	I-Method
representation	I-Method
,	O
the	O
left	O
child	O
and	O
the	O
right	O
child	O
and	O
the	O
relevant	O
input	O
representation	O
,	O
every	O
non	O
-	O
leaf	O
node	O
simply	O
updates	O
its	O
own	O
representation	O
by	O
using	O
the	O
following	O
equation	O
in	O
a	O
bottom	O
-	O
up	O
manner	O
.	O
	
and	O
this	O
equation	O
is	O
similarity	O
to	O
the	O
global	B-Method
attention	I-Method
.	O
	
However	O
,	O
now	O
each	O
non	O
-	O
leaf	O
node	O
attentively	O
collects	O
its	O
own	O
and	O
children	O
representations	O
and	O
passes	O
towards	O
the	O
root	O
which	O
finally	O
constructs	O
the	O
attentively	O
blended	O
tree	B-Method
representation	O
.	O
	
Note	O
that	O
unlike	O
the	O
global	B-Method
attention	I-Method
,	O
the	O
tree	B-Method
attention	I-Method
locally	O
normalizes	O
the	O
attention	O
scores	O
with	O
.	O
	
section	O
:	O
Experiments	O
	
We	O
describe	O
in	O
this	O
section	O
experiments	O
on	O
three	O
different	O
NLP	B-Task
tasks	I-Task
,	O
natural	B-Task
language	I-Task
inference	I-Task
,	O
question	B-Task
answering	I-Task
and	O
sentence	B-Task
classification	I-Task
to	O
demonstrate	O
the	O
flexibility	O
and	O
the	O
effectiveness	O
of	O
NTI	B-Method
in	O
the	O
different	O
settings	O
.	O
	
We	O
trained	O
NTI	B-Method
using	O
Adam	B-Method
with	O
hyperparameters	B-Method
selected	O
on	O
development	O
set	O
.	O
	
The	O
pre	O
-	O
trained	O
300	O
-	O
D	O
Glove	O
840B	O
vectors	O
were	O
obtained	O
for	O
the	O
word	B-Task
embeddings	I-Task
.	O
	
The	O
word	O
embeddings	O
are	O
fixed	O
during	O
training	O
.	O
	
The	O
embeddings	O
for	O
out	O
-	O
of	O
-	O
vocabulary	O
words	O
were	O
set	O
to	O
zero	O
vector	O
.	O
	
We	O
pad	O
the	O
input	O
sequence	O
to	O
form	O
a	O
full	O
binary	O
tree	B-Method
.	O
	
A	O
padding	O
vector	O
was	O
inserted	O
when	O
padding	O
.	O
	
We	O
analyzed	O
the	O
effects	O
of	O
the	O
padding	O
size	O
and	O
found	O
out	O
that	O
it	O
has	O
no	O
influence	O
on	O
the	O
performance	O
(	O
see	O
Appendix	O
[	O
reference	O
]	O
)	O
.	O
	
The	O
size	O
of	O
hidden	O
units	O
of	O
the	O
NTI	B-Method
modules	O
were	O
set	O
to	O
300	O
.	O
	
The	O
models	O
were	O
regularized	O
by	O
using	O
dropouts	B-Method
and	O
an	O
weight	B-Method
decay	I-Method
.	O
	
subsection	O
:	O
Natural	B-Task
Language	I-Task
Inference	I-Task
	
We	O
conducted	O
experiments	O
on	O
the	O
Stanford	B-Material
Natural	I-Material
Language	I-Material
Inference	I-Material
(	O
SNLI	B-Material
)	O
dataset	O
,	O
which	O
consists	O
of	O
549	O
,	O
367	O
/	O
9	O
,	O
842	O
/	O
9	O
,	O
824	O
premise	O
-	O
hypothesis	O
pairs	O
for	O
train	O
/	O
dev	O
/	O
test	O
sets	O
and	O
target	O
label	O
indicating	O
their	O
relation	O
.	O
	
Unless	O
otherwise	O
noted	O
,	O
we	O
follow	O
the	O
setting	O
in	O
the	O
previous	O
work	O
and	O
use	O
an	O
MLP	B-Method
for	O
classification	B-Task
which	O
takes	O
in	O
NTI	B-Method
outputs	O
and	O
computes	O
the	O
concatenation	O
,	O
absolute	O
difference	O
and	O
elementwise	O
product	O
of	O
the	O
two	O
sentence	B-Method
representations	I-Method
.	O
	
The	O
MLP	B-Method
has	O
also	O
an	O
input	B-Method
layer	I-Method
with	O
1024	B-Method
units	I-Method
with	O
activation	B-Method
and	O
a	O
output	B-Method
layer	I-Method
.	O
	
We	O
explored	O
nine	O
different	O
task	O
-	O
oriented	O
NTI	B-Method
models	O
with	O
varying	O
complexity	O
,	O
to	O
be	O
described	O
below	O
.	O
	
For	O
each	O
model	O
,	O
we	O
set	O
the	O
batch	O
size	O
to	O
32	O
.	O
	
The	O
initial	B-Method
learning	I-Method
,	O
the	O
regularization	O
strength	O
and	O
the	O
number	O
of	O
epoch	O
to	O
be	O
trained	O
are	O
varied	O
for	O
each	O
model	O
.	O
	
NTI	B-Method
-	I-Method
SLSTM	I-Method
:	O
this	O
model	O
does	O
not	O
rely	O
on	O
transformer	B-Method
but	O
uses	O
the	O
S	O
-	O
LSTM	B-Method
units	O
for	O
the	O
non	O
-	O
leaf	O
node	O
function	O
.	O
	
We	O
set	O
the	O
initial	O
learning	B-Metric
rate	I-Metric
to	O
1e	O
-	O
3	O
and	O
regularizer	O
strength	O
to	O
3e	O
-	O
5	O
,	O
and	O
train	O
the	O
model	O
for	O
90	O
epochs	O
.	O
	
The	O
neural	B-Method
net	I-Method
was	O
regularized	O
by	O
10	O
%	O
input	B-Method
dropouts	I-Method
and	O
the	O
20	O
%	O
output	O
dropouts	O
.	O
	
NTI	B-Method
-	I-Method
SLSTM	I-Method
-	I-Method
LSTM	I-Method
	
:	O
we	O
use	O
LSTM	B-Method
for	O
the	O
leaf	O
node	O
function	O
.	O
	
Concretely	O
,	O
the	O
LSTM	B-Method
output	O
vectors	O
are	O
given	O
to	O
NTI	B-Method
-	I-Method
SLSTM	I-Method
and	O
the	O
memory	O
cells	O
of	O
the	O
lowest	O
level	O
S	O
-	O
LSTM	B-Method
were	O
initialized	O
with	O
the	O
LSTM	B-Method
memory	O
states	O
.	O
	
The	O
hyper	O
-	O
parameters	O
are	O
the	O
same	O
as	O
the	O
previous	O
model	O
.	O
	
NTI	B-Method
-	I-Method
SLSTM	I-Method
node	I-Method
-	I-Method
by	I-Method
-	I-Method
node	I-Method
global	I-Method
attention	I-Method
	
:	O
This	O
model	O
learns	O
inter	O
-	O
sentence	O
relation	O
with	O
the	O
global	B-Method
attention	I-Method
over	O
premise	O
-	O
indexed	O
tree	B-Method
,	O
which	O
is	O
similar	O
to	O
word	B-Method
-	I-Method
by	I-Method
-	I-Method
word	I-Method
attention	I-Method
model	I-Method
of	O
rocktaschel:16	O
in	O
that	O
it	O
attends	O
over	O
the	O
premise	O
tree	B-Method
nodes	O
at	O
every	O
time	O
step	O
of	O
hypothesis	B-Method
encoding	I-Method
.	O
	
We	O
tie	O
the	O
weight	O
parameters	O
of	O
the	O
two	O
NTI	B-Method
-	I-Method
SLSTMs	I-Method
for	O
premise	O
and	O
hypothesis	O
and	O
no	O
transformer	O
used	O
.	O
	
We	O
set	O
the	O
initial	O
learning	B-Metric
rate	I-Metric
to	O
3e	O
-	O
4	O
and	O
regularizer	O
strength	O
to	O
1e	O
-	O
5	O
,	O
and	O
train	O
the	O
model	O
for	O
40	O
epochs	O
.	O
	
The	O
neural	B-Method
net	I-Method
was	O
regularized	O
by	O
15	O
%	O
input	O
dropouts	O
and	O
the	O
15	O
%	O
output	O
dropouts	O
.	O
	
NTI	B-Method
-	I-Method
SLSTM	I-Method
node	I-Method
-	I-Method
by	I-Method
-	I-Method
node	I-Method
tree	I-Method
attention	I-Method
	
:	O
this	O
is	O
a	O
variation	O
of	O
the	O
previous	O
model	O
with	O
the	O
tree	B-Method
attention	O
.	O
	
The	O
hyper	O
-	O
parameters	O
are	O
the	O
same	O
as	O
the	O
previous	O
model	O
.	O
	
NTI	B-Method
-	I-Method
SLSTM	I-Method
-	I-Method
LSTM	I-Method
node	I-Method
-	I-Method
by	I-Method
-	I-Method
node	I-Method
global	I-Method
attention	I-Method
:	O
in	O
this	O
model	O
we	O
include	O
LSTM	B-Method
as	O
the	O
leaf	O
node	O
function	O
.	O
	
Here	O
we	O
initialize	O
the	O
memory	O
cell	O
of	O
S	O
-	O
LSTM	B-Method
with	O
LSTM	B-Method
memory	O
and	O
hidden	B-Method
/	I-Method
memory	I-Method
state	I-Method
of	O
hypothesis	O
LSTM	B-Method
with	O
premise	O
LSTM	B-Method
(	O
the	O
later	O
follows	O
the	O
work	O
of	O
)	O
.	O
	
We	O
set	O
the	O
initial	O
learning	B-Metric
rate	I-Metric
to	O
3e	O
-	O
4	O
and	O
regularizer	O
strength	O
to	O
1e	O
-	O
5	O
,	O
and	O
train	O
the	O
model	O
for	O
10	O
epochs	O
.	O
	
The	O
neural	B-Method
net	I-Method
was	O
regularized	O
by	O
10	O
%	O
input	O
dropouts	O
and	O
the	O
15	O
%	O
output	O
dropouts	O
.	O
	
NTI	B-Method
-	I-Method
SLSTM	I-Method
-	I-Method
LSTM	I-Method
node	I-Method
-	I-Method
by	I-Method
-	I-Method
node	I-Method
tree	I-Method
attention	I-Method
:	O
this	O
is	O
a	O
variation	O
of	O
the	O
previous	O
model	O
with	O
the	O
tree	B-Method
attention	O
.	O
	
The	O
hyper	O
-	O
parameters	O
are	O
the	O
same	O
as	O
the	O
previous	O
model	O
.	O
	
Tree	B-Method
matching	I-Method
NTI	I-Method
-	I-Method
SLSTM	I-Method
-	I-Method
LSTM	I-Method
global	I-Method
attention	I-Method
:	O
this	O
model	O
first	O
constructs	O
the	O
premise	O
and	O
hypothesis	O
trees	O
simultaneously	O
with	O
the	O
NTI	B-Method
-	I-Method
SLSTM	I-Method
-	I-Method
LSTM	I-Method
model	I-Method
and	O
then	O
computes	O
their	O
matching	O
vector	O
by	O
using	O
the	O
global	B-Method
attention	I-Method
and	O
an	O
additional	O
LSTM	B-Method
.	O
	
The	O
attention	O
vectors	O
are	O
produced	O
at	O
each	O
hypothesis	O
tree	B-Method
node	O
and	O
then	O
are	O
given	O
to	O
the	O
LSTM	B-Method
model	O
sequentially	O
.	O
	
The	O
LSTM	B-Method
model	O
compress	O
the	O
attention	O
vectors	O
and	O
outputs	O
a	O
single	O
matching	O
vector	O
,	O
which	O
is	O
passed	O
to	O
an	O
MLP	B-Method
for	O
classification	B-Task
.	O
	
The	O
MLP	B-Method
for	O
this	O
tree	B-Method
matching	O
setting	O
has	O
an	O
input	B-Method
layer	I-Method
with	O
1024	O
units	O
with	O
activation	O
and	O
a	O
output	B-Method
layer	I-Method
.	O
	
Unlike	O
WangJ15b	O
’s	O
matching	O
LSTM	B-Method
model	O
which	O
is	O
specific	O
to	O
matching	O
sequences	O
,	O
we	O
use	O
the	O
standard	O
LSTM	B-Method
units	O
and	O
match	B-Method
trees	I-Method
.	O
	
We	O
set	O
the	O
initial	O
learning	B-Metric
rate	I-Metric
to	O
3e	O
-	O
4	O
and	O
regularizer	O
strength	O
to	O
3e	O
-	O
5	O
,	O
and	O
train	O
the	O
model	O
for	O
20	O
epochs	O
.	O
	
The	O
neural	B-Method
net	I-Method
was	O
regularized	O
by	O
20	O
%	O
input	B-Method
dropouts	I-Method
and	O
the	O
20	O
%	O
output	O
dropouts	O
.	O
	
Tree	B-Method
matching	I-Method
NTI	I-Method
-	I-Method
SLSTM	I-Method
-	I-Method
LSTM	I-Method
tree	I-Method
attention	I-Method
:	O
we	O
replace	O
the	O
global	B-Method
attention	I-Method
with	O
the	O
tree	B-Method
attention	O
.	O
	
The	O
hyper	O
-	O
parameters	O
are	O
the	O
same	O
as	O
the	O
previous	O
model	O
.	O
	
Full	B-Method
tree	I-Method
matching	I-Method
NTI	I-Method
-	I-Method
SLSTM	I-Method
-	I-Method
LSTM	I-Method
global	I-Method
attention	I-Method
:	O
this	O
model	O
produces	O
two	O
sets	O
of	O
the	O
attention	O
vectors	O
,	O
one	O
by	O
attending	O
over	O
the	O
premise	O
tree	B-Method
regarding	O
each	O
hypothesis	O
tree	B-Method
node	O
and	O
another	O
by	O
attending	O
over	O
the	O
hypothesis	O
tree	B-Method
regarding	O
each	O
premise	O
tree	B-Method
node	O
.	O
	
Each	O
set	O
of	O
the	O
attention	O
vectors	O
is	O
given	O
to	O
a	O
LSTM	B-Method
model	O
to	O
achieve	O
full	O
tree	B-Method
matching	O
.	O
	
The	O
last	O
hidden	O
states	O
of	O
the	O
two	O
LSTM	B-Method
models	O
(	O
i.e.	O
one	O
for	O
each	O
attention	O
vector	O
set	O
)	O
are	O
concatenated	O
for	O
classification	B-Task
.	O
	
The	O
training	O
weights	O
are	O
shared	O
among	O
the	O
LSTM	B-Method
models	O
	
The	O
hyper	O
-	O
parameters	O
are	O
the	O
same	O
as	O
the	O
previous	O
model	O
.	O
	
Table	O
[	O
reference	O
]	O
shows	O
the	O
results	O
of	O
our	O
models	O
.	O
	
For	O
comparison	O
,	O
we	O
include	O
the	O
results	O
from	O
the	O
published	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
systems	O
.	O
	
While	O
most	O
of	O
the	O
sentence	B-Method
encoder	I-Method
models	I-Method
rely	O
solely	O
on	O
word	B-Method
embeddings	I-Method
,	O
the	O
dependency	O
tree	B-Method
CNN	O
and	O
the	O
SPINN	B-Method
-	I-Method
PI	I-Method
models	I-Method
make	O
use	O
of	O
sentence	O
parser	O
output	O
;	O
which	O
present	O
strong	O
baseline	O
systems	O
.	O
	
The	O
last	O
set	O
of	O
methods	O
designs	O
inter	B-Task
-	I-Task
sentence	I-Task
relation	I-Task
with	O
soft	O
attention	O
.	O
	
Our	O
best	O
score	O
on	O
this	O
task	O
is	O
87.3	O
%	O
accuracy	B-Metric
obtained	O
with	O
the	O
full	B-Method
tree	I-Method
matching	I-Method
NTI	I-Method
model	I-Method
.	O
	
The	O
previous	O
best	O
performing	O
model	O
on	O
the	O
task	O
performs	O
phrase	B-Task
matching	I-Task
by	O
using	O
the	O
attention	B-Method
mechanism	I-Method
.	O
	
Our	O
results	O
show	O
that	O
NTI	B-Method
-	I-Method
SLSTM	I-Method
improved	O
the	O
performance	O
of	O
the	O
sequential	B-Method
LSTM	I-Method
encoder	I-Method
by	O
approximately	O
2	O
%	O
.	O
	
Not	O
surprisingly	O
,	O
using	O
LSTM	B-Method
as	O
leaf	O
node	O
function	O
helps	O
in	O
learning	O
better	O
representations	B-Task
.	O
	
Our	O
NTI	B-Method
-	I-Method
SLSTM	I-Method
-	I-Method
LSTM	I-Method
is	O
a	O
hybrid	B-Method
model	I-Method
which	O
encodes	O
a	O
sequence	O
sequentially	O
through	O
its	O
leaf	O
node	O
function	O
and	O
then	O
hierarchically	O
composes	O
the	O
output	B-Method
representations	I-Method
.	O
	
The	O
node	B-Method
-	I-Method
by	I-Method
-	I-Method
node	I-Method
attention	I-Method
models	I-Method
improve	O
the	O
performance	O
,	O
indicating	O
that	O
modeling	O
inter	B-Task
-	I-Task
sentence	I-Task
interaction	I-Task
is	O
an	O
important	O
element	O
in	O
NLI	B-Task
.	O
	
Aggregating	B-Task
matching	I-Task
vector	I-Task
between	O
trees	O
or	O
sequences	O
with	O
a	O
separate	O
LSTM	B-Method
model	O
is	O
effective	O
.	O
	
The	O
global	B-Method
attention	I-Method
seems	O
to	O
be	O
robust	O
on	O
this	O
task	O
.	O
	
The	O
tree	B-Method
attention	O
were	O
not	O
helpful	O
as	O
it	O
normalizes	O
the	O
attention	O
scores	O
locally	O
in	O
parent	O
-	O
child	O
relationship	O
.	O
	
subsection	O
:	O
Answer	B-Task
Sentence	I-Task
Selection	I-Task
	
For	O
this	O
task	O
,	O
a	O
model	O
is	O
trained	O
to	O
identify	O
the	O
correct	O
sentences	O
that	O
answer	O
a	O
factual	O
question	O
,	O
from	O
a	O
set	O
of	O
candidate	O
sentences	O
.	O
	
We	O
experiment	O
on	O
WikiQA	B-Material
dataset	I-Material
constructed	O
from	O
Wikipedia	O
.	O
	
The	O
dataset	O
contains	O
20	O
,	O
360	O
/	O
2	O
,	O
733	O
/	O
6	O
,	O
165	O
QA	O
pairs	O
for	O
train	O
/	O
dev	O
/	O
test	O
sets	O
.	O
	
We	O
used	O
the	O
same	O
setup	O
in	O
the	O
language	B-Task
inference	I-Task
task	I-Task
except	O
that	O
we	O
replace	O
the	O
layer	O
with	O
a	O
layer	O
and	O
model	O
the	O
following	O
conditional	O
probability	O
distribution	O
.	O
	
where	O
and	O
are	O
the	O
question	O
and	O
the	O
answer	O
encoded	O
vectors	O
and	O
denotes	O
the	O
output	O
of	O
the	O
hidden	B-Method
layer	I-Method
of	O
the	O
MLP	B-Method
.	O
	
For	O
this	O
task	O
,	O
we	O
use	O
NTI	B-Method
-	I-Method
SLSTM	I-Method
-	I-Method
LSTM	I-Method
to	O
encode	O
answer	O
candidate	O
sentences	O
and	O
NTI	B-Method
-	O
ANF	O
-	O
LSTM	B-Method
to	O
encode	O
the	O
question	O
sentences	O
.	O
	
Note	O
that	O
NTI	B-Method
-	O
ANF	O
-	O
LSTM	B-Method
is	O
relied	O
on	O
ANF	B-Method
as	O
the	O
non	O
-	O
leaf	O
node	O
function	O
.	O
	
vector	B-Method
for	O
NTI	B-Method
-	O
ANF	O
-	O
LSTM	B-Method
is	O
the	O
answer	B-Method
representation	I-Method
produced	O
by	O
the	O
answer	O
encoding	O
NTI	B-Method
-	O
SLSTM	O
-	O
LSTM	B-Method
model	O
.	O
	
We	O
set	O
the	O
batch	O
size	O
to	O
4	O
and	O
the	O
initial	O
learning	B-Metric
rate	I-Metric
to	O
1e	O
-	O
3	O
,	O
and	O
train	O
the	O
model	O
for	O
10	O
epochs	O
.	O
	
We	O
used	O
20	O
%	O
input	O
dropouts	O
and	O
no	O
weight	B-Method
decay	I-Method
.	O
	
Following	O
previous	O
work	O
,	O
we	O
adopt	O
MAP	B-Method
and	O
MRR	B-Method
as	O
the	O
evaluation	B-Metric
metrics	I-Metric
for	O
this	O
task	O
.	O
	
Table	O
[	O
reference	O
]	O
presents	O
the	O
results	O
of	O
our	O
model	O
and	O
the	O
previous	O
models	O
for	O
the	O
task	O
.	O
	
The	O
classifier	B-Method
with	O
handcrafted	O
features	O
is	O
a	O
SVM	B-Method
model	I-Method
trained	O
with	O
a	O
set	O
of	O
features	O
.	O
	
The	O
Bigram	B-Method
-	I-Method
CNN	I-Method
model	I-Method
is	O
a	O
simple	O
convolutional	B-Method
neural	I-Method
net	I-Method
.	O
	
The	O
Deep	B-Method
LSTM	I-Method
and	O
LSTM	B-Method
attention	I-Method
models	I-Method
outperform	O
the	O
previous	O
best	O
result	O
by	O
a	O
large	O
margin	O
,	O
nearly	O
5	O
-	O
6	O
%	O
.	O
	
NASM	B-Method
improves	O
the	O
result	O
further	O
and	O
sets	O
a	O
strong	O
baseline	O
by	O
combining	O
variational	B-Method
auto	I-Method
-	I-Method
encoder	I-Method
with	O
the	O
soft	O
attention	O
.	O
	
In	O
NASM	B-Method
,	O
they	O
adopt	O
a	O
deep	O
three	O
-	O
layer	O
LSTM	B-Method
and	O
introduced	O
a	O
latent	B-Method
stochastic	I-Method
attention	I-Method
mechanism	I-Method
over	O
the	O
answer	O
sentence	O
.	O
	
Our	O
NTI	B-Method
model	O
exceeds	O
NASM	B-Method
by	O
approximately	O
0.4	O
%	O
on	O
MAP	B-Task
for	O
this	O
task	O
.	O
	
subsection	O
:	O
Sentence	B-Task
Classification	I-Task
	
Lastly	O
,	O
we	O
evaluated	O
NTI	B-Method
on	O
the	O
Stanford	B-Material
Sentiment	I-Material
Treebank	I-Material
(	O
SST	B-Material
)	O
.	O
	
This	O
dataset	O
comes	O
with	O
standard	O
train	O
/	O
dev	O
/	O
test	O
sets	O
and	O
two	O
subtasks	O
:	O
binary	B-Task
sentence	I-Task
classification	I-Task
or	O
fine	B-Task
-	I-Task
grained	I-Task
classification	I-Task
of	O
five	O
classes	O
.	O
	
We	O
trained	O
our	O
model	O
on	O
the	O
text	O
spans	O
corresponding	O
to	O
labeled	O
phrases	O
in	O
the	O
training	O
set	O
and	O
evaluated	O
the	O
model	O
on	O
the	O
full	O
sentences	O
.	O
	
We	O
use	O
NTI	B-Method
-	I-Method
SLSTM	I-Method
and	O
NTI	B-Method
-	I-Method
SLSTM	I-Method
-	I-Method
LSTM	I-Method
models	O
to	O
learn	O
sentence	B-Method
representations	I-Method
for	O
the	O
task	O
.	O
	
The	O
sentence	B-Method
representations	I-Method
were	O
passed	O
to	O
a	O
two	O
-	O
layer	B-Method
MLP	I-Method
for	O
classification	B-Task
.	O
	
We	O
set	O
the	O
batch	O
size	O
to	O
64	O
,	O
the	O
initial	O
learning	B-Metric
rate	I-Metric
to	O
1e	O
-	O
3	O
and	O
regularizer	O
strength	O
to	O
3e	O
-	O
5	O
,	O
and	O
train	O
each	O
model	O
for	O
10	O
epochs	O
.	O
	
The	O
NTI	B-Method
-	I-Method
SLSTM	I-Method
model	I-Method
was	O
regularized	O
by	O
10%	O
/	O
20	O
%	O
of	O
input	O
/	O
output	O
and	O
20%	O
/	O
30	O
%	O
of	O
input	B-Method
/	I-Method
output	I-Method
dropouts	I-Method
and	O
the	O
NTI	B-Method
-	I-Method
SLSTM	I-Method
-	I-Method
LSTM	I-Method
model	I-Method
20	O
%	O
of	O
input	O
and	O
20%	O
/	O
30	O
%	O
of	O
input	O
/	O
output	O
dropouts	O
for	O
binary	B-Task
and	I-Task
fine	I-Task
-	I-Task
grained	I-Task
settings	I-Task
.	O
	
NTI	B-Method
-	I-Method
SLSTM	I-Method
-	I-Method
LSTM	I-Method
(	O
as	O
shown	O
in	O
Table	O
[	O
reference	O
]	O
)	O
set	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
results	O
on	O
both	O
subtasks	O
.	O
	
Our	O
NTI	B-Method
-	I-Method
SLSTM	I-Method
model	I-Method
performed	O
slightly	O
worse	O
than	O
its	O
constituency	O
tree	B-Method
-	O
based	O
counter	O
part	O
,	O
CT	O
-	O
LSTM	B-Method
model	O
.	O
	
The	O
CT	O
-	O
LSTM	B-Method
model	O
composes	O
phrases	O
according	O
to	O
the	O
output	O
of	O
a	O
sentence	B-Method
parser	I-Method
and	O
uses	O
a	O
node	B-Method
composition	I-Method
function	I-Method
similar	O
to	O
S	B-Method
-	I-Method
LSTM	I-Method
.	O
	
After	O
we	O
transformed	O
the	O
input	O
with	O
the	O
LSTM	B-Method
leaf	O
node	O
function	O
,	O
we	O
achieved	O
the	O
best	O
performance	O
on	O
this	O
task	O
.	O
	
section	O
:	O
Qualitative	B-Task
Analysis	I-Task
	
subsection	O
:	O
Attention	B-Task
and	O
Compositionality	O
	
To	O
help	O
analyzing	O
the	O
results	O
,	O
we	O
output	O
attention	O
weights	O
by	O
our	O
NTI	B-Method
-	I-Method
SLSTM	I-Method
node	I-Method
-	I-Method
by	I-Method
-	I-Method
node	I-Method
global	I-Method
attention	I-Method
model	I-Method
.	O
	
Figure	O
[	O
reference	O
]	O
shows	O
the	O
attention	O
heatmaps	O
for	O
two	O
sentences	O
in	O
the	O
SNLI	B-Material
test	O
set	O
.	O
	
It	O
shows	O
that	O
our	O
model	O
semantically	O
aligns	O
single	O
or	O
multiword	O
expressions	O
(	O
”	O
little	O
child	O
”	O
and	O
”	O
toddler	O
”	O
;	O
”	O
rock	O
wall	O
”	O
and	O
”	O
stone	O
”	O
)	O
.	O
	
In	O
addition	O
,	O
our	O
model	O
is	O
able	O
to	O
re	O
-	O
orient	O
its	O
attention	O
over	O
different	O
parts	O
of	O
the	O
hypothesis	O
when	O
the	O
expression	O
is	O
more	O
complex	O
.	O
	
For	O
example	O
,	O
for	O
(	O
c	O
)	O
”	O
rock	O
wall	O
in	O
autumn	O
”	O
,	O
NTI	B-Method
mostly	O
focuses	O
on	O
the	O
nodes	O
in	O
depth	O
1	O
,	O
2	O
and	O
3	O
representing	O
contexts	O
related	O
to	O
”	O
a	O
stone	O
”	O
,	O
”	O
leaves	O
.	O
”	O
and	O
”	O
a	O
stone	O
wall	O
surrounded	O
”	O
.	O
	
Surprisingly	O
,	O
attention	O
degree	O
for	O
the	O
single	O
word	O
expression	O
like	O
”	O
stone	O
”	O
,	O
”	O
wall	O
”	O
and	O
”	O
leaves	O
”	O
is	O
lower	O
to	O
compare	O
with	O
multiword	O
phrases	O
.	O
	
Sequence	B-Method
models	I-Method
lack	O
this	O
property	O
as	O
they	O
have	O
no	O
explicit	O
composition	B-Method
module	I-Method
to	O
produce	O
such	O
mutiword	O
phrases	O
.	O
	
Finally	O
,	O
the	O
most	O
interesting	O
pattern	O
is	O
that	O
the	O
model	O
attends	O
over	O
higher	O
level	O
(	O
low	O
depth	O
)	O
tree	B-Method
nodes	O
with	O
rich	O
semantics	O
when	O
considering	O
a	O
(	O
c	O
)	O
longer	O
phrase	O
or	O
(	O
d	O
)	O
full	O
sentence	O
.	O
	
As	O
shown	O
in	O
(	O
d	O
)	O
,	O
the	O
NTI	B-Method
model	O
aligns	O
the	O
root	O
node	O
representing	O
the	O
whole	O
hypothesis	O
sentence	O
to	O
the	O
higher	O
level	O
tree	B-Method
nodes	O
covering	O
larger	O
sub	O
-	O
trees	O
in	O
the	O
premise	O
.	O
	
It	O
certainly	O
ignores	O
the	O
lower	O
level	O
single	O
word	O
expressions	O
and	O
only	O
starts	O
to	O
attend	O
when	O
the	O
words	O
are	O
collectively	O
to	O
form	O
rich	O
semantics	O
.	O
	
subsection	O
:	O
Learned	O
Representations	O
of	O
Phrases	O
and	O
Sentences	O
	
Using	O
cosine	O
similarity	O
between	O
their	O
representations	O
produced	O
by	O
the	O
NTI	B-Method
-	I-Method
SLSTM	I-Method
model	I-Method
,	O
we	O
show	O
that	O
NTI	B-Method
is	O
able	O
to	O
capture	O
paraphrases	O
on	O
SNLI	B-Material
test	O
data	O
.	O
	
As	O
shown	O
in	O
Table	O
[	O
reference	O
]	O
,	O
NTI	B-Method
seems	O
to	O
distinguish	O
plural	O
from	O
singular	O
forms	O
(	O
similar	O
phrases	O
to	O
”	O
a	O
person	O
”	O
)	O
.	O
	
In	O
addition	O
,	O
NTI	B-Method
captures	O
non	O
-	O
surface	O
knowledge	O
.	O
	
For	O
example	O
,	O
the	O
phrases	O
similar	O
to	O
”	O
park	O
for	O
fun	O
”	O
tend	O
to	O
align	O
to	O
the	O
semantic	O
content	O
of	O
fun	O
and	O
park	O
,	O
including	O
”	O
people	O
play	O
frisbee	O
outdoors	O
”	O
.	O
	
The	O
NTI	B-Method
model	O
was	O
able	O
to	O
relate	O
”	O
Santa	O
Claus	O
”	O
to	O
christmas	O
and	O
snow	O
.	O
	
Interestingly	O
,	O
the	O
learned	O
representations	O
were	O
also	O
able	O
to	O
connect	O
implicit	O
semantics	O
.	O
	
For	O
example	O
,	O
NTI	B-Method
found	O
that	O
”	O
sad	O
,	O
depressed	O
,	O
and	O
hatred	O
”	O
is	O
close	O
to	O
the	O
phrases	O
like	O
”	O
an	O
Obama	O
supporter	O
is	O
upset	O
”	O
.	O
	
Overall	O
the	O
NTI	B-Method
model	O
is	O
robust	O
to	O
the	O
length	O
of	O
the	O
phrases	O
being	O
matched	O
.	O
	
Given	O
a	O
short	O
phrase	O
,	O
NTI	B-Method
can	O
retrieve	O
longer	O
yet	O
semantically	O
coherent	O
sequences	O
from	O
the	O
SNLI	B-Material
test	O
set	O
.	O
	
In	O
Table	O
[	O
reference	O
]	O
,	O
we	O
show	O
nearest	O
-	O
neighbor	O
sentences	O
from	O
SNLI	B-Material
test	O
set	O
.	O
	
Note	O
that	O
the	O
sentences	O
listed	O
in	O
the	O
first	O
two	O
columns	O
sound	O
semantically	O
coherent	O
but	O
not	O
the	O
ones	O
in	O
the	O
last	O
column	O
.	O
	
The	O
query	O
sentence	O
”	O
A	O
dog	O
sells	O
a	O
women	O
a	O
hat	O
”	O
does	O
not	O
actually	O
represent	O
a	O
common	O
-	O
sense	O
knowledge	O
and	O
this	O
sentence	O
now	O
seem	O
to	O
confuse	O
the	O
NTI	B-Method
model	O
.	O
	
As	O
a	O
result	O
,	O
the	O
retrieved	O
sentence	O
are	O
arbitrary	O
and	O
not	O
coherent	O
.	O
	
subsection	O
:	O
Effects	O
of	O
Padding	B-Metric
Size	I-Metric
	
We	O
introduced	O
a	O
special	O
padding	O
character	O
in	O
order	O
to	O
construct	O
full	O
binary	O
tree	B-Method
.	O
	
Does	O
this	O
padding	O
character	O
influence	O
the	O
performance	O
of	O
the	O
NTI	B-Method
models	O
?	O
	
In	O
Figure	O
[	O
reference	O
]	O
,	O
we	O
show	O
relationship	O
between	O
the	O
padding	O
size	O
and	O
the	O
accuracy	B-Metric
on	O
Stanford	B-Material
sentiment	I-Material
analysis	I-Material
data	I-Material
.	O
	
Each	O
sentence	O
was	O
padded	O
to	O
form	O
a	O
full	O
binary	O
tree	B-Method
.	O
	
The	O
x	O
-	O
axis	O
represents	O
the	O
number	O
of	O
padding	O
characters	O
introduced	O
.	O
	
When	O
the	O
padding	O
size	O
is	O
less	O
(	O
up	O
to	O
10	O
)	O
,	O
the	O
NTI	B-Method
-	I-Method
SLSTM	I-Method
-	I-Method
LSTM	I-Method
model	I-Method
performs	O
better	O
.	O
	
However	O
,	O
this	O
model	O
tends	O
to	O
perform	O
poorly	O
or	O
equally	O
when	O
the	O
padding	O
size	O
is	O
large	O
.	O
	
Overall	O
we	O
do	O
not	O
observe	O
any	O
significant	O
performance	O
drop	O
for	O
both	O
models	O
as	O
the	O
padding	O
size	O
increases	O
.	O
	
This	O
suggests	O
that	O
NTI	B-Method
learns	O
to	O
ignore	O
the	O
special	O
padding	O
character	O
while	O
processing	O
padded	O
sentences	O
.	O
	
The	O
same	O
scenario	O
was	O
also	O
observed	O
while	O
analyzing	O
attention	O
weights	O
.	O
	
The	O
attention	O
over	O
the	O
padded	O
nodes	O
was	O
nearly	O
zero	O
.	O
	
section	O
:	O
Discussion	O
and	O
Conclusion	O
	
We	O
introduced	O
Neural	B-Method
Tree	I-Method
Indexers	I-Method
,	O
a	O
class	O
of	O
tree	B-Method
structured	O
recursive	O
neural	O
network	O
.	O
	
The	O
NTI	B-Method
models	O
achieved	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
performance	O
on	O
different	O
NLP	B-Task
tasks	I-Task
.	O
	
Most	O
of	O
the	O
NTI	B-Method
models	O
form	O
deep	B-Method
neural	I-Method
networks	I-Method
and	O
we	O
think	O
this	O
is	O
one	O
reason	O
that	O
NTI	B-Method
works	O
well	O
even	O
if	O
it	O
lacks	O
direct	O
linguistic	O
motivations	O
followed	O
by	O
other	O
syntactic	O
-	O
tree	B-Method
-	O
structured	O
recursive	O
models	O
.	O
	
CNN	B-Method
and	O
NTI	B-Method
are	O
topologically	O
related	O
.	O
	
Both	O
NTI	B-Method
and	O
CNNs	B-Method
are	O
hierarchical	O
.	O
	
However	O
,	O
current	O
implementation	O
of	O
NTI	B-Method
only	O
operates	O
on	O
non	O
-	O
overlapping	O
sub	O
-	O
trees	O
while	O
CNNs	B-Method
can	O
slide	O
over	O
the	O
input	O
to	O
produce	O
higher	O
-	O
level	B-Method
representations	I-Method
.	O
	
NTI	B-Method
is	O
flexible	O
in	O
selecting	O
the	O
node	O
function	O
and	O
the	O
attention	B-Method
mechanism	I-Method
.	O
	
Like	O
CNN	B-Method
,	O
the	O
computation	O
in	O
the	O
same	O
tree	B-Method
-	O
depth	O
can	O
be	O
parallelized	O
effectively	O
;	O
and	O
therefore	O
NTI	B-Method
is	O
scalable	O
and	O
suitable	O
for	O
large	B-Task
-	I-Task
scale	I-Task
sequence	I-Task
processing	I-Task
.	O
	
Note	O
that	O
NTI	B-Method
can	O
be	O
seen	O
as	O
a	O
generalization	O
of	O
LSTM	B-Method
.	O
	
If	O
we	O
construct	O
left	O
-	O
branching	O
trees	O
in	O
a	O
bottom	O
-	O
up	O
fashion	O
,	O
the	O
model	O
acts	O
just	O
like	O
sequential	O
LSTM	B-Method
.	O
	
Different	O
branching	O
factors	O
for	O
the	O
underlying	O
tree	B-Method
structure	O
have	O
yet	O
to	O
be	O
explored	O
.	O
	
NTI	B-Method
can	O
be	O
extended	O
so	O
it	O
learns	O
to	O
select	O
and	O
compose	O
dynamic	O
number	O
of	O
nodes	O
for	O
efficiency	O
,	O
essentially	O
discovering	O
intrinsic	O
hierarchical	O
structure	O
in	O
the	O
input	O
.	O
	
section	O
:	O
Acknowledgments	O
	
We	O
would	O
like	O
to	O
thank	O
the	O
anonymous	O
reviewers	O
for	O
their	O
insightful	O
comments	O
and	O
suggestions	O
.	O
	
This	O
work	O
was	O
supported	O
in	O
part	O
by	O
the	O
grant	O
HL125089	O
from	O
the	O
National	O
Institutes	O
of	O
Health	O
(	O
NIH	O
)	O
.	O
	
Any	O
opinions	O
,	O
findings	O
and	O
conclusions	O
or	O
recommendations	O
expressed	O
in	O
this	O
material	O
are	O
those	O
of	O
the	O
authors	O
and	O
do	O
not	O
necessarily	O
reflect	O
those	O
of	O
the	O
sponsor	O
.	O
	
bibliography	O
:	O
References	O
	
document	O
:	O
Understanding	B-Task
Humans	I-Task
in	I-Task
Crowded	I-Task
Scenes	I-Task
:	O
Deep	B-Method
Nested	I-Method
Adversarial	I-Method
Learning	I-Method
and	O
A	O
New	O
Benchmark	O
for	O
Multi	B-Task
-	I-Task
Human	I-Task
Parsing	I-Task
	
Despite	O
the	O
noticeable	O
progress	O
in	O
perceptual	B-Task
tasks	I-Task
like	O
detection	B-Task
,	O
instance	B-Task
segmentation	I-Task
and	O
human	B-Task
parsing	I-Task
,	O
computers	O
still	O
perform	O
unsatisfactorily	O
on	O
visually	B-Task
understanding	I-Task
humans	I-Task
in	I-Task
crowded	I-Task
scenes	I-Task
,	O
such	O
as	O
group	B-Task
behavior	I-Task
analysis	I-Task
,	O
person	B-Task
re	I-Task
-	I-Task
identification	I-Task
and	O
autonomous	B-Task
driving	I-Task
,	O
etc	O
.	O
	
To	O
this	O
end	O
,	O
models	O
need	O
to	O
comprehensively	O
perceive	O
the	O
semantic	O
information	O
and	O
the	O
differences	O
between	O
instances	O
in	O
a	O
multi	O
-	O
human	O
image	O
,	O
which	O
is	O
recently	O
defined	O
as	O
the	O
multi	O
-	O
human	B-Task
parsing	I-Task
task	O
.	O
	
In	O
this	O
paper	O
,	O
we	O
present	O
a	O
new	O
large	O
-	O
scale	O
database	O
“	O
M	B-Task
ulti	I-Task
-	I-Task
	
H	O
uman	O
	
P	B-Method
arsing	I-Method
(	O
MHP	B-Task
)	O
”	O
for	O
algorithm	B-Task
development	I-Task
and	O
evaluation	B-Task
,	O
and	O
advances	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
in	O
understanding	B-Task
humans	I-Task
in	I-Task
crowded	I-Task
scenes	I-Task
.	O
	
MHP	B-Task
contains	O
25	O
,	O
403	O
elaborately	O
annotated	O
images	O
with	O
58	O
fine	O
-	O
grained	O
semantic	O
category	O
labels	O
,	O
involving	O
2	O
-	O
26	O
persons	O
per	O
image	O
and	O
captured	O
in	O
real	O
-	O
world	O
scenes	O
from	O
various	O
viewpoints	O
,	O
poses	O
,	O
occlusion	O
,	O
interactions	O
and	O
background	O
.	O
	
We	O
further	O
propose	O
a	O
novel	O
deep	O
N	B-Method
ested	I-Method
A	I-Method
dversarial	I-Method
N	I-Method
etwork	I-Method
(	O
NAN	B-Method
)	O
model	O
for	O
multi	B-Task
-	I-Task
human	I-Task
parsing	I-Task
.	O
	
NAN	B-Method
consists	O
of	O
three	O
G	O
enerative	O
	
A	O
dversarial	O
N	O
etwork	O
(	O
GAN	B-Method
)-	O
like	O
sub	O
-	O
nets	O
,	O
respectively	O
performing	O
semantic	B-Method
saliency	I-Method
prediction	I-Method
,	O
instance	B-Method
-	I-Method
agnostic	I-Method
parsing	I-Method
and	O
instance	B-Method
-	I-Method
aware	I-Method
clustering	I-Method
.	O
	
These	O
sub	O
-	O
nets	O
form	O
a	O
nested	O
structure	O
and	O
are	O
carefully	O
designed	O
to	O
learn	O
jointly	O
in	O
an	O
end	O
-	O
to	O
-	O
end	O
way	O
.	O
	
NAN	B-Method
consistently	O
outperforms	O
existing	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
solutions	O
on	O
our	O
MHP	B-Task
and	O
several	O
other	O
datasets	O
,	O
and	O
serves	O
as	O
a	O
strong	O
baseline	O
to	O
drive	O
the	O
future	O
research	O
for	O
multi	B-Task
-	I-Task
human	I-Task
parsing	I-Task
.	O
	
section	O
:	O
Introduction	O
	
One	O
of	O
the	O
primary	O
goals	O
of	O
intelligent	B-Task
human	I-Task
-	I-Task
computer	I-Task
interaction	I-Task
is	O
understanding	O
the	O
humans	O
in	O
visual	O
scenes	O
.	O
	
It	O
involves	O
several	O
perceptual	B-Task
tasks	I-Task
including	O
detection	B-Task
,	O
i.e.	O
localizing	O
different	O
persons	O
at	O
a	O
coarse	O
,	O
bounding	O
box	O
level	O
(	O
Fig	O
.	O
	
[	O
reference	O
]	O
(	O
a	O
)	O
)	O
,	O
instance	B-Task
segmentation	I-Task
,	O
i.e.	O
labelling	O
each	O
pixel	O
of	O
each	O
person	O
uniquely	O
(	O
Fig	O
.	O
	
[	O
reference	O
]	O
(	O
b	O
)	O
)	O
,	O
and	O
human	B-Task
parsing	I-Task
,	O
i.e.	O
decomposing	O
persons	O
into	O
their	O
semantic	O
categories	O
(	O
Fig	O
.	O
	
[	O
reference	O
]	O
	
(	O
c	O
)	O
)	O
.	O
	
Recently	O
,	O
deep	B-Method
learning	I-Method
based	I-Method
methods	I-Method
have	O
achieved	O
remarkable	O
sucess	O
in	O
these	O
perceptual	B-Task
tasks	I-Task
thanks	O
to	O
the	O
availability	O
of	O
plentiful	O
annotated	O
images	O
for	O
training	O
and	O
evaluation	B-Task
purposes	I-Task
.	O
	
Though	O
exciting	O
,	O
current	O
progress	O
is	O
still	O
far	O
from	O
the	O
utimate	O
goal	O
of	O
visually	B-Task
understanding	I-Task
humans	I-Task
.	O
	
As	O
Fig	O
.	O
	
[	O
reference	O
]	O
shows	O
,	O
previous	O
efforts	O
on	O
understanding	O
humans	B-Task
in	I-Task
visual	I-Task
scenes	I-Task
	
either	O
only	O
consider	O
coarse	O
information	O
or	O
are	O
agnostic	O
to	O
different	O
instances	O
.	O
	
In	O
the	O
real	O
-	O
world	O
scenarios	O
,	O
it	O
is	O
more	O
likely	O
that	O
there	O
simutaneously	O
exist	O
multiple	O
persons	O
,	O
with	O
various	O
human	O
interactions	O
,	O
poses	O
and	O
occlusion	O
.	O
	
Thus	O
,	O
it	O
is	O
more	O
practically	O
demanded	O
to	O
parse	O
human	O
body	O
parts	O
and	O
fashion	O
items	O
at	O
the	O
instance	O
level	O
,	O
which	O
is	O
recently	O
defined	O
as	O
the	O
multi	O
-	O
human	B-Task
parsing	I-Task
task	O
.	O
	
Multi	B-Task
-	I-Task
human	I-Task
parsing	I-Task
enables	O
more	O
detailed	O
understanding	B-Task
of	I-Task
humans	I-Task
in	O
crowded	O
scenes	O
and	O
aligns	O
better	O
with	O
many	O
real	B-Task
-	I-Task
world	I-Task
applications	I-Task
,	O
such	O
as	O
group	B-Task
behavior	I-Task
analysis	I-Task
,	O
person	B-Task
re	I-Task
-	I-Task
identification	I-Task
,	O
e	B-Task
-	I-Task
commerce	I-Task
,	O
image	B-Task
editing	I-Task
,	O
video	B-Task
surveillance	I-Task
,	O
autonomous	B-Task
driving	I-Task
and	O
virtual	B-Task
reality	I-Task
.	O
	
However	O
,	O
the	O
existing	O
benchmark	O
datasets	O
are	O
not	O
suitable	O
for	O
such	O
a	O
new	O
task	O
.	O
	
Even	O
though	O
Li	O
et	O
al	O
.	O
proposed	O
a	O
preliminary	O
M	O
	
ulti	O
-	O
H	O
uman	O
	
P	O
arsing	O
(	O
MHP	B-Material
v1.0	I-Material
)	O
	
dataset	O
	
,	O
it	O
only	O
contains	O
4	O
,	O
980	O
images	O
annotated	O
with	O
18	O
semantic	O
labels	O
.	O
	
In	O
this	O
work	O
,	O
we	O
propose	O
a	O
new	O
large	B-Task
-	I-Task
scale	I-Task
benchmark	I-Task
“	O
M	B-Task
	
ulti	B-Task
-	I-Task
H	I-Task
uman	I-Task
	
P	B-Task
arsing	I-Task
(	O
MHP	B-Material
v2.0	I-Material
)	O
	
”	O
,	O
aiming	O
to	O
push	O
the	O
frontiers	O
of	O
multi	O
-	O
human	B-Task
parsing	I-Task
research	O
towards	O
holistically	B-Task
understanding	I-Task
humans	I-Task
in	I-Task
crowded	I-Task
scenes	I-Task
.	O
	
The	O
data	O
in	O
MHP	B-Material
v2.0	I-Material
cover	O
wide	O
variability	O
and	O
complexity	O
w.r.t	O
.	O
viewpoints	O
,	O
poses	O
,	O
occlusion	O
,	O
human	O
interactions	O
and	O
background	O
.	O
	
It	O
in	O
total	O
includes	O
25	O
,	O
403	O
human	O
images	O
with	O
pixel	O
-	O
wise	O
annotations	O
of	O
58	O
semantic	O
categories	O
.	O
	
We	O
further	O
propose	O
a	O
novel	O
deep	O
N	B-Method
ested	I-Method
A	I-Method
dversarial	I-Method
N	I-Method
etwork	I-Method
(	O
NAN	B-Method
)	O
model	O
for	O
solving	O
the	O
challenging	O
multi	O
-	O
human	B-Task
parsing	I-Task
problem	O
.	O
	
Unlike	O
most	O
existing	O
methods	O
which	O
rely	O
on	O
separate	O
stages	O
of	O
instance	B-Task
localization	I-Task
,	O
human	B-Task
parsing	I-Task
and	O
result	B-Task
refinement	I-Task
,	O
the	O
proposed	O
NAN	B-Method
parses	O
semantic	B-Task
categories	I-Task
and	O
differentiates	O
different	O
person	O
instances	O
simultaneously	O
in	O
an	O
effective	O
and	O
time	O
-	O
efficient	O
manner	O
.	O
	
NAN	B-Method
consists	O
of	O
three	O
G	O
enerative	O
	
A	O
dversarial	O
N	O
etwork	O
(	O
GAN	B-Method
)-	O
like	O
sub	O
-	O
nets	O
,	O
respectively	O
performing	O
semantic	B-Method
saliency	I-Method
prediction	I-Method
,	O
instance	B-Method
-	I-Method
agnostic	I-Method
parsing	I-Method
and	O
instance	B-Method
-	I-Method
aware	I-Method
clustering	I-Method
.	O
	
Each	O
sub	B-Task
-	I-Task
task	I-Task
is	O
simpler	O
than	O
the	O
original	O
multi	O
-	O
human	B-Task
parsing	I-Task
task	O
,	O
and	O
is	O
more	O
easily	O
addressed	O
by	O
the	O
corresponding	O
sub	O
-	O
net	O
.	O
	
Unlike	O
many	O
multi	B-Task
-	I-Task
task	I-Task
learning	I-Task
applications	I-Task
,	O
in	O
our	O
method	O
the	O
sub	O
-	O
nets	O
depend	O
on	O
each	O
other	O
,	O
forming	O
a	O
causal	O
nest	O
by	O
dynamically	O
boosting	O
each	O
other	O
through	O
an	O
adversarial	B-Method
strategy	I-Method
(	O
See	O
Fig	O
.	O
	
[	O
reference	O
]	O
)	O
,	O
which	O
is	O
hence	O
called	O
a	O
“	O
nested	B-Method
adversarial	I-Method
learning	I-Method
”	I-Method
structure	I-Method
.	O
	
Such	O
a	O
structure	O
enables	O
effortless	O
gradient	O
B	B-Method
ackpro	I-Method
P	I-Method
agation	I-Method
(	O
BP	B-Method
)	O
in	O
NAN	B-Method
such	O
that	O
it	O
can	O
be	O
trained	O
in	O
a	O
holistic	O
,	O
end	O
-	O
to	O
-	O
end	O
way	O
,	O
which	O
is	O
favorable	O
to	O
both	O
accuracy	B-Metric
and	O
speed	B-Metric
.	O
	
We	O
conduct	O
qualitative	O
and	O
quantitative	O
experiments	O
on	O
the	O
MHP	B-Task
	
v2.0	O
	
dataset	O
proposed	O
in	O
this	O
work	O
,	O
as	O
well	O
as	O
the	O
MHP	B-Material
v1.0	I-Material
,	O
PASCAL	B-Material
-	I-Material
Person	I-Material
-	I-Material
Part	I-Material
and	O
Buffy	B-Material
benchmark	I-Material
datasets	I-Material
.	O
	
The	O
results	O
demonstrate	O
the	O
superiority	O
of	O
NAN	B-Method
on	O
multi	B-Task
-	I-Task
human	I-Task
parsing	I-Task
over	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
arts	O
.	O
	
Our	O
contributions	O
are	O
summarized	O
as	O
follows	O
.	O
	
We	O
propose	O
a	O
new	O
large	B-Metric
-	I-Metric
scale	I-Metric
benchmark	I-Metric
and	I-Metric
evaluation	I-Metric
server	I-Metric
to	O
advance	O
understanding	B-Task
of	I-Task
humans	I-Task
in	I-Task
crowded	I-Task
scenes	I-Task
,	O
which	O
contains	O
25	O
,	O
403	O
images	O
annotated	O
pixel	O
-	O
wisely	O
with	O
58	O
semantic	O
category	O
labels	O
.	O
	
We	O
propose	O
a	O
novel	O
deep	O
N	B-Method
ested	I-Method
A	I-Method
dversarial	I-Method
N	I-Method
etwork	I-Method
(	O
NAN	B-Method
)	O
model	O
for	O
multi	B-Task
-	I-Task
human	I-Task
parsing	I-Task
,	O
which	O
serves	O
as	O
a	O
strong	O
baseline	O
to	O
inspire	O
more	O
future	O
research	O
efforts	O
on	O
this	O
task	O
.	O
	
Comprehensive	O
evaluations	O
on	O
the	O
MHP	B-Task
	
v2.0	O
	
dataset	O
proposed	O
in	O
this	O
work	O
,	O
as	O
well	O
as	O
the	O
MHP	B-Material
v1.0	I-Material
,	O
PASCAL	B-Material
-	I-Material
Person	I-Material
-	I-Material
Part	I-Material
and	O
Buffy	B-Material
benchmark	I-Material
datasets	I-Material
verify	O
the	O
superiority	O
of	O
NAN	B-Method
on	O
understanding	B-Task
humans	I-Task
in	O
crowded	O
scenes	O
over	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
arts	O
.	O
	
section	O
:	O
Related	O
Work	O
	
paragraph	O
:	O
Human	B-Material
Parsing	I-Material
Datasets	I-Material
	
The	O
statistics	O
of	O
popular	O
publicly	O
available	O
datasets	O
for	O
human	B-Task
parsing	I-Task
are	O
summarized	O
in	O
Tab	O
.	O
	
[	O
reference	O
]	O
.	O
	
The	O
Buffy	B-Material
dataset	I-Material
was	O
released	O
in	O
2011	O
for	O
human	B-Task
parsing	I-Task
and	O
instance	B-Task
segmentation	I-Task
.	O
	
It	O
contains	O
only	O
748	O
images	O
annotated	O
with	O
13	O
semantic	O
categories	O
.	O
	
The	O
Fashionista	B-Material
dataset	I-Material
was	O
released	O
in	O
2012	O
for	O
human	B-Task
parsing	I-Task
,	O
containing	O
limited	O
images	O
annotated	O
with	O
56	O
fashion	O
categories	O
.	O
	
The	O
PASCAL	B-Material
-	I-Material
Person	I-Material
-	I-Material
Part	I-Material
dataset	O
was	O
initially	O
annotated	O
by	O
Chen	O
et	O
al	O
.	O
from	O
the	O
PASCAL	B-Material
-	I-Material
VOC	I-Material
-	I-Material
2010	I-Material
dataset	I-Material
.	O
	
Chen	O
et	O
al	O
.	O
extended	O
it	O
for	O
human	B-Task
parsing	I-Task
with	O
7	O
coarse	O
body	O
part	O
labels	O
.	O
	
The	O
ATR	B-Material
dataset	I-Material
was	O
released	O
in	O
2015	O
for	O
human	B-Task
parsing	I-Task
with	O
a	O
large	O
number	O
of	O
images	O
annotated	O
with	O
18	O
semantic	O
categories	O
.	O
	
The	O
LIP	B-Material
dataset	O
further	O
extended	O
ATR	O
by	O
cropping	O
person	O
instances	O
from	O
Microsoft	B-Material
COCO	I-Material
.	O
	
It	O
is	O
a	O
large	O
-	O
scale	O
human	B-Task
parsing	I-Task
dataset	O
with	O
densely	O
pixel	O
-	O
wise	O
annotations	O
of	O
20	O
semantic	O
categories	O
.	O
	
But	O
it	O
has	O
two	O
limitations	O
.	O
	
1	O
)	O
	
Despite	O
the	O
large	O
data	O
size	O
,	O
it	O
contains	O
limited	O
semantic	O
category	O
annotations	O
,	O
which	O
restricts	O
the	O
fine	B-Task
-	I-Task
grained	I-Task
understanding	I-Task
of	I-Task
humans	I-Task
in	I-Task
visual	I-Task
scenes	I-Task
.	O
	
2	O
)	O
In	O
LIP	B-Material
,	O
only	O
a	O
small	O
proportion	O
of	O
images	O
involve	O
multiple	O
persons	O
with	O
interactions	O
.	O
	
Such	O
an	O
instance	B-Method
-	I-Method
agnostic	I-Method
setting	I-Method
severely	O
deviates	O
from	O
reality	O
.	O
	
Even	O
in	O
the	O
MHP	B-Task
v1.0	O
dataset	O
proposed	O
by	O
Li	O
et	O
al	O
.	O
for	O
multi	B-Task
-	I-Task
human	I-Task
parsing	I-Task
,	O
only	O
4	O
,	O
980	O
images	O
are	O
included	O
and	O
annotated	O
with	O
18	O
semantic	O
labels	O
.	O
	
Comparatively	O
,	O
our	O
MHP	B-Material
v2.0	I-Material
dataset	I-Material
contains	O
25	O
,	O
403	O
elaborately	O
annotated	O
images	O
with	O
58	O
fine	O
-	O
grained	O
semantic	O
part	O
labels	O
.	O
	
It	O
is	O
the	O
largest	O
and	O
most	O
comprehensive	O
multi	O
-	O
human	B-Task
parsing	I-Task
dataset	O
to	O
date	O
,	O
to	O
our	O
best	O
knowledge	O
.	O
	
Visual	O
comparisons	O
between	O
LIP	B-Material
,	O
MHP	B-Material
v1.0	I-Material
and	O
our	O
MHP	B-Material
v2.0	I-Material
are	O
provided	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
.	O
	
paragraph	O
:	O
Human	B-Method
Parsing	I-Method
Approaches	I-Method
	
Recently	O
,	O
many	O
research	O
efforts	O
have	O
been	O
devoted	O
to	O
human	B-Task
parsing	I-Task
due	O
to	O
its	O
wide	O
range	O
of	O
potential	O
applications	O
.	O
	
For	O
example	O
,	O
Liang	O
et	O
al	O
.	O
proposed	O
a	O
proposal	B-Method
-	I-Method
free	I-Method
network	I-Method
for	O
instance	B-Task
segmentation	I-Task
by	O
directly	O
predicting	O
the	O
instance	O
numbers	O
of	O
different	O
categories	O
and	O
the	O
pixel	O
-	O
level	O
information	O
.	O
	
Gong	O
et	O
al	O
.	O
proposed	O
a	O
self	B-Method
-	I-Method
supervised	I-Method
structure	I-Method
-	I-Method
sensitive	I-Method
learning	I-Method
approach	I-Method
,	O
which	O
imposes	O
human	O
pose	O
structures	O
to	O
parsing	O
results	O
without	O
resorting	O
to	O
extra	O
supervision	O
.	O
	
Liu	O
et	O
al	O
.	O
proposed	O
a	O
single	B-Method
frame	I-Method
video	I-Method
parsing	I-Method
method	I-Method
which	O
integrates	O
frame	B-Method
parsing	I-Method
,	O
optical	B-Method
flow	I-Method
estimation	I-Method
and	O
temporal	B-Method
fusion	I-Method
into	O
a	O
unified	B-Method
network	I-Method
.	O
	
Zhao	O
et	O
al	O
.	O
proposed	O
a	O
self	B-Method
-	I-Method
supervised	I-Method
neural	I-Method
aggregation	I-Method
network	I-Method
,	O
which	O
learns	O
to	O
aggregate	O
the	O
multi	O
-	O
scale	O
features	O
and	O
incorporates	O
a	O
self	O
-	O
supervised	O
joint	O
loss	O
to	O
ensure	O
the	O
consistency	O
between	O
parsing	O
and	O
pose	O
.	O
	
He	O
et	O
al	O
.	O
proposed	O
the	O
Mask	B-Method
R	I-Method
-	I-Method
CNN	I-Method
,	O
which	O
is	O
extended	O
from	O
Faster	O
R	O
-	O
CNN	B-Method
by	O
adding	O
a	O
branch	O
for	O
predicting	O
an	O
object	O
mask	O
in	O
parallel	O
with	O
the	O
existing	O
branch	O
for	O
bounding	B-Task
box	I-Task
recognition	I-Task
.	O
	
Brabandere	O
et	O
al	O
.	O
proposed	O
to	O
tackle	O
instance	B-Task
segmentation	I-Task
with	O
a	O
discriminative	B-Method
loss	I-Method
function	I-Method
,	O
operating	O
at	O
the	O
pixel	O
level	O
,	O
which	O
encourages	O
a	O
convolutional	B-Method
network	I-Method
to	O
produce	O
a	O
representation	O
of	O
the	O
image	O
that	O
can	O
be	O
easily	O
clustered	O
into	O
instances	O
with	O
a	O
simple	O
post	B-Method
-	I-Method
processing	I-Method
step	I-Method
.	O
	
However	O
,	O
these	O
methods	O
either	O
only	O
consider	O
coarse	O
semantic	O
information	O
or	O
are	O
agnostic	O
to	O
different	O
instances	O
.	O
	
To	O
enable	O
more	O
detailed	O
human	B-Task
-	I-Task
centric	I-Task
analysis	I-Task
,	O
Li	O
et	O
al	O
.	O
initially	O
proposed	O
the	O
multi	O
-	O
human	B-Task
parsing	I-Task
task	O
,	O
which	O
aligns	O
better	O
with	O
the	O
realistic	O
scenarios	O
.	O
	
They	O
also	O
proposed	O
a	O
novel	O
MH	B-Method
-	I-Method
Parser	I-Method
model	O
as	O
a	O
reference	O
method	O
which	O
generates	O
parsing	O
maps	O
and	O
instance	O
masks	O
simutaneously	O
in	O
a	O
bottom	O
-	O
up	O
fashion	O
.	O
	
Jiang	O
et	O
al	O
.	O
proposed	O
a	O
new	O
approach	O
to	O
segment	O
human	O
instances	O
and	O
label	O
their	O
body	O
parts	O
using	O
region	B-Method
assembly	I-Method
.	O
	
Li	O
et	O
al	O
.	O
proposed	O
a	O
framework	O
with	O
a	O
human	B-Method
detector	I-Method
and	O
a	O
category	B-Method
-	I-Method
level	I-Method
segmentation	I-Method
module	I-Method
to	O
segment	O
the	O
parts	O
of	O
objects	O
at	O
the	O
instance	O
level	O
.	O
	
These	O
methods	O
involve	O
mutiple	O
separate	O
stages	O
for	O
instance	O
localization	B-Task
,	O
human	B-Task
parsing	I-Task
and	O
result	B-Task
refinement	I-Task
.	O
	
In	O
comparison	O
,	O
the	O
proposed	O
NAN	B-Method
produces	O
accurate	O
multi	B-Task
-	I-Task
human	I-Task
parsing	I-Task
results	O
through	O
a	O
single	O
forward	B-Method
-	I-Method
pass	I-Method
in	O
a	O
time	O
-	O
efficient	O
manner	O
without	O
tedious	O
pre	O
-	O
or	O
post	B-Task
-	I-Task
processing	I-Task
.	O
	
section	O
:	O
Multi	B-Task
-	I-Task
Human	I-Task
Parsing	I-Task
Benchmark	O
	
In	O
this	O
section	O
,	O
we	O
introduce	O
the	O
“	O
M	O
	
ulti	O
-	O
H	O
uman	O
	
P	O
arsing	O
(	O
MHP	B-Material
v2.0	I-Material
)	O
	
”	O
,	O
a	O
new	O
large	O
-	O
scale	O
dataset	O
focusing	O
on	O
semantic	B-Task
understanding	I-Task
of	I-Task
humans	I-Task
in	I-Task
crowded	I-Task
scenes	I-Task
with	O
several	O
appealing	O
properties	O
.	O
	
1	O
)	O
	
It	O
contains	O
25	O
,	O
403	O
elaborately	O
annotated	O
images	O
with	O
58	O
fine	O
-	O
grained	O
labels	O
on	O
body	O
parts	O
,	O
fashion	O
items	O
and	O
one	O
background	O
label	O
,	O
which	O
is	O
larger	O
and	O
more	O
comprehensive	O
than	O
previous	O
similar	O
attempts	O
.	O
	
2	O
)	O
	
The	O
images	O
within	O
MHP	B-Material
v2.0	I-Material
are	O
collected	O
from	O
real	O
-	O
world	O
scenarios	O
,	O
involving	O
humans	O
with	O
various	O
viewpoints	O
,	O
poses	O
,	O
occlusion	O
,	O
interactions	O
and	O
resolution	O
.	O
	
3	O
)	O
	
The	O
background	O
of	O
images	O
in	O
MHP	B-Material
v2.0	I-Material
is	O
more	O
complex	O
and	O
diverse	O
than	O
previous	O
datasets	O
.	O
	
Some	O
examples	O
are	O
showed	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
.	O
	
The	O
MHP	B-Material
v2.0	I-Material
dataset	I-Material
is	O
expected	O
to	O
provide	O
a	O
new	O
benchmark	O
suitable	O
for	O
multi	B-Task
-	I-Task
human	I-Task
parsing	I-Task
together	O
with	O
a	O
standard	O
evaluation	O
server	O
where	O
the	O
test	O
set	O
will	O
be	O
kept	O
secret	O
to	O
avoid	O
overfitting	O
.	O
	
subsection	O
:	O
Image	B-Task
Collection	I-Task
and	O
Annotation	B-Task
	
We	O
manually	O
specify	O
some	O
underlying	O
relationships	O
(	O
such	O
as	O
family	O
,	O
couple	O
,	O
team	O
,	O
etc	O
.	O
)	O
and	O
possible	O
scenes	O
(	O
such	O
as	O
sports	O
,	O
conferences	O
,	O
banquets	O
,	O
etc	O
.	O
)	O
to	O
ensure	O
the	O
diversity	O
of	O
returned	O
results	O
.	O
	
Based	O
on	O
any	O
one	O
of	O
these	O
specifications	O
,	O
corresponding	O
multi	O
-	O
human	O
images	O
are	O
located	O
by	O
performing	O
Internet	O
searches	O
over	O
Creative	O
Commons	O
licensed	O
imagery	O
.	O
	
For	O
each	O
identified	O
image	O
,	O
the	O
contained	O
human	O
number	O
and	O
the	O
corresponding	O
URL	O
are	O
stored	O
in	O
a	O
spreadsheet	O
.	O
	
Automated	B-Method
scrapping	I-Method
software	I-Method
is	O
used	O
to	O
download	O
the	O
multi	O
-	O
human	O
imagery	O
and	O
stores	O
all	O
relevant	O
information	O
in	O
a	O
relational	O
database	O
.	O
	
Moreover	O
,	O
a	O
pool	O
of	O
images	O
containing	O
clearly	O
visible	O
persons	O
with	O
interactions	O
and	O
rich	O
fashion	O
items	O
is	O
also	O
constructed	O
from	O
the	O
existing	O
human	O
-	O
centric	O
datasets	O
to	O
augment	O
and	O
complement	O
Internet	B-Task
scraping	I-Task
results	O
.	O
	
After	O
curating	O
the	O
imagery	O
,	O
manual	B-Task
annotation	I-Task
is	O
conducted	O
by	O
professional	O
data	O
annotators	O
,	O
which	O
includes	O
two	O
distinct	O
tasks	O
.	O
	
The	O
first	O
task	O
is	O
manually	O
counting	O
the	O
number	O
of	O
foreground	O
persons	O
and	O
duplicating	O
each	O
image	O
to	O
several	O
copies	O
according	O
to	O
the	O
count	O
number	O
.	O
	
Each	O
duplicated	O
image	O
is	O
marked	O
with	O
the	O
image	O
ID	O
,	O
the	O
contained	O
person	O
number	O
and	O
a	O
self	O
-	O
index	O
.	O
	
The	O
second	O
is	O
assigning	O
the	O
fine	O
-	O
grained	O
pixel	O
-	O
wise	O
label	O
to	O
each	O
semantic	O
category	O
for	O
each	O
person	O
instance	O
.	O
	
We	O
implement	O
an	O
annotation	B-Method
tool	I-Method
and	O
generate	O
multi	B-Task
-	I-Task
scale	I-Task
superpixels	I-Task
of	I-Task
images	I-Task
based	O
on	O
to	O
speed	O
up	O
the	O
annotation	B-Task
.	O
	
See	O
Fig	O
.	O
	
[	O
reference	O
]	O
for	O
an	O
example	O
.	O
	
Each	O
multi	O
-	O
human	O
image	O
contains	O
at	O
least	O
two	O
instances	O
.	O
	
The	O
annotation	O
for	O
each	O
instance	O
is	O
done	O
in	O
a	O
left	O
-	O
to	O
-	O
right	O
order	O
,	O
corresponding	O
to	O
the	O
duplicated	O
image	O
with	O
the	O
self	O
-	O
index	O
from	O
beginning	O
to	O
end	O
.	O
	
For	O
each	O
instance	O
,	O
58	O
semantic	O
categories	O
are	O
defined	O
and	O
annotated	O
,	O
including	O
cap	O
/	O
hat	O
,	O
helmet	O
,	O
face	O
,	O
hair	O
,	O
left	O
-	O
arm	O
,	O
right	O
-	O
arm	O
,	O
left	O
-	O
hand	O
,	O
right	O
-	O
hand	O
,	O
protector	O
,	O
bikini	O
/	O
bra	O
,	O
jacket	O
/	O
windbreaker	O
/	O
hoodie	O
,	O
t	O
-	O
shirt	O
,	O
polo	O
-	O
shirt	O
,	O
sweater	O
,	O
singlet	O
,	O
torso	O
-	O
skin	O
,	O
pants	O
,	O
shorts	O
/	O
swim	O
-	O
shorts	O
,	O
skirt	O
,	O
stockings	O
,	O
socks	O
,	O
left	O
-	O
boot	O
,	O
right	O
-	O
boot	O
,	O
left	O
-	O
shoe	O
,	O
right	O
-	O
shoe	O
,	O
left	O
-	O
highheel	O
,	O
right	O
-	O
highheel	O
,	O
left	O
-	O
sandal	O
,	O
right	O
-	O
sandal	O
,	O
left	O
-	O
leg	O
,	O
right	O
-	O
leg	O
,	O
left	O
-	O
foot	O
,	O
right	O
-	O
foot	O
,	O
coat	O
,	O
dress	O
,	O
robe	O
,	O
jumpsuits	O
,	O
other	O
-	O
full	O
-	O
body	O
-	O
clothes	O
,	O
headwear	O
,	O
backpack	O
,	O
ball	O
,	O
bats	O
,	O
belt	O
,	O
bottle	O
,	O
carrybag	O
,	O
cases	O
,	O
sunglasses	O
,	O
eyewear	O
,	O
gloves	O
,	O
scarf	O
,	O
umbrella	O
,	O
wallet	O
/	O
purse	O
,	O
watch	O
,	O
wristband	O
,	O
tie	O
,	O
other	O
-	O
accessaries	O
,	O
other	O
-	O
upper	O
-	O
body	O
-	O
clothes	O
and	O
other	O
-	O
lower	O
-	O
body	O
-	O
clothes	O
.	O
	
Each	O
instance	O
has	O
a	O
complete	O
set	O
of	O
annotations	O
whenever	O
the	O
corresponding	O
category	O
appears	O
in	O
the	O
current	O
image	O
.	O
	
When	O
annotating	O
one	O
instance	O
,	O
others	O
are	O
regarded	O
as	O
background	O
.	O
	
Thus	O
,	O
the	O
resulting	O
annotation	O
set	O
for	O
each	O
image	O
consists	O
of	O
instance	O
-	O
level	O
parsing	O
masks	O
,	O
where	O
is	O
the	O
number	O
of	O
persons	O
in	O
the	O
image	O
.	O
	
After	O
annotation	O
,	O
manual	B-Task
inspection	I-Task
is	O
performed	O
on	O
all	O
images	O
and	O
corresponding	O
annotations	O
to	O
verify	O
the	O
correctness	O
.	O
	
In	O
cases	O
where	O
annotations	O
are	O
erroneous	O
,	O
the	O
information	O
is	O
manually	O
rectified	O
by	O
5	O
well	O
informed	O
analysts	O
.	O
	
The	O
whole	O
work	O
took	O
around	O
three	O
months	O
to	O
accomplish	O
by	O
25	O
professional	O
data	O
annotators	O
.	O
	
subsection	O
:	O
Dataset	O
Splits	O
and	O
Statistics	O
	
In	O
total	O
,	O
there	O
are	O
25	O
,	O
403	O
images	O
in	O
the	O
MHP	B-Material
v2.0	I-Material
dataset	I-Material
.	O
	
Each	O
image	O
contains	O
2	O
-	O
26	O
person	O
instances	O
,	O
with	O
3	O
on	O
average	O
.	O
	
The	O
resolution	O
of	O
the	O
images	O
ranges	O
from	O
85	O
100	O
to	O
4	O
,	O
511	O
6	O
,	O
919	O
,	O
with	O
644	O
718	O
on	O
average	O
.	O
	
We	O
spit	O
the	O
images	O
into	O
training	O
,	O
validation	O
and	O
testing	O
sets	O
.	O
	
Following	O
random	B-Method
selection	I-Method
,	O
we	O
arrive	O
at	O
a	O
unique	O
split	O
consisting	O
of	O
15	O
,	O
403	O
training	O
and	O
5	O
,	O
000	O
validation	O
images	O
with	O
publicly	O
available	O
annotations	O
,	O
as	O
well	O
as	O
5	O
,	O
000	O
testing	O
images	O
with	O
annotations	O
withheld	O
for	O
benchmarking	O
purpose	O
.	O
	
The	O
statistics	O
w.r.t	O
.	O
data	O
distribution	O
on	O
59	O
semantic	O
categories	O
,	O
the	O
average	O
semantic	B-Metric
category	I-Metric
number	I-Metric
per	O
image	O
and	O
the	O
average	O
instance	O
number	O
per	O
image	O
in	O
the	O
MHP	B-Task
	
v2.0	O
dataset	O
are	O
illustrated	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
(	O
a	O
)	O
,	O
(	O
b	O
)	O
and	O
(	O
c	O
)	O
,	O
respectively	O
.	O
	
In	O
general	O
,	O
face	O
,	O
arms	O
and	O
legs	O
are	O
the	O
most	O
remarkable	O
parts	O
of	O
a	O
human	O
body	O
.	O
	
However	O
,	O
understanding	O
humans	B-Task
in	I-Task
crowded	I-Task
scenes	I-Task
needs	O
to	O
analyze	O
fine	O
-	O
grained	O
details	O
of	O
each	O
person	O
of	O
interest	O
,	O
including	O
different	O
body	O
parts	O
,	O
clothes	O
and	O
accessaries	O
.	O
	
We	O
therefore	O
define	O
11	O
body	O
parts	O
,	O
and	O
47	O
clothes	O
and	O
accessaries	O
.	O
	
Among	O
these	O
11	O
body	O
parts	O
,	O
we	O
divide	O
arms	O
,	O
hands	O
,	O
legs	O
and	O
feet	O
into	O
left	O
and	O
right	O
side	O
for	O
more	O
precise	O
analysis	O
,	O
which	O
also	O
increases	O
the	O
difficulty	O
of	O
the	O
task	O
.	O
	
We	O
define	O
hair	O
,	O
face	O
and	O
torso	O
-	O
skin	O
as	O
the	O
remaining	O
three	O
body	O
parts	O
,	O
which	O
can	O
be	O
used	O
as	O
auxiliary	O
guidance	O
for	O
more	O
comprehensive	O
instance	B-Task
-	I-Task
level	I-Task
analysis	I-Task
.	O
	
As	O
for	O
clothing	B-Task
categories	I-Task
,	O
we	O
have	O
common	O
clothes	O
like	O
coat	O
,	O
jacket	O
/	O
windbreaker	O
/	O
hoodie	O
,	O
sweater	O
,	O
singlet	O
,	O
pants	O
,	O
shorts	O
/	O
swim	O
-	O
shorts	O
and	O
shoes	O
,	O
confusing	O
categories	O
such	O
as	O
t	O
-	O
shirt	O
v.s	O
.	O
polo	O
-	O
shirt	O
,	O
stockings	O
v.s	O
.	O
	
socks	O
,	O
skirt	O
	
v.s	O
.	O
dress	O
and	O
robe	O
,	O
and	O
boots	O
	
v.s	O
.	O
	
sandals	O
and	O
highheels	O
,	O
and	O
infrequent	O
categories	O
such	O
as	O
cap	O
/	O
hat	O
,	O
helmet	O
,	O
protector	O
,	O
bikini	O
/	O
bra	O
,	O
jumpsuits	O
,	O
gloves	O
and	O
scarf	O
.	O
	
Furthermore	O
,	O
accessaries	O
like	O
sunglasses	O
,	O
belt	O
,	O
tie	O
,	O
watch	O
and	O
bags	O
are	O
also	O
taken	O
into	O
account	O
,	O
which	O
are	O
common	O
but	O
hard	O
to	O
predict	O
,	O
especially	O
for	O
the	O
small	O
-	O
scale	O
ones	O
.	O
	
To	O
summarize	O
,	O
the	O
pre	O
-	O
defined	O
semantic	O
categories	O
of	O
MHP	B-Material
v2.0	I-Material
involve	O
most	O
body	O
parts	O
,	O
clothes	O
and	O
accessaries	O
of	O
different	O
styles	O
for	O
men	O
,	O
women	O
and	O
children	O
in	O
all	O
seasons	O
.	O
	
The	O
images	O
in	O
the	O
MHP	B-Material
	
v2.0	B-Material
	
dataset	B-Material
contain	O
diverse	O
instance	O
numbers	O
,	O
viewpoints	O
,	O
poses	O
,	O
occlusion	O
,	O
interactions	O
and	O
background	O
complexities	O
.	O
	
MHP	B-Task
	
v2.0	O
aligns	O
better	O
with	O
real	O
-	O
world	O
scenarios	O
and	O
serves	O
as	O
a	O
more	O
realistic	O
benchmark	O
for	O
human	B-Task
-	I-Task
centric	I-Task
analysis	I-Task
,	O
which	O
pushes	O
the	O
frontiers	O
of	O
fine	O
-	O
grained	O
multi	O
-	O
human	B-Task
parsing	I-Task
research	O
.	O
	
section	O
:	O
Deep	B-Method
Nested	I-Method
Adversarial	I-Method
Networks	I-Method
	
As	O
shown	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
,	O
the	O
proposed	O
deep	O
N	B-Method
ested	I-Method
A	I-Method
dversarial	I-Method
N	I-Method
etwork	I-Method
(	O
NAN	B-Method
)	O
model	O
consists	O
of	O
three	O
GAN	B-Method
-	O
like	O
sub	O
-	O
nets	O
that	O
jointly	O
perform	O
semantic	B-Method
saliency	I-Method
prediction	I-Method
,	O
instance	B-Method
-	I-Method
agnostic	I-Method
parsing	I-Method
and	O
instance	B-Method
-	I-Method
aware	I-Method
clustering	I-Method
end	O
-	O
to	O
-	O
end	O
.	O
	
NAN	B-Method
produces	O
accurate	O
multi	O
-	O
human	B-Task
parsing	I-Task
results	O
through	O
a	O
single	O
forward	B-Method
-	I-Method
pass	I-Method
in	O
a	O
time	O
-	O
efficient	O
manner	O
without	O
tedious	O
pre	O
-	O
or	O
post	B-Task
-	I-Task
processing	I-Task
.	O
	
We	O
now	O
present	O
each	O
component	O
in	O
details	O
.	O
	
subsection	O
:	O
Semantic	B-Task
Saliency	I-Task
Prediction	I-Task
	
Large	O
modality	O
and	O
interaction	O
variations	O
are	O
the	O
main	O
challenge	O
to	O
multi	B-Task
-	I-Task
human	I-Task
parsing	I-Task
and	O
also	O
the	O
key	O
obstacle	O
to	O
learning	O
a	O
well	O
-	O
performing	O
human	B-Method
-	I-Method
centric	I-Method
analysis	I-Method
model	I-Method
.	O
	
To	O
address	O
this	O
problem	O
,	O
we	O
propose	O
to	O
decompose	O
the	O
original	O
task	O
into	O
three	O
granularities	O
and	O
adaptively	O
impose	O
a	O
prior	O
on	O
the	O
specific	O
process	O
,	O
each	O
with	O
the	O
aid	O
of	O
a	O
GAN	B-Method
-	I-Method
based	I-Method
sub	I-Method
-	I-Method
net	I-Method
.	O
	
This	O
reduces	O
the	O
training	B-Metric
complexity	I-Metric
and	O
leads	O
to	O
better	O
empirical	B-Metric
performance	I-Metric
with	O
limited	O
data	O
.	O
	
The	O
first	O
sub	O
-	O
net	O
estimates	O
semantic	B-Task
saliency	I-Task
maps	I-Task
to	O
locate	O
the	O
most	O
noticeable	O
and	O
eye	O
-	O
attracting	O
human	O
regions	O
in	O
images	O
,	O
which	O
serves	O
as	O
a	O
basic	O
prior	O
to	O
facilitate	O
further	O
processing	O
on	O
humans	O
,	O
as	O
illustrated	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
left	O
.	O
	
We	O
formulate	O
semantic	B-Method
saliency	I-Method
prediction	I-Method
as	O
a	O
binary	B-Task
pixel	I-Task
-	I-Task
wise	I-Task
labelling	I-Task
problem	I-Task
to	O
segment	O
out	O
foreground	O
v.s	O
.	O
background	O
.	O
	
Inspired	O
by	O
the	O
recent	O
success	O
of	O
F	O
ully	O
C	O
	
onvolutional	O
N	O
etwork	O
s	O
(	O
FCNs	B-Method
)	O
based	O
methods	O
on	O
image	B-Task
-	I-Task
to	I-Task
-	I-Task
image	I-Task
applications	I-Task
	
,	O
we	O
leverage	O
an	O
FCN	B-Method
backbone	I-Method
(	O
FCN	B-Method
-	I-Method
8s	I-Method
)	O
as	O
the	O
generator	O
of	O
NAN	B-Method
for	O
semantic	B-Method
saliency	I-Method
prediction	I-Method
,	O
where	O
denotes	O
the	O
network	O
parameters	O
,	O
and	O
,	O
,	O
and	O
denote	O
the	O
image	O
height	O
,	O
width	O
,	O
channel	O
number	O
and	O
semantic	O
category	O
(	O
i.e.	O
,	O
foreground	O
plus	O
background	O
)	O
number	O
,	O
repectively	O
.	O
	
Formally	O
,	O
let	O
the	O
input	O
RGB	B-Material
image	I-Material
be	O
denoted	O
by	O
and	O
the	O
semantic	B-Method
saliency	I-Method
map	I-Method
be	O
denoted	O
by	O
,	O
then	O
The	O
key	O
requirements	O
for	O
are	O
that	O
the	O
semantic	B-Method
saliency	I-Method
map	I-Method
should	O
present	O
indistinguishable	O
properities	O
compared	O
with	O
a	O
real	O
one	O
(	O
i.e.	O
,	O
ground	O
truth	O
)	O
in	O
appearance	O
while	O
preserving	O
the	O
intrinsic	O
contextually	O
remarkable	O
information	O
.	O
	
To	O
this	O
end	O
,	O
we	O
propose	O
to	O
learn	O
by	O
minimizing	O
a	O
combination	O
of	O
two	O
losses	O
:	O
where	O
is	O
the	O
adv	O
ersarial	O
loss	O
for	O
refining	B-Task
realism	I-Task
and	I-Task
alleviating	I-Task
artifacts	I-Task
,	O
is	O
the	O
s	O
emantic	B-Metric
s	I-Metric
aliency	I-Metric
loss	I-Metric
for	O
pixel	B-Task
-	I-Task
wise	I-Task
image	I-Task
labelling	I-Task
,	O
are	O
weighting	O
parameters	O
among	O
different	O
losses	O
.	O
	
is	O
a	O
pixel	B-Metric
-	I-Metric
wise	I-Metric
cross	I-Metric
-	I-Metric
entropy	I-Metric
loss	I-Metric
calculated	O
based	O
on	O
the	O
binary	O
pixel	O
-	O
wise	O
annotations	O
to	O
learn	O
:	O
is	O
proposed	O
to	O
narrow	O
the	O
gap	O
between	O
the	O
distributions	O
of	O
generated	O
and	O
real	O
results	O
.	O
	
To	O
facilitate	O
this	O
process	O
,	O
we	O
leverage	O
a	O
C	B-Method
onvolutional	I-Method
N	I-Method
eural	I-Method
N	I-Method
etwork	I-Method
(	O
CNN	B-Method
)	O
backbone	O
as	O
the	O
discriminator	O
to	O
be	O
as	O
simple	O
as	O
possible	O
to	O
avoid	O
typical	O
GAN	B-Method
tricks	O
.	O
	
We	O
alternatively	O
optimize	O
and	O
to	O
learn	O
and	O
:	O
where	O
denotes	O
the	O
binary	O
real	O
v.s	O
.	O
fake	O
indicator	O
.	O
	
subsection	O
:	O
Instance	B-Method
-	I-Method
Agnostic	I-Method
Parsing	I-Method
	
The	O
second	O
sub	O
-	O
net	O
concatenates	O
the	O
information	O
from	O
the	O
original	O
RGB	B-Material
image	I-Material
with	O
semantic	O
saliency	O
prior	O
as	O
input	O
and	O
estimates	O
a	O
fine	O
-	O
grained	O
instance	B-Method
-	I-Method
agnostic	I-Method
parsing	I-Method
map	I-Method
,	O
which	O
further	O
serves	O
as	O
stronger	O
semantic	O
guidance	O
from	O
the	O
global	O
perspective	O
to	O
facilitate	O
instance	B-Method
-	I-Method
aware	I-Method
clustering	I-Method
,	O
as	O
illustrated	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
middle	O
.	O
	
We	O
formulate	O
instance	B-Method
-	I-Method
agnostic	I-Method
parsing	I-Method
as	O
a	O
multi	B-Task
-	I-Task
class	I-Task
dense	I-Task
classification	I-Task
problem	I-Task
to	O
mask	O
semantically	O
consistent	O
regions	O
of	O
body	O
parts	O
and	O
fashion	O
items	O
.	O
	
Inspired	O
by	O
the	O
leading	O
performance	O
of	O
the	O
skip	B-Method
-	I-Method
net	I-Method
on	O
recognition	B-Task
tasks	I-Task
,	O
we	O
modify	O
a	O
skip	B-Method
-	I-Method
net	I-Method
(	O
WS	B-Method
-	I-Method
ResNet	I-Method
)	O
into	O
an	O
FCN	B-Method
-	I-Method
based	I-Method
architecture	I-Method
as	O
the	O
generator	O
of	O
NAN	B-Method
to	O
learn	O
a	O
highly	O
non	B-Method
-	I-Method
linear	I-Method
transformation	I-Method
for	O
instance	B-Method
-	I-Method
agnostic	I-Method
parsing	I-Method
,	O
where	O
denotes	O
the	O
network	O
parameters	O
for	O
the	O
generator	O
and	O
denotes	O
the	O
semantic	O
category	O
number	O
.	O
	
The	O
prediction	B-Task
is	O
downsampled	O
by	O
for	O
accuracy	B-Metric
v.s	O
.	O
speed	B-Metric
trade	I-Metric
-	I-Metric
off	I-Metric
.	O
	
Contextual	O
information	O
from	O
global	O
and	O
local	O
regions	O
compensates	O
each	O
other	O
and	O
naturally	O
benefits	O
human	B-Task
parsing	I-Task
.	O
	
The	O
hierarchical	O
features	O
within	O
a	O
skip	B-Method
-	I-Method
net	I-Method
are	O
multi	O
-	O
scale	O
in	O
nature	O
due	O
to	O
the	O
increasing	O
receptive	O
field	O
sizes	O
,	O
which	O
are	O
combined	O
together	O
via	O
skip	O
connections	O
.	O
	
Such	O
a	O
combined	O
representation	O
comprehensively	O
maintains	O
the	O
contextual	O
information	O
,	O
which	O
is	O
crucial	O
for	O
generating	O
smooth	B-Task
and	I-Task
accurate	I-Task
parsing	I-Task
results	I-Task
.	O
	
Formally	O
,	O
let	O
the	O
instance	B-Method
-	I-Method
agnostic	I-Method
parsing	I-Method
map	I-Method
be	O
denoted	O
by	O
,	O
then	O
Similar	O
to	O
the	O
first	O
sub	O
-	O
net	O
,	O
we	O
propose	O
to	O
learn	O
by	O
minimizing	O
:	O
where	O
is	O
the	O
g	B-Method
lobal	I-Method
p	I-Method
arsing	I-Method
loss	I-Method
for	O
semantic	B-Task
part	I-Task
labelling	I-Task
.	O
	
is	O
a	O
standard	O
pixel	B-Metric
-	I-Metric
wise	I-Metric
cross	I-Metric
-	I-Metric
entropy	I-Metric
loss	I-Metric
calculated	O
based	O
on	O
the	O
multi	O
-	O
class	O
pixel	O
-	O
wise	O
annotations	O
to	O
learn	O
.	O
	
is	O
also	O
slightly	O
finetuned	O
due	O
to	O
the	O
hinged	B-Method
gradient	I-Method
backpropagation	I-Method
route	I-Method
within	O
the	O
nested	O
structure	O
:	O
is	O
proposed	O
to	O
ensure	O
the	O
correctness	O
and	O
realism	O
of	O
the	O
current	O
phase	O
and	O
also	O
the	O
previous	O
one	O
for	O
information	B-Task
flow	I-Task
consistency	I-Task
.	O
	
To	O
facilitate	O
this	O
process	O
,	O
we	O
leverage	O
a	O
same	O
CNN	B-Method
backbone	I-Method
with	O
as	O
the	O
discriminator	O
,	O
which	O
are	O
learned	O
separately	O
.	O
	
We	O
alternatively	O
optimize	O
and	O
to	O
learn	O
,	O
and	O
slightly	O
finetune	O
:	O
	
subsection	O
:	O
Instance	B-Method
-	I-Method
Aware	I-Method
Clustering	I-Method
	
The	O
third	O
sub	O
-	O
net	O
concatenates	O
the	O
information	O
from	O
the	O
original	O
RGB	B-Material
image	I-Material
with	O
semantic	O
saliency	O
and	O
instance	B-Method
-	I-Method
agnostic	I-Method
parsing	I-Method
priors	O
as	O
input	O
and	O
estimates	O
an	O
instance	B-Method
-	I-Method
aware	I-Method
clustering	I-Method
map	I-Method
by	O
associating	O
each	O
semantic	B-Method
parsing	I-Method
mask	I-Method
to	O
one	O
of	O
the	O
person	O
instances	O
in	O
the	O
scene	O
,	O
as	O
illustrated	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
	
right	O
.	O
	
Inspired	O
by	O
the	O
observation	O
that	O
a	O
human	O
glances	O
at	O
an	O
image	O
and	O
instantly	O
knows	O
how	O
many	O
and	O
where	O
the	O
objects	O
are	O
in	O
the	O
image	O
,	O
we	O
formulate	O
instance	B-Method
-	I-Method
aware	I-Method
clustering	I-Method
by	O
parallelly	O
inferring	O
the	O
instance	O
number	O
and	O
pixel	O
-	O
wise	O
instance	O
location	O
,	O
discarding	O
the	O
requirement	O
of	O
time	O
-	O
consuming	O
region	B-Method
proposal	I-Method
generation	I-Method
.	O
	
We	O
modify	O
a	O
same	O
backbone	B-Method
architecture	I-Method
to	O
incorporate	O
two	O
sibling	O
branches	O
as	O
the	O
generator	O
of	O
NAN	B-Method
for	O
location	B-Task
-	I-Task
sensitive	I-Task
learning	I-Task
,	O
where	O
denotes	O
the	O
network	O
parameters	O
for	O
the	O
generator	O
and	O
denotes	O
the	O
pre	O
-	O
defined	O
instance	O
location	O
coordinate	O
number	O
.	O
	
As	O
multi	O
-	O
scale	O
features	O
integrating	O
both	O
global	O
and	O
local	O
contextual	O
information	O
are	O
crucial	O
for	O
increasing	O
location	B-Task
prediction	I-Task
accuracy	I-Task
,	O
we	O
further	O
augment	O
the	O
pixel	B-Method
-	I-Method
wise	I-Method
instance	I-Method
location	I-Method
prediction	I-Method
branch	I-Method
with	O
a	O
M	O
ulti	O
-	O
S	O
cale	O
F	O
usion	O
	
U	O
nit	O
(	O
MSFU	B-Method
)	O
to	O
fuse	O
shallow	O
-	O
,	O
middle	O
-	O
and	O
deep	O
-	O
level	O
features	O
,	O
while	O
using	O
the	O
feature	O
maps	O
downsampled	O
by	O
concatenated	O
with	O
feature	O
maps	O
from	O
the	O
first	O
branch	O
for	O
instance	B-Task
number	I-Task
regression	I-Task
.	O
	
Formally	O
,	O
let	O
the	O
pixel	O
-	O
wise	O
instance	O
location	O
map	O
be	O
denoted	O
by	O
and	O
the	O
instance	O
number	O
be	O
denoted	O
by	O
,	O
then	O
We	O
propose	O
to	O
learn	O
by	O
minimizing	O
:	O
where	O
is	O
the	O
p	O
ixel	O
-	O
wise	O
i	B-Metric
nstance	I-Metric
l	I-Metric
ocation	I-Metric
loss	I-Metric
for	O
pixel	B-Method
-	I-Method
wise	I-Method
instance	I-Method
location	I-Method
regression	I-Method
and	O
is	O
the	O
i	B-Metric
nstance	I-Metric
n	I-Metric
umber	I-Metric
loss	I-Metric
for	O
instance	B-Task
number	I-Task
regression	I-Task
.	O
	
is	O
a	O
standard	O
smooth	O
-	O
loss	O
calculated	O
based	O
on	O
the	O
foreground	O
pixel	O
-	O
wise	O
instance	O
location	O
annotations	O
to	O
learn	O
.	O
	
Since	O
a	O
person	O
instance	O
can	O
be	O
identified	O
by	O
its	O
top	O
-	O
left	O
corner	O
and	O
bottom	O
-	O
right	O
corner	O
of	O
the	O
surrounding	O
bounding	O
box	O
,	O
for	O
each	O
pixel	O
belonging	O
to	O
the	O
person	O
instance	O
,	O
the	O
pixel	O
-	O
wise	O
instance	O
location	O
vector	O
is	O
defined	O
as	O
,	O
where	O
and	O
are	O
the	O
width	O
and	O
height	O
of	O
the	O
person	O
instance	O
for	O
normalization	B-Task
,	O
respectively	O
.	O
	
is	O
a	O
standard	O
loss	B-Metric
calculated	O
based	O
on	O
the	O
instance	O
number	O
annotations	O
to	O
learn	O
.	O
	
and	O
are	O
also	O
slightly	O
finetuned	O
due	O
to	O
the	O
chained	O
schema	O
within	O
the	O
nest	O
:	O
	
Given	O
these	O
information	O
,	O
instance	B-Method
-	I-Method
aware	I-Method
clustering	I-Method
maps	I-Method
can	O
be	O
effortlessly	O
generated	O
with	O
little	O
computational	B-Metric
overhead	I-Metric
,	O
which	O
are	O
denoted	O
by	O
.	O
	
Similar	O
to	O
,	O
is	O
proposed	O
to	O
ensure	O
the	O
correctness	O
and	O
realism	O
of	O
all	O
phases	O
for	O
the	O
information	B-Task
flow	I-Task
consistency	I-Task
.	O
	
To	O
facilitate	O
this	O
process	O
,	O
we	O
leverage	O
a	O
same	O
CNN	B-Method
backbone	I-Method
with	O
as	O
the	O
discriminator	O
,	O
which	O
are	O
learned	O
separately	O
.	O
	
We	O
alternatively	O
optimize	O
and	O
to	O
learn	O
,	O
and	O
slightly	O
finetune	O
and	O
:	O
	
subsection	O
:	O
Training	O
and	O
Inference	B-Task
	
The	O
goal	O
of	O
NAN	B-Method
is	O
to	O
use	O
sets	O
of	O
real	O
targets	O
to	O
learn	O
three	O
GAN	B-Method
-	O
like	O
sub	O
-	O
nets	O
that	O
mutually	O
boost	O
and	O
jointly	O
accomplish	O
multi	B-Task
-	I-Task
human	I-Task
parsing	I-Task
.	O
	
Each	O
separate	O
loss	O
serves	O
as	O
a	O
deep	O
supervision	O
within	O
the	O
nested	O
structure	O
benefitting	O
network	B-Task
convergence	I-Task
.	O
	
The	O
overall	O
objective	B-Metric
function	I-Metric
for	O
NAN	B-Method
is	O
Clearly	O
,	O
the	O
NAN	B-Method
is	O
end	O
-	O
to	O
-	O
end	O
trainable	O
and	O
can	O
be	O
optimized	O
with	O
the	O
proposed	O
nested	B-Method
adversarial	I-Method
learning	I-Method
strategy	I-Method
and	O
BP	B-Method
algorithm	I-Method
.	O
	
During	O
testing	O
,	O
we	O
simply	O
feed	O
the	O
input	O
image	O
into	O
NAN	B-Method
to	O
get	O
the	O
instance	B-Method
-	I-Method
agnostic	I-Method
parsing	I-Method
map	I-Method
from	O
,	O
pixel	O
-	O
wise	O
instance	O
location	O
map	O
and	O
instance	O
number	O
from	O
.	O
	
Then	O
we	O
employ	O
an	O
off	B-Method
-	I-Method
the	I-Method
-	I-Method
shelf	I-Method
clustering	I-Method
method	I-Method
to	O
obtain	O
the	O
instance	B-Method
-	I-Method
aware	I-Method
clustering	I-Method
map	I-Method
.	O
	
Example	O
results	O
are	O
visualized	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
.	O
	
section	O
:	O
Experiments	O
	
We	O
evaluate	O
NAN	B-Method
qualitatively	O
and	O
quantitatively	O
under	O
various	O
settings	O
and	O
granularities	O
for	O
understanding	B-Task
humans	I-Task
in	I-Task
crowded	I-Task
scenes	I-Task
.	O
	
In	O
particular	O
,	O
we	O
evaluate	O
multi	B-Task
-	I-Task
human	I-Task
parsing	I-Task
performance	O
on	O
the	O
MHP	B-Task
	
v2.0	O
	
dataset	O
proposed	O
in	O
this	O
work	O
,	O
as	O
well	O
as	O
the	O
MHP	B-Material
v1.0	I-Material
and	O
PASCAL	B-Material
-	I-Material
Person	I-Material
-	I-Material
Part	I-Material
benchmark	I-Material
datasets	I-Material
.	O
	
We	O
also	O
evaluate	O
instance	B-Method
-	I-Method
agnostic	I-Method
parsing	I-Method
and	O
instance	B-Method
-	I-Method
aware	I-Method
clustering	I-Method
results	O
on	O
the	O
Buffy	B-Material
benchmark	I-Material
dataset	I-Material
,	O
which	O
are	O
byproducts	O
of	O
NAN	B-Method
.	O
	
subsection	O
:	O
Experimental	O
Settings	O
	
subsubsection	O
:	O
Implementation	O
Details	O
	
Throughout	O
the	O
experiments	O
,	O
the	O
sizes	O
of	O
the	O
RGB	B-Material
image	I-Material
,	O
the	O
semantic	B-Method
saliency	I-Method
prediction	I-Method
,	O
inputs	O
to	O
the	O
discriminator	B-Method
and	O
inputs	O
to	O
the	O
generator	O
are	O
fixed	O
as	O
;	O
the	O
sizes	O
of	O
the	O
instance	B-Method
-	I-Method
agnostic	I-Method
parsing	I-Method
prediction	I-Method
,	O
instance	B-Method
-	I-Method
aware	I-Method
clustering	I-Method
prediction	O
,	O
inputs	O
to	O
the	O
discriminator	B-Method
,	O
inputs	O
to	O
the	O
generator	O
,	O
inputs	O
to	O
the	O
discriminator	O
and	O
instance	O
location	O
map	O
are	O
fixed	O
as	O
;	O
the	O
channel	O
number	O
of	O
the	O
pixel	O
-	O
wise	O
instance	O
location	O
map	O
is	O
fixed	O
as	O
,	O
incorporating	O
two	O
corner	O
points	O
of	O
the	O
associated	O
bounding	O
box	O
;	O
the	O
constraint	O
factors	O
are	O
empirically	O
fixed	O
as	O
and	O
,	O
respectively	O
;	O
the	O
generator	B-Method
is	O
initialized	O
with	O
FCN	B-Method
-	I-Method
8s	I-Method
by	O
replacing	O
the	O
last	O
layer	O
with	O
a	O
new	O
convolutional	B-Method
layer	I-Method
with	O
kernel	O
size	O
,	O
pretrained	O
on	O
PASCAL	B-Material
-	I-Material
VOC	I-Material
-	I-Material
2011	I-Material
and	O
finetuned	O
on	O
the	O
target	O
dataset	O
;	O
the	O
generator	O
is	O
initialized	O
with	O
WS	B-Method
-	I-Method
ResNet	I-Method
by	O
eliminating	O
the	O
spatial	O
pooling	O
layers	O
,	O
increasing	O
the	O
strides	O
of	O
the	O
first	O
convolutional	O
layers	O
up	O
to	O
2	O
in	O
B	O
,	O
eliminating	O
the	O
top	O
-	O
most	O
global	O
pooling	O
layer	O
and	O
the	O
linear	B-Method
classifier	I-Method
,	O
and	O
adding	O
two	O
new	O
convolutional	B-Method
layers	I-Method
with	O
kernel	O
sizes	O
and	O
,	O
pretrained	O
on	O
ImageNet	B-Material
and	O
PASCAL	B-Material
-	I-Material
VOC	I-Material
-	I-Material
2012	I-Material
,	O
and	O
finetuned	O
on	O
the	O
target	O
dataset	O
;	O
the	O
generator	O
is	O
initialized	O
with	O
the	O
same	O
backbone	B-Method
architecture	I-Method
and	O
pre	O
-	O
trained	O
weights	O
with	O
(	O
which	O
are	O
learned	O
separately	O
)	O
,	O
by	O
further	O
augmenting	O
it	O
with	O
two	O
sibling	O
branches	O
for	O
pixel	B-Task
-	I-Task
wise	I-Task
instance	I-Task
location	I-Task
map	I-Task
prediction	I-Task
and	O
instance	B-Task
number	I-Task
prediction	I-Task
,	O
where	O
the	O
first	O
branch	O
utilizes	O
a	O
MSFU	B-Method
(	O
three	O
convolutional	B-Method
layers	I-Method
with	O
kernal	O
sizes	O
for	O
specific	O
scale	O
adaption	O
)	O
ended	O
with	O
a	O
convolutional	B-Method
layer	I-Method
with	O
kernel	O
size	O
for	O
multi	B-Method
-	I-Method
scale	I-Method
feature	I-Method
aggregation	I-Method
and	O
a	O
final	O
convolutional	B-Method
layer	I-Method
with	O
kernel	O
size	O
for	O
location	B-Task
regression	I-Task
and	O
the	O
second	O
branch	O
utilizes	O
the	O
feature	O
maps	O
downsampled	O
by	O
8	O
concatenated	O
with	O
the	O
feature	O
maps	O
from	O
the	O
first	O
branch	O
ended	O
with	O
a	O
global	B-Method
pooling	I-Method
layer	I-Method
,	O
a	O
hidden	B-Method
512	I-Method
-	I-Method
way	I-Method
fully	I-Method
-	I-Method
connected	I-Method
layer	I-Method
and	O
a	O
final	O
1	B-Method
-	I-Method
way	I-Method
fully	I-Method
-	I-Method
connected	I-Method
layer	I-Method
for	O
instance	B-Task
number	I-Task
regression	I-Task
;	O
the	O
three	O
discriminators	O
(	O
which	O
are	O
learned	O
separately	O
)	O
are	O
all	O
initialized	O
with	O
a	O
VGG	B-Method
-	I-Method
16	I-Method
by	O
adding	O
a	O
new	O
convolutional	O
layer	O
at	O
the	O
very	O
begining	O
with	O
kernel	O
size	O
for	O
input	B-Task
adaption	I-Task
,	O
and	O
replacing	O
the	O
last	O
layer	O
with	O
a	O
new	O
1	O
-	O
way	O
fully	O
-	O
connected	O
layer	O
activated	O
by	O
sigmoid	O
,	O
pre	O
-	O
trained	O
on	O
ImageNet	B-Material
and	O
finetuned	O
on	O
the	O
target	O
dataset	O
;	O
the	O
newly	O
added	O
layers	O
are	O
randomly	O
initialized	O
by	O
drawing	O
weights	O
from	O
a	O
zero	O
-	O
mean	O
Gaussian	O
distribution	O
with	O
standard	O
deviation	O
;	O
we	O
employ	O
an	O
off	B-Method
-	I-Method
the	I-Method
-	I-Method
shelf	I-Method
clustering	I-Method
method	I-Method
to	O
obtain	O
the	O
instance	B-Method
-	I-Method
aware	I-Method
clustering	I-Method
map	I-Method
;	O
the	O
dropout	B-Metric
ratio	I-Metric
is	O
empirically	O
fixed	O
as	O
;	O
the	O
weight	O
decay	O
and	O
batch	O
size	O
are	O
fixed	O
as	O
and	O
,	O
respectively	O
;	O
We	O
use	O
an	O
initial	O
learning	B-Metric
rate	I-Metric
of	O
for	O
pre	O
-	O
trained	O
layers	O
,	O
and	O
for	O
newly	O
added	O
layers	O
in	O
all	O
our	O
experiments	O
;	O
we	O
decrease	O
the	O
learning	B-Metric
rate	I-Metric
to	O
of	O
the	O
previous	O
one	O
after	O
20	O
epochs	O
and	O
train	O
the	O
network	O
for	O
roughly	O
60	O
epochs	O
one	O
after	O
the	O
other	O
;	O
the	O
proposed	O
network	O
is	O
implemented	O
based	O
on	O
the	O
publicly	O
available	O
TensorFlow	B-Method
platform	I-Method
,	O
which	O
is	O
trained	O
using	O
Adam	B-Method
(	I-Method
)	O
on	O
four	O
NVIDIA	B-Method
GeForce	I-Method
GTX	I-Method
TITAN	I-Method
X	I-Method
GPUs	I-Method
with	O
12	O
G	O
memory	O
;	O
the	O
same	O
training	O
setting	O
is	O
utilized	O
for	O
all	O
our	O
compared	O
network	O
variants	O
;	O
we	O
evaluate	O
the	O
testing	B-Metric
time	I-Metric
by	O
averaging	O
the	O
running	B-Metric
time	I-Metric
for	O
images	O
on	O
the	O
target	O
set	O
on	O
NVIDIA	B-Method
GeForce	I-Method
GTX	I-Method
TITAN	I-Method
X	I-Method
GPU	I-Method
and	O
Intel	O
Core	O
i7	O
-	O
4930	O
K	O
CPU@3.40GHZ	O
;	O
our	O
NAN	B-Method
can	O
rapidly	O
process	O
one	O
image	O
in	O
about	O
1	O
second	O
,	O
which	O
compares	O
much	O
favorably	O
to	O
other	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
approaches	O
,	O
as	O
the	O
current	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
methods	O
rely	O
on	O
region	B-Method
proposal	I-Method
preprocessing	I-Method
and	O
complex	O
processing	O
steps	O
.	O
	
subsubsection	O
:	O
Evaluation	B-Metric
Metrics	I-Metric
	
Following	O
,	O
we	O
use	O
the	O
A	B-Metric
verage	I-Metric
P	I-Metric
recision	I-Metric
based	O
on	O
p	B-Method
art	I-Method
(	O
)	O
and	O
P	B-Method
ercentage	I-Method
of	I-Method
C	I-Method
orrectly	I-Method
parsed	I-Method
semantic	I-Method
P	I-Method
arts	I-Method
(	O
PCP	B-Method
)	O
metrics	O
for	O
multi	O
-	O
human	B-Task
parsing	I-Task
evaluation	O
.	O
	
Different	O
from	O
the	O
A	B-Metric
verage	I-Metric
P	I-Metric
recision	I-Metric
based	O
on	O
r	B-Method
egion	I-Method
(	O
)	O
used	O
in	O
instance	B-Task
segmentation	I-Task
,	O
uses	O
part	O
-	O
level	O
pixel	O
	
I	O
ntersection	O
o	O
ver	O
U	O
nion	O
(	O
IoU	O
)	O
of	O
different	O
semantic	O
part	O
categories	O
within	O
a	O
person	O
instance	O
to	O
determine	O
if	O
one	O
instance	O
is	O
a	O
true	O
positive	O
.	O
	
We	O
prefer	O
over	O
as	O
we	O
focus	O
on	O
human	B-Task
-	I-Task
centric	I-Task
analysis	I-Task
and	O
we	O
aim	O
to	O
investigate	O
to	O
how	O
well	O
a	O
person	O
instance	O
as	O
a	O
whole	O
is	O
parsed	O
.	O
	
Additionally	O
,	O
we	O
also	O
report	O
the	O
,	O
which	O
is	O
the	O
mean	O
of	O
the	O
at	O
IoU	O
thresholds	O
ranging	O
from	O
to	O
,	O
in	O
increments	O
of	O
0.1	O
.	O
	
As	O
averages	O
the	O
IoU	O
of	O
each	O
semantic	O
part	O
category	O
,	O
it	O
fails	O
to	O
reflect	O
how	O
many	O
semantic	O
parts	O
are	O
correctly	O
parsed	O
.	O
	
We	O
further	O
incorporate	O
the	O
PCP	B-Method
,	O
originally	O
used	O
in	O
human	B-Task
pose	I-Task
estimation	I-Task
,	O
to	O
evaluate	O
the	O
parsing	B-Metric
quality	I-Metric
within	O
person	O
instances	O
.	O
	
For	O
each	O
true	O
-	O
positive	O
person	O
instance	O
,	O
we	O
find	O
all	O
the	O
semantic	O
categories	O
(	O
excluding	O
background	O
)	O
with	O
pixel	O
IoU	O
larger	O
than	O
a	O
threshold	O
,	O
which	O
are	O
regarded	O
as	O
correctly	O
parsed	O
.	O
	
The	O
PCP	B-Method
of	O
one	O
person	O
instance	O
is	O
the	O
ratio	O
between	O
the	O
correctly	O
parsed	O
semantic	O
category	O
number	O
and	O
the	O
total	O
semantic	O
category	O
number	O
of	O
that	O
person	O
.	O
	
Missed	O
person	O
instances	O
are	O
assigned	O
with	O
PCP	B-Method
.	O
	
The	O
overall	O
PCP	B-Method
is	O
the	O
average	O
PCP	B-Method
for	O
all	O
person	O
instances	O
.	O
	
Note	O
that	O
PCP	B-Method
is	O
also	O
a	O
human	B-Metric
-	I-Metric
centric	I-Metric
evaluation	I-Metric
metric	I-Metric
.	O
	
subsection	O
:	O
Evaluations	O
on	O
the	O
MHP	B-Material
v2.0	I-Material
Benchmark	I-Material
	
The	O
MHP	B-Material
v2.0	I-Material
dataset	I-Material
proposed	O
in	O
this	O
paper	O
is	O
the	O
largest	O
and	O
most	O
comprehensive	O
multi	O
-	O
human	B-Task
parsing	I-Task
benchmark	O
to	O
date	O
,	O
which	O
extends	O
MHP	B-Material
v1.0	I-Material
to	O
push	O
the	O
frontiers	O
of	O
understanding	B-Task
humans	I-Task
in	O
crowded	O
scenes	O
by	O
containing	O
25	O
,	O
403	O
elaborately	O
annotated	O
images	O
with	O
58	O
fine	O
-	O
grained	O
semantic	O
category	O
labels	O
.	O
	
Annotation	O
examples	O
are	O
visualized	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
(	O
c	O
)	O
.	O
	
The	O
data	O
are	O
randomly	O
organized	O
into	O
3	O
splits	O
,	O
consisting	O
of	O
15	O
,	O
403	O
training	O
and	O
5	O
,	O
000	O
validation	O
images	O
with	O
publicly	O
available	O
annotations	O
,	O
as	O
well	O
as	O
5	O
,	O
000	O
testing	O
images	O
with	O
annotations	O
withheld	O
for	O
benchmarking	O
purpose	O
.	O
	
Evaluation	O
systems	O
report	O
the	O
and	O
PCP	B-Method
over	O
the	O
validation	O
and	O
testing	O
sets	O
.	O
	
subsubsection	O
:	O
Component	B-Method
Analysis	I-Method
	
We	O
first	O
investigate	O
different	O
architectures	O
and	O
loss	O
function	O
combinations	O
of	O
NAN	B-Method
to	O
see	O
their	O
respective	O
roles	O
in	O
multi	B-Task
-	I-Task
human	I-Task
parsing	I-Task
.	O
	
We	O
compare	O
16	O
variants	O
from	O
four	O
aspects	O
,	O
i.e.	O
,	O
different	O
baselines	O
(	O
Mask	B-Method
R	I-Method
-	I-Method
CNN	I-Method
and	O
MH	B-Method
-	I-Method
Parser	I-Method
)	O
,	O
different	O
network	B-Method
structures	I-Method
(	O
w	O
/	O
o	O
,	O
w	O
/	O
o	O
concatenated	O
input	O
(	O
RGB	O
only	O
)	O
,	O
w	O
/	O
o	O
concatenated	O
input	O
(	O
RGB	O
only	O
)	O
,	O
w	O
/	O
o	O
,	O
w	O
/	O
o	O
,	O
w	O
/	O
o	O
concatenated	O
input	O
,	O
w	O
/	O
o	O
,	O
w	O
/	O
o	O
concatenated	O
input	O
,	O
w	O
/	O
o	O
MSFU	B-Method
)	O
,	O
our	O
proposed	O
NAN	B-Method
,	O
and	O
upperbounds	O
(	O
:	O
use	O
the	O
ground	O
truth	O
semantic	O
saliency	O
maps	O
instead	O
of	O
prediction	O
while	O
keeping	O
other	O
settings	O
the	O
same	O
;	O
:	O
use	O
the	O
ground	B-Method
truth	I-Method
instance	I-Method
-	I-Method
agnostic	I-Method
parsing	I-Method
maps	I-Method
instead	O
of	O
prediction	O
while	O
keeping	O
other	O
settings	O
the	O
same	O
;	O
:	O
use	O
the	O
ground	O
truth	O
instance	O
number	O
instead	O
of	O
prediction	O
while	O
keeping	O
other	O
settings	O
the	O
same	O
;	O
:	O
use	O
the	O
ground	O
truth	O
pixel	O
-	O
wise	O
instance	O
location	O
maps	O
instead	O
of	O
prediction	O
while	O
keeping	O
other	O
settings	O
the	O
same	O
)	O
.	O
	
The	O
performance	O
comparison	O
in	O
terms	O
of	O
@IoU=0.5	B-Metric
,	O
and	O
PCP@IoU=0.5	B-Method
on	O
the	O
MHP	B-Task
v2.0	O
validation	O
set	O
is	O
reported	O
in	O
Tab	O
.	O
	
[	O
reference	O
]	O
.	O
	
By	O
comaring	O
the	O
results	O
from	O
the	O
v.s	O
.	O
panels	O
,	O
we	O
observe	O
that	O
our	O
proposed	O
NAN	B-Method
consistently	O
outperforms	O
the	O
baselines	B-Method
Mask	I-Method
R	I-Method
-	I-Method
CNN	I-Method
and	O
MH	B-Method
-	I-Method
Parser	I-Method
by	O
a	O
large	O
margin	O
,	O
i.e.	O
,	O
and	O
in	O
terms	O
of	O
,	O
and	O
in	O
terms	O
of	O
,	O
and	O
and	O
in	O
terms	O
of	O
PCP	B-Method
.	O
	
Mask	B-Method
R	I-Method
-	I-Method
CNN	I-Method
suffers	O
difficulties	O
to	O
differentiate	O
entangled	O
humans	O
.	O
	
MH	B-Method
-	I-Method
Parser	I-Method
involves	O
multiple	O
stages	O
for	O
instance	B-Task
localization	I-Task
,	O
human	B-Task
parsing	I-Task
and	O
result	B-Task
refinement	I-Task
with	O
high	O
complexity	B-Metric
,	O
yielding	O
sub	O
-	O
optimal	O
results	O
,	O
whereas	O
NAN	B-Method
parses	O
semantic	O
categories	O
,	O
differentiates	O
different	O
person	O
instances	O
and	O
refines	O
results	O
simultaneously	O
through	O
deep	B-Method
nested	I-Method
adversarial	I-Method
learning	I-Method
in	O
an	O
effective	O
yet	O
time	O
-	O
efficient	O
manner	O
.	O
	
By	O
comaring	O
the	O
results	O
from	O
the	O
v.s	O
.	O
panels	O
,	O
we	O
observe	O
that	O
NAN	B-Method
consistently	O
outperforms	O
the	O
9	O
variants	O
in	O
terms	O
of	O
network	O
structure	O
.	O
	
In	O
particular	O
,	O
w	B-Method
/	I-Method
o	I-Method
refers	O
to	O
truncating	O
the	O
semantic	B-Method
saliency	I-Method
prediction	I-Method
sub	O
-	O
net	O
from	O
NAN	B-Method
,	O
leading	O
to	O
,	O
and	O
performance	O
drop	O
in	O
terms	O
of	O
all	O
metrics	O
.	O
	
This	O
verifies	O
the	O
necessity	O
of	O
semantic	B-Method
saliency	I-Method
prediction	I-Method
that	O
locates	O
the	O
most	O
noticeable	O
human	O
regions	O
in	O
images	O
to	O
serve	O
as	O
a	O
basic	O
prior	O
to	O
facilitate	O
further	O
human	B-Task
-	I-Task
centic	I-Task
processing	I-Task
.	O
	
The	O
superiority	O
of	O
incorporating	O
adaptive	O
prior	O
information	O
to	O
specific	O
process	O
can	O
be	O
verified	O
by	O
comparing	O
w	O
/	O
o	O
concatenated	O
input	O
with	O
NAN	B-Method
,	O
i.e.	O
,	O
,	O
and	O
;	O
,	O
and	O
differences	O
in	O
terms	O
of	O
all	O
metrics	O
.	O
	
The	O
superiority	O
of	O
incorporating	O
adversarial	B-Method
learning	I-Method
to	O
specific	O
process	O
can	O
be	O
verified	O
by	O
comparing	O
w	B-Method
/	I-Method
o	I-Method
with	O
NAN	B-Method
,	O
i.e.	O
,	O
,	O
and	O
;	O
,	O
and	O
;	O
,	O
and	O
decrease	O
in	O
terms	O
of	O
all	O
metrics	O
.	O
	
Nested	B-Method
adversarial	I-Method
learning	I-Method
strategy	I-Method
ensures	O
the	O
correctness	O
and	O
realism	O
of	O
all	O
phases	O
for	O
information	B-Task
flow	I-Task
consistency	I-Task
,	O
the	O
superiority	O
of	O
which	O
is	O
verified	O
by	O
comparing	O
w	O
/	O
o	O
concatenated	O
input	O
with	O
NAN	B-Method
,	O
i.e.	O
,	O
,	O
and	O
;	O
,	O
and	O
decline	O
in	O
terms	O
of	O
all	O
metrics	O
.	O
	
MSFU	B-Method
dynamically	O
fuses	O
multi	O
-	O
scale	O
features	O
for	O
enhancing	O
instance	B-Method
-	I-Method
aware	I-Method
clustering	I-Method
accuracy	O
,	O
the	O
superiority	O
of	O
which	O
is	O
verified	O
by	O
comparing	O
w	B-Method
/	I-Method
o	I-Method
MSFU	I-Method
with	O
NAN	B-Method
,	O
i.e.	O
,	O
,	O
and	O
drop	O
in	O
terms	O
of	O
all	O
metrics	O
.	O
	
Finally	O
,	O
we	O
also	O
evaluate	O
the	O
limitations	O
of	O
our	O
current	O
algorithm	O
.	O
	
By	O
comparing	O
with	O
NAN	B-Method
,	O
only	O
,	O
and	O
improvement	O
in	O
term	O
of	O
all	O
metrics	O
are	O
obtained	O
,	O
which	O
shows	O
that	O
the	O
errors	O
from	O
semantic	B-Method
saliency	I-Method
prediction	I-Method
are	O
already	O
small	O
and	O
have	O
only	O
little	O
effect	O
on	O
the	O
final	O
results	O
.	O
	
A	O
large	O
gap	O
between	O
,	O
and	O
of	O
and	O
,	O
and	O
of	O
NAN	B-Method
shows	O
that	O
a	O
better	O
instance	B-Method
-	I-Method
agnostic	I-Method
parsing	I-Method
network	I-Method
architecture	I-Method
can	O
definitely	O
help	O
improve	O
the	O
performance	O
of	O
multi	B-Task
-	I-Task
human	I-Task
parsing	I-Task
under	O
our	O
NAN	B-Method
framework	O
.	O
	
By	O
comparing	O
and	O
with	O
NAN	B-Method
,	O
,	O
and	O
;	O
,	O
and	O
improvement	O
in	O
term	O
of	O
all	O
metrics	O
are	O
obtained	O
,	O
which	O
shows	O
that	O
accurate	O
instance	B-Method
-	I-Method
aware	I-Method
clustering	I-Method
results	O
are	O
critical	O
for	O
superior	O
multi	B-Task
-	I-Task
human	I-Task
parsing	I-Task
.	O
	
subsubsection	B-Method
:	O
Quantitative	B-Metric
Comparison	I-Metric
	
The	O
performance	O
comparison	O
of	O
the	O
proposed	O
NAN	B-Method
with	O
two	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
methods	O
in	O
terms	O
of	O
@IoU=0.5	B-Metric
,	O
and	O
PCP@IoU=0.5	B-Method
on	O
the	O
MHP	B-Task
	
v2.0	O
testing	O
set	O
is	O
reported	O
in	O
Tab	O
.	O
	
[	O
reference	O
]	O
.	O
	
Following	O
,	O
we	O
conduct	O
experiments	O
under	O
three	O
settings	O
:	O
	
All	O
reports	O
the	O
evaluation	O
over	O
the	O
whole	O
testing	O
set	O
;	O
Inter%20	O
reports	O
the	O
evaluation	O
over	O
the	O
sub	O
-	O
set	O
containing	O
the	O
images	O
with	O
top	O
20	O
%	O
interaction	O
intensity	O
;	O
Inter%10	O
reports	O
the	O
evaluation	O
over	O
the	O
sub	O
-	O
set	O
containing	O
the	O
images	O
with	O
top	O
10	O
%	O
interaction	O
intensity	O
.	O
	
Our	O
NAN	B-Method
is	O
significantly	O
superior	O
over	O
other	O
state	O
-	O
of	O
-	O
the	O
-	O
arts	O
on	O
setting	O
-	O
1	O
.	O
	
In	O
particular	O
,	O
NAN	B-Method
improves	O
the	O
-	O
best	O
by	O
,	O
and	O
in	O
terms	O
of	O
all	O
metrics	O
.	O
	
For	O
the	O
more	O
challenging	O
scenarios	O
with	O
intensive	O
interactions	O
(	O
setting	O
-	O
2	O
,	O
3	O
)	O
,	O
NAN	B-Method
also	O
consistently	O
achieves	O
the	O
best	O
performance	O
.	O
	
In	O
particular	O
,	O
for	O
Inter%20	O
and	O
Inter%10	O
,	O
NAN	B-Method
improves	O
the	O
-	O
best	O
by	O
,	O
and	O
;	O
,	O
and	O
in	O
terms	O
of	O
all	O
metrics	O
.	O
	
This	O
verifies	O
the	O
effectiveness	O
of	O
our	O
NAN	B-Method
for	O
multi	O
-	O
human	B-Task
parsing	I-Task
and	O
understanding	O
humans	O
in	O
crowded	O
scenes	O
.	O
	
Moreover	O
,	O
NAN	B-Method
can	O
rapidly	O
process	O
one	O
512	O
512	O
image	O
in	O
about	O
1	O
second	O
with	O
acceptable	O
resource	B-Metric
consumption	I-Metric
,	O
which	O
is	O
attractive	O
to	O
real	O
applications	O
.	O
	
This	O
compares	O
much	O
favorably	O
to	O
MH	B-Method
-	I-Method
Parser	I-Method
(	O
14.94	O
img	B-Method
/	I-Method
s	I-Method
)	O
,	O
which	O
relies	O
on	O
separate	O
and	O
complex	O
post	B-Method
-	I-Method
processing	I-Method
(	O
including	O
CRF	B-Method
)	O
steps	O
.	O
	
subsubsection	O
:	O
Qualitative	B-Metric
Comparison	I-Metric
	
Fig	O
.	O
	
[	O
reference	O
]	O
visualizes	O
the	O
qualitative	O
comparison	O
of	O
the	O
proposed	O
NAN	B-Method
with	O
two	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
methods	O
and	O
corresponding	O
ground	B-Metric
truths	I-Metric
on	O
the	O
MHP	B-Material
v2.0	I-Material
dataset	I-Material
.	O
	
Note	O
that	O
Mask	B-Method
R	I-Method
-	I-Method
CNN	I-Method
only	O
offers	O
silhouettes	O
of	O
different	O
person	O
instances	O
,	O
we	O
only	O
compare	O
our	O
instance	B-Method
-	I-Method
aware	I-Method
clustering	I-Method
results	O
with	O
it	O
while	O
comparing	O
our	O
holistic	O
results	O
with	O
MH	B-Method
-	I-Method
Parser	I-Method
.	O
	
It	O
can	O
be	O
observed	O
that	O
the	O
proposed	O
NAN	B-Method
performs	O
well	O
in	O
multi	B-Task
-	I-Task
human	I-Task
parsing	I-Task
with	O
a	O
wide	O
range	O
of	O
viewpoints	O
,	O
poses	O
,	O
occlusion	O
,	O
interactions	O
and	O
background	O
complexity	O
.	O
	
The	O
instance	B-Method
-	I-Method
agnostic	I-Method
parsing	I-Method
and	O
instance	B-Method
-	I-Method
aware	I-Method
clustering	I-Method
predictions	O
of	O
NAN	B-Method
present	O
high	O
consistency	O
with	O
corresponding	O
ground	O
truths	O
,	O
thanks	O
to	O
the	O
novel	O
network	B-Method
structure	I-Method
and	O
effective	O
training	B-Method
strategy	I-Method
.	O
	
In	O
contrast	O
,	O
Mask	B-Method
R	I-Method
-	I-Method
CNN	I-Method
suffers	O
difficulties	O
to	O
differentiate	O
entangled	O
humans	O
,	O
while	O
MH	B-Method
-	I-Method
Parser	I-Method
struggles	O
to	O
generate	O
fine	B-Task
-	I-Task
grained	I-Task
parsing	I-Task
results	I-Task
and	O
clearly	O
segmented	O
instance	O
masks	O
.	O
	
This	O
further	O
desmonstrates	O
the	O
effectiveness	O
of	O
the	O
proposed	O
NAN	B-Method
.	O
	
We	O
also	O
show	O
some	O
failure	O
cases	O
of	O
our	O
NAN	B-Method
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
.	O
	
As	O
can	O
be	O
observed	O
,	O
humans	O
in	O
crowded	O
scenes	O
with	O
heavy	O
occlusion	O
,	O
extreme	O
poses	O
and	O
intensive	O
interactions	O
are	O
difficult	O
to	O
identify	O
and	O
segment	O
.	O
	
Some	O
small	O
-	O
scale	O
semantic	O
categories	O
within	O
person	O
instances	O
are	O
difficult	O
to	O
parse	O
.	O
	
This	O
confirms	O
that	O
MHP	B-Material
v2.0	I-Material
aligns	O
with	O
real	O
-	O
world	O
situations	O
and	O
deserves	O
more	O
furture	O
attention	O
and	O
research	O
efforts	O
.	O
	
subsection	O
:	O
Evaluations	O
on	O
the	O
MHP	B-Material
v1.0	I-Material
Benchmark	I-Material
	
The	O
MHP	B-Task
v1.0	O
dataset	O
is	O
the	O
first	O
multi	O
-	O
human	B-Task
parsing	I-Task
benchmark	O
,	O
originally	O
proposed	O
by	O
Li	O
et	O
al	O
.	O
,	O
which	O
contains	O
4	O
,	O
980	O
images	O
annotated	O
with	O
18	O
semantic	O
labels	O
.	O
	
Annotation	O
examples	O
are	O
visualized	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
(	O
b	O
)	O
.	O
	
The	O
data	O
are	O
randomly	O
organized	O
into	O
3	O
splits	O
,	O
consisting	O
of	O
3	O
,	O
000	O
training	O
,	O
1	O
,	O
000	O
validation	O
and	O
1	O
,	O
000	O
testing	O
images	O
with	O
publicly	O
available	O
annotations	O
.	O
	
Evaluation	O
systems	O
report	O
the	O
and	O
PCP	B-Method
over	O
the	O
testing	O
set	O
.	O
	
Refer	O
to	O
for	O
more	O
details	O
.	O
	
The	O
performance	O
comparison	O
of	O
the	O
proposed	O
NAN	B-Method
with	O
three	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
methods	O
in	O
terms	O
of	O
@IoU=0.5	B-Metric
,	O
and	O
PCP@IoU=0.5	B-Method
on	O
the	O
MHP	B-Task
v1.0	O
testing	O
set	O
is	O
reported	O
in	O
Tab	O
.	O
	
[	O
reference	O
]	O
.	O
	
With	O
the	O
nested	B-Method
adversarial	I-Method
learning	I-Method
of	I-Method
semantic	I-Method
saliency	I-Method
prediction	I-Method
,	O
instance	B-Method
-	I-Method
agnostic	I-Method
parsing	I-Method
and	O
instance	B-Method
-	I-Method
aware	I-Method
clustering	I-Method
,	O
our	O
method	O
outperforms	O
the	O
-	O
best	O
by	O
for	O
,	O
for	O
and	O
for	O
PCP	B-Method
.	O
	
Visual	O
comparison	O
of	O
multi	B-Task
-	I-Task
human	I-Task
parsing	I-Task
results	O
by	O
NAN	B-Method
and	O
three	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
methods	O
is	O
provided	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
,	O
which	O
further	O
validates	O
the	O
advantages	O
of	O
our	O
NAN	B-Method
over	O
existing	O
solutions	O
.	O
	
subsection	O
:	O
Evaluations	O
on	O
the	O
PASCAL	B-Material
-	I-Material
Person	I-Material
-	I-Material
Part	I-Material
Benchmark	O
	
The	O
PASCAL	B-Material
-	I-Material
Person	I-Material
-	I-Material
Part	I-Material
dataset	O
is	O
a	O
set	O
of	O
additional	O
annotations	O
for	O
PASCAL	B-Material
-	I-Material
VOC	I-Material
-	I-Material
2010	I-Material
.	O
	
It	O
goes	O
beyond	O
the	O
original	O
PASCAL	B-Task
object	I-Task
detection	I-Task
task	I-Task
by	O
providing	O
pixel	O
-	O
wise	O
labels	O
for	O
six	O
human	O
body	O
parts	O
,	O
i.e.	O
,	O
head	O
,	O
torso	O
,	O
upper	O
-/	O
lower	O
-	O
arms	O
,	O
and	O
upper	O
-/	O
lower	O
-	O
legs	O
.	O
	
The	O
rest	O
of	O
each	O
image	O
is	O
considered	O
as	O
background	O
.	O
	
There	O
are	O
3	O
,	O
535	O
images	O
in	O
the	O
PASCAL	B-Material
-	I-Material
Person	I-Material
-	I-Material
Part	I-Material
dataset	O
,	O
which	O
is	O
split	O
into	O
separate	O
training	O
set	O
containing	O
1	O
,	O
717	O
images	O
and	O
testing	O
set	O
containing	O
1	O
,	O
818	O
images	O
.	O
	
For	O
fair	O
comparison	O
,	O
we	O
report	O
the	O
over	O
the	O
testing	O
set	O
for	O
multi	B-Task
-	I-Task
human	I-Task
parsing	I-Task
.	O
	
Refer	O
to	O
for	O
more	O
details	O
.	O
	
The	O
performance	O
comparison	O
of	O
the	O
proposed	O
NAN	B-Method
with	O
two	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
methods	O
in	O
terms	O
of	O
@IoU=	B-Metric
and	O
on	O
the	O
PASCAL	B-Material
-	I-Material
Person	I-Material
-	I-Material
Part	I-Material
testing	O
set	O
is	O
reported	O
in	O
Tab	O
.	O
	
[	O
reference	O
]	O
.	O
	
Our	O
method	O
dramatically	O
surpasses	O
the	O
-	O
best	O
by	O
for	O
and	O
for	O
.	O
	
Qualitative	O
multi	O
-	O
human	B-Task
parsing	I-Task
results	O
by	O
NAN	B-Method
are	O
visualized	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
,	O
which	O
possess	O
a	O
high	O
concordance	O
with	O
corresponding	O
ground	B-Metric
truths	I-Metric
.	O
	
This	O
again	O
verifies	O
the	O
effectiveness	O
of	O
our	O
method	O
for	O
human	B-Task
-	I-Task
centric	I-Task
analysis	I-Task
.	O
	
subsection	O
:	O
Evaluations	O
on	O
the	O
Buffy	B-Material
Benchmark	I-Material
	
The	O
Buffy	B-Material
dataset	I-Material
was	O
released	O
in	O
2011	O
for	O
human	B-Task
parsing	I-Task
and	O
instance	B-Task
segmentation	I-Task
,	O
which	O
contains	O
748	O
images	O
annotated	O
with	O
12	O
semantic	O
labels	O
.	O
	
The	O
data	O
are	O
randomly	O
organized	O
into	O
2	O
splits	O
,	O
consisting	O
of	O
452	O
training	O
and	O
296	O
testing	O
images	O
with	O
publicly	O
available	O
annotations	O
.	O
	
For	O
fair	O
comparison	O
,	O
we	O
report	O
the	O
F	B-Metric
orward	I-Metric
(	I-Metric
F	I-Metric
)	O
and	O
B	B-Metric
ackward	I-Metric
(	O
B	B-Metric
)	O
scores	O
over	O
the	O
episode	O
4	O
,	O
5	O
and	O
6	O
for	O
instance	B-Task
segmentation	I-Task
evaluation	I-Task
.	O
	
Refer	O
to	O
for	O
more	O
details	O
.	O
	
The	O
performance	O
comparison	O
of	O
the	O
proposed	O
NAN	B-Method
with	O
three	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
methods	O
in	O
terms	O
of	O
F	B-Metric
and	I-Metric
B	I-Metric
scores	I-Metric
on	O
the	O
Buffy	B-Material
dataset	I-Material
episode	O
4	O
,	O
5	O
and	O
6	O
is	O
reported	O
in	O
Tab	O
.	O
	
[	O
reference	O
]	O
.	O
	
Our	O
NAN	B-Method
consistently	O
achieves	O
the	O
best	O
performance	O
for	O
all	O
metrics	O
.	O
	
In	O
particualr	O
,	O
NAN	B-Method
significantly	O
improves	O
the	O
-	O
best	O
by	O
for	O
F	B-Metric
score	I-Metric
and	O
for	O
B	B-Metric
score	I-Metric
,	O
with	O
an	O
average	O
boost	O
of	O
.	O
	
Qualitative	O
instance	B-Method
-	I-Method
agnostic	I-Method
parsing	I-Method
and	O
instance	B-Method
-	I-Method
aware	I-Method
clustering	I-Method
results	O
by	O
NAN	B-Method
are	O
visualized	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
,	O
which	O
well	O
shows	O
the	O
promising	O
potential	O
of	O
our	O
method	O
for	O
fine	B-Task
-	I-Task
grained	I-Task
understanding	I-Task
humans	I-Task
in	I-Task
crowded	I-Task
scenes	I-Task
.	O
	
section	O
:	O
Conclusions	O
	
In	O
this	O
work	O
,	O
we	O
presented	O
“	O
M	O
	
ulti	O
-	O
H	O
uman	O
	
P	O
arsing	O
(	O
MHP	B-Material
v2.0	I-Material
)	O
	
”	O
,	O
a	O
large	O
-	O
scale	O
multi	O
-	O
human	B-Task
parsing	I-Task
dataset	O
and	O
a	O
carefully	O
designed	O
benchmark	O
to	O
spark	O
progress	O
in	O
understanding	B-Task
humans	I-Task
in	I-Task
crowded	I-Task
scenes	I-Task
.	O
	
MHP	B-Material
v2.0	I-Material
contains	O
25	O
,	O
403	O
images	O
,	O
which	O
are	O
richly	O
labelled	O
with	O
59	O
semantic	O
categories	O
.	O
	
We	O
also	O
proposed	O
a	O
novel	O
deep	O
N	B-Method
ested	I-Method
A	I-Method
dversarial	I-Method
N	I-Method
etwork	I-Method
(	O
NAN	B-Method
)	O
model	O
to	O
address	O
this	O
challenging	O
problem	O
and	O
performed	O
detailed	O
evaluations	O
of	O
the	O
proposed	O
method	O
with	O
current	O
state	O
-	O
of	O
-	O
the	O
-	O
arts	O
on	O
MHP	B-Material
v2.0	I-Material
and	O
several	O
other	O
datasets	O
.	O
	
We	O
envision	O
the	O
proposed	O
MHP	B-Material
v2.0	I-Material
dataset	I-Material
and	O
the	O
baseline	O
method	O
would	O
drive	O
the	O
human	B-Task
parsing	I-Task
research	O
towards	O
real	B-Task
-	I-Task
world	I-Task
application	I-Task
scenario	I-Task
with	O
simultaneous	O
presence	O
of	O
multiple	O
persons	O
and	O
complex	O
interactions	O
among	O
them	O
.	O
	
In	O
future	O
,	O
we	O
will	O
continue	O
to	O
take	O
efforts	O
to	O
construct	O
a	O
more	O
comprehensive	O
multi	O
-	O
human	B-Task
parsing	I-Task
benchmark	O
dataset	O
with	O
more	O
images	O
and	O
more	O
detailed	O
semantic	O
category	O
annotations	O
to	O
further	O
push	O
the	O
frontiers	O
of	O
multi	O
-	O
human	B-Task
parsing	I-Task
research	O
.	O
	
section	O
:	O
Acknowledgement	O
	
The	O
work	O
of	O
Jian	O
Zhao	O
was	O
partially	O
supported	O
by	O
C	O
hina	O
S	O
cholarship	O
C	O
ouncil	O
(	O
CSC	B-Method
)	O
grant	O
201503170248	O
.	O
	
The	O
work	O
of	O
Jiashi	O
Feng	O
was	O
partially	O
supported	O
by	O
NUS	O
	
startup	O
R	O
-	O
263	O
-	O
000	O
-	O
C08	O
-	O
133	O
,	O
	
MOE	O
Tier	O
-	O
I	O
R	O
-	O
263	O
-	O
000	O
-	O
C21	O
	
-	O
112	O
,	O
NUS	O
IDS	O
R	O
-	O
263	O
-	O
000	O
-	O
C67	O
-	O
646	O
and	O
ECRA	B-Method
	
R	O
-	O
263	O
-	O
000	O
-	O
C87	O
-	O
133	O
.	O
	
bibliography	O
:	O
References	O
	
document	O
:	O
Deep	B-Method
Fried	I-Method
Convnets	I-Method
	
The	O
fully	B-Method
-	I-Method
connected	I-Method
layers	I-Method
of	I-Method
deep	I-Method
convolutional	I-Method
neural	I-Method
networks	I-Method
typically	O
contain	O
over	O
90	O
%	O
of	O
the	O
network	O
parameters	O
.	O
	
Reducing	O
the	O
number	O
of	O
parameters	O
while	O
preserving	O
predictive	B-Metric
performance	I-Metric
is	O
critically	O
important	O
for	O
training	O
big	B-Method
models	I-Method
in	O
distributed	B-Task
systems	I-Task
and	O
for	O
deployment	O
in	O
embedded	B-Task
devices	I-Task
.	O
	
In	O
this	O
paper	O
,	O
we	O
introduce	O
a	O
novel	O
Adaptive	B-Method
Fastfood	I-Method
transform	I-Method
to	O
reparameterize	O
the	O
matrix	B-Method
-	I-Method
vector	I-Method
multiplication	I-Method
of	I-Method
fully	I-Method
connected	I-Method
layers	I-Method
.	O
	
Reparameterizing	O
a	O
fully	B-Method
connected	I-Method
layer	I-Method
with	O
inputs	O
and	O
outputs	O
with	O
the	O
Adaptive	B-Method
Fastfood	I-Method
transform	I-Method
reduces	O
the	O
storage	B-Metric
and	I-Metric
computational	I-Metric
costs	I-Metric
costs	I-Metric
from	O
to	O
and	O
respectively	O
.	O
	
Using	O
the	O
Adaptive	B-Method
Fastfood	I-Method
transform	I-Method
in	O
convolutional	B-Method
networks	I-Method
results	O
in	O
what	O
we	O
call	O
a	O
deep	B-Method
fried	I-Method
convnet	I-Method
.	O
	
These	O
convnets	B-Method
are	O
end	O
-	O
to	O
-	O
end	O
trainable	O
,	O
and	O
enable	O
us	O
to	O
attain	O
substantial	O
reductions	O
in	O
the	O
number	O
of	O
parameters	O
without	O
affecting	O
prediction	B-Metric
accuracy	I-Metric
on	O
the	O
MNIST	B-Material
and	O
ImageNet	B-Material
datasets	I-Material
.	O
	
section	O
:	O
Introduction	O
	
In	O
recent	O
years	O
we	O
have	O
witnessed	O
an	O
explosion	O
of	O
applications	O
of	O
convolutional	B-Method
neural	I-Method
networks	I-Method
with	O
millions	O
and	O
billions	O
of	O
parameters	O
.	O
	
Reducing	O
this	O
vast	O
number	O
of	O
parameters	O
would	O
improve	O
the	O
efficiency	O
of	O
training	B-Task
in	O
distributed	B-Task
architectures	I-Task
.	O
	
It	O
would	O
also	O
allow	O
for	O
the	O
deployment	O
of	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
convolutional	B-Method
neural	I-Method
networks	I-Method
on	O
embedded	B-Task
mobile	I-Task
applications	I-Task
.	O
	
These	O
train	B-Metric
and	I-Metric
test	I-Metric
time	I-Metric
considerations	I-Metric
are	O
both	O
of	O
great	O
importance	O
.	O
	
A	O
standard	O
convolutional	B-Method
network	I-Method
is	O
composed	O
of	O
two	O
types	O
of	O
layers	O
,	O
each	O
with	O
very	O
different	O
properties	O
.	O
	
Convolutional	B-Method
layers	I-Method
,	O
which	O
contain	O
a	O
small	O
fraction	O
of	O
the	O
network	O
parameters	O
,	O
represent	O
most	O
of	O
the	O
computational	B-Metric
effort	I-Metric
.	O
	
In	O
contrast	O
,	O
fully	B-Method
connected	I-Method
layers	I-Method
contain	O
the	O
vast	O
majority	O
of	O
the	O
parameters	O
but	O
are	O
comparatively	O
cheap	O
to	O
evaluate	O
.	O
	
This	O
imbalance	O
between	O
memory	O
and	O
computation	O
suggests	O
that	O
the	O
efficiency	O
of	O
these	O
two	O
types	O
of	O
layers	O
should	O
be	O
addressed	O
in	O
different	O
ways	O
.	O
	
and	O
both	O
describe	O
methods	O
for	O
minimizing	O
computational	B-Metric
cost	I-Metric
of	O
evaluating	O
a	O
network	O
at	O
test	O
time	O
by	O
approximating	O
the	O
learned	B-Method
convolutional	I-Method
filters	I-Method
with	O
separable	B-Method
approximations	I-Method
.	O
	
These	O
approaches	O
realize	O
speed	O
gains	O
at	O
test	O
time	O
but	O
do	O
not	O
address	O
the	O
issue	O
of	O
training	B-Task
,	O
since	O
the	O
approximations	O
are	O
made	O
after	O
the	O
network	O
has	O
been	O
fully	O
trained	O
.	O
	
Additionally	O
,	O
neither	O
approach	O
achieves	O
a	O
substantial	O
reduction	O
in	O
the	O
number	O
of	O
parameters	O
,	O
since	O
they	O
both	O
work	O
with	O
approximations	B-Method
of	I-Method
the	I-Method
convolutional	I-Method
layers	I-Method
,	O
which	O
represent	O
only	O
a	O
small	O
portion	O
of	O
the	O
total	O
number	O
of	O
parameters	O
.	O
	
Many	O
other	O
works	O
have	O
addressed	O
the	O
computational	B-Metric
efficiency	I-Metric
of	O
convolutional	B-Method
networks	I-Method
in	O
more	O
specialized	O
settings	O
.	O
	
In	O
contrast	O
to	O
the	O
above	O
approaches	O
,	O
demonstrates	O
that	O
there	O
is	O
significant	O
redundancy	O
in	O
the	O
parameterization	O
of	O
several	O
deep	B-Method
learning	I-Method
models	I-Method
,	O
and	O
exploits	O
this	O
to	O
reduce	O
the	O
number	O
of	O
parameters	O
.	O
	
More	O
specifically	O
,	O
their	O
method	O
represents	O
the	O
parameter	O
matrix	O
as	O
a	O
product	O
of	O
two	O
low	O
rank	O
factors	O
,	O
and	O
the	O
training	B-Method
algorithm	I-Method
fixes	O
one	O
factor	O
(	O
called	O
static	O
parameters	O
)	O
and	O
only	O
updates	O
the	O
other	O
factor	O
(	O
called	O
dynamic	O
parameters	O
)	O
.	O
uses	O
low	B-Method
-	I-Method
rank	I-Method
matrix	I-Method
factorization	I-Method
to	O
reduce	O
the	O
size	O
of	O
the	O
fully	O
connected	O
layers	O
at	O
train	O
time	O
.	O
	
They	O
demonstrate	O
large	O
improvements	O
in	O
reducing	O
the	O
number	O
of	O
parameters	O
of	O
the	O
output	O
softmax	O
layer	O
,	O
but	O
only	O
modest	O
improvements	O
for	O
the	O
hidden	B-Method
fully	I-Method
connected	I-Method
layers	I-Method
.	O
	
implements	O
low	B-Method
-	I-Method
rank	I-Method
factorizations	I-Method
using	O
the	O
SVD	B-Method
after	O
training	O
the	O
full	B-Method
model	I-Method
.	O
	
In	O
contrast	O
,	O
the	O
methods	O
advanced	O
in	O
and	O
this	O
paper	O
apply	O
both	O
at	O
train	O
and	O
test	O
time	O
.	O
	
In	O
this	O
paper	O
we	O
show	O
how	O
the	O
number	O
of	O
parameters	O
required	O
to	O
represent	O
a	O
deep	B-Method
convolutional	I-Method
neural	I-Method
network	I-Method
can	O
be	O
substantially	O
reduced	O
without	O
sacrificing	O
predictive	B-Metric
performance	I-Metric
.	O
	
Our	O
approach	O
works	O
by	O
replacing	O
the	O
fully	B-Method
connected	I-Method
layers	I-Method
of	I-Method
the	I-Method
network	I-Method
with	O
an	O
Adaptive	B-Method
Fastfood	I-Method
transform	I-Method
,	O
which	O
is	O
a	O
generalization	O
of	O
the	O
Fastfood	B-Method
transform	I-Method
for	O
approximating	B-Task
kernels	I-Task
.	O
	
Convolutional	B-Method
neural	I-Method
networks	I-Method
with	O
Adaptive	B-Method
Fastfood	I-Method
transforms	I-Method
,	O
which	O
we	O
refer	O
to	O
as	O
deep	B-Method
fried	I-Method
convnets	I-Method
,	O
are	O
end	O
-	O
to	O
-	O
end	O
trainable	O
and	O
achieve	O
the	O
same	O
predictive	O
performance	O
as	O
standard	O
convolutional	B-Method
networks	I-Method
on	O
ImageNet	B-Method
using	O
approximately	O
half	O
the	O
number	O
of	O
parameters	O
.	O
	
Several	O
works	O
have	O
considered	O
kernel	B-Method
methods	I-Method
in	O
deep	B-Task
learning	I-Task
.	O
	
The	O
Doubly	B-Method
Stochastic	I-Method
Gradients	I-Method
method	I-Method
of	O
showed	O
that	O
effective	O
use	O
of	O
randomization	B-Method
can	O
allow	O
kernel	B-Method
methods	I-Method
to	O
scale	O
to	O
extremely	O
large	O
data	O
sets	O
.	O
	
However	O
,	O
the	O
approach	O
used	O
fixed	O
convolutional	O
features	O
,	O
and	O
can	O
not	O
jointly	O
learn	O
the	O
kernel	B-Method
classifier	I-Method
and	O
convolutional	B-Method
filters	I-Method
.	O
	
showed	O
how	O
to	O
learn	O
a	O
kernel	B-Method
function	I-Method
in	O
an	O
unsupervised	B-Method
manner	I-Method
.	O
	
There	O
have	O
been	O
other	O
attempts	O
to	O
replace	O
the	O
fully	O
connected	O
layers	O
.	O
	
The	O
Network	B-Method
in	I-Method
Network	I-Method
architecture	I-Method
of	O
achieves	O
state	O
of	O
the	O
art	O
results	O
on	O
several	O
deep	B-Task
learning	I-Task
benchmarks	I-Task
by	O
replacing	O
the	O
fully	B-Method
connected	I-Method
layers	I-Method
with	O
global	B-Method
average	I-Method
pooling	I-Method
.	O
	
A	O
similar	O
approach	O
was	O
used	O
by	O
to	O
win	O
the	O
ILSVRC	B-Task
2014	I-Task
object	I-Task
detection	I-Task
competition	I-Task
.	O
	
Although	O
the	O
global	B-Method
average	I-Method
pooling	I-Method
approach	I-Method
achieves	O
impressive	O
results	O
,	O
it	O
has	O
two	O
significant	O
drawbacks	O
.	O
	
First	O
,	O
feature	B-Task
transfer	I-Task
is	O
more	O
difficult	O
with	O
this	O
approach	O
.	O
	
It	O
is	O
very	O
common	O
in	O
practice	O
to	O
take	O
a	O
convolutional	B-Method
network	I-Method
trained	O
on	O
ImageNet	B-Material
and	O
re	O
-	O
train	O
the	O
top	O
layer	O
on	O
a	O
different	O
data	O
set	O
,	O
re	O
-	O
using	O
the	O
features	O
learned	O
from	O
ImageNet	B-Material
for	O
the	O
new	O
task	O
(	O
potentially	O
with	O
fine	B-Task
-	I-Task
tuning	I-Task
)	O
,	O
and	O
this	O
is	O
difficult	O
with	O
global	B-Method
average	I-Method
pooling	I-Method
.	O
	
This	O
deficiency	O
is	O
noted	O
by	O
,	O
and	O
motivates	O
them	O
to	O
add	O
an	O
extra	O
linear	O
layer	O
to	O
the	O
top	O
of	O
their	O
network	O
to	O
enable	O
them	O
to	O
more	O
easily	O
adapt	O
and	O
fine	O
tune	O
their	O
network	O
to	O
other	O
label	O
sets	O
.	O
	
The	O
second	O
drawback	O
of	O
global	B-Method
average	I-Method
pooling	I-Method
is	O
computation	B-Task
.	O
	
Convolutional	B-Method
layers	I-Method
are	O
much	O
more	O
expensive	O
to	O
evaluate	O
than	O
fully	O
connected	O
layers	O
,	O
so	O
replacing	O
fully	B-Method
connected	I-Method
layers	I-Method
with	O
more	O
convolutions	B-Method
can	O
decrease	O
model	B-Metric
size	I-Metric
but	O
comes	O
at	O
the	O
cost	O
of	O
increased	O
evaluation	B-Metric
time	I-Metric
.	O
	
In	O
parallel	O
or	O
after	O
the	O
first	O
(	O
technical	O
report	O
)	O
version	O
of	O
this	O
work	O
,	O
several	O
researchers	O
have	O
attempted	O
to	O
create	O
sparse	B-Method
networks	I-Method
by	O
applying	O
pruning	B-Method
or	I-Method
sparsity	I-Method
regularizers	I-Method
.	O
	
These	O
approaches	O
however	O
require	O
training	O
the	O
original	O
full	B-Method
model	I-Method
and	O
,	O
consequently	O
,	O
do	O
not	O
enjoy	O
the	O
efficient	O
training	B-Metric
time	I-Metric
benefits	O
of	O
the	O
techniques	O
proposed	O
in	O
this	O
paper	O
.	O
	
Since	O
then	O
,	O
hashing	B-Method
methods	I-Method
have	O
also	O
been	O
advanced	O
to	O
reduce	O
the	O
number	O
of	O
parameters	O
.	O
	
Hashes	B-Method
have	O
irregular	O
memory	O
access	O
patterns	O
and	O
,	O
consequently	O
,	O
good	O
performance	O
on	O
large	O
GPU	B-Task
-	I-Task
based	I-Task
platforms	I-Task
is	O
yet	O
to	O
be	O
demonstrated	O
.	O
	
Finally	O
,	O
distillation	B-Method
also	O
offers	O
a	O
way	O
of	O
compressing	B-Method
neural	I-Method
networks	I-Method
,	O
as	O
a	O
post	B-Task
-	I-Task
processing	I-Task
step	I-Task
.	O
	
section	O
:	O
The	O
Adaptive	B-Method
Fastfood	I-Method
Transform	I-Method
	
Large	O
dense	O
matrices	O
are	O
the	O
main	O
building	O
block	O
of	O
fully	B-Method
connected	I-Method
neural	I-Method
network	I-Method
layers	I-Method
.	O
	
In	O
propagating	O
the	O
signal	O
from	O
the	O
-	O
th	O
layer	O
with	O
activations	O
to	O
the	O
-	O
th	O
layer	O
with	O
activations	O
,	O
we	O
have	O
to	O
compute	O
The	O
storage	B-Metric
and	I-Metric
computational	I-Metric
costs	I-Metric
of	O
this	O
matrix	B-Method
multiplication	I-Method
step	I-Method
are	O
both	O
.	O
	
The	O
storage	B-Metric
cost	I-Metric
in	O
particular	O
can	O
be	O
prohibitive	O
for	O
many	O
applications	O
.	O
	
Our	O
proposed	O
solution	O
is	O
to	O
reparameterize	O
the	O
matrix	O
of	O
parameters	O
with	O
an	O
Adaptive	B-Method
Fastfood	I-Method
transform	I-Method
,	O
as	O
follows	O
In	O
Section	O
[	O
reference	O
]	O
,	O
we	O
will	O
provide	O
background	O
and	O
intuitions	O
behind	O
this	O
design	O
.	O
	
For	O
now	O
it	O
suffices	O
to	O
state	O
that	O
the	O
storage	B-Metric
requirements	I-Metric
of	O
this	O
reparameterization	B-Method
are	O
and	O
the	O
computational	B-Metric
cost	I-Metric
is	O
.	O
	
We	O
will	O
also	O
show	O
in	O
the	O
experimental	O
section	O
that	O
these	O
theoretical	O
savings	O
are	O
mirrored	O
in	O
practice	O
by	O
significant	O
reductions	O
in	O
the	O
number	O
of	O
parameters	O
without	O
increased	O
prediction	B-Metric
errors	I-Metric
.	O
	
To	O
understand	O
these	O
claims	O
,	O
we	O
need	O
to	O
describe	O
the	O
component	B-Method
modules	I-Method
of	O
the	O
Adaptive	B-Method
Fastfood	I-Method
transform	I-Method
.	O
	
For	O
simplicity	O
of	O
presentation	O
,	O
let	O
us	O
first	O
assume	O
that	O
.	O
	
Adaptive	B-Method
Fastfood	I-Method
has	O
three	O
types	O
of	O
module	O
:	O
and	O
are	O
diagonal	O
matrices	O
of	O
parameters	O
.	O
	
In	O
the	O
original	O
non	B-Method
-	I-Method
adaptive	I-Method
Fastfood	I-Method
formulation	I-Method
they	O
are	O
random	O
matrices	O
,	O
as	O
described	O
further	O
in	O
Section	O
[	O
reference	O
]	O
.	O
	
The	O
computational	B-Metric
and	I-Metric
storage	I-Metric
costs	I-Metric
are	O
trivially	O
.	O
	
is	O
a	O
random	B-Method
permutation	I-Method
matrix	I-Method
.	O
	
It	O
can	O
be	O
implemented	O
as	O
a	O
lookup	O
table	O
,	O
so	O
the	O
storage	B-Metric
and	I-Metric
computational	I-Metric
costs	I-Metric
are	O
also	O
.	O
	
denotes	O
the	O
Walsh	B-Method
-	I-Method
Hadamard	I-Method
matrix	I-Method
,	O
which	O
is	O
defined	O
recursively	O
as	O
The	O
Fast	B-Method
Hadamard	I-Method
Transform	I-Method
,	O
a	O
variant	O
of	O
Fast	B-Method
Fourier	I-Method
Transform	I-Method
,	O
enables	O
us	O
to	O
compute	O
in	O
time	O
.	O
	
In	O
summary	O
,	O
the	O
overall	O
storage	B-Metric
cost	I-Metric
of	O
the	O
Adaptive	B-Method
Fastfood	I-Method
transform	I-Method
is	O
,	O
while	O
the	O
computational	B-Metric
cost	I-Metric
is	O
.	O
	
These	O
are	O
substantial	O
theoretical	O
improvements	O
over	O
the	O
costs	O
of	O
ordinary	O
fully	B-Method
connected	I-Method
layers	I-Method
.	O
	
When	O
the	O
number	O
of	O
output	O
units	O
is	O
larger	O
than	O
the	O
number	O
of	O
inputs	O
,	O
we	O
can	O
perform	O
Adaptive	B-Method
Fastfood	I-Method
transforms	I-Method
and	O
stack	O
them	O
to	O
attain	O
the	O
desired	O
size	O
.	O
	
In	O
doing	O
so	O
,	O
the	O
computational	B-Metric
and	I-Metric
storage	I-Metric
costs	I-Metric
become	O
and	O
respectively	O
,	O
as	O
opposed	O
to	O
the	O
more	O
substantial	O
costs	O
for	O
linear	B-Method
modules	I-Method
.	O
	
The	O
number	O
of	O
outputs	O
can	O
also	O
be	O
refined	O
with	O
pruning	O
.	O
	
subsection	O
:	O
Learning	O
Fastfood	B-Task
by	O
backpropagation	B-Method
	
The	O
parameters	O
of	O
the	O
Adaptive	B-Method
Fastfood	I-Method
transform	I-Method
(	O
and	O
)	O
can	O
be	O
learned	O
by	O
standard	O
error	B-Method
derivative	I-Method
backpropagation	I-Method
.	O
	
Moreover	O
,	O
the	O
backward	O
pass	O
can	O
also	O
be	O
computed	O
efficiently	O
using	O
the	O
Fast	B-Method
Hadamard	I-Method
Transform	I-Method
.	O
	
In	O
particular	O
,	O
let	O
us	O
consider	O
learning	O
the	O
-	B-Method
th	I-Method
layer	I-Method
of	I-Method
the	I-Method
network	I-Method
,	O
.	O
	
For	O
simplicity	O
,	O
let	O
us	O
again	O
assume	O
that	O
and	O
that	O
.	O
	
Using	O
backpropagation	B-Method
,	O
assume	O
we	O
already	O
have	O
,	O
where	O
is	O
the	O
objective	O
function	O
,	O
then	O
Since	O
is	O
a	O
diagonal	O
matrix	O
,	O
we	O
only	O
need	O
to	O
calculate	O
the	O
derivative	O
with	O
respect	O
to	O
the	O
diagonal	O
entries	O
and	O
this	O
step	O
requires	O
only	O
operations	O
.	O
	
Proceeding	O
in	O
this	O
way	O
,	O
denote	O
the	O
partial	O
products	O
by	O
Then	O
the	O
gradients	O
with	O
respect	O
to	O
different	O
parameters	O
in	O
the	O
Fastfood	O
layer	O
can	O
be	O
computed	O
recursively	O
as	O
follows	O
:	O
	
Note	O
that	O
the	O
operations	O
in	O
and	O
are	O
simply	O
applications	O
of	O
the	O
Hadamard	B-Method
transform	I-Method
,	O
since	O
,	O
and	O
consequently	O
can	O
be	O
computed	O
in	O
time	O
.	O
	
The	O
operation	O
in	O
is	O
an	O
application	O
of	O
a	O
permutation	O
(	O
the	O
transpose	O
of	O
permutation	O
matrix	O
is	O
a	O
permutation	O
matrix	O
)	O
and	O
can	O
be	O
computed	O
in	O
time	O
.	O
	
All	O
other	O
operations	O
are	O
diagonal	B-Method
matrix	I-Method
multiplications	I-Method
.	O
	
section	O
:	O
Intuitions	O
behind	O
Adaptive	O
Fastfood	O
	
The	O
proposed	O
Adaptive	B-Method
Fastfood	I-Method
transform	I-Method
may	O
be	O
understood	O
either	O
as	O
a	O
trainable	O
type	O
of	O
structured	B-Method
random	I-Method
projection	I-Method
or	O
as	O
an	O
approximation	O
to	O
the	O
feature	O
space	O
of	O
a	O
learned	O
kernel	O
.	O
	
Both	O
views	O
not	O
only	O
shed	O
light	O
on	O
Adaptive	B-Method
Fastfood	I-Method
and	I-Method
competing	I-Method
techniques	I-Method
,	O
but	O
also	O
open	O
up	O
room	O
to	O
innovate	O
new	O
techniques	O
to	O
reduce	O
computation	B-Task
and	I-Task
memory	I-Task
in	O
neural	B-Method
networks	I-Method
.	O
	
subsection	O
:	O
A	O
view	O
from	O
structured	B-Method
random	I-Method
projections	I-Method
	
Adaptive	B-Method
Fastfood	I-Method
is	O
based	O
on	O
the	O
Fastfood	B-Method
transform	I-Method
,	O
in	O
which	O
the	O
diagonal	O
matrices	O
,	O
and	O
have	O
random	O
entries	O
.	O
	
In	O
the	O
experiments	O
,	O
we	O
will	O
compare	O
the	O
performance	O
of	O
the	O
existing	O
random	O
and	O
proposed	O
adaptive	B-Method
versions	I-Method
of	O
Fastfood	B-Method
when	O
used	O
to	O
replace	O
fully	B-Method
connected	I-Method
layers	I-Method
in	O
convolutional	B-Method
neural	I-Method
networks	I-Method
.	O
	
The	O
intriguing	O
idea	O
of	O
constructing	O
neural	B-Method
networks	I-Method
with	O
random	O
weights	O
has	O
been	O
reasonably	O
explored	O
in	O
the	O
neural	B-Task
networks	I-Task
field	I-Task
.	O
	
This	O
idea	O
is	O
related	O
to	O
random	O
projections	O
,	O
which	O
have	O
been	O
deeply	O
studied	O
in	O
theoretical	B-Task
computer	I-Task
science	I-Task
.	O
	
In	O
a	O
random	B-Method
projection	I-Method
,	O
the	O
basic	O
operation	O
is	O
of	O
the	O
form	O
where	O
is	O
a	O
random	O
matrix	O
,	O
either	O
Gaussian	O
or	O
binary	O
.	O
	
Importantly	O
,	O
the	O
embeddings	O
generated	O
by	O
these	O
random	O
projections	O
approximately	O
preserve	O
metric	O
information	O
,	O
as	O
formalized	O
by	O
many	O
variants	O
of	O
the	O
celebrated	O
Johnson	B-Method
-	I-Method
Lindenstrauss	I-Method
Lemma	I-Method
.	O
	
The	O
one	O
shortcoming	O
of	O
random	O
projections	O
is	O
that	O
the	O
cost	O
of	O
storing	O
the	O
matrix	O
is	O
.	O
	
Using	O
a	O
sparse	O
random	O
matrix	O
by	O
itself	O
to	O
reduce	O
this	O
cost	O
is	O
often	O
not	O
a	O
viable	O
option	O
because	O
the	O
variance	O
of	O
the	O
estimates	O
of	O
can	O
be	O
very	O
high	O
for	O
some	O
inputs	O
,	O
for	O
example	O
when	O
is	O
also	O
sparse	O
.	O
	
To	O
see	O
this	O
,	O
consider	O
the	O
extreme	O
case	O
of	O
a	O
very	O
sparse	O
input	O
,	O
then	O
many	O
of	O
the	O
products	O
with	O
will	O
be	O
zero	O
and	O
hence	O
not	O
help	O
improve	O
the	O
estimates	O
of	O
metric	O
properties	O
of	O
the	O
embedding	O
space	O
.	O
	
One	O
popular	O
option	O
for	O
reducing	O
the	O
storage	B-Task
and	I-Task
computational	I-Task
costs	I-Task
of	I-Task
random	I-Task
projections	I-Task
is	O
to	O
adopt	O
random	B-Method
hash	I-Method
functions	I-Method
to	O
replace	O
the	O
random	B-Method
matrix	I-Method
multiplication	I-Method
.	O
	
For	O
example	O
,	O
the	O
count	B-Method
-	I-Method
sketch	I-Method
algorithm	I-Method
uses	O
pairwise	B-Method
independent	I-Method
hash	I-Method
functions	I-Method
to	O
carry	O
this	O
job	O
very	O
effectively	O
in	O
many	O
applications	O
.	O
	
This	O
technique	O
is	O
often	O
referred	O
to	O
as	O
the	O
hashing	O
trick	O
in	O
the	O
machine	B-Task
learning	I-Task
literature	I-Task
.	O
	
Hashes	B-Method
have	O
irregular	O
memory	O
access	O
patterns	O
,	O
so	O
it	O
is	O
not	O
clear	O
how	O
to	O
get	O
good	O
performance	O
on	O
GPUs	O
when	O
following	O
this	O
approach	O
,	O
as	O
pointed	O
out	O
in	O
.	O
	
Ailon	O
and	O
Chazelle	O
introduced	O
an	O
alternative	O
approach	O
that	O
is	O
not	O
only	O
very	O
efficient	O
,	O
but	O
also	O
preserves	O
most	O
of	O
the	O
desirable	O
theoretical	O
properties	O
of	O
random	O
projections	O
.	O
	
Their	O
idea	O
was	O
to	O
replace	O
the	O
random	O
matrix	O
by	O
a	O
transform	O
that	O
mimics	O
the	O
properties	O
of	O
random	O
matrices	O
,	O
but	O
which	O
can	O
be	O
stored	O
efficiently	O
.	O
	
In	O
particular	O
,	O
they	O
proposed	O
the	O
following	O
PHD	B-Method
transform	I-Method
:	O
where	O
is	O
a	O
sparse	O
random	O
matrix	O
with	O
Gaussian	O
entries	O
,	O
is	O
a	O
Hadamard	O
matrix	O
and	O
is	O
a	O
diagonal	O
matrix	O
with	O
entries	O
drawn	O
independently	O
with	O
probability	O
.	O
	
The	O
inclusion	O
of	O
the	O
Hadamard	B-Method
transform	I-Method
avoids	O
the	O
problems	O
of	O
using	O
a	O
sparse	O
random	O
matrix	O
by	O
itself	O
,	O
but	O
it	O
is	O
still	O
efficient	O
to	O
compute	O
.	O
	
We	O
can	O
think	O
of	O
the	O
original	O
Fastfood	B-Method
transform	I-Method
as	O
an	O
alternative	O
to	O
this	O
.	O
	
Fastfood	B-Method
reduces	O
the	O
computation	O
and	O
storage	O
of	O
random	O
projections	O
to	O
and	O
respectively	O
.	O
	
In	O
the	O
original	O
formulation	O
and	O
are	O
diagonal	O
random	O
matrices	O
,	O
which	O
are	O
computed	O
once	O
and	O
then	O
stored	O
.	O
	
In	O
contrast	O
,	O
in	O
our	O
proposed	O
Adaptive	B-Method
Fastfood	I-Method
transform	I-Method
,	O
the	O
diagonal	O
matrices	O
are	O
learned	O
by	O
backpropagation	B-Method
.	O
	
By	O
adapting	O
,	O
we	O
are	O
effectively	O
implementing	O
Automatic	B-Task
Relevance	I-Task
Determination	I-Task
on	O
features	O
.	O
	
The	O
matrix	O
controls	O
the	O
bandwidth	O
of	O
the	O
kernel	O
and	O
its	O
spectral	B-Method
incoherence	I-Method
.	O
	
Finally	O
,	O
represents	O
different	O
kernel	O
types	O
.	O
	
For	O
example	O
,	O
for	O
the	O
RBF	B-Method
kernel	I-Method
follows	O
Chi	B-Method
-	I-Method
squared	I-Method
distribution	I-Method
.	O
	
By	O
adapting	O
,	O
we	O
learn	O
the	O
correct	O
kernel	O
type	O
.	O
	
While	O
we	O
have	O
introduced	O
Fastfood	O
in	O
this	O
section	O
,	O
it	O
was	O
originally	O
proposed	O
as	O
a	O
fast	O
way	O
of	O
computing	O
random	O
features	O
to	O
approximate	O
kernels	O
.	O
	
We	O
expand	O
on	O
this	O
perspective	O
in	O
the	O
following	O
section	O
.	O
	
subsection	O
:	O
A	O
view	O
from	O
kernels	O
	
There	O
is	O
a	O
nice	O
duality	O
between	O
inner	O
products	O
of	O
features	O
and	O
kernels	B-Method
.	O
	
This	O
duality	O
can	O
be	O
used	O
to	O
design	O
neural	B-Method
network	I-Method
modules	I-Method
using	O
kernels	B-Method
and	O
vice	O
-	O
versa	O
.	O
	
For	O
computational	B-Task
reasons	I-Task
,	O
we	O
often	O
want	O
to	O
determine	O
the	O
features	O
associated	O
with	O
a	O
kernel	B-Method
.	O
	
Working	O
with	O
features	O
is	O
preferable	O
when	O
the	O
kernel	O
matrix	O
is	O
dense	O
and	O
large	O
.	O
	
(	O
Storing	O
this	O
matrix	O
requires	O
space	O
,	O
and	O
computing	O
it	O
takes	O
operations	O
,	O
where	O
is	O
the	O
number	O
of	O
data	O
points	O
and	O
is	O
the	O
dimension	O
.	O
)	O
	
We	O
might	O
also	O
want	O
to	O
design	O
statistical	B-Method
methods	I-Method
using	O
kernels	B-Method
and	O
then	O
map	O
these	O
designs	O
to	O
features	O
that	O
can	O
be	O
used	O
as	O
modules	O
in	O
neural	B-Method
networks	I-Method
.	O
	
Unfortunately	O
,	O
one	O
of	O
the	O
difficulties	O
with	O
this	O
line	O
of	O
attack	O
is	O
that	O
deriving	O
features	O
from	O
kernels	B-Method
is	O
far	O
from	O
trivial	O
in	O
general	O
.	O
	
An	O
important	O
fact	O
,	O
noted	O
in	O
,	O
is	O
that	O
infinite	B-Method
kernel	I-Method
expansions	I-Method
can	O
be	O
approximated	O
in	O
an	O
unbiased	O
manner	O
using	O
randomly	O
drawn	O
features	O
.	O
	
For	O
shift	B-Method
-	I-Method
invariant	I-Method
kernels	I-Method
this	O
relies	O
on	O
a	O
classical	O
result	O
from	O
harmonic	B-Method
analysis	I-Method
,	O
known	O
as	O
Bochner	B-Method
’s	I-Method
Lemma	I-Method
,	O
which	O
states	O
that	O
a	O
continuous	O
shift	O
-	O
invariant	O
kernel	O
on	O
is	O
positive	O
definite	O
if	O
and	O
only	O
if	O
is	O
the	O
Fourier	O
transform	O
of	O
a	O
non	O
-	O
negative	O
measure	O
.	O
	
This	O
measure	O
,	O
known	O
as	O
the	O
spectral	O
density	O
,	O
in	O
turn	O
implies	O
the	O
existence	O
of	O
a	O
probability	O
density	O
such	O
that	O
where	O
the	O
imaginary	O
part	O
is	O
dropped	O
since	O
both	O
the	O
kernel	O
and	O
distribution	O
are	O
real	O
.	O
	
We	O
can	O
apply	O
Monte	B-Method
Carlo	I-Method
methods	I-Method
to	O
approximate	O
the	O
above	O
expectation	O
,	O
and	O
hence	O
approximate	O
the	O
kernel	B-Method
with	O
an	O
inner	B-Method
product	I-Method
of	I-Method
stacked	I-Method
cosine	I-Method
and	I-Method
sine	I-Method
features	I-Method
.	O
	
Specifically	O
,	O
suppose	O
we	O
sample	O
vectors	O
from	O
and	O
collect	O
them	O
in	O
a	O
matrix	O
.	O
	
The	O
kernel	O
can	O
then	O
be	O
approximated	O
as	O
the	O
inner	B-Method
-	I-Method
product	I-Method
of	O
the	O
following	O
random	O
features	O
:	O
That	O
is	O
,	O
is	O
the	O
neural	B-Method
network	I-Method
module	I-Method
,	O
consisting	O
of	O
a	O
linear	B-Method
layer	I-Method
and	O
entry	O
-	O
wise	O
nonlinearities	O
(	O
cosine	O
and	O
sine	O
in	O
the	O
above	O
equation	O
)	O
,	O
that	O
corresponds	O
to	O
a	O
particular	O
implicit	O
kernel	O
function	O
.	O
	
Approximating	O
a	O
given	O
kernel	O
function	O
with	O
random	O
features	O
requires	O
the	O
specification	O
of	O
a	O
sampling	B-Method
distribution	I-Method
.	O
	
Such	O
distributions	O
have	O
been	O
derived	O
for	O
many	O
popular	O
kernels	B-Method
.	O
	
For	O
example	O
,	O
if	O
we	O
want	O
the	O
implicit	O
kernel	O
to	O
be	O
a	O
squared	B-Method
exponential	I-Method
kernel	I-Method
,	O
we	O
know	O
that	O
the	O
distribution	O
must	O
be	O
Gaussian	O
:	O
.	O
	
In	O
other	O
words	O
,	O
if	O
we	O
draw	O
the	O
rows	O
of	O
from	O
this	O
Gaussian	B-Method
distribution	I-Method
and	O
use	O
equation	O
(	O
[	O
reference	O
]	O
)	O
to	O
implement	O
a	O
neural	B-Method
module	I-Method
,	O
we	O
are	O
implicitly	O
approximating	O
a	O
squared	B-Method
exponential	I-Method
kernel	I-Method
.	O
	
As	O
another	O
example	O
of	O
the	O
mapping	O
between	O
kernels	O
and	O
random	O
features	O
,	O
introduced	O
the	O
rotationally	B-Method
invariant	I-Method
arc	I-Method
-	I-Method
cosine	I-Method
kernel	I-Method
where	O
is	O
the	O
angle	O
between	O
and	O
.	O
	
Then	O
by	O
choosing	O
to	O
be	O
a	O
random	O
Gaussian	O
matrix	O
,	O
they	O
showed	O
that	O
this	O
kernel	O
can	O
be	O
approximated	O
with	O
Rectified	B-Method
Linear	I-Method
Unit	I-Method
(	O
ReLU	B-Method
)	O
	
features	O
:	O
	
The	O
Fastfood	B-Method
transform	I-Method
was	O
introduced	O
to	O
replace	O
in	O
Equation	O
[	O
reference	O
]	O
with	O
,	O
thus	O
decreasing	O
the	O
computational	B-Metric
and	I-Metric
storage	I-Metric
costs	I-Metric
.	O
	
section	O
:	O
Deep	B-Method
Fried	I-Method
Convolutional	I-Method
Networks	I-Method
	
We	O
propose	O
to	O
greatly	O
reduce	O
the	O
number	O
of	O
parameters	O
of	O
the	O
fully	B-Method
connected	I-Method
layers	I-Method
by	O
replacing	O
them	O
with	O
an	O
Adaptive	B-Method
Fastfood	I-Method
transform	I-Method
followed	O
by	O
a	O
nonlinearity	O
.	O
	
We	O
call	O
this	O
new	O
architecture	O
a	O
deep	B-Method
fried	I-Method
convolutional	I-Method
network	I-Method
.	O
	
An	O
illustration	O
of	O
this	O
architecture	O
is	O
shown	O
in	O
Figure	O
[	O
reference	O
]	O
.	O
	
In	O
principle	O
,	O
we	O
could	O
also	O
apply	O
the	O
Adaptive	B-Method
Fastfood	I-Method
transform	I-Method
to	O
the	O
softmax	B-Method
classifier	I-Method
.	O
	
However	O
,	O
reducing	O
the	O
memory	B-Metric
cost	I-Metric
of	O
this	O
layer	O
is	O
already	O
well	O
studied	O
;	O
for	O
example	O
,	O
show	O
that	O
low	B-Method
-	I-Method
rank	I-Method
matrix	I-Method
factorization	I-Method
can	O
be	O
applied	O
during	O
training	B-Task
to	O
reduce	O
the	O
size	O
of	O
the	O
softmax	B-Method
layer	I-Method
substantially	O
.	O
	
Importantly	O
,	O
they	O
also	O
show	O
that	O
training	O
a	O
low	B-Method
rank	I-Method
factorization	I-Method
for	O
the	O
internal	O
layers	O
performs	O
poorly	O
,	O
which	O
agrees	O
with	O
the	O
results	O
of	O
.	O
	
For	O
this	O
reason	O
,	O
we	O
focus	O
our	O
attention	O
on	O
reducing	O
the	O
size	O
of	O
the	O
internal	O
layers	O
.	O
	
section	O
:	O
MNIST	B-Material
Experiment	O
	
The	O
first	O
problem	O
we	O
study	O
is	O
the	O
classical	O
MNIST	B-Material
optical	O
character	O
recognition	O
task	O
.	O
	
This	O
simple	O
task	O
serves	O
as	O
an	O
easy	O
proof	O
of	O
concept	O
for	O
our	O
method	O
,	O
and	O
contrasting	O
the	O
results	O
in	O
this	O
section	O
with	O
our	O
later	O
experiments	O
gives	O
insights	O
into	O
the	O
behavior	O
of	O
the	O
Adaptive	B-Method
Fastfood	I-Method
transform	I-Method
at	O
different	O
scales	O
.	O
	
As	O
a	O
reference	O
model	O
we	O
use	O
the	O
Caffe	B-Method
implementation	I-Method
of	I-Method
the	I-Method
LeNet	I-Method
convolutional	I-Method
network	I-Method
.	O
	
It	O
achieves	O
an	O
error	B-Metric
rate	I-Metric
of	O
on	O
the	O
MNIST	B-Material
dataset	O
.	O
	
We	O
jointly	O
train	O
all	O
layers	O
of	O
the	O
deep	B-Method
fried	I-Method
network	I-Method
(	O
including	O
convolutional	B-Method
layers	I-Method
)	O
from	O
scratch	O
.	O
	
We	O
compare	O
both	O
the	O
adaptive	B-Method
and	I-Method
non	I-Method
-	I-Method
adaptive	I-Method
Fastfood	I-Method
transforms	I-Method
using	O
1024	O
and	O
2048	O
features	O
.	O
	
For	O
the	O
non	O
-	O
adaptive	B-Method
transforms	I-Method
we	O
report	O
the	O
best	O
performance	O
achieved	O
by	O
varying	O
the	O
standard	O
deviation	O
of	O
the	O
random	O
Gaussian	O
matrix	O
over	O
the	O
set	O
,	O
and	O
for	O
the	O
adaptive	B-Method
variant	I-Method
we	O
learn	O
these	O
parameters	O
by	O
backpropagation	B-Method
as	O
described	O
in	O
Section	O
[	O
reference	O
]	O
.	O
	
The	O
results	O
of	O
the	O
MNIST	B-Material
experiment	O
are	O
shown	O
in	O
Table	O
[	O
reference	O
]	O
.	O
	
Because	O
the	O
width	O
of	O
the	O
deep	B-Method
fried	I-Method
network	I-Method
is	O
substantially	O
larger	O
than	O
the	O
reference	O
model	O
,	O
we	O
also	O
experimented	O
with	O
adding	O
dropout	B-Method
in	O
the	O
model	O
,	O
which	O
increased	O
performance	O
in	O
the	O
deep	B-Task
fried	I-Task
case	I-Task
.	O
	
Deep	B-Method
fried	I-Method
networks	I-Method
are	O
able	O
to	O
obtain	O
high	O
accuracy	B-Metric
using	O
only	O
a	O
small	O
fraction	O
of	O
of	O
parameters	O
of	O
the	O
original	O
network	O
(	O
11	O
times	O
reduction	O
in	O
the	O
best	O
case	O
)	O
.	O
	
Interestingly	O
,	O
we	O
see	O
no	O
benefit	O
from	O
adaptation	B-Method
in	O
this	O
experiment	O
,	O
with	O
the	O
more	O
powerful	O
adaptive	B-Method
models	I-Method
performing	O
equivalently	O
or	O
worse	O
than	O
their	O
non	O
-	O
adaptive	O
counterparts	O
;	O
however	O
,	O
this	O
should	O
be	O
contrasted	O
with	O
the	O
ImageNet	O
results	O
reported	O
in	O
the	O
following	O
sections	O
.	O
	
section	O
:	O
Imagenet	B-Task
Experiments	I-Task
	
We	O
now	O
examine	O
how	O
deep	B-Method
fried	I-Method
networks	I-Method
behave	O
in	O
a	O
more	O
realistic	O
setting	O
with	O
a	O
much	O
larger	O
dataset	O
and	O
many	O
more	O
classes	O
.	O
	
Specifically	O
,	O
we	O
use	O
the	O
ImageNet	B-Material
ILSVRC	I-Material
-	I-Material
2012	I-Material
dataset	I-Material
which	O
has	O
1.2	O
M	O
training	O
examples	O
and	O
50	O
K	O
validation	O
examples	O
distributed	O
across	O
1000	O
classes	O
.	O
	
We	O
use	O
the	O
the	O
Caffe	B-Method
ImageNet	I-Method
model	I-Method
as	O
the	O
reference	B-Method
model	I-Method
in	O
these	O
experiments	O
.	O
	
This	O
model	O
is	O
a	O
modified	O
version	O
of	O
AlexNet	B-Method
,	O
and	O
achieves	O
top	B-Metric
-	I-Metric
1	I-Metric
error	I-Metric
on	O
the	O
ILSVRC	B-Metric
-	I-Metric
2012	I-Metric
validation	I-Metric
set	I-Metric
.	O
	
The	O
initial	O
layers	O
of	O
this	O
model	O
are	O
a	O
cascade	B-Method
of	I-Method
convolution	I-Method
and	I-Method
pooling	I-Method
layers	I-Method
with	O
interspersed	B-Method
normalization	I-Method
.	O
	
The	O
last	O
several	O
layers	O
of	O
the	O
network	O
take	O
the	O
form	O
of	O
an	O
MLP	B-Method
and	O
follow	O
a	O
9216–4096–4096–1000	B-Method
architecture	I-Method
.	O
	
The	O
final	O
layer	O
is	O
a	O
logistic	B-Method
regression	I-Method
layer	I-Method
with	O
1000	O
output	O
classes	O
.	O
	
All	O
layers	O
of	O
this	O
network	O
use	O
the	O
ReLU	B-Method
nonlinearity	O
,	O
and	O
dropout	B-Method
is	O
used	O
in	O
the	O
fully	O
connected	O
layers	O
to	O
prevent	O
overfitting	O
.	O
	
There	O
are	O
total	O
of	O
58	O
,	O
649	O
,	O
184	O
parameters	O
in	O
the	O
reference	O
model	O
,	O
of	O
which	O
58	O
,	O
621	O
,	O
952	O
are	O
in	O
the	O
fully	O
connected	O
layers	O
and	O
only	O
27	O
,	O
232	O
are	O
in	O
the	O
convolutional	B-Method
layers	I-Method
.	O
	
The	O
parameters	O
of	O
fully	B-Method
connected	I-Method
layer	I-Method
take	O
up	O
of	O
the	O
total	O
number	O
of	O
parameters	O
.	O
	
We	O
show	O
that	O
the	O
Adaptive	B-Method
Fastfood	I-Method
transform	I-Method
can	O
be	O
used	O
to	O
substantially	O
reduce	O
the	O
number	O
of	O
parameters	O
in	O
this	O
model	O
.	O
	
subsection	O
:	O
Fixed	B-Method
feature	I-Method
extractor	I-Method
	
Previous	O
work	O
on	O
applying	O
kernel	B-Method
methods	I-Method
to	O
ImageNet	B-Task
has	O
focused	O
on	O
building	O
models	O
on	O
features	O
extracted	O
from	O
the	O
convolutional	B-Method
layers	I-Method
of	O
a	O
pre	B-Method
-	I-Method
trained	I-Method
network	I-Method
.	O
	
This	O
setting	O
is	O
less	O
general	O
than	O
training	O
a	O
network	O
from	O
scratch	O
but	O
does	O
mirror	O
the	O
common	O
use	O
case	O
where	O
a	O
convolutional	B-Method
network	I-Method
is	O
first	O
trained	O
on	O
ImageNet	B-Material
and	O
used	O
as	O
a	O
feature	B-Method
extractor	I-Method
for	O
a	O
different	O
task	O
.	O
	
In	O
order	O
to	O
compare	O
our	O
Adaptive	B-Method
Fastfood	I-Method
transform	I-Method
directly	O
to	O
this	O
previous	O
work	O
,	O
we	O
extract	O
features	O
from	O
the	O
final	O
convolutional	B-Method
layer	I-Method
of	O
a	O
pre	O
-	O
trained	O
reference	B-Method
model	I-Method
and	O
train	O
an	O
Adaptive	B-Method
Fastfood	I-Method
transform	I-Method
classifier	I-Method
using	O
these	O
features	O
.	O
	
Although	O
the	O
reference	O
model	O
uses	O
two	O
fully	O
connected	O
layers	O
,	O
we	O
investigate	O
replacing	O
these	O
with	O
only	O
a	O
single	O
Fastfood	B-Method
transform	I-Method
.	O
	
We	O
experiment	O
with	O
two	O
sizes	O
for	O
this	O
transform	O
:	O
Fastfood	O
16	O
and	O
Fastfood	O
32	O
using	O
16	O
,	O
384	O
and	O
32	O
,	O
768	O
Fastfood	O
features	O
respectively	O
.	O
	
Since	O
the	O
Fastfood	B-Method
transform	I-Method
is	O
a	O
composite	B-Method
module	I-Method
,	O
we	O
can	O
apply	O
dropout	B-Method
between	O
any	O
of	O
its	O
layers	O
.	O
	
In	O
the	O
experiments	O
reported	O
here	O
,	O
we	O
applied	O
dropout	O
after	O
the	O
matrix	O
and	O
after	O
the	O
matrix	O
.	O
	
We	O
also	O
applied	O
dropout	B-Method
to	O
the	O
last	O
convolutional	B-Method
layer	I-Method
(	O
that	O
is	O
,	O
before	O
the	O
matrix	O
)	O
.	O
	
We	O
also	O
train	O
an	O
MLP	B-Method
with	O
the	O
same	O
structure	O
as	O
the	O
top	O
layers	O
of	O
the	O
reference	O
model	O
for	O
comparison	O
.	O
	
In	O
this	O
setting	O
it	O
is	O
important	O
to	O
compare	O
against	O
the	O
re	B-Method
-	I-Method
trained	I-Method
MLP	I-Method
rather	O
than	O
the	O
jointly	B-Method
trained	I-Method
reference	I-Method
model	I-Method
,	O
as	O
training	O
on	O
features	O
extracted	O
from	O
fixed	O
convolutional	O
layers	O
typically	O
leads	O
to	O
lower	O
performance	O
than	O
joint	B-Method
training	I-Method
.	O
	
The	O
results	O
of	O
the	O
fixed	O
feature	O
experiment	O
are	O
shown	O
in	O
Table	O
[	O
reference	O
]	O
.	O
	
Following	O
and	O
we	O
observe	O
that	O
training	O
on	O
ImageNet	O
activations	O
produces	O
significantly	O
lower	O
performance	O
than	O
of	O
the	O
original	O
,	O
jointly	B-Method
trained	I-Method
network	I-Method
.	O
	
Nonetheless	O
,	O
deep	B-Method
fried	I-Method
networks	I-Method
are	O
able	O
to	O
outperform	O
both	O
the	O
re	B-Method
-	I-Method
trained	I-Method
MLP	I-Method
model	I-Method
as	O
well	O
as	O
the	O
results	O
in	O
while	O
using	O
fewer	O
parameters	O
.	O
	
In	O
contrast	O
with	O
our	O
MNIST	B-Material
experiment	O
,	O
here	O
we	O
find	O
that	O
the	O
Adaptive	B-Method
Fastfood	I-Method
transform	I-Method
provides	O
a	O
significant	O
performance	O
boost	O
over	O
the	O
non	O
-	O
adaptive	B-Method
version	I-Method
,	O
improving	O
top	O
-	O
1	O
performance	O
by	O
4.5	O
-	O
6.5	O
%	O
.	O
	
subsection	O
:	O
Jointly	B-Method
trained	I-Method
model	I-Method
	
Finally	O
,	O
we	O
train	O
a	O
deep	B-Method
fried	I-Method
network	I-Method
from	O
scratch	O
on	O
ImageNet	B-Material
.	O
	
With	O
16	O
,	O
384	O
features	O
in	O
the	O
Fastfood	B-Method
layer	I-Method
we	O
lose	O
less	O
than	O
0.3	O
%	O
top	B-Metric
-	I-Metric
1	I-Metric
validation	I-Metric
performance	I-Metric
,	O
but	O
the	O
number	O
of	O
parameters	O
in	O
the	O
network	O
is	O
reduced	O
from	O
58.7	O
M	O
to	O
16.4	O
M	O
which	O
corresponds	O
to	O
a	O
factor	O
of	O
3.6x	O
.	O
	
By	O
further	O
increasing	O
the	O
number	O
of	O
features	O
to	O
32	O
,	O
768	O
,	O
we	O
are	O
able	O
to	O
perform	O
0.6	O
%	O
better	O
than	O
the	O
reference	O
model	O
while	O
using	O
approximately	O
half	O
as	O
many	O
parameters	O
.	O
	
Results	O
from	O
this	O
experiment	O
are	O
shown	O
in	O
Table	O
[	O
reference	O
]	O
.	O
	
Nearly	O
all	O
of	O
the	O
parameters	O
of	O
the	O
deep	B-Method
fried	I-Method
network	I-Method
reside	O
in	O
the	O
final	O
softmax	B-Method
regression	I-Method
layer	I-Method
,	O
which	O
still	O
uses	O
a	O
dense	O
linear	O
transformation	O
,	O
and	O
accounts	O
for	O
more	O
than	O
99	O
%	O
of	O
the	O
parameters	O
of	O
the	O
network	O
.	O
	
This	O
is	O
a	O
side	O
effect	O
of	O
the	O
large	O
number	O
of	O
classes	O
in	O
ImageNet	B-Material
.	O
	
For	O
a	O
data	O
set	O
with	O
fewer	O
classes	O
the	O
advantage	O
of	O
deep	B-Method
fried	I-Method
convolutional	I-Method
networks	I-Method
would	O
be	O
even	O
greater	O
.	O
	
Moreover	O
,	O
as	O
shown	O
by	O
,	O
the	O
last	O
layer	O
often	O
contains	O
considerable	O
redundancy	O
.	O
	
We	O
also	O
note	O
that	O
any	O
of	O
the	O
techniques	O
from	O
could	O
be	O
applied	O
to	O
the	O
final	O
layer	O
of	O
a	O
deep	B-Method
fried	I-Method
network	I-Method
to	O
further	O
reduce	O
memory	B-Metric
consumption	I-Metric
at	O
test	O
time	O
.	O
	
We	O
illustrate	O
this	O
with	O
low	B-Task
-	I-Task
rank	I-Task
matrix	I-Task
factorization	I-Task
in	O
the	O
following	O
section	O
.	O
	
section	O
:	O
Comparison	O
with	O
Post	B-Method
Processing	I-Method
	
In	O
this	O
section	O
we	O
provide	O
a	O
comparison	O
to	O
some	O
existing	O
works	O
on	O
reducing	O
the	O
number	O
of	O
parameters	O
in	O
a	O
convolutional	B-Method
neural	I-Method
network	I-Method
.	O
	
The	O
techniques	O
we	O
compare	O
against	O
here	O
are	O
post	B-Method
-	I-Method
processing	I-Method
techniques	I-Method
,	O
which	O
start	O
from	O
a	O
full	B-Method
trained	I-Method
model	I-Method
and	O
attempt	O
to	O
compress	O
it	O
,	O
whereas	O
our	O
method	O
trains	O
the	O
compressed	B-Method
network	I-Method
from	O
scratch	O
.	O
	
Matrix	B-Method
factorization	I-Method
is	O
the	O
most	O
common	O
method	O
for	O
compressing	B-Task
neural	I-Task
networks	I-Task
,	O
and	O
has	O
proven	O
to	O
be	O
very	O
effective	O
.	O
	
Given	O
the	O
weight	O
matrix	O
of	O
fully	O
connected	O
layers	O
,	O
we	O
factorize	O
it	O
as	O
where	O
and	O
and	O
is	O
a	O
diagonal	O
matrix	O
.	O
	
In	O
order	O
to	O
reduce	O
the	O
parameters	O
,	O
we	O
truncate	O
all	O
but	O
the	O
largest	O
singular	O
values	O
,	O
leading	O
to	O
the	O
approximation	O
where	O
and	O
and	O
has	O
been	O
absorbed	O
into	O
the	O
other	O
two	O
factors	O
.	O
	
If	O
is	O
sufficiently	O
small	O
then	O
storing	O
and	O
is	O
less	O
expensive	O
than	O
storing	O
directly	O
,	O
and	O
this	O
parameterization	O
is	O
still	O
learnable	O
.	O
	
It	O
has	O
been	O
shown	O
that	O
training	O
a	O
factorized	B-Method
representation	I-Method
directly	O
leads	O
to	O
poor	O
performance	O
(	O
although	O
it	O
does	O
work	O
when	O
applied	O
only	O
to	O
the	O
final	O
logistic	B-Method
regression	I-Method
layer	I-Method
)	O
.	O
	
However	O
,	O
first	O
training	O
a	O
full	B-Method
model	I-Method
,	O
then	O
preforming	O
an	O
SVD	B-Method
of	I-Method
the	I-Method
weight	I-Method
matrices	I-Method
followed	O
by	O
a	O
fine	B-Method
tuning	I-Method
phase	I-Method
preserves	O
much	O
of	O
the	O
performance	O
of	O
the	O
original	O
model	O
.	O
	
We	O
compare	O
our	O
deep	B-Method
fried	I-Method
approach	I-Method
to	O
SVD	B-Method
followed	O
by	O
fine	B-Method
tuning	I-Method
,	O
and	O
show	O
that	O
our	O
approach	O
achieves	O
better	O
performance	O
per	O
parameter	O
in	O
spite	O
of	O
training	O
a	O
compressed	O
parameterization	O
from	O
scratch	O
.	O
	
We	O
also	O
compare	O
against	O
a	O
post	O
-	O
processed	O
version	O
of	O
our	O
model	O
,	O
where	O
we	O
train	O
a	O
deep	B-Method
fried	I-Method
convnet	I-Method
and	O
then	O
apply	O
SVD	B-Method
plus	I-Method
fine	I-Method
-	I-Method
tuning	I-Method
to	O
the	O
final	O
softmax	B-Method
layer	I-Method
,	O
which	O
further	O
reduces	O
the	O
number	O
of	O
parameters	O
.	O
	
Results	O
of	O
these	O
post	B-Task
-	I-Task
processing	I-Task
experiments	O
are	O
shown	O
in	O
Table	O
[	O
reference	O
]	O
.	O
	
For	O
the	O
SVD	B-Method
decomposition	I-Method
of	O
each	O
of	O
the	O
three	O
fully	O
connected	O
layers	O
in	O
the	O
reference	B-Method
model	I-Method
we	O
set	O
in	O
SVD	O
-	O
half	O
and	O
in	O
SVD	O
-	O
quarter	O
.	O
	
SVD	B-Method
-	I-Method
half	I-Method
-	I-Method
F	I-Method
and	O
SVD	B-Method
-	I-Method
quarter	I-Method
	
-	O
F	O
mean	O
that	O
the	O
model	O
has	O
been	O
fine	O
tuned	O
after	O
the	O
decomposition	O
.	O
	
There	O
is	O
1	O
%	O
drop	O
in	O
accuracy	B-Metric
for	O
SVD	B-Method
-	O
half	O
and	O
3.5	O
%	O
drop	O
for	O
SVD	B-Method
-	I-Method
quarter	I-Method
.	O
	
Even	O
though	O
the	O
increase	O
in	O
the	O
error	B-Metric
for	O
the	O
SVD	B-Method
can	O
be	O
mitigated	O
by	O
finetuning	O
(	O
the	O
drop	O
decreases	O
to	O
0.1	O
%	O
for	O
SVD	O
-	O
half	O
-	O
F	O
and	O
1.3	O
%	O
for	O
SVD	B-Method
-	I-Method
quarter	I-Method
-	I-Method
F	I-Method
)	O
,	O
deep	B-Method
fried	I-Method
convnets	I-Method
still	O
perform	O
better	O
both	O
in	O
terms	O
of	O
the	O
accuracy	B-Metric
and	O
the	O
number	O
of	O
parameters	O
.	O
	
Applying	O
a	O
rank	B-Method
600	I-Method
SVD	I-Method
followed	O
by	O
fine	B-Method
tuning	I-Method
to	O
the	O
final	O
softmax	B-Method
layer	I-Method
of	O
the	O
Adaptive	B-Method
Fastfood	I-Method
32	I-Method
model	I-Method
removes	O
an	O
additional	O
12.5	O
M	O
parameters	O
at	O
the	O
expense	O
of	O
0.7	O
%	O
top	B-Metric
-	I-Metric
1	I-Metric
error	I-Metric
.	O
	
For	O
reference	O
,	O
we	O
also	O
include	O
the	O
results	O
of	O
Collins	B-Method
and	O
Kohli	B-Method
,	O
who	O
pre	O
-	O
train	O
a	O
full	B-Method
network	I-Method
and	O
use	O
a	O
sparsity	B-Method
regularizer	I-Method
during	O
fine	B-Method
-	I-Method
tuning	I-Method
to	O
encourage	O
connections	O
in	O
the	O
fully	O
connected	O
layers	O
to	O
be	O
zero	O
.	O
	
They	O
are	O
able	O
to	O
achieve	O
a	O
significant	O
reduction	O
in	O
the	O
number	O
of	O
parameters	O
this	O
way	O
,	O
however	O
the	O
performance	O
of	O
their	O
compressed	B-Method
network	I-Method
suffers	O
when	O
compared	O
to	O
the	O
reference	O
model	O
.	O
	
Another	O
drawback	O
of	O
this	O
method	O
is	O
that	O
using	O
sparse	B-Method
weight	I-Method
matrices	I-Method
requires	O
additional	O
overhead	O
to	O
store	O
the	O
indexes	O
of	O
the	O
non	O
-	O
zero	O
values	O
.	O
	
The	O
index	B-Method
storage	I-Method
takes	O
up	O
space	O
and	O
using	O
sparse	B-Method
representation	I-Method
is	O
better	O
than	O
using	O
a	O
dense	O
matrix	O
only	O
when	O
number	O
of	O
nonzero	O
entries	O
is	O
small	O
.	O
	
section	O
:	O
Conclusion	O
	
Many	O
methods	O
have	O
been	O
advanced	O
to	O
reduce	O
the	O
size	O
of	O
convolutional	B-Method
networks	I-Method
at	O
test	O
time	O
.	O
	
In	O
contrast	O
to	O
this	O
trend	O
,	O
the	O
Adaptive	B-Method
Fastfood	I-Method
transform	I-Method
introduced	O
in	O
this	O
paper	O
is	O
end	O
-	O
to	O
-	O
end	O
differentiable	O
and	O
hence	O
it	O
enables	O
us	O
to	O
attain	O
reductions	O
in	O
the	O
number	O
of	O
parameters	O
even	O
at	O
train	O
time	O
.	O
	
Deep	B-Method
fried	I-Method
convnets	I-Method
capitalize	O
on	O
the	O
proposed	O
Adaptive	B-Method
Fastfood	I-Method
transform	I-Method
to	O
achieve	O
a	O
substantial	O
reduction	O
in	O
the	O
number	O
of	O
parameters	O
without	O
sacrificing	O
predictive	B-Metric
performance	I-Metric
on	O
MNIST	B-Material
and	O
ImageNet	B-Material
.	O
	
They	O
also	O
compare	O
favorably	O
against	O
simple	O
test	B-Method
-	I-Method
time	I-Method
low	I-Method
-	I-Method
rank	I-Method
matrix	I-Method
factorization	I-Method
schemes	I-Method
.	O
	
Our	O
experiments	O
have	O
also	O
cast	O
some	O
light	O
on	O
the	O
issue	O
of	O
random	O
versus	O
adaptive	O
weights	O
.	O
	
The	O
structured	B-Method
random	I-Method
transformations	I-Method
developed	O
in	O
the	O
kernel	B-Method
literature	I-Method
perform	O
very	O
well	O
on	O
MNIST	B-Material
without	O
any	O
learning	B-Method
;	O
however	O
,	O
when	O
moving	O
to	O
ImageNet	B-Material
,	O
the	O
benefit	O
of	O
adaptation	B-Task
becomes	O
clear	O
,	O
as	O
it	O
allows	O
us	O
to	O
achieve	O
substantially	O
better	O
performance	O
.	O
	
This	O
is	O
an	O
important	O
point	O
which	O
illustrates	O
the	O
importance	O
of	O
learning	B-Task
which	O
would	O
not	O
have	O
been	O
visible	O
from	O
experiments	O
only	O
on	O
small	O
data	O
sets	O
.	O
	
The	O
Fastfood	B-Method
transform	I-Method
allows	O
for	O
a	O
theoretical	B-Task
reduction	I-Task
in	I-Task
computation	I-Task
from	O
to	O
.	O
	
However	O
,	O
the	O
computation	B-Task
in	O
convolutional	B-Method
neural	I-Method
networks	I-Method
is	O
dominated	O
by	O
the	O
convolutions	B-Method
,	O
and	O
hence	O
deep	B-Method
fried	I-Method
convnets	I-Method
are	O
not	O
necessarily	O
faster	O
in	O
practice	O
.	O
	
It	O
is	O
clear	O
looking	O
at	O
out	O
results	O
on	O
ImageNet	B-Material
in	O
Table	O
2	O
that	O
the	O
remaining	O
parameters	O
are	O
mostly	O
in	O
the	O
output	O
softmax	B-Method
layer	I-Method
.	O
	
The	O
comparative	O
experiment	O
in	O
Section	O
7	O
showed	O
that	O
the	O
matrix	O
of	O
parameters	O
in	O
the	O
softmax	O
can	O
be	O
easily	O
compressed	O
using	O
the	O
SVD	B-Method
,	O
but	O
many	O
other	O
methods	O
could	O
be	O
used	O
to	O
achieve	O
this	O
.	O
	
One	O
avenue	O
for	O
future	O
research	O
involves	O
replacing	O
the	O
softmax	O
matrix	O
,	O
at	O
train	O
and	O
test	O
times	O
,	O
using	O
the	O
abundant	O
set	O
of	O
techniques	O
that	O
have	O
been	O
proposed	O
to	O
solve	O
this	O
problem	O
,	O
including	O
low	B-Method
-	I-Method
rank	I-Method
decomposition	I-Method
,	O
Adaptive	B-Method
Fastfood	I-Method
,	O
and	O
pruning	B-Method
.	O
	
The	O
development	O
of	O
GPU	B-Method
optimized	I-Method
Fastfood	I-Method
transforms	I-Method
that	O
can	O
be	O
used	O
to	O
replace	O
linear	O
layers	O
in	O
arbitrary	B-Method
neural	I-Method
models	I-Method
would	O
also	O
be	O
of	O
great	O
value	O
to	O
the	O
entire	O
research	O
community	O
given	O
the	O
ubiquity	O
of	O
fully	O
connected	O
layers	O
layers	O
.	O
	
bibliography	O
:	O
References	O
	
Strong	O
Baselines	O
for	O
Neural	B-Task
Semi	I-Task
-	I-Task
supervised	I-Task
Learning	I-Task
under	O
Domain	B-Task
Shift	I-Task
	
section	O
:	O
Abstract	O
	
Novel	O
neural	B-Method
models	I-Method
have	O
been	O
proposed	O
in	O
recent	O
years	O
for	O
learning	B-Task
under	I-Task
domain	I-Task
shift	I-Task
.	O
	
Most	O
models	O
,	O
however	O
,	O
only	O
evaluate	O
on	O
a	O
single	O
task	O
,	O
on	O
proprietary	O
datasets	O
,	O
or	O
compare	O
to	O
weak	O
baselines	O
,	O
which	O
makes	O
comparison	O
of	O
models	O
difficult	O
.	O
	
In	O
this	O
paper	O
,	O
we	O
re	O
-	O
evaluate	O
classic	O
general	B-Method
-	I-Method
purpose	I-Method
bootstrapping	I-Method
approaches	I-Method
in	O
the	O
context	O
of	O
neural	B-Method
networks	I-Method
under	O
domain	O
shifts	O
vs.	O
recent	O
neural	B-Method
approaches	I-Method
and	O
propose	O
a	O
novel	O
multi	B-Method
-	I-Method
task	I-Method
tri	I-Method
-	I-Method
training	I-Method
method	I-Method
that	O
reduces	O
the	O
time	B-Metric
and	I-Metric
space	I-Metric
complexity	I-Metric
of	O
classic	O
tri	B-Method
-	I-Method
training	I-Method
.	O
	
Extensive	O
experiments	O
on	O
two	O
benchmarks	O
are	O
negative	O
:	O
while	O
our	O
novel	O
method	O
establishes	O
a	O
new	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
for	O
sentiment	B-Task
analysis	I-Task
,	O
it	O
does	O
not	O
fare	O
consistently	O
the	O
best	O
.	O
	
More	O
importantly	O
,	O
we	O
arrive	O
at	O
the	O
somewhat	O
surprising	O
conclusion	O
that	O
classic	O
tri	B-Method
-	I-Method
training	I-Method
,	O
with	O
some	O
additions	O
,	O
outperforms	O
the	O
state	O
of	O
the	O
art	O
.	O
	
We	O
conclude	O
that	O
classic	O
approaches	O
constitute	O
an	O
important	O
and	O
strong	O
baseline	O
.	O
	
section	O
:	O
Introduction	O
	
Deep	B-Method
neural	I-Method
networks	I-Method
(	O
DNNs	B-Method
)	O
excel	O
at	O
learning	O
from	O
labeled	O
data	O
and	O
have	O
achieved	O
state	O
of	O
the	O
art	O
in	O
a	O
wide	O
array	O
of	O
supervised	B-Task
NLP	I-Task
tasks	I-Task
such	O
as	O
dependency	B-Task
parsing	I-Task
[	O
reference	O
]	O
,	O
named	B-Task
entity	I-Task
recognition	I-Task
[	O
reference	O
]	O
,	O
and	O
semantic	B-Task
role	I-Task
labeling	I-Task
[	O
reference	O
]	O
.	O
	
In	O
contrast	O
,	O
learning	B-Task
from	O
unlabeled	O
data	O
,	O
especially	O
under	O
domain	B-Task
shift	I-Task
,	O
remains	O
a	O
challenge	O
.	O
	
This	O
is	O
common	O
in	O
many	O
real	B-Task
-	I-Task
world	I-Task
applications	I-Task
where	O
the	O
distribution	O
of	O
the	O
training	O
and	O
test	O
data	O
differs	O
.	O
	
Many	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
domain	B-Method
adaptation	I-Method
approaches	I-Method
leverage	O
task	O
-	O
specific	O
characteristics	O
such	O
as	O
sentiment	O
words	O
[	O
reference	O
][	O
reference	O
]	O
or	O
distributional	O
features	O
[	O
reference	O
][	O
reference	O
]	O
which	O
do	O
not	O
generalize	O
to	O
other	O
tasks	O
.	O
	
Other	O
approaches	O
that	O
are	O
in	O
theory	O
more	O
general	O
only	O
evaluate	O
on	O
proprietary	O
datasets	O
[	O
reference	O
]	O
or	O
on	O
a	O
single	O
benchmark	O
[	O
reference	O
]	O
,	O
which	O
carries	O
the	O
risk	O
of	O
overfitting	O
to	O
the	O
task	O
.	O
	
In	O
addition	O
,	O
most	O
models	O
only	O
compare	O
against	O
weak	O
baselines	O
and	O
,	O
strikingly	O
,	O
almost	O
none	O
considers	O
evaluating	O
against	O
approaches	O
from	O
the	O
extensive	O
semi	B-Method
-	I-Method
supervised	I-Method
learning	I-Method
(	O
SSL	B-Method
)	O
literature	O
[	O
reference	O
]	O
.	O
	
In	O
this	O
work	O
,	O
we	O
make	O
the	O
argument	O
that	O
such	O
algorithms	O
make	O
strong	O
baselines	O
for	O
any	O
task	O
in	O
line	O
with	O
recent	O
efforts	O
highlighting	O
the	O
usefulness	O
of	O
classic	O
approaches	O
	
[	O
reference	O
][	O
reference	O
]	O
.	O
We	O
re	O
-	O
evaluate	O
bootstrapping	B-Method
algorithms	I-Method
in	O
the	O
context	O
of	O
DNNs	B-Method
.	O
	
These	O
are	O
general	O
-	O
purpose	O
semi	B-Method
-	I-Method
supervised	I-Method
algorithms	I-Method
that	O
treat	O
the	O
model	O
as	O
a	O
black	O
box	O
and	O
can	O
thus	O
be	O
used	O
easily	O
-	O
with	O
a	O
few	O
additions	O
-	O
with	O
the	O
current	O
generation	O
of	O
NLP	B-Method
models	I-Method
.	O
	
Many	O
of	O
these	O
methods	O
,	O
though	O
,	O
were	O
originally	O
developed	O
with	O
in	O
-	O
domain	O
performance	O
in	O
mind	O
,	O
so	O
their	O
effectiveness	O
in	O
a	O
domain	B-Task
adaptation	I-Task
setting	I-Task
remains	O
unexplored	O
.	O
	
In	O
particular	O
,	O
we	O
re	O
-	O
evaluate	O
three	O
traditional	O
bootstrapping	B-Method
methods	I-Method
,	O
self	B-Method
-	I-Method
training	I-Method
[	O
reference	O
]	O
,	O
tri	B-Method
-	I-Method
training	I-Method
[	O
reference	O
]	O
,	O
and	O
tritraining	B-Method
with	O
disagreement	B-Method
[	O
reference	O
]	O
for	O
neural	B-Method
network	I-Method
-	I-Method
based	I-Method
approaches	I-Method
on	O
two	O
NLP	B-Task
tasks	I-Task
with	O
different	O
characteristics	O
,	O
namely	O
,	O
a	O
sequence	B-Task
prediction	I-Task
and	O
a	O
classification	B-Task
task	I-Task
(	O
POS	B-Task
tagging	I-Task
and	O
sentiment	B-Task
analysis	I-Task
)	O
.	O
	
We	O
evaluate	O
the	O
methods	O
across	O
multiple	O
domains	O
on	O
two	O
wellestablished	O
benchmarks	O
,	O
without	O
taking	O
any	O
further	O
task	B-Metric
-	I-Metric
specific	I-Metric
measures	I-Metric
,	O
and	O
compare	O
to	O
the	O
best	O
results	O
published	O
in	O
the	O
literature	O
.	O
	
We	O
make	O
the	O
somewhat	O
surprising	O
observation	O
that	O
classic	O
tri	B-Method
-	I-Method
training	I-Method
outperforms	O
task	O
-	O
agnostic	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
semi	B-Method
-	I-Method
supervised	I-Method
learning	I-Method
[	O
reference	O
]	O
and	O
recent	O
neural	B-Method
adaptation	I-Method
approaches	I-Method
	
[	O
reference	O
][	O
reference	O
]	O
.	O
	
In	O
addition	O
,	O
we	O
propose	O
multi	B-Method
-	I-Method
task	I-Method
tri	I-Method
-	I-Method
training	I-Method
,	O
which	O
reduces	O
the	O
main	O
deficiency	O
of	O
tri	B-Method
-	I-Method
training	I-Method
,	O
namely	O
its	O
time	B-Metric
and	I-Metric
space	I-Metric
complexity	I-Metric
.	O
	
It	O
establishes	O
a	O
new	O
state	O
of	O
the	O
art	O
on	O
unsupervised	B-Task
domain	I-Task
adaptation	I-Task
for	O
sentiment	B-Task
analysis	I-Task
but	O
it	O
is	O
outperformed	O
by	O
classic	O
tri	B-Method
-	I-Method
training	I-Method
for	O
POS	B-Task
tagging	I-Task
.	O
	
Contributions	O
Our	O
contributions	O
are	O
:	O
a	O
)	O
	
We	O
propose	O
a	O
novel	O
multi	B-Method
-	I-Method
task	I-Method
tri	I-Method
-	I-Method
training	I-Method
method	I-Method
.	O
	
b	O
)	O
	
We	O
show	O
that	O
tri	B-Method
-	I-Method
training	I-Method
can	O
serve	O
as	O
a	O
strong	O
and	O
robust	O
semi	B-Method
-	I-Method
supervised	I-Method
learning	I-Method
baseline	I-Method
for	O
the	O
current	O
generation	O
of	O
NLP	B-Method
models	I-Method
.	O
	
c	O
)	O
	
We	O
perform	O
an	O
extensive	O
evaluation	O
of	O
bootstrapping	B-Method
1	I-Method
algorithms	I-Method
compared	O
to	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
approaches	O
on	O
two	O
benchmark	O
datasets	O
.	O
	
d	O
)	O
	
We	O
shed	O
light	O
on	O
the	O
task	O
and	O
data	O
characteristics	O
that	O
yield	O
the	O
best	O
performance	O
for	O
each	O
model	O
.	O
	
section	O
:	O
Neural	B-Method
bootstrapping	I-Method
methods	I-Method
	
We	O
first	O
introduce	O
three	O
classic	O
bootstrapping	B-Method
methods	I-Method
,	O
self	B-Method
-	I-Method
training	I-Method
,	O
tri	B-Method
-	I-Method
training	I-Method
,	O
and	O
tri	B-Method
-	I-Method
training	I-Method
with	O
disagreement	B-Method
and	O
detail	O
how	O
they	O
can	O
be	O
used	O
with	O
neural	B-Method
networks	I-Method
.	O
	
For	O
in	O
-	O
depth	O
details	O
we	O
refer	O
the	O
reader	O
to	O
[	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
)	O
.	O
	
We	O
introduce	O
our	O
novel	O
multitask	O
tri	B-Method
-	I-Method
training	I-Method
method	O
in	O
§	O
2.3	O
.	O
	
section	O
:	O
Self	B-Method
-	I-Method
training	I-Method
	
Self	B-Method
-	I-Method
training	I-Method
[	O
reference	O
][	O
reference	O
]	O
)	O
is	O
one	O
of	O
the	O
earliest	O
and	O
simplest	O
bootstrapping	B-Method
approaches	I-Method
.	O
	
In	O
essence	O
,	O
it	O
leverages	O
the	O
model	O
's	O
own	O
predictions	O
on	O
unlabeled	O
data	O
to	O
obtain	O
additional	O
information	O
that	O
can	O
be	O
used	O
during	O
training	B-Task
.	O
	
Typically	O
the	O
most	O
confident	O
predictions	O
are	O
taken	O
at	O
face	O
value	O
,	O
as	O
detailed	O
next	O
.	O
	
Self	B-Method
-	I-Method
training	I-Method
trains	O
a	O
model	B-Method
m	I-Method
on	O
a	O
labeled	O
training	O
set	O
L	O
and	O
an	O
unlabeled	O
data	O
set	O
U	O
.	O
	
At	O
each	O
iteration	O
,	O
the	O
model	O
provides	O
predictions	O
m	O
(	O
x	O
)	O
in	O
the	O
form	O
of	O
a	O
probability	O
distribution	O
over	O
classes	O
for	O
all	O
unlabeled	O
examples	O
x	O
in	O
U	O
.	O
	
If	O
the	O
probability	O
assigned	O
to	O
the	O
most	O
likely	O
class	O
is	O
higher	O
than	O
a	O
predetermined	O
threshold	O
τ	O
,	O
x	O
is	O
added	O
to	O
the	O
labeled	O
examples	O
with	O
p	O
(	O
x	O
)	O
=	O
arg	O
max	O
m	O
(	O
x	O
)	O
as	O
pseudo	O
-	O
label	O
.	O
	
This	O
instantiation	O
is	O
the	O
most	O
widely	O
used	O
and	O
shown	O
in	O
Algorithm	O
1	O
.	O
	
Calibration	B-Task
	
It	O
is	O
well	O
-	O
known	O
that	O
output	O
probabilities	O
in	O
neural	B-Method
networks	I-Method
are	O
poorly	O
calibrated	O
[	O
reference	O
]	O
.	O
Using	O
a	O
fixed	O
threshold	O
τ	O
is	O
thus	O
Algorithm	O
1	O
Self	B-Method
-	I-Method
training	I-Method
[	O
reference	O
]	O
	
L	O
←	O
L	O
∪	O
{	O
(	O
x	O
,	O
p	O
(	O
x	O
)	O
)	O
}	O
6	O
:	O
until	O
no	O
more	O
predictions	O
are	O
confident	O
not	O
the	O
best	O
choice	O
.	O
	
While	O
the	O
absolute	B-Metric
confidence	I-Metric
value	I-Metric
is	O
inaccurate	O
,	O
we	O
can	O
expect	O
that	O
the	O
relative	O
order	O
of	O
confidences	O
is	O
more	O
robust	O
.	O
	
For	O
this	O
reason	O
,	O
we	O
select	O
the	O
top	O
n	O
unlabeled	O
examples	O
that	O
have	O
been	O
predicted	O
with	O
the	O
highest	O
confidence	O
after	O
every	O
epoch	O
and	O
add	O
them	O
to	O
the	O
labeled	O
data	O
.	O
	
This	O
is	O
one	O
of	O
the	O
many	O
variants	O
for	O
self	B-Method
-	I-Method
training	I-Method
,	O
called	O
throttling	B-Task
	
[	O
reference	O
]	O
.	O
We	O
empirically	O
confirm	O
that	O
this	O
outperforms	O
the	O
classic	O
selection	B-Method
in	O
our	O
experiments	O
.	O
	
Online	B-Method
learning	I-Method
In	O
contrast	O
to	O
many	O
classic	O
algorithms	O
,	O
DNNs	B-Method
are	O
trained	O
online	O
by	O
default	O
.	O
	
We	O
compare	O
training	O
setups	O
and	O
find	O
that	O
training	O
until	O
convergence	O
on	O
labeled	O
data	O
and	O
then	O
training	O
until	O
convergence	O
using	O
self	B-Method
-	I-Method
training	I-Method
performs	O
best	O
.	O
	
Classic	O
self	B-Method
-	I-Method
training	I-Method
has	O
shown	O
mixed	O
success	O
.	O
	
In	O
parsing	B-Task
it	O
proved	O
successful	O
only	O
with	O
small	O
datasets	O
[	O
reference	O
]	O
or	O
when	O
a	O
generative	B-Method
component	I-Method
is	O
used	O
together	O
with	O
a	O
reranker	B-Method
in	O
high	B-Task
-	I-Task
data	I-Task
conditions	I-Task
	
[	O
reference	O
][	O
reference	O
]	O
.	O
Some	O
success	O
was	O
achieved	O
with	O
careful	O
task	O
-	O
specific	O
data	B-Task
selection	I-Task
[	O
reference	O
]	O
,	O
while	O
others	O
report	O
limited	O
success	O
on	O
a	O
variety	O
of	O
NLP	B-Task
tasks	I-Task
[	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
.	O
Its	O
main	O
downside	O
is	O
that	O
the	O
model	O
is	O
not	O
able	O
to	O
correct	O
its	O
own	O
mistakes	O
and	O
errors	O
are	O
amplified	O
,	O
an	O
effect	O
that	O
is	O
increased	O
under	O
domain	O
shift	O
.	O
	
section	O
:	O
Tri	B-Method
-	I-Method
training	I-Method
	
Tri	B-Method
-	I-Method
training	I-Method
[	O
reference	O
]	O
)	O
is	O
a	O
classic	O
method	O
that	O
reduces	O
the	O
bias	O
of	O
predictions	O
on	O
unlabeled	O
data	O
by	O
utilizing	O
the	O
agreement	O
of	O
three	O
independently	O
trained	B-Method
models	I-Method
.	O
	
Tri	B-Method
-	I-Method
training	I-Method
(	O
cf	O
.	O
	
Algorithm	O
2	O
)	O
first	O
trains	O
three	O
models	O
m	O
1	O
,	O
m	O
2	O
,	O
and	O
m	O
3	O
on	O
bootstrap	O
samples	O
of	O
the	O
labeled	O
data	O
	
L.	O
An	O
unlabeled	O
data	O
point	O
is	O
added	O
to	O
the	O
training	O
set	O
of	O
a	O
model	O
m	O
	
i	O
if	O
the	O
other	O
two	O
models	O
m	O
j	O
and	O
m	O
k	O
agree	O
on	O
its	O
label	O
.	O
	
Training	O
stops	O
when	O
the	O
classifiers	B-Method
do	O
not	O
change	O
anymore	O
.	O
	
Tri	B-Method
-	I-Method
training	I-Method
with	O
disagreement	O
[	O
reference	O
]	O
	
Algorithm	O
2	O
Tri	B-Method
-	I-Method
training	I-Method
[	O
reference	O
]	O
	
1	O
:	O
for	O
i	O
∈	O
{	O
1	O
..	O
3	O
}	O
do	O
2	O
:	O
	
for	O
i	O
∈	O
{	O
1	O
..	O
3	O
}	O
do	O
6	O
:	O
	
for	O
x	O
∈	O
U	O
do	O
8	O
:	O
	
10	O
:	O
until	O
none	O
of	O
m	O
i	O
changes	O
11	O
:	O
apply	O
majority	O
vote	O
over	O
m	O
i	O
is	O
based	O
on	O
the	O
intuition	O
that	O
a	O
model	O
should	O
only	O
be	O
strengthened	O
in	O
its	O
weak	O
points	O
and	O
that	O
the	O
labeled	O
data	O
should	O
not	O
be	O
skewed	O
by	O
easy	O
data	O
points	O
.	O
	
In	O
order	O
to	O
achieve	O
this	O
,	O
it	O
adds	O
a	O
simple	O
modification	O
to	O
the	O
original	O
algorithm	O
(	O
altering	O
line	O
8	O
in	O
Algorithm	O
2	O
)	O
,	O
requiring	O
that	O
for	O
an	O
unlabeled	O
data	O
point	O
on	O
which	O
m	O
j	O
and	O
m	O
k	O
agree	O
,	O
	
the	O
other	O
model	O
	
m	O
i	O
disagrees	O
on	O
the	O
prediction	O
.	O
	
Tri	B-Method
-	I-Method
training	I-Method
with	O
disagreement	B-Method
is	O
more	O
data	O
-	O
efficient	O
than	O
tritraining	B-Method
and	O
has	O
achieved	O
competitive	O
results	O
on	O
part	B-Task
-	I-Task
of	I-Task
-	I-Task
speech	I-Task
tagging	I-Task
[	O
reference	O
]	O
.	O
	
Sampling	O
unlabeled	O
data	O
Both	O
tri	B-Method
-	I-Method
training	I-Method
and	O
tri	B-Method
-	I-Method
training	I-Method
with	O
disagreement	B-Task
can	O
be	O
very	O
expensive	O
in	O
their	O
original	O
formulation	O
as	O
they	O
require	O
to	O
produce	O
predictions	O
for	O
each	O
of	O
the	O
three	O
models	O
on	O
all	O
unlabeled	O
data	O
samples	O
,	O
which	O
can	O
be	O
in	O
the	O
millions	O
in	O
realistic	O
applications	O
.	O
	
We	O
thus	O
propose	O
to	O
sample	O
a	O
number	O
of	O
unlabeled	O
examples	O
at	O
every	O
epoch	O
.	O
	
For	O
all	O
traditional	O
bootstrapping	B-Method
approaches	I-Method
we	O
sample	O
10k	O
candidate	O
instances	O
in	O
each	O
epoch	O
.	O
	
For	O
the	O
neural	B-Method
approaches	I-Method
we	O
use	O
a	O
linearly	B-Method
growing	I-Method
candidate	I-Method
sampling	I-Method
scheme	I-Method
proposed	O
by	O
[	O
reference	O
]	O
,	O
increasing	O
the	O
candidate	O
pool	O
size	O
as	O
the	O
models	O
become	O
more	O
accurate	O
.	O
	
Confidence	B-Method
thresholding	I-Method
Similar	O
to	O
selftraining	B-Method
,	O
we	O
can	O
introduce	O
an	O
additional	O
requirement	O
that	O
pseudo	O
-	O
labeled	O
examples	O
are	O
only	O
added	O
if	O
the	O
probability	O
of	O
the	O
prediction	O
of	O
at	O
least	O
one	O
model	O
is	O
higher	O
than	O
some	O
threshold	O
τ	O
.	O
	
We	O
did	O
not	O
find	O
this	O
to	O
outperform	O
prediction	B-Task
without	O
threshold	O
for	O
traditional	O
tri	B-Method
-	I-Method
training	I-Method
,	O
but	O
thresholding	B-Method
proved	O
essential	O
for	O
our	O
method	O
(	O
§	O
2.3	O
)	O
.	O
	
The	O
most	O
important	O
condition	O
for	O
tri	B-Method
-	I-Method
training	I-Method
and	O
tri	B-Method
-	I-Method
training	I-Method
with	O
disagreement	O
is	O
that	O
the	O
models	O
are	O
diverse	O
.	O
	
Typically	O
,	O
bootstrap	O
samples	O
are	O
used	O
to	O
create	O
this	O
diversity	O
[	O
reference	O
][	O
reference	O
]	O
.	O
	
However	O
,	O
training	O
separate	O
models	O
on	O
bootstrap	O
samples	O
of	O
a	O
potentially	O
large	O
amount	O
of	O
training	O
data	O
is	O
expensive	O
and	O
takes	O
a	O
lot	O
of	O
time	O
.	O
	
This	O
drawback	O
motivates	O
our	O
approach	O
.	O
	
section	O
:	O
Multi	O
-	O
task	O
tri	B-Method
-	I-Method
training	I-Method
	
In	O
order	O
to	O
reduce	O
both	O
the	O
time	B-Metric
and	I-Metric
space	I-Metric
complexity	I-Metric
of	O
tri	B-Method
-	I-Method
training	I-Method
,	O
we	O
propose	O
Multi	O
-	O
task	O
Tritraining	B-Method
(	O
MT	O
-	O
Tri	B-Method
)	O
.	O
	
MT	O
-	O
Tri	B-Method
leverages	O
insights	O
from	O
multi	B-Task
-	I-Task
task	I-Task
learning	I-Task
(	O
MTL	B-Task
)	O
[	O
reference	O
]	O
to	O
share	O
knowledge	O
across	O
models	O
and	O
accelerate	O
training	B-Task
.	O
	
Rather	O
than	O
storing	O
and	O
training	O
each	O
model	O
separately	O
,	O
we	O
propose	O
to	O
share	O
the	O
parameters	O
of	O
the	O
models	O
and	O
train	O
them	O
jointly	O
using	O
MTL	B-Task
.	O
	
2	O
	
All	O
models	O
thus	O
collaborate	O
on	O
learning	O
a	O
joint	B-Method
representation	I-Method
,	O
which	O
improves	O
convergence	B-Task
.	O
	
The	O
output	O
softmax	O
layers	O
are	O
model	O
-	O
specific	O
and	O
are	O
only	O
updated	O
for	O
the	O
input	O
of	O
the	O
respective	O
model	O
.	O
	
We	O
show	O
the	O
model	O
in	O
Figure	O
1	O
(	O
as	O
instantiated	O
for	O
POS	B-Task
tagging	I-Task
)	O
.	O
	
As	O
the	O
models	O
leverage	O
a	O
joint	B-Method
representation	I-Method
,	O
we	O
need	O
to	O
ensure	O
that	O
the	O
features	O
used	O
for	O
prediction	B-Task
in	O
the	O
softmax	O
layers	O
of	O
the	O
different	O
models	O
are	O
as	O
diverse	O
as	O
possible	O
,	O
so	O
that	O
the	O
models	O
can	O
still	O
learn	O
from	O
each	O
other	O
's	O
predictions	O
.	O
	
In	O
contrast	O
,	O
if	O
the	O
parameters	O
in	O
all	O
output	O
softmax	O
layers	O
were	O
the	O
same	O
,	O
the	O
method	O
would	O
degenerate	O
to	O
self	B-Method
-	I-Method
training	I-Method
.	O
	
To	O
guarantee	O
diversity	O
,	O
we	O
introduce	O
an	O
orthogonality	O
constraint	O
[	O
reference	O
]	O
as	O
an	O
additional	O
loss	O
term	O
,	O
which	O
we	O
define	O
as	O
follows	O
:	O
	
where	O
|	O
·	O
2	O
F	O
is	O
the	O
squared	O
Frobenius	O
norm	O
and	O
	
W	O
m	O
1	O
and	O
W	O
m	O
2	O
are	O
the	O
softmax	O
output	O
parameters	O
of	O
the	O
two	O
source	O
and	O
	
pseudo	O
-	O
labeled	O
output	O
layers	O
m	O
1	O
and	O
m	O
2	O
,	O
respectively	O
.	O
	
The	O
orthogonality	O
constraint	O
encourages	O
the	O
models	O
not	O
to	O
rely	O
on	O
the	O
same	O
features	O
for	O
prediction	B-Task
.	O
	
As	O
enforcing	O
pairwise	O
orthogonality	O
between	O
three	O
matrices	O
is	O
not	O
possible	O
,	O
we	O
only	O
enforce	O
orthogonality	O
between	O
the	O
softmax	O
output	O
layers	O
of	O
m	O
1	O
and	O
m	O
2	O
,	O
3	O
while	O
m	O
3	O
is	O
gradually	O
trained	O
to	O
be	O
more	O
target	O
-	O
specific	O
.	O
	
We	O
parameterize	O
L	O
orth	O
by	O
γ=0.01	O
following	O
.	O
	
We	O
do	O
not	O
further	O
tune	O
γ	O
.	O
	
More	O
formally	O
,	O
let	O
us	O
illustrate	O
the	O
model	O
by	O
taking	O
the	O
sequence	B-Task
prediction	I-Task
task	I-Task
(	O
Figure	O
1	O
)	O
as	O
illustration	O
.	O
	
Given	O
an	O
utterance	O
with	O
labels	O
y	O
1	O
,	O
..	O
,	O
y	O
n	O
,	O
our	O
Multi	O
-	O
task	O
Tri	B-Method
-	O
training	O
loss	O
consists	O
of	O
three	O
task	O
-	O
specific	O
(	O
m	O
1	O
,	O
m	O
2	O
,	O
m	O
3	O
)	O
tagging	O
loss	O
functions	O
(	O
where	O
h	O
is	O
the	O
uppermost	B-Method
Bi	I-Method
-	I-Method
LSTM	I-Method
encoding	I-Method
)	O
:	O
	
In	O
contrast	O
to	O
classic	O
tri	B-Method
-	I-Method
training	I-Method
,	O
we	O
can	O
train	O
the	O
multi	B-Method
-	I-Method
task	I-Method
model	I-Method
with	O
its	O
three	O
model	O
-	O
specific	O
outputs	O
jointly	O
and	O
without	O
bootstrap	B-Method
sampling	I-Method
on	O
the	O
labeled	O
source	O
domain	O
data	O
until	O
convergence	O
,	O
as	O
the	O
orthogonality	O
constraint	O
enforces	O
different	O
representations	O
between	O
models	O
m	O
1	O
and	O
m	O
2	O
.	O
	
From	O
this	O
point	O
,	O
we	O
can	O
leverage	O
the	O
pair	O
-	O
wise	O
agreement	O
of	O
two	O
output	B-Method
layers	I-Method
to	O
add	O
pseudo	O
-	O
labeled	O
examples	O
as	O
training	O
data	O
to	O
the	O
third	O
model	O
.	O
	
We	O
train	O
the	O
third	O
output	O
layer	O
m	O
3	O
only	O
on	O
pseudo	O
-	O
labeled	O
target	O
instances	O
in	O
order	O
to	O
make	O
tri	B-Method
-	I-Method
training	I-Method
more	O
robust	O
to	O
a	O
domain	O
shift	O
.	O
	
For	O
the	O
final	O
prediction	B-Task
,	O
majority	B-Method
voting	I-Method
of	O
all	O
three	O
output	O
layers	O
is	O
used	O
,	O
which	O
resulted	O
in	O
the	O
best	O
instantiation	O
,	O
together	O
with	O
confidence	B-Method
thresholding	I-Method
(	O
τ	O
=	O
0.9	O
,	O
except	O
for	O
highresource	O
POS	O
where	O
τ	O
=	O
0.8	O
performed	O
slightly	O
better	O
)	O
.	O
	
We	O
also	O
experimented	O
with	O
using	O
a	O
domainadversarial	O
loss	O
[	O
reference	O
]	O
on	O
the	O
jointly	O
learned	O
representation	O
,	O
but	O
found	O
this	O
not	O
to	O
help	O
.	O
	
The	O
full	O
pseudo	O
-	O
code	O
is	O
given	O
in	O
Algorithm	O
3	O
.	O
	
Computational	B-Metric
complexity	I-Metric
	
The	O
motivation	O
for	O
MT	O
-	O
Tri	B-Method
was	O
to	O
reduce	O
the	O
space	B-Metric
and	I-Metric
time	I-Metric
complexity	I-Metric
of	O
tri	B-Method
-	I-Method
training	I-Method
.	O
	
We	O
thus	O
give	O
an	O
estimate	O
of	O
its	O
efficiency	O
gains	O
.	O
	
MT	O
-	O
Tri	B-Method
is~3×	O
more	O
spaceefficient	O
than	O
regular	B-Method
tri	I-Method
-	I-Method
training	I-Method
;	O
tri	B-Method
-	I-Method
training	I-Method
stores	O
one	O
set	O
of	O
parameters	O
for	O
each	O
of	O
the	O
three	O
models	O
,	O
while	O
MT	O
-	O
Tri	B-Method
only	O
stores	O
one	O
set	O
of	O
parameters	O
(	O
we	O
use	O
three	O
output	O
layers	O
,	O
but	O
these	O
make	O
up	O
a	O
comparatively	O
small	O
part	O
of	O
the	O
total	O
parameter	O
budget	O
)	O
.	O
	
In	O
terms	O
of	O
time	B-Metric
efficiency	I-Metric
,	O
tri	B-Method
-	I-Method
training	I-Method
first	I-Method
[	O
reference	O
]	O
	
We	O
also	O
tried	O
enforcing	O
orthogonality	O
on	O
a	O
hidden	O
layer	O
rather	O
than	O
the	O
output	O
layer	O
,	O
but	O
this	O
did	O
not	O
help	O
.	O
	
10	O
:	O
until	O
end	O
condition	O
is	O
met	O
11	O
:	O
apply	O
majority	B-Method
vote	I-Method
over	O
m	O
i	O
requires	O
to	O
train	O
each	O
of	O
the	O
models	O
from	O
scratch	O
.	O
	
The	O
actual	O
tri	B-Method
-	I-Method
training	I-Method
takes	O
about	O
the	O
same	O
time	O
as	O
training	O
from	O
scratch	O
and	O
requires	O
a	O
separate	O
forward	B-Method
pass	I-Method
for	O
each	O
model	O
,	O
effectively	O
training	O
three	O
independent	O
models	O
simultaneously	O
.	O
	
In	O
contrast	O
,	O
MT	O
-	O
Tri	B-Method
only	O
necessitates	O
one	O
forward	B-Method
pass	I-Method
as	O
well	O
as	O
the	O
evaluation	O
of	O
the	O
two	O
additional	O
output	O
layers	O
(	O
which	O
takes	O
a	O
negligible	O
amount	O
of	O
time	O
)	O
and	O
requires	O
about	O
as	O
many	O
epochs	O
as	O
tri	B-Method
-	I-Method
training	I-Method
until	O
convergence	O
(	O
see	O
Table	O
3	O
,	O
second	O
column	O
)	O
while	O
adding	O
fewer	O
unlabeled	O
examples	O
per	O
epoch	O
(	O
see	O
Section	O
3.4	O
)	O
.	O
	
In	O
our	O
experiments	O
,	O
MT	O
-	O
Tri	B-Method
trained	O
about	O
5	O
-	O
6×	O
faster	O
than	O
traditional	O
tri	B-Method
-	I-Method
training	I-Method
.	O
	
MT	O
-	O
Tri	B-Method
can	O
be	O
seen	O
as	O
a	O
self	B-Method
-	I-Method
ensembling	I-Method
technique	I-Method
,	O
where	O
different	O
variations	O
of	O
a	O
model	O
are	O
used	O
to	O
create	O
a	O
stronger	O
ensemble	B-Task
prediction	I-Task
.	O
	
Recent	O
approaches	O
in	O
this	O
line	O
are	O
snapshot	O
ensembling	B-Method
)	O
that	O
ensembles	O
models	O
converged	O
to	O
different	O
minima	O
during	O
a	O
training	O
run	O
,	O
asymmetric	O
tri	B-Method
-	I-Method
training	I-Method
[	O
reference	O
]	O
)	O
	
(	O
ASYM	O
)	O
	
that	O
leverages	O
agreement	O
on	O
two	O
models	O
as	O
information	O
for	O
the	O
third	O
,	O
and	O
temporal	B-Method
ensembling	I-Method
[	O
reference	O
]	O
,	O
which	O
ensembles	O
predictions	O
of	O
a	O
model	O
at	O
different	O
epochs	O
.	O
	
We	O
tried	O
to	O
compare	O
to	O
temporal	B-Method
ensembling	I-Method
in	O
our	O
experiments	O
,	O
but	O
were	O
not	O
able	O
to	O
obtain	O
consistent	O
results	O
.	O
	
[	O
reference	O
]	O
	
We	O
compare	O
to	O
the	O
closest	O
most	O
recent	O
method	O
,	O
asymmetric	B-Method
tritraining	I-Method
[	O
reference	O
]	O
.	O
	
It	O
differs	O
from	O
ours	O
in	O
two	O
aspects	O
:	O
	
a	O
)	O
ASYM	B-Method
leverages	O
only	O
pseudolabels	O
from	O
data	O
points	O
on	O
which	O
m	O
1	O
and	O
m	O
2	O
agree	O
,	O
and	O
b	O
)	O
it	O
uses	O
only	O
one	O
task	O
(	O
m	O
3	O
)	O
as	O
final	O
predictor	O
.	O
	
In	O
essence	O
,	O
our	O
formulation	O
of	O
MT	O
-	O
Tri	B-Method
is	O
closer	O
to	O
the	O
original	O
tri	B-Method
-	I-Method
training	I-Method
formulation	I-Method
(	O
agreements	O
on	O
two	O
provide	O
pseudo	O
-	O
labels	O
to	O
the	O
third	O
)	O
thereby	O
incorporating	O
more	O
diversity	O
.	O
	
[	O
reference	O
]	O
for	O
POS	B-Task
tagging	I-Task
(	O
above	O
)	O
and	O
the	O
Amazon	B-Material
Reviews	I-Material
dataset	I-Material
[	O
reference	O
]	O
for	O
sentiment	B-Task
analysis	I-Task
(	O
below	O
)	O
.	O
	
section	O
:	O
Experiments	O
	
In	O
order	O
to	O
ascertain	O
which	O
methods	O
are	O
robust	O
across	O
different	O
domains	O
,	O
we	O
evaluate	O
on	O
two	O
widely	O
used	O
unsupervised	O
domain	O
adaptation	O
datasets	O
for	O
two	O
tasks	O
,	O
a	O
sequence	B-Task
labeling	I-Task
and	O
a	O
classification	B-Task
task	I-Task
,	O
cf	O
.	O
	
Table	O
1	O
for	O
data	O
statistics	O
.	O
	
section	O
:	O
POS	B-Task
tagging	I-Task
	
For	O
POS	B-Task
tagging	I-Task
we	O
use	O
the	O
SANCL	B-Material
2012	I-Material
shared	I-Material
task	I-Material
dataset	I-Material
[	O
reference	O
]	O
and	O
compare	O
to	O
the	O
top	O
results	O
in	O
both	O
low	O
and	O
high	O
-	O
data	O
conditions	O
	
[	O
reference	O
][	O
reference	O
]	O
.	O
	
Both	O
are	O
strong	O
baselines	O
,	O
as	O
the	O
FLORS	B-Method
tagger	I-Method
has	O
been	O
developed	O
for	O
this	O
challenging	O
dataset	O
and	O
it	O
is	O
based	O
on	O
contextual	O
distributional	O
features	O
(	O
excluding	O
the	O
word	O
's	O
identity	O
)	O
,	O
and	O
hand	O
-	O
crafted	O
suffix	O
and	O
shape	O
features	O
(	O
including	O
some	O
languagespecific	O
morphological	O
features	O
)	O
.	O
	
We	O
want	O
to	O
gauge	O
to	O
what	O
extent	O
we	O
can	O
adopt	O
a	O
nowadays	O
fairly	O
standard	O
(	O
but	O
more	O
lexicalized	O
)	O
general	O
neural	B-Method
tagger	I-Method
.	O
	
Our	O
POS	B-Method
tagging	I-Method
model	I-Method
is	O
a	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
Bi	B-Method
-	I-Method
LSTM	I-Method
tagger	I-Method
[	O
reference	O
]	O
with	O
word	O
and	O
100	O
-	O
dim	O
character	O
embeddings	O
.	O
	
Word	O
embeddings	O
are	O
initialized	O
with	O
the	O
100	O
-	O
dim	O
Glove	O
embeddings	O
[	O
reference	O
]	O
.	O
The	O
BiLSTM	B-Method
has	O
one	O
hidden	B-Method
layer	I-Method
with	O
100	O
dimensions	O
.	O
	
The	O
base	O
POS	B-Method
model	I-Method
is	O
trained	O
on	O
WSJ	B-Material
with	O
early	B-Task
stopping	I-Task
on	O
the	O
WSJ	B-Material
development	I-Material
set	I-Material
,	O
using	O
patience	O
2	O
,	O
Gaussian	O
noise	O
with	O
σ	O
=	O
0.2	O
and	O
word	B-Method
dropout	I-Method
with	O
p	O
=	O
0.25	O
	
[	O
reference	O
]	O
.	O
	
Regarding	O
data	O
,	O
the	O
source	O
domain	O
is	O
the	O
Ontonotes	B-Material
4.0	I-Material
release	I-Material
of	O
the	O
Penn	B-Material
treebank	I-Material
Wall	I-Material
Street	I-Material
Journal	I-Material
(	O
WSJ	B-Material
)	O
annotated	O
for	O
48	O
fine	O
-	O
grained	O
POS	O
tags	O
.	O
	
This	O
amounts	O
to	O
30	O
,	O
060	O
labeled	O
sentences	O
.	O
	
We	O
use	O
100	O
,	O
000	O
WSJ	B-Material
sentences	O
from	O
1988	O
as	O
unlabeled	O
data	O
,	O
following	O
[	O
reference	O
]	O
.	O
[	O
reference	O
]	O
	
As	O
target	O
data	O
,	O
we	O
use	O
the	O
five	O
SANCL	B-Material
domains	I-Material
(	O
answers	O
,	O
emails	O
,	O
newsgroups	O
,	O
reviews	O
,	O
weblogs	O
)	O
.	O
	
We	O
restrict	O
the	O
amount	O
of	O
unlabeled	O
data	O
for	O
each	O
SANCL	B-Material
domain	I-Material
to	O
the	O
first	O
100k	O
sentences	O
,	O
and	O
do	O
not	O
do	O
any	O
pre	O
-	O
processing	O
.	O
	
We	O
consider	O
the	O
development	O
set	O
of	O
ANSWERS	O
as	O
our	O
only	O
target	O
dev	O
set	O
to	O
set	O
hyperparameters	O
.	O
	
This	O
may	O
result	O
in	O
suboptimal	B-Task
per	I-Task
-	I-Task
domain	I-Task
settings	I-Task
but	O
better	O
resembles	O
an	O
unsupervised	B-Task
adaptation	I-Task
scenario	I-Task
.	O
	
section	O
:	O
Sentiment	B-Task
analysis	I-Task
	
For	O
sentiment	B-Task
analysis	I-Task
,	O
we	O
evaluate	O
on	O
the	O
Amazon	B-Material
reviews	I-Material
dataset	I-Material
[	O
reference	O
]	O
.	O
Reviews	O
with	O
1	O
to	O
3	O
stars	O
are	O
ranked	O
as	O
negative	O
,	O
while	O
reviews	O
with	O
4	O
or	O
5	O
stars	O
are	O
ranked	O
as	O
positive	O
.	O
	
The	O
dataset	O
consists	O
of	O
four	O
domains	O
,	O
yielding	O
12	O
adaptation	O
scenarios	O
.	O
	
We	O
use	O
the	O
same	O
pre	B-Method
-	I-Method
processing	I-Method
and	O
architecture	O
as	O
used	O
in	O
[	O
reference	O
][	O
reference	O
]	O
:	O
5	O
,	O
000	O
-	O
dimensional	O
tf	B-Method
-	I-Method
idf	I-Method
weighted	I-Method
unigram	I-Method
and	I-Method
bigram	I-Method
features	I-Method
as	O
input	O
;	O
2k	O
labeled	O
source	O
samples	O
and	O
2k	O
unlabeled	O
target	O
samples	O
for	O
training	O
,	O
200	O
labeled	O
target	O
samples	O
for	O
validation	B-Task
,	O
and	O
between	O
3k	O
-	O
6k	O
samples	O
for	O
testing	O
.	O
	
The	O
model	O
is	O
an	O
MLP	B-Method
with	O
one	O
hidden	B-Method
layer	I-Method
with	O
50	O
dimensions	O
,	O
sigmoid	O
activations	O
,	O
and	O
a	O
softmax	O
output	O
.	O
	
We	O
compare	O
against	O
the	O
Variational	B-Method
Fair	I-Method
Autoencoder	I-Method
(	O
VFAE	O
)	O
[	O
reference	O
]	O
model	O
and	O
domain	B-Method
-	I-Method
adversarial	I-Method
neural	I-Method
networks	I-Method
(	O
DANN	B-Method
)	O
	
[	O
reference	O
]	O
.	O
	
section	O
:	O
Baselines	O
	
Besides	O
comparing	O
to	O
the	O
top	O
results	O
published	O
on	O
both	O
datasets	O
,	O
we	O
include	O
the	O
following	O
baselines	O
:	O
a	O
)	O
the	O
task	B-Method
model	I-Method
trained	O
on	O
the	O
source	O
domain	O
;	O
b	O
)	O
self	B-Method
-	I-Method
training	I-Method
(	O
Self	O
)	O
;	O
c	O
)	O
tri	B-Method
-	I-Method
training	I-Method
(	O
Tri	B-Method
)	O
;	O
d	O
)	O
tri	B-Method
-	I-Method
training	I-Method
with	O
disagreement	B-Method
(	O
Tri	B-Method
-	O
D	O
)	O
;	O
and	O
e	O
)	O
asymmetric	B-Method
tri	I-Method
-	I-Method
training	I-Method
[	O
reference	O
]	O
)	O
.	O
	
Our	O
proposed	O
model	O
is	O
multi	B-Method
-	I-Method
task	I-Method
tri	I-Method
-	I-Method
training	I-Method
(	O
MTTri	B-Method
)	O
.	O
	
We	O
implement	O
our	O
models	O
in	O
DyNet	B-Method
.	O
	
Reporting	O
single	O
evaluation	B-Metric
scores	I-Metric
might	O
result	O
in	O
biased	O
results	O
[	O
reference	O
]	O
.	O
Throughout	O
the	O
paper	O
,	O
we	O
report	O
mean	B-Metric
accuracy	I-Metric
and	O
standard	O
deviation	O
over	O
five	O
runs	O
for	O
POS	B-Task
tagging	I-Task
and	O
over	O
ten	O
runs	O
for	O
sentiment	B-Task
analysis	I-Task
.	O
	
Significance	O
is	O
computed	O
using	O
bootstrap	B-Method
test	I-Method
.	O
	
The	O
code	O
for	O
all	O
experiments	O
is	O
released	O
at	O
:	O
https:	O
//	O
github.com	O
/	O
bplank	O
/	O
semi	B-Metric
-	I-Metric
supervised	I-Metric
-	I-Metric
baselines	I-Metric
.	O
	
section	O
:	O
Results	O
	
section	O
:	O
Sentiment	B-Task
analysis	I-Task
	
We	O
show	O
results	O
for	O
sentiment	B-Task
analysis	I-Task
for	O
all	O
12	O
domain	B-Task
adaptation	I-Task
scenarios	I-Task
in	O
Figure	O
2	O
.	O
	
For	O
clarity	O
,	O
we	O
also	O
show	O
the	O
accuracy	B-Metric
scores	O
averaged	O
across	O
each	O
target	O
domain	O
as	O
well	O
as	O
a	O
global	B-Metric
macro	I-Metric
average	I-Metric
in	O
Table	O
2	O
Self	B-Method
-	I-Method
training	I-Method
achieves	O
surprisingly	O
good	O
results	O
but	O
is	O
not	O
able	O
to	O
compete	O
with	O
tri	B-Method
-	I-Method
training	I-Method
.	O
	
Tritraining	B-Method
with	O
disagreement	B-Method
is	O
only	O
slightly	O
better	O
than	O
self	B-Method
-	I-Method
training	I-Method
,	O
showing	O
that	O
the	O
disagreement	B-Method
component	I-Method
might	O
not	O
be	O
useful	O
when	O
there	O
is	O
a	O
strong	O
domain	O
shift	O
.	O
	
Tri	B-Method
-	I-Method
training	I-Method
achieves	O
the	O
best	O
average	O
results	O
on	O
two	O
target	O
domains	O
and	O
clearly	O
outperforms	O
the	O
state	O
of	O
the	O
art	O
on	O
average	O
.	O
	
MT	O
-	O
Tri	B-Method
finally	O
outperforms	O
the	O
state	O
of	O
the	O
art	O
on	O
3	O
/	O
4	O
domains	O
,	O
and	O
even	O
slightly	O
traditional	O
tritraining	B-Method
,	O
resulting	O
in	O
the	O
overall	O
best	O
method	O
.	O
	
This	O
improvement	O
is	O
mainly	O
due	O
to	O
the	O
B	O
-	O
>E	O
and	O
D	O
-	O
>E	O
scenarios	O
,	O
on	O
which	O
tri	B-Method
-	I-Method
training	I-Method
struggles	O
.	O
	
These	O
domain	O
pairs	O
are	O
among	O
those	O
with	O
the	O
highest	O
Adistance	O
[	O
reference	O
]	O
,	O
which	O
highlights	O
that	O
tri	B-Method
-	I-Method
training	I-Method
has	O
difficulty	O
dealing	O
with	O
a	O
strong	O
shift	O
in	O
domain	O
.	O
	
Our	O
method	O
is	O
able	O
to	O
mitigate	O
this	O
deficiency	O
by	O
training	O
one	O
of	O
the	O
three	O
output	B-Method
layers	I-Method
only	O
on	O
pseudo	O
-	O
labeled	O
target	O
domain	O
examples	O
.	O
	
In	O
addition	O
,	O
MT	O
-	O
Tri	B-Method
is	O
more	O
efficient	O
as	O
it	O
adds	O
a	O
smaller	O
number	O
of	O
pseudo	O
-	O
labeled	O
examples	O
than	O
tri	B-Method
-	I-Method
training	I-Method
at	O
every	O
epoch	O
.	O
	
For	O
sentiment	B-Task
analysis	I-Task
,	O
tri	B-Method
-	I-Method
training	I-Method
adds	O
around	O
1800	O
-	O
1950	O
/	O
2000	O
unlabeled	O
examples	O
at	O
every	O
epoch	O
,	O
while	O
MT	O
-	O
Tri	B-Method
only	O
adds	O
around	O
100	O
-	O
300	O
in	O
early	O
epochs	O
.	O
	
This	O
shows	O
that	O
the	O
orthogonality	O
constraint	O
is	O
useful	O
for	O
inducing	O
diversity	O
.	O
	
In	O
addition	O
,	O
adding	O
fewer	O
examples	O
poses	O
a	O
smaller	O
risk	O
of	O
swamping	O
the	O
learned	O
representations	O
with	O
useless	O
signals	O
and	O
is	O
more	O
akin	O
to	O
fine	B-Method
-	I-Method
tuning	I-Method
,	O
the	O
standard	O
method	O
for	O
supervised	B-Task
domain	I-Task
adaptation	I-Task
[	O
reference	O
]	O
.	O
	
We	O
observe	O
an	O
asymmetry	O
in	O
the	O
results	O
between	O
some	O
of	O
the	O
domain	O
pairs	O
,	O
e.g.	O
B	O
-	O
>D	O
and	O
D	O
-	O
>B.	O
	
We	O
hypothesize	O
that	O
the	O
asymmetry	O
may	O
be	O
due	O
to	O
properties	O
of	O
the	O
data	O
and	O
that	O
the	O
domains	O
are	O
relatively	O
far	O
apart	O
e.g.	O
,	O
in	O
terms	O
of	O
A	O
-	O
distance	O
.	O
	
In	O
fact	O
,	O
asymmetry	O
in	O
these	O
domains	O
is	O
already	O
reflected	O
Table	O
4	O
:	O
Accuracy	B-Metric
for	O
POS	B-Task
tagging	I-Task
on	O
the	O
dev	O
and	O
test	O
sets	O
of	O
the	O
SANCL	B-Material
domains	I-Material
,	O
models	O
trained	O
on	O
full	O
source	O
data	O
setup	O
.	O
	
Values	O
for	O
methods	O
with	O
*	O
are	O
from	O
[	O
reference	O
]	O
.	O
	
in	O
the	O
results	O
of	O
[	O
reference	O
]	O
and	O
is	O
corroborated	O
in	O
the	O
results	O
for	O
asymmetric	B-Method
tri	I-Method
-	I-Method
training	I-Method
[	O
reference	O
]	O
and	O
our	O
method	O
.	O
	
We	O
note	O
a	O
weakness	O
of	O
this	O
dataset	O
is	O
high	O
variance	O
.	O
	
Existing	O
approaches	O
only	O
report	O
the	O
mean	O
,	O
which	O
makes	O
an	O
objective	O
comparison	O
difficult	O
.	O
	
For	O
this	O
reason	O
,	O
we	O
believe	O
it	O
is	O
essential	O
to	O
evaluate	O
proposed	O
approaches	O
also	O
on	O
other	O
tasks	O
.	O
	
POS	B-Task
tagging	I-Task
Results	O
for	O
tagging	B-Task
in	O
the	O
low	O
-	O
data	O
regime	O
(	O
10	O
%	O
of	O
WSJ	B-Material
)	O
are	O
given	O
in	O
Table	O
3	O
.	O
	
Self	B-Method
-	I-Method
training	I-Method
does	O
not	O
work	O
for	O
the	O
sequence	B-Task
prediction	I-Task
task	I-Task
.	O
	
We	O
report	O
only	O
the	O
best	O
instantiation	O
(	O
throttling	O
with	O
n=800	O
)	O
.	O
	
Our	O
results	O
contribute	O
to	O
negative	O
findings	O
regarding	O
self	B-Method
-	I-Method
training	I-Method
[	O
reference	O
][	O
reference	O
]	O
.	O
	
In	O
the	O
low	B-Task
-	I-Task
data	I-Task
setup	I-Task
,	O
tri	B-Method
-	I-Method
training	I-Method
with	O
disagreement	B-Method
works	O
best	O
,	O
reaching	O
an	O
overall	B-Metric
average	I-Metric
accuracy	I-Metric
of	O
89.70	O
,	O
closely	O
followed	O
by	O
classic	O
tritraining	B-Method
,	O
and	O
significantly	O
outperforming	O
the	O
baseline	O
on	O
4	O
/	O
5	O
domains	O
.	O
	
The	O
exception	O
is	O
newsgroups	O
,	O
a	O
difficult	O
domain	O
with	O
high	O
OOV	B-Metric
rate	I-Metric
where	O
none	O
of	O
the	O
approches	O
beats	O
the	O
baseline	O
(	O
see	O
§	O
3.4	O
)	O
.	O
	
Our	O
proposed	O
MT	O
-	O
Tri	B-Method
is	O
better	O
than	O
asymmetric	B-Method
tritraining	I-Method
,	O
but	O
falls	O
below	O
classic	O
tri	B-Method
-	I-Method
training	I-Method
.	O
	
It	O
beats	O
Table	O
5	O
:	O
Accuracy	B-Metric
scores	I-Metric
on	O
dev	O
sets	O
for	O
OOV	O
and	O
unknown	O
word	O
-	O
tag	O
(	O
UWT	B-Material
)	O
tokens	O
.	O
	
the	O
baseline	O
significantly	O
on	O
only	O
2	O
/	O
5	O
domains	O
(	O
answers	O
and	O
emails	O
)	O
.	O
	
The	O
FLORS	B-Method
tagger	I-Method
[	O
reference	O
]	O
fares	O
better	O
.	O
	
Its	O
contextual	O
distributional	O
features	O
are	O
particularly	O
helpful	O
on	O
unknown	O
word	O
-	O
tag	O
combinations	O
(	O
see	O
§	O
3.4	O
)	O
,	O
which	O
is	O
a	O
limitation	O
of	O
the	O
lexicalized	B-Method
generic	I-Method
bi	I-Method
-	I-Method
LSTM	I-Method
tagger	I-Method
.	O
	
For	O
the	O
high	O
-	O
data	O
setup	O
(	O
Table	O
4	O
)	O
results	O
are	O
similar	O
.	O
	
Disagreement	B-Task
,	O
however	O
,	O
is	O
only	O
favorable	O
in	O
the	O
low	O
-	O
data	O
setups	O
;	O
the	O
effect	O
of	O
avoiding	O
easy	O
points	O
no	O
longer	O
holds	O
in	O
the	O
full	O
data	O
setup	O
.	O
	
Classic	O
tritraining	B-Method
is	O
the	O
best	O
method	O
.	O
	
In	O
particular	O
,	O
traditional	O
tri	B-Method
-	I-Method
training	I-Method
is	O
complementary	O
to	O
word	B-Task
embedding	I-Task
initialization	I-Task
,	O
pushing	O
the	O
non	O
-	O
pre	O
-	O
trained	O
baseline	O
to	O
the	O
level	O
of	O
SRC	B-Method
with	O
Glove	B-Method
initalization	I-Method
.	O
	
Tritraining	B-Method
pushes	O
performance	O
even	O
further	O
and	O
results	O
in	O
the	O
best	O
model	O
,	O
significantly	O
outperforming	O
the	O
baseline	O
again	O
in	O
4	O
/	O
5	O
cases	O
,	O
and	O
reaching	O
FLORS	O
performance	O
on	O
weblogs	O
.	O
	
Multi	O
-	O
task	O
tritraining	B-Method
is	O
often	O
slightly	O
more	O
effective	O
than	O
asymmetric	B-Method
tri	I-Method
-	I-Method
training	I-Method
[	O
reference	O
]	O
;	O
however	O
,	O
improvements	O
for	O
both	O
are	O
not	O
robust	O
across	O
domains	O
,	O
sometimes	O
performance	O
even	O
drops	O
.	O
	
The	O
model	O
likely	O
is	O
too	O
simplistic	O
for	O
such	O
a	O
high	B-Task
-	I-Task
data	I-Task
POS	I-Task
setup	I-Task
,	O
and	O
exploring	O
shared	B-Method
-	I-Method
private	I-Method
models	I-Method
might	O
prove	O
more	O
fruitful	O
.	O
	
On	O
the	O
test	O
sets	O
,	O
tri	B-Method
-	I-Method
training	I-Method
performs	O
consistently	O
the	O
best	O
.	O
	
section	O
:	O
POS	B-Method
analysis	I-Method
	
We	O
analyze	O
POS	B-Metric
tagging	I-Metric
accuracy	I-Metric
with	O
respect	O
to	O
word	O
frequency	O
6	O
and	O
unseen	O
word	O
-	O
tag	O
combinations	O
(	O
UWT	B-Material
)	O
on	O
the	O
dev	O
sets	O
.	O
	
known	O
tags	O
,	O
OOVs	O
and	O
unknown	O
word	O
-	O
tag	O
(	O
UWT	B-Material
)	O
rate	O
.	O
	
The	O
SANCL	B-Material
dataset	I-Material
is	O
overall	O
very	O
challenging	O
:	O
OOV	B-Metric
rates	I-Metric
are	O
high	O
(	O
6.8	O
-	O
11	O
%	O
compared	O
to	O
2.3	O
%	O
in	O
WSJ	B-Material
)	O
,	O
so	O
is	O
the	O
unknown	O
word	O
-	O
tag	O
(	O
UWT	B-Material
)	O
rate	O
(	O
answers	O
and	O
emails	O
contain	O
2.91	O
%	O
and	O
3.47	O
%	O
UWT	B-Material
compared	O
to	O
0.61	O
%	O
on	O
WSJ	B-Material
)	O
and	O
	
almost	O
all	O
target	O
domains	O
even	O
contain	O
unknown	O
tags	O
[	O
reference	O
]	O
)	O
	
(	O
unknown	O
tags	O
:	O
ADD	O
,	O
GW	O
,	O
NFP	O
,	O
XX	O
)	O
,	O
except	O
for	O
weblogs	O
.	O
	
Email	O
is	O
the	O
domain	O
with	O
the	O
highest	O
OOV	B-Metric
rate	I-Metric
and	O
highest	O
unknown	O
-	O
tag	O
-	O
for	O
-	O
known	B-Metric
-	I-Metric
words	I-Metric
rate	I-Metric
.	O
	
We	O
plot	O
accuracy	B-Metric
with	O
respect	O
to	O
word	O
frequency	O
on	O
email	O
in	O
Figure	O
3	O
,	O
analyzing	O
how	O
the	O
three	O
methods	O
fare	O
in	O
comparison	O
to	O
the	O
baseline	O
on	O
this	O
difficult	O
domain	O
.	O
	
Regarding	O
OOVs	B-Task
,	O
the	O
results	O
in	O
Table	O
5	O
(	O
second	O
part	O
)	O
show	O
that	O
classic	O
tri	B-Method
-	I-Method
training	I-Method
outperforms	O
the	O
source	B-Method
model	I-Method
(	O
trained	O
on	O
only	O
source	O
data	O
)	O
on	O
3	O
/	O
5	O
domains	O
in	O
terms	O
of	O
OOV	B-Metric
accuracy	I-Metric
,	O
except	O
on	O
two	O
domains	O
with	O
high	O
OOV	B-Metric
rate	I-Metric
(	O
newsgroups	O
and	O
weblogs	O
)	O
.	O
	
In	O
general	O
,	O
we	O
note	O
that	O
tri	B-Method
-	I-Method
training	I-Method
works	O
best	O
on	O
OOVs	B-Material
and	O
on	O
low	O
-	O
frequency	O
tokens	O
,	O
which	O
is	O
also	O
shown	O
in	O
Figure	O
3	O
(	O
leftmost	O
bins	O
)	O
.	O
	
Both	O
other	O
methods	O
fall	O
typically	O
below	O
the	O
baseline	O
in	O
terms	O
of	O
OOV	B-Metric
accuracy	I-Metric
,	O
but	O
MT	O
-	O
Tri	B-Method
still	O
outperforms	O
Asym	O
in	O
4	O
/	O
5	O
cases	O
.	O
	
Table	O
5	O
(	O
last	O
part	O
)	O
also	O
shows	O
that	O
no	O
bootstrapping	B-Method
method	I-Method
works	O
well	O
on	O
unknown	O
word	O
-	O
tag	O
combinations	O
.	O
	
UWT	B-Material
tokens	O
are	O
very	O
difficult	O
to	O
predict	O
correctly	O
using	O
an	O
unsupervised	B-Method
approach	I-Method
;	O
the	O
less	O
lexicalized	O
and	O
more	O
context	B-Method
-	I-Method
driven	I-Method
approach	I-Method
taken	O
by	O
FLORS	B-Method
is	O
clearly	O
superior	O
for	O
these	O
cases	O
,	O
resulting	O
in	O
higher	O
UWT	B-Material
accuracies	O
for	O
4	O
/	O
5	O
domains	O
.	O
	
section	O
:	O
Related	O
work	O
	
Learning	O
under	O
Domain	B-Method
Shift	I-Method
	
There	O
is	O
a	O
large	O
body	O
of	O
work	O
on	O
domain	B-Task
adaptation	I-Task
.	O
	
Studies	O
on	O
unsupervised	B-Task
domain	I-Task
adaptation	I-Task
include	O
early	O
work	O
on	O
bootstrapping	B-Method
[	O
reference	O
][	O
reference	O
]	O
,	O
shared	B-Method
feature	I-Method
representations	I-Method
[	O
reference	O
][	O
reference	O
]	O
and	O
instance	B-Method
weighting	I-Method
	
[	O
reference	O
]	O
.	O
Recent	O
approaches	O
include	O
adversarial	B-Method
learning	I-Method
[	O
reference	O
]	O
and	O
fine	B-Method
-	I-Method
tuning	I-Method
[	O
reference	O
]	O
.	O
	
There	O
is	O
almost	O
no	O
work	O
on	O
bootstrapping	B-Method
approaches	I-Method
for	O
recent	O
neural	B-Task
NLP	I-Task
,	O
in	O
particular	O
under	O
domain	B-Task
shift	I-Task
.	O
	
Tri	B-Method
-	I-Method
training	I-Method
is	O
less	O
studied	O
,	O
and	O
only	O
recently	O
re	O
-	O
emerged	O
in	O
the	O
vision	B-Task
community	I-Task
[	O
reference	O
]	O
,	O
albeit	O
is	O
not	O
compared	O
to	O
classic	O
tri	B-Method
-	I-Method
training	I-Method
.	O
	
Neural	B-Method
network	I-Method
ensembling	I-Method
Related	O
work	O
on	O
self	B-Method
-	I-Method
ensembling	I-Method
approaches	I-Method
includes	O
snapshot	B-Task
ensembling	I-Task
or	O
temporal	B-Method
ensembling	I-Method
	
[	O
reference	O
]	O
.	O
	
In	O
general	O
,	O
the	O
line	O
between	O
"	O
explicit	O
"	O
and	O
"	O
implicit	O
"	O
ensembling	O
,	O
like	O
dropout	B-Method
[	O
reference	O
]	O
or	O
temporal	B-Method
ensembling	I-Method
[	O
reference	O
]	O
,	O
is	O
more	O
fuzzy	O
.	O
	
As	O
we	O
noted	O
earlier	O
our	O
multi	B-Task
-	I-Task
task	I-Task
learning	I-Task
setup	I-Task
can	O
be	O
seen	O
as	O
a	O
form	O
of	O
self	B-Task
-	I-Task
ensembling	I-Task
.	O
	
Multi	B-Method
-	I-Method
task	I-Method
learning	I-Method
in	O
NLP	B-Method
Neural	I-Method
networks	I-Method
are	O
particularly	O
well	O
-	O
suited	O
for	O
MTL	B-Task
allowing	O
for	O
parameter	B-Task
sharing	I-Task
[	O
reference	O
]	O
.	O
Recent	O
NLP	B-Material
conferences	I-Material
witnessed	O
a	O
"	O
tsunami	O
"	O
of	O
deep	O
learning	O
papers	O
[	O
reference	O
]	O
,	O
followed	O
by	O
what	O
we	O
call	O
a	O
multi	B-Method
-	I-Method
task	I-Method
learning	I-Method
"	O
wave	O
"	O
:	O
MTL	B-Task
has	O
been	O
successfully	O
applied	O
to	O
a	O
wide	O
range	O
of	O
NLP	B-Task
tasks	I-Task
[	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
.	O
	
Related	O
to	O
it	O
is	O
the	O
pioneering	O
work	O
on	O
adversarial	B-Method
learning	I-Method
(	O
DANN	B-Task
)	O
	
[	O
reference	O
]	O
.	O
For	O
sentiment	B-Task
analysis	I-Task
	
we	O
found	O
tri	B-Method
-	I-Method
training	I-Method
and	O
our	O
MT	O
-	O
Tri	B-Method
model	O
to	O
outperform	O
DANN	B-Method
.	O
	
Our	O
MT	O
-	O
Tri	B-Method
model	O
lends	O
itself	O
well	O
to	O
shared	B-Method
-	I-Method
private	I-Method
models	I-Method
such	O
as	O
those	O
proposed	O
recently	O
[	O
reference	O
]	O
,	O
which	O
extend	O
upon	O
[	O
reference	O
]	O
by	O
having	O
separate	O
source	O
and	O
target	O
-	O
specific	B-Method
encoders	I-Method
.	O
	
section	O
:	O
Conclusions	O
	
We	O
re	O
-	O
evaluate	O
a	O
range	O
of	O
traditional	O
generalpurpose	B-Method
bootstrapping	I-Method
algorithms	I-Method
in	O
the	O
context	O
of	O
neural	B-Method
network	I-Method
approaches	I-Method
to	O
semi	B-Task
-	I-Task
supervised	I-Task
learning	I-Task
under	O
domain	B-Task
shift	I-Task
.	O
	
For	O
the	O
two	O
examined	O
NLP	B-Task
tasks	I-Task
classic	O
tri	B-Method
-	I-Method
training	I-Method
works	O
the	O
best	O
and	O
even	O
outperforms	O
a	O
recent	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
method	O
.	O
	
The	O
drawback	O
of	O
tri	B-Method
-	I-Method
training	I-Method
it	O
	
its	O
time	B-Metric
and	I-Metric
space	I-Metric
complexity	I-Metric
.	O
	
We	O
therefore	O
propose	O
a	O
more	O
efficient	O
multi	O
-	O
task	O
tri	B-Method
-	I-Method
training	I-Method
model	O
,	O
which	O
outperforms	O
both	O
traditional	O
tri	B-Method
-	I-Method
training	I-Method
and	O
recent	O
alternatives	O
in	O
the	O
case	O
of	O
sentiment	B-Task
analysis	I-Task
.	O
	
For	O
POS	B-Task
tagging	I-Task
,	O
classic	O
tri	B-Method
-	I-Method
training	I-Method
is	O
superior	O
,	O
performing	O
especially	O
well	O
on	O
OOVs	O
and	O
low	O
frequency	O
tokens	O
,	O
which	O
suggests	O
it	O
is	O
less	O
affected	O
by	O
error	O
propagation	O
.	O
	
Overall	O
we	O
emphasize	O
the	O
importance	O
of	O
comparing	O
neural	B-Method
approaches	I-Method
to	O
strong	O
baselines	O
and	O
reporting	O
results	O
across	O
several	O
runs	O
.	O
	
section	O
:	O
	
section	O
:	O
Acknowledgments	O
	
We	O
thank	O
the	O
anonymous	O
reviewers	O
for	O
their	O
valuable	O
feedback	O
.	O
	
Sebastian	O
is	O
supported	O
by	O
Irish	O
Research	O
Council	O
Grant	O
Number	O
EBPPG	O
/	O
2014	O
/	O
30	O
and	O
Science	O
Foundation	O
	
Ireland	O
Grant	O
Number	O
SFI	O
/	O
12	O
/	O
RC	O
/	O
2289	O
.	O
	
Barbara	O
is	O
supported	O
by	O
NVIDIA	O
corporation	O
and	O
thanks	O
the	O
Computing	O
Center	O
of	O
the	O
University	O
of	O
Groningen	O
for	O
HPC	O
support	O
.	O
	
section	O
:	O
	
document	O
:	O
PCL	B-Method
:	O
Proposal	B-Method
Cluster	I-Method
Learning	I-Method
for	O
Weakly	B-Task
Supervised	I-Task
Object	I-Task
Detection	I-Task
	
Weakly	B-Task
Supervised	I-Task
Object	I-Task
Detection	I-Task
(	O
WSOD	B-Task
)	I-Task
,	O
using	O
only	O
image	O
-	O
level	O
annotations	O
to	O
train	O
object	B-Method
detectors	I-Method
,	O
is	O
of	O
growing	O
importance	O
in	O
object	B-Task
recognition	I-Task
.	O
	
In	O
this	O
paper	O
,	O
we	O
propose	O
a	O
novel	O
deep	B-Method
network	I-Method
for	O
WSOD	B-Task
.	O
	
Unlike	O
previous	O
networks	O
that	O
transfer	O
the	O
object	B-Task
detection	I-Task
problem	O
to	O
an	O
image	B-Task
classification	I-Task
problem	I-Task
using	O
Multiple	B-Method
Instance	I-Method
Learning	I-Method
(	O
MIL	B-Method
)	O
,	O
our	O
strategy	O
generates	O
proposal	B-Method
clusters	I-Method
to	O
learn	O
refined	O
instance	B-Method
classifiers	I-Method
by	O
an	O
iterative	B-Method
process	I-Method
.	O
	
The	O
proposals	O
in	O
the	O
same	O
cluster	O
are	O
spatially	O
adjacent	O
and	O
associated	O
with	O
the	O
same	O
object	O
.	O
	
This	O
prevents	O
the	O
network	O
from	O
concentrating	O
too	O
much	O
on	O
parts	O
of	O
objects	O
instead	O
of	O
whole	O
objects	O
.	O
	
We	O
first	O
show	O
that	O
instances	O
can	O
be	O
assigned	O
object	O
or	O
background	O
labels	O
directly	O
based	O
on	O
proposal	B-Method
clusters	I-Method
for	O
instance	B-Task
classifier	I-Task
refinement	I-Task
,	O
and	O
then	O
show	O
that	O
treating	O
each	O
cluster	O
as	O
a	O
small	O
new	O
bag	O
yields	O
fewer	O
ambiguities	O
than	O
the	O
directly	O
assigning	B-Method
label	I-Method
method	I-Method
.	O
	
The	O
iterative	B-Method
instance	I-Method
classifier	I-Method
refinement	I-Method
is	O
implemented	O
online	O
using	O
multiple	O
streams	O
in	O
convolutional	B-Method
neural	O
networks	O
,	O
where	O
the	O
first	O
is	O
an	O
MIL	B-Method
network	O
and	O
the	O
others	O
are	O
for	O
instance	B-Method
classifier	I-Method
refinement	I-Method
supervised	O
by	O
the	O
preceding	O
one	O
.	O
	
Experiments	O
are	O
conducted	O
on	O
the	O
PASCAL	B-Material
VOC	I-Material
,	O
ImageNet	B-Material
detection	I-Material
,	O
and	O
MS	B-Material
-	I-Material
COCO	I-Material
benchmarks	O
for	O
WSOD	B-Task
.	O
	
Results	O
show	O
that	O
our	O
method	O
outperforms	O
the	O
previous	O
state	O
of	O
the	O
art	O
significantly	O
.	O
	
Object	B-Task
detection	I-Task
,	O
weakly	B-Task
supervised	I-Task
learning	I-Task
,	O
convolutional	B-Method
neural	O
network	O
,	O
multiple	B-Method
instance	I-Method
learning	I-Method
,	O
proposal	B-Task
cluster	I-Task
.	O
	
section	O
:	O
Introduction	O
	
Object	B-Task
detection	I-Task
is	O
one	O
of	O
the	O
most	O
important	O
problems	O
in	O
computer	B-Task
vision	I-Task
with	O
many	O
applications	O
.	O
	
Recently	O
,	O
due	O
to	O
the	O
development	O
of	O
Convolutional	B-Method
Neural	I-Method
Network	I-Method
(	O
CNN	B-Method
)	O
and	O
the	O
availability	O
of	O
large	O
scale	O
datasets	O
with	O
detailed	O
boundingbox	O
-	O
level	O
annotations	O
,	O
there	O
have	O
been	O
great	O
leap	O
forwards	O
in	O
object	B-Task
detection	I-Task
.	O
	
However	O
,	O
it	O
is	O
very	O
labor	O
-	O
intensive	O
and	O
time	O
-	O
consuming	O
to	O
collect	O
detailed	O
annotations	O
,	O
whereas	O
acquiring	O
images	O
with	O
only	O
image	O
-	O
level	O
annotations	O
(	O
i.e	O
.	O
,	O
image	O
tags	O
)	O
indicating	O
whether	O
an	O
object	O
class	O
exists	O
in	O
an	O
image	O
or	O
not	O
is	O
much	O
easier	O
.	O
	
For	O
example	O
,	O
we	O
can	O
use	O
image	O
search	O
queries	O
to	O
search	O
on	O
the	O
Internet	O
(	O
e.g	O
.	O
,	O
Google	O
and	O
Flickr	O
)	O
to	O
obtain	O
a	O
mass	O
of	O
images	O
with	O
such	O
image	O
-	O
level	O
annotations	O
.	O
	
This	O
fact	O
inspires	O
us	O
to	O
explore	O
methods	O
for	O
the	O
Weakly	B-Task
Supervised	I-Task
Object	I-Task
Detection	I-Task
(	O
WSOD	B-Task
)	O
problem	O
,	O
	
i.e	O
.	O
,	O
	
training	O
object	B-Method
detectors	I-Method
with	O
only	O
image	O
tag	O
supervisions	O
.	O
	
Many	O
previous	O
methods	O
follow	O
the	O
Multiple	B-Method
Instance	I-Method
Learning	I-Method
(	O
MIL	B-Method
)	O
pipeline	O
for	O
WSOD	B-Task
.	O
	
They	O
treat	O
images	O
as	O
bags	O
and	O
proposals	O
as	O
instances	O
;	O
then	O
instance	B-Method
classifiers	I-Method
(	O
object	B-Method
detectors	I-Method
)	O
are	O
trained	O
under	O
MIL	B-Method
constraints	O
(	O
i.e	O
.	O
,	O
a	O
positive	O
bag	O
contains	O
at	O
least	O
one	O
positive	O
instance	O
and	O
all	O
instances	O
in	O
negative	O
bags	O
are	O
negative	O
)	O
.	O
	
In	O
addition	O
,	O
inspired	O
by	O
the	O
great	O
success	O
of	O
CNN	B-Method
,	O
recent	O
efforts	O
often	O
combine	O
MIL	B-Method
and	O
CNN	B-Method
to	O
obtain	O
better	O
WSOD	B-Task
performance	O
.	O
	
Some	O
researches	O
have	O
shown	O
that	O
treating	O
CNNs	B-Method
pre	O
-	O
trained	O
on	O
large	O
scale	O
datasets	O
as	O
off	O
-	O
the	O
-	O
shelf	O
proposal	B-Method
feature	I-Method
extractors	I-Method
can	O
obtain	O
much	O
better	O
performance	O
than	O
traditional	O
hand	O
-	O
designed	O
features	O
.	O
	
Moreover	O
,	O
many	O
recent	O
works	O
have	O
achieved	O
even	O
better	O
results	O
for	O
WSOD	B-Task
by	O
an	O
MIL	B-Method
network	O
using	O
standard	O
end	B-Method
-	I-Method
to	I-Method
-	I-Method
end	I-Method
training	I-Method
or	O
a	O
variant	O
of	O
end	B-Method
-	I-Method
to	I-Method
-	I-Method
end	I-Method
training	I-Method
.	O
	
See	O
Section	O
[	O
reference	O
]	O
for	O
this	O
variant	O
of	O
end	B-Task
-	I-Task
to	I-Task
-	I-Task
end	I-Task
and	O
how	O
it	O
differs	O
from	O
the	O
standard	O
one	O
.	O
	
We	O
use	O
the	O
same	O
strategy	O
of	O
training	O
a	O
variant	O
of	O
end	O
-	O
to	O
-	O
end	O
MIL	B-Method
network	O
inspired	O
by	O
.	O
	
Although	O
some	O
promising	O
results	O
have	O
been	O
obtained	O
by	O
MIL	B-Method
networks	I-Method
for	O
WSOD	B-Task
,	O
they	O
do	O
not	O
perform	O
as	O
well	O
as	O
fully	B-Method
supervised	I-Method
ones	I-Method
.	O
	
As	O
shown	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
(	O
a	O
)	O
,	O
previous	O
MIL	B-Method
networks	I-Method
integrate	O
the	O
MIL	B-Method
constraints	O
into	O
the	O
network	B-Method
training	I-Method
by	O
transferring	O
the	O
instance	B-Task
classification	I-Task
(	O
object	B-Task
detection	I-Task
)	O
problem	O
to	O
a	O
bag	B-Task
classification	I-Task
(	O
image	B-Task
classification	I-Task
)	I-Task
problem	I-Task
,	O
where	O
the	O
final	O
image	B-Metric
scores	I-Metric
are	O
the	O
aggregation	O
of	O
the	O
proposal	O
scores	O
.	O
	
However	O
,	O
there	O
is	O
a	O
big	O
gap	O
between	O
image	B-Task
classification	I-Task
and	O
object	B-Task
detection	I-Task
.	O
	
For	O
classification	B-Task
,	O
even	O
parts	O
of	O
objects	O
can	O
contribute	O
to	O
correct	O
results	O
(	O
e.g	O
.	O
,	O
the	O
red	O
boxes	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
)	O
,	O
because	O
important	O
parts	O
include	O
many	O
characteristics	O
of	O
the	O
objects	O
.	O
	
Many	O
proposals	O
only	O
cover	O
parts	O
of	O
objects	O
,	O
and	O
“	O
seeing	O
”	O
proposals	O
only	O
of	O
parts	O
may	O
be	O
enough	O
to	O
roughly	O
localize	O
the	O
objects	O
.	O
	
But	O
this	O
may	O
not	O
localize	O
objects	O
well	O
enough	O
considering	O
the	O
performance	O
requirement	O
of	O
high	O
Intersection	B-Metric
-	I-Metric
over	I-Metric
-	I-Metric
Union	I-Metric
(	O
IoU	B-Metric
)	O
between	O
the	O
resulting	O
boxes	O
and	O
groundtruth	O
boundingboxes	O
:	O
the	O
top	O
ranking	B-Method
proposals	I-Method
may	O
only	O
localize	O
parts	O
of	O
objects	O
instead	O
of	O
whole	O
objects	O
.	O
	
Recall	O
that	O
for	O
detection	B-Task
,	O
the	O
resulting	O
boxes	O
should	O
not	O
only	O
give	O
correct	O
classification	B-Task
,	O
but	O
also	O
localize	O
objects	O
and	O
have	O
enough	O
overlap	O
with	O
groundtruth	O
boundingboxes	O
(	O
	
e.g	O
.	O
,	O
the	O
green	O
boxes	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
)	O
.	O
	
Before	O
presenting	O
our	O
solution	O
of	O
the	O
problem	O
referred	O
above	O
,	O
we	O
first	O
introduce	O
the	O
concept	O
of	O
proposal	B-Method
cluster	I-Method
.	O
	
Object	B-Task
detection	I-Task
requires	O
algorithms	O
to	O
generate	O
multiple	O
overlapping	O
proposals	O
closely	O
surrounding	O
objects	O
to	O
ensure	O
high	O
proposal	B-Metric
recall	I-Metric
(	O
e.g	O
.	O
,	O
for	O
each	O
object	O
,	O
there	O
are	O
tens	O
of	O
proposals	O
on	O
average	O
from	O
Selective	B-Method
Search	I-Method
which	O
have	O
IoU	B-Metric
0.5	O
with	O
the	O
groundtruth	O
boundingbox	O
on	O
the	O
PASCAL	B-Material
VOC	I-Material
dataset	O
)	O
.	O
	
Object	O
proposals	O
in	O
an	O
image	O
can	O
be	O
grouped	O
into	O
different	O
spatial	O
clusters	O
.	O
	
Except	O
for	O
one	O
cluster	O
for	O
background	O
proposals	O
,	O
each	O
object	O
cluster	O
is	O
associated	O
with	O
a	O
single	O
object	O
and	O
proposals	O
in	O
each	O
cluster	O
are	O
spatially	O
adjacent	O
,	O
as	O
shown	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
.	O
	
For	O
fully	B-Task
supervised	I-Task
object	I-Task
detection	I-Task
(	O
i.e	O
.	O
,	O
training	O
object	B-Task
detectors	I-Task
using	O
boundingbox	O
-	O
level	O
annotations	O
)	O
,	O
proposal	O
clusters	O
can	O
be	O
generated	O
by	O
treating	O
the	O
groundtruth	O
boundingboxes	O
as	O
cluster	O
centers	O
.	O
	
Then	O
object	B-Method
detectors	I-Method
are	O
trained	O
according	O
to	O
the	O
proposal	O
clusters	O
(	O
e.g	O
.	O
,	O
assigning	O
all	O
proposals	O
the	O
label	O
of	O
the	O
corresponding	O
object	O
class	O
for	O
each	O
cluster	O
)	O
.	O
	
This	O
alleviates	O
the	O
problem	O
that	O
detectors	B-Task
may	O
only	O
focus	O
on	O
parts	O
.	O
	
But	O
in	O
the	O
weakly	B-Task
supervised	I-Task
scenario	I-Task
,	O
it	O
is	O
difficult	O
to	O
generate	O
proposal	O
clusters	O
because	O
groundtruth	O
boundingboxes	O
that	O
can	O
be	O
used	O
as	O
cluster	O
centers	O
are	O
not	O
provided	O
.	O
	
To	O
cope	O
with	O
this	O
difficulty	O
,	O
we	O
suggest	O
to	O
find	O
proposal	O
clusters	O
as	O
follows	O
.	O
	
First	O
we	O
generate	O
proposal	O
cluster	O
centers	O
from	O
those	O
proposals	O
which	O
have	O
high	O
classification	B-Metric
scores	I-Metric
during	O
training	O
,	O
because	O
these	O
top	O
ranking	O
proposals	O
can	O
always	O
detect	O
at	O
least	O
parts	O
of	O
objects	O
.	O
	
That	O
is	O
,	O
for	O
each	O
image	O
,	O
after	O
obtaining	O
proposal	O
scores	O
,	O
we	O
select	O
some	O
proposals	O
with	O
high	O
scores	O
as	O
cluster	O
centers	O
,	O
and	O
then	O
proposal	O
clusters	O
are	O
generated	O
based	O
on	O
spatial	O
overlaps	O
with	O
the	O
cluster	O
centers	O
.	O
	
Then	O
the	O
problem	O
reduces	O
to	O
how	O
to	O
select	O
proposals	O
as	O
centers	O
,	O
because	O
many	O
high	O
scoring	O
proposals	O
may	O
correspond	O
to	O
the	O
same	O
object	O
.	O
	
The	O
most	O
straightforward	O
way	O
is	O
to	O
choose	O
the	O
proposal	O
with	O
the	O
highest	O
score	O
for	O
each	O
positive	O
object	O
class	O
(	O
i.e	O
.	O
	
,	O
the	O
object	O
class	O
exists	O
in	O
the	O
image	O
)	O
as	O
the	O
center	O
.	O
	
But	O
such	O
a	O
method	O
ignores	O
the	O
fact	O
that	O
there	O
may	O
exist	O
more	O
than	O
one	O
object	O
with	O
the	O
same	O
object	O
category	O
in	O
natural	O
images	O
(	O
e.g	O
.	O
,	O
the	O
two	O
motorbikes	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
)	O
.	O
	
Therefore	O
,	O
we	O
propose	O
a	O
graph	B-Method
-	I-Method
based	I-Method
method	I-Method
to	O
find	O
cluster	O
centers	O
.	O
	
More	O
specifically	O
,	O
we	O
build	O
a	O
graph	O
of	O
top	O
ranking	O
proposals	O
according	O
to	O
the	O
spatial	O
similarity	O
for	O
each	O
positive	O
object	O
class	O
.	O
	
In	O
the	O
graph	O
,	O
two	O
proposals	O
are	O
connected	O
if	O
they	O
have	O
enough	O
spatial	O
overlaps	O
.	O
	
Then	O
we	O
greedily	O
and	O
iteratively	O
choose	O
the	O
proposals	O
which	O
have	O
most	O
connections	O
with	O
others	O
to	O
estimate	O
the	O
centers	O
.	O
	
Although	O
a	O
cluster	B-Method
center	I-Method
proposal	I-Method
may	O
only	O
capture	O
an	O
object	O
partially	O
,	O
its	O
adjacent	O
proposals	O
(	O
i.e	O
.	O
,	O
other	O
proposals	O
in	O
the	O
cluster	O
)	O
can	O
cover	O
the	O
whole	O
object	O
,	O
or	O
at	O
worst	O
contain	O
larger	O
parts	O
of	O
the	O
object	O
.	O
	
Based	O
on	O
these	O
proposal	O
clusters	O
,	O
we	O
propose	O
two	O
methods	O
to	O
refine	O
instance	B-Method
classifiers	I-Method
(	O
object	B-Method
detectors	I-Method
)	O
during	O
training	B-Task
.	O
	
We	O
first	O
propose	O
to	O
assign	O
proposals	O
object	O
labels	O
directly	O
.	O
	
That	O
is	O
,	O
for	O
each	O
cluster	O
,	O
we	O
assign	O
its	O
proposals	O
the	O
label	O
of	O
its	O
corresponding	O
object	O
class	O
,	O
as	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
(	O
b	O
)	O
.	O
	
Compared	O
with	O
the	O
conventional	O
MIL	B-Method
network	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
(	O
a	O
)	O
,	O
this	O
strategy	O
forces	O
network	O
to	O
“	O
see	O
”	O
larger	O
parts	O
of	O
objects	O
by	O
assigning	O
object	O
labels	O
to	O
proposals	O
that	O
cover	O
larger	O
parts	O
of	O
objects	O
directly	O
,	O
which	O
fills	O
the	O
gap	O
between	O
classification	B-Task
and	O
detection	B-Task
to	O
some	O
extent	O
.	O
	
While	O
effective	O
,	O
this	O
strategy	O
still	O
has	O
potential	O
ambiguities	O
,	O
because	O
assigning	O
the	O
same	O
object	O
label	O
to	O
proposals	O
that	O
cover	O
different	O
parts	O
of	O
objects	O
simultaneously	O
may	O
confuse	O
the	O
network	O
and	O
will	O
hurt	O
the	O
discriminative	O
power	O
of	O
the	O
detector	O
.	O
	
To	O
address	O
this	O
problem	O
,	O
we	O
propose	O
to	O
treat	O
each	O
proposal	O
cluster	O
as	O
a	O
small	O
new	O
bag	O
to	O
train	O
refined	O
instance	B-Method
classifiers	I-Method
,	O
as	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
	
(	O
c	O
)	O
.	O
	
Most	O
of	O
the	O
proposals	O
in	O
these	O
new	O
bags	O
should	O
have	O
relatively	O
high	O
classification	B-Metric
scores	I-Metric
because	O
the	O
cluster	O
centers	O
covers	O
at	O
least	O
parts	O
of	O
objects	O
and	O
proposals	O
in	O
the	O
same	O
cluster	O
are	O
spatially	O
adjacent	O
(	O
except	O
for	O
the	O
background	O
cluster	O
)	O
.	O
	
In	O
the	O
same	O
time	O
,	O
not	O
all	O
proposals	O
in	O
the	O
bags	O
should	O
have	O
high	O
classification	B-Metric
scores	I-Metric
.	O
	
Thus	O
compared	O
with	O
the	O
directly	O
assigning	B-Method
label	I-Method
strategy	I-Method
,	O
this	O
strategy	O
is	O
more	O
flexible	O
and	O
can	O
reduce	O
the	O
ambiguities	O
to	O
some	O
extent	O
.	O
	
We	O
name	O
our	O
method	O
Proposal	B-Method
Cluster	I-Method
Learning	I-Method
(	O
PCL	B-Method
)	O
because	O
it	O
learns	O
refined	O
instance	B-Method
classifiers	I-Method
based	O
on	O
proposal	B-Method
clusters	I-Method
.	O
	
To	O
implement	O
our	O
idea	O
effectively	O
and	O
efficiently	O
,	O
we	O
further	O
propose	O
an	O
online	B-Method
training	I-Method
approach	I-Method
.	O
	
Our	O
network	O
has	O
multiple	O
output	O
streams	O
as	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
.	O
	
The	O
first	O
stream	O
is	O
a	O
basic	O
MIL	B-Method
network	O
which	O
aggregates	O
proposal	O
scores	O
into	O
final	O
image	O
scores	O
to	O
train	O
basic	O
instance	B-Method
classifiers	I-Method
,	O
and	O
the	O
other	O
streams	O
refine	O
the	O
instance	B-Method
classifiers	I-Method
iteratively	O
.	O
	
During	O
the	O
forward	O
process	O
of	O
training	B-Task
,	O
proposal	B-Metric
classification	I-Metric
scores	I-Metric
are	O
obtained	O
and	O
proposal	O
clusters	O
are	O
generated	O
consequently	O
for	O
each	O
stream	O
.	O
	
Then	O
based	O
on	O
these	O
proposal	O
clusters	O
,	O
supervisions	O
are	O
generated	O
to	O
compute	O
losses	O
for	O
the	O
next	O
stream	O
.	O
	
According	O
to	O
the	O
losses	O
,	O
these	O
refined	O
classifiers	B-Method
are	O
trained	O
during	O
back	B-Method
-	I-Method
propagation	I-Method
.	O
	
Except	O
for	O
the	O
first	O
stream	O
that	O
is	O
supervised	O
by	O
image	O
labels	O
,	O
the	O
other	O
streams	O
are	O
supervised	O
by	O
the	O
image	O
labels	O
as	O
well	O
as	O
outputs	O
from	O
their	O
preceding	O
streams	O
.	O
	
As	O
our	O
method	O
forces	O
the	O
network	O
to	O
“	O
see	O
”	O
larger	O
parts	O
of	O
objects	O
,	O
the	O
detector	B-Method
can	O
discover	O
the	O
whole	O
object	O
instead	O
of	O
parts	O
gradually	O
by	O
performing	O
refinement	O
multiple	O
times	O
(	O
i.e	O
.	O
,	O
multiple	O
output	O
streams	O
)	O
.	O
	
But	O
at	O
the	O
start	O
of	O
training	O
,	O
all	O
classifiers	B-Method
are	O
almost	O
untrained	O
,	O
which	O
will	O
result	O
in	O
very	O
noisy	O
proposal	O
clusters	O
,	O
and	O
so	O
the	O
training	O
will	O
deviate	O
from	O
the	O
correct	O
solutions	O
a	O
lot	O
.	O
	
Thus	O
we	O
design	O
a	O
weighted	O
loss	O
further	O
by	O
associating	O
different	O
proposals	O
with	O
different	O
weights	O
in	O
different	O
training	O
iterations	O
.	O
	
After	O
that	O
,	O
all	O
training	B-Method
procedures	I-Method
can	O
thus	O
be	O
integrated	O
into	O
a	O
single	O
end	B-Method
-	I-Method
to	I-Method
-	I-Method
end	I-Method
network	I-Method
.	O
	
This	O
can	O
improve	O
the	O
performance	O
benefiting	O
from	O
our	O
PCL	B-Method
-	O
based	O
classifier	O
refinement	O
procedure	O
.	O
	
It	O
is	O
also	O
very	O
computational	O
efficient	O
in	O
both	O
training	B-Task
and	O
testing	B-Task
.	O
	
In	O
addition	O
,	O
performance	O
can	O
be	O
improved	O
by	O
sharing	O
proposal	O
features	O
among	O
different	O
output	O
streams	O
.	O
	
We	O
elaborately	O
conduct	O
many	O
experiments	O
on	O
the	O
challenging	O
PASCAL	B-Material
VOC	I-Material
,	O
ImageNet	B-Material
detection	I-Material
,	O
and	O
MS	B-Material
-	I-Material
COCO	I-Material
datasets	I-Material
to	O
confirm	O
the	O
effectiveness	O
of	O
our	O
method	O
.	O
	
Our	O
method	O
achieves	O
mAP	B-Metric
and	O
CorLoc	B-Material
on	O
VOC	B-Material
2007	I-Material
which	O
is	O
more	O
than	O
absolute	O
improvement	O
compared	O
with	O
previous	O
best	O
performed	O
methods	O
.	O
	
This	O
paper	O
is	O
an	O
extended	O
version	O
of	O
our	O
previous	O
work	O
.	O
	
In	O
particular	O
,	O
we	O
give	O
more	O
analyses	O
of	O
our	O
method	O
and	O
enrich	O
literatures	O
of	O
most	O
recent	O
related	O
works	O
,	O
making	O
the	O
manuscript	O
more	O
complete	O
.	O
	
In	O
addition	O
,	O
we	O
make	O
two	O
methodological	O
improvements	O
:	O
the	O
first	O
one	O
is	O
to	O
generate	O
proposal	O
clusters	O
using	O
graphs	O
of	O
top	O
ranking	O
proposals	O
instead	O
of	O
using	O
the	O
highest	O
scoring	O
proposal	O
,	O
and	O
the	O
second	O
one	O
is	O
to	O
treat	O
each	O
proposal	O
cluster	O
as	O
a	O
small	O
new	O
bag	O
.	O
	
In	O
addition	O
,	O
we	O
provide	O
more	O
discussions	O
of	O
experimental	O
results	O
,	O
and	O
show	O
the	O
effectiveness	O
of	O
our	O
method	O
on	O
the	O
challenging	O
ImageNet	B-Material
detection	I-Material
and	O
MS	B-Material
-	I-Material
COCO	I-Material
datasets	I-Material
.	O
	
The	O
rest	O
of	O
our	O
paper	O
is	O
organized	O
as	O
follows	O
.	O
	
In	O
Section	O
[	O
reference	O
]	O
,	O
some	O
related	O
works	O
are	O
introduced	O
.	O
	
In	O
Section	O
[	O
reference	O
]	O
,	O
the	O
details	O
of	O
our	O
method	O
are	O
described	O
.	O
	
Elaborate	O
experiments	O
and	O
analyses	O
are	O
conducted	O
in	O
Section	O
[	O
reference	O
]	O
.	O
	
Finally	O
,	O
conclusions	O
and	O
future	O
directions	O
are	O
presented	O
in	O
Section	O
[	O
reference	O
]	O
.	O
	
section	O
:	O
Related	O
work	O
	
subsection	O
:	O
Multiple	B-Method
instance	I-Method
learning	I-Method
	
MIL	B-Method
,	O
first	O
proposed	O
for	O
drug	B-Task
activity	I-Task
prediction	I-Task
,	O
is	O
a	O
classical	O
weakly	B-Task
supervised	I-Task
learning	I-Task
problem	O
.	O
	
Many	O
variants	O
have	O
been	O
proposed	O
for	O
MIL	B-Method
.	O
	
In	O
MIL	B-Method
,	O
a	O
set	O
of	O
bags	O
are	O
given	O
,	O
and	O
each	O
bag	O
is	O
associated	O
with	O
a	O
collection	O
of	O
instances	O
.	O
	
It	O
is	O
natural	O
to	O
treat	O
WSOD	B-Task
as	O
an	O
MIL	B-Method
problem	O
.	O
	
Then	O
the	O
problem	O
turns	O
into	O
finding	O
instance	B-Method
classifiers	I-Method
only	O
given	O
bag	O
labels	O
.	O
	
Our	O
method	O
also	O
follows	O
the	O
MIL	B-Method
strategy	O
and	O
makes	O
several	O
improvements	O
to	O
WSOD	B-Task
.	O
	
In	O
particular	O
,	O
we	O
learn	O
refined	O
instance	B-Method
classifiers	I-Method
based	O
on	O
proposal	O
clusters	O
according	O
to	O
both	O
instance	O
scores	O
and	O
spatial	O
relations	O
in	O
an	O
online	O
manner	O
.	O
	
MIL	B-Method
has	O
many	O
applications	O
to	O
computer	B-Task
vision	I-Task
,	O
such	O
as	O
image	B-Task
classification	I-Task
,	O
weakly	B-Task
supervised	I-Task
semantic	I-Task
segmentation	I-Task
,	O
object	B-Task
detection	I-Task
,	O
object	B-Task
tracking	I-Task
,	O
etc	O
.	O
	
The	O
strategy	O
of	O
treating	O
proposal	O
clusters	O
as	O
bags	O
was	O
partly	O
inspired	O
by	O
,	O
where	O
proposes	O
to	O
train	O
MIL	B-Method
for	O
patches	O
around	O
groundtruth	O
locations	O
and	O
proposes	O
to	O
train	O
MIL	B-Method
for	O
patches	O
around	O
predicted	O
object	O
locations	O
.	O
	
However	O
,	O
they	O
require	O
groundtruth	O
locations	O
for	O
either	O
all	O
training	O
samples	O
or	O
the	O
beginning	O
time	O
frames	O
,	O
whereas	O
WSOD	B-Task
does	O
not	O
have	O
such	O
annotations	O
.	O
	
Therefore	O
,	O
it	O
is	O
much	O
harder	O
to	O
generate	O
proposal	O
clusters	O
only	O
guided	O
by	O
image	O
-	O
level	O
supervisions	O
for	O
WSOD	B-Task
.	O
	
In	O
addition	O
,	O
we	O
incorporate	O
the	O
strategy	O
of	O
treating	O
proposal	O
clusters	O
as	O
bags	O
into	O
the	O
network	B-Method
training	I-Method
whereas	O
do	O
not	O
.	O
	
Oquab	O
et	O
al	O
.	O
also	O
train	O
a	O
CNN	B-Method
network	O
using	O
the	O
max	O
pooing	O
MIL	B-Method
strategy	O
to	O
localize	B-Task
objects	I-Task
.	O
	
But	O
their	O
methods	O
can	O
only	O
coarsely	O
localize	O
objects	O
regardless	O
of	O
their	O
sizes	O
and	O
aspect	O
ratios	O
,	O
whereas	O
our	O
method	O
can	O
detect	O
objects	O
more	O
accurately	O
.	O
	
subsection	O
:	O
Weakly	O
supervised	O
object	B-Task
detection	I-Task
	
WSOD	B-Task
has	O
attracted	O
great	O
interests	O
nowadays	O
because	O
the	O
amount	O
of	O
data	O
with	O
image	O
-	O
level	O
annotations	O
is	O
much	O
bigger	O
and	O
is	O
growing	O
much	O
faster	O
than	O
that	O
with	O
boundingbox	O
-	O
level	O
annotations	O
.	O
	
Many	O
methods	O
are	O
emerging	O
for	O
the	O
WSOD	B-Task
problem	I-Task
.	O
	
For	O
example	O
,	O
Chum	O
and	O
Zisserman	O
first	O
initialize	O
object	O
locations	O
by	O
discriminative	O
visual	O
words	O
and	O
then	O
introduce	O
an	O
exemplar	B-Method
model	I-Method
to	O
measure	O
similarity	O
between	O
image	O
pairs	O
for	O
updating	O
locations	O
.	O
	
Deselaers	O
et	O
al	O
.	O
propose	O
to	O
initialize	O
boxes	O
by	O
objectness	O
and	O
use	O
a	O
CRF	B-Method
-	I-Method
based	I-Method
model	I-Method
to	O
iteratively	O
localize	B-Task
objects	I-Task
.	O
	
Pandey	O
and	O
Lazebnik	O
train	O
a	O
DPM	B-Method
model	I-Method
under	O
weak	B-Method
supervisions	I-Method
for	O
WSOD	B-Task
.	O
	
Shi	O
et	O
al	O
.	O
use	O
Bayesian	B-Method
latent	I-Method
topic	I-Method
models	I-Method
to	O
jointly	O
model	O
different	O
object	O
classes	O
and	O
background	O
.	O
	
Song	O
et	O
al	O
.	O
develop	O
a	O
technology	O
to	O
discover	O
frequent	O
discriminative	O
configurations	O
of	O
visual	O
patterns	O
for	O
robust	B-Task
WSOD	I-Task
.	O
	
Cinbis	O
et	O
al	O
.	O
iteratively	O
train	O
a	O
multi	O
-	O
fold	O
MIL	B-Method
to	O
avoid	O
the	O
detector	B-Method
being	O
locked	O
onto	O
inaccurate	O
local	O
optima	O
.	O
	
Wang	O
et	O
al	O
.	O
relax	O
the	O
MIL	B-Method
constraints	O
into	O
a	O
derivable	O
loss	O
function	O
to	O
train	O
detectors	B-Method
more	O
efficient	O
.	O
	
Recently	O
,	O
with	O
the	O
revolution	O
of	O
CNNs	B-Method
in	O
computer	B-Task
vision	I-Task
,	O
many	O
works	O
also	O
try	O
to	O
combine	O
the	O
WSOD	B-Task
with	O
CNNs	B-Method
.	O
	
Early	O
works	O
treat	O
CNN	B-Method
models	O
pre	O
-	O
trained	O
on	O
ImageNet	B-Material
as	O
off	O
-	O
the	O
-	O
shelf	O
feature	B-Method
extractors	I-Method
.	O
	
They	O
extract	O
CNN	B-Method
features	O
for	O
each	O
candidate	O
regions	O
,	O
and	O
then	O
train	O
their	O
own	O
detectors	O
on	O
top	O
of	O
these	O
features	O
.	O
	
These	O
methods	O
have	O
shown	O
that	O
CNN	B-Method
descriptors	O
can	O
boost	O
performance	O
against	O
traditional	O
hand	O
-	O
designed	O
features	O
.	O
	
More	O
recent	O
efforts	O
tend	O
to	O
train	O
end	B-Method
-	I-Method
to	I-Method
-	I-Method
end	I-Method
networks	I-Method
for	O
WSOD	B-Task
.	O
	
They	O
integrate	O
the	O
MIL	B-Method
constraints	O
into	O
the	O
network	B-Method
training	I-Method
by	O
aggregating	O
proposal	B-Metric
classification	I-Metric
scores	I-Metric
into	O
final	O
image	B-Metric
classification	I-Metric
scores	I-Metric
,	O
and	O
then	O
image	O
-	O
level	O
supervision	O
can	O
be	O
directly	O
added	O
to	O
image	O
classification	O
scores	O
.	O
	
For	O
example	O
,	O
Tang	O
et	O
al	O
.	O
propose	O
to	O
use	O
max	B-Method
pooling	I-Method
for	O
aggregation	B-Task
.	O
	
Bilen	O
and	O
Vedaldi	O
develop	O
a	O
weighted	B-Method
sum	I-Method
pooing	I-Method
strategy	I-Method
.	O
	
Building	O
on	O
,	O
Kantorov	O
et	O
al	O
.	O
argue	O
that	O
context	O
information	O
can	O
improve	O
the	O
performance	O
.	O
	
Diba	O
et	O
al	O
.	O
show	O
that	O
weakly	B-Method
supervised	I-Method
segmentation	I-Method
map	I-Method
can	O
be	O
used	O
as	O
guidance	O
to	O
filter	B-Task
proposals	I-Task
,	O
and	O
jointly	O
train	O
the	O
weakly	B-Method
supervised	I-Method
segmentation	I-Method
network	I-Method
and	O
WSOD	B-Task
end	O
-	O
to	O
-	O
end	O
.	O
	
Our	O
method	O
is	O
built	O
on	O
these	O
networks	O
and	O
any	O
of	O
them	O
can	O
be	O
chosen	O
as	O
our	O
basic	O
network	O
.	O
	
Our	O
strategy	O
proposes	O
to	O
learn	O
refined	O
instance	B-Method
classifiers	I-Method
based	O
on	O
proposal	B-Method
clusters	I-Method
,	O
and	O
propose	O
a	O
novel	O
online	B-Method
approach	I-Method
to	O
train	O
our	O
network	O
effectively	O
and	O
efficiently	O
.	O
	
Experimental	O
results	O
show	O
our	O
strategies	O
can	O
boost	O
the	O
results	O
significantly	O
.	O
	
In	O
addition	O
to	O
the	O
weighted	B-Method
sum	I-Method
pooing	I-Method
,	O
also	O
proposes	O
a	O
“	O
spatial	B-Method
regulariser	I-Method
”	I-Method
that	O
forces	O
features	O
of	O
the	O
highest	O
scoring	O
proposal	O
and	O
its	O
spatially	O
adjacent	O
proposals	O
to	O
be	O
the	O
same	O
.	O
	
Unlike	O
this	O
,	O
we	O
show	O
that	O
finding	O
proposal	O
cluster	O
centers	O
using	O
graph	B-Method
and	O
treating	O
proposal	B-Method
clusters	I-Method
as	O
bags	O
are	O
more	O
effective	O
.	O
	
The	O
contemporary	O
work	O
uses	O
a	O
graph	B-Method
model	I-Method
to	O
generate	O
seed	O
proposals	O
.	O
	
Their	O
network	B-Method
training	I-Method
has	O
many	O
steps	O
:	O
first	O
,	O
an	O
MIL	B-Method
network	O
is	O
trained	O
;	O
second	O
,	O
seed	O
proposals	O
are	O
generated	O
using	O
the	O
graph	O
;	O
third	O
,	O
based	O
on	O
these	O
seed	O
proposals	O
,	O
a	O
Fast	O
R	O
-	O
CNN	B-Method
like	O
detector	O
is	O
trained	O
.	O
	
Our	O
method	O
differs	O
from	O
in	O
many	O
aspects	O
:	O
first	O
,	O
we	O
propose	O
to	O
generate	O
proposal	O
clusters	O
for	O
each	O
training	O
iteration	O
and	O
thus	O
our	O
network	O
is	O
trained	O
end	O
-	O
to	O
-	O
end	O
instead	O
of	O
step	O
-	O
by	O
-	O
step	O
,	O
which	O
is	O
more	O
efficient	O
and	O
can	O
benefit	O
from	O
sharing	O
proposal	O
features	O
among	O
different	O
streams	O
;	O
second	O
,	O
we	O
propose	O
to	O
treat	O
proposal	O
clusters	O
as	O
bags	O
for	O
training	O
better	O
classifiers	B-Task
.	O
	
As	O
evidenced	O
by	O
experiments	O
,	O
our	O
method	O
obtains	O
much	O
better	O
and	O
more	O
robust	O
results	O
.	O
	
subsection	O
:	O
End	O
-	O
to	O
-	O
end	O
and	O
its	O
variants	O
	
In	O
standard	O
end	B-Task
-	I-Task
to	I-Task
-	I-Task
end	I-Task
training	I-Task
,	O
the	O
update	O
requires	O
optimizing	O
losses	O
w.r.t	O
.	O
	
all	O
functions	O
of	O
network	O
parameters	O
.	O
	
For	O
example	O
,	O
the	O
Fast	B-Method
R	I-Method
-	I-Method
CNN	I-Method
optimizes	O
their	O
classification	B-Metric
loss	I-Metric
and	O
boundingbox	B-Method
regression	I-Method
loss	I-Method
w.r.t	O
.	O
proposal	B-Task
classification	I-Task
and	O
feature	B-Task
extraction	I-Task
for	O
fully	B-Task
supervised	I-Task
object	I-Task
detection	I-Task
.	O
	
The	O
MIL	B-Method
networks	I-Method
in	O
optimize	O
their	O
MIL	B-Method
loss	O
w.r.t	O
.	O
proposal	B-Task
classification	I-Task
and	O
feature	B-Task
extraction	I-Task
for	O
WSOD	B-Task
.	O
	
Unlike	O
the	O
standard	O
end	B-Method
-	I-Method
to	I-Method
-	I-Method
end	I-Method
training	I-Method
,	O
there	O
exists	O
a	O
variant	O
of	O
end	B-Method
-	I-Method
to	I-Method
-	I-Method
end	I-Method
training	I-Method
.	O
	
The	O
variant	O
contains	O
functions	O
which	O
depend	O
on	O
network	O
parameters	O
,	O
but	O
losses	O
are	O
not	O
optimized	O
w.r.t	O
.	O
	
all	O
these	O
functions	O
.	O
	
As	O
we	O
described	O
in	O
Section	O
[	O
reference	O
]	O
,	O
the	O
“	O
spatial	B-Method
regulariser	I-Method
”	O
in	O
forces	O
features	O
of	O
the	O
highest	O
scoring	O
proposal	O
and	O
its	O
spatially	O
adjacent	O
proposals	O
to	O
be	O
the	O
same	O
.	O
	
They	O
use	O
a	O
function	O
of	O
network	O
parameters	O
to	O
compute	O
the	O
highest	O
scoring	O
proposal	O
,	O
and	O
do	O
not	O
optimize	O
their	O
losses	O
w.r.t	O
.	O
	
this	O
function	O
.	O
	
Diba	O
et	O
al	O
.	O
	
filter	O
out	O
background	O
proposals	O
using	O
a	O
function	O
of	O
network	O
parameters	O
and	O
use	O
these	O
filtered	O
proposals	O
in	O
their	O
latter	O
network	B-Method
computations	I-Method
.	O
	
They	O
also	O
do	O
not	O
optimize	O
their	O
losses	O
w.r.t	O
.	O
	
this	O
function	O
.	O
	
Inspired	O
by	O
,	O
we	O
use	O
this	O
variant	O
of	O
end	B-Task
-	I-Task
to	I-Task
-	I-Task
end	I-Task
training	I-Task
.	O
	
More	O
precisely	O
,	O
we	O
do	O
not	O
optimize	O
our	O
losses	O
w.r.t	O
.	O
	
the	O
generated	O
supervisions	O
for	O
instance	B-Task
classifier	I-Task
refinement	I-Task
.	O
	
subsection	O
:	O
Others	O
	
There	O
are	O
many	O
other	O
important	O
related	O
works	O
that	O
do	O
not	O
focus	O
on	O
weakly	B-Task
supervised	I-Task
learning	I-Task
but	O
should	O
be	O
discussed	O
.	O
	
Similar	O
to	O
other	O
end	O
-	O
to	O
-	O
end	O
MIL	B-Method
networks	I-Method
,	O
our	O
method	O
is	O
built	O
on	O
top	O
of	O
the	O
Region	B-Method
of	I-Method
Interest	I-Method
(	O
RoI	B-Method
)	O
pooling	O
layer	O
or	O
Spatial	B-Method
Pyramid	I-Method
Pooling	I-Method
(	O
SPP	B-Method
)	O
layer	O
to	O
share	O
convolutional	B-Method
computations	O
among	O
different	O
proposals	O
for	O
model	B-Task
acceleration	I-Task
.	O
	
But	O
both	O
and	O
require	O
boundingbox	O
-	O
level	O
annotations	O
to	O
train	O
their	O
detectors	O
.	O
	
The	O
sharing	B-Method
proposal	I-Method
feature	I-Method
strategy	I-Method
in	O
our	O
network	O
is	O
similar	O
to	O
multi	B-Task
-	I-Task
task	I-Task
learning	I-Task
.	O
	
Unlike	O
the	O
multi	B-Method
-	I-Method
task	I-Method
learning	I-Method
that	O
each	O
output	O
stream	O
has	O
their	O
own	O
relatively	O
independent	O
external	O
supervisions	O
for	O
different	O
tasks	O
,	O
in	O
our	O
method	O
,	O
all	O
streams	O
have	O
the	O
same	O
task	O
and	O
supervisions	O
of	O
later	O
streams	O
depend	O
on	O
the	O
outputs	O
from	O
their	O
preceding	O
streams	O
.	O
	
section	O
:	O
Method	O
	
The	O
overall	O
architecture	O
of	O
our	O
method	O
is	O
shown	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
.	O
	
Given	O
an	O
image	O
,	O
about	O
object	O
proposals	O
from	O
Selective	O
Search	O
or	O
EdgeBox	O
are	O
generated	O
.	O
	
During	O
the	O
forward	O
process	O
of	O
training	B-Task
,	O
the	O
image	O
and	O
these	O
proposals	O
are	O
fed	O
into	O
some	O
convolutional	B-Method
(	O
conv	B-Method
)	I-Method
layers	O
with	O
an	O
SPP	B-Method
layer	O
to	O
produce	O
a	O
fixed	O
-	O
size	O
conv	B-Method
feature	I-Method
map	I-Method
per	O
-	O
proposal	O
.	O
	
After	O
that	O
,	O
proposal	O
feature	O
maps	O
are	O
fed	O
into	O
two	O
fully	B-Method
connected	I-Method
(	O
fc	B-Method
)	O
layers	O
to	O
produce	O
proposal	O
features	O
.	O
	
These	O
features	O
are	O
branched	O
into	O
different	O
streams	O
:	O
the	O
first	O
one	O
is	O
an	O
MIL	B-Method
network	O
to	O
train	O
basic	O
instance	B-Method
classifiers	I-Method
and	O
the	O
others	O
refine	O
the	O
classifiers	B-Method
iteratively	O
.	O
	
For	O
each	O
stream	O
,	O
proposal	B-Metric
classification	I-Metric
scores	I-Metric
are	O
obtained	O
and	O
proposal	O
clusters	O
are	O
generated	O
consequently	O
.	O
	
Then	O
based	O
on	O
these	O
proposal	O
clusters	O
,	O
supervisions	O
are	O
generated	O
to	O
compute	O
losses	O
for	O
the	O
next	O
stream	O
.	O
	
During	O
the	O
back	B-Method
-	I-Method
propagation	I-Method
process	I-Method
of	O
training	O
,	O
the	O
network	O
losses	O
are	O
optimized	O
to	O
train	O
proposal	O
features	O
and	O
classifiers	B-Method
.	O
	
As	O
shown	O
in	O
the	O
figure	O
,	O
supervisions	O
of	O
the	O
-	O
st	O
refined	B-Method
classifier	I-Method
depend	O
on	O
the	O
output	O
from	O
the	O
basic	B-Method
classifier	I-Method
,	O
and	O
supervisions	B-Method
of	O
-	O
th	O
refined	B-Method
classifier	I-Method
depend	O
on	O
outputs	O
from	O
-	O
th	O
refined	B-Method
classifier	I-Method
.	O
	
In	O
this	O
section	O
,	O
we	O
will	O
introduce	O
our	O
method	O
of	O
learning	O
refined	B-Task
instance	I-Task
classifiers	I-Task
based	O
on	O
proposal	B-Method
clusters	I-Method
in	O
detail	O
.	O
	
subsection	O
:	O
Notations	O
	
Before	O
presenting	O
our	O
method	O
,	O
we	O
first	O
introduce	O
some	O
of	O
the	O
mostly	O
used	O
notations	O
as	O
follows	O
.	O
	
We	O
have	O
proposals	O
with	O
boxes	O
for	O
an	O
given	O
image	O
and	O
proposal	O
features	O
,	O
where	O
is	O
the	O
-	O
th	O
proposal	O
box	O
.	O
	
The	O
number	O
of	O
refined	O
instance	B-Method
classifiers	I-Method
is	O
(	O
i.e	O
.	O
	
,	O
we	O
refine	O
instance	O
classifier	O
times	O
)	O
,	O
and	O
thus	O
there	O
are	O
streams	O
.	O
	
The	O
number	O
of	O
object	O
classes	O
is	O
.	O
	
and	O
are	O
the	O
parameters	O
of	O
the	O
basic	B-Method
instance	I-Method
classifier	I-Method
and	O
the	O
-	B-Method
th	I-Method
refined	I-Method
instance	I-Method
classifier	I-Method
,	O
respectively	O
.	O
	
and	O
are	O
the	O
predicted	B-Metric
score	I-Metric
matrices	I-Metric
of	O
the	O
basic	B-Method
instance	I-Method
classifier	I-Method
and	O
the	O
-	O
th	O
refined	B-Method
instance	I-Method
classifier	I-Method
,	O
respectively	O
,	O
where	O
indicates	O
the	O
object	O
classes	O
and	O
background	O
class	O
.	O
	
We	O
use	O
later	O
for	O
simplification	O
,	O
dropping	O
the	O
dependence	O
on	O
.	O
	
is	O
the	O
predicted	O
score	O
of	O
the	O
-	O
th	O
proposal	O
for	O
class	O
from	O
the	O
-	O
th	O
instance	B-Method
classifier	I-Method
.	O
	
is	O
the	O
image	O
label	O
vector	O
,	O
where	O
or	O
indicates	O
the	O
image	O
with	O
or	O
without	O
object	O
class	O
.	O
	
is	O
the	O
supervision	O
of	O
the	O
-	B-Method
th	I-Method
instance	I-Method
classifier	I-Method
,	O
where	O
is	O
the	O
image	O
label	O
vector	O
.	O
	
is	O
the	O
loss	O
function	O
to	O
train	O
the	O
-	B-Method
th	I-Method
instance	I-Method
classifier	I-Method
.	O
	
We	O
compute	O
proposal	O
cluster	O
centers	O
for	O
the	O
-	B-Method
th	I-Method
refinement	I-Method
.	O
	
The	O
-	O
th	O
cluster	O
center	O
consists	O
of	O
a	O
proposal	O
box	O
,	O
an	O
object	O
label	O
(	O
indicates	O
the	O
-	O
th	O
object	O
class	O
)	O
,	O
and	O
a	O
confidence	O
score	O
indicating	O
the	O
confidence	O
that	O
covers	O
at	O
least	O
part	O
of	O
an	O
object	O
of	O
class	O
.	O
	
We	O
have	O
proposal	O
clusters	O
according	O
to	O
(	O
for	O
background	O
and	O
others	O
for	O
objects	O
)	O
.	O
	
For	O
object	B-Task
clusters	I-Task
,	O
the	O
-	O
th	O
cluster	O
consists	O
of	O
proposal	O
boxes	O
,	O
an	O
object	O
label	O
that	O
is	O
the	O
same	O
as	O
the	O
cluster	O
center	O
label	O
,	O
and	O
a	O
confidence	B-Metric
score	I-Metric
that	O
is	O
the	O
same	O
as	O
the	O
cluster	O
center	O
score	O
,	O
where	O
indicates	O
the	O
confidence	O
that	O
corresponds	O
to	O
an	O
object	O
of	O
class	O
.	O
	
Unlike	O
object	B-Method
clusters	I-Method
,	O
the	O
background	O
cluster	O
consists	O
of	O
proposals	O
and	O
a	O
label	O
indicating	O
the	O
background	O
.	O
	
The	O
-	O
th	O
proposal	O
consists	O
of	O
a	O
proposal	O
box	O
and	O
a	O
confidence	O
score	O
indicating	O
the	O
confidence	O
that	O
is	O
the	O
background	O
.	O
	
subsection	O
:	O
Basic	O
MIL	B-Method
network	O
	
It	O
is	O
necessary	O
to	O
generate	O
proposal	O
scores	O
and	O
clusters	O
to	O
supervise	O
refined	O
instance	B-Method
classifiers	I-Method
.	O
	
More	O
specifically	O
,	O
the	O
first	O
refined	O
classifier	B-Method
requires	O
basic	O
instance	B-Method
classifiers	I-Method
to	O
generate	O
proposal	O
scores	O
and	O
clusters	O
.	O
	
Therefore	O
,	O
we	O
first	O
introduce	O
our	O
basic	O
MIL	B-Method
network	O
as	O
the	O
basic	O
instance	B-Method
classifier	I-Method
.	O
	
Our	O
overall	O
network	O
is	O
independent	O
of	O
the	O
specific	O
MIL	B-Method
methods	O
,	O
and	O
thus	O
any	O
method	O
that	O
can	O
be	O
trained	O
end	O
-	O
to	O
-	O
end	O
could	O
be	O
used	O
.	O
	
There	O
are	O
many	O
possible	O
choices	O
.	O
	
Here	O
we	O
choose	O
the	O
method	O
by	O
Bilen	O
and	O
Vedaldi	O
which	O
proposes	O
a	O
weighted	B-Method
sum	I-Method
pooling	I-Method
strategy	I-Method
to	O
obtain	O
the	O
instance	B-Method
classifier	I-Method
,	O
because	O
of	O
its	O
effectiveness	O
and	O
implementation	O
convenience	O
.	O
	
To	O
make	O
our	O
paper	O
self	O
-	O
contained	O
,	O
we	O
briefly	O
introduce	O
as	O
follows	O
.	O
	
Given	O
an	O
input	O
image	O
and	O
its	O
proposal	O
boxes	O
,	O
a	O
set	O
of	O
proposal	O
features	O
are	O
first	O
generated	O
by	O
the	O
network	O
.	O
	
Then	O
as	O
shown	O
in	O
the	O
“	O
Basic	O
MIL	B-Method
network	O
”	O
block	O
of	O
Fig	O
.	O
	
[	O
reference	O
]	O
	
,	O
there	O
are	O
two	O
branches	O
which	O
process	O
the	O
proposal	O
features	O
to	O
produce	O
two	O
matrices	O
(	O
we	O
use	O
later	O
for	O
simplification	O
,	O
dropping	O
the	O
dependence	O
on	O
)	O
of	O
an	O
input	O
image	O
by	O
two	O
fc	B-Method
layers	O
,	O
where	O
and	O
denote	O
the	O
parameters	O
of	O
the	O
fc	B-Method
layer	O
for	O
and	O
the	O
parameters	O
of	O
the	O
fc	B-Method
layer	O
for	O
,	O
respectively	O
.	O
	
Then	O
the	O
two	O
matrices	O
are	O
passed	O
through	O
two	O
softmax	B-Method
layer	I-Method
along	O
different	O
directions	O
:	O
and	O
.	O
	
Let	O
us	O
denote	O
by	O
.	O
	
The	O
proposal	O
scores	O
are	O
generated	O
by	O
element	B-Method
-	I-Method
wise	I-Method
product	I-Method
.	O
	
Finally	O
,	O
the	O
image	B-Metric
score	I-Metric
of	O
the	O
-	O
th	O
class	O
is	O
obtained	O
by	O
the	O
sum	O
over	O
all	O
proposals	O
:	O
.	O
	
A	O
simple	O
interpretation	O
of	O
the	O
two	O
branches	B-Method
framework	I-Method
is	O
as	O
follows	O
.	O
	
is	O
the	O
probability	O
of	O
the	O
-	O
th	O
proposal	O
belonging	O
to	O
class	O
.	O
	
is	O
the	O
normalized	O
weight	O
that	O
indicates	O
the	O
contribution	O
of	O
the	O
-	O
th	O
proposal	O
to	O
image	O
being	O
classified	O
to	O
class	O
.	O
	
So	O
is	O
obtained	O
by	O
weighted	B-Method
sum	I-Method
pooling	I-Method
and	O
falls	O
in	O
the	O
range	O
of	O
.	O
	
Given	O
the	O
image	O
label	O
vector	O
.	O
	
We	O
train	O
the	O
basic	O
instance	B-Method
classifier	I-Method
by	O
optimizing	O
the	O
multi	B-Metric
-	I-Metric
class	I-Metric
cross	I-Metric
entropy	I-Metric
loss	I-Metric
Eq	I-Metric
.	O
	
(	O
[	O
reference	O
]	O
)	O
	
w.r.t	O
.	O
.	O
	
subsection	O
:	O
The	O
overall	O
training	B-Method
strategy	I-Method
	
To	O
refine	O
instance	B-Method
classifiers	I-Method
iteratively	O
,	O
we	O
add	O
multiple	O
output	O
streams	O
in	O
our	O
network	O
where	O
each	O
stream	O
corresponds	O
to	O
a	O
refined	O
classifier	O
,	O
as	O
shown	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
.	O
	
We	O
integrate	O
the	O
basic	O
MIL	B-Method
network	O
and	O
the	O
classifier	B-Method
refinement	I-Method
into	O
an	O
end	B-Method
-	I-Method
to	I-Method
-	I-Method
end	I-Method
network	I-Method
to	O
learn	O
the	O
refined	O
classifier	B-Method
online	O
.	O
	
Unlike	O
the	O
basic	O
instance	B-Method
classifier	I-Method
,	O
for	O
an	O
input	O
image	O
the	O
output	O
score	O
matrix	O
of	O
the	O
-	B-Method
th	I-Method
refined	I-Method
classifier	I-Method
is	O
a	O
matrix	O
and	O
is	O
obtained	O
by	O
passing	O
the	O
proposal	O
features	O
through	O
a	O
single	O
fc	B-Method
layer	O
(	O
with	O
parameters	O
)	O
as	O
well	O
as	O
a	O
softmax	B-Method
over	I-Method
-	I-Method
classes	I-Method
layer	I-Method
,	O
i.e	O
.	O
,	O
,	O
as	O
in	O
the	O
“	O
Instance	B-Method
classifier	I-Method
refinement	I-Method
”	O
blocks	O
of	O
Fig	O
.	O
	
[	O
reference	O
]	O
.	O
	
Notice	O
that	O
we	O
use	O
the	O
same	O
proposal	O
features	O
for	O
all	O
classifiers	B-Method
.	O
	
We	O
use	O
later	O
for	O
simplification	O
,	O
dropping	O
the	O
dependence	O
on	O
.	O
	
As	O
we	O
stated	O
before	O
,	O
supervisions	O
to	O
train	O
the	O
-	B-Method
th	I-Method
instance	I-Method
classifier	I-Method
are	O
generated	O
based	O
on	O
proposal	O
scores	O
and	O
image	O
label	O
.	O
	
Thus	O
we	O
denote	O
the	O
supervisions	O
by	O
.	O
	
Then	O
we	O
train	O
our	O
overall	O
network	O
by	O
optimizing	O
the	O
loss	B-Metric
Eq	I-Metric
.	O
	
(	O
[	O
reference	O
]	O
)	O
	
w.r.t	O
.	O
.	O
	
We	O
do	O
not	O
optimize	O
the	O
loss	O
w.r.t	O
.	O
,	O
which	O
means	O
that	O
the	O
supervisions	O
are	O
only	O
computed	O
in	O
the	O
forward	O
process	O
and	O
we	O
do	O
not	O
compute	O
their	O
gradients	O
to	O
train	O
our	O
network	O
.	O
	
The	O
loss	O
for	O
the	O
-	O
th	O
refined	B-Method
instance	I-Method
classifier	I-Method
is	O
defined	O
in	O
later	O
Eq	O
.	O
	
(	O
[	O
reference	O
]	O
)	O
/	O
(	O
[	O
reference	O
]	O
)	O
/	O
(	O
[	O
reference	O
]	O
)	O
which	O
are	O
loss	O
functions	O
with	O
supervisions	O
provided	O
by	O
.	O
	
We	O
will	O
give	O
details	O
about	O
how	O
to	O
get	O
supervisions	O
and	O
loss	O
functions	O
in	O
Section	O
[	O
reference	O
]	O
.	O
	
[	O
t	O
]	O
	
The	O
overall	O
training	O
procedure	O
(	O
one	O
iteration	O
)	O
	
[	O
1	O
]	O
An	O
image	O
,	O
its	O
proposal	O
boxes	O
,	O
and	O
its	O
image	O
label	O
vector	O
;	O
refinement	O
times	O
.	O
	
An	O
updated	O
network	O
.	O
	
Feed	O
the	O
image	O
and	O
into	O
the	O
network	O
to	O
produce	O
proposal	O
score	O
matrices	O
(	O
simplified	O
as	O
later	O
)	O
.	O
	
Compute	O
loss	O
by	O
Eq	O
.	O
	
(	O
[	O
reference	O
]	O
)	O
,	O
see	O
Section	O
[	O
reference	O
]	O
.	O
	
Generate	O
supervisions	O
,	O
see	O
Section	O
[	O
reference	O
]	O
.	O
	
Compute	O
loss	O
by	O
Eq	O
.	O
	
(	O
[	O
reference	O
]	O
)	O
/	O
(	O
[	O
reference	O
]	O
)	O
/	O
(	O
[	O
reference	O
]	O
)	O
,	O
see	O
Section	O
[	O
reference	O
]	O
.	O
	
Optimize	B-Task
,	O
i.e	O
.	O
,	O
Eq	O
.	O
	
(	O
[	O
reference	O
]	O
)	O
,	O
	
w.r.t	O
.	O
	
(	O
not	O
w.r.t	O
.	O
)	O
.	O
	
During	O
the	O
forward	O
process	O
of	O
each	O
Stochastic	B-Method
Gradient	I-Method
Descent	I-Method
(	O
SGD	B-Method
)	O
training	O
iteration	O
,	O
we	O
obtain	O
a	O
set	O
of	O
proposal	O
scores	O
of	O
an	O
input	O
image	O
.	O
	
Accordingly	O
,	O
we	O
generate	O
the	O
supervisions	O
for	O
the	O
iteration	O
to	O
compute	O
the	O
loss	O
Eq	O
.	O
	
(	O
[	O
reference	O
]	O
)	O
.	O
	
During	O
the	O
back	B-Method
-	I-Method
propagation	I-Method
process	I-Method
of	O
each	O
SGD	B-Method
training	O
iteration	O
,	O
we	O
optimize	O
the	O
loss	O
Eq	O
.	O
	
(	O
[	O
reference	O
]	O
)	O
	
w.r.t	O
.	O
	
proposal	B-Method
features	I-Method
and	O
classifiers	B-Method
.	O
	
We	O
summarize	O
this	O
procedure	O
in	O
Algorithm	O
[	O
reference	O
]	O
.	O
	
Note	O
that	O
we	O
do	O
not	O
use	O
an	O
alternating	B-Method
training	I-Method
strategy	I-Method
,	O
i.e	O
.	O
,	O
fixing	O
supervisions	O
and	O
training	O
a	O
complete	B-Method
model	I-Method
,	O
fixing	O
the	O
model	O
and	O
updating	O
supervisions	O
.	O
	
The	O
reasons	O
are	O
that	O
:	O
1	O
)	O
it	O
is	O
very	O
time	O
-	O
consuming	O
because	O
it	O
requires	O
training	O
models	O
multiple	O
times	O
;	O
2	O
)	O
training	O
different	O
models	O
in	O
different	O
refinement	O
steps	O
separately	O
may	O
harm	O
the	O
performance	O
because	O
it	O
hinders	O
the	O
process	O
to	O
benefit	O
from	O
the	O
shared	O
proposal	O
features	O
(	O
i.e	O
.	O
,	O
)	O
.	O
	
subsection	O
:	O
Proposal	B-Method
cluster	I-Method
learning	I-Method
	
Here	O
we	O
will	O
introduce	O
our	O
methods	O
to	O
learn	O
refined	B-Method
instance	I-Method
classifiers	I-Method
based	O
on	O
proposal	B-Method
clusters	I-Method
(	O
i.e	O
.	O
,	O
proposal	B-Method
cluster	I-Method
learning	I-Method
)	O
.	O
	
Recall	O
from	O
Section	O
[	O
reference	O
]	O
that	O
we	O
have	O
a	O
set	O
of	O
proposals	O
with	O
boxes	O
.	O
	
For	O
the	O
-	B-Task
th	I-Task
refinement	I-Task
,	O
our	O
goal	O
is	O
to	O
generate	O
supervisions	O
for	O
the	O
loss	O
functions	O
using	O
the	O
proposal	O
scores	O
and	O
image	O
label	O
in	O
each	O
training	O
iteration	O
.	O
	
We	O
use	O
later	O
for	O
simplification	O
,	O
dropping	O
the	O
dependence	O
on	O
.	O
	
We	O
do	O
this	O
in	O
three	O
steps	O
.	O
	
1	O
)	O
We	O
find	O
proposal	O
cluster	O
centers	O
which	O
are	O
proposals	O
corresponding	O
to	O
different	O
objects	O
.	O
	
2	O
)	O
	
We	O
group	O
the	O
remaining	O
proposals	O
into	O
different	O
clusters	O
,	O
where	O
each	O
cluster	O
is	O
associated	O
with	O
a	O
cluster	O
center	O
or	O
corresponds	O
to	O
the	O
background	O
.	O
	
3	O
)	O
	
We	O
generate	O
the	O
supervisions	O
for	O
the	O
loss	O
functions	O
,	O
enabling	O
us	O
to	O
train	O
the	O
refined	O
instance	B-Method
classifiers	I-Method
.	O
	
For	O
the	O
first	O
step	O
,	O
we	O
compute	O
proposal	O
cluster	O
centers	O
based	O
on	O
and	O
.	O
	
The	O
-	O
th	O
cluster	O
center	O
is	O
defined	O
in	O
Section	O
[	O
reference	O
]	O
.	O
	
We	O
propose	O
two	O
algorithms	O
to	O
find	O
in	O
Section	O
[	O
reference	O
]	O
(	O
1	O
)	O
and	O
(	O
2	O
)	O
(	O
also	O
Algorithm	O
[	O
reference	O
]	O
and	O
Algorithm	O
[	O
reference	O
]	O
)	O
,	O
where	O
the	O
first	O
one	O
was	O
proposed	O
in	O
the	O
conference	O
version	O
paper	O
and	O
the	O
second	O
one	O
is	O
proposed	O
in	O
this	O
paper	O
.	O
	
For	O
the	O
second	O
step	O
,	O
according	O
to	O
the	O
proposal	O
cluster	O
centers	O
,	O
proposal	O
clusters	O
are	O
generated	O
(	O
for	O
background	O
and	O
others	O
for	O
objects	O
)	O
.	O
	
The	O
-	B-Method
th	I-Method
object	I-Method
cluster	I-Method
and	O
the	O
background	O
cluster	O
are	O
defined	O
in	O
Section	O
[	O
reference	O
]	O
.	O
	
We	O
use	O
the	O
different	O
notation	O
for	O
the	O
background	O
cluster	O
because	O
background	O
proposals	O
are	O
scattered	O
in	O
each	O
image	O
,	O
and	O
thus	O
it	O
is	O
hard	O
to	O
determine	O
a	O
cluster	O
center	O
and	O
accordingly	O
a	O
cluster	O
score	O
.	O
	
The	O
method	O
to	O
generate	O
was	O
proposed	O
in	O
the	O
conference	O
version	O
paper	O
and	O
is	O
described	O
in	O
Section	O
[	O
reference	O
]	O
(	O
also	O
Algorithm	O
[	O
reference	O
]	O
)	O
.	O
	
For	O
the	O
third	O
step	O
,	O
supervisions	O
to	O
train	O
the	O
-	O
th	O
refined	B-Method
instance	I-Method
classifier	I-Method
are	O
generated	O
based	O
on	O
the	O
proposal	O
clusters	O
.	O
	
We	O
use	O
two	O
strategies	O
where	O
are	O
either	O
proposal	O
-	O
level	O
labels	O
indicating	O
whether	O
a	O
proposal	O
belongs	O
to	O
an	O
object	O
class	O
,	O
or	O
cluster	O
-	O
level	O
labels	O
that	O
treats	O
each	O
proposal	O
cluster	O
as	O
a	O
bag	O
.	O
	
Subsequently	O
these	O
are	O
used	O
to	O
compute	O
the	O
loss	B-Method
functions	I-Method
.	O
	
We	O
propose	O
two	O
approaches	O
to	O
do	O
this	O
as	O
described	O
in	O
Section	O
[	O
reference	O
]	O
(	O
1	O
)	O
and	O
(	O
2	O
)	O
,	O
where	O
the	O
first	O
one	O
was	O
proposed	O
in	O
the	O
conference	O
version	O
paper	O
and	O
the	O
second	O
one	O
is	O
proposed	O
in	O
this	O
paper	O
.	O
	
subsubsection	B-Method
:	O
Finding	O
proposal	B-Method
cluster	I-Method
centers	I-Method
	
In	O
the	O
following	O
we	O
introduce	O
two	O
algorithms	O
to	O
find	O
proposal	O
cluster	O
centers	O
.	O
	
[	O
t	O
]	O
Finding	O
proposal	O
cluster	O
centers	O
using	O
the	O
highest	O
scoring	O
proposal	O
[	O
1	O
]	O
Proposal	O
boxes	O
;	O
image	O
label	O
vector	O
;	O
proposal	O
score	O
matrix	O
.	O
	
Proposal	B-Method
cluster	I-Method
centers	I-Method
.	O
	
Initialize	O
.	O
	
Choose	O
the	O
-	O
th	O
proposal	O
by	O
Eq	O
.	O
	
(	O
[	O
reference	O
]	O
)	O
.	O
.	O
	
(	O
1	O
)	O
Finding	O
proposal	O
cluster	O
centers	O
using	O
the	O
highest	O
scoring	O
proposal	O
.	O
	
A	O
solution	O
for	O
finding	O
proposal	O
cluster	O
centers	O
is	O
to	O
choose	O
the	O
highest	O
scoring	O
proposal	O
,	O
as	O
in	O
our	O
conference	O
version	O
paper	O
.	O
	
As	O
in	O
Algorithm	O
[	O
reference	O
]	O
,	O
suppose	O
an	O
image	O
has	O
object	O
class	O
label	O
(	O
i.e	O
.	O
,	O
)	O
.	O
	
For	O
the	O
-	O
th	O
refinement	O
,	O
we	O
first	O
select	O
the	O
-	O
th	O
proposal	O
which	O
has	O
the	O
highest	O
score	O
by	O
Eq	O
.	O
	
(	O
[	O
reference	O
]	O
)	O
,	O
where	O
is	O
the	O
predicted	O
score	O
of	O
the	O
-	O
th	O
proposal	O
,	O
as	O
defined	O
in	O
Section	O
[	O
reference	O
]	O
.	O
	
Then	O
this	O
proposal	O
is	O
chosen	O
as	O
the	O
cluster	O
center	O
,	O
i.e	O
.	O
,	O
,	O
where	O
is	O
the	O
box	O
of	O
the	O
-	O
th	O
proposal	O
.	O
	
is	O
chosen	O
as	O
the	O
confidence	O
score	O
that	O
the	O
-	O
th	O
proposal	O
covers	O
at	O
least	O
part	O
of	O
an	O
object	O
of	O
class	O
,	O
because	O
is	O
	
the	O
predicted	O
score	O
of	O
the	O
-	O
th	O
proposal	O
been	O
categorized	O
to	O
class	O
.	O
	
Therefore	O
,	O
the	O
highest	O
scoring	O
proposal	O
can	O
probably	O
cover	O
at	O
least	O
part	O
of	O
the	O
object	O
and	O
thus	O
be	O
chosen	O
as	O
the	O
cluster	O
center	O
.	O
	
There	O
is	O
a	O
potential	O
problem	O
that	O
one	O
proposal	O
may	O
be	O
chosen	O
as	O
the	O
cluster	O
centers	O
for	O
multiple	O
object	O
classes	O
.	O
	
To	O
avoid	O
this	O
problem	O
,	O
if	O
one	O
proposal	O
corresponds	O
to	O
the	O
cluster	O
centers	O
for	O
multiple	O
object	O
classes	O
,	O
this	O
proposal	O
would	O
be	O
chosen	O
as	O
the	O
cluster	O
center	O
only	O
by	O
the	O
class	O
with	O
the	O
highest	O
predicted	O
score	O
and	O
we	O
re	O
-	O
choose	O
cluster	O
centers	O
for	O
other	O
classes	O
.	O
	
(	O
2	O
)	O
Finding	O
proposal	O
cluster	O
centers	O
using	O
graphs	O
of	O
top	O
ranking	O
proposals	O
.	O
	
As	O
stated	O
in	O
Section	O
[	O
reference	O
]	O
,	O
although	O
we	O
can	O
find	O
good	O
proposal	O
cluster	O
centers	O
using	O
the	O
highest	O
scoring	O
proposal	O
,	O
this	O
ignores	O
that	O
in	O
natural	O
images	O
there	O
are	O
often	O
more	O
than	O
one	O
object	O
for	O
each	O
category	O
.	O
	
Therefore	O
,	O
we	O
propose	O
a	O
new	O
method	O
to	O
find	O
cluster	O
centers	O
using	O
graphs	O
of	O
top	O
ranking	O
proposals	O
.	O
	
[	O
t	O
]	O
Finding	O
proposal	O
cluster	O
centers	O
using	O
graphs	O
of	O
top	O
ranking	O
proposals	O
[	O
1	O
]	O
Proposal	O
boxes	O
;	O
image	O
label	O
vector	O
;	O
proposal	O
score	O
matrix	O
.	O
	
Proposal	B-Method
cluster	I-Method
centers	I-Method
.	O
	
Initialize	O
.	O
	
Select	O
top	O
ranking	O
proposals	O
with	O
indexes	O
.	O
	
Build	O
a	O
graph	O
using	O
the	O
top	O
ranking	O
proposals	O
.	O
	
Set	O
.	O
	
Set	O
.	O
.	O
	
Remove	O
the	O
-	O
th	O
proposal	O
box	O
from	O
,	O
or	O
.	O
is	O
empty	O
.	O
	
More	O
specifically	O
,	O
suppose	O
an	O
image	O
has	O
object	O
class	O
label	O
.	O
	
We	O
first	O
select	O
the	O
top	O
ranking	O
proposals	O
with	O
indexes	O
for	O
the	O
-	O
th	O
refinement	O
.	O
	
Then	O
we	O
build	O
an	O
undirected	O
unweighted	O
graph	O
of	O
these	O
proposals	O
based	O
on	O
spatial	O
similarity	O
,	O
where	O
vertexes	O
correspond	O
to	O
these	O
top	O
ranking	O
proposals	O
,	O
and	O
edges	O
correspond	O
to	O
the	O
connections	O
between	O
the	O
vertexes	O
.	O
	
is	O
determined	O
according	O
to	O
the	O
spatial	O
similarity	O
between	O
two	O
vertexes	O
(	O
i.e	O
.	O
,	O
proposals	O
)	O
as	O
in	O
Eq	O
.	O
	
(	O
[	O
reference	O
]	O
)	O
,	O
where	O
is	O
the	O
IoU	B-Metric
between	O
the	O
-	O
th	O
and	O
-	O
th	O
proposals	O
and	O
is	O
a	O
threshold	O
(	O
e.g	O
.	O
,	O
)	O
.	O
	
Therefore	O
,	O
two	O
vertexes	O
are	O
connected	O
if	O
they	O
are	O
spatially	O
adjacent	O
.	O
	
After	O
that	O
,	O
we	O
greedily	O
generate	O
some	O
cluster	O
centers	O
for	O
class	O
using	O
this	O
graph	O
.	O
	
That	O
is	O
,	O
we	O
iteratively	O
select	O
vertexes	O
which	O
have	O
most	O
connections	O
to	O
be	O
the	O
cluster	O
centers	O
,	O
as	O
in	O
Algorithm	O
[	O
reference	O
]	O
.	O
	
The	O
number	O
of	O
cluster	O
centers	O
(	O
i.e	O
.	O
,	O
)	O
changes	O
for	O
each	O
image	O
in	O
each	O
training	O
iteration	O
because	O
the	O
top	O
ranking	O
proposals	O
change	O
.	O
	
See	O
Section	O
[	O
reference	O
]	O
for	O
some	O
typical	O
values	O
of	O
.	O
	
We	O
use	O
the	O
same	O
method	O
as	O
in	O
Section	O
[	O
reference	O
]	O
	
(	O
1	O
)	O
to	O
avoid	O
one	O
proposal	O
been	O
chosen	O
as	O
the	O
cluster	O
centers	O
for	O
multiple	O
object	O
classes	O
.	O
	
The	O
reasons	O
for	O
this	O
strategy	O
are	O
as	O
follows	O
.	O
	
First	O
,	O
according	O
to	O
our	O
observation	O
,	O
the	O
top	O
ranking	O
proposals	O
can	O
always	O
cover	O
at	O
least	O
parts	O
of	O
objects	O
,	O
thus	O
generating	O
centers	O
from	O
these	O
proposals	O
encourages	O
the	O
selected	O
centers	O
to	O
meet	O
our	O
requirements	O
.	O
	
Second	O
,	O
because	O
these	O
proposals	O
cover	O
objects	O
well	O
,	O
better	O
proposals	O
(	O
covering	O
more	O
parts	O
of	O
objects	O
)	O
should	O
have	O
more	O
spatially	O
overlapped	O
proposals	O
(	O
i.e	O
.	O
,	O
have	O
more	O
connections	O
)	O
.	O
	
Third	O
,	O
these	O
centers	O
are	O
spatially	O
far	O
apart	O
,	O
and	O
thus	O
different	O
centers	O
can	O
correspond	O
to	O
different	O
objects	O
.	O
	
This	O
method	O
also	O
has	O
the	O
attractive	O
characteristic	O
that	O
it	O
can	O
generate	O
adaptive	O
number	O
of	O
proposals	O
for	O
each	O
object	O
class	O
,	O
which	O
is	O
desirable	O
because	O
in	O
natural	O
images	O
there	O
are	O
arbitrary	O
number	O
of	O
objects	O
per	O
-	O
class	O
.	O
	
We	O
set	O
the	O
score	O
of	O
the	O
-	O
th	O
proposal	O
cluster	O
center	O
by	O
(	O
see	O
the	O
-	O
th	O
line	O
in	O
Algorithm	O
[	O
reference	O
]	O
)	O
because	O
if	O
the	O
adjacent	O
proposals	O
of	O
a	O
center	O
proposal	O
have	O
high	O
confidence	O
to	O
cover	O
at	O
least	O
part	O
of	O
an	O
object	O
(	O
i.e	O
.	O
,	O
have	O
high	O
classification	O
scores	O
)	O
the	O
center	B-Method
proposal	I-Method
should	O
also	O
have	O
such	O
high	O
confidence	O
.	O
	
There	O
is	O
an	O
important	O
issue	O
for	O
the	O
graph	B-Method
-	I-Method
based	I-Method
method	I-Method
:	O
how	O
to	O
select	O
the	O
top	O
ranking	O
proposals	O
?	O
	
A	O
simple	O
method	O
is	O
to	O
select	O
proposals	O
whose	O
scores	O
exceed	O
a	O
threshold	O
.	O
	
But	O
in	O
our	O
case	O
,	O
proposal	O
scores	O
change	O
in	O
each	O
training	O
iteration	O
,	O
and	O
thus	O
it	O
is	O
hard	O
to	O
determine	O
a	O
threshold	O
.	O
	
Instead	O
,	O
for	O
each	O
positive	O
object	O
class	O
,	O
we	O
use	O
the	O
-	B-Method
means	I-Method
algorithm	I-Method
to	O
divide	O
proposal	O
scores	O
of	O
an	O
image	O
into	O
some	O
clusters	O
,	O
and	O
choose	O
proposals	O
in	O
the	O
cluster	O
which	O
has	O
the	O
highest	O
score	O
center	O
to	O
form	O
the	O
top	O
ranking	O
proposals	O
.	O
	
This	O
method	O
ensures	O
that	O
we	O
can	O
select	O
the	O
top	O
ranking	O
proposals	O
although	O
proposal	O
scores	O
change	O
during	O
training	O
.	O
	
Other	O
choices	O
are	O
possible	O
,	O
but	O
this	O
method	O
works	O
well	O
in	O
experiments	O
.	O
	
[	O
t	O
]	O
Generating	O
proposal	O
clusters	O
[	O
1	O
]	O
Proposal	O
boxes	O
;	O
proposal	O
cluster	O
centers	O
.	O
	
Proposal	B-Method
clusters	I-Method
.	O
	
Initialize	O
.	O
	
Set	O
of	O
to	O
of	O
,	O
.	O
	
Initialize	O
and	O
set	O
.	O
	
Compute	O
IoUs	B-Method
.	O
	
Choose	O
the	O
most	O
spatially	O
adjacent	O
center	O
.	O
.	O
.	O
	
subsubsection	B-Method
:	O
Generating	O
proposal	B-Method
clusters	I-Method
	
After	O
the	O
cluster	O
centers	O
are	O
found	O
,	O
we	O
generate	O
the	O
proposal	O
clusters	O
as	O
in	O
our	O
conference	O
version	O
paper	O
.	O
	
Except	O
for	O
the	O
cluster	O
for	O
background	O
,	O
good	O
proposal	O
clusters	O
require	O
that	O
proposals	O
in	O
the	O
same	O
cluster	O
are	O
associated	O
with	O
the	O
same	O
object	O
,	O
and	O
thus	O
proposals	O
in	O
the	O
same	O
cluster	O
should	O
be	O
spatially	O
adjacent	O
.	O
	
Specially	O
,	O
given	O
the	O
-	O
th	O
proposal	O
,	O
we	O
compute	O
a	O
set	O
of	O
IoUs	O
,	O
where	O
is	O
the	O
IoU	B-Metric
between	O
the	O
-	O
th	O
proposal	O
and	O
the	O
box	O
of	O
the	O
-	O
th	O
cluster	O
center	O
.	O
	
Then	O
we	O
assign	O
the	O
-	O
th	O
proposal	O
to	O
the	O
-	O
th	O
object	O
cluster	O
if	O
is	O
larger	O
than	O
a	O
threshold	O
(	O
e.g	O
.	O
,	O
)	O
and	O
to	O
the	O
background	O
cluster	O
otherwise	O
,	O
where	O
is	O
the	O
index	O
of	O
the	O
most	O
spatially	O
adjacent	O
cluster	O
center	O
as	O
Eq	O
.	O
	
(	O
[	O
reference	O
]	O
)	O
.	O
	
The	O
overall	O
procedures	O
to	O
generate	O
proposal	O
clusters	O
are	O
summarized	O
in	O
Algorithm	O
[	O
reference	O
]	O
.	O
	
We	O
set	O
the	O
proposal	O
scores	O
for	O
the	O
background	O
cluster	O
to	O
the	O
scores	O
of	O
their	O
most	O
spatially	O
adjacent	O
centers	O
as	O
the	O
10	O
-	O
the	O
line	O
in	O
Algorithm	O
[	O
reference	O
]	O
,	O
because	O
if	O
the	O
cluster	O
center	O
has	O
confidence	O
that	O
it	O
covers	O
an	O
object	O
,	O
the	O
proposal	O
far	O
away	O
from	O
should	O
have	O
confidence	O
to	O
be	O
background	O
.	O
	
subsubsection	B-Method
:	O
Learning	O
refined	O
instance	B-Method
classifiers	I-Method
	
To	O
get	O
supervisions	O
and	O
loss	O
functions	O
to	O
learn	O
the	O
-	O
th	O
refined	B-Method
instance	I-Method
classifier	I-Method
,	O
we	O
design	O
two	O
approaches	O
as	O
follows	O
.	O
	
(	O
1	O
)	O
Assigning	O
proposals	O
object	O
labels	O
.	O
	
The	O
most	O
straightforward	O
way	O
to	O
refine	O
classifiers	B-Method
is	O
to	O
directly	O
assign	O
object	O
labels	O
to	O
all	O
proposals	O
in	O
object	O
clusters	O
because	O
these	O
proposals	O
potentially	O
correspond	O
to	O
whole	O
objects	O
,	O
as	O
in	O
our	O
conference	O
version	O
paper	O
.	O
	
As	O
the	O
cluster	O
centers	O
covers	O
at	O
least	O
parts	O
of	O
objects	O
,	O
their	O
adjacent	O
proposals	O
(	O
i.e	O
.	O
,	O
proposals	O
in	O
the	O
cluster	O
)	O
can	O
contain	O
larger	O
parts	O
of	O
objects	O
.	O
	
Accordingly	O
,	O
we	O
can	O
assign	O
the	O
cluster	O
label	O
to	O
all	O
proposals	O
in	O
the	O
-	O
th	O
cluster	O
.	O
	
More	O
specifically	O
,	O
the	O
supervisions	O
are	O
proposal	O
-	O
level	O
labels	O
,	O
	
i.e	O
.	O
	
,	O
.	O
is	O
the	O
label	O
vector	O
of	O
the	O
-	O
th	O
proposal	O
for	O
the	O
-	O
th	O
refinement	O
,	O
where	O
and	O
if	O
the	O
-	O
th	O
proposal	O
belongs	O
to	O
the	O
-	O
th	O
clusters	O
.	O
	
Consequently	O
,	O
we	O
use	O
the	O
standard	O
softmax	O
loss	O
function	O
to	O
train	O
the	O
refined	B-Method
classifiers	I-Method
as	O
in	O
Eq	O
.	O
	
(	O
[	O
reference	O
]	O
)	O
,	O
where	O
is	O
the	O
predicted	O
score	O
of	O
the	O
-	O
th	O
proposal	O
as	O
defined	O
in	O
Section	O
[	O
reference	O
]	O
.	O
	
Through	O
iterative	B-Method
instance	I-Method
classifier	I-Method
refinement	I-Method
(	O
i.e	O
.	O
,	O
multiple	O
times	O
of	O
refinement	O
as	O
increase	O
)	O
,	O
the	O
detector	O
detects	O
larger	O
parts	O
of	O
objects	O
gradually	O
by	O
forcing	O
the	O
network	O
to	O
“	O
see	O
”	O
larger	O
parts	O
of	O
objects	O
.	O
	
Actually	O
,	O
the	O
so	O
learnt	O
supervisions	O
are	O
very	O
noisy	O
,	O
especially	O
in	O
the	O
beginning	O
of	O
training	O
.	O
	
This	O
results	O
in	O
unstable	O
solutions	O
.	O
	
To	O
solve	O
this	O
problem	O
,	O
we	O
change	O
the	O
loss	O
in	O
Eq	O
.	O
	
(	O
[	O
reference	O
]	O
)	O
to	O
a	O
weighted	B-Method
version	I-Method
,	O
as	O
in	O
Eq	O
.	O
	
(	O
[	O
reference	O
]	O
)	O
.	O
	
is	O
the	O
loss	O
weight	O
that	O
is	O
the	O
same	O
as	O
the	O
cluster	O
confidence	O
score	O
for	O
object	O
clusters	O
or	O
proposal	O
confidence	O
score	O
for	O
the	O
background	O
cluster	O
if	O
the	O
-	O
th	O
proposal	O
belongs	O
to	O
the	O
-	O
th	O
cluster	O
.	O
	
From	O
Algorithm	O
[	O
reference	O
]	O
,	O
we	O
can	O
observe	O
that	O
is	O
the	O
same	O
as	O
the	O
cluster	B-Metric
center	I-Metric
confidence	I-Metric
score	I-Metric
.	O
	
The	O
reasons	O
for	O
this	O
strategy	O
are	O
as	O
follows	O
.	O
	
In	O
the	O
beginning	O
of	O
training	O
,	O
although	O
we	O
can	O
not	O
obtain	O
good	O
proposal	O
clusters	O
,	O
each	O
is	O
small	O
,	O
hence	O
each	O
is	O
small	O
and	O
the	O
loss	O
is	O
also	O
small	O
.	O
	
As	O
a	O
consequence	O
,	O
the	O
performance	O
of	O
the	O
network	O
will	O
not	O
decrease	O
a	O
lot	O
.	O
	
During	O
the	O
training	O
,	O
the	O
top	O
ranking	O
proposals	O
will	O
cover	O
objects	O
well	O
,	O
and	O
thus	O
we	O
can	O
generate	O
good	O
proposal	O
clusters	O
.	O
	
Then	O
we	O
can	O
train	O
satisfactory	O
instance	B-Method
classifiers	I-Method
.	O
	
(	O
2	O
)	O
Treating	O
clusters	O
as	O
bags	O
.	O
	
As	O
we	O
stressed	O
before	O
,	O
although	O
directly	O
assigning	O
proposals	O
object	O
labels	O
can	O
boost	O
the	O
results	O
,	O
it	O
may	O
confuse	O
the	O
network	O
because	O
we	O
simultaneously	O
assign	O
the	O
same	O
label	O
to	O
different	O
parts	O
of	O
objects	O
.	O
	
Focusing	O
on	O
this	O
,	O
we	O
further	O
propose	O
to	O
treat	O
each	O
proposal	O
cluster	O
as	O
a	O
small	O
new	O
bag	O
and	O
use	O
the	O
cluster	O
label	O
as	O
the	O
bag	O
label	O
.	O
	
Thus	O
the	O
supervisions	O
for	O
the	O
-	B-Task
th	I-Task
refinement	I-Task
are	O
bag	O
-	O
level	O
(	O
cluster	O
-	O
level	O
)	O
labels	O
,	O
	
i.e	O
.	O
	
,	O
.	O
is	O
the	O
label	O
of	O
the	O
-	O
th	O
bag	O
,	O
	
i.e	O
.	O
,	O
the	O
label	O
of	O
the	O
-	O
th	O
proposal	O
cluster	O
,	O
as	O
defined	O
in	O
Section	O
[	O
reference	O
]	O
.	O
	
Specially	O
,	O
for	O
object	B-Task
clusters	I-Task
,	O
we	O
choose	O
average	O
MIL	B-Method
pooling	O
,	O
because	O
these	O
proposals	O
should	O
cover	O
at	O
least	O
parts	O
of	O
objects	O
and	O
thus	O
should	O
have	O
relatively	O
high	O
prediction	B-Metric
scores	I-Metric
.	O
	
For	O
the	O
background	O
cluster	O
,	O
we	O
assign	O
the	O
background	O
label	O
to	O
all	O
proposals	O
in	O
the	O
cluster	O
according	O
to	O
the	O
MIL	B-Method
constraints	O
(	O
all	O
instances	O
in	O
negative	O
bags	O
are	O
negative	O
)	O
.	O
	
Then	O
the	O
loss	O
function	O
for	O
refinement	B-Task
will	O
be	O
Eq	O
.	O
	
(	O
[	O
reference	O
]	O
)	O
.	O
,	O
,	O
and	O
are	O
the	O
cluster	B-Metric
confidence	I-Metric
score	I-Metric
of	O
the	O
-	O
th	O
object	O
cluster	O
,	O
the	O
number	O
of	O
proposals	O
in	O
the	O
-	O
th	O
cluster	O
,	O
and	O
the	O
predicted	O
score	O
of	O
the	O
-	O
th	O
proposal	O
,	O
respectively	O
,	O
as	O
defined	O
in	O
Section	O
[	O
reference	O
]	O
.	O
	
and	O
indicate	O
that	O
the	O
-	O
th	O
proposal	O
belongs	O
to	O
the	O
-	O
th	O
object	O
cluster	O
and	O
the	O
background	O
cluster	O
respectively	O
.	O
	
Compared	O
with	O
the	O
directly	O
assigning	B-Method
label	I-Method
approach	I-Method
,	O
this	O
method	O
tolerates	O
some	O
proposals	O
to	O
have	O
low	O
scores	O
,	O
which	O
can	O
reduce	O
the	O
ambiguities	O
to	O
some	O
extent	O
.	O
	
subsection	O
:	O
Testing	O
	
During	O
testing	O
,	O
the	O
proposal	O
scores	O
of	O
refined	O
instance	B-Method
classifiers	I-Method
are	O
used	O
as	O
the	O
final	O
detection	B-Metric
scores	I-Metric
,	O
as	O
the	O
blue	O
arrows	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
.	O
	
Here	O
the	O
mean	O
output	O
of	O
all	O
refined	O
classifiers	B-Method
is	O
chosen	O
.	O
	
The	O
Non	B-Method
-	I-Method
Maxima	I-Method
Suppression	I-Method
(	O
NMS	B-Method
)	O
is	O
used	O
to	O
filter	O
out	O
redundant	O
detections	O
.	O
	
section	O
:	O
Experiments	O
	
In	O
this	O
section	O
,	O
we	O
first	O
introduce	O
our	O
experimental	O
setup	O
including	O
datasets	B-Metric
,	O
evaluation	B-Metric
metrics	I-Metric
,	O
and	O
implementation	O
details	O
.	O
	
Then	O
we	O
conduct	O
elaborate	O
experiments	O
to	O
discuss	O
the	O
influence	O
of	O
different	O
settings	O
.	O
	
Next	O
,	O
we	O
compare	O
our	O
results	O
with	O
others	O
to	O
show	O
the	O
effectiveness	O
of	O
our	O
method	O
.	O
	
After	O
that	O
,	O
we	O
show	O
some	O
qualitative	O
results	O
for	O
further	O
analyses	O
.	O
	
Finally	O
,	O
we	O
give	O
some	O
runtime	O
analyses	O
of	O
our	O
method	O
.	O
	
Codes	O
for	O
reproducing	O
our	O
results	O
are	O
available	O
at	O
.	O
	
subsection	O
:	O
Experimental	O
setup	O
	
subsubsection	O
:	O
Datasets	O
and	O
evaluation	B-Metric
metrics	I-Metric
	
We	O
evaluate	O
our	O
method	O
on	O
four	O
challenging	O
datasets	O
:	O
the	O
PASCAL	B-Material
VOC	I-Material
2007	I-Material
and	O
2012	B-Material
datasets	I-Material
,	O
the	O
ImageNet	B-Material
detection	O
dataset	O
,	O
and	O
the	O
MS	B-Material
-	I-Material
COCO	I-Material
dataset	O
.	O
	
Only	O
image	O
-	O
level	O
annotations	O
are	O
used	O
to	O
train	O
our	O
models	O
.	O
	
The	O
PASCAL	B-Material
VOC	I-Material
2007	I-Material
and	O
2012	B-Material
datasets	I-Material
have	O
and	O
images	O
respectively	O
for	O
object	O
classes	O
.	O
	
These	O
two	O
datasets	O
are	O
divided	O
into	O
train	O
,	O
val	O
,	O
and	O
test	O
sets	O
.	O
	
Here	O
we	O
choose	O
the	O
trainval	O
set	O
(	O
images	O
for	O
2007	O
and	O
images	O
for	O
2012	B-Material
)	O
to	O
train	O
our	O
network	O
.	O
	
For	O
testing	O
,	O
there	O
are	O
two	O
metrics	O
for	O
evaluation	B-Task
:	O
mAP	B-Metric
and	O
CorLoc	B-Material
.	O
	
Following	O
the	O
standard	O
PASCAL	B-Metric
VOC	I-Metric
protocol	I-Metric
,	O
Average	B-Metric
Precision	I-Metric
(	O
AP	B-Metric
)	O
and	O
the	O
mean	B-Metric
of	I-Metric
AP	I-Metric
(	O
mAP	B-Metric
)	O
is	O
the	O
evaluation	B-Metric
metric	I-Metric
to	O
test	O
our	O
model	O
on	O
the	O
testing	O
set	O
.	O
	
Correct	B-Task
Localization	I-Task
(	O
CorLoc	B-Material
)	O
is	O
to	O
test	O
our	O
model	O
on	O
the	O
training	O
set	O
measuring	O
the	O
localization	B-Metric
accuracy	I-Metric
.	O
	
All	O
these	O
two	O
metrics	O
are	O
based	O
on	O
the	O
PASCAL	B-Metric
criterion	I-Metric
,	O
	
i.e	O
.	O
,	O
IoU	B-Metric
0.5	O
between	O
groundtruth	O
boundingboxes	O
and	O
predicted	O
boxes	O
.	O
	
The	O
ImageNet	B-Material
detection	O
dataset	O
has	O
hundreds	O
of	O
thousands	O
of	O
images	O
with	O
object	O
classes	O
.	O
	
It	O
is	O
also	O
divided	O
into	O
train	O
,	O
val	O
,	O
and	O
test	O
sets	O
.	O
	
Following	O
,	O
we	O
split	O
the	O
val	O
set	O
into	O
val1	O
and	O
val2	O
,	O
and	O
randomly	O
choose	O
at	O
most	O
K	O
images	O
in	O
the	O
train	O
set	O
for	O
each	O
object	O
class	O
(	O
we	O
call	O
it	O
train	O
)	O
.	O
	
We	O
train	O
our	O
model	O
on	O
the	O
mixture	O
of	O
train	O
and	O
val1	O
sets	O
,	O
and	O
test	O
it	O
on	O
the	O
val2	O
set	O
,	O
which	O
will	O
lead	O
to	O
images	O
for	O
training	O
and	O
images	O
for	O
testing	O
.	O
	
We	O
also	O
use	O
the	O
mAP	B-Metric
for	O
evaluation	O
on	O
the	O
ImageNet	B-Material
.	O
	
The	O
MS	B-Material
-	I-Material
COCO	I-Material
dataset	O
has	O
object	O
classes	O
and	O
is	O
divided	O
into	O
train	O
,	O
val	O
,	O
and	O
test	O
sets	O
.	O
	
Since	O
the	O
groundtruths	O
on	O
the	O
test	O
set	O
are	O
not	O
released	O
,	O
we	O
train	O
our	O
model	O
on	O
the	O
MS	B-Material
-	I-Material
COCO	I-Material
2014	O
train	O
set	O
(	O
about	O
K	O
images	O
)	O
and	O
test	O
it	O
on	O
the	O
val	O
set	O
(	O
about	O
K	O
images	O
)	O
.	O
	
For	O
evaluation	O
,	O
we	O
use	O
two	O
metrics	O
mAP@0.5	B-Metric
and	O
mAP@	B-Metric
[	I-Metric
.5	I-Metric
,	O
.95	O
]	O
which	O
are	O
the	O
standard	O
PASCAL	B-Metric
criterion	I-Metric
(	O
i.e	O
.	O
,	O
	
IoU	B-Metric
0.5	O
)	O
	
and	O
the	O
standard	O
MS	B-Material
-	I-Material
COCO	I-Material
criterion	O
(	O
i.e	O
.	O
,	O
computing	O
the	O
average	O
of	O
mAP	B-Metric
for	O
IoU	B-Metric
	
[	O
0.5	O
:	O
0.05	O
:	O
0.95	O
]	O
)	O
respectively	O
.	O
	
subsubsection	O
:	O
Implementation	O
details	O
	
Our	O
method	O
is	O
built	O
on	O
two	O
pre	O
-	O
trained	O
ImageNet	B-Material
networks	O
VGG	B-Method
M	I-Method
and	O
VGG16	B-Method
,	O
each	O
of	O
which	O
has	O
some	O
conv	B-Method
layers	I-Method
with	O
max	B-Method
-	I-Method
pooling	I-Method
layers	I-Method
and	O
three	O
fc	B-Method
layers	O
.	O
	
We	O
replace	O
the	O
last	O
max	B-Method
-	I-Method
pooling	I-Method
layer	I-Method
by	O
the	O
SPP	B-Method
layer	O
,	O
and	O
the	O
last	O
fc	B-Method
layer	O
as	O
well	O
as	O
the	O
softmax	O
loss	O
layer	O
by	O
the	O
layers	O
described	O
in	O
Section	O
[	O
reference	O
]	O
.	O
	
To	O
increase	O
the	O
feature	O
map	O
size	O
from	O
the	O
last	O
conv	O
layer	O
,	O
we	O
replace	O
the	O
penultimate	B-Method
max	I-Method
-	I-Method
pooling	I-Method
layer	I-Method
and	O
its	O
subsequent	O
conv	B-Method
layers	I-Method
by	O
the	O
dilated	B-Method
conv	I-Method
layers	I-Method
.	O
	
The	O
newly	O
added	O
layers	O
are	O
initialized	O
using	O
Gaussian	B-Method
distributions	I-Method
with	O
-	O
mean	O
and	O
standard	O
deviations	O
.	O
	
Biases	O
are	O
initialized	O
to	O
.	O
	
During	O
training	B-Task
,	O
the	O
mini	B-Metric
-	I-Metric
batch	I-Metric
size	I-Metric
for	O
SGD	B-Method
is	O
set	O
to	O
be	O
,	O
,	O
and	O
for	O
PASCAL	B-Material
VOC	I-Material
,	O
ImageNet	B-Material
,	O
and	O
MS	B-Material
-	I-Material
COCO	I-Material
,	O
respectively	O
.	O
	
The	O
learning	B-Metric
rate	I-Metric
is	O
set	O
to	O
for	O
the	O
first	O
K	O
,	O
K	O
,	O
K	O
,	O
and	O
K	O
iterations	O
for	O
the	O
PASCAL	B-Material
VOC	I-Material
2007	I-Material
,	O
PASCAL	B-Material
VOC	I-Material
2012	I-Material
,	O
ImageNet	B-Material
,	O
and	O
MS	B-Material
-	I-Material
COCO	I-Material
datasets	I-Material
,	O
respectively	O
.	O
	
Then	O
we	O
decrease	O
the	O
learning	B-Metric
rate	I-Metric
to	O
in	O
the	O
following	O
K	O
,	O
K	O
,	O
K	O
,	O
and	O
K	O
iterations	O
for	O
the	O
PASCAL	B-Material
VOC	I-Material
2007	I-Material
,	O
PASCAL	B-Material
VOC	I-Material
2012	I-Material
,	O
ImageNet	B-Material
,	O
and	O
MS	B-Material
-	I-Material
COCO	I-Material
datasets	I-Material
,	O
respectively	O
.	O
	
The	O
momentum	O
and	O
weight	O
decay	O
are	O
set	O
to	O
be	O
and	O
respectively	O
.	O
	
Selective	B-Method
Search	I-Method
,	O
EdgeBox	B-Method
,	O
and	O
MCG	B-Method
are	O
adopted	O
to	O
generate	O
about	O
proposals	O
per	O
-	O
image	B-Material
for	O
the	O
PASCAL	B-Material
VOC	I-Material
,	O
ImageNet	B-Material
,	O
and	O
MS	B-Material
-	I-Material
COCO	I-Material
datasets	O
,	O
respectively	O
.	O
	
For	O
data	B-Task
augmentation	I-Task
,	O
we	O
use	O
five	O
image	O
scales	O
(	O
resize	O
the	O
shortest	O
side	O
to	O
one	O
of	O
these	O
scales	O
)	O
with	O
horizontal	O
flips	O
for	O
both	O
training	O
and	O
testing	O
.	O
	
If	O
not	O
specified	O
,	O
the	O
instance	B-Method
classifiers	I-Method
are	O
refined	O
three	O
times	O
,	O
i.e	O
.	O
	
,	O
in	O
Section	O
[	O
reference	O
]	O
,	O
	
so	O
there	O
are	O
four	O
output	O
streams	O
;	O
	
the	O
IoU	B-Metric
threshold	O
in	O
Section	O
[	O
reference	O
]	O
(	O
2	O
)	O
(	O
also	O
Eq	O
.	O
	
(	O
[	O
reference	O
]	O
)	O
)	O
is	O
set	O
to	O
;	O
the	O
number	O
of	O
-	O
means	O
clusters	O
in	O
the	O
last	O
paragraph	O
of	O
Section	O
[	O
reference	O
]	O
(	O
2	O
)	O
is	O
set	O
to	O
;	O
in	O
Section	O
[	O
reference	O
]	O
(	O
also	O
the	O
-	O
th	O
line	O
of	O
Algorithm	O
[	O
reference	O
]	O
)	O
is	O
set	O
to	O
.	O
	
Similar	O
to	O
other	O
works	O
,	O
we	O
train	O
a	O
supervised	B-Method
object	I-Method
detector	I-Method
through	O
choosing	O
the	O
top	O
-	O
scoring	O
proposals	O
given	O
by	O
our	O
method	O
as	O
pseudo	O
groundtruths	O
to	O
further	O
improve	O
our	O
results	O
.	O
	
Here	O
we	O
train	O
a	O
Fast	B-Method
R	I-Method
-	I-Method
CNN	I-Method
(	O
FRCNN	B-Method
)	O
using	O
the	O
VGG16	B-Method
model	O
and	O
the	O
same	O
five	O
image	O
scales	O
(	O
horizontal	O
flips	O
only	O
in	O
training	O
)	O
.	O
	
The	O
same	O
proposals	O
are	O
chosen	O
to	O
train	O
and	O
test	O
the	O
FRCNN	B-Method
.	O
	
NMS	B-Method
(	O
with	O
IoU	B-Metric
threshold	O
)	O
is	O
applied	O
to	O
compute	O
AP	B-Metric
.	O
	
Our	O
experiments	O
are	O
implemented	O
based	O
on	O
the	O
Caffe	B-Method
deep	I-Method
learning	I-Method
framework	I-Method
,	O
using	O
Python	B-Material
and	O
C	B-Material
++	I-Material
.	O
	
The	O
-	B-Method
means	I-Method
algorithm	I-Method
to	O
produce	O
top	O
ranking	O
proposals	O
is	O
implemented	O
by	O
scikit	B-Method
-	I-Method
learn	I-Method
.	O
	
All	O
of	O
our	O
experiments	O
are	O
running	O
on	O
an	O
NVIDIA	B-Material
GTX	I-Material
TitanX	I-Material
Pascal	I-Material
GPU	I-Material
and	O
Intel	O
(	O
R	O
)	O
	
i7	O
-	O
6850	O
	
K	O
CPU	O
(	O
3.60GHz	O
)	O
.	O
	
subsection	O
:	O
Discussions	O
	
We	O
first	O
conduct	O
some	O
experiments	O
to	O
discuss	O
the	O
influence	O
of	O
different	O
components	O
of	O
our	O
method	O
(	O
including	O
instance	B-Method
classifier	I-Method
refinement	I-Method
,	O
different	O
proposal	B-Method
generation	I-Method
methods	I-Method
,	O
different	O
refinement	B-Method
strategies	I-Method
,	O
and	O
weighted	O
loss	O
)	O
and	O
different	O
parameter	O
settings	O
(	O
including	O
the	O
IoU	B-Metric
threshold	O
defined	O
in	O
Section	O
[	O
reference	O
]	O
	
(	O
2	O
)	O
,	O
the	O
number	O
of	O
-	O
means	O
clusters	O
described	O
in	O
Section	O
[	O
reference	O
]	O
(	O
2	O
)	O
,	O
the	O
IoU	B-Metric
threshold	O
defined	O
in	O
Section	O
[	O
reference	O
]	O
,	O
and	O
multi	O
-	O
scale	O
training	O
and	O
testing	O
.	O
)	O
	
We	O
also	O
discuss	O
the	O
number	O
of	O
proposal	O
cluster	O
centers	O
.	O
	
Without	O
loss	O
of	O
generality	O
,	O
we	O
only	O
perform	O
experiments	O
on	O
the	O
VOC	B-Material
2007	I-Material
dataset	I-Material
and	O
use	O
the	O
VGG	B-Method
M	I-Method
model	O
.	O
	
subsubsection	O
:	O
The	O
influence	O
of	O
instance	B-Method
classifier	I-Method
refinement	I-Method
	
As	O
the	O
five	O
curves	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
show	O
,	O
we	O
observe	O
that	O
compared	O
with	O
the	O
basic	O
MIL	B-Method
network	O
,	O
for	O
both	O
refinement	B-Method
methods	I-Method
,	O
even	O
refining	O
instance	B-Method
classifier	I-Method
a	O
single	O
time	O
boosts	O
the	O
performance	O
a	O
lot	O
.	O
	
This	O
confirms	O
the	O
necessity	O
of	O
refinement	O
.	O
	
If	O
we	O
refine	O
the	O
classifier	O
multiple	O
times	O
,	O
the	O
results	O
are	O
improved	O
further	O
.	O
	
But	O
when	O
refinement	B-Method
is	O
implemented	O
too	O
many	O
times	O
,	O
the	O
performance	O
gets	O
saturated	O
(	O
there	O
are	O
no	O
obvious	O
improvements	O
from	O
times	O
to	O
times	O
)	O
.	O
	
This	O
is	O
because	O
the	O
network	O
tends	O
to	O
converge	O
so	O
that	O
the	O
supervision	O
of	O
the	O
-	O
th	O
time	O
is	O
similar	O
to	O
the	O
-	O
rd	O
time	O
.	O
	
In	O
the	O
rest	O
of	O
this	O
paper	O
we	O
only	O
refine	O
classifiers	O
times	O
.	O
	
Notice	O
that	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
,	O
the	O
“	O
0	O
time	O
”	O
is	O
similar	O
to	O
the	O
WSDDN	B-Method
using	O
Selective	B-Method
Search	I-Method
as	O
proposals	O
.	O
	
subsubsection	O
:	O
The	O
influence	O
of	O
different	O
proposal	B-Method
cluster	I-Method
generation	I-Method
methods	I-Method
	
We	O
discuss	O
the	O
influence	O
of	O
different	O
proposal	B-Method
cluster	I-Method
generation	I-Method
methods	I-Method
.	O
	
As	O
shown	O
in	O
the	O
Fig	O
.	O
	
[	O
reference	O
]	O
	
(	O
green	O
and	O
purple	O
solid	O
curves	O
for	O
the	O
highest	O
scoring	B-Method
proposal	I-Method
based	I-Method
method	I-Method
,	O
blue	O
and	O
red	O
solid	O
curves	O
for	O
the	O
graph	B-Method
-	I-Method
based	I-Method
method	I-Method
)	O
,	O
for	O
all	O
refinement	B-Metric
times	I-Metric
,	O
the	O
graph	B-Method
-	I-Method
based	I-Method
method	I-Method
obtains	O
better	O
performance	O
,	O
because	O
it	O
can	O
generate	O
better	O
cluster	O
centers	O
.	O
	
Thus	O
we	O
choose	O
the	O
graph	B-Method
-	I-Method
based	I-Method
method	I-Method
in	O
the	O
rest	O
of	O
our	O
paper	O
.	O
	
subsubsection	O
:	O
The	O
influence	O
of	O
different	O
refinement	B-Method
strategies	I-Method
	
We	O
then	O
show	O
the	O
influence	O
of	O
different	O
refinement	B-Method
strategies	I-Method
.	O
	
The	O
directly	O
assigning	B-Method
label	I-Method
method	I-Method
is	O
replaced	O
by	O
treating	O
clusters	O
as	O
bags	O
(	O
blue	O
and	O
green	O
solid	O
curves	O
)	O
.	O
	
From	O
Fig	O
.	O
	
[	O
reference	O
]	O
	
,	O
it	O
is	O
obvious	O
that	O
the	O
results	O
by	O
treating	O
clusters	O
as	O
bags	O
are	O
better	O
.	O
	
In	O
addition	O
,	O
compared	O
with	O
the	O
alternating	B-Method
training	I-Method
strategy	I-Method
(	O
blue	O
dashed	O
curve	O
)	O
,	O
our	O
online	B-Method
training	I-Method
boosts	O
the	O
performance	O
consistently	O
and	O
significantly	O
,	O
which	O
confirms	O
the	O
necessity	O
of	O
sharing	O
proposal	O
features	O
.	O
	
Online	B-Task
training	I-Task
also	O
reduces	O
the	O
training	B-Metric
time	I-Metric
a	O
lot	O
,	O
because	O
it	O
only	O
requires	O
training	O
a	O
single	O
model	O
instead	O
of	O
training	O
models	O
for	O
times	B-Task
refinement	I-Task
in	O
the	O
alternating	B-Method
strategy	I-Method
.	O
	
In	O
the	O
rest	O
of	O
our	O
paper	O
,	O
we	O
only	O
report	O
results	O
by	O
the	O
“	O
PCL	B-Method
-	O
OB	O
-	O
G	O
”	O
method	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
because	O
it	O
achieves	O
the	O
best	O
performance	O
.	O
	
subsubsection	O
:	O
The	O
influence	O
of	O
weighted	B-Method
loss	I-Method
	
We	O
also	O
study	O
the	O
influence	O
of	O
our	O
weighted	B-Metric
loss	I-Metric
in	O
Eq	O
.	O
	
(	O
[	O
reference	O
]	O
)	O
.	O
	
Note	O
that	O
Eq	O
.	O
	
(	O
[	O
reference	O
]	O
)	O
can	O
be	O
easily	O
changed	O
to	O
the	O
unweighted	O
version	O
by	O
simply	O
setting	O
and	O
to	O
be	O
.	O
	
Here	O
we	O
train	O
a	O
network	O
using	O
the	O
unweighted	B-Method
loss	I-Method
.	O
	
The	O
results	O
of	O
the	O
unweighted	B-Method
loss	I-Method
are	O
mAP	B-Metric
and	O
CorLoc	B-Material
.	O
	
We	O
see	O
that	O
if	O
we	O
use	O
the	O
unweighted	O
loss	O
,	O
the	O
improvement	O
from	O
refinement	B-Task
is	O
very	O
scant	O
and	O
the	O
performance	O
is	O
even	O
worse	O
than	O
the	O
alternating	B-Method
strategy	I-Method
.	O
	
Using	O
the	O
weighted	B-Method
loss	I-Method
achieves	O
much	O
better	O
performance	O
(	O
mAP	B-Metric
and	O
CorLoc	B-Material
)	O
,	O
which	O
confirms	O
our	O
theory	O
in	O
Section	O
[	O
reference	O
]	O
.	O
	
subsubsection	O
:	O
The	O
influence	O
of	O
the	O
IoU	B-Metric
threshold	O
	
Here	O
we	O
discuss	O
the	O
influence	O
of	O
the	O
IoU	B-Metric
threshold	O
defined	O
in	O
Section	O
[	O
reference	O
]	O
(	O
2	O
)	O
and	O
Eq	O
.	O
	
(	O
[	O
reference	O
]	O
)	O
.	O
	
From	O
Fig	O
.	O
	
[	O
reference	O
]	O
	
,	O
we	O
see	O
that	O
setting	O
to	O
obtains	O
the	O
best	O
performance	O
.	O
	
Therefore	O
,	O
we	O
set	O
to	O
for	O
the	O
other	O
experiments	O
.	O
	
subsubsection	O
:	O
The	O
influence	O
of	O
the	O
number	O
of	O
-	O
means	O
clusters	O
	
In	O
previous	O
experiments	O
we	O
set	O
the	O
number	O
of	O
-	O
means	O
clusters	O
described	O
in	O
the	O
last	O
paragraph	O
of	O
Section	O
[	O
reference	O
]	O
(	O
2	O
)	O
to	O
be	O
.	O
	
Here	O
we	O
set	O
it	O
to	O
other	O
numbers	O
to	O
explore	O
its	O
influence	O
.	O
	
The	O
results	O
from	O
other	O
numbers	O
of	O
-	O
means	O
clusters	O
are	O
mAP	B-Metric
and	O
CorLoc	B-Material
for	O
clusters	O
,	O
and	O
mAP	B-Metric
and	O
CorLoc	B-Material
for	O
clusters	O
,	O
which	O
are	O
a	O
little	O
worse	O
than	O
the	O
results	O
from	O
cluster	B-Method
.	O
	
Therefore	O
,	O
we	O
set	O
the	O
number	O
of	O
-	O
means	O
clusters	O
to	O
for	O
the	O
other	O
experiments	O
.	O
	
subsubsection	O
:	O
The	O
influence	O
of	O
the	O
IoU	B-Metric
threshold	O
	
We	O
also	O
analyse	O
the	O
influence	O
of	O
defined	O
in	O
Section	O
[	O
reference	O
]	O
and	O
the	O
-	O
th	O
line	O
of	O
Algorithm	O
[	O
reference	O
]	O
.	O
	
As	O
shown	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
,	O
outperforms	O
other	O
choices	O
.	O
	
Therefore	O
,	O
we	O
set	O
to	O
for	O
the	O
other	O
experiments	O
.	O
	
subsubsection	O
:	O
The	O
influence	O
of	O
multi	B-Task
-	I-Task
scale	I-Task
training	I-Task
and	I-Task
testing	I-Task
	
Previously	O
our	O
experiments	O
are	O
conducted	O
based	O
on	O
five	O
image	O
scales	O
for	O
training	O
and	O
testing	O
.	O
	
Here	O
we	O
show	O
the	O
influence	O
of	O
this	O
multi	O
-	O
scale	O
setting	O
.	O
	
We	O
train	O
and	O
test	O
our	O
method	O
using	O
a	O
single	O
image	O
scale	O
as	O
the	O
default	O
scale	O
setting	O
of	O
FRCNN	B-Method
.	O
	
The	O
single	O
-	O
scale	O
results	O
are	O
mAP	B-Metric
and	O
CorLoc	B-Material
which	O
are	O
much	O
worse	O
than	O
our	O
multi	O
-	O
scale	O
results	O
(	O
mAP	B-Metric
and	O
CorLoc	B-Material
)	O
.	O
	
Therefore	O
,	O
we	O
use	O
five	O
image	O
scales	O
as	O
many	O
WSOD	B-Task
networks	O
.	O
	
subsubsection	O
:	O
The	O
number	O
of	O
proposal	O
cluster	O
centers	O
	
As	O
we	O
stated	O
in	O
Section	O
[	O
reference	O
]	O
(	O
2	O
)	O
,	O
the	O
number	O
of	O
proposal	O
cluster	O
centers	O
(	O
i.e	O
.	O
,	O
)	O
changes	O
for	O
each	O
image	O
in	O
each	O
training	O
iteration	O
.	O
	
Here	O
we	O
give	O
some	O
typical	O
values	O
of	O
.	O
	
In	O
the	O
beginning	O
of	O
training	O
,	O
the	O
proposal	O
scores	O
are	O
very	O
noisy	O
and	O
thus	O
the	O
selected	O
top	O
ranking	O
proposals	O
to	O
form	O
graphs	O
are	O
scattered	O
in	O
images	O
,	O
which	O
results	O
in	O
dozens	O
of	O
proposal	O
cluster	O
centers	O
for	O
each	O
image	O
.	O
	
After	O
some	O
(	O
about	O
3	O
K	O
)	O
training	O
iterations	O
,	O
the	O
proposal	O
scores	O
are	O
more	O
reliable	O
and	O
our	O
method	O
finds	O
1	O
3	O
proposal	O
cluster	O
centers	O
for	O
each	O
positive	O
object	O
class	O
.	O
	
To	O
make	O
the	O
training	O
more	O
stable	O
in	O
the	O
beginning	O
,	O
for	O
each	O
positive	O
object	O
class	O
we	O
empirically	O
select	O
at	O
most	O
five	O
proposal	O
cluster	O
centers	O
which	O
have	O
higher	O
scores	O
,	O
and	O
the	O
number	O
of	O
selected	O
proposal	O
cluster	O
centers	O
does	O
not	O
influence	O
the	O
performance	O
much	O
.	O
	
subsection	O
:	O
Comparison	O
with	O
other	O
methods	O
	
Here	O
we	O
compare	O
our	O
best	O
performed	O
strategy	O
PCL	B-Method
-	O
OB	O
-	O
G	O
,	O
i.e	O
.	O
,	O
using	O
graph	B-Method
-	I-Method
based	I-Method
method	I-Method
and	O
treating	O
clusters	O
as	O
bags	O
to	O
train	O
the	O
network	O
online	O
,	O
with	O
other	O
methods	O
.	O
	
We	O
first	O
report	O
our	O
results	O
for	O
each	O
class	O
on	O
VOC	B-Material
2007	I-Material
and	O
2012	B-Material
in	O
Table	O
[	O
reference	O
]	O
,	O
Table	O
[	O
reference	O
]	O
,	O
Table	O
[	O
reference	O
]	O
,	O
and	O
Table	O
[	O
reference	O
]	O
.	O
	
It	O
is	O
obvious	O
that	O
our	O
method	O
outperforms	O
other	O
methods	O
using	O
single	O
model	O
VGG	B-Method
M	I-Method
or	O
VGG16	B-Method
	
(	O
PCL	B-Method
-	O
OB	O
-	O
G	O
+	O
VGG	B-Method
M	I-Method
and	O
PCL	B-Method
-	O
OB	O
-	O
G	O
+	O
VGG16	B-Method
in	O
tables	O
.	O
)	O
	
Our	O
single	O
model	O
results	O
even	O
better	O
than	O
others	O
by	O
combining	O
multiple	O
different	O
models	O
(	O
e.g	O
.	O
,	O
ensemble	B-Method
of	I-Method
models	I-Method
)	O
.	O
	
Specially	O
,	O
our	O
method	O
obtains	O
much	O
better	O
results	O
compared	O
with	O
other	O
two	O
methods	O
also	O
using	O
the	O
same	O
basic	O
MIL	B-Method
network	O
.	O
	
Importantly	O
,	O
also	O
equips	O
the	O
weighted	B-Method
sum	I-Method
pooling	I-Method
with	O
objectness	B-Method
measure	I-Method
of	I-Method
EdgeBox	I-Method
and	O
the	O
spatial	B-Method
regulariser	I-Method
,	O
and	O
adds	O
context	O
information	O
into	O
the	O
network	O
,	O
both	O
of	O
which	O
are	O
more	O
complicated	O
than	O
our	O
basic	O
MIL	B-Method
network	O
.	O
	
We	O
believe	O
that	O
our	O
performance	O
can	O
be	O
improved	O
by	O
choosing	O
better	O
basic	O
MIL	B-Method
networks	O
,	O
like	O
the	O
complete	B-Method
network	I-Method
in	O
and	O
using	O
context	O
information	O
.	O
	
As	O
reimplementing	O
their	O
method	O
completely	O
is	O
non	O
-	O
trivial	O
,	O
here	O
we	O
only	O
choose	O
the	O
simplest	O
architecture	O
in	O
.	O
	
Even	O
in	O
this	O
simplified	O
case	O
,	O
our	O
method	O
achieves	O
very	O
promising	O
results	O
.	O
	
Our	O
results	O
can	O
also	O
be	O
improved	O
by	O
combing	O
multiple	B-Method
models	I-Method
.	O
	
As	O
shown	O
in	O
the	O
tables	O
,	O
there	O
are	O
little	O
improvements	O
from	O
the	O
ensemble	O
of	O
the	O
VGG	B-Method
M	I-Method
and	O
VGG16	B-Method
models	O
(	O
PCL	B-Method
-	I-Method
OB	I-Method
-	I-Method
G	I-Method
-	I-Method
Ens	I-Method
.	O
in	O
tables	O
)	O
.	O
	
Here	O
we	O
do	O
the	O
ensemble	O
by	O
summing	O
up	O
the	O
scores	O
produced	O
by	O
the	O
two	O
models	O
.	O
	
Also	O
,	O
as	O
mentioned	O
in	O
Section	O
[	O
reference	O
]	O
,	O
similar	O
to	O
,	O
we	O
train	O
a	O
FRCNN	B-Method
detector	O
using	O
top	O
-	O
scoring	O
proposals	O
produced	O
by	O
PCL	B-Method
-	I-Method
OB	I-Method
-	I-Method
G	I-Method
-	I-Method
Ens	I-Method
.	O
as	O
groundtruths	O
	
(	O
PCL	B-Method
-	I-Method
OB	I-Method
-	I-Method
G	I-Method
-	I-Method
Ens.	I-Method
+	O
FRCNN	B-Method
in	O
tables	O
)	O
.	O
	
As	O
we	O
can	O
see	O
,	O
the	O
performance	O
is	O
improved	O
further	O
.	O
	
We	O
then	O
show	O
results	O
of	O
our	O
method	O
on	O
the	O
large	O
scale	O
ImageNet	B-Material
detection	O
dataset	O
in	O
Table	O
[	O
reference	O
]	O
.	O
	
We	O
observe	O
similar	O
phenomenon	O
that	O
our	O
method	O
outperforms	O
other	O
methods	O
by	O
a	O
large	O
margin	O
.	O
	
We	O
finally	O
report	O
results	O
of	O
our	O
method	O
on	O
MS	B-Material
-	I-Material
COCO	I-Material
in	O
Table	O
[	O
reference	O
]	O
.	O
	
Our	O
method	O
obtains	O
better	O
performance	O
than	O
the	O
recent	O
work	O
.	O
	
In	O
particular	O
,	O
Ge	O
et	O
al	O
.	O
use	O
the	O
method	O
proposed	O
in	O
our	O
conference	O
version	O
paper	O
as	O
a	O
basic	O
component	O
.	O
	
We	O
can	O
expect	O
to	O
obtain	O
better	O
detection	B-Task
performance	O
through	O
replacing	O
our	O
conference	B-Method
version	I-Method
method	I-Method
in	O
by	O
our	O
newly	O
proposed	O
method	O
here	O
,	O
which	O
we	O
would	O
like	O
to	O
explore	O
in	O
the	O
future	O
.	O
	
subsection	O
:	O
Qualitative	O
results	O
	
We	O
first	O
show	O
some	O
proposal	O
clusters	O
generated	O
by	O
our	O
method	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
.	O
	
As	O
we	O
can	O
see	O
,	O
the	O
cluster	O
centers	O
contain	O
at	O
least	O
parts	O
of	O
objects	O
and	O
are	O
able	O
to	O
cover	O
adaptive	O
number	O
of	O
objects	O
for	O
each	O
class	O
.	O
	
We	O
then	O
show	O
qualitative	O
comparisons	O
among	O
the	O
WSDDN	B-Method
,	O
the	O
WSDDN	B-Method
+	I-Method
context	I-Method
,	O
and	O
our	O
PCL	B-Method
method	O
,	O
both	O
of	O
which	O
use	O
the	O
same	O
basic	O
MIL	B-Method
network	O
.	O
	
As	O
shown	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
,	O
we	O
can	O
observe	O
that	O
for	O
classes	O
such	O
as	O
bike	O
,	O
car	O
,	O
cat	O
,	O
etc	O
.	O
,	O
our	O
method	O
tends	O
to	O
provide	O
more	O
accurate	O
detections	O
,	O
whereas	O
other	O
two	O
methods	O
sometimes	O
fails	O
by	O
producing	O
boxes	O
that	O
are	O
overlarge	O
or	O
only	O
contain	O
parts	O
of	O
objects	O
(	O
the	O
first	O
four	O
rows	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
)	O
.	O
	
But	O
for	O
some	O
classes	O
such	O
as	O
person	O
,	O
our	O
method	O
sometimes	O
fails	O
by	O
only	O
detecting	O
parts	O
of	O
objects	O
such	O
as	O
the	O
head	O
of	O
person	O
(	O
the	O
fifth	O
row	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
)	O
.	O
	
Exploiting	O
context	O
information	O
sometimes	O
help	O
the	O
detection	B-Task
(	O
as	O
in	O
WSDDN	B-Task
+	I-Task
context	I-Task
)	O
,	O
we	O
believe	O
our	O
method	O
can	O
be	O
further	O
improved	O
by	O
incorporating	O
context	O
information	O
into	O
our	O
framework	O
.	O
	
All	O
these	O
three	O
methods	O
(	O
actually	O
almost	O
all	O
weakly	O
supervised	O
object	B-Task
detection	I-Task
methods	O
)	O
suffers	O
from	O
two	O
problems	O
:	O
producing	O
boxes	O
that	O
not	O
only	O
contain	O
the	O
target	O
object	O
but	O
also	O
include	O
their	O
adjacent	O
similar	O
objects	O
,	O
or	O
only	O
detecting	O
parts	O
of	O
object	O
for	O
objects	O
with	O
deformation	O
(	O
the	O
last	O
row	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
)	O
.	O
	
We	O
finally	O
visualize	O
some	O
success	O
and	O
failure	B-Metric
detection	I-Metric
results	O
on	O
VOC	B-Material
2007	I-Material
trainval	O
by	O
PCL	B-Method
-	O
Ens.	O
+	O
FRCNN	B-Method
,	O
as	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
.	O
	
We	O
observe	O
similar	O
phenomena	O
as	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
.	O
	
Our	O
method	O
is	O
robust	O
to	O
the	O
size	O
and	O
aspect	O
of	O
objects	O
,	O
especially	O
for	O
rigid	O
objects	O
.	O
	
The	O
main	O
failures	O
for	O
these	O
rigid	O
objects	O
are	O
always	O
due	O
to	O
overlarge	O
boxes	O
that	O
not	O
only	O
contain	O
objects	O
,	O
but	O
also	O
include	O
adjacent	O
similar	O
objects	O
.	O
	
For	O
non	O
-	O
rigid	O
objects	O
like	O
“	O
cat	O
”	O
,	O
“	O
dog	O
”	O
,	O
and	O
“	O
person	O
”	O
,	O
they	O
often	O
have	O
great	O
deformations	O
,	O
but	O
their	O
parts	O
(	O
e.g	O
.	O
,	O
head	O
of	O
person	O
)	O
have	O
much	O
less	O
deformation	O
,	O
so	O
our	O
detector	O
is	O
still	O
inclined	O
to	O
find	O
these	O
parts	O
.	O
	
An	O
ideal	O
solution	O
is	O
yet	O
wanted	O
because	O
there	O
is	O
still	O
room	O
for	O
improvement	O
.	O
	
subsection	O
:	O
Runtime	O
	
The	O
runtime	O
comparisons	O
between	O
our	O
method	O
and	O
our	O
basic	O
MIL	B-Method
network	O
are	O
shown	O
in	O
Table	O
[	O
reference	O
]	O
,	O
where	O
the	O
runtime	B-Metric
of	O
proposal	B-Task
generation	I-Task
is	O
not	O
considered	O
.	O
	
As	O
we	O
can	O
see	O
,	O
although	O
our	O
method	O
has	O
more	O
components	O
than	O
our	O
basic	O
MIL	B-Method
network	O
,	O
our	O
method	O
takes	O
almost	O
the	O
same	O
testing	O
time	O
as	O
it	O
.	O
	
This	O
is	O
because	O
all	O
our	O
output	O
streams	O
share	O
the	O
same	O
proposal	O
feature	O
computations	O
.	O
	
The	O
small	O
extra	O
training	O
computations	O
of	O
our	O
method	O
mainly	O
come	O
from	O
the	O
procedures	O
to	O
find	O
proposal	O
cluster	O
centers	O
and	O
generate	O
proposal	O
clusters	O
.	O
	
Although	O
with	O
small	O
extra	O
training	O
computations	O
,	O
our	O
method	O
obtains	O
much	O
better	O
detection	B-Task
results	O
than	O
the	O
basic	O
MIL	B-Method
network	O
.	O
	
section	O
:	O
Conclusion	O
	
In	O
this	O
paper	O
,	O
we	O
propose	O
to	O
generate	O
proposal	B-Method
clusters	I-Method
to	O
learn	O
refined	B-Method
instance	I-Method
classifiers	I-Method
for	O
weakly	O
supervised	O
object	B-Task
detection	I-Task
.	O
	
We	O
propose	O
two	O
strategies	O
for	O
proposal	B-Task
cluster	I-Task
generation	I-Task
and	O
classifier	B-Task
refinement	I-Task
,	O
both	O
of	O
which	O
can	O
boost	O
the	O
performance	O
significantly	O
.	O
	
The	O
classifier	B-Method
refinement	I-Method
is	O
implemented	O
by	O
multiple	O
output	O
streams	O
corresponding	O
to	O
some	O
instance	B-Method
classifiers	I-Method
in	O
multiple	B-Method
instance	I-Method
learning	I-Method
networks	I-Method
.	O
	
An	O
online	B-Method
training	I-Method
algorithm	I-Method
is	O
introduced	O
to	O
train	O
the	O
proposed	O
network	O
end	O
-	O
to	O
-	O
end	O
for	O
effectiveness	O
and	O
efficiency	O
.	O
	
Experiments	O
show	O
substantial	O
and	O
consistent	O
improvements	O
by	O
our	O
method	O
.	O
	
We	O
observe	O
that	O
the	O
most	O
common	O
failure	O
cases	O
of	O
our	O
algorithm	O
are	O
connected	O
with	O
the	O
deformation	B-Task
of	I-Task
non	I-Task
-	I-Task
rigid	I-Task
objects	I-Task
.	O
	
In	O
the	O
future	O
,	O
we	O
will	O
concentrate	O
on	O
this	O
problem	O
.	O
	
In	O
addition	O
,	O
we	O
believe	O
our	O
learning	B-Method
algorithm	I-Method
has	O
the	O
potential	O
to	O
be	O
applied	O
in	O
other	O
weakly	B-Task
supervised	I-Task
visual	I-Task
learning	I-Task
tasks	I-Task
such	O
as	O
weakly	B-Task
supervised	I-Task
semantic	I-Task
segmentation	I-Task
.	O
	
We	O
will	O
also	O
explore	O
how	O
to	O
apply	O
our	O
method	O
to	O
these	O
related	O
applications	O
.	O
	
section	O
:	O
Acknowledgements	O
	
This	O
work	O
was	O
supported	O
by	O
NSFC	O
	
(	O
No	O
.	O
61733007	O
,	O
No	O
.	O
61572207	O
,	O
No	O
.	O
61876212	O
,	O
No	O
.	O
61672336	O
,	O
No	O
.	O
61573160	O
)	O
,	O
ONR	O
with	O
grant	O
N00014	O
-	O
15	O
-	O
1	O
-	O
2356	O
,	O
Hubei	O
Scientific	O
and	O
Technical	O
Innovation	O
Key	O
Project	O
,	O
and	O
the	O
Program	O
for	O
HUST	O
Academic	O
Frontier	O
Youth	O
Team	O
.	O
	
The	O
corresponding	O
author	O
of	O
this	O
paper	O
is	O
Xinggang	O
Wang	O
.	O
	
bibliography	O
:	O
References	O
	
[	O
]	O
Peng	O
Tang	O
received	O
the	O
B.S.	O
degree	O
in	O
Electronics	B-Task
and	I-Task
Information	I-Task
Engineering	I-Task
from	O
Huazhong	O
University	O
of	O
Science	O
and	O
Technology	O
(	O
HUST	O
)	O
in	O
2014	O
.	O
	
He	O
is	O
currently	O
pursuing	O
the	O
Ph.D.	O
degree	O
in	O
the	O
School	O
of	O
Electronic	B-Task
Information	I-Task
and	I-Task
Communications	I-Task
at	O
HUST	B-Material
,	O
and	O
visiting	O
the	O
Department	O
of	O
Computer	B-Task
Science	I-Task
at	O
Johns	O
Hopkins	O
University	O
.	O
	
He	O
was	O
an	O
intern	O
at	O
Microsoft	O
Research	O
Asia	O
in	O
2017	O
.	O
	
His	O
research	O
interests	O
include	O
image	B-Task
classification	I-Task
and	O
object	B-Task
detection	I-Task
in	O
images	O
/	O
videos	O
.	O
	
[	O
]	O
Xinggang	O
Wang	O
is	O
an	O
assistant	O
professor	O
of	O
School	O
of	O
Electronics	B-Task
Information	I-Task
and	I-Task
Communications	I-Task
of	O
Huazhong	O
University	O
of	O
Science	O
and	O
Technology	O
(	O
HUST	O
)	O
.	O
	
He	O
received	O
his	O
Bachelor	O
degree	O
in	O
communication	B-Task
and	I-Task
information	I-Task
system	I-Task
and	O
Ph.D.	B-Task
degree	I-Task
in	O
computer	B-Task
vision	I-Task
both	O
from	O
HUST	O
.	O
	
From	O
May	O
2010	O
to	O
July	O
2011	O
,	O
he	O
was	O
with	O
the	O
Department	O
of	O
Computer	O
and	O
Information	O
Science	O
,	O
Temple	O
University	O
,	O
Philadelphia	O
,	O
PA	O
.	O
,	O
as	O
a	O
visiting	O
scholar	O
.	O
	
From	O
February	O
2013	O
to	O
September	O
2013	O
,	O
he	O
was	O
with	O
the	O
University	O
of	O
California	O
,	O
Los	O
Angeles	O
(	O
UCLA	O
)	O
,	O
as	O
a	O
visiting	O
graduate	O
researcher	O
.	O
	
He	O
is	O
a	O
reviewer	O
of	O
IEEE	O
Trans	O
on	O
PAMI	O
,	O
IEEE	O
Trans	O
on	O
Image	O
Processing	O
,	O
IEEE	O
Trans	O
.	O
	
on	O
Cybernetics	B-Task
,	O
Pattern	B-Task
Recognition	I-Task
,	O
Computer	B-Task
Vision	I-Task
and	O
Image	B-Task
Understanding	I-Task
,	O
Neurocomputing	B-Task
,	O
NIPS	B-Material
,	O
ICML	B-Material
,	O
CVPR	B-Material
,	O
ICCV	B-Material
and	O
ECCV	B-Material
etc	O
.	O
	
His	O
research	O
interests	O
include	O
computer	B-Task
vision	I-Task
and	O
machine	B-Task
learning	I-Task
,	O
especially	O
object	B-Task
recognition	I-Task
.	O
	
[	O
]	O
Song	O
Bai	O
received	O
the	O
B.S.	O
and	O
Ph.D.	O
degree	O
in	O
Electronics	O
and	O
Information	B-Task
Engineering	I-Task
from	O
Huazhong	O
University	O
of	O
Science	O
and	O
Technology	O
(	O
HUST	O
)	O
,	O
Wuhan	O
,	O
China	O
in	O
2013	O
and	O
2018	O
,	O
respectively	O
.	O
	
He	O
was	O
with	O
University	O
of	O
Texas	O
at	O
San	O
Antonio	O
(	O
UTSA	O
)	O
and	O
Johns	O
Hopkins	O
University	O
(	O
JHU	O
)	O
as	O
a	O
research	O
scholar	O
.	O
	
His	O
research	O
interests	O
include	O
image	B-Task
retrieval	I-Task
and	O
classification	B-Task
,	O
3D	B-Task
shape	I-Task
recognition	I-Task
,	O
person	B-Task
re	I-Task
-	I-Task
identification	I-Task
,	O
semantic	B-Task
segmentation	I-Task
and	O
deep	B-Task
learning	I-Task
.	O
	
More	O
information	O
can	O
be	O
found	O
in	O
his	O
homepage	O
:	O
.	O
	
[	O
]	O
Wei	O
Shen	O
received	O
his	O
B.S.	O
and	O
Ph.D.	O
degree	O
both	O
in	O
Electronics	B-Task
and	I-Task
Information	I-Task
Engineering	I-Task
from	O
the	O
Huazhong	O
University	O
of	O
Science	O
and	O
Technology	O
(	O
HUST	O
)	O
,	O
Wuhan	O
,	O
China	O
,	O
in	O
2007	O
and	O
in	O
2012	B-Material
.	O
	
From	O
April	O
2011	O
to	O
November	O
2011	O
,	O
he	O
worked	O
in	O
Microsoft	O
Research	O
Asia	O
as	O
an	O
intern	O
.	O
	
In	O
2012	B-Material
,	O
he	O
joined	O
School	O
of	O
Communication	B-Task
and	I-Task
Information	I-Task
Engineering	I-Task
,	O
Shanghai	O
University	O
as	O
an	O
Assistant	O
Professor	O
.	O
	
From	O
2017	O
,	O
he	O
became	O
an	O
Associate	O
Professor	O
.	O
	
He	O
is	O
currently	O
visiting	O
Department	O
of	O
Computer	B-Task
Science	I-Task
,	O
Johns	O
Hopkins	O
University	O
.	O
	
His	O
current	O
research	O
interests	O
include	O
random	B-Task
forests	I-Task
,	O
deep	B-Task
learning	I-Task
,	O
object	B-Task
detection	I-Task
and	O
segmentation	O
.	O
	
[	O
]	O
Xiang	O
Bai	O
received	O
his	O
B.S.	O
,	O
M.S.	O
,	O
and	O
Ph.D.	O
degrees	O
from	O
the	O
Huazhong	O
University	O
of	O
Science	O
and	O
Technology	O
(	O
HUST	O
)	O
,	O
Wuhan	O
,	O
China	O
,	O
in	O
2003	O
,	O
2005	O
,	O
and	O
2009	O
,	O
respectively	O
,	O
all	O
in	O
electronics	B-Task
and	I-Task
information	I-Task
engineering	I-Task
.	O
	
He	O
is	O
currently	O
a	O
Professor	O
with	O
the	O
School	O
of	O
Electronic	B-Task
Information	I-Task
and	I-Task
Communications	I-Task
,	O
HUST	B-Material
.	O
	
He	O
is	O
also	O
the	O
Vice	O
-	O
director	O
of	O
the	O
National	O
Center	O
of	O
Anti	B-Task
-	I-Task
Counterfeiting	I-Task
Technology	I-Task
,	O
HUST	B-Material
.	O
	
His	O
research	O
interests	O
include	O
object	B-Task
recognition	I-Task
,	O
shape	B-Task
analysis	I-Task
,	O
scene	B-Task
text	I-Task
recognition	I-Task
and	O
intelligent	B-Task
systems	I-Task
.	O
	
He	O
serves	O
as	O
an	O
associate	O
editor	O
for	O
Pattern	B-Task
Recognition	I-Task
,	O
Pattern	B-Task
Recognition	I-Task
Letters	I-Task
,	O
Neurocomputing	B-Task
and	I-Task
Frontiers	I-Task
of	I-Task
Computer	I-Task
Science	I-Task
.	O
	
[	O
]	O
Wenyu	O
Liu	O
received	O
the	O
B.S.	O
degree	O
in	O
Computer	B-Task
Science	I-Task
from	O
Tsinghua	O
University	O
,	O
Beijing	O
,	O
China	O
,	O
in	O
1986	O
,	O
and	O
the	O
M.S.	O
and	O
Ph.D.	O
degrees	O
,	O
both	O
in	O
Electronics	B-Task
and	I-Task
Information	I-Task
Engineering	I-Task
,	O
from	O
Huazhong	O
University	O
of	O
Science	O
and	O
Technology	O
(	O
HUST	O
)	O
,	O
Wuhan	O
,	O
China	O
,	O
in	O
1991	O
and	O
2001	O
,	O
respectively	O
.	O
	
He	O
is	O
now	O
a	O
professor	O
and	O
associate	O
dean	O
of	O
the	O
School	O
of	O
Electronic	B-Task
Information	I-Task
and	I-Task
Communications	I-Task
,	O
HUST	B-Material
.	O
	
His	O
current	O
research	O
areas	O
include	O
computer	B-Task
vision	I-Task
,	O
multimedia	B-Task
,	O
and	O
machine	B-Task
learning	I-Task
.	O
	
He	O
is	O
a	O
senior	O
member	O
of	O
IEEE	O
.	O
	
[	O
]	O
Alan	O
Yuille	O
received	O
the	O
B.A.	O
degree	O
in	O
mathematics	O
from	O
the	O
University	O
of	O
Cambridge	O
in	O
1976	O
,	O
and	O
the	O
Ph.D.	O
degree	O
in	O
theoretical	O
physics	O
from	O
Cambridge	O
in	O
1980	O
.	O
	
He	O
then	O
held	O
a	O
post	O
-	O
doctoral	O
position	O
with	O
the	O
Physics	O
Department	O
,	O
University	O
of	O
Texas	O
,	O
Austin	O
,	O
and	O
the	O
Institute	O
for	O
Theoretical	O
Physics	O
,	O
Santa	O
Barbara	O
.	O
	
He	O
then	O
became	O
a	O
Research	O
Scientists	O
with	O
the	O
Artificial	O
Intelligence	O
Laboratory	O
,	O
MIT	O
,	O
from	O
1982	O
to	O
1986	O
,	O
and	O
followed	O
this	O
with	O
a	O
faculty	O
position	O
in	O
the	O
division	O
of	O
applied	O
sciences	O
,	O
Harvard	O
,	O
from	O
1986	O
to	O
1995	O
,	O
rising	O
to	O
the	O
position	O
of	O
an	O
associate	O
professor	O
.	O
	
From	O
1995	O
to	O
2002	O
,	O
he	O
was	O
a	O
Senior	O
Scientist	O
with	O
the	O
Smith	O
-	O
Kettlewell	O
Eye	O
Research	O
Institute	O
in	O
San	O
Francisco	O
.	O
	
From	O
2002	O
to	O
2016	O
,	O
he	O
was	O
a	O
Full	O
Professor	O
with	O
the	O
Department	O
of	O
Statistics	O
,	O
UCLA	O
,	O
with	O
joint	O
appointments	O
in	O
Psychology	O
,	O
Computer	O
Science	O
,	O
and	O
Psychiatry	O
.	O
	
In	O
2016	O
,	O
he	O
became	O
a	O
Bloomberg	O
Distinguished	O
Professor	O
of	O
cognitive	O
science	O
and	O
computer	O
science	O
with	O
Johns	O
Hopkins	O
University	O
.	O
	
He	O
received	O
the	O
Marr	O
Prize	O
and	O
the	O
Helmholtz	O
Prize	O
.	O
	
document	O
:	O
Aggregate	B-Method
Channel	I-Method
Features	I-Method
for	O
Multi	B-Task
-	I-Task
view	I-Task
Face	I-Task
Detection	I-Task
	
Face	O
detection	B-Task
has	O
drawn	O
much	O
attention	O
in	O
recent	O
decades	O
since	O
the	O
seminal	O
work	O
by	O
Viola	O
and	O
Jones	O
.	O
	
While	O
many	O
subsequences	O
have	O
improved	O
the	O
work	O
with	O
more	O
powerful	O
learning	B-Method
algorithms	I-Method
,	O
the	O
feature	B-Method
representation	I-Method
used	O
for	O
face	O
detection	B-Task
still	O
ca	O
n’t	O
meet	O
the	O
demand	O
for	O
effectively	O
and	O
efficiently	O
handling	O
faces	O
with	O
large	O
appearance	O
variance	O
in	O
the	O
wild	O
.	O
	
To	O
solve	O
this	O
bottleneck	O
,	O
we	O
borrow	O
the	O
concept	O
of	O
channel	O
features	O
to	O
the	O
face	O
detection	B-Task
domain	O
,	O
which	O
extends	O
the	O
image	O
channel	O
to	O
diverse	O
types	O
like	O
gradient	O
magnitude	O
and	O
oriented	O
gradient	O
histograms	O
and	O
therefore	O
encodes	O
rich	O
information	O
in	O
a	O
simple	O
form	O
.	O
	
We	O
adopt	O
a	O
novel	O
variant	O
called	O
aggregate	B-Method
channel	I-Method
features	I-Method
,	O
make	O
a	O
full	O
exploration	O
of	O
feature	B-Method
design	I-Method
,	O
and	O
discover	O
a	O
multi	B-Method
-	I-Method
scale	I-Method
version	I-Method
of	I-Method
features	I-Method
with	O
better	O
performance	O
.	O
	
To	O
deal	O
with	O
poses	O
of	O
faces	O
in	O
the	O
wild	O
,	O
we	O
propose	O
a	O
multi	O
-	O
view	O
detection	B-Task
approach	O
featuring	O
score	B-Method
re	I-Method
-	I-Method
ranking	I-Method
and	O
detection	B-Task
adjustment	O
.	O
	
Following	O
the	O
learning	B-Method
pipelines	I-Method
in	O
Viola	B-Method
-	I-Method
Jones	I-Method
framework	I-Method
,	O
the	O
multi	B-Method
-	I-Method
view	I-Method
face	I-Method
detector	I-Method
using	O
aggregate	B-Method
channel	I-Method
features	I-Method
shows	O
competitive	O
performance	O
against	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
algorithms	O
on	O
AFW	B-Material
and	O
FDDB	B-Material
testsets	O
,	O
while	O
runs	O
at	O
42	O
FPS	B-Metric
on	O
VGA	B-Material
images	I-Material
.	O
	
section	O
:	O
Introduction	O
	
Human	O
face	O
detection	B-Task
have	O
long	O
been	O
one	O
of	O
the	O
most	O
fundamental	O
problems	O
in	O
computer	B-Task
vision	I-Task
and	O
human	B-Task
-	I-Task
computer	I-Task
interaction	I-Task
.	O
	
In	O
the	O
past	O
decade	O
,	O
the	O
most	O
influential	O
work	O
should	O
be	O
the	O
face	O
detection	B-Task
framework	O
proposed	O
by	O
Viola	O
and	O
Jones	O
.	O
	
The	O
Viola	O
-	O
Jones	O
(	O
abbreviated	O
as	O
VJ	O
below	O
)	O
	
framework	O
uses	O
rectangular	O
Haar	O
-	O
like	O
features	O
and	O
learns	O
the	O
hypothesis	O
using	O
Adaboost	B-Method
algorithm	I-Method
.	O
	
Combined	O
with	O
the	O
attentional	B-Method
cascade	I-Method
structure	I-Method
,	O
the	O
VJ	B-Method
detector	I-Method
achieved	O
real	O
-	O
time	O
face	O
detection	B-Task
at	O
that	O
time	O
.	O
	
Despite	O
the	O
great	O
success	O
of	O
the	O
VJ	B-Method
detector	I-Method
,	O
the	O
performance	O
is	O
still	O
far	O
from	O
satisfactory	O
due	O
to	O
the	O
large	O
appearance	O
variance	O
of	O
faces	O
in	O
unconstrained	O
settings	O
.	O
	
To	O
handle	O
faces	O
in	O
the	O
wild	O
,	O
many	O
subsequences	O
of	O
VJ	B-Method
framework	I-Method
merged	O
.	O
	
These	O
methods	O
mainly	O
get	O
the	O
performance	O
gains	O
in	O
two	O
aspects	O
,	O
more	O
complicated	O
features	O
and	O
(	O
or	O
)	O
more	O
powerful	O
learning	B-Method
algorithms	I-Method
.	O
	
As	O
the	O
combination	O
of	O
boosting	B-Method
and	O
cascade	B-Method
has	O
been	O
proven	O
to	O
be	O
quite	O
effective	O
in	O
face	O
detection	B-Task
,	O
the	O
bottleneck	O
lies	O
in	O
the	O
feature	B-Method
representation	I-Method
since	O
complicated	O
features	O
adopted	O
in	O
the	O
above	O
literatures	O
bring	O
about	O
limited	O
performance	O
gains	O
at	O
the	O
cost	O
of	O
large	O
computation	B-Metric
cost	I-Metric
.	O
	
Lately	O
in	O
another	O
domain	O
of	O
pedestrian	B-Task
detection	I-Task
,	O
a	O
family	O
of	O
channel	B-Method
features	I-Method
has	O
achieved	O
record	O
performances	O
.	O
	
Channel	B-Method
features	I-Method
compute	O
registered	O
maps	O
of	O
the	O
original	O
images	O
like	O
gradients	O
and	O
histograms	O
of	O
oriented	O
gradients	O
and	O
then	O
extract	O
features	O
on	O
these	O
extended	O
channels	O
.	O
	
The	O
classifier	B-Method
learning	I-Method
process	I-Method
follows	O
the	O
VJ	B-Method
framework	I-Method
pipeline	I-Method
.	O
	
In	O
this	O
paper	O
,	O
we	O
adopt	O
a	O
variant	O
of	O
channel	O
features	O
called	O
aggregate	B-Method
channel	I-Method
features	I-Method
,	O
which	O
are	O
extracted	O
directly	O
as	O
pixel	O
values	O
on	O
subsampled	O
channels	O
.	O
	
Channel	B-Method
extension	I-Method
offers	O
rich	O
representation	O
capacity	O
,	O
while	O
simple	O
feature	O
form	O
guarantees	O
fast	O
computation	O
.	O
	
With	O
these	O
two	O
superiorities	O
,	O
the	O
aggregate	O
channel	O
features	O
break	O
through	O
the	O
bottleneck	O
in	O
VJ	B-Method
framework	I-Method
and	O
have	O
the	O
potential	O
to	O
make	O
great	O
advance	O
in	O
face	O
detection	B-Task
.	O
	
As	O
we	O
mainly	O
concentrate	O
our	O
efforts	O
to	O
the	O
feature	B-Method
representation	I-Method
rather	O
than	O
learning	B-Method
algorithms	I-Method
in	O
this	O
paper	O
,	O
we	O
not	O
only	O
just	O
adopt	O
the	O
aggregate	B-Method
channel	I-Method
features	I-Method
in	O
face	O
detection	B-Task
,	O
but	O
also	O
try	O
to	O
explore	O
the	O
full	O
potential	O
of	O
this	O
novel	O
representation	O
.	O
	
To	O
do	O
so	O
,	O
we	O
make	O
a	O
deep	O
and	O
all	O
-	O
round	O
investigation	O
into	O
the	O
specific	O
feature	O
parameters	O
concerning	O
channel	O
types	O
,	O
feature	O
pool	O
size	O
,	O
subsampling	B-Method
method	I-Method
,	O
feature	O
scale	O
and	O
so	O
on	O
,	O
which	O
gives	O
insights	O
into	O
the	O
feature	B-Method
design	I-Method
and	O
hopefully	O
provides	O
helpful	O
guidelines	O
for	O
practitioners	O
.	O
	
Through	O
the	O
deep	O
exploration	O
,	O
we	O
find	O
that	O
:	O
1	O
)	O
multi	B-Method
-	I-Method
scaling	I-Method
the	O
feature	B-Method
representation	I-Method
further	O
enriches	O
the	O
representation	O
capacity	O
since	O
original	O
aggregate	O
channel	O
features	O
have	O
uniform	O
feature	O
scale	O
;	O
2	O
)	O
different	O
combinations	O
of	O
channel	O
types	O
impact	O
the	O
performance	O
greatly	O
,	O
while	O
for	O
face	O
detection	B-Task
the	O
color	O
channel	O
in	O
LUV	O
space	O
,	O
plus	O
gradient	O
magnitude	O
channel	O
and	O
gradient	O
histograms	O
channels	O
in	O
RGB	O
space	O
show	O
best	O
result	O
;	O
3	O
)	O
multi	B-Task
-	I-Task
view	I-Task
detection	I-Task
is	O
proven	O
to	O
be	O
a	O
good	O
match	O
with	O
aggregate	O
channel	O
features	O
as	O
the	O
representation	O
naturally	O
encodes	O
the	O
facial	O
structure	O
(	O
Figure	O
[	O
reference	O
]	O
)	O
.	O
	
Although	O
multi	B-Task
-	I-Task
view	I-Task
detection	I-Task
could	O
effectively	O
deal	O
with	O
diverse	O
poses	O
,	O
additional	O
issues	O
come	O
up	O
as	O
how	O
to	O
merge	O
detections	O
output	O
by	O
separately	O
trained	O
subview	B-Method
detectors	I-Method
,	O
and	O
how	O
to	O
deal	O
with	O
the	O
offsets	O
of	O
location	O
and	O
scale	O
between	O
output	O
detections	O
and	O
ground	O
-	O
truth	O
.	O
	
We	O
solve	O
these	O
problems	O
by	O
carefully	O
designed	O
post	B-Method
-	I-Method
processing	I-Method
including	O
score	B-Task
re	I-Task
-	I-Task
ranking	I-Task
,	O
detection	B-Task
merging	I-Task
and	O
bounding	B-Task
box	I-Task
adjustment	I-Task
.	O
	
The	O
detailed	O
experimental	O
exploration	O
of	O
aggregate	O
channel	O
features	O
,	O
along	O
with	O
our	O
improvements	O
on	O
multi	B-Task
-	I-Task
view	I-Task
detection	I-Task
,	O
leads	O
to	O
large	O
performance	O
gain	O
in	O
face	O
detection	B-Task
in	O
the	O
wild	O
.	O
	
On	O
two	O
challenging	O
face	O
databases	O
,	O
AFW	B-Material
and	O
FDDB	B-Material
,	O
the	O
proposed	O
multi	B-Method
-	I-Method
view	I-Method
face	I-Method
detector	I-Method
shows	O
competitive	O
performance	O
against	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
detectors	O
in	O
both	O
detection	B-Task
accuracy	I-Metric
and	O
speed	B-Metric
.	O
	
The	O
remaining	O
parts	O
of	O
this	O
paper	O
are	O
organized	O
as	O
follows	O
.	O
	
Section	O
2	O
revisits	O
related	O
work	O
in	O
face	O
detection	B-Task
.	O
	
Section	O
3	O
describes	O
how	O
we	O
build	O
the	O
face	B-Method
detector	I-Method
using	O
aggregate	B-Method
channel	I-Method
features	I-Method
.	O
	
Section	O
4	O
addresses	O
problems	O
concerning	O
multi	O
-	O
view	O
face	O
detection	B-Task
.	O
	
Experimental	O
results	O
on	O
AFW	B-Material
and	O
FDDB	B-Material
are	O
shown	O
in	O
section	O
5	O
and	O
we	O
conclude	O
the	O
paper	O
in	O
section	O
6	O
.	O
	
section	O
:	O
Related	O
work	O
	
Face	O
detection	B-Task
has	O
drawn	O
much	O
attention	O
since	O
the	O
early	O
time	O
of	O
computer	B-Task
vision	I-Task
.	O
	
Although	O
many	O
solutions	O
had	O
been	O
put	O
forward	O
,	O
it	O
was	O
not	O
until	O
Viola	O
and	O
Jones	O
proposed	O
their	O
milestone	O
work	O
that	O
face	O
detection	B-Task
saw	O
surprising	O
progress	O
in	O
the	O
past	O
decades	O
.	O
	
The	O
VJ	B-Method
face	I-Method
detector	I-Method
features	I-Method
in	O
three	O
aspects	O
:	O
fast	O
feature	B-Task
computation	I-Task
via	O
integral	B-Method
image	I-Method
representation	I-Method
,	O
classifier	B-Method
learning	I-Method
using	O
Adaboost	B-Method
,	O
and	O
the	O
attentional	B-Method
cascade	I-Method
structure	I-Method
.	O
	
One	O
main	O
drawback	O
of	O
the	O
VJ	B-Method
framework	I-Method
is	O
that	O
the	O
features	O
have	O
limited	O
representation	O
capacity	O
,	O
while	O
the	O
feature	O
pool	O
size	O
is	O
quite	O
large	O
to	O
compensate	O
for	O
that	O
.	O
	
Typically	O
,	O
in	O
a	O
detection	B-Task
window	O
,	O
the	O
number	O
of	O
Haar	O
-	O
like	O
features	O
is	O
160	O
,	O
000	O
.	O
	
To	O
address	O
the	O
problem	O
,	O
efforts	O
are	O
made	O
in	O
two	O
directions	O
.	O
	
Some	O
focus	O
on	O
more	O
complicated	O
features	O
like	O
HoG	O
,	O
SURF	O
.	O
	
Some	O
aim	O
to	O
speed	O
up	O
the	O
feature	B-Task
selection	I-Task
in	O
a	O
heuristic	O
way	O
.	O
	
However	O
,	O
the	O
problem	O
has	O
n’t	O
been	O
solved	O
perfectly	O
.	O
	
In	O
this	O
paper	O
,	O
we	O
mainly	O
focus	O
on	O
the	O
feature	B-Method
representation	I-Method
part	I-Method
and	O
make	O
a	O
deep	O
exploration	O
into	O
it	O
,	O
which	O
is	O
complementary	O
to	O
existing	O
work	O
on	O
the	O
learning	B-Method
algorithm	I-Method
and	O
classifier	B-Method
structure	I-Method
in	O
the	O
VJ	B-Method
framework	I-Method
.	O
	
Recently	O
channel	B-Method
features	I-Method
have	O
been	O
proposed	O
and	O
shown	O
record	O
performance	O
in	O
pedestrian	B-Task
detection	I-Task
.	O
	
Due	O
to	O
the	O
channel	B-Method
extension	I-Method
to	O
diverse	O
types	O
like	O
gradients	O
and	O
local	O
histograms	O
,	O
the	O
features	O
show	O
richer	O
representation	B-Metric
capacity	I-Metric
for	O
classification	B-Task
.	O
	
However	O
,	O
the	O
features	O
are	O
extracted	O
as	O
rectangular	O
sums	O
at	O
various	O
locations	O
and	O
scales	O
which	O
we	O
believe	O
leads	O
to	O
a	O
redundant	O
feature	O
pool	O
.	O
	
During	O
preparation	O
of	O
this	O
paper	O
,	O
Mathias	O
independently	O
discover	O
the	O
effectiveness	O
of	O
integral	B-Method
channel	I-Method
features	I-Method
in	O
face	O
detection	B-Task
domain	O
.	O
	
In	O
this	O
paper	O
,	O
we	O
adopt	O
a	O
novel	O
variant	O
of	O
channel	B-Method
features	I-Method
called	O
aggregate	B-Method
channel	I-Method
features	I-Method
,	O
which	O
extract	O
features	O
directly	O
as	O
pixel	O
values	O
in	O
extended	O
channels	O
without	O
computing	O
rectangular	O
sums	O
at	O
various	O
locations	O
and	O
scales	O
.	O
	
The	O
feature	O
has	O
powerful	O
representation	B-Method
capacity	I-Method
and	O
the	O
feature	B-Metric
pool	I-Metric
size	I-Metric
is	O
only	O
several	O
thousands	O
.	O
	
Through	O
careful	O
design	O
in	O
section	O
3	O
and	O
implementation	O
of	O
multi	B-Task
-	I-Task
view	I-Task
detection	I-Task
in	O
section	O
4	O
,	O
the	O
aggregate	B-Method
channel	I-Method
features	I-Method
based	I-Method
detector	I-Method
achieves	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
performance	O
on	O
challenging	O
databases	O
.	O
	
section	O
:	O
Proposed	O
face	B-Method
detector	I-Method
	
In	O
this	O
section	O
,	O
we	O
make	O
a	O
full	O
exploration	O
of	O
the	O
aggregate	O
channel	O
features	O
in	O
the	O
context	O
of	O
face	O
detection	B-Task
.	O
	
We	O
first	O
give	O
a	O
brief	O
introduction	O
of	O
the	O
feature	O
itself	O
,	O
including	O
its	O
computation	O
,	O
properties	O
and	O
advantages	O
over	O
traditional	O
Haar	B-Method
-	I-Method
like	I-Method
features	I-Method
used	O
in	O
VJ	O
framework	O
.	O
	
Then	O
the	O
detailed	O
experimental	O
investigation	O
is	O
described	O
in	O
two	O
parts	O
,	O
feature	B-Method
design	I-Method
and	O
training	B-Task
design	I-Task
.	O
	
Before	O
that	O
,	O
some	O
guidelines	O
concerning	O
how	O
we	O
conduct	O
the	O
investigation	O
are	O
demonstrated	O
.	O
	
Each	O
design	O
part	O
is	O
divided	O
into	O
several	O
separate	O
experiments	O
ended	O
with	O
a	O
summary	O
explaining	O
the	O
specific	O
parameters	O
used	O
in	O
our	O
proposed	O
face	B-Method
detector	I-Method
.	O
	
Note	O
that	O
each	O
experiment	O
focuses	O
on	O
only	O
one	O
parameter	O
and	O
the	O
others	O
remain	O
constant	O
.	O
	
Through	O
the	O
well	O
-	O
designed	O
experiments	O
,	O
the	O
proposed	O
face	B-Method
detector	I-Method
based	O
on	O
aggregate	O
channel	O
features	O
is	O
built	O
step	O
by	O
step	O
.	O
	
Issues	O
concerning	O
the	O
implementation	O
of	O
multi	O
-	O
view	O
face	O
detection	B-Task
which	O
further	O
improves	O
the	O
performance	O
are	O
discussed	O
in	O
the	O
next	O
section	O
.	O
	
subsection	O
:	O
Feature	B-Method
description	I-Method
	
Channel	B-Method
extension	I-Method
:	O
The	O
basic	O
structure	O
of	O
the	O
aggregate	O
channel	O
features	O
is	O
channel	O
.	O
	
The	O
application	O
of	O
channel	B-Method
has	O
a	O
long	O
history	O
since	O
digital	O
images	O
were	O
invented	O
.	O
	
The	O
most	O
common	O
type	O
of	O
channel	O
should	O
be	O
the	O
color	O
channels	O
of	O
the	O
image	O
,	O
with	O
Gray	O
-	O
scale	O
and	O
RGB	O
being	O
typical	O
ones	O
.	O
	
Besides	O
color	O
channels	O
,	O
many	O
different	O
channel	O
types	O
have	O
been	O
invented	O
to	O
encode	O
different	O
types	O
of	O
information	O
for	O
more	O
difficult	O
problems	O
.	O
	
Generally	O
,	O
channels	O
can	O
be	O
defined	O
as	O
a	O
registered	B-Method
map	I-Method
of	O
the	O
original	O
image	O
,	O
whose	O
pixels	O
are	O
computed	O
from	O
corresponding	O
patches	O
of	O
original	O
pixels	O
.	O
	
Different	O
channels	O
can	O
be	O
computed	O
with	O
linear	B-Method
or	I-Method
non	I-Method
-	I-Method
linear	I-Method
transformation	I-Method
of	O
the	O
original	O
image	O
.	O
	
To	O
allow	O
for	O
sliding	O
window	O
detection	B-Task
,	O
the	O
transformations	O
are	O
constrained	O
to	O
be	O
translationally	O
invariant	O
.	O
	
Feature	B-Task
computation	I-Task
:	O
	
Based	O
on	O
the	O
definition	O
of	O
channels	O
,	O
the	O
computation	B-Task
of	I-Task
aggregate	I-Task
channel	I-Task
features	I-Task
is	O
quite	O
simple	O
.	O
	
As	O
shown	O
in	O
Figure	O
[	O
reference	O
]	O
,	O
given	O
a	O
color	O
image	O
,	O
all	O
defined	O
channels	O
are	O
computed	O
and	O
subsampled	O
by	O
a	O
pre	O
-	O
set	O
factor	O
.	O
	
The	O
aggregate	O
pixels	O
in	O
all	O
subsampled	O
channels	O
are	O
then	O
vectorized	O
into	O
a	O
pixel	O
look	O
-	O
up	O
table	O
.	O
	
Note	O
that	O
an	O
optional	O
smoothing	B-Method
procedure	I-Method
can	O
be	O
done	O
on	O
each	O
channel	O
with	O
a	O
binomial	B-Method
filter	I-Method
both	O
before	O
computation	O
and	O
after	O
subsampling	B-Method
.	O
	
Classifier	B-Method
learning	I-Method
:	O
The	O
learning	B-Method
process	I-Method
is	O
quite	O
simple	O
.	O
	
Two	O
changes	O
are	O
made	O
compared	O
with	O
VJ	B-Method
framework	I-Method
.	O
	
First	O
is	O
that	O
weak	B-Method
classifier	I-Method
is	O
changed	O
from	O
decision	O
stump	O
to	O
depth	O
-	O
2	O
decision	O
tree	O
.	O
	
The	O
more	O
complex	O
weak	B-Method
classifier	I-Method
shows	O
stronger	O
ability	O
in	O
seeking	O
the	O
discriminant	O
intra	O
and	O
inter	O
channel	O
correlations	O
for	O
classification	B-Task
.	O
	
Second	O
difference	O
is	O
that	O
soft	B-Method
-	I-Method
cascade	I-Method
structure	I-Method
is	O
used	O
.	O
	
Unlike	O
the	O
attentional	B-Method
cascade	I-Method
structure	I-Method
in	O
VJ	B-Method
framework	I-Method
which	O
has	O
several	O
cascade	B-Method
stages	I-Method
,	O
a	O
single	B-Method
-	I-Method
stage	I-Method
classifier	I-Method
is	O
trained	O
on	O
the	O
whole	O
training	O
data	O
and	O
a	O
threshold	O
is	O
then	O
set	O
after	O
each	O
weak	B-Method
classifier	I-Method
picked	O
by	O
Adaboost	B-Method
.	O
	
These	O
two	O
changes	O
lead	O
to	O
more	O
efficient	O
training	B-Task
and	O
detection	B-Task
.	O
	
Overall	O
superiority	O
:	O
	
Compared	O
with	O
traditional	O
Haar	B-Method
-	I-Method
like	I-Method
features	I-Method
used	O
in	O
VJ	B-Method
framework	I-Method
,	O
aggregate	B-Method
channel	I-Method
features	I-Method
have	O
the	O
following	O
differences	O
and	O
advantages	O
:	O
1	O
)	O
	
The	O
image	O
channels	O
are	O
extended	O
to	O
more	O
types	O
in	O
order	O
to	O
encode	O
diverse	O
information	O
like	O
color	O
,	O
gradients	O
,	O
local	O
histograms	O
and	O
so	O
on	O
,	O
therefore	O
possess	O
richer	O
representation	O
capacity	O
.	O
	
2	O
)	O
	
Features	O
are	O
extracted	O
directly	O
as	O
pixel	O
values	O
on	O
downsampled	O
channels	O
rather	O
than	O
computing	O
rectangular	O
sums	O
with	O
various	O
locations	O
and	O
scales	O
using	O
integral	O
images	O
,	O
leading	O
to	O
a	O
faster	O
feature	B-Task
computation	I-Task
and	O
smaller	O
feature	B-Metric
pool	I-Metric
size	I-Metric
for	O
boosting	B-Method
learning	I-Method
.	O
	
With	O
the	O
help	O
of	O
cascade	B-Method
structure	I-Method
,	O
detection	B-Task
speed	O
is	O
accelerated	O
more	O
.	O
	
3	O
)	O
	
Due	O
to	O
its	O
structure	O
consistence	O
with	O
the	O
overall	O
image	O
,	O
when	O
coupled	O
with	O
boosting	B-Method
method	I-Method
,	O
the	O
boosted	B-Method
classifier	I-Method
naturally	O
encodes	O
structured	O
pattern	O
information	O
from	O
large	O
training	O
data	O
(	O
see	O
Figure	O
[	O
reference	O
]	O
for	O
an	O
illustration	O
)	O
,	O
which	O
gives	O
more	O
accurate	O
localization	B-Task
of	I-Task
faces	I-Task
in	O
the	O
image	O
.	O
	
subsection	O
:	O
Investigation	O
guidelines	O
	
All	O
investigations	O
are	O
trained	O
on	O
the	O
AFLW	B-Material
face	O
database	O
and	O
tested	O
on	O
the	O
Annotated	B-Material
Faces	I-Material
in	I-Material
the	I-Material
Wild	I-Material
(	O
AFW	B-Material
)	O
testset	O
.	O
	
To	O
make	O
it	O
clear	O
,	O
there	O
are	O
in	O
total	O
positive	O
samples	O
and	O
negative	O
samples	O
selected	O
from	O
AFLW	B-Material
which	O
are	O
kept	O
constant	O
in	O
all	O
investigations	O
.	O
	
Testset	O
contains	O
natural	O
images	O
with	O
faces	O
that	O
vary	O
a	O
lot	O
in	O
pose	O
,	O
appearance	O
and	O
illumination	O
.	O
	
To	O
alleviate	O
the	O
ground	O
-	O
truth	O
offset	O
caused	O
by	O
different	O
annotation	O
styles	O
(	O
Figure	O
[	O
reference	O
]	O
)	O
in	O
training	O
and	O
testing	O
set	O
and	O
make	O
the	O
evaluation	O
more	O
comparable	O
,	O
a	O
lower	O
Jaccard	B-Metric
index	I-Metric
with	O
threshold	O
is	O
adopted	O
in	O
comparative	B-Metric
evaluation	I-Metric
.	O
	
Practically	O
the	O
lower	O
threshold	O
wo	O
n’t	O
cause	O
errors	O
being	O
mistakenly	O
corrected	O
.	O
	
Note	O
that	O
in	O
final	O
evaluation	O
of	O
the	O
proposed	O
face	B-Method
detector	I-Method
(	O
section	O
5	O
)	O
,	O
the	O
AFW	B-Material
testset	O
,	O
together	O
with	O
another	O
face	O
benchmark	O
FDDB	B-Material
database	O
,	O
are	O
used	O
as	O
testbed	O
and	O
the	O
evaluation	B-Metric
metric	I-Metric
follows	O
the	O
database	O
protocol	O
.	O
	
subsection	O
:	O
Feature	B-Method
design	I-Method
	
To	O
fully	O
exploit	O
the	O
power	O
of	O
aggregate	O
channel	O
features	O
in	O
face	O
detection	B-Task
domain	O
,	O
a	O
deep	O
investigation	O
into	O
the	O
design	O
of	O
the	O
feature	O
is	O
done	O
mainly	O
on	O
channel	O
types	O
,	O
window	O
size	O
,	O
subsampling	B-Method
method	I-Method
and	O
feature	O
scale	O
.	O
	
Results	O
of	O
comparative	O
experiments	O
are	O
shown	O
in	O
Figure	O
[	O
reference	O
]	O
.	O
	
Channel	O
types	O
:	O
Three	O
types	O
of	O
channels	O
are	O
used	O
,	O
which	O
are	O
color	O
channel	O
(	O
Gray	O
-	O
scale	O
,	O
RGB	O
,	O
HSV	O
and	O
LUV	O
)	O
,	O
gradient	O
magnitude	O
,	O
and	O
gradient	B-Method
histograms	I-Method
.	O
	
The	O
computation	O
of	O
the	O
latter	O
two	O
channel	O
types	O
could	O
be	O
seen	O
as	O
a	O
generalized	O
version	O
of	O
HoG	B-Method
features	I-Method
.	O
	
Specifically	O
,	O
gradient	O
magnitude	O
is	O
the	O
biggest	O
response	O
on	O
all	O
three	O
color	O
channels	O
,	O
and	O
oriented	O
gradient	O
histograms	O
follow	O
the	O
idea	O
of	O
HoG	B-Method
in	O
that	O
:	O
1	O
)	O
rectangular	O
cell	O
size	O
in	O
HoG	B-Method
equals	O
the	O
subsampling	O
factor	O
in	O
aggregated	O
channel	O
features	O
;	O
2	O
)	O
each	O
orientation	O
bin	O
results	O
in	O
one	O
feature	O
channel	O
(	O
6	O
orientation	O
bins	O
are	O
used	O
in	O
this	O
paper	O
)	O
.	O
	
Figure	O
[	O
reference	O
]	O
(	O
a	O
)	O
~	O
(	O
c	O
)	O
show	O
how	O
much	O
each	O
of	O
these	O
three	O
types	O
alone	O
contributes	O
to	O
the	O
performance	O
of	O
face	O
detection	B-Task
.	O
	
It	O
can	O
be	O
seen	O
that	O
the	O
gradient	O
histograms	O
contribute	O
most	O
to	O
the	O
performance	O
among	O
all	O
three	O
channel	O
types	O
.	O
	
Figure	O
[	O
reference	O
]	O
(	O
d	O
)	O
shows	O
the	O
performances	O
of	O
combinations	O
of	O
these	O
three	O
types	O
computed	O
on	O
different	O
color	O
channels	O
.	O
	
Detection	B-Metric
window	I-Metric
size	I-Metric
:	O
	
Detection	B-Metric
window	I-Metric
size	I-Metric
is	O
the	O
scale	O
to	O
which	O
we	O
resize	O
all	O
face	O
and	O
non	O
-	O
face	O
samples	O
and	O
then	O
train	O
our	O
detector	O
.	O
	
Larger	O
window	O
size	O
includes	O
more	O
pixels	O
in	O
feature	O
pool	O
and	O
thus	O
may	O
improve	O
the	O
face	O
detection	B-Task
performance	O
.	O
	
On	O
the	O
other	O
hand	O
,	O
too	O
large	O
window	O
will	O
miss	O
some	O
small	O
faces	O
and	O
diminish	O
the	O
detection	B-Task
efficiency	O
.	O
	
Figure	O
[	O
reference	O
]	O
	
(	O
e	O
)	O
shows	O
comparison	O
of	O
window	O
size	O
ranging	O
from	O
to	O
with	O
a	O
stride	O
of	O
pixels	O
.	O
	
Subsampling	B-Method
:	O
The	O
factor	O
for	O
subsampling	B-Task
can	O
be	O
regarded	O
as	O
the	O
perceptive	O
scale	O
for	O
that	O
it	O
controls	O
the	O
scale	O
at	O
which	O
the	O
aggregation	B-Task
is	O
done	O
.	O
	
Changing	O
the	O
factor	O
from	O
large	O
to	O
small	O
leads	O
to	O
the	O
feature	B-Method
representation	I-Method
shifting	O
from	O
coarse	O
to	O
fine	O
and	O
the	O
feature	O
pool	O
size	O
getting	O
bigger	O
.	O
	
Experiments	O
on	O
different	O
subsampling	O
factors	O
are	O
shown	O
in	O
Figure	O
[	O
reference	O
]	O
	
(	O
f	O
)	O
.	O
	
In	O
original	O
aggregate	O
channel	O
features	O
,	O
the	O
way	O
to	O
do	O
subsampling	B-Method
is	O
average	B-Method
pooling	I-Method
.	O
	
Following	O
the	O
idea	O
in	O
Convolutional	B-Method
Neural	I-Method
Networks	I-Method
,	O
another	O
two	O
ways	O
of	O
subsampling	B-Method
,	O
max	B-Method
pooling	I-Method
and	O
stochastic	B-Method
pooling	I-Method
are	O
tested	O
in	O
Figure	O
[	O
reference	O
]	O
	
(	O
g	O
)	O
.	O
	
Smoothing	B-Method
:	O
	
As	O
described	O
in	O
feature	B-Method
description	I-Method
,	O
both	O
pre	B-Method
and	I-Method
post	I-Method
smoothing	I-Method
is	O
done	O
in	O
default	O
setting	O
of	O
aggregate	O
channel	O
features	O
.	O
	
A	O
binomial	B-Method
filter	I-Method
with	O
a	O
radius	O
of	O
is	O
used	O
for	O
smoothing	B-Task
.	O
	
The	O
smoothing	B-Method
procedure	I-Method
also	O
has	O
a	O
great	O
influence	O
on	O
the	O
scale	O
of	O
the	O
feature	B-Method
representation	I-Method
.	O
	
Concretely	O
,	O
pre	B-Method
-	I-Method
smoothing	I-Method
determines	O
how	O
far	O
the	O
local	O
neighborhood	O
is	O
in	O
which	O
local	O
correlations	O
are	O
encoded	O
before	O
channel	B-Method
computation	I-Method
,	O
while	O
post	B-Method
-	I-Method
smoothing	I-Method
determines	O
the	O
neighborhood	O
size	O
in	O
which	O
the	O
computed	O
channel	O
features	O
are	O
integrated	O
with	O
each	O
other	O
.	O
	
In	O
,	O
the	O
former	O
corresponds	O
to	O
the	O
‘	O
local	O
scale	O
’	O
of	O
the	O
feature	O
,	O
while	O
the	O
latter	O
represents	O
the	O
‘	O
integration	O
scale	O
’	O
.	O
	
We	O
vary	O
the	O
filter	O
radius	O
used	O
in	O
pre	O
and	O
post	B-Task
smoothing	I-Task
and	O
find	O
that	O
both	O
using	O
a	O
radius	O
of	O
gets	O
the	O
best	O
results	O
.	O
	
Figure	O
[	O
reference	O
]	O
(	O
h	O
)	O
~	O
(	O
i	O
)	O
present	O
the	O
comparative	O
results	O
.	O
	
Multi	O
-	O
scale	O
:	O
In	O
aggregate	O
channel	O
features	O
,	O
although	O
hidden	O
information	O
at	O
different	O
scale	O
could	O
be	O
extracted	O
at	O
a	O
cost	O
of	O
more	O
weak	B-Method
classifiers	I-Method
,	O
it	O
would	O
be	O
better	O
to	O
make	O
the	O
integrated	O
channel	O
features	O
multi	O
-	O
scaled	O
and	O
thus	O
make	O
themselves	O
more	O
discriminant	O
.	O
	
Therefore	O
the	O
same	O
or	O
better	O
classification	B-Metric
performance	I-Metric
can	O
be	O
achieved	O
with	O
fewer	O
weak	B-Method
classifiers	I-Method
.	O
	
In	O
this	O
part	O
,	O
we	O
implement	O
three	O
multi	B-Method
-	I-Method
scale	I-Method
version	I-Method
of	I-Method
aggregate	I-Method
channel	I-Method
features	I-Method
in	O
the	O
aforementioned	O
three	O
kinds	O
of	O
scale	O
,	O
perceptive	O
scale	O
(	O
subsampling	B-Method
)	O
,	O
local	O
scale	O
(	O
pre	B-Method
-	I-Method
smoothing	I-Method
)	O
and	O
integration	O
scale	O
(	O
post	B-Method
-	I-Method
smoothing	I-Method
)	O
and	O
compare	O
their	O
performaces	O
.	O
	
See	O
results	O
in	O
Figure	O
[	O
reference	O
]	O
(	O
j	O
)	O
~	O
(	O
l	O
)	O
.	O
	
Summary	O
:	O
	
The	O
color	O
channel	O
,	O
gradient	O
magnitude	O
and	O
gradient	O
histograms	O
prove	O
themselves	O
a	O
good	O
match	O
in	O
aggregate	O
channel	O
features	O
.	O
	
However	O
,	O
different	O
choices	O
of	O
color	O
channel	O
used	O
and	O
on	O
which	O
gradients	O
are	O
computed	O
have	O
a	O
great	O
impact	O
on	O
performance	O
.	O
	
According	O
to	O
the	O
experiments	O
,	O
LUV	O
channel	O
and	O
gradient	O
magnitude	O
and	O
6	O
-	O
bin	O
histograms	O
computed	O
on	O
RGB	O
color	O
space	O
(	O
in	O
total	O
10	O
channels	O
)	O
are	O
the	O
best	O
choice	O
for	O
face	O
detection	B-Task
.	O
	
Larger	O
detection	B-Task
window	O
size	O
generally	O
gets	O
better	O
performance	O
,	O
but	O
will	O
miss	O
many	O
small	O
faces	O
in	O
testing	O
and	O
lead	O
to	O
inefficient	O
detection	B-Task
.	O
	
In	O
this	O
work	O
,	O
we	O
set	O
the	O
size	O
to	O
as	O
its	O
optimal	O
performance	O
.	O
	
A	O
subsampling	O
factor	O
of	O
is	O
most	O
reasonable	O
according	O
to	O
the	O
experiments	O
,	O
while	O
different	O
pooling	B-Method
methods	I-Method
show	O
small	O
differences	O
.	O
	
However	O
,	O
max	B-Method
pooling	I-Method
and	O
stochastic	B-Method
pooling	I-Method
are	O
much	O
slower	O
than	O
average	B-Method
pooling	I-Method
,	O
therefore	O
the	O
average	B-Method
pooling	I-Method
becomes	O
the	O
best	O
match	O
for	O
the	O
sake	O
of	O
efficiency	O
.	O
	
In	O
this	O
way	O
,	O
the	O
resulting	O
feature	B-Metric
pool	I-Metric
size	I-Metric
of	O
our	O
face	B-Method
detector	I-Method
is	O
,	O
considerably	O
smaller	O
than	O
that	O
in	O
VJ	B-Method
framework	I-Method
.	O
	
As	O
for	O
multi	B-Method
-	I-Method
scale	I-Method
version	I-Method
of	I-Method
aggregate	I-Method
channel	I-Method
features	I-Method
,	O
multi	B-Method
-	I-Method
local	I-Method
-	I-Method
scale	I-Method
with	O
an	O
additional	O
scale	O
of	O
radius	O
shows	O
the	O
best	O
performance	O
.	O
	
The	O
probable	O
reason	O
is	O
that	O
pre	O
-	O
smoothing	B-Method
controls	O
the	O
local	O
scale	O
of	O
the	O
neighborhood	O
feature	O
correlations	O
and	O
therefore	O
matches	O
the	O
intuition	O
inside	O
multi	O
-	O
scale	O
best	O
.	O
	
Compared	O
with	O
other	O
fine	B-Method
-	I-Method
tuning	I-Method
,	O
the	O
multi	B-Method
-	I-Method
scale	I-Method
version	I-Method
has	O
a	O
notable	O
performance	O
gain	O
for	O
that	O
it	O
makes	O
up	O
for	O
the	O
scale	O
uniformity	O
caused	O
by	O
subsampling	O
to	O
some	O
extent	O
.	O
	
One	O
main	O
drawback	O
is	O
that	O
it	O
doubles	O
the	O
feature	O
pool	O
size	O
and	O
as	O
a	O
result	O
slows	O
down	O
the	O
detection	B-Task
speed	O
somewhat	O
.	O
	
Based	O
on	O
the	O
trade	O
-	O
off	O
,	O
we	O
implement	O
two	O
face	B-Method
detectors	I-Method
with	O
different	O
scale	O
settings	O
,	O
one	O
is	O
single	O
-	O
scaled	O
with	O
faster	O
speed	O
and	O
the	O
other	O
is	O
multi	O
-	O
scaled	O
with	O
better	O
accuracy	B-Metric
.	O
	
We	O
evaluate	O
and	O
discuss	O
the	O
performances	O
of	O
these	O
two	O
versions	O
in	O
detail	O
in	O
section	O
5	O
.	O
	
subsection	O
:	O
Training	O
design	O
	
Besides	O
careful	O
design	O
of	O
the	O
aggregate	O
channel	O
features	O
,	O
experiments	O
on	O
the	O
training	B-Task
process	I-Task
which	O
is	O
similar	O
to	O
that	O
in	O
VJ	B-Method
framework	I-Method
are	O
also	O
carried	O
out	O
.	O
	
The	O
differences	O
are	O
that	O
the	O
weak	B-Method
classifier	I-Method
is	O
changed	O
into	O
depth	O
-	O
2	O
decision	O
tree	O
and	O
soft	O
-	O
cascade	O
structure	O
is	O
used	O
.	O
	
Details	O
of	O
the	O
training	B-Method
design	I-Method
are	O
as	O
follows	O
.	O
	
Number	O
of	O
weak	B-Method
classifiers	I-Method
:	O
	
Given	O
a	O
feature	O
pool	O
size	O
of	O
,	O
we	O
vary	O
the	O
number	O
of	O
weak	B-Method
classifiers	I-Method
contained	O
in	O
the	O
soft	B-Method
-	I-Method
cascade	I-Method
.	O
	
In	O
Figure	O
[	O
reference	O
]	O
performances	O
of	O
various	O
numbers	O
of	O
weak	B-Method
classifiers	I-Method
ranging	O
from	O
to	O
are	O
displayed	O
,	O
which	O
shows	O
that	O
apparently	O
more	O
classifiers	O
generate	O
better	O
performance	O
,	O
and	O
when	O
the	O
number	O
gets	O
larger	O
the	O
performance	O
begins	O
to	O
saturate	O
.	O
	
Since	O
more	O
classifiers	B-Method
slow	O
down	O
the	O
detection	B-Task
speed	O
,	O
there	O
’s	O
a	O
trade	O
-	O
off	O
between	O
accuracy	B-Metric
and	O
speed	B-Metric
.	O
	
Searching	O
for	O
the	O
saturate	O
point	O
as	O
the	O
optimal	O
is	O
significant	O
during	O
training	O
in	O
such	O
framework	O
.	O
	
Training	O
data	O
:	O
Empirically	O
,	O
more	O
training	O
data	O
will	O
get	O
better	O
performance	O
given	O
powerful	O
representation	O
capacity	O
.	O
	
In	O
this	O
case	O
,	O
AFLW	B-Material
database	O
is	O
used	O
as	O
the	O
only	O
positive	O
training	O
data	O
.	O
	
However	O
,	O
as	O
images	O
in	O
AFLW	B-Material
database	O
are	O
very	O
salient	O
and	O
the	O
background	O
has	O
very	O
less	O
variance	O
,	O
negative	O
samples	O
cropped	O
from	O
the	O
AFLW	B-Material
database	O
ca	O
n’t	O
represent	O
the	O
real	O
world	O
scenario	O
well	O
,	O
which	O
limits	O
the	O
face	O
detection	B-Task
performance	O
in	O
the	O
wild	O
.	O
	
In	O
this	O
part	O
,	O
we	O
further	O
use	O
PASCAL	B-Material
VOC	I-Material
database	I-Material
and	O
randomly	O
crop	O
windows	O
from	O
images	O
without	O
person	O
as	O
the	O
new	O
negative	O
samples	O
.	O
	
Experiments	O
show	O
that	O
the	O
new	O
training	O
data	O
containing	O
cluttered	O
background	O
significantly	O
improve	O
the	O
performance	O
with	O
.	O
	
Summary	O
:	O
	
Based	O
on	O
observations	O
above	O
,	O
we	O
choose	O
as	O
the	O
number	O
of	O
weak	B-Method
classifiers	I-Method
contained	O
in	O
the	O
soft	B-Method
cascade	I-Method
.	O
	
As	O
each	O
weak	B-Method
classifier	I-Method
is	O
a	O
depth	O
-	O
2	O
decision	O
tree	O
,	O
it	O
takes	O
only	O
two	O
comparing	B-Method
operations	I-Method
to	O
apply	O
a	O
weak	B-Method
classifier	I-Method
,	O
which	O
is	O
quite	O
fast	O
.	O
	
During	O
training	B-Task
,	O
as	O
negative	O
data	O
is	O
large	O
,	O
we	O
adopt	O
a	O
standard	O
Bootstrap	B-Method
procedure	I-Method
to	O
sample	O
hard	O
negative	O
samples	O
from	O
PASCAL	B-Material
VOC	I-Material
in	O
the	O
implementation	O
of	O
the	O
proposed	O
face	B-Method
detector	I-Method
.	O
	
section	O
:	O
Multi	O
-	O
view	O
detection	B-Task
	
Human	O
faces	O
in	O
real	O
world	O
usually	O
have	O
highly	O
varied	O
poses	O
.	O
	
In	O
AFLW	B-Material
database	O
,	O
the	O
human	O
pose	O
is	O
divided	O
into	O
three	O
aspects	O
:	O
1	O
in	O
-	O
plane	O
rotation	O
	
‘	O
roll	O
’	O
and	O
2	O
out	O
-	O
of	O
-	O
plane	O
rotations	O
	
‘	O
yaw	O
’	O
and	O
‘	O
pitch	O
’	O
.	O
	
Because	O
of	O
this	O
large	O
variance	O
in	O
face	O
pose	O
,	O
it	O
is	O
difficult	O
to	O
train	O
a	O
single	B-Method
view	I-Method
face	I-Method
detector	I-Method
to	O
handle	O
all	O
the	O
poses	O
effectively	O
.	O
	
A	O
multi	B-Task
-	I-Task
view	I-Task
detection	I-Task
is	O
further	O
examined	O
in	O
this	O
part	O
.	O
	
Due	O
to	O
the	O
adoption	O
of	O
soft	B-Method
-	I-Method
cascade	I-Method
structure	I-Method
,	O
a	O
multi	B-Method
-	I-Method
view	I-Method
version	I-Method
of	I-Method
face	I-Method
detector	I-Method
wo	O
n’t	O
cause	O
too	O
much	O
computation	B-Metric
burden	I-Metric
.	O
	
Typically	O
,	O
we	O
divide	O
the	O
out	O
-	O
of	O
-	O
plane	O
rotation	O
¡	O
°	O
yaw¡±	O
into	O
different	O
views	O
and	O
let	O
the	O
classifier	B-Method
itself	O
tolerate	O
the	O
pose	O
variance	O
in	O
the	O
other	O
two	O
types	O
of	O
rotations	O
.	O
	
Adopting	O
multi	B-Task
-	I-Task
view	I-Task
detection	I-Task
also	O
brings	O
about	O
many	O
troublesome	O
issues	O
.	O
	
If	O
handled	O
improperly	O
,	O
the	O
performance	O
will	O
differ	O
greatly	O
.	O
	
First	O
,	O
detectors	O
of	O
different	O
view	O
will	O
each	O
produce	O
a	O
set	O
of	O
candidate	O
positive	O
windows	O
followed	O
with	O
a	O
set	O
of	O
confidence	O
scores	O
.	O
	
For	O
application	O
purpose	O
,	O
we	O
need	O
to	O
merge	O
these	O
detections	O
from	O
different	O
views	O
and	O
also	O
remove	O
duplicated	O
windows	O
.	O
	
A	O
typical	O
approach	O
is	O
Non	B-Method
-	I-Method
Maximum	I-Method
Suppression	I-Method
(	O
NMS	B-Method
)	O
.	O
	
An	O
issue	O
rises	O
on	O
how	O
to	O
compare	O
confidence	O
scores	O
from	O
different	O
classifiers	B-Method
and	O
how	O
to	O
do	O
window	B-Task
merging	I-Task
in	O
the	O
trade	O
-	O
off	O
between	O
high	B-Metric
precision	I-Metric
rate	I-Metric
and	O
high	O
detection	B-Task
rate	O
.	O
	
Second	O
,	O
as	O
for	O
detection	B-Task
evaluation	I-Task
,	O
usually	O
the	O
overlap	O
of	O
bounding	O
boxes	O
is	O
used	O
as	O
the	O
criterion	O
.	O
	
However	O
,	O
annotations	O
in	O
different	O
data	O
sets	O
may	O
not	O
have	O
a	O
consistent	O
style	O
(	O
Figure	O
[	O
reference	O
]	O
(	O
a	O
)	O
)	O
.	O
	
This	O
diversity	O
suffers	O
more	O
in	O
profile	O
faces	O
.	O
	
Since	O
our	O
face	B-Method
detector	I-Method
is	O
trained	O
and	O
tested	O
on	O
different	O
data	O
sets	O
,	O
this	O
issue	O
impacts	O
the	O
performance	O
a	O
lot	O
.	O
	
Third	O
,	O
detectors	O
of	O
different	O
views	O
need	O
to	O
be	O
trained	O
with	O
different	O
samples	O
separately	O
.	O
	
How	O
to	O
divide	O
the	O
views	O
therefore	O
becomes	O
another	O
concerning	O
problem	O
.	O
	
In	O
this	O
section	O
,	O
we	O
address	O
the	O
above	O
three	O
issues	O
successfully	O
by	O
careful	O
designs	O
and	O
therefore	O
fully	O
exploit	O
the	O
advantage	O
of	O
multi	B-Task
-	I-Task
view	I-Task
detection	I-Task
.	O
	
subsection	O
:	O
View	B-Method
partition	I-Method
	
In	O
the	O
scenario	O
of	O
detecting	B-Task
faces	I-Task
in	I-Task
the	I-Task
wild	I-Task
,	O
pose	B-Task
variation	I-Task
caused	O
by	O
yaw	O
is	O
usually	O
severer	O
than	O
pitch	O
and	O
roll	O
.	O
	
Therefore	O
we	O
divide	O
the	O
faces	O
in	O
AFLW	B-Material
database	O
according	O
to	O
yaw	O
angle	O
.	O
	
We	O
have	O
subviews	O
which	O
are	O
horizontally	O
symmetric	O
(	O
see	O
Figure	O
.	O
	
[	O
reference	O
]	O
(	O
b	O
)	O
)	O
because	O
we	O
flip	O
each	O
image	O
in	O
the	O
training	O
set	O
.	O
	
Specifically	O
,	O
there	O
are	O
,	O
,	O
,	O
,	O
,	O
images	O
in	O
views	O
from	O
to	O
.	O
	
Benefitting	O
from	O
the	O
symmetry	O
of	O
our	O
model	O
,	O
we	O
can	O
only	O
train	O
three	O
subview	B-Method
detectors	I-Method
of	O
the	O
right	O
side	O
for	O
simplicity	O
,	O
and	O
use	O
these	O
trained	O
right	B-Method
-	I-Method
side	I-Method
detectors	I-Method
to	O
generate	O
the	O
left	B-Method
-	I-Method
side	I-Method
detectors	I-Method
.	O
	
Detections	O
of	O
all	O
six	O
detectors	O
are	O
then	O
merged	O
to	O
get	O
the	O
final	O
detections	O
.	O
	
Though	O
multi	B-Task
-	I-Task
view	I-Task
detection	I-Task
significantly	O
improves	O
the	O
detection	B-Task
performance	O
(	O
especially	O
the	O
recall	B-Metric
rate	I-Metric
)	O
,	O
the	O
post	B-Task
-	I-Task
processing	I-Task
of	I-Task
detections	I-Task
from	O
different	O
detectors	O
becomes	O
a	O
trouble	O
.	O
	
If	O
handled	O
improperly	O
,	O
the	O
performance	O
degrades	O
a	O
lot	O
.	O
	
subsection	O
:	O
Post	B-Task
-	I-Task
processing	I-Task
	
Difficulties	O
in	O
the	O
post	O
-	O
processing	O
of	O
multi	O
-	O
view	O
detection	B-Task
mainly	O
reflect	O
on	O
the	O
following	O
aspects	O
:	O
1	O
)	O
different	O
score	O
distributions	O
and	O
;	O
2	O
)	O
different	O
bounding	O
box	O
styles	O
.	O
	
Concretely	O
,	O
as	O
each	O
subview	B-Method
detector	I-Method
is	O
trained	O
separately	O
,	O
their	O
output	O
confidence	B-Metric
scores	I-Metric
usually	O
have	O
different	O
distributions	O
.	O
	
What	O
’s	O
more	O
,	O
due	O
to	O
the	O
annotation	O
rule	O
in	O
the	O
AFLW	B-Material
database	O
that	O
the	O
face	O
	
’s	O
nose	O
is	O
approximately	O
at	O
the	O
center	O
location	O
of	O
the	O
bounding	O
box	O
ground	O
-	O
truth	O
,	O
as	O
the	O
subview	O
changes	O
,	O
the	O
bounding	O
box	O
shifts	O
.	O
	
This	O
bounding	O
box	O
offset	O
causes	O
difficulty	O
both	O
in	O
detection	B-Task
merging	I-Task
and	O
final	O
evaluation	B-Task
using	O
Jaccard	B-Metric
index	I-Metric
metric	I-Metric
.	O
	
To	O
solve	O
these	O
annoying	O
issues	O
and	O
make	O
the	O
best	O
use	O
of	O
multi	B-Task
-	I-Task
view	I-Task
detection	I-Task
,	O
we	O
introduce	O
the	O
following	O
methods	O
for	O
post	B-Task
-	I-Task
processing	I-Task
.	O
	
Score	O
re	O
-	O
ranking	B-Task
	
:	O
We	O
propose	O
the	O
following	O
three	O
kinds	O
of	O
score	B-Task
re	I-Task
-	I-Task
ranking	I-Task
:	O
1	O
)	O
normalizing	O
scores	O
of	O
different	O
views	O
to	O
[	O
0	O
,	O
1	O
]	O
;	O
2	O
)	O
defining	O
a	O
new	O
score	O
that	O
has	O
uniform	O
distribution	O
and	O
;	O
3	O
)	O
taking	O
overlapping	O
detections	O
into	O
consideration	O
.	O
	
:	O
After	O
training	O
a	O
classifier	B-Method
,	O
calculate	O
the	O
output	O
range	O
of	O
the	O
classifier	O
and	O
use	O
the	O
range	O
to	O
do	O
normalization	O
later	O
so	O
that	O
output	O
score	O
has	O
a	O
range	O
of	O
[	O
0	O
,	O
1	O
]	O
.	O
:	O
Originally	O
,	O
each	O
weak	B-Method
classifier	I-Method
in	O
the	O
soft	O
-	O
cascade	O
owns	O
a	O
score	O
and	O
final	O
score	O
is	O
the	O
sum	O
of	O
all	O
scores	O
.	O
	
Instead	O
,	O
we	O
use	O
the	O
number	O
of	O
weak	B-Method
classifier	I-Method
that	O
the	O
image	O
patch	O
passed	O
positively	O
as	O
the	O
new	O
score	O
.	O
	
Therefore	O
the	O
upper	O
limit	O
of	O
the	O
new	O
score	O
is	O
in	O
our	O
case	O
.	O
	
:	O
	
Given	O
an	O
image	O
,	O
multiple	O
detections	O
from	O
multi	B-Method
-	I-Method
view	I-Method
detectors	I-Method
exist	O
each	O
with	O
a	O
score	O
.	O
	
For	O
each	O
detection	B-Task
,	O
we	O
first	O
calculate	O
the	O
number	O
of	O
overlapped	O
detection	B-Task
it	O
has	O
(	O
overlap	O
threshold	O
is	O
)	O
and	O
then	O
multiply	O
score	O
of	O
each	O
detection	B-Task
with	O
a	O
factor	O
of	O
its	O
overlapping	O
number	O
ranking	O
.	O
	
:	O
Instead	O
of	O
using	O
overlapping	O
as	O
a	O
multiply	O
factor	O
,	O
here	O
we	O
use	O
the	O
sum	O
of	O
overlapped	O
detections	O
’	O
scores	O
as	O
the	O
current	O
detection	B-Task
’s	O
new	O
score	O
.	O
	
Detection	B-Task
merging	I-Task
:	O
Apart	O
from	O
the	O
version	O
of	O
Non	B-Method
Maximum	I-Method
Suppression	I-Method
,	O
we	O
also	O
use	O
the	O
detection	B-Task
combination	O
introduced	O
in	O
.	O
	
It	O
averages	O
the	O
locations	O
of	O
overlapped	O
detections	O
rather	O
than	O
suppresses	O
them	O
.	O
	
Detection	B-Task
adjustment	I-Task
:	O
	
As	O
shown	O
in	O
Figure	O
[	O
reference	O
]	O
(	O
a	O
)	O
,	O
different	O
databases	O
have	O
different	O
annotation	O
styles	O
of	O
ground	O
-	O
truth	O
.	O
	
Specifically	O
,	O
AFLW	B-Material
has	O
square	O
annotations	O
with	O
nose	O
located	O
approximately	O
at	O
the	O
center	O
.	O
	
AFW	B-Material
uses	O
tight	O
rectangular	O
bounding	O
boxes	O
as	O
annotations	O
with	O
the	O
eye	O
-	O
brow	O
being	O
the	O
approximate	O
upper	O
bound	O
.	O
	
FDDB	B-Material
uses	O
elliptical	O
annotations	O
bounding	O
the	O
whole	O
head	O
.	O
	
As	O
our	O
detector	O
is	O
trained	O
on	O
AFLW	B-Material
and	O
tested	O
on	O
AFW	B-Material
and	O
FDDB	B-Material
,	O
there	O
exist	O
offsets	O
in	O
both	O
detection	B-Task
position	O
and	O
scale	O
.	O
	
According	O
to	O
observations	O
,	O
the	O
offsets	O
vary	O
as	O
face	O
pose	O
changes	O
.	O
	
Therefore	O
we	O
adopt	O
a	O
view	O
-	O
specific	O
detection	B-Task
adjustment	O
to	O
alleviate	O
the	O
offsets	O
.	O
	
Note	O
that	O
the	O
adjustment	O
is	O
constant	O
for	O
all	O
images	O
and	O
faces	O
in	O
the	O
same	O
database	O
,	O
see	O
Figure	O
[	O
reference	O
]	O
(	O
b	O
)	O
for	O
details	O
.	O
	
Summary	O
:	O
	
According	O
to	O
experimental	O
results	O
(	O
Table	O
[	O
reference	O
]	O
)	O
,	O
seems	O
to	O
be	O
the	O
best	O
score	O
re	B-Method
-	I-Method
ranking	I-Method
method	I-Method
.	O
	
The	O
underlying	O
reason	O
may	O
be	O
that	O
true	O
positives	O
usually	O
have	O
many	O
overlapped	O
detections	O
,	O
while	O
the	O
false	O
positives	O
would	O
only	O
get	O
a	O
few	O
responses	O
.	O
	
Therefore	O
leveraging	O
this	O
overlapping	O
information	O
in	O
score	B-Task
re	I-Task
-	I-Task
ranking	I-Task
can	O
reduce	O
many	O
false	O
positives	O
.	O
	
However	O
,	O
in	O
practice	O
,	O
overlap	B-Method
related	I-Method
methods	I-Method
and	O
detection	B-Task
combination	O
both	O
cost	O
much	O
time	O
to	O
process	O
,	O
which	O
is	O
infeasible	O
in	O
a	O
large	O
majority	O
of	O
applications	O
.	O
	
We	O
finally	O
adopt	O
score	B-Method
re	I-Method
-	I-Method
ranking	I-Method
combined	O
with	O
Non	B-Method
Maximum	I-Method
Suppression	I-Method
for	O
the	O
sake	O
of	O
detection	B-Task
speed	O
.	O
	
section	O
:	O
Experiments	O
	
In	O
this	O
section	O
,	O
we	O
compare	O
our	O
method	O
with	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
methods	O
on	O
AFW	B-Material
and	O
FDDB	B-Material
databases	I-Material
which	O
contain	O
challenging	O
faces	O
in	O
the	O
wild	O
.	O
	
In	O
AFW	B-Material
,	O
we	O
compare	O
with	O
three	O
commercial	O
systems	O
(	O
Google	B-Method
Picasa	I-Method
,	O
Face.com	B-Method
and	O
Face	B-Method
++	I-Method
)	O
and	O
five	O
academic	O
methods	O
(	O
Shen	O
,	O
Zhu	O
,	O
DPM	B-Method
,	O
multiHOG	B-Method
and	O
Kalal	B-Method
)	O
.	O
	
In	O
FDDB	B-Material
,	O
we	O
compare	O
with	O
one	O
commercial	O
system	O
(	O
Olaworks	B-Method
)	O
and	O
six	O
academic	O
methods	O
(	O
Yan	O
,	O
Boosted	B-Method
Exemplar	I-Method
,	O
SURF	B-Method
multiview	I-Method
,	O
PEP	B-Method
-	I-Method
Adapt	I-Method
,	O
XZJY	O
and	O
Zhu	O
)	O
listed	O
on	O
FDDB	B-Material
results	O
page	O
.	O
	
subsection	O
:	O
Evaluation	O
on	O
benchmark	O
face	O
database	O
	
As	O
shown	O
in	O
Figure	O
[	O
reference	O
]	O
,	O
in	O
AFW	B-Material
,	O
our	O
multi	B-Method
-	I-Method
scale	I-Method
detector	I-Method
achieves	O
an	O
ap	O
value	O
of	O
,	O
outperforming	O
other	O
academic	B-Method
methods	I-Method
by	O
a	O
large	O
margin	O
.	O
	
When	O
it	O
comes	O
to	O
commercial	O
systems	O
,	O
ours	O
is	O
better	O
than	O
Face.com	B-Method
and	O
almost	O
equal	O
to	O
Face	B-Method
++	I-Method
and	O
Google	B-Method
Picasa	I-Method
.	O
	
Note	O
that	O
most	O
of	O
our	O
false	B-Metric
positives	I-Metric
on	O
AFW	B-Material
database	O
are	O
faces	O
that	O
have	O
n’t	O
been	O
annotated	O
(	O
small	O
,	O
seriously	O
occluded	O
or	O
artificial	O
faces	O
like	O
mask	O
and	O
cartoon	O
character	O
)	O
.	O
	
When	O
evaluated	O
on	O
FDDB	B-Material
database	O
,	O
we	O
follow	O
the	O
evaluation	O
protocol	O
in	O
and	O
report	O
the	O
average	O
discrete	B-Metric
and	I-Metric
continuous	I-Metric
ROC	I-Metric
of	O
the	O
ten	O
subfolders	O
.	O
	
For	O
equality	O
,	O
we	O
fix	O
the	O
number	O
of	O
false	O
positives	O
to	O
(	O
equivalent	O
to	O
an	O
average	O
of	O
False	B-Metric
Positive	I-Metric
Per	O
Image	O
)	O
and	O
compare	O
the	O
true	B-Metric
positive	I-Metric
rate	I-Metric
.	O
	
In	O
discrete	B-Metric
score	I-Metric
where	O
evaluation	B-Metric
metric	I-Metric
is	O
the	O
same	O
as	O
in	O
AFW	B-Material
,	O
our	O
detector	O
achieves	O
,	O
which	O
is	O
a	O
little	O
better	O
than	O
Yan	O
.	O
	
Note	O
that	O
the	O
ground	O
-	O
truth	O
in	O
FDDB	B-Material
are	O
elliptical	O
faces	O
,	O
therefore	O
the	O
evaluation	B-Metric
metric	I-Metric
of	O
an	O
overlap	B-Metric
ratio	I-Metric
bigger	O
than	O
can	O
not	O
reveal	O
the	O
true	O
performance	O
of	O
the	O
proposed	O
detector	O
well	O
.	O
	
When	O
using	O
continuous	O
score	O
which	O
takes	O
the	O
overlap	B-Metric
ratio	I-Metric
as	O
the	O
score	O
,	O
our	O
method	O
gets	O
true	B-Metric
positive	I-Metric
rate	I-Metric
at	O
FPPI	B-Method
for	O
multi	B-Task
-	I-Task
scale	I-Task
version	I-Task
,	O
surpassing	O
other	O
methods	O
which	O
output	O
rectangular	O
detections	O
by	O
a	O
notable	O
margin	O
(	O
the	O
Yan	B-Method
detector	I-Method
outputs	O
the	O
same	O
elliptical	O
detections	O
as	O
the	O
ground	O
-	O
truth	O
,	O
therefore	O
having	O
advantages	O
with	O
this	O
metric	O
)	O
.	O
	
Our	O
detector	O
using	O
single	B-Method
-	I-Method
scale	I-Method
features	I-Method
performs	O
a	O
little	O
worse	O
with	O
the	O
benefit	O
of	O
faster	O
detection	B-Task
speed	O
.	O
	
subsection	O
:	O
Discussion	O
	
Training	B-Metric
efficiency	I-Metric
:	O
We	O
implement	O
the	O
method	O
with	O
Piotr	B-Method
’s	I-Method
MATLAB	I-Method
toolbox	I-Method
on	O
a	O
PC	O
with	O
Intel	O
Core	O
i7	O
-	O
3770	O
CPU	O
and	O
16	O
GB	O
RAM	O
.	O
	
With	O
positive	O
images	O
and	O
negative	O
images	O
in	O
total	O
6	O
views	O
,	O
the	O
training	O
process	O
takes	O
about	O
mins	O
for	O
a	O
single	O
-	O
scale	B-Method
subview	I-Method
detector	I-Method
containing	O
weak	B-Method
classifiers	I-Method
and	O
mins	B-Method
for	O
multi	B-Method
-	I-Method
scale	I-Method
version	I-Method
.	O
	
Note	O
that	O
we	O
use	O
much	O
fewer	O
training	O
data	O
than	O
SURF	B-Method
multiview	I-Method
whilst	O
still	O
outperforming	O
their	O
performance	O
.	O
	
Comparative	O
results	O
:	O
When	O
inspecting	O
detections	O
of	O
the	O
proposed	O
face	B-Method
detector	I-Method
and	O
other	O
algorithms	O
on	O
the	O
testsets	O
,	O
some	O
patterns	O
can	O
be	O
found	O
to	O
explain	O
why	O
our	O
detector	O
outperforms	O
others	O
.	O
	
One	O
evident	O
strength	O
lies	O
in	O
detecting	O
faces	O
with	O
extreme	O
poses	O
.	O
	
Because	O
we	O
adopt	O
multi	B-Task
-	I-Task
view	I-Task
detection	I-Task
and	O
train	O
each	O
subview	B-Method
detector	I-Method
separately	O
,	O
our	O
detector	O
handles	O
pose	O
variations	O
very	O
well	O
.	O
	
Second	O
is	O
the	O
outstanding	O
illumination	O
invariance	O
of	O
our	O
detector	O
,	O
which	O
is	O
mainly	O
owing	O
to	O
the	O
extension	O
of	O
channel	O
types	O
to	O
LUV	O
color	O
space	O
and	O
gradient	O
-	O
related	O
channels	O
.	O
	
Detection	B-Metric
speed	I-Metric
:	O
	
Due	O
to	O
the	O
simple	O
form	O
of	O
aggregate	O
channel	O
features	O
and	O
fast	O
computation	O
of	O
feature	B-Method
pyramid	I-Method
,	O
detection	B-Task
is	O
quite	O
efficient	O
.	O
	
For	O
full	O
yaw	O
pose	O
face	O
detection	B-Task
in	O
VGA	B-Task
image	I-Task
,	O
the	O
proposed	O
detector	O
using	O
single	B-Method
-	I-Method
scale	I-Method
features	I-Method
runs	O
at	O
FPS	O
on	O
a	O
single	O
thread	O
and	O
FPS	O
if	O
threads	O
are	O
used	O
.	O
	
If	O
only	O
frontal	O
faces	O
are	O
concerned	O
,	O
the	O
detector	O
runs	O
at	O
FPS	O
and	O
FPS	O
after	O
parallelization	O
.	O
	
When	O
it	O
comes	O
to	O
the	O
proposed	O
detector	B-Method
using	O
multi	O
-	O
scale	O
features	O
,	O
the	O
above	O
four	O
indices	O
reduce	O
to	O
,	O
,	O
and	O
FPS	B-Metric
.	O
	
Considering	O
the	O
large	O
performance	O
gain	O
and	O
similar	O
speed	O
,	O
the	O
proposed	O
method	O
can	O
replace	O
Viola	B-Method
-	I-Method
Jones	I-Method
detector	I-Method
for	O
face	O
detection	B-Task
in	O
the	O
wild	O
.	O
	
section	O
:	O
Conclusion	O
	
A	O
novel	O
feature	B-Method
representation	I-Method
called	O
aggregate	B-Method
channel	I-Method
features	I-Method
possesses	O
the	O
merits	O
of	O
fast	O
feature	B-Method
extraction	I-Method
and	O
powerful	O
representation	B-Method
capacity	I-Method
.	O
	
In	O
this	O
paper	O
,	O
we	O
successfully	O
apply	O
the	O
feature	B-Method
representation	I-Method
to	O
face	O
detection	B-Task
domain	O
through	O
a	O
deep	O
investigation	O
into	O
the	O
feature	B-Method
design	I-Method
,	O
and	O
propose	O
a	O
multi	B-Method
-	I-Method
scale	I-Method
version	I-Method
of	I-Method
feature	I-Method
which	O
further	O
enriches	O
the	O
representation	O
capacity	O
.	O
	
Combined	O
with	O
our	O
efforts	O
into	O
solving	O
issues	O
concerning	O
multi	B-Task
-	I-Task
view	I-Task
detection	I-Task
,	O
the	O
proposed	O
multi	B-Method
-	I-Method
view	I-Method
face	I-Method
detector	I-Method
shows	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
performance	O
in	O
both	O
effectiveness	O
and	O
efficiency	O
on	O
faces	O
in	O
the	O
wild	O
.	O
	
The	O
proposed	O
method	O
appeals	O
to	O
real	B-Task
world	I-Task
application	I-Task
demands	I-Task
and	O
has	O
the	O
potential	O
to	O
be	O
embedded	O
into	O
low	O
power	O
devices	O
.	O
	
section	O
:	O
Acknowledgement	O
	
This	O
work	O
was	O
supported	O
by	O
the	O
Chinese	O
National	O
Natural	O
Science	O
Foundation	O
Projects	O
#	O
61105023	O
,	O
#	O
61103156	O
,	O
#	O
61105037	O
,	O
#	O
61203267	O
,	O
#	O
61375037	O
,	O
National	O
Science	O
and	O
Technology	O
Support	O
Program	O
Project	O
#	O
2013BAK02B01	O
,	O
Chinese	O
Academy	O
of	O
Sciences	O
	
Project	O
No	O
.	O
	
KGZD	O
-	O
EW	O
-	O
102	O
-	O
2	O
,	O
and	O
AuthenMetric	O
R	O
&	O
D	O
Funds	O
.	O
	
bibliography	O
:	O
References	O
	
document	O
:	O
Training	O
Region	B-Method
-	I-Method
based	I-Method
Object	I-Method
Detectors	I-Method
with	O
Online	B-Method
Hard	I-Method
Example	I-Method
Mining	I-Method
	
The	O
field	O
of	O
object	B-Task
detection	I-Task
has	O
made	O
significant	O
advances	O
riding	O
on	O
the	O
wave	O
of	O
region	B-Method
-	I-Method
based	I-Method
ConvNets	I-Method
,	O
but	O
their	O
training	O
procedure	O
still	O
includes	O
many	O
heuristics	O
and	O
hyperparameters	O
that	O
are	O
costly	O
to	O
tune	O
.	O
	
We	O
present	O
a	O
simple	O
yet	O
surprisingly	O
effective	O
online	B-Method
hard	I-Method
example	I-Method
mining	I-Method
	
(	O
OHEM	B-Method
)	O
algorithm	O
for	O
training	O
region	B-Method
-	I-Method
based	I-Method
ConvNet	I-Method
detectors	I-Method
.	O
	
Our	O
motivation	O
is	O
the	O
same	O
as	O
it	O
has	O
always	O
been	O
–	O
detection	O
datasets	O
contain	O
an	O
overwhelming	O
number	O
of	O
easy	O
examples	O
and	O
a	O
small	O
number	O
of	O
hard	O
examples	O
.	O
	
Automatic	B-Task
selection	I-Task
of	O
these	O
hard	O
examples	O
can	O
make	O
training	O
more	O
effective	O
and	O
efficient	O
.	O
	
OHEM	B-Method
is	O
a	O
simple	O
and	O
intuitive	O
algorithm	O
that	O
eliminates	O
several	O
heuristics	O
and	O
hyperparameters	O
in	O
common	O
use	O
.	O
	
But	O
more	O
importantly	O
,	O
it	O
yields	O
consistent	O
and	O
significant	O
boosts	O
in	O
detection	B-Metric
performance	I-Metric
on	O
benchmarks	O
like	O
PASCAL	B-Material
VOC	I-Material
2007	I-Material
and	O
2012	B-Material
.	O
	
Its	O
effectiveness	O
increases	O
as	O
datasets	O
become	O
larger	O
and	O
more	O
difficult	O
,	O
as	O
demonstrated	O
by	O
the	O
results	O
on	O
the	O
MS	B-Material
COCO	I-Material
dataset	O
.	O
	
Moreover	O
,	O
combined	O
with	O
complementary	O
advances	O
in	O
the	O
field	O
,	O
OHEM	B-Method
leads	O
to	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
results	O
of	O
78.9	O
%	O
and	O
76.3	O
%	O
mAP	B-Metric
on	O
PASCAL	B-Material
VOC	I-Material
2007	I-Material
and	O
2012	B-Material
respectively	O
.	O
	
section	O
:	O
Introduction	O
	
Image	B-Task
classification	I-Task
and	O
object	B-Task
detection	I-Task
are	O
two	O
fundamental	O
computer	B-Task
vision	I-Task
tasks	I-Task
.	O
	
Object	B-Method
detectors	I-Method
are	O
often	O
trained	O
through	O
a	O
reduction	B-Method
that	O
converts	O
object	B-Task
detection	I-Task
into	O
an	O
image	B-Task
classification	I-Task
problem	I-Task
.	O
	
This	O
reduction	O
introduces	O
a	O
new	O
challenge	O
that	O
is	O
not	O
found	O
in	O
natural	B-Task
image	I-Task
classification	I-Task
tasks	I-Task
:	O
the	O
training	O
set	O
is	O
distinguished	O
by	O
a	O
large	O
imbalance	O
between	O
the	O
number	O
of	O
annotated	O
objects	O
and	O
the	O
number	O
of	O
background	O
examples	O
(	O
image	O
regions	O
not	O
belonging	O
to	O
any	O
object	O
class	O
of	O
interest	O
)	O
.	O
	
In	O
the	O
case	O
of	O
sliding	B-Method
-	I-Method
window	I-Method
object	I-Method
detectors	I-Method
,	O
such	O
as	O
the	O
deformable	B-Method
parts	I-Method
model	I-Method
(	O
DPM	B-Method
)	I-Method
,	O
this	O
imbalance	O
may	O
be	O
as	O
extreme	O
as	O
100	O
,	O
000	O
background	O
examples	O
to	O
every	O
one	O
object	O
.	O
	
The	O
recent	O
trend	O
towards	O
object	B-Method
-	I-Method
proposal	I-Method
-	I-Method
based	I-Method
detectors	I-Method
mitigates	O
this	O
issue	O
to	O
an	O
extent	O
,	O
but	O
the	O
imbalance	B-Metric
ratio	I-Metric
may	O
still	O
be	O
high	O
(	O
,	O
70:1	O
)	O
.	O
	
This	O
challenge	O
opens	O
space	O
for	O
learning	B-Method
techniques	I-Method
that	O
cope	O
with	O
imbalance	O
and	O
yield	O
faster	O
training	B-Task
,	O
higher	O
accuracy	B-Metric
,	O
or	O
both	O
.	O
	
Unsurprisingly	O
,	O
this	O
is	O
not	O
a	O
new	O
challenge	O
and	O
a	O
standard	O
solution	O
,	O
originally	O
called	O
bootstrapping	B-Method
(	O
and	O
now	O
often	O
called	O
hard	B-Task
negative	I-Task
mining	I-Task
)	O
,	O
has	O
existed	O
for	O
at	O
least	O
20	O
years	O
.	O
	
Bootstrapping	B-Method
was	O
introduced	O
in	O
the	O
work	O
of	O
Sung	O
and	O
Poggio	O
in	O
the	O
mid	O
-	O
1990	O
	
’s	O
(	O
if	O
not	O
earlier	O
)	O
for	O
training	O
face	B-Method
detection	I-Method
models	I-Method
.	O
	
Their	O
key	O
idea	O
was	O
to	O
gradually	O
grow	O
,	O
or	O
bootstrap	O
,	O
the	O
set	O
of	O
background	O
examples	O
by	O
selecting	O
those	O
examples	O
for	O
which	O
the	O
detector	B-Method
triggers	O
a	O
false	O
alarm	O
.	O
	
This	O
strategy	O
leads	O
to	O
an	O
iterative	B-Method
training	I-Method
algorithm	I-Method
that	O
alternates	O
between	O
updating	O
the	O
detection	B-Method
model	I-Method
given	O
the	O
current	O
set	O
of	O
examples	O
,	O
and	O
then	O
using	O
the	O
updated	O
model	O
to	O
find	O
new	O
false	O
positives	O
to	O
add	O
to	O
the	O
bootstrapped	O
training	O
set	O
.	O
	
The	O
process	O
typically	O
commences	O
with	O
a	O
training	O
set	O
consisting	O
of	O
all	O
object	O
examples	O
and	O
a	O
small	O
,	O
random	O
set	O
of	O
background	O
examples	O
.	O
	
Bootstrapping	B-Method
has	O
seen	O
widespread	O
use	O
in	O
the	O
intervening	O
decades	O
of	O
object	B-Task
detection	I-Task
research	I-Task
.	O
	
Dalal	O
and	O
Triggs	O
used	O
it	O
when	O
training	O
SVMs	B-Method
for	O
pedestrian	B-Task
detection	I-Task
.	O
	
Felzenszwalb	O
later	O
proved	O
that	O
a	O
form	O
of	O
bootstrapping	B-Method
for	O
SVMs	B-Method
converges	O
to	O
the	O
global	O
optimal	O
solution	O
defined	O
on	O
the	O
entire	O
dataset	O
.	O
	
Their	O
algorithm	O
is	O
often	O
referred	O
to	O
as	O
hard	B-Task
negative	I-Task
mining	I-Task
and	O
is	O
frequently	O
used	O
when	O
training	O
SVMs	B-Method
for	O
object	B-Task
detection	I-Task
.	O
	
Bootstrapping	B-Method
was	O
also	O
successfully	O
applied	O
to	O
a	O
variety	O
of	O
other	O
learning	B-Method
models	I-Method
,	O
including	O
shallow	B-Method
neural	I-Method
networks	I-Method
and	O
boosted	B-Method
decision	I-Method
trees	I-Method
.	O
	
Even	O
modern	O
detection	B-Method
methods	I-Method
based	O
on	O
deep	B-Method
convolutional	I-Method
neural	I-Method
networks	I-Method
(	O
ConvNets	B-Method
)	I-Method
,	O
such	O
as	O
R	B-Method
-	I-Method
CNN	I-Method
and	O
SPPnet	B-Method
,	O
still	O
employ	O
SVMs	B-Method
trained	O
with	O
hard	B-Method
negative	I-Method
mining	I-Method
.	O
	
It	O
may	O
seem	O
odd	O
then	O
that	O
the	O
current	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
object	B-Method
detectors	I-Method
,	O
embodied	O
by	O
Fast	B-Method
R	I-Method
-	I-Method
CNN	I-Method
and	O
its	O
descendants	O
,	O
do	O
not	O
use	O
bootstrapping	B-Method
.	O
	
The	O
underlying	O
reason	O
is	O
a	O
technical	O
difficulty	O
brought	O
on	O
by	O
the	O
shift	O
towards	O
purely	O
online	B-Method
learning	I-Method
algorithms	I-Method
,	O
particularly	O
in	O
the	O
context	O
of	O
deep	B-Method
ConvNets	I-Method
trained	O
with	O
stochastic	B-Method
gradient	I-Method
descent	I-Method
(	O
SGD	B-Method
)	O
on	O
millions	O
of	O
examples	O
.	O
	
Bootstrapping	B-Method
,	O
and	O
its	O
variants	O
in	O
the	O
literature	O
,	O
rely	O
on	O
the	O
aforementioned	O
alternation	B-Method
template	I-Method
:	O
(	O
a	O
)	O
for	O
some	O
period	O
of	O
time	O
a	O
fixed	B-Method
model	I-Method
is	O
used	O
to	O
find	O
new	O
examples	O
to	O
add	O
to	O
the	O
active	O
training	O
set	O
;	O
(	O
b	O
)	O
then	O
,	O
for	O
some	O
period	O
of	O
time	O
the	O
model	O
is	O
trained	O
on	O
the	O
fixed	O
active	O
training	O
set	O
.	O
	
Training	O
deep	B-Method
ConvNet	I-Method
detectors	I-Method
with	O
SGD	B-Method
typically	O
requires	O
hundreds	O
of	O
thousands	O
of	O
SGD	B-Method
steps	I-Method
and	O
freezing	O
the	O
model	O
for	O
even	O
a	O
few	O
iterations	O
at	O
a	O
time	O
would	O
dramatically	O
slow	O
progress	O
.	O
	
What	O
is	O
needed	O
,	O
instead	O
,	O
is	O
a	O
purely	O
online	B-Method
form	I-Method
of	O
hard	B-Task
example	I-Task
selection	I-Task
.	O
	
In	O
this	O
paper	O
,	O
we	O
propose	O
a	O
novel	O
bootstrapping	B-Method
technique	I-Method
called	O
online	B-Method
hard	I-Method
example	I-Method
mining	I-Method
(	O
OHEM	B-Method
)	O
for	O
training	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
detection	B-Method
models	I-Method
based	O
on	O
deep	B-Method
ConvNets	I-Method
.	O
	
The	O
algorithm	O
is	O
a	O
simple	O
modification	O
to	O
SGD	B-Method
in	O
which	O
training	O
examples	O
are	O
sampled	O
according	O
to	O
a	O
non	O
-	O
uniform	O
,	O
non	O
-	O
stationary	O
distribution	O
that	O
depends	O
on	O
the	O
current	O
loss	O
of	O
each	O
example	O
under	O
consideration	O
.	O
	
The	O
method	O
takes	O
advantage	O
of	O
detection	B-Task
-	I-Task
specific	I-Task
problem	I-Task
structure	I-Task
in	O
which	O
each	O
SGD	B-Method
mini	I-Method
-	I-Method
batch	I-Method
consists	O
of	O
only	O
one	O
or	O
two	O
images	O
,	O
but	O
thousands	O
of	O
candidate	O
examples	O
.	O
	
The	O
candidate	O
examples	O
are	O
subsampled	O
according	O
to	O
a	O
distribution	O
that	O
favors	O
diverse	O
,	O
high	O
loss	O
instances	O
.	O
	
Gradient	B-Method
computation	I-Method
(	O
backpropagation	B-Method
)	O
is	O
still	O
efficient	O
because	O
it	O
only	O
uses	O
a	O
small	O
subset	O
of	O
all	O
candidates	O
.	O
	
We	O
apply	O
OHEM	B-Method
to	O
the	O
standard	O
Fast	B-Method
R	I-Method
-	I-Method
CNN	I-Method
detection	O
method	O
and	O
show	O
three	O
benefits	O
compared	O
to	O
the	O
baseline	B-Method
training	I-Method
algorithm	I-Method
:	O
It	O
removes	O
the	O
need	O
for	O
several	O
heuristics	O
and	O
hyperparameters	O
commonly	O
used	O
in	O
region	B-Method
-	I-Method
based	I-Method
ConvNets	I-Method
.	O
	
It	O
yields	O
a	O
consistent	O
and	O
significant	O
boosts	O
in	O
mean	B-Metric
average	I-Metric
precision	I-Metric
.	O
	
Its	O
effectiveness	O
increases	O
as	O
the	O
training	O
set	O
becomes	O
larger	O
and	O
more	O
difficult	O
,	O
as	O
demonstrated	O
by	O
results	O
on	O
the	O
MS	B-Material
COCO	I-Material
dataset	O
.	O
	
Moreover	O
,	O
the	O
gains	O
from	O
OHEM	B-Method
are	O
complementary	O
to	O
recent	O
improvements	O
in	O
object	B-Task
detection	I-Task
,	O
such	O
as	O
multi	B-Method
-	I-Method
scale	I-Method
testing	O
and	O
iterative	B-Method
bounding	I-Method
-	I-Method
box	I-Method
regression	I-Method
.	O
	
Combined	O
with	O
these	O
tricks	O
,	O
OHEM	B-Method
gives	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
results	O
of	O
78.9	O
%	O
and	O
76.3	O
%	O
mAP	B-Metric
on	O
PASCAL	B-Material
VOC	I-Material
2007	I-Material
and	O
2012	B-Material
,	O
respectively	O
.	O
	
section	O
:	O
Related	O
work	O
	
Object	B-Task
detection	I-Task
is	O
one	O
of	O
the	O
oldest	O
and	O
most	O
fundamental	O
problems	O
in	O
computer	B-Task
vision	I-Task
.	O
	
The	O
idea	O
of	O
dataset	B-Task
bootstrapping	I-Task
,	O
typically	O
called	O
hard	B-Task
negative	I-Task
mining	I-Task
in	O
recent	O
work	O
,	O
appears	O
in	O
the	O
training	O
of	O
most	O
successful	O
object	B-Method
detectors	I-Method
.	O
	
Many	O
of	O
these	O
approaches	O
use	O
SVMs	B-Method
as	O
the	O
detection	B-Metric
scoring	I-Metric
function	I-Metric
,	O
even	O
after	O
training	O
a	O
deep	B-Method
convolutional	I-Method
neural	I-Method
network	I-Method
(	O
ConvNet	B-Method
)	O
for	O
feature	B-Task
extraction	I-Task
.	O
	
One	O
notable	O
exception	O
is	O
the	O
Fast	B-Method
R	I-Method
-	I-Method
CNN	I-Method
detector	O
and	O
its	O
descendants	O
,	O
such	O
as	O
Faster	B-Method
R	I-Method
-	I-Method
CNN	I-Method
.	O
	
Since	O
these	O
models	O
do	O
not	O
use	O
SVMs	B-Method
,	O
and	O
are	O
trained	O
purely	O
online	O
with	O
SGD	B-Method
,	O
existing	O
hard	B-Method
example	I-Method
mining	I-Method
techniques	I-Method
can	O
not	O
be	O
immediately	O
applied	O
.	O
	
This	O
work	O
addresses	O
that	O
problem	O
by	O
introducing	O
an	O
online	B-Method
hard	I-Method
example	I-Method
mining	I-Method
algorithm	I-Method
that	O
improves	O
optimization	B-Metric
and	I-Metric
detection	I-Metric
accuracy	I-Metric
.	O
	
We	O
briefly	O
review	O
hard	B-Task
example	I-Task
mining	I-Task
,	O
modern	O
ConvNet	B-Task
-	I-Task
based	I-Task
object	I-Task
detection	I-Task
,	O
and	O
relationships	O
to	O
concurrent	O
works	O
using	O
hard	B-Method
example	I-Method
selection	I-Method
for	O
training	O
deep	B-Method
networks	I-Method
.	O
	
paragraph	O
:	O
Hard	B-Task
example	I-Task
mining	I-Task
.	O
	
There	O
are	O
two	O
hard	O
example	B-Method
mining	I-Method
algorithms	I-Method
in	O
common	O
use	O
.	O
	
The	O
first	O
is	O
used	O
when	O
optimizing	O
SVMs	B-Method
.	O
	
In	O
this	O
case	O
,	O
the	O
training	B-Method
algorithm	I-Method
maintains	O
a	O
working	O
set	O
of	O
examples	O
and	O
alternates	O
between	O
training	O
an	O
SVM	B-Method
to	O
convergence	O
on	O
the	O
working	O
set	O
,	O
and	O
updating	O
the	O
working	O
set	O
by	O
removing	O
some	O
examples	O
and	O
adding	O
others	O
according	O
to	O
a	O
specific	O
rule	O
.	O
	
The	O
rule	O
removes	O
examples	O
that	O
are	O
“	O
easy	O
”	O
in	O
the	O
sense	O
that	O
they	O
are	O
correctly	O
classified	O
beyond	O
the	O
current	O
model	O
	
’s	O
margin	O
.	O
	
Conversely	O
,	O
the	O
rule	O
adds	O
new	O
examples	O
that	O
are	O
hard	O
in	O
the	O
sense	O
that	O
they	O
violate	O
the	O
current	O
model	O
’s	O
margin	O
.	O
	
Applying	O
this	O
rule	O
leads	O
to	O
the	O
global	B-Method
SVM	I-Method
solution	I-Method
.	O
	
Importantly	O
,	O
the	O
working	O
set	O
is	O
usually	O
a	O
small	O
subset	O
of	O
the	O
entire	O
training	O
set	O
.	O
	
The	O
second	O
method	O
is	O
used	O
for	O
non	B-Method
-	I-Method
SVMs	I-Method
and	O
has	O
been	O
applied	O
to	O
a	O
variety	O
of	O
models	O
including	O
shallow	B-Method
neural	I-Method
networks	I-Method
and	O
boosted	B-Method
decision	I-Method
trees	I-Method
.	O
	
This	O
algorithm	O
usually	O
starts	O
with	O
a	O
dataset	O
of	O
positive	O
examples	O
and	O
a	O
random	O
set	O
of	O
negative	O
examples	O
.	O
	
The	O
machine	B-Method
learning	I-Method
model	I-Method
is	O
then	O
trained	O
to	O
convergence	O
on	O
that	O
dataset	O
and	O
subsequently	O
applied	O
to	O
a	O
larger	O
dataset	O
to	O
harvest	O
false	O
positives	O
.	O
	
The	O
false	O
positives	O
are	O
then	O
added	O
to	O
the	O
training	O
set	O
	
and	O
then	O
the	O
model	O
is	O
trained	O
again	O
.	O
	
This	O
process	O
is	O
usually	O
iterated	O
only	O
once	O
and	O
does	O
not	O
have	O
any	O
convergence	O
proofs	O
.	O
	
paragraph	O
:	O
ConvNet	B-Method
-	I-Method
based	I-Method
object	I-Method
detection	I-Method
.	O
	
In	O
the	O
last	O
three	O
years	O
significant	O
gains	O
have	O
been	O
made	O
in	O
object	B-Task
detection	I-Task
.	O
	
These	O
improvements	O
were	O
made	O
possible	O
by	O
the	O
successful	O
application	O
of	O
deep	B-Method
ConvNets	I-Method
to	O
ImageNet	B-Task
classification	I-Task
.	O
	
The	O
R	B-Method
-	I-Method
CNN	I-Method
and	I-Method
OverFeat	I-Method
detectors	I-Method
lead	O
this	O
wave	O
with	O
impressive	O
results	O
on	O
PASCAL	B-Material
VOC	I-Material
and	O
ImageNet	B-Task
detection	I-Task
.	O
	
OverFeat	B-Method
is	O
based	O
on	O
the	O
sliding	B-Method
-	I-Method
window	I-Method
detection	I-Method
method	I-Method
,	O
which	O
is	O
perhaps	O
the	O
most	O
intuitive	O
and	O
oldest	O
search	B-Method
method	I-Method
for	O
detection	B-Task
.	O
	
R	B-Method
-	I-Method
CNN	I-Method
,	O
in	O
contrast	O
,	O
uses	O
region	B-Method
proposals	I-Method
,	O
a	O
method	O
that	O
was	O
made	O
popular	O
by	O
the	O
selective	B-Method
search	I-Method
algorithm	I-Method
.	O
	
Since	O
R	B-Method
-	I-Method
CNN	I-Method
,	O
there	O
has	O
been	O
rapid	O
progress	O
in	O
region	B-Task
-	I-Task
based	I-Task
ConvNets	I-Task
,	O
including	O
SPPnet	B-Method
,	O
MR	B-Method
-	I-Method
CNN	I-Method
,	O
and	O
Fast	B-Method
R	I-Method
-	I-Method
CNN	I-Method
,	O
which	O
our	O
work	O
builds	O
on	O
.	O
	
paragraph	O
:	O
Hard	B-Task
example	I-Task
selection	I-Task
in	O
deep	B-Task
learning	I-Task
.	O
	
There	O
is	O
recent	O
work	O
concurrent	O
to	O
our	O
own	O
that	O
selects	O
hard	O
examples	O
for	O
training	O
deep	B-Method
networks	I-Method
.	O
	
Similar	O
to	O
our	O
approach	O
,	O
all	O
these	O
methods	O
base	O
their	O
selection	O
on	O
the	O
current	O
loss	O
for	O
each	O
datapoint	O
.	O
	
independently	O
selects	O
hard	O
positive	O
and	O
negative	O
example	O
from	O
a	O
larger	O
set	O
of	O
random	O
examples	O
based	O
on	O
their	O
loss	O
to	O
learn	O
image	B-Task
descriptors	I-Task
.	O
	
Given	O
a	O
positive	O
pair	O
of	O
patches	O
,	O
finds	O
hard	O
negative	O
patches	O
from	O
a	O
large	O
set	O
using	O
triplet	B-Method
loss	I-Method
.	O
	
Akin	O
to	O
our	O
approach	O
,	O
investigates	O
online	B-Task
selection	I-Task
of	I-Task
hard	I-Task
examples	I-Task
for	O
mini	B-Method
-	I-Method
batch	I-Method
SGD	I-Method
methods	I-Method
.	O
	
Their	O
selection	O
is	O
also	O
based	O
on	O
loss	B-Task
,	O
but	O
the	O
focus	O
is	O
on	O
ConvNets	B-Method
for	O
image	B-Task
classification	I-Task
.	O
	
Complementary	O
to	O
,	O
we	O
focus	O
on	O
online	B-Method
hard	I-Method
example	I-Method
selection	I-Method
strategy	I-Method
for	O
region	B-Task
-	I-Task
based	I-Task
object	I-Task
detectors	I-Task
.	O
	
section	O
:	O
Overview	O
of	O
Fast	B-Method
R	I-Method
-	I-Method
CNN	I-Method
	
We	O
first	O
summarize	O
the	O
Fast	B-Method
R	I-Method
-	I-Method
CNN	I-Method
(	O
FRCN	B-Method
)	O
framework	O
.	O
	
FRCN	B-Method
takes	O
as	O
input	O
an	O
image	O
and	O
a	O
set	O
of	O
object	O
proposal	O
regions	O
of	O
interest	O
(	O
RoIs	O
)	O
.	O
	
The	O
FRCN	B-Method
network	O
itself	O
can	O
be	O
divided	O
into	O
two	O
sequential	O
parts	O
:	O
a	O
convolutional	B-Method
(	I-Method
conv	I-Method
)	I-Method
network	I-Method
with	O
several	O
convolution	B-Method
and	I-Method
max	I-Method
-	I-Method
pooling	I-Method
layers	I-Method
(	O
Figure	O
[	O
reference	O
]	O
,	O
“	O
Convolutional	B-Method
Network	I-Method
”	O
)	O
;	O
and	O
an	O
RoI	B-Method
network	I-Method
with	O
an	O
RoI	B-Method
-	I-Method
pooling	I-Method
layer	I-Method
,	O
several	O
fully	B-Method
-	I-Method
connected	I-Method
(	I-Method
fc	I-Method
)	I-Method
layers	I-Method
and	O
two	O
loss	B-Method
layers	I-Method
(	O
Figure	O
[	O
reference	O
]	O
,	O
“	O
RoI	B-Method
Network	I-Method
”	O
)	O
.	O
	
During	O
inference	B-Task
,	O
the	O
conv	B-Method
network	I-Method
is	O
applied	O
to	O
the	O
given	O
image	O
to	O
produce	O
a	O
conv	O
feature	O
map	O
,	O
size	O
of	O
which	O
depends	O
on	O
the	O
input	O
image	O
dimensions	O
.	O
	
Then	O
,	O
for	O
each	O
object	O
proposal	O
,	O
the	O
RoI	B-Method
-	I-Method
pooling	I-Method
layer	I-Method
projects	O
the	O
proposal	O
onto	O
the	O
conv	O
feature	O
map	O
and	O
extracts	O
a	O
fixed	O
-	O
length	O
feature	O
vector	O
.	O
	
Each	O
feature	O
vector	O
is	O
fed	O
into	O
the	O
fc	B-Method
layers	I-Method
,	O
which	O
finally	O
give	O
two	O
outputs	O
:	O
(	O
1	O
)	O
a	O
softmax	O
probability	O
distribution	O
over	O
the	O
object	O
classes	O
and	O
background	O
;	O
and	O
(	O
2	O
)	O
regressed	O
coordinates	O
for	O
bounding	B-Task
-	I-Task
box	I-Task
relocalization	I-Task
.	O
	
There	O
are	O
several	O
reasons	O
for	O
choosing	O
FRCN	B-Method
as	O
our	O
base	O
object	B-Method
detector	I-Method
,	O
apart	O
from	O
it	O
being	O
a	O
fast	O
end	O
-	O
to	O
-	O
end	B-Method
system	I-Method
.	O
	
Firstly	O
,	O
the	O
basic	O
two	O
network	B-Method
setup	I-Method
(	O
conv	B-Method
and	O
RoI	B-Method
)	O
is	O
also	O
used	O
by	O
other	O
recent	O
detectors	B-Method
like	O
SPPnet	B-Method
and	O
MR	B-Method
-	I-Method
CNN	I-Method
;	O
therefore	O
,	O
our	O
proposed	O
algorithm	O
is	O
more	O
broadly	O
applicable	O
.	O
	
Secondly	O
,	O
though	O
the	O
basic	O
setup	O
is	O
similar	O
,	O
FRCN	B-Method
also	O
allows	O
for	O
training	O
the	O
entire	O
conv	B-Method
network	I-Method
,	O
as	O
opposed	O
to	O
both	O
SPPnet	O
and	O
MR	B-Method
-	I-Method
CNN	I-Method
which	O
keep	O
the	O
conv	B-Method
network	I-Method
fixed	O
.	O
	
And	O
finally	O
,	O
both	O
SPPnet	B-Method
and	O
MR	B-Method
-	I-Method
CNN	I-Method
require	O
features	O
from	O
the	O
RoI	B-Method
network	I-Method
to	O
be	O
cached	O
for	O
training	O
a	O
separate	O
SVM	B-Method
classifier	I-Method
(	O
using	O
hard	B-Task
negative	I-Task
mining	I-Task
)	O
.	O
	
FRCN	B-Method
uses	O
the	O
RoI	B-Method
network	I-Method
itself	O
to	O
train	O
the	O
desired	O
classifiers	B-Method
.	O
	
In	O
fact	O
,	O
shows	O
that	O
in	O
the	O
unified	B-Method
system	I-Method
using	O
the	O
SVM	B-Method
classifiers	I-Method
at	O
later	O
stages	O
was	O
unnecessary	O
.	O
	
subsection	O
:	O
Training	O
	
Like	O
most	O
deep	B-Method
networks	I-Method
,	O
FRCN	B-Method
is	O
trained	O
using	O
stochastic	B-Method
gradient	I-Method
descent	I-Method
(	O
SGD	B-Method
)	O
.	O
	
The	O
loss	O
per	O
example	O
	
RoI	B-Method
is	O
the	O
sum	O
of	O
a	O
classification	B-Method
log	I-Method
loss	I-Method
that	O
encourages	O
predicting	O
the	O
correct	O
object	O
(	O
or	O
background	O
)	O
label	O
and	O
a	O
localization	B-Method
loss	I-Method
that	O
encourages	O
predicting	O
an	O
accurate	O
bounding	O
box	O
(	O
see	O
for	O
details	O
)	O
.	O
	
To	O
share	O
conv	B-Task
network	I-Task
computation	I-Task
between	O
RoIs	O
,	O
SGD	O
mini	O
-	O
batches	O
are	O
created	O
hierarchically	O
.	O
	
For	O
each	O
mini	O
-	O
batch	O
,	O
images	O
are	O
first	O
sampled	O
from	O
the	O
dataset	O
,	O
and	O
then	O
RoIs	O
are	O
sampled	O
from	O
each	O
image	O
.	O
	
Setting	O
and	O
works	O
well	O
in	O
practice	O
.	O
	
The	O
RoI	B-Method
sampling	I-Method
procedure	I-Method
uses	O
several	O
heuristics	O
,	O
which	O
we	O
describe	O
briefly	O
below	O
.	O
	
One	O
contribution	O
of	O
this	O
paper	O
is	O
to	O
eliminate	O
some	O
of	O
these	O
heuristics	O
and	O
their	O
hyperparameters	O
.	O
	
paragraph	O
:	O
Foreground	O
RoIs	O
.	O
	
For	O
an	O
example	O
RoI	O
to	O
be	O
labeled	O
as	O
foreground	O
(	O
fg	O
)	O
,	O
its	O
intersection	B-Metric
over	I-Metric
union	I-Metric
(	O
IoU	O
)	O
overlap	O
with	O
a	O
ground	O
-	O
truth	O
bounding	O
box	O
should	O
be	O
at	O
least	O
.	O
	
This	O
is	O
a	O
fairly	O
standard	O
design	O
choice	O
,	O
in	O
part	O
inspired	O
by	O
the	O
evaluation	B-Metric
protocol	I-Metric
of	O
the	O
PASCAL	B-Material
VOC	I-Material
object	O
detection	O
benchmark	O
.	O
	
The	O
same	O
criterion	O
is	O
used	O
in	O
the	O
SVM	B-Method
hard	I-Method
mining	I-Method
procedures	I-Method
of	O
R	B-Method
-	I-Method
CNN	I-Method
,	O
SPPnet	B-Method
,	O
and	O
MR	B-Method
-	I-Method
CNN	I-Method
.	O
	
We	O
use	O
the	O
same	O
setting	O
.	O
	
paragraph	O
:	O
Background	O
RoIs	O
.	O
	
A	O
region	O
is	O
labeled	O
background	O
(	O
bg	O
)	O
if	O
its	O
maximum	O
IoU	O
with	O
ground	O
truth	O
is	O
in	O
the	O
interval	O
bg_lo	O
,	O
0.5	O
)	O
.	O
	
A	O
lower	O
threshold	O
of	O
bg_lo	B-Method
is	O
used	O
by	O
both	O
FRCN	B-Method
and	O
SPPnet	B-Method
,	O
and	O
is	O
hypothesized	O
in	O
to	O
crudely	O
approximate	O
hard	B-Task
negative	I-Task
mining	I-Task
;	O
the	O
assumption	O
is	O
that	O
regions	O
with	O
some	O
overlap	O
with	O
the	O
ground	O
truth	O
are	O
more	O
likely	O
to	O
be	O
the	O
confusing	O
or	O
hard	O
ones	O
.	O
	
We	O
show	O
in	O
Section	O
[	O
reference	O
]	O
that	O
although	O
this	O
heuristic	O
helps	O
convergence	B-Metric
and	O
detection	B-Metric
accuracy	I-Metric
,	O
it	O
is	O
suboptimal	O
because	O
it	O
ignores	O
some	O
infrequent	O
,	O
but	O
important	O
,	O
difficult	O
background	O
regions	O
.	O
	
Our	O
method	O
removes	O
the	O
bg_lo	O
threshold	O
.	O
	
paragraph	O
:	O
Balancing	O
fg	O
-	O
bg	O
RoIs	O
:	O
	
To	O
handle	O
the	O
data	O
imbalance	O
described	O
in	O
Section	O
[	O
reference	O
]	O
,	O
designed	O
heuristics	O
to	O
rebalance	O
the	O
foreground	O
-	O
to	O
-	O
background	O
ratio	O
in	O
each	O
mini	O
-	O
batch	O
to	O
a	O
target	O
of	O
by	O
undersampling	O
the	O
background	O
patches	O
at	O
random	O
,	O
thus	O
ensuring	O
that	O
of	O
a	O
mini	O
-	O
batch	O
is	O
fg	O
RoIs	O
.	O
	
We	O
found	O
that	O
this	O
is	O
an	O
important	O
design	O
decision	O
for	O
the	O
training	O
FRCN	B-Method
.	O
	
Removing	O
this	O
ratio	O
(	O
randomly	O
sampling	O
RoIs	O
)	O
,	O
or	O
increasing	O
it	O
,	O
decreases	O
accuracy	B-Metric
by	O
points	B-Metric
mAP	I-Metric
.	O
	
With	O
our	O
proposed	O
method	O
,	O
we	O
can	O
remove	O
this	O
ratio	O
hyperparameter	O
with	O
no	O
ill	O
effect	O
.	O
	
section	O
:	O
Our	O
approach	O
	
We	O
propose	O
a	O
simple	O
yet	O
effective	O
online	B-Method
hard	I-Method
example	I-Method
mining	I-Method
algorithm	I-Method
for	O
training	O
Fast	B-Method
R	I-Method
-	I-Method
CNN	I-Method
(	O
or	O
any	O
Fast	B-Method
R	I-Method
-	I-Method
CNN	I-Method
style	O
object	O
detector	O
)	O
.	O
	
We	O
argue	O
that	O
the	O
current	O
way	O
of	O
creating	O
mini	B-Method
-	I-Method
batches	I-Method
for	O
SGD	B-Method
(	O
Section	O
[	O
reference	O
]	O
)	O
is	O
inefficient	O
and	O
suboptimal	O
,	O
and	O
we	O
demonstrate	O
that	O
our	O
approach	O
leads	O
to	O
better	O
training	B-Metric
(	O
lower	O
training	B-Metric
loss	I-Metric
)	O
and	O
higher	O
testing	B-Metric
performance	I-Metric
(	O
mAP	B-Metric
)	O
.	O
	
subsection	O
:	O
Online	B-Task
hard	I-Task
example	I-Task
mining	I-Task
	
Recall	O
the	O
alternating	O
steps	O
that	O
define	O
a	O
hard	B-Method
example	I-Method
mining	I-Method
algorithm	I-Method
:	O
(	O
a	O
)	O
for	O
some	O
period	O
of	O
time	O
a	O
fixed	B-Method
model	I-Method
is	O
used	O
to	O
find	O
new	O
examples	O
to	O
add	O
to	O
the	O
active	O
training	O
set	O
;	O
(	O
b	O
)	O
then	O
,	O
for	O
some	O
period	O
of	O
time	O
the	O
model	O
is	O
trained	O
on	O
the	O
fixed	O
active	O
training	O
set	O
.	O
	
In	O
the	O
context	O
of	O
SVM	B-Method
-	I-Method
based	I-Method
object	I-Method
detectors	I-Method
,	O
such	O
as	O
the	O
SVMs	B-Method
trained	O
in	O
R	B-Method
-	I-Method
CNN	I-Method
or	O
SPPnet	B-Method
,	O
step	O
(	O
a	O
)	O
inspects	O
a	O
variable	O
number	O
of	O
images	O
(	O
often	O
10	O
’s	O
or	O
100	O
’s	O
)	O
until	O
the	O
active	O
training	O
set	O
reaches	O
a	O
threshold	O
size	O
,	O
and	O
then	O
in	O
step	O
(	O
b	O
)	O
the	O
SVM	B-Method
is	O
trained	O
to	O
convergence	O
on	O
the	O
active	O
training	O
set	O
.	O
	
This	O
process	O
repeats	O
until	O
the	O
active	O
training	O
set	O
contains	O
all	O
support	O
vectors	O
.	O
	
Applying	O
an	O
analogous	O
strategy	O
to	O
FRCN	B-Method
ConvNet	O
training	O
slows	O
learning	B-Task
because	O
no	O
model	B-Method
updates	I-Method
are	O
made	O
while	O
selecting	O
examples	O
from	O
the	O
10	O
’s	O
or	O
100	O
’s	O
of	O
images	O
.	O
	
Our	O
main	O
observation	O
is	O
that	O
these	O
alternating	B-Method
steps	I-Method
can	O
be	O
combined	O
with	O
how	O
FRCN	B-Method
is	O
trained	O
using	O
online	B-Method
SGD	I-Method
.	O
	
The	O
key	O
is	O
that	O
although	O
each	O
SGD	B-Method
iteration	I-Method
samples	O
only	O
a	O
small	O
number	O
of	O
images	O
,	O
each	O
image	O
contains	O
thousands	O
of	O
example	O
RoIs	O
from	O
which	O
we	O
can	O
select	O
the	O
hard	O
examples	O
rather	O
than	O
a	O
heuristically	O
sampled	O
subset	O
.	O
	
This	O
strategy	O
fits	O
the	O
alternation	O
template	O
to	O
SGD	B-Method
by	O
“	O
freezing	O
”	O
the	O
model	O
for	O
only	O
one	O
mini	O
-	O
batch	O
.	O
	
Thus	O
the	O
model	O
is	O
updated	O
exactly	O
as	O
frequently	O
as	O
with	O
the	O
baseline	B-Method
SGD	I-Method
approach	I-Method
and	O
therefore	O
learning	B-Task
is	O
not	O
delayed	O
.	O
	
More	O
specifically	O
,	O
the	O
online	B-Method
hard	I-Method
example	I-Method
mining	I-Method
algorithm	I-Method
(	O
OHEM	B-Method
)	O
proceeds	O
as	O
follows	O
.	O
	
For	O
an	O
input	O
image	O
at	O
SGD	B-Task
iteration	I-Task
,	O
we	O
first	O
compute	O
a	O
conv	B-Method
feature	I-Method
map	I-Method
using	O
the	O
conv	B-Method
network	I-Method
.	O
	
Then	O
the	O
RoI	B-Method
network	I-Method
uses	O
this	O
feature	B-Method
map	I-Method
and	O
the	O
all	O
the	O
input	O
RoIs	O
,	O
instead	O
of	O
a	O
sampled	O
mini	O
-	O
batch	O
,	O
to	O
do	O
a	O
forward	B-Method
pass	I-Method
.	O
	
Recall	O
that	O
this	O
step	O
only	O
involves	O
RoI	B-Method
pooling	I-Method
,	O
a	O
few	O
fc	B-Method
layers	I-Method
,	O
and	O
loss	B-Method
computation	I-Method
for	O
each	O
RoI.	O
	
The	O
loss	O
represents	O
how	O
well	O
the	O
current	O
network	O
performs	O
on	O
each	O
RoI.	O
Hard	O
examples	O
are	O
selected	O
by	O
sorting	O
the	O
input	O
RoIs	O
by	O
loss	O
and	O
taking	O
the	O
examples	O
for	O
which	O
the	O
current	O
network	O
performs	O
worst	O
.	O
	
Most	O
of	O
the	O
forward	B-Method
computation	I-Method
is	O
shared	O
between	O
RoIs	O
via	O
the	O
conv	B-Method
feature	I-Method
map	I-Method
,	O
so	O
the	O
extra	O
computation	O
needed	O
to	O
forward	O
all	O
RoIs	O
is	O
relatively	O
small	O
.	O
	
Moreover	O
,	O
because	O
only	O
a	O
small	O
number	O
of	O
RoIs	O
are	O
selected	O
for	O
updating	O
the	O
model	O
,	O
the	O
backward	B-Method
pass	I-Method
is	O
no	O
more	O
expensive	O
than	O
before	O
.	O
	
However	O
,	O
there	O
is	O
a	O
small	O
caveat	O
:	O
co	O
-	O
located	O
RoIs	O
with	O
high	O
overlap	O
are	O
likely	O
to	O
have	O
correlated	O
losses	O
.	O
	
Moreover	O
,	O
these	O
overlapping	O
RoIs	O
can	O
project	O
onto	O
the	O
same	O
region	O
in	O
the	O
conv	O
feature	O
map	O
,	O
because	O
of	O
resolution	O
disparity	O
,	O
thus	O
leading	O
to	O
loss	B-Task
double	I-Task
counting	I-Task
.	O
	
To	O
deal	O
with	O
these	O
redundant	O
and	O
correlated	O
regions	O
,	O
we	O
use	O
standard	O
non	B-Method
-	I-Method
maximum	I-Method
suppression	I-Method
(	O
NMS	B-Method
)	O
to	O
perform	O
deduplication	B-Task
(	O
the	O
implementation	O
from	O
)	O
.	O
	
Given	O
a	O
list	O
of	O
RoIs	O
and	O
their	O
losses	O
,	O
NMS	B-Method
works	O
by	O
iteratively	O
selecting	O
the	O
RoI	O
with	O
the	O
highest	O
loss	O
,	O
and	O
then	O
removing	O
all	O
lower	O
loss	O
RoIs	O
that	O
have	O
high	O
overlap	O
with	O
the	O
selected	O
region	O
.	O
	
We	O
use	O
a	O
relaxed	O
IoU	O
threshold	O
of	O
to	O
suppress	O
only	O
highly	O
overlapping	O
RoIs	O
.	O
	
We	O
note	O
that	O
the	O
procedure	O
described	O
above	O
does	O
not	O
need	O
a	O
fg	O
-	O
bg	O
ratio	O
for	O
data	B-Task
balancing	I-Task
.	O
	
If	O
any	O
class	O
were	O
neglected	O
,	O
its	O
loss	O
would	O
increase	O
until	O
it	O
has	O
a	O
high	O
probability	O
of	O
being	O
sampled	O
.	O
	
There	O
can	O
be	O
images	O
where	O
the	O
fg	O
RoIs	O
are	O
easy	O
(	O
canonical	O
view	O
of	O
a	O
car	O
)	O
,	O
so	O
the	O
network	O
is	O
free	O
to	O
use	O
only	O
bg	O
regions	O
in	O
a	O
mini	O
-	O
batch	O
;	O
and	O
vice	O
-	O
versa	O
when	O
bg	O
is	O
trivial	O
(	O
sky	O
,	O
grass	O
)	O
,	O
the	O
mini	B-Method
-	I-Method
batch	I-Method
can	O
be	O
entirely	O
fg	O
regions	O
.	O
	
subsection	O
:	O
Implementation	O
details	O
	
There	O
are	O
many	O
ways	O
to	O
implement	O
OHEM	B-Method
in	O
the	O
FRCN	B-Method
detector	O
,	O
each	O
with	O
different	O
trade	O
-	O
offs	O
.	O
	
An	O
obvious	O
way	O
is	O
to	O
modify	O
the	O
loss	O
layers	O
to	O
do	O
the	O
hard	B-Task
example	I-Task
selection	I-Task
.	O
	
The	O
loss	B-Method
layer	I-Method
can	O
compute	O
loss	O
for	O
all	O
RoIs	O
,	O
sort	O
them	O
based	O
on	O
this	O
loss	O
to	O
select	O
hard	O
RoIs	O
,	O
and	O
finally	O
set	O
the	O
loss	O
of	O
all	O
non	O
-	O
hard	O
RoIs	O
to	O
.	O
	
Though	O
straightforward	O
,	O
this	O
implementation	O
is	O
inefficient	O
as	O
the	O
RoI	B-Method
network	I-Method
still	O
allocates	O
memory	O
and	O
performs	O
backward	O
pass	O
for	O
all	O
RoIs	O
,	O
even	O
though	O
most	O
RoIs	O
have	O
loss	O
and	O
hence	O
no	O
gradient	O
updates	O
(	O
a	O
limitation	O
of	O
current	O
deep	B-Method
learning	I-Method
toolboxes	I-Method
)	O
.	O
	
To	O
overcome	O
this	O
,	O
we	O
propose	O
the	O
architecture	O
presented	O
in	O
Figure	O
[	O
reference	O
]	O
.	O
	
Our	O
implementation	O
maintains	O
two	O
copies	O
of	O
the	O
RoI	B-Method
network	I-Method
,	O
one	O
of	O
which	O
is	O
readonly	O
.	O
	
This	O
implies	O
that	O
the	O
readonly	B-Method
RoI	I-Method
network	I-Method
(	O
Figure	O
[	O
reference	O
]	O
(	O
a	O
)	O
)	O
allocates	O
memory	O
only	O
for	O
forward	O
pass	O
of	O
all	O
RoIs	O
as	O
opposed	O
to	O
the	O
standard	O
RoI	B-Method
network	I-Method
,	O
which	O
allocates	O
memory	O
for	O
both	O
forward	O
and	O
backward	O
passes	O
.	O
	
For	O
an	O
SGD	B-Method
iteration	I-Method
,	O
given	O
the	O
conv	O
feature	O
map	O
,	O
the	O
readonly	B-Method
RoI	I-Method
network	I-Method
performs	O
a	O
forward	B-Method
pass	I-Method
and	O
computes	O
loss	O
for	O
all	O
input	O
RoIs	O
(	O
Figure	O
[	O
reference	O
]	O
,	O
green	O
arrows	O
)	O
.	O
	
Then	O
the	O
hard	B-Method
RoI	I-Method
sampling	I-Method
module	I-Method
uses	O
the	O
procedure	O
described	O
in	O
Section	O
[	O
reference	O
]	O
to	O
select	O
hard	O
examples	O
,	O
which	O
are	O
input	O
to	O
the	O
regular	B-Method
RoI	I-Method
network	I-Method
(	O
Figure	O
[	O
reference	O
]	O
(	O
b	O
)	O
,	O
red	O
arrows	O
)	O
)	O
.	O
	
This	O
network	O
computes	O
forward	O
and	O
backward	O
passes	O
only	O
for	O
,	O
accumulates	O
the	O
gradients	O
and	O
passes	O
them	O
to	O
the	O
conv	B-Method
network	I-Method
.	O
	
In	O
practice	O
,	O
we	O
use	O
all	O
RoIs	O
from	O
all	O
images	O
as	O
,	O
therefore	O
the	O
effective	O
batch	B-Metric
size	I-Metric
for	O
the	O
readonly	B-Method
RoI	I-Method
network	I-Method
is	O
and	O
for	O
the	O
regular	B-Method
RoI	I-Method
network	I-Method
is	O
the	O
standard	O
from	O
Section	O
[	O
reference	O
]	O
.	O
	
We	O
implement	O
both	O
options	O
described	O
above	O
using	O
the	O
Caffe	B-Method
framework	I-Method
(	O
see	O
)	O
.	O
	
Our	O
implementation	O
uses	O
gradient	B-Method
accumulation	I-Method
with	O
forward	B-Method
-	I-Method
backward	I-Method
passes	I-Method
of	I-Method
single	I-Method
image	I-Method
mini	I-Method
-	I-Method
batches	I-Method
.	O
	
Following	O
FRCN	B-Method
,	O
we	O
use	O
(	O
which	O
results	O
in	O
)	O
and	O
.	O
	
Under	O
these	O
settings	O
,	O
the	O
proposed	O
architecture	O
(	O
Figure	O
[	O
reference	O
]	O
)	O
has	O
similar	O
memory	O
footprint	O
as	O
the	O
first	O
option	O
,	O
but	O
is	O
faster	O
.	O
	
Unless	O
specified	O
otherwise	O
,	O
the	O
architecture	O
and	O
settings	O
described	O
above	O
will	O
be	O
used	O
throughout	O
this	O
paper	O
.	O
	
section	O
:	O
Analyzing	O
online	B-Method
hard	I-Method
example	I-Method
mining	I-Method
	
This	O
section	O
compares	O
FRCN	B-Method
training	O
with	O
online	B-Method
hard	I-Method
example	I-Method
mining	I-Method
(	O
OHEM	B-Method
)	O
to	O
the	O
baseline	B-Method
heuristic	I-Method
sampling	I-Method
approach	I-Method
.	O
	
We	O
also	O
compare	O
FRCN	B-Method
with	O
OHEM	B-Method
to	O
a	O
less	O
efficient	O
approach	O
that	O
uses	O
all	O
available	O
example	O
RoIs	O
in	O
each	O
mini	O
-	O
batch	O
,	O
not	O
just	O
the	O
hardest	O
examples	O
.	O
	
subsection	O
:	O
Experimental	O
setup	O
	
We	O
conduct	O
experiments	O
with	O
two	O
standard	O
ConvNet	B-Method
architectures	I-Method
:	O
VGG_CNN_M_1024	B-Method
(	O
VGGM	B-Method
,	O
for	O
short	O
)	O
from	O
,	O
which	O
is	O
a	O
wider	O
version	O
of	O
AlexNet	B-Method
,	O
and	O
VGG16	B-Method
from	O
.	O
	
All	O
experiments	O
in	O
this	O
section	O
are	O
performed	O
on	O
the	O
PASCAL	B-Material
VOC07	I-Material
dataset	I-Material
.	O
	
Training	O
is	O
done	O
on	O
the	O
trainval	O
set	O
and	O
testing	O
on	O
the	O
test	O
set	O
.	O
	
Unless	O
specified	O
otherwise	O
,	O
we	O
will	O
use	O
the	O
default	O
settings	O
from	O
FRCN	B-Method
.	O
	
We	O
train	O
all	O
methods	O
with	O
SGD	B-Method
for	O
80k	O
mini	O
-	O
batch	O
iterations	O
,	O
with	O
an	O
initial	O
learning	B-Metric
rate	I-Metric
of	O
0.001	O
and	O
we	O
decay	O
the	O
learning	B-Metric
rate	I-Metric
by	O
0.1	O
every	O
30k	O
iterations	O
.	O
	
The	O
baseline	O
numbers	O
reported	O
in	O
Table	O
[	O
reference	O
]	O
(	O
row	O
1	O
-	O
2	O
)	O
were	O
reproduced	O
using	O
our	O
training	O
schedule	O
and	O
are	O
slightly	O
higher	O
than	O
the	O
ones	O
reported	O
in	O
.	O
	
subsection	O
:	O
OHEM	B-Method
vs.	O
heuristic	B-Method
sampling	I-Method
	
Standard	O
FRCN	B-Method
,	O
reported	O
in	O
Table	O
[	O
reference	O
]	O
(	O
rows	O
)	O
,	O
uses	O
as	O
a	O
heuristic	B-Method
for	O
hard	B-Task
mining	I-Task
(	O
Section	O
[	O
reference	O
]	O
)	O
.	O
	
To	O
test	O
the	O
importance	O
of	O
this	O
heuristic	O
,	O
we	O
ran	O
FRCN	B-Method
with	O
.	O
	
Table	O
[	O
reference	O
]	O
(	O
rows	O
)	O
shows	O
that	O
for	O
VGGM	B-Method
,	O
mAP	B-Metric
drops	O
by	O
points	O
,	O
whereas	O
for	O
VGG16	O
it	O
remains	O
roughly	O
the	O
same	O
.	O
	
Now	O
compare	O
this	O
to	O
training	O
FRCN	B-Method
with	O
OHEM	B-Method
(	O
rows	O
)	O
.	O
	
OHEM	B-Method
improves	O
mAP	B-Metric
by	O
points	O
compared	O
to	O
FRCN	B-Method
with	O
the	O
heuristic	O
for	O
VGGM	B-Method
,	O
and	O
points	O
without	O
the	O
heuristic	O
.	O
	
This	O
result	O
demonstrates	O
the	O
sub	O
-	O
optimality	O
of	O
these	O
heuristics	O
and	O
the	O
effectiveness	O
of	O
our	O
hard	B-Method
mining	I-Method
approach	I-Method
.	O
	
subsection	O
:	O
Robust	B-Method
gradient	I-Method
estimates	I-Method
	
One	O
concern	O
over	O
using	O
only	O
images	O
per	O
batch	O
is	O
that	O
it	O
may	O
cause	O
unstable	O
gradients	O
and	O
slow	O
convergence	O
because	O
RoIs	O
from	O
an	O
image	O
may	O
be	O
highly	O
correlated	O
.	O
	
FRCN	B-Method
reports	O
that	O
this	O
was	O
not	O
a	O
practical	O
issue	O
for	O
their	O
training	O
.	O
	
But	O
this	O
detail	O
might	O
raise	O
concerns	O
over	O
our	O
training	O
procedure	O
because	O
we	O
use	O
examples	O
with	O
high	O
loss	O
from	O
the	O
same	O
image	O
and	O
as	O
a	O
result	O
they	O
may	O
be	O
more	O
highly	O
correlated	O
.	O
	
To	O
address	O
this	O
concern	O
,	O
we	O
experiment	O
with	O
in	O
order	O
to	O
increase	O
correlation	O
in	O
an	O
effort	O
to	O
break	O
our	O
method	O
.	O
	
As	O
seen	O
in	O
Table	O
[	O
reference	O
]	O
(	O
rows	O
)	O
,	O
performance	O
of	O
the	O
original	O
FRCN	B-Method
drops	O
by	O
point	O
with	O
,	O
but	O
when	O
using	O
our	O
training	B-Method
procedure	I-Method
,	O
mAP	B-Metric
remains	O
approximately	O
the	O
same	O
.	O
	
This	O
shows	O
that	O
OHEM	B-Method
is	O
robust	O
in	O
case	O
one	O
needs	O
fewer	O
images	O
per	O
batch	O
in	O
order	O
to	O
reduce	O
GPU	O
memory	O
usage	O
.	O
	
subsection	O
:	O
Why	O
just	O
hard	O
examples	O
,	O
when	O
you	O
can	O
use	O
all	O
?	O
	
Online	B-Task
hard	I-Task
example	I-Task
mining	I-Task
is	O
based	O
on	O
the	O
hypothesis	O
that	O
it	O
is	O
important	O
to	O
consider	O
all	O
RoIs	O
in	O
an	O
image	O
and	O
then	O
select	O
hard	O
examples	O
for	O
training	O
.	O
	
But	O
what	O
if	O
we	O
train	O
with	O
all	O
the	O
RoIs	O
,	O
not	O
just	O
the	O
hard	O
ones	O
?	O
	
The	O
easy	O
examples	O
will	O
have	O
low	O
loss	O
,	O
and	O
wo	O
n’t	O
contribute	O
much	O
to	O
the	O
gradient	O
;	O
training	O
will	O
automatically	O
focus	O
on	O
the	O
hard	O
examples	O
.	O
	
To	O
compare	O
this	O
option	O
,	O
we	O
ran	O
standard	O
FRCN	B-Method
training	O
with	O
a	O
large	O
mini	O
-	O
batch	O
size	O
of	O
,	O
using	O
,	O
and	O
with	O
other	O
hyperparameters	O
fixed	O
.	O
	
Because	O
this	O
experiment	O
uses	O
a	O
large	O
mini	O
-	O
batch	O
,	O
it	O
’s	O
important	O
to	O
tune	O
the	O
learning	B-Metric
rate	I-Metric
to	O
adjust	O
for	O
this	O
change	O
.	O
	
We	O
found	O
optimal	O
results	O
by	O
increasing	O
it	O
to	O
for	O
VGG16	B-Method
and	O
for	O
VGGM	B-Method
.	O
	
The	O
outcomes	O
are	O
reported	O
in	O
Table	O
[	O
reference	O
]	O
(	O
rows	O
)	O
.	O
	
Using	O
these	O
settings	O
,	O
mAP	B-Metric
of	O
both	O
VGG16	O
and	O
VGGM	O
increased	O
by	O
point	O
compared	O
to	O
,	O
but	O
the	O
improvement	O
from	O
our	O
approach	O
is	O
still	O
points	O
over	O
using	O
all	O
RoIs	O
.	O
	
Moreover	O
,	O
because	O
we	O
compute	O
gradients	O
with	O
a	O
smaller	O
mini	B-Method
-	I-Method
batch	I-Method
size	I-Method
training	I-Method
is	O
faster	O
.	O
	
Removing	O
hard	B-Method
mining	I-Method
heuristic	I-Method
(	O
Section	O
[	O
reference	O
]	O
)	O
	
Fewer	O
images	O
per	O
batch	O
(	O
Section	O
[	O
reference	O
]	O
)	O
	
Bigger	O
batch	O
,	O
High	O
LR	O
(	O
Section	O
[	O
reference	O
]	O
)	O
	
Our	O
Approach	O
	
subsection	O
:	O
Better	O
optimization	B-Task
	
Finally	O
,	O
we	O
analyze	O
the	O
training	B-Metric
loss	I-Metric
for	O
the	O
various	O
FRCN	B-Method
training	O
methods	O
discussed	O
above	O
.	O
	
It	O
’s	O
important	O
to	O
measure	O
training	B-Metric
loss	I-Metric
in	O
a	O
way	O
that	O
does	O
not	O
depend	O
on	O
the	O
sampling	B-Method
procedure	I-Method
and	O
thus	O
results	O
in	O
a	O
valid	O
comparison	O
between	O
methods	O
.	O
	
To	O
achieve	O
this	O
goal	O
,	O
we	O
take	O
model	O
snapshots	O
from	O
each	O
method	O
every	O
20k	O
steps	O
of	O
optimization	B-Task
and	O
run	O
them	O
over	O
the	O
entire	O
VOC07	B-Material
trainval	O
set	O
to	O
compute	O
the	O
average	B-Metric
loss	I-Metric
over	O
all	O
RoIs	O
.	O
	
This	O
measures	O
the	O
training	B-Metric
set	I-Metric
loss	I-Metric
in	O
a	O
way	O
that	O
does	O
not	O
depend	O
on	O
the	O
example	B-Method
sampling	I-Method
scheme	I-Method
.	O
	
Figure	O
[	O
reference	O
]	O
shows	O
the	O
average	B-Metric
loss	I-Metric
per	I-Metric
RoI	I-Metric
for	O
VGG16	B-Method
with	O
the	O
various	O
hyperparameter	O
settings	O
discussed	O
above	O
and	O
presented	O
in	O
Table	O
[	O
reference	O
]	O
.	O
	
We	O
see	O
that	O
results	O
in	O
the	O
highest	O
training	B-Metric
loss	I-Metric
,	O
while	O
using	O
the	O
heuristic	B-Method
results	O
in	O
a	O
much	O
lower	O
training	B-Metric
loss	I-Metric
.	O
	
Increasing	O
the	O
mini	O
-	O
batch	O
size	O
to	O
and	O
increasing	O
the	O
learning	B-Metric
rate	I-Metric
lowers	O
the	O
training	B-Metric
loss	I-Metric
below	O
the	O
heuristic	O
.	O
	
Our	O
proposed	O
online	B-Method
hard	I-Method
example	I-Method
mining	I-Method
method	O
achieves	O
the	O
lowest	O
training	B-Metric
loss	I-Metric
of	O
all	O
methods	O
,	O
validating	O
our	O
claims	O
that	O
OHEM	B-Method
leads	O
to	O
better	O
training	B-Task
for	O
FRCN	B-Method
.	O
	
*	O
:	O
uses	O
gradient	B-Method
accumulation	I-Method
over	O
two	O
forward	O
/	O
backward	O
passes	O
	
subsection	O
:	O
Computational	B-Metric
cost	I-Metric
	
OHEM	B-Method
adds	O
reasonable	O
computational	B-Metric
and	I-Metric
memory	I-Metric
overhead	I-Metric
,	O
as	O
reported	O
in	O
Table	O
[	O
reference	O
]	O
.	O
	
OHEM	B-Method
costs	O
0.09s	O
per	O
training	O
iteration	O
for	O
VGGM	B-Method
network	I-Method
(	O
0.43s	O
for	O
VGG16	B-Method
)	O
and	O
requires	O
1	O
G	O
more	O
memory	O
(	O
2.3	O
G	O
for	O
VGG16	B-Method
)	O
.	O
	
Given	O
that	O
FRCN	B-Method
is	O
a	O
fast	O
detector	B-Method
to	O
train	O
,	O
the	O
increase	O
in	O
training	B-Metric
time	I-Metric
is	O
likely	O
acceptable	O
to	O
most	O
users	O
.	O
	
,	O
2http:	O
//	O
host.robots.ox.ac.uk:8080	O
/	O
anonymous	O
/	O
H49PTT.html	O
,	O
3http:	O
//	O
host.robots.ox.ac.uk:8080	O
/	O
anonymous	O
	
/	O
LSANTB.html	B-Method
,	O
4http:	O
//	O
host.robots.ox.ac.uk:8080	O
/	O
anonymous	O
/	O
R7EAMX.html	O
	
section	O
:	O
PASCAL	B-Material
VOC	I-Material
and	O
MS	B-Material
COCO	I-Material
results	O
	
In	O
this	O
section	O
,	O
we	O
evaluate	O
our	O
method	O
on	O
VOC	B-Material
2012	I-Material
as	O
well	O
as	O
the	O
more	O
challenging	O
MS	B-Material
COCO	I-Material
dataset	O
.	O
	
We	O
demonstrate	O
consistent	O
and	O
significant	O
improvement	O
in	O
FRCN	B-Method
performance	O
when	O
using	O
the	O
proposed	O
OHEM	B-Method
approach	O
.	O
	
Per	O
-	O
class	O
results	O
are	O
also	O
presented	O
on	O
VOC	B-Material
2007	I-Material
for	O
comparison	O
with	O
prior	O
work	O
.	O
	
paragraph	O
:	O
Experimental	O
setup	O
.	O
	
We	O
use	O
VGG16	B-Method
for	O
all	O
experiments	O
.	O
	
When	O
training	O
on	O
VOC07	B-Material
trainval	I-Material
,	O
we	O
use	O
the	O
SGD	O
parameters	O
as	O
in	O
Section	O
[	O
reference	O
]	O
and	O
when	O
using	O
extra	O
data	O
(	O
07	O
+	O
12	O
and	O
07	O
++	O
12	O
,	O
see	O
Table	O
[	O
reference	O
]	O
and	O
[	O
reference	O
]	O
)	O
	
,	O
we	O
use	O
200k	O
mini	B-Method
-	I-Method
batch	I-Method
iterations	I-Method
,	O
with	O
an	O
initial	O
learning	B-Metric
rate	I-Metric
of	O
0.001	O
and	O
decay	B-Metric
step	I-Metric
size	I-Metric
of	O
40k	O
.	O
	
When	O
training	O
on	O
MS	B-Material
COCO	I-Material
,	O
we	O
use	O
240k	O
mini	B-Method
-	I-Method
batch	I-Method
iterations	I-Method
,	O
with	O
an	O
initial	O
learning	B-Metric
rate	I-Metric
of	O
0.001	O
and	O
decay	B-Metric
step	I-Metric
size	I-Metric
of	O
160k	O
,	O
owing	O
to	O
a	O
larger	O
epoch	O
size	O
.	O
	
subsection	O
:	O
VOC	B-Material
2007	O
and	O
2012	B-Material
results	O
	
Table	O
[	O
reference	O
]	O
shows	O
that	O
on	O
VOC07	B-Material
,	O
OHEM	B-Method
improves	O
the	O
mAP	B-Metric
of	O
FRCN	B-Method
from	O
67.2	O
%	O
to	O
69.9	O
%	O
(	O
and	O
70.0	O
%	O
to	O
74.6	O
%	O
with	O
extra	O
data	O
)	O
.	O
	
On	O
VOC12	B-Material
,	O
OHEM	B-Method
leads	O
to	O
an	O
improvement	O
of	O
4.1	O
points	O
in	O
mAP	B-Metric
(	O
from	O
65.7	O
%	O
to	O
69.8	O
%	O
)	O
.	O
	
With	O
extra	O
data	O
,	O
we	O
achieve	O
an	O
mAP	B-Metric
of	O
71.9	O
%	O
as	O
compared	O
to	O
68.4	O
%	O
mAP	B-Metric
of	O
FRCN	B-Method
,	O
an	O
improvement	O
of	O
3.5	O
points	O
.	O
	
Interestingly	O
the	O
improvements	O
are	O
not	O
uniform	O
across	O
categories	O
.	O
	
Bottle	O
,	O
chair	O
,	O
and	O
tvmonitor	O
show	O
larger	O
improvements	O
that	O
are	O
consistent	O
across	O
the	O
different	O
PASCAL	O
splits	O
.	O
	
Why	O
these	O
classes	O
benefit	O
the	O
most	O
is	O
an	O
interesting	O
and	O
open	O
question	O
.	O
	
subsection	O
:	O
MS	B-Material
COCO	I-Material
results	O
	
To	O
test	O
the	O
benefit	O
of	O
using	O
OHEM	B-Method
on	O
a	O
larger	O
and	O
more	O
challenging	O
dataset	O
,	O
we	O
conduct	O
experiments	O
on	O
MS	B-Material
COCO	I-Material
and	O
report	O
numbers	O
from	O
test	O
-	O
dev	O
2015	O
evaluation	O
server	O
(	O
Table	O
[	O
reference	O
]	O
)	O
.	O
	
On	O
the	O
standard	O
COCO	B-Metric
evaluation	I-Metric
metric	I-Metric
,	O
FRCN	B-Method
scores	O
19.7	O
%	O
AP	B-Metric
,	O
and	O
OHEM	B-Method
improves	O
it	O
to	O
22.6	O
%	O
AP	B-Metric
.	O
	
Using	O
the	O
VOC	B-Material
overlap	O
metric	O
of	O
,	O
OHEM	B-Method
gives	O
a	O
6.6	O
points	O
boost	O
in	O
AP	B-Metric
.	O
	
It	O
is	O
also	O
interesting	O
to	O
note	O
that	O
OHEM	B-Method
helps	O
improve	O
the	O
AP	B-Metric
of	O
medium	O
sized	O
objects	O
by	O
4.9	O
points	O
on	O
the	O
strict	O
COCO	O
AP	B-Metric
evaluation	O
metric	O
,	O
which	O
indicates	O
that	O
the	O
proposed	O
hard	B-Method
example	I-Method
mining	I-Method
approach	I-Method
is	O
helpful	O
when	O
dealing	O
with	O
smaller	O
sized	O
objects	O
.	O
	
Note	O
that	O
FRCN	B-Method
with	O
and	O
without	O
OHEM	B-Method
were	O
trained	O
on	O
MS	B-Material
COCO	I-Material
train	O
set	O
.	O
	
section	O
:	O
Adding	O
bells	O
and	O
whistles	O
	
We	O
’	O
ve	O
demonstrated	O
consistent	O
gains	O
in	O
detection	B-Metric
accuracy	I-Metric
by	O
applying	O
OHEM	B-Method
to	O
FRCN	B-Method
training	O
.	O
	
In	O
this	O
section	O
,	O
we	O
show	O
that	O
these	O
improvements	O
are	O
orthogonal	O
to	O
recent	O
bells	O
and	O
whistles	O
that	O
enhance	O
object	B-Metric
detection	I-Metric
accuracy	I-Metric
.	O
	
OHEM	B-Method
with	O
the	O
following	O
two	O
additions	O
	
yields	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
results	O
on	O
VOC	B-Material
and	O
competitive	O
results	O
on	O
MS	B-Material
COCO	I-Material
.	O
	
paragraph	O
:	O
Multi	O
-	O
scale	O
(	O
M	O
)	O
.	O
	
We	O
adopt	O
the	O
multi	B-Method
-	I-Method
scale	I-Method
strategy	O
from	O
SPPnet	B-Method
(	O
and	O
used	O
by	O
both	O
FRCN	B-Method
and	O
MR	B-Method
-	I-Method
CNN	I-Method
)	O
.	O
	
Scale	O
is	O
defined	O
as	O
the	O
size	O
of	O
the	O
shortest	O
side	O
(	O
)	O
of	O
an	O
image	O
.	O
	
During	O
training	O
,	O
one	O
scale	O
is	O
chosen	O
at	O
random	O
,	O
whereas	O
at	O
test	O
time	O
inference	B-Task
is	O
run	O
on	O
all	O
scales	O
.	O
	
For	O
VGG16	B-Method
networks	I-Method
,	O
we	O
use	O
for	O
training	B-Task
,	O
and	O
during	O
testing	O
,	O
with	O
the	O
max	O
dimension	O
capped	O
at	O
1000	O
.	O
	
The	O
scales	O
and	O
caps	O
were	O
chosen	O
because	O
of	O
GPU	O
memory	O
constraints	O
.	O
	
paragraph	O
:	O
Iterative	B-Method
bounding	I-Method
-	I-Method
box	I-Method
regression	I-Method
(	O
B	O
)	O
.	O
	
We	O
adopt	O
the	O
iterative	B-Method
localization	I-Method
and	I-Method
bounding	I-Method
-	I-Method
box	I-Method
(	I-Method
bbox	I-Method
)	I-Method
voting	I-Method
scheme	I-Method
from	O
.	O
	
The	O
network	O
evaluates	O
each	O
proposal	O
RoI	O
to	O
get	O
scores	O
and	O
relocalized	O
boxes	O
.	O
	
High	O
-	O
scoring	O
boxes	O
are	O
the	O
rescored	O
and	O
relocalized	O
,	O
yielding	O
boxes	O
.	O
	
Union	O
of	O
and	O
is	O
used	O
as	O
the	O
final	O
set	O
for	O
post	B-Task
-	I-Task
processing	I-Task
,	O
where	O
is	O
obtained	O
using	O
NMS	B-Method
on	O
with	O
an	O
IoU	O
threshold	O
of	O
0.3	O
and	O
weighted	B-Method
voting	I-Method
is	O
performed	O
on	O
each	O
box	O
in	O
using	O
boxes	O
in	O
with	O
an	O
IoU	O
of	O
0.5	O
with	O
(	O
see	O
for	O
details	O
)	O
.	O
	
from	O
the	O
leaderboard	B-Method
,	O
*	O
trained	O
on	O
trainval	O
set	O
	
subsection	O
:	O
VOC	B-Material
2007	I-Material
and	O
2012	B-Material
results	O
	
We	O
report	O
the	O
results	O
on	O
VOC	B-Material
benchmarks	O
in	O
Table	O
[	O
reference	O
]	O
and	O
[	O
reference	O
]	O
.	O
	
On	O
VOC07	B-Material
,	O
FRCN	B-Method
with	O
the	O
above	O
mentioned	O
additions	O
achieves	O
72.4	O
%	O
mAP	B-Metric
and	O
OHEM	B-Method
improves	O
it	O
to	O
75.1	O
%	O
,	O
which	O
is	O
currently	O
the	O
highest	O
reported	O
score	O
under	O
this	O
setting	O
(	O
07	O
data	O
)	O
.	O
	
When	O
using	O
extra	O
data	O
(	O
07	O
+	O
12	O
)	O
,	O
OHEM	B-Method
achieves	O
78.9	O
%	O
mAP	B-Metric
,	O
surpassing	O
the	O
current	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
MR	B-Method
-	I-Method
CNN	I-Method
(	O
78.2	O
%	O
mAP	B-Metric
)	O
.	O
	
We	O
note	O
that	O
MR	B-Method
-	I-Method
CNN	I-Method
uses	O
selective	O
search	O
and	O
edge	O
boxes	O
during	O
training	O
,	O
whereas	O
we	O
only	O
use	O
selective	O
search	O
boxes	O
.	O
	
Our	O
multi	B-Method
-	I-Method
scale	I-Method
implementation	O
is	O
also	O
different	O
,	O
using	O
fewer	O
scales	O
than	O
MR	B-Method
-	I-Method
CNN	I-Method
.	O
	
On	O
VOC12	B-Material
	
(	O
Table	O
[	O
reference	O
]	O
)	O
	
,	O
we	O
consistently	O
perform	O
better	O
than	O
MR	B-Method
-	I-Method
CNN	I-Method
.	O
	
When	O
using	O
extra	O
data	O
,	O
we	O
achieve	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
mAP	B-Metric
of	O
76.3	O
%	O
(	O
73.9	O
%	O
mAP	B-Metric
of	O
MR	B-Method
-	I-Method
CNN	I-Method
)	O
.	O
	
paragraph	O
:	O
Ablation	B-Method
analysis	I-Method
.	O
	
We	O
now	O
study	O
in	O
detail	O
the	O
impact	O
of	O
these	O
two	O
additions	O
and	O
whether	O
OHEM	B-Method
is	O
complementary	O
to	O
them	O
,	O
and	O
report	O
the	O
analysis	O
in	O
Table	O
[	O
reference	O
]	O
.	O
	
Baseline	B-Metric
FRCN	I-Metric
mAP	I-Metric
improves	O
from	O
67.2	O
%	O
to	O
68.6	O
%	O
when	O
using	O
multi	B-Method
-	I-Method
scale	I-Method
during	O
both	O
training	O
and	O
testing	B-Task
(	O
we	O
refer	O
to	O
this	O
as	O
M	O
)	O
.	O
	
However	O
,	O
note	O
that	O
there	O
is	O
only	O
a	O
marginal	O
benefit	O
of	O
using	O
it	O
at	O
training	O
time	O
.	O
	
Iterative	B-Method
bbox	I-Method
regression	I-Method
(	O
B	O
)	O
further	O
improves	O
the	O
FRCN	B-Method
mAP	I-Metric
to	O
72.4	O
%	O
.	O
	
But	O
more	O
importantly	O
,	O
using	O
OHEM	B-Method
improves	O
it	O
to	O
75.1	O
%	O
mAP	B-Metric
,	O
which	O
is	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
for	O
methods	O
trained	O
on	O
VOC07	B-Material
data	I-Material
(	O
see	O
Table	O
[	O
reference	O
]	O
)	O
.	O
	
In	O
fact	O
,	O
using	O
OHEM	B-Method
consistently	O
results	O
in	O
higher	O
mAP	B-Metric
for	O
all	O
variants	O
of	O
these	O
two	O
additions	O
(	O
see	O
Table	O
[	O
reference	O
]	O
)	O
.	O
	
Iterative	B-Method
bbox	I-Method
reg	I-Method
.	O
	
(	O
B	O
)	O
	
subsection	O
:	O
MS	B-Material
COCO	I-Material
results	O
	
MS	B-Material
COCO	I-Material
test	I-Material
-	I-Material
dev	I-Material
2015	I-Material
evaluation	O
server	O
results	O
are	O
reported	O
in	O
Table	O
[	O
reference	O
]	O
.	O
	
Using	O
multi	B-Method
-	I-Method
scale	I-Method
improves	O
the	O
performance	O
of	O
our	O
method	O
to	O
24.4	O
%	O
AP	B-Metric
on	O
the	O
standard	O
COCO	B-Metric
metric	I-Metric
and	O
to	O
44.4	O
%	O
AP	B-Metric
on	O
the	O
VOC	B-Material
metric	O
.	O
	
This	O
again	O
shows	O
the	O
complementary	O
nature	O
of	O
using	O
multi	B-Method
-	I-Method
scale	I-Method
and	O
OHEM	B-Method
.	O
	
Finally	O
,	O
we	O
train	O
our	O
method	O
using	O
the	O
entire	O
MS	B-Material
COCO	I-Material
trainval	O
set	O
,	O
which	O
further	O
improves	O
performance	O
to	O
25.5	O
%	O
AP	B-Metric
(	O
and	O
45.9	O
%	O
AP	B-Metric
)	O
.	O
	
In	O
the	O
2015	O
MS	B-Material
COCO	I-Material
Detection	O
Challenge	O
,	O
a	O
variant	O
of	O
this	O
approach	O
finished	O
place	O
overall	O
.	O
	
section	O
:	O
Conclusion	O
	
We	O
presented	O
an	O
online	B-Method
hard	I-Method
example	I-Method
mining	I-Method
(	O
OHEM	B-Method
)	O
algorithm	O
,	O
a	O
simple	O
and	O
effective	O
method	O
to	O
train	O
region	B-Method
-	I-Method
based	I-Method
ConvNet	I-Method
detectors	I-Method
.	O
	
OHEM	B-Method
eliminates	O
several	O
heuristics	O
and	O
hyperparameters	O
in	O
common	O
use	O
by	O
automatically	O
selecting	O
hard	O
examples	O
,	O
thus	O
simplifying	O
training	B-Task
.	O
	
We	O
conducted	O
extensive	O
experimental	O
analysis	O
to	O
demonstrate	O
the	O
effectiveness	O
of	O
the	O
proposed	O
algorithm	O
,	O
which	O
leads	O
to	O
better	O
training	B-Metric
convergence	I-Metric
and	O
consistent	O
improvements	O
in	O
detection	B-Metric
accuracy	I-Metric
on	O
standard	O
benchmarks	O
.	O
	
We	O
also	O
reported	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
results	O
on	O
PASCAL	B-Material
VOC	I-Material
2007	I-Material
and	O
2012	B-Material
when	O
using	O
OHEM	B-Method
with	O
other	O
orthogonal	B-Method
additions	I-Method
.	O
	
Though	O
we	O
used	O
Fast	B-Method
R	I-Method
-	I-Method
CNN	I-Method
throughout	O
this	O
paper	O
,	O
OHEM	B-Method
can	O
be	O
used	O
for	O
training	O
any	O
region	B-Method
-	I-Method
based	I-Method
ConvNet	I-Method
detector	I-Method
.	O
	
Our	O
experimental	O
analysis	O
was	O
based	O
on	O
the	O
overall	B-Metric
detection	I-Metric
accuracy	I-Metric
,	O
however	O
it	O
will	O
be	O
an	O
interesting	O
future	O
direction	O
to	O
study	O
the	O
impact	O
of	O
various	O
training	B-Method
methodologies	I-Method
on	O
individual	O
category	O
performance	O
.	O
	
paragraph	O
:	O
Acknowledgment	O
.	O
	
This	O
project	O
started	O
as	O
an	O
intern	O
project	O
at	O
Microsoft	O
Research	O
and	O
continued	O
at	O
CMU	O
.	O
	
We	O
thank	O
Larry	O
Zitnick	O
,	O
Ishan	O
Misra	O
and	O
Sean	O
Bell	O
for	O
many	O
helpful	O
discussions	O
.	O
	
AS	O
was	O
supported	O
by	O
the	O
Microsoft	O
Research	O
PhD	O
Fellowship	O
.	O
	
This	O
work	O
was	O
also	O
partially	O
supported	O
by	O
ONR	O
MURI	O
N000141612007	O
.	O
	
We	O
thank	O
NVIDIA	O
for	O
donating	O
GPUs	O
.	O
	
bibliography	O
:	O
References	O
	
document	O
:	O
The	O
Microsoft	O
2016	O
Conversational	B-Method
Speech	I-Method
Recognition	I-Method
System	I-Method
	
We	O
describe	O
Microsoft	B-Method
’s	I-Method
conversational	I-Method
speech	I-Method
recognition	I-Method
system	I-Method
,	O
in	O
which	O
we	O
combine	O
recent	O
developments	O
in	O
neural	B-Method
-	I-Method
network	I-Method
-	I-Method
based	I-Method
acoustic	I-Method
and	I-Method
language	I-Method
modeling	I-Method
to	O
advance	O
the	O
state	O
of	O
the	O
art	O
on	O
the	O
Switchboard	B-Material
recognition	O
task	O
.	O
	
Inspired	O
by	O
machine	B-Method
learning	I-Method
ensemble	I-Method
techniques	I-Method
,	O
the	O
system	O
uses	O
a	O
range	O
of	O
convolutional	B-Method
and	I-Method
recurrent	I-Method
neural	I-Method
networks	I-Method
.	O
	
I	B-Method
-	I-Method
vector	I-Method
modeling	I-Method
and	O
lattice	B-Method
-	I-Method
free	I-Method
MMI	I-Method
training	I-Method
provide	O
significant	O
gains	O
for	O
all	O
acoustic	B-Method
model	I-Method
architectures	I-Method
.	O
	
Language	B-Method
model	I-Method
rescoring	I-Method
with	O
multiple	O
forward	B-Method
and	I-Method
backward	I-Method
running	I-Method
RNNLMs	I-Method
,	O
and	O
word	B-Method
posterior	I-Method
-	I-Method
based	I-Method
system	I-Method
combination	I-Method
provide	O
a	O
20	O
%	O
boost	O
.	O
	
The	O
best	O
single	O
system	O
uses	O
a	O
ResNet	B-Method
architecture	I-Method
acoustic	I-Method
model	I-Method
with	O
RNNLM	B-Method
rescoring	I-Method
,	O
and	O
achieves	O
a	O
word	B-Metric
error	I-Metric
rate	I-Metric
of	O
6.9	O
%	O
on	O
the	O
NIST	O
2000	O
Switchboard	B-Material
task	O
.	O
	
The	O
combined	O
system	O
has	O
an	O
error	B-Metric
rate	I-Metric
of	O
6.2	O
%	O
,	O
representing	O
an	O
improvement	O
over	O
previously	O
reported	O
results	O
on	O
this	O
benchmark	O
task	O
.	O
	
W.Xiong	O
,	O
J.Droppo	O
,	O
X.Huang	O
,	O
F.Seide	O
,	O
M.Seltzer	O
,	O
A.Stolcke	O
,	O
	
D.YuandG.Zweig	O
MicrosoftResearch	B-Task
Conversational	I-Task
speech	I-Task
recognition	I-Task
,	O
convolutional	B-Method
neural	I-Method
networks	I-Method
,	O
recurrent	B-Method
neural	I-Method
networks	I-Method
,	O
VGG	B-Method
,	O
ResNet	B-Method
,	O
LACE	B-Method
,	O
BLSTM	B-Method
.	O
	
section	O
:	O
Introduction	O
	
Recent	O
years	O
have	O
seen	O
a	O
rapid	O
reduction	O
in	O
speech	B-Metric
recognition	I-Metric
error	I-Metric
rates	I-Metric
as	O
a	O
result	O
of	O
careful	O
engineering	O
and	O
optimization	B-Method
of	I-Method
convolutional	I-Method
and	I-Method
recurrent	I-Method
neural	I-Method
networks	I-Method
.	O
	
While	O
the	O
basic	O
structures	O
have	O
been	O
well	O
known	O
for	O
a	O
long	O
period	O
,	O
it	O
is	O
only	O
recently	O
that	O
they	O
have	O
dominated	O
the	O
field	O
as	O
the	O
best	O
models	O
for	O
speech	B-Task
recognition	I-Task
.	O
	
Surprisingly	O
,	O
this	O
is	O
the	O
case	O
for	O
both	O
acoustic	B-Task
modeling	I-Task
and	O
language	B-Task
modeling	I-Task
.	O
	
In	O
comparison	O
to	O
standard	O
feed	B-Method
-	I-Method
forward	I-Method
MLPs	I-Method
or	O
DNNs	B-Method
,	O
these	O
acoustic	B-Method
models	I-Method
have	O
the	O
ability	O
to	O
model	O
a	O
large	O
amount	O
of	O
acoustic	O
context	O
with	O
temporal	O
invariance	O
,	O
and	O
in	O
the	O
case	O
of	O
convolutional	B-Method
models	I-Method
,	O
with	O
frequency	O
invariance	O
as	O
well	O
.	O
	
In	O
language	B-Task
modeling	I-Task
,	O
recurrent	B-Method
models	I-Method
appear	O
to	O
improve	O
over	O
classical	O
N	B-Method
-	I-Method
gram	I-Method
models	I-Method
through	O
the	O
generalization	B-Method
ability	I-Method
of	O
continuous	B-Method
word	I-Method
representations	I-Method
.	O
	
In	O
the	O
meantime	O
,	O
ensemble	B-Method
learning	I-Method
has	O
become	O
commonly	O
used	O
in	O
several	O
neural	B-Method
models	I-Method
,	O
to	O
improve	O
robustness	B-Metric
by	O
reducing	O
bias	B-Metric
and	I-Metric
variance	I-Metric
.	O
	
In	O
this	O
paper	O
,	O
we	O
use	O
ensembles	B-Method
of	I-Method
models	I-Method
extensively	O
,	O
as	O
well	O
as	O
improvements	O
to	O
individual	O
component	B-Method
models	I-Method
,	O
to	O
to	O
advance	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
in	O
conversational	B-Task
telephone	I-Task
speech	I-Task
recognition	I-Task
(	O
CTS	B-Task
)	I-Task
,	O
which	O
has	O
been	O
a	O
benchmark	O
speech	B-Task
recognition	I-Task
task	I-Task
since	O
the	O
1990s	O
.	O
	
The	O
main	O
features	O
of	O
this	O
system	O
are	O
:	O
An	O
ensemble	O
of	O
two	O
fundamental	O
acoustic	B-Method
model	I-Method
architectures	I-Method
,	O
convolutional	B-Method
neural	I-Method
nets	I-Method
(	O
CNNs	B-Method
)	O
and	O
long	B-Method
-	I-Method
short	I-Method
-	I-Method
term	I-Method
memory	I-Method
nets	I-Method
(	O
LSTMs	B-Method
)	O
,	O
with	O
multiple	O
variants	O
of	O
each	O
An	O
attention	B-Method
mechanism	I-Method
in	O
the	O
LACE	B-Method
CNN	I-Method
which	O
differentially	O
weights	O
distant	B-Method
context	I-Method
Lattice	I-Method
-	I-Method
free	I-Method
MMI	I-Method
training	I-Method
The	O
use	O
of	O
i	B-Method
-	I-Method
vector	I-Method
based	I-Method
adaptation	I-Method
in	O
all	O
models	O
Language	B-Method
model	I-Method
(	I-Method
LM	I-Method
)	I-Method
rescoring	I-Method
with	O
multiple	O
,	O
recurrent	B-Method
neural	I-Method
net	I-Method
LMs	I-Method
running	O
in	O
both	O
forward	O
and	O
reverse	O
direction	O
Confusion	B-Method
network	I-Method
system	I-Method
combination	O
coupled	O
with	O
search	O
for	O
best	O
system	O
subset	O
,	O
as	O
necessitated	O
by	O
the	O
large	O
number	O
of	O
candidate	O
systems	O
.	O
	
The	O
remainder	O
of	O
this	O
paper	O
describes	O
our	O
system	O
in	O
detail	O
.	O
	
Section	O
[	O
reference	O
]	O
describes	O
the	O
CNN	B-Method
and	I-Method
LSTM	I-Method
models	I-Method
.	O
	
Section	O
[	O
reference	O
]	O
describes	O
our	O
implementation	O
of	O
i	B-Method
-	I-Method
vector	I-Method
adaptation	I-Method
.	O
	
Section	O
[	O
reference	O
]	O
presents	O
out	O
lattice	B-Method
-	I-Method
free	I-Method
MMI	I-Method
training	I-Method
process	I-Method
.	O
	
Language	B-Method
model	I-Method
rescoring	I-Method
is	O
a	O
significant	O
part	O
of	O
our	O
system	O
,	O
and	O
described	O
in	O
Section	O
[	O
reference	O
]	O
.	O
	
Experimental	O
results	O
are	O
presented	O
in	O
Section	O
[	O
reference	O
]	O
,	O
followed	O
by	O
a	O
discussion	O
of	O
related	O
work	O
and	O
conclusions	O
.	O
	
section	O
:	O
Convolutional	B-Method
and	I-Method
LSTM	I-Method
Neural	I-Method
Networks	I-Method
	
We	O
use	O
three	O
CNN	B-Method
variants	I-Method
.	O
	
The	O
first	O
is	O
the	O
VGG	B-Method
architecture	I-Method
of	O
.	O
	
Compared	O
to	O
the	O
networks	O
used	O
previously	O
in	O
image	B-Task
recognition	I-Task
,	O
this	O
network	O
uses	O
	
small	O
(	O
3x3	O
)	O
filters	O
,	O
is	O
deeper	O
,	O
and	O
applies	O
up	O
to	O
five	O
convolutional	B-Method
layers	I-Method
before	O
pooling	B-Method
.	O
	
The	O
second	O
network	O
is	O
modeled	O
on	O
the	O
ResNet	B-Method
architecture	I-Method
,	O
which	O
adds	O
highway	O
connections	O
,	O
i.e.	O
a	O
linear	O
transform	O
of	O
each	O
layer	O
’s	O
input	O
to	O
the	O
layer	O
’s	O
output	O
.	O
	
The	O
only	O
difference	O
is	O
that	O
we	O
move	O
the	O
Batch	O
Normalization	O
node	O
to	O
the	O
place	O
right	O
before	O
each	O
ReLU	O
activation	O
.	O
	
The	O
last	O
CNN	B-Method
variant	I-Method
is	O
the	O
LACE	B-Method
(	I-Method
layer	I-Method
-	I-Method
wise	I-Method
context	I-Method
expansion	I-Method
with	I-Method
attention	I-Method
)	I-Method
model	I-Method
.	O
	
LACE	B-Method
is	O
a	O
TDNN	B-Method
variant	I-Method
in	O
which	O
each	O
higher	O
layer	O
is	O
a	O
weighted	B-Method
sum	I-Method
of	I-Method
nonlinear	I-Method
transformations	I-Method
of	O
a	O
window	O
of	O
lower	O
layer	O
frames	O
.	O
	
In	O
other	O
words	O
,	O
each	O
higher	O
layer	O
exploits	O
broader	O
context	O
than	O
lower	O
layers	O
.	O
	
Lower	B-Method
layers	I-Method
focus	O
on	O
extracting	O
simple	O
local	O
patterns	O
while	O
higher	O
layers	O
extract	O
complex	O
patterns	O
that	O
cover	O
broader	O
contexts	O
.	O
	
Since	O
not	O
all	O
frames	O
in	O
a	O
window	O
carry	O
the	O
same	O
importance	O
,	O
an	O
attention	O
mask	O
is	O
applied	O
.	O
	
The	O
LACE	B-Method
model	I-Method
differs	O
from	O
the	O
earlier	O
TDNN	B-Method
models	I-Method
e.g.	O
in	O
the	O
use	O
of	O
a	O
learned	O
attention	O
mask	O
and	O
ResNet	O
like	O
linear	O
pass	O
-	O
through	O
.	O
	
As	O
illustrated	O
in	O
detail	O
in	O
Figure	O
[	O
reference	O
]	O
,	O
the	O
model	O
is	O
composed	O
of	O
4	O
blocks	O
,	O
each	O
with	O
the	O
same	O
architecture	O
.	O
	
Each	O
block	O
starts	O
with	O
a	O
convolution	B-Method
layer	I-Method
with	O
stride	O
2	O
which	O
sub	O
-	O
samples	O
the	O
input	O
and	O
increases	O
the	O
number	O
of	O
channels	O
.	O
	
This	O
layer	O
is	O
followed	O
by	O
4	O
RELU	B-Method
-	I-Method
convolution	I-Method
layers	I-Method
with	O
jump	O
links	O
similar	O
to	O
those	O
used	O
in	O
ResNet	B-Method
.	O
	
Table	O
[	O
reference	O
]	O
compares	O
the	O
layer	O
structure	O
and	O
parameters	O
of	O
the	O
three	O
CNN	B-Method
architectures	I-Method
.	O
	
While	O
our	O
best	O
performing	O
models	O
are	O
convolutional	B-Method
,	O
the	O
use	O
of	O
long	B-Method
short	I-Method
-	I-Method
term	I-Method
memory	I-Method
networks	I-Method
is	O
a	O
close	O
second	O
.	O
	
We	O
use	O
a	O
bidirectional	B-Method
architecture	I-Method
without	O
frame	B-Method
-	I-Method
skipping	I-Method
.	O
	
The	O
core	B-Method
model	I-Method
structure	I-Method
is	O
the	O
LSTM	B-Method
defined	O
in	O
.	O
	
We	O
found	O
that	O
using	O
networks	B-Method
with	O
more	O
than	O
six	O
layers	O
did	O
not	O
improve	O
the	O
word	B-Metric
error	I-Metric
rate	I-Metric
on	O
the	O
development	O
set	O
,	O
and	O
chose	O
512	O
hidden	O
units	O
,	O
per	O
direction	O
,	O
per	O
layer	O
,	O
as	O
that	O
provided	O
a	O
reasonable	O
trade	O
-	O
off	O
between	O
training	B-Metric
time	I-Metric
and	O
final	O
model	B-Metric
accuracy	I-Metric
.	O
	
Network	O
parameters	O
for	O
different	O
configurations	O
of	O
the	O
LSTM	B-Method
architecture	I-Method
are	O
summarized	O
in	O
Table	O
[	O
reference	O
]	O
.	O
	
section	O
:	O
Speaker	B-Method
Adaptive	I-Method
Modeling	I-Method
	
Speaker	B-Method
adaptive	I-Method
modeling	I-Method
in	O
our	O
system	O
is	O
based	O
on	O
conditioning	O
the	O
network	O
on	O
an	O
i	B-Method
-	I-Method
vector	I-Method
characterization	I-Method
of	O
each	O
speaker	O
.	O
	
A	O
100	O
-	O
dimensional	O
i	O
-	O
vector	O
is	O
generated	O
for	O
each	O
conversation	O
side	O
.	O
	
For	O
the	O
LSTM	B-Method
system	I-Method
,	O
the	O
conversation	O
-	O
side	O
i	O
-	O
vector	O
is	O
appended	O
to	O
each	O
frame	O
of	O
input	O
.	O
	
For	O
convolutional	B-Method
networks	I-Method
,	O
this	O
approach	O
is	O
inappropriate	O
because	O
we	O
do	O
not	O
expect	O
to	O
see	O
spatially	O
contiguous	O
patterns	O
in	O
the	O
input	O
.	O
	
Instead	O
,	O
for	O
the	O
CNNs	B-Method
,	O
we	O
add	O
a	O
learnable	O
weight	O
matrix	O
to	O
each	O
layer	O
,	O
and	O
add	O
to	O
the	O
activation	O
of	O
the	O
layer	O
before	O
the	O
nonlinearity	O
.	O
	
Thus	O
,	O
in	O
the	O
CNN	B-Method
,	O
the	O
i	O
-	O
vector	O
essentially	O
serves	O
as	O
an	O
additional	O
bias	O
to	O
each	O
layer	O
.	O
	
Note	O
that	O
the	O
i	O
-	O
vectors	O
are	O
estimated	O
using	O
MFCC	O
features	O
;	O
by	O
using	O
them	O
subsequently	O
in	O
systems	O
based	O
on	O
log	O
-	O
filterbank	O
features	O
,	O
we	O
may	O
benefit	O
from	O
a	O
form	O
of	O
feature	B-Method
combination	I-Method
.	O
	
section	O
:	O
Lattice	B-Method
-	I-Method
Free	I-Method
Sequence	I-Method
Training	I-Method
	
After	O
standard	O
cross	B-Method
-	I-Method
entropy	I-Method
training	I-Method
,	O
we	O
optimize	O
the	O
model	O
parameters	O
using	O
the	O
maximum	B-Metric
mutual	I-Metric
information	I-Metric
(	I-Metric
MMI	I-Metric
)	I-Metric
objective	I-Metric
function	I-Metric
.	O
	
Denoting	O
a	O
word	O
sequence	O
by	O
and	O
its	O
corresponding	O
acoustic	O
realization	O
by	O
,	O
the	O
training	B-Metric
criterion	I-Metric
is	O
As	O
noted	O
in	O
,	O
the	O
necessary	O
gradient	O
for	O
use	O
in	O
backpropagation	B-Method
is	O
a	O
simple	O
function	O
of	O
the	O
posterior	O
probability	O
of	O
a	O
particular	O
acoustic	O
model	O
state	O
at	O
a	O
given	O
time	O
,	O
as	O
computed	O
by	O
summing	O
over	O
all	O
possible	O
word	O
sequences	O
in	O
an	O
unconstrained	O
manner	O
.	O
	
As	O
first	O
done	O
in	O
,	O
and	O
more	O
recently	O
in	O
,	O
this	O
can	O
be	O
accomplished	O
with	O
a	O
straightforward	O
alpha	B-Method
-	I-Method
beta	I-Method
computation	I-Method
over	O
the	O
finite	B-Method
state	I-Method
acceptor	I-Method
representing	O
the	O
decoding	O
search	O
space	O
.	O
	
In	O
,	O
the	O
search	O
space	O
is	O
taken	O
to	O
be	O
an	O
acceptor	O
representing	O
the	O
composition	O
for	O
a	O
unigram	B-Method
language	I-Method
model	I-Method
on	O
words	O
.	O
	
In	O
,	O
a	O
language	B-Method
model	I-Method
on	O
phonemes	B-Method
is	O
used	O
instead	O
.	O
	
In	O
our	O
implementation	O
,	O
we	O
use	O
a	O
mixed	B-Method
-	I-Method
history	I-Method
acoustic	I-Method
unit	I-Method
language	I-Method
model	I-Method
.	O
	
In	O
this	O
model	O
,	O
the	O
probability	O
of	O
transitioning	O
into	O
a	O
new	O
context	O
-	O
dependent	O
phonetic	O
state	O
(	O
senone	O
)	O
is	O
conditioned	O
both	O
the	O
senone	O
and	O
phone	O
history	O
.	O
	
We	O
found	O
this	O
model	O
to	O
perform	O
better	O
than	O
either	O
purely	O
word	B-Method
-	I-Method
based	I-Method
or	I-Method
phone	I-Method
-	I-Method
based	I-Method
models	I-Method
.	O
	
Based	O
on	O
a	O
set	O
of	O
initial	O
experiments	O
,	O
we	O
developed	O
the	O
following	O
procedure	O
:	O
Perform	O
a	O
forced	B-Task
alignment	I-Task
of	O
the	O
training	O
data	O
to	O
select	O
lexical	O
variants	O
and	O
determine	O
frame	O
-	O
aligned	O
senone	O
sequences	O
.	O
	
Compress	O
consecutive	O
framewise	O
occurrences	O
of	O
a	O
single	O
senone	O
into	O
a	O
single	O
occurrence	O
.	O
	
Estimate	O
an	O
unsmoothed	B-Method
,	I-Method
variable	I-Method
-	I-Method
length	I-Method
N	I-Method
-	I-Method
gram	I-Method
language	I-Method
model	I-Method
from	O
this	O
data	O
,	O
where	O
the	O
history	O
state	O
consists	O
of	O
the	O
previous	O
phone	O
and	O
previous	O
senones	O
within	O
the	O
current	O
phone	O
.	O
	
To	O
illustrate	O
this	O
,	O
consider	O
the	O
sample	O
senone	O
sequence	O
{	O
s	O
	
_	O
s2.1288	O
,	O
	
s	O
_	O
s3.1061	O
,	O
s	O
_	O
s4.1096	O
}	O
,	O
{	O
eh	O
_	O
s2.527	O
,	O
eh	O
	
_	O
s3.128	O
,	O
eh	O
_	O
	
s4.66	O
}	O
,	O
{	O
t	O
_	O
s2.729	O
,	O
	
t	O
_	O
s3.572	O
,	O
	
t	O
_	O
s4.748}.	O
	
When	O
predicting	O
the	O
state	O
following	O
	
eh	O
_	O
s4.66	O
	
the	O
history	O
consists	O
of	O
(	O
s	O
,	O
eh	O
_	O
s2.527	O
,	O
eh	O
_	O
s3.128	O
,	O
eh	O
_	O
s4.66	O
)	O
,	O
and	O
following	O
t	O
_	O
s2.729	O
,	O
the	O
history	O
is	O
(	O
eh	O
,	O
t	O
_	O
s2.729	O
)	O
.	O
	
We	O
construct	O
the	O
denominator	O
graph	O
from	O
this	O
language	B-Method
model	I-Method
,	O
and	O
HMM	O
transition	O
probabilities	O
as	O
determined	O
by	O
transition	B-Method
-	I-Method
counting	I-Method
in	O
the	O
senone	O
sequences	O
found	O
in	O
the	O
training	O
data	O
.	O
	
Our	O
approach	O
not	O
only	O
largely	O
reduces	O
the	O
complexity	B-Metric
of	O
building	O
up	O
the	O
language	B-Method
model	I-Method
but	O
also	O
provides	O
very	O
reliable	O
training	O
performance	O
.	O
	
We	O
have	O
found	O
it	O
convenient	O
to	O
do	O
the	O
full	O
computation	O
,	O
without	O
pruning	O
,	O
in	O
a	O
series	O
of	O
matrix	B-Method
-	I-Method
vector	I-Method
operations	I-Method
on	O
the	O
GPU	O
.	O
	
The	O
underlying	O
acceptor	O
is	O
represented	O
with	O
a	O
sparse	O
matrix	O
,	O
and	O
we	O
maintain	O
a	O
dense	O
likelihood	O
vector	O
for	O
each	O
time	O
frame	O
.	O
	
The	O
alpha	B-Method
and	I-Method
beta	I-Method
recursions	I-Method
are	O
implemented	O
with	O
CUSPARSE	B-Method
level	I-Method
-	I-Method
2	I-Method
routines	I-Method
:	O
sparse	B-Method
-	I-Method
matrix	I-Method
,	O
dense	B-Method
vector	I-Method
multiplies	I-Method
.	O
	
Run	B-Metric
time	I-Metric
is	O
about	O
100	O
times	O
faster	O
than	O
real	O
time	O
.	O
	
As	O
in	O
,	O
we	O
use	O
cross	B-Method
-	I-Method
entropy	I-Method
regularization	I-Method
.	O
	
In	O
all	O
the	O
lattice	B-Method
-	I-Method
free	I-Method
MMI	I-Method
(	I-Method
LFMMI	I-Method
)	O
experiments	O
mentioned	O
below	O
we	O
use	O
a	O
trigram	B-Method
language	I-Method
model	I-Method
.	O
	
Most	O
of	O
the	O
gain	O
is	O
usually	O
obtained	O
after	O
processing	O
24	O
to	O
48	O
hours	O
of	O
data	O
.	O
	
section	O
:	O
LM	B-Task
Rescoring	I-Task
and	O
System	B-Task
Combination	I-Task
	
An	O
initial	O
decoding	B-Task
is	O
done	O
with	O
a	O
WFST	B-Method
decoder	I-Method
,	O
using	O
the	O
architecture	O
described	O
in	O
.	O
	
We	O
use	O
an	O
N	B-Method
-	I-Method
gram	I-Method
language	I-Method
model	I-Method
trained	O
and	O
pruned	O
with	O
the	O
SRILM	B-Method
toolkit	I-Method
.	O
	
The	O
first	B-Method
-	I-Method
pass	I-Method
LM	I-Method
has	O
approximately	O
15.9	O
million	O
bigrams	O
,	O
trigrams	O
,	O
and	O
4grams	O
,	O
and	O
a	O
vocabulary	O
of	O
30	O
,	O
500	O
words	O
.	O
	
It	O
gives	O
a	O
perplexity	O
of	O
69	O
on	O
the	O
1997	O
CTS	B-Material
evaluation	I-Material
transcripts	I-Material
.	O
	
The	O
initial	O
decoding	B-Method
produces	O
a	O
lattice	O
with	O
the	O
pronunciation	O
variants	O
marked	O
,	O
from	O
which	O
500	O
-	O
best	O
lists	O
are	O
generated	O
for	O
rescoring	B-Task
purposes	I-Task
.	O
	
Subsequent	O
N	B-Method
-	I-Method
best	I-Method
rescoring	I-Method
uses	O
an	O
unpruned	B-Method
LM	I-Method
comprising	O
145	O
million	O
N	O
-	O
grams	O
.	O
	
All	O
N	B-Method
-	I-Method
gram	I-Method
LMs	I-Method
were	O
estimated	O
by	O
a	O
maximum	B-Metric
entropy	I-Metric
criterion	I-Metric
as	O
described	O
in	O
.	O
	
subsection	O
:	O
RNNLM	B-Method
setup	I-Method
	
The	O
N	O
-	O
best	O
hypotheses	O
are	O
then	O
rescored	O
using	O
a	O
combination	O
of	O
the	O
large	B-Method
N	I-Method
-	I-Method
gram	I-Method
LM	I-Method
and	O
several	O
RNNLMs	B-Method
,	O
trained	O
and	O
evaluated	O
using	O
the	O
CUED	B-Method
-	I-Method
RNNLM	I-Method
toolkit	I-Method
.	O
	
Our	O
RNNLM	B-Method
configuration	I-Method
has	O
several	O
distinctive	O
features	O
,	O
as	O
described	O
below	O
.	O
	
1	O
)	O
	
We	O
trained	O
both	O
standard	O
,	O
forward	B-Method
-	I-Method
predicting	I-Method
RNNLMs	I-Method
and	O
backward	B-Method
RNNLMs	I-Method
that	O
predict	O
words	O
in	O
reverse	O
temporal	O
order	O
.	O
	
The	O
log	O
probabilities	O
from	O
both	O
models	O
are	O
added	O
.	O
	
2	O
)	O
	
As	O
is	O
customary	O
,	O
the	O
RNNLM	B-Method
probability	I-Method
estimates	I-Method
are	O
interpolated	O
at	O
the	O
word	O
-	O
level	O
with	O
corresponding	O
N	O
-	O
gram	O
LM	O
probabilities	O
(	O
separately	O
for	O
the	O
forward	B-Method
and	I-Method
backward	I-Method
models	I-Method
)	O
.	O
	
In	O
addition	O
,	O
we	O
trained	O
a	O
second	O
RNNLM	B-Method
for	O
each	O
direction	O
,	O
obtained	O
by	O
starting	O
with	O
different	O
random	O
initial	O
weights	O
.	O
	
The	O
two	O
RNNLMs	B-Method
and	O
the	O
N	B-Method
-	I-Method
gram	I-Method
LM	I-Method
for	O
each	O
direction	O
are	O
interpolated	O
with	O
weights	O
of	O
(	O
0.375	O
,	O
0.375	O
,	O
0.25	O
)	O
.	O
	
3	O
)	O
	
In	O
order	O
to	O
make	O
use	O
of	O
LM	B-Material
training	I-Material
data	I-Material
that	O
is	O
not	O
fully	O
matched	O
to	O
the	O
target	O
conversational	O
speech	O
domain	O
,	O
we	O
start	O
RNNLM	B-Method
training	I-Method
with	O
the	O
union	O
of	O
in	O
-	O
domain	O
(	O
here	O
,	O
CTS	B-Material
)	O
and	O
out	O
-	O
of	O
-	O
domain	O
(	O
e.g.	O
,	O
Web	B-Material
)	O
data	O
.	O
	
Upon	O
convergence	O
,	O
the	O
network	O
undergoes	O
a	O
second	O
training	B-Method
phase	I-Method
using	O
the	O
in	O
-	O
domain	O
data	O
only	O
.	O
	
Both	O
training	O
phases	O
use	O
in	O
-	O
domain	O
validation	O
data	O
to	O
regulate	O
the	O
learning	B-Metric
rate	I-Metric
schedule	I-Metric
and	O
termination	B-Task
.	O
	
Because	O
the	O
size	O
of	O
the	O
out	O
-	O
of	O
-	O
domain	O
data	O
is	O
a	O
multiple	O
of	O
the	O
in	O
-	O
domain	O
data	O
,	O
a	O
standard	O
training	O
on	O
a	O
simple	O
union	O
of	O
the	O
data	O
would	O
not	O
yield	O
a	O
well	O
-	O
matched	B-Method
model	I-Method
,	O
and	O
have	O
poor	O
perplexity	O
in	O
the	O
target	O
domain	O
.	O
	
4	O
)	O
We	O
found	O
best	O
results	O
with	O
an	O
RNNLM	B-Method
configuration	I-Method
that	O
had	O
a	O
second	O
,	O
non	B-Method
-	I-Method
recurrent	I-Method
hidden	I-Method
layer	I-Method
.	O
	
This	O
produced	O
lower	O
perplexity	B-Metric
and	O
word	B-Metric
error	I-Metric
than	O
the	O
standard	O
,	O
single	B-Method
-	I-Method
hidden	I-Method
-	I-Method
layer	I-Method
RNNLM	I-Method
architecture	I-Method
.	O
	
The	O
overall	O
network	B-Method
architecture	I-Method
thus	O
had	O
two	O
hidden	O
layers	O
with	O
1000	O
units	O
each	O
,	O
using	O
ReLU	B-Method
nonlinearities	I-Method
.	O
	
Training	B-Method
used	O
noise	B-Method
-	I-Method
contrastive	I-Method
estimation	I-Method
(	O
NCE	B-Method
)	O
.	O
	
5	O
)	O
	
The	O
RNNLM	B-Material
output	I-Material
vocabulary	I-Material
consists	O
of	O
all	O
words	O
occurring	O
more	O
than	O
once	O
in	O
the	O
in	O
-	O
domain	O
training	O
set	O
.	O
	
While	O
the	O
RNNLM	B-Method
estimates	O
a	O
probability	O
for	O
unknown	O
words	O
,	O
we	O
take	O
a	O
different	O
approach	O
in	O
rescoring	B-Task
:	O
The	O
number	O
of	O
out	O
-	O
of	O
-	O
set	O
words	O
is	O
recorded	O
for	O
each	O
hypothesis	O
and	O
a	O
penalty	O
for	O
them	O
is	O
estimated	O
for	O
them	O
when	O
optimizing	O
the	O
relative	O
weights	O
for	O
all	O
model	O
scores	O
(	O
acoustic	O
,	O
LM	O
,	O
pronunciation	O
)	O
,	O
using	O
the	O
SRILM	B-Method
nbest	I-Method
-	I-Method
optimize	I-Method
tool	I-Method
.	O
	
subsection	O
:	O
Training	O
data	O
	
The	O
4	B-Method
-	I-Method
gram	I-Method
language	I-Method
model	I-Method
for	O
decoding	B-Task
was	O
trained	O
on	O
the	O
available	O
CTS	B-Material
transcripts	I-Material
from	O
the	O
DARPA	B-Material
EARS	I-Material
program	I-Material
:	O
Switchboard	B-Material
(	O
3	O
M	O
words	O
)	O
,	O
BBN	O
Switchboard	B-Material
-	O
2	O
transcripts	O
(	O
850k	O
)	O
,	O
Fisher	B-Material
(	O
21	O
M	O
)	O
,	O
English	O
CallHome	B-Material
(	O
200k	O
)	O
,	O
and	O
the	O
University	O
of	O
Washington	O
conversational	O
Web	B-Material
corpus	O
(	O
191	O
M	O
)	O
.	O
	
A	O
separate	O
model	O
was	O
trained	O
from	O
each	O
source	O
and	O
interpolated	O
with	O
weights	O
optimized	O
on	O
RT	B-Material
-	I-Material
03	I-Material
transcripts	I-Material
.	O
	
For	O
the	O
unpruned	B-Task
large	I-Task
rescoring	I-Task
4	I-Task
-	I-Task
gram	I-Task
,	O
an	O
additional	O
LM	B-Method
component	I-Method
was	O
added	O
,	O
trained	O
on	O
133	O
M	O
word	O
of	O
LDC	B-Material
Broadcast	I-Material
News	I-Material
texts	I-Material
.	O
	
The	O
N	B-Method
-	I-Method
gram	I-Method
LM	I-Method
configuration	I-Method
is	O
modeled	O
after	O
that	O
described	O
in	O
,	O
except	O
that	O
maxent	B-Method
smoothing	I-Method
was	O
used	O
.	O
	
The	O
RNNLMs	B-Method
were	O
trained	O
on	O
Switchboard	B-Material
and	O
Fisher	B-Material
transcripts	O
as	O
in	O
-	O
domain	O
data	O
(	O
20	O
M	O
words	O
for	O
gradient	B-Task
computation	I-Task
,	O
3	O
M	O
for	O
validation	B-Task
)	O
.	O
	
To	O
this	O
we	O
added	O
62	O
M	O
words	O
of	O
UW	O
Web	B-Material
data	O
as	O
out	O
-	O
of	O
-	O
domain	O
data	O
,	O
for	O
use	O
in	O
the	O
two	O
-	O
phase	O
training	B-Method
procedure	I-Method
described	O
above	O
.	O
	
subsection	O
:	O
RNNLM	B-Method
performance	O
	
Table	O
[	O
reference	O
]	O
gives	O
perplexity	B-Metric
and	O
word	B-Metric
error	I-Metric
performance	I-Metric
for	O
various	O
RNNLM	B-Method
setups	I-Method
,	O
from	O
simple	O
to	O
more	O
complex	O
.	O
	
The	O
acoustic	B-Method
model	I-Method
used	O
was	O
the	O
ResNet	B-Method
CNN	I-Method
.	O
	
As	O
can	O
be	O
seen	O
,	O
each	O
of	O
the	O
measures	O
described	O
earlier	O
adds	O
incremental	O
gains	O
,	O
which	O
,	O
while	O
small	O
individually	O
,	O
add	O
up	O
to	O
a	O
9	O
%	O
relative	B-Metric
error	I-Metric
reduction	I-Metric
over	O
a	O
plain	O
RNNLM	B-Method
.	O
	
subsection	O
:	O
System	O
Combination	O
	
The	O
LM	B-Method
rescoring	I-Method
is	O
carried	O
out	O
separately	O
for	O
each	O
acoustic	B-Method
model	I-Method
.	O
	
The	O
rescored	O
N	O
-	O
best	O
lists	O
from	O
each	O
subsystem	O
are	O
then	O
aligned	O
into	O
a	O
single	O
confusion	B-Method
network	I-Method
using	O
the	O
SRILM	B-Method
nbest	I-Method
-	I-Method
rover	I-Method
tool	I-Method
.	O
	
However	O
,	O
the	O
number	O
of	O
potential	O
candidate	O
systems	O
is	O
too	O
large	O
to	O
allow	O
an	O
all	O
-	O
out	O
combination	O
,	O
both	O
for	O
practical	O
reasons	O
and	O
due	O
to	O
overfitting	B-Task
issues	I-Task
.	O
	
Instead	O
,	O
we	O
perform	O
a	O
greedy	B-Method
search	I-Method
,	O
starting	O
with	O
the	O
single	O
best	O
system	O
,	O
and	O
successively	O
adding	O
additional	O
systems	O
,	O
to	O
find	O
a	O
small	O
set	O
of	O
systems	O
that	O
are	O
maximally	O
complementary	O
.	O
	
The	O
RT	O
-	O
02	O
Switchboard	B-Material
set	O
was	O
used	O
for	O
this	O
search	B-Method
procedure	I-Method
.	O
	
The	O
relative	O
weighting	O
(	O
for	O
confusion	B-Task
-	I-Task
network	I-Task
mediated	I-Task
voting	I-Task
)	O
of	O
the	O
different	O
systems	O
is	O
optimized	O
using	O
an	O
EM	B-Method
algorithm	I-Method
,	O
using	O
the	O
same	O
data	O
,	O
and	O
smoothed	O
hierarchically	O
by	O
interpolating	O
each	O
set	O
of	O
system	O
weights	O
with	O
the	O
preceding	O
one	O
in	O
the	O
search	O
.	O
	
section	O
:	O
Experimental	O
Setup	O
and	O
Results	O
	
subsection	O
:	O
Speech	B-Material
corpora	I-Material
	
We	O
train	O
with	O
the	O
commonly	O
used	O
English	B-Material
CTS	I-Material
(	O
Switchboard	B-Material
and	O
Fisher	B-Material
)	O
corpora	O
.	O
	
Evaluation	O
is	O
carried	O
out	O
on	O
the	O
NIST	B-Material
2000	I-Material
CTS	I-Material
test	I-Material
set	I-Material
,	O
which	O
comprises	O
both	O
Switchboard	B-Material
(	O
SWB	B-Material
)	O
and	O
CallHome	B-Material
(	O
CH	B-Material
)	O
subsets	O
.	O
	
The	O
Switchboard	B-Material
-	O
1	O
portion	O
of	O
the	O
NIST	B-Material
2002	I-Material
CTS	I-Material
test	I-Material
set	I-Material
was	O
used	O
for	O
tuning	B-Task
and	O
development	B-Task
.	O
	
The	O
acoustic	B-Material
training	I-Material
data	I-Material
is	O
comprised	O
by	O
LDC	B-Material
corpora	I-Material
97S62	O
,	O
2004S13	O
,	O
2005S13	O
,	O
2004S11	O
and	O
2004S09	O
;	O
see	O
for	O
a	O
full	O
description	O
.	O
	
subsection	O
:	O
1	B-Method
-	I-Method
bit	I-Method
SGD	I-Method
Training	I-Method
	
All	O
presented	O
models	O
are	O
costly	O
to	O
train	O
.	O
	
To	O
make	O
training	O
feasible	O
,	O
we	O
parallelize	B-Task
training	I-Task
with	O
our	O
previously	O
proposed	O
1	B-Method
-	I-Method
bit	I-Method
SGD	I-Method
parallelization	I-Method
technique	I-Method
.	O
	
This	O
data	B-Method
-	I-Method
parallel	I-Method
method	I-Method
distributes	O
minibatches	B-Method
over	O
multiple	O
worker	O
nodes	O
,	O
and	O
then	O
aggregates	O
the	O
sub	O
-	O
gradients	O
.	O
	
While	O
the	O
necessary	O
communication	B-Metric
time	I-Metric
would	O
otherwise	O
be	O
prohibitive	O
,	O
the	O
1	B-Method
-	I-Method
bit	I-Method
SGD	I-Method
method	I-Method
eliminates	O
the	O
bottleneck	O
by	O
two	O
techniques	O
:	O
1	B-Method
-	I-Method
bit	I-Method
quantization	I-Method
of	I-Method
gradients	I-Method
and	O
automatic	B-Method
minibatch	I-Method
-	I-Method
size	I-Method
scaling	I-Method
.	O
	
In	O
,	O
we	O
showed	O
that	O
gradient	O
values	O
can	O
be	O
quantized	O
to	O
just	O
a	O
single	O
bit	O
,	O
if	O
one	O
carries	O
over	O
the	O
quantization	O
error	O
from	O
one	O
minibatch	O
to	O
the	O
next	O
.	O
	
Each	O
time	O
a	O
sub	O
-	O
gradient	O
is	O
quantized	O
,	O
the	O
quantization	O
error	O
is	O
computed	O
and	O
remembered	O
,	O
and	O
then	O
added	O
to	O
the	O
next	O
minibatch	O
’s	O
sub	O
-	O
gradient	O
.	O
	
This	O
reduces	O
the	O
required	O
bandwidth	O
32	O
-	O
fold	O
with	O
minimal	O
loss	O
in	O
accuracy	B-Metric
.	O
	
Secondly	O
,	O
automatic	B-Method
minibatch	I-Method
-	I-Method
size	I-Method
scaling	I-Method
progressively	O
decreases	O
the	O
frequency	O
of	O
model	B-Method
updates	I-Method
.	O
	
At	O
regular	O
intervals	O
(	O
e.g.	O
every	O
72h	O
of	O
training	O
data	O
)	O
,	O
the	O
trainer	O
tries	O
larger	O
minibatch	O
sizes	O
on	O
a	O
small	O
subset	O
of	O
data	O
and	O
picks	O
the	O
largest	O
that	O
maintains	O
training	O
loss	O
.	O
	
subsection	O
:	O
Acoustic	B-Method
Model	I-Method
Details	O
	
Forty	O
-	O
dimensional	O
log	O
-	O
filterbank	O
features	O
were	O
extracted	O
every	O
10	O
milliseconds	O
,	O
using	O
a	O
25	O
-	O
millisecond	O
analysis	O
window	O
.	O
	
The	O
CNN	B-Method
models	I-Method
used	O
window	O
sizes	O
as	O
indicated	O
in	O
Table	O
[	O
reference	O
]	O
,	O
and	O
the	O
LSTMs	B-Method
processed	O
one	O
frame	O
of	O
input	O
at	O
a	O
time	O
.	O
	
The	O
bulk	O
of	O
our	O
models	O
use	O
three	O
state	B-Method
left	I-Method
-	I-Method
to	I-Method
-	I-Method
right	I-Method
triphone	I-Method
models	I-Method
with	O
9000	O
tied	O
states	O
.	O
	
Additionally	O
,	O
we	O
have	O
trained	O
several	O
models	O
with	O
27k	O
tied	O
states	O
.	O
	
The	O
phonetic	O
inventory	O
includes	O
special	O
models	O
for	O
noise	O
,	O
vocalized	O
-	O
noise	O
,	O
laughter	O
and	O
silence	O
.	O
	
We	O
use	O
a	O
30k	O
-	O
vocabulary	O
derived	O
from	O
the	O
most	O
common	O
words	O
in	O
the	O
Switchboard	B-Material
and	O
Fisher	B-Material
corpora	I-Material
.	O
	
The	O
decoder	B-Method
uses	O
a	O
statically	O
compiled	O
unigram	O
graph	O
,	O
and	O
dynamically	O
applies	O
the	O
language	B-Method
model	I-Method
score	I-Method
.	O
	
The	O
unigram	B-Method
graph	I-Method
has	O
about	O
300k	O
states	O
and	O
500k	O
arcs	O
.	O
	
All	O
acoustic	B-Method
models	I-Method
were	O
trained	O
using	O
the	O
open	B-Method
-	I-Method
source	I-Method
Computational	I-Method
Network	I-Method
Toolkit	I-Method
(	O
CNTK	B-Method
)	O
.	O
	
Table	O
[	O
reference	O
]	O
shows	O
the	O
result	O
of	O
i	B-Method
-	I-Method
vector	I-Method
adaptation	I-Method
and	O
LFMMI	B-Method
training	I-Method
on	O
several	O
of	O
our	O
systems	O
.	O
	
We	O
achieve	O
a	O
5–8	O
%	O
relative	O
improvement	O
from	O
i	B-Metric
-	I-Metric
vectors	I-Metric
,	O
including	O
on	O
CNN	B-Method
systems	I-Method
.	O
	
The	O
last	O
row	O
of	O
Table	O
[	O
reference	O
]	O
shows	O
the	O
effect	O
of	O
LFMMI	B-Method
training	I-Method
on	O
the	O
different	O
models	O
.	O
	
We	O
see	O
a	O
consistent	O
7–10	O
%	O
further	O
relative	O
reduction	O
in	O
error	B-Metric
rate	I-Metric
for	O
all	O
models	O
.	O
	
Considering	O
the	O
great	O
increase	O
in	O
procedural	B-Metric
simplicity	I-Metric
of	O
LFMMI	B-Method
over	O
the	O
previous	O
practice	O
of	O
writing	B-Task
lattices	I-Task
and	O
post	O
-	O
processing	O
them	O
,	O
we	O
consider	O
LFMMI	B-Method
to	O
be	O
a	O
significant	O
advance	O
in	O
technology	O
.	O
	
subsection	O
:	O
Comparative	O
System	O
Performance	O
	
Model	O
performance	O
for	O
our	O
individual	O
models	O
as	O
well	O
as	O
relevant	O
comparisons	O
from	O
the	O
literature	O
are	O
shown	O
in	O
Table	O
[	O
reference	O
]	O
.	O
	
Out	O
of	O
the	O
15	O
models	O
built	O
,	O
only	O
models	O
given	O
non	O
-	O
zero	O
weight	O
in	O
the	O
final	O
system	O
combination	O
are	O
shown	O
.	O
	
section	O
:	O
Relation	O
to	O
Prior	O
Work	O
	
Compared	O
to	O
earlier	O
applications	O
of	O
CNNs	B-Method
to	O
speech	B-Task
recognition	I-Task
,	O
our	O
networks	O
are	O
much	O
deeper	O
,	O
and	O
use	O
linear	O
bypass	O
connections	O
across	O
convolutional	B-Method
layers	I-Method
.	O
	
They	O
are	O
similar	O
in	O
spirit	O
to	O
those	O
studied	O
more	O
recently	O
by	O
.	O
	
We	O
improve	O
on	O
these	O
architectures	O
with	O
the	O
LACE	B-Method
model	I-Method
,	O
which	O
iteratively	O
expands	O
the	O
effective	O
window	O
size	O
,	O
layer	O
-	O
by	O
-	O
layer	O
,	O
and	O
adds	O
an	O
attention	O
mask	O
to	O
differentially	O
weight	O
distant	O
context	O
.	O
	
Our	O
use	O
of	O
lattice	B-Method
-	I-Method
free	I-Method
MMI	I-Method
is	O
distinctive	O
,	O
and	O
extends	O
previous	O
work	O
by	O
proposing	O
the	O
use	O
of	O
a	O
mixed	O
triphone	O
/	O
phoneme	O
history	O
in	O
the	O
language	B-Method
model	I-Method
.	O
	
On	O
the	O
language	B-Task
modeling	I-Task
side	I-Task
,	O
we	O
achieve	O
a	O
performance	O
boost	O
by	O
combining	O
multiple	O
RNNLMs	B-Method
in	O
both	O
forward	O
and	O
backward	O
directions	O
,	O
and	O
by	O
using	O
a	O
two	O
-	O
phase	B-Method
training	I-Method
regimen	I-Method
to	O
get	O
best	O
results	O
from	O
out	O
-	O
of	O
-	O
domain	O
data	O
.	O
	
For	O
our	O
best	O
CNN	B-Method
system	I-Method
,	O
RNNLM	B-Method
rescoring	I-Method
yields	O
a	O
relative	B-Metric
word	I-Metric
error	I-Metric
reduction	I-Metric
of	O
20	O
%	O
,	O
and	O
a	O
16	O
%	O
relative	O
gain	O
for	O
the	O
combined	O
recognition	B-Method
system	I-Method
.	O
	
(	O
Elsewhere	O
we	O
report	O
further	O
improvements	O
,	O
using	O
LSTM	B-Method
-	I-Method
based	I-Method
LMs	I-Method
.	O
)	O
	
section	O
:	O
Conclusions	O
	
We	O
have	O
described	O
Microsoft	B-Method
’s	I-Method
conversational	I-Method
speech	I-Method
recognition	I-Method
system	I-Method
for	O
2016	O
.	O
	
The	O
use	O
of	O
CNNs	B-Method
in	O
the	O
acoustic	B-Method
model	I-Method
has	O
proved	O
singularly	O
effective	O
,	O
as	O
has	O
the	O
use	O
of	O
RNN	B-Method
language	I-Method
models	I-Method
.	O
	
Our	O
best	O
single	O
system	O
achieves	O
an	O
error	B-Metric
rate	I-Metric
of	O
6.9	O
%	O
on	O
the	O
NIST	O
2000	O
Switchboard	B-Material
set	O
.	O
	
We	O
believe	O
this	O
is	O
the	O
best	O
performance	O
reported	O
to	O
date	O
for	O
a	O
recognition	B-Method
system	I-Method
not	O
based	O
on	O
system	B-Method
combination	I-Method
.	O
	
An	O
ensemble	B-Method
of	I-Method
acoustic	I-Method
models	I-Method
advances	O
the	O
state	O
of	O
the	O
art	O
to	O
6.2	O
%	O
on	O
the	O
Switchboard	B-Material
test	O
data	O
.	O
	
Acknowledgments	O
.	O
	
We	O
thank	O
X.	O
Chen	O
from	O
CUED	B-Material
for	O
valuable	O
assistance	O
with	O
the	O
CUED	B-Method
-	I-Method
RNNLM	I-Method
toolkit	I-Method
,	O
and	O
ICSI	B-Method
for	O
compute	B-Material
and	I-Material
data	I-Material
resources	I-Material
.	O
	
bibliography	O
:	O
References	O
	
document	O
:	O
Pyramid	B-Method
Scene	I-Method
Parsing	I-Method
Network	I-Method
	
Scene	B-Task
parsing	I-Task
is	O
challenging	O
for	O
unrestricted	O
open	O
vocabulary	O
and	O
diverse	O
scenes	O
.	O
	
In	O
this	O
paper	O
,	O
we	O
exploit	O
the	O
capability	O
of	O
global	O
context	O
information	O
by	O
different	O
-	O
region	B-Method
-	I-Method
based	I-Method
context	I-Method
aggregation	I-Method
through	O
our	O
pyramid	B-Method
pooling	I-Method
module	I-Method
together	O
with	O
the	O
proposed	O
pyramid	B-Method
scene	I-Method
parsing	I-Method
network	I-Method
(	O
PSPNet	B-Method
)	O
.	O
	
Our	O
global	B-Method
prior	I-Method
representation	I-Method
is	O
effective	O
to	O
produce	O
good	O
quality	O
results	O
on	O
the	O
scene	B-Task
parsing	I-Task
task	I-Task
,	O
while	O
PSPNet	B-Method
provides	O
a	O
superior	O
framework	O
for	O
pixel	B-Task
-	I-Task
level	I-Task
prediction	I-Task
.	O
	
The	O
proposed	O
approach	O
achieves	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
performance	O
on	O
various	O
datasets	O
.	O
	
It	O
came	O
first	O
in	O
ImageNet	B-Task
scene	I-Task
parsing	I-Task
challenge	I-Task
2016	I-Task
,	O
PASCAL	B-Material
VOC	I-Material
2012	I-Material
benchmark	I-Material
and	O
Cityscapes	B-Material
benchmark	I-Material
.	O
	
A	O
single	O
PSPNet	B-Method
yields	O
the	O
new	O
record	O
of	O
mIoU	B-Metric
accuracy	I-Metric
85.4	O
%	O
on	O
PASCAL	B-Material
VOC	I-Material
2012	I-Material
and	O
accuracy	B-Metric
80.2	O
%	O
on	O
Cityscapes	B-Material
.	O
	
section	O
:	O
Introduction	O
	
Scene	B-Task
parsing	I-Task
,	O
based	O
on	O
semantic	B-Task
segmentation	I-Task
,	O
is	O
a	O
fundamental	O
topic	O
in	O
computer	B-Task
vision	I-Task
.	O
	
The	O
goal	O
is	O
to	O
assign	O
each	O
pixel	O
in	O
the	O
image	O
a	O
category	O
label	O
.	O
	
Scene	B-Task
parsing	I-Task
provides	O
complete	O
understanding	O
of	O
the	O
scene	O
.	O
	
It	O
predicts	O
the	O
label	O
,	O
location	O
,	O
as	O
well	O
as	O
shape	O
for	O
each	O
element	O
.	O
	
This	O
topic	O
is	O
of	O
broad	O
interest	O
for	O
potential	O
applications	O
of	O
automatic	B-Task
driving	I-Task
,	O
robot	B-Task
sensing	I-Task
,	O
to	O
name	O
a	O
few	O
.	O
	
Difficulty	O
of	O
scene	B-Task
parsing	I-Task
is	O
closely	O
related	O
to	O
scene	O
and	O
label	O
variety	O
.	O
	
The	O
pioneer	O
scene	B-Task
parsing	I-Task
task	I-Task
is	O
to	O
classify	O
33	O
scenes	O
for	O
2	O
,	O
688	O
images	O
on	O
LMO	B-Material
dataset	I-Material
.	O
	
More	O
recent	O
PASCAL	B-Material
VOC	I-Material
semantic	I-Task
segmentation	I-Task
and	O
PASCAL	B-Material
context	I-Material
datasets	I-Material
include	O
more	O
labels	O
with	O
similar	O
context	O
,	O
such	O
as	O
chair	O
and	O
sofa	O
,	O
horse	O
and	O
cow	O
,	O
etc	O
.	O
	
The	O
new	O
ADE20	B-Material
K	I-Material
dataset	I-Material
is	O
the	O
most	O
challenging	O
one	O
with	O
a	O
large	O
and	O
unrestricted	O
open	O
vocabulary	O
and	O
more	O
scene	O
classes	O
.	O
	
A	O
few	O
representative	O
images	O
are	O
shown	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
.	O
	
To	O
develop	O
an	O
effective	O
algorithm	O
for	O
these	O
datasets	O
needs	O
to	O
conquer	O
a	O
few	O
difficulties	O
.	O
	
State	O
-	O
of	O
-	O
the	O
-	O
art	O
scene	B-Method
parsing	I-Method
frameworks	I-Method
are	O
mostly	O
based	O
on	O
the	O
fully	B-Method
convolutional	I-Method
network	I-Method
(	O
FCN	B-Method
)	O
.	O
	
The	O
deep	O
convolutional	B-Method
neural	I-Method
network	I-Method
(	O
CNN	B-Method
)	O
based	O
methods	O
boost	O
dynamic	B-Task
object	I-Task
understanding	I-Task
,	O
and	O
yet	O
still	O
face	O
challenges	O
considering	O
diverse	O
scenes	O
and	O
unrestricted	O
vocabulary	O
.	O
	
One	O
example	O
is	O
shown	O
in	O
the	O
first	O
row	O
of	O
Fig	O
.	O
	
[	O
reference	O
]	O
,	O
where	O
a	O
boat	O
is	O
mistaken	O
as	O
a	O
car	O
.	O
	
These	O
errors	O
are	O
due	O
to	O
similar	O
appearance	O
of	O
objects	O
.	O
	
But	O
when	O
viewing	O
the	O
image	O
regarding	O
the	O
context	O
prior	O
that	O
the	O
scene	O
is	O
described	O
as	O
boathouse	O
near	O
a	O
river	O
,	O
correct	O
prediction	O
should	O
be	O
yielded	O
.	O
	
Towards	O
accurate	B-Task
scene	I-Task
perception	I-Task
,	O
the	O
knowledge	B-Method
graph	I-Method
relies	O
on	O
prior	O
information	O
of	O
scene	O
context	O
.	O
	
We	O
found	O
that	O
the	O
major	O
issue	O
for	O
current	O
FCN	B-Method
based	I-Method
models	I-Method
is	O
lack	O
of	O
suitable	O
strategy	O
to	O
utilize	O
global	O
scene	O
category	O
clues	O
.	O
	
For	O
typical	O
complex	B-Task
scene	I-Task
understanding	I-Task
,	O
previously	O
to	O
get	O
a	O
global	O
image	O
-	O
level	O
feature	O
,	O
spatial	B-Method
pyramid	I-Method
pooling	I-Method
was	O
widely	O
employed	O
where	O
spatial	O
statistics	O
provide	O
a	O
good	O
descriptor	O
for	O
overall	B-Task
scene	I-Task
interpretation	I-Task
.	O
	
Spatial	B-Method
pyramid	I-Method
pooling	I-Method
network	I-Method
further	O
enhances	O
the	O
ability	O
.	O
	
Different	O
from	O
these	O
methods	O
,	O
to	O
incorporate	O
suitable	O
global	O
features	O
,	O
we	O
propose	O
pyramid	B-Method
scene	I-Method
parsing	I-Method
network	I-Method
(	O
PSPNet	B-Method
)	O
.	O
	
In	O
addition	O
to	O
traditional	O
dilated	B-Method
FCN	I-Method
for	O
pixel	B-Task
prediction	I-Task
,	O
we	O
extend	O
the	O
pixel	O
-	O
level	O
feature	O
to	O
the	O
specially	O
designed	O
global	B-Method
pyramid	I-Method
pooling	I-Method
one	I-Method
.	O
	
The	O
local	O
and	O
global	O
clues	O
together	O
make	O
the	O
final	O
prediction	B-Task
more	O
reliable	O
.	O
	
We	O
also	O
propose	O
an	O
optimization	B-Method
strategy	I-Method
with	O
deeply	B-Task
supervised	I-Task
loss	I-Task
.	O
	
We	O
give	O
all	O
implementation	O
details	O
,	O
which	O
are	O
key	O
to	O
our	O
decent	O
performance	O
in	O
this	O
paper	O
,	O
and	O
make	O
the	O
code	O
and	O
trained	O
models	O
publicly	O
available	O
.	O
	
Our	O
approach	O
achieves	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
performance	O
on	O
all	O
available	O
datasets	O
.	O
	
It	O
is	O
the	O
champion	O
of	O
ImageNet	B-Task
scene	I-Task
parsing	I-Task
challenge	I-Task
2016	I-Task
,	O
and	O
arrived	O
the	O
1st	O
place	O
on	O
PASCAL	B-Material
VOC	I-Material
2012	O
semantic	B-Task
segmentation	I-Task
benchmark	O
,	O
and	O
the	O
1st	O
place	O
on	O
urban	O
scene	O
Cityscapes	B-Material
data	O
.	O
	
They	O
manifest	O
that	O
PSPNet	B-Method
gives	O
a	O
promising	O
direction	O
for	O
pixel	B-Task
-	I-Task
level	I-Task
prediction	I-Task
tasks	I-Task
,	O
which	O
may	O
even	O
benefit	O
CNN	B-Method
-	O
based	O
stereo	O
matching	O
,	O
optical	B-Task
flow	I-Task
,	O
depth	B-Task
estimation	I-Task
,	O
etc	O
.	O
in	O
follow	O
-	O
up	O
work	O
.	O
	
Our	O
main	O
contributions	O
are	O
threefold	O
.	O
	
We	O
propose	O
a	O
pyramid	B-Method
scene	I-Method
parsing	I-Method
network	I-Method
to	O
embed	O
difficult	O
scenery	O
context	O
features	O
in	O
an	O
FCN	B-Method
based	I-Method
pixel	I-Method
prediction	I-Method
framework	I-Method
.	O
	
We	O
develop	O
an	O
effective	O
optimization	B-Method
strategy	I-Method
for	O
deep	B-Task
ResNet	I-Task
based	O
on	O
deeply	B-Task
supervised	I-Task
loss	I-Task
.	O
	
We	O
build	O
a	O
practical	O
system	O
for	O
state	O
-	O
of	O
-	B-Task
the	I-Task
-	I-Task
art	I-Task
scene	I-Task
parsing	I-Task
and	O
semantic	B-Task
segmentation	I-Task
where	O
all	O
crucial	O
implementation	O
details	O
are	O
included	O
.	O
	
section	O
:	O
Related	O
Work	O
	
In	O
the	O
following	O
,	O
we	O
review	O
recent	O
advances	O
in	O
scene	B-Task
parsing	I-Task
and	O
semantic	B-Task
segmentation	I-Task
tasks	O
.	O
	
Driven	O
by	O
powerful	O
deep	B-Method
neural	I-Method
networks	I-Method
,	O
pixel	B-Task
-	I-Task
level	I-Task
prediction	I-Task
tasks	I-Task
like	O
scene	B-Task
parsing	I-Task
and	O
semantic	B-Task
segmentation	I-Task
achieve	O
great	O
progress	O
inspired	O
by	O
replacing	O
the	O
fully	B-Method
-	I-Method
connected	I-Method
layer	I-Method
in	O
classification	B-Method
with	O
the	O
convolution	B-Method
layer	I-Method
.	O
	
To	O
enlarge	O
the	O
receptive	O
field	O
of	O
neural	B-Method
networks	I-Method
,	O
methods	O
of	O
used	O
dilated	B-Method
convolution	I-Method
.	O
	
Noh	O
proposed	O
a	O
coarse	B-Method
-	I-Method
to	I-Method
-	I-Method
fine	I-Method
structure	I-Method
with	O
deconvolution	B-Method
network	I-Method
to	O
learn	O
the	O
segmentation	O
mask	O
.	O
	
Our	O
baseline	O
network	O
is	O
FCN	B-Method
and	I-Method
dilated	I-Method
network	I-Method
.	O
	
Other	O
work	O
mainly	O
proceeds	O
in	O
two	O
directions	O
.	O
	
One	O
line	O
is	O
with	O
multi	B-Method
-	I-Method
scale	I-Method
feature	I-Method
ensembling	I-Method
.	O
	
Since	O
in	O
deep	B-Method
networks	I-Method
,	O
higher	O
-	O
layer	O
feature	O
contains	O
more	O
semantic	O
meaning	O
and	O
less	O
location	O
information	O
.	O
	
Combining	O
multi	O
-	O
scale	O
features	O
can	O
improve	O
the	O
performance	O
.	O
	
The	O
other	O
direction	O
is	O
based	O
on	O
structure	B-Task
prediction	I-Task
.	O
	
The	O
pioneer	O
work	O
used	O
conditional	B-Method
random	I-Method
field	I-Method
(	I-Method
CRF	I-Method
)	O
as	O
post	B-Task
processing	I-Task
to	O
refine	O
the	O
segmentation	B-Task
result	O
.	O
	
Following	O
methods	O
refined	O
networks	O
via	O
end	B-Method
-	I-Method
to	I-Method
-	I-Method
end	I-Method
modeling	I-Method
.	O
	
Both	O
of	O
the	O
two	O
directions	O
ameliorate	O
the	O
localization	B-Task
ability	I-Task
of	O
scene	B-Task
parsing	I-Task
where	O
predicted	O
semantic	O
boundary	O
fits	O
objects	O
.	O
	
Yet	O
there	O
is	O
still	O
much	O
room	O
to	O
exploit	O
necessary	O
information	O
in	O
complex	O
scenes	O
.	O
	
To	O
make	O
good	O
use	O
of	O
global	O
image	O
-	O
level	O
priors	O
for	O
diverse	B-Task
scene	I-Task
understanding	I-Task
,	O
methods	O
of	O
extracted	O
global	O
context	O
information	O
with	O
traditional	O
features	O
not	O
from	O
deep	B-Method
neural	I-Method
networks	I-Method
.	O
	
Similar	O
improvement	O
was	O
made	O
under	O
object	B-Method
detection	I-Method
frameworks	I-Method
.	O
	
Liu	O
proved	O
that	O
global	B-Method
average	I-Method
pooling	I-Method
with	O
FCN	B-Method
can	O
improve	O
semantic	B-Task
segmentation	I-Task
results	O
.	O
	
However	O
,	O
our	O
experiments	O
show	O
that	O
these	O
global	B-Method
descriptors	I-Method
are	O
not	O
representative	O
enough	O
for	O
the	O
challenging	O
ADE20	B-Material
K	I-Material
data	O
.	O
	
Therefore	O
,	O
different	O
from	O
global	B-Method
pooling	I-Method
in	O
,	O
we	O
exploit	O
the	O
capability	O
of	O
global	O
context	O
information	O
by	O
different	O
-	O
region	B-Method
-	I-Method
based	I-Method
context	I-Method
aggregation	I-Method
via	O
our	O
pyramid	B-Method
scene	I-Method
parsing	I-Method
network	I-Method
.	O
	
section	O
:	O
Pyramid	B-Method
Scene	I-Method
Parsing	I-Method
Network	I-Method
	
We	O
start	O
with	O
our	O
observation	O
and	O
analysis	O
of	O
representative	B-Task
failure	I-Task
cases	I-Task
when	O
applying	O
FCN	B-Method
methods	I-Method
to	O
scene	B-Task
parsing	I-Task
.	O
	
They	O
motivate	O
proposal	O
of	O
our	O
pyramid	B-Method
pooling	I-Method
module	I-Method
as	O
the	O
effective	O
global	O
context	O
prior	O
.	O
	
Our	O
pyramid	B-Method
scene	I-Method
parsing	I-Method
network	I-Method
(	O
PSPNet	B-Method
)	O
illustrated	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
is	O
then	O
described	O
to	O
improve	O
performance	O
for	O
open	B-Task
-	I-Task
vocabulary	I-Task
object	I-Task
and	I-Task
stuff	I-Task
identification	I-Task
in	O
complex	B-Task
scene	I-Task
parsing	I-Task
.	O
	
subsection	O
:	O
Important	O
Observations	O
	
The	O
new	O
ADE20	B-Material
K	I-Material
dataset	I-Material
contains	O
150	O
stuff	O
/	O
object	O
category	O
labels	O
(	O
,	O
wall	O
,	O
sky	O
,	O
and	O
tree	O
)	O
and	O
1	O
,	O
038	O
image	O
-	O
level	O
scene	O
descriptors	O
(	O
,	O
airport_terminal	O
,	O
bedroom	O
,	O
and	O
street	O
)	O
.	O
	
So	O
a	O
large	O
amount	O
of	O
labels	O
and	O
vast	O
distributions	O
of	O
scenes	O
come	O
into	O
existence	O
.	O
	
Inspecting	O
the	O
prediction	B-Task
results	O
of	O
the	O
FCN	B-Method
baseline	I-Method
provided	O
in	O
,	O
we	O
summarize	O
several	O
common	O
issues	O
for	O
complex	B-Task
-	I-Task
scene	I-Task
parsing	I-Task
.	O
	
paragraph	O
:	O
Mismatched	O
Relationship	O
	
Context	O
relationship	O
is	O
universal	O
and	O
important	O
especially	O
for	O
complex	B-Task
scene	I-Task
understanding	I-Task
.	O
	
There	O
exist	O
co	O
-	O
occurrent	O
visual	O
patterns	O
.	O
	
For	O
example	O
,	O
an	O
airplane	O
is	O
likely	O
to	O
be	O
in	O
runway	O
or	O
fly	O
in	O
sky	O
while	O
not	O
over	O
a	O
road	O
.	O
	
For	O
the	O
first	O
-	O
row	O
example	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
	
,	O
FCN	B-Method
predicts	O
the	O
boat	O
in	O
the	O
yellow	O
box	O
as	O
a	O
“	O
car	O
”	O
based	O
on	O
its	O
appearance	O
.	O
	
But	O
the	O
common	O
knowledge	O
is	O
that	O
a	O
car	O
is	O
seldom	O
over	O
a	O
river	O
.	O
	
Lack	O
of	O
the	O
ability	O
to	O
collect	O
contextual	O
information	O
increases	O
the	O
chance	O
of	O
misclassification	O
.	O
	
paragraph	O
:	O
Confusion	O
Categories	O
	
There	O
are	O
many	O
class	O
label	O
pairs	O
in	O
the	O
ADE20	B-Material
K	I-Material
dataset	I-Material
that	O
are	O
confusing	O
in	O
classification	B-Task
.	O
	
Examples	O
are	O
field	O
and	O
earth	O
;	O
mountain	O
and	O
hill	O
;	O
wall	O
,	O
house	O
,	O
building	O
and	O
skyscraper	O
.	O
	
They	O
are	O
with	O
similar	O
appearance	O
.	O
	
The	O
expert	O
annotator	O
who	O
labeled	O
the	O
entire	O
dataset	O
,	O
still	O
makes	O
17.60	O
%	O
pixel	B-Metric
error	I-Metric
as	O
described	O
in	O
.	O
	
In	O
the	O
second	O
row	O
of	O
Fig	O
.	O
	
[	O
reference	O
]	O
	
,	O
FCN	B-Method
predicts	O
the	O
object	O
in	O
the	O
box	O
as	O
part	O
of	O
skyscraper	O
and	O
part	O
of	O
building	O
.	O
	
These	O
results	O
should	O
be	O
excluded	O
so	O
that	O
the	O
whole	O
object	O
is	O
either	O
skyscraper	O
or	O
building	O
,	O
but	O
not	O
both	O
.	O
	
This	O
problem	O
can	O
be	O
remedied	O
by	O
utilizing	O
the	O
relationship	O
between	O
categories	O
.	O
	
paragraph	O
:	O
Inconspicuous	O
Classes	O
	
Scene	O
contains	O
objects	O
/	O
stuff	O
of	O
arbitrary	O
size	O
.	O
	
Several	O
small	O
-	O
size	O
things	O
,	O
like	O
streetlight	O
and	O
signboard	O
,	O
are	O
hard	O
to	O
find	O
while	O
they	O
may	O
be	O
of	O
great	O
importance	O
.	O
	
Contrarily	O
,	O
big	O
objects	O
or	O
stuff	O
may	O
exceed	O
the	O
receptive	O
field	O
of	O
FCN	B-Method
and	O
thus	O
cause	O
discontinuous	B-Task
prediction	I-Task
.	O
	
As	O
shown	O
in	O
the	O
third	O
row	O
of	O
Fig	O
.	O
	
[	O
reference	O
]	O
,	O
the	O
pillow	O
has	O
similar	O
appearance	O
with	O
the	O
sheet	O
.	O
	
Overlooking	O
the	O
global	O
scene	O
category	O
may	O
fail	O
to	O
parse	O
the	O
pillow	O
.	O
	
To	O
improve	O
performance	O
for	O
remarkably	O
small	O
or	O
large	O
objects	O
,	O
one	O
should	O
pay	O
much	O
attention	O
to	O
different	O
sub	O
-	O
regions	O
that	O
contain	O
inconspicuous	O
-	O
category	O
stuff	O
.	O
	
To	O
summarize	O
these	O
observations	O
,	O
many	O
errors	O
are	O
partially	O
or	O
completely	O
related	O
to	O
contextual	O
relationship	O
and	O
global	O
information	O
for	O
different	O
receptive	O
fields	O
.	O
	
Thus	O
a	O
deep	B-Method
network	I-Method
with	O
a	O
suitable	O
global	O
-	O
scene	O
-	O
level	O
prior	O
can	O
much	O
improve	O
the	O
performance	O
of	O
scene	B-Task
parsing	I-Task
.	O
	
subsection	O
:	O
Pyramid	B-Method
Pooling	I-Method
Module	I-Method
	
With	O
above	O
analysis	O
,	O
in	O
what	O
follows	O
,	O
we	O
introduce	O
the	O
pyramid	B-Method
pooling	I-Method
module	I-Method
,	O
which	O
empirically	O
proves	O
to	O
be	O
an	O
effective	O
global	O
contextual	O
prior	O
.	O
	
In	O
a	O
deep	B-Method
neural	I-Method
network	I-Method
,	O
the	O
size	O
of	O
receptive	O
field	O
can	O
roughly	O
indicates	O
how	O
much	O
we	O
use	O
context	O
information	O
.	O
	
Although	O
theoretically	O
the	O
receptive	O
field	O
of	O
ResNet	B-Method
is	O
already	O
larger	O
than	O
the	O
input	O
image	O
,	O
it	O
is	O
shown	O
by	O
Zhou	O
that	O
the	O
empirical	O
receptive	O
field	O
of	O
CNN	B-Method
is	O
much	O
smaller	O
than	O
the	O
theoretical	O
one	O
especially	O
on	O
high	O
-	O
level	O
layers	O
.	O
	
This	O
makes	O
many	O
networks	O
not	O
sufficiently	O
incorporate	O
the	O
momentous	O
global	O
scenery	O
prior	O
.	O
	
We	O
address	O
this	O
issue	O
by	O
proposing	O
an	O
effective	O
global	B-Method
prior	I-Method
representation	I-Method
.	O
	
Global	B-Method
average	I-Method
pooling	I-Method
is	O
a	O
good	O
baseline	O
model	O
as	O
the	O
global	O
contextual	O
prior	O
,	O
which	O
is	O
commonly	O
used	O
in	O
image	B-Task
classification	I-Task
tasks	I-Task
.	O
	
In	O
,	O
it	O
was	O
successfully	O
applied	O
to	O
semantic	B-Task
segmentation	I-Task
.	O
	
But	O
regarding	O
the	O
complex	O
-	O
scene	O
images	O
in	O
ADE20	B-Material
K	I-Material
,	O
this	O
strategy	O
is	O
not	O
enough	O
to	O
cover	O
necessary	O
information	O
.	O
	
Pixels	O
in	O
these	O
scene	O
images	O
are	O
annotated	O
regarding	O
many	O
stuff	O
and	O
objects	O
.	O
	
Directly	O
fusing	O
them	O
to	O
form	O
a	O
single	O
vector	O
may	O
lose	O
the	O
spatial	O
relation	O
and	O
cause	O
ambiguity	O
.	O
	
Global	O
context	O
information	O
along	O
with	O
sub	O
-	O
region	O
context	O
is	O
helpful	O
in	O
this	O
regard	O
to	O
distinguish	O
among	O
various	O
categories	O
.	O
	
A	O
more	O
powerful	O
representation	O
could	O
be	O
fused	O
information	O
from	O
different	O
sub	O
-	O
regions	O
with	O
these	O
receptive	O
fields	O
.	O
	
Similar	O
conclusion	O
was	O
drawn	O
in	O
classical	O
work	O
of	O
scene	B-Task
/	I-Task
image	I-Task
classification	I-Task
.	O
	
In	O
,	O
feature	O
maps	O
in	O
different	O
levels	O
generated	O
by	O
pyramid	B-Method
pooling	I-Method
were	O
finally	O
flattened	O
and	O
concatenated	O
to	O
be	O
fed	O
into	O
a	O
fully	B-Method
connected	I-Method
layer	I-Method
for	O
classification	B-Task
.	O
	
This	O
global	O
prior	O
is	O
designed	O
to	O
remove	O
the	O
fixed	O
-	O
size	O
constraint	O
of	O
CNN	B-Method
for	O
image	B-Task
classification	I-Task
.	O
	
To	O
further	O
reduce	O
context	O
information	O
loss	O
between	O
different	O
sub	O
-	O
regions	O
,	O
we	O
propose	O
a	O
hierarchical	O
global	O
prior	O
,	O
containing	O
information	O
with	O
different	O
scales	O
and	O
varying	O
among	O
different	O
sub	O
-	O
regions	O
.	O
	
We	O
call	O
it	O
pyramid	B-Method
pooling	I-Method
module	I-Method
for	O
global	B-Task
scene	I-Task
prior	I-Task
construction	I-Task
upon	O
the	O
final	O
-	O
layer	O
-	O
feature	O
-	O
map	O
of	O
the	O
deep	B-Method
neural	I-Method
network	I-Method
,	O
as	O
illustrated	O
in	O
part	O
(	O
c	O
)	O
of	O
Fig	O
.	O
	
[	O
reference	O
]	O
.	O
	
The	O
pyramid	B-Method
pooling	I-Method
module	I-Method
fuses	O
features	O
under	O
four	O
different	O
pyramid	O
scales	O
.	O
	
The	O
coarsest	O
level	O
highlighted	O
in	O
red	O
is	O
global	B-Method
pooling	I-Method
to	O
generate	O
a	O
single	O
bin	O
output	O
.	O
	
The	O
following	O
pyramid	O
level	O
separates	O
the	O
feature	O
map	O
into	O
different	O
sub	O
-	O
regions	O
and	O
forms	O
pooled	B-Method
representation	I-Method
for	O
different	O
locations	O
.	O
	
The	O
output	O
of	O
different	O
levels	O
in	O
the	O
pyramid	B-Method
pooling	I-Method
module	I-Method
contains	O
the	O
feature	O
map	O
with	O
varied	O
sizes	O
.	O
	
To	O
maintain	O
the	O
weight	O
of	O
global	O
feature	O
,	O
we	O
use	O
convolution	B-Method
layer	I-Method
after	O
each	O
pyramid	O
level	O
to	O
reduce	O
the	O
dimension	O
of	O
context	B-Method
representation	I-Method
to	O
of	O
the	O
original	O
one	O
if	O
the	O
level	O
size	O
of	O
pyramid	O
is	O
.	O
	
Then	O
we	O
directly	O
upsample	O
the	O
low	O
-	O
dimension	O
feature	O
maps	O
to	O
get	O
the	O
same	O
size	O
feature	O
as	O
the	O
original	O
feature	O
map	O
via	O
bilinear	B-Method
interpolation	I-Method
.	O
	
Finally	O
,	O
different	O
levels	O
of	O
features	O
are	O
concatenated	O
as	O
the	O
final	O
pyramid	O
pooling	O
global	O
feature	O
.	O
	
Noted	O
that	O
the	O
number	O
of	O
pyramid	O
levels	O
and	O
size	O
of	O
each	O
level	O
can	O
be	O
modified	O
.	O
	
They	O
are	O
related	O
to	O
the	O
size	O
of	O
feature	O
map	O
that	O
is	O
fed	O
into	O
the	O
pyramid	B-Method
pooling	I-Method
layer	I-Method
.	O
	
The	O
structure	O
abstracts	O
different	O
sub	O
-	O
regions	O
by	O
adopting	O
varying	B-Method
-	I-Method
size	I-Method
pooling	I-Method
kernels	I-Method
in	O
a	O
few	O
strides	O
.	O
	
Thus	O
the	O
multi	B-Method
-	I-Method
stage	I-Method
kernels	I-Method
should	O
maintain	O
a	O
reasonable	O
gap	O
in	O
representation	O
.	O
	
Our	O
pyramid	B-Method
pooling	I-Method
module	I-Method
is	O
a	O
four	O
-	O
level	O
one	O
with	O
bin	O
sizes	O
of	O
,	O
,	O
and	O
respectively	O
.	O
	
For	O
the	O
type	O
of	O
pooling	O
operation	O
between	O
max	O
and	O
average	O
,	O
we	O
perform	O
extensive	O
experiments	O
to	O
show	O
the	O
difference	O
in	O
Section	O
[	O
reference	O
]	O
.	O
	
subsection	O
:	O
Network	B-Method
Architecture	I-Method
	
With	O
the	O
pyramid	B-Method
pooling	I-Method
module	I-Method
,	O
we	O
propose	O
our	O
pyramid	B-Method
scene	I-Method
parsing	I-Method
network	I-Method
(	O
PSPNet	B-Method
)	O
as	O
illustrated	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
.	O
	
Given	O
an	O
input	O
image	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
	
(	O
a	O
)	O
,	O
we	O
use	O
a	O
pretrained	B-Method
ResNet	I-Method
model	I-Method
with	O
the	O
dilated	B-Method
network	I-Method
strategy	I-Method
to	O
extract	O
the	O
feature	O
map	O
.	O
	
The	O
final	O
feature	B-Metric
map	I-Metric
size	I-Metric
is	O
of	O
the	O
input	O
image	O
,	O
as	O
shown	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
(	O
b	O
)	O
.	O
	
On	O
top	O
of	O
the	O
map	O
,	O
we	O
use	O
the	O
pyramid	B-Method
pooling	I-Method
module	I-Method
shown	O
in	O
(	O
c	O
)	O
to	O
gather	O
context	O
information	O
.	O
	
Using	O
our	O
4	B-Method
-	I-Method
level	I-Method
pyramid	I-Method
,	O
the	O
pooling	B-Method
kernels	I-Method
cover	O
the	O
whole	O
,	O
half	O
of	O
,	O
and	O
small	O
portions	O
of	O
the	O
image	O
.	O
	
They	O
are	O
fused	O
as	O
the	O
global	O
prior	O
.	O
	
Then	O
we	O
concatenate	O
the	O
prior	O
with	O
the	O
original	O
feature	O
map	O
in	O
the	O
final	O
part	O
of	O
(	O
c	O
)	O
.	O
	
It	O
is	O
followed	O
by	O
a	O
convolution	B-Method
layer	I-Method
to	O
generate	O
the	O
final	O
prediction	O
map	O
in	O
(	O
d	O
)	O
.	O
	
To	O
explain	O
our	O
structure	O
,	O
PSPNet	B-Method
provides	O
an	O
effective	O
global	B-Method
contextual	I-Method
prior	I-Method
for	O
pixel	B-Task
-	I-Task
level	I-Task
scene	I-Task
parsing	I-Task
.	O
	
The	O
pyramid	B-Method
pooling	I-Method
module	I-Method
can	O
collect	O
levels	O
of	O
information	O
,	O
more	O
representative	O
than	O
global	B-Method
pooling	I-Method
.	O
	
In	O
terms	O
of	O
computational	B-Metric
cost	I-Metric
,	O
our	O
PSPNet	B-Method
does	O
not	O
much	O
increase	O
it	O
compared	O
to	O
the	O
original	O
dilated	B-Method
FCN	I-Method
network	I-Method
.	O
	
In	O
end	B-Task
-	I-Task
to	I-Task
-	I-Task
end	I-Task
learning	I-Task
,	O
the	O
global	B-Method
pyramid	I-Method
pooling	I-Method
module	I-Method
and	O
the	O
local	O
FCN	O
feature	O
can	O
be	O
optimized	O
simultaneously	O
.	O
	
section	O
:	O
Deep	B-Task
Supervision	I-Task
for	O
ResNet	B-Method
-	I-Method
Based	I-Method
FCN	I-Method
	
Deep	B-Method
pretrained	I-Method
networks	I-Method
lead	O
to	O
good	O
performance	O
.	O
	
However	O
,	O
increasing	O
depth	O
of	O
the	O
network	O
may	O
introduce	O
additional	O
optimization	B-Metric
difficulty	I-Metric
as	O
shown	O
in	O
for	O
image	B-Task
classification	I-Task
.	O
	
ResNet	B-Method
solves	O
this	O
problem	O
with	O
skip	O
connection	O
in	O
each	O
block	O
.	O
	
Latter	O
layers	O
of	O
deep	B-Method
ResNet	I-Method
mainly	O
learn	O
residues	O
based	O
on	O
previous	O
ones	O
.	O
	
We	O
contrarily	O
propose	O
generating	O
initial	O
results	O
by	O
supervision	O
with	O
an	O
additional	O
loss	O
,	O
and	O
learning	O
the	O
residue	O
afterwards	O
with	O
the	O
final	O
loss	O
.	O
	
Thus	O
,	O
optimization	B-Task
of	O
the	O
deep	B-Method
network	I-Method
is	O
decomposed	O
into	O
two	O
,	O
each	O
is	O
simpler	O
to	O
solve	O
.	O
	
An	O
example	O
of	O
our	O
deeply	B-Method
supervised	I-Method
ResNet101	I-Method
model	I-Method
is	O
illustrated	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
.	O
	
Apart	O
from	O
the	O
main	O
branch	O
using	O
softmax	O
loss	O
to	O
train	O
the	O
final	O
classifier	B-Method
,	O
another	O
classifier	B-Method
is	O
applied	O
after	O
the	O
fourth	O
stage	O
,	O
i.e.	O
,	O
the	O
res4b22	O
residue	O
block	O
.	O
	
Different	O
from	O
relay	B-Method
backpropagation	I-Method
that	O
blocks	O
the	O
backward	O
auxiliary	O
loss	O
to	O
several	O
shallow	O
layers	O
,	O
we	O
let	O
the	O
two	O
loss	O
functions	O
pass	O
through	O
all	O
previous	O
layers	O
.	O
	
The	O
auxiliary	O
loss	O
helps	O
optimize	O
the	O
learning	B-Task
process	I-Task
,	O
while	O
the	O
master	B-Method
branch	I-Method
loss	I-Method
takes	O
the	O
most	O
responsibility	O
.	O
	
We	O
add	O
weight	O
to	O
balance	O
the	O
auxiliary	O
loss	O
.	O
	
In	O
the	O
testing	O
phase	O
,	O
we	O
abandon	O
this	O
auxiliary	O
branch	O
and	O
only	O
use	O
the	O
well	O
optimized	O
master	O
branch	O
for	O
final	O
prediction	B-Task
.	O
	
This	O
kind	O
of	O
deeply	B-Method
supervised	I-Method
training	I-Method
strategy	I-Method
for	O
ResNet	B-Method
-	I-Method
based	I-Method
FCN	I-Method
is	O
broadly	O
useful	O
under	O
different	O
experimental	O
settings	O
and	O
works	O
with	O
the	O
pre	O
-	O
trained	O
ResNet	B-Method
model	I-Method
.	O
	
This	O
manifests	O
the	O
generality	O
of	O
such	O
a	O
learning	B-Method
strategy	I-Method
.	O
	
More	O
details	O
are	O
provided	O
in	O
Section	O
[	O
reference	O
]	O
.	O
	
section	O
:	O
Experiments	O
	
Our	O
proposed	O
method	O
is	O
successful	O
on	O
scene	B-Task
parsing	I-Task
and	O
semantic	B-Task
segmentation	I-Task
challenges	O
.	O
	
We	O
evaluate	O
it	O
in	O
this	O
section	O
on	O
three	O
different	O
datasets	O
,	O
including	O
ImageNet	B-Task
scene	I-Task
parsing	I-Task
challenge	I-Task
2016	I-Task
,	O
PASCAL	B-Task
VOC	I-Task
2012	I-Task
semantic	I-Task
segmentation	I-Task
and	O
urban	O
scene	O
understanding	O
dataset	O
Cityscapes	B-Material
.	O
	
subsection	O
:	O
Implementation	O
Details	O
	
For	O
a	O
practical	O
deep	B-Method
learning	I-Method
system	I-Method
,	O
devil	O
is	O
always	O
in	O
the	O
details	O
.	O
	
Our	O
implementation	O
is	O
based	O
on	O
the	O
public	B-Method
platform	I-Method
Caffe	I-Method
.	O
	
Inspired	O
by	O
,	O
we	O
use	O
the	O
“	O
poly	B-Method
”	I-Method
learning	I-Method
rate	I-Method
policy	I-Method
where	O
current	O
learning	B-Metric
rate	I-Metric
equals	O
to	O
the	O
base	O
one	O
multiplying	O
.	O
	
We	O
set	O
base	O
learning	B-Metric
rate	I-Metric
to	O
0.01	O
and	O
power	O
to	O
0.9	O
.	O
	
The	O
performance	O
can	O
be	O
improved	O
by	O
increasing	O
the	O
iteration	B-Metric
number	I-Metric
,	O
which	O
is	O
set	O
to	O
150	O
K	O
for	O
ImageNet	B-Material
experiment	I-Material
,	O
30	O
K	O
for	O
PASCAL	B-Material
VOC	I-Material
and	O
90	O
K	O
for	O
Cityscapes	B-Material
.	O
	
Momentum	O
and	O
weight	O
decay	O
are	O
set	O
to	O
0.9	O
and	O
0.0001	O
respectively	O
.	O
	
For	O
data	B-Task
augmentation	I-Task
,	O
we	O
adopt	O
random	O
mirror	O
and	O
random	O
resize	O
between	O
0.5	O
and	O
2	O
for	O
all	O
datasets	O
,	O
and	O
additionally	O
add	O
random	O
rotation	O
between	O
-	O
10	O
and	O
10	O
degrees	O
,	O
and	O
random	O
Gaussian	O
blur	O
for	O
ImageNet	B-Material
and	O
PASCAL	B-Material
VOC	I-Material
.	O
	
This	O
comprehensive	O
data	B-Method
augmentation	I-Method
scheme	I-Method
makes	O
the	O
network	O
resist	O
overfitting	O
.	O
	
Our	O
network	O
contains	O
dilated	B-Method
convolution	I-Method
following	I-Method
.	O
	
During	O
the	O
course	O
of	O
experiments	O
,	O
we	O
notice	O
that	O
an	O
appropriately	O
large	O
“	O
cropsize	O
”	O
can	O
yield	O
good	O
performance	O
and	O
“	O
batchsize	O
”	O
in	O
the	O
batch	B-Method
normalization	I-Method
layer	I-Method
is	O
of	O
great	O
importance	O
.	O
	
Due	O
to	O
limited	O
physical	O
memory	O
on	O
GPU	O
cards	O
,	O
we	O
set	O
the	O
“	O
batchsize	O
”	O
to	O
16	O
during	O
training	B-Task
.	O
	
To	O
achieve	O
this	O
,	O
we	O
modify	O
Caffe	B-Method
from	O
together	O
with	O
branch	B-Method
and	O
make	O
it	O
support	O
batch	B-Task
normalization	I-Task
on	O
data	O
gathered	O
from	O
multiple	O
GPUs	O
based	O
on	O
OpenMPI	B-Method
.	O
	
For	O
the	O
auxiliary	B-Task
loss	I-Task
,	O
we	O
set	O
the	O
weight	O
to	O
0.4	O
in	O
experiments	O
.	O
	
subsection	O
:	O
ImageNet	B-Task
Scene	I-Task
Parsing	I-Task
Challenge	I-Task
2016	I-Task
	
paragraph	O
:	O
Dataset	O
and	O
Evaluation	B-Metric
Metrics	I-Metric
	
The	O
ADE20	B-Material
K	I-Material
dataset	I-Material
is	O
used	O
in	O
ImageNet	B-Task
scene	I-Task
parsing	I-Task
challenge	I-Task
2016	I-Task
.	O
	
Different	O
from	O
other	O
datasets	O
,	O
ADE20	B-Material
K	I-Material
is	O
more	O
challenging	O
for	O
the	O
up	O
to	O
150	O
classes	O
and	O
diverse	O
scenes	O
with	O
a	O
total	O
of	O
1	O
,	O
038	O
image	O
-	O
level	O
labels	O
.	O
	
The	O
challenge	O
data	O
is	O
divided	O
into	O
20K	O
/	O
2K	O
/	O
3	O
K	O
images	O
for	O
training	O
,	O
validation	B-Task
and	O
testing	B-Task
.	O
	
Also	O
,	O
it	O
needs	O
to	O
parse	O
both	O
objects	O
and	O
stuff	O
in	O
the	O
scene	O
,	O
which	O
makes	O
it	O
more	O
difficult	O
than	O
other	O
datasets	O
.	O
	
For	O
evaluation	O
,	O
both	O
pixel	B-Metric
-	I-Metric
wise	I-Metric
accuracy	I-Metric
(	O
Pixel	B-Metric
Acc	I-Metric
.	O
)	O
and	O
mean	O
of	O
class	B-Metric
-	I-Metric
wise	I-Metric
intersection	I-Metric
over	I-Metric
union	I-Metric
(	O
Mean	B-Metric
IoU	I-Metric
)	I-Metric
are	O
used	O
.	O
	
paragraph	O
:	O
Ablation	B-Task
Study	I-Task
for	O
PSPNet	B-Method
	
To	O
evaluate	O
PSPNet	B-Method
,	O
we	O
conduct	O
experiments	O
with	O
several	O
settings	O
,	O
including	O
pooling	O
types	O
of	O
max	B-Method
and	I-Method
average	I-Method
,	O
pooling	B-Method
with	O
just	O
one	O
global	O
feature	O
or	O
four	O
-	O
level	O
features	O
,	O
with	O
and	O
without	O
dimension	B-Method
reduction	I-Method
after	O
the	O
pooling	B-Method
operation	I-Method
and	O
before	O
concatenation	B-Method
.	O
	
As	O
listed	O
in	O
Table	O
[	O
reference	O
]	O
,	O
average	B-Method
pooling	I-Method
works	O
better	O
than	O
max	B-Method
pooling	I-Method
in	O
all	O
settings	O
.	O
	
Pooling	B-Method
with	O
pyramid	B-Method
parsing	I-Method
outperforms	O
that	O
using	O
global	B-Method
pooling	I-Method
.	O
	
With	O
dimension	B-Method
reduction	I-Method
,	O
the	O
performance	O
is	O
further	O
enhanced	O
.	O
	
With	O
our	O
proposed	O
PSPNet	B-Method
,	O
the	O
best	O
setting	O
yields	O
results	O
41.68	O
/	O
80.04	O
in	O
terms	O
of	O
Mean	B-Metric
IoU	I-Metric
and	O
Pixel	B-Metric
Acc	I-Metric
.	O
	
(	O
%	O
)	O
,	O
exceeding	O
global	B-Metric
average	I-Metric
pooling	I-Metric
of	O
40.07	O
/	O
79.52	O
as	O
idea	O
in	O
Liu	O
by	O
1.61	O
/	O
0.52	O
.	O
	
And	O
compared	O
to	O
the	O
baseline	O
,	O
PSPNet	B-Method
outperforming	O
it	O
by	O
4.45	O
/	O
2.03	O
in	O
terms	O
of	O
absolute	B-Metric
improvement	I-Metric
and	O
11.95	O
/	O
2.60	O
in	O
terms	O
of	O
relative	B-Metric
difference	I-Metric
.	O
	
paragraph	O
:	O
Ablation	B-Task
Study	I-Task
for	O
Auxiliary	B-Task
Loss	I-Task
	
The	O
introduced	O
auxiliary	O
loss	O
helps	O
optimize	O
the	O
learning	B-Task
process	I-Task
while	O
not	O
influencing	O
learning	B-Task
in	O
the	O
master	O
branch	O
.	O
	
We	O
experiment	O
with	O
setting	O
the	O
auxiliary	O
loss	O
weight	O
between	O
0	O
and	O
1	O
and	O
show	O
the	O
results	O
in	O
Table	O
[	O
reference	O
]	O
.	O
	
The	O
baseline	O
uses	O
ResNet50	B-Method
-	I-Method
based	I-Method
FCN	I-Method
with	O
dilated	B-Method
network	I-Method
,	O
with	O
the	O
master	O
branch	O
’s	O
softmax	O
loss	O
for	O
optimization	B-Task
.	O
	
Adding	O
the	O
auxiliary	O
loss	O
branch	O
,	O
=	O
0.4	O
yields	O
the	O
best	O
performance	O
.	O
	
It	O
outperforms	O
the	O
baseline	O
with	O
an	O
improvement	O
of	O
1.41	O
/	O
0.94	O
in	O
terms	O
of	O
Mean	B-Metric
IoU	I-Metric
and	O
Pixel	B-Metric
Acc	I-Metric
.	O
	
(	O
%	O
)	O
.	O
	
We	O
believe	O
deeper	O
networks	O
will	O
benefit	O
more	O
given	O
the	O
new	O
augmented	O
auxiliary	O
loss	O
.	O
	
paragraph	O
:	O
Ablation	B-Task
Study	I-Task
for	O
Pre	O
-	O
trained	B-Method
Model	I-Method
	
Deeper	B-Method
neural	I-Method
networks	I-Method
have	O
been	O
shown	O
in	O
previous	O
work	O
to	O
be	O
beneficial	O
to	O
large	B-Task
scale	I-Task
data	I-Task
classification	I-Task
.	O
	
To	O
further	O
analyze	O
PSPNet	B-Method
,	O
we	O
conduct	O
experiments	O
for	O
different	O
depths	O
of	O
pre	O
-	O
trained	O
ResNet	B-Method
.	O
	
We	O
test	O
four	O
depths	O
of	O
{	O
50	O
,	O
101	O
,	O
152	O
,	O
269}.	O
As	O
shown	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
,	O
with	O
the	O
same	O
setting	O
,	O
increasing	O
the	O
depth	O
of	O
ResNet	O
from	O
50	O
to	O
269	O
can	O
improve	O
the	O
score	B-Metric
of	O
(	O
Mean	B-Metric
IoU	I-Metric
+	O
Pixel	B-Metric
Acc	I-Metric
.	O
)	O
	
/	O
2	O
(	O
%	O
)	O
from	O
60.86	O
to	O
62.35	O
,	O
with	O
1.49	O
absolute	O
improvement	O
.	O
	
Detailed	O
scores	O
of	O
PSPNet	B-Method
pre	O
-	O
trained	O
from	O
different	O
depth	B-Method
ResNet	I-Method
models	I-Method
are	O
listed	O
in	O
Table	O
[	O
reference	O
]	O
.	O
	
paragraph	O
:	O
More	O
Detailed	O
Performance	O
Analysis	O
	
We	O
show	O
our	O
more	O
detailed	O
analysis	O
on	O
the	O
validation	O
set	O
of	O
ADE20	B-Material
K	I-Material
in	O
Table	O
[	O
reference	O
]	O
.	O
	
All	O
our	O
results	O
except	O
the	O
last	O
-	O
row	O
one	O
use	O
single	O
-	O
scale	O
test	O
.	O
	
“	O
	
ResNet269	B-Method
+	I-Method
DA	I-Method
+	I-Method
AL	I-Method
+	I-Method
PSP	I-Method
+	I-Method
MS	I-Method
	
”	O
uses	O
multi	B-Task
-	I-Task
scale	I-Task
testing	I-Task
.	O
	
Our	O
baseline	O
is	O
adapted	O
from	O
ResNet50	B-Method
with	I-Method
dilated	I-Method
network	I-Method
,	O
which	O
yields	O
MeanIoU	B-Metric
34.28	I-Metric
and	O
Pixel	B-Metric
Acc	I-Metric
.	O
	
76.35	O
.	O
	
It	O
already	O
outperforms	O
other	O
prior	O
systems	O
possibly	O
due	O
to	O
the	O
powerful	O
ResNet	B-Method
.	O
	
Our	O
proposed	O
architecture	O
makes	O
further	O
improvement	O
compared	O
to	O
the	O
baseline	O
.	O
	
Using	O
data	B-Method
augmentation	I-Method
,	O
our	O
result	O
exceeds	O
the	O
baseline	O
by	O
1.54	O
/	O
0.72	O
and	O
reaches	O
35.82	O
/	O
77.07	O
.	O
	
Using	O
the	O
auxiliary	O
loss	O
can	O
further	O
improve	O
it	O
by	O
1.41	O
/	O
0.94	O
and	O
reaches	O
37.23	O
/	O
78.01	O
.	O
	
With	O
PSPNet	B-Method
,	O
we	O
notice	O
relatively	O
more	O
significant	O
progress	O
for	O
improvement	O
of	O
4.45	O
/	O
2.03	O
.	O
	
The	O
result	O
reaches	O
41.68	O
/	O
80.04	O
.	O
	
The	O
difference	O
from	O
the	O
baseline	O
result	O
is	O
7.40	O
/	O
3.69	O
in	O
terms	O
of	O
absolute	B-Metric
improvement	I-Metric
and	O
21.59	O
/	O
4.83	O
(	O
%	O
)	O
in	O
terms	O
of	O
relativity	B-Metric
.	O
	
A	O
deeper	O
network	O
of	O
ResNet269	B-Method
yields	O
even	O
higher	O
performance	O
up	O
to	O
43.81	O
/	O
80.88	O
.	O
	
Finally	O
,	O
the	O
multi	B-Method
-	I-Method
scale	I-Method
testing	I-Method
scheme	I-Method
moves	O
the	O
scores	O
to	O
44.94	O
/	O
81.69	O
.	O
	
paragraph	O
:	O
Results	O
in	O
Challenge	O
	
Using	O
the	O
proposed	O
architecture	O
,	O
our	O
team	O
came	O
in	O
the	O
1st	O
place	O
in	O
ImageNet	B-Task
scene	I-Task
parsing	I-Task
challenge	I-Task
2016	I-Task
.	O
	
Table	O
[	O
reference	O
]	O
shows	O
a	O
few	O
results	O
in	O
this	O
competition	O
.	O
	
Our	O
ensemble	O
submission	O
achieves	O
score	B-Metric
57.21	O
%	O
on	O
the	O
testing	O
set	O
.	O
	
Our	O
single	O
-	O
model	O
yields	O
score	B-Metric
55.38	O
%	O
,	O
which	O
is	O
even	O
higher	O
than	O
a	O
few	O
other	O
multi	B-Method
-	I-Method
model	I-Method
ensemble	I-Method
submissions	I-Method
.	O
	
This	O
score	B-Metric
is	O
lower	O
than	O
that	O
on	O
the	O
validation	O
set	O
possibly	O
due	O
to	O
the	O
difference	O
of	O
data	O
distributions	O
between	O
validation	O
and	O
testing	O
sets	O
.	O
	
As	O
shown	O
in	O
column	O
(	O
d	O
)	O
of	O
Fig	O
.	O
	
[	O
reference	O
]	O
,	O
PSPNet	B-Method
solves	O
the	O
common	O
problems	O
in	O
FCN	B-Method
.	O
	
Fig	O
.	O
	
[	O
reference	O
]	O
shows	O
another	O
few	O
parsing	B-Task
results	O
on	O
validation	O
set	O
of	O
ADE20K.	B-Material
	
Our	O
results	O
contain	O
more	O
accurate	O
and	O
detailed	O
structures	O
compared	O
to	O
the	O
baseline	O
.	O
	
subsection	O
:	O
PASCAL	B-Material
VOC	I-Material
2012	I-Material
	
Our	O
PSPNet	B-Method
also	O
works	O
satisfyingly	O
on	O
semantic	B-Task
segmentation	I-Task
.	O
	
We	O
carry	O
out	O
experiments	O
on	O
the	O
PASCAL	B-Material
VOC	I-Material
2012	I-Material
segmentation	I-Material
dataset	I-Material
,	O
which	O
contains	O
20	O
object	O
categories	O
and	O
one	O
background	O
class	O
.	O
	
Following	O
the	O
procedure	O
of	O
,	O
we	O
use	O
augmented	O
data	O
with	O
the	O
annotation	O
of	O
resulting	O
10	O
,	O
582	O
,	O
1	O
,	O
449	O
and	O
1	O
,	O
456	O
images	O
for	O
training	O
,	O
validation	B-Task
and	O
testing	B-Task
.	O
	
Results	O
are	O
shown	O
in	O
Table	O
[	O
reference	O
]	O
,	O
we	O
compare	O
PSPNet	B-Method
with	O
previous	O
best	O
-	O
performing	O
methods	O
on	O
the	O
testing	O
set	O
based	O
on	O
two	O
settings	O
,	O
i.e.	O
,	O
with	O
or	O
without	O
pre	B-Method
-	I-Method
training	I-Method
on	O
MS	B-Material
-	I-Material
COCO	I-Material
dataset	O
.	O
	
Methods	O
pre	O
-	O
trained	O
with	O
MS	B-Material
-	I-Material
COCO	I-Material
are	O
marked	O
by	O
‘	O
	
†	O
’	O
.	O
	
For	O
fair	O
comparison	O
with	O
current	O
ResNet	B-Method
based	I-Method
frameworks	I-Method
in	O
scene	O
parsing	O
/	O
semantic	B-Task
segmentation	I-Task
task	O
,	O
we	O
build	O
our	O
architecture	O
based	O
on	O
ResNet101	B-Method
while	O
without	O
post	B-Method
-	I-Method
processing	I-Method
like	O
CRF	B-Method
.	O
	
We	O
evaluate	O
PSPNet	B-Method
with	O
several	O
-	O
scale	O
input	O
and	O
use	O
the	O
average	O
results	O
following	O
.	O
	
As	O
shown	O
in	O
Table	O
[	O
reference	O
]	O
,	O
PSPNet	B-Method
outperforms	O
prior	O
methods	O
on	O
both	O
settings	O
.	O
	
Trained	O
with	O
only	O
VOC	B-Material
2012	I-Material
data	I-Material
,	O
we	O
achieve	O
82.6	O
%	O
accuracy	B-Metric
	
–	O
	
we	O
get	O
the	O
highest	O
accuracy	B-Metric
on	O
all	O
20	O
classes	O
.	O
	
When	O
PSPNet	B-Method
is	O
pre	O
-	O
trained	O
with	O
MS	B-Material
-	I-Material
COCO	I-Material
dataset	O
,	O
it	O
reaches	O
85.4	O
%	O
accuracy	B-Metric
where	O
19	O
out	O
of	O
the	O
20	O
classes	O
receive	O
the	O
highest	O
accuracy	B-Metric
.	O
	
Intriguingly	O
,	O
our	O
PSPNet	B-Method
trained	O
with	O
only	O
VOC	B-Material
2012	I-Material
data	I-Material
outperforms	O
existing	O
methods	O
trained	O
with	O
the	O
MS	B-Material
-	I-Material
COCO	I-Material
pre	O
-	O
trained	O
model	O
.	O
	
One	O
may	O
argue	O
that	O
our	O
based	B-Method
classification	I-Method
model	I-Method
is	O
more	O
powerful	O
than	O
several	O
prior	O
methods	O
since	O
ResNet	B-Method
was	O
recently	O
proposed	O
.	O
	
To	O
exhibit	O
our	O
unique	O
contribution	O
,	O
we	O
show	O
that	O
our	O
method	O
also	O
outperforms	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
frameworks	O
that	O
use	O
the	O
same	O
model	O
,	O
including	O
FCRNs	B-Method
,	O
LRR	B-Method
,	O
and	O
DeepLab	B-Method
.	O
	
In	O
this	O
process	O
,	O
we	O
even	O
do	O
not	O
employ	O
time	O
-	O
consuming	O
but	O
effective	O
post	B-Method
-	I-Method
processing	I-Method
,	O
such	O
as	O
CRF	B-Method
,	O
as	O
that	O
in	O
.	O
	
Several	O
examples	O
are	O
shown	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
.	O
	
For	O
“	O
cows	O
”	O
in	O
row	O
one	O
,	O
our	O
baseline	O
model	O
treats	O
it	O
as	O
“	O
horse	O
”	O
and	O
“	O
dog	O
”	O
while	O
PSPNet	B-Method
corrects	O
these	O
errors	O
.	O
	
For	O
“	O
aeroplane	O
”	O
and	O
“	O
table	O
”	O
in	O
the	O
second	O
and	O
third	O
rows	O
,	O
PSPNet	B-Method
finds	O
missing	O
parts	O
.	O
	
For	O
“	O
person	O
”	O
,	O
“	O
bottle	O
”	O
and	O
“	O
plant	O
”	O
in	O
following	O
rows	O
,	O
PSPNet	B-Method
performs	O
well	O
on	O
these	O
small	O
-	O
size	O
-	O
object	O
classes	O
in	O
the	O
images	O
compared	O
to	O
the	O
baseline	O
model	O
.	O
	
More	O
visual	O
comparisons	O
between	O
PSPNet	B-Method
and	O
other	O
methods	O
are	O
included	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
.	O
	
subsection	O
:	O
Cityscapes	B-Material
	
Cityscapes	B-Material
is	O
a	O
recently	O
released	O
dataset	O
for	O
semantic	B-Task
urban	I-Task
scene	I-Task
understanding	I-Task
.	O
	
It	O
contains	O
5	O
,	O
000	O
high	O
quality	O
pixel	O
-	O
level	O
finely	O
annotated	O
images	O
collected	O
from	O
50	O
cities	O
in	O
different	O
seasons	O
.	O
	
The	O
images	O
are	O
divided	O
into	O
sets	O
with	O
numbers	O
2	O
,	O
975	O
,	O
500	O
,	O
and	O
1	O
,	O
525	O
for	O
training	O
,	O
validation	B-Task
and	O
testing	B-Task
.	O
	
It	O
defines	O
19	O
categories	O
containing	O
both	O
stuff	O
and	O
objects	O
.	O
	
Also	O
,	O
20	O
,	O
000	O
coarsely	O
annotated	O
images	O
are	O
provided	O
for	O
two	O
settings	O
in	O
comparison	O
,	O
i.e.	O
,	O
training	O
with	O
only	O
fine	O
data	O
or	O
with	O
both	O
the	O
fine	O
and	O
coarse	O
data	O
.	O
	
Methods	O
trained	O
using	O
both	O
fine	O
and	O
coarse	O
data	O
are	O
marked	O
with	O
‘	O
’	O
.	O
	
Detailed	O
results	O
are	O
listed	O
in	O
Table	O
[	O
reference	O
]	O
.	O
	
Our	O
base	O
model	O
is	O
ResNet101	B-Method
as	O
in	O
DeepLab	B-Method
for	O
fair	O
comparison	O
and	O
the	O
testing	O
procedure	O
follows	O
Section	O
[	O
reference	O
]	O
.	O
	
Statistics	O
in	O
Table	O
[	O
reference	O
]	O
show	O
that	O
PSPNet	B-Method
outperforms	O
other	O
methods	O
with	O
notable	O
advantage	O
.	O
	
Using	O
both	O
fine	O
and	O
coarse	O
data	O
for	O
training	O
makes	O
our	O
method	O
yield	O
80.2	O
accuracy	B-Metric
.	O
	
Several	O
examples	O
are	O
shown	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
.	O
	
Detailed	O
per	O
-	O
class	O
results	O
on	O
testing	O
set	O
are	O
shown	O
in	O
Table	O
[	O
reference	O
]	O
.	O
	
section	O
:	O
Concluding	O
Remarks	O
	
We	O
have	O
proposed	O
an	O
effective	O
pyramid	B-Method
scene	I-Method
parsing	I-Method
network	I-Method
for	O
complex	B-Task
scene	I-Task
understanding	I-Task
.	O
	
The	O
global	B-Method
pyramid	I-Method
pooling	I-Method
feature	I-Method
provides	O
additional	O
contextual	O
information	O
.	O
	
We	O
have	O
also	O
provided	O
a	O
deeply	O
supervised	B-Method
optimization	I-Method
strategy	I-Method
for	O
ResNet	B-Method
-	I-Method
based	I-Method
FCN	I-Method
network	I-Method
.	O
	
We	O
hope	O
the	O
implementation	O
details	O
publicly	O
available	O
can	O
help	O
the	O
community	O
adopt	O
these	O
useful	O
strategies	O
for	O
scene	B-Task
parsing	I-Task
and	O
semantic	B-Task
segmentation	I-Task
and	O
advance	O
related	O
techniques	O
.	O
	
section	O
:	O
Acknowledgements	O
	
We	O
would	O
like	O
to	O
thank	O
Gang	O
Sun	O
and	O
Tong	O
Xiao	O
for	O
their	O
help	O
in	O
training	O
the	O
basic	O
classification	B-Method
models	I-Method
,	O
Qun	O
Luo	O
for	O
technical	O
support	O
.	O
	
This	O
work	O
is	O
supported	O
by	O
a	O
grant	O
from	O
the	O
Research	O
Grants	O
Council	O
of	O
the	O
Hong	O
Kong	O
SAR	O
(	O
project	O
No	O
.	O
2150760	O
)	O
.	O
	
bibliography	O
:	O
References	O
	
document	O
:	O
ArtTrack	B-Method
:	O
Articulated	B-Method
Multi	I-Method
-	I-Method
person	I-Method
Tracking	I-Method
in	O
the	O
Wild	O
	
In	O
this	O
paper	O
we	O
propose	O
an	O
approach	O
for	O
articulated	B-Task
tracking	I-Task
of	I-Task
multiple	I-Task
people	I-Task
in	I-Task
unconstrained	I-Task
videos	I-Task
.	O
	
Our	O
starting	O
point	O
is	O
a	O
model	O
that	O
resembles	O
existing	O
architectures	O
for	O
single	B-Task
-	I-Task
frame	I-Task
pose	I-Task
estimation	I-Task
but	O
is	O
substantially	O
faster	O
.	O
	
We	O
achieve	O
this	O
in	O
two	O
ways	O
:	O
(	O
1	O
)	O
by	O
simplifying	O
and	O
sparsifying	O
the	O
body	B-Method
-	I-Method
part	I-Method
relationship	I-Method
graph	I-Method
and	O
leveraging	O
recent	O
methods	O
for	O
faster	B-Task
inference	I-Task
,	O
and	O
(	O
2	O
)	O
by	O
offloading	O
a	O
substantial	O
share	O
of	O
computation	O
onto	O
a	O
feed	B-Method
-	I-Method
forward	I-Method
convolutional	I-Method
architecture	I-Method
that	O
is	O
able	O
to	O
detect	O
and	O
associate	O
body	O
joints	O
of	O
the	O
same	O
person	O
even	O
in	O
clutter	O
.	O
	
We	O
use	O
this	O
model	O
to	O
generate	O
proposals	O
for	O
body	O
joint	O
locations	O
and	O
formulate	O
articulated	B-Task
tracking	I-Task
as	O
spatio	B-Task
-	I-Task
temporal	I-Task
grouping	I-Task
of	O
such	O
proposals	O
.	O
	
This	O
allows	O
to	O
jointly	O
solve	O
the	O
association	B-Task
problem	I-Task
for	O
all	O
people	O
in	O
the	O
scene	O
by	O
propagating	O
evidence	O
from	O
strong	O
detections	O
through	O
time	O
and	O
enforcing	O
constraints	O
that	O
each	O
proposal	O
can	O
be	O
assigned	O
to	O
one	O
person	O
only	O
.	O
	
We	O
report	O
results	O
on	O
a	O
public	O
“	O
MPII	B-Material
Human	O
Pose	O
”	O
benchmark	O
and	O
on	O
a	O
new	O
“	O
MPII	B-Material
Video	O
Pose	O
”	O
dataset	O
of	O
image	O
sequences	O
with	O
multiple	O
people	O
.	O
	
We	O
demonstrate	O
that	O
our	O
model	O
achieves	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
results	O
while	O
using	O
only	O
a	O
fraction	O
of	O
time	O
and	O
is	O
able	O
to	O
leverage	O
temporal	O
information	O
to	O
improve	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
for	O
crowded	B-Task
scenes	I-Task
.	O
	
section	O
:	O
Introduction	O
	
This	O
paper	O
addresses	O
the	O
task	O
of	O
articulated	B-Task
human	I-Task
pose	I-Task
tracking	I-Task
in	O
monocular	O
video	O
.	O
	
We	O
focus	O
on	O
scenes	O
of	O
realistic	O
complexity	O
that	O
often	O
include	O
fast	O
motions	O
,	O
large	O
variability	O
in	O
appearance	O
and	O
clothing	O
,	O
and	O
person	O
-	O
person	O
occlusions	O
.	O
	
A	O
successful	O
approach	O
must	O
thus	O
identify	O
the	O
number	O
of	O
people	O
in	O
each	O
video	O
frame	O
,	O
determine	O
locations	O
of	O
the	O
joints	O
of	O
each	O
person	O
and	O
associate	O
the	O
joints	O
over	O
time	O
.	O
	
One	O
of	O
the	O
key	O
challenges	O
in	O
such	O
scenes	O
is	O
that	O
people	O
might	O
overlap	O
and	O
only	O
a	O
subset	O
of	O
joints	O
of	O
the	O
person	O
might	O
be	O
visible	O
in	O
each	O
frame	O
either	O
due	O
to	O
person	O
-	O
person	O
occlusion	O
or	O
truncation	O
by	O
image	O
boundaries	O
(	O
.	O
	
Fig	O
.	O
	
[	O
reference	O
]	O
)	O
.	O
	
Arguably	O
,	O
resolving	O
such	O
cases	O
correctly	O
requires	O
reasoning	O
beyond	O
purely	O
geometric	O
information	O
on	O
the	O
arrangement	O
of	O
body	O
joints	O
in	O
the	O
image	O
,	O
and	O
requires	O
incorporation	O
of	O
a	O
variety	O
of	O
image	O
cues	O
and	O
joint	B-Method
modeling	I-Method
of	O
several	O
persons	O
.	O
	
The	O
design	O
of	O
our	O
model	O
is	O
motivated	O
by	O
two	O
factors	O
.	O
	
We	O
would	O
like	O
to	O
leverage	O
bottom	O
-	O
up	O
end	B-Method
-	I-Method
to	I-Method
-	I-Method
end	I-Method
learning	I-Method
to	O
directly	O
capture	O
image	O
information	O
.	O
	
At	O
the	O
same	O
time	O
we	O
aim	O
to	O
address	O
a	O
complex	O
multi	B-Task
-	I-Task
person	I-Task
articulated	I-Task
tracking	I-Task
problem	I-Task
that	O
does	O
not	O
naturally	O
lend	O
itself	O
to	O
an	O
end	B-Task
-	I-Task
to	I-Task
-	I-Task
end	I-Task
prediction	I-Task
task	I-Task
and	O
for	O
which	O
training	O
data	O
is	O
not	O
available	O
in	O
the	O
amounts	O
usually	O
required	O
for	O
end	O
-	O
to	O
-	O
end	B-Method
learning	I-Method
.	O
	
To	O
leverage	O
the	O
available	O
image	O
information	O
we	O
learn	O
a	O
model	O
for	O
associating	O
a	O
body	O
joint	O
to	O
a	O
specific	O
person	O
in	O
an	O
end	O
-	O
to	O
-	O
end	O
fashion	O
relying	O
on	O
a	O
convolutional	B-Method
network	I-Method
.	O
	
We	O
then	O
incorporate	O
these	O
part	O
-	O
to	O
-	O
person	O
association	O
responses	O
into	O
a	O
framework	O
for	O
jointly	B-Task
reasoning	I-Task
about	I-Task
assignment	I-Task
of	I-Task
body	I-Task
joints	I-Task
within	O
the	O
image	O
and	O
over	O
time	O
.	O
	
To	O
that	O
end	O
we	O
use	O
the	O
graph	B-Method
partitioning	I-Method
formulation	I-Method
that	O
has	O
been	O
used	O
for	O
people	B-Task
tracking	I-Task
and	I-Task
pose	I-Task
estimation	I-Task
in	O
the	O
past	O
,	O
but	O
has	O
not	O
been	O
shown	O
to	O
enable	O
articulated	B-Task
people	I-Task
tracking	I-Task
.	O
	
To	O
facilitate	O
efficient	O
inference	B-Task
in	O
video	B-Task
we	O
resort	O
to	O
fast	O
inference	B-Method
methods	I-Method
based	O
on	O
local	B-Method
combinatorial	I-Method
optimization	I-Method
and	O
aim	O
for	O
a	O
sparse	B-Method
model	I-Method
that	O
keeps	O
the	O
number	O
of	O
connections	O
between	O
variables	O
to	O
a	O
minimum	O
.	O
	
As	O
we	O
demonstrate	O
,	O
in	O
combination	O
with	O
feed	B-Method
-	I-Method
forward	I-Method
reasoning	I-Method
for	O
joint	B-Task
-	I-Task
to	I-Task
-	I-Task
person	I-Task
association	I-Task
this	O
allows	O
us	O
to	O
achieve	O
substantial	O
speed	O
-	O
ups	O
compared	O
to	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
while	O
maintaining	O
the	O
same	O
level	O
of	O
accuracy	B-Metric
.	O
	
The	O
main	O
contribution	O
of	O
this	O
work	O
is	O
a	O
new	O
articulated	B-Method
tracking	I-Method
model	I-Method
that	O
operates	O
by	O
bottom	O
-	O
up	O
assembly	O
of	O
part	B-Method
detections	I-Method
within	O
each	O
frame	O
and	O
over	O
time	O
.	O
	
In	O
contrast	O
to	O
this	O
model	O
is	O
suitable	O
for	O
scenes	O
with	O
an	O
unknown	O
number	O
of	O
subjects	O
and	O
reasons	O
jointly	O
across	O
multiple	O
people	O
incorporating	O
inter	O
-	O
person	O
exclusion	O
constraints	O
and	O
propagating	O
strong	O
observations	O
to	O
neighboring	O
frames	O
.	O
	
Our	O
second	O
contribution	O
is	O
a	O
formulation	O
for	O
single	B-Task
-	I-Task
frame	I-Task
pose	I-Task
estimation	I-Task
that	O
relies	O
on	O
a	O
sparse	B-Method
graph	I-Method
between	O
body	O
parts	O
and	O
a	O
mechanism	O
for	O
generating	O
body	B-Task
-	I-Task
part	I-Task
proposals	I-Task
conditioned	O
on	O
a	O
person	O
’s	O
location	O
.	O
	
This	O
is	O
in	O
contrast	O
to	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
approaches	O
that	O
perform	O
expensive	B-Task
inference	I-Task
in	O
a	O
full	O
graph	O
and	O
rely	O
on	O
generic	B-Method
bottom	I-Method
-	I-Method
up	I-Method
proposals	I-Method
.	O
	
We	O
demonstrate	O
that	O
a	O
sparse	B-Method
model	I-Method
with	O
a	O
few	O
spatial	O
edges	O
performs	O
competitively	O
with	O
a	O
fully	B-Method
-	I-Method
connected	I-Method
model	I-Method
while	O
being	O
much	O
more	O
efficient	O
.	O
	
Notably	O
,	O
a	O
simple	O
model	O
that	O
operates	O
in	O
top	B-Method
-	I-Method
down	I-Method
/	I-Method
bottom	I-Method
-	I-Method
up	I-Method
fashion	I-Method
exceeds	O
the	O
performance	O
of	O
a	O
fully	B-Method
-	I-Method
connected	I-Method
model	I-Method
while	O
being	O
x	O
faster	O
at	O
inference	O
time	O
(	O
cf	O
.	O
	
Tab	O
.	O
	
[	O
reference	O
]	O
)	O
.	O
	
This	O
is	O
due	O
to	O
offloading	O
of	O
a	O
large	O
share	O
of	O
the	O
reasoning	O
about	O
body	B-Task
-	I-Task
part	I-Task
association	I-Task
onto	O
a	O
feed	B-Method
-	I-Method
forward	I-Method
convolutional	I-Method
architecture	I-Method
.	O
	
Finally	O
,	O
we	O
contribute	O
a	O
new	O
challenging	O
dataset	O
for	O
evaluation	O
of	O
articulated	B-Task
body	I-Task
joint	I-Task
tracking	I-Task
in	O
crowded	O
realistic	O
environments	O
with	O
multiple	O
overlapping	O
people	O
.	O
	
Related	O
work	O
.	O
	
Convolutional	B-Method
networks	I-Method
have	O
emerged	O
as	O
an	O
effective	O
approach	O
to	O
localizing	B-Task
body	I-Task
joints	I-Task
of	I-Task
people	I-Task
in	I-Task
images	I-Task
and	O
have	O
also	O
been	O
extended	O
for	O
joint	B-Task
estimation	I-Task
of	I-Task
body	I-Task
configurations	I-Task
over	I-Task
time	I-Task
,	O
and	O
3D	B-Task
pose	I-Task
estimation	I-Task
in	O
outdoor	B-Task
environments	I-Task
in	O
multi	B-Task
-	I-Task
camera	I-Task
setting	I-Task
.	O
	
Current	O
approaches	O
are	O
increasingly	O
effective	O
for	O
estimating	B-Task
body	I-Task
configurations	I-Task
of	I-Task
single	I-Task
people	I-Task
achieving	O
high	O
accuracies	B-Metric
on	O
this	O
task	O
,	O
but	O
are	O
still	O
failing	O
on	O
fast	O
moving	O
and	O
articulated	O
limbs	O
.	O
	
More	O
complex	O
recent	O
models	O
jointly	O
reason	O
about	O
entire	O
scenes	O
,	O
but	O
are	O
too	O
complex	O
and	O
inefficient	O
to	O
directly	O
generalize	O
to	O
image	O
sequences	O
.	O
	
Recent	O
feed	B-Method
-	I-Method
forward	I-Method
models	I-Method
are	O
able	O
to	O
jointly	O
infer	O
body	O
joints	O
of	O
the	O
same	O
person	O
and	O
even	O
operate	O
over	O
time	O
but	O
consider	O
isolated	O
persons	O
only	O
and	O
do	O
not	O
generalize	O
to	O
the	O
case	O
of	O
multiple	O
overlapping	O
people	O
.	O
	
Similarly	O
,	O
consider	O
a	O
simplified	O
task	O
of	O
tracking	B-Task
upper	I-Task
body	I-Task
poses	I-Task
of	I-Task
isolated	I-Task
upright	I-Task
individuals	I-Task
.	O
	
We	O
build	O
on	O
recent	O
CNN	B-Method
detectors	I-Method
that	O
are	O
effective	O
in	O
localizing	B-Task
body	I-Task
joints	I-Task
in	O
cluttered	O
scenes	O
and	O
explore	O
different	O
mechanisms	O
for	O
assembling	O
the	O
joints	O
into	O
multiple	O
person	O
configurations	O
.	O
	
To	O
that	O
end	O
we	O
rely	O
on	O
a	O
graph	B-Method
partitioning	I-Method
approach	I-Method
closely	O
related	O
to	O
.	O
	
In	O
contrast	O
to	O
who	O
focus	O
on	O
pedestrian	B-Task
tracking	I-Task
,	O
and	O
who	O
perform	O
single	B-Task
frame	I-Task
multi	I-Task
-	I-Task
person	I-Task
pose	I-Task
estimation	I-Task
,	O
we	O
solve	O
a	O
more	O
complex	O
problem	O
of	O
articulated	B-Task
multi	I-Task
-	I-Task
person	I-Task
pose	I-Task
tracking	I-Task
.	O
	
Earlier	O
approaches	O
to	O
articulated	B-Task
pose	I-Task
tracking	I-Task
in	O
monocular	O
videos	O
rely	O
on	O
hand	B-Method
-	I-Method
crafted	I-Method
image	I-Method
representations	I-Method
and	O
focus	O
on	O
simplified	B-Task
tasks	I-Task
,	O
such	O
as	O
tracking	B-Task
upper	I-Task
body	I-Task
poses	I-Task
of	I-Task
frontal	I-Task
isolated	I-Task
people	I-Task
,	O
or	O
tracking	B-Task
walking	I-Task
pedestrians	I-Task
with	O
little	O
degree	O
of	O
articulation	O
.	O
	
In	O
contrast	O
,	O
we	O
address	O
a	O
harder	O
problem	O
of	O
multi	B-Task
-	I-Task
person	I-Task
articulated	I-Task
pose	I-Task
tracking	I-Task
and	O
do	O
not	O
make	O
assumptions	O
about	O
the	O
type	O
of	O
body	O
motions	O
or	O
activities	O
of	O
people	O
.	O
	
Our	O
approach	O
is	O
closely	O
related	O
to	O
who	O
propose	O
a	O
similar	O
formulation	O
based	O
on	O
graph	B-Method
partitioning	I-Method
.	O
	
Our	O
approach	O
differs	O
from	O
primarily	O
in	O
the	O
type	O
of	O
body	B-Task
-	I-Task
part	I-Task
proposals	I-Task
and	O
the	O
structure	O
of	O
the	O
spatio	O
-	O
temporal	O
graph	O
.	O
	
In	O
our	O
approach	O
we	O
introduce	O
a	O
person	B-Method
-	I-Method
conditioned	I-Method
model	I-Method
that	O
is	O
trained	O
to	O
associate	O
body	O
parts	O
of	O
a	O
specific	O
person	O
already	O
at	O
the	O
detection	B-Task
stage	I-Task
.	O
	
This	O
is	O
in	O
contrast	O
to	O
the	O
approach	O
of	O
that	O
relies	O
on	O
the	O
generic	B-Method
body	I-Method
-	I-Method
part	I-Method
detectors	I-Method
.	O
	
Overview	O
.	O
	
Our	O
model	O
consists	O
of	O
the	O
two	O
components	O
:	O
(	O
1	O
)	O
a	O
convolutional	B-Method
network	I-Method
for	O
generating	O
body	B-Task
part	I-Task
proposals	I-Task
and	O
(	O
2	O
)	O
an	O
approach	O
to	O
group	O
the	O
proposals	O
into	O
spatio	O
-	O
temporal	O
clusters	O
.	O
	
In	O
Sec	O
.	O
	
[	O
reference	O
]	O
	
we	O
introduce	O
a	O
general	O
formulation	O
for	O
multi	B-Task
-	I-Task
target	I-Task
tracking	I-Task
that	O
follows	O
and	O
allows	O
us	O
to	O
define	O
pose	B-Task
estimation	I-Task
and	O
articulated	B-Task
tracking	I-Task
in	O
a	O
unified	O
framework	O
.	O
	
We	O
then	O
describe	O
the	O
details	O
of	O
our	O
articulated	B-Method
tracking	I-Method
approach	I-Method
in	O
Sec	O
.	O
	
[	O
reference	O
]	O
,	O
and	O
introduce	O
two	O
variants	O
of	O
our	O
formulation	O
:	O
bottom	O
-	O
up	O
(	O
BU	B-Method
)	O
and	O
top	O
-	O
down	O
/	O
bottom	O
-	O
up	O
(	O
TD	B-Method
/	O
BU	B-Method
)	O
.	O
	
We	O
present	O
experimental	O
results	O
in	O
Sec	O
.	O
	
[	O
reference	O
]	O
.	O
	
section	O
:	O
Tracking	B-Task
by	O
Spatio	B-Method
-	I-Method
temporal	I-Method
Grouping	I-Method
	
Our	O
body	B-Method
part	I-Method
detector	I-Method
generates	O
a	O
set	O
of	O
proposals	O
for	O
each	O
frame	O
of	O
the	O
video	O
.	O
	
Each	O
proposal	O
is	O
given	O
by	O
,	O
where	O
denotes	O
the	O
index	O
of	O
the	O
video	O
frame	O
,	O
is	O
the	O
spatial	O
location	O
of	O
the	O
proposal	O
in	O
image	O
coordinates	O
,	O
is	O
the	O
probability	O
of	O
correct	O
detection	B-Task
,	O
and	O
is	O
the	O
type	O
of	O
the	O
body	O
joint	O
(	O
ankle	O
or	O
shoulder	O
)	O
.	O
	
Let	O
be	O
a	O
graph	O
whose	O
nodes	O
are	O
the	O
joint	O
detections	O
in	O
a	O
video	O
and	O
whose	O
edges	O
connect	O
pairs	O
of	O
detections	O
that	O
hypothetically	O
correspond	O
to	O
the	O
same	O
target	O
.	O
	
The	O
output	O
of	O
the	O
tracking	B-Method
algorithm	I-Method
is	O
a	O
subgraph	O
of	O
,	O
where	O
is	O
a	O
subset	O
of	O
nodes	O
after	O
filtering	O
redundant	O
and	O
erroneous	O
detections	O
and	O
are	O
edges	O
linking	O
nodes	O
corresponding	O
to	O
the	O
same	O
target	O
.	O
	
We	O
specify	O
via	O
binary	O
variables	O
and	O
that	O
define	O
subsets	O
of	O
edges	O
and	O
nodes	O
included	O
in	O
.	O
	
In	O
particular	O
each	O
track	O
will	O
correspond	O
to	O
a	O
connected	O
component	O
in	O
.	O
	
As	O
a	O
general	O
way	O
to	O
introduce	O
constraints	O
on	O
edge	O
configurations	O
that	O
correspond	O
to	O
a	O
valid	O
tracking	B-Task
solution	I-Task
we	O
introduce	O
a	O
set	O
and	O
define	O
a	O
combination	O
of	O
edge	O
and	O
node	O
indicator	O
variables	O
to	O
be	O
feasible	O
if	O
and	O
only	O
if	O
.	O
	
An	O
example	O
of	O
a	O
constraint	O
encoded	O
through	O
is	O
that	O
endpoint	O
nodes	O
of	O
an	O
edge	O
included	O
by	O
must	O
also	O
be	O
included	O
by	O
.	O
	
Note	O
that	O
the	O
variables	O
and	O
are	O
coupled	O
though	O
.	O
	
Moreover	O
,	O
assuming	O
that	O
we	O
are	O
free	O
to	O
set	O
components	O
of	O
and	O
independently	O
to	O
maximize	O
the	O
tracking	B-Metric
objective	I-Metric
.	O
	
Given	O
image	O
observations	O
we	O
compute	O
a	O
set	O
of	O
features	O
for	O
each	O
node	O
and	O
edge	O
in	O
the	O
graph	O
.	O
	
We	O
denote	O
such	O
node	O
and	O
edge	O
features	O
as	O
and	O
respectively	O
.	O
	
Assuming	O
independence	O
of	O
the	O
feature	O
vectors	O
the	O
conditional	O
probability	O
of	O
indicator	O
functions	O
of	O
nodes	O
and	O
of	O
edges	O
given	O
features	O
and	O
and	O
given	O
a	O
feasible	O
set	O
is	O
given	O
by	O
where	O
assigns	O
a	O
constant	O
non	O
-	O
zero	O
probability	O
to	O
every	O
feasible	O
solution	O
and	O
is	O
equal	O
to	O
zero	O
otherwise	O
.	O
	
Minimizing	O
the	O
negative	O
log	O
-	O
likelihood	O
of	O
Eq	O
.	O
	
[	O
reference	O
]	O
is	O
equivalent	O
to	O
solving	O
the	O
following	O
integer	B-Task
-	I-Task
linear	I-Task
program	I-Task
:	O
where	O
is	O
the	O
cost	O
of	O
retaining	O
as	O
part	O
of	O
the	O
solution	O
,	O
and	O
is	O
the	O
cost	O
of	O
assigning	O
the	O
detections	O
linked	O
by	O
an	O
edge	O
to	O
the	O
same	O
track	O
.	O
	
We	O
define	O
the	O
set	O
of	O
constraints	O
as	O
in	O
:	O
Jointly	O
with	O
the	O
objective	O
in	O
Eq	O
.	O
	
[	O
reference	O
]	O
the	O
constraints	O
(	O
[	O
reference	O
]	O
)	O
-	O
(	O
[	O
reference	O
]	O
)	O
define	O
an	O
instance	O
of	O
the	O
minimum	B-Task
cost	I-Task
subgraph	I-Task
multicut	I-Task
problem	I-Task
.	O
	
The	O
constraints	O
(	O
[	O
reference	O
]	O
)	O
and	O
(	O
[	O
reference	O
]	O
)	O
ensure	O
that	O
assignment	O
of	O
node	O
and	O
edge	O
variables	O
is	O
consistent	O
.	O
	
The	O
constraint	O
(	O
[	O
reference	O
]	O
)	O
ensures	O
that	O
for	O
every	O
two	O
nodes	O
either	O
all	O
or	O
none	O
of	O
the	O
paths	O
between	O
these	O
nodes	O
in	O
graph	O
are	O
contained	O
in	O
one	O
of	O
the	O
connected	O
components	O
of	O
subgraph	O
.	O
	
This	O
constraint	O
is	O
necessary	O
to	O
unambigously	O
assign	O
person	O
identity	O
to	O
a	O
body	O
part	O
proposal	O
based	O
on	O
its	O
membership	O
in	O
a	O
specific	O
connnected	O
component	O
of	O
.	O
	
section	O
:	O
Articulated	B-Method
Multi	I-Method
-	I-Method
person	I-Method
Tracking	I-Method
	
In	O
Sec	O
.	O
	
[	O
reference	O
]	O
	
we	O
introduced	O
a	O
general	O
framework	O
for	O
multi	B-Task
-	I-Task
object	I-Task
tracking	I-Task
by	O
solving	O
an	O
instance	O
of	O
the	O
subgraph	B-Task
multicut	I-Task
problem	I-Task
.	O
	
The	O
subgraph	B-Task
multicut	I-Task
problem	I-Task
is	O
NP	O
-	O
hard	O
,	O
but	O
recent	O
work	O
has	O
shown	O
that	O
efficient	O
approximate	B-Task
inference	I-Task
is	O
possible	O
with	O
local	B-Method
search	I-Method
methods	I-Method
.	O
	
The	O
framework	O
allows	O
for	O
a	O
variety	O
of	O
graphs	O
and	O
connectivity	O
patterns	O
.	O
	
Simpler	O
connectivity	B-Method
allows	O
for	O
faster	O
and	O
more	O
efficient	O
processing	B-Task
at	O
the	O
cost	O
of	O
ignoring	O
some	O
of	O
the	O
potentially	O
informative	O
dependencies	O
between	O
model	O
variables	O
.	O
	
Our	O
goal	O
is	O
to	O
design	O
a	O
model	O
that	O
is	O
efficient	O
,	O
with	O
as	O
few	O
edges	O
as	O
possible	O
,	O
yet	O
effective	O
in	O
crowded	O
scenes	O
,	O
and	O
that	O
allows	O
us	O
to	O
model	O
temporal	O
continuity	O
and	O
inter	O
-	O
person	O
exclusion	O
.	O
	
Our	O
articulated	B-Method
tracking	I-Method
approach	I-Method
proceeds	O
by	O
constructing	O
a	O
graph	B-Method
that	O
couples	O
body	O
part	O
proposals	O
within	O
the	O
same	O
frame	O
and	O
across	O
neighboring	O
frames	O
.	O
	
In	O
general	O
the	O
graph	O
will	O
have	O
three	O
types	O
of	O
edges	O
:	O
(	O
1	O
)	O
cross	O
-	O
type	O
edges	O
shown	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
(	O
a	O
)	O
and	O
Fig	O
.	O
	
[	O
reference	O
]	O
	
(	O
b	O
)	O
that	O
connect	O
two	O
parts	O
of	O
different	O
types	O
,	O
(	O
2	O
)	O
same	O
-	O
type	O
edges	O
shown	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
	
(	O
b	O
)	O
that	O
connect	O
two	O
nodes	O
of	O
the	O
same	O
type	O
in	O
the	O
same	O
image	O
,	O
and	O
(	O
3	O
)	O
temporal	O
edges	O
shown	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
	
(	O
c	O
)	O
that	O
connect	O
nodes	O
in	O
the	O
neighboring	O
frames	O
.	O
	
We	O
now	O
define	O
two	O
variants	O
of	O
our	O
model	O
that	O
we	O
denote	O
as	O
Bottom	O
-	O
Up	O
(	O
BU	B-Method
)	O
and	O
Top	O
-	O
Down	O
	
/	O
Bottom	O
-	O
Up	O
(	O
TD	B-Method
/	O
BU	B-Method
)	O
.	O
	
In	O
the	O
BU	B-Method
model	I-Method
the	O
body	O
part	O
proposals	O
are	O
generated	O
with	O
our	O
publicly	O
available	O
convolutional	B-Method
part	I-Method
detector	I-Method
.	O
	
In	O
the	O
TD	B-Method
/	O
BU	B-Method
model	O
we	O
substitute	O
these	O
generic	B-Method
part	I-Method
detectors	I-Method
with	O
a	O
new	O
convolutional	B-Method
body	I-Method
-	I-Method
part	I-Method
detector	I-Method
that	O
is	O
trained	O
to	O
output	O
consistent	O
body	O
configurations	O
conditioned	O
on	O
the	O
person	O
location	O
.	O
	
This	O
alows	O
to	O
further	O
reduce	O
the	O
complexity	B-Metric
of	O
the	O
model	B-Method
graph	I-Method
since	O
the	O
task	O
of	O
associating	B-Task
body	I-Task
parts	I-Task
is	O
addressed	O
within	O
the	O
proposal	B-Method
mechanism	I-Method
.	O
	
As	O
we	O
show	O
in	O
Sec	O
.	O
	
[	O
reference	O
]	O
	
this	O
leads	O
to	O
considerable	O
gains	O
in	O
performance	O
and	O
allows	O
for	O
faster	O
inference	B-Task
.	O
	
Note	O
that	O
the	O
BU	B-Method
and	O
TD	B-Method
/	O
BU	B-Method
models	O
have	O
identical	O
same	O
-	O
type	O
and	O
temporal	O
pairwise	O
terms	O
,	O
but	O
differ	O
in	O
the	O
form	O
of	O
cross	O
-	O
type	O
pairwise	O
terms	O
,	O
and	O
the	O
connectivity	O
of	O
the	O
nodes	O
in	O
.	O
	
For	O
both	O
models	O
we	O
rely	O
on	O
the	O
solver	B-Method
from	O
for	O
inference	B-Task
.	O
	
subsection	O
:	O
Bottom	B-Method
-	I-Method
Up	I-Method
Model	I-Method
(	O
BU	B-Method
)	O
.	O
	
For	O
each	O
body	O
part	O
proposal	O
the	O
detector	O
outputs	O
image	O
location	O
,	O
probability	O
of	O
detection	B-Task
,	O
and	O
a	O
label	O
that	O
indicates	O
the	O
type	O
of	O
the	O
detected	O
part	O
(	O
shoulder	O
or	O
ankle	O
)	O
.	O
	
We	O
directly	O
use	O
the	O
probability	O
of	O
detection	O
to	O
derive	O
the	O
unary	O
costs	O
in	O
Eq	O
.	O
	
[	O
reference	O
]	O
as	O
.	O
	
Image	O
features	O
in	O
this	O
case	O
correspond	O
to	O
the	O
image	B-Method
representation	I-Method
generated	O
by	O
the	O
convolutional	B-Method
network	I-Method
.	O
	
We	O
consider	O
two	O
connectivity	O
patterns	O
for	O
nodes	O
in	O
the	O
graph	O
.	O
	
We	O
either	O
define	O
edges	O
for	O
every	O
pair	O
of	O
proposals	O
which	O
results	O
in	O
a	O
fully	O
connected	O
graph	O
in	O
each	O
image	O
.	O
	
Alternatively	O
we	O
obtain	O
a	O
sparse	B-Method
version	I-Method
of	O
the	O
model	O
by	O
defining	O
edges	O
for	O
a	O
subset	O
of	O
part	O
types	O
only	O
as	O
is	O
shown	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
(	O
a	O
)	O
.	O
	
The	O
rationale	O
behind	O
the	O
sparse	B-Method
version	I-Method
is	O
to	O
obtain	O
a	O
simpler	O
and	O
faster	O
version	O
of	O
the	O
model	O
by	O
omitting	O
edges	O
between	O
parts	O
that	O
carry	O
little	O
information	O
about	O
each	O
other	O
’s	O
image	O
location	O
(	O
left	O
ankle	O
and	O
right	O
arm	O
)	O
.	O
	
Edge	B-Metric
costs	I-Metric
.	O
	
In	O
our	O
Bottom	B-Method
-	I-Method
Up	I-Method
model	I-Method
the	O
cost	O
of	O
the	O
edges	O
connecting	O
two	O
body	O
part	O
detections	O
and	O
is	O
defined	O
as	O
a	O
function	O
of	O
the	O
detection	O
types	O
and	O
.	O
	
Following	O
we	O
thus	O
train	O
for	O
each	O
pair	O
of	O
part	O
types	O
a	O
regression	B-Method
function	I-Method
that	O
predicts	O
relative	O
image	O
location	O
of	O
the	O
parts	O
in	O
the	O
pair	O
.	O
	
The	O
cost	O
is	O
given	O
by	O
the	O
output	O
of	O
the	O
logistic	B-Method
regression	I-Method
given	O
the	O
features	O
computed	O
from	O
offset	O
and	O
angle	O
of	O
the	O
predicted	O
and	O
actual	O
location	O
of	O
the	O
other	O
joint	O
in	O
the	O
pair	O
.	O
	
We	O
refer	O
to	O
for	O
more	O
details	O
on	O
these	O
pairwise	O
terms	O
.	O
	
Note	O
that	O
our	O
model	O
generalizes	O
in	O
that	O
the	O
edge	B-Metric
cost	I-Metric
depends	O
on	O
the	O
type	O
of	O
nodes	O
linked	O
by	O
the	O
edge	O
.	O
	
It	O
also	O
generalizes	O
by	O
allowing	O
to	O
be	O
sparse	O
.	O
	
This	O
is	O
achieved	O
by	O
reformulating	O
the	O
model	O
with	O
a	O
more	O
general	O
type	O
of	O
cycle	O
constraint	O
(	O
[	O
reference	O
]	O
)	O
,	O
in	O
contrast	O
to	O
simple	O
triangle	O
inequalities	O
used	O
in	O
.	O
	
subsection	O
:	O
Top	B-Method
-	I-Method
Down	I-Method
/	I-Method
Bottom	I-Method
-	I-Method
up	I-Method
Model	I-Method
(	O
TD	B-Method
/	O
BU	B-Method
)	O
	
We	O
now	O
introduce	O
a	O
version	O
of	O
our	O
model	O
that	O
operates	O
by	O
first	O
generating	O
body	O
part	O
proposals	O
conditioned	O
on	O
the	O
locations	O
of	O
people	O
in	O
the	O
image	O
and	O
then	O
performing	O
joint	B-Method
reasoning	I-Method
to	O
group	O
these	O
proposals	O
into	O
spatio	O
-	O
temporal	O
clusters	O
corresponding	O
to	O
different	O
people	O
.	O
	
We	O
follow	O
the	O
intuition	O
that	O
it	O
is	O
considerably	O
easier	O
to	O
identify	O
and	O
detect	O
individual	O
people	O
(	O
e.g.	O
by	O
detecting	O
their	O
heads	O
)	O
compared	O
to	O
correctly	O
associating	O
body	O
parts	O
such	O
as	O
ankles	O
and	O
wrists	O
to	O
each	O
person	O
.	O
	
We	O
select	O
person	O
’s	O
head	O
as	O
a	O
root	O
part	O
that	O
is	O
responsible	O
for	O
representing	O
the	O
person	O
location	O
,	O
and	O
delegate	O
the	O
task	O
of	O
identifying	B-Task
body	I-Task
parts	I-Task
of	O
the	O
person	O
corresponding	O
to	O
a	O
head	O
location	O
to	O
a	O
convolutional	B-Method
network	I-Method
.	O
	
The	O
structure	O
of	O
TD	B-Method
/	O
BU	B-Method
model	O
is	O
illustrated	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
	
(	O
b	O
)	O
for	O
the	O
simplified	O
case	O
of	O
two	O
distinct	O
head	O
detections	O
.	O
	
Let	O
us	O
denote	O
the	O
set	O
of	O
all	O
root	O
part	O
detections	O
as	O
.	O
	
For	O
each	O
pair	O
of	O
the	O
root	O
nodes	O
we	O
explicitly	O
set	O
the	O
corresponding	O
edge	O
indicator	O
variables	O
.	O
	
This	O
implements	O
a	O
“	O
must	O
-	O
not	O
-	O
link	O
”	O
constraint	O
between	O
these	O
nodes	O
,	O
and	O
in	O
combination	O
with	O
the	O
cycle	O
inequality	O
(	O
[	O
reference	O
]	O
)	O
implies	O
that	O
each	O
proposal	O
can	O
be	O
connected	O
to	O
one	O
of	O
the	O
“	O
person	O
nodes	O
”	O
only	O
.	O
	
The	O
cost	O
for	O
an	O
edge	O
connecting	O
detection	O
proposal	O
and	O
a	O
“	O
person	O
node	O
”	O
is	O
based	O
on	O
the	O
conditional	O
distribution	O
generated	O
by	O
the	O
convolutional	B-Method
network	I-Method
.	O
	
The	O
output	O
of	O
such	O
network	O
is	O
a	O
set	O
of	O
conditional	O
distributions	O
,	O
one	O
for	O
each	O
node	O
type	O
.	O
	
We	O
augment	O
the	O
graph	O
with	O
attractive	O
/	O
repulsive	O
and	O
temporal	O
terms	O
as	O
described	O
in	O
Sec	O
.	O
	
[	O
reference	O
]	O
and	O
Sec	O
.	O
	
[	O
reference	O
]	O
and	O
set	O
the	O
unary	O
costs	O
for	O
all	O
indicator	O
variables	O
to	O
a	O
constant	O
.	O
	
Any	O
proposal	O
not	O
connected	O
to	O
any	O
of	O
the	O
root	O
nodes	O
is	O
excluded	O
from	O
the	O
final	O
solution	O
.	O
	
We	O
use	O
the	O
solver	O
from	O
for	O
consistency	B-Task
,	O
but	O
a	O
simpler	O
KL	B-Method
-	I-Method
based	I-Method
solver	I-Method
as	O
in	O
could	O
be	O
used	O
as	O
well	O
since	O
the	O
TD	B-Method
/	O
BU	B-Method
model	O
effectively	O
ignores	O
the	O
unary	O
variables	O
.	O
	
The	O
processing	B-Method
stages	I-Method
of	O
TD	B-Method
/	O
BU	B-Method
model	O
are	O
shown	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
.	O
	
Note	O
that	O
the	O
body	O
-	O
part	O
heatmaps	O
change	O
depending	O
on	O
the	O
person	O
-	O
identity	O
signal	O
provided	O
by	O
the	O
person	O
’s	O
neck	O
,	O
and	O
that	O
the	O
bottom	O
-	O
up	O
step	O
was	O
able	O
to	O
correct	O
the	O
predictions	O
on	O
the	O
forearms	O
of	O
the	O
front	O
person	O
.	O
	
Implementation	O
details	O
.	O
	
For	O
head	B-Task
detection	I-Task
,	O
we	O
use	O
a	O
version	O
of	O
our	O
model	O
that	O
contains	O
the	O
two	O
head	O
parts	O
(	O
neck	O
and	O
head	O
top	O
)	O
.	O
	
This	O
makes	O
our	O
TD	B-Method
/	O
BU	B-Method
model	O
related	O
to	O
the	O
hierarchical	B-Method
model	I-Method
defined	O
in	O
that	O
also	O
uses	O
easier	O
-	O
to	O
-	O
detect	O
parts	O
to	O
guide	O
the	O
rest	O
of	O
the	O
inference	B-Task
process	I-Task
.	O
	
However	O
here	O
we	O
replace	O
all	O
the	O
stages	O
in	O
the	O
hierarchical	B-Task
inference	I-Task
except	O
the	O
first	O
one	O
with	O
a	O
convolutional	B-Method
network	I-Method
.	O
	
The	O
structure	O
of	O
the	O
convolutional	B-Method
network	I-Method
used	O
to	O
generate	O
person	O
-	O
conditioned	O
proposals	O
is	O
shown	O
on	O
Fig	O
.	O
	
[	O
reference	O
]	O
.	O
	
The	O
network	O
uses	O
the	O
ResNet	O
-	O
101	O
from	O
that	O
we	O
modify	O
to	O
bring	O
the	O
stride	O
of	O
the	O
network	O
down	O
to	O
8	O
pixels	O
.	O
	
The	O
network	O
generates	O
predictions	O
for	O
all	O
body	O
parts	O
after	O
the	O
conv4_4	O
block	O
.	O
	
We	O
use	O
the	O
cross	B-Metric
-	I-Metric
entropy	I-Metric
binary	I-Metric
classification	I-Metric
loss	I-Metric
at	O
this	O
stage	O
to	O
predict	O
the	O
part	O
heatmaps	O
.	O
	
At	O
each	O
training	O
iteration	O
we	O
forward	O
pass	O
an	O
image	O
with	O
multiple	O
people	O
potentially	O
in	O
close	O
proximity	O
to	O
each	O
other	O
.	O
	
We	O
select	O
a	O
single	O
person	O
from	O
the	O
image	O
and	O
condition	O
the	O
network	O
on	O
the	O
person	O
’s	O
neck	O
location	O
by	O
zeroing	O
out	O
the	O
heatmap	O
of	O
the	O
neck	O
joint	O
outside	O
the	O
ground	O
-	O
truth	O
region	O
.	O
	
We	O
then	O
pass	O
the	O
neck	O
heatmap	O
through	O
a	O
convolutional	B-Method
layer	I-Method
to	O
match	O
the	O
dimensionality	O
of	O
the	O
feature	O
channels	O
and	O
add	O
them	O
to	O
the	O
main	O
stream	O
of	O
the	O
ResNet	B-Method
.	O
	
We	O
finally	O
add	O
a	O
joint	B-Method
prediction	I-Method
layer	I-Method
at	O
the	O
end	O
of	O
the	O
network	O
with	O
a	O
loss	O
that	O
considers	O
predictions	O
to	O
be	O
correct	O
only	O
if	O
they	O
correspond	O
to	O
the	O
body	O
joints	O
of	O
the	O
selected	O
person	O
.	O
	
Spatial	B-Method
propagation	I-Method
(	O
SP	B-Method
)	O
.	O
	
In	O
our	O
network	O
the	O
person	O
identity	O
signal	O
is	O
provided	O
by	O
the	O
location	O
of	O
the	O
head	O
.	O
	
In	O
principle	O
the	O
receptive	O
field	O
size	O
of	O
the	O
network	O
is	O
large	O
enough	O
to	O
propagate	O
this	O
signal	O
to	O
all	O
body	O
parts	O
.	O
	
However	O
we	O
found	O
that	O
it	O
is	O
useful	O
to	O
introduce	O
an	O
additional	O
mechanism	O
to	O
propagate	O
the	O
person	O
identity	O
signal	O
.	O
	
To	O
that	O
end	O
we	O
inject	O
intermediate	O
supervision	O
layers	O
for	O
individual	O
body	O
parts	O
arranged	O
in	O
the	O
order	O
of	O
kinematic	O
proximity	O
to	O
the	O
root	O
joint	O
(	O
Fig	O
.	O
	
[	O
reference	O
]	O
)	O
.	O
	
We	O
place	O
prediction	B-Method
layers	I-Method
for	O
shoulders	O
at	O
conv4_8	O
,	O
for	O
elbows	O
and	O
hips	O
at	O
conv4_14	O
and	O
for	O
knees	O
at	O
conv4_18	O
.	O
	
We	O
empirically	O
found	O
that	O
such	O
an	O
explicit	O
form	O
of	O
spatial	B-Method
propagation	I-Method
significantly	O
improves	O
performance	O
on	O
joints	O
such	O
as	O
ankles	O
,	O
that	O
are	O
typically	O
far	O
from	O
the	O
head	O
in	O
the	O
image	O
space	O
(	O
see	O
Tab	O
.	O
	
[	O
reference	O
]	O
for	O
details	O
)	O
.	O
	
Training	O
.	O
	
We	O
use	O
Caffe	B-Method
’s	I-Method
ResNet	I-Method
implementation	I-Method
and	O
initialize	O
from	O
the	O
ImageNet	B-Method
-	I-Method
pre	I-Method
-	I-Method
trained	I-Method
models	I-Method
.	O
	
Networks	O
are	O
trained	O
on	O
the	O
MPII	B-Material
Human	I-Material
Pose	I-Material
dataset	I-Material
with	O
SGD	B-Method
for	O
1	O
M	O
iterations	O
with	O
stepwise	B-Metric
learning	I-Metric
rate	I-Metric
(	O
lr=0.002	B-Method
for	O
400k	O
,	O
	
lr=0.0002	B-Method
for	O
300k	O
and	O
lr=0.0001	O
for	O
300k	O
)	O
.	O
	
subsection	O
:	O
Attractive	O
/	O
Repulsive	O
Edges	O
	
Attractive	O
/	O
repulsive	O
edges	O
are	O
defined	O
between	O
two	O
proposals	O
of	O
the	O
same	O
type	O
within	O
the	O
same	O
image	O
.	O
	
The	O
costs	O
of	O
these	O
edges	O
is	O
inversely	O
-	O
proportional	O
to	O
distance	O
.	O
	
The	O
decision	O
to	O
group	O
two	O
nodes	O
is	O
made	O
based	O
on	O
the	O
evidence	O
from	O
the	O
entire	O
image	O
,	O
which	O
is	O
in	O
contrast	O
to	O
typical	O
non	B-Method
-	I-Method
maximum	I-Method
suppression	I-Method
based	O
on	O
the	O
state	O
of	O
just	O
two	O
detections	O
.	O
	
Inversely	O
,	O
these	O
edges	O
prevent	O
grouping	O
of	O
multiple	O
distant	O
hypothesis	O
of	O
the	O
same	O
type	O
,	O
prevent	O
merging	O
two	O
heads	O
of	O
different	O
people	O
.	O
	
subsection	O
:	O
Temporal	B-Method
Model	I-Method
	
Regardless	O
of	O
the	O
type	O
of	O
within	B-Method
frame	I-Method
model	I-Method
(	O
BU	B-Method
or	O
TD	B-Method
/	O
BU	B-Method
)	O
we	O
rely	O
on	O
the	O
same	O
type	O
of	O
temporal	O
edges	O
that	O
connect	O
nodes	O
of	O
the	O
same	O
type	O
in	O
adjacent	O
frames	O
.	O
	
We	O
derive	O
the	O
costs	O
for	O
such	O
temporal	O
edges	O
via	O
logistic	B-Method
regression	I-Method
.	O
	
Given	O
the	O
feature	O
vector	O
the	O
probability	O
that	O
the	O
two	O
proposals	O
and	O
in	O
adjacent	O
frames	O
correspond	O
to	O
the	O
same	O
body	O
part	O
is	O
given	O
by	O
:	O
,	O
where	O
,	O
and	O
-	O
,	O
is	O
Euclidean	O
distance	O
between	O
the	O
SIFT	O
descriptors	O
computed	O
at	O
and	O
,	O
and	O
and	O
measure	O
the	O
agreement	O
with	O
the	O
dense	O
motion	O
field	O
computed	O
with	O
the	O
DeepMatching	B-Method
approach	I-Method
of	O
.	O
	
For	O
SIFT	O
features	O
we	O
specify	O
the	O
location	O
of	O
the	O
detection	O
proposal	O
,	O
but	O
rely	O
on	O
SIFT	B-Method
to	O
identify	O
the	O
local	O
orientation	O
.	O
	
In	O
cases	O
with	O
multiple	O
local	O
maxima	O
in	O
orientation	B-Task
estimation	I-Task
we	O
compute	O
SIFT	B-Method
descriptor	I-Method
for	O
each	O
orientation	O
and	O
set	O
to	O
the	O
minimal	O
distance	O
among	O
all	O
pairs	O
of	O
descriptors	O
.	O
	
We	O
found	O
that	O
this	O
makes	O
the	O
SIFT	O
distance	O
more	O
robust	O
in	O
the	O
presence	O
of	O
rotations	O
of	O
the	O
body	O
limbs	O
.	O
	
We	O
define	O
the	O
features	O
and	O
as	O
in	O
.	O
	
Let	O
be	O
an	O
squared	O
image	O
region	O
centered	O
on	O
the	O
part	O
proposal	O
.	O
	
We	O
define	O
as	O
a	O
ratio	O
of	O
the	O
number	O
of	O
point	O
correspondences	O
between	O
the	O
regions	O
and	O
and	O
the	O
total	O
number	O
of	O
point	O
correspondences	O
in	O
either	O
of	O
them	O
.	O
	
Specifically	O
,	O
let	O
be	O
a	O
set	O
of	O
point	O
correspondences	O
between	O
the	O
two	O
images	O
computed	O
with	O
DeepMatching	B-Method
,	O
where	O
and	O
and	O
denote	O
the	O
corresponding	O
points	O
in	O
the	O
first	O
and	O
second	O
image	O
respectively	O
.	O
	
Using	O
this	O
notation	O
we	O
define	O
:	O
The	O
rationale	O
behind	O
computing	O
by	O
aggregating	O
across	O
multiple	O
correspondences	O
is	O
to	O
make	O
the	O
feature	O
robust	O
to	O
outliers	O
and	O
to	O
inaccuracies	O
in	O
body	B-Task
part	I-Task
detection	I-Task
.	O
is	O
defined	O
analogously	O
,	O
but	O
using	O
the	O
DeepMatching	O
correspondences	O
obtained	O
by	O
inverting	O
the	O
order	O
of	O
images	O
.	O
	
Discussion	O
.	O
	
As	O
we	O
demonstrate	O
in	O
Sec	O
.	O
	
[	O
reference	O
]	O
	
,	O
we	O
found	O
the	O
set	O
of	O
features	O
described	O
above	O
to	O
be	O
complementary	O
to	O
each	O
other	O
.	O
	
Euclidean	O
distance	O
between	O
proposals	O
is	O
informative	O
for	O
finding	B-Task
correspondences	I-Task
for	O
slow	O
motions	O
,	O
but	O
fails	O
for	O
faster	O
motions	O
and	O
in	O
the	O
presence	O
of	O
multiple	O
people	O
.	O
	
DeepMatching	B-Method
is	O
usually	O
effective	O
in	O
finding	O
corresponding	B-Task
regions	I-Task
between	O
the	O
two	O
images	O
,	O
but	O
occasionally	O
fails	O
in	O
the	O
case	O
of	O
sudden	O
background	O
changes	O
due	O
to	O
fast	O
motion	O
or	O
large	O
changes	O
in	O
body	O
limb	O
orientation	O
.	O
	
In	O
these	O
cases	O
SIFT	B-Method
is	O
often	O
still	O
able	O
to	O
provide	O
a	O
meaningful	O
measure	O
of	O
similarity	B-Metric
due	O
to	O
its	O
rotation	O
invariance	O
.	O
	
section	O
:	O
Experiments	O
	
subsection	O
:	O
Datasets	O
and	O
evaluation	B-Metric
measure	I-Metric
	
Single	O
frame	O
.	O
	
We	O
evaluate	O
our	O
single	B-Method
frame	I-Method
models	I-Method
on	O
the	O
MPII	B-Material
Multi	O
-	O
Person	O
dataset	O
.	O
	
We	O
report	O
all	O
intermediate	O
results	O
on	O
a	O
validation	O
set	O
of	O
images	O
sampled	O
uniformly	O
at	O
random	O
(	O
MPII	B-Material
Multi	O
-	O
Person	O
Val	O
)	O
,	O
while	O
major	O
results	O
and	O
comparison	O
to	O
the	O
state	O
of	O
the	O
art	O
are	O
reported	O
on	O
the	O
test	O
set	O
.	O
	
Video	O
.	O
	
In	O
order	O
to	O
evaluate	O
video	B-Method
-	I-Method
based	I-Method
models	I-Method
we	O
introduce	O
a	O
novel	O
“	O
MPII	B-Material
Video	O
Pose	O
”	O
dataset	O
.	O
	
To	O
this	O
end	O
we	O
manually	O
selected	O
challenging	O
keyframes	O
from	O
MPII	B-Material
Multi	O
-	O
Person	O
dataset	O
.	O
	
Selected	O
keyframes	O
represent	O
crowded	O
scenes	O
with	O
highly	O
articulated	O
people	O
engaging	O
in	O
various	O
dynamic	O
activities	O
.	O
	
In	O
addition	O
to	O
each	O
keyframe	O
,	O
we	O
include	O
+	O
/-	O
	
neighboring	O
frames	O
from	O
the	O
corresponding	O
publicly	O
available	O
video	O
sequences	O
,	O
and	O
annotate	O
every	O
second	O
frame	O
.	O
	
Each	O
body	O
pose	O
was	O
annotated	O
following	O
the	O
standard	O
annotation	B-Method
procedure	I-Method
,	O
while	O
maintaining	O
person	O
identity	O
throughout	O
the	O
sequence	O
.	O
	
In	O
contrast	O
to	O
MPII	B-Material
Multi	O
-	O
Person	O
where	O
some	O
frames	O
may	O
contain	O
non	O
-	O
annotated	O
people	O
,	O
we	O
annotate	O
all	O
people	O
participating	O
in	O
the	O
activity	O
captured	O
in	O
the	O
video	O
,	O
and	O
add	O
ignore	O
regions	O
for	O
areas	O
that	O
contain	O
dense	O
crowds	O
(	O
e.g.	O
static	O
spectators	O
in	O
the	O
dancing	O
sequences	O
)	O
.	O
	
In	O
total	O
,	O
our	O
dataset	O
consists	O
of	O
sequences	O
with	O
over	O
annotated	O
poses	O
.	O
	
Evaluation	B-Metric
details	I-Metric
.	O
	
The	O
average	O
precision	O
(	O
AP	B-Metric
)	O
measure	O
is	O
used	O
for	O
evaluation	B-Task
of	I-Task
pose	I-Task
estimation	I-Task
accuracy	I-Task
.	O
	
For	O
each	O
algorithm	O
we	O
also	O
report	O
run	B-Metric
time	I-Metric
of	O
the	O
proposal	B-Task
generation	I-Task
and	O
of	O
the	O
graph	B-Method
partitioning	I-Method
stages	I-Method
.	O
	
All	O
time	O
measurements	O
were	O
conducted	O
on	O
a	O
single	O
core	O
Intel	O
Xeon	O
GHz	O
.	O
	
Finally	O
we	O
also	O
evaluate	O
tracking	B-Metric
perfomance	I-Metric
using	O
standard	O
MOTA	B-Metric
metric	I-Metric
.	O
	
Evaluation	O
on	O
our	O
“	O
MPII	B-Material
Video	O
Pose	O
”	O
dataset	O
is	O
performed	O
on	O
the	O
full	O
frames	O
using	O
the	O
publicly	O
available	O
evaluation	O
kit	O
of	O
.	O
	
On	O
MPII	B-Material
Multi	O
-	O
Person	O
we	O
follow	O
the	O
official	O
evaluation	O
protocol	O
and	O
evaluate	O
on	O
groups	O
using	O
the	O
provided	O
rough	O
group	O
location	O
and	O
scale	O
.	O
	
subsection	O
:	O
Single	B-Method
-	I-Method
frame	I-Method
models	I-Method
	
We	O
compare	O
the	O
performance	O
of	O
different	O
variants	O
of	O
our	O
Bottom	O
-	O
Up	O
(	O
BU	B-Method
)	O
and	O
Top	O
-	O
Down	O
/	O
Bottom	O
-	O
Up	O
(	O
TD	B-Method
/	O
BU	B-Method
)	O
models	O
introduced	O
in	O
Sec	O
.	O
	
[	O
reference	O
]	O
and	O
Sec	O
.	O
	
[	O
reference	O
]	O
.	O
	
For	O
BU	B-Method
we	O
consider	O
a	O
model	O
that	O
(	O
1	O
)	O
uses	O
a	O
fully	B-Method
-	I-Method
connected	I-Method
graph	I-Method
with	O
up	O
to	O
detection	O
proposals	O
and	O
jointly	O
performs	O
partitioning	B-Task
and	I-Task
body	I-Task
-	I-Task
part	I-Task
labeling	I-Task
similar	O
to	O
(	O
BU	B-Method
-	O
full	O
,	O
label	O
)	O
;	O
(	O
2	O
)	O
is	O
same	O
as	O
(	O
1	O
)	O
,	O
but	O
labeling	B-Task
of	I-Task
detection	I-Task
proposals	I-Task
is	O
done	O
based	O
on	O
detection	B-Metric
score	I-Metric
(	O
BU	B-Method
-	O
full	O
)	O
;	O
(	O
3	O
)	O
is	O
same	O
as	O
(	O
2	O
)	O
,	O
but	O
uses	O
a	O
sparsely	O
-	O
connected	O
graph	O
(	O
BU	B-Method
-	O
sparse	O
)	O
.	O
	
The	O
results	O
are	O
shown	O
in	O
Tab	O
.	O
	
[	O
reference	O
]	O
.	O
	
BU	B-Method
-	O
full	O
,	O
label	O
achieves	O
%	O
AP	B-Metric
with	O
a	O
median	B-Metric
inference	I-Metric
run	I-Metric
-	I-Metric
time	I-Metric
of	O
s	O
	
/	O
f	O
.	O
	
BU	B-Method
-	O
full	O
achieves	O
run	B-Metric
-	I-Metric
time	I-Metric
reduction	I-Metric
(	O
vs.	O
s	B-Metric
/	I-Metric
f	I-Metric
)	O
:	O
	
pre	O
-	O
labeling	B-Task
detection	I-Task
candidates	I-Task
based	O
on	O
detection	B-Metric
score	I-Metric
significantly	O
reduces	O
the	O
number	O
of	O
variables	O
in	O
the	O
problem	O
graph	O
.	O
	
Interestingly	O
,	O
pre	B-Method
-	I-Method
labeling	I-Method
also	O
improves	O
the	O
performance	O
(	O
vs.	O
%	O
AP	B-Metric
)	O
:	O
some	O
of	O
the	O
low	O
-	O
scoring	O
detections	O
may	O
complicate	O
the	O
search	O
for	O
an	O
optimal	O
labeling	O
.	O
	
BU	B-Method
-	O
sparse	O
further	O
reduces	O
run	B-Metric
-	I-Metric
time	I-Metric
(	O
vs.	O
s	O
/	O
f	B-Metric
)	O
,	O
as	O
it	O
reduces	O
the	O
complexity	B-Metric
of	O
the	O
initial	O
problem	O
by	O
sparsifying	O
the	O
graph	O
,	O
at	O
a	O
price	O
of	O
a	O
drop	O
in	O
performance	O
(	O
vs.	O
%	O
AP	B-Metric
)	O
.	O
	
In	O
Tab	O
.	O
	
[	O
reference	O
]	O
we	O
compare	O
the	O
variants	O
of	O
the	O
TD	B-Method
/	O
BU	B-Method
model	O
.	O
	
Our	O
TD	B-Method
approach	O
achieves	O
%	O
AP	B-Metric
,	O
performing	O
on	O
par	O
with	O
a	O
more	O
complex	O
BU	B-Method
-	O
full	O
.	O
	
Explicit	B-Method
spatial	I-Method
propagation	I-Method
(	O
TD	B-Method
+	O
SP	O
)	O
further	O
improves	O
the	O
results	O
(	O
vs.	O
%	O
AP	B-Metric
)	O
.	O
	
The	O
largest	O
improvement	O
is	O
observed	O
for	O
ankles	O
:	O
progressive	B-Task
prediction	I-Task
that	O
conditions	O
on	O
the	O
close	O
-	O
by	O
parts	O
in	O
the	O
tree	O
hierarchy	O
reduces	O
the	O
distance	O
between	O
the	O
conditioning	O
signal	O
and	O
the	O
location	O
of	O
the	O
predicted	O
body	O
part	O
and	O
simplifies	O
the	O
prediction	B-Task
task	I-Task
.	O
	
Performing	O
inference	B-Method
(	O
TD	B-Method
/	O
BU	B-Method
+	O
SP	O
)	O
improves	O
the	O
performance	O
to	O
%	O
AP	B-Metric
,	O
due	O
to	O
more	O
optimal	O
assignment	O
of	O
part	O
detection	O
candidates	O
to	O
corresponding	O
persons	O
.	O
	
Graph	B-Method
simplification	I-Method
in	O
TD	B-Method
/	O
BU	B-Method
allows	O
to	O
further	O
reduce	O
the	O
inference	B-Metric
time	I-Metric
for	O
graph	B-Task
partitioning	I-Task
(	O
vs.	O
for	O
BU	B-Method
-	O
sparse	O
)	O
.	O
	
Single	B-Task
Frame	I-Task
Tracking	I-Task
Single	I-Task
Frame	I-Task
Tracking	I-Task
Comparison	O
to	O
the	O
State	O
of	O
the	O
Art	O
.	O
	
We	O
compare	O
the	O
proposed	O
single	B-Method
-	I-Method
frame	I-Method
approaches	I-Method
to	O
the	O
state	O
of	O
the	O
art	O
on	O
MPII	B-Material
Multi	I-Material
-	I-Material
Person	I-Material
Test	I-Material
and	O
WAF	B-Material
datasets	I-Material
.	O
	
Comparison	O
on	O
MPII	B-Material
is	O
shown	O
in	O
Tab	O
.	O
	
[	O
reference	O
]	O
.	O
	
Both	O
BU	B-Method
-	O
full	O
and	O
TD	B-Method
/	O
BU	B-Method
improve	O
over	O
the	O
best	O
published	O
result	O
of	O
DeeperCut	O
,	O
achieving	O
and	O
%	O
AP	B-Metric
respectively	O
vs.	O
%	O
AP	B-Metric
by	O
DeeperCut	O
.	O
	
For	O
the	O
TD	B-Method
/	O
BU	B-Method
the	O
improvements	O
on	O
articulated	O
parts	O
(	O
elbows	O
,	O
wrists	O
,	O
ankles	O
,	O
knees	O
)	O
are	O
particularly	O
pronounced	O
.	O
	
We	O
argue	O
that	O
this	O
is	O
due	O
to	O
using	O
the	O
network	O
that	O
is	O
directly	O
trained	O
to	O
disambiguate	O
body	O
parts	O
of	O
different	O
people	O
,	O
instead	O
of	O
using	O
explicit	O
geometric	O
pairwise	O
terms	O
that	O
only	O
serve	O
as	O
a	O
proxy	O
to	O
person	O
’s	O
identity	O
.	O
	
Overall	O
,	O
the	O
performance	O
of	O
our	O
best	O
TD	B-Method
/	O
BU	B-Method
method	O
is	O
noticeably	O
higher	O
(	O
vs.	O
%	O
AP	B-Metric
)	O
.	O
	
Remarkably	O
,	O
its	O
run	B-Metric
-	I-Metric
time	I-Metric
of	O
graph	B-Method
partitioning	I-Method
stage	I-Method
is	O
orders	O
of	O
magnitude	O
faster	O
compared	O
to	O
DeeperCut	O
.	O
	
This	O
speed	O
-	O
up	O
is	O
due	O
to	O
two	O
factors	O
.	O
	
First	O
,	O
TD	B-Method
/	O
BU	B-Method
relies	O
on	O
a	O
faster	B-Method
solver	I-Method
that	O
tackles	O
the	O
graph	B-Task
-	I-Task
partitioning	I-Task
problem	I-Task
via	O
local	B-Task
search	I-Task
,	O
in	O
contrast	O
to	O
the	O
exact	B-Method
solver	I-Method
used	O
in	O
.	O
	
Second	O
,	O
in	O
the	O
case	O
of	O
TD	B-Method
/	O
BU	B-Method
model	O
the	O
graph	O
is	O
sparse	O
and	O
a	O
large	O
portion	O
of	O
the	O
computation	O
is	O
performed	O
by	O
the	O
feed	B-Method
-	I-Method
forward	I-Method
CNN	I-Method
introduced	O
in	O
Sec	O
.	O
	
[	O
reference	O
]	O
.	O
	
On	O
WAF	B-Material
dataset	I-Material
TD	I-Method
/	O
BU	B-Method
substantially	O
improves	O
over	O
the	O
best	O
published	O
result	O
(	O
vs.	O
%	O
AP	B-Metric
by	O
)	O
.	O
	
We	O
refer	O
to	O
supplemental	O
material	O
for	O
details	O
.	O
	
subsection	O
:	O
Multi	B-Method
-	I-Method
frame	I-Method
models	I-Method
	
Comparison	O
of	O
video	B-Method
-	I-Method
based	I-Method
models	I-Method
.	O
	
Performance	O
of	O
the	O
proposed	O
video	B-Method
-	I-Method
based	I-Method
models	I-Method
is	O
compared	O
in	O
Tab	O
.	O
	
[	O
reference	O
]	O
.	O
	
Video	B-Method
-	I-Method
based	I-Method
models	I-Method
outperform	O
single	B-Method
-	I-Method
frame	I-Method
models	I-Method
in	O
each	O
case	O
.	O
	
BU	B-Method
-	O
full	O
+	O
temporal	O
slightly	O
outperforms	O
BU	B-Method
-	O
full	O
,	O
where	O
improvements	O
are	O
noticeable	O
for	O
ankle	O
,	O
knee	O
and	O
head	O
.	O
	
BU	B-Method
-	O
sparse	O
+	O
temporal	O
noticeably	O
improves	O
over	O
BU	B-Method
-	O
sparse	O
(	O
vs.	O
%	O
AP	B-Metric
)	O
.	O
	
We	O
observe	O
significant	O
improvements	O
on	O
the	O
most	O
difficult	O
parts	O
such	O
as	O
ankles	O
(	O
%	O
AP	B-Metric
)	O
and	O
wrists	O
(	O
%	O
AP	B-Metric
)	O
.	O
	
Interestingly	O
,	O
BU	B-Method
-	O
sparse	O
+	O
temporal	O
outperforms	O
:	O
longer	O
-	O
range	O
connections	O
such	O
as	O
,	O
,	O
head	O
to	O
ankle	O
,	O
may	O
introduce	O
additional	O
confusion	O
when	O
information	O
is	O
propagated	O
over	O
time	O
.	O
	
Finally	O
,	O
TD	B-Method
/	O
BU	B-Method
+	O
temporal	O
improves	O
over	O
TD	B-Method
/	O
BU	B-Method
(	O
%	O
AP	B-Metric
)	O
.	O
	
Similarly	O
to	O
BU	B-Method
-	O
sparse	O
+	O
temporal	O
,	O
improvement	O
is	O
most	O
prominent	O
on	O
ankles	O
(	O
%	O
AP	B-Metric
)	O
and	O
wrists	O
(	O
%	O
AP	B-Metric
)	O
.	O
	
Note	O
that	O
even	O
the	O
single	O
-	O
frame	O
TD	B-Method
/	O
BU	B-Method
outperforms	O
the	O
best	O
temporal	O
BU	B-Method
model	O
.	O
	
We	O
show	O
examples	O
of	O
articulated	B-Task
tracking	I-Task
on	O
“	O
MPII	B-Material
Video	O
Pose	O
”	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
.	O
	
Temporal	B-Task
reasoning	I-Task
helps	O
in	O
cases	O
when	O
image	O
information	O
is	O
ambiguous	O
due	O
to	O
close	O
proximity	O
of	O
multiple	O
people	O
.	O
	
For	O
example	O
the	O
video	B-Method
-	I-Method
based	I-Method
approach	I-Method
succeeds	O
in	O
correctly	O
localizing	O
legs	O
of	O
the	O
person	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
(	O
d	O
)	O
and	O
(	O
h	O
)	O
.	O
	
Temporal	O
features	O
.	O
	
We	O
perform	O
an	O
ablative	O
experiment	O
on	O
the	O
“	O
MPII	B-Material
Video	O
Pose	O
”	O
dataset	O
to	O
evaluate	O
the	O
individual	O
contribution	O
of	O
the	O
temporal	O
features	O
introduced	O
in	O
Sec	O
.	O
	
[	O
reference	O
]	O
.	O
	
The	O
Euclidean	O
distance	O
alone	O
achieves	O
AP	B-Metric
,	O
adding	O
DeepMatching	O
features	O
improves	O
the	O
resuls	O
to	O
AP	B-Metric
,	O
whereas	O
the	O
combination	O
of	O
all	O
features	O
achieves	O
the	O
best	O
result	O
of	O
AP	B-Metric
(	O
details	O
in	O
supplemental	O
material	O
)	O
.	O
	
Tracking	B-Task
evaluation	I-Task
.	O
	
In	O
Tab	O
.	O
	
[	O
reference	O
]	O
	
we	O
present	O
results	O
of	O
the	O
evaluation	O
of	O
multi	B-Task
-	I-Task
person	I-Task
articulated	I-Task
body	I-Task
tracking	I-Task
.	O
	
We	O
treat	O
each	O
body	O
joint	O
of	O
each	O
person	O
as	O
a	O
tracking	O
target	O
and	O
measure	O
tracking	B-Task
performance	O
using	O
a	O
standard	O
multiple	B-Metric
object	I-Metric
tracking	I-Metric
accuracy	I-Metric
(	O
MOTA	B-Metric
)	I-Metric
metric	I-Metric
that	O
incorporates	O
identity	O
switches	O
,	O
false	B-Metric
positives	I-Metric
and	O
false	B-Metric
negatives	I-Metric
.	O
	
We	O
experimentally	O
compare	O
to	O
a	O
baseline	B-Method
model	I-Method
that	O
first	O
tracks	O
people	O
across	O
frames	O
and	O
then	O
performs	O
per	B-Task
-	I-Task
frame	I-Task
pose	I-Task
estimation	I-Task
.	O
	
To	O
track	O
a	O
person	O
we	O
use	O
a	O
reduced	O
version	O
of	O
our	O
algorithm	O
that	O
operates	O
on	O
the	O
two	O
head	O
joints	O
only	O
.	O
	
This	O
allows	O
to	O
achieve	O
near	O
perfect	O
person	B-Task
tracking	I-Task
results	O
in	O
most	O
cases	O
.	O
	
Our	O
tracker	O
still	O
fails	O
when	O
the	O
person	O
head	O
is	O
occluded	O
for	O
multiple	O
frames	O
as	O
it	O
does	O
not	O
incorporate	O
long	O
-	O
range	O
connectivity	O
between	O
target	O
hypothesis	O
.	O
	
We	O
leave	O
handling	O
of	O
long	B-Task
-	I-Task
term	I-Task
occlusions	I-Task
for	O
the	O
future	O
work	O
.	O
	
For	O
full	B-Task
-	I-Task
body	I-Task
tracking	I-Task
we	O
use	O
the	O
same	O
inital	O
head	O
tracks	O
and	O
add	O
them	O
to	O
the	O
set	O
of	O
body	O
part	O
proposals	O
,	O
while	O
also	O
adding	O
must	O
-	O
link	O
and	O
must	O
-	O
cut	O
constraints	O
for	O
the	O
temporal	O
edges	O
corresponding	O
to	O
the	O
head	O
parts	O
detections	O
.	O
	
The	O
rest	O
of	O
the	O
graph	O
remains	O
unchanged	O
so	O
that	O
at	O
inference	O
time	O
the	O
body	O
parts	O
can	O
be	O
freely	O
assigned	O
to	O
different	O
person	O
tracks	O
.	O
	
For	O
the	O
BU	B-Method
-	O
sparse	O
the	O
full	B-Task
body	I-Task
tracking	I-Task
improves	O
performance	O
by	O
and	O
MOTA	B-Method
on	O
wrists	O
and	O
ankles	O
,	O
and	O
by	O
and	O
MOTA	B-Method
on	O
elbows	O
and	O
knees	O
respectively	O
.	O
	
TD	B-Method
/	O
BU	B-Method
benefits	O
from	O
adding	O
temporal	O
connections	O
between	O
body	O
parts	O
as	O
well	O
,	O
but	O
to	O
a	O
lesser	O
extent	O
than	O
BU	B-Method
-	O
sparse	O
.	O
	
The	O
most	O
significant	O
improvement	O
is	O
for	O
ankles	O
(	O
MOTA	B-Task
)	O
.	O
	
BU	B-Method
-	O
sparse	O
also	O
achieves	O
the	O
best	O
overall	O
score	O
of	O
compared	O
to	O
by	O
TD	B-Method
/	O
BU	B-Method
.	O
	
This	O
is	O
surprising	O
since	O
TD	B-Method
/	O
BU	B-Method
outperformed	O
BU	B-Method
-	O
sparse	O
on	O
the	O
pose	B-Task
estimation	I-Task
task	I-Task
(	O
see	O
Tab	O
.	O
	
[	O
reference	O
]	O
and	O
[	O
reference	O
]	O
)	O
.	O
	
We	O
hypothesize	O
that	O
limited	O
improvement	O
of	O
TD	B-Method
/	O
BU	B-Method
could	O
be	O
due	O
to	O
balancing	O
issues	O
between	O
the	O
temporal	O
and	O
spatial	O
pairwise	O
terms	O
that	O
are	O
estimated	O
independently	O
of	O
each	O
other	O
.	O
	
section	O
:	O
Conclusion	O
	
In	O
this	O
paper	O
we	O
introduced	O
an	O
efficient	O
and	O
effective	O
approach	O
to	O
articulated	B-Task
body	I-Task
tracking	I-Task
in	O
monocular	O
video	O
.	O
	
Our	O
approach	O
defines	O
a	O
model	O
that	O
jointly	O
groups	O
body	O
part	O
proposals	O
within	O
each	O
video	O
frame	O
and	O
across	O
time	O
.	O
	
Grouping	B-Task
is	O
formulated	O
as	O
a	O
graph	B-Task
partitioning	I-Task
problem	I-Task
that	O
lends	O
itself	O
to	O
efficient	O
inference	B-Task
with	O
recent	O
local	B-Method
search	I-Method
techniques	I-Method
.	O
	
Our	O
approach	O
improves	O
over	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
while	O
being	O
substantially	O
faster	O
compared	O
to	O
other	O
related	O
work	O
.	O
	
Acknowledgements	O
.	O
	
This	O
work	O
has	O
been	O
supported	O
by	O
the	O
Max	O
Planck	O
Center	O
for	O
Visual	B-Task
Computing	I-Task
and	I-Task
Communication	I-Task
.	O
	
The	O
authors	O
thank	O
Varvara	O
Obolonchykova	O
and	O
Bahar	O
Tarakameh	O
for	O
their	O
help	O
in	O
creating	O
the	O
video	O
dataset	O
.	O
	
section	O
:	O
Additional	O
Results	O
on	O
the	O
MPII	B-Material
Multi	O
-	O
Person	O
Dataset	O
	
We	O
perform	O
qualitative	O
comparison	O
of	O
the	O
proposed	O
single	B-Method
-	I-Method
frame	I-Method
based	I-Method
TD	I-Method
/	O
BU	B-Method
and	O
BU	B-Method
-	I-Method
full	I-Method
methods	I-Method
on	O
challenging	O
scenes	O
containing	O
highly	O
articulated	O
and	O
strongly	O
overlapping	O
individuals	O
.	O
	
Results	O
are	O
shown	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
and	O
Figure	O
[	O
reference	O
]	O
.	O
	
The	O
BU	B-Method
-	O
full	O
works	O
well	O
when	O
persons	O
are	O
sufficiently	O
separated	O
(	O
images	O
11	O
and	O
12	O
)	O
.	O
	
However	O
,	O
it	O
fails	O
on	O
images	O
where	O
people	O
significantly	O
overlap	O
(	O
images	O
1	O
-	O
3	O
,	O
5	O
-	O
10	O
)	O
or	O
exhibit	O
high	O
degree	O
of	O
articulation	O
(	O
image	O
4	O
)	O
.	O
	
This	O
is	O
due	O
to	O
the	O
fact	O
that	O
geometric	O
image	O
-	O
conditioned	O
pairwise	O
may	O
get	O
confused	O
in	O
the	O
presence	O
of	O
multiple	O
overlapping	O
individuals	O
and	O
thus	O
mislead	O
post	O
-	O
CNN	B-Task
bottom	I-Task
-	I-Task
up	I-Task
assembling	I-Task
of	I-Task
body	I-Task
poses	I-Task
.	O
	
In	O
contrast	O
,	O
TD	B-Method
/	O
BU	B-Method
performs	O
explicit	B-Method
modeling	I-Method
of	I-Method
person	I-Method
identity	I-Method
via	O
top	B-Method
-	I-Method
dop	I-Method
bottom	I-Method
-	I-Method
up	I-Method
reasoning	I-Method
while	O
offloading	O
the	O
larger	O
share	O
of	O
the	O
reasoning	O
about	O
body	O
-	O
part	O
association	O
onto	O
feed	B-Method
-	I-Method
forward	I-Method
convolutional	I-Method
architecture	I-Method
,	O
and	O
thus	O
is	O
able	O
to	O
resolve	O
such	O
challenging	O
cases	O
.	O
	
Interestingly	O
,	O
TD	B-Method
/	O
BU	B-Method
is	O
able	O
to	O
correctly	O
predict	O
lower	O
limbs	O
of	O
people	O
in	O
the	O
back	O
through	O
partial	O
occlusion	O
(	O
image	O
3	O
,	O
5	O
,	O
7	O
,	O
10	O
)	O
.	O
	
TD	B-Method
/	O
BU	B-Method
model	O
occasionally	O
incorrectly	O
assembles	O
body	O
parts	O
in	O
kinematically	O
implausible	O
manner	O
(	O
image	O
12	O
)	O
,	O
as	O
it	O
does	O
not	O
explicitly	O
model	O
geometric	O
body	O
part	O
relations	O
.	O
	
Finally	O
,	O
both	O
models	O
fail	O
in	O
presense	O
of	O
high	O
variations	O
in	O
scale	O
(	O
image	O
13	O
)	O
.	O
	
We	O
envision	O
that	O
reasoning	O
over	O
multiple	O
scales	O
is	O
likely	O
to	O
improve	O
the	O
results	O
.	O
	
BU	B-Method
TD	I-Method
/	O
BU	B-Method
BU	I-Method
	
TD	B-Method
/	O
BU	B-Method
BU	I-Method
TD	I-Method
/	O
BU	B-Method
BU	I-Method
TD	I-Method
/	O
BU	B-Method
	
section	O
:	O
Results	O
on	O
the	O
We	O
Are	O
Family	B-Material
dataset	I-Material
	
We	O
compare	O
our	O
proposed	O
TD	B-Method
/	O
BU	B-Method
model	I-Method
to	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
methods	O
on	O
the	O
“	O
	
We	O
Are	O
Family	O
”	O
(	O
WAF	O
)	O
dataset	O
and	O
present	O
results	O
in	O
Table	O
[	O
reference	O
]	O
.	O
	
We	O
use	O
evaluation	O
protocol	O
from	O
and	O
report	O
the	O
AP	B-Metric
evaluation	O
measure	O
.	O
	
TD	B-Method
/	O
BU	B-Method
model	I-Method
outperforms	O
the	O
best	O
published	O
results	O
across	O
all	O
body	O
parts	O
(	O
vs	O
%	O
AP	B-Metric
)	O
as	O
well	O
improves	O
on	O
articulated	O
parts	O
such	O
as	O
wrists	O
(	O
%	O
AP	B-Metric
)	O
and	O
elbows	O
(	O
%	O
AP	B-Metric
)	O
.	O
	
We	O
attribute	O
that	O
to	O
the	O
ability	O
of	O
top	B-Method
-	I-Method
down	I-Method
model	I-Method
to	O
better	O
learn	O
part	O
associations	O
compared	O
to	O
explicit	O
modeling	O
geometric	O
pairwise	O
relations	O
as	O
in	O
.	O
	
section	O
:	O
Evaluation	B-Task
of	I-Task
temporal	I-Task
features	I-Task
.	O
	
We	O
evaluate	O
the	O
importance	O
of	O
combining	O
temporal	O
features	O
introduced	O
in	O
Sec	O
.	O
	
3.4	O
of	O
the	O
paper	O
on	O
our	O
Multi	B-Material
-	I-Material
Person	I-Material
Video	I-Material
dataset	I-Material
.	O
	
To	O
that	O
end	O
,	O
we	O
consider	O
BU	B-Method
-	O
sparse	O
+	O
temporal	O
model	O
and	O
compare	O
results	O
to	O
BU	B-Method
-	O
sparse	O
in	O
Tab	O
.	O
	
[	O
reference	O
]	O
.	O
	
Single	O
-	O
frame	O
BU	B-Method
-	O
sparse	O
achieves	O
%	O
AP	B-Metric
.	O
	
It	O
can	O
be	O
seen	O
that	O
using	O
geometry	O
based	O
det	O
-	O
distance	O
features	O
slightly	O
improves	O
the	O
results	O
to	O
%	O
AP	B-Metric
,	O
as	O
it	O
enables	O
the	O
propagation	O
of	O
information	O
from	O
neighboring	O
frames	O
.	O
	
Using	O
deepmatch	O
features	O
slightly	O
improves	O
the	O
performance	O
further	O
as	O
it	O
helps	O
to	O
link	O
the	O
same	O
body	O
part	O
of	O
the	O
same	O
person	O
over	O
time	O
based	O
on	O
the	O
body	O
part	O
appearance	O
.	O
	
It	O
is	O
especially	O
helpful	O
in	O
the	O
case	O
of	O
fast	B-Task
motion	I-Task
where	O
det	O
-	O
distance	O
may	O
fail	O
.	O
	
The	O
combination	O
of	O
both	O
geometry	O
and	O
appearance	O
based	O
features	O
further	O
improves	O
the	O
performance	O
to	O
%	O
,	O
which	O
shows	O
their	O
complementarity	O
.	O
	
Finally	O
,	O
adding	O
the	O
sift	B-Method
-	I-Method
distance	I-Method
feature	I-Method
improves	O
the	O
results	O
to	O
%	O
,	O
since	O
it	O
copes	O
better	O
with	O
the	O
sudden	O
changes	O
in	O
background	O
and	O
body	O
part	O
orientations	O
.	O
	
Overall	O
,	O
using	O
a	O
combination	O
of	O
temporal	O
features	O
in	O
BU	B-Method
-	O
sparse	O
+	O
temporal	O
results	O
in	O
a	O
%	O
AP	B-Metric
improvement	O
over	O
the	O
single	O
-	O
frame	O
BU	B-Method
-	O
sparse	O
.	O
	
This	O
demonstrates	O
the	O
advantages	O
of	O
the	O
proposed	O
approach	O
to	O
improve	O
pose	B-Task
estimation	I-Task
performance	O
using	O
temporal	O
information	O
.	O
	
bibliography	O
:	O
References	O
	
Question	B-Task
Answering	I-Task
with	O
Subgraph	B-Method
Embeddings	I-Method
	
section	O
:	O
	
Abstract	O
.	O
	
This	O
paper	O
presents	O
a	O
system	O
which	O
learns	O
to	O
answer	O
questions	O
on	O
a	O
broad	O
range	O
of	O
topics	O
from	O
a	O
knowledge	O
base	O
using	O
few	O
handcrafted	O
features	O
.	O
	
Our	O
model	O
learns	O
low	O
-	O
dimensional	O
embeddings	O
of	O
words	O
and	O
knowledge	O
base	O
constituents	O
;	O
these	O
representations	O
are	O
used	O
to	O
score	O
natural	O
language	O
questions	O
against	O
candidate	O
answers	O
.	O
	
Training	O
our	O
system	O
using	O
pairs	O
of	O
questions	O
and	O
structured	O
representations	O
of	O
their	O
answers	O
,	O
and	O
pairs	O
of	O
question	O
paraphrases	O
,	O
yields	O
competitive	O
results	O
on	O
a	O
recent	O
benchmark	O
of	O
the	O
literature	O
.	O
	
section	O
:	O
Introduction	O
	
Teaching	B-Task
machines	I-Task
how	O
to	O
automatically	O
answer	O
questions	O
asked	O
in	O
natural	O
language	O
on	O
any	O
topic	O
or	O
in	O
any	O
domain	O
has	O
always	O
been	O
a	O
long	O
standing	O
goal	O
in	O
Artificial	B-Task
Intelligence	I-Task
.	O
	
With	O
the	O
rise	O
of	O
large	O
scale	O
structured	O
knowledge	O
bases	O
(	O
KBs	O
)	O
,	O
this	O
problem	O
,	O
known	O
as	O
open	B-Task
-	I-Task
domain	I-Task
question	I-Task
answering	I-Task
(	O
or	O
open	B-Task
QA	I-Task
)	O
,	O
boils	O
down	O
to	O
being	O
able	O
to	O
query	O
efficiently	O
such	O
databases	O
with	O
natural	O
language	O
.	O
	
These	O
KBs	O
,	O
such	O
as	O
Freebase	B-Material
[	O
reference	O
]	O
encompass	O
huge	O
ever	O
growing	O
amounts	O
of	O
information	O
and	O
ease	O
open	B-Task
QA	I-Task
by	O
organizing	O
a	O
great	O
variety	O
of	O
answers	O
in	O
a	O
structured	O
format	O
.	O
	
However	O
,	O
the	O
scale	O
and	O
the	O
difficulty	O
for	O
machines	B-Task
to	O
interpret	O
natural	O
language	O
still	O
makes	O
this	O
task	O
a	O
challenging	O
problem	O
.	O
	
The	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
techniques	O
in	O
open	B-Task
QA	I-Task
can	O
be	O
classified	O
into	O
two	O
main	O
classes	O
,	O
namely	O
,	O
information	B-Task
retrieval	I-Task
based	O
and	O
semantic	B-Task
parsing	I-Task
based	O
.	O
	
Information	B-Task
retrieval	I-Task
systems	I-Task
first	O
retrieve	O
a	O
broad	O
set	O
of	O
candidate	O
answers	O
by	O
querying	O
the	O
search	O
API	O
of	O
KBs	O
with	O
a	O
transformation	O
of	O
the	O
question	O
into	O
a	O
valid	O
query	O
and	O
then	O
use	O
fine	O
-	O
grained	O
detection	B-Method
heuristics	I-Method
to	O
identify	O
the	O
exact	O
answer	O
[	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
.	O
	
On	O
the	O
other	O
hand	O
,	O
semantic	B-Method
parsing	I-Method
methods	I-Method
focus	O
on	O
the	O
correct	O
interpretation	O
of	O
the	O
meaning	O
of	O
a	O
question	O
by	O
a	O
semantic	B-Method
parsing	I-Method
system	I-Method
.	O
	
A	O
correct	O
interpretation	O
converts	O
a	O
question	O
into	O
the	O
exact	O
database	O
query	O
that	O
returns	O
the	O
correct	O
answer	O
.	O
	
Interestingly	O
,	O
recent	O
works	O
[	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
have	O
shown	O
that	O
such	O
systems	O
can	O
be	O
efficiently	O
trained	O
under	O
indirect	O
and	O
imperfect	O
supervision	O
and	O
hence	O
scale	O
to	O
large	O
-	O
scale	O
regimes	O
,	O
while	O
bypassing	O
most	O
of	O
the	O
annotation	B-Metric
costs	I-Metric
.	O
	
Yet	O
,	O
even	O
if	O
both	O
kinds	O
of	O
system	O
have	O
shown	O
the	O
ability	O
to	O
handle	O
largescale	O
KBs	O
,	O
they	O
still	O
require	O
experts	O
to	O
hand	O
-	O
craft	O
lexicons	O
,	O
grammars	O
,	O
and	O
KB	B-Method
schema	I-Method
to	O
be	O
effective	O
.	O
	
This	O
non	O
-	O
negligible	O
human	O
intervention	O
might	O
not	O
be	O
generic	O
enough	O
to	O
conveniently	O
scale	O
up	O
to	O
new	O
databases	O
with	O
other	O
schema	O
,	O
broader	O
vocabularies	O
or	O
languages	O
other	O
than	O
English	O
.	O
	
In	O
contrast	O
,	O
[	O
reference	O
]	O
proposed	O
a	O
framework	O
for	O
open	B-Task
QA	I-Task
requiring	O
almost	O
no	O
human	B-Task
annotation	I-Task
.	O
	
Despite	O
being	O
an	O
interesting	O
approach	O
,	O
this	O
method	O
is	O
outperformed	O
by	O
other	O
competing	O
methods	O
.	O
	
[	O
reference	O
]	O
introduced	O
an	O
embedding	B-Method
model	I-Method
,	O
which	O
learns	O
low	O
-	O
dimensional	O
vector	O
representations	O
of	O
words	O
and	O
symbols	O
(	O
such	O
as	O
KBs	O
constituents	O
)	O
and	O
can	O
be	O
trained	O
with	O
even	O
less	O
supervision	O
than	O
the	O
system	O
of	O
[	O
reference	O
]	O
while	O
being	O
able	O
to	O
achieve	O
better	O
prediction	B-Task
performance	O
.	O
	
However	O
,	O
this	O
approach	O
is	O
only	O
compared	O
with	O
[	O
reference	O
]	O
which	O
operates	O
in	O
a	O
simplified	O
setting	O
and	O
has	O
not	O
been	O
applied	O
in	O
more	O
realistic	O
conditions	O
nor	O
evaluated	O
against	O
the	O
best	O
performing	O
methods	O
.	O
	
In	O
this	O
paper	O
,	O
we	O
improve	O
the	O
model	O
of	O
[	O
reference	O
]	O
by	O
providing	O
the	O
ability	O
to	O
answer	O
more	O
complicated	O
questions	O
.	O
	
sThe	O
main	O
contributions	O
of	O
the	O
paper	O
are	O
:	O
(	O
1	O
)	O
a	O
more	O
sophisticated	O
inference	B-Method
procedure	I-Method
that	O
is	O
both	O
efficient	O
and	O
can	O
consider	O
longer	O
paths	O
(	O
[	O
reference	O
]	O
considered	O
only	O
answers	O
directly	O
connected	O
to	O
the	O
question	O
in	O
the	O
graph	O
)	O
;	O
and	O
(	O
2	O
)	O
a	O
richer	O
representation	O
of	O
the	O
answers	O
which	O
encodes	O
the	O
question	O
-	O
answer	O
path	O
and	O
surrounding	O
subgraph	O
of	O
the	O
KB	O
.	O
	
Our	O
approach	O
is	O
competitive	O
with	O
the	O
current	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
on	O
the	O
recent	O
benchmark	O
WebQuestions	B-Material
[	O
reference	O
]	O
without	O
using	O
any	O
lexicon	O
,	O
rules	O
or	O
additional	O
system	O
for	O
partof	B-Task
-	I-Task
speech	I-Task
tagging	I-Task
,	O
syntactic	B-Task
or	I-Task
dependency	I-Task
parsing	I-Task
during	O
training	O
as	O
most	O
other	O
systems	O
do	O
.	O
	
section	O
:	O
Task	O
Definition	O
	
Our	O
main	O
motivation	O
is	O
to	O
provide	O
a	O
system	O
for	O
open	B-Task
QA	I-Task
able	O
to	O
be	O
trained	O
as	O
long	O
as	O
it	O
has	O
access	O
to	O
:	O
(	O
1	O
)	O
a	O
training	O
set	O
of	O
questions	O
paired	O
with	O
answers	O
and	O
(	O
2	O
)	O
a	O
KB	B-Method
providing	O
a	O
structure	O
among	O
answers	O
.	O
	
We	O
suppose	O
that	O
all	O
potential	O
answers	O
are	O
entities	O
in	O
the	O
KB	O
and	O
that	O
questions	O
are	O
sequences	O
of	O
words	O
that	O
include	O
one	O
identified	O
KB	O
entity	O
.	O
	
When	O
this	O
entity	O
is	O
not	O
given	O
,	O
plain	B-Method
string	I-Method
matching	I-Method
is	O
used	O
to	O
perform	O
entity	B-Task
resolution	I-Task
.	O
	
Smarter	B-Method
methods	I-Method
could	O
be	O
used	O
but	O
this	O
is	O
not	O
our	O
focus	O
.	O
	
We	O
use	O
WebQuestions	B-Material
[	O
1	O
]	O
as	O
our	O
evaluation	O
bemchmark	O
.	O
	
Since	O
it	O
contains	O
few	O
training	O
samples	O
,	O
it	O
is	O
impossible	O
to	O
learn	O
on	O
it	O
alone	O
,	O
and	O
this	O
section	O
describes	O
the	O
various	O
data	O
sources	O
that	O
were	O
used	O
for	O
training	O
.	O
	
These	O
are	O
similar	O
to	O
those	O
used	O
in	O
[	O
reference	O
]	O
.	O
	
WebQuestions	B-Material
	
This	O
dataset	O
is	O
built	O
using	O
Freebase	B-Material
as	O
the	O
KB	O
and	O
contains	O
5	O
,	O
810	O
question	O
-	O
answer	O
pairs	O
.	O
	
It	O
was	O
created	O
by	O
crawling	O
questions	O
through	O
the	O
Google	B-Material
Suggest	I-Material
API	I-Material
,	O
and	O
then	O
obtaining	O
answers	O
using	O
Amazon	B-Material
Mechanical	I-Material
Turk	I-Material
.	O
	
We	O
used	O
the	O
original	O
split	O
(	O
3	O
,	O
778	O
examples	O
for	O
training	O
and	O
2	O
,	O
032	O
for	O
testing	O
)	O
,	O
and	O
isolated	O
1k	O
questions	O
from	O
the	O
training	O
set	O
for	O
validation	B-Task
.	O
	
WebQuestions	B-Material
is	O
built	O
on	O
Freebase	B-Material
since	O
all	O
answers	O
are	O
defined	O
as	O
Freebase	B-Material
entities	O
.	O
	
In	O
each	O
question	O
,	O
we	O
identified	O
one	O
Freebase	B-Material
entity	O
using	O
string	O
matching	O
between	O
words	O
of	O
the	O
question	O
and	O
entity	O
names	O
in	O
Freebase	B-Material
.	O
	
When	O
the	O
same	O
string	O
matches	O
multiple	O
entities	O
,	O
only	O
the	O
entity	O
appearing	O
in	O
most	O
triples	O
,	O
i.e.	O
the	O
most	O
popular	O
in	O
Freebase	B-Material
,	O
was	O
kept	O
.	O
	
Example	O
questions	O
(	O
answers	O
)	O
in	O
the	O
dataset	O
include	O
"	O
Where	O
did	O
Edgar	O
Allan	O
Poe	O
died	O
?	O
"	O
(	O
baltimore	O
)	O
or	O
"	O
What	O
degrees	O
did	O
Barack	O
Obama	O
get	O
?	O
	
"	O
(	O
bachelor	O
of	O
arts	O
,	O
juris	O
doctor	O
)	O
.	O
	
Freebase	B-Material
Freebase	I-Material
[	O
reference	O
]	O
is	O
a	O
huge	O
and	O
freely	O
available	O
database	O
of	O
general	O
facts	O
;	O
data	O
is	O
organized	O
as	O
triplets	O
(	O
subject	O
,	O
type1.type2.predicate	O
,	O
object	O
)	O
,	O
where	O
two	O
entities	O
subject	O
and	O
object	O
(	O
identified	O
by	O
mids	O
)	O
are	O
connected	O
by	O
the	O
relation	O
type	O
type1.type2.predicate	O
.	O
	
We	O
used	O
a	O
subset	O
,	O
created	O
by	O
only	O
keeping	O
triples	O
where	O
one	O
of	O
the	O
entities	O
was	O
appearing	O
in	O
either	O
the	O
WebQuestions	B-Material
training	O
/	O
validation	O
set	O
or	O
in	O
ClueWeb	B-Task
extractions	I-Task
.	O
	
We	O
also	O
removed	O
all	O
entities	O
appearing	O
less	O
than	O
5	O
times	O
and	O
finally	O
obtained	O
a	O
Freebase	B-Material
set	O
containing	O
14	O
M	O
triples	O
made	O
of	O
2.2	O
M	O
entities	O
and	O
7k	O
relation	O
types	O
.	O
	
section	O
:	O
WebQuestions	B-Material
	
1	O
	
Since	O
the	O
format	O
of	O
triples	O
does	O
not	O
correspond	O
to	O
any	O
structure	O
one	O
could	O
find	O
in	O
language	O
,	O
we	O
decided	O
to	O
transform	O
them	O
into	O
automatically	O
generated	O
questions	O
.	O
	
Hence	O
,	O
all	O
triples	O
were	O
converted	O
into	O
questions	O
	
"	O
What	O
is	O
the	O
predicate	O
of	O
the	O
type2	O
subject	O
?	O
	
"	O
(	O
using	O
the	O
mid	O
of	O
the	O
subject	O
)	O
with	O
the	O
answer	O
being	O
object	O
.	O
	
An	O
example	O
is	O
"	O
What	O
is	O
the	O
nationality	O
of	O
the	O
person	O
barack	O
obama	O
?	O
	
"	O
(	O
united	O
states	O
)	O
.	O
	
More	O
examples	O
and	O
details	O
are	O
given	O
in	O
a	O
longer	O
version	O
of	O
this	O
paper	O
[	O
reference	O
]	O
.	O
	
section	O
:	O
ClueWeb	B-Task
Extractions	I-Task
	
Freebase	B-Material
data	O
allows	O
to	O
train	O
our	O
model	O
on	O
14	O
M	O
questions	O
but	O
these	O
have	O
a	O
fixed	O
lexicon	O
and	O
vocabulary	O
,	O
which	O
is	O
not	O
realistic	O
.	O
	
Following	O
[	O
reference	O
]	O
,	O
we	O
also	O
created	O
questions	O
using	O
ClueWeb	O
extractions	O
provided	O
by	O
[	O
reference	O
]	O
.	O
Using	O
string	B-Method
matching	I-Method
,	O
we	O
ended	O
up	O
with	O
2	O
M	O
extractions	O
structured	O
as	O
(	O
subject	O
,	O
"	O
text	O
string	O
"	O
,	O
object	O
)	O
with	O
both	O
subject	O
and	O
object	O
linked	O
to	O
Freebase	B-Material
.	O
	
We	O
also	O
converted	O
these	O
triples	O
into	O
questions	O
by	O
using	O
simple	O
patterns	O
and	O
Freebase	B-Material
types	O
.	O
	
An	O
example	O
of	O
generated	O
question	O
is	O
"	O
Where	O
barack	O
obama	O
was	O
allegedly	O
bear	O
in	O
?	O
	
"	O
(	O
hawaii	O
)	O
.	O
	
Paraphrases	O
The	O
automatically	O
generated	O
questions	O
that	O
are	O
useful	O
to	O
connect	O
Freebase	B-Material
triples	O
and	O
natural	O
language	O
,	O
do	O
not	O
provide	O
a	O
satisfactory	O
modeling	O
of	O
natural	O
language	O
because	O
of	O
their	O
semi	O
-	O
automatic	O
wording	O
and	O
rigid	O
syntax	O
.	O
	
To	O
overcome	O
this	O
issue	O
,	O
we	O
follow	O
[	O
reference	O
]	O
Table	O
2	O
.	O
	
Examples	O
of	O
questions	O
,	O
answer	O
paths	O
and	O
paraphrases	O
used	O
in	O
this	O
paper	O
.	O
	
as	O
rephrasings	O
of	O
each	O
other	O
:	O
[	O
reference	O
]	O
harvested	O
a	O
set	O
of	O
2	O
M	O
distinct	O
questions	O
from	O
WikiAnswers	B-Material
,	O
which	O
were	O
grouped	O
into	O
350k	O
paraphrase	O
clusters	O
.	O
	
section	O
:	O
Embedding	O
Questions	O
and	O
Answers	O
	
Inspired	O
by	O
[	O
reference	O
]	O
,	O
our	O
model	O
works	O
by	O
learning	O
low	B-Method
-	I-Method
dimensional	I-Method
vector	I-Method
embeddings	I-Method
of	O
words	O
appearing	O
in	O
questions	O
and	O
of	O
entities	O
and	O
relation	O
types	O
of	O
Freebase	B-Material
,	O
so	O
that	O
representations	O
of	O
questions	O
and	O
of	O
their	O
corresponding	O
answers	O
are	O
close	O
to	O
each	O
other	O
in	O
the	O
joint	O
embedding	O
space	O
.	O
	
Let	O
q	O
denote	O
a	O
question	O
and	O
a	O
a	O
candidate	O
answer	O
.	O
	
Learning	B-Task
embeddings	I-Task
is	O
achieved	O
by	O
learning	O
a	O
scoring	B-Method
function	I-Method
S	I-Method
(	I-Method
q	I-Method
,	O
a	O
)	O
,	O
so	O
that	O
S	O
generates	O
a	O
high	O
score	O
if	O
a	O
is	O
the	O
correct	O
answer	O
to	O
the	O
question	O
q	O
,	O
and	O
a	O
low	O
score	O
otherwise	O
.	O
	
Note	O
that	O
both	O
q	O
and	O
a	O
are	O
represented	O
as	O
a	O
combination	O
of	O
the	O
embeddings	O
of	O
their	O
individual	O
words	O
and	O
/	O
or	O
symbols	O
;	O
hence	O
,	O
learning	B-Task
S	I-Task
essentially	O
involves	O
learning	O
these	O
embeddings	O
.	O
	
In	O
our	O
model	O
,	O
the	O
form	O
of	O
the	O
scoring	B-Metric
function	I-Metric
is	O
:	O
	
Let	O
W	O
be	O
a	O
matrix	O
of	O
R	O
k×N	O
,	O
where	O
k	O
is	O
the	O
dimension	O
of	O
the	O
embedding	O
space	O
which	O
is	O
fixed	O
a	O
-	O
priori	O
,	O
and	O
N	O
is	O
the	O
dictionary	O
of	O
embeddings	O
to	O
be	O
learned	O
.	O
	
Let	O
N	O
W	O
denote	O
the	O
total	O
number	O
of	O
words	O
and	O
N	O
S	O
the	O
total	O
number	O
of	O
entities	O
and	O
relation	O
types	O
.	O
	
With	O
N	O
=	O
	
N	O
W	O
+	O
N	O
S	O
,	O
the	O
i	O
-	O
th	O
column	O
of	O
W	O
is	O
the	O
embedding	O
of	O
the	O
i	O
-	O
th	O
element	O
(	O
word	O
,	O
entity	O
or	O
relation	O
type	O
)	O
in	O
the	O
dictionary	O
.	O
	
The	O
function	O
f	O
(	O
.	O
)	O
,	O
which	O
maps	O
the	O
questions	O
into	O
the	O
embedding	O
space	O
R	O
k	O
is	O
defined	O
as	O
f	O
(	O
q	O
)	O
=	O
	
Wφ	O
(	O
q	O
)	O
,	O
where	O
φ	O
(	O
q	O
)	O
∈	O
N	O
N	O
,	O
is	O
a	O
sparse	O
vector	O
indicating	O
the	O
number	O
of	O
times	O
	
each	O
word	O
appears	O
in	O
the	O
question	O
q	O
(	O
usually	O
0	O
or	O
1	O
)	O
.	O
	
Likewise	O
the	O
function	O
g	O
(	O
.	O
)	O
which	O
maps	O
the	O
answer	O
into	O
the	O
same	O
embedding	O
space	O
R	O
k	O
as	O
the	O
questions	O
,	O
is	O
given	O
by	O
g	O
(	O
a	O
)	O
	
=	O
Wψ	O
(	O
a	O
)	O
.	O
	
Here	O
ψ	O
(	O
a	O
)	O
	
∈	O
N	O
N	O
is	O
a	O
sparse	B-Method
vector	I-Method
representation	I-Method
of	I-Method
the	I-Method
answer	I-Method
a	I-Method
,	O
which	O
we	O
now	O
detail	O
.	O
	
section	O
:	O
Embedding	B-Method
model	I-Method
	
Freebase	B-Material
subgraph	O
	
section	O
:	O
Binary	B-Method
encoding	I-Method
of	I-Method
the	I-Method
subgraph	I-Method
ψ	I-Method
(	I-Method
a	I-Method
)	O
	
section	O
:	O
Embedding	B-Task
of	I-Task
the	I-Task
subgraph	I-Task
g	I-Task
(	I-Task
a	I-Task
)	O
	
Binary	B-Method
encoding	I-Method
of	O
the	O
ques0on	O
Φ	O
(	O
q	O
)	O
	
section	O
:	O
Embedding	O
of	O
the	O
ques0on	O
f	O
(	O
q	O
)	O
	
Ques0on	O
	
q	O
	
Subgraph	O
of	O
a	O
candidate	O
answer	O
a	O
(	O
here	O
K.	O
Preston	O
)	O
	
section	O
:	O
Score	O
S	O
(	O
q	O
,	O
a	O
)	O
	
How	O
the	O
candidate	O
answer	O
fits	O
the	O
ques0on	O
	
section	O
:	O
Dot	B-Method
product	I-Method
	
Embedding	O
matrix	O
W	O
Fig	O
.	O
	
1	O
.	O
	
Illustration	O
of	O
the	O
subgraph	B-Method
embedding	I-Method
model	I-Method
scoring	O
a	O
candidate	O
answer	O
:	O
	
(	O
i	O
)	O
locate	O
entity	O
in	O
the	O
question	O
;	O
(	O
ii	O
)	O
compute	O
path	O
from	O
entity	O
to	O
answer	O
;	O
(	O
iii	O
)	O
represent	O
answer	O
as	O
path	O
plus	O
all	O
connected	O
entities	O
to	O
the	O
answer	O
(	O
the	O
subgraph	O
)	O
;	O
(	O
iv	O
)	O
embed	O
both	O
the	O
question	O
and	O
the	O
answer	O
subgraph	O
separately	O
using	O
the	O
learnt	O
embedding	O
vectors	O
,	O
and	O
score	O
the	O
match	O
via	O
their	O
dot	B-Method
product	I-Method
.	O
	
section	O
:	O
Representing	O
Candidate	O
Answers	O
	
We	O
now	O
describe	O
possible	O
feature	B-Method
representations	I-Method
for	O
a	O
single	O
candidate	O
answer	O
.	O
	
(	O
When	O
there	O
are	O
multiple	O
correct	O
answers	O
,	O
we	O
average	O
these	O
representations	O
,	O
see	O
Section	O
3.4	O
.	O
)	O
	
We	O
consider	O
three	O
different	O
types	O
of	O
representation	O
,	O
corresponding	O
to	O
different	O
subgraphs	O
of	O
Freebase	B-Material
around	O
it	O
.	O
	
(	O
i	O
)	O
	
Single	O
Entity	O
.	O
	
The	O
answer	O
is	O
represented	O
as	O
a	O
single	O
entity	O
from	O
Freebase	B-Material
:	O
	
ψ	O
(	O
a	O
)	O
is	O
a	O
	
1	O
-	O
of	O
-	O
N	O
S	O
coded	O
vector	O
with	O
1	O
corresponding	O
to	O
the	O
entity	O
of	O
the	O
answer	O
,	O
and	O
0	O
elsewhere	O
.	O
	
(	O
ii	O
)	O
	
Path	B-Method
Representation	I-Method
.	O
	
The	O
answer	O
is	O
represented	O
as	O
a	O
path	O
from	O
the	O
entity	O
mentioned	O
in	O
the	O
question	O
to	O
the	O
answer	O
entity	O
.	O
	
In	O
our	O
experiments	O
,	O
we	O
considered	O
1	O
-	O
or	O
2	O
-	O
hops	O
paths	O
(	O
i.e.	O
with	O
either	O
1	O
or	O
2	O
edges	O
to	O
traverse	O
)	O
:	O
(	O
barack	O
obama	O
,	O
people.person.place	O
of	O
birth	O
,	O
honolulu	O
)	O
is	O
a	O
1	O
-	O
hop	O
path	O
and	O
(	O
barack	O
obama	O
,	O
people.person.place	O
of	O
birth	O
,	O
location	O
.	O
	
location.containedby	O
,	O
hawaii	O
)	O
a	O
2	O
-	O
hops	O
path	O
.	O
	
This	O
results	O
in	O
a	O
ψ	B-Method
(	I-Method
a	I-Method
)	I-Method
which	O
is	O
a	O
3	O
-	O
of	O
-	O
N	O
S	O
or	O
4	O
-	O
of	O
-	O
N	O
S	O
coded	O
vector	O
,	O
expressing	O
the	O
start	O
and	O
end	O
entities	O
of	O
the	O
path	O
and	O
the	O
relation	O
types	O
(	O
but	O
not	O
entities	O
)	O
in	O
-	O
between	O
.	O
	
(	O
iii	O
)	O
Subgraph	B-Method
Representation	I-Method
.	O
	
We	O
encode	O
both	O
the	O
path	B-Method
representation	I-Method
from	O
(	O
ii	O
)	O
,	O
and	O
the	O
entire	O
subgraph	O
of	O
entities	O
connected	O
to	O
the	O
candidate	O
answer	O
entity	O
.	O
	
That	O
is	O
,	O
for	O
each	O
entity	O
connected	O
to	O
the	O
answer	O
we	O
include	O
both	O
the	O
relation	O
type	O
and	O
the	O
entity	O
itself	O
in	O
the	O
representation	O
ψ	O
(	O
a	O
)	O
.	O
	
In	O
order	O
to	O
represent	O
the	O
answer	O
path	O
differently	O
to	O
the	O
surrounding	O
subgraph	O
(	O
so	O
the	O
model	O
can	O
differentiate	O
them	O
)	O
,	O
we	O
double	O
the	O
dictionary	O
size	O
for	O
entities	O
,	O
and	O
use	O
one	O
embedding	B-Method
representation	I-Method
if	O
they	O
are	O
in	O
the	O
path	O
and	O
another	O
if	O
they	O
are	O
in	O
the	O
subgraph	O
.	O
	
Thus	O
we	O
now	O
learn	O
a	O
parameter	O
matrix	O
R	O
k×N	O
where	O
N	O
	
=	O
N	O
W	O
+	O
2N	O
S	O
	
(	O
N	O
S	O
is	O
the	O
total	O
number	O
of	O
entities	O
and	O
relation	O
types	O
)	O
.	O
	
If	O
there	O
are	O
C	O
connected	O
entities	O
with	O
D	O
relation	O
types	O
to	O
the	O
candidate	O
answer	O
,	O
its	O
representation	O
is	O
a	O
3	O
+	O
C	O
+	O
D	O
or	O
4	O
+	O
C	O
+	O
D	O
-	O
of	O
-	O
N	O
S	O
coded	O
vector	O
,	O
depending	O
on	O
the	O
path	O
length	O
.	O
	
Our	O
hypothesis	O
is	O
that	O
including	O
more	O
information	O
about	O
the	O
answer	O
in	O
its	O
representation	O
will	O
lead	O
to	O
improved	O
results	O
.	O
	
While	O
it	O
is	O
possible	O
that	O
all	O
required	O
information	O
could	O
be	O
encoded	O
in	O
the	O
k	B-Method
dimensional	I-Method
embedding	I-Method
of	O
the	O
single	O
entity	O
(	O
i	O
)	O
,	O
it	O
is	O
unclear	O
what	O
dimension	O
k	O
should	O
be	O
to	O
make	O
this	O
possible	O
.	O
	
For	O
example	O
the	O
embedding	O
of	O
a	O
country	O
entity	O
encoding	O
all	O
of	O
its	O
citizens	O
seems	O
unrealistic	O
.	O
	
Similarly	O
,	O
only	O
having	O
access	O
to	O
the	O
path	O
ignores	O
all	O
the	O
other	O
information	O
we	O
have	O
about	O
the	O
answer	O
entity	O
,	O
unless	O
it	O
is	O
encoded	O
in	O
the	O
embeddings	O
of	O
either	O
the	O
entity	O
of	O
the	O
question	O
,	O
the	O
answer	O
or	O
the	O
relations	O
linking	O
them	O
,	O
which	O
might	O
be	O
quite	O
complicated	O
as	O
well	O
.	O
	
We	O
thus	O
adopt	O
the	O
subgraph	B-Method
approach	I-Method
.	O
	
Figure	O
1	O
illustrates	O
our	O
model	O
.	O
	
section	O
:	O
Training	O
and	O
Loss	B-Metric
Function	I-Metric
	
As	O
in	O
[	O
reference	O
]	O
,	O
we	O
train	O
our	O
model	O
using	O
a	O
margin	B-Method
-	I-Method
based	I-Method
ranking	I-Method
loss	I-Method
function	I-Method
.	O
	
Let	O
D	O
=	O
{	O
(	O
q	O
i	O
,	O
a	O
i	O
)	O
:	O
	
i	O
=	O
1	O
,	O
.	O
.	O
.	O
,	O
|D|	O
}	O
be	O
the	O
training	O
set	O
of	O
questions	O
	
q	O
i	O
paired	O
with	O
their	O
correct	O
answer	O
a	O
i	O
.	O
	
The	O
loss	O
function	O
we	O
minimize	O
is	O
	
where	O
m	O
is	O
the	O
margin	O
(	O
fixed	O
to	O
0.1	O
)	O
.	O
	
Minimizing	B-Task
Eq	I-Task
.	O
	
(	O
2	O
)	O
learns	O
the	O
embedding	O
matrix	O
W	O
so	O
that	O
the	O
score	O
of	O
a	O
question	O
paired	O
with	O
a	O
correct	O
answer	O
is	O
greater	O
than	O
with	O
any	O
incorrect	O
answerā	O
by	O
at	O
least	O
m.ā	O
is	O
sampled	O
from	O
a	O
set	O
of	O
incorrect	O
candidatesĀ.	O
	
This	O
is	O
achieved	O
by	O
sampling	O
50	O
%	O
of	O
the	O
time	O
from	O
the	O
set	O
of	O
entities	O
connected	O
to	O
the	O
entity	O
of	O
the	O
question	O
(	O
i.e.	O
other	O
candidate	O
paths	O
)	O
,	O
and	O
by	O
replacing	O
the	O
answer	O
entity	O
by	O
a	O
random	O
one	O
otherwise	O
.	O
	
Optimization	B-Task
is	O
accomplished	O
using	O
stochastic	B-Method
gradient	I-Method
descent	I-Method
,	O
multi	O
-	O
threaded	O
with	O
Hogwild	B-Method
!	O
	
[	O
reference	O
]	O
,	O
with	O
the	O
constraint	O
that	O
the	O
columns	O
w	O
i	O
of	O
W	O
remain	O
within	O
the	O
unit	O
-	O
ball	O
,	O
i.e.	O
,	O
∀	O
i	O
,	O
||w	O
i	O
||	O
	
2	O
≤	O
1	O
.	O
	
section	O
:	O
Multitask	B-Task
Training	I-Task
of	I-Task
Embeddings	I-Task
	
Since	O
a	O
large	O
number	O
of	O
questions	O
in	O
our	O
training	O
datasets	O
are	O
synthetically	O
generated	O
,	O
they	O
do	O
not	O
adequately	O
cover	O
the	O
range	O
of	O
syntax	O
used	O
in	O
natural	O
language	O
.	O
	
Hence	O
,	O
we	O
also	O
multi	O
-	O
task	O
the	O
training	O
of	O
our	O
model	O
with	O
the	O
task	O
of	O
paraphrase	B-Task
prediction	I-Task
.	O
	
We	O
do	O
so	O
by	O
alternating	O
the	O
training	O
of	O
S	B-Method
with	O
that	O
of	O
a	O
scoring	B-Method
function	I-Method
S	O
prp	O
(	O
q	O
1	O
,	O
q	O
2	O
)	O
=	O
	
f	O
(	O
q	O
1	O
)	O
f	O
(	O
q	O
2	O
)	O
,	O
which	O
uses	O
the	O
same	O
embedding	O
matrix	O
W	O
and	O
makes	O
the	O
embeddings	O
of	O
a	O
pair	O
of	O
questions	O
(	O
q	O
1	O
,	O
q	O
2	O
)	O
similar	O
to	O
each	O
other	O
	
if	O
they	O
are	O
paraphrases	O
(	O
i.e.	O
if	O
they	O
belong	O
to	O
the	O
same	O
paraphrase	O
cluster	O
)	O
,	O
and	O
make	O
them	O
different	O
otherwise	O
.	O
	
Training	O
S	O
prp	O
is	O
similar	O
to	O
that	O
of	O
S	O
except	O
that	O
negative	O
samples	O
are	O
obtained	O
by	O
sampling	O
a	O
question	O
from	O
another	O
paraphrase	O
cluster	O
.	O
	
We	O
also	O
multitask	O
the	O
training	O
of	O
the	O
embeddings	O
with	O
the	O
mapping	O
of	O
the	O
mids	O
of	O
Freebase	B-Material
entities	O
to	O
the	O
actual	O
words	O
of	O
their	O
names	O
,	O
so	O
that	O
the	O
model	O
learns	O
that	O
the	O
embedding	O
of	O
the	O
mid	O
of	O
an	O
entity	O
should	O
be	O
similar	O
to	O
the	O
embedding	O
of	O
	
the	O
word	O
(	O
s	O
)	O
that	O
compose	O
its	O
name	O
(	O
s	O
)	O
.	O
	
section	O
:	O
Inference	B-Task
	
Once	O
W	O
is	O
trained	O
,	O
at	O
test	O
time	O
,	O
for	O
a	O
given	O
question	O
q	O
the	O
model	O
predicts	O
the	O
answer	O
with	O
:	O
â	O
=	O
argmax	O
a	O
∈A	O
(	O
q	O
	
)	O
S	O
(	O
q	O
,	O
a	O
)	O
	
where	O
A	O
(	O
q	O
)	O
is	O
the	O
candidate	O
answer	O
set	O
.	O
	
This	O
candidate	O
set	O
could	O
be	O
the	O
whole	O
KB	O
but	O
this	O
has	O
both	O
speed	O
and	O
potentially	O
precision	B-Metric
issues	I-Metric
.	O
	
Instead	O
,	O
we	O
create	O
a	O
candidate	O
set	O
A	O
(	O
q	O
)	O
for	O
each	O
question	O
.	O
	
We	O
recall	O
that	O
each	O
question	O
contains	O
one	O
identified	O
Freebase	B-Material
entity	O
.	O
	
A	O
(	O
q	O
)	O
is	O
first	O
populated	O
with	O
all	O
triples	O
from	O
Freebase	B-Material
involving	O
this	O
entity	O
.	O
	
This	O
allows	O
to	O
answer	O
simple	O
factual	O
questions	O
whose	O
answers	O
are	O
directly	O
connected	O
to	O
them	O
(	O
i.e.	O
1	O
-	O
hop	O
paths	O
)	O
.	O
	
This	O
strategy	O
is	O
denoted	O
C	O
1	O
.	O
	
Since	O
a	O
system	O
able	O
to	O
answer	O
only	O
such	O
questions	O
would	O
be	O
limited	O
,	O
we	O
supplement	O
A	O
(	O
q	O
)	O
with	O
examples	O
situated	O
in	O
the	O
KB	O
graph	O
at	O
2	O
-	O
hops	O
from	O
the	O
entity	O
of	O
the	O
question	O
.	O
	
We	O
do	O
not	O
add	O
all	O
such	O
quadruplets	O
since	O
this	O
would	O
lead	O
to	O
very	O
large	O
candidate	O
sets	O
.	O
	
Instead	O
,	O
we	O
consider	O
the	O
following	O
general	O
approach	O
:	O
given	O
that	O
we	O
are	O
predicting	O
a	O
path	O
,	O
we	O
can	O
predict	O
its	O
elements	O
in	O
turn	O
using	O
a	O
beam	B-Method
search	I-Method
,	O
and	O
hence	O
avoid	O
scoring	O
all	O
candidates	O
.	O
	
Specifically	O
,	O
our	O
model	O
first	O
ranks	O
relation	O
types	O
using	O
Eq	O
.	O
	
(	O
1	O
)	O
,	O
i.e.	O
selects	O
which	O
relation	O
types	O
are	O
the	O
most	O
likely	O
to	O
be	O
expressed	O
in	O
q.	O
	
We	O
keep	O
the	O
top	O
10	O
types	O
(	O
10	O
was	O
selected	O
on	O
the	O
validation	O
set	O
)	O
and	O
only	O
add	O
2	O
-	O
hops	O
candidates	O
to	O
A	O
(	O
q	O
)	O
when	O
these	O
relations	O
appear	O
in	O
their	O
path	O
.	O
	
Scores	O
of	O
1	O
-	O
hop	O
triples	O
are	O
weighted	O
by	O
1.5	O
since	O
they	O
have	O
one	O
less	O
element	O
than	O
2	O
-	O
hops	O
quadruplets	O
.	O
	
This	O
strategy	O
,	O
denoted	O
C	O
2	O
,	O
is	O
used	O
by	O
default	O
.	O
	
A	O
prediction	O
a	O
can	O
commonly	O
actually	O
be	O
a	O
set	O
of	O
candidate	O
answers	O
,	O
not	O
just	O
one	O
answer	O
,	O
for	O
example	O
for	O
questions	O
like	O
"	O
Who	O
are	O
David	O
Beckham	O
's	O
children	O
?	O
"	O
.	O
	
This	O
is	O
achieved	O
by	O
considering	O
a	O
prediction	O
to	O
be	O
all	O
the	O
entities	O
that	O
lie	O
on	O
the	O
same	O
1	O
-	O
hop	O
or	O
	
2	O
-	O
hops	O
path	O
from	O
the	O
entity	O
found	O
in	O
the	O
question	O
.	O
	
Hence	O
,	O
all	O
answers	O
to	O
the	O
above	O
question	O
are	O
connected	O
to	O
david	O
beckham	O
via	O
the	O
same	O
path	O
(	O
david	O
beckham	O
,	O
people.person.children	O
,	O
*	O
)	O
.	O
	
The	O
feature	B-Method
representation	I-Method
of	O
the	O
prediction	B-Task
is	O
then	O
the	O
average	O
over	O
each	O
candidate	O
entity	O
's	O
features	O
(	O
see	O
Section	O
3.1	O
)	O
,	O
i.e.	O
ψ	O
all	O
(	O
a	O
)	O
=	O
1	O
|a	O
	
|	O
	
a	O
j	O
:	O
	
a	O
ψ	O
(	O
a	O
j	O
)	O
where	O
a	O
j	O
are	O
the	O
individual	O
entities	O
in	O
the	O
overall	O
prediction	O
a	O
.	O
	
In	O
the	O
results	O
,	O
we	O
compare	O
to	O
a	O
baseline	O
method	O
that	O
can	O
only	O
predict	O
single	O
candidates	O
,	O
which	O
understandly	O
performs	O
poorly	O
.	O
	
section	O
:	O
Experiments	O
	
We	O
compare	O
our	O
system	O
in	O
terms	O
of	O
F1	B-Metric
score	I-Metric
as	O
computed	O
by	O
the	O
official	B-Metric
evaluation	I-Metric
script	I-Metric
2	O
(	O
F1	B-Metric
(	O
Berant	O
)	O
)	O
but	O
also	O
with	O
a	O
slightly	O
different	O
F1	B-Metric
definition	O
,	O
termed	O
F1	B-Metric
(	O
Yao	O
)	O
which	O
was	O
used	O
in	O
[	O
reference	O
]	O
(	O
the	O
difference	O
being	O
the	O
way	O
that	O
questions	O
with	O
no	O
answers	O
are	O
dealt	O
with	O
)	O
,	O
and	O
precision	B-Metric
@	O
	
1	O
(	O
p@1	O
)	O
of	O
the	O
first	O
candidate	O
entity	O
(	O
even	O
when	O
there	O
are	O
a	O
set	O
of	O
correct	O
answers	O
)	O
,	O
comparing	O
to	O
recently	O
published	O
systems	O
.	O
	
3	O
	
The	O
upper	O
part	O
of	O
Table	O
3	O
indicates	O
that	O
our	O
approach	O
outperforms	O
[	O
reference	O
]	O
,	O
[	O
reference	O
]	O
and	O
[	O
reference	O
]	O
,	O
and	O
performs	O
similarly	O
as	O
[	O
reference	O
]	O
.	O
	
The	O
lower	O
part	O
of	O
Table	O
3	O
compares	O
various	O
versions	O
of	O
our	O
model	O
.	O
	
Our	O
default	B-Method
approach	I-Method
uses	O
the	O
Subgraph	B-Method
representation	I-Method
for	O
answers	O
and	O
C	O
2	O
as	O
the	O
candidate	O
answers	O
set	O
.	O
	
Replacing	O
C	O
2	O
by	O
C	O
1	O
induces	O
a	O
large	O
drop	O
in	O
performance	O
because	O
many	O
questions	O
do	O
not	O
have	O
answers	O
thatare	O
directly	O
connected	O
to	O
their	O
inluded	O
entity	O
(	O
not	O
in	O
C	O
1	O
)	O
.	O
	
However	O
,	O
using	O
all	O
2	O
-	O
hops	O
connections	O
as	O
a	O
candidate	O
set	O
is	O
also	O
detrimental	O
,	O
because	O
the	O
larger	O
number	O
of	O
candidates	O
confuses	O
(	O
and	O
slows	O
a	O
lot	O
)	O
our	O
ranking	B-Method
based	I-Method
inference	I-Method
.	O
	
Our	O
results	O
also	O
verify	O
our	O
hypothesis	O
of	O
Section	O
3.1	O
,	O
that	O
a	O
richer	O
representation	O
for	O
answers	O
(	O
using	O
the	O
local	O
subgraph	O
)	O
can	O
store	O
more	O
pertinent	O
information	O
.	O
	
Finally	O
,	O
we	O
demonstrate	O
that	O
we	O
greatly	O
improve	O
upon	O
the	O
model	O
of	O
[	O
reference	O
]	O
,	O
which	O
actually	O
corresponds	O
to	O
a	O
setting	O
with	O
the	O
Path	B-Method
representation	I-Method
and	O
C	O
1	O
as	O
candidate	O
set	O
.	O
	
We	O
also	O
considered	O
an	O
ensemble	O
of	O
our	O
approach	O
and	O
that	O
of	O
[	O
reference	O
]	O
.	O
	
As	O
we	O
only	O
had	O
access	O
to	O
their	O
test	O
predictions	O
we	O
used	O
the	O
following	O
combination	B-Method
method	I-Method
.	O
	
Our	O
approach	O
gives	O
a	O
score	O
S	O
(	O
q	O
,	O
a	O
)	O
for	O
the	O
answer	O
it	O
predicts	O
.	O
	
We	O
chose	O
a	O
threshold	O
such	O
that	O
our	O
approach	O
predicts	O
50	O
%	O
of	O
the	O
time	O
(	O
when	O
S	O
(	O
q	O
,	O
a	O
)	O
is	O
above	O
its	O
value	O
)	O
,	O
and	O
the	O
other	O
50	O
%	O
of	O
the	O
time	O
we	O
use	O
the	O
prediction	O
of	O
[	O
reference	O
]	O
instead	O
.	O
	
We	O
aimed	O
for	O
a	O
50	O
/	O
50	O
ratio	O
because	O
both	O
methods	O
perform	O
similarly	O
.	O
	
The	O
ensemble	O
improves	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
,	O
and	O
indicates	O
that	O
our	O
models	O
are	O
significantly	O
different	O
in	O
their	O
design	O
.	O
	
section	O
:	O
Conclusion	O
	
This	O
paper	O
presented	O
an	O
embedding	B-Method
model	I-Method
that	O
learns	O
to	O
perform	O
open	B-Task
QA	I-Task
using	O
training	O
data	O
made	O
of	O
questions	O
paired	O
with	O
their	O
answers	O
and	O
of	O
a	O
KB	O
to	O
provide	O
a	O
structure	O
among	O
answers	O
,	O
and	O
can	O
achieve	O
promising	O
performance	O
on	O
the	O
competitive	O
benchmark	O
WebQuestions	B-Material
.	O
	
section	O
:	O
	
document	O
:	O
[	O
	
Combinatorial	O
features	O
are	O
essential	O
for	O
the	O
success	O
of	O
many	O
commercial	O
models	O
.	O
	
Manually	O
crafting	O
these	O
features	O
usually	O
comes	O
with	O
high	O
cost	B-Metric
due	O
to	O
the	O
variety	O
,	O
volume	O
and	O
velocity	O
of	O
raw	O
data	O
in	O
web	B-Task
-	I-Task
scale	I-Task
systems	I-Task
.	O
	
Factorization	B-Method
based	I-Method
models	I-Method
,	O
which	O
measure	O
interactions	O
in	O
terms	O
of	O
vector	O
product	O
,	O
can	O
learn	O
patterns	O
of	O
combinatorial	O
features	O
automatically	O
and	O
generalize	O
to	O
unseen	O
features	O
as	O
well	O
.	O
	
With	O
the	O
great	O
success	O
of	O
deep	B-Method
neural	I-Method
networks	I-Method
(	O
DNNs	B-Method
)	O
in	O
various	O
fields	O
,	O
recently	O
researchers	O
have	O
proposed	O
several	O
DNN	B-Method
-	O
based	O
factorization	O
model	O
to	O
learn	O
both	O
low	O
-	O
and	O
high	O
-	O
order	O
feature	O
interactions	O
.	O
	
Despite	O
the	O
powerful	O
ability	O
of	O
learning	O
an	O
arbitrary	O
function	O
from	O
data	O
,	O
plain	O
DNNs	B-Method
generate	O
feature	O
interactions	O
implicitly	O
and	O
at	O
the	O
bit	O
-	O
wise	O
level	O
.	O
	
In	O
this	O
paper	O
,	O
we	O
propose	O
a	O
novel	O
Compressed	B-Method
Interaction	I-Method
Network	I-Method
(	O
CIN	B-Method
)	O
,	O
which	O
aims	O
to	O
generate	O
feature	O
interactions	O
in	O
an	O
explicit	O
fashion	O
and	O
at	O
the	O
vector	O
-	O
wise	O
level	O
.	O
	
We	O
show	O
that	O
the	O
CIN	B-Method
share	O
some	O
functionalities	O
with	O
convolutional	B-Method
neural	I-Method
networks	I-Method
(	O
CNNs	B-Method
)	O
and	O
recurrent	B-Method
neural	I-Method
networks	I-Method
(	O
RNNs	B-Method
)	O
.	O
	
We	O
further	O
combine	O
a	O
CIN	B-Method
and	O
a	O
classical	O
DNN	B-Method
into	O
one	O
unified	B-Method
model	I-Method
,	O
and	O
named	O
this	O
new	O
model	O
eXtreme	O
Deep	B-Method
Factorization	I-Method
Machine	I-Method
(	O
xDeepFM	B-Method
)	O
.	O
	
On	O
one	O
hand	O
,	O
the	O
xDeepFM	B-Method
is	O
able	O
to	O
learn	O
certain	O
bounded	O
-	O
degree	O
feature	O
interactions	O
explicitly	O
;	O
on	O
the	O
other	O
hand	O
,	O
it	O
can	O
learn	O
arbitrary	O
low	O
-	O
and	O
high	O
-	O
order	O
feature	O
interactions	O
implicitly	O
.	O
	
We	O
conduct	O
comprehensive	O
experiments	O
on	O
three	O
real	O
-	O
world	O
datasets	O
.	O
	
Our	O
results	O
demonstrate	O
that	O
xDeepFM	B-Method
outperforms	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
models	O
.	O
	
We	O
have	O
released	O
the	O
source	O
code	O
of	O
xDeepFM	B-Method
at	O
.	O
	
Combining	O
Explicit	O
and	O
Implicit	O
Feature	O
Interactions	O
for	O
Recommender	B-Task
Systems	I-Task
]	O
xDeepFM	B-Method
:	O
	
Combining	O
Explicit	O
and	O
Implicit	O
Feature	O
Interactions	O
for	O
Recommender	B-Task
Systems	I-Task
J.	O
Lian	O
]	O
Jianxun	O
Lian	O
X.	O
Zhou	O
]	O
Xiaohuan	O
Zhou	O
F.	O
	
Zhang	O
]	O
Fuzheng	O
Zhang	O
Z.	O
Chen	O
]	O
Zhongxia	O
Chen	O
	
X.	O
Xie	O
]	O
Xing	O
Xie	O
G.	O
Sun	O
]	O
Guangzhong	O
	
Sun	O
¡	O
ccs2012	O
¿	O
¡	O
concept	O
¿	O
¡	O
concept_id¿10002951.10003260.10003261.10003271¡	O
/	O
concept_id	O
¿	O
¡	O
concept_desc¿Information	O
systems	O
Personalization¡	O
/	O
concept_desc	O
¿	O
¡	O
concept_significance¿500¡	O
/	O
concept_significance	O
¿	O
¡	O
/	O
concept	O
¿	O
¡	O
concept	O
¿	O
¡	O
concept_id¿10010147.10010257.10010293.10010294¡	O
/	O
concept_id	O
¿	O
¡	O
concept_desc¿Computing	O
methodologies	O
	
Neural	O
networks¡	O
/	O
concept_desc	O
¿	O
¡	O
concept_significance¿500¡	O
/	O
concept_significance	O
¿	O
¡	O
/	O
concept	O
¿	O
¡	O
concept	O
¿	O
¡	O
concept_id¿10010147.10010257.10010293.10010309¡	O
/	O
concept_id	O
¿	O
¡	O
concept_desc¿Computing	O
methodologies	O
	
Factorization	O
methods¡	O
/	O
concept_desc	O
¿	O
¡	O
concept_significance¿500¡	O
/	O
concept_significance	O
¿	O
¡	O
/	O
concept	O
¿	O
¡	O
/	O
ccs2012	O
	
¿	O
[	O
500	O
]	O
Information	O
systems	O
Personalization	O
[	O
500	O
]	O
Computing	O
methodologies	O
	
Neural	B-Method
networks	I-Method
[	O
500	O
]	O
Computing	O
methodologies	O
	
Factorization	B-Method
methods	I-Method
	
2018	O
2018	O
acmcopyright	O
	
[	O
KDD	B-Method
’	O
	
18	O
]	O
The	O
24th	O
	
ACM	B-Task
SIGKDD	I-Task
International	I-Task
Conference	I-Task
on	O
Knowledge	B-Task
Discovery	I-Task
&	O
Data	B-Task
MiningAugust	I-Task
19–23	O
,	O
	
2018London	O
,	O
United	O
Kingdom	O
KDD	O
’	O
18	O
:	O
	
The	O
24th	O
ACM	B-Task
SIGKDD	I-Task
International	I-Task
Conference	I-Task
on	O
Knowledge	B-Task
Discovery	I-Task
&	I-Task
Data	I-Task
Mining	I-Task
,	O
August	O
19–23	O
,	O
2018	O
,	O
London	O
,	O
United	O
Kingdom	O
15.00	O
10.1145	O
/	O
3219819.3220023	O
	
978	O
-	O
1	O
-	O
4503	O
-	O
5552	O
-	O
0	O
/	O
18	O
/	O
08	O
	
section	O
:	O
introduction	O
	
Features	O
play	O
a	O
central	O
role	O
in	O
the	O
success	O
of	O
many	O
predictive	B-Method
systems	I-Method
.	O
	
Because	O
using	O
raw	O
features	O
can	O
rarely	O
lead	O
to	O
optimal	O
results	O
,	O
data	O
scientists	O
usually	O
spend	O
a	O
lot	O
of	O
work	O
on	O
the	O
transformation	B-Task
of	I-Task
raw	I-Task
features	I-Task
in	O
order	O
to	O
generate	O
best	O
predictive	B-Method
systems	I-Method
or	O
to	O
win	O
data	B-Task
mining	I-Task
games	I-Task
.	O
	
One	O
major	O
type	O
of	O
feature	B-Method
transformation	I-Method
is	O
the	O
cross	B-Method
-	I-Method
product	I-Method
transformation	I-Method
over	O
categorical	O
features	O
.	O
	
These	O
features	O
are	O
called	O
cross	O
features	O
or	O
multi	O
-	O
way	O
features	O
,	O
they	O
measure	O
the	O
interactions	O
of	O
multiple	O
raw	O
features	O
.	O
	
For	O
instance	O
,	O
a	O
3	O
-	O
way	O
feature	O
AND	O
(	O
user_organization	O
=	O
msra	O
,	O
item_category	O
=	O
deeplearning	O
,	O
time	O
=	O
monday	O
)	O
has	O
value	O
1	O
if	O
the	O
user	O
works	O
at	O
Microsoft	O
Research	O
Asia	O
and	O
is	O
shown	O
a	O
technical	O
article	O
about	O
deep	B-Method
learning	I-Method
on	O
a	O
Monday	O
.	O
	
There	O
are	O
three	O
major	O
downsides	O
for	O
traditional	O
cross	B-Method
feature	I-Method
engineering	I-Method
.	O
	
First	O
,	O
obtaining	O
high	O
-	O
quality	O
features	O
comes	O
with	O
a	O
high	O
cost	O
.	O
	
Because	O
right	O
features	O
are	O
usually	O
task	O
-	O
specific	O
,	O
data	B-Task
scientists	I-Task
need	O
spend	O
a	O
lot	O
of	O
time	O
exploring	O
the	O
potential	O
patterns	O
from	O
the	O
product	O
data	O
before	O
they	O
become	O
domain	O
experts	O
and	O
extract	O
meaningful	O
cross	O
features	O
.	O
	
Second	O
,	O
in	O
large	B-Task
-	I-Task
scale	I-Task
predictive	I-Task
systems	I-Task
such	O
as	O
web	B-Task
-	I-Task
scale	I-Task
recommender	I-Task
systems	I-Task
,	O
the	O
huge	O
number	O
of	O
raw	O
features	O
makes	O
it	O
infeasible	O
to	O
extract	O
all	O
cross	O
features	O
manually	O
.	O
	
Third	O
,	O
hand	O
-	O
crafted	O
cross	O
features	O
do	O
not	O
generalize	O
to	O
unseen	O
interactions	O
in	O
the	O
training	O
data	O
.	O
	
Therefore	O
,	O
learning	O
to	O
interact	O
features	O
without	O
manual	B-Task
engineering	I-Task
is	O
a	O
meaningful	O
task	O
.	O
	
Factorization	B-Method
Machines	I-Method
(	O
FM	B-Method
)	O
embed	O
each	O
feature	O
to	O
a	O
latent	O
factor	O
vector	O
,	O
and	O
pairwise	O
feature	O
interactions	O
are	O
modeled	O
as	O
the	O
inner	O
product	O
of	O
latent	O
vectors	O
:	O
.	O
	
In	O
this	O
paper	O
we	O
use	O
the	O
term	O
bit	O
to	O
denote	O
a	O
element	O
(	O
such	O
as	O
)	O
in	O
latent	O
vectors	O
.	O
	
The	O
classical	O
FM	B-Method
can	O
be	O
extended	O
to	O
arbitrary	O
higher	O
-	O
order	O
feature	O
interactions	O
,	O
but	O
one	O
major	O
downside	O
is	O
that	O
,	O
proposes	O
to	O
model	O
all	O
feature	O
interactions	O
,	O
including	O
both	O
useful	O
and	O
useless	O
combinations	O
.	O
	
As	O
revealed	O
in	O
,	O
the	O
interactions	O
with	O
useless	O
features	O
may	O
introduce	O
noises	O
and	O
degrade	O
the	O
performance	O
.	O
	
In	O
recent	O
years	O
,	O
deep	B-Method
neural	I-Method
networks	I-Method
(	O
DNNs	B-Method
)	O
have	O
become	O
successful	O
in	O
computer	B-Task
vision	I-Task
,	O
speech	B-Task
recognition	I-Task
,	O
and	O
natural	B-Task
language	I-Task
processing	I-Task
with	O
their	O
great	O
power	O
of	O
feature	B-Method
representation	I-Method
learning	I-Method
.	O
	
It	O
is	O
promising	O
to	O
exploit	O
DNNs	B-Method
to	O
learn	O
sophisticated	O
and	O
selective	O
feature	O
interactions	O
.	O
	
proposes	O
a	O
Factorisation	B-Method
-	I-Method
machine	I-Method
supported	I-Method
Neural	I-Method
Network	I-Method
(	O
FNN	B-Method
)	O
to	O
learn	O
high	O
-	O
order	O
feature	O
interactions	O
.	O
	
It	O
uses	O
the	O
pre	O
-	O
trained	O
factorization	B-Method
machines	I-Method
for	O
field	B-Task
embedding	I-Task
before	O
applying	O
DNN	B-Method
.	O
	
further	O
proposes	O
a	O
Product	B-Method
-	I-Method
based	I-Method
Neural	I-Method
Network	I-Method
(	O
PNN	B-Method
)	O
,	O
which	O
introduces	O
a	O
product	B-Method
layer	I-Method
between	O
embedding	B-Method
layer	I-Method
and	O
DNN	B-Method
layer	O
,	O
and	O
does	O
not	O
rely	O
on	O
pre	O
-	O
trained	O
FM	B-Method
.	O
	
The	O
major	O
downside	O
of	O
FNN	B-Method
and	O
PNN	B-Method
is	O
that	O
they	O
focus	O
more	O
on	O
high	O
-	O
order	O
feature	O
interactions	O
while	O
capture	O
little	O
low	O
-	O
order	O
interactions	O
.	O
	
The	O
Wide	B-Method
&	I-Method
Deep	I-Method
and	O
DeepFM	B-Method
models	O
overcome	O
this	O
problem	O
by	O
introducing	O
hybrid	B-Method
architectures	I-Method
,	O
which	O
contain	O
a	O
shallow	B-Method
component	I-Method
and	O
a	O
deep	B-Method
component	I-Method
with	O
the	O
purpose	O
of	O
learning	O
both	O
memorization	B-Task
and	I-Task
generalization	I-Task
.	O
	
Therefore	O
they	O
can	O
jointly	O
learn	O
low	O
-	O
order	O
and	O
high	O
-	O
order	O
feature	O
interactions	O
.	O
	
All	O
the	O
abovementioned	O
models	O
leverage	O
DNNs	B-Method
for	O
learning	B-Task
high	I-Task
-	I-Task
order	I-Task
feature	I-Task
interactions	I-Task
.	O
	
However	O
,	O
DNNs	B-Method
model	O
high	O
-	O
order	O
feature	O
interactions	O
in	O
an	O
implicit	O
fashion	O
.	O
	
The	O
final	O
function	O
learned	O
by	O
DNNs	B-Method
can	O
be	O
arbitrary	O
,	O
and	O
there	O
is	O
no	O
theoretical	O
conclusion	O
on	O
what	O
the	O
maximum	O
degree	O
of	O
feature	O
interactions	O
is	O
.	O
	
In	O
addition	O
,	O
DNNs	B-Method
model	O
feature	O
interactions	O
at	O
the	O
bit	O
-	O
wise	O
level	O
,	O
which	O
is	O
different	O
from	O
the	O
traditional	O
FM	B-Method
framework	O
which	O
models	O
feature	O
interactions	O
at	O
the	O
vector	O
-	O
wise	O
level	O
.	O
	
Thus	O
,	O
in	O
the	O
field	O
of	O
recommender	B-Task
systems	I-Task
,	O
whether	O
DNNs	B-Method
are	O
indeed	O
the	O
most	O
effective	O
model	O
in	O
representing	B-Task
high	I-Task
-	I-Task
order	I-Task
feature	I-Task
interactions	I-Task
remains	O
an	O
open	O
question	O
.	O
	
In	O
this	O
paper	O
,	O
we	O
propose	O
a	O
neural	B-Method
network	I-Method
-	I-Method
based	I-Method
model	I-Method
to	O
learn	O
feature	O
interactions	O
in	O
an	O
explicit	O
,	O
vector	O
-	O
wise	O
fashion	O
.	O
	
Our	O
approach	O
is	O
based	O
on	O
the	O
Deep	B-Method
&	I-Method
Cross	I-Method
Network	I-Method
(	O
DCN	B-Method
)	O
,	O
which	O
aims	O
to	O
efficiently	O
capture	O
feature	O
interactions	O
of	O
bounded	O
degrees	O
.	O
	
However	O
,	O
we	O
will	O
argue	O
in	O
Section	O
[	O
reference	O
]	O
that	O
DCN	B-Method
will	O
lead	O
to	O
a	O
special	O
format	O
of	O
interactions	O
.	O
	
We	O
thus	O
design	O
a	O
novel	O
compressed	B-Method
interaction	I-Method
network	I-Method
(	O
CIN	B-Method
)	O
to	O
replace	O
the	O
cross	B-Method
network	I-Method
in	O
the	O
DCN	B-Method
.	O
	
CIN	B-Method
learns	O
feature	O
interactions	O
explicitly	O
,	O
and	O
the	O
degree	O
of	O
interactions	O
grows	O
with	O
the	O
depth	O
of	O
the	O
network	O
.	O
	
Following	O
the	O
spirit	O
of	O
the	O
Wide	B-Method
&	I-Method
Deep	I-Method
and	O
DeepFM	B-Method
models	O
,	O
we	O
combine	O
the	O
explicit	B-Method
high	I-Method
-	I-Method
order	I-Method
interaction	I-Method
module	I-Method
with	O
implicit	B-Method
interaction	I-Method
module	I-Method
and	O
traditional	O
FM	B-Method
module	O
,	O
and	O
name	O
the	O
joint	B-Method
model	I-Method
eXtreme	O
Deep	B-Method
Factorization	I-Method
Machine	I-Method
(	O
xDeepFM	B-Method
)	O
.	O
	
The	O
new	O
model	O
requires	O
no	O
manual	B-Task
feature	I-Task
engineering	I-Task
and	O
release	O
data	B-Task
scientists	I-Task
from	O
tedious	O
feature	B-Task
searching	I-Task
work	O
.	O
	
To	O
summarize	O
,	O
we	O
make	O
the	O
following	O
contributions	O
:	O
We	O
propose	O
a	O
novel	O
model	O
,	O
named	O
eXtreme	O
Deep	B-Method
Factorization	I-Method
Machine	I-Method
(	O
xDeepFM	B-Method
)	O
,	O
that	O
jointly	O
learns	O
explicit	O
and	O
implicit	O
high	O
-	O
order	O
feature	O
interactions	O
effectively	O
and	O
requires	O
no	O
manual	B-Method
feature	I-Method
engineering	I-Method
.	O
	
We	O
design	O
a	O
compressed	B-Method
interaction	I-Method
network	I-Method
(	O
CIN	B-Method
)	O
in	O
xDeepFM	B-Method
that	O
learns	O
high	O
-	O
order	O
feature	O
interactions	O
explicitly	O
.	O
	
We	O
show	O
that	O
the	O
degree	O
of	O
feature	O
interactions	O
increases	O
at	O
each	O
layer	O
,	O
and	O
features	O
interact	O
at	O
the	O
vector	O
-	O
wise	O
level	O
rather	O
than	O
the	O
bit	O
-	O
wise	O
level	O
.	O
	
We	O
conduct	O
extensive	O
experiments	O
on	O
three	O
real	O
-	O
world	O
dataset	O
,	O
and	O
the	O
results	O
demonstrate	O
that	O
our	O
xDeepFM	B-Method
outperforms	O
several	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
models	O
significantly	O
.	O
	
The	O
rest	O
of	O
this	O
paper	O
is	O
organized	O
as	O
follows	O
.	O
	
Section	O
[	O
reference	O
]	O
provides	O
some	O
preliminary	O
knowledge	O
which	O
is	O
necessary	O
for	O
understanding	O
deep	B-Method
learning	I-Method
-	I-Method
based	I-Method
recommender	I-Method
systems	I-Method
.	O
	
Section	O
[	O
reference	O
]	O
introduces	O
our	O
proposed	O
CIN	B-Method
and	O
xDeepFM	B-Method
model	I-Method
in	O
detail	O
.	O
	
We	O
will	O
present	O
experimental	O
explorations	O
on	O
multiple	O
datasets	O
in	O
Section	O
[	O
reference	O
]	O
.	O
	
Related	O
works	O
are	O
discussed	O
in	O
Section	O
[	O
reference	O
]	O
.	O
	
Section	O
[	O
reference	O
]	O
concludes	O
this	O
paper	O
.	O
	
section	O
:	O
Preliminaries	O
	
subsection	O
:	O
Embedding	B-Method
Layer	I-Method
	
In	O
computer	B-Task
vision	I-Task
or	O
natural	B-Task
language	I-Task
understanding	I-Task
,	O
the	O
input	O
data	O
are	O
usually	O
images	O
or	O
textual	O
signals	O
,	O
which	O
are	O
known	O
to	O
be	O
spatially	O
and	O
/	O
or	O
temporally	O
correlated	O
,	O
so	O
DNNs	B-Method
can	O
be	O
applied	O
directly	O
on	O
the	O
raw	O
feature	O
with	O
dense	O
structures	O
.	O
	
However	O
,	O
in	O
web	B-Task
-	I-Task
scale	I-Task
recommender	I-Task
systems	I-Task
,	O
the	O
input	O
features	O
are	O
sparse	O
,	O
of	O
huge	O
dimension	O
,	O
and	O
present	O
no	O
clear	O
spatial	O
or	O
temporal	O
correlation	O
.	O
	
Therefore	O
,	O
multi	O
-	O
field	O
categorical	O
form	O
is	O
widely	O
used	O
by	O
related	O
works	O
.	O
	
For	O
example	O
,	O
one	O
input	O
instance	O
[	O
user_id	O
=	O
s02	O
,	O
gender	O
=	O
male	O
,	O
organization	O
=	O
msra	O
,	O
interests	O
=	O
comedy	O
&	O
rock	O
]	O
is	O
normally	O
transformed	O
into	O
a	O
high	O
-	O
dimensional	O
sparse	O
features	O
via	O
field	B-Method
-	I-Method
aware	I-Method
one	I-Method
-	I-Method
hot	I-Method
encoding	I-Method
:	O
An	O
embedding	B-Method
layer	I-Method
is	O
applied	O
upon	O
the	O
raw	O
feature	O
input	O
to	O
compress	O
it	O
to	O
a	O
low	O
dimensional	O
,	O
dense	O
real	O
-	O
value	O
vector	O
.	O
	
If	O
the	O
field	O
is	O
univalent	O
,	O
the	O
feature	B-Method
embedding	I-Method
is	O
used	O
as	O
the	O
field	B-Method
embedding	I-Method
.	O
	
Take	O
the	O
above	O
instance	O
as	O
an	O
example	O
,	O
the	O
embedding	O
of	O
feature	O
male	O
is	O
taken	O
as	O
the	O
embedding	O
of	O
field	O
gender	O
.	O
	
If	O
the	O
field	O
is	O
multivalent	O
,	O
the	O
sum	B-Method
of	I-Method
feature	I-Method
embedding	I-Method
is	O
used	O
as	O
the	O
field	B-Method
embedding	I-Method
.	O
	
The	O
embedding	B-Method
layer	I-Method
is	O
illustrated	O
in	O
Figure	O
[	O
reference	O
]	O
.	O
	
The	O
result	O
of	O
embedding	B-Method
layer	I-Method
is	O
a	O
wide	O
concatenated	O
vector	O
:	O
where	O
denotes	O
the	O
number	O
of	O
fields	O
,	O
and	O
denotes	O
the	O
embedding	O
of	O
one	O
field	O
.	O
	
Although	O
the	O
feature	O
lengths	O
of	O
instances	O
can	O
be	O
various	O
,	O
their	O
embeddings	O
are	O
of	O
the	O
same	O
length	O
,	O
where	O
is	O
the	O
dimension	O
of	O
field	B-Method
embedding	I-Method
.	O
	
subsection	O
:	O
Implicit	B-Task
High	I-Task
-	I-Task
order	I-Task
Interactions	I-Task
	
FNN	B-Method
,	O
Deep	B-Method
Crossing	I-Method
,	O
and	O
the	O
deep	B-Method
part	I-Method
in	O
Wide	B-Method
&	I-Method
Deep	I-Method
exploit	O
a	O
feed	B-Method
-	I-Method
forward	I-Method
neural	I-Method
network	I-Method
on	O
the	O
field	O
embedding	O
vector	O
to	O
learn	O
high	O
-	O
order	O
feature	O
interactions	O
.	O
	
The	O
forward	B-Method
process	I-Method
is	O
:	O
where	O
is	O
the	O
layer	O
depth	O
,	O
is	O
an	O
activation	O
function	O
,	O
and	O
is	O
the	O
output	O
of	O
the	O
-	O
th	O
layer	O
.	O
	
The	O
visual	O
structure	O
is	O
very	O
similar	O
to	O
what	O
is	O
shown	O
in	O
Figure	O
[	O
reference	O
]	O
,	O
except	O
that	O
they	O
do	O
not	O
include	O
the	O
FM	B-Method
or	O
Product	O
layer	O
.	O
	
This	O
architecture	O
models	O
the	O
interaction	O
in	O
a	O
bit	O
-	O
wise	O
fashion	O
.	O
	
That	O
is	O
to	O
say	O
,	O
even	O
the	O
elements	O
within	O
the	O
same	O
field	O
embedding	O
vector	O
will	O
influence	O
each	O
other	O
.	O
	
PNN	B-Method
and	O
DeepFM	B-Method
modify	O
the	O
above	O
architecture	O
slightly	O
.	O
	
Besides	O
applying	O
DNNs	B-Method
on	O
the	O
embedding	O
vector	O
,	O
they	O
add	O
a	O
two	O
-	O
way	B-Method
interaction	I-Method
layer	I-Method
in	O
the	O
architecture	O
.	O
	
Therefore	O
,	O
both	O
bit	O
-	O
wise	O
and	O
vector	O
-	O
wise	O
interaction	O
is	O
included	O
in	O
their	O
model	O
.	O
	
The	O
major	O
difference	O
between	O
PNN	B-Method
and	O
DeepFM	B-Method
,	O
is	O
that	O
PNN	B-Method
connects	O
the	O
outputs	O
of	O
product	O
layer	O
to	O
the	O
DNNs	B-Method
,	O
whereas	O
DeepFM	B-Method
connects	O
the	O
FM	B-Method
layer	O
directly	O
to	O
the	O
output	O
unit	O
(	O
refer	O
to	O
Figure	O
[	O
reference	O
]	O
)	O
.	O
	
subsection	O
:	O
Explicit	O
High	O
-	O
order	O
Interactions	O
	
proposes	O
the	O
Cross	B-Method
Network	I-Method
(	O
CrossNet	B-Method
)	O
whose	O
architecture	O
is	O
shown	O
in	O
Figure	O
[	O
reference	O
]	O
.	O
	
It	O
aims	O
to	O
explicitly	O
model	O
the	O
high	O
-	O
order	O
feature	O
interactions	O
.	O
	
Unlike	O
the	O
classical	O
fully	B-Method
-	I-Method
connected	I-Method
feed	I-Method
-	I-Method
forward	I-Method
network	I-Method
,	O
the	O
hidden	O
layers	O
are	O
calculated	O
by	O
the	O
following	O
cross	B-Method
operation	I-Method
:	O
where	O
are	O
weights	O
,	O
bias	O
and	O
output	O
of	O
the	O
-	O
th	O
layer	O
,	O
respectively	O
.	O
	
We	O
argue	O
that	O
the	O
CrossNet	B-Method
learns	O
a	O
special	O
type	O
of	O
high	O
-	O
order	O
feature	O
interactions	O
,	O
where	O
each	O
hidden	O
layer	O
in	O
the	O
CrossNet	B-Method
is	O
a	O
scalar	O
multiple	O
of	O
.	O
	
Consider	O
a	O
-	B-Method
layer	I-Method
cross	I-Method
network	I-Method
with	O
the	O
(	O
i	O
+	O
1	O
)-	O
th	O
layer	O
defined	O
as	O
.	O
	
Then	O
,	O
the	O
output	O
of	O
the	O
cross	B-Method
network	I-Method
is	O
a	O
scalar	O
multiple	O
of	O
.	O
	
When	O
=	O
1	O
,	O
according	O
to	O
the	O
associative	O
law	O
and	O
distributive	B-Method
law	I-Method
for	O
matrix	B-Task
multiplication	I-Task
,	O
we	O
have	O
:	O
where	O
the	O
scalar	O
is	O
actually	O
a	O
linear	B-Method
regression	I-Method
of	O
.	O
	
Thus	O
,	O
is	O
a	O
scalar	O
multiple	O
of	O
.	O
	
Suppose	O
the	O
scalar	O
multiple	O
statement	O
holds	O
for	O
=	O
.	O
	
For	O
=	O
,	O
we	O
have	O
:	O
where	O
,	O
is	O
a	O
scalar	O
.	O
	
Thus	O
is	O
still	O
a	O
scalar	O
multiple	O
of	O
.	O
	
By	O
induction	O
hypothesis	O
,	O
the	O
output	O
of	O
cross	B-Method
network	I-Method
is	O
a	O
scalar	O
multiple	O
of	O
.	O
	
Note	O
that	O
the	O
scalar	O
multiple	O
does	O
not	O
mean	O
is	O
linear	O
with	O
.	O
	
The	O
coefficient	O
is	O
sensitive	O
with	O
.	O
	
The	O
CrossNet	B-Method
can	O
learn	O
feature	O
interactions	O
very	O
efficiently	O
(	O
the	O
complexity	B-Metric
is	O
negligible	O
compared	O
with	O
a	O
DNN	B-Method
model	O
)	O
,	O
however	O
the	O
downsides	O
are	O
:	O
(	O
1	O
)	O
the	O
output	O
of	O
CrossNet	B-Method
is	O
limited	O
in	O
a	O
special	O
form	O
,	O
with	O
each	O
hidden	O
layer	O
is	O
a	O
scalar	O
multiple	O
of	O
;	O
(	O
2	O
)	O
interactions	O
come	O
in	O
a	O
bit	O
-	O
wise	O
fashion	O
.	O
	
section	O
:	O
Our	O
proposed	O
model	O
	
.33	O
	
.32	O
	
.32	O
	
subsection	O
:	O
Compressed	B-Method
Interaction	I-Method
Network	I-Method
	
We	O
design	O
a	O
new	O
cross	B-Method
network	I-Method
,	O
named	O
Compressed	B-Method
Interaction	I-Method
Network	I-Method
(	O
CIN	B-Method
)	O
,	O
with	O
the	O
following	O
considerations	O
:	O
(	O
1	O
)	O
interactions	O
are	O
applied	O
at	O
vector	O
-	O
wise	O
level	O
,	O
not	O
at	O
bit	O
-	O
wise	O
level	O
;	O
(	O
2	O
)	O
high	O
-	O
order	O
feature	O
interactions	O
is	O
measured	O
explicitly	O
;	O
(	O
3	O
)	O
the	O
complexity	B-Metric
of	O
network	O
will	O
not	O
grow	O
exponentially	O
with	O
the	O
degree	O
of	O
interactions	O
.	O
	
Since	O
an	O
embedding	O
vector	O
is	O
regarded	O
as	O
a	O
unit	O
for	O
vector	O
-	O
wise	O
interactions	O
,	O
hereafter	O
we	O
formulate	O
the	O
output	O
of	O
field	B-Method
embedding	I-Method
as	O
a	O
matrix	O
,	O
where	O
the	O
-	O
th	O
row	O
in	O
is	O
the	O
embedding	O
vector	O
of	O
the	O
-	O
th	O
field	O
:	O
,	O
and	O
is	O
the	O
dimension	O
of	O
the	O
field	B-Method
embedding	I-Method
.	O
	
The	O
output	O
of	O
the	O
-	B-Method
th	I-Method
layer	I-Method
in	O
CIN	B-Method
is	O
also	O
a	O
matrix	O
,	O
where	O
denotes	O
the	O
number	O
of	O
(	O
embedding	O
)	O
feature	O
vectors	O
in	O
the	O
-	O
th	O
layer	O
and	O
we	O
let	O
.	O
	
For	O
each	O
layer	O
,	O
are	O
calculated	O
via	O
:	O
where	O
,	O
is	O
the	O
parameter	O
matrix	O
for	O
the	O
-	O
th	O
feature	O
vector	O
,	O
and	O
denotes	O
the	O
Hadamard	O
product	O
,	O
for	O
example	O
,	O
.	O
	
Note	O
that	O
is	O
derived	O
via	O
the	O
interactions	O
between	O
and	O
,	O
thus	O
feature	O
interactions	O
are	O
measured	O
explicitly	O
and	O
the	O
degree	O
of	O
interactions	O
increases	O
with	O
the	O
layer	O
depth	O
.	O
	
The	O
structure	O
of	O
CIN	B-Method
is	O
very	O
similar	O
to	O
the	O
Recurrent	B-Method
Neural	I-Method
Network	I-Method
(	O
RNN	B-Method
)	O
,	O
where	O
the	O
outputs	O
of	O
the	O
next	O
hidden	O
layer	O
are	O
dependent	O
on	O
the	O
last	O
hidden	O
layer	O
and	O
an	O
additional	O
input	O
.	O
	
We	O
hold	O
the	O
structure	O
of	O
embedding	O
vectors	O
at	O
all	O
layers	O
,	O
thus	O
the	O
interactions	O
are	O
applied	O
at	O
the	O
vector	O
-	O
wise	O
level	O
.	O
	
It	O
is	O
interesting	O
to	O
point	O
out	O
that	O
Equation	O
[	O
reference	O
]	O
has	O
strong	O
connections	O
with	O
the	O
well	O
-	O
known	O
Convolutional	B-Method
Neural	I-Method
Networks	I-Method
(	O
CNNs	B-Method
)	O
in	O
computer	B-Task
vision	I-Task
.	O
	
As	O
shown	O
in	O
Figure	O
[	O
reference	O
]	O
,	O
we	O
introduce	O
an	O
intermediate	O
tensor	O
,	O
which	O
is	O
the	O
outer	O
products	O
(	O
along	O
each	O
embedding	O
dimension	O
)	O
of	O
hidden	O
layer	O
and	O
original	O
feature	O
matrix	O
.	O
	
Then	O
can	O
be	O
regarded	O
as	O
a	O
special	O
type	O
of	O
image	O
and	O
is	O
a	O
filter	B-Method
.	O
	
We	O
slide	O
the	O
filter	O
across	O
along	O
the	O
embedding	O
dimension	O
(	O
D	O
)	O
as	O
shown	O
in	O
Figure	O
[	O
reference	O
]	O
,	O
and	O
get	O
an	O
hidden	O
vector	O
,	O
which	O
is	O
usually	O
called	O
a	O
feature	B-Task
map	I-Task
in	O
computer	B-Task
vision	I-Task
.	O
	
Therefore	O
,	O
is	O
a	O
collection	O
of	O
different	O
feature	O
maps	O
.	O
	
The	O
term	O
“	O
compressed	O
”	O
in	O
the	O
name	O
of	O
CIN	B-Method
indicates	O
that	O
the	O
-	O
th	O
hidden	B-Method
layer	I-Method
compress	O
the	O
potential	O
space	O
of	O
vectors	O
down	O
to	O
vectors	O
.	O
	
Figure	O
[	O
reference	O
]	O
provides	O
an	O
overview	O
of	O
the	O
architecture	O
of	O
CIN	B-Method
.	O
	
Let	O
T	O
denotes	O
the	O
depth	O
of	O
the	O
network	O
.	O
	
Every	O
hidden	B-Method
layer	I-Method
has	O
a	O
connection	O
with	O
output	O
units	O
.	O
	
We	O
first	O
apply	O
sum	B-Method
pooling	I-Method
on	O
each	O
feature	O
map	O
of	O
the	O
hidden	O
layer	O
:	O
for	O
.	O
	
Thus	O
,	O
we	O
have	O
a	O
pooling	O
vector	O
with	O
length	O
for	O
the	O
-	O
th	O
hidden	O
layer	O
.	O
	
All	O
pooling	O
vectors	O
from	O
hidden	O
layers	O
are	O
concatenated	O
before	O
connected	O
to	O
output	O
units	O
:	O
.	O
	
If	O
we	O
use	O
CIN	B-Method
directly	O
for	O
binary	B-Task
classification	I-Task
,	O
the	O
output	O
unit	O
is	O
a	O
sigmoid	O
node	O
on	O
:	O
where	O
are	O
the	O
regression	O
parameters	O
.	O
	
subsection	O
:	O
CIN	B-Method
Analysis	O
	
We	O
analyze	O
the	O
proposed	O
CIN	B-Method
to	O
study	O
the	O
model	B-Metric
complexity	I-Metric
and	O
the	O
potential	O
effectiveness	O
.	O
	
subsubsection	O
:	O
Space	B-Metric
Complexity	I-Metric
	
The	O
-	O
th	O
feature	O
map	O
at	O
the	O
-	O
th	O
layer	O
contains	O
parameters	O
,	O
which	O
is	O
exactly	O
the	O
size	O
of	O
.	O
	
Thus	O
,	O
there	O
are	O
parameters	O
at	O
the	O
-	O
th	O
layer	O
.	O
	
Considering	O
the	O
last	O
regression	B-Method
layer	I-Method
for	O
the	O
output	O
unit	O
,	O
which	O
has	O
parameters	O
,	O
the	O
total	O
number	O
of	O
parameters	O
for	O
CIN	B-Method
is	O
.	O
	
Note	O
that	O
CIN	B-Method
is	O
independent	O
of	O
the	O
embedding	O
dimension	O
.	O
	
In	O
contrast	O
,	O
a	O
plain	O
-	O
layers	O
DNN	B-Method
contains	O
parameters	O
,	O
and	O
the	O
number	O
of	O
parameters	O
will	O
increase	O
with	O
the	O
embedding	O
dimension	O
.	O
	
Usually	O
and	O
will	O
not	O
be	O
very	O
large	O
,	O
so	O
the	O
scale	O
of	O
is	O
acceptable	O
.	O
	
When	O
necessary	O
,	O
we	O
can	O
exploit	O
a	O
-	B-Method
order	I-Method
decomposition	I-Method
and	O
replace	O
with	O
two	O
smaller	O
matrices	O
and	O
:	O
where	O
and	O
.	O
	
Hereafter	O
we	O
assume	O
that	O
each	O
hidden	O
layer	O
has	O
the	O
same	O
number	O
(	O
which	O
is	O
)	O
of	O
feature	O
maps	O
for	O
simplicity	O
.	O
	
Through	O
the	O
-	B-Method
order	I-Method
decomposition	I-Method
,	O
the	O
space	O
complexity	O
of	O
CIN	B-Method
is	O
reduced	O
from	O
to	O
.	O
	
In	O
contrast	O
,	O
the	O
space	B-Metric
complexity	I-Metric
of	O
the	O
plain	B-Method
DNN	I-Method
is	O
,	O
which	O
is	O
sensitive	O
to	O
the	O
dimension	O
(	O
D	O
)	O
of	O
field	B-Method
embedding	I-Method
.	O
	
subsubsection	B-Method
:	O
Time	B-Metric
Complexity	I-Metric
	
The	O
cost	O
of	O
computing	O
tensor	O
(	O
as	O
shown	O
in	O
Figure	O
[	O
reference	O
]	O
)	O
is	O
time	O
.	O
	
Because	O
we	O
have	O
feature	O
maps	O
in	O
one	O
hidden	O
layer	O
,	O
computing	O
a	O
-	O
layers	O
CIN	B-Method
takes	O
time	O
.	O
	
A	O
-	O
layers	O
plain	O
DNN	B-Method
,	O
by	O
contrast	O
,	O
takes	O
time	O
.	O
	
Therefore	O
,	O
the	O
major	O
downside	O
of	O
CIN	B-Method
lies	O
in	O
the	O
time	B-Metric
complexity	I-Metric
.	O
	
subsubsection	B-Method
:	O
Polynomial	B-Method
Approximation	I-Method
	
Next	O
we	O
examine	O
the	O
high	O
-	O
order	O
interaction	O
properties	O
of	O
CIN	B-Method
.	O
	
For	O
simplicity	O
,	O
we	O
assume	O
that	O
numbers	O
of	O
feature	O
maps	O
at	O
hidden	O
layers	O
are	O
all	O
equal	O
to	O
the	O
number	O
of	O
fields	O
.	O
	
Let	O
denote	O
the	O
set	O
of	O
positive	O
integers	O
that	O
are	O
less	O
than	O
or	O
equal	O
to	O
.	O
	
The	O
-	O
th	O
feature	O
map	O
at	O
the	O
first	O
layer	O
,	O
denoted	O
as	O
,	O
is	O
calculated	O
via	O
:	O
	
Therefore	O
,	O
each	O
feature	O
map	O
at	O
the	O
first	O
layer	O
models	O
pair	O
-	O
wise	O
interactions	O
with	O
coefficients	O
.	O
	
Similarly	O
,	O
the	O
-	O
th	O
feature	O
map	O
at	O
the	O
second	O
layer	O
is	O
:	O
	
Note	O
that	O
all	O
calculations	O
related	O
to	O
the	O
subscript	O
and	O
is	O
already	O
finished	O
at	O
the	O
previous	O
hidden	O
layer	O
.	O
	
We	O
expand	O
the	O
factors	O
in	O
Equation	O
[	O
reference	O
]	O
just	O
for	O
clarity	O
.	O
	
We	O
can	O
observe	O
that	O
each	O
feature	O
map	O
at	O
the	O
second	O
layer	O
models	O
3	O
-	O
way	O
interactions	O
with	O
new	O
parameters	O
.	O
	
A	O
classical	O
-	O
order	O
polynomial	O
has	O
coefficients	O
.	O
	
We	O
show	O
that	O
CIN	B-Method
approximate	O
this	O
class	O
of	O
polynomial	O
with	O
only	O
parameters	O
in	O
terms	O
of	O
a	O
chain	B-Method
of	I-Method
feature	I-Method
maps	I-Method
.	O
	
By	O
induction	O
hypothesis	O
,	O
we	O
can	O
prove	O
that	O
the	O
-	O
th	O
feature	O
map	O
at	O
the	O
-	O
th	O
layer	O
is	O
:	O
For	O
better	O
illustration	O
,	O
here	O
we	O
borrow	O
the	O
notations	O
from	O
.	O
	
Let	O
denote	O
a	O
multi	O
-	O
index	O
,	O
and	O
.	O
	
We	O
omit	O
the	O
original	O
superscript	O
from	O
,	O
and	O
use	O
to	O
denote	O
it	O
since	O
we	O
only	O
we	O
the	O
feature	O
maps	O
from	O
the	O
-	O
th	O
layer	O
(	O
which	O
is	O
exactly	O
the	O
field	O
embeddings	O
)	O
for	O
the	O
final	O
expanded	O
expression	O
(	O
refer	O
to	O
Eq	O
.	O
	
[	O
reference	O
]	O
)	O
.	O
	
Now	O
a	O
superscript	O
is	O
used	O
to	O
denote	O
the	O
vector	O
operation	O
,	O
such	O
as	O
.	O
	
Let	O
denote	O
a	O
multi	O
-	O
vector	O
polynomial	O
of	O
degree	O
:	O
Each	O
vector	O
polylnomial	O
in	O
this	O
class	O
has	O
coefficients	O
.	O
	
Then	O
,	O
our	O
CIN	B-Method
approaches	O
the	O
coefficient	O
with	O
:	O
where	O
,	O
is	O
a	O
multi	O
-	O
index	O
,	O
and	O
is	O
the	O
set	O
of	O
all	O
the	O
permutations	O
of	O
the	O
indices	O
.	O
	
subsection	O
:	O
Combination	O
with	O
Implicit	B-Method
Networks	I-Method
	
As	O
discussed	O
in	O
Section	O
[	O
reference	O
]	O
,	O
plain	O
DNNs	B-Method
learn	O
implicit	O
high	O
-	O
order	O
feature	O
interactions	O
.	O
	
Since	O
CIN	B-Method
and	O
plain	B-Method
DNNs	I-Method
can	O
complement	O
each	O
other	O
,	O
an	O
intuitive	O
way	O
to	O
make	O
the	O
model	O
stronger	O
is	O
to	O
combine	O
these	O
two	O
structures	O
.	O
	
The	O
resulting	O
model	O
is	O
very	O
similar	O
to	O
the	O
Wide	B-Method
&	I-Method
Deep	I-Method
or	O
DeepFM	B-Method
model	I-Method
.	O
	
The	O
architecture	O
is	O
shown	O
in	O
Figure	O
[	O
reference	O
]	O
.	O
	
We	O
name	O
the	O
new	O
model	O
eXtreme	O
Deep	B-Method
Factorization	I-Method
Machine	I-Method
(	O
xDeepFM	B-Method
)	O
,	O
considering	O
that	O
on	O
one	O
hand	O
,	O
it	O
includes	O
both	O
low	O
-	O
order	O
and	O
high	O
-	O
order	O
feature	O
interactions	O
;	O
on	O
the	O
other	O
hand	O
,	O
it	O
includes	O
both	O
implicit	O
feature	O
interactions	O
and	O
explicit	O
feature	O
interactions	O
.	O
	
Its	O
resulting	O
output	O
unit	O
becomes	O
:	O
where	O
is	O
the	O
sigmoid	O
function	O
,	O
is	O
the	O
raw	O
features	O
.	O
	
are	O
the	O
outputs	O
of	O
the	O
plain	B-Method
DNN	I-Method
and	O
CIN	B-Method
,	O
respectively	O
.	O
	
and	O
are	O
learnable	O
parameters	O
.	O
	
For	O
binary	B-Task
classifications	I-Task
,	O
the	O
loss	B-Metric
function	I-Metric
is	O
the	O
log	B-Metric
loss	I-Metric
:	O
where	O
is	O
the	O
total	O
number	O
of	O
training	O
instances	O
.	O
	
The	O
optimization	B-Task
process	I-Task
is	O
to	O
minimize	O
the	O
following	O
objective	B-Metric
function	I-Metric
:	O
where	O
denotes	O
the	O
regularization	O
term	O
and	O
denotes	O
the	O
set	O
of	O
parameters	O
,	O
including	O
these	O
in	O
linear	O
part	O
,	O
CIN	B-Method
part	O
,	O
and	O
DNN	B-Method
part	O
.	O
	
subsubsection	O
:	O
Relationship	O
with	O
FM	B-Method
and	O
DeepFM	B-Method
	
Suppose	O
all	O
fields	O
are	O
univalent	O
.	O
	
It	O
’s	O
not	O
hard	O
to	O
observe	O
from	O
Figure	O
[	O
reference	O
]	O
that	O
,	O
when	O
the	O
depth	O
and	O
feature	O
maps	O
of	O
the	O
CIN	B-Method
part	O
are	O
both	O
set	O
to	O
1	O
,	O
xDeepFM	B-Method
is	O
a	O
generalization	O
of	O
DeepFM	B-Method
by	O
learning	O
the	O
linear	B-Method
regression	I-Method
weights	I-Method
for	O
the	O
FM	B-Method
layer	O
(	O
note	O
that	O
in	O
DeepFM	B-Method
,	O
units	O
of	O
FM	B-Method
layer	O
are	O
directly	O
linked	O
to	O
the	O
output	O
unit	O
without	O
any	O
coefficients	O
)	O
.	O
	
When	O
we	O
further	O
remove	O
the	O
DNN	B-Method
part	O
,	O
and	O
at	O
the	O
same	O
time	O
use	O
a	O
constant	B-Method
sum	I-Method
filter	I-Method
(	O
which	O
simply	O
takes	O
the	O
sum	O
of	O
inputs	O
without	O
any	O
parameter	B-Method
learning	I-Method
)	O
for	O
the	O
feature	O
map	O
,	O
then	O
xDeepFM	B-Method
is	O
downgraded	O
to	O
the	O
traditional	O
FM	B-Method
model	O
.	O
	
section	O
:	O
Experiments	O
	
In	O
this	O
section	O
,	O
we	O
conduct	O
extensive	O
experiments	O
to	O
answer	O
the	O
following	O
questions	O
:	O
(	O
Q1	O
)	O
	
How	O
does	O
our	O
proposed	O
CIN	B-Method
perform	O
in	O
high	B-Task
-	I-Task
order	I-Task
feature	I-Task
interactions	I-Task
learning	I-Task
?	O
	
(	O
Q2	O
)	O
Is	O
it	O
necessary	O
to	O
combine	O
explicit	O
and	O
implicit	O
high	O
-	O
order	O
feature	O
interactions	O
for	O
recommender	B-Task
systems	I-Task
?	O
	
(	O
Q3	O
)	O
	
How	O
does	O
the	O
settings	O
of	O
networks	O
influence	O
the	O
performance	O
of	O
xDeepFM	B-Method
?	O
	
We	O
will	O
answer	O
these	O
questions	O
after	O
presenting	O
some	O
fundamental	O
experimental	O
settings	O
.	O
	
subsection	O
:	O
Experiment	O
Setup	O
	
subsubsection	O
:	O
Datasets	O
.	O
	
We	O
evaluate	O
our	O
proposed	O
models	O
on	O
the	O
following	O
three	O
datasets	O
:	O
1	O
.	O
	
Criteo	B-Material
Dataset	I-Material
.	O
	
It	O
is	O
a	O
famous	O
industry	O
benchmarking	O
dataset	O
for	O
developing	O
models	O
predicting	B-Task
ad	I-Task
click	I-Task
-	I-Task
through	I-Task
rate	I-Task
,	O
and	O
is	O
publicly	O
accessible	O
.	O
	
Given	O
a	O
user	O
and	O
the	O
page	O
he	O
is	O
visiting	O
,	O
the	O
goal	O
is	O
to	O
predict	O
the	O
probability	O
that	O
he	O
will	O
clik	O
on	O
a	O
given	O
ad	O
.	O
	
2	O
.	O
	
Dianping	B-Material
Dataset	I-Material
.	O
	
Dianping.com	B-Method
is	O
the	O
largest	O
consumer	O
review	O
site	O
in	O
China	O
.	O
	
It	O
provides	O
diverse	O
functions	O
such	O
as	O
reviews	O
,	O
check	O
-	O
ins	O
,	O
and	O
shops	O
’	O
meta	O
information	O
(	O
including	O
geographical	O
messages	O
and	O
shop	O
attributes	O
)	O
.	O
	
We	O
collect	O
6	O
months	O
’	O
users	O
check	O
-	O
in	O
activities	O
for	O
restaurant	B-Task
recommendation	I-Task
experiments	O
.	O
	
Given	O
a	O
user	O
’s	O
profile	O
,	O
a	O
restaurant	O
’s	O
attributes	O
and	O
the	O
user	O
’s	O
last	O
three	O
visited	O
POIs	O
(	O
point	O
of	O
interest	O
)	O
,	O
we	O
want	O
to	O
predict	O
the	O
probability	O
that	O
he	O
will	O
visit	O
the	O
restaurant	O
.	O
	
For	O
each	O
restaurant	O
in	O
a	O
user	O
’s	O
check	O
-	O
in	O
instance	O
,	O
we	O
sample	O
four	O
restaurants	O
which	O
are	O
within	O
3	O
kilometers	O
as	O
negative	O
instances	O
by	O
POI	O
popularity	O
.	O
	
3	O
.	O
	
Bing	B-Material
News	I-Material
Dataset	I-Material
.	O
	
Bing	B-Material
News	I-Material
is	O
part	O
of	O
Microsoft	O
’s	O
Bing	O
search	O
engine	O
.	O
	
In	O
order	O
to	O
evaluate	O
the	O
performance	O
of	O
our	O
model	O
in	O
a	O
real	O
commercial	O
dataset	O
,	O
we	O
collect	O
five	O
consecutive	O
days	O
’	O
impression	O
logs	O
on	O
news	O
reading	O
service	O
.	O
	
We	O
use	O
the	O
first	O
three	O
days	O
’	O
data	O
for	O
training	O
and	O
validation	B-Task
,	O
and	O
the	O
next	O
two	O
days	O
for	O
testing	O
.	O
	
For	O
the	O
Criteo	B-Material
dataset	I-Material
and	O
the	O
Dianping	B-Material
dataset	O
,	O
we	O
randomly	O
split	O
instances	O
by	O
8:1:1	O
for	O
training	O
,	O
validation	B-Task
and	O
test	O
.	O
	
The	O
characteristics	O
of	O
the	O
three	O
datasets	O
are	O
summarized	O
in	O
Table	O
[	O
reference	O
]	O
.	O
	
subsubsection	O
:	O
Evaluation	B-Metric
Metrics	I-Metric
.	O
	
We	O
use	O
two	O
metrics	O
for	O
model	B-Metric
evaluation	I-Metric
:	O
AUC	B-Metric
(	O
Area	B-Metric
Under	I-Metric
the	I-Metric
ROC	I-Metric
curve	I-Metric
)	O
and	O
Logloss	B-Metric
(	O
cross	B-Metric
entropy	I-Metric
)	O
.	O
	
These	O
two	O
metrics	O
evaluate	O
the	O
performance	O
from	O
two	O
different	O
angels	O
:	O
AUC	B-Metric
measures	O
the	O
probability	O
that	O
a	O
positive	O
instance	O
will	O
be	O
ranked	O
higher	O
than	O
a	O
randomly	O
chosen	O
negative	O
one	O
.	O
	
It	O
only	O
takes	O
into	O
account	O
the	O
order	O
of	O
predicted	O
instances	O
and	O
is	O
insensitive	O
to	O
class	B-Task
imbalance	I-Task
problem	I-Task
.	O
	
Logloss	B-Metric
,	O
in	O
contrast	O
,	O
measures	O
the	O
distance	O
between	O
the	O
predicted	O
score	O
and	O
the	O
true	O
label	O
for	O
each	O
instance	O
.	O
	
Sometimes	O
we	O
rely	O
more	O
on	O
Logloss	B-Metric
because	O
we	O
need	O
to	O
use	O
the	O
predicted	O
probability	O
to	O
estimate	O
the	O
benefit	O
of	O
a	O
ranking	B-Method
strategy	I-Method
(	O
which	O
is	O
usually	O
adjusted	O
as	O
CTR	B-Task
bid	O
)	O
.	O
	
subsubsection	O
:	O
Baselines	O
.	O
	
We	O
compare	O
our	O
xDeepFM	B-Method
with	O
LR	B-Method
(	O
logistic	B-Method
regression	I-Method
)	O
,	O
FM	B-Method
,	O
DNN	B-Method
(	O
plain	B-Method
deep	I-Method
neural	I-Method
network	I-Method
)	O
,	O
PNN	B-Method
(	O
choose	O
the	O
better	O
one	O
from	O
iPNN	B-Method
and	O
oPNN	B-Method
)	O
,	O
Wide	B-Method
&	I-Method
Deep	I-Method
,	O
DCN	B-Method
(	O
Deep	B-Method
&	I-Method
Cross	I-Method
Network	I-Method
)	O
and	O
DeepFM	B-Method
.	O
	
As	O
introduced	O
and	O
discussed	O
in	O
Section	O
[	O
reference	O
]	O
,	O
these	O
models	O
are	O
highly	O
related	O
to	O
our	O
xDeepFM	B-Method
and	O
some	O
of	O
them	O
are	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
models	O
for	O
recommender	B-Task
systems	I-Task
.	O
	
Note	O
that	O
the	O
focus	O
of	O
this	O
paper	O
is	O
to	O
learn	O
feature	O
interactions	O
automatically	O
,	O
so	O
we	O
do	O
not	O
include	O
any	O
hand	O
-	O
crafted	O
cross	O
features	O
.	O
	
subsubsection	O
:	O
Reproducibility	O
	
We	O
implement	O
our	O
method	O
using	O
Tensorflow	B-Method
.	O
	
Hyper	O
-	O
parameters	O
of	O
each	O
model	O
are	O
tuned	O
by	O
grid	B-Method
-	I-Method
searching	I-Method
on	O
the	O
validation	O
set	O
,	O
and	O
the	O
best	O
settings	O
for	O
each	O
model	O
will	O
be	O
shown	O
in	O
corresponding	O
sections	O
.	O
	
Learning	B-Metric
rate	I-Metric
is	O
set	O
to	O
0.001	O
.	O
	
For	O
optimization	B-Method
method	I-Method
,	O
we	O
use	O
the	O
Adam	B-Method
with	O
a	O
mini	B-Method
-	I-Method
batch	I-Method
size	I-Method
of	O
4096	O
.	O
	
We	O
use	O
a	O
L2	B-Method
regularization	I-Method
with	O
for	O
DNN	B-Method
,	O
DCN	B-Method
,	O
Wide	B-Method
&	I-Method
Deep	I-Method
,	O
DeepFM	B-Method
and	O
xDeepFM	B-Method
,	O
and	O
use	O
dropout	B-Method
0.5	I-Method
for	O
PNN	B-Method
.	O
	
The	O
default	O
setting	O
for	O
number	O
of	O
neurons	O
per	O
layer	O
is	O
:	O
(	O
1	O
)	O
400	O
for	O
DNN	B-Method
layers	O
;	O
(	O
2	O
)	O
200	O
for	O
CIN	B-Method
layers	O
on	O
Criteo	B-Material
dataset	I-Material
,	O
and	O
100	O
for	O
CIN	B-Method
layers	O
on	O
Dianping	B-Material
and	O
Bing	B-Material
News	I-Material
datasets	I-Material
.	O
	
Since	O
we	O
focus	O
on	O
neural	B-Task
networks	I-Task
structures	I-Task
in	O
this	O
paper	O
,	O
we	O
make	O
the	O
dimension	O
of	O
field	B-Method
embedding	I-Method
for	O
all	O
models	O
be	O
a	O
fixed	O
value	O
of	O
10	O
.	O
	
We	O
conduct	O
experiments	O
of	O
different	O
settings	O
in	O
parallel	O
with	O
5	O
Tesla	B-Method
K80	I-Method
GPUs	I-Method
.	O
	
The	O
source	O
code	O
is	O
available	O
at	O
.	O
	
subsection	O
:	O
Performance	O
Comparison	O
among	O
Individual	O
Neural	B-Method
Components	I-Method
(	O
Q1	O
)	O
	
We	O
want	O
to	O
know	O
how	O
CIN	B-Method
performs	O
individually	O
.	O
	
Note	O
that	O
FM	B-Method
measures	O
2	O
-	O
order	O
feature	O
interactions	O
explicitly	O
,	O
DNN	B-Method
model	O
high	O
-	O
order	O
feature	O
interactions	O
implicitly	O
,	O
CrossNet	B-Method
tries	O
to	O
model	O
high	O
-	O
order	O
feature	O
interactions	O
with	O
a	O
small	O
number	O
of	O
parameters	O
(	O
which	O
is	O
proven	O
not	O
effective	O
in	O
Section	O
[	O
reference	O
]	O
)	O
,	O
and	O
CIN	B-Method
models	O
high	O
-	O
order	O
feature	O
interactions	O
explicitly	O
.	O
	
There	O
is	O
no	O
theoretic	O
guarantee	O
of	O
the	O
superiority	O
of	O
one	O
individual	O
model	O
over	O
the	O
others	O
,	O
due	O
to	O
that	O
it	O
really	O
depends	O
on	O
the	O
dataset	O
.	O
	
For	O
example	O
,	O
if	O
the	O
practical	O
dataset	O
does	O
not	O
require	O
high	O
-	O
order	O
feature	O
interactions	O
,	O
FM	B-Method
may	O
be	O
the	O
best	O
individual	O
model	O
.	O
	
Thus	O
we	O
do	O
not	O
have	O
any	O
expectation	O
for	O
which	O
model	O
will	O
perform	O
the	O
best	O
in	O
this	O
experiment	O
.	O
	
Table	O
[	O
reference	O
]	O
shows	O
the	O
results	O
of	O
individual	O
models	O
on	O
the	O
three	O
practical	O
datasets	O
.	O
	
Surprisingly	O
,	O
our	O
CIN	B-Method
outperform	O
the	O
other	O
models	O
consistently	O
.	O
	
On	O
one	O
hand	O
,	O
the	O
results	O
indicate	O
that	O
for	O
practical	O
datasets	O
,	O
higher	O
-	O
order	O
interactions	O
over	O
sparse	O
features	O
are	O
necessary	O
,	O
and	O
this	O
can	O
be	O
verified	O
through	O
the	O
fact	O
that	O
DNN	B-Method
,	O
CrossNet	B-Method
and	O
CIN	B-Method
outperform	O
FM	B-Method
significantly	O
on	O
all	O
the	O
three	O
datasets	O
.	O
	
On	O
the	O
other	O
hand	O
,	O
CIN	B-Method
is	O
the	O
best	O
individual	O
model	O
,	O
which	O
demonstrates	O
the	O
effectiveness	O
of	O
CIN	B-Method
on	O
modeling	O
explicit	B-Task
high	I-Task
-	I-Task
order	I-Task
feature	I-Task
interactions	I-Task
.	O
	
Note	O
that	O
a	O
-	O
layer	O
CIN	B-Method
can	O
model	O
-	O
degree	O
feature	O
interactions	O
.	O
	
It	O
is	O
also	O
interesting	O
to	O
see	O
that	O
it	O
take	O
5	O
layers	O
for	O
CIN	B-Method
to	O
yield	O
the	O
best	O
result	O
ON	O
the	O
Bing	B-Material
News	I-Material
dataset	I-Material
.	O
	
subsection	O
:	O
Performance	O
of	O
Integrated	B-Method
Models	I-Method
(	O
Q2	O
)	O
	
xDeepFM	B-Method
integrates	O
CIN	B-Method
and	O
DNN	B-Method
into	O
an	O
end	B-Method
-	I-Method
to	I-Method
-	I-Method
end	I-Method
model	I-Method
.	O
	
While	O
CIN	B-Method
and	O
DNN	B-Method
covers	O
two	O
distinct	O
properties	O
in	O
learning	B-Task
feature	I-Task
interactions	I-Task
,	O
we	O
are	O
interested	O
to	O
know	O
whether	O
it	O
is	O
indeed	O
necessary	O
and	O
effective	O
to	O
combine	O
them	O
together	O
for	O
jointly	B-Task
explicit	I-Task
and	I-Task
implicit	I-Task
learning	I-Task
.	O
	
Here	O
we	O
compare	O
several	O
strong	O
baselines	O
which	O
are	O
not	O
limited	O
to	O
individual	O
models	O
,	O
and	O
the	O
results	O
are	O
shown	O
in	O
Table	O
[	O
reference	O
]	O
.	O
	
We	O
observe	O
that	O
LR	B-Method
is	O
far	O
worse	O
than	O
all	O
the	O
rest	O
models	O
,	O
which	O
demonstrates	O
that	O
factorization	B-Method
-	I-Method
based	I-Method
models	I-Method
are	O
essential	O
for	O
measuring	B-Task
sparse	I-Task
features	I-Task
.	O
	
Wide	B-Method
&	I-Method
Deep	I-Method
,	O
DCN	B-Method
,	O
DeepFM	B-Method
and	O
xDeepFM	B-Method
are	O
significantly	O
better	O
than	O
DNN	B-Method
,	O
which	O
directly	O
reflects	O
that	O
,	O
despite	O
their	O
simplicity	O
,	O
incorporating	O
hybrid	B-Method
components	I-Method
are	O
important	O
for	O
boosting	O
the	O
accuracy	B-Metric
of	O
predictive	B-Method
systems	I-Method
.	O
	
Our	O
proposed	O
xDeepFM	B-Method
achieves	O
the	O
best	O
performance	O
on	O
all	O
datasets	O
,	O
which	O
demonstrates	O
that	O
combining	O
explicit	O
and	O
implicit	O
high	O
-	O
order	O
feature	O
interaction	O
is	O
necessary	O
,	O
and	O
xDeepFM	B-Method
is	O
effective	O
in	O
learning	O
this	O
class	O
of	O
combination	B-Task
.	O
	
Another	O
interesting	O
observation	O
is	O
that	O
,	O
all	O
the	O
neural	B-Method
-	I-Method
based	I-Method
models	I-Method
do	O
not	O
require	O
a	O
very	O
deep	B-Method
network	I-Method
structure	I-Method
for	O
the	O
best	O
performance	O
.	O
	
Typical	O
settings	O
for	O
the	O
depth	O
hyper	O
-	O
parameter	O
are	O
2	O
and	O
3	O
,	O
and	O
the	O
best	O
depth	O
setting	O
for	O
xDeepFM	B-Method
is	O
3	O
,	O
which	O
indicates	O
that	O
the	O
interactions	O
we	O
learned	O
are	O
at	O
most	O
4	O
-	O
order	O
.	O
	
subsection	O
:	O
Hyper	O
-	O
Parameter	O
Study	O
(	O
Q3	O
)	O
	
We	O
study	O
the	O
impact	O
of	O
hyper	O
-	O
parameters	O
on	O
xDeepFM	B-Method
in	O
this	O
section	O
,	O
including	O
(	O
1	O
)	O
the	O
number	O
of	O
hidden	O
layers	O
;	O
(	O
2	O
)	O
the	O
number	O
of	O
neurons	O
per	O
layer	O
;	O
and	O
(	O
3	O
)	O
activation	O
functions	O
.	O
	
We	O
conduct	O
experiments	O
via	O
holding	O
the	O
best	O
settings	O
for	O
the	O
DNN	B-Method
part	O
while	O
varying	O
the	O
settings	O
for	O
the	O
CIN	B-Method
part	O
.	O
	
.32	O
	
.32	O
	
.32	O
	
.32	O
	
.32	O
	
.32	O
Depth	O
of	O
Network	O
.	O
	
Figure	O
[	O
reference	O
]	O
and	O
[	O
reference	O
]	O
demonstrate	O
the	O
impact	O
of	O
number	O
of	O
hidden	O
layers	O
.	O
	
We	O
can	O
observe	O
that	O
the	O
performance	O
of	O
xDeepFM	B-Method
increases	O
with	O
the	O
depth	O
of	O
network	O
at	O
the	O
beginning	O
.	O
	
However	O
,	O
model	O
performance	O
degrades	O
when	O
the	O
depth	O
of	O
network	O
is	O
set	O
greater	O
than	O
3	O
.	O
	
It	O
is	O
caused	O
by	O
overfitting	O
evidenced	O
by	O
that	O
we	O
notice	O
that	O
the	O
loss	O
of	O
training	O
data	O
still	O
keeps	O
decreasing	O
when	O
we	O
add	O
more	O
hidden	O
layers	O
.	O
	
Number	O
of	O
Neurons	O
per	O
Layer	O
.	O
	
Adding	O
the	O
number	O
of	O
neurons	O
per	O
layer	O
indicates	O
increasing	O
the	O
number	O
of	O
feature	O
maps	O
in	O
CIN	B-Method
.	O
	
As	O
shown	O
in	O
Figure	O
[	O
reference	O
]	O
and	O
[	O
reference	O
]	O
,	O
model	O
performance	O
on	O
Bing	B-Material
News	I-Material
dataset	I-Material
increases	O
steadily	O
when	O
we	O
increase	O
the	O
number	O
of	O
neurons	O
from	O
to	O
,	O
while	O
on	O
Dianping	B-Material
dataset	O
,	O
is	O
a	O
more	O
suitable	O
setting	O
for	O
the	O
number	O
of	O
neurons	O
per	O
layer	O
.	O
	
In	O
this	O
experiment	O
we	O
fix	O
the	O
depth	O
of	O
network	O
at	O
3	O
.	O
	
Activation	B-Method
Function	I-Method
.	O
	
Note	O
that	O
we	O
exploit	O
the	O
identity	O
as	O
activation	O
function	O
on	O
neurons	O
of	O
CIN	B-Method
,	O
as	O
shown	O
in	O
Eq	O
.	O
	
[	O
reference	O
]	O
.	O
	
A	O
common	O
practice	O
in	O
deep	B-Task
learning	I-Task
literature	I-Task
is	O
to	O
employ	O
non	B-Method
-	I-Method
linear	I-Method
activation	I-Method
functions	I-Method
on	O
hidden	O
neurons	O
.	O
	
We	O
thus	O
compare	O
the	O
results	O
of	O
different	O
activation	B-Method
functions	I-Method
on	O
CIN	B-Method
(	O
for	O
neurons	O
in	O
DNN	B-Method
,	O
we	O
keep	O
the	O
activation	O
function	O
with	O
relu	B-Method
)	O
.	O
	
As	O
shown	O
in	O
Figure	O
[	O
reference	O
]	O
and	O
[	O
reference	O
]	O
,	O
identify	B-Method
function	I-Method
is	O
indeed	O
the	O
most	O
suitable	O
one	O
for	O
neurons	O
in	O
CIN	B-Method
.	O
	
section	O
:	O
related	O
work	O
	
subsection	O
:	O
Classical	O
Recommender	B-Task
Systems	I-Task
	
subsubsection	O
:	O
Non	B-Method
-	I-Method
factorization	I-Method
Models	I-Method
	
For	O
web	B-Task
-	I-Task
scale	I-Task
recommender	I-Task
systems	I-Task
(	O
RSs	B-Task
)	O
,	O
the	O
input	O
features	O
are	O
usually	O
sparse	O
,	O
categorical	O
-	O
continuous	O
-	O
mixed	O
,	O
and	O
high	O
-	O
dimensional	O
.	O
	
Linear	B-Method
models	I-Method
,	O
such	O
as	O
logistic	B-Method
regression	I-Method
with	O
FTRL	B-Method
,	O
are	O
widely	O
adopted	O
as	O
they	O
are	O
easy	O
to	O
manage	O
,	O
maintain	O
,	O
and	O
deploy	O
.	O
	
Because	O
linear	B-Method
models	I-Method
lack	O
the	O
ability	O
of	O
learning	O
feature	O
interactions	O
,	O
data	O
scientists	O
have	O
to	O
spend	O
a	O
lot	O
of	O
work	O
on	O
engineering	O
cross	O
features	O
in	O
order	O
to	O
achieve	O
better	O
performance	O
.	O
	
Considering	O
that	O
some	O
hidden	O
features	O
are	O
hard	O
to	O
design	O
manually	O
,	O
some	O
researchers	O
exploit	O
boosting	B-Method
decision	I-Method
trees	I-Method
to	O
help	O
build	O
feature	O
transformations	O
.	O
	
subsubsection	O
:	O
Factorization	B-Method
Models	I-Method
	
A	O
major	O
downside	O
of	O
the	O
aforementioned	O
models	O
is	O
that	O
they	O
can	O
not	O
generalize	O
to	O
unseen	O
feature	O
interactions	O
in	O
the	O
training	O
set	O
.	O
	
Factorization	B-Method
Machines	I-Method
overcome	O
this	O
problem	O
via	O
embedding	O
each	O
feature	O
into	O
a	O
low	O
dimension	O
latent	O
vector	O
.	O
	
Matrix	B-Method
factorization	I-Method
(	O
MF	B-Method
)	O
,	O
which	O
only	O
considers	O
IDs	O
as	O
features	O
,	O
can	O
be	O
regarded	O
as	O
a	O
special	O
kind	O
of	O
FM	B-Method
.	O
	
Recommendations	B-Task
are	O
made	O
via	O
the	O
product	O
of	O
two	O
latent	O
vectors	O
,	O
thus	O
it	O
does	O
not	O
require	O
the	O
co	O
-	O
occurrence	O
of	O
user	O
and	O
item	O
in	O
the	O
training	O
set	O
.	O
	
MF	B-Method
is	O
the	O
most	O
popular	O
model	O
-	O
based	O
collaborative	B-Method
filtering	I-Method
method	O
in	O
the	O
RS	O
literature	O
.	O
	
extend	O
MF	B-Method
to	O
leveraging	O
side	B-Method
information	I-Method
,	O
in	O
which	O
both	O
a	O
linear	B-Method
model	I-Method
and	O
a	O
MF	B-Method
model	O
are	O
included	O
.	O
	
On	O
the	O
other	O
hand	O
,	O
for	O
many	O
recommender	B-Task
systems	I-Task
,	O
only	O
implicit	O
feedback	O
datasets	O
such	O
as	O
users	O
’	O
watching	O
history	O
and	O
browsing	O
activities	O
are	O
available	O
.	O
	
Thus	O
researchers	O
extend	O
the	O
factorization	B-Method
models	I-Method
to	O
a	O
Bayesian	B-Method
Personalized	I-Method
Ranking	I-Method
(	O
BPR	B-Method
)	O
framework	O
for	O
implicit	B-Task
feedback	I-Task
.	O
	
subsection	O
:	O
Recommender	B-Task
Systems	I-Task
with	O
Deep	B-Method
Learning	I-Method
	
Deep	B-Method
learning	I-Method
techniques	I-Method
have	O
achieved	O
great	O
success	O
in	O
computer	B-Task
vision	I-Task
,	O
speech	B-Task
recognition	I-Task
and	O
natural	B-Task
language	I-Task
understanding	I-Task
.	O
	
As	O
a	O
result	O
,	O
an	O
increasing	O
number	O
of	O
researchers	O
are	O
interested	O
in	O
employing	O
DNNs	B-Method
for	O
recommender	B-Task
systems	I-Task
.	O
	
subsubsection	O
:	O
Deep	B-Method
Learning	I-Method
for	O
High	B-Task
-	I-Task
Order	I-Task
Interactions	I-Task
	
To	O
avoid	O
manually	O
building	O
up	O
high	O
-	O
order	O
cross	O
features	O
,	O
researchers	O
apply	O
DNNs	B-Method
on	O
field	B-Method
embedding	I-Method
,	O
thus	O
patterns	O
from	O
categorical	O
feature	O
interactions	O
can	O
be	O
learned	O
automatically	O
.	O
	
Representative	O
models	O
include	O
FNN	B-Method
,	O
PNN	B-Method
,	O
DeepCross	B-Method
,	O
NFM	B-Method
,	O
DCN	B-Method
,	O
Wide	B-Method
&	I-Method
Deep	I-Method
,	O
and	O
DeepFM	B-Method
.	O
	
These	O
models	O
are	O
highly	O
related	O
to	O
our	O
proposed	O
xDeepFM	B-Method
.	O
	
Since	O
we	O
have	O
reviewed	O
them	O
in	O
Section	O
[	O
reference	O
]	O
and	O
Section	O
[	O
reference	O
]	O
,	O
we	O
do	O
not	O
further	O
discuss	O
them	O
in	O
detail	O
in	O
this	O
section	O
.	O
	
We	O
have	O
demonstrated	O
that	O
our	O
proposed	O
xDeepFM	B-Method
has	O
two	O
special	O
properties	O
in	O
comparison	O
with	O
these	O
models	O
:	O
(	O
1	O
)	O
xDeepFM	B-Method
learns	O
high	O
-	O
order	O
feature	O
interactions	O
in	O
both	O
explicit	O
and	O
implicit	O
fashions	O
;	O
(	O
2	O
)	O
xDeepFM	B-Method
learns	O
feature	O
interactions	O
at	O
the	O
vector	O
-	O
wise	O
level	O
rather	O
than	O
at	O
the	O
bit	O
-	O
wise	O
level	O
.	O
	
subsubsection	B-Method
:	O
Deep	B-Method
Learning	I-Method
for	O
Elaborate	B-Task
Representation	I-Task
Learning	I-Task
	
We	O
include	O
some	O
other	O
deep	B-Method
learning	I-Method
-	I-Method
based	I-Method
RSs	I-Method
in	O
this	O
section	O
due	O
to	O
that	O
they	O
are	O
less	O
focused	O
on	O
learning	O
feature	O
interactions	O
.	O
	
Some	O
early	O
work	O
employs	O
deep	B-Method
learning	I-Method
mainly	O
to	O
model	O
auxiliary	O
information	O
,	O
such	O
as	O
visual	O
data	O
and	O
audio	O
data	O
.	O
	
Recently	O
,	O
deep	B-Method
neural	I-Method
networks	I-Method
are	O
used	O
to	O
model	O
the	O
collaborative	B-Method
filtering	I-Method
(	O
CF	B-Method
)	O
in	O
RSs	O
.	O
	
proposes	O
a	O
Neural	B-Method
Collaborative	I-Method
Filtering	I-Method
(	O
NCF	B-Method
)	I-Method
so	O
that	O
the	O
inner	O
product	O
in	O
MF	B-Method
can	O
be	O
replaced	O
with	O
an	O
arbitrary	O
function	O
via	O
a	O
neural	B-Method
architecture	I-Method
.	O
	
model	O
CF	B-Method
base	O
on	O
the	O
autoencoder	B-Method
paradigm	I-Method
,	O
and	O
they	O
have	O
empirically	O
demonstrated	O
that	O
autoencoder	O
-	O
based	O
CF	B-Method
outperforms	O
several	O
classical	O
MF	B-Method
models	O
.	O
	
Autoencoders	B-Method
can	O
be	O
further	O
employed	O
for	O
jointly	B-Method
modeling	I-Method
CF	I-Method
and	O
side	B-Method
information	I-Method
with	O
the	O
purpose	O
of	O
generating	O
better	O
latent	O
factors	O
.	O
	
employ	O
neural	B-Method
networks	I-Method
to	O
jointly	O
train	O
multiple	O
domains	O
’	O
latent	O
factors	O
.	O
	
proposes	O
the	O
Attentive	B-Method
Collaborative	I-Method
Filtering	I-Method
(	O
ACF	B-Method
)	O
to	O
learn	O
more	O
elaborate	O
preference	O
at	O
both	O
item	O
-	O
level	O
and	O
component	O
-	O
level	O
.	O
	
shows	O
tha	O
traditional	O
RSs	B-Method
can	O
not	O
capture	O
interest	O
diversity	O
and	O
local	O
activation	O
effectively	O
,	O
	
so	O
they	O
introduce	O
a	O
Deep	B-Method
Interest	I-Method
Network	I-Method
(	O
DIN	B-Method
)	O
to	O
represent	O
users	O
’	O
diverse	O
interests	O
with	O
an	O
attentive	B-Method
activation	I-Method
mechanism	I-Method
.	O
	
section	O
:	O
Conclusions	O
	
In	O
this	O
paper	O
,	O
we	O
propose	O
a	O
novel	O
network	O
named	O
Compressed	B-Method
Interaction	I-Method
Network	I-Method
(	O
CIN	B-Method
)	O
,	O
which	O
aims	O
to	O
learn	O
high	O
-	O
order	O
feature	O
interactions	O
explicitly	O
.	O
	
CIN	B-Method
has	O
two	O
special	O
virtues	O
:	O
(	O
1	O
)	O
it	O
can	O
learn	O
certain	O
bounded	O
-	O
degree	O
feature	O
interactions	O
effectively	O
;	O
(	O
2	O
)	O
it	O
learns	O
feature	O
interactions	O
at	O
a	O
vector	O
-	O
wise	O
level	O
.	O
	
Following	O
the	O
spirit	O
of	O
several	O
popular	O
models	O
,	O
we	O
incorporate	O
a	O
CIN	B-Method
and	O
a	O
DNN	B-Method
in	O
an	O
end	B-Method
-	I-Method
to	I-Method
-	I-Method
end	I-Method
framework	I-Method
,	O
and	O
named	O
the	O
resulting	O
model	O
eXtreme	O
Deep	B-Method
Factorization	I-Method
Machine	I-Method
(	O
xDeepFM	B-Method
)	O
.	O
	
Thus	O
xDeepFM	B-Method
can	O
automatically	O
learn	O
high	O
-	O
order	O
feature	O
interactions	O
in	O
both	O
explicit	O
and	O
implicit	O
fashions	O
,	O
which	O
is	O
of	O
great	O
significance	O
to	O
reducing	O
manual	B-Task
feature	I-Task
engineering	I-Task
work	I-Task
.	O
	
We	O
conduct	O
comprehensive	O
experiments	O
and	O
the	O
results	O
demonstrate	O
that	O
our	O
xDeepFM	B-Method
outperforms	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
models	O
consistently	O
on	O
three	O
real	O
-	O
world	O
datasets	O
.	O
	
There	O
are	O
two	O
directions	O
for	O
future	O
work	O
.	O
	
First	O
,	O
currently	O
we	O
simply	O
employ	O
a	O
sum	B-Method
pooling	I-Method
for	O
embedding	B-Task
multivalent	I-Task
fields	I-Task
.	O
	
We	O
can	O
explore	O
the	O
usage	O
of	O
the	O
DIN	B-Method
mechanism	I-Method
to	O
capture	O
the	O
related	O
activation	O
according	O
to	O
the	O
candidate	O
item	O
.	O
	
Second	O
,	O
as	O
discussed	O
in	O
section	O
[	O
reference	O
]	O
,	O
the	O
time	B-Metric
complexity	I-Metric
of	O
the	O
CIN	B-Method
module	O
is	O
high	O
.	O
	
We	O
are	O
interested	O
in	O
developing	O
a	O
distributed	B-Method
version	I-Method
of	O
xDeepFM	B-Method
which	O
can	O
be	O
trained	O
efficiently	O
on	O
a	O
GPU	B-Method
cluster	I-Method
.	O
	
section	O
:	O
Acknowledgements	O
	
The	O
authors	O
would	O
like	O
to	O
thank	O
the	O
anonymous	O
reviewers	O
for	O
their	O
insightful	O
reviews	O
,	O
which	O
are	O
very	O
helpful	O
on	O
the	O
revision	O
of	O
this	O
paper	O
.	O
	
This	O
work	O
is	O
supported	O
in	O
part	O
by	O
Youth	O
Innovation	O
Promotion	O
Association	O
of	O
CAS	O
.	O
	
bibliography	O
:	O
References	O
	
document	O
:	O
Explaining	O
and	O
Harnessing	O
Adversarial	O
Examples	O
	
Several	O
machine	B-Method
learning	I-Method
models	I-Method
,	O
including	O
neural	B-Method
networks	I-Method
,	O
consistently	O
misclassify	O
adversarial	O
examples	O
—inputs	O
formed	O
by	O
applying	O
small	O
but	O
intentionally	O
worst	O
-	O
case	O
perturbations	O
to	O
examples	O
from	O
the	O
dataset	O
,	O
such	O
that	O
the	O
perturbed	O
input	O
results	O
in	O
the	O
model	O
outputting	O
an	O
incorrect	O
answer	O
with	O
high	O
confidence	O
.	O
	
Early	O
attempts	O
at	O
explaining	O
this	O
phenomenon	O
focused	O
on	O
nonlinearity	O
and	O
overfitting	O
.	O
	
We	O
argue	O
instead	O
that	O
the	O
primary	O
cause	O
of	O
neural	B-Method
networks	I-Method
’	O
vulnerability	O
to	O
adversarial	B-Task
perturbation	I-Task
is	O
their	O
linear	O
nature	O
.	O
	
This	O
explanation	O
is	O
supported	O
by	O
new	O
quantitative	O
results	O
while	O
giving	O
the	O
first	O
explanation	O
of	O
the	O
most	O
intriguing	O
fact	O
about	O
them	O
:	O
their	O
generalization	O
across	O
architectures	B-Method
and	O
training	O
sets	O
.	O
	
Moreover	O
,	O
this	O
view	O
yields	O
a	O
simple	O
and	O
fast	O
method	O
of	O
generating	B-Task
adversarial	I-Task
examples	I-Task
.	O
	
Using	O
this	O
approach	O
to	O
provide	O
examples	O
for	O
adversarial	B-Method
training	I-Method
,	O
we	O
reduce	O
the	O
test	B-Metric
set	I-Metric
error	I-Metric
of	O
a	O
maxout	B-Method
network	I-Method
on	O
the	O
MNIST	B-Material
dataset	I-Material
.	O
	
*	O
	
section	O
:	O
	
0pt1pt1pt	O
	
section	O
:	O
Introduction	O
	
Szegedy	O
-	O
ICLR2014	O
made	O
an	O
intriguing	O
discovery	O
:	O
several	O
machine	B-Method
learning	I-Method
models	I-Method
,	O
including	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
neural	B-Method
networks	I-Method
,	O
are	O
vulnerable	O
to	O
adversarial	O
examples	O
.	O
	
That	O
is	O
,	O
these	O
machine	B-Method
learning	I-Method
models	I-Method
misclassify	O
examples	O
that	O
are	O
only	O
slightly	O
different	O
from	O
correctly	O
classified	O
examples	O
drawn	O
from	O
the	O
data	O
distribution	O
.	O
	
In	O
many	O
cases	O
,	O
a	O
wide	O
variety	O
of	O
models	O
with	O
different	O
architectures	O
trained	O
on	O
different	O
subsets	O
of	O
the	O
training	O
data	O
misclassify	O
the	O
same	O
adversarial	O
example	O
.	O
	
This	O
suggests	O
that	O
adversarial	O
examples	O
expose	O
fundamental	O
blind	O
spots	O
in	O
our	O
training	B-Method
algorithms	I-Method
.	O
	
The	O
cause	O
of	O
these	O
adversarial	O
examples	O
was	O
a	O
mystery	O
,	O
and	O
speculative	O
explanations	O
have	O
suggested	O
it	O
is	O
due	O
to	O
extreme	O
nonlinearity	O
of	O
deep	B-Method
neural	I-Method
networks	I-Method
,	O
perhaps	O
combined	O
with	O
insufficient	O
model	B-Method
averaging	I-Method
and	O
insufficient	O
regularization	B-Method
of	O
the	O
purely	O
supervised	B-Task
learning	I-Task
problem	I-Task
.	O
	
We	O
show	O
that	O
these	O
speculative	O
hypotheses	O
are	O
unnecessary	O
.	O
	
Linear	O
behavior	O
in	O
high	O
-	O
dimensional	O
spaces	O
is	O
sufficient	O
to	O
cause	O
adversarial	O
examples	O
.	O
	
This	O
view	O
enables	O
us	O
to	O
design	O
a	O
fast	O
method	O
of	O
generating	B-Task
adversarial	I-Task
examples	I-Task
that	O
makes	O
adversarial	B-Method
training	I-Method
practical	O
.	O
	
We	O
show	O
that	O
adversarial	B-Method
training	I-Method
can	O
provide	O
an	O
additional	O
regularization	O
benefit	O
beyond	O
that	O
provided	O
by	O
using	O
dropout	B-Method
dropout	I-Method
alone	O
.	O
	
Generic	B-Method
regularization	I-Method
strategies	I-Method
such	O
as	O
dropout	B-Method
,	O
pretraining	B-Method
,	O
and	O
model	B-Method
averaging	I-Method
do	O
not	O
confer	O
a	O
significant	O
reduction	O
in	O
a	O
model	O
’s	O
vulnerability	O
to	O
adversarial	O
examples	O
,	O
but	O
changing	O
to	O
nonlinear	B-Method
model	I-Method
families	I-Method
such	O
as	O
RBF	B-Method
networks	I-Method
can	O
do	O
so	O
.	O
	
Our	O
explanation	O
suggests	O
a	O
fundamental	O
tension	O
between	O
designing	O
models	O
that	O
are	O
easy	O
to	O
train	O
due	O
to	O
their	O
linearity	O
and	O
designing	O
models	O
that	O
use	O
nonlinear	O
effects	O
to	O
resist	O
adversarial	O
perturbation	O
.	O
	
In	O
the	O
long	O
run	O
,	O
it	O
may	O
be	O
possible	O
to	O
escape	O
this	O
tradeoff	O
by	O
designing	O
more	O
powerful	O
optimization	B-Method
methods	I-Method
that	O
can	O
succesfully	O
train	O
more	O
nonlinear	B-Method
models	I-Method
.	O
	
section	O
:	O
Related	O
work	O
	
Szegedy	O
-	O
ICLR2014	B-Method
demonstrated	O
a	O
variety	O
of	O
intriguing	O
properties	O
of	O
neural	B-Method
networks	I-Method
and	O
related	O
models	O
.	O
	
Those	O
most	O
relevant	O
to	O
this	O
paper	O
include	O
:	O
Box	B-Method
-	I-Method
constrained	I-Method
L	I-Method
-	I-Method
BFGS	I-Method
can	O
reliably	O
find	O
adversarial	O
examples	O
.	O
	
On	O
some	O
datasets	O
,	O
such	O
as	O
ImageNet	B-Material
ImageNet	I-Material
,	O
the	O
adversarial	O
examples	O
were	O
so	O
close	O
to	O
the	O
original	O
examples	O
that	O
the	O
differences	O
were	O
indistinguishable	O
to	O
the	O
human	O
eye	O
.	O
	
The	O
same	O
adversarial	O
example	O
is	O
often	O
misclassified	O
by	O
a	O
variety	O
of	O
classifiers	B-Method
with	O
different	O
architectures	B-Method
or	O
trained	O
on	O
different	O
subsets	O
of	O
the	O
training	O
data	O
.	O
	
Shallow	B-Method
softmax	I-Method
regression	I-Method
models	I-Method
are	O
also	O
vulnerable	O
to	O
adversarial	O
examples	O
.	O
	
Training	O
on	O
adversarial	O
examples	O
can	O
regularize	O
the	O
model	O
—	O
however	O
,	O
this	O
was	O
not	O
practical	O
at	O
the	O
time	O
due	O
to	O
the	O
need	O
for	O
expensive	O
constrained	B-Task
optimization	I-Task
in	O
the	O
inner	O
loop	O
.	O
	
These	O
results	O
suggest	O
that	O
classifiers	B-Method
based	O
on	O
modern	O
machine	B-Method
learning	I-Method
techniques	I-Method
,	O
even	O
those	O
that	O
obtain	O
excellent	O
performance	O
on	O
the	O
test	O
set	O
,	O
are	O
not	O
learning	O
the	O
true	O
underlying	O
concepts	O
that	O
determine	O
the	O
correct	O
output	O
label	O
.	O
	
Instead	O
,	O
these	O
algorithms	O
have	O
built	O
a	O
Potemkin	B-Method
village	I-Method
that	O
works	O
well	O
on	O
naturally	O
occuring	O
data	O
,	O
but	O
is	O
exposed	O
as	O
a	O
fake	O
when	O
one	O
visits	O
points	O
in	O
space	O
that	O
do	O
not	O
have	O
high	O
probability	O
in	O
the	O
data	O
distribution	O
.	O
	
This	O
is	O
particularly	O
disappointing	O
because	O
a	O
popular	O
approach	O
in	O
computer	B-Task
vision	I-Task
is	O
to	O
use	O
convolutional	B-Method
network	I-Method
features	I-Method
as	O
a	O
space	O
where	O
Euclidean	O
distance	O
approximates	O
perceptual	O
distance	O
.	O
	
This	O
resemblance	O
is	O
clearly	O
flawed	O
if	O
images	O
that	O
have	O
an	O
immeasurably	O
small	O
perceptual	O
distance	O
correspond	O
to	O
completely	O
different	O
classes	O
in	O
the	O
network	B-Method
’s	I-Method
representation	I-Method
.	O
	
These	O
results	O
have	O
often	O
been	O
interpreted	O
as	O
being	O
a	O
flaw	O
in	O
deep	B-Task
networks	I-Task
in	O
particular	O
,	O
even	O
though	O
linear	B-Method
classifiers	I-Method
have	O
the	O
same	O
problem	O
.	O
	
We	O
regard	O
the	O
knowledge	O
of	O
this	O
flaw	O
as	O
an	O
opportunity	O
to	O
fix	O
it	O
.	O
	
Indeed	O
,	O
Luca	B-Method
and	O
causal	O
have	O
already	O
begun	O
the	O
first	O
steps	O
toward	O
designing	O
models	O
that	O
resist	O
adversarial	O
perturbation	O
,	O
though	O
no	O
model	O
has	O
yet	O
succesfully	O
done	O
so	O
while	O
maintaining	O
state	O
of	O
the	O
art	O
accuracy	B-Metric
on	O
clean	O
inputs	O
.	O
	
section	O
:	O
The	O
linear	B-Method
explanation	I-Method
of	I-Method
adversarial	I-Method
examples	I-Method
	
We	O
start	O
with	O
explaining	O
the	O
existence	O
of	O
adversarial	O
examples	O
for	O
linear	B-Method
models	I-Method
.	O
	
In	O
many	O
problems	O
,	O
the	O
precision	O
of	O
an	O
individual	O
input	O
feature	O
is	O
limited	O
.	O
	
For	O
example	O
,	O
digital	O
images	O
often	O
use	O
only	O
8	O
bits	O
per	O
pixel	O
	
so	O
they	O
discard	O
all	O
information	O
below	O
of	O
the	O
dynamic	O
range	O
.	O
	
Because	O
the	O
precision	O
of	O
the	O
features	O
is	O
limited	O
,	O
it	O
is	O
not	O
rational	O
for	O
the	O
classifier	B-Method
to	O
respond	O
differently	O
to	O
an	O
input	O
than	O
to	O
an	O
adversarial	O
input	O
if	O
every	O
element	O
of	O
the	O
perturbation	O
is	O
smaller	O
than	O
the	O
precision	O
of	O
the	O
features	O
.	O
	
Formally	O
,	O
for	O
problems	O
with	O
well	O
-	O
separated	O
classes	O
,	O
we	O
expect	O
the	O
classifier	B-Method
to	O
assign	O
the	O
same	O
class	O
to	O
and	O
so	O
long	O
as	O
,	O
where	O
is	O
small	O
enough	O
to	O
be	O
discarded	O
by	O
the	O
sensor	O
or	O
data	O
storage	O
apparatus	O
associated	O
with	O
our	O
problem	O
.	O
	
Consider	O
the	O
dot	O
product	O
between	O
a	O
weight	O
vector	O
and	O
an	O
adversarial	O
example	O
:	O
The	O
adversarial	O
perturbation	O
causes	O
the	O
activation	O
to	O
grow	O
by	O
.	O
	
We	O
can	O
maximize	O
this	O
increase	O
subject	O
to	O
the	O
max	O
norm	O
constraint	O
on	O
by	O
assigning	O
.	O
	
If	O
has	O
dimensions	O
and	O
the	O
average	O
magnitude	O
of	O
an	O
element	O
of	O
the	O
weight	O
vector	O
is	O
,	O
then	O
the	O
activation	O
will	O
grow	O
by	O
.	O
	
Since	O
does	O
not	O
grow	O
with	O
the	O
dimensionality	O
of	O
the	O
problem	O
but	O
the	O
change	O
in	O
activation	O
caused	O
by	O
perturbation	O
by	O
can	O
grow	O
linearly	O
with	O
,	O
then	O
for	O
high	B-Task
dimensional	I-Task
problems	I-Task
,	O
we	O
can	O
make	O
many	O
infinitesimal	O
changes	O
to	O
the	O
input	O
that	O
add	O
up	O
to	O
one	O
large	O
change	O
to	O
the	O
output	O
.	O
	
We	O
can	O
think	O
of	O
this	O
as	O
a	O
sort	O
of	O
“	O
accidental	B-Task
steganography	I-Task
,	O
”	O
where	O
a	O
linear	B-Method
model	I-Method
is	O
forced	O
to	O
attend	O
exclusively	O
to	O
the	O
signal	O
that	O
aligns	O
most	O
closely	O
with	O
its	O
weights	O
,	O
even	O
if	O
multiple	O
signals	O
are	O
present	O
and	O
other	O
signals	O
have	O
much	O
greater	O
amplitude	O
.	O
	
This	O
explanation	O
shows	O
that	O
a	O
simple	O
linear	B-Method
model	I-Method
can	O
have	O
adversarial	O
examples	O
if	O
its	O
input	O
has	O
sufficient	O
dimensionality	O
.	O
	
Previous	O
explanations	O
for	O
adversarial	B-Task
examples	I-Task
invoked	O
hypothesized	O
properties	O
of	O
neural	B-Method
networks	I-Method
,	O
such	O
as	O
their	O
supposed	O
highly	O
non	O
-	O
linear	O
nature	O
.	O
	
Our	O
hypothesis	O
based	O
on	O
linearity	O
is	O
simpler	O
,	O
and	O
can	O
also	O
explain	O
why	O
softmax	B-Method
regression	I-Method
is	O
vulnerable	O
to	O
adversarial	O
examples	O
.	O
	
section	O
:	O
Linear	B-Task
perturbation	I-Task
of	I-Task
non	I-Task
-	I-Task
linear	I-Task
models	I-Task
	
The	O
linear	B-Method
view	I-Method
of	I-Method
adversarial	I-Method
examples	I-Method
suggests	O
a	O
fast	O
way	O
of	O
generating	O
them	O
.	O
	
We	O
hypothesize	O
that	O
neural	B-Method
networks	I-Method
are	O
too	O
linear	O
to	O
resist	O
linear	B-Method
adversarial	I-Method
perturbation	I-Method
.	O
	
LSTMs	B-Method
lstm	I-Method
,	O
ReLUs	O
Jarrett	O
-	O
ICCV2009	O
,	O
Glorot	O
+	O
al	O
-	O
AI	B-Task
-	O
2011	O
,	O
and	O
maxout	B-Method
networks	I-Method
	
Goodfellow	O
-	O
et	O
-	O
al	O
-	O
ICML2013	B-Method
are	O
all	O
intentionally	O
designed	O
to	O
behave	O
in	O
very	O
linear	O
ways	O
,	O
so	O
that	O
they	O
are	O
easier	O
to	O
optimize	O
.	O
	
More	O
nonlinear	B-Method
models	I-Method
such	O
as	O
sigmoid	B-Method
networks	I-Method
are	O
carefully	O
tuned	O
to	O
spend	O
most	O
of	O
their	O
time	O
in	O
the	O
non	O
-	O
saturating	O
,	O
more	O
linear	O
regime	O
for	O
the	O
same	O
reason	O
.	O
	
This	O
linear	O
behavior	O
suggests	O
that	O
cheap	O
,	O
analytical	B-Method
perturbations	I-Method
of	O
a	O
linear	B-Method
model	I-Method
should	O
also	O
damage	O
neural	B-Method
networks	I-Method
.	O
	
Let	O
be	O
the	O
parameters	O
of	O
a	O
model	O
,	O
the	O
input	O
to	O
the	O
model	O
,	O
the	O
targets	O
associated	O
with	O
(	O
for	O
machine	B-Task
learning	I-Task
tasks	I-Task
that	O
have	O
targets	O
)	O
and	O
be	O
the	O
cost	O
used	O
to	O
train	O
the	O
neural	B-Method
network	I-Method
.	O
	
We	O
can	O
linearize	O
the	O
cost	O
function	O
around	O
the	O
current	O
value	O
of	O
,	O
obtaining	O
an	O
optimal	O
max	B-Method
-	I-Method
norm	I-Method
constrained	I-Method
pertubation	I-Method
of	O
We	O
refer	O
to	O
this	O
as	O
the	O
“	O
fast	B-Method
gradient	I-Method
sign	I-Method
method	I-Method
”	O
of	O
generating	B-Task
adversarial	I-Task
examples	I-Task
.	O
	
Note	O
that	O
the	O
required	O
gradient	O
can	O
be	O
computed	O
efficiently	O
using	O
backpropagation	B-Method
.	O
	
We	O
find	O
that	O
this	O
method	O
reliably	O
causes	O
a	O
wide	O
variety	O
of	O
models	O
to	O
misclassify	O
their	O
input	O
.	O
	
See	O
Fig	O
.	O
	
[	O
reference	O
]	O
for	O
a	O
demonstration	O
on	O
ImageNet	B-Material
.	O
	
We	O
find	O
that	O
using	O
,	O
we	O
cause	O
a	O
shallow	B-Method
softmax	I-Method
classifier	I-Method
to	O
have	O
an	O
error	B-Metric
rate	O
of	O
99.9	O
%	O
with	O
an	O
average	B-Metric
confidence	I-Metric
of	O
79.3	O
%	O
on	O
the	O
MNIST	B-Material
LeCun	O
+	O
98	O
test	O
set	O
.	O
	
In	O
the	O
same	O
setting	O
,	O
a	O
maxout	B-Method
network	I-Method
misclassifies	O
89.4	O
%	O
of	O
our	O
adversarial	O
examples	O
with	O
an	O
average	B-Metric
confidence	I-Metric
of	O
97.6	O
%	O
.	O
	
Similarly	O
,	O
using	O
,	O
we	O
obtain	O
an	O
error	B-Metric
rate	O
of	O
87.15	O
%	O
and	O
an	O
average	B-Metric
probability	I-Metric
of	O
96.6	O
%	O
assigned	O
to	O
the	O
incorrect	O
labels	O
when	O
using	O
a	O
convolutional	B-Method
maxout	I-Method
network	I-Method
on	O
a	O
preprocessed	O
version	O
of	O
the	O
CIFAR	B-Material
-	I-Material
10	I-Material
KrizhevskyHinton2009	O
test	O
set	O
.	O
	
Other	O
simple	O
methods	O
of	O
generating	B-Task
adversarial	I-Task
examples	I-Task
are	O
possible	O
.	O
	
For	O
example	O
,	O
we	O
also	O
found	O
that	O
rotating	O
by	O
a	O
small	O
angle	O
in	O
the	O
direction	O
of	O
the	O
gradient	O
reliably	O
produces	O
adversarial	O
examples	O
.	O
	
The	O
fact	O
that	O
these	O
simple	O
,	O
cheap	B-Method
algorithms	I-Method
are	O
able	O
to	O
generate	O
misclassified	O
examples	O
serves	O
as	O
evidence	O
in	O
favor	O
of	O
our	O
interpretation	O
of	O
adversarial	O
examples	O
as	O
a	O
result	O
of	O
linearity	O
.	O
	
The	O
algorithms	O
are	O
also	O
useful	O
as	O
a	O
way	O
of	O
speeding	O
up	O
adversarial	B-Method
training	I-Method
or	O
even	O
just	O
analysis	B-Task
of	I-Task
trained	I-Task
networks	I-Task
.	O
	
section	O
:	O
Adversarial	B-Method
training	I-Method
of	I-Method
linear	I-Method
models	I-Method
versus	O
weight	B-Method
decay	I-Method
	
Perhaps	O
the	O
simplest	O
possible	O
model	O
we	O
can	O
consider	O
is	O
logistic	B-Method
regression	I-Method
.	O
	
In	O
this	O
case	O
,	O
the	O
fast	B-Method
gradient	I-Method
sign	I-Method
method	I-Method
is	O
exact	O
.	O
	
We	O
can	O
use	O
this	O
case	O
to	O
gain	O
some	O
intuition	O
for	O
how	O
adversarial	O
examples	O
are	O
generated	O
in	O
a	O
simple	O
setting	O
.	O
	
See	O
Fig	O
.	O
	
[	O
reference	O
]	O
for	O
instructive	O
images	O
.	O
	
If	O
we	O
train	O
a	O
single	O
model	O
to	O
recognize	O
labels	O
with	O
where	O
is	O
the	O
logistic	O
sigmoid	O
function	O
,	O
then	O
training	O
consists	O
of	O
gradient	B-Method
descent	I-Method
on	O
where	O
is	O
the	O
softplus	O
function	O
.	O
	
We	O
can	O
derive	O
a	O
simple	O
analytical	B-Method
form	I-Method
for	O
training	B-Task
on	O
the	O
worst	O
-	O
case	O
adversarial	O
perturbation	O
of	O
rather	O
than	O
itself	O
,	O
based	O
on	O
gradient	B-Method
sign	I-Method
perturbation	I-Method
.	O
	
Note	O
that	O
the	O
sign	O
of	O
the	O
gradient	O
is	O
just	O
,	O
and	O
that	O
.	O
	
The	O
adversarial	B-Method
version	I-Method
of	O
logistic	B-Method
regression	I-Method
is	O
therefore	O
to	O
minimize	O
This	O
is	O
somewhat	O
similar	O
to	O
regularization	B-Method
.	O
	
However	O
,	O
there	O
are	O
some	O
important	O
differences	O
.	O
	
Most	O
significantly	O
,	O
the	O
penalty	O
is	O
subtracted	O
off	O
the	O
model	O
	
’s	O
activation	O
during	O
training	O
,	O
rather	O
than	O
added	O
to	O
the	O
training	B-Metric
cost	I-Metric
.	O
	
This	O
means	O
that	O
the	O
penalty	O
can	O
eventually	O
start	O
to	O
disappear	O
if	O
the	O
model	O
learns	O
to	O
make	O
confident	O
enough	O
predictions	O
that	O
saturates	O
.	O
	
This	O
is	O
not	O
guaranteed	O
to	O
happen	O
—	O
in	O
the	O
underfitting	B-Task
regime	I-Task
,	O
adversarial	B-Method
training	I-Method
will	O
simply	O
worsen	O
underfitting	O
.	O
	
We	O
can	O
thus	O
view	O
weight	B-Method
decay	I-Method
as	O
being	O
more	O
“	O
worst	O
case	O
”	O
than	O
adversarial	B-Method
training	I-Method
,	O
because	O
it	O
fails	O
to	O
deactivate	O
in	O
the	O
case	O
of	O
good	O
margin	O
.	O
	
If	O
we	O
move	O
beyond	O
logistic	B-Method
regression	I-Method
to	O
multiclass	B-Method
softmax	I-Method
regression	I-Method
,	O
weight	B-Method
decay	I-Method
becomes	O
even	O
more	O
pessimistic	O
,	O
because	O
it	O
treats	O
each	O
of	O
the	O
softmax	O
’s	O
outputs	O
as	O
independently	O
perturbable	O
,	O
when	O
in	O
fact	O
it	O
is	O
usually	O
not	O
possible	O
to	O
find	O
a	O
single	O
that	O
aligns	O
with	O
all	O
of	O
the	O
class	O
’s	O
weight	O
vectors	O
.	O
	
Weight	B-Method
decay	I-Method
overestimates	O
the	O
damage	O
achievable	O
with	O
perturbation	O
even	O
more	O
in	O
the	O
case	O
of	O
a	O
deep	B-Method
network	I-Method
with	O
multiple	O
hidden	O
units	O
.	O
	
Because	O
weight	B-Method
decay	I-Method
overestimates	O
the	O
amount	O
of	O
damage	O
an	O
adversary	O
can	O
do	O
,	O
it	O
is	O
necessary	O
to	O
use	O
a	O
smaller	O
weight	O
decay	O
coefficient	O
than	O
the	O
associated	O
with	O
the	O
precision	B-Metric
of	O
our	O
features	O
.	O
	
When	O
training	O
maxout	B-Method
networks	I-Method
on	O
MNIST	B-Material
,	O
we	O
obtained	O
good	O
results	O
using	O
adversarial	B-Method
training	I-Method
with	O
.	O
	
When	O
applying	O
weight	B-Method
decay	I-Method
to	O
the	O
first	O
layer	O
,	O
we	O
found	O
that	O
even	O
a	O
coefficient	O
of	O
.0025	O
was	O
too	O
large	O
,	O
and	O
caused	O
the	O
model	O
to	O
get	O
stuck	O
with	O
over	O
5	O
%	O
error	B-Metric
on	O
the	O
training	O
set	O
.	O
	
Smaller	O
weight	O
decay	O
coefficients	O
permitted	O
succesful	O
training	O
but	O
conferred	O
no	O
regularization	O
benefit	O
.	O
	
section	O
:	O
Adversarial	B-Task
training	I-Task
of	I-Task
deep	I-Task
networks	I-Task
	
The	O
criticism	O
of	O
deep	B-Method
networks	I-Method
as	O
vulnerable	O
to	O
adversarial	O
examples	O
is	O
somewhat	O
misguided	O
,	O
because	O
unlike	O
shallow	B-Method
linear	I-Method
models	I-Method
,	O
deep	B-Method
networks	I-Method
are	O
at	O
least	O
able	O
to	O
represent	O
functions	O
that	O
resist	O
adversarial	O
perturbation	O
.	O
	
The	O
universal	B-Method
approximator	I-Method
theorem	I-Method
Hornik89	I-Method
guarantees	O
that	O
a	O
neural	B-Method
network	I-Method
with	O
at	O
least	O
one	O
hidden	O
layer	O
can	O
represent	O
any	O
function	O
to	O
an	O
arbitary	O
degree	O
of	O
accuracy	B-Metric
so	O
long	O
as	O
its	O
hidden	O
layer	O
is	O
permitted	O
to	O
have	O
enough	O
units	O
.	O
	
Shallow	B-Method
linear	I-Method
models	I-Method
are	O
not	O
able	O
to	O
become	O
constant	O
near	O
training	O
points	O
while	O
also	O
assigning	O
different	O
outputs	O
to	O
different	O
training	O
points	O
.	O
	
Of	O
course	O
,	O
the	O
universal	B-Method
approximator	I-Method
theorem	I-Method
does	O
not	O
say	O
anything	O
about	O
whether	O
a	O
training	B-Method
algorithm	I-Method
will	O
be	O
able	O
to	O
discover	O
a	O
function	O
with	O
all	O
of	O
the	O
desired	O
properties	O
.	O
	
Obviously	O
,	O
standard	O
supervised	B-Method
training	I-Method
does	O
not	O
specify	O
that	O
the	O
chosen	O
function	O
be	O
resistant	O
to	O
adversarial	O
examples	O
.	O
	
This	O
must	O
be	O
encoded	O
in	O
the	O
training	B-Method
procedure	I-Method
somehow	O
.	O
	
Szegedy	O
-	O
ICLR2014	B-Method
showed	O
that	O
by	O
training	O
on	O
a	O
mixture	O
of	O
adversarial	O
and	O
clean	O
examples	O
,	O
a	O
neural	B-Method
network	I-Method
could	O
be	O
regularized	O
somewhat	O
.	O
	
Training	B-Task
on	O
adversarial	O
examples	O
is	O
somewhat	O
different	O
from	O
other	O
data	B-Method
augmentation	I-Method
schemes	I-Method
;	O
usually	O
,	O
one	O
augments	O
the	O
data	O
with	O
transformations	O
such	O
as	O
translations	O
that	O
are	O
expected	O
to	O
actually	O
occur	O
in	O
the	O
test	O
set	O
.	O
	
This	O
form	O
of	O
data	B-Task
augmentation	I-Task
instead	O
uses	O
inputs	O
that	O
are	O
unlikely	O
to	O
occur	O
naturally	O
but	O
that	O
expose	O
flaws	O
in	O
the	O
ways	O
that	O
the	O
model	O
conceptualizes	O
its	O
decision	O
function	O
.	O
	
At	O
the	O
time	O
,	O
this	O
procedure	O
was	O
never	O
demonstrated	O
to	O
improve	O
beyond	O
dropout	B-Method
on	O
a	O
state	O
of	O
the	O
art	O
benchmark	O
.	O
	
However	O
,	O
this	O
was	O
partially	O
because	O
it	O
was	O
difficult	O
to	O
experiment	O
extensively	O
with	O
expensive	O
adversarial	O
examples	O
based	O
on	O
L	B-Method
-	I-Method
BFGS	I-Method
.	O
	
We	O
found	O
that	O
training	O
with	O
an	O
adversarial	O
objective	O
function	O
based	O
on	O
the	O
fast	B-Method
gradient	I-Method
sign	I-Method
method	I-Method
was	O
an	O
effective	O
regularizer	B-Method
:	O
In	O
all	O
of	O
our	O
experiments	O
,	O
we	O
used	O
.	O
	
Other	O
values	O
may	O
work	O
better	O
;	O
our	O
initial	O
guess	O
of	O
this	O
hyperparameter	O
worked	O
well	O
enough	O
that	O
we	O
did	O
not	O
feel	O
the	O
need	O
to	O
explore	O
more	O
.	O
	
This	O
approach	O
means	O
that	O
we	O
continually	O
update	O
our	O
supply	O
of	O
adversarial	O
examples	O
,	O
to	O
make	O
them	O
resist	O
the	O
current	O
version	O
of	O
the	O
model	O
.	O
	
Using	O
this	O
approach	O
to	O
train	O
a	O
maxout	B-Method
network	I-Method
that	O
was	O
also	O
regularized	O
with	O
dropout	B-Method
,	O
we	O
were	O
able	O
to	O
reduce	O
the	O
error	B-Metric
rate	O
from	O
0.94	O
%	O
without	O
adversarial	B-Method
training	I-Method
to	O
0.84	O
%	O
with	O
adversarial	B-Method
training	I-Method
.	O
	
We	O
observed	O
that	O
we	O
were	O
not	O
reaching	O
zero	O
error	B-Metric
rate	O
on	O
adversarial	O
examples	O
on	O
the	O
training	O
set	O
.	O
	
We	O
fixed	O
this	O
problem	O
by	O
making	O
two	O
changes	O
.	O
	
First	O
,	O
we	O
made	O
the	O
model	O
larger	O
,	O
using	O
1600	O
units	O
per	O
layer	O
rather	O
than	O
the	O
240	O
used	O
by	O
the	O
original	O
maxout	B-Method
network	I-Method
for	O
this	O
problem	O
.	O
	
Without	O
adversarial	B-Method
training	I-Method
,	O
this	O
causes	O
the	O
model	O
to	O
overfit	O
slightly	O
,	O
and	O
get	O
an	O
error	B-Metric
rate	O
of	O
1.14	O
%	O
on	O
the	O
test	O
set	O
.	O
	
With	O
adversarial	B-Method
training	I-Method
,	O
we	O
found	O
that	O
the	O
validation	O
set	O
error	B-Metric
leveled	O
off	O
over	O
time	O
,	O
and	O
made	O
very	O
slow	O
progress	O
.	O
	
The	O
original	O
maxout	B-Method
result	O
uses	O
early	O
stopping	O
,	O
and	O
terminates	O
learning	B-Task
after	O
the	O
validation	O
set	O
error	B-Metric
rate	O
has	O
not	O
decreased	O
for	O
100	O
epochs	O
.	O
	
We	O
found	O
that	O
while	O
the	O
validation	O
set	O
error	B-Metric
was	O
very	O
flat	O
,	O
the	O
adversarial	B-Metric
validation	I-Metric
set	I-Metric
error	I-Metric
was	O
not	O
.	O
	
We	O
therefore	O
used	O
early	B-Method
stopping	I-Method
on	O
the	O
adversarial	B-Metric
validation	I-Metric
set	I-Metric
error	I-Metric
.	O
	
Using	O
this	O
criterion	O
to	O
choose	O
the	O
number	O
of	O
epochs	O
to	O
train	O
for	O
,	O
we	O
then	O
retrained	O
on	O
all	O
60	O
,	O
000	O
examples	O
.	O
	
Five	O
different	O
training	O
runs	O
using	O
different	O
seeds	O
for	O
the	O
random	B-Method
number	I-Method
generators	I-Method
used	O
to	O
select	O
minibatches	O
of	O
training	O
examples	O
,	O
initialize	O
model	O
weights	O
,	O
and	O
generate	O
dropout	O
masks	O
result	O
in	O
four	O
trials	O
that	O
each	O
had	O
an	O
error	B-Metric
rate	O
of	O
0.77	O
%	O
on	O
the	O
test	O
set	O
and	O
one	O
trial	O
that	O
had	O
an	O
error	B-Metric
rate	O
of	O
0.83	O
%	O
.	O
	
The	O
average	O
of	O
0.782	O
%	O
is	O
the	O
best	O
result	O
reported	O
on	O
the	O
permutation	B-Method
invariant	I-Method
version	I-Method
of	O
MNIST	B-Material
,	O
though	O
statistically	O
indistinguishable	O
from	O
the	O
result	O
obtained	O
by	O
fine	B-Method
-	I-Method
tuning	I-Method
DBMs	I-Method
with	O
dropout	B-Method
dropout	I-Method
at	O
0.79	O
%	O
.	O
	
The	O
model	O
also	O
became	O
somewhat	O
resistant	O
to	O
adversarial	O
examples	O
.	O
	
Recall	O
that	O
without	O
adversarial	B-Method
training	I-Method
,	O
this	O
same	O
kind	O
of	O
model	O
had	O
an	O
error	B-Metric
rate	O
of	O
89.4	O
%	O
on	O
adversarial	O
examples	O
based	O
on	O
the	O
fast	B-Method
gradient	I-Method
sign	I-Method
method	I-Method
.	O
	
With	O
adversarial	B-Method
training	I-Method
,	O
the	O
error	B-Metric
rate	O
fell	O
to	O
17.9	O
%	O
.	O
	
Adversarial	O
examples	O
are	O
transferable	O
between	O
the	O
two	O
models	O
but	O
with	O
the	O
adversarially	B-Method
trained	I-Method
model	I-Method
showing	O
greater	O
robustness	O
.	O
	
Adversarial	O
examples	O
generated	O
via	O
the	O
original	O
model	O
yield	O
an	O
error	B-Metric
rate	O
of	O
19.6	O
%	O
on	O
the	O
adversarially	B-Method
trained	I-Method
model	I-Method
,	O
while	O
adversarial	O
examples	O
generated	O
via	O
the	O
new	O
model	O
yield	O
an	O
error	B-Metric
rate	O
of	O
40.9	O
%	O
on	O
the	O
original	O
model	O
.	O
	
When	O
the	O
adversarially	B-Method
trained	I-Method
model	I-Method
does	O
misclassify	O
an	O
adversarial	O
example	O
,	O
its	O
predictions	O
are	O
unfortunately	O
still	O
highly	O
confident	O
.	O
	
The	O
average	O
confidence	O
on	O
a	O
misclassified	O
example	O
was	O
81.4	O
%	O
.	O
	
We	O
also	O
found	O
that	O
the	O
weights	O
of	O
the	O
learned	O
model	O
changed	O
significantly	O
,	O
with	O
the	O
weights	O
of	O
the	O
adversarially	B-Method
trained	I-Method
model	I-Method
being	O
significantly	O
more	O
localized	O
and	O
interpretable	O
(	O
see	O
Fig	O
.	O
	
[	O
reference	O
]	O
)	O
.	O
	
The	O
adversarial	B-Method
training	I-Method
procedure	O
can	O
be	O
seen	O
as	O
minimizing	O
the	O
worst	O
case	O
error	B-Metric
when	O
the	O
data	O
is	O
perturbed	O
by	O
an	O
adversary	O
.	O
	
That	O
can	O
be	O
interpreted	O
as	O
learning	O
to	O
play	O
an	O
adversarial	B-Method
game	I-Method
,	O
or	O
as	O
minimizing	O
an	O
upper	O
bound	O
on	O
the	O
expected	B-Metric
cost	I-Metric
over	O
noisy	O
samples	O
with	O
noise	O
from	O
added	O
to	O
the	O
inputs	O
.	O
	
Adversarial	B-Method
training	I-Method
can	O
also	O
be	O
seen	O
as	O
a	O
form	O
of	O
active	B-Method
learning	I-Method
,	O
where	O
the	O
model	O
is	O
able	O
to	O
request	O
labels	O
on	O
new	O
points	O
.	O
	
In	O
this	O
case	O
the	O
human	B-Task
labeler	I-Task
is	O
replaced	O
with	O
a	O
heuristic	B-Method
labeler	I-Method
that	O
copies	O
labels	O
from	O
nearby	O
points	O
.	O
	
We	O
could	O
also	O
regularize	O
the	O
model	O
to	O
be	O
insensitive	O
to	O
changes	O
in	O
its	O
features	O
that	O
are	O
smaller	O
than	O
the	O
precision	O
simply	O
by	O
training	O
on	O
all	O
points	O
within	O
the	O
max	O
norm	O
box	O
,	O
or	O
sampling	O
many	O
points	O
within	O
this	O
box	O
.	O
	
This	O
corresponds	O
to	O
adding	O
noise	O
with	O
max	B-Method
norm	I-Method
during	O
training	O
.	O
	
However	O
,	O
noise	O
with	O
zero	O
mean	O
and	O
zero	O
covariance	O
is	O
very	O
inefficient	O
at	O
preventing	O
adversarial	O
examples	O
.	O
	
The	O
expected	O
dot	O
product	O
between	O
any	O
reference	O
vector	O
and	O
such	O
a	O
noise	O
vector	O
is	O
zero	O
.	O
	
This	O
means	O
that	O
in	O
many	O
cases	O
the	O
noise	O
will	O
have	O
essentially	O
no	O
effect	O
rather	O
than	O
yielding	O
a	O
more	O
difficult	O
input	O
.	O
	
In	O
fact	O
,	O
in	O
many	O
cases	O
the	O
noise	O
will	O
actualy	O
result	O
in	O
a	O
lower	O
objective	B-Metric
function	I-Metric
value	I-Metric
.	O
	
We	O
can	O
think	O
of	O
adversarial	B-Method
training	I-Method
as	O
doing	O
hard	B-Task
example	I-Task
mining	I-Task
among	O
the	O
set	O
of	O
noisy	O
inputs	O
,	O
in	O
order	O
to	O
train	O
more	O
efficiently	O
by	O
considering	O
only	O
those	O
noisy	O
points	O
that	O
strongly	O
resist	O
classification	B-Task
.	O
	
As	O
control	O
experiments	O
,	O
we	O
trained	O
training	O
a	O
maxout	B-Method
network	I-Method
with	O
noise	O
based	O
on	O
randomly	O
adding	O
to	O
each	O
pixel	O
,	O
or	O
adding	O
noise	O
in	O
to	O
each	O
pixel	O
.	O
	
These	O
obtained	O
an	O
error	B-Metric
rate	O
of	O
86.2	O
%	O
with	O
confidence	B-Metric
97.3	O
%	O
and	O
an	O
error	B-Metric
rate	O
of	O
90.4	O
%	O
with	O
a	O
confidence	B-Metric
of	O
97.8	O
%	O
respectively	O
on	O
fast	B-Task
gradient	I-Task
sign	I-Task
adversarial	I-Task
examples	I-Task
.	O
	
Because	O
the	O
derivative	O
of	O
the	O
sign	O
function	O
is	O
zero	O
or	O
undefined	O
everywhere	O
,	O
gradient	B-Method
descent	I-Method
on	O
the	O
adversarial	O
objective	O
function	O
based	O
on	O
the	O
fast	B-Method
gradient	I-Method
sign	I-Method
method	I-Method
does	O
not	O
allow	O
the	O
model	O
to	O
anticipate	O
how	O
the	O
adversary	O
will	O
react	O
to	O
changes	O
in	O
the	O
parameters	O
.	O
	
If	O
we	O
instead	O
adversarial	O
examples	O
based	O
on	O
small	O
rotations	O
or	O
addition	O
of	O
the	O
scaled	O
gradient	O
,	O
then	O
the	O
perturbation	B-Method
process	I-Method
is	O
itself	O
differentiable	O
and	O
the	O
learning	B-Method
can	O
take	O
the	O
reaction	O
of	O
the	O
adversary	O
into	O
account	O
.	O
	
However	O
,	O
we	O
did	O
not	O
find	O
nearly	O
as	O
powerful	O
of	O
a	O
regularizing	O
result	O
from	O
this	O
process	O
,	O
perhaps	O
because	O
these	O
kinds	O
of	O
adversarial	O
examples	O
are	O
not	O
as	O
difficult	O
to	O
solve	O
.	O
	
One	O
natural	O
question	O
is	O
whether	O
it	O
is	O
better	O
to	O
perturb	O
the	O
input	O
or	O
the	O
hidden	O
layers	O
or	O
both	O
.	O
	
Here	O
the	O
results	O
are	O
inconsistent	O
.	O
	
Szegedy	O
-	O
ICLR2014	B-Method
reported	O
that	O
adversarial	O
perturbations	O
yield	O
the	O
best	O
regularization	O
when	O
applied	O
to	O
the	O
hidden	O
layers	O
.	O
	
That	O
result	O
was	O
obtained	O
on	O
a	O
sigmoidal	B-Method
network	I-Method
.	O
	
In	O
our	O
experiments	O
with	O
the	O
fast	B-Method
gradient	I-Method
sign	I-Method
method	I-Method
,	O
we	O
find	O
that	O
networks	O
with	O
hidden	O
units	O
whose	O
activations	O
are	O
unbounded	O
simply	O
respond	O
by	O
making	O
their	O
hidden	O
unit	O
activations	O
very	O
large	O
,	O
so	O
it	O
is	O
usually	O
better	O
to	O
just	O
perturb	O
the	O
original	O
input	O
.	O
	
On	O
saturating	B-Method
models	I-Method
such	O
as	O
the	O
Rust	B-Method
model	I-Method
we	O
found	O
that	O
perturbation	O
of	O
the	O
input	O
performed	O
comparably	O
to	O
perturbation	O
of	O
the	O
hidden	O
layers	O
.	O
	
Perturbations	O
based	O
on	O
rotating	O
the	O
hidden	O
layers	O
solve	O
the	O
problem	O
of	O
unbounded	O
activations	O
growing	O
to	O
make	O
additive	O
perturbations	O
smaller	O
by	O
comparison	O
.	O
	
We	O
were	O
able	O
to	O
succesfully	O
train	O
maxout	B-Method
networks	I-Method
with	O
rotational	O
perturbations	O
of	O
the	O
hidden	O
layers	O
.	O
	
However	O
,	O
this	O
did	O
not	O
yield	O
nearly	O
as	O
strong	O
of	O
a	O
regularizing	O
effect	O
as	O
additive	O
perturbation	O
of	O
the	O
input	B-Method
layer	I-Method
.	O
	
Our	O
view	O
of	O
adversarial	B-Method
training	I-Method
is	O
that	O
it	O
is	O
only	O
clearly	O
useful	O
when	O
the	O
model	O
has	O
the	O
capacity	O
to	O
learn	O
to	O
resist	O
adversarial	O
examples	O
.	O
	
This	O
is	O
only	O
clearly	O
the	O
case	O
when	O
a	O
universal	B-Method
approximator	I-Method
theorem	I-Method
applies	O
.	O
	
Because	O
the	O
last	O
layer	O
of	O
a	O
neural	B-Method
network	I-Method
,	O
the	O
linear	B-Method
-	I-Method
sigmoid	I-Method
or	I-Method
linear	I-Method
-	I-Method
softmax	I-Method
layer	I-Method
,	O
is	O
not	O
a	O
universal	B-Method
approximator	I-Method
of	I-Method
functions	I-Method
of	O
the	O
final	O
hidden	O
layer	O
,	O
this	O
suggests	O
that	O
one	O
is	O
likely	O
to	O
encounter	O
problems	O
with	O
underfitting	O
when	O
applying	O
adversarial	O
perturbations	O
to	O
the	O
final	O
hidden	O
layer	O
.	O
	
We	O
indeed	O
found	O
this	O
effect	O
.	O
	
Our	O
best	O
results	O
with	O
training	O
using	O
perturbations	O
of	O
hidden	O
layers	O
never	O
involved	O
perturbations	O
of	O
the	O
final	O
hidden	O
layer	O
.	O
	
section	O
:	O
Different	O
kinds	O
of	O
model	O
capacity	O
	
One	O
reason	O
that	O
the	O
existence	O
of	O
adversarial	O
examples	O
can	O
seem	O
counter	O
-	O
intuitive	O
is	O
that	O
most	O
of	O
us	O
have	O
poor	O
intuitions	O
for	O
high	O
dimensional	O
spaces	O
.	O
	
We	O
live	O
in	O
three	O
dimensions	O
,	O
so	O
we	O
are	O
not	O
used	O
to	O
small	O
effects	O
in	O
hundreds	O
of	O
dimensions	O
adding	O
up	O
to	O
create	O
a	O
large	O
effect	O
.	O
	
There	O
is	O
another	O
way	O
that	O
our	O
intuitions	O
serve	O
us	O
poorly	O
.	O
	
Many	O
people	O
think	O
of	O
models	O
with	O
low	O
capacity	O
as	O
being	O
unable	O
to	O
make	O
many	O
different	O
confident	O
predictions	O
.	O
	
This	O
is	O
not	O
correct	O
.	O
	
Some	O
models	O
with	O
low	O
capacity	O
do	O
exhibit	O
this	O
behavior	O
.	O
	
For	O
example	O
shallow	B-Method
RBF	I-Method
networks	I-Method
with	O
are	O
only	O
able	O
to	O
confidently	O
predict	O
that	O
the	O
positive	O
class	O
is	O
present	O
in	O
the	O
vicinity	O
of	O
.	O
	
Elsewhere	O
,	O
they	O
default	O
to	O
predicting	O
the	O
class	O
is	O
absent	O
,	O
or	O
have	O
low	O
-	O
confidence	O
predictions	O
.	O
	
RBF	B-Method
networks	I-Method
are	O
naturally	O
immune	O
to	O
adversarial	O
examples	O
,	O
in	O
the	O
sense	O
that	O
they	O
have	O
low	O
confidence	O
when	O
they	O
are	O
fooled	O
.	O
	
A	O
shallow	B-Method
RBF	I-Method
network	I-Method
with	O
no	O
hidden	O
layers	O
gets	O
an	O
error	B-Metric
rate	O
of	O
55.4	O
%	O
on	O
MNIST	B-Material
using	O
adversarial	O
examples	O
generated	O
with	O
the	O
fast	B-Method
gradient	I-Method
sign	I-Method
method	I-Method
and	O
.	O
	
However	O
,	O
its	O
confidence	O
on	O
mistaken	O
examples	O
is	O
only	O
.	O
	
Its	O
average	O
confidence	B-Metric
on	O
clean	O
test	O
examples	O
is	O
%	O
.	O
	
We	O
ca	O
n’t	O
expect	O
a	O
model	O
with	O
such	O
low	O
capacity	O
to	O
get	O
the	O
right	O
answer	O
at	O
all	O
points	O
of	O
space	O
,	O
but	O
it	O
does	O
correctly	O
respond	O
by	O
reducing	O
its	O
confidence	O
considerably	O
on	O
points	O
it	O
does	O
not	O
“	O
understand	O
.	O
	
”	O
	
RBF	B-Method
units	I-Method
are	O
unfortunately	O
not	O
invariant	O
to	O
any	O
significant	O
transformations	O
so	O
they	O
can	O
not	O
generalize	O
very	O
well	O
.	O
	
We	O
can	O
view	O
linear	B-Method
units	I-Method
and	O
RBF	B-Method
units	I-Method
as	O
different	O
points	O
on	O
a	O
precision	B-Metric
-	I-Metric
recall	I-Metric
tradeoff	I-Metric
curve	I-Metric
.	O
	
Linear	B-Method
units	I-Method
achieve	O
high	O
recall	B-Metric
by	O
responding	O
to	O
every	O
input	O
in	O
a	O
certain	O
direction	O
,	O
but	O
may	O
have	O
low	O
precision	B-Metric
due	O
to	O
responding	O
too	O
strongly	O
in	O
unfamiliar	O
situations	O
.	O
	
RBF	B-Method
units	I-Method
achieve	O
high	O
precision	B-Metric
by	O
responding	O
only	O
to	O
a	O
specific	O
point	O
in	O
space	O
,	O
but	O
in	O
doing	O
so	O
sacrifice	O
recall	B-Metric
.	O
	
Motivated	O
by	O
this	O
idea	O
,	O
we	O
decided	O
to	O
explore	O
a	O
variety	O
of	O
models	O
involving	O
quadratic	B-Method
units	I-Method
,	O
including	O
deep	B-Method
RBF	I-Method
networks	I-Method
.	O
	
We	O
found	O
this	O
to	O
be	O
a	O
difficult	O
task	O
—	O
very	O
model	O
with	O
sufficient	O
quadratic	O
inhibition	O
to	O
resist	O
adversarial	O
perturbation	O
obtained	O
high	O
training	O
set	O
error	B-Metric
when	O
trained	O
with	O
SGD	B-Method
.	O
	
section	O
:	O
Why	O
do	O
adversarial	O
examples	O
generalize	O
?	O
	
An	O
intriguing	O
aspect	O
of	O
adversarial	O
examples	O
is	O
that	O
an	O
example	O
generated	O
for	O
one	O
model	O
is	O
often	O
misclassified	O
by	O
other	O
models	O
,	O
even	O
when	O
they	O
have	O
different	O
architecures	O
or	O
were	O
trained	O
on	O
disjoint	O
training	O
sets	O
.	O
	
Moreover	O
,	O
when	O
these	O
different	O
models	O
misclassify	O
an	O
adversarial	O
example	O
,	O
they	O
often	O
agree	O
with	O
each	O
other	O
on	O
its	O
class	O
.	O
	
Explanations	O
based	O
on	O
extreme	O
non	O
-	O
linearity	O
and	O
overfitting	B-Method
can	O
not	O
readily	O
account	O
for	O
this	O
behavior	O
—	O
	
why	O
should	O
multiple	O
extremely	O
non	B-Method
-	I-Method
linear	I-Method
model	I-Method
with	O
excess	O
capacity	O
consistently	O
label	O
out	O
-	O
of	O
-	O
distribution	O
points	O
in	O
the	O
same	O
way	O
?	O
	
This	O
behavior	O
is	O
especially	O
surprising	O
from	O
the	O
view	O
of	O
the	O
hypothesis	O
that	O
adversarial	O
examples	O
finely	O
tile	O
space	O
like	O
the	O
rational	O
numbers	O
among	O
the	O
reals	O
,	O
because	O
in	O
this	O
view	O
adversarial	O
examples	O
are	O
common	O
but	O
occur	O
only	O
at	O
very	O
precise	O
locations	O
.	O
	
Under	O
the	O
linear	O
view	O
,	O
adversarial	O
examples	O
occur	O
in	O
broad	O
subspaces	O
.	O
	
The	O
direction	O
need	O
only	O
have	O
positive	O
dot	O
product	O
with	O
the	O
gradient	O
of	O
the	O
cost	O
function	O
,	O
and	O
need	O
only	O
be	O
large	O
enough	O
.	O
	
Fig	O
.	O
	
[	O
reference	O
]	O
demonstrates	O
this	O
phenomenon	O
.	O
	
By	O
tracing	O
out	O
different	O
values	O
of	O
we	O
see	O
that	O
adversarial	O
examples	O
occur	O
in	O
contiguous	O
regions	O
of	O
the	O
1	O
-	O
D	O
subspace	O
defined	O
by	O
the	O
fast	B-Method
gradient	I-Method
sign	I-Method
method	I-Method
,	O
not	O
in	O
fine	O
pockets	O
.	O
	
This	O
explains	O
why	O
adversarial	O
examples	O
are	O
abundant	O
and	O
why	O
an	O
example	O
misclassified	O
by	O
one	O
classifier	B-Method
has	O
a	O
fairly	O
high	O
prior	O
probability	O
of	O
being	O
misclassified	O
by	O
another	O
classifier	B-Method
.	O
	
To	O
explain	O
why	O
mutiple	B-Method
classifiers	I-Method
assign	O
the	O
same	O
class	O
to	O
adversarial	O
examples	O
,	O
we	O
hypothesize	O
that	O
neural	B-Method
networks	I-Method
trained	O
with	O
current	O
methodologies	O
all	O
resemble	O
the	O
linear	B-Method
classifier	I-Method
learned	O
on	O
the	O
same	O
training	O
set	O
.	O
	
This	O
reference	B-Method
classifier	I-Method
is	O
able	O
to	O
learn	O
approximately	O
the	O
same	O
classification	B-Task
weights	O
when	O
trained	O
on	O
different	O
subsets	O
of	O
the	O
training	O
set	O
,	O
simply	O
because	O
machine	B-Method
learning	I-Method
algorithms	I-Method
are	O
able	O
to	O
generalize	O
.	O
	
The	O
stability	O
of	O
the	O
underlying	O
classification	B-Task
weights	O
in	O
turn	O
results	O
in	O
the	O
stability	O
of	O
adversarial	O
examples	O
.	O
	
To	O
test	O
this	O
hypothesis	O
,	O
we	O
generated	O
adversarial	O
examples	O
on	O
a	O
deep	B-Method
maxout	I-Method
network	I-Method
and	O
classified	O
these	O
examples	O
using	O
a	O
shallow	B-Method
softmax	I-Method
network	I-Method
and	O
a	O
shallow	B-Method
RBF	I-Method
network	I-Method
.	O
	
On	O
examples	O
that	O
were	O
misclassified	O
by	O
the	O
maxout	B-Method
network	I-Method
,	O
the	O
RBF	B-Method
network	I-Method
predicted	O
the	O
maxout	B-Method
network	I-Method
	
’s	O
class	B-Method
assignment	I-Method
only	O
16.0	O
%	O
of	O
the	O
time	O
,	O
while	O
the	O
softmax	B-Method
classifier	I-Method
predict	O
the	O
maxout	B-Method
network	I-Method
’s	O
class	O
correctly	O
54.6	O
%	O
of	O
the	O
time	O
.	O
	
These	O
numbers	O
are	O
largely	O
driven	O
by	O
the	O
differing	O
error	B-Metric
rate	O
of	O
the	O
different	O
models	O
though	O
.	O
	
If	O
we	O
exclude	O
our	O
attention	O
to	O
cases	O
where	O
both	O
models	O
being	O
compared	O
make	O
a	O
mistake	O
,	O
then	O
softmax	B-Method
regression	I-Method
predict	O
’s	O
maxout	O
’s	O
class	O
84.6	O
%	O
of	O
the	O
time	O
,	O
while	O
the	O
RBF	B-Method
network	I-Method
is	O
able	O
to	O
predict	O
maxout	O
’s	O
class	O
only	O
54.3	O
%	O
of	O
the	O
time	O
.	O
	
For	O
comparison	O
,	O
the	O
RBF	B-Method
network	I-Method
can	O
predict	O
softmax	B-Method
regression	I-Method
’s	O
class	O
53.6	O
%	O
of	O
the	O
time	O
,	O
so	O
it	O
does	O
have	O
a	O
strong	O
linear	B-Method
component	I-Method
to	O
its	O
own	O
behavior	O
.	O
	
Our	O
hypothesis	O
does	O
not	O
explain	O
all	O
of	O
the	O
maxout	B-Method
network	I-Method
’s	O
mistakes	O
or	O
all	O
of	O
the	O
mistakes	O
that	O
generalize	O
across	O
models	O
,	O
but	O
clearly	O
a	O
significant	O
proportion	O
of	O
them	O
are	O
consistent	O
with	O
linear	O
behavior	O
being	O
a	O
major	O
cause	O
of	O
cross	B-Method
-	I-Method
model	I-Method
generalization	I-Method
.	O
	
section	O
:	O
Alternative	O
hypotheses	O
	
We	O
now	O
consider	O
and	O
refute	O
some	O
alternative	O
hypotheses	O
for	O
the	O
existence	B-Task
of	I-Task
adversarial	I-Task
examples	I-Task
.	O
	
First	O
,	O
one	O
hypothesis	O
is	O
that	O
generative	B-Method
training	I-Method
could	O
provide	O
more	O
constraint	O
on	O
the	O
training	O
process	O
,	O
or	O
cause	O
the	O
model	O
to	O
learn	O
what	O
to	O
distinguish	O
“	O
real	O
”	O
from	O
“	O
fake	O
”	O
data	O
and	O
be	O
confident	O
only	O
on	O
“	O
real	O
”	O
data	O
.	O
	
The	O
MP	B-Method
-	I-Method
DBM	I-Method
mpdbm	I-Method
provides	O
a	O
good	O
model	O
to	O
test	O
this	O
hypothesis	O
.	O
	
Its	O
inference	B-Method
procedure	I-Method
gets	O
good	O
classification	B-Task
accuracy	O
(	O
an	O
0.88	O
%	O
error	B-Metric
rate	O
)	O
on	O
MNIST	B-Material
.	O
	
This	O
inference	B-Method
procedure	I-Method
is	O
differentiable	O
.	O
	
Other	O
generative	B-Method
models	I-Method
either	O
have	O
non	O
-	O
differentiable	B-Method
inference	I-Method
procedures	I-Method
,	O
making	O
it	O
harder	O
to	O
compute	O
adversarial	O
examples	O
,	O
or	O
require	O
an	O
additional	O
non	B-Method
-	I-Method
generative	I-Method
discriminator	I-Method
model	I-Method
to	O
get	O
good	O
classification	B-Task
accuracy	O
on	O
MNIST	B-Material
.	O
	
In	O
the	O
case	O
of	O
the	O
MP	B-Method
-	I-Method
DBM	I-Method
,	O
we	O
can	O
be	O
sure	O
that	O
the	O
generative	B-Method
model	I-Method
itself	O
is	O
responding	O
to	O
adversarial	O
examples	O
,	O
rather	O
than	O
the	O
non	B-Method
-	I-Method
generative	I-Method
classifier	I-Method
model	I-Method
on	O
top	O
.	O
	
We	O
find	O
that	O
the	O
model	O
is	O
vulnerable	O
to	O
adversarial	O
examples	O
.	O
	
With	O
an	O
of	O
0.25	O
,	O
we	O
find	O
an	O
error	B-Metric
rate	O
of	O
97.5	O
%	O
on	O
adversarial	O
examples	O
generated	O
from	O
the	O
MNIST	B-Material
test	O
set	O
.	O
	
It	O
remains	O
possible	O
that	O
some	O
other	O
form	O
of	O
generative	B-Method
training	I-Method
could	O
confer	O
resistance	O
,	O
but	O
clearly	O
the	O
mere	O
fact	O
of	O
being	O
generative	O
is	O
not	O
alone	O
sufficient	O
.	O
	
Another	O
hypothesis	O
about	O
why	O
adversarial	O
examples	O
exist	O
is	O
that	O
individual	O
models	O
have	O
strange	O
quirks	O
but	O
averaging	O
over	O
many	O
models	O
can	O
cause	O
adversarial	O
examples	O
to	O
wash	O
out	O
.	O
	
To	O
test	O
this	O
hypothesis	O
,	O
we	O
trained	O
an	O
ensemble	B-Method
of	I-Method
twelve	I-Method
maxout	I-Method
networks	I-Method
on	O
MNIST	B-Material
.	O
	
Each	O
network	O
was	O
trained	O
using	O
a	O
different	O
seed	O
for	O
the	O
random	B-Method
number	I-Method
generator	I-Method
used	O
to	O
initialize	O
the	O
weights	O
,	O
generate	O
dropout	O
masks	O
,	O
and	O
select	O
minibatches	O
of	O
data	O
for	O
stochastic	B-Method
gradient	I-Method
descent	I-Method
.	O
	
The	O
ensemble	O
gets	O
an	O
error	B-Metric
rate	O
of	O
91.1	O
%	O
on	O
adversarial	O
examples	O
designed	O
to	O
perturb	O
the	O
entire	O
ensemble	O
with	O
.	O
	
If	O
we	O
instead	O
use	O
adversarial	O
examples	O
designed	O
to	O
perturb	O
only	O
one	O
member	O
of	O
the	O
ensemble	O
,	O
the	O
error	B-Metric
rate	O
falls	O
to	O
87.9	O
%	O
.	O
	
Ensembling	B-Method
provides	O
only	O
limited	O
resistance	O
to	O
adversarial	O
perturbation	O
.	O
	
section	O
:	O
Summary	O
and	O
discussion	O
	
As	O
a	O
summary	O
,	O
this	O
paper	O
has	O
made	O
the	O
following	O
observations	O
:	O
Adversarial	O
examples	O
can	O
be	O
explained	O
as	O
a	O
property	O
of	O
high	O
-	O
dimensional	O
dot	O
products	O
.	O
	
They	O
are	O
a	O
result	O
of	O
models	O
being	O
too	O
linear	O
,	O
rather	O
than	O
too	O
nonlinear	O
.	O
	
The	O
generalization	O
of	O
adversarial	O
examples	O
across	O
different	O
models	O
can	O
be	O
explained	O
as	O
a	O
result	O
of	O
adversarial	O
perturbations	O
being	O
highly	O
aligned	O
with	O
the	O
weight	O
vectors	O
of	O
a	O
model	O
,	O
and	O
different	O
models	O
learning	O
similar	O
functions	O
when	O
trained	O
to	O
perform	O
the	O
same	O
task	O
.	O
	
The	O
direction	O
of	O
perturbation	O
,	O
rather	O
than	O
the	O
specific	O
point	O
in	O
space	O
,	O
matters	O
most	O
.	O
	
Space	O
is	O
not	O
full	O
of	O
pockets	O
of	O
adversarial	O
examples	O
that	O
finely	O
tile	O
the	O
reals	O
like	O
the	O
rational	O
numbers	O
.	O
	
Because	O
it	O
is	O
the	O
direction	O
that	O
matters	O
most	O
,	O
adversarial	O
perturbations	O
generalize	O
across	O
different	O
clean	O
examples	O
.	O
	
We	O
have	O
introduced	O
a	O
family	O
of	O
fast	O
methods	O
for	O
generating	B-Task
adversarial	I-Task
examples	I-Task
.	O
	
We	O
have	O
demonstrated	O
that	O
adversarial	B-Method
training	I-Method
can	O
result	O
in	O
regularization	B-Task
;	O
even	O
further	O
regularization	B-Task
than	O
dropout	B-Method
.	O
	
We	O
have	O
run	O
control	O
experiments	O
that	O
failed	O
to	O
reproduce	O
this	O
effect	O
with	O
simpler	O
but	O
less	O
efficient	O
regularizers	B-Method
including	O
weight	B-Method
decay	I-Method
and	O
adding	O
noise	O
.	O
	
Models	O
that	O
are	O
easy	O
to	O
optimize	O
are	O
easy	O
to	O
perturb	O
.	O
	
Linear	B-Method
models	I-Method
lack	O
the	O
capacity	O
to	O
resist	O
adversarial	O
perturbation	O
;	O
only	O
structures	O
with	O
a	O
hidden	O
layer	O
(	O
where	O
the	O
universal	B-Method
approximator	I-Method
theorem	I-Method
applies	O
)	O
should	O
be	O
trained	O
to	O
resist	O
adversarial	O
perturbation	O
.	O
	
RBF	B-Method
networks	I-Method
are	O
resistant	O
to	O
adversarial	O
examples	O
.	O
	
Models	O
trained	O
to	O
model	O
the	O
input	O
distribution	O
are	O
not	O
resistant	O
to	O
adversarial	O
examples	O
.	O
	
Ensembles	B-Method
are	O
not	O
resistant	O
to	O
adversarial	O
examples	O
.	O
	
Some	O
further	O
observations	O
concerning	O
rubbish	O
class	O
examples	O
are	O
presented	O
in	O
the	O
appendix	O
:	O
Rubbish	O
class	O
examples	O
are	O
ubiquitous	O
and	O
easily	O
generated	O
.	O
	
Shallow	B-Method
linear	I-Method
models	I-Method
are	O
not	O
resistant	O
to	O
rubbish	O
class	O
examples	O
.	O
	
RBF	B-Method
networks	I-Method
are	O
resistant	O
to	O
rubbish	O
class	O
examples	O
.	O
	
Gradient	B-Method
-	I-Method
based	I-Method
optimization	I-Method
is	O
the	O
workhorse	O
of	O
modern	O
AI	B-Task
.	O
	
Using	O
a	O
network	O
that	O
has	O
been	O
designed	O
to	O
be	O
sufficiently	O
linear	O
–	O
whether	O
it	O
is	O
a	O
ReLU	B-Method
or	I-Method
maxout	I-Method
network	I-Method
,	O
an	O
LSTM	B-Method
,	O
or	O
a	O
sigmoid	B-Method
network	I-Method
that	O
has	O
been	O
carefully	O
configured	O
not	O
to	O
saturate	O
too	O
much–	O
we	O
are	O
able	O
to	O
fit	O
most	O
problems	O
we	O
care	O
about	O
,	O
at	O
least	O
on	O
the	O
training	O
set	O
.	O
	
The	O
existence	O
of	O
adversarial	O
examples	O
suggests	O
that	O
being	O
able	O
to	O
explain	O
the	O
training	O
data	O
or	O
even	O
being	O
able	O
to	O
correctly	O
label	O
the	O
test	O
data	O
does	O
not	O
imply	O
that	O
our	O
models	O
truly	O
understand	O
the	O
tasks	O
we	O
have	O
asked	O
them	O
to	O
perform	O
.	O
	
Instead	O
,	O
their	O
linear	O
responses	O
are	O
overly	O
confident	O
at	O
points	O
that	O
do	O
not	O
occur	O
in	O
the	O
data	O
distribution	O
,	O
and	O
these	O
confident	O
predictions	O
are	O
often	O
highly	O
incorrect	O
.	O
	
This	O
work	O
has	O
shown	O
we	O
can	O
partially	O
correct	O
for	O
this	O
problem	O
by	O
explicitly	O
identifying	O
problematic	O
points	O
and	O
correcting	O
the	O
model	O
at	O
each	O
of	O
these	O
points	O
.	O
	
However	O
,	O
one	O
may	O
also	O
conclude	O
that	O
the	O
model	O
families	O
we	O
use	O
are	O
intrinsically	O
flawed	O
.	O
	
Ease	O
of	O
optimization	B-Task
has	O
come	O
at	O
the	O
cost	O
of	O
models	O
that	O
are	O
easily	O
misled	O
.	O
	
This	O
motivates	O
the	O
development	O
of	O
optimization	B-Method
procedures	I-Method
that	O
are	O
able	O
to	O
train	O
models	O
whose	O
behavior	O
is	O
more	O
locally	O
stable	O
.	O
	
subsubsection	O
:	O
Acknowledgments	O
	
We	O
would	O
like	O
to	O
thank	O
Geoffrey	O
Hinton	O
and	O
Ilya	O
Sutskever	O
for	O
helpful	O
discussions	O
.	O
	
We	O
would	O
also	O
like	O
to	O
thank	O
Jeff	O
Dean	O
,	O
Greg	O
Corrado	O
,	O
and	O
Oriol	O
Vinyals	O
for	O
their	O
feedback	O
on	O
drafts	O
of	O
this	O
article	O
.	O
	
We	O
would	O
like	O
to	O
thank	O
the	O
developers	O
of	O
Theano	O
bergstra	O
+	O
al:2010	O
-	O
scipy	O
	
,	O
Bastien	O
-	O
Theano	O
-	O
2012	O
,	O
	
Pylearn2	B-Method
pylearn2_arxiv_2013	I-Method
,	O
and	O
DistBelief	B-Method
distbelief	I-Method
.	O
	
plus	O
0.3ex	O
	
bibliography	O
:	O
References	O
	
appendix	O
:	O
Rubbish	O
class	O
examples	O
	
A	O
concept	O
related	O
to	O
adversarial	O
examples	O
is	O
the	O
concept	O
of	O
examples	O
drawn	O
from	O
a	O
“	O
rubbish	O
class	O
.	O
	
”	O
	
These	O
examples	O
are	O
degenerate	O
inputs	O
that	O
a	O
human	O
would	O
classify	O
as	O
not	O
belonging	O
to	O
any	O
of	O
the	O
categories	O
in	O
the	O
training	O
set	O
.	O
	
If	O
we	O
call	O
these	O
classes	O
in	O
the	O
training	O
set	O
“	O
the	O
positive	O
classes	O
,	O
”	O
then	O
we	O
want	O
to	O
be	O
careful	O
to	O
avoid	O
false	O
positives	O
on	O
rubbish	O
inputs	O
	
–	O
	
i.e	O
.	O
	
,	O
we	O
do	O
not	O
want	O
to	O
classify	O
a	O
degenerate	O
input	O
as	O
being	O
something	O
real	O
.	O
	
In	O
the	O
case	O
of	O
separate	O
binary	B-Method
classifiers	I-Method
for	O
each	O
class	O
,	O
we	O
want	O
all	O
classes	O
output	O
near	O
zero	O
probability	O
of	O
the	O
class	O
being	O
present	O
,	O
and	O
in	O
the	O
case	O
of	O
a	O
multinoulli	O
distribution	O
over	O
only	O
the	O
positive	O
classes	O
,	O
we	O
would	O
prefer	O
that	O
the	O
classifier	B-Method
output	O
a	O
high	O
-	O
entropy	O
(	O
nearly	O
uniform	O
)	O
distribution	O
over	O
the	O
classes	O
.	O
	
The	O
traditional	O
approach	O
to	O
reducing	O
vulnerability	O
to	O
rubbish	O
inputs	O
is	O
to	O
introduce	O
an	O
extra	O
,	O
constant	O
output	O
to	O
the	O
model	O
representing	O
the	O
rubbish	O
class	O
LeCun	O
+	O
98	O
.	O
	
fool	O
recently	O
re	O
-	O
popularized	O
the	O
concept	O
of	O
the	O
rubbish	B-Method
class	I-Method
in	O
the	O
context	O
of	O
computer	B-Task
vision	I-Task
under	O
the	O
name	O
fooling	O
images	O
.	O
	
As	O
with	O
adversarial	O
examples	O
,	O
there	O
has	O
been	O
a	O
misconception	O
that	O
rubbish	O
class	O
false	O
positives	O
are	O
hard	O
to	O
find	O
,	O
and	O
that	O
they	O
are	O
primarily	O
a	O
problem	O
faced	O
by	O
deep	B-Method
networks	I-Method
.	O
	
Our	O
explanation	O
of	O
adversarial	O
examples	O
as	O
the	O
result	O
of	O
linearity	O
and	O
high	O
dimensional	O
spaces	O
also	O
applies	O
to	O
analyzing	O
the	O
behavior	O
of	O
the	O
model	O
on	O
rubbish	O
class	O
examples	O
.	O
	
Linear	B-Method
models	I-Method
produce	O
more	O
extreme	O
predictions	O
at	O
points	O
that	O
are	O
far	O
from	O
the	O
training	O
data	O
than	O
at	O
points	O
that	O
are	O
near	O
the	O
training	O
data	O
.	O
	
In	O
order	O
to	O
find	O
high	O
confidence	O
rubbish	O
false	O
positives	O
for	O
such	O
a	O
model	O
,	O
we	O
need	O
only	O
generate	O
a	O
point	O
that	O
is	O
far	O
from	O
the	O
data	O
,	O
with	O
larger	O
norms	O
yielding	O
more	O
confidence	O
.	O
	
RBF	B-Method
networks	I-Method
,	O
which	O
are	O
not	O
able	O
to	O
confidently	O
predict	O
the	O
presence	O
of	O
any	O
class	O
far	O
from	O
the	O
training	O
data	O
,	O
are	O
not	O
fooled	O
by	O
this	O
phenomenon	O
.	O
	
We	O
generated	O
10	O
,	O
000	O
samples	O
from	O
and	O
fed	O
them	O
into	O
various	O
classifiers	B-Method
on	O
the	O
MNIST	B-Material
dataset	I-Material
.	O
	
In	O
this	O
context	O
,	O
we	O
consider	O
assigning	O
a	O
probability	O
greater	O
than	O
0.5	O
to	O
any	O
class	O
to	O
be	O
an	O
error	B-Metric
.	O
	
A	O
naively	O
trained	O
maxout	B-Method
network	I-Method
with	O
a	O
softmax	B-Method
layer	I-Method
on	O
top	O
had	O
an	O
error	B-Metric
rate	O
of	O
98.35	O
%	O
on	O
Gaussian	O
rubbish	O
examples	O
with	O
an	O
average	B-Metric
confidence	I-Metric
of	O
92.8	O
%	O
on	O
mistakes	O
.	O
	
Changing	O
the	O
top	O
layer	O
to	O
independent	O
sigmoids	B-Method
dropped	O
the	O
error	B-Metric
rate	O
to	O
68	O
%	O
with	O
an	O
average	O
confidence	B-Metric
on	O
mistakes	B-Metric
of	O
87.9	O
%	O
.	O
	
On	O
CIFAR	B-Material
-	I-Material
10	I-Material
,	O
using	O
1	O
,	O
000	O
samples	O
from	O
,	O
a	O
convolutional	B-Method
maxout	I-Method
net	I-Method
obtains	O
an	O
error	B-Metric
rate	O
of	O
93.4	O
%	O
,	O
with	O
an	O
average	B-Metric
confidence	I-Metric
of	O
84.4	O
%	O
.	O
	
These	O
experiments	O
suggest	O
that	O
the	O
optimization	B-Method
algorithms	I-Method
employed	O
by	O
fool	B-Method
are	O
overkill	O
(	O
or	O
perhaps	O
only	O
needed	O
on	O
ImageNet	B-Material
)	O
,	O
and	O
that	O
the	O
rich	O
geometric	O
structure	O
in	O
their	O
fooling	O
images	O
are	O
due	O
to	O
the	O
priors	O
encoded	O
in	O
their	O
search	B-Method
procedures	I-Method
,	O
rather	O
than	O
those	O
structures	O
being	O
uniquely	O
able	O
to	O
cause	O
false	O
positives	O
.	O
	
Though	O
fool	O
focused	O
their	O
attention	O
on	O
deep	B-Method
networks	I-Method
,	O
shallow	B-Method
linear	I-Method
models	I-Method
have	O
the	O
same	O
problem	O
.	O
	
A	O
softmax	B-Method
regression	I-Method
model	I-Method
has	O
an	O
error	B-Metric
rate	O
of	O
59.8	O
%	O
on	O
the	O
rubbish	O
examples	O
,	O
with	O
an	O
average	B-Metric
confidence	I-Metric
on	O
mistakes	O
of	O
70.8	O
%	O
.	O
	
If	O
we	O
use	O
instead	O
an	O
RBF	B-Method
network	I-Method
,	O
which	O
does	O
not	O
behave	O
like	O
a	O
linear	O
function	O
,	O
we	O
find	O
an	O
error	B-Metric
rate	O
of	O
0	O
%	O
.	O
	
Note	O
that	O
when	O
the	O
error	B-Metric
rate	O
is	O
zero	O
the	O
average	B-Metric
confidence	I-Metric
on	O
a	O
mistake	O
is	O
undefined	O
.	O
	
fool	B-Method
focused	O
on	O
the	O
problem	O
of	O
generating	B-Task
fooling	I-Task
images	I-Task
for	O
a	O
specific	O
class	O
,	O
which	O
is	O
a	O
harder	O
problem	O
than	O
simply	O
finding	O
points	O
that	O
the	O
network	O
confidently	O
classifies	O
as	O
belonging	O
to	O
any	O
one	O
class	O
despite	O
being	O
defective	O
.	O
	
The	O
above	O
methods	O
on	O
MNIST	B-Material
and	O
CIFAR	B-Material
-	I-Material
10	I-Material
tend	O
to	O
have	O
a	O
very	O
skewed	O
distribution	O
over	O
classes	O
.	O
	
On	O
MNIST	B-Material
,	O
45.3	O
%	O
of	O
a	O
naively	O
trained	O
maxout	B-Method
network	I-Method
’s	O
false	B-Metric
positives	I-Metric
were	O
classified	O
as	O
5s	O
,	O
and	O
none	O
were	O
classified	O
as	O
8s	O
.	O
	
Likewise	O
,	O
on	O
CIFAR	B-Material
-	I-Material
10	I-Material
,	O
49.7	O
%	O
of	O
the	O
convolutional	B-Method
network	I-Method
’s	O
false	B-Metric
positives	I-Metric
were	O
classified	O
as	O
frogs	O
,	O
and	O
none	O
were	O
classified	O
as	O
airplanes	O
,	O
automobiles	O
,	O
horses	O
,	O
ships	O
,	O
or	O
trucks	O
.	O
	
To	O
solve	O
the	O
problem	O
introduced	O
by	O
fool	O
of	O
generating	O
a	O
fooling	B-Task
image	I-Task
for	O
a	O
particular	O
class	O
,	O
we	O
propose	O
adding	O
to	O
a	O
Gaussian	B-Method
sample	I-Method
as	O
a	O
fast	O
method	O
of	O
generating	O
a	O
fooling	B-Task
image	I-Task
classified	O
as	O
class	O
.	O
	
If	O
we	O
repeat	O
this	O
sampling	O
process	O
until	O
it	O
succeeds	O
,	O
we	O
a	O
randomized	B-Method
algorithm	I-Method
with	O
variable	O
runtime	O
.	O
	
On	O
CIFAR	B-Material
-	I-Material
10	I-Material
,	O
we	O
found	O
that	O
one	O
sampling	O
step	O
had	O
a	O
100	O
%	O
success	B-Metric
rate	I-Metric
for	O
frogs	O
and	O
trucks	O
,	O
and	O
the	O
hardest	O
class	O
was	O
airplanes	O
,	O
with	O
a	O
success	B-Metric
rate	I-Metric
of	O
24.7	O
%	O
per	O
sampling	O
step	O
.	O
	
Averaged	O
over	O
all	O
ten	O
classes	O
,	O
the	O
method	O
has	O
an	O
average	O
per	B-Metric
-	I-Metric
step	I-Metric
success	I-Metric
rate	I-Metric
of	O
75.3	O
%	O
.	O
	
We	O
can	O
thus	O
generate	O
any	O
desired	O
class	O
with	O
a	O
handful	O
of	O
samples	O
and	O
no	O
special	O
priors	O
,	O
rather	O
than	O
tens	O
of	O
thousands	O
of	O
generations	O
of	O
evolution	O
.	O
	
To	O
confirm	O
that	O
the	O
resulting	O
examples	O
are	O
indeed	O
fooling	O
images	O
,	O
and	O
not	O
images	O
of	O
real	O
classes	O
rendered	O
by	O
the	O
gradient	B-Method
sign	I-Method
method	I-Method
,	O
see	O
Fig	O
.	O
	
[	O
reference	O
]	O
.	O
	
The	O
success	B-Metric
rate	I-Metric
of	O
this	O
method	O
in	O
terms	O
of	O
generating	B-Task
members	I-Task
of	I-Task
class	I-Task
may	O
degrade	O
for	O
datasets	O
with	O
more	O
classes	O
,	O
since	O
the	O
risk	O
of	O
inadvertently	O
increasing	O
the	O
activation	O
of	O
a	O
different	O
class	O
increases	O
in	O
that	O
case	O
.	O
	
We	O
found	O
that	O
we	O
were	O
able	O
to	O
train	O
a	O
maxout	B-Method
network	I-Method
to	O
have	O
a	O
zero	O
percent	O
error	B-Metric
rate	O
on	O
Gaussian	O
rubbish	O
examples	O
(	O
it	O
was	O
still	O
vulnerable	O
to	O
rubbish	O
examples	O
generated	O
by	O
applying	O
a	O
fast	O
gradient	O
sign	O
step	O
to	O
a	O
Gaussian	O
sample	O
)	O
with	O
no	O
negative	O
impact	O
on	O
its	O
ability	O
to	O
classify	O
clean	O
examples	O
.	O
	
Unfortunately	O
,	O
unlike	O
training	O
on	O
adversarial	O
examples	O
,	O
this	O
did	O
not	O
result	O
in	O
any	O
significant	O
reduction	O
of	O
the	O
model	O
’s	O
test	B-Metric
set	I-Metric
error	I-Metric
rate	O
.	O
	
In	O
conclusion	O
,	O
it	O
appears	O
that	O
a	O
randomly	O
selected	O
input	O
to	O
deep	B-Method
or	I-Method
shallow	I-Method
models	I-Method
built	O
from	O
linear	B-Method
parts	I-Method
is	O
overwhelmingly	O
likely	O
to	O
be	O
processed	O
incorrectly	O
,	O
and	O
that	O
these	O
models	O
only	O
behave	O
reasonably	O
on	O
a	O
very	O
thin	O
manifold	O
encompassing	O
the	O
training	O
data	O
.	O
	
document	O
:	O
aNMM	B-Method
:	O
Ranking	B-Task
Short	I-Task
Answer	I-Task
Texts	I-Task
with	O
Attention	B-Method
-	I-Method
Based	I-Method
Neural	I-Method
Matching	I-Method
Model	I-Method
	
As	O
an	O
alternative	O
to	O
question	B-Task
answering	I-Task
methods	O
based	O
on	O
feature	B-Method
engineering	I-Method
,	O
deep	B-Method
learning	I-Method
approaches	I-Method
such	O
as	O
convolutional	B-Method
neural	I-Method
networks	I-Method
(	O
CNNs	B-Method
)	O
and	O
Long	B-Method
Short	I-Method
-	I-Method
Term	I-Method
Memory	I-Method
Models	I-Method
(	O
LSTMs	B-Method
)	O
have	O
recently	O
been	O
proposed	O
for	O
semantic	B-Task
matching	I-Task
of	I-Task
questions	I-Task
and	I-Task
answers	I-Task
.	O
	
To	O
achieve	O
good	O
results	O
,	O
however	O
,	O
these	O
models	O
have	O
been	O
combined	O
with	O
additional	O
features	O
such	O
as	O
word	O
overlap	O
or	O
BM25	B-Metric
scores	I-Metric
.	O
	
Without	O
this	O
combination	O
,	O
these	O
models	O
perform	O
significantly	O
worse	O
than	O
methods	O
based	O
on	O
linguistic	B-Method
feature	I-Method
engineering	I-Method
.	O
	
In	O
this	O
paper	O
,	O
we	O
propose	O
an	O
attention	B-Method
based	I-Method
neural	I-Method
matching	I-Method
model	I-Method
for	O
ranking	B-Task
short	I-Task
answer	I-Task
text	I-Task
.	O
	
We	O
adopt	O
value	B-Method
-	I-Method
shared	I-Method
weighting	I-Method
scheme	I-Method
instead	O
of	O
position	B-Method
-	I-Method
shared	I-Method
weighting	I-Method
scheme	I-Method
for	O
combining	O
different	O
matching	O
signals	O
and	O
incorporate	O
question	B-Method
term	I-Method
importance	I-Method
learning	I-Method
using	O
question	B-Task
attention	I-Task
network	O
.	O
	
Using	O
the	O
popular	O
benchmark	O
TREC	B-Material
QA	O
data	O
,	O
we	O
show	O
that	O
the	O
relatively	O
simple	O
aNMM	B-Method
model	O
can	O
significantly	O
outperform	O
other	O
neural	B-Method
network	I-Method
models	I-Method
that	O
have	O
been	O
used	O
for	O
the	O
question	B-Task
answering	I-Task
task	O
,	O
and	O
is	O
competitive	O
with	O
models	O
that	O
are	O
combined	O
with	O
additional	O
features	O
.	O
	
When	O
aNMM	B-Method
is	O
combined	O
with	O
additional	O
features	O
,	O
it	O
outperforms	O
all	O
baselines	O
.	O
	
2016	O
,	O
October	O
24	O
-	O
28	O
,	O
2016	O
,	O
Indianapolis	O
,	O
IN	O
,	O
	
USA	O
¡	O
ccs2012	O
¿	O
¡	O
concept	O
¿	O
¡	O
concept_id¿10002951.10003317.10003338¡	O
/	O
concept_id	O
¿	O
¡	O
concept_desc¿Information	B-Method
systems	I-Method
Retrieval	I-Method
models	I-Method
and	O
ranking¡	O
/	O
concept_desc	O
¿	O
¡	O
concept_significance¿500¡	O
/	O
concept_significance	O
¿	O
¡	O
/	O
concept	O
¿	O
¡	O
concept	O
¿	O
¡	O
concept_id¿10002951.10003317.10003347.10003348¡	O
/	O
concept_id	O
¿	O
¡	O
concept_desc¿Information	B-Method
systems	I-Method
Question	I-Task
answering¡	I-Task
/	O
concept_desc	O
¿	O
¡	O
concept_significance¿500¡	O
/	O
concept_significance	O
¿	O
¡	O
/	O
concept	O
¿	O
¡	O
/	O
ccs2012	O
¿	O
[	O
500	O
]	O
Information	O
systems	O
Retrieval	B-Method
models	I-Method
and	O
ranking	B-Task
systems	I-Task
Question	I-Task
answering	I-Task
	
section	O
:	O
Introduction	O
	
Question	B-Task
answering	I-Task
(	O
QA	B-Task
)	O
,	O
which	O
returns	O
exact	O
answers	O
as	O
either	O
short	O
facts	O
or	O
long	O
passages	O
to	O
natural	O
language	O
questions	O
issued	O
by	O
users	O
,	O
is	O
a	O
challenging	O
task	O
and	O
plays	O
a	O
central	O
role	O
in	O
the	O
next	O
generation	O
of	O
advanced	B-Task
web	I-Task
search	I-Task
.	O
	
Many	O
of	O
current	O
QA	B-Method
systems	I-Method
use	O
a	O
learning	B-Method
to	I-Method
rank	I-Method
approach	I-Method
that	O
encodes	O
question	O
/	O
answer	O
pairs	O
with	O
complex	O
linguistic	O
features	O
including	O
lexical	O
,	O
syntactic	O
and	O
semantic	O
features	O
.	O
	
For	O
instance	O
,	O
Surdeanu	O
et	O
al	O
.	O
investigated	O
a	O
wide	O
range	O
of	O
feature	O
types	O
including	O
similarity	O
features	O
,	O
translation	O
features	O
,	O
density	O
/	O
frequency	O
features	O
and	O
web	B-Method
correlation	I-Method
features	I-Method
for	O
learning	O
to	O
rank	O
answers	O
and	O
show	O
improvements	O
in	O
accuracy	B-Metric
.	O
	
However	O
,	O
such	O
methods	O
rely	O
on	O
manual	B-Method
feature	I-Method
engineering	I-Method
,	O
which	O
is	O
often	O
time	O
-	O
consuming	O
and	O
requires	O
domain	O
dependent	O
expertise	O
and	O
experience	O
.	O
	
Moreover	O
,	O
they	O
may	O
need	O
additional	O
NLP	B-Method
parsers	I-Method
or	O
external	O
knowledge	O
sources	O
that	O
may	O
not	O
be	O
available	O
for	O
some	O
languages	O
.	O
	
Recently	O
,	O
researchers	O
have	O
been	O
studying	O
deep	B-Method
learning	I-Method
approaches	I-Method
to	O
automatically	O
learn	O
semantic	B-Task
match	I-Task
between	O
questions	O
and	O
answers	O
.	O
	
Such	O
methods	O
are	O
built	O
on	O
the	O
top	O
of	O
neural	B-Method
network	I-Method
models	I-Method
such	O
as	O
convolutional	B-Method
neural	I-Method
networks	I-Method
(	O
CNNs	B-Method
)	O
and	O
Long	B-Method
Short	I-Method
-	I-Method
Term	I-Method
Memory	I-Method
Models	I-Method
(	O
LSTMs	B-Method
)	O
.	O
	
The	O
proposed	O
models	O
have	O
the	O
benefit	O
of	O
not	O
requiring	O
hand	O
-	O
crafted	O
linguistic	O
features	O
and	O
external	O
resources	O
.	O
	
Some	O
of	O
them	O
achieve	O
state	O
-	O
of	O
-	O
the	O
art	O
performance	O
for	O
the	O
answer	B-Task
sentence	I-Task
selection	I-Task
task	I-Task
benchmarked	O
by	O
the	O
TREC	B-Material
QA	O
track	O
.	O
	
However	O
,	O
the	O
weakness	O
of	O
the	O
existing	O
studies	O
is	O
that	O
the	O
proposed	O
deep	B-Method
models	I-Method
,	O
either	O
based	O
on	O
CNNs	B-Method
or	O
LSTMs	B-Method
,	O
need	O
to	O
be	O
combined	O
with	O
additional	O
features	O
such	O
as	O
word	O
overlap	O
features	O
and	O
	
BM25	B-Method
to	O
perform	O
well	O
.	O
	
Without	O
combining	O
these	O
additional	O
features	O
,	O
their	O
performance	O
is	O
significantly	O
worse	O
than	O
the	O
results	O
obtained	O
by	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
methods	O
based	O
on	O
linguistic	B-Method
feature	I-Method
engineering	I-Method
.	O
	
This	O
led	O
us	O
to	O
propose	O
the	O
following	O
research	O
questions	O
:	O
RQ1	O
Without	O
combining	O
additional	O
features	O
,	O
could	O
we	O
build	O
deep	B-Method
learning	I-Method
models	I-Method
that	O
can	O
achieve	O
comparable	O
or	O
even	O
better	O
performance	O
than	O
methods	O
using	O
feature	B-Method
engineering	I-Method
?	O
	
RQ2	O
	
By	O
combining	O
additional	O
features	O
,	O
could	O
our	O
model	O
outperform	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
models	O
for	O
question	B-Task
answering	I-Task
?	O
	
To	O
address	O
these	O
research	O
questions	O
,	O
we	O
analyze	O
the	O
existing	O
current	O
deep	B-Method
learning	I-Method
architectures	I-Method
for	O
answer	B-Task
ranking	I-Task
and	O
make	O
the	O
following	O
two	O
key	O
observations	O
:	O
Architectures	O
not	O
specifically	O
designed	O
for	O
question	B-Task
/	I-Task
answer	I-Task
matching	I-Task
:	O
Some	O
methods	O
employ	O
CNNs	B-Method
for	O
question	B-Task
/	I-Task
answer	I-Task
matching	I-Task
.	O
	
However	O
,	O
CNNs	B-Method
are	O
originally	O
designed	O
for	O
computer	B-Task
vision	I-Task
(	O
CV	B-Task
)	O
,	O
which	O
uses	O
position	O
-	O
shared	O
weights	O
with	O
local	B-Method
perceptive	I-Method
filters	I-Method
,	O
to	O
learn	O
spatial	O
regularities	O
in	O
many	O
CV	B-Task
tasks	O
.	O
	
However	O
,	O
such	O
spatial	O
regularities	O
may	O
not	O
exist	O
in	O
semantic	B-Task
matching	I-Task
between	O
questions	O
and	O
answers	O
,	O
since	O
important	O
similarity	O
signals	O
between	O
question	O
and	O
answer	O
terms	O
could	O
appear	O
in	O
any	O
position	O
due	O
to	O
the	O
complex	O
linguistic	O
property	O
of	O
natural	O
languages	O
.	O
	
Meanwhile	O
,	O
models	O
based	O
on	O
LSTMs	B-Method
view	O
the	O
question	B-Task
/	I-Task
answer	I-Task
matching	I-Task
problem	I-Task
in	O
a	O
sequential	O
way	O
.	O
	
Without	O
direct	O
interactions	O
between	O
question	O
and	O
answer	O
terms	O
,	O
the	O
model	O
may	O
not	O
be	O
able	O
to	O
capture	O
sufficiently	O
detailed	O
matching	O
signals	O
between	O
them	O
.	O
	
Lack	O
of	O
modeling	O
question	O
focus	O
:	O
	
Understanding	O
the	O
focus	O
of	O
questions	O
,	O
e.g.	O
,	O
important	O
terms	O
in	O
a	O
question	O
,	O
is	O
helpful	O
for	O
ranking	O
the	O
answers	O
correctly	O
.	O
	
For	O
example	O
,	O
given	O
a	O
question	O
like	O
“	O
Where	O
was	O
the	O
first	O
burger	O
king	O
restaurant	O
opened	O
?	O
”	O
,	O
it	O
is	O
critical	O
for	O
the	O
answer	O
to	O
talk	O
about	O
“	O
burger	O
”	O
,	O
“	O
king	O
”	O
,	O
“	O
open	O
”	O
,	O
etc	O
.	O
	
Most	O
existing	O
text	B-Method
matching	I-Method
models	I-Method
do	O
not	O
explicitly	O
model	O
question	O
focus	O
.	O
	
For	O
example	O
,	O
models	O
based	O
on	O
CNNs	B-Method
treat	O
all	O
the	O
question	O
terms	O
as	O
equally	O
important	O
when	O
matching	O
to	O
answer	O
terms	O
.	O
	
Models	O
based	O
on	O
LSTMs	B-Method
usually	O
model	O
question	O
terms	O
closer	O
to	O
the	O
end	O
to	O
be	O
more	O
important	O
.	O
	
To	O
handle	O
these	O
issues	O
in	O
the	O
existing	O
deep	B-Method
learning	I-Method
architectures	I-Method
for	O
ranking	B-Task
answers	I-Task
,	O
we	O
propose	O
an	O
attention	B-Method
based	I-Method
neural	I-Method
matching	I-Method
model	I-Method
(	O
aNMM	B-Method
)	O
.	O
	
The	O
novel	O
properties	O
of	O
the	O
proposed	O
model	O
and	O
our	O
contributions	O
can	O
be	O
summarized	O
as	O
follows	O
:	O
	
Deep	B-Method
neural	I-Method
network	I-Method
with	O
value	B-Method
-	I-Method
shared	I-Method
weights	I-Method
:	O
We	O
introduce	O
a	O
novel	O
value	B-Method
-	I-Method
shared	I-Method
weighting	I-Method
scheme	I-Method
in	O
deep	B-Method
neural	I-Method
networks	I-Method
as	O
a	O
counterpart	O
of	O
the	O
position	B-Method
-	I-Method
shared	I-Method
weighting	I-Method
scheme	I-Method
in	O
CNNs	B-Method
,	O
based	O
on	O
the	O
idea	O
that	O
semantic	B-Task
matching	I-Task
between	O
a	O
question	O
and	O
answer	O
is	O
mainly	O
about	O
the	O
(	O
semantic	O
similarity	O
)	O
value	O
regularities	O
rather	O
than	O
spatial	O
regularities	O
.	O
	
Incorporate	O
attention	B-Method
scheme	I-Method
over	O
question	O
terms	O
:	O
We	O
incorporate	O
the	O
attention	B-Method
scheme	I-Method
over	O
the	O
question	O
terms	O
using	O
a	O
gating	B-Method
function	I-Method
,	O
so	O
that	O
we	O
can	O
explicitly	O
discriminate	O
the	O
question	O
term	O
importance	O
.	O
	
Extensive	O
experimental	O
evaluation	O
and	O
promising	O
results	O
.	O
	
We	O
perform	O
a	O
thorough	O
experimental	O
study	O
based	O
on	O
the	O
TREC	B-Material
QA	I-Material
dataset	I-Material
from	O
TREC	B-Material
QA	O
tracks	O
8	O
-	O
13	O
,	O
which	O
appears	O
to	O
be	O
one	O
of	O
the	O
most	O
widely	O
used	O
benchmarks	O
for	O
answer	B-Task
re	I-Task
-	I-Task
ranking	I-Task
.	O
	
Unlike	O
previous	O
methods	O
using	O
CNNs	B-Method
and	O
LSTMs	B-Method
,	O
which	O
showed	O
inferior	O
results	O
without	O
combining	O
additional	O
features	O
,	O
our	O
model	O
can	O
achieve	O
better	O
performance	O
than	O
a	O
state	O
-	O
of	O
-	O
art	O
method	O
using	O
linguistic	B-Method
feature	I-Method
engineering	I-Method
and	O
comparable	O
performance	O
with	O
previous	O
deep	B-Method
learning	I-Method
models	I-Method
with	O
combined	O
additional	O
features	O
.	O
	
If	O
we	O
combine	O
our	O
model	O
with	O
a	O
simple	O
additional	O
feature	O
like	O
QL	B-Metric
,	O
our	O
method	O
can	O
achieve	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
performance	O
among	O
current	O
existing	O
methods	O
for	O
ranking	B-Task
answers	I-Task
under	O
multiple	O
metrics	B-Metric
.	O
	
Roadmap	O
.	O
	
The	O
rest	O
of	O
our	O
paper	O
is	O
organized	O
as	O
follows	O
.	O
	
We	O
will	O
review	O
related	O
work	O
in	O
Section	O
[	O
reference	O
]	O
.	O
	
In	O
Section	O
[	O
reference	O
]	O
,	O
we	O
will	O
present	O
the	O
proposed	O
aNMM	B-Method
model	O
with	O
two	O
components	O
:	O
value	O
-	O
shared	O
weights	O
and	O
question	B-Task
attention	I-Task
network	O
with	O
gating	O
functions	O
.	O
	
Two	O
different	O
architectures	O
will	O
be	O
presented	O
and	O
analyzed	O
.	O
	
Section	O
[	O
reference	O
]	O
is	O
a	O
systematic	O
experimental	O
analysis	O
using	O
the	O
TREC	B-Material
QA	O
benchmark	O
dataset	O
.	O
	
Finally	O
,	O
we	O
conclude	O
our	O
paper	O
and	O
discuss	O
future	O
work	O
in	O
Section	O
[	O
reference	O
]	O
.	O
	
section	O
:	O
Related	O
Work	O
	
Our	O
work	O
is	O
related	O
to	O
several	O
research	O
areas	O
,	O
including	O
deep	B-Method
learning	I-Method
models	I-Method
for	O
text	B-Task
matching	I-Task
,	O
factoid	O
question	B-Task
answering	I-Task
,	O
answer	B-Task
ranking	I-Task
in	O
CQA	B-Task
and	O
answer	B-Task
passage	I-Task
/	I-Task
sentence	I-Task
retrieval	I-Task
.	O
	
Deep	B-Method
Learning	I-Method
Models	I-Method
for	O
Text	B-Task
Matching	I-Task
.	O
	
Recently	O
there	O
have	O
been	O
many	O
deep	B-Method
learning	I-Method
models	I-Method
proposed	O
for	O
text	B-Task
matching	I-Task
and	I-Task
ranking	I-Task
.	O
	
Such	O
deep	B-Method
learning	I-Method
models	I-Method
include	O
DSSM	B-Method
,	O
CDSSM	B-Method
,	O
ARC	B-Method
-	I-Method
I	I-Method
/	O
ARC	B-Method
-	I-Method
II	I-Method
,	O
DCNN	B-Method
,	O
DeepMatch	B-Method
,	O
MultiGranCNN	B-Method
and	O
MatchPyramid	B-Method
.	O
	
DSSM	B-Method
performs	O
a	O
non	B-Method
-	I-Method
linear	I-Method
projection	I-Method
to	O
map	O
the	O
query	O
and	O
the	O
documents	O
to	O
a	O
common	O
semantic	O
space	O
.	O
	
The	O
neural	B-Method
network	I-Method
models	I-Method
are	O
trained	O
using	O
clickthrough	O
data	O
such	O
that	O
the	O
conditional	O
likelihood	O
of	O
the	O
clicked	O
document	O
given	O
the	O
query	O
is	O
maximized	O
.	O
	
DeepMatch	B-Method
uses	O
a	O
topic	B-Method
model	I-Method
to	O
construct	O
the	O
interactions	O
between	O
two	O
texts	O
and	O
then	O
makes	O
different	O
levels	O
of	O
abstractions	O
with	O
a	O
deep	B-Method
architecture	I-Method
to	O
model	O
the	O
relationships	O
between	O
topics	O
.	O
	
ARC	B-Method
-	I-Method
I	I-Method
and	O
ARC	B-Method
-	I-Method
II	I-Method
are	O
two	O
different	O
architectures	O
proposed	O
by	O
Hu	O
et	O
.	O
	
al	O
.	O
for	O
matching	B-Task
natural	I-Task
language	I-Task
sentences	I-Task
.	O
	
ARC	B-Method
-	I-Method
I	I-Method
firstly	O
finds	O
the	O
representation	O
of	O
each	O
sentence	O
and	O
then	O
compares	O
the	O
representations	O
of	O
the	O
two	O
sentences	O
with	O
a	O
multi	B-Method
-	I-Method
layer	I-Method
perceptron	I-Method
(	O
MLP	B-Method
)	O
.	O
	
The	O
drawback	O
of	O
ARC	B-Method
-	I-Method
I	I-Method
is	O
that	O
it	O
defers	O
the	O
interaction	O
between	O
two	O
sentences	O
until	O
their	O
individual	O
representation	O
matures	O
in	O
the	O
convolution	B-Method
model	I-Method
,	O
and	O
therefore	O
has	O
the	O
risk	O
of	O
losing	O
details	O
,	O
which	O
could	O
be	O
important	O
for	O
the	O
matching	B-Task
task	I-Task
.	O
	
On	O
the	O
other	O
hand	O
,	O
ARC	B-Method
-	I-Method
II	I-Method
is	O
built	O
directly	O
on	O
the	O
interaction	O
space	O
between	O
two	O
sentences	O
.	O
	
Thus	O
ARC	B-Method
-	I-Method
II	I-Method
makes	O
two	O
sentences	O
meet	O
before	O
their	O
own	O
high	O
-	O
level	O
representations	O
mature	O
,	O
while	O
still	O
retaining	O
the	O
space	O
for	O
individual	O
development	O
of	O
abstraction	O
of	O
each	O
sentence	O
.	O
	
Our	O
aNMM	B-Method
architecture	O
adopts	O
a	O
similar	O
design	O
with	O
ARC	B-Method
-	I-Method
II	I-Method
in	O
the	O
QA	B-Task
matching	I-Task
matrix	I-Task
where	O
we	O
build	O
neural	B-Method
networks	I-Method
directly	O
on	O
the	O
interaction	O
of	O
sentence	O
term	O
pairs	O
.	O
	
However	O
,	O
we	O
adopt	O
value	O
-	O
shared	O
weights	O
instead	O
of	O
position	O
-	O
shared	O
weights	O
as	O
in	O
the	O
CNN	B-Method
used	O
by	O
ARC	B-Method
-	I-Method
II	I-Method
.	O
	
We	O
also	O
add	O
attention	B-Method
scheme	I-Method
to	O
learn	O
question	O
term	O
importance	O
.	O
	
Factoid	B-Task
Question	I-Task
Answering	I-Task
.	O
	
There	O
have	O
been	O
many	O
previous	O
studies	O
on	O
factoid	O
question	B-Task
answering	I-Task
,	O
most	O
of	O
which	O
use	O
the	O
benchmark	O
data	O
from	O
TREC	B-Material
QA	O
track	O
.	O
	
Yih	O
et	O
.	O
	
al	O
.	O
formulated	O
answer	B-Task
sentence	I-Task
selection	I-Task
as	O
a	O
semantic	B-Task
matching	I-Task
problem	I-Task
with	O
a	O
latent	O
word	O
-	O
alignment	O
structure	O
and	O
conducted	O
a	O
series	O
of	O
experimental	O
studies	O
on	O
leveraging	O
proposed	O
lexical	B-Method
semantic	I-Method
models	I-Method
.	O
	
Iyyer	O
et	O
.	O
	
al	O
.	O
introduced	O
a	O
recursive	B-Method
neural	I-Method
network	I-Method
(	O
RNN	B-Method
)	O
model	O
that	O
can	O
reason	O
over	O
text	O
that	O
contains	O
very	O
few	O
individual	O
words	O
by	O
modeling	O
textual	B-Method
compositionality	I-Method
.	O
	
Yu	O
et	O
al	O
.	O
proposed	O
an	O
approach	O
for	O
answer	B-Task
sentence	I-Task
selection	I-Task
via	O
distributed	B-Method
representations	I-Method
,	O
and	O
learned	O
to	O
match	O
questions	O
with	O
answers	O
by	O
considering	O
their	O
semantic	B-Method
encoding	I-Method
.	O
	
They	O
combined	O
the	O
learning	O
results	O
of	O
their	O
model	O
with	O
word	O
overlap	O
features	O
by	O
training	O
a	O
logistic	B-Method
regression	I-Method
classifier	I-Method
.	O
	
Wang	O
and	O
Nyberg	O
proposed	O
a	O
method	O
which	O
uses	O
a	O
stacked	O
bidirectional	B-Method
Long	I-Method
-	I-Method
Short	I-Method
Term	I-Method
Memory	I-Method
(	O
BLSTM	B-Method
)	O
network	O
to	O
sequentially	O
read	O
words	O
from	O
question	O
and	O
answer	O
sentences	O
,	O
and	O
then	O
output	O
their	O
relevance	O
scores	O
.	O
	
Their	O
system	O
needs	O
to	O
combine	O
the	O
stacked	O
BLSTM	B-Method
relevance	O
model	O
with	O
a	O
BM25	O
score	O
to	O
achieve	O
good	O
performance	O
.	O
	
Severyn	O
and	O
Moschitti	O
presented	O
a	O
convolutional	B-Method
neural	I-Method
network	I-Method
architecture	I-Method
for	O
re	B-Task
-	I-Task
ranking	I-Task
pairs	I-Task
of	O
short	O
texts	O
,	O
where	O
they	O
learned	O
the	O
optimal	B-Method
representation	I-Method
of	O
text	O
pairs	O
and	O
a	O
similarity	O
function	O
to	O
relate	O
them	O
in	O
a	O
supervised	O
way	O
from	O
the	O
available	O
training	O
data	O
.	O
	
They	O
also	O
need	O
to	O
combine	O
additional	O
features	O
into	O
their	O
model	O
to	O
outperform	O
previous	O
methods	O
.	O
	
Unlike	O
the	O
previous	O
research	O
,	O
our	O
method	O
can	O
outperform	O
previous	O
methods	O
using	O
feature	B-Method
engineering	I-Method
without	O
combining	O
any	O
additional	O
features	O
.	O
	
With	O
an	O
additional	O
simple	O
feature	O
like	O
QL	B-Metric
,	O
our	O
model	O
is	O
significantly	O
better	O
than	O
the	O
previous	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
methods	O
including	O
deep	B-Method
learning	I-Method
methods	I-Method
.	O
	
Answer	B-Task
Ranking	I-Task
in	O
CQA	B-Task
.	O
	
There	O
is	O
also	O
previous	O
research	O
on	O
ranking	B-Task
answers	I-Task
from	O
community	B-Task
question	I-Task
answering	I-Task
(	O
CQA	B-Task
)	O
sites	O
.	O
	
Surdeanu	O
et	O
al	O
.	O
investigated	O
a	O
wide	O
range	O
of	O
feature	O
types	O
such	O
as	O
similarity	O
features	O
,	O
translation	O
features	O
,	O
density	B-Method
/	I-Method
frequency	I-Method
features	I-Method
for	O
ranking	B-Task
answers	I-Task
to	O
non	O
-	O
factoid	O
questions	O
in	O
Yahoo	O
!	O
	
Answers	O
.	O
	
Jansen	O
et	O
al	O
.	O
presented	O
an	O
answer	B-Method
re	I-Method
-	I-Method
ranking	I-Method
model	I-Method
for	O
non	B-Task
-	I-Task
factoid	I-Task
questions	I-Task
that	O
integrate	O
lexical	O
semantics	O
with	O
discourse	O
information	O
driven	O
by	O
two	O
representations	B-Method
of	I-Method
discourse	I-Method
.	O
	
Xue	O
et	O
al	O
.	O
proposed	O
a	O
retrieval	B-Method
model	I-Method
that	O
combines	O
a	O
translation	B-Method
-	I-Method
based	I-Method
language	I-Method
model	I-Method
for	O
the	O
question	O
part	O
with	O
a	O
query	B-Method
likelihood	I-Method
approach	I-Method
for	O
the	O
answer	O
part	O
.	O
	
Questions	O
from	O
CQA	B-Material
sites	I-Material
are	O
mostly	O
non	O
-	O
factoid	O
questions	O
.	O
	
Our	O
research	O
is	O
closer	O
to	O
factoid	O
questions	O
such	O
as	O
questions	O
in	O
TREC	B-Material
QA	O
data	O
.	O
	
Answer	B-Task
Passage	I-Task
/	I-Task
Sentence	I-Task
Retrieval	I-Task
.	O
	
Our	O
work	O
is	O
also	O
related	O
to	O
previous	O
research	O
on	O
answer	B-Task
passage	I-Task
/	I-Task
sentence	I-Task
retrieval	I-Task
.	O
	
Tymoshenko	O
and	O
Moschitti	O
studied	O
the	O
use	O
of	O
syntactic	O
and	O
semantic	O
structures	O
obtained	O
with	O
shallow	B-Method
and	I-Method
deeper	I-Method
syntactic	I-Method
parsers	I-Method
in	O
the	O
answer	B-Task
passage	I-Task
re	I-Task
-	I-Task
ranking	I-Task
task	I-Task
.	O
	
Keikha	O
et	O
al	O
.	O
developed	O
an	O
annotated	O
data	O
set	O
for	O
non	B-Task
-	I-Task
factoid	I-Task
answer	I-Task
finding	I-Task
using	O
TREC	B-Material
GOV2	O
collections	O
and	O
topics	O
.	O
	
They	O
annotated	O
passage	O
-	O
level	O
answers	O
,	O
revisited	O
several	O
passage	B-Method
retrieval	I-Method
models	I-Method
with	O
this	O
data	O
,	O
and	O
came	O
to	O
the	O
conclusion	O
that	O
the	O
current	O
methods	O
are	O
not	O
effective	O
for	O
this	O
task	O
.	O
	
Yang	O
et	O
al	O
.	O
developed	O
effective	O
methods	O
for	O
answer	B-Task
sentence	I-Task
retrieval	I-Task
using	O
this	O
annotated	O
data	O
by	O
combining	O
semantic	O
features	O
,	O
context	O
features	O
and	O
basic	B-Method
text	I-Method
matching	I-Method
features	I-Method
with	O
a	O
learning	B-Method
to	I-Method
rank	I-Method
approach	I-Method
.	O
	
Our	O
model	O
is	O
built	O
on	O
attention	B-Method
-	I-Method
based	I-Method
neural	I-Method
matching	I-Method
model	I-Method
with	O
value	B-Method
-	I-Method
shared	I-Method
weighting	I-Method
schema	I-Method
.	O
	
Unlike	O
learning	B-Method
to	O
rank	B-Method
approaches	I-Method
with	O
feature	B-Method
engineering	I-Method
,	O
our	O
model	O
can	O
achieve	O
good	O
performance	O
for	O
ranking	B-Task
answers	I-Task
without	O
any	O
additional	O
manual	B-Method
feature	I-Method
engineering	I-Method
,	O
preprocessing	O
of	O
NLP	B-Method
parsers	I-Method
and	O
external	O
resources	O
like	O
knowledge	O
bases	O
.	O
	
section	O
:	O
Attention	B-Method
-	I-Method
based	I-Method
Neural	I-Method
Matching	I-Method
Model	I-Method
	
In	O
this	O
section	O
we	O
present	O
the	O
proposed	O
model	O
referred	O
as	O
aNMM	B-Method
(	O
attention	B-Method
-	I-Method
based	I-Method
Neural	I-Method
Matching	I-Method
Model	I-Method
)	O
,	O
which	O
is	O
shown	O
in	O
Figure	O
[	O
reference	O
]	O
.	O
	
Before	O
we	O
introduce	O
our	O
model	O
,	O
we	O
firstly	O
define	O
some	O
terminologies	O
.	O
	
subsection	O
:	O
Terminology	O
	
Short	O
Answer	O
Text	O
:	O
We	O
use	O
Short	O
Answer	O
Text	O
to	O
refer	O
to	O
a	O
short	O
fact	O
,	O
answer	O
sentences	O
or	O
answer	O
passages	O
that	O
can	O
address	O
users	O
’	O
information	O
needs	O
in	O
the	O
issued	O
questions	O
.	O
	
This	O
is	O
the	O
ranking	O
object	O
in	O
this	O
paper	O
and	O
includes	O
answers	O
in	O
various	O
lengths	O
.	O
	
In	O
the	O
experiments	O
of	O
this	O
paper	O
,	O
we	O
mainly	O
focus	O
on	O
ranking	B-Task
answer	I-Task
sentences	I-Task
that	O
contain	O
correct	O
answer	O
facts	O
as	O
in	O
TREC	B-Material
QA	O
data	O
.	O
	
QA	B-Method
Matching	I-Method
Matrix	I-Method
:	O
We	O
use	O
QA	B-Method
Matching	I-Method
Matrix	I-Method
to	O
refer	O
to	O
a	O
matrix	O
which	O
represents	O
the	O
semantic	O
matching	O
information	O
of	O
term	O
pairs	O
from	O
a	O
question	O
and	O
answer	O
pair	O
.	O
	
Given	O
a	O
question	O
with	O
length	O
and	O
an	O
answer	O
with	O
length	O
,	O
a	O
QA	B-Method
matching	I-Method
matrix	I-Method
is	O
an	O
by	B-Method
matrix	I-Method
,	O
where	O
denote	O
the	O
semantic	O
similarity	O
between	O
term	O
and	O
term	O
measured	O
by	O
the	O
cosine	O
similarity	O
of	O
the	O
corresponding	O
word	O
embeddings	O
of	O
terms	O
.	O
	
If	O
and	O
are	O
the	O
same	O
term	O
,	O
we	O
assign	O
as	O
.	O
	
QA	O
Matching	O
Vector	O
:	O
	
We	O
use	O
QA	O
Matching	O
Vector	O
to	O
refer	O
to	O
a	O
row	O
in	O
the	O
QA	O
matching	O
matrix	O
.	O
	
As	O
presented	O
before	O
,	O
the	O
-	O
th	O
row	O
of	O
the	O
QA	O
matching	O
matrix	O
contains	O
the	O
semantic	O
similarity	O
between	O
and	O
all	O
terms	O
in	O
answer	O
.	O
	
subsection	O
:	O
Model	O
Overview	O
	
Our	O
method	O
contains	O
three	O
steps	O
as	O
follows	O
:	O
We	O
construct	O
QA	O
matching	O
matrix	O
for	O
each	O
question	O
and	O
answer	O
pair	O
with	O
pre	O
-	O
trained	O
word	B-Method
embeddings	I-Method
.	O
	
We	O
then	O
employ	O
a	O
deep	B-Method
neural	I-Method
network	I-Method
with	O
value	B-Method
-	I-Method
shared	I-Method
weighting	I-Method
scheme	I-Method
in	O
the	O
first	O
layer	O
,	O
and	O
fully	B-Method
connected	I-Method
layers	I-Method
in	O
the	O
rest	O
to	O
learn	O
hierarchical	B-Task
abstraction	I-Task
of	I-Task
the	I-Task
semantic	I-Task
matching	I-Task
between	O
question	O
and	O
answer	O
terms	O
.	O
	
Finally	O
,	O
we	O
employ	O
a	O
question	B-Task
attention	I-Task
network	O
to	O
learn	O
question	O
term	O
importance	O
and	O
produce	O
the	O
final	O
ranking	B-Metric
score	I-Metric
.	O
	
We	O
propose	O
two	O
neural	B-Method
matching	I-Method
model	I-Method
architectures	I-Method
and	O
compare	O
the	O
effectivenesses	O
of	O
them	O
.	O
	
We	O
firstly	O
describe	O
a	O
basic	O
version	O
of	O
the	O
architecture	O
,	O
which	O
is	O
referred	O
to	O
as	O
aNMM	B-Method
-	I-Method
1	I-Method
.	O
	
In	O
the	O
following	O
sections	O
,	O
we	O
will	O
explain	O
in	O
detail	O
the	O
two	O
major	O
designs	O
of	O
aNMM	B-Method
-	I-Method
1	I-Method
,	O
i.e.	O
,	O
value	B-Method
-	I-Method
shared	I-Method
weights	I-Method
and	O
question	B-Task
attention	I-Task
network	O
.	O
	
subsection	O
:	O
Value	B-Method
-	I-Method
shared	I-Method
Weighting	I-Method
	
We	O
first	O
train	O
word	B-Method
embeddings	I-Method
with	O
the	O
Word2Vec	B-Method
tool	I-Method
by	O
Mikolov	O
et	O
al	O
.	O
with	O
the	O
English	B-Material
Wikipedia	I-Material
dump	I-Material
to	O
construct	O
QA	O
matching	O
matrices	O
.	O
	
Given	O
a	O
question	O
sentence	O
and	O
an	O
answer	O
sentence	O
,	O
we	O
compute	O
the	O
dot	O
product	O
of	O
the	O
normalized	O
word	O
embeddings	O
of	O
all	O
term	O
pairs	O
to	O
construct	O
the	O
QA	O
matching	O
matrix	O
as	O
defined	O
in	O
Section	O
[	O
reference	O
]	O
.	O
	
A	O
major	O
problem	O
with	O
the	O
QA	B-Method
matching	I-Method
matrix	I-Method
is	O
the	O
variable	O
size	O
due	O
to	O
the	O
different	O
lengths	O
of	O
answers	O
for	O
a	O
given	O
question	O
.	O
	
To	O
solve	O
this	O
problem	O
,	O
one	O
can	O
use	O
CNN	B-Method
with	I-Method
pooling	I-Method
strategy	I-Method
to	O
handle	O
the	O
variable	O
size	O
.	O
	
However	O
,	O
as	O
we	O
have	O
mentioned	O
before	O
,	O
CNNs	B-Method
basically	O
use	O
position	B-Method
-	I-Method
shared	I-Method
weighting	I-Method
scheme	I-Method
which	O
may	O
not	O
fit	O
semantic	O
matching	O
between	O
questions	O
and	O
answers	O
.	O
	
Important	O
question	O
terms	O
and	O
semantically	O
similar	O
answer	O
words	O
could	O
appear	O
anywhere	O
in	O
questions	O
/	O
answers	O
due	O
to	O
the	O
complex	O
linguistic	O
property	O
of	O
natural	O
languages	O
.	O
	
Thus	O
we	O
adopt	O
the	O
following	O
method	O
to	O
handle	O
the	O
various	B-Task
length	I-Task
problem	I-Task
:	O
	
Value	O
-	O
shared	O
Weights	O
:	O
For	O
this	O
method	O
,	O
the	O
assumption	O
is	O
that	O
matching	O
signals	O
in	O
different	O
ranges	O
play	O
different	O
roles	O
in	O
deciding	O
the	O
final	O
ranking	B-Metric
score	I-Metric
.	O
	
Thus	O
we	O
introduce	O
the	O
value	B-Method
-	I-Method
shared	I-Method
weighting	I-Method
scheme	I-Method
to	O
learn	O
the	O
importance	O
of	O
different	O
levels	O
of	O
matching	O
signals	O
.	O
	
The	O
comparison	O
between	O
the	O
position	O
-	O
shared	O
weight	O
and	O
value	O
-	O
shared	O
weight	O
is	O
shown	O
in	O
Figure	O
[	O
reference	O
]	O
.	O
	
We	O
can	O
see	O
that	O
for	O
position	O
-	O
shared	O
weights	O
,	O
the	O
weight	O
associated	O
with	O
a	O
node	O
only	O
depends	O
on	O
its	O
position	O
or	O
relative	O
location	O
as	O
specified	O
by	O
the	O
filters	B-Method
in	O
CNN	B-Method
.	O
	
However	O
in	O
our	O
model	O
,	O
the	O
weight	O
associated	O
with	O
a	O
node	O
depends	O
on	O
its	O
value	O
.	O
	
The	O
value	O
of	O
a	O
node	O
denotes	O
the	O
strength	O
of	O
the	O
matching	O
signal	O
between	O
term	O
pairs	O
of	O
questions	O
and	O
answers	O
from	O
the	O
QA	O
matching	O
matrix	O
,	O
as	O
explained	O
in	O
Section	O
[	O
reference	O
]	O
.	O
	
Such	O
a	O
setting	O
enables	O
us	O
to	O
use	O
the	O
learned	O
weights	O
to	O
encode	O
how	O
to	O
combine	O
different	O
levels	O
of	O
matching	O
signals	O
.	O
	
After	O
this	O
step	O
,	O
the	O
size	O
of	O
the	O
hidden	B-Method
representation	I-Method
becomes	O
fixed	O
and	O
we	O
can	O
use	O
normal	O
fully	B-Method
connected	I-Method
layers	I-Method
to	O
learn	O
higher	B-Method
level	I-Method
representations	I-Method
.	O
	
We	O
use	O
the	O
term	O
bin	O
to	O
denote	O
a	O
specific	O
range	O
of	O
matching	O
signals	O
.	O
	
since	O
,	O
if	O
we	O
set	O
the	O
size	O
of	O
bins	O
as	O
,	O
then	O
we	O
have	O
bins	O
where	O
there	O
is	O
a	O
separate	O
bin	O
for	O
to	O
denote	O
exact	O
match	O
of	O
terms	O
.	O
	
Specifically	O
,	O
value	O
-	O
shared	O
weights	O
are	O
adopted	O
in	O
the	O
forward	B-Method
propagation	I-Method
prediction	I-Method
process	I-Method
from	O
the	O
input	O
layer	O
to	O
the	O
hidden	O
layer	O
over	O
each	O
question	O
term	O
in	O
aNMM	B-Method
-	I-Method
1	I-Method
as	O
follows	O
:	O
Input	O
Layer	O
to	O
Hidden	B-Method
Layer	I-Method
.	O
	
Let	O
denote	O
a	O
dimensional	O
model	O
parameter	O
from	O
input	O
layer	O
to	O
hidden	O
layer	O
.	O
	
denotes	O
the	O
sum	O
of	O
all	O
matching	O
signals	O
within	O
the	O
-	O
th	O
value	O
range	O
or	O
bin	O
.	O
	
For	O
each	O
QA	O
matching	O
vector	O
of	O
a	O
given	O
query	O
,	O
the	O
combined	O
score	O
after	O
the	O
activation	O
function	O
of	O
the	O
-	O
th	O
node	O
in	O
hidden	O
layer	O
is	O
defined	O
as	O
where	O
is	O
the	O
index	O
of	O
question	O
words	O
in	O
.	O
	
We	O
use	O
the	O
sigmoid	O
function	O
as	O
the	O
activation	O
function	O
,	O
which	O
is	O
commonly	O
adopted	O
in	O
many	O
neural	B-Method
network	I-Method
architectures	I-Method
.	O
	
subsection	O
:	O
Question	B-Method
Attention	I-Method
Network	I-Method
	
In	O
addition	O
to	O
value	B-Method
-	I-Method
shared	I-Method
weighting	I-Method
,	O
another	O
model	B-Method
component	I-Method
of	O
aNMM	B-Method
-	I-Method
1	I-Method
is	O
the	O
question	B-Task
attention	I-Task
network	O
.	O
	
In	O
a	O
committee	B-Method
of	I-Method
neural	I-Method
networks	I-Method
which	O
consists	O
of	O
multiple	O
networks	O
,	O
we	O
need	O
to	O
combine	O
the	O
output	O
of	O
these	O
networks	O
to	O
output	O
a	O
final	O
decision	O
vector	O
.	O
	
The	O
question	B-Task
attention	I-Task
network	O
uses	O
the	O
gating	O
function	O
to	O
control	O
the	O
output	O
of	O
each	O
network	O
in	O
this	O
process	O
.	O
	
Specifically	O
,	O
in	O
aNMM	B-Method
-	I-Method
1	I-Method
we	O
use	O
the	O
softmax	O
gate	O
function	O
to	O
combine	O
the	O
output	O
of	O
multiple	O
networks	O
where	O
each	O
network	O
corresponds	O
to	O
a	O
question	O
term	O
as	O
shown	O
in	O
Figure	O
[	O
reference	O
]	O
.	O
	
We	O
feed	O
the	O
dot	O
product	O
of	O
query	O
word	O
embedding	O
and	O
model	O
parameter	O
to	O
the	O
softmax	O
function	O
to	O
represent	O
the	O
query	O
term	O
importance	O
.	O
	
In	O
this	O
setting	O
,	O
we	O
can	O
directly	O
compare	O
the	O
relative	O
term	O
importance	O
of	O
query	O
words	O
within	O
the	O
same	O
query	O
with	O
softmax	O
function	O
.	O
	
We	O
also	O
tried	O
sigmoid	O
gate	O
function	O
,	O
but	O
this	O
did	O
not	O
perform	O
as	O
well	O
as	O
softmax	O
gate	O
function	O
.	O
	
Softmax	O
gate	O
function	O
is	O
used	O
in	O
the	O
forward	B-Method
propagation	I-Method
process	I-Method
from	O
the	O
hidden	O
layer	O
to	O
the	O
output	O
layer	O
as	O
follows	O
:	O
Hidden	O
Layer	O
to	O
Output	O
Layer	O
.	O
	
From	O
the	O
hidden	O
layer	O
to	O
the	O
output	O
layer	O
,	O
we	O
add	O
a	O
softmax	O
gate	O
function	O
to	O
learn	O
question	B-Task
attention	I-Task
.	O
	
Let	O
denote	O
a	O
dimensional	O
vector	O
which	O
is	O
a	O
model	O
parameter	O
.	O
	
We	O
feed	O
the	O
dot	B-Method
product	I-Method
of	I-Method
query	I-Method
word	I-Method
embedding	I-Method
and	O
to	O
the	O
softmax	O
function	O
to	O
represent	O
the	O
query	O
term	O
importance	O
as	O
shown	O
in	O
Equation	O
[	O
reference	O
]	O
.	O
	
Note	O
that	O
we	O
normalize	O
the	O
query	O
word	O
embedding	O
before	O
computing	O
the	O
dot	O
product	O
.	O
	
Unlike	O
previous	O
models	O
like	O
CNNs	B-Method
and	O
BLSTM	B-Method
,	O
which	O
learn	O
the	O
semantic	O
match	O
score	O
between	O
questions	O
and	O
answers	O
through	O
representation	B-Method
learning	I-Method
from	O
matching	O
matrix	O
or	O
question	O
/	O
answer	O
pair	O
sequences	O
,	O
aNMM	B-Method
achieves	O
this	O
by	O
combining	O
semantic	O
matching	O
signals	O
of	O
term	O
pairs	O
in	O
questions	O
and	O
answers	O
weighted	O
by	O
the	O
output	O
of	O
question	B-Task
attention	I-Task
network	O
,	O
where	O
softmax	O
gate	O
functions	O
help	O
discriminate	O
the	O
term	O
importance	O
or	O
attention	O
on	O
different	O
question	O
terms	O
.	O
	
subsection	O
:	O
Model	B-Method
Training	I-Method
	
For	O
aNMM	B-Method
-	I-Method
1	I-Method
,	O
the	O
model	O
parameters	O
contain	O
two	O
sets	O
:	O
1	O
)	O
The	O
value	O
-	O
shared	O
weights	O
for	O
combining	O
matching	O
signals	O
from	O
the	O
input	O
layer	O
to	O
the	O
hidden	O
layer	O
.	O
	
2	O
)	O
	
The	O
parameters	O
in	O
the	O
gating	O
function	O
from	O
the	O
hidden	O
layer	O
to	O
the	O
output	O
layer	O
.	O
	
To	O
learn	O
the	O
model	O
parameters	O
from	O
the	O
training	O
data	O
,	O
we	O
adopt	O
a	O
pair	B-Method
-	I-Method
wise	I-Method
learning	I-Method
strategy	I-Method
with	O
a	O
large	O
margin	O
objective	O
.	O
	
Firstly	O
we	O
construct	O
triples	O
from	O
the	O
training	O
data	O
,	O
with	O
matched	O
with	O
better	O
than	O
with	O
.	O
	
We	O
have	O
the	O
ranking	B-Metric
-	I-Metric
based	I-Metric
loss	I-Metric
as	O
the	O
objective	B-Metric
function	I-Metric
as	O
following	O
:	O
where	O
denote	O
the	O
predicted	B-Metric
matching	I-Metric
score	I-Metric
for	O
QA	O
pair	O
.	O
	
During	O
training	O
stage	O
,	O
we	O
will	O
scan	O
all	O
the	O
triples	O
in	O
training	O
data	O
.	O
	
Given	O
a	O
triple	O
,	O
we	O
will	O
compute	O
.	O
	
If	O
,	O
we	O
will	O
skip	O
this	O
triple	O
.	O
	
Otherwise	O
,	O
we	O
need	O
to	O
update	O
model	B-Method
parameters	I-Method
with	O
back	B-Method
propagation	I-Method
algorithm	I-Method
to	O
minimize	O
the	O
objective	B-Metric
function	I-Metric
.	O
	
Under	O
softmax	O
gate	O
function	O
setting	O
,	O
the	O
gradients	O
of	O
w.r.t	O
.	O
from	O
hidden	O
layer	O
to	O
the	O
output	O
layer	O
is	O
shown	O
in	O
Equation	O
[	O
reference	O
]	O
where	O
can	O
be	O
derived	O
as	O
The	O
gradient	O
of	O
w.r.t	O
.	O
from	O
input	O
layer	O
to	O
hidden	O
layer	O
is	O
shown	O
in	O
Equation	O
[	O
reference	O
]	O
.	O
	
With	O
the	O
formulas	O
of	O
gradients	O
,	O
we	O
can	O
perform	O
stochastic	B-Method
gradient	I-Method
descent	I-Method
to	O
learn	O
model	O
parameters	O
.	O
	
We	O
use	O
mini	B-Method
-	I-Method
batch	I-Method
gradient	I-Method
descent	I-Method
to	O
achieve	O
more	O
robust	O
performance	O
on	O
the	O
ranking	B-Task
task	I-Task
.	O
	
For	O
the	O
learning	B-Metric
rate	I-Metric
,	O
we	O
adopt	O
adaptive	B-Metric
learning	I-Metric
rate	I-Metric
:	O
,	O
where	O
will	O
approach	O
with	O
more	O
iterations	O
.	O
	
Such	O
a	O
setting	O
has	O
better	O
guarantee	O
for	O
convergence	B-Metric
.	O
	
subsection	O
:	O
Extension	O
to	O
Deep	B-Method
Neural	I-Method
Networks	I-Method
with	O
Multiple	O
Sets	O
of	O
Value	O
-	O
shared	O
Weights	O
	
In	O
aNMM	B-Method
-	I-Method
1	I-Method
,	O
we	O
can	O
only	O
use	O
one	O
set	O
of	O
value	O
-	O
shared	O
weights	O
for	O
each	O
QA	O
matching	O
vector	O
.	O
	
We	O
further	O
propose	O
a	O
more	O
flexible	O
neural	B-Method
network	I-Method
architecture	I-Method
which	O
could	O
enable	O
us	O
to	O
use	O
multiple	O
sets	O
of	O
value	O
-	O
shared	O
weights	O
for	O
each	O
QA	O
matching	O
vector	O
,	O
leading	O
to	O
multiple	O
intermediate	O
nodes	O
in	O
the	O
first	O
hidden	O
layer	O
,	O
as	O
shown	O
in	O
Figure	O
[	O
reference	O
]	O
by	O
the	O
yellow	O
color	O
.	O
	
We	O
refer	O
to	O
this	O
extended	O
model	O
as	O
aNMM	B-Method
-	I-Method
2	I-Method
.	O
	
The	O
model	O
architecture	O
shown	O
in	O
Figure	O
[	O
reference	O
]	O
is	O
corresponding	O
to	O
aNMM	B-Method
-	I-Method
2	I-Method
.	O
	
subsubsection	O
:	O
Forward	B-Method
Propagation	I-Method
Prediction	I-Method
	
For	O
aNMM	B-Method
-	I-Method
2	I-Method
,	O
we	O
add	O
a	O
hidden	O
layer	O
in	O
the	O
neural	B-Method
network	I-Method
where	O
we	O
learn	O
multiple	O
combined	O
scores	O
from	O
the	O
input	O
layer	O
.	O
	
With	O
this	O
hidden	B-Method
layer	I-Method
,	O
we	O
define	O
multiple	O
weight	O
vectors	O
as	O
.	O
	
Thus	O
becomes	O
a	O
two	O
dimensional	O
matrix	O
.	O
	
The	O
formula	O
for	O
the	O
forward	B-Task
propagation	I-Task
prediction	I-Task
is	O
as	O
follows	O
:	O
where	O
and	O
denote	O
the	O
softmax	O
gate	O
function	O
.	O
	
is	O
the	O
number	O
of	O
nodes	O
in	O
hidden	O
layer	O
1	O
.	O
	
is	O
the	O
model	O
parameter	O
from	O
hidden	O
layer	O
1	O
to	O
hidden	O
layer	O
2	O
,	O
where	O
we	O
feed	O
the	O
linear	O
combination	O
of	O
outputs	O
of	O
nodes	O
in	O
hidden	O
layer	O
1	O
to	O
an	O
extra	O
activation	O
function	O
comparing	O
with	O
Equation	O
[	O
reference	O
]	O
.	O
	
Then	O
from	O
hidden	O
layer	O
2	O
to	O
output	O
layer	O
,	O
we	O
sum	O
over	O
all	O
outputs	O
of	O
nodes	O
in	O
hidden	O
layer	O
2	O
weighted	O
by	O
the	O
outputs	O
of	O
softmax	O
gate	O
functions	O
,	O
which	O
also	O
form	O
the	O
question	B-Task
attention	I-Task
network	O
.	O
	
subsubsection	O
:	O
Back	B-Method
Propagation	I-Method
for	O
Model	B-Task
Training	I-Task
	
For	O
aNMM	B-Method
-	I-Method
2	I-Method
,	O
we	O
have	O
three	O
sets	O
of	O
model	O
parameters	O
:	O
1	O
)	O
from	O
input	O
layer	O
to	O
hidden	O
layer	O
1	O
;	O
2	O
)	O
from	O
hidden	O
layer	O
1	O
to	O
hidden	O
layer	O
2	O
;	O
3	O
)	O
from	O
hidden	O
layer	O
2	O
to	O
output	O
layer	O
.	O
	
All	O
three	O
sets	O
of	O
parameters	O
are	O
updated	O
through	O
back	B-Method
propagation	I-Method
.	O
	
The	O
definition	O
of	O
the	O
objective	O
function	O
is	O
the	O
same	O
as	O
Equation	O
[	O
reference	O
]	O
.	O
	
The	O
back	B-Method
propagation	I-Method
process	I-Method
for	O
model	B-Task
parameter	I-Task
learning	I-Task
is	O
described	O
as	O
follows	O
:	O
	
From	O
hidden	O
layer	O
2	O
to	O
output	O
layer	O
.	O
	
The	O
gradients	O
of	O
the	O
objective	O
function	O
w.r.t	O
.	O
is	O
as	O
following	O
:	O
	
Where	O
From	O
hidden	O
layer	O
1	O
to	O
hidden	O
layer	O
2	O
.	O
	
The	O
gradients	O
of	O
the	O
objective	O
function	O
w.r.t	O
.	O
is	O
as	O
following	O
:	O
Where	O
.	O
	
From	O
input	O
layer	O
to	O
hidden	O
layer	O
1	O
.	O
	
The	O
gradients	O
of	O
the	O
objective	O
function	O
w.r.t	O
.	O
is	O
as	O
following	O
:	O
Where	O
Initially	O
we	O
will	O
randomly	O
give	O
the	O
values	O
of	O
model	O
parameters	O
.	O
	
Then	O
we	O
will	O
use	O
back	B-Method
propagation	I-Method
to	O
update	O
the	O
model	O
parameters	O
.	O
	
When	O
the	O
learning	O
process	O
converge	O
,	O
we	O
use	O
the	O
learned	O
model	O
parameters	O
for	O
prediction	B-Task
to	O
rank	O
short	O
answer	O
texts	O
.	O
	
section	O
:	O
Experiments	O
	
subsection	O
:	O
Data	O
Set	O
and	O
Experiment	O
Settings	O
	
We	O
use	O
the	O
TREC	B-Material
QA	O
data	O
set	O
created	O
by	O
Wang	O
et	O
.	O
	
al	O
.	O
	
from	O
TREC	B-Material
QA	O
track	O
8	O
-	O
13	O
data	O
,	O
with	O
candidate	O
answers	O
automatically	O
selected	O
from	O
each	O
question	O
	
’s	O
document	O
pool	O
using	O
a	O
combination	O
of	O
overlapping	O
non	O
-	O
stop	O
word	O
counts	O
and	O
pattern	B-Method
matching	I-Method
.	O
	
This	O
data	O
set	O
is	O
one	O
of	O
the	O
most	O
widely	O
used	O
benchmarks	O
for	O
answer	B-Task
re	I-Task
-	I-Task
ranking	I-Task
.	O
	
Table	O
[	O
reference	O
]	O
shows	O
the	O
statistics	O
of	O
this	O
data	O
set	O
.	O
	
The	O
dataset	O
contains	O
a	O
set	O
of	O
factoid	O
questions	O
with	O
candidate	O
answers	O
which	O
are	O
limited	O
to	O
a	O
single	O
sentence	O
.	O
	
There	O
are	O
two	O
training	O
data	O
sets	O
:	O
TRAIN	B-Material
and	O
TRAIN	B-Material
-	O
ALL	O
.	O
	
Answers	O
in	O
TRAIN	B-Material
have	O
manual	O
judgments	O
for	O
the	O
answer	B-Metric
correctness	I-Metric
.	O
	
The	O
manual	O
judgment	O
of	O
candidate	O
answer	O
sentences	O
is	O
provided	O
for	O
the	O
entire	O
TREC	B-Material
13	I-Material
set	I-Material
and	O
for	O
a	O
part	O
of	O
questions	O
from	O
TREC	B-Material
8	O
-	O
12	O
.	O
	
TRAIN	B-Material
-	I-Material
ALL	I-Material
is	O
another	O
training	O
set	O
with	O
much	O
larger	O
number	O
of	O
questions	O
.	O
	
The	O
correctness	O
of	O
candidate	O
answer	O
sentences	O
in	O
TRAIN	B-Material
-	O
ALL	O
is	O
identified	O
by	O
matching	O
answer	O
sentences	O
with	O
answer	O
pattern	O
regular	O
expressions	O
provided	O
by	O
TREC	B-Material
.	O
	
This	O
data	O
set	O
is	O
more	O
noisy	O
,	O
however	O
it	O
provides	O
many	O
more	O
QA	O
pairs	O
for	O
model	B-Task
training	I-Task
.	O
	
There	O
is	O
a	O
DEV	O
set	O
for	O
hyper	B-Method
-	I-Method
parameter	I-Method
optimization	I-Method
and	O
TEST	O
set	O
for	O
model	B-Task
testing	I-Task
.	O
	
We	O
use	O
the	O
same	O
train	O
/	O
dev	O
/	O
test	O
partition	O
in	O
our	O
experiments	O
to	O
directly	O
compare	O
our	O
results	O
with	O
previous	O
works	O
.	O
	
For	O
data	B-Task
preprocess	I-Task
,	O
we	O
perform	O
tokenization	B-Method
without	I-Method
stemming	I-Method
.	O
	
We	O
maintain	O
stop	O
words	O
during	O
the	O
model	O
training	O
stage	O
.	O
	
Word	B-Task
Embeddings	I-Task
.	O
	
We	O
obtain	O
pre	O
-	O
trained	O
word	O
embeddings	O
with	O
the	O
Word2Vec	B-Method
tool	I-Method
by	O
Mikolov	O
et	O
al	O
.	O
	
with	O
the	O
English	B-Material
Wikipedia	I-Material
dump	I-Material
.	O
	
We	O
use	O
the	O
skip	B-Method
-	I-Method
gram	I-Method
model	I-Method
with	O
window	O
size	O
and	O
filter	O
words	O
with	O
frequency	O
less	O
than	O
following	O
the	O
common	O
practice	O
in	O
many	O
neural	B-Method
embedding	I-Method
models	I-Method
.	O
	
For	O
the	O
word	O
vector	O
dimension	O
,	O
we	O
tune	O
it	O
as	O
a	O
hyper	O
-	O
parameter	O
on	O
the	O
validation	O
data	O
starting	O
from	O
to	O
.	O
	
Embeddings	O
for	O
words	O
not	O
present	O
are	O
randomly	O
initialized	O
with	O
sampled	O
numbers	O
from	O
uniform	O
distribution	O
U	O
[-	O
0.25	O
,	O
0.25	O
]	O
,	O
which	O
follows	O
the	O
same	O
setting	O
as	O
.	O
	
Model	O
Hyper	O
-	O
parameters	O
.	O
	
For	O
the	O
setting	O
of	O
hyper	O
-	O
parameters	O
,	O
we	O
set	O
the	O
number	O
of	O
bins	O
as	O
,	O
word	O
embedding	O
dimension	O
as	O
for	O
aNNM	B-Method
-	I-Method
1	I-Method
,	O
the	O
number	O
of	O
bins	O
as	O
,	O
word	O
embedding	O
dimension	O
as	O
for	O
aNNM	B-Method
-	I-Method
2	I-Method
after	O
we	O
tune	O
hyper	O
-	O
parameters	O
on	O
the	O
provided	O
DEV	O
set	O
of	O
TREC	B-Material
QA	O
data	O
.	O
	
subsection	O
:	O
Evaluation	B-Metric
and	O
Metrics	B-Metric
	
For	O
evaluation	O
,	O
we	O
rank	O
answer	O
sentences	O
with	O
the	O
predicted	O
score	O
of	O
each	O
method	O
and	O
compare	O
the	O
rank	O
list	O
with	O
the	O
ground	O
truth	O
to	O
compute	O
metrics	B-Metric
.	O
	
We	O
choose	O
Mean	B-Metric
Average	I-Metric
Precision	I-Metric
(	O
MAP	B-Metric
)	O
and	O
Mean	B-Metric
Reciprocal	I-Metric
Rank	I-Metric
(	O
MRR	B-Metric
)	O
,	O
which	O
are	O
commonly	O
used	O
in	O
information	B-Task
retrieval	I-Task
and	O
question	B-Task
answering	I-Task
,	O
as	O
the	O
metric	O
to	O
evaluate	O
our	O
model	O
.	O
	
The	O
definition	O
of	O
MRR	B-Metric
is	O
as	O
follows	O
:	O
where	O
is	O
the	O
position	O
of	O
the	O
first	O
correct	O
answer	O
in	O
the	O
rank	O
list	O
.	O
	
Thus	O
MRR	B-Metric
is	O
only	O
based	O
on	O
the	O
rank	O
of	O
the	O
first	O
correct	O
answer	O
.	O
	
It	O
is	O
more	O
suitable	O
for	O
the	O
cases	O
where	O
the	O
rank	O
of	O
the	O
first	O
correct	O
answer	O
is	O
emphasized	O
or	O
	
each	O
question	O
only	O
have	O
one	O
correct	O
answer	O
.	O
	
On	O
the	O
other	O
hand	O
,	O
MAP	B-Metric
looks	O
at	O
the	O
ranks	O
of	O
all	O
correct	O
answers	O
.	O
	
It	O
is	O
computed	O
as	O
following	O
:	O
where	O
is	O
the	O
average	B-Metric
precision	I-Metric
for	O
each	O
query	O
.	O
	
Thus	O
MAP	B-Metric
is	O
the	O
average	O
performance	O
on	O
all	O
correct	O
answers	O
.	O
	
We	O
use	O
the	O
official	O
scripts	O
for	O
computing	O
these	O
metrics	B-Metric
.	O
	
subsection	O
:	O
Model	B-Method
Learning	I-Method
Results	O
	
In	O
this	O
section	O
,	O
we	O
give	O
some	O
qualitative	B-Task
analysis	I-Task
and	O
visualization	B-Task
of	O
our	O
model	B-Task
learning	I-Task
results	O
.	O
	
Specifically	O
,	O
we	O
analyze	O
the	O
learned	O
value	O
-	O
shard	O
weights	O
and	O
question	O
term	O
importance	O
by	O
aNMM	B-Method
.	O
	
subsubsection	O
:	O
Value	O
-	O
shared	O
Weight	O
	
We	O
take	O
the	O
learned	O
value	O
-	O
shared	O
weights	O
of	O
aNMM	B-Method
-	I-Method
1	I-Method
as	O
the	O
example	O
.	O
	
Figure	O
[	O
reference	O
]	O
shows	O
the	O
learned	O
value	O
-	O
shared	O
weights	O
by	O
aNMM	B-Method
-	I-Method
1	I-Method
.	O
	
In	O
aNMM	B-Method
-	I-Method
1	I-Method
,	O
for	O
each	O
QA	O
matching	O
vector	O
,	O
there	O
is	O
only	O
one	O
bin	O
node	O
.	O
	
Thus	O
the	O
learned	O
value	O
-	O
shared	O
weights	O
for	O
aNMM	B-Method
-	I-Method
1	I-Method
is	O
a	O
one	O
dimension	O
vector	O
.	O
	
For	O
aNMM	B-Method
-	I-Method
1	I-Method
,	O
we	O
set	O
the	O
number	O
of	O
bins	O
as	O
as	O
presented	O
in	O
Section	O
[	O
reference	O
]	O
.	O
	
Note	O
that	O
the	O
x	O
-	O
axis	O
is	O
the	O
index	O
of	O
bin	O
range	O
and	O
the	O
y	O
-	O
axis	O
is	O
the	O
value	O
-	O
shared	O
weights	O
corresponding	O
to	O
each	O
bin	O
range	O
.	O
	
The	O
range	O
of	O
match	O
signals	O
is	O
[	O
-	O
1	O
,	O
1	O
]	O
from	O
the	O
left	O
to	O
the	O
right	O
.	O
	
We	O
make	O
the	O
following	O
observations	O
:	O
(	O
1	O
)	O
The	O
exact	O
match	O
signal	O
which	O
is	O
corresponding	O
to	O
in	O
the	O
last	O
bin	O
is	O
tied	O
with	O
a	O
very	O
large	O
weight	O
,	O
which	O
shows	O
that	O
exact	O
match	O
information	O
is	O
very	O
important	O
.	O
	
(	O
2	O
)	O
	
For	O
positive	O
matching	O
score	O
from	O
,	O
which	O
is	O
corresponding	O
to	O
bin	O
index	O
,	O
the	O
learned	O
value	O
-	O
shared	O
weights	O
are	O
different	O
for	O
matching	B-Metric
score	I-Metric
range	I-Metric
(	O
bin	O
index	O
)	O
and	O
matching	B-Metric
score	I-Metric
range	I-Metric
(	O
bin	O
index	O
)	O
.	O
	
We	O
can	O
observe	O
many	O
positive	O
value	O
-	O
shared	O
weights	O
for	O
matching	B-Metric
score	I-Metric
range	I-Metric
and	O
negative	O
value	O
-	O
shared	O
weights	O
for	O
matching	B-Metric
score	I-Metric
range	I-Metric
.	O
	
This	O
makes	O
sense	O
since	O
high	O
semantic	B-Metric
matching	I-Metric
scores	I-Metric
are	O
positive	O
indicators	O
on	O
answer	B-Metric
correctness	I-Metric
,	O
whereas	O
low	B-Metric
semantic	I-Metric
matching	I-Metric
scores	I-Metric
indicate	O
that	O
the	O
candidate	O
answer	O
sentences	O
contain	O
irrelevant	O
terms	O
.	O
	
(	O
3	O
)	O
	
For	O
negative	O
matching	O
scores	O
from	O
,	O
we	O
can	O
see	O
there	O
is	O
not	O
a	O
lot	O
of	O
differences	O
between	O
value	O
-	O
shared	O
weights	O
for	O
different	O
ranges	O
.	O
	
A	O
major	O
reason	O
is	O
that	O
most	O
similarity	B-Metric
scores	I-Metric
based	O
on	O
word	B-Method
embeddings	I-Method
are	O
positive	O
.	O
	
Therefore	O
,	O
we	O
can	O
remove	O
bins	O
corresponding	O
to	O
negative	O
matching	O
scores	O
to	O
reduce	O
the	O
dimension	O
of	O
value	O
-	O
shared	O
weight	O
vectors	O
,	O
which	O
can	O
help	O
improve	O
the	O
efficiency	O
of	O
the	O
model	B-Method
training	I-Method
process	I-Method
.	O
	
We	O
will	O
show	O
more	O
quantitative	O
results	O
on	O
the	O
comparison	O
between	O
value	O
-	O
shared	O
weights	O
and	O
position	O
-	O
shared	O
weights	O
in	O
CNN	B-Method
in	O
Section	O
[	O
reference	O
]	O
.	O
	
subsubsection	O
:	O
Question	O
Term	O
Importance	O
	
Next	O
we	O
analyze	O
the	O
learned	O
question	O
term	O
importance	O
of	O
our	O
model	O
.	O
	
Due	O
to	O
the	O
space	O
limit	O
,	O
we	O
also	O
use	O
the	O
learned	O
question	O
term	O
importance	O
of	O
aNMM	B-Method
-	I-Method
1	I-Method
as	O
an	O
example	O
.	O
	
Table	O
[	O
reference	O
]	O
shows	O
the	O
examples	O
of	O
learned	O
question	O
term	O
importance	O
by	O
aNMM	B-Method
-	I-Method
1	I-Method
.	O
	
We	O
also	O
visualize	O
the	O
question	O
term	O
importance	O
in	O
Figure	O
[	O
reference	O
]	O
.	O
	
Based	O
on	O
the	O
results	O
in	O
the	O
table	O
and	O
the	O
figure	O
,	O
we	O
can	O
clearly	O
see	O
that	O
aNMM	B-Method
-	I-Method
1	I-Method
learns	O
reasonable	O
term	O
importance	O
.	O
	
For	O
instance	O
,	O
with	O
the	O
question	B-Task
attention	I-Task
network	O
,	O
aNMM	B-Method
-	I-Method
1	I-Method
discovers	O
important	O
terms	O
like	O
“	O
khmer	O
”	O
,	O
	
“	O
rouge	O
”	O
,	O
“	O
power	O
”	O
as	O
for	O
the	O
question	O
	
“	O
	
When	O
did	O
the	O
khmer	O
rouge	O
come	O
into	O
power	O
?	O
”	O
.	O
	
Terms	O
like	O
“	O
age	O
”	O
,	O
“	O
rossinin	O
	
”	O
,	O
“	O
stop	O
”	O
,	O
“	O
	
writing”	O
,	O
“opera	O
”	O
are	O
highlighted	O
for	O
the	O
question	O
“	O
	
At	O
what	O
age	O
did	O
rossini	O
stop	O
writing	O
opera	O
?	O
”	O
.	O
	
For	O
the	O
question	O
“	O
Where	O
was	O
the	O
first	O
burger	O
king	O
restaurant	O
opened	O
?	O
”	O
mentioned	O
in	O
Section	O
[	O
reference	O
]	O
,	O
“	O
burger	O
”	O
,	O
“	O
king	O
”	O
,	O
“	O
opened	O
”	O
are	O
treated	O
as	O
important	O
question	O
terms	O
.	O
	
An	O
interesting	O
question	O
is	O
how	O
the	O
learned	O
term	O
importance	O
compare	O
with	O
traditional	O
IR	B-Method
term	I-Method
weighting	I-Method
methods	I-Method
such	O
as	O
IDF	B-Method
.	O
	
We	O
design	O
an	O
experiment	O
to	O
compare	O
aNMM	B-Method
-	I-Method
1	I-Method
/	O
aNMM	B-Method
-	I-Method
2	I-Method
with	O
aNMM	B-Method
-	I-Method
IDF	I-Method
,	O
which	O
is	O
a	O
degenerate	O
version	O
of	O
our	O
model	O
where	O
we	O
use	O
IDF	B-Method
to	O
directly	O
replace	O
the	O
output	O
of	O
question	B-Task
attention	I-Task
network	O
.	O
	
In	O
this	O
case	O
,	O
in	O
Equation	O
[	O
reference	O
]	O
is	O
replaced	O
by	O
the	O
IDF	B-Method
of	O
the	O
j	O
-	O
th	O
question	O
term	O
.	O
	
Table	O
[	O
reference	O
]	O
shows	O
the	O
results	O
.	O
	
We	O
find	O
that	O
if	O
we	O
replace	O
the	O
output	O
of	O
question	B-Task
attention	I-Task
network	O
of	O
aNMM	B-Method
with	O
IDF	B-Method
,	O
it	O
will	O
decrease	O
the	O
answer	B-Metric
ranking	I-Metric
performance	I-Metric
,	O
especially	O
on	O
TRAIN	B-Material
data	O
.	O
	
Thus	O
,	O
we	O
can	O
see	O
that	O
with	O
the	O
optimization	B-Method
process	I-Method
in	O
the	O
back	B-Method
propagation	I-Method
training	I-Method
process	I-Method
,	O
aNMM	B-Method
can	O
learn	O
better	O
question	B-Metric
term	I-Metric
weighting	I-Metric
score	I-Metric
than	O
heuristic	B-Method
term	I-Method
weighting	I-Method
functions	I-Method
like	O
IDF	B-Method
.	O
	
subsection	O
:	O
Experimental	O
Results	O
for	O
Ranking	B-Task
Answers	I-Task
	
subsubsection	O
:	O
Learning	B-Task
without	O
Combining	O
Additional	O
Features	O
	
Our	O
first	O
experimental	O
setting	O
is	O
ranking	O
answer	O
sentences	O
directly	O
by	O
the	O
predicted	O
score	O
from	O
aNMM	B-Method
without	O
combining	O
any	O
additional	O
features	O
.	O
	
This	O
will	O
enable	O
us	O
to	O
answer	O
RQ1	O
proposed	O
in	O
Section	O
[	O
reference	O
]	O
.	O
	
Table	O
[	O
reference	O
]	O
shows	O
the	O
results	O
of	O
TREC	B-Material
QA	I-Material
on	O
TRAIN	B-Material
and	O
TRAIN	B-Material
-	I-Material
ALL	I-Material
without	O
combining	O
additional	O
features	O
.	O
	
In	O
this	O
table	O
,	O
we	O
compare	O
the	O
results	O
of	O
aNMM	B-Method
with	O
other	O
previous	O
deep	B-Method
learning	I-Method
methods	I-Method
including	O
CNN	B-Method
and	O
LSTM	B-Method
.	O
	
We	O
summarize	O
our	O
observations	O
as	O
follows	O
:	O
(	O
1	O
)	O
Both	O
aNMM	B-Method
-	I-Method
1	I-Method
and	O
aNMM	B-Method
-	I-Method
2	I-Method
show	O
significant	O
improvements	O
for	O
MAP	B-Metric
and	O
MRR	B-Metric
on	O
TRAIN	B-Material
and	O
TRAIN	B-Material
-	I-Material
ALL	I-Material
data	I-Material
sets	I-Material
comparing	O
with	O
previous	O
deep	B-Method
learning	I-Method
methods	I-Method
.	O
	
Specifically	O
,	O
if	O
we	O
compare	O
the	O
results	O
of	O
aNMM	B-Method
-	I-Method
1	I-Method
with	O
the	O
strongest	O
deep	B-Method
learning	I-Method
baseline	I-Method
method	I-Method
by	O
Severyn	O
et	O
al	O
.	O
based	O
on	O
CNN	B-Method
,	O
we	O
can	O
see	O
aNMM	B-Method
-	I-Method
1	I-Method
outperform	O
CNN	B-Method
for	O
%	O
in	O
MAP	B-Metric
on	O
TRAIN	B-Material
,	O
%	O
in	O
MAP	B-Metric
on	O
TRAIN	B-Material
-	I-Material
ALL	I-Material
.	O
	
For	O
MRR	B-Metric
,	O
we	O
can	O
also	O
observe	O
similar	O
significant	O
improvements	O
of	O
aNMM	B-Method
-	I-Method
1	I-Method
.	O
	
These	O
results	O
show	O
that	O
with	O
the	O
value	B-Method
-	I-Method
shared	I-Method
weight	I-Method
scheme	I-Method
instead	O
of	O
the	O
position	B-Method
-	I-Method
shared	I-Method
weight	I-Method
scheme	I-Method
in	O
CNN	B-Method
and	O
term	B-Method
importance	I-Method
learning	I-Method
with	O
question	B-Task
attention	I-Task
network	O
,	O
aNMM	B-Method
can	O
predict	O
ranking	B-Metric
scores	I-Metric
with	O
much	O
higher	O
accuracy	B-Metric
comparing	O
with	O
previous	O
deep	B-Method
learning	I-Method
models	I-Method
for	O
ranking	B-Task
answers	I-Task
.	O
	
(	O
2	O
)	O
If	O
we	O
compare	O
the	O
results	O
of	O
aNMM	B-Method
-	I-Method
1	I-Method
and	O
aNMM	B-Method
-	I-Method
2	I-Method
,	O
we	O
can	O
see	O
their	O
results	O
are	O
very	O
close	O
.	O
	
aNMM	B-Method
-	I-Method
1	I-Method
has	O
slightly	O
better	O
performance	O
than	O
aNMM	B-Method
-	I-Method
2	I-Method
.	O
	
This	O
result	O
indicates	O
that	O
adding	O
one	O
more	O
hidden	O
layer	O
to	O
incorporate	O
multiple	O
bin	O
nodes	O
does	O
not	O
necessarily	O
increase	O
the	O
performance	O
for	O
answer	B-Task
ranking	I-Task
in	O
TREC	B-Material
QA	O
data	O
.	O
	
From	O
the	O
perspective	O
of	O
model	B-Metric
efficiency	I-Metric
,	O
aNMM	B-Method
-	I-Method
1	I-Method
could	O
be	O
a	O
better	O
choice	O
since	O
it	O
can	O
be	O
trained	O
much	O
faster	O
with	O
good	O
prediction	B-Metric
accuracy	I-Metric
.	O
	
However	O
,	O
for	O
larger	O
training	O
data	O
sets	O
than	O
TREC	B-Material
QA	O
data	O
,	O
aNMM	B-Method
-	O
2	O
could	O
have	O
better	O
performance	O
since	O
it	O
has	O
more	O
model	O
parameters	O
and	O
is	O
suitable	O
for	O
fitting	O
larger	O
training	O
data	O
set	O
.	O
	
We	O
leave	O
the	O
study	O
of	O
impact	O
of	O
the	O
number	O
of	O
hidden	O
layers	O
in	O
aNMM	B-Method
to	O
future	O
work	O
.	O
	
Table	O
[	O
reference	O
]	O
shows	O
the	O
comparison	O
between	O
aNMM	B-Method
with	O
previous	O
methods	O
using	O
feature	B-Method
engineering	I-Method
on	O
TRAIN	B-Material
-	I-Material
ALL	I-Material
without	O
combining	O
additional	O
features	O
.	O
	
We	O
find	O
that	O
both	O
aNMM	B-Method
-	I-Method
1	I-Method
and	O
aNMM	B-Method
-	I-Method
2	I-Method
achieve	O
better	O
performance	O
comparing	O
with	O
other	O
methods	O
using	O
feature	B-Method
engineering	I-Method
.	O
	
Specifically	O
,	O
comparing	O
the	O
results	O
of	O
aNMM	B-Method
-	I-Method
1	I-Method
with	O
the	O
strongest	O
baseline	O
by	O
Yih	O
et	O
al	O
.	O
based	O
on	O
enhanced	B-Method
lexical	I-Method
semantic	I-Method
models	I-Method
,	O
aNMM	B-Method
-	I-Method
1	I-Method
achieves	O
%	O
gain	O
for	O
MAP	B-Metric
and	O
%	O
gain	O
for	O
MRR	B-Metric
.	O
	
These	O
results	O
show	O
that	O
it	O
is	O
possible	O
to	O
build	O
a	O
uniform	B-Method
deep	I-Method
learning	I-Method
model	I-Method
such	O
that	O
it	O
can	O
achieve	O
better	O
performance	O
than	O
methods	O
using	O
feature	B-Method
engineering	I-Method
.	O
	
To	O
the	O
best	O
of	O
our	O
knowledge	O
,	O
aNMM	B-Method
is	O
the	O
first	O
deep	B-Method
learning	I-Method
model	I-Method
that	O
can	O
achieve	O
good	O
performance	O
comparing	O
with	O
previous	O
methods	O
either	O
based	O
on	O
deep	B-Method
learning	I-Method
models	I-Method
or	O
feature	B-Method
engineering	I-Method
for	O
ranking	B-Task
answers	I-Task
without	O
any	O
additional	O
features	O
,	O
syntactic	B-Method
parsers	I-Method
and	O
external	O
resources	O
except	O
for	O
pre	O
-	O
trained	O
word	O
embeddings	O
.	O
	
subsubsection	O
:	O
Learning	O
with	O
Combining	O
Additional	O
Features	O
	
Our	O
second	O
experimental	O
setting	O
is	O
to	O
address	O
RQ2	O
proposed	O
in	O
Section	O
[	O
reference	O
]	O
,	O
where	O
we	O
ask	O
whether	O
our	O
model	O
can	O
outperform	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
performance	O
achieved	O
by	O
CNN	B-Method
and	O
LSTM	B-Method
for	O
answer	B-Task
ranking	I-Task
when	O
combining	O
additional	O
features	O
.	O
	
We	O
combine	O
the	O
predicted	B-Metric
score	I-Metric
from	O
aNMM	B-Method
-	I-Method
1	I-Method
and	O
aNMM	B-Method
-	I-Method
2	I-Method
with	O
the	O
Query	B-Metric
Likelihood	I-Metric
(	O
QL	B-Metric
)	O
score	O
using	O
LambdaMART	B-Method
following	O
a	O
similar	O
approach	O
to	O
.	O
	
We	O
use	O
the	O
implementation	O
of	O
LambdaMART	B-Method
in	O
jforests	B-Method
We	O
compare	O
the	O
results	O
with	O
previous	O
deep	B-Method
learning	I-Method
models	I-Method
with	O
additional	O
features	O
.	O
	
Table	O
[	O
reference	O
]	O
shows	O
the	O
results	O
on	O
TRAIN	B-Material
and	O
TRAIN	B-Material
-	O
ALL	O
when	O
combining	O
additional	O
features	O
.	O
	
We	O
can	O
see	O
that	O
with	O
combined	O
features	O
,	O
both	O
aNMM	B-Method
-	I-Method
1	I-Method
and	O
aNMM	B-Method
-	I-Method
2	I-Method
have	O
better	O
performance	O
.	O
	
aNMM	B-Method
-	I-Method
1	I-Method
also	O
outperforms	O
CNN	B-Method
by	O
Severyn	O
et	O
al	O
.	O
which	O
is	O
the	O
current	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
method	O
for	O
ranking	B-Task
answers	I-Task
in	O
terms	O
of	O
both	O
MAP	B-Metric
and	O
MRR	B-Metric
on	O
TRAIN	B-Material
and	O
TRAIN	B-Material
-	I-Material
ALL	I-Material
.	O
	
We	O
also	O
tried	O
to	O
combine	O
aNMM	B-Method
score	O
with	O
other	O
additional	O
features	O
such	O
as	O
word	O
overlap	O
features	O
,	O
IDF	O
weighted	O
word	O
overlap	O
features	O
and	O
BM25	B-Method
as	O
in	O
previous	O
research	O
.	O
	
The	O
results	O
were	O
either	O
similar	O
or	O
worse	O
than	O
combining	O
aNMM	B-Method
score	O
with	O
QL	B-Metric
.	O
	
For	O
aNMM	B-Method
,	O
the	O
gains	O
after	O
combining	O
additional	O
features	O
are	O
not	O
as	O
large	O
as	O
neural	B-Method
network	I-Method
models	I-Method
like	O
CNN	B-Method
in	I-Method
and	O
LSTM	B-Method
in	I-Method
.	O
	
We	O
think	O
the	O
reasons	O
for	O
this	O
are	O
two	O
-	O
fold	O
:	O
(	O
1	O
)	O
The	O
QA	B-Method
matching	I-Method
matrix	I-Method
in	O
aNMM	B-Method
model	O
can	O
capture	O
exact	O
match	O
information	O
by	O
assigning	O
to	O
matrix	O
elements	O
if	O
the	O
corresponding	O
answer	O
term	O
and	O
question	O
term	O
are	O
the	O
same	O
.	O
	
This	O
exact	O
match	O
information	O
include	O
match	O
between	O
numbers	O
and	O
proper	O
nouns	O
,	O
which	O
are	O
highlighted	O
in	O
previous	O
research	O
work	O
as	O
especially	O
important	O
for	O
factoid	B-Task
questions	I-Task
answering	I-Task
,	O
where	O
most	O
of	O
the	O
questions	O
are	O
of	O
type	O
what	O
,	O
when	O
,	O
who	O
that	O
are	O
looking	O
for	O
answers	O
containing	O
numbers	O
or	O
proper	O
nouns	O
.	O
	
Within	O
aNMM	B-Method
architecture	O
,	O
this	O
problem	O
has	O
already	O
been	O
handled	O
with	O
QA	B-Method
matching	I-Method
matrix	I-Method
.	O
	
Thus	O
incorporating	O
word	O
overlap	O
features	O
will	O
not	O
help	O
much	O
for	O
improving	O
the	O
performance	O
of	O
aNMM	B-Method
.	O
	
(	O
2	O
)	O
	
In	O
addition	O
to	O
exact	O
match	O
information	O
,	O
aNMM	B-Method
could	O
also	O
learn	O
question	O
term	O
importance	O
like	O
IDF	O
information	O
through	O
question	B-Task
attention	I-Task
network	O
.	O
	
Instead	O
of	O
empirically	O
designing	O
heuristic	B-Method
functions	I-Method
like	O
IDF	B-Method
,	O
aNMM	B-Method
can	O
get	O
learning	O
based	O
question	B-Metric
term	I-Metric
importance	I-Metric
score	I-Metric
.	O
	
As	O
analyzed	O
in	O
Section	O
[	O
reference	O
]	O
,	O
with	O
the	O
optimization	B-Method
process	I-Method
in	O
the	O
back	B-Method
propagation	I-Method
training	I-Method
process	I-Method
,	O
aNMM	B-Method
can	O
learn	O
similar	O
or	O
even	O
better	O
term	B-Metric
weighting	I-Metric
score	I-Metric
than	O
IDF	B-Method
.	O
	
Thus	O
combining	O
aNMM	B-Method
score	O
with	O
features	O
like	O
IDF	B-Method
weighted	I-Method
word	I-Method
overlap	I-Method
features	I-Method
and	O
BM25	B-Method
may	O
not	O
increase	O
the	O
performance	O
of	O
aNMM	B-Method
by	O
a	O
large	O
margin	O
as	O
the	O
case	O
in	O
related	O
research	O
works	O
.	O
	
subsubsection	O
:	O
Results	O
Summary	O
	
[	O
b	O
]	O
0.48	O
[	O
b	O
]	O
0.48	O
Finally	O
we	O
summarize	O
the	O
results	O
of	O
previously	O
published	O
systems	O
on	O
the	O
QA	B-Task
answer	I-Task
ranking	I-Task
task	I-Task
in	O
Table	O
[	O
reference	O
]	O
.	O
	
We	O
can	O
see	O
aNMM	B-Method
trained	O
with	O
TRAIN	B-Material
-	O
ALL	O
set	O
beats	O
all	O
the	O
previous	O
state	O
-	O
of	O
-	O
the	O
art	O
systems	O
including	O
both	O
methods	O
using	O
feature	B-Method
engineering	I-Method
and	O
deep	B-Method
learning	I-Method
models	I-Method
.	O
	
These	O
results	O
are	O
very	O
promising	O
since	O
aNMM	B-Method
requires	O
no	O
manual	B-Method
feature	I-Method
engineering	I-Method
,	O
no	O
expensive	O
processing	O
by	O
various	O
NLP	B-Method
parsers	I-Method
and	O
no	O
external	O
results	O
like	O
large	O
scale	O
knowledge	O
base	O
except	O
for	O
pre	O
-	O
trained	O
word	O
embeddings	O
.	O
	
Furthermore	O
,	O
even	O
without	O
combining	O
additional	O
features	O
,	O
aNMM	B-Method
still	O
performs	O
well	O
for	O
answer	B-Task
ranking	I-Task
,	O
showing	O
significant	O
improvements	O
over	O
previous	O
deep	B-Method
learning	I-Method
model	I-Method
with	O
no	O
additional	O
features	O
and	O
linguistic	B-Method
feature	I-Method
engineering	I-Method
methods	I-Method
.	O
	
subsection	O
:	O
Parameter	B-Method
Sensitivity	I-Method
Analysis	I-Method
	
We	O
perform	O
parameter	B-Task
sensitivity	I-Task
analysis	I-Task
of	O
our	O
proposed	O
model	O
aNMM	B-Method
.	O
	
We	O
focus	O
on	O
aNMM	B-Method
-	I-Method
1	I-Method
as	O
the	O
example	O
due	O
to	O
the	O
space	O
limitation	O
.	O
	
For	O
aNMM	B-Method
-	I-Method
1	I-Method
,	O
we	O
fix	O
the	O
number	O
of	O
bins	O
as	O
and	O
change	O
the	O
dimension	O
of	O
word	O
vectors	O
.	O
	
Similarly	O
,	O
we	O
fix	O
the	O
dimension	O
of	O
word	O
vectors	O
as	O
and	O
vary	O
the	O
number	O
of	O
bins	O
.	O
	
Figure	O
[	O
reference	O
]	O
shows	O
the	O
change	O
of	O
MAP	B-Metric
and	O
MRR	B-Metric
on	O
the	O
validation	O
data	O
as	O
we	O
vary	O
the	O
hyper	O
-	O
parameters	O
.	O
	
We	O
summarize	O
our	O
observations	O
as	O
follows	O
:	O
	
(	O
1	O
)	O
For	O
word	O
vector	O
dimension	O
,	O
the	O
range	O
is	O
a	O
good	O
choice	O
as	O
much	O
lower	O
or	O
higher	O
word	O
vector	O
dimensions	O
will	O
hurt	O
the	O
performance	O
.	O
	
The	O
choice	O
of	O
word	O
vector	O
dimension	O
also	O
depends	O
on	O
the	O
size	O
of	O
training	O
corpus	O
.	O
	
Larger	O
corpus	O
requires	O
higher	O
dimension	O
of	O
word	O
vectors	O
to	O
embed	O
terms	O
in	O
vocabulary	O
.	O
	
(	O
2	O
)	O
	
For	O
the	O
number	O
of	O
bins	O
,	O
we	O
can	O
see	O
that	O
MAP	B-Metric
and	O
MRR	B-Metric
will	O
decrease	O
as	O
the	O
bin	O
number	O
increase	O
.	O
	
Too	O
many	O
bins	O
will	O
increase	O
the	O
model	B-Metric
complexity	I-Metric
,	O
which	O
leads	O
aNMM	B-Method
to	O
be	O
more	O
likely	O
to	O
overfit	O
the	O
training	O
data	O
.	O
	
Thus	O
choosing	O
suitable	O
number	O
of	O
bins	O
by	O
optimizing	O
hyper	O
-	O
parameter	O
on	O
validation	O
data	O
can	O
help	O
improve	O
the	O
performance	O
of	O
aNMM	B-Method
.	O
	
section	O
:	O
Conclusions	O
and	O
Future	O
Work	O
	
In	O
this	O
paper	O
,	O
we	O
propose	O
an	O
attention	B-Method
based	I-Method
neural	I-Method
matching	I-Method
model	I-Method
for	O
ranking	B-Task
short	I-Task
answer	I-Task
text	I-Task
.	O
	
We	O
adopt	O
value	B-Method
-	I-Method
shared	I-Method
weighting	I-Method
scheme	I-Method
instead	O
of	O
position	B-Method
-	I-Method
shared	I-Method
weighting	I-Method
scheme	I-Method
for	O
combing	O
different	O
matching	O
signals	O
and	O
incorporate	O
question	B-Method
term	I-Method
importance	I-Method
learning	I-Method
using	O
a	O
question	B-Task
attention	I-Task
network	O
.	O
	
We	O
perform	O
a	O
thorough	O
experimental	O
study	O
with	O
the	O
TREC	B-Material
QA	I-Material
dataset	I-Material
from	O
TREC	B-Material
QA	O
tracks	O
8	O
-	O
13	O
and	O
show	O
promising	O
results	O
.	O
	
Unlike	O
previous	O
methods	O
including	O
CNN	B-Method
as	O
in	O
and	O
LSTM	B-Method
as	O
in	O
,	O
which	O
only	O
show	O
inferior	O
results	O
without	O
combining	O
additional	O
features	O
,	O
our	O
model	O
can	O
achieve	O
better	O
performance	O
than	O
the	O
state	O
-	O
of	O
-	O
art	O
method	O
using	O
linguistic	B-Method
feature	I-Method
engineering	I-Method
without	O
additional	O
features	O
.	O
	
With	O
a	O
simple	O
additional	O
feature	O
,	O
our	O
method	O
can	O
achieve	O
the	O
new	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
performance	O
among	O
current	O
existing	O
methods	O
.	O
	
For	O
further	O
work	O
,	O
we	O
will	O
study	O
other	O
deep	B-Method
learning	I-Method
architectures	I-Method
for	O
answer	B-Task
ranking	I-Task
and	O
extend	O
our	O
work	O
to	O
include	O
non	B-Task
-	I-Task
factoid	I-Task
question	I-Task
answering	I-Task
data	O
sets	O
.	O
	
section	O
:	O
Acknowledgments	O
	
This	O
work	O
was	O
supported	O
in	O
part	O
by	O
the	O
Center	O
for	O
Intelligent	B-Task
Information	I-Task
Retrieval	I-Task
,	O
in	O
part	O
by	O
NSF	O
IIS	O
-	O
1160894	O
,	O
and	O
in	O
part	O
by	O
NSF	O
grant	O
#	O
IIS	O
-	O
1419693	O
.	O
	
Any	O
opinions	O
,	O
findings	O
and	O
conclusions	O
or	O
recommendations	O
expressed	O
in	O
this	O
material	O
are	O
those	O
of	O
the	O
authors	O
and	O
do	O
not	O
necessarily	O
reflect	O
those	O
of	O
the	O
sponsor	O
.	O
	
bibliography	O
:	O
References	O
	
document	O
:	O
Adversarial	B-Method
Discriminative	I-Method
Domain	I-Method
Adaptation	I-Method
	
Adversarial	B-Method
learning	I-Method
methods	I-Method
are	O
a	O
promising	O
approach	O
to	O
training	O
robust	B-Task
deep	I-Task
networks	I-Task
,	O
and	O
can	O
generate	O
complex	O
samples	O
across	O
diverse	O
domains	O
.	O
	
They	O
also	O
can	O
improve	O
recognition	B-Task
despite	O
the	O
presence	O
of	O
domain	O
shift	O
or	O
dataset	O
bias	O
:	O
several	O
adversarial	B-Method
approaches	I-Method
to	O
unsupervised	B-Task
domain	I-Task
adaptation	I-Task
have	O
recently	O
been	O
introduced	O
,	O
which	O
reduce	O
the	O
difference	O
between	O
the	O
training	O
and	O
test	O
domain	O
distributions	O
and	O
thus	O
improve	O
generalization	B-Task
performance	O
.	O
	
Prior	O
generative	B-Method
approaches	I-Method
show	O
compelling	O
visualizations	O
,	O
but	O
are	O
not	O
optimal	O
on	O
discriminative	B-Task
tasks	I-Task
and	O
can	O
be	O
limited	O
to	O
smaller	O
shifts	O
.	O
	
Prior	O
discriminative	B-Method
approaches	I-Method
could	O
handle	O
larger	O
domain	O
shifts	O
,	O
but	O
imposed	O
tied	O
weights	O
on	O
the	O
model	O
and	O
did	O
not	O
exploit	O
a	O
GAN	B-Method
-	O
based	O
loss	O
.	O
	
We	O
first	O
outline	O
a	O
novel	O
generalized	B-Method
framework	I-Method
for	O
adversarial	B-Task
adaptation	I-Task
,	O
which	O
subsumes	O
recent	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
approaches	O
as	O
special	O
cases	O
,	O
and	O
we	O
use	O
this	O
generalized	O
view	O
to	O
better	O
relate	O
the	O
prior	O
approaches	O
.	O
	
We	O
propose	O
a	O
previously	O
unexplored	O
instance	O
of	O
our	O
general	O
framework	O
which	O
combines	O
discriminative	B-Method
modeling	I-Method
,	O
untied	B-Method
weight	I-Method
sharing	I-Method
,	O
and	O
a	O
GAN	B-Method
loss	O
,	O
which	O
we	O
call	O
Adversarial	B-Method
Discriminative	I-Method
Domain	I-Method
Adaptation	I-Method
(	O
ADDA	B-Method
)	O
.	O
	
We	O
show	O
that	O
ADDA	B-Method
is	O
more	O
effective	O
yet	O
considerably	O
simpler	O
than	O
competing	O
domain	B-Method
-	I-Method
adversarial	I-Method
methods	I-Method
,	O
and	O
demonstrate	O
the	O
promise	O
of	O
our	O
approach	O
by	O
exceeding	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
unsupervised	B-Method
adaptation	I-Method
results	O
on	O
standard	O
cross	B-Task
-	I-Task
domain	I-Task
digit	I-Task
classification	I-Task
tasks	I-Task
and	O
a	O
new	O
more	O
difficult	O
cross	B-Task
-	I-Task
modality	I-Task
object	I-Task
classification	I-Task
task	I-Task
.	O
	
section	O
:	O
Introduction	O
	
Deep	B-Method
convolutional	I-Method
networks	I-Method
,	O
when	O
trained	O
on	O
large	O
-	O
scale	O
datasets	O
,	O
can	O
learn	O
representations	O
which	O
are	O
generically	O
usefull	O
across	O
a	O
variety	O
of	O
tasks	O
and	O
visual	O
domains	O
.	O
	
However	O
,	O
due	O
to	O
a	O
phenomenon	O
known	O
as	O
dataset	O
bias	O
or	O
domain	O
shift	O
,	O
recognition	B-Method
models	I-Method
trained	O
along	O
with	O
these	O
representations	O
on	O
one	O
large	O
dataset	O
do	O
not	O
generalize	O
well	O
to	O
novel	O
datasets	O
and	O
tasks	O
.	O
	
The	O
typical	O
solution	O
is	O
to	O
further	O
fine	O
-	O
tune	O
	
these	O
networks	O
on	O
task	O
-	O
specific	O
datasets	O
—	O
however	O
	
,	O
it	O
is	O
often	O
prohibitively	O
difficult	O
and	O
expensive	O
to	O
obtain	O
enough	O
labeled	O
data	O
to	O
properly	O
fine	O
-	O
tune	O
the	O
large	O
number	O
of	O
parameters	O
employed	O
by	O
deep	B-Method
multilayer	I-Method
networks	I-Method
.	O
	
Domain	B-Method
adaptation	I-Method
methods	I-Method
attempt	O
to	O
mitigate	O
the	O
harmful	O
effects	O
of	O
domain	O
shift	O
.	O
	
Recent	O
domain	B-Method
adaptation	I-Method
methods	I-Method
learn	O
deep	B-Method
neural	I-Method
transformations	I-Method
that	O
map	O
both	O
domains	O
into	O
a	O
common	O
feature	O
space	O
.	O
	
This	O
is	O
generally	O
achieved	O
by	O
optimizing	O
the	O
representation	O
to	O
minimize	O
some	O
measure	O
of	O
domain	O
shift	O
such	O
as	O
maximum	B-Metric
mean	I-Metric
discrepancy	I-Metric
or	O
correlation	B-Metric
distances	I-Metric
.	O
	
An	O
alternative	O
is	O
to	O
reconstruct	O
the	O
target	O
domain	O
from	O
the	O
source	B-Method
representation	I-Method
.	O
	
Adversarial	B-Method
adaptation	I-Method
methods	I-Method
have	O
become	O
an	O
increasingly	O
popular	O
incarnation	O
of	O
this	O
type	O
of	O
approach	O
which	O
seeks	O
to	O
minimize	O
an	O
approximate	O
domain	B-Metric
discrepancy	I-Metric
distance	I-Metric
through	O
an	O
adversarial	O
objective	O
with	O
respect	O
to	O
a	O
domain	B-Method
discriminator	I-Method
.	O
	
These	O
methods	O
are	O
closely	O
related	O
to	O
generative	B-Method
adversarial	I-Method
learning	I-Method
,	O
which	O
pits	O
two	O
networks	O
against	O
each	O
other	O
—	O
a	O
generator	B-Method
and	O
a	O
discriminator	B-Method
.	O
	
The	O
generator	O
is	O
trained	O
to	O
produce	O
images	O
in	O
a	O
way	O
that	O
confuses	O
the	O
discriminator	O
,	O
which	O
in	O
turn	O
tries	O
to	O
distinguish	O
them	O
from	O
real	O
image	O
examples	O
.	O
	
In	O
domain	B-Task
adaptation	I-Task
,	O
this	O
principle	O
has	O
been	O
employed	O
to	O
ensure	O
that	O
the	O
network	O
can	O
not	O
distinguish	O
between	O
the	O
distributions	O
of	O
its	O
training	O
and	O
test	O
domain	O
examples	O
.	O
	
However	O
,	O
each	O
algorithm	O
makes	O
different	O
design	O
choices	O
such	O
as	O
whether	O
to	O
use	O
a	O
generator	B-Method
,	O
which	O
loss	O
function	O
to	O
employ	O
,	O
or	O
whether	O
to	O
share	O
weights	O
across	O
domains	O
.	O
	
For	O
example	O
,	O
share	O
weights	O
and	O
learn	O
a	O
symmetric	B-Method
mapping	I-Method
of	O
both	O
source	O
and	O
target	O
images	O
to	O
the	O
shared	O
feature	O
space	O
,	O
while	O
decouple	O
some	O
layers	O
thus	O
learning	O
a	O
partially	O
asymmetric	O
mapping	O
.	O
	
In	O
this	O
work	O
,	O
we	O
propose	O
a	O
novel	O
unified	B-Method
framework	I-Method
for	O
adversarial	B-Task
domain	I-Task
adaptation	I-Task
,	O
allowing	O
us	O
to	O
effectively	O
examine	O
the	O
different	O
factors	O
of	O
variation	O
between	O
the	O
existing	O
approaches	O
and	O
clearly	O
view	O
the	O
similarities	O
they	O
each	O
share	O
.	O
	
Our	O
framework	O
unifies	O
design	O
choices	O
such	O
as	O
weight	B-Method
-	I-Method
sharing	I-Method
,	O
base	B-Method
models	I-Method
,	O
and	O
adversarial	B-Method
losses	I-Method
and	O
subsumes	O
previous	O
work	O
,	O
while	O
also	O
facilitating	O
the	O
design	O
of	O
novel	O
instantiations	O
that	O
improve	O
upon	O
existing	O
ones	O
.	O
	
In	O
particular	O
,	O
we	O
observe	O
that	O
generative	B-Method
modeling	I-Method
of	I-Method
input	I-Method
image	I-Method
distributions	I-Method
is	O
not	O
necessary	O
,	O
as	O
the	O
ultimate	O
task	O
is	O
to	O
learn	O
a	O
discriminative	B-Method
representation	I-Method
.	O
	
On	O
the	O
other	O
hand	O
,	O
asymmetric	O
mappings	O
can	O
better	O
model	O
the	O
difference	O
in	O
low	O
level	O
features	O
than	O
symmetric	O
ones	O
.	O
	
We	O
therefore	O
propose	O
a	O
previously	O
unexplored	O
unsupervised	B-Method
adversarial	I-Method
adaptation	I-Method
method	I-Method
,	O
Adversarial	B-Method
Discriminative	I-Method
Domain	I-Method
Adaptation	I-Method
(	O
ADDA	B-Method
)	O
,	O
illustrated	O
in	O
Figure	O
[	O
reference	O
]	O
.	O
	
ADDA	B-Method
first	O
learns	O
a	O
discriminative	B-Method
representation	I-Method
using	O
the	O
labels	O
in	O
the	O
source	O
domain	O
and	O
then	O
a	O
separate	O
encoding	O
that	O
maps	O
the	O
target	O
data	O
to	O
the	O
same	O
space	O
using	O
an	O
asymmetric	B-Method
mapping	I-Method
learned	O
through	O
a	O
domain	B-Method
-	I-Method
adversarial	I-Method
loss	I-Method
.	O
	
Our	O
approach	O
is	O
simple	O
yet	O
surprisingly	O
powerful	O
and	O
achieves	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
visual	B-Task
adaptation	I-Task
results	O
on	O
the	O
MNIST	B-Material
,	O
USPS	B-Material
,	O
and	O
SVHN	B-Material
digits	O
datasets	O
.	O
	
We	O
also	O
test	O
its	O
potential	O
to	O
bridge	O
the	O
gap	O
between	O
even	O
more	O
difficult	O
cross	O
-	O
modality	O
shifts	O
,	O
without	O
requiring	O
instance	O
constraints	O
,	O
by	O
transferring	O
object	B-Method
classifiers	I-Method
from	O
RGB	B-Material
color	O
images	O
to	O
depth	O
observations	O
.	O
	
section	O
:	O
Related	O
work	O
	
There	O
has	O
been	O
extensive	O
prior	O
work	O
on	O
domain	B-Task
transfer	I-Task
learning	I-Task
,	O
see	O
e.g.	O
,	O
.	O
	
Recent	O
work	O
has	O
focused	O
on	O
transferring	O
deep	B-Method
neural	I-Method
network	I-Method
representations	I-Method
from	O
a	O
labeled	O
source	O
datasets	O
to	O
a	O
target	O
domain	O
where	O
labeled	O
data	O
is	O
sparse	O
or	O
non	O
-	O
existent	O
.	O
	
In	O
the	O
case	O
of	O
unlabeled	B-Task
target	I-Task
domains	I-Task
(	O
the	O
focus	O
of	O
this	O
paper	O
)	O
the	O
main	O
strategy	O
has	O
been	O
to	O
guide	O
feature	B-Task
learning	I-Task
by	O
minimizing	O
the	O
difference	O
between	O
the	O
source	O
and	O
target	O
feature	O
distributions	O
.	O
	
Several	O
methods	O
have	O
used	O
the	O
Maximum	B-Metric
Mean	I-Metric
Discrepancy	I-Metric
(	O
MMD	B-Metric
)	O
loss	O
for	O
this	O
purpose	O
.	O
	
MMD	B-Metric
computes	O
the	O
norm	O
of	O
the	O
difference	O
between	O
two	O
domain	O
means	O
.	O
	
The	O
DDC	B-Method
method	I-Method
used	O
MMD	B-Metric
in	O
addition	O
to	O
the	O
regular	O
classification	O
loss	O
on	O
the	O
source	O
to	O
learn	O
a	O
representation	O
that	O
is	O
both	O
discriminative	O
and	O
domain	O
invariant	O
.	O
	
The	O
Deep	B-Method
Adaptation	I-Method
Network	I-Method
(	O
DAN	B-Method
)	O
applied	O
MMD	B-Metric
to	O
layers	O
embedded	O
in	O
a	O
reproducing	B-Method
kernel	I-Method
Hilbert	I-Method
space	I-Method
,	O
effectively	O
matching	O
higher	O
order	O
statistics	O
of	O
the	O
two	O
distributions	O
.	O
	
In	O
contrast	O
,	O
the	O
deep	O
Correlation	B-Method
Alignment	I-Method
(	O
CORAL	B-Method
)	O
method	O
proposed	O
to	O
match	O
the	O
mean	O
and	O
covariance	O
of	O
the	O
two	O
distributions	O
.	O
	
Other	O
methods	O
have	O
chosen	O
an	O
adversarial	B-Method
loss	I-Method
to	O
minimize	O
domain	B-Task
shift	I-Task
,	O
learning	O
a	O
representation	O
that	O
is	O
simultaneously	O
discriminative	O
of	O
source	O
labels	O
while	O
not	O
being	O
able	O
to	O
distinguish	O
between	O
domains	O
.	O
	
proposed	O
adding	O
a	O
domain	B-Method
classifier	I-Method
(	O
a	O
single	O
fully	B-Method
connected	I-Method
layer	I-Method
)	O
that	O
predicts	O
the	O
binary	O
domain	O
label	O
of	O
the	O
inputs	O
and	O
designed	O
a	O
domain	O
confusion	O
loss	O
to	O
encourage	O
its	O
prediction	O
to	O
be	O
as	O
close	O
as	O
possible	O
to	O
a	O
uniform	O
distribution	O
over	O
binary	O
labels	O
.	O
	
The	O
gradient	B-Method
reversal	I-Method
algorithm	I-Method
(	O
ReverseGrad	B-Method
)	O
proposed	O
in	O
also	O
treats	O
domain	B-Task
invariance	I-Task
as	O
a	O
binary	B-Task
classification	I-Task
problem	I-Task
,	O
but	O
directly	O
maximizes	O
the	O
loss	O
of	O
the	O
domain	B-Method
classifier	I-Method
by	O
reversing	O
its	O
gradients	O
.	O
	
DRCN	B-Method
takes	O
a	O
similar	O
approach	O
but	O
also	O
learns	O
to	O
reconstruct	O
target	O
domain	O
images	O
.	O
	
In	O
related	O
work	O
,	O
adversarial	B-Method
learning	I-Method
has	O
been	O
explored	O
for	O
generative	B-Task
tasks	I-Task
.	O
	
The	O
Generative	B-Method
Adversarial	I-Method
Network	I-Method
(	O
GAN	B-Method
)	O
method	O
is	O
a	O
generative	B-Method
deep	I-Method
model	I-Method
that	O
pits	O
two	O
networks	O
against	O
one	O
another	O
:	O
a	O
generative	B-Method
model	I-Method
	
G	O
that	O
captures	O
the	O
data	O
distribution	O
and	O
a	O
discriminative	B-Method
model	I-Method
D	I-Method
that	O
distinguishes	O
between	O
samples	O
drawn	O
from	O
G	O
and	O
images	O
drawn	O
from	O
the	O
training	O
data	O
by	O
predicting	O
a	O
binary	O
label	O
.	O
	
The	O
networks	O
are	O
trained	O
jointly	O
using	O
backprop	B-Method
on	O
the	O
label	B-Task
prediction	I-Task
loss	I-Task
in	O
a	O
mini	B-Method
-	I-Method
max	I-Method
fashion	I-Method
:	O
simultaneously	O
update	O
G	O
to	O
minimize	O
the	O
loss	O
while	O
also	O
updating	O
D	O
to	O
maximize	O
the	O
loss	O
(	O
fooling	O
the	O
discriminator	O
)	O
.	O
	
The	O
advantage	O
of	O
GAN	B-Method
over	O
other	O
generative	B-Method
methods	I-Method
is	O
that	O
there	O
is	O
no	O
need	O
for	O
complex	O
sampling	O
or	O
inference	B-Task
during	O
training	B-Task
;	O
the	O
downside	O
is	O
that	O
it	O
may	O
be	O
difficult	O
to	O
train	O
.	O
	
GANs	B-Method
have	O
been	O
applied	O
to	O
generate	O
natural	B-Task
images	I-Task
of	I-Task
objects	I-Task
,	O
such	O
as	O
digits	O
and	O
faces	O
,	O
and	O
have	O
been	O
extended	O
in	O
several	O
ways	O
.	O
	
The	O
BiGAN	B-Method
approach	I-Method
extends	O
GANs	B-Method
to	O
also	O
learn	O
the	O
inverse	O
mapping	O
from	O
the	O
image	O
data	O
back	O
into	O
the	O
latent	O
space	O
,	O
and	O
shows	O
that	O
this	O
can	O
learn	O
features	O
useful	O
for	O
image	B-Task
classification	I-Task
tasks	I-Task
.	O
	
The	O
conditional	B-Method
generative	I-Method
adversarial	I-Method
net	I-Method
(	O
CGAN	B-Method
)	O
is	O
an	O
extension	O
of	O
the	O
GAN	B-Method
where	O
both	O
networks	O
G	O
and	O
D	O
receive	O
an	O
additional	O
vector	O
of	O
information	O
as	O
input	O
.	O
	
This	O
might	O
contain	O
,	O
say	O
,	O
information	O
about	O
the	O
class	O
of	O
the	O
training	O
example	O
.	O
	
The	O
authors	O
apply	O
CGAN	B-Method
to	O
generate	O
a	O
(	O
possibly	O
multi	O
-	O
modal	O
)	O
distribution	O
of	O
tag	O
-	O
vectors	O
conditional	O
on	O
image	O
features	O
.	O
	
Recently	O
the	O
CoGAN	B-Method
approach	I-Method
applied	O
GANs	B-Method
to	O
the	O
domain	B-Task
transfer	I-Task
problem	I-Task
by	O
training	O
two	O
GANs	B-Method
to	O
generate	O
the	O
source	O
and	O
target	O
images	O
respectively	O
.	O
	
The	O
approach	O
achieves	O
a	O
domain	O
invariant	O
feature	O
space	O
by	O
tying	O
the	O
high	O
-	O
level	O
layer	O
parameters	O
of	O
the	O
two	O
GANs	B-Method
,	O
and	O
shows	O
that	O
the	O
same	O
noise	O
input	O
can	O
generate	O
a	O
corresponding	O
pair	O
of	O
images	O
from	O
the	O
two	O
distributions	O
.	O
	
Domain	B-Method
adaptation	I-Method
was	O
performed	O
by	O
training	O
a	O
classifier	B-Method
on	O
the	O
discriminator	O
output	O
and	O
applied	O
to	O
shifts	O
between	O
the	O
MNIST	B-Material
and	O
USPS	B-Material
digit	O
datasets	O
.	O
	
However	O
,	O
this	O
approach	O
relies	O
on	O
the	O
generators	O
finding	O
a	O
mapping	O
from	O
the	O
shared	O
high	O
-	O
level	O
layer	O
feature	O
space	O
to	O
full	O
images	O
in	O
both	O
domains	O
.	O
	
This	O
can	O
work	O
well	O
for	O
say	O
digits	O
which	O
can	O
be	O
difficult	O
in	O
the	O
case	O
of	O
more	O
distinct	O
domains	O
.	O
	
In	O
this	O
paper	O
,	O
we	O
observe	O
that	O
modeling	O
the	O
image	O
distributions	O
is	O
not	O
strictly	O
necessary	O
to	O
achieve	O
domain	B-Task
adaptation	I-Task
,	O
as	O
long	O
as	O
the	O
latent	O
feature	O
space	O
is	O
domain	O
invariant	O
,	O
and	O
propose	O
a	O
discriminative	B-Method
approach	I-Method
.	O
	
section	O
:	O
Generalized	B-Method
adversarial	I-Method
adaptation	I-Method
	
We	O
present	O
a	O
general	O
framework	O
for	O
adversarial	B-Method
unsupervised	I-Method
adaptation	I-Method
methods	I-Method
.	O
	
In	O
unsupervised	B-Task
adaptation	I-Task
,	O
we	O
assume	O
access	O
to	O
source	O
images	O
and	O
labels	O
drawn	O
from	O
a	O
source	O
domain	O
distribution	O
,	O
as	O
well	O
as	O
target	O
images	O
drawn	O
from	O
a	O
target	O
distribution	O
,	O
where	O
there	O
are	O
no	O
label	O
observations	O
.	O
	
Our	O
goal	O
is	O
to	O
learn	O
a	O
target	B-Method
representation	I-Method
,	O
and	O
classifier	B-Method
that	O
can	O
correctly	O
classify	O
target	O
images	O
into	O
one	O
of	O
categories	O
at	O
test	O
time	O
,	O
despite	O
the	O
lack	O
of	O
in	O
domain	O
annotations	O
.	O
	
Since	O
direct	O
supervised	B-Task
learning	I-Task
on	O
the	O
target	O
is	O
not	O
possible	O
,	O
domain	B-Task
adaptation	I-Task
instead	O
learns	O
a	O
source	B-Method
representation	I-Method
mapping	I-Method
,	O
,	O
along	O
with	O
a	O
source	B-Method
classifier	I-Method
,	O
,	O
and	O
then	O
learns	O
to	O
adapt	O
that	O
model	O
for	O
use	O
in	O
the	O
target	O
domain	O
.	O
	
In	O
adversarial	B-Method
adaptive	I-Method
methods	I-Method
,	O
the	O
main	O
goal	O
is	O
to	O
regularize	O
the	O
learning	O
of	O
the	O
source	O
and	O
target	O
mappings	O
,	O
and	O
,	O
so	O
as	O
to	O
minimize	O
the	O
distance	O
between	O
the	O
empirical	O
source	O
and	O
target	O
mapping	O
distributions	O
:	O
and	O
.	O
	
If	O
this	O
is	O
the	O
case	O
then	O
the	O
source	B-Method
classification	I-Method
model	I-Method
,	O
,	O
can	O
be	O
directly	O
applied	O
to	O
the	O
target	O
representations	O
,	O
elimating	O
the	O
need	O
to	O
learn	O
a	O
separate	O
target	B-Method
classifier	I-Method
and	O
instead	O
setting	O
,	O
.	O
	
The	O
source	B-Method
classification	I-Method
model	I-Method
is	O
then	O
trained	O
using	O
the	O
standard	O
supervised	B-Method
loss	I-Method
below	O
:	O
We	O
are	O
now	O
able	O
to	O
describe	O
our	O
full	O
general	O
framework	O
view	O
of	O
adversarial	B-Method
adaptation	I-Method
approaches	I-Method
.	O
	
We	O
note	O
that	O
all	O
approaches	O
minimize	O
source	O
and	O
target	O
representation	O
distances	O
through	O
alternating	B-Method
minimization	I-Method
between	O
two	O
functions	O
.	O
	
First	O
a	O
domain	B-Method
discriminator	I-Method
,	O
,	O
which	O
classifies	O
whether	O
a	O
data	O
point	O
is	O
drawn	O
from	O
the	O
source	O
or	O
the	O
target	O
domain	O
.	O
	
Thus	O
,	O
is	O
optimized	O
according	O
to	O
a	O
standard	O
supervised	O
loss	O
,	O
where	O
the	O
labels	O
indicate	O
the	O
origin	O
domain	O
,	O
defined	O
below	O
:	O
Second	O
,	O
the	O
source	O
and	O
target	O
mappings	O
are	O
optimized	O
according	O
to	O
a	O
constrained	B-Method
adversarial	I-Method
objective	I-Method
,	O
whose	O
particular	O
instantiation	O
may	O
vary	O
across	O
methods	O
.	O
	
Thus	O
,	O
we	O
can	O
derive	O
a	O
generic	B-Method
formulation	I-Method
for	O
domain	B-Method
adversarial	I-Method
techniques	I-Method
below	O
:	O
	
In	O
the	O
next	O
sections	O
,	O
we	O
demonstrate	O
the	O
value	O
of	O
our	O
framework	O
by	O
positioning	O
recent	O
domain	B-Method
adversarial	I-Method
approaches	I-Method
within	O
our	O
framework	O
.	O
	
We	O
describe	O
the	O
potential	O
mapping	O
structure	O
,	O
mapping	O
optimization	O
constraints	O
(	O
)	O
choices	O
and	O
finally	O
choices	O
of	O
adversarial	O
mapping	O
loss	O
,	O
.	O
	
subsection	O
:	O
Source	O
and	O
target	O
mappings	O
	
In	O
the	O
case	O
of	O
learning	O
a	O
source	B-Task
mapping	I-Task
alone	O
it	O
is	O
clear	O
that	O
supervised	B-Method
training	I-Method
through	O
a	O
latent	B-Method
space	I-Method
discriminative	I-Method
loss	I-Method
using	O
the	O
known	O
labels	O
results	O
in	O
the	O
best	O
representation	O
for	O
final	O
source	B-Task
recognition	I-Task
.	O
	
However	O
,	O
given	O
that	O
our	O
target	O
domain	O
is	O
unlabeled	O
,	O
it	O
remains	O
an	O
open	O
question	O
how	O
best	O
to	O
minimize	O
the	O
distance	O
between	O
the	O
source	O
and	O
target	O
mappings	O
.	O
	
Thus	O
the	O
first	O
choice	O
to	O
be	O
made	O
is	O
in	O
the	O
particular	O
parameterization	O
of	O
these	O
mappings	O
.	O
	
Because	O
unsupervised	B-Task
domain	I-Task
adaptation	I-Task
generally	O
considers	O
target	B-Task
discriminative	I-Task
tasks	I-Task
such	O
as	O
classification	B-Task
,	O
previous	O
adaptation	B-Method
methods	I-Method
have	O
generally	O
relied	O
on	O
adapting	O
discriminative	B-Method
models	I-Method
between	O
domains	O
.	O
	
With	O
a	O
discriminative	B-Method
base	I-Method
model	I-Method
,	O
input	O
images	O
are	O
mapped	O
into	O
a	O
feature	O
space	O
that	O
is	O
useful	O
for	O
a	O
discriminative	B-Task
task	I-Task
such	O
as	O
image	B-Task
classification	I-Task
.	O
	
For	O
example	O
,	O
in	O
the	O
case	O
of	O
digit	B-Task
classification	I-Task
this	O
may	O
be	O
the	O
standard	O
LeNet	B-Method
model	I-Method
.	O
	
However	O
,	O
Liu	O
and	O
Tuzel	O
achieve	O
state	O
of	O
the	O
art	O
results	O
on	O
unsupervised	O
MNIST	B-Material
-	O
USPS	B-Material
using	O
two	O
generative	B-Method
adversarial	I-Method
networks	I-Method
.	O
	
These	O
generative	B-Method
models	I-Method
use	O
random	O
noise	O
as	O
input	O
to	O
generate	O
samples	O
in	O
image	O
space	O
	
—	O
generally	O
,	O
an	O
intermediate	O
feature	O
of	O
an	O
adversarial	B-Method
discriminator	I-Method
is	O
then	O
used	O
as	O
a	O
feature	O
for	O
training	O
a	O
task	B-Method
-	I-Method
specific	I-Method
classifier	I-Method
.	O
	
Once	O
the	O
mapping	O
parameterization	O
is	O
determined	O
for	O
the	O
source	O
,	O
we	O
must	O
decide	O
how	O
to	O
parametrize	O
the	O
target	O
mapping	O
.	O
	
In	O
general	O
,	O
the	O
target	O
mapping	O
almost	O
always	O
matches	O
the	O
source	O
in	O
terms	O
of	O
the	O
specific	O
functional	O
layer	O
(	O
architecture	O
)	O
,	O
but	O
different	O
methods	O
have	O
proposed	O
various	O
regularization	B-Method
techniques	I-Method
.	O
	
All	O
methods	O
initialize	O
the	O
target	O
mapping	O
parameters	O
with	O
the	O
source	O
,	O
but	O
different	O
methods	O
choose	O
different	O
constraints	O
between	O
the	O
source	O
and	O
target	O
mappings	O
,	O
.	O
	
The	O
goal	O
is	O
to	O
make	O
sure	O
that	O
the	O
target	O
mapping	O
is	O
set	O
so	O
as	O
to	O
minimize	O
the	O
distance	O
between	O
the	O
source	O
and	O
target	O
domains	O
under	O
their	O
respective	O
mappings	O
,	O
while	O
crucially	O
also	O
maintaining	O
a	O
target	O
mapping	O
that	O
is	O
category	O
discriminative	O
.	O
	
Consider	O
a	O
layered	B-Method
representations	I-Method
where	O
each	O
layer	O
parameters	O
are	O
denoted	O
as	O
,	O
or	O
,	O
for	O
a	O
given	O
set	O
of	O
equivalent	O
layers	O
,	O
.	O
	
Then	O
the	O
space	O
of	O
constraints	O
explored	O
in	O
the	O
literature	O
can	O
be	O
described	O
through	O
layerwise	O
equality	O
constraints	O
as	O
follows	O
:	O
where	O
each	O
individual	O
layer	O
can	O
be	O
constrained	O
independently	O
.	O
	
A	O
very	O
common	O
form	O
of	O
constraint	O
is	O
source	O
and	O
target	O
layerwise	O
equality	O
:	O
It	O
is	O
also	O
common	O
to	O
leave	O
layers	O
unconstrained	O
.	O
	
These	O
equality	O
constraints	O
can	O
easily	O
be	O
imposed	O
within	O
a	O
convolutional	B-Method
network	I-Method
framework	I-Method
through	O
weight	B-Method
sharing	I-Method
.	O
	
For	O
many	O
prior	B-Method
adversarial	I-Method
adaptation	I-Method
methods	I-Method
,	O
all	O
layers	O
are	O
constrained	O
,	O
thus	O
enforcing	O
exact	O
source	O
and	O
target	O
mapping	O
consistency	O
.	O
	
Learning	O
a	O
symmetric	B-Method
transformation	I-Method
reduces	O
the	O
number	O
of	O
parameters	O
in	O
the	O
model	O
and	O
ensures	O
that	O
the	O
mapping	O
used	O
for	O
the	O
target	O
is	O
discriminative	O
at	O
least	O
when	O
applied	O
to	O
the	O
source	O
domain	O
.	O
	
However	O
,	O
this	O
may	O
make	O
the	O
optimization	B-Task
poorly	O
conditioned	O
,	O
since	O
the	O
same	O
network	O
must	O
handle	O
images	O
from	O
two	O
separate	O
domains	O
.	O
	
An	O
alternative	O
approach	O
is	O
instead	O
to	O
learn	O
an	O
asymmetric	B-Method
transformation	I-Method
with	O
only	O
a	O
subset	O
of	O
the	O
layers	O
constrained	O
,	O
thus	O
enforcing	O
partial	O
alignment	O
.	O
	
Rozantsev	O
et	O
al	O
.	O
showed	O
that	O
partially	O
shared	O
weights	O
can	O
lead	O
to	O
effective	O
adaptation	B-Task
in	O
both	O
supervised	B-Task
and	I-Task
unsupervised	I-Task
settings	I-Task
.	O
	
As	O
a	O
result	O
,	O
some	O
recent	O
methods	O
have	O
favored	O
untying	O
weights	O
(	O
fully	O
or	O
partially	O
)	O
between	O
the	O
two	O
domains	O
,	O
allowing	O
models	O
to	O
learn	O
parameters	O
for	O
each	O
domain	O
individually	O
.	O
	
subsection	O
:	O
Adversarial	O
losses	O
	
Once	O
we	O
have	O
decided	O
on	O
a	O
parametrization	O
of	O
,	O
we	O
employ	O
an	O
adversarial	B-Method
loss	I-Method
to	O
learn	O
the	O
actual	O
mapping	O
.	O
	
There	O
are	O
various	O
different	O
possible	O
choices	O
of	O
adversarial	O
loss	O
functions	O
,	O
each	O
of	O
which	O
have	O
their	O
own	O
unique	O
use	O
cases	O
.	O
	
All	O
adversarial	B-Method
losses	I-Method
train	O
the	O
adversarial	B-Method
discriminator	I-Method
using	O
a	O
standard	O
classification	B-Method
loss	I-Method
,	O
,	O
previously	O
stated	O
in	O
Equation	O
[	O
reference	O
]	O
.	O
	
However	O
,	O
they	O
differ	O
in	O
the	O
loss	O
used	O
to	O
train	O
the	O
mapping	B-Task
,	O
.	O
	
The	O
gradient	B-Method
reversal	I-Method
layer	I-Method
of	O
optimizes	O
the	O
mapping	B-Method
to	O
maximize	O
the	O
discriminator	O
loss	O
directly	O
:	O
This	O
optimization	O
corresponds	O
to	O
the	O
true	O
minimax	B-Metric
objective	I-Metric
for	O
generative	B-Method
adversarial	I-Method
networks	I-Method
.	O
	
However	O
,	O
this	O
objective	O
can	O
be	O
problematic	O
,	O
since	O
early	O
on	O
during	O
training	O
the	O
discriminator	B-Method
converges	O
quickly	O
,	O
causing	O
the	O
gradient	O
to	O
vanish	O
.	O
	
When	O
training	O
GANs	B-Method
,	O
rather	O
than	O
directly	O
using	O
the	O
minimax	B-Method
loss	I-Method
,	O
it	O
is	O
typical	O
to	O
train	O
the	O
generator	B-Method
with	O
the	O
standard	O
loss	O
function	O
with	O
inverted	O
labels	O
.	O
	
This	O
splits	O
the	O
optimization	B-Task
into	O
two	O
independent	O
objectives	O
,	O
one	O
for	O
the	O
generator	B-Method
and	O
one	O
for	O
the	O
discriminator	B-Method
,	O
where	O
remains	O
unchanged	O
,	O
but	O
becomes	O
:	O
This	O
objective	O
has	O
the	O
same	O
fixed	O
-	O
point	O
properties	O
as	O
the	O
minimax	O
loss	O
but	O
provides	O
stronger	O
gradients	O
to	O
the	O
target	O
mapping	O
.	O
	
We	O
refer	O
to	O
this	O
modified	O
loss	O
function	O
as	O
the	O
“	O
GAN	B-Method
loss	O
function	O
”	O
for	O
the	O
remainder	O
of	O
this	O
paper	O
.	O
	
Note	O
that	O
,	O
in	O
this	O
setting	O
,	O
we	O
use	O
independent	O
mappings	O
for	O
source	O
and	O
target	O
and	O
learn	O
only	O
adversarially	O
.	O
	
This	O
mimics	O
the	O
GAN	B-Method
setting	O
,	O
where	O
the	O
real	O
image	O
distribution	O
remains	O
fixed	O
,	O
and	O
the	O
generating	O
distribution	O
is	O
learned	O
to	O
match	O
it	O
.	O
	
The	O
GAN	B-Method
loss	O
function	O
is	O
the	O
standard	O
choice	O
in	O
the	O
setting	O
where	O
the	O
generator	O
is	O
attempting	O
to	O
mimic	O
another	O
unchanging	O
distribution	O
.	O
	
However	O
,	O
in	O
the	O
setting	O
where	O
both	O
distributions	O
are	O
changing	O
,	O
this	O
objective	O
will	O
lead	O
to	O
oscillation	O
—	O
when	O
the	O
mapping	O
converges	O
to	O
its	O
optimum	O
,	O
the	O
discriminator	B-Method
can	O
simply	O
flip	O
the	O
sign	O
of	O
its	O
prediction	O
in	O
response	O
.	O
	
Tzeng	O
et	O
al	O
.	O
instead	O
proposed	O
the	O
domain	B-Task
confusion	I-Task
objective	I-Task
,	O
under	O
which	O
the	O
mapping	B-Method
is	O
trained	O
using	O
a	O
cross	B-Method
-	I-Method
entropy	I-Method
loss	I-Method
function	I-Method
against	O
a	O
uniform	O
distribution	O
:	O
This	O
loss	O
ensures	O
that	O
the	O
adversarial	B-Method
discriminator	I-Method
views	O
the	O
two	O
domains	O
identically	O
.	O
	
section	O
:	O
Adversarial	B-Task
discriminative	I-Task
domain	I-Task
adaptation	I-Task
	
The	O
benefit	O
of	O
our	O
generalized	O
framework	O
for	O
domain	B-Method
adversarial	I-Method
methods	I-Method
is	O
that	O
it	O
directly	O
enables	O
the	O
development	O
of	O
novel	O
adaptive	B-Method
methods	I-Method
.	O
	
In	O
fact	O
,	O
designing	O
a	O
new	O
method	O
has	O
now	O
been	O
simplified	O
to	O
the	O
space	O
of	O
making	O
three	O
design	O
choices	O
:	O
whether	O
to	O
use	O
a	O
generative	B-Method
or	I-Method
discriminative	I-Method
base	I-Method
model	I-Method
,	O
whether	O
to	O
tie	O
or	O
untie	O
the	O
weights	O
,	O
and	O
which	O
adversarial	B-Method
learning	I-Method
objective	I-Method
to	O
use	O
.	O
	
In	O
light	O
of	O
this	O
view	O
we	O
can	O
summarize	O
our	O
method	O
,	O
adversarial	B-Method
discriminative	I-Method
domain	I-Method
adaptation	I-Method
(	O
ADDA	B-Method
)	O
,	O
as	O
well	O
as	O
its	O
connection	O
to	O
prior	O
work	O
,	O
according	O
to	O
our	O
choices	O
(	O
see	O
Table	O
[	O
reference	O
]	O
	
“	O
ADDA	B-Method
”	O
)	O
.	O
	
Specifically	O
,	O
we	O
use	O
a	O
discriminative	B-Method
base	I-Method
model	I-Method
,	O
unshared	O
weights	O
,	O
and	O
the	O
standard	O
GAN	B-Method
loss	O
.	O
	
We	O
illustrate	O
our	O
overall	O
sequential	B-Method
training	I-Method
procedure	I-Method
in	O
Figure	O
[	O
reference	O
]	O
.	O
	
First	O
,	O
we	O
choose	O
a	O
discriminative	B-Method
base	I-Method
model	I-Method
,	O
as	O
we	O
hypothesize	O
that	O
much	O
of	O
the	O
parameters	O
required	O
to	O
generate	O
convincing	O
in	O
-	O
domain	O
samples	O
are	O
irrelevant	O
for	O
discriminative	B-Task
adaptation	I-Task
tasks	I-Task
.	O
	
Most	O
prior	O
adversarial	B-Method
adaptive	I-Method
methods	I-Method
optimize	O
directly	O
in	O
a	O
discriminative	O
space	O
for	O
this	O
reason	O
.	O
	
One	O
counter	O
-	O
example	O
is	O
CoGANs	O
.	O
	
However	O
,	O
this	O
method	O
has	O
only	O
shown	O
dominance	O
in	O
settings	O
where	O
the	O
source	O
and	O
target	O
domain	O
are	O
very	O
similar	O
such	O
as	O
MNIST	B-Material
and	O
USPS	B-Material
,	O
and	O
in	O
our	O
experiments	O
we	O
have	O
had	O
difficulty	O
getting	O
it	O
to	O
converge	O
for	O
larger	O
distribution	O
shifts	O
.	O
	
Next	O
,	O
we	O
choose	O
to	O
allow	O
independent	O
source	O
and	O
target	O
mappings	O
by	O
untying	O
the	O
weights	O
.	O
	
This	O
is	O
a	O
more	O
flexible	O
learing	B-Method
paradigm	I-Method
as	O
it	O
allows	O
more	O
domain	B-Task
specific	I-Task
feature	I-Task
extraction	I-Task
to	O
be	O
learned	O
.	O
	
However	O
,	O
note	O
that	O
the	O
target	O
domain	O
has	O
no	O
label	O
access	O
,	O
and	O
thus	O
without	O
weight	B-Method
sharing	I-Method
a	O
target	B-Method
model	I-Method
may	O
quickly	O
learn	O
a	O
degenerate	O
solution	O
if	O
we	O
do	O
not	O
take	O
care	O
with	O
proper	O
initialization	B-Method
and	I-Method
training	I-Method
procedures	I-Method
.	O
	
Therefore	O
,	O
we	O
use	O
the	O
pre	O
-	O
trained	O
source	B-Method
model	I-Method
as	O
an	O
intitialization	B-Method
for	O
the	O
target	O
representation	O
space	O
and	O
fix	O
the	O
source	B-Method
model	I-Method
during	O
adversarial	B-Task
training	I-Task
.	O
	
In	O
doing	O
so	O
,	O
we	O
are	O
effectively	O
learning	O
an	O
asymmetric	B-Method
mapping	I-Method
,	O
in	O
which	O
we	O
modify	O
the	O
target	O
model	O
so	O
as	O
to	O
match	O
the	O
source	O
distribution	O
.	O
	
This	O
is	O
most	O
similar	O
to	O
the	O
original	O
generative	B-Method
adversarial	I-Method
learning	I-Method
setting	I-Method
,	O
where	O
a	O
generated	O
space	O
is	O
updated	O
until	O
it	O
is	O
indistinguishable	O
with	O
a	O
fixed	O
real	O
space	O
.	O
	
Therefore	O
,	O
we	O
choose	O
the	O
inverted	O
label	O
GAN	B-Method
loss	O
described	O
in	O
the	O
previous	O
section	O
.	O
	
Our	O
proposed	O
method	O
,	O
ADDA	B-Method
,	O
thus	O
corresponds	O
to	O
the	O
following	O
unconstrained	B-Task
optimization	I-Task
:	O
We	O
choose	O
to	O
optimize	O
this	O
objective	O
in	O
stages	O
.	O
	
We	O
begin	O
by	O
optimizing	O
over	O
and	O
by	O
training	O
using	O
the	O
labeled	O
source	O
data	O
,	O
and	O
.	O
	
Because	O
we	O
have	O
opted	O
to	O
leave	O
fixed	O
while	O
learning	B-Task
,	O
we	O
can	O
thus	O
optimize	O
and	O
without	O
revisiting	O
the	O
first	O
objective	O
term	O
.	O
	
A	O
summary	O
of	O
this	O
entire	O
training	O
process	O
is	O
provided	O
in	O
Figure	O
[	O
reference	O
]	O
.	O
	
We	O
note	O
that	O
the	O
unified	O
framework	O
presented	O
in	O
the	O
previous	O
section	O
has	O
enabled	O
us	O
to	O
compare	O
prior	B-Method
domain	I-Method
adversarial	I-Method
methods	I-Method
and	O
make	O
informed	O
decisions	O
about	O
the	O
different	O
factors	O
of	O
variation	O
.	O
	
Through	O
this	O
framework	O
we	O
are	O
able	O
to	O
motivate	O
a	O
novel	O
domain	B-Method
adaptation	I-Method
method	I-Method
,	O
ADDA	B-Method
,	O
and	O
offer	O
insight	O
into	O
our	O
design	O
decisions	O
.	O
	
In	O
the	O
next	O
section	O
we	O
demonstrate	O
promising	O
results	O
on	O
unsupervised	B-Task
adaptation	I-Task
benchmark	I-Task
tasks	I-Task
,	O
studying	O
adaptation	B-Task
across	O
digits	O
and	O
across	O
modalities	O
.	O
	
section	O
:	O
Experiments	O
	
We	O
now	O
evaluate	O
ADDA	B-Method
for	O
unsupervised	B-Task
classification	I-Task
adaptation	I-Task
across	O
four	O
different	O
domain	O
shifts	O
.	O
	
We	O
explore	O
three	O
digits	O
datasets	O
of	O
varying	O
difficulty	O
:	O
MNIST	B-Material
,	O
USPS	B-Material
,	O
and	O
SVHN	B-Material
.	O
	
We	O
additionally	O
evaluate	O
on	O
the	O
NYUD	B-Material
dataset	I-Material
to	O
study	O
adaptation	O
across	O
modalities	O
.	O
	
Example	O
images	O
from	O
all	O
experimental	O
datasets	O
are	O
provided	O
in	O
Figure	O
[	O
reference	O
]	O
.	O
	
For	O
the	O
case	O
of	O
digit	B-Task
adaptation	I-Task
,	O
we	O
compare	O
against	O
multiple	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
unsupervised	B-Method
adaptation	I-Method
methods	I-Method
,	O
all	O
based	O
upon	O
domain	B-Method
adversarial	I-Method
learning	I-Method
objectives	I-Method
.	O
	
In	O
3	O
of	O
4	O
of	O
our	O
experimental	O
setups	O
,	O
our	O
method	O
outperforms	O
all	O
competing	O
approaches	O
,	O
and	O
in	O
the	O
last	O
domain	O
shift	O
studied	O
,	O
our	O
approach	O
outperforms	O
all	O
but	O
one	O
competing	O
approach	O
.	O
	
We	O
also	O
validate	O
our	O
model	O
on	O
a	O
real	B-Task
-	I-Task
world	I-Task
modality	I-Task
adaptation	I-Task
task	I-Task
using	O
the	O
NYU	B-Material
depth	I-Material
dataset	I-Material
.	O
	
Despite	O
a	O
large	O
domain	O
shift	O
between	O
the	O
RGB	B-Material
and	O
depth	O
modalities	O
,	O
ADDA	B-Method
learns	O
a	O
useful	O
depth	B-Method
representation	I-Method
without	O
any	O
labeled	O
depth	O
data	O
and	O
improves	O
over	O
the	O
nonadaptive	O
baseline	O
by	O
over	O
50	O
%	O
(	O
relative	O
)	O
.	O
	
subsection	O
:	O
MNIST	B-Material
,	O
USPS	B-Material
,	O
and	O
SVHN	B-Material
digits	O
datasets	O
	
We	O
experimentally	O
validate	O
our	O
proposed	O
method	O
in	O
an	O
unsupervised	B-Task
adaptation	I-Task
task	I-Task
between	O
the	O
MNIST	B-Material
,	O
USPS	B-Material
,	O
and	O
SVHN	B-Material
digits	O
datasets	O
,	O
which	O
consist	O
10	O
classes	O
of	O
digits	O
.	O
	
Example	O
images	O
from	O
each	O
dataset	O
are	O
visualized	O
in	O
Figure	O
[	O
reference	O
]	O
and	O
Table	O
[	O
reference	O
]	O
.	O
	
For	O
adaptation	B-Task
between	O
MNIST	B-Material
and	O
USPS	B-Material
,	O
we	O
follow	O
the	O
training	O
protocol	O
established	O
in	O
,	O
sampling	O
2000	O
images	O
from	O
MNIST	B-Material
and	O
1800	O
from	O
USPS	B-Material
.	O
	
For	O
adaptation	B-Task
between	O
SVHN	B-Material
and	I-Material
MNIST	I-Material
,	O
we	O
use	O
the	O
full	O
training	O
sets	O
for	O
comparison	O
against	O
.	O
	
All	O
experiments	O
are	O
performed	O
in	O
the	O
unsupervised	B-Task
settings	I-Task
,	O
where	O
labels	O
in	O
the	O
target	O
domain	O
are	O
withheld	O
,	O
and	O
we	O
consider	O
adaptation	B-Task
in	O
three	O
directions	O
:	O
MNIST	B-Material
USPS	I-Material
,	O
USPS	B-Material
MNIST	I-Material
,	O
and	O
SVHN	B-Material
MNIST	I-Material
.	O
	
For	O
these	O
experiments	O
,	O
we	O
use	O
the	O
simple	O
modified	B-Method
LeNet	I-Method
architecture	I-Method
provided	O
in	O
the	O
Caffe	B-Method
source	I-Method
code	I-Method
.	O
	
When	O
training	O
with	O
ADDA	B-Method
,	O
our	O
adversarial	B-Method
discriminator	I-Method
consists	O
of	O
3	O
fully	B-Method
connected	I-Method
layers	I-Method
:	O
two	O
layers	O
with	O
500	O
hidden	O
units	O
followed	O
by	O
the	O
final	O
discriminator	O
output	O
.	O
	
Each	O
of	O
the	O
500	B-Method
-	I-Method
unit	I-Method
layers	I-Method
uses	O
a	O
ReLU	B-Method
activation	I-Method
function	I-Method
.	O
	
Results	O
of	O
our	O
experiment	O
are	O
provided	O
in	O
Table	O
[	O
reference	O
]	O
.	O
	
On	O
the	O
easier	O
MNIST	B-Material
and	O
USPS	B-Material
shifts	O
ADDA	B-Method
achieves	O
comparable	O
performance	O
to	O
the	O
current	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
,	O
CoGANs	B-Method
,	O
despite	O
being	O
a	O
considerably	O
simpler	O
model	O
.	O
	
This	O
provides	O
compelling	O
evidence	O
that	O
the	O
machinery	O
required	O
to	O
generate	O
images	O
is	O
largely	O
irrelevant	O
to	O
enabling	O
effective	O
adaptation	B-Task
.	O
	
Additionally	O
,	O
we	O
show	O
convincing	O
results	O
on	O
the	O
challenging	O
SVHN	B-Material
and	O
MNIST	B-Material
task	O
in	O
comparison	O
to	O
other	O
methods	O
,	O
indicating	O
that	O
our	O
method	O
has	O
the	O
potential	O
to	O
generalize	O
to	O
a	O
variety	O
of	O
settings	O
.	O
	
In	O
contrast	O
,	O
we	O
were	O
unable	O
to	O
get	O
CoGANs	B-Method
to	O
converge	O
on	O
SVHN	B-Material
and	O
MNIST	B-Material
—	O
because	O
the	O
domains	O
are	O
so	O
disparate	O
,	O
we	O
were	O
unable	O
to	O
train	O
coupled	B-Method
generators	I-Method
for	O
them	O
.	O
	
subsection	O
:	O
Modality	B-Task
adaptation	I-Task
	
bathtub	O
bed	O
bookshelf	O
box	O
chair	O
counter	O
desk	O
door	O
dresser	O
garbage	O
bin	O
lamp	O
monitor	O
night	O
stand	O
pillow	O
sink	O
sofa	O
table	O
television	O
toilet	O
overall	O
	
We	O
use	O
the	O
NYU	B-Material
depth	I-Material
dataset	I-Material
,	O
which	O
contains	O
bounding	O
box	O
annotations	O
for	O
19	O
object	O
classes	O
in	O
1449	O
images	O
from	O
indoor	O
scenes	O
.	O
	
The	O
dataset	O
is	O
split	O
into	O
a	O
train	O
(	O
381	O
images	O
)	O
,	O
val	O
(	O
414	O
images	O
)	O
and	O
test	O
(	O
654	O
)	O
sets	O
.	O
	
To	O
perform	O
our	O
cross	B-Method
-	I-Method
modality	I-Method
adaptation	I-Method
,	O
we	O
first	O
crop	O
out	O
tight	O
bounding	O
boxes	O
around	O
instances	O
of	O
these	O
19	O
classes	O
present	O
in	O
the	O
dataset	O
and	O
evaluate	O
on	O
a	O
19	B-Task
-	I-Task
way	I-Task
classification	I-Task
task	I-Task
over	O
object	B-Task
crops	I-Task
.	O
	
In	O
order	O
to	O
ensure	O
that	O
the	O
same	O
instance	O
is	O
not	O
seen	O
in	O
both	O
domains	O
,	O
we	O
use	O
the	O
RGB	B-Material
images	O
from	O
the	O
train	O
split	O
as	O
the	O
source	O
domain	O
and	O
the	O
depth	O
images	O
from	O
the	O
val	O
split	O
as	O
the	O
target	O
domain	O
.	O
	
This	O
corresponds	O
to	O
2	O
,	O
186	O
labeled	O
source	O
images	O
and	O
2	O
,	O
401	O
unlabeled	O
target	O
images	O
.	O
	
Figure	O
[	O
reference	O
]	O
visualizes	O
samples	O
from	O
each	O
of	O
the	O
two	O
domains	O
.	O
	
We	O
consider	O
the	O
task	O
of	O
adaptation	B-Task
between	O
these	O
RGB	B-Material
and	O
HHA	B-Material
encoded	I-Material
depth	I-Material
images	I-Material
,	O
using	O
them	O
as	O
source	O
and	O
target	O
domains	O
respectively	O
.	O
	
Because	O
the	O
bounding	O
boxes	O
are	O
tight	O
and	O
relatively	O
low	O
resolution	O
,	O
accurate	O
classification	B-Task
is	O
quite	O
difficult	O
,	O
even	O
when	O
evaluating	O
in	B-Task
-	I-Task
domain	I-Task
.	O
	
In	O
addition	O
,	O
the	O
dataset	O
has	O
very	O
few	O
examples	O
for	O
certain	O
classes	O
,	O
such	O
as	O
toilet	O
and	O
bathtub	O
,	O
which	O
directly	O
translates	O
to	O
reduced	O
classification	B-Metric
performance	I-Metric
.	O
	
For	O
this	O
experiment	O
,	O
our	O
base	O
architecture	O
is	O
the	O
VGG	B-Method
-	I-Method
16	I-Method
architecture	I-Method
,	O
initializing	O
from	O
weights	O
pretrained	O
on	O
ImageNet	B-Material
.	O
	
This	O
network	O
is	O
then	O
fully	O
fine	O
-	O
tuned	O
on	O
the	O
source	O
domain	O
for	O
20	O
,	O
000	O
iterations	O
using	O
a	O
batch	O
size	O
of	O
128	O
.	O
	
When	O
training	O
with	O
ADDA	B-Method
,	O
the	O
adversarial	B-Method
discriminator	I-Method
consists	O
of	O
three	O
additional	O
fully	B-Method
connected	I-Method
layers	I-Method
:	O
1024	O
hidden	O
units	O
,	O
2048	O
hidden	O
units	O
,	O
then	O
the	O
adversarial	B-Method
discriminator	I-Method
output	O
.	O
	
With	O
the	O
exception	O
of	O
the	O
output	O
,	O
these	O
additionally	O
fully	B-Method
connected	I-Method
layers	I-Method
use	O
a	O
ReLU	B-Method
activation	I-Method
function	I-Method
.	O
	
ADDA	B-Method
training	O
then	O
proceeds	O
for	O
another	O
20	O
,	O
000	O
iterations	O
,	O
again	O
with	O
a	O
batch	O
size	O
of	O
128	O
.	O
	
We	O
find	O
that	O
our	O
method	O
,	O
ADDA	B-Method
,	O
greatly	O
improves	O
classification	B-Metric
accuracy	I-Metric
for	O
this	O
task	O
.	O
	
For	O
certain	O
categories	O
,	O
like	O
counter	O
,	O
classification	B-Metric
accuracy	I-Metric
goes	O
from	O
2.9	O
%	O
under	O
the	O
source	O
only	O
baseline	O
up	O
to	O
44.7	O
%	O
after	O
adaptation	B-Method
.	O
	
In	O
general	O
,	O
average	O
accuracy	B-Metric
across	O
all	O
classes	O
improves	O
significantly	O
from	O
13.9	O
%	O
to	O
21.1	O
%	O
.	O
	
However	O
,	O
not	O
all	O
classes	O
improve	O
.	O
	
Three	O
classes	O
have	O
no	O
correctly	O
labeled	O
target	O
images	O
before	O
adaptation	O
,	O
and	O
adaptation	B-Method
is	O
unable	O
to	O
recover	O
performance	O
on	O
these	O
classes	O
.	O
	
Additionally	O
,	O
the	O
classes	O
of	O
pillow	O
and	O
nightstand	O
suffer	O
performance	O
loss	O
after	O
adaptation	B-Task
.	O
	
For	O
additional	O
insight	O
on	O
what	O
effect	O
ADDA	B-Method
has	O
on	O
classification	B-Task
,	O
Figure	O
[	O
reference	O
]	O
plots	O
confusion	O
matrices	O
before	O
adaptation	O
,	O
after	O
adaptation	O
,	O
and	O
in	O
the	O
hypothetical	O
best	B-Task
-	I-Task
case	I-Task
scenario	I-Task
where	O
the	O
target	O
labels	O
are	O
present	O
.	O
	
Examining	O
the	O
confusion	B-Metric
matrix	I-Metric
for	O
the	O
source	O
only	O
baseline	O
reveals	O
that	O
the	O
domain	O
shift	O
is	O
quite	O
large	O
—	O
as	O
a	O
result	O
,	O
the	O
network	O
is	O
poorly	O
conditioned	O
and	O
incorrectly	O
predicts	O
pillow	O
for	O
the	O
majority	O
of	O
the	O
dataset	O
.	O
	
This	O
tendency	O
to	O
output	O
pillow	O
also	O
explains	O
why	O
the	O
source	B-Method
only	I-Method
model	I-Method
achieves	O
such	O
abnormally	O
high	O
accuracy	B-Metric
on	O
the	O
pillow	O
class	O
,	O
despite	O
poor	O
performance	O
on	O
the	O
rest	O
of	O
the	O
classes	O
.	O
	
In	O
contrast	O
,	O
the	O
classifier	B-Method
trained	O
using	O
ADDA	B-Method
predicts	O
a	O
much	O
wider	O
variety	O
of	O
classes	O
.	O
	
This	O
leads	O
to	O
decreased	O
accuracy	B-Metric
for	O
the	O
pillow	O
class	O
,	O
but	O
significantly	O
higher	O
accuracies	B-Metric
for	O
many	O
of	O
the	O
other	O
classes	O
.	O
	
Additionally	O
,	O
comparison	O
with	O
the	O
“	O
train	B-Method
on	I-Method
target	I-Method
”	I-Method
model	I-Method
reveals	O
that	O
many	O
of	O
the	O
mistakes	O
the	O
ADDA	B-Method
model	O
makes	O
are	O
reasonable	O
,	O
such	O
as	O
confusion	O
between	O
the	O
chair	O
and	O
table	O
classes	O
,	O
indicating	O
that	O
the	O
ADDA	B-Method
model	O
is	O
learning	O
a	O
useful	O
representation	O
on	O
depth	O
images	O
.	O
	
section	O
:	O
Conclusion	O
	
We	O
have	O
proposed	O
a	O
unified	O
framework	O
for	O
unsupervised	B-Task
domain	I-Task
adaptation	I-Task
techniques	O
based	O
on	O
adversarial	B-Method
learning	I-Method
objectives	I-Method
.	O
	
Our	O
framework	O
provides	O
a	O
simplified	O
and	O
cohesive	O
view	O
by	O
which	O
we	O
may	O
understand	O
and	O
connect	O
the	O
similarities	O
and	O
differences	O
between	O
recently	O
proposed	O
adaptation	B-Method
methods	I-Method
.	O
	
Through	O
this	O
comparison	O
,	O
we	O
are	O
able	O
to	O
understand	O
the	O
benefits	O
and	O
key	O
ideas	O
from	O
each	O
approach	O
and	O
to	O
combine	O
these	O
strategies	O
into	O
a	O
new	O
adaptation	B-Method
method	I-Method
,	O
ADDA	B-Method
.	O
	
We	O
present	O
evaluation	O
across	O
four	O
domain	O
shifts	O
for	O
our	O
unsupervised	B-Method
adaptation	I-Method
approach	I-Method
.	O
	
Our	O
method	O
generalizes	O
well	O
across	O
a	O
variety	O
of	O
tasks	O
,	O
achieving	O
strong	O
results	O
on	O
benchmark	O
adaptation	O
datasets	O
as	O
well	O
as	O
a	O
challenging	O
cross	B-Task
-	I-Task
modality	I-Task
adaptation	I-Task
task	I-Task
.	O
	
Additional	O
analysis	O
indicates	O
that	O
the	O
representations	O
learned	O
via	O
ADDA	B-Method
resemble	O
features	O
learned	O
with	O
supervisory	O
data	O
in	O
the	O
target	O
domain	O
much	O
more	O
closely	O
than	O
unadapted	O
features	O
,	O
providing	O
further	O
evidence	O
that	O
ADDA	B-Method
is	O
effective	O
at	O
partially	O
undoing	O
the	O
effects	O
of	O
domain	O
shift	O
.	O
	
bibliography	O
:	O
References	O
	
document	O
:	O
Exploiting	O
temporal	O
information	O
for	O
3D	B-Task
human	I-Task
pose	I-Task
estimation	I-Task
	
In	O
this	O
work	O
,	O
we	O
address	O
the	O
problem	O
of	O
3D	B-Task
human	I-Task
pose	I-Task
estimation	I-Task
from	O
a	O
sequence	O
of	O
2D	O
human	O
poses	O
.	O
	
Although	O
the	O
recent	O
success	O
of	O
deep	B-Method
networks	I-Method
has	O
led	O
many	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
methods	O
for	O
3D	B-Task
pose	I-Task
estimation	O
to	O
train	O
deep	B-Method
networks	I-Method
end	O
-	O
to	O
-	O
end	O
to	O
predict	O
from	O
images	O
directly	O
,	O
the	O
top	O
-	O
performing	O
approaches	O
have	O
shown	O
the	O
effectiveness	O
of	O
dividing	O
the	O
task	O
of	O
3D	B-Task
pose	I-Task
estimation	O
into	O
two	O
steps	O
:	O
using	O
a	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
2D	B-Method
pose	I-Method
estimator	I-Method
to	O
estimate	O
the	O
2D	O
pose	O
from	O
images	O
and	O
then	O
mapping	O
them	O
into	O
3D	O
space	O
.	O
	
They	O
also	O
showed	O
that	O
a	O
low	B-Method
-	I-Method
dimensional	I-Method
representation	I-Method
like	O
2D	O
locations	O
of	O
a	O
set	O
of	O
joints	O
can	O
be	O
discriminative	O
enough	O
to	O
estimate	O
3D	B-Task
pose	I-Task
with	O
high	O
accuracy	B-Metric
.	O
	
However	O
,	O
estimation	O
of	O
3D	B-Task
pose	I-Task
for	O
individual	O
frames	O
leads	O
to	O
temporally	O
incoherent	O
estimates	O
due	O
to	O
independent	O
error	B-Metric
in	O
each	O
frame	O
causing	O
jitter	O
.	O
	
Therefore	O
,	O
in	O
this	O
work	O
we	O
utilize	O
the	O
temporal	O
information	O
across	O
a	O
sequence	O
of	O
2D	O
joint	O
locations	O
to	O
estimate	O
a	O
sequence	O
of	O
3D	O
poses	O
.	O
	
We	O
designed	O
a	O
sequence	B-Method
-	I-Method
to	I-Method
-	I-Method
sequence	I-Method
network	I-Method
composed	O
of	O
layer	O
-	O
normalized	O
LSTM	B-Method
units	O
with	O
shortcut	O
connections	O
connecting	O
the	O
input	O
to	O
the	O
output	O
on	O
the	O
decoder	O
side	O
and	O
imposed	O
temporal	O
smoothness	O
constraint	O
during	O
training	O
.	O
	
We	O
found	O
that	O
the	O
knowledge	O
of	O
temporal	O
consistency	O
improves	O
the	O
best	O
reported	O
result	O
on	O
Human3.6	B-Material
M	I-Material
dataset	I-Material
by	O
approximately	O
and	O
helps	O
our	O
network	O
to	O
recover	O
temporally	O
consistent	O
3D	O
poses	O
over	O
a	O
sequence	O
of	O
images	O
even	O
when	O
the	O
2D	B-Method
pose	I-Method
detector	I-Method
fails	O
.	O
	
section	O
:	O
Introduction	O
	
The	O
task	O
of	O
estimating	B-Task
3D	I-Task
human	I-Task
pose	I-Task
from	O
2D	B-Method
representations	I-Method
like	O
monocular	O
images	O
or	O
videos	O
is	O
an	O
open	O
research	O
problem	O
among	O
the	O
computer	B-Task
vision	I-Task
and	I-Task
graphics	I-Task
community	I-Task
for	O
a	O
long	O
time	O
.	O
	
An	O
understanding	B-Task
of	I-Task
human	I-Task
posture	I-Task
and	I-Task
limb	I-Task
articulation	I-Task
is	O
important	O
for	O
high	B-Task
level	I-Task
computer	I-Task
vision	I-Task
tasks	I-Task
such	O
as	O
human	B-Task
action	I-Task
or	I-Task
activity	I-Task
recognition	I-Task
,	O
sports	B-Task
analysis	I-Task
,	O
augmented	B-Task
and	I-Task
virtual	I-Task
reality	I-Task
.	O
	
A	O
2D	B-Method
representation	I-Method
of	I-Method
human	I-Method
pose	I-Method
,	O
which	O
is	O
considered	O
to	O
be	O
much	O
easier	O
to	O
estimate	O
,	O
can	O
be	O
used	O
for	O
these	O
tasks	O
.	O
	
However	O
,	O
2D	O
poses	O
can	O
be	O
ambiguous	O
because	O
of	O
occlusion	O
and	O
foreshortening	O
.	O
	
Additionally	O
poses	O
that	O
are	O
totally	O
different	O
can	O
appear	O
to	O
be	O
similar	O
in	O
2D	O
because	O
of	O
the	O
way	O
they	O
are	O
projected	O
as	O
shown	O
in	O
Figure	O
[	O
reference	O
]	O
.	O
	
The	O
depth	O
information	O
in	O
3D	B-Task
representation	I-Task
of	I-Task
human	I-Task
pose	I-Task
makes	O
it	O
free	O
from	O
such	O
ambiguities	O
and	O
hence	O
can	O
improve	O
performance	O
for	O
higher	O
level	B-Task
tasks	I-Task
.	O
	
Moreover	O
,	O
3D	B-Task
pose	I-Task
can	O
be	O
very	O
useful	O
in	O
computer	B-Task
animation	I-Task
,	O
where	O
the	O
articulated	O
pose	O
of	O
a	O
person	O
in	O
3D	O
can	O
be	O
used	O
to	O
accurately	O
model	O
human	O
posture	O
and	O
movement	O
.	O
	
However	O
,	O
3D	B-Task
pose	I-Task
estimation	O
is	O
an	O
ill	O
-	O
posed	B-Task
problem	I-Task
because	O
of	O
the	O
inherent	O
ambiguity	O
in	O
back	O
-	O
projecting	O
a	O
2D	O
view	O
of	O
an	O
object	O
to	O
the	O
3D	O
space	O
maintaining	O
its	O
structure	O
.	O
	
Since	O
the	O
3D	B-Task
pose	I-Task
of	O
a	O
person	O
can	O
be	O
projected	O
in	O
an	O
infinite	O
number	O
of	O
ways	O
on	O
a	O
2D	O
plane	O
,	O
the	O
mapping	O
from	O
a	O
2D	O
pose	O
to	O
3D	O
is	O
not	O
unique	O
.	O
	
Moreover	O
,	O
obtaining	O
a	O
dataset	O
for	O
3D	B-Task
pose	I-Task
is	O
difficult	O
and	O
expensive	O
.	O
	
Unlike	O
the	O
2D	O
pose	O
datasets	O
where	O
the	O
users	O
can	O
manually	O
label	O
the	O
keypoints	O
by	O
mouse	O
clicks	O
,	O
3D	B-Task
pose	I-Task
datasets	O
require	O
a	O
complicated	O
laboratory	O
setup	O
with	O
motion	O
capture	O
sensors	O
and	O
cameras	O
.	O
	
Hence	O
,	O
there	O
is	O
a	O
lack	O
of	O
motion	O
capture	O
datasets	O
for	O
images	O
in	O
-	O
the	O
-	O
wild	O
.	O
	
Over	O
the	O
years	O
,	O
different	O
techniques	O
have	O
been	O
used	O
to	O
address	O
the	O
problem	O
of	O
3D	B-Task
pose	I-Task
estimation	O
.	O
	
Earlier	O
methods	O
used	O
to	O
focus	O
on	O
extracting	O
features	O
,	O
invariant	O
to	O
factors	O
such	O
as	O
background	O
scenes	O
,	O
lighting	O
,	O
and	O
skin	O
color	O
from	O
images	O
and	O
mapping	O
them	O
into	O
3D	O
human	O
pose	O
.	O
	
With	O
the	O
success	O
of	O
deep	B-Method
networks	I-Method
,	O
recent	O
methods	O
tend	O
to	O
focus	O
on	O
training	O
a	O
deep	B-Method
convolutional	I-Method
neural	I-Method
network	I-Method
(	O
CNN	B-Method
)	O
end	O
-	O
to	O
-	O
end	O
to	O
estimate	O
3D	B-Task
poses	I-Task
from	O
images	O
directly	O
.	O
	
Some	O
approaches	O
divided	O
the	O
3D	B-Task
pose	I-Task
estimation	O
task	O
into	O
first	O
predicting	O
the	O
joint	O
locations	O
in	O
2D	O
using	O
2D	B-Method
pose	I-Method
estimators	I-Method
and	O
then	O
back	O
-	O
projecting	O
them	O
to	O
estimate	O
the	O
3D	O
joint	O
locations	O
.	O
	
These	O
results	O
suggest	O
the	O
effectiveness	O
of	O
decoupling	O
the	O
task	O
of	O
3D	B-Task
pose	I-Task
estimation	O
where	O
2D	B-Method
pose	I-Method
estimator	I-Method
abstracts	O
the	O
complexities	O
in	O
the	O
image	O
.	O
	
In	O
this	O
paper	O
,	O
we	O
also	O
adopt	O
the	O
decoupled	B-Method
approach	I-Method
to	O
3D	B-Task
pose	I-Task
estimation	O
.	O
	
However	O
,	O
predicting	O
3D	B-Task
pose	I-Task
for	O
each	O
frame	O
individually	O
can	O
lead	O
to	O
jitter	O
in	O
videos	O
because	O
the	O
errors	O
in	O
each	O
frame	O
are	O
independent	O
of	O
each	O
other	O
.	O
	
Therefore	O
,	O
we	O
designed	O
a	O
sequence	B-Method
-	I-Method
to	I-Method
-	I-Method
sequence	I-Method
network	I-Method
with	O
shortcut	B-Method
connections	I-Method
on	O
the	O
decoder	O
side	O
that	O
predicts	O
a	O
sequence	O
of	O
temporally	O
consistent	O
3D	O
poses	O
given	O
a	O
sequence	O
of	O
2D	O
poses	O
.	O
	
Each	O
unit	O
of	O
our	O
network	O
is	O
a	O
Long	B-Method
Short	I-Method
-	I-Method
Term	I-Method
Memory	I-Method
(	O
LSTM	B-Method
)	O
unit	O
with	O
layer	B-Method
normalization	I-Method
and	O
recurrent	B-Method
dropout	I-Method
.	O
	
We	O
also	O
imposed	O
a	O
temporal	O
smoothness	O
constraint	O
on	O
the	O
predicted	O
3D	O
poses	O
during	O
training	O
to	O
ensure	O
that	O
our	O
predictions	O
are	O
smooth	O
over	O
a	O
sequence	O
.	O
	
Our	O
network	O
achieves	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
result	O
on	O
the	O
Human3.6	B-Material
M	I-Material
dataset	I-Material
improving	O
the	O
previous	O
best	O
result	O
by	O
approximately	O
.	O
	
We	O
also	O
obtained	O
the	O
lowest	O
error	B-Metric
for	O
every	O
action	O
class	O
in	O
Human3.6	B-Material
M	I-Material
dataset	I-Material
.	O
	
Moreover	O
,	O
we	O
observed	O
that	O
our	O
network	O
predicted	O
meaningful	O
3D	O
poses	O
on	O
Youtube	B-Material
videos	I-Material
,	O
even	O
when	O
the	O
detections	O
from	O
the	O
2D	B-Method
pose	I-Method
detector	I-Method
were	O
extremely	O
noisy	O
or	O
meaningless	O
.	O
	
This	O
shows	O
the	O
effectiveness	O
of	O
using	O
temporal	O
information	O
.	O
	
In	O
short	O
our	O
contributions	O
in	O
this	O
work	O
are	O
:	O
Designing	O
an	O
efficient	O
sequence	B-Method
-	I-Method
to	I-Method
-	I-Method
sequence	I-Method
network	I-Method
that	O
achieves	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
results	O
for	O
every	O
action	O
class	O
of	O
Human3.6	B-Material
M	I-Material
dataset	I-Material
and	O
can	O
be	O
trained	O
very	O
fast	O
.	O
	
Exploiting	O
the	O
ability	O
of	O
sequence	B-Method
-	I-Method
to	I-Method
-	I-Method
sequence	I-Method
networks	I-Method
to	O
take	O
into	O
account	O
the	O
events	O
in	O
the	O
past	O
,	O
to	O
predict	O
temporally	O
consistent	O
3D	O
poses	O
.	O
	
Effectively	O
imposing	O
temporal	O
consistency	O
constraint	O
on	O
the	O
predicted	O
3D	O
poses	O
during	O
training	O
so	O
that	O
the	O
errors	O
in	O
the	O
predictions	O
are	O
distributed	O
smoothly	O
over	O
the	O
sequence	O
.	O
	
Using	O
only	O
the	O
previous	O
frames	O
to	O
understand	O
temporal	O
context	O
so	O
that	O
it	O
can	O
be	O
deployed	O
online	O
and	O
real	O
-	O
time	O
.	O
	
section	O
:	O
Related	O
Work	O
	
paragraph	O
:	O
Representation	O
of	O
3D	B-Task
pose	I-Task
	
Both	O
model	B-Method
-	I-Method
based	I-Method
and	I-Method
model	I-Method
-	I-Method
free	I-Method
representations	I-Method
of	I-Method
3D	I-Method
human	I-Method
pose	I-Method
have	O
been	O
used	O
in	O
the	O
past	O
.	O
	
The	O
most	O
common	O
model	B-Method
-	I-Method
based	I-Method
representation	I-Method
is	O
a	O
skeleton	O
defined	O
by	O
a	O
kinematic	O
tree	O
of	O
a	O
set	O
of	O
joints	O
,	O
parameterized	O
by	O
the	O
offset	O
and	O
rotational	O
parameters	O
of	O
each	O
joint	O
relative	O
to	O
its	O
parent	O
.	O
	
Several	O
3D	B-Task
pose	I-Task
methods	O
have	O
used	O
this	O
representation	O
.	O
	
Others	O
model	O
3D	B-Task
pose	I-Task
as	O
a	O
sparse	B-Method
linear	I-Method
combination	I-Method
of	O
an	O
over	O
-	O
complete	O
dictionary	O
of	O
basis	O
poses	O
.	O
	
However	O
,	O
we	O
have	O
chosen	O
a	O
model	O
-	O
free	O
representation	O
of	O
3D	B-Task
pose	I-Task
,	O
where	O
a	O
3D	B-Task
pose	I-Task
is	O
simply	O
a	O
set	O
of	O
3D	O
joint	O
locations	O
relative	O
to	O
the	O
root	O
node	O
like	O
several	O
recent	O
approaches	O
.	O
	
This	O
representation	O
is	O
much	O
simpler	O
and	O
low	O
-	O
dimensional	O
.	O
	
paragraph	O
:	O
Estimating	O
3D	B-Task
pose	I-Task
from	O
2D	O
joints	O
	
Lee	O
and	O
Chen	O
were	O
the	O
first	O
to	O
infer	O
3D	O
joint	O
locations	O
from	O
their	O
2D	O
projections	O
given	O
the	O
bone	O
lengths	O
using	O
a	O
binary	O
decision	O
tree	O
where	O
each	O
branch	O
corresponds	O
to	O
two	O
possible	O
states	O
of	O
a	O
joint	O
relative	O
to	O
its	O
parent	O
.	O
	
Jiang	O
used	O
the	O
2D	O
joint	O
locations	O
to	O
estimate	O
a	O
set	O
of	O
hypothesis	O
3D	O
poses	O
using	O
Taylor	B-Method
’s	I-Method
algorithm	I-Method
and	O
used	O
them	O
to	O
query	O
a	O
large	O
database	O
of	O
motion	O
capture	O
data	O
to	O
find	O
the	O
nearest	O
neighbor	O
.	O
	
Gupta	O
et	O
al	O
.	O
and	O
Chen	O
and	O
Ramanan	O
also	O
used	O
this	O
idea	O
of	O
using	O
the	O
detected	O
2D	O
pose	O
to	O
query	O
a	O
large	O
database	O
of	O
exemplar	O
poses	O
to	O
find	O
the	O
nearest	O
nearest	O
neighbor	O
3D	B-Task
pose	I-Task
.	O
	
Another	O
common	O
approach	O
to	O
estimating	B-Task
3D	I-Task
joint	I-Task
locations	I-Task
given	O
the	O
2D	B-Task
pose	I-Task
is	O
to	O
separate	O
the	O
camera	O
pose	O
variability	O
from	O
the	O
intrinsic	O
deformation	O
of	O
the	O
human	O
body	O
,	O
the	O
latter	O
of	O
which	O
is	O
modeled	O
by	O
learning	O
an	O
over	O
-	O
complete	O
dictionary	O
of	O
basis	O
3D	O
poses	O
from	O
a	O
large	O
database	O
of	O
motion	O
capture	O
data	O
.	O
	
A	O
valid	O
3D	B-Task
pose	I-Task
is	O
defined	O
by	O
a	O
sparse	B-Method
linear	I-Method
combination	I-Method
of	O
the	O
bases	O
and	O
by	O
transforming	O
the	O
points	O
using	O
transformation	O
matrix	O
representing	O
camera	O
extrinsic	O
parameters	O
.	O
	
Moreno	O
-	O
Nouguer	O
used	O
the	O
pair	O
-	O
wise	O
distance	O
matrix	O
of	O
2D	O
joints	O
to	O
learn	O
a	O
distance	O
matrix	O
for	O
3D	O
joints	O
,	O
which	O
they	O
found	O
invariant	O
up	O
to	O
a	O
rigid	B-Method
similarity	I-Method
transform	I-Method
with	O
the	O
ground	O
truth	O
3D	O
and	O
used	O
multi	B-Method
-	I-Method
dimensional	I-Method
scaling	I-Method
(	O
MDS	B-Method
)	O
with	O
pose	O
-	O
priors	O
to	O
rule	O
out	O
the	O
ambiguities	O
.	O
	
Martinez	O
et	O
al	O
.	O
designed	O
a	O
fully	B-Method
connected	I-Method
network	I-Method
with	O
shortcut	O
connections	O
every	O
two	O
linear	O
layers	O
to	O
estimate	O
3D	O
joint	O
locations	O
relative	O
to	O
the	O
root	O
node	O
in	O
the	O
camera	O
coordinate	O
space	O
.	O
	
paragraph	O
:	O
Deep	B-Method
network	I-Method
based	I-Method
methods	I-Method
	
With	O
the	O
success	O
of	O
deep	B-Method
networks	I-Method
,	O
many	O
have	O
designed	O
networks	O
that	O
can	O
be	O
trained	O
end	O
-	O
to	O
-	O
end	O
to	O
predict	B-Task
3D	I-Task
poses	I-Task
from	O
images	O
directly	O
.	O
	
Li	O
et	O
al	O
.	O
and	O
Park	O
et	O
al	O
.	O
designed	O
CNNs	B-Method
to	O
jointly	O
predict	O
2D	O
and	O
3D	O
poses	O
.	O
	
Mehta	O
et	O
al	O
.	O
and	O
Sun	O
et	O
al	O
.	O
	
used	O
transfer	B-Method
learning	I-Method
to	O
transfer	O
the	O
knowledge	O
learned	O
for	O
2D	B-Task
human	I-Task
pose	I-Task
estimation	I-Task
to	O
the	O
task	O
of	O
3D	B-Task
pose	I-Task
estimation	O
.	O
	
Pavlakos	O
et	O
al	O
.	O
extended	O
the	O
stacked	B-Method
-	I-Method
hourglass	I-Method
network	O
originally	O
designed	O
to	O
predict	O
2D	O
heatmaps	O
of	O
each	O
joint	O
to	O
make	O
it	O
predict	O
3D	B-Task
volumetric	I-Task
heatmaps	I-Task
.	O
	
Tome	O
et	O
al	O
.	O
also	O
extended	O
a	O
2D	B-Method
pose	I-Method
estimator	I-Method
called	O
Convolutional	B-Method
Pose	I-Method
Machine	I-Method
(	O
CPM	B-Method
)	O
to	O
make	O
it	O
predict	O
3D	B-Task
pose	I-Task
.	O
	
Rogesz	O
and	O
Schmid	O
and	O
Varol	O
et	O
al	O
.	O
augmented	O
the	O
training	O
data	O
with	O
synthetic	O
images	O
and	O
trained	O
CNNs	B-Method
to	O
predict	O
3D	B-Task
poses	I-Task
from	O
real	O
images	O
.	O
	
Sun	O
et	O
al	O
.	O
designed	O
a	O
unified	B-Method
network	I-Method
that	O
can	O
regress	O
both	O
2D	O
and	O
3D	O
poses	O
at	O
the	O
same	O
time	O
given	O
an	O
image	O
.	O
	
Hence	O
during	O
training	O
time	O
,	O
in	O
-	O
the	O
-	O
wild	O
images	O
which	O
do	O
not	O
have	O
any	O
ground	O
truth	O
3D	O
poses	O
can	O
be	O
combined	O
with	O
the	O
data	O
with	O
ground	O
truth	O
3D	O
poses	O
.	O
	
A	O
similar	O
idea	O
of	O
exploiting	O
in	B-Task
-	I-Task
the	I-Task
-	I-Task
wild	I-Task
images	I-Task
to	O
learn	O
pose	O
structure	O
was	O
used	O
by	O
Fang	O
et	O
al	O
.	O
.	O
	
They	O
learned	O
a	O
pose	B-Method
grammar	I-Method
that	O
encodes	O
the	O
possible	O
human	O
pose	O
configurations	O
.	O
	
paragraph	O
:	O
Using	O
temporal	O
information	O
	
Since	O
estimating	O
poses	O
for	O
each	O
frame	O
individually	O
leads	O
to	O
incoherent	O
and	O
jittery	O
predictions	O
over	O
a	O
sequence	O
,	O
many	O
approaches	O
tried	O
to	O
exploit	O
temporal	O
information	O
.	O
	
Andriluka	O
et	O
al	O
.	O
used	O
tracking	B-Method
-	I-Method
by	I-Method
-	I-Method
detection	I-Method
to	O
associate	O
2D	O
poses	O
detected	O
in	O
each	O
frame	O
individually	O
and	O
used	O
them	O
to	O
retrieve	O
3D	B-Task
pose	I-Task
.	O
	
Tekin	O
et	O
al	O
.	O
used	O
a	O
CNN	B-Method
to	O
first	O
align	O
bounding	O
boxes	O
of	O
successive	O
frames	O
so	O
that	O
the	O
person	O
in	O
the	O
image	O
is	O
always	O
at	O
the	O
center	O
of	O
the	O
box	O
and	O
then	O
extracted	O
3D	O
HOG	O
features	O
densely	O
over	O
the	O
spatio	O
-	O
temporal	O
volume	O
from	O
which	O
they	O
regress	O
the	O
3D	B-Task
pose	I-Task
of	O
the	O
central	O
frame	O
.	O
	
Mehta	O
et	O
al	O
.	O
implemented	O
a	O
real	B-Method
-	I-Method
time	I-Method
system	I-Method
for	O
3D	B-Task
pose	I-Task
estimation	O
that	O
applies	O
temporal	B-Method
filtering	I-Method
across	O
2D	O
and	O
3D	O
poses	O
from	O
previous	O
frames	O
to	O
predict	O
a	O
temporally	O
consistent	O
3D	B-Task
pose	I-Task
.	O
	
Lin	O
et	O
al	O
.	O
performed	O
a	O
multi	B-Method
-	I-Method
stage	I-Method
sequential	I-Method
refinement	I-Method
using	O
LSTMs	B-Method
to	O
predict	O
3D	B-Task
pose	I-Task
sequences	O
using	O
previously	O
predicted	O
2D	O
pose	O
representations	O
and	O
3D	B-Task
pose	I-Task
.	O
	
We	O
focus	O
on	O
predicting	B-Task
temporally	I-Task
consistent	I-Task
3D	I-Task
poses	I-Task
by	O
learning	O
the	O
temporal	O
context	O
of	O
a	O
sequence	O
using	O
a	O
form	O
of	O
sequence	B-Method
-	I-Method
to	I-Method
-	I-Method
sequence	I-Method
network	I-Method
.	O
	
Unlike	O
Lin	O
et	O
al	O
.	O
	
our	O
method	O
does	O
not	O
need	O
multiple	O
stages	O
of	O
refinement	O
.	O
	
It	O
is	O
simpler	O
and	O
requires	O
fewer	O
parameters	O
to	O
train	O
,	O
leading	O
to	O
much	O
improved	O
performance	O
.	O
	
section	O
:	O
Our	O
Approach	O
	
paragraph	O
:	O
Network	B-Method
Design	I-Method
	
We	O
designed	O
a	O
sequence	B-Method
-	I-Method
to	I-Method
-	I-Method
sequence	I-Method
network	I-Method
with	O
LSTM	B-Method
units	O
and	O
residual	B-Method
connections	I-Method
on	O
the	O
decoder	O
side	O
to	O
predict	O
a	O
temporally	O
coherent	O
sequence	O
of	O
3D	O
poses	O
given	O
a	O
sequence	O
of	O
2D	O
joint	O
locations	O
.	O
	
Figure	O
[	O
reference	O
]	O
shows	O
the	O
architecture	O
of	O
our	O
network	O
.	O
	
The	O
motivation	O
behind	O
using	O
a	O
sequence	B-Method
-	I-Method
to	I-Method
-	I-Method
sequence	I-Method
network	I-Method
comes	O
from	O
its	O
application	O
on	O
the	O
task	O
of	O
Neural	B-Task
Machine	I-Task
Translation	I-Task
(	O
NMT	B-Task
)	O
by	O
Sutskever	O
et	O
al	O
.	O
,	O
where	O
their	O
model	O
translates	O
a	O
sentence	O
in	O
one	O
language	O
to	O
a	O
sentence	O
in	O
another	O
language	O
	
e.g.	O
English	O
to	O
French	O
.	O
	
In	O
a	O
language	B-Method
translation	I-Method
model	I-Method
,	O
the	O
input	O
and	O
output	O
sentences	O
can	O
have	O
different	O
lengths	O
.	O
	
Although	O
our	O
case	O
is	O
analogous	O
to	O
the	O
NMT	B-Task
,	O
the	O
input	O
and	O
output	O
sequences	O
always	O
have	O
the	O
same	O
length	O
while	O
the	O
input	O
vectors	O
to	O
the	O
encoder	O
and	O
decoder	O
have	O
different	O
dimensions	O
.	O
	
The	O
encoder	O
side	O
of	O
our	O
network	O
takes	O
a	O
sequence	O
of	O
2D	O
poses	O
and	O
encodes	O
them	O
in	O
a	O
fixed	O
size	O
high	O
dimensional	O
vector	O
in	O
the	O
hidden	O
state	O
of	O
its	O
final	O
LSTM	B-Method
unit	O
.	O
	
Since	O
the	O
LSTMs	B-Method
are	O
excellent	O
in	O
memorizing	O
events	O
and	O
information	O
from	O
the	O
past	O
,	O
the	O
encoded	O
vector	O
stores	O
the	O
2D	O
pose	O
information	O
of	O
all	O
the	O
frames	O
.	O
	
The	O
initial	O
state	O
of	O
the	O
decoder	O
is	O
initialized	O
by	O
the	O
final	O
state	O
of	O
the	O
encoder	O
.	O
	
A	O
token	O
is	O
passed	O
as	O
initial	O
input	O
to	O
the	O
decoder	B-Method
,	O
which	O
in	O
our	O
case	O
is	O
a	O
vector	O
of	O
ones	O
,	O
telling	O
it	O
to	O
start	O
decoding	B-Task
.	O
	
Given	O
a	O
3D	B-Task
pose	I-Task
estimate	O
at	O
a	O
time	O
step	O
each	O
decoder	B-Method
unit	I-Method
predicts	O
the	O
3D	B-Task
pose	I-Task
for	O
next	O
time	O
step	O
.	O
	
Note	O
that	O
the	O
order	O
of	O
the	O
input	O
sequence	O
is	O
reversed	O
as	O
recommended	O
by	O
Sutskever	O
et	O
al	O
.	O
.	O
	
The	O
shortcut	O
connections	O
on	O
the	O
decoder	O
side	O
cause	O
each	O
decoder	B-Method
unit	I-Method
to	O
estimate	O
the	O
amount	O
of	O
perturbation	O
in	O
the	O
3D	B-Task
pose	I-Task
from	O
the	O
previous	O
frame	O
instead	O
of	O
having	O
to	O
estimate	O
the	O
actual	O
3D	B-Task
pose	I-Task
for	O
each	O
frame	O
.	O
	
As	O
suggested	O
by	O
He	O
et	O
al	O
.	O
,	O
such	O
a	O
mapping	O
is	O
easier	O
to	O
learn	O
for	O
the	O
network	O
.	O
	
We	O
use	O
layer	B-Method
normalization	I-Method
and	O
recurrent	B-Method
dropout	I-Method
to	O
regularize	O
our	O
network	O
.	O
	
Ba	O
et	O
al	O
.	O
came	O
up	O
with	O
the	O
idea	O
of	O
layer	B-Method
normalization	I-Method
which	O
estimates	O
the	O
normalization	O
statistics	O
(	O
mean	B-Metric
and	I-Metric
standard	I-Metric
deviation	I-Metric
)	O
from	O
the	O
summed	O
inputs	O
to	O
the	O
recurrent	O
neurons	O
of	O
hidden	B-Method
layer	I-Method
on	O
a	O
single	O
training	O
example	O
to	O
regularize	O
the	O
RNN	B-Method
units	I-Method
.	O
	
Similarly	O
,	O
Zaremba	O
et	O
al	O
.	O
proposed	O
the	O
idea	O
of	O
applying	O
dropout	B-Method
only	O
on	O
the	O
non	O
-	O
recurrent	O
connections	O
of	O
the	O
network	O
with	O
a	O
certain	O
probability	O
while	O
always	O
keeping	O
the	O
recurrent	O
connections	O
intact	O
because	O
they	O
are	O
necessary	O
for	O
the	O
recurrent	O
units	O
to	O
remember	O
the	O
information	O
from	O
the	O
past	O
.	O
	
paragraph	O
:	O
Loss	B-Method
function	I-Method
	
Given	O
a	O
sequence	O
of	O
2D	O
joint	O
locations	O
as	O
input	O
,	O
our	O
network	O
predicts	O
a	O
sequence	O
of	O
3D	O
joint	O
locations	O
relative	O
to	O
the	O
root	O
node	O
(	O
central	O
hip	O
)	O
.	O
	
We	O
predict	O
each	O
3D	B-Task
pose	I-Task
in	O
the	O
camera	O
coordinate	O
space	O
instead	O
of	O
predicting	O
them	O
in	O
an	O
arbitrary	O
global	O
frame	O
as	O
suggested	O
by	O
Martinez	O
et	O
al	O
.	O
.	O
	
We	O
impose	O
a	O
temporal	O
smoothness	O
constraint	O
on	O
the	O
predicted	O
3D	O
joint	O
locations	O
to	O
ensure	O
that	O
the	O
prediction	O
of	O
each	O
joint	O
in	O
one	O
frame	O
does	O
not	O
differ	O
too	O
much	O
from	O
its	O
previous	O
frame	O
.	O
	
Because	O
the	O
2D	B-Method
pose	I-Method
detectors	I-Method
work	O
on	O
individual	O
frames	O
,	O
even	O
with	O
the	O
minimal	O
movement	O
of	O
the	O
subject	O
in	O
the	O
image	O
,	O
the	O
detections	O
from	O
successive	O
frames	O
may	O
vary	O
,	O
particularly	O
for	O
the	O
joints	O
which	O
move	O
fast	O
or	O
are	O
prone	O
to	O
occlusion	O
.	O
	
Hence	O
,	O
we	O
made	O
an	O
assumption	O
that	O
the	O
subject	O
does	O
not	O
move	O
too	O
much	O
in	O
successive	O
frames	O
given	O
the	O
frame	B-Metric
rate	I-Metric
is	O
high	O
enough	O
.	O
	
Therefore	O
,	O
we	O
added	O
the	O
L2	O
norm	O
of	O
the	O
first	O
order	O
derivative	O
on	O
the	O
3D	O
joint	O
locations	O
with	O
respect	O
to	O
time	O
to	O
our	O
loss	B-Method
function	I-Method
during	O
training	O
.	O
	
This	O
constraint	O
helps	O
us	O
to	O
estimate	O
3D	O
poses	O
reliably	O
even	O
when	O
the	O
2D	B-Method
pose	I-Method
detector	I-Method
fails	O
for	O
a	O
few	O
frames	O
within	O
the	O
temporal	O
window	O
without	O
any	O
post	O
-	O
processing	O
.	O
	
Empirically	O
we	O
found	O
that	O
certain	O
joints	O
are	O
more	O
difficult	O
to	O
estimate	O
accurately	O
e.g.	O
wrist	O
,	O
ankle	O
,	O
elbow	O
compared	O
to	O
others	O
.	O
	
To	O
address	O
this	O
issue	O
,	O
we	O
partitioned	O
the	O
joints	O
into	O
three	O
disjoint	O
sets	O
,	O
and	O
based	O
on	O
their	O
contribution	O
to	O
overall	O
error	B-Metric
.	O
	
We	O
observed	O
that	O
the	O
joints	O
connected	O
to	O
the	O
torso	O
and	O
the	O
head	O
e.g.	O
hips	O
,	O
shoulders	O
,	O
neck	O
are	O
always	O
predicted	O
with	O
high	O
accuracy	B-Metric
compared	O
to	O
those	O
joints	O
belonging	O
to	O
the	O
limbs	O
and	O
therefore	O
put	O
them	O
in	O
the	O
set	O
.	O
	
The	O
joints	O
of	O
the	O
limbs	O
,	O
especially	O
the	O
joints	O
on	O
the	O
arms	O
,	O
are	O
always	O
more	O
difficult	O
to	O
predict	O
due	O
to	O
their	O
high	O
range	O
of	O
motion	O
and	O
occlusion	O
.	O
	
We	O
put	O
the	O
knees	O
and	O
the	O
ankles	O
in	O
the	O
set	O
and	O
the	O
elbow	O
and	O
wrist	O
in	O
.	O
	
We	O
multiply	O
the	O
derivatives	O
of	O
each	O
set	O
of	O
joints	O
with	O
different	O
scalar	O
values	O
based	O
on	O
their	O
contribution	O
to	O
the	O
overall	O
error	B-Metric
.	O
	
Therefore	O
our	O
loss	B-Method
function	I-Method
consists	O
of	O
the	O
sum	O
of	O
two	O
separate	O
terms	O
:	O
	
Mean	B-Metric
Squared	I-Metric
Error	I-Metric
(	O
MSE	B-Metric
)	O
of	O
different	O
sequences	O
of	O
3D	O
joint	O
locations	O
;	O
and	O
the	O
mean	O
of	O
the	O
L2	B-Metric
norm	I-Metric
of	O
the	O
first	O
order	O
derivative	O
of	O
sequences	O
of	O
3D	O
joint	O
locations	O
with	O
respect	O
to	O
time	O
,	O
where	O
the	O
joints	O
are	O
divided	O
into	O
three	O
disjoint	O
sets	O
.	O
	
The	O
MSE	B-Metric
over	O
sequences	O
,	O
each	O
of	O
time	O
-	O
steps	O
,	O
of	O
3D	O
joint	O
locations	O
is	O
given	O
by	O
Here	O
,	O
denotes	O
the	O
estimated	O
3D	O
joint	O
locations	O
while	O
denotes	O
3D	O
ground	O
truth	O
.	O
	
The	O
mean	B-Metric
of	I-Metric
L2	I-Metric
norm	I-Metric
of	O
the	O
first	O
order	O
derivative	O
of	O
sequences	O
of	O
3D	O
joint	O
locations	O
,	O
each	O
of	O
length	O
,	O
with	O
respect	O
to	O
time	O
is	O
given	O
by	O
In	O
the	O
above	O
equation	O
,	O
,	O
and	O
denotes	O
the	O
predicted	O
3D	O
locations	O
of	O
joints	O
belonging	O
to	O
the	O
sets	O
,	O
and	O
respectively	O
.	O
	
The	O
and	O
are	O
scalar	O
hyper	O
-	O
parameters	O
to	O
control	O
the	O
significance	O
of	O
the	O
derivatives	O
of	O
3D	O
locations	O
of	O
each	O
of	O
the	O
three	O
set	O
of	O
joints	O
.	O
	
A	O
higher	O
weight	O
is	O
assigned	O
to	O
the	O
set	O
of	O
joints	O
which	O
are	O
generally	O
predicted	O
with	O
higher	O
error	B-Metric
.	O
	
The	O
overall	O
loss	B-Metric
function	I-Metric
for	O
our	O
network	O
is	O
given	O
as	O
Here	O
and	O
are	O
scalar	O
hyper	O
-	O
parameters	O
regulating	O
the	O
importance	O
of	O
each	O
of	O
the	O
two	O
terms	O
in	O
the	O
loss	O
function	O
.	O
	
section	O
:	O
Experimental	O
Evaluation	O
	
paragraph	O
:	O
Datasets	O
and	O
protocols	O
	
We	O
perform	O
quantitative	O
evaluation	O
on	O
the	O
Human	B-Material
3.6	I-Material
M	I-Material
dataset	I-Material
and	O
on	O
the	O
HumanEva	B-Material
dataset	I-Material
.	O
	
Human	B-Material
3.6	I-Material
M	I-Material
,	O
to	O
the	O
best	O
of	O
our	O
knowledge	O
,	O
is	O
the	O
largest	O
publicly	O
available	O
dataset	O
for	O
human	O
3D	B-Task
pose	I-Task
estimation	O
.	O
	
The	O
dataset	O
contains	O
3.6	O
million	O
images	O
of	O
7	O
different	O
professional	O
actors	O
performing	O
15	O
everyday	O
activities	O
like	O
walking	O
,	O
eating	O
,	O
sitting	O
,	O
making	O
a	O
phone	O
call	O
.	O
	
The	O
dataset	O
consists	O
of	O
2D	O
and	O
3D	O
joint	O
locations	O
for	O
each	O
corresponding	O
image	O
.	O
	
Each	O
video	O
is	O
captured	O
using	O
4	O
different	O
calibrated	O
high	O
resolution	O
cameras	O
.	O
	
In	O
addition	O
to	O
2D	O
and	O
3D	B-Task
pose	I-Task
ground	O
truth	O
,	O
the	O
dataset	O
also	O
provides	O
ground	O
truth	O
for	O
bounding	O
boxes	O
,	O
the	O
camera	O
parameters	O
,	O
the	O
body	O
proportion	O
of	O
all	O
the	O
actors	O
and	O
high	O
resolution	O
body	O
scans	O
or	O
meshes	O
of	O
each	O
actor	O
.	O
	
HumanEva	B-Material
,	O
on	O
the	O
other	O
hand	O
,	O
is	O
a	O
much	O
smaller	O
dataset	O
.	O
	
It	O
has	O
been	O
largely	O
used	O
to	O
benchmark	O
previous	O
work	O
over	O
the	O
last	O
decade	O
.	O
	
Most	O
of	O
the	O
methods	O
report	O
results	O
on	O
two	O
different	O
actions	O
and	O
on	O
three	O
actors	O
.	O
	
For	O
qualitative	O
evaluation	O
,	O
we	O
used	O
the	O
some	O
videos	O
from	O
Youtube	B-Material
and	O
the	O
Human3.6	B-Material
M	I-Material
dataset	I-Material
.	O
	
We	O
follow	O
the	O
standard	O
protocols	O
of	O
the	O
Human3.6	B-Material
M	I-Material
dataset	I-Material
used	O
in	O
the	O
literature	O
.	O
	
We	O
used	O
subjects	O
1	O
,	O
5	O
,	O
6	O
,	O
7	O
,	O
and	O
8	O
for	O
training	O
,	O
and	O
subjects	O
9	O
and	O
11	O
for	O
testing	O
and	O
the	O
error	B-Metric
is	O
evaluated	O
on	O
the	O
predicted	O
3D	B-Task
pose	I-Task
without	O
any	O
transformation	O
.	O
	
We	O
refer	O
this	O
as	O
protocol	O
#	O
1	O
.	O
	
Another	O
common	O
approach	O
used	O
by	O
many	O
to	O
evaluate	O
their	O
methods	O
is	O
to	O
align	O
the	O
predicted	O
3D	B-Task
pose	I-Task
with	O
the	O
ground	O
truth	O
using	O
a	O
similarity	B-Method
transformation	I-Method
(	O
Procrustes	B-Method
analysis	I-Method
)	O
.	O
	
We	O
refer	O
this	O
as	O
protocol	O
#	O
2	O
.	O
	
We	O
use	O
the	O
average	B-Metric
error	I-Metric
per	O
joint	O
in	O
millimeters	O
between	O
the	O
estimated	O
and	O
the	O
ground	O
truth	O
3D	B-Task
pose	I-Task
relative	O
to	O
the	O
root	O
node	O
as	O
the	O
error	B-Metric
metric	I-Metric
.	O
	
For	O
the	O
HumanEva	B-Material
dataset	I-Material
,	O
we	O
report	O
results	O
on	O
each	O
subject	O
and	O
action	O
separately	O
after	O
performing	O
rigid	B-Task
alignment	I-Task
with	O
the	O
ground	O
truth	O
data	O
,	O
following	O
the	O
protocol	O
used	O
by	O
the	O
previous	O
methods	O
.	O
	
paragraph	O
:	O
2D	B-Task
detections	I-Task
	
We	O
fine	O
-	O
tuned	O
a	O
model	O
of	O
stacked	B-Method
-	I-Method
hourglass	I-Method
network	O
,	O
initially	O
trained	O
on	O
the	O
MPII	B-Material
dataset	I-Material
(	O
a	O
benchmark	O
dataset	O
for	O
2D	B-Task
pose	I-Task
estimation	I-Task
)	O
,	O
on	O
the	O
images	O
of	O
the	O
Human3.6	B-Material
M	I-Material
dataset	I-Material
to	O
obtain	O
2D	B-Task
pose	I-Task
estimations	I-Task
for	O
each	O
image	O
.	O
	
We	O
used	O
the	O
bounding	O
box	O
information	O
provided	O
with	O
the	O
dataset	O
to	O
first	O
compute	O
the	O
center	O
of	O
the	O
person	O
in	O
the	O
image	O
and	O
then	O
cropped	O
a	O
region	O
across	O
the	O
person	O
and	O
resized	O
it	O
to	O
.	O
	
We	O
fine	O
-	O
tuned	O
the	O
network	O
for	O
250	O
iterations	O
and	O
used	O
a	O
batch	O
size	O
of	O
3	O
and	O
a	O
learning	B-Metric
rate	I-Metric
of	O
.	O
	
paragraph	O
:	O
Baselines	O
	
Since	O
many	O
of	O
the	O
previous	O
methods	O
are	O
based	O
on	O
single	B-Method
frame	I-Method
predictions	I-Method
,	O
we	O
used	O
two	O
baselines	O
for	O
comparison	O
.	O
	
To	O
show	O
that	O
our	O
method	O
is	O
much	O
better	O
than	O
naive	B-Method
post	I-Method
processing	I-Method
,	O
we	O
applied	O
a	O
mean	B-Method
filter	I-Method
and	O
a	O
median	B-Method
filter	I-Method
on	O
the	O
3D	B-Task
pose	I-Task
predictions	O
of	O
Martinez	O
et	O
al	O
.	O
.	O
	
We	O
used	O
a	O
window	O
size	O
of	O
5	O
frames	O
and	O
a	O
stride	O
length	O
of	O
1	O
to	O
apply	O
the	O
filters	O
.	O
	
Although	O
non	B-Method
-	I-Method
rigid	I-Method
structure	I-Method
from	I-Method
motion	I-Method
(	O
NRSFM	B-Method
)	I-Method
is	O
one	O
of	O
the	O
most	O
general	O
approaches	O
for	O
any	O
3D	B-Task
reconstruction	I-Task
problem	I-Task
from	O
a	O
sequence	O
of	O
2D	O
correspondences	O
,	O
we	O
did	O
not	O
use	O
it	O
as	O
a	O
baseline	O
because	O
Zhou	O
et	O
al	O
.	O
did	O
not	O
find	O
NRSFM	B-Method
techniques	I-Method
to	O
be	O
effective	O
for	O
3D	B-Task
human	I-Task
pose	I-Task
estimation	I-Task
.	O
	
They	O
found	O
that	O
the	O
NRSFM	B-Method
techniques	I-Method
do	O
not	O
work	O
well	O
with	O
slow	O
camera	O
motion	O
.	O
	
Since	O
the	O
videos	O
in	O
the	O
Human3.6	B-Material
M	I-Material
dataset	I-Material
are	O
captured	O
by	O
stationary	O
cameras	O
,	O
the	O
subjects	O
in	O
the	O
dataset	O
do	O
not	O
rotate	O
that	O
much	O
to	O
provide	O
alternative	O
views	O
for	O
NRSFM	B-Method
algorithm	I-Method
to	O
perform	O
well	O
.	O
	
Another	O
reason	O
is	O
that	O
human	B-Task
pose	I-Task
reconstruction	I-Task
is	O
a	O
specialized	B-Task
problem	I-Task
in	O
which	O
constraints	O
from	O
human	O
body	O
structure	O
apply	O
.	O
	
paragraph	O
:	O
Data	B-Task
pre	I-Task
-	I-Task
processing	I-Task
	
We	O
normalized	O
the	O
3D	O
ground	O
truth	O
poses	O
,	O
the	O
noisy	B-Method
2D	I-Method
pose	I-Method
estimates	I-Method
from	O
stacked	B-Method
-	I-Method
hourglass	I-Method
network	O
and	O
the	O
2D	O
ground	O
truth	O
by	O
subtracting	O
the	O
mean	O
and	O
dividing	O
by	O
standard	O
deviation	O
.	O
	
We	O
do	O
not	O
predict	O
the	O
3D	O
location	O
of	O
the	O
root	O
joint	O
i.e.	O
central	O
hip	O
joint	O
and	O
hence	O
zero	O
center	O
the	O
3D	O
joint	O
locations	O
relative	O
to	O
the	O
global	O
position	O
of	O
the	O
root	O
node	O
.	O
	
To	O
obtain	O
the	O
ground	O
truth	O
3D	O
poses	O
in	O
camera	O
coordinate	O
space	O
,	O
an	O
inverse	B-Method
rigid	I-Method
body	I-Method
transformation	I-Method
is	O
applied	O
on	O
the	O
the	O
ground	O
truth	O
3D	O
poses	O
in	O
global	O
coordinate	O
space	O
using	O
the	O
given	O
camera	O
parameters	O
.	O
	
To	O
generate	O
both	O
training	O
and	O
test	O
sequences	O
,	O
we	O
translated	O
a	O
sliding	O
window	O
of	O
length	O
by	O
one	O
frame	O
.	O
	
Hence	O
there	O
is	O
an	O
overlap	O
between	O
the	O
sequences	O
.	O
	
This	O
gives	O
us	O
more	O
data	O
to	O
train	O
on	O
,	O
which	O
is	O
always	O
an	O
advantage	O
for	O
deep	B-Method
learning	I-Method
systems	I-Method
.	O
	
During	O
test	O
time	O
,	O
we	O
initially	O
predict	O
the	O
first	O
frames	O
of	O
the	O
sequence	O
and	O
slide	O
the	O
window	O
by	O
a	O
stride	O
length	O
of	O
1	O
to	O
predict	O
the	O
next	O
frame	O
using	O
the	O
previous	O
frames	O
.	O
	
paragraph	O
:	O
Training	O
details	O
	
We	O
trained	O
our	O
network	O
for	O
100	O
epochs	O
,	O
where	O
each	O
epoch	O
makes	O
a	O
complete	O
pass	O
over	O
the	O
entire	O
Human	B-Material
3.6	I-Material
M	I-Material
dataset	I-Material
.	O
	
We	O
used	O
the	O
Adam	B-Method
optimizer	I-Method
for	O
training	O
the	O
network	O
with	O
a	O
learning	B-Metric
rate	I-Metric
of	O
which	O
is	O
decayed	O
exponentially	O
per	O
iteration	O
.	O
	
The	O
weights	O
of	O
the	O
LSTM	B-Method
units	O
are	O
initialized	O
by	O
Xavier	B-Method
uniform	I-Method
initializer	I-Method
.	O
	
We	O
used	O
a	O
mini	O
-	O
batch	O
batch	O
size	O
of	O
32	O
i.e.	O
32	O
sequences	O
.	O
	
For	O
most	O
of	O
our	O
experiments	O
we	O
used	O
a	O
sequence	O
length	O
of	O
5	O
,	O
because	O
it	O
allows	O
faster	O
training	B-Task
with	O
high	O
accuracy	B-Metric
.	O
	
We	O
experimented	O
with	O
different	O
sequence	O
lengths	O
and	O
found	O
sequence	O
length	O
4	O
,	O
5	O
and	O
6	O
to	O
generally	O
give	O
better	O
results	O
,	O
which	O
we	O
will	O
discuss	O
in	O
detail	O
in	O
the	O
results	O
section	O
.	O
	
We	O
trained	O
a	O
single	O
model	O
for	O
all	O
the	O
action	O
classes	O
.	O
	
Our	O
code	O
is	O
implemented	O
in	O
Tensorflow	B-Method
.	O
	
We	O
perform	O
cross	B-Metric
-	I-Metric
validation	I-Metric
on	O
the	O
training	O
set	O
to	O
select	O
the	O
hyper	O
-	O
parameter	O
values	O
and	O
of	O
our	O
loss	O
function	O
to	O
and	O
respectively	O
.	O
	
Similarly	O
,	O
using	O
cross	B-Method
-	I-Method
validation	I-Method
,	O
the	O
three	O
hyper	O
-	O
parameters	O
of	O
the	O
temporal	O
consistency	O
constraint	O
and	O
,	O
are	O
set	O
to	O
and	O
respectively	O
.	O
	
A	O
single	O
training	B-Method
step	I-Method
for	O
sequences	O
of	O
length	O
5	O
takes	O
only	O
34	O
ms	O
approximately	O
,	O
while	O
a	O
forward	B-Method
pass	I-Method
takes	O
only	O
about	O
16ms	O
on	O
NVIDIA	O
Titan	O
X	O
GPU	O
.	O
	
Therefore	O
given	O
the	O
2D	O
joint	O
locations	O
from	O
a	O
pose	B-Method
detector	I-Method
,	O
our	O
network	O
takes	O
about	O
3.2ms	O
to	O
predict	O
3D	B-Task
pose	I-Task
per	O
frame	O
.	O
	
subsection	O
:	O
Quantitative	O
results	O
	
paragraph	O
:	O
Evaluation	O
on	O
estimated	B-Task
2D	I-Task
pose	I-Task
	
As	O
mentioned	O
before	O
,	O
we	O
used	O
a	O
sequence	O
length	O
of	O
5	O
to	O
perform	O
both	O
qualitative	O
and	O
quantitative	O
evaluation	O
of	O
our	O
network	O
.	O
	
The	O
results	O
on	O
Human3.6	B-Material
M	I-Material
dataset	I-Material
under	O
protocol	O
#	O
1	O
are	O
shown	O
in	O
Table	O
[	O
reference	O
]	O
.	O
	
From	O
the	O
table	O
we	O
observe	O
that	O
our	O
model	O
achieves	O
the	O
lowest	O
error	B-Metric
for	O
every	O
action	O
class	O
under	O
protocol	O
#	O
1	O
,	O
unlike	O
many	O
of	O
the	O
previous	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
methods	O
.	O
	
Note	O
that	O
we	O
train	O
a	O
single	O
model	O
for	O
all	O
the	O
action	O
classes	O
unlike	O
many	O
other	O
methods	O
which	O
trained	O
a	O
model	O
for	O
each	O
action	O
class	O
.	O
	
Our	O
network	O
significantly	O
improves	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
result	O
of	O
Sun	O
et	O
al	O
.	O
	
by	O
approximately	O
(	O
by	O
mm	O
)	O
.	O
	
The	O
results	O
under	O
protocol	O
#	O
2	O
,	O
which	O
aligns	O
the	O
predictions	O
to	O
the	O
ground	O
truth	O
using	O
a	O
rigid	B-Method
body	I-Method
similarity	I-Method
transform	I-Method
before	O
computing	O
the	O
error	B-Metric
,	O
is	O
reported	O
in	O
Table	O
[	O
reference	O
]	O
.	O
	
Our	O
network	O
improves	O
the	O
reported	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
results	O
by	O
(	O
by	O
mm	B-Method
)	O
and	O
achieves	O
the	O
lowest	O
error	B-Metric
for	O
each	O
action	O
in	O
protocol	O
#	O
2	O
as	O
well	O
.	O
	
From	O
the	O
results	O
,	O
we	O
observe	O
the	O
effectiveness	O
of	O
exploiting	O
temporal	O
information	O
across	O
multiple	O
sequences	O
.	O
	
By	O
using	O
the	O
information	O
of	O
temporal	O
context	O
,	O
our	O
network	O
reduced	O
the	O
overall	O
error	B-Metric
in	O
estimating	B-Task
3D	I-Task
joint	I-Task
locations	I-Task
,	O
especially	O
on	O
actions	O
like	O
phone	O
,	O
photo	O
,	O
sit	O
and	O
sitting	O
down	O
on	O
which	O
most	O
previous	O
methods	O
did	O
not	O
perform	O
well	O
due	O
to	O
heavy	O
occlusion	O
.	O
	
We	O
also	O
observe	O
that	O
our	O
method	O
outperforms	O
both	O
the	O
baselines	O
by	O
a	O
large	O
margin	O
on	O
both	O
the	O
protocols	O
.	O
	
This	O
shows	O
that	O
our	O
method	O
learned	O
the	O
temporal	O
context	O
of	O
the	O
sequences	O
and	O
predicted	O
temporally	O
consistent	O
3D	O
poses	O
,	O
which	O
naive	O
post	B-Method
-	I-Method
processing	I-Method
techniques	I-Method
like	O
temporal	B-Method
mean	I-Method
and	I-Method
median	I-Method
filters	I-Method
over	O
frame	B-Method
-	I-Method
wise	I-Method
prediction	I-Method
failed	O
to	O
do	O
.	O
	
Like	O
most	O
previous	O
methods	O
,	O
we	O
report	O
the	O
results	O
on	O
action	B-Task
classes	I-Task
Walking	I-Task
and	O
Jogging	B-Material
of	O
the	O
HumanEva	B-Material
dataset	I-Material
in	O
Table	O
[	O
reference	O
]	O
.	O
	
We	O
obtained	O
the	O
lowest	O
error	B-Metric
in	O
four	O
of	O
the	O
six	O
cases	O
and	O
the	O
lowest	O
average	B-Metric
error	I-Metric
for	O
the	O
two	O
actions	O
.	O
	
We	O
also	O
obtained	O
the	O
second	O
best	O
result	O
on	O
subject	O
2	O
of	O
action	B-Task
Walking	I-Task
.	O
	
However	O
,	O
HumanEva	B-Material
is	O
a	O
smaller	O
dataset	O
than	O
Human3.6	B-Material
M	I-Material
and	O
the	O
same	O
subjects	O
appear	O
in	O
both	O
training	O
and	O
testing	O
.	O
	
paragraph	O
:	O
Evaluation	O
on	O
2D	B-Task
ground	I-Task
truth	I-Task
	
As	O
suggested	O
by	O
Martinez	O
et	O
al	O
.	O
,	O
we	O
also	O
found	O
that	O
the	O
more	O
accurate	O
the	O
2D	O
joint	O
locations	O
are	O
,	O
the	O
better	O
are	O
the	O
estimates	O
for	O
3D	B-Task
pose	I-Task
.	O
	
We	O
trained	O
our	O
model	O
on	O
ground	O
truth	O
2D	O
poses	O
for	O
a	O
sequence	O
length	O
of	O
5	O
.	O
	
The	O
results	O
under	O
protocol	O
#	O
1	O
are	O
reported	O
in	O
Table	O
[	O
reference	O
]	O
.	O
	
As	O
seen	O
from	O
the	O
table	O
,	O
our	O
model	O
improves	O
the	O
lower	B-Metric
bound	I-Metric
error	I-Metric
of	O
Martinez	O
et	O
al	O
.	O
by	O
almost	O
.	O
	
The	O
results	O
on	O
ground	O
truth	O
2D	O
joint	O
input	O
for	O
protocol	O
#	O
2	O
are	O
reported	O
in	O
Table	O
[	O
reference	O
]	O
.	O
	
When	O
there	O
is	O
no	O
noise	O
in	O
2D	O
joint	O
locations	O
,	O
our	O
network	O
performs	O
better	O
than	O
the	O
models	O
by	O
Martinez	O
et	O
al	O
.	O
and	O
Moreno	O
-	O
Nouguer	O
.	O
	
These	O
results	O
suggest	O
that	O
the	O
information	O
of	O
temporal	O
consistency	O
from	O
previous	O
frames	O
is	O
a	O
valuable	O
cue	O
for	O
the	O
task	O
of	O
estimating	O
3D	B-Task
pose	I-Task
even	O
when	O
the	O
detections	O
are	O
noise	O
free	O
.	O
	
paragraph	O
:	O
Robustness	B-Metric
to	O
noise	O
	
We	O
carried	O
out	O
some	O
experiments	O
to	O
test	O
the	O
tolerance	O
of	O
our	O
model	O
to	O
different	O
levels	O
of	O
noise	O
in	O
the	O
input	O
data	O
by	O
training	O
our	O
network	O
on	O
2D	O
ground	O
truth	O
poses	O
and	O
testing	O
on	O
inputs	O
corrupted	O
by	O
different	O
levels	O
of	O
Gaussian	O
noise	O
.	O
	
Table	O
[	O
reference	O
]	O
shows	O
how	O
our	O
final	O
model	O
compares	O
against	O
the	O
models	O
by	O
Moreno	O
-	O
Nouguer	O
and	O
Martinez	O
et	O
al	O
.	O
.	O
	
Our	O
network	O
is	O
significantly	O
more	O
robust	O
than	O
Moreno	O
-	O
Nouguer	B-Method
’s	I-Method
model	I-Method
.	O
	
When	O
compared	O
against	O
Martinez	O
et	O
al	O
.	O
	
our	O
network	O
performs	O
better	O
when	O
the	O
level	O
of	O
input	O
noise	O
is	O
low	O
i.e.	O
standard	O
deviation	O
less	O
than	O
or	O
equal	O
to	O
10	O
.	O
	
However	O
,	O
for	O
higher	O
levels	O
of	O
noise	O
our	O
network	O
performs	O
slightly	O
worse	O
than	O
Martinez	O
et	O
al	O
.	O
.	O
	
We	O
would	O
like	O
to	O
attribute	O
the	O
cause	O
of	O
this	O
to	O
the	O
temporal	O
smoothness	O
constraint	O
imposed	O
during	O
training	O
which	O
distributes	O
the	O
error	B-Metric
of	O
individual	O
frames	O
over	O
the	O
entire	O
sequence	O
.	O
	
However	O
,	O
its	O
usefulness	O
can	O
be	O
observed	O
in	O
the	O
qualitative	O
results	O
(	O
See	O
Figure	O
[	O
reference	O
]	O
and	O
Figure	O
[	O
reference	O
]	O
)	O
.	O
	
paragraph	O
:	O
Ablative	B-Method
analysis	I-Method
	
To	O
show	O
the	O
usefulness	O
of	O
each	O
component	O
and	O
design	O
decision	O
of	O
our	O
network	O
,	O
we	O
perform	O
an	O
ablative	B-Method
analysis	I-Method
.	O
	
We	O
follow	O
protocol	O
#	O
1	O
for	O
performing	O
ablative	B-Task
analysis	I-Task
and	O
trained	O
a	O
single	O
model	O
for	O
all	O
the	O
actions	O
.	O
	
The	O
results	O
are	O
reported	O
in	O
Table	O
[	O
reference	O
]	O
.	O
	
We	O
observe	O
that	O
the	O
biggest	O
improvement	O
in	O
result	O
is	O
due	O
the	O
the	O
residual	O
connections	O
on	O
the	O
decoder	O
side	O
,	O
which	O
agrees	O
with	O
the	O
hypothesis	O
of	O
He	O
et	O
al	O
.	O
.	O
	
Removing	O
the	O
residual	O
connections	O
massively	O
increases	O
the	O
error	B-Metric
by	O
mm	O
.	O
	
When	O
we	O
do	O
not	O
apply	O
layer	B-Method
normalization	I-Method
on	O
LSTM	B-Method
units	O
,	O
the	O
error	B-Metric
increases	O
by	O
mm	B-Method
.	O
	
On	O
the	O
other	O
hand	O
when	O
dropout	O
is	O
not	O
performed	O
,	O
the	O
error	B-Metric
raises	O
by	O
mm	O
.	O
	
When	O
both	O
layer	B-Method
normalization	I-Method
and	O
recurrent	B-Method
dropout	I-Method
are	O
not	O
used	O
the	O
results	O
get	O
worse	O
by	O
mm	B-Method
.	O
	
Although	O
the	O
temporal	O
consistency	O
constraint	O
may	O
seem	O
to	O
have	O
less	O
impact	O
(	O
only	O
mm	O
)	O
quantitatively	O
on	O
the	O
performance	O
of	O
our	O
network	O
,	O
it	O
ensures	O
that	O
the	O
predictions	O
over	O
a	O
sequence	O
are	O
smooth	O
and	O
temporally	O
consistent	O
which	O
is	O
apparent	O
from	O
our	O
qualitative	O
results	O
as	O
seen	O
in	O
Figure	O
[	O
reference	O
]	O
and	O
Figure	O
[	O
reference	O
]	O
.	O
	
To	O
show	O
the	O
effectiveness	O
of	O
our	O
model	O
on	O
detections	B-Task
from	O
different	O
2D	B-Method
pose	I-Method
detectors	I-Method
,	O
we	O
also	O
experimented	O
with	O
the	O
detections	O
from	O
CPM	B-Method
and	O
from	O
stacked	B-Method
-	I-Method
hourglass	I-Method
(	O
SH	B-Method
)	O
module	O
which	O
is	O
not	O
fine	O
-	O
tuned	O
on	O
Human3.6	B-Material
M	I-Material
dataset	I-Material
.	O
	
We	O
observe	O
that	O
even	O
for	O
the	O
non	O
-	O
fine	B-Method
tuned	I-Method
stacked	I-Method
hourglass	I-Method
detections	I-Method
,	O
our	O
model	O
achieves	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
results	O
.	O
	
For	O
detections	O
from	O
CPM	B-Method
,	O
our	O
model	O
achieves	O
competitive	B-Metric
accuracy	I-Metric
for	O
the	O
predictions	B-Task
.	O
	
paragraph	O
:	O
Performance	O
on	O
different	O
sequence	O
lengths	O
	
The	O
results	O
reported	O
so	O
far	O
have	O
been	O
for	O
input	O
and	O
output	O
sequences	O
of	O
length	O
5	O
.	O
	
We	O
carried	O
out	O
experiments	O
to	O
see	O
how	O
our	O
network	O
performs	O
for	O
different	O
sequence	O
lengths	O
ranging	O
from	O
2	O
to	O
10	O
.	O
	
The	O
results	O
are	O
shown	O
in	O
Figure	O
[	O
reference	O
]	O
.	O
	
As	O
can	O
be	O
seen	O
,	O
the	O
performance	O
of	O
our	O
network	O
remains	O
stable	O
for	O
sequences	O
of	O
varying	O
lengths	O
.	O
	
Even	O
for	O
a	O
sequence	O
length	O
of	O
2	O
,	O
which	O
only	O
considers	O
the	O
previous	O
and	O
the	O
current	O
frame	O
,	O
our	O
model	O
generates	O
very	O
good	O
results	O
.	O
	
Particularly	O
the	O
best	O
results	O
were	O
obtained	O
for	O
length	O
4	O
,	O
5	O
and	O
6	O
.	O
	
However	O
,	O
we	O
chose	O
sequence	O
length	O
5	O
for	O
carrying	O
out	O
our	O
experiments	O
as	O
a	O
compromise	O
between	O
training	B-Metric
time	I-Metric
and	O
accuracy	B-Metric
.	O
	
subsection	O
:	O
Qualitative	B-Method
Analysis	I-Method
	
We	O
provide	O
qualitative	O
results	O
on	O
some	O
videos	O
of	O
Human3.6	B-Material
M	I-Material
and	O
Youtube	B-Material
.	O
	
We	O
apply	O
the	O
model	O
trained	O
on	O
the	O
Human3.6	B-Material
M	I-Material
dataset	I-Material
on	O
some	O
videos	O
gathered	O
from	O
Youtube	O
,	O
The	O
bounding	O
box	O
for	O
each	O
person	O
in	O
the	O
Youtube	B-Material
video	I-Material
is	O
labeled	O
manually	O
and	O
for	O
	
Human3.6	B-Material
M	I-Material
the	O
ground	O
truth	O
bounding	O
box	O
is	O
used	O
.	O
	
The	O
2D	O
poses	O
are	O
detected	O
using	O
the	O
stacked	B-Method
-	I-Method
hourglass	I-Method
model	O
fine	O
-	O
tuned	O
on	O
Human3.6	B-Material
M	I-Material
data	O
.	O
	
The	O
qualitative	O
result	O
for	O
Youtube	B-Material
videos	I-Material
is	O
shown	O
in	O
Figure	O
[	O
reference	O
]	O
and	O
for	O
Human3.6	B-Material
M	I-Material
in	O
Figure	O
[	O
reference	O
]	O
.	O
	
The	O
real	O
advantage	O
of	O
using	O
the	O
temporal	O
smoothness	O
constraint	O
during	O
training	O
is	O
apparent	O
in	O
these	O
figures	O
.	O
	
For	O
Figure	O
[	O
reference	O
]	O
,	O
we	O
can	O
see	O
that	O
even	O
when	O
the	O
2D	B-Method
pose	I-Method
estimator	I-Method
breaks	O
or	O
generates	O
extremely	O
noisy	O
detections	O
,	O
our	O
system	O
can	O
recover	O
temporally	O
coherent	O
3D	O
poses	O
by	O
exploiting	O
the	O
temporal	O
consistency	O
information	O
.	O
	
A	O
similar	O
trend	O
can	O
also	O
be	O
found	O
for	O
Human3.6	B-Material
M	I-Material
videos	O
in	O
Figure	O
[	O
reference	O
]	O
,	O
particularly	O
for	O
the	O
action	O
sitting	O
down	O
of	O
subject	O
11	O
.	O
	
We	O
have	O
provided	O
more	O
qualitative	O
results	O
in	O
the	O
supplementary	O
material	O
.	O
	
section	O
:	O
Conclusion	O
	
Both	O
the	O
quantitative	O
and	O
qualitative	O
results	O
for	O
our	O
network	O
show	O
the	O
effectiveness	O
of	O
exploiting	O
temporal	O
information	O
over	O
multiple	O
sequences	O
to	O
estimate	O
3D	O
poses	O
which	O
are	O
temporally	O
smooth	O
.	O
	
Our	O
network	O
achieved	O
the	O
best	O
accuracy	B-Metric
till	O
date	O
on	O
all	O
of	O
the	O
15	O
action	O
classes	O
in	O
the	O
Human3.6	B-Material
M	I-Material
dataset	I-Material
.	O
	
Particularly	O
,	O
most	O
of	O
the	O
previous	O
methods	O
struggled	O
with	O
actions	O
which	O
have	O
a	O
high	O
degree	O
of	O
occlusion	O
like	O
taking	O
photo	O
,	O
talking	O
on	O
the	O
phone	O
,	O
sitting	O
and	O
sitting	O
down	O
.	O
	
Our	O
network	O
has	O
significantly	O
better	O
results	O
on	O
these	O
actions	O
.	O
	
Additionally	O
we	O
found	O
that	O
our	O
network	O
is	O
reasonably	O
robust	O
to	O
noisy	O
2D	O
poses	O
.	O
	
Although	O
the	O
contribution	O
of	O
temporal	O
smoothness	O
constraint	O
is	O
not	O
apparent	O
in	O
the	O
ablative	B-Method
analysis	I-Method
in	O
Table	O
[	O
reference	O
]	O
,	O
its	O
effectiveness	O
is	O
clearly	O
visible	O
in	O
the	O
qualitative	O
results	O
,	O
particularly	O
on	O
challenging	O
Youtube	B-Material
videos	I-Material
(	O
see	O
Figure	O
[	O
reference	O
]	O
)	O
.	O
	
Our	O
network	O
effectively	O
demonstrates	O
the	O
power	O
of	O
using	O
temporal	O
context	O
information	O
which	O
we	O
achieved	O
using	O
a	O
sequence	B-Method
-	I-Method
to	I-Method
-	I-Method
sequence	I-Method
network	I-Method
that	O
can	O
be	O
trained	O
efficiently	O
in	O
a	O
reasonably	O
quick	O
time	O
.	O
	
Also	O
our	O
network	O
makes	O
predictions	O
from	O
2D	O
poses	O
at	O
3ms	O
per	O
frame	O
on	O
average	O
which	O
suggests	O
that	O
,	O
given	O
the	O
2D	B-Method
pose	I-Method
detector	I-Method
is	O
real	O
time	O
,	O
our	O
network	O
can	O
be	O
applied	O
in	O
real	B-Task
-	I-Task
time	I-Task
scenarios	I-Task
.	O
	
bibliography	O
:	O
References	O
	
Probabilistic	B-Method
Model	I-Method
-	I-Method
Agnostic	I-Method
Meta	I-Method
-	I-Method
Learning	I-Method
	
section	O
:	O
Abstract	O
	
Meta	B-Method
-	I-Method
learning	I-Method
for	O
few	B-Task
-	I-Task
shot	I-Task
learning	I-Task
entails	O
acquiring	O
a	O
prior	O
over	O
previous	O
tasks	O
and	O
experiences	O
,	O
such	O
that	O
new	O
tasks	O
be	O
learned	O
from	O
small	O
amounts	O
of	O
data	O
.	O
	
However	O
,	O
a	O
critical	O
challenge	O
in	O
few	B-Task
-	I-Task
shot	I-Task
learning	I-Task
is	O
task	B-Task
ambiguity	I-Task
:	O
even	O
when	O
a	O
powerful	O
prior	O
can	O
be	O
meta	O
-	O
learned	O
from	O
a	O
large	O
number	O
of	O
prior	O
tasks	O
,	O
a	O
small	O
dataset	O
for	O
a	O
new	O
task	O
can	O
simply	O
be	O
too	O
ambiguous	O
to	O
acquire	O
a	O
single	O
model	O
(	O
e.g.	O
,	O
a	O
classifier	B-Method
)	O
for	O
that	O
task	O
that	O
is	O
accurate	O
.	O
	
In	O
this	O
paper	O
,	O
we	O
propose	O
a	O
probabilistic	B-Method
meta	I-Method
-	I-Method
learning	I-Method
algorithm	I-Method
that	O
can	O
sample	O
models	O
for	O
a	O
new	O
task	O
from	O
a	O
model	O
distribution	O
.	O
	
Our	O
approach	O
extends	O
model	B-Method
-	I-Method
agnostic	I-Method
meta	I-Method
-	I-Method
learning	I-Method
,	O
which	O
adapts	O
to	O
new	O
tasks	O
via	O
gradient	B-Method
descent	I-Method
,	O
to	O
incorporate	O
a	O
parameter	O
distribution	O
that	O
is	O
trained	O
via	O
a	O
variational	O
lower	O
bound	O
.	O
	
At	O
meta	O
-	O
test	O
time	O
,	O
our	O
algorithm	O
adapts	O
via	O
a	O
simple	O
procedure	O
that	O
injects	O
noise	O
into	O
gradient	B-Method
descent	I-Method
,	O
and	O
at	O
meta	B-Task
-	I-Task
training	I-Task
time	I-Task
,	O
the	O
model	O
is	O
trained	O
such	O
that	O
this	O
stochastic	B-Method
adaptation	I-Method
procedure	I-Method
produces	O
samples	O
from	O
the	O
approximate	B-Method
model	I-Method
posterior	I-Method
.	O
	
Our	O
experimental	O
results	O
show	O
that	O
our	O
method	O
can	O
sample	O
plausible	B-Method
classifiers	I-Method
and	O
regressors	B-Method
in	O
ambiguous	B-Task
few	I-Task
-	I-Task
shot	I-Task
learning	I-Task
problems	I-Task
.	O
	
section	O
:	O
Introduction	O
	
Learning	O
from	O
a	O
few	O
examples	O
is	O
a	O
key	O
aspect	O
of	O
human	B-Task
intelligence	I-Task
.	O
	
One	O
way	O
to	O
make	O
it	O
possible	O
to	O
acquire	O
solutions	O
to	O
complex	O
tasks	O
from	O
only	O
a	O
few	O
examples	O
is	O
to	O
leverage	O
past	O
experience	O
to	O
learn	O
a	O
prior	O
over	O
tasks	O
.	O
	
The	O
process	O
of	O
learning	O
this	O
prior	O
entails	O
discovering	O
the	O
shared	O
structure	O
across	O
different	O
tasks	O
from	O
the	O
same	O
family	O
,	O
such	O
as	O
commonly	O
occurring	O
visual	O
features	O
or	O
semantic	O
cues	O
.	O
	
Structure	B-Method
is	O
useful	O
insofar	O
as	O
it	O
yields	O
efficient	O
learning	B-Task
of	I-Task
new	I-Task
tasks	I-Task
-	O
a	O
mechanism	O
known	O
as	O
learning	B-Task
-	I-Task
to	I-Task
-	I-Task
learn	I-Task
,	O
or	O
meta	B-Method
-	I-Method
learning	I-Method
	
[	O
reference	O
]	O
.	O
However	O
,	O
when	O
the	O
end	O
goal	O
of	O
few	B-Method
-	I-Method
shot	I-Method
meta	I-Method
-	I-Method
learning	I-Method
is	O
to	O
learn	O
solutions	O
to	O
new	O
tasks	O
from	O
small	O
amounts	O
of	O
data	O
,	O
a	O
critical	O
issue	O
that	O
must	O
be	O
dealt	O
with	O
is	O
task	B-Task
ambiguity	I-Task
:	O
even	O
with	O
the	O
best	O
possible	O
prior	O
,	O
there	O
might	O
simply	O
not	O
be	O
enough	O
information	O
in	O
the	O
examples	O
for	O
a	O
new	O
task	O
to	O
resolve	O
that	O
task	O
with	O
high	O
certainty	O
.	O
	
It	O
is	O
therefore	O
quite	O
desireable	O
to	O
develop	O
few	B-Method
-	I-Method
shot	I-Method
meta	I-Method
-	I-Method
learning	I-Method
methods	I-Method
that	O
can	O
propose	O
multiple	O
potential	O
solutions	O
to	O
an	O
ambiguous	B-Task
few	I-Task
-	I-Task
shot	I-Task
learning	I-Task
problem	I-Task
.	O
	
Such	O
a	O
method	O
could	O
be	O
used	O
to	O
evaluate	O
uncertainty	O
(	O
by	O
measuring	O
agreement	O
between	O
the	O
samples	O
)	O
,	O
perform	O
active	B-Method
learning	I-Method
,	O
or	O
elicit	O
direct	O
human	O
supervision	O
about	O
which	O
sample	O
is	O
preferable	O
.	O
	
For	O
example	O
,	O
in	O
safety	B-Task
-	I-Task
critical	I-Task
applications	I-Task
,	O
such	O
as	O
few	B-Task
-	I-Task
shot	I-Task
medical	I-Task
image	I-Task
classification	I-Task
,	O
uncertainty	B-Task
is	O
crucial	O
for	O
determining	O
if	O
the	O
learned	O
classifier	B-Method
should	O
be	O
trusted	O
.	O
	
When	O
learning	B-Task
from	O
such	O
small	O
amounts	O
of	O
data	O
,	O
uncertainty	B-Task
estimation	I-Task
can	O
also	O
help	O
predict	O
if	O
additional	O
data	O
would	O
be	O
beneficial	O
for	O
learning	B-Task
and	O
improving	O
the	O
estimate	O
of	O
the	O
rewards	O
.	O
	
Finally	O
,	O
while	O
we	O
do	O
not	O
experiment	O
with	O
this	O
in	O
this	O
paper	O
,	O
we	O
expect	O
that	O
modeling	O
this	O
ambiguity	O
will	O
be	O
helpful	O
for	O
reinforcement	B-Task
learning	I-Task
problems	I-Task
,	O
where	O
it	O
can	O
be	O
used	O
to	O
aid	O
in	O
exploration	B-Task
.	O
	
While	O
recognizing	O
and	O
accounting	O
for	O
ambiguity	B-Task
is	O
an	O
important	O
aspect	O
of	O
the	O
few	B-Task
-	I-Task
shot	I-Task
learning	I-Task
problem	I-Task
,	O
it	O
is	O
particularly	O
challenging	O
to	O
model	O
when	O
scaling	O
to	O
high	O
-	O
dimensional	O
data	O
,	O
large	O
function	B-Method
approximators	I-Method
,	O
and	O
multimodal	O
task	O
structure	O
.	O
	
Representing	O
distributions	O
over	O
functions	O
is	O
relatively	O
straightforward	O
when	O
using	O
simple	O
function	B-Method
approximators	I-Method
,	O
such	O
as	O
linear	B-Method
functions	I-Method
,	O
and	O
has	O
been	O
done	O
extensively	O
in	O
early	O
few	B-Method
-	I-Method
shot	I-Method
learning	I-Method
approaches	I-Method
using	O
Bayesian	B-Method
models	I-Method
	
[	O
reference	O
][	O
reference	O
]	O
.	O
	
But	O
this	O
problem	O
becomes	O
substantially	O
more	O
challenging	O
when	O
reasoning	O
over	O
high	B-Method
-	I-Method
dimensional	I-Method
function	I-Method
approximators	I-Method
such	O
as	O
deep	B-Method
neural	I-Method
networks	I-Method
,	O
since	O
explicitly	O
representing	O
expressive	O
distributions	O
over	O
thousands	O
or	O
millions	O
of	O
parameters	O
if	O
often	O
intractable	O
.	O
	
As	O
a	O
result	O
,	O
recent	O
more	O
scalable	O
approaches	O
to	O
few	B-Task
-	I-Task
shot	I-Task
learning	I-Task
have	O
focused	O
on	O
acquiring	O
deterministic	B-Method
learning	I-Method
algorithms	I-Method
that	O
disregard	O
ambiguity	O
over	O
the	O
underlying	O
function	O
.	O
	
Can	O
we	O
develop	O
an	O
approach	O
that	O
has	O
the	O
benefits	O
of	O
both	O
classes	O
of	O
few	B-Method
-	I-Method
shot	I-Method
learning	I-Method
methods	I-Method
-	O
scalability	O
and	O
uncertainty	B-Task
awareness	I-Task
?	O
	
To	O
do	O
so	O
,	O
we	O
build	O
upon	O
tools	O
in	O
amortized	B-Method
variational	I-Method
inference	I-Method
for	O
developing	O
a	O
probabilistic	B-Method
meta	I-Method
-	I-Method
learning	I-Method
approach	I-Method
.	O
	
In	O
particular	O
,	O
our	O
method	O
builds	O
on	O
model	B-Method
-	I-Method
agnostic	I-Method
meta	I-Method
-	I-Method
learning	I-Method
(	O
MAML	B-Method
)	O
	
[	O
reference	O
]	O
,	O
a	O
few	B-Method
shot	I-Method
metalearning	I-Method
algorithm	I-Method
that	O
uses	O
standard	O
gradient	B-Method
descent	I-Method
to	O
adapt	O
the	O
model	O
at	O
meta	O
-	O
test	O
time	O
to	O
a	O
new	O
few	B-Task
-	I-Task
shot	I-Task
task	I-Task
,	O
and	O
trains	O
the	O
model	B-Method
parameters	I-Method
at	O
meta	O
-	O
training	O
time	O
to	O
enable	O
rapid	B-Task
adaptation	I-Task
,	O
essentially	O
optimizing	O
for	O
a	O
neural	B-Method
network	I-Method
initialization	I-Method
that	O
is	O
well	O
-	O
suited	O
for	O
few	B-Task
shot	I-Task
learning	I-Task
.	O
	
MAML	B-Method
can	O
be	O
shown	O
to	O
retain	O
the	O
generality	O
of	O
black	B-Method
-	I-Method
box	I-Method
meta	I-Method
-	I-Method
learners	I-Method
such	O
as	O
RNNs	B-Method
[	O
reference	O
]	O
,	O
while	O
being	O
applicable	O
to	O
standard	O
neural	B-Method
network	I-Method
architectures	I-Method
.	O
	
Our	O
approach	O
extends	O
MAML	B-Method
to	O
model	O
a	O
distribution	O
over	O
prior	O
model	O
parameters	O
,	O
which	O
leads	O
to	O
an	O
appealing	O
simple	O
stochastic	B-Method
adaptation	I-Method
procedure	I-Method
that	O
simply	O
injects	O
noise	O
into	O
gradient	B-Method
descent	I-Method
at	O
meta	O
-	O
test	O
time	O
.	O
	
The	O
meta	B-Method
-	I-Method
training	I-Method
procedure	I-Method
then	O
optimizes	O
for	O
this	O
simple	O
inference	B-Method
process	I-Method
to	O
produce	O
samples	O
from	O
an	O
approximate	O
model	O
posterior	O
.	O
	
The	O
primary	O
contribution	O
of	O
this	O
paper	O
is	O
a	O
reframing	O
of	O
MAML	B-Method
as	O
a	O
graphical	B-Task
model	I-Task
inference	I-Task
problem	I-Task
,	O
where	O
variational	B-Method
inference	I-Method
can	O
provide	O
us	O
with	O
a	O
principled	O
and	O
natural	O
mechanism	O
for	O
modeling	B-Task
uncertainty	I-Task
and	I-Task
ambiguity	I-Task
.	O
	
Our	O
approach	O
enables	O
sampling	O
multiple	O
potential	O
solutions	O
to	O
a	O
few	B-Task
-	I-Task
shot	I-Task
learning	I-Task
problem	I-Task
at	O
meta	O
-	O
test	O
time	O
,	O
and	O
our	O
experiments	O
show	O
that	O
this	O
ability	O
can	O
be	O
utilized	O
to	O
sample	O
multiple	O
possible	O
regressors	O
for	O
an	O
ambiguous	B-Task
regression	I-Task
problem	I-Task
,	O
as	O
well	O
as	O
multiple	O
possible	O
classifiers	B-Method
for	O
ambiguous	B-Task
few	I-Task
-	I-Task
shot	I-Task
attribute	I-Task
classification	I-Task
tasks	I-Task
.	O
	
section	O
:	O
Related	O
Work	O
	
Hierarchical	B-Method
Bayesian	I-Method
models	I-Method
are	O
a	O
long	O
-	O
standing	O
approach	O
for	O
few	B-Task
-	I-Task
shot	I-Task
learning	I-Task
that	O
naturally	O
allow	O
for	O
the	O
ability	O
to	O
reason	O
about	O
uncertainty	O
over	O
functions	O
	
[	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
.	O
	
While	O
these	O
approaches	O
have	O
been	O
demonstrated	O
on	O
simple	O
few	B-Task
-	I-Task
shot	I-Task
image	I-Task
classification	I-Task
datasets	I-Task
[	O
reference	O
]	O
,	O
they	O
have	O
yet	O
to	O
scale	O
to	O
the	O
more	O
complex	O
problems	O
,	O
such	O
as	O
the	O
experiments	O
in	O
this	O
paper	O
.	O
	
A	O
number	O
of	O
works	O
have	O
approached	O
the	O
problem	O
of	O
few	B-Task
-	I-Task
shot	I-Task
learning	I-Task
from	O
a	O
meta	B-Method
-	I-Method
learning	I-Method
perspective	I-Method
[	O
reference	O
][	O
reference	O
]	O
,	O
including	O
black	B-Method
-	I-Method
box	I-Method
[	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
and	O
optimization	B-Method
-	I-Method
based	I-Method
approaches	I-Method
[	O
reference	O
][	O
reference	O
]	O
.	O
While	O
these	O
approaches	O
scale	O
to	O
large	O
-	O
scale	O
image	O
datasets	O
[	O
reference	O
]	O
and	O
visual	B-Task
reinforcement	I-Task
learning	I-Task
problems	I-Task
[	O
reference	O
]	O
,	O
they	O
typically	O
lack	O
the	O
ability	O
to	O
reason	O
about	O
uncertainty	O
.	O
	
Our	O
work	O
is	O
most	O
related	O
to	O
methods	O
that	O
combine	O
deep	B-Method
networks	I-Method
and	O
probabilistic	B-Method
methods	I-Method
for	O
few	B-Task
-	I-Task
shot	I-Task
learning	I-Task
	
[	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
.	O
One	O
approach	O
that	O
considers	O
hierarchical	B-Method
Bayesian	I-Method
models	I-Method
for	O
few	B-Task
-	I-Task
shot	I-Task
learning	I-Task
is	O
the	O
neural	B-Method
statistician	I-Method
[	O
reference	O
]	O
,	O
which	O
uses	O
an	O
explicit	O
task	O
variable	O
to	O
model	O
task	O
distributions	O
.	O
	
Our	O
method	O
is	O
fully	O
model	B-Method
agnostic	I-Method
,	O
and	O
directly	O
samples	O
model	O
weights	O
for	O
each	O
task	O
for	O
any	O
network	B-Method
architecture	I-Method
.	O
	
Our	O
experiments	O
show	O
that	O
our	O
approach	O
improves	O
on	O
MAML	B-Method
[	O
reference	O
]	O
,	O
which	O
outperforms	O
the	O
model	O
by	O
Edwards	O
and	O
Storkey	O
	
[	O
reference	O
]	O
.	O
Other	O
work	O
that	O
considers	O
model	B-Task
uncertainty	I-Task
in	O
the	O
few	B-Task
-	I-Task
shot	I-Task
learning	I-Task
setting	I-Task
is	O
the	O
LLAMA	B-Method
method	I-Method
[	O
reference	O
]	O
,	O
which	O
also	O
builds	O
on	O
the	O
MAML	B-Method
algorithm	O
.	O
	
LLAMA	B-Method
makes	O
use	O
of	O
a	O
local	B-Method
Laplace	I-Method
approximation	I-Method
for	O
modeling	O
the	O
task	O
parameters	O
(	O
post	O
-	O
update	O
parameters	O
)	O
,	O
which	O
introduces	O
the	O
need	O
to	O
approximate	O
a	O
high	O
dimensional	O
covariance	O
matrix	O
.	O
	
We	O
instead	O
propose	O
a	O
method	O
that	O
approximately	O
infers	O
the	O
pre	O
-	O
update	O
parameters	O
,	O
which	O
we	O
make	O
tractable	O
through	O
a	O
choice	O
of	O
approximate	O
posterior	O
parameterized	O
by	O
gradient	B-Method
operations	I-Method
.	O
	
Bayesian	B-Method
neural	I-Method
networks	I-Method
[	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
have	O
been	O
studied	O
extensively	O
as	O
a	O
way	O
to	O
incorporate	O
uncertainty	O
into	O
deep	B-Method
networks	I-Method
.	O
	
Although	O
exact	B-Task
inference	I-Task
in	O
Bayesian	B-Method
neural	I-Method
networks	I-Method
is	O
impractical	O
,	O
approximations	O
based	O
on	O
backpropagation	B-Method
and	I-Method
sampling	I-Method
[	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
have	O
been	O
effective	O
in	O
incorporating	O
uncertainty	O
into	O
the	O
weights	O
of	O
generic	B-Method
networks	I-Method
.	O
	
Our	O
approach	O
differs	O
from	O
these	O
methods	O
in	O
that	O
we	O
explicitly	O
train	O
a	O
hierarchical	B-Method
Bayesian	I-Method
model	I-Method
over	O
weights	O
,	O
where	O
a	O
posterior	O
task	O
-	O
specific	O
parameter	O
distribution	O
is	O
inferred	O
at	O
meta	O
-	O
test	O
time	O
conditioned	O
on	O
a	O
learned	O
weight	O
prior	O
and	O
a	O
(	O
few	O
-	O
shot	O
)	O
training	O
set	O
,	O
while	O
conventional	O
Bayesian	B-Method
neural	I-Method
networks	I-Method
directly	O
learn	O
only	O
the	O
posterior	O
weight	O
distribution	O
for	O
a	O
single	O
task	O
.	O
	
Our	O
method	O
draws	O
on	O
amortized	B-Method
variational	I-Method
inference	I-Method
methods	I-Method
[	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
to	O
make	O
this	O
possible	O
,	O
but	O
the	O
key	O
modification	O
is	O
that	O
the	O
model	O
and	O
inference	B-Method
networks	I-Method
share	O
the	O
same	O
parameters	O
.	O
	
The	O
resulting	O
method	O
corresponds	O
structurally	O
to	O
a	O
Bayesian	O
version	O
of	O
model	B-Method
-	I-Method
agnostic	I-Method
meta	I-Method
-	I-Method
learning	I-Method
[	O
reference	O
]	O
.	O
into	O
the	O
center	B-Method
model	I-Method
after	O
performing	O
inference	O
over	O
φi	O
.	O
	
We	O
find	O
it	O
beneficial	O
to	O
introduce	O
additional	O
dependencies	O
of	O
the	O
prior	O
on	O
the	O
training	O
data	O
to	O
compensate	O
for	O
using	O
the	O
MAP	B-Metric
estimate	O
to	O
approximate	O
p	O
(	O
φi	O
)	O
,	O
as	O
shown	O
on	O
the	O
right	O
.	O
	
section	O
:	O
Preliminaries	O
	
In	O
the	O
meta	B-Task
-	I-Task
learning	I-Task
problem	I-Task
setting	I-Task
that	O
we	O
consider	O
,	O
the	O
goal	O
is	O
to	O
learn	O
models	O
that	O
can	O
learn	O
new	O
tasks	O
from	O
small	O
amounts	O
of	O
data	O
.	O
	
To	O
do	O
so	O
,	O
meta	B-Method
-	I-Method
learning	I-Method
algorithms	I-Method
require	O
a	O
set	O
of	O
meta	O
-	O
training	O
and	O
meta	B-Task
-	I-Task
testing	I-Task
tasks	I-Task
drawn	O
from	O
some	O
distribution	B-Method
p	I-Method
(	I-Method
T	I-Method
)	O
.	O
	
The	O
key	O
assumption	O
of	O
learning	B-Task
-	I-Task
to	I-Task
-	I-Task
learn	I-Task
is	O
that	O
the	O
tasks	O
in	O
this	O
distribution	O
share	O
common	O
structure	O
that	O
can	O
be	O
exploited	O
for	O
faster	B-Task
learning	I-Task
of	I-Task
new	I-Task
tasks	I-Task
.	O
	
Thus	O
,	O
the	O
goal	O
of	O
the	O
meta	B-Method
-	I-Method
learning	I-Method
process	I-Method
is	O
to	O
discover	O
that	O
structure	O
.	O
	
In	O
this	O
section	O
,	O
we	O
will	O
introduce	O
notation	O
and	O
overview	O
the	O
model	B-Method
-	I-Method
agnostic	I-Method
meta	I-Method
-	I-Method
learning	I-Method
(	O
MAML	B-Method
)	O
algorithm	O
[	O
reference	O
]	O
.	O
	
Meta	B-Method
-	I-Method
learning	I-Method
algorithms	I-Method
proceed	O
by	O
sampling	O
data	O
from	O
a	O
given	O
task	O
,	O
and	O
splitting	O
the	O
sampled	O
data	O
into	O
a	O
set	O
of	O
a	O
few	O
datapoints	O
,	O
	
D	O
	
where	O
φ	O
i	O
is	O
used	O
to	O
denote	O
the	O
parameters	O
updated	O
by	O
gradient	B-Method
descent	I-Method
and	O
where	O
the	O
loss	O
corresponds	O
to	O
negative	O
log	O
likelihood	O
of	O
the	O
data	O
.	O
	
In	O
particular	O
,	O
in	O
the	O
case	O
of	O
supervised	B-Task
classification	I-Task
with	O
inputs	O
{	O
x	O
j	O
}	O
,	O
their	O
corresponding	O
labels	O
{	O
y	O
j	O
}	O
,	O
and	O
a	O
classifier	B-Method
f	I-Method
θ	I-Method
,	O
we	O
will	O
denote	O
the	O
negative	O
log	O
likelihood	O
of	O
the	O
data	O
under	O
the	O
classifier	B-Method
as	O
L	O
(	O
θ	O
,	O
D	O
)	O
=	O
	
−	O
(	O
xj	O
,	O
yj	O
)	O
∈D	O
log	O
	
p	O
(	O
y	O
	
j	O
	
|x	O
j	O
,	O
θ	O
)	O
.	O
	
This	O
corresponds	O
to	O
the	O
cross	O
entropy	O
loss	O
function	O
.	O
	
section	O
:	O
Method	O
	
Our	O
goal	O
is	O
to	O
build	O
a	O
meta	B-Method
-	I-Method
learning	I-Method
method	I-Method
that	O
can	O
handle	O
the	O
uncertainty	O
and	O
ambiguity	O
that	O
occurs	O
when	O
learning	O
from	O
small	O
amounts	O
of	O
data	O
,	O
while	O
scaling	O
to	O
highly	O
-	O
expressive	O
function	B-Method
approximators	I-Method
such	O
as	O
neural	B-Method
networks	I-Method
.	O
	
To	O
do	O
so	O
,	O
we	O
set	O
up	O
a	O
graphical	B-Method
model	I-Method
for	O
the	O
few	B-Task
-	I-Task
shot	I-Task
learning	I-Task
problem	I-Task
.	O
	
In	O
particular	O
,	O
we	O
want	O
a	O
hierarchical	B-Method
Bayesian	I-Method
model	I-Method
that	O
includes	O
random	O
variables	O
for	O
the	O
prior	O
distribution	O
over	O
function	O
parameters	O
,	O
θ	O
,	O
the	O
distribution	O
over	O
parameters	O
for	O
a	O
particular	O
task	O
,	O
φ	O
i	O
,	O
and	O
the	O
task	O
training	O
and	O
test	O
datapoints	O
.	O
	
This	O
graphical	B-Method
model	I-Method
is	O
illustrated	O
in	O
Figure	O
1	O
(	O
left	O
)	O
,	O
where	O
tasks	O
are	O
indexed	O
over	O
i	O
and	O
datapoints	O
are	O
indexed	O
over	O
j.	O
	
We	O
will	O
use	O
the	O
shorthand	O
x	O
.	O
	
Therefore	O
,	O
posterior	B-Task
inference	I-Task
over	O
φ	O
i	O
must	O
take	O
into	O
account	O
both	O
the	O
evidence	O
(	O
training	O
set	O
)	O
and	O
the	O
prior	O
imposed	O
by	O
p	O
(	O
θ	O
)	O
and	O
p	O
(	O
φ	O
i	O
|θ	O
)	O
.	O
	
Conventional	O
MAML	B-Method
can	O
be	O
interpreted	O
as	O
approximating	O
maximum	B-Method
a	I-Method
posteriori	I-Method
inference	I-Method
under	O
a	O
simplified	O
model	O
where	O
p	O
(	O
θ	O
)	O
is	O
a	O
delta	O
function	O
,	O
and	O
inference	B-Task
is	O
performed	O
by	O
running	O
gradient	B-Method
descent	I-Method
on	O
log	O
	
p	O
(	O
y	O
	
tr	O
	
|x	O
tr	O
,	O
φ	O
i	O
)	O
for	O
a	O
fixed	O
number	O
of	O
iterations	O
starting	O
from	O
φ	O
[	O
reference	O
]	O
.	O
The	O
corresponding	O
distribution	O
p	O
(	O
φ	O
i	O
|θ	O
)	O
is	O
approximately	O
Gaussian	O
,	O
with	O
a	O
mean	O
that	O
depends	O
on	O
the	O
step	O
size	O
and	O
number	O
of	O
gradient	O
steps	O
.	O
	
When	O
p	O
(	O
θ	O
)	O
is	O
not	O
deterministic	O
,	O
we	O
must	O
make	O
a	O
further	O
approximation	O
to	O
account	O
for	O
the	O
random	O
variable	O
θ	O
.	O
	
One	O
way	O
we	O
can	O
do	O
this	O
is	O
by	O
using	O
structured	B-Method
variational	I-Method
inference	I-Method
.	O
	
In	O
structured	B-Task
variational	I-Task
inference	I-Task
,	O
we	O
approximate	O
the	O
distribution	O
over	O
the	O
hidden	O
variables	O
θ	O
and	O
φ	O
i	O
for	O
each	O
task	O
with	O
some	O
approximate	O
distribution	O
q	O
i	O
(	O
θ	O
,	O
φ	O
i	O
)	O
.	O
	
There	O
are	O
two	O
reasonable	O
choices	O
we	O
can	O
make	O
for	O
q	O
i	O
(	O
θ	O
,	O
φ	O
i	O
)	O
.	O
	
First	O
,	O
we	O
can	O
approximate	O
it	O
as	O
a	O
product	O
of	O
independent	O
marginals	O
,	O
according	O
to	O
	
However	O
,	O
this	O
approximation	O
does	O
not	O
permit	O
uncertainty	O
to	O
propagate	O
effectively	O
from	O
θ	O
to	O
φ	O
i	O
.	O
	
A	O
more	O
expressive	O
approximation	O
is	O
the	O
structured	B-Method
variational	I-Method
approximation	I-Method
	
We	O
can	O
further	O
avoid	O
storing	O
a	O
separate	O
variational	B-Method
distribution	I-Method
	
q	O
i	O
(	O
φ	O
i	O
|θ	O
)	O
and	O
	
q	O
i	O
(	O
θ	O
)	O
for	O
each	O
task	O
	
T	O
i	O
by	O
employing	O
an	O
amortized	B-Method
variational	I-Method
inference	I-Method
technique	I-Method
[	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
,	O
where	O
we	O
instead	O
set	O
	
,	O
where	O
q	O
ψ	O
is	O
defined	O
by	O
some	O
function	B-Method
approximator	I-Method
with	O
parameters	O
ψ	O
that	O
takes	O
x	O
tr	O
i	O
,	O
	
y	O
tr	O
	
i	O
as	O
input	O
,	O
and	O
the	O
same	O
q	O
ψ	O
is	O
used	O
for	O
all	O
tasks	O
.	O
	
Similarly	O
,	O
we	O
can	O
define	O
	
We	O
can	O
now	O
write	O
down	O
the	O
variational	B-Metric
lower	I-Metric
bound	I-Metric
on	O
the	O
log	O
-	O
likelihood	O
as	O
	
The	O
likelihood	O
terms	O
on	O
the	O
first	O
line	O
can	O
be	O
evaluated	O
efficiently	O
:	O
given	O
a	O
sample	O
θ	O
,	O
φ	O
i	O
∼	O
q	O
(	O
θ	O
,	O
φ	O
i	O
	
|x	O
	
,	O
the	O
training	O
and	O
test	O
likelihoods	O
simply	O
correspond	O
to	O
the	O
loss	O
of	O
the	O
network	O
with	O
parameters	O
φ	O
i	O
.	O
	
The	O
prior	O
p	O
(	O
θ	O
)	O
can	O
be	O
chosen	O
to	O
be	O
Gaussian	O
,	O
with	O
a	O
learned	O
mean	O
and	O
(	O
diagonal	O
)	O
covariance	O
to	O
provide	O
for	O
flexibility	O
to	O
choose	O
the	O
prior	O
parameters	O
.	O
	
This	O
corresponds	O
to	O
a	O
Bayesian	B-Method
version	I-Method
of	O
the	O
MAML	B-Method
algorithm	O
.	O
	
We	O
will	O
define	O
these	O
parameters	O
as	O
µ	O
θ	O
and	O
σ	O
2	O
θ	O
.	O
	
Lastly	O
,	O
p	O
(	O
φ	O
i	O
|θ	O
)	O
must	O
be	O
chosen	O
.	O
	
This	O
choice	O
is	O
more	O
delicate	O
.	O
	
One	O
way	O
to	O
ensure	O
a	O
tractable	O
likelihood	O
is	O
to	O
use	O
a	O
Gaussian	B-Method
with	I-Method
mean	I-Method
θ	I-Method
.	O
	
This	O
choice	O
is	O
reasonable	O
,	O
because	O
it	O
encourages	O
φ	O
i	O
to	O
stay	O
close	O
to	O
the	O
prior	O
parameters	O
φ	O
i	O
,	O
but	O
we	O
will	O
see	O
in	O
the	O
next	O
section	O
how	O
a	O
more	O
expressive	O
implicit	O
conditional	O
can	O
be	O
obtained	O
using	O
gradient	B-Method
descent	I-Method
,	O
resulting	O
in	O
a	O
procedure	O
that	O
more	O
closely	O
resembles	O
the	O
original	O
MAML	B-Method
algorithm	O
while	O
still	O
modeling	O
the	O
uncertainty	O
.	O
	
Lastly	O
,	O
we	O
must	O
choose	O
a	O
form	O
for	O
the	O
inference	B-Method
networks	I-Method
q	I-Method
ψ	I-Method
(	O
φ	O
i	O
|θ	O
,	O
	
They	O
must	O
be	O
chosen	O
so	O
that	O
their	O
entropies	O
on	O
the	O
second	O
line	O
of	O
the	O
above	O
equation	O
are	O
tractable	O
.	O
	
Furthermore	O
,	O
note	O
that	O
both	O
of	O
these	O
distributions	O
model	O
very	O
high	O
-	O
dimensional	O
random	O
variables	O
:	O
a	O
deep	B-Method
neural	I-Method
network	I-Method
can	O
have	O
hundreds	O
of	O
thousands	O
or	O
millions	O
of	O
parameters	O
.	O
	
So	O
while	O
we	O
can	O
use	O
an	O
arbitrary	O
function	B-Method
approximator	I-Method
,	O
we	O
would	O
like	O
to	O
find	O
a	O
scalable	O
solution	O
.	O
	
One	O
convenient	O
solution	O
is	O
to	O
allow	O
q	O
ψ	O
to	O
reuse	O
the	O
learned	O
mean	O
of	O
the	O
prior	O
µ	O
θ	O
.	O
	
We	O
observe	O
that	O
adapting	O
the	O
parameters	O
with	O
gradient	B-Method
descent	I-Method
is	O
a	O
good	O
way	O
to	O
update	O
them	O
to	O
a	O
given	O
training	O
set	O
x	O
	
where	O
v	O
q	O
is	O
a	O
learned	O
(	O
diagonal	O
)	O
covariance	O
,	O
and	O
the	O
mean	O
has	O
an	O
additional	O
parameter	O
beyond	O
µ	O
θ	O
,	O
which	O
is	O
a	O
"	O
learning	O
rate	O
"	O
vector	O
γ	O
q	O
that	O
is	O
pointwise	O
multiplied	O
with	O
the	O
gradient	O
.	O
	
While	O
this	O
choice	O
may	O
at	O
first	O
seem	O
arbitrary	O
,	O
there	O
is	O
a	O
simple	O
intuition	O
:	O
the	O
inference	B-Method
network	I-Method
should	O
produce	O
a	O
sample	O
of	O
θ	O
that	O
is	O
close	O
to	O
the	O
posterior	O
p	O
(	O
θ|x	O
	
A	O
reasonable	O
way	O
to	O
arrive	O
at	O
a	O
value	O
of	O
θ	O
close	O
to	O
this	O
posterior	O
is	O
to	O
adapt	O
it	O
to	O
both	O
the	O
training	O
set	O
and	O
test	O
set	O
.	O
	
[	O
reference	O
]	O
	
Note	O
that	O
this	O
is	O
only	O
done	O
during	O
meta	B-Task
-	I-Task
training	I-Task
.	O
	
It	O
remains	O
to	O
choose	O
q	O
ψ	O
(	O
φ	O
i	O
|θ	O
,	O
	
,	O
which	O
can	O
also	O
be	O
formulated	O
as	O
a	O
conditional	O
Gaussian	O
with	O
mean	O
given	O
by	O
applying	O
gradient	B-Method
descent	I-Method
.	O
	
Although	O
this	O
variational	B-Method
distribution	I-Method
is	O
substantially	O
more	O
compact	O
in	O
terms	O
of	O
parameters	O
than	O
a	O
separate	O
neural	B-Method
network	I-Method
,	O
it	O
only	O
provides	O
estimates	O
of	O
the	O
posterior	O
during	O
meta	B-Task
-	I-Task
training	I-Task
.	O
	
At	O
meta	O
-	O
test	O
time	O
,	O
we	O
must	O
obtain	O
the	O
posterior	O
	
p	O
(	O
φ	O
i	O
	
|x	O
.	O
	
We	O
can	O
train	O
a	O
separate	O
set	O
of	O
inference	B-Method
networks	I-Method
to	O
perform	O
this	O
operation	O
,	O
potentially	O
also	O
using	O
gradient	B-Method
descent	I-Method
within	O
the	O
inference	B-Method
network	I-Method
.	O
	
However	O
,	O
these	O
networks	O
do	O
not	O
receive	O
any	O
gradient	O
information	O
during	O
meta	B-Method
-	I-Method
training	I-Method
,	O
and	O
may	O
not	O
work	O
well	O
in	O
practice	O
.	O
	
In	O
the	O
next	O
section	O
we	O
propose	O
an	O
even	O
simpler	O
and	O
more	O
practical	O
approach	O
that	O
uses	O
only	O
a	O
single	O
inference	B-Method
network	I-Method
during	O
meta	B-Task
-	I-Task
training	I-Task
,	O
and	O
none	O
during	O
meta	B-Task
-	I-Task
testing	I-Task
.	O
	
section	O
:	O
Algorithm	O
1	O
Meta	B-Method
-	I-Method
training	I-Method
,	O
differences	O
from	O
MAML	B-Method
in	O
red	O
	
Require	O
:	O
p	O
(	O
T	O
)	O
:	O
distribution	O
over	O
tasks	O
1	O
:	O
initialize	O
Θ	O
:	O
=	O
{	O
µ	O
	
θ	O
,	O
σ	O
2	O
θ	O
,	O
vq	O
,	O
γp	O
,	O
γq	O
}	O
2	O
:	O
while	O
not	O
done	O
do	O
3	O
:	O
	
Sample	O
batch	O
of	O
tasks	O
	
Ti	O
∼	O
p	O
(	O
T	O
)	O
4	O
:	O
	
for	O
all	O
Ti	O
do	O
5	O
:	O
	
Evaluate	O
	
Compute	O
adapted	O
parameters	O
with	O
gradient	B-Method
descent	I-Method
:	O
	
Compute	O
∇Θ	B-Method
	
Update	O
Θ	B-Method
using	O
Adam	B-Method
	
section	O
:	O
Algorithm	O
2	O
Meta	B-Task
-	I-Task
testing	I-Task
	
section	O
:	O
Probabilistic	B-Method
Model	I-Method
-	I-Method
Agnostic	I-Method
Meta	I-Method
-	I-Method
Learning	I-Method
Approach	I-Method
with	O
Hybrid	B-Method
Inference	I-Method
	
To	O
formulate	O
a	O
simpler	O
variational	B-Method
meta	I-Method
-	I-Method
learning	I-Method
procedure	I-Method
,	O
we	O
recall	O
the	O
probabilistic	B-Method
interpretation	I-Method
of	O
MAML	B-Method
:	O
as	O
discussed	O
by	O
Grant	O
et	O
al	O
.	O
	
[	O
reference	O
]	O
,	O
MAML	B-Method
can	O
be	O
interpreted	O
as	O
approximate	B-Method
inference	I-Method
for	O
the	O
posterior	B-Task
p	I-Task
(	I-Task
y	I-Task
	
where	O
we	O
use	O
the	O
maximum	O
a	O
posteriori	O
(	O
MAP	B-Metric
)	O
value	O
φ	O
i	O
.	O
	
It	O
can	O
be	O
shown	O
that	O
,	O
for	O
likelihoods	O
that	O
are	O
Gaussian	O
in	O
φ	O
i	O
,	O
gradient	B-Method
descent	I-Method
for	O
a	O
fixed	O
number	O
of	O
iterations	O
using	O
x	O
tr	O
i	O
,	O
y	O
tr	O
i	O
corresponds	O
exactly	O
to	O
maximum	B-Task
a	I-Task
posteriori	I-Task
inference	I-Task
under	O
a	O
Gaussian	O
prior	O
p	O
(	O
φ	O
i	O
|θ	O
)	O
	
[	O
reference	O
]	O
.	O
	
In	O
the	O
case	O
of	O
non	O
-	O
Gaussian	O
likelihoods	O
,	O
the	O
equivalence	O
is	O
only	O
locally	O
approximate	O
,	O
and	O
the	O
exact	O
form	O
of	O
the	O
prior	O
p	O
(	O
φ	O
i	O
|θ	O
)	O
is	O
intractable	O
.	O
	
However	O
,	O
in	O
practice	O
this	O
implicit	O
prior	O
can	O
actually	O
be	O
preferable	O
to	O
an	O
explicit	O
(	O
and	O
simple	O
)	O
	
Gaussian	B-Method
prior	I-Method
,	O
since	O
it	O
incorporates	O
the	O
rich	O
nonlinear	O
structure	O
of	O
the	O
neural	B-Method
network	I-Method
parameter	I-Method
manifold	I-Method
,	O
and	O
produces	O
good	O
performance	O
in	O
practice	O
[	O
reference	O
][	O
reference	O
]	O
.	O
We	O
can	O
interpret	O
this	O
MAP	B-Metric
approximation	O
as	O
inferring	O
an	O
approximate	O
posterior	O
on	O
φ	O
i	O
of	O
the	O
form	O
p	O
(	O
φ	O
i	O
|x	O
	
where	O
φ	O
i	O
is	O
obtained	O
via	O
gradient	B-Method
descent	I-Method
on	O
the	O
training	O
set	O
x	O
tr	O
i	O
,	O
y	O
tr	O
i	O
starting	O
from	O
θ	O
.	O
	
Incorporating	O
this	O
approximate	B-Method
inference	I-Method
procedure	I-Method
transforms	O
the	O
graphical	B-Method
model	I-Method
in	O
Figure	O
1	O
(	O
a	O
)	O
into	O
the	O
one	O
in	O
Figure	O
1	O
(	O
b	O
)	O
,	O
where	O
there	O
is	O
now	O
a	O
factor	O
over	O
p	O
(	O
φ	O
	
i	O
	
|x	O
	
tr	O
i	O
,	O
y	O
tr	O
i	O
,	O
θ	O
)	O
.	O
	
While	O
this	O
is	O
a	O
crude	O
approximation	O
to	O
the	O
likelihood	O
,	O
it	O
provides	O
us	O
with	O
an	O
empirically	O
effective	O
and	O
simple	O
tool	O
that	O
greatly	O
simplifies	O
the	O
variational	B-Method
inference	I-Method
procedure	I-Method
described	O
in	O
the	O
previous	O
section	O
,	O
in	O
the	O
case	O
where	O
we	O
aim	O
to	O
model	O
a	O
distribution	O
over	O
the	O
global	O
parameters	O
p	O
(	O
θ	O
)	O
.	O
	
After	O
using	O
gradient	B-Method
descent	I-Method
to	O
estimate	O
p	B-Task
(	I-Task
φ	I-Task
i	I-Task
|	O
x	O
is	O
not	O
observed	O
.	O
	
Thus	O
,	O
we	O
can	O
now	O
write	O
down	O
a	O
variational	B-Metric
lower	I-Metric
bound	I-Metric
for	O
the	O
logarithm	O
of	O
the	O
approximate	O
likelihood	O
on	O
the	O
second	O
line	O
,	O
which	O
is	O
given	O
by	O
	
In	O
this	O
bound	O
,	O
we	O
essentially	O
perform	O
approximate	B-Method
inference	I-Method
via	O
MAP	B-Metric
on	O
φ	O
i	O
to	O
obtain	O
p	O
(	O
φ	O
i	O
|x	O
	
To	O
evaluate	O
the	O
variational	O
lower	O
bound	O
during	O
training	B-Task
,	O
we	O
can	O
use	O
the	O
following	O
procedure	O
:	O
first	O
,	O
we	O
evaluate	O
the	O
mean	O
by	O
starting	O
from	O
µ	O
θ	O
and	O
taking	O
one	O
(	O
or	O
more	O
)	O
gradient	O
steps	O
on	O
log	O
	
p	O
(	O
y	O
test	O
	
i	O
	
|x	O
test	O
i	O
,	O
θ	O
current	O
)	O
,	O
where	O
θ	O
current	O
starts	O
at	O
µ	O
θ	O
.	O
	
We	O
then	O
add	O
noise	O
with	O
variance	O
v	O
q	O
,	O
which	O
is	O
made	O
differentiable	O
via	O
the	O
reparameterization	B-Method
trick	I-Method
	
[	O
reference	O
]	O
.	O
We	O
then	O
take	O
additional	O
gradient	B-Method
steps	I-Method
on	O
the	O
training	O
likelihood	O
	
log	O
	
p	O
(	O
y	O
	
tr	O
i	O
	
|x	O
	
tr	O
i	O
,	O
θ	O
current	O
)	O
.	O
	
This	O
accounts	O
for	O
the	O
MAP	B-Metric
inference	O
procedure	O
on	O
φ	O
i	O
.	O
	
Training	B-Task
of	O
µ	O
θ	O
,	O
σ	O
2	O
θ	O
,	O
and	O
v	B-Method
q	I-Method
is	O
performed	O
by	O
backpropagating	O
gradients	O
through	O
this	O
entire	O
procedure	O
with	O
respect	O
to	O
the	O
variational	O
lower	O
bound	O
,	O
which	O
includes	O
a	O
term	O
for	O
the	O
likelihood	O
	
tr	O
,	O
y	O
tr	O
,	O
φ	O
i	O
)	O
and	O
the	O
KL	O
-	O
divergence	O
between	O
the	O
sample	O
	
θ	O
∼	O
	
q	O
ψ	O
and	O
the	O
prior	B-Method
p	I-Method
(	I-Method
θ	I-Method
)	O
.	O
	
This	O
meta	B-Method
-	I-Method
training	I-Method
procedure	I-Method
is	O
detailed	O
in	O
Algorithm	O
1	O
.	O
	
At	O
meta	B-Task
-	I-Task
test	I-Task
time	I-Task
,	O
the	O
inference	B-Method
procedure	I-Method
is	O
much	O
simpler	O
.	O
	
The	O
test	O
labels	O
are	O
not	O
available	O
,	O
so	O
we	O
simply	O
sample	O
θ	O
∼	O
p	O
(	O
θ	O
)	O
and	O
perform	O
MAP	B-Metric
inference	O
on	O
φ	O
i	O
using	O
the	O
training	O
set	O
,	O
which	O
corresponds	O
to	O
gradient	O
steps	O
on	O
log	O
	
p	O
(	O
y	O
	
tr	O
i	O
	
|x	O
	
tr	O
i	O
,	O
θ	O
current	O
)	O
,	O
where	O
θ	O
current	O
starts	O
at	O
the	O
sampled	O
θ	O
.	O
	
This	O
meta	B-Method
-	I-Method
testing	I-Method
procedure	I-Method
is	O
detailed	O
in	O
Algorithm	O
2	O
.	O
	
section	O
:	O
Adding	O
Additional	O
Dependencies	O
	
In	O
the	O
transformed	B-Method
graphical	I-Method
model	I-Method
,	O
the	O
training	O
data	O
x	O
tr	O
i	O
,	O
y	O
tr	O
i	O
and	O
the	O
prior	O
θ	O
are	O
conditionally	O
independent	O
.	O
	
However	O
,	O
since	O
we	O
have	O
only	O
a	O
crude	O
approximation	O
to	O
p	O
(	O
φ	O
	
i	O
	
|	O
x	O
tr	O
i	O
,	O
y	O
tr	O
	
i	O
,	O
θ	O
)	O
	
,	O
this	O
independence	O
often	O
does	O
n't	O
actually	O
hold	O
.	O
	
We	O
can	O
allow	O
the	O
model	O
to	O
compensate	O
for	O
this	O
approximation	O
by	O
additionally	O
conditioning	O
the	O
learned	O
prior	O
p	O
(	O
θ	O
)	O
on	O
the	O
training	O
data	O
.	O
	
In	O
this	O
case	O
,	O
the	O
learned	O
"	O
prior	O
"	O
has	O
the	O
form	O
p	O
(	O
θ	O
	
i	O
	
|x	O
	
tr	O
i	O
,	O
y	O
tr	O
i	O
)	O
,	O
where	O
θ	O
i	O
is	O
now	O
task	O
-	O
specific	O
,	O
but	O
with	O
global	O
parameters	O
µ	O
θ	O
	
and	O
σ	O
2	O
θ	O
.	O
	
We	O
thus	O
obtain	O
the	O
modified	O
graphical	B-Method
model	I-Method
in	O
Figure	O
1	O
(	O
c	O
)	O
.	O
	
Similarly	O
to	O
the	O
inference	B-Method
network	I-Method
q	I-Method
ψ	I-Method
,	O
we	O
parameterize	O
the	O
learned	O
prior	O
as	O
follows	O
:	O
	
With	O
this	O
new	O
form	O
for	O
distribution	B-Task
over	I-Task
θ	I-Task
,	O
the	O
variational	B-Task
training	I-Task
objective	I-Task
uses	O
the	O
likelihood	B-Method
term	I-Method
log	I-Method
p	I-Method
(	I-Method
θ	I-Method
	
i	O
	
|x	O
	
In	O
our	O
experiments	O
,	O
we	O
find	O
that	O
this	O
more	O
expressive	O
distribution	O
often	O
leads	O
to	O
better	O
performance	O
.	O
	
section	O
:	O
Experiments	O
	
The	O
goal	O
of	O
our	O
experimental	O
evaluation	O
is	O
to	O
answer	O
the	O
following	O
questions	O
:	O
(	O
1	O
)	O
can	O
our	O
approach	O
enable	O
sampling	O
from	O
the	O
distribution	O
over	O
potential	O
functions	O
underlying	O
the	O
training	O
data	O
?	O
,	O
(	O
2	O
)	O
does	O
our	O
approach	O
improve	O
upon	O
the	O
MAML	B-Method
algorithm	O
when	O
there	O
is	O
ambiguity	O
over	O
the	O
class	O
of	O
functions	O
?	O
	
,	O
and	O
(	O
3	O
)	O
can	O
our	O
approach	O
scale	O
to	O
deep	B-Method
convolutional	I-Method
networks	I-Method
?	O
	
We	O
study	O
two	O
illustrative	O
toy	O
examples	O
and	O
a	O
realistic	O
ambiguous	B-Task
few	I-Task
-	I-Task
shot	I-Task
image	I-Task
classification	I-Task
problem	I-Task
.	O
	
For	O
the	O
both	O
experimental	O
domains	O
,	O
we	O
compare	O
MAML	B-Method
to	O
our	O
probabilistic	B-Method
approach	I-Method
.	O
	
We	O
will	O
refer	O
to	O
our	O
version	O
of	O
MAML	B-Method
as	O
a	O
PLATIPUS	B-Method
(	O
Probabilistic	B-Method
LATent	I-Method
model	I-Method
for	I-Method
Incorporating	I-Method
Priors	I-Method
and	I-Method
Uncertainty	I-Method
in	I-Method
few	I-Method
-	I-Method
Shot	I-Method
learning	I-Method
)	O
,	O
due	O
to	O
its	O
unusual	O
combination	O
of	O
two	O
approximate	B-Method
inference	I-Method
methods	I-Method
:	O
amortized	B-Method
inference	I-Method
and	O
MAP	B-Metric
.	O
	
Both	O
PLATIPUS	B-Method
and	O
MAML	B-Method
use	O
the	O
same	O
neural	B-Method
network	I-Method
architecture	I-Method
and	O
the	O
same	O
number	O
of	O
inner	O
gradient	O
steps	O
.	O
	
We	O
additionally	O
provide	O
a	O
comparison	O
on	O
the	O
MiniImagenet	B-Material
benchmark	I-Material
and	O
specify	O
the	O
hyperparameters	O
in	O
the	O
supplementary	O
appendix	O
.	O
,	O
and	O
Gaussian	O
noise	O
with	O
a	O
standard	O
deviation	O
of	O
0.3	O
is	O
added	O
to	O
the	O
labels	O
.	O
	
We	O
trained	O
both	O
MAML	B-Method
and	O
PLATIPUS	B-Method
for	O
5	B-Task
-	I-Task
shot	I-Task
regression	I-Task
.	O
	
In	O
Figure	O
2	O
,	O
we	O
show	O
the	O
qualitative	O
performance	O
of	O
both	O
methods	O
,	O
where	O
the	O
ground	O
truth	O
underlying	O
function	O
is	O
shown	O
in	O
gray	O
and	O
the	O
datapoints	O
in	O
D	O
tr	O
are	O
shown	O
as	O
purple	O
triangles	O
.	O
	
We	O
show	O
the	O
function	O
f	O
φi	O
learned	O
by	O
MAML	B-Method
in	O
black	O
.	O
	
For	O
PLATIPUS	B-Method
,	O
we	O
sample	O
10	O
sets	O
of	O
parameters	O
from	O
p	O
(	O
φ	O
i	O
|θ	O
)	O
and	O
plot	O
the	O
resulting	O
functions	O
in	O
different	O
colors	O
.	O
	
In	O
the	O
top	O
row	O
,	O
we	O
can	O
see	O
that	O
PLATIPUS	B-Method
allows	O
the	O
model	O
to	O
effectively	O
reason	O
over	O
the	O
set	O
of	O
functions	O
underlying	O
the	O
provided	O
datapoints	O
,	O
with	O
increased	O
variance	O
in	O
parts	O
of	O
the	O
function	O
where	O
there	O
is	O
more	O
uncertainty	O
.	O
	
Further	O
,	O
we	O
see	O
that	O
PLATIPUS	B-Method
is	O
able	O
to	O
capture	O
the	O
multimodal	O
structure	O
,	O
as	O
the	O
curves	O
are	O
all	O
linear	O
or	O
sinusoidal	O
.	O
	
A	O
particularly	O
useful	O
application	O
of	O
uncertainty	B-Task
estimates	I-Task
in	O
few	B-Task
-	I-Task
shot	I-Task
learning	I-Task
is	O
estimating	O
when	O
more	O
data	O
would	O
be	O
helpful	O
.	O
	
In	O
particular	O
,	O
seeing	O
a	O
large	O
variance	O
in	O
a	O
particular	O
part	O
of	O
the	O
input	O
space	O
suggests	O
that	O
more	O
data	O
would	O
be	O
helpful	O
for	O
learning	O
the	O
function	O
in	O
that	O
part	O
of	O
the	O
input	O
space	O
.	O
	
On	O
the	O
bottom	O
of	O
Figure	O
2	O
,	O
we	O
show	O
the	O
results	O
for	O
a	O
single	O
task	O
at	O
meta	O
-	O
test	O
time	O
with	O
increasing	O
numbers	O
of	O
training	O
datapoints	O
.	O
	
Even	O
though	O
the	O
model	O
was	O
only	O
trained	O
on	O
training	O
set	O
sizes	O
of	O
5	O
datapoints	O
,	O
we	O
observe	O
that	O
PLATIPUS	B-Method
is	O
able	O
to	O
effectively	O
reduce	O
its	O
uncertainty	O
as	O
more	O
and	O
more	O
datapoints	O
are	O
available	O
.	O
	
This	O
suggests	O
that	O
the	O
uncertainty	O
provided	O
by	O
PLATIPUS	B-Method
can	O
be	O
used	O
for	O
approximately	B-Task
gauging	I-Task
when	O
more	O
data	O
would	O
be	O
helpful	O
for	O
learning	O
a	O
new	O
task	O
.	O
	
consisting	O
of	O
both	O
positive	O
and	O
negative	O
examples	O
.	O
	
We	O
plot	O
the	O
results	O
using	O
the	O
same	O
scheme	O
as	O
before	O
,	O
except	O
that	O
we	O
plot	O
the	O
decision	O
boundary	O
(	O
rather	O
than	O
the	O
regression	O
function	O
)	O
and	O
visualize	O
the	O
single	O
positive	O
datapoint	O
with	O
a	O
green	O
plus	O
.	O
	
As	O
seen	O
in	O
Figure	O
3	O
,	O
we	O
see	O
that	O
PLATIPUS	B-Method
captures	O
a	O
broad	O
distribution	O
over	O
possible	O
decision	O
boundaries	O
,	O
all	O
of	O
which	O
are	O
roughly	O
circular	O
.	O
	
MAML	B-Method
provides	O
a	O
single	O
decision	O
boundary	O
of	O
average	O
size	O
.	O
	
Ambiguous	B-Task
image	I-Task
classification	I-Task
.	O
	
The	O
ambiguity	O
illustrated	O
in	O
the	O
previous	O
settings	O
is	O
common	O
in	O
real	B-Task
world	I-Task
tasks	I-Task
where	O
images	O
can	O
share	O
multiple	O
attributes	O
.	O
	
We	O
study	O
an	O
ambiguous	B-Task
extension	I-Task
to	O
the	O
celebA	B-Task
attribute	I-Task
classification	I-Task
task	I-Task
.	O
	
Our	O
meta	O
-	O
training	O
dataset	O
is	O
formed	O
by	O
sampling	O
two	O
attributes	O
at	O
random	O
to	O
form	O
a	O
positive	O
class	O
and	O
taking	O
the	O
same	O
number	O
of	O
random	O
examples	O
without	O
either	O
attribute	O
to	O
from	O
the	O
negative	O
classes	O
.	O
	
To	O
evaluate	O
the	O
ability	O
to	O
capture	O
multiple	O
decision	O
boundaries	O
while	O
simultaneously	O
obtaining	O
good	O
performance	O
,	O
we	O
evaluate	O
our	O
method	O
as	O
follows	O
:	O
	
We	O
sample	O
from	O
a	O
test	O
set	O
of	O
three	O
attributes	O
and	O
a	O
corresponding	O
set	O
of	O
images	O
with	O
those	O
attributes	O
.	O
	
Since	O
the	O
tasks	O
involve	O
classifying	O
images	O
that	O
have	O
two	O
attributes	O
,	O
this	O
task	O
is	O
ambiguous	O
,	O
and	O
there	O
are	O
three	O
possible	O
combinations	O
of	O
two	O
attributes	O
that	O
explain	O
the	O
training	O
set	O
.	O
	
We	O
sample	O
models	O
from	O
our	O
prior	O
as	O
described	O
in	O
Section	O
4	O
and	O
assign	O
each	O
of	O
the	O
sampled	O
models	O
to	O
one	O
of	O
the	O
three	O
possible	O
tasks	O
based	O
on	O
its	O
log	O
-	O
likelihood	O
.	O
	
If	O
each	O
of	O
the	O
three	O
possible	O
tasks	O
is	O
assigned	O
a	O
nonzero	O
number	O
of	O
samples	O
,	O
this	O
means	O
that	O
the	O
model	O
effectively	O
covers	O
all	O
three	O
possible	O
modes	O
that	O
explain	O
the	O
ambiguous	O
training	O
set	O
.	O
	
We	O
can	O
measure	O
coverage	B-Metric
and	O
accuracy	B-Metric
from	O
this	O
protocol	O
.	O
	
The	O
coverage	B-Metric
score	I-Metric
indicates	O
the	O
average	O
number	O
of	O
tasks	O
(	O
between	O
1	O
and	O
3	O
)	O
that	O
receive	O
at	O
least	O
one	O
sample	O
for	O
each	O
ambiguous	O
training	O
set	O
,	O
and	O
the	O
accuracy	B-Metric
score	O
is	O
the	O
average	O
number	O
of	O
correct	O
classifications	O
on	O
these	O
tasks	O
(	O
according	O
to	O
the	O
sampled	O
models	O
assigned	O
to	O
them	O
)	O
.	O
	
A	O
highly	O
random	B-Method
method	I-Method
will	O
achieve	O
good	O
coverage	B-Metric
but	O
poor	O
accuracy	B-Metric
,	O
while	O
a	O
deterministic	B-Method
method	I-Method
will	O
have	O
a	O
coverage	O
of	O
1	O
.	O
	
Our	O
results	O
are	O
summarized	O
in	O
Table	O
5	O
and	O
Fig	O
.	O
4	O
.	O
	
The	O
accuracy	B-Metric
of	O
our	O
method	O
is	O
comparable	O
to	O
standard	O
,	O
deterministic	O
MAML	B-Method
.	O
	
However	O
,	O
the	O
deterministic	B-Method
algorithm	I-Method
only	O
ever	O
captures	O
one	O
mode	O
observes	O
five	O
positives	O
that	O
share	O
three	O
attributes	O
,	O
and	O
five	O
negatives	O
.	O
	
A	O
classifier	B-Method
that	O
uses	O
any	O
two	O
attributes	O
can	O
correctly	O
classify	O
the	O
training	O
set	O
.	O
	
On	O
the	O
right	O
,	O
we	O
show	O
each	O
of	O
the	O
possible	O
two	O
-	O
attribute	O
tasks	O
that	O
this	O
training	O
set	O
can	O
correspond	O
to	O
,	O
and	O
illustrate	O
the	O
labels	O
(	O
positive	O
indicated	O
by	O
red	O
border	O
)	O
assigned	O
by	O
the	O
best	O
sample	O
for	O
that	O
task	O
.	O
	
We	O
see	O
that	O
the	O
different	O
samples	O
are	O
able	O
to	O
make	O
reasonable	O
predictions	O
with	O
no	O
hats	O
(	O
2nd	O
column	O
)	O
or	O
pay	O
attention	O
to	O
them	O
(	O
1st	O
and	O
3rd	O
column	O
)	O
,	O
and	O
can	O
effectively	O
capture	O
the	O
three	O
possible	O
explanations	O
.	O
	
for	O
each	O
ambiguous	B-Task
task	I-Task
,	O
where	O
the	O
maximum	O
is	O
three	O
.	O
	
Our	O
method	O
on	O
average	O
captures	O
between	O
two	O
and	O
three	O
modes	O
.	O
	
The	O
qualitative	O
analysis	O
in	O
Figure	O
4	O
illustrates	O
3	O
an	O
example	O
ambiguous	O
training	O
set	O
,	O
example	O
images	O
for	O
the	O
three	O
possible	O
two	O
-	O
attribute	O
pairs	O
that	O
can	O
correspond	O
to	O
this	O
training	O
set	O
,	O
and	O
the	O
classifications	O
made	O
by	O
different	O
sampled	B-Method
classifiers	I-Method
trained	O
on	O
the	O
ambiguous	O
training	O
set	O
.	O
	
Note	O
that	O
the	O
different	O
samples	O
each	O
pay	O
attention	O
to	O
different	O
attributes	O
,	O
indicating	O
that	O
PLATIPUS	B-Method
is	O
effective	O
at	O
capturing	O
the	O
different	O
modes	O
of	O
the	O
task	O
.	O
	
section	O
:	O
Discussion	O
and	O
Future	O
Work	O
	
We	O
introduced	O
an	O
algorithm	O
for	O
few	B-Method
-	I-Method
shot	I-Method
meta	I-Method
-	I-Method
learning	I-Method
that	O
enables	O
simple	O
and	O
effective	O
sampling	B-Method
of	I-Method
models	I-Method
for	O
new	O
tasks	O
at	O
meta	B-Task
-	I-Task
test	I-Task
time	I-Task
.	O
	
Our	O
algorithm	O
,	O
PLATIPUS	B-Method
,	O
adapts	O
to	O
new	O
tasks	O
by	O
running	O
gradient	B-Method
descent	I-Method
with	O
injected	O
noise	O
.	O
	
During	O
meta	B-Task
-	I-Task
training	I-Task
,	O
the	O
model	O
parameters	O
are	O
optimized	O
with	O
respect	O
to	O
a	O
variational	O
lower	O
bound	O
on	O
the	O
likelihood	O
for	O
the	O
meta	B-Task
-	I-Task
training	I-Task
tasks	I-Task
,	O
so	O
as	O
to	O
enable	O
this	O
simple	O
adaptation	B-Method
procedure	I-Method
to	O
produce	O
approximate	O
samples	O
from	O
the	O
model	O
posterior	O
when	O
conditioned	O
on	O
a	O
few	O
-	O
shot	O
training	O
set	O
.	O
	
This	O
approach	O
has	O
a	O
number	O
of	O
benefits	O
.	O
	
The	O
adaptation	B-Method
procedure	I-Method
is	O
exceedingly	O
simple	O
,	O
and	O
the	O
method	O
can	O
be	O
applied	O
to	O
any	O
standard	O
model	B-Method
architecture	I-Method
.	O
	
The	O
algorithm	O
introduces	O
a	O
modest	O
number	O
of	O
additional	O
parameters	O
:	O
besides	O
the	O
initial	O
model	O
weights	O
,	O
we	O
must	O
learn	O
a	O
variance	O
on	O
each	O
parameter	O
for	O
the	O
inference	B-Method
network	I-Method
and	O
prior	O
,	O
and	O
the	O
number	O
of	O
parameters	O
scales	O
only	O
linearly	O
with	O
the	O
number	O
of	O
model	O
weights	O
.	O
	
Our	O
experimental	O
results	O
show	O
that	O
our	O
method	O
can	O
be	O
used	O
to	O
effectively	O
sample	O
diverse	O
solutions	O
to	O
both	O
regression	B-Task
and	I-Task
classification	I-Task
tasks	I-Task
at	O
meta	B-Task
-	I-Task
test	I-Task
time	I-Task
,	O
including	O
for	O
task	O
families	O
that	O
have	O
multi	O
-	O
modal	O
task	O
distributions	O
.	O
	
Although	O
our	O
approach	O
is	O
simple	O
and	O
broadly	O
applicable	O
,	O
it	O
has	O
a	O
number	O
of	O
potential	O
limitations	O
that	O
could	O
be	O
addressed	O
in	O
future	O
work	O
.	O
	
First	O
,	O
the	O
current	O
form	O
of	O
the	O
method	O
provides	O
a	O
relatively	O
impoverished	B-Method
estimator	I-Method
of	I-Method
posterior	I-Method
variance	I-Method
,	O
which	O
might	O
be	O
less	O
effective	O
at	O
gauging	O
uncertainty	O
in	O
settings	O
where	O
different	O
tasks	O
have	O
very	O
different	O
degrees	O
of	O
ambiguity	O
.	O
	
In	O
these	O
cases	O
,	O
finding	O
a	O
way	O
to	O
make	O
the	O
variance	O
dependent	O
on	O
the	O
few	O
-	O
shot	O
training	O
set	O
might	O
produce	O
better	O
results	O
,	O
and	O
investigating	O
how	O
to	O
do	O
this	O
without	O
adding	O
a	O
large	O
number	O
of	O
additional	O
parameters	O
would	O
be	O
an	O
interesting	O
direction	O
for	O
future	O
work	O
.	O
	
Another	O
exciting	O
direction	O
for	O
future	O
research	O
would	O
be	O
to	O
study	O
how	O
our	O
approach	O
could	O
be	O
applied	O
in	O
settings	O
where	O
ambiguity	O
and	O
uncertainty	O
can	O
directly	O
guide	O
data	B-Task
acquisition	I-Task
,	O
so	O
as	O
to	O
devise	O
better	O
few	B-Method
-	I-Method
shot	I-Method
active	I-Method
learning	I-Method
and	I-Method
reinforcement	I-Method
learning	I-Method
algorithms	I-Method
.	O
	
section	O
:	O
Appendix	O
A	O
Ambiguous	O
CelebA	B-Material
Details	O
	
To	O
construct	O
our	O
ambiguous	B-Method
few	I-Method
-	I-Method
shot	I-Method
variant	I-Method
of	O
CelebA	B-Material
,	O
we	O
take	O
the	O
entire	O
base	O
set	O
of	O
attributes	O
holding	O
out	O
10	O
attributes	O
for	O
testing	O
.	O
	
We	O
consider	O
every	O
combination	O
of	O
2	O
attributes	O
,	O
discarding	O
those	O
with	O
insufficient	O
numbers	O
of	O
examples	O
.	O
	
This	O
leave	O
us	O
with	O
a	O
total	O
of	O
387	O
training	O
tasks	O
and	O
43	O
testing	O
attributes	O
.	O
	
We	O
partition	O
our	O
meta	O
-	O
training	O
set	O
and	O
meta	O
-	O
validation	O
set	O
to	O
337	O
/	O
50	O
respectively	O
.	O
	
During	O
meta	B-Task
-	I-Task
training	I-Task
,	O
we	O
sample	O
2	O
random	O
attributes	O
to	O
construct	O
a	O
positive	O
class	O
and	O
randomly	O
sample	O
examples	O
with	O
neither	O
attribute	O
as	O
negative	O
examples	O
.	O
	
During	O
testing	O
of	O
our	O
approach	O
,	O
we	O
sample	O
3	O
attributes	O
from	O
the	O
test	O
set	O
,	O
and	O
sample	O
the	O
3	O
corresponding	O
2	O
-	O
uples	O
to	O
form	O
the	O
test	O
task	O
.	O
	
The	O
training	O
attributes	O
are	O
:	O
	
section	O
:	O
B	O
Experimental	O
Details	O
	
In	O
the	O
illustrative	O
experiments	O
,	O
we	O
use	O
a	O
fully	B-Method
connected	I-Method
network	I-Method
with	O
3	O
ReLU	O
layers	O
of	O
size	O
100	O
.	O
	
For	O
CelebA	B-Material
,	O
we	O
adapt	O
the	O
base	O
convolutional	B-Method
architecture	I-Method
described	O
in	O
Finn	O
et	O
al	O
.	O
	
[	O
reference	O
]	O
which	O
we	O
refer	O
the	O
readers	O
to	O
for	O
more	O
detail	O
.	O
	
Our	O
approximate	O
posterior	O
and	O
prior	O
have	O
dimensionality	O
matching	O
the	O
underlying	O
model	O
.	O
	
We	O
tune	O
our	O
approach	O
over	O
the	O
inner	B-Metric
learning	I-Metric
rate	I-Metric
α	I-Metric
,	O
a	O
weight	O
on	O
the	O
D	O
KL	O
,	O
the	O
scale	O
of	O
the	O
initialization	O
of	O
µ	O
θ	O
,	O
σ	O
2	O
θ	O
,	O
v	O
q	O
,	O
γ	O
p	O
,	O
γ	O
q	O
,	O
with	O
early	B-Method
stopping	I-Method
on	O
the	O
validation	O
set	O
.	O
	
At	O
meta	O
-	O
test	O
time	O
,	O
we	O
evaluate	O
our	O
approach	O
by	O
taking	O
10	O
samples	O
from	O
the	O
prior	O
before	O
determining	O
the	O
assignments	O
.	O
	
The	O
assignments	O
are	O
made	O
based	O
on	O
the	O
complete	O
likelihood	O
of	O
the	O
testing	O
examples	O
(	O
including	O
the	O
negatives	O
)	O
.	O
	
section	O
:	O
C	O
MiniImagenet	B-Metric
Comparison	I-Metric
	
We	O
provide	O
an	O
additional	O
comparison	O
on	O
the	O
MiniImagenet	B-Material
dataset	I-Material
.	O
	
Since	O
this	O
benchmark	O
does	O
not	O
contain	O
a	O
large	O
amount	O
of	O
ambiguity	O
,	O
we	O
do	O
not	O
aim	O
to	O
show	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
performance	O
.	O
	
Instead	O
,	O
our	O
goal	O
with	O
this	O
experiment	O
is	O
to	O
compare	O
our	O
approach	O
on	O
to	O
MAML	B-Method
and	O
prior	O
methods	O
that	O
build	O
upon	O
MAML	B-Method
on	O
this	O
standard	O
benchmark	O
.	O
	
Since	O
our	O
goal	O
is	O
to	O
compare	O
algorithms	O
,	O
rather	O
than	O
achieving	O
maximal	O
performance	O
,	O
we	O
decouple	O
the	O
effect	O
of	O
the	O
meta	B-Method
-	I-Method
learning	I-Method
algorithm	I-Method
and	O
the	O
architecture	O
used	O
by	O
using	O
the	O
standard	O
4	B-Method
-	I-Method
block	I-Method
convolutional	I-Method
architecture	I-Method
used	O
by	O
Vinyals	O
et	O
al	O
.	O
	
[	O
reference	O
]	O
,	O
Ravi	O
and	O
Larochelle	O
[	O
reference	O
]	O
,	O
Finn	O
et	O
al	O
.	O
	
[	O
reference	O
]	O
and	O
others	O
.	O
	
We	O
note	O
that	O
better	O
performance	O
can	O
likely	O
be	O
achieved	O
by	O
tuning	O
the	O
architecture	O
.	O
	
The	O
results	O
,	O
in	O
Table	O
2	O
indicate	O
that	O
our	O
method	O
slightly	O
outperforms	O
MAML	B-Method
and	O
achieves	O
comparable	O
performance	O
to	O
a	O
number	O
of	O
other	O
prior	B-Method
methods	I-Method
.	O
	
MiniImagenet	B-Material
5	I-Material
-	I-Material
way	I-Material
,	O
1	O
-	O
shot	O
Accuracy	O
MAML	B-Method
[	O
reference	O
]	O
48.70	O
±	O
1.84	O
%	O
LLAMA	O
[	O
reference	O
]	O
49.40	O
±	O
1.83	O
%	O
Reptile	O
[	O
reference	O
]	O
49.97	O
±	O
0.32	O
%	O
PLATIPUS	B-Method
(	O
ours	O
)	O
50.13	O
±	O
	
1.86	O
%	O
Meta	B-Method
-	I-Method
SGD	I-Method
[	O
reference	O
]	O
50.71	O
±	O
1.87	O
%	O
matching	B-Method
nets	I-Method
[	O
reference	O
]	O
43.56	O
±	O
0.84	O
%	O
meta	B-Method
-	I-Method
learner	I-Method
LSTM	I-Method
[	O
reference	O
]	O
43.44	O
±	O
0.77	O
%	O
SNAIL	B-Method
[	O
reference	O
]	O
	
*	O
45.10	O
±	O
	
0.00	O
%	O
prototypical	O
networks	O
[	O
reference	O
]	O
46.61	O
±	O
0.78	O
%	O
mAP	B-Method
-	I-Method
DLM	I-Method
[	O
reference	O
]	O
49.82	O
±	O
0.78	O
%	O
GNN	B-Method
[	O
reference	O
]	O
50.33	O
±	O
0.36	O
%	O
Relation	O
Net	O
[	O
reference	O
]	O
50.44	O
±	O
0.82	O
%	O
Table	O
2	O
:	O
Comparison	O
between	O
our	O
approach	O
and	O
prior	O
MAML	B-Method
-	O
based	O
methods	O
(	O
top	O
)	O
,	O
and	O
other	O
prior	B-Method
few	I-Method
-	I-Method
shot	I-Method
learning	I-Method
techniques	I-Method
on	O
the	O
5	B-Material
-	I-Material
way	I-Material
,	I-Material
1	I-Material
-	I-Material
shot	I-Material
MiniImagenet	I-Material
benchmark	I-Material
.	O
	
Our	O
approach	O
gives	O
a	O
small	O
boost	O
over	O
MAML	B-Method
,	O
and	O
is	O
comparable	O
to	O
other	O
approaches	O
.	O
	
We	O
bold	O
the	O
approaches	O
that	O
are	O
above	O
the	O
highest	O
confidence	O
interval	O
lower	O
-	O
bound	O
.	O
	
*	O
	
Accuracy	B-Metric
using	O
comparable	B-Method
network	I-Method
architecture	I-Method
.	O
	
section	O
:	O
	
section	O
:	O
Acknowledgments	O
	
We	O
thank	O
Marvin	O
Zhang	O
and	O
Dibya	O
Ghosh	O
for	O
comments	O
on	O
an	O
earlier	O
draft	O
of	O
this	O
paper	O
.	O
	
This	O
research	O
was	O
supported	O
by	O
an	O
NSF	O
Graduate	O
Research	O
Fellowship	O
,	O
NSF	O
IIS	O
-	O
1651843	O
,	O
the	O
Office	O
of	O
Naval	O
Research	O
,	O
and	O
NVIDIA	O
.	O
	
section	O
:	O
	
document	O
:	O
Pixel2Mesh	B-Method
:	O
Generating	O
3D	B-Method
Mesh	I-Method
Models	I-Method
from	O
Single	O
RGB	B-Material
Images	I-Material
	
We	O
propose	O
an	O
end	O
-	O
to	O
-	O
end	B-Method
deep	I-Method
learning	I-Method
architecture	I-Method
that	O
produces	O
a	O
3D	O
shape	O
in	O
triangular	O
mesh	O
from	O
a	O
single	O
color	O
image	O
.	O
	
Limited	O
by	O
the	O
nature	O
of	O
deep	B-Method
neural	I-Method
network	I-Method
,	O
previous	O
methods	O
usually	O
represent	O
a	O
3D	O
shape	O
in	O
volume	O
or	O
point	O
cloud	O
,	O
and	O
it	O
is	O
non	O
-	O
trivial	O
to	O
convert	O
them	O
to	O
the	O
more	O
ready	O
-	O
to	O
-	O
use	O
mesh	B-Method
model	I-Method
.	O
	
Unlike	O
the	O
existing	O
methods	O
,	O
our	O
network	O
represents	O
3D	B-Method
mesh	I-Method
in	O
a	O
graph	B-Method
-	I-Method
based	I-Method
convolutional	I-Method
neural	I-Method
network	I-Method
and	O
produces	O
correct	O
geometry	O
by	O
progressively	O
deforming	O
an	O
ellipsoid	O
,	O
leveraging	O
perceptual	O
features	O
extracted	O
from	O
the	O
input	O
image	O
.	O
	
We	O
adopt	O
a	O
coarse	B-Method
-	I-Method
to	I-Method
-	I-Method
fine	I-Method
strategy	I-Method
to	O
make	O
the	O
whole	O
deformation	B-Method
procedure	I-Method
stable	O
,	O
and	O
define	O
various	O
of	O
mesh	O
related	O
losses	O
to	O
capture	O
properties	O
of	O
different	O
levels	O
to	O
guarantee	O
visually	O
appealing	O
and	O
physically	O
accurate	O
3D	O
geometry	O
.	O
	
Extensive	O
experiments	O
show	O
that	O
our	O
method	O
not	O
only	O
qualitatively	O
produces	O
mesh	B-Method
model	I-Method
with	O
better	O
details	O
,	O
but	O
also	O
achieves	O
higher	O
3D	B-Metric
shape	I-Metric
estimation	I-Metric
accuracy	I-Metric
compared	O
to	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
.	O
indicates	O
equal	O
contributions	O
.	O
indicates	O
corresponding	O
author	O
.	O
	
section	O
:	O
Introduction	O
	
Inferring	B-Task
3D	I-Task
shape	I-Task
from	O
a	O
single	O
perspective	O
is	O
a	O
fundamental	O
human	B-Task
vision	I-Task
functionality	I-Task
but	O
is	O
extremely	O
challenging	O
for	O
computer	B-Task
vision	I-Task
.	O
	
Recently	O
,	O
great	O
success	O
has	O
been	O
achieved	O
for	O
3d	B-Task
shape	I-Task
generation	I-Task
from	O
a	O
single	O
color	O
image	O
using	O
deep	B-Method
learning	I-Method
techniques	I-Method
.	O
	
Taking	O
advantage	O
of	O
convolutional	B-Method
layers	I-Method
on	O
regular	O
grids	O
or	O
multi	B-Method
-	I-Method
layer	I-Method
perception	I-Method
,	O
the	O
estimated	O
3D	O
shape	O
,	O
as	O
the	O
output	O
of	O
the	O
neural	B-Method
network	I-Method
,	O
is	O
represented	O
as	O
either	O
a	O
volume	O
or	O
point	O
cloud	O
.	O
	
However	O
,	O
both	O
representations	O
lose	O
important	O
surface	O
details	O
,	O
and	O
is	O
non	O
-	O
trivial	O
to	O
reconstruct	O
a	O
surface	B-Method
model	I-Method
(	O
Fig	O
.	O
	
[	O
reference	O
]	O
)	O
,	O
i.e.	O
a	O
mesh	O
,	O
which	O
is	O
more	O
desirable	O
for	O
many	O
real	B-Task
applications	I-Task
since	O
it	O
is	O
lightweight	O
,	O
capable	O
of	O
modelling	O
shape	O
details	O
,	O
easy	O
to	O
deform	O
for	O
animation	B-Task
,	O
to	O
name	O
a	O
few	O
.	O
	
In	O
this	O
paper	O
,	O
we	O
push	O
along	O
the	O
direction	O
of	O
single	B-Task
image	I-Task
reconstruction	I-Task
,	O
and	O
propose	O
an	O
algorithm	O
to	O
extract	O
a	O
3D	B-Task
triangular	I-Task
mesh	I-Task
from	O
a	O
single	O
color	O
image	O
.	O
	
Rather	O
than	O
directly	O
synthesizing	O
,	O
our	O
model	O
learns	O
to	O
deform	O
a	O
mesh	O
from	O
a	O
mean	O
shape	O
to	O
the	O
target	O
geometry	O
.	O
	
This	O
benefits	O
us	O
from	O
several	O
aspects	O
.	O
	
First	O
,	O
deep	B-Method
network	I-Method
is	O
better	O
at	O
predicting	O
residual	O
,	O
e.g.	O
a	O
spatial	O
deformation	O
,	O
rather	O
than	O
structured	O
output	O
,	O
e.g.	O
a	O
graph	O
.	O
	
Second	O
,	O
a	O
series	O
of	O
deformations	O
can	O
be	O
added	O
up	O
together	O
,	O
which	O
allows	O
shape	O
to	O
be	O
gradually	O
refined	O
in	O
detail	O
.	O
	
It	O
also	O
enables	O
the	O
control	O
of	O
the	O
trade	O
-	O
off	O
between	O
the	O
complexity	B-Metric
of	O
the	O
deep	B-Method
learning	I-Method
model	I-Method
and	O
the	O
quality	O
of	O
the	O
result	O
.	O
	
Lastly	O
,	O
it	O
provides	O
the	O
chance	O
to	O
encode	O
any	O
prior	O
knowledge	O
to	O
the	O
initial	O
mesh	O
,	O
e.g.	O
topology	O
.	O
	
As	O
a	O
pioneer	O
study	O
,	O
in	O
this	O
work	O
,	O
we	O
specifically	O
work	O
on	O
objects	O
that	O
can	O
be	O
approximated	O
using	O
3D	O
mesh	O
with	O
genus	O
0	O
by	O
deforming	O
an	O
ellipsoid	O
with	O
a	O
fixed	O
size	O
.	O
	
In	O
practice	O
,	O
we	O
found	O
most	O
of	O
the	O
commonly	O
seen	O
categories	O
can	O
be	O
handled	O
well	O
under	O
this	O
setting	O
,	O
e.g.	O
car	O
,	O
plane	O
,	O
table	O
,	O
etc	O
.	O
	
To	O
achieve	O
this	O
goal	O
,	O
there	O
are	O
several	O
inherent	O
challenges	O
.	O
	
The	O
first	O
challenge	O
is	O
how	O
to	O
represent	O
a	O
mesh	B-Method
model	I-Method
,	O
which	O
is	O
essentially	O
an	O
irregular	B-Method
graph	I-Method
,	O
in	O
a	O
neural	B-Method
network	I-Method
and	O
still	O
be	O
capable	O
of	O
extracting	O
shape	O
details	O
effectively	O
from	O
a	O
given	O
color	O
image	O
represented	O
in	O
a	O
2D	O
regular	O
grid	O
.	O
	
It	O
requires	O
the	O
integration	O
of	O
the	O
knowledge	O
learned	O
from	O
two	O
data	O
modalities	O
.	O
	
On	O
the	O
3D	O
geometry	O
side	O
,	O
we	O
directly	O
build	O
a	O
graph	B-Method
based	I-Method
fully	I-Method
convolutional	I-Method
network	I-Method
(	O
GCN	B-Method
)	O
on	O
the	O
mesh	B-Method
model	I-Method
,	O
where	O
the	O
vertices	O
and	O
edges	O
in	O
the	O
mesh	O
are	O
directly	O
represented	O
as	O
nodes	O
and	O
connections	O
in	O
a	O
graph	O
.	O
	
Network	O
feature	O
encoding	O
information	O
for	O
3D	O
shape	O
is	O
saved	O
on	O
each	O
vertex	O
.	O
	
Through	O
forward	B-Method
propagation	I-Method
,	O
the	O
convolutional	B-Method
layers	I-Method
enable	O
feature	O
exchanging	O
across	O
neighboring	O
nodes	O
,	O
and	O
eventually	O
regress	O
the	O
3D	O
location	O
for	O
each	O
vertex	O
.	O
	
On	O
the	O
2D	O
image	O
side	O
,	O
we	O
use	O
a	O
VGG	B-Method
-	I-Method
16	I-Method
like	I-Method
architecture	I-Method
to	O
extract	O
features	O
as	O
it	O
has	O
been	O
demonstrated	O
to	O
be	O
successful	O
for	O
many	O
tasks	O
.	O
	
To	O
bridge	O
these	O
two	O
,	O
we	O
design	O
a	O
perceptual	B-Method
feature	I-Method
pooling	I-Method
layer	I-Method
which	O
allows	O
each	O
node	O
in	O
the	O
GCN	B-Method
to	O
pool	O
image	O
features	O
from	O
its	O
2D	O
projection	O
on	O
the	O
image	O
,	O
which	O
can	O
be	O
readily	O
obtained	O
by	O
assuming	O
known	O
camera	O
intrinsic	O
matrix	O
.	O
	
The	O
perceptual	B-Method
feature	I-Method
pooling	I-Method
is	O
enabled	O
once	O
after	O
several	O
convolutions	B-Method
(	O
i.e.	O
a	O
deformation	O
block	O
described	O
in	O
Sec	O
.	O
	
[	O
reference	O
]	O
)	O
using	O
updated	O
3D	O
locations	O
,	O
and	O
hence	O
the	O
image	O
features	O
from	O
correct	O
locations	O
can	O
be	O
effectively	O
integrated	O
with	O
3D	O
shapes	O
.	O
	
Given	O
the	O
graph	B-Method
representation	I-Method
,	O
the	O
next	O
challenge	O
is	O
how	O
to	O
update	O
the	O
vertex	O
location	O
effectively	O
towards	O
ground	O
truth	O
.	O
	
In	O
practice	O
,	O
we	O
observe	O
that	O
network	B-Method
trained	O
to	O
directly	O
predict	O
mesh	O
with	O
a	O
large	O
number	O
of	O
vertices	O
is	O
likely	O
to	O
make	O
mistake	O
in	O
the	O
beginning	O
and	O
hard	O
to	O
fix	O
later	O
.	O
	
One	O
reason	O
is	O
that	O
a	O
vertex	O
can	O
not	O
effectively	O
retrieve	O
features	O
from	O
other	O
vertices	O
with	O
a	O
number	O
of	O
edges	O
away	O
,	O
i.e.	O
the	O
limited	O
receptive	O
field	O
.	O
	
To	O
solve	O
this	O
problem	O
,	O
we	O
design	O
a	O
graph	B-Method
unpooling	I-Method
layer	I-Method
,	O
which	O
allows	O
the	O
network	O
to	O
initiate	O
with	O
a	O
smaller	O
number	O
of	O
vertices	O
and	O
increase	O
during	O
the	O
forward	B-Method
propagation	I-Method
.	O
	
With	O
fewer	O
vertices	O
at	O
the	O
beginning	O
stages	O
,	O
the	O
network	O
learns	O
to	O
distribute	O
the	O
vertices	O
around	O
to	O
the	O
most	O
representative	O
location	O
,	O
and	O
then	O
add	O
local	O
details	O
as	O
the	O
number	O
of	O
vertices	O
increases	O
later	O
.	O
	
Besides	O
the	O
graph	B-Method
unpooling	I-Method
layer	I-Method
,	O
we	O
use	O
a	O
deep	O
GCN	B-Method
enhanced	O
by	O
shortcut	B-Method
connections	I-Method
as	O
the	O
backbone	O
of	O
our	O
architecture	O
,	O
which	O
enables	O
large	O
receptive	O
fields	O
for	O
global	O
context	O
and	O
more	O
steps	O
of	O
movements	O
.	O
	
Representing	O
the	O
shape	O
in	O
graph	O
also	O
benefits	O
the	O
learning	B-Method
procedure	I-Method
.	O
	
The	O
known	O
connectivity	O
allows	O
us	O
to	O
define	O
higher	O
order	O
loss	O
functions	O
across	O
neighboring	O
nodes	O
,	O
which	O
are	O
important	O
to	O
regularize	O
3D	O
shapes	O
.	O
	
Specifically	O
,	O
we	O
define	O
a	O
surface	O
normal	O
loss	O
to	O
favor	O
smooth	O
surface	O
;	O
an	O
edge	O
loss	O
to	O
encourage	O
uniform	O
distribution	O
of	O
mesh	O
vertices	O
for	O
high	O
recall	B-Task
;	O
and	O
a	O
laplacian	O
loss	O
to	O
prevent	O
mesh	O
faces	O
from	O
intersecting	O
each	O
other	O
.	O
	
All	O
of	O
these	O
losses	O
are	O
essential	O
to	O
generate	O
quality	O
appealing	B-Method
mesh	I-Method
model	I-Method
,	O
and	O
none	O
of	O
them	O
can	O
be	O
trivially	O
defined	O
without	O
the	O
graph	B-Method
representation	I-Method
.	O
	
The	O
contributions	O
of	O
this	O
paper	O
are	O
mainly	O
in	O
three	O
aspects	O
.	O
	
First	O
,	O
we	O
propose	O
a	O
novel	O
end	B-Method
-	I-Method
to	I-Method
-	I-Method
end	I-Method
neural	I-Method
network	I-Method
architecture	I-Method
that	O
generates	O
a	O
3D	B-Method
mesh	I-Method
model	I-Method
from	O
a	O
single	O
RGB	B-Material
image	I-Material
.	O
	
Second	O
,	O
we	O
design	O
a	O
projection	B-Method
layer	I-Method
which	O
incorporates	O
perceptual	O
image	O
features	O
into	O
the	O
3D	O
geometry	O
represented	O
by	O
GCN	B-Method
.	O
	
Third	O
,	O
our	O
network	O
predict	O
3D	O
geometry	O
in	O
a	O
coarse	O
to	O
fine	O
fashion	O
,	O
which	O
is	O
more	O
reliable	O
and	O
easy	O
to	O
learn	O
.	O
	
section	O
:	O
Related	O
Work	O
	
3D	B-Task
reconstruction	I-Task
has	O
been	O
well	O
studied	O
based	O
on	O
the	O
multi	O
-	O
view	O
geometry	O
(	O
MVG	B-Method
)	I-Method
in	O
the	O
literature	O
.	O
	
The	O
major	O
research	O
directions	O
include	O
structure	B-Method
from	I-Method
motion	I-Method
(	O
SfM	B-Method
)	O
for	O
large	B-Method
-	I-Method
scale	I-Method
high	I-Method
-	I-Method
quality	I-Method
reconstruction	I-Method
and	O
simultaneous	B-Method
localization	I-Method
and	I-Method
mapping	I-Method
(	O
SLAM	B-Method
)	O
for	O
navigation	B-Task
.	O
	
Though	O
they	O
are	O
very	O
successful	O
in	O
these	O
scenarios	O
,	O
they	O
are	O
restricted	O
by	O
1	O
)	O
the	O
coverage	O
that	O
the	O
multiple	O
views	O
can	O
give	O
and	O
2	O
)	O
the	O
appearance	O
of	O
the	O
object	O
that	O
wants	O
to	O
reconstruct	O
.	O
	
The	O
former	O
restriction	O
means	O
MVG	B-Method
can	O
not	O
reconstruct	O
unseen	O
parts	O
of	O
the	O
object	O
,	O
and	O
thus	O
it	O
usually	O
takes	O
a	O
long	O
time	O
to	O
get	O
enough	O
views	O
for	O
a	O
good	O
reconstruction	B-Task
;	O
the	O
latter	O
restriction	O
means	O
MVG	B-Method
can	O
not	O
reconstruct	O
non	O
-	O
lambertian	O
(	O
e.g.	O
reflective	O
or	O
transparent	O
)	O
or	O
textureless	O
objects	O
.	O
	
These	O
restrictions	O
lead	O
to	O
the	O
trend	O
of	O
resorting	O
to	O
learning	B-Method
based	I-Method
approaches	I-Method
.	O
	
Learning	B-Method
based	I-Method
approaches	I-Method
usually	O
consider	O
single	O
or	O
few	O
images	O
,	O
as	O
it	O
largely	O
relies	O
on	O
the	O
shape	O
priors	O
that	O
it	O
can	O
learn	O
from	O
data	O
.	O
	
Early	O
works	O
can	O
be	O
traced	O
back	O
to	O
Hoiem	O
et	O
al	O
.	O
and	O
Saxena	O
et	O
al	O
.	O
.	O
	
Most	O
recently	O
,	O
with	O
the	O
success	O
of	O
deep	B-Method
learning	I-Method
architectures	I-Method
and	O
the	O
release	O
of	O
large	O
-	O
scale	O
3D	O
shape	O
datasets	O
such	O
as	O
ShapeNet	B-Method
,	O
learning	B-Method
based	I-Method
approaches	I-Method
have	O
achieved	O
great	O
progress	O
.	O
	
Huang	O
et	O
al	O
.	O
and	O
Su	O
et	O
al	O
.	O
	
retrieve	O
shape	B-Method
components	I-Method
from	O
a	O
large	O
dataset	O
,	O
assemble	O
them	O
and	O
deform	O
the	O
assembled	O
shape	O
to	O
fit	O
the	O
observed	O
image	O
.	O
	
However	O
,	O
shape	B-Task
retrieval	I-Task
from	O
images	O
itself	O
is	O
an	O
ill	B-Task
-	I-Task
posed	I-Task
problem	I-Task
.	O
	
To	O
avoid	O
this	O
problem	O
,	O
Kar	O
et	O
al	O
.	O
learns	O
a	O
3D	B-Method
deformable	I-Method
model	I-Method
for	O
each	O
object	O
category	O
and	O
capture	O
the	O
shape	O
variations	O
in	O
different	O
images	O
.	O
	
However	O
,	O
the	O
reconstruction	B-Task
is	O
limited	O
to	O
the	O
popular	O
categories	O
and	O
its	O
reconstruction	B-Task
result	O
is	O
usually	O
lack	O
of	O
details	O
.	O
	
Another	O
line	O
of	O
research	O
is	O
to	O
directly	O
learn	O
3D	O
shapes	O
from	O
single	O
images	O
.	O
	
Restricted	O
by	O
the	O
prevalent	O
grid	B-Method
-	I-Method
based	I-Method
deep	I-Method
learning	I-Method
architectures	I-Method
,	O
most	O
works	O
outputs	O
3D	O
voxels	O
,	O
which	O
are	O
usually	O
with	O
low	O
resolutions	O
due	O
to	O
the	O
memory	O
constraint	O
on	O
a	O
modern	O
GPU	O
.	O
	
Most	O
recently	O
,	O
Tatarchenko	O
et	O
al	O
.	O
have	O
proposed	O
an	O
octree	B-Method
representation	I-Method
,	O
which	O
allows	O
to	O
reconstructing	O
higher	O
resolution	O
outputs	O
with	O
a	O
limited	O
memory	O
budget	O
.	O
	
However	O
,	O
a	O
3D	B-Method
voxel	I-Method
is	O
still	O
not	O
a	O
popular	O
shape	B-Method
representation	I-Method
in	O
game	B-Task
and	I-Task
movie	I-Task
industries	I-Task
.	O
	
To	O
avoid	O
drawbacks	O
of	O
the	O
voxel	B-Method
representation	I-Method
,	O
Fan	O
et	O
al	O
.	O
propose	O
to	O
generate	O
point	B-Task
clouds	I-Task
from	O
single	O
images	O
.	O
	
The	O
point	B-Method
cloud	I-Method
representation	I-Method
has	O
no	O
local	O
connections	O
between	O
points	O
,	O
and	O
thus	O
the	O
point	O
positions	O
have	O
a	O
very	O
large	O
degree	O
of	O
freedom	O
.	O
	
Consequently	O
,	O
the	O
generated	O
point	O
cloud	O
is	O
usually	O
not	O
close	O
to	O
a	O
surface	O
and	O
can	O
not	O
be	O
used	O
to	O
recover	O
a	O
3D	O
mesh	O
directly	O
.	O
	
Besides	O
these	O
typical	O
3D	B-Method
representations	I-Method
,	O
there	O
is	O
an	O
interesting	O
work	O
which	O
uses	O
a	O
so	O
-	O
called	O
“	O
geometry	O
image	O
”	O
to	O
represent	O
a	O
3D	O
shape	O
.	O
	
Thus	O
,	O
their	O
network	O
is	O
a	O
2D	B-Method
convolutional	I-Method
neural	I-Method
network	I-Method
which	O
conducts	O
an	O
image	B-Task
to	I-Task
image	I-Task
mapping	I-Task
.	O
	
Our	O
works	O
are	O
mostly	O
related	O
to	O
the	O
two	O
recent	O
works	O
and	O
.	O
	
However	O
,	O
the	O
former	O
adopts	O
simple	O
silhouette	O
supervision	O
,	O
and	O
hence	O
does	O
not	O
perform	O
well	O
for	O
complicated	O
objects	O
such	O
as	O
car	O
,	O
lamp	O
,	O
etc	O
;	O
the	O
latter	O
needs	O
a	O
large	O
model	B-Method
repository	I-Method
to	O
generate	O
a	O
combined	B-Method
model	I-Method
.	O
	
Our	O
base	O
network	O
is	O
a	O
graph	B-Method
neural	I-Method
network	I-Method
;	O
this	O
architecture	O
has	O
been	O
adopted	O
for	O
shape	B-Task
analysis	I-Task
.	O
	
In	O
the	O
meanwhile	O
,	O
there	O
are	O
charting	B-Method
-	I-Method
based	I-Method
methods	I-Method
which	O
directly	O
apply	O
convolutions	B-Method
on	I-Method
surface	I-Method
manifolds	I-Method
for	O
shape	B-Task
analysis	I-Task
.	O
	
As	O
far	O
as	O
we	O
know	O
,	O
these	O
architectures	O
have	O
never	O
been	O
adopted	O
for	O
3D	B-Task
reconstruction	I-Task
from	O
single	O
images	O
,	O
though	O
graph	B-Method
and	I-Method
surface	I-Method
manifold	I-Method
are	O
natural	O
representations	O
for	O
meshed	O
objects	O
.	O
	
For	O
a	O
comprehensive	O
understanding	O
of	O
the	O
graph	B-Method
neural	I-Method
network	I-Method
,	O
the	O
charting	B-Method
-	I-Method
based	I-Method
methods	I-Method
and	O
their	O
applications	O
,	O
please	O
refer	O
to	O
this	O
survey	O
.	O
	
section	O
:	O
Method	O
	
subsection	O
:	O
Preliminary	O
:	O
Graph	B-Method
-	I-Method
based	I-Method
Convolution	I-Method
	
We	O
first	O
provide	O
some	O
background	O
about	O
graph	B-Method
based	I-Method
convolution	I-Method
;	O
more	O
detailed	O
introduction	O
can	O
be	O
found	O
in	O
.	O
	
A	O
3D	O
mesh	O
is	O
a	O
collection	O
of	O
vertices	O
,	O
edges	O
and	O
faces	O
that	O
defines	O
the	O
shape	O
of	O
a	O
3D	O
object	O
;	O
it	O
can	O
be	O
represented	O
by	O
a	O
graph	B-Method
,	O
where	O
is	O
the	O
set	O
of	O
vertices	O
in	O
the	O
mesh	O
,	O
is	O
the	O
set	O
of	O
edges	O
with	O
each	O
connecting	O
two	O
vertices	O
,	O
and	O
are	O
the	O
feature	O
vectors	O
attached	O
on	O
vertices	O
.	O
	
A	O
graph	B-Method
based	I-Method
convolutional	I-Method
layer	I-Method
is	O
defined	O
on	O
irregular	O
graph	O
as	O
:	O
where	O
are	O
the	O
feature	O
vectors	O
on	O
vertex	O
before	O
and	O
after	O
the	O
convolution	O
,	O
and	O
is	O
the	O
neighboring	O
vertices	O
of	O
;	O
and	O
are	O
the	O
learnable	O
parameter	O
matrices	O
of	O
that	O
are	O
applied	O
to	O
all	O
vertices	O
.	O
	
Note	O
that	O
is	O
shared	O
for	O
all	O
edges	O
,	O
and	O
thus	O
(	O
[	O
reference	O
]	O
)	O
works	O
on	O
nodes	O
with	O
different	O
vertex	O
degrees	O
.	O
	
In	O
our	O
case	O
,	O
the	O
attached	O
feature	O
vector	O
is	O
the	O
concatenation	O
of	O
the	O
3D	O
vertex	O
coordinate	O
,	O
feature	O
encoding	O
3D	O
shape	O
,	O
and	O
feature	O
learned	O
from	O
the	O
input	O
color	O
image	O
(	O
if	O
they	O
exist	O
)	O
.	O
	
Running	O
convolutions	B-Method
updates	O
the	O
features	O
,	O
which	O
is	O
equivalent	O
as	O
applying	O
a	O
deformation	O
.	O
	
subsection	O
:	O
System	O
Overview	O
	
Our	O
model	O
is	O
an	O
end	B-Method
-	I-Method
to	I-Method
-	I-Method
end	I-Method
deep	I-Method
learning	I-Method
framework	I-Method
that	O
takes	O
a	O
single	O
color	O
image	O
as	O
input	O
and	O
produces	O
a	O
3D	B-Method
mesh	I-Method
model	I-Method
in	O
camera	O
coordinate	O
.	O
	
The	O
overview	O
of	O
our	O
framework	O
is	O
illustrated	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
.	O
	
The	O
whole	O
network	O
consists	O
an	O
image	B-Method
feature	I-Method
network	I-Method
and	O
a	O
cascaded	B-Method
mesh	I-Method
deformation	I-Method
network	I-Method
.	O
	
The	O
image	B-Method
feature	I-Method
network	I-Method
is	O
a	O
2D	B-Method
CNN	I-Method
that	O
extract	O
perceptual	O
feature	O
from	O
the	O
input	O
image	O
,	O
which	O
is	O
leveraged	O
by	O
the	O
mesh	B-Method
deformation	I-Method
network	I-Method
to	O
progressively	O
deform	O
an	O
ellipsoid	O
mesh	O
into	O
the	O
desired	O
3D	B-Method
model	I-Method
.	O
	
The	O
cascaded	B-Method
mesh	I-Method
deformation	I-Method
network	I-Method
is	O
a	O
graph	B-Method
-	I-Method
based	I-Method
convolution	I-Method
network	I-Method
(	O
GCN	B-Method
)	O
,	O
which	O
contains	O
three	O
deformation	O
blocks	O
intersected	O
by	O
two	O
graph	B-Method
unpooling	I-Method
layers	I-Method
.	O
	
Each	O
deformation	B-Method
block	I-Method
takes	O
an	O
input	O
graph	O
representing	O
the	O
current	O
mesh	B-Method
model	I-Method
with	O
the	O
3D	O
shape	O
feature	O
attached	O
on	O
vertices	O
,	O
and	O
produces	O
new	O
vertices	O
locations	O
and	O
features	O
.	O
	
Whereas	O
the	O
graph	B-Method
unpooling	I-Method
layers	I-Method
increase	O
the	O
number	O
of	O
vertices	O
to	O
increase	O
the	O
capacity	O
of	O
handling	O
details	O
,	O
while	O
still	O
maintain	O
the	O
triangular	O
mesh	O
topology	O
.	O
	
Starting	O
from	O
a	O
smaller	O
number	O
of	O
vertices	O
,	O
our	O
model	O
learns	O
to	O
gradually	O
deform	O
and	O
add	O
details	O
to	O
the	O
mesh	B-Method
model	I-Method
in	O
a	O
coarse	O
-	O
to	O
-	O
fine	O
fashion	O
.	O
	
In	O
order	O
to	O
train	O
the	O
network	O
to	O
produce	O
stable	O
deformation	O
and	O
generate	O
an	O
accurate	O
mesh	O
,	O
we	O
extend	O
the	O
Chamfer	O
Distance	O
loss	O
used	O
by	O
Fan	O
et	O
al	O
.	O
	
with	O
three	O
other	O
mesh	O
specific	O
loss	O
–	O
Surface	O
normal	O
loss	O
,	O
Laplacian	O
regularization	O
loss	O
,	O
and	O
Edge	O
length	O
loss	O
.	O
	
The	O
remaining	O
part	O
of	O
this	O
section	O
describes	O
details	O
of	O
these	O
components	O
.	O
	
subsection	O
:	O
Initial	O
ellipsoid	O
	
Our	O
model	O
does	O
not	O
require	O
any	O
prior	O
knowledge	O
of	O
the	O
3D	O
shape	O
,	O
and	O
always	O
deform	O
from	O
an	O
initial	O
ellipsoid	O
with	O
average	O
size	O
placed	O
at	O
the	O
common	O
location	O
in	O
the	O
camera	O
coordinate	O
.	O
	
The	O
ellipsoid	O
is	O
centered	O
at	O
0.8	O
m	O
in	O
front	O
of	O
the	O
camera	O
with	O
0.2	O
m	O
,	O
0.2	O
m	O
,	O
0.4	O
m	O
as	O
the	O
radius	O
of	O
three	O
axis	O
.	O
	
The	O
mesh	B-Method
model	I-Method
is	O
generated	O
by	O
implicit	B-Method
surface	I-Method
algorithm	I-Method
in	O
Meshlab	B-Method
and	O
contains	O
156	O
vertices	O
.	O
	
We	O
use	O
this	O
ellipsoid	O
to	O
initialize	O
our	O
input	O
graph	O
,	O
where	O
the	O
initial	O
feature	O
contains	O
only	O
the	O
3D	O
coordinate	O
of	O
each	O
vertex	O
.	O
	
subsection	O
:	O
Mesh	B-Method
deformation	I-Method
block	I-Method
	
The	O
architecture	O
of	O
mesh	B-Task
deformation	I-Task
block	I-Task
is	O
shown	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
(	O
a	O
)	O
.	O
	
In	O
order	O
to	O
generate	O
3D	B-Method
mesh	I-Method
model	I-Method
that	O
is	O
consistent	O
with	O
the	O
object	O
shown	O
in	O
the	O
input	O
image	O
,	O
the	O
deformation	O
block	O
need	O
to	O
pool	O
feature	O
(	O
)	O
from	O
the	O
input	O
image	O
.	O
	
This	O
is	O
done	O
in	O
conjunction	O
with	O
the	O
image	B-Method
feature	I-Method
network	I-Method
and	O
a	O
perceptual	B-Method
feature	I-Method
pooling	I-Method
layer	I-Method
given	O
the	O
location	O
of	O
vertex	O
(	O
)	O
in	O
the	O
current	O
mesh	B-Method
model	I-Method
.	O
	
The	O
pooled	O
perceptual	O
feature	O
is	O
then	O
concatenated	O
with	O
the	O
3D	O
shape	O
feature	O
attached	O
on	O
the	O
vertex	O
from	O
the	O
input	O
graph	O
(	O
)	O
and	O
fed	O
into	O
a	O
series	O
of	O
graph	B-Method
based	I-Method
ResNet	I-Method
(	O
G	B-Method
-	I-Method
ResNet	I-Method
)	O
.	O
	
The	O
G	B-Method
-	I-Method
ResNet	I-Method
produces	O
,	O
also	O
as	O
the	O
output	O
of	O
the	O
mesh	B-Method
deformation	I-Method
block	I-Method
,	O
the	O
new	O
coordinates	O
(	O
)	O
and	O
3d	O
shape	O
feature	O
(	O
)	O
for	O
each	O
vertex	O
.	O
	
subsubsection	O
:	O
Perceptual	B-Method
feature	I-Method
pooling	I-Method
layer	I-Method
	
We	O
use	O
a	O
VGG	B-Method
-	I-Method
16	I-Method
architecture	I-Method
up	O
to	O
layer	B-Method
conv5_3	I-Method
as	O
the	O
image	B-Method
feature	I-Method
network	I-Method
as	O
it	O
has	O
been	O
widely	O
used	O
.	O
	
Given	O
the	O
3D	O
coordinate	O
of	O
a	O
vertex	O
,	O
we	O
calculate	O
its	O
2D	O
projection	O
on	O
input	O
image	O
plane	O
using	O
camera	O
intrinsics	O
,	O
and	O
then	O
pool	O
the	O
feature	O
from	O
four	O
nearby	O
pixels	O
using	O
bilinear	B-Method
interpolation	I-Method
.	O
	
In	O
particular	O
,	O
we	O
concatenate	O
feature	O
extracted	O
from	O
layer	O
‘	O
conv3_3	O
’	O
,	O
	
‘	O
	
conv4_3	B-Method
’	O
,	O
and	O
‘	O
conv5_3	O
’	O
,	O
which	O
results	O
in	O
a	O
total	O
dimension	O
of	O
1280	O
.	O
	
This	O
perceptual	O
feature	O
is	O
then	O
concatenated	O
with	O
the	O
128	O
-	O
dim	O
3D	O
feature	O
from	O
the	O
input	O
mesh	O
,	O
which	O
results	O
in	O
a	O
total	O
dimension	O
of	O
1408	O
.	O
	
This	O
is	O
illustrated	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
(	O
b	O
)	O
.	O
	
Note	O
that	O
in	O
the	O
first	O
block	O
,	O
the	O
perceptual	O
feature	O
is	O
concatenated	O
with	O
the	O
3	O
-	O
dim	O
feature	O
(	O
coordinate	O
)	O
since	O
there	O
is	O
no	O
learnt	O
shape	O
feature	O
at	O
the	O
beginning	O
.	O
	
subsubsection	O
:	O
G	B-Method
-	I-Method
ResNet	I-Method
	
After	O
obtaining	O
1408	O
-	O
dim	O
feature	O
for	O
each	O
vertex	O
representing	O
both	O
3D	O
shape	O
and	O
2D	O
image	O
information	O
,	O
we	O
design	O
a	O
graph	B-Method
based	I-Method
convolutional	I-Method
neural	I-Method
network	I-Method
to	O
predict	O
new	O
location	O
and	O
3D	O
shape	O
feature	O
for	O
each	O
vertex	O
.	O
	
This	O
requires	O
efficient	O
exchange	O
of	O
the	O
information	O
between	O
vertices	O
.	O
	
However	O
,	O
as	O
defined	O
in	O
(	O
[	O
reference	O
]	O
)	O
,	O
each	O
convolution	B-Method
only	O
enables	O
the	O
feature	O
exchanging	O
between	O
neighboring	O
pixels	O
,	O
which	O
severely	O
impairs	O
the	O
efficiency	O
of	O
information	B-Task
exchanging	I-Task
.	O
	
This	O
is	O
equivalent	O
as	O
the	O
small	O
receptive	O
field	O
issue	O
on	O
2D	B-Method
CNN	I-Method
.	O
	
To	O
solve	O
this	O
issue	O
,	O
we	O
make	O
a	O
very	O
deep	B-Method
network	I-Method
with	O
shortcut	O
connections	O
and	O
denote	O
it	O
as	O
G	O
-	O
ResNet	O
(	O
Fig	O
.	O
	
[	O
reference	O
]	O
(	O
a	O
)	O
)	O
.	O
	
In	O
this	O
work	O
,	O
the	O
G	O
-	O
ResNet	O
in	O
all	O
blocks	O
has	O
the	O
same	O
structure	O
,	O
which	O
consists	O
of	O
14	O
graph	B-Method
residual	I-Method
convolutional	I-Method
layers	I-Method
with	O
128	O
channels	O
.	O
	
The	O
serial	B-Method
of	I-Method
G	I-Method
-	I-Method
ResNet	I-Method
block	I-Method
produces	O
a	O
new	O
128	O
-	O
dim	O
3D	O
feature	O
.	O
	
In	O
addition	O
to	O
the	O
feature	O
output	O
,	O
there	O
is	O
a	O
branch	B-Method
which	O
applies	O
an	O
extra	O
graph	B-Method
convolutional	I-Method
layer	I-Method
to	O
the	O
last	O
layer	O
features	O
and	O
outputs	O
the	O
3D	O
coordinates	O
of	O
the	O
vertex	O
.	O
	
subsection	O
:	O
Graph	B-Method
unpooling	I-Method
layer	I-Method
	
The	O
goal	O
of	O
unpooling	B-Method
layer	I-Method
is	O
to	O
increase	O
the	O
number	O
of	O
vertex	O
in	O
the	O
GCNN	B-Method
.	O
	
It	O
allows	O
us	O
to	O
start	O
from	O
a	O
mesh	O
with	O
fewer	O
vertices	O
and	O
add	O
more	O
only	O
when	O
necessary	O
,	O
which	O
reduces	O
memory	B-Metric
costs	I-Metric
and	O
produces	O
better	O
results	O
.	O
	
A	O
straightforward	O
approach	O
is	O
to	O
add	O
one	O
vertex	O
in	O
the	O
center	O
of	O
each	O
triangle	O
and	O
connect	O
it	O
with	O
the	O
three	O
vertices	O
of	O
the	O
triangle	O
(	O
Fig	O
.	O
	
[	O
reference	O
]	O
	
(	O
b	O
)	O
Face	B-Method
-	I-Method
based	I-Method
)	O
.	O
	
However	O
,	O
this	O
causes	O
imbalanced	O
vertex	O
degrees	O
,	O
i.e.	O
number	O
of	O
edges	O
on	O
vertex	O
.	O
	
Inspired	O
by	O
the	O
vertex	B-Method
adding	I-Method
strategy	I-Method
of	O
the	O
mesh	B-Method
subdivision	I-Method
algorithm	I-Method
prevalent	O
in	O
computer	B-Task
graphics	I-Task
,	O
we	O
add	O
a	O
vertex	O
at	O
the	O
center	O
of	O
each	O
edge	O
and	O
connect	O
it	O
with	O
the	O
two	O
end	O
-	O
point	O
of	O
this	O
edge	O
(	O
Fig	O
.	O
	
[	O
reference	O
]	O
(	O
a	O
)	O
)	O
.	O
	
The	O
3D	O
feature	O
for	O
newly	O
added	O
vertex	O
is	O
set	O
as	O
the	O
average	O
of	O
its	O
two	O
neighbors	O
.	O
	
We	O
also	O
connect	O
three	O
vertices	O
if	O
they	O
are	O
added	O
on	O
the	O
same	O
triangle	O
(	O
dashed	O
line	O
.	O
)	O
	
Consequently	O
,	O
we	O
create	O
4	O
new	O
triangles	O
for	O
each	O
triangle	O
in	O
the	O
original	O
mesh	O
,	O
and	O
the	O
number	O
of	O
vertex	O
is	O
increased	O
by	O
the	O
number	O
of	O
edges	O
in	O
the	O
original	O
mesh	O
.	O
	
This	O
edge	O
-	O
based	O
unpooling	O
uniformly	O
upsamples	O
the	O
vertices	O
as	O
shown	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
(	O
b	O
)	O
Edge	B-Method
-	I-Method
based	I-Method
.	O
	
subsection	O
:	O
Losses	O
	
We	O
define	O
four	O
kinds	O
of	O
losses	O
to	O
constrain	O
the	O
property	O
of	O
the	O
output	O
shape	O
and	O
the	O
deformation	B-Method
procedure	I-Method
to	O
guarantee	O
appealing	O
results	O
.	O
	
We	O
adopt	O
the	O
Chamfer	O
loss	O
to	O
constrain	O
the	O
location	O
of	O
mesh	O
vertices	O
,	O
a	O
normal	O
loss	O
to	O
enforce	O
the	O
consistency	O
of	O
surface	O
normal	O
,	O
a	O
laplacian	B-Method
regularization	I-Method
to	O
maintain	O
relative	O
location	O
between	O
neighboring	O
vertices	O
during	O
deformation	O
,	O
and	O
an	O
edge	B-Method
length	I-Method
regularization	I-Method
to	O
prevent	O
outliers	O
.	O
	
These	O
losses	O
are	O
applied	O
with	O
equal	O
weight	O
on	O
both	O
the	O
intermediate	O
and	O
final	O
mesh	O
.	O
	
Unless	O
otherwise	O
stated	O
,	O
we	O
use	O
for	O
a	O
vertex	O
in	O
the	O
predicted	O
mesh	O
,	O
for	O
a	O
vertex	O
in	O
the	O
ground	O
truth	O
mesh	O
,	O
for	O
the	O
neighboring	O
pixel	O
of	O
,	O
till	O
the	O
end	O
of	O
this	O
section	O
.	O
	
subsubsection	O
:	O
Chamfer	B-Method
loss	I-Method
	
The	O
Chamfer	O
distance	O
measures	O
the	O
distance	O
of	O
each	O
point	O
to	O
the	O
other	O
set	O
:	O
It	O
is	O
reasonably	O
good	O
to	O
regress	O
the	O
vertices	O
close	O
to	O
its	O
correct	O
position	O
,	O
however	O
is	O
not	O
sufficient	O
to	O
produce	O
nice	O
3D	O
mesh	O
(	O
see	O
the	O
result	O
of	O
Fan	O
et	O
al	O
.	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
)	O
.	O
	
subsubsection	O
:	O
Normal	B-Method
loss	I-Method
	
We	O
further	O
define	O
loss	O
on	O
surface	O
normal	O
to	O
characterize	O
high	O
order	O
properties	O
:	O
where	O
is	O
the	O
closest	O
vertex	O
for	O
that	O
is	O
found	O
when	O
calculating	O
the	O
chamfer	O
loss	O
,	O
is	O
the	O
neighboring	O
pixel	O
of	O
,	O
is	O
the	O
inner	O
product	O
of	O
two	O
vectors	O
,	O
and	O
is	O
the	O
observed	O
surface	O
normal	O
from	O
ground	O
truth	O
.	O
	
Essentially	O
,	O
this	O
loss	O
requires	O
the	O
edge	O
between	O
a	O
vertex	O
with	O
its	O
neighbors	O
to	O
perpendicular	O
to	O
the	O
observation	O
from	O
the	O
ground	O
truth	O
.	O
	
One	O
may	O
find	O
that	O
this	O
loss	O
does	O
not	O
equal	O
to	O
zero	O
unless	O
on	O
a	O
planar	O
surface	O
.	O
	
However	O
,	O
optimizing	O
this	O
loss	O
is	O
equivalent	O
as	O
forcing	O
the	O
normal	O
of	O
a	O
locally	O
fitted	O
tangent	O
plane	O
to	O
be	O
consistent	O
with	O
the	O
observation	O
,	O
which	O
works	O
practically	O
well	O
in	O
our	O
experiment	O
.	O
	
Moreover	O
,	O
this	O
normal	B-Method
loss	I-Method
is	O
fully	O
differentiable	O
and	O
easy	O
to	O
optimize	O
.	O
	
subsubsection	O
:	O
Regularization	B-Method
	
Even	O
with	O
the	O
Chamfer	O
loss	O
and	O
Normal	O
loss	O
,	O
the	O
optimization	B-Task
is	O
easily	O
stucked	O
in	O
some	O
local	O
minimum	O
.	O
	
More	O
specifically	O
,	O
the	O
network	O
may	O
generate	O
some	O
super	O
large	O
deformation	O
to	O
favor	O
some	O
local	O
consistency	O
,	O
which	O
is	O
especially	O
harmful	O
at	O
the	O
beginning	O
when	O
the	O
estimation	O
is	O
far	O
from	O
ground	O
truth	O
,	O
and	O
causes	O
flying	O
vertices	O
(	O
Fig	O
.	O
	
[	O
reference	O
]	O
)	O
.	O
	
paragraph	O
:	O
Laplacian	B-Method
regularization	I-Method
	
To	O
handle	O
these	O
problem	O
,	O
we	O
first	O
propose	O
a	O
Laplacian	B-Method
term	I-Method
to	O
prevent	O
the	O
vertices	O
from	O
moving	O
too	O
freely	O
,	O
which	O
potentially	O
avoids	O
mesh	B-Task
self	I-Task
-	I-Task
intersection	I-Task
.	O
	
The	O
laplaician	B-Method
term	I-Method
serves	O
as	O
a	O
local	B-Method
detail	I-Method
preserving	I-Method
operator	I-Method
,	O
that	O
encourages	O
neighboring	O
vertices	O
to	O
have	O
the	O
same	O
movement	O
.	O
	
In	O
the	O
first	O
deformation	O
block	O
,	O
it	O
acts	O
like	O
a	O
surface	O
smoothness	O
term	O
since	O
the	O
input	O
to	O
this	O
block	O
is	O
a	O
smooth	O
-	O
everywhere	O
ellipsoid	O
;	O
starting	O
from	O
the	O
second	O
block	O
,	O
it	O
prevents	O
the	O
3D	B-Method
mesh	I-Method
model	I-Method
from	O
deforming	O
too	O
much	O
,	O
so	O
that	O
only	O
fine	O
-	O
grained	O
details	O
are	O
added	O
to	O
the	O
mesh	B-Method
model	I-Method
.	O
	
To	O
calculate	O
this	O
loss	O
,	O
we	O
first	O
define	O
a	O
laplacian	O
coordinate	O
for	O
each	O
vertex	O
as	O
and	O
the	O
laplacian	O
regularization	O
is	O
defined	O
as	O
:	O
where	O
and	O
are	O
the	O
laplacian	O
coordinate	O
of	O
a	O
vertex	O
after	O
and	O
before	O
a	O
deformation	O
block	O
.	O
	
paragraph	O
:	O
Edge	B-Method
length	I-Method
regularization	I-Method
.	O
	
To	O
penalize	O
flying	O
vertices	O
,	O
which	O
ususally	O
cause	O
long	O
edge	O
,	O
we	O
add	O
an	O
edge	O
length	O
regularization	O
loss	O
:	O
The	O
overall	B-Metric
loss	I-Metric
is	O
a	O
weighted	O
sum	O
of	O
all	O
four	O
losses	O
,	O
,	O
where	O
,	O
and	O
are	O
the	O
hyperparameters	O
which	O
balance	O
the	O
losses	O
and	O
fixed	O
for	O
all	O
the	O
experiments	O
.	O
	
section	O
:	O
Experiment	O
	
In	O
this	O
section	O
,	O
we	O
perform	O
an	O
extensive	O
evaluation	O
on	O
our	O
model	O
.	O
	
In	O
addition	O
to	O
comparing	O
with	O
previous	O
3D	B-Method
shape	I-Method
generation	I-Method
works	O
for	O
evaluating	O
the	O
reconstruction	B-Task
accuracy	O
,	O
we	O
also	O
analyse	O
the	O
importance	O
of	O
each	O
component	O
in	O
our	O
model	O
.	O
	
Qualitative	O
results	O
on	O
both	O
synthetic	O
and	O
real	O
-	O
world	O
images	O
further	O
show	O
that	O
our	O
model	O
produces	O
triangular	O
meshes	O
with	O
smooth	O
surfaces	O
and	O
still	O
maintains	O
details	O
depicted	O
in	O
the	O
input	O
images	O
.	O
	
subsection	O
:	O
Experimental	O
setup	O
	
subsubsection	O
:	O
Data	O
.	O
	
We	O
use	O
the	O
dataset	O
provided	O
by	O
Choy	O
et	O
al	O
.	O
.	O
	
The	O
dataset	O
contains	O
rendering	O
images	O
of	O
50k	O
models	O
belonging	O
to	O
13	O
object	O
categories	O
from	O
ShapeNet	B-Material
,	O
which	O
is	O
a	O
collection	O
of	O
3D	B-Method
CAD	I-Method
models	I-Method
that	O
are	O
organized	O
according	O
to	O
the	O
WordNet	O
hierarchy	O
.	O
	
A	O
model	O
is	O
rendered	O
from	O
various	O
camera	O
viewpoints	O
,	O
and	O
camera	O
intrinsic	O
and	O
extrinsic	O
matrices	O
are	O
recorded	O
.	O
	
For	O
fair	O
comparison	O
,	O
we	O
use	O
the	O
same	O
training	O
/	O
testing	O
split	O
as	O
in	O
Choy	O
et	O
.	O
	
al	O
.	O
.	O
	
subsubsection	O
:	O
Evaluation	B-Metric
Metric	I-Metric
.	O
	
We	O
adopt	O
the	O
standard	O
3D	B-Task
reconstruction	I-Task
metric	O
.	O
	
We	O
first	O
uniformly	O
sample	O
points	O
from	O
our	O
result	O
and	O
ground	O
truth	O
.	O
	
We	O
calculate	O
precision	B-Metric
and	O
recall	B-Metric
by	O
checking	O
the	O
percentage	O
of	O
points	O
in	O
prediction	O
or	O
ground	O
truth	O
that	O
can	O
find	O
a	O
nearest	O
neighbor	O
from	O
the	O
other	O
within	O
certain	O
threshold	O
.	O
	
A	O
F	B-Metric
-	I-Metric
score	I-Metric
as	O
the	O
harmonic	B-Metric
mean	I-Metric
of	I-Metric
precision	I-Metric
and	I-Metric
recall	I-Metric
is	O
then	O
calculated	O
.	O
	
Following	O
Fan	O
et	O
.	O
	
al	O
.	O
	
,	O
we	O
also	O
report	O
the	O
Chamfer	O
Distance	O
(	O
CD	B-Method
)	O
and	O
Earth	O
Mover	O
’s	O
Distance	O
(	O
EMD	B-Method
)	O
.	O
	
For	O
F	B-Metric
-	I-Metric
Score	I-Metric
,	O
larger	O
is	O
better	O
.	O
	
For	O
CD	B-Method
and	O
EMD	B-Method
,	O
smaller	O
is	O
better	O
.	O
	
On	O
the	O
other	O
hand	O
,	O
we	O
realize	O
that	O
the	O
commonly	O
used	O
evaluation	B-Metric
metrics	I-Metric
for	O
shape	B-Task
generation	I-Task
may	O
not	O
thoroughly	O
reflect	O
the	O
shape	B-Metric
quality	I-Metric
.	O
	
They	O
often	O
capture	O
occupancy	O
or	O
point	O
-	O
wise	O
distance	O
rather	O
than	O
surface	O
properties	O
,	O
such	O
as	O
continuity	O
,	O
smoothness	O
,	O
high	O
-	O
order	O
details	O
,	O
for	O
which	O
a	O
standard	O
evaluation	B-Metric
metric	I-Metric
is	O
barely	O
missing	O
in	O
literature	O
.	O
	
Thus	O
,	O
we	O
recommend	O
to	O
pay	O
attention	O
on	O
qualitative	O
results	O
for	O
better	O
understanding	O
of	O
these	O
aspects	O
.	O
	
subsubsection	O
:	O
Baselines	O
.	O
	
We	O
compare	O
the	O
presented	O
approach	O
to	O
the	O
most	O
recent	O
single	B-Task
image	I-Task
reconstruction	I-Task
approaches	O
.	O
	
Specifically	O
,	O
we	O
compare	O
with	O
two	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
methods	O
-	O
Choy	O
et	O
.	O
	
al	O
.	O
	
(	O
3D	O
-	O
R2N2	O
)	O
producing	O
3D	O
volume	O
,	O
and	O
Fan	O
et	O
.	O
	
al	O
.	O
	
(	O
PSG	B-Method
)	O
producing	O
point	O
cloud	O
.	O
	
Since	O
the	O
metrics	O
are	O
defined	O
on	O
point	O
cloud	O
,	O
we	O
can	O
evaluate	O
PSG	B-Method
directly	O
on	O
its	O
output	O
,	O
our	O
method	O
by	O
uniformly	O
sampling	O
point	O
on	O
surface	O
,	O
and	O
3D	O
-	O
R2N2	O
by	O
uniformly	O
sampling	O
point	O
from	O
mesh	O
created	O
using	O
the	O
Marching	B-Method
Cube	I-Method
method	I-Method
.	O
	
We	O
also	O
compare	O
to	O
Neural	B-Method
3D	I-Method
Mesh	I-Method
Renderer	I-Method
(	O
N3MR	B-Method
)	O
which	O
is	O
so	O
far	O
the	O
only	O
deep	B-Method
learning	I-Method
based	I-Method
mesh	I-Method
generation	I-Method
model	I-Method
with	O
code	O
public	O
available	O
.	O
	
For	O
fair	O
comparison	O
,	O
the	O
models	O
are	O
trained	O
with	O
the	O
same	O
data	O
using	O
the	O
same	O
amount	O
of	O
time	O
.	O
	
subsubsection	O
:	O
Training	O
and	O
Runtime	O
.	O
	
Our	O
network	O
receives	O
input	O
images	O
of	O
size	O
,	O
and	O
initial	O
ellipsoid	O
with	O
156	O
vertices	O
and	O
462	O
edges	O
.	O
	
The	O
network	O
is	O
implemented	O
in	O
Tensorflow	B-Method
and	O
optimized	O
using	O
Adam	B-Method
with	O
weight	B-Method
decay	I-Method
1e	O
-	O
5	O
.	O
	
The	O
batch	O
size	O
is	O
1	O
;	O
the	O
total	O
number	O
of	O
training	O
epoch	O
is	O
50	O
;	O
the	O
learning	B-Metric
rate	I-Metric
is	O
initialized	O
as	O
3e	O
-	O
5	O
and	O
drops	O
to	O
1e	O
-	O
5	O
after	O
40	O
epochs	O
.	O
	
The	O
total	O
training	B-Metric
time	I-Metric
is	O
72	O
hours	O
on	O
a	O
Nvidia	B-Material
Titan	I-Material
X.	I-Material
	
During	O
testing	O
,	O
our	O
model	O
takes	O
15.58ms	O
to	O
generate	O
a	O
mesh	O
with	O
2466	O
vertices	O
.	O
	
subsection	O
:	O
Comparison	O
to	O
state	O
of	O
the	O
art	O
	
Tab	O
.	O
	
[	O
reference	O
]	O
shows	O
the	O
F	B-Metric
-	I-Metric
score	I-Metric
with	O
different	O
thresholds	O
of	O
different	O
methods	O
.	O
	
Our	O
approach	O
outperforms	O
the	O
other	O
methods	O
in	O
all	O
categories	O
except	O
watercraft	O
.	O
	
Notably	O
,	O
our	O
results	O
are	O
significantly	O
better	O
than	O
the	O
others	O
in	O
all	O
categories	O
under	O
a	O
smaller	O
threshold	O
,	O
showing	O
at	O
least	O
10	O
%	O
F	B-Metric
-	I-Metric
score	I-Metric
improvement	I-Metric
.	O
	
N3MR	B-Method
does	O
not	O
perform	O
well	O
,	O
and	O
its	O
result	O
is	O
about	O
50	O
%	O
worse	O
than	O
ours	O
,	O
probably	O
because	O
their	O
model	O
only	O
learns	O
from	O
limited	O
silhouette	O
signal	O
in	O
images	O
and	O
lacks	O
of	O
explicit	O
handling	O
of	O
the	O
3D	O
mesh	O
.	O
	
We	O
also	O
show	O
the	O
CD	O
and	O
EMD	B-Method
for	O
all	O
categories	O
in	O
Tab	O
.	O
	
[	O
reference	O
]	O
.	O
	
Our	O
approach	O
outperforms	O
the	O
other	O
methods	O
in	O
most	O
categories	O
and	O
achieves	O
the	O
best	O
mean	B-Metric
score	I-Metric
.	O
	
The	O
major	O
competitor	O
is	O
PSG	B-Method
,	O
which	O
produces	O
a	O
point	O
cloud	O
and	O
has	O
the	O
most	O
freedom	O
;	O
this	O
freedom	O
leads	O
to	O
smaller	O
CD	O
and	O
EMD	B-Method
,	O
however	O
does	O
not	O
necessarily	O
leads	O
to	O
a	O
better	O
mesh	B-Method
model	I-Method
without	O
proper	O
regularization	B-Method
.	O
	
To	O
demonstrate	O
this	O
,	O
we	O
show	O
the	O
qualitative	O
results	O
to	O
analyze	O
why	O
our	O
approach	O
outperforms	O
the	O
others	O
.	O
	
Fig	O
.	O
	
[	O
reference	O
]	O
shows	O
the	O
visual	O
results	O
.	O
	
To	O
compare	O
the	O
quality	O
of	O
mesh	B-Method
model	I-Method
,	O
we	O
convert	O
volumetric	O
and	O
point	O
cloud	O
to	O
mesh	O
using	O
standard	O
approaches	O
.	O
	
As	O
we	O
can	O
see	O
,	O
the	O
3D	O
volume	O
results	O
produced	O
by	O
3D	O
-	O
R2N2	O
lack	O
of	O
details	O
due	O
to	O
the	O
low	O
resolution	O
,	O
e.g.	O
,	O
the	O
legs	O
are	O
missing	O
in	O
the	O
chair	O
example	O
as	O
shown	O
in	O
the	O
4	O
-	O
th	O
row	O
of	O
Fig	O
.	O
	
[	O
reference	O
]	O
.	O
	
We	O
tried	O
octree	B-Method
based	I-Method
solution	I-Method
to	O
increase	O
the	O
volume	O
resolution	O
,	O
but	O
found	O
it	O
still	O
hard	O
to	O
recover	O
surface	O
level	O
details	O
as	O
much	O
as	O
our	O
model	O
.	O
	
PSG	B-Method
produces	O
sparse	B-Task
3D	I-Task
point	I-Task
clouds	I-Task
,	O
and	O
it	O
is	O
non	O
-	O
trivial	O
to	O
recover	O
meshes	O
from	O
them	O
.	O
	
This	O
is	O
due	O
to	O
the	O
applied	O
Chamfer	B-Method
loss	I-Method
acting	O
like	O
a	O
regression	B-Method
loss	I-Method
which	O
gives	O
too	O
much	O
degree	O
of	O
freedom	O
to	O
the	O
point	O
cloud	O
.	O
	
N3MR	B-Method
produces	O
very	O
rough	O
shape	O
,	O
which	O
might	O
be	O
sufficient	O
for	O
some	O
rendering	B-Task
tasks	I-Task
,	O
however	O
can	O
not	O
recover	O
complicated	O
objects	O
such	O
as	O
chairs	O
and	O
tables	O
.	O
	
In	O
contrast	O
,	O
our	O
model	O
does	O
not	O
suffer	O
from	O
these	O
issues	O
by	O
leveraging	O
a	O
mesh	B-Method
representation	I-Method
,	O
integration	O
of	O
perceptual	O
feature	O
,	O
and	O
carefully	O
defined	O
losses	O
during	O
the	O
training	O
.	O
	
Our	O
result	O
is	O
not	O
restricted	O
by	O
the	O
resolution	O
due	O
to	O
the	O
limited	O
memory	O
budget	O
and	O
contains	O
both	O
smooth	O
continuous	O
surface	O
and	O
local	O
details	O
.	O
	
subsection	O
:	O
Ablation	B-Task
Study	I-Task
	
Now	O
we	O
conduct	O
controlled	O
experiments	O
to	O
analyse	O
the	O
importance	O
of	O
each	O
component	O
in	O
our	O
model	O
.	O
	
Tab	O
.	O
	
[	O
reference	O
]	O
reports	O
the	O
performance	O
of	O
each	O
model	O
by	O
removing	O
one	O
component	O
from	O
the	O
full	B-Method
model	I-Method
.	O
	
Again	O
,	O
we	O
argue	O
that	O
these	O
commonly	O
used	O
evaluation	B-Metric
metrics	I-Metric
does	O
not	O
necessarily	O
reflect	O
the	O
quality	O
of	O
the	O
recovered	O
3D	O
geometry	O
.	O
	
For	O
example	O
,	O
the	O
model	O
with	O
no	O
edge	B-Method
length	I-Method
regularization	I-Method
achieves	O
the	O
best	O
performance	O
across	O
all	O
,	O
however	O
,	O
in	O
fact	O
produces	O
the	O
worst	O
mesh	O
(	O
Fig	O
.	O
	
[	O
reference	O
]	O
,	O
the	O
last	O
2nd	O
column	O
)	O
.	O
	
As	O
such	O
,	O
we	O
use	O
qualitative	O
result	O
Fig	O
.	O
	
[	O
reference	O
]	O
to	O
show	O
the	O
contribution	O
of	O
each	O
component	O
in	O
our	O
system	O
.	O
	
subsubsection	O
:	O
Graph	B-Method
Unpooling	I-Method
	
We	O
first	O
remove	O
the	O
graph	O
unpooling	O
layers	O
,	O
and	O
thus	O
each	O
block	O
has	O
the	O
same	O
number	O
of	O
vertices	O
as	O
in	O
the	O
last	O
block	O
of	O
our	O
full	B-Method
model	I-Method
.	O
	
It	O
is	O
observed	O
that	O
the	O
deformation	O
makes	O
mistake	O
easier	O
at	O
beginning	O
,	O
which	O
can	O
not	O
be	O
fixed	O
later	O
on	O
.	O
	
Consequently	O
,	O
there	O
are	O
some	O
obvious	O
artifacts	O
in	O
some	O
parts	O
of	O
the	O
objects	O
.	O
	
subsubsection	O
:	O
G	B-Method
-	I-Method
ResNet	I-Method
	
We	O
then	O
remove	O
the	O
shortcut	O
connections	O
in	O
G	O
-	O
ResNet	O
,	O
and	O
make	O
it	O
regular	O
GCN	B-Method
.	O
	
As	O
can	O
be	O
seen	O
from	O
Tab	O
.	O
	
[	O
reference	O
]	O
	
,	O
there	O
is	O
a	O
huge	O
performance	O
gap	O
in	O
all	O
four	O
measurement	B-Metric
metrics	I-Metric
,	O
which	O
means	O
the	O
failure	O
of	O
optimizing	B-Metric
Chamfer	I-Metric
distance	I-Metric
.	O
	
The	O
main	O
reason	O
is	O
the	O
degradation	B-Task
problem	I-Task
observed	O
in	O
the	O
very	O
deep	B-Method
2D	I-Method
convolutional	I-Method
neural	I-Method
network	I-Method
.	O
	
Such	O
problem	O
leads	O
to	O
a	O
higher	O
training	B-Metric
error	I-Metric
(	O
and	O
thus	O
higher	O
testing	B-Metric
error	I-Metric
)	O
when	O
adding	O
more	O
layers	O
to	O
a	O
suitably	O
deep	B-Method
model	I-Method
.	O
	
Essetially	O
,	O
our	O
network	O
has	O
42	O
graph	B-Method
convolutional	I-Method
layers	I-Method
.	O
	
Thus	O
,	O
this	O
phenomenon	O
has	O
also	O
been	O
observed	O
in	O
our	O
very	O
deep	B-Method
graph	I-Method
neural	I-Method
network	I-Method
experiment	O
.	O
	
subsubsection	O
:	O
Loss	O
terms	O
	
We	O
evaluate	O
the	O
function	O
of	O
each	O
additional	O
terms	O
besides	O
the	O
Chamfer	O
loss	O
.	O
	
As	O
can	O
be	O
seen	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
,	O
removing	O
normal	O
loss	O
severely	O
impairs	O
the	O
surface	O
smoothness	O
and	O
local	O
details	O
,	O
e.g.	O
seat	O
back	O
	
;	O
removing	O
Laplacian	O
term	O
causes	O
intersecting	O
geometry	O
because	O
the	O
local	O
topology	O
changes	O
,	O
e.g.	O
the	O
hand	O
held	O
of	O
the	O
chair	O
;	O
removing	O
edge	O
length	O
term	O
causes	O
flying	O
vertices	O
and	O
surfaces	O
,	O
which	O
completely	O
ruins	O
the	O
surface	O
characteristics	O
.	O
	
These	O
results	O
demonstrate	O
that	O
all	O
the	O
components	O
presented	O
in	O
this	O
work	O
contribute	O
to	O
the	O
final	O
performance	O
.	O
	
subsubsection	O
:	O
Number	O
of	O
Deformation	O
Blocks	O
	
We	O
now	O
analyze	O
the	O
effects	O
of	O
the	O
number	O
of	O
blocks	O
.	O
	
Figure	O
Fig	O
.	O
	
[	O
reference	O
]	O
(	O
left	O
)	O
shows	O
the	O
mean	B-Metric
F	I-Metric
-	I-Metric
score	I-Metric
(	O
)	O
and	O
CD	B-Metric
with	O
regard	O
to	O
the	O
number	O
of	O
blocks	O
.	O
	
The	O
results	O
indicate	O
that	O
increasing	O
the	O
number	O
of	O
blocks	O
helps	O
,	O
but	O
the	O
benefit	O
is	O
getting	O
saturated	O
with	O
more	O
blocks	O
,	O
e.g.	O
from	O
3	O
to	O
4	O
.	O
	
In	O
our	O
experiment	O
,	O
we	O
found	O
that	O
4	O
blocks	O
results	O
in	O
too	O
many	O
vertices	O
and	O
edges	O
,	O
which	O
slow	O
down	O
our	O
approach	O
dramatically	O
even	O
though	O
it	O
provides	O
better	O
accuracy	B-Metric
on	O
evaluation	B-Metric
metrics	I-Metric
.	O
	
Therefore	O
,	O
we	O
use	O
3	O
blocks	O
in	O
all	O
our	O
experiment	O
for	O
the	O
best	O
balance	O
of	O
performance	O
and	O
efficiency	O
.	O
	
Fig	O
.	O
	
[	O
reference	O
]	O
(	O
right	O
)	O
shows	O
the	O
output	O
of	O
our	O
model	O
after	O
each	O
deformation	O
block	O
.	O
	
Notice	O
how	O
mesh	O
is	O
densified	O
with	O
more	O
vertices	O
and	O
new	O
details	O
are	O
added	O
.	O
	
subsection	O
:	O
Reconstructing	B-Task
Real	I-Task
-	I-Task
World	I-Task
images	I-Task
	
Following	O
Choy	O
et	O
.	O
	
al	O
.	O
	
,	O
we	O
test	O
our	O
network	O
on	O
the	O
Online	B-Material
Products	I-Material
dataset	I-Material
and	O
Internet	B-Material
images	I-Material
for	O
qualitative	O
evaluation	O
on	O
real	O
images	O
.	O
	
We	O
use	O
the	O
model	O
trained	O
from	O
ShapeNet	B-Material
dataset	I-Material
and	O
directly	O
run	O
on	O
real	O
images	O
without	O
finetuning	O
,	O
and	O
show	O
results	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
.	O
	
As	O
can	O
be	O
seen	O
,	O
our	O
model	O
trained	O
on	O
synthetic	O
data	O
	
generalizes	O
well	O
to	O
the	O
real	O
-	O
world	O
images	O
across	O
various	O
categories	O
.	O
	
section	O
:	O
Conclusion	O
	
We	O
have	O
presented	O
an	O
approach	O
to	O
extract	O
3D	B-Task
triangular	I-Task
meshes	I-Task
from	O
singe	O
images	O
.	O
	
We	O
exploit	O
the	O
key	O
advantages	O
the	O
mesh	B-Task
presentation	I-Task
can	O
bring	O
to	O
us	O
,	O
and	O
the	O
key	O
issues	O
required	O
to	O
solve	O
for	O
success	O
.	O
	
The	O
former	O
includes	O
surface	O
normal	O
constraints	O
and	O
information	O
propagation	O
along	O
edges	O
;	O
the	O
latter	O
includes	O
perceptual	O
features	O
extracted	O
from	O
images	O
as	O
a	O
guidance	O
.	O
	
We	O
carefully	O
design	O
our	O
network	B-Method
structure	I-Method
and	O
propose	O
a	O
very	O
deep	B-Method
cascaded	I-Method
graph	I-Method
convolutional	I-Method
neural	I-Method
network	I-Method
with	O
“	O
shortcut	B-Method
”	I-Method
connections	I-Method
.	O
	
Meshes	O
are	O
progressively	O
refined	O
by	O
our	O
network	O
trained	O
end	O
-	O
to	O
-	O
end	O
with	O
the	O
chamfer	B-Method
loss	I-Method
and	O
normal	B-Method
loss	I-Method
.	O
	
Our	O
results	O
are	O
significantly	O
better	O
than	O
the	O
previous	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
using	O
other	O
shape	B-Method
representations	I-Method
such	O
as	O
3D	O
volume	O
or	O
3D	O
point	O
cloud	O
.	O
	
Thus	O
,	O
we	O
believe	O
mesh	B-Method
representation	I-Method
is	O
the	O
next	O
big	O
thing	O
in	O
this	O
direction	O
,	O
and	O
we	O
hope	O
that	O
the	O
key	O
components	O
discovered	O
in	O
our	O
work	O
can	O
support	O
follow	O
-	O
up	O
works	O
that	O
will	O
further	O
advance	O
direct	O
3D	O
mesh	O
reconstruction	B-Task
from	O
single	O
images	O
.	O
	
subsubsection	O
:	O
Future	O
work	O
	
Our	O
method	O
only	O
produces	O
meshes	O
with	O
the	O
same	O
topology	O
as	O
the	O
initial	O
mesh	O
.	O
	
In	O
the	O
future	O
,	O
we	O
will	O
extend	O
our	O
approach	O
to	O
more	O
general	O
cases	O
,	O
such	O
as	O
scene	B-Task
level	I-Task
reconstruction	I-Task
,	O
and	O
learn	O
from	O
multiple	O
images	O
for	O
multi	B-Task
-	I-Task
view	I-Task
reconstruction	I-Task
.	O
	
subsubsection	O
:	O
Acknowledgements	O
	
This	O
work	O
was	O
supported	O
by	O
two	O
projects	O
from	O
NSFC	O
(	O
#	O
61622204	O
and	O
#	O
61572134	O
)	O
,	O
two	O
projects	O
from	O
STCSM	O
(	O
#	O
16JC1420401	O
and	O
#	O
16QA1400500	O
)	O
,	O
Eastern	O
Scholar	O
(	O
TP2017006	O
)	O
,	O
and	O
The	O
Thousand	O
Talents	O
Plan	O
of	O
China	O
(	O
for	O
young	O
professionals	O
,	O
D1410009	O
)	O
.	O
	
bibliography	O
:	O
References	O
	
document	O
:	O
Curriculum	B-Method
Domain	I-Method
Adaptation	I-Method
for	O
Semantic	B-Task
Segmentation	I-Task
of	I-Task
Urban	I-Task
Scenes	I-Task
	
During	O
the	O
last	O
half	O
decade	O
,	O
convolutional	B-Method
neural	I-Method
networks	I-Method
(	O
CNNs	B-Method
)	O
have	O
triumphed	O
over	O
semantic	B-Task
segmentation	I-Task
,	O
which	O
is	O
a	O
core	O
task	O
of	O
various	O
emerging	O
industrial	B-Task
applications	I-Task
such	O
as	O
autonomous	B-Task
driving	I-Task
and	O
medical	B-Task
imaging	I-Task
.	O
	
However	O
,	O
to	O
train	O
CNNs	B-Method
requires	O
a	O
huge	O
amount	O
of	O
data	O
,	O
which	O
is	O
difficult	O
to	O
collect	O
and	O
laborious	O
to	O
annotate	O
.	O
	
Recent	O
advances	O
in	O
computer	B-Task
graphics	I-Task
make	O
it	O
possible	O
to	O
train	O
CNN	B-Method
models	O
on	O
photo	O
-	O
realistic	O
synthetic	O
data	O
with	O
computer	O
-	O
generated	O
annotations	O
.	O
	
Despite	O
this	O
,	O
the	O
domain	O
mismatch	O
between	O
the	O
real	O
images	O
and	O
the	O
synthetic	O
data	O
significantly	O
decreases	O
the	O
models	O
’	O
performance	O
.	O
	
Hence	O
we	O
propose	O
a	O
curriculum	B-Method
-	I-Method
style	I-Method
learning	I-Method
approach	I-Method
to	O
minimize	O
the	O
domain	B-Task
gap	I-Task
in	O
semantic	B-Task
segmentation	I-Task
.	O
	
The	O
curriculum	B-Method
domain	I-Method
adaptation	I-Method
solves	O
easy	O
tasks	O
first	O
in	O
order	O
to	O
infer	O
some	O
necessary	O
properties	O
about	O
the	O
target	O
domain	O
;	O
in	O
particular	O
,	O
the	O
first	O
task	O
is	O
to	O
learn	O
global	O
label	O
distributions	O
over	O
images	O
and	O
local	O
distributions	O
over	O
landmark	O
superpixels	O
.	O
	
These	O
are	O
easy	O
to	O
estimate	O
because	O
images	O
of	O
urban	O
traffic	O
scenes	O
have	O
strong	O
idiosyncrasies	O
(	O
e.g.	O
,	O
the	O
size	O
and	O
spatial	O
relations	O
of	O
buildings	O
,	O
streets	O
,	O
cars	O
,	O
etc	O
.	O
)	O
.	O
	
We	O
then	O
train	O
the	O
segmentation	B-Method
network	I-Method
in	O
such	O
a	O
way	O
that	O
the	O
network	O
predictions	O
in	O
the	O
target	O
domain	O
follow	O
those	O
inferred	O
properties	O
.	O
	
In	O
experiments	O
,	O
our	O
method	O
significantly	O
outperforms	O
the	O
baselines	O
as	O
well	O
as	O
the	O
only	O
known	O
existing	O
approach	O
to	O
the	O
same	O
problem	O
.	O
	
1	O
]	O
Yang	O
	
Zhang	O
2	O
]	O
Philip	O
David	O
1	O
]	O
Boqing	O
Gong	O
[	O
1	O
]	O
Center	O
for	O
Research	O
in	O
Computer	B-Task
Vision	I-Task
,	O
	
University	O
of	O
Central	O
Florida	O
[	O
2	O
]	O
Computational	O
and	O
Information	O
Sciences	O
Directorate	O
,	O
U.S.	O
Army	O
Research	O
Laboratory	O
yangzhang@knights.ucf.edu	O
,	O
philip.j.david4.civ@mail.mil	O
,	O
	
bgong@crcv.ucf.edu	O
	
section	O
:	O
Introduction	O
	
This	O
paper	O
is	O
concerned	O
with	O
domain	B-Task
adaptation	I-Task
for	O
semantic	B-Task
image	I-Task
segmentation	I-Task
of	I-Task
urban	I-Task
scenes	I-Task
,	O
i.e.	O
,	O
assigning	O
a	O
category	O
label	O
to	O
every	O
pixel	O
of	O
an	O
image	O
or	O
video	O
frame	O
.	O
	
Our	O
interest	O
in	O
this	O
problem	O
is	O
partially	O
due	O
to	O
the	O
exciting	O
vision	B-Task
of	I-Task
autonomous	I-Task
driving	I-Task
,	O
where	O
understanding	B-Task
complex	I-Task
inner	I-Task
-	I-Task
city	I-Task
traffic	I-Task
scenes	I-Task
is	O
an	O
essential	O
module	O
and	O
semantic	B-Task
segmentation	I-Task
is	O
one	O
of	O
its	O
key	O
constituents	O
.	O
	
Machine	B-Method
learning	I-Method
methods	I-Method
for	O
automatic	B-Task
semantic	I-Task
segmentation	I-Task
require	O
massive	O
amounts	O
of	O
high	O
-	O
quality	O
annotated	O
imagery	O
in	O
order	O
to	O
produce	O
effective	O
classifiers	B-Method
that	O
generalize	O
well	O
to	O
novel	O
scenes	O
.	O
	
However	O
,	O
annotating	O
training	O
imagery	O
for	O
semantic	B-Task
segmentation	I-Task
is	O
a	O
very	O
cumbersome	O
task	O
for	O
humans	O
.	O
	
Cordts	O
et	O
al	O
.	O
report	O
that	O
the	O
annotation	B-Task
and	O
quality	B-Task
control	I-Task
take	O
more	O
than	O
1.5	O
hours	O
on	O
a	O
single	O
image	O
of	O
the	O
Cityscapes	B-Material
dataset	I-Material
.	O
	
Besides	O
,	O
it	O
is	O
very	O
difficult	O
and	O
time	O
-	O
consuming	O
to	O
collect	O
imagery	O
that	O
depicts	O
the	O
large	O
number	O
of	O
variabilities	O
possible	O
of	O
urban	O
scenes	O
in	O
different	O
countries	O
,	O
seasons	O
,	O
and	O
lighting	O
conditions	O
,	O
etc	O
.	O
	
To	O
overcome	O
both	O
shortcomings	O
,	O
simulated	O
urban	O
environments	O
may	O
be	O
used	O
to	O
automatically	O
generate	O
large	O
amounts	O
of	O
annotated	O
training	O
imagery	O
.	O
	
This	O
,	O
however	O
,	O
introduces	O
a	O
new	O
problem	O
,	O
that	O
of	O
domain	O
mismatch	O
between	O
the	O
source	O
(	O
simulated	O
)	O
domain	O
and	O
the	O
target	O
(	O
real	O
)	O
domain	O
.	O
	
Figure	O
[	O
reference	O
]	O
illustrates	O
some	O
examples	O
drawn	O
from	O
the	O
synthetic	O
SYNTHIA	B-Material
dataset	O
and	O
the	O
real	O
Cityscapes	B-Material
dataset	O
.	O
	
It	O
is	O
readily	O
apparent	O
that	O
there	O
are	O
significant	O
visual	O
differences	O
between	O
the	O
two	O
datasets	O
.	O
	
Domain	B-Method
adaptation	I-Method
techniques	I-Method
may	O
be	O
used	O
by	O
machine	B-Method
learning	I-Method
methods	I-Method
to	O
bridge	O
this	O
gap	O
between	O
the	O
two	O
domains	O
.	O
	
In	O
computer	B-Task
vision	I-Task
,	O
learning	B-Task
domain	I-Task
-	I-Task
invariant	I-Task
features	I-Task
has	O
been	O
a	O
prevalent	O
and	O
successful	O
strategy	O
to	O
tackle	O
the	O
discrepancy	O
between	O
two	O
domains	O
,	O
mainly	O
for	O
classification	B-Task
and	I-Task
regression	I-Task
problems	I-Task
.	O
	
The	O
core	O
idea	O
is	O
to	O
infer	O
a	O
new	O
feature	O
space	O
such	O
that	O
the	O
marginal	O
distributions	O
of	O
the	O
source	O
domain	O
(	O
S	O
)	O
and	O
the	O
target	O
domain	O
(	O
T	O
)	O
are	O
about	O
the	O
same	O
,	O
i.e.	O
,	O
.	O
	
Furthermore	O
,	O
the	O
prediction	O
function	O
from	O
that	O
space	O
is	O
assumed	O
to	O
be	O
the	O
same	O
across	O
the	O
domains	O
so	O
that	O
one	O
can	O
leverage	O
the	O
rich	O
labeled	O
data	O
in	O
the	O
source	O
domain	O
to	O
train	O
classifiers	B-Method
that	O
generalize	O
well	O
to	O
the	O
target	O
.	O
	
It	O
is	O
hard	O
to	O
verify	O
the	O
assumption	O
,	O
but	O
the	O
work	O
along	O
this	O
line	O
is	O
rich	O
and	O
has	O
led	O
to	O
impressive	O
practical	O
results	O
regardless	O
,	O
such	O
as	O
the	O
algorithms	O
using	O
linear	B-Method
transformation	I-Method
,	O
kernel	B-Method
methods	I-Method
,	O
and	O
the	O
recent	O
deep	B-Method
learning	I-Method
methods	I-Method
that	O
directly	O
extract	O
domain	O
-	O
invariant	O
features	O
from	O
raw	O
input	O
images	O
.	O
	
In	O
contrast	O
to	O
prior	O
arts	O
,	O
the	O
semantic	B-Task
segmentation	I-Task
we	O
study	O
in	O
this	O
paper	O
is	O
a	O
highly	O
structured	B-Task
prediction	I-Task
problem	I-Task
,	O
for	O
which	O
domain	B-Task
adaptation	I-Task
is	O
only	O
sparsely	O
explored	O
in	O
the	O
literature	O
.	O
	
Under	O
structured	B-Task
prediction	I-Task
,	O
can	O
we	O
still	O
achieve	O
good	O
domain	B-Task
adaptation	I-Task
results	O
by	O
following	O
the	O
above	O
principles	O
?	O
	
Our	O
intuition	O
and	O
experimental	O
studies	O
(	O
cf	O
.	O
	
Section	O
[	O
reference	O
]	O
)	O
tell	O
us	O
no	O
.	O
	
Learning	O
a	O
decision	B-Method
function	I-Method
for	O
structured	B-Task
prediction	I-Task
is	O
more	O
involved	O
than	O
classification	B-Task
because	O
it	O
has	O
to	O
resolve	O
the	O
predictions	O
in	O
an	O
exponentially	O
large	O
label	O
space	O
.	O
	
As	O
a	O
result	O
,	O
the	O
assumption	O
that	O
the	O
source	O
and	O
target	O
domains	O
share	O
the	O
same	O
prediction	O
function	O
becomes	O
less	O
likely	O
to	O
hold	O
.	O
	
Besides	O
,	O
some	O
discriminative	O
cues	O
in	O
the	O
data	O
would	O
be	O
suppressed	O
if	O
one	O
matches	O
the	O
feature	B-Method
representations	I-Method
of	O
the	O
two	O
domains	O
without	O
taking	O
careful	O
account	O
of	O
the	O
structured	O
labels	O
.	O
	
Finally	O
,	O
data	O
instances	O
are	O
the	O
proxy	O
to	O
measure	O
the	O
domain	O
difference	O
.	O
	
However	O
,	O
it	O
is	O
not	O
immediately	O
clear	O
what	O
comprises	O
the	O
instances	O
in	O
semantic	B-Task
segmentation	I-Task
,	O
especially	O
given	O
that	O
the	O
top	O
-	O
performing	O
segmentation	B-Method
methods	I-Method
are	O
built	O
upon	O
deep	B-Method
neural	I-Method
networks	I-Method
.	O
	
Hoffman	O
et	O
al	O
.	O
take	O
each	O
spatial	O
unit	O
in	O
the	O
fully	B-Method
convolutional	I-Method
network	I-Method
(	O
FCN	B-Method
)	O
as	O
an	O
instance	O
.	O
	
We	O
contend	O
that	O
such	O
instances	O
are	O
actually	O
non	O
-	O
i.i.d	O
.	O
in	O
either	O
individual	O
domain	O
,	O
as	O
their	O
receptive	O
fields	O
overlap	O
with	O
each	O
other	O
.	O
	
How	O
can	O
we	O
avoid	O
the	O
assumption	O
that	O
the	O
source	O
and	O
target	O
domains	O
share	O
the	O
same	O
prediction	O
function	O
in	O
a	O
transformed	O
domain	O
-	O
invariant	O
feature	O
space	O
?	O
	
Our	O
proposed	O
solution	O
draws	O
on	O
two	O
key	O
observations	O
.	O
	
One	O
is	O
that	O
the	O
urban	O
traffic	O
scene	O
images	O
have	O
strong	O
idiosyncrasies	O
(	O
e.g.	O
,	O
the	O
size	O
and	O
spatial	O
relations	O
of	O
buildings	O
,	O
streets	O
,	O
cars	O
,	O
etc	O
.	O
)	O
.	O
	
Therefore	O
,	O
some	O
tasks	O
are	O
“	O
easy	O
”	O
and	O
,	O
more	O
importantly	O
,	O
suffer	O
less	O
because	O
of	O
the	O
domain	O
discrepancy	O
.	O
	
Second	O
,	O
the	O
structured	O
output	O
in	O
semantic	B-Task
segmentation	I-Task
enables	O
convenient	O
posterior	B-Method
regularization	I-Method
,	O
as	O
opposed	O
to	O
the	O
popular	O
(	O
e.g.	O
,	O
)	O
regularization	O
over	O
model	O
parameters	O
.	O
	
Accordingly	O
,	O
we	O
propose	O
a	O
curriculum	B-Method
-	I-Method
style	I-Method
domain	I-Method
adaptation	I-Method
approach	I-Method
.	O
	
Recall	O
that	O
,	O
in	O
domain	B-Task
adaptation	I-Task
,	O
only	O
the	O
source	O
domain	O
supplies	O
many	O
labeled	O
data	O
while	O
there	O
are	O
no	O
or	O
only	O
scarce	O
labels	O
from	O
the	O
target	O
.	O
	
The	O
curriculum	B-Task
domain	I-Task
adaptation	I-Task
begins	O
with	O
the	O
easy	B-Task
tasks	I-Task
,	O
in	O
order	O
to	O
gain	O
some	O
high	O
-	O
level	O
properties	O
about	O
the	O
unknown	O
pixel	O
-	O
level	O
labels	O
for	O
each	O
target	O
image	O
.	O
	
It	O
then	O
learns	O
a	O
semantic	B-Method
segmentation	I-Method
network	I-Method
	
—	O
the	O
hard	B-Task
task	I-Task
,	O
whose	O
predictions	O
over	O
the	O
target	O
images	O
are	O
forced	O
to	O
follow	O
those	O
necessary	O
properties	O
as	O
much	O
as	O
possible	O
.	O
	
To	O
develop	O
the	O
easy	O
tasks	O
in	O
the	O
curriculum	O
,	O
we	O
consider	O
label	O
distributions	O
over	O
both	O
holistic	O
images	O
and	O
some	O
landmark	O
superpixels	O
of	O
the	O
target	O
domain	O
.	O
	
Take	O
the	O
former	O
for	O
instance	O
.	O
	
The	O
label	O
distribution	O
of	O
an	O
image	O
indicates	O
the	O
percentage	O
of	O
pixels	O
that	O
belong	O
to	O
each	O
category	O
,	O
respectively	O
.	O
	
We	O
argue	O
that	O
such	O
tasks	O
are	O
easier	O
,	O
despite	O
the	O
domain	O
mismatch	O
,	O
than	O
assigning	O
pixel	O
-	O
wise	O
labels	O
.	O
	
Indeed	O
,	O
we	O
may	O
directly	O
estimate	O
the	O
label	O
distributions	O
without	O
inferring	O
the	O
pixel	O
-	O
wise	O
labels	O
.	O
	
Moreover	O
,	O
the	O
relative	O
sizes	O
of	O
road	O
,	O
vehicle	O
,	O
pedestrian	O
,	O
etc	O
.	O
constrain	O
the	O
shape	O
of	O
the	O
distributions	O
,	O
effectively	O
reducing	O
the	O
search	O
space	O
.	O
	
Finally	O
,	O
models	O
to	O
estimate	O
the	O
label	B-Task
distributions	I-Task
over	O
superpixels	O
may	O
benefit	O
from	O
the	O
urban	O
scenes	O
’	O
canonical	O
layout	O
that	O
transcends	O
domains	O
,	O
e.g.	O
,	O
buildings	O
stand	O
beside	O
streets	O
.	O
	
Why	O
and	O
when	O
are	O
the	O
seemingly	O
simple	O
label	B-Method
distributions	I-Method
useful	O
for	O
the	O
domain	B-Task
adaptation	I-Task
of	I-Task
semantic	I-Task
segmentation	I-Task
?	O
	
In	O
our	O
experiments	O
,	O
we	O
find	O
that	O
the	O
segmentation	B-Method
networks	I-Method
trained	O
on	O
the	O
source	O
domain	O
perform	O
poorly	O
on	O
many	O
target	O
images	O
,	O
giving	O
rise	O
to	O
disproportionate	O
label	O
assignments	O
(	O
e.g.	O
,	O
many	O
more	O
pixels	O
are	O
classified	O
to	O
sidewalks	O
than	O
to	O
streets	O
)	O
.	O
	
To	O
rectify	O
this	O
,	O
the	O
image	O
-	O
level	O
label	O
distribution	O
informs	O
the	O
segmentation	B-Method
network	I-Method
how	O
to	O
update	O
the	O
predictions	O
while	O
the	O
label	O
distributions	O
of	O
the	O
landmark	O
superpixels	O
tell	O
the	O
network	O
where	O
to	O
update	O
.	O
	
Jointly	O
,	O
they	O
guide	O
the	O
adaptation	O
of	O
the	O
networks	O
to	O
the	O
target	O
domain	O
to	O
,	O
at	O
least	O
,	O
generate	O
proportional	O
label	O
predictions	O
.	O
	
Note	O
that	O
additional	O
“	O
easy	O
tasks	O
”	O
can	O
be	O
conveniently	O
incorporated	O
into	O
our	O
framework	O
in	O
the	O
future	O
.	O
	
Our	O
main	O
contribution	O
is	O
on	O
the	O
proposed	O
curriculum	B-Method
-	I-Method
style	I-Method
domain	I-Method
adaptation	I-Method
for	O
the	O
semantic	B-Task
segmentation	I-Task
of	I-Task
urban	I-Task
scenes	I-Task
.	O
	
We	O
select	O
into	O
the	O
curriculum	O
the	O
easy	O
and	O
useful	O
tasks	O
of	O
inferring	B-Task
label	I-Task
distributions	I-Task
for	O
the	O
target	O
images	O
and	O
landmark	O
superpixels	O
,	O
in	O
order	O
to	O
gain	O
some	O
necessary	O
properties	O
about	O
the	O
target	O
domain	O
.	O
	
Built	O
upon	O
these	O
,	O
we	O
learn	O
a	O
pixel	B-Method
-	I-Method
wise	I-Method
discriminative	I-Method
segmentation	I-Method
network	I-Method
from	O
the	O
labeled	O
source	O
data	O
and	O
,	O
meanwhile	O
,	O
conduct	O
a	O
“	O
sanity	O
check	O
”	O
to	O
ensure	O
the	O
network	O
behavior	O
is	O
consistent	O
with	O
the	O
previously	O
learned	O
knowledge	O
about	O
the	O
target	O
domain	O
.	O
	
Our	O
approach	O
effectively	O
eludes	O
the	O
assumption	O
about	O
the	O
existence	O
of	O
a	O
common	O
prediction	O
function	O
for	O
both	O
domains	O
in	O
a	O
transformed	O
feature	O
space	O
.	O
	
It	O
readily	O
applies	O
to	O
different	O
segmentation	B-Method
networks	I-Method
,	O
as	O
it	O
does	O
not	O
change	O
the	O
network	B-Method
architecture	I-Method
or	O
tax	O
any	O
intermediate	O
layers	O
.	O
	
section	O
:	O
Related	O
work	O
	
We	O
discuss	O
some	O
related	O
work	O
on	O
domain	B-Task
adaptation	I-Task
and	O
semantic	B-Task
segmentation	I-Task
,	O
with	O
special	O
focus	O
on	O
that	O
transferring	B-Task
knowledge	I-Task
from	O
virtual	O
images	O
to	O
real	O
photos	O
.	O
	
paragraph	O
:	O
Domain	B-Method
adaptation	I-Method
.	O
	
Conventional	O
machine	B-Method
learning	I-Method
algorithms	I-Method
rely	O
on	O
the	O
assumption	O
that	O
the	O
training	O
and	O
test	O
data	O
are	O
drawn	O
i.i.d	O
.	O
	
from	O
the	O
same	O
underlying	O
distribution	O
.	O
	
However	O
,	O
it	O
is	O
often	O
the	O
case	O
that	O
there	O
exists	O
some	O
discrepancy	O
from	O
the	O
training	O
to	O
the	O
test	O
stage	O
.	O
	
Domain	B-Method
adaptation	I-Method
aims	O
to	O
rectify	O
this	O
mismatch	O
and	O
tune	O
the	O
models	O
toward	O
better	O
generalization	B-Task
at	O
testing	O
.	O
	
The	O
existing	O
work	O
on	O
domain	B-Task
adaptation	I-Task
mostly	O
focuses	O
on	O
classification	B-Task
and	I-Task
regression	I-Task
problems	I-Task
,	O
e.g.	O
,	O
learning	O
from	O
online	O
commercial	O
images	O
to	O
classify	O
real	B-Task
-	I-Task
world	I-Task
objects	I-Task
,	O
and	O
,	O
more	O
recently	O
,	O
aims	O
to	O
improve	O
the	O
adaptability	O
of	O
deep	B-Method
neural	I-Method
networks	I-Method
.	O
	
Among	O
them	O
,	O
the	O
most	O
relevant	O
work	O
to	O
ours	O
is	O
that	O
exploring	O
simulated	O
data	O
.	O
	
Sun	O
and	O
Saenko	O
train	O
generic	B-Method
object	I-Method
detectors	I-Method
from	O
the	O
synthetic	O
images	O
,	O
while	O
Vazquez	O
et	O
al	O
.	O
	
use	O
the	O
virtual	O
images	O
to	O
improve	O
pedestrian	B-Task
detections	I-Task
in	O
real	O
environment	O
.	O
	
The	O
other	O
way	O
around	O
,	O
i.e.	O
,	O
how	O
to	O
improve	O
the	O
quality	O
of	O
the	O
simulated	O
images	O
using	O
the	O
real	O
ones	O
,	O
is	O
studied	O
in	O
.	O
	
paragraph	O
:	O
Semantic	B-Task
segmentation	I-Task
.	O
	
Semantic	B-Task
segmentation	I-Task
is	O
the	O
task	O
of	O
assigning	O
an	O
object	O
label	O
to	O
each	O
pixel	O
of	O
an	O
image	O
.	O
	
Traditional	O
methods	O
rely	O
on	O
local	O
image	O
features	O
manually	O
designed	O
by	O
domain	O
experts	O
.	O
	
After	O
the	O
pioneering	O
work	O
that	O
introduced	O
the	O
convolutional	B-Method
neural	I-Method
network	I-Method
(	O
CNN	B-Method
)	O
to	O
semantic	B-Task
segmentation	I-Task
,	O
most	O
recent	O
top	O
-	O
performing	O
methods	O
are	O
built	O
on	O
CNNs	B-Method
.	O
	
An	O
enormous	O
amount	O
of	O
labor	O
-	O
intensive	O
work	O
is	O
required	O
to	O
annotate	O
the	O
many	O
images	O
that	O
are	O
needed	O
to	O
obtain	O
accurate	O
segmentation	B-Method
models	I-Method
.	O
	
The	O
PASCAL	B-Material
VOC2012	I-Material
Challenge	I-Material
contains	O
nearly	O
10	O
,	O
000	O
annotated	O
images	O
for	O
the	O
segmentation	B-Task
competition	I-Task
,	O
and	O
the	O
MS	B-Material
COCO	I-Material
Challenge	I-Material
includes	O
over	O
200	O
,	O
000	O
annotated	O
images	O
.	O
	
According	O
to	O
,	O
it	O
took	O
about	O
60	O
minutes	O
to	O
manually	O
segment	O
each	O
image	O
in	O
and	O
about	O
90	O
minutes	O
for	O
each	O
in	O
.	O
	
A	O
plausible	O
approach	O
to	O
reducing	O
the	O
human	B-Metric
workload	I-Metric
is	O
to	O
utilize	O
weakly	O
supervised	O
information	O
such	O
as	O
image	O
labels	O
and	O
bounding	O
boxes	O
.	O
	
We	O
instead	O
explore	O
the	O
use	O
of	O
almost	O
effortlessly	O
labeled	O
virtual	O
images	O
for	O
training	O
high	B-Task
-	I-Task
quality	I-Task
segmentation	I-Task
networks	I-Task
.	O
	
In	O
,	O
annotating	O
a	O
synthetic	O
image	O
took	O
only	O
7	O
seconds	O
on	O
average	O
through	O
a	O
computer	B-Method
game	I-Method
.	O
	
For	O
the	O
urban	O
scenes	O
,	O
we	O
use	O
the	O
SYNTHIA	B-Material
dataset	O
which	O
contains	O
images	O
of	O
a	O
virtual	O
city	O
.	O
	
paragraph	O
:	O
Domain	B-Task
adaptation	I-Task
for	O
semantic	B-Task
segmentation	I-Task
.	O
	
Upon	O
observing	O
the	O
obvious	O
mismatch	O
between	O
virtual	O
and	O
real	O
data	O
,	O
we	O
expect	O
domain	B-Method
adaptation	I-Method
to	O
enhance	O
the	O
segmentation	B-Task
performance	O
on	O
real	O
images	O
by	O
networks	O
trained	O
on	O
virtual	O
ones	O
.	O
	
To	O
the	O
best	O
of	O
our	O
knowledge	O
,	O
the	O
only	O
attempt	O
to	O
algorithmically	O
address	O
this	O
problem	O
is	O
.	O
	
While	O
it	O
regularizes	O
the	O
intermediate	O
layers	O
and	O
constrains	O
the	O
output	O
of	O
the	O
network	O
,	O
we	O
propose	O
a	O
different	O
curriculum	B-Method
domain	I-Method
adaptation	I-Method
strategy	I-Method
.	O
	
We	O
solve	O
the	O
easy	B-Task
task	I-Task
first	O
and	O
then	O
use	O
the	O
learned	O
knowledge	O
about	O
the	O
target	O
domain	O
to	O
regularize	O
the	O
network	O
predictions	O
.	O
	
section	O
:	O
Approach	O
	
In	O
this	O
section	O
,	O
we	O
present	O
the	O
details	O
of	O
the	O
proposed	O
curriculum	B-Method
domain	I-Method
adaptation	I-Method
for	O
semantic	B-Task
segmentation	I-Task
of	I-Task
urban	I-Task
scene	I-Task
images	I-Task
.	O
	
Unlike	O
previous	O
work	O
that	O
aligns	O
the	O
domains	O
via	O
an	O
intermediate	O
feature	O
space	O
and	O
thereby	O
implicitly	O
assumes	O
the	O
existence	O
of	O
the	O
same	O
decision	O
function	O
for	O
the	O
two	O
domains	O
,	O
it	O
is	O
our	O
intuition	O
that	O
,	O
for	O
structured	B-Task
prediction	I-Task
(	O
i.e.	O
,	O
semantic	B-Task
segmentation	I-Task
here	O
)	O
,	O
the	O
cross	B-Method
-	I-Method
domain	I-Method
generalization	I-Method
of	I-Method
machine	I-Method
learning	I-Method
models	I-Method
can	O
be	O
more	O
efficiently	O
improved	O
if	O
we	O
avoid	O
this	O
assumption	O
and	O
instead	O
train	O
them	O
subject	O
to	O
necessary	O
properties	O
they	O
should	O
retain	O
in	O
the	O
target	O
domain	O
.	O
	
paragraph	O
:	O
Preliminaries	O
.	O
	
In	O
particular	O
,	O
the	O
properties	O
are	O
about	O
the	O
pixel	O
-	O
wise	O
category	O
labels	O
of	O
an	O
arbitrary	O
image	O
from	O
the	O
target	O
domain	O
,	O
where	O
and	O
are	O
the	O
width	O
and	O
height	O
of	O
the	O
image	O
,	O
respectively	O
,	O
and	O
is	O
the	O
number	O
of	O
categories	O
.	O
	
We	O
use	O
one	B-Method
-	I-Method
hot	I-Method
vector	I-Method
encoding	I-Method
for	O
the	O
groundtruth	O
labels	O
,	O
i.e.	O
,	O
takes	O
the	O
value	O
of	O
0	O
or	O
1	O
and	O
the	O
latter	O
means	O
that	O
the	O
-	O
th	O
label	O
is	O
assigned	O
by	O
a	O
human	O
annotator	O
to	O
the	O
pixel	O
at	O
.	O
	
Correspondingly	O
,	O
the	O
prediction	B-Task
by	O
a	O
segmentation	B-Method
network	I-Method
is	O
realized	O
by	O
a	O
softmax	B-Method
function	I-Method
per	O
pixel	O
.	O
	
We	O
express	O
each	O
target	O
property	O
in	O
the	O
form	O
of	O
a	O
distribution	O
over	O
the	O
categories	O
,	O
where	O
represents	O
the	O
occupancy	O
proportion	O
of	O
the	O
category	O
over	O
the	O
-	O
th	O
target	O
image	O
or	O
a	O
superpixel	O
of	O
the	O
image	O
.	O
	
Therefore	O
,	O
one	O
can	O
immediately	O
calculate	O
the	O
distribution	O
given	O
the	O
human	O
annotations	O
to	O
the	O
image	O
.	O
	
For	O
instance	O
,	O
the	O
image	O
level	O
label	O
distribution	O
is	O
expressed	O
by	O
Similarly	O
,	O
we	O
can	O
compute	O
the	O
target	O
property	O
/	O
distribution	O
from	O
the	O
network	B-Method
predictions	I-Method
and	O
denote	O
it	O
by	O
.	O
	
subsection	O
:	O
Domain	B-Task
adaptation	I-Task
using	O
the	O
target	O
properties	O
	
Ideally	O
,	O
we	O
would	O
like	O
to	O
have	O
a	O
segmentation	B-Method
network	I-Method
to	O
imitate	O
human	O
annotators	O
on	O
the	O
target	O
domain	O
.	O
	
Therefore	O
,	O
necessarily	O
,	O
the	O
properties	O
of	O
their	O
annotation	O
results	O
should	O
be	O
the	O
same	O
too	O
.	O
	
We	O
capture	O
this	O
notion	O
by	O
minimizing	O
the	O
cross	B-Metric
entropy	I-Metric
at	O
training	B-Task
,	O
where	O
the	O
first	O
term	O
of	O
the	O
right	O
-	O
hand	O
side	O
is	O
the	O
entropy	O
and	O
the	O
second	O
is	O
the	O
KL	O
-	O
divergence	O
.	O
	
Given	O
a	O
mini	O
-	O
batch	O
consisting	O
of	O
both	O
source	O
images	O
(	O
)	O
and	O
target	O
images	O
(	O
)	O
,	O
	
the	O
overall	O
objective	B-Metric
function	I-Metric
for	O
training	O
the	O
cross	B-Method
-	I-Method
domain	I-Method
generalizing	I-Method
segmentation	I-Method
network	I-Method
is	O
,	O
where	O
is	O
the	O
pixel	B-Metric
-	I-Metric
wise	I-Metric
cross	I-Metric
-	I-Metric
entropy	I-Metric
loss	I-Metric
defined	O
over	O
the	O
sufficiently	O
labeled	O
source	O
domain	O
images	O
,	O
enforcing	O
the	O
network	O
to	O
have	O
the	O
pixel	O
level	O
discriminative	O
capabilities	O
,	O
and	O
the	O
second	O
term	O
is	O
over	O
the	O
unlabeled	O
target	O
domain	O
images	O
,	O
hinting	O
the	O
network	O
what	O
necessary	O
properties	O
its	O
predictions	O
should	O
have	O
in	O
the	O
target	O
domain	O
.	O
	
We	O
use	O
to	O
balance	O
the	O
two	O
strengths	O
in	O
training	O
and	O
superscript	O
to	O
index	O
different	O
types	O
of	O
label	O
distributions	O
.	O
	
Note	O
that	O
in	O
the	O
domain	B-Task
adaptation	I-Task
context	I-Task
,	O
we	O
actually	O
can	O
not	O
directly	O
compute	O
the	O
label	O
distribution	O
from	O
the	O
groundtruth	O
annotations	O
of	O
the	O
target	O
domain	O
.	O
	
Nonetheless	O
,	O
estimating	O
them	O
using	O
the	O
labeled	O
source	O
data	O
is	O
easier	O
than	O
assigning	O
labels	O
to	O
every	O
single	O
pixel	O
of	O
the	O
target	O
images	O
.	O
	
We	O
present	O
the	O
details	O
in	O
the	O
next	O
section	O
.	O
	
paragraph	O
:	O
Remarks	O
.	O
	
Mathematically	O
,	O
the	O
objective	B-Metric
function	I-Metric
has	O
a	O
similar	O
form	O
as	O
in	O
model	B-Task
compression	I-Task
.	O
	
We	O
thus	O
borrow	O
some	O
concepts	O
to	O
gain	O
more	O
intuitive	O
understanding	O
about	O
our	O
domain	B-Method
adaptation	I-Method
procedure	I-Method
.	O
	
The	O
“	O
student	B-Method
”	I-Method
network	I-Method
follows	O
a	O
curriculum	O
to	O
learn	O
simple	O
knowledge	O
about	O
the	O
target	O
domain	O
before	O
it	O
addresses	O
the	O
hard	O
one	O
of	O
semantically	B-Task
segmenting	I-Task
images	I-Task
.	O
	
The	O
models	O
inferring	O
the	O
target	O
properties	O
act	O
like	O
“	O
teachers	O
”	O
,	O
as	O
they	O
hint	O
what	O
label	O
distributions	O
the	O
final	O
solution	O
(	O
image	B-Task
annotation	I-Task
)	O
may	O
have	O
in	O
the	O
target	O
domain	O
at	O
the	O
image	O
and	O
superpixel	O
levels	O
.	O
	
Another	O
perspective	O
is	O
to	O
understand	O
the	O
target	O
properties	O
as	O
a	O
posterior	B-Method
regularization	I-Method
for	O
the	O
network	O
.	O
	
The	O
posterior	B-Method
regularization	I-Method
can	O
conveniently	O
encode	O
a	O
priori	O
knowledge	O
into	O
the	O
objective	O
function	O
.	O
	
Some	O
applications	O
include	O
weakly	B-Task
supervised	I-Task
segmentation	I-Task
and	I-Task
detection	I-Task
,	O
and	O
rule	B-Method
-	I-Method
regularized	I-Method
training	I-Method
of	I-Method
neural	I-Method
networks	I-Method
.	O
	
In	O
addition	O
to	O
the	O
domain	B-Task
adaptation	I-Task
setting	I-Task
and	O
novel	O
target	O
properties	O
,	O
another	O
key	O
distinction	O
of	O
our	O
work	O
is	O
that	O
we	O
decouple	O
the	O
label	O
distributions	O
from	O
the	O
network	O
predictions	O
and	O
thus	O
avoid	O
the	O
EM	B-Method
type	I-Method
of	I-Method
optimizations	I-Method
.	O
	
Our	O
approach	O
learns	O
the	O
segmentation	B-Method
network	I-Method
with	O
almost	O
effortless	O
changes	O
to	O
the	O
popular	O
deep	B-Method
learning	I-Method
tools	I-Method
.	O
	
subsection	O
:	O
Inferring	O
the	O
target	O
properties	O
	
Thus	O
far	O
we	O
have	O
presented	O
the	O
“	O
hard	O
”	O
task	O
in	O
the	O
curriculum	B-Task
domain	I-Task
adaptation	I-Task
.	O
	
In	O
this	O
section	O
,	O
we	O
describe	O
the	O
“	O
easy	O
”	O
ones	O
,	O
i.e.	O
,	O
how	O
to	O
infer	O
the	O
target	O
properties	O
without	O
accessing	O
the	O
image	O
annotations	O
of	O
the	O
target	O
domain	O
.	O
	
Our	O
contributions	O
also	O
include	O
selecting	O
the	O
particular	O
property	O
of	O
label	O
distributions	O
to	O
constitute	O
the	O
simple	O
tasks	O
.	O
	
subsubsection	O
:	O
Global	B-Task
label	I-Task
distributions	I-Task
of	I-Task
images	I-Task
	
Due	O
to	O
the	O
domain	O
disparity	O
,	O
a	O
baseline	B-Method
segmentation	I-Method
network	I-Method
trained	O
on	O
the	O
source	O
domain	O
(	O
i.e.	O
,	O
using	O
the	O
first	O
term	O
of	O
eq	O
.	O
	
(	O
[	O
reference	O
]	O
)	O
)	O
could	O
be	O
easily	O
crippled	O
given	O
the	O
target	O
images	O
.	O
	
In	O
our	O
experiments	O
,	O
we	O
find	O
that	O
our	O
baseline	O
network	O
constantly	O
mistakes	O
streets	O
for	O
sidewalks	O
and	O
/	O
or	O
cars	O
	
(	O
cf	O
.	O
	
Figure	O
[	O
reference	O
]	O
)	O
.	O
	
Consequently	O
,	O
the	O
predicted	O
labels	O
for	O
the	O
pixels	O
are	O
highly	O
disproportionate	O
.	O
	
To	O
rectify	O
this	O
,	O
we	O
employ	O
the	O
label	O
distribution	O
over	O
the	O
global	O
image	O
as	O
our	O
first	O
property	O
(	O
cf	O
.	O
eq	O
.	O
	
(	O
[	O
reference	O
]	O
)	O
)	O
.	O
	
Without	O
access	O
to	O
the	O
target	O
labels	O
,	O
we	O
have	O
to	O
train	O
machine	B-Method
learning	I-Method
models	I-Method
from	O
the	O
labeled	O
source	O
images	O
to	O
estimate	O
the	O
label	B-Task
distribution	I-Task
for	O
the	O
target	O
image	O
.	O
	
Nonetheless	O
,	O
we	O
argue	O
that	O
this	O
is	O
less	O
challenging	O
than	O
generating	O
the	O
per	B-Task
-	I-Task
pixel	I-Task
predictions	I-Task
despite	O
that	O
both	O
tasks	O
are	O
influenced	O
by	O
the	O
domain	O
mismatch	O
.	O
	
In	O
our	O
experiments	O
,	O
we	O
examine	O
different	O
approaches	O
to	O
this	O
task	O
.	O
	
We	O
extract	O
image	O
features	O
using	O
the	O
Inception	B-Method
-	I-Method
Resnet	I-Method
-	I-Method
v2	I-Method
as	O
the	O
input	O
to	O
the	O
following	O
models	O
.	O
	
Although	O
multinomial	O
logistic	B-Method
regression	I-Method
(	O
LR	B-Method
)	O
is	O
mainly	O
used	O
for	O
classification	B-Task
,	O
its	O
output	O
is	O
actually	O
a	O
valid	O
distribution	O
over	O
the	O
categories	O
.	O
	
For	O
our	O
purpose	O
,	O
we	O
thus	O
train	O
it	O
by	O
replacing	O
the	O
one	O
-	O
hot	O
vectors	O
in	O
the	O
cross	B-Metric
-	I-Metric
entropy	I-Metric
loss	I-Metric
with	O
the	O
groundtruth	O
label	O
distribution	O
,	O
which	O
is	O
calculated	O
using	O
eq	O
.	O
	
(	O
[	O
reference	O
]	O
)	O
and	O
the	O
available	O
human	O
labels	O
of	O
the	O
source	O
domain	O
.	O
	
Given	O
a	O
target	O
image	O
,	O
we	O
directly	O
take	O
the	O
LR	B-Method
’s	O
output	O
as	O
the	O
predicted	O
label	O
distribution	O
.	O
	
We	O
also	O
test	O
a	O
nonparametric	B-Method
method	I-Method
by	O
simply	O
retrieving	O
the	O
nearest	B-Method
neighbors	I-Method
(	O
NNs	B-Method
)	O
for	O
a	O
target	O
image	O
and	O
then	O
transferring	O
the	O
mean	O
of	O
the	O
NNs	O
’	O
label	O
distributions	O
to	O
the	O
target	O
image	O
.	O
	
We	O
use	O
the	O
distance	O
for	O
the	O
NN	B-Task
retrieval	I-Task
.	O
	
Finally	O
,	O
we	O
include	O
two	O
dumb	O
predictions	O
as	O
the	O
control	O
experiment	O
.	O
	
One	O
is	O
,	O
for	O
any	O
target	O
image	O
,	O
to	O
output	O
the	O
mean	O
of	O
all	O
the	O
label	B-Method
distributions	I-Method
in	O
the	O
source	O
domain	O
(	O
source	O
mean	O
)	O
,	O
and	O
the	O
other	O
is	O
to	O
output	O
a	O
uniform	O
distribution	O
.	O
	
subsubsection	O
:	O
Local	O
label	O
distributions	O
of	O
landmark	B-Method
superpixels	I-Method
	
The	O
image	O
level	O
label	O
distribution	O
globally	O
penalizes	O
potentially	O
disproportional	O
segmentation	O
output	O
on	O
the	O
target	O
domain	O
,	O
and	O
yet	O
is	O
inadequate	O
in	O
providing	O
spatial	O
constraints	O
.	O
	
In	O
this	O
section	O
,	O
we	O
consider	O
the	O
use	O
of	O
label	O
distributions	O
over	O
some	O
superpixels	O
as	O
the	O
anchors	O
to	O
drive	O
the	O
network	O
towards	O
spatially	O
desired	O
target	O
properties	O
.	O
	
Note	O
that	O
it	O
is	O
not	O
necessary	O
,	O
and	O
is	O
even	O
harmful	O
,	O
to	O
use	O
all	O
of	O
the	O
superpixels	O
in	O
a	O
target	O
image	O
to	O
regularize	O
the	O
segmentation	B-Method
network	I-Method
,	O
because	O
that	O
would	O
be	O
too	O
strong	O
a	O
force	O
and	O
may	O
overrule	O
the	O
pixel	O
-	O
wise	O
discriminativeness	O
revealed	O
by	O
the	O
labeled	O
source	O
images	O
,	O
especially	O
when	O
the	O
label	O
distributions	O
are	O
not	O
inferred	O
accurately	O
enough	O
.	O
	
In	O
order	O
to	O
have	O
the	O
dual	O
effect	O
of	O
both	O
estimating	O
the	O
label	B-Task
distributions	I-Task
of	I-Task
superpixels	I-Task
and	O
filtering	O
the	O
superpixels	B-Task
,	O
we	O
simplify	O
the	O
problem	O
and	O
employ	O
a	O
linear	B-Method
SVM	I-Method
in	O
this	O
work	O
.	O
	
In	O
particular	O
,	O
we	O
segment	O
each	O
image	O
into	O
100	O
superpixels	B-Method
using	O
linear	B-Method
spectral	I-Method
clustering	I-Method
.	O
	
For	O
the	O
superpixels	O
of	O
the	O
source	O
domain	O
,	O
we	O
are	O
able	O
to	O
assign	O
a	O
single	O
dominant	O
label	O
to	O
each	O
of	O
them	O
,	O
and	O
then	O
use	O
the	O
labels	O
and	O
the	O
corresponding	O
features	O
extracted	O
from	O
the	O
superpixels	O
to	O
train	O
a	O
multi	B-Method
-	I-Method
class	I-Method
SVM	I-Method
.	O
	
Given	O
a	O
test	O
superpixel	O
of	O
a	O
target	O
image	O
,	O
the	O
multi	B-Method
-	I-Method
class	I-Method
SVM	I-Method
returns	O
a	O
class	O
label	O
as	O
well	O
as	O
a	O
decision	O
value	O
,	O
which	O
is	O
interpreted	O
as	O
the	O
confidence	B-Metric
score	I-Metric
about	O
classifying	O
this	O
superpixel	O
.	O
	
We	O
keep	O
the	O
top	O
60	O
%	O
superpixels	O
,	O
called	O
landmark	O
superpixels	O
,	O
in	O
the	O
target	O
domain	O
and	O
calculate	O
their	O
label	O
distributions	O
as	O
the	O
second	O
type	O
of	O
“	O
easy	O
”	O
tasks	O
.	O
	
In	O
particular	O
,	O
the	O
class	O
label	O
of	O
a	O
landmark	O
superpixel	O
is	O
encoded	O
into	O
a	O
one	O
-	O
hot	O
vector	O
,	O
which	O
serves	O
as	O
a	O
valid	O
distribution	O
about	O
the	O
categories	O
in	O
the	O
landmark	O
superpixel	O
.	O
	
Albeit	O
simple	O
,	O
we	O
find	O
this	O
method	O
works	O
very	O
well	O
in	O
our	O
experiments	O
.	O
	
We	O
encode	O
both	O
visual	O
and	O
contextual	O
information	O
to	O
represent	O
a	O
superpixel	O
.	O
	
First	O
,	O
we	O
use	O
the	O
FCN	B-Method
-	I-Method
8s	I-Method
pre	O
-	O
trained	O
on	O
the	O
PASCAL	B-Material
CONTEXT	I-Material
dataset	I-Material
,	O
which	O
has	O
59	O
distinct	O
classes	O
,	O
to	O
obtain	O
59	O
detection	B-Metric
scores	I-Metric
for	O
each	O
pixel	O
.	O
	
We	O
then	O
average	O
them	O
within	O
each	O
superpixel	O
.	O
	
Finally	O
,	O
we	O
represent	O
a	O
superpixel	O
by	O
the	O
concatenation	O
of	O
the	O
59D	O
vectors	O
of	O
itself	O
,	O
its	O
left	O
and	O
right	O
superpixels	O
,	O
as	O
well	O
as	O
the	O
two	O
respectively	O
above	O
and	O
below	O
it	O
.	O
	
subsection	O
:	O
Curriculum	B-Task
domain	I-Task
adaptation	I-Task
:	O
recapitulation	O
	
We	O
recap	O
the	O
proposed	O
curriculum	B-Method
domain	I-Method
adaptation	I-Method
using	O
Figure	O
[	O
reference	O
]	O
before	O
presenting	O
the	O
experiments	O
in	O
the	O
next	O
section	O
.	O
	
Our	O
main	O
idea	O
is	O
to	O
execute	O
the	O
domain	B-Method
adaptation	I-Method
step	O
by	O
step	O
,	O
starting	O
from	O
the	O
easy	B-Task
tasks	I-Task
that	O
are	O
less	O
sensitive	O
to	O
the	O
domain	O
discrepancy	O
than	O
the	O
semantic	B-Task
segmentation	I-Task
.	O
	
We	O
choose	O
the	O
labels	O
distributions	O
over	O
global	O
images	O
and	O
local	O
landmark	O
superpixels	O
in	O
this	O
work	O
;	O
more	O
tasks	O
will	O
be	O
explored	O
in	O
the	O
future	O
.	O
	
The	O
solutions	O
to	O
them	O
provide	O
useful	O
gradients	O
originating	O
from	O
the	O
target	O
domain	O
(	O
cf	O
.	O
	
the	O
arrows	O
with	O
brown	O
color	O
in	O
Figure	O
[	O
reference	O
]	O
)	O
,	O
while	O
the	O
source	O
domain	O
feeds	O
the	O
network	O
with	O
well	O
-	O
labeled	O
images	O
and	O
segmentation	O
masks	O
(	O
cf	O
.	O
	
the	O
dark	O
blue	O
arrows	O
in	O
Figure	O
[	O
reference	O
]	O
)	O
.	O
	
section	O
:	O
Experiments	O
	
In	O
this	O
section	O
,	O
we	O
describe	O
the	O
experimental	O
setup	O
and	O
compare	O
the	O
results	O
of	O
our	O
approach	O
,	O
its	O
variations	O
,	O
and	O
some	O
existing	O
baseline	O
methods	O
.	O
	
subsection	O
:	O
Segmentation	B-Method
network	I-Method
and	O
optimization	B-Task
	
In	O
our	O
experiments	O
,	O
we	O
use	O
FCN	B-Method
-	I-Method
8s	I-Method
as	O
our	O
semantic	B-Method
segmentation	I-Method
network	I-Method
.	O
	
We	O
initialize	O
its	O
convolutional	B-Method
layers	I-Method
with	O
VGG	B-Method
-	I-Method
19	I-Method
,	O
and	O
then	O
train	O
it	O
using	O
the	O
AdaDelta	B-Method
optimizer	I-Method
with	O
default	O
parameters	O
.	O
	
Each	O
mini	O
-	O
batch	O
is	O
comprised	O
of	O
five	O
source	O
images	O
and	O
five	O
randomly	O
chosen	O
target	O
images	O
.	O
	
When	O
we	O
train	O
the	O
baseline	B-Method
network	I-Method
with	O
no	O
adaptation	B-Method
,	O
however	O
,	O
we	O
try	O
to	O
use	O
the	O
largest	O
possible	O
mini	O
-	O
batch	O
that	O
includes	O
15	O
source	O
images	O
.	O
	
The	O
network	O
is	O
implemented	O
in	O
Keras	B-Method
and	O
Theano	O
.	O
	
We	O
train	O
different	O
versions	O
of	O
the	O
network	O
on	O
a	O
single	O
Tesla	B-Method
K40	I-Method
GPU	I-Method
.	O
	
Unlike	O
the	O
existing	O
deep	B-Method
domain	I-Method
adaptation	I-Method
methods	I-Method
which	O
introduce	O
regularization	O
to	O
the	O
intermediate	O
layers	O
,	O
we	O
only	O
revise	O
the	O
loss	O
function	O
over	O
the	O
output	O
.	O
	
Hence	O
,	O
our	O
curriculum	B-Method
domain	I-Method
adaptation	I-Method
can	O
be	O
readily	O
applied	O
to	O
other	O
segmentation	B-Method
networks	I-Method
(	O
e.g.	O
,	O
)	O
.	O
	
subsection	O
:	O
Datasets	O
and	O
evaluation	O
	
We	O
use	O
the	O
publicly	O
available	O
Cityscpaes	B-Material
and	O
SYNTHIA	B-Material
datasets	I-Material
in	O
our	O
experiments	O
.	O
	
Cityscapes	B-Material
is	O
a	O
real	O
-	O
world	O
,	O
vehicle	O
-	O
egocentric	O
image	O
dataset	O
collected	O
in	O
50	O
cities	O
in	O
Germany	O
and	O
nearby	O
countries	O
.	O
	
It	O
provides	O
four	O
disjoint	O
subsets	O
:	O
2	O
,	O
993	O
training	O
images	O
,	O
503	O
validation	O
image	O
,	O
1	O
,	O
531	O
test	O
images	O
,	O
and	O
20	O
,	O
021	O
auxiliary	O
images	O
.	O
	
All	O
the	O
training	O
,	O
validation	O
,	O
and	O
test	O
images	O
are	O
accurately	O
annotated	O
with	O
per	O
pixel	O
category	O
labels	O
,	O
while	O
the	O
auxiliary	O
set	O
is	O
coarsely	O
labeled	O
.	O
	
There	O
are	O
34	O
distinct	O
categories	O
in	O
the	O
dataset	O
.	O
	
SYNTHIA	B-Material
is	O
a	O
large	O
dataset	O
of	O
synthetic	O
images	O
and	O
provides	O
a	O
particular	O
subset	O
,	O
called	O
SYNTHIA	B-Material
-	I-Material
RAND	I-Material
-	I-Material
CITYSCAPES	I-Material
,	O
to	O
pair	O
with	O
Cityscapes	B-Material
.	O
	
This	O
subset	O
contains	O
9	O
,	O
400	O
images	O
that	O
are	O
automatically	O
annotated	O
with	O
12	O
object	O
categories	O
,	O
one	O
void	O
class	O
,	O
and	O
some	O
unnamed	O
classes	O
.	O
	
Note	O
that	O
the	O
virtual	O
city	O
used	O
to	O
generate	O
the	O
synthetic	O
images	O
does	O
not	O
correspond	O
to	O
any	O
of	O
the	O
real	O
cities	O
covered	O
by	O
Cityscapes	B-Material
.	O
	
We	O
abbreviate	O
SYNTHIA	B-Material
-	I-Material
RAND	I-Material
-	I-Material
CITYSCAPES	I-Material
to	O
SYNTHIA	B-Material
hereon	O
.	O
	
paragraph	O
:	O
Domain	O
idiosyncrasies	O
.	O
	
Although	O
both	O
datasets	O
depict	O
urban	B-Material
scenes	I-Material
,	O
and	O
SYNTHIA	B-Material
is	O
created	O
to	O
be	O
as	O
photo	O
-	O
realistic	O
as	O
possible	O
,	O
they	O
are	O
mismatched	O
domains	O
in	O
several	O
ways	O
.	O
	
The	O
most	O
noticeable	O
difference	O
is	O
probably	O
the	O
coarse	O
-	O
grained	O
textures	O
in	O
SYNTHIA	B-Material
;	O
very	O
similar	O
texture	O
patterns	O
repeat	O
in	O
a	O
regular	O
manner	O
across	O
different	O
images	O
.	O
	
In	O
contrast	O
,	O
the	O
Cityscapes	B-Material
images	I-Material
are	O
captured	O
by	O
high	O
-	O
quality	O
dash	O
-	O
cameras	O
.	O
	
Another	O
major	O
distinction	O
is	O
the	O
variability	O
in	O
view	O
angles	O
.	O
	
Since	O
Cityscapes	B-Material
images	I-Material
are	O
recorded	O
by	O
the	O
dash	B-Method
cameras	I-Method
mounted	O
on	O
a	O
moving	O
car	O
,	O
they	O
are	O
viewed	O
from	O
almost	O
a	O
constant	O
angle	O
that	O
is	O
about	O
parallel	O
to	O
the	O
ground	O
.	O
	
More	O
diverse	O
view	O
angles	O
are	O
employed	O
by	O
SYNTHIA	B-Material
—	O
	
it	O
seems	O
like	O
some	O
cameras	O
are	O
placed	O
on	O
the	O
buildings	O
that	O
are	O
significantly	O
higher	O
than	O
a	O
bus	O
.	O
	
Finally	O
,	O
some	O
of	O
the	O
SYNTHIA	B-Material
images	O
are	O
severely	O
shadowed	O
by	O
extreme	O
lighting	O
conditions	O
,	O
while	O
we	O
find	O
no	O
such	O
conditions	O
in	O
the	O
Cityscapes	B-Material
images	I-Material
.	O
	
These	O
combined	O
factors	O
,	O
among	O
others	O
,	O
make	O
domain	B-Task
adaptation	I-Task
from	O
SYNTHIA	B-Material
to	O
Cityscapes	B-Material
a	O
very	O
challenging	O
problem	O
.	O
	
Figure	O
[	O
reference	O
]	O
shows	O
some	O
example	O
images	O
from	O
both	O
datasets	O
.	O
	
We	O
pair	O
each	O
Cityscpaes	B-Material
image	I-Material
with	O
its	O
nearest	O
neighbor	O
in	O
SYNTHIA	B-Material
,	O
retrieved	O
by	O
the	O
Inception	O
-	O
Resnet	O
-	O
v2	O
features	O
.	O
	
However	O
,	O
the	O
cross	O
-	O
dataset	O
nearest	O
neighbors	O
are	O
visually	O
very	O
different	O
from	O
the	O
query	B-Material
images	I-Material
,	O
verifying	O
the	O
dramatic	O
disparity	O
between	O
the	O
two	O
domains	O
.	O
	
paragraph	O
:	O
Experiment	O
setup	O
.	O
	
Since	O
our	O
ultimate	O
goal	O
is	O
to	O
solve	O
the	O
semantic	B-Task
segmentation	I-Task
problem	I-Task
for	O
real	B-Task
images	I-Task
of	I-Task
urban	I-Task
scenes	I-Task
,	O
we	O
take	O
Cityscapes	B-Material
as	O
the	O
target	O
domain	O
and	O
SYNTHIA	B-Material
as	O
the	O
source	O
domain	O
.	O
	
The	O
Cityscapes	B-Material
validation	I-Material
set	I-Material
is	O
used	O
as	O
our	O
test	O
set	O
.	O
	
We	O
split	O
500	O
images	O
out	O
of	O
the	O
Cityscpaes	B-Material
training	I-Material
set	I-Material
for	O
the	O
validation	B-Task
purpose	I-Task
(	O
e.g.	O
,	O
to	O
monitor	O
the	O
convergence	O
of	O
the	O
networks	O
)	O
.	O
	
In	O
training	O
,	O
we	O
randomly	O
sample	O
mini	O
-	O
batches	O
from	O
both	O
the	O
images	O
(	O
and	O
their	O
labels	O
)	O
of	O
SYNTHIA	B-Material
and	O
the	O
remaining	O
images	O
of	O
Cityscapes	B-Material
yet	O
with	O
no	O
labels	O
.	O
	
As	O
in	O
,	O
we	O
manually	O
find	O
16	O
common	O
classes	O
between	O
the	O
two	O
datasets	O
:	O
sky	O
,	O
building	O
,	O
road	O
,	O
sidewalk	O
,	O
fence	O
,	O
vegetation	O
,	O
pole	O
,	O
car	O
,	O
traffic	O
sign	O
,	O
person	O
,	O
bicycle	O
,	O
motorcycle	O
,	O
traffic	O
light	O
,	O
bus	O
,	O
wall	O
,	O
and	O
rider	O
.	O
	
The	O
last	O
four	O
are	O
unnamed	O
and	O
yet	O
labeled	O
in	O
SYNTHIA	B-Material
.	O
	
paragraph	O
:	O
Evaluation	O
.	O
	
We	O
use	O
the	O
evaluation	O
code	O
released	O
along	O
with	O
the	O
Cityscapes	B-Material
dataset	I-Material
to	O
evaluate	O
our	O
results	O
.	O
	
It	O
calculates	O
the	O
PASCAL	B-Task
VOC	I-Task
intersection	I-Task
-	I-Task
over	I-Task
-	I-Task
union	I-Task
,	O
i.e.	O
,	O
,	O
where	O
TP	B-Metric
,	O
FP	B-Metric
,	O
and	O
FN	B-Metric
are	O
the	O
numbers	O
of	O
true	O
positive	O
,	O
false	O
positive	O
,	O
and	O
false	O
negative	O
pixels	O
,	O
respectively	O
,	O
determined	O
over	O
the	O
whole	O
test	O
set	O
.	O
	
Since	O
we	O
have	O
to	O
resize	O
the	O
images	O
before	O
feeding	O
them	O
to	O
the	O
segmentation	B-Method
network	I-Method
,	O
we	O
resize	O
the	O
output	O
segmentation	O
mask	O
back	O
to	O
the	O
original	O
image	O
size	O
before	O
running	O
the	O
evaluation	O
against	O
the	O
groundtruth	O
annotations	O
.	O
	
subsection	O
:	O
Results	O
of	O
inferring	B-Task
global	I-Task
label	I-Task
distributions	I-Task
	
Before	O
presenting	O
the	O
final	O
semantic	B-Task
segmentation	I-Task
results	O
,	O
we	O
first	O
compare	O
the	O
different	O
approaches	O
to	O
inferring	O
the	O
global	O
label	O
distributions	O
of	O
the	O
target	O
images	O
(	O
cf	O
.	O
	
Section	O
[	O
reference	O
]	O
)	O
.	O
	
We	O
report	O
the	O
results	O
on	O
the	O
held	O
-	O
out	O
validation	O
images	O
of	O
Cityscapes	B-Material
in	O
this	O
experiment	O
,	O
and	O
then	O
select	O
the	O
best	O
method	O
for	O
the	O
remaining	O
experiments	O
.	O
	
In	O
Table	O
[	O
reference	O
]	O
,	O
we	O
compare	O
the	O
estimated	O
label	O
distributions	O
with	O
the	O
groundtruth	O
ones	O
using	O
the	O
distance	O
,	O
the	O
smaller	O
the	O
better	O
.	O
	
We	O
see	O
that	O
the	O
baseline	B-Method
network	I-Method
(	O
NoAdapt	B-Method
)	O
,	O
which	O
is	O
directly	O
learned	O
from	O
the	O
source	O
domain	O
without	O
any	O
adaptation	B-Method
methods	I-Method
,	O
outperforms	O
the	O
dumb	B-Method
uniform	I-Method
distribution	I-Method
(	O
Uniform	B-Method
)	O
and	O
yet	O
no	O
other	O
methods	O
.	O
	
This	O
confirms	O
that	O
the	O
baseline	B-Method
network	I-Method
gives	O
rise	O
to	O
severely	O
disproportionate	O
predictions	O
over	O
the	O
target	O
domain	O
.	O
	
Another	O
dumb	B-Method
prediction	I-Method
(	O
Src	B-Method
mean	I-Method
)	O
,	O
i.e.	O
,	O
using	O
the	O
mean	O
of	O
all	O
label	B-Method
distributions	I-Method
over	O
the	O
source	O
domain	O
as	O
the	O
prediction	O
for	O
the	O
target	O
images	O
,	O
however	O
,	O
performs	O
reasonably	O
well	O
.	O
	
To	O
some	O
extent	O
,	O
this	O
indicates	O
the	O
value	O
of	O
the	O
simulated	O
source	O
domain	O
for	O
the	O
semantic	B-Task
segmentation	I-Task
task	I-Task
of	I-Task
urban	I-Task
scenes	I-Task
.	O
	
Finally	O
,	O
the	O
nearest	B-Method
neighbors	I-Method
(	I-Method
NN	I-Method
)	I-Method
based	I-Method
method	I-Method
and	O
the	O
multinomial	O
logistic	B-Method
regression	I-Method
(	O
LR	B-Method
)	O
(	O
cf	O
.	O
	
Section	O
[	O
reference	O
]	O
)	O
perform	O
the	O
best	O
.	O
	
We	O
use	O
the	O
output	O
of	O
LR	B-Method
on	O
the	O
target	O
domain	O
in	O
our	O
remaining	O
experiments	O
.	O
	
subsection	O
:	O
Comparison	O
results	O
	
bike	O
fence	O
wall	O
t	O
-	O
sign	O
pole	O
mbike	O
t	O
-	O
light	O
sky	O
bus	O
rider	O
veg	O
bldg	O
car	O
person	O
sidewalk	O
road	O
	
We	O
report	O
the	O
final	O
semantic	B-Task
segmentation	I-Task
results	O
on	O
the	O
test	O
data	O
of	O
the	O
target	O
domain	O
in	O
this	O
section	O
.	O
	
We	O
compare	O
our	O
approach	O
to	O
the	O
following	O
competing	O
methods	O
.	O
	
We	O
directly	O
train	O
the	O
FCN	B-Method
-	I-Method
8s	I-Method
model	O
on	O
SYNTHIA	B-Material
without	O
applying	O
any	O
domain	B-Method
adaptation	I-Method
methods	I-Method
.	O
	
This	O
is	O
the	O
most	O
basic	O
baseline	O
for	O
our	O
experiments	O
.	O
	
Recall	O
that	O
we	O
have	O
trained	O
a	O
multi	B-Method
-	I-Method
class	I-Method
SVM	I-Method
using	O
the	O
dominant	O
labels	O
of	O
the	O
superpixels	O
in	O
the	O
source	O
domain	O
.	O
	
We	O
then	O
use	O
them	O
to	O
classify	O
the	O
target	O
superpixels	O
.	O
	
Since	O
we	O
keep	O
the	O
top	O
60	O
%	O
most	O
confidently	O
classified	O
superpixels	O
as	O
the	O
landmarks	O
to	O
regularize	O
our	O
segmentation	B-Method
network	I-Method
during	O
training	O
(	O
cf	O
.	O
	
Section	O
[	O
reference	O
]	O
)	O
	
,	O
it	O
is	O
also	O
interesting	O
to	O
examine	O
the	O
classification	B-Task
results	O
of	O
these	O
superpixels	B-Method
.	O
	
We	O
run	O
the	O
evaluation	O
after	O
assigning	O
the	O
void	O
class	O
label	O
to	O
the	O
other	O
pixels	O
of	O
the	O
images	O
.	O
	
In	O
addition	O
to	O
the	O
IoU	B-Metric
,	O
we	O
have	O
also	O
evaluated	O
the	O
classification	B-Task
results	O
of	O
the	O
superpixels	O
by	O
accuracy	B-Metric
.	O
	
We	O
find	O
that	O
the	O
classification	B-Metric
accuracy	I-Metric
is	O
71	O
%	O
for	O
all	O
the	O
superpixels	O
of	O
the	O
target	O
domain	O
,	O
while	O
for	O
the	O
selected	O
60	O
%	O
landmark	O
superpixels	O
,	O
the	O
classification	B-Metric
accuracy	I-Metric
is	O
more	O
than	O
88	O
%	O
.	O
	
Hoffman	O
et	O
al	O
.	O
	
’s	O
work	O
is	O
the	O
only	O
existing	O
one	O
addressing	O
the	O
same	O
problem	O
as	O
ours	O
,	O
to	O
the	O
best	O
of	O
our	O
knowledge	O
.	O
	
They	O
introduce	O
a	O
pixel	B-Method
-	I-Method
level	I-Method
adversarial	I-Method
loss	I-Method
to	O
the	O
intermediate	O
layers	O
of	O
the	O
network	O
and	O
impose	O
constraints	O
to	O
the	O
network	O
output	O
.	O
	
Their	O
experimental	O
setup	O
is	O
about	O
identical	O
to	O
ours	O
except	O
that	O
they	O
do	O
not	O
specify	O
which	O
part	O
of	O
Cityscapes	B-Material
is	O
considered	O
as	O
the	O
test	O
set	O
.	O
	
Nonetheless	O
,	O
we	O
include	O
their	O
results	O
for	O
comparison	O
to	O
put	O
our	O
work	O
in	O
a	O
better	O
perspective	O
.	O
	
The	O
comparison	O
results	O
are	O
shown	O
in	O
Table	O
[	O
reference	O
]	O
.	O
	
Immediately	O
,	O
we	O
note	O
that	O
all	O
our	O
domain	B-Method
adaptation	I-Method
results	O
are	O
significantly	O
better	O
than	O
those	O
without	O
adaptation	B-Method
(	O
NoAdapt	B-Method
)	O
.	O
	
We	O
denote	O
by	O
(	O
Ours	O
(	O
I	O
)	O
)	O
	
the	O
network	O
trained	O
using	O
the	O
global	O
label	O
distributions	O
over	O
the	O
target	O
images	O
(	O
and	O
the	O
labeled	O
source	O
images	O
)	O
.	O
	
Although	O
one	O
may	O
wonder	O
that	O
the	O
image	O
-	O
wise	O
label	O
distributions	O
are	O
too	O
high	O
-	O
level	O
to	O
supervise	O
the	O
pixel	B-Method
-	I-Method
wise	I-Method
discriminative	I-Method
network	I-Method
,	O
the	O
gain	O
is	O
actually	O
significant	O
.	O
	
They	O
are	O
able	O
to	O
correct	O
some	O
obvious	O
errors	O
of	O
the	O
baseline	O
network	O
,	O
such	O
as	O
the	O
disproportional	O
predictions	O
about	O
road	O
and	O
sidewalk	O
(	O
cf	O
.	O
	
the	O
results	O
of	O
Ours	O
(	O
I	O
)	O
vs.	O
NoAdapt	O
in	O
the	O
last	O
two	O
columns	O
)	O
.	O
	
It	O
is	O
interesting	O
to	O
see	O
that	O
both	O
superpixel	B-Method
classification	I-Method
-	I-Method
based	I-Method
segmentation	I-Method
results	O
(	O
SP	B-Method
and	O
SP	B-Method
Lndmk	I-Method
)	O
are	O
also	O
better	O
than	O
the	O
baseline	B-Method
network	I-Method
(	O
NoAdapt	B-Method
)	O
.	O
	
The	O
label	O
distributions	O
obtained	O
over	O
the	O
landmark	B-Method
superpixels	I-Method
boost	O
the	O
segmentation	B-Method
network	I-Method
(	O
Ours	B-Method
(	I-Method
SP	I-Method
)	I-Method
)	O
to	O
the	O
mean	B-Metric
IoU	I-Metric
of	O
28.1	O
%	O
,	O
which	O
is	O
better	O
than	O
those	O
by	O
either	O
superpixel	B-Method
classification	I-Method
or	O
the	O
baseline	B-Method
network	I-Method
individually	O
.	O
	
We	O
have	O
also	O
tried	O
to	O
use	O
the	O
label	O
distributions	O
over	O
all	O
the	O
superpixels	O
to	O
train	O
the	O
network	O
,	O
and	O
observe	O
little	O
improvement	O
over	O
NoAdapt	B-Method
.	O
	
This	O
is	O
probably	O
because	O
it	O
is	O
too	O
forceful	O
to	O
regularize	O
the	O
network	O
output	O
at	O
every	O
single	O
superpixel	O
especially	O
when	O
the	O
estimated	O
label	O
distributions	O
are	O
not	O
accurate	O
enough	O
.	O
	
The	O
superpixel	B-Method
-	I-Method
based	I-Method
methods	I-Method
,	O
including	O
Ours	B-Method
(	I-Method
SP	I-Method
)	I-Method
,	O
miss	O
small	O
objects	O
such	O
as	O
fences	O
,	O
traffic	O
lights	O
(	O
t	O
-	O
light	O
)	O
,	O
and	O
traffic	O
signs	O
(	O
t	O
-	O
sign	O
)	O
,	O
and	O
instead	O
are	O
very	O
accurate	O
for	O
categories	O
like	O
the	O
sky	O
,	O
road	O
,	O
and	O
building	O
,	O
that	O
typically	O
occupy	O
larger	O
image	O
regions	O
.	O
	
On	O
the	O
contrary	O
,	O
the	O
label	O
distributions	O
on	O
the	O
images	O
give	O
rise	O
to	O
a	O
network	O
(	O
Ours	O
(	O
I	O
)	O
)	O
that	O
performs	O
better	O
on	O
the	O
small	O
objects	O
than	O
Ours	O
(	O
SP	B-Method
)	O
.	O
	
In	O
other	O
words	O
,	O
they	O
mutually	O
complement	O
to	O
some	O
extent	O
.	O
	
Re	O
-	O
training	O
the	O
network	O
by	O
using	O
the	O
label	O
distributions	O
over	O
both	O
global	O
images	O
and	O
local	O
landmark	O
superpixels	O
(	O
Ours	O
(	O
I	O
+	O
SP	O
)	O
)	O
,	O
we	O
achieve	O
the	O
best	O
semantic	B-Task
segmentation	I-Task
results	O
on	O
the	O
target	O
domain	O
.	O
	
In	O
the	O
future	O
work	O
,	O
it	O
is	O
worth	O
exploring	O
other	O
target	O
properties	O
,	O
perhaps	O
still	O
in	O
the	O
form	O
of	O
label	O
distributions	O
,	O
that	O
handle	O
the	O
small	O
objects	O
well	O
,	O
in	O
order	O
to	O
further	O
complement	O
the	O
superpixel	B-Method
-	I-Method
level	I-Method
label	I-Method
distributions	I-Method
.	O
	
paragraph	O
:	O
Comparison	O
with	O
FCNs	B-Method
in	O
the	O
wild	O
.	O
	
Although	O
we	O
use	O
the	O
same	O
segmentation	B-Method
network	I-Method
(	O
FCN	B-Method
-	I-Method
8s	I-Method
)	O
as	O
,	O
our	O
baseline	O
results	O
(	O
NoAdapt	B-Method
)	O
are	O
better	O
than	O
those	O
reported	O
in	O
.	O
	
This	O
may	O
be	O
due	O
to	O
subtle	O
differences	O
in	O
terms	O
of	O
implementation	O
or	O
experimental	O
setup	O
.	O
	
Although	O
our	O
own	O
baseline	O
results	O
are	O
superior	O
,	O
we	O
gain	O
larger	O
improvements	O
(	O
7	O
%	O
)	O
over	O
them	O
than	O
the	O
performance	O
gain	O
of	O
(	O
3	O
%	O
)	O
over	O
the	O
seemingly	O
underperforming	O
baseline	O
network	O
there	O
.	O
	
paragraph	O
:	O
Comparison	O
with	O
learning	O
domain	O
-	O
invariant	O
features	O
.	O
	
At	O
our	O
first	O
attempt	O
to	O
solve	O
the	O
domain	B-Task
adaptation	I-Task
problem	I-Task
for	O
the	O
semantic	B-Task
segmentation	I-Task
of	I-Task
urban	I-Task
scenes	I-Task
,	O
we	O
tried	O
to	O
learn	O
domain	O
invariant	O
features	O
following	O
the	O
deep	B-Method
domain	I-Method
adaptation	I-Method
methods	I-Method
for	O
classification	B-Task
.	O
	
In	O
particular	O
,	O
we	O
impose	O
the	O
maximum	O
mean	O
discrepancy	O
over	O
the	O
layer	O
before	O
the	O
output	O
.	O
	
We	O
name	O
such	O
network	B-Method
layer	I-Method
the	O
feature	B-Method
layer	I-Method
.	O
	
Since	O
there	O
are	O
virtually	O
three	O
output	O
layers	O
in	O
FCN	B-Method
-	I-Method
8s	I-Method
,	O
we	O
experiment	O
with	O
all	O
the	O
three	O
feature	O
layers	O
correspondingly	O
.	O
	
We	O
have	O
also	O
tested	O
the	O
domain	B-Method
adaptation	I-Method
by	O
reversing	O
the	O
gradients	O
of	O
a	O
domain	B-Method
classifier	I-Method
.	O
	
However	O
,	O
none	O
of	O
these	O
efforts	O
lead	O
to	O
any	O
noticeable	O
gain	O
over	O
the	O
baseline	O
network	O
so	O
the	O
results	O
are	O
omitted	O
.	O
	
section	O
:	O
Conclusion	O
	
In	O
this	O
paper	O
,	O
we	O
address	O
domain	B-Task
adaptation	I-Task
for	O
the	O
semantic	B-Task
segmentation	I-Task
of	I-Task
urban	I-Task
scenes	I-Task
.	O
	
We	O
propose	O
a	O
curriculum	B-Method
style	I-Method
approach	I-Method
to	O
this	O
problem	O
.	O
	
We	O
learn	O
to	O
estimate	O
the	O
global	O
label	O
distributions	O
of	O
the	O
images	O
and	O
local	O
label	O
distributions	O
of	O
the	O
landmark	O
superpixels	O
of	O
the	O
target	O
domain	O
.	O
	
Such	O
tasks	O
are	O
easier	O
to	O
solve	O
than	O
the	O
pixel	B-Task
-	I-Task
wise	I-Task
label	I-Task
assignment	I-Task
.	O
	
Therefore	O
,	O
we	O
use	O
their	O
results	O
to	O
effectively	O
regularize	O
our	O
training	O
of	O
the	O
semantic	B-Method
segmentation	I-Method
network	I-Method
such	O
that	O
its	O
predictions	O
meet	O
the	O
inferred	O
label	O
distributions	O
over	O
the	O
target	O
domain	O
.	O
	
Our	O
method	O
outperforms	O
several	O
competing	O
methods	O
that	O
do	O
domain	B-Method
adaptation	I-Method
from	O
simulated	O
images	O
to	O
real	O
photos	O
of	O
urban	O
traffic	O
scenes	O
.	O
	
In	O
future	O
work	O
,	O
we	O
will	O
explore	O
more	O
target	O
properties	O
that	O
can	O
be	O
conveniently	O
inferred	O
to	O
enrich	O
our	O
curriculum	B-Method
domain	I-Method
adaptation	I-Method
framework	I-Method
.	O
	
paragraph	O
:	O
Acknowledgements	O
.	O
	
This	O
work	O
is	O
supported	O
by	O
the	O
NSF	O
award	O
IIS	O
#	O
1566511	O
,	O
a	O
gift	O
from	O
Adobe	O
Systems	O
Inc.	O
,	O
and	O
a	O
GPU	B-Method
from	O
NVIDIA	B-Method
.	O
	
We	O
thank	O
the	O
anonymous	O
reviewers	O
and	O
area	O
chairs	O
for	O
their	O
insightful	O
comments	O
.	O
	
bibliography	O
:	O
References	O
	
bike	O
fence	O
wall	O
t	O
-	O
sign	O
pole	O
mbike	O
t	O
-	O
light	O
sky	O
bus	O
rider	O
veg	O
terrain	O
train	O
bldg	O
car	O
person	O
truck	O
sidewalk	O
road	O
	
appendix	O
:	O
GTA	B-Material
Cityscapes	I-Material
	
The	O
main	O
text	O
above	O
has	O
been	O
accepted	O
to	O
IEEE	O
International	O
Conference	O
on	O
Computer	B-Task
Vision	I-Task
(	O
ICCV	B-Task
)	O
2017	O
.	O
	
After	O
the	O
paper	O
submission	O
,	O
we	O
have	O
been	O
continuously	O
working	O
on	O
the	O
project	O
and	O
have	O
got	O
more	O
results	O
.	O
	
We	O
include	O
them	O
below	O
to	O
complement	O
the	O
experiments	O
in	O
the	O
main	O
text	O
.	O
	
The	O
new	O
experiment	O
is	O
basically	O
the	O
same	O
as	O
the	O
one	O
in	O
the	O
main	O
text	O
except	O
that	O
we	O
replace	O
SYNTHIA	B-Material
with	O
the	O
GTA	B-Material
dataset	O
.	O
	
GTA	B-Material
is	O
a	O
synthetic	O
,	O
vehicle	O
-	O
egocentric	O
image	O
dataset	O
collected	O
from	O
the	O
open	O
world	O
in	O
the	O
realistically	O
rendered	O
computer	O
game	O
Grand	B-Material
Theft	I-Material
Auto	I-Material
V	I-Material
(	O
GTA	B-Material
,	O
or	O
GTA5	B-Material
)	O
.	O
	
It	O
contains	O
24	O
,	O
996	O
images	O
,	O
whose	O
semantic	O
segmentation	O
annotations	O
are	O
fully	O
compatible	O
with	O
the	O
classes	O
used	O
in	O
Cityscapes	B-Material
.	O
	
Hence	O
we	O
use	O
all	O
the	O
19	O
official	O
training	O
classes	O
in	O
our	O
experiment	O
.	O
	
The	O
results	O
are	O
shown	O
in	O
Table	O
[	O
reference	O
]	O
.	O
	
As	O
in	O
the	O
main	O
text	O
,	O
the	O
same	O
observations	O
about	O
our	O
approach	O
apply	O
here	O
.	O
	
Additionally	O
,	O
we	O
note	O
that	O
the	O
results	O
are	O
overall	O
better	O
than	O
those	O
adapting	O
from	O
SYNTHIA	B-Material
to	O
Cityscapes	B-Material
.	O
	
This	O
is	O
not	O
surprising	O
,	O
because	O
the	O
GTA	B-Material
images	O
are	O
more	O
photo	O
-	O
realistic	O
than	O
SYNTHIA	B-Material
’s	I-Material
.	O
	
BB8	B-Method
:	O
	
A	O
Scalable	O
,	O
Accurate	O
,	O
Robust	O
to	O
Partial	B-Method
Occlusion	I-Method
Method	I-Method
for	O
Predicting	B-Task
the	I-Task
3D	I-Task
Poses	I-Task
of	I-Task
Challenging	I-Task
Objects	I-Task
without	O
Using	O
Depth	O
	
section	O
:	O
Abstract	O
	
We	O
introduce	O
a	O
novel	O
method	O
for	O
3D	B-Task
object	I-Task
detection	I-Task
and	O
pose	B-Task
estimation	I-Task
from	O
color	O
images	O
only	O
.	O
	
We	O
first	O
use	O
segmentation	B-Method
to	O
detect	O
the	O
objects	B-Task
of	I-Task
interest	I-Task
in	I-Task
2D	I-Task
even	I-Task
in	O
presence	O
of	O
partial	O
occlusions	O
and	O
cluttered	O
background	O
.	O
	
By	O
contrast	O
with	O
recent	O
patch	B-Method
-	I-Method
based	I-Method
methods	I-Method
,	O
we	O
rely	O
on	O
a	O
"	O
holistic	B-Method
"	I-Method
approach	I-Method
:	O
We	O
apply	O
to	O
the	O
detected	O
objects	O
a	O
Convolutional	B-Method
Neural	I-Method
Network	I-Method
(	O
CNN	B-Method
)	O
trained	O
to	O
predict	O
their	O
3D	O
poses	O
in	O
the	O
form	O
of	O
2D	O
projections	O
of	O
the	O
corners	O
of	O
their	O
3D	O
bounding	O
boxes	O
.	O
	
This	O
,	O
however	O
,	O
is	O
not	O
sufficient	O
for	O
handling	O
objects	O
from	O
the	O
recent	O
T	B-Material
-	I-Material
LESS	I-Material
dataset	O
:	O
These	O
objects	O
exhibit	O
an	O
axis	O
of	O
rotational	O
symmetry	O
,	O
and	O
the	O
similarity	O
of	O
two	O
images	O
of	O
such	O
an	O
object	O
under	O
two	O
different	O
poses	O
makes	O
training	O
the	O
CNN	B-Method
challenging	O
.	O
	
We	O
solve	O
this	O
problem	O
by	O
restricting	O
the	O
range	O
of	O
poses	O
used	O
for	O
training	O
,	O
and	O
by	O
introducing	O
a	O
classifier	B-Method
to	O
identify	O
the	O
range	O
of	O
a	O
pose	O
at	O
run	O
-	O
time	O
before	O
estimating	O
it	O
.	O
	
We	O
also	O
use	O
an	O
optional	O
additional	O
step	O
that	O
refines	O
the	O
predicted	O
poses	O
.	O
	
We	O
improve	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
on	O
the	O
LINEMOD	B-Material
dataset	I-Material
from	O
73.7	O
%	O
[	O
2	O
]	O
to	O
89.3	O
%	O
of	O
correctly	O
registered	O
RGB	B-Material
frames	I-Material
.	O
	
We	O
are	O
also	O
the	O
first	O
to	O
report	O
results	O
on	O
the	O
Occlusion	B-Material
dataset	I-Material
[	O
1	O
]	O
using	O
color	O
images	O
only	O
.	O
	
We	O
obtain	O
54	O
%	O
of	O
frames	O
passing	O
the	O
Pose	B-Metric
6D	I-Metric
criterion	I-Metric
on	O
average	O
on	O
several	O
sequences	O
of	O
the	O
T	B-Material
-	I-Material
LESS	I-Material
dataset	O
,	O
compared	O
to	O
the	O
67	O
%	O
of	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
[	O
10	O
]	O
on	O
the	O
same	O
sequences	O
which	O
uses	O
both	O
color	O
and	O
depth	O
.	O
	
The	O
full	O
approach	O
is	O
also	O
scalable	O
,	O
as	O
a	O
single	O
network	O
can	O
be	O
trained	O
for	O
multiple	O
objects	O
simultaneously	O
.	O
	
section	O
:	O
Introduction	O
	
3D	O
pose	B-Task
estimation	I-Task
of	O
object	O
instances	O
has	O
recently	O
become	O
a	O
popular	O
problem	O
again	O
,	O
because	O
of	O
its	O
application	O
in	O
robotics	B-Task
,	O
virtual	B-Task
and	I-Task
augmented	I-Task
reality	I-Task
.	O
	
Many	O
recent	O
approaches	O
rely	O
on	O
depth	O
maps	O
,	O
sometimes	O
in	O
conjunction	O
with	O
color	O
images	O
[	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
.	O
	
However	O
,	O
it	O
is	O
not	O
always	O
possible	O
to	O
use	O
depth	O
cameras	O
,	O
as	O
they	O
fail	O
	
(	O
c	O
)	O
(	O
d	O
)	O
Figure	O
1	O
.	O
	
Zooms	O
on	O
estimated	O
poses	O
for	O
(	O
a	O
)	O
the	O
Ape	O
of	O
the	O
LINEMOD	B-Material
dataset	I-Material
[	O
reference	O
]	O
,	O
(	O
b	O
)	O
the	O
Driller	O
of	O
the	O
Occlusion	B-Material
dataset	I-Material
[	O
reference	O
]	O
,	O
(	O
c	O
)	O
and	O
(	O
d	O
)	O
three	O
objects	O
of	O
the	O
T	B-Material
-	I-Material
LESS	I-Material
[	O
reference	O
]	O
dataset	O
.	O
	
The	O
green	O
bounding	O
boxes	O
correspond	O
to	O
the	O
ground	O
truth	O
poses	O
,	O
and	O
the	O
blue	O
bounding	O
boxes	O
to	O
the	O
poses	O
estimated	O
with	O
our	O
method	O
.	O
	
The	O
two	O
boxes	O
often	O
overlap	O
almost	O
perfectly	O
,	O
showing	O
the	O
accuracy	B-Metric
of	O
our	O
estimated	O
poses	O
.	O
	
The	O
parts	O
of	O
the	O
bounding	O
boxes	O
occluded	O
by	O
the	O
object	O
were	O
removed	O
using	O
the	O
object	O
mask	O
rendered	O
from	O
our	O
estimated	O
pose	O
.	O
	
In	O
(	O
b	O
)	O
,	O
we	O
can	O
still	O
obtain	O
a	O
good	O
pose	O
despite	O
the	O
large	O
occlusion	O
by	O
the	O
bench	O
vise	O
.	O
	
In	O
(	O
c	O
)	O
and	O
(	O
d	O
)	O
,	O
we	O
also	O
obtain	O
very	O
good	O
estimates	O
despite	O
large	O
occlusions	O
,	O
the	O
similarities	O
between	O
the	O
objects	O
,	O
and	O
the	O
fact	O
that	O
the	O
symmetries	O
challenge	O
the	O
learning	B-Method
algorithms	I-Method
.	O
	
outdoor	O
or	O
on	O
specular	O
objects	O
.	O
	
In	O
addition	O
,	O
they	O
drain	O
the	O
batteries	O
of	O
mobile	O
devices	O
,	O
being	O
an	O
active	B-Method
sensor	I-Method
.	O
	
It	O
is	O
therefore	O
desirable	O
to	O
rely	O
only	O
on	O
color	O
images	O
for	O
3D	B-Task
pose	I-Task
estimation	I-Task
,	O
even	O
if	O
it	O
is	O
more	O
challenging	O
.	O
	
Recent	O
methods	O
[	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
work	O
by	O
identifying	O
the	O
'	O
object	O
coordinates	O
'	O
of	O
the	O
pixels	O
,	O
which	O
are	O
the	O
pixels	O
'	O
3D	O
coordinates	O
in	O
a	O
coordinate	O
system	O
related	O
to	O
the	O
object	O
[	O
reference	O
]	O
.	O
	
The	O
object	O
	
3D	B-Task
pose	I-Task
can	O
then	O
be	O
estimated	O
using	O
a	O
PnP	B-Method
algorithm	I-Method
from	O
these	O
2D	O
-	O
3D	O
correspondences	O
.	O
	
[	O
reference	O
]	O
obtain	O
similar	O
correspondences	O
by	O
associating	O
some	O
pixels	O
in	O
selected	O
parts	O
of	O
the	O
object	O
with	O
virtual	O
3D	O
points	O
.	O
	
However	O
,	O
obtaining	O
these	O
2D	O
-	O
3D	O
correspondences	O
from	O
local	O
patches	O
is	O
difficult	O
and	O
the	O
output	O
is	O
typically	O
very	O
noisy	O
for	O
these	O
methods	O
.	O
	
A	O
robust	B-Method
optimization	I-Method
is	O
then	O
needed	O
to	O
estimate	O
the	O
pose	O
.	O
	
In	O
this	O
paper	O
,	O
we	O
argue	O
for	O
a	O
"	O
holistic	B-Method
"	I-Method
approach	I-Method
,	O
in	O
the	O
sense	O
that	O
we	O
predict	O
the	O
pose	O
of	O
an	O
object	O
directly	O
from	O
its	O
appearance	O
,	O
instead	O
of	O
identifying	O
its	O
individual	O
surface	O
points	O
.	O
	
As	O
we	O
will	O
show	O
,	O
this	O
approach	O
provides	O
significantly	O
better	O
results	O
.	O
	
We	O
first	O
detect	O
the	O
target	O
objects	O
in	O
2D.	O
	
We	O
show	O
that	O
using	O
object	B-Method
segmentation	I-Method
performs	O
better	O
for	O
this	O
task	O
compared	O
to	O
a	O
standard	O
sliding	B-Method
window	I-Method
detector	I-Method
,	O
in	O
particular	O
in	O
presence	O
of	O
partial	O
occlusion	O
.	O
	
We	O
then	O
apply	O
a	O
CNN	B-Method
to	O
predict	O
the	O
3D	B-Task
pose	I-Task
of	I-Task
the	I-Task
detected	I-Task
objects	I-Task
.	O
	
While	O
the	O
predicted	O
3D	O
pose	O
can	O
be	O
represented	O
directly	O
by	O
a	O
translation	O
and	O
a	O
rotation	O
,	O
we	O
achieve	O
better	O
accuracy	B-Metric
by	O
using	O
a	O
representation	O
similar	O
to	O
the	O
one	O
used	O
in	O
[	O
reference	O
]	O
for	O
object	B-Task
parts	I-Task
:	O
We	O
predict	O
the	O
2D	O
projections	O
of	O
the	O
corners	O
of	O
the	O
object	O
's	O
bounding	O
box	O
,	O
and	O
compute	O
the	O
3D	O
pose	O
from	O
these	O
2D	O
-	O
3D	O
correspondences	O
with	O
a	O
PnP	B-Method
algorithm	I-Method
.	O
	
Compared	O
to	O
the	O
object	B-Method
coordinate	I-Method
approaches	I-Method
the	O
predictions	O
are	O
typically	O
outlier	O
-	O
free	O
,	O
and	O
no	O
robust	B-Method
estimation	I-Method
is	O
thus	O
needed	O
.	O
	
Compared	O
to	O
the	O
direct	B-Task
prediction	I-Task
of	I-Task
the	I-Task
pose	I-Task
,	O
this	O
also	O
avoids	O
the	O
need	O
for	O
a	O
meta	O
-	O
parameter	O
to	O
balance	O
the	O
translation	O
and	O
rotation	O
terms	O
.	O
	
Unfortunately	O
,	O
this	O
simple	O
approach	O
performs	O
badly	O
on	O
the	O
recent	O
and	O
challenging	O
T	B-Material
-	I-Material
LESS	I-Material
dataset	O
.	O
	
This	O
dataset	O
is	O
made	O
of	O
manufactured	O
objects	O
that	O
are	O
not	O
only	O
similar	O
to	O
each	O
other	O
,	O
but	O
also	O
have	O
one	O
axis	O
of	O
rotational	O
symmetry	O
.	O
	
For	O
example	O
,	O
the	O
squared	O
box	O
of	O
Fig	O
.	O
1	O
(	O
c	O
)	O
has	O
an	O
angle	O
of	O
symmetry	O
of	O
90	O
	
•	O
	
and	O
the	O
other	O
object	O
has	O
an	O
angle	O
of	O
symmetry	O
of	O
0	O
	
•	O
since	O
it	O
is	O
an	O
object	O
of	O
revolution	O
;	O
Object	O
#	O
5	O
in	O
Fig	O
.	O
	
1	O
(	O
d	O
)	O
is	O
not	O
perfectly	O
symmetrical	O
but	O
only	O
because	O
of	O
the	O
small	O
screw	O
on	O
the	O
top	O
face	O
.	O
	
The	O
approach	O
described	O
above	O
fails	O
on	O
these	O
objects	O
because	O
it	O
tries	O
to	O
learn	O
a	O
mapping	O
from	O
the	O
image	O
space	O
to	O
the	O
pose	O
space	O
.	O
	
Since	O
two	O
images	O
of	O
a	O
symmetrical	O
object	O
under	O
two	O
different	O
poses	O
look	O
identical	O
,	O
the	O
image	O
-	O
pose	O
correspondence	O
is	O
in	O
fact	O
a	O
one	O
-	O
to	O
-	O
many	O
relationship	O
.	O
	
This	O
issue	O
is	O
actually	O
not	O
restricted	O
to	O
our	O
approach	O
.	O
	
For	O
example	O
,	O
[	O
reference	O
]	O
,	O
which	O
relies	O
on	O
object	O
coordinates	O
,	O
does	O
not	O
provide	O
results	O
on	O
the	O
Bowl	B-Material
object	I-Material
of	O
the	O
LINEMOD	B-Material
dataset	I-Material
,	O
an	O
object	O
with	O
an	O
axis	O
of	O
symmetry	O
:	O
It	O
is	O
not	O
clear	O
which	O
coordinates	O
should	O
be	O
assigned	O
to	O
the	O
3D	O
points	O
of	O
this	O
object	O
,	O
as	O
all	O
the	O
points	O
on	O
a	O
circle	O
orthogonal	O
to	O
the	O
axis	O
of	O
symmetry	O
have	O
the	O
same	O
appearance	O
.	O
	
To	O
solve	O
this	O
problem	O
,	O
we	O
train	O
the	O
method	O
described	O
above	O
using	O
images	O
of	O
the	O
object	O
under	O
rotation	O
in	O
a	O
restricted	O
range	O
,	O
such	O
that	O
the	O
training	O
set	O
does	O
not	O
contain	O
ambiguous	O
images	O
.	O
	
In	O
order	O
to	O
recover	O
the	O
object	O
pose	O
under	O
a	O
larger	O
range	O
of	O
rotation	O
,	O
we	O
train	O
a	O
classifer	B-Method
to	O
tell	O
under	O
which	O
range	O
the	O
object	O
rotation	O
is	O
.	O
	
Again	O
,	O
this	O
is	O
easy	O
to	O
do	O
with	O
a	O
"	O
holistic	B-Method
"	I-Method
approach	I-Method
,	O
and	O
this	O
classifier	B-Method
takes	O
an	O
image	O
of	O
the	O
entire	O
object	O
as	O
input	O
.	O
	
As	O
we	O
will	O
explain	O
in	O
more	O
details	O
,	O
we	O
can	O
then	O
always	O
use	O
the	O
CNN	B-Method
trained	O
on	O
the	O
restricted	O
range	O
to	O
estimate	O
any	O
pose	O
.	O
	
In	O
addition	O
,	O
we	O
will	O
show	O
how	O
to	O
adapt	O
this	O
idea	O
to	O
handle	O
"	O
approximatively	O
symmetrical	O
"	O
objects	O
like	O
Object	O
#	O
5	O
.	O
	
This	O
approach	O
allows	O
us	O
to	O
obtain	O
good	O
performance	O
on	O
the	O
T	B-Material
-	I-Material
LESS	I-Material
dataset	O
.	O
	
Finally	O
,	O
we	O
show	O
that	O
we	O
can	O
add	O
an	O
optional	O
last	O
step	O
to	O
refine	O
the	O
pose	B-Task
estimates	I-Task
by	O
using	O
the	O
"	O
feedback	B-Method
loop	I-Method
"	O
proposed	O
in	O
[	O
reference	O
]	O
for	O
hand	B-Task
detection	I-Task
in	O
depth	O
images	O
:	O
We	O
train	O
a	O
network	O
to	O
improve	O
the	O
prediction	O
of	O
the	O
2D	O
projections	O
by	O
comparing	O
the	O
input	O
image	O
and	O
a	O
rendering	O
of	O
the	O
object	O
for	O
the	O
initial	O
pose	B-Task
estimate	I-Task
.	O
	
This	O
allows	O
us	O
to	O
improve	O
even	O
more	O
our	O
results	O
on	O
the	O
LINEMOD	B-Material
and	O
Occlusion	B-Material
datasets	I-Material
.	O
	
Our	O
full	O
approach	O
,	O
which	O
we	O
call	O
BB8	B-Method
,	O
for	O
the	O
8	O
corners	O
of	O
the	O
bounding	O
box	O
,	O
is	O
also	O
very	O
fast	O
,	O
as	O
it	O
only	O
requires	O
to	O
apply	O
Deep	B-Method
Networks	I-Method
to	O
the	O
input	O
image	O
a	O
few	O
times	O
.	O
	
In	O
the	O
remainder	O
of	O
the	O
paper	O
,	O
we	O
first	O
discuss	O
related	O
work	O
,	O
describe	O
our	O
approach	O
,	O
and	O
compare	O
it	O
against	O
the	O
state	O
-	O
ofthe	O
-	O
art	O
on	O
the	O
three	O
available	O
datasets	O
.	O
	
section	O
:	O
Related	O
Work	O
	
The	O
literature	O
on	O
3D	B-Task
object	I-Task
detection	I-Task
is	O
very	O
large	O
,	O
thus	O
we	O
will	O
focus	O
only	O
on	O
recent	O
works	O
.	O
	
Keypoint	B-Method
-	I-Method
based	I-Method
methods	I-Method
[	O
reference	O
][	O
reference	O
]	O
were	O
popular	O
for	O
a	O
long	O
time	O
and	O
perform	O
well	O
but	O
only	O
on	O
very	O
textured	O
objects	O
.	O
	
The	O
apparition	O
of	O
inexpensive	O
3D	B-Method
cameras	I-Method
favored	O
the	O
development	O
of	O
methods	O
suitable	O
for	O
untextured	O
objects	O
:	O
[	O
reference	O
][	O
reference	O
]	O
rely	O
on	O
depth	O
data	O
only	O
and	O
use	O
votes	O
from	O
pairs	O
of	O
3D	O
points	O
and	O
their	O
normals	O
to	O
detect	O
3D	O
objects	O
.	O
	
[	O
reference	O
]	O
uses	O
a	O
decision	B-Method
tree	I-Method
applied	O
to	O
RGB	B-Material
-	I-Material
D	I-Material
images	O
to	O
simultaneously	O
recognize	O
the	O
objects	O
and	O
predict	O
their	O
poses	O
.	O
	
[	O
reference	O
][	O
reference	O
]	O
consider	O
a	O
template	B-Method
-	I-Method
based	I-Method
representation	I-Method
computed	O
from	O
RGB	B-Material
-	I-Material
D	I-Material
or	O
RGB	B-Material
data	I-Material
,	O
which	O
allows	O
for	O
large	B-Task
scale	I-Task
detection	I-Task
[	O
reference	O
]	O
.	O
However	O
,	O
this	O
template	B-Method
approach	I-Method
is	O
sensitive	O
to	O
partial	O
occlusions	O
.	O
	
To	O
tackle	O
clutter	O
and	O
partial	O
occlusions	O
,	O
[	O
reference	O
]	O
and	O
[	O
reference	O
]	O
rely	O
on	O
local	B-Method
patches	I-Method
recognition	I-Method
performed	O
with	O
Random	B-Method
Forests	I-Method
.	O
	
In	O
particular	O
,	O
[	O
reference	O
]	O
considers	O
'	O
3D	O
object	O
coordinates	O
'	O
:	O
A	O
Random	B-Method
Forest	I-Method
is	O
trained	O
to	O
predict	O
the	O
3D	O
location	O
in	O
the	O
object	O
coordinate	O
system	O
of	O
each	O
image	O
location	O
.	O
	
The	O
prediction	O
of	O
this	O
forest	O
is	O
integrated	O
in	O
an	O
energy	B-Method
function	I-Method
together	O
with	O
a	O
term	O
that	O
compares	O
the	O
depth	O
map	O
with	O
a	O
rendering	O
of	O
the	O
object	O
and	O
a	O
term	O
that	O
penalizes	O
pixels	O
that	O
lie	O
on	O
the	O
object	O
rendering	O
but	O
predicted	O
by	O
the	O
forest	O
to	O
not	O
be	O
an	O
object	O
point	O
.	O
	
This	O
energy	B-Method
function	I-Method
is	O
optimized	O
by	O
a	O
RANSAC	B-Method
procedure	I-Method
.	O
	
[	O
reference	O
]	O
replaces	O
this	O
energy	O
function	O
by	O
an	O
energy	O
computed	O
from	O
the	O
output	O
of	O
a	O
CNN	B-Method
trained	O
to	O
compare	O
observed	O
image	O
features	O
and	O
features	O
computed	O
from	O
a	O
3D	B-Method
rendering	I-Method
of	O
the	O
potentially	O
detected	O
object	O
.	O
	
This	O
makes	O
the	O
approach	O
very	O
robust	O
to	O
partial	O
occlusions	O
.	O
	
These	O
works	O
,	O
however	O
,	O
are	O
designed	O
for	O
RGB	B-Material
-	I-Material
D	I-Material
data	O
.	O
	
[	O
reference	O
]	O
extends	O
this	O
work	O
and	O
relies	O
on	O
RGB	B-Material
data	I-Material
only	O
,	O
as	O
we	O
do	O
.	O
	
They	O
use	O
Auto	O
-	O
Context	O
[	O
reference	O
]	O
to	O
obtain	O
better	O
predictions	O
from	O
the	O
Random	B-Method
Forests	I-Method
,	O
estimate	O
a	O
distribute	O
over	O
the	O
object	O
coordinates	O
to	O
handle	O
the	O
prediction	O
uncertainties	O
better	O
,	O
and	O
propose	O
a	O
more	O
sophisticated	O
RANSAC	B-Method
-	O
like	O
method	O
that	O
scales	O
with	O
the	O
number	O
of	O
objects	O
.	O
	
This	O
results	O
in	O
an	O
efficient	O
and	O
accurate	O
method	O
,	O
however	O
,	O
robustness	B-Metric
to	O
partial	O
occlusions	O
are	O
not	O
demonstrated	O
.	O
	
[	O
3	O
]	O
is	O
related	O
to	O
[	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
but	O
focuses	O
on	O
providing	O
sparse	B-Task
2D	I-Task
-	I-Task
3D	I-Task
correspondences	I-Task
from	O
reliable	O
object	O
parts	O
.	O
	
Unfortunately	O
,	O
it	O
provides	O
results	O
on	O
its	O
own	O
dataset	O
only	O
,	O
not	O
on	O
more	O
broadly	O
available	O
datasets	O
.	O
	
Like	O
us	O
,	O
[	O
reference	O
]	O
relies	O
on	O
a	O
CNN	B-Method
to	O
directly	O
predict	O
a	O
3D	O
pose	O
,	O
but	O
in	O
the	O
form	O
of	O
a	O
translation	O
and	O
a	O
rotation	O
.	O
	
It	O
considers	O
camera	B-Task
relocalisation	I-Task
in	I-Task
urban	I-Task
environment	I-Task
rather	O
than	O
3D	B-Task
object	I-Task
detection	I-Task
,	O
and	O
uses	O
the	O
full	O
image	O
as	O
input	O
to	O
the	O
CNN	B-Method
.	O
	
By	O
predicting	O
the	O
2D	O
projections	O
of	O
the	O
corners	O
of	O
the	O
bounding	O
box	O
,	O
we	O
avoid	O
the	O
need	O
for	O
a	O
meta	O
-	O
parameter	O
to	O
balance	O
the	O
position	O
and	O
orientation	O
errors	O
.	O
	
As	O
shown	O
in	O
our	O
experiments	O
,	O
the	O
pose	O
appears	O
to	O
be	O
more	O
accurate	O
when	O
predicted	O
in	O
this	O
form	O
.	O
	
Intuitively	O
,	O
this	O
should	O
not	O
be	O
surprising	O
,	O
as	O
predicting	O
2D	O
locations	O
from	O
a	O
color	O
images	O
seems	O
easier	O
than	O
predicting	O
a	O
3D	O
translation	O
and	O
a	O
quaternion	O
,	O
for	O
example	O
.	O
	
[	O
6	O
]	O
also	O
uses	O
a	O
CNN	B-Method
to	O
predict	O
the	O
3D	B-Task
pose	I-Task
of	I-Task
generic	I-Task
objects	I-Task
but	O
from	O
RGB	B-Material
-	I-Material
D	I-Material
data	O
.	O
	
It	O
first	O
segments	O
the	O
objects	O
of	O
interest	O
to	O
avoid	O
the	O
influence	O
of	O
clutter	O
.	O
	
We	O
tried	O
segmenting	O
the	O
objects	O
before	O
predicting	O
the	O
pose	O
as	O
well	O
,	O
however	O
,	O
this	O
performed	O
poorly	O
on	O
the	O
LINEMOD	B-Material
dataset	I-Material
,	O
because	O
the	O
segmented	O
silhouttes	O
were	O
not	O
very	O
accurate	O
,	O
even	O
with	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
segmentation	B-Method
methods	I-Method
.	O
	
In	O
summary	O
,	O
our	O
method	O
appears	O
to	O
be	O
one	O
of	O
the	O
first	O
to	O
deal	O
with	O
RGB	B-Material
data	I-Material
only	O
to	O
detect	O
3D	O
objects	O
and	O
estimate	O
their	O
poses	O
on	O
recent	O
datasets	O
.	O
	
As	O
we	O
will	O
show	O
in	O
the	O
experiments	O
,	O
it	O
outperforms	O
the	O
accuracy	B-Metric
of	O
the	O
state	O
-	O
of	O
-	O
theart	O
[	O
reference	O
]	O
by	O
a	O
large	O
margin	O
.	O
	
section	O
:	O
Proposed	O
Approach	O
	
In	O
our	O
approach	O
,	O
we	O
first	O
find	O
the	O
objects	O
in	O
2D	O
,	O
we	O
obtain	O
a	O
first	O
estimate	O
of	O
the	O
3D	O
poses	O
,	O
including	O
objects	O
with	O
a	O
rotational	O
symmetry	O
,	O
and	O
we	O
finally	O
refine	O
the	O
initial	O
pose	B-Task
estimates	I-Task
.	O
	
We	O
describe	O
each	O
step	O
in	O
this	O
section	O
.	O
	
section	O
:	O
Localizing	O
the	O
Objects	O
in	O
2D	O
	
We	O
first	O
identify	O
the	O
2D	O
centers	O
of	O
the	O
objects	O
of	O
interest	O
in	O
the	O
input	O
images	O
.	O
	
We	O
could	O
use	O
a	O
standard	O
2D	B-Method
object	I-Method
detector	I-Method
,	O
but	O
we	O
developed	O
an	O
approach	O
based	O
on	O
segmentation	B-Method
that	O
resulted	O
in	O
better	O
performance	O
as	O
it	O
can	O
provide	O
accurate	O
locations	O
even	O
under	O
partial	O
occlusions	O
.	O
	
Compared	O
to	O
our	O
initial	O
tests	O
using	O
a	O
sliding	B-Method
window	I-Method
,	O
this	O
ap	O
-	O
proach	O
improved	O
our	O
2D	B-Task
detection	I-Task
results	O
from	O
about	O
75	O
%	O
to	O
98.8	O
%	O
correct	B-Metric
detection	I-Metric
rate	I-Metric
based	O
on	O
a	O
IoU	B-Metric
of	I-Metric
0.5	I-Metric
.	O
	
We	O
only	O
need	O
a	O
low	B-Method
resolution	I-Method
segmentation	I-Method
and	O
thus	O
do	O
not	O
need	O
a	O
hourglass	B-Method
-	I-Method
shaped	I-Method
architecture	I-Method
[	O
reference	O
]	O
,	O
which	O
makes	O
our	O
segmentation	B-Task
more	O
efficient	O
.	O
	
As	O
shown	O
in	O
Fig	O
.	O
2	O
,	O
our	O
approach	O
performs	O
a	O
two	O
-	O
level	B-Task
coarse	I-Task
-	I-Task
to	I-Task
-	I-Task
fine	I-Task
object	I-Task
segmentation	I-Task
.	O
	
For	O
each	O
level	O
,	O
we	O
train	O
a	O
single	O
network	O
for	O
all	O
the	O
objects	O
.	O
	
The	O
first	O
network	O
is	O
obtained	O
by	O
replacing	O
the	O
last	B-Method
layer	I-Method
of	O
VGG	B-Method
[	O
reference	O
]	O
by	O
a	O
fully	B-Method
connected	I-Method
layer	I-Method
with	O
the	O
required	O
number	O
of	O
output	O
required	O
by	O
each	O
step	O
,	O
and	O
fine	O
-	O
tune	O
it	O
.	O
	
The	O
second	O
network	O
has	O
a	O
simple	O
,	O
ad	B-Method
hoc	I-Method
architecture	I-Method
.	O
	
More	O
exactly	O
,	O
the	O
first	O
network	O
is	O
trained	O
to	O
provide	O
a	O
very	O
low	B-Task
resolution	I-Task
binary	I-Task
segmentation	I-Task
of	O
the	O
objects	O
given	O
an	O
image	O
region	O
J	O
of	O
size	O
	
128	O
×	O
128	O
by	O
minimizing	O
the	O
following	O
objective	B-Metric
function	I-Metric
:	O
	
where	O
T	O
s	O
is	O
a	O
training	O
set	O
made	O
of	O
image	O
regions	O
J	O
,	O
and	O
the	O
corresponding	O
segmentations	O
S	O
for	O
object	O
o	O
,	O
(	O
f	O
	
is	O
the	O
output	O
of	O
network	B-Method
f	O
1	O
φ	O
for	O
region	O
J	O
and	O
object	O
	
o.	O
	
φ	O
denotes	O
the	O
network	O
's	O
parameters	O
,	O
optimized	O
during	O
training	O
.	O
	
For	O
the	O
LINEMOD	B-Material
and	O
Occlusion	B-Material
datasets	I-Material
,	O
there	O
is	O
at	O
most	O
one	O
object	O
for	O
a	O
given	O
region	O
J	O
,	O
but	O
more	O
objects	O
can	O
be	O
present	O
for	O
the	O
T	B-Material
-	I-Material
LESS	I-Material
dataset	O
.	O
	
At	O
run	O
-	O
time	O
,	O
to	O
get	O
the	O
segmentations	B-Task
,	O
we	O
compute	O
:	O
	
where	O
s	O
1	O
,	O
o	O
is	O
a	O
8	O
×	O
8	O
binary	B-Method
segmentation	I-Method
of	O
J	O
for	O
object	O
o	O
,	O
and	O
τ	O
1	O
is	O
a	O
threshold	O
used	O
to	O
binarize	O
the	O
network	O
's	O
output	O
.	O
	
To	O
obtain	O
a	O
binary	B-Task
segmentation	I-Task
for	O
the	O
full	O
input	O
image	O
,	O
we	O
split	O
this	O
image	O
into	O
regions	O
and	O
compute	O
the	O
s	O
1	O
,	O
o	O
for	O
each	O
region	O
.	O
	
This	O
gives	O
us	O
one	O
binary	B-Method
segmentation	I-Method
S	I-Method
1	I-Method
,	I-Method
o	I-Method
for	O
the	O
full	O
input	O
image	O
,	O
and	O
each	O
possible	O
object	O
.	O
	
This	O
usually	O
results	O
in	O
a	O
single	O
connected	B-Method
component	I-Method
per	O
visible	O
object	O
;	O
if	O
several	O
components	O
are	O
present	O
,	O
we	O
keep	O
only	O
the	O
largest	O
one	O
for	O
each	O
object	O
.	O
	
If	O
the	O
largest	O
component	O
in	O
a	O
segmentation	O
S	O
1	O
,	O
o	O
is	O
small	O
,	O
object	O
o	O
is	O
likely	O
not	O
visible	O
.	O
	
For	O
the	O
remaining	O
object	O
(	O
s	O
)	O
,	O
we	O
refine	O
the	O
shape	O
of	O
the	O
largest	O
component	O
by	O
applying	O
a	O
second	O
network	O
to	O
each	O
16	O
×	O
16	O
image	O
patch	O
P	O
that	O
corresponds	O
to	O
an	O
active	O
location	O
in	O
S	O
1	O
:	O
	
using	O
notations	O
similar	O
to	O
the	O
ones	O
in	O
Eq	O
.	O
	
[	O
reference	O
]	O
.	O
	
Since	O
the	O
input	O
to	O
f	O
2	O
ψ	O
(	O
P	O
)	O
has	O
a	O
low	O
resolution	O
,	O
we	O
do	O
not	O
need	O
a	O
complex	O
network	O
such	O
as	O
VGG	B-Method
[	O
reference	O
]	O
,	O
and	O
we	O
use	O
a	O
much	O
simpler	O
architecture	O
with	O
2	O
convolutional	B-Method
layers	I-Method
and	O
2	O
pooling	B-Method
layers	I-Method
.	O
	
We	O
finally	O
obtain	O
a	O
segmentation	B-Method
S	I-Method
2	I-Method
,	I-Method
o	I-Method
with	O
resolution	O
64	O
×	O
48	O
for	O
the	O
full	O
input	O
image	O
and	O
each	O
visible	O
object	O
	
o.	O
	
We	O
therefore	O
get	O
the	O
identities	O
o	O
of	O
the	O
visible	O
object	O
(	O
s	O
)	O
,	O
and	O
for	O
these	O
objects	O
,	O
we	O
use	O
the	O
segmentation	O
centroids	O
as	O
their	O
2D	O
centers	O
,	O
to	O
compute	O
the	O
3D	O
poses	O
of	O
the	O
objects	O
as	O
described	O
below	O
.	O
	
section	O
:	O
Predicting	O
the	O
3D	B-Task
Pose	I-Task
	
We	O
predict	O
the	O
3D	O
pose	O
of	O
an	O
object	O
by	O
applying	O
a	O
Deep	B-Method
Network	I-Method
to	O
an	O
image	O
window	O
W	O
centered	O
on	O
the	O
2D	O
object	O
center	O
estimated	O
as	O
described	O
in	O
the	O
previous	O
section	O
.	O
	
As	O
for	O
the	O
segmentation	B-Task
,	O
we	O
use	O
VGG	B-Method
[	O
reference	O
]	O
as	O
a	O
basis	O
for	O
this	O
network	O
.	O
	
This	O
allows	O
us	O
to	O
handle	O
all	O
the	O
objects	O
of	O
the	O
target	O
dataset	O
with	O
a	O
single	O
network	O
.	O
	
It	O
is	O
possible	O
to	O
directly	O
predict	O
the	O
pose	O
in	O
the	O
form	O
of	O
a	O
3	O
-	O
vector	O
and	O
an	O
exponential	O
map	O
for	O
example	O
,	O
as	O
in	O
[	O
reference	O
]	O
.	O
However	O
,	O
a	O
more	O
accurate	O
approach	O
was	O
proposed	O
in	O
[	O
reference	O
]	O
for	O
predicting	B-Task
the	I-Task
poses	I-Task
of	I-Task
object	I-Task
parts	I-Task
.	O
	
To	O
apply	O
it	O
here	O
,	O
we	O
minimize	O
the	O
following	O
cost	B-Metric
function	I-Metric
over	O
the	O
parameters	O
Θ	O
of	O
network	B-Method
g	I-Method
Θ	I-Method
:	O
	
where	O
T	O
is	O
a	O
training	O
set	O
made	O
of	O
image	O
windows	O
W	O
containing	O
object	O
o	O
under	O
a	O
pose	O
defined	O
by	O
an	O
exponential	O
map	O
e	O
and	O
a	O
	
3	O
-	O
vector	O
t.	O
The	O
M	O
o	O
	
i	O
are	O
the	O
3D	O
coordinates	O
of	O
the	O
corners	O
of	O
the	O
bounding	O
box	O
of	O
object	O
o	O
in	O
the	O
object	O
coordinate	O
system	O
.	O
	
Proj	O
e	O
,	O
t	O
(	O
M	O
)	O
projects	O
the	O
3D	O
point	O
M	O
on	O
the	O
image	O
from	O
the	O
pose	O
defined	O
by	O
e	O
and	O
t.	O
	
returns	O
the	O
two	O
components	O
of	O
the	O
output	O
of	O
g	O
Θ	O
corresponding	O
to	O
the	O
predicted	O
2D	O
coordinates	O
of	O
the	O
i	O
-	O
th	O
corner	O
for	O
object	O
	
o.	O
•	O
modulo	O
180	O
	
•	O
	
(	O
c	O
)	O
.	O
	
Our	O
solution	O
is	O
to	O
restrict	O
the	O
range	O
during	O
training	O
to	O
be	O
between	O
0	O
	
•	O
and	O
90	O
	
•	O
.	O
	
We	O
use	O
a	O
classifier	B-Method
to	O
detect	O
if	O
the	O
pose	O
in	O
an	O
input	O
image	O
is	O
between	O
90	O
	
•	O
and	O
180	O
	
•	O
.	O
	
If	O
this	O
is	O
the	O
case	O
(	O
d	O
)	O
,	O
we	O
mirror	O
the	O
input	O
image	O
(	O
e	O
)	O
,	O
and	O
mirror	O
back	O
the	O
predicted	O
projections	O
for	O
the	O
corners	O
(	O
f	O
)	O
.	O
	
At	O
run	O
-	O
time	O
,	O
the	O
segmentation	B-Method
gives	O
the	O
identity	O
and	O
the	O
2D	O
locations	O
of	O
the	O
visible	O
object	O
(	O
s	O
)	O
	
o.	O
	
The	O
3D	O
pose	O
can	O
then	O
be	O
estimated	O
for	O
the	O
correspondences	O
between	O
the	O
3D	O
points	O
	
M	O
o	O
i	O
and	O
the	O
predicted	O
m	O
i	O
(	O
(	O
g	O
Θ	O
(	O
W	O
)	O
)	O
	
[	O
o	O
]	O
)	O
using	O
a	O
PnP	B-Method
algorithm	I-Method
.	O
	
Other	O
3D	O
points	O
could	O
be	O
used	O
here	O
,	O
however	O
,	O
the	O
corners	O
of	O
the	O
bounding	O
box	O
are	O
a	O
natural	O
choice	O
as	O
they	O
frame	O
the	O
object	O
and	O
are	O
well	O
spread	O
in	O
space	O
1	O
.	O
	
section	O
:	O
Handling	O
Objects	O
with	O
an	O
Axis	O
of	O
Symmetry	O
	
If	O
we	O
apply	O
the	O
method	O
described	O
so	O
far	O
to	O
the	O
T	B-Material
-	I-Material
LESS	I-Material
dataset	O
,	O
the	O
performances	O
are	O
significantly	O
lower	O
than	O
the	O
performances	O
on	O
the	O
LINEMOD	B-Material
dataset	I-Material
.	O
	
As	O
mentioned	O
in	O
the	O
introduction	O
,	O
this	O
is	O
because	O
training	O
images	O
W	O
in	O
Eq	O
.	O
	
(	O
4	O
)	O
for	O
the	O
objects	O
of	O
this	O
dataset	O
can	O
be	O
identical	O
while	O
having	O
very	O
different	O
expected	O
predictions	O
Proj	O
e	O
,	O
t	O
(	O
M	O
o	O
i	O
)	O
,	O
because	O
of	O
the	O
rotational	O
symmetry	O
of	O
the	O
objects	O
.	O
	
We	O
first	O
remark	O
that	O
for	O
an	O
object	O
with	O
an	O
angle	O
of	O
symmetry	O
α	O
,	O
its	O
3D	O
rotation	O
around	O
its	O
axis	O
of	O
symmetry	O
can	O
be	O
defined	O
only	O
modulo	O
α	O
,	O
not	O
2π	O
.	O
	
For	O
an	O
object	O
with	O
an	O
angle	O
of	O
symmetry	O
α	O
,	O
we	O
can	O
therefore	O
restrict	O
the	O
poses	O
used	O
for	O
training	O
to	O
the	O
poses	O
where	O
the	O
angle	O
of	O
rotation	O
around	O
the	O
symmetry	O
axis	O
is	O
within	O
the	O
range	O
[	O
0	O
;	O
α	O
[	O
,	O
to	O
avoid	O
the	O
ambiguity	O
between	O
images	O
.	O
	
However	O
,	O
this	O
solves	O
our	O
problem	O
only	O
partially	O
:	O
	
Images	O
at	O
one	O
extremity	O
of	O
this	O
range	O
of	O
poses	O
and	O
the	O
images	O
at	O
the	O
other	O
extremity	O
,	O
while	O
not	O
identical	O
,	O
still	O
look	O
very	O
similar	O
.	O
	
As	O
a	O
result	O
,	O
for	O
input	O
images	O
with	O
an	O
angle	O
of	O
rotation	O
close	O
to	O
0	O
modulo	O
α	O
,	O
the	O
pose	B-Task
prediction	I-Task
can	O
still	O
be	O
very	O
bad	O
,	O
as	O
illustrated	O
in	O
Fig	O
.	O
3	O
.	O
	
To	O
explain	O
our	O
solution	O
,	O
let	O
us	O
first	O
denote	O
by	O
β	O
the	O
rotation	O
angle	O
,	O
and	O
introduce	O
the	O
intervals	O
r	O
1	O
=	O
[	O
0	O
;	O
α	O
/	O
2	O
[	O
and	O
r	O
2	O
=	O
	
[	O
α	O
/	O
2	O
;	O
	
α	O
[	O
.	O
	
To	O
avoid	O
ambiguity	O
,	O
we	O
restrict	O
β	O
to	O
be	O
in	O
r	O
1	O
for	O
the	O
training	O
images	O
used	O
in	O
the	O
optimization	B-Task
problem	I-Task
of	I-Task
Eq	I-Task
.	O
	
(	O
4	O
)	O
.	O
	
The	O
drawback	O
is	O
of	O
course	O
that	O
,	O
without	O
doing	O
anything	O
else	O
,	O
we	O
would	O
not	O
be	O
able	O
to	O
estimate	O
the	O
poses	O
when	O
β	O
is	O
in	O
r	O
2	O
.	O
	
We	O
therefore	O
introduce	O
a	O
CNN	B-Method
classifier	I-Method
k	I-Method
(	O
·	O
)	O
to	O
predict	O
at	O
run	O
-	O
time	O
if	O
β	O
is	O
in	O
r	O
1	O
or	O
r	O
2	O
:	O
If	O
β	O
is	O
in	O
r	O
1	O
,	O
we	O
can	O
estimate	O
the	O
pose	O
as	O
before	O
;	O
If	O
β	O
is	O
in	O
r	O
2	O
,	O
one	O
option	O
would	O
be	O
to	O
apply	O
another	O
g	B-Method
Θ	I-Method
(	I-Method
·	I-Method
)	I-Method
network	I-Method
trained	O
for	O
this	O
range	O
.	O
	
However	O
,	O
it	O
is	O
actually	O
possible	O
to	O
use	O
the	O
same	O
network	B-Method
g	I-Method
Θ	I-Method
(	O
·	O
)	O
for	O
both	O
r	O
1	O
and	O
r	O
2	O
,	O
as	O
follows	O
.	O
	
If	O
the	O
classifier	B-Method
predicts	O
that	O
β	O
in	O
in	O
r	O
2	O
,	O
we	O
mirror	O
the	O
input	O
image	O
W	O
:	O
	
As	O
illustrated	O
in	O
Fig	O
.	O
	
3	O
(	O
e	O
)	O
,	O
the	O
object	O
appears	O
in	O
the	O
mirror	O
image	O
with	O
a	O
rotation	O
angle	O
equal	O
to	O
α	O
−	O
β	O
,	O
which	O
is	O
in	O
r	O
1	O
.	O
	
Therefore	O
we	O
can	O
apply	O
g	B-Method
Θ	I-Method
(	O
·	O
)	O
to	O
the	O
mirrored	O
W	O
.	O
	
To	O
obtain	O
the	O
correct	O
pose	O
,	O
we	O
finally	O
mirror	O
back	O
the	O
projections	O
of	O
the	O
corners	O
predicted	O
by	O
g	O
Θ	O
(	O
·	O
)	O
.	O
	
We	O
currently	O
consider	O
the	O
case	O
where	O
the	O
axis	O
of	O
symmetry	O
is	O
more	O
or	O
less	O
vertical	O
in	O
the	O
image	O
,	O
and	O
mirror	O
the	O
image	O
from	O
left	O
to	O
right	O
.	O
	
When	O
the	O
axis	O
is	O
closer	O
to	O
be	O
horizontal	O
,	O
we	O
should	O
mirror	O
the	O
image	O
from	O
top	O
to	O
bottom	O
.	O
	
Objects	O
of	O
revolution	O
are	O
a	O
special	O
and	O
simpler	O
case	O
:	O
since	O
their	O
angle	O
of	O
symmetry	O
is	O
0	O
	
•	O
	
,	O
we	O
predict	O
their	O
poses	O
under	O
the	O
same	O
angle	O
of	O
rotation	O
.	O
	
For	O
training	O
the	O
pose	B-Task
predictor	I-Task
g	I-Task
Θ	I-Task
(	O
·	O
)	O
,	O
we	O
use	O
the	O
original	O
training	O
images	O
with	O
angles	O
of	O
rotation	O
in	O
r	O
1	O
,	O
and	O
mirror	O
the	O
training	O
images	O
with	O
angles	O
of	O
rotation	O
in	O
r	O
2	O
.	O
	
Handling	O
Objects	O
that	O
are	O
'	O
Not	O
Exactly	O
Symmetrical	O
'	O
As	O
mentioned	O
in	O
the	O
introduction	O
,	O
some	O
objects	O
of	O
the	O
T	B-Material
-	I-Material
LESS	I-Material
dataset	O
are	O
only	O
approximately	O
symmetrical	O
,	O
such	O
as	O
Object	O
#	O
5	O
in	O
Fig	O
.	O
1	O
(	O
d	O
)	O
.	O
	
The	O
small	O
details	O
that	O
make	O
the	O
object	O
not	O
perfectly	O
symmetrical	O
,	O
however	O
,	O
do	O
not	O
help	O
the	O
optimization	B-Task
problem	I-Task
of	I-Task
Eq	I-Task
.	O
	
(	O
4	O
)	O
,	O
but	O
	
we	O
would	O
still	O
like	O
to	O
predict	O
the	O
pose	O
of	O
this	O
object	O
.	O
	
In	O
the	O
case	O
of	O
Object	O
#	O
5	O
,	O
we	O
consider	O
4	O
regions	O
instead	O
of	O
2	O
:	O
r	O
1	O
=	O
[	O
0	O
;	O
π	O
/	O
2	O
[	O
,	O
r	O
1	O
=	O
	
[	O
π	O
/	O
2	O
;	O
π	O
[	O
,	O
r	O
3	O
=	O
	
[	O
π	O
;	O
3π	O
/	O
2	O
[	O
,	O
and	O
r	O
4	O
=	O
	
[	O
3π	O
/	O
2	O
;	O
2π	O
[	O
,	O
and	O
we	O
train	O
the	O
classifier	B-Method
k	I-Method
(	O
·	O
)	O
to	O
predict	O
in	O
which	O
of	O
these	O
four	O
regions	O
the	O
angle	O
of	O
rotation	O
β	O
is	O
.	O
	
If	O
β	O
∈	O
r	O
2	O
or	O
β	O
∈	O
r	O
4	O
,	O
we	O
mirror	O
the	O
image	O
before	O
computing	O
the	O
pose	O
as	O
before	O
.	O
	
Then	O
,	O
if	O
β	O
∈	O
r	O
3	O
or	O
β	O
∈	O
r	O
4	O
,	O
we	O
still	O
have	O
to	O
add	O
π	O
to	O
the	O
angle	O
of	O
rotation	O
of	O
the	O
recovered	O
pose	O
to	O
get	O
an	O
angle	O
between	O
0	O
and	O
2π	O
.	O
	
section	O
:	O
Refining	O
the	O
Pose	O
	
We	O
also	O
introduce	O
an	O
optional	O
additional	O
stage	O
to	O
improve	O
the	O
accuracy	B-Metric
of	O
the	O
pose	B-Task
estimates	I-Task
inspired	O
by	O
[	O
reference	O
]	O
.	O
As	O
illustrated	O
in	O
Fig	O
.	O
4	O
,	O
we	O
train	O
another	O
CNN	B-Method
that	O
predicts	O
an	O
update	O
to	O
improve	O
the	O
pose	O
.	O
	
Because	O
this	O
CNN	B-Method
takes	O
4	O
or	O
6	O
channels	O
as	O
input	O
,	O
it	O
is	O
not	O
clear	O
how	O
we	O
can	O
use	O
VGG	B-Method
,	O
as	O
we	O
did	O
for	O
the	O
previously	O
introduced	O
networks	O
,	O
and	O
we	O
use	O
here	O
one	O
CNN	B-Method
per	O
object	O
.	O
	
However	O
,	O
this	O
stage	O
is	O
optional	O
,	O
and	O
without	O
it	O
,	O
we	O
already	O
outperform	O
the	O
-	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
.	O
	
The	O
first	O
image	O
is	O
the	O
image	O
window	O
W	O
as	O
for	O
g	O
Θ	O
(	O
·	O
)	O
.	O
	
The	O
second	O
image	O
depends	O
on	O
the	O
current	O
estimate	O
of	O
the	O
pose	O
:	O
	
While	O
[	O
reference	O
]	O
generates	O
a	O
depth	O
map	O
with	O
a	O
deep	B-Method
network	I-Method
,	O
we	O
render	O
(	O
using	O
OpenGL	B-Method
)	O
either	O
a	O
binary	O
mask	O
or	O
a	O
color	O
rendering	O
of	O
the	O
target	O
object	O
as	O
seen	O
from	O
this	O
current	O
estimate	O
.	O
	
More	O
formally	O
we	O
train	O
this	O
CNN	B-Method
by	O
minimizing	O
:	O
	
where	O
h	O
µ	O
denotes	O
the	O
CNN	B-Method
,	O
µ	O
its	O
parameters	O
;	O
N	O
(	O
e	O
,	O
t	O
)	O
is	O
a	O
set	O
of	O
poses	O
sampled	O
around	O
pose	O
(	O
e	O
,	O
t	O
)	O
,	O
and	O
Render	O
(	O
e	O
,	O
t	O
)	O
a	O
function	O
that	O
returns	O
a	O
binary	O
mask	O
,	O
or	O
a	O
color	O
rendering	O
,	O
of	O
the	O
target	O
object	O
seen	O
from	O
pose	O
(	O
e	O
,	O
t	O
)	O
.	O
	
At	O
run	O
-	O
time	O
,	O
given	O
a	O
current	O
estimate	O
of	O
the	O
object	O
pose	O
represented	O
by	O
the	O
projections	O
of	O
the	O
cornersv	O
=	O
	
[	O
.	O
.	O
.m	O
	
i	O
.	O
.	O
.	O
]	O
	
,	O
and	O
the	O
corresponding	O
parameterisation	O
(	O
ê	O
,	O
t	O
)	O
,	O
we	O
can	O
update	O
this	O
estimate	O
by	O
invoking	O
h	O
µ	O
(	O
·	O
)	O
:	O
	
section	O
:	O
Generating	O
Training	B-Material
Images	I-Material
	
In	O
Section	O
4	O
,	O
we	O
will	O
compare	O
our	O
method	O
to	O
the	O
stateof	O
-	O
the	O
art	O
for	O
3D	B-Task
object	I-Task
detection	I-Task
in	O
color	O
images	O
[	O
reference	O
]	O
,	O
and	O
like	O
them	O
,	O
for	O
each	O
of	O
15	O
objects	O
of	O
the	O
LINEMOD	B-Material
dataset	I-Material
,	O
we	O
use	O
15	O
%	O
of	O
the	O
images	O
for	O
training	O
and	O
use	O
the	O
rest	O
for	O
testing	O
.	O
	
The	O
training	O
images	O
are	O
selected	O
as	O
in	O
[	O
reference	O
]	O
,	O
such	O
that	O
relative	O
orientation	O
between	O
them	O
should	O
be	O
larger	O
than	O
a	O
threshold	O
.	O
	
We	O
also	O
tried	O
a	O
random	B-Method
selection	I-Method
,	O
and	O
there	O
was	O
only	O
a	O
slight	O
drop	O
in	O
performance	O
,	O
for	O
some	O
objects	O
only	O
.	O
	
The	O
selection	B-Method
method	I-Method
thus	O
does	O
not	O
seem	O
critical	O
.	O
	
The	O
T	B-Material
-	I-Material
LESS	I-Material
dataset	O
provides	O
regularly	O
sampled	O
training	O
images	O
.	O
	
As	O
shown	O
in	O
Fig	O
.	O
5	O
,	O
we	O
also	O
use	O
a	O
similar	O
method	O
as	O
[	O
reference	O
]	O
to	O
augment	O
the	O
training	O
set	O
:	O
We	O
extract	O
the	O
objects	O
'	O
silhouettes	O
from	O
these	O
images	O
,	O
which	O
can	O
be	O
done	O
as	O
the	O
ground	O
Figure	O
5	O
.	O
	
Two	O
generated	O
training	O
images	O
for	O
different	O
objects	O
from	O
the	O
LINEMOD	B-Material
dataset	I-Material
	
[	O
reference	O
]	O
.	O
	
The	O
object	O
is	O
shifted	O
from	O
the	O
center	O
to	O
handle	O
the	O
inaccuracy	O
of	O
the	O
detection	B-Method
method	I-Method
,	O
and	O
the	O
background	O
is	O
random	O
to	O
make	O
sure	O
that	O
the	O
network	B-Method
gΘ	I-Method
can	O
not	O
exploit	O
the	O
context	O
specific	O
to	O
the	O
dataset	O
.	O
	
truth	O
poses	O
and	O
the	O
objects	O
'	O
3D	B-Method
models	I-Method
are	O
available	O
.	O
	
Note	O
that	O
this	O
means	O
the	O
results	O
are	O
not	O
influenced	O
by	O
the	O
scene	O
context	O
,	O
which	O
makes	O
the	O
pose	B-Task
estimation	I-Task
more	O
difficult	O
.	O
	
To	O
be	O
robust	O
to	O
clutter	O
and	O
scale	O
changes	O
,	O
we	O
scale	O
the	O
segmented	O
objects	O
by	O
a	O
factor	O
of	O
s	O
∈	O
[	O
0.8	O
,	O
1.2	O
]	O
,	O
and	O
change	O
the	O
background	O
by	O
a	O
patch	O
extracted	O
from	O
a	O
randomly	O
picked	O
image	O
from	O
the	O
ImageNet	B-Material
dataset	I-Material
	
[	O
reference	O
]	O
.	O
Moreover	O
,	O
the	O
object	O
is	O
shifted	O
by	O
some	O
pixels	O
from	O
the	O
center	O
of	O
the	O
image	O
window	O
in	O
both	O
x	O
and	O
y	O
directions	O
.	O
	
This	O
helps	O
us	O
to	O
handle	O
small	B-Task
object	I-Task
localization	I-Task
errors	I-Task
made	O
during	O
detection	B-Task
.	O
	
section	O
:	O
Experiments	O
	
In	O
this	O
section	O
,	O
we	O
present	O
and	O
discuss	O
the	O
results	O
of	O
our	O
evaluation	O
.	O
	
We	O
first	O
describe	O
the	O
three	O
evaluation	B-Metric
metrics	I-Metric
used	O
in	O
the	O
literature	O
and	O
in	O
this	O
paper	O
.	O
	
We	O
evaluate	O
our	O
method	O
on	O
all	O
the	O
possible	O
datasets	O
with	O
color	O
images	O
for	O
instance	O
3D	B-Task
detection	I-Task
and	O
pose	B-Task
estimation	I-Task
we	O
are	O
aware	O
of	O
:	O
the	O
LINEMOD	B-Material
[	O
reference	O
]	O
,	O
Occlusion	B-Material
[	O
reference	O
]	O
,	O
and	O
T	B-Material
-	I-Material
LESS	I-Material
[	O
reference	O
]	O
datasets	O
.	O
	
section	O
:	O
Evaluation	B-Metric
Metrics	I-Metric
	
As	O
in	O
[	O
reference	O
]	O
,	O
we	O
use	O
the	O
percentage	O
of	O
correctly	O
predicted	O
poses	O
for	O
each	O
sequence	O
and	O
each	O
object	O
,	O
where	O
a	O
pose	O
is	O
considered	O
correct	O
if	O
it	O
passes	O
the	O
tests	O
presented	O
below	O
.	O
	
section	O
:	O
2D	O
Projections	O
[	O
2	O
]	O
	
This	O
is	O
a	O
metric	O
suited	O
for	O
applications	O
such	O
as	O
augmented	B-Task
reality	I-Task
.	O
	
A	O
pose	O
is	O
considered	O
correct	O
if	O
the	O
average	O
of	O
the	O
2D	O
distances	O
between	O
the	O
projections	O
of	O
the	O
object	O
's	O
vertices	O
from	O
the	O
estimated	O
pose	O
and	O
the	O
ground	O
truth	O
pose	O
is	O
less	O
than	O
5	O
pixels	O
.	O
	
6D	O
Pose	O
[	O
reference	O
]	O
	
With	O
this	O
metric	O
,	O
a	O
pose	O
is	O
considered	O
correct	O
if	O
the	O
average	O
of	O
the	O
3D	O
distances	O
between	O
the	O
transformed	O
of	O
the	O
object	O
's	O
vertices	O
Table	O
1	O
.	O
	
Evaluation	O
using	O
the	O
2D	B-Metric
Projections	I-Metric
metric	I-Metric
of	O
using	O
the	O
2D	O
projections	O
of	O
the	O
bounding	O
box	O
(	O
'	O
BB	O
'	O
)	O
,	O
compared	O
to	O
the	O
direct	O
prediction	O
of	O
the	O
pose	O
(	O
'	O
Direct	O
'	O
)	O
,	O
and	O
of	O
the	O
refinement	B-Method
methods	I-Method
.	O
	
For	O
this	O
evaluation	O
,	O
we	O
used	O
the	O
ground	O
truth	O
2D	O
object	O
center	O
to	O
avoid	O
the	O
influence	O
of	O
the	O
detection	B-Task
.	O
	
For	O
the	O
objects	O
marked	O
with	O
a	O
(	O
*	O
)	O
,	O
we	O
optimize	O
the	O
value	O
of	O
the	O
weight	O
balancing	O
the	O
rotation	O
and	O
translation	O
terms	O
on	O
the	O
test	O
set	O
,	O
giving	O
an	O
advantage	O
to	O
the	O
'	O
Direct	B-Method
'	I-Method
pose	I-Method
method	I-Method
.	O
	
For	O
the	O
other	O
objects	O
,	O
we	O
used	O
the	O
value	O
that	O
is	O
optimal	O
for	O
both	O
the	O
Ape	B-Method
and	O
the	O
Driller	B-Method
.	O
	
is	O
less	O
than	O
10	O
%	O
of	O
the	O
object	O
's	O
diameter	O
.	O
	
V	O
is	O
the	O
set	O
of	O
the	O
object	O
's	O
vertices	O
,	O
(	O
ê	O
,	O
t	O
)	O
	
the	O
estimated	O
pose	O
and	O
(	O
ē	O
,	O
t	O
)	O
the	O
ground	O
truth	O
pose	O
,	O
and	O
	
Tr	O
e	O
,	O
t	O
(	O
·	O
)	O
a	O
rigid	O
transformation	O
by	O
rotation	O
e	O
,	O
translation	O
	
t.	O
	
For	O
the	O
objects	O
with	O
ambigious	O
poses	O
due	O
to	O
symmetries	O
,	O
[	O
reference	O
]	O
replaces	O
this	O
measure	O
by	O
:	O
	
5	O
cm	O
5	O
	
•	O
	
Metric	O
[	O
reference	O
]	O
	
With	O
this	O
metric	O
,	O
a	O
pose	O
is	O
considered	O
correct	O
if	O
the	O
translation	O
and	O
rotation	O
errors	O
are	O
below	O
5	O
cm	O
and	O
5	O
	
•	O
respectively	O
.	O
	
section	O
:	O
Contributions	O
of	O
the	O
Different	O
Steps	O
	
The	O
columns	O
'	O
BB	O
'	O
,	O
'	O
Mask	O
Ref	O
.	O
	
[	O
reference	O
]	O
,	O
and	O
'	O
RGB	O
Ref	O
.	O
'	O
of	O
Table	O
1	O
compare	O
the	O
results	O
of	O
our	O
method	O
before	O
and	O
after	O
two	O
iterations	O
of	O
refinement	O
,	O
using	O
either	O
a	O
binary	O
mask	O
or	O
a	O
color	B-Method
rendering	I-Method
.	O
	
For	O
this	O
evaluation	O
,	O
we	O
used	O
the	O
ground	O
truth	O
2D	O
object	O
center	O
to	O
avoid	O
the	O
influence	O
of	O
the	O
detection	B-Task
.	O
	
Using	O
refinement	B-Method
improves	O
the	O
results	O
on	O
average	O
by	O
4.5	O
%	O
and	O
6.3	O
%	O
for	O
the	O
mask	B-Task
and	I-Task
color	I-Task
rendering	I-Task
respectively	O
.	O
	
Using	O
a	O
color	B-Method
rendering	I-Method
systematically	O
yields	O
the	O
best	O
results	O
,	O
but	O
using	O
the	O
binary	O
mask	O
yields	O
already	O
a	O
significant	O
improvement	O
,	O
showing	O
that	O
an	O
untextured	B-Method
model	I-Method
can	O
be	O
used	O
.	O
	
[	O
reference	O
]	O
and	O
our	O
method	O
without	O
and	O
with	O
RGB	B-Method
Refinement	I-Method
using	O
our	O
segmentation	B-Method
-	I-Method
based	I-Method
method	I-Method
to	O
obtain	O
the	O
2D	O
object	O
centers	O
on	O
the	O
LINEMOD	B-Material
dataset	I-Material
.	O
	
[	O
reference	O
]	O
does	O
not	O
provide	O
results	O
for	O
the	O
Bowl	O
and	O
the	O
Cup	O
,	O
hence	O
for	O
the	O
sake	O
of	O
comparison	O
the	O
average	O
is	O
taken	O
over	O
the	O
first	O
13	O
objects	O
.	O
	
section	O
:	O
The	O
LINEMOD	B-Material
Dataset	O
:	O
Comparison	O
with	O
[	O
2	O
]	O
	
Table	O
2	O
compares	O
our	O
BB8	B-Method
method	O
with	O
and	O
without	O
RGB	B-Method
refinement	I-Method
against	O
the	O
one	O
presented	O
in	O
[	O
reference	O
]	O
on	O
the	O
LINEMOD	B-Material
dataset	I-Material
.	O
	
Because	O
of	O
lack	O
of	O
space	O
,	O
we	O
provide	O
the	O
results	O
without	O
refinement	O
only	O
for	O
the	O
2D	B-Metric
Projection	I-Metric
metric	I-Metric
,	O
however	O
,	O
the	O
results	O
for	O
the	O
other	O
metrics	O
are	O
comparable	O
.	O
	
For	O
this	O
evaluation	O
,	O
we	O
used	O
the	O
results	O
of	O
our	O
detection	B-Method
method	I-Method
presented	O
in	O
Section	O
3.1	O
,	O
not	O
the	O
ground	O
truth	O
2D	O
object	O
center	O
.	O
	
Our	O
method	O
outperforms	O
[	O
reference	O
]	O
by	O
a	O
large	O
margin	O
:	O
15.6	O
%	O
for	O
2D	B-Task
Projection	I-Task
,	O
12.6	O
%	O
for	O
6D	O
Pose	O
and	O
28.4	O
%	O
for	O
the	O
5	O
cm	O
5	O
	
•	O
metric	B-Metric
.	O
	
Fig	O
.	O
	
7	O
shows	O
qualitative	O
results	O
for	O
our	O
method	O
on	O
this	O
dataset	O
.	O
	
For	O
most	O
of	O
the	O
images	O
,	O
the	O
two	O
bounding	O
boxes	O
,	O
for	O
the	O
ground	O
truth	O
pose	O
and	O
for	O
the	O
pose	O
we	O
estimate	O
,	O
overlap	O
almost	O
perfectly	O
.	O
	
section	O
:	O
The	O
Occlusion	B-Material
Dataset	I-Material
:	O
Robustness	B-Metric
to	O
Partial	O
Occlusions	O
	
The	O
Occlusion	B-Material
dataset	I-Material
was	O
created	O
by	O
[	O
reference	O
]	O
from	O
the	O
LINEMOD	B-Material
dataset	I-Material
.	O
	
The	O
partial	O
occlusions	O
make	O
it	O
significantly	O
more	O
difficult	O
,	O
and	O
to	O
the	O
best	O
of	O
our	O
knowledge	O
,	O
the	O
only	O
published	O
results	O
use	O
both	O
color	O
and	O
depth	O
data	O
.	O
	
[	O
reference	O
]	O
provide	O
results	O
using	O
only	O
color	O
images	O
,	O
but	O
limited	O
to	O
2D	B-Task
detection	I-Task
,	O
not	O
3D	B-Task
pose	I-Task
estimation	I-Task
.	O
	
We	O
only	O
use	O
images	O
from	O
the	O
LINEMOD	B-Material
dataset	I-Material
to	O
generate	O
our	O
training	O
images	O
by	O
using	O
the	O
approach	O
explained	O
in	O
Section	O
3.5	O
,	O
except	O
that	O
we	O
also	O
randomly	O
superimpose	O
objects	O
extracted	O
from	O
the	O
other	O
sequences	O
to	O
the	O
target	O
ob	O
-	O
ject	O
to	O
be	O
robust	O
to	O
occlusions	O
.	O
	
We	O
do	O
not	O
use	O
any	O
image	O
of	O
the	O
test	O
sequence	O
to	O
avoid	O
having	O
occlusions	O
similar	O
to	O
the	O
ones	O
presented	O
in	O
the	O
test	O
sequence	O
.	O
	
Although	O
all	O
the	O
poses	O
in	O
the	O
test	O
sets	O
are	O
not	O
visible	O
in	O
the	O
training	O
sequences	O
,	O
we	O
can	O
estimate	O
accurate	O
poses	O
with	O
a	O
2D	B-Metric
Projection	I-Metric
error	I-Metric
lower	O
than	O
15px	O
for	O
about	O
80	O
%	O
of	O
the	O
frames	O
for	O
these	O
seven	O
objects	O
.	O
	
We	O
do	O
not	O
report	O
the	O
performance	O
of	O
our	O
method	O
for	O
the	O
Eggbox	B-Task
,	O
as	O
more	O
than	O
70	O
%	O
of	O
close	O
poses	O
are	O
not	O
seen	O
in	O
the	O
training	O
sequence	O
.	O
	
Some	O
qualitative	O
results	O
are	O
shown	O
in	O
the	O
second	O
row	O
of	O
Fig	O
.	O
7	O
.	O
	
To	O
the	O
best	O
of	O
our	O
knowledge	O
,	O
we	O
are	O
the	O
first	O
to	O
present	O
results	O
on	O
this	O
dataset	O
using	O
color	O
images	O
only	O
.	O
	
section	O
:	O
The	O
T	B-Material
-	I-Material
LESS	I-Material
Dataset	O
:	O
Handling	O
Objects	O
with	O
an	O
Axis	O
of	O
Symmetry	O
	
The	O
test	O
sequences	O
of	O
the	O
T	B-Material
-	I-Material
LESS	I-Material
dataset	O
are	O
very	O
challenging	O
,	O
with	O
sometimes	O
multiple	O
instances	O
of	O
the	O
same	O
objects	O
and	O
a	O
high	O
amount	O
of	O
clutter	O
and	O
occlusion	O
.	O
	
We	O
considered	O
only	O
Scenes	O
#	O
1	O
,	O
#	O
2	O
,	O
#	O
4	O
,	O
#	O
5	O
,	O
and	O
#	O
7	O
in	O
our	O
experiments	O
.	O
	
It	O
is	O
also	O
difficult	O
to	O
compare	O
against	O
the	O
only	O
published	O
work	O
on	O
T	B-Material
-	I-Material
LESS	I-Material
[	O
reference	O
]	O
,	O
as	O
it	O
provides	O
the	O
6D	B-Metric
pose	I-Metric
metric	I-Metric
averaged	O
per	O
object	O
or	O
per	O
scene	O
,	O
computed	O
using	O
RGB	B-Material
-	I-Material
D	I-Material
data	O
,	O
while	O
,	O
to	O
the	O
best	O
of	O
our	O
knowledge	O
,	O
we	O
are	O
the	O
first	O
to	O
report	O
results	O
on	O
the	O
T	B-Material
-	I-Material
LESS	I-Material
dataset	O
using	O
RGB	B-Material
images	I-Material
Figure	O
7	O
.	O
	
Some	O
qualitative	O
results	O
.	O
	
First	O
row	O
:	O
LINEMOD	B-Material
dataset	I-Material
;	O
	
Second	O
row	O
:	O
Occlusion	B-Material
dataset	I-Material
;	O
	
Third	O
row	O
:	O
T	B-Material
-	I-Material
LESS	I-Material
dataset	O
(	O
for	O
objects	O
of	O
revolution	O
,	O
we	O
represent	O
the	O
pose	O
with	O
a	O
cylinder	O
rather	O
than	O
a	O
box	O
)	O
;	O
	
Last	O
row	O
:	O
Some	O
failure	O
cases	O
.	O
	
From	O
left	O
to	O
right	O
:	O
An	O
example	O
of	O
a	O
pose	O
rejected	O
by	O
the	O
2D	B-Method
Projections	I-Method
metric	I-Method
,	O
a	O
failure	O
due	O
to	O
the	O
lack	O
of	O
corresponding	O
poses	O
in	O
the	O
training	O
set	O
,	O
two	O
examples	O
from	O
T	B-Material
-	I-Material
LESS	I-Material
rejected	O
by	O
the	O
6D	B-Metric
pose	I-Metric
metric	I-Metric
,	O
and	O
one	O
failure	O
due	O
to	O
the	O
fact	O
that	O
some	O
objects	O
are	O
made	O
of	O
several	O
instances	O
of	O
another	O
object	O
.	O
	
Table	O
3	O
.	O
	
Our	O
quantitative	O
results	O
on	O
T	B-Material
-	I-Material
LESS	I-Material
	
[	O
reference	O
]	O
.	O
Most	O
of	O
the	O
errors	O
are	O
along	O
the	O
z	O
axis	O
of	O
the	O
camera	O
,	O
as	O
we	O
rely	O
on	O
color	O
images	O
.	O
	
only	O
.	O
	
Similarly	O
to	O
[	O
reference	O
]	O
,	O
we	O
evaluate	O
the	O
poses	O
with	O
more	O
than	O
10	O
%	O
of	O
the	O
object	O
surface	O
visible	O
in	O
the	O
ground	O
truth	O
poses	O
.	O
	
As	O
shown	O
in	O
Table	O
3	O
,	O
the	O
6D	B-Metric
Pose	I-Metric
average	I-Metric
per	I-Metric
scene	I-Metric
with	O
our	O
method	O
is	O
54	O
%	O
.	O
	
The	O
object	O
3D	O
orientation	O
and	O
translation	O
along	O
the	O
x	O
and	O
y	O
axes	O
of	O
the	O
camera	O
are	O
typically	O
very	O
well	O
estimated	O
,	O
and	O
most	O
of	O
the	O
error	O
is	O
along	O
the	O
z	O
axis	O
,	O
which	O
should	O
not	O
be	O
surprising	O
for	O
a	O
method	O
using	O
color	O
images	O
only	O
.	O
	
section	O
:	O
Computation	B-Metric
Times	I-Metric
	
Our	O
implementation	O
takes	O
140	O
ms	O
for	O
the	O
segmentation	B-Task
,	O
130	O
ms	O
for	O
the	O
pose	B-Task
prediction	I-Task
,	O
and	O
21	O
ms	O
for	O
each	O
refinement	B-Method
iteration	I-Method
,	O
on	O
an	O
Intel	O
Core	O
i7	O
-	O
5820	O
K	O
3.30	O
GHz	O
desktop	O
with	O
a	O
GeForce	O
TITAN	O
X.	O
	
If	O
there	O
is	O
only	O
one	O
object	O
of	O
interest	O
,	O
we	O
can	O
replace	O
VGG	B-Method
by	O
a	O
specific	O
network	O
with	O
a	O
simpler	O
architecture	O
,	O
the	O
computation	B-Metric
times	I-Metric
then	O
become	O
20	O
ms	O
for	O
the	O
segmentation	B-Task
and	O
12	O
ms	O
for	O
the	O
pose	B-Task
prediction	I-Task
,	O
with	O
similar	O
accuracy	B-Metric
.	O
	
section	O
:	O
Conclusion	O
	
Our	O
"	O
holistic	B-Method
"	I-Method
approach	I-Method
,	O
made	O
possible	O
by	O
the	O
remarkable	O
abilities	O
of	O
Deep	B-Method
Networks	I-Method
for	O
regression	B-Task
,	O
allowed	O
us	O
to	O
significantly	O
advance	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
on	O
3D	B-Task
pose	I-Task
estimation	I-Task
from	O
color	O
images	O
,	O
even	O
on	O
challenging	O
objects	O
from	O
the	O
T	B-Material
-	I-Material
LESS	I-Material
dataset	O
.	O
	
section	O
:	O
	
section	O
:	O
	
Acknowledgment	O
:	O
This	O
work	O
was	O
funded	O
by	O
the	O
Christian	O
Doppler	O
Laboratory	O
for	O
Semantic	B-Task
3D	I-Task
Computer	I-Task
Vision	I-Task
.	O
	
section	O
:	O
	
document	O
:	O
Simple	O
and	O
Accurate	O
Dependency	B-Task
Parsing	I-Task
Using	O
Bidirectional	B-Method
LSTM	I-Method
Feature	I-Method
Representations	I-Method
	
We	O
present	O
a	O
simple	O
and	O
effective	O
scheme	O
for	O
dependency	B-Task
parsing	I-Task
which	O
is	O
based	O
on	O
bidirectional	B-Method
-	I-Method
LSTMs	I-Method
(	O
BiLSTMs	B-Method
)	O
.	O
	
Each	O
sentence	O
token	O
is	O
associated	O
with	O
a	O
BiLSTM	O
vector	O
representing	O
the	O
token	O
in	O
its	O
sentential	O
context	O
,	O
and	O
feature	O
vectors	O
are	O
constructed	O
by	O
concatenating	O
a	O
few	O
BiLSTM	O
vectors	O
.	O
	
The	O
BiLSTM	B-Method
is	O
trained	O
jointly	O
with	O
the	O
parser	B-Metric
objective	I-Metric
,	O
resulting	O
in	O
very	O
effective	O
feature	B-Method
extractors	I-Method
for	O
parsing	B-Task
.	O
	
We	O
demonstrate	O
the	O
effectiveness	O
of	O
the	O
approach	O
by	O
applying	O
it	O
to	O
a	O
greedy	B-Method
transition	I-Method
-	I-Method
based	I-Method
parser	I-Method
as	O
well	O
as	O
to	O
a	O
globally	B-Method
optimized	I-Method
graph	I-Method
-	I-Method
based	I-Method
parser	I-Method
.	O
	
The	O
resulting	O
parsers	B-Method
have	O
very	O
simple	O
architectures	O
,	O
and	O
match	O
or	O
surpass	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
accuracies	B-Metric
on	O
English	B-Material
and	O
Chinese	B-Material
.	O
	
noitemsep	O
,	O
topsep=0pt	O
,	O
parsep=0pt	O
,	O
partopsep=0pt	O
1.0em	O
	
section	O
:	O
Introduction	O
	
The	O
focus	O
of	O
this	O
paper	O
is	O
on	O
feature	B-Task
representation	I-Task
for	O
dependency	B-Task
parsing	I-Task
,	O
using	O
recent	O
techniques	O
from	O
the	O
neural	B-Method
-	I-Method
networks	I-Method
(	O
‘	O
‘	O
deep	B-Method
learning	I-Method
’	O
’	O
)	O
literature	O
.	O
	
Modern	O
approaches	O
to	O
dependency	B-Task
parsing	I-Task
can	O
be	O
broadly	O
categorized	O
into	O
graph	B-Method
-	I-Method
based	I-Method
and	O
transition	B-Method
-	I-Method
based	I-Method
parsers	I-Method
.	O
	
Graph	B-Method
-	I-Method
based	I-Method
parsers	I-Method
treat	O
parsing	B-Task
as	O
a	O
search	B-Task
-	I-Task
based	I-Task
structured	I-Task
prediction	I-Task
problem	I-Task
in	O
which	O
the	O
goal	O
is	O
learning	O
a	O
scoring	O
function	O
over	O
dependency	O
trees	O
such	O
that	O
the	O
correct	O
tree	O
is	O
scored	O
above	O
all	O
other	O
trees	O
.	O
	
Transition	B-Method
-	I-Method
based	I-Method
parsers	I-Method
treat	O
parsing	B-Task
as	O
a	O
sequence	O
of	O
actions	O
that	O
produce	O
a	O
parse	O
tree	O
,	O
and	O
a	O
classifier	B-Method
is	O
trained	O
to	O
score	O
the	O
possible	O
actions	O
at	O
each	O
stage	O
of	O
the	O
process	O
and	O
guide	O
the	O
parsing	B-Task
process	I-Task
.	O
	
Perhaps	O
the	O
simplest	O
graph	B-Method
-	I-Method
based	I-Method
parsers	O
are	O
arc	B-Method
-	I-Method
factored	I-Method
(	I-Method
first	I-Method
order	I-Method
)	I-Method
models	I-Method
,	O
in	O
which	O
the	O
scoring	B-Method
function	I-Method
for	O
a	O
tree	O
decomposes	O
over	O
the	O
individual	O
arcs	O
of	O
the	O
tree	O
.	O
	
More	O
elaborate	O
models	O
look	O
at	O
larger	O
(	O
overlapping	O
)	O
parts	O
,	O
requiring	O
more	O
sophisticated	O
inference	B-Method
and	I-Method
training	I-Method
algorithms	I-Method
.	O
	
The	O
basic	O
transition	B-Method
-	I-Method
based	I-Method
parsers	I-Method
work	O
in	O
a	O
greedy	O
manner	O
,	O
performing	O
a	O
series	O
of	O
locally	O
-	O
optimal	O
decisions	O
,	O
and	O
boast	O
very	O
fast	O
parsing	B-Metric
speeds	I-Metric
.	O
	
More	O
advanced	O
transition	B-Method
-	I-Method
based	I-Method
parsers	I-Method
introduce	O
some	O
search	O
into	O
the	O
process	O
using	O
a	O
beam	B-Method
or	I-Method
dynamic	I-Method
programming	I-Method
.	O
	
Regardless	O
of	O
the	O
details	O
of	O
the	O
parsing	B-Method
framework	I-Method
being	O
used	O
,	O
a	O
crucial	O
step	O
in	O
parser	B-Task
design	I-Task
is	O
choosing	O
the	O
right	O
feature	O
function	O
for	O
the	O
underlying	O
statistical	B-Method
model	I-Method
.	O
	
Recent	O
work	O
(	O
see	O
Section	O
[	O
reference	O
]	O
for	O
an	O
overview	O
)	O
attempt	O
to	O
alleviate	O
parts	O
of	O
the	O
feature	B-Task
function	I-Task
design	I-Task
problem	I-Task
by	O
moving	O
from	O
linear	B-Method
to	I-Method
non	I-Method
-	I-Method
linear	I-Method
models	I-Method
,	O
enabling	O
the	O
modeler	O
to	O
focus	O
on	O
a	O
small	O
set	O
of	O
‘	O
‘	O
core	O
’	O
’	O
features	O
and	O
leaving	O
it	O
up	O
to	O
the	O
machine	B-Method
-	I-Method
learning	I-Method
machinery	I-Method
to	O
come	O
up	O
with	O
good	O
feature	O
combinations	O
.	O
	
However	O
,	O
the	O
need	O
to	O
carefully	O
define	O
a	O
set	O
of	O
core	O
features	O
remains	O
.	O
	
For	O
example	O
,	O
the	O
work	O
of	O
chen2014fast	O
uses	O
18	O
different	O
elements	O
in	O
its	O
feature	O
function	O
,	O
while	O
the	O
work	O
of	O
pei2015effective	O
uses	O
21	O
different	O
elements	O
.	O
	
Other	O
works	O
,	O
notably	O
dyer2015transitionbased	O
and	O
le2014insideoutside	O
,	O
propose	O
more	O
sophisticated	O
feature	B-Method
representations	I-Method
,	O
in	O
which	O
the	O
feature	B-Method
engineering	I-Method
is	O
replaced	O
with	O
architecture	B-Method
engineering	I-Method
.	O
	
In	O
this	O
work	O
,	O
we	O
suggest	O
an	O
approach	O
which	O
is	O
much	O
simpler	O
in	O
terms	O
of	O
both	O
feature	B-Task
engineering	I-Task
and	O
architecture	B-Task
engineering	I-Task
.	O
	
Our	O
proposal	O
(	O
Section	O
[	O
reference	O
]	O
)	O
is	O
centered	O
around	O
BiRNNs	B-Method
,	O
and	O
more	O
specifically	O
BiLSTMs	B-Method
,	O
which	O
are	O
strong	B-Method
and	I-Method
trainable	I-Method
sequence	I-Method
models	I-Method
(	O
see	O
Section	O
[	O
reference	O
]	O
)	O
.	O
	
The	O
BiLSTM	B-Method
excels	O
at	O
representing	O
elements	O
in	O
a	O
sequence	O
(	O
i.e.	O
,	O
words	O
)	O
together	O
with	O
their	O
contexts	O
,	O
capturing	O
the	O
element	O
and	O
an	O
‘	O
‘	O
infinite	O
’	O
’	O
window	O
around	O
it	O
.	O
	
We	O
represent	O
each	O
word	O
by	O
its	O
BiLSTM	B-Method
encoding	I-Method
,	O
and	O
use	O
a	O
concatenation	O
of	O
a	O
minimal	O
set	O
of	O
such	O
BiLSTM	B-Method
encodings	I-Method
as	O
our	O
feature	O
function	O
,	O
which	O
is	O
then	O
passed	O
to	O
a	O
non	B-Method
-	I-Method
linear	I-Method
scoring	I-Method
function	I-Method
(	O
multi	B-Method
-	I-Method
layer	I-Method
perceptron	I-Method
)	O
.	O
	
Crucially	O
,	O
the	O
BiLSTM	B-Method
is	O
trained	O
with	O
the	O
rest	O
of	O
the	O
parser	B-Method
in	O
order	O
to	O
learn	O
a	O
good	O
feature	B-Method
representation	I-Method
for	O
the	O
parsing	B-Task
problem	I-Task
.	O
	
If	O
we	O
set	O
aside	O
the	O
inherent	O
complexity	O
of	O
the	O
BiLSTM	B-Method
itself	I-Method
and	O
treat	O
it	O
as	O
a	O
black	O
box	O
,	O
our	O
proposal	O
results	O
in	O
a	O
pleasingly	O
simple	O
feature	B-Method
extractor	I-Method
.	O
	
We	O
demonstrate	O
the	O
effectiveness	O
of	O
the	O
approach	O
by	O
using	O
the	O
BiLSTM	B-Method
feature	I-Method
extractor	I-Method
in	O
two	O
parsing	B-Method
architectures	I-Method
,	O
transition	B-Method
-	I-Method
based	I-Method
(	O
Section	O
[	O
reference	O
]	O
)	O
as	O
well	O
as	O
a	O
graph	B-Method
-	I-Method
based	I-Method
(	O
Section	O
[	O
reference	O
]	O
)	O
.	O
	
In	O
the	O
graph	B-Method
-	I-Method
based	I-Method
parser	O
,	O
we	O
jointly	O
train	O
a	O
structured	B-Method
-	I-Method
prediction	I-Method
model	I-Method
on	O
top	O
of	O
a	O
BiLSTM	B-Method
,	O
propagating	O
errors	O
from	O
the	O
structured	O
objective	O
all	O
the	O
way	O
back	O
to	O
the	O
BiLSTM	B-Method
feature	I-Method
-	I-Method
encoder	I-Method
.	O
	
To	O
the	O
best	O
of	O
our	O
knowledge	O
,	O
we	O
are	O
the	O
first	O
to	O
perform	O
such	O
end	O
-	O
to	O
-	O
end	B-Task
training	I-Task
of	O
a	O
structured	B-Method
prediction	I-Method
model	I-Method
and	O
a	O
recurrent	B-Method
feature	I-Method
extractor	I-Method
for	O
non	O
-	O
sequential	O
outputs	O
.	O
	
Aside	O
from	O
the	O
novelty	O
of	O
the	O
BiLSTM	B-Method
feature	I-Method
extractor	I-Method
and	O
the	O
end	B-Task
-	I-Task
to	I-Task
-	I-Task
end	I-Task
structured	I-Task
training	I-Task
,	O
we	O
rely	O
on	O
existing	O
models	O
and	O
techniques	O
from	O
the	O
parsing	B-Task
and	I-Task
structured	I-Task
prediction	I-Task
literature	I-Task
.	O
	
We	O
stick	O
to	O
the	O
simplest	O
parsers	B-Method
in	O
each	O
category	O
–	O
greedy	B-Method
inference	I-Method
for	O
the	O
transition	B-Method
-	I-Method
based	I-Method
architecture	I-Method
,	O
and	O
a	O
first	B-Method
-	I-Method
order	I-Method
,	I-Method
arc	I-Method
-	I-Method
factored	I-Method
model	I-Method
for	O
the	O
graph	B-Method
-	I-Method
based	I-Method
architecture	O
.	O
	
Despite	O
the	O
simplicity	O
of	O
the	O
parsing	B-Method
architectures	I-Method
and	O
the	O
feature	O
functions	O
,	O
we	O
achieve	O
near	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
parsing	B-Metric
accuracies	I-Metric
in	O
both	O
English	B-Material
(	O
93.1	O
UAS	B-Metric
)	O
and	O
Chinese	B-Material
(	O
86.6	O
UAS	B-Metric
)	O
,	O
using	O
a	O
first	B-Method
-	I-Method
order	I-Method
parser	I-Method
with	O
two	O
features	O
and	O
while	O
training	O
solely	O
on	O
Treebank	B-Material
data	I-Material
,	O
without	O
relying	O
on	O
semi	B-Method
-	I-Method
supervised	I-Method
signals	I-Method
such	O
as	O
pre	O
-	O
trained	O
word	O
embeddings	O
,	O
word	B-Method
-	I-Method
clusters	I-Method
,	O
or	O
techniques	O
such	O
as	O
tri	B-Method
-	I-Method
training	I-Method
.	O
	
When	O
also	O
including	O
pre	O
-	O
trained	O
word	O
embeddings	O
,	O
we	O
obtain	O
further	O
improvements	O
,	O
with	O
accuracies	B-Metric
of	O
93.9	O
UAS	B-Metric
(	O
English	B-Material
)	O
and	O
87.6	O
UAS	B-Metric
(	O
Chinese	B-Material
)	O
for	O
a	O
greedy	B-Method
transition	I-Method
-	I-Method
based	I-Method
parser	I-Method
with	O
11	O
features	O
,	O
and	O
93.6	O
UAS	B-Metric
(	O
En	B-Material
)	O
/	O
87.4	O
(	O
Ch	B-Material
)	O
for	O
a	O
greedy	B-Method
transition	I-Method
-	I-Method
based	I-Method
parser	I-Method
with	O
4	O
features	O
.	O
	
section	O
:	O
Background	O
and	O
Notation	O
	
paragraph	O
:	O
Notation	O
	
We	O
use	O
to	O
denote	O
a	O
sequence	O
of	O
vectors	O
.	O
	
is	O
a	O
function	O
parameterized	O
with	O
parameters	O
.	O
	
We	O
write	O
as	O
shorthand	O
for	O
–	O
an	O
instantiation	O
of	O
with	O
a	O
specific	O
set	O
of	O
parameters	O
.	O
	
We	O
use	O
to	O
denote	O
a	O
vector	O
concatenation	O
operation	O
,	O
and	O
to	O
denote	O
an	O
indexing	O
operation	O
taking	O
the	O
th	O
element	O
of	O
a	O
vector	O
.	O
	
subsection	O
:	O
Feature	O
Functions	O
in	O
Dependency	B-Task
Parsing	I-Task
	
Traditionally	O
,	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
parsers	B-Method
rely	O
on	O
linear	B-Method
models	I-Method
over	O
hand	O
-	O
crafted	O
feature	O
functions	O
.	O
	
The	O
feature	O
functions	O
look	O
at	O
core	O
components	O
(	O
e.g.	O
‘	O
‘	O
word	O
on	O
top	O
of	O
stack	O
’	O
’	O
,	O
	
‘	O
	
‘	O
leftmost	O
child	O
of	O
the	O
second	O
-	O
to	O
-	O
top	O
word	O
on	O
the	O
stack	O
’	O
’	O
,	O
	
‘	O
	
‘	O
distance	O
between	O
the	O
head	O
and	O
the	O
modifier	O
words	O
’	O
’	O
)	O
,	O
and	O
are	O
comprised	O
of	O
several	O
templates	O
,	O
where	O
each	O
template	O
instantiates	O
a	O
binary	O
indicator	O
function	O
over	O
a	O
conjunction	O
of	O
core	O
elements	O
(	O
resulting	O
in	O
features	O
of	O
the	O
form	O
	
‘	O
	
‘	O
word	O
on	O
top	O
of	O
stack	O
is	O
X	O
and	O
leftmost	O
child	O
is	O
Y	O
and	O
…	O
’’	O
)	O
.	O
	
The	O
design	O
of	O
the	O
feature	O
function	O
–	O
which	O
components	O
to	O
consider	O
and	O
which	O
combinations	O
of	O
components	O
to	O
include	O
–	O
is	O
a	O
major	O
challenge	O
in	O
parser	B-Task
design	I-Task
.	O
	
Once	O
a	O
good	O
feature	O
function	O
is	O
proposed	O
in	O
a	O
paper	O
it	O
is	O
usually	O
adopted	O
in	O
later	O
works	O
,	O
and	O
sometimes	O
tweaked	O
to	O
improve	O
performance	O
.	O
	
Examples	O
of	O
good	O
feature	O
functions	O
are	O
the	O
feature	B-Method
-	I-Method
set	I-Method
proposed	O
by	O
zhang11acl	O
for	O
transition	B-Task
-	I-Task
based	I-Task
parsing	I-Task
(	O
including	O
roughly	O
20	O
core	O
components	O
and	O
72	O
feature	O
templates	O
)	O
,	O
and	O
the	O
feature	O
-	O
set	O
proposed	O
by	O
mst	B-Method
for	O
graph	B-Method
-	I-Method
based	I-Method
parsing	O
,	O
with	O
the	O
paper	O
listing	O
18	O
templates	O
for	O
a	O
first	B-Method
-	I-Method
order	I-Method
parser	I-Method
,	O
while	O
the	O
first	B-Method
order	I-Method
feature	I-Method
-	I-Method
extractor	I-Method
in	O
the	O
actual	O
implementation	O
’s	O
code	O
(	O
MSTParser	B-Method
)	O
includes	O
roughly	O
a	O
hundred	O
feature	O
templates	O
.	O
	
The	O
core	O
features	O
in	O
a	O
transition	B-Method
-	I-Method
based	I-Method
parser	I-Method
usually	O
look	O
at	O
information	O
such	O
as	O
the	O
word	O
-	O
identity	O
and	O
part	O
-	O
of	O
-	O
speech	O
(	O
POS	B-Metric
)	O
tags	O
of	O
a	O
fixed	O
number	O
of	O
words	O
on	O
top	O
of	O
the	O
stack	O
,	O
a	O
fixed	O
number	O
of	O
words	O
on	O
the	O
top	O
of	O
the	O
buffer	O
,	O
the	O
modifiers	O
(	O
usually	O
left	O
-	O
most	O
and	O
right	O
-	O
most	O
)	O
of	O
items	O
on	O
the	O
stack	O
and	O
on	O
the	O
buffer	O
,	O
the	O
number	O
of	O
modifiers	O
of	O
these	O
elements	O
,	O
parents	O
of	O
words	O
on	O
the	O
stack	O
,	O
and	O
the	O
length	O
of	O
the	O
spans	O
spanned	O
by	O
the	O
words	O
on	O
the	O
stack	O
.	O
	
The	O
core	O
features	O
of	O
a	O
first	O
-	O
order	O
graph	B-Method
-	I-Method
based	I-Method
parser	O
usually	O
take	O
into	O
account	O
the	O
word	O
and	O
POS	B-Metric
of	O
the	O
head	O
and	O
modifier	O
items	O
,	O
as	O
well	O
as	O
POS	B-Metric
-	O
tags	O
of	O
the	O
items	O
around	O
the	O
head	O
and	O
modifier	O
,	O
POS	B-Metric
tags	O
of	O
items	O
between	O
the	O
head	O
and	O
modifier	O
,	O
and	O
the	O
distance	O
and	O
direction	O
between	O
the	O
head	O
and	O
modifier	O
.	O
	
subsection	O
:	O
Related	O
Research	O
Efforts	O
	
Coming	O
up	O
with	O
a	O
good	O
feature	O
-	O
set	O
for	O
a	O
parser	B-Method
is	O
a	O
hard	O
and	O
time	O
consuming	O
task	O
,	O
and	O
many	O
researchers	O
attempt	O
to	O
reduce	O
the	O
required	O
manual	O
effort	O
.	O
	
The	O
work	O
of	O
lei	O
-	O
EtAl:2014:P14	O
-	O
1	O
suggests	O
a	O
low	B-Method
-	I-Method
rank	I-Method
tensor	I-Method
representation	I-Method
to	O
automatically	O
find	O
good	O
feature	O
combinations	O
.	O
	
taubtabib2015template	O
suggest	O
a	O
kernel	B-Method
-	I-Method
based	I-Method
approach	I-Method
to	O
implicitly	O
consider	O
all	O
possible	O
feature	O
combinations	O
over	O
sets	O
of	O
core	O
-	O
features	O
.	O
	
The	O
recent	O
popularity	O
of	O
neural	B-Method
networks	I-Method
prompted	O
a	O
move	O
from	O
templates	B-Method
of	I-Method
sparse	I-Method
,	I-Method
binary	I-Method
indicator	I-Method
features	I-Method
to	O
dense	B-Method
core	I-Method
feature	I-Method
encodings	I-Method
fed	O
into	O
non	B-Method
-	I-Method
linear	I-Method
classifiers	I-Method
.	O
	
chen2014fast	O
encode	O
each	O
core	O
feature	O
of	O
a	O
greedy	B-Method
transition	I-Method
-	I-Method
based	I-Method
parser	I-Method
as	O
a	O
dense	O
low	O
-	O
dimensional	O
vector	O
,	O
and	O
the	O
vectors	O
are	O
then	O
concatenated	O
and	O
fed	O
into	O
a	O
non	B-Method
-	I-Method
linear	I-Method
classifier	I-Method
(	O
multi	B-Method
-	I-Method
layer	I-Method
perceptron	I-Method
)	O
which	O
can	O
potentially	O
capture	O
arbitrary	O
feature	O
combinations	O
.	O
	
weiss2015structured	O
showed	O
further	O
gains	O
using	O
the	O
same	O
approach	O
coupled	O
with	O
a	O
somewhat	O
improved	O
set	O
of	O
core	O
features	O
,	O
a	O
more	O
involved	O
network	B-Method
architecture	I-Method
with	O
skip	B-Method
-	I-Method
layers	I-Method
,	O
beam	B-Method
search	I-Method
-	I-Method
decoding	I-Method
,	O
and	O
careful	O
hyper	B-Method
-	I-Method
parameter	I-Method
tuning	I-Method
.	O
	
pei2015effective	O
apply	O
a	O
similar	O
methodology	O
to	O
graph	B-Method
-	I-Method
based	I-Method
parsing	O
.	O
	
While	O
the	O
move	O
to	O
neural	B-Method
-	I-Method
network	I-Method
classifiers	I-Method
alleviates	O
the	O
need	O
for	O
hand	O
-	O
crafting	O
feature	O
-	O
combinations	O
,	O
the	O
need	O
to	O
carefully	O
define	O
a	O
set	O
of	O
core	O
features	O
remain	O
.	O
	
For	O
example	O
,	O
the	O
feature	B-Method
representation	I-Method
in	O
chen2014fast	O
is	O
a	O
concatenation	O
of	O
18	O
word	O
vectors	O
,	O
18	O
POS	B-Metric
vectors	O
and	O
12	O
dependency	O
-	O
label	O
vectors	O
.	O
	
The	O
above	O
works	O
tackle	O
the	O
effort	O
in	O
hand	O
-	O
crafting	O
effective	O
feature	B-Task
combinations	I-Task
.	O
	
A	O
different	O
line	O
of	O
work	O
attacks	O
the	O
feature	B-Task
-	I-Task
engineering	I-Task
problem	I-Task
by	O
suggesting	O
novel	O
neural	B-Method
-	I-Method
network	I-Method
architectures	I-Method
for	O
encoding	O
the	O
parser	O
state	O
,	O
including	O
intermediately	O
-	O
built	O
subtrees	O
,	O
as	O
vectors	O
which	O
are	O
then	O
fed	O
to	O
non	B-Method
-	I-Method
linear	I-Method
classifiers	I-Method
.	O
	
Titov	O
and	O
Henderson	O
encode	O
the	O
parser	O
state	O
using	O
incremental	B-Method
sigmoid	I-Method
-	I-Method
belief	I-Method
networks	I-Method
titov	O
-	O
henderson:2007:IWPT2007	O
.	O
	
In	O
the	O
work	O
of	O
dyer2015transitionbased	O
,	O
the	O
entire	O
stack	O
and	O
buffer	O
of	O
a	O
transition	B-Method
-	I-Method
based	I-Method
parser	I-Method
are	O
encoded	O
as	O
a	O
stack	B-Method
-	I-Method
LSTMs	I-Method
,	O
where	O
each	O
stack	O
element	O
is	O
itself	O
based	O
on	O
a	O
compositional	B-Method
representation	I-Method
of	I-Method
parse	I-Method
trees	I-Method
.	O
	
le2014insideoutside	O
encode	O
each	O
tree	O
node	O
as	O
two	O
compositional	B-Method
representations	I-Method
capturing	O
the	O
inside	O
and	O
outside	O
structures	O
around	O
the	O
node	O
,	O
and	O
feed	O
the	O
representations	O
into	O
a	O
reranker	B-Method
.	O
	
A	O
similar	O
reranking	B-Method
approach	I-Method
,	O
this	O
time	O
based	O
on	O
convolutional	B-Method
neural	I-Method
networks	I-Method
,	O
is	O
taken	O
by	O
zhu2015reranking	O
.	O
	
Finally	O
,	O
in	O
kiperwasser2016ef	O
we	O
present	O
an	O
Easy	B-Method
-	I-Method
First	I-Method
parser	I-Method
based	O
on	O
a	O
novel	O
hierarchical	B-Method
-	I-Method
LSTM	I-Method
tree	I-Method
encoding	I-Method
.	O
	
In	O
contrast	O
to	O
these	O
,	O
the	O
approach	O
we	O
present	O
in	O
this	O
work	O
results	O
in	O
much	O
simpler	O
feature	O
functions	O
,	O
without	O
resorting	O
to	O
elaborate	O
network	B-Method
architectures	I-Method
or	O
compositional	B-Method
tree	I-Method
representations	I-Method
.	O
	
Work	O
by	O
vinlays2014grammar	O
employs	O
a	O
sequence	B-Method
-	I-Method
to	I-Method
-	I-Method
sequence	I-Method
with	I-Method
attention	I-Method
architecture	I-Method
for	O
constituency	B-Task
parsing	I-Task
.	O
	
Each	O
token	O
in	O
the	O
input	O
sentence	O
is	O
encoded	O
in	O
a	O
deep	B-Method
-	I-Method
BiLSTM	I-Method
representation	I-Method
,	O
and	O
then	O
the	O
tokens	O
are	O
fed	O
as	O
input	O
to	O
a	O
deep	B-Method
-	I-Method
LSTM	I-Method
that	O
predicts	O
a	O
sequence	O
of	O
bracketing	O
actions	O
based	O
on	O
the	O
already	O
predicted	O
bracketing	O
as	O
well	O
as	O
the	O
encoded	O
BiLSTM	O
vectors	O
.	O
	
A	O
trainable	B-Method
attention	I-Method
mechanism	I-Method
is	O
used	O
to	O
guide	O
the	O
parser	B-Method
to	O
relevant	O
BiLSTM	O
vectors	O
at	O
each	O
stage	O
.	O
	
This	O
architecture	O
shares	O
with	O
ours	O
the	O
use	O
of	O
BiLSTM	B-Method
encoding	I-Method
and	O
end	B-Task
-	I-Task
to	I-Task
-	I-Task
end	I-Task
training	I-Task
.	O
	
The	O
sequence	O
of	O
bracketing	O
actions	O
can	O
be	O
interpreted	O
as	O
a	O
sequence	O
of	O
Shift	B-Method
and	I-Method
Reduce	I-Method
operations	I-Method
of	O
a	O
transition	B-Method
-	I-Method
based	I-Method
parser	I-Method
.	O
	
However	O
,	O
while	O
the	O
parser	B-Method
of	O
Vinyals	O
et	O
al	O
.	O
relies	O
on	O
a	O
trainable	B-Method
attention	I-Method
mechanism	I-Method
for	O
focusing	O
on	O
specific	O
BiLSTM	O
vectors	O
,	O
parsers	B-Method
in	O
the	O
transition	B-Method
-	I-Method
based	I-Method
family	I-Method
we	O
use	O
in	O
Section	O
[	O
reference	O
]	O
use	O
a	O
human	B-Method
designed	I-Method
stack	I-Method
and	I-Method
buffer	I-Method
mechanism	I-Method
to	O
manually	O
direct	O
the	O
parser	O
’s	O
attention	O
.	O
	
While	O
the	O
effectiveness	O
of	O
the	O
trainable	B-Method
attention	I-Method
approach	I-Method
is	O
impressive	O
,	O
the	O
stack	O
-	O
and	O
-	O
buffer	O
guidance	O
of	O
transition	B-Method
-	I-Method
based	I-Method
parsers	I-Method
results	O
in	O
more	O
robust	O
learning	B-Task
.	O
	
Indeed	O
,	O
work	O
by	O
cross2016incremental	O
,	O
published	O
while	O
working	O
on	O
the	O
camera	O
-	O
ready	O
version	O
of	O
this	O
paper	O
,	O
show	O
that	O
the	O
same	O
methodology	O
as	O
ours	O
is	O
highly	O
effective	O
also	O
for	O
greedy	B-Task
,	I-Task
transition	I-Task
-	I-Task
based	I-Task
constituency	I-Task
parsing	I-Task
,	O
surpassing	O
the	O
beam	B-Method
-	I-Method
based	I-Method
architecture	I-Method
of	O
Vinyals	O
et	O
al	O
.	O
	
(	O
88.3F	O
vs.	O
89.8F	O
points	O
)	O
when	O
trained	O
on	O
the	O
Penn	B-Material
Treebank	I-Material
dataset	I-Material
and	O
without	O
using	O
orthogonal	B-Method
methods	I-Method
such	O
as	O
ensembling	B-Method
and	O
up	B-Method
-	I-Method
training	I-Method
.	O
	
subsection	O
:	O
Bidirectional	B-Method
Recurrent	I-Method
Neural	I-Method
Networks	I-Method
	
Recurrent	B-Method
neural	I-Method
networks	I-Method
(	O
RNNs	B-Method
)	O
are	O
statistical	B-Method
learners	I-Method
for	O
modeling	O
sequential	O
data	O
.	O
	
An	O
RNN	B-Method
allows	O
one	O
to	O
model	O
the	O
th	O
element	O
in	O
the	O
sequence	O
based	O
on	O
the	O
past	O
–	O
the	O
elements	O
up	O
to	O
and	O
including	O
it	O
.	O
	
The	O
RNN	B-Method
model	O
provides	O
a	O
framework	O
for	O
conditioning	O
on	O
the	O
entire	O
history	O
without	O
resorting	O
to	O
the	O
Markov	O
assumption	O
which	O
is	O
traditionally	O
used	O
for	O
modeling	B-Task
sequences	I-Task
.	O
	
RNNs	B-Method
were	O
shown	O
to	O
be	O
capable	O
of	O
learning	O
to	O
count	O
,	O
as	O
well	O
as	O
to	O
model	O
line	O
lengths	O
and	O
complex	O
phenomena	O
such	O
as	O
bracketing	O
and	O
code	B-Task
indentation	I-Task
.	O
	
Our	O
proposed	O
feature	B-Method
extractors	I-Method
are	O
based	O
on	O
a	O
bidirectional	B-Method
recurrent	I-Method
neural	I-Method
network	I-Method
(	O
BiRNN	B-Method
)	O
,	O
an	O
extension	O
of	O
RNNs	B-Method
that	O
take	O
into	O
account	O
both	O
the	O
past	O
and	O
the	O
future	O
.	O
	
We	O
use	O
a	O
specific	O
flavor	O
of	O
RNN	B-Method
called	O
a	O
long	B-Method
short	I-Method
-	I-Method
term	I-Method
memory	I-Method
network	I-Method
(	O
LSTM	B-Method
)	I-Method
.	O
	
For	O
brevity	O
,	O
we	O
treat	O
RNN	B-Method
as	O
an	O
abstraction	O
,	O
without	O
getting	O
into	O
the	O
mathematical	O
details	O
of	O
the	O
implementation	O
of	O
the	O
RNNs	B-Method
and	O
LSTMs	B-Method
.	O
	
For	O
further	O
details	O
on	O
RNNs	B-Method
and	O
LSTMs	B-Method
,	O
the	O
reader	O
is	O
referred	O
to	O
goldberg	O
-	O
primer	O
and	O
cho	O
-	O
primer	O
.	O
	
The	O
recurrent	B-Method
neural	I-Method
network	I-Method
(	O
RNN	B-Method
)	O
abstraction	O
is	O
a	O
parameterized	B-Method
function	I-Method
mapping	O
a	O
sequence	O
of	O
input	O
vectors	O
,	O
to	O
a	O
sequence	O
of	O
output	O
vectors	O
.	O
	
Each	O
output	O
vector	O
is	O
conditioned	O
on	O
all	O
the	O
input	O
vectors	O
,	O
and	O
can	O
be	O
thought	O
of	O
as	O
a	O
summary	O
of	O
the	O
prefix	O
of	O
.	O
	
In	O
our	O
notation	O
,	O
we	O
ignore	O
the	O
intermediate	O
vectors	O
and	O
take	O
the	O
output	O
of	O
to	O
be	O
the	O
vector	O
.	O
	
A	O
bidirectional	O
RNN	B-Method
is	O
composed	O
of	O
two	O
RNNs	B-Method
,	O
and	O
,	O
one	O
reading	O
the	O
sequence	O
in	O
its	O
regular	O
order	O
,	O
and	O
the	O
other	O
reading	O
it	O
in	O
reverse	O
.	O
	
Concretely	O
,	O
given	O
a	O
sequence	O
of	O
vectors	O
and	O
a	O
desired	O
index	O
,	O
the	O
function	O
is	O
defined	O
as	O
:	O
The	O
vector	O
is	O
then	O
a	O
representation	O
of	O
the	O
th	O
item	O
in	O
,	O
taking	O
into	O
account	O
both	O
the	O
entire	O
history	O
and	O
the	O
entire	O
future	O
by	O
concatenating	O
the	O
matching	B-Method
Rnn	I-Method
	
s.	O
	
We	O
can	O
view	O
the	O
BiRNN	B-Method
encoding	O
of	O
an	O
item	O
as	O
representing	O
the	O
item	O
together	O
with	O
a	O
context	O
of	O
an	O
infinite	O
window	O
around	O
it	O
.	O
	
paragraph	O
:	O
Computational	B-Metric
Complexity	I-Metric
	
Computing	O
the	O
BiRNN	B-Method
vectors	O
encoding	O
of	O
the	O
th	O
element	O
of	O
a	O
sequence	O
requires	O
time	O
for	O
computing	O
the	O
two	O
RNNs	B-Method
and	O
concatenating	O
their	O
outputs	O
.	O
	
A	O
naive	O
approach	O
of	O
computing	O
the	O
bidirectional	B-Method
representation	I-Method
of	I-Method
all	I-Method
elements	I-Method
result	O
in	O
computation	B-Task
.	O
	
However	O
,	O
it	O
is	O
trivial	O
to	O
compute	O
the	O
BiRNN	B-Method
encoding	O
of	O
all	O
sequence	O
items	O
in	O
linear	O
time	O
by	O
pre	O
-	O
computing	O
and	O
,	O
keeping	O
the	O
intermediate	B-Method
representations	I-Method
,	O
and	O
concatenating	O
the	O
required	O
elements	O
as	O
needed	O
.	O
	
paragraph	O
:	O
BiRNN	B-Method
Training	O
	
Initially	O
,	O
the	O
BiRNN	B-Method
encodings	O
do	O
not	O
capture	O
any	O
particular	O
information	O
.	O
	
During	O
training	O
,	O
the	O
encoded	O
vectors	O
are	O
fed	O
into	O
further	O
network	B-Method
layers	I-Method
,	O
until	O
at	O
some	O
point	O
a	O
prediction	O
is	O
made	O
,	O
and	O
a	O
loss	O
is	O
incurred	O
.	O
	
The	O
back	B-Method
-	I-Method
propagation	I-Method
algorithm	I-Method
is	O
used	O
to	O
compute	O
the	O
gradients	O
of	O
all	O
the	O
parameters	O
in	O
the	O
network	O
(	O
including	O
the	O
BiRNN	B-Method
parameters	O
)	O
with	O
respect	O
to	O
the	O
loss	O
,	O
and	O
an	O
optimizer	B-Method
is	O
used	O
to	O
update	O
the	O
parameters	O
according	O
to	O
the	O
gradients	O
.	O
	
The	O
training	O
procedure	O
causes	O
the	O
BiRNN	B-Method
function	O
to	O
extract	O
from	O
the	O
input	O
sequence	O
the	O
relevant	O
information	O
for	O
the	O
task	O
task	O
at	O
hand	O
.	O
	
paragraph	O
:	O
Going	O
deeper	O
	
We	O
use	O
a	O
variant	O
of	O
deep	O
bidirectional	O
RNN	B-Method
(	O
or	O
-	O
layer	O
BiRNN	B-Method
)	O
which	O
is	O
composed	O
of	O
BiRNN	B-Method
functions	O
that	O
feed	O
into	O
each	O
other	O
:	O
the	O
output	O
of	O
becomes	O
the	O
input	O
of	O
.	O
	
Stacking	O
BiRNNs	B-Method
in	O
this	O
way	O
has	O
been	O
empirically	O
shown	O
to	O
be	O
effective	O
.	O
	
In	O
this	O
work	O
,	O
we	O
use	O
BiRNNs	B-Method
and	O
deep	O
-	O
BiRNNs	B-Method
interchangeably	O
,	O
specifying	O
the	O
number	O
of	O
layers	O
when	O
needed	O
.	O
	
paragraph	O
:	O
Historical	O
Notes	O
	
RNNs	B-Method
were	O
introduced	O
by	O
elman1990finding	O
,	O
and	O
extended	O
to	O
BiRNNs	B-Method
by	O
schuster1997bidirectional	O
.	O
	
The	O
LSTM	O
variant	O
of	O
RNNs	B-Method
is	O
due	O
to	O
hochreiter1997long	O
.	O
	
BiLSTMs	B-Method
were	O
recently	O
popularized	O
by	O
graves2008supervised	O
,	O
and	O
deep	O
BiRNNs	B-Method
were	O
introduced	O
to	O
NLP	B-Task
by	O
irsoy2014opinion	O
,	O
who	O
used	O
them	O
for	O
sequence	B-Task
tagging	I-Task
.	O
	
In	O
the	O
context	O
of	O
parsing	B-Task
,	O
lewis2016lstm	O
and	O
Vaswani:2016:NAACL	O
use	O
a	O
BiLSTM	B-Method
sequence	I-Method
tagging	I-Method
model	I-Method
to	O
assign	O
a	O
CCG	O
supertag	O
for	O
each	O
token	O
in	O
the	O
sentence	O
.	O
	
lewis2016lstm	O
feeds	O
the	O
resulting	O
supertags	O
sequence	O
into	O
an	O
A	B-Method
*	I-Method
CCG	I-Method
parser	I-Method
.	O
	
Vaswani:2016:NAACL	O
adds	O
an	O
additional	O
layer	O
of	O
LSTM	B-Method
which	O
receives	O
the	O
BiLSTM	B-Method
representation	I-Method
together	O
with	O
the	O
k	O
-	O
best	O
supertags	O
for	O
each	O
word	O
and	O
outputs	O
the	O
most	O
likely	O
supertag	O
given	O
previous	O
tags	O
,	O
and	O
then	O
feeds	O
the	O
predicted	O
supertags	O
to	O
a	O
discriminitively	B-Method
trained	I-Method
parser	I-Method
.	O
	
In	O
both	O
works	O
,	O
the	O
BiLSTM	B-Method
is	O
trained	O
to	O
produce	O
accurate	O
CCG	B-Task
supertags	I-Task
,	O
and	O
is	O
not	O
aware	O
of	O
the	O
global	B-Metric
parsing	I-Metric
objective	I-Metric
.	O
	
section	O
:	O
Our	O
Approach	O
	
We	O
propose	O
to	O
replace	O
the	O
hand	O
-	O
crafted	O
feature	O
functions	O
in	O
favor	O
of	O
minimally	O
-	O
defined	O
feature	O
functions	O
which	O
make	O
use	O
of	O
automatically	B-Method
learned	I-Method
Bidirectional	I-Method
LSTM	I-Method
representations	I-Method
.	O
	
Given	O
-	O
words	O
input	O
sentence	O
with	O
words	O
together	O
with	O
the	O
corresponding	O
POS	B-Metric
tags	O
,	O
we	O
associate	O
each	O
word	O
and	O
POS	B-Metric
with	O
embedding	O
vectors	O
and	O
,	O
and	O
create	O
a	O
sequence	O
of	O
input	O
vectors	O
in	O
which	O
each	O
is	O
a	O
concatenation	O
of	O
the	O
corresponding	O
word	O
and	O
POS	B-Metric
vectors	O
:	O
The	O
embeddings	O
are	O
trained	O
together	O
with	O
the	O
model	O
.	O
	
This	O
encodes	O
each	O
word	O
in	O
isolation	O
,	O
disregarding	O
its	O
context	O
.	O
	
We	O
introduce	O
context	O
by	O
representing	O
each	O
input	O
element	O
as	O
its	O
(	O
deep	O
)	O
BiLSTM	O
vector	O
,	O
:	O
Our	O
feature	O
function	O
is	O
then	O
a	O
concatenation	O
of	O
a	O
small	O
number	O
of	O
BiLSTM	O
vectors	O
.	O
	
The	O
exact	O
feature	O
function	O
is	O
parser	O
dependent	O
and	O
will	O
be	O
discussed	O
when	O
discussing	O
the	O
corresponding	O
parsers	B-Method
.	O
	
The	O
resulting	O
feature	O
vectors	O
are	O
then	O
scored	O
using	O
a	O
non	B-Method
-	I-Method
linear	I-Method
function	I-Method
,	O
namely	O
a	O
multi	B-Method
-	I-Method
layer	I-Method
perceptron	I-Method
with	O
one	B-Method
hidden	I-Method
layer	I-Method
(	O
MLP	B-Method
)	O
:	O
where	O
are	O
the	O
model	O
parameters	O
.	O
	
Beside	O
using	O
the	O
BiLSTM	B-Method
-	I-Method
based	I-Method
feature	I-Method
functions	I-Method
,	O
we	O
make	O
use	O
of	O
standard	O
parsing	B-Method
techniques	I-Method
.	O
	
Crucially	O
,	O
the	O
BiLSTM	B-Method
is	O
trained	O
jointly	O
with	O
the	O
rest	O
of	O
the	O
parsing	B-Task
objective	I-Task
.	O
	
This	O
allows	O
it	O
to	O
learn	O
representations	O
which	O
are	O
suitable	O
for	O
the	O
parsing	B-Task
task	I-Task
.	O
	
Consider	O
a	O
concatenation	O
of	O
two	O
BiLSTM	O
vectors	O
(	O
)	O
scored	O
using	O
an	O
MLP	B-Method
.	O
	
The	O
scoring	B-Method
function	I-Method
has	O
access	O
to	O
the	O
words	O
and	O
POS	B-Metric
-	O
tags	O
of	O
and	O
,	O
as	O
well	O
as	O
the	O
words	O
and	O
POS	B-Metric
-	O
tags	O
of	O
the	O
words	O
in	O
an	O
infinite	O
window	O
surrounding	O
them	O
.	O
	
As	O
LSTMs	B-Method
are	O
known	O
to	O
capture	O
length	O
and	O
sequence	O
position	O
information	O
,	O
it	O
is	O
very	O
plausible	O
that	O
the	O
scoring	B-Method
function	I-Method
can	O
be	O
sensitive	O
also	O
to	O
the	O
distance	O
between	O
and	O
,	O
their	O
ordering	O
,	O
and	O
the	O
sequential	O
material	O
between	O
them	O
.	O
	
paragraph	O
:	O
Parsing	B-Metric
-	I-Metric
time	I-Metric
Complexity	I-Metric
	
Once	O
the	O
BiLSTM	B-Method
is	O
trained	O
,	O
parsing	B-Task
is	O
performed	O
by	O
first	O
computing	O
the	O
BiLSTM	B-Method
encoding	I-Method
for	O
each	O
word	O
in	O
the	O
sentence	O
(	O
a	O
linear	O
time	O
operation	O
)	O
.	O
	
Then	O
,	O
parsing	B-Task
proceeds	O
as	O
usual	O
,	O
where	O
the	O
feature	B-Task
extraction	I-Task
involves	O
a	O
concatenation	O
of	O
a	O
small	O
number	O
of	O
the	O
pre	O
-	O
computed	O
vectors	O
.	O
	
section	O
:	O
Transition	B-Method
-	I-Method
based	I-Method
Parser	I-Method
	
We	O
begin	O
by	O
integrating	O
the	O
feature	B-Method
extractor	I-Method
in	O
a	O
transition	B-Method
-	I-Method
based	I-Method
parser	I-Method
.	O
	
We	O
follow	O
the	O
notation	O
in	O
tacl2013dynamic	O
.	O
	
The	O
transition	B-Method
-	I-Method
based	I-Method
parsing	I-Method
framework	I-Method
assumes	O
a	O
transition	B-Method
system	I-Method
,	O
an	O
abstract	B-Method
machine	I-Method
that	O
processes	O
sentences	O
and	O
produces	O
parse	O
trees	O
.	O
	
The	O
transition	B-Method
system	I-Method
has	O
a	O
set	O
of	O
configurations	O
and	O
a	O
set	O
of	O
transitions	O
which	O
are	O
applied	O
to	O
configurations	O
.	O
	
When	O
parsing	O
a	O
sentence	O
,	O
the	O
system	O
is	O
initialized	O
to	O
an	O
initial	O
configuration	O
based	O
on	O
the	O
input	O
sentence	O
,	O
and	O
transitions	O
are	O
repeatedly	O
applied	O
to	O
this	O
configuration	O
.	O
	
After	O
a	O
finite	O
number	O
of	O
transitions	O
,	O
the	O
system	O
arrives	O
at	O
a	O
terminal	O
configuration	O
,	O
and	O
a	O
parse	O
tree	O
is	O
read	O
off	O
the	O
terminal	O
configuration	O
.	O
	
In	O
a	O
greedy	B-Method
parser	I-Method
,	O
a	O
classifier	B-Method
is	O
used	O
to	O
choose	O
the	O
transition	O
to	O
take	O
in	O
each	O
configuration	O
,	O
based	O
on	O
features	O
extracted	O
from	O
the	O
configuration	O
itself	O
.	O
	
The	O
parsing	B-Method
algorithm	I-Method
is	O
presented	O
in	O
Algorithm	O
[	O
reference	O
]	O
below	O
.	O
	
[	O
h	O
]	O
Greedy	B-Method
transition	I-Method
-	I-Method
based	I-Method
parsing	I-Method
[	O
1	O
]	O
Input	O
:	O
sentence	O
,	O
parameterized	O
function	O
with	O
parameters	O
.	O
	
not	O
Given	O
a	O
sentence	O
,	O
the	O
parser	B-Method
is	O
initialized	O
with	O
the	O
configuration	O
(	O
line	O
[	O
reference	O
]	O
)	O
.	O
	
Then	O
,	O
a	O
feature	O
function	O
represents	O
the	O
configuration	O
as	O
a	O
vector	O
,	O
which	O
is	O
fed	O
to	O
a	O
scoring	B-Method
function	I-Method
Score	O
assigning	O
scores	O
to	O
(	O
configuration	O
,	O
transition	O
)	O
pairs	O
.	O
	
Score	O
scores	O
the	O
possible	O
transitions	O
,	O
and	O
the	O
highest	O
scoring	O
transition	O
is	O
chosen	O
(	O
line	O
[	O
reference	O
]	O
)	O
.	O
	
The	O
transition	O
is	O
applied	O
to	O
the	O
configuration	O
,	O
resulting	O
in	O
a	O
new	O
parser	O
configuration	O
.	O
	
The	O
process	O
ends	O
when	O
reaching	O
a	O
final	O
configuration	O
,	O
from	O
which	O
the	O
resulting	O
parse	O
tree	O
is	O
read	O
and	O
returned	O
(	O
line	O
[	O
reference	O
]	O
)	O
.	O
	
Transition	B-Method
systems	I-Method
differ	O
by	O
the	O
way	O
they	O
define	O
configurations	O
,	O
and	O
by	O
the	O
particular	O
set	O
of	O
transitions	O
available	O
to	O
them	O
.	O
	
A	O
parser	B-Method
is	O
determined	O
by	O
the	O
choice	O
of	O
a	O
transition	B-Method
system	I-Method
,	O
a	O
feature	O
function	O
and	O
a	O
scoring	B-Metric
function	I-Metric
Score	I-Metric
.	O
	
Our	O
choices	O
are	O
detailed	O
below	O
.	O
	
paragraph	O
:	O
The	O
Arc	B-Method
-	I-Method
Hybrid	I-Method
System	I-Method
	
Many	O
transition	B-Method
systems	I-Method
exist	O
in	O
the	O
literature	O
.	O
	
In	O
this	O
work	O
,	O
we	O
use	O
the	O
arc	B-Method
-	I-Method
hybrid	I-Method
transition	I-Method
system	I-Method
,	O
which	O
is	O
similar	O
to	O
the	O
more	O
popular	O
arc	B-Method
-	I-Method
standard	I-Method
system	I-Method
,	O
but	O
for	O
which	O
an	O
efficient	O
dynamic	B-Method
oracle	I-Method
is	O
available	O
.	O
	
In	O
the	O
arc	B-Method
-	I-Method
hybrid	I-Method
system	I-Method
,	O
a	O
configuration	O
consists	O
of	O
a	O
stack	O
,	O
a	O
buffer	O
,	O
and	O
a	O
set	O
of	O
dependency	O
arcs	O
.	O
	
Both	O
the	O
stack	O
and	O
the	O
buffer	O
hold	O
integer	O
indices	O
pointing	O
to	O
sentence	O
elements	O
.	O
	
Given	O
a	O
sentence	O
,	O
the	O
system	O
is	O
initialized	O
with	O
an	O
empty	O
stack	O
,	O
an	O
empty	O
arc	O
set	O
,	O
and	O
,	O
where	O
is	O
the	O
special	O
root	O
index	O
.	O
	
Any	O
configuration	O
with	O
an	O
empty	O
stack	O
and	O
a	O
buffer	O
containing	O
only	O
is	O
terminal	O
,	O
and	O
the	O
parse	O
tree	O
is	O
given	O
by	O
the	O
arc	O
set	O
of	O
.	O
	
The	O
arc	B-Method
-	I-Method
hybrid	I-Method
system	I-Method
allows	O
3	O
possible	O
transitions	O
,	O
Shift	O
,	O
and	O
,	O
defined	O
as	O
:	O
The	O
Shift	B-Method
transition	I-Method
moves	O
the	O
first	O
item	O
of	O
the	O
buffer	O
(	O
)	O
to	O
the	O
stack	O
.	O
	
The	O
Leftℓ	O
transition	O
removes	O
the	O
first	O
item	O
on	O
top	O
of	O
the	O
stack	O
(	O
)	O
and	O
attaches	O
it	O
as	O
a	O
modifier	O
to	O
with	O
label	O
,	O
adding	O
the	O
arc	O
.	O
	
The	O
Rightℓ	O
transition	O
removes	O
from	O
the	O
stack	O
and	O
attaches	O
it	O
as	O
a	O
modifier	O
to	O
the	O
next	O
item	O
on	O
the	O
stack	O
(	O
)	O
,	O
adding	O
the	O
arc	O
.	O
	
paragraph	O
:	O
Scoring	B-Method
Function	I-Method
	
Traditionally	O
,	O
the	O
scoring	B-Method
function	I-Method
is	O
a	O
discriminative	B-Method
linear	I-Method
model	I-Method
of	O
the	O
form	O
.	O
	
The	O
linearity	O
of	O
Score	O
required	O
the	O
feature	O
function	O
to	O
encode	O
non	O
-	O
linearities	O
in	O
the	O
form	O
of	O
combination	O
features	O
.	O
	
We	O
follow	O
Chen	O
and	O
Manning	O
chen2014fast	O
and	O
replace	O
the	O
linear	B-Method
scoring	I-Method
model	I-Method
with	O
an	O
MLP	B-Method
.	O
	
paragraph	O
:	O
Simple	O
Feature	O
Function	O
	
The	O
feature	O
function	O
is	O
typically	O
complex	O
(	O
see	O
Section	O
[	O
reference	O
]	O
)	O
.	O
	
Our	O
feature	B-Method
function	I-Method
is	O
the	O
concatenated	O
BiLSTM	O
vectors	O
of	O
the	O
top	O
3	O
items	O
on	O
the	O
stack	O
and	O
the	O
first	O
item	O
on	O
the	O
buffer	O
.	O
	
I.e.	O
,	O
for	O
a	O
configuration	O
the	O
feature	B-Method
extractor	I-Method
is	O
defined	O
as	O
:	O
This	O
feature	B-Method
function	I-Method
is	O
rather	O
minimal	O
:	O
it	O
takes	O
into	O
account	O
the	O
BiLSTM	B-Method
representations	I-Method
of	O
and	O
,	O
which	O
are	O
the	O
items	O
affected	O
by	O
the	O
possible	O
transitions	O
being	O
scored	O
,	O
as	O
well	O
as	O
one	O
extra	O
stack	O
context	O
.	O
	
Figure	O
1	O
depicts	O
transition	O
scoring	O
with	O
our	O
architecture	O
and	O
this	O
feature	O
function	O
.	O
	
Note	O
that	O
,	O
unlike	O
previous	O
work	O
,	O
this	O
feature	B-Method
function	I-Method
does	O
not	O
take	O
into	O
account	O
,	O
the	O
already	O
built	O
structure	O
.	O
	
The	O
high	O
parsing	B-Metric
accuracies	I-Metric
in	O
the	O
experimental	O
sections	O
suggest	O
that	O
the	O
BiLSTM	B-Method
encoding	I-Method
is	O
capable	O
of	O
estimating	O
a	O
lot	O
of	O
the	O
missing	O
information	O
based	O
on	O
the	O
provided	O
stack	O
and	O
buffer	O
elements	O
and	O
the	O
sequential	O
content	O
between	O
them	O
.	O
	
While	O
not	O
explored	O
in	O
this	O
work	O
,	O
relying	O
on	O
only	O
four	O
word	O
indices	O
for	O
scoring	O
an	O
action	O
results	O
in	O
very	O
compact	O
state	O
signatures	O
,	O
making	O
our	O
proposed	O
feature	B-Method
representation	I-Method
very	O
appealing	O
for	O
use	O
in	O
transition	B-Method
-	I-Method
based	I-Method
parsers	I-Method
that	O
employ	O
dynamic	B-Method
-	I-Method
programming	I-Method
search	I-Method
.	O
	
paragraph	O
:	O
Extended	O
Feature	O
Function	O
	
One	O
of	O
the	O
benefits	O
of	O
the	O
greedy	B-Method
transition	I-Method
-	I-Method
based	I-Method
parsing	I-Method
framework	I-Method
is	O
precisely	O
its	O
ability	O
to	O
look	O
at	O
arbitrary	O
features	O
from	O
the	O
already	O
built	O
tree	O
.	O
	
If	O
we	O
allow	O
somewhat	O
less	O
minimal	O
feature	O
function	O
,	O
we	O
could	O
add	O
the	O
BiLSTM	O
vectors	O
corresponding	O
to	O
the	O
right	O
-	O
most	O
and	O
left	O
-	O
	
most	O
modifiers	O
of	O
,	O
and	O
,	O
as	O
well	O
as	O
the	O
left	O
-	O
most	O
modifier	O
of	O
,	O
reaching	O
a	O
total	O
of	O
11	O
BiLSTM	O
vectors	O
.	O
	
We	O
refer	O
to	O
this	O
as	O
the	O
extended	O
feature	O
set	O
.	O
	
As	O
we	O
’ll	O
see	O
in	O
Section	O
[	O
reference	O
]	O
,	O
using	O
the	O
extended	O
set	O
does	O
indeed	O
improve	O
parsing	B-Metric
accuracies	I-Metric
when	O
using	O
pre	O
-	O
trained	O
word	O
embeddings	O
,	O
but	O
has	O
a	O
minimal	O
effect	O
in	O
the	O
fully	B-Task
-	I-Task
supervised	I-Task
case	I-Task
.	O
	
subsection	O
:	O
Details	O
of	O
the	O
Training	B-Method
Algorithm	I-Method
	
The	O
training	B-Metric
objective	I-Metric
is	O
to	O
set	O
the	O
score	O
of	O
correct	O
transitions	O
above	O
the	O
scores	O
of	O
incorrect	O
transitions	O
.	O
	
We	O
use	O
a	O
margin	B-Method
-	I-Method
based	I-Method
objective	I-Method
,	O
aiming	O
to	O
maximize	O
the	O
margin	O
between	O
the	O
highest	O
scoring	O
correct	O
action	O
and	O
the	O
highest	O
scoring	O
incorrect	O
action	O
.	O
	
The	O
hinge	O
loss	O
at	O
each	O
parsing	O
configuration	O
is	O
defined	O
as	O
:	O
where	O
is	O
the	O
set	O
of	O
possible	O
transitions	O
and	O
is	O
the	O
set	O
of	O
correct	O
(	O
gold	O
)	O
transitions	O
at	O
the	O
current	O
stage	O
.	O
	
At	O
each	O
stage	O
of	O
the	O
training	O
process	O
the	O
parser	B-Method
scores	O
the	O
possible	O
transitions	O
,	O
incurs	O
a	O
loss	O
,	O
selects	O
a	O
transition	O
to	O
follow	O
,	O
and	O
moves	O
to	O
the	O
next	O
configuration	O
based	O
on	O
it	O
.	O
	
The	O
local	O
losses	O
are	O
summed	O
throughout	O
the	O
parsing	B-Task
process	I-Task
of	O
a	O
sentence	O
,	O
and	O
the	O
parameters	O
are	O
updated	O
with	O
respect	O
to	O
the	O
sum	O
of	O
the	O
losses	O
at	O
sentence	O
boundaries	O
.	O
	
The	O
gradients	O
of	O
the	O
entire	O
network	O
(	O
including	O
the	O
MLP	B-Method
and	O
the	O
BiLSTM	B-Method
)	O
with	O
respect	O
to	O
the	O
sum	O
of	O
the	O
losses	O
are	O
calculated	O
using	O
the	O
backpropagation	B-Method
algorithm	I-Method
.	O
	
As	O
usual	O
,	O
we	O
perform	O
several	O
training	O
iterations	O
over	O
the	O
training	O
corpus	O
,	O
shuffling	O
the	O
order	O
of	O
sentences	O
in	O
each	O
iteration	O
.	O
	
paragraph	O
:	O
Error	B-Method
-	I-Method
Exploration	I-Method
and	O
Dynamic	B-Task
Oracle	I-Task
Training	I-Task
	
We	O
follow	O
tacl2013dynamic	O
;	O
coling2012dynamic	O
in	O
using	O
error	B-Method
exploration	I-Method
training	I-Method
with	O
a	O
dynamic	B-Method
-	I-Method
oracle	I-Method
,	O
which	O
we	O
briefly	O
describe	O
below	O
.	O
	
At	O
each	O
stage	O
in	O
the	O
training	O
process	O
,	O
the	O
parser	B-Method
assigns	O
scores	O
to	O
all	O
the	O
possible	O
transitions	O
.	O
	
It	O
then	O
selects	O
a	O
transition	O
,	O
applies	O
it	O
,	O
and	O
moves	O
to	O
the	O
next	O
step	O
.	O
	
Which	O
transition	O
should	O
be	O
followed	O
?	O
	
A	O
common	O
approach	O
follows	O
the	O
highest	O
scoring	O
transition	O
that	O
can	O
lead	O
to	O
the	O
gold	O
tree	O
.	O
	
However	O
,	O
when	O
training	O
in	O
this	O
way	O
the	O
parser	B-Method
sees	O
only	O
configurations	O
that	O
result	O
from	O
following	O
correct	O
actions	O
,	O
and	O
as	O
a	O
result	O
tends	O
to	O
suffer	O
from	O
error	B-Task
propagation	I-Task
at	O
test	O
time	O
.	O
	
Instead	O
,	O
in	O
error	B-Task
-	I-Task
exploration	I-Task
training	I-Task
the	O
parser	B-Method
follows	O
the	O
highest	O
scoring	O
action	O
in	O
during	O
training	O
even	O
if	O
this	O
action	O
is	O
incorrect	O
,	O
exposing	O
it	O
to	O
configurations	O
that	O
result	O
from	O
erroneous	O
decisions	O
.	O
	
This	O
strategy	O
requires	O
defining	O
the	O
set	O
such	O
that	O
the	O
correct	O
actions	O
to	O
take	O
are	O
well	O
-	O
defined	O
also	O
for	O
states	O
that	O
can	O
not	O
lead	O
to	O
the	O
gold	O
tree	O
.	O
	
Such	O
a	O
set	O
is	O
called	O
a	O
dynamic	O
oracle	O
.	O
	
We	O
perform	O
error	B-Method
-	I-Method
exploration	I-Method
training	I-Method
using	O
the	O
dynamic	O
-	O
oracle	O
defined	O
by	O
tacl2013dynamic	O
.	O
	
paragraph	O
:	O
Aggressive	B-Method
Exploration	I-Method
	
We	O
found	O
that	O
even	O
when	O
using	O
error	B-Method
-	I-Method
exploration	I-Method
,	O
after	O
one	O
iteration	O
the	O
model	O
remembers	O
the	O
training	O
set	O
quite	O
well	O
,	O
and	O
does	O
not	O
make	O
enough	O
errors	O
to	O
make	O
error	B-Method
-	I-Method
exploration	I-Method
effective	O
.	O
	
In	O
order	O
to	O
expose	O
the	O
parser	B-Method
to	O
more	O
errors	O
,	O
we	O
follow	O
an	O
aggressive	O
-	O
exploration	B-Method
scheme	I-Method
:	O
we	O
sometimes	O
follow	O
incorrect	O
transitions	O
also	O
if	O
they	O
score	O
below	O
correct	O
transitions	O
.	O
	
Specifically	O
,	O
when	O
the	O
score	O
of	O
the	O
correct	O
transition	O
is	O
greater	O
than	O
that	O
of	O
the	O
wrong	O
transition	O
but	O
the	O
difference	O
is	O
smaller	O
than	O
a	O
margin	O
constant	O
,	O
we	O
chose	O
to	O
follow	O
the	O
incorrect	O
action	O
with	O
probability	O
(	O
we	O
use	O
in	O
our	O
experiments	O
)	O
.	O
	
paragraph	O
:	O
Summary	O
	
The	O
greedy	B-Method
transition	I-Method
-	I-Method
based	I-Method
parser	I-Method
follows	O
standard	O
techniques	O
from	O
the	O
literature	O
(	O
margin	B-Metric
-	I-Metric
based	I-Metric
objective	I-Metric
,	O
dynamic	B-Method
oracle	I-Method
training	I-Method
,	O
error	B-Method
exploration	I-Method
,	O
MLP	B-Method
-	I-Method
based	I-Method
non	I-Method
-	I-Method
linear	I-Method
scoring	I-Method
function	I-Method
)	O
.	O
	
We	O
depart	O
from	O
the	O
literature	O
by	O
replacing	O
the	O
hand	O
-	O
crafted	O
feature	O
function	O
over	O
carefully	O
selected	O
components	O
of	O
the	O
configuration	O
with	O
a	O
concatenation	B-Method
of	I-Method
BiLSTM	I-Method
representations	I-Method
of	O
a	O
few	O
prominent	O
items	O
on	O
the	O
stack	O
and	O
the	O
buffer	O
,	O
and	O
training	O
the	O
BiLSTM	B-Method
encoder	I-Method
jointly	O
with	O
the	O
rest	O
of	O
the	O
network	O
.	O
	
section	O
:	O
Graph	B-Method
-	I-Method
based	I-Method
Parser	I-Method
	
Graph	B-Method
-	I-Method
based	I-Method
parsing	I-Method
follows	O
the	O
common	O
structured	B-Method
prediction	I-Method
paradigm	I-Method
:	O
Given	O
an	O
input	O
sentence	O
(	O
and	O
the	O
corresponding	O
sequence	O
of	O
vectors	O
)	O
we	O
look	O
for	O
the	O
highest	O
-	O
scoring	O
parse	O
tree	O
in	O
the	O
space	O
of	O
valid	O
dependency	O
trees	O
over	O
.	O
	
In	O
order	O
to	O
make	O
the	O
search	O
tractable	O
,	O
the	O
scoring	O
function	O
is	O
decomposed	O
to	O
the	O
sum	O
of	O
local	O
scores	O
for	O
each	O
part	O
independently	O
.	O
	
In	O
this	O
work	O
,	O
we	O
focus	O
on	O
arc	B-Method
-	I-Method
factored	I-Method
graph	I-Method
based	I-Method
approach	I-Method
presented	O
in	O
mst	B-Method
.	O
	
Arc	B-Method
-	I-Method
factored	I-Method
parsing	I-Method
decomposes	O
the	O
score	O
of	O
a	O
tree	O
to	O
the	O
sum	O
of	O
the	O
score	O
of	O
its	O
head	O
-	O
modifier	O
arcs	O
:	O
	
Given	O
the	O
scores	O
of	O
the	O
arcs	O
the	O
highest	O
scoring	O
projective	O
tree	O
can	O
be	O
efficiently	O
found	O
using	O
Eisner	B-Method
’s	I-Method
decoding	I-Method
algorithm	I-Method
eisner1996dep	O
.	O
	
McDonald	O
et	O
al	O
.	O
and	O
most	O
subsequent	O
work	O
estimate	O
the	O
local	B-Metric
score	I-Metric
of	O
an	O
arc	O
by	O
a	O
linear	B-Method
model	I-Method
parameterized	O
by	O
a	O
weight	O
vector	O
,	O
and	O
a	O
feature	B-Method
function	I-Method
assigning	O
a	O
sparse	O
feature	O
vector	O
for	O
an	O
arc	O
linking	O
modifier	O
to	O
head	O
.	O
	
We	O
follow	O
pei2015effective	O
and	O
replace	O
the	O
linear	B-Method
scoring	I-Method
function	I-Method
with	O
an	O
MLP	B-Method
.	O
	
The	O
feature	B-Method
extractor	I-Method
is	O
usually	O
complex	O
,	O
involving	O
many	O
elements	O
(	O
see	O
Section	O
[	O
reference	O
]	O
)	O
.	O
	
In	O
contrast	O
,	O
our	O
feature	B-Method
extractor	I-Method
uses	O
merely	O
the	O
BiLSTM	B-Method
encoding	I-Method
of	O
the	O
head	O
word	O
and	O
the	O
modifier	O
word	O
:	O
The	O
final	O
model	O
is	O
:	O
The	O
architecture	O
is	O
illustrated	O
in	O
Figure	O
[	O
reference	O
]	O
.	O
	
paragraph	O
:	O
Training	O
	
The	O
training	O
objective	O
is	O
to	O
set	O
the	O
score	O
function	O
such	O
that	O
correct	O
tree	O
is	O
scored	O
above	O
incorrect	O
ones	O
.	O
	
We	O
use	O
a	O
margin	B-Metric
-	I-Metric
based	I-Metric
objective	I-Metric
,	O
aiming	O
to	O
maximize	O
the	O
margin	O
between	O
the	O
score	O
of	O
the	O
gold	O
tree	O
and	O
the	O
highest	O
scoring	O
incorrect	O
tree	O
.	O
	
We	O
define	O
a	O
hinge	O
loss	O
with	O
respect	O
to	O
a	O
gold	O
tree	O
as	O
:	O
Each	O
of	O
the	O
tree	O
scores	O
is	O
then	O
calculated	O
by	O
activating	O
the	O
MLP	B-Method
on	O
the	O
arc	B-Method
representations	I-Method
.	O
	
The	O
entire	O
loss	B-Metric
can	O
viewed	O
as	O
the	O
sum	B-Method
of	I-Method
multiple	I-Method
neural	I-Method
networks	I-Method
,	O
which	O
is	O
sub	O
-	O
differentiable	O
.	O
	
We	O
calculate	O
the	O
gradients	O
of	O
the	O
entire	O
network	O
(	O
including	O
to	O
the	O
BiLSTM	B-Method
encoder	I-Method
and	O
word	O
embeddings	O
)	O
.	O
	
paragraph	O
:	O
Labeled	B-Task
Parsing	I-Task
	
Up	O
to	O
now	O
,	O
we	O
described	O
unlabeled	B-Task
parsing	I-Task
.	O
	
A	O
possible	O
approach	O
for	O
adding	B-Task
labels	I-Task
is	O
to	O
score	O
the	O
combination	O
of	O
an	O
unlabeled	O
arc	O
and	O
its	O
label	O
by	O
considering	O
the	O
label	O
as	O
part	O
of	O
the	O
arc	O
.	O
	
This	O
results	O
in	O
parts	O
that	O
need	O
to	O
be	O
scored	O
,	O
leading	O
to	O
slow	B-Task
parsing	I-Task
speeds	I-Task
and	O
arguably	O
a	O
harder	O
learning	B-Task
problem	I-Task
.	O
	
Instead	O
,	O
we	O
chose	O
to	O
first	O
predict	O
the	O
unlabeled	O
structure	O
using	O
the	O
model	O
given	O
above	O
,	O
and	O
then	O
predict	O
the	O
label	O
of	O
each	O
resulting	O
arc	O
.	O
	
Using	O
this	O
approach	O
,	O
the	O
number	O
of	O
parts	O
stays	O
small	O
,	O
enabling	O
fast	O
parsing	B-Task
.	O
	
The	O
labeling	O
of	O
an	O
arc	O
is	O
performed	O
using	O
the	O
same	O
feature	B-Method
representation	I-Method
fed	O
into	O
a	O
different	O
MLP	B-Method
predictor	I-Method
:	O
As	O
before	O
we	O
use	O
a	O
margin	B-Method
based	I-Method
hinge	I-Method
loss	I-Method
.	O
	
The	O
labeler	O
is	O
trained	O
on	O
the	O
gold	O
trees	O
.	O
	
The	O
BiLSTM	B-Method
encoder	I-Method
responsible	O
for	O
producing	O
and	O
is	O
shared	O
with	O
the	O
arc	B-Method
-	I-Method
factored	I-Method
parser	I-Method
:	O
the	O
same	O
BiLSTM	B-Method
encoder	I-Method
is	O
used	O
in	O
the	O
parer	B-Method
and	O
the	O
labeler	B-Method
.	O
	
This	O
sharing	O
of	O
parameters	O
can	O
be	O
seen	O
as	O
an	O
instance	O
of	O
multi	B-Task
-	I-Task
task	I-Task
learning	I-Task
.	O
	
As	O
we	O
show	O
in	O
Section	O
[	O
reference	O
]	O
,	O
the	O
sharing	O
is	O
effective	O
:	O
training	O
the	O
BiLSTM	B-Method
feature	I-Method
encoder	I-Method
to	O
be	O
good	O
at	O
predicting	O
arc	O
-	O
labels	O
significantly	O
improves	O
the	O
parser	B-Method
’s	O
unlabeled	B-Metric
accuracy	I-Metric
.	O
	
paragraph	O
:	O
Loss	B-Method
augmented	I-Method
inference	I-Method
	
In	O
initial	O
experiments	O
,	O
the	O
network	O
learned	O
quickly	O
and	O
overfit	O
the	O
data	O
.	O
	
In	O
order	O
to	O
remedy	O
this	O
,	O
we	O
found	O
it	O
useful	O
to	O
use	O
loss	B-Method
augmented	I-Method
inference	I-Method
.	O
	
The	O
intuition	O
behind	O
loss	B-Method
augmented	I-Method
inference	I-Method
is	O
to	O
update	O
against	O
trees	O
which	O
have	O
high	O
model	O
scores	O
and	O
are	O
also	O
very	O
wrong	O
.	O
	
This	O
is	O
done	O
by	O
augmenting	O
the	O
score	O
of	O
each	O
part	O
not	O
belonging	O
to	O
the	O
gold	O
tree	O
by	O
adding	O
a	O
constant	O
to	O
its	O
score	O
.	O
	
Formally	O
,	O
the	O
loss	B-Method
transforms	I-Method
as	O
follows	O
:	O
	
paragraph	O
:	O
Speed	O
improvements	O
	
The	O
arc	B-Method
-	I-Method
factored	I-Method
model	I-Method
requires	O
the	O
scoring	B-Task
of	I-Task
arcs	I-Task
.	O
	
Scoring	B-Task
is	O
performed	O
using	O
an	O
MLP	B-Method
with	O
one	O
hidden	B-Method
layer	I-Method
,	O
resulting	O
in	O
matrix	B-Method
-	I-Method
vector	I-Method
multiplications	I-Method
from	O
the	O
input	O
to	O
the	O
hidden	O
layer	O
,	O
and	O
multiplications	O
from	O
the	O
hidden	O
to	O
the	O
output	O
layer	O
.	O
	
The	O
first	O
multiplications	O
involve	O
larger	O
dimensional	O
input	O
and	O
output	O
vectors	O
,	O
and	O
are	O
the	O
most	O
time	O
consuming	O
.	O
	
Fortunately	O
,	O
these	O
can	O
be	O
reduced	O
to	O
multiplications	O
and	O
vector	O
additions	O
,	O
by	O
observing	O
that	O
the	O
multiplication	O
can	O
be	O
written	O
as	O
where	O
and	O
are	O
are	O
the	O
first	O
and	O
second	O
half	O
of	O
the	O
matrix	O
and	O
reusing	O
the	O
products	O
across	O
different	O
pairs	O
.	O
	
Summary	O
The	O
graph	B-Method
-	I-Method
based	I-Method
parser	O
is	O
straight	O
-	O
forward	O
first	B-Method
-	I-Method
order	I-Method
parser	I-Method
,	O
trained	O
with	O
a	O
margin	B-Method
-	I-Method
based	I-Method
hinge	I-Method
-	I-Method
loss	I-Method
and	O
loss	B-Method
-	I-Method
augmented	I-Method
inference	I-Method
.	O
	
We	O
depart	O
from	O
the	O
literature	O
by	O
replacing	O
the	O
hand	O
-	O
crafted	O
feature	O
function	O
with	O
a	O
concatenation	B-Method
of	I-Method
BiLSTM	I-Method
representations	I-Method
of	O
the	O
head	O
and	O
modifier	O
words	O
,	O
and	O
training	O
the	O
BiLSTM	B-Method
encoder	I-Method
jointly	O
with	O
the	O
structured	O
objective	O
.	O
	
We	O
also	O
introduce	O
a	O
novel	O
multi	B-Method
-	I-Method
task	I-Method
learning	I-Method
approach	I-Method
for	O
labeled	B-Task
parsing	I-Task
by	O
training	O
a	O
second	O
-	O
stage	O
arc	B-Method
-	I-Method
labeler	I-Method
sharing	O
the	O
same	O
BiLSTM	B-Method
encoder	I-Method
with	O
the	O
unlabeled	B-Method
parser	I-Method
.	O
	
section	O
:	O
Experiments	O
and	O
Results	O
	
We	O
evaluated	O
our	O
parsing	B-Method
model	I-Method
on	O
English	B-Material
and	O
Chinese	B-Material
data	O
.	O
	
For	O
comparison	O
purposes	O
we	O
follow	O
the	O
setup	O
of	O
dyer2015transitionbased	O
.	O
	
paragraph	O
:	O
Data	O
	
For	O
English	B-Material
,	O
we	O
used	O
the	O
Stanford	B-Material
Dependency	I-Material
(	O
SD	B-Material
)	O
conversion	O
of	O
the	O
Penn	B-Material
Treebank	I-Material
,	O
using	O
the	O
standard	O
train	O
/	O
dev	O
/	O
test	O
splits	O
with	O
the	O
same	O
predicted	O
POS	B-Metric
-	I-Metric
tags	I-Metric
as	O
used	O
in	O
dyer2015transitionbased	O
;	O
chen2014fast	O
.	O
	
This	O
dataset	O
contains	O
a	O
few	O
non	O
-	O
projective	O
trees	O
.	O
	
Punctuation	O
symbols	O
are	O
excluded	O
from	O
the	O
evaluation	O
.	O
	
For	O
Chinese	B-Material
,	O
we	O
use	O
the	O
Penn	O
Chinese	B-Material
Treebank	O
5.1	O
(	O
CTB5	B-Material
)	O
,	O
using	O
the	O
train	O
/	O
test	O
/	O
dev	O
splits	O
of	O
with	O
gold	O
part	O
-	O
of	O
-	O
speech	O
tags	O
,	O
also	O
following	O
.	O
	
When	O
using	O
external	O
word	O
embeddings	O
,	O
we	O
also	O
use	O
the	O
same	O
data	O
as	O
dyer2015transitionbased	O
.	O
	
paragraph	O
:	O
Implementation	O
Details	O
	
The	O
parsers	B-Method
are	O
implemented	O
in	O
python	B-Method
,	O
using	O
the	O
PyCNN	B-Method
toolkit	I-Method
for	O
neural	B-Method
network	I-Method
training	I-Method
.	O
	
The	O
code	O
is	O
available	O
at	O
the	O
github	O
repository	O
.	O
	
We	O
use	O
the	O
LSTM	B-Method
variant	I-Method
implemented	O
in	O
PyCNN	B-Method
,	O
and	O
optimize	O
using	O
the	O
Adam	B-Method
optimizer	I-Method
.	O
	
Unless	O
otherwise	O
noted	O
,	O
we	O
use	O
the	O
default	O
values	O
provided	O
by	O
PyCNN	B-Method
(	O
e.g.	O
for	O
random	O
initialization	O
,	O
learning	B-Metric
rates	I-Metric
etc	O
)	O
.	O
	
The	O
word	O
and	O
POS	B-Metric
embeddings	O
and	O
are	O
initialized	O
to	O
random	O
values	O
and	O
trained	O
together	O
with	O
the	O
rest	O
of	O
the	O
parsers	B-Method
’	I-Method
networks	I-Method
.	O
	
In	O
some	O
experiments	O
,	O
we	O
introduce	O
also	O
pre	O
-	O
trained	O
word	B-Method
embeddings	I-Method
.	O
	
In	O
those	O
cases	O
,	O
the	O
vector	B-Method
representation	I-Method
of	O
a	O
word	O
is	O
a	O
concatenation	O
of	O
its	O
randomly	B-Method
-	I-Method
initialized	I-Method
vector	I-Method
embedding	I-Method
with	O
its	O
pre	O
-	O
trained	O
word	O
vector	O
.	O
	
Both	O
are	O
tuned	O
during	O
training	O
.	O
	
We	O
use	O
the	O
same	O
word	O
vectors	O
as	O
in	O
dyer2015transitionbased	O
During	O
training	B-Task
,	O
we	O
employ	O
a	O
variant	O
of	O
word	B-Method
dropout	I-Method
,	O
and	O
replace	O
a	O
word	O
with	O
the	O
unknown	O
-	O
word	O
symbol	O
with	O
probability	O
that	O
is	O
inversely	O
proportional	O
to	O
the	O
frequency	O
of	O
the	O
word	O
.	O
	
A	O
word	O
appearing	O
times	O
in	O
the	O
training	O
corpus	O
is	O
replaced	O
with	O
the	O
unknown	O
symbol	O
with	O
probability	O
.	O
	
If	O
a	O
word	O
was	O
dropped	O
the	O
external	O
embedding	O
of	O
the	O
word	O
is	O
also	O
dropped	O
with	O
probability	O
.	O
	
We	O
train	O
the	O
parsers	B-Method
for	O
up	O
to	O
30	O
iterations	O
,	O
and	O
choose	O
the	O
best	O
model	O
according	O
to	O
the	O
UAS	B-Metric
accuracy	O
on	O
the	O
development	O
set	O
.	O
	
paragraph	O
:	O
Hyperparameter	B-Method
Tuning	I-Method
	
We	O
performed	O
a	O
very	O
minimal	O
hyper	B-Method
-	I-Method
parameter	I-Method
search	I-Method
with	O
the	O
graph	B-Method
-	I-Method
based	I-Method
parser	O
,	O
and	O
use	O
the	O
same	O
hyper	O
-	O
parameters	O
for	O
both	O
parsers	O
.	O
	
The	O
hyper	O
-	O
parameters	O
of	O
the	O
final	O
networks	O
used	O
for	O
all	O
the	O
reported	O
experiments	O
are	O
detailed	O
in	O
Table	O
[	O
reference	O
]	O
.	O
	
Main	O
Results	O
Table	O
[	O
reference	O
]	O
lists	O
the	O
test	O
-	O
set	O
accuracies	B-Metric
of	O
our	O
best	O
parsing	B-Method
models	I-Method
,	O
compared	O
to	O
other	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
parsers	B-Method
from	O
the	O
literature	O
.	O
	
It	O
is	O
clear	O
that	O
our	O
parsers	B-Method
are	O
very	O
competitive	O
,	O
despite	O
using	O
very	O
simple	O
parsing	B-Method
architectures	I-Method
and	O
minimal	B-Method
feature	I-Method
extractors	I-Method
.	O
	
When	O
not	O
using	O
external	O
embeddings	O
,	O
the	O
first	O
-	O
order	O
graph	B-Method
-	I-Method
based	I-Method
parser	O
with	O
2	O
features	O
outperforms	O
all	O
other	O
systems	O
that	O
are	O
not	O
using	O
external	O
resources	O
,	O
including	O
the	O
third	B-Method
-	I-Method
order	I-Method
TurboParser	I-Method
.	O
	
The	O
greedy	B-Method
transition	I-Method
based	I-Method
parser	I-Method
with	O
4	O
features	O
also	O
matches	O
or	O
outperforms	O
most	O
other	O
parsers	B-Method
,	O
including	O
the	O
beam	B-Method
-	I-Method
based	I-Method
transition	I-Method
parser	I-Method
with	O
heavily	O
engineered	O
features	O
of	O
Zhang	O
and	O
Nivre	O
(	O
2011	O
)	O
and	O
the	O
Stack	B-Method
-	I-Method
LSTM	I-Method
parser	I-Method
of	O
dyer2015transitionbased	O
,	O
as	O
well	O
as	O
the	O
same	O
parser	B-Method
when	O
trained	O
using	O
a	O
dynamic	B-Method
oracle	I-Method
.	O
	
Moving	O
from	O
the	O
simple	O
(	O
4	O
features	O
)	O
to	O
the	O
extended	O
(	O
11	O
features	O
)	O
feature	O
set	O
leads	O
to	O
some	O
gains	O
in	O
accuracy	B-Metric
for	O
both	O
English	B-Material
and	O
Chinese	B-Material
.	O
	
Interestingly	O
,	O
when	O
adding	O
external	O
word	O
embeddings	O
the	O
accuracy	B-Metric
of	O
the	O
graph	B-Method
-	I-Method
based	I-Method
parser	O
degrades	O
.	O
	
We	O
are	O
not	O
sure	O
why	O
this	O
happens	O
,	O
and	O
leave	O
the	O
exploration	O
of	O
effective	O
semi	B-Task
-	I-Task
supervised	I-Task
parsing	I-Task
with	O
the	O
graph	B-Method
-	I-Method
based	I-Method
model	O
for	O
future	O
work	O
.	O
	
The	O
greedy	B-Method
parser	I-Method
does	O
manage	O
to	O
benefit	O
from	O
the	O
external	O
embeddings	O
,	O
and	O
using	O
them	O
we	O
also	O
see	O
gains	O
from	O
moving	O
from	O
the	O
simple	O
to	O
the	O
extended	O
feature	O
set	O
.	O
	
Both	O
feature	O
sets	O
result	O
in	O
very	O
competitive	O
results	O
,	O
with	O
the	O
extended	O
feature	O
set	O
yielding	O
the	O
best	O
reported	O
results	O
for	O
Chinese	B-Material
,	O
and	O
ranked	O
second	O
for	O
English	B-Material
,	O
after	O
the	O
heavily	O
-	O
tuned	O
beam	B-Method
-	I-Method
based	I-Method
parser	I-Method
of	O
weiss2015structured	O
.	O
	
paragraph	O
:	O
Additional	O
Results	O
	
We	O
perform	O
some	O
ablation	O
experiments	O
in	O
order	O
to	O
quantify	O
the	O
effect	O
of	O
the	O
different	O
components	O
on	O
our	O
best	O
models	O
(	O
Table	O
[	O
reference	O
]	O
)	O
.	O
	
Loss	B-Task
augmented	I-Task
inference	I-Task
is	O
crucial	O
for	O
the	O
success	O
of	O
the	O
graph	B-Method
-	I-Method
based	I-Method
parser	O
,	O
and	O
the	O
multi	B-Method
-	I-Method
task	I-Method
learning	I-Method
scheme	I-Method
for	O
the	O
arc	B-Task
-	I-Task
labeler	I-Task
contributes	O
nicely	O
to	O
the	O
unlabeled	O
scores	O
.	O
	
Dynamic	B-Method
oracle	I-Method
training	I-Method
yields	O
nice	O
gains	O
for	O
both	O
English	B-Material
and	O
Chinese	B-Material
.	O
	
section	O
:	O
Conclusion	O
	
We	O
presented	O
a	O
pleasingly	O
effective	O
approach	O
for	O
feature	B-Task
extraction	I-Task
for	O
dependency	B-Task
parsing	I-Task
based	O
on	O
a	O
BiLSTM	B-Method
encoder	I-Method
that	O
is	O
trained	O
jointly	O
with	O
the	O
parser	B-Method
,	O
and	O
demonstrated	O
its	O
effectiveness	O
by	O
integrating	O
it	O
into	O
two	O
simple	O
parsing	B-Method
models	I-Method
:	O
a	O
greedy	B-Method
transition	I-Method
-	I-Method
based	I-Method
parser	I-Method
and	O
a	O
globally	O
optimized	O
first	O
-	O
order	O
graph	B-Method
-	I-Method
based	I-Method
parser	O
,	O
yielding	O
very	O
competitive	O
parsing	B-Metric
accuracies	I-Metric
in	O
both	O
cases	O
.	O
	
paragraph	O
:	O
Acknowledgements	O
	
This	O
research	O
is	O
supported	O
by	O
the	O
Intel	O
Collaborative	O
Research	O
Institute	O
for	O
Computational	O
Intelligence	O
(	O
ICRI	O
-	O
CI	O
)	O
and	O
the	O
Israeli	O
Science	O
Foundation	O
(	O
grant	O
number	O
1555	O
/	O
15	O
)	O
.	O
	
We	O
thank	O
Lillian	O
Lee	O
for	O
her	O
important	O
feedback	O
and	O
efforts	O
invested	O
in	O
editing	O
this	O
paper	O
.	O
	
We	O
also	O
thank	O
the	O
reviewers	O
for	O
their	O
valuable	O
comments	O
.	O
	
bibliography	O
:	O
References	O
	
Holistic	B-Task
,	I-Task
Instance	I-Task
-	I-Task
level	I-Task
Human	I-Task
Parsing	I-Task
	
section	O
:	O
Abstract	O
	
Object	B-Task
parsing	I-Task
-	O
the	O
task	O
of	O
decomposing	B-Task
an	I-Task
object	I-Task
into	O
its	O
semantic	O
parts	O
-	O
has	O
traditionally	O
been	O
formulated	O
as	O
a	O
category	B-Task
-	I-Task
level	I-Task
segmentation	I-Task
problem	I-Task
.	O
	
Consequently	O
,	O
when	O
there	O
are	O
multiple	O
objects	O
in	O
an	O
image	O
,	O
current	O
methods	O
can	O
not	O
count	O
the	O
number	O
of	O
objects	O
in	O
the	O
scene	O
,	O
nor	O
can	O
they	O
determine	O
which	O
part	O
belongs	O
to	O
which	O
object	O
.	O
	
We	O
address	O
this	O
problem	O
by	O
segmenting	O
the	O
parts	O
of	O
objects	O
at	O
an	O
instance	O
-	O
level	O
,	O
such	O
that	O
each	O
pixel	O
in	O
the	O
image	O
is	O
assigned	O
a	O
part	O
label	O
,	O
as	O
well	O
as	O
the	O
identity	O
of	O
the	O
object	O
it	O
belongs	O
to	O
.	O
	
Moreover	O
,	O
we	O
show	O
how	O
this	O
approach	O
benefits	O
us	O
in	O
obtaining	O
segmentations	B-Task
at	O
coarser	O
granularities	O
as	O
well	O
.	O
	
Our	O
proposed	O
network	O
is	O
trained	O
end	O
-	O
to	O
-	O
end	O
given	O
detections	O
,	O
and	O
begins	O
with	O
a	O
category	B-Method
-	I-Method
level	I-Method
segmentation	I-Method
module	I-Method
.	O
	
Thereafter	O
,	O
a	O
differentiable	O
Conditional	B-Method
Random	I-Method
Field	I-Method
,	O
defined	O
over	O
a	O
variable	O
number	O
of	O
instances	O
for	O
every	O
input	O
image	O
,	O
reasons	O
about	O
the	O
identity	O
of	O
each	O
part	O
by	O
associating	O
it	O
with	O
a	O
human	B-Task
detection	I-Task
.	O
	
In	O
contrast	O
to	O
other	O
approaches	O
,	O
our	O
method	O
can	O
handle	O
the	O
varying	O
number	O
of	O
people	O
in	O
each	O
image	O
and	O
our	O
holistic	B-Method
network	I-Method
produces	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
results	O
in	O
instance	B-Method
-	I-Method
level	I-Method
part	I-Method
and	O
human	B-Method
segmentation	I-Method
,	O
together	O
with	O
competitive	O
results	O
in	O
category	B-Task
-	I-Task
level	I-Task
part	I-Task
segmentation	I-Task
,	O
all	O
achieved	O
by	O
a	O
single	O
forward	B-Method
-	I-Method
pass	I-Method
through	O
our	O
neural	B-Method
network	I-Method
.	O
	
section	O
:	O
Introduction	O
	
Object	B-Task
parsing	I-Task
,	O
the	O
segmentation	B-Task
of	O
an	O
object	O
into	O
semantic	O
parts	O
,	O
is	O
naturally	O
performed	O
by	O
humans	O
to	O
obtain	O
a	O
more	O
detailed	O
understanding	O
of	O
the	O
scene	O
.	O
	
When	O
performed	O
automatically	O
by	O
computers	O
,	O
it	O
has	O
many	O
practical	O
applications	O
,	O
such	O
as	O
in	O
human	B-Task
-	I-Task
robot	I-Task
interaction	I-Task
,	O
human	B-Task
behaviour	I-Task
analysis	I-Task
and	O
image	B-Task
descriptions	I-Task
for	O
the	O
visually	B-Task
impaired	I-Task
.	O
	
Furthermore	O
,	O
detailed	O
part	O
information	O
has	O
been	O
shown	O
to	O
be	O
beneficial	O
in	O
other	O
visual	B-Task
recognition	I-Task
tasks	I-Task
such	O
as	O
fine	B-Task
-	I-Task
grained	I-Task
recognition	I-Task
[	O
reference	O
]	O
,	O
human	B-Task
pose	I-Task
estimation	I-Task
[	O
reference	O
]	O
and	O
object	B-Task
detection	I-Task
	
[	O
reference	O
]	O
.	O
	
In	O
this	O
paper	O
,	O
we	O
focus	O
on	O
the	O
application	O
of	O
parsing	B-Task
humans	I-Task
as	O
it	O
is	O
more	O
commonly	O
studied	O
,	O
although	O
our	O
method	O
makes	O
no	O
assumptions	O
on	O
the	O
type	O
of	O
object	O
it	O
is	O
segmenting	O
.	O
	
In	O
contrast	O
to	O
existing	O
human	B-Method
parsing	I-Method
approaches	I-Method
[	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
,	O
we	O
operate	O
at	O
an	O
instance	O
level	O
(	O
to	O
our	O
knowledge	O
,	O
we	O
are	O
the	O
first	O
work	O
to	O
do	O
so	O
)	O
.	O
	
As	O
shown	O
in	O
Fig	O
.	O
1	O
,	O
not	O
only	O
do	O
we	O
segment	O
the	O
various	O
body	O
parts	O
of	O
humans	O
(	O
Fig	O
.	O
	
1b	O
)	O
,	O
	
but	O
we	O
associate	O
each	O
of	O
these	O
parts	O
to	O
one	O
of	O
the	O
humans	O
in	O
the	O
scene	O
(	O
Fig	O
.	O
1c	O
)	O
,	O
which	O
is	O
particularly	O
important	O
for	O
understanding	O
scenes	O
with	O
multiple	O
people	O
.	O
	
In	O
contrast	O
to	O
existing	O
instance	B-Method
segmentation	I-Method
work	O
[	O
reference	O
]	O
Part	B-Task
Segmentation	I-Task
Human	I-Task
Segmentation	I-Task
Figure	O
1	O
:	O
Our	O
proposed	O
approach	O
segments	O
human	O
parts	O
at	O
an	O
instance	O
level	O
(	O
c	O
)	O
(	O
which	O
to	O
our	O
knowledge	O
is	O
the	O
first	O
work	O
to	O
do	O
so	O
)	O
from	O
category	B-Method
-	I-Method
level	I-Method
part	I-Method
segmentations	I-Method
produced	O
earlier	O
in	O
the	O
network	O
(	O
b	O
)	O
.	O
	
Moreover	O
,	O
we	O
can	O
easily	O
obtain	O
human	O
instance	O
segmentations	O
(	O
d	O
)	O
by	O
taking	O
the	O
union	O
of	O
all	O
pixels	O
associated	O
to	O
a	O
particular	O
person	O
.	O
	
Therefore	O
,	O
our	O
proposed	O
end	O
-	O
to	O
-	O
end	B-Method
trained	I-Method
neural	I-Method
network	I-Method
parses	O
humans	O
into	O
semantic	O
parts	O
at	O
both	O
category	O
and	O
instance	O
level	O
in	O
a	O
single	O
forward	O
-	O
pass	O
.	O
	
Best	O
viewed	O
in	O
colour	O
.	O
	
[	O
reference	O
]	O
	
,	O
we	O
operate	O
at	O
a	O
more	O
detailed	O
part	O
level	O
,	O
enabling	O
us	O
to	O
extract	O
more	O
comprehensive	O
information	O
of	O
the	O
scene	O
.	O
	
Furthermore	O
,	O
with	O
our	O
part	B-Method
-	I-Method
level	I-Method
instance	I-Method
segmentation	I-Method
of	I-Method
humans	I-Method
,	O
we	O
can	O
easily	O
recover	O
human	B-Task
-	I-Task
level	I-Task
instance	I-Task
segmentation	I-Task
(	O
by	O
taking	O
the	O
union	O
of	O
all	O
parts	O
assigned	O
to	O
a	O
particular	O
instance	O
as	O
shown	O
in	O
Fig	O
.	O
	
1d	O
)	O
,	O
and	O
we	O
show	O
significant	O
improvement	O
over	O
previous	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
in	O
human	B-Task
instance	I-Task
-	I-Task
segmentation	I-Task
when	O
doing	O
so	O
.	O
	
Our	O
approach	O
is	O
based	O
on	O
a	O
deep	O
Convolutional	B-Method
Neural	I-Method
Network	I-Method
(	O
CNN	B-Method
)	O
,	O
which	O
consists	O
of	O
an	O
initial	O
category	B-Method
-	I-Method
level	I-Method
part	I-Method
segmentation	I-Method
module	I-Method
.	O
	
Using	O
the	O
output	O
of	O
a	O
human	B-Method
detector	I-Method
,	O
we	O
are	O
then	O
able	O
to	O
associate	O
segmented	O
parts	O
with	O
detected	O
humans	O
in	O
the	O
image	O
using	O
a	O
differentiable	O
Conditional	B-Method
Random	I-Method
Field	I-Method
(	O
CRF	B-Method
)	O
,	O
producing	O
a	O
part	B-Method
-	I-Method
level	I-Method
instance	I-Method
segmentation	I-Method
of	O
the	O
image	O
.	O
	
Our	O
formulation	O
is	O
robust	O
to	O
false	O
-	O
positive	O
detections	O
as	O
well	O
as	O
imperfect	O
bounding	O
boxes	O
which	O
do	O
not	O
cover	O
the	O
entire	O
human	O
,	O
in	O
contrast	O
to	O
other	O
instance	B-Method
segmentation	I-Method
methods	I-Method
based	O
on	O
object	B-Method
detectors	I-Method
	
[	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
.	O
Given	O
object	O
detections	O
,	O
our	O
network	O
is	O
trained	O
end	O
-	O
to	O
-	O
end	O
,	O
given	O
detections	O
,	O
with	O
a	O
novel	O
loss	B-Method
function	I-Method
which	O
allows	O
us	O
to	O
handle	O
a	O
variable	O
number	O
of	O
human	O
instances	O
on	O
every	O
image	O
.	O
	
We	O
evaluate	O
our	O
approach	O
on	O
the	O
Pascal	B-Material
Person	I-Material
-	I-Material
Parts	I-Material
[	O
reference	O
]	O
dataset	O
,	O
which	O
contains	O
humans	O
in	O
a	O
diverse	O
set	O
of	O
poses	O
and	O
occlusions	O
.	O
	
We	O
achieve	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
results	O
on	O
instancelevel	B-Task
segmentation	I-Task
of	I-Task
both	I-Task
body	I-Task
parts	I-Task
and	O
humans	O
.	O
	
Moreover	O
,	O
our	O
results	O
on	O
semantic	B-Method
part	I-Method
segmentation	I-Method
(	O
which	O
is	O
not	O
-	O
instance	B-Task
aware	I-Task
)	O
is	O
also	O
competitive	O
with	O
current	O
state	O
-	O
of	O
-	O
theart	O
.	O
	
All	O
of	O
these	O
results	O
are	O
achieved	O
with	O
a	O
holistic	O
,	O
end	B-Method
-	I-Method
to	I-Method
-	I-Method
end	I-Method
trained	I-Method
model	I-Method
which	O
parses	O
humans	O
at	O
both	O
an	O
instance	O
and	O
category	O
level	O
,	O
and	O
outputs	O
a	O
dynamic	O
number	O
of	O
instances	O
per	O
image	O
,	O
all	O
in	O
a	O
single	O
forward	O
-	O
pass	O
through	O
the	O
network	O
.	O
	
section	O
:	O
Related	O
Work	O
	
The	O
problem	O
of	O
object	B-Task
parsing	I-Task
,	O
which	O
aims	O
to	O
decompose	O
objects	O
into	O
their	O
semantic	O
parts	O
,	O
has	O
been	O
addressed	O
by	O
numerous	O
works	O
[	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
,	O
most	O
of	O
which	O
have	O
concentrated	O
on	O
parsing	B-Task
humans	I-Task
.	O
	
However	O
,	O
none	O
of	O
the	O
aforementioned	O
works	O
have	O
parsed	O
objects	O
at	O
an	O
instance	O
level	O
as	O
shown	O
in	O
Fig	O
.	O
1	O
,	O
but	O
rather	O
category	O
level	O
.	O
	
In	O
fact	O
,	O
a	O
lot	O
of	O
work	O
on	O
human	B-Task
parsing	I-Task
has	O
focussed	O
on	O
datasets	O
such	O
as	O
Fashionista	B-Material
[	O
reference	O
]	O
,	O
ATR	B-Material
[	O
reference	O
]	O
and	O
Deep	B-Material
Fashion	I-Material
[	O
reference	O
]	O
where	O
images	O
typically	O
contain	O
only	O
one	O
,	O
centred	O
person	O
.	O
	
The	O
notion	O
of	O
instance	B-Method
-	I-Method
level	I-Method
segmentation	I-Method
only	O
matters	O
when	O
more	O
than	O
one	O
person	O
is	O
present	O
in	O
an	O
image	O
,	O
motivating	O
us	O
to	O
evaluate	O
our	O
method	O
on	O
the	O
Pascal	B-Material
Person	I-Material
-	I-Material
Parts	I-Material
dataset	O
[	O
reference	O
]	O
where	O
multiple	O
people	O
can	O
appear	O
in	O
unconstrained	O
environments	O
.	O
	
Recent	O
human	B-Method
parsing	I-Method
approaches	I-Method
have	O
typically	O
been	O
similar	O
to	O
semantic	B-Task
segmentation	I-Task
works	O
using	O
fully	B-Method
convolutional	I-Method
networks	I-Method
(	O
FCNs	B-Method
)	O
[	O
reference	O
]	O
,	O
but	O
trained	O
to	O
label	O
parts	O
[	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
instead	O
of	O
object	O
classes	O
.	O
	
However	O
,	O
methods	O
using	O
only	O
FCNs	B-Method
do	O
not	O
explicitly	O
model	O
the	O
structure	O
of	O
a	O
human	O
body	O
,	O
and	O
typically	O
do	O
not	O
perform	O
as	O
well	O
as	O
methods	O
which	O
do	O
[	O
reference	O
]	O
.	O
Structural	O
priors	O
of	O
the	O
human	O
body	O
have	O
been	O
encoded	O
using	O
pictorial	O
structures	O
[	O
reference	O
][	O
reference	O
]	O
,	O
Conditional	B-Method
Random	I-Method
Fields	I-Method
(	O
CRFs	B-Method
)	O
	
[	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
and	O
more	O
recently	O
,	O
with	O
LSTMs	B-Method
	
[	O
reference	O
][	O
reference	O
]	O
.	O
	
The	O
HAZN	B-Method
approach	I-Method
of	O
[	O
reference	O
]	O
addressed	O
the	O
problem	O
that	O
some	O
parts	O
are	O
often	O
very	O
small	O
compared	O
to	O
other	O
parts	O
and	O
difficult	O
to	O
segment	O
with	O
scale	B-Method
-	I-Method
variant	I-Method
CNNs	I-Method
.	O
	
This	O
scale	O
variation	O
was	O
handled	O
by	O
a	O
cascade	B-Method
of	O
three	O
separatelytrained	B-Method
FCNs	I-Method
,	O
each	O
parsing	O
different	O
regions	O
of	O
the	O
image	O
at	O
different	O
scales	O
.	O
	
An	O
early	O
instance	B-Task
segmentation	I-Task
work	O
by	O
Winn	O
et	O
al	O
.	O
	
[	O
reference	O
]	O
predicted	O
the	O
parts	O
of	O
an	O
object	O
,	O
and	O
then	O
encouraged	O
these	O
parts	O
to	O
maintain	O
a	O
spatial	O
ordering	O
,	O
characteristic	O
of	O
an	O
instance	O
,	O
using	O
asymmetric	O
pairwise	O
potentials	O
in	O
a	O
CRF	B-Method
.	O
	
However	O
,	O
subsequent	O
work	O
has	O
not	O
operated	O
at	O
a	O
part	O
level	O
.	O
	
Zhang	O
et	O
al	O
.	O
	
[	O
reference	O
][	O
reference	O
]	O
performed	O
instance	B-Task
segmentation	I-Task
of	I-Task
vehicles	I-Task
using	O
an	O
MRF	B-Method
.	O
	
However	O
,	O
this	O
graphical	B-Method
model	I-Method
was	O
not	O
trained	O
end	O
-	O
to	O
-	O
end	O
as	O
done	O
by	O
[	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
and	O
our	O
approach	O
.	O
	
Furthermore	O
,	O
they	O
assumed	O
a	O
maximum	O
of	O
9	O
cars	O
per	O
image	O
.	O
	
Approaches	O
using	O
recurrent	B-Method
neural	I-Method
networks	I-Method
[	O
reference	O
][	O
reference	O
]	O
can	O
handle	O
a	O
variable	O
number	O
of	O
instances	O
per	O
image	O
by	O
segmenting	O
an	O
instance	O
per	O
time	O
-	O
step	O
,	O
but	O
are	O
currently	O
restricted	O
to	O
only	O
one	O
object	O
category	O
.	O
	
Our	O
method	O
,	O
on	O
the	O
other	O
hand	O
,	O
is	O
able	O
to	O
handle	O
both	O
an	O
arbitrary	O
number	O
of	O
objects	O
,	O
and	O
multiple	O
object	O
categories	O
in	O
the	O
image	O
with	O
a	O
single	O
forward	O
-	O
pass	O
through	O
the	O
network	O
.	O
	
Various	O
methods	O
of	O
instance	B-Task
segmentation	I-Task
have	O
also	O
involved	O
modifying	O
object	B-Method
detection	I-Method
systems	I-Method
to	O
output	O
segments	O
instead	O
of	O
bounding	O
boxes	O
[	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
.	O
	
However	O
,	O
these	O
methods	O
can	O
not	O
produce	O
a	O
segmentation	B-Task
map	I-Task
of	I-Task
the	I-Task
image	I-Task
,	O
as	O
shown	O
in	O
Fig	O
.	O
1	O
,	O
without	O
postprocessing	O
as	O
they	O
consider	O
each	O
detection	O
independently	O
.	O
	
Although	O
our	O
method	O
also	O
uses	O
an	O
object	B-Method
detector	I-Method
,	O
it	O
considers	O
all	O
detections	O
in	O
the	O
image	O
jointly	O
with	O
an	O
initial	O
category	B-Method
-	I-Method
level	I-Method
segmentation	I-Method
,	O
and	O
produces	O
segmentation	B-Task
maps	I-Task
naturally	O
where	O
one	O
pixel	O
can	O
not	O
belong	O
to	O
multiple	O
instances	O
in	O
contrast	O
to	O
the	O
aforementioned	O
approaches	O
.	O
	
The	O
idea	O
of	O
combining	O
the	O
outputs	O
of	O
a	O
category	B-Method
-	I-Method
level	I-Method
segmentation	I-Method
network	I-Method
and	O
an	O
object	B-Method
detector	I-Method
to	O
reason	O
about	O
different	O
instances	O
was	O
also	O
presented	O
by	O
[	O
reference	O
]	O
.	O
However	O
,	O
that	O
system	O
was	O
not	O
trained	O
end	O
-	O
toend	O
,	O
could	O
not	O
segment	O
instances	O
outside	O
the	O
detector	O
's	O
bounding	O
box	O
,	O
and	O
did	O
not	O
operate	O
at	O
a	O
part	O
level	O
.	O
	
section	O
:	O
Proposed	O
Approach	O
	
Our	O
network	O
(	O
Fig	O
.	O
2	O
)	O
consists	O
of	O
two	O
components	O
:	O
a	O
category	B-Method
-	I-Method
level	I-Method
part	I-Method
segmentation	I-Method
module	I-Method
,	O
and	O
an	O
instance	B-Method
segmentation	I-Method
module	I-Method
.	O
	
As	O
both	O
of	O
these	O
modules	O
are	O
differentiable	O
,	O
they	O
can	O
be	O
integrated	O
into	O
a	O
single	O
network	O
and	O
trained	O
jointly	O
.	O
	
The	O
instance	B-Method
segmentation	I-Method
module	I-Method
(	O
Sec	O
.	O
3.2	O
)	O
uses	O
the	O
output	O
of	O
the	O
first	B-Method
category	I-Method
-	I-Method
level	I-Method
segmentation	I-Method
module	I-Method
(	O
Sec	O
.	O
3.1	O
)	O
as	O
well	O
as	O
the	O
outputs	O
of	O
an	O
object	B-Method
detector	I-Method
as	O
its	O
input	O
.	O
	
It	O
associates	O
each	O
pixel	O
in	O
the	O
categorylevel	B-Method
segmentation	I-Method
with	O
an	O
object	B-Task
detection	I-Task
,	O
resulting	O
in	O
an	O
instance	B-Method
-	I-Method
level	I-Method
segmentation	I-Method
of	O
the	O
image	O
.	O
	
Given	O
a	O
H	O
×W	O
×	O
3	O
input	O
image	O
,	O
I	O
,	O
the	O
category	B-Method
-	I-Method
level	I-Method
part	I-Method
segmentation	I-Method
module	I-Method
produces	O
a	O
H	O
	
×W	O
	
×	O
	
(	O
P	O
+	O
1	O
)	O
dimensional	O
output	O
Q	O
where	O
P	O
is	O
the	O
number	O
of	O
part	O
classes	O
in	O
the	O
dataset	O
and	O
one	O
background	O
class	O
.	O
	
There	O
can	O
be	O
a	O
variable	O
number	O
,	O
D	O
,	O
of	O
human	O
detections	O
per	O
image	O
,	O
and	O
the	O
output	O
of	O
the	O
instance	B-Method
segmentation	I-Method
module	I-Method
is	O
an	O
H	O
	
×W	O
	
×	O
(	O
PD	O
+	O
1	O
)	O
tensor	O
denoting	O
the	O
probabilities	O
,	O
at	O
each	O
pixel	O
in	O
the	O
image	O
,	O
of	O
each	O
of	O
the	O
P	O
part	O
classes	O
belonging	O
to	O
one	O
of	O
the	O
D	O
detections	O
.	O
	
Two	O
challenges	O
of	O
instance	B-Task
segmentation	I-Task
are	O
the	O
variable	O
number	O
of	O
instances	O
in	O
every	O
image	O
,	O
and	O
the	O
fact	O
that	O
permutations	O
of	O
instance	O
labels	O
lead	O
to	O
identical	O
results	O
(	O
in	O
Fig	O
.	O
	
1	O
,	O
how	O
we	O
order	O
the	O
different	O
people	O
does	O
not	O
matter	O
)	O
.	O
	
Zhang	O
et	O
al	O
.	O
	
[	O
reference	O
][	O
reference	O
]	O
resolve	O
these	O
issues	O
by	O
assuming	O
a	O
maximum	O
number	O
of	O
instances	O
and	O
using	O
the	O
ground	O
-	O
truth	O
depth	O
ordering	O
of	O
instances	O
respectively	O
.	O
	
Others	O
have	O
bypassed	O
both	O
of	O
these	O
issues	O
by	O
predicting	O
each	O
instance	O
independently	O
[	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
,	O
but	O
this	O
also	O
allows	O
a	O
pixel	O
to	O
belong	O
to	O
multiple	O
instances	O
.	O
	
Instead	O
,	O
we	O
use	O
a	O
loss	O
function	O
(	O
Sec	B-Method
3.3	I-Method
)	O
that	O
is	O
based	O
on	O
"	O
matching	O
"	O
the	O
prediction	O
to	O
the	O
ground	O
-	O
truth	O
,	O
allowing	O
us	O
to	O
handle	O
permutations	O
of	O
the	O
ground	O
truth	O
.	O
	
Furthermore	O
,	O
weight	B-Method
-	I-Method
sharing	I-Method
in	O
our	O
instance	B-Method
segmentation	I-Method
module	I-Method
allows	O
us	O
to	O
segment	O
a	O
variable	O
number	O
of	O
instances	O
per	O
image	O
.	O
	
As	O
a	O
result	O
,	O
we	O
do	O
not	O
assume	O
a	O
maximum	O
number	O
of	O
instances	O
,	O
consider	O
all	O
instances	O
jointly	O
,	O
and	O
train	O
our	O
network	O
end	O
-	O
to	O
-	O
end	O
,	O
given	O
object	B-Task
detections	I-Task
.	O
	
section	O
:	O
Category	B-Method
-	I-Method
level	I-Method
part	I-Method
segmentation	I-Method
module	I-Method
	
The	O
part	B-Method
segmentation	I-Method
module	I-Method
is	O
a	O
fully	B-Method
convolutional	I-Method
network	I-Method
[	O
reference	O
]	O
based	O
on	O
ResNet	B-Method
-	I-Method
101	I-Method
	
[	O
reference	O
]	O
.	O
A	O
common	O
technique	O
,	O
presented	O
in	O
[	O
reference	O
][	O
reference	O
]	O
,	O
is	O
to	O
predict	O
the	O
image	O
at	O
three	O
different	O
scales	O
(	O
with	O
network	O
weights	O
shared	O
among	O
all	O
the	O
scales	O
)	O
,	O
and	O
combine	O
predictions	O
together	O
with	O
learned	O
,	O
image	O
-	O
dependent	O
weights	O
.	O
	
We	O
take	O
a	O
different	O
approach	O
of	O
fusing	O
information	O
at	O
multiple	O
scales	O
-	O
we	O
pool	O
the	O
features	O
after	O
res5c	O
[	O
reference	O
]	O
at	O
five	O
different	O
resolutions	O
(	O
by	O
varying	O
the	O
pooling	O
stride	O
)	O
,	O
upsample	O
the	O
features	O
to	O
the	O
resolution	O
before	O
pooling	O
,	O
and	O
then	O
concatenate	O
these	O
features	O
before	O
passing	O
them	O
to	O
the	O
final	O
convolutional	B-Method
classifier	I-Method
,	O
as	O
proposed	O
in	O
[	O
reference	O
]	O
.	O
	
As	O
we	O
show	O
in	O
Sec	O
4.4	O
,	O
this	O
approach	O
achieves	O
better	O
semantic	B-Task
segmentation	I-Task
results	O
than	O
[	O
reference	O
][	O
reference	O
]	O
.	O
	
We	O
denote	O
the	O
output	O
of	O
this	O
module	O
by	O
the	O
tensor	O
,	O
Q	O
,	O
where	O
Q	O
i	O
(	O
l	O
)	O
is	O
the	O
probability	O
of	O
pixel	O
i	O
being	O
assigned	O
label	O
l	O
∈	O
{	O
0	O
,	O
1	O
,	O
2	O
,	O
...	O
,	O
	
P}.	O
Further	O
details	O
of	O
this	O
module	O
are	O
included	O
in	O
the	O
appendix	O
.	O
	
section	O
:	O
Instance	B-Method
-	I-Method
level	I-Method
segmentation	I-Method
module	I-Method
	
This	O
module	O
creates	O
an	O
instance	B-Method
-	I-Method
level	I-Method
segmentation	I-Method
of	O
the	O
image	O
by	O
associating	O
each	O
pixel	O
in	O
the	O
input	O
category	B-Method
-	I-Method
level	I-Method
segmentation	I-Method
,	O
Q	O
,	O
with	O
one	O
of	O
the	O
D	O
input	O
human	O
-	O
detections	O
or	O
the	O
background	O
label	O
.	O
	
Let	O
there	O
be	O
D	O
input	O
human	O
-	O
detections	O
for	O
the	O
image	O
,	O
where	O
the	O
i	O
-	O
th	O
detection	O
is	O
represented	O
by	O
B	O
i	O
,	O
the	O
set	O
of	O
pixels	O
lying	O
within	O
the	O
four	O
corners	O
of	O
its	O
bounding	O
box	O
,	O
and	O
s	O
i	O
∈	O
[	O
0	O
,	O
1	O
]	O
,	O
the	O
detection	B-Metric
score	I-Metric
.	O
	
We	O
assume	O
that	O
the	O
0	B-Task
-	I-Task
th	I-Task
detection	I-Task
refers	O
to	O
the	O
background	O
label	O
.	O
	
Furthermore	O
,	O
we	O
define	O
a	O
multinomial	O
random	O
variable	O
,	O
V	O
i	O
,	O
at	O
each	O
of	O
the	O
N	O
pixels	O
in	O
the	O
image	O
,	O
and	O
let	O
	
.	O
	
This	O
variable	O
can	O
take	O
on	O
a	O
label	O
from	O
the	O
set	O
{	O
1	O
,	O
2	O
,	O
...	O
,	O
D	O
}	O
×	O
{	O
1	O
,	O
2	O
,	O
...	O
	
,	O
P	O
}	O
∪	O
{	O
(	O
0	O
,	O
0	O
)	O
}	O
since	O
each	O
of	O
the	O
P	O
part	O
labels	O
can	O
be	O
associated	O
with	O
one	O
of	O
the	O
D	O
human	O
detections	O
,	O
or	O
that	O
pixel	O
could	O
belong	O
to	O
the	O
background	O
label	O
,	O
(	O
0	O
,	O
0	O
)	O
.	O
	
We	O
formulate	O
a	O
Conditional	B-Method
Random	I-Method
Field	I-Method
over	O
these	O
V	O
variables	O
,	O
where	O
the	O
energy	O
of	O
the	O
assignment	O
v	O
to	O
all	O
of	O
the	O
instance	O
variables	O
V	O
consists	O
of	O
two	O
unary	O
terms	O
,	O
and	O
one	O
pairwise	O
term	O
(	O
whose	O
weighting	O
co	O
-	O
efficients	O
are	O
all	O
learned	O
via	O
backpropagation	B-Method
)	O
:	O
	
(	O
	
The	O
unary	O
and	O
pairwise	O
potentials	O
are	O
computed	O
within	O
our	O
neural	B-Method
network	I-Method
,	O
differentiable	O
with	O
respect	O
to	O
their	O
input	O
and	O
parameters	O
,	O
and	O
described	O
in	O
Sec	O
.	O
	
3.2.1	O
through	O
3.2.3	O
.	O
	
The	O
Maximum	B-Method
-	I-Method
a	I-Method
-	I-Method
Posteriori	I-Method
(	I-Method
MAP	I-Method
)	I-Method
estimate	I-Method
of	O
our	O
CRF	B-Method
(	O
since	O
the	O
energy	O
in	O
Eq	O
.	O
1	O
characterises	O
a	O
Gibbs	O
distribution	O
)	O
is	O
computed	O
as	O
the	O
final	O
labelling	B-Task
produced	O
by	O
our	O
network	O
.	O
	
We	O
perform	O
the	O
iterative	B-Method
mean	I-Method
-	I-Method
field	I-Method
inference	I-Method
algorithm	I-Method
to	O
approximately	O
compute	O
the	O
MAP	B-Method
solution	I-Method
by	O
minimising	O
Eq	O
.	O
1	O
.	O
	
As	O
shown	O
by	O
Zheng	O
et	O
al	O
.	O
	
[	O
reference	O
]	O
,	O
this	O
can	O
be	O
formulated	O
as	O
a	O
Recurrent	B-Method
Neural	I-Method
Network	I-Method
(	O
RNN	B-Method
)	I-Method
,	O
allowing	O
it	O
to	O
be	O
trained	O
end	O
-	O
to	O
-	O
end	O
as	O
part	O
of	O
a	O
larger	O
network	O
.	O
	
However	O
,	O
as	O
our	O
network	O
is	O
input	O
a	O
variable	O
number	O
of	O
detections	O
per	O
image	O
,	O
D	O
,	O
the	O
label	O
space	O
of	O
the	O
CRF	B-Method
is	O
dynamic	O
.	O
	
Therefore	O
,	O
unlike	O
[	O
reference	O
]	O
,	O
the	O
parameters	O
of	O
our	O
CRF	B-Method
are	O
not	O
class	O
-	O
specific	O
to	O
allow	O
for	O
this	O
variable	O
number	O
of	O
"	O
channels	O
"	O
.	O
	
section	O
:	O
Box	O
Consistency	O
Term	O
	
We	O
observe	O
that	O
in	O
most	O
cases	O
,	O
a	O
body	O
part	O
belonging	O
to	O
a	O
person	O
is	O
located	O
inside	O
the	O
bounding	O
box	O
of	O
the	O
person	O
.	O
	
Based	O
on	O
this	O
observation	O
,	O
the	O
box	B-Method
consistency	I-Method
term	I-Method
is	O
employed	O
to	O
encourage	O
pixel	O
locations	O
inside	O
a	O
human	O
bounding	O
box	O
B	O
i	O
to	O
be	O
associated	O
with	O
the	O
i	O
-	O
th	O
human	B-Task
detection	I-Task
.	O
	
The	O
box	O
term	O
potential	O
at	O
spatial	O
location	O
k	O
for	O
body	O
part	O
j	O
of	O
a	O
human	O
i	O
is	O
assigned	O
either	O
0	O
for	O
k	O
/	O
∈	O
B	O
i	O
,	O
or	O
the	O
product	O
of	O
the	O
detection	B-Metric
score	I-Metric
,	O
s	O
i	O
,	O
and	O
the	O
category	O
-	O
level	O
part	O
segmentation	O
confidence	O
,	O
	
Note	O
that	O
this	O
potential	O
may	O
be	O
robust	O
to	O
false	B-Task
-	I-Task
positive	I-Task
detections	I-Task
when	O
the	O
category	B-Task
-	I-Task
level	I-Task
segmentation	I-Task
and	O
human	B-Task
detection	I-Task
do	O
not	O
agree	O
with	O
each	O
other	O
,	O
since	O
Q	O
k	O
(	O
l	O
)	O
,	O
the	O
probability	O
of	O
a	O
pixel	O
k	O
taking	O
on	O
body	O
-	O
part	O
label	O
l	O
,	O
is	O
low	O
.	O
	
Furthermore	O
,	O
note	O
that	O
we	O
use	O
one	O
humandetection	O
to	O
reason	O
about	O
the	O
identity	O
of	O
all	O
parts	O
which	O
constitute	O
that	O
human	O
.	O
	
section	O
:	O
Global	O
Term	O
	
A	O
possible	O
shortcoming	O
for	O
the	O
box	O
consistency	O
potential	O
is	O
that	O
if	O
some	O
pixels	O
belonging	O
to	O
a	O
human	O
instance	O
fall	O
outside	O
the	O
bounding	O
box	O
and	O
are	O
consequently	O
assigned	O
0	O
for	O
the	O
box	O
consistency	O
term	O
potential	O
,	O
they	O
would	O
be	O
lost	O
in	O
the	O
final	O
instance	B-Task
segmentation	I-Task
prediction	I-Task
.	O
	
Visually	O
,	O
the	O
generated	O
instance	O
masks	O
would	O
appear	O
truncated	O
along	O
the	O
bounding	O
box	O
boundaries	O
-	O
a	O
problem	O
suffered	O
by	O
[	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
.	O
To	O
overcome	O
this	O
undesirable	O
effect	O
,	O
we	O
introduce	O
the	O
global	O
potential	O
:	O
it	O
complements	O
the	O
box	O
consistency	O
term	O
by	O
assuming	O
that	O
a	O
pixel	O
is	O
equally	O
likely	O
to	O
belong	O
to	O
any	O
one	O
of	O
the	O
detected	O
humans	O
.	O
	
It	O
is	O
expressed	O
as	O
	
Prediction	B-Task
,	O
P	O
Original	O
ground	O
-	O
truth	O
,	O
Y	O
"	O
Matched	O
"	O
ground	O
-	O
truth	O
,	O
Y	O
*	O
Figure	O
3	O
:	O
As	O
different	O
permutations	O
of	O
the	O
ground	O
-	O
truth	O
are	O
equivalent	O
in	O
the	O
case	O
of	O
instance	B-Task
segmentation	I-Task
,	O
we	O
"	O
match	O
"	O
the	O
original	O
ground	O
-	O
truth	O
,	O
Y	O
,	O
to	O
our	O
network	O
's	O
prediction	B-Method
,	O
P	O
,	O
to	O
obtain	O
the	O
"	O
matched	O
"	O
ground	O
-	O
truth	O
which	O
we	O
use	O
to	O
compute	O
our	O
loss	B-Metric
during	O
training	B-Task
.	O
	
section	O
:	O
Pairwise	B-Method
Term	I-Method
	
Our	O
pairwise	O
term	O
is	O
composed	O
of	O
densely	B-Method
-	I-Method
connected	I-Method
Gaussian	I-Method
kernels	I-Method
[	O
reference	O
]	O
which	O
are	O
commonly	O
used	O
in	O
segmentation	B-Task
literature	O
	
[	O
reference	O
][	O
reference	O
]	O
.	O
	
This	O
pairwise	O
potential	O
encourages	O
both	O
spatial	O
and	O
appearance	O
consistency	O
,	O
and	O
we	O
find	O
these	O
priors	O
to	O
be	O
suitable	O
in	O
the	O
case	O
of	O
instancelevel	B-Task
segmentation	I-Task
as	O
well	O
.	O
	
As	O
in	O
[	O
reference	O
]	O
,	O
the	O
weighting	O
parameters	O
of	O
these	O
potentials	O
are	O
learned	O
via	O
backpropagation	B-Method
,	O
though	O
in	O
our	O
case	O
,	O
the	O
weights	O
are	O
shared	O
among	O
all	O
classes	O
.	O
	
section	O
:	O
Loss	O
function	O
and	O
network	B-Method
training	I-Method
	
We	O
first	O
pre	O
-	O
train	O
the	O
category	B-Method
-	I-Method
level	I-Method
segmentation	I-Method
part	I-Method
of	O
our	O
network	O
,	O
as	O
described	O
in	O
the	O
appendix	O
.	O
	
Thereafter	O
,	O
we	O
add	O
the	O
instance	B-Method
segmentation	I-Method
module	I-Method
,	O
and	O
train	O
with	O
a	O
permutationinvariant	B-Method
loss	I-Method
function	I-Method
which	O
is	O
backpropagated	O
through	O
both	O
our	O
instance	B-Method
-	I-Method
and	I-Method
categorylevel	I-Method
segmentation	I-Method
networks	I-Method
.	O
	
Since	O
all	O
permutations	O
of	O
an	O
instance	O
segmentation	O
have	O
the	O
same	O
qualitative	O
result	O
,	O
we	O
"	O
match	O
"	O
the	O
original	O
ground	O
-	O
truth	O
to	O
our	O
prediction	O
before	O
computing	O
the	O
loss	B-Metric
,	O
as	O
shown	O
in	O
Fig	O
.	O
	
3	O
.	O
	
This	O
matching	O
is	O
based	O
on	O
the	O
Intersection	B-Method
over	I-Method
Union	I-Method
(	I-Method
IoU	I-Method
)	I-Method
[	O
reference	O
]	O
of	O
a	O
predicted	O
and	O
ground	O
-	O
truth	O
instance	O
,	O
similar	O
to	O
[	O
reference	O
]	O
.	O
Let	O
Y	O
=	O
{	O
y	O
1	O
,	O
y	O
2	O
,	O
...	O
,	O
y	O
m	O
}	O
,	O
a	O
set	O
of	O
m	O
segments	O
,	O
denote	O
the	O
ground	O
-	O
truth	O
labelling	O
of	O
an	O
image	O
,	O
where	O
each	O
segment	O
is	O
an	O
instance	O
and	O
has	O
a	O
part	O
label	O
assigned	O
to	O
it	O
.	O
	
Similarly	O
,	O
let	O
P	O
=	O
{	O
p	O
1	O
,	O
p	O
2	O
,	O
...	O
,	O
p	O
n	O
}	O
denote	O
our	O
n	O
predicted	O
instances	O
,	O
each	O
with	O
an	O
associated	O
part	O
label	O
.	O
	
Note	O
that	O
m	O
and	O
n	O
need	O
not	O
be	O
the	O
same	O
as	O
we	O
may	O
predict	O
greater	O
or	O
fewer	O
instances	O
than	O
there	O
actually	O
are	O
in	O
the	O
image	O
.	O
	
The	O
"	O
matched	O
"	O
ground	O
truth	O
,	O
Y	O
*	O
is	O
the	O
permutation	O
of	O
the	O
original	O
ground	B-Method
-	I-Method
truth	I-Method
labelling	I-Method
which	O
maximises	O
the	O
IoU	B-Metric
between	O
our	O
prediction	O
,	O
P	O
and	O
ground	O
-	O
truth	O
	
where	O
π	O
(	O
Y	O
)	O
denotes	O
the	O
set	O
of	O
all	O
permutations	O
of	O
Y.	O
Note	O
that	O
we	O
define	O
the	O
IoU	O
between	O
all	O
segments	O
of	O
different	O
labels	O
to	O
be	O
0	O
.	O
	
Eq	O
.	O
	
4	O
can	O
be	O
solved	O
efficiently	O
using	O
the	O
Hungarian	B-Method
algorithm	I-Method
as	O
it	O
can	O
be	O
formulated	O
as	O
a	O
bipartite	B-Task
graph	I-Task
matching	I-Task
problem	I-Task
,	O
and	O
once	O
we	O
have	O
the	O
"	O
matched	O
"	O
ground	O
-	O
truth	O
,	O
Y	O
*	O
,	O
we	O
can	O
apply	O
any	O
loss	B-Method
function	I-Method
to	O
it	O
and	O
train	O
our	O
network	O
for	O
segmentation	B-Task
.	O
	
In	O
our	O
case	O
,	O
we	O
use	O
the	O
standard	O
cross	B-Method
-	I-Method
entropy	I-Method
loss	I-Method
function	I-Method
on	O
the	O
"	O
matched	O
"	O
ground	O
truth	O
.	O
	
In	O
addition	O
,	O
we	O
employ	O
Online	B-Task
Hard	I-Task
Example	I-Task
Mining	I-Task
(	O
OHEM	B-Method
)	I-Method
,	O
and	O
only	O
compute	O
our	O
loss	B-Metric
over	O
the	O
top	O
K	O
pixels	O
with	O
the	O
highest	O
loss	O
in	O
the	O
training	O
mini	O
-	O
batch	O
.	O
	
We	O
found	O
that	O
during	O
training	O
,	O
many	O
pixels	O
already	O
had	O
a	O
high	O
probability	O
of	O
being	O
assigned	O
to	O
the	O
correct	O
class	O
.	O
	
By	O
only	O
selecting	O
the	O
top	O
K	O
pixels	O
with	O
the	O
highest	O
loss	O
,	O
we	O
are	O
able	O
to	O
encourage	O
our	O
network	O
to	O
improve	O
on	O
the	O
pixels	O
it	O
is	O
currently	O
misclassifying	O
,	O
as	O
opposed	O
to	O
increasing	O
the	O
probability	O
of	O
a	O
pixel	O
it	O
is	O
already	O
classifying	O
correctly	O
.	O
	
This	O
approach	O
was	O
inspired	O
by	O
"	O
bootstrapping	B-Method
"	O
[	O
reference	O
][	O
reference	O
]	O
or	O
"	O
hard	B-Method
-	I-Method
negative	I-Method
mining	I-Method
"	O
[	O
reference	O
]	O
commonly	O
used	O
in	O
training	O
object	B-Method
detectors	I-Method
.	O
	
However	O
,	O
these	O
methods	O
mined	O
hard	O
examples	O
from	O
the	O
entire	O
dataset	O
.	O
	
Our	O
approach	O
is	O
most	O
similar	O
to	O
[	O
reference	O
]	O
,	O
who	O
mined	O
hard	O
examples	O
online	O
from	O
each	O
mini	O
-	O
batch	O
in	O
the	O
context	O
of	O
detection	B-Task
.	O
	
Similar	O
to	O
the	O
aforementioned	O
works	O
,	O
we	O
found	O
OHEM	B-Method
to	O
improve	O
our	O
overall	O
results	O
,	O
as	O
shown	O
in	O
Sec	O
.	O
	
4.2	O
.	O
	
section	O
:	O
Obtaining	O
segmentations	B-Task
at	O
other	O
granularities	O
	
Given	O
the	O
part	B-Method
instance	I-Method
prediction	I-Method
produced	O
by	O
our	O
proposed	O
network	O
,	O
we	O
are	O
able	O
to	O
easily	O
obtain	O
human	B-Method
instance	I-Method
segmentation	I-Method
and	O
semantic	B-Method
part	I-Method
segmentation	I-Method
.	O
	
In	O
order	O
to	O
achieve	O
human	B-Method
instance	I-Method
segmentation	I-Method
,	O
we	O
map	O
the	O
predicted	O
part	O
instance	O
labels	O
(	O
i	O
,	O
j	O
)	O
,	O
i.e.	O
part	O
j	O
of	O
person	O
i	O
,	O
to	O
i.	O
	
Whereas	O
to	O
obtain	O
semantic	B-Method
part	I-Method
segmentation	I-Method
,	O
we	O
map	O
predicted	O
part	O
instance	O
labels	O
(	O
i	O
,	O
j	O
)	O
to	O
j	O
instead	O
.	O
	
section	O
:	O
Experiments	O
	
We	O
describe	O
our	O
dataset	O
and	O
experimental	O
set	O
-	O
up	O
in	O
Sec	O
.	O
	
4.1	O
,	O
before	O
presenting	O
results	O
on	O
instance	B-Method
-	I-Method
level	I-Method
part	I-Method
segmentation	I-Method
(	O
Fig	O
.	O
1c	O
)	O
,	O
instance	B-Method
-	I-Method
level	I-Method
human	I-Method
segmentation	I-Method
(	O
	
Fig	O
.	O
1d	O
)	O
and	O
semantic	B-Method
part	I-Method
segmentation	I-Method
	
(	O
Fig	O
.	O
	
1b	O
)	O
.	O
	
Additional	O
quantitative	O
and	O
qualitative	O
results	O
,	O
failure	O
cases	O
and	O
experimental	O
details	O
are	O
included	O
in	O
the	O
appendix	O
.	O
	
section	O
:	O
Experimental	O
Set	O
-	O
up	O
	
We	O
evaluate	O
our	O
proposed	O
method	O
on	O
the	O
Pascal	B-Material
Person	I-Material
-	I-Material
Part	I-Material
dataset	I-Material
[	O
reference	O
]	O
which	O
contains	O
1716	O
training	O
images	O
,	O
and	O
1817	O
test	O
images	O
.	O
	
This	O
dataset	O
contains	O
multiple	O
people	O
per	O
image	O
in	O
unconstrained	O
poses	O
and	O
environments	O
,	O
and	O
contains	O
six	O
human	O
body	O
part	O
classes	O
(	O
Fig	O
.	O
1b	O
)	O
,	O
as	O
well	O
as	O
the	O
background	O
label	O
.	O
	
As	O
described	O
in	O
Sec	O
.	O
	
3.3	O
	
,	O
we	O
initially	O
pre	O
-	O
train	O
our	O
categorylevel	B-Method
segmentation	I-Method
module	I-Method
before	O
training	O
for	O
instance	B-Method
-	I-Method
level	I-Method
segmentation	I-Method
.	O
	
This	O
module	O
is	O
first	O
trained	O
on	O
the	O
21	O
classes	O
of	O
the	O
Pascal	B-Material
VOC	I-Material
dataset	I-Material
[	O
reference	O
]	O
,	O
and	O
then	O
finetuned	O
on	O
the	O
seven	O
classes	O
of	O
the	O
Pascal	B-Material
Part	I-Material
training	I-Material
set	I-Material
using	O
category	O
-	O
level	O
annotations	O
.	O
	
Finally	O
,	O
we	O
train	O
for	O
instance	B-Task
segmentation	I-Task
with	O
instance	O
-	O
level	O
ground	O
truth	O
.	O
	
Full	O
details	O
of	O
our	O
training	O
process	O
,	O
including	O
all	O
hyperparameters	B-Method
such	O
as	O
learning	B-Metric
rate	I-Metric
,	O
are	O
in	O
the	O
appendix	O
.	O
	
To	O
clarify	O
these	O
details	O
,	O
we	O
will	O
also	O
release	O
our	O
code	O
.	O
	
We	O
use	O
the	O
standard	O
AP	B-Metric
r	I-Metric
metric	I-Metric
[	O
reference	O
]	O
for	O
evaluating	O
instance	B-Method
-	I-Method
level	I-Method
segmentation	I-Method
:	O
the	O
mean	B-Metric
Average	I-Metric
Precision	I-Metric
of	O
our	O
predictions	O
is	O
computed	O
where	O
a	O
prediction	B-Task
is	O
considered	O
correct	O
if	O
its	O
IoU	O
with	O
a	O
ground	O
-	O
truth	O
instance	O
is	O
above	O
a	O
certain	O
threshold	O
.	O
	
This	O
is	O
similar	O
to	O
the	O
AP	B-Metric
metric	I-Metric
used	O
in	O
object	B-Task
detection	I-Task
.	O
	
However	O
,	O
in	O
detection	B-Task
,	O
the	O
IoU	O
between	O
groundtruth	O
and	O
predicted	O
bounding	O
boxes	O
is	O
computed	O
,	O
whereas	O
here	O
,	O
the	O
IoU	O
between	O
regions	O
is	O
computed	O
.	O
	
Furthermore	O
,	O
in	O
detection	B-Task
,	O
an	O
overlap	O
threshold	O
of	O
0.5	O
is	O
used	O
,	O
whereas	O
we	O
vary	O
this	O
threshold	O
.	O
	
Finally	O
,	O
we	O
define	O
the	O
AP	B-Metric
r	I-Metric
vol	O
which	O
is	O
the	O
mean	O
of	O
the	O
AP	B-Metric
	
r	B-Metric
score	O
for	O
overlap	O
thresholds	O
varying	O
from	O
0.1	O
to	O
0.9	O
in	O
increments	O
of	O
0.1	O
.	O
	
We	O
use	O
the	O
publicly	O
available	O
R	B-Method
-	I-Method
FCN	I-Method
detection	I-Method
framework	I-Method
[	O
reference	O
]	O
,	O
and	O
train	O
a	O
new	O
model	O
with	O
data	O
from	O
VOC	B-Material
2012	O
[	O
reference	O
]	O
that	O
do	O
not	O
overlap	O
with	O
any	O
of	O
our	O
test	O
sets	O
.	O
	
We	O
train	O
with	O
all	O
object	O
classes	O
of	O
VOC	B-Material
,	O
and	O
only	O
use	O
the	O
output	O
for	O
the	O
human	O
class	O
.	O
	
Non	B-Method
-	I-Method
maximal	I-Method
suppression	I-Method
is	O
performed	O
on	O
all	O
detections	O
before	O
being	O
fed	O
into	O
our	O
network	O
.	O
	
Table	O
1	O
shows	O
our	O
results	O
on	O
part	B-Task
-	I-Task
level	I-Task
instance	I-Task
segmentation	I-Task
on	O
the	O
Pascal	B-Material
Person	I-Material
-	I-Material
Part	I-Material
dataset	I-Material
.	O
	
To	O
our	O
knowledge	O
,	O
we	O
are	O
the	O
first	O
work	O
to	O
do	O
this	O
,	O
and	O
hence	O
we	O
study	O
the	O
effects	O
of	O
various	O
design	O
choices	O
on	O
overall	O
performance	O
.	O
	
We	O
also	O
use	O
the	O
publicly	O
available	O
code	O
for	O
MNC	B-Method
[	O
reference	O
]	O
,	O
which	O
won	O
the	O
MS	B-Material
-	I-Material
COCO	I-Material
2016	I-Material
instance	I-Material
segmentation	I-Material
challenge	I-Material
,	O
and	O
finetune	O
their	O
public	O
model	O
trained	O
on	O
VOC	B-Material
2011	O
[	O
reference	O
]	O
on	O
Person	B-Material
-	I-Material
Part	I-Material
instances	I-Material
as	O
a	O
baseline	O
.	O
	
section	O
:	O
Results	O
on	O
Instance	B-Method
-	I-Method
level	I-Method
Part	I-Method
Segmentation	I-Method
	
We	O
first	O
train	O
our	O
model	O
in	O
a	O
piecewise	O
manner	O
,	O
by	O
first	O
optimising	O
the	O
parameters	O
of	O
the	O
category	B-Method
-	I-Method
level	I-Method
segmentation	I-Method
module	I-Method
,	O
and	O
then	O
"	O
freezing	O
"	O
the	O
weights	O
of	O
this	O
module	O
and	O
only	O
training	O
the	O
instance	B-Method
network	I-Method
.	O
	
Initially	O
,	O
we	O
only	O
use	O
the	O
box	O
consistency	O
term	O
(	O
Sec	O
.	O
3.2.1	O
)	O
in	O
the	O
Instance	O
CRF	B-Method
,	O
resulting	O
in	O
an	O
AP	B-Metric
r	I-Metric
at	O
0.5	O
of	O
38.0	O
%	O
.	O
	
Note	O
that	O
this	O
model	O
is	O
equivalent	O
to	O
our	O
reimplementation	O
of	O
[	O
reference	O
]	O
.	O
Adding	O
in	O
the	O
global	O
potential	O
(	O
Sec	O
.	O
	
3.2.2	O
)	O
helps	O
us	O
cope	O
with	O
bounding	O
boxes	O
which	O
do	O
not	O
cover	O
the	O
whole	O
human	O
,	O
and	O
we	O
see	O
an	O
improvement	O
at	O
all	O
IoU	O
thresholds	O
.	O
	
Training	O
our	O
entire	O
network	O
end	O
-	O
to	O
-	O
end	O
gives	O
further	O
benefits	O
.	O
	
We	O
then	O
train	O
all	O
variants	O
of	O
our	O
model	O
with	O
OHEM	B-Method
,	O
and	O
observe	O
consistent	O
improvements	O
across	O
all	O
IoU	B-Metric
thresholds	I-Metric
with	O
respect	O
to	O
the	O
corresponding	O
baseline	O
.	O
	
Here	O
,	O
we	O
set	O
K	O
=	O
2	O
[	O
reference	O
]	O
,	O
meaning	O
that	O
we	O
computed	O
our	O
loss	O
over	O
2	O
[	O
reference	O
]	O
or	O
approximately	O
12	O
%	O
of	O
the	O
hardest	O
pixels	O
in	O
each	O
training	O
image	O
(	O
since	O
we	O
train	O
at	O
full	O
resolution	O
)	O
.	O
	
We	O
also	O
employ	O
OHEM	B-Method
when	O
pre	O
-	O
training	O
the	O
category	B-Method
-	I-Method
level	I-Method
segmentation	I-Method
module	I-Method
of	O
our	O
network	O
,	O
and	O
observe	O
minimal	O
difference	O
in	O
the	O
final	O
result	O
if	O
we	O
use	O
OHEM	B-Method
when	O
training	O
the	O
category	B-Method
-	I-Method
level	I-Method
segmentation	I-Method
module	I-Method
but	O
not	O
the	O
instance	B-Method
segmentation	I-Method
module	I-Method
.	O
	
Training	O
end	O
-	O
to	O
-	O
end	O
with	O
OHEM	B-Method
achieves	O
2.6	O
%	O
higher	O
in	O
AP	B-Metric
r	I-Metric
at	O
0.5	O
,	O
and	O
1.8	O
%	O
higher	O
AP	B-Metric
r	I-Metric
vol	O
over	O
a	O
piecewise	B-Method
-	I-Method
trained	I-Method
baseline	I-Method
model	I-Method
without	O
OHEM	B-Method
and	O
only	O
the	O
box	B-Method
term	I-Method
(	O
second	O
row	O
)	O
,	O
which	O
is	O
equivalent	O
to	O
the	O
model	O
of	O
[	O
reference	O
]	O
.	O
Furthermore	O
,	O
our	O
AP	B-Metric
r	I-Metric
vol	O
is	O
1.7	O
%	O
greater	O
than	O
the	O
strong	O
MNC	B-Method
[	O
reference	O
]	O
baseline	O
.	O
	
Note	O
that	O
although	O
[	O
reference	O
]	O
also	O
performed	O
instance	B-Method
-	I-Method
level	I-Method
segmentation	I-Method
on	O
the	O
same	O
dataset	O
,	O
their	O
evaluation	O
was	O
only	O
done	O
using	O
human	O
instance	O
labels	O
,	O
which	O
is	O
similar	O
to	O
our	O
following	O
experiment	O
on	O
human	B-Method
instance	I-Method
segmentation	I-Method
.	O
	
section	O
:	O
Results	O
on	O
Human	B-Task
Instance	I-Task
Segmentation	I-Task
	
We	O
can	O
trivially	O
obtain	O
instance	B-Method
-	I-Method
level	I-Method
segmentations	I-Method
of	O
humans	O
(	O
Fig	O
1d	O
)	O
,	O
as	O
mentioned	O
in	O
Sec	O
.	O
	
3.4	O
.	O
	
Table	O
2	O
shows	O
our	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
instance	B-Task
segmentation	I-Task
results	O
for	O
humans	B-Method
on	O
the	O
VOC	B-Material
2012	O
validation	O
set	O
	
[	O
reference	O
]	O
.	O
	
We	O
use	O
the	O
best	O
model	O
from	O
the	O
previous	O
section	O
as	O
there	O
is	O
DeepLab	O
*	O
[	O
reference	O
]	O
	
53.0	O
Attention	O
[	O
reference	O
]	O
56.4	O
HAZN	B-Method
[	O
reference	O
]	O
57.5	O
LG	B-Method
-	I-Method
LSTM	I-Method
[	O
reference	O
]	O
	
58.0	O
Graph	B-Method
LSTM	I-Method
[	O
reference	O
]	O
	
60.2	O
DeepLab	O
v2	O
[	O
reference	O
]	O
64.9	O
RefineNet	O
[	O
reference	O
]	O
68.6	O
	
Ours	O
,	O
pre	O
-	O
trained	O
65.9	O
Ours	O
,	O
final	O
network	O
66.3	O
*	O
Result	O
reported	O
in	O
[	O
reference	O
]	O
	
no	O
overlap	O
between	O
the	O
Pascal	B-Material
Person	I-Material
-	I-Material
Part	I-Material
training	I-Material
set	I-Material
,	O
and	O
the	O
VOC	B-Material
2012	O
validation	O
set	O
.	O
	
As	O
Tab	O
.	O
2	O
shows	O
,	O
our	O
proposed	O
approach	O
outperforms	O
previous	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
by	O
a	O
significant	O
margin	O
,	O
particularly	O
at	O
high	O
IoU	O
thresholds	O
.	O
	
Our	O
model	O
receives	O
extra	O
supervision	O
in	O
its	O
part	O
labels	O
,	O
but	O
the	O
fact	O
that	O
our	O
network	O
can	O
implicitly	O
infer	O
relationships	O
between	O
different	O
parts	O
whilst	O
training	O
may	O
help	O
it	O
handle	O
occluding	O
instances	O
better	O
than	O
other	O
approaches	O
,	O
leading	O
to	O
better	O
instance	B-Task
segmentation	I-Task
performance	O
.	O
	
The	O
fact	O
that	O
our	O
network	O
is	O
trained	O
with	O
part	O
-	O
level	O
annotations	O
may	O
also	O
help	O
it	O
identify	O
small	O
features	O
of	O
humans	O
better	O
,	O
leading	O
to	O
more	O
precise	O
segmentations	B-Task
and	O
thus	O
improvements	O
at	O
high	O
AP	B-Metric
r	I-Metric
thresholds	O
.	O
	
Our	O
AP	B-Metric
r	I-Metric
at	O
each	O
IoU	O
threshold	O
for	O
human	B-Method
instance	I-Method
segmentation	I-Method
is	O
higher	O
than	O
that	O
for	O
part	B-Task
instance	I-Task
segmentation	I-Task
(	O
Tab	O
.	O
1	O
)	O
.	O
	
This	O
is	O
because	O
parts	O
are	O
smaller	O
than	O
entire	O
humans	O
,	O
and	O
thus	O
more	O
difficult	O
to	O
localise	O
accurately	O
.	O
	
An	O
alternate	O
method	O
of	O
performing	O
instance	B-Method
-	I-Method
level	I-Method
part	I-Method
segmentation	I-Method
may	O
be	O
to	O
first	O
obtain	O
an	O
instance	B-Method
-	I-Method
level	I-Method
human	I-Method
segmentation	I-Method
using	O
another	O
method	O
from	O
Tab	O
.	O
2	O
,	O
and	O
then	O
partition	O
it	O
into	O
the	O
various	O
body	O
parts	O
of	O
a	O
human	O
.	O
	
However	O
,	O
our	O
approach	O
,	O
which	O
groups	O
parts	O
into	O
instances	O
,	O
is	O
validated	O
by	O
the	O
fact	O
that	O
it	O
achieves	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
instance	O
-	O
level	O
human	B-Method
segmentation	I-Method
performance	O
.	O
	
section	O
:	O
Results	O
on	O
Category	B-Task
-	I-Task
level	I-Task
Part	I-Task
Segmentation	I-Task
	
Finally	O
,	O
our	O
model	O
is	O
also	O
able	O
to	O
produce	O
category	B-Task
-	I-Task
level	I-Task
segmentations	I-Task
(	O
as	O
shown	O
in	O
Fig	O
.	O
	
1b	O
)	O
.	O
	
This	O
can	O
be	O
obtained	O
from	O
the	O
output	O
of	O
the	O
category	B-Method
-	I-Method
level	I-Method
segmentation	I-Method
module	I-Method
,	O
or	O
from	O
our	O
instance	B-Method
module	I-Method
as	O
described	O
in	O
Sec	O
.	O
	
3.4	O
.	O
	
As	O
shown	O
in	O
Tab	O
.	O
	
3	O
,	O
our	O
semantic	B-Task
segmentation	I-Task
results	O
are	O
competitive	O
with	O
current	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
.	O
	
By	O
training	O
our	O
entire	O
network	O
consisting	O
of	O
the	O
category	O
-	O
level	O
and	O
instance	B-Method
-	I-Method
level	I-Method
segmentation	I-Method
modules	O
jointly	O
,	O
and	O
then	O
obtaining	O
the	O
semantic	B-Method
segmentation	I-Method
from	O
the	O
final	O
instance	B-Method
segmentation	I-Method
output	O
by	O
our	O
network	O
,	O
we	O
are	O
able	O
to	O
obtain	O
a	O
small	O
improvement	O
of	O
0.4	O
%	O
in	O
mean	B-Metric
IoU	I-Metric
over	O
the	O
output	O
of	O
the	O
initial	O
semantic	B-Method
segmentation	I-Method
module	I-Method
.	O
	
section	O
:	O
Conclusion	O
	
Our	O
proposed	O
,	O
end	O
-	O
to	O
-	O
end	B-Method
trained	I-Method
network	I-Method
outputs	O
instance	B-Task
-	I-Task
level	I-Task
body	I-Task
part	I-Task
and	I-Task
human	I-Task
segmentations	I-Task
,	O
as	O
well	O
as	O
category	B-Method
-	I-Method
level	I-Method
part	I-Method
segmentations	I-Method
in	O
a	O
single	O
forward	O
-	O
pass	O
.	O
	
Moreover	O
,	O
	
section	O
:	O
Input	O
	
Semantic	B-Task
Segmentation	I-Task
Instance	I-Task
Segmentation	I-Task
Ground	I-Task
Truth	I-Task
Figure	O
4	O
:	O
	
Some	O
results	O
of	O
our	O
system	O
.	O
	
The	O
first	O
column	O
shows	O
the	O
input	O
image	O
and	O
the	O
input	O
detections	O
we	O
obtained	O
from	O
training	O
the	O
R	B-Method
-	I-Method
FCN	I-Method
detector	I-Method
[	O
reference	O
]	O
.	O
	
The	O
second	O
and	O
third	O
columns	O
show	O
our	O
final	O
semantic	B-Task
segmentation	I-Task
(	O
Sec	O
.	O
3.4	O
)	O
and	O
instance	B-Method
-	I-Method
level	I-Method
part	I-Method
segmentation	I-Method
.	O
	
First	O
row	O
:	O
our	O
network	O
can	O
deal	O
with	O
poor	O
bounding	B-Task
box	I-Task
localisation	I-Task
,	O
as	O
it	O
manages	O
to	O
segment	O
the	O
third	O
person	O
from	O
the	O
left	O
although	O
the	O
bounding	O
box	O
only	O
partially	O
covers	O
her	O
.	O
	
Second	O
row	O
:	O
our	O
method	O
is	O
robust	O
against	O
false	B-Metric
positive	I-Metric
detections	I-Metric
because	O
of	O
the	O
box	O
term	O
.	O
	
Observe	O
that	O
the	O
bowl	O
of	O
the	O
rightmost	O
person	O
in	O
the	O
bottom	O
row	O
is	O
falsely	O
detected	O
as	O
a	O
person	O
,	O
but	O
rejected	O
in	O
the	O
final	O
prediction	O
.	O
	
Following	O
rows	O
:	O
we	O
are	O
able	O
to	O
handle	O
overlapping	O
bounding	O
boxes	O
by	O
reasoning	O
globally	O
using	O
the	O
Instance	O
CRF	B-Method
.	O
	
we	O
have	O
shown	O
how	O
segmenting	O
objects	O
into	O
their	O
constituent	O
parts	O
helps	O
us	O
segment	O
the	O
object	O
as	O
a	O
whole	O
with	O
our	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
results	O
on	O
instance	B-Method
-	I-Method
level	I-Method
segmentation	I-Method
of	O
both	O
body	B-Task
parts	I-Task
and	O
entire	O
humans	O
.	O
	
Furthermore	O
,	O
our	O
category	B-Method
-	I-Method
level	I-Method
segmentations	I-Method
improve	O
after	O
training	O
for	O
instance	B-Method
-	I-Method
level	I-Method
segmentation	I-Method
.	O
	
Our	O
future	O
work	O
is	O
to	O
train	O
the	O
object	B-Method
detector	I-Method
end	O
-	O
to	O
-	O
end	O
as	O
well	O
.	O
	
Moreover	O
,	O
the	O
improvement	O
that	O
we	O
obtained	O
in	O
instance	B-Task
segmentation	I-Task
of	I-Task
humans	I-Task
as	O
a	O
result	O
of	O
first	O
segmenting	O
parts	O
motivates	O
us	O
to	O
explore	O
weakly	B-Method
-	I-Method
supervised	I-Method
methods	I-Method
which	O
do	O
not	O
require	O
explicit	O
object	O
part	O
annotations	O
.	O
	
In	O
our	O
main	O
paper	O
,	O
we	O
reported	O
our	O
AP	B-Metric
r	I-Metric
results	O
averaged	O
over	O
all	O
classes	O
.	O
	
Fig	O
.	O
5	O
visualises	O
the	O
perclass	O
results	O
of	O
our	O
best	O
model	O
at	O
different	O
IoU	O
thresholds	O
.	O
	
Fig	O
.	O
6	O
displays	O
the	O
success	O
cases	O
of	O
our	O
method	O
,	O
while	O
Fig	O
.	O
7	O
shows	O
examples	O
of	O
failure	O
cases	O
.	O
	
Furthermore	O
,	O
we	O
illustrate	O
the	O
strengths	O
and	O
weaknesses	O
of	O
our	O
part	B-Method
instance	I-Method
segmentation	I-Method
method	I-Method
in	O
comparison	O
to	O
MNC	B-Method
[	O
reference	O
]	O
in	O
Fig	O
.	O
8	O
,	O
and	O
compare	O
our	O
instance	O
-	O
level	O
human	B-Method
segmentation	I-Method
results	O
,	O
which	O
we	O
obtain	O
by	O
the	O
simple	O
mapping	B-Method
described	O
in	O
Sec	O
.	O
	
3.4	O
of	O
our	O
main	O
paper	O
,	O
to	O
MNC	B-Method
in	O
Fig	O
.	O
	
9	O
.	O
	
Finally	O
,	O
we	O
attach	O
an	O
additional	O
video	O
.	O
	
We	O
run	O
our	O
system	O
offline	O
,	O
on	O
a	O
frame	O
-	O
by	O
-	O
frame	O
basis	O
on	O
the	O
entire	O
music	O
video	O
,	O
and	O
show	O
how	O
our	O
method	O
is	O
able	O
to	O
accurately	O
parse	O
humans	O
at	O
both	O
category	O
and	O
instance	B-Metric
level	I-Metric
on	O
internet	O
data	O
outside	O
the	O
Pascal	B-Material
dataset	I-Material
.	O
	
Instance	B-Task
-	I-Task
level	I-Task
segmentation	I-Task
of	I-Task
videos	I-Task
requires	O
data	B-Task
association	I-Task
.	O
	
We	O
use	O
a	O
simple	O
,	O
greedy	B-Method
method	I-Method
which	O
operates	O
on	O
a	O
frame	O
-	O
by	O
-	O
frame	O
basis	O
.	O
	
Segments	O
from	O
one	O
frame	O
are	O
associated	O
to	O
segments	O
in	O
the	O
next	O
frame	O
based	O
on	O
the	O
IoU	O
,	O
using	O
the	O
same	O
method	O
we	O
use	O
for	O
our	O
loss	B-Method
function	I-Method
as	O
described	O
in	O
Sec	O
.	O
	
3.3	O
of	O
the	O
main	O
paper	O
.	O
	
It	O
shows	O
that	O
our	O
method	O
achieves	O
best	O
instance	B-Metric
accuracy	I-Metric
for	O
the	O
head	B-Task
category	I-Task
,	O
and	O
finds	O
lower	O
arms	O
and	O
lower	O
legs	O
most	O
challenging	O
to	O
segment	O
correctly	O
.	O
	
This	O
is	O
likely	O
because	O
of	O
the	O
thin	O
shape	O
of	O
the	O
lower	O
limbs	O
which	O
is	O
known	O
to	O
pose	O
difficulty	O
for	O
semantic	B-Task
segmentation	I-Task
.	O
	
section	O
:	O
Input	O
	
Semantic	B-Task
Segmentation	I-Task
Instance	I-Task
Segmentation	I-Task
Ground	I-Task
Truth	I-Task
Figure	O
6	O
:	O
Success	O
cases	O
of	O
our	O
method	O
.	O
	
The	O
first	O
column	O
shows	O
the	O
input	O
image	O
and	O
the	O
input	O
detections	O
we	O
obtained	O
from	O
training	O
the	O
R	B-Method
-	I-Method
FCN	I-Method
detector	I-Method
[	O
reference	O
]	O
.	O
	
The	O
second	O
column	O
shows	O
our	O
final	O
semantic	B-Task
segmentation	I-Task
(	O
as	O
described	O
in	O
Sec	O
.	O
	
3.4	O
of	O
the	O
main	O
paper	O
)	O
.	O
	
Our	O
proposed	O
method	O
is	O
able	O
to	O
leverage	O
an	O
initial	O
category	B-Method
-	I-Method
level	I-Method
segmentation	I-Method
network	I-Method
and	O
human	O
detections	O
to	O
produce	O
accurate	O
instance	B-Method
-	I-Method
level	I-Method
part	I-Method
segmentation	I-Method
as	O
shown	O
in	O
the	O
third	O
column	O
.	O
	
First	O
row	O
:	O
unlike	O
MNC	B-Method
which	O
predicts	O
for	O
each	O
part	O
instance	O
independently	O
,	O
our	O
method	O
reasons	O
globally	O
and	O
jointly	O
.	O
	
As	O
a	O
result	O
,	O
MNC	B-Method
predicts	O
two	O
instances	O
of	O
lower	O
legs	O
for	O
the	O
same	O
lower	O
leg	O
of	O
the	O
second	O
and	O
third	O
person	O
from	O
the	O
left	O
.	O
	
Furthermore	O
,	O
with	O
a	O
dedicated	O
category	B-Method
-	I-Method
level	I-Method
segmentation	I-Method
module	I-Method
,	O
we	O
are	O
less	O
prone	O
to	O
false	O
negatives	O
,	O
whereas	O
MNC	B-Method
misses	O
the	O
legs	O
of	O
the	O
rightmost	O
person	O
,	O
and	O
the	O
lower	O
arm	O
of	O
the	O
second	O
person	O
from	O
the	O
right	O
.	O
	
Second	O
row	O
:	O
while	O
we	O
can	O
handle	O
poor	O
bounding	B-Task
box	I-Task
localisation	I-Task
because	O
of	O
our	O
global	O
potential	O
term	O
,	O
MNC	B-Method
is	O
unable	O
to	O
segment	O
regions	O
outside	O
the	O
bounding	O
boxes	O
it	O
generates	O
.	O
	
Consequently	O
,	O
only	O
one	O
lower	O
arm	O
of	O
the	O
person	O
on	O
the	O
left	O
is	O
segmented	O
as	O
the	O
other	O
one	O
is	O
outside	O
the	O
bounding	O
box	O
.	O
	
The	O
square	O
corners	O
of	O
the	O
segmented	O
lower	O
arm	O
correspond	O
to	O
the	O
limits	O
imposed	O
by	O
the	O
bounding	O
box	O
which	O
MNC	B-Method
internally	O
uses	O
(	O
box	B-Method
generation	I-Method
is	O
the	O
first	O
stage	O
of	O
the	O
cascade	O
[	O
reference	O
]	O
)	O
.	O
	
Third	O
row	O
:	O
By	O
analysing	O
an	O
image	O
globally	O
and	O
employing	O
a	O
differentiable	O
CRF	B-Method
,	O
our	O
method	O
can	O
produce	O
more	O
precise	O
boundaries	O
.	O
	
As	O
MNC	B-Method
does	O
not	O
perform	O
category	B-Method
-	I-Method
level	I-Method
segmentation	I-Method
over	O
the	O
entire	O
image	O
,	O
it	O
has	O
no	O
incentive	O
to	O
produce	O
a	O
coherent	O
and	O
continuous	B-Task
prediction	I-Task
.	O
	
Visually	O
,	O
this	O
is	O
reflected	O
in	O
the	O
gaps	O
of	O
"	O
background	O
"	O
between	O
body	O
parts	O
of	O
the	O
same	O
person	O
.	O
	
Fourth	O
row	O
:	O
MNC	B-Method
predicts	O
two	O
instances	O
of	O
lower	O
leg	O
for	O
the	O
second	O
person	O
from	O
the	O
right	O
,	O
and	O
fails	O
to	O
segment	O
any	O
lower	O
arms	O
for	O
all	O
four	O
people	O
due	O
to	O
the	O
aforementioned	O
problems	O
.	O
	
[	O
reference	O
]	O
using	O
the	O
default	O
parameters	O
and	O
extract	O
only	O
its	O
human	O
instance	O
predictions	O
.	O
	
In	O
contrast	O
with	O
proposal	B-Method
-	I-Method
driven	I-Method
methods	I-Method
such	O
as	O
MNC	B-Method
,	O
our	O
approach	O
assigns	O
each	O
pixel	O
to	O
only	O
one	O
instance	O
,	O
is	O
robust	O
against	O
non	O
-	O
ideal	O
bounding	O
boxes	O
,	O
and	O
often	O
produces	O
better	O
boundaries	O
due	O
to	O
the	O
Instance	O
CRF	B-Method
which	O
is	O
trained	O
endto	O
-	O
end	O
.	O
	
First	O
and	O
second	O
row	O
:	O
since	O
MNC	B-Method
predicts	O
instances	O
independently	O
,	O
it	O
is	O
prone	O
to	O
predicting	O
multiple	O
instances	O
for	O
a	O
single	O
person	O
.	O
	
Third	O
row	O
:	O
due	O
to	O
the	O
global	O
potential	O
term	O
,	O
we	O
can	O
segment	O
regions	O
outside	O
of	O
a	O
detection	O
bounding	O
box	O
which	O
fails	O
to	O
cover	O
the	O
entire	O
person	O
,	O
whereas	O
MNC	B-Method
is	O
unable	O
to	O
recover	O
from	O
such	O
imperfect	O
bounding	O
boxes	O
,	O
leading	O
to	O
its	O
frequent	O
occurrences	O
of	O
truncated	B-Task
instance	I-Task
predictions	I-Task
.	O
	
Fourth	O
row	O
:	O
a	O
case	O
where	O
MNC	B-Method
and	O
our	O
method	O
show	O
different	O
failure	O
modes	O
.	O
	
MNC	B-Method
predicts	O
three	O
people	O
where	O
there	O
are	O
only	O
two	O
,	O
and	O
our	O
method	O
can	O
only	O
predict	O
one	O
instance	O
due	O
to	O
a	O
missing	B-Task
detection	I-Task
.	O
	
MNC	B-Method
is	O
unable	O
to	O
recover	O
from	O
a	O
false	B-Task
positive	I-Task
detection	I-Task
and	O
predicts	O
two	O
people	O
.	O
	
Second	O
row	O
:	O
while	O
both	O
MNC	B-Method
and	O
our	O
method	O
start	O
off	O
with	O
poor	O
bounding	B-Method
box	I-Method
localisation	I-Method
that	O
does	O
not	O
cover	O
the	O
whole	O
instance	O
,	O
we	O
are	O
able	O
to	O
segment	O
the	O
entire	O
person	O
,	O
whereas	O
MNC	B-Method
is	O
bounded	O
by	O
its	O
flawed	O
region	B-Method
proposal	I-Method
.	O
	
Third	O
row	O
:	O
MNC	B-Method
performs	O
better	O
in	O
this	O
case	O
as	O
it	O
is	O
able	O
to	O
segment	O
the	O
infant	O
,	O
whereas	O
we	O
miss	O
her	O
completely	O
due	O
to	O
a	O
false	B-Task
negative	I-Task
person	I-Task
detection	I-Task
.	O
	
section	O
:	O
B	O
Additional	O
information	O
	
We	O
detail	O
our	O
initial	O
category	B-Method
-	I-Method
level	I-Method
segmentation	I-Method
module	I-Method
and	O
compare	O
it	O
to	O
DeepLab	B-Method
-	I-Method
v2	I-Method
[	O
reference	O
]	O
in	O
Sec	O
.	O
	
B.1	O
,	O
present	O
our	O
network	O
training	O
details	O
in	O
Sec	O
.	O
	
B.2	O
,	O
and	O
finally	O
describe	O
how	O
we	O
train	O
the	O
MNC	B-Method
model	O
which	O
serves	O
as	O
our	O
baseline	O
in	O
Sec	O
.	O
	
B.3	O
.	O
	
section	O
:	O
B.1	O
Details	O
of	O
the	O
category	B-Method
-	I-Method
level	I-Method
segmentation	I-Method
module	I-Method
	
As	O
shown	O
in	O
Fig	O
10b	O
,	O
the	O
structure	O
of	O
our	O
category	B-Method
-	I-Method
level	I-Method
segmentation	I-Method
module	I-Method
consists	O
of	O
a	O
ResNet	B-Method
-	I-Method
101	I-Method
backbone	I-Method
,	O
and	O
a	O
classifier	B-Method
that	O
extracts	O
multi	O
-	O
scale	O
features	O
from	O
the	O
ResNet	O
-	O
101	O
output	O
by	O
using	O
average	B-Method
pooling	I-Method
with	O
different	O
kernel	O
sizes	O
.	O
	
While	O
our	O
category	B-Method
-	I-Method
level	I-Method
segmentation	I-Method
module	I-Method
and	O
the	O
Deeplab	B-Method
-	I-Method
v2	I-Method
network	I-Method
(	O
Fig	O
.	O
10a	O
)	O
of	O
Chen	O
et	O
al	O
.	O
	
[	O
reference	O
]	O
both	O
attempt	O
to	O
exploit	O
multi	O
-	O
scale	O
information	O
in	O
the	O
image	O
,	O
the	O
approach	O
of	O
[	O
reference	O
]	O
entails	O
executing	O
three	O
forward	O
passes	O
for	O
each	O
image	O
,	O
whereas	O
we	O
only	O
need	O
a	O
single	O
forward	O
pass	O
.	O
	
In	O
comparison	O
to	O
Deeplab	B-Method
-	I-Method
v2	I-Method
,	O
our	O
network	O
saves	O
both	O
memory	O
and	O
time	O
,	O
and	O
achieves	O
better	O
performance	O
.	O
	
To	O
carry	O
out	O
a	O
single	O
forward	B-Method
pass	I-Method
,	O
our	O
network	O
uses	O
4.3	O
GB	O
of	O
memory	O
while	O
Deeplab	B-Method
-	I-Method
v2	I-Method
[	O
reference	O
]	O
needs	O
9.5	O
GB	O
,	O
120	O
%	O
more	O
than	O
ours	O
.	O
	
Speed	O
-	O
wise	O
,	O
our	O
network	O
runs	O
forward	O
passes	O
at	O
0.255	O
seconds	O
per	O
image	O
(	O
3.9	O
fps	O
)	O
,	O
whereas	O
Deeplab	B-Method
-	I-Method
v2	I-Method
takes	O
55	O
%	O
longer	O
,	O
at	O
0.396	O
seconds	O
per	O
image	O
(	O
2.5	O
fps	B-Metric
)	O
on	O
average	O
.	O
	
When	O
Deeplab	B-Method
-	I-Method
v2	I-Method
adds	O
a	O
CRF	B-Method
with	O
10	O
mean	B-Method
-	I-Method
field	I-Method
iterations	I-Method
to	O
post	O
-	O
process	O
the	O
network	O
output	O
,	O
it	O
gains	O
a	O
small	O
improvement	O
in	O
mean	B-Metric
IoU	I-Metric
by	O
0.54	O
%	O
[	O
reference	O
]	O
,	O
but	O
it	O
requires	O
11.2	O
GB	O
of	O
memory	O
to	O
make	O
a	O
forward	O
pass	O
(	O
140	O
%	O
of	O
the	O
total	O
amount	O
used	O
by	O
our	O
full	B-Method
network	I-Method
including	O
the	O
instance	B-Method
-	I-Method
level	I-Method
segmentation	I-Method
module	O
)	O
,	O
and	O
takes	O
0.960	O
seconds	O
per	O
image	O
(	O
1.0	O
fps	O
)	O
,	O
almost	O
a	O
quater	O
of	O
our	O
frame	B-Metric
rate	I-Metric
.	O
	
Tests	O
are	O
done	O
on	O
a	O
single	O
GeForce	B-Method
GTX	I-Method
Titan	I-Method
X	I-Method
(	I-Method
Maxwell	I-Method
)	I-Method
card	I-Method
.	O
	
Overall	O
,	O
we	O
are	O
able	O
to	O
achieve	O
better	O
segmentation	B-Metric
accuracy	I-Metric
(	O
as	O
shown	O
in	O
Tab	O
.	O
	
3	O
of	O
our	O
main	O
paper	O
)	O
and	O
is	O
more	O
memory	O
-	O
and	O
time	O
-	O
efficient	O
than	O
Deeplab	B-Method
-	I-Method
v2	I-Method
.	O
	
section	O
:	O
B.2	O
Training	O
our	O
proposed	O
network	O
B.2.1	O
Training	O
the	O
category	B-Method
-	I-Method
level	I-Method
segmentation	I-Method
module	I-Method
	
We	O
initialise	O
our	O
semantic	B-Method
segmentation	I-Method
network	I-Method
with	O
the	O
COCO	O
pre	O
-	O
trained	O
ResNet	O
-	O
101	O
weights	O
provided	O
by	O
[	O
reference	O
]	O
.	O
Training	O
is	O
first	O
performed	O
on	O
the	O
Pascal	B-Material
VOC	I-Material
2012	I-Material
training	I-Material
set	I-Material
using	O
the	O
extra	O
annotations	O
from	O
[	O
reference	O
]	O
,	O
which	O
combine	O
to	O
a	O
total	O
of	O
9012	O
training	O
images	O
.	O
	
Care	O
is	O
taken	O
to	O
ensure	O
that	O
all	O
images	O
from	O
the	O
Pascal	B-Material
Person	I-Material
-	I-Material
Parts	I-Material
test	O
set	O
is	O
excluded	O
from	O
this	O
training	O
set	O
.	O
	
A	O
polynomial	B-Method
learning	I-Method
rate	I-Method
policy	I-Method
is	O
adopted	O
such	O
that	O
the	O
effective	B-Metric
learning	I-Metric
rate	I-Metric
at	O
iteration	O
i	O
is	O
given	O
by	O
l	O
	
i	O
=	O
	
l	O
0	O
(	O
1	O
	
−	O
i	O
	
i	O
max	O
)	O
	
p	O
,	O
where	O
the	O
base	B-Metric
learning	I-Metric
rate	I-Metric
,	O
l	O
0	O
,	O
is	O
set	O
to	O
6.25	O
×	O
	
10	O
−4	O
,	O
the	O
total	O
number	O
of	O
iterations	O
,	O
i	O
max	O
,	O
is	O
set	O
to	O
30k	O
,	O
and	O
the	O
power	O
,	O
p	O
,	O
is	O
set	O
to	O
0.9	O
.	O
	
A	O
batch	O
size	O
of	O
16	O
is	O
used	O
.	O
	
However	O
,	O
due	O
to	O
memory	O
constraints	O
,	O
we	O
simulate	O
this	O
batch	O
size	O
by	O
"	O
accumulating	O
gradients	O
"	O
:	O
We	O
carry	O
out	O
16	O
forward	O
and	O
backward	O
passes	O
with	O
one	O
image	O
per	O
iteration	O
,	O
and	O
only	O
perform	O
the	O
weight	B-Method
update	I-Method
after	O
completing	O
all	O
16	O
passes	O
.	O
	
We	O
use	O
a	O
momentum	O
of	O
0.9	O
and	O
weight	O
decay	O
of	O
1	O
×	O
10	O
−4	O
for	O
these	O
experiments	O
.	O
	
After	O
30k	O
of	O
iterations	O
are	O
completed	O
,	O
we	O
take	O
the	O
best	O
performing	O
model	O
and	O
finetune	O
on	O
the	O
Pascal	B-Material
Person	I-Material
-	I-Material
Parts	I-Material
training	O
set	O
using	O
the	O
same	O
training	O
scheme	O
as	O
described	O
above	O
.	O
	
Note	O
that	O
the	O
parameters	O
of	O
the	O
batch	B-Method
normalisation	I-Method
modules	I-Method
are	O
kept	O
unchanged	O
in	O
the	O
whole	O
learning	B-Task
process	I-Task
.	O
	
Online	B-Task
data	I-Task
-	I-Task
augmentation	I-Task
is	O
performed	O
during	O
training	B-Task
to	O
regularise	O
the	O
model	O
.	O
	
The	O
training	O
images	O
are	O
randomly	O
mirrored	O
,	O
scaled	O
by	O
a	O
ratio	O
between	O
0.5	O
and	O
2	O
,	O
rotated	O
by	O
an	O
angle	O
between	O
-	O
10	O
and	O
10	O
degrees	O
,	O
translated	O
by	O
a	O
random	O
amount	O
in	O
the	O
HSV	O
colour	O
space	O
,	O
and	O
blurred	O
with	O
a	O
randomly	O
-	O
sized	O
Gaussian	B-Method
kernel	I-Method
,	O
all	O
on	O
-	O
the	O
-	O
fly	O
.	O
	
We	O
observe	O
that	O
these	O
techniques	O
are	O
effective	O
at	O
reducing	O
the	O
accuracy	B-Metric
gap	I-Metric
between	O
training	B-Metric
and	O
testing	B-Task
,	O
leading	O
to	O
overall	O
higher	O
test	B-Metric
accuracies	I-Metric
.	O
	
[	O
reference	O
]	O
and	O
our	O
network	O
structure	O
.	O
	
The	O
numbers	O
following	O
the	O
layer	O
type	O
denote	O
the	O
kernel	O
size	O
and	O
number	O
of	O
filters	O
.	O
	
For	O
pooling	O
layers	O
,	O
only	O
their	O
kernel	O
sizes	O
are	O
shown	O
as	O
the	O
number	O
of	O
filters	O
is	O
not	O
applicable	O
.	O
	
The	O
upsampling	O
ratios	O
can	O
be	O
inferred	O
from	O
the	O
context	O
.	O
	
Fig	O
.	O
10a	O
	
:	O
in	O
the	O
Deeplab	B-Method
-	I-Method
v2	I-Method
architecture	I-Method
,	O
a	O
513×513×3	O
input	O
image	O
is	O
downsampled	O
by	O
two	O
different	O
ratios	O
(	O
0.75	O
and	O
0.5	O
)	O
to	O
produce	O
multi	O
-	O
scale	O
input	O
at	O
three	O
different	O
resolutions	O
.	O
	
The	O
three	O
resolutions	O
are	O
independently	O
processed	O
by	O
a	O
ResNet	B-Method
-	I-Method
101	I-Method
-	I-Method
based	I-Method
network	I-Method
using	O
shared	O
weights	O
(	O
shown	O
by	O
the	O
individually	O
coloured	O
paths	O
)	O
.	O
	
The	O
output	O
feature	O
maps	O
are	O
then	O
upsampled	O
where	O
appropriate	O
,	O
combined	O
by	O
taking	O
the	O
elementwise	O
maximum	O
,	O
and	O
finally	O
upsampled	O
back	O
to	O
513×513	O
.	O
	
Fig	O
.	O
	
10b	O
:	O
	
the	O
category	B-Method
-	I-Method
level	I-Method
segmentation	I-Method
module	I-Method
proposed	O
in	O
this	O
paper	O
forwards	O
an	O
input	O
image	O
of	O
size	O
521×521×3	O
through	O
a	O
ResNet	O
-	O
101	O
-	O
based	O
CNN	B-Method
,	O
producing	O
a	O
feature	B-Method
map	I-Method
of	O
resolution	O
66×66×2048	O
.	O
	
This	O
feature	B-Method
map	I-Method
is	O
average	O
-	O
pooled	O
with	O
four	O
different	O
kernel	O
sizes	O
,	O
giving	O
us	O
four	O
feature	O
maps	O
with	O
spatial	O
resolutions	O
1×1	O
,	O
2×2	O
,	O
3×3	O
,	O
and	O
6×6	O
respectively	O
.	O
	
Each	O
feature	B-Method
map	I-Method
undergoes	O
convolution	B-Method
and	O
upsampling	B-Method
,	O
before	O
being	O
concatenated	O
together	O
with	O
each	O
other	O
and	O
the	O
66×66×2048	O
ResNet	O
-	O
101	O
output	O
.	O
	
This	O
is	O
followed	O
by	O
a	O
convolution	B-Method
layer	I-Method
that	O
reduces	O
the	O
dimension	O
of	O
the	O
concatenated	O
features	O
to	O
512	O
,	O
and	O
a	O
convolutional	B-Method
classifier	I-Method
that	O
maps	O
the	O
512	O
channels	O
to	O
the	O
size	O
of	O
label	O
space	O
in	O
the	O
dataset	O
.	O
	
Finally	O
,	O
the	O
prediction	O
is	O
upsampled	O
back	O
to	O
521×521	O
.	O
	
In	O
both	O
Fig	O
.	O
10a	O
and	O
10b	O
,	O
the	O
ResNet	B-Method
-	I-Method
101	I-Method
backbone	I-Method
uses	O
dilated	B-Method
convolution	I-Method
such	O
that	O
its	O
output	O
at	O
res5c	O
is	O
at	O
1	O
/	O
8	O
of	O
the	O
input	O
resolution	O
,	O
instead	O
of	O
1	O
/	O
32	O
for	O
the	O
original	O
ResNet	O
-	O
101	O
	
[	O
reference	O
]	O
.	O
	
The	O
convolutional	B-Method
classifiers	I-Method
(	O
coloured	O
in	O
purple	O
)	O
output	O
C	O
channels	O
,	O
corresponding	O
to	O
the	O
number	O
of	O
classes	O
in	O
the	O
dataset	O
including	O
a	O
background	O
class	O
.	O
	
For	O
the	O
Pascal	B-Material
Person	I-Material
-	I-Material
Parts	I-Material
Dataset	O
,	O
C	O
is	O
7	O
.	O
	
Best	O
viewed	O
in	O
colour	O
.	O
	
section	O
:	O
B.2.2	O
Training	O
the	O
instance	B-Method
-	I-Method
level	I-Method
segmentation	I-Method
module	O
	
In	O
our	O
model	O
,	O
the	O
pairwise	O
term	O
of	O
the	O
fully	O
-	O
connected	O
CRF	B-Method
takes	O
the	O
following	O
form	O
:	O
	
where	O
µ	O
(	O
·	O
,	O
·	O
)	O
is	O
a	O
compatibility	O
function	O
,	O
k	O
(	O
·	O
,	O
·	O
)	O
is	O
a	O
kernel	O
function	O
,	O
and	O
f	O
	
i	O
is	O
a	O
feature	O
vector	O
at	O
spatial	O
location	O
	
i	O
containing	O
the	O
3	O
-	O
dimensional	O
colour	O
vector	O
	
I	O
i	O
and	O
	
the	O
2	O
-	O
dimensional	O
position	O
vector	O
p	O
	
i	O
	
[	O
reference	O
]	O
.	O
	
We	O
further	O
define	O
the	O
kernel	O
as	O
follows	O
:	O
	
where	O
w	O
[	O
reference	O
]	O
and	O
w	O
[	O
reference	O
]	O
are	O
the	O
linear	O
combination	O
weights	O
for	O
the	O
bilateral	O
term	O
and	O
the	O
Gaussian	O
term	O
respectively	O
.	O
	
In	O
order	O
to	O
determine	O
the	O
initial	O
values	O
for	O
the	O
parameters	O
in	O
the	O
Instance	O
CRF	B-Method
to	O
train	O
from	O
,	O
we	O
carry	O
out	O
a	O
random	B-Method
search	I-Method
.	O
	
According	O
to	O
the	O
search	O
results	O
,	O
the	O
best	O
prediction	B-Metric
accuracy	I-Metric
is	O
obtained	O
by	O
initialising	O
w	O
(	O
1	O
)	O
=	O
8	O
,	O
w	O
(	O
2	O
)	O
=	O
2	O
,	O
θ	O
α	O
=	O
2	O
,	O
θ	O
β	O
=	O
8	O
,	O
θ	O
γ	O
=	O
2	O
.	O
	
Furthermore	O
,	O
we	O
use	O
a	O
fixed	O
learning	B-Metric
rate	I-Metric
of	O
1	O
×	O
10	O
−6	O
,	O
momentum	O
of	O
0.9	O
,	O
and	O
weight	O
decay	O
of	O
1	O
×	O
10	O
−4	O
for	O
training	O
both	O
the	O
instance	B-Method
-	I-Method
level	I-Method
and	I-Method
category	I-Method
-	I-Method
level	I-Method
segmentation	I-Method
modules	I-Method
jointly	O
.	O
	
Although	O
we	O
previously	O
use	O
the	O
polynomial	B-Method
learning	I-Method
rate	I-Method
policy	I-Method
,	O
we	O
find	O
that	O
for	O
training	O
the	O
instance	B-Method
-	I-Method
level	I-Method
segmentation	I-Method
module	O
,	O
a	O
fixed	O
learning	B-Metric
rate	I-Metric
leads	O
to	O
better	O
results	O
.	O
	
Furthermore	O
,	O
our	O
experiments	O
show	O
that	O
a	O
batch	O
size	O
of	O
one	O
works	O
best	O
at	O
this	O
training	O
stage	O
.	O
	
Using	O
this	O
scheme	O
,	O
we	O
train	O
for	O
175k	O
iterations	O
,	O
or	O
approximately	O
100	O
epochs	O
.	O
	
section	O
:	O
B.3	O
Training	O
Multi	B-Method
-	I-Method
task	I-Method
Network	I-Method
Cascades	I-Method
(	O
MNC	B-Method
)	O
	
We	O
use	O
the	O
publicly	O
available	O
Multi	B-Method
-	I-Method
task	I-Method
Network	I-Method
Cascades	I-Method
(	O
MNC	B-Method
)	O
framework	O
[	O
reference	O
]	O
,	O
and	O
train	O
a	O
new	O
model	O
for	O
instance	B-Method
-	I-Method
level	I-Method
part	I-Method
segmentation	I-Method
using	O
the	O
Pascal	B-Material
Person	I-Material
-	I-Material
Parts	I-Material
dataset	O
.	O
	
The	O
weights	O
are	O
initialised	O
with	O
the	O
officially	O
released	O
MNC	B-Method
model	O
1	O
which	O
has	O
been	O
trained	O
on	O
Pascal	O
VOC	B-Material
	
2011	O
/	O
SBD	O
[	O
reference	O
]	O
.	O
	
The	O
base	B-Metric
learning	I-Metric
rate	I-Metric
is	O
set	O
to	O
1	O
×	O
10	O
−3	O
,	O
which	O
is	O
reduced	O
by	O
10	O
times	O
after	O
20k	O
iterations	O
.	O
	
A	O
total	O
of	O
25k	O
training	O
iterations	O
are	O
carried	O
out	O
.	O
	
A	O
batch	O
size	O
of	O
8	O
,	O
momentum	O
of	O
0.9	O
and	O
weight	O
decay	O
of	O
5	O
×	O
10	O
−4	O
are	O
used	O
.	O
	
These	O
settings	O
are	O
identical	O
to	O
the	O
ones	O
used	O
in	O
training	O
the	O
original	O
MNC	B-Method
and	O
provided	O
in	O
their	O
public	O
source	O
code	O
.	O
	
Using	O
these	O
settings	O
,	O
we	O
are	O
also	O
able	O
to	O
reproduce	O
the	O
experimental	O
results	O
obtained	O
in	O
the	O
original	O
MNC	B-Method
paper	O
[	O
reference	O
]	O
,	O
and	O
hence	O
we	O
believe	O
that	O
the	O
MNC	B-Method
model	O
we	O
have	O
trained	O
acts	O
as	O
a	O
strong	O
baseline	O
for	O
our	O
proposed	O
approach	O
.	O
	
section	O
:	O
	
section	O
:	O
	
section	O
:	O
	
section	O
:	O
Appendix	O
	
In	O
this	O
appendix	O
,	O
we	O
present	O
additional	O
results	O
of	O
our	O
proposed	O
approach	O
in	O
Sec	O
.	O
	
A	O
,	O
and	O
provide	O
additional	O
training	O
and	O
implementation	O
details	O
in	O
Sec	O
.	O
	
B	O
(	O
both	O
for	O
our	O
model	O
,	O
and	O
the	O
strong	O
MNC	B-Method
baseline	O
[	O
reference	O
]	O
)	O
.	O
	
section	O
:	O
	
Discriminative	B-Method
Unsupervised	I-Method
Feature	I-Method
Learning	I-Method
with	I-Method
Convolutional	I-Method
Neural	I-Method
Networks	I-Method
Current	O
methods	O
for	O
training	O
convolutional	B-Method
neural	I-Method
networks	I-Method
depend	O
on	O
large	O
amounts	O
of	O
labeled	O
samples	O
for	O
supervised	B-Task
training	I-Task
.	O
	
In	O
this	O
paper	O
we	O
present	O
an	O
approach	O
for	O
training	O
a	O
convolutional	O
neural	O
network	B-Method
using	O
only	O
unlabeled	O
data	O
.	O
	
We	O
train	O
the	O
network	B-Method
to	O
discriminate	O
between	O
a	O
set	O
of	O
surrogate	O
classes	O
.	O
	
Each	O
surrogate	O
class	O
is	O
formed	O
by	O
applying	O
a	O
variety	O
of	O
transformations	O
to	O
a	O
randomly	O
sampled	O
’	O
seed	O
’	O
image	O
patch	O
.	O
	
We	O
find	O
that	O
this	O
simple	O
feature	B-Method
learning	I-Method
algorithm	I-Method
is	O
surprisingly	O
successful	O
when	O
applied	O
to	O
visual	B-Task
object	I-Task
recognition	I-Task
.	O
	
The	O
feature	B-Method
representation	I-Method
learned	O
by	O
our	O
algorithm	O
achieves	O
classification	B-Task
results	O
matching	O
or	O
outperforming	O
the	O
current	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
for	O
unsupervised	B-Method
learning	I-Method
on	O
several	O
popular	O
datasets	O
(	O
STL	B-Material
-	I-Material
10	I-Material
,	O
CIFAR	B-Material
-	I-Material
10	I-Material
,	O
Caltech	B-Material
-	I-Material
101	I-Material
)	O
.	O
	
1	O
Introduction	O
Convolutional	B-Method
neural	I-Method
networks	I-Method
(	O
CNNs	B-Method
)	O
trained	O
via	O
backpropagation	B-Method
were	O
recently	O
shown	O
to	O
perform	O
well	O
on	O
image	B-Task
classification	I-Task
tasks	I-Task
with	O
millions	O
of	O
training	O
images	O
and	O
thousands	O
of	O
categories	O
[	O
1	O
,	O
2	O
]	O
.	O
	
The	O
feature	B-Method
representation	I-Method
learned	O
by	O
these	O
networks	O
achieves	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
performance	O
not	O
only	O
on	O
the	O
classification	B-Task
task	I-Task
for	O
which	O
the	O
network	B-Method
was	O
trained	O
,	O
but	O
also	O
on	O
various	O
other	O
visual	B-Task
recognition	I-Task
tasks	I-Task
,	O
for	O
example	O
:	O
classification	B-Task
on	O
Caltech	B-Material
-	I-Material
101	I-Material
[	O
2	O
,	O
3	O
]	O
,	O
Caltech	O
-	O
256	O
	
[	O
2	O
]	O
and	O
the	O
CaltechUCSD	B-Material
birds	I-Material
dataset	I-Material
[	O
3	O
]	O
;	O
scene	B-Task
recognition	I-Task
on	O
the	O
SUN	B-Material
-	I-Material
397	I-Material
database	I-Material
[	O
3	O
]	O
;	O
detection	B-Task
on	O
the	O
PASCAL	B-Material
VOC	I-Material
dataset	I-Material
[	O
4	O
]	O
.	O
	
This	O
capability	O
to	O
generalize	O
to	O
new	O
datasets	O
makes	O
supervised	B-Method
CNN	I-Method
training	I-Method
an	O
attractive	O
approach	O
for	O
generic	B-Task
visual	I-Task
feature	I-Task
learning	I-Task
.	O
	
The	O
downside	O
of	O
supervised	B-Task
training	I-Task
is	O
the	O
need	O
for	O
expensive	B-Task
labeling	I-Task
,	O
as	O
the	O
amount	O
of	O
required	O
labeled	O
samples	O
grows	O
quickly	O
the	O
larger	O
the	O
model	O
gets	O
.	O
	
The	O
large	O
performance	O
increase	O
achieved	O
by	O
methods	O
based	O
on	O
the	O
work	O
of	O
Krizhevsky	O
et	O
al	O
.	O
	
[	O
1	O
]	O
was	O
,	O
for	O
example	O
,	O
only	O
possible	O
due	O
to	O
massive	O
efforts	O
on	O
manually	O
annotating	O
millions	O
of	O
images	O
.	O
	
For	O
this	O
reason	O
,	O
unsupervised	B-Method
learning	I-Method
–	O
although	O
currently	O
underperforming	O
–	O
remains	O
an	O
appealing	O
paradigm	O
,	O
since	O
it	O
can	O
make	O
use	O
of	O
raw	O
unlabeled	O
images	O
and	O
videos	O
.	O
	
Furthermore	O
,	O
on	O
vision	B-Task
tasks	I-Task
outside	O
classification	B-Task
it	O
is	O
not	O
even	O
certain	O
whether	O
training	O
based	O
on	O
object	O
class	O
labels	O
is	O
advantageous	O
.	O
	
For	O
example	O
,	O
unsupervised	B-Method
feature	I-Method
learning	I-Method
is	O
known	O
to	O
be	O
beneficial	O
for	O
image	B-Task
restoration	I-Task
[	O
5	O
]	O
and	O
recent	O
results	O
show	O
that	O
it	O
outperforms	O
supervised	B-Method
feature	I-Method
learning	I-Method
also	O
on	O
descriptor	B-Task
matching	I-Task
[	O
6	O
]	O
.	O
	
In	O
this	O
work	O
we	O
combine	O
the	O
power	O
of	O
a	O
discriminative	B-Method
objective	I-Method
with	O
the	O
major	O
advantage	O
of	O
unsupervised	B-Method
feature	I-Method
learning	I-Method
:	O
cheap	B-Task
data	I-Task
acquisition	I-Task
.	O
	
We	O
introduce	O
a	O
novel	O
training	B-Method
procedure	I-Method
for	O
convolutional	B-Method
neural	I-Method
networks	I-Method
that	O
does	O
not	O
require	O
any	O
labeled	O
data	O
.	O
	
It	O
rather	O
relies	O
on	O
an	O
automatically	O
generated	O
surrogate	B-Task
task	I-Task
.	O
	
The	O
task	O
is	O
created	O
by	O
taking	O
the	O
idea	O
of	O
data	B-Task
augmentation	I-Task
–	O
which	O
is	O
commonly	O
used	O
in	O
supervised	B-Task
learning	I-Task
–	O
to	O
the	O
extreme	O
.	O
	
Starting	O
with	O
trivial	O
surrogate	O
classes	O
consisting	O
of	O
one	O
random	O
image	O
patch	O
each	O
,	O
we	O
augment	O
the	O
data	O
by	O
applying	O
a	O
random	O
set	O
of	O
transformations	O
to	O
each	O
patch	O
.	O
	
Then	O
we	O
train	O
a	O
CNN	B-Method
to	O
classify	O
these	O
surrogate	O
classes	O
.	O
	
We	O
refer	O
to	O
this	O
method	O
as	O
exemplar	B-Method
training	I-Method
of	I-Method
convolutional	I-Method
neural	I-Method
networks	I-Method
(	O
Exemplar	B-Method
-	I-Method
CNN	I-Method
)	O
.	O
	
The	O
feature	B-Method
representation	I-Method
learned	O
by	O
Exemplar	B-Method
-	I-Method
CNN	I-Method
is	O
,	O
by	O
construction	O
,	O
discriminative	O
and	O
invariant	O
to	O
typical	O
transformations	O
.	O
	
We	O
confirm	O
this	O
both	O
theoretically	O
and	O
empirically	O
,	O
showing	O
that	O
this	O
approach	O
matches	O
or	O
outperforms	O
all	O
previous	O
unsupervised	B-Method
feature	I-Method
learning	I-Method
methods	I-Method
on	O
the	O
standard	O
image	O
classification	O
benchmarks	O
STL	B-Material
-	I-Material
10	I-Material
,	O
CIFAR	B-Material
-	I-Material
10	I-Material
,	O
and	O
Caltech	B-Material
-	I-Material
101	I-Material
.	O
	
1.1	O
Related	O
Work	O
	
Our	O
approach	O
is	O
related	O
to	O
a	O
large	O
body	O
of	O
work	O
on	O
unsupervised	B-Method
learning	I-Method
of	O
invariant	O
features	O
and	O
training	O
of	O
convolutional	B-Method
neural	I-Method
networks	I-Method
.	O
	
Convolutional	B-Method
training	I-Method
is	O
commonly	O
used	O
in	O
both	O
supervised	B-Method
and	I-Method
unsupervised	I-Method
methods	I-Method
to	O
utilize	O
the	O
invariance	O
of	O
image	O
statistics	O
to	O
translations	O
(	O
e.g.	O
LeCun	O
et	O
al	O
.	O
	
[	O
7	O
]	O
,	O
Kavukcuoglu	O
et	O
al	O
.	O
	
[	O
8	O
]	O
,	O
Krizhevsky	O
et	O
al	O
.	O
	
[	O
1	O
]	O
)	O
.	O
	
Similar	O
to	O
our	O
approach	O
the	O
current	O
surge	O
of	O
successful	O
methods	O
employing	O
convolutional	B-Method
neural	I-Method
networks	I-Method
for	O
object	B-Task
recognition	I-Task
often	O
rely	O
on	O
data	B-Task
augmentation	I-Task
to	O
generate	O
additional	O
training	O
samples	O
for	O
their	O
classification	B-Metric
objective	I-Metric
(	O
e.g.	O
Krizhevsky	O
et	O
al	O
.	O
	
[	O
1	O
]	O
,	O
Zeiler	O
and	O
Fergus	O
[	O
2	O
]	O
)	O
	
.	O
	
While	O
we	O
share	O
the	O
architecture	O
(	O
a	O
convolutional	O
neural	O
network	B-Method
)	O
with	O
these	O
approaches	O
,	O
our	O
method	O
does	O
not	O
rely	O
on	O
any	O
labeled	O
training	O
data	O
.	O
	
In	O
unsupervised	B-Method
learning	I-Method
,	O
several	O
studies	O
on	O
learning	B-Task
invariant	I-Task
representations	I-Task
exist	O
.	O
	
Denoising	B-Method
autoencoders	I-Method
[	O
9	O
]	O
,	O
for	O
example	O
,	O
learn	O
features	O
that	O
are	O
robust	O
to	O
noise	O
by	O
trying	O
to	O
reconstruct	O
data	O
from	O
randomly	O
perturbed	O
input	O
samples	O
.	O
	
Zou	O
et	O
al	O
.	O
	
[	O
10	O
]	O
learn	O
invariant	O
features	O
from	O
video	O
by	O
enforcing	O
a	O
temporal	O
slowness	O
constraint	O
on	O
the	O
feature	B-Method
representation	I-Method
learned	O
by	O
a	O
linear	B-Method
autoencoder	I-Method
.	O
	
Sohn	O
and	O
Lee	O
[	O
11	O
]	O
and	O
Hui	O
	
[	O
12	O
]	O
learn	O
features	O
invariant	O
to	O
local	O
image	O
transformations	O
.	O
	
In	O
contrast	O
to	O
our	O
discriminative	B-Method
approach	I-Method
,	O
all	O
these	O
methods	O
rely	O
on	O
directly	O
modeling	O
the	O
input	O
distribution	O
and	O
are	O
typically	O
hard	O
to	O
use	O
for	O
jointly	O
training	O
multiple	O
layers	O
of	O
a	O
CNN	B-Method
.	O
	
The	O
idea	O
of	O
learning	O
features	O
that	O
are	O
invariant	O
to	O
transformations	O
has	O
also	O
been	O
explored	O
for	O
supervised	B-Task
training	I-Task
of	I-Task
neural	I-Task
networks	I-Task
.	O
	
The	O
research	O
most	O
similar	O
to	O
ours	O
is	O
early	O
work	O
on	O
tangent	B-Method
propagation	I-Method
[	O
13	O
]	O
(	O
and	O
the	O
related	O
double	B-Method
backpropagation	I-Method
[	O
14	O
]	O
)	O
which	O
aims	O
to	O
learn	O
invariance	O
to	O
small	O
predefined	O
transformations	O
in	O
a	O
neural	O
network	B-Method
by	O
directly	O
penalizing	O
the	O
derivative	O
of	O
the	O
output	O
with	O
respect	O
to	O
the	O
magnitude	O
of	O
the	O
transformations	O
.	O
	
In	O
contrast	O
,	O
our	O
algorithm	O
does	O
not	O
regularize	O
the	O
derivative	O
explicitly	O
.	O
	
Thus	O
it	O
is	O
less	O
sensitive	O
to	O
the	O
magnitude	O
of	O
the	O
applied	O
transformation	O
.	O
	
This	O
work	O
is	O
also	O
loosely	O
related	O
to	O
the	O
use	O
of	O
unlabeled	O
data	O
for	O
regularizing	B-Method
supervised	I-Method
algorithms	I-Method
,	O
for	O
example	O
self	B-Task
-	I-Task
training	I-Task
[	O
15	O
]	O
or	O
entropy	B-Method
regularization	I-Method
	
[	O
16	O
]	O
.	O
	
In	O
contrast	O
to	O
these	O
semi	B-Method
-	I-Method
supervised	I-Method
methods	I-Method
,	O
Exemplar	B-Method
-	I-Method
CNN	I-Method
training	I-Method
does	O
not	O
require	O
any	O
labeled	O
data	O
.	O
	
Finally	O
,	O
the	O
idea	O
of	O
creating	O
an	O
auxiliary	B-Task
task	I-Task
in	O
order	O
to	O
learn	O
a	O
good	O
data	B-Method
representation	I-Method
was	O
used	O
by	O
Ahmed	O
et	O
al	O
.	O
	
[	O
17	O
]	O
,	O
Collobert	O
et	O
al	O
.	O
	
[	O
18	O
]	O
.	O
2	O
Creating	O
Surrogate	B-Material
Training	I-Material
Data	I-Material
	
The	O
input	O
to	O
the	O
training	O
procedure	O
is	O
a	O
set	O
of	O
unlabeled	O
images	O
,	O
which	O
come	O
from	O
roughly	O
the	O
same	O
distribution	O
as	O
the	O
images	O
to	O
which	O
we	O
later	O
aim	O
to	O
apply	O
the	O
learned	O
features	O
.	O
	
We	O
randomly	O
sample	O
N	O
∈	O
[	O
50	O
,	O
32000	O
]	O
patches	O
of	O
size	O
32×32	O
pixels	O
from	O
different	O
images	O
at	O
varying	O
positions	O
and	O
scales	O
forming	O
the	O
initial	O
training	O
set	O
X	O
=	O
{	O
x1	O
,	O
.	O
.	O
	
.xN}.	O
	
We	O
are	O
interested	O
in	O
patches	O
containing	O
objects	O
or	O
parts	O
of	O
objects	O
,	O
hence	O
we	O
sample	O
only	O
from	O
regions	O
containing	O
considerable	O
gradients	O
.	O
	
We	O
define	O
a	O
family	O
of	O
transformations	O
{	O
Tα|α	O
∈	O
A	O
}	O
parameterized	O
by	O
vectors	O
α	O
	
∈	O
A	O
,	O
where	O
A	O
is	O
the	O
set	O
of	O
all	O
possible	O
parameter	O
vectors	O
.	O
	
Each	O
transformation	O
	
Tα	B-Method
is	O
a	O
composition	O
of	O
elementary	O
transformations	O
from	O
the	O
following	O
list	O
:	O
	
•	O
translation	O
:	O
vertical	O
or	O
horizontal	O
translation	O
by	O
a	O
distance	O
within	O
0.2	O
of	O
the	O
patch	O
size	O
;	O
•	O
scaling	B-Method
:	O
multiplication	O
of	O
the	O
patch	O
scale	O
by	O
a	O
factor	O
between	O
0.7	O
and	O
1.4	O
;	O
•	O
rotation	O
:	O
rotation	O
of	O
the	O
image	O
by	O
an	O
angle	O
up	O
to	O
20	O
degrees	O
;	O
•	O
contrast	O
1	O
:	O
multiply	O
the	O
projection	O
of	O
each	O
patch	O
pixel	O
onto	O
the	O
principal	O
components	O
of	O
the	O
set	O
of	O
all	O
pixels	O
by	O
a	O
factor	O
between	O
0.5	O
and	O
2	O
(	O
factors	O
are	O
independent	O
for	O
each	O
principal	O
component	O
and	O
the	O
same	O
for	O
all	O
pixels	O
within	O
a	O
patch	O
)	O
;	O
•	O
	
contrast	O
2	O
:	O
	
raise	O
saturation	O
and	O
value	O
(	O
S	O
and	O
V	O
components	O
of	O
the	O
HSV	B-Method
color	I-Method
representation	I-Method
)	O
of	O
all	O
pixels	O
to	O
a	O
power	O
between	O
0.25	O
and	O
4	O
(	O
same	O
for	O
all	O
pixels	O
within	O
a	O
patch	O
)	O
,	O
multiply	O
these	O
values	O
by	O
a	O
factor	O
between	O
0.7	O
and	O
1.4	O
,	O
	
add	O
to	O
them	O
a	O
value	O
between	O
−0.1	O
and	O
0.1	O
;	O
	
•	O
color	O
:	O
add	O
a	O
value	O
between	O
−0.1	O
and	O
0.1	O
to	O
the	O
hue	O
	
(	O
H	B-Method
component	I-Method
of	O
the	O
HSV	B-Method
color	I-Method
representation	I-Method
)	O
of	O
all	O
pixels	O
in	O
the	O
patch	O
(	O
the	O
same	O
value	O
is	O
used	O
for	O
all	O
pixels	O
within	O
a	O
patch	O
)	O
.	O
	
All	O
numerical	O
parameters	O
of	O
elementary	O
transformations	O
,	O
when	O
concatenated	O
together	O
,	O
form	O
a	O
single	O
parameter	O
vector	O
α	O
.	O
	
For	O
each	O
initial	O
patch	O
xi	O
∈	O
X	O
we	O
sample	O
K	O
∈	O
[	O
1	O
,	O
300	O
]	O
random	O
parameter	O
vectors	O
{	O
α1i	O
,	O
.	O
.	O
	
.	O
,	O
αKi	O
}	O
	
and	O
apply	O
the	O
corresponding	O
transformations	O
	
Ti	O
=	O
	
{	O
Tα1i	O
,	O
.	O
.	O
.	O
,	O
TαKi	O
}	O
to	O
the	O
patch	O
xi	O
.	O
	
This	O
yields	O
the	O
set	O
of	O
its	O
transformed	O
versions	O
Sxi	O
=	O
	
Tixi	O
=	O
	
{	O
Txi|T	O
∈	O
	
Ti}.	O
	
Afterwards	O
we	O
subtract	O
the	O
mean	O
of	O
each	O
pixel	O
over	O
the	O
whole	O
resulting	O
dataset	O
.	O
	
We	O
do	O
not	O
apply	O
any	O
other	O
preprocessing	O
.	O
	
Exemplary	O
patches	O
sampled	O
from	O
the	O
STL	B-Material
-	O
10	O
unlabeled	O
dataset	O
are	O
shown	O
in	O
Fig	O
.	O
1	O
.	O
	
Examples	O
of	O
transformed	B-Method
versions	I-Method
of	O
one	O
patch	O
are	O
shown	O
in	O
Fig	O
.	O
	
2	O
.	O
	
3	O
	
Learning	B-Method
Algorithm	I-Method
Given	O
the	O
sets	O
of	O
transformed	O
image	O
patches	O
,	O
we	O
declare	O
each	O
of	O
these	O
sets	O
to	O
be	O
a	O
class	O
by	O
assigning	O
label	O
i	O
to	O
the	O
class	O
Sxi	O
.	O
	
We	O
next	O
train	O
a	O
CNN	B-Method
to	O
discriminate	O
between	O
these	O
surrogate	O
classes	O
.	O
	
Formally	O
,	O
we	O
minimize	O
the	O
following	O
loss	B-Metric
function	I-Metric
:	O
L	B-Method
(	I-Method
X	I-Method
)	O
=	O
	
∑	O
xi∈X	O
	
∑	O
T∈Ti	O
l	O
(	O
i	O
,	O
Txi	O
)	O
,	O
(	O
1	O
)	O
where	O
l	O
(	O
i	O
,	O
Txi	O
)	O
is	O
the	O
loss	O
on	O
the	O
transformed	O
sample	O
Txi	O
with	O
(	O
surrogate	O
)	O
true	O
label	O
	
i.	O
	
We	O
use	O
a	O
CNN	B-Method
with	O
a	O
softmax	B-Method
output	I-Method
layer	I-Method
and	O
optimize	O
the	O
multinomial	O
negative	O
log	O
likelihood	O
of	O
the	O
network	B-Method
output	O
,	O
hence	O
in	O
our	O
case	O
l	O
(	O
i	O
,	O
Txi	O
)	O
=	O
	
M	O
(	O
ei	O
,	O
f	O
(	O
Txi	O
)	O
)	O
,	O
	
M	O
(	O
y	O
,	O
f	O
)	O
=	O
	
−〈y	O
,	O
log	O
f	O
〉	O
=	O
	
−	O
	
∑	O
k	O
yk	O
log	O
fk	O
,	O
(	O
2	O
)	O
	
where	O
f	O
(	O
·	O
)	O
denotes	O
the	O
function	O
computing	O
the	O
values	O
of	O
the	O
output	O
layer	O
of	O
the	O
CNN	B-Method
given	O
the	O
input	O
data	O
,	O
and	O
ei	O
is	O
the	O
ith	O
standard	O
basis	O
vector	O
.	O
	
We	O
note	O
that	O
in	O
the	O
limit	O
of	O
an	O
infinite	O
number	O
of	O
transformations	O
per	O
surrogate	O
class	O
,	O
the	O
objective	B-Metric
function	I-Metric
(	O
1	O
)	O
takes	O
the	O
form	O
L̂	O
(	O
X	O
)	O
=	O
	
∑	O
xi∈X	O
Eα	O
[	O
l	O
(	O
i	O
,	O
Tαxi	O
)	O
]	O
,	O
(	O
3	O
)	O
which	O
we	O
shall	O
analyze	O
in	O
the	O
next	O
section	O
.	O
	
Intuitively	O
,	O
the	O
classification	B-Task
problem	I-Task
described	O
above	O
serves	O
to	O
ensure	O
that	O
different	O
input	O
samples	O
can	O
be	O
distinguished	O
.	O
	
At	O
the	O
same	O
time	O
,	O
it	O
enforces	O
invariance	O
to	O
the	O
specified	O
transformations	O
.	O
	
In	O
the	O
following	O
sections	O
we	O
provide	O
a	O
foundation	O
for	O
this	O
intuition	O
.	O
	
We	O
first	O
present	O
a	O
formal	O
analysis	O
of	O
the	O
objective	O
,	O
separating	O
it	O
into	O
a	O
well	O
defined	O
classification	B-Task
problem	I-Task
and	O
a	O
regularizer	B-Method
that	O
enforces	O
invariance	O
(	O
resembling	O
the	O
analysis	O
in	O
Wager	O
et	O
al	O
.	O
	
[	O
19	O
]	O
)	O
.	O
	
We	O
then	O
discuss	O
the	O
derived	O
properties	O
of	O
this	O
classification	B-Task
problem	I-Task
and	O
compare	O
it	O
to	O
common	O
practices	O
for	O
unsupervised	B-Method
feature	I-Method
learning	I-Method
.	O
	
3.1	O
Formal	B-Task
Analysis	I-Task
	
We	O
denote	O
by	O
α	O
∈	O
A	O
the	O
random	O
vector	O
of	O
transformation	O
parameters	O
,	O
by	O
g	O
(	O
x	O
)	O
	
the	O
vector	O
of	O
activations	O
of	O
the	O
second	O
-	O
to	O
-	O
last	O
layer	O
of	O
the	O
network	B-Method
when	O
presented	O
the	O
input	O
patch	O
x	O
,	O
by	O
W	O
the	O
matrix	O
of	O
the	O
weights	O
of	O
the	O
last	O
network	B-Method
layer	O
,	O
by	O
	
h	O
(	O
x	O
)	O
=	O
	
Wg	O
(	O
x	O
)	O
	
the	O
last	O
layer	O
activations	O
before	O
applying	O
the	O
softmax	O
,	O
and	O
by	O
f	O
(	O
x	O
)	O
	
=	O
softmax	O
(	O
h	O
(	O
x	O
)	O
)	O
	
the	O
output	O
of	O
the	O
network	B-Method
.	O
	
By	O
plugging	O
in	O
the	O
definition	O
of	O
the	O
softmax	O
activation	O
function	O
softmax	O
(	O
z	O
)	O
=	O
	
exp	O
(	O
z	O
)/	O
‖	O
exp	O
(	O
z	O
)	O
‖1	O
	
(	O
4	O
)	O
the	O
objective	B-Metric
function	I-Metric
(	O
3	O
)	O
with	O
loss	O
(	O
2	O
)	O
takes	O
the	O
form∑	O
xi∈X	O
	
Eα	O
[	O
−〈ei	O
,	O
h	O
(	O
Tαxi	O
)	O
〉	O
+	O
log	O
‖	O
exp	O
(	O
h	O
(	O
Tαxi	O
))	O
‖1	O
]	O
.	O
	
(	O
5	O
)	O
With	O
ĝi	O
=	O
	
Eα	O
[	O
g	O
(	O
Tαxi	O
)	O
]	O
being	O
the	O
average	B-Method
feature	I-Method
representation	I-Method
of	I-Method
transformed	I-Method
versions	I-Method
of	O
the	O
image	B-Method
patch	I-Method
	
xi	O
we	O
can	O
rewrite	O
Eq	O
.	O
	
(	O
5	O
)	O
as∑	O
xi∈X	O
	
[	O
−〈ei	O
,	O
Wĝi〉	O
+	O
log	O
‖	O
exp	O
(	O
Wĝi	O
)	O
‖1	O
]	O
	
+	O
∑	O
xi∈X	O
	
[	O
Eα	O
[	O
log	O
‖	O
exp	O
(	O
h	O
(	O
Tαxi	O
))	O
‖1	O
]	O
−	O
log	O
‖	O
exp	O
(	O
Wĝi	O
)	O
‖1	O
]	O
.	O
	
(	O
6	O
)	O
	
The	O
first	O
sum	O
is	O
the	O
objective	B-Metric
function	I-Metric
of	O
a	O
multinomial	B-Task
logistic	I-Task
regression	I-Task
problem	I-Task
with	O
input	O
-	O
target	O
pairs	O
(	O
ĝi	O
,	O
ei	O
)	O
.	O
	
This	O
objective	O
falls	O
back	O
to	O
the	O
transformation	B-Task
-	I-Task
free	I-Task
instance	I-Task
classification	I-Task
problem	I-Task
L	I-Task
(	I-Task
X	I-Task
)	O
=	O
	
∑	O
xi∈X	O
	
l	O
(	O
i	O
,	O
xi	O
)	O
	
if	O
g	O
(	O
xi	O
)	O
	
=	O
	
Eα	O
[	O
g	O
(	O
Tαx	O
)]	O
.	O
	
In	O
general	O
,	O
this	O
equality	O
does	O
not	O
hold	O
and	O
thus	O
the	O
first	O
sum	O
enforces	O
correct	B-Metric
classification	I-Metric
of	O
the	O
average	O
representation	O
Eα	O
[	O
g	O
(	O
Tαxi	O
)	O
]	O
for	O
a	O
given	O
input	O
sample	O
.	O
	
For	O
a	O
truly	O
invariant	B-Method
representation	I-Method
,	O
however	O
,	O
the	O
equality	O
is	O
achieved	O
.	O
	
Similarly	O
,	O
if	O
we	O
suppose	O
that	O
Tαx	O
=	O
x	O
for	O
α	O
=	O
0	O
,	O
that	O
for	O
small	O
values	O
of	O
α	O
the	O
feature	B-Method
representation	I-Method
g	I-Method
(	I-Method
Tαxi	I-Method
)	O
is	O
approximately	O
linear	O
with	O
respect	O
to	O
α	O
and	O
that	O
the	O
random	O
variable	O
α	O
is	O
centered	O
,	O
i.e.	O
Eα	O
[	O
α	O
]	O
=	O
0	O
,	O
then	O
ĝi	O
=	O
	
Eα	O
[	O
g	O
(	O
Tαxi	O
)	O
]	O
	
≈	O
	
Eα	O
[	O
g	O
(	O
xi	O
)	O
+	O
∇α	O
(	O
g	O
(	O
Tαxi	O
))	O
|α=0	O
	
α	O
]	O
	
=	O
g	O
(	O
xi	O
)	O
.	O
	
The	O
second	O
sum	O
in	O
Eq	O
.	O
	
(	O
6	O
)	O
can	O
be	O
seen	O
as	O
a	O
regularizer	B-Method
enforcing	O
all	O
h	O
(	O
Tαxi	O
)	O
to	O
be	O
close	O
to	O
their	O
average	O
value	O
,	O
i.e.	O
,	O
the	O
feature	B-Method
representation	I-Method
is	O
sought	O
to	O
be	O
approximately	O
invariant	O
to	O
the	O
transformations	O
Tα	O
.	O
	
To	O
show	O
this	O
we	O
use	O
the	O
convexity	O
of	O
the	O
function	O
log	O
‖	O
exp	O
(	O
·	O
)	O
‖1	O
and	O
	
Jensen	O
’s	O
inequality	O
,	O
which	O
yields	O
(	O
proof	O
in	O
supplementary	O
material	O
)	O
	
Eα	O
	
[	O
log	O
‖	O
exp	O
(	O
h	O
(	O
Tαxi	O
))	O
‖1	O
]	O
−	O
	
log	O
‖	O
exp	O
(	O
Wĝi	O
)	O
‖1	O
≥	O
0	O
.	O
	
(	O
7	O
)	O
	
If	O
the	O
feature	B-Method
representation	I-Method
is	O
perfectly	O
invariant	O
,	O
then	O
h	O
(	O
Tαxi	O
)	O
=	O
	
Wĝi	B-Method
and	O
inequality	O
	
(	O
7	O
)	O
turns	O
to	O
equality	O
,	O
meaning	O
that	O
the	O
regularizer	B-Method
reaches	O
its	O
global	O
minimum	O
.	O
	
3.2	O
Conceptual	O
Comparison	O
to	O
Previous	O
Unsupervised	B-Method
Learning	I-Method
Methods	I-Method
Suppose	O
we	O
want	O
to	O
unsupervisedly	O
learn	O
a	O
feature	B-Method
representation	I-Method
useful	O
for	O
a	O
recognition	B-Task
task	I-Task
,	O
for	O
example	O
classification	B-Task
.	O
	
The	O
mapping	O
from	O
input	O
images	O
x	O
to	O
a	O
feature	B-Method
representation	I-Method
g	I-Method
(	I-Method
x	I-Method
)	O
should	O
then	O
satisfy	O
two	O
requirements	O
:	O
(	O
1	O
)	O
there	O
must	O
be	O
at	O
least	O
one	O
feature	O
that	O
is	O
similar	O
for	O
images	O
of	O
the	O
same	O
category	O
y	O
(	O
invariance	O
)	O
;	O
(	O
2	O
)	O
there	O
must	O
be	O
at	O
least	O
one	O
feature	O
that	O
is	O
sufficiently	O
different	O
for	O
images	O
of	O
different	O
categories	O
(	O
ability	O
to	O
discriminate	O
)	O
.	O
	
Most	O
unsupervised	B-Method
feature	I-Method
learning	I-Method
methods	I-Method
aim	O
to	O
learn	O
such	O
a	O
representation	O
by	O
modeling	O
the	O
input	O
distribution	B-Method
p	I-Method
(	I-Method
x	I-Method
)	I-Method
.	O
	
This	O
is	O
based	O
on	O
the	O
assumption	O
that	O
a	O
good	O
model	O
of	O
p	O
(	O
x	O
)	O
contains	O
information	O
about	O
the	O
category	O
distribution	O
p	O
(	O
y|x	O
)	O
.	O
	
That	O
is	O
,	O
if	O
a	O
representation	O
is	O
learned	O
,	O
from	O
which	O
a	O
given	O
sample	O
can	O
be	O
reconstructed	O
perfectly	O
,	O
then	O
the	O
representation	O
is	O
expected	O
to	O
also	O
encode	O
information	O
about	O
the	O
category	O
of	O
the	O
sample	O
(	O
ability	O
to	O
discriminate	O
)	O
.	O
	
Additionally	O
,	O
the	O
learned	O
representation	O
should	O
be	O
invariant	O
to	O
variations	O
in	O
the	O
samples	O
that	O
are	O
irrelevant	O
for	O
the	O
classification	B-Task
task	I-Task
	
,	O
i.e.	O
,	O
it	O
should	O
adhere	O
to	O
the	O
manifold	O
hypothesis	O
(	O
see	O
e.g.	O
Rifai	O
et	O
al	O
.	O
	
[	O
20	O
]	O
for	O
a	O
recent	O
discussion	O
)	O
.	O
	
Invariance	B-Task
is	O
classically	O
achieved	O
by	O
regularization	B-Method
of	I-Method
the	I-Method
latent	I-Method
representation	I-Method
,	O
e.g.	O
,	O
by	O
enforcing	O
sparsity	O
[	O
8	O
]	O
or	O
robustness	B-Metric
to	O
noise	O
[	O
9	O
]	O
.	O
	
In	O
contrast	O
,	O
the	O
discriminative	B-Metric
objective	I-Metric
in	O
Eq	O
.	O
	
(	O
1	O
)	O
does	O
not	O
directly	O
model	O
the	O
input	O
distribution	O
p	O
(	O
x	O
)	O
but	O
learns	O
a	O
representation	O
that	O
discriminates	O
between	O
input	O
samples	O
.	O
	
The	O
representation	O
is	O
not	O
required	O
to	O
reconstruct	O
the	O
input	O
,	O
which	O
is	O
unnecessary	O
in	O
a	O
recognition	B-Task
or	I-Task
matching	I-Task
task	I-Task
.	O
	
This	O
leaves	O
more	O
degrees	O
of	O
freedom	O
to	O
model	O
the	O
desired	O
variability	O
of	O
a	O
sample	O
.	O
	
As	O
shown	O
in	O
our	O
analysis	O
(	O
see	O
Eq	O
.	O
	
(	O
7	O
)	O
)	O
,	O
we	O
achieve	O
partial	O
invariance	O
to	O
transformations	O
applied	O
during	O
surrogate	B-Task
data	I-Task
creation	I-Task
by	O
forcing	O
the	O
representation	B-Method
g	I-Method
(	I-Method
Tαxi	I-Method
)	O
of	O
the	O
transformed	O
image	O
patch	O
to	O
be	O
predictive	O
of	O
the	O
surrogate	O
label	O
assigned	O
to	O
the	O
original	O
image	O
patch	O
	
xi	O
.	O
	
It	O
should	O
be	O
noted	O
that	O
this	O
approach	O
assumes	O
that	O
the	O
transformations	O
Tα	O
do	O
not	O
change	O
the	O
identity	O
of	O
the	O
image	O
content	O
.	O
	
If	O
we	O
,	O
for	O
example	O
,	O
use	O
a	O
color	O
transformation	O
we	O
will	O
force	O
the	O
network	B-Method
to	O
be	O
invariant	O
to	O
this	O
change	O
and	O
can	O
not	O
expect	O
the	O
extracted	O
features	O
to	O
perform	O
well	O
in	O
a	O
task	O
relying	O
on	O
color	O
information	O
(	O
such	O
as	O
differentiating	O
black	O
panthers	O
from	O
pumas	O
)	O
1	O
.	O
	
4	O
Experiments	O
To	O
compare	O
our	O
discriminative	B-Method
approach	I-Method
to	O
previous	O
unsupervised	B-Method
feature	I-Method
learning	I-Method
methods	I-Method
,	O
we	O
report	O
classification	B-Task
results	O
on	O
the	O
STL	B-Material
-	I-Material
10	I-Material
[	O
21	O
]	O
,	O
CIFAR	B-Material
-	I-Material
10	I-Material
[	O
22	O
]	O
and	O
Caltech	B-Material
-	I-Material
101	I-Material
[	O
23	O
]	O
datasets	O
.	O
	
Moreover	O
,	O
we	O
assess	O
the	O
influence	O
of	O
the	O
augmentation	O
parameters	O
on	O
the	O
classification	B-Metric
performance	I-Metric
and	O
study	O
the	O
invariance	B-Metric
properties	I-Metric
of	O
the	O
network	B-Method
.	O
	
4.1	O
Experimental	O
Setup	O
	
The	O
datasets	O
we	O
test	O
on	O
differ	O
in	O
the	O
number	O
of	O
classes	O
(	O
10	O
for	O
CIFAR	B-Material
and	O
STL	B-Material
,	O
101	O
for	O
Caltech	B-Material
)	O
and	O
the	O
number	O
of	O
samples	O
per	O
class	O
.	O
	
STL	B-Material
is	O
especially	O
well	O
suited	O
for	O
unsupervised	B-Method
learning	I-Method
as	O
it	O
contains	O
a	O
large	O
set	O
of	O
100	O
,	O
000	O
unlabeled	O
samples	O
.	O
	
In	O
all	O
experiments	O
(	O
except	O
for	O
the	O
dataset	B-Task
transfer	I-Task
experiment	O
in	O
the	O
supplementary	O
material	O
)	O
we	O
extracted	O
surrogate	O
training	O
data	O
from	O
the	O
unlabeled	O
subset	O
of	O
STL	B-Material
-	I-Material
10	I-Material
.	O
	
When	O
testing	O
on	O
CIFAR	B-Material
-	I-Material
10	I-Material
,	O
we	O
resized	O
the	O
images	O
from	O
32×32	O
pixels	O
to	O
64×64	O
pixels	O
so	O
that	O
the	O
scale	O
of	O
depicted	O
objects	O
roughly	O
matches	O
the	O
two	O
other	O
datasets	O
.	O
	
We	O
worked	O
with	O
two	O
network	B-Method
architectures	O
.	O
	
A	O
“	O
small	O
”	O
network	B-Method
was	O
used	O
to	O
evaluate	O
the	O
influence	O
of	O
different	O
components	O
of	O
the	O
augmentation	B-Method
procedure	I-Method
on	O
classification	B-Task
performance	O
.	O
	
It	O
consists	O
of	O
two	O
convolutional	B-Method
layers	I-Method
with	O
64	B-Method
filters	I-Method
each	O
followed	O
by	O
a	O
fully	B-Method
connected	I-Method
layer	I-Method
with	O
128	O
neurons	O
.	O
	
This	O
last	O
layer	O
is	O
succeeded	O
by	O
a	O
softmax	B-Method
layer	I-Method
,	O
which	O
serves	O
as	O
the	O
network	B-Method
output	O
.	O
	
A	O
“	O
large	O
”	O
network	B-Method
,	O
consisting	O
of	O
three	O
convolutional	B-Method
layers	I-Method
with	O
64	O
,	O
128	O
and	O
256	O
filters	O
respectively	O
followed	O
by	O
a	O
fully	B-Method
connected	I-Method
layer	I-Method
with	O
512	O
neurons	O
,	O
was	O
trained	O
to	O
compare	O
our	O
method	O
to	O
the	O
state	O
-	O
of	O
-	O
theart	O
.	O
	
In	O
both	O
models	O
all	O
convolutional	B-Method
filters	I-Method
are	O
connected	O
to	O
a	O
5×5	O
region	O
of	O
their	O
input	O
.	O
	
2×2	B-Method
maxpooling	I-Method
was	O
performed	O
after	O
the	O
first	O
and	O
second	O
convolutional	B-Method
layers	I-Method
.	O
	
Dropout	B-Method
[	O
24	O
]	O
was	O
applied	O
to	O
the	O
fully	B-Method
connected	I-Method
layers	I-Method
.	O
	
We	O
trained	O
the	O
networks	O
using	O
an	O
implementation	O
based	O
on	O
Caffe	B-Method
	
[	O
25	O
]	O
.	O
Details	O
on	O
the	O
training	B-Task
,	O
the	O
hyperparameter	O
settings	O
,	O
and	O
an	O
analysis	O
of	O
the	O
performance	O
depending	O
on	O
the	O
network	B-Method
architecture	O
is	O
provided	O
in	O
the	O
supplementary	O
material	O
.	O
	
Our	O
code	O
and	O
training	O
data	O
are	O
available	O
at	O
http:	O
//	O
lmb.informatik.uni	O
-	O
freiburg.de	O
/	O
resources	O
.	O
	
We	O
applied	O
the	O
feature	B-Method
representation	I-Method
to	O
images	O
of	O
arbitrary	O
size	O
by	O
convolutionally	B-Method
computing	O
the	O
responses	O
of	O
all	O
the	O
network	B-Method
layers	O
except	O
the	O
top	O
softmax	O
.	O
	
To	O
each	O
feature	O
map	O
,	O
we	O
applied	O
the	O
pooling	B-Method
method	I-Method
that	O
is	O
commonly	O
used	O
for	O
the	O
respective	O
dataset	O
:	O
1	O
)	O
4	B-Method
-	I-Method
quadrant	I-Method
max	I-Method
-	I-Method
pooling	I-Method
,	O
resulting	O
in	O
4	O
values	O
per	O
feature	O
map	O
,	O
which	O
is	O
the	O
standard	O
procedure	O
for	O
STL	B-Material
-	I-Material
10	I-Material
and	O
CIFAR	B-Material
-	I-Material
10	I-Material
[	O
26	O
,	O
10	O
,	O
27	O
,	O
12	O
]	O
;	O
2	O
)	O
	
3	B-Method
-	I-Method
layer	I-Method
spatial	I-Method
pyramid	I-Method
,	O
i.e.	O
max	B-Method
-	I-Method
pooling	I-Method
over	O
the	O
whole	O
image	O
as	O
well	O
as	O
within	O
4	O
quadrants	O
and	O
within	O
the	O
cells	O
of	O
a	O
4	O
×	O
4	O
grid	O
,	O
resulting	O
in	O
1	O
+	O
4	O
+	O
16	O
=	O
21	O
values	O
per	O
feature	O
map	O
,	O
which	O
is	O
the	O
standard	O
for	O
Caltech	B-Material
-	I-Material
101	I-Material
[	O
28	O
,	O
10	O
,	O
29	O
]	O
.	O
	
Finally	O
,	O
we	O
trained	O
a	O
linear	B-Method
support	I-Method
vector	I-Method
machine	I-Method
(	O
SVM	B-Method
)	O
on	O
the	O
pooled	O
features	O
.	O
	
On	O
all	O
datasets	O
we	O
used	O
the	O
standard	O
training	B-Metric
and	I-Metric
test	I-Metric
protocols	I-Metric
.	O
	
On	O
STL	B-Material
-	I-Material
10	I-Material
the	O
SVM	B-Method
was	O
trained	O
on	O
10	O
pre	O
-	O
defined	O
folds	O
of	O
the	O
training	O
data	O
.	O
	
We	O
report	O
the	O
mean	O
and	O
standard	O
deviation	O
achieved	O
on	O
the	O
fixed	O
test	O
set	O
.	O
	
For	O
CIFAR	B-Material
-	I-Material
10	I-Material
we	O
report	O
two	O
results	O
:	O
(	O
1	O
)	O
training	O
the	O
SVM	B-Method
on	O
the	O
whole	O
CIFAR	B-Material
-	I-Material
10	I-Material
training	O
set	O
(	O
’	O
CIFAR	B-Material
-	I-Material
10	I-Material
’	O
)	O
;	O
(	O
2	O
)	O
the	O
average	O
over	O
10	O
random	O
selections	O
of	O
400	O
training	O
samples	O
per	O
class	O
(	O
’	O
CIFAR	B-Material
-	I-Material
10	I-Material
(	O
400	O
)	O
’	O
)	O
.	O
	
For	O
Caltech	B-Material
-	I-Material
101	I-Material
we	O
followed	O
the	O
usual	O
protocol	O
of	O
selecting	O
30	O
random	O
samples	O
per	O
class	O
for	O
training	O
and	O
not	O
more	O
than	O
50	O
samples	O
per	O
class	O
for	O
testing	O
.	O
	
This	O
was	O
repeated	O
10	O
times	O
.	O
	
4.2	O
Classification	B-Task
Results	O
	
In	O
Table	O
1	O
we	O
compare	O
Exemplar	B-Method
-	I-Method
CNN	I-Method
to	O
several	O
unsupervised	B-Method
feature	I-Method
learning	I-Method
methods	I-Method
,	O
including	O
the	O
current	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
on	O
each	O
dataset	O
.	O
	
We	O
also	O
list	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
for	O
supervised	B-Task
learning	I-Task
(	O
which	O
is	O
not	O
directly	O
comparable	O
)	O
.	O
	
Additionally	O
we	O
show	O
the	O
dimensionality	O
of	O
the	O
feature	O
vectors	O
1Such	O
cases	O
could	O
be	O
covered	O
either	O
by	O
careful	O
selection	O
of	O
applied	O
transformations	O
or	O
by	O
combining	O
features	O
from	O
multiple	O
networks	O
trained	O
with	O
different	O
sets	O
of	O
transformations	O
and	O
letting	O
the	O
final	O
classifier	B-Method
choose	O
which	O
features	O
to	O
use	O
.	O
	
produced	O
by	O
each	O
method	O
before	O
final	O
pooling	B-Task
.	O
	
The	O
small	B-Method
network	I-Method
was	O
trained	O
on	O
8000	O
surrogate	O
classes	O
containing	O
150	O
samples	O
each	O
and	O
the	O
large	O
one	O
on	O
16000	O
classes	O
with	O
100	O
samples	O
each	O
.	O
	
The	O
features	O
extracted	O
from	O
the	O
larger	O
network	B-Method
match	O
or	O
outperform	O
the	O
best	O
prior	O
result	O
on	O
all	O
datasets	O
.	O
	
This	O
is	O
despite	O
the	O
fact	O
that	O
the	O
dimensionality	O
of	O
the	O
feature	O
vector	O
is	O
smaller	O
than	O
that	O
of	O
most	O
other	O
approaches	O
and	O
that	O
the	O
networks	O
are	O
trained	O
on	O
the	O
STL	B-Material
-	O
10	O
unlabeled	O
dataset	O
(	O
i.e.	O
they	O
are	O
used	O
in	O
a	O
transfer	B-Method
learning	I-Method
manner	I-Method
when	O
applied	O
to	O
CIFAR	B-Material
-	I-Material
10	I-Material
and	O
Caltech	B-Material
101	I-Material
)	O
.	O
	
The	O
increase	O
in	O
performance	O
is	O
especially	O
pronounced	O
when	O
only	O
few	O
labeled	O
samples	O
are	O
available	O
for	O
training	O
the	O
SVM	B-Method
(	O
as	O
is	O
the	O
case	O
for	O
all	O
the	O
datasets	O
except	O
full	O
CIFAR	B-Material
-	I-Material
10	I-Material
)	O
.	O
	
This	O
is	O
in	O
agreement	O
with	O
previous	O
evidence	O
that	O
with	O
increasing	O
feature	O
vector	O
dimensionality	O
and	O
number	O
of	O
labeled	O
samples	O
,	O
training	O
an	O
SVM	B-Method
becomes	O
less	O
dependent	O
on	O
the	O
quality	O
of	O
the	O
features	O
	
[	O
26	O
,	O
12	O
]	O
.	O
Remarkably	O
,	O
on	O
STL	B-Material
-	I-Material
10	I-Material
we	O
achieve	O
an	O
accuracy	B-Metric
of	O
72.8	O
%	O
,	O
which	O
is	O
a	O
large	O
improvement	O
over	O
all	O
previously	O
reported	O
results	O
.	O
	
4.3	O
Detailed	O
Analysis	O
	
We	O
performed	O
additional	O
experiments	O
(	O
using	O
the	O
“	O
small	O
”	O
network	B-Method
)	O
to	O
study	O
the	O
effect	O
of	O
three	O
design	O
choices	O
in	O
Exemplar	B-Method
-	I-Method
CNN	I-Method
training	I-Method
and	O
validate	O
the	O
invariance	O
properties	O
of	O
the	O
learned	O
features	O
.	O
	
Experiments	O
on	O
sampling	O
’	O
seed	O
’	O
patches	O
from	O
different	O
datasets	O
can	O
be	O
found	O
in	O
the	O
supplementary	O
.	O
	
4.3.1	O
Number	O
of	O
Surrogate	O
Classes	O
	
We	O
varied	O
the	O
number	O
N	O
of	O
surrogate	O
classes	O
between	O
50	O
and	O
32000	O
.	O
	
As	O
a	O
sanity	O
check	O
,	O
we	O
also	O
tried	O
classification	B-Method
with	O
random	B-Method
filters	I-Method
.	O
	
The	O
results	O
are	O
shown	O
in	O
Fig	O
.	O
	
3	O
.	O
	
Clearly	O
,	O
the	O
classification	B-Metric
accuracy	I-Metric
increases	O
with	O
the	O
number	O
of	O
surrogate	O
classes	O
until	O
it	O
reaches	O
an	O
optimum	O
at	O
about	O
8000	O
surrogate	O
classes	O
after	O
which	O
it	O
did	O
not	O
change	O
or	O
even	O
decreased	O
.	O
	
This	O
is	O
to	O
be	O
expected	O
:	O
the	O
larger	O
the	O
number	O
of	O
surrogate	O
classes	O
,	O
the	O
more	O
likely	O
it	O
is	O
to	O
draw	O
very	O
similar	O
or	O
even	O
identical	O
samples	O
,	O
which	O
are	O
hard	O
or	O
impossible	O
to	O
discriminate	O
.	O
	
Few	O
such	O
cases	O
are	O
not	O
detrimental	O
to	O
the	O
classification	B-Task
performance	O
,	O
but	O
as	O
soon	O
as	O
such	O
collisions	O
dominate	O
the	O
set	O
of	O
surrogate	O
labels	O
,	O
the	O
discriminative	B-Metric
loss	I-Metric
is	O
no	O
longer	O
reasonable	O
and	O
training	O
the	O
network	B-Method
to	O
the	O
surrogate	B-Task
task	I-Task
no	O
longer	O
succeeds	O
.	O
	
To	O
check	O
the	O
validity	O
of	O
this	O
explanation	O
we	O
also	O
plot	O
in	O
Fig	O
.	O
	
3	O
	
the	O
classification	B-Metric
error	I-Metric
on	O
the	O
validation	O
set	O
(	O
taken	O
from	O
the	O
surrogate	O
data	O
)	O
computed	O
after	O
training	O
the	O
network	B-Method
.	O
	
It	O
rapidly	O
grows	O
as	O
the	O
number	O
of	O
surrogate	O
classes	O
increases	O
.	O
	
We	O
also	O
observed	O
that	O
the	O
optimal	O
number	O
of	O
surrogate	O
classes	O
increases	O
with	O
the	O
size	O
of	O
the	O
network	B-Method
(	O
not	O
shown	O
in	O
the	O
figure	O
)	O
,	O
but	O
eventually	O
saturates	O
.	O
	
This	O
demonstrates	O
the	O
main	O
limitation	O
of	O
our	O
approach	O
to	O
randomly	O
sample	O
’	O
seed	O
’	O
patches	O
:	O
it	O
does	O
not	O
scale	O
to	O
arbitrarily	O
large	O
amounts	O
of	O
unlabeled	O
data	O
.	O
	
However	O
,	O
we	O
do	O
not	O
see	O
this	O
as	O
a	O
fundamental	O
restriction	O
and	O
discuss	O
possible	O
solutions	O
in	O
Section	O
5	O
.	O
	
4.3.2	O
Number	O
of	O
Samples	O
per	O
Surrogate	O
Class	O
Fig	O
.	O
	
4	O
shows	O
the	O
classification	B-Metric
accuracy	I-Metric
when	O
the	O
number	O
K	O
of	O
training	O
samples	O
per	O
surrogate	O
class	O
varies	O
between	O
1	O
and	O
300	O
.	O
	
The	O
performance	O
improves	O
with	O
more	O
samples	O
per	O
surrogate	O
class	O
and	O
2	O
On	O
Caltech	B-Material
-	I-Material
101	I-Material
one	O
can	O
either	O
measure	O
average	B-Metric
accuracy	I-Metric
over	O
all	O
samples	O
(	O
average	B-Metric
overall	I-Metric
accuracy	I-Metric
)	O
or	O
calculate	O
the	O
accuracy	B-Metric
for	O
each	O
class	O
and	O
then	O
average	O
these	O
values	O
(	O
average	B-Metric
per	I-Metric
-	I-Metric
class	I-Metric
accuracy	I-Metric
)	O
.	O
	
These	O
differ	O
,	O
as	O
some	O
classes	O
contain	O
fewer	O
than	O
50	O
test	O
samples	O
.	O
	
Most	O
researchers	O
in	O
ML	B-Task
use	O
average	B-Metric
overall	I-Metric
accuracy	I-Metric
.	O
	
saturates	O
at	O
around	O
100	O
samples	O
.	O
	
This	O
indicates	O
that	O
this	O
amount	O
is	O
sufficient	O
to	O
approximate	O
the	O
formal	O
objective	O
from	O
Eq	O
.	O
	
(	O
3	O
)	O
,	O
hence	O
further	O
increasing	O
the	O
number	O
of	O
samples	O
does	O
not	O
significantly	O
change	O
the	O
optimization	B-Task
problem	I-Task
.	O
	
On	O
the	O
other	O
hand	O
,	O
if	O
the	O
number	O
of	O
samples	O
is	O
too	O
small	O
,	O
there	O
is	O
insufficient	O
data	O
to	O
learn	O
the	O
desired	O
invariance	O
properties	O
.	O
	
4.3.3	O
Types	O
of	O
Transformations	O
	
We	O
varied	O
the	O
transformations	O
used	O
for	O
creating	O
the	O
surrogate	O
data	O
to	O
analyze	O
their	O
influence	O
on	O
the	O
final	O
classification	B-Metric
performance	I-Metric
.	O
	
The	O
set	O
of	O
’	O
seed	O
’	O
patches	O
was	O
fixed	O
.	O
	
The	O
result	O
is	O
shown	O
in	O
Fig	O
.	O
5	O
.	O
	
The	O
value	O
’	O
0	O
’	O
corresponds	O
to	O
applying	O
random	O
compositions	O
of	O
all	O
elementary	O
transformations	O
:	O
scaling	B-Method
,	O
rotation	O
,	O
translation	O
,	O
color	O
variation	O
,	O
and	O
contrast	O
variation	O
.	O
	
Different	O
columns	O
of	O
the	O
plot	O
show	O
the	O
difference	O
in	O
classification	B-Metric
accuracy	I-Metric
as	O
we	O
discarded	O
some	O
types	O
of	O
elementary	O
transformations	O
.	O
	
Several	O
tendencies	O
can	O
be	O
observed	O
.	O
	
First	O
,	O
rotation	O
and	O
scaling	B-Method
have	O
only	O
a	O
minor	O
impact	O
on	O
the	O
performance	O
,	O
while	O
translations	O
,	O
color	O
variations	O
and	O
contrast	O
variations	O
are	O
significantly	O
more	O
important	O
.	O
	
Secondly	O
,	O
the	O
results	O
on	O
STL	B-Material
-	I-Material
10	I-Material
and	O
CIFAR	B-Material
-	I-Material
10	I-Material
consistently	O
show	O
that	O
spatial	O
invariance	O
and	O
color	O
-	O
contrast	O
invariance	O
are	O
approximately	O
of	O
equal	O
importance	O
for	O
the	O
classification	B-Task
performance	O
.	O
	
This	O
indicates	O
that	O
variations	O
in	O
color	O
and	O
contrast	O
,	O
though	O
often	O
neglected	O
,	O
may	O
also	O
improve	O
performance	O
in	O
a	O
supervised	B-Task
learning	I-Task
scenario	I-Task
.	O
	
Thirdly	O
,	O
on	O
Caltech	B-Material
-	I-Material
101	I-Material
color	O
and	O
contrast	O
transformations	O
are	O
much	O
more	O
important	O
compared	O
to	O
spatial	O
transformations	O
than	O
on	O
the	O
two	O
other	O
datasets	O
.	O
	
This	O
is	O
not	O
surprising	O
,	O
since	O
Caltech	B-Material
-	I-Material
101	I-Material
images	O
are	O
often	O
well	O
aligned	O
,	O
and	O
this	O
dataset	O
bias	O
makes	O
spatial	O
invariance	O
less	O
useful	O
.	O
	
4.3.4	O
	
Invariance	B-Metric
Properties	I-Metric
of	O
the	O
Learned	B-Method
Representation	I-Method
	
In	O
a	O
final	O
experiment	O
,	O
we	O
analyzed	O
to	O
which	O
extent	O
the	O
representation	O
learned	O
by	O
the	O
network	B-Method
is	O
invariant	O
to	O
the	O
transformations	O
applied	O
during	O
training	O
.	O
	
We	O
randomly	O
sampled	O
500	O
images	O
from	O
the	O
STL	B-Material
-	O
10	O
test	O
set	O
and	O
applied	O
a	O
range	O
of	O
transformations	O
(	O
translation	O
,	O
rotation	O
,	O
contrast	O
,	O
color	O
)	O
to	O
each	O
image	O
.	O
	
To	O
avoid	O
empty	O
regions	O
beyond	O
the	O
image	O
boundaries	O
when	O
applying	O
spatial	O
transformations	O
,	O
we	O
cropped	O
the	O
central	O
64×64	O
pixel	O
sub	O
-	O
patch	O
from	O
each	O
96×96	O
pixel	O
image	O
.	O
	
We	O
then	O
applied	O
two	O
measures	O
of	O
invariance	O
to	O
these	O
patches	O
.	O
	
First	O
,	O
as	O
an	O
explicit	O
measure	O
of	O
invariance	B-Metric
,	O
we	O
calculated	O
the	O
normalized	O
Euclidean	O
distance	O
between	O
normalized	O
feature	O
vectors	O
of	O
the	O
original	O
image	O
patch	O
and	O
the	O
transformed	O
one	O
[	O
10	O
]	O
(	O
see	O
the	O
supplementary	O
material	O
for	O
details	O
)	O
.	O
	
The	O
downside	O
of	O
this	O
approach	O
is	O
that	O
the	O
distance	O
between	O
extracted	O
features	O
does	O
not	O
take	O
into	O
account	O
how	O
informative	O
and	O
discriminative	O
they	O
are	O
.	O
	
We	O
there	O
-	O
fore	O
evaluated	O
a	O
second	O
measure	O
–	O
classification	B-Metric
performance	I-Metric
depending	O
on	O
the	O
magnitude	O
of	O
the	O
transformation	O
applied	O
to	O
the	O
classified	O
patches	O
–	O
	
which	O
does	O
not	O
come	O
with	O
this	O
problem	O
.	O
	
To	O
compute	O
the	O
classification	B-Metric
accuracy	I-Metric
,	O
we	O
trained	O
an	O
SVM	B-Method
on	O
the	O
central	O
64	O
×	O
64	O
pixel	O
patches	O
from	O
one	O
fold	O
of	O
the	O
STL	B-Material
-	O
10	O
training	O
set	O
and	O
measured	O
classification	B-Task
performance	O
on	O
all	O
transformed	O
versions	O
of	O
500	O
samples	O
from	O
the	O
test	O
set	O
.	O
	
The	O
results	O
of	O
both	O
experiments	O
are	O
shown	O
in	O
Fig	O
.	O
6	O
.	O
	
Due	O
to	O
space	O
restrictions	O
we	O
show	O
only	O
few	O
representative	O
plots	O
.	O
	
Overall	O
the	O
experiment	O
empirically	O
confirms	O
that	O
the	O
Exemplar	B-Method
-	I-Method
CNN	I-Method
objective	I-Method
leads	O
to	O
learning	O
invariant	O
features	O
.	O
	
Features	O
in	O
the	O
third	O
layer	O
and	O
the	O
final	O
pooled	B-Method
feature	I-Method
representation	I-Method
compare	O
favorably	O
to	O
a	O
HOG	B-Method
baseline	I-Method
(	O
Fig	O
.	O
6	O
(	O
a	O
)	O
)	O
.	O
	
Furthermore	O
,	O
adding	O
stronger	O
transformations	O
in	O
the	O
surrogate	O
training	O
data	O
leads	O
to	O
more	O
invariant	O
classification	B-Task
with	O
respect	O
to	O
these	O
transformations	O
(	O
Fig	O
.	O
6	O
(	O
b	O
)-(	O
d	O
)	O
)	O
.	O
	
However	O
,	O
adding	O
too	O
much	O
contrast	O
variation	O
may	O
deteriorate	O
classification	B-Metric
performance	I-Metric
(	O
Fig	O
.	O
6	O
(	O
d	O
)	O
)	O
.	O
	
One	O
possible	O
reason	O
is	O
that	O
level	O
of	O
contrast	O
can	O
be	O
a	O
useful	O
feature	O
:	O
for	O
example	O
,	O
strong	O
edges	O
in	O
an	O
image	O
are	O
usually	O
more	O
important	O
than	O
weak	O
ones	O
.	O
	
5	O
Discussion	O
	
We	O
have	O
proposed	O
a	O
discriminative	B-Method
objective	I-Method
for	O
unsupervised	B-Method
feature	I-Method
learning	I-Method
by	O
training	O
a	O
CNN	B-Method
without	I-Method
class	I-Method
labels	I-Method
.	O
	
The	O
core	O
idea	O
is	O
to	O
generate	O
a	O
set	O
of	O
surrogate	O
labels	O
via	O
data	B-Task
augmentation	I-Task
.	O
	
The	O
features	O
learned	O
by	O
the	O
network	B-Method
yield	O
a	O
large	O
improvement	O
in	O
classification	B-Metric
accuracy	I-Metric
compared	O
to	O
features	O
obtained	O
with	O
previous	O
unsupervised	B-Method
methods	I-Method
.	O
	
These	O
results	O
strongly	O
indicate	O
that	O
a	O
discriminative	B-Method
objective	I-Method
is	O
superior	O
to	O
objectives	O
previously	O
used	O
for	O
unsupervised	B-Method
feature	I-Method
learning	I-Method
.	O
	
One	O
potential	O
shortcoming	O
of	O
the	O
proposed	O
method	O
is	O
that	O
in	O
its	O
current	O
state	O
it	O
does	O
not	O
scale	O
to	O
arbitrarily	O
large	O
datasets	O
.	O
	
Two	O
probable	O
reasons	O
for	O
this	O
are	O
that	O
(	O
1	O
)	O
as	O
the	O
number	O
of	O
surrogate	O
classes	O
grows	O
larger	O
,	O
many	O
of	O
them	O
become	O
similar	O
,	O
which	O
contradicts	O
the	O
discriminative	B-Metric
objective	I-Metric
,	O
and	O
(	O
2	O
)	O
the	O
surrogate	B-Task
task	I-Task
we	O
use	O
is	O
relatively	O
simple	O
and	O
does	O
not	O
allow	O
the	O
network	B-Method
to	O
learn	O
invariance	O
to	O
complex	O
variations	O
,	O
such	O
as	O
3D	O
viewpoint	O
changes	O
or	O
inter	O
-	O
instance	O
variation	O
.	O
	
We	O
hypothesize	O
that	O
the	O
presented	O
approach	O
could	O
learn	O
more	O
powerful	O
higher	O
-	O
level	O
features	O
,	O
if	O
the	O
surrogate	O
data	O
were	O
more	O
diverse	O
.	O
	
This	O
could	O
be	O
achieved	O
by	O
using	O
additional	O
weak	O
supervision	O
,	O
for	O
example	O
,	O
by	O
means	O
of	O
video	O
or	O
a	O
small	O
number	O
of	O
labeled	O
samples	O
.	O
	
Another	O
possible	O
way	O
of	O
obtaining	O
richer	O
surrogate	O
training	O
data	O
and	O
at	O
the	O
same	O
time	O
avoiding	O
similar	O
surrogate	O
classes	O
would	O
be	O
(	O
unsupervised	O
)	O
merging	O
of	O
similar	O
surrogate	O
classes	O
.	O
	
We	O
see	O
these	O
as	O
interesting	O
directions	O
for	O
future	O
work	O
.	O
	
Acknowledgements	O
We	O
acknowledge	O
funding	O
by	O
the	O
ERC	O
Starting	O
Grant	O
VideoLearn	O
(	O
279401	O
)	O
;	O
the	O
work	O
was	O
also	O
partly	O
supported	O
by	O
the	O
BrainLinks	O
-	O
BrainTools	O
Cluster	O
of	O
Excellence	O
funded	O
by	O
the	O
German	O
Research	O
Foundation	O
(	O
DFG	O
,	O
grant	O
number	O
EXC	O
1086	O
)	O
.	O
	
document	O
:	O
CoupleNet	B-Method
:	O
Coupling	O
Global	O
Structure	O
with	O
Local	O
Parts	O
for	O
Object	B-Task
Detection	I-Task
	
The	O
region	O
-	O
based	O
Convolutional	B-Method
Neural	I-Method
Network	I-Method
(	O
CNN	B-Method
)	O
detectors	O
such	O
as	O
Faster	O
R	O
-	O
CNN	B-Method
or	O
R	B-Method
-	I-Method
FCN	I-Method
have	O
already	O
shown	O
promising	O
results	O
for	O
object	B-Task
detection	I-Task
by	O
combining	O
the	O
region	B-Method
proposal	I-Method
subnetwork	I-Method
and	O
the	O
classification	B-Method
subnetwork	I-Method
together	O
.	O
	
Although	O
R	B-Method
-	I-Method
FCN	I-Method
has	O
achieved	O
higher	O
detection	B-Metric
speed	I-Metric
while	O
keeping	O
the	O
detection	B-Task
performance	O
,	O
the	O
global	O
structure	O
information	O
is	O
ignored	O
by	O
the	O
position	O
-	O
sensitive	O
score	O
maps	O
.	O
	
To	O
fully	O
explore	O
the	O
local	O
and	O
global	O
properties	O
,	O
in	O
this	O
paper	O
,	O
we	O
propose	O
a	O
novel	O
fully	B-Method
convolutional	I-Method
network	I-Method
,	O
named	O
as	O
CoupleNet	B-Method
,	O
to	O
couple	O
the	O
global	O
structure	O
with	O
local	O
parts	O
for	O
object	B-Task
detection	I-Task
.	O
	
Specifically	O
,	O
the	O
object	O
proposals	O
obtained	O
by	O
the	O
Region	B-Method
Proposal	I-Method
Network	I-Method
(	O
RPN	B-Method
)	O
are	O
fed	O
into	O
the	O
the	O
coupling	B-Method
module	I-Method
which	O
consists	O
of	O
two	O
branches	O
.	O
	
One	O
branch	O
adopts	O
the	O
position	B-Method
-	I-Method
sensitive	I-Method
RoI	I-Method
(	I-Method
PSRoI	I-Method
)	I-Method
pooling	I-Method
to	O
capture	O
the	O
local	O
part	O
information	O
of	O
the	O
object	O
,	O
while	O
the	O
other	O
employs	O
the	O
RoI	B-Method
pooling	I-Method
to	O
encode	O
the	O
global	O
and	O
context	O
information	O
.	O
	
Next	O
,	O
we	O
design	O
different	O
coupling	B-Method
strategies	I-Method
and	O
normalization	O
ways	O
to	O
make	O
full	O
use	O
of	O
the	O
complementary	O
advantages	O
between	O
the	O
global	O
and	O
local	O
branches	O
.	O
	
Extensive	O
experiments	O
demonstrate	O
the	O
effectiveness	O
of	O
our	O
approach	O
.	O
	
We	O
achieve	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
results	O
on	O
all	O
three	O
challenging	O
datasets	O
,	O
a	O
mAP	B-Metric
of	O
on	O
VOC07	B-Material
,	O
on	O
VOC12	B-Material
,	O
and	O
on	O
COCO	B-Material
.	O
	
Codes	O
will	O
be	O
made	O
publicly	O
available	O
.	O
	
section	O
:	O
Introduction	O
	
General	O
object	B-Task
detection	I-Task
requires	O
to	O
accurately	O
locate	O
and	O
classify	O
all	O
targets	O
in	O
the	O
image	O
or	O
video	O
.	O
	
Compared	O
to	O
specific	O
object	B-Task
detection	I-Task
,	O
such	O
as	O
face	B-Task
,	I-Task
pedestrian	I-Task
and	I-Task
vehicle	I-Task
detection	I-Task
,	O
general	O
object	B-Task
detection	I-Task
often	O
faces	O
more	O
challenges	O
due	O
to	O
the	O
large	O
inter	O
-	O
class	O
appearance	O
differences	O
.	O
	
The	O
variations	O
arise	O
not	O
only	O
from	O
changes	O
in	O
a	O
variety	O
of	O
non	O
-	O
rigid	O
deformations	O
,	O
but	O
also	O
due	O
to	O
the	O
truncations	O
,	O
occlusions	O
and	O
inter	O
-	O
class	O
interference	O
.	O
	
However	O
,	O
no	O
matter	O
how	O
complicated	O
the	O
objects	O
are	O
,	O
when	O
humans	O
identify	O
a	O
target	O
,	O
the	O
recognition	B-Task
of	I-Task
object	I-Task
categories	I-Task
is	O
subserved	O
by	O
both	O
a	O
global	B-Method
process	I-Method
that	O
retrieves	O
structural	O
information	O
and	O
a	O
local	B-Method
process	I-Method
that	O
is	O
sensitive	O
to	O
individual	O
parts	O
.	O
	
This	O
motivates	O
us	O
to	O
build	O
a	O
detection	B-Method
model	I-Method
that	O
fused	O
both	O
global	O
and	O
local	O
information	O
.	O
	
With	O
the	O
revival	O
of	O
Convolutional	B-Method
Neural	I-Method
Networks	I-Method
(	O
CNN	B-Method
)	O
,	O
CNN	B-Method
-	O
based	O
object	B-Task
detection	I-Task
pipelines	O
have	O
been	O
proposed	O
consecutively	O
and	O
made	O
impressive	O
improvements	O
in	O
generic	O
benchmarks	O
,	O
PASCAL	B-Material
VOC	I-Material
and	O
MS	B-Material
COCO	I-Material
.	O
	
As	O
two	O
representative	O
region	O
-	O
based	O
CNN	B-Method
approaches	O
,	O
Fast	O
/	O
Faster	O
R	O
-	O
CNN	B-Method
uses	O
a	O
certain	O
subnetwork	O
to	O
predict	O
the	O
category	O
of	O
each	O
region	O
proposal	O
while	O
R	B-Method
-	I-Method
FCN	I-Method
conducts	O
the	O
inference	B-Task
with	O
the	O
position	O
-	O
sensitive	O
score	O
maps	O
.	O
	
Through	O
removing	O
the	O
RoI	B-Method
-	I-Method
wise	I-Method
subnetwork	I-Method
,	O
R	B-Method
-	I-Method
FCN	I-Method
has	O
achieved	O
higher	O
detection	B-Metric
speed	I-Metric
while	O
keeping	O
the	O
detection	B-Task
performance	O
.	O
	
However	O
,	O
the	O
global	O
structure	O
information	O
is	O
ignored	O
by	O
the	O
PSRoI	B-Method
pooling	I-Method
.	O
	
As	O
shown	O
in	O
Figure	O
[	O
reference	O
]	O
,	O
using	O
PSRoI	B-Method
pooling	I-Method
to	O
extract	O
local	O
part	O
information	O
for	O
final	O
object	B-Task
category	I-Task
prediction	I-Task
,	O
R	B-Method
-	I-Method
FCN	I-Method
leads	O
to	O
a	O
low	B-Metric
confidence	I-Metric
score	I-Metric
of	O
0.08	O
for	O
the	O
sofa	B-Task
detection	I-Task
since	O
the	O
local	O
responses	O
of	O
sofa	O
are	O
disturbed	O
by	O
a	O
women	O
and	O
a	O
dog	O
(	O
they	O
are	O
also	O
the	O
categories	O
that	O
need	O
to	O
be	O
detected	O
)	O
.	O
	
Conversely	O
,	O
the	O
global	O
structure	O
of	O
sofa	O
could	O
be	O
extracted	O
by	O
the	O
RoI	B-Method
pooling	I-Method
,	O
but	O
the	O
confidence	B-Metric
score	I-Metric
is	O
0.45	O
,	O
which	O
is	O
also	O
very	O
low	O
for	O
the	O
incomplete	O
structure	O
of	O
sofa	O
.	O
	
By	O
coupling	O
the	O
global	O
confidence	O
with	O
the	O
local	O
part	O
confidence	O
together	O
,	O
we	O
can	O
obtain	O
a	O
more	O
reliable	O
prediction	O
with	O
the	O
confidence	B-Metric
score	I-Metric
of	O
0.78	O
.	O
	
In	O
fact	O
,	O
the	O
idea	O
of	O
fusing	O
global	O
and	O
local	O
information	O
together	O
is	O
widely	O
used	O
in	O
lots	O
of	O
visual	B-Task
tasks	I-Task
.	O
	
In	O
fingerprint	B-Task
recognition	I-Task
,	O
Gu	O
combined	O
the	O
global	O
orientation	O
field	O
and	O
local	O
minutiae	O
cue	O
to	O
largely	O
improve	O
the	O
performance	O
.	O
	
In	O
clique	B-Task
-	I-Task
graph	I-Task
matching	I-Task
,	O
Nie	O
proposed	O
a	O
clique	B-Method
-	I-Method
graph	I-Method
matching	I-Method
method	I-Method
by	O
preserving	O
global	O
clique	O
-	O
to	O
-	O
clique	O
correspondence	O
and	O
local	O
unary	O
and	O
pairwise	O
correspondences	O
.	O
	
In	O
scene	B-Task
parsing	I-Task
,	O
Zhao	O
designed	O
a	O
pyramid	B-Method
pooling	I-Method
module	I-Method
to	O
effectively	O
extract	O
hierarchical	O
global	O
contextual	O
prior	O
,	O
and	O
then	O
concatenated	O
it	O
with	O
the	O
local	O
FCN	O
feature	O
to	O
improve	O
the	O
performance	O
.	O
	
In	O
traditional	O
object	B-Task
detection	I-Task
,	O
Felzenszwalb	O
incorporated	O
a	O
global	B-Method
root	I-Method
model	I-Method
and	O
several	O
finer	B-Method
local	I-Method
part	I-Method
models	I-Method
to	O
represent	O
highly	O
variable	O
objects	O
.	O
	
All	O
of	O
which	O
show	O
that	O
effective	O
combination	O
of	O
the	O
global	O
structural	O
properties	O
and	O
local	O
fine	O
-	O
grained	O
details	O
can	O
achieve	O
complementary	O
advantages	O
.	O
	
Therefore	O
,	O
to	O
fully	O
explore	O
the	O
global	O
and	O
local	O
clues	O
,	O
in	O
this	O
paper	O
,	O
we	O
propose	O
a	O
novel	O
full	B-Method
convolutional	I-Method
network	I-Method
named	O
as	O
CoupleNet	B-Method
,	O
to	O
couple	O
the	O
global	O
structure	O
and	O
local	O
parts	O
to	O
boost	O
the	O
detection	B-Metric
accuracy	I-Metric
.	O
	
Specifically	O
,	O
the	O
object	O
proposals	O
obtained	O
by	O
the	O
RPN	B-Method
are	O
fed	O
into	O
the	O
coupling	B-Method
module	I-Method
which	O
consists	O
of	O
two	O
branches	O
.	O
	
One	O
branch	O
adopts	O
the	O
PSRoI	B-Method
pooling	I-Method
to	O
capture	O
the	O
local	O
part	O
information	O
of	O
the	O
object	O
,	O
while	O
the	O
other	O
employs	O
the	O
RoI	B-Method
pooling	I-Method
to	O
encode	O
the	O
global	O
and	O
context	O
information	O
.	O
	
Moreover	O
,	O
we	O
design	O
different	O
coupling	B-Method
strategies	I-Method
and	O
normalization	O
ways	O
to	O
make	O
full	O
use	O
of	O
the	O
complementary	O
advantages	O
between	O
the	O
global	O
and	O
local	O
branches	O
.	O
	
With	O
the	O
coupling	O
structure	O
,	O
our	O
network	O
can	O
jointly	O
learn	O
the	O
local	O
,	O
global	O
and	O
context	O
expression	O
of	O
the	O
objects	O
,	O
which	O
makes	O
the	O
model	O
have	O
a	O
more	O
powerful	O
representation	B-Metric
capacity	I-Metric
and	O
generalization	B-Metric
ability	I-Metric
.	O
	
Extensive	O
experiments	O
demonstrate	O
that	O
CoupleNet	B-Method
can	O
significantly	O
improve	O
the	O
detection	B-Task
performance	O
.	O
	
Our	O
detector	O
shows	O
competitive	O
results	O
on	O
PASCAL	B-Material
VOC	I-Material
07	I-Material
/	O
12	B-Material
and	O
MS	B-Material
COCO	I-Material
compared	O
to	O
other	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
detectors	O
,	O
even	O
with	O
model	B-Method
ensemble	I-Method
approaches	I-Method
.	O
	
In	O
summary	O
,	O
our	O
main	O
contributions	O
are	O
as	O
follows	O
:	O
	
1	O
.	O
	
We	O
propose	O
a	O
unified	B-Method
fully	I-Method
convolutional	I-Method
network	I-Method
to	O
jointly	O
learn	O
the	O
local	O
,	O
global	O
and	O
context	O
information	O
for	O
object	B-Task
detection	I-Task
.	O
	
2	O
.	O
	
We	O
design	O
different	O
normalization	B-Method
methods	I-Method
and	O
coupling	B-Method
strategies	I-Method
to	O
mine	O
the	O
compatibility	O
and	O
complementarity	O
between	O
the	O
global	O
and	O
local	O
branches	O
.	O
	
3	O
.	O
	
We	O
achieve	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
results	O
on	O
all	O
three	O
challenging	O
datasets	O
,	O
a	O
mAP	B-Metric
of	O
on	O
VOC07	B-Material
,	O
on	O
VOC12	B-Material
,	O
and	O
on	O
MS	B-Material
COCO	I-Material
.	O
	
section	O
:	O
Related	O
work	O
	
Before	O
the	O
arrival	O
of	O
CNN	B-Method
,	O
visual	B-Task
tasks	I-Task
have	O
been	O
dominated	O
by	O
traditional	O
paradigms	O
.	O
	
As	O
one	O
of	O
an	O
outstanding	O
framework	O
,	O
DPM	B-Method
described	O
the	O
object	B-Method
system	I-Method
using	O
mixtures	B-Method
of	I-Method
multi	I-Method
-	I-Method
scale	I-Method
deformable	I-Method
part	I-Method
models	I-Method
,	O
including	O
a	O
coarse	B-Method
global	I-Method
root	I-Method
model	I-Method
and	O
several	O
finer	B-Method
local	I-Method
part	I-Method
models	I-Method
.	O
	
The	O
root	B-Method
model	I-Method
extracts	O
structural	O
information	O
of	O
the	O
objects	O
,	O
while	O
the	O
part	B-Method
models	I-Method
capture	O
local	O
appearance	O
properties	O
of	O
an	O
object	O
.	O
	
The	O
sum	O
of	O
root	O
response	O
and	O
weighted	O
average	O
response	O
of	O
each	O
part	O
is	O
used	O
as	O
the	O
final	O
confidence	O
of	O
an	O
object	O
.	O
	
Although	O
DPM	B-Method
provides	O
an	O
elegant	O
framework	O
for	O
object	B-Task
detection	I-Task
,	O
the	O
hand	O
-	O
crafted	O
features	O
,	O
improved	O
HOG	B-Method
,	O
are	O
not	O
discriminative	O
enough	O
to	O
express	O
the	O
diversity	O
of	O
object	O
categories	O
.	O
	
This	O
is	O
also	O
the	O
main	O
reason	O
that	O
CNN	B-Method
completely	O
surpassed	O
the	O
traditional	O
methods	O
in	O
a	O
short	O
period	O
time	O
.	O
	
In	O
order	O
to	O
leverage	O
the	O
great	O
success	O
of	O
deep	B-Method
neural	I-Method
networks	I-Method
for	O
image	B-Task
classification	I-Task
,	O
considerable	O
object	B-Task
detection	I-Task
methods	O
based	O
on	O
deep	B-Method
learning	I-Method
have	O
been	O
proposed	O
.	O
	
Although	O
there	O
are	O
end	O
-	O
to	O
-	O
end	B-Method
detection	I-Method
frameworks	I-Method
,	O
like	O
SSD	B-Method
,	O
YOLO	B-Method
and	O
DenseBox	B-Method
,	O
region	B-Method
-	I-Method
based	I-Method
systems	I-Method
(	O
Fast	O
/	O
Faster	O
R	O
-	O
CNN	B-Method
and	O
R	B-Method
-	I-Method
FCN	I-Method
)	O
still	O
dominate	O
the	O
detection	B-Metric
accuracy	I-Metric
on	O
generic	O
benchmarks	O
.	O
	
Compared	O
to	O
the	O
end	B-Method
-	I-Method
to	I-Method
-	I-Method
end	I-Method
framework	I-Method
,	O
the	O
region	B-Method
-	I-Method
based	I-Method
systems	I-Method
have	O
several	O
advantages	O
.	O
	
Firstly	O
,	O
by	O
exploiting	O
a	O
divide	B-Method
-	I-Method
and	I-Method
-	I-Method
conquer	I-Method
strategy	I-Method
,	O
the	O
two	O
-	O
step	B-Method
framework	I-Method
is	O
more	O
stable	O
and	O
easier	O
to	O
converge	O
.	O
	
Secondly	O
,	O
without	O
the	O
complicated	O
data	B-Method
augmentation	I-Method
and	O
training	O
skills	O
,	O
you	O
can	O
still	O
easily	O
achieve	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
performance	O
.	O
	
The	O
main	O
reason	O
for	O
these	O
advantages	O
is	O
that	O
there	O
is	O
a	O
certain	O
structure	O
to	O
encode	O
translation	O
variance	O
features	O
for	O
each	O
proposal	O
,	O
since	O
in	O
deep	B-Method
networks	I-Method
,	O
higher	O
-	O
layers	O
contain	O
more	O
semantic	O
meaning	O
and	O
less	O
location	O
information	O
.	O
	
As	O
a	O
consequence	O
,	O
a	O
RoI	B-Method
-	I-Method
wise	I-Method
subnetwork	I-Method
or	O
a	O
position	B-Method
-	I-Method
sensitive	I-Method
RoI	I-Method
pooling	I-Method
layer	I-Method
is	O
used	O
to	O
achieve	O
the	O
translation	O
variance	O
in	O
region	B-Method
-	I-Method
based	I-Method
systems	I-Method
.	O
	
However	O
,	O
all	O
the	O
existing	O
region	B-Method
-	I-Method
based	I-Method
systems	I-Method
utilize	O
either	O
the	O
region	O
-	O
level	O
or	O
part	O
-	O
level	O
features	O
to	O
learn	O
the	O
variations	O
,	O
where	O
each	O
one	O
alone	O
is	O
not	O
representative	O
enough	O
for	O
a	O
variety	O
of	O
challenging	O
situations	O
.	O
	
Therefore	O
,	O
this	O
motivates	O
us	O
to	O
design	O
a	O
certain	O
structure	O
to	O
take	O
advantages	O
of	O
both	O
the	O
global	O
and	O
local	O
features	O
.	O
	
In	O
addition	O
,	O
context	O
is	O
known	O
to	O
play	O
an	O
important	O
role	O
in	O
visual	B-Task
recognition	I-Task
.	O
	
Considerable	O
works	O
have	O
been	O
proposed	O
for	O
exploting	B-Task
context	I-Task
in	O
object	B-Task
detection	I-Task
.	O
	
Bell	O
explored	O
the	O
use	O
of	O
recurrent	B-Method
neural	I-Method
networks	I-Method
to	O
model	O
the	O
contextual	O
information	O
.	O
	
Gidaris	B-Method
proposed	O
to	O
utilize	O
multiple	O
contextual	O
regions	O
around	O
the	O
object	O
.	O
	
Cai	O
collected	O
the	O
context	O
by	O
padding	O
the	O
proposals	O
for	O
pedestrian	B-Task
and	I-Task
car	I-Task
detection	I-Task
.	O
	
Similar	O
to	O
these	O
works	O
,	O
we	O
also	O
absorb	O
the	O
context	O
prior	O
to	O
enhance	O
the	O
global	B-Method
feature	I-Method
representation	I-Method
.	O
	
section	O
:	O
CoupleNet	B-Method
	
In	O
this	O
section	O
,	O
we	O
first	O
introduce	O
the	O
architecture	O
of	O
the	O
proposed	O
CoupleNet	B-Method
for	O
object	B-Task
detection	I-Task
.	O
	
Then	O
we	O
explain	O
in	O
detail	O
how	O
we	O
incorporate	O
local	B-Method
representations	I-Method
,	O
global	O
appearance	O
and	O
contextual	O
information	O
for	O
robust	O
object	B-Task
detection	I-Task
.	O
	
subsection	O
:	O
Network	B-Method
architecture	I-Method
	
The	O
architecture	O
of	O
our	O
proposed	O
CoupleNet	B-Method
is	O
illustrated	O
in	O
Figure	O
[	O
reference	O
]	O
.	O
	
Our	O
CoupleNet	B-Method
includes	O
two	O
different	O
branches	O
:	O
a	O
)	O
a	O
local	B-Method
part	I-Method
-	I-Method
sensitive	I-Method
fully	I-Method
convolutional	I-Method
network	I-Method
to	O
learn	O
the	O
object	O
-	O
specific	O
parts	O
,	O
denoted	O
as	O
local	B-Method
FCN	I-Method
;	O
b	O
)	O
a	O
global	B-Method
region	I-Method
-	I-Method
sensitive	I-Method
fully	I-Method
convolutional	I-Method
network	I-Method
to	O
encode	O
the	O
whole	O
appearance	O
structure	O
and	O
context	O
prior	O
of	O
the	O
object	O
,	O
denoted	O
as	O
global	B-Method
FCN	I-Method
.	O
	
We	O
first	O
use	O
the	O
ImageNet	B-Material
pre	O
-	O
trained	O
ResNet	B-Method
-	I-Method
101	I-Method
released	O
in	O
to	O
initialize	O
our	O
network	O
.	O
	
For	O
our	O
detection	B-Task
task	I-Task
,	O
we	O
remove	O
the	O
last	B-Method
average	I-Method
pooling	I-Method
layer	I-Method
and	O
the	O
fc	B-Method
layer	I-Method
.	O
	
Given	O
an	O
input	O
image	O
,	O
we	O
extract	O
candidate	O
proposals	O
by	O
using	O
the	O
Region	B-Method
Proposal	I-Method
Network	I-Method
(	O
RPN	B-Method
)	I-Method
,	O
which	O
also	O
shares	O
convolution	O
features	O
with	O
CoupleNet	B-Method
following	O
.	O
	
Then	O
each	O
proposal	O
flows	O
to	O
two	O
different	O
branches	O
:	O
the	O
local	B-Method
FCN	I-Method
and	O
the	O
global	B-Method
FCN	I-Method
.	O
	
Finally	O
,	O
the	O
output	O
of	O
global	B-Method
and	I-Method
local	I-Method
FCN	I-Method
are	O
coupled	O
together	O
as	O
the	O
final	O
score	O
of	O
the	O
object	O
.	O
	
We	O
also	O
perform	O
class	B-Method
-	I-Method
agnostic	I-Method
bounding	I-Method
box	I-Method
regression	I-Method
in	O
a	O
similar	O
way	O
.	O
	
subsection	O
:	O
Local	B-Method
FCN	I-Method
	
To	O
effectively	O
capture	O
the	O
specific	O
fine	O
-	O
grained	O
parts	O
in	O
local	B-Method
FCN	I-Method
,	O
we	O
construct	O
a	O
set	O
of	O
part	B-Method
-	I-Method
sensitive	I-Method
score	I-Method
maps	I-Method
by	O
appending	O
a	O
1x1	O
convolutional	B-Method
layer	I-Method
with	O
channels	O
,	O
where	O
means	O
we	O
divide	O
the	O
object	O
into	O
local	O
parts	O
(	O
here	O
is	O
set	O
to	O
the	O
default	O
value	O
7	O
)	O
and	O
is	O
the	O
number	O
of	O
object	O
categories	O
plus	O
background	O
.	O
	
For	O
each	O
category	O
,	O
there	O
are	O
totally	O
channels	O
and	O
each	O
channel	O
is	O
responsible	O
for	O
encoding	O
a	O
specific	O
part	O
of	O
the	O
object	O
.	O
	
The	O
final	O
score	O
of	O
a	O
category	O
is	O
determined	O
by	O
voting	O
the	O
responses	O
.	O
	
Here	O
we	O
use	O
position	B-Method
-	I-Method
sensitive	I-Method
RoI	I-Method
pooling	I-Method
layer	I-Method
in	O
to	O
extract	O
object	O
-	O
specific	O
parts	O
and	O
we	O
simply	O
perform	O
average	B-Method
pooling	I-Method
for	O
voting	B-Task
.	O
	
Then	O
,	O
we	O
obtain	O
a	O
-	O
d	O
vector	O
which	O
indicates	O
the	O
probability	O
that	O
the	O
object	O
belongs	O
to	O
each	O
class	O
.	O
	
This	O
procedure	O
is	O
equivalent	O
to	O
dividing	O
a	O
strong	O
object	O
category	O
decision	O
into	O
the	O
sum	O
of	O
multiple	O
weak	B-Method
classifiers	I-Method
,	O
which	O
serves	O
as	O
the	O
ensemble	O
of	O
several	O
part	B-Method
models	I-Method
.	O
	
Here	O
we	O
refer	O
this	O
part	O
ensemble	O
as	O
local	B-Method
structure	I-Method
representation	I-Method
.	O
	
As	O
shown	O
in	O
Figure	O
[	O
reference	O
]	O
(	O
a	O
)	O
,	O
for	O
the	O
truncated	O
person	O
,	O
one	O
can	O
hardly	O
get	O
a	O
strong	O
response	O
from	O
the	O
global	O
description	O
of	O
the	O
person	O
due	O
to	O
truncation	O
,	O
on	O
the	O
contrary	O
,	O
our	O
local	B-Method
FCN	I-Method
can	O
effectively	O
capture	O
several	O
specific	O
parts	O
,	O
such	O
as	O
human	O
nose	O
,	O
mouth	O
,	O
,	O
which	O
correspond	O
to	O
the	O
regions	O
with	O
large	O
responses	O
in	O
the	O
feature	O
map	O
.	O
	
We	O
argue	O
that	O
the	O
local	B-Method
FCN	I-Method
is	O
much	O
concerned	O
with	O
the	O
internal	O
structure	O
and	O
components	O
,	O
which	O
can	O
effectively	O
reflect	O
the	O
local	O
properties	O
of	O
visual	O
object	O
,	O
especially	O
when	O
the	O
object	O
is	O
occluded	O
or	O
the	O
whole	O
boundary	O
is	O
incomplete	O
.	O
	
However	O
,	O
for	O
those	O
having	O
simple	O
spatial	O
structure	O
and	O
encompassing	O
considerable	O
background	O
in	O
the	O
bounding	O
box	O
,	O
dining	O
table	O
,	O
the	O
local	B-Method
FCN	I-Method
alone	O
is	O
difficult	O
to	O
make	O
robust	O
predictions	O
.	O
	
Thus	O
it	O
is	O
necessary	O
to	O
add	O
the	O
global	O
structure	O
information	O
to	O
enhance	O
the	O
discrimination	B-Task
.	O
	
subsection	O
:	O
Global	B-Method
FCN	I-Method
	
For	O
the	O
global	B-Method
FCN	I-Method
,	O
we	O
aim	O
to	O
describe	O
the	O
object	O
by	O
using	O
the	O
whole	O
region	O
-	O
level	O
features	O
.	O
	
Firstly	O
,	O
we	O
attach	O
a	O
1024	B-Method
-	I-Method
d	I-Method
1x1	I-Method
convolutional	I-Method
layer	I-Method
after	O
the	O
last	O
convolutional	O
block	O
in	O
ResNet	B-Method
-	I-Method
101	I-Method
for	O
reducing	O
the	O
dimension	O
.	O
	
Due	O
to	O
the	O
diverse	O
size	O
of	O
the	O
object	O
,	O
we	O
insert	O
a	O
RoI	B-Method
pooling	I-Method
layer	I-Method
in	O
to	O
extract	O
a	O
fixed	O
-	O
length	O
feature	O
vector	O
as	O
the	O
global	O
structure	O
description	O
of	O
the	O
object	O
.	O
	
Secondly	O
,	O
we	O
use	O
two	O
convolutional	B-Method
layers	I-Method
with	O
kernal	O
size	O
and	O
respectively	O
(	O
is	O
set	O
to	O
the	O
default	O
value	O
7	O
)	O
to	O
further	O
abstract	O
the	O
global	B-Method
representation	I-Method
of	I-Method
RoI.	I-Method
	
Finally	O
,	O
the	O
output	O
of	O
1x1	B-Method
convolution	I-Method
is	O
fed	O
into	O
the	O
classifier	B-Method
whose	O
output	O
is	O
also	O
a	O
-	O
d	O
vector	O
.	O
	
In	O
addition	O
,	O
context	O
prior	O
is	O
the	O
most	O
basic	O
and	O
important	O
factor	O
for	O
visual	B-Task
recognition	I-Task
tasks	I-Task
.	O
	
For	O
example	O
,	O
the	O
boat	O
usually	O
travels	O
in	O
the	O
water	O
while	O
is	O
unlikely	O
to	O
fly	O
in	O
the	O
sky	O
.	O
	
Despite	O
the	O
higher	O
layers	O
in	O
deep	B-Method
neural	I-Method
network	I-Method
can	O
involve	O
the	O
spatial	O
context	O
information	O
around	O
the	O
objects	O
due	O
to	O
the	O
large	O
receptive	O
field	O
,	O
Zhou	O
have	O
shown	O
that	O
the	O
practical	O
receptive	O
field	O
is	O
actually	O
much	O
smaller	O
than	O
the	O
theoretical	O
one	O
.	O
	
Therefore	O
,	O
it	O
is	O
necessary	O
to	O
explicitly	O
collect	O
the	O
surrounding	O
information	O
to	O
reduce	O
the	O
chance	O
of	O
misclassification	B-Task
.	O
	
To	O
enhance	O
the	O
feature	B-Task
representation	I-Task
ability	O
of	O
the	O
global	B-Method
FCN	I-Method
,	O
here	O
we	O
introduce	O
the	O
contextual	O
information	O
as	O
an	O
effective	O
supplement	O
.	O
	
Specifically	O
,	O
we	O
extend	O
the	O
context	O
region	O
by	O
2	O
times	O
larger	O
than	O
the	O
size	O
of	O
original	O
proposal	O
.	O
	
Then	O
the	O
features	O
RoI	O
pooled	O
from	O
the	O
original	O
region	O
and	O
context	O
region	O
are	O
concatenated	O
together	O
and	O
fed	O
into	O
the	O
latter	O
RoI	B-Method
-	I-Method
wise	I-Method
subnetwork	I-Method
.	O
	
As	O
shown	O
in	O
Figure	O
[	O
reference	O
]	O
,	O
the	O
context	O
region	O
is	O
embedded	O
into	O
the	O
global	O
branch	O
to	O
extract	O
a	O
more	O
complete	O
appearance	O
structure	O
and	O
discriminative	B-Method
prior	I-Method
representation	I-Method
,	O
which	O
will	O
help	O
the	O
classifier	B-Method
to	O
better	O
identity	O
the	O
object	O
categories	O
.	O
	
Due	O
to	O
the	O
RoI	B-Method
pooling	I-Method
operation	I-Method
,	O
the	O
global	B-Method
FCN	I-Method
describes	O
the	O
proposal	O
as	O
a	O
whole	O
with	O
CNN	B-Method
features	O
,	O
which	O
can	O
be	O
seen	O
as	O
a	O
global	O
structure	O
description	O
of	O
the	O
object	O
.	O
	
Therefore	O
,	O
it	O
can	O
easily	O
deal	O
with	O
the	O
objects	O
with	O
intact	O
structure	O
and	O
finer	O
scale	O
.	O
	
As	O
shown	O
in	O
Figure	O
[	O
reference	O
]	O
(	O
b	O
)	O
,	O
our	O
global	B-Method
FCN	I-Method
shows	O
a	O
large	O
confidence	O
for	O
the	O
dining	O
table	O
.	O
	
However	O
,	O
in	O
most	O
cases	O
,	O
natural	O
scenes	O
consist	O
of	O
considerable	O
objects	O
with	O
occlusions	O
or	O
truncations	O
,	O
making	O
the	O
detection	B-Task
more	O
difficult	O
.	O
	
Figure	O
[	O
reference	O
]	O
(	O
a	O
)	O
shows	O
that	O
using	O
the	O
global	O
structure	O
information	O
alone	O
can	O
hardly	O
make	O
a	O
confident	O
prediction	O
for	O
the	O
truncated	O
person	O
.	O
	
By	O
adding	O
local	O
part	O
structural	O
supports	O
,	O
the	O
detection	B-Task
performance	O
can	O
be	O
significantly	O
boosted	O
.	O
	
Therefore	O
,	O
it	O
is	O
essential	O
to	O
combine	O
both	O
local	O
and	O
global	O
descriptions	O
for	O
a	O
robust	B-Task
detection	I-Task
.	O
	
subsection	O
:	O
Coupling	O
structure	O
	
To	O
match	O
the	O
same	O
order	O
of	O
magnitude	O
,	O
we	O
apply	O
a	O
normalization	B-Method
operation	I-Method
to	O
the	O
output	O
of	O
local	B-Method
and	I-Method
global	I-Method
FCN	I-Method
before	O
they	O
are	O
combined	O
together	O
.	O
	
We	O
explored	O
two	O
different	O
methods	O
to	O
perform	O
normalization	B-Task
:	O
an	O
L2	B-Method
normalization	I-Method
layer	I-Method
or	O
a	O
1x1	B-Method
convolutional	I-Method
layer	I-Method
to	O
model	O
the	O
scale	O
.	O
	
Meanwhile	O
,	O
how	O
to	O
couple	O
the	O
local	O
and	O
global	O
output	O
is	O
also	O
a	O
problem	O
that	O
needs	O
to	O
be	O
researched	O
.	O
	
Here	O
,	O
we	O
investigated	O
three	O
different	O
coupling	B-Method
methods	I-Method
:	O
element	B-Method
-	I-Method
wise	I-Method
sum	I-Method
,	O
element	B-Method
-	I-Method
wise	I-Method
product	I-Method
and	O
element	B-Method
-	I-Method
wise	I-Method
maximum	I-Method
.	O
	
Our	O
experiments	O
show	O
that	O
using	O
1x1	B-Method
convolution	I-Method
along	O
with	O
element	B-Method
-	I-Method
wise	I-Method
sum	I-Method
achieves	O
the	O
best	O
performance	O
and	O
we	O
will	O
discuss	O
it	O
in	O
Section	O
[	O
reference	O
]	O
.	O
	
With	O
the	O
coupling	O
structure	O
,	O
CoupleNet	B-Method
simultaneously	O
exploits	O
the	O
local	O
parts	O
,	O
global	O
structure	O
and	O
context	O
prior	O
for	O
object	B-Task
detection	I-Task
.	O
	
The	O
whole	O
network	O
is	O
fully	O
convolutional	B-Method
and	O
benefits	O
from	O
approximate	B-Method
joint	I-Method
training	I-Method
and	O
multi	B-Task
-	I-Task
task	I-Task
learning	I-Task
.	O
	
We	O
also	O
note	O
that	O
the	O
global	O
branch	O
can	O
be	O
regarded	O
as	O
a	O
lightweight	O
Faster	O
R	O
-	O
CNN	B-Method
,	O
in	O
which	O
all	O
learnable	O
parameters	O
are	O
from	O
convolutional	B-Method
layers	I-Method
and	O
the	O
depth	O
of	O
RoI	O
-	O
wise	O
subnetwork	O
is	O
only	O
two	O
.	O
	
Therefore	O
,	O
the	O
computational	B-Metric
complexity	I-Metric
is	O
far	O
less	O
than	O
the	O
subnetwork	O
in	O
ResNet	O
-	O
based	O
Faster	O
R	O
-	O
CNN	B-Method
system	O
whose	O
depth	O
is	O
ten	O
.	O
	
As	O
a	O
consequence	O
,	O
our	O
CoupleNet	B-Method
can	O
perform	O
the	O
inference	B-Task
efficiently	O
,	O
which	O
runs	O
slightly	O
slower	O
than	O
R	B-Method
-	I-Method
FCN	I-Method
but	O
much	O
more	O
faster	O
than	O
Faster	O
R	O
-	O
CNN	B-Method
.	O
	
section	O
:	O
Experiments	O
	
We	O
train	O
and	O
evaluate	O
our	O
method	O
on	O
three	O
challenging	O
object	B-Task
detection	I-Task
datasets	O
:	O
PASCAL	O
VOC2007	B-Material
,	O
VOC2012	B-Material
and	O
MS	B-Material
COCO	I-Material
.	O
	
Since	O
all	O
these	O
three	O
datasets	O
contain	O
a	O
variety	O
of	O
circumstances	O
,	O
which	O
can	O
sufficiently	O
verify	O
the	O
effectiveness	O
of	O
our	O
method	O
.	O
	
We	O
demonstrate	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
results	O
on	O
all	O
three	O
datasets	O
without	O
bells	O
and	O
whistles	O
.	O
	
subsection	O
:	O
Ablation	B-Task
studies	I-Task
on	O
VOC2007	B-Material
	
We	O
first	O
perform	O
experiments	O
on	O
PASCAL	B-Material
VOC	I-Material
2007	O
with	O
20	O
object	O
categories	O
for	O
detailed	O
analysis	O
of	O
our	O
proposed	O
CoupleNet	B-Method
detector	O
.	O
	
We	O
train	O
the	O
models	O
on	O
the	O
union	B-Material
set	I-Material
of	I-Material
VOC	I-Material
2007	I-Material
trainval	I-Material
and	O
VOC	B-Material
2012	I-Material
trainval	I-Material
(	O
“	O
07	O
+	O
12	B-Material
”	O
)	O
following	O
,	O
and	O
evaluate	O
on	O
VOC	B-Material
2007	I-Material
test	I-Material
set	I-Material
.	O
	
Object	B-Metric
detection	I-Metric
accuracy	I-Metric
is	O
measured	O
by	O
mean	B-Metric
Average	I-Metric
Precision	I-Metric
(	O
mAP	B-Metric
)	O
,	O
all	O
the	O
ablation	O
experiments	O
use	O
single	O
-	O
scale	O
training	O
and	O
testing	O
,	O
and	O
we	O
did	O
not	O
add	O
the	O
context	O
prior	O
.	O
	
Normalization	B-Task
.	O
	
Since	O
features	O
extracted	O
form	O
different	O
layers	O
of	O
CNN	B-Method
show	O
various	O
of	O
scales	O
,	O
it	O
is	O
essential	O
to	O
normalize	O
different	O
features	O
before	O
coupling	O
them	O
together	O
.	O
	
Bell	O
proposed	O
to	O
use	O
L2	B-Method
normalization	I-Method
to	O
each	O
RoI	O
-	O
pooled	O
feature	O
and	O
re	O
-	O
scale	O
back	O
up	O
by	O
a	O
empirical	O
scale	O
,	O
which	O
shows	O
a	O
great	O
gain	O
on	O
VOC	B-Material
dataset	I-Material
.	O
	
In	O
this	O
paper	O
,	O
we	O
also	O
explore	O
two	O
different	O
normalization	B-Method
ways	I-Method
to	O
normalize	O
the	O
output	O
of	O
local	B-Method
and	I-Method
global	I-Method
FCN	I-Method
:	O
an	O
L2	B-Method
normalization	I-Method
layer	I-Method
or	O
a	O
1x1	B-Method
convolutional	I-Method
layer	I-Method
to	O
learn	O
the	O
scale	O
.	O
	
As	O
shown	O
in	O
Table	O
[	O
reference	O
]	O
,	O
we	O
find	O
that	O
the	O
use	O
of	O
L2	B-Method
normalization	I-Method
decreases	O
the	O
performance	O
greatly	O
,	O
even	O
worse	O
than	O
the	O
direct	B-Method
addition	I-Method
(	O
without	O
any	O
normalization	O
ways	O
)	O
.	O
	
To	O
explain	O
such	O
a	O
phenomenon	O
,	O
we	O
measured	O
the	O
outputs	O
of	O
two	O
branches	O
before	O
and	O
after	O
L2	B-Method
normalization	I-Method
.	O
	
We	O
further	O
found	O
that	O
L2	B-Method
normalization	I-Method
reduces	O
the	O
output	O
gap	O
between	O
different	O
categories	O
,	O
which	O
results	O
in	O
a	O
smaller	O
score	B-Metric
gap	I-Metric
.	O
	
As	O
we	O
know	O
,	O
a	O
small	O
score	O
gap	O
between	O
different	O
categories	O
always	O
means	O
the	O
classifier	B-Method
can	O
not	O
make	O
a	O
confident	O
prediction	O
.	O
	
Therefore	O
,	O
we	O
assume	O
that	O
this	O
is	O
the	O
reason	O
for	O
the	O
performance	O
degradation	O
.	O
	
Moreover	O
,	O
we	O
also	O
exploit	O
a	O
1x1	B-Method
convolution	I-Method
to	O
adaptively	O
learn	O
the	O
scales	O
between	O
the	O
global	O
and	O
local	O
branches	O
.	O
	
Table	O
[	O
reference	O
]	O
shows	O
that	O
using	O
1x1	B-Method
convolution	I-Method
increases	O
by	O
points	O
compared	O
to	O
the	O
direct	B-Method
addition	I-Method
and	O
points	O
over	O
R	B-Method
-	I-Method
FCN	I-Method
.	O
	
Therefore	O
,	O
we	O
use	O
1x1	B-Method
convolution	I-Method
to	O
replace	O
the	O
L2	B-Method
normalization	I-Method
in	O
the	O
following	O
experiments	O
.	O
	
Coupling	B-Method
strategy	I-Method
.	O
	
We	O
explore	O
three	O
different	O
response	B-Method
coupling	I-Method
strategies	I-Method
:	O
element	B-Method
-	I-Method
wise	I-Method
sum	I-Method
,	O
element	B-Method
-	I-Method
wise	I-Method
product	I-Method
and	O
element	B-Method
-	I-Method
wise	I-Method
maximum	I-Method
.	O
	
Table	O
[	O
reference	O
]	O
shows	O
the	O
comparison	O
results	O
for	O
the	O
above	O
three	O
different	O
implementations	O
.	O
	
We	O
can	O
see	O
that	O
the	O
element	B-Method
-	I-Method
wise	I-Method
sum	I-Method
always	O
achieves	O
the	O
best	O
performance	O
even	O
though	O
in	O
different	O
normalization	B-Method
methods	I-Method
.	O
	
Generally	O
,	O
current	O
advanced	O
residual	B-Method
networks	I-Method
also	O
use	O
element	B-Method
-	I-Method
wise	I-Method
sum	I-Method
as	O
the	O
effective	O
way	O
to	O
integrate	O
information	O
from	O
previous	O
layers	O
,	O
which	O
greatly	O
facilitates	O
the	O
circulation	O
of	O
information	O
and	O
achieves	O
the	O
complementary	O
advantages	O
.	O
	
For	O
element	B-Task
-	I-Task
wise	I-Task
product	I-Task
,	O
we	O
argue	O
that	O
the	O
system	O
is	O
relatively	O
unstable	O
and	O
is	O
susceptible	O
to	O
the	O
weak	O
side	O
,	O
which	O
results	O
in	O
a	O
large	O
gradient	O
to	O
update	O
the	O
weak	O
branch	O
that	O
makes	O
it	O
difficult	O
to	O
converge	O
.	O
	
For	O
element	B-Method
-	I-Method
wise	I-Method
maximum	I-Method
,	O
it	O
equals	O
to	O
an	O
ensemble	B-Method
model	I-Method
within	O
the	O
network	O
to	O
some	O
extent	O
,	O
which	O
losts	O
the	O
advantages	O
of	O
mutual	O
support	O
compared	O
to	O
element	O
-	O
wise	O
sum	O
when	O
both	O
two	O
branches	O
are	O
failed	O
to	O
detect	O
the	O
object	O
.	O
	
Moreover	O
,	O
a	O
better	O
coupling	B-Method
strategy	I-Method
can	O
be	O
taken	O
into	O
consideration	O
as	O
the	O
future	O
work	O
to	O
further	O
improve	O
the	O
accuracy	B-Metric
,	O
such	O
as	O
designing	O
a	O
more	O
subtle	O
nonlinear	O
structure	O
to	O
learn	O
the	O
coupling	O
relationship	O
.	O
	
Model	B-Method
ensemble	I-Method
.	O
	
Model	B-Method
ensemble	I-Method
is	O
commonly	O
used	O
to	O
improve	O
the	O
final	O
detection	B-Task
performance	O
,	O
since	O
diverse	O
initialization	O
of	O
parameters	O
and	O
the	O
randomness	O
of	O
training	O
samples	O
both	O
lead	O
to	O
different	O
performance	O
for	O
the	O
same	O
model	O
.	O
	
Although	O
the	O
differences	O
and	O
complementarities	O
will	O
be	O
more	O
pronounced	O
for	O
different	O
models	O
,	O
the	O
promotion	O
is	O
often	O
very	O
limited	O
.	O
	
As	O
shown	O
in	O
Table	O
[	O
reference	O
]	O
,	O
we	O
also	O
compare	O
our	O
CoupleNet	B-Method
with	O
the	O
model	B-Method
ensemble	I-Method
.	O
	
For	O
a	O
fair	O
comparison	O
,	O
we	O
first	O
re	O
-	O
implemented	O
Faster	O
R	O
-	O
CNN	B-Method
using	O
ResNet	B-Method
-	I-Method
101	I-Method
and	O
online	B-Method
hard	I-Method
example	I-Method
mining	I-Method
(	O
OHEM	B-Method
)	O
,	O
which	O
achieves	O
a	O
mAP	B-Metric
of	O
on	O
VOC07	B-Material
(	O
in	O
original	O
paper	O
without	O
OHEM	B-Method
)	O
.	O
	
We	O
also	O
re	O
-	O
implemented	O
R	B-Method
-	I-Method
FCN	I-Method
with	O
appropriate	O
joint	B-Method
training	I-Method
using	O
the	O
public	B-Method
available	I-Method
code	I-Method
py	I-Method
-	I-Method
R	I-Method
-	I-Method
FCN	I-Method
,	O
which	O
achieves	O
a	O
slightly	O
lower	O
result	O
compared	O
to	O
(	O
vs.	O
)	O
.	O
	
We	O
use	O
our	O
reimplementation	B-Method
models	I-Method
to	O
conduct	O
the	O
comparisons	O
for	O
consistency	O
.	O
	
We	O
found	O
that	O
the	O
promotion	O
brought	O
by	O
model	B-Method
ensemble	I-Method
is	O
less	O
than	O
1	O
point	O
.	O
	
As	O
shown	O
in	O
Table	O
[	O
reference	O
]	O
,	O
it	O
is	O
far	O
less	O
than	O
our	O
method	O
(	O
)	O
.	O
	
On	O
the	O
one	O
hand	O
,	O
we	O
argue	O
that	O
the	O
naive	B-Method
model	I-Method
ensemble	I-Method
just	O
combines	O
the	O
results	O
together	O
and	O
does	O
not	O
essentially	O
guide	O
the	O
learning	B-Method
process	I-Method
of	O
the	O
network	O
,	O
while	O
our	O
CoupleNet	B-Method
can	O
simultaneously	O
utilize	O
the	O
global	O
and	O
local	O
information	O
to	O
update	O
the	O
network	O
and	O
to	O
infer	O
the	O
final	O
results	O
.	O
	
On	O
the	O
other	O
hand	O
,	O
our	O
method	O
enjoys	O
end	B-Task
-	I-Task
to	I-Task
-	I-Task
end	I-Task
training	I-Task
and	O
there	O
is	O
no	O
need	O
to	O
train	O
multiple	O
models	O
,	O
thus	O
greatly	O
reducing	O
the	O
training	B-Metric
time	I-Metric
.	O
	
Amount	O
of	O
parameters	O
.	O
	
Since	O
our	O
CoupleNet	B-Method
introduces	O
a	O
few	O
more	O
parameters	O
compared	O
with	O
the	O
single	B-Method
branch	I-Method
detectors	I-Method
,	O
to	O
further	O
verify	O
effectiveness	O
of	O
the	O
coupling	B-Method
structure	I-Method
,	O
here	O
we	O
increase	O
the	O
parameters	O
of	O
the	O
prediction	O
head	O
for	O
each	O
single	O
branch	O
implementation	O
to	O
maintain	O
the	O
same	O
amount	O
of	O
parameters	O
with	O
CoupleNet	B-Method
for	O
comparison	O
.	O
	
In	O
detail	O
,	O
we	O
add	O
a	O
new	O
residual	B-Method
variant	I-Method
block	I-Method
with	O
three	O
convolution	B-Method
layers	I-Method
,	O
where	O
the	O
kernel	O
size	O
is	O
1x1x256	O
,	O
3x3x256	O
and	O
1x1x1024	O
respectively	O
,	O
to	O
the	O
prediction	B-Method
sub	I-Method
-	I-Method
network	I-Method
.	O
	
We	O
found	O
that	O
the	O
standard	O
R	B-Method
-	I-Method
FCN	I-Method
with	O
one	O
or	O
two	O
extra	O
heads	O
got	O
a	O
mAP	B-Metric
of	O
and	O
respectively	O
in	O
VOC07	B-Material
,	O
which	O
is	O
slightly	O
higher	O
than	O
our	O
re	O
-	O
implemented	O
version	O
(	O
)	O
in	O
as	O
shown	O
in	O
Table	O
[	O
reference	O
]	O
.	O
	
Meanwhile	O
,	O
our	O
global	B-Method
FCN	I-Method
,	O
which	O
performs	O
the	O
ROI	B-Method
Pooling	I-Method
on	O
top	O
of	O
conv5	B-Method
,	O
got	O
a	O
relative	O
higher	O
gain	O
(	O
a	O
mAP	B-Metric
of	O
for	O
one	O
head	O
,	O
for	O
two	O
heads	O
)	O
.	O
	
The	O
results	O
indicate	O
that	O
simply	O
adding	O
more	O
prediction	O
layers	O
obtains	O
a	O
very	O
limited	O
performance	O
gain	O
,	O
while	O
our	O
coupling	B-Method
structure	I-Method
shows	O
more	O
discriminative	O
power	O
with	O
the	O
same	O
amount	O
of	O
parameters	O
.	O
	
subsection	O
:	O
Results	O
on	O
VOC2007	B-Material
	
Using	O
the	O
public	O
available	O
ResNet	B-Method
-	I-Method
101	I-Method
as	O
the	O
initialization	B-Method
model	I-Method
,	O
we	O
note	O
that	O
our	O
method	O
is	O
easy	O
to	O
follow	O
and	O
the	O
hyper	O
-	O
parameters	O
for	O
training	O
are	O
the	O
same	O
as	O
in	O
.	O
	
Similarly	O
,	O
we	O
use	O
the	O
dilation	B-Method
strategy	I-Method
to	O
reduce	O
the	O
effective	O
stride	O
of	O
ResNet	B-Method
-	I-Method
101	I-Method
,	O
just	O
as	O
shows	O
,	O
thus	O
both	O
the	O
global	O
and	O
local	O
branches	O
have	O
a	O
stride	O
of	O
16	O
.	O
	
We	O
also	O
use	O
a	O
1	B-Method
-	I-Method
GPU	I-Method
implementation	I-Method
,	O
and	O
the	O
effective	O
mini	B-Metric
-	I-Metric
batch	I-Metric
size	I-Metric
is	O
2	O
images	O
by	O
setting	O
the	O
to	O
2	O
.	O
	
The	O
whole	O
network	O
is	O
trained	O
for	O
80k	O
iterations	O
with	O
a	O
learning	B-Metric
rate	I-Metric
of	O
0.001	O
and	O
then	O
for	O
30k	O
iterations	O
with	O
0.0001	O
.	O
	
In	O
addition	O
,	O
the	O
context	O
prior	O
is	O
proposed	O
to	O
further	O
boost	O
the	O
performance	O
while	O
keeping	O
the	O
iterations	O
unchanged	O
.	O
	
Finally	O
,	O
we	O
also	O
perform	O
multi	B-Task
-	I-Task
scale	I-Task
training	I-Task
with	O
the	O
shorter	O
sides	O
of	O
images	O
are	O
randomly	O
resized	O
from	O
480	O
to	O
864	O
.	O
	
Table	O
[	O
reference	O
]	O
shows	O
the	O
detailed	O
comparisons	O
with	O
Faster	O
R	O
-	O
CNN	B-Method
and	O
R	B-Method
-	I-Method
FCN	I-Method
.	O
	
As	O
we	O
can	O
see	O
that	O
our	O
single	O
model	O
achieves	O
a	O
mAP	B-Metric
of	O
,	O
which	O
outperforms	O
the	O
R	B-Method
-	I-Method
FCN	I-Method
by	O
2.2	O
points	O
.	O
	
However	O
,	O
while	O
embedding	O
the	O
context	O
prior	O
to	O
the	O
global	O
branch	O
,	O
our	O
mAP	B-Metric
rises	O
up	O
to	O
,	O
which	O
is	O
the	O
current	O
best	O
single	O
model	O
detector	O
to	O
our	O
knowledge	O
.	O
	
Moreover	O
,	O
we	O
also	O
evaluate	O
the	O
inference	B-Metric
time	I-Metric
of	O
our	O
network	O
using	O
a	O
NVIDIA	B-Method
TITAN	I-Method
X	I-Method
GPU	I-Method
(	O
pascal	O
)	O
along	O
with	O
CUDA	B-Method
8.0	I-Method
and	O
cuDNN	B-Method
-	I-Method
v5.1	I-Method
.	O
	
As	O
shown	O
in	O
the	O
last	O
column	O
of	O
Table	O
[	O
reference	O
]	O
,	O
our	O
method	O
is	O
slightly	O
slower	O
than	O
R	B-Method
-	I-Method
FCN	I-Method
,	O
which	O
also	O
reaches	O
a	O
real	B-Metric
-	I-Metric
time	I-Metric
speed	I-Metric
(	O
8.2	O
fps	B-Metric
or	O
9.8	O
fps	O
without	O
context	O
)	O
and	O
achieves	O
the	O
best	O
trade	O
-	O
off	O
between	O
accuracy	B-Metric
and	O
speed	B-Metric
.	O
	
We	O
argue	O
that	O
the	O
sharing	O
process	O
of	O
feature	B-Method
extraction	I-Method
between	O
two	O
branches	O
and	O
the	O
design	O
of	O
lightweight	B-Method
RoI	I-Method
-	I-Method
wise	I-Method
subnetwork	I-Method
after	O
RoI	B-Method
pooling	I-Method
both	O
greatly	O
reduce	O
the	O
model	B-Metric
complexity	I-Metric
.	O
	
As	O
shown	O
in	O
Table	O
[	O
reference	O
]	O
,	O
we	O
also	O
compared	O
our	O
method	O
with	O
other	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
single	B-Method
model	I-Method
.	O
	
We	O
found	O
that	O
our	O
method	O
outperforms	O
the	O
others	O
with	O
a	O
large	O
margin	O
,	O
including	O
the	O
advanced	O
end	B-Method
-	I-Method
to	I-Method
-	I-Method
end	I-Method
SSD	I-Method
method	I-Method
,	O
which	O
requires	O
complicated	O
data	B-Task
augmentation	I-Task
and	O
careful	O
training	O
skills	O
.	O
	
Just	O
as	O
discussed	O
earlier	O
,	O
CoupleNet	B-Method
shows	O
a	O
large	O
gain	O
over	O
the	O
classes	O
with	O
occlusions	O
,	O
truncations	O
and	O
considerable	O
background	O
information	O
,	O
like	O
sofa	O
,	O
person	O
,	O
table	O
and	O
chair	O
,	O
which	O
verifies	O
our	O
analyses	O
.	O
	
We	O
also	O
observed	O
a	O
large	O
improvement	O
for	O
airplane	O
,	O
bird	O
,	O
boat	O
and	O
pottedplant	O
,	O
which	O
usually	O
have	O
class	O
-	O
specific	O
backgrounds	O
,	O
the	O
sky	O
for	O
airplane	O
and	O
bird	O
,	O
water	O
for	O
boat	O
and	O
so	O
on	O
.	O
	
Therefore	O
,	O
the	O
context	O
surrounding	O
the	O
objects	O
provides	O
an	O
extra	O
auxiliary	O
discrimination	O
.	O
	
subsection	O
:	O
Results	O
on	O
VOC2012	B-Material
	
We	O
also	O
evaluate	O
our	O
method	O
on	O
the	O
more	O
challenging	O
VOC2012	B-Material
dataset	O
by	O
submitting	O
results	O
to	O
the	O
public	B-Metric
evaluation	I-Metric
server	I-Metric
.	O
	
We	O
use	O
VOC07	B-Material
trainval	O
,	O
VOC07	B-Material
test	O
and	O
VOC12	B-Material
trainval	I-Material
as	O
the	O
training	O
set	O
,	O
which	O
consists	O
of	O
21k	O
images	O
in	O
total	O
.	O
	
We	O
also	O
follow	O
the	O
similar	O
hyper	O
-	O
parameter	O
settings	O
in	O
VOC07	B-Material
but	O
change	O
the	O
iterations	O
,	O
since	O
there	O
are	O
more	O
training	O
images	O
.	O
	
We	O
train	O
our	O
models	O
with	O
4	O
GPUs	B-Method
,	O
and	O
the	O
effective	O
mini	O
-	O
batch	O
size	O
thus	O
becomes	O
4	O
(	O
1	O
per	O
GPU	O
)	O
.	O
	
As	O
a	O
result	O
,	O
the	O
network	O
is	O
trained	O
for	O
60k	O
iterations	O
with	O
a	O
learning	B-Metric
rate	I-Metric
of	O
0.001	O
and	O
0.0001	O
for	O
the	O
following	O
20k	O
iterations	O
.	O
	
Table	O
[	O
reference	O
]	O
shows	O
the	O
results	O
on	O
the	O
VOC2012	B-Material
test	O
set	O
.	O
	
Our	O
method	O
obtains	O
a	O
top	O
mAP	B-Metric
of	O
,	O
which	O
is	O
2.8	O
points	O
higher	O
than	O
R	B-Method
-	I-Method
FCN	I-Method
.	O
	
We	O
note	O
that	O
without	O
using	O
the	O
extra	O
tricks	O
in	O
the	O
testing	B-Task
phase	I-Task
,	O
our	O
detector	O
is	O
the	O
first	O
one	O
with	O
a	O
mAP	B-Metric
higher	O
than	O
.	O
	
Similar	O
promotions	O
over	O
the	O
specific	O
classes	O
analysed	O
in	O
VOC07	B-Material
are	O
also	O
observed	O
,	O
which	O
once	O
again	O
validates	O
the	O
effectiveness	O
of	O
our	O
method	O
.	O
	
Figure	O
[	O
reference	O
]	O
shows	O
some	O
detection	O
examples	O
on	O
VOC	B-Material
2012	I-Material
test	I-Material
set	I-Material
.	O
	
subsection	O
:	O
Results	O
on	O
MS	B-Material
COCO	I-Material
	
Next	O
we	O
present	O
more	O
results	O
on	O
the	O
Microsoft	O
COCO	O
object	B-Task
detection	I-Task
dataset	O
.	O
	
The	O
dataset	O
consists	O
of	O
80k	O
training	O
set	O
,	O
40k	O
validation	O
set	O
and	O
20k	O
test	O
-	O
dev	O
set	O
,	O
which	O
involves	O
80	O
object	O
categories	O
.	O
	
All	O
our	O
models	O
are	O
trained	O
on	O
the	O
union	O
set	O
of	O
80k	O
training	O
set	O
and	O
40k	O
validation	O
set	O
,	O
and	O
evaluated	O
on	O
20k	O
test	O
-	O
dev	O
set	O
.	O
	
The	O
COCO	B-Metric
standard	I-Metric
metric	I-Metric
denotes	O
as	O
AP	B-Method
,	O
which	O
is	O
evaluated	O
at	O
.	O
	
Following	O
the	O
VOC2012	B-Material
,	O
a	O
4	B-Method
-	I-Method
GPU	I-Method
implementation	I-Method
is	O
used	O
to	O
accelerate	O
the	O
training	B-Task
process	I-Task
.	O
	
We	O
use	O
an	O
initial	O
learning	B-Metric
rate	I-Metric
of	O
0.001	O
for	O
the	O
first	O
510k	O
iterations	O
and	O
0.0001	O
for	O
the	O
next	O
70k	O
iterations	O
.	O
	
In	O
addition	O
,	O
we	O
conduct	O
multi	B-Task
-	I-Task
scale	I-Task
training	I-Task
with	O
the	O
scales	O
are	O
randomly	O
sampled	O
from	O
while	O
testing	O
in	O
a	O
single	O
scale	O
.	O
	
Table	O
[	O
reference	O
]	O
shows	O
our	O
results	O
.	O
	
Our	O
single	B-Method
-	I-Method
scale	I-Method
trained	I-Method
detector	I-Method
has	O
already	O
achieved	O
a	O
result	O
of	O
,	O
which	O
outperforms	O
the	O
R	B-Method
-	I-Method
FCN	I-Method
by	O
3.9	O
points	O
.	O
	
In	O
addition	O
,	O
the	O
multi	B-Method
-	I-Method
scale	I-Method
training	I-Method
further	O
improves	O
the	O
performance	O
up	O
to	O
.	O
	
Interestingly	O
,	O
we	O
observed	O
that	O
the	O
more	O
challenging	O
the	O
dataset	O
,	O
the	O
more	O
the	O
promotion	O
(	O
,	O
for	O
VOC07	B-Material
,	O
for	O
VOC12	B-Material
and	O
for	O
COCO	B-Material
,	O
all	O
in	O
multi	B-Task
-	I-Task
scale	I-Task
training	I-Task
)	O
,	O
which	O
directly	O
proves	O
that	O
our	O
approach	O
can	O
effectively	O
cope	O
with	O
a	O
variety	O
of	O
complex	O
situations	O
.	O
	
section	O
:	O
Conclusion	O
	
In	O
this	O
paper	O
,	O
we	O
present	O
the	O
CoupleNet	B-Method
,	O
a	O
concise	O
yet	O
effective	O
network	O
that	O
simultaneously	O
couples	O
global	O
,	O
local	O
and	O
context	O
cues	O
for	O
accurate	O
object	B-Task
detection	I-Task
.	O
	
Our	O
system	O
naturally	O
combines	O
the	O
advantages	O
of	O
different	O
region	B-Method
-	I-Method
based	I-Method
approaches	I-Method
with	O
the	O
coupling	O
structure	O
.	O
	
With	O
the	O
combination	O
of	O
local	B-Method
part	I-Method
representation	I-Method
,	O
global	O
structural	O
information	O
and	O
the	O
contextual	O
assistance	O
,	O
our	O
CoupleNet	B-Method
achieves	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
results	O
on	O
the	O
challenging	O
PASCAL	B-Material
VOC	I-Material
and	O
COCO	B-Material
datasets	I-Material
without	O
using	O
any	O
extra	O
tricks	O
in	O
the	O
testing	O
phase	O
,	O
which	O
validates	O
the	O
effectiveness	O
of	O
our	O
method	O
.	O
	
bibliography	O
:	O
References	O
	
OUTRAGEOUSLY	B-Method
LARGE	I-Method
NEURAL	I-Method
NETWORKS	I-Method
:	O
	
THE	O
SPARSELY	B-Method
-	I-Method
GATED	I-Method
MIXTURE	I-Method
-	I-Method
OF	I-Method
-	I-Method
EXPERTS	I-Method
LAYER	I-Method
	
section	O
:	O
ABSTRACT	O
	
The	O
capacity	O
of	O
a	O
neural	B-Method
network	I-Method
to	O
absorb	O
information	O
is	O
limited	O
by	O
its	O
number	O
of	O
parameters	O
.	O
	
Conditional	B-Task
computation	I-Task
,	O
where	O
parts	O
of	O
the	O
network	O
are	O
active	O
on	O
a	O
per	O
-	O
example	O
basis	O
,	O
has	O
been	O
proposed	O
in	O
theory	O
as	O
a	O
way	O
of	O
dramatically	O
increasing	O
model	B-Task
capacity	I-Task
without	O
a	O
proportional	O
increase	O
in	O
computation	B-Task
.	O
	
In	O
practice	O
,	O
however	O
,	O
there	O
are	O
significant	O
algorithmic	O
and	O
performance	O
challenges	O
.	O
	
In	O
this	O
work	O
,	O
we	O
address	O
these	O
challenges	O
and	O
finally	O
realize	O
the	O
promise	O
of	O
conditional	B-Task
computation	I-Task
,	O
achieving	O
greater	O
than	O
1000x	O
improvements	O
in	O
model	B-Metric
capacity	I-Metric
with	O
only	O
minor	O
losses	O
in	O
computational	B-Metric
efficiency	I-Metric
on	O
modern	O
GPU	B-Method
clusters	I-Method
.	O
	
We	O
introduce	O
a	O
Sparsely	O
-	O
Gated	O
Mixture	B-Method
-	I-Method
of	I-Method
-	I-Method
Experts	I-Method
layer	I-Method
(	O
MoE	B-Method
)	O
,	O
consisting	O
of	O
up	O
to	O
thousands	O
of	O
feed	B-Method
-	I-Method
forward	I-Method
sub	I-Method
-	I-Method
networks	I-Method
.	O
	
A	O
trainable	B-Method
gating	I-Method
network	I-Method
determines	O
a	O
sparse	O
combination	O
of	O
these	O
experts	O
to	O
use	O
for	O
each	O
example	O
.	O
	
We	O
apply	O
the	O
MoE	B-Method
to	O
the	O
tasks	O
of	O
language	B-Task
modeling	I-Task
and	O
machine	B-Task
translation	I-Task
,	O
where	O
model	B-Task
capacity	I-Task
is	O
critical	O
for	O
absorbing	O
the	O
vast	O
quantities	O
of	O
knowledge	O
available	O
in	O
the	O
training	O
corpora	O
.	O
	
We	O
present	O
model	B-Method
architectures	I-Method
in	O
which	O
a	O
MoE	B-Method
with	O
up	O
to	O
137	O
billion	O
parameters	O
is	O
applied	O
convolutionally	B-Method
between	O
stacked	O
LSTM	B-Method
layers	O
.	O
	
On	O
large	O
language	B-Task
modeling	I-Task
and	O
machine	B-Task
translation	I-Task
benchmarks	O
,	O
these	O
models	O
achieve	O
significantly	O
better	O
results	O
than	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
at	O
lower	O
computational	B-Metric
cost	I-Metric
.	O
	
section	O
:	O
INTRODUCTION	O
AND	O
RELATED	O
WORK	O
	
section	O
:	O
CONDITIONAL	B-Task
COMPUTATION	I-Task
	
Exploiting	O
scale	O
in	O
both	O
training	O
data	O
and	O
model	B-Metric
size	I-Metric
has	O
been	O
central	O
to	O
the	O
success	O
of	O
deep	B-Method
learning	I-Method
.	O
	
When	O
datasets	O
are	O
sufficiently	O
large	O
,	O
increasing	O
the	O
capacity	O
(	O
number	O
of	O
parameters	O
)	O
of	O
neural	B-Method
networks	I-Method
can	O
give	O
much	O
better	O
prediction	B-Metric
accuracy	I-Metric
.	O
	
This	O
has	O
been	O
shown	O
in	O
domains	O
such	O
as	O
text	O
[	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
,	O
images	O
[	O
reference	O
][	O
reference	O
]	O
,	O
and	O
audio	O
	
[	O
reference	O
][	O
reference	O
]	O
.	O
	
For	O
typical	O
deep	B-Method
learning	I-Method
models	I-Method
,	O
where	O
the	O
entire	O
model	O
is	O
activated	O
for	O
every	O
example	O
,	O
this	O
leads	O
to	O
a	O
roughly	O
quadratic	O
blow	O
-	O
up	O
in	O
training	B-Metric
costs	I-Metric
,	O
as	O
both	O
the	O
model	B-Metric
size	I-Metric
and	O
the	O
number	O
of	O
training	O
examples	O
increase	O
.	O
	
Unfortunately	O
,	O
the	O
advances	O
in	O
computing	B-Metric
power	I-Metric
and	O
distributed	B-Task
computation	I-Task
fall	O
short	O
of	O
meeting	O
such	O
demand	O
.	O
	
Various	O
forms	O
of	O
conditional	B-Method
computation	I-Method
have	O
been	O
proposed	O
as	O
a	O
way	O
to	O
increase	O
model	O
capacity	O
without	O
a	O
proportional	O
increase	O
in	O
computational	B-Metric
costs	I-Metric
[	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
.	O
	
In	O
these	O
schemes	O
,	O
large	O
parts	O
of	O
a	O
network	O
are	O
active	O
or	O
inactive	O
on	O
a	O
per	O
-	O
example	O
basis	O
.	O
	
The	O
gating	O
decisions	O
may	O
be	O
binary	O
or	O
sparse	O
and	O
continuous	O
,	O
stochastic	O
or	O
deterministic	O
.	O
	
Various	O
forms	O
of	O
reinforcement	B-Method
learning	I-Method
and	O
back	B-Method
-	I-Method
propagation	I-Method
are	O
proposed	O
for	O
trarining	B-Task
the	I-Task
gating	I-Task
decisions	I-Task
.	O
	
•	O
	
Model	B-Method
capacity	I-Method
is	O
most	O
critical	O
for	O
very	O
large	O
data	O
sets	O
.	O
	
The	O
existing	O
literature	O
on	O
conditional	B-Task
computation	I-Task
deals	O
with	O
relatively	O
small	O
image	O
recognition	O
data	O
sets	O
consisting	O
of	O
up	O
to	O
600	O
,	O
000	O
images	O
.	O
	
It	O
is	O
hard	O
to	O
imagine	O
that	O
the	O
labels	O
of	O
these	O
images	O
provide	O
a	O
sufficient	O
signal	O
to	O
adequately	O
train	O
a	O
model	O
with	O
millions	O
,	O
let	O
alone	O
billions	O
of	O
parameters	O
.	O
	
In	O
this	O
work	O
,	O
we	O
for	O
the	O
first	O
time	O
address	O
all	O
of	O
the	O
above	O
challenges	O
and	O
finally	O
realize	O
the	O
promise	O
of	O
conditional	B-Task
computation	I-Task
.	O
	
We	O
obtain	O
greater	O
than	O
1000x	O
improvements	O
in	O
model	B-Metric
capacity	I-Metric
with	O
only	O
minor	O
losses	O
in	O
computational	B-Metric
efficiency	I-Metric
and	O
significantly	O
advance	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
results	O
on	O
public	O
language	B-Task
modeling	I-Task
and	O
translation	O
data	O
sets	O
.	O
	
section	O
:	O
OUR	O
APPROACH	O
:	O
THE	O
SPARSELY	B-Method
-	I-Method
GATED	I-Method
MIXTURE	I-Method
-	I-Method
OF	I-Method
-	I-Method
EXPERTS	I-Method
LAYER	I-Method
	
Our	O
approach	O
to	O
conditional	B-Task
computation	I-Task
is	O
to	O
introduce	O
a	O
new	O
type	O
of	O
general	B-Method
purpose	I-Method
neural	I-Method
network	I-Method
component	I-Method
:	O
a	O
Sparsely	B-Method
-	I-Method
Gated	I-Method
Mixture	I-Method
-	I-Method
of	I-Method
-	I-Method
Experts	I-Method
Layer	I-Method
(	O
MoE	B-Method
)	O
.	O
	
The	O
MoE	B-Method
consists	O
of	O
a	O
number	O
of	O
experts	B-Method
,	O
each	O
a	O
simple	O
feed	B-Method
-	I-Method
forward	I-Method
neural	I-Method
network	I-Method
,	O
and	O
a	O
trainable	B-Method
gating	I-Method
network	I-Method
which	O
selects	O
a	O
sparse	O
combination	O
of	O
the	O
experts	O
to	O
process	O
each	O
input	O
(	O
see	O
Figure	O
1	O
)	O
.	O
	
All	O
parts	O
of	O
the	O
network	O
are	O
trained	O
jointly	O
by	O
back	B-Method
-	I-Method
propagation	I-Method
.	O
	
While	O
the	O
introduced	O
technique	O
is	O
generic	O
,	O
in	O
this	O
paper	O
we	O
focus	O
on	O
language	B-Task
modeling	I-Task
and	O
machine	B-Task
translation	I-Task
tasks	O
,	O
which	O
are	O
known	O
to	O
benefit	O
from	O
very	O
large	O
models	O
.	O
	
In	O
particular	O
,	O
we	O
apply	O
a	O
MoE	B-Method
convolutionally	O
between	O
stacked	O
LSTM	B-Method
layers	O
[	O
reference	O
]	O
,	O
as	O
in	O
Figure	O
1	O
.	O
	
The	O
MoE	B-Method
is	O
called	O
once	O
for	O
each	O
position	O
in	O
the	O
text	O
,	O
selecting	O
a	O
potentially	O
different	O
combination	O
of	O
experts	O
at	O
each	O
position	O
.	O
	
The	O
different	O
experts	O
tend	O
to	O
become	O
highly	O
specialized	O
based	O
on	O
syntax	O
and	O
semantics	O
(	O
see	O
Appendix	O
E	O
Table	O
9	O
)	O
.	O
	
On	O
both	O
language	B-Task
modeling	I-Task
and	O
machine	B-Task
translation	I-Task
benchmarks	O
,	O
we	O
improve	O
on	O
best	O
published	O
results	O
at	O
a	O
fraction	O
of	O
the	O
computational	B-Metric
cost	I-Metric
.	O
	
section	O
:	O
RELATED	O
WORK	O
ON	O
MIXTURES	B-Task
OF	I-Task
EXPERTS	I-Task
	
Since	O
its	O
introduction	O
more	O
than	O
two	O
decades	O
ago	O
[	O
reference	O
][	O
reference	O
]	O
,	O
the	O
mixture	B-Method
-	I-Method
of	I-Method
-	I-Method
experts	I-Method
approach	I-Method
has	O
been	O
the	O
subject	O
of	O
much	O
research	O
.	O
	
Different	O
types	O
of	O
expert	B-Method
architectures	I-Method
hae	O
been	O
proposed	O
such	O
as	O
SVMs	B-Method
[	O
reference	O
]	O
,	O
Gaussian	B-Method
Processes	I-Method
[	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
,	O
Dirichlet	B-Method
Processes	I-Method
[	O
reference	O
]	O
,	O
and	O
deep	B-Method
networks	I-Method
.	O
	
Other	O
work	O
has	O
focused	O
on	O
different	O
expert	O
configurations	O
such	O
as	O
a	O
hierarchical	O
structure	O
[	O
reference	O
]	O
,	O
infinite	O
numbers	O
of	O
experts	O
[	O
reference	O
]	O
,	O
and	O
adding	O
experts	O
sequentially	O
[	O
reference	O
]	O
.	O
[	O
reference	O
]	O
suggest	O
an	O
ensemble	B-Method
model	I-Method
in	O
the	O
format	O
of	O
mixture	B-Method
of	I-Method
experts	I-Method
for	O
machine	B-Task
translation	I-Task
.	O
	
The	O
gating	B-Method
network	I-Method
is	O
trained	O
on	O
a	O
pre	O
-	O
trained	O
ensemble	B-Method
NMT	I-Method
model	I-Method
.	O
	
The	O
works	O
above	O
concern	O
top	O
-	O
level	O
mixtures	O
of	O
experts	O
.	O
	
The	O
mixture	B-Method
of	I-Method
experts	I-Method
is	O
the	O
whole	O
model	O
.	O
	
[	O
reference	O
]	O
introduce	O
the	O
idea	O
of	O
using	O
multiple	O
MoEs	B-Method
with	O
their	O
own	O
gating	B-Method
networks	I-Method
as	O
parts	O
of	O
a	O
deep	B-Method
model	I-Method
.	O
	
It	O
is	O
intuitive	O
that	O
the	O
latter	O
approach	O
is	O
more	O
powerful	O
,	O
since	O
complex	O
problems	O
may	O
contain	O
many	O
sub	O
-	O
problems	O
each	O
requiring	O
different	O
experts	O
.	O
	
They	O
also	O
allude	O
in	O
their	O
conclusion	O
to	O
the	O
potential	O
to	O
introduce	O
sparsity	O
,	O
turning	O
MoEs	B-Method
into	O
a	O
vehicle	O
for	O
computational	B-Task
computation	I-Task
.	O
	
Our	O
work	O
builds	O
on	O
this	O
use	O
of	O
MoEs	B-Method
as	O
a	O
general	B-Method
purpose	I-Method
neural	I-Method
network	I-Method
component	I-Method
.	O
	
While	O
[	O
reference	O
]	O
uses	O
two	O
stacked	B-Method
MoEs	I-Method
allowing	O
for	O
two	O
sets	O
of	O
gating	O
decisions	O
,	O
our	O
convolutional	B-Method
application	I-Method
of	O
the	O
MoE	B-Method
allows	O
for	O
different	O
gating	O
decisions	O
at	O
each	O
position	O
in	O
the	O
text	O
.	O
	
We	O
also	O
realize	O
sparse	B-Method
gating	I-Method
and	O
demonstrate	O
its	O
use	O
as	O
a	O
practical	O
way	O
to	O
massively	O
increase	O
model	B-Metric
capacity	I-Metric
.	O
	
section	O
:	O
THE	O
STRUCTURE	O
OF	O
THE	O
MIXTURE	B-Method
-	I-Method
OF	I-Method
-	I-Method
EXPERTS	I-Method
LAYER	I-Method
	
The	O
Mixture	O
-	O
of	O
-	O
Experts	O
(	O
MoE	B-Method
)	O
layer	O
consists	O
of	O
a	O
set	O
of	O
n	O
"	O
expert	B-Method
networks	I-Method
"	O
E	O
1	O
,	O
·	O
·	O
·	O
,	O
E	O
n	O
,	O
and	O
a	O
"	O
gating	B-Method
network	I-Method
	
"	O
G	O
whose	O
output	O
is	O
a	O
sparse	O
n	O
-	O
dimensional	O
vector	O
.	O
	
Figure	O
1	O
shows	O
an	O
overview	O
of	O
the	O
MoE	B-Method
module	O
.	O
	
The	O
experts	O
are	O
themselves	O
neural	B-Method
networks	I-Method
,	O
each	O
with	O
their	O
own	O
parameters	O
.	O
	
Although	O
in	O
principle	O
we	O
only	O
require	O
that	O
the	O
experts	O
accept	O
the	O
same	O
sized	O
inputs	O
and	O
produce	O
the	O
same	O
-	O
sized	O
outputs	O
,	O
in	O
our	O
initial	O
investigations	O
in	O
this	O
paper	O
,	O
we	O
restrict	O
ourselves	O
to	O
the	O
case	O
where	O
the	O
models	O
are	O
feed	B-Method
-	I-Method
forward	I-Method
networks	I-Method
with	O
identical	O
architectures	O
,	O
but	O
with	O
separate	O
parameters	O
.	O
	
Let	O
us	O
denote	O
by	O
G	O
(	O
x	O
)	O
and	O
E	O
i	O
(	O
x	O
)	O
the	O
output	O
of	O
the	O
gating	B-Method
network	I-Method
and	O
the	O
output	O
of	O
the	O
i	O
-	O
th	O
expert	B-Method
network	I-Method
for	O
a	O
given	O
input	O
	
x.	O
	
The	O
output	O
y	O
of	O
the	O
MoE	B-Method
module	O
can	O
be	O
written	O
as	O
follows	O
:	O
	
We	O
save	O
computation	O
based	O
on	O
the	O
sparsity	O
of	O
the	O
output	O
of	O
G	O
(	O
x	O
)	O
.	O
	
Wherever	O
G	O
(	O
x	O
)	O
	
i	O
	
=	O
0	O
,	O
we	O
need	O
not	O
compute	O
E	O
i	O
(	O
	
x	O
)	O
.	O
	
In	O
our	O
experiments	O
,	O
we	O
have	O
up	O
to	O
thousands	O
of	O
experts	O
,	O
but	O
only	O
need	O
to	O
evaluate	O
a	O
handful	O
of	O
them	O
for	O
every	O
example	O
.	O
	
If	O
the	O
number	O
of	O
experts	O
is	O
very	O
large	O
,	O
we	O
can	O
reduce	O
the	O
branching	O
factor	O
by	O
using	O
a	O
two	O
-	O
level	B-Method
hierarchical	I-Method
MoE.	I-Method
	
In	O
a	O
hierarchical	O
MoE	B-Method
,	O
a	O
primary	B-Method
gating	I-Method
network	I-Method
chooses	O
a	O
sparse	B-Method
weighted	I-Method
combination	I-Method
of	O
"	O
experts	O
"	O
,	O
each	O
of	O
which	O
is	O
itself	O
a	O
secondary	O
mixture	O
-	O
of	O
-	O
experts	O
with	O
its	O
own	O
gating	B-Method
network	I-Method
.	O
	
In	O
the	O
following	O
we	O
focus	O
on	O
ordinary	B-Task
MoEs	I-Task
.	O
	
We	O
provide	O
more	O
details	O
on	O
hierarchical	O
MoEs	O
in	O
Appendix	O
B.	O
	
Our	O
implementation	O
is	O
related	O
to	O
other	O
models	O
of	O
conditional	B-Task
computation	I-Task
.	O
	
A	O
MoE	B-Method
whose	O
experts	O
are	O
simple	O
weight	O
matrices	O
is	O
similar	O
to	O
the	O
parameterized	B-Method
weight	I-Method
matrix	I-Method
proposed	O
in	O
.	O
	
A	O
MoE	B-Method
whose	O
experts	O
have	O
one	O
hidden	O
layer	O
is	O
similar	O
to	O
the	O
block	B-Method
-	I-Method
wise	I-Method
dropout	I-Method
described	O
in	O
[	O
reference	O
]	O
,	O
where	O
the	O
dropped	O
-	O
out	O
layer	O
is	O
sandwiched	O
between	O
fully	O
-	O
activated	O
layers	O
.	O
	
section	O
:	O
GATING	B-Method
NETWORK	I-Method
	
Softmax	B-Method
Gating	I-Method
:	O
A	O
simple	O
choice	O
of	O
non	B-Method
-	I-Method
sparse	I-Method
gating	I-Method
function	I-Method
[	O
reference	O
]	O
is	O
to	O
multiply	O
the	O
input	O
by	O
a	O
trainable	O
weight	O
matrix	O
W	O
g	O
and	O
then	O
apply	O
the	O
Sof	B-Method
tmax	I-Method
function	I-Method
.	O
	
Noisy	B-Method
Top	I-Method
-	I-Method
K	I-Method
Gating	I-Method
:	O
We	O
add	O
two	O
components	O
to	O
the	O
Softmax	B-Method
gating	I-Method
network	I-Method
:	O
sparsity	O
and	O
noise	O
.	O
	
Before	O
taking	O
the	O
softmax	O
function	O
,	O
we	O
add	O
tunable	O
Gaussian	O
noise	O
,	O
then	O
keep	O
only	O
the	O
top	O
k	O
values	O
,	O
setting	O
the	O
rest	O
to	O
−∞	O
(	O
which	O
causes	O
the	O
corresponding	O
gate	O
values	O
to	O
equal	O
0	O
)	O
.	O
	
The	O
sparsity	O
serves	O
to	O
save	O
computation	O
,	O
as	O
described	O
above	O
.	O
	
While	O
this	O
form	O
of	O
sparsity	O
creates	O
some	O
theoretically	O
scary	O
discontinuities	O
in	O
the	O
output	O
of	O
gating	O
function	O
,	O
we	O
have	O
not	O
yet	O
observed	O
this	O
to	O
be	O
a	O
problem	O
in	O
practice	O
.	O
	
The	O
noise	O
term	O
helps	O
with	O
load	B-Task
balancing	I-Task
,	O
as	O
will	O
be	O
discussed	O
in	O
Appendix	O
A.	O
	
The	O
amount	O
of	O
noise	O
per	O
component	O
is	O
controlled	O
by	O
a	O
second	O
trainable	B-Method
weight	I-Method
matrix	I-Method
W	I-Method
noise	I-Method
.	O
	
Training	O
the	O
Gating	B-Method
Network	I-Method
	
We	O
train	O
the	O
gating	B-Method
network	I-Method
by	O
simple	O
back	B-Method
-	I-Method
propagation	I-Method
,	O
along	O
with	O
the	O
rest	O
of	O
the	O
model	O
.	O
	
If	O
we	O
choose	O
k	O
>	O
1	O
,	O
the	O
gate	O
values	O
for	O
the	O
top	O
k	O
experts	O
have	O
nonzero	O
derivatives	O
with	O
respect	O
to	O
the	O
weights	O
of	O
the	O
gating	B-Method
network	I-Method
.	O
	
This	O
type	O
of	O
occasionally	O
-	O
sensitive	O
behavior	O
is	O
described	O
in	O
[	O
reference	O
]	O
)	O
with	O
respect	O
to	O
noisy	B-Method
rectifiers	I-Method
.	O
	
Gradients	O
also	O
backpropagate	O
through	O
the	O
gating	B-Method
network	I-Method
to	O
its	O
inputs	O
.	O
	
Our	O
method	O
differs	O
here	O
from	O
[	O
reference	O
]	O
who	O
use	O
boolean	O
gates	O
and	O
a	O
REINFORCE	B-Method
-	I-Method
style	I-Method
approach	I-Method
to	O
train	O
the	O
gating	B-Method
network	I-Method
.	O
	
section	O
:	O
ADDRESSING	O
PERFORMANCE	B-Task
CHALLENGES	I-Task
	
section	O
:	O
THE	O
SHRINKING	B-Task
BATCH	I-Task
PROBLEM	I-Task
	
On	O
modern	O
CPUs	B-Method
and	O
GPUs	B-Method
,	O
large	O
batch	O
sizes	O
are	O
necessary	O
for	O
computational	B-Metric
efficiency	I-Metric
,	O
so	O
as	O
to	O
amortize	O
the	O
overhead	O
of	O
parameter	O
loads	O
and	O
updates	O
.	O
	
If	O
the	O
gating	B-Method
network	I-Method
chooses	O
k	O
out	O
of	O
n	O
experts	O
for	O
each	O
example	O
,	O
then	O
for	O
a	O
batch	O
of	O
b	O
examples	O
,	O
each	O
expert	O
receives	O
a	O
much	O
smaller	O
batch	O
of	O
approximately	O
kb	O
n	O
b	O
examples	O
.	O
	
This	O
causes	O
a	O
naive	O
MoE	B-Method
implementation	O
to	O
become	O
very	O
inefficient	O
as	O
the	O
number	O
of	O
experts	O
increases	O
.	O
	
The	O
solution	O
to	O
this	O
shrinking	B-Task
batch	I-Task
problem	I-Task
is	O
to	O
make	O
the	O
original	O
batch	O
size	O
as	O
large	O
as	O
possible	O
.	O
	
However	O
,	O
batch	O
size	O
tends	O
to	O
be	O
limited	O
by	O
the	O
memory	O
necessary	O
to	O
store	O
activations	O
between	O
the	O
forwards	O
and	O
backwards	O
passes	O
.	O
	
We	O
propose	O
the	O
following	O
techniques	O
for	O
increasing	O
the	O
batch	B-Task
size	I-Task
:	O
	
Mixing	B-Task
Data	I-Task
Parallelism	I-Task
and	O
Model	B-Task
Parallelism	I-Task
:	O
In	O
a	O
conventional	O
distributed	B-Task
training	I-Task
setting	I-Task
,	O
multiple	O
copies	O
of	O
the	O
model	O
on	O
different	O
devices	O
asynchronously	O
process	O
distinct	O
batches	O
of	O
data	O
,	O
and	O
parameters	O
are	O
synchronized	O
through	O
a	O
set	O
of	O
parameter	B-Method
servers	I-Method
.	O
	
In	O
our	O
technique	O
,	O
these	O
different	O
batches	O
run	O
synchronously	O
so	O
that	O
they	O
can	O
be	O
combined	O
for	O
the	O
MoE	B-Method
layer	O
.	O
	
We	O
distribute	O
the	O
standard	O
layers	O
of	O
the	O
model	O
and	O
the	O
gating	B-Method
network	I-Method
according	O
to	O
conventional	O
data	B-Method
-	I-Method
parallel	I-Method
schemes	I-Method
,	O
but	O
keep	O
only	O
one	O
shared	O
copy	O
of	O
each	O
expert	O
.	O
	
Each	O
expert	O
in	O
the	O
MoE	B-Method
layer	O
receives	O
a	O
combined	O
batch	O
consisting	O
of	O
the	O
relevant	O
examples	O
from	O
all	O
of	O
the	O
data	O
-	O
parallel	O
input	O
batches	O
.	O
	
The	O
same	O
set	O
of	O
devices	O
function	O
as	O
data	B-Method
-	I-Method
parallel	I-Method
replicas	I-Method
(	O
for	O
the	O
standard	O
layers	O
and	O
the	O
gating	B-Method
networks	I-Method
)	O
and	O
as	O
model	B-Method
-	I-Method
parallel	I-Method
shards	I-Method
(	O
each	O
hosting	O
a	O
subset	O
of	O
the	O
experts	O
)	O
.	O
	
If	O
the	O
model	O
is	O
distributed	O
over	O
d	O
devices	O
,	O
and	O
each	O
device	O
processes	O
a	O
batch	O
of	O
size	O
b	O
,	O
each	O
expert	O
receives	O
a	O
batch	O
of	O
approximately	O
kbd	O
n	O
examples	O
.	O
	
Thus	O
,	O
we	O
achieve	O
a	O
factor	O
of	O
d	O
improvement	O
in	O
expert	B-Metric
batch	I-Metric
size	I-Metric
.	O
	
In	O
the	O
case	O
of	O
a	O
hierarchical	O
MoE	B-Method
(	O
Section	O
B	O
)	O
,	O
the	O
primary	B-Method
gating	I-Method
network	I-Method
employs	O
data	B-Method
parallelism	I-Method
,	O
and	O
the	O
secondary	B-Method
MoEs	I-Method
employ	O
model	B-Method
parallelism	I-Method
.	O
	
Each	O
secondary	O
MoE	B-Method
resides	O
on	O
one	O
device	O
.	O
	
This	O
technique	O
allows	O
us	O
to	O
increase	O
the	O
number	O
of	O
experts	O
(	O
and	O
hence	O
the	O
number	O
of	O
parameters	O
)	O
by	O
proportionally	O
increasing	O
the	O
number	O
of	O
devices	O
in	O
the	O
training	O
cluster	O
.	O
	
The	O
total	O
batch	B-Metric
size	I-Metric
increases	O
,	O
keeping	O
the	O
batch	O
size	O
per	O
expert	O
constant	O
.	O
	
The	O
memory	B-Metric
and	I-Metric
bandwidth	I-Metric
requirements	I-Metric
per	O
device	O
also	O
remain	O
constant	O
,	O
as	O
do	O
the	O
step	O
times	O
,	O
as	O
does	O
the	O
amount	O
of	O
time	O
necessary	O
to	O
process	O
a	O
number	O
of	O
training	O
examples	O
equal	O
to	O
the	O
number	O
of	O
parameters	O
in	O
the	O
model	O
.	O
	
It	O
is	O
our	O
goal	O
to	O
train	O
a	O
trillionparameter	B-Method
model	I-Method
on	O
a	O
trillion	B-Material
-	I-Material
word	I-Material
corpus	I-Material
.	O
	
We	O
have	O
not	O
scaled	O
our	O
systems	O
this	O
far	O
as	O
of	O
the	O
writing	O
of	O
this	O
paper	O
,	O
but	O
it	O
should	O
be	O
possible	O
by	O
adding	O
more	O
hardware	O
.	O
	
Taking	O
Advantage	O
of	O
Convolutionality	B-Method
:	O
In	O
our	O
language	B-Method
models	I-Method
,	O
we	O
apply	O
the	O
same	O
MoE	B-Method
to	O
each	O
time	O
step	O
of	O
the	O
previous	O
layer	O
.	O
	
If	O
we	O
wait	O
for	O
the	O
previous	O
layer	O
to	O
finish	O
,	O
we	O
can	O
apply	O
the	O
MoE	B-Method
to	O
all	O
the	O
time	O
steps	O
together	O
as	O
one	O
big	O
batch	O
.	O
	
Doing	O
so	O
increases	O
the	O
size	O
of	O
the	O
input	O
batch	O
to	O
the	O
MoE	B-Method
layer	O
by	O
a	O
factor	O
of	O
the	O
number	O
of	O
unrolled	O
time	O
steps	O
.	O
	
Increasing	B-Metric
Batch	I-Metric
Size	I-Metric
for	O
a	O
Recurrent	O
MoE	B-Method
:	O
We	O
suspect	O
that	O
even	O
more	O
powerful	O
models	O
may	O
involve	O
applying	O
a	O
MoE	B-Method
recurrently	O
.	O
	
For	O
example	O
,	O
the	O
weight	O
matrices	O
of	O
a	O
LSTM	B-Method
or	O
other	O
RNN	B-Method
could	O
be	O
replaced	O
by	O
a	O
MoE.	B-Method
	
Sadly	O
,	O
such	O
models	O
break	O
the	O
convolutional	B-Method
trick	I-Method
from	O
the	O
last	O
paragraph	O
,	O
since	O
the	O
input	O
to	O
the	O
MoE	B-Method
at	O
one	O
timestep	O
depends	O
on	O
the	O
output	O
of	O
the	O
MoE	B-Method
at	O
the	O
previous	O
timestep	O
.	O
	
[	O
reference	O
]	O
describe	O
a	O
technique	O
for	O
drastically	O
reducing	O
the	O
number	O
of	O
stored	O
activations	O
in	O
an	O
unrolled	B-Task
RNN	I-Task
,	O
at	O
the	O
cost	O
of	O
recomputing	O
forward	O
activations	O
.	O
	
This	O
would	O
allow	O
for	O
a	O
large	O
increase	O
in	O
batch	B-Metric
size	I-Metric
.	O
	
section	O
:	O
NETWORK	O
BANDWIDTH	O
	
Another	O
major	O
performance	O
concern	O
in	O
distributed	B-Task
computing	I-Task
is	O
network	O
bandwidth	O
.	O
	
Since	O
the	O
experts	O
are	O
stationary	O
(	O
see	O
above	O
)	O
and	O
the	O
number	O
of	O
gating	O
parameters	O
is	O
small	O
,	O
most	O
of	O
the	O
communication	O
involves	O
sending	O
the	O
inputs	O
and	O
outputs	O
of	O
the	O
experts	O
across	O
the	O
network	O
.	O
	
To	O
maintain	O
computational	B-Metric
efficiency	I-Metric
,	O
the	O
ratio	O
of	O
an	O
expert	B-Method
's	I-Method
computation	I-Method
to	O
the	O
size	O
of	O
its	O
input	O
and	O
output	O
must	O
exceed	O
the	O
ratio	O
of	O
computational	O
to	O
network	O
capacity	O
of	O
the	O
computing	B-Method
device	I-Method
.	O
	
For	O
GPUs	B-Method
,	O
this	O
may	O
be	O
thousands	O
to	O
one	O
.	O
	
In	O
our	O
experiments	O
,	O
we	O
use	O
experts	B-Method
with	O
one	O
hidden	B-Method
layer	I-Method
containing	O
thousands	O
of	O
RELU	O
-	O
activated	O
units	O
.	O
	
Since	O
the	O
weight	O
matrices	O
in	O
the	O
expert	O
have	O
sizes	O
input_size×hidden_size	O
and	O
hidden_size	O
×	O
output_size	O
,	O
the	O
ratio	O
of	O
computation	O
to	O
input	O
and	O
output	O
is	O
equal	O
to	O
the	O
size	O
of	O
the	O
hidden	O
layer	O
.	O
	
Conveniently	O
,	O
we	O
can	O
increase	O
computational	B-Metric
efficiency	I-Metric
simply	O
by	O
using	O
a	O
larger	O
hidden	O
layer	O
,	O
or	O
more	O
hidden	O
layers	O
.	O
	
section	O
:	O
BALANCING	B-Task
EXPERT	I-Task
UTILIZATION	I-Task
	
We	O
have	O
observed	O
that	O
the	O
gating	B-Method
network	I-Method
tends	O
to	O
converge	O
to	O
a	O
state	O
where	O
it	O
always	O
produces	O
large	O
weights	O
for	O
the	O
same	O
few	O
experts	O
.	O
	
This	O
imbalance	O
is	O
self	O
-	O
reinforcing	O
,	O
as	O
the	O
favored	O
experts	O
are	O
trained	O
more	O
rapidly	O
and	O
thus	O
are	O
selected	O
even	O
more	O
by	O
the	O
gating	B-Method
network	I-Method
.	O
	
[	O
reference	O
]	O
describe	O
the	O
same	O
phenomenon	O
,	O
and	O
use	O
a	O
hard	O
constraint	O
at	O
the	O
beginning	O
of	O
training	O
to	O
avoid	O
this	O
local	O
minimum	O
.	O
	
[	O
reference	O
]	O
include	O
a	O
soft	O
constraint	O
on	O
the	O
batch	O
-	O
wise	O
average	O
of	O
each	O
gate	O
.	O
	
[	O
reference	O
]	O
	
We	O
take	O
a	O
soft	B-Method
constraint	I-Method
approach	I-Method
.	O
	
We	O
define	O
the	O
importance	O
of	O
an	O
expert	O
relative	O
to	O
a	O
batch	O
of	O
training	O
examples	O
to	O
be	O
the	O
batchwise	O
sum	O
of	O
the	O
gate	O
values	O
for	O
that	O
expert	O
.	O
	
We	O
define	O
an	O
additional	O
loss	O
L	O
importance	O
,	O
which	O
is	O
added	O
to	O
the	O
overall	O
loss	B-Metric
function	I-Metric
for	O
the	O
model	O
.	O
	
This	O
loss	O
is	O
equal	O
to	O
the	O
square	O
of	O
the	O
coefficient	B-Metric
of	I-Metric
variation	I-Metric
of	O
the	O
set	O
of	O
importance	O
values	O
,	O
multiplied	O
by	O
a	O
hand	O
-	O
tuned	O
scaling	O
factor	O
w	O
importance	O
.	O
	
This	O
additional	O
loss	O
encourages	O
all	O
experts	O
to	O
have	O
equal	O
importance	O
.	O
	
1	O
[	O
reference	O
]	O
also	O
include	O
two	O
additional	O
losses	O
.	O
	
One	O
controls	O
per	B-Task
-	I-Task
example	I-Task
sparsity	I-Task
,	O
which	O
we	O
do	O
not	O
need	O
since	O
it	O
is	O
enforced	O
by	O
the	O
fixed	O
value	O
of	O
k.	O
	
A	O
third	O
loss	O
encourages	O
diversity	O
of	O
gate	O
values	O
.	O
	
In	O
our	O
experiments	O
,	O
we	O
find	O
that	O
the	O
gate	O
values	O
naturally	O
diversify	O
as	O
the	O
experts	O
specialize	O
(	O
in	O
a	O
virtuous	O
cycle	O
)	O
,	O
and	O
we	O
do	O
not	O
need	O
to	O
enforce	O
diversity	O
of	O
gate	O
values	O
.	O
	
While	O
this	O
loss	B-Method
function	I-Method
can	O
ensure	O
equal	O
importance	O
,	O
experts	O
may	O
still	O
receive	O
very	O
different	O
numbers	O
of	O
examples	O
.	O
	
For	O
example	O
,	O
one	O
expert	O
may	O
receive	O
a	O
few	O
examples	O
with	O
large	O
weights	O
,	O
and	O
another	O
may	O
receive	O
many	O
examples	O
with	O
small	O
weights	O
.	O
	
This	O
can	O
cause	O
memory	B-Task
and	I-Task
performance	I-Task
problems	I-Task
on	O
distributed	O
hardware	O
.	O
	
To	O
solve	O
this	O
problem	O
,	O
we	O
introduce	O
a	O
second	O
loss	O
function	O
,	O
L	O
load	O
,	O
which	O
ensures	O
balanced	O
loads	O
.	O
	
Appendix	O
A	O
contains	O
the	O
definition	O
of	O
this	O
function	O
,	O
along	O
with	O
experimental	O
results	O
.	O
	
section	O
:	O
EXPERIMENTS	O
	
section	O
:	O
1	O
BILLION	B-Task
WORD	I-Task
LANGUAGE	I-Task
MODELING	I-Task
BENCHMARK	I-Task
	
Dataset	O
:	O
	
This	O
dataset	O
,	O
introduced	O
by	O
[	O
reference	O
]	O
consists	O
of	O
shuffled	O
unique	O
sentences	O
from	O
news	O
articles	O
,	O
totaling	O
approximately	O
829	O
million	O
words	O
,	O
with	O
a	O
vocabulary	O
of	O
793	O
,	O
471	O
words	O
.	O
	
Previous	O
State	O
-	O
of	O
-	O
the	O
-	O
Art	O
:	O
	
The	O
best	O
previously	O
published	O
results	O
[	O
reference	O
]	O
use	O
models	O
consisting	O
of	O
one	O
or	O
more	O
stacked	O
Long	B-Method
Short	I-Method
-	I-Method
Term	I-Method
Memory	I-Method
(	O
LSTM	B-Method
)	O
layers	O
[	O
reference	O
][	O
reference	O
]	O
.	O
	
The	O
number	O
of	O
parameters	O
in	O
the	O
LSTM	B-Method
layers	O
of	O
these	O
models	O
vary	O
from	O
2	O
million	O
to	O
151	O
million	O
.	O
	
Quality	B-Metric
increases	O
greatly	O
with	O
parameter	B-Metric
count	I-Metric
,	O
as	O
do	O
computational	B-Metric
costs	I-Metric
.	O
	
Results	O
for	O
these	O
models	O
form	O
the	O
top	O
line	O
of	O
Figure	O
2	O
-	O
right	O
.	O
	
MoE	B-Method
Models	O
:	O
	
Our	O
models	O
consist	O
of	O
two	O
stacked	O
LSTM	B-Method
layers	O
with	O
a	O
MoE	B-Method
layer	O
between	O
them	O
(	O
see	O
Figure	O
1	O
)	O
.	O
	
We	O
vary	O
the	O
sizes	O
of	O
the	O
layers	O
and	O
the	O
number	O
of	O
experts	O
.	O
	
For	O
full	O
details	O
on	O
model	B-Method
architecture	I-Method
,	O
training	O
regimen	O
,	O
additional	O
baselines	O
and	O
results	O
,	O
see	O
Appendix	O
C.	O
	
Low	O
Computation	O
,	O
Varied	O
Capacity	O
:	O
To	O
investigate	O
the	O
effects	O
of	O
adding	O
capacity	O
,	O
we	O
trained	O
a	O
series	O
of	O
MoE	B-Method
models	O
all	O
with	O
roughly	O
equal	O
computational	B-Metric
costs	I-Metric
:	O
about	O
8	O
million	O
multiply	O
-	O
andadds	O
per	O
training	O
example	O
per	O
timestep	O
in	O
the	O
forwards	O
pass	O
,	O
excluding	O
the	O
softmax	B-Method
layer	I-Method
.	O
	
We	O
call	O
this	O
metric	O
(	O
ops	O
/	O
timestep	O
)	O
.	O
	
We	O
trained	O
models	O
with	O
flat	O
MoEs	O
containing	O
4	O
,	O
32	O
,	O
and	O
256	O
experts	O
,	O
and	O
models	O
with	O
hierarchical	O
MoEs	O
containing	O
256	O
,	O
1024	O
,	O
and	O
4096	O
experts	O
.	O
	
Each	O
expert	O
had	O
about	O
1	O
million	O
parameters	O
.	O
	
For	O
all	O
the	O
MoE	B-Method
layers	I-Method
,	O
4	O
experts	O
were	O
active	O
per	O
input	O
.	O
	
The	O
results	O
of	O
these	O
models	O
are	O
shown	O
in	O
Figure	O
2	O
-	O
left	O
.	O
	
The	O
model	O
with	O
4	O
always	O
-	O
active	O
experts	O
performed	O
(	O
unsurprisingly	O
)	O
similarly	O
to	O
the	O
computationally	O
-	O
matched	B-Method
baseline	I-Method
models	I-Method
,	O
while	O
the	O
largest	O
of	O
the	O
models	O
(	O
4096	O
experts	O
)	O
achieved	O
an	O
impressive	O
24	O
%	O
lower	O
perplexity	B-Metric
on	O
the	O
test	O
set	O
.	O
	
Varied	B-Task
Computation	I-Task
,	O
High	O
Capacity	O
:	O
	
In	O
addition	O
to	O
the	O
largest	O
model	O
from	O
the	O
previous	O
section	O
,	O
we	O
trained	O
two	O
more	O
MoE	B-Method
models	O
with	O
similarly	O
high	O
capacity	O
(	O
4	O
billion	O
parameters	O
)	O
,	O
but	O
higher	O
computation	O
budgets	O
.	O
	
These	O
models	O
had	O
larger	O
LSTMs	B-Method
,	O
and	O
fewer	O
but	O
larger	O
and	O
experts	O
.	O
	
Details	O
can	O
be	O
found	O
in	O
Appendix	O
C.2	O
.	O
	
Results	O
of	O
these	O
three	O
models	O
form	O
the	O
bottom	O
line	O
of	O
Figure	O
2	O
-	O
right	O
.	O
	
Table	O
1	O
compares	O
the	O
results	O
of	O
these	O
models	O
to	O
the	O
best	O
previously	O
-	O
published	O
result	O
on	O
this	O
dataset	O
.	O
	
Even	O
the	O
fastest	O
of	O
these	O
models	O
beats	O
the	O
best	O
published	O
result	O
(	O
when	O
controlling	O
for	O
the	O
number	O
of	O
training	O
epochs	O
)	O
,	O
despite	O
requiring	O
only	O
6	O
%	O
of	O
the	O
computation	O
.	O
	
Computational	B-Metric
Efficiency	I-Metric
:	O
	
We	O
trained	O
our	O
models	O
using	O
TensorFlow	B-Method
[	O
reference	O
]	O
on	O
clusters	O
containing	O
16	O
-	O
32	O
Tesla	B-Method
K40	I-Method
GPUs	I-Method
.	O
	
For	O
each	O
of	O
our	O
models	O
,	O
we	O
determine	O
computational	B-Metric
efficiency	I-Metric
in	O
TFLOPS	B-Metric
/	I-Metric
GPU	I-Metric
by	O
dividing	O
the	O
number	O
of	O
floating	O
point	O
operations	O
required	O
to	O
process	O
one	O
training	O
batch	O
by	O
the	O
observed	O
step	O
time	O
and	O
the	O
number	O
of	O
GPUs	O
in	O
the	O
cluster	O
.	O
	
The	O
operation	O
counts	O
used	O
here	O
are	O
higher	O
than	O
the	O
ones	O
we	O
report	O
in	O
our	O
ops	O
/	O
timestep	O
numbers	O
in	O
that	O
we	O
include	O
the	O
backwards	O
pass	O
,	O
we	O
include	O
the	O
importance	B-Method
-	I-Method
sampling	I-Method
-	I-Method
based	I-Method
training	I-Method
of	O
the	O
softmax	B-Method
layer	I-Method
,	O
and	O
we	O
count	O
a	O
multiply	O
-	O
and	O
-	O
add	O
as	O
two	O
separate	O
operations	O
.	O
	
For	O
all	O
of	O
our	O
MoE	B-Method
models	O
,	O
the	O
floating	O
point	O
operations	O
involved	O
in	O
the	O
experts	O
represent	O
between	O
37	O
%	O
and	O
46	O
%	O
of	O
the	O
total	O
.	O
	
For	O
our	O
baseline	O
models	O
wtih	O
no	O
MoE	B-Method
,	O
observed	O
computational	B-Metric
efficiency	I-Metric
ranged	O
from	O
1.07	O
-	O
1.29	O
TFLOPS	O
/	O
GPU	O
.	O
	
For	O
our	O
low	O
-	O
computation	O
MoE	B-Method
models	O
,	O
computation	B-Metric
efficiency	I-Metric
ranged	O
from	O
0.74	O
-	O
0.90	O
TFLOPS	O
/	O
GPU	B-Method
,	O
except	O
for	O
the	O
4	B-Method
-	I-Method
expert	I-Method
model	I-Method
which	O
did	O
not	O
make	O
full	O
use	O
of	O
the	O
available	O
parallelism	O
.	O
	
Our	O
highest	O
-	O
computation	O
MoE	B-Method
model	O
was	O
more	O
efficient	O
at	O
1.56	O
TFLOPS	O
/	O
GPU	O
,	O
likely	O
due	O
to	O
the	O
larger	O
matrices	O
.	O
	
These	O
numbers	O
represent	O
a	O
significant	O
fraction	O
of	O
the	O
theoretical	O
maximum	O
of	O
4.29	O
TFLOPS	O
/	O
GPU	O
claimed	O
by	O
NVIDIA	O
.	O
	
Detailed	O
results	O
are	O
in	O
Appendix	O
C	O
,	O
Table	O
7	O
.	O
	
section	O
:	O
100	B-Material
BILLION	I-Material
WORD	I-Material
GOOGLE	I-Material
NEWS	I-Material
CORPUS	I-Material
	
Figure	O
3	O
:	O
	
Language	B-Method
modeling	I-Method
on	O
a	O
100	O
billion	B-Material
word	I-Material
corpus	I-Material
.	O
	
Models	O
have	O
similar	O
computational	B-Metric
budgets	I-Metric
(	O
8	O
million	O
ops	O
/	O
timestep	O
)	O
.	O
	
On	O
the	O
1	B-Material
-	I-Material
billion	I-Material
-	I-Material
word	I-Material
corpus	I-Material
,	O
adding	O
additional	O
capacity	O
seems	O
to	O
produce	O
diminishing	O
returns	O
as	O
the	O
number	O
of	O
parameters	O
in	O
the	O
MoE	B-Method
layer	O
exceeds	O
1	O
billion	O
,	O
as	O
can	O
be	O
seen	O
in	O
Figure	O
2	O
-	O
left	O
.	O
	
We	O
hypothesized	O
that	O
for	O
a	O
larger	O
training	O
set	O
,	O
even	O
higher	O
capacities	O
would	O
produce	O
significant	O
quality	B-Metric
improvements	I-Metric
.	O
	
We	O
constructed	O
a	O
similar	O
training	O
set	O
consisting	O
of	O
shuffled	O
unique	O
sentences	O
from	O
Google	B-Material
's	I-Material
internal	I-Material
news	I-Material
corpus	I-Material
,	O
totalling	O
roughly	O
100	O
billion	O
words	O
.	O
	
Similarly	O
to	O
the	O
previous	O
section	O
,	O
we	O
tested	O
a	O
series	O
of	O
models	O
with	O
similar	O
computational	B-Metric
costs	I-Metric
of	O
about	O
8	O
million	O
ops	O
/	O
timestep	O
.	O
	
In	O
addition	O
to	O
a	O
baseline	O
LSTM	B-Method
model	O
,	O
we	O
trained	O
models	O
augmented	O
with	O
MoE	B-Method
layers	I-Method
containing	O
[	O
reference	O
]	O
experts	O
.	O
	
This	O
corresponds	O
to	O
up	O
to	O
137	O
billion	O
parameters	O
in	O
the	O
MoE	B-Method
layer	O
.	O
	
Details	O
on	O
architecture	O
,	O
training	O
,	O
and	O
results	O
are	O
given	O
in	O
Appendix	O
D.	O
	
Results	O
:	O
Figure	O
3	O
shows	O
test	O
perplexity	O
as	O
a	O
function	O
of	O
capacity	O
after	O
training	O
on	O
10	O
billion	O
words	O
(	O
top	O
line	O
)	O
and	O
100	O
billion	O
words	O
(	O
bottom	O
line	O
)	O
.	O
	
When	O
training	O
over	O
the	O
full	O
100	O
billion	O
words	O
,	O
test	O
perplexity	O
improves	O
significantly	O
up	O
to	O
65536	O
experts	O
(	O
68	O
billion	O
parameters	O
)	O
,	O
dropping	O
39	O
%	O
lower	O
than	O
the	O
computationally	O
matched	O
baseline	O
,	O
but	O
degrades	O
at	O
131072	O
experts	O
,	O
possibly	O
a	O
result	O
of	O
too	O
much	O
sparsity	O
.	O
	
The	O
widening	O
gap	O
between	O
the	O
two	O
lines	O
demonstrates	O
(	O
unsurprisingly	O
)	O
that	O
increased	O
model	O
capacity	O
helps	O
more	O
on	O
larger	O
training	O
sets	O
.	O
	
Even	O
at	O
65536	O
experts	O
(	O
99.994	O
%	O
layer	B-Metric
sparsity	I-Metric
)	O
,	O
computational	B-Metric
efficiency	I-Metric
for	O
the	O
model	O
stays	O
at	O
a	O
respectable	O
0.72	O
TFLOPS	O
/	O
GPU	O
.	O
	
section	O
:	O
MACHINE	B-Task
TRANSLATION	I-Task
(	O
SINGLE	B-Task
LANGUAGE	I-Task
PAIR	I-Task
)	O
	
Model	B-Method
Architecture	I-Method
:	O
	
Our	O
model	O
was	O
a	O
modified	O
version	O
of	O
the	O
GNMT	B-Method
model	I-Method
described	O
in	O
[	O
reference	O
]	O
.	O
To	O
reduce	O
computation	O
,	O
we	O
decreased	O
the	O
number	O
of	O
LSTM	B-Method
layers	O
in	O
the	O
encoder	O
and	O
decoder	O
from	O
9	O
and	O
8	O
to	O
3	O
and	O
2	O
respectively	O
.	O
	
We	O
inserted	O
MoE	B-Method
layers	O
in	O
both	O
the	O
encoder	B-Method
(	O
between	O
layers	O
2	O
and	O
3	O
)	O
and	O
the	O
decoder	O
(	O
between	O
layers	O
1	O
and	O
2	O
)	O
.	O
	
Each	O
MoE	B-Method
layer	O
contained	O
up	O
to	O
2048	O
experts	O
each	O
with	O
about	O
two	O
million	O
parameters	O
,	O
adding	O
a	O
total	O
of	O
about	O
8	O
billion	O
parameters	O
to	O
the	O
models	O
.	O
	
Further	O
details	O
on	O
model	B-Method
architecture	I-Method
,	O
testing	O
procedure	O
and	O
results	O
can	O
be	O
found	O
in	O
Appendix	O
E.	O
	
Datasets	O
:	O
	
We	O
benchmarked	O
our	O
method	O
on	O
the	O
WMT'14	B-Material
En→Fr	I-Material
and	O
En→De	B-Material
corpora	I-Material
,	O
whose	O
training	O
sets	O
have	O
36	O
M	O
sentence	O
pairs	O
and	O
5	O
M	O
sentence	O
pairs	O
,	O
respectively	O
.	O
	
The	O
experimental	O
protocols	O
were	O
also	O
similar	O
to	O
those	O
in	O
[	O
reference	O
]	O
:	O
newstest2014	O
was	O
used	O
as	O
the	O
test	O
set	O
to	O
compare	O
against	O
previous	O
work	O
[	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
,	O
while	O
the	O
combination	O
of	O
newstest2012	O
and	O
newstest2013	O
was	O
used	O
as	O
the	O
development	O
set	O
.	O
	
We	O
also	O
tested	O
the	O
same	O
model	O
on	O
a	O
Google	B-Material
's	I-Material
Production	I-Material
English	I-Material
to	I-Material
French	I-Material
data	I-Material
.	O
	
[	O
reference	O
]	O
2.79	O
39.22	O
214	O
M	O
278	O
M	O
6	O
days	O
/	O
96	O
k80s	O
GNMT	B-Method
+	O
RL	B-Method
[	O
reference	O
]	O
2.96	O
	
39.92	O
214	O
M	O
278	O
M	O
6	O
days	O
/	O
96	O
k80s	O
PBMT	O
[	O
reference	O
]	O
37.0	O
LSTM	B-Method
(	O
6	B-Method
-	I-Method
layer	I-Method
)	O
	
[	O
reference	O
]	O
31.5	O
LSTM	B-Method
(	O
6	O
-	O
layer	O
+	O
PosUnk	O
)	O
[	O
reference	O
]	O
33.1	O
DeepAtt	O
[	O
reference	O
]	O
37.7	O
DeepAtt	O
+	O
PosUnk	O
[	O
reference	O
]	O
39.2	O
[	O
reference	O
]	O
5.25	O
24.91	O
214	O
M	O
278	O
M	O
1	O
	
day	O
/	O
96	O
k80s	O
GNMT	B-Method
+	O
RL	B-Method
[	O
reference	O
]	O
	
8.08	O
24.66	O
214	O
M	O
278	O
M	O
1	O
	
day	O
/	O
96	O
k80s	O
PBMT	O
[	O
reference	O
]	O
	
20.7	O
DeepAtt	O
[	O
reference	O
]	O
	
20.6	O
Results	O
:	O
Tables	O
2	O
,	O
3	O
,	O
and	O
4	O
show	O
the	O
results	O
of	O
our	O
largest	O
models	O
,	O
compared	O
with	O
published	O
results	O
.	O
	
Our	O
approach	O
achieved	O
BLEU	B-Metric
scores	I-Metric
of	O
40.56	O
and	O
26.03	O
on	O
the	O
WMT'14	B-Material
En→Fr	I-Material
and	O
En→De	B-Material
benchmarks	O
.	O
	
As	O
our	O
models	O
did	O
not	O
use	O
RL	B-Method
refinement	O
,	O
these	O
results	O
constitute	O
significant	O
gains	O
of	O
1.34	O
and	O
1.12	O
BLEU	B-Metric
score	I-Metric
on	O
top	O
of	O
the	O
strong	O
baselines	O
in	O
[	O
reference	O
]	O
.	O
	
The	O
perplexity	B-Metric
scores	I-Metric
are	O
also	O
better	O
.	O
	
2	O
	
On	O
the	O
Google	B-Material
Production	I-Material
dataset	I-Material
,	O
our	O
model	O
achieved	O
1.01	O
higher	O
test	O
BLEU	B-Metric
score	I-Metric
even	O
after	O
training	O
for	O
only	O
one	O
sixth	O
of	O
the	O
time	O
.	O
	
section	O
:	O
MULTILINGUAL	B-Task
MACHINE	I-Task
TRANSLATION	I-Task
	
Dataset	O
:	O
(	O
Johnson	O
et	O
al	O
.	O
,	O
2016	O
)	O
train	O
a	O
single	O
GNMT	B-Method
[	O
reference	O
]	O
)	O
	
model	O
on	O
a	O
very	O
large	O
combined	O
dataset	O
of	O
twelve	O
language	O
pairs	O
.	O
	
Results	O
are	O
somewhat	O
worse	O
than	O
those	O
for	O
12	O
separately	O
trained	O
single	O
-	O
pair	O
GNMT	B-Method
models	O
.	O
	
This	O
is	O
not	O
surprising	O
,	O
given	O
that	O
the	O
twelve	O
models	O
have	O
12	O
times	O
the	O
capacity	O
and	O
twelve	O
times	O
the	O
aggregate	O
training	O
of	O
the	O
one	O
model	O
.	O
	
We	O
repeat	O
this	O
experiment	O
with	O
a	O
single	O
MoE	B-Method
-	O
augmented	O
model	O
.	O
	
See	O
Appendix	O
E	O
for	O
details	O
on	O
model	B-Method
architecture	I-Method
.	O
	
We	O
train	O
our	O
model	O
on	O
the	O
same	O
dataset	O
as	O
[	O
reference	O
]	O
and	O
process	O
the	O
same	O
number	O
of	O
training	O
examples	O
(	O
about	O
3	O
billion	O
sentence	O
pairs	O
)	O
.	O
	
Our	O
training	B-Metric
time	I-Metric
was	O
shorter	O
due	O
to	O
the	O
lower	O
computational	B-Metric
budget	I-Metric
of	O
our	O
model	O
.	O
	
section	O
:	O
Results	O
:	O
	
Results	O
for	O
the	O
single	O
-	O
pair	O
GNMT	B-Method
models	O
,	O
the	O
multilingual	O
GNMT	B-Method
model	O
and	O
the	O
multilingual	O
MoE	B-Method
model	O
are	O
given	O
in	O
Table	O
5	O
.	O
	
The	O
MoE	B-Method
model	O
achieves	O
19	O
%	O
lower	O
perplexity	B-Metric
on	O
the	O
dev	O
set	O
than	O
the	O
multilingual	O
GNMT	B-Method
model	O
.	O
	
On	O
BLEU	B-Metric
score	I-Metric
,	O
the	O
MoE	B-Method
model	O
significantly	O
beats	O
the	O
multilingual	O
GNMT	B-Method
model	O
on	O
11	O
of	O
the	O
12	O
language	O
pairs	O
(	O
by	O
as	O
much	O
as	O
5.84	O
points	O
)	O
,	O
and	O
even	O
beats	O
the	O
monolingual	O
GNMT	B-Method
models	O
on	O
8	O
of	O
12	O
language	O
pairs	O
.	O
	
The	O
poor	O
performance	O
on	O
English	B-Material
→	I-Material
Korean	I-Material
seems	O
to	O
be	O
a	O
result	O
of	O
severe	O
overtraining	O
,	O
as	O
for	O
the	O
rarer	O
language	O
pairs	O
a	O
small	O
number	O
of	O
real	O
examples	O
were	O
highly	O
oversampled	O
in	O
the	O
training	O
corpus	O
.	O
	
section	O
:	O
CONCLUSION	O
	
This	O
work	O
is	O
the	O
first	O
to	O
demonstrate	O
major	O
wins	O
from	O
conditional	B-Method
computation	I-Method
in	O
deep	B-Task
networks	I-Task
.	O
	
We	O
carefully	O
identified	O
the	O
design	O
considerations	O
and	O
challenges	O
of	O
conditional	B-Task
computing	I-Task
and	O
addressed	O
them	O
with	O
a	O
combination	O
of	O
algorithmic	B-Method
and	I-Method
engineering	I-Method
solutions	I-Method
.	O
	
While	O
we	O
focused	O
on	O
text	O
,	O
conditional	B-Task
computation	I-Task
may	O
help	O
in	O
other	O
domains	O
as	O
well	O
,	O
provided	O
sufficiently	O
large	O
training	O
sets	O
.	O
	
We	O
look	O
forward	O
to	O
seeing	O
many	O
novel	O
implementations	O
and	O
applications	O
of	O
conditional	B-Task
computation	I-Task
in	O
the	O
years	O
to	O
come	O
.	O
	
section	O
:	O
ACKNOWLEDGMENTS	O
	
We	O
would	O
like	O
to	O
thank	O
all	O
of	O
the	O
members	O
of	O
the	O
Google	O
Brain	O
and	O
Google	O
Translate	O
teams	O
who	O
helped	O
us	O
with	O
this	O
project	O
,	O
in	O
particular	O
Zhifeng	O
Chen	O
,	O
Yonghui	O
Wu	O
,	O
and	O
Melvin	O
Johnson	O
.	O
	
Thanks	O
also	O
to	O
our	O
anonymous	O
ICLR	O
reviewers	O
for	O
the	O
helpful	O
suggestions	O
on	O
making	O
this	O
paper	O
better	O
.	O
	
section	O
:	O
APPENDICES	O
A	O
LOAD	B-Method
-	I-Method
BALANCING	I-Method
LOSS	I-Method
	
As	O
discussed	O
in	O
section	O
4	O
,	O
for	O
load	B-Task
-	I-Task
balancing	I-Task
purposes	I-Task
,	O
we	O
want	O
to	O
define	O
an	O
additional	O
loss	O
function	O
to	O
encourage	O
experts	O
to	O
receive	O
roughly	O
equal	O
numbers	O
of	O
training	O
examples	O
.	O
	
Unfortunately	O
,	O
the	O
number	O
of	O
examples	O
received	O
by	O
an	O
expert	O
is	O
a	O
discrete	O
quantity	O
,	O
so	O
it	O
can	O
not	O
be	O
used	O
in	O
backpropagation	B-Method
.	O
	
Instead	O
,	O
we	O
define	O
a	O
smooth	B-Method
estimator	I-Method
Load	I-Method
(	I-Method
X	I-Method
)	I-Method
of	O
the	O
number	O
of	O
examples	O
assigned	O
to	O
each	O
expert	O
for	O
a	O
batch	O
X	O
of	O
inputs	O
.	O
	
The	O
smoothness	O
allows	O
us	O
to	O
back	O
-	O
propagate	O
gradients	O
through	O
the	O
estimator	O
.	O
	
This	O
is	O
the	O
purpose	O
of	O
the	O
noise	O
term	O
in	O
the	O
gating	B-Method
function	I-Method
.	O
	
We	O
define	O
P	O
(	O
x	O
,	O
i	O
)	O
as	O
the	O
probability	O
that	O
G	O
(	O
x	O
)	O
i	O
is	O
nonzero	O
,	O
given	O
a	O
new	O
random	O
choice	O
of	O
noise	O
on	O
element	O
i	O
,	O
but	O
keeping	O
the	O
already	O
-	O
sampled	O
choices	O
of	O
noise	O
on	O
the	O
other	O
elements	O
.	O
	
To	O
compute	O
P	O
(	O
x	O
,	O
i	O
)	O
,	O
we	O
note	O
that	O
the	O
G	O
(	O
x	O
)	O
	
i	O
is	O
nonzero	O
if	O
and	O
only	O
if	O
H	O
(	O
x	O
)	O
	
i	O
is	O
greater	O
than	O
the	O
k	O
th	O
-	O
greatest	O
element	O
of	O
H	O
(	O
x	O
)	O
excluding	O
itself	O
.	O
	
The	O
probability	O
works	O
out	O
to	O
be	O
:	O
	
Where	O
kth_excluding	O
(	O
v	O
,	O
k	O
,	O
i	O
)	O
means	O
the	O
kth	O
highest	O
component	O
of	O
v	O
,	O
excluding	O
component	O
i.	O
Simplifying	O
,	O
we	O
get	O
:	O
	
Where	O
Φ	O
is	O
the	O
CDF	O
of	O
the	O
standard	B-Method
normal	I-Method
distribution	I-Method
.	O
	
We	O
can	O
now	O
define	O
the	O
load	O
loss	O
to	O
be	O
the	O
square	O
of	O
the	O
coefficient	O
of	O
variation	O
of	O
the	O
load	O
vector	O
,	O
multiplied	O
by	O
a	O
hand	O
-	O
tuned	O
scaling	O
factor	O
w	O
load	O
.	O
	
Initial	B-Task
Load	I-Task
Imbalance	I-Task
:	O
To	O
avoid	O
out	O
-	O
of	O
-	O
memory	O
errors	O
,	O
we	O
need	O
to	O
initialize	O
the	O
network	O
in	O
a	O
state	O
of	O
approximately	O
equal	O
expert	O
load	O
(	O
since	O
the	O
soft	O
constraints	O
need	O
some	O
time	O
to	O
work	O
)	O
.	O
	
To	O
accomplish	O
this	O
,	O
we	O
initialize	O
the	O
matrices	O
W	O
g	O
and	O
W	O
noise	O
to	O
all	O
zeros	O
,	O
which	O
yields	O
no	O
signal	O
and	O
some	O
noise	O
.	O
	
section	O
:	O
Experiments	O
:	O
	
We	O
trained	O
a	O
set	O
of	O
models	O
with	O
identical	B-Method
architecture	I-Method
(	O
the	O
MoE	B-Method
-	O
256	O
model	O
described	O
in	O
Appendix	O
C	O
)	O
,	O
using	O
different	O
values	O
of	O
w	O
importance	O
and	O
w	O
load	O
.	O
	
We	O
trained	O
each	O
model	O
for	O
10	O
epochs	O
,	O
then	O
measured	O
perplexity	B-Method
on	O
the	O
test	O
set	O
.	O
	
We	O
also	O
measured	O
the	O
coefficients	O
of	O
variation	O
in	O
Importance	O
and	O
Load	O
,	O
as	O
well	O
as	O
ratio	O
of	O
the	O
load	O
on	O
the	O
most	O
overloaded	O
expert	O
to	O
the	O
average	O
load	O
.	O
	
This	O
last	O
value	O
is	O
significant	O
for	O
load	B-Task
balancing	I-Task
purposes	I-Task
on	O
distributed	B-Task
hardware	I-Task
.	O
	
All	O
of	O
these	O
metrics	O
were	O
averaged	O
over	O
several	O
training	O
batches	O
.	O
	
Results	O
:	O
	
Results	O
are	O
reported	O
in	O
Table	O
6	O
.	O
	
All	O
the	O
combinations	O
containing	O
at	O
least	O
one	O
the	O
two	O
losses	O
led	O
to	O
very	O
similar	O
model	B-Metric
quality	I-Metric
,	O
where	O
having	O
no	O
loss	O
was	O
much	O
worse	O
.	O
	
Models	O
with	O
higher	O
values	O
of	O
w	O
load	O
had	O
lower	O
loads	O
on	O
the	O
most	O
overloaded	O
expert	O
.	O
	
section	O
:	O
B	O
HIERACHICAL	B-Method
MIXTURE	I-Method
OF	I-Method
EXPERTS	I-Method
	
If	O
the	O
number	O
of	O
experts	O
is	O
very	O
large	O
,	O
we	O
can	O
reduce	O
the	O
branching	B-Metric
factor	I-Metric
by	O
using	O
a	O
two	O
-	O
level	B-Method
hierarchical	I-Method
MoE.	I-Method
	
In	O
a	O
hierarchical	O
MoE	B-Method
,	O
a	O
primary	B-Method
gating	I-Method
network	I-Method
chooses	O
a	O
sparse	B-Method
weighted	I-Method
combination	I-Method
of	O
"	O
experts	O
"	O
,	O
each	O
of	O
which	O
is	O
itself	O
a	O
secondary	O
mixture	O
-	O
of	O
-	O
experts	O
with	O
its	O
own	O
gating	B-Method
network	I-Method
.	O
	
3	O
	
If	O
the	O
hierarchical	O
MoE	B-Method
consists	O
of	O
a	O
groups	O
of	O
b	O
experts	O
each	O
,	O
we	O
denote	O
the	O
primary	B-Method
gating	I-Method
network	I-Method
by	O
G	O
primary	O
,	O
the	O
secondary	B-Method
gating	I-Method
networks	I-Method
by	O
(	O
G	O
1	O
,	O
G	O
2	O
..	O
	
G	O
a	O
)	O
,	O
and	O
the	O
expert	B-Method
networks	I-Method
by	O
(	O
E	O
0	O
,	O
0	O
,	O
E	O
0	O
,	O
1	O
..	O
	
E	O
a	O
,	O
b	O
)	O
.	O
	
The	O
output	O
of	O
the	O
MoE	B-Method
is	O
given	O
by	O
:	O
	
Our	O
metrics	O
of	O
expert	B-Task
utilization	I-Task
change	O
to	O
the	O
following	O
:	O
	
Load	O
primary	O
and	O
Load	O
	
i	O
deonte	O
the	O
Load	O
functions	O
for	O
the	O
primary	B-Method
gating	I-Method
network	I-Method
and	O
i	O
th	O
secondary	B-Method
gating	I-Method
network	I-Method
respectively	O
.	O
	
X	O
(	O
i	O
)	O
denotes	O
the	O
subset	O
of	O
X	O
for	O
which	O
G	O
primary	O
(	O
x	O
)	O
	
i	O
>	O
0	O
.	O
	
It	O
would	O
seem	O
simpler	O
to	O
let	O
	
Load	O
H	O
(	O
X	O
)	O
i	O
,	O
j	O
=	O
Load	O
	
i	O
	
(	O
X	O
i	O
)	O
	
j	O
,	O
but	O
this	O
would	O
not	O
have	O
a	O
gradient	O
with	O
respect	O
to	O
the	O
primary	B-Method
gating	I-Method
network	I-Method
,	O
so	O
we	O
use	O
the	O
formulation	O
above	O
.	O
	
section	O
:	O
C	O
1	O
BILLION	B-Task
WORD	I-Task
LANGUAGE	I-Task
MODELING	I-Task
BENCHMARK	I-Task
-	O
EXPERIMENTAL	O
DETAILS	O
C.1	O
8	B-Method
-	I-Method
MILLION	I-Method
-	I-Method
OPERATIONS	I-Method
-	I-Method
PER	I-Method
-	I-Method
TIMESTEP	I-Method
MODELS	I-Method
	
Model	B-Method
Architecture	I-Method
:	O
	
Our	O
model	O
consists	O
of	O
five	O
layers	O
:	O
a	O
word	O
embedding	B-Method
layer	O
,	O
a	O
recurrent	O
Long	B-Method
Short	I-Method
-	I-Method
Term	I-Method
Memory	I-Method
(	O
LSTM	B-Method
)	O
layer	O
[	O
reference	O
][	O
reference	O
]	O
,	O
a	O
MoE	B-Method
layer	O
,	O
a	O
second	O
LSTM	B-Method
layer	O
,	O
and	O
a	O
softmax	B-Method
layer	I-Method
.	O
	
The	O
dimensionality	O
of	O
the	O
embedding	B-Method
layer	O
,	O
the	O
number	O
of	O
units	O
in	O
each	O
LSTM	B-Method
layer	O
,	O
and	O
the	O
input	O
and	O
output	O
dimensionality	O
of	O
the	O
MoE	B-Method
layer	O
are	O
all	O
equal	O
to	O
512	O
.	O
	
For	O
every	O
layer	O
other	O
than	O
the	O
softmax	O
,	O
we	O
apply	O
drouput	B-Method
[	O
reference	O
]	O
to	O
the	O
layer	O
output	O
,	O
dropping	O
each	O
activation	O
with	O
probability	O
DropP	O
rob	O
,	O
otherwise	O
dividing	O
by	O
(	O
1	O
−	O
DropP	O
rob	O
)	O
.	O
	
After	O
dropout	O
,	O
the	O
output	O
of	O
the	O
previous	O
layer	O
is	O
added	O
to	O
the	O
layer	O
output	O
.	O
	
This	O
residual	O
connection	O
encourages	O
gradient	B-Method
flow	I-Method
	
[	O
reference	O
]	O
.	O
	
For	O
the	O
hierarchical	O
MoE	B-Method
layers	O
,	O
the	O
first	O
level	O
branching	O
factor	O
was	O
16	O
,	O
corresponding	O
to	O
the	O
number	O
of	O
GPUs	O
in	O
our	O
cluster	O
.	O
	
We	O
use	O
Noisy	B-Method
-	I-Method
Top	I-Method
-	I-Method
K	I-Method
Gating	I-Method
(	O
see	O
Section	O
2.1	O
)	O
with	O
k	O
=	O
4	O
for	O
the	O
ordinary	O
MoE	B-Method
layers	O
and	O
k	O
=	O
2	O
at	O
each	O
level	O
of	O
the	O
hierarchical	O
MoE	B-Method
layers	O
.	O
	
Thus	O
,	O
each	O
example	O
is	O
processed	O
by	O
exactly	O
4	O
experts	O
for	O
a	O
total	O
of	O
4	O
M	O
ops	O
/	O
timestep	O
.	O
	
The	O
two	O
LSTM	B-Method
layers	O
contribute	O
2	O
M	O
ops	O
/	O
timestep	O
each	O
for	O
the	O
desired	O
total	O
of	O
8M.	O
	
section	O
:	O
Computationally	O
-	O
Matched	O
Baselines	O
:	O
	
The	O
MoE	B-Method
-	O
4	O
model	O
does	O
not	O
employ	O
sparsity	O
,	O
since	O
all	O
4	O
experts	O
are	O
always	O
used	O
.	O
	
In	O
addition	O
,	O
we	O
trained	O
four	O
more	O
computationally	O
-	O
matched	B-Method
baseline	I-Method
models	I-Method
with	O
no	O
sparsity	O
:	O
	
•	O
	
MoE	B-Method
-	O
1	O
-	O
Wide	O
	
:	O
	
The	O
MoE	B-Method
layer	O
consists	O
of	O
a	O
single	O
"	O
expert	O
"	O
containing	O
one	O
ReLU	B-Method
-	I-Method
activated	I-Method
hidden	I-Method
layer	I-Method
of	O
size	O
4096	O
.	O
	
•	O
	
MoE	B-Method
-	O
1	O
-	O
Deep	O
:	O
	
The	O
MoE	B-Method
layer	O
consists	O
of	O
a	O
single	O
"	O
expert	O
"	O
containing	O
four	O
ReLU	B-Method
-	I-Method
activated	I-Method
hidden	I-Method
layers	I-Method
,	O
each	O
with	O
size	O
1024	O
.	O
	
•	O
4xLSTM	B-Method
-	I-Method
512	I-Method
:	O
	
We	O
replace	O
the	O
MoE	B-Method
layer	O
with	O
two	O
additional	O
512	O
-	O
unit	O
LSTM	B-Method
layers	O
.	O
	
•	O
	
LSTM	B-Method
-	O
2048	O
-	O
512	O
	
:	O
The	O
model	O
contains	O
one	O
2048	O
-	O
unit	O
LSTM	B-Method
layer	O
(	O
and	O
no	O
MoE	B-Method
)	O
.	O
	
The	O
output	O
of	O
the	O
LSTM	B-Method
is	O
projected	O
down	O
to	O
512	O
dimensions	O
[	O
reference	O
]	O
.	O
The	O
next	O
timestep	O
of	O
the	O
LSTM	B-Method
receives	O
the	O
projected	O
output	O
.	O
	
This	O
is	O
identical	O
to	O
one	O
of	O
the	O
models	O
published	O
in	O
[	O
reference	O
]	O
.	O
We	O
re	O
-	O
ran	O
it	O
to	O
account	O
for	O
differences	O
in	O
training	O
regimen	O
,	O
and	O
obtained	O
results	O
very	O
similar	O
to	O
the	O
published	O
ones	O
.	O
	
Training	O
:	O
The	O
models	O
were	O
trained	O
on	O
a	O
cluster	O
of	O
16	O
K40	B-Method
GPUs	I-Method
using	O
the	O
synchronous	B-Method
method	I-Method
described	O
in	O
Section	O
3	O
.	O
	
Each	O
batch	O
consisted	O
of	O
a	O
set	O
of	O
sentences	O
totaling	O
roughly	O
300	O
,	O
000	O
words	O
.	O
	
In	O
the	O
interest	O
of	O
time	O
,	O
we	O
limited	O
training	O
to	O
10	O
epochs	O
,	O
(	O
27	O
,	O
000	O
steps	O
)	O
.	O
	
Training	B-Task
took	O
12	O
-	O
16	O
hours	O
for	O
all	O
models	O
,	O
except	O
for	O
MoE	B-Method
-	O
4	O
,	O
which	O
took	O
18	O
hours	O
(	O
since	O
all	O
the	O
expert	B-Method
computation	I-Method
was	O
performed	O
on	O
only	O
4	O
of	O
16	O
GPUs	O
)	O
.	O
	
We	O
used	O
the	O
Adam	B-Method
optimizer	I-Method
	
[	O
reference	O
]	O
.	O
	
The	O
base	B-Metric
learning	I-Metric
rate	I-Metric
was	O
increased	O
linearly	O
for	O
the	O
first	O
1000	O
training	O
steps	O
,	O
and	O
decreased	O
after	O
that	O
so	O
as	O
to	O
be	O
proportional	O
to	O
the	O
inverse	O
square	O
root	O
of	O
the	O
step	O
number	O
.	O
	
The	O
Softmax	B-Method
output	I-Method
layer	I-Method
was	O
trained	O
efficiently	O
using	O
importance	B-Method
sampling	I-Method
similarly	O
to	O
the	O
models	O
in	O
[	O
reference	O
]	O
.	O
For	O
each	O
model	O
,	O
we	O
performed	O
a	O
hyper	B-Method
-	I-Method
parmeter	I-Method
search	I-Method
to	O
find	O
the	O
best	O
dropout	O
probability	O
,	O
in	O
increments	O
of	O
0.1	O
.	O
	
To	O
ensure	O
balanced	O
expert	O
utilization	O
we	O
set	O
w	O
importance	O
=	O
0.1	O
and	O
w	O
load	O
=	O
0.1	O
,	O
as	O
described	O
in	O
Section	O
4	O
and	O
Appendix	O
A.	O
	
Results	O
:	O
	
We	O
evaluate	O
our	O
model	O
using	O
perplexity	B-Method
on	O
the	O
holdout	B-Material
dataset	I-Material
,	O
used	O
by	O
[	O
reference	O
][	O
reference	O
]	O
.	O
	
We	O
follow	O
the	O
standard	O
procedure	O
and	O
sum	O
over	O
all	O
the	O
words	O
including	O
the	O
end	O
of	O
sentence	O
symbol	O
.	O
	
Results	O
are	O
reported	O
in	O
Table	O
7	O
.	O
	
For	O
each	O
model	O
,	O
we	O
report	O
the	O
test	B-Metric
perplexity	I-Metric
,	O
the	O
computational	B-Metric
budget	I-Metric
,	O
the	O
parameter	O
counts	O
,	O
the	O
value	O
of	O
DropP	B-Metric
rob	I-Metric
,	O
and	O
the	O
computational	B-Metric
efficiency	I-Metric
.	O
	
section	O
:	O
C.2	O
MORE	O
EXPENSIVE	O
MODELS	O
	
We	O
ran	O
two	O
additional	O
models	O
(	O
MoE	B-Method
-	O
34	O
M	O
and	O
MoE	B-Method
-	O
143	O
M	O
)	O
to	O
investigate	O
the	O
effects	O
of	O
adding	O
more	O
computation	O
in	O
the	O
presence	O
of	O
a	O
large	O
MoE	B-Method
layer	O
.	O
	
These	O
models	O
have	O
computation	B-Metric
budgets	I-Metric
of	O
34	O
M	O
and	O
143	O
M	O
ops	O
/	O
timestep	O
.	O
	
Similar	O
to	O
the	O
models	O
above	O
,	O
these	O
models	O
use	O
a	O
MoE	B-Method
layer	O
between	O
two	O
LSTM	B-Method
layers	O
.	O
	
The	O
dimensionality	O
of	O
the	O
embedding	B-Method
layer	O
,	O
and	O
the	O
input	O
and	O
output	O
dimensionality	O
of	O
the	O
MoE	B-Method
layer	O
are	O
set	O
to	O
1024	O
instead	O
of	O
512	O
.	O
	
For	O
MoE	B-Method
-	O
34	O
M	O
,	O
the	O
LSTM	B-Method
layers	O
have	O
1024	O
units	O
.	O
	
For	O
MoE	B-Method
-	O
143	O
M	O
,	O
the	O
LSTM	B-Method
layers	O
have	O
4096	O
units	O
and	O
an	O
output	O
projection	O
of	O
size	O
1024	O
	
[	O
reference	O
]	O
.	O
MoE	B-Method
-	O
34	O
M	O
uses	O
a	O
hierarchical	O
MoE	B-Method
layer	O
with	O
1024	O
experts	O
,	O
each	O
with	O
a	O
hidden	O
layer	O
of	O
size	O
2048	O
.	O
	
MoE	B-Method
-	O
143	O
	
M	B-Method
uses	O
a	O
hierarchical	O
MoE	B-Method
layer	O
with	O
256	O
experts	O
,	O
each	O
with	O
a	O
hidden	B-Method
layer	I-Method
of	O
size	O
8192	O
.	O
	
Both	O
models	O
have	O
4B	O
parameters	O
in	O
the	O
MoE	B-Method
layers	O
.	O
	
We	O
searched	O
for	O
the	O
best	O
DropP	O
rob	O
for	O
each	O
model	O
,	O
and	O
trained	O
each	O
model	O
for	O
10	O
epochs	O
.	O
	
The	O
two	O
models	O
achieved	O
test	O
perplexity	B-Metric
of	O
31.3	O
and	O
28.0	O
respectively	O
,	O
showing	O
that	O
even	O
in	O
the	O
presence	O
of	O
a	O
large	O
MoE	B-Method
,	O
more	O
computation	O
is	O
still	O
useful	O
.	O
	
Results	O
are	O
reported	O
at	O
the	O
bottom	O
of	O
Table	O
7	O
.	O
	
The	O
larger	O
of	O
the	O
two	O
models	O
has	O
a	O
similar	O
computational	B-Metric
budget	I-Metric
to	O
the	O
best	O
published	O
model	O
from	O
the	O
literature	O
,	O
and	O
training	B-Metric
times	I-Metric
are	O
similar	O
.	O
	
Comparing	O
after	O
10	O
epochs	O
,	O
our	O
model	O
has	O
a	O
lower	O
test	B-Metric
perplexity	I-Metric
by	O
18	O
%	O
.	O
	
section	O
:	O
D	O
100	B-Material
BILLION	I-Material
WORD	I-Material
GOOGLE	I-Material
NEWS	I-Material
CORPUS	I-Material
-	O
EXPERIMENTAL	O
DETAILS	O
	
Model	B-Method
Architecture	I-Method
:	O
	
The	O
models	O
are	O
similar	O
in	O
structure	O
to	O
the	O
8	B-Method
-	I-Method
million	I-Method
-	I-Method
operations	I-Method
-	I-Method
per	I-Method
-	I-Method
timestep	I-Method
models	I-Method
described	O
in	O
the	O
previous	O
section	O
.	O
	
We	O
vary	O
the	O
number	O
of	O
experts	O
between	O
models	O
,	O
using	O
an	O
ordinary	O
MoE	B-Method
layer	O
with	O
32	O
experts	O
and	O
hierarchical	O
MoE	B-Method
layers	O
with	O
256	O
,	O
1024	O
,	O
4096	O
,	O
16384	O
,	O
65536	O
and	O
131072	O
experts	O
.	O
	
For	O
the	O
hierarchical	O
MoE	B-Method
layers	O
,	O
the	O
first	O
level	O
branching	O
factors	O
are	O
[	O
reference	O
]	O
	
Training	O
:	O
	
Models	O
are	O
trained	O
on	O
a	O
cluster	O
of	O
32	O
Tesla	B-Method
K40	I-Method
GPUs	I-Method
,	O
except	O
for	O
the	O
last	O
two	O
models	O
,	O
which	O
are	O
trained	O
on	O
clusters	O
of	O
64	O
and	O
128	O
GPUs	O
so	O
as	O
to	O
have	O
enough	O
memory	O
for	O
all	O
the	O
parameters	O
.	O
	
For	O
all	O
models	O
,	O
training	O
batch	O
sizes	O
are	O
approximately	O
2.5	O
million	O
words	O
.	O
	
Models	O
are	O
trained	O
once	O
-	O
through	O
over	O
about	O
100	O
billion	O
words	O
.	O
	
We	O
implement	O
several	O
memory	B-Method
optimizations	I-Method
in	O
order	O
to	O
fit	O
up	O
to	O
1	O
billion	O
parameters	O
per	O
GPU	O
.	O
	
First	O
,	O
we	O
do	O
not	O
store	O
the	O
activations	O
of	O
the	O
hidden	O
layers	O
of	O
the	O
experts	O
,	O
but	O
instead	O
recompute	O
them	O
on	O
the	O
backwards	O
pass	O
.	O
	
Secondly	O
,	O
we	O
modify	O
the	O
optimizer	B-Method
on	O
the	O
expert	O
parameters	O
to	O
require	O
less	O
auxiliary	O
storage	O
:	O
	
The	O
Adam	B-Method
optimizer	I-Method
[	O
reference	O
]	O
keeps	O
first	O
and	O
second	O
moment	B-Method
estimates	I-Method
of	O
the	O
perparameter	O
gradients	O
.	O
	
This	O
triples	O
the	O
required	O
memory	O
.	O
	
To	O
avoid	O
keeping	O
a	O
first	B-Method
-	I-Method
moment	I-Method
estimator	I-Method
,	O
we	O
set	O
β	O
1	O
=	O
0	O
.	O
	
To	O
reduce	O
the	O
size	O
of	O
the	O
second	B-Method
moment	I-Method
estimator	I-Method
,	O
we	O
replace	O
it	O
with	O
a	O
factored	B-Method
approximation	I-Method
.	O
	
For	O
a	O
matrix	O
of	O
parameters	O
,	O
instead	O
of	O
maintaining	O
a	O
full	B-Method
matrix	I-Method
of	I-Method
second	I-Method
-	I-Method
moment	I-Method
estimators	I-Method
,	O
we	O
maintain	O
vectors	O
of	O
row	O
-	O
wise	O
and	O
column	O
-	O
wise	O
averages	O
of	O
that	O
matrix	O
.	O
	
At	O
each	O
step	O
,	O
the	O
matrix	O
of	O
estimators	B-Method
is	O
taken	O
to	O
be	O
the	O
outer	O
product	O
of	O
those	O
two	O
vectors	O
divided	O
by	O
the	O
mean	O
of	O
either	O
one	O
.	O
	
This	O
technique	O
could	O
similarly	O
be	O
applied	O
to	O
Adagrad	B-Method
[	O
reference	O
]	O
.	O
Results	O
:	O
We	O
evaluate	O
our	O
model	O
using	O
perplexity	B-Method
on	O
a	O
holdout	B-Material
dataset	I-Material
.	O
	
Results	O
are	O
reported	O
in	O
Table	O
8	O
.	O
	
Perplexity	B-Metric
after	O
100	O
billion	O
training	O
words	O
is	O
39	O
%	O
lower	O
for	O
the	O
68	O
-	O
billion	O
-	O
parameter	O
MoE	B-Method
model	O
than	O
for	O
the	O
baseline	B-Method
model	I-Method
.	O
	
It	O
is	O
notable	O
that	O
the	O
measured	O
computational	B-Metric
efficiency	I-Metric
of	O
the	O
largest	O
model	O
(	O
0.30	O
TFLOPS	B-Method
/	O
GPU	B-Method
)	O
is	O
very	O
low	O
compared	O
to	O
the	O
other	O
models	O
.	O
	
This	O
is	O
likely	O
a	O
result	O
of	O
the	O
fact	O
that	O
,	O
for	O
purposes	O
of	O
comparison	O
to	O
the	O
other	O
models	O
,	O
we	O
did	O
not	O
increase	O
the	O
training	B-Metric
batch	I-Metric
size	I-Metric
proportionally	O
to	O
the	O
number	O
of	O
GPUs	O
.	O
	
For	O
comparison	O
,	O
we	O
include	O
results	O
for	O
a	O
computationally	B-Method
matched	I-Method
baseline	I-Method
model	I-Method
consisting	O
of	O
4	O
LSTMs	B-Method
,	O
and	O
for	O
an	O
unpruned	B-Method
5	I-Method
-	I-Method
gram	I-Method
model	I-Method
with	O
Kneser	B-Method
-	I-Method
Ney	I-Method
smoothing	I-Method
[	O
reference	O
]	O
.	O
	
section	O
:	O
E	O
MACHINE	B-Task
TRANSLATION	I-Task
-	O
EXPERIMENTAL	O
DETAILS	O
	
Model	B-Method
Architecture	I-Method
for	O
Single	O
Language	O
Pair	O
MoE	B-Method
Models	O
:	O
	
Our	O
model	O
is	O
a	O
modified	O
version	O
of	O
the	O
GNMT	B-Method
model	I-Method
described	O
in	O
[	O
reference	O
]	O
.	O
To	O
reduce	O
computation	O
,	O
we	O
decrease	O
the	O
number	O
of	O
LSTM	B-Method
layers	O
in	O
the	O
encoder	O
and	O
decoder	O
from	O
9	O
and	O
8	O
to	O
3	O
and	O
2	O
respectively	O
.	O
	
We	O
insert	O
MoE	B-Method
layers	O
in	O
both	O
the	O
encoder	B-Method
(	O
between	O
layers	O
2	O
and	O
3	O
)	O
and	O
the	O
decoder	O
(	O
between	O
layers	O
1	O
and	O
2	O
)	O
.	O
	
We	O
use	O
an	O
attention	B-Method
mechanism	I-Method
between	O
the	O
encoder	B-Method
and	I-Method
decoder	I-Method
,	O
with	O
the	O
first	O
decoder	O
LSTM	B-Method
receiving	O
output	O
from	O
and	O
providing	O
input	O
for	O
the	O
attention	O
5	O
.	O
	
All	O
of	O
the	O
layers	O
in	O
our	O
model	O
have	O
input	O
and	O
output	O
dimensionality	O
of	O
512	O
.	O
	
Our	O
LSTM	B-Method
layers	O
have	O
2048	O
hidden	O
units	O
,	O
with	O
a	O
512	O
-	O
dimensional	O
output	O
projection	O
.	O
	
We	O
add	O
residual	O
connections	O
around	O
all	O
LSTM	B-Method
and	O
MoE	B-Method
layers	O
to	O
encourage	O
gradient	O
flow	O
[	O
reference	O
]	O
.	O
Similar	O
to	O
GNMT	B-Method
,	O
to	O
effectively	O
deal	O
with	O
rare	O
words	O
,	O
we	O
used	O
subword	O
units	O
(	O
also	O
known	O
as	O
"	O
wordpieces	O
"	O
)	O
(	O
Schuster	O
&	O
Nakajima	O
,	O
2012	O
)	O
for	O
inputs	O
and	O
outputs	O
in	O
our	O
system	O
.	O
	
We	O
use	O
a	O
shared	O
source	O
and	O
target	O
vocabulary	O
of	O
32	O
K	O
wordpieces	O
.	O
	
We	O
also	O
used	O
the	O
same	O
beam	B-Method
search	I-Method
technique	I-Method
as	O
proposed	O
in	O
[	O
reference	O
]	O
.	O
	
We	O
train	O
models	O
with	O
different	O
numbers	O
of	O
experts	O
in	O
the	O
MoE	B-Method
layers	O
.	O
	
In	O
addition	O
to	O
a	O
baseline	B-Method
model	I-Method
with	O
no	O
MoE	B-Method
layers	O
,	O
we	O
train	O
models	O
with	O
flat	O
MoE	B-Method
layers	O
containing	O
32	O
experts	O
,	O
and	O
models	O
with	O
hierarchical	O
MoE	B-Method
layers	O
containing	O
512	O
and	O
2048	O
experts	O
.	O
	
The	O
flat	O
MoE	B-Method
layers	O
use	O
k	O
=	O
4	O
and	O
the	O
hierarchical	O
MoE	B-Method
models	O
use	O
k	O
=	O
2	O
at	O
each	O
level	O
of	O
the	O
gating	B-Method
network	I-Method
.	O
	
Thus	O
,	O
each	O
input	O
is	O
processed	O
by	O
exactly	O
4	O
experts	O
in	O
each	O
MoE	B-Method
layer	O
.	O
	
Each	O
expert	O
in	O
the	O
MoE	B-Method
layer	O
is	O
a	O
feed	B-Method
forward	I-Method
network	I-Method
with	O
one	O
hidden	B-Method
layer	I-Method
of	O
size	O
2048	O
and	O
ReLU	B-Method
activation	I-Method
.	O
	
Thus	O
,	O
each	O
expert	O
contains	O
[	O
512	O
*	O
2048	O
]	O
+	O
	
[	O
2048	O
*	O
512	O
]	O
=	O
	
2	O
M	O
parameters	O
.	O
	
The	O
output	O
of	O
the	O
MoE	B-Method
layer	O
is	O
passed	O
through	O
a	O
sigmoid	B-Method
function	I-Method
.	O
	
We	O
use	O
the	O
strictly	B-Method
-	I-Method
balanced	I-Method
gating	I-Method
function	I-Method
described	O
in	O
Appendix	O
F.	O
	
section	O
:	O
Model	B-Method
Architecture	I-Method
for	O
Multilingual	O
MoE	B-Method
Model	O
:	O
	
We	O
used	O
the	O
same	O
model	B-Method
architecture	I-Method
as	O
for	O
the	O
single	B-Method
-	I-Method
language	I-Method
-	I-Method
pair	I-Method
models	I-Method
,	O
with	O
the	O
following	O
exceptions	O
:	O
We	O
used	O
noisy	B-Method
-	I-Method
top	I-Method
-	I-Method
k	I-Method
gating	I-Method
as	O
described	O
in	O
Section	O
2.1	O
,	O
not	O
the	O
scheme	O
from	O
	
Appendix	O
F.	O
The	O
MoE	B-Method
layers	I-Method
in	O
the	O
encoder	B-Method
and	I-Method
decoder	I-Method
are	O
non	O
-	O
hierarchical	B-Method
MoEs	I-Method
with	O
n	O
=	O
512	O
experts	O
,	O
and	O
k	O
=	O
2	O
.	O
	
Each	O
expert	O
has	O
a	O
larger	O
hidden	O
layer	O
of	O
size	O
8192	O
.	O
	
This	O
doubles	O
the	O
amount	O
of	O
computation	O
in	O
the	O
MoE	B-Method
layers	O
,	O
raising	O
the	O
computational	B-Metric
budget	I-Metric
of	O
the	O
entire	O
model	O
from	O
85	O
M	O
to	O
102	O
M	O
ops	O
/	O
timestep	O
.	O
	
Training	O
:	O
	
We	O
trained	O
our	O
networks	O
using	O
the	O
Adam	B-Method
optimizer	I-Method
	
[	O
reference	O
]	O
.	O
	
The	O
base	O
learning	B-Metric
rate	I-Metric
was	O
increased	O
linearly	O
for	O
the	O
first	O
2000	O
training	O
steps	O
,	O
held	O
constant	O
for	O
an	O
additional	O
8000	O
steps	O
,	O
and	O
decreased	O
after	O
that	O
so	O
as	O
to	O
be	O
proportional	O
to	O
the	O
inverse	O
square	O
root	O
of	O
the	O
step	O
number	O
.	O
	
For	O
the	O
single	B-Task
-	I-Task
language	I-Task
-	I-Task
pair	I-Task
models	I-Task
,	O
similarly	O
to	O
[	O
reference	O
]	O
,	O
we	O
applied	O
dropout	B-Method
[	O
reference	O
]	O
to	O
the	O
output	O
of	O
all	O
embedding	B-Method
,	O
LSTM	B-Method
and	O
MoE	B-Method
layers	I-Method
,	O
using	O
DropP	O
rob	O
=	O
0.4	O
.	O
	
Training	B-Task
was	O
done	O
synchronously	O
on	O
a	O
cluster	O
of	O
up	O
to	O
64	O
GPUs	O
as	O
described	O
in	O
section	O
3	O
.	O
	
Each	O
training	O
batch	O
consisted	O
of	O
a	O
set	O
of	O
sentence	O
pairs	O
containing	O
roughly	O
16000	O
words	O
per	O
GPU	O
.	O
	
To	O
ensure	O
balanced	O
expert	O
utilization	O
we	O
set	O
w	O
importance	O
=	O
0.01	O
and	O
w	O
load	O
=	O
0.01	O
,	O
as	O
described	O
in	O
Section	O
4	O
and	O
Appendix	O
A.	O
	
section	O
:	O
Metrics	B-Metric
:	O
	
We	O
evaluated	O
our	O
models	O
using	O
the	O
perplexity	B-Method
and	O
the	O
standard	O
BLEU	B-Metric
score	I-Metric
metric	O
.	O
	
We	O
reported	O
tokenized	O
BLEU	B-Metric
score	I-Metric
as	O
computed	O
by	O
the	O
multi	B-Method
-	I-Method
bleu.pl	I-Method
script	I-Method
,	O
downloaded	O
from	O
the	O
public	O
implementation	O
of	O
Moses	B-Method
(	O
on	O
Github	O
)	O
,	O
which	O
was	O
also	O
used	O
in	O
[	O
reference	O
]	O
.	O
Tables	O
2	O
,	O
3	O
and	O
4	O
in	O
Section	O
5.3	O
show	O
comparisons	O
of	O
our	O
results	O
to	O
other	O
published	O
methods	O
.	O
	
Figure	O
4	O
shows	O
test	O
perplexity	O
as	O
a	O
function	O
of	O
number	O
of	O
words	O
in	O
the	O
(	O
training	O
data	O
's	O
)	O
source	O
sentences	O
processed	O
for	O
models	O
with	O
different	O
numbers	O
of	O
experts	O
.	O
	
As	O
can	O
be	O
seen	O
from	O
the	O
Figure	O
,	O
as	O
we	O
increased	O
the	O
number	O
of	O
experts	O
to	O
approach	O
2048	O
,	O
the	O
test	O
perplexity	O
of	O
our	O
model	O
continued	O
to	O
improve	O
.	O
	
Figure	O
4	O
:	O
Perplexity	B-Metric
on	O
WMT'14	O
En→	O
	
Fr	O
(	O
left	O
)	O
and	O
Google	O
Production	O
En→	O
	
Fr	O
(	O
right	O
)	O
datasets	O
as	O
a	O
function	O
of	O
number	O
of	O
words	O
processed	O
.	O
	
The	O
large	O
differences	O
between	O
models	O
at	O
the	O
beginning	O
of	O
training	O
are	O
due	O
to	O
different	O
batch	O
sizes	O
.	O
	
All	O
models	O
incur	O
the	O
same	O
computational	O
budget	O
(	O
85	O
M	O
ops	O
/	O
timestep	O
)	O
except	O
the	O
one	O
with	O
no	O
experts	O
.	O
	
section	O
:	O
Results	O
:	O
	
We	O
found	O
that	O
the	O
experts	O
indeed	O
become	O
highly	O
specialized	O
by	O
syntax	O
and	O
/	O
or	O
semantics	O
,	O
as	O
can	O
be	O
seen	O
in	O
Table	O
9	O
.	O
	
For	O
example	O
,	O
one	O
expert	O
is	O
used	O
when	O
the	O
indefinite	O
article	O
"	O
a	O
"	O
introduces	O
the	O
direct	O
object	O
in	O
a	O
verb	O
phrase	O
indicating	O
importance	O
or	O
leadership	O
.	O
	
section	O
:	O
F	O
STRICTLY	B-Method
BALANCED	I-Method
GATING	I-Method
	
Due	O
to	O
some	O
peculiarities	O
in	O
our	O
infrastructure	O
which	O
have	O
since	O
been	O
fixed	O
,	O
at	O
the	O
time	O
we	O
ran	O
some	O
of	O
the	O
machine	B-Task
translation	I-Task
experiments	O
,	O
our	O
models	O
ran	O
faster	O
if	O
every	O
expert	O
received	O
exactly	O
the	O
same	O
batch	O
size	O
.	O
	
To	O
accommodate	O
this	O
,	O
we	O
used	O
a	O
different	O
gating	B-Method
function	I-Method
which	O
we	O
describe	O
below	O
.	O
	
Recall	O
that	O
we	O
define	O
the	O
softmax	O
gating	O
function	O
to	O
be	O
:	O
	
Sparse	B-Method
Gating	I-Method
(	O
alternate	B-Method
formulation	I-Method
)	O
:	O
	
To	O
obtain	O
a	O
sparse	O
gating	O
vector	O
,	O
we	O
multiply	O
G	O
σ	O
	
(	O
x	O
)	O
component	O
-	O
wise	O
with	O
a	O
sparse	B-Method
mask	I-Method
M	I-Method
(	O
G	O
σ	O
(	O
x	O
)	O
)	O
and	O
normalize	O
the	O
output	O
.	O
	
The	O
mask	O
itself	O
is	O
a	O
function	O
of	O
G	O
σ	O
(	O
x	O
)	O
and	O
specifies	O
which	O
experts	O
are	O
assigned	O
to	O
each	O
input	O
example	O
:	O
	
As	O
our	O
experiments	O
suggest	O
and	O
also	O
observed	O
in	O
[	O
reference	O
]	O
,	O
using	O
a	O
batchwise	B-Method
function	I-Method
during	O
training	B-Method
(	O
such	O
as	O
M	B-Method
batchwise	I-Method
)	O
requires	O
modifications	O
to	O
the	O
inference	B-Task
when	O
we	O
may	O
not	O
have	O
a	O
large	O
batch	O
of	O
examples	O
.	O
	
Our	O
solution	O
to	O
this	O
is	O
to	O
train	O
a	O
vector	B-Method
T	I-Method
of	I-Method
per	I-Method
-	I-Method
expert	I-Method
threshold	I-Method
values	I-Method
to	O
approximate	O
the	O
effects	O
of	O
the	O
batchwise	O
mask	O
.	O
	
We	O
use	O
the	O
following	O
mask	O
at	O
inference	O
time	O
:	O
	
To	O
learn	O
the	O
threshold	O
values	O
,	O
we	O
apply	O
an	O
additional	O
loss	O
at	O
training	O
time	O
which	O
is	O
minimized	O
when	O
the	O
batchwise	O
mask	O
and	O
the	O
threshold	O
mask	O
are	O
identical	O
.	O
	
G	O
ATTENTION	B-Method
FUNCTION	I-Method
	
The	O
attention	B-Method
mechanism	I-Method
described	O
in	O
GNMT	B-Method
[	O
reference	O
]	O
)	O
involves	O
a	O
learned	O
"	O
Attention	B-Method
Function	I-Method
"	O
A	O
(	O
x	O
i	O
,	O
y	O
j	O
)	O
which	O
takes	O
a	O
"	O
source	O
vector	O
"	O
x	O
i	O
and	O
a	O
"	O
target	O
vector	O
"	O
y	O
j	O
,	O
and	O
must	O
be	O
computed	O
for	O
every	O
source	O
time	O
step	O
i	O
and	O
target	O
time	O
step	O
	
j.	O
	
In	O
GNMT	B-Method
,	O
the	O
attention	B-Method
function	I-Method
is	O
implemented	O
as	O
a	O
feed	B-Method
forward	I-Method
neural	I-Method
network	I-Method
with	O
a	O
hidden	O
layer	O
of	O
size	O
	
n.	O
	
It	O
can	O
be	O
expressed	O
as	O
:	O
	
Where	O
U	O
and	O
W	O
are	O
trainable	O
weight	O
matrices	O
and	O
V	O
is	O
a	O
trainable	O
weight	O
vector	O
.	O
	
For	O
performance	O
reasons	O
,	O
in	O
our	O
models	O
,	O
we	O
used	O
a	O
slightly	O
different	O
attention	O
function	O
:	O
	
With	O
our	O
attention	B-Method
function	I-Method
,	O
we	O
can	O
simultaneously	O
compute	O
the	O
attention	O
function	O
on	O
multiple	O
source	O
time	O
steps	O
and	O
multiple	O
target	O
time	O
steps	O
using	O
optimized	O
matrix	B-Method
multiplications	I-Method
.	O
	
We	O
found	O
little	O
difference	O
in	O
quality	O
between	O
the	O
two	O
functions	O
.	O
	
section	O
:	O
	
document	O
:	O
Triplet	B-Method
Probabilistic	I-Method
Embedding	I-Method
for	O
Face	B-Task
Verification	I-Task
and	O
Clustering	B-Task
	
Despite	O
significant	O
progress	O
made	O
over	O
the	O
past	O
twenty	O
five	O
years	O
,	O
unconstrained	B-Task
face	I-Task
verification	I-Task
remains	O
a	O
challenging	O
problem	O
.	O
	
This	O
paper	O
proposes	O
an	O
approach	O
that	O
couples	O
a	O
deep	O
CNN	B-Method
-	O
based	O
approach	O
with	O
a	O
low	B-Method
-	I-Method
dimensional	I-Method
discriminative	I-Method
embedding	I-Method
step	I-Method
,	O
learned	O
using	O
triplet	O
probability	O
constraints	O
to	O
address	O
the	O
unconstrained	B-Task
face	I-Task
verification	I-Task
problem	I-Task
.	O
	
Aside	O
from	O
yielding	O
performance	O
improvements	O
,	O
this	O
embedding	O
provides	O
significant	O
advantages	O
in	O
terms	O
of	O
memory	B-Metric
and	O
for	O
post	B-Task
-	I-Task
processing	I-Task
operations	I-Task
like	O
subject	B-Method
specific	I-Method
clustering	I-Method
.	O
	
Experiments	O
on	O
the	O
challenging	O
IJB	B-Material
-	I-Material
A	I-Material
dataset	I-Material
show	O
that	O
the	O
proposed	O
algorithm	O
performs	O
close	O
to	O
the	O
state	O
of	O
the	O
art	O
methods	O
in	O
verification	B-Metric
and	I-Metric
identification	I-Metric
metrics	I-Metric
,	O
while	O
requiring	O
much	O
less	O
training	O
data	O
and	O
training	B-Metric
/	I-Metric
test	I-Metric
time	I-Metric
.	O
	
The	O
superior	O
performance	O
of	O
the	O
proposed	O
method	O
on	O
the	O
CFP	B-Material
dataset	O
shows	O
that	O
the	O
representation	B-Method
learned	O
by	O
our	O
deep	O
CNN	B-Method
is	O
robust	O
to	O
large	O
pose	O
variation	O
.	O
	
Furthermore	O
,	O
we	O
demonstrate	O
the	O
robustness	O
of	O
deep	O
features	O
to	O
challenges	O
including	O
age	O
,	O
pose	O
,	O
blur	O
and	O
clutter	O
by	O
performing	O
simple	O
clustering	B-Method
experiments	O
on	O
both	O
IJB	B-Material
-	I-Material
A	I-Material
and	O
LFW	B-Material
datasets	I-Material
.	O
	
section	O
:	O
Introduction	O
	
Recently	O
,	O
with	O
the	O
advent	O
of	O
curated	O
face	O
datasets	O
like	O
Labeled	B-Material
faces	I-Material
in	I-Material
the	I-Material
Wild	I-Material
(	O
LFW	B-Material
)	O
and	O
advances	O
in	O
learning	B-Method
algorithms	I-Method
like	O
Deep	B-Method
neural	I-Method
nets	I-Method
,	O
there	O
is	O
more	O
hope	O
that	O
the	O
unconstrained	B-Task
face	I-Task
verification	I-Task
problem	I-Task
can	O
be	O
solved	O
.	O
	
A	O
face	B-Method
verification	I-Method
algorithm	I-Method
compares	O
two	O
given	O
templates	O
that	O
are	O
typically	O
not	O
seen	O
during	O
training	O
.	O
	
Research	O
in	O
face	B-Task
verification	I-Task
has	O
progressed	O
well	O
over	O
the	O
past	O
few	O
years	O
,	O
resulting	O
in	O
the	O
saturation	O
of	O
performance	O
on	O
the	O
LFW	B-Material
dataset	O
,	O
yet	O
the	O
problem	O
of	O
unconstrained	B-Task
face	I-Task
verification	I-Task
remains	O
a	O
challenge	O
.	O
	
This	O
is	O
evident	O
by	O
the	O
performance	O
of	O
traditional	O
algorithms	O
on	O
the	O
publicly	O
available	O
IJB	B-Material
-	I-Material
A	I-Material
dataset	I-Material
(	O
,	O
)	O
that	O
was	O
released	O
recently	O
.	O
	
Moreover	O
,	O
despite	O
the	O
superb	O
performance	O
of	O
CNN	B-Method
-	O
based	O
approaches	O
compared	O
to	O
traditional	O
methods	O
,	O
a	O
drawback	O
of	O
such	O
methods	O
is	O
the	O
long	O
training	B-Metric
time	I-Metric
needed	O
.	O
	
In	O
this	O
work	O
,	O
we	O
present	O
a	O
Deep	B-Method
CNN	I-Method
(	O
DCNN	B-Method
)	O
architecture	O
that	O
ensures	O
faster	O
training	B-Task
,	O
and	O
investigate	O
how	O
much	O
the	O
performance	O
can	O
be	O
improved	O
if	O
we	O
are	O
provided	O
domain	O
specific	O
data	O
.	O
	
Specifically	O
,	O
our	O
contributions	O
are	O
as	O
follows	O
:	O
	
We	O
propose	O
a	O
deep	B-Method
network	I-Method
architecture	I-Method
and	O
a	O
training	B-Method
scheme	I-Method
that	O
ensures	O
faster	O
training	B-Metric
time	I-Metric
.	O
	
We	O
formulate	O
a	O
triplet	B-Method
probability	I-Method
embedding	I-Method
learning	I-Method
method	I-Method
to	O
improve	O
the	O
performance	O
of	O
deep	O
features	O
for	O
face	B-Task
verification	I-Task
and	O
subject	B-Task
clustering	I-Task
.	O
	
During	O
training	B-Task
,	O
we	O
use	O
a	O
publicly	O
available	O
face	O
dataset	O
to	O
train	O
our	O
deep	B-Method
architecture	I-Method
.	O
	
Each	O
image	O
is	O
pre	O
-	O
processed	O
and	O
aligned	O
to	O
a	O
canonical	O
view	O
before	O
passing	O
it	O
to	O
the	O
deep	B-Method
network	I-Method
whose	O
features	O
are	O
used	O
to	O
represent	O
the	O
image	O
.	O
	
In	O
the	O
case	O
of	O
IJB	B-Material
-	I-Material
A	I-Material
dataset	I-Material
,	O
the	O
data	O
is	O
divided	O
into	O
10	O
splits	O
,	O
each	O
split	O
containing	O
a	O
training	O
set	O
and	O
a	O
test	O
set	O
.	O
	
Hence	O
,	O
to	O
further	O
improve	O
performance	O
,	O
we	O
learn	O
the	O
proposed	O
triplet	B-Method
probability	I-Method
embedding	I-Method
using	O
the	O
training	O
set	O
provided	O
with	O
each	O
split	O
over	O
the	O
features	O
extracted	O
from	O
our	O
DCNN	B-Method
model	O
.	O
	
During	O
the	O
deployment	O
phase	O
,	O
given	O
a	O
face	O
template	O
,	O
we	O
extract	O
the	O
deep	O
features	O
using	O
the	O
raw	O
CNN	B-Method
model	O
after	O
implementing	O
automatic	B-Method
pre	I-Method
-	I-Method
processing	I-Method
steps	I-Method
such	O
as	O
face	B-Task
detection	I-Task
and	O
fiducial	B-Task
extraction	I-Task
.	O
	
The	O
deep	O
features	O
are	O
projected	O
onto	O
a	O
low	O
-	O
dimensional	O
space	O
using	O
the	O
embedding	O
matrix	O
learned	O
during	O
training	O
(	O
note	O
that	O
the	O
projection	O
involves	O
only	O
matrix	O
multiplication	O
)	O
.	O
	
We	O
use	O
the	O
128	O
-	O
dimensional	O
feature	O
as	O
the	O
final	O
representation	O
of	O
the	O
given	O
face	O
template	O
.	O
	
This	O
paper	O
is	O
organized	O
as	O
follows	O
:	O
Section	O
[	O
reference	O
]	O
places	O
our	O
work	O
among	O
the	O
recently	O
proposed	O
approaches	O
for	O
face	B-Task
verification	I-Task
.	O
	
Section	O
[	O
reference	O
]	O
details	O
the	O
network	B-Method
architecture	I-Method
and	O
the	O
training	B-Method
scheme	I-Method
.	O
	
The	O
triplet	B-Method
probabilistic	I-Method
embedding	I-Method
learning	I-Method
method	I-Method
is	O
described	O
in	O
Section	O
[	O
reference	O
]	O
followed	O
by	O
results	O
on	O
IJB	B-Material
-	I-Material
A	I-Material
and	O
CFP	B-Material
datasets	O
and	O
a	O
brief	O
discussion	O
in	O
Section	O
[	O
reference	O
]	O
.	O
	
In	O
Section	O
[	O
reference	O
]	O
,	O
we	O
demonstrate	O
the	O
ability	O
of	O
the	O
proposed	O
method	O
to	O
cluster	O
a	O
media	O
collection	O
from	O
LFW	B-Material
and	O
IJB	B-Material
-	I-Material
A	I-Material
datasets	I-Material
.	O
	
section	O
:	O
Related	O
Work	O
	
In	O
the	O
past	O
few	O
years	O
,	O
there	O
have	O
been	O
numerous	O
works	O
in	O
using	O
deep	O
features	O
for	O
tasks	O
related	O
to	O
face	B-Task
verification	I-Task
.	O
	
The	O
DeepFace	B-Method
approach	I-Method
uses	O
a	O
carefully	O
crafted	O
3D	B-Method
alignment	I-Method
procedure	I-Method
to	O
preprocess	O
face	O
images	O
and	O
feeds	O
them	O
to	O
a	O
deep	B-Method
network	I-Method
that	O
is	O
trained	O
using	O
a	O
large	O
training	O
set	O
.	O
	
More	O
recently	O
,	O
Facenet	B-Material
uses	O
a	O
large	O
private	O
dataset	O
to	O
train	O
several	O
deep	B-Method
network	I-Method
models	I-Method
using	O
a	O
triplet	O
distance	O
loss	O
function	O
.	O
	
The	O
training	B-Metric
time	I-Metric
for	O
this	O
network	O
is	O
of	O
the	O
order	O
of	O
few	O
weeks	O
.	O
	
Since	O
the	O
release	O
of	O
the	O
IJB	B-Material
-	I-Material
A	I-Material
dataset	I-Material
,	O
there	O
have	O
been	O
several	O
works	O
that	O
have	O
published	O
verification	B-Task
results	O
for	O
this	O
dataset	O
.	O
	
Previous	O
approaches	O
presented	O
in	O
and	O
train	O
deep	B-Method
networks	I-Method
using	O
the	O
CASIA	B-Material
-	I-Material
WebFace	I-Material
dataset	I-Material
and	O
the	O
VGG	B-Material
-	I-Material
Face	I-Material
dataset	I-Material
respectively	O
,	O
requiring	O
substantial	O
training	B-Metric
time	I-Metric
.	O
	
This	O
paper	O
proposes	O
a	O
network	B-Method
architecture	I-Method
and	O
a	O
training	B-Method
scheme	I-Method
that	O
needs	O
shorter	O
training	B-Metric
time	I-Metric
and	O
a	O
small	O
query	B-Metric
time	I-Metric
.	O
	
The	O
idea	O
of	O
learning	O
a	O
compact	B-Method
and	I-Method
discriminative	I-Method
representation	I-Method
has	O
been	O
around	O
for	O
decades	O
.	O
	
Weinberger	O
et	O
al	O
.	O
used	O
a	O
Semi	B-Method
Definite	I-Method
Programming	I-Method
(	I-Method
SDP	I-Method
)-	I-Method
based	I-Method
formulation	I-Method
to	O
learn	O
a	O
metric	O
satisfying	O
pairwise	O
and	O
triplet	O
distance	O
constraints	O
in	O
a	O
large	B-Method
margin	I-Method
framework	I-Method
.	O
	
More	O
recently	O
,	O
this	O
idea	O
has	O
been	O
successfully	O
applied	O
to	O
face	B-Task
verification	I-Task
by	O
integrating	O
the	O
loss	O
function	O
within	O
the	O
deep	B-Method
network	I-Method
architecture	I-Method
(	O
,	O
)	O
.	O
	
Joint	B-Method
Bayesian	I-Method
metric	I-Method
learning	I-Method
is	O
also	O
another	O
popular	O
metric	O
used	O
for	O
face	B-Task
verification	I-Task
(	O
,	O
)	O
.	O
	
These	O
methods	O
either	O
require	O
a	O
large	O
dataset	O
for	O
convergence	O
or	O
learn	O
a	O
metric	O
directly	O
and	O
therefore	O
are	O
not	O
amenable	O
to	O
subsequent	O
operations	O
like	O
discriminative	B-Method
clustering	I-Method
or	O
hashing	B-Method
.	O
	
Classic	O
methods	O
like	O
t	B-Method
-	I-Method
SNE	I-Method
,	O
t	B-Method
-	I-Method
STE	I-Method
and	O
Crowd	B-Method
Kernel	I-Method
Learning	I-Method
(	O
CKL	B-Method
)	O
perform	O
extremely	O
well	O
when	O
used	O
to	O
visualize	O
or	O
cluster	O
a	O
given	O
data	O
collection	O
.	O
	
They	O
either	O
operate	O
on	O
the	O
data	O
matrix	O
directly	O
or	O
the	O
distance	O
matrix	O
generated	O
from	O
data	O
by	O
generating	O
a	O
large	O
set	O
of	O
pairwise	O
or	O
triplet	O
constraints	O
.	O
	
While	O
these	O
methods	O
perform	O
very	O
well	O
on	O
a	O
given	O
set	O
of	O
data	O
points	O
,	O
they	O
do	O
not	O
generalize	O
to	O
out	O
-	O
of	O
-	O
sample	O
data	O
.	O
	
In	O
the	O
current	O
work	O
,	O
we	O
aim	O
to	O
generalize	O
such	O
formulations	O
,	O
to	O
a	O
more	O
traditional	O
classification	B-Task
setting	I-Task
,	O
where	O
domain	O
specific	O
training	O
and	O
testing	O
data	O
is	O
provided	O
.	O
	
We	O
formulate	O
an	O
optimization	B-Task
problem	I-Task
based	O
on	O
triplet	O
probabilities	O
that	O
performs	O
dimensionality	B-Task
reduction	I-Task
aside	O
from	O
improving	O
the	O
discriminative	B-Metric
ability	I-Metric
of	O
the	O
test	O
data	O
.	O
	
The	O
embedding	B-Method
scheme	I-Method
described	O
in	O
this	O
work	O
is	O
a	O
more	O
general	O
framework	O
that	O
can	O
be	O
applied	O
to	O
any	O
setting	O
where	O
labeled	O
training	O
data	O
is	O
available	O
.	O
	
section	O
:	O
Network	B-Method
Architecture	I-Method
	
This	O
section	O
details	O
the	O
architecture	O
and	O
training	B-Method
algorithm	I-Method
for	O
the	O
deep	B-Method
network	I-Method
used	O
in	O
our	O
work	O
.	O
	
Our	O
architecture	O
consists	O
of	O
7	O
convolutional	B-Method
layers	I-Method
with	O
varying	O
kernel	O
sizes	O
.	O
	
The	O
initial	O
layers	O
have	O
a	O
larger	O
size	O
rapidly	O
subsampling	O
the	O
image	O
and	O
reducing	O
the	O
parameters	O
while	O
subsequent	O
layers	O
consist	O
of	O
small	O
filter	O
sizes	O
,	O
which	O
has	O
proved	O
to	O
be	O
very	O
useful	O
in	O
face	B-Task
recognition	I-Task
tasks	I-Task
(	O
,	O
)	O
.	O
	
Furthermore	O
,	O
we	O
use	O
the	O
Parametric	B-Method
Rectifier	I-Method
Linear	I-Method
units	I-Method
(	O
PReLUs	B-Method
)	O
instead	O
of	O
ReLUs	B-Method
,	O
since	O
they	O
allow	O
a	O
negative	O
value	O
for	O
the	O
output	O
based	O
on	O
a	O
learned	O
threshold	O
and	O
have	O
been	O
shown	O
to	O
improve	O
the	O
convergence	B-Metric
rate	I-Metric
.	O
	
tableDeep	B-Method
Network	I-Method
architecture	I-Method
details	O
	
The	O
top	O
three	O
convolutional	B-Method
layers	I-Method
(	O
conv1	B-Method
-	I-Method
conv3	I-Method
)	O
are	O
initialized	O
with	O
the	O
weights	O
from	O
the	O
AlexNet	B-Method
model	I-Method
trained	O
on	O
the	O
ImageNet	B-Material
challenge	I-Material
dataset	I-Material
.	O
	
Several	O
recent	O
works	O
(	O
,	O
)	O
have	O
empirically	O
shown	O
that	O
this	O
transfer	O
of	O
knowledge	O
across	O
different	O
networks	O
,	O
albeit	O
for	O
a	O
different	O
objective	O
,	O
improves	O
performance	O
and	O
more	O
significantly	O
reduces	O
the	O
need	O
to	O
train	O
over	O
a	O
large	O
number	O
of	O
iterations	O
.	O
	
The	O
compared	O
methods	O
either	O
learn	O
their	O
deep	B-Method
models	I-Method
from	O
scratch	O
(	O
,	O
)	O
or	O
finetune	O
only	O
the	O
last	B-Method
layer	I-Method
of	I-Method
fully	I-Method
pre	I-Method
-	I-Method
trained	I-Method
models	I-Method
.	O
	
The	O
former	O
results	O
in	O
large	O
training	B-Metric
time	I-Metric
and	O
the	O
latter	O
does	O
not	O
generalize	O
well	O
to	O
the	O
task	O
at	O
hand	O
(	O
face	B-Task
verification	I-Task
)	O
and	O
hence	O
resulting	O
in	O
sub	O
optimal	O
performance	O
.	O
	
In	O
the	O
current	O
work	O
,	O
even	O
though	O
we	O
use	O
a	O
pre	B-Method
-	I-Method
trained	I-Method
model	I-Method
(	O
AlexNet	B-Method
)	O
to	O
initialize	O
the	O
proposed	O
deep	B-Method
network	I-Method
,	O
we	O
do	O
so	O
only	O
for	O
the	O
first	O
three	O
convolutional	B-Method
layers	I-Method
,	O
since	O
they	O
retain	O
more	O
generic	O
information	O
(	O
)	O
.	O
	
Subsequent	O
layers	O
learn	O
representations	O
which	O
are	O
more	O
specific	O
to	O
the	O
task	O
at	O
hand	O
.	O
	
Thus	O
,	O
to	O
learn	O
more	O
task	O
specific	O
information	O
,	O
we	O
add	O
4	O
convolutional	B-Method
layers	I-Method
each	O
consisting	O
of	O
512	O
kernels	O
of	O
size	O
.	O
	
The	O
layers	O
conv4	B-Method
-	I-Method
conv7	I-Method
do	O
not	O
downsample	O
the	O
input	O
thereby	O
learning	O
more	O
complex	O
higher	O
dimensional	O
representations	O
.	O
	
This	O
hybrid	O
architecture	O
proves	O
to	O
be	O
extremely	O
effective	O
as	O
our	O
raw	O
CNN	B-Method
representation	O
outperforms	O
some	O
very	O
deep	O
CNN	B-Method
models	O
on	O
the	O
IJB	B-Material
-	I-Material
A	I-Material
dataset	I-Material
(	O
Table	O
2	O
in	O
Results	O
)	O
.	O
	
In	O
addition	O
,	O
we	O
achieve	O
that	O
performance	O
by	O
training	O
the	O
proposed	O
deep	B-Method
network	I-Method
using	O
the	O
relatively	O
smaller	O
CASIA	B-Material
-	I-Material
WebFace	I-Material
dataset	I-Material
.	O
	
The	O
architecture	O
of	O
our	O
network	O
is	O
shown	O
in	O
Table	O
[	O
reference	O
]	O
.	O
	
Layers	O
conv4	B-Method
-	I-Method
conv7	I-Method
and	O
the	O
fully	B-Method
connected	I-Method
layers	I-Method
fc6	I-Method
-	I-Method
fc8	I-Method
are	O
initialized	O
from	O
scratch	O
using	O
random	B-Method
Gaussian	I-Method
distributions	I-Method
.	O
	
PReLU	O
	
activation	O
functions	O
are	O
added	O
between	O
each	O
layer	O
.	O
	
Since	O
the	O
network	O
is	O
used	O
as	O
a	O
feature	B-Method
extractor	I-Method
,	O
the	O
last	B-Method
layer	I-Method
fc8	I-Method
is	O
removed	O
during	O
deployment	O
,	O
thus	O
reducing	O
the	O
number	O
of	O
parameters	O
to	O
29M.	O
	
The	O
inputs	O
to	O
the	O
network	O
are	O
227x227x3	O
RGB	O
images	O
.	O
	
When	O
the	O
network	O
is	O
deployed	O
,	O
the	O
features	O
are	O
extracted	O
from	O
the	O
fc7	B-Method
layer	I-Method
resulting	O
in	O
a	O
dimensionality	B-Metric
of	O
512	O
.	O
	
The	O
network	O
is	O
trained	O
using	O
the	O
Softmax	B-Method
loss	I-Method
function	I-Method
for	O
multiclass	B-Task
classification	I-Task
using	O
the	O
Caffe	B-Method
deep	I-Method
learning	I-Method
platform	I-Method
.	O
	
section	O
:	O
Learning	O
a	O
Discriminative	B-Method
Embedding	I-Method
	
In	O
this	O
section	O
,	O
we	O
describe	O
our	O
algorithm	O
for	O
learning	O
a	O
low	B-Task
-	I-Task
dimensional	I-Task
embedding	I-Task
such	O
that	O
the	O
resulting	O
projections	O
are	O
more	O
discriminative	O
.	O
	
Aside	O
from	O
an	O
improved	O
performance	O
,	O
this	O
embedding	O
provides	O
significant	O
advantages	O
in	O
terms	O
of	O
memory	B-Metric
and	O
enables	O
post	B-Task
-	I-Task
processing	I-Task
operations	I-Task
like	O
visualization	B-Task
and	O
clustering	B-Task
.	O
	
Consider	O
a	O
triplet	O
,	O
where	O
(	O
anchor	O
)	O
and	O
(	O
positive	O
)	O
are	O
from	O
the	O
same	O
class	O
,	O
but	O
(	O
negative	O
)	O
belongs	O
to	O
a	O
different	O
class	O
.	O
	
Consider	O
a	O
function	O
that	O
is	O
parameterized	O
by	O
the	O
matrix	O
,	O
that	O
measures	O
the	O
similarity	O
between	O
two	O
vectors	O
.	O
	
Ideally	O
,	O
for	O
all	O
triplets	O
that	O
exist	O
in	O
the	O
training	O
set	O
,	O
we	O
would	O
like	O
the	O
following	O
constraint	O
to	O
be	O
satisfied	O
:	O
	
Thus	O
,	O
the	O
probability	O
of	O
a	O
given	O
triplet	O
satisfying	O
(	O
[	O
reference	O
]	O
)	O
can	O
be	O
written	O
as	O
:	O
The	O
specific	O
form	O
of	O
the	O
similarity	O
function	O
is	O
given	O
as	O
:	O
.	O
	
In	O
our	O
case	O
,	O
and	O
are	O
deep	O
features	O
normalized	O
to	O
unit	O
length	O
.	O
	
To	O
learn	O
the	O
embedding	O
from	O
a	O
given	O
set	O
of	O
triplets	O
,	O
we	O
solve	O
the	O
following	O
optimization	B-Task
:	O
(	O
[	O
reference	O
]	O
)	O
can	O
be	O
interpreted	O
as	O
maximizing	O
the	O
likelihood	O
(	O
[	O
reference	O
]	O
)	O
or	O
minimizing	O
the	O
negative	O
log	O
-	O
likelihood	O
(	O
NLL	B-Method
)	O
over	O
the	O
triplet	O
set	O
.	O
	
In	O
practice	O
,	O
the	O
above	O
problem	O
is	O
solved	O
in	O
a	O
Large	B-Method
-	I-Method
Margin	I-Method
framework	I-Method
using	O
Stochastic	B-Method
Gradient	I-Method
Descent	I-Method
(	O
SGD	B-Method
)	O
and	O
the	O
triplets	O
are	O
sampled	O
online	O
.	O
	
The	O
gradient	B-Method
update	I-Method
for	O
is	O
given	O
as	O
:	O
where	O
is	O
the	O
estimate	O
at	O
iteration	O
,	O
is	O
the	O
updated	O
estimate	O
,	O
is	O
the	O
triplet	O
sampled	O
at	O
the	O
current	O
iteration	O
and	O
is	O
the	O
learning	B-Metric
rate	I-Metric
.	O
	
By	O
choosing	O
the	O
dimension	O
of	O
as	O
with	O
,	O
we	O
achieve	O
dimensionality	B-Task
reduction	I-Task
in	O
addition	O
to	O
improved	O
performance	O
.	O
	
For	O
our	O
work	O
,	O
we	O
fix	O
based	O
on	O
cross	B-Metric
validation	I-Metric
and	O
is	O
the	O
dimensionality	B-Metric
of	O
our	O
deep	O
features	O
.	O
	
is	O
initialized	O
with	O
the	O
first	O
principal	B-Method
components	I-Method
of	O
the	O
training	O
data	O
.	O
	
At	O
each	O
iteration	O
,	O
a	O
random	O
anchor	O
and	O
a	O
random	O
positive	O
data	O
point	O
are	O
chosen	O
.	O
	
To	O
choose	O
the	O
negative	O
,	O
we	O
perform	O
hard	B-Task
negative	I-Task
mining	I-Task
,	O
ie	O
.	O
	
we	O
choose	O
the	O
data	O
point	O
that	O
has	O
the	O
least	O
likelihood	O
(	O
[	O
reference	O
]	O
)	O
among	O
the	O
randomly	O
chosen	O
2000	O
negative	O
instances	O
at	O
each	O
iteration	O
.	O
	
Since	O
we	O
compute	O
the	O
embedding	O
matrix	O
by	O
optimizing	O
over	O
triplet	O
probabilities	O
,	O
we	O
call	O
this	O
method	O
	
Triplet	B-Method
Probability	I-Method
Embedding	I-Method
(	O
TPE	B-Method
)	O
.	O
	
The	O
technique	O
closest	O
to	O
the	O
one	O
presented	O
in	O
this	O
section	O
,	O
which	O
is	O
used	O
in	O
recent	O
works	O
(	O
,	O
)	O
computes	O
the	O
embedding	B-Task
based	O
on	O
satisfying	O
a	O
hinge	O
loss	O
constraint	O
:	O
acts	O
a	O
margin	O
parameter	O
for	O
the	O
loss	O
function	O
.	O
	
To	O
be	O
consistent	O
with	O
the	O
terminology	O
used	O
in	O
this	O
paper	O
,	O
we	O
call	O
it	O
	
Triplet	B-Method
Distance	I-Method
Embedding	I-Method
(	O
TDE	B-Method
)	O
.	O
	
To	O
appreciate	O
the	O
difference	O
between	O
the	O
two	O
approaches	O
,	O
Figure	O
[	O
reference	O
]	O
shows	O
the	O
case	O
where	O
the	O
gradient	B-Method
update	I-Method
for	O
the	O
TDE	B-Method
method	I-Method
(	O
[	O
reference	O
]	O
)	O
occurs	O
.	O
	
If	O
the	O
value	O
of	O
is	O
not	O
appropriately	O
chosen	O
,	O
a	O
triplet	O
is	O
considered	O
good	O
even	O
if	O
the	O
positive	O
and	O
negative	O
are	O
very	O
close	O
to	O
one	O
another	O
.	O
	
But	O
under	O
the	O
proposed	O
formulation	O
,	O
both	O
cases	O
referred	O
to	O
in	O
Figure	O
[	O
reference	O
]	O
will	O
update	O
the	O
gradient	O
but	O
their	O
contribution	O
to	O
the	O
gradient	O
will	O
be	O
modulated	O
by	O
the	O
probability	O
with	O
which	O
they	O
violate	O
the	O
constraint	O
in	O
(	O
[	O
reference	O
]	O
)	O
.	O
	
This	O
modulation	O
factor	O
is	O
specified	O
by	O
the	O
term	O
in	O
the	O
gradient	B-Method
update	I-Method
for	O
TPE	B-Method
in	O
(	O
[	O
reference	O
]	O
)	O
implying	O
that	O
if	O
the	O
likelihood	O
of	O
a	O
sampled	O
triplet	O
satisfying	O
(	O
[	O
reference	O
]	O
)	O
is	O
high	O
,	O
then	O
the	O
gradient	B-Method
update	I-Method
is	O
given	O
a	O
lower	O
weight	O
and	O
vice	O
-	O
versa	O
.	O
	
Thus	O
,	O
in	O
our	O
method	O
,	O
the	O
margin	O
parameter	O
(	O
)	O
is	O
automatically	O
set	O
based	O
on	O
the	O
likelihood	O
.	O
	
To	O
compare	O
the	O
relative	O
performances	O
of	O
the	O
raw	O
features	O
before	O
projection	B-Method
,	O
with	O
TDE	B-Method
and	O
with	O
TPE	B-Method
(	O
proposed	O
method	O
)	O
,	O
we	O
plot	O
the	O
traditional	O
ROC	B-Metric
curve	I-Metric
(	O
TAR	B-Metric
(	O
vs	O
)	O
FAR	B-Metric
)	O
for	O
split	O
1	O
of	O
the	O
IJB	B-Material
-	I-Material
A	I-Material
verify	O
protocol	O
for	O
the	O
three	O
methods	O
in	O
Figure	O
[	O
reference	O
]	O
.	O
	
The	O
Equal	B-Metric
Error	I-Metric
Rate	I-Metric
(	I-Metric
EER	I-Metric
)	I-Metric
metric	I-Metric
is	O
specified	O
for	O
each	O
method	O
.	O
	
The	O
performance	O
improvement	O
due	O
to	O
TPE	B-Method
is	O
significant	O
,	O
especially	O
at	O
regions	O
of	O
FAR	B-Metric
.	O
	
We	O
observed	O
a	O
similar	O
behaviour	O
for	O
all	O
the	O
ten	O
splits	O
of	O
the	O
IJB	B-Material
-	I-Material
A	I-Material
dataset	I-Material
.	O
	
section	O
:	O
Experimental	O
setup	O
and	O
Results	O
	
In	O
this	O
section	O
we	O
evaluate	O
the	O
proposed	O
method	O
on	O
two	O
challenging	O
datasets	O
:	O
IARPA	B-Material
Janus	I-Material
Benchmark	I-Material
-	I-Material
A	I-Material
(	O
IJB	B-Material
-	I-Material
A	I-Material
)	O
:	O
This	O
dataset	O
contains	O
500	O
subjects	O
with	O
a	O
total	O
of	O
25	O
,	O
813	O
images	O
(	O
5	O
,	O
399	O
still	B-Material
images	I-Material
and	O
20	O
,	O
414	O
video	O
frames	O
sampled	O
at	O
a	O
rate	O
of	O
1	O
in	O
60	O
)	O
.	O
	
The	O
faces	O
in	O
the	O
IJB	B-Material
-	I-Material
A	I-Material
dataset	I-Material
contain	O
extreme	O
poses	O
and	O
illuminations	O
,	O
more	O
challenging	O
than	O
LFW	B-Material
.	O
	
Some	O
sample	O
images	O
from	O
the	O
IJB	B-Material
-	I-Material
A	I-Material
dataset	I-Material
are	O
shown	O
in	O
Figure	O
[	O
reference	O
]	O
.	O
	
An	O
additional	O
challenge	O
of	O
the	O
IJB	B-Material
-	I-Material
A	I-Material
verification	O
protocol	O
is	O
that	O
the	O
template	O
comparisons	O
include	O
image	O
to	O
image	O
,	O
image	O
to	O
set	O
and	O
set	O
to	O
set	O
comparisons	O
.	O
	
In	O
this	O
work	O
,	O
for	O
a	O
given	O
test	O
template	O
of	O
the	O
IJB	B-Material
-	I-Material
A	I-Material
data	O
we	O
perform	O
two	O
kinds	O
of	O
pooling	B-Method
to	O
produce	O
its	O
final	O
representation	O
:	O
Average	B-Method
pooling	I-Method
(	O
CNN	B-Method
)	O
:	O
	
The	O
deep	O
features	O
of	O
the	O
images	O
and	O
/	O
or	O
frames	O
present	O
in	O
the	O
template	O
are	O
combined	O
by	O
taking	O
a	O
componentwise	B-Method
average	I-Method
to	O
produce	O
one	O
feature	O
vector	O
.	O
	
Thus	O
each	O
feature	O
equally	O
contributes	O
to	O
the	O
final	O
representation	O
.	O
	
Media	B-Method
pooling	I-Method
(	O
CNN	B-Method
)	O
:	O
	
The	O
deep	O
features	O
are	O
combined	O
keeping	O
in	O
mind	O
the	O
media	O
source	O
they	O
come	O
from	O
.	O
	
The	O
metadata	O
provided	O
with	O
IJB	B-Material
-	I-Material
A	I-Material
gives	O
us	O
the	O
media	O
	
i	O
	
d	O
for	O
each	O
item	O
of	O
the	O
template	O
.	O
	
Thus	O
to	O
get	O
the	O
final	O
feature	O
vector	O
,	O
we	O
first	O
take	O
an	O
intra	B-Method
-	I-Method
media	I-Method
average	I-Method
and	O
then	O
combine	O
these	O
by	O
taking	O
the	O
inter	B-Method
-	I-Method
media	I-Method
average	I-Method
.	O
	
Thus	O
each	O
feature	O
’s	O
contribution	O
to	O
the	O
final	O
representation	O
is	O
weighted	O
based	O
on	O
its	O
source	O
.	O
	
Celebrities	O
in	O
Frontal	O
-	O
Profile	O
(	O
CFP	B-Material
)	O
	
[	O
]	O
:	O
This	O
dataset	O
contains	O
7000	O
images	O
of	O
500	O
subjects	O
.	O
	
The	O
dataset	O
is	O
used	O
for	O
evaluating	O
how	O
face	B-Method
verification	I-Method
approaches	I-Method
handle	O
pose	B-Task
variation	I-Task
.	O
	
Hence	O
,	O
it	O
consists	O
of	O
5000	O
images	O
in	O
frontal	O
view	O
and	O
2000	O
images	O
in	O
extreme	O
profile	O
.	O
	
The	O
data	O
is	O
organized	O
into	O
10	O
splits	O
,	O
each	O
containing	O
equal	O
number	O
of	O
frontal	O
-	O
frontal	O
and	O
frontal	O
-	O
profile	O
comparisons	O
.	O
	
Sample	O
comparison	O
pairs	O
of	O
the	O
CFP	B-Material
dataset	O
are	O
shown	O
in	O
Figure	O
[	O
reference	O
]	O
.	O
	
.5	O
	
.25	O
	
.25	O
	
subsection	O
:	O
Pre	B-Task
-	I-Task
processing	I-Task
	
In	O
the	O
training	B-Task
phase	I-Task
,	O
given	O
an	O
input	O
image	O
,	O
we	O
use	O
the	O
HyperFace	B-Method
method	I-Method
for	O
face	B-Task
detection	I-Task
and	O
fiducial	B-Task
point	I-Task
extraction	I-Task
.	O
	
The	O
HyperFace	B-Method
detector	I-Method
automatically	O
extracts	O
many	O
faces	O
from	O
a	O
given	O
image	O
.	O
	
For	O
the	O
IJB	B-Material
-	I-Material
A	I-Material
dataset	I-Material
,	O
since	O
most	O
images	O
contain	O
more	O
than	O
one	O
face	O
,	O
we	O
use	O
the	O
bounding	O
boxes	O
provided	O
along	O
with	O
the	O
dataset	O
to	O
select	O
the	O
person	O
of	O
interest	O
from	O
the	O
list	O
of	O
automatic	B-Task
detections	I-Task
.	O
	
We	O
select	O
the	O
detection	O
that	O
has	O
the	O
maximum	O
area	O
overlap	O
with	O
the	O
manually	O
provided	O
bounding	O
box	O
.	O
	
In	O
the	O
IJB	B-Material
-	I-Material
A	I-Material
dataset	I-Material
,	O
there	O
are	O
few	O
images	O
for	O
which	O
the	O
HyperFace	B-Method
detector	I-Method
can	O
not	O
find	O
the	O
relevant	O
face	O
.	O
	
For	O
the	O
missed	O
cases	O
,	O
we	O
crop	O
the	O
face	O
using	O
the	O
bounding	O
box	O
information	O
provided	O
with	O
the	O
dataset	O
and	O
pass	O
it	O
to	O
HyperFace	B-Method
to	O
extract	O
the	O
fiducials	O
.	O
	
We	O
use	O
six	O
fiducial	O
points	O
(	O
eyes	O
and	O
mouth	O
corners	O
)	O
to	O
align	O
the	O
detected	O
image	O
to	O
a	O
canonical	O
view	O
using	O
the	O
similarity	B-Method
transform	I-Method
.	O
	
For	O
the	O
CFP	B-Material
dataset	O
,	O
since	O
the	O
six	O
keypoints	O
can	O
not	O
be	O
computed	O
for	O
profile	O
faces	O
we	O
only	O
use	O
three	O
keypoints	O
on	O
one	O
side	O
of	O
the	O
face	O
for	O
aligning	O
them	O
.	O
	
tableIdentification	O
and	O
Verification	B-Task
results	O
on	O
the	O
IJB	B-Material
-	I-Material
A	I-Material
dataset	I-Material
.	O
	
For	O
identification	B-Task
,	O
the	O
scores	O
reported	O
are	O
TPIR	O
values	O
at	O
the	O
indicated	O
points	O
.	O
	
The	O
results	O
are	O
averages	O
over	O
10	O
splits	O
and	O
the	O
standard	O
deviation	O
is	O
given	O
in	O
the	O
brackets	O
for	O
methods	O
which	O
have	O
reported	O
them	O
.	O
	
implies	O
that	O
the	O
result	O
is	O
not	O
reported	O
for	O
that	O
method	O
.	O
	
The	O
best	O
results	O
are	O
given	O
in	O
bold	O
.	O
	
tableResults	O
on	O
the	O
CFP	B-Material
dataset	O
.	O
	
The	O
numbers	O
are	O
averaged	O
over	O
ten	O
test	O
splits	O
and	O
the	O
numbers	O
in	O
brackets	O
indicate	O
standard	O
deviations	O
of	O
those	O
runs	O
.	O
	
The	O
best	O
results	O
are	O
given	O
in	O
bold	O
.	O
	
subsection	O
:	O
Parameters	O
and	O
training	O
times	O
	
The	O
training	O
of	O
the	O
proposed	O
deep	B-Method
architecture	I-Method
is	O
done	O
using	O
SGD	B-Method
with	O
momentum	B-Method
,	O
which	O
is	O
set	O
to	O
0.9	O
and	O
the	O
learning	B-Metric
rate	I-Metric
is	O
set	O
to	O
1e	O
-	O
3	O
and	O
decreased	O
uniformly	O
by	O
a	O
factor	O
of	O
10	O
every	O
50	O
K	O
iterations	O
.	O
	
The	O
weight	O
decay	O
is	O
set	O
to	O
5e	O
-	O
4	O
for	O
all	O
layers	O
.	O
	
The	O
training	O
batch	O
size	O
is	O
set	O
to	O
256	O
.	O
	
The	O
training	B-Metric
time	I-Metric
for	O
our	O
deep	B-Method
network	I-Method
is	O
24	O
hours	O
on	O
a	O
single	O
NVIDIA	O
TitanX	O
GPU	O
.	O
	
For	O
the	O
IJB	B-Material
-	I-Material
A	I-Material
dataset	I-Material
,	O
we	O
use	O
the	O
training	O
data	O
provided	O
with	O
each	O
split	O
to	O
obtain	O
the	O
triplet	B-Method
embedding	I-Method
which	O
takes	O
3	O
mins	O
per	O
split	O
.	O
	
This	O
is	O
the	O
only	O
additional	O
splitwise	B-Task
processing	I-Task
that	O
is	O
done	O
by	O
the	O
proposed	O
approach	O
.	O
	
During	O
deployment	B-Task
,	O
the	O
average	O
enrollment	B-Metric
time	I-Metric
per	O
image	O
after	O
pre	B-Task
-	I-Task
processing	I-Task
,	O
including	O
alignment	B-Task
and	O
feature	B-Task
extraction	I-Task
is	O
8ms	O
.	O
	
subsection	O
:	O
Evaluation	B-Metric
Pipeline	I-Metric
	
Given	O
an	O
image	O
,	O
we	O
pre	O
-	O
process	O
it	O
as	O
described	O
in	O
Section	O
5.1	O
.	O
	
The	O
deep	O
features	O
are	O
computed	O
as	O
an	O
average	O
of	O
the	O
image	O
and	O
its	O
flip	O
.	O
	
Given	O
two	O
deep	O
features	O
to	O
compare	O
,	O
we	O
compute	O
their	O
cosine	B-Metric
similarity	I-Metric
score	I-Metric
.	O
	
More	O
specifically	O
,	O
for	O
the	O
IJB	B-Material
-	I-Material
A	I-Material
dataset	I-Material
,	O
given	O
a	O
template	O
containing	O
multiple	O
faces	O
,	O
we	O
flatten	O
the	O
template	O
features	O
by	O
average	B-Method
pooling	I-Method
or	O
media	B-Method
pooling	I-Method
to	O
obtain	O
a	O
vector	B-Method
representation	I-Method
.	O
	
For	O
each	O
split	O
,	O
we	O
learn	O
the	O
TPE	B-Method
projection	I-Method
using	O
the	O
provided	O
training	O
data	O
.	O
	
Given	O
two	O
templates	O
for	O
comparison	O
,	O
we	O
compute	O
the	O
cosine	B-Metric
similarity	I-Metric
score	I-Metric
using	O
the	O
projected	B-Method
128	I-Method
-	I-Method
dimensional	I-Method
representations	I-Method
.	O
	
matrix	O
.	O
	
subsection	O
:	O
Evaluation	B-Metric
Metrics	I-Metric
	
We	O
report	O
two	O
types	O
of	O
results	O
for	O
the	O
IJB	B-Material
-	I-Material
A	I-Material
dataset	I-Material
:	O
Verification	B-Task
and	O
Identification	B-Task
.	O
	
For	O
the	O
verification	B-Task
protocol	I-Task
,	O
we	O
report	O
the	O
False	B-Metric
Non	I-Metric
-	I-Metric
Match	I-Metric
Rate	I-Metric
(	I-Metric
FNMR	I-Metric
)	I-Metric
values	I-Metric
at	O
several	O
False	B-Metric
Match	I-Metric
Rates	I-Metric
(	O
FMR	B-Method
)	O
.	O
	
For	O
the	O
identification	B-Task
results	O
,	O
we	O
report	O
open	B-Metric
set	I-Metric
and	I-Metric
closed	I-Metric
set	I-Metric
metrics	I-Metric
.	O
	
For	O
the	O
open	B-Metric
set	I-Metric
metrics	I-Metric
,	O
the	O
True	B-Metric
Positive	I-Metric
Identification	I-Metric
Rate	I-Metric
quantifies	O
the	O
fraction	O
of	O
subjects	O
that	O
are	O
classified	O
correctly	O
among	O
the	O
ones	O
that	O
exist	O
in	O
probe	O
but	O
not	O
in	O
gallery	O
.	O
	
For	O
the	O
closed	B-Metric
set	I-Metric
metrics	I-Metric
,	O
we	O
report	O
the	O
CMC	B-Metric
numbers	I-Metric
at	O
different	O
values	O
of	O
False	B-Metric
Positive	I-Metric
Identification	I-Metric
Rates	I-Metric
(	O
FPIRs	B-Metric
)	O
and	O
Ranks	B-Metric
.	O
	
More	O
details	O
on	O
the	O
evaluation	B-Metric
metrics	I-Metric
for	O
the	O
IJB	B-Material
-	I-Material
A	I-Material
protocol	O
can	O
be	O
found	O
in	O
.	O
	
For	O
the	O
CFP	B-Material
dataset	O
,	O
following	O
the	O
protocol	O
set	O
in	O
,	O
we	O
report	O
the	O
Area	O
under	O
the	O
curve	O
(	O
AUC	B-Metric
)	O
and	O
Equal	B-Metric
Error	I-Metric
Rate	I-Metric
(	O
EER	B-Metric
)	O
values	O
as	O
averages	O
across	O
splits	O
,	O
in	O
addition	O
to	O
the	O
classification	B-Metric
accuracy	I-Metric
.	O
	
To	O
obtain	O
the	O
accuracy	B-Metric
for	O
each	O
split	O
,	O
we	O
threshold	O
our	O
CNN	B-Method
similarity	O
scores	O
where	O
the	O
threshold	O
is	O
set	O
to	O
the	O
value	O
that	O
provides	O
the	O
highest	O
classification	B-Metric
accuracy	I-Metric
over	O
the	O
training	O
data	O
for	O
each	O
split	O
.	O
	
subsection	O
:	O
Discussion	O
	
subsubsection	O
:	O
Performance	O
on	O
IJB	B-Material
-	I-Material
A	I-Material
	
Table	O
[	O
reference	O
]	O
presents	O
the	O
results	O
for	O
the	O
proposed	O
methods	O
compared	O
to	O
existing	O
results	O
for	O
the	O
IJB	B-Material
-	I-Material
A	I-Material
Verification	O
and	O
Identification	O
protocol	O
.	O
	
The	O
compared	O
methods	O
are	O
described	O
below	O
:	O
Government	B-Method
-	I-Method
of	I-Method
-	I-Method
the	I-Method
-	I-Method
Shelf	I-Method
(	I-Method
GOTS	I-Method
)	O
is	O
the	O
baseline	O
performance	O
provided	O
along	O
with	O
the	O
IJB	B-Material
-	I-Material
A	I-Material
dataset	I-Material
.	O
	
Parkhi	O
et	O
al	O
.	O
train	O
a	O
very	O
deep	B-Method
network	I-Method
(	O
22	O
layers	O
)	O
over	O
the	O
VGG	B-Material
-	I-Material
Face	I-Material
dataset	I-Material
which	O
contains	O
2.6	O
M	O
images	O
from	O
2622	O
subjects	O
.	O
	
The	O
Neural	B-Method
Aggregation	I-Method
network	I-Method
(	O
NAN	B-Method
)	O
is	O
trained	O
over	O
large	O
amount	O
of	O
videos	O
from	O
the	O
CELEB	B-Material
-	I-Material
1000	I-Material
dataset	I-Material
starting	O
from	O
the	O
GoogleNet	B-Method
architecture	I-Method
.	O
	
Masi	O
et	O
al	O
.	O
use	O
a	O
deep	O
CNN	B-Method
based	O
approach	O
that	O
includes	O
a	O
combination	O
of	O
in	O
-	O
plane	O
aligned	O
images	O
,	O
3D	B-Material
rendered	I-Material
images	I-Material
to	O
augment	O
their	O
performance	O
.	O
	
The	O
3D	O
rendered	O
images	O
are	O
also	O
generated	O
during	O
test	O
time	O
per	O
template	O
comparison	O
.	O
	
It	O
should	O
be	O
noted	O
that	O
many	O
test	O
images	O
of	O
the	O
IJB	B-Material
-	I-Material
A	I-Material
dataset	I-Material
contain	O
extreme	O
poses	O
,	O
harsh	O
illumination	O
conditions	O
and	O
significant	O
blur	O
.	O
	
Crosswhite	O
et	O
al	O
.	O
use	O
template	B-Method
adaptation	I-Method
to	O
tune	O
the	O
performance	O
of	O
their	O
raw	O
features	O
specifically	O
to	O
the	O
IJB	B-Material
-	I-Material
A	I-Material
dataset	I-Material
.	O
	
Compared	O
to	O
these	O
methods	O
,	O
the	O
proposed	O
method	O
trains	O
a	O
single	O
CNN	B-Method
model	O
on	O
the	O
CASIA	B-Material
-	I-Material
WebFace	I-Material
dataset	I-Material
which	O
consists	O
of	O
about	O
500	O
K	O
images	O
and	O
requires	O
much	O
shorter	O
training	B-Metric
time	I-Metric
and	O
has	O
a	O
very	O
fast	O
query	B-Metric
time	I-Metric
(	O
0.08s	O
after	O
face	B-Task
detection	I-Task
per	O
image	O
pair	O
)	O
.	O
	
As	O
shown	O
in	O
Table	O
[	O
reference	O
]	O
,	O
our	O
raw	O
CNN	B-Method
features	O
after	O
media	B-Method
pooling	I-Method
perform	O
better	O
than	O
most	O
compared	O
methods	O
across	O
both	O
the	O
verification	B-Task
and	I-Task
identification	I-Task
protocols	I-Task
of	O
the	O
IJB	B-Material
-	I-Material
A	I-Material
dataset	I-Material
,	O
with	O
the	O
exception	O
of	O
the	O
template	B-Method
adaptation	I-Method
method	I-Method
by	O
Crosswhite	O
et	O
al	O
.	O
which	O
is	O
discussed	O
below	O
.	O
	
The	O
TPE	B-Method
method	I-Method
provides	O
significant	O
improvement	O
for	O
both	O
identification	B-Task
and	I-Task
verification	I-Task
tasks	I-Task
as	O
shown	O
in	O
Table	O
[	O
reference	O
]	O
.	O
	
The	O
method	O
by	O
Crosswhite	O
et	O
al	O
.	O
uses	O
the	O
VGG	B-Method
-	I-Method
Face	I-Method
network	I-Method
descriptors	I-Method
(	O
4096	O
-	O
d	O
)	O
as	O
the	O
raw	O
features	O
.	O
	
They	O
use	O
the	O
concept	O
of	O
template	B-Method
adaptation	I-Method
to	O
improve	O
their	O
performance	O
as	O
follows	O
:	O
when	O
pooling	O
multiple	O
faces	O
of	O
a	O
given	O
template	O
,	O
they	O
train	O
a	O
linear	B-Method
SVM	I-Method
with	O
the	O
features	O
of	O
this	O
template	O
as	O
positive	O
and	O
a	O
fixed	O
set	O
of	O
negatives	O
extracted	O
from	O
the	O
training	O
data	O
of	O
the	O
IJB	B-Material
-	I-Material
A	I-Material
splits	O
.	O
	
Let	O
’s	O
denote	O
the	O
pooled	O
template	O
feature	O
and	O
classifier	O
pair	O
as	O
.	O
	
Then	O
,	O
at	O
query	O
time	O
when	O
comparing	O
two	O
templates	O
and	O
,	O
the	O
similarity	B-Metric
score	I-Metric
is	O
computed	O
as	O
:	O
.	O
	
Even	O
when	O
using	O
a	O
carefully	O
engineered	O
fast	B-Method
linear	I-Method
classifier	I-Method
training	I-Method
algorithm	I-Method
,	O
this	O
procedure	O
increases	O
the	O
run	B-Metric
time	I-Metric
of	O
the	O
pooling	B-Method
procedure	I-Method
.	O
	
The	O
query	B-Metric
time	I-Metric
per	O
template	B-Task
comparison	I-Task
is	O
also	O
higher	O
due	O
to	O
the	O
high	O
dimensionality	O
of	O
the	O
input	O
features	O
.	O
	
In	O
contrast	O
,	O
the	O
proposed	O
approach	O
requires	O
a	O
matrix	B-Method
multiplication	I-Method
and	O
a	O
vector	O
dot	O
product	O
per	O
comparison	O
.	O
	
By	O
using	O
a	O
simple	O
neural	B-Method
network	I-Method
architecture	I-Method
,	O
a	O
relatively	O
smaller	O
training	O
dataset	O
and	O
a	O
fast	O
embedding	B-Method
method	I-Method
we	O
have	O
realized	O
a	O
faster	O
and	O
more	O
efficient	O
end	O
-	O
to	O
-	O
end	B-Task
system	I-Task
.	O
	
To	O
improve	O
our	O
performance	O
further	O
,	O
we	O
are	O
currently	O
incorporating	O
the	O
use	O
of	O
video	O
data	O
into	O
our	O
approach	O
.	O
	
subsubsection	B-Method
:	O
Performance	O
on	O
CFP	B-Material
	
On	O
the	O
CFP	B-Material
dataset	O
,	O
we	O
achieve	O
a	O
new	O
state	O
-	O
of	O
-	O
art	O
on	O
both	O
Frontal	B-Task
-	I-Task
Frontal	I-Task
and	I-Task
Frontal	I-Task
-	I-Task
Profile	I-Task
comparisons	I-Task
,	O
the	O
latter	O
by	O
a	O
large	O
margin	O
.	O
	
More	O
specifically	O
,	O
for	O
the	O
Frontal	B-Task
-	I-Task
Profile	I-Task
case	I-Task
,	O
we	O
manage	O
to	O
reduce	O
the	O
error	B-Metric
rate	I-Metric
by	O
40.8	O
%	O
.	O
	
It	O
should	O
be	O
noted	O
that	O
for	O
a	O
fair	O
comparison	O
we	O
have	O
used	O
our	O
raw	O
CNN	B-Method
features	O
without	O
performing	O
TPE	B-Method
.	O
	
This	O
shows	O
that	O
the	O
raw	O
CNN	B-Method
features	O
we	O
learn	O
are	O
effective	O
even	O
at	O
extreme	O
pose	O
variations	O
.	O
	
section	O
:	O
Clustering	B-Task
Faces	O
	
.5	O
.5	O
.5	O
.5	O
	
This	O
section	O
illustrates	O
how	O
the	O
proposed	O
TPE	B-Method
method	I-Method
can	O
be	O
used	O
to	O
cluster	O
a	O
given	O
data	B-Task
collection	I-Task
.	O
	
We	O
perform	O
two	O
clustering	B-Task
experiments	O
:	O
We	O
perform	O
clustering	B-Method
on	O
the	O
entire	O
LFW	B-Material
dataset	O
that	O
consists	O
of	O
13233	O
images	O
of	O
5749	O
subjects	O
.	O
	
It	O
should	O
be	O
noted	O
that	O
about	O
4169	O
subjects	O
have	O
only	O
one	O
image	O
.	O
	
We	O
use	O
the	O
IJB	B-Material
-	I-Material
A	I-Material
dataset	I-Material
and	O
cluster	O
the	O
templates	O
corresponding	O
to	O
the	O
query	O
set	O
for	O
each	O
split	O
in	O
the	O
IJB	B-Material
-	I-Material
A	I-Material
verify	O
protocol	O
.	O
	
For	O
evaluating	O
the	O
clustering	B-Task
results	O
,	O
we	O
use	O
the	O
metrics	O
defined	O
in	O
.	O
	
These	O
are	O
summarized	O
below	O
:	O
Pairwise	B-Metric
Precision	I-Metric
(	O
P⁢pair	O
)	O
:	O
	
The	O
fraction	O
of	O
pairs	O
of	O
samples	O
within	O
a	O
cluster	O
among	O
all	O
possible	O
pairs	O
which	O
are	O
of	O
the	O
same	O
class	O
,	O
over	O
the	O
total	O
number	O
of	O
same	O
cluster	O
pairs	O
.	O
	
Pairwise	B-Metric
Recall	I-Metric
(	O
R⁢pair	O
)	O
:	O
	
The	O
fraction	O
of	O
pairs	O
of	O
samples	O
within	O
a	O
class	O
among	O
all	O
possible	O
pairs	O
which	O
are	O
placed	O
in	O
the	O
same	O
cluster	O
,	O
over	O
the	O
total	O
number	O
of	O
same	O
-	O
class	O
pairs	O
.	O
	
Using	O
these	O
metrics	O
,	O
the	O
F	B-Metric
-	I-Metric
score	I-Metric
is	O
computed	O
as	O
:	O
The	O
simplest	O
way	O
we	O
found	O
to	O
demonstrate	O
the	O
effectiveness	O
of	O
our	O
deep	B-Method
features	I-Method
and	O
the	O
proposed	O
TPE	B-Method
method	I-Method
,	O
is	O
to	O
use	O
the	O
standard	O
MATLAB	B-Method
implementation	I-Method
of	O
the	O
agglomerative	B-Method
clustering	I-Method
algorithm	I-Method
with	O
the	O
average	B-Method
linkage	I-Method
metric	I-Method
.	O
	
We	O
use	O
the	O
cosine	O
similarity	O
as	O
our	O
basic	O
clustering	B-Metric
metric	I-Metric
.	O
	
The	O
simple	O
clustering	B-Method
algorithm	I-Method
that	O
we	O
have	O
used	O
here	O
has	O
computational	B-Metric
complexity	I-Metric
of	O
.	O
	
In	O
its	O
current	O
form	O
,	O
this	O
does	O
not	O
scale	O
to	O
large	O
datasets	O
with	O
millions	O
of	O
images	O
.	O
	
We	O
are	O
currently	O
working	O
on	O
a	O
more	O
efficient	O
and	O
scalable	O
(	O
yet	O
approximate	O
)	O
version	O
of	O
this	O
algorithm	O
.	O
	
paragraph	O
:	O
Clustering	B-Task
LFW:	O
-	O
	
The	O
images	O
in	O
the	O
LFW	B-Material
dataset	O
are	O
pre	O
-	O
processed	O
as	O
described	O
in	O
Section	O
5.1	O
.	O
	
For	O
each	O
image	O
and	O
its	O
flip	O
,	O
the	O
deep	O
features	O
are	O
extracted	O
using	O
the	O
proposed	O
architecture	O
,	O
averaged	O
and	O
normalized	O
to	O
unit	O
norm	O
.	O
	
We	O
run	O
the	O
clustering	B-Method
algorithm	I-Method
over	O
the	O
entire	O
data	O
in	O
a	O
single	O
shot	O
.	O
	
The	O
clustering	B-Method
algorithm	I-Method
takes	O
as	O
input	O
a	O
cut	O
-	O
off	O
parameter	O
which	O
acts	O
as	O
a	O
distance	O
threshold	O
(	O
below	O
which	O
any	O
two	O
clusters	O
will	O
not	O
be	O
merged	O
)	O
.	O
	
In	O
our	O
experiments	O
,	O
we	O
vary	O
this	O
cut	O
-	O
off	O
parameter	O
over	O
a	O
small	O
range	O
and	O
evaluate	O
the	O
resulting	O
clustering	B-Method
using	O
the	O
-	O
score	O
.	O
	
We	O
pick	O
the	O
result	O
that	O
yields	O
the	O
best	O
-	O
score	O
.	O
	
Table	O
[	O
reference	O
]	O
shows	O
the	O
result	O
of	O
our	O
approach	O
and	O
compares	O
it	O
to	O
a	O
recently	O
released	O
clustering	B-Method
approach	I-Method
based	O
on	O
approximate	B-Method
Rank	I-Method
-	I-Method
order	I-Method
clustering	I-Method
.	O
	
It	O
should	O
be	O
noted	O
that	O
,	O
in	O
the	O
case	O
of	O
,	O
the	O
clustering	B-Task
result	O
is	O
chosen	O
by	O
varying	O
the	O
number	O
of	O
clusters	O
and	O
picking	O
the	O
one	O
with	O
the	O
best	O
-	O
score	O
.	O
	
In	O
our	O
approach	O
,	O
we	O
vary	O
the	O
cut	O
-	O
off	O
threshold	O
which	O
is	O
the	O
property	O
of	O
deep	O
features	O
and	O
hence	O
is	O
a	O
more	O
intuitive	O
parameter	O
to	O
tune	O
.	O
	
We	O
see	O
from	O
Table	O
[	O
reference	O
]	O
that	O
aside	O
from	O
better	O
performance	O
,	O
our	O
total	O
cluster	B-Method
estimate	I-Method
is	O
closer	O
to	O
the	O
ground	O
truth	O
value	O
of	O
5749	O
than	O
.	O
	
table	O
-	O
score	O
for	O
comparison	O
of	O
the	O
two	O
clustering	B-Method
schemes	I-Method
on	O
the	O
LFW	B-Material
dataset	O
.	O
	
The	O
ground	B-Metric
truth	I-Metric
cluster	I-Metric
number	I-Metric
is	O
5749	O
.	O
	
tableClustering	B-Metric
metrics	I-Metric
over	O
the	O
IJB	B-Material
-	I-Material
A	I-Material
1:1	O
protocol	O
.	O
	
The	O
standard	O
deviation	O
is	O
indicated	O
in	O
brackets	O
.	O
	
The	O
ground	O
truth	O
subjects	O
per	O
each	O
split	O
is	O
167	O
.	O
	
paragraph	O
:	O
Clustering	B-Task
IJB	I-Material
-	I-Material
A:	I-Material
-	I-Material
	
The	O
IJB	B-Material
-	I-Material
A	I-Material
dataset	I-Material
is	O
processed	O
as	O
described	O
in	O
Section	O
5	O
.	O
	
In	O
this	O
section	O
,	O
we	O
aim	O
to	O
cluster	O
the	O
query	O
templates	O
provided	O
with	O
each	O
split	O
for	O
the	O
verify	B-Method
protocol	I-Method
.	O
	
We	O
report	O
the	O
results	O
of	O
two	O
experiments	O
:	O
with	O
the	O
raw	O
CNN	B-Method
features	O
(	O
CNN	B-Method
in	O
Table	O
2	O
)	O
and	O
with	O
the	O
projected	O
CNN	B-Method
features	O
,	O
where	O
the	O
projection	O
matrix	O
is	O
learned	O
through	O
the	O
proposed	O
TPE	B-Method
method	I-Method
(	O
CNN	B-Method
+	O
TPE	B-Method
in	O
Table	O
2	O
)	O
.	O
	
The	O
cut	O
-	O
off	O
threshold	O
required	O
for	O
our	O
clustering	B-Method
algorithm	I-Method
is	O
learned	O
automatically	O
based	O
on	O
the	O
training	O
data	O
,	O
i.e.	O
we	O
choose	O
the	O
threshold	O
that	O
gives	O
the	O
maximum	O
-	O
score	O
over	O
the	O
training	O
data	O
.	O
	
The	O
scores	O
reported	O
in	O
Table	O
[	O
reference	O
]	O
are	O
average	O
values	O
over	O
ten	O
splits	O
.	O
	
As	O
expected	O
,	O
the	O
TPE	B-Method
method	I-Method
improves	O
the	O
clustering	B-Task
performance	O
of	O
raw	O
features	O
.	O
	
The	O
subject	O
estimate	O
is	O
the	O
number	O
of	O
clusters	O
produced	O
as	O
a	O
direct	O
result	O
of	O
our	O
clustering	B-Method
algorithm	I-Method
.	O
	
The	O
pruned	B-Method
estimate	I-Method
is	O
obtained	O
by	O
ignoring	O
clusters	O
that	O
have	O
fewer	O
than	O
3	O
images	O
.	O
	
For	O
a	O
more	O
complete	O
evaluation	O
of	O
our	O
performance	O
over	O
varying	O
threshold	O
values	O
,	O
we	O
plot	O
the	O
Precision	B-Metric
-	I-Metric
Recall	I-Metric
(	O
PR	B-Metric
)	O
curve	O
for	O
the	O
IJB	B-Method
-	I-Method
A	I-Method
clustering	I-Method
experiment	O
in	O
Figure	O
[	O
reference	O
]	O
.	O
	
As	O
can	O
be	O
observed	O
,	O
the	O
PR	B-Metric
curve	O
for	O
clustering	B-Task
the	O
IJB	B-Material
-	I-Material
A	I-Material
data	O
using	O
embedded	O
features	O
exhibits	O
a	O
better	O
performance	O
at	O
all	O
operating	O
points	O
.	O
	
This	O
is	O
a	O
more	O
transparent	O
evaluation	O
than	O
reporting	O
only	O
the	O
-	O
score	O
since	O
the	O
latter	O
effectively	O
fixes	O
the	O
operating	O
point	O
but	O
the	O
PR	B-Metric
curve	O
reveals	O
the	O
performance	O
at	O
all	O
operating	O
points	O
.	O
	
section	O
:	O
Conclusion	O
and	O
Future	O
Work	O
	
In	O
this	O
paper	O
,	O
we	O
proposed	O
a	O
deep	O
CNN	B-Method
-	O
based	O
approach	O
coupled	O
with	O
a	O
low	B-Method
-	I-Method
dimensional	I-Method
discriminative	I-Method
embedding	I-Method
learned	O
using	O
triplet	O
probability	O
constraints	O
in	O
a	O
large	O
margin	O
fashion	O
.	O
	
The	O
proposed	O
pipeline	O
enables	O
a	O
faster	O
training	B-Metric
time	I-Metric
and	O
improves	O
face	B-Task
verification	I-Task
performance	O
especially	O
at	O
low	O
FMRs	B-Metric
.	O
	
We	O
demonstrated	O
the	O
effectiveness	O
of	O
the	O
proposed	O
method	O
on	O
two	O
challenging	O
datasets	O
:	O
IJB	B-Material
-	I-Material
A	I-Material
and	O
CFP	B-Material
and	O
achieved	O
performance	O
close	O
to	O
the	O
state	O
of	O
the	O
art	O
while	O
using	O
a	O
deep	B-Method
model	I-Method
which	O
is	O
more	O
compact	O
and	O
trained	O
using	O
a	O
moderately	O
sized	O
dataset	O
.	O
	
We	O
demonstrated	O
the	O
robustness	O
of	O
our	O
features	O
using	O
a	O
simple	O
clustering	B-Method
algorithm	I-Method
on	O
the	O
LFW	B-Material
and	O
IJB	B-Material
-	I-Material
A	I-Material
datasets	O
.	O
	
For	O
future	O
work	O
,	O
we	O
plan	O
to	O
use	O
videos	O
directly	O
during	O
training	O
and	O
also	O
embed	O
our	O
TPE	B-Method
approach	I-Method
into	O
training	O
the	O
deep	B-Method
network	I-Method
.	O
	
We	O
intend	O
to	O
scale	O
our	O
clustering	B-Method
algorithm	I-Method
to	O
handle	O
large	B-Task
scale	I-Task
scenarios	I-Task
such	O
as	O
large	O
impostor	O
sets	O
of	O
the	O
order	O
of	O
millions	O
.	O
	
section	O
:	O
Acknowledgement	O
	
This	O
research	O
is	O
based	O
upon	O
work	O
supported	O
by	O
the	O
Office	O
of	O
the	O
Director	O
of	O
National	O
Intelligence	O
(	O
ODNI	O
)	O
,	O
Intelligence	O
Advanced	O
Research	O
Projects	O
Activity	O
(	O
IARPA	O
),	O
via	O
IARPA	O
R	O
&	O
D	O
Contract	O
No	O
.	O
2014	O
-	O
14071600012	O
.	O
	
The	O
views	O
and	O
conclusions	O
contained	O
herein	O
are	O
those	O
of	O
the	O
authors	O
and	O
should	O
not	O
be	O
interpreted	O
as	O
necessarily	O
representing	O
the	O
official	O
policies	O
or	O
endorsements	O
,	O
either	O
expressed	O
or	O
implied	O
,	O
of	O
the	O
ODNI	O
,	O
IARPA	O
,	O
or	O
the	O
U.S.	O
Government	O
.	O
	
The	O
U.S.	O
Government	O
is	O
authorized	O
to	O
reproduce	O
and	O
distribute	O
reprints	O
for	O
Governmental	O
purposes	O
notwithstanding	O
any	O
copyright	O
annotation	O
thereon	O
.	O
	
bibliography	O
:	O
References	O
	
document	O
:	O
High	B-Task
-	I-Task
Resolution	I-Task
Image	I-Task
Synthesis	I-Task
and	O
Semantic	B-Task
Manipulation	I-Task
with	O
Conditional	B-Method
GANs	I-Method
	
We	O
present	O
a	O
new	O
method	O
for	O
synthesizing	B-Task
high	I-Task
-	I-Task
resolution	I-Task
photo	I-Task
-	I-Task
realistic	I-Task
images	I-Task
from	O
semantic	B-Task
label	I-Task
maps	I-Task
using	O
conditional	B-Method
generative	I-Method
adversarial	I-Method
networks	I-Method
(	O
conditional	B-Method
GANs	I-Method
)	O
.	O
	
Conditional	B-Method
GANs	I-Method
have	O
enabled	O
a	O
variety	O
of	O
applications	O
,	O
but	O
the	O
results	O
are	O
often	O
limited	O
to	O
low	O
-	O
resolution	O
and	O
still	O
far	O
from	O
realistic	O
.	O
	
In	O
this	O
work	O
,	O
we	O
generate	O
visually	O
appealing	O
results	O
with	O
a	O
novel	O
adversarial	B-Method
loss	I-Method
,	O
as	O
well	O
as	O
new	O
multi	B-Method
-	I-Method
scale	I-Method
generator	I-Method
and	I-Method
discriminator	I-Method
architectures	I-Method
.	O
	
Furthermore	O
,	O
we	O
extend	O
our	O
framework	O
to	O
interactive	B-Task
visual	I-Task
manipulation	I-Task
with	O
two	O
additional	O
features	O
.	O
	
First	O
,	O
we	O
incorporate	O
object	O
instance	O
segmentation	O
information	O
,	O
which	O
enables	O
object	O
manipulations	O
such	O
as	O
removing	O
/	O
adding	O
objects	O
and	O
changing	O
the	O
object	O
category	O
.	O
	
Second	O
,	O
we	O
propose	O
a	O
method	O
to	O
generate	O
diverse	O
results	O
given	O
the	O
same	O
input	O
,	O
allowing	O
users	O
to	O
edit	O
the	O
object	O
appearance	O
interactively	O
.	O
	
Human	O
opinion	O
studies	O
demonstrate	O
that	O
our	O
method	O
significantly	O
outperforms	O
existing	O
methods	O
,	O
advancing	O
both	O
the	O
quality	B-Metric
and	O
the	O
resolution	B-Metric
of	O
deep	B-Task
image	I-Task
synthesis	I-Task
and	I-Task
editing	I-Task
.	O
	
section	O
:	O
Introduction	O
	
Photo	B-Task
-	I-Task
realistic	I-Task
image	I-Task
rendering	I-Task
using	O
standard	O
graphics	B-Method
techniques	I-Method
is	O
involved	O
,	O
since	O
geometry	O
,	O
materials	O
,	O
and	O
light	O
transport	O
must	O
be	O
simulated	O
explicitly	O
.	O
	
Although	O
existing	O
graphics	B-Method
algorithms	I-Method
excel	O
at	O
the	O
task	O
,	O
building	B-Task
and	I-Task
editing	I-Task
virtual	I-Task
environments	I-Task
is	O
expensive	O
and	O
time	O
-	O
consuming	O
.	O
	
That	O
is	O
because	O
we	O
have	O
to	O
model	O
every	O
aspect	O
of	O
the	O
world	O
explicitly	O
.	O
	
If	O
we	O
were	O
able	O
to	O
render	O
photo	O
-	O
realistic	O
images	O
using	O
a	O
model	O
learned	O
from	O
data	O
,	O
we	O
could	O
turn	O
the	O
process	O
of	O
graphics	B-Task
rendering	I-Task
into	O
a	O
model	B-Task
learning	I-Task
and	I-Task
inference	I-Task
problem	I-Task
.	O
	
Then	O
,	O
we	O
could	O
simplify	O
the	O
process	O
of	O
creating	B-Task
new	I-Task
virtual	I-Task
worlds	I-Task
by	O
training	O
models	O
on	O
new	O
datasets	O
.	O
	
We	O
could	O
even	O
make	O
it	O
easier	O
to	O
customize	O
environments	O
by	O
allowing	O
users	O
to	O
simply	O
specify	O
overall	O
semantic	O
structure	O
rather	O
than	O
modeling	O
geometry	O
,	O
materials	O
,	O
or	O
lighting	O
.	O
	
In	O
this	O
paper	O
,	O
we	O
discuss	O
a	O
new	O
approach	O
that	O
produces	O
high	B-Task
-	I-Task
resolution	I-Task
images	I-Task
from	O
semantic	B-Task
label	I-Task
maps	I-Task
.	O
	
This	O
method	O
has	O
a	O
wide	O
range	O
of	O
applications	O
.	O
	
For	O
example	O
,	O
we	O
can	O
use	O
it	O
to	O
create	O
synthetic	O
training	O
data	O
for	O
training	O
visual	B-Task
recognition	I-Task
algorithms	I-Task
,	O
since	O
it	O
is	O
much	O
easier	O
to	O
create	O
semantic	O
labels	O
for	O
desired	O
scenarios	O
than	O
to	O
generate	O
training	O
images	O
.	O
	
Using	O
semantic	B-Method
segmentation	I-Method
methods	I-Method
,	O
we	O
can	O
transform	O
images	O
into	O
a	O
semantic	O
label	O
domain	O
,	O
edit	O
the	O
objects	O
in	O
the	O
label	O
domain	O
,	O
and	O
then	O
transform	O
them	O
back	O
to	O
the	O
image	O
domain	O
.	O
	
This	O
method	O
also	O
gives	O
us	O
new	O
tools	O
for	O
higher	B-Task
-	I-Task
level	I-Task
image	I-Task
editing	I-Task
,	O
e.g.	O
,	O
adding	O
objects	O
to	O
images	O
or	O
changing	O
the	O
appearance	O
of	O
existing	O
objects	O
.	O
	
To	O
synthesize	O
images	O
from	O
semantic	O
labels	O
,	O
one	O
can	O
use	O
the	O
pix2pix	B-Method
method	I-Method
,	O
an	O
image	B-Task
-	I-Task
to	I-Task
-	I-Task
image	I-Task
translation	I-Task
framework	O
which	O
leverages	O
generative	B-Method
adversarial	I-Method
networks	I-Method
(	O
GANs	B-Method
)	O
in	O
a	O
conditional	B-Method
setting	I-Method
.	O
	
Recently	O
,	O
Chen	O
and	O
Koltun	O
suggest	O
that	O
adversarial	B-Method
training	I-Method
might	O
be	O
unstable	O
and	O
prone	O
to	O
failure	O
for	O
high	B-Task
-	I-Task
resolution	I-Task
image	I-Task
generation	I-Task
tasks	I-Task
.	O
	
Instead	O
,	O
they	O
adopt	O
a	O
modified	O
perceptual	B-Method
loss	I-Method
to	O
synthesize	O
images	O
,	O
which	O
are	O
high	O
-	O
resolution	O
but	O
often	O
lack	O
fine	O
details	O
and	O
realistic	O
textures	O
.	O
	
Here	O
we	O
address	O
two	O
main	O
issues	O
of	O
the	O
above	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
methods	O
:	O
(	O
1	O
)	O
the	O
difficulty	O
of	O
generating	B-Task
high	I-Task
-	I-Task
resolution	I-Task
images	I-Task
with	O
GANs	B-Method
and	O
(	O
2	O
)	O
the	O
lack	O
of	O
details	O
and	O
realistic	O
textures	O
in	O
the	O
previous	O
high	O
-	O
resolution	O
results	O
.	O
	
We	O
show	O
that	O
through	O
a	O
new	O
,	O
robust	O
adversarial	B-Method
learning	I-Method
objective	I-Method
together	O
with	O
new	O
multi	B-Method
-	I-Method
scale	I-Method
generator	I-Method
and	I-Method
discriminator	I-Method
architectures	I-Method
,	O
we	O
can	O
synthesize	O
photo	O
-	O
realistic	O
images	O
at	O
resolution	O
,	O
which	O
are	O
more	O
visually	O
appealing	O
than	O
those	O
computed	O
by	O
previous	O
methods	O
.	O
	
We	O
first	O
obtain	O
our	O
results	O
with	O
adversarial	B-Method
training	I-Method
only	O
,	O
without	O
relying	O
on	O
any	O
hand	O
-	O
crafted	O
losses	O
or	O
pre	B-Method
-	I-Method
trained	I-Method
networks	I-Method
(	O
e.g.	O
VGGNet	B-Method
)	O
for	O
perceptual	O
losses	O
(	O
Figs	O
.	O
	
[	O
reference	O
]	O
c	O
,	O
[	O
reference	O
]	O
b	O
)	O
.	O
	
Then	O
we	O
show	O
that	O
adding	O
perceptual	O
losses	O
from	O
pre	O
-	O
trained	B-Method
networks	I-Method
can	O
slightly	O
improve	O
the	O
results	O
in	O
some	O
circumstances	O
(	O
Figs	O
.	O
	
[	O
reference	O
]	O
d	O
,	O
[	O
reference	O
]	O
c	O
)	O
,	O
if	O
a	O
pre	B-Method
-	I-Method
trained	I-Method
network	I-Method
is	O
available	O
.	O
	
Both	O
results	O
outperform	O
previous	O
works	O
substantially	O
in	O
terms	O
of	O
image	B-Metric
quality	I-Metric
.	O
	
Furthermore	O
,	O
to	O
support	O
interactive	B-Task
semantic	I-Task
manipulation	I-Task
,	O
we	O
extend	O
our	O
method	O
in	O
two	O
directions	O
.	O
	
First	O
,	O
we	O
use	O
instance	O
-	O
level	O
object	O
segmentation	O
information	O
,	O
which	O
can	O
separate	O
different	O
object	O
instances	O
within	O
the	O
same	O
category	O
.	O
	
This	O
enables	O
flexible	O
object	B-Task
manipulations	I-Task
,	O
such	O
as	O
adding	O
/	O
removing	O
objects	O
and	O
changing	O
object	O
types	O
.	O
	
Second	O
,	O
we	O
propose	O
a	O
method	O
to	O
generate	O
diverse	O
results	O
given	O
the	O
same	O
input	O
label	O
map	O
,	O
allowing	O
the	O
user	O
to	O
edit	O
the	O
appearance	O
of	O
the	O
same	O
object	O
interactively	O
.	O
	
We	O
compare	O
against	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
visual	B-Method
synthesis	I-Method
systems	I-Method
,	O
and	O
show	O
that	O
our	O
method	O
outperforms	O
these	O
approaches	O
regarding	O
both	O
quantitative	B-Metric
evaluations	I-Metric
and	O
human	B-Task
perception	I-Task
studies	I-Task
.	O
	
We	O
also	O
perform	O
an	O
ablation	O
study	O
regarding	O
the	O
training	B-Metric
objectives	I-Metric
and	O
the	O
importance	O
of	O
instance	O
-	O
level	O
segmentation	O
information	O
.	O
	
In	O
addition	O
to	O
semantic	B-Task
manipulation	I-Task
,	O
we	O
test	O
our	O
method	O
on	O
edge2photo	B-Task
applications	I-Task
(	O
Figs	O
.	O
	
[	O
reference	O
]	O
,	O
[	O
reference	O
]	O
)	O
,	O
which	O
shows	O
the	O
generalizability	O
of	O
our	O
approach	O
.	O
	
Code	O
and	O
data	O
are	O
available	O
at	O
our	O
.	O
	
section	O
:	O
Related	O
Work	O
	
paragraph	O
:	O
Generative	B-Method
adversarial	I-Method
networks	I-Method
	
Generative	B-Method
adversarial	I-Method
networks	I-Method
(	O
GANs	B-Method
)	O
aim	O
to	O
model	O
the	O
natural	O
image	O
distribution	O
by	O
forcing	O
the	O
generated	O
samples	O
to	O
be	O
indistinguishable	O
from	O
natural	O
images	O
.	O
	
GANs	B-Method
enable	O
a	O
wide	O
variety	O
of	O
applications	O
such	O
as	O
image	B-Task
generation	I-Task
,	O
representation	B-Task
learning	I-Task
,	O
image	B-Task
manipulation	I-Task
,	O
object	B-Task
detection	I-Task
,	O
and	O
video	B-Task
applications	I-Task
.	O
	
Various	O
coarse	B-Method
-	I-Method
to	I-Method
-	I-Method
fine	I-Method
schemes	I-Method
have	O
been	O
proposed	O
to	O
synthesize	O
larger	O
images	O
(	O
e.g.	O
)	O
in	O
an	O
unconditional	B-Task
setting	I-Task
.	O
	
Inspired	O
by	O
their	O
successes	O
,	O
we	O
propose	O
a	O
new	O
coarse	B-Method
-	I-Method
to	I-Method
-	I-Method
fine	I-Method
generator	I-Method
and	O
multi	B-Method
-	I-Method
scale	I-Method
discriminator	I-Method
architectures	I-Method
suitable	O
for	O
conditional	B-Task
image	I-Task
generation	I-Task
at	O
a	O
much	O
higher	O
resolution	O
.	O
	
paragraph	O
:	O
Image	B-Task
-	I-Task
to	I-Task
-	I-Task
image	I-Task
translation	I-Task
	
Many	O
researchers	O
have	O
leveraged	O
adversarial	B-Method
learning	I-Method
for	O
image	B-Task
-	I-Task
to	I-Task
-	I-Task
image	I-Task
translation	I-Task
,	O
whose	O
goal	O
is	O
to	O
translate	O
an	O
input	O
image	O
from	O
one	O
domain	O
to	O
another	O
domain	O
given	O
input	O
-	O
output	O
image	O
pairs	O
as	O
training	O
data	O
.	O
	
Compared	O
to	O
loss	B-Method
,	O
which	O
often	O
leads	O
to	O
blurry	O
images	O
,	O
the	O
adversarial	B-Method
loss	I-Method
has	O
become	O
a	O
popular	O
choice	O
for	O
many	O
image	B-Task
-	I-Task
to	I-Task
-	I-Task
image	I-Task
tasks	I-Task
.	O
	
The	O
reason	O
is	O
that	O
the	O
discriminator	B-Method
can	O
learn	O
a	O
trainable	B-Method
loss	I-Method
function	I-Method
and	O
automatically	O
adapt	O
to	O
the	O
differences	O
between	O
the	O
generated	O
and	O
real	O
images	O
in	O
the	O
target	O
domain	O
.	O
	
For	O
example	O
,	O
the	O
recent	O
pix2pix	B-Method
framework	O
used	O
image	B-Method
-	I-Method
conditional	I-Method
GANs	I-Method
for	O
different	O
applications	O
,	O
such	O
as	O
transforming	O
Google	B-Method
maps	I-Method
to	O
satellite	O
views	O
and	O
generating	B-Task
cats	I-Task
from	O
user	O
sketches	O
.	O
	
Various	O
methods	O
have	O
also	O
been	O
proposed	O
to	O
learn	O
an	O
image	B-Task
-	I-Task
to	I-Task
-	I-Task
image	I-Task
translation	I-Task
in	O
the	O
absence	O
of	O
training	O
pairs	O
.	O
	
Recently	O
,	O
Chen	O
and	O
Koltun	O
suggest	O
that	O
it	O
might	O
be	O
hard	O
for	O
conditional	B-Method
GANs	I-Method
to	O
generate	O
high	B-Task
-	I-Task
resolution	I-Task
images	I-Task
due	O
to	O
the	O
training	B-Task
instability	I-Task
and	O
optimization	B-Task
issues	I-Task
.	O
	
To	O
avoid	O
this	O
difficulty	O
,	O
they	O
use	O
a	O
direct	B-Method
regression	I-Method
objective	I-Method
based	O
on	O
a	O
perceptual	O
loss	O
and	O
produce	O
the	O
first	O
model	O
that	O
can	O
synthesize	O
images	O
.	O
	
The	O
generated	O
results	O
are	O
high	O
-	O
resolution	O
but	O
often	O
lack	O
fine	O
details	O
and	O
realistic	O
textures	O
.	O
	
Motivated	O
by	O
their	O
success	O
,	O
we	O
show	O
that	O
using	O
our	O
new	O
objective	O
function	O
as	O
well	O
as	O
novel	O
multi	B-Method
-	I-Method
scale	I-Method
generators	I-Method
and	O
discriminators	B-Method
,	O
we	O
not	O
only	O
largely	O
stabilize	O
the	O
training	O
of	O
conditional	B-Method
GANs	I-Method
on	O
high	O
-	O
resolution	O
images	O
,	O
but	O
also	O
achieve	O
significantly	O
better	O
results	O
compared	O
to	O
Chen	O
and	O
Koltun	O
.	O
	
Side	O
-	O
by	O
-	O
side	O
comparisons	O
clearly	O
show	O
our	O
advantage	O
(	O
Figs	O
.	O
	
[	O
reference	O
]	O
,	O
[	O
reference	O
]	O
,	O
[	O
reference	O
]	O
,	O
[	O
reference	O
]	O
)	O
.	O
	
paragraph	O
:	O
Deep	B-Task
visual	I-Task
manipulation	I-Task
	
Recently	O
,	O
deep	B-Method
neural	I-Method
networks	I-Method
have	O
obtained	O
promising	O
results	O
in	O
various	O
image	B-Task
processing	I-Task
tasks	I-Task
,	O
such	O
as	O
style	B-Task
transfer	I-Task
,	O
inpainting	B-Task
,	O
colorization	B-Task
,	O
and	O
restoration	B-Task
.	O
	
However	O
,	O
most	O
of	O
these	O
works	O
lack	O
an	O
interface	O
for	O
users	O
to	O
adjust	O
the	O
current	O
result	O
or	O
explore	O
the	O
output	O
space	O
.	O
	
To	O
address	O
this	O
issue	O
,	O
Zhu	O
developed	O
an	O
optimization	B-Method
method	I-Method
for	O
editing	B-Task
the	I-Task
object	I-Task
appearance	I-Task
based	O
on	O
the	O
priors	O
learned	O
by	O
GANs	B-Method
.	O
	
Recent	O
works	O
also	O
provide	O
user	O
interfaces	O
for	O
creating	O
novel	B-Task
imagery	I-Task
from	O
low	O
-	O
level	O
cues	O
such	O
as	O
color	O
and	O
sketch	O
.	O
	
All	O
of	O
the	O
prior	O
works	O
report	O
results	O
on	O
low	O
-	O
resolution	O
images	O
.	O
	
Our	O
system	O
shares	O
the	O
same	O
spirit	O
as	O
this	O
past	O
work	O
,	O
but	O
we	O
focus	O
on	O
object	B-Task
-	I-Task
level	I-Task
semantic	I-Task
editing	I-Task
,	O
allowing	O
users	O
to	O
interact	O
with	O
the	O
entire	O
scene	O
and	O
manipulate	O
individual	O
objects	O
in	O
the	O
image	O
.	O
	
As	O
a	O
result	O
,	O
users	O
can	O
quickly	O
create	O
a	O
new	O
scene	O
with	O
minimal	O
effort	O
.	O
	
Our	O
interface	O
is	O
inspired	O
by	O
prior	O
data	B-Method
-	I-Method
driven	I-Method
graphics	I-Method
systems	I-Method
.	O
	
But	O
our	O
system	O
allows	O
more	O
flexible	O
manipulations	O
and	O
produces	O
high	O
-	O
res	O
results	O
in	O
real	O
-	O
time	O
.	O
	
section	O
:	O
Instance	B-Task
-	I-Task
Level	I-Task
Image	I-Task
Synthesis	I-Task
	
We	O
propose	O
a	O
conditional	B-Method
adversarial	I-Method
framework	I-Method
for	O
generating	O
high	B-Task
-	I-Task
resolution	I-Task
photo	I-Task
-	I-Task
realistic	I-Task
images	I-Task
from	O
semantic	B-Task
label	I-Task
maps	I-Task
.	O
	
We	O
first	O
review	O
our	O
baseline	O
model	O
pix2pix	B-Method
(	O
Sec	O
.	O
	
[	O
reference	O
]	O
)	O
.	O
	
We	O
then	O
describe	O
how	O
we	O
increase	O
the	O
photo	B-Metric
-	I-Metric
realism	I-Metric
and	O
resolution	B-Metric
of	O
the	O
results	O
with	O
our	O
improved	O
objective	B-Metric
function	I-Metric
and	O
network	B-Method
design	I-Method
(	O
Sec	O
.	O
	
[	O
reference	O
]	O
)	O
.	O
	
Next	O
,	O
we	O
use	O
additional	O
instance	O
-	O
level	O
object	O
semantic	O
information	O
to	O
further	O
improve	O
the	O
image	B-Metric
quality	I-Metric
(	O
Sec	O
.	O
	
[	O
reference	O
]	O
)	O
.	O
	
Finally	O
,	O
we	O
introduce	O
an	O
instance	B-Method
-	I-Method
level	I-Method
feature	I-Method
embedding	I-Method
scheme	I-Method
to	O
better	O
handle	O
the	O
multi	B-Task
-	I-Task
modal	I-Task
nature	I-Task
of	I-Task
image	I-Task
synthesis	I-Task
,	O
which	O
enables	O
interactive	B-Task
object	I-Task
editing	I-Task
(	O
Sec	O
.	O
	
[	O
reference	O
]	O
)	O
.	O
	
subsection	O
:	O
The	O
pix2pix	B-Method
Baseline	O
	
The	O
pix2pix	B-Method
method	I-Method
is	O
a	O
conditional	B-Method
GAN	I-Method
framework	I-Method
for	O
image	B-Task
-	I-Task
to	I-Task
-	I-Task
image	I-Task
translation	I-Task
.	O
	
It	O
consists	O
of	O
a	O
generator	B-Method
and	O
a	O
discriminator	B-Method
.	O
	
For	O
our	O
task	O
,	O
the	O
objective	O
of	O
the	O
generator	O
is	O
to	O
translate	O
semantic	B-Task
label	I-Task
maps	I-Task
to	O
realistic	O
-	O
looking	O
images	O
,	O
while	O
the	O
discriminator	B-Method
aims	O
to	O
distinguish	O
real	O
images	O
from	O
the	O
translated	O
ones	O
.	O
	
The	O
framework	O
operates	O
in	O
a	O
supervised	B-Task
setting	I-Task
.	O
	
In	O
other	O
words	O
,	O
the	O
training	O
dataset	O
is	O
given	O
as	O
a	O
set	O
of	O
pairs	O
of	O
corresponding	O
images	O
,	O
where	O
is	O
a	O
semantic	O
label	O
map	O
and	O
is	O
a	O
corresponding	O
natural	O
photo	O
.	O
	
Conditional	B-Method
GANs	I-Method
aim	O
to	O
model	O
the	O
conditional	O
distribution	O
of	O
real	O
images	O
given	O
the	O
input	O
semantic	O
label	O
maps	O
via	O
the	O
following	O
minimax	B-Method
game	I-Method
:	O
where	O
the	O
objective	B-Metric
function	I-Metric
is	O
given	O
by	O
The	O
pix2pix	B-Method
method	I-Method
adopts	O
U	B-Method
-	I-Method
Net	I-Method
as	O
the	O
generator	B-Method
and	O
a	O
patch	B-Method
-	I-Method
based	I-Method
fully	I-Method
convolutional	I-Method
network	I-Method
as	O
the	O
discriminator	B-Method
.	O
	
The	O
input	O
to	O
the	O
discriminator	B-Method
is	O
a	O
channel	B-Method
-	I-Method
wise	I-Method
concatenation	I-Method
of	O
the	O
semantic	B-Method
label	I-Method
map	I-Method
and	O
the	O
corresponding	O
image	O
.	O
	
However	O
,	O
the	O
resolution	O
of	O
the	O
generated	O
images	O
on	O
Cityscapes	B-Material
is	O
up	O
to	O
.	O
	
We	O
tested	O
directly	O
applying	O
the	O
pix2pix	B-Method
framework	O
to	O
generate	O
high	O
-	O
resolution	O
images	O
but	O
found	O
the	O
training	O
unstable	O
and	O
the	O
quality	O
of	O
generated	O
images	O
unsatisfactory	O
.	O
	
Therefore	O
,	O
we	O
describe	O
how	O
we	O
improve	O
the	O
pix2pix	B-Method
framework	O
in	O
the	O
next	O
subsection	O
.	O
	
subsection	O
:	O
Improving	O
Photorealism	B-Metric
and	I-Metric
Resolution	I-Metric
	
We	O
improve	O
the	O
pix2pix	B-Method
framework	O
by	O
using	O
a	O
coarse	B-Method
-	I-Method
to	I-Method
-	I-Method
fine	I-Method
generator	I-Method
,	O
a	O
multi	B-Method
-	I-Method
scale	I-Method
discriminator	I-Method
architecture	I-Method
,	O
and	O
a	O
robust	B-Method
adversarial	I-Method
learning	I-Method
objective	I-Method
function	I-Method
.	O
	
Coarse	B-Task
-	I-Task
to	I-Task
-	I-Task
fine	I-Task
generator	I-Task
We	O
decompose	O
the	O
generator	B-Method
into	O
two	O
sub	B-Method
-	I-Method
networks	I-Method
:	O
and	O
.	O
	
We	O
term	O
as	O
the	O
global	B-Method
generator	I-Method
network	I-Method
and	O
as	O
the	O
local	B-Method
enhancer	I-Method
network	I-Method
.	O
	
The	O
generator	B-Method
is	O
then	O
given	O
by	O
the	O
tuple	O
as	O
visualized	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
.	O
	
The	O
global	B-Method
generator	I-Method
network	I-Method
operates	O
at	O
a	O
resolution	O
of	O
,	O
and	O
the	O
local	B-Method
enhancer	I-Method
network	I-Method
outputs	O
an	O
image	O
with	O
a	O
resolution	O
that	O
is	O
the	O
output	O
size	O
of	O
the	O
previous	O
one	O
(	O
along	O
each	O
image	O
dimension	O
)	O
.	O
	
For	O
synthesizing	B-Task
images	I-Task
at	O
an	O
even	O
higher	O
resolution	O
,	O
additional	O
local	B-Method
enhancer	I-Method
networks	I-Method
could	O
be	O
utilized	O
.	O
	
For	O
example	O
,	O
the	O
output	O
image	O
resolution	O
of	O
the	O
generator	B-Method
is	O
,	O
and	O
the	O
output	O
image	B-Metric
resolution	I-Metric
of	O
is	O
.	O
	
Our	O
global	B-Method
generator	I-Method
is	O
built	O
on	O
the	O
architecture	O
proposed	O
by	O
Johnson	B-Method
,	O
which	O
has	O
been	O
proven	O
successful	O
for	O
neural	B-Task
style	I-Task
transfer	I-Task
on	O
images	O
up	O
to	O
.	O
	
It	O
consists	O
of	O
components	O
:	O
a	O
convolutional	B-Method
front	I-Method
-	I-Method
end	I-Method
,	O
a	O
set	O
of	O
residual	B-Method
blocks	I-Method
,	O
and	O
a	O
transposed	B-Method
convolutional	I-Method
back	I-Method
-	I-Method
end	I-Method
.	O
	
A	O
semantic	O
label	O
map	O
of	O
resolution	O
is	O
passed	O
through	O
the	O
3	O
components	O
sequentially	O
to	O
output	O
an	O
image	B-Task
of	I-Task
resolution	I-Task
.	O
	
The	O
local	B-Method
enhancer	I-Method
network	I-Method
also	O
consists	O
of	O
3	O
components	O
:	O
a	O
convolutional	B-Method
front	I-Method
-	I-Method
end	I-Method
,	O
a	O
set	O
of	O
residual	O
blocks	O
,	O
and	O
a	O
transposed	B-Method
convolutional	I-Method
back	I-Method
-	I-Method
end	I-Method
.	O
	
The	O
resolution	O
of	O
the	O
input	O
label	O
map	O
to	O
is	O
.	O
	
Different	O
from	O
the	O
global	B-Method
generator	I-Method
network	I-Method
,	O
the	O
input	O
to	O
the	O
residual	O
block	O
is	O
the	O
element	O
-	O
wise	O
sum	O
of	O
two	O
feature	O
maps	O
:	O
the	O
output	O
feature	O
map	O
of	O
,	O
and	O
the	O
last	O
feature	O
map	O
of	O
the	O
back	O
-	O
end	O
of	O
the	O
global	B-Method
generator	I-Method
network	I-Method
.	O
	
This	O
helps	O
integrating	O
the	O
global	O
information	O
from	O
to	O
.	O
	
During	O
training	O
,	O
we	O
first	O
train	O
the	O
global	B-Method
generator	I-Method
and	O
then	O
train	O
the	O
local	B-Method
enhancer	I-Method
in	O
the	O
order	O
of	O
their	O
resolutions	O
.	O
	
We	O
then	O
jointly	O
fine	O
-	O
tune	O
all	O
the	O
networks	O
together	O
.	O
	
We	O
use	O
this	O
generator	B-Method
design	I-Method
to	O
effectively	O
aggregate	O
global	O
and	O
local	O
information	O
for	O
the	O
image	B-Task
synthesis	I-Task
task	I-Task
.	O
	
We	O
note	O
that	O
such	O
a	O
multi	B-Method
-	I-Method
resolution	I-Method
pipeline	I-Method
is	O
a	O
well	O
-	O
established	O
practice	O
in	O
computer	B-Task
vision	I-Task
and	O
two	B-Task
-	I-Task
scale	I-Task
is	O
often	O
enough	O
.	O
	
Similar	O
ideas	O
but	O
different	O
architectures	O
could	O
be	O
found	O
in	O
recent	O
unconditional	B-Method
GANs	I-Method
and	O
conditional	B-Task
image	I-Task
generation	I-Task
.	O
	
Multi	B-Task
-	I-Task
scale	I-Task
discriminators	I-Task
High	I-Task
-	I-Task
resolution	I-Task
image	I-Task
synthesis	I-Task
poses	O
a	O
significant	O
challenge	O
to	O
the	O
GAN	B-Method
discriminator	I-Method
design	I-Method
.	O
	
To	O
differentiate	O
high	O
-	O
resolution	O
real	O
and	O
synthesized	O
images	O
,	O
the	O
discriminator	B-Method
needs	O
to	O
have	O
a	O
large	O
receptive	O
field	O
.	O
	
This	O
would	O
require	O
either	O
a	O
deeper	B-Method
network	I-Method
or	O
larger	O
convolutional	B-Method
kernels	I-Method
,	O
both	O
of	O
which	O
would	O
increase	O
the	O
network	O
capacity	O
and	O
potentially	O
cause	O
overfitting	O
.	O
	
Also	O
,	O
both	O
choices	O
demand	O
a	O
larger	O
memory	O
footprint	O
for	O
training	B-Task
,	O
which	O
is	O
already	O
a	O
scarce	O
resource	O
for	O
high	B-Task
-	I-Task
resolution	I-Task
image	I-Task
generation	I-Task
.	O
	
To	O
address	O
the	O
issue	O
,	O
we	O
propose	O
using	O
multi	B-Method
-	I-Method
scale	I-Method
discriminators	I-Method
.	O
	
We	O
use	O
discriminators	B-Method
that	O
have	O
an	O
identical	O
network	O
structure	O
but	O
operate	O
at	O
different	O
image	O
scales	O
.	O
	
We	O
will	O
refer	O
to	O
the	O
discriminators	O
as	O
,	O
and	O
.	O
	
Specifically	O
,	O
we	O
downsample	O
the	O
real	O
and	O
synthesized	O
high	O
-	O
resolution	O
images	O
by	O
a	O
factor	O
of	O
and	O
to	O
create	O
an	O
image	O
pyramid	O
of	O
3	O
scales	O
.	O
	
The	O
discriminators	O
,	O
and	O
are	O
then	O
trained	O
to	O
differentiate	O
real	O
and	O
synthesized	O
images	O
at	O
the	O
different	O
scales	O
,	O
respectively	O
.	O
	
Although	O
the	O
discriminators	B-Method
have	O
an	O
identical	O
architecture	O
,	O
the	O
one	O
that	O
operates	O
at	O
the	O
coarsest	O
scale	O
has	O
the	O
largest	O
receptive	O
field	O
.	O
	
It	O
has	O
a	O
more	O
global	O
view	O
of	O
the	O
image	O
and	O
can	O
guide	O
the	O
generator	B-Method
to	O
generate	O
globally	O
consistent	O
images	O
.	O
	
On	O
the	O
other	O
hand	O
,	O
the	O
discriminator	O
at	O
the	O
finest	O
scale	O
encourages	O
the	O
generator	B-Method
to	O
produce	O
finer	O
details	O
.	O
	
This	O
also	O
makes	O
training	O
the	O
coarse	B-Task
-	I-Task
to	I-Task
-	I-Task
fine	I-Task
generator	I-Task
easier	O
,	O
since	O
extending	O
a	O
low	B-Method
-	I-Method
resolution	I-Method
model	I-Method
to	O
a	O
higher	O
resolution	O
only	O
requires	O
adding	O
a	O
discriminator	B-Method
at	O
the	O
finest	O
level	O
,	O
rather	O
than	O
retraining	O
from	O
scratch	O
.	O
	
Without	O
the	O
multi	B-Method
-	I-Method
scale	I-Method
discriminators	I-Method
,	O
we	O
observe	O
that	O
many	O
repeated	O
patterns	O
often	O
appear	O
in	O
the	O
generated	O
images	O
.	O
	
With	O
the	O
discriminators	B-Method
,	O
the	O
learning	B-Task
problem	I-Task
in	O
Eq	O
.	O
	
(	O
[	O
reference	O
]	O
)	O
then	O
becomes	O
a	O
multi	B-Task
-	I-Task
task	I-Task
learning	I-Task
problem	I-Task
of	O
Using	O
multiple	O
GAN	B-Method
discriminators	I-Method
at	O
the	O
same	O
image	O
scale	O
has	O
been	O
proposed	O
in	O
unconditional	B-Method
GANs	I-Method
.	O
	
Iizuka	O
et	O
al	O
.	O
	
add	O
a	O
global	B-Method
image	I-Method
classifier	I-Method
to	O
conditional	B-Method
GANs	I-Method
to	O
synthesize	O
globally	O
coherent	O
content	O
for	O
inpainting	B-Task
.	O
	
Here	O
we	O
extend	O
the	O
design	O
to	O
multiple	O
discriminators	B-Method
at	O
different	O
image	O
scales	O
for	O
modeling	B-Task
high	I-Task
-	I-Task
resolution	I-Task
images	I-Task
.	O
	
Improved	O
adversarial	B-Metric
loss	I-Metric
	
We	O
improve	O
the	O
GAN	B-Metric
loss	I-Metric
in	O
Eq	O
.	O
	
(	O
[	O
reference	O
]	O
)	O
by	O
incorporating	O
a	O
feature	B-Method
matching	I-Method
loss	I-Method
based	O
on	O
the	O
discriminator	B-Method
.	O
	
This	O
loss	O
stabilizes	O
the	O
training	B-Task
as	O
the	O
generator	B-Method
has	O
to	O
produce	O
natural	O
statistics	O
at	O
multiple	O
scales	O
.	O
	
Specifically	O
,	O
we	O
extract	O
features	O
from	O
multiple	O
layers	O
of	O
the	O
discriminator	B-Method
and	O
learn	O
to	O
match	O
these	O
intermediate	B-Method
representations	I-Method
from	O
the	O
real	O
and	O
the	O
synthesized	O
image	O
.	O
	
For	O
ease	O
of	O
presentation	O
,	O
we	O
denote	O
the	O
th	B-Method
-	I-Method
layer	I-Method
feature	I-Method
extractor	I-Method
of	O
discriminator	B-Method
as	O
(	O
from	O
input	O
to	O
the	O
th	O
layer	O
of	O
)	O
.	O
	
The	O
feature	B-Metric
matching	I-Metric
loss	I-Metric
is	O
then	O
calculated	O
as	O
:	O
where	O
is	O
the	O
total	O
number	O
of	O
layers	O
and	O
denotes	O
the	O
number	O
of	O
elements	O
in	O
each	O
layer	O
.	O
	
Our	O
GAN	B-Method
discriminator	I-Method
feature	I-Method
matching	I-Method
loss	I-Method
is	O
related	O
to	O
the	O
perceptual	O
loss	O
,	O
which	O
has	O
been	O
shown	O
to	O
be	O
useful	O
for	O
image	B-Task
super	I-Task
-	I-Task
resolution	I-Task
and	I-Task
style	I-Task
transfer	I-Task
.	O
	
In	O
our	O
experiments	O
,	O
we	O
discuss	O
how	O
the	O
discriminator	B-Method
feature	I-Method
matching	I-Method
loss	I-Method
and	O
the	O
perceptual	O
loss	O
can	O
be	O
jointly	O
used	O
for	O
further	O
improving	O
the	O
performance	O
.	O
	
We	O
note	O
that	O
a	O
similar	O
loss	O
is	O
used	O
in	O
VAE	B-Method
-	I-Method
GANs	I-Method
.	O
	
Our	O
full	O
objective	O
combines	O
both	O
GAN	B-Metric
loss	I-Metric
and	O
feature	B-Task
matching	I-Task
loss	I-Task
as	O
:	O
where	O
controls	O
the	O
importance	O
of	O
the	O
two	O
terms	O
.	O
	
Note	O
that	O
for	O
the	O
feature	B-Task
matching	I-Task
loss	I-Task
,	O
only	O
serves	O
as	O
a	O
feature	B-Method
extractor	I-Method
and	O
does	O
not	O
maximize	O
the	O
loss	B-Metric
.	O
	
subsection	O
:	O
Using	O
Instance	B-Method
Maps	I-Method
	
Existing	O
image	B-Method
synthesis	I-Method
methods	I-Method
only	O
utilize	O
semantic	B-Method
label	I-Method
maps	I-Method
,	O
an	O
image	O
where	O
each	O
pixel	O
value	O
represents	O
the	O
object	O
class	O
of	O
the	O
pixel	O
.	O
	
This	O
map	O
does	O
not	O
differentiate	O
objects	O
of	O
the	O
same	O
category	O
.	O
	
On	O
the	O
other	O
hand	O
,	O
an	O
instance	O
-	O
level	O
semantic	O
label	O
map	O
contains	O
a	O
unique	O
object	O
ID	O
for	O
each	O
individual	O
object	O
.	O
	
To	O
incorporate	O
the	O
instance	O
map	O
,	O
one	O
can	O
directly	O
pass	O
it	O
into	O
the	O
network	O
,	O
or	O
encode	O
it	O
into	O
a	O
one	O
-	O
hot	O
vector	O
.	O
	
However	O
,	O
both	O
approaches	O
are	O
difficult	O
to	O
implement	O
in	O
practice	O
,	O
since	O
different	O
images	O
may	O
contain	O
different	O
numbers	O
of	O
objects	O
of	O
the	O
same	O
category	O
.	O
	
Alternatively	O
,	O
one	O
can	O
pre	O
-	O
allocate	O
a	O
fixed	O
number	O
of	O
channels	O
(	O
e.g.	O
,	O
)	O
for	O
each	O
class	O
,	O
but	O
this	O
method	O
fails	O
when	O
the	O
number	O
is	O
set	O
too	O
small	O
,	O
and	O
wastes	O
memory	O
when	O
the	O
number	O
is	O
too	O
large	O
.	O
	
Instead	O
,	O
we	O
argue	O
that	O
the	O
most	O
critical	O
information	O
the	O
instance	O
map	O
provides	O
,	O
which	O
is	O
not	O
available	O
in	O
the	O
semantic	B-Task
label	I-Task
map	I-Task
,	O
is	O
the	O
object	O
boundary	O
.	O
	
For	O
example	O
,	O
when	O
objects	O
of	O
the	O
same	O
class	O
are	O
next	O
to	O
one	O
another	O
,	O
looking	O
at	O
the	O
semantic	O
label	O
map	O
alone	O
can	O
not	O
tell	O
them	O
apart	O
.	O
	
This	O
is	O
especially	O
true	O
for	O
the	O
street	B-Task
scene	I-Task
since	O
many	O
parked	O
cars	O
or	O
walking	O
pedestrians	O
are	O
often	O
next	O
to	O
one	O
another	O
,	O
as	O
shown	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
	
a.	O
	
However	O
,	O
with	O
the	O
instance	B-Method
map	I-Method
,	O
separating	O
these	O
objects	O
becomes	O
an	O
easier	O
task	O
.	O
	
Therefore	O
,	O
to	O
extract	O
this	O
information	O
,	O
we	O
first	O
compute	O
the	O
instance	O
boundary	O
map	O
(	O
Fig	O
.	O
	
[	O
reference	O
]	O
b	O
)	O
.	O
	
In	O
our	O
implementation	O
,	O
a	O
pixel	O
in	O
the	O
instance	O
boundary	O
map	O
is	O
if	O
its	O
object	O
ID	O
is	O
different	O
from	O
any	O
of	O
its	O
-	O
neighbors	O
,	O
and	O
otherwise	O
.	O
	
The	O
instance	B-Method
boundary	I-Method
map	I-Method
is	O
then	O
concatenated	O
with	O
the	O
one	B-Method
-	I-Method
hot	I-Method
vector	I-Method
representation	I-Method
of	I-Method
the	I-Method
semantic	I-Method
label	I-Method
map	I-Method
,	O
and	O
fed	O
into	O
the	O
generator	B-Method
network	I-Method
.	O
	
Similarly	O
,	O
the	O
input	O
to	O
the	O
discriminator	B-Method
is	O
the	O
channel	B-Method
-	I-Method
wise	I-Method
concatenation	I-Method
of	I-Method
instance	I-Method
boundary	I-Method
map	I-Method
,	O
semantic	B-Method
label	I-Method
map	I-Method
,	O
and	O
the	O
real	O
/	O
synthesized	O
image	O
.	O
	
Figure	O
[	O
reference	O
]	O
	
b	O
shows	O
an	O
example	O
demonstrating	O
the	O
improvement	O
by	O
using	O
object	O
boundaries	O
.	O
	
Our	O
user	O
study	O
in	O
Sec	O
.	O
	
[	O
reference	O
]	O
also	O
shows	O
the	O
model	O
trained	O
with	O
instance	B-Method
boundary	I-Method
maps	I-Method
renders	O
more	O
photo	O
-	O
realistic	O
object	O
boundaries	O
.	O
	
subsection	O
:	O
Learning	O
an	O
Instance	B-Method
-	I-Method
level	I-Method
Feature	I-Method
Embedding	I-Method
	
Image	B-Task
synthesis	I-Task
from	O
semantic	B-Task
label	I-Task
maps	I-Task
is	O
a	O
one	B-Task
-	I-Task
to	I-Task
-	I-Task
many	I-Task
mapping	I-Task
problem	I-Task
.	O
	
An	O
ideal	O
image	B-Method
synthesis	I-Method
algorithm	I-Method
should	O
be	O
able	O
to	O
generate	O
diverse	O
,	O
realistic	O
images	O
using	O
the	O
same	O
semantic	O
label	O
map	O
.	O
	
Recently	O
,	O
several	O
works	O
learn	O
to	O
produce	O
a	O
fixed	O
number	O
of	O
discrete	O
outputs	O
given	O
the	O
same	O
input	O
or	O
synthesize	O
diverse	O
modes	O
controlled	O
by	O
a	O
latent	B-Method
code	I-Method
that	O
encodes	O
the	O
entire	O
image	O
.	O
	
Although	O
these	O
approaches	O
tackle	O
the	O
multi	B-Task
-	I-Task
modal	I-Task
image	I-Task
synthesis	I-Task
problem	I-Task
,	O
they	O
are	O
unsuitable	O
for	O
our	O
image	B-Task
manipulation	I-Task
task	I-Task
mainly	O
for	O
two	O
reasons	O
.	O
	
First	O
,	O
the	O
user	O
has	O
no	O
intuitive	O
control	O
over	O
which	O
kinds	O
of	O
images	O
the	O
model	O
would	O
produce	O
.	O
	
Second	O
,	O
these	O
methods	O
focus	O
on	O
global	O
color	O
and	O
texture	O
changes	O
and	O
allow	O
no	O
object	O
-	O
level	O
control	O
on	O
the	O
generated	O
contents	O
.	O
	
To	O
generate	O
diverse	O
images	O
and	O
allow	O
instance	B-Task
-	I-Task
level	I-Task
control	I-Task
,	O
we	O
propose	O
adding	O
additional	O
low	O
-	O
dimensional	O
feature	O
channels	O
as	O
the	O
input	O
to	O
the	O
generator	B-Method
network	I-Method
.	O
	
We	O
show	O
that	O
,	O
by	O
manipulating	O
these	O
features	O
,	O
we	O
can	O
have	O
flexible	O
control	O
over	O
the	O
image	B-Task
synthesis	I-Task
process	I-Task
.	O
	
Furthermore	O
,	O
note	O
that	O
since	O
the	O
feature	O
channels	O
are	O
continuous	O
quantities	O
,	O
our	O
model	O
is	O
,	O
in	O
principle	O
,	O
capable	O
of	O
generating	O
infinitely	O
many	O
images	O
.	O
	
To	O
generate	O
the	O
low	O
-	O
dimensional	O
features	O
,	O
we	O
train	O
an	O
encoder	B-Method
network	I-Method
to	O
find	O
a	O
low	O
-	O
dimensional	O
feature	O
vector	O
that	O
corresponds	O
to	O
the	O
ground	O
truth	O
target	O
for	O
each	O
instance	O
in	O
the	O
image	O
.	O
	
Our	O
feature	B-Method
encoder	I-Method
architecture	I-Method
is	O
a	O
standard	O
encoder	B-Method
-	I-Method
decoder	I-Method
network	I-Method
.	O
	
To	O
ensure	O
the	O
features	O
are	O
consistent	O
within	O
each	O
instance	O
,	O
we	O
add	O
an	O
instance	B-Method
-	I-Method
wise	I-Method
average	I-Method
pooling	I-Method
layer	I-Method
to	O
the	O
output	O
of	O
the	O
encoder	O
to	O
compute	O
the	O
average	O
feature	O
for	O
the	O
object	O
instance	O
.	O
	
The	O
average	O
feature	O
is	O
then	O
broadcast	O
to	O
all	O
the	O
pixel	O
locations	O
of	O
the	O
instance	O
.	O
	
Figure	O
[	O
reference	O
]	O
visualizes	O
an	O
example	O
of	O
the	O
encoded	O
features	O
.	O
	
We	O
replace	O
with	O
in	O
Eq	O
.	O
	
(	O
[	O
reference	O
]	O
)	O
and	O
train	O
the	O
encoder	B-Method
jointly	O
with	O
the	O
generators	B-Method
and	I-Method
discriminators	I-Method
.	O
	
After	O
the	O
encoder	B-Method
is	O
trained	O
,	O
we	O
run	O
it	O
on	O
all	O
instances	O
in	O
the	O
training	O
images	O
and	O
record	O
the	O
obtained	O
features	O
.	O
	
Then	O
we	O
perform	O
a	O
-	B-Method
means	I-Method
clustering	I-Method
on	O
these	O
features	O
for	O
each	O
semantic	O
category	O
.	O
	
Each	O
cluster	O
thus	O
encodes	O
the	O
features	O
for	O
a	O
specific	O
style	O
,	O
for	O
example	O
,	O
the	O
asphalt	O
or	O
cobblestone	O
texture	O
for	O
a	O
road	O
.	O
	
At	O
inference	O
time	O
,	O
we	O
randomly	O
pick	O
one	O
of	O
the	O
cluster	O
centers	O
and	O
use	O
it	O
as	O
the	O
encoded	O
features	O
.	O
	
These	O
features	O
are	O
concatenated	O
with	O
the	O
label	O
map	O
and	O
used	O
as	O
the	O
input	O
to	O
our	O
generator	O
.	O
	
We	O
tried	O
to	O
enforce	O
the	O
Kullback	O
-	O
Leibler	O
loss	O
on	O
the	O
feature	O
space	O
for	O
better	O
test	B-Task
-	I-Task
time	I-Task
sampling	I-Task
as	O
used	O
in	O
the	O
recent	O
work	O
but	O
found	O
it	O
quite	O
involved	O
for	O
users	O
to	O
adjust	O
the	O
latent	O
vectors	O
for	O
each	O
object	O
directly	O
.	O
	
Instead	O
,	O
for	O
each	O
object	O
instance	O
,	O
we	O
present	O
modes	O
for	O
users	O
to	O
choose	O
from	O
.	O
	
section	O
:	O
Results	O
	
We	O
first	O
provide	O
a	O
quantitative	O
comparison	O
against	O
leading	O
methods	O
in	O
Sec	O
.	O
	
[	O
reference	O
]	O
.	O
	
We	O
then	O
report	O
a	O
subjective	O
human	O
perceptual	O
study	O
in	O
Sec	O
.	O
	
[	O
reference	O
]	O
.	O
	
Finally	O
,	O
we	O
show	O
a	O
few	O
examples	O
of	O
interactive	B-Task
object	I-Task
editing	I-Task
results	O
in	O
Sec	O
.	O
	
[	O
reference	O
]	O
.	O
	
Implementation	O
details	O
We	O
use	O
LSGANs	B-Method
for	O
stable	B-Task
training	I-Task
.	O
	
In	O
all	O
experiments	O
,	O
we	O
set	O
the	O
weight	O
(	O
Eq	O
.	O
	
(	O
[	O
reference	O
]	O
)	O
)	O
and	O
for	O
K	B-Method
-	I-Method
means	I-Method
.	O
	
We	O
use	O
-	O
dimensional	O
vectors	O
to	O
encode	O
features	O
for	O
each	O
object	O
instance	O
.	O
	
We	O
experimented	O
with	O
adding	O
a	O
perceptual	B-Metric
loss	I-Metric
to	O
our	O
objective	O
(	O
Eq	O
.	O
	
(	O
[	O
reference	O
]	O
)	O
)	O
,	O
where	O
and	O
denotes	O
the	O
-	O
th	O
layer	O
with	O
elements	O
of	O
the	O
VGG	B-Method
network	I-Method
.	O
	
We	O
observe	O
that	O
this	O
loss	O
slightly	O
improves	O
the	O
results	O
.	O
	
We	O
name	O
these	O
two	O
variants	O
as	O
ours	O
and	O
ours	O
(	O
w	B-Method
/	I-Method
o	I-Method
VGG	I-Method
loss	I-Method
)	O
.	O
	
Please	O
find	O
more	O
training	O
and	O
architecture	O
details	O
in	O
the	O
appendix	O
.	O
	
Datasets	O
We	O
conduct	O
extensive	O
comparisons	O
and	O
ablation	O
studies	O
on	O
Cityscapes	B-Material
dataset	I-Material
and	O
NYU	B-Material
Indoor	I-Material
RGBD	I-Material
dataset	I-Material
.	O
	
We	O
report	O
additional	O
qualitative	O
results	O
on	O
ADE20	B-Material
K	I-Material
dataset	I-Material
and	O
Helen	B-Material
Face	I-Material
dataset	I-Material
.	O
	
Baselines	O
	
We	O
compare	O
our	O
method	O
with	O
two	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
algorithms	O
:	O
pix2pix	B-Method
and	O
CRN	B-Method
.	O
	
We	O
train	O
pix2pix	B-Method
models	I-Method
on	O
high	O
-	O
res	O
images	O
with	O
the	O
default	O
setting	O
.	O
	
We	O
produce	O
the	O
high	O
-	O
res	O
CRN	O
images	O
via	O
the	O
authors	O
’	O
publicly	O
available	O
model	O
.	O
	
subsection	O
:	O
Quantitative	O
Comparisons	O
	
We	O
adopt	O
the	O
same	O
evaluation	O
protocol	O
from	O
previous	O
image	B-Task
-	I-Task
to	I-Task
-	I-Task
image	I-Task
translation	I-Task
works	O
.	O
	
To	O
quantify	O
the	O
quality	O
of	O
our	O
results	O
,	O
we	O
perform	O
semantic	B-Task
segmentation	I-Task
on	O
the	O
synthesized	O
images	O
and	O
compare	O
how	O
well	O
the	O
predicted	O
segments	O
match	O
the	O
input	O
.	O
	
The	O
intuition	O
is	O
that	O
if	O
we	O
can	O
produce	O
realistic	O
images	O
that	O
correspond	O
to	O
the	O
input	O
label	O
map	O
,	O
an	O
off	O
-	O
the	O
-	O
shelf	O
semantic	B-Method
segmentation	I-Method
model	I-Method
(	O
e.g.	O
,	O
PSPNet	B-Method
that	O
we	O
use	O
)	O
should	O
be	O
able	O
to	O
predict	O
the	O
ground	O
truth	O
label	O
.	O
	
Table	O
[	O
reference	O
]	O
reports	O
the	O
calculated	O
segmentation	B-Metric
accuracy	I-Metric
.	O
	
As	O
can	O
be	O
seen	O
,	O
for	O
both	O
pixel	B-Metric
-	I-Metric
wise	I-Metric
accuracy	I-Metric
and	O
mean	O
intersection	B-Metric
-	I-Metric
over	I-Metric
-	I-Metric
union	I-Metric
(	O
IoU	B-Metric
)	O
,	O
our	O
method	O
outperforms	O
the	O
other	O
methods	O
by	O
a	O
large	O
margin	O
.	O
	
Moreover	O
,	O
our	O
result	O
is	O
very	O
close	O
to	O
the	O
result	O
of	O
the	O
original	O
images	O
,	O
the	O
theoretical	O
“	O
upper	O
bound	O
”	O
of	O
the	O
realism	B-Metric
we	O
can	O
achieve	O
.	O
	
This	O
justifies	O
the	O
superiority	O
of	O
our	O
algorithm	O
.	O
	
subsection	O
:	O
Human	B-Task
Perceptual	I-Task
Study	I-Task
	
We	O
further	O
evaluate	O
our	O
algorithm	O
via	O
a	O
human	B-Metric
subjective	I-Metric
study	I-Metric
.	O
	
We	O
perform	O
pairwise	O
A	O
/	O
B	O
tests	O
deployed	O
on	O
the	O
Amazon	B-Method
Mechanical	I-Method
Turk	I-Method
(	O
MTurk	B-Method
)	O
platform	O
on	O
the	O
Cityscapes	B-Material
dataset	I-Material
.	O
	
We	O
follow	O
the	O
same	O
experimental	O
procedure	O
as	O
described	O
in	O
Chen	O
and	O
Koltun	O
.	O
	
More	O
specifically	O
,	O
two	O
different	O
kinds	O
of	O
experiments	O
are	O
conducted	O
:	O
unlimited	O
time	O
and	O
limited	O
time	O
,	O
as	O
explained	O
below	O
.	O
	
Unlimited	O
time	O
For	O
this	O
task	O
,	O
workers	O
are	O
given	O
two	O
images	O
at	O
once	O
,	O
each	O
of	O
which	O
is	O
synthesized	O
by	O
a	O
different	O
method	O
for	O
the	O
same	O
label	O
map	O
.	O
	
We	O
give	O
them	O
unlimited	O
time	O
to	O
select	O
which	O
image	O
looks	O
more	O
natural	O
.	O
	
The	O
left	O
-	O
right	O
order	O
and	O
the	O
image	O
order	O
are	O
randomized	O
to	O
ensure	O
fair	O
comparisons	O
.	O
	
All	O
Cityscapes	B-Material
test	O
images	O
are	O
compared	O
times	O
,	O
resulting	O
in	O
human	O
judgments	O
for	O
each	O
method	O
.	O
	
In	O
this	O
experiment	O
,	O
we	O
use	O
the	O
model	O
trained	O
on	O
labels	O
only	O
(	O
without	O
instance	O
maps	O
)	O
to	O
ensure	O
a	O
fair	O
comparison	O
.	O
	
Table	O
[	O
reference	O
]	O
shows	O
that	O
both	O
variants	O
of	O
our	O
method	O
outperform	O
the	O
other	O
methods	O
significantly	O
.	O
	
Limited	O
time	O
	
Next	O
,	O
for	O
the	O
limited	B-Task
time	I-Task
experiment	I-Task
,	O
we	O
compare	O
our	O
result	O
with	O
CRN	B-Method
and	O
the	O
original	O
image	O
(	O
ground	O
truth	O
)	O
.	O
	
In	O
each	O
comparison	O
,	O
we	O
show	O
results	O
of	O
two	O
methods	O
for	O
a	O
short	O
period	O
of	O
time	O
.	O
	
We	O
randomly	O
select	O
a	O
duration	O
between	O
seconds	O
and	O
seconds	O
,	O
as	O
adopted	O
by	O
prior	O
work	O
.	O
	
This	O
evaluates	O
how	O
quickly	O
the	O
difference	O
between	O
the	O
images	O
can	O
be	O
perceived	O
.	O
	
Fig	O
.	O
	
[	O
reference	O
]	O
shows	O
the	O
comparison	O
results	O
at	O
different	O
time	O
intervals	O
.	O
	
As	O
the	O
given	O
time	O
becomes	O
longer	O
and	O
longer	O
,	O
the	O
differences	O
between	O
these	O
three	O
types	O
of	O
images	O
become	O
more	O
apparent	O
and	O
easier	O
to	O
observe	O
.	O
	
Figures	O
[	O
reference	O
]	O
and	O
[	O
reference	O
]	O
show	O
some	O
example	O
results	O
.	O
	
Analysis	O
of	O
the	O
loss	O
function	O
We	O
also	O
study	O
the	O
importance	O
of	O
each	O
term	O
in	O
our	O
objective	B-Metric
function	I-Metric
using	O
the	O
unlimited	O
time	O
experiment	O
.	O
	
Specifically	O
,	O
our	O
final	O
loss	O
contains	O
three	O
components	O
:	O
GAN	B-Method
loss	I-Method
,	O
discriminator	B-Method
-	I-Method
based	I-Method
feature	I-Method
matching	I-Method
loss	I-Method
,	O
and	O
VGG	B-Method
perceptual	I-Method
loss	I-Method
.	O
	
We	O
compare	O
our	O
final	O
implementation	O
to	O
the	O
results	O
using	O
(	O
)	O
only	O
GAN	O
loss	O
,	O
and	O
(	O
)	O
GAN	O
feature	O
matching	O
loss	O
(	O
i.e.	O
,	O
without	O
VGG	O
loss	O
)	O
.	O
	
The	O
obtained	O
preference	B-Metric
rates	I-Metric
are	O
and	O
,	O
respectively	O
.	O
	
As	O
can	O
be	O
seen	O
,	O
adding	O
the	O
feature	B-Method
matching	I-Method
loss	I-Method
substantially	O
improves	O
the	O
performance	O
,	O
while	O
adding	O
perceptual	O
loss	O
further	O
enhances	O
the	O
results	O
.	O
	
However	O
,	O
note	O
that	O
using	O
the	O
perceptual	O
loss	O
is	O
not	O
critical	O
,	O
and	O
we	O
are	O
still	O
able	O
to	O
generate	O
visually	O
appealing	O
results	O
even	O
without	O
it	O
(	O
e.g.	O
,	O
Figs	O
.	O
	
[	O
reference	O
]	O
c	O
,	O
[	O
reference	O
]	O
b	O
)	O
.	O
	
Using	O
instance	B-Method
maps	I-Method
We	O
compare	O
the	O
results	O
using	O
instance	B-Method
maps	I-Method
to	O
results	O
without	O
using	O
them	O
.	O
	
We	O
highlight	O
the	O
car	O
regions	O
in	O
the	O
images	O
and	O
ask	O
the	O
participants	O
to	O
choose	O
which	O
region	O
looks	O
more	O
realistic	O
.	O
	
We	O
obtain	O
a	O
preference	B-Metric
rate	I-Metric
of	O
,	O
which	O
indicates	O
that	O
using	O
instance	B-Method
maps	I-Method
improves	O
the	O
realism	O
of	O
our	O
results	O
,	O
especially	O
around	O
the	O
object	O
boundaries	O
.	O
	
Analysis	O
of	O
the	O
generator	O
We	O
compare	O
results	O
of	O
different	O
generators	O
with	O
all	O
the	O
other	O
components	O
fixed	O
.	O
	
In	O
particular	O
,	O
we	O
compare	O
our	O
generator	O
with	O
two	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
generator	B-Method
architectures	I-Method
:	O
U	B-Method
-	I-Method
Net	I-Method
and	O
CRN	B-Method
.	O
	
We	O
evaluate	O
the	O
performance	O
regarding	O
both	O
semantic	B-Metric
segmentation	I-Metric
scores	I-Metric
and	O
human	O
perceptual	O
study	O
results	O
.	O
	
Table	O
[	O
reference	O
]	O
and	O
Table	O
[	O
reference	O
]	O
show	O
that	O
our	O
coarse	B-Method
-	I-Method
to	I-Method
-	I-Method
fine	I-Method
generator	I-Method
outperforms	O
other	O
networks	O
by	O
a	O
large	O
margin	O
.	O
	
Analysis	O
of	O
the	O
discriminator	O
	
Next	O
,	O
we	O
also	O
compare	O
results	O
using	O
our	O
multi	B-Method
-	I-Method
scale	I-Method
discriminators	I-Method
and	O
results	O
using	O
only	O
one	O
discriminator	O
while	O
we	O
keep	O
the	O
generator	B-Method
and	O
the	O
loss	O
function	O
fixed	O
.	O
	
The	O
segmentation	B-Metric
scores	I-Metric
on	O
Cityscapes	B-Material
(	O
Table	O
[	O
reference	O
]	O
)	O
demonstrate	O
that	O
using	O
multi	B-Method
-	I-Method
scale	I-Method
discriminators	I-Method
helps	O
produce	O
higher	O
quality	O
results	O
as	O
well	O
as	O
stabilize	O
the	O
adversarial	B-Method
training	I-Method
.	O
	
We	O
also	O
perform	O
pairwise	B-Metric
A	I-Metric
/	I-Metric
B	I-Metric
tests	I-Metric
on	O
the	O
Amazon	B-Method
Mechanical	I-Method
Turk	I-Method
platform	I-Method
.	O
	
of	O
the	O
participants	O
prefer	O
our	O
results	O
with	O
multi	B-Method
-	I-Method
scale	I-Method
discriminators	I-Method
over	O
the	O
results	O
trained	O
with	O
a	O
single	O
-	O
scale	B-Method
discriminator	I-Method
(	O
Chance	O
is	O
)	O
.	O
	
Additional	O
datasets	O
To	O
further	O
evaluate	O
our	O
method	O
	
,	O
we	O
perform	O
unlimited	O
time	O
comparisons	O
on	O
the	O
NYU	B-Material
dataset	I-Material
.	O
	
We	O
obtain	O
and	O
against	O
pix2pix	B-Method
and	O
CRN	B-Method
,	O
respectively	O
.	O
	
Fig	O
.	O
	
[	O
reference	O
]	O
show	O
some	O
example	O
images	O
.	O
	
Finally	O
,	O
we	O
show	O
results	O
on	O
the	O
ADE20	B-Material
K	I-Material
dataset	I-Material
(	O
Fig	O
.	O
	
[	O
reference	O
]	O
)	O
.	O
	
subsection	O
:	O
Interactive	B-Task
Object	I-Task
Editing	I-Task
	
Our	O
feature	B-Method
encoder	I-Method
allows	O
us	O
to	O
perform	O
interactive	B-Task
instance	I-Task
editing	I-Task
on	O
the	O
resulting	O
images	O
.	O
	
For	O
example	O
,	O
we	O
can	O
change	O
the	O
object	O
labels	O
in	O
the	O
image	O
to	O
quickly	O
create	O
novel	O
scenes	O
,	O
such	O
as	O
replacing	O
trees	O
with	O
buildings	O
(	O
Fig	O
.	O
	
[	O
reference	O
]	O
b	O
)	O
.	O
	
We	O
can	O
also	O
change	O
the	O
colors	O
of	O
individual	O
cars	O
or	O
the	O
textures	O
of	O
the	O
road	O
(	O
Fig	O
.	O
	
[	O
reference	O
]	O
c	O
)	O
.	O
	
Please	O
check	O
out	O
our	O
interactive	O
demos	O
on	O
our	O
website	O
.	O
	
Besides	O
,	O
we	O
implement	O
our	O
interactive	B-Method
object	I-Method
editing	I-Method
feature	I-Method
on	O
the	O
Helen	B-Material
Face	I-Material
dataset	I-Material
where	O
labels	O
for	O
different	O
facial	O
parts	O
are	O
available	O
	
(	O
Fig	O
.	O
	
[	O
reference	O
]	O
)	O
.	O
	
This	O
makes	O
it	O
easy	O
to	O
edit	O
human	O
portraits	O
,	O
e.g.	O
,	O
changing	O
the	O
face	O
color	O
to	O
mimic	O
different	O
make	O
-	O
up	O
effects	O
or	O
adding	O
beard	O
to	O
a	O
face	O
.	O
	
section	O
:	O
Discussion	O
and	O
Conclusion	O
	
The	O
results	O
in	O
this	O
paper	O
suggest	O
that	O
conditional	B-Method
GANs	I-Method
can	O
synthesize	O
high	O
-	O
resolution	O
photo	O
-	O
realistic	O
imagery	O
without	O
any	O
hand	O
-	O
crafted	O
losses	O
or	O
pre	B-Method
-	I-Method
trained	I-Method
networks	I-Method
.	O
	
We	O
have	O
observed	O
that	O
incorporating	O
a	O
perceptual	O
loss	O
can	O
slightly	O
improve	O
the	O
results	O
.	O
	
Our	O
method	O
allows	O
many	O
applications	O
and	O
will	O
be	O
potentially	O
useful	O
for	O
domains	O
where	O
high	O
-	O
resolution	O
results	O
are	O
in	O
demand	O
but	O
pre	O
-	O
trained	B-Method
networks	I-Method
are	O
not	O
available	O
(	O
e.g.	O
,	O
medical	O
imaging	O
and	O
biology	O
)	O
.	O
	
This	O
paper	O
also	O
shows	O
that	O
an	O
image	B-Method
-	I-Method
to	I-Method
-	I-Method
image	I-Method
synthesis	I-Method
pipeline	I-Method
can	O
be	O
extended	O
to	O
produce	O
diverse	O
outputs	O
,	O
and	O
enable	O
interactive	B-Task
image	I-Task
manipulation	I-Task
given	O
appropriate	O
training	O
input	O
-	O
output	O
pairs	O
(	O
e.g.	O
,	O
instance	O
maps	O
in	O
our	O
case	O
)	O
.	O
	
Without	O
ever	O
been	O
told	O
what	O
a	O
“	O
texture	O
”	O
is	O
,	O
our	O
model	O
learns	O
to	O
stylize	O
different	O
objects	O
,	O
which	O
may	O
be	O
generalized	O
to	O
other	O
datasets	O
as	O
well	O
(	O
i.e.	O
,	O
using	O
textures	O
in	O
one	O
dataset	O
to	O
synthesize	O
images	O
in	O
another	O
dataset	O
)	O
.	O
	
We	O
believe	O
these	O
extensions	O
can	O
be	O
potentially	O
applied	O
to	O
other	O
image	B-Task
synthesis	I-Task
problems	I-Task
.	O
	
Acknowledgements	O
We	O
thank	O
Taesung	O
Park	O
,	O
Phillip	O
Isola	O
,	O
Tinghui	O
Zhou	O
,	O
Richard	O
Zhang	O
,	O
Rafael	O
Valle	O
and	O
Alexei	O
A.	O
Efros	O
for	O
helpful	O
comments	O
.	O
	
We	O
also	O
thank	O
Chen	O
and	O
Koltun	O
and	O
Isola	O
et	O
al	O
.	O
for	O
sharing	O
their	O
code	O
.	O
	
JYZ	B-Method
is	O
supported	O
by	O
a	O
Facebook	O
graduate	O
fellowship	O
.	O
	
bibliography	O
:	O
References	O
	
appendix	O
:	O
Training	O
Details	O
	
All	O
the	O
networks	O
were	O
trained	O
from	O
scratch	O
,	O
using	O
the	O
Adam	B-Method
solver	I-Method
and	O
a	O
learning	B-Metric
rate	I-Metric
of	O
.	O
	
We	O
keep	O
the	O
same	O
learning	B-Metric
rate	I-Metric
for	O
the	O
first	O
epochs	O
and	O
linearly	O
decay	O
the	O
rate	O
to	O
zero	O
over	O
the	O
next	O
epochs	O
.	O
	
Weights	O
were	O
initialized	O
from	O
a	O
Gaussian	B-Method
distribution	I-Method
with	O
mean	O
and	O
standard	O
deviation	O
.	O
	
We	O
train	O
all	O
our	O
models	O
on	O
an	O
NVIDIA	O
	
Quadro	B-Method
M6000	I-Method
GPU	I-Method
with	O
GB	B-Method
GPU	I-Method
memory	I-Method
.	O
	
The	O
inference	B-Metric
time	I-Metric
is	O
between	O
milliseconds	O
per	O
input	O
image	O
on	O
an	O
NVIDIA	B-Method
1080Ti	I-Method
GPU	I-Method
with	O
GB	B-Method
GPU	I-Method
memory	I-Method
.	O
	
This	O
real	O
-	O
time	O
performance	O
allows	O
us	O
to	O
develop	O
interactive	B-Task
image	I-Task
editing	I-Task
applications	I-Task
.	O
	
Below	O
we	O
discuss	O
the	O
details	O
of	O
the	O
datasets	O
we	O
used	O
.	O
	
Cityscapes	B-Material
dataset	I-Material
[	O
]	O
:	O
training	O
images	O
from	O
the	O
Cityscapes	B-Material
training	O
set	O
with	O
image	O
size	O
.	O
	
We	O
use	O
the	O
Cityscapes	B-Material
validation	O
set	O
for	O
testing	O
,	O
which	O
consists	O
of	O
500	O
images	O
.	O
	
NYU	B-Material
Indoor	I-Material
RGBD	I-Material
dataset	I-Material
[	O
]	O
:	O
training	O
images	O
and	O
test	O
images	O
,	O
all	O
at	O
resolution	O
of	O
.	O
	
ADE20	B-Material
	
K	O
dataset	O
[	O
]	O
:	O
training	O
images	O
and	O
test	O
images	O
with	O
varying	O
image	O
sizes	O
.	O
	
We	O
scale	O
the	O
width	O
of	O
all	O
images	O
to	O
before	O
training	O
and	O
inference	B-Task
.	O
	
Helen	B-Material
Face	I-Material
dataset	I-Material
[	O
]	O
:	O
training	O
images	O
and	O
test	O
images	O
with	O
varying	O
image	O
sizes	O
.	O
	
We	O
resize	O
all	O
images	O
to	O
before	O
training	O
and	O
inference	B-Task
.	O
	
appendix	O
:	O
Generator	B-Method
Architectures	I-Method
	
Our	O
generator	O
consists	O
of	O
a	O
global	B-Method
generator	I-Method
network	I-Method
and	O
a	O
local	B-Method
enhancer	I-Method
network	I-Method
.	O
	
we	O
follow	O
the	O
naming	O
convention	O
used	O
in	O
Johnson	O
el	O
al	O
.	O
	
and	O
CycleGAN	O
.	O
	
Let	O
c7s1	B-Method
-	I-Method
k	I-Method
denote	O
a	O
Convolution	B-Method
-	I-Method
InstanceNorm	I-Method
-	I-Method
ReLU	I-Method
layer	I-Method
with	O
filters	B-Method
and	O
stride	O
.	O
	
dk	B-Method
denotes	O
a	O
Convolution	B-Method
-	I-Method
InstanceNorm	I-Method
-	I-Method
ReLU	I-Method
layer	I-Method
with	O
filters	B-Method
,	O
and	O
stride	O
.	O
	
We	O
use	O
reflection	O
padding	O
to	O
reduce	O
boundary	O
artifacts	O
.	O
	
Rk	B-Method
denotes	O
a	O
residual	O
block	O
that	O
contains	O
two	O
convolutional	B-Method
layers	I-Method
with	O
the	O
same	O
number	O
of	O
filters	O
on	O
both	O
layers	O
.	O
	
uk	B-Method
denotes	O
a	O
fractional	B-Method
-	I-Method
strided	I-Method
-	I-Method
Convolution	I-Method
-	I-Method
InstanceNorm	I-Method
-	I-Method
ReLU	I-Method
layer	I-Method
with	O
filters	B-Method
,	O
and	O
stride	O
.	O
	
Recall	O
that	O
we	O
have	O
two	O
generators	O
:	O
	
the	O
global	B-Method
generator	I-Method
and	O
the	O
local	B-Method
enhancer	I-Method
.	O
	
Our	O
global	B-Method
network	I-Method
:	O
c7s1	O
-	O
64	O
,	O
d128	O
,	O
d256	O
,	O
d512	O
,	O
d1024	O
,	O
R1024	O
,	O
R1024	O
,	O
R1024	O
,	O
R1024	O
,	O
R1024	O
,	O
R1024	O
,	O
R1024	O
,	O
R1024	O
,	O
R1024	O
,	O
u512	O
,	O
u256	O
,	O
u128	O
,	O
u64	O
,	O
c7s1	O
-	O
3	O
	
Our	O
local	B-Method
enhancer	I-Method
:	O
	
c7s1	O
-	O
32	O
,	O
d64We	O
add	O
the	O
last	O
feature	O
map	O
(	O
u64	O
)	O
in	O
our	O
global	B-Method
network	I-Method
to	O
the	O
output	O
of	O
this	O
layer.	O
,	O
R64	O
,	O
R64	O
,	O
R64	O
,	O
u32	O
,	O
c7s1	O
-	O
3	O
	
appendix	O
:	O
Discriminator	B-Method
Architectures	I-Method
	
For	O
discriminator	B-Method
networks	I-Method
,	O
we	O
use	O
PatchGAN	B-Method
.	O
	
Let	O
Ck	B-Method
denote	O
a	O
Convolution	B-Method
-	I-Method
InstanceNorm	I-Method
-	I-Method
LeakyReLU	I-Method
layer	I-Method
with	O
k	O
filters	B-Method
and	O
stride	O
.	O
	
After	O
the	O
last	O
layer	O
,	O
we	O
apply	O
a	O
convolution	B-Method
to	O
produce	O
a	O
dimensional	O
output	O
.	O
	
We	O
do	O
not	O
use	O
InstanceNorm	B-Method
for	O
the	O
first	O
C64	B-Method
layer	I-Method
.	O
	
We	O
use	O
leaky	O
ReLUs	O
with	O
slope	O
.	O
	
All	O
our	O
three	O
discriminators	O
have	O
the	O
identical	O
architecture	O
as	O
follows	O
:	O
	
C64	O
-	O
C128	O
-	O
C256	O
-	O
C512	O
	
appendix	O
:	O
Change	O
log	O
	
paragraph	O
:	O
v1	O
	
initial	O
preprint	O
release	O
	
paragraph	O
:	O
v2	O
	
CVPR	B-Method
camera	I-Method
ready	O
,	O
adding	O
more	O
results	O
for	O
edge	B-Task
-	I-Task
to	I-Task
-	I-Task
photo	I-Task
examples	I-Task
.	O
	
document	O
:	O
Spatial	B-Method
Pyramid	I-Method
Pooling	I-Method
in	O
Deep	B-Method
Convolutional	I-Method
Networks	I-Method
for	O
Visual	B-Task
Recognition	I-Task
	
Existing	O
deep	B-Method
convolutional	I-Method
neural	I-Method
networks	I-Method
(	O
CNNs	B-Method
)	O
require	O
a	O
fixed	O
-	O
size	O
(	O
,	O
224	O
224	O
)	O
input	O
image	O
.	O
	
This	O
requirement	O
is	O
“	O
artificial	O
”	O
and	O
may	O
reduce	O
the	O
recognition	B-Metric
accuracy	I-Metric
for	O
the	O
images	O
or	O
sub	O
-	O
images	O
of	O
an	O
arbitrary	O
size	O
/	O
scale	O
.	O
	
In	O
this	O
work	O
,	O
we	O
equip	O
the	O
networks	O
with	O
another	O
pooling	B-Method
strategy	I-Method
,	O
	
“	O
spatial	B-Method
pyramid	I-Method
pooling	I-Method
”	O
,	O
to	O
eliminate	O
the	O
above	O
requirement	O
.	O
	
The	O
new	O
network	B-Method
structure	I-Method
,	O
called	O
SPP	B-Method
-	I-Method
net	I-Method
,	O
can	O
generate	O
a	O
fixed	B-Method
-	I-Method
length	I-Method
representation	I-Method
regardless	O
of	O
image	O
size	O
/	O
scale	O
.	O
	
Pyramid	B-Method
pooling	I-Method
is	O
also	O
robust	O
to	O
object	O
deformations	O
.	O
	
With	O
these	O
advantages	O
,	O
SPP	B-Method
-	I-Method
net	I-Method
should	O
in	O
general	O
improve	O
all	O
CNN	B-Method
-	I-Method
based	I-Method
image	I-Method
classification	I-Method
methods	I-Method
.	O
	
On	O
the	O
ImageNet	B-Material
2012	I-Material
dataset	I-Material
,	O
we	O
demonstrate	O
that	O
SPP	B-Method
-	I-Method
net	I-Method
boosts	O
the	O
accuracy	B-Metric
of	O
a	O
variety	O
of	O
CNN	B-Method
architectures	I-Method
despite	O
their	O
different	O
designs	O
.	O
	
On	O
the	O
Pascal	B-Material
VOC	I-Material
2007	I-Material
and	O
Caltech101	B-Material
datasets	I-Material
,	O
SPP	B-Method
-	I-Method
net	I-Method
achieves	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
classification	B-Task
results	O
using	O
a	O
single	O
full	B-Method
-	I-Method
image	I-Method
representation	I-Method
and	O
no	O
fine	B-Method
-	I-Method
tuning	I-Method
.	O
	
The	O
power	O
of	O
SPP	B-Method
-	I-Method
net	I-Method
is	O
also	O
significant	O
in	O
object	B-Task
detection	I-Task
.	O
	
Using	O
SPP	B-Method
-	I-Method
net	I-Method
,	O
we	O
compute	O
the	O
feature	O
maps	O
from	O
the	O
entire	O
image	O
only	O
once	O
,	O
and	O
then	O
pool	O
features	O
in	O
arbitrary	O
regions	O
(	O
sub	O
-	O
images	O
)	O
to	O
generate	O
fixed	B-Method
-	I-Method
length	I-Method
representations	I-Method
for	O
training	O
the	O
detectors	O
.	O
	
This	O
method	O
avoids	O
repeatedly	O
computing	O
the	O
convolutional	O
features	O
.	O
	
In	O
processing	O
test	O
images	O
,	O
our	O
method	O
is	O
24	O
-	O
102	O
faster	O
than	O
the	O
R	B-Method
-	I-Method
CNN	I-Method
method	I-Method
,	O
while	O
achieving	O
better	O
or	O
comparable	O
accuracy	B-Metric
on	O
Pascal	B-Material
VOC	I-Material
2007	I-Material
.	O
	
In	O
ImageNet	B-Task
Large	I-Task
Scale	I-Task
Visual	I-Task
Recognition	I-Task
Challenge	I-Task
(	O
ILSVRC	B-Task
)	I-Task
2014	I-Task
,	O
our	O
methods	O
rank	O
#	O
2	O
in	O
object	B-Task
detection	I-Task
and	O
#	O
3	O
in	O
image	B-Task
classification	I-Task
among	O
all	O
38	O
teams	O
.	O
	
This	O
manuscript	O
also	O
introduces	O
the	O
improvement	O
made	O
for	O
this	O
competition	O
.	O
	
onvolutional	B-Method
Neural	I-Method
Networks	I-Method
,	O
Spatial	B-Method
Pyramid	I-Method
Pooling	I-Method
,	O
Image	B-Task
Classification	I-Task
,	O
Object	B-Task
Detection	I-Task
	
section	O
:	O
Introduction	O
	
We	O
are	O
witnessing	O
a	O
rapid	O
,	O
revolutionary	O
change	O
in	O
our	O
vision	B-Task
community	I-Task
,	O
mainly	O
caused	O
by	O
deep	B-Method
convolutional	I-Method
neural	I-Method
networks	I-Method
(	O
CNNs	B-Method
)	O
and	O
the	O
availability	O
of	O
large	O
scale	O
training	O
data	O
.	O
	
Deep	B-Method
-	I-Method
networks	I-Method
-	I-Method
based	I-Method
approaches	I-Method
have	O
recently	O
been	O
substantially	O
improving	O
upon	O
the	O
state	O
of	O
the	O
art	O
in	O
image	B-Task
classification	I-Task
,	O
object	B-Task
detection	I-Task
,	O
many	O
other	O
recognition	B-Task
tasks	I-Task
,	O
and	O
even	O
non	B-Task
-	I-Task
recognition	I-Task
tasks	I-Task
.	O
	
However	O
,	O
there	O
is	O
a	O
technical	O
issue	O
in	O
the	O
training	B-Task
and	I-Task
testing	I-Task
of	O
the	O
CNNs	B-Method
:	O
the	O
prevalent	B-Method
CNNs	I-Method
require	O
a	O
fixed	O
input	O
image	O
size	O
(	O
,	O
224	O
224	O
)	O
,	O
which	O
limits	O
both	O
the	O
aspect	O
ratio	O
and	O
the	O
scale	O
of	O
the	O
input	O
image	O
.	O
	
When	O
applied	O
to	O
images	O
of	O
arbitrary	O
sizes	O
,	O
current	O
methods	O
mostly	O
fit	O
the	O
input	O
image	O
to	O
the	O
fixed	O
size	O
,	O
either	O
via	O
cropping	B-Method
or	O
via	O
warping	O
,	O
as	O
shown	O
in	O
Figure	O
[	O
reference	O
]	O
(	O
top	O
)	O
.	O
	
But	O
the	O
cropped	O
region	O
may	O
not	O
contain	O
the	O
entire	O
object	O
,	O
while	O
the	O
warped	O
content	O
may	O
result	O
in	O
unwanted	O
geometric	O
distortion	O
.	O
	
Recognition	B-Metric
accuracy	I-Metric
can	O
be	O
compromised	O
due	O
to	O
the	O
content	O
loss	O
or	O
distortion	O
.	O
	
Besides	O
,	O
a	O
pre	O
-	O
defined	O
scale	O
may	O
not	O
be	O
suitable	O
when	O
object	O
scales	O
vary	O
.	O
	
Fixing	O
input	O
sizes	O
overlooks	O
the	O
issues	O
involving	O
scales	O
.	O
	
So	O
why	O
do	O
CNNs	B-Method
require	O
a	O
fixed	O
input	O
size	O
?	O
	
A	O
CNN	B-Method
mainly	O
consists	O
of	O
two	O
parts	O
:	O
convolutional	B-Method
layers	I-Method
,	O
and	O
fully	B-Method
-	I-Method
connected	I-Method
layers	I-Method
that	O
follow	O
.	O
	
The	O
convolutional	B-Method
layers	I-Method
operate	O
in	O
a	O
sliding	B-Method
-	I-Method
window	I-Method
manner	I-Method
and	O
output	O
feature	O
maps	O
which	O
represent	O
the	O
spatial	O
arrangement	O
of	O
the	O
activations	O
(	O
Figure	O
[	O
reference	O
]	O
)	O
.	O
	
In	O
fact	O
,	O
convolutional	B-Method
layers	I-Method
do	O
not	O
require	O
a	O
fixed	O
image	O
size	O
and	O
can	O
generate	O
feature	O
maps	O
of	O
any	O
sizes	O
.	O
	
On	O
the	O
other	O
hand	O
,	O
the	O
fully	O
-	O
connected	O
layers	O
need	O
to	O
have	O
fixed	O
-	O
size	O
/	O
length	O
input	O
by	O
their	O
definition	O
.	O
	
Hence	O
,	O
the	O
fixed	O
-	O
size	O
constraint	O
comes	O
only	O
from	O
the	O
fully	O
-	O
connected	O
layers	O
,	O
which	O
exist	O
at	O
a	O
deeper	O
stage	O
of	O
the	O
network	O
.	O
	
In	O
this	O
paper	O
,	O
we	O
introduce	O
a	O
spatial	B-Method
pyramid	I-Method
pooling	I-Method
(	O
SPP	B-Method
)	O
layer	O
to	O
remove	O
the	O
fixed	O
-	O
size	O
constraint	O
of	O
the	O
network	O
.	O
	
Specifically	O
,	O
we	O
add	O
an	O
SPP	B-Method
layer	O
on	O
top	O
of	O
the	O
last	O
convolutional	B-Method
layer	I-Method
.	O
	
The	O
SPP	B-Method
layer	O
pools	O
the	O
features	O
and	O
generates	O
fixed	O
-	O
length	O
outputs	O
,	O
which	O
are	O
then	O
fed	O
into	O
the	O
fully	B-Method
-	I-Method
connected	I-Method
layers	I-Method
(	O
or	O
other	O
classifiers	B-Method
)	O
.	O
	
In	O
other	O
words	O
,	O
we	O
perform	O
some	O
information	B-Method
“	I-Method
aggregation	I-Method
”	O
at	O
a	O
deeper	O
stage	O
of	O
the	O
network	O
hierarchy	O
(	O
between	O
convolutional	O
layers	O
and	O
fully	O
-	O
connected	O
layers	O
)	O
to	O
avoid	O
the	O
need	O
for	O
cropping	O
or	O
warping	O
at	O
the	O
beginning	O
.	O
	
Figure	O
[	O
reference	O
]	O
(	O
bottom	O
)	O
shows	O
the	O
change	O
of	O
the	O
network	B-Method
architecture	I-Method
by	O
introducing	O
the	O
SPP	B-Method
layer	O
.	O
	
We	O
call	O
the	O
new	O
network	O
structure	O
SPP	B-Method
-	O
net	O
.	O
	
Spatial	B-Method
pyramid	I-Method
pooling	I-Method
(	O
popularly	O
known	O
as	O
spatial	B-Method
pyramid	I-Method
matching	I-Method
or	O
SPM	B-Method
)	O
,	O
as	O
an	O
extension	O
of	O
the	O
Bag	B-Method
-	I-Method
of	I-Method
-	I-Method
Words	I-Method
(	I-Method
BoW	I-Method
)	I-Method
model	I-Method
,	O
is	O
one	O
of	O
the	O
most	O
successful	O
methods	O
in	O
computer	B-Task
vision	I-Task
.	O
	
It	O
partitions	O
the	O
image	O
into	O
divisions	O
from	O
finer	O
to	O
coarser	O
levels	O
,	O
and	O
aggregates	O
local	O
features	O
in	O
them	O
.	O
	
SPP	B-Method
has	O
long	O
been	O
a	O
key	O
component	O
in	O
the	O
leading	B-Task
and	I-Task
competition	I-Task
-	I-Task
winning	I-Task
systems	I-Task
for	O
classification	B-Task
(	I-Task
,	I-Task
)	I-Task
and	I-Task
detection	I-Task
(	O
,	O
)	O
before	O
the	O
recent	O
prevalence	O
of	O
CNNs	B-Method
.	O
	
Nevertheless	O
,	O
SPP	B-Method
has	O
not	O
been	O
considered	O
in	O
the	O
context	O
of	O
CNNs	B-Method
.	O
	
We	O
note	O
that	O
SPP	B-Method
has	O
several	O
remarkable	O
properties	O
for	O
deep	B-Method
CNNs	I-Method
:	O
1	O
)	O
SPP	B-Method
is	O
able	O
to	O
generate	O
a	O
fixed	O
-	O
length	O
output	O
regardless	O
of	O
the	O
input	O
size	O
,	O
while	O
the	O
sliding	B-Method
window	I-Method
pooling	I-Method
used	O
in	O
the	O
previous	O
deep	B-Method
networks	I-Method
	
can	O
not	O
;	O
2	O
)	O
SPP	B-Method
uses	O
multi	O
-	O
level	O
spatial	O
bins	O
,	O
while	O
the	O
sliding	B-Method
window	I-Method
pooling	I-Method
uses	O
only	O
a	O
single	O
window	O
size	O
.	O
	
Multi	B-Method
-	I-Method
level	I-Method
pooling	I-Method
has	O
been	O
shown	O
to	O
be	O
robust	O
to	O
object	O
deformations	O
;	O
3	O
)	O
SPP	B-Method
can	O
pool	O
features	O
extracted	O
at	O
variable	O
scales	O
thanks	O
to	O
the	O
flexibility	O
of	O
input	O
scales	O
.	O
	
Through	O
experiments	O
we	O
show	O
that	O
all	O
these	O
factors	O
elevate	O
the	O
recognition	B-Metric
accuracy	I-Metric
of	O
deep	B-Method
networks	I-Method
.	O
	
SPP	B-Method
-	I-Method
net	I-Method
not	O
only	O
makes	O
it	O
possible	O
to	O
generate	O
representations	O
from	O
arbitrarily	O
sized	O
images	O
/	O
windows	O
for	O
testing	O
,	O
but	O
also	O
allows	O
us	O
to	O
feed	O
images	O
with	O
varying	O
sizes	O
or	O
scales	O
during	O
training	O
.	O
	
Training	O
with	O
variable	O
-	O
size	O
images	O
increases	O
scale	O
-	O
invariance	O
and	O
reduces	O
over	B-Task
-	I-Task
fitting	I-Task
.	O
	
We	O
develop	O
a	O
simple	O
multi	B-Method
-	I-Method
size	I-Method
training	I-Method
method	I-Method
.	O
	
For	O
a	O
single	O
network	O
to	O
accept	O
variable	O
input	O
sizes	O
,	O
we	O
approximate	O
it	O
by	O
multiple	O
networks	O
that	O
share	O
all	O
parameters	O
,	O
while	O
each	O
of	O
these	O
networks	O
is	O
trained	O
using	O
a	O
fixed	O
input	O
size	O
.	O
	
In	O
each	O
epoch	O
we	O
train	O
the	O
network	O
with	O
a	O
given	O
input	O
size	O
,	O
and	O
switch	O
to	O
another	O
input	O
size	O
for	O
the	O
next	O
epoch	O
.	O
	
Experiments	O
show	O
that	O
this	O
multi	B-Method
-	I-Method
size	I-Method
training	I-Method
converges	O
just	O
as	O
the	O
traditional	O
single	B-Method
-	I-Method
size	I-Method
training	I-Method
,	O
and	O
leads	O
to	O
better	O
testing	B-Metric
accuracy	I-Metric
.	O
	
The	O
advantages	O
of	O
SPP	B-Method
are	O
orthogonal	O
to	O
the	O
specific	O
CNN	B-Method
designs	I-Method
.	O
	
In	O
a	O
series	O
of	O
controlled	O
experiments	O
on	O
the	O
ImageNet	B-Material
2012	I-Material
dataset	I-Material
,	O
we	O
demonstrate	O
that	O
SPP	B-Method
improves	O
four	O
different	O
CNN	B-Method
architectures	I-Method
in	O
existing	O
publications	O
(	O
or	O
their	O
modifications	O
)	O
,	O
over	O
the	O
no	O
-	O
SPP	B-Method
counterparts	O
.	O
	
These	O
architectures	O
have	O
various	O
filter	O
numbers	O
/	O
sizes	O
,	O
strides	O
,	O
depths	O
,	O
or	O
other	O
designs	O
.	O
	
It	O
is	O
thus	O
reasonable	O
for	O
us	O
to	O
conjecture	O
that	O
SPP	B-Method
should	O
improve	O
more	O
sophisticated	O
(	O
deeper	O
and	O
larger	O
)	O
convolutional	B-Method
architectures	I-Method
.	O
	
SPP	B-Method
-	I-Method
net	I-Method
also	O
shows	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
classification	B-Metric
results	O
on	O
Caltech101	B-Material
and	O
Pascal	B-Material
VOC	I-Material
2007	I-Material
using	O
only	O
a	O
single	O
full	B-Method
-	I-Method
image	I-Method
representation	I-Method
and	O
no	O
fine	B-Method
-	I-Method
tuning	I-Method
.	O
	
SPP	B-Method
-	I-Method
net	I-Method
also	O
shows	O
great	O
strength	O
in	O
object	B-Task
detection	I-Task
.	O
	
In	O
the	O
leading	O
object	B-Task
detection	I-Task
method	O
R	O
-	O
CNN	O
,	O
the	O
features	O
from	O
candidate	O
windows	O
are	O
extracted	O
via	O
deep	B-Method
convolutional	I-Method
networks	I-Method
.	O
	
This	O
method	O
shows	O
remarkable	O
detection	B-Metric
accuracy	I-Metric
on	O
both	O
the	O
VOC	B-Material
and	O
ImageNet	B-Material
datasets	I-Material
.	O
	
But	O
the	O
feature	B-Task
computation	I-Task
in	O
R	B-Method
-	I-Method
CNN	I-Method
is	O
time	O
-	O
consuming	O
,	O
because	O
it	O
repeatedly	O
applies	O
the	O
deep	B-Method
convolutional	I-Method
networks	I-Method
to	O
the	O
raw	O
pixels	O
of	O
thousands	O
of	O
warped	O
regions	O
per	O
image	O
.	O
	
In	O
this	O
paper	O
,	O
we	O
show	O
that	O
we	O
can	O
run	O
the	O
convolutional	B-Method
layers	I-Method
only	O
once	O
on	O
the	O
entire	O
image	O
(	O
regardless	O
of	O
the	O
number	O
of	O
windows	O
)	O
,	O
and	O
then	O
extract	O
features	O
by	O
SPP	B-Method
-	I-Method
net	I-Method
on	O
the	O
feature	O
maps	O
.	O
	
This	O
method	O
yields	O
a	O
speedup	O
of	O
over	O
one	O
hundred	O
times	O
over	O
R	B-Method
-	I-Method
CNN	I-Method
.	O
	
Note	O
that	O
training	O
/	O
running	O
a	O
detector	B-Method
on	O
the	O
feature	O
maps	O
(	O
rather	O
than	O
image	O
regions	O
)	O
is	O
actually	O
a	O
more	O
popular	O
idea	O
.	O
	
But	O
SPP	B-Method
-	I-Method
net	I-Method
inherits	O
the	O
power	O
of	O
the	O
deep	B-Method
CNN	I-Method
feature	I-Method
maps	I-Method
and	O
also	O
the	O
flexibility	O
of	O
SPP	B-Method
on	O
arbitrary	O
window	O
sizes	O
,	O
which	O
leads	O
to	O
outstanding	O
accuracy	B-Metric
and	O
efficiency	O
.	O
	
In	O
our	O
experiment	O
,	O
the	O
SPP	B-Method
-	O
net	O
-	O
based	O
system	O
(	O
built	O
upon	O
the	O
R	B-Method
-	I-Method
CNN	I-Method
pipeline	I-Method
)	O
computes	O
features	O
24	O
-	O
102	O
faster	O
than	O
R	B-Method
-	I-Method
CNN	I-Method
,	O
while	O
has	O
better	O
or	O
comparable	O
accuracy	B-Metric
.	O
	
With	O
the	O
recent	O
fast	O
proposal	B-Method
method	I-Method
of	O
EdgeBoxes	B-Method
,	O
our	O
system	O
takes	O
0.5	O
seconds	O
processing	O
an	O
image	O
(	O
including	O
all	O
steps	O
)	O
.	O
	
This	O
makes	O
our	O
method	O
practical	O
for	O
real	B-Task
-	I-Task
world	I-Task
applications	I-Task
.	O
	
A	O
preliminary	O
version	O
of	O
this	O
manuscript	O
has	O
been	O
published	O
in	O
ECCV	O
2014	O
.	O
	
Based	O
on	O
this	O
work	O
,	O
we	O
attended	O
the	O
competition	O
of	O
ILSVRC	B-Task
2014	I-Task
,	O
and	O
ranked	O
#	O
2	O
in	O
object	B-Task
detection	I-Task
and	O
#	O
3	O
in	O
image	B-Task
classification	I-Task
(	O
both	O
are	O
provided	O
-	O
data	O
-	O
only	O
tracks	O
)	O
among	O
all	O
38	O
teams	O
.	O
	
There	O
are	O
a	O
few	O
modifications	O
made	O
for	O
ILSVRC	B-Task
2014	I-Task
.	O
	
We	O
show	O
that	O
the	O
SPP	B-Method
-	O
nets	O
can	O
boost	O
various	O
networks	O
that	O
are	O
deeper	O
and	O
larger	O
(	O
Sec	O
.	O
	
[	O
reference	O
]	O
-	O
[	O
reference	O
]	O
)	O
over	O
the	O
no	O
-	O
SPP	B-Method
counterparts	O
.	O
	
Further	O
,	O
driven	O
by	O
our	O
detection	B-Method
framework	I-Method
,	O
we	O
find	O
that	O
multi	B-Task
-	I-Task
view	I-Task
testing	I-Task
on	O
feature	O
maps	O
with	O
flexibly	O
located	O
/	O
sized	O
windows	O
(	O
Sec	O
.	O
	
[	O
reference	O
]	O
)	O
can	O
increase	O
the	O
classification	B-Metric
accuracy	I-Metric
.	O
	
This	O
manuscript	O
also	O
provides	O
the	O
details	O
of	O
these	O
modifications	O
.	O
	
We	O
have	O
released	O
the	O
code	O
to	O
facilitate	O
future	O
research	O
(	O
http:	O
//	O
research.microsoft.com	O
/	O
en	O
-	O
us	O
/	O
um	O
/	O
people	O
/	O
kahe	O
/	O
)	O
.	O
	
section	O
:	O
Deep	B-Method
Networks	I-Method
with	O
Spatial	B-Method
Pyramid	I-Method
Pooling	I-Method
	
subsection	O
:	O
Convolutional	B-Method
Layers	I-Method
and	O
Feature	B-Method
Maps	I-Method
	
Consider	O
the	O
popular	O
seven	B-Method
-	I-Method
layer	I-Method
architectures	I-Method
.	O
	
The	O
first	O
five	O
layers	O
are	O
convolutional	B-Method
,	O
some	O
of	O
which	O
are	O
followed	O
by	O
pooling	B-Method
layers	I-Method
.	O
	
These	O
pooling	B-Method
layers	I-Method
can	O
also	O
be	O
considered	O
as	O
“	O
convolutional	O
”	O
,	O
in	O
the	O
sense	O
that	O
they	O
are	O
using	O
sliding	O
windows	O
.	O
	
The	O
last	O
two	O
layers	O
are	O
fully	O
connected	O
,	O
with	O
an	O
N	B-Method
-	I-Method
way	I-Method
softmax	I-Method
as	O
the	O
output	O
,	O
where	O
N	O
is	O
the	O
number	O
of	O
categories	O
.	O
	
The	O
deep	B-Method
network	I-Method
described	O
above	O
needs	O
a	O
fixed	O
image	O
size	O
.	O
	
However	O
,	O
we	O
notice	O
that	O
the	O
requirement	O
of	O
fixed	O
sizes	O
is	O
only	O
due	O
to	O
the	O
fully	B-Method
-	I-Method
connected	I-Method
layers	I-Method
that	O
demand	O
fixed	O
-	O
length	O
vectors	O
as	O
inputs	O
.	O
	
On	O
the	O
other	O
hand	O
,	O
the	O
convolutional	B-Method
layers	I-Method
accept	O
inputs	O
of	O
arbitrary	O
sizes	O
.	O
	
The	O
convolutional	B-Method
layers	I-Method
use	O
sliding	B-Method
filters	I-Method
,	O
and	O
their	O
outputs	O
have	O
roughly	O
the	O
same	O
aspect	O
ratio	O
as	O
the	O
inputs	O
.	O
	
These	O
outputs	O
are	O
known	O
as	O
feature	O
maps	O
-	O
they	O
involve	O
not	O
only	O
the	O
strength	O
of	O
the	O
responses	O
,	O
but	O
also	O
their	O
spatial	O
positions	O
.	O
	
In	O
Figure	O
[	O
reference	O
]	O
,	O
we	O
visualize	O
some	O
feature	O
maps	O
.	O
	
They	O
are	O
generated	O
by	O
some	O
filters	B-Method
of	I-Method
the	I-Method
conv	I-Method
layer	I-Method
.	O
	
Figure	O
[	O
reference	O
]	O
	
(	O
c	O
)	O
shows	O
the	O
strongest	O
activated	O
images	O
of	O
these	O
filters	O
in	O
the	O
ImageNet	B-Material
dataset	I-Material
.	O
	
We	O
see	O
a	O
filter	B-Method
can	O
be	O
activated	O
by	O
some	O
semantic	O
content	O
.	O
	
For	O
example	O
,	O
the	O
55	O
-	O
th	O
filter	O
(	O
Figure	O
[	O
reference	O
]	O
,	O
bottom	O
left	O
)	O
is	O
most	O
activated	O
by	O
a	O
circle	O
shape	O
;	O
the	O
66	O
-	O
th	O
filter	O
(	O
Figure	O
[	O
reference	O
]	O
,	O
top	O
right	O
)	O
is	O
most	O
activated	O
by	O
a	O
-	O
shape	O
;	O
and	O
the	O
118	B-Method
-	I-Method
th	I-Method
filter	I-Method
(	O
Figure	O
[	O
reference	O
]	O
,	O
bottom	O
right	O
)	O
is	O
most	O
activated	O
by	O
a	O
-	O
shape	O
.	O
	
These	O
shapes	O
in	O
the	O
input	O
images	O
(	O
Figure	O
[	O
reference	O
]	O
(	O
a	O
)	O
)	O
activate	O
the	O
feature	O
maps	O
at	O
the	O
corresponding	O
positions	O
(	O
the	O
arrows	O
in	O
Figure	O
[	O
reference	O
]	O
)	O
.	O
	
It	O
is	O
worth	O
noticing	O
that	O
we	O
generate	O
the	O
feature	O
maps	O
in	O
Figure	O
[	O
reference	O
]	O
without	O
fixing	O
the	O
input	O
size	O
.	O
	
These	O
feature	O
maps	O
generated	O
by	O
deep	B-Method
convolutional	I-Method
layers	I-Method
are	O
analogous	O
to	O
the	O
feature	O
maps	O
in	O
traditional	O
methods	O
.	O
	
In	O
those	O
methods	O
,	O
SIFT	O
vectors	O
or	O
image	O
patches	O
are	O
densely	O
extracted	O
and	O
then	O
encoded	O
,	O
,	O
by	O
vector	B-Method
quantization	I-Method
,	O
sparse	B-Method
coding	I-Method
,	O
or	O
Fisher	B-Method
kernels	I-Method
.	O
	
These	O
encoded	O
features	O
consist	O
of	O
the	O
feature	O
maps	O
,	O
and	O
are	O
then	O
pooled	O
by	O
Bag	B-Method
-	I-Method
of	I-Method
-	I-Method
Words	I-Method
(	I-Method
BoW	I-Method
)	I-Method
or	O
spatial	B-Method
pyramids	I-Method
.	O
	
Analogously	O
,	O
the	O
deep	O
convolutional	O
features	O
can	O
be	O
pooled	O
in	O
a	O
similar	O
way	O
.	O
	
subsection	O
:	O
The	O
Spatial	B-Method
Pyramid	I-Method
Pooling	I-Method
Layer	O
	
The	O
convolutional	B-Method
layers	I-Method
accept	O
arbitrary	O
input	O
sizes	O
,	O
but	O
they	O
produce	O
outputs	O
of	O
variable	O
sizes	O
.	O
	
The	O
classifiers	B-Method
(	O
SVM	B-Method
/	I-Method
softmax	I-Method
)	O
or	O
fully	B-Method
-	I-Method
connected	I-Method
layers	I-Method
require	O
fixed	O
-	O
length	O
vectors	O
.	O
	
Such	O
vectors	O
can	O
be	O
generated	O
by	O
the	O
Bag	B-Method
-	I-Method
of	I-Method
-	I-Method
Words	I-Method
(	I-Method
BoW	I-Method
)	I-Method
approach	I-Method
that	O
pools	O
the	O
features	O
together	O
.	O
	
Spatial	B-Method
pyramid	I-Method
pooling	I-Method
improves	O
BoW	B-Method
in	O
that	O
it	O
can	O
maintain	O
spatial	O
information	O
by	O
pooling	O
in	O
local	O
spatial	O
bins	O
.	O
	
These	O
spatial	O
bins	O
have	O
sizes	O
proportional	O
to	O
the	O
image	O
size	O
,	O
so	O
the	O
number	O
of	O
bins	O
is	O
fixed	O
regardless	O
of	O
the	O
image	O
size	O
.	O
	
This	O
is	O
in	O
contrast	O
to	O
the	O
sliding	B-Method
window	I-Method
pooling	I-Method
of	O
the	O
previous	O
deep	B-Method
networks	I-Method
,	O
where	O
the	O
number	O
of	O
sliding	O
windows	O
depends	O
on	O
the	O
input	O
size	O
.	O
	
To	O
adopt	O
the	O
deep	B-Method
network	I-Method
for	O
images	O
of	O
arbitrary	O
sizes	O
,	O
we	O
replace	O
the	O
last	O
pooling	B-Method
layer	I-Method
(	O
,	O
pool	O
,	O
after	O
the	O
last	O
convolutional	B-Method
layer	I-Method
)	O
with	O
a	O
spatial	B-Method
pyramid	I-Method
pooling	I-Method
layer	O
.	O
	
Figure	O
[	O
reference	O
]	O
illustrates	O
our	O
method	O
.	O
	
In	O
each	O
spatial	O
bin	O
,	O
we	O
pool	O
the	O
responses	O
of	O
each	O
filter	O
(	O
throughout	O
this	O
paper	O
we	O
use	O
max	B-Method
pooling	I-Method
)	O
.	O
	
The	O
outputs	O
of	O
the	O
spatial	B-Method
pyramid	I-Method
pooling	I-Method
are	O
-	O
dimensional	O
vectors	O
with	O
the	O
number	O
of	O
bins	O
denoted	O
as	O
(	O
is	O
the	O
number	O
of	O
filters	O
in	O
the	O
last	O
convolutional	B-Method
layer	I-Method
)	O
.	O
	
The	O
fixed	O
-	O
dimensional	O
vectors	O
are	O
the	O
input	O
to	O
the	O
fully	B-Method
-	I-Method
connected	I-Method
layer	I-Method
.	O
	
With	O
spatial	B-Method
pyramid	I-Method
pooling	I-Method
,	O
the	O
input	O
image	O
can	O
be	O
of	O
any	O
sizes	O
.	O
	
This	O
not	O
only	O
allows	O
arbitrary	O
aspect	O
ratios	O
,	O
but	O
also	O
allows	O
arbitrary	O
scales	O
.	O
	
We	O
can	O
resize	O
the	O
input	O
image	O
to	O
any	O
scale	O
(	O
,	O
=	O
180	O
,	O
224	O
,	O
…	O
)	O
and	O
apply	O
the	O
same	O
deep	B-Method
network	I-Method
.	O
	
When	O
the	O
input	O
image	O
is	O
at	O
different	O
scales	O
,	O
the	O
network	O
(	O
with	O
the	O
same	O
filter	O
sizes	O
)	O
will	O
extract	O
features	O
at	O
different	O
scales	O
.	O
	
The	O
scales	O
play	O
important	O
roles	O
in	O
traditional	O
methods	O
,	O
,	O
the	O
SIFT	O
vectors	O
are	O
often	O
extracted	O
at	O
multiple	O
scales	O
(	O
determined	O
by	O
the	O
sizes	O
of	O
the	O
patches	O
and	O
Gaussian	B-Method
filters	I-Method
)	O
.	O
	
We	O
will	O
show	O
that	O
the	O
scales	O
are	O
also	O
important	O
for	O
the	O
accuracy	B-Metric
of	O
deep	B-Task
networks	I-Task
.	O
	
Interestingly	O
,	O
the	O
coarsest	O
pyramid	O
level	O
has	O
a	O
single	O
bin	O
that	O
covers	O
the	O
entire	O
image	O
.	O
	
This	O
is	O
in	O
fact	O
a	O
“	O
global	O
pooling	O
”	O
operation	O
,	O
which	O
is	O
also	O
investigated	O
in	O
several	O
concurrent	O
works	O
.	O
	
In	O
a	O
global	B-Method
average	I-Method
pooling	I-Method
is	O
used	O
to	O
reduce	O
the	O
model	O
size	O
and	O
also	O
reduce	O
overfitting	O
;	O
in	O
,	O
a	O
global	B-Method
average	I-Method
pooling	I-Method
is	O
used	O
on	O
the	O
testing	O
stage	O
after	O
all	O
fc	B-Method
layers	I-Method
to	O
improve	O
accuracy	B-Metric
;	O
in	O
,	O
a	O
global	B-Method
max	I-Method
pooling	I-Method
is	O
used	O
for	O
weakly	B-Task
supervised	I-Task
object	I-Task
recognition	I-Task
.	O
	
The	O
global	B-Method
pooling	I-Method
operation	I-Method
corresponds	O
to	O
the	O
traditional	O
Bag	B-Method
-	I-Method
of	I-Method
-	I-Method
Words	I-Method
method	I-Method
.	O
	
subsection	O
:	O
Training	O
the	O
Network	O
	
Theoretically	O
,	O
the	O
above	O
network	B-Method
structure	I-Method
can	O
be	O
trained	O
with	O
standard	O
back	B-Method
-	I-Method
propagation	I-Method
,	O
regardless	O
of	O
the	O
input	O
image	O
size	O
.	O
	
But	O
in	O
practice	O
the	O
GPU	B-Method
implementations	I-Method
(	O
such	O
as	O
cuda	B-Method
-	I-Method
convnet	I-Method
and	I-Method
Caffe	I-Method
)	O
are	O
preferably	O
run	O
on	O
fixed	O
input	O
images	O
.	O
	
Next	O
we	O
describe	O
our	O
training	B-Method
solution	I-Method
that	O
takes	O
advantage	O
of	O
these	O
GPU	B-Method
implementations	I-Method
while	O
still	O
preserving	O
the	O
spatial	B-Method
pyramid	I-Method
pooling	I-Method
behaviors	O
.	O
	
subsubsection	B-Method
:	O
Single	B-Method
-	I-Method
size	I-Method
training	I-Method
	
As	O
in	O
previous	O
works	O
,	O
we	O
first	O
consider	O
a	O
network	O
taking	O
a	O
fixed	O
-	O
size	O
input	O
(	O
224	O
224	O
)	O
cropped	O
from	O
images	O
.	O
	
The	O
cropping	B-Task
is	O
for	O
the	O
purpose	O
of	O
data	B-Task
augmentation	I-Task
.	O
	
For	O
an	O
image	O
with	O
a	O
given	O
size	O
,	O
we	O
can	O
pre	O
-	O
compute	O
the	O
bin	O
sizes	O
needed	O
for	O
spatial	B-Method
pyramid	I-Method
pooling	I-Method
.	O
	
Consider	O
the	O
feature	O
maps	O
after	O
conv	B-Method
that	O
have	O
a	O
size	O
of	O
(	O
,	O
13	O
13	O
)	O
.	O
	
With	O
a	O
pyramid	O
level	O
of	O
bins	O
,	O
we	O
implement	O
this	O
pooling	B-Method
level	I-Method
as	O
a	O
sliding	B-Method
window	I-Method
pooling	I-Method
,	O
where	O
the	O
window	O
size	O
and	O
stride	O
with	O
and	O
denoting	O
ceiling	O
and	O
floor	O
operations	O
.	O
	
With	O
an	O
-	B-Method
level	I-Method
pyramid	I-Method
,	O
we	O
implement	O
such	O
layers	O
.	O
	
The	O
next	O
fully	B-Method
-	I-Method
connected	I-Method
layer	I-Method
(	O
fc	B-Method
)	O
will	O
concatenate	O
the	O
outputs	O
.	O
	
Figure	O
[	O
reference	O
]	O
shows	O
an	O
example	O
configuration	O
of	O
3	O
-	O
level	O
pyramid	O
pooling	O
(	O
3	O
3	O
,	O
2	O
2	O
,	O
1	O
1	O
)	O
in	O
the	O
cuda	B-Method
-	I-Method
convnet	I-Method
style	I-Method
.	O
	
The	O
main	O
purpose	O
of	O
our	O
single	B-Method
-	I-Method
size	I-Method
training	I-Method
is	O
to	O
enable	O
the	O
multi	O
-	O
level	O
pooling	O
behavior	O
.	O
	
Experiments	O
show	O
that	O
this	O
is	O
one	O
reason	O
for	O
the	O
gain	O
of	O
accuracy	B-Metric
.	O
	
subsubsection	O
:	O
Multi	B-Task
-	I-Task
size	I-Task
training	I-Task
	
Our	O
network	O
with	O
SPP	B-Method
is	O
expected	O
to	O
be	O
applied	O
on	O
images	O
of	O
any	O
sizes	O
.	O
	
To	O
address	O
the	O
issue	O
of	O
varying	O
image	O
sizes	O
in	O
training	B-Task
,	O
we	O
consider	O
a	O
set	O
of	O
pre	O
-	O
defined	O
sizes	O
.	O
	
We	O
consider	O
two	O
sizes	O
:	O
180	O
180	O
in	O
addition	O
to	O
224	O
224	O
.	O
	
Rather	O
than	O
crop	O
a	O
smaller	O
180	O
180	O
region	O
,	O
we	O
resize	O
the	O
aforementioned	O
224	O
224	O
region	O
to	O
180	O
180	O
.	O
	
So	O
the	O
regions	O
at	O
both	O
scales	O
differ	O
only	O
in	O
resolution	O
but	O
not	O
in	O
content	O
/	O
layout	O
.	O
	
For	O
the	O
network	O
to	O
accept	O
180	O
180	O
inputs	O
,	O
we	O
implement	O
another	O
fixed	O
-	O
size	O
-	O
input	O
(	O
180	O
180	O
)	O
network	O
.	O
	
The	O
feature	B-Metric
map	I-Metric
size	I-Metric
after	O
conv	B-Method
is	O
10	O
in	O
this	O
case	O
.	O
	
Then	O
we	O
still	O
use	O
and	O
to	O
implement	O
each	O
pyramid	O
pooling	O
level	O
.	O
	
The	O
output	O
of	O
the	O
spatial	B-Method
pyramid	I-Method
pooling	I-Method
layer	O
of	O
this	O
180	O
-	O
network	O
has	O
the	O
same	O
fixed	O
length	O
as	O
the	O
224	O
-	O
network	O
.	O
	
As	O
such	O
,	O
this	O
180	O
-	O
network	O
has	O
exactly	O
the	O
same	O
parameters	O
as	O
the	O
224	O
-	O
network	O
in	O
each	O
layer	O
.	O
	
In	O
other	O
words	O
,	O
during	O
training	B-Task
we	O
implement	O
the	O
varying	O
-	O
input	O
-	O
size	O
SPP	B-Method
-	O
net	O
by	O
two	O
fixed	B-Method
-	I-Method
size	I-Method
networks	I-Method
that	O
share	O
parameters	O
.	O
	
To	O
reduce	O
the	O
overhead	O
to	O
switch	O
from	O
one	O
network	O
(	O
,	O
224	O
)	O
to	O
the	O
other	O
(	O
,	O
180	O
)	O
,	O
we	O
train	O
each	O
full	O
epoch	O
on	O
one	O
network	O
,	O
and	O
then	O
switch	O
to	O
the	O
other	O
one	O
(	O
keeping	O
all	O
weights	O
)	O
for	O
the	O
next	O
full	O
epoch	O
.	O
	
This	O
is	O
iterated	O
.	O
	
In	O
experiments	O
,	O
we	O
find	O
the	O
convergence	B-Metric
rate	I-Metric
of	O
this	O
multi	B-Method
-	I-Method
size	I-Method
training	I-Method
to	O
be	O
similar	O
to	O
the	O
above	O
single	B-Method
-	I-Method
size	I-Method
training	I-Method
.	O
	
The	O
main	O
purpose	O
of	O
our	O
multi	B-Method
-	I-Method
size	I-Method
training	I-Method
is	O
to	O
simulate	O
the	O
varying	O
input	O
sizes	O
while	O
still	O
leveraging	O
the	O
existing	O
well	O
-	O
optimized	O
fixed	B-Method
-	I-Method
size	I-Method
implementations	I-Method
.	O
	
Besides	O
the	O
above	O
two	O
-	O
scale	B-Method
implementation	I-Method
,	O
we	O
have	O
also	O
tested	O
a	O
variant	O
using	O
as	O
input	O
where	O
is	O
randomly	O
and	O
uniformly	O
sampled	O
from	O
at	O
each	O
epoch	O
.	O
	
We	O
report	O
the	O
results	O
of	O
both	O
variants	O
in	O
the	O
experiment	O
section	O
.	O
	
Note	O
that	O
the	O
above	O
single	O
/	O
multi	B-Method
-	I-Method
size	I-Method
solutions	I-Method
are	O
for	O
training	B-Task
only	O
.	O
	
At	O
the	O
testing	O
stage	O
,	O
it	O
is	O
straightforward	O
to	O
apply	O
SPP	B-Method
-	I-Method
net	I-Method
on	O
images	O
of	O
any	O
sizes	O
.	O
	
section	O
:	O
SPP	B-Method
-	I-Method
net	I-Method
for	O
Image	B-Task
Classification	I-Task
	
subsection	O
:	O
Experiments	O
on	O
ImageNet	B-Task
2012	I-Task
Classification	I-Task
	
We	O
train	O
the	O
networks	O
on	O
the	O
1000	O
-	O
category	O
training	O
set	O
of	O
ImageNet	B-Material
2012	I-Material
.	O
	
Our	O
training	B-Method
algorithm	I-Method
follows	O
the	O
practices	O
of	O
previous	O
work	O
.	O
	
The	O
images	O
are	O
resized	O
so	O
that	O
the	O
smaller	O
dimension	O
is	O
256	O
,	O
and	O
a	O
224	O
224	O
crop	O
is	O
picked	O
from	O
the	O
center	O
or	O
the	O
four	O
corners	O
from	O
the	O
entire	O
image	O
.	O
	
The	O
data	O
are	O
augmented	O
by	O
horizontal	O
flipping	O
and	O
color	O
altering	O
.	O
	
Dropout	B-Method
is	O
used	O
on	O
the	O
two	O
fully	B-Method
-	I-Method
connected	I-Method
layers	I-Method
.	O
	
The	O
learning	B-Metric
rate	I-Metric
starts	O
from	O
0.01	O
,	O
and	O
is	O
divided	O
by	O
10	O
(	O
twice	O
)	O
when	O
the	O
error	O
plateaus	O
.	O
	
Our	O
implementation	O
is	O
based	O
on	O
the	O
publicly	O
available	O
code	O
of	O
cuda	B-Method
-	I-Method
convnet	I-Method
and	O
Caffe	B-Method
.	O
	
All	O
networks	O
in	O
this	O
paper	O
can	O
be	O
trained	O
on	O
a	O
single	O
GeForce	B-Method
GTX	I-Method
Titan	I-Method
GPU	I-Method
(	O
6	O
GB	O
memory	O
)	O
within	O
two	O
to	O
four	O
weeks	O
.	O
	
subsubsection	O
:	O
Baseline	B-Method
Network	I-Method
Architectures	I-Method
	
The	O
advantages	O
of	O
SPP	B-Method
are	O
independent	O
of	O
the	O
convolutional	B-Method
network	I-Method
architectures	I-Method
used	O
.	O
	
We	O
investigate	O
four	O
different	O
network	B-Method
architectures	I-Method
in	O
existing	O
publications	O
(	O
or	O
their	O
modifications	O
)	O
,	O
and	O
we	O
show	O
SPP	B-Method
improves	O
the	O
accuracy	B-Metric
of	O
all	O
these	O
architectures	O
.	O
	
These	O
baseline	O
architectures	O
are	O
in	O
Table	O
[	O
reference	O
]	O
and	O
briefly	O
introduced	O
below	O
:	O
	
ZF	B-Method
-	I-Method
5	I-Method
:	O
this	O
architecture	O
is	O
based	O
on	O
Zeiler	O
and	O
Fergus	O
’s	O
(	O
ZF	O
)	O
	
“	O
	
fast	O
”	O
(	O
smaller	O
)	O
model	O
.	O
	
The	O
number	O
indicates	O
five	O
convolutional	B-Method
layers	I-Method
.	O
	
Convnet*	B-Method
-	I-Method
5	I-Method
	
:	O
this	O
is	O
a	O
modification	O
on	O
Krizhevsky	B-Method
’s	I-Method
network	I-Method
.	O
	
We	O
put	O
the	O
two	O
pooling	B-Method
layers	I-Method
after	O
conv	B-Method
and	O
conv	B-Method
(	O
instead	O
of	O
after	O
conv	B-Method
and	O
conv	B-Method
)	O
.	O
	
As	O
a	O
result	O
,	O
the	O
feature	O
maps	O
after	O
each	O
layer	O
have	O
the	O
same	O
size	O
as	O
ZF	O
-	O
5	O
.	O
	
Overfeat	O
-	O
5	O
/	O
7	O
	
:	O
this	O
architecture	O
is	O
based	O
on	O
the	O
Overfeat	O
paper	O
,	O
with	O
some	O
modifications	O
as	O
in	O
.	O
	
In	O
contrast	O
to	O
ZF	B-Method
-	I-Method
5	I-Method
/	I-Method
Convnet*	I-Method
-	I-Method
5	I-Method
,	O
this	O
architecture	O
produces	O
a	O
larger	O
feature	O
map	O
(	O
instead	O
of	O
)	O
before	O
the	O
last	O
pooling	B-Method
layer	I-Method
.	O
	
A	O
larger	O
filter	O
number	O
(	O
512	O
)	O
is	O
used	O
in	O
conv	O
and	O
the	O
following	O
convolutional	B-Method
layers	I-Method
.	O
	
We	O
also	O
investigate	O
a	O
deeper	B-Method
architecture	I-Method
with	O
7	O
convolutional	B-Method
layers	I-Method
,	O
where	O
conv	O
to	O
conv	O
have	O
the	O
same	O
structures	O
.	O
	
In	O
the	O
baseline	O
models	O
,	O
the	O
pooling	B-Method
layer	I-Method
after	O
the	O
last	O
convolutional	B-Method
layer	I-Method
generates	O
feature	O
maps	O
,	O
with	O
two	O
4096	B-Method
-	I-Method
d	I-Method
fc	I-Method
layers	I-Method
and	O
a	O
1000	B-Method
-	I-Method
way	I-Method
softmax	I-Method
layer	I-Method
following	O
.	O
	
Our	O
replications	O
of	O
these	O
baseline	O
networks	O
are	O
in	O
Table	O
[	O
reference	O
]	O
	
(	O
a	O
)	O
.	O
	
We	O
train	O
70	O
epochs	O
for	O
ZF	O
-	O
5	O
and	O
90	O
epochs	O
for	O
the	O
others	O
.	O
	
Our	O
replication	O
of	O
ZF	B-Method
-	I-Method
5	I-Method
is	O
better	O
than	O
the	O
one	O
reported	O
in	O
.	O
	
This	O
gain	O
is	O
because	O
the	O
corner	O
crops	O
are	O
from	O
the	O
entire	O
image	O
,	O
as	O
is	O
also	O
reported	O
in	O
.	O
	
subsubsection	O
:	O
Multi	B-Method
-	I-Method
level	I-Method
Pooling	I-Method
Improves	O
Accuracy	B-Metric
	
In	O
Table	O
[	O
reference	O
]	O
	
(	O
b	O
)	O
we	O
show	O
the	O
results	O
using	O
single	B-Method
-	I-Method
size	I-Method
training	I-Method
.	O
	
The	O
training	O
and	O
testing	O
sizes	O
are	O
both	O
224	O
224	O
.	O
	
In	O
these	O
networks	O
,	O
the	O
convolutional	B-Method
layers	I-Method
have	O
the	O
same	O
structures	O
as	O
the	O
corresponding	O
baseline	B-Method
models	I-Method
,	O
whereas	O
the	O
pooling	B-Method
layer	I-Method
after	O
the	O
final	O
convolutional	B-Method
layer	I-Method
is	O
replaced	O
with	O
the	O
SPP	B-Method
layer	O
.	O
	
For	O
the	O
results	O
in	O
Table	O
[	O
reference	O
]	O
,	O
we	O
use	O
a	O
4	O
-	O
level	O
pyramid	O
.	O
	
The	O
pyramid	O
is	O
{	O
6	O
6	O
,	O
3	O
3	O
,	O
2	O
2	O
,	O
1	O
1	O
}	O
(	O
totally	O
50	O
bins	O
)	O
.	O
	
For	O
fair	O
comparison	O
,	O
we	O
still	O
use	O
the	O
standard	O
10	B-Method
-	I-Method
view	I-Method
prediction	I-Method
with	O
each	O
view	O
a	O
224	O
224	O
crop	O
.	O
	
Our	O
results	O
in	O
Table	O
[	O
reference	O
]	O
(	O
b	O
)	O
show	O
considerable	O
improvement	O
over	O
the	O
no	O
-	O
SPP	B-Method
baselines	O
in	O
Table	O
[	O
reference	O
]	O
(	O
a	O
)	O
.	O
	
Interestingly	O
,	O
the	O
largest	O
gain	O
of	O
top	B-Metric
-	I-Metric
1	I-Metric
error	I-Metric
(	O
1.65	O
%	O
)	O
is	O
given	O
by	O
the	O
most	O
accurate	O
architecture	O
.	O
	
Since	O
we	O
are	O
still	O
using	O
the	O
same	O
10	O
cropped	O
views	O
as	O
in	O
(	O
a	O
)	O
,	O
these	O
gains	O
are	O
solely	O
because	O
of	O
multi	B-Method
-	I-Method
level	I-Method
pooling	I-Method
.	O
	
It	O
is	O
worth	O
noticing	O
that	O
the	O
gain	O
of	O
multi	B-Method
-	I-Method
level	I-Method
pooling	I-Method
is	O
not	O
simply	O
due	O
to	O
more	O
parameters	O
;	O
rather	O
,	O
it	O
is	O
because	O
the	O
multi	B-Method
-	I-Method
level	I-Method
pooling	I-Method
is	O
robust	O
to	O
the	O
variance	O
in	O
object	O
deformations	O
and	O
spatial	O
layout	O
.	O
	
To	O
show	O
this	O
,	O
we	O
train	O
another	O
ZF	B-Method
-	I-Method
5	I-Method
network	I-Method
with	O
a	O
different	O
4	O
-	O
level	O
pyramid	O
:	O
{	O
4	O
4	O
,	O
3	O
3	O
,	O
2	O
2	O
,	O
1	O
1	O
}	O
(	O
totally	O
30	O
bins	O
)	O
.	O
	
This	O
network	O
has	O
fewer	O
parameters	O
than	O
its	O
no	O
-	O
SPP	B-Method
counterpart	O
,	O
because	O
its	O
fc	B-Method
layer	I-Method
has	O
30	O
256	O
-	O
d	O
inputs	O
instead	O
of	O
36	O
256	O
-	O
d	O
.	O
	
The	O
top	B-Metric
-	I-Metric
1	I-Metric
/	I-Metric
top	I-Metric
-	I-Metric
5	I-Metric
errors	I-Metric
of	O
this	O
network	O
are	O
35.06	O
/	O
14.04	O
.	O
	
This	O
result	O
is	O
similar	O
to	O
the	O
50	O
-	O
bin	O
pyramid	O
above	O
(	O
34.98	O
/	O
14.14	O
)	O
,	O
but	O
considerably	O
better	O
than	O
the	O
no	O
-	O
SPP	B-Method
counterpart	O
(	O
35.99	O
/	O
14.76	O
)	O
.	O
	
subsubsection	O
:	O
Multi	B-Method
-	I-Method
size	I-Method
Training	I-Method
Improves	O
Accuracy	B-Metric
	
Table	O
[	O
reference	O
]	O
	
(	O
c	O
)	O
shows	O
our	O
results	O
using	O
multi	B-Method
-	I-Method
size	I-Method
training	I-Method
.	O
	
The	O
training	O
sizes	O
are	O
224	O
and	O
180	O
,	O
while	O
the	O
testing	O
size	O
is	O
still	O
224	O
.	O
	
We	O
still	O
use	O
the	O
standard	O
10	B-Method
-	I-Method
view	I-Method
prediction	I-Method
.	O
	
The	O
top	B-Metric
-	I-Metric
1	I-Metric
/	I-Metric
top	I-Metric
-	I-Metric
5	I-Metric
errors	I-Metric
of	O
all	O
architectures	O
further	O
drop	O
.	O
	
The	O
top	B-Metric
-	I-Metric
1	I-Metric
error	I-Metric
of	O
SPP	B-Method
-	I-Method
net	I-Method
(	O
Overfeat	B-Method
-	I-Method
7	I-Method
)	O
drops	O
to	O
29.68	O
%	O
,	O
which	O
is	O
2.33	O
%	O
better	O
than	O
its	O
no	O
-	O
SPP	B-Method
counterpart	O
and	O
0.68	O
%	O
better	O
than	O
its	O
single	B-Method
-	I-Method
size	I-Method
trained	I-Method
counterpart	I-Method
.	O
	
Besides	O
using	O
the	O
two	O
discrete	O
sizes	O
of	O
180	O
and	O
224	O
,	O
we	O
have	O
also	O
evaluated	O
using	O
a	O
random	O
size	O
uniformly	O
sampled	O
from	O
.	O
	
The	O
top	B-Metric
-	I-Metric
1	I-Metric
/	I-Metric
5	I-Metric
error	I-Metric
of	O
SPP	B-Method
-	I-Method
net	I-Method
(	O
Overfeat	B-Method
-	I-Method
7	I-Method
)	O
is	O
30.06%	O
/	O
10.96	O
%	O
.	O
	
The	O
top	B-Metric
-	I-Metric
1	I-Metric
error	I-Metric
is	O
slightly	O
worse	O
than	O
the	O
two	O
-	O
size	O
version	O
,	O
possibly	O
because	O
the	O
size	O
of	O
224	O
(	O
which	O
is	O
used	O
for	O
testing	O
)	O
is	O
visited	O
less	O
.	O
	
But	O
the	O
results	O
are	O
still	O
better	O
the	O
single	O
-	O
size	O
version	O
.	O
	
There	O
are	O
previous	O
CNN	B-Method
solutions	I-Method
that	O
deal	O
with	O
various	O
scales	O
/	O
sizes	O
,	O
but	O
they	O
are	O
mostly	O
based	O
on	O
testing	O
.	O
	
In	O
Overfeat	O
and	O
Howard	B-Method
’s	I-Method
method	I-Method
,	O
the	O
single	B-Method
network	I-Method
is	O
applied	O
at	O
multiple	O
scales	O
in	O
the	O
testing	O
stage	O
,	O
and	O
the	O
scores	O
are	O
averaged	O
.	O
	
Howard	O
further	O
trains	O
two	O
different	O
networks	O
on	O
low	O
/	O
high	O
-	O
resolution	O
image	O
regions	O
and	O
averages	O
the	O
scores	O
.	O
	
To	O
our	O
knowledge	O
,	O
our	O
method	O
is	O
the	O
first	O
one	O
that	O
trains	O
a	O
single	O
network	O
with	O
input	O
images	O
of	O
multiple	O
sizes	O
.	O
	
subsubsection	O
:	O
Full	B-Method
-	I-Method
image	I-Method
Representations	I-Method
Improve	O
Accuracy	B-Task
	
Next	O
we	O
investigate	O
the	O
accuracy	B-Metric
of	O
the	O
full	O
-	O
image	O
views	O
.	O
	
We	O
resize	O
the	O
image	O
so	O
that	O
=	O
256	O
while	O
maintaining	O
its	O
aspect	O
ratio	O
.	O
	
The	O
SPP	B-Method
-	I-Method
net	I-Method
is	O
applied	O
on	O
this	O
full	O
image	O
to	O
compute	O
the	O
scores	O
of	O
the	O
full	O
view	O
.	O
	
For	O
fair	O
comparison	O
,	O
we	O
also	O
evaluate	O
the	O
accuracy	B-Metric
of	O
the	O
single	O
view	O
in	O
the	O
center	O
224	O
224	O
crop	O
(	O
which	O
is	O
used	O
in	O
the	O
above	O
evaluations	O
)	O
.	O
	
The	O
comparisons	O
of	O
single	B-Metric
-	I-Metric
view	I-Metric
testing	I-Metric
accuracy	I-Metric
are	O
in	O
Table	O
[	O
reference	O
]	O
.	O
	
Here	O
we	O
evaluate	O
ZF	O
-	O
5	O
/	O
Overfeat	B-Method
-	I-Method
7	I-Method
.	O
	
The	O
top	B-Metric
-	I-Metric
1	I-Metric
error	I-Metric
rates	I-Metric
are	O
all	O
reduced	O
by	O
the	O
full	B-Method
-	I-Method
view	I-Method
representation	I-Method
.	O
	
This	O
shows	O
the	O
importance	O
of	O
maintaining	O
the	O
complete	O
content	O
.	O
	
Even	O
though	O
our	O
network	O
is	O
trained	O
using	O
square	O
images	O
only	O
,	O
it	O
generalizes	O
well	O
to	O
other	O
aspect	O
ratios	O
.	O
	
Comparing	O
Table	O
[	O
reference	O
]	O
and	O
Table	O
[	O
reference	O
]	O
	
,	O
we	O
find	O
that	O
the	O
combination	O
of	O
multiple	O
views	O
is	O
substantially	O
better	O
than	O
the	O
single	O
full	B-Method
-	I-Method
image	I-Method
view	I-Method
.	O
	
However	O
,	O
the	O
full	B-Method
-	I-Method
image	I-Method
representations	I-Method
are	O
still	O
of	O
good	O
merits	O
.	O
	
First	O
,	O
we	O
empirically	O
find	O
that	O
(	O
discussed	O
in	O
the	O
next	O
subsection	O
)	O
even	O
for	O
the	O
combination	O
of	O
dozens	O
of	O
views	O
,	O
the	O
additional	O
two	O
full	O
-	O
image	O
views	O
(	O
with	O
flipping	O
)	O
can	O
still	O
boost	O
the	O
accuracy	B-Metric
by	O
about	O
0.2	O
%	O
.	O
	
Second	O
,	O
the	O
full	B-Task
-	I-Task
image	I-Task
view	I-Task
is	O
methodologically	O
consistent	O
with	O
the	O
traditional	O
methods	O
where	O
the	O
encoded	O
SIFT	O
vectors	O
of	O
the	O
entire	O
image	O
are	O
pooled	O
together	O
.	O
	
Third	O
,	O
in	O
other	O
applications	O
such	O
as	O
image	B-Task
retrieval	I-Task
,	O
an	O
image	B-Task
representation	I-Task
,	O
rather	O
than	O
a	O
classification	B-Metric
score	I-Metric
,	O
is	O
required	O
for	O
similarity	B-Task
ranking	I-Task
.	O
	
A	O
full	B-Method
-	I-Method
image	I-Method
representation	I-Method
can	O
be	O
preferred	O
.	O
	
subsubsection	O
:	O
Multi	B-Task
-	I-Task
view	I-Task
Testing	I-Task
on	O
Feature	B-Task
Maps	I-Task
	
Inspired	O
by	O
our	O
detection	B-Method
algorithm	I-Method
(	O
described	O
in	O
the	O
next	O
section	O
)	O
,	O
we	O
further	O
propose	O
a	O
multi	B-Method
-	I-Method
view	I-Method
testing	I-Method
method	I-Method
on	O
the	O
feature	O
maps	O
.	O
	
Thanks	O
to	O
the	O
flexibility	O
of	O
SPP	B-Method
,	O
we	O
can	O
easily	O
extract	O
the	O
features	O
from	O
windows	O
(	O
views	O
)	O
of	O
arbitrary	O
sizes	O
from	O
the	O
convolutional	B-Method
feature	I-Method
maps	I-Method
.	O
	
On	O
the	O
testing	O
stage	O
,	O
we	O
resize	O
an	O
image	O
so	O
where	O
represents	O
a	O
predefined	O
scale	O
(	O
like	O
256	O
)	O
.	O
	
Then	O
we	O
compute	O
the	O
convolutional	B-Method
feature	I-Method
maps	I-Method
from	O
the	O
entire	O
image	O
.	O
	
For	O
the	O
usage	O
of	O
flipped	O
views	O
,	O
we	O
also	O
compute	O
the	O
feature	O
maps	O
of	O
the	O
flipped	O
image	O
.	O
	
Given	O
any	O
view	O
(	O
window	O
)	O
in	O
the	O
image	O
,	O
we	O
map	O
this	O
window	O
to	O
the	O
feature	O
maps	O
(	O
the	O
way	O
of	O
mapping	O
is	O
in	O
Appendix	O
)	O
,	O
and	O
then	O
use	O
SPP	B-Method
to	O
pool	O
the	O
features	O
from	O
this	O
window	O
(	O
see	O
Figure	O
[	O
reference	O
]	O
)	O
.	O
	
The	O
pooled	O
features	O
are	O
then	O
fed	O
into	O
the	O
fc	B-Method
layers	I-Method
to	O
compute	O
the	O
softmax	B-Metric
score	I-Metric
of	O
this	O
window	O
.	O
	
These	O
scores	O
are	O
averaged	O
for	O
the	O
final	O
prediction	B-Task
.	O
	
For	O
the	O
standard	O
10	B-Method
-	I-Method
view	I-Method
,	O
we	O
use	O
and	O
the	O
views	O
are	O
224	O
224	O
windows	O
on	O
the	O
corners	O
or	O
center	O
.	O
	
Experiments	O
show	O
that	O
the	O
top	B-Metric
-	I-Metric
5	I-Metric
error	I-Metric
of	O
the	O
10	B-Task
-	I-Task
view	I-Task
prediction	I-Task
on	O
feature	B-Task
maps	I-Task
is	O
within	O
0.1	O
%	O
around	O
the	O
original	O
10	B-Method
-	I-Method
view	I-Method
prediction	I-Method
on	O
image	B-Task
crops	I-Task
.	O
	
We	O
further	O
apply	O
this	O
method	O
to	O
extract	O
multiple	O
views	O
from	O
multiple	O
scales	O
.	O
	
We	O
resize	O
the	O
image	O
to	O
six	O
scales	O
and	O
compute	O
the	O
feature	O
maps	O
on	O
the	O
entire	O
image	O
for	O
each	O
scale	O
.	O
	
We	O
use	O
as	O
the	O
view	O
size	O
for	O
any	O
scale	O
,	O
so	O
these	O
views	O
have	O
different	O
relative	O
sizes	O
on	O
the	O
original	O
image	O
for	O
different	O
scales	O
.	O
	
We	O
use	O
18	O
views	O
for	O
each	O
scale	O
:	O
one	O
at	O
the	O
center	O
,	O
four	O
at	O
the	O
corners	O
,	O
and	O
four	O
on	O
the	O
middle	O
of	O
each	O
side	O
,	O
with	O
/	O
without	O
flipping	O
(	O
when	O
=	O
224	O
there	O
are	O
6	O
different	O
views	O
)	O
.	O
	
The	O
combination	O
of	O
these	O
96	O
views	O
reduces	O
the	O
top	B-Metric
-	I-Metric
5	I-Metric
error	I-Metric
from	O
10.95	O
%	O
to	O
9.36	O
%	O
.	O
	
Combining	O
the	O
two	O
full	O
-	O
image	O
views	O
(	O
with	O
flipping	O
)	O
further	O
reduces	O
the	O
top	B-Metric
-	I-Metric
5	I-Metric
error	I-Metric
to	O
9.14	O
%	O
.	O
	
In	O
the	O
Overfeat	O
paper	O
,	O
the	O
views	O
are	O
also	O
extracted	O
from	O
the	O
convolutional	B-Method
feature	I-Method
maps	I-Method
instead	O
of	O
image	O
crops	O
.	O
	
However	O
,	O
their	O
views	O
can	O
not	O
have	O
arbitrary	O
sizes	O
;	O
rather	O
,	O
the	O
windows	O
are	O
those	O
where	O
the	O
pooled	O
features	O
match	O
the	O
desired	O
dimensionality	O
.	O
	
We	O
empirically	O
find	O
that	O
these	O
restricted	O
windows	O
are	O
less	O
beneficial	O
than	O
our	O
flexibly	O
located	O
/	O
sized	O
windows	O
.	O
	
subsubsection	O
:	O
Summary	O
and	O
Results	O
for	O
ILSVRC	B-Task
2014	I-Task
	
In	O
Table	O
[	O
reference	O
]	O
we	O
compare	O
with	O
previous	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
methods	O
.	O
	
Krizhevsky	B-Method
’s	I-Method
is	O
the	O
winning	O
method	O
in	O
ILSVRC	B-Task
2012	O
;	O
Overfeat	O
,	O
Howard	O
’s	O
,	O
and	O
Zeiler	O
and	O
Fergus	O
’s	O
are	O
the	O
leading	O
methods	O
in	O
ILSVRC	B-Task
2013	I-Task
.	O
	
We	O
only	O
consider	O
single	O
-	O
network	O
performance	O
for	O
manageable	O
comparisons	O
.	O
	
Our	O
best	O
single	O
network	O
achieves	O
9.14	O
%	O
	
top	B-Metric
-	I-Metric
5	I-Metric
error	I-Metric
on	O
the	O
validation	O
set	O
.	O
	
This	O
is	O
exactly	O
the	O
single	O
-	O
model	O
entry	O
we	O
submitted	O
to	O
ILSVRC	B-Task
2014	I-Task
.	O
	
The	O
top	B-Metric
-	I-Metric
5	I-Metric
error	I-Metric
is	O
9.08	O
%	O
on	O
the	O
testing	O
set	O
	
(	O
ILSVRC	B-Task
2014	I-Task
has	O
the	O
same	O
training	O
/	O
validation	O
/	O
testing	O
data	O
as	O
ILSVRC	B-Material
2012	I-Material
)	O
.	O
	
After	O
combining	O
eleven	O
models	O
,	O
our	O
team	O
’s	O
result	O
(	O
8.06	O
%	O
)	O
is	O
ranked	O
#	O
3	O
among	O
all	O
38	O
teams	O
attending	O
ILSVRC	B-Task
2014	I-Task
(	O
Table	O
[	O
reference	O
]	O
)	O
.	O
	
Since	O
the	O
advantages	O
of	O
SPP	B-Method
-	I-Method
net	I-Method
should	O
be	O
in	O
general	O
independent	O
of	O
architectures	O
,	O
we	O
expect	O
that	O
it	O
will	O
further	O
improve	O
the	O
deeper	O
and	O
larger	O
convolutional	B-Method
architectures	I-Method
.	O
	
subsection	O
:	O
Experiments	O
on	O
VOC	B-Material
2007	O
Classification	O
	
Our	O
method	O
can	O
generate	O
a	O
full	B-Task
-	I-Task
view	I-Task
image	I-Task
representation	I-Task
.	O
	
With	O
the	O
above	O
networks	O
pre	O
-	O
trained	O
on	O
ImageNet	B-Material
,	O
we	O
extract	O
these	O
representations	O
from	O
the	O
images	O
in	O
the	O
target	O
datasets	O
and	O
re	O
-	O
train	O
SVM	B-Method
classifiers	I-Method
.	O
	
In	O
the	O
SVM	B-Task
training	I-Task
,	O
we	O
intentionally	O
do	O
not	O
use	O
any	O
data	B-Method
augmentation	I-Method
(	O
flip	O
/	O
multi	O
-	O
view	O
)	O
.	O
	
We	O
l	O
-	O
normalize	O
the	O
features	O
for	O
SVM	B-Task
training	I-Task
.	O
	
The	O
classification	B-Task
task	I-Task
in	O
Pascal	B-Material
VOC	I-Material
2007	I-Material
involves	O
9	O
,	O
963	O
images	O
in	O
20	O
categories	O
.	O
	
5	O
,	O
011	O
images	O
are	O
for	O
training	O
,	O
and	O
the	O
rest	O
are	O
for	O
testing	O
.	O
	
The	O
performance	O
is	O
evaluated	O
by	O
mean	B-Metric
Average	I-Metric
Precision	I-Metric
(	O
mAP	B-Metric
)	O
.	O
	
Table	O
[	O
reference	O
]	O
summarizes	O
the	O
results	O
.	O
	
We	O
start	O
from	O
a	O
baseline	O
in	O
Table	O
[	O
reference	O
]	O
	
(	O
a	O
)	O
.	O
	
The	O
model	O
is	O
ZF	O
-	O
5	O
without	O
SPP	B-Method
.	O
	
To	O
apply	O
this	O
model	O
,	O
we	O
resize	O
the	O
image	O
so	O
that	O
its	O
smaller	O
dimension	O
is	O
224	O
,	O
and	O
crop	O
the	O
center	O
224	O
224	O
region	O
.	O
	
The	O
SVM	B-Method
is	O
trained	O
via	O
the	O
features	O
of	O
a	O
layer	O
.	O
	
On	O
this	O
dataset	O
,	O
the	O
deeper	O
the	O
layer	O
is	O
,	O
the	O
better	O
the	O
result	O
is	O
.	O
	
In	O
Table	O
[	O
reference	O
]	O
	
(	O
b	O
)	O
,	O
we	O
replace	O
the	O
no	O
-	O
SPP	B-Method
net	O
with	O
our	O
SPP	B-Method
-	I-Method
net	I-Method
.	O
	
As	O
a	O
first	O
-	O
step	O
comparison	O
,	O
we	O
still	O
apply	O
the	O
SPP	B-Method
-	I-Method
net	I-Method
on	O
the	O
center	O
224	O
224	O
crop	O
.	O
	
The	O
results	O
of	O
the	O
fc	B-Method
layers	I-Method
improve	O
.	O
	
This	O
gain	O
is	O
mainly	O
due	O
to	O
multi	B-Method
-	I-Method
level	I-Method
pooling	I-Method
.	O
	
Table	O
[	O
reference	O
]	O
	
(	O
c	O
)	O
shows	O
our	O
results	O
on	O
full	O
images	O
,	O
where	O
the	O
images	O
are	O
resized	O
so	O
that	O
the	O
shorter	O
side	O
is	O
224	O
.	O
	
We	O
find	O
that	O
the	O
results	O
are	O
considerably	O
improved	O
(	O
78.39	O
%	O
76.45	O
%	O
)	O
.	O
	
This	O
is	O
due	O
to	O
the	O
full	B-Method
-	I-Method
image	I-Method
representation	I-Method
that	O
maintains	O
the	O
complete	O
content	O
.	O
	
Because	O
the	O
usage	O
of	O
our	O
network	O
does	O
not	O
depend	O
on	O
scale	O
,	O
we	O
resize	O
the	O
images	O
so	O
that	O
the	O
smaller	O
dimension	O
is	O
and	O
use	O
the	O
same	O
network	O
to	O
extract	O
features	O
.	O
	
We	O
find	O
that	O
gives	O
the	O
best	O
results	O
(	O
Table	O
[	O
reference	O
]	O
(	O
d	O
)	O
)	O
based	O
on	O
the	O
validation	O
set	O
.	O
	
This	O
is	O
mainly	O
because	O
the	O
objects	O
occupy	O
smaller	O
regions	O
in	O
VOC	B-Material
2007	O
but	O
larger	O
regions	O
in	O
ImageNet	B-Material
,	O
so	O
the	O
relative	O
object	O
scales	O
are	O
different	O
between	O
the	O
two	O
sets	O
.	O
	
These	O
results	O
indicate	O
scale	O
matters	O
in	O
the	O
classification	B-Task
tasks	I-Task
,	O
and	O
SPP	B-Method
-	I-Method
net	I-Method
can	O
partially	O
address	O
this	O
“	O
scale	O
mismatch	O
”	O
issue	O
.	O
	
In	O
Table	O
[	O
reference	O
]	O
	
(	O
e	O
)	O
the	O
network	B-Method
architecture	I-Method
is	O
replaced	O
with	O
our	O
best	O
model	O
(	O
Overfeat	B-Method
-	I-Method
7	I-Method
,	O
multi	O
-	O
size	O
trained	O
)	O
,	O
and	O
the	O
mAP	B-Metric
increases	O
to	O
82.44	O
%	O
.	O
	
Table	O
[	O
reference	O
]	O
summarizes	O
our	O
results	O
and	O
the	O
comparisons	O
with	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
methods	O
.	O
	
Among	O
these	O
methods	O
,	O
VQ	B-Method
,	O
LCC	B-Method
,	O
and	O
FK	B-Method
are	O
all	O
based	O
on	O
spatial	B-Method
pyramids	I-Method
matching	I-Method
,	O
and	O
are	O
based	O
on	O
deep	B-Method
networks	I-Method
.	O
	
In	O
these	O
results	O
,	O
Oquab	O
’s	O
(	O
77.7	O
%	O
)	O
and	O
Chatfield	B-Metric
’s	I-Metric
(	O
82.42	O
%	O
)	O
are	O
obtained	O
by	O
network	B-Method
fine	I-Method
-	I-Method
tuning	I-Method
and	O
multi	B-Method
-	I-Method
view	I-Method
testing	I-Method
.	O
	
Our	O
result	O
is	O
comparable	O
with	O
the	O
state	O
of	O
the	O
art	O
,	O
using	O
only	O
a	O
single	O
full	B-Method
-	I-Method
image	I-Method
representation	I-Method
and	O
without	O
fine	B-Method
-	I-Method
tuning	I-Method
.	O
	
subsection	O
:	O
Experiments	O
on	O
Caltech101	B-Material
	
The	O
Caltech101	B-Material
dataset	O
contains	O
9	O
,	O
144	O
images	O
in	O
102	O
categories	O
(	O
one	O
background	O
)	O
.	O
	
We	O
randomly	O
sample	O
30	O
images	O
per	O
category	O
for	O
training	O
and	O
up	O
to	O
50	O
images	O
per	O
category	O
for	O
testing	O
.	O
	
We	O
repeat	O
10	O
random	O
splits	O
and	O
average	O
the	O
accuracy	B-Metric
.	O
	
Table	O
[	O
reference	O
]	O
summarizes	O
our	O
results	O
.	O
	
There	O
are	O
some	O
common	O
observations	O
in	O
the	O
Pascal	B-Material
VOC	I-Material
2007	I-Material
and	O
Caltech101	B-Material
results	O
:	O
SPP	B-Method
-	I-Method
net	I-Method
is	O
better	O
than	O
the	O
no	O
-	O
SPP	B-Method
net	O
(	O
Table	O
[	O
reference	O
]	O
(	O
b	O
)	O
(	O
a	O
)	O
)	O
,	O
and	O
the	O
full	B-Method
-	I-Method
view	I-Method
representation	I-Method
is	O
better	O
than	O
the	O
crop	B-Method
(	O
(	O
c	O
)	O
(	O
b	O
)	O
)	O
.	O
	
But	O
the	O
results	O
in	O
Caltech101	B-Material
have	O
some	O
differences	O
with	O
Pascal	O
VOC	B-Material
.	O
	
The	O
fully	B-Method
-	I-Method
connected	I-Method
layers	I-Method
are	O
less	O
accurate	O
,	O
and	O
the	O
SPP	B-Method
layers	O
are	O
better	O
.	O
	
This	O
is	O
possibly	O
because	O
the	O
object	O
categories	O
in	O
Caltech101	B-Material
are	O
less	O
related	O
to	O
those	O
in	O
ImageNet	B-Material
,	O
and	O
the	O
deeper	B-Method
layers	I-Method
are	O
more	O
category	O
-	O
specialized	O
.	O
	
Further	O
,	O
we	O
find	O
that	O
the	O
scale	B-Method
224	I-Method
has	O
the	O
best	O
performance	O
among	O
the	O
scales	O
we	O
tested	O
on	O
this	O
dataset	O
.	O
	
This	O
is	O
mainly	O
because	O
the	O
objects	O
in	O
Caltech101	B-Material
also	O
occupy	O
large	O
regions	O
of	O
the	O
images	O
,	O
as	O
is	O
the	O
case	O
of	O
ImageNet	B-Material
.	O
	
Besides	O
cropping	B-Task
,	O
we	O
also	O
evaluate	O
warping	O
the	O
image	O
to	O
fit	O
the	O
224	O
224	O
size	O
.	O
	
This	O
solution	O
maintains	O
the	O
complete	O
content	O
,	O
but	O
introduces	O
distortion	O
.	O
	
On	O
the	O
SPP	B-Method
(	O
ZF	O
-	O
5	O
)	O
model	O
,	O
the	O
accuracy	B-Metric
is	O
89.91	O
%	O
using	O
the	O
SPP	B-Method
layer	O
as	O
features	O
-	O
lower	O
than	O
91.44	O
%	O
which	O
uses	O
the	O
same	O
model	O
on	O
the	O
undistorted	O
full	O
image	O
.	O
	
Table	O
[	O
reference	O
]	O
summarizes	O
our	O
results	O
compared	O
with	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
methods	O
on	O
Caltech101	B-Material
.	O
	
Our	O
result	O
(	O
93.42	O
%	O
)	O
exceeds	O
the	O
previous	O
record	O
(	O
88.54	O
%	O
)	O
by	O
a	O
substantial	O
margin	O
(	O
4.88	O
%	O
)	O
.	O
	
section	O
:	O
SPP	B-Method
-	I-Method
net	I-Method
for	O
Object	B-Task
Detection	I-Task
	
Deep	B-Method
networks	I-Method
have	O
been	O
used	O
for	O
object	B-Task
detection	I-Task
.	O
	
We	O
briefly	O
review	O
the	O
recent	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
R	B-Method
-	I-Method
CNN	I-Method
method	I-Method
.	O
	
R	B-Method
-	I-Method
CNN	I-Method
first	O
extracts	O
about	O
2	O
,	O
000	O
candidate	O
windows	O
from	O
each	O
image	O
via	O
selective	B-Method
search	I-Method
.	O
	
Then	O
the	O
image	O
region	O
in	O
each	O
window	O
is	O
warped	O
to	O
a	O
fixed	O
size	O
(	O
227	O
227	O
)	O
.	O
	
A	O
pre	O
-	O
trained	O
deep	B-Method
network	I-Method
is	O
used	O
to	O
extract	O
the	O
feature	O
of	O
each	O
window	O
.	O
	
A	O
binary	B-Method
SVM	I-Method
classifier	I-Method
is	O
then	O
trained	O
on	O
these	O
features	O
for	O
detection	B-Task
.	O
	
R	B-Method
-	I-Method
CNN	I-Method
generates	O
results	O
of	O
compelling	O
quality	O
and	O
substantially	O
outperforms	O
previous	O
methods	O
.	O
	
However	O
,	O
because	O
R	B-Method
-	I-Method
CNN	I-Method
repeatedly	O
applies	O
the	O
deep	B-Method
convolutional	I-Method
network	I-Method
to	O
about	O
2	O
,	O
000	O
windows	O
per	O
image	O
,	O
it	O
is	O
time	O
-	O
consuming	O
.	O
	
Feature	B-Task
extraction	I-Task
is	O
the	O
major	O
timing	O
bottleneck	O
in	O
testing	B-Task
.	O
	
Our	O
SPP	B-Method
-	I-Method
net	I-Method
can	O
also	O
be	O
used	O
for	O
object	B-Task
detection	I-Task
.	O
	
We	O
extract	O
the	O
feature	O
maps	O
from	O
the	O
entire	O
image	O
only	O
once	O
(	O
possibly	O
at	O
multiple	O
scales	O
)	O
.	O
	
Then	O
we	O
apply	O
the	O
spatial	B-Method
pyramid	I-Method
pooling	I-Method
on	O
each	O
candidate	O
window	O
of	O
the	O
feature	O
maps	O
to	O
pool	O
a	O
fixed	O
-	O
length	O
representation	O
of	O
this	O
window	O
(	O
see	O
Figure	O
[	O
reference	O
]	O
)	O
.	O
	
Because	O
the	O
time	O
-	O
consuming	O
convolutions	B-Method
are	O
only	O
applied	O
once	O
,	O
our	O
method	O
can	O
run	O
orders	O
of	O
magnitude	O
faster	O
.	O
	
Our	O
method	O
extracts	O
window	O
-	O
wise	O
features	O
from	O
regions	O
of	O
the	O
feature	O
maps	O
,	O
while	O
R	B-Method
-	I-Method
CNN	I-Method
extracts	O
directly	O
from	O
image	O
regions	O
.	O
	
In	O
previous	O
works	O
,	O
the	O
Deformable	B-Method
Part	I-Method
Model	I-Method
(	O
DPM	B-Method
)	O
extracts	O
features	O
from	O
windows	O
in	O
HOG	O
feature	O
maps	O
,	O
and	O
the	O
Selective	B-Method
Search	I-Method
(	I-Method
SS	I-Method
)	I-Method
method	I-Method
extracts	O
from	O
windows	O
in	O
encoded	O
SIFT	O
feature	O
maps	O
.	O
	
The	O
Overfeat	B-Method
detection	I-Method
method	I-Method
also	O
extracts	O
from	O
windows	B-Method
of	I-Method
deep	I-Method
convolutional	I-Method
feature	I-Method
maps	I-Method
,	O
but	O
needs	O
to	O
pre	O
-	O
define	O
the	O
window	O
size	O
.	O
	
On	O
the	O
contrary	O
,	O
our	O
method	O
enables	O
feature	B-Task
extraction	I-Task
in	O
arbitrary	O
windows	O
from	O
the	O
deep	B-Method
convolutional	I-Method
feature	I-Method
maps	I-Method
.	O
	
subsection	O
:	O
Detection	B-Method
Algorithm	I-Method
	
We	O
use	O
the	O
“	O
fast	O
”	O
mode	O
of	O
selective	B-Method
search	I-Method
to	O
generate	O
about	O
2	O
,	O
000	O
candidate	O
windows	O
per	O
image	O
.	O
	
Then	O
we	O
resize	O
the	O
image	O
such	O
that	O
,	O
and	O
extract	O
the	O
feature	O
maps	O
from	O
the	O
entire	O
image	O
.	O
	
We	O
use	O
the	O
SPP	B-Method
-	O
net	O
model	O
of	O
ZF	B-Method
-	I-Method
5	I-Method
(	I-Method
single	I-Method
-	I-Method
size	I-Method
trained	I-Method
)	O
for	O
the	O
time	O
being	O
.	O
	
In	O
each	O
candidate	O
window	O
,	O
we	O
use	O
a	O
4	O
-	O
level	O
spatial	O
pyramid	O
(	O
1	O
1	O
,	O
2	O
2	O
,	O
3	O
3	O
,	O
6	O
6	O
,	O
totally	O
50	O
bins	O
)	O
to	O
pool	O
the	O
features	O
.	O
	
This	O
generates	O
a	O
12	O
,	O
800	O
-	O
d	O
(	O
256	O
50	O
)	O
representation	O
for	O
each	O
window	O
.	O
	
These	O
representations	O
are	O
provided	O
to	O
the	O
fully	B-Method
-	I-Method
connected	I-Method
layers	I-Method
of	I-Method
the	I-Method
network	I-Method
.	O
	
Then	O
we	O
train	O
a	O
binary	B-Method
linear	I-Method
SVM	I-Method
classifier	I-Method
for	O
each	O
category	O
on	O
these	O
features	O
.	O
	
Our	O
implementation	O
of	O
the	O
SVM	B-Method
training	I-Method
follows	O
.	O
	
We	O
use	O
the	O
ground	O
-	O
truth	O
windows	O
to	O
generate	O
the	O
positive	O
samples	O
.	O
	
The	O
negative	O
samples	O
are	O
those	O
overlapping	O
a	O
positive	O
window	O
by	O
at	O
most	O
30	O
%	O
(	O
measured	O
by	O
the	O
intersection	B-Metric
-	I-Metric
over	I-Metric
-	I-Metric
union	I-Metric
(	I-Metric
IoU	I-Metric
)	I-Metric
ratio	I-Metric
)	O
.	O
	
Any	O
negative	O
sample	O
is	O
removed	O
if	O
it	O
overlaps	O
another	O
negative	O
sample	O
by	O
more	O
than	O
70	O
%	O
.	O
	
We	O
apply	O
the	O
standard	O
hard	B-Method
negative	I-Method
mining	I-Method
to	O
train	O
the	O
SVM	B-Method
.	O
	
This	O
step	O
is	O
iterated	O
once	O
.	O
	
It	O
takes	O
less	O
than	O
1	O
hour	O
to	O
train	O
SVMs	B-Method
for	O
all	O
20	O
categories	O
.	O
	
In	O
testing	O
,	O
the	O
classifier	B-Method
is	O
used	O
to	O
score	O
the	O
candidate	O
windows	O
.	O
	
Then	O
we	O
use	O
non	B-Method
-	I-Method
maximum	I-Method
suppression	I-Method
(	O
threshold	O
of	O
30	O
%	O
)	O
on	O
the	O
scored	O
windows	O
.	O
	
Our	O
method	O
can	O
be	O
improved	O
by	O
multi	B-Method
-	I-Method
scale	I-Method
feature	I-Method
extraction	I-Method
.	O
	
We	O
resize	O
the	O
image	O
such	O
that	O
,	O
and	O
compute	O
the	O
feature	O
maps	O
of	O
conv	B-Method
for	O
each	O
scale	O
.	O
	
One	O
strategy	O
of	O
combining	O
the	O
features	O
from	O
these	O
scales	O
is	O
to	O
pool	O
them	O
channel	O
-	O
by	O
-	O
channel	O
.	O
	
But	O
we	O
empirically	O
find	O
that	O
another	O
strategy	O
provides	O
better	O
results	O
.	O
	
For	O
each	O
candidate	O
window	O
,	O
we	O
choose	O
a	O
single	O
scale	O
such	O
that	O
the	O
scaled	O
candidate	O
window	O
has	O
a	O
number	O
of	O
pixels	O
closest	O
to	O
224	O
224	O
.	O
	
Then	O
we	O
only	O
use	O
the	O
feature	O
maps	O
extracted	O
from	O
this	O
scale	O
to	O
compute	O
the	O
feature	O
of	O
this	O
window	O
.	O
	
If	O
the	O
pre	O
-	O
defined	O
scales	O
are	O
dense	O
enough	O
and	O
the	O
window	O
is	O
approximately	O
square	O
,	O
our	O
method	O
is	O
roughly	O
equivalent	O
to	O
resizing	O
the	O
window	O
to	O
224	O
224	O
and	O
then	O
extracting	O
features	O
from	O
it	O
.	O
	
Nevertheless	O
,	O
our	O
method	O
only	O
requires	O
computing	O
the	O
feature	O
maps	O
once	O
(	O
at	O
each	O
scale	O
)	O
from	O
the	O
entire	O
image	O
,	O
regardless	O
of	O
the	O
number	O
of	O
candidate	O
windows	O
.	O
	
We	O
also	O
fine	O
-	O
tune	O
our	O
pre	B-Method
-	I-Method
trained	I-Method
network	I-Method
,	O
following	O
.	O
	
Since	O
our	O
features	O
are	O
pooled	O
from	O
the	O
conv	B-Method
feature	I-Method
maps	I-Method
from	O
windows	O
of	O
any	O
sizes	O
,	O
for	O
simplicity	O
we	O
only	O
fine	O
-	O
tune	O
the	O
fully	B-Method
-	I-Method
connected	I-Method
layers	I-Method
.	O
	
In	O
this	O
case	O
,	O
the	O
data	B-Method
layer	I-Method
accepts	O
the	O
fixed	O
-	O
length	O
pooled	O
features	O
after	O
conv	B-Method
,	O
and	O
the	O
fc	B-Method
layers	I-Method
and	O
a	O
new	O
21	O
-	O
way	O
(	O
one	O
extra	O
negative	O
category	O
)	O
fc	B-Method
layer	I-Method
follow	O
.	O
	
The	O
fc	B-Method
weights	I-Method
are	O
initialized	O
with	O
a	O
Gaussian	B-Method
distribution	I-Method
of	O
=	O
0.01	O
.	O
	
We	O
fix	O
all	O
the	O
learning	B-Metric
rates	I-Metric
to	O
1e	O
-	O
4	O
and	O
then	O
adjust	O
to	O
1e	O
-	O
5	O
for	O
all	O
three	O
layers	O
.	O
	
During	O
fine	B-Task
-	I-Task
tuning	I-Task
,	O
the	O
positive	O
samples	O
are	O
those	O
overlapping	O
with	O
a	O
ground	O
-	O
truth	O
window	O
by	O
,	O
and	O
the	O
negative	O
samples	O
by	O
.	O
	
In	O
each	O
mini	O
-	O
batch	O
,	O
25	O
%	O
of	O
the	O
samples	O
are	O
positive	O
.	O
	
We	O
train	O
250k	O
	
mini	O
-	O
batches	O
using	O
the	O
learning	B-Metric
rate	I-Metric
1e	I-Metric
-	I-Metric
4	I-Metric
,	O
and	O
then	O
50k	O
mini	O
-	O
batches	O
using	O
1e	O
-	O
5	O
.	O
	
Because	O
we	O
only	O
fine	O
-	O
tune	O
the	O
fc	B-Method
layers	I-Method
,	O
the	O
training	B-Task
is	O
very	O
fast	O
and	O
takes	O
about	O
2	O
hours	O
on	O
the	O
GPU	O
(	O
excluding	O
pre	O
-	O
caching	O
feature	O
maps	O
which	O
takes	O
about	O
1	O
hour	O
)	O
.	O
	
Also	O
following	O
,	O
we	O
use	O
bounding	B-Method
box	I-Method
regression	I-Method
to	O
post	O
-	O
process	O
the	O
prediction	O
windows	O
.	O
	
The	O
features	O
used	O
for	O
regression	B-Task
are	O
the	O
pooled	O
features	O
from	O
conv	B-Method
(	O
as	O
a	O
counterpart	O
of	O
the	O
pool	O
features	O
used	O
in	O
)	O
.	O
	
The	O
windows	O
used	O
for	O
the	O
regression	B-Task
training	I-Task
are	O
those	O
overlapping	O
with	O
a	O
ground	O
-	O
truth	O
window	O
by	O
at	O
least	O
50	O
%	O
.	O
	
subsection	O
:	O
Detection	B-Task
Results	O
	
We	O
evaluate	O
our	O
method	O
on	O
the	O
detection	B-Task
task	I-Task
of	O
the	O
Pascal	O
VOC	B-Material
2007	O
dataset	O
.	O
	
Table	O
[	O
reference	O
]	O
shows	O
our	O
results	O
on	O
various	O
layers	O
,	O
by	O
using	O
1	O
-	O
scale	O
(	O
=	O
688	O
)	O
or	O
	
5	B-Method
-	I-Method
scale	I-Method
.	O
	
Here	O
the	O
R	B-Method
-	I-Method
CNN	I-Method
results	O
are	O
as	O
reported	O
in	O
using	O
the	O
AlexNet	B-Method
with	O
5	O
conv	B-Method
layers	I-Method
.	O
	
Using	O
the	O
pool	O
layers	O
(	O
in	O
our	O
case	O
the	O
pooled	O
features	O
)	O
,	O
our	O
result	O
(	O
44.9	O
%	O
)	O
is	O
comparable	O
with	O
R	B-Method
-	I-Method
CNN	I-Method
’s	O
result	O
(	O
44.2	O
%	O
)	O
.	O
	
But	O
using	O
the	O
non	O
-	O
fine	B-Method
-	I-Method
tuned	I-Method
fc	I-Method
layers	I-Method
,	O
our	O
results	O
are	O
inferior	O
.	O
	
An	O
explanation	O
is	O
that	O
our	O
fc	B-Method
layers	I-Method
are	O
pre	O
-	O
trained	O
using	O
image	O
regions	O
,	O
while	O
in	O
the	O
detection	B-Task
case	I-Task
they	O
are	O
used	O
on	O
the	O
feature	O
map	O
regions	O
.	O
	
The	O
feature	O
map	O
regions	O
can	O
have	O
strong	O
activations	O
near	O
the	O
window	O
boundaries	O
,	O
while	O
the	O
image	O
regions	O
may	O
not	O
.	O
	
This	O
difference	O
of	O
usages	O
can	O
be	O
addressed	O
by	O
fine	B-Method
-	I-Method
tuning	I-Method
.	O
	
Using	O
the	O
fine	B-Method
-	I-Method
tuned	I-Method
fc	I-Method
layers	I-Method
(	O
ftfc	B-Method
)	O
,	O
our	O
results	O
are	O
comparable	O
with	O
or	O
slightly	O
better	O
than	O
the	O
fine	O
-	O
tuned	O
results	O
of	O
R	B-Method
-	I-Method
CNN	I-Method
.	O
	
After	O
bounding	B-Method
box	I-Method
regression	I-Method
,	O
our	O
5	B-Metric
-	I-Metric
scale	I-Metric
result	I-Metric
(	O
59.2	O
%	O
)	O
is	O
0.7	O
%	O
better	O
than	O
R	B-Method
-	I-Method
CNN	I-Method
(	O
58.5	O
%	O
)	O
,	O
and	O
our	O
1	B-Metric
-	I-Metric
scale	I-Metric
result	I-Metric
(	O
58.0	O
%	O
)	O
is	O
0.5	O
%	O
worse	O
.	O
	
In	O
Table	O
[	O
reference	O
]	O
we	O
further	O
compare	O
with	O
R	B-Method
-	I-Method
CNN	I-Method
using	O
the	O
same	O
pre	B-Method
-	I-Method
trained	I-Method
model	I-Method
of	O
SPPnet	B-Method
(	O
ZF	B-Method
-	I-Method
5	I-Method
)	O
.	O
	
In	O
this	O
case	O
,	O
our	O
method	O
and	O
R	B-Method
-	I-Method
CNN	I-Method
have	O
comparable	O
averaged	B-Metric
scores	I-Metric
.	O
	
The	O
R	B-Task
-	I-Task
CNN	I-Task
result	O
is	O
boosted	O
by	O
this	O
pre	O
-	O
trained	O
model	O
.	O
	
This	O
is	O
because	O
of	O
the	O
better	O
architecture	O
of	O
ZF	B-Method
-	I-Method
5	I-Method
than	O
AlexNet	B-Method
,	O
and	O
also	O
because	O
of	O
the	O
multi	B-Method
-	I-Method
level	I-Method
pooling	I-Method
of	O
SPPnet	B-Method
(	O
if	O
using	O
the	O
no	O
-	O
SPP	B-Method
ZF	O
-	O
5	O
,	O
the	O
R	B-Method
-	I-Method
CNN	I-Method
result	O
drops	O
)	O
.	O
	
Table	O
[	O
reference	O
]	O
shows	O
the	O
results	O
for	O
each	O
category	O
.	O
	
Table	O
[	O
reference	O
]	O
also	O
includes	O
additional	O
methods	O
.	O
	
Selective	B-Method
Search	I-Method
(	O
SS	B-Method
)	O
applies	O
spatial	B-Method
pyramid	I-Method
matching	I-Method
on	O
SIFT	O
feature	O
maps	O
.	O
	
DPM	B-Method
and	O
Regionlet	B-Method
are	O
based	O
on	O
HOG	O
features	O
.	O
	
The	O
Regionlet	B-Method
method	I-Method
improves	O
to	O
46.1	O
%	O
by	O
combining	O
various	O
features	O
including	O
conv	O
.	O
	
DetectorNet	B-Method
trains	O
a	O
deep	B-Method
network	I-Method
that	O
outputs	O
pixel	O
-	O
wise	O
object	O
masks	O
.	O
	
This	O
method	O
only	O
needs	O
to	O
apply	O
the	O
deep	B-Method
network	I-Method
once	O
to	O
the	O
entire	O
image	O
,	O
as	O
is	O
the	O
case	O
for	O
our	O
method	O
.	O
	
But	O
this	O
method	O
has	O
lower	O
mAP	B-Metric
(	O
30.5	O
%	O
)	O
.	O
	
subsection	O
:	O
Complexity	B-Metric
and	O
Running	B-Metric
Time	I-Metric
	
Despite	O
having	O
comparable	O
accuracy	B-Metric
,	O
our	O
method	O
is	O
much	O
faster	O
than	O
R	B-Method
-	I-Method
CNN	I-Method
.	O
	
The	O
complexity	B-Metric
of	O
the	O
convolutional	B-Method
feature	I-Method
computation	I-Method
in	O
R	B-Method
-	I-Method
CNN	I-Method
is	O
with	O
the	O
window	O
number	O
(	O
2000	O
)	O
.	O
	
This	O
complexity	O
of	O
our	O
method	O
is	O
at	O
a	O
scale	O
,	O
where	O
is	O
the	O
aspect	O
ratio	O
.	O
	
Assume	O
is	O
about	O
4	O
/	O
3	O
.	O
	
In	O
the	O
single	O
-	O
scale	O
version	O
when	O
,	O
this	O
complexity	O
is	O
about	O
1	O
/	O
160	O
of	O
R	B-Method
-	I-Method
CNN	I-Method
’s	I-Method
;	O
in	O
the	O
5	O
-	O
scale	O
version	O
,	O
this	O
complexity	O
is	O
about	O
1	O
/	O
24	O
of	O
R	B-Method
-	I-Method
CNN	I-Method
’s	I-Method
.	O
	
In	O
Table	O
[	O
reference	O
]	O
,	O
we	O
provide	O
a	O
fair	O
comparison	O
on	O
the	O
running	B-Metric
time	I-Metric
of	O
the	O
feature	B-Method
computation	I-Method
using	O
the	O
same	O
SPP	B-Method
(	O
ZF	O
-	O
5	O
)	O
model	O
.	O
	
The	O
implementation	O
of	O
R	B-Method
-	I-Method
CNN	I-Method
is	O
from	O
the	O
code	O
published	O
by	O
the	O
authors	O
implemented	O
in	O
Caffe	B-Method
.	O
	
We	O
also	O
implement	O
our	O
feature	B-Method
computation	I-Method
in	O
Caffe	B-Method
.	O
	
In	O
Table	O
[	O
reference	O
]	O
we	O
evaluate	O
the	O
average	B-Metric
time	I-Metric
of	O
100	O
random	O
VOC	B-Material
images	O
using	O
GPU	B-Method
.	O
	
R	B-Method
-	I-Method
CNN	I-Method
takes	O
14.37s	O
per	O
image	O
for	O
convolutions	B-Task
,	O
while	O
our	O
1	B-Method
-	I-Method
scale	I-Method
version	I-Method
takes	O
only	O
0.053s	O
per	O
image	O
.	O
	
So	O
ours	O
is	O
270	O
faster	O
than	O
R	B-Method
-	I-Method
CNN	I-Method
.	O
	
Our	O
5	B-Method
-	I-Method
scale	I-Method
version	I-Method
takes	O
0.293s	O
per	O
image	O
for	O
convolutions	B-Method
,	O
so	O
is	O
49	O
faster	O
than	O
R	B-Method
-	I-Method
CNN	I-Method
.	O
	
Our	O
convolutional	B-Method
feature	I-Method
computation	I-Method
is	O
so	O
fast	O
that	O
the	O
computational	B-Metric
time	I-Metric
of	O
fc	B-Method
layers	I-Method
takes	O
a	O
considerable	O
portion	O
.	O
	
Table	O
[	O
reference	O
]	O
shows	O
that	O
the	O
GPU	B-Metric
time	I-Metric
of	O
computing	O
the	O
4	O
,	O
096	O
-	O
d	O
fc	O
features	O
is	O
0.089s	O
per	O
image	O
.	O
	
Considering	O
both	O
convolutional	B-Method
and	I-Method
fully	I-Method
-	I-Method
connected	I-Method
features	I-Method
,	O
our	O
1	B-Method
-	I-Method
scale	I-Method
version	I-Method
is	O
102×	O
faster	O
than	O
R	B-Method
-	I-Method
CNN	I-Method
and	O
is	O
1.2	O
%	O
inferior	O
;	O
our	O
5	B-Method
-	I-Method
scale	I-Method
version	I-Method
is	O
38×	O
faster	O
and	O
has	O
comparable	O
results	O
.	O
	
We	O
also	O
compares	O
the	O
running	B-Metric
time	I-Metric
in	O
Table	O
[	O
reference	O
]	O
where	O
R	B-Method
-	I-Method
CNN	I-Method
uses	O
AlexNet	B-Method
as	O
is	O
in	O
the	O
original	O
paper	O
.	O
	
Our	O
method	O
is	O
24	O
to	O
64	O
faster	O
.	O
	
Note	O
that	O
the	O
AlexNet	B-Method
has	O
the	O
same	O
number	O
of	O
filters	O
as	O
our	O
ZF	B-Method
-	I-Method
5	I-Method
on	O
each	O
conv	B-Method
layer	I-Method
.	O
	
The	O
AlexNet	B-Method
is	O
faster	O
because	O
it	O
uses	O
splitting	O
on	O
some	O
layers	O
,	O
which	O
was	O
designed	O
for	O
two	O
GPUs	O
in	O
.	O
	
We	O
further	O
achieve	O
an	O
efficient	O
full	B-Method
system	I-Method
with	O
the	O
help	O
of	O
the	O
recent	B-Method
window	I-Method
proposal	I-Method
method	I-Method
.	O
	
The	O
Selective	B-Method
Search	I-Method
(	I-Method
SS	I-Method
)	I-Method
proposal	I-Method
takes	O
about	O
1	O
-	O
2	O
seconds	O
per	O
image	O
on	O
a	O
CPU	O
.	O
	
The	O
method	O
of	O
EdgeBoxes	B-Method
only	O
takes	O
0.2s	O
.	O
	
Note	O
that	O
it	O
is	O
sufficient	O
to	O
use	O
a	O
fast	O
proposal	B-Method
method	I-Method
during	O
testing	B-Task
only	O
.	O
	
Using	O
the	O
same	O
model	O
trained	O
as	O
above	O
(	O
using	O
SS	B-Method
)	O
,	O
we	O
test	O
proposals	O
generated	O
by	O
EdgeBoxes	O
only	O
.	O
	
The	O
mAP	B-Metric
is	O
52.8	O
without	O
bounding	B-Method
box	I-Method
regression	I-Method
.	O
	
This	O
is	O
reasonable	O
considering	O
that	O
EdgeBoxes	O
are	O
not	O
used	O
for	O
training	B-Task
.	O
	
Then	O
we	O
use	O
both	O
SS	B-Method
and	O
EdgeBox	O
as	O
proposals	O
in	O
the	O
training	O
stage	O
,	O
and	O
adopt	O
only	O
EdgeBoxes	O
in	O
the	O
testing	O
stage	O
.	O
	
The	O
mAP	B-Metric
is	O
56.3	O
without	O
bounding	B-Method
box	I-Method
regression	I-Method
,	O
which	O
is	O
better	O
than	O
55.2	O
(	O
Table	O
[	O
reference	O
]	O
)	O
due	O
to	O
additional	O
training	O
samples	O
.	O
	
In	O
this	O
case	O
,	O
the	O
overall	O
testing	B-Metric
time	I-Metric
is	O
0.5s	O
per	O
image	O
including	O
all	O
steps	O
(	O
proposal	O
and	O
recognition	B-Task
)	O
.	O
	
This	O
makes	O
our	O
method	O
practical	O
for	O
real	B-Task
-	I-Task
world	I-Task
applications	I-Task
.	O
	
subsection	O
:	O
Model	B-Method
Combination	I-Method
for	O
Detection	B-Task
	
Model	B-Method
combination	I-Method
is	O
an	O
important	O
strategy	O
for	O
boosting	B-Task
CNN	I-Task
-	I-Task
based	I-Task
classification	I-Task
accuracy	I-Task
.	O
	
We	O
propose	O
a	O
simple	O
combination	B-Method
method	I-Method
for	O
detection	B-Task
.	O
	
We	O
pre	O
-	O
train	O
another	O
network	O
in	O
ImageNet	B-Material
,	O
using	O
the	O
same	O
structure	O
but	O
different	O
random	O
initializations	O
.	O
	
Then	O
we	O
repeat	O
the	O
above	O
detection	B-Method
algorithm	I-Method
.	O
	
Table	O
[	O
reference	O
]	O
	
(	O
SPP	B-Method
-	I-Method
net	I-Method
(	O
2	O
)	O
)	O
shows	O
the	O
results	O
of	O
this	O
network	O
.	O
	
Its	O
mAP	B-Metric
is	O
comparable	O
with	O
the	O
first	O
network	O
(	O
59.1	O
%	O
59.2	O
%	O
)	O
,	O
and	O
outperforms	O
the	O
first	O
network	O
in	O
11	O
categories	O
.	O
	
Given	O
the	O
two	O
models	O
,	O
we	O
first	O
use	O
either	O
model	O
to	O
score	O
all	O
candidate	O
windows	O
on	O
the	O
test	O
image	O
.	O
	
Then	O
we	O
perform	O
non	B-Method
-	I-Method
maximum	I-Method
suppression	I-Method
on	O
the	O
union	O
of	O
the	O
two	O
sets	O
of	O
candidate	O
windows	O
(	O
with	O
their	O
scores	O
)	O
.	O
	
A	O
more	O
confident	O
window	O
given	O
by	O
one	O
method	O
can	O
suppress	O
those	O
less	O
confident	O
given	O
by	O
the	O
other	O
method	O
.	O
	
After	O
combination	B-Task
,	O
the	O
mAP	B-Metric
is	O
boosted	O
to	O
60.9	O
%	O
(	O
Table	O
[	O
reference	O
]	O
)	O
.	O
	
In	O
17	O
out	O
of	O
all	O
20	O
categories	O
the	O
combination	O
performs	O
better	O
than	O
either	O
individual	O
model	O
.	O
	
This	O
indicates	O
that	O
the	O
two	O
models	O
are	O
complementary	O
.	O
	
We	O
further	O
find	O
that	O
the	O
complementarity	O
is	O
mainly	O
because	O
of	O
the	O
convolutional	B-Method
layers	I-Method
.	O
	
We	O
have	O
tried	O
to	O
combine	O
two	O
randomly	O
initialized	O
fine	O
-	O
tuned	O
results	O
of	O
the	O
same	O
convolutional	B-Method
model	I-Method
,	O
and	O
found	O
no	O
gain	O
.	O
	
subsection	O
:	O
ILSVRC	B-Task
2014	I-Task
Detection	O
	
The	O
ILSVRC	B-Task
2014	I-Task
detection	O
task	O
involves	O
200	O
categories	O
.	O
	
There	O
are	O
450k	O
/	O
20k	O
/	O
40k	O
images	O
in	O
the	O
training	O
/	O
validation	O
/	O
testing	O
sets	O
.	O
	
We	O
focus	O
on	O
the	O
task	O
of	O
the	O
provided	O
-	O
data	O
-	O
only	O
track	O
(	O
the	O
1000	B-Material
-	I-Material
category	I-Material
CLS	I-Material
training	I-Material
data	I-Material
is	O
not	O
allowed	O
to	O
use	O
)	O
.	O
	
There	O
are	O
three	O
major	O
differences	O
between	O
the	O
detection	B-Task
(	I-Task
DET	I-Task
)	O
and	O
classification	B-Task
(	I-Task
CLS	I-Task
)	O
training	O
datasets	O
,	O
which	O
greatly	O
impacts	O
the	O
pre	B-Metric
-	I-Metric
training	I-Metric
quality	I-Metric
.	O
	
First	O
,	O
the	O
DET	B-Material
training	I-Material
data	I-Material
is	O
merely	O
1	O
/	O
3	O
of	O
the	O
CLS	B-Material
training	I-Material
data	I-Material
.	O
	
This	O
seems	O
to	O
be	O
a	O
fundamental	O
challenge	O
of	O
the	O
provided	B-Task
-	I-Task
data	I-Task
-	I-Task
only	I-Task
DET	I-Task
task	I-Task
.	O
	
Second	O
,	O
the	O
category	O
number	O
of	O
DET	O
is	O
1	O
/	O
5	O
of	O
CLS	O
.	O
	
To	O
overcome	O
this	O
problem	O
,	O
we	O
harness	O
the	O
provided	O
subcategory	O
labels	O
for	O
pre	B-Task
-	I-Task
training	I-Task
.	O
	
There	O
are	O
totally	O
499	O
non	O
-	O
overlapping	O
subcategories	O
(	O
,	O
the	O
leaf	O
nodes	O
in	O
the	O
provided	O
category	O
hierarchy	O
)	O
.	O
	
So	O
we	O
pre	O
-	O
train	O
a	O
499	B-Method
-	I-Method
category	I-Method
network	I-Method
on	O
the	O
DET	B-Material
training	I-Material
set	I-Material
.	O
	
Third	O
,	O
the	O
distributions	O
of	O
object	O
scales	O
are	O
different	O
between	O
DET	B-Material
/	I-Material
CLS	I-Material
training	I-Material
sets	I-Material
.	O
	
The	O
dominant	O
object	O
scale	O
in	O
CLS	B-Method
is	O
about	O
0.8	O
of	O
the	O
image	O
length	O
,	O
but	O
in	O
DET	O
is	O
about	O
0.5	O
.	O
	
To	O
address	O
the	O
scale	O
difference	O
,	O
we	O
resize	O
each	O
training	O
image	O
to	O
(	O
instead	O
of	O
)	O
,	O
and	O
randomly	O
crop	O
views	O
for	O
training	O
.	O
	
A	O
crop	O
is	O
only	O
used	O
when	O
it	O
overlaps	O
with	O
a	O
ground	O
truth	O
object	O
by	O
at	O
least	O
50	O
%	O
.	O
	
We	O
verify	O
the	O
effect	O
of	O
pre	B-Task
-	I-Task
training	I-Task
on	O
Pascal	B-Material
VOC	I-Material
2007	I-Material
.	O
	
For	O
a	O
CLS	B-Task
-	I-Task
pre	I-Task
-	I-Task
training	I-Task
baseline	I-Task
,	O
we	O
consider	O
the	O
pool	O
features	O
(	O
mAP	B-Metric
43.0	O
%	O
in	O
Table	O
[	O
reference	O
]	O
)	O
.	O
	
Replaced	O
with	O
a	O
200	B-Method
-	I-Method
category	I-Method
network	I-Method
pre	O
-	O
trained	O
on	O
DET	B-Method
,	O
the	O
mAP	B-Metric
significantly	O
drops	O
to	O
32.7	O
%	O
.	O
	
A	O
499	O
-	O
category	O
pre	B-Method
-	I-Method
trained	I-Method
network	I-Method
improves	O
the	O
result	O
to	O
35.9	O
%	O
.	O
	
Interestingly	O
,	O
even	O
if	O
the	O
amount	O
of	O
training	O
data	O
do	O
not	O
increase	O
,	O
training	O
a	O
network	O
of	O
more	O
categories	O
boosts	O
the	O
feature	B-Metric
quality	I-Metric
.	O
	
Finally	O
,	O
training	O
with	O
instead	O
of	O
further	O
improves	O
the	O
mAP	B-Metric
to	O
37.8	O
%	O
.	O
	
Even	O
so	O
,	O
we	O
see	O
that	O
there	O
is	O
still	O
a	O
considerable	O
gap	O
to	O
the	O
CLS	B-Method
-	O
pre	O
-	O
training	O
result	O
.	O
	
This	O
indicates	O
the	O
importance	O
of	O
big	O
data	O
to	O
deep	B-Task
learning	I-Task
.	O
	
For	O
ILSVRC	B-Task
2014	I-Task
,	O
we	O
train	O
a	O
499	O
-	O
category	O
Overfeat	B-Method
-	I-Method
7	I-Method
SPP	I-Method
-	I-Method
net	I-Method
.	O
	
The	O
remaining	O
steps	O
are	O
similar	O
to	O
the	O
VOC	B-Material
2007	O
case	O
.	O
	
Following	O
,	O
we	O
use	O
the	O
validation	O
set	O
to	O
generate	O
the	O
positive	O
/	O
negative	O
samples	O
,	O
with	O
windows	O
proposed	O
by	O
the	O
selective	B-Method
search	I-Method
fast	I-Method
mode	I-Method
.	O
	
The	O
training	O
set	O
only	O
contributes	O
positive	O
samples	O
using	O
the	O
ground	O
truth	O
windows	O
.	O
	
We	O
fine	O
-	O
tune	O
the	O
fc	B-Method
layers	I-Method
and	O
then	O
train	O
the	O
SVMs	B-Method
using	O
the	O
samples	O
in	O
both	O
validation	O
and	O
training	O
sets	O
.	O
	
The	O
bounding	B-Method
box	I-Method
regression	I-Method
is	O
trained	O
on	O
the	O
validation	O
set	O
.	O
	
Our	O
single	O
model	O
leads	O
to	O
31.84	O
%	O
mAP	B-Metric
in	O
the	O
ILSVRC	B-Task
2014	I-Task
testing	O
set	O
.	O
	
We	O
combine	O
six	O
similar	O
models	O
using	O
the	O
strategy	O
introduced	O
in	O
this	O
paper	O
.	O
	
The	O
mAP	B-Metric
is	O
35.11	O
%	O
in	O
the	O
testing	O
set	O
.	O
	
This	O
result	O
ranks	O
#	O
2	O
in	O
the	O
provided	O
-	O
data	O
-	O
only	O
track	O
of	O
ILSVRC	B-Task
2014	I-Task
(	O
Table	O
[	O
reference	O
]	O
)	O
.	O
	
The	O
winning	O
result	O
is	O
37.21	O
%	O
from	O
NUS	B-Method
,	O
which	O
uses	O
contextual	O
information	O
.	O
	
Our	O
system	O
still	O
shows	O
great	O
advantages	O
on	O
speed	B-Metric
for	O
this	O
dataset	O
.	O
	
It	O
takes	O
our	O
single	O
model	O
0.6	O
seconds	O
(	O
0.5	O
for	O
conv	B-Method
,	O
0.1	O
for	O
fc	B-Method
,	O
excluding	O
proposals	O
)	O
per	O
testing	O
image	O
on	O
a	O
GPU	O
extracting	O
convolutional	O
features	O
from	O
all	O
5	O
scales	O
.	O
	
Using	O
the	O
same	O
model	O
,	O
it	O
takes	O
32	O
seconds	O
per	O
image	O
in	O
the	O
way	O
of	O
RCNN	B-Method
.	O
	
For	O
the	O
40k	O
testing	O
images	O
,	O
our	O
method	O
requires	O
8	O
GPU	O
hours	O
to	O
compute	O
convolutional	O
features	O
,	O
while	O
RCNN	B-Method
would	O
require	O
15	O
GPU	O
days	O
.	O
	
section	O
:	O
Conclusion	O
	
SPP	B-Method
is	O
a	O
flexible	O
solution	O
for	O
handling	O
different	O
scales	O
,	O
sizes	O
,	O
and	O
aspect	O
ratios	O
.	O
	
These	O
issues	O
are	O
important	O
in	O
visual	B-Task
recognition	I-Task
,	O
but	O
received	O
little	O
consideration	O
in	O
the	O
context	O
of	O
deep	B-Method
networks	I-Method
.	O
	
We	O
have	O
suggested	O
a	O
solution	O
to	O
train	O
a	O
deep	B-Method
network	I-Method
with	O
a	O
spatial	B-Method
pyramid	I-Method
pooling	I-Method
layer	O
.	O
	
The	O
resulting	O
SPP	B-Method
-	I-Method
net	I-Method
shows	O
outstanding	O
accuracy	B-Metric
in	O
classification	B-Task
/	I-Task
detection	I-Task
tasks	I-Task
and	O
greatly	O
accelerates	O
DNN	B-Method
-	I-Method
based	I-Method
detection	I-Method
.	O
	
Our	O
studies	O
also	O
show	O
that	O
many	O
time	O
-	O
proven	O
techniques	O
/	O
insights	O
in	O
computer	B-Task
vision	I-Task
can	O
still	O
play	O
important	O
roles	O
in	O
deep	B-Task
-	I-Task
networks	I-Task
-	I-Task
based	I-Task
recognition	I-Task
.	O
	
section	O
:	O
	
In	O
the	O
appendix	O
,	O
we	O
describe	O
some	O
implementation	O
details	O
:	O
	
Mean	B-Method
Subtraction	I-Method
.	O
	
The	O
224	O
224	O
cropped	O
training	O
/	O
testing	O
images	O
are	O
often	O
pre	O
-	O
processed	O
by	O
subtracting	O
the	O
per	O
-	O
pixel	O
mean	O
.	O
	
When	O
input	O
images	O
are	O
in	O
any	O
sizes	O
,	O
the	O
fixed	B-Method
-	I-Method
size	I-Method
mean	I-Method
image	I-Method
is	O
not	O
directly	O
applicable	O
.	O
	
In	O
the	O
ImageNet	B-Material
dataset	I-Material
,	O
we	O
warp	O
the	O
224	O
224	O
mean	O
image	O
to	O
the	O
desired	O
size	O
and	O
then	O
subtract	O
it	O
.	O
	
In	O
Pascal	B-Material
VOC	I-Material
2007	I-Material
and	O
Caltech101	B-Material
,	O
we	O
use	O
the	O
constant	O
mean	O
(	O
128	O
)	O
in	O
all	O
the	O
experiments	O
.	O
	
Implementation	O
of	O
Pooling	O
Bins	O
.	O
	
We	O
use	O
the	O
following	O
implementation	O
to	O
handle	O
all	O
bins	O
when	O
applying	O
the	O
network	O
.	O
	
Denote	O
the	O
width	O
and	O
height	O
of	O
the	O
conv	O
feature	O
maps	O
(	O
can	O
be	O
the	O
full	O
image	O
or	O
a	O
window	O
)	O
as	O
and	O
.	O
	
For	O
a	O
pyramid	O
level	O
with	O
bins	O
,	O
the	O
-	O
th	O
bin	O
is	O
in	O
the	O
range	O
of	O
.	O
	
Intuitively	O
,	O
if	O
rounding	O
is	O
needed	O
,	O
we	O
take	O
the	O
floor	O
operation	O
on	O
the	O
left	O
/	O
top	O
boundary	O
and	O
ceiling	O
on	O
the	O
right	O
/	O
bottom	O
boundary	O
.	O
	
Mapping	O
a	O
Window	O
to	O
Feature	O
Maps	O
.	O
	
In	O
the	O
detection	B-Method
algorithm	I-Method
(	O
and	O
multi	B-Task
-	I-Task
view	I-Task
testing	I-Task
on	I-Task
feature	I-Task
maps	I-Task
)	O
,	O
a	O
window	O
is	O
given	O
in	O
the	O
image	O
domain	O
,	O
and	O
we	O
use	O
it	O
to	O
crop	O
the	O
convolutional	O
feature	O
maps	O
(	O
,	O
conv	O
)	O
which	O
have	O
been	O
sub	O
-	O
sampled	O
several	O
times	O
.	O
	
So	O
we	O
need	O
to	O
align	O
the	O
window	O
on	O
the	O
feature	O
maps	O
.	O
	
In	O
our	O
implementation	O
,	O
we	O
project	O
the	O
corner	O
point	O
of	O
a	O
window	O
onto	O
a	O
pixel	O
in	O
the	O
feature	O
maps	O
,	O
such	O
that	O
this	O
corner	O
point	O
in	O
the	O
image	O
domain	O
is	O
closest	O
to	O
the	O
center	O
of	O
the	O
receptive	O
field	O
of	O
that	O
feature	O
map	O
pixel	O
.	O
	
The	O
mapping	B-Task
is	O
complicated	O
by	O
the	O
padding	B-Method
of	I-Method
all	I-Method
convolutional	I-Method
and	I-Method
pooling	I-Method
layers	I-Method
.	O
	
To	O
simplify	O
the	O
implementation	O
,	O
during	O
deployment	O
we	O
pad	O
pixels	O
for	O
a	O
layer	O
with	O
a	O
filter	O
size	O
of	O
.	O
	
As	O
such	O
,	O
for	O
a	O
response	O
centered	O
at	O
,	O
its	O
effective	O
receptive	O
field	O
in	O
the	O
image	O
domain	O
is	O
centered	O
at	O
where	O
is	O
the	O
product	O
of	O
all	O
previous	O
strides	O
.	O
	
In	O
our	O
models	O
,	O
for	O
ZF	B-Task
-	I-Task
5	I-Task
on	O
conv	B-Task
,	O
and	O
for	O
Overfeat	O
-	O
5	O
/	O
7	O
on	O
conv	O
.	O
	
Given	O
a	O
window	O
in	O
the	O
image	O
domain	O
,	O
we	O
project	O
the	O
left	O
(	O
top	O
)	O
boundary	O
by	O
:	O
and	O
the	O
right	O
(	O
bottom	O
)	O
boundary	O
.	O
	
If	O
the	O
padding	O
is	O
not	O
,	O
we	O
need	O
to	O
add	O
a	O
proper	O
offset	O
to	O
.	O
	
bibliography	O
:	O
References	O
	
section	O
:	O
Changelog	O
	
arXiv	O
v1	O
.	O
	
Initial	O
technical	O
report	O
for	O
ECCV	O
2014	O
paper	O
.	O
	
arXiv	O
	
v2	O
.	O
	
Submitted	O
version	O
for	O
TPAMI	O
.	O
	
Includes	O
extra	O
experiments	O
of	O
SPP	B-Method
on	O
various	O
architectures	O
.	O
	
Includes	O
details	O
for	O
ILSVRC	B-Task
2014	I-Task
.	O
arXiv	O
	
v3	O
.	O
	
Accepted	O
version	O
for	O
TPAMI	B-Task
.	O
	
Includes	O
comparisons	O
with	O
R	B-Method
-	I-Method
CNN	I-Method
using	O
the	O
same	O
architecture	O
.	O
	
Includes	O
detection	B-Task
experiments	O
using	O
EdgeBoxes	O
.	O
	
arXiv	O
v4	O
.	O
	
Revised	O
“	O
	
Mapping	O
a	O
Window	O
to	O
Feature	O
Maps	O
”	O
in	O
Appendix	O
for	O
easier	O
implementation	O
.	O
	
	
	
